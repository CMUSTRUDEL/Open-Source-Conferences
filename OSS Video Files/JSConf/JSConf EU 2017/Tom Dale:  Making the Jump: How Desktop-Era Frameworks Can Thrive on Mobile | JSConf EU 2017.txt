Title: Tom Dale:  Making the Jump: How Desktop-Era Frameworks Can Thrive on Mobile | JSConf EU 2017
Publication date: 2017-05-23
Playlist: JSConf EU 2017
Description: 
	http://2017.jsconf.eu/speakers/tom-dale-making-the-jump-how-desktopera-frameworks-can-thrive-on-mobile.html

Today’s most popular frameworks come from a time when the world was a different place. Ember’s first rendering engine, for example, was optimized around the performance gotchas of Internet Explorer 6. IE6 has since faded into history, and smartphones with spotty connectivity and occasionally dodgy hardware have become the lowest common denominator that we must optimize for.

In this talk, we’ll discuss how smartphones fundamentally change the assumptions we make about architecting applications for the web. Then, we’ll cover how we can embrace these new mobile constraints to build even better apps—for everyone. Finally, we’ll look at the techniques used by desktop-era libraries and what they’re doing to become great for the mobile web.
Captions: 
	00:00:03,100 --> 00:00:28,000
"Making the Jump: How Desktop-Era Frameworks Can Thrive on Mobile"

00:00:28,000 --> 00:00:29,490
Tom Dale

00:00:29,490 --> 00:00:30,490
>> Thank you so much, Ashley.

00:00:30,490 --> 00:00:31,490
That was really amazing.

00:00:31,490 --> 00:00:32,490
And before you go, I took a photo of this.

00:00:32,490 --> 00:00:33,490
So this store, in New York, that sells karate hip hop action/drama headphones and luxury

00:00:33,490 --> 00:00:34,490
items.

00:00:34,490 --> 00:00:35,490
Have you ever been in this store?

00:00:35,490 --> 00:00:36,490
ASHLEY: No, I just stood outside.

00:00:36,490 --> 00:00:37,490
I'll come back and let you know.

00:00:37,490 --> 00:00:38,490
>> Awesome.

00:00:38,490 --> 00:00:39,490
Thank you, Ashley.

00:00:39,490 --> 00:00:40,490
Okay.

00:00:40,490 --> 00:00:41,490
We have two more talks left today.

00:00:41,490 --> 00:00:42,490
We're next, welcoming to the stage Tom Dale.

00:00:42,490 --> 00:00:43,490
He is from New York City, of course.

00:00:43,490 --> 00:00:44,490
He's a JavaScript thinkfluencer.

00:00:44,490 --> 00:00:45,490
So this is going to be a think-piece talk, I think.

00:00:45,490 --> 00:00:46,490
He's wearing a suit today because he's a contrarian, apparently and I think he wants everyone to

00:00:46,490 --> 00:00:47,490
take a photo with him in the photobooth truck, which every time I walk past, there's not

00:00:47,490 --> 00:00:48,490
enough people in there.

00:00:48,490 --> 00:00:49,490
So I hope you've all had a turn in the photobooth truck.

00:00:49,490 --> 00:00:50,490
So Tom's also wearing a suit because he wants you to join his professional network.

00:00:50,490 --> 00:00:51,490
He works at LinkedIn.

00:00:51,490 --> 00:00:52,490
[ Laughter ]

00:00:52,490 --> 00:00:53,490
He looks very professional.

00:00:53,490 --> 00:00:54,490
So he's going to give a talk today on how desktop-era frameworks can thrive on mobile.

00:00:54,490 --> 00:00:55,490
I'm a little bit sad that he's actually in the completing the look with the bowtie and

00:00:55,490 --> 00:00:56,490
didn't go all the way.

00:00:56,490 --> 00:00:57,490
Thank you, Tom.

00:00:57,490 --> 00:00:58,490
TOM: Thank you very much.

00:00:58,490 --> 00:00:59,490
Thank you all for having me here today.

00:00:59,490 --> 00:01:00,490
It really is an honor to be here.

00:01:00,490 --> 00:01:01,490
My name is Tom.

00:01:01,490 --> 00:01:02,490
JSConf is a very special conference for me.

00:01:02,490 --> 00:01:03,490
I was here about four years ago, which is when I met Zahra, who you saw earlier.

00:01:03,490 --> 00:01:04,490
Jed introduced us on the plane and then two years after that, I proposed and we're getting

00:01:04,490 --> 00:01:05,490
married in August.

00:01:05,490 --> 00:01:06,490
So, for me, in particular, JSConf EU has been particularly life-changing and hopefully many

00:01:06,490 --> 00:01:07,490
of you can develop specially similar relationships, professionally, I mean.

00:01:07,490 --> 00:01:09,329
So today I want to talk to you about smartphones.

00:01:09,329 --> 00:01:15,930
And in particular, I want to talk about how tools that grew up on the desktop like Ember,

00:01:15,930 --> 00:01:20,600
Angular, and React, can make the jump to the mobile future.

00:01:20,600 --> 00:01:26,609
And I think when people think about adapting apps to phones, they often focus on the more

00:01:26,609 --> 00:01:28,000
obvious differences.

00:01:28,000 --> 00:01:31,020
So, for example, things like the difference in screen size.

00:01:31,020 --> 00:01:36,299
The difference in CPU performance, the different input devices, touch versus a mouse.

00:01:36,299 --> 00:01:40,329
But I think where the device is used is important, too.

00:01:40,329 --> 00:01:44,500
So, for example, a user on a mobile phone is more likely to be distracted than someone

00:01:44,500 --> 00:01:48,320
who might be focused on a task at their desk.

00:01:48,320 --> 00:01:53,840
Or they might have a more intermittent network connection than having a broadband Wi-Fi router

00:01:53,840 --> 00:01:55,530
in their apartment.

00:01:55,530 --> 00:02:01,210
So when phones can be used anywhere, there are very few assumptions we can make, whether

00:02:01,210 --> 00:02:05,369
that's how attentive the user is, or whenever they have that Internet connection at all.

00:02:05,369 --> 00:02:10,580
So I started working at LinkedIn in December and one thing about working at a site like

00:02:10,580 --> 00:02:15,560
LinkedIn is it reminds me of how truly global the web can be.

00:02:15,560 --> 00:02:22,190
In many cases, adapting to smartphones really means adapting to new users.

00:02:22,190 --> 00:02:25,470
For many people, their first computer is a smartphone.

00:02:25,470 --> 00:02:29,330
That means millions, maybe even billions of people are going to be participating online

00:02:29,330 --> 00:02:32,280
without ever owning a desktop computer.

00:02:32,280 --> 00:02:36,780
And the more global your app is, the more combinations of devices and networks you'll

00:02:36,780 --> 00:02:37,970
have to deal with.

00:02:37,970 --> 00:02:43,530
CPU power can range from a feature phone to a low-end smartphone, to the latest iPhone,

00:02:43,530 --> 00:02:46,120
up to a beefy desktop computer.

00:02:46,120 --> 00:02:52,400
And network connectivity can range from GPRS, to gigabit fiber, to nothing at all, just

00:02:52,400 --> 00:02:56,820
ride the subway in New York.

00:02:56,820 --> 00:03:04,640
So the problem with this is that without careful design, it's easy to optimize for one combination

00:03:04,640 --> 00:03:06,950
at the cost of another.

00:03:06,950 --> 00:03:09,350
So let's take a look at two different users.

00:03:09,350 --> 00:03:11,550
Let's imagine these two scenarios.

00:03:11,550 --> 00:03:14,890
So user A has a very low-end smartphone.

00:03:14,890 --> 00:03:22,440
It has a CPU has easily overheats and starts throttling itself, and it would be borderline

00:03:22,440 --> 00:03:28,210
useless except for the fact that it's not full.

00:03:28,210 --> 00:03:37,950
It Opera Mini which heavily processes requests before the user gets it.

00:03:37,950 --> 00:03:44,810
User B has a phone with a CPU that might rival a desktop computer and they've got plenty

00:03:44,810 --> 00:03:45,860
of fast storage.

00:03:45,860 --> 00:03:50,700
But the problem is this person is traveling without any cellular data.

00:03:50,700 --> 00:03:55,590
So while they have sometimes access to broadband Internet, it's only when they're within range

00:03:55,590 --> 00:03:59,450
of a Wi-Fi network that it's useful.

00:03:59,450 --> 00:04:05,910
For user A, anything that's JavaScript is probably not going to be helpful at all.

00:04:05,910 --> 00:04:12,540
Even if they stopped using Opera's proxy, with the slow CPU meaning that getting the

00:04:12,540 --> 00:04:17,580
JavaScript means long load times.

00:04:17,580 --> 00:04:24,280
It's about keeping the file size as small as possible.

00:04:24,280 --> 00:04:28,730
For user B, we want our web app to work more like a native application.

00:04:28,730 --> 00:04:35,031
In fact, we'd be willing to spend more time up front to load the entire app and as much

00:04:35,031 --> 00:04:36,640
data possible on the phone.

00:04:36,640 --> 00:04:38,670
That's basically what the App Store does, right?

00:04:38,670 --> 00:04:42,561
So that meant that he could use it when we were away from the Wi-Fi connection that we

00:04:42,561 --> 00:04:48,450
were relying on, and this user probably has higher expectations on this app, as well.

00:04:48,450 --> 00:04:54,780
It would be worth sending a bit more code to get 60 frames per second animation and

00:04:54,780 --> 00:05:00,750
buttery smooth scrolling if their device can handle it.

00:05:00,750 --> 00:05:06,460
So best experience on a slow device is often radical different for the best experience

00:05:06,460 --> 00:05:10,660
on a faster device.

00:05:10,660 --> 00:05:19,180
And the more we try to take advantage of higher end phones, the worst we've made the experience

00:05:19,180 --> 00:05:21,480
for the majority of the world.

00:05:21,480 --> 00:05:26,020
So what do you all think is the solution to this problem?

00:05:26,020 --> 00:05:31,790
I'll give you a hint, the initials are, "PE."

00:05:31,790 --> 00:05:34,330
Any guesses?

00:05:34,330 --> 00:05:35,330
That's right!

00:05:35,330 --> 00:05:39,350
Panic and evacuate the building!

00:05:39,350 --> 00:05:41,000
Very good.

00:05:41,000 --> 00:05:46,080
The answer is supposed to be progressive enhancement but one thing that's implicit, at least in

00:05:46,080 --> 00:05:50,830
all the advice that I've received about progressive enhancement is that you're supposed to do

00:05:50,830 --> 00:05:51,830
it yourself.

00:05:51,830 --> 00:05:56,840
It almost always means rendering on the server, and denying yourself the temptation of using

00:05:56,840 --> 00:06:00,070
too much JavaScript.

00:06:00,070 --> 00:06:05,570
And browsers in the last ten years, let's say, have advanced at a remarkable rate.

00:06:05,570 --> 00:06:11,660
To me, it feels like the web has never had more momentum add feature after feature.

00:06:11,660 --> 00:06:18,980
And, yet, despite all this incredible innovation from index.db to web workers, it doesn't actually

00:06:18,980 --> 00:06:24,960
feel to me the experience of using web apps day to day has improved that much in the last

00:06:24,960 --> 00:06:26,570
three or four years.

00:06:26,570 --> 00:06:32,360
So why is it that these radical improvements in the browser don't seem to be translating

00:06:32,360 --> 00:06:37,830
into radically improved web applications?

00:06:37,830 --> 00:06:46,900
And I would argue the reason for this is the cost of code is too damn high.

00:06:46,900 --> 00:06:51,820
Taking advantage of all of those new features in the browser requires a lot of code.

00:06:51,820 --> 00:06:56,440
Native apps that work offline with beautiful user experiences with hundreds of megabytes

00:06:56,440 --> 00:07:02,040
and that's not even factoring in the SDK that ships with the operating system on the phone.

00:07:02,040 --> 00:07:07,320
On the web, just parsing and downloading JavaScript can be enough to turn phones janky, and when

00:07:07,320 --> 00:07:12,120
you start bundling your JavaScript into a file, every byte starts to count.

00:07:12,120 --> 00:07:20,270
And in turn, misaligned libraries have to compete on file size rather than robustness.

00:07:20,270 --> 00:07:24,760
So how do they achieve these improbably small file sizes?

00:07:24,760 --> 00:07:30,070
Often it's by persuading you that the old thing is unnecessarily complex, the cardinal

00:07:30,070 --> 00:07:36,590
sin in JavaScript but they've seen through the BS and built something simple and that

00:07:36,590 --> 00:07:39,100
leads to us the JavaScript simplicity fetish.

00:07:39,100 --> 00:07:44,380
It is this emphasis on file size that leaves the JavaScript community to this fetish, when

00:07:44,380 --> 00:07:51,470
file size relies on simplicity and speed relies on file size, and speed is paramount on the

00:07:51,470 --> 00:07:55,840
web, we have to pretend that simple tools are the best tools because what other choice

00:07:55,840 --> 00:07:58,180
do we have?

00:07:58,180 --> 00:08:04,790
The only way to run an app that run well on slower phones and networks is write less JavaScript,

00:08:04,790 --> 00:08:12,419
too often, handling edge cases and higher levels of abstraction.

00:08:12,419 --> 00:08:17,979
We eventually start to collapse under our own page weight.

00:08:17,979 --> 00:08:18,979
That's rational.

00:08:18,979 --> 00:08:20,880
We've seen this play out several times now.

00:08:20,880 --> 00:08:25,620
The more sophistication equals more code, equals slower load times.

00:08:25,620 --> 00:08:33,110
So the time period from 2011 to that we have could be roughly broken up into the Backbone

00:08:33,110 --> 00:08:36,449
era, and the Angular era and the Ember era.

00:08:36,449 --> 00:08:45,779
This trio of eras can sometimes also been known as the Ember era.

00:08:45,779 --> 00:08:52,220
Now it's easy to become enamored with the complexity of a tool.

00:08:52,220 --> 00:08:58,759
And let's go back to 2011 and the most cutting-edge tool that people were using was Backbone.

00:08:58,759 --> 00:09:06,149
And people were saying, I love it, I can clone it from GitHub, and read the source code within

00:09:06,149 --> 00:09:08,329
a day.

00:09:08,329 --> 00:09:13,810
But whenever my model changes, everything breaks.

00:09:13,810 --> 00:09:17,850
I heard about this new library called Angular.

00:09:17,850 --> 00:09:19,860
Two-way binding is so simple.

00:09:19,860 --> 00:09:22,970
You just change it, and it changes it on the screen.

00:09:22,970 --> 00:09:30,379
But a year later, it's like my app contains a controller with 3 million lines of code.

00:09:30,379 --> 00:09:40,800
But don't worry, React is amazing and so simple because it's just the "V" in MVC and a year

00:09:40,800 --> 00:09:50,369
or two into building your app you realize it's 7 megabytes and takes two years to build.

00:09:50,369 --> 00:09:58,240
So Don Norman what you may know as the author of design of Everyday things, wrote this:

00:09:58,240 --> 00:10:04,210
The numerous defeats in security measures prompts my slogan, the more secure you try

00:10:04,210 --> 00:10:07,189
to make something, the less secure it becomes.

00:10:07,189 --> 00:10:08,379
Why?

00:10:08,379 --> 00:10:14,360
Because when security gets in the way, sensible and well meaning people develop hacks.

00:10:14,360 --> 00:10:21,259
Like password rules are too annoying, people just write the password and put it on their

00:10:21,259 --> 00:10:22,259
desk.

00:10:22,259 --> 00:10:32,740
So I would like to offer a different corollary because when simplicity gets in the way, sensible,

00:10:32,740 --> 00:10:38,459
and well meaning people develop hacks to defeat the simplicity.

00:10:38,459 --> 00:10:40,800
So how do we break out of this local maxima.

00:10:40,800 --> 00:10:45,430
How do we write one app that can scale up and down across these different devices and

00:10:45,430 --> 00:10:47,230
performance characteristics?

00:10:47,230 --> 00:10:53,610
Well, I think we can learn from native developers because they've had to tackle a similar problem.

00:10:53,610 --> 00:10:59,209
So these are different CPU architectures and different CPU architectures have different

00:10:59,209 --> 00:11:00,209
instruction sets.

00:11:00,209 --> 00:11:12,200
If you write some code for x86 and you want to run on ARM, they're totally different.

00:11:12,200 --> 00:11:15,759
If this is how software was written, there probably wouldn't be that much cross-platform

00:11:15,759 --> 00:11:21,999
code and introducing new CPU architectures would be borderline impossible.

00:11:21,999 --> 00:11:27,290
We've figured out, a long time ago, that a compiler can take a higher level program and

00:11:27,290 --> 00:11:31,680
get it to run across all of these architectures and if a new architecture comes along, you

00:11:31,680 --> 00:11:35,170
just have to update the compiler and not rewrite every app in existence.

00:11:35,170 --> 00:11:41,439
So here's an existence of plying an LVM, and taking C code and taking an architecture that

00:11:41,439 --> 00:11:46,070
didn't exist in the '70s, which was WebAssembly.

00:11:46,070 --> 00:11:52,320
And best of all, the compiler makes our code not only run on all these architectures, but

00:11:52,320 --> 00:11:58,660
it can be used to opt my our code differently for particular characteristics of that platform.

00:11:58,660 --> 00:12:05,110
So, for example, here's a paper about optimizing GCC, where they said, finally, a new target-independent

00:12:05,110 --> 00:12:09,269
feature could be implemented to take into account certain specific features of the target.

00:12:09,269 --> 00:12:16,959
For example, to make advantage of the Intel Itanium, it's dating the paper, we've implemented

00:12:16,959 --> 00:12:19,989
the support in the instruction scheduler.

00:12:19,989 --> 00:12:25,559
And this is something that Ashley said in her talk when I totally agree with, if there's

00:12:25,559 --> 00:12:30,309
one thing that I want you to take away from this talk is that modern web toolkits are

00:12:30,309 --> 00:12:39,990
transforming away into something like a compiler where instead of compiling your into native

00:12:39,990 --> 00:12:44,879
code, it's going into a highly optimized version.

00:12:44,879 --> 00:12:50,399
And I think this would mean taking an app and delivering the most optimized version

00:12:50,399 --> 00:12:51,689
to your device.

00:12:51,689 --> 00:12:59,529
This could be like delivering new ES6 builds, or transpiled ES5 builds and/or transitioning

00:12:59,529 --> 00:13:04,509
from server-side rendering and client-side rendering based on the network speed detected.

00:13:04,509 --> 00:13:11,720
But most importantly, these tools can decouple the file size.

00:13:11,720 --> 00:13:18,160
If we can shift the complexity to our build tools rather than being these monolithic runtime

00:13:18,160 --> 00:13:22,989
libraries, we can reduce this pressure to be simple.

00:13:22,989 --> 00:13:28,769
So unfortunately I don't have that much time for you today but I wanted to highlight three

00:13:28,769 --> 00:13:32,970
things that the teams behind React, Ember, and Angular are working on, in order to demonstrate

00:13:32,970 --> 00:13:36,119
that these things are becoming mobile on compilers.

00:13:36,119 --> 00:13:42,410
And so the first thing that I want to talk about is React, and also Prepack which is

00:13:42,410 --> 00:13:47,720
an open source tool for optimizing JavaScript validation.

00:13:47,720 --> 00:13:52,939
Prepack was released while on the plane on my plane to Berlin.

00:13:52,939 --> 00:14:01,610
But it was definitely true, the Prepack website uses quite a bit of computer science terminology

00:14:01,610 --> 00:14:03,949
to explain what it's doing.

00:14:03,949 --> 00:14:10,579
It's genuinely exciting and novel but you don't need to understand heap serialization

00:14:10,579 --> 00:14:16,449
to understand why Prepack is cool for optimizing web apps.

00:14:16,449 --> 00:14:23,860
So to understand why Prepack is school, let's see how something like a Rollup works.

00:14:23,860 --> 00:14:29,569
It starts by analyzing which file it imports.

00:14:29,569 --> 00:14:32,649
For each of those files.

00:14:32,649 --> 00:14:37,480
Once it's analyzed the entire graph, it builds a new JavaScript file that includes just the

00:14:37,480 --> 00:14:43,860
modules that were actually used.

00:14:43,860 --> 00:14:55,730
And once -- 

00:14:55,730 --> 00:14:57,989
the final output is on the right.

00:14:57,989 --> 00:15:02,199
Everything we've imported is inlined right into that file and modules that aren't imported

00:15:02,199 --> 00:15:05,069
with excluded.

00:15:05,069 --> 00:15:09,170
This gives us smaller files by eliminating the files that we don't actually use.

00:15:09,170 --> 00:15:11,209
But it's not just modules.

00:15:11,209 --> 00:15:16,470
Rollup can do other things if it sees things that we didn't use.

00:15:16,470 --> 00:15:25,259
Notice that we've added a new class to animal.js, that's because Rollup is smart enough not

00:15:25,259 --> 00:15:38,899
to include the feral animal class 

00:15:38,899 --> 00:15:43,600
static analysis just means figuring out things about how a program will run without actually

00:15:43,600 --> 00:15:44,920
having to run it.

00:15:44,920 --> 00:15:49,250
Rollup isn't running your code, it's just scanning to figure out what gets imported

00:15:49,250 --> 00:15:51,369
and what gets exported.

00:15:51,369 --> 00:15:58,149
And modules don't work inside of conditionals so it knows with 100% certainty.

00:15:58,149 --> 00:16:02,670
That's roll-up.

00:16:02,670 --> 00:16:04,819
Let's take a look at V8.

00:16:04,819 --> 00:16:10,209
Specifically, I mean, any JavaScript virtual mean but we'll look at V8 specifically.

00:16:10,209 --> 00:16:12,350
V8 can't help you with file size.

00:16:12,350 --> 00:16:18,119
By definition, it has to have downloaded the JavaScript file already but it can help with

00:16:18,119 --> 00:16:20,079
making your code faster.

00:16:20,079 --> 00:16:25,220
So this is a high level view of the architecture, V8 and there's three major components.

00:16:25,220 --> 00:16:28,420
I think there are V8 people here so please forgive me if I get anything wrong.

00:16:28,420 --> 00:16:33,089
So the parser which turns your JavaScript into the instruction, and then the interpreter

00:16:33,089 --> 00:16:39,389
ignition which evaluates your JavaScript and then the Turbofan which turns your JavaScript

00:16:39,389 --> 00:16:47,619
into something more time to generate but it can run at truly ridiculous speeds.

00:16:47,619 --> 00:16:54,980
And as your program executes, it keeps track of how they're run and based on this information

00:16:54,980 --> 00:17:07,040
it will ask Turbo fan to make optimized versions of your that it thinks it will make it run

00:17:07,040 --> 00:17:08,040
faster.

00:17:08,040 --> 00:17:11,640
Not running it JavaScript probably would be considered a bug because because it relies

00:17:11,640 --> 00:17:16,860
on how the program actually runs, you have to use the unoptimized code for a while until

00:17:16,860 --> 00:17:23,089
V8 can make discussions and that that means that every user pays that cost even though

00:17:23,089 --> 00:17:26,909
the ended result is more or less the same for everyone.

00:17:26,909 --> 00:17:34,539
This is the tension that we have with static analysis and dynamic analysis you pay the

00:17:34,539 --> 00:17:39,970
cost once and all your users benefit but static analysis can only get you so far because you

00:17:39,970 --> 00:17:43,620
can only perform optimizations you're 100% sure about.

00:17:43,620 --> 00:17:48,549
If the module might get use, Rollup can't use it because if it guesses wrong, the app

00:17:48,549 --> 00:17:49,549
breaks.

00:17:49,549 --> 00:17:52,870
Information about the runtime analysis can collect information about how the program

00:17:52,870 --> 00:17:57,280
actually runs so they don't have to guess but requiring the program to run in order

00:17:57,280 --> 00:18:04,450
to optimize it is a bit of a catch-22.

00:18:04,450 --> 00:18:07,931
And then that's the opposite of what we want on the web where things typically want to

00:18:07,931 --> 00:18:09,080
feel instant.

00:18:09,080 --> 00:18:10,840
So that's what makes Prepack so cool.

00:18:10,840 --> 00:18:13,590
What it does is actually run you are why code.

00:18:13,590 --> 00:18:18,779
Similar to V8, it's an actual JavaScript virtual machine but rather than running apps, though,

00:18:18,779 --> 00:18:24,960
it runs at build time and it reverse-engineers a version that's faster for your JavaScript

00:18:24,960 --> 00:18:30,080
to execute than the first time.

00:18:30,080 --> 00:18:35,000
So this whole thing is a talk into itself and I'm still digesting how it works internally

00:18:35,000 --> 00:18:36,720
but let's just take a quick look at how it works.

00:18:36,720 --> 00:18:42,210
I know I showed an example also put so imagine we're writing a library that prints the data

00:18:42,210 --> 00:18:50,730
of JSConf EU, so publish -- so if we run this through Prepack, you can see that it's turned

00:18:50,730 --> 00:18:57,260
it you will into a string literal.

00:18:57,260 --> 00:19:02,070
But instead of every user having to allocate a data object, parse a date string, initialize

00:19:02,070 --> 00:19:10,610
a date object, and generating an ISO-601 string, and this is a contrived example.

00:19:10,610 --> 00:19:16,820
And each of these small stakes may start to really add up in codebase the sizes Ember,

00:19:16,820 --> 00:19:18,100
Angular, or React.

00:19:18,100 --> 00:19:24,220
And I'm hearing a rumor that Jason Miller is going to release something called pre-Prepack,

00:19:24,220 --> 00:19:30,550
that does everything that Prepack does in only 600 bytes of code.

00:19:30,550 --> 00:19:43,200
So let's look at Angular, it's on Typescript that's just a subset of JavaScript, and those

00:19:43,200 --> 00:19:52,519
types makes refactoring much easier as your project grows, but to me, the most exciting

00:19:52,519 --> 00:19:59,820
and underappreciated reasons for is the potential for using that type information to more aggressively

00:19:59,820 --> 00:20:01,510
minify your builds.

00:20:01,510 --> 00:20:11,870
So in this examiner we've renamed this variable,

00:20:11,870 --> 00:20:17,460
fruit, to be called o and because these variables inside this go nowhere outside of this function

00:20:17,460 --> 00:20:21,799
can access it, so whatever we call inside it is arbitrary.

00:20:21,799 --> 00:20:25,780
Let's change this example a little bit and instead of making fruit a string, we make

00:20:25,780 --> 00:20:31,779
it an object with name property and even though the variable fruit gets mangled, the property

00:20:31,779 --> 00:20:35,360
name stays the same.

00:20:35,360 --> 00:20:44,730
Now uglify.js has a property -- renaming properties can break things.

00:20:44,730 --> 00:20:48,370
In fact, the readme of uglify says, note, this will probably break your code, which

00:20:48,370 --> 00:20:52,330
doesn't instill a lot of confidence.

00:20:52,330 --> 00:20:59,059
So, for example, if we have an element and we change its onclick property, if that gets

00:20:59,059 --> 00:21:02,110
renamed to something else, then this is just going to fail silently.

00:21:02,110 --> 00:21:06,559
That click handler that we thought we were handling just doesn't exist anymore.

00:21:06,559 --> 00:21:12,139
And similarly if we look at a component, this is a React component, for example, there are

00:21:12,139 --> 00:21:18,299
parts of this object that are private and then there are other things that are public,

00:21:18,299 --> 00:21:21,929
meaning things like a library or a platform rely on it.

00:21:21,929 --> 00:21:25,880
Really what we want to do is mangle the private stuff but make sure that the library can keep

00:21:25,880 --> 00:21:28,820
using the public stuff and there's good news.

00:21:28,820 --> 00:21:33,299
Google's closure compiler already supports this advanced minification for JavaScript.

00:21:33,299 --> 00:21:40,330
Unfortunately, it requires an notating types with js style comments and -- approximately

00:21:40,330 --> 00:21:44,529
seven people on the planet outside of Google have actually gotten this to work.

00:21:44,529 --> 00:21:51,270
Now the Angular team has released an amazing tool called Sickle that translates a type

00:21:51,270 --> 00:21:59,200
script project who the bizarre format that compiler, and because Angular is written in

00:21:59,200 --> 00:22:09,360
Typescript two, closure can do some advanced minification.

00:22:09,360 --> 00:22:21,899
The idea it more accessible to broader world, and integrating into this NGCLI by default

00:22:21,899 --> 00:22:28,820
I think would make a huge impact into basically every Angular app.

00:22:28,820 --> 00:22:35,340
So lastly I just want to talk about Ember, and specifically Glimmer, which is the rendering

00:22:35,340 --> 00:22:38,409
engineer in Ember, and also the library that we extracted to be used standalone outside

00:22:38,409 --> 00:22:40,630
of Ember a month or two ago.

00:22:40,630 --> 00:22:46,700
So now in thinking about the rendering engine is there's three things to consider.

00:22:46,700 --> 00:22:54,000
How fast does it take to load.

00:22:54,000 --> 00:22:58,399
But then once you have something within reasonable bound of time, you want to look at how long

00:22:58,399 --> 00:23:01,559
does it take to render a component for the first time when you have to create brand-new

00:23:01,559 --> 00:23:02,870
DOM elements.

00:23:02,870 --> 00:23:07,080
And third, how long does it take to rerender a component updating its existing DOM elements

00:23:07,080 --> 00:23:10,149
instead of replacing them when the data backing that component changes.

00:23:10,149 --> 00:23:11,149
Okay.

00:23:11,149 --> 00:23:13,149
So who remembers this app?

00:23:13,149 --> 00:23:16,820
Yeah, the db bain of my existence.

00:23:16,820 --> 00:23:26,509
This is Ryan Florence's dbmon demo app, which heights the differential app and everyone

00:23:26,509 --> 00:23:28,710
was competing to have the fastest score on it.

00:23:28,710 --> 00:23:33,370
And it's all anyone ever focused on but then more recently the community's focus has been

00:23:33,370 --> 00:23:38,490
on initial load times as people have grappled with how we deal with these low-end phones

00:23:38,490 --> 00:23:40,630
and slow networks.

00:23:40,630 --> 00:23:44,429
And the tricky thing is trying to find the sweet spot that balances between optimizing

00:23:44,429 --> 00:23:46,950
the first render and optimizing rerenders.

00:23:46,950 --> 00:23:49,490
Fundamentally, this is an issue of bookkeeping.

00:23:49,490 --> 00:23:53,659
The more bookkeeping you do in the initial render to make subsequent renders faster,

00:23:53,659 --> 00:23:56,409
the longer that that render is going to take.

00:23:56,409 --> 00:24:00,980
So consider a render using Bootstrap markup on VirtualJS.

00:24:00,980 --> 00:24:04,280
That makes a lot of sense.

00:24:04,280 --> 00:24:09,250
This is basically just instructions for how to create the real DOM but if a single part

00:24:09,250 --> 00:24:14,049
changes we have to run the entire render function again and that's quite a few allocations of

00:24:14,049 --> 00:24:17,870
virtual DOM objects, not to mention that once you have them, you have to then do this diffing

00:24:17,870 --> 00:24:23,539
step to kind of reverse-engineer what changed between last render and this render.

00:24:23,539 --> 00:24:29,399
So the performance cost is probably negligible but in larger apps you can see how it starts

00:24:29,399 --> 00:24:31,220
to add up.

00:24:31,220 --> 00:24:39,950
And in Glimmer we use Handlebar templates and success how do we compile them into.

00:24:39,950 --> 00:24:46,050
Come Ember's history, this answer changed three times, first it was strings and then

00:24:46,050 --> 00:24:54,179
DOM, and into with glimmer, byte code.

00:24:54,179 --> 00:25:03,289
[Inaudible], and a virtual machine that runs that compiled

00:25:03,289 --> 00:25:04,289
code.

00:25:04,289 --> 00:25:07,021
So in Glimmer we compiled this template into a JSON object that looks like this.

00:25:07,021 --> 00:25:11,250
Now, this probably doesn't book meaningful to you but what this object represents is

00:25:11,250 --> 00:25:21,929
a series of op codes, or instructions how to build -- into integers, string literals,

00:25:21,929 --> 00:25:24,830
so parsing is fast and memory consumption is much lower.

00:25:24,830 --> 00:25:29,750
When we landed Glimmer in ember 2.10, many apps found their template sizes dropped from

00:25:29,750 --> 00:25:31,460
75-85% which is significant.

00:25:31,460 --> 00:25:39,529
Now if you look closely as 30 but we use integers to represent instructions for compactness

00:25:39,529 --> 00:25:47,039
and for certainly V8 operations but if we were to operate it in a hypothetical linearized

00:25:47,039 --> 00:25:52,020
set of instructions so when we take those instructions and we execute them on top of

00:25:52,020 --> 00:25:55,740
the Glimmer VM, it looks a little bit something like this.

00:25:55,740 --> 00:25:59,299
We have an instruction pointer that just goes through this sequence and so this is going

00:25:59,299 --> 00:26:05,000
to build an li element and then we're going to move on and run the static add p code and

00:26:05,000 --> 00:26:08,490
that's going to set the attribute and then we're going to add another static attribute

00:26:08,490 --> 00:26:12,379
which is the active class and then that's the whole template and then we're going to

00:26:12,379 --> 00:26:16,190
flush the element which tells Glimmer that this is something to go to put in the DOM.

00:26:16,190 --> 00:26:20,710
Now this isn't this is an easy example because this is static.

00:26:20,710 --> 00:26:27,490
But what I want mentioned yet is the Glimmer VM is made up of two VMs.

00:26:27,490 --> 00:26:36,360
One is constructing DOM initial on initial render and the other is for updates.

00:26:36,360 --> 00:26:40,049
So this is the program for initially rendering this template.

00:26:40,049 --> 00:26:42,659
Now we could run this again for updates, right?

00:26:42,659 --> 00:26:46,759
But there's a lot of static content in here and spending time executing op codes for static

00:26:46,759 --> 00:26:49,700
content we know hasn't changed isn't a good use of time.

00:26:49,700 --> 00:26:56,070
In fact, we just want to focus on this dynamic part and the way that we optimize is through

00:26:56,070 --> 00:26:58,639
a technique called partial evaluation.

00:26:58,639 --> 00:27:03,800
And partial evaluation simply means to generate an optimize program by evaluating an initial

00:27:03,800 --> 00:27:04,800
program.

00:27:04,800 --> 00:27:08,090
And we use this technique to generate it automatically.

00:27:08,090 --> 00:27:15,990
So initially as the initial program is being run, we're generating a more optimized version

00:27:15,990 --> 00:27:17,370
when the data changes.

00:27:17,370 --> 00:27:21,730
Essentially these operations in the initial rendering program are responsible for generating

00:27:21,730 --> 00:27:23,730
their own subsequent code.

00:27:23,730 --> 00:27:26,990
So the way this works is that we're going to go through our op code for the initial

00:27:26,990 --> 00:27:30,999
render as before that's going to open a new div and we're going to set some status traits

00:27:30,999 --> 00:27:38,429
on this, so in addition to appending that text content to the DOM, we're also going

00:27:38,429 --> 00:27:43,809
to generate an updating code which is to update that content and it's going to include a reference

00:27:43,809 --> 00:27:47,350
to what value what you were putting in it as well as a reference to the text value that

00:27:47,350 --> 00:27:50,360
you created.

00:27:50,360 --> 00:27:54,539
Now when that data value behind that component updates instead of going that whole process

00:27:54,539 --> 00:27:58,929
again, all we have to do is evaluate our highly optimized updating program which is just going

00:27:58,929 --> 00:28:02,450
to take the old data out of the DOM and update it.

00:28:02,450 --> 00:28:05,389
And you can think of it doing as something -- it's a little more complex than this -- but

00:28:05,389 --> 00:28:14,280
you can think of why it ends up being fast because it needs -- notice that basically

00:28:14,280 --> 00:28:19,470
all the rendering library benchmarks only tested pure dynamic content but it's not representative

00:28:19,470 --> 00:28:23,330
of apps in the world.

00:28:23,330 --> 00:28:28,409
So we created benchmarks that had a mix of both static and dynamic content and what we

00:28:28,409 --> 00:28:34,909
noticed was that initial I'm not putting the other names here because it's not a competition.

00:28:34,909 --> 00:28:37,960
I think I wanted to show that we're basically in the same ballpark.

00:28:37,960 --> 00:28:42,929
However, when we moved to updating other performance what we noticed was that it seems like having

00:28:42,929 --> 00:28:49,330
this optimized bytecode makes a big difference, which can make a big difference, especially

00:28:49,330 --> 00:28:50,669
on lower end phones.

00:28:50,669 --> 00:28:53,850
So today we've talked about three popular frameworks and things that they're doing to

00:28:53,850 --> 00:29:01,009
improve performance on mobile devices.

00:29:01,009 --> 00:29:11,289
It's -- there's an exciting trend towards more sophisticated tools that can analyze

00:29:11,289 --> 00:29:16,240
your app, perform optimizations that can be time consuming, practically impossible to

00:29:16,240 --> 00:29:17,559
do by hand.

00:29:17,559 --> 00:29:23,149
Best of all code that clearly conveys intent to other humans has a funny way of conveying

00:29:23,149 --> 00:29:28,210
the intent for optimizing compilers, too, p so in that we have be the idea that build

00:29:28,210 --> 00:29:35,450
tools are -- sophisticated build process of a modern web app.

00:29:35,450 --> 00:29:39,159
This morning, Addy showed a bunch of techniques for measuring and improving the performance

00:29:39,159 --> 00:29:40,600
for your web apps.

00:29:40,600 --> 00:29:45,360
That's awesome information but not everyone can be Addy standing over them and reminding

00:29:45,360 --> 00:29:50,809
them to take care of performance and spend time learning about these techniques so I'm

00:29:50,809 --> 00:29:56,129
incredibly excited about a community that can help democratize and commoditize that

00:29:56,129 --> 00:30:00,860
performance know-how.

00:30:00,860 --> 00:30:06,340
So the best approach of approaching frameworks and compilers isn't that they just help today's

00:30:06,340 --> 00:30:09,940
by reducing the cost of code, we can build better apps that don't collapse under the

00:30:09,940 --> 00:30:20,679
weight of their own complexity.

00:30:20,679 --> 00:30:23,460
This is a very exciting time to be a JavaScript developer.

00:30:23,460 --> 00:30:28,340
I for one am really looking forward to web apps that load instantly, work offline, feel

00:30:28,340 --> 00:30:30,240
great to use for everyone.

00:30:30,240 --> 00:30:40,450

YouTube URL: https://www.youtube.com/watch?v=PU94cgLuw9I


