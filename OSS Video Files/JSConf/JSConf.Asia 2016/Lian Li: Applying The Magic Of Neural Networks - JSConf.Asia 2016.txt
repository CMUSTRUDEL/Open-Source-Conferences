Title: Lian Li: Applying The Magic Of Neural Networks - JSConf.Asia 2016
Publication date: 2016-12-12
Playlist: JSConf.Asia 2016
Description: 
	Have you ever been in a betting pool for your local football league? Then you might know, how exhausting it is, to come up with sensible results for every single game and most of us are not using the scientific method... at all. No need to fret about it anymore! Iâ€™ll show you how to write a program that learns to predict football scores with the help of the Node.js library synaptic.

Lian is working as Jack of all trades at the interface between development and support. She completed her apprenticeship as IT specialist in early 2014, after a failed attempt at becoming a lawyer.


JSConf.Asia - Capitol Theatre, Singapore - 26 November 2016.

Source: https://2016.jsconf.asia/
Slides: https://slidr.io/Chimney42/applying-the-magic-of-neural-networks-jsconf-asia-edition#1

License: For reuse of this video under a more permissive license please get in touch with us. The speakers retain the copyright for their performances.
Captions: 
	00:00:19,000 --> 00:00:25,460
gosh James talk was so funny it's like

00:00:23,090 --> 00:00:28,430
following up Adele and the crew could

00:00:25,460 --> 00:00:29,900
borrow something all right um so thanks

00:00:28,430 --> 00:00:32,239
for your interest and i'll be talking

00:00:29,900 --> 00:00:33,860
about neural networks today how they

00:00:32,239 --> 00:00:36,800
work how you can implement in your

00:00:33,860 --> 00:00:40,280
network yourself and hopefully also how

00:00:36,800 --> 00:00:42,620
you can improve your algorithm so this

00:00:40,280 --> 00:00:45,500
is me you can follow me on twitter and

00:00:42,620 --> 00:00:47,840
github on google+ although i'm like

00:00:45,500 --> 00:00:51,050
rarely on there but it's always nice if

00:00:47,840 --> 00:00:52,880
someone still on google+ so yeah i'm a

00:00:51,050 --> 00:00:56,329
web developer by day and I basically

00:00:52,880 --> 00:00:59,470
turned machine learning enthusiast after

00:00:56,329 --> 00:01:01,489
i attended the AI course by and room

00:00:59,470 --> 00:01:05,000
that was the one that actually started

00:01:01,489 --> 00:01:07,310
Kucera and afterwards i wanted to like

00:01:05,000 --> 00:01:10,070
use my new skills for a hands-on project

00:01:07,310 --> 00:01:13,310
and at this time I was in a betting pool

00:01:10,070 --> 00:01:15,740
in the office for the football league in

00:01:13,310 --> 00:01:18,290
Germany and like every week you have to

00:01:15,740 --> 00:01:19,670
come up with new predictions and usually

00:01:18,290 --> 00:01:21,799
if you're interested in football you

00:01:19,670 --> 00:01:25,100
don't you're not very objective about

00:01:21,799 --> 00:01:27,620
like teams and so it's you're not using

00:01:25,100 --> 00:01:29,150
the scientific method basically so what

00:01:27,620 --> 00:01:32,330
I was thinking was that would be a

00:01:29,150 --> 00:01:35,530
perfect use case to implement something

00:01:32,330 --> 00:01:38,540
like a soccer match tendency predictor I

00:01:35,530 --> 00:01:41,900
will show you what i was thinking and

00:01:38,540 --> 00:01:44,570
what I meant by that so um let's start

00:01:41,900 --> 00:01:46,729
with a funny quote and this one's by

00:01:44,570 --> 00:01:48,950
paul gascoigne and he's also known as

00:01:46,729 --> 00:01:52,490
gaza he's a famous English football

00:01:48,950 --> 00:01:55,310
player and he famously said that I never

00:01:52,490 --> 00:01:59,270
predict anything and I never will so

00:01:55,310 --> 00:02:01,159
following his lead i will also predict

00:01:59,270 --> 00:02:02,750
something i will predict the tendencies

00:02:01,159 --> 00:02:05,810
of the mattress for the Premier League

00:02:02,750 --> 00:02:09,200
this weekend I think they will start at

00:02:05,810 --> 00:02:10,519
like 9pm and then you can just check for

00:02:09,200 --> 00:02:13,040
yourself how well the algorithm actually

00:02:10,519 --> 00:02:14,420
performs and whether you want to bet

00:02:13,040 --> 00:02:17,970
money on it

00:02:14,420 --> 00:02:20,370
so um first of all we have to ask

00:02:17,970 --> 00:02:22,790
yourself like what is machine learning

00:02:20,370 --> 00:02:26,280
like why would we use machine learning

00:02:22,790 --> 00:02:30,300
so like consider we were like the

00:02:26,280 --> 00:02:33,450
programmers of an AI in like an RPG game

00:02:30,300 --> 00:02:35,940
and this blue sword would represent a

00:02:33,450 --> 00:02:38,520
player's action so the player would

00:02:35,940 --> 00:02:40,290
attack us and then we will maybe react

00:02:38,520 --> 00:02:43,320
with the defense action with a blocking

00:02:40,290 --> 00:02:45,390
action so you could have some kind of

00:02:43,320 --> 00:02:48,030
behavior tree where based on your leg

00:02:45,390 --> 00:02:49,770
remaining health points you would also

00:02:48,030 --> 00:02:52,140
have the option to launch a

00:02:49,770 --> 00:02:55,140
counter-attack or maybe you want to

00:02:52,140 --> 00:02:56,970
drink a potion so the problem is and

00:02:55,140 --> 00:02:59,790
when you have to cite the appropriate

00:02:56,970 --> 00:03:02,430
actions and that's you will decided when

00:02:59,790 --> 00:03:04,680
you program this tree so the the inputs

00:03:02,430 --> 00:03:06,209
and the weights so how important is the

00:03:04,680 --> 00:03:09,270
health in proportion through the play

00:03:06,209 --> 00:03:11,390
action for example its deterministic

00:03:09,270 --> 00:03:13,709
because you decide on it beforehand and

00:03:11,390 --> 00:03:16,380
this also means that the decision making

00:03:13,709 --> 00:03:17,940
process is very subjective because it's

00:03:16,380 --> 00:03:21,269
implemented by a program or a game

00:03:17,940 --> 00:03:23,340
designer and the machine cannot adapt to

00:03:21,269 --> 00:03:27,180
individual players does it doesn't it

00:03:23,340 --> 00:03:29,100
doesn't learn and let's say if we wanted

00:03:27,180 --> 00:03:32,220
to implement this in a deterministic way

00:03:29,100 --> 00:03:34,590
might look something like this so if the

00:03:32,220 --> 00:03:37,950
player attacks we look at our health bar

00:03:34,590 --> 00:03:40,530
and then we say at the health bar like

00:03:37,950 --> 00:03:42,870
above 75 percent then we do a

00:03:40,530 --> 00:03:45,120
counter-attack if it's between 25 and

00:03:42,870 --> 00:03:47,430
seventy-five percent we do a defense

00:03:45,120 --> 00:03:49,050
action and we have less than twenty-five

00:03:47,430 --> 00:03:52,350
percent of our house left and we will

00:03:49,050 --> 00:03:56,190
drink or health potion so these

00:03:52,350 --> 00:03:58,310
thresholds they have to be chosen

00:03:56,190 --> 00:04:01,350
beforehand and they might seem arbitrary

00:03:58,310 --> 00:04:03,780
or like it's like a personal feeling

00:04:01,350 --> 00:04:05,940
that what makes sense but in complex

00:04:03,780 --> 00:04:07,680
games and it might not be possible to

00:04:05,940 --> 00:04:09,900
manually implement all the possibilities

00:04:07,680 --> 00:04:13,910
and all the things you want to look at

00:04:09,900 --> 00:04:16,830
so we would not want to have this like

00:04:13,910 --> 00:04:18,660
the sturdy monistic logic instead we

00:04:16,830 --> 00:04:21,060
want to have something that will change

00:04:18,660 --> 00:04:23,669
or logic depending on something else

00:04:21,060 --> 00:04:25,920
maybe so this entire thing should be

00:04:23,669 --> 00:04:29,550
very dynamic

00:04:25,920 --> 00:04:32,070
so um the way that you can do this is

00:04:29,550 --> 00:04:34,020
with calculus and I'm trying to not go

00:04:32,070 --> 00:04:36,120
too deep into math because I'm like

00:04:34,020 --> 00:04:38,490
don't have the time for it but let's

00:04:36,120 --> 00:04:41,790
just take the scenario that we have the

00:04:38,490 --> 00:04:45,090
what the user did input and then we add

00:04:41,790 --> 00:04:48,030
the how healthy we are input and then we

00:04:45,090 --> 00:04:51,450
will get something that pertains to the

00:04:48,030 --> 00:04:53,370
three possible outputs of course like

00:04:51,450 --> 00:04:55,680
the two inputs are not equally important

00:04:53,370 --> 00:04:59,220
for decision-making so what we need here

00:04:55,680 --> 00:05:01,470
is some weights and in this case I just

00:04:59,220 --> 00:05:03,510
called them a and B and basically those

00:05:01,470 --> 00:05:05,840
weights determine how important those

00:05:03,510 --> 00:05:08,760
inputs are in relation to each other and

00:05:05,840 --> 00:05:10,860
then in the end we don't want to

00:05:08,760 --> 00:05:12,480
directly have like the action that we

00:05:10,860 --> 00:05:15,180
want to take instead we want to have

00:05:12,480 --> 00:05:17,310
like a probability distribution this

00:05:15,180 --> 00:05:19,290
could for example just be like what's

00:05:17,310 --> 00:05:22,770
the most probable action that a human

00:05:19,290 --> 00:05:24,690
player would take for example and this

00:05:22,770 --> 00:05:29,610
way it's called classification because

00:05:24,690 --> 00:05:33,210
we try to classify the correct output

00:05:29,610 --> 00:05:35,520
for the given inputs and once we have

00:05:33,210 --> 00:05:37,350
the correct weights like if we can

00:05:35,520 --> 00:05:40,380
calculate the best a and the best be

00:05:37,350 --> 00:05:41,970
then we have a model that represents the

00:05:40,380 --> 00:05:45,000
logic or the pattern that we want to

00:05:41,970 --> 00:05:48,300
make predictions on and the thing about

00:05:45,000 --> 00:05:50,820
models is like Georgie keybox said that

00:05:48,300 --> 00:05:53,190
all models are wrong but some are useful

00:05:50,820 --> 00:05:56,310
and what he means by that is basically

00:05:53,190 --> 00:05:59,070
that our model will not give us the

00:05:56,310 --> 00:06:00,510
perfect or the correct result but they

00:05:59,070 --> 00:06:04,020
will give us one that is the best

00:06:00,510 --> 00:06:06,740
approximation to reality basically or to

00:06:04,020 --> 00:06:10,500
the data that we already collected and

00:06:06,740 --> 00:06:12,900
so this is basically the magic inside a

00:06:10,500 --> 00:06:15,570
node but it's not called neural node

00:06:12,900 --> 00:06:17,250
it's called neural networks so we have

00:06:15,570 --> 00:06:21,240
to like understand what neural networks

00:06:17,250 --> 00:06:23,490
are and so the important question to

00:06:21,240 --> 00:06:25,950
answer is how does anything learn and

00:06:23,490 --> 00:06:27,750
some type of people and took a look at

00:06:25,950 --> 00:06:31,260
it like how learning is done in nature

00:06:27,750 --> 00:06:33,240
and as you already know probably it's

00:06:31,260 --> 00:06:34,370
done by neurons and this would be one

00:06:33,240 --> 00:06:36,620
neuron

00:06:34,370 --> 00:06:38,419
neuron receives input through its

00:06:36,620 --> 00:06:41,210
dendrites that's a fuzzy purple

00:06:38,419 --> 00:06:43,460
attentively stuff and then there it has

00:06:41,210 --> 00:06:45,710
the soma which is the middle part with

00:06:43,460 --> 00:06:48,620
the green coordinate and inside the soma

00:06:45,710 --> 00:06:50,360
there's magic happening and the input

00:06:48,620 --> 00:06:53,270
gets changed in a deterministic way

00:06:50,360 --> 00:06:56,360
inside the soma and then the result of

00:06:53,270 --> 00:06:59,990
it is sent through the axon terminals

00:06:56,360 --> 00:07:01,699
and in nature of course a decision in

00:06:59,990 --> 00:07:03,889
your brain is not made by one single

00:07:01,699 --> 00:07:06,500
neuron but by a vast network of neurons

00:07:03,889 --> 00:07:09,289
so we can have multiple layers of

00:07:06,500 --> 00:07:12,590
neurons in this case for example we have

00:07:09,289 --> 00:07:14,630
two layers with two and three neurons so

00:07:12,590 --> 00:07:17,060
in all output from the previous layer

00:07:14,630 --> 00:07:20,180
will be sent to all nodes in the next

00:07:17,060 --> 00:07:23,350
layer so in the end every node will

00:07:20,180 --> 00:07:26,150
output a value pertaining to one singer

00:07:23,350 --> 00:07:30,139
like one single possibility that you can

00:07:26,150 --> 00:07:32,419
take and the thing to take away from the

00:07:30,139 --> 00:07:35,240
slide basically is that instead of one

00:07:32,419 --> 00:07:37,580
neuron doing the magic ones you have

00:07:35,240 --> 00:07:41,330
multiple neurons that do it in parallel

00:07:37,580 --> 00:07:43,130
and also sequentially so even though

00:07:41,330 --> 00:07:45,680
each neuron changes values

00:07:43,130 --> 00:07:49,820
deterministically the whole thing is not

00:07:45,680 --> 00:07:51,770
deterministic okay so this is basically

00:07:49,820 --> 00:07:55,940
the same representation that we saw

00:07:51,770 --> 00:07:57,650
before except now i just changed in the

00:07:55,940 --> 00:08:01,729
natural neurons with artificial neurons

00:07:57,650 --> 00:08:04,250
and so for the for the math to work its

00:08:01,729 --> 00:08:06,919
magic we need numerical representations

00:08:04,250 --> 00:08:08,900
of our inputs and outputs so for example

00:08:06,919 --> 00:08:10,639
we can represent a health bar in a

00:08:08,900 --> 00:08:14,120
percentage which would be ninety-five

00:08:10,639 --> 00:08:16,460
percent in this case but so I personally

00:08:14,120 --> 00:08:18,710
think it's better to have like the most

00:08:16,460 --> 00:08:20,930
information possible so instead of

00:08:18,710 --> 00:08:22,729
saying this we have ninety-five percent

00:08:20,930 --> 00:08:24,919
over health left we could say that our

00:08:22,729 --> 00:08:28,910
maximum health or your current health is

00:08:24,919 --> 00:08:32,779
114 and the maximum help is 120 and by

00:08:28,910 --> 00:08:36,219
that or algorithm can deduce that it's

00:08:32,779 --> 00:08:40,159
ninety-five percent and have left and

00:08:36,219 --> 00:08:43,099
then we have the attack so the attack

00:08:40,159 --> 00:08:45,900
isn't it could be a string or label but

00:08:43,099 --> 00:08:48,150
in this case our neural network

00:08:45,900 --> 00:08:51,360
needs a numerical value so it can

00:08:48,150 --> 00:08:53,310
calculate on it and we could just give

00:08:51,360 --> 00:08:56,100
it like an ID and then just map it

00:08:53,310 --> 00:08:58,920
somewhere and but I didn't really like

00:08:56,100 --> 00:09:00,420
that idea because I was afraid M that I

00:08:58,920 --> 00:09:02,820
would introduce some numerical

00:09:00,420 --> 00:09:05,460
implications that I don't want to for

00:09:02,820 --> 00:09:07,890
example if attack is one and defense is

00:09:05,460 --> 00:09:10,290
to then somehow my neural network could

00:09:07,890 --> 00:09:12,570
think that the blocking action is like

00:09:10,290 --> 00:09:15,420
twice the attack action so this doesn't

00:09:12,570 --> 00:09:18,660
sound very smart one way to counter that

00:09:15,420 --> 00:09:22,320
is to instead use a vector or an area in

00:09:18,660 --> 00:09:24,480
the JavaScript context so by using this

00:09:22,320 --> 00:09:26,370
M airing I basically say that there are

00:09:24,480 --> 00:09:29,010
three possible actions that the user

00:09:26,370 --> 00:09:30,930
could take and he took the first one so

00:09:29,010 --> 00:09:34,680
basically that's like a like a bull

00:09:30,930 --> 00:09:36,360
array and so in this case the first

00:09:34,680 --> 00:09:37,890
value would be attack and the second

00:09:36,360 --> 00:09:43,770
would be defense and the third would be

00:09:37,890 --> 00:09:48,030
potion so how do we get our predictions

00:09:43,770 --> 00:09:50,850
and the first thing is I'm talking about

00:09:48,030 --> 00:09:53,370
is going to call is called forward

00:09:50,850 --> 00:09:56,430
propagation and it's called that because

00:09:53,370 --> 00:10:00,180
we propagate data for word from our

00:09:56,430 --> 00:10:02,460
input nodes to the output nodes so we

00:10:00,180 --> 00:10:04,800
start with our inputs that's the one

00:10:02,460 --> 00:10:08,310
you've seen before and then we send each

00:10:04,800 --> 00:10:10,380
input to each node in the first layer so

00:10:08,310 --> 00:10:13,680
let's focus on upper node so it's not so

00:10:10,380 --> 00:10:17,130
complicated and in this node we do our

00:10:13,680 --> 00:10:19,560
math magic so we have our weights and we

00:10:17,130 --> 00:10:23,850
multiply it with our inputs and then we

00:10:19,560 --> 00:10:25,440
get a new value which is X 11 because

00:10:23,850 --> 00:10:27,840
it's the value we get from the first

00:10:25,440 --> 00:10:29,900
node of the first layer and then we send

00:10:27,840 --> 00:10:33,090
that new value to the next nodes and

00:10:29,900 --> 00:10:36,690
then the lower note is the same thing

00:10:33,090 --> 00:10:38,460
and in the next layer all the nodes do

00:10:36,690 --> 00:10:40,770
exactly the same thing again of course

00:10:38,460 --> 00:10:43,680
the weights are different here I just

00:10:40,770 --> 00:10:46,770
call them D and E and then we get a

00:10:43,680 --> 00:10:51,030
value in the end so I just I just said

00:10:46,770 --> 00:10:54,150
that as 0.67 and because this would be

00:10:51,030 --> 00:10:56,040
like the probability of the

00:10:54,150 --> 00:10:57,930
action that is like directly linked to

00:10:56,040 --> 00:11:04,020
this node because like each output node

00:10:57,930 --> 00:11:07,590
is referring to one possible output okay

00:11:04,020 --> 00:11:09,450
so now we have basically made

00:11:07,590 --> 00:11:12,540
predictions from a training data but the

00:11:09,450 --> 00:11:14,070
prediction is not that good because in

00:11:12,540 --> 00:11:17,700
the first iteration which shoes are

00:11:14,070 --> 00:11:19,890
weights randomly and now we have to like

00:11:17,700 --> 00:11:24,450
the machine learns by trying to get

00:11:19,890 --> 00:11:26,250
better at predicting stuff and so my

00:11:24,450 --> 00:11:27,900
first instinct would be you could just

00:11:26,250 --> 00:11:30,420
reverse engineer right because you have

00:11:27,900 --> 00:11:32,400
the data and you know what's supposed to

00:11:30,420 --> 00:11:34,650
be the output and then you can just like

00:11:32,400 --> 00:11:36,000
reverse engineer and this is more or

00:11:34,650 --> 00:11:39,300
less basically what the machine also

00:11:36,000 --> 00:11:41,160
does this is called back propagation and

00:11:39,300 --> 00:11:43,140
might have guessed already it's because

00:11:41,160 --> 00:11:46,380
we propagate data back from the output

00:11:43,140 --> 00:11:48,690
nodes to the input nodes and let's say

00:11:46,380 --> 00:11:50,520
like these are our predictions this is

00:11:48,690 --> 00:11:52,320
the probability that like for example a

00:11:50,520 --> 00:11:54,990
human player would take this action with

00:11:52,320 --> 00:11:56,850
the given inputs and then this is the

00:11:54,990 --> 00:11:59,370
actual result this is like the truth

00:11:56,850 --> 00:12:01,650
that we know from our data set and then

00:11:59,370 --> 00:12:03,900
we need to figure out what the costs are

00:12:01,650 --> 00:12:06,600
and the costs are basically just the

00:12:03,900 --> 00:12:09,420
difference between the actual result and

00:12:06,600 --> 00:12:14,370
what we predicted so in this case it

00:12:09,420 --> 00:12:18,810
would be 0.33 0.14 and 0.19 respectively

00:12:14,370 --> 00:12:20,910
and now inside the nodes we do not try

00:12:18,810 --> 00:12:22,950
to get the right inputs instead we try

00:12:20,910 --> 00:12:25,950
to calculate how we would have to change

00:12:22,950 --> 00:12:28,560
the wave so the cost is lower next time

00:12:25,950 --> 00:12:30,210
like in the next iteration and I'm not

00:12:28,560 --> 00:12:32,550
going to go too deeply into that right

00:12:30,210 --> 00:12:35,940
now because like it's very mathematical

00:12:32,550 --> 00:12:38,190
and but after we've done that we will

00:12:35,940 --> 00:12:39,900
back propagate the values the first

00:12:38,190 --> 00:12:44,640
layer and we will do the same thing

00:12:39,900 --> 00:12:47,100
there okay and so one way that we

00:12:44,640 --> 00:12:48,660
calculate how to change the weights it's

00:12:47,100 --> 00:12:50,670
called like gradient descent there are

00:12:48,660 --> 00:12:52,410
other algorithms that you can use but in

00:12:50,670 --> 00:12:54,600
this case I want to show you I'm the way

00:12:52,410 --> 00:12:57,510
in descent because it's it's easy to

00:12:54,600 --> 00:13:02,700
explain in a graphical representation so

00:12:57,510 --> 00:13:05,190
um let's say our data is will be

00:13:02,700 --> 00:13:07,180
represented in this 3d am representation

00:13:05,190 --> 00:13:09,190
and we'll take a very simple

00:13:07,180 --> 00:13:11,290
example would like only two numerical

00:13:09,190 --> 00:13:15,120
features like only the max health and

00:13:11,290 --> 00:13:18,220
the current health and then we have our

00:13:15,120 --> 00:13:21,130
weights would so we do not plot the

00:13:18,220 --> 00:13:24,970
actual input data we plot the weights so

00:13:21,130 --> 00:13:28,900
that's a and B and then on the z axis we

00:13:24,970 --> 00:13:32,380
plot the cost and so the idea is that in

00:13:28,900 --> 00:13:33,940
the front you have high cost so the

00:13:32,380 --> 00:13:36,460
predictions that you make are very far

00:13:33,940 --> 00:13:39,250
from the actual reality and in the back

00:13:36,460 --> 00:13:40,410
we have low cost and the way we plot

00:13:39,250 --> 00:13:43,210
data in this three-dimensional

00:13:40,410 --> 00:13:45,550
representation is we have those circles

00:13:43,210 --> 00:13:48,190
the circle means that all the data

00:13:45,550 --> 00:13:49,870
points that are on the circle so all the

00:13:48,190 --> 00:13:52,960
combinations of a and B that are on the

00:13:49,870 --> 00:13:55,840
circle have the same cost and then you

00:13:52,960 --> 00:13:57,850
have different circles like this one and

00:13:55,840 --> 00:13:59,320
it's the same here like all the

00:13:57,850 --> 00:14:01,720
different data points on this circle

00:13:59,320 --> 00:14:03,880
have the same cost although this circle

00:14:01,720 --> 00:14:04,960
is a little bit darker and I made a

00:14:03,880 --> 00:14:08,020
darker because I wanted to represent

00:14:04,960 --> 00:14:10,000
that the cost is lower and so they all

00:14:08,020 --> 00:14:12,940
have the same cost on the circle but of

00:14:10,000 --> 00:14:15,610
course the differs from the from the

00:14:12,940 --> 00:14:17,530
previous circle and then we you know

00:14:15,610 --> 00:14:19,150
like further plot the data and then we

00:14:17,530 --> 00:14:21,490
get like this kind of funnel where you

00:14:19,150 --> 00:14:24,790
can just basically you look inside the

00:14:21,490 --> 00:14:27,550
funnel and in the middle that's our

00:14:24,790 --> 00:14:29,470
global minimum that's the point where

00:14:27,550 --> 00:14:34,720
the cost is the lowest that we can ever

00:14:29,470 --> 00:14:36,400
get with our with our algorithm so the

00:14:34,720 --> 00:14:38,290
way that gradient descent now tries to

00:14:36,400 --> 00:14:40,690
get there mathematically to the red dot

00:14:38,290 --> 00:14:42,070
is that we have start somewhere randomly

00:14:40,690 --> 00:14:44,470
like I said before we choose n be

00:14:42,070 --> 00:14:48,520
randomly and then basically great into

00:14:44,470 --> 00:14:50,980
the centers like walks steps towards the

00:14:48,520 --> 00:14:53,200
global minimum and just like one was

00:14:50,980 --> 00:14:55,000
around a little bit and just tries to

00:14:53,200 --> 00:14:58,420
try to approximate the global minimum

00:14:55,000 --> 00:15:00,430
and at some point hopefully it will get

00:14:58,420 --> 00:15:02,230
there doesn't really happen that often

00:15:00,430 --> 00:15:04,060
real life because we don't actually know

00:15:02,230 --> 00:15:06,340
what the global minimum is we can see it

00:15:04,060 --> 00:15:08,350
here because its graphical but if you

00:15:06,340 --> 00:15:13,270
have a mathematical represent you don't

00:15:08,350 --> 00:15:14,820
actually know and so the idea of this

00:15:13,270 --> 00:15:17,970
whole thing is like we iteratively

00:15:14,820 --> 00:15:21,540
approximate our model to the truth

00:15:17,970 --> 00:15:24,899
okay so i hope you still with me because

00:15:21,540 --> 00:15:27,389
this is gonna be a I'm not gonna go

00:15:24,899 --> 00:15:29,579
further into it because it's interesting

00:15:27,389 --> 00:15:31,379
to know how neural networks work but

00:15:29,579 --> 00:15:33,720
when you implement something you want to

00:15:31,379 --> 00:15:36,930
use a framework and not be bothered by

00:15:33,720 --> 00:15:40,980
all the mathematical stuff and so I'm

00:15:36,930 --> 00:15:44,000
gonna like introduce it another smart

00:15:40,980 --> 00:15:46,769
guy who said this longer quote thing and

00:15:44,000 --> 00:15:48,689
he says an approximate answers the right

00:15:46,769 --> 00:15:51,329
problems were the good deal more than an

00:15:48,689 --> 00:15:52,769
exact answer to approximate problem so

00:15:51,329 --> 00:15:54,959
basically the better you describe your

00:15:52,769 --> 00:15:56,639
problem the better your approximated

00:15:54,959 --> 00:16:02,100
answer will fill it even though it's not

00:15:56,639 --> 00:16:04,470
perfect so okay and let's implement

00:16:02,100 --> 00:16:06,930
something I will not do a live demo

00:16:04,470 --> 00:16:10,019
because I'm really scared and that's not

00:16:06,930 --> 00:16:12,060
gonna work and I have used a node.js

00:16:10,019 --> 00:16:13,829
library which is called synaptic and

00:16:12,060 --> 00:16:16,019
like I said it implements all the fun

00:16:13,829 --> 00:16:18,720
math stuff already and we just have to

00:16:16,019 --> 00:16:21,449
like build the application so these are

00:16:18,720 --> 00:16:23,370
22 lines of code and it's basically all

00:16:21,449 --> 00:16:25,079
you need to predict a tendency with

00:16:23,370 --> 00:16:27,750
their artificial network so we're not

00:16:25,079 --> 00:16:30,930
doing like AI anymore for RPGs now we're

00:16:27,750 --> 00:16:34,319
doing the prediction of soccer mattress

00:16:30,930 --> 00:16:36,240
so first we have this historic data with

00:16:34,319 --> 00:16:38,579
inputs in this case it's the market

00:16:36,240 --> 00:16:41,339
value of the two teams home team and

00:16:38,579 --> 00:16:43,980
away team and then the output represents

00:16:41,339 --> 00:16:46,139
the result so in this case the first

00:16:43,980 --> 00:16:47,879
element would be that the home team won

00:16:46,139 --> 00:16:49,649
the second element would be I'm

00:16:47,879 --> 00:16:52,050
representing a draw and the third

00:16:49,649 --> 00:16:55,920
element would be representing that the

00:16:52,050 --> 00:16:57,660
away team won and then we have like

00:16:55,920 --> 00:17:00,240
mattress that are that haven't happened

00:16:57,660 --> 00:17:01,680
yet they have of course also inputs but

00:17:00,240 --> 00:17:04,140
they don't have an output because of

00:17:01,680 --> 00:17:09,059
course we don't have a result yet so

00:17:04,140 --> 00:17:11,819
that makes two datasets basically and

00:17:09,059 --> 00:17:15,089
then we have to build our network and we

00:17:11,819 --> 00:17:17,159
use the number of input nodes that is

00:17:15,089 --> 00:17:21,059
the same number of inputs we have and

00:17:17,159 --> 00:17:23,309
then India we have three output nodes

00:17:21,059 --> 00:17:25,409
because we have three different classes

00:17:23,309 --> 00:17:27,689
that are possible and inside we have

00:17:25,409 --> 00:17:30,850
hidden layers and I just like edges

00:17:27,689 --> 00:17:32,470
chose two layers with six nodes

00:17:30,850 --> 00:17:34,960
it's not the this is the law or

00:17:32,470 --> 00:17:38,530
something and then we have to get a

00:17:34,960 --> 00:17:40,270
trainer for a network and then we train

00:17:38,530 --> 00:17:41,890
on it we tell them what the learning

00:17:40,270 --> 00:17:43,539
rate is the learning rate is basically

00:17:41,890 --> 00:17:46,120
the size of the steps that gradient

00:17:43,539 --> 00:17:49,000
descent takes and this is also i just

00:17:46,120 --> 00:17:51,940
chose that value and because it just

00:17:49,000 --> 00:17:53,770
felt like it and also i have to define

00:17:51,940 --> 00:17:55,360
the number of iterations which is how

00:17:53,770 --> 00:17:58,360
often you go through the entire training

00:17:55,360 --> 00:17:59,799
set to train your network and then when

00:17:58,360 --> 00:18:03,429
we're done with training we actually

00:17:59,799 --> 00:18:05,760
make predictions and if i would run the

00:18:03,429 --> 00:18:09,309
script it would look something like this

00:18:05,760 --> 00:18:12,309
so um what we can see like if we look at

00:18:09,309 --> 00:18:14,320
the first prediction and the the home

00:18:12,309 --> 00:18:16,120
team is worth less than half the of the

00:18:14,320 --> 00:18:18,220
away team and the probability of winning

00:18:16,120 --> 00:18:20,710
the match is also about half of the

00:18:18,220 --> 00:18:21,909
probability to lose the match that seems

00:18:20,710 --> 00:18:24,370
pretty straightforward and probably

00:18:21,909 --> 00:18:27,250
whatever I would have predicted to if it

00:18:24,370 --> 00:18:28,830
just only had those given data but when

00:18:27,250 --> 00:18:31,179
we look at like the third prediction

00:18:28,830 --> 00:18:33,070
although the home team is also worth

00:18:31,179 --> 00:18:35,080
about half compared to the way team our

00:18:33,070 --> 00:18:36,760
machine predicts that is likely more

00:18:35,080 --> 00:18:39,460
likely for the home team to win the game

00:18:36,760 --> 00:18:40,870
and this could have a lot of like this

00:18:39,460 --> 00:18:42,580
could have a lot of meanings it could

00:18:40,870 --> 00:18:45,130
mean that there's something like a home

00:18:42,580 --> 00:18:47,679
team advantage or there's like a

00:18:45,130 --> 00:18:49,840
different like implication that we don't

00:18:47,679 --> 00:18:52,419
know about and the problem with machine

00:18:49,840 --> 00:18:54,190
learning and prediction is that we don't

00:18:52,419 --> 00:18:56,590
really know how our machine gets there

00:18:54,190 --> 00:18:58,600
because it's non deterministic and those

00:18:56,590 --> 00:19:00,309
model is purely mathematical and the

00:18:58,600 --> 00:19:02,710
weights don't translate into something

00:19:00,309 --> 00:19:04,780
that you can understand intuitively so

00:19:02,710 --> 00:19:06,610
we can reverse engineer something like

00:19:04,780 --> 00:19:11,320
home team advantage unless we actually

00:19:06,610 --> 00:19:14,409
implemented it okay so I hope you're

00:19:11,320 --> 00:19:16,630
still with me and this is how we

00:19:14,409 --> 00:19:20,289
implemented it now we have got like our

00:19:16,630 --> 00:19:21,970
predictions and then now how do we know

00:19:20,289 --> 00:19:24,940
how well we're actually doing with our

00:19:21,970 --> 00:19:26,890
algorithm and if we know how we're doing

00:19:24,940 --> 00:19:31,570
how can we implement how can we improve

00:19:26,890 --> 00:19:33,159
it so um when we want to figure figure

00:19:31,570 --> 00:19:34,510
out how our algorithm performs there's

00:19:33,159 --> 00:19:36,490
something called the error like the

00:19:34,510 --> 00:19:39,309
errors like I said the difference

00:19:36,490 --> 00:19:40,790
between the actual real result and what

00:19:39,309 --> 00:19:43,910
we predicted

00:19:40,790 --> 00:19:45,110
and so it's an epic already gives

00:19:43,910 --> 00:19:47,660
something and has something like that

00:19:45,110 --> 00:19:49,190
it's called the data error and all we

00:19:47,660 --> 00:19:51,740
have to do is add a schedule to our

00:19:49,190 --> 00:19:54,470
trainer and we say basically that every

00:19:51,740 --> 00:19:57,140
10,000 iteration do the stuff that I

00:19:54,470 --> 00:19:59,780
give you in the function and basically

00:19:57,140 --> 00:20:04,610
we just lock the data error rate and if

00:19:59,780 --> 00:20:06,430
I run this it will look like this so we

00:20:04,610 --> 00:20:10,030
can see that there is an error rate of

00:20:06,430 --> 00:20:12,050
0.19 this does not mean that like

00:20:10,030 --> 00:20:14,750
nineteen percent of our predictions are

00:20:12,050 --> 00:20:16,790
false this is a mathematical error rate

00:20:14,750 --> 00:20:19,070
it's the mean squared error and it's

00:20:16,790 --> 00:20:21,020
basically just a distance the errors

00:20:19,070 --> 00:20:23,810
distant distance between our predictions

00:20:21,020 --> 00:20:25,850
and the truth so this doesn't really

00:20:23,810 --> 00:20:27,380
translate into anything like if people

00:20:25,850 --> 00:20:29,900
ask me how well does it I wouldn't

00:20:27,380 --> 00:20:34,100
perform if I same I mean squared error

00:20:29,900 --> 00:20:36,650
is like 19 0.19 nobody knows what I'm

00:20:34,100 --> 00:20:38,930
talking about right so I wanted to like

00:20:36,650 --> 00:20:40,430
try to come up with a metric that is

00:20:38,930 --> 00:20:41,570
more straightforward and that would tell

00:20:40,430 --> 00:20:47,210
me an error rate that I can actually

00:20:41,570 --> 00:20:48,170
understand so I was coming up with

00:20:47,210 --> 00:20:49,940
something that's called the

00:20:48,170 --> 00:20:54,110
classification error it's basically the

00:20:49,940 --> 00:20:57,010
same thing where we in this case we have

00:20:54,110 --> 00:20:59,270
an error counter and then we do a

00:20:57,010 --> 00:21:01,070
classification actually because now

00:20:59,270 --> 00:21:05,750
before you saw that we have a

00:21:01,070 --> 00:21:07,640
probability distribution and now we want

00:21:05,750 --> 00:21:09,920
to make an actual prediction from the

00:21:07,640 --> 00:21:11,720
distribution so basically we say this is

00:21:09,920 --> 00:21:14,180
the most likely so I'm going to predict

00:21:11,720 --> 00:21:17,540
this and then we just count the numbers

00:21:14,180 --> 00:21:21,680
the times that we are wrong and then bye

00:21:17,540 --> 00:21:26,600
I'm sorry from that we want to calculate

00:21:21,680 --> 00:21:28,250
our error rate and in this case if I run

00:21:26,600 --> 00:21:29,690
my algorithm it would love doing

00:21:28,250 --> 00:21:32,270
something like that you can see that the

00:21:29,690 --> 00:21:34,370
error went up compared to the mean

00:21:32,270 --> 00:21:36,260
squared error which is logical because

00:21:34,370 --> 00:21:39,650
we actually make predictions and we can

00:21:36,260 --> 00:21:43,460
either be wrong or right we don't have

00:21:39,650 --> 00:21:46,160
like a distance anymore so we have this

00:21:43,460 --> 00:21:48,620
data but it's we use the classification

00:21:46,160 --> 00:21:51,710
data we use the same data that we train

00:21:48,620 --> 00:21:53,090
or network on which is not very smart

00:21:51,710 --> 00:21:55,610
because our

00:21:53,090 --> 00:21:58,280
should actually predict something that

00:21:55,610 --> 00:22:01,010
it doesn't know about yet so to figure

00:21:58,280 --> 00:22:02,930
out how our algorithm performs with data

00:22:01,010 --> 00:22:06,080
that it doesn't know about you basically

00:22:02,930 --> 00:22:08,990
take our data sets and then split it in

00:22:06,080 --> 00:22:11,510
two thirds basically we take two thirds

00:22:08,990 --> 00:22:13,820
of the trainings of the data set to

00:22:11,510 --> 00:22:17,000
train and then the last third we use to

00:22:13,820 --> 00:22:19,790
classify or to Bella date or a measure

00:22:17,000 --> 00:22:21,890
of performance so I have to speed up a

00:22:19,790 --> 00:22:24,440
little bit and basically we do the same

00:22:21,890 --> 00:22:25,670
thing that we did before but in this

00:22:24,440 --> 00:22:27,650
case we just use the cross-validation

00:22:25,670 --> 00:22:30,980
set to make our predictions instead of

00:22:27,650 --> 00:22:33,230
training set and if we run the script it

00:22:30,980 --> 00:22:34,790
looks something like this again our

00:22:33,230 --> 00:22:36,680
error I'd jumped up a little bit and

00:22:34,790 --> 00:22:38,420
also it's just like all over the place

00:22:36,680 --> 00:22:40,880
is like super weird because it doesn't

00:22:38,420 --> 00:22:45,320
seem to like go down silly but it just

00:22:40,880 --> 00:22:47,300
like jumps around and so okay we know

00:22:45,320 --> 00:22:49,370
those error rates and I'm going to skip

00:22:47,300 --> 00:22:52,730
the slide real quick because it's just

00:22:49,370 --> 00:22:54,710
like a summary and and the next question

00:22:52,730 --> 00:22:57,200
would be how do we interpret this and

00:22:54,710 --> 00:23:03,320
how can we actually improve on it and I

00:22:57,200 --> 00:23:05,120
have to skip the sled to I'm sorry ok so

00:23:03,320 --> 00:23:08,540
there are like a few things that I want

00:23:05,120 --> 00:23:10,640
to try to improve the improve the

00:23:08,540 --> 00:23:12,320
algorithm first thing is adjusting the

00:23:10,640 --> 00:23:14,210
learning rate so we saw that the error

00:23:12,320 --> 00:23:16,190
rate was jumping like up and down and up

00:23:14,210 --> 00:23:17,810
and down and this could mean that we

00:23:16,190 --> 00:23:19,940
already like reach the global minimum

00:23:17,810 --> 00:23:23,660
and are just like wandering around it

00:23:19,940 --> 00:23:26,630
and I just wanted to like try what would

00:23:23,660 --> 00:23:29,030
happen if I just changed the learning

00:23:26,630 --> 00:23:31,990
rate so this is the error rate that we

00:23:29,030 --> 00:23:35,900
had before with the am learning rate of

00:23:31,990 --> 00:23:39,590
0.003 and then I just changed it to 0 0

00:23:35,900 --> 00:23:41,330
to 1 and this is what happened what you

00:23:39,590 --> 00:23:44,150
can see is that the error it is a little

00:23:41,330 --> 00:23:45,530
bit higher but now it like slowly goes

00:23:44,150 --> 00:23:48,800
down and doesn't like walk around

00:23:45,530 --> 00:23:51,290
anymore and this could mean that if I do

00:23:48,800 --> 00:23:53,180
more iterations I will get a better like

00:23:51,290 --> 00:23:55,280
error wait I will be closer to the

00:23:53,180 --> 00:23:58,580
global minimum even though my steps are

00:23:55,280 --> 00:24:00,260
smaller and in this case I just decided

00:23:58,580 --> 00:24:02,050
to leave it at that to just show you

00:24:00,260 --> 00:24:04,180
what what can happen

00:24:02,050 --> 00:24:06,730
when you change the learning rate and I

00:24:04,180 --> 00:24:08,500
wanted to try some other stuff too so

00:24:06,730 --> 00:24:11,590
the next thing I wanted to try was to

00:24:08,500 --> 00:24:14,500
just simply get more data and i get i

00:24:11,590 --> 00:24:17,530
just added in to new seasons which was

00:24:14,500 --> 00:24:19,000
100% more data and again this is the

00:24:17,530 --> 00:24:21,310
learning rate from before the error

00:24:19,000 --> 00:24:23,350
rates from before and these are the

00:24:21,310 --> 00:24:26,190
error rates after i added more data and

00:24:23,350 --> 00:24:28,900
what you can see is that between the

00:24:26,190 --> 00:24:31,120
10,000 iteration in the 100,000th

00:24:28,900 --> 00:24:34,090
iteration there is like a bigger

00:24:31,120 --> 00:24:36,580
difference with more data then with less

00:24:34,090 --> 00:24:38,650
data which means like if you train your

00:24:36,580 --> 00:24:40,300
algorithm like a hundred thousand four

00:24:38,650 --> 00:24:41,920
hundred thousand integrations but the

00:24:40,300 --> 00:24:45,040
error rate doesn't change that much you

00:24:41,920 --> 00:24:46,960
don't really have to write so this could

00:24:45,040 --> 00:24:51,520
mean that it actually would be worth

00:24:46,960 --> 00:24:53,290
your time to get more data and then the

00:24:51,520 --> 00:24:55,810
last thing that I tried was to simply

00:24:53,290 --> 00:24:58,300
add more features to give the algorithm

00:24:55,810 --> 00:25:00,130
or inputs which would also just mean

00:24:58,300 --> 00:25:04,180
that I'm describing the problem better

00:25:00,130 --> 00:25:06,130
or more detailed so before I had two

00:25:04,180 --> 00:25:09,580
features those were the market values of

00:25:06,130 --> 00:25:12,100
the two teams and now i just added like

00:25:09,580 --> 00:25:14,410
three more features and the positions of

00:25:12,100 --> 00:25:17,830
the teams in the table before the match

00:25:14,410 --> 00:25:19,840
starts and also the MH day so I'm saying

00:25:17,830 --> 00:25:21,850
probably it does have an influence how

00:25:19,840 --> 00:25:24,430
far into the season we are and how well

00:25:21,850 --> 00:25:25,990
they are compared to other teams and now

00:25:24,430 --> 00:25:28,540
if we look at the error rate right now

00:25:25,990 --> 00:25:30,490
looks pretty good except that the

00:25:28,540 --> 00:25:32,710
cross-validation error seems to go up at

00:25:30,490 --> 00:25:34,540
some point but it still is performing

00:25:32,710 --> 00:25:36,580
better than having only two features so

00:25:34,540 --> 00:25:38,560
we could say from that that it might

00:25:36,580 --> 00:25:43,990
make sense to put more effort into

00:25:38,560 --> 00:25:47,280
getting more features so yeah those are

00:25:43,990 --> 00:25:49,870
the things that I actually tried and

00:25:47,280 --> 00:25:51,700
this is basically just prototyping stuff

00:25:49,870 --> 00:25:54,040
just trying stuff out and then decide

00:25:51,700 --> 00:25:55,930
what would be like worth my time the

00:25:54,040 --> 00:25:57,760
most and there's also this thing called

00:25:55,930 --> 00:26:00,340
regularization that like real data

00:25:57,760 --> 00:26:02,020
scientists use but I unfortunate don't

00:26:00,340 --> 00:26:03,400
have the time to really go that deep

00:26:02,020 --> 00:26:09,210
into it but we can talk about it later

00:26:03,400 --> 00:26:12,070
after the talk and okay so I'm gonna

00:26:09,210 --> 00:26:12,980
pull up another quote so you still with

00:26:12,070 --> 00:26:15,410
me

00:26:12,980 --> 00:26:17,179
so this Court is most famously of

00:26:15,410 --> 00:26:20,390
tributed niels bohr but I'm not quite

00:26:17,179 --> 00:26:21,950
sure if he actually said that but the

00:26:20,390 --> 00:26:24,410
chorus prediction is very difficult

00:26:21,950 --> 00:26:26,030
especially about the future and now as

00:26:24,410 --> 00:26:28,010
they have seen it's not even that easy

00:26:26,030 --> 00:26:32,390
about like predicting stuff in the past

00:26:28,010 --> 00:26:35,419
or the present and so what I want to

00:26:32,390 --> 00:26:38,720
like talk about now that I'm coming to

00:26:35,419 --> 00:26:41,660
the end and is how do you actually work

00:26:38,720 --> 00:26:42,980
with machines like how do you actually

00:26:41,660 --> 00:26:46,370
work when you're doing machine learning

00:26:42,980 --> 00:26:49,040
and what I've learned is that you have

00:26:46,370 --> 00:26:51,679
to work incrementally you will get there

00:26:49,040 --> 00:26:53,570
eventually but neural networks are just

00:26:51,679 --> 00:26:55,580
basically like your brain and practices

00:26:53,570 --> 00:26:57,260
what makes perfect so you can't expect

00:26:55,580 --> 00:27:00,320
to have the perfect solution like right

00:26:57,260 --> 00:27:02,929
out of the box have to slowly get there

00:27:00,320 --> 00:27:05,419
and you have to think about the problem

00:27:02,929 --> 00:27:07,100
not the solution the reason to work with

00:27:05,419 --> 00:27:08,390
neural networks is precisely so you

00:27:07,100 --> 00:27:10,340
don't have to come up with a solution

00:27:08,390 --> 00:27:13,400
yourself you get them giving this to a

00:27:10,340 --> 00:27:15,169
machine and you can put your time and

00:27:13,400 --> 00:27:19,190
effort into thinking about how to best

00:27:15,169 --> 00:27:20,630
describe your problem and you should try

00:27:19,190 --> 00:27:24,110
out different configuration parameters

00:27:20,630 --> 00:27:26,390
if you start with a new and problem or

00:27:24,110 --> 00:27:28,010
new thing then no one can tell you what

00:27:26,390 --> 00:27:29,870
your perfect learning rate will should

00:27:28,010 --> 00:27:32,809
be or how many layers you will need or

00:27:29,870 --> 00:27:34,309
how to choose like what what kind of

00:27:32,809 --> 00:27:36,620
configuration camera parameters you

00:27:34,309 --> 00:27:38,120
should use you should just come up with

00:27:36,620 --> 00:27:40,640
a metric that is important to you that

00:27:38,120 --> 00:27:42,530
you can understand and just like change

00:27:40,640 --> 00:27:44,750
stuff and try it out and then basically

00:27:42,530 --> 00:27:47,929
see what it does here metric and then

00:27:44,750 --> 00:27:49,429
decide which way you want to go and the

00:27:47,929 --> 00:27:52,010
most important thing about machine

00:27:49,429 --> 00:27:54,049
learning is it's about the data and if

00:27:52,010 --> 00:27:56,450
you have data that is biased you will

00:27:54,049 --> 00:27:58,580
get biased results I don't know if you

00:27:56,450 --> 00:28:00,440
remember this one an incident where like

00:27:58,580 --> 00:28:03,049
this face recognition software would

00:28:00,440 --> 00:28:05,480
flag like African Americans as like Apes

00:28:03,049 --> 00:28:07,340
and that's not because the machine is

00:28:05,480 --> 00:28:10,309
like evil or several races it's because

00:28:07,340 --> 00:28:11,990
the data was biased and and so you have

00:28:10,309 --> 00:28:13,429
to be really careful what you give your

00:28:11,990 --> 00:28:18,760
machine because it's going to learn from

00:28:13,429 --> 00:28:21,320
this data and not anything else okay and

00:28:18,760 --> 00:28:23,150
so I have those recommended reading

00:28:21,320 --> 00:28:24,909
section in case you want to read up more

00:28:23,150 --> 00:28:27,940
on machine learning

00:28:24,909 --> 00:28:30,099
and just dive into it I hope I've like

00:28:27,940 --> 00:28:32,019
made it clear that it's not really that

00:28:30,099 --> 00:28:33,489
complicated to actually build something

00:28:32,019 --> 00:28:36,190
with it even though you're not like

00:28:33,489 --> 00:28:39,220
totally into the math part and the first

00:28:36,190 --> 00:28:41,559
link is a link to my repository and you

00:28:39,220 --> 00:28:43,149
can find the whole thing there like the

00:28:41,559 --> 00:28:48,099
whole data retrieval included and how

00:28:43,149 --> 00:28:54,039
implemented the whole like error error

00:28:48,099 --> 00:28:56,739
recognition of error rate and pop my I'm

00:28:54,039 --> 00:29:00,220
sorry so you can just check it out there

00:28:56,739 --> 00:29:03,759
and then this is the little link to the

00:29:00,220 --> 00:29:07,029
library i use synaptic and i have the i

00:29:03,759 --> 00:29:08,259
have also linked to the course I'm think

00:29:07,029 --> 00:29:10,570
it's not that interesting now that I'm

00:29:08,259 --> 00:29:12,700
going to tell you about like each and

00:29:10,570 --> 00:29:15,399
every single link I'm going to put up

00:29:12,700 --> 00:29:17,349
the slides later I'm gonna edit to get

00:29:15,399 --> 00:29:20,320
her I think yeah get her on Twitter and

00:29:17,349 --> 00:29:22,749
so you can check it out there but also

00:29:20,320 --> 00:29:24,639
there's this amazing page called coding

00:29:22,749 --> 00:29:26,320
game so it's basically just coding for

00:29:24,639 --> 00:29:28,029
fun and coding with your friends and

00:29:26,320 --> 00:29:29,649
everything and they have an awesome new

00:29:28,029 --> 00:29:32,200
machine learning section that uses

00:29:29,649 --> 00:29:34,299
tensorflow tender flows the machine

00:29:32,200 --> 00:29:36,129
learning library for python by google if

00:29:34,299 --> 00:29:38,889
you don't know that and it's like really

00:29:36,129 --> 00:29:42,639
easy to use and and you should totally

00:29:38,889 --> 00:29:45,099
check it out okay so like I said before

00:29:42,639 --> 00:29:46,809
I've done some predictions for the

00:29:45,099 --> 00:29:48,369
Premier League those are the predictions

00:29:46,809 --> 00:29:50,769
you can like take a picture right now

00:29:48,369 --> 00:29:53,409
and then check and then you just bet

00:29:50,769 --> 00:29:55,539
money on it and then we can just see who

00:29:53,409 --> 00:29:58,059
made the most money tomorrow by the end

00:29:55,539 --> 00:29:59,769
of the day or like tomorrow and then who

00:29:58,059 --> 00:30:03,519
made the most money you should just buy

00:29:59,769 --> 00:30:06,419
us all drinks I guess alright so that

00:30:03,519 --> 00:30:06,419
was it thank you

00:30:07,510 --> 00:30:09,570

YouTube URL: https://www.youtube.com/watch?v=rZ_8xTX1LU4


