Title: Algorithms and Their Habitat by Vitalii Bobrov | JSConf Budapest 2019
Publication date: 2019-11-07
Playlist: JSConf Budapest 2019
Description: 
	https://2019.jsconfbp.com/speakers/vitalii_bobrov

Algorithms are mysterious beasts that hard to catch in the source code. However, well-chosen data structures and efficient algorithms applied to a web app is a key to performance. I want to show how to fit the knowledge you got at the university can solve your daily routines.

Vitalii is a Lead JavaScript Engineer with more than six years of professional experience. He is co-organizer of Angular Wroclaw meetup. Vitalii is keeping up-to-date with the latest Web Platform features and doing great experiments with it. This guy is not just a nerd, but tech speaker, ngGirls mentor, and the father of the excellent little girl.
Captions: 
	00:00:05,420 --> 00:00:12,210
okay hello everyone so I'm going to

00:00:08,970 --> 00:00:15,059
speak about our greens all these small

00:00:12,210 --> 00:00:18,500
creatures that living in our codebases

00:00:15,059 --> 00:00:22,410
even we if we don't really know about it

00:00:18,500 --> 00:00:24,930
before we start few facts about me so

00:00:22,410 --> 00:00:26,760
i'm vitaly i'm working for company

00:00:24,930 --> 00:00:29,400
called upon as the leads of train

00:00:26,760 --> 00:00:32,880
engineer in poland in broad swath i'm

00:00:29,400 --> 00:00:34,440
Corgan eyes in meetups and i really love

00:00:32,880 --> 00:00:36,510
to experiment with some interesting

00:00:34,440 --> 00:00:39,350
stuff combined and expect these things

00:00:36,510 --> 00:00:42,629
and stuff like that so and you can

00:00:39,350 --> 00:00:46,350
follow me on twitter read my blog and

00:00:42,629 --> 00:00:49,700
things like that so our main topic Algar

00:00:46,350 --> 00:00:53,730
is what is actually our grids

00:00:49,700 --> 00:00:57,449
so it's a specification how to solve

00:00:53,730 --> 00:01:01,800
some problem step by step so it's just

00:00:57,449 --> 00:01:06,260
instructions yes and what why we should

00:01:01,800 --> 00:01:09,840
care about it we just using some react

00:01:06,260 --> 00:01:12,060
components to build your eyes so we are

00:01:09,840 --> 00:01:16,409
not doing some rocket science or things

00:01:12,060 --> 00:01:19,409
like that but actually algorithm a way

00:01:16,409 --> 00:01:22,740
even in all of your frameworks right so

00:01:19,409 --> 00:01:25,670
many algorithmic optimizations to reduce

00:01:22,740 --> 00:01:29,280
memory footprint to make them faster and

00:01:25,670 --> 00:01:31,950
all these things might came with some

00:01:29,280 --> 00:01:36,090
trade-offs and we will speak about them

00:01:31,950 --> 00:01:39,570
as well so before we start I need to

00:01:36,090 --> 00:01:42,360
introduce what is complexity how we can

00:01:39,570 --> 00:01:46,350
measure our algorithm is it good enough

00:01:42,360 --> 00:01:50,970
or we should look for better solution

00:01:46,350 --> 00:01:55,409
for it so complexity is the way to

00:01:50,970 --> 00:01:58,110
explain us how our code will scale will

00:01:55,409 --> 00:02:00,329
work at scale for example on your test

00:01:58,110 --> 00:02:02,579
environment you have just few tests

00:02:00,329 --> 00:02:05,159
user's ten of them but in real

00:02:02,579 --> 00:02:08,340
application you have millions of them or

00:02:05,159 --> 00:02:12,190
something so you should know how it will

00:02:08,340 --> 00:02:15,430
behave should you optimize this for more

00:02:12,190 --> 00:02:19,330
or entities and in computer science

00:02:15,430 --> 00:02:24,960
reset standard notation for that called

00:02:19,330 --> 00:02:29,920
Big O so what is that it's actually a

00:02:24,960 --> 00:02:34,810
graphical representation how our time of

00:02:29,920 --> 00:02:39,010
algorithm will be behaved on more and

00:02:34,810 --> 00:02:42,700
more input date so we have like near one

00:02:39,010 --> 00:02:44,470
so it grows as we increase the entities

00:02:42,700 --> 00:02:47,680
we pass to the functions

00:02:44,470 --> 00:02:49,840
it could be logarithmic and it could be

00:02:47,680 --> 00:02:52,870
quadratic and so on so forth

00:02:49,840 --> 00:02:55,480
and there is pretty easier explanation

00:02:52,870 --> 00:02:58,650
about it with some emojis yeah

00:02:55,480 --> 00:03:02,260
constant time you're happy you probably

00:02:58,650 --> 00:03:09,460
couldn't do it even faster logarithmic

00:03:02,260 --> 00:03:13,150
good one linear okay and then you became

00:03:09,460 --> 00:03:15,910
more and more sad and those kind of

00:03:13,150 --> 00:03:18,970
content complexity or memory complexity

00:03:15,910 --> 00:03:20,739
means that you actually need to improve

00:03:18,970 --> 00:03:24,430
something or even write your code

00:03:20,739 --> 00:03:27,190
completely and we have to management's

00:03:24,430 --> 00:03:30,940
management's time and space complexity

00:03:27,190 --> 00:03:34,600
time stands for how many times it takes

00:03:30,940 --> 00:03:37,870
on some generic computer machine to

00:03:34,600 --> 00:03:40,650
execute your code we just thinking that

00:03:37,870 --> 00:03:44,620
we have some machine that executes one

00:03:40,650 --> 00:03:47,170
action fair-cheeked yeah and space

00:03:44,620 --> 00:03:49,750
complexity our memory usage we can

00:03:47,170 --> 00:03:54,040
predict how many memory we will utilize

00:03:49,750 --> 00:03:57,130
with our app so as I said before all

00:03:54,040 --> 00:03:59,140
these metrics will show us where is the

00:03:57,130 --> 00:04:01,840
bottleneck in our code what we should

00:03:59,140 --> 00:04:04,120
improve and the sink is with algorithm

00:04:01,840 --> 00:04:07,390
even if you have good enough or green

00:04:04,120 --> 00:04:11,440
there is a possibility to find a better

00:04:07,390 --> 00:04:15,760
one so there is no any limits even if

00:04:11,440 --> 00:04:18,609
you have some knowledge in computer

00:04:15,760 --> 00:04:21,190
science that there is the best algorithm

00:04:18,609 --> 00:04:25,230
you could use probably you can invent a

00:04:21,190 --> 00:04:29,380
new one better or more suited for your

00:04:25,230 --> 00:04:31,600
situation your application and the first

00:04:29,380 --> 00:04:35,140
thing I want to speak about is data

00:04:31,600 --> 00:04:37,600
normalization now it's common to use

00:04:35,140 --> 00:04:41,110
some state management tools like redox

00:04:37,600 --> 00:04:44,340
or NGO rigs whatever and it basically a

00:04:41,110 --> 00:04:46,990
big object containing all data sets and

00:04:44,340 --> 00:04:48,870
usually when you want to access some

00:04:46,990 --> 00:04:52,720
entities in list

00:04:48,870 --> 00:04:55,750
you won't do that as fast as possible

00:04:52,720 --> 00:05:00,790
and there is a technique called data

00:04:55,750 --> 00:05:04,140
normalization that allows you to have a

00:05:00,790 --> 00:05:07,260
constant time access to your entities

00:05:04,140 --> 00:05:11,410
basically what you do you remove your

00:05:07,260 --> 00:05:15,480
data from array to object with key of

00:05:11,410 --> 00:05:18,640
some ID and object as a value itself

00:05:15,480 --> 00:05:23,040
where we can use it when we have some

00:05:18,640 --> 00:05:26,350
related data entities in our store or

00:05:23,040 --> 00:05:30,550
any other kind of data when we have

00:05:26,350 --> 00:05:34,000
recursive entities and we want to have

00:05:30,550 --> 00:05:36,850
fast lookup through list of entities

00:05:34,000 --> 00:05:38,979
let's take a look of some examples for

00:05:36,850 --> 00:05:42,070
example data with relations imagine you

00:05:38,979 --> 00:05:45,840
have ecommerce website with some phone

00:05:42,070 --> 00:05:50,220
selling and each phone has a category it

00:05:45,840 --> 00:05:55,450
relates to so it's a relation between

00:05:50,220 --> 00:05:58,360
item in a cart and a category in your

00:05:55,450 --> 00:06:01,180
e-commerce shop recursive data

00:05:58,360 --> 00:06:03,729
structures your categories could have

00:06:01,180 --> 00:06:06,490
some subcategories and basically they

00:06:03,729 --> 00:06:10,090
should represent some kind of tree and

00:06:06,490 --> 00:06:13,600
this and this tree could have cycles as

00:06:10,090 --> 00:06:19,240
well sometimes so it's a recursive data

00:06:13,600 --> 00:06:21,790
set when we can and why we can use data

00:06:19,240 --> 00:06:24,220
normalization in such cases so for

00:06:21,790 --> 00:06:28,570
example we want to get some product body

00:06:24,220 --> 00:06:31,090
so instead of accessing and traversing

00:06:28,570 --> 00:06:34,060
through the list we just accessing it

00:06:31,090 --> 00:06:37,780
through ID the same when we want to get

00:06:34,060 --> 00:06:38,830
some categories by ID or products by

00:06:37,780 --> 00:06:42,190
category

00:06:38,830 --> 00:06:45,520
and actually we can reduce some memory

00:06:42,190 --> 00:06:49,750
footprint with that as well let's take a

00:06:45,520 --> 00:06:53,139
look in any service just need to update

00:06:49,750 --> 00:06:55,509
or select our data so for example we

00:06:53,139 --> 00:06:58,780
want to get a product body we have a

00:06:55,509 --> 00:07:02,490
list of products and we find in ID

00:06:58,780 --> 00:07:06,430
inside this list yes it should have a

00:07:02,490 --> 00:07:09,099
linear time complexity another thing we

00:07:06,430 --> 00:07:11,590
want to get all products related to some

00:07:09,099 --> 00:07:14,409
category so we going through all

00:07:11,590 --> 00:07:17,139
products and finding if the product

00:07:14,409 --> 00:07:22,469
related to some category and returning

00:07:17,139 --> 00:07:26,919
them interest it will take us n by n

00:07:22,469 --> 00:07:30,550
time complexity where the end could be a

00:07:26,919 --> 00:07:33,340
number of our products and M is number

00:07:30,550 --> 00:07:37,090
of our categories could be improve it

00:07:33,340 --> 00:07:40,780
and probably yeah and we also have a

00:07:37,090 --> 00:07:43,150
recursive access to categories for

00:07:40,780 --> 00:07:43,900
example if we are looking for category

00:07:43,150 --> 00:07:47,349
by ID

00:07:43,900 --> 00:07:51,460
we iterating through them until we find

00:07:47,349 --> 00:07:55,900
as a category we want and it could be

00:07:51,460 --> 00:07:59,650
linear time and also we could to use

00:07:55,900 --> 00:08:02,919
some memory because we have a recursive

00:07:59,650 --> 00:08:07,990
call stack that actually uses memory for

00:08:02,919 --> 00:08:10,389
each call else recursive code could look

00:08:07,990 --> 00:08:13,449
like this you go and deeper and deeper

00:08:10,389 --> 00:08:17,620
it's very more harder to maintain it

00:08:13,449 --> 00:08:22,569
an't right so this the things we want to

00:08:17,620 --> 00:08:25,210
improve so we can normalize our data

00:08:22,569 --> 00:08:28,930
instead of list of products we can keep

00:08:25,210 --> 00:08:31,599
products by its ID in an object and it

00:08:28,930 --> 00:08:35,349
will be immediate access the same we can

00:08:31,599 --> 00:08:38,860
do for categories also too if we need to

00:08:35,349 --> 00:08:42,940
keep the order of products we can keep

00:08:38,860 --> 00:08:45,420
the list of ID's to keep that order

00:08:42,940 --> 00:08:47,740
instead to have additional list with all

00:08:45,420 --> 00:08:51,190
objects the same we can do with

00:08:47,740 --> 00:08:52,450
scattegories let's take a look how our

00:08:51,190 --> 00:08:55,180
selectors they

00:08:52,450 --> 00:08:58,320
the selectors could look like four get

00:08:55,180 --> 00:09:00,370
product by D we just accessing our

00:08:58,320 --> 00:09:04,000
Kisuke of an object

00:09:00,370 --> 00:09:07,720
it's laning our time the same for

00:09:04,000 --> 00:09:11,800
categories and if we want to get

00:09:07,720 --> 00:09:13,030
categories by D be still have not the

00:09:11,800 --> 00:09:15,760
best solution yeah

00:09:13,030 --> 00:09:18,970
we're reducing the products by

00:09:15,760 --> 00:09:22,180
categories and so on that's a point we

00:09:18,970 --> 00:09:25,570
could improve even more and if you know

00:09:22,180 --> 00:09:30,250
about databases for fast searches we

00:09:25,570 --> 00:09:32,740
prepare indexes for search we can do

00:09:30,250 --> 00:09:36,670
pretty similar things with our data on

00:09:32,740 --> 00:09:40,930
client side so if we prepare the

00:09:36,670 --> 00:09:45,300
products IDs by category in some object

00:09:40,930 --> 00:09:49,330
we can have immediate access for it and

00:09:45,300 --> 00:09:52,120
after that we can easily get products by

00:09:49,330 --> 00:09:55,600
category just getting kills from the

00:09:52,120 --> 00:10:00,400
object and map it to and map product IDs

00:09:55,600 --> 00:10:03,240
to actual products and it will improve

00:10:00,400 --> 00:10:06,130
our time complexity to be linear one and

00:10:03,240 --> 00:10:08,080
I believe there are more and more

00:10:06,130 --> 00:10:12,520
different techniques to improve these

00:10:08,080 --> 00:10:16,360
things so how to use it in your code of

00:10:12,520 --> 00:10:19,690
course you can always do it yourself the

00:10:16,360 --> 00:10:22,900
code you could rely only it's only your

00:10:19,690 --> 00:10:25,270
code isn't it but they're a bunch of

00:10:22,900 --> 00:10:27,370
libraries for example for react you can

00:10:25,270 --> 00:10:31,860
use something like normally is roof for

00:10:27,370 --> 00:10:37,150
ng weeks you can use built in entity

00:10:31,860 --> 00:10:39,340
entity module and that's easy that's a

00:10:37,150 --> 00:10:42,130
very very important technique I want to

00:10:39,340 --> 00:10:45,520
speak about memorization memorization is

00:10:42,130 --> 00:10:49,120
the ability of some function to remember

00:10:45,520 --> 00:10:51,820
the results of previous calls sounds

00:10:49,120 --> 00:10:55,240
really easy well we can use it again

00:10:51,820 --> 00:10:58,780
when we work in this sons like redux and

00:10:55,240 --> 00:11:04,600
we return in completely new state on

00:10:58,780 --> 00:11:05,769
each state changes we can trigger the

00:11:04,600 --> 00:11:08,529
renders which

00:11:05,769 --> 00:11:11,559
Changez more often wear than they

00:11:08,529 --> 00:11:14,649
actually needed for examples we have

00:11:11,559 --> 00:11:18,220
some data selection that's really really

00:11:14,649 --> 00:11:21,040
deep in our store and if we change

00:11:18,220 --> 00:11:25,360
something different and that property we

00:11:21,040 --> 00:11:27,489
trigger changes on this subscription so

00:11:25,360 --> 00:11:30,279
for data selections we can use

00:11:27,489 --> 00:11:34,029
memorization for repeated commutations

00:11:30,279 --> 00:11:36,309
like you repeat some product

00:11:34,029 --> 00:11:40,239
I don't know hash or something like this

00:11:36,309 --> 00:11:43,989
you can catch this result if it computer

00:11:40,239 --> 00:11:47,259
CPU heavy computations and for derived

00:11:43,989 --> 00:11:50,799
data states as well the simplest example

00:11:47,259 --> 00:11:55,480
to explain normalization is Fibonacci

00:11:50,799 --> 00:11:58,269
numbers yeah we call them our function

00:11:55,480 --> 00:12:02,790
with recursive calls we optimize it with

00:11:58,269 --> 00:12:05,499
tail recursion and if we look on call 3

00:12:02,790 --> 00:12:08,889
these which arguments we call in our

00:12:05,499 --> 00:12:12,249
function we can see that we're repeating

00:12:08,889 --> 00:12:16,059
some computations all went over again

00:12:12,249 --> 00:12:23,619
and this is the work that we actually

00:12:16,059 --> 00:12:26,889
want to do again so to reduce recursive

00:12:23,619 --> 00:12:30,459
expensive calls we can use memorization

00:12:26,889 --> 00:12:32,259
and for frequently used data as well how

00:12:30,459 --> 00:12:35,350
it will look like for example with

00:12:32,259 --> 00:12:38,230
Fibonacci so we create another function

00:12:35,350 --> 00:12:41,679
that will return Fibonacci 1 and this

00:12:38,230 --> 00:12:44,019
function will contain some object for

00:12:41,679 --> 00:12:48,329
cashing results or it could be list

00:12:44,019 --> 00:12:51,730
actually in Fibonacci and if we already

00:12:48,329 --> 00:12:55,089
calculated the value for the past

00:12:51,730 --> 00:12:57,429
argument we just returning immediately

00:12:55,089 --> 00:13:01,749
value from the cache not computing

00:12:57,429 --> 00:13:05,110
anything again how we can use it of

00:13:01,749 --> 00:13:08,079
course we can do it ourselves every time

00:13:05,110 --> 00:13:10,899
but better solution to use some library

00:13:08,079 --> 00:13:14,649
like we select on them and the thing is

00:13:10,899 --> 00:13:18,910
that I show the some basic example of

00:13:14,649 --> 00:13:19,520
memorization but we have multi slotted

00:13:18,910 --> 00:13:21,920
memories

00:13:19,520 --> 00:13:26,830
Multi slaughtered and some libraries

00:13:21,920 --> 00:13:29,300
provide you a factory methods to create

00:13:26,830 --> 00:13:32,480
memorization customized for your needs

00:13:29,300 --> 00:13:38,030
so it's better to at least check those

00:13:32,480 --> 00:13:40,340
libraries and the next more interesting

00:13:38,030 --> 00:13:43,240
things that I want to show levenshtein

00:13:40,340 --> 00:13:49,700
distance algorithm and how to improve

00:13:43,240 --> 00:13:53,590
some user experience with it so what is

00:13:49,700 --> 00:13:57,440
levenshtein distance if the algorithm

00:13:53,590 --> 00:14:01,040
place how many edits you need to perform

00:13:57,440 --> 00:14:03,830
to create one string from another it

00:14:01,040 --> 00:14:08,440
calculates the number of edits number of

00:14:03,830 --> 00:14:12,400
changes and it could be easily

00:14:08,440 --> 00:14:15,260
introduced by Albert Livingston yes

00:14:12,400 --> 00:14:19,670
everyone trusted information in over

00:14:15,260 --> 00:14:23,960
Internet yes now it was a Vadim a

00:14:19,670 --> 00:14:28,220
Livingston mathematician that created

00:14:23,960 --> 00:14:32,390
this algorithm in 1965 we can represent

00:14:28,220 --> 00:14:35,300
the work of this a grid with the matrix

00:14:32,390 --> 00:14:37,910
and actually be aphelion matrices when

00:14:35,300 --> 00:14:41,180
we have executed it so we have two

00:14:37,910 --> 00:14:43,790
boards Honda and Hyundai and for each

00:14:41,180 --> 00:14:47,120
letter in this world starting from the

00:14:43,790 --> 00:14:49,670
first one we calculating do we need to

00:14:47,120 --> 00:14:53,060
change something in target three strings

00:14:49,670 --> 00:14:55,760
to get the first one and at the end we

00:14:53,060 --> 00:14:58,910
get the number total number of these

00:14:55,760 --> 00:15:01,660
changes so in this case it will be three

00:14:58,910 --> 00:15:06,610
and that means the distance between

00:15:01,660 --> 00:15:09,110
those two strings will be three and

00:15:06,610 --> 00:15:11,540
actually this algorithm out that

00:15:09,110 --> 00:15:17,240
complicated sounds like such a lines of

00:15:11,540 --> 00:15:19,850
code and the interesting story how I

00:15:17,240 --> 00:15:24,020
found this algorithm I was looking to

00:15:19,850 --> 00:15:27,620
some source code of angular UI and I've

00:15:24,020 --> 00:15:30,860
seen how they provide outer correction

00:15:27,620 --> 00:15:32,930
for comments so they have a list of

00:15:30,860 --> 00:15:33,350
comments and if you get a typo

00:15:32,930 --> 00:15:35,870
they

00:15:33,350 --> 00:15:38,900
suggest you and as a comment that

00:15:35,870 --> 00:15:41,050
probably you want to execute and for

00:15:38,900 --> 00:15:46,610
that they using levenshtein distance

00:15:41,050 --> 00:15:49,630
algorithm so when it oftenly used so two

00:15:46,610 --> 00:15:52,880
for after correction after completion or

00:15:49,630 --> 00:15:59,210
smart suggestions for example keyboards

00:15:52,880 --> 00:16:03,920
or Szalai tools or after correction in

00:15:59,210 --> 00:16:07,160
text editor and who's how to look like

00:16:03,920 --> 00:16:11,090
for example indeed if you try to call

00:16:07,160 --> 00:16:15,170
get claim instead clone it will suggest

00:16:11,090 --> 00:16:19,850
you that hey you might want to execute

00:16:15,170 --> 00:16:22,400
clone command and the example in angular

00:16:19,850 --> 00:16:25,370
sly where I found actually and treat

00:16:22,400 --> 00:16:29,300
about levenshtein distance algorithm so

00:16:25,370 --> 00:16:32,720
if I call to generate some component it

00:16:29,300 --> 00:16:35,960
suggest me generate comment and it's

00:16:32,720 --> 00:16:39,530
fast but let's try to use levenshtein

00:16:35,960 --> 00:16:44,360
distance algorithm to create smart for

00:16:39,530 --> 00:16:47,330
zero for pages and to prove our uux what

00:16:44,360 --> 00:16:51,410
is the problem this usual standard for

00:16:47,330 --> 00:16:54,830
zero for page we get a type of for

00:16:51,410 --> 00:16:57,710
example or link is already broken or was

00:16:54,830 --> 00:17:00,980
changed on back end and we hit an enter

00:16:57,710 --> 00:17:02,990
and we get some helpful you Ivy's

00:17:00,980 --> 00:17:05,360
kitties yes

00:17:02,990 --> 00:17:08,390
it's very useful we can watch for a

00:17:05,360 --> 00:17:12,160
while and completely forget what we want

00:17:08,390 --> 00:17:16,520
to do but that's it solve any problem

00:17:12,160 --> 00:17:22,310
probably not what we can do instead we

00:17:16,520 --> 00:17:23,210
can suggest you sir proper link here's a

00:17:22,310 --> 00:17:30,830
simple example

00:17:23,210 --> 00:17:33,410
I have an application oh it won't play

00:17:30,830 --> 00:17:37,340
the video ok I have an application just

00:17:33,410 --> 00:17:41,150
few links home about contacts yeah so

00:17:37,340 --> 00:17:43,610
let's make a typo for example hain and

00:17:41,150 --> 00:17:46,809
at the bottom of the page I have a

00:17:43,610 --> 00:17:49,870
suggestion for user sorry

00:17:46,809 --> 00:17:54,399
you probably made a typo did you mean

00:17:49,870 --> 00:18:00,610
about page or we can type contract in

00:17:54,399 --> 00:18:04,870
instead contact and we will be

00:18:00,610 --> 00:18:08,049
redirected to correct page so it's

00:18:04,870 --> 00:18:11,289
actually will solve problem for user it

00:18:08,049 --> 00:18:14,649
will have some value for them so why not

00:18:11,289 --> 00:18:17,320
to improve our 4:04 pages with this

00:18:14,649 --> 00:18:21,999
algorithm how we actually how it's

00:18:17,320 --> 00:18:24,789
working so usually we have some listing

00:18:21,999 --> 00:18:28,990
of all roads we have in our application

00:18:24,789 --> 00:18:32,799
we can gather them in some list then we

00:18:28,990 --> 00:18:37,240
can sort them by levenshtein distance

00:18:32,799 --> 00:18:41,110
will calculate it to user input so user

00:18:37,240 --> 00:18:44,409
meta title yeah came instead home then

00:18:41,110 --> 00:18:47,230
we have abolition of all possible roads

00:18:44,409 --> 00:18:50,619
and we sort them by Livingstone distance

00:18:47,230 --> 00:18:53,669
to Haines and probably the first one

00:18:50,619 --> 00:18:56,619
will be the correct one in our case home

00:18:53,669 --> 00:18:59,730
so we can return this value to the user

00:18:56,619 --> 00:19:03,610
and create a link to the correct page

00:18:59,730 --> 00:19:08,139
how it looks like in code for example

00:19:03,610 --> 00:19:14,710
for this demo I have home about contact

00:19:08,139 --> 00:19:18,940
is just some hash map with strings of

00:19:14,710 --> 00:19:20,889
passable roads then I have a surgeon so

00:19:18,940 --> 00:19:23,649
I have a type of path and I have

00:19:20,889 --> 00:19:27,999
dictionaries that I prepared that's all

00:19:23,649 --> 00:19:30,549
the possible paths in my Rochin and then

00:19:27,999 --> 00:19:36,159
I sort in it using levenshtein distance

00:19:30,549 --> 00:19:38,470
al green but to prevent calls of that I

00:19:36,159 --> 00:19:42,820
already did computations that I did for

00:19:38,470 --> 00:19:45,869
already did I question them so if there

00:19:42,820 --> 00:19:49,119
is no computed value in cash i

00:19:45,869 --> 00:19:53,049
recalculate it otherwise i just return

00:19:49,119 --> 00:19:58,179
the difference and the last step we take

00:19:53,049 --> 00:20:00,310
in our pass with half our rows and I

00:19:58,179 --> 00:20:03,990
also introduce some threshold for

00:20:00,310 --> 00:20:08,070
if the levenshtein distance is too big

00:20:03,990 --> 00:20:13,770
it's probably completely different word

00:20:08,070 --> 00:20:16,210
so I have a threshold and if it is our

00:20:13,770 --> 00:20:19,630
suggested value is below this threshold

00:20:16,210 --> 00:20:21,160
I just return nothing just standard

00:20:19,630 --> 00:20:23,500
kittens or something

00:20:21,160 --> 00:20:27,580
otherwise I will return the first item

00:20:23,500 --> 00:20:30,700
that's the most closed world and this

00:20:27,580 --> 00:20:34,150
thing shows us that we can use something

00:20:30,700 --> 00:20:38,920
like our grids and apply it to some

00:20:34,150 --> 00:20:42,280
unexpected user cases to create some

00:20:38,920 --> 00:20:44,440
value for the end users that's also the

00:20:42,280 --> 00:20:47,770
case why you should actually care about

00:20:44,440 --> 00:20:53,530
our greens why they're great why they're

00:20:47,770 --> 00:20:56,350
cool so I want you to come home and just

00:20:53,530 --> 00:20:58,840
try to find some interesting problem and

00:20:56,350 --> 00:21:02,520
find some algorithms to solve this or

00:20:58,840 --> 00:21:06,040
maybe create your own solution for that

00:21:02,520 --> 00:21:08,800
reinvent it and maybe in a few years who

00:21:06,040 --> 00:21:12,850
knows we will use your alga algorithm to

00:21:08,800 --> 00:21:13,930
solve our UI problems that's all that I

00:21:12,850 --> 00:21:16,870
have for today

00:21:13,930 --> 00:21:29,080
thank you very much and do your auguries

00:21:16,870 --> 00:21:29,080

YouTube URL: https://www.youtube.com/watch?v=5JsQ7mvUeSU


