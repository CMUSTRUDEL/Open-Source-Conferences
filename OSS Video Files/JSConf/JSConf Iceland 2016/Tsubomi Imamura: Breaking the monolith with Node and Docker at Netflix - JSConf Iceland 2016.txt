Title: Tsubomi Imamura: Breaking the monolith with Node and Docker at Netflix - JSConf Iceland 2016
Publication date: 2016-09-16
Playlist: JSConf Iceland 2016
Description: 
	At Netflix, we run Node servers at scale for our website, TV and mobile devicesâ€™ UI data API services. In this talk, I will share our journey of how we migrated from data API service monolith to well isolated micro services running in Node Docker containers. Using Docker containers and tooling infrastructure, we provide a Node.js platform as a service, making debugging, testing and deployment easy to perform. Every software releases can be consistently reproduced across the stack. UI engineers can focus on developing core business logic to be more productive.
Captions: 
	00:00:11,390 --> 00:00:21,290
hi how is everybody I'm glad everybody

00:00:16,550 --> 00:00:23,119
knows Netflix so I'm to Bobby imamura

00:00:21,290 --> 00:00:26,390
senior software engineer from netflix

00:00:23,119 --> 00:00:28,970
today I'm gonna share our journey how we

00:00:26,390 --> 00:00:32,000
migrated from you I data API Mona less

00:00:28,970 --> 00:00:37,400
to well isolated microservice in nodejs

00:00:32,000 --> 00:00:39,730
darker cantina so why did we have a UI

00:00:37,400 --> 00:00:42,890
data API model is from the first place

00:00:39,730 --> 00:00:44,840
to understand that let me start by show

00:00:42,890 --> 00:00:47,449
some business background about our

00:00:44,840 --> 00:00:49,550
company you probably already knew we are

00:00:47,449 --> 00:00:51,649
video streaming company what you might

00:00:49,550 --> 00:00:54,320
not know is we have over 80 million

00:00:51,649 --> 00:00:58,190
subscribers worldwide we stream our

00:00:54,320 --> 00:01:01,160
content more than 125 million hours per

00:00:58,190 --> 00:01:04,940
day so that stuns a lot of traffic to

00:01:01,160 --> 00:01:06,790
manage now user can view our content

00:01:04,940 --> 00:01:09,590
from hundreds of different color device

00:01:06,790 --> 00:01:12,830
each device has its own performance

00:01:09,590 --> 00:01:15,050
characteristic and form factor so we

00:01:12,830 --> 00:01:18,740
need very different kind of data to

00:01:15,050 --> 00:01:21,920
render each you I screen now the

00:01:18,740 --> 00:01:27,920
question is how do we fetch the internal

00:01:21,920 --> 00:01:32,329
paula deta to render it GUI in the past

00:01:27,920 --> 00:01:34,700
we built a java data API server that

00:01:32,329 --> 00:01:37,250
will have exposed all the internal power

00:01:34,700 --> 00:01:40,520
service and we will have all different

00:01:37,250 --> 00:01:43,159
kind of rest endpoint here so our your

00:01:40,520 --> 00:01:45,860
client can make multiple requests to

00:01:43,159 --> 00:01:49,159
this comment java api similar to fetch

00:01:45,860 --> 00:01:51,649
the internal holiday dough but there's a

00:01:49,159 --> 00:01:53,479
problem here most of us are you our

00:01:51,649 --> 00:01:56,960
developer here we all know orchestrate

00:01:53,479 --> 00:01:58,850
multiple rest api request is cuba's am

00:01:56,960 --> 00:02:02,360
and not performing from the client

00:01:58,850 --> 00:02:04,399
device so we improve our Comment our API

00:02:02,360 --> 00:02:08,330
server you will take the responsibility

00:02:04,399 --> 00:02:13,160
to orchestrate and fail the request to

00:02:08,330 --> 00:02:15,560
our internal potter service now our

00:02:13,160 --> 00:02:18,260
client device has full control of the

00:02:15,560 --> 00:02:20,269
request response cycle we can just make

00:02:18,260 --> 00:02:23,330
a word request to fudge the internal

00:02:20,269 --> 00:02:32,630
pallador back that's awesome

00:02:23,330 --> 00:02:37,100
oh oops did I skip so however the data

00:02:32,630 --> 00:02:39,920
returned is in generic format it's a

00:02:37,100 --> 00:02:42,830
one-size-fits-all device so that music

00:02:39,920 --> 00:02:44,960
means every device will fetch data that

00:02:42,830 --> 00:02:47,930
has some puddle and belong to render its

00:02:44,960 --> 00:02:57,230
screen you also need to pass it that's

00:02:47,930 --> 00:02:59,300
not very efficient so we decide to let

00:02:57,230 --> 00:03:02,110
our UI developer to write new idea

00:02:59,300 --> 00:03:04,640
endpoints crib inside this Java server

00:03:02,110 --> 00:03:07,700
so inside this you are data endpoints

00:03:04,640 --> 00:03:09,800
crib that we can write business logic to

00:03:07,700 --> 00:03:13,610
transform the internal pollinator to the

00:03:09,800 --> 00:03:15,890
format that fits individual device now

00:03:13,610 --> 00:03:18,130
UI developer has full control of the

00:03:15,890 --> 00:03:21,080
data returned back to the client and

00:03:18,130 --> 00:03:23,840
also all your developer doesn't like to

00:03:21,080 --> 00:03:26,180
write type the language like Java so we

00:03:23,840 --> 00:03:28,100
let them right groovy script for this

00:03:26,180 --> 00:03:29,930
endpoints cliff and we can upload the

00:03:28,100 --> 00:03:35,269
Google script to a host of java 7 wrong

00:03:29,930 --> 00:03:38,959
time and compile there now the benefit

00:03:35,269 --> 00:03:41,450
of having this architecture is we get a

00:03:38,959 --> 00:03:43,550
service infrastructure oh you are

00:03:41,450 --> 00:03:45,920
developer that I have to write a server

00:03:43,550 --> 00:03:50,180
or managing the server wrong time in

00:03:45,920 --> 00:03:52,040
production and we have good operational

00:03:50,180 --> 00:03:54,830
insight already building without Java

00:03:52,040 --> 00:03:56,930
server so UI developer has good

00:03:54,830 --> 00:04:01,580
visibility into the data endpoint script

00:03:56,930 --> 00:04:03,680
d right and we have a dedicated packin

00:04:01,580 --> 00:04:06,530
team they were managing the server

00:04:03,680 --> 00:04:11,870
dependency for example conquered or

00:04:06,530 --> 00:04:15,080
groovy version and all our i-team has a

00:04:11,870 --> 00:04:16,850
consistent development workflow they

00:04:15,080 --> 00:04:19,669
have the same script to upload their

00:04:16,850 --> 00:04:22,250
goofy square and we have an atomic

00:04:19,669 --> 00:04:24,380
deployment workflow because all the data

00:04:22,250 --> 00:04:28,300
in points crib are deployed together

00:04:24,380 --> 00:04:31,669
with just our server so it's awesome

00:04:28,300 --> 00:04:34,090
however over the time we realize there's

00:04:31,669 --> 00:04:37,560
a problem with this architecture our

00:04:34,090 --> 00:04:40,390
developer workflow is inefficient

00:04:37,560 --> 00:04:41,950
during implementation cycle we need to

00:04:40,390 --> 00:04:46,920
constantly contact switch between

00:04:41,950 --> 00:04:50,590
JavaScript and groovy script and also

00:04:46,920 --> 00:04:52,780
when we do in code iteration we need to

00:04:50,590 --> 00:04:55,810
upload the groovy script to a hosted

00:04:52,780 --> 00:04:58,210
testing environment each upload takes

00:04:55,810 --> 00:05:01,270
two to three minutes or maybe you are

00:04:58,210 --> 00:05:04,090
longer we have 200 you I developers

00:05:01,270 --> 00:05:06,730
every one of them does this 20 to 30

00:05:04,090 --> 00:05:09,330
times a day this workflow really slows

00:05:06,730 --> 00:05:14,560
down our developer and add low pressure

00:05:09,330 --> 00:05:17,410
to our testing server an even worse we

00:05:14,560 --> 00:05:19,540
have very limited visibility into the

00:05:17,410 --> 00:05:21,490
testing server environment the only way

00:05:19,540 --> 00:05:24,610
to see anything is the traditional

00:05:21,490 --> 00:05:28,960
printing annotation so you can see our

00:05:24,610 --> 00:05:30,880
developers in here now and also it's

00:05:28,960 --> 00:05:32,590
very difficult to reproduce a production

00:05:30,880 --> 00:05:34,600
problem inside the local machine to

00:05:32,590 --> 00:05:39,610
debug because we don't have a server

00:05:34,600 --> 00:05:41,560
setup from the first place and even

00:05:39,610 --> 00:05:44,440
worse we figure out that we have

00:05:41,560 --> 00:05:48,550
long-term issue here the problem is

00:05:44,440 --> 00:05:51,970
inside data endpoint square we have 1000

00:05:48,550 --> 00:05:54,910
10 points crib and hundreds of update

00:05:51,970 --> 00:05:57,400
every day all this crap are running

00:05:54,910 --> 00:06:00,580
inside the Java server without isolation

00:05:57,400 --> 00:06:02,950
a bug inside one set of data endpoints

00:06:00,580 --> 00:06:09,160
crib could bring down entire you are

00:06:02,950 --> 00:06:11,650
data API fleet now if one set of data if

00:06:09,160 --> 00:06:14,230
you ask web is taking too much cpu or

00:06:11,650 --> 00:06:17,380
memory you will stop all the other you

00:06:14,230 --> 00:06:22,210
are data API web so we can scale them

00:06:17,380 --> 00:06:24,580
independently and also it's difficult to

00:06:22,210 --> 00:06:26,800
identify which data import script is

00:06:24,580 --> 00:06:28,750
taking that much resource because all

00:06:26,800 --> 00:06:33,310
the operational metrics is combined as

00:06:28,750 --> 00:06:35,830
even worse now it's also complex to

00:06:33,310 --> 00:06:38,380
offer research platform we need to load

00:06:35,830 --> 00:06:40,690
it runs on the API into memory compile

00:06:38,380 --> 00:06:43,870
and warm them before we can start to

00:06:40,690 --> 00:06:46,720
serve production traffic so the server

00:06:43,870 --> 00:06:49,300
style time takes 15 minutes we can't

00:06:46,720 --> 00:06:50,240
scale our server fast enough to handle

00:06:49,300 --> 00:06:53,060
the large trafficking

00:06:50,240 --> 00:06:57,710
crees you feel the eternity when you try

00:06:53,060 --> 00:06:59,599
to start up your server and also we have

00:06:57,710 --> 00:07:02,090
hundreds of different kind of scrip they

00:06:59,599 --> 00:07:05,360
are all loaded inside the memory now

00:07:02,090 --> 00:07:09,530
even the largest amazon instance can run

00:07:05,360 --> 00:07:12,410
such server and at this point you can

00:07:09,530 --> 00:07:14,389
see all you advice need to make requests

00:07:12,410 --> 00:07:16,910
through this java data API server to

00:07:14,389 --> 00:07:20,690
fetch internal parody de so this server

00:07:16,910 --> 00:07:23,840
is a mano less and also it's critical if

00:07:20,690 --> 00:07:26,090
this server goes down the UI give us can

00:07:23,840 --> 00:07:30,620
search any data which means you can

00:07:26,090 --> 00:07:33,349
watch your video that's a bummer so it's

00:07:30,620 --> 00:07:38,960
important that we make this you are data

00:07:33,349 --> 00:07:40,639
API server resilient and performing now

00:07:38,960 --> 00:07:45,740
at this point we know the pro and cons

00:07:40,639 --> 00:07:48,110
of our monolithic data API server we

00:07:45,740 --> 00:07:50,240
want to decouple our UI data endpoint

00:07:48,110 --> 00:07:53,539
scrip from this monolithic a server and

00:07:50,240 --> 00:07:56,090
make a resilient we clock feedback from

00:07:53,539 --> 00:07:58,639
our different UI team and to see what's

00:07:56,090 --> 00:08:01,490
their ideal next generation you I did if

00:07:58,639 --> 00:08:04,009
you have loved one our developer want to

00:08:01,490 --> 00:08:06,919
continue have the benefit as we had in

00:08:04,009 --> 00:08:11,150
the old architecture however they want

00:08:06,919 --> 00:08:13,400
to fix the issue that you have let's see

00:08:11,150 --> 00:08:18,080
what's our developers ideal development

00:08:13,400 --> 00:08:20,690
workflow we want to continue

00:08:18,080 --> 00:08:22,729
half-civilized infrastructure our UI

00:08:20,690 --> 00:08:25,639
developer doesn't want to implement

00:08:22,729 --> 00:08:27,830
server or configure the server we want

00:08:25,639 --> 00:08:31,639
to continue have easy environment setup

00:08:27,830 --> 00:08:35,000
on the top of that we don't want to

00:08:31,639 --> 00:08:37,120
contact switch anymore and we wanted to

00:08:35,000 --> 00:08:39,680
have our code reflecting to the server

00:08:37,120 --> 00:08:41,240
instantaneously because we are impatient

00:08:39,680 --> 00:08:45,680
we just want to relo and have things

00:08:41,240 --> 00:08:49,820
happen and we want to run a local server

00:08:45,680 --> 00:08:52,279
so we can attach a debug onto it we want

00:08:49,820 --> 00:08:54,410
to reproduce a production code inside

00:08:52,279 --> 00:08:58,579
developed local machine precisely to

00:08:54,410 --> 00:09:02,630
debug problem now let's see what our

00:08:58,579 --> 00:09:03,950
production go we like the operational

00:09:02,630 --> 00:09:07,730
visibility into our you

00:09:03,950 --> 00:09:10,010
api server and our java server has

00:09:07,730 --> 00:09:13,010
already integrate with our netflix

00:09:10,010 --> 00:09:15,460
existing infrastructure for example or

00:09:13,010 --> 00:09:17,990
personal dashboard a loading system

00:09:15,460 --> 00:09:19,610
discovered crime so that's a nice

00:09:17,990 --> 00:09:23,150
feature we want to continue have that

00:09:19,610 --> 00:09:27,140
and we want to have countable deployment

00:09:23,150 --> 00:09:30,770
workflow so what's on top of it is we

00:09:27,140 --> 00:09:32,870
want to get wrong time isolation and we

00:09:30,770 --> 00:09:36,800
want to scale different kind of data API

00:09:32,870 --> 00:09:39,350
service independently for example our TV

00:09:36,800 --> 00:09:41,180
you are team has long tail device some

00:09:39,350 --> 00:09:43,820
old version of data if your service

00:09:41,180 --> 00:09:46,460
monthly just need one server to handle

00:09:43,820 --> 00:09:50,240
the traffic however the latest version

00:09:46,460 --> 00:09:54,410
might need a lot of machines so how do

00:09:50,240 --> 00:09:57,920
we achieve all these goals here's our

00:09:54,410 --> 00:10:01,970
solution run no geoserver inside docker

00:09:57,920 --> 00:10:04,370
container javascript is a language or UI

00:10:01,970 --> 00:10:06,320
developer a familiar with so normal

00:10:04,370 --> 00:10:09,560
context switch between JavaScript and

00:10:06,320 --> 00:10:13,160
groovy script and using dunkle continued

00:10:09,560 --> 00:10:15,650
we got process isolation to reproduce a

00:10:13,160 --> 00:10:17,300
version of server become easy just

00:10:15,650 --> 00:10:20,660
viewed a version of server code as a

00:10:17,300 --> 00:10:25,700
docker image and deploy anywhere now

00:10:20,660 --> 00:10:27,710
also style of time become fast now at

00:10:25,700 --> 00:10:30,470
this point we got an empty darker

00:10:27,710 --> 00:10:33,260
container how do we build our new server

00:10:30,470 --> 00:10:35,630
has the same feature parity as we had in

00:10:33,260 --> 00:10:37,670
our Java server we know we wanted to

00:10:35,630 --> 00:10:39,650
have operational visibility an

00:10:37,670 --> 00:10:43,190
integration with existing there for the

00:10:39,650 --> 00:10:44,780
netflix infrastructure however all UI

00:10:43,190 --> 00:10:47,360
developer wants to have civil

00:10:44,780 --> 00:10:49,550
infrastructure they are great fry and

00:10:47,360 --> 00:10:51,380
developer but they might not have

00:10:49,550 --> 00:10:54,770
specific knowledge about building a

00:10:51,380 --> 00:10:56,660
server we obviously don't want to put

00:10:54,770 --> 00:11:00,800
the burden to have them write a node.js

00:10:56,660 --> 00:11:03,110
server startup code like this to fill in

00:11:00,800 --> 00:11:06,260
the gap here we decided to view the

00:11:03,110 --> 00:11:08,780
common know Gia's platform so we will

00:11:06,260 --> 00:11:11,440
write comment suicide the code in this

00:11:08,780 --> 00:11:14,480
problem for example server startup

00:11:11,440 --> 00:11:18,490
location error handling matrix

00:11:14,480 --> 00:11:21,050
population and this load balancing

00:11:18,490 --> 00:11:22,940
so all your developer can focus on

00:11:21,050 --> 00:11:27,080
implementing business logic without

00:11:22,940 --> 00:11:30,140
worry about silverside concern now let's

00:11:27,080 --> 00:11:32,030
see how we view this nodejs platform we

00:11:30,140 --> 00:11:35,090
use verse 5 framework to build our own

00:11:32,030 --> 00:11:38,120
OTA server response already building

00:11:35,090 --> 00:11:41,150
with operational matrix so it has good

00:11:38,120 --> 00:11:43,630
debug ability we have been used

00:11:41,150 --> 00:11:48,130
ratifying our website for a couple years

00:11:43,630 --> 00:11:51,260
so it's well tested in production and

00:11:48,130 --> 00:11:56,810
also it's one of the fastest no Jerry

00:11:51,260 --> 00:11:59,390
server it's lightweight its specific

00:11:56,810 --> 00:12:03,620
phobia dressed API service so we only

00:11:59,390 --> 00:12:05,450
need a minimum set of dependency now

00:12:03,620 --> 00:12:08,540
let's see how will allow you our

00:12:05,450 --> 00:12:10,820
developer to create server out we use

00:12:08,540 --> 00:12:12,490
red fire in raw module to let our

00:12:10,820 --> 00:12:16,640
developer to create some around

00:12:12,490 --> 00:12:18,530
declaratively in JSON format this way

00:12:16,640 --> 00:12:21,080
our UI developer doesn't have to know

00:12:18,530 --> 00:12:24,710
response pacifica a p.i and you make

00:12:21,080 --> 00:12:26,570
rotation easy and also this role

00:12:24,710 --> 00:12:29,210
configuration file become a single place

00:12:26,570 --> 00:12:32,390
where we can find out what kind of API

00:12:29,210 --> 00:12:37,100
is inside our no GL server it can

00:12:32,390 --> 00:12:40,670
prevent real collision this is an

00:12:37,100 --> 00:12:43,820
example of the role configuration you

00:12:40,670 --> 00:12:46,490
can see search is the route past get is

00:12:43,820 --> 00:12:50,240
the raw method the value of source is

00:12:46,490 --> 00:12:53,540
the entry point square now what is the

00:12:50,240 --> 00:12:56,480
entry point square by yourself this is a

00:12:53,540 --> 00:12:58,310
pseudocode for our search service we

00:12:56,480 --> 00:13:01,270
will write business logic to fetch

00:12:58,310 --> 00:13:04,100
search data and transform the data to

00:13:01,270 --> 00:13:06,950
individual device format in this

00:13:04,100 --> 00:13:09,350
middleware function now what's important

00:13:06,950 --> 00:13:11,120
here is we will export this middleware

00:13:09,350 --> 00:13:13,880
function here in the entry point scrip

00:13:11,120 --> 00:13:18,230
this is the contract between the usual

00:13:13,880 --> 00:13:19,910
encode and plop the platform now I just

00:13:18,230 --> 00:13:23,090
mentioned something called connect style

00:13:19,910 --> 00:13:25,760
middleware function what is that in no

00:13:23,090 --> 00:13:28,340
geoserver we use a middleware function

00:13:25,760 --> 00:13:30,680
or an array of middleware function to

00:13:28,340 --> 00:13:33,050
handle a request

00:13:30,680 --> 00:13:35,330
the middle function will take input of

00:13:33,050 --> 00:13:38,240
request response after and next call

00:13:35,330 --> 00:13:40,430
back in the end of the function we will

00:13:38,240 --> 00:13:43,970
invoke the next call back to change to

00:13:40,430 --> 00:13:45,589
the next request handler now in most of

00:13:43,970 --> 00:13:47,720
the case we will have very complicated

00:13:45,589 --> 00:13:49,520
business logic so we will export an

00:13:47,720 --> 00:13:52,370
array of middleware function in the

00:13:49,520 --> 00:13:54,110
entry points clip the platform going to

00:13:52,370 --> 00:13:57,649
take this middle functional ray a

00:13:54,110 --> 00:13:59,810
injecting to ratify server by doing so

00:13:57,649 --> 00:14:01,459
our UI developer can focus on

00:13:59,810 --> 00:14:03,410
implementing business logic and the

00:14:01,459 --> 00:14:08,779
platform will take care of server-side

00:14:03,410 --> 00:14:13,100
bootstrap code now how does our platform

00:14:08,779 --> 00:14:15,140
publish matrix we use verse by audio

00:14:13,100 --> 00:14:18,860
longer plugging to publish matrix into

00:14:15,140 --> 00:14:21,290
server log this whole bunch of texts are

00:14:18,860 --> 00:14:23,390
requests log so what's important here is

00:14:21,290 --> 00:14:25,790
you can see in a bottom of the screen

00:14:23,390 --> 00:14:28,550
that read texts a unique request ID and

00:14:25,790 --> 00:14:31,339
we also publish request header so these

00:14:28,550 --> 00:14:34,160
are information we can use for debug and

00:14:31,339 --> 00:14:36,440
most importantly will measure request

00:14:34,160 --> 00:14:39,080
latency for each middleware handler now

00:14:36,440 --> 00:14:42,230
we can easily find out where our server

00:14:39,080 --> 00:14:43,700
is spending time at this actually is a

00:14:42,230 --> 00:14:46,970
production of class has performance

00:14:43,700 --> 00:14:48,650
issue I can easily find out the rest I

00:14:46,970 --> 00:14:51,410
walk around handle is the one take the

00:14:48,650 --> 00:14:55,970
longest time so I can be very targeted

00:14:51,410 --> 00:15:00,260
to keep up my performance issue here we

00:14:55,970 --> 00:15:01,940
also want our server to be resilient so

00:15:00,260 --> 00:15:05,360
the platform will handle common system

00:15:01,940 --> 00:15:07,790
level error for example if our upstream

00:15:05,360 --> 00:15:11,900
server is doing a deployment we might

00:15:07,790 --> 00:15:13,279
get a network error so the platform will

00:15:11,900 --> 00:15:17,000
retry our network error using

00:15:13,279 --> 00:15:20,300
exponential back-off algorithm we also

00:15:17,000 --> 00:15:22,400
use res file requests expiry plugging to

00:15:20,300 --> 00:15:25,700
time our requests when the clients no

00:15:22,400 --> 00:15:28,850
longer interesting while request expiry

00:15:25,700 --> 00:15:34,310
is important it can improve the server

00:15:28,850 --> 00:15:36,620
performance now in some case our service

00:15:34,310 --> 00:15:38,510
can get d dust the event queue will be

00:15:36,620 --> 00:15:41,029
filled in with a lot of requests that

00:15:38,510 --> 00:15:42,709
nobody is carrying about so using the

00:15:41,029 --> 00:15:44,120
request expiry flogging we can quickly

00:15:42,709 --> 00:15:46,339
discard those

00:15:44,120 --> 00:15:49,880
active event and starting to serve

00:15:46,339 --> 00:15:53,060
active request a young another scenario

00:15:49,880 --> 00:15:55,550
I'll upstream server can have long

00:15:53,060 --> 00:15:57,710
latency when a data come back to our

00:15:55,550 --> 00:16:00,080
note a server the client has already

00:15:57,710 --> 00:16:03,110
turned out so we don't want to waste

00:16:00,080 --> 00:16:06,230
extra CPU cycle to parse and render the

00:16:03,110 --> 00:16:08,390
data and send it back to the client so

00:16:06,230 --> 00:16:13,700
the platform works also kill the middle

00:16:08,390 --> 00:16:16,880
we're here now we can easily stand up

00:16:13,700 --> 00:16:20,810
the data API service using on top of the

00:16:16,880 --> 00:16:22,790
node.js platform the next step is we

00:16:20,810 --> 00:16:24,650
want to be the tooling to make it easy

00:16:22,790 --> 00:16:26,510
for our UI developer to set their

00:16:24,650 --> 00:16:31,520
environment I have a consistent

00:16:26,510 --> 00:16:33,980
development workflow we have introduced

00:16:31,520 --> 00:16:36,290
darker into this workflow it's a new

00:16:33,980 --> 00:16:39,589
technology that can add learning curve

00:16:36,290 --> 00:16:42,589
and most of our developer are used mac

00:16:39,589 --> 00:16:45,020
or windows as their development Shing so

00:16:42,589 --> 00:16:48,230
they need the VirtualBox to run local

00:16:45,020 --> 00:16:51,500
docker container that can add network

00:16:48,230 --> 00:16:53,450
complexity so if all this our developer

00:16:51,500 --> 00:16:56,270
wants to manually install into their

00:16:53,450 --> 00:17:00,200
local dev box that can take a day or two

00:16:56,270 --> 00:17:02,240
this is a too painful that's why we

00:17:00,200 --> 00:17:05,089
decided to build tooling to streamline

00:17:02,240 --> 00:17:07,699
our developers workflow the tooling will

00:17:05,089 --> 00:17:10,760
encapsulate darker complexity and make

00:17:07,699 --> 00:17:14,260
it easy to install build deploy a docker

00:17:10,760 --> 00:17:17,179
container now this is a common workflow

00:17:14,260 --> 00:17:19,819
for mac OS users starting to work with

00:17:17,179 --> 00:17:23,510
our newest aqua container platform we

00:17:19,819 --> 00:17:26,240
only need is full step first is set up

00:17:23,510 --> 00:17:29,450
it's obvious we install the darker

00:17:26,240 --> 00:17:33,500
VirtualBox node npn another related

00:17:29,450 --> 00:17:36,110
software into developing local box he

00:17:33,500 --> 00:17:40,400
will set up the darker server to work

00:17:36,110 --> 00:17:43,070
with internal dhaka registry next up we

00:17:40,400 --> 00:17:46,190
will generate a simple call repo using

00:17:43,070 --> 00:17:48,380
human generator now even you develop on

00:17:46,190 --> 00:17:51,050
board they can quickly start off with

00:17:48,380 --> 00:17:54,380
their endpoint script just by changing a

00:17:51,050 --> 00:17:56,929
working sample and a lot of time after

00:17:54,380 --> 00:17:57,770
we build our code it might take a long

00:17:56,929 --> 00:18:00,620
time for us

00:17:57,770 --> 00:18:02,780
the cic d pipeline to push the code to

00:18:00,620 --> 00:18:05,210
test our products are men so in this

00:18:02,780 --> 00:18:08,270
initialization step our tooling will

00:18:05,210 --> 00:18:12,290
create a cic d pipeline for our

00:18:08,270 --> 00:18:15,740
developer now well we're ready to test

00:18:12,290 --> 00:18:18,200
we can build a local image the tooling

00:18:15,740 --> 00:18:20,420
will handle nesting of darker image you

00:18:18,200 --> 00:18:22,970
will pull the node.js platform image

00:18:20,420 --> 00:18:27,080
from internal dhaka registry and build a

00:18:22,970 --> 00:18:29,390
data API server image on top of it the

00:18:27,080 --> 00:18:32,750
final step is to employ a continued

00:18:29,390 --> 00:18:34,580
locally a tooling will start an ode to

00:18:32,750 --> 00:18:37,460
node.js server running inside the docker

00:18:34,580 --> 00:18:40,360
container and create by man between the

00:18:37,460 --> 00:18:43,570
host a pre-poll into the darker Cantina

00:18:40,360 --> 00:18:47,090
now I just said something about by month

00:18:43,570 --> 00:18:49,640
what is it it's a filesystem mounting

00:18:47,090 --> 00:18:53,680
between hosts file system and the log

00:18:49,640 --> 00:18:56,570
taco container why do we need it

00:18:53,680 --> 00:18:58,850
remember our developer wants to have

00:18:56,570 --> 00:19:00,680
fast code iteration they want to have

00:18:58,850 --> 00:19:03,920
their code reflecting side the server

00:19:00,680 --> 00:19:07,130
instantaneously however a docker image

00:19:03,920 --> 00:19:08,900
is immutable we don't want to review a

00:19:07,130 --> 00:19:13,480
new image every time when people change

00:19:08,900 --> 00:19:17,840
code so using this by mom we can achieve

00:19:13,480 --> 00:19:20,620
the code change instantaneously the

00:19:17,840 --> 00:19:23,210
tooling will watch the file system and

00:19:20,620 --> 00:19:24,830
the change can be reflecting side the

00:19:23,210 --> 00:19:28,310
docker container and server is restarted

00:19:24,830 --> 00:19:30,170
now a change can be reflect in a couple

00:19:28,310 --> 00:19:34,490
second in compared to previously a

00:19:30,170 --> 00:19:36,740
couple minutes and remember we need to

00:19:34,490 --> 00:19:39,470
support hundreds of different device a

00:19:36,740 --> 00:19:42,910
UI developer needs to test from

00:19:39,470 --> 00:19:45,260
different device to their local data API

00:19:42,910 --> 00:19:47,240
so it's complicated to set up the

00:19:45,260 --> 00:19:50,690
network for their local development

00:19:47,240 --> 00:19:53,450
lemon and the tooling take care of that

00:19:50,690 --> 00:19:55,700
it will make our local data API server

00:19:53,450 --> 00:19:59,690
discoverable by a common routing gateway

00:19:55,700 --> 00:20:01,580
now our developer can test their local

00:19:59,690 --> 00:20:03,610
data API from any device with an

00:20:01,580 --> 00:20:03,610
internet

00:20:05,970 --> 00:20:10,860
now how do we get a better debugging

00:20:08,130 --> 00:20:12,930
method now since we have a local server

00:20:10,860 --> 00:20:15,270
running the tooling world set up port

00:20:12,930 --> 00:20:18,420
forwarding on VirtualBox a gyro the

00:20:15,270 --> 00:20:19,950
remote debugging now developer can

00:20:18,420 --> 00:20:22,740
choose their favorite debugger to

00:20:19,950 --> 00:20:25,590
install no inspector and use our

00:20:22,740 --> 00:20:28,440
favorite chrome dev tool to debug server

00:20:25,590 --> 00:20:30,090
side issue as well our developer no

00:20:28,440 --> 00:20:32,040
longer needs to write console the log

00:20:30,090 --> 00:20:38,070
over the place inside their code and

00:20:32,040 --> 00:20:39,840
stirring a testing server now we have a

00:20:38,070 --> 00:20:43,130
very efficient developer workflow now

00:20:39,840 --> 00:20:46,410
how do we solve our production problem

00:20:43,130 --> 00:20:48,990
remember we have we need to achieve

00:20:46,410 --> 00:20:52,940
long-term isolation and skill different

00:20:48,990 --> 00:20:52,940
kind of data API service independently

00:20:53,360 --> 00:20:58,650
in the old architecture or our you are

00:20:56,580 --> 00:21:02,160
data API service is running inside the

00:20:58,650 --> 00:21:04,520
same java more no less we want to

00:21:02,160 --> 00:21:08,700
decouple them out from the Java server

00:21:04,520 --> 00:21:11,900
each logical set of data endpoint script

00:21:08,700 --> 00:21:14,520
is running inside at all no Jade server

00:21:11,900 --> 00:21:17,130
by doing so we can scale them

00:21:14,520 --> 00:21:20,090
independently and monitor their

00:21:17,130 --> 00:21:22,170
operational matrix separately and also

00:21:20,090 --> 00:21:24,570
because the Iranians are different

00:21:22,170 --> 00:21:26,610
node.js server a bug inside one set of

00:21:24,570 --> 00:21:30,210
data API service wouldn't affect the

00:21:26,610 --> 00:21:32,760
other when a client make a request to

00:21:30,210 --> 00:21:34,710
the no geoserver the node.js server will

00:21:32,760 --> 00:21:36,930
make another request to a remote service

00:21:34,710 --> 00:21:43,080
layer which has all the internal prodded

00:21:36,930 --> 00:21:45,120
atta exposed there this June we have

00:21:43,080 --> 00:21:47,250
viewed a search service using this new

00:21:45,120 --> 00:21:50,280
architecture and integrating to our

00:21:47,250 --> 00:21:53,670
website we are ready to test it in

00:21:50,280 --> 00:21:56,100
production when the production coming to

00:21:53,670 --> 00:21:59,970
mind our developers immediate reaction

00:21:56,100 --> 00:22:03,650
is what happen if I'm on call how do I

00:21:59,970 --> 00:22:06,660
debug a production issue that's critical

00:22:03,650 --> 00:22:10,020
we don't want our UI developer to worry

00:22:06,660 --> 00:22:13,040
about production matrix the platform has

00:22:10,020 --> 00:22:15,840
already build original matrix in mind

00:22:13,040 --> 00:22:18,530
the notary server has integral with

00:22:15,840 --> 00:22:20,900
Netflix or personal dashboard atlas

00:22:18,530 --> 00:22:22,510
ulta lewis is a tool will aggregate

00:22:20,900 --> 00:22:26,450
different kind of operational metrics

00:22:22,510 --> 00:22:29,540
into you I dashboard and it's also an

00:22:26,450 --> 00:22:31,940
open source now when I know dear server

00:22:29,540 --> 00:22:35,750
make requests will publish variety

00:22:31,940 --> 00:22:38,660
matrix into outlets for example will

00:22:35,750 --> 00:22:41,030
publish request-response count so we

00:22:38,660 --> 00:22:43,580
will know the historical obvious of our

00:22:41,030 --> 00:22:46,010
server we can make inform the decision

00:22:43,580 --> 00:22:50,090
if we want to scale our server up or

00:22:46,010 --> 00:22:52,820
down we also aggregate the request

00:22:50,090 --> 00:22:56,480
latency and request q-dubs so we know

00:22:52,820 --> 00:22:59,450
our server performance and we measure

00:22:56,480 --> 00:23:01,550
server figlio count and time i'll count

00:22:59,450 --> 00:23:06,100
and we can set threshold on the error

00:23:01,550 --> 00:23:09,860
rate so we can alert our developer and

00:23:06,100 --> 00:23:12,440
we have silver restyle count if our

00:23:09,860 --> 00:23:14,360
server continuously restarting that's an

00:23:12,440 --> 00:23:19,370
indication of severe problem inside the

00:23:14,360 --> 00:23:21,800
data endpoints cliff we also publish a

00:23:19,370 --> 00:23:25,400
flawed system level metrics for example

00:23:21,800 --> 00:23:27,590
cpu or heap use it so we can be alerted

00:23:25,400 --> 00:23:32,690
if there's performance or memory leak

00:23:27,590 --> 00:23:35,290
going on in production in some time imma

00:23:32,690 --> 00:23:39,740
get a 500 error for a particular request

00:23:35,290 --> 00:23:42,050
so I want to see the error log I however

00:23:39,740 --> 00:23:43,550
we don't want our I developer to take

00:23:42,050 --> 00:23:47,300
the trouble to log into production

00:23:43,550 --> 00:23:48,740
server until the server log and also we

00:23:47,300 --> 00:23:51,620
have hundreds of different colored

00:23:48,740 --> 00:23:54,260
server we wouldn't know which requests

00:23:51,620 --> 00:23:57,200
were coming to which server so we view

00:23:54,260 --> 00:24:00,470
the tooling to aggregate a server into

00:23:57,200 --> 00:24:04,250
ink we allocate the server log into a UI

00:24:00,470 --> 00:24:08,710
tool now our UI developer can call it a

00:24:04,250 --> 00:24:08,710
server log through this UI to real time

00:24:09,520 --> 00:24:15,020
at this point we have good visibility

00:24:11,660 --> 00:24:18,950
into a node.js server is that enough to

00:24:15,020 --> 00:24:22,970
debug a production issue actually it's

00:24:18,950 --> 00:24:24,980
not we have a distributed system the

00:24:22,970 --> 00:24:28,100
first step to this debug a production

00:24:24,980 --> 00:24:31,200
issue is identify which stuck in the

00:24:28,100 --> 00:24:33,659
requests segment has problem we

00:24:31,200 --> 00:24:36,240
has come in you will come to a routing

00:24:33,659 --> 00:24:39,269
gateway the Gateway wore out the request

00:24:36,240 --> 00:24:41,600
to our no Jo server then no geoserver

00:24:39,269 --> 00:24:44,779
make requests to a remote service layer

00:24:41,600 --> 00:24:47,309
finally we fetch the internal holiday de

00:24:44,779 --> 00:24:49,380
wouldn't be great if we have operational

00:24:47,309 --> 00:24:53,250
metrics for each individual request

00:24:49,380 --> 00:24:55,919
segment so we build distributed request

00:24:53,250 --> 00:24:58,500
treating tool to measure request latency

00:24:55,919 --> 00:25:02,179
and status for each individual local

00:24:58,500 --> 00:25:08,820
segment now we have good visibility into

00:25:02,179 --> 00:25:11,279
entire Netflix API ecosystem at this

00:25:08,820 --> 00:25:14,010
point we have all the tooling available

00:25:11,279 --> 00:25:17,130
for us to debug now we are ready to test

00:25:14,010 --> 00:25:19,789
in production with full scale however

00:25:17,130 --> 00:25:23,220
any new architecture could cause

00:25:19,789 --> 00:25:25,740
unexpected issue we have over 80 million

00:25:23,220 --> 00:25:29,059
subscribers we don't want to test a new

00:25:25,740 --> 00:25:32,429
architecture while in impacting our

00:25:29,059 --> 00:25:35,700
subscribers to experience so we decide

00:25:32,429 --> 00:25:38,309
to run shallow traffic what is the

00:25:35,700 --> 00:25:41,039
shuttle traffic here when a device make

00:25:38,309 --> 00:25:43,320
a request to our routing gateway it will

00:25:41,039 --> 00:25:46,769
duplicate the request when go to the

00:25:43,320 --> 00:25:48,870
mono list data API server the other go

00:25:46,769 --> 00:25:52,139
to the new notice taco container

00:25:48,870 --> 00:25:54,600
platform now only the monolithic data

00:25:52,139 --> 00:25:57,210
API server will return the data back to

00:25:54,600 --> 00:25:59,190
our client the note G of stalker

00:25:57,210 --> 00:26:01,559
container platform will only return the

00:25:59,190 --> 00:26:04,470
data back to the routing gateway and the

00:26:01,559 --> 00:26:07,529
data is dropped there this way we can

00:26:04,470 --> 00:26:12,269
test our new architecture without impact

00:26:07,529 --> 00:26:14,250
customers experience at this point we

00:26:12,269 --> 00:26:16,380
have slayed our data API more or less

00:26:14,250 --> 00:26:18,480
and make it each data API service

00:26:16,380 --> 00:26:21,899
running inside it's all know Tiesto

00:26:18,480 --> 00:26:24,990
Cantina in production we have achieved

00:26:21,899 --> 00:26:26,490
long time isolation we can scale a

00:26:24,990 --> 00:26:28,740
different calendar if you have service

00:26:26,490 --> 00:26:31,049
in apparently we have reached

00:26:28,740 --> 00:26:35,010
operational insight into our notice

00:26:31,049 --> 00:26:38,429
server during development we have much

00:26:35,010 --> 00:26:40,679
efficient developer workflow we can

00:26:38,429 --> 00:26:42,809
reproduce a production problem in

00:26:40,679 --> 00:26:44,790
developers local machine precisely to

00:26:42,809 --> 00:26:47,340
debug issue

00:26:44,790 --> 00:26:49,340
this architecture improvement has made

00:26:47,340 --> 00:26:54,720
big impact to our business and

00:26:49,340 --> 00:26:56,790
developers workflow thank you for coming

00:26:54,720 --> 00:26:58,740
to my talk if you are interested in

00:26:56,790 --> 00:27:01,080
working in node.js or darker Cantina

00:26:58,740 --> 00:27:04,440
feel free to reach out to me after the

00:27:01,080 --> 00:27:06,840
talk and our company is hiring if you

00:27:04,440 --> 00:27:10,730
are interested please what look for our

00:27:06,840 --> 00:27:10,730

YouTube URL: https://www.youtube.com/watch?v=Skafzq6lHlY


