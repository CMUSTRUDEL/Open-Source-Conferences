Title: We Live in Memory: Making Î» and GraphQL respond in 70ms - Francis Gulotta - JSConf US 2018
Publication date: 2018-11-11
Playlist: JSConf US 2018
Description: 
	
Captions: 
	00:00:00,320 --> 00:00:03,840
[Music]

00:00:02,070 --> 00:00:05,660
[Applause]

00:00:03,840 --> 00:00:07,410
[Music]

00:00:05,660 --> 00:00:09,280
[Applause]

00:00:07,410 --> 00:00:11,020
[Music]

00:00:09,280 --> 00:00:12,780
[Applause]

00:00:11,020 --> 00:00:15,920
[Music]

00:00:12,780 --> 00:00:15,920
[Applause]

00:00:16,870 --> 00:00:29,309
[Music]

00:00:23,550 --> 00:00:35,020
[Applause]

00:00:29,309 --> 00:00:38,620
hello my name is Francis I look like

00:00:35,020 --> 00:00:42,489
this most places on the internet and I

00:00:38,620 --> 00:00:46,540
work a bustle VP of engineering a puzzle

00:00:42,489 --> 00:00:49,630
and so we are a Content site where

00:00:46,540 --> 00:00:52,450
digital a digital media company and a

00:00:49,630 --> 00:00:53,739
lot of people ask hey Francis how did

00:00:52,450 --> 00:00:56,230
you everyone a puzzle like that would

00:00:53,739 --> 00:00:58,690
say so fast and I know this one you know

00:00:56,230 --> 00:01:00,489
we put everything in Redis and since

00:00:58,690 --> 00:01:03,579
that's not a talk and it's usually

00:01:00,489 --> 00:01:05,170
doesn't explain anything I did make this

00:01:03,579 --> 00:01:07,149
talk and I call it we live in memory

00:01:05,170 --> 00:01:10,000
because it's a really nice way to say we

00:01:07,149 --> 00:01:12,490
use Redis and I'm gonna tell you about

00:01:10,000 --> 00:01:16,090
how we use Amazon lambda and graph :

00:01:12,490 --> 00:01:17,470
Redis to make a really fast API if you

00:01:16,090 --> 00:01:19,750
want to follow along if you want to do

00:01:17,470 --> 00:01:23,440
the links any of the open-source you can

00:01:19,750 --> 00:01:26,170
get the talks on the side here and I

00:01:23,440 --> 00:01:28,720
just to prove you know that we really do

00:01:26,170 --> 00:01:30,369
have fast api's I see 70 milliseconds in

00:01:28,720 --> 00:01:33,700
the title because that's the average but

00:01:30,369 --> 00:01:36,729
most requests are in 24 milliseconds and

00:01:33,700 --> 00:01:38,890
this is our API response rate and I love

00:01:36,729 --> 00:01:41,950
it makes me so happy if you're a stats

00:01:38,890 --> 00:01:43,960
nerd you'll notice the distribution

00:01:41,950 --> 00:01:45,850
there is a quite perfect like

00:01:43,960 --> 00:01:51,010
distribution and that bothers me too and

00:01:45,850 --> 00:01:52,299
I don't know why so this talks gonna be

00:01:51,010 --> 00:01:53,439
in three parts I'm gonna tell you what

00:01:52,299 --> 00:01:54,640
bustled is doing I'm gonna tell you how

00:01:53,439 --> 00:01:59,320
we're doing it and then I'm gonna say it

00:01:54,640 --> 00:02:00,909
tell you how you can do it so where as I

00:01:59,320 --> 00:02:02,799
said we're a digital media company right

00:02:00,909 --> 00:02:05,530
so we have you know big websites only

00:02:02,799 --> 00:02:07,289
show ads and you know we do all kind of

00:02:05,530 --> 00:02:10,390
stuff we're one of the largest

00:02:07,289 --> 00:02:12,129
publishers for millennial women right

00:02:10,390 --> 00:02:13,450
I found out we're actually just really

00:02:12,129 --> 00:02:16,329
big in general we're bigger than the

00:02:13,450 --> 00:02:18,370
Washington Post and they make news and

00:02:16,329 --> 00:02:20,230
we're also biggest bigger than like

00:02:18,370 --> 00:02:21,940
Stack Exchange which is also really

00:02:20,230 --> 00:02:22,880
weird because that in my head is just

00:02:21,940 --> 00:02:25,460
one of the most massive

00:02:22,880 --> 00:02:27,140
sites out there yeah and then also doing

00:02:25,460 --> 00:02:28,940
research I found out that WebMD is a

00:02:27,140 --> 00:02:30,380
digital media site we're bigger than

00:02:28,940 --> 00:02:32,090
them but the fact there are digital

00:02:30,380 --> 00:02:34,130
media site instead of maybe like I don't

00:02:32,090 --> 00:02:40,070
know a medical site it makes makes me

00:02:34,130 --> 00:02:41,630
really and we're growing right so we

00:02:40,070 --> 00:02:43,790
keep adding these sites to our platform

00:02:41,630 --> 00:02:45,140
and it means we just got to keep you

00:02:43,790 --> 00:02:49,550
know being able to go faster and store

00:02:45,140 --> 00:02:50,540
more data so what are our goals right we

00:02:49,550 --> 00:02:52,550
want to have the best reader experience

00:02:50,540 --> 00:02:54,080
right and we want to have the best

00:02:52,550 --> 00:02:56,090
features so we can make the most

00:02:54,080 --> 00:02:58,460
interesting compelling content you know

00:02:56,090 --> 00:03:00,110
and there is not a software project out

00:02:58,460 --> 00:03:03,590
there that doesn't have these same goals

00:03:00,110 --> 00:03:06,290
I just want to be good right our

00:03:03,590 --> 00:03:08,090
strategies to make this happen is we

00:03:06,290 --> 00:03:09,980
want a very fast page load like we got

00:03:08,090 --> 00:03:12,230
it we have ads to show you you know and

00:03:09,980 --> 00:03:14,120
we want to make it really cheap to

00:03:12,230 --> 00:03:19,160
change things and throw stuff away and

00:03:14,120 --> 00:03:20,960
try out new ideas yeah before I go much

00:03:19,160 --> 00:03:23,120
further I just want to say what Amazon

00:03:20,960 --> 00:03:25,600
lambda is because it's really easy to

00:03:23,120 --> 00:03:28,880
assume everybody knows that except you

00:03:25,600 --> 00:03:30,560
it's functions as a service and what

00:03:28,880 --> 00:03:33,290
does that even mean it means you get an

00:03:30,560 --> 00:03:35,360
API in this case an Amazon HTTP API

00:03:33,290 --> 00:03:37,340
alright that lets you execute your

00:03:35,360 --> 00:03:40,250
JavaScript or a couple other languages

00:03:37,340 --> 00:03:42,260
function remotely and lets you do it

00:03:40,250 --> 00:03:44,000
with a consistent environment right so

00:03:42,260 --> 00:03:45,800
you have guaranteed CPU guaranteed

00:03:44,000 --> 00:03:47,810
memory and it doesn't care if you have

00:03:45,800 --> 00:03:49,550
one running every second or a hundred

00:03:47,810 --> 00:03:51,170
thousand running every second you know

00:03:49,550 --> 00:03:52,760
you're guaranteed to have just as much

00:03:51,170 --> 00:03:55,430
memory and CPU available to every

00:03:52,760 --> 00:03:58,250
request and this makes scaling easier

00:03:55,430 --> 00:03:59,570
right and we're using it because we were

00:03:58,250 --> 00:04:01,520
able to take a whole bunch of app

00:03:59,570 --> 00:04:03,350
servers that we had there to handle push

00:04:01,520 --> 00:04:05,630
notifications and unpredictable traffic

00:04:03,350 --> 00:04:08,120
and we're paying about 30km month and

00:04:05,630 --> 00:04:10,880
now we're paying 3km up you know in

00:04:08,120 --> 00:04:13,070
lambda and sometimes we have like 15 20

00:04:10,880 --> 00:04:16,280
X or normal traffic for like two minutes

00:04:13,070 --> 00:04:18,109
you know and that that's sucks well I

00:04:16,280 --> 00:04:21,830
mean that's hard I should say it's

00:04:18,109 --> 00:04:23,270
actually really amazing and so and over

00:04:21,830 --> 00:04:26,270
the time since we've been we've been

00:04:23,270 --> 00:04:28,340
building this platform for two years in

00:04:26,270 --> 00:04:29,220
this incarnation or so and we've grown

00:04:28,340 --> 00:04:31,110
about 10

00:04:29,220 --> 00:04:32,580
in that amount and I haven't had to

00:04:31,110 --> 00:04:34,740
worry about it it's still the same

00:04:32,580 --> 00:04:35,910
functions doing the same stuff you know

00:04:34,740 --> 00:04:38,700
it's got to make sure the database can

00:04:35,910 --> 00:04:40,950
stay up to speed and you know I will

00:04:38,700 --> 00:04:44,730
have to worry about it soon but but it's

00:04:40,950 --> 00:04:50,430
bought us a lot so how does it actually

00:04:44,730 --> 00:04:52,260
work right it works like this so when

00:04:50,430 --> 00:04:53,580
you go and load this article and why

00:04:52,260 --> 00:04:57,540
your kid wants to hear good night moon

00:04:53,580 --> 00:04:59,130
again hits our CDN you know the CDN will

00:04:57,540 --> 00:05:00,690
give you the rendered content or if

00:04:59,130 --> 00:05:02,340
you're if you're already have the page

00:05:00,690 --> 00:05:04,050
loaded and it's an API request to go

00:05:02,340 --> 00:05:07,350
straight to the API we render everything

00:05:04,050 --> 00:05:08,760
and react our API is handled by graph QL

00:05:07,350 --> 00:05:10,920
and all the data comes from reddest

00:05:08,760 --> 00:05:13,260
elasticsearch and you can sort of split

00:05:10,920 --> 00:05:15,390
this up into a few layers the CDN layer

00:05:13,260 --> 00:05:19,950
the rendering layer the API layer the

00:05:15,390 --> 00:05:22,230
database layer and the CDN tries really

00:05:19,950 --> 00:05:24,060
hard not to bother anyone else with

00:05:22,230 --> 00:05:26,310
anything if you can serve your request

00:05:24,060 --> 00:05:27,900
the CDN servers are much closer to where

00:05:26,310 --> 00:05:30,540
you live you know they're all around the

00:05:27,900 --> 00:05:32,190
world and I would rather everything to

00:05:30,540 --> 00:05:36,240
be served out of the CDN I would rather

00:05:32,190 --> 00:05:38,340
be 100% CDN served site but you know

00:05:36,240 --> 00:05:40,110
there's a couple options you can use

00:05:38,340 --> 00:05:42,480
especially if this stack right now we're

00:05:40,110 --> 00:05:44,340
using fastly but I actually have one

00:05:42,480 --> 00:05:46,470
more requirement I want out of my CDN is

00:05:44,340 --> 00:05:48,060
that it should execute my functions this

00:05:46,470 --> 00:05:51,750
is weird because a function execution

00:05:48,060 --> 00:05:52,980
isn't exactly an HTTP request and but

00:05:51,750 --> 00:05:54,180
it's close enough and it can give them

00:05:52,980 --> 00:05:54,930
the same data and it should be a

00:05:54,180 --> 00:05:56,730
question again

00:05:54,930 --> 00:05:58,800
and so in this world where I don't

00:05:56,730 --> 00:06:00,390
actually have any web servers I don't

00:05:58,800 --> 00:06:02,669
want to have an upstream web server I

00:06:00,390 --> 00:06:05,130
want to have you know the CDN do all the

00:06:02,669 --> 00:06:06,960
work and so we accomplished this kind of

00:06:05,130 --> 00:06:09,510
hacky we have API gateway which is

00:06:06,960 --> 00:06:11,490
Amazon's web server for functions and

00:06:09,510 --> 00:06:13,169
that executes sar lambda and then we

00:06:11,490 --> 00:06:14,669
have fastly in front of it and fastly

00:06:13,169 --> 00:06:16,680
gives us really fast cache invalidation

00:06:14,669 --> 00:06:18,900
so when we update a post it's

00:06:16,680 --> 00:06:21,090
it's a pushed out to follow the seed in

00:06:18,900 --> 00:06:24,090
and 100 a minute usually under a second

00:06:21,090 --> 00:06:25,890
to actually there's a near future where

00:06:24,090 --> 00:06:26,620
maybe we use cloud flower workers or

00:06:25,890 --> 00:06:29,290
they run

00:06:26,620 --> 00:06:31,270
and have a v8 running in in the edge or

00:06:29,290 --> 00:06:32,800
we use cloud front with their lambda at

00:06:31,270 --> 00:06:34,180
the edge and have these executor

00:06:32,800 --> 00:06:36,699
functions for us and that way we can

00:06:34,180 --> 00:06:38,979
drop a whole hop about 10 or 15

00:06:36,699 --> 00:06:42,310
milliseconds and you know we can we can

00:06:38,979 --> 00:06:44,229
serve up stuff that much faster still a

00:06:42,310 --> 00:06:45,430
little an experimentation but I think

00:06:44,229 --> 00:06:49,060
this is something CD ends are going to

00:06:45,430 --> 00:06:51,370
do from out of the box pretty soon their

00:06:49,060 --> 00:06:53,949
rendering layer you know so this is a

00:06:51,370 --> 00:06:56,740
function right and it gives us a status

00:06:53,949 --> 00:06:58,360
and eight a body and headers and that's

00:06:56,740 --> 00:07:00,160
everything you need for an HTTP response

00:06:58,360 --> 00:07:02,110
you know it's got a couple of

00:07:00,160 --> 00:07:03,729
responsibilities like this is the app of

00:07:02,110 --> 00:07:05,350
bustled you know we're all client-side

00:07:03,729 --> 00:07:06,669
apps and so it's got to do the

00:07:05,350 --> 00:07:08,949
server-side rendering it's got to serve

00:07:06,669 --> 00:07:10,780
up all the assets in a good way it's got

00:07:08,949 --> 00:07:12,699
to you know be smart about the

00:07:10,780 --> 00:07:15,070
components and the style shades and

00:07:12,699 --> 00:07:17,620
break it all apart and so you know we

00:07:15,070 --> 00:07:20,350
use react for our CMS's we use pre-act

00:07:17,620 --> 00:07:23,010
because it's not much smaller for when

00:07:20,350 --> 00:07:25,720
you go to bustled calm or raw / calm and

00:07:23,010 --> 00:07:28,870
webpack makes everything possible we

00:07:25,720 --> 00:07:31,990
even went pack the api we're happy with

00:07:28,870 --> 00:07:34,690
how that works the api it's got a couple

00:07:31,990 --> 00:07:36,700
of responsibilities it wants to take a

00:07:34,690 --> 00:07:38,470
query and return some data you know and

00:07:36,700 --> 00:07:40,300
then when you want to make a change yeah

00:07:38,470 --> 00:07:43,360
take some input change the state and

00:07:40,300 --> 00:07:45,220
then return some data and I have the

00:07:43,360 --> 00:07:47,919
requirement that I want it to be strict

00:07:45,220 --> 00:07:48,970
I want it to guarantee that when you ask

00:07:47,919 --> 00:07:52,030
for a field do you know what you're

00:07:48,970 --> 00:07:54,910
getting and you always get it and so we

00:07:52,030 --> 00:07:59,169
use graph QL right because graph qo does

00:07:54,910 --> 00:08:01,090
all these things we're able to we start

00:07:59,169 --> 00:08:02,199
of like a dozen record services and so

00:08:01,090 --> 00:08:03,580
whenever we wanted to make a request

00:08:02,199 --> 00:08:05,349
we'd have to go and get it from one and

00:08:03,580 --> 00:08:07,270
the other and the other and then try to

00:08:05,349 --> 00:08:09,070
get them all back and then sometimes if

00:08:07,270 --> 00:08:10,750
we didn't implement it right status

00:08:09,070 --> 00:08:12,760
codes to be different you know err

00:08:10,750 --> 00:08:14,979
errors would be a different shape we had

00:08:12,760 --> 00:08:16,660
a lot of ifs in our in our response

00:08:14,979 --> 00:08:18,250
handling to try to normalize it in fact

00:08:16,660 --> 00:08:20,199
our front-end team did more data

00:08:18,250 --> 00:08:22,720
normalization than our than our API team

00:08:20,199 --> 00:08:24,550
and graph QL kind of gave us a single

00:08:22,720 --> 00:08:26,470
place a single end point where we put

00:08:24,550 --> 00:08:28,000
everything behind one thing and we wrap

00:08:26,470 --> 00:08:30,490
all our third-party services and stuff

00:08:28,000 --> 00:08:33,459
in this - it's helped a lot to have one

00:08:30,490 --> 00:08:35,740
way to do things and the last player is

00:08:33,459 --> 00:08:37,599
the database layer and you just want it

00:08:35,740 --> 00:08:39,030
to store data safely right and you

00:08:37,599 --> 00:08:41,219
wanted to retrieve data fast

00:08:39,030 --> 00:08:44,099
and I wanted to retrieve data fast in a

00:08:41,219 --> 00:08:46,050
consistent time because it doesn't help

00:08:44,099 --> 00:08:48,150
me if I ask for a post and I get it and

00:08:46,050 --> 00:08:49,500
and you know in under 70 milliseconds

00:08:48,150 --> 00:08:51,630
and then I asked for it again later and

00:08:49,500 --> 00:08:54,180
I get it in its second and a half like I

00:08:51,630 --> 00:08:56,850
think that's broken yeah I want it to be

00:08:54,180 --> 00:08:58,530
much much faster and so actually it can

00:08:56,850 --> 00:09:01,260
even be slow if I know how fast it is

00:08:58,530 --> 00:09:04,830
and in order to get this we use Redis as

00:09:01,260 --> 00:09:07,110
our primary data star so if you don't

00:09:04,830 --> 00:09:09,240
know Redis it's a data structure server

00:09:07,110 --> 00:09:10,830
and it slow gives you things like hashes

00:09:09,240 --> 00:09:11,580
and started sets and let you talk to it

00:09:10,830 --> 00:09:13,140
over the network

00:09:11,580 --> 00:09:15,180
let's do kind of operations on the stuff

00:09:13,140 --> 00:09:17,640
remember a lot of people use this for

00:09:15,180 --> 00:09:18,750
cash or maybe they put their sessions in

00:09:17,640 --> 00:09:21,000
there because they could have sort of a

00:09:18,750 --> 00:09:22,710
little JSON session in there and it's

00:09:21,000 --> 00:09:24,540
really fast and gives it back but if

00:09:22,710 --> 00:09:26,490
Redis dies you know if you if the

00:09:24,540 --> 00:09:29,520
process exits all the data is gone and

00:09:26,490 --> 00:09:30,870
you know what that's okay but just

00:09:29,520 --> 00:09:32,610
because as good of that doesn't mean

00:09:30,870 --> 00:09:35,490
it's actually not good as a database

00:09:32,610 --> 00:09:36,750
it's got known persistence and most

00:09:35,490 --> 00:09:38,370
people when they hear we use it they

00:09:36,750 --> 00:09:39,450
they don't they don't know that because

00:09:38,370 --> 00:09:43,589
why would you turn it on if it's

00:09:39,450 --> 00:09:47,339
ephemeral data all right and so I tell

00:09:43,589 --> 00:09:50,820
them and they don't believe me so I'm

00:09:47,339 --> 00:09:52,530
gonna show you whenever I write comes in

00:09:50,820 --> 00:09:55,350
it gets appended to this append-only

00:09:52,530 --> 00:09:56,610
file which is how it is a lot of

00:09:55,350 --> 00:09:59,160
databases have this kind of thing this

00:09:56,610 --> 00:10:00,720
is the write log yeah and every second

00:09:59,160 --> 00:10:02,790
we write this to disk so if the process

00:10:00,720 --> 00:10:07,260
itself crashes which we haven't ever had

00:10:02,790 --> 00:10:08,910
happen in four years but but it can it

00:10:07,260 --> 00:10:10,170
we can just start it up again

00:10:08,910 --> 00:10:11,339
I'll pick up where I left off that's

00:10:10,170 --> 00:10:14,160
what everything back to memory and we're

00:10:11,339 --> 00:10:15,900
fine we take that throw test3 but we

00:10:14,160 --> 00:10:17,910
also take a full shot of memory which is

00:10:15,900 --> 00:10:20,580
a little faster to load that's the Rd be

00:10:17,910 --> 00:10:22,620
the Redis database file and we put that

00:10:20,580 --> 00:10:24,089
desk three two and so we can restore

00:10:22,620 --> 00:10:26,010
another machine we were start staging

00:10:24,089 --> 00:10:27,839
every night off that data and you know

00:10:26,010 --> 00:10:30,930
and we just have as much I haven't had

00:10:27,839 --> 00:10:32,760
as good data retention in Postgres or

00:10:30,930 --> 00:10:34,380
anything else I mean I mean and that's

00:10:32,760 --> 00:10:35,970
that's the fault of the problem that's

00:10:34,380 --> 00:10:38,580
the pole of our ops you know you can do

00:10:35,970 --> 00:10:39,780
this pretty much any database of course

00:10:38,580 --> 00:10:42,390
we have high availability there read

00:10:39,780 --> 00:10:44,339
replicas in the primary so if it does if

00:10:42,390 --> 00:10:45,600
it does exist it will readers won't

00:10:44,339 --> 00:10:47,430
notice maybe we'll lose a couple of

00:10:45,600 --> 00:10:50,400
requests well switches over that's

00:10:47,430 --> 00:10:54,720
and this works very well for us you know

00:10:50,400 --> 00:10:57,060
and you can you could do this with your

00:10:54,720 --> 00:10:59,040
tool of choice this really this talk I

00:10:57,060 --> 00:11:02,160
love Radisson I would love to actually

00:10:59,040 --> 00:11:03,360
give an entire read of stock but but

00:11:02,160 --> 00:11:05,040
this really could be any database

00:11:03,360 --> 00:11:08,730
whatever your favorite is it will work

00:11:05,040 --> 00:11:10,290
just fine so if we take our stock and

00:11:08,730 --> 00:11:12,090
we've split it up into the layers you

00:11:10,290 --> 00:11:13,530
know the CDN tries to do everything I

00:11:12,090 --> 00:11:15,240
can not to bother anyone the rendering

00:11:13,530 --> 00:11:17,520
gives you the rendered content you know

00:11:15,240 --> 00:11:19,530
the API you know well forms and handles

00:11:17,520 --> 00:11:23,160
all the changes to stay in the database

00:11:19,530 --> 00:11:26,220
keeps everything safe we're gonna talk

00:11:23,160 --> 00:11:28,800
about this part because part of the part

00:11:26,220 --> 00:11:30,900
I know the most I'm not gonna talk about

00:11:28,800 --> 00:11:34,530
elasticsearch but we use it you know for

00:11:30,900 --> 00:11:36,450
search and we also related content and

00:11:34,530 --> 00:11:38,610
some other nice things you know it's

00:11:36,450 --> 00:11:41,730
great but in the end of the day Redis is

00:11:38,610 --> 00:11:43,500
the primary so let's make an example I

00:11:41,730 --> 00:11:46,080
recently became a dad and so all my

00:11:43,500 --> 00:11:47,820
shoes are dad shoes you know and so I

00:11:46,080 --> 00:11:49,500
heard it's actually hard to pull off dad

00:11:47,820 --> 00:11:51,960
shoes and so I was like well let's check

00:11:49,500 --> 00:11:54,420
it out and at the top of Google there's

00:11:51,960 --> 00:11:56,970
a bustle article about dad shoes yeah

00:11:54,420 --> 00:12:00,210
and it turns out the secret to dad shoes

00:11:56,970 --> 00:12:05,160
is wearing a flowy skirt but if you look

00:12:00,210 --> 00:12:07,680
at the data that goes into this post you

00:12:05,160 --> 00:12:09,750
have what you would expect it's a JSON

00:12:07,680 --> 00:12:13,080
blog right and we have sort of this tree

00:12:09,750 --> 00:12:15,480
of data we have the site it's bustled it

00:12:13,080 --> 00:12:17,280
has a post on the post field you know

00:12:15,480 --> 00:12:19,530
and it has all the data for the post and

00:12:17,280 --> 00:12:22,290
Escada the post has an author field that

00:12:19,530 --> 00:12:24,330
has a user object it has a tags field

00:12:22,290 --> 00:12:26,160
which has an array of tags and this

00:12:24,330 --> 00:12:29,730
matches our graph QL querying real

00:12:26,160 --> 00:12:31,710
closely we're asking for this in the

00:12:29,730 --> 00:12:33,390
same shape and there's a little bit of

00:12:31,710 --> 00:12:34,650
prescription here because we can ask for

00:12:33,390 --> 00:12:37,050
it like this we get like this and we use

00:12:34,650 --> 00:12:39,210
it like this but if we got it back you

00:12:37,050 --> 00:12:41,400
know one request for each tag or even if

00:12:39,210 --> 00:12:44,280
nested data if we got it back in a flat

00:12:41,400 --> 00:12:46,320
format you know like with a JSON API or

00:12:44,280 --> 00:12:47,850
something we would basically go and

00:12:46,320 --> 00:12:50,160
build the shape again you know to give

00:12:47,850 --> 00:12:51,960
it to our components so we've been very

00:12:50,160 --> 00:12:54,000
happy with this you also get only the

00:12:51,960 --> 00:12:55,470
fields you asked for so we can you know

00:12:54,000 --> 00:12:57,240
in the API team just keep throwing stuff

00:12:55,470 --> 00:12:58,949
in there for people to try out and most

00:12:57,240 --> 00:13:00,449
using it they do we can get forget

00:12:58,949 --> 00:13:01,499
fields and it pops up in their linter

00:13:00,449 --> 00:13:04,399
and they say oh they'll use this field

00:13:01,499 --> 00:13:07,170
anymore you know and it's kind of cool

00:13:04,399 --> 00:13:11,040
if we remove all the data we end up with

00:13:07,170 --> 00:13:14,639
this little tree right a graph perhaps

00:13:11,040 --> 00:13:16,319
of the of the names of the you know the

00:13:14,639 --> 00:13:18,389
types and their IDs and their

00:13:16,319 --> 00:13:19,579
relationships right and if we squint and

00:13:18,389 --> 00:13:22,649
we can make it kind of look like this

00:13:19,579 --> 00:13:24,360
all right so this site has a post field

00:13:22,649 --> 00:13:26,759
with the post and has the author field

00:13:24,360 --> 00:13:28,949
of the user and the tags with the tags

00:13:26,759 --> 00:13:31,499
if we want to describe this a little

00:13:28,949 --> 00:13:33,869
more graph database II you know and they

00:13:31,499 --> 00:13:37,170
the graph community uses the word

00:13:33,869 --> 00:13:38,490
predicate to describe an edge I looked

00:13:37,170 --> 00:13:41,399
it up on google i don't know why i'm

00:13:38,490 --> 00:13:42,929
sorry but the predicates here side has

00:13:41,399 --> 00:13:44,459
post and get a little more a little more

00:13:42,929 --> 00:13:47,730
descriptive with them and so we can

00:13:44,459 --> 00:13:50,699
store this in the database and like we

00:13:47,730 --> 00:13:54,569
want to represent it and in order to do

00:13:50,699 --> 00:13:57,480
that we built a graph database we call

00:13:54,569 --> 00:13:59,279
it Gradius way after an old video game

00:13:57,480 --> 00:14:01,019
and this is actually the name of our

00:13:59,279 --> 00:14:03,990
whole API in the graph database the kind

00:14:01,019 --> 00:14:06,329
of game hand in hand and this has

00:14:03,990 --> 00:14:07,949
allowed us to grow with a relatively

00:14:06,329 --> 00:14:10,379
small engineering team where were less

00:14:07,949 --> 00:14:12,179
than 15 people you know over the past

00:14:10,379 --> 00:14:14,670
couple years only we could have done it

00:14:12,179 --> 00:14:17,100
without this so whenever I say what

00:14:14,670 --> 00:14:20,699
graph database immediately people say oh

00:14:17,100 --> 00:14:22,499
like neo4j right and exactly like neo4j

00:14:20,699 --> 00:14:25,769
except it doesn't do anything to offer

00:14:22,499 --> 00:14:27,899
to us your fridge a is amazing it's a

00:14:25,769 --> 00:14:30,269
it's a very complicated actually I have

00:14:27,899 --> 00:14:32,579
a hard time and this is a failing of

00:14:30,269 --> 00:14:35,069
mine not it because they have wonderful

00:14:32,579 --> 00:14:36,509
beautiful tools and I wish I had but

00:14:35,069 --> 00:14:38,249
it's it's hard for me to understand it

00:14:36,509 --> 00:14:41,100
does a lot and the queries can get super

00:14:38,249 --> 00:14:44,100
complex right and the reason ours is

00:14:41,100 --> 00:14:45,720
faster is because it's because we made

00:14:44,100 --> 00:14:48,629
some trade-offs but I mean when people

00:14:45,720 --> 00:14:49,920
say databases are faster right what do

00:14:48,629 --> 00:14:52,110
they mean you know it's

00:14:49,920 --> 00:14:54,540
I had a DBA should I work for and his

00:14:52,110 --> 00:14:56,129
big analogy was trans art slow they have

00:14:54,540 --> 00:14:58,559
one speed that people get it on up on

00:14:56,129 --> 00:15:00,240
and off and the people are slow right

00:14:58,559 --> 00:15:02,279
but if there were no people the trans

00:15:00,240 --> 00:15:04,290
would be super fast databases are the

00:15:02,279 --> 00:15:06,089
same they aren't slow the data going in

00:15:04,290 --> 00:15:07,980
and out it's the queries that are slow

00:15:06,089 --> 00:15:09,029
and they specially said this every

00:15:07,980 --> 00:15:11,540
single time somebody complain the

00:15:09,029 --> 00:15:14,550
databases for slow

00:15:11,540 --> 00:15:16,320
but you can build a faster train and I

00:15:14,550 --> 00:15:18,900
was the trade-off we made in fact we

00:15:16,320 --> 00:15:20,550
traded query flexibility for speed and

00:15:18,900 --> 00:15:23,760
we made it super difficult to make a

00:15:20,550 --> 00:15:25,170
slow query you know and if you can't

00:15:23,760 --> 00:15:30,330
have a slow query then everything is

00:15:25,170 --> 00:15:32,820
fast right oh I think I should say yeah

00:15:30,330 --> 00:15:34,260
we because it's not flexible because we

00:15:32,820 --> 00:15:36,330
can't do these complex queries we

00:15:34,260 --> 00:15:37,530
replicate to other databases elastic

00:15:36,330 --> 00:15:40,950
search being one of them you know for

00:15:37,530 --> 00:15:44,280
search but also to bigquery for you know

00:15:40,950 --> 00:15:45,810
doing analytics and for you know you can

00:15:44,280 --> 00:15:47,190
get a feed all the changes and so we're

00:15:45,810 --> 00:15:49,500
playing of different databases you know

00:15:47,190 --> 00:15:51,000
we have our DBMS is for reporting you

00:15:49,500 --> 00:15:55,560
know but a rightist remains this for

00:15:51,000 --> 00:15:57,660
sector so we don't love open source we

00:15:55,560 --> 00:15:59,640
just had Ghost 2.0 got released various

00:15:57,660 --> 00:16:01,350
ghost that uses mobile doc as a data

00:15:59,640 --> 00:16:04,140
storage and we helped develop mobile doc

00:16:01,350 --> 00:16:06,510
that's how we store all of our posts and

00:16:04,140 --> 00:16:09,120
so we haven't been able to open source

00:16:06,510 --> 00:16:10,440
Gradius because it's everything and it's

00:16:09,120 --> 00:16:12,300
in no shape to be shared with other

00:16:10,440 --> 00:16:14,400
people and so i started porting

00:16:12,300 --> 00:16:18,060
everything to something I call Nemesis

00:16:14,400 --> 00:16:20,160
DB Nemesis is the US arcade port of the

00:16:18,060 --> 00:16:23,070
gradius game so I figured it was a good

00:16:20,160 --> 00:16:24,630
name for it and it's really fast you

00:16:23,070 --> 00:16:26,130
know as fast as iris already got

00:16:24,630 --> 00:16:27,900
features I wish I could use and Gradius

00:16:26,130 --> 00:16:29,520
and as soon as we get it to a certain

00:16:27,900 --> 00:16:31,980
point I want to advertise cluster

00:16:29,520 --> 00:16:34,140
support so we can get much bigger we

00:16:31,980 --> 00:16:37,230
we're switching the whole company to it

00:16:34,140 --> 00:16:40,170
it'll be a nice little migration by it's

00:16:37,230 --> 00:16:41,850
not done however I use it completely in

00:16:40,170 --> 00:16:43,740
this talk it does everything we showed

00:16:41,850 --> 00:16:45,210
you here today and if this interests you

00:16:43,740 --> 00:16:47,190
if you want to know how it works please

00:16:45,210 --> 00:16:49,770
see me after please check it out and

00:16:47,190 --> 00:16:50,940
open many issues and and like the fire

00:16:49,770 --> 00:16:54,630
for me to finish this because I think

00:16:50,940 --> 00:16:58,200
it'd be better for everybody so let's

00:16:54,630 --> 00:16:59,340
make a graph QL server we're gonna go

00:16:58,200 --> 00:17:00,690
over the tools we're gonna go over to

00:16:59,340 --> 00:17:02,040
what a schema is we're gonna go over how

00:17:00,690 --> 00:17:07,850
the resolvers work and I talked about

00:17:02,040 --> 00:17:09,870
the loaders and this is our package JSON

00:17:07,850 --> 00:17:11,730
dependencies are Apollo server

00:17:09,870 --> 00:17:15,390
I love Apollo I wish I actually used

00:17:11,730 --> 00:17:17,670
Apollo server for Gradius we started it

00:17:15,390 --> 00:17:19,000
before it was ready I think but it's

00:17:17,670 --> 00:17:22,510
totally ready now

00:17:19,000 --> 00:17:23,920
and it's not that complex either and

00:17:22,510 --> 00:17:25,689
that makes me happy it's hard to make

00:17:23,920 --> 00:17:27,400
simple things and so the Apollo tools

00:17:25,689 --> 00:17:29,410
and Apollo server stuff they've they've

00:17:27,400 --> 00:17:30,760
been able to help make a more

00:17:29,410 --> 00:17:32,830
straightforward to develop and I'm very

00:17:30,760 --> 00:17:35,500
happy with it

00:17:32,830 --> 00:17:36,730
and so our server file and this is what

00:17:35,500 --> 00:17:41,560
you would use for developing on your own

00:17:36,730 --> 00:17:45,010
machine reads like this you know you do

00:17:41,560 --> 00:17:46,660
your requires and you get all your type

00:17:45,010 --> 00:17:49,180
definitions it's just a file you read

00:17:46,660 --> 00:17:50,920
into a string and then you start the

00:17:49,180 --> 00:17:53,170
server and you say here that here is the

00:17:50,920 --> 00:17:54,730
schema here are my results and don't

00:17:53,170 --> 00:17:59,290
listen on a port there's not much more

00:17:54,730 --> 00:18:00,880
to it if you have a lambda you know we

00:17:59,290 --> 00:18:02,530
need to play to lambda it's the same

00:18:00,880 --> 00:18:04,030
thing except they have a slightly

00:18:02,530 --> 00:18:05,590
different server which knows how to

00:18:04,030 --> 00:18:07,690
handle the lambda requests and instead

00:18:05,590 --> 00:18:09,130
of listening on a port you tell lambda

00:18:07,690 --> 00:18:10,810
hey this is the name of this is the

00:18:09,130 --> 00:18:15,310
function you call for each request and

00:18:10,810 --> 00:18:17,620
it handles handles the rest but what it

00:18:15,310 --> 00:18:19,570
gives you is a lot so you have the it

00:18:17,620 --> 00:18:21,280
can process graph you all queries but it

00:18:19,570 --> 00:18:23,590
also gives you graphical which is a tool

00:18:21,280 --> 00:18:25,330
that you can use to play with queries

00:18:23,590 --> 00:18:27,070
all right and so I forgive me some

00:18:25,330 --> 00:18:28,600
graphical czar white some are black some

00:18:27,070 --> 00:18:31,090
are dark I don't know how easy this is

00:18:28,600 --> 00:18:32,500
to read but this is a query on the left

00:18:31,090 --> 00:18:34,690
on the data on the right and a big play

00:18:32,500 --> 00:18:36,790
button in the middle and so you can get

00:18:34,690 --> 00:18:38,260
auto completing queries where you can

00:18:36,790 --> 00:18:40,210
hover and see which type it's supposed

00:18:38,260 --> 00:18:42,280
to be and see the data it's gonna get

00:18:40,210 --> 00:18:45,220
copy and paste this into your component

00:18:42,280 --> 00:18:47,740
and use it and even better its

00:18:45,220 --> 00:18:49,720
documenting because there is a schema

00:18:47,740 --> 00:18:52,360
isn't just for the graph 12 server for

00:18:49,720 --> 00:18:54,610
the client - and it's able to pull out

00:18:52,360 --> 00:18:56,740
all the relationships so this is the

00:18:54,610 --> 00:18:58,840
site which has a post which has an

00:18:56,740 --> 00:19:00,520
author which is a user you know and you

00:18:58,840 --> 00:19:01,540
can see what all the types are you know

00:19:00,520 --> 00:19:04,570
you can see if they're gonna be null or

00:19:01,540 --> 00:19:05,980
not and you can click around and and if

00:19:04,570 --> 00:19:08,320
I broke descriptions which I didn't

00:19:05,980 --> 00:19:10,270
you'd see them there too or deprecations

00:19:08,320 --> 00:19:14,470
which I didn't you could see why we got

00:19:10,270 --> 00:19:16,780
rid of stuff and I I firmly github

00:19:14,470 --> 00:19:19,150
scratch qlae API is a wonderful shining

00:19:16,780 --> 00:19:20,710
example of how you can do this right you

00:19:19,150 --> 00:19:24,490
know we crimp stuff from them quite a

00:19:20,710 --> 00:19:26,020
lot so the schema defines what the data

00:19:24,490 --> 00:19:26,380
looks like and it doesn't care how it

00:19:26,020 --> 00:19:28,900
works

00:19:26,380 --> 00:19:29,929
so I have the state I have the posts and

00:19:28,900 --> 00:19:32,179
the users and

00:19:29,929 --> 00:19:33,619
but it all cares is what's the data it

00:19:32,179 --> 00:19:35,990
kind of look like when you give it to

00:19:33,619 --> 00:19:38,119
the API client doesn't care where it

00:19:35,990 --> 00:19:41,029
actually comes from and so the only

00:19:38,119 --> 00:19:43,490
thing required is the query right and

00:19:41,029 --> 00:19:46,399
here we have a field called site and the

00:19:43,490 --> 00:19:47,749
site has requires a name which is an

00:19:46,399 --> 00:19:50,149
enum so you don't have to put in quotes

00:19:47,749 --> 00:19:51,710
and it can only be specific things and

00:19:50,149 --> 00:19:52,970
it returns the site object guaranteed

00:19:51,710 --> 00:19:53,960
that's what the explanation point mean

00:19:52,970 --> 00:19:57,559
this means not normal

00:19:53,960 --> 00:19:59,330
and the site itself has two different

00:19:57,559 --> 00:20:01,340
kinds of things it's got some data the

00:19:59,330 --> 00:20:03,080
idea name right and that comes from our

00:20:01,340 --> 00:20:05,749
database and then it's got this lookup

00:20:03,080 --> 00:20:07,700
field post and post takes the required

00:20:05,749 --> 00:20:09,769
path it's a string and it will try to

00:20:07,700 --> 00:20:11,990
give you a post maybe give you a post

00:20:09,769 --> 00:20:14,450
it's not no I rather it is knowable so

00:20:11,990 --> 00:20:16,129
it doesn't know you know for sure that

00:20:14,450 --> 00:20:19,249
there is opposed to that path and that's

00:20:16,129 --> 00:20:20,749
okay neither do we but there's no

00:20:19,249 --> 00:20:24,049
difference here between data and lookup

00:20:20,749 --> 00:20:27,379
fields and and that comes later in the

00:20:24,049 --> 00:20:29,929
resolvers post is another example you

00:20:27,379 --> 00:20:31,580
have ID path title body those are all

00:20:29,929 --> 00:20:33,740
data they're just strings and numbers

00:20:31,580 --> 00:20:36,289
you know they could be objects but but

00:20:33,740 --> 00:20:38,659
they're data and the authors is a lookup

00:20:36,289 --> 00:20:40,759
for the user the tags does a lookup for

00:20:38,659 --> 00:20:42,350
the tags and we guarantee to give you an

00:20:40,759 --> 00:20:45,230
array and that array is guaranteed to

00:20:42,350 --> 00:20:46,190
have zero or more tags in it so if there

00:20:45,230 --> 00:20:47,450
is anything in the array it's going to

00:20:46,190 --> 00:20:49,220
be a time but it doesn't have to be

00:20:47,450 --> 00:20:51,230
anything and if you use the type

00:20:49,220 --> 00:20:52,759
language or if your type script you know

00:20:51,230 --> 00:20:56,899
you'll notice that there's no way you

00:20:52,759 --> 00:20:58,340
can type the length of an array and

00:20:56,899 --> 00:21:02,029
users and types are boring they're just

00:20:58,340 --> 00:21:03,919
data no that's great so the resolvers

00:21:02,029 --> 00:21:05,539
you don't need a resolver for everything

00:21:03,919 --> 00:21:08,269
just for the lookups right and this is

00:21:05,539 --> 00:21:10,580
where it kind of gets like this is where

00:21:08,269 --> 00:21:12,200
the infinite power and variability you

00:21:10,580 --> 00:21:14,090
know of how you million ways you can do

00:21:12,200 --> 00:21:15,350
things sort of as a paralyzing force

00:21:14,090 --> 00:21:18,080
when you're starting with crafty well

00:21:15,350 --> 00:21:20,899
but it just needs to return full objects

00:21:18,080 --> 00:21:22,610
of other things this is the you know you

00:21:20,899 --> 00:21:26,600
can do many things but this is the most

00:21:22,610 --> 00:21:29,029
common case yeah and we do it per type

00:21:26,600 --> 00:21:31,029
so our query has the site field and so

00:21:29,029 --> 00:21:33,379
it gets a function and it gives you the

00:21:31,029 --> 00:21:35,179
the root is nothing in the query case

00:21:33,379 --> 00:21:37,009
but the argument object for the second

00:21:35,179 --> 00:21:39,619
one if your call site had it required a

00:21:37,009 --> 00:21:41,029
name the site is the post field and if

00:21:39,619 --> 00:21:43,220
you're caught if you recall it requires

00:21:41,029 --> 00:21:43,549
a path but it also gives you the site as

00:21:43,220 --> 00:21:46,399
the

00:21:43,549 --> 00:21:48,019
root of that woke up field and the post

00:21:46,399 --> 00:21:49,340
itself you know you get the post and

00:21:48,019 --> 00:21:51,259
there are no fields on those lookups and

00:21:49,340 --> 00:21:52,700
so using that post you have to look up

00:21:51,259 --> 00:21:57,440
the authors and have to look up the tags

00:21:52,700 --> 00:21:58,909
and in practice we do it like this you

00:21:57,440 --> 00:22:01,639
know so this is the site looking up its

00:21:58,909 --> 00:22:02,960
post and so nemesis TV is something

00:22:01,639 --> 00:22:05,330
called a labeled edge but it just means

00:22:02,960 --> 00:22:06,860
you can you know on the site store a

00:22:05,330 --> 00:22:09,259
path and have it be a reference to

00:22:06,860 --> 00:22:10,879
another object and we look it up and if

00:22:09,259 --> 00:22:13,190
it doesn't exist we return null which is

00:22:10,879 --> 00:22:15,559
perfectly allowed by the schema and then

00:22:13,190 --> 00:22:16,700
we have and then if it does exist we go

00:22:15,559 --> 00:22:18,859
only find it and we return that object

00:22:16,700 --> 00:22:22,549
in fact we return a promise for that

00:22:18,859 --> 00:22:24,559
object which is just fine post is a

00:22:22,549 --> 00:22:26,179
little more complex but the author will

00:22:24,559 --> 00:22:28,489
actually each one is even more simple

00:22:26,179 --> 00:22:31,789
the author looks for an edge to a user

00:22:28,489 --> 00:22:33,230
you know and if and it returns it you

00:22:31,789 --> 00:22:34,970
know pulls out the ID and then actually

00:22:33,230 --> 00:22:36,799
goes and gets the user same thing for

00:22:34,970 --> 00:22:39,080
the tags except it's an array so we get

00:22:36,799 --> 00:22:40,340
all the edges for the for the tags and

00:22:39,080 --> 00:22:42,190
then we just sort of map over and get

00:22:40,340 --> 00:22:44,720
each one return it and promise all and

00:22:42,190 --> 00:22:47,690
so this each returns the object you're

00:22:44,720 --> 00:22:51,769
looking for now if you have ever worked

00:22:47,690 --> 00:22:54,200
and say rails the concept of n plus one

00:22:51,769 --> 00:22:55,639
comes up all the time and this is when

00:22:54,200 --> 00:22:57,470
you're making too many round trips to

00:22:55,639 --> 00:23:01,039
the database and it slows everything

00:22:57,470 --> 00:23:04,340
down and I it's really just not a

00:23:01,039 --> 00:23:06,529
problem if you match the query of the

00:23:04,340 --> 00:23:08,989
commands to match the queries right and

00:23:06,529 --> 00:23:11,720
so data loader is a little utility it's

00:23:08,989 --> 00:23:14,809
like a couple hundred lines and it lets

00:23:11,720 --> 00:23:18,619
you take all the requests you make in

00:23:14,809 --> 00:23:19,940
one once event loop and batch them all

00:23:18,619 --> 00:23:22,179
together so you give it a little

00:23:19,940 --> 00:23:24,559
function do the lookup and I made up a

00:23:22,179 --> 00:23:26,059
function here get a bunch of IDs then

00:23:24,559 --> 00:23:28,669
those how to look up like a whole array

00:23:26,059 --> 00:23:30,200
of IDs and so you can go and ask for a

00:23:28,669 --> 00:23:33,799
bunch of objects and then it's going to

00:23:30,200 --> 00:23:35,989
call your your batch your bachelor your

00:23:33,799 --> 00:23:37,399
get bunch of IDs with addy DuPage array

00:23:35,989 --> 00:23:41,299
of all those things are trying to get

00:23:37,399 --> 00:23:44,239
and this allows you to instead of having

00:23:41,299 --> 00:23:45,109
if I load 50 posts and all their authors

00:23:44,239 --> 00:23:47,539
instead of loading each other

00:23:45,109 --> 00:23:49,970
individually it's going to go and give

00:23:47,539 --> 00:23:52,369
me 50 IDs for those 50 authors so

00:23:49,970 --> 00:23:54,649
instead of doing a new request and you

00:23:52,369 --> 00:23:55,920
look up to the database for each item it

00:23:54,649 --> 00:23:59,070
does it for each depth

00:23:55,920 --> 00:24:00,600
the graph this made it much faster and

00:23:59,070 --> 00:24:04,140
we were able to abuse this a little bit

00:24:00,600 --> 00:24:05,430
and we're able to do it with with Redis

00:24:04,140 --> 00:24:07,410
itself there's something called

00:24:05,430 --> 00:24:09,240
pipelining which lets you put a whole

00:24:07,410 --> 00:24:11,490
bunch of crazed together and no one

00:24:09,240 --> 00:24:13,260
query and send them all and so if we

00:24:11,490 --> 00:24:16,610
wanted to

00:24:13,260 --> 00:24:18,630
this is nemesis DB again which can take

00:24:16,610 --> 00:24:20,360
Redis object or can take your Redis

00:24:18,630 --> 00:24:22,830
loader object which is the same shape

00:24:20,360 --> 00:24:25,320
and if you go and you ask for all these

00:24:22,830 --> 00:24:27,180
notes at the same time with Redis and

00:24:25,320 --> 00:24:29,640
this is not a fair benchmark I ran out

00:24:27,180 --> 00:24:32,280
on my own machine and localhost but it

00:24:29,640 --> 00:24:34,860
will do four different queries and vote

00:24:32,280 --> 00:24:36,270
with Redis loader it does one query with

00:24:34,860 --> 00:24:38,630
with less because it doesn't ask for

00:24:36,270 --> 00:24:40,770
node twice and it's significantly faster

00:24:38,630 --> 00:24:42,840
when you added real network in there

00:24:40,770 --> 00:24:46,170
maybe you need to multiply this by 10 or

00:24:42,840 --> 00:24:47,670
100 but it's still real fast so even if

00:24:46,170 --> 00:24:50,670
we didn't match I don't think I would

00:24:47,670 --> 00:24:52,230
have noticed for our setup but for most

00:24:50,670 --> 00:24:54,600
databases which maybe it's a couple

00:24:52,230 --> 00:24:55,920
milliseconds between responses you know

00:24:54,600 --> 00:24:58,080
it's a good idea to keep them together

00:24:55,920 --> 00:25:00,030
and this keeps you protected I guess it

00:24:58,080 --> 00:25:01,860
becomes from an N plus 1 2 and plus 1

00:25:00,030 --> 00:25:03,630
divided by you know whatever is a

00:25:01,860 --> 00:25:10,800
reasonable batch size 200 or something

00:25:03,630 --> 00:25:13,170
like that the tooling we use to to put

00:25:10,800 --> 00:25:15,810
to deploy our lambdas right now we're

00:25:13,170 --> 00:25:17,940
using Sammy which uses Amazon Sam this

00:25:15,810 --> 00:25:21,900
serverless application model under the

00:25:17,940 --> 00:25:22,170
hood but Sam is kind of annoying uh I'm

00:25:21,900 --> 00:25:26,460
sorry

00:25:22,170 --> 00:25:28,110
Sam is kind of verbose and so we made a

00:25:26,460 --> 00:25:31,260
little wrapper that helps you know

00:25:28,110 --> 00:25:32,760
generate some useful scripts and so that

00:25:31,260 --> 00:25:35,730
were you Sammy for most of our projects

00:25:32,760 --> 00:25:39,210
I'm really excited about architect I

00:25:35,730 --> 00:25:40,920
find out of our codes and it lets you

00:25:39,210 --> 00:25:41,820
describe the kind of server this

00:25:40,920 --> 00:25:43,830
environment you want

00:25:41,820 --> 00:25:46,710
dynamodb tables there's a little

00:25:43,830 --> 00:25:48,360
prescriptive but it's it's it's super

00:25:46,710 --> 00:25:49,830
straightforward to use and I think it

00:25:48,360 --> 00:25:52,260
makes getting started aflame just super

00:25:49,830 --> 00:25:54,000
easy and of course we built a tool

00:25:52,260 --> 00:25:56,310
called shop which I forgot to put in a

00:25:54,000 --> 00:25:58,700
description but chef is the shepherd for

00:25:56,310 --> 00:26:02,090
your lambdas

00:25:58,700 --> 00:26:03,800
and chef is not prescriptive it just

00:26:02,090 --> 00:26:05,510
sets up like like here's your functions

00:26:03,800 --> 00:26:08,330
in a folder here's a web pack like

00:26:05,510 --> 00:26:11,330
config that works and will will deploy

00:26:08,330 --> 00:26:12,860
stuff and about a second or two and it's

00:26:11,330 --> 00:26:14,360
a fastest way to get something out there

00:26:12,860 --> 00:26:16,160
because it escapes CloudFormation and

00:26:14,360 --> 00:26:17,540
all those other big things that if you

00:26:16,160 --> 00:26:21,320
don't know about yet maybe get in the

00:26:17,540 --> 00:26:24,350
way but it still works it's great we

00:26:21,320 --> 00:26:25,430
just do we we've required more and it's

00:26:24,350 --> 00:26:29,270
easier to go to Sam

00:26:25,430 --> 00:26:31,910
or rather Sammy I think that's all you

00:26:29,270 --> 00:26:34,760
need to get goin I think you could take

00:26:31,910 --> 00:26:36,200
this and if you go to the repo I'd have

00:26:34,760 --> 00:26:37,970
all the code there and you can choose

00:26:36,200 --> 00:26:43,280
one of those deploy tools and you can

00:26:37,970 --> 00:26:45,200
run your API on lambda today Redis

00:26:43,280 --> 00:26:46,580
running Redis you know for Hobby project

00:26:45,200 --> 00:26:48,410
is a little more expensive so you can

00:26:46,580 --> 00:26:50,630
swap that out for anything you want like

00:26:48,410 --> 00:26:55,880
literally anything you want

00:26:50,630 --> 00:26:58,300
so DynamoDB or Postgres you know and it

00:26:55,880 --> 00:27:01,460
will work the same way

00:26:58,300 --> 00:27:03,230
nemesis isn't finished and you can

00:27:01,460 --> 00:27:04,700
totally help and if you have opinions or

00:27:03,230 --> 00:27:06,710
if you think we could achieve this with

00:27:04,700 --> 00:27:08,420
a database that already exists you

00:27:06,710 --> 00:27:08,690
should come and try to convince me of

00:27:08,420 --> 00:27:10,220
that

00:27:08,690 --> 00:27:14,930
because it would be awesome not to build

00:27:10,220 --> 00:27:16,810
anything we have a ton of open-source

00:27:14,930 --> 00:27:19,490
libraries that we use for our stuff

00:27:16,810 --> 00:27:20,420
you'll you we just share them and

00:27:19,490 --> 00:27:23,690
sometimes we sneak them into other

00:27:20,420 --> 00:27:26,780
things but everything from the command

00:27:23,690 --> 00:27:29,570
batching - you know officially storing

00:27:26,780 --> 00:27:31,010
JSON documents of trees to working with

00:27:29,570 --> 00:27:33,170
async iterators which I want to

00:27:31,010 --> 00:27:34,790
completely replace all my streams with -

00:27:33,170 --> 00:27:36,800
using async functions and streams with

00:27:34,790 --> 00:27:38,330
blue stream which which is was our work

00:27:36,800 --> 00:27:42,230
around before I think iterators was the

00:27:38,330 --> 00:27:44,630
place you should check it out

00:27:42,230 --> 00:27:45,920
love love any feedback and help and

00:27:44,630 --> 00:27:48,910
hopefully it makes things working with

00:27:45,920 --> 00:27:51,910
whatever you're doing somewhat easier

00:27:48,910 --> 00:27:51,910
Thanks

00:27:52,230 --> 00:27:54,290

YouTube URL: https://www.youtube.com/watch?v=urohq-WcGWY


