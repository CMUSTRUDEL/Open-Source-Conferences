Title: How to Wait - Max Goodhart | JSConf Hawaii 2020
Publication date: 2020-03-26
Playlist: JSConf HI 2020
Description: 
	Our story begins with a humble 'await fetch': your script fires off an HTTP request and settles down to nap, trusting that it'll be awoken when response data is available. While your program does nothing, a cascade of activity is now taking place: in your JS runtime, your operating system, and your hardware. What happens while your code is waiting for something to happen? In this talk, we'll peek behind the layers of the event loop, select/epoll nonblocking I/O, and hardware architecture to answer a simple question: what is waiting, and how does a program wait?

Slides: https://chromakode.com/m/how-to-wait/

JSConf Hawaii will return soon
https://www.jsconfhi.com/
Captions: 
	00:00:08,160 --> 00:00:13,010
everyone

00:00:11,060 --> 00:00:15,110
our story begins with a humble await

00:00:13,010 --> 00:00:17,150
fetch these two lines of code make an

00:00:15,110 --> 00:00:19,520
HTTP request wait for a response and

00:00:17,150 --> 00:00:21,590
print out the status code while this

00:00:19,520 --> 00:00:23,390
code is waiting a cascade of activity is

00:00:21,590 --> 00:00:26,349
taking place in your JavaScript runtime

00:00:23,390 --> 00:00:28,669
your operating system and your hardware

00:00:26,349 --> 00:00:30,140
in this talk we're going to look at what

00:00:28,669 --> 00:00:31,910
happens between these two lines of code

00:00:30,140 --> 00:00:34,430
and what waiting can teach us about

00:00:31,910 --> 00:00:36,590
software design now you may be thinking

00:00:34,430 --> 00:00:38,120
hold up why do I need to think about the

00:00:36,590 --> 00:00:40,790
stuff while writing JavaScript code and

00:00:38,120 --> 00:00:44,450
more so a hundred feet from a beautiful

00:00:40,790 --> 00:00:46,040
beach well I can sympathize I've

00:00:44,450 --> 00:00:47,480
wrestled with motivating myself to dig

00:00:46,040 --> 00:00:48,950
into these lower level details before

00:00:47,480 --> 00:00:51,380
and I'd like to offer two motivating

00:00:48,950 --> 00:00:53,330
ideas may be enough to get you over the

00:00:51,380 --> 00:00:55,340
post-lunch home first

00:00:53,330 --> 00:00:56,660
this isn't trivia these are real systems

00:00:55,340 --> 00:00:58,520
we use every day while writing

00:00:56,660 --> 00:01:00,950
JavaScript code understanding systems

00:00:58,520 --> 00:01:03,230
teaches us examples of how problems can

00:01:00,950 --> 00:01:04,909
be solved and most importantly it gives

00:01:03,230 --> 00:01:07,900
us the opportunity to identify patterns

00:01:04,909 --> 00:01:10,520
that guide how new systems can be built

00:01:07,900 --> 00:01:12,200
second computers are really complex and

00:01:10,520 --> 00:01:14,180
powerful and that can sometimes make

00:01:12,200 --> 00:01:15,740
them feel magical but much of that

00:01:14,180 --> 00:01:17,719
complexity comes from layer upon layer

00:01:15,740 --> 00:01:20,240
of simple solutions to simple problems

00:01:17,719 --> 00:01:21,890
as JavaScript programmers these problems

00:01:20,240 --> 00:01:23,719
are relatable to us because we live in

00:01:21,890 --> 00:01:25,969
an asynchronous world by understanding

00:01:23,719 --> 00:01:27,289
the problems the lower layers solve we

00:01:25,969 --> 00:01:30,319
can gain a greater confidence in the

00:01:27,289 --> 00:01:31,789
face of this complexity as you'll see a

00:01:30,319 --> 00:01:35,299
lot of that complexity serves a simple

00:01:31,789 --> 00:01:37,880
task how computers wait my name's max

00:01:35,299 --> 00:01:39,590
I'm visiting from San Francisco and I'm

00:01:37,880 --> 00:01:41,539
a developer experience engineer at

00:01:39,590 --> 00:01:43,249
patreon on the first Wednesday of every

00:01:41,539 --> 00:01:44,689
month I co organize a local meetup

00:01:43,249 --> 00:01:48,319
called waffle Jas you can see the logo

00:01:44,689 --> 00:01:50,420
on screen it's a really fun time I work

00:01:48,319 --> 00:01:52,159
with a team of some amazingly talented

00:01:50,420 --> 00:01:54,619
people who I've learned a ton from and

00:01:52,159 --> 00:01:56,450
if you're ever passing through I invite

00:01:54,619 --> 00:01:59,119
you to come join us it's a really fun

00:01:56,450 --> 00:02:02,329
night or come give a talk to talk to me

00:01:59,119 --> 00:02:04,700
after the after this so back to waiting

00:02:02,329 --> 00:02:06,109
waiting is kind of a strange concept and

00:02:04,700 --> 00:02:08,149
it was difficult for me to like nail

00:02:06,109 --> 00:02:10,670
down in writing this talk because we

00:02:08,149 --> 00:02:12,620
rarely do it we spend as little time

00:02:10,670 --> 00:02:13,850
waiting as humanly possible if I ask you

00:02:12,620 --> 00:02:17,300
to wait for something you're gonna

00:02:13,850 --> 00:02:19,069
switch to something else to do so our

00:02:17,300 --> 00:02:21,080
use of the word wait is usually in the

00:02:19,069 --> 00:02:22,430
context of a set of instructions to do

00:02:21,080 --> 00:02:24,590
something and when there's some

00:02:22,430 --> 00:02:24,950
dependency in that process we have to

00:02:24,590 --> 00:02:26,510
wait for

00:02:24,950 --> 00:02:28,099
our progress into the pillow progress is

00:02:26,510 --> 00:02:30,080
no longer blocked by the way thanks

00:02:28,099 --> 00:02:33,500
Andres for the cute spaghetti image on

00:02:30,080 --> 00:02:35,239
this slide good recipes take advantage

00:02:33,500 --> 00:02:36,950
of the idle time by interleaving

00:02:35,239 --> 00:02:38,720
processes while you're blocked on one

00:02:36,950 --> 00:02:41,319
thing you can start on another this is a

00:02:38,720 --> 00:02:43,489
great analogy to how computers multitask

00:02:41,319 --> 00:02:44,780
except computers have thousands of

00:02:43,489 --> 00:02:46,640
different processes they're carrying out

00:02:44,780 --> 00:02:48,349
at any given time and unlike most

00:02:46,640 --> 00:02:51,349
recipes the order in which things can

00:02:48,349 --> 00:02:52,790
happen is unpredictable as programmers

00:02:51,349 --> 00:02:54,379
we like to think in terms of sequential

00:02:52,790 --> 00:02:56,390
steps because it makes our codes simple

00:02:54,379 --> 00:02:58,640
to reason about you make an HTTP request

00:02:56,390 --> 00:03:00,620
then you wait for the response then you

00:02:58,640 --> 00:03:02,360
print out the status this is why async

00:03:00,620 --> 00:03:04,400
await style programming is so useful it

00:03:02,360 --> 00:03:07,160
lets us express steps in a clear and

00:03:04,400 --> 00:03:09,410
linear order waiting makes that possible

00:03:07,160 --> 00:03:11,900
it's the glue that allows us to express

00:03:09,410 --> 00:03:13,370
a series of separate events linearly but

00:03:11,900 --> 00:03:14,840
when we say to wait we expect that the

00:03:13,370 --> 00:03:16,489
human or computer on the other side is

00:03:14,840 --> 00:03:19,400
going to find something else to do in

00:03:16,489 --> 00:03:21,769
the meantime this is a behavior we have

00:03:19,400 --> 00:03:23,540
to design into our computers let's dive

00:03:21,769 --> 00:03:25,010
into the mechanisms of how this works

00:03:23,540 --> 00:03:27,560
starting with a simple microprocessor

00:03:25,010 --> 00:03:29,660
for simplicity I'm going to focus on a

00:03:27,560 --> 00:03:30,889
single core CPU that means it can only

00:03:29,660 --> 00:03:32,690
do one thing at a time

00:03:30,889 --> 00:03:34,579
Rich's talk which is immediately after

00:03:32,690 --> 00:03:35,959
this at around 1:30 is going to cover

00:03:34,579 --> 00:03:38,299
threading which takes advantage of

00:03:35,959 --> 00:03:41,480
modern CPUs having multiple concurrent

00:03:38,299 --> 00:03:43,280
course so back to the CPU we're gonna

00:03:41,480 --> 00:03:45,709
start with a simple sub component called

00:03:43,280 --> 00:03:47,480
the clock the clock periodically pulses

00:03:45,709 --> 00:03:49,430
an electrical signal on and off and this

00:03:47,480 --> 00:03:52,010
is what it drives instruction execution

00:03:49,430 --> 00:03:53,480
in your CPU in modern CPUs we measure

00:03:52,010 --> 00:03:55,220
the frequency of the clock in gigahertz

00:03:53,480 --> 00:03:57,680
meaning the clock is oscillating

00:03:55,220 --> 00:03:59,540
billions of times per second from a

00:03:57,680 --> 00:04:01,310
reductionist point of view every single

00:03:59,540 --> 00:04:03,590
thing a computer does or waits for

00:04:01,310 --> 00:04:06,799
begins at one clock cycle and ends with

00:04:03,590 --> 00:04:08,209
another by programming a microprocessor

00:04:06,799 --> 00:04:10,160
we can implement a simple kind of

00:04:08,209 --> 00:04:11,630
waiting called busy waiting this is a

00:04:10,160 --> 00:04:13,370
loop where each cycle we check the

00:04:11,630 --> 00:04:14,750
condition we're waiting for if you want

00:04:13,370 --> 00:04:16,340
to do other things while we wait though

00:04:14,750 --> 00:04:17,989
we kind of have to intersperse them in

00:04:16,340 --> 00:04:20,419
this wait loop and that increases the

00:04:17,989 --> 00:04:22,070
time between checks as a number of

00:04:20,419 --> 00:04:23,810
things we want to wait for increases

00:04:22,070 --> 00:04:25,310
this loop becomes less and less

00:04:23,810 --> 00:04:29,870
efficient because you're checking more

00:04:25,310 --> 00:04:31,669
things each type you cycle that's where

00:04:29,870 --> 00:04:33,500
interrupts come in interrupt signal the

00:04:31,669 --> 00:04:34,849
CPU when something happens such as your

00:04:33,500 --> 00:04:36,950
network interface receiving data a

00:04:34,849 --> 00:04:38,200
keyboard key being pressed or timer

00:04:36,950 --> 00:04:40,460
elapsing

00:04:38,200 --> 00:04:42,590
when a processor receives an interrupt

00:04:40,460 --> 00:04:44,180
it pauses what's currently running saves

00:04:42,590 --> 00:04:45,380
the execution State and switches to

00:04:44,180 --> 00:04:47,419
different code called an interrupt

00:04:45,380 --> 00:04:49,160
handler the interrupt handler takes any

00:04:47,419 --> 00:04:51,770
immediate actions necessary and then

00:04:49,160 --> 00:04:53,389
determines how to proceed forward the

00:04:51,770 --> 00:04:55,610
code that implements interrupt handlers

00:04:53,389 --> 00:04:57,110
is part of your operating system the OS

00:04:55,610 --> 00:04:58,520
makes it possible to write higher-level

00:04:57,110 --> 00:04:59,960
programs that don't have to worry about

00:04:58,520 --> 00:05:02,360
interrupt handling and communication

00:04:59,960 --> 00:05:03,800
with hardware the OS governs switching

00:05:02,360 --> 00:05:05,210
between which programs are running so

00:05:03,800 --> 00:05:08,440
that multiple programs can take turns

00:05:05,210 --> 00:05:11,120
sharing a CPU this is called scheduling

00:05:08,440 --> 00:05:12,979
the operating system also provides api's

00:05:11,120 --> 00:05:14,210
for i/o called system calls for things

00:05:12,979 --> 00:05:16,550
like writing the files and sending

00:05:14,210 --> 00:05:18,410
packets in Linux most kinds of i/o is

00:05:16,550 --> 00:05:21,100
represented as operations on streams of

00:05:18,410 --> 00:05:23,930
bytes here's a couple examples on-screen

00:05:21,100 --> 00:05:25,370
IO takes time though you know disks take

00:05:23,930 --> 00:05:27,380
time to perform operations network

00:05:25,370 --> 00:05:29,180
devices take time to transfer data when

00:05:27,380 --> 00:05:30,770
a program is performing i/o it often

00:05:29,180 --> 00:05:32,840
wants to wait until that IO is completed

00:05:30,770 --> 00:05:34,580
so a simple model for this is called

00:05:32,840 --> 00:05:36,770
blocking i/o while the program is

00:05:34,580 --> 00:05:38,870
waiting for an i/o operation we say that

00:05:36,770 --> 00:05:41,030
the calling program blocks until that IO

00:05:38,870 --> 00:05:42,800
completes once the OS receives an

00:05:41,030 --> 00:05:44,630
interrupt that the AI is completed the

00:05:42,800 --> 00:05:48,020
process is queued to be resumed by the

00:05:44,630 --> 00:05:49,669
scheduler while that process is blocked

00:05:48,020 --> 00:05:51,789
the OS scheduler can run something else

00:05:49,669 --> 00:05:54,289
in the meantime

00:05:51,789 --> 00:05:55,789
simple blocking i/o system calls only

00:05:54,289 --> 00:05:57,229
wait for one thing at a time though if

00:05:55,789 --> 00:05:58,820
we want to wait for multiple things

00:05:57,229 --> 00:06:00,560
we're gonna need some more tools the

00:05:58,820 --> 00:06:03,470
operating systems provide non blocking

00:06:00,560 --> 00:06:04,850
versions of many i/o calls for this when

00:06:03,470 --> 00:06:06,200
you open a file or network connection

00:06:04,850 --> 00:06:08,570
the OS returns a number that identifies

00:06:06,200 --> 00:06:10,639
the stream called a file descriptor you

00:06:08,570 --> 00:06:12,500
can use that FD to reference the stream

00:06:10,639 --> 00:06:14,990
and other system calls so in this

00:06:12,500 --> 00:06:16,520
example if an operation would block the

00:06:14,990 --> 00:06:18,800
non blocking read returns an error

00:06:16,520 --> 00:06:20,450
instead if we get an error indicating

00:06:18,800 --> 00:06:22,039
the read would block that means there's

00:06:20,450 --> 00:06:23,930
no late data left in the buffer for us

00:06:22,039 --> 00:06:26,270
to read so instead we can find something

00:06:23,930 --> 00:06:27,800
else to do instead of pausing execution

00:06:26,270 --> 00:06:29,300
this leaves our process running so we

00:06:27,800 --> 00:06:32,600
get to decide what to do instead of

00:06:29,300 --> 00:06:34,010
blocking non-blocking i/o calls can also

00:06:32,600 --> 00:06:36,320
be used to wait for multiple things at a

00:06:34,010 --> 00:06:37,729
time for example we can loop over a set

00:06:36,320 --> 00:06:39,770
of file descriptors and try to read from

00:06:37,729 --> 00:06:41,120
each of them if there's no data to read

00:06:39,770 --> 00:06:41,810
we continue on to the next file

00:06:41,120 --> 00:06:43,789
descriptor

00:06:41,810 --> 00:06:45,680
however now we're back to essentially

00:06:43,789 --> 00:06:47,240
busy waiting what we really want to do

00:06:45,680 --> 00:06:49,099
is block on a set of things that could

00:06:47,240 --> 00:06:51,229
happen resuming when any one of them

00:06:49,099 --> 00:06:51,980
does operating systems provide event

00:06:51,229 --> 00:06:55,190
based system call

00:06:51,980 --> 00:06:57,230
for this a simple one is called select

00:06:55,190 --> 00:06:58,820
select is given three sets of file

00:06:57,230 --> 00:07:01,100
descriptors one for each kind of event

00:06:58,820 --> 00:07:03,680
stream is ready to read streams ready to

00:07:01,100 --> 00:07:05,750
write and streams with errors the Select

00:07:03,680 --> 00:07:07,730
call then blocks until an event happens

00:07:05,750 --> 00:07:09,950
or a specified amount of time elapses it

00:07:07,730 --> 00:07:11,480
then returns to the programmer which

00:07:09,950 --> 00:07:14,510
file descriptors can be read to written

00:07:11,480 --> 00:07:17,530
to or have errors so here's a really

00:07:14,510 --> 00:07:20,210
simplified example of how select works

00:07:17,530 --> 00:07:21,800
we pass a set of file descriptors we're

00:07:20,210 --> 00:07:23,450
interested in reading from and then it

00:07:21,800 --> 00:07:26,630
blocks until one or many of them becomes

00:07:23,450 --> 00:07:28,010
readable when select returns it gives us

00:07:26,630 --> 00:07:30,110
the list of files that now have data

00:07:28,010 --> 00:07:33,470
available and we can loop over them and

00:07:30,110 --> 00:07:35,000
read from them without blocking each

00:07:33,470 --> 00:07:36,650
operating system provides a slightly

00:07:35,000 --> 00:07:38,660
different modern implementation of a

00:07:36,650 --> 00:07:41,240
venture of an i/o though linux this is

00:07:38,660 --> 00:07:43,940
called eople mac OS and bsd fkq and

00:07:41,240 --> 00:07:45,860
Windows has iocp to write cross-platform

00:07:43,940 --> 00:07:48,500
software we have to implement different

00:07:45,860 --> 00:07:50,270
i/o code for each one some programs do

00:07:48,500 --> 00:07:51,800
that but many others use libraries that

00:07:50,270 --> 00:07:55,490
abstract over the differences between

00:07:51,800 --> 00:07:57,740
these api's this is where libuv comes in

00:07:55,490 --> 00:07:59,570
Lybia v abstract so ver the varying

00:07:57,740 --> 00:08:01,460
implementations of event-driven i/o in

00:07:59,570 --> 00:08:03,650
different operating systems and provides

00:08:01,460 --> 00:08:05,060
a common interface for them Libby V is

00:08:03,650 --> 00:08:06,980
used by node which we'll be using as our

00:08:05,060 --> 00:08:08,870
example JavaScript runtime in the future

00:08:06,980 --> 00:08:10,250
of these slides I'm guessing there may

00:08:08,870 --> 00:08:12,380
be a few Lybia V developers in the

00:08:10,250 --> 00:08:14,920
audience today if you can find one of

00:08:12,380 --> 00:08:17,270
them give them a high-five for me okay

00:08:14,920 --> 00:08:19,160
Libby Vee lets you perform network and

00:08:17,270 --> 00:08:21,080
file operations and register callbacks

00:08:19,160 --> 00:08:22,520
and events happen Libby Vee uses the

00:08:21,080 --> 00:08:24,380
operating systems event-driven i/o

00:08:22,520 --> 00:08:25,340
constructs to wait for events and when

00:08:24,380 --> 00:08:27,020
something happens

00:08:25,340 --> 00:08:28,940
Libby P then executes the registered

00:08:27,020 --> 00:08:30,320
callbacks and resumes waiting this is

00:08:28,940 --> 00:08:32,630
called an event loop and here's an

00:08:30,320 --> 00:08:34,820
example to make a network connection

00:08:32,630 --> 00:08:37,010
we initialize what libuv calls a handle

00:08:34,820 --> 00:08:39,530
which represents some kind of i/o object

00:08:37,010 --> 00:08:41,120
we can perform operations on when we

00:08:39,530 --> 00:08:42,680
open the network connection we pass

00:08:41,120 --> 00:08:44,300
Libby via callback to run when the

00:08:42,680 --> 00:08:46,310
connection is established this is very

00:08:44,300 --> 00:08:47,810
familiar if you're used to like running

00:08:46,310 --> 00:08:50,420
JavaScript code and assigning callbacks

00:08:47,810 --> 00:08:52,190
when things complete to read data from

00:08:50,420 --> 00:08:53,390
the connection we need to tell we BV to

00:08:52,190 --> 00:08:55,520
track when the connection becomes

00:08:53,390 --> 00:08:56,930
readable we provide a read callback

00:08:55,520 --> 00:08:58,940
which will be called with the data as it

00:08:56,930 --> 00:09:00,890
becomes available and then the last

00:08:58,940 --> 00:09:02,930
thing we need to do is run the bv event

00:09:00,890 --> 00:09:04,930
loop this is going to block until the

00:09:02,930 --> 00:09:08,980
next IO event we're interested in happen

00:09:04,930 --> 00:09:11,410
and call the related callback for us no

00:09:08,980 --> 00:09:14,080
js' is implemented on top of this Libya

00:09:11,410 --> 00:09:16,480
via vent loop and when J s uses a node

00:09:14,080 --> 00:09:18,370
API to perform IO under the hood notice

00:09:16,480 --> 00:09:20,649
calling libuv to perform it and then

00:09:18,370 --> 00:09:22,029
when IO events happen node runs the

00:09:20,649 --> 00:09:27,070
callbacks or triggers events in

00:09:22,029 --> 00:09:28,720
JavaScript so that was a lot now that we

00:09:27,070 --> 00:09:31,810
have our cast of characters let's return

00:09:28,720 --> 00:09:33,610
to our code in order to make an HTTP

00:09:31,810 --> 00:09:35,170
request we have to perform several

00:09:33,610 --> 00:09:37,750
network operations including looking up

00:09:35,170 --> 00:09:39,880
the host name opening a socket sending

00:09:37,750 --> 00:09:42,100
an HTTP request and receiving data I'm

00:09:39,880 --> 00:09:43,810
going to gloss over many of those steps

00:09:42,100 --> 00:09:45,490
so we can just look at a single walk

00:09:43,810 --> 00:09:49,360
through the layers as we establish a

00:09:45,490 --> 00:09:53,290
socket connection so let's dive in and

00:09:49,360 --> 00:09:57,040
break this down let's start with the

00:09:53,290 --> 00:09:59,589
fetch call fetch uses nodes HTTP module

00:09:57,040 --> 00:10:01,149
to start the request it then returns a

00:09:59,589 --> 00:10:03,370
promise that represents the pending

00:10:01,149 --> 00:10:05,230
value of the fetch response our

00:10:03,370 --> 00:10:07,870
JavaScript awaits the response from the

00:10:05,230 --> 00:10:09,700
fetch this tells node to pause and save

00:10:07,870 --> 00:10:11,500
the JavaScript state and then switch to

00:10:09,700 --> 00:10:13,839
running up other queued up JavaScript

00:10:11,500 --> 00:10:16,360
code we're gonna skip over looking up

00:10:13,839 --> 00:10:19,240
the IP address here and go straight to

00:10:16,360 --> 00:10:22,029
opening a connection so node uses libuv

00:10:19,240 --> 00:10:23,860
to open a connection to jcsoh I calm and

00:10:22,029 --> 00:10:26,320
accuse up a callback to run when the

00:10:23,860 --> 00:10:28,330
connections established to accomplish

00:10:26,320 --> 00:10:31,360
this libuv tells linux to make the

00:10:28,330 --> 00:10:33,550
connection at this point if node has no

00:10:31,360 --> 00:10:35,200
more JavaScript to run it then calls

00:10:33,550 --> 00:10:36,910
into Libby V's event loop which will

00:10:35,200 --> 00:10:40,240
wait for the next i/o event so now no

00:10:36,910 --> 00:10:42,430
js' is waiting under the hood libuv is

00:10:40,240 --> 00:10:45,520
using the Linux pull API to track these

00:10:42,430 --> 00:10:46,959
i/o events libuv tells Linux it's

00:10:45,520 --> 00:10:49,779
interested in when the socket becomes

00:10:46,959 --> 00:10:51,820
writable then libuv waits as well

00:10:49,779 --> 00:10:54,970
locking until a timeout or the next

00:10:51,820 --> 00:10:56,380
event happens in the meantime Linux is

00:10:54,970 --> 00:10:58,270
Network stack is busy making the

00:10:56,380 --> 00:11:00,100
connection this involves the operating

00:10:58,270 --> 00:11:01,990
system Network driver sending data and

00:11:00,100 --> 00:11:04,089
the CPU transferring that data to the

00:11:01,990 --> 00:11:05,649
network device while we wait for a

00:11:04,089 --> 00:11:07,140
response the operating system is going

00:11:05,649 --> 00:11:09,459
to switch to running other things

00:11:07,140 --> 00:11:10,690
eventually though the CPU will receive

00:11:09,459 --> 00:11:12,310
an interrupt that we're interested in

00:11:10,690 --> 00:11:15,250
that the network device has received

00:11:12,310 --> 00:11:17,110
data this interrupt will cause the

00:11:15,250 --> 00:11:18,710
operating system Network driver to read

00:11:17,110 --> 00:11:20,630
the data from the network interface

00:11:18,710 --> 00:11:21,950
and then this is going to continue back

00:11:20,630 --> 00:11:24,200
and forth for a while until the

00:11:21,950 --> 00:11:25,910
connection is totally established at

00:11:24,200 --> 00:11:27,950
this point the connection socket becomes

00:11:25,910 --> 00:11:30,110
ready to write which is what libuv is

00:11:27,950 --> 00:11:32,060
waiting for Libya V execute any

00:11:30,110 --> 00:11:33,920
callbacks waiting on file descriptors

00:11:32,060 --> 00:11:35,510
that became ready and it just so happens

00:11:33,920 --> 00:11:37,760
that we have one from node waiting for

00:11:35,510 --> 00:11:39,410
the connection to be established once

00:11:37,760 --> 00:11:41,270
we've finished processing all waiting

00:11:39,410 --> 00:11:43,360
callbacks we finished our first

00:11:41,270 --> 00:11:45,350
iteration of the Libya v event loop

00:11:43,360 --> 00:11:46,400
there's going to be like a couple other

00:11:45,350 --> 00:11:48,320
things that happen here that I'm

00:11:46,400 --> 00:11:50,390
glossing over there's several similar

00:11:48,320 --> 00:11:52,030
back and forth that we've seen like

00:11:50,390 --> 00:11:54,980
starting a secure TLS connection

00:11:52,030 --> 00:11:56,330
handshake and actually making the HTTP

00:11:54,980 --> 00:11:59,140
request we're gonna go out skip over

00:11:56,330 --> 00:12:02,000
them here but when that's all finished

00:11:59,140 --> 00:12:04,520
nodes HTTP module is going to emit a

00:12:02,000 --> 00:12:06,020
response event this is what our fetch

00:12:04,520 --> 00:12:09,100
promise that we initially made is

00:12:06,020 --> 00:12:11,990
waiting for when the promise resolves

00:12:09,100 --> 00:12:13,730
the wait is now ready to resume so node

00:12:11,990 --> 00:12:20,150
execute our next line of JavaScript code

00:12:13,730 --> 00:12:22,340
printing out the response code that was

00:12:20,150 --> 00:12:24,950
a lot to digest huh let's look at the

00:12:22,340 --> 00:12:27,410
key parts in one picture so your

00:12:24,950 --> 00:12:29,600
JavaScript code awaits a promise no js'

00:12:27,410 --> 00:12:31,700
accomplishes this by pausing execution

00:12:29,600 --> 00:12:33,680
until the promise resolves under the

00:12:31,700 --> 00:12:36,140
hood node lit uses libuv

00:12:33,680 --> 00:12:38,420
to queue up network operations Libby Vee

00:12:36,140 --> 00:12:40,070
uses the Linux Ipoh API to listen for

00:12:38,420 --> 00:12:43,460
events when the network connection is

00:12:40,070 --> 00:12:45,140
ready so I told you I was gonna explain

00:12:43,460 --> 00:12:47,120
how to wait but like we're in this

00:12:45,140 --> 00:12:48,710
process are we actually waiting and how

00:12:47,120 --> 00:12:51,020
does the waiting happen let's break this

00:12:48,710 --> 00:12:52,220
down a little bit more the first three

00:12:51,020 --> 00:12:54,740
steps are essentially creating

00:12:52,220 --> 00:12:56,780
information when the request finishes

00:12:54,740 --> 00:12:58,640
resumed my JavaScript code when the

00:12:56,780 --> 00:13:00,980
connection is established run my libuv

00:12:58,640 --> 00:13:02,420
callback we're not waiting here we're

00:13:00,980 --> 00:13:04,010
really just defining relationships

00:13:02,420 --> 00:13:06,770
between what we're waiting for and what

00:13:04,010 --> 00:13:08,870
to do when it's ready in contrast the

00:13:06,770 --> 00:13:11,090
operating system in CPU are responding

00:13:08,870 --> 00:13:13,030
to real world events and executing the

00:13:11,090 --> 00:13:15,230
code that's queued up waiting for them

00:13:13,030 --> 00:13:17,410
let's recap and summarize what's

00:13:15,230 --> 00:13:20,240
happening when our JavaScript code waits

00:13:17,410 --> 00:13:22,490
together our JavaScript code nodejs and

00:13:20,240 --> 00:13:24,890
Libby Vee are performing i/o and queuing

00:13:22,490 --> 00:13:27,100
up handling the responses when this iowa

00:13:24,890 --> 00:13:30,260
event happens run this javascript code

00:13:27,100 --> 00:13:31,790
the OS juggles incoming i/o events and

00:13:30,260 --> 00:13:32,450
runs processes as soon as they become

00:13:31,790 --> 00:13:34,370
unblocked

00:13:32,450 --> 00:13:35,839
the CPU is busy executing these

00:13:34,370 --> 00:13:38,529
instructions and then it gets

00:13:35,839 --> 00:13:40,760
interrupted as real-world events happen

00:13:38,529 --> 00:13:42,889
intuitively this is similar to how

00:13:40,760 --> 00:13:44,540
humans wait we keep track of something

00:13:42,889 --> 00:13:46,250
we're waiting for and do things that

00:13:44,540 --> 00:13:47,630
were not blocked on until something

00:13:46,250 --> 00:13:49,029
interrupts us and there's something new

00:13:47,630 --> 00:13:51,769
to do

00:13:49,029 --> 00:13:53,690
so far we've thought of CPUs in terms of

00:13:51,769 --> 00:13:55,639
being a black box that just does i/o for

00:13:53,690 --> 00:13:57,260
us but modern CPUs are really

00:13:55,639 --> 00:13:59,360
interesting they can actually perform

00:13:57,260 --> 00:14:00,980
many async operations in themselves that

00:13:59,360 --> 00:14:04,130
will be pretty familiar to you as a

00:14:00,980 --> 00:14:05,899
JavaScript programmer modern CPUs

00:14:04,130 --> 00:14:08,570
offload data transfers using something

00:14:05,899 --> 00:14:10,190
called DMA direct memory access this is

00:14:08,570 --> 00:14:11,750
a subsystem that transfers data between

00:14:10,190 --> 00:14:14,089
devices and memory in the background

00:14:11,750 --> 00:14:16,010
when a transfer finishes the CPU gets

00:14:14,089 --> 00:14:18,110
notified B an interrupt think of it like

00:14:16,010 --> 00:14:19,820
a callback in JavaScript the CPU makes a

00:14:18,110 --> 00:14:21,649
DMA request it transfers in the

00:14:19,820 --> 00:14:24,800
background and then later on the CPU is

00:14:21,649 --> 00:14:26,660
notified when it completes CPUs can also

00:14:24,800 --> 00:14:28,279
set timers to trigger in an interrupt

00:14:26,660 --> 00:14:30,260
and a specified time using the high

00:14:28,279 --> 00:14:31,639
precision event timer this is really

00:14:30,260 --> 00:14:33,649
analogous to set timeout and set

00:14:31,639 --> 00:14:35,540
interval in JavaScript the CPU can set

00:14:33,649 --> 00:14:37,640
background triggers to fire after some

00:14:35,540 --> 00:14:39,529
time has passed so as you can see like

00:14:37,640 --> 00:14:41,209
as JavaScript programmers we're really

00:14:39,529 --> 00:14:43,010
familiar with asynchronous callbacks and

00:14:41,209 --> 00:14:45,709
set timeout and set interval the CPU can

00:14:43,010 --> 00:14:46,490
do all of this so when work is happening

00:14:45,709 --> 00:14:48,290
in the background

00:14:46,490 --> 00:14:49,850
sometimes the CPU actually doesn't have

00:14:48,290 --> 00:14:52,130
anything to do there's no interrupt

00:14:49,850 --> 00:14:54,260
instruction that needs to be run before

00:14:52,130 --> 00:14:57,019
the next interrupt so how does the CPU

00:14:54,260 --> 00:14:58,880
wait the first thing CPUs can do is

00:14:57,019 --> 00:15:00,620
lower their clock speed this reduces the

00:14:58,880 --> 00:15:02,209
amount of power the CPU consumes and the

00:15:00,620 --> 00:15:05,240
amount of heat it generates at the cost

00:15:02,209 --> 00:15:07,040
of slower execution the second thing

00:15:05,240 --> 00:15:09,350
CPUs can do is progressively turn

00:15:07,040 --> 00:15:11,300
themselves off in a modern until our AMD

00:15:09,350 --> 00:15:13,640
CPU a core can issue a halt instruction

00:15:11,300 --> 00:15:15,319
this will cause the CPU to stop its

00:15:13,640 --> 00:15:17,329
executing instructions until an

00:15:15,319 --> 00:15:18,769
interrupt is received this allows the

00:15:17,329 --> 00:15:20,420
CPU to power parts of itself off

00:15:18,769 --> 00:15:23,839
resulting in a significant energy

00:15:20,420 --> 00:15:25,610
savings as an aside this is one reason

00:15:23,839 --> 00:15:27,829
why requestanimationframe is useful

00:15:25,610 --> 00:15:29,630
requestanimationframe is used by

00:15:27,829 --> 00:15:31,850
front-end JavaScript code to schedule

00:15:29,630 --> 00:15:33,139
animation timers as you can probably see

00:15:31,850 --> 00:15:35,389
I think animations are awesome

00:15:33,139 --> 00:15:37,399
personally but to save battery we should

00:15:35,389 --> 00:15:39,589
use them sparingly requestanimationframe

00:15:37,399 --> 00:15:41,360
can reduce the frequency of animations

00:15:39,589 --> 00:15:42,620
or skip them entirely to save battery

00:15:41,360 --> 00:15:44,660
which enables 2cp

00:15:42,620 --> 00:15:46,220
enable CPUs to enter powered off sleep

00:15:44,660 --> 00:15:48,240
states

00:15:46,220 --> 00:15:50,329
if we look at how weighting is

00:15:48,240 --> 00:15:52,709
implemented at each layer of the stack

00:15:50,329 --> 00:15:54,290
what we're trying to accomplish and how

00:15:52,709 --> 00:15:57,300
we accomplish it bears a resemblance

00:15:54,290 --> 00:15:58,980
each of node libby v and the OS

00:15:57,300 --> 00:16:02,250
scheduler consume incoming notifications

00:15:58,980 --> 00:16:04,050
that something happened they then

00:16:02,250 --> 00:16:09,240
dispatch handlers to respond to each

00:16:04,050 --> 00:16:11,579
incoming event when there's nothing left

00:16:09,240 --> 00:16:13,709
to do the loop sleeps until new events

00:16:11,579 --> 00:16:15,720
are available in a nutshell we're

00:16:13,709 --> 00:16:18,000
running in a loop we consume a queue of

00:16:15,720 --> 00:16:19,980
incoming events and then wait until more

00:16:18,000 --> 00:16:22,680
ready for us this is where the named

00:16:19,980 --> 00:16:24,899
event loop comes from so for example the

00:16:22,680 --> 00:16:27,149
nodejs event loop is consuming libuv

00:16:24,899 --> 00:16:29,399
callbacks it runs a queue of JavaScript

00:16:27,149 --> 00:16:30,990
callbacks and then it pauses and blocks

00:16:29,399 --> 00:16:33,690
the process essentially to wait for the

00:16:30,990 --> 00:16:35,940
next limit V callback the contrasts the

00:16:33,690 --> 00:16:37,350
Linux scheduler it's it's it's not

00:16:35,940 --> 00:16:38,940
exactly the same because Linux

00:16:37,350 --> 00:16:40,940
schedulers actually always executing

00:16:38,940 --> 00:16:43,800
something and it's getting interrupted

00:16:40,940 --> 00:16:45,690
but those interrupts come in they get

00:16:43,800 --> 00:16:47,640
stored and queued up and then the Linux

00:16:45,690 --> 00:16:50,310
scheduler runs a Q the Q of unblock

00:16:47,640 --> 00:16:51,890
processes and then it'll continue on its

00:16:50,310 --> 00:16:54,180
way until the next interrupt comes along

00:16:51,890 --> 00:16:56,010
and maybe if there's absolutely nothing

00:16:54,180 --> 00:16:57,959
to do the Linux scheduler will issue a

00:16:56,010 --> 00:17:01,410
halt instruction which will turn off the

00:16:57,959 --> 00:17:03,480
CPU or turn off parts of it if you

00:17:01,410 --> 00:17:05,069
squint both the operating system and no

00:17:03,480 --> 00:17:07,620
GS appear to be doing kind of similar

00:17:05,069 --> 00:17:09,650
things here the operating system enables

00:17:07,620 --> 00:17:12,569
programmers to write linear blocking i/o

00:17:09,650 --> 00:17:14,459
whereas nodejs enables developers to

00:17:12,569 --> 00:17:16,949
write sequences of i/o using callbacks

00:17:14,459 --> 00:17:19,049
or a sync await code both the operating

00:17:16,949 --> 00:17:21,120
system scheduler and nodejs is event

00:17:19,049 --> 00:17:23,850
loop allow multiple sequences of code to

00:17:21,120 --> 00:17:25,380
be interleaved one big difference

00:17:23,850 --> 00:17:27,449
between these two systems is that the

00:17:25,380 --> 00:17:29,970
operating system implements pre-emptive

00:17:27,449 --> 00:17:32,400
multitasking if a CPU interrupt occurs

00:17:29,970 --> 00:17:33,929
while a process is running the OS make

00:17:32,400 --> 00:17:35,610
pause the process and switch to another

00:17:33,929 --> 00:17:37,350
in addition the operating system

00:17:35,610 --> 00:17:39,299
scheduler uses a timer so it can

00:17:37,350 --> 00:17:41,130
regularly interrupt processes so that

00:17:39,299 --> 00:17:44,400
each gets its phone share fair share of

00:17:41,130 --> 00:17:46,950
the CPU time in contrast JavaScript

00:17:44,400 --> 00:17:49,200
runtimes interrupt implement cooperative

00:17:46,950 --> 00:17:50,760
multitasking this means that the runtime

00:17:49,200 --> 00:17:53,010
will not interrupt any running

00:17:50,760 --> 00:17:54,720
JavaScript code the event loop only runs

00:17:53,010 --> 00:17:57,960
in the spaces between JavaScript

00:17:54,720 --> 00:17:58,980
execution your JS can and will delay the

00:17:57,960 --> 00:18:00,960
event loop from pan

00:17:58,980 --> 00:18:02,549
events this is actually a deliberate

00:18:00,960 --> 00:18:04,230
design choice and it provides some

00:18:02,549 --> 00:18:06,150
advantages to JavaScript programmers

00:18:04,230 --> 00:18:08,429
while javascript code is running

00:18:06,150 --> 00:18:10,380
incoming i/o can't interrupt or change

00:18:08,429 --> 00:18:11,760
the state of the JavaScript world this

00:18:10,380 --> 00:18:14,190
also gives JavaScript code the ability

00:18:11,760 --> 00:18:17,309
to choose exactly when it wants to yield

00:18:14,190 --> 00:18:19,559
to the event loop then why do we need

00:18:17,309 --> 00:18:22,980
the OS layer at all wouldn't our code be

00:18:19,559 --> 00:18:24,720
more efficient without it potentially

00:18:22,980 --> 00:18:27,090
you could do that but what you lose is

00:18:24,720 --> 00:18:28,530
generalism our computers are typically

00:18:27,090 --> 00:18:30,480
doing much more than just running our

00:18:28,530 --> 00:18:32,309
JavaScript code and not all software is

00:18:30,480 --> 00:18:33,990
written in JavaScript however it is

00:18:32,309 --> 00:18:35,910
possible to eliminate the OS layer

00:18:33,990 --> 00:18:38,100
entirely and build runtimes that operate

00:18:35,910 --> 00:18:39,600
directly on the CPU and hardware these

00:18:38,100 --> 00:18:41,490
are called Yuna kernels some are

00:18:39,600 --> 00:18:44,580
research projects some are more actually

00:18:41,490 --> 00:18:45,870
used in production in general though we

00:18:44,580 --> 00:18:47,520
want our computers to be able to run

00:18:45,870 --> 00:18:49,290
many different kinds of software at once

00:18:47,520 --> 00:18:54,120
and that's where an extra layer of

00:18:49,290 --> 00:18:56,429
operating system comes in handy what if

00:18:54,120 --> 00:18:58,080
instead we eliminated the event loop and

00:18:56,429 --> 00:19:00,150
just let the operating system schedule

00:18:58,080 --> 00:19:01,530
blocking i/o why do we need the event

00:19:00,150 --> 00:19:05,130
loop at all can we just run a lot of

00:19:01,530 --> 00:19:07,830
processes the answer lies in economies

00:19:05,130 --> 00:19:10,860
of scale each operating system process

00:19:07,830 --> 00:19:12,600
has overhead processes take up memory it

00:19:10,860 --> 00:19:14,549
also takes time to switch between them

00:19:12,600 --> 00:19:17,340
while we save and restore the execution

00:19:14,549 --> 00:19:19,140
state by using a venture of an i/o and

00:19:17,340 --> 00:19:20,790
an event loop a single process can

00:19:19,140 --> 00:19:23,280
manage a vast number of async IO

00:19:20,790 --> 00:19:25,169
operations in bulk overhead is lower

00:19:23,280 --> 00:19:27,030
because the single process can use more

00:19:25,169 --> 00:19:29,040
compact data structures for keeping

00:19:27,030 --> 00:19:31,230
track of state the event loop can also

00:19:29,040 --> 00:19:32,669
exert finer grained control over the

00:19:31,230 --> 00:19:34,350
priority in which it handles different

00:19:32,669 --> 00:19:36,419
events compared to the operating systems

00:19:34,350 --> 00:19:37,980
more generic scheduler the operating

00:19:36,419 --> 00:19:40,580
system knows much less about what we're

00:19:37,980 --> 00:19:42,390
doing but this is a JavaScript talk and

00:19:40,580 --> 00:19:44,130
what does this all have to do with

00:19:42,390 --> 00:19:45,679
JavaScript and what does it have to do

00:19:44,130 --> 00:19:48,570
with waiting

00:19:45,679 --> 00:19:50,220
well most interactive applications can

00:19:48,570 --> 00:19:52,799
actually be thought of as a tapestry of

00:19:50,220 --> 00:19:54,450
event-driven code we weave together a

00:19:52,799 --> 00:19:55,860
sparse graph of code that runs in

00:19:54,450 --> 00:19:57,480
response to external I o events

00:19:55,860 --> 00:19:59,100
happening and in between those short

00:19:57,480 --> 00:20:00,600
bursts of activity our code isn't doing

00:19:59,100 --> 00:20:04,230
very much our code is actually just

00:20:00,600 --> 00:20:06,390
waiting a great abstraction layer breaks

00:20:04,230 --> 00:20:09,659
down a complex problem into multiple

00:20:06,390 --> 00:20:11,309
similar pieces blocking cylla o enables

00:20:09,659 --> 00:20:12,870
us to think about this tapestry as

00:20:11,309 --> 00:20:14,430
linear flows of events

00:20:12,870 --> 00:20:16,740
this is what makes no js' and

00:20:14,430 --> 00:20:19,140
async/await such a powerful tools they

00:20:16,740 --> 00:20:20,700
give us leverage over complexity under

00:20:19,140 --> 00:20:22,470
the hood the event loop ingests an

00:20:20,700 --> 00:20:24,450
unpredictable stream of incoming events

00:20:22,470 --> 00:20:28,410
and advances the linear flows we've

00:20:24,450 --> 00:20:29,970
defined great abstractions also tend to

00:20:28,410 --> 00:20:33,000
make both sides of their problem space

00:20:29,970 --> 00:20:34,860
more efficient blocking silo not only

00:20:33,000 --> 00:20:37,110
helps programmers understand their data

00:20:34,860 --> 00:20:39,150
flows it makes explicit what processes

00:20:37,110 --> 00:20:42,620
are waiting for so that our runtime can

00:20:39,150 --> 00:20:45,510
focus its attention elsewhere and yet

00:20:42,620 --> 00:20:47,010
abstractions always leak what we do in

00:20:45,510 --> 00:20:48,810
our JavaScript code has impacts across

00:20:47,010 --> 00:20:51,030
the entire system even though sometimes

00:20:48,810 --> 00:20:52,920
we have limited control over it as our

00:20:51,030 --> 00:20:54,360
stack of abstractions gets deeper the

00:20:52,920 --> 00:20:56,970
distance between what we intend to

00:20:54,360 --> 00:20:58,350
happen and how it happens widens before

00:20:56,970 --> 00:21:00,060
we wrap up I'd like to point out to

00:20:58,350 --> 00:21:01,440
newish layers of the stack we haven't

00:21:00,060 --> 00:21:03,330
really gotten to yet which are pretty

00:21:01,440 --> 00:21:06,510
interesting ones on the backend and

00:21:03,330 --> 00:21:07,830
another's on the front end if your

00:21:06,510 --> 00:21:10,470
back-end code is running in the cloud

00:21:07,830 --> 00:21:12,180
it's not running on a real CPU there's

00:21:10,470 --> 00:21:14,580
an additional virtualization layer which

00:21:12,180 --> 00:21:16,620
provides a virtual CPU to our operating

00:21:14,580 --> 00:21:18,330
system called a hypervisor the

00:21:16,620 --> 00:21:20,640
hypervisor has its own scheduler which

00:21:18,330 --> 00:21:21,870
allocates CPU and i/o time based on how

00:21:20,640 --> 00:21:23,850
much you're paying for so you're

00:21:21,870 --> 00:21:26,040
actually running an even more schedulers

00:21:23,850 --> 00:21:28,020
than you thought however if your

00:21:26,040 --> 00:21:30,090
front-end code is running on react 16 or

00:21:28,020 --> 00:21:31,710
later your Dom renders are subject to an

00:21:30,090 --> 00:21:34,170
additional scheduler - called react

00:21:31,710 --> 00:21:35,670
fiber because the event loop doesn't

00:21:34,170 --> 00:21:37,380
have a way to preempt control from

00:21:35,670 --> 00:21:40,110
JavaScript when it's taking too long

00:21:37,380 --> 00:21:41,850
react fiber schedules itself it's saves

00:21:40,110 --> 00:21:44,130
State and pauses when it's out of time

00:21:41,850 --> 00:21:46,530
and resumes after the browser renders

00:21:44,130 --> 00:21:48,360
the next frame the fiber scheduler

00:21:46,530 --> 00:21:49,800
splits up large UI rear Enders into

00:21:48,360 --> 00:21:51,960
smaller pieces of work that can execute

00:21:49,800 --> 00:21:54,180
incremental e it also prioritizes

00:21:51,960 --> 00:21:58,950
time-sensitive work like updating input

00:21:54,180 --> 00:22:01,320
elements so here's like a broad overview

00:21:58,950 --> 00:22:02,970
of the many layers of our stack when

00:22:01,320 --> 00:22:05,400
we're working both in back in JavaScript

00:22:02,970 --> 00:22:06,810
and in front-end JavaScript there's a

00:22:05,400 --> 00:22:08,520
lot of layers here and there's a

00:22:06,810 --> 00:22:10,110
tendency for us to think of high level

00:22:08,520 --> 00:22:11,970
programming languages like JavaScript as

00:22:10,110 --> 00:22:13,860
less efficient because they introduce

00:22:11,970 --> 00:22:17,190
additional layers of overhead and give

00:22:13,860 --> 00:22:19,560
us less control over the execution I

00:22:17,190 --> 00:22:21,930
want to leave you with more nuanced idea

00:22:19,560 --> 00:22:23,340
than that as we've seen with waiting

00:22:21,930 --> 00:22:25,200
working at a high level of abstraction

00:22:23,340 --> 00:22:26,130
often leaves you with a clearer

00:22:25,200 --> 00:22:28,080
expression

00:22:26,130 --> 00:22:29,940
of what you're writing the more clearly

00:22:28,080 --> 00:22:31,860
programmers can express their intentions

00:22:29,940 --> 00:22:33,570
the more information we can weave into

00:22:31,860 --> 00:22:35,430
our tapestry of events and the more

00:22:33,570 --> 00:22:38,610
latitude we provide our execution layers

00:22:35,430 --> 00:22:40,140
to optimize them the real cost of adding

00:22:38,610 --> 00:22:41,760
too many layers is mismatching

00:22:40,140 --> 00:22:43,680
abstractions where we waste energy

00:22:41,760 --> 00:22:45,660
translating one problem into another as

00:22:43,680 --> 00:22:47,460
you've seen many layers of modern

00:22:45,660 --> 00:22:49,680
computers provide means of waiting in

00:22:47,460 --> 00:22:51,420
similar ways over time we're gonna

00:22:49,680 --> 00:22:52,950
simplify away some of those layers and

00:22:51,420 --> 00:22:55,830
specialize them to better serve the

00:22:52,950 --> 00:22:57,660
needs of modern applications at the same

00:22:55,830 --> 00:22:59,640
time we can expect that the future will

00:22:57,660 --> 00:23:01,200
demand even higher level languages or

00:22:59,640 --> 00:23:03,300
high-level abstractions built in those

00:23:01,200 --> 00:23:05,430
languages like react as you've seen

00:23:03,300 --> 00:23:07,800
JavaScript gives us tremendous leverage

00:23:05,430 --> 00:23:10,110
over the CPU and OS to weave together

00:23:07,800 --> 00:23:12,090
flows in a way that's intuitive to us as

00:23:10,110 --> 00:23:13,830
programmers but programming is still a

00:23:12,090 --> 00:23:16,460
young medium and we still have much

00:23:13,830 --> 00:23:18,960
learn about how to structure our ideas

00:23:16,460 --> 00:23:19,680
if you're interested in diving in deeper

00:23:18,960 --> 00:23:22,160
on these topics

00:23:19,680 --> 00:23:24,930
I'd recommend three awesome resources

00:23:22,160 --> 00:23:27,420
Sam Roberts is talk on how up close

00:23:24,930 --> 00:23:29,550
shows up close how Libby V is used to

00:23:27,420 --> 00:23:30,660
create the Jas event loop and exposes

00:23:29,550 --> 00:23:33,570
the trade-offs that are made in

00:23:30,660 --> 00:23:35,490
designing it Cindy sweethearts talk on

00:23:33,570 --> 00:23:36,750
non-blocking i/o dives deeper into how

00:23:35,490 --> 00:23:39,420
the operating system implements

00:23:36,750 --> 00:23:41,940
event-driven IO internally and finally

00:23:39,420 --> 00:23:43,830
Merrick Mitch cows Keast blog series on

00:23:41,940 --> 00:23:45,930
select walks through the history of how

00:23:43,830 --> 00:23:47,820
i/o multiplexing evolved starting in

00:23:45,930 --> 00:23:50,580
early computer systems in a time before

00:23:47,820 --> 00:23:51,990
people are just figuring out in a time

00:23:50,580 --> 00:23:53,430
when people were just figuring out how

00:23:51,990 --> 00:23:54,630
to write networked computers like at the

00:23:53,430 --> 00:23:56,490
dawn of the internet it's really

00:23:54,630 --> 00:23:59,490
fascinating stuff and I highly recommend

00:23:56,490 --> 00:24:01,800
diving in and with that I'm gonna yield

00:23:59,490 --> 00:24:03,240
back to the conference loop thanks for

00:24:01,800 --> 00:24:05,960
scheduling your attention for the past

00:24:03,240 --> 00:24:05,960
25 minutes

00:24:06,300 --> 00:24:08,360

YouTube URL: https://www.youtube.com/watch?v=UTol97sYpSI


