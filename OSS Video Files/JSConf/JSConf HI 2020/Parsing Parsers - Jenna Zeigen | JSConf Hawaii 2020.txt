Title: Parsing Parsers - Jenna Zeigen | JSConf Hawaii 2020
Publication date: 2020-03-12
Playlist: JSConf HI 2020
Description: 
	Have you ever wondered how your code goes from being characters in a file to something that the computer can "understand" and do something with? A key part of this is the parser. In this talk, we’ll look at building a search query parser (all in JavaScript, of course). On this journey, we’ll first take a step back and learn about the building blocks of all languages, from letters to grammars, and how they represent meaning. Then, we’ll talk about what a parser is and does and why we might want one for our task. With this new knowledge, we’ll dive into building the parser, from tokenizing to building a data structure that represents the query and lets us build a UI around it.

Slides: https://jenna.is/slides/at-jsconfhi.pdf

JSConf Hawaii will return in soon
https://www.jsconfhi.com/
Captions: 
	00:00:09,310 --> 00:00:15,520
so yeah again Jenna this is parsing

00:00:12,310 --> 00:00:18,580
cursors and I am a senior front-end

00:00:15,520 --> 00:00:20,230
engineer at slack I'm on the search and

00:00:18,580 --> 00:00:22,930
discovery team we're based in New York

00:00:20,230 --> 00:00:25,600
City I spend a lot of time thinking

00:00:22,930 --> 00:00:27,520
about the quick switcher and other art

00:00:25,600 --> 00:00:29,770
of completes throughout the product some

00:00:27,520 --> 00:00:32,440
other things I do in New York include

00:00:29,770 --> 00:00:34,900
organizing to JavaScript communities one

00:00:32,440 --> 00:00:37,059
is Empire Jas which is an annual

00:00:34,900 --> 00:00:39,010
JavaScript conference yeah there is

00:00:37,059 --> 00:00:40,690
Brooklyn Jas which is a monthly

00:00:39,010 --> 00:00:43,629
JavaScript Meetup

00:00:40,690 --> 00:00:45,489
so I know firsthand how much effort it

00:00:43,629 --> 00:00:46,780
takes to pull off an event like this so

00:00:45,489 --> 00:00:48,820
can we get a round of applause for all

00:00:46,780 --> 00:00:57,489
with organizers volunteers and everyone

00:00:48,820 --> 00:00:59,739
else so my twitter handle is Zygon

00:00:57,489 --> 00:01:02,739
vector you can feel free to tweet

00:00:59,739 --> 00:01:05,320
questions comments and compliments at me

00:01:02,739 --> 00:01:07,420
there I'll also tweet out the link to my

00:01:05,320 --> 00:01:10,150
slides which just happens to be on this

00:01:07,420 --> 00:01:12,369
slide she also mentioned there's a lot

00:01:10,150 --> 00:01:14,110
of information here so I've included

00:01:12,369 --> 00:01:16,210
some citations at the bottom of my

00:01:14,110 --> 00:01:19,119
bottom of my slides there's probably

00:01:16,210 --> 00:01:22,439
like entire college courses on parsers

00:01:19,119 --> 00:01:24,789
but I have to do this in 25 minutes so

00:01:22,439 --> 00:01:26,649
there's gonna be a lot of information in

00:01:24,789 --> 00:01:28,299
a short amount of time some of its going

00:01:26,649 --> 00:01:30,030
to be high-level some of its gonna be

00:01:28,299 --> 00:01:32,350
fast sorry

00:01:30,030 --> 00:01:35,740
so if you want to learn more please

00:01:32,350 --> 00:01:38,829
check out those links all right let's

00:01:35,740 --> 00:01:42,219
parse some parsers so I think to really

00:01:38,829 --> 00:01:44,439
understand parsers like understand what

00:01:42,219 --> 00:01:47,200
they're doing we need to learn a little

00:01:44,439 --> 00:01:50,770
bit about what makes languages language

00:01:47,200 --> 00:01:53,170
what makes languages languages so we'll

00:01:50,770 --> 00:01:54,880
talk a little bit about that and then as

00:01:53,170 --> 00:01:57,340
I was building the talk I just realized

00:01:54,880 --> 00:01:59,710
that the best way to learn about parsers

00:01:57,340 --> 00:02:01,840
is to build one which we will be

00:01:59,710 --> 00:02:03,490
stepping through the code for because

00:02:01,840 --> 00:02:07,210
I'm not brave enough to live code on

00:02:03,490 --> 00:02:09,429
stage so it'll be small it'll be a

00:02:07,210 --> 00:02:12,069
little too a parser but hopefully you

00:02:09,429 --> 00:02:13,780
can learn some things that I learned and

00:02:12,069 --> 00:02:17,070
feel the joy that I felt while building

00:02:13,780 --> 00:02:19,780
it so let's learn about language

00:02:17,070 --> 00:02:22,190
language is a structured system of

00:02:19,780 --> 00:02:24,620
communication might seem obvious

00:02:22,190 --> 00:02:26,950
we're starting at the basics here so we

00:02:24,620 --> 00:02:31,760
are using language to encode information

00:02:26,950 --> 00:02:34,040
to send between two entities like two

00:02:31,760 --> 00:02:37,850
people two computers a person and a

00:02:34,040 --> 00:02:41,240
computer etc the language that we're

00:02:37,850 --> 00:02:43,790
used to is called natural language we

00:02:41,240 --> 00:02:46,340
humans we speak it we sign it we write

00:02:43,790 --> 00:02:48,710
it we understand it innately because our

00:02:46,340 --> 00:02:50,690
brains evolved to understand it there

00:02:48,710 --> 00:02:52,490
are rules that govern how we put words

00:02:50,690 --> 00:02:55,780
together and how we put letters together

00:02:52,490 --> 00:02:59,510
to form words but we don't necessarily

00:02:55,780 --> 00:03:01,880
know these rules explicitly we might

00:02:59,510 --> 00:03:03,470
learn them in English class or in

00:03:01,880 --> 00:03:06,080
whatever class like that where you learn

00:03:03,470 --> 00:03:08,360
the rules of grammar but we don't

00:03:06,080 --> 00:03:10,790
necessarily know these rules explicitly

00:03:08,360 --> 00:03:14,360
some of these rules might be that now

00:03:10,790 --> 00:03:17,390
it's combined with verbs an adverb might

00:03:14,360 --> 00:03:19,610
come in to modify that verb but again we

00:03:17,390 --> 00:03:21,860
understand language and we've learned

00:03:19,610 --> 00:03:23,630
these rules without ever even really

00:03:21,860 --> 00:03:26,420
trying because our brains have evolved

00:03:23,630 --> 00:03:28,610
seamlessly to acquire language and even

00:03:26,420 --> 00:03:30,980
if we break these rules it's okay you

00:03:28,610 --> 00:03:34,970
generally understand what the other

00:03:30,980 --> 00:03:37,190
person is trying to say formal languages

00:03:34,970 --> 00:03:39,830
on the other hand are a bit more well

00:03:37,190 --> 00:03:41,930
formal they're more math class than

00:03:39,830 --> 00:03:44,690
English or Spanish class formal

00:03:41,930 --> 00:03:46,820
languages are also made up of words that

00:03:44,690 --> 00:03:49,100
are made up of letters from an alphabet

00:03:46,820 --> 00:03:52,040
both of which can be combined at each

00:03:49,100 --> 00:03:54,320
level based on specific rules which is

00:03:52,040 --> 00:03:56,510
called the languages grammar programming

00:03:54,320 --> 00:03:58,670
languages are formal languages which

00:03:56,510 --> 00:04:00,890
mean to that they have an alphabet like

00:03:58,670 --> 00:04:03,230
unicode and a grammar which we sometimes

00:04:00,890 --> 00:04:05,330
called the syntax that tells us how to

00:04:03,230 --> 00:04:08,900
write our code all the way down to the

00:04:05,330 --> 00:04:11,209
punctuation so as I said languages

00:04:08,900 --> 00:04:14,720
grammar is the set of rules for that

00:04:11,209 --> 00:04:17,120
language formal grammars put these rules

00:04:14,720 --> 00:04:20,510
in terms of rules of replacement which

00:04:17,120 --> 00:04:22,280
are called production rules so to get a

00:04:20,510 --> 00:04:24,050
sense of what I mean by replacement

00:04:22,280 --> 00:04:26,390
let's take a look at this little

00:04:24,050 --> 00:04:29,419
sentence diagram for this very short

00:04:26,390 --> 00:04:31,940
sentence Jenna gave the talk so we can

00:04:29,419 --> 00:04:34,190
kind of see that a sentence can be

00:04:31,940 --> 00:04:36,150
broken down into a noun and a verb

00:04:34,190 --> 00:04:38,940
phrase a verb phrase can

00:04:36,150 --> 00:04:41,130
replaced by a verb and a noun phrase etc

00:04:38,940 --> 00:04:43,860
all the way down the line so here are

00:04:41,130 --> 00:04:46,170
these rules put another way so you can

00:04:43,860 --> 00:04:48,960
see that sentence now a plus verb phrase

00:04:46,170 --> 00:04:51,030
verb phrase verb plus noun phrase down

00:04:48,960 --> 00:04:53,070
phrase can be broken down into a direct

00:04:51,030 --> 00:04:56,870
object and a noun and neither of these

00:04:53,070 --> 00:04:56,870
can be broken down any further

00:04:57,440 --> 00:05:02,370
programming languages have their

00:04:59,700 --> 00:05:04,290
grammars defined in a spec if any of you

00:05:02,370 --> 00:05:06,180
have ever been brave enough to try and

00:05:04,290 --> 00:05:07,610
read the Ekman script spec you might

00:05:06,180 --> 00:05:10,130
have seen that there is a section on

00:05:07,610 --> 00:05:12,870
grammars and a good chunk of it is

00:05:10,130 --> 00:05:14,610
describing how we put the bits of

00:05:12,870 --> 00:05:18,480
JavaScript together to create proper

00:05:14,610 --> 00:05:20,760
JavaScript so let's start our journey

00:05:18,480 --> 00:05:24,000
towards building our parser and first

00:05:20,760 --> 00:05:26,310
define our language and its grammar so I

00:05:24,000 --> 00:05:28,530
wanted to choose a language that had a

00:05:26,310 --> 00:05:30,480
few moving parts that I knew well and

00:05:28,530 --> 00:05:32,790
then I could explain how it works and

00:05:30,480 --> 00:05:34,830
what it means so I chose a language that

00:05:32,790 --> 00:05:38,340
was right there in front of me every day

00:05:34,830 --> 00:05:40,650
seven days a week you might be familiar

00:05:38,340 --> 00:05:42,360
with it it is the search query language

00:05:40,650 --> 00:05:45,540
from slack if you're not familiar with

00:05:42,360 --> 00:05:47,910
it explain what's going on here and our

00:05:45,540 --> 00:05:48,960
goal ultimately will be to build an even

00:05:47,910 --> 00:05:51,870
better visualizer

00:05:48,960 --> 00:05:54,420
for this language so here's an example

00:05:51,870 --> 00:05:57,200
of the search query language we have

00:05:54,420 --> 00:05:59,910
there are terms here like JavaScript

00:05:57,200 --> 00:06:03,330
phrases like front end in a single round

00:05:59,910 --> 00:06:06,150
of quotation marks there's these filters

00:06:03,330 --> 00:06:08,970
like in random and in general which say

00:06:06,150 --> 00:06:10,590
which messages we want to find which

00:06:08,970 --> 00:06:14,340
channels we want to search for messages

00:06:10,590 --> 00:06:16,290
in and from filters like from Jenna you

00:06:14,340 --> 00:06:19,830
want to find all the messages that are

00:06:16,290 --> 00:06:22,410
from me so here's what this grammar is

00:06:19,830 --> 00:06:24,530
going to look like a query can just be a

00:06:22,410 --> 00:06:27,810
term you can search for just JavaScript

00:06:24,530 --> 00:06:29,700
query can also be a term plus more query

00:06:27,810 --> 00:06:31,290
if we were to lock JavaScript off the

00:06:29,700 --> 00:06:34,260
beginning that would still be a valid

00:06:31,290 --> 00:06:35,520
query query can just be a filter you

00:06:34,260 --> 00:06:38,520
want to search for all the messages in

00:06:35,520 --> 00:06:40,560
random you can just do that and then you

00:06:38,520 --> 00:06:42,420
can search for all of the messages that

00:06:40,560 --> 00:06:44,580
have the word JavaScript in them in the

00:06:42,420 --> 00:06:47,820
random Channel and that's our little

00:06:44,580 --> 00:06:49,390
grammar for our language then I want us

00:06:47,820 --> 00:06:51,580
to build something that looks like

00:06:49,390 --> 00:06:53,440
that highlights the different types of

00:06:51,580 --> 00:06:55,560
bits of language in their own color

00:06:53,440 --> 00:06:56,770
whether it be green purple or light pink

00:06:55,560 --> 00:07:00,180
okay

00:06:56,770 --> 00:07:04,210
parsers that's what we are all here for

00:07:00,180 --> 00:07:06,220
so what what is a parser well it parses

00:07:04,210 --> 00:07:08,650
which is the process of analyzing

00:07:06,220 --> 00:07:10,720
language against the rules of its

00:07:08,650 --> 00:07:12,460
grammar so we're going to take the

00:07:10,720 --> 00:07:14,320
language and break it down into its

00:07:12,460 --> 00:07:16,720
components to find its underlying

00:07:14,320 --> 00:07:17,980
structure to see if it adheres to the

00:07:16,720 --> 00:07:20,350
rules of the language that it was

00:07:17,980 --> 00:07:22,120
written for this process also helps us

00:07:20,350 --> 00:07:24,240
turn language into something the

00:07:22,120 --> 00:07:26,410
computer can better use and maybe

00:07:24,240 --> 00:07:30,040
understand if we're going to think about

00:07:26,410 --> 00:07:32,950
it in human terms Bursar's can be really

00:07:30,040 --> 00:07:36,340
complicated but in the end all they have

00:07:32,950 --> 00:07:38,650
to do is take they all have to do is be

00:07:36,340 --> 00:07:41,830
a function that takes raw input and

00:07:38,650 --> 00:07:44,670
turns it into meaningful data that is

00:07:41,830 --> 00:07:48,790
created from the input or it's going to

00:07:44,670 --> 00:07:51,490
send off an error so again if it takes

00:07:48,790 --> 00:07:53,110
some unstructured language and turns it

00:07:51,490 --> 00:07:56,310
into something that is more structure

00:07:53,110 --> 00:07:57,490
and is more meaningful that's a parser

00:07:56,310 --> 00:08:00,340
Purser's

00:07:57,490 --> 00:08:02,500
in general when they're more complicated

00:08:00,340 --> 00:08:05,320
they usually have two parts to them they

00:08:02,500 --> 00:08:07,240
have a lexer and a parser which is the

00:08:05,320 --> 00:08:10,360
main event because you know it takes on

00:08:07,240 --> 00:08:13,150
the whole word right so the lexer is

00:08:10,360 --> 00:08:16,150
going to take the text and break it down

00:08:13,150 --> 00:08:18,310
into meaningful units called tokens

00:08:16,150 --> 00:08:21,940
these meaningful units are going to be

00:08:18,310 --> 00:08:25,000
the words the punctuation etc the first

00:08:21,940 --> 00:08:27,100
step in lexing is going to be the

00:08:25,000 --> 00:08:29,650
scanner so it's going to go through and

00:08:27,100 --> 00:08:31,840
break the string of characters into the

00:08:29,650 --> 00:08:34,410
proper chunks Jirka lexemes and these

00:08:31,840 --> 00:08:37,240
lexemes are the words in the language

00:08:34,410 --> 00:08:40,030
they can be key words literals like a

00:08:37,240 --> 00:08:42,610
number or string punctuation etc and

00:08:40,030 --> 00:08:46,180
this process is often accomplished by

00:08:42,610 --> 00:08:48,900
using Magilla expressions so let's dig

00:08:46,180 --> 00:08:48,900
into some code

00:08:53,520 --> 00:08:56,610
[Music]

00:08:58,339 --> 00:09:03,199
all right so we have a regular

00:09:00,740 --> 00:09:05,180
expressions here that define the four

00:09:03,199 --> 00:09:08,059
types of things that we can have an in

00:09:05,180 --> 00:09:10,939
filter from filter a phrase within those

00:09:08,059 --> 00:09:15,199
quotation marks and just a single term

00:09:10,939 --> 00:09:17,089
so just one word and this is pretty much

00:09:15,199 --> 00:09:19,759
just gonna be our lexer it's going to

00:09:17,089 --> 00:09:22,189
take those regular expressions and match

00:09:19,759 --> 00:09:24,949
them against the string that we put in

00:09:22,189 --> 00:09:32,379
so let's see what happens when we use

00:09:24,949 --> 00:09:37,240
our example a little bit so we can see

00:09:32,379 --> 00:09:40,790
here that these are our lexemes just

00:09:37,240 --> 00:09:44,480
smaller strings made from the initial

00:09:40,790 --> 00:09:51,350
input which was JavaScript front-end in

00:09:44,480 --> 00:09:53,540
general from jena etc well so let's also

00:09:51,350 --> 00:09:59,509
take a look at what javascript is doing

00:09:53,540 --> 00:10:02,029
because that's also interesting so

00:09:59,509 --> 00:10:04,639
javascript is going to take this little

00:10:02,029 --> 00:10:07,790
snippet of code and turn it into

00:10:04,639 --> 00:10:09,199
something that looks like this not very

00:10:07,790 --> 00:10:11,240
different but you can see it's going to

00:10:09,199 --> 00:10:13,879
break it down into its lexemes

00:10:11,240 --> 00:10:17,209
which include just const the variable

00:10:13,879 --> 00:10:20,600
name lexeme that equals sign which is

00:10:17,209 --> 00:10:22,939
punctuation the next step is the

00:10:20,600 --> 00:10:25,990
evaluator is going to combine the

00:10:22,939 --> 00:10:29,899
lexemes type with its value to create a

00:10:25,990 --> 00:10:36,170
token so first let's take a look at our

00:10:29,899 --> 00:10:45,620
code and you can see this next little

00:10:36,170 --> 00:10:48,559
bit so we're gonna take the tokens and

00:10:45,620 --> 00:10:50,360
combine them with their type which we

00:10:48,559 --> 00:10:52,370
can figure out because we know exactly

00:10:50,360 --> 00:10:54,139
what an in token looks like based on its

00:10:52,370 --> 00:10:56,540
regular expression or diff from token

00:10:54,139 --> 00:11:01,220
looks like based on that and etc so we

00:10:56,540 --> 00:11:03,319
can take those and turn them into the

00:11:01,220 --> 00:11:05,209
types of tokens that they are which just

00:11:03,319 --> 00:11:07,160
like a little object wrapper nothing too

00:11:05,209 --> 00:11:10,209
complicated because again little

00:11:07,160 --> 00:11:10,209
language little parser

00:11:10,940 --> 00:11:23,190
so javascript is going to take its

00:11:20,060 --> 00:11:26,940
lexemes like this and it's going to put

00:11:23,190 --> 00:11:29,430
them up into the mash them up with their

00:11:26,940 --> 00:11:31,980
type and turn them into these tokens and

00:11:29,430 --> 00:11:33,810
shout out to spree mahir which is a very

00:11:31,980 --> 00:11:35,430
popular parser that folks use for

00:11:33,810 --> 00:11:37,110
javascript that back some of our

00:11:35,430 --> 00:11:39,720
favorite JavaScript tools that do you

00:11:37,110 --> 00:11:41,640
like source transformation demo tools

00:11:39,720 --> 00:11:45,180
link at the bottom so if you want to you

00:11:41,640 --> 00:11:46,440
know see how it shakes out with whatever

00:11:45,180 --> 00:11:48,570
whatever your favorite snippet of

00:11:46,440 --> 00:11:51,980
JavaScript is you can do that there and

00:11:48,570 --> 00:11:55,230
this is what it is actually going to

00:11:51,980 --> 00:12:00,180
spit out it's really simple it has this

00:11:55,230 --> 00:12:02,640
type and it's the value never showed you

00:12:00,180 --> 00:12:15,450
what our little parser ends up doing so

00:12:02,640 --> 00:12:17,130
let's look at that hello tokens

00:12:15,450 --> 00:12:20,160
it's either the tokens from our little

00:12:17,130 --> 00:12:22,470
language so we have a term and in filter

00:12:20,160 --> 00:12:23,910
C not too much more complicated but they

00:12:22,470 --> 00:12:25,740
still have a little bit more meaning we

00:12:23,910 --> 00:12:27,450
can you know that this is an in filter

00:12:25,740 --> 00:12:29,190
you know this is a from filter and

00:12:27,450 --> 00:12:30,570
that's something that the computer might

00:12:29,190 --> 00:12:33,450
be able to do a little bit more with

00:12:30,570 --> 00:12:36,500
than just those fair strings that we had

00:12:33,450 --> 00:12:36,500
from lexemes

00:12:38,000 --> 00:12:45,620
all right so now we're onto the main

00:12:43,410 --> 00:12:47,790
event the parser which is going to

00:12:45,620 --> 00:12:49,980
analyze the tokens that were produced by

00:12:47,790 --> 00:12:52,350
the lexer checking that the syntax is

00:12:49,980 --> 00:12:54,690
correct based on the prescribed rules of

00:12:52,350 --> 00:12:57,240
the language while creating again that

00:12:54,690 --> 00:13:00,120
structure based on the production rules

00:12:57,240 --> 00:13:01,560
the result of parsing is usually a tree

00:13:00,120 --> 00:13:04,260
you might have heard about parse trees

00:13:01,560 --> 00:13:06,990
or syntax trees so that's what usually

00:13:04,260 --> 00:13:09,420
gets created and then if the parser

00:13:06,990 --> 00:13:12,210
cannot create a tree you end up with a

00:13:09,420 --> 00:13:14,370
syntax error so what we're gonna want

00:13:12,210 --> 00:13:16,380
out of this is a tree that kind of looks

00:13:14,370 --> 00:13:18,690
like this because that's what we need to

00:13:16,380 --> 00:13:20,310
build our visualizer parsers in the end

00:13:18,690 --> 00:13:22,830
or just around to help us achieve our

00:13:20,310 --> 00:13:24,690
end we can build a parser in different

00:13:22,830 --> 00:13:26,700
ways to achieve different goals

00:13:24,690 --> 00:13:28,890
and this is all we need we need to know

00:13:26,700 --> 00:13:34,350
that all of these tokens wrap up into a

00:13:28,890 --> 00:13:37,800
single query so let's take a look at our

00:13:34,350 --> 00:13:43,650
code and how it ends up spitting out our

00:13:37,800 --> 00:13:48,270
little tree so I'm gonna actually go to

00:13:43,650 --> 00:13:54,270
PS code okay so our parser isn't

00:13:48,270 --> 00:13:56,880
actually that much more complicated so

00:13:54,270 --> 00:13:58,650
we're gonna take we're gonna make a base

00:13:56,880 --> 00:14:01,200
query which is going to be our top level

00:13:58,650 --> 00:14:03,360
and just give it the tokens because

00:14:01,200 --> 00:14:05,460
that's all that we need to create our

00:14:03,360 --> 00:14:08,010
parser the way that we need it to be

00:14:05,460 --> 00:14:13,320
created creating this tree structure for

00:14:08,010 --> 00:14:21,480
our visualizer so then let's take a look

00:14:13,320 --> 00:14:24,390
at what it spits out Oh parse tree we

00:14:21,480 --> 00:14:28,920
have tokens top levels the query and

00:14:24,390 --> 00:14:30,570
then the tokens are here spit out we

00:14:28,920 --> 00:14:32,940
just have the single level these don't

00:14:30,570 --> 00:14:40,260
get broken down any further we are at

00:14:32,940 --> 00:14:45,210
the end cool so Java Script or something

00:14:40,260 --> 00:14:47,630
a little bit more complicated here going

00:14:45,210 --> 00:14:54,660
to have this program that eventually

00:14:47,630 --> 00:14:57,150
filters down into this tree of the you

00:14:54,660 --> 00:14:58,560
know I can't help but notice that like

00:14:57,150 --> 00:15:00,000
the leaves here are the thing that

00:14:58,560 --> 00:15:02,040
really matters right like we have like

00:15:00,000 --> 00:15:04,050
the variable names at the bottom the

00:15:02,040 --> 00:15:05,820
strings the method names that's like the

00:15:04,050 --> 00:15:07,530
stuff that really has meaning to us and

00:15:05,820 --> 00:15:09,420
then the rest of it was just there to

00:15:07,530 --> 00:15:13,890
help the purser figure out what was

00:15:09,420 --> 00:15:16,110
going on and this is what a stream is

00:15:13,890 --> 00:15:17,850
going to spit out it's a lot for such a

00:15:16,110 --> 00:15:19,530
little snippet of JavaScript and this I

00:15:17,850 --> 00:15:21,240
had to cut it off so you could even have

00:15:19,530 --> 00:15:26,089
a fighting chance of reading any of it

00:15:21,240 --> 00:15:29,880
so it's a lot but anything that helps us

00:15:26,089 --> 00:15:32,910
helps the computer make our JavaScript

00:15:29,880 --> 00:15:35,040
to do what we want it to do come to

00:15:32,910 --> 00:15:38,470
throw a little curveball into our little

00:15:35,040 --> 00:15:41,650
language here I think that we should

00:15:38,470 --> 00:15:43,270
I like these tokens these entities

00:15:41,650 --> 00:15:46,150
because they're they're their own

00:15:43,270 --> 00:15:48,070
separate meaningful unit right so what

00:15:46,150 --> 00:15:50,890
do we have to do to make our visualizer

00:15:48,070 --> 00:15:52,540
be able to do this well first we have to

00:15:50,890 --> 00:15:54,160
change our grammar around a little bit

00:15:52,540 --> 00:15:56,650
before we had it so that a filter

00:15:54,160 --> 00:15:58,990
couldn't be broken down any further but

00:15:56,650 --> 00:16:02,050
now it can into a modifier and an entity

00:15:58,990 --> 00:16:05,590
which they themselves could not be

00:16:02,050 --> 00:16:09,210
broken down anymore and then our tree is

00:16:05,590 --> 00:16:11,590
going to end up looking like this a

00:16:09,210 --> 00:16:13,770
little bit more complicated one more

00:16:11,590 --> 00:16:18,460
layer surely we can do this in our

00:16:13,770 --> 00:16:22,260
little parser with what we have so let's

00:16:18,460 --> 00:16:22,260
take a look back at our code

00:16:30,820 --> 00:16:37,580
second round maybe you know the first

00:16:35,000 --> 00:16:39,410
step is the lexer right we're gonna try

00:16:37,580 --> 00:16:41,930
and use our regular expressions but I

00:16:39,410 --> 00:16:44,120
don't see a way for us to be able to use

00:16:41,930 --> 00:16:46,490
just these regular expressions and be

00:16:44,120 --> 00:16:50,780
able to maintain some connection between

00:16:46,490 --> 00:16:52,370
the N and the the channel that we're

00:16:50,780 --> 00:16:53,930
looking in or the from and the person

00:16:52,370 --> 00:16:56,150
there's no way to maintain the

00:16:53,930 --> 00:16:59,570
connection between the modifier and

00:16:56,150 --> 00:17:03,260
their entity but what we do know is how

00:16:59,570 --> 00:17:05,240
to decompose a in token into its

00:17:03,260 --> 00:17:08,990
modifier and its entity we know that

00:17:05,240 --> 00:17:12,350
production rule so if we can just you

00:17:08,990 --> 00:17:14,150
know say okay this is our parser we do

00:17:12,350 --> 00:17:15,770
what we want to we know how to take and

00:17:14,150 --> 00:17:18,170
in token and then we're tokenizing we

00:17:15,770 --> 00:17:20,780
know how to take it's like lex IAM and

00:17:18,170 --> 00:17:22,850
split it apart we know that an in token

00:17:20,780 --> 00:17:25,130
the modifier is going to be an in

00:17:22,850 --> 00:17:28,730
modifier and we know that the filter is

00:17:25,130 --> 00:17:31,370
going to be this particular entity which

00:17:28,730 --> 00:17:33,140
is anything after the in filters pull in

00:17:31,370 --> 00:17:34,790
and maybe a space so we know how to

00:17:33,140 --> 00:17:37,370
break these two things apart because we

00:17:34,790 --> 00:17:39,440
know the production rule for turning and

00:17:37,370 --> 00:17:42,050
in token into its modifier and its

00:17:39,440 --> 00:17:45,530
entity so why not this is our parser

00:17:42,050 --> 00:17:49,100
then we can then make a mini tree out of

00:17:45,530 --> 00:17:51,590
this in token and then we can you know

00:17:49,100 --> 00:17:54,050
in our parse step we still have these

00:17:51,590 --> 00:17:57,740
tokens that all roll up into that query

00:17:54,050 --> 00:18:10,040
and we end up getting a tree that is a

00:17:57,740 --> 00:18:13,310
little bit more complicated let's do so

00:18:10,040 --> 00:18:19,010
our tree is going to be one more layer

00:18:13,310 --> 00:18:27,380
deep in token now turns into a modifier

00:18:19,010 --> 00:18:28,310
and an entity cool cool all right so now

00:18:27,380 --> 00:18:29,750
we're gonna get into a little bit more

00:18:28,310 --> 00:18:34,790
theory which is what this was all

00:18:29,750 --> 00:18:37,190
building up to why was the regex enough

00:18:34,790 --> 00:18:39,500
for the first example but not for the

00:18:37,190 --> 00:18:40,040
second you know there's a lot going on

00:18:39,500 --> 00:18:41,810
here

00:18:40,040 --> 00:18:43,730
seems pretty powerful right we were able

00:18:41,810 --> 00:18:45,890
to pretty much capsule

00:18:43,730 --> 00:18:48,410
everything that we needed to do our

00:18:45,890 --> 00:18:50,420
parse for our first smaller language but

00:18:48,410 --> 00:18:52,250
once we added that extra layer the

00:18:50,420 --> 00:18:55,190
regular expression wasn't enough anymore

00:18:52,250 --> 00:18:57,860
to be able to really encapsulate the

00:18:55,190 --> 00:19:01,130
entire languages grammar that's because

00:18:57,860 --> 00:19:03,590
the first language that we had was a

00:19:01,130 --> 00:19:07,730
regular grammar that grammar was able to

00:19:03,590 --> 00:19:09,020
be described by this most simple type of

00:19:07,730 --> 00:19:11,060
language which is called a regular

00:19:09,020 --> 00:19:13,730
language that has a regular grammar and

00:19:11,060 --> 00:19:17,690
all the production rules are of the

00:19:13,730 --> 00:19:19,670
following type you have the thing on the

00:19:17,690 --> 00:19:21,500
left can be broken down farther it is

00:19:19,670 --> 00:19:24,260
called a non-terminal gonna be a lot

00:19:21,500 --> 00:19:26,210
easier for me to use that term and then

00:19:24,260 --> 00:19:28,370
thing on the right is cannot be broken

00:19:26,210 --> 00:19:31,220
down any further and it is called a

00:19:28,370 --> 00:19:33,170
terminal the other way that a rule can

00:19:31,220 --> 00:19:36,590
look is that a terminal can be broken

00:19:33,170 --> 00:19:39,320
down into one non-terminal and one

00:19:36,590 --> 00:19:41,030
terminal so if we take a look at our

00:19:39,320 --> 00:19:42,950
Whittle language end up getting

00:19:41,030 --> 00:19:45,400
something that looks like that either

00:19:42,950 --> 00:19:47,420
have the non terminal on the left

00:19:45,400 --> 00:19:50,000
turning into something that can't be

00:19:47,420 --> 00:19:52,850
broken down any further or it turns into

00:19:50,000 --> 00:19:54,680
a combination of just one thing that can

00:19:52,850 --> 00:19:56,270
be broken down further and one thing

00:19:54,680 --> 00:19:56,780
that could not be broken down any

00:19:56,270 --> 00:20:00,700
further

00:19:56,780 --> 00:20:03,110
but once we added in that next

00:20:00,700 --> 00:20:05,020
production rule so we could break down

00:20:03,110 --> 00:20:08,420
the filter into a modifier and entity

00:20:05,020 --> 00:20:10,310
ended up not being able to describe this

00:20:08,420 --> 00:20:12,290
with the regular grammar anymore so the

00:20:10,310 --> 00:20:14,840
regular expression was no longer able to

00:20:12,290 --> 00:20:15,950
be just our friend and we needed to add

00:20:14,840 --> 00:20:19,970
an something else

00:20:15,950 --> 00:20:22,220
that knew how to get that bit into our

00:20:19,970 --> 00:20:26,450
language and allow us to represent that

00:20:22,220 --> 00:20:29,060
as the structure that we needed so the

00:20:26,450 --> 00:20:31,790
next level of complexity in languages is

00:20:29,060 --> 00:20:37,660
called a context-free grammar it has

00:20:31,790 --> 00:20:40,880
rules that follow this these rules so

00:20:37,660 --> 00:20:42,380
alpha it's a little bit you know

00:20:40,880 --> 00:20:45,230
intimidating but all the means is that

00:20:42,380 --> 00:20:46,760
it's any combination of things that can

00:20:45,230 --> 00:20:49,340
be broken down further and things that

00:20:46,760 --> 00:20:51,860
cannot be broken down further and it's

00:20:49,340 --> 00:20:54,170
just a little bit more power that lets

00:20:51,860 --> 00:20:56,940
us do a lot more things so the classic

00:20:54,170 --> 00:21:00,120
example here is that now we can

00:20:56,940 --> 00:21:03,570
do you nesting which includes matching

00:21:00,120 --> 00:21:05,220
parentheses so regular expressions can't

00:21:03,570 --> 00:21:08,010
do this because they don't have any

00:21:05,220 --> 00:21:11,460
concept of memory whereas we need to

00:21:08,010 --> 00:21:14,040
know if like verify if we indeed do have

00:21:11,460 --> 00:21:16,710
matching parentheses if when we see a

00:21:14,040 --> 00:21:19,950
closing parentheses if we'd seen the

00:21:16,710 --> 00:21:21,630
opening one earlier and not seen or

00:21:19,950 --> 00:21:23,550
maybe we'd seen another opening one

00:21:21,630 --> 00:21:26,190
beforehand but we need to have some type

00:21:23,550 --> 00:21:28,590
of memory to know if we are actually

00:21:26,190 --> 00:21:31,620
closing something based on the rules of

00:21:28,590 --> 00:21:34,440
the grammar that's why you might have

00:21:31,620 --> 00:21:37,380
heard that HTML isn't possible by

00:21:34,440 --> 00:21:39,480
regular expressions might be really

00:21:37,380 --> 00:21:41,100
tempting such a simple language of

00:21:39,480 --> 00:21:43,290
course it should be possible by regular

00:21:41,100 --> 00:21:45,390
expressions that's again because of the

00:21:43,290 --> 00:21:49,740
nesting we need to know if our divs are

00:21:45,390 --> 00:21:51,930
closing properly so I mean you might be

00:21:49,740 --> 00:21:53,760
thinking oh but like look ahead in

00:21:51,930 --> 00:21:55,260
regular expressions it's because regular

00:21:53,760 --> 00:21:57,780
expressions these days are more power

00:21:55,260 --> 00:21:58,830
powerful than just a regular grammar so

00:21:57,780 --> 00:22:00,810
they have that little bit of memory

00:21:58,830 --> 00:22:03,360
that's necessary to give it that little

00:22:00,810 --> 00:22:04,830
extra boost and and make them just a

00:22:03,360 --> 00:22:09,360
little bit more powerful than just a

00:22:04,830 --> 00:22:11,100
normal regular grammar so HTML like most

00:22:09,360 --> 00:22:13,800
if not all programming language grammars

00:22:11,100 --> 00:22:15,720
fall into the context-free family so you

00:22:13,800 --> 00:22:18,090
can do a lot with just this little extra

00:22:15,720 --> 00:22:22,350
bit of power that this little stack of

00:22:18,090 --> 00:22:24,060
memory that these parsers have so I've

00:22:22,350 --> 00:22:26,580
been talking a lot about like oh this is

00:22:24,060 --> 00:22:28,140
like a toy parser this isn't necessarily

00:22:26,580 --> 00:22:30,180
how these things necessarily work in the

00:22:28,140 --> 00:22:32,070
real world it's because writing one by

00:22:30,180 --> 00:22:34,470
hand would be a little bit

00:22:32,070 --> 00:22:36,300
time-consuming most of the time if

00:22:34,470 --> 00:22:38,490
you're gonna build a parser for a

00:22:36,300 --> 00:22:40,170
language you have a program that builds

00:22:38,490 --> 00:22:44,970
the purse or for you which is called a

00:22:40,170 --> 00:22:47,280
purse or generator so let's just go into

00:22:44,970 --> 00:22:51,540
what these things are doing at a higher

00:22:47,280 --> 00:22:54,690
level so if we were doing this following

00:22:51,540 --> 00:22:58,020
the more like suitable way of doing it

00:22:54,690 --> 00:23:00,270
we would end up lexing those terms down

00:22:58,020 --> 00:23:02,730
into their leaves so you would end up

00:23:00,270 --> 00:23:06,240
with these terms and then the modifier

00:23:02,730 --> 00:23:09,690
and entity would be their own lexemes

00:23:06,240 --> 00:23:10,410
and tokens in the end then the next

00:23:09,690 --> 00:23:12,720
thing that the parser

00:23:10,410 --> 00:23:15,240
going to do is go through and match the

00:23:12,720 --> 00:23:16,860
tokens to production rules there's a

00:23:15,240 --> 00:23:18,720
bunch of ways for doing this but let's

00:23:16,860 --> 00:23:21,120
step through one which is the top-down

00:23:18,720 --> 00:23:24,030
method so we're gonna take the tokens

00:23:21,120 --> 00:23:26,010
and then we're gonna start with the

00:23:24,030 --> 00:23:28,080
highest level of non-terminal that we

00:23:26,010 --> 00:23:31,020
have which is a query you know the

00:23:28,080 --> 00:23:33,720
queries can be broken down into other

00:23:31,020 --> 00:23:36,660
things in a myriad of different ways

00:23:33,720 --> 00:23:38,100
let's just say we got lucky and we chose

00:23:36,660 --> 00:23:41,520
the one that was going to work for our

00:23:38,100 --> 00:23:43,770
language first right off the bat so we

00:23:41,520 --> 00:23:46,440
say okay query can be broken down into a

00:23:43,770 --> 00:23:49,140
term and another query does that work

00:23:46,440 --> 00:23:51,930
with the tokens that we have at hand yes

00:23:49,140 --> 00:23:52,710
yes it does we can't break down a term

00:23:51,930 --> 00:23:54,270
anymore

00:23:52,710 --> 00:23:58,380
we can't break down a query anymore

00:23:54,270 --> 00:23:59,700
let's try that rule again cool that

00:23:58,380 --> 00:24:04,100
worked for us because we were able to

00:23:59,700 --> 00:24:07,680
pop that term off of our list of tokens

00:24:04,100 --> 00:24:12,390
feeling lucky let's try that rule again

00:24:07,680 --> 00:24:15,750
oh no didn't work we don't have another

00:24:12,390 --> 00:24:18,230
term let's try the next rule Oh looks

00:24:15,750 --> 00:24:23,360
like we got maybe lucky this time

00:24:18,230 --> 00:24:26,880
because let's let you know let's see

00:24:23,360 --> 00:24:30,510
what is a filter it can be turned into a

00:24:26,880 --> 00:24:30,840
modifier and an entity oh cool we got

00:24:30,510 --> 00:24:32,900
lucky

00:24:30,840 --> 00:24:38,010
that was like best-case scenario I think

00:24:32,900 --> 00:24:40,860
we only had to backtrack once okay

00:24:38,010 --> 00:24:43,800
so running out of time luckily I've

00:24:40,860 --> 00:24:48,540
reached the end of the talk I hope if

00:24:43,800 --> 00:24:50,930
you've learned anything it's that a

00:24:48,540 --> 00:24:53,160
parser is just something that takes

00:24:50,930 --> 00:24:56,280
unstructured language and turns it into

00:24:53,160 --> 00:24:59,160
structured language based on the grammar

00:24:56,280 --> 00:25:01,170
that that language is that the grammar

00:24:59,160 --> 00:25:02,970
for that language when I started this

00:25:01,170 --> 00:25:06,180
talk I wanted to learn more about

00:25:02,970 --> 00:25:08,130
parsers and once I realized that and I

00:25:06,180 --> 00:25:11,940
was building my own it became a lot more

00:25:08,130 --> 00:25:13,980
let give it a lot less intimidating so I

00:25:11,940 --> 00:25:15,960
hope if anything you take that away and

00:25:13,980 --> 00:25:18,150
maybe one day you'll have to write your

00:25:15,960 --> 00:25:19,710
own search query parser so you'll have

00:25:18,150 --> 00:25:21,390
this under your belt and then maybe you

00:25:19,710 --> 00:25:23,590
want to write your own JavaScript parser

00:25:21,390 --> 00:25:26,289
that's cool too

00:25:23,590 --> 00:25:29,140
hope this helped you so thank you for

00:25:26,289 --> 00:25:31,150
your time feel free to tweet at me and

00:25:29,140 --> 00:25:32,690
you can find my slides at that link

00:25:31,150 --> 00:25:38,390
thanks again

00:25:32,690 --> 00:25:38,390

YouTube URL: https://www.youtube.com/watch?v=rvQP2RTxEH8


