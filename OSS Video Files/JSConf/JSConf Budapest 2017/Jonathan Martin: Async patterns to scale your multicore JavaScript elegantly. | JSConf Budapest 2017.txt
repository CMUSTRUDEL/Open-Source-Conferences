Title: Jonathan Martin: Async patterns to scale your multicore JavaScript elegantly. | JSConf Budapest 2017
Publication date: 2017-12-01
Playlist: JSConf Budapest 2017
Description: 
	“JavaScript is a toy language because it doesn’t support multithreading.” Heard that one before? Although the event loop means our program does one thing at a time, JavaScript is actually well-suited for a plethora of concurrency problems while avoiding typical multithreading woes. You might say JavaScript is single-threaded… just so it can be multithreaded!

Using functional programming techniques with Async IIFEs, Web Worker clusters and SharedArrayBuffers, you can elegantly architecture highly concurrent multicore web apps and backends… without spaghetti.

http://jsconfbp.com/speakers/jonathan-martin/
Captions: 
	00:00:00,140 --> 00:00:05,520
good morning thank you for coming out to

00:00:02,730 --> 00:00:07,200
my session on elegant pacing patterns

00:00:05,520 --> 00:00:09,540
and different functional programming

00:00:07,200 --> 00:00:12,179
techniques you guys can use right now to

00:00:09,540 --> 00:00:14,070
help scale your JavaScript up to

00:00:12,179 --> 00:00:15,299
multiple cores if that sounds a little

00:00:14,070 --> 00:00:16,770
bit crazy and you're thinking wait a

00:00:15,299 --> 00:00:17,699
minute javascript can't even do this

00:00:16,770 --> 00:00:19,980
hang tight

00:00:17,699 --> 00:00:23,369
we'll get there so I'm Jonathan Martin

00:00:19,980 --> 00:00:25,470
or you can find me at nibbler on the web

00:00:23,369 --> 00:00:28,109
one of the awesome calligraphy artists

00:00:25,470 --> 00:00:30,179
do this and spell this out so if you

00:00:28,109 --> 00:00:31,529
haven't already checked out their booth

00:00:30,179 --> 00:00:33,149
by the way you should check it out

00:00:31,529 --> 00:00:35,910
they're really really good at what they

00:00:33,149 --> 00:00:38,100
do and I'm an instructor in web

00:00:35,910 --> 00:00:41,010
developer for a consultancy in the USA

00:00:38,100 --> 00:00:43,950
it's called big nerd ranch big nerd

00:00:41,010 --> 00:00:46,379
ranch develops web and mobile apps for

00:00:43,950 --> 00:00:47,969
our clients and we also teach developers

00:00:46,379 --> 00:00:50,280
to do the same through intensive

00:00:47,969 --> 00:00:52,829
five-day Bute camps mostly in the US and

00:00:50,280 --> 00:00:55,320
then also we fly out to many of our

00:00:52,829 --> 00:00:56,699
clients around the globe we also teach

00:00:55,320 --> 00:00:58,710
developers to our best-selling

00:00:56,699 --> 00:01:00,300
programming guides so maybe you've seen

00:00:58,710 --> 00:01:02,010
some of these before especially in the

00:01:00,300 --> 00:01:04,700
iOS and Android space and we have a

00:01:02,010 --> 00:01:06,930
front-end web development guide as well

00:01:04,700 --> 00:01:08,760
outside big nerd ranch I'm also a

00:01:06,930 --> 00:01:10,920
digital nomad which really just means

00:01:08,760 --> 00:01:11,760
that I leverage technology to work from

00:01:10,920 --> 00:01:14,610
anywhere in the globe

00:01:11,760 --> 00:01:17,340
so some of these areas might be where I

00:01:14,610 --> 00:01:19,530
might be working any given day this

00:01:17,340 --> 00:01:21,810
isn't quite the norm yet I'm working up

00:01:19,530 --> 00:01:23,610
towards this so over the last three

00:01:21,810 --> 00:01:25,049
years this lifestyle in particular has

00:01:23,610 --> 00:01:27,119
really helped me to nurture my love for

00:01:25,049 --> 00:01:29,460
landscape photography so if you don't

00:01:27,119 --> 00:01:31,380
like JavaScript or multi-threading which

00:01:29,460 --> 00:01:33,630
seems unusual since you came to a Jay s

00:01:31,380 --> 00:01:35,759
comp you can go look at pretty pictures

00:01:33,630 --> 00:01:39,240
instead for now I'll assume that's not

00:01:35,759 --> 00:01:40,650
the case since it is a Escom so when I

00:01:39,240 --> 00:01:42,630
was accepted it comes to speak here at

00:01:40,650 --> 00:01:44,369
Budapest I was pretty excited so I

00:01:42,630 --> 00:01:46,380
started to piece together my travel

00:01:44,369 --> 00:01:48,329
plans for speaking here in Budapest I'm

00:01:46,380 --> 00:01:50,159
slightly obsessed with the two to-do

00:01:48,329 --> 00:01:51,869
lists so I started listening out the

00:01:50,159 --> 00:01:54,360
things I need to complete before I could

00:01:51,869 --> 00:01:56,310
give this talk in Budapest of course I

00:01:54,360 --> 00:01:57,990
need to fly out here be a little bit

00:01:56,310 --> 00:01:59,729
hard to give it over hangouts internet

00:01:57,990 --> 00:02:02,250
connections in Alabama are the slowest

00:01:59,729 --> 00:02:03,840
in the u.s. also I'd need to put

00:02:02,250 --> 00:02:06,030
together a slide deck so I need to work

00:02:03,840 --> 00:02:08,940
on those I'd probably need to get packed

00:02:06,030 --> 00:02:10,470
for the trip I just some phone calls I

00:02:08,940 --> 00:02:12,330
need to make before that true

00:02:10,470 --> 00:02:15,300
and probably on the flight I should read

00:02:12,330 --> 00:02:18,200
a book and at least some time before my

00:02:15,300 --> 00:02:21,690
session I needed to take a shower so

00:02:18,200 --> 00:02:23,370
lists are great and but to really start

00:02:21,690 --> 00:02:25,050
knocking out leads to dues of course you

00:02:23,370 --> 00:02:26,610
need to figure out well what order am I

00:02:25,050 --> 00:02:29,550
gonna do these in what's gonna be my

00:02:26,610 --> 00:02:31,530
plan for completing these so I could

00:02:29,550 --> 00:02:34,410
just naively go from top to bottom and

00:02:31,530 --> 00:02:35,790
complete them one by one in that case I

00:02:34,410 --> 00:02:37,470
probably would have never made it out

00:02:35,790 --> 00:02:39,330
here since I didn't actually have the

00:02:37,470 --> 00:02:41,370
slide deck finished until a few minutes

00:02:39,330 --> 00:02:43,080
ago so I probably would never have flown

00:02:41,370 --> 00:02:45,540
out here and so I wouldn't be here so

00:02:43,080 --> 00:02:47,130
that's one strategy I could use I could

00:02:45,540 --> 00:02:50,070
go from top to bottom finish these one

00:02:47,130 --> 00:02:53,250
by one but we're human we don't actually

00:02:50,070 --> 00:02:55,980
finish things this way we tend to do

00:02:53,250 --> 00:02:58,560
more than one thing at a time so for

00:02:55,980 --> 00:03:00,180
example some of these things could

00:02:58,560 --> 00:03:02,550
happen at the same time you know maybe

00:03:00,180 --> 00:03:04,650
on my flight I could work on my slide

00:03:02,550 --> 00:03:06,630
deck if I was able to stay awake for

00:03:04,650 --> 00:03:08,640
that flight so if I were smarter when

00:03:06,630 --> 00:03:11,130
writing my to-do lists maybe I could

00:03:08,640 --> 00:03:13,350
encode constraints and preferences so I

00:03:11,130 --> 00:03:17,340
could better plan how to tackle this

00:03:13,350 --> 00:03:20,130
really onerous to-do list for example I

00:03:17,340 --> 00:03:22,020
could encode my constraints as arrows

00:03:20,130 --> 00:03:24,360
which show that some things logically

00:03:22,020 --> 00:03:26,130
have to come before others for example I

00:03:24,360 --> 00:03:28,830
have to pack before my flight and I have

00:03:26,130 --> 00:03:30,420
to fly before I can speak I also have to

00:03:28,830 --> 00:03:32,310
work on my slide deck but really that

00:03:30,420 --> 00:03:34,170
can happen any time before I get my talk

00:03:32,310 --> 00:03:35,670
so long as it happens before then I

00:03:34,170 --> 00:03:37,830
could work on it before or after my

00:03:35,670 --> 00:03:39,750
flight now some of these things also

00:03:37,830 --> 00:03:41,340
can't happen at the same time for

00:03:39,750 --> 00:03:43,380
example I can't make a phone call while

00:03:41,340 --> 00:03:45,209
I'm on the plane and I can't read a book

00:03:43,380 --> 00:03:48,000
while I'm in the shower as awesome as

00:03:45,209 --> 00:03:50,370
that sounds together these describe my

00:03:48,000 --> 00:03:53,600
constraints and preferences for how I'm

00:03:50,370 --> 00:03:55,980
going to get ready for my Jas comp talk

00:03:53,600 --> 00:03:58,410
software also deals with to-do lists of

00:03:55,980 --> 00:04:00,660
its own and the problem is twofold we

00:03:58,410 --> 00:04:03,090
need a way to model constraints and

00:04:00,660 --> 00:04:05,160
preferences for how work gets done and

00:04:03,090 --> 00:04:07,410
we need to figure out the optimal

00:04:05,160 --> 00:04:09,450
solution that satisfies all those

00:04:07,410 --> 00:04:11,040
constraints and preferences and the way

00:04:09,450 --> 00:04:13,830
we solve these two problems is a

00:04:11,040 --> 00:04:15,000
defining characteristic of many

00:04:13,830 --> 00:04:18,359
different programming languages

00:04:15,000 --> 00:04:19,739
including Java Script now before I hop

00:04:18,359 --> 00:04:21,370
into the body of this session I want to

00:04:19,739 --> 00:04:23,199
recap some terminology briefly

00:04:21,370 --> 00:04:26,669
in particular we're going to toss around

00:04:23,199 --> 00:04:28,720
the terms concurrency and parallelism

00:04:26,669 --> 00:04:30,729
parallelism excuse me

00:04:28,720 --> 00:04:33,370
concurrency just means that two or more

00:04:30,729 --> 00:04:36,160
computations have overlapping timelines

00:04:33,370 --> 00:04:38,919
with each other in terms of execution so

00:04:36,160 --> 00:04:41,410
for example task 3 begins before task

00:04:38,919 --> 00:04:44,169
two and task 1 but before task 3

00:04:41,410 --> 00:04:46,210
completes task 1 and task 2 will already

00:04:44,169 --> 00:04:48,669
begin computing so that's what I mean by

00:04:46,210 --> 00:04:50,860
overlapping timelines now how you

00:04:48,669 --> 00:04:52,000
achieve that concurrency is really up to

00:04:50,860 --> 00:04:54,550
you there's a lot of different

00:04:52,000 --> 00:04:56,320
strategies you could use one example is

00:04:54,550 --> 00:04:59,169
you could switch really quickly between

00:04:56,320 --> 00:05:00,789
working on these three tasks so in

00:04:59,169 --> 00:05:04,060
particular and software we could use

00:05:00,789 --> 00:05:06,130
multi-threading to do this a single CPU

00:05:04,060 --> 00:05:08,260
core can really only do one thing at a

00:05:06,130 --> 00:05:10,419
time but by quickly switching we could

00:05:08,260 --> 00:05:12,669
have these overlapping execution

00:05:10,419 --> 00:05:14,169
timelines context switching makes it

00:05:12,669 --> 00:05:16,110
seem like we're doing three things at

00:05:14,169 --> 00:05:18,400
the same time even though we aren't

00:05:16,110 --> 00:05:20,229
there's another way we can do this we

00:05:18,400 --> 00:05:23,650
could have three separate machines or

00:05:20,229 --> 00:05:26,650
CPU cores and dedicate one core per task

00:05:23,650 --> 00:05:28,539
this specific form of concurrency is

00:05:26,650 --> 00:05:31,090
often called parallelism

00:05:28,539 --> 00:05:32,340
so to summarize concurrent programs can

00:05:31,090 --> 00:05:34,080
run multiple pieces of code

00:05:32,340 --> 00:05:36,820
independently of each other and

00:05:34,080 --> 00:05:39,639
multi-threading and parallelism are just

00:05:36,820 --> 00:05:42,250
two execution strategies for running

00:05:39,639 --> 00:05:44,500
code concurrently so how we write our

00:05:42,250 --> 00:05:46,479
code our choice of style isn't really

00:05:44,500 --> 00:05:49,270
going to very much based on our choice

00:05:46,479 --> 00:05:51,580
of do we write it in parallel or

00:05:49,270 --> 00:05:52,750
multi-threaded so for this talk

00:05:51,580 --> 00:05:54,639
I'm not going to distinguish between

00:05:52,750 --> 00:05:59,199
them I'm just going to collectively

00:05:54,639 --> 00:06:00,970
refer to it as concurrency so after this

00:05:59,199 --> 00:06:02,289
point you don't have to remember any of

00:06:00,970 --> 00:06:03,580
those crazy things we're just always

00:06:02,289 --> 00:06:05,440
going to talk about code being

00:06:03,580 --> 00:06:08,199
concurrent which just means two or more

00:06:05,440 --> 00:06:11,889
things to our more functions perhaps are

00:06:08,199 --> 00:06:15,070
running at the same time now some of you

00:06:11,889 --> 00:06:16,240
gave me a funny little wink when I said

00:06:15,070 --> 00:06:17,740
something about multi-threading in

00:06:16,240 --> 00:06:19,870
JavaScript in the same sentence

00:06:17,740 --> 00:06:21,699
so note in front-end developers alike

00:06:19,870 --> 00:06:24,070
are commonly trolled by the classic

00:06:21,699 --> 00:06:26,080
question how do you scale a JavaScript

00:06:24,070 --> 00:06:29,169
code base since it's single threaded a

00:06:26,080 --> 00:06:31,450
little bit of a loaded question but in

00:06:29,169 --> 00:06:33,789
fact not only is it multi-threaded

00:06:31,450 --> 00:06:34,930
javascript is highly concurrent by

00:06:33,789 --> 00:06:37,539
default Thanks

00:06:34,930 --> 00:06:38,710
to the event loop but it shields us at

00:06:37,539 --> 00:06:40,570
the same time from many of them

00:06:38,710 --> 00:06:42,460
multi-threading woes and synchronization

00:06:40,570 --> 00:06:45,220
primitives you might be familiar with in

00:06:42,460 --> 00:06:48,970
other languages like semaphores mutexes

00:06:45,220 --> 00:06:51,610
locks etc so for example each of these

00:06:48,970 --> 00:06:53,979
web api calls seamlessly fires up a

00:06:51,610 --> 00:06:55,870
separate thread for a total of four

00:06:53,979 --> 00:06:57,250
threads you have the main Orchestrator

00:06:55,870 --> 00:06:59,650
thread which is where you write this

00:06:57,250 --> 00:07:01,479
code and then you also get these three

00:06:59,650 --> 00:07:04,600
others in the background for free that

00:07:01,479 --> 00:07:06,880
are powering these different api's so

00:07:04,600 --> 00:07:09,490
how on earth does that actually work if

00:07:06,880 --> 00:07:11,259
javascript is multi-threaded how is it

00:07:09,490 --> 00:07:13,449
that everything seemed like you is

00:07:11,259 --> 00:07:14,949
running on one thread which means that

00:07:13,449 --> 00:07:17,169
there's only one call stack and there's

00:07:14,949 --> 00:07:18,729
one thing happening at a time so how can

00:07:17,169 --> 00:07:20,650
you write your code in such a way that

00:07:18,729 --> 00:07:22,060
it looks like it's singles write it but

00:07:20,650 --> 00:07:24,099
it's actually taking advantage of

00:07:22,060 --> 00:07:26,979
multiple cores well that's where the

00:07:24,099 --> 00:07:28,419
event loop comes in now in 30 minutes I

00:07:26,979 --> 00:07:30,460
can't actually do full justice and

00:07:28,419 --> 00:07:32,199
explaining the event loop so let me just

00:07:30,460 --> 00:07:34,300
give you a quick recap and just keep in

00:07:32,199 --> 00:07:36,310
mind that I'm lying to you quite a bit

00:07:34,300 --> 00:07:38,820
so it's grossly inaccurate I'll forward

00:07:36,310 --> 00:07:40,630
you guys to a slightly better

00:07:38,820 --> 00:07:43,180
examination of the event loop near the

00:07:40,630 --> 00:07:45,340
end so in the middle of this slide we

00:07:43,180 --> 00:07:47,050
have the call stack and the call stack

00:07:45,340 --> 00:07:49,539
just helps us keep track of what is

00:07:47,050 --> 00:07:52,180
currently executing you might think of

00:07:49,539 --> 00:07:53,919
this and if this is your main javascript

00:07:52,180 --> 00:07:56,229
file and the pages just started up you

00:07:53,919 --> 00:07:58,720
might think of this as the main function

00:07:56,229 --> 00:08:00,340
if you have a callback executing then

00:07:58,720 --> 00:08:03,490
you could imagine that callback is on

00:08:00,340 --> 00:08:05,080
the call stack so on the far left we

00:08:03,490 --> 00:08:07,720
have the built-in web api's

00:08:05,080 --> 00:08:09,430
and these are natively implemented for

00:08:07,720 --> 00:08:11,590
equivalency this could also be the node

00:08:09,430 --> 00:08:13,900
api's node works the same way it also

00:08:11,590 --> 00:08:15,370
uses the event loop and then finally on

00:08:13,900 --> 00:08:17,800
the far left we have our source code

00:08:15,370 --> 00:08:18,970
that we've written we've loaded into the

00:08:17,800 --> 00:08:21,159
browser and now we're going to start

00:08:18,970 --> 00:08:23,650
executing it so the first line is

00:08:21,159 --> 00:08:25,900
performing an ajax request and it

00:08:23,650 --> 00:08:30,280
executes a function called parse once we

00:08:25,900 --> 00:08:32,979
receive an ajax response second we're

00:08:30,280 --> 00:08:35,200
using the set timeout api to schedule a

00:08:32,979 --> 00:08:37,510
refresh function to run in about five

00:08:35,200 --> 00:08:40,839
seconds or so and finally we use the

00:08:37,510 --> 00:08:43,120
indexdb api to make a database query and

00:08:40,839 --> 00:08:45,730
invoke a function called render once

00:08:43,120 --> 00:08:47,350
that query has completed so how is the

00:08:45,730 --> 00:08:48,380
JavaScript runtime actually going to go

00:08:47,350 --> 00:08:50,000
about eval

00:08:48,380 --> 00:08:51,680
awaiting this code some of these

00:08:50,000 --> 00:08:54,050
operations for example will take a while

00:08:51,680 --> 00:08:55,610
in Ajax requests might take a few

00:08:54,050 --> 00:08:57,380
hundred milliseconds or it might take

00:08:55,610 --> 00:08:59,840
several seconds depending on the

00:08:57,380 --> 00:09:01,810
connection yarn so javascript is going

00:08:59,840 --> 00:09:04,820
to evaluate these in a very specific

00:09:01,810 --> 00:09:05,840
order and so let's just to build up our

00:09:04,820 --> 00:09:08,240
understanding of the event loop we're

00:09:05,840 --> 00:09:09,590
going to walk through this ourselves so

00:09:08,240 --> 00:09:11,120
as soon as that fetch function is

00:09:09,590 --> 00:09:13,760
invoked you can imagine that that's

00:09:11,120 --> 00:09:16,730
currently on the call stack and it fires

00:09:13,760 --> 00:09:19,880
up a natively implemented web api in the

00:09:16,730 --> 00:09:22,190
backgrounds but it doesn't just fire up

00:09:19,880 --> 00:09:25,100
the fetch API it also passes along a

00:09:22,190 --> 00:09:28,490
function or callback to invoke once that

00:09:25,100 --> 00:09:30,500
fetch API receives the Ajax response now

00:09:28,490 --> 00:09:31,370
while that fetch Web API is running in

00:09:30,500 --> 00:09:33,350
the background

00:09:31,370 --> 00:09:35,390
the runtime will advance to the next

00:09:33,350 --> 00:09:37,190
line and go ahead and execute it without

00:09:35,390 --> 00:09:39,530
waiting for the Ajax request to finish

00:09:37,190 --> 00:09:42,800
this is how we think of asynchronous

00:09:39,530 --> 00:09:45,020
coding in JavaScript the set timeout API

00:09:42,800 --> 00:09:46,880
also fires up a native web the API and

00:09:45,020 --> 00:09:48,590
passes along a callback to execute once

00:09:46,880 --> 00:09:53,150
the time is up it's a very similar

00:09:48,590 --> 00:09:54,830
behavior so indexdb works exactly the

00:09:53,150 --> 00:09:57,440
same way it fires up a native web api

00:09:54,830 --> 00:10:02,060
and it passes a callback to execute - in

00:09:57,440 --> 00:10:03,710
the indexdb web api so now what we're

00:10:02,060 --> 00:10:05,540
out of source code to execute there's

00:10:03,710 --> 00:10:06,740
nothing on the call stack in most

00:10:05,540 --> 00:10:08,480
languages this would mean that your

00:10:06,740 --> 00:10:11,060
program is dead it's not running

00:10:08,480 --> 00:10:13,070
anything however we do have those native

00:10:11,060 --> 00:10:15,560
web api is still crunching some code for

00:10:13,070 --> 00:10:18,800
us in the background and so let's say

00:10:15,560 --> 00:10:21,110
that when the index DB query finishes it

00:10:18,800 --> 00:10:22,970
will alert the JavaScript runtime by

00:10:21,110 --> 00:10:25,520
pushing that render callback we gave it

00:10:22,970 --> 00:10:28,400
on to a queue it's very imaginatively

00:10:25,520 --> 00:10:31,820
named the callback queue now this

00:10:28,400 --> 00:10:33,380
doesn't yet run our render function so

00:10:31,820 --> 00:10:35,210
the event loop is actually just a

00:10:33,380 --> 00:10:37,970
mechanism that checks to see if there's

00:10:35,210 --> 00:10:39,110
anything currently running in other

00:10:37,970 --> 00:10:40,910
words is there something in the call

00:10:39,110 --> 00:10:43,280
stack and if there is something in the

00:10:40,910 --> 00:10:44,900
callback queue if there's nothing in the

00:10:43,280 --> 00:10:47,540
call stack and there's at least

00:10:44,900 --> 00:10:49,790
something on the combat queue the event

00:10:47,540 --> 00:10:52,310
loop will pop off that first callback

00:10:49,790 --> 00:10:54,620
off the queue and push it onto the call

00:10:52,310 --> 00:10:58,760
stack which means that now our render

00:10:54,620 --> 00:11:00,350
function is executing now while that

00:10:58,760 --> 00:11:02,490
render function is executing it could

00:11:00,350 --> 00:11:04,170
take a while another way

00:11:02,490 --> 00:11:06,840
I might finish its background work

00:11:04,170 --> 00:11:09,300
perhaps our Ajax request so that web api

00:11:06,840 --> 00:11:12,690
will immediately push the parse function

00:11:09,300 --> 00:11:14,820
onto the callback queue however this

00:11:12,690 --> 00:11:15,720
time there is code already on call stack

00:11:14,820 --> 00:11:17,580
being executed

00:11:15,720 --> 00:11:20,220
so that parse function is actually just

00:11:17,580 --> 00:11:23,100
going to stay in the callback queue this

00:11:20,220 --> 00:11:24,960
behavior is called run to completion it

00:11:23,100 --> 00:11:27,510
guarantees that the currently executing

00:11:24,960 --> 00:11:29,670
function will not be interrupted by

00:11:27,510 --> 00:11:30,810
another callback which in a nutshell

00:11:29,670 --> 00:11:34,710
means you don't have to worry about

00:11:30,810 --> 00:11:37,260
thread safety now when that current

00:11:34,710 --> 00:11:39,120
function on the call set takes a long

00:11:37,260 --> 00:11:41,550
time to finish this is what we call

00:11:39,120 --> 00:11:43,290
blocking the event loop you can just

00:11:41,550 --> 00:11:45,090
imagine that if the event loop keeps

00:11:43,290 --> 00:11:46,620
trying to figure out hey can I push

00:11:45,090 --> 00:11:48,450
something can I push something yet can i

00:11:46,620 --> 00:11:51,030
grab one of these callbacks and start

00:11:48,450 --> 00:11:55,350
executing it it's blocked until the call

00:11:51,030 --> 00:11:57,960
stack is empty now during this time our

00:11:55,350 --> 00:11:59,760
timer API might also finish and it just

00:11:57,960 --> 00:12:01,410
pushes the refresh function onto that

00:11:59,760 --> 00:12:04,050
callback queue and waits to be executed

00:12:01,410 --> 00:12:06,030
once that render function finally

00:12:04,050 --> 00:12:08,190
finishes executing the call stack is now

00:12:06,030 --> 00:12:10,500
empty which means that the event loop

00:12:08,190 --> 00:12:13,320
can pop the first callback off the

00:12:10,500 --> 00:12:15,660
callback queue and push it onto the call

00:12:13,320 --> 00:12:17,040
stack which means it's being executed

00:12:15,660 --> 00:12:19,680
that's what's currently being executed

00:12:17,040 --> 00:12:21,390
and of course once the parse function

00:12:19,680 --> 00:12:23,550
finishes the call SEC will again be

00:12:21,390 --> 00:12:26,640
empty so we can push that final refresh

00:12:23,550 --> 00:12:30,480
callback and then execute that to

00:12:26,640 --> 00:12:32,580
completion so in summary while our own

00:12:30,480 --> 00:12:34,110
JavaScript code looks like it's single

00:12:32,580 --> 00:12:35,670
threaded and in a way it is actually

00:12:34,110 --> 00:12:37,770
single threaded meaning there is only

00:12:35,670 --> 00:12:40,830
one call stack and only one function

00:12:37,770 --> 00:12:43,920
running at a time the native background

00:12:40,830 --> 00:12:45,630
Web API is that powered JavaScript can

00:12:43,920 --> 00:12:47,730
be executed on separate background

00:12:45,630 --> 00:12:49,710
threads seamlessly it's not even

00:12:47,730 --> 00:12:52,200
something we have to think about now not

00:12:49,710 --> 00:12:54,690
all of the async Web API s use separate

00:12:52,200 --> 00:12:56,430
threads but the mental model holds and

00:12:54,690 --> 00:12:58,350
it helps explain why no js' and

00:12:56,430 --> 00:13:00,960
javascript in the browser can perform so

00:12:58,350 --> 00:13:02,880
much work concurrently while appearing

00:13:00,960 --> 00:13:05,640
single threaded makes it very easy to

00:13:02,880 --> 00:13:07,530
reason about again this was a highly

00:13:05,640 --> 00:13:09,030
inaccurate version of this I hope that

00:13:07,530 --> 00:13:10,680
sets the stage at least for the rest of

00:13:09,030 --> 00:13:11,940
the session but you owe it to yourself

00:13:10,680 --> 00:13:14,190
to watch Phillip Roberts

00:13:11,940 --> 00:13:15,670
talk on the subject it's called help I'm

00:13:14,190 --> 00:13:17,980
stuck in an event loop

00:13:15,670 --> 00:13:20,230
you can check out this link bitly event

00:13:17,980 --> 00:13:23,200
loop help really great talk and it's

00:13:20,230 --> 00:13:25,420
only 20 minutes so the event loop is

00:13:23,200 --> 00:13:27,460
great but in nodejs you can pretty soon

00:13:25,420 --> 00:13:29,350
hit a scaling limit with a single

00:13:27,460 --> 00:13:31,660
process despite the many background

00:13:29,350 --> 00:13:33,580
threads so at this point many developers

00:13:31,660 --> 00:13:37,060
typically turn to something like nodes

00:13:33,580 --> 00:13:38,770
cluster module or PM 2 but turning to

00:13:37,060 --> 00:13:40,480
multi-processing 2 soon

00:13:38,770 --> 00:13:42,280
negates many of the single process

00:13:40,480 --> 00:13:45,160
benefits we enjoy and the predictability

00:13:42,280 --> 00:13:47,410
of having a single call stack in

00:13:45,160 --> 00:13:49,150
JavaScript now luckily a single

00:13:47,410 --> 00:13:51,670
JavaScript runtime thread can actually

00:13:49,150 --> 00:13:54,190
orchestrate an amazing amount of work

00:13:51,670 --> 00:13:55,600
but to write code that all that will

00:13:54,190 --> 00:13:58,300
scale easily and doesn't look like a

00:13:55,600 --> 00:14:00,310
bunch of promise dot all spaghetti will

00:13:58,300 --> 00:14:01,720
need to exercise a few patents so in the

00:14:00,310 --> 00:14:03,430
remainder of this session we're going to

00:14:01,720 --> 00:14:05,140
cover these three different patterns and

00:14:03,430 --> 00:14:07,240
recipes that you can use both in your

00:14:05,140 --> 00:14:09,040
node.js and your front-end web

00:14:07,240 --> 00:14:10,930
applications to write scalable

00:14:09,040 --> 00:14:13,660
performant code that remains elegant and

00:14:10,930 --> 00:14:14,890
actually scales to multiple cores we're

00:14:13,660 --> 00:14:16,930
gonna do that also without any

00:14:14,890 --> 00:14:19,530
third-party libraries no frameworks or

00:14:16,930 --> 00:14:23,260
fads just plain old JavaScript yes

00:14:19,530 --> 00:14:26,320
2017 specifically so the first pattern

00:14:23,260 --> 00:14:28,330
is coordinating concurrency with async

00:14:26,320 --> 00:14:31,680
if ease you probably haven't all heard

00:14:28,330 --> 00:14:34,360
of and seeing if ease so async if ease

00:14:31,680 --> 00:14:36,340
should bring up some interesting ideas

00:14:34,360 --> 00:14:37,900
so when you do more than one thing at a

00:14:36,340 --> 00:14:39,700
time you usually need some ugly

00:14:37,900 --> 00:14:41,740
pipelining to describe how those

00:14:39,700 --> 00:14:44,170
different tasks are related to each

00:14:41,740 --> 00:14:46,360
other so here's a concrete example let's

00:14:44,170 --> 00:14:48,580
say we're building iTunes in the browser

00:14:46,360 --> 00:14:50,800
and we're beginning to write the code

00:14:48,580 --> 00:14:53,260
for importing mp3 files into our music

00:14:50,800 --> 00:14:54,850
library in the browser the user might

00:14:53,260 --> 00:14:56,470
import these files by dragging and

00:14:54,850 --> 00:14:58,510
dropping them into the browser this is

00:14:56,470 --> 00:15:01,150
not a theoretical app by the way all the

00:14:58,510 --> 00:15:03,690
technology for this exists if you're

00:15:01,150 --> 00:15:05,770
interested I'll show you guys a demo of

00:15:03,690 --> 00:15:07,780
basically iTunes in the browser and

00:15:05,770 --> 00:15:10,450
working with mp3s some cool blog posts

00:15:07,780 --> 00:15:12,340
and stuff so we might imagine if we're

00:15:10,450 --> 00:15:15,220
writing this mp3 importer there are five

00:15:12,340 --> 00:15:17,950
steps to import a song first we need to

00:15:15,220 --> 00:15:20,140
read in the mp3 files contents we might

00:15:17,950 --> 00:15:22,090
have a file object and so we might need

00:15:20,140 --> 00:15:23,100
to read that in to some sort of binary

00:15:22,090 --> 00:15:25,680
data type enjoy

00:15:23,100 --> 00:15:27,870
script then from that we might want to

00:15:25,680 --> 00:15:29,700
parse out the song's title the album

00:15:27,870 --> 00:15:32,340
name and some other useful metadata in

00:15:29,700 --> 00:15:35,010
most mp3s this information is encoded in

00:15:32,340 --> 00:15:37,770
the beginning of the file it's a format

00:15:35,010 --> 00:15:39,300
called ID 3 if you're interested in how

00:15:37,770 --> 00:15:41,580
to parse that data and working with

00:15:39,300 --> 00:15:45,380
binary data in JavaScript check out the

00:15:41,580 --> 00:15:48,240
blog post it's bitly slash mp3 - parser

00:15:45,380 --> 00:15:52,050
now unfortunately id3 metadata doesn't

00:15:48,240 --> 00:15:53,100
usually include the songs duration so

00:15:52,050 --> 00:15:55,020
we'll actually need to calculate

00:15:53,100 --> 00:15:58,680
ourselves and we can do that using the

00:15:55,020 --> 00:16:00,900
web's audio api and once all that

00:15:58,680 --> 00:16:03,330
metadata is extracted we're going to

00:16:00,900 --> 00:16:05,400
auto create a new album in the database

00:16:03,330 --> 00:16:07,410
if one doesn't already exist by that

00:16:05,400 --> 00:16:09,870
name and then we'll finally create a new

00:16:07,410 --> 00:16:11,040
song entry in our music library using

00:16:09,870 --> 00:16:14,400
all the information from those previous

00:16:11,040 --> 00:16:15,990
four steps so my first solution when I

00:16:14,400 --> 00:16:18,570
was coding this up looked roughly like

00:16:15,990 --> 00:16:20,580
this very much the code corresponds

00:16:18,570 --> 00:16:22,680
exactly with those steps we read in the

00:16:20,580 --> 00:16:24,420
file in this case we're reading it in as

00:16:22,680 --> 00:16:28,350
an array buffer which is JavaScript

00:16:24,420 --> 00:16:30,360
binary data type and then we parse out

00:16:28,350 --> 00:16:31,980
ID 3 metadata this is a library of god

00:16:30,360 --> 00:16:34,050
on github you guys can check out and

00:16:31,980 --> 00:16:37,050
it's just using a lot of those binary

00:16:34,050 --> 00:16:39,930
files and then we're calculating the

00:16:37,050 --> 00:16:42,530
duration using some audio api's in

00:16:39,930 --> 00:16:44,880
particular this is audio context and

00:16:42,530 --> 00:16:47,100
then we're creating entries in the

00:16:44,880 --> 00:16:50,160
database for the album and then for the

00:16:47,100 --> 00:16:52,200
song now you'll notice that async and

00:16:50,160 --> 00:16:53,490
await makes this code really nice we've

00:16:52,200 --> 00:16:55,500
got a lot of asynchronous stuff

00:16:53,490 --> 00:16:57,960
happening here and all we have to do is

00:16:55,500 --> 00:17:00,660
put in a weight in front of every line

00:16:57,960 --> 00:17:02,250
that would return a promise this gets

00:17:00,660 --> 00:17:04,620
rid of all the dot then callback so this

00:17:02,250 --> 00:17:07,770
looks really nice there's a problem

00:17:04,620 --> 00:17:10,170
however we're actually blocking too much

00:17:07,770 --> 00:17:12,120
anytime you see a weight just realize

00:17:10,170 --> 00:17:13,950
that no code below that away will

00:17:12,120 --> 00:17:17,220
execute in other words we're kind of

00:17:13,950 --> 00:17:19,650
hamstringing JavaScript's pattern of

00:17:17,220 --> 00:17:22,440
just going line by line by line without

00:17:19,650 --> 00:17:24,540
pausing for a breath so unfortunately

00:17:22,440 --> 00:17:26,400
we're actually forcing more things than

00:17:24,540 --> 00:17:29,340
necessary to execute one after another

00:17:26,400 --> 00:17:32,030
when in reality they could be executing

00:17:29,340 --> 00:17:34,590
in parallel or I should say concurrently

00:17:32,030 --> 00:17:36,030
but if we wanted to execute some of this

00:17:34,590 --> 00:17:37,950
code concurrently you know

00:17:36,030 --> 00:17:39,390
squint at this and try to figure out hmm

00:17:37,950 --> 00:17:42,690
some of these things yeah they can run

00:17:39,390 --> 00:17:44,940
in concurrently but to do that you have

00:17:42,690 --> 00:17:47,400
to sacrifice those really elegant awaits

00:17:44,940 --> 00:17:49,860
here's one way we might do that we could

00:17:47,400 --> 00:17:51,840
use promised doll to block further code

00:17:49,860 --> 00:17:54,660
until the file reader and the parser

00:17:51,840 --> 00:17:57,030
have finished before computing the

00:17:54,660 --> 00:17:59,370
song's duration or importing in album

00:17:57,030 --> 00:18:01,320
not only does this uglify the solution

00:17:59,370 --> 00:18:04,230
quite a bit but more disturbingly it's

00:18:01,320 --> 00:18:06,600
still a suboptimal solution if the file

00:18:04,230 --> 00:18:08,940
reader for example finishes before the

00:18:06,600 --> 00:18:11,430
parser there's no reason the import

00:18:08,940 --> 00:18:14,370
album couldn't already begin doing its

00:18:11,430 --> 00:18:16,350
work the problem is it takes a fair

00:18:14,370 --> 00:18:19,350
amount of work to figure out the optimal

00:18:16,350 --> 00:18:22,170
grouping of which tasks can be run in

00:18:19,350 --> 00:18:24,660
parallel and any time you switch any one

00:18:22,170 --> 00:18:28,020
of these steps from asynchronous API to

00:18:24,660 --> 00:18:29,880
an async one it completely changes that

00:18:28,020 --> 00:18:30,870
optimal solution which means you're

00:18:29,880 --> 00:18:32,280
going to have a lot of code sharing

00:18:30,870 --> 00:18:35,160
you're gonna have very large get discs

00:18:32,280 --> 00:18:37,020
so luckily there's another way that we

00:18:35,160 --> 00:18:40,410
can model these kinds of concurrency

00:18:37,020 --> 00:18:44,100
relationships so what if we modeled each

00:18:40,410 --> 00:18:46,350
chunk of code as a dependency graph for

00:18:44,100 --> 00:18:48,480
the runtime to evaluate just like we did

00:18:46,350 --> 00:18:52,200
with my to-do list for coming to speak

00:18:48,480 --> 00:18:54,060
at J's conf to accomplish this we're

00:18:52,200 --> 00:18:56,040
going to use a pattern called the async

00:18:54,060 --> 00:18:58,110
immediately invoked function expression

00:18:56,040 --> 00:19:01,410
it's an elegant pattern for managing

00:18:58,110 --> 00:19:02,970
concurrency on a single thread now most

00:19:01,410 --> 00:19:05,370
of you have probably already seen async

00:19:02,970 --> 00:19:08,010
functions something to keep in mind is

00:19:05,370 --> 00:19:10,910
that in async function when invoked

00:19:08,010 --> 00:19:13,500
always returns a promise no exception

00:19:10,910 --> 00:19:15,750
even if there's an error it's just

00:19:13,500 --> 00:19:18,330
returns a promise that rejects so the

00:19:15,750 --> 00:19:21,540
return value from an async function

00:19:18,330 --> 00:19:23,130
invoked is always a promise so in async

00:19:21,540 --> 00:19:25,530
if e is just you creating an async

00:19:23,130 --> 00:19:29,160
function an anonymous one and you invoke

00:19:25,530 --> 00:19:31,890
it so the async Afiya allows us to group

00:19:29,160 --> 00:19:34,110
together sequential code into a single

00:19:31,890 --> 00:19:36,930
unit we might call a task and then

00:19:34,110 --> 00:19:39,900
immediately invokes it a task can depend

00:19:36,930 --> 00:19:43,170
on other tasks as a source of input but

00:19:39,900 --> 00:19:45,600
it produces a single return value as its

00:19:43,170 --> 00:19:47,220
output which means that this async if e

00:19:45,600 --> 00:19:49,080
is going to return a promise that

00:19:47,220 --> 00:19:51,419
resolves to the results

00:19:49,080 --> 00:19:54,749
now the task local variable that you see

00:19:51,419 --> 00:19:55,619
is also going to be a promise so if

00:19:54,749 --> 00:19:58,080
there's one thing you should take away

00:19:55,619 --> 00:20:00,450
from this talk it should be the async if

00:19:58,080 --> 00:20:05,580
you design pattern it kind of resembles

00:20:00,450 --> 00:20:06,960
a task in a task runner like a gulp like

00:20:05,580 --> 00:20:08,879
gulp or a makefile

00:20:06,960 --> 00:20:10,230
so if it helps you can think of async

00:20:08,879 --> 00:20:13,019
appeases sort of like those different

00:20:10,230 --> 00:20:15,210
tasks in a task runner now if we

00:20:13,019 --> 00:20:17,159
refactor our mp3 importer code into

00:20:15,210 --> 00:20:19,710
multiple tasks here's one way we might

00:20:17,159 --> 00:20:21,690
break it down so first when we read in

00:20:19,710 --> 00:20:23,669
that file this just returns a promise

00:20:21,690 --> 00:20:26,970
just for naming conventions I might call

00:20:23,669 --> 00:20:29,129
this the read task and then the meta

00:20:26,970 --> 00:20:31,529
task would just run that parsing code

00:20:29,129 --> 00:20:34,919
now you notice in every single one of

00:20:31,529 --> 00:20:37,769
these tasks all these operations depend

00:20:34,919 --> 00:20:40,710
on the very previous line in other words

00:20:37,769 --> 00:20:43,559
there's no line in any of these tasks

00:20:40,710 --> 00:20:45,419
that doesn't depend on everything before

00:20:43,559 --> 00:20:47,940
it we've tried to separate that out into

00:20:45,419 --> 00:20:50,220
these small chunks now each task is an

00:20:47,940 --> 00:20:52,919
async iffy so it returns a promise which

00:20:50,220 --> 00:20:55,649
evaluates to the functions return value

00:20:52,919 --> 00:20:57,809
at the very end the thing that kind of

00:20:55,649 --> 00:21:00,600
kick starts this process is when we're

00:20:57,809 --> 00:21:03,269
awaiting the song import task which is

00:21:00,600 --> 00:21:08,129
sort of the top level task that calls

00:21:03,269 --> 00:21:09,690
all these others so with multiple tasks

00:21:08,129 --> 00:21:11,730
we're just leveraging local variables

00:21:09,690 --> 00:21:13,230
and concurrency by default to

00:21:11,730 --> 00:21:14,759
essentially create a dependency graph

00:21:13,230 --> 00:21:16,889
which the JavaScript runtime will

00:21:14,759 --> 00:21:19,289
optimally evaluate for us no matter how

00:21:16,889 --> 00:21:21,179
complex it is so if we were to break

00:21:19,289 --> 00:21:22,980
these down you could imagine that this

00:21:21,179 --> 00:21:24,509
is the dependency graph that we've just

00:21:22,980 --> 00:21:26,309
modeled but we didn't actually have to

00:21:24,509 --> 00:21:28,049
type this out ourselves we didn't have

00:21:26,309 --> 00:21:30,330
to explicitly define that execution

00:21:28,049 --> 00:21:32,609
order just by wrapping sequential chunks

00:21:30,330 --> 00:21:34,289
of code into a sink if ease we modeled

00:21:32,609 --> 00:21:36,809
the constraints and let JavaScript

00:21:34,289 --> 00:21:39,869
figure out how to satisfy those

00:21:36,809 --> 00:21:41,460
constraints again there's tons more to

00:21:39,869 --> 00:21:42,809
the async if you pattern so definitely

00:21:41,460 --> 00:21:47,820
check out this blog post to learn more

00:21:42,809 --> 00:21:51,480
bitly slash async - if II leave that up

00:21:47,820 --> 00:21:53,759
just for a moment so our second step to

00:21:51,480 --> 00:21:56,549
creating elegant scalable code is to

00:21:53,759 --> 00:21:58,019
define execution preferences async

00:21:56,549 --> 00:22:00,210
ephese allow us to define those

00:21:58,019 --> 00:22:02,310
constraints how things have to execute

00:22:00,210 --> 00:22:05,010
but a lot of times you

00:22:02,310 --> 00:22:06,270
to say how would we like these things to

00:22:05,010 --> 00:22:08,760
be executed how would we like to

00:22:06,270 --> 00:22:10,560
prioritize them in particular how could

00:22:08,760 --> 00:22:12,840
we throttle how many things are allowed

00:22:10,560 --> 00:22:15,210
to run concurrently with functional

00:22:12,840 --> 00:22:17,100
programming so our mp3 importer right

00:22:15,210 --> 00:22:17,760
now runs as fast as possible which is

00:22:17,100 --> 00:22:19,770
fabulous

00:22:17,760 --> 00:22:21,750
but this is a browser so we need to be

00:22:19,770 --> 00:22:25,110
considerate of the CPU which is after

00:22:21,750 --> 00:22:26,370
all a limited resource so a syncope has

00:22:25,110 --> 00:22:28,920
led us to find those execution

00:22:26,370 --> 00:22:31,830
constraints how could we declaratively

00:22:28,920 --> 00:22:34,500
define our preferences for how that work

00:22:31,830 --> 00:22:36,600
gets executed on the CPU for example in

00:22:34,500 --> 00:22:40,730
our application if a user drops in a

00:22:36,600 --> 00:22:43,530
very large collection of mp3s by default

00:22:40,730 --> 00:22:46,110
we might either import all these songs

00:22:43,530 --> 00:22:49,200
one by one which is not so cool or we

00:22:46,110 --> 00:22:50,760
might import them all at once now your

00:22:49,200 --> 00:22:52,470
solution is great in particular if we

00:22:50,760 --> 00:22:54,150
started importing all of them at once

00:22:52,470 --> 00:22:56,880
we might get this really irritating

00:22:54,150 --> 00:22:58,740
progress bar behavior like this where it

00:22:56,880 --> 00:23:01,800
jumps from oh I'm importing the first

00:22:58,740 --> 00:23:03,750
one and then 20 seconds later it jumps

00:23:01,800 --> 00:23:05,490
all the way to the hand since all those

00:23:03,750 --> 00:23:06,810
songs started importing at the same time

00:23:05,490 --> 00:23:08,910
the progress bar is basically

00:23:06,810 --> 00:23:11,270
meaningless to the user and it will

00:23:08,910 --> 00:23:14,400
often lock up the browser also not great

00:23:11,270 --> 00:23:16,860
so instead what if we said well we only

00:23:14,400 --> 00:23:18,750
want to import a few songs at a time and

00:23:16,860 --> 00:23:20,910
then we'll queue up the others for

00:23:18,750 --> 00:23:23,760
import once another song finishes

00:23:20,910 --> 00:23:29,070
importing so only importing a few at a

00:23:23,760 --> 00:23:31,140
time so in many threaded languages you

00:23:29,070 --> 00:23:34,170
can accomplish something like this with

00:23:31,140 --> 00:23:37,320
semaphores semaphores are an object that

00:23:34,170 --> 00:23:41,100
represent a limited resource and you can

00:23:37,320 --> 00:23:43,740
acquire and release access to it to

00:23:41,100 --> 00:23:44,820
basically throttle how many times or how

00:23:43,740 --> 00:23:48,600
many people are trying to use that

00:23:44,820 --> 00:23:50,010
semaphore so for example the CPU is an

00:23:48,600 --> 00:23:52,020
example of something a semaphore might

00:23:50,010 --> 00:23:55,260
represent it could be a database or even

00:23:52,020 --> 00:23:57,090
network i/o at their extreme we could

00:23:55,260 --> 00:23:59,370
limit it to one client at a time which

00:23:57,090 --> 00:24:00,960
we would call a mutex now in an

00:23:59,370 --> 00:24:02,940
object-oriented paradigm we could

00:24:00,960 --> 00:24:05,040
initialize a semaphore object with the

00:24:02,940 --> 00:24:07,800
maximum number of concurrent clients and

00:24:05,040 --> 00:24:09,630
use a wait to acquire a spot in the

00:24:07,800 --> 00:24:11,760
queue before we execute our code and

00:24:09,630 --> 00:24:12,450
then once a spot opens up we do some

00:24:11,760 --> 00:24:14,970
things

00:24:12,450 --> 00:24:18,630
and we release our spot so another

00:24:14,970 --> 00:24:20,910
client can execute some code so here's a

00:24:18,630 --> 00:24:23,010
sample object-oriented solution to

00:24:20,910 --> 00:24:24,300
creating a semaphore and it just tracks

00:24:23,010 --> 00:24:26,880
functions that are waiting to be

00:24:24,300 --> 00:24:28,410
executed and whenever a spot opens up it

00:24:26,880 --> 00:24:34,590
executes the next function in the queue

00:24:28,410 --> 00:24:36,000
so this is very standard cs20 101 type

00:24:34,590 --> 00:24:38,550
solution you would probably write for

00:24:36,000 --> 00:24:40,230
semaphore unfortunately there's some

00:24:38,550 --> 00:24:41,840
really brittle boilerplate with an

00:24:40,230 --> 00:24:44,490
object-oriented solution for a semaphore

00:24:41,840 --> 00:24:47,160
in particular we could easily write code

00:24:44,490 --> 00:24:48,030
that will acquire a semaphore but never

00:24:47,160 --> 00:24:49,860
release it

00:24:48,030 --> 00:24:51,690
perhaps we throw an exception which will

00:24:49,860 --> 00:24:54,320
blow up the rest of the function so now

00:24:51,690 --> 00:24:57,420
that some before will never be released

00:24:54,320 --> 00:24:58,890
so instead here's a functional

00:24:57,420 --> 00:25:00,660
programming version of that same

00:24:58,890 --> 00:25:02,640
semaphore and instead of returning an

00:25:00,660 --> 00:25:05,220
object it's going to return a

00:25:02,640 --> 00:25:07,140
higher-order function that wraps up

00:25:05,220 --> 00:25:08,970
other functions with a call to acquire

00:25:07,140 --> 00:25:11,340
and release so you can almost think of

00:25:08,970 --> 00:25:14,180
it as it I can take any function and

00:25:11,340 --> 00:25:18,810
I'll prepend it with a choir and then

00:25:14,180 --> 00:25:20,460
suffix it with dot release so use this

00:25:18,810 --> 00:25:22,590
functional sum before we can invoke it

00:25:20,460 --> 00:25:25,260
with an async function now there's no

00:25:22,590 --> 00:25:27,960
way a semaphore can be acquired but not

00:25:25,260 --> 00:25:29,280
released now we're actually only one

00:25:27,960 --> 00:25:30,960
step away from turning this into a

00:25:29,280 --> 00:25:33,000
really elegant higher-order function

00:25:30,960 --> 00:25:35,400
that doesn't even force us to think

00:25:33,000 --> 00:25:37,680
about semaphores at all so let's suppose

00:25:35,400 --> 00:25:41,250
that we want to limit how many times our

00:25:37,680 --> 00:25:43,140
import mp3 function is called and we

00:25:41,250 --> 00:25:45,270
want to limit how many times it can be

00:25:43,140 --> 00:25:48,270
run concurrently so in other words if

00:25:45,270 --> 00:25:50,250
you call import mp3 four times right

00:25:48,270 --> 00:25:52,470
after each other say we only want to

00:25:50,250 --> 00:25:55,620
allow two instances of that function to

00:25:52,470 --> 00:25:57,930
run at a time and then it would delay

00:25:55,620 --> 00:26:00,210
the third and fourth invocations until

00:25:57,930 --> 00:26:03,060
there's a slot left until one of those

00:26:00,210 --> 00:26:04,770
first two invocations is finished so we

00:26:03,060 --> 00:26:06,870
could think of this function we might

00:26:04,770 --> 00:26:08,850
call it limit we could think of it as a

00:26:06,870 --> 00:26:11,370
decorator or higher-order function and

00:26:08,850 --> 00:26:14,130
it takes an async function that usually

00:26:11,370 --> 00:26:15,570
runs with unlimited concurrency and it

00:26:14,130 --> 00:26:17,910
returns the same function but now

00:26:15,570 --> 00:26:19,950
composed with throttling behavior so

00:26:17,910 --> 00:26:21,810
this example would take our mp3 importer

00:26:19,950 --> 00:26:24,570
function and return a new function that

00:26:21,810 --> 00:26:25,690
looks exactly the same but only allows

00:26:24,570 --> 00:26:28,420
two instances

00:26:25,690 --> 00:26:31,090
function to run concurrently so in this

00:26:28,420 --> 00:26:33,970
example song 1 and song 2 will

00:26:31,090 --> 00:26:35,950
immediately begin importing but song 3

00:26:33,970 --> 00:26:38,260
won't even begin importing until song 1

00:26:35,950 --> 00:26:41,650
or song 2 finishes meaning there's a

00:26:38,260 --> 00:26:43,480
slot in the semaphore the limit function

00:26:41,650 --> 00:26:45,040
it turns out is really easy to write

00:26:43,480 --> 00:26:47,260
with a semaphore we built it's just

00:26:45,040 --> 00:26:48,970
three or four lines of code but the key

00:26:47,260 --> 00:26:51,580
takeaway from this is that instead of

00:26:48,970 --> 00:26:54,130
focusing now on managing this abstract

00:26:51,580 --> 00:26:56,770
semaphore object we're focusing on

00:26:54,130 --> 00:26:58,570
creating functions with new throttling

00:26:56,770 --> 00:27:00,520
behavior it's really elegant and cuts

00:26:58,570 --> 00:27:02,290
down on potential bugs from trying to

00:27:00,520 --> 00:27:04,900
share a similar object throughout your

00:27:02,290 --> 00:27:07,210
codebase and it preserves your existing

00:27:04,900 --> 00:27:09,100
API so that way if you want to throttle

00:27:07,210 --> 00:27:10,960
concurrency in your codebase you don't

00:27:09,100 --> 00:27:13,930
have to refactor your code or change any

00:27:10,960 --> 00:27:15,700
of your api's again there's a whole lot

00:27:13,930 --> 00:27:17,110
more we could dive into here so feel

00:27:15,700 --> 00:27:19,330
free to check out the source code in

00:27:17,110 --> 00:27:20,860
particular for the semaphore if you want

00:27:19,330 --> 00:27:24,540
to play around without a bit on github

00:27:20,860 --> 00:27:27,640
but the final component of this talk is

00:27:24,540 --> 00:27:31,450
how can we create our own long-lived

00:27:27,640 --> 00:27:32,230
async tasks with a web worker cluster so

00:27:31,450 --> 00:27:34,090
what do I mean by this

00:27:32,230 --> 00:27:36,340
so the browser comes with a huge

00:27:34,090 --> 00:27:36,910
selection of async api's that we use all

00:27:36,340 --> 00:27:39,310
the time

00:27:36,910 --> 00:27:41,440
these api's are natively implemented

00:27:39,310 --> 00:27:44,200
there's not JavaScript code behind in

00:27:41,440 --> 00:27:46,780
Ajax requests so for example the fetch

00:27:44,200 --> 00:27:49,360
on index DB abis are all natively

00:27:46,780 --> 00:27:50,830
implemented and they use promises and

00:27:49,360 --> 00:27:53,800
other asynchronous mechanisms like

00:27:50,830 --> 00:27:55,930
callbacks now under the hood the browser

00:27:53,800 --> 00:27:58,090
handles this by managing a dedicated

00:27:55,930 --> 00:28:00,940
thread pool that's ready to crunch those

00:27:58,090 --> 00:28:04,300
async api's for you whenever you try to

00:28:00,940 --> 00:28:06,250
use one of these async api's but what if

00:28:04,300 --> 00:28:08,740
you could create your own how would you

00:28:06,250 --> 00:28:11,050
create your own native async api's for

00:28:08,740 --> 00:28:13,000
your own long-lived async operations

00:28:11,050 --> 00:28:14,440
that maybe they take up a lot of time

00:28:13,000 --> 00:28:14,770
and you don't want to block the main

00:28:14,440 --> 00:28:16,990
thread

00:28:14,770 --> 00:28:19,570
for example maybe we want to move our

00:28:16,990 --> 00:28:22,300
mp3 importer off the main thread which

00:28:19,570 --> 00:28:24,400
is also rendering the UI maybe we want

00:28:22,300 --> 00:28:26,710
to move it to the background so that way

00:28:24,400 --> 00:28:28,660
it won't lock up the UI if it takes a

00:28:26,710 --> 00:28:29,320
particularly long time to import some of

00:28:28,660 --> 00:28:31,630
these mp3s

00:28:29,320 --> 00:28:34,180
well web workers are essentially that

00:28:31,630 --> 00:28:36,760
there are standard web api for creating

00:28:34,180 --> 00:28:38,680
background threads so to create a web

00:28:36,760 --> 00:28:39,320
worker we just invoke the worker

00:28:38,680 --> 00:28:41,210
construct

00:28:39,320 --> 00:28:42,710
and give it the path to the JavaScript

00:28:41,210 --> 00:28:45,200
code that will execute with its own

00:28:42,710 --> 00:28:47,150
dedicated scope and with its own event

00:28:45,200 --> 00:28:49,400
loop it's completely isolated from your

00:28:47,150 --> 00:28:52,100
main thread now to communicate with a

00:28:49,400 --> 00:28:54,350
worker you can only exchange messages

00:28:52,100 --> 00:28:56,510
this is a really important concept those

00:28:54,350 --> 00:28:58,310
of you have maybe tried elixir or some

00:28:56,510 --> 00:28:59,690
of these high concurrency high fault

00:28:58,310 --> 00:29:01,400
tolerance type languages are probably

00:28:59,690 --> 00:29:04,010
already familiar with this concept of

00:29:01,400 --> 00:29:06,080
exchanging messages basically it means

00:29:04,010 --> 00:29:08,240
the worker must be listening for that

00:29:06,080 --> 00:29:10,880
message and handle it as part of its own

00:29:08,240 --> 00:29:14,030
event loop cycle so in other words

00:29:10,880 --> 00:29:15,590
messages are received asynchronously now

00:29:14,030 --> 00:29:17,990
the main thread and the worker thread

00:29:15,590 --> 00:29:19,760
don't have to both block to exchange

00:29:17,990 --> 00:29:21,370
that message they just send and check

00:29:19,760 --> 00:29:23,870
for messages whenever they're ready to

00:29:21,370 --> 00:29:26,150
now the basic web worker API is not

00:29:23,870 --> 00:29:27,830
exceptionally elegant if you want to

00:29:26,150 --> 00:29:29,270
have a two-way conversation between the

00:29:27,830 --> 00:29:31,840
worker main thread it can really quickly

00:29:29,270 --> 00:29:34,610
turn into this really ugly callbacks OOP

00:29:31,840 --> 00:29:37,760
so what if web workers looked more like

00:29:34,610 --> 00:29:39,710
an async web api call where we invoke it

00:29:37,760 --> 00:29:43,130
and we get a promise in return that

00:29:39,710 --> 00:29:45,050
resolves to the workers end result that

00:29:43,130 --> 00:29:47,240
would make it really trivial to move CPU

00:29:45,050 --> 00:29:49,040
intensive computations to a separate

00:29:47,240 --> 00:29:50,600
thread so we don't end up walking the

00:29:49,040 --> 00:29:52,460
main thread so you can imagine there's

00:29:50,600 --> 00:29:54,410
probably a lot of use cases for this up

00:29:52,460 --> 00:29:56,210
until cryptography was added to the

00:29:54,410 --> 00:29:58,280
browser standards cryptography would

00:29:56,210 --> 00:30:00,560
have been a really common use case same

00:29:58,280 --> 00:30:02,600
for doing any sort of 3d graphics maybe

00:30:00,560 --> 00:30:04,010
game rendering maybe you'd like to move

00:30:02,600 --> 00:30:05,600
these to the background off the main

00:30:04,010 --> 00:30:07,730
thread but you don't have to completely

00:30:05,600 --> 00:30:11,360
rewrite your code base to take advantage

00:30:07,730 --> 00:30:13,310
of it so in particular we're going to

00:30:11,360 --> 00:30:15,380
take our mp3 importer and move it into a

00:30:13,310 --> 00:30:18,950
worker and treat it as though it were a

00:30:15,380 --> 00:30:19,970
natively implemented async web api to do

00:30:18,950 --> 00:30:22,160
this we're going to create this

00:30:19,970 --> 00:30:24,080
mysterious cluster function to make the

00:30:22,160 --> 00:30:26,780
web worker API a little bit more elegant

00:30:24,080 --> 00:30:29,240
for our use case and cluster is just

00:30:26,780 --> 00:30:32,390
going to spin up a bunch of web workers

00:30:29,240 --> 00:30:34,160
in the background for us and these web

00:30:32,390 --> 00:30:36,380
workers will handle the task of

00:30:34,160 --> 00:30:37,670
importing mp3s so a functional

00:30:36,380 --> 00:30:40,160
programming the implementation for this

00:30:37,670 --> 00:30:41,870
cluster is actually really terse so this

00:30:40,160 --> 00:30:43,640
code has a lot of stuff at the beginning

00:30:41,870 --> 00:30:45,530
basically it figures out what's the best

00:30:43,640 --> 00:30:48,430
number of web workers to use usually

00:30:45,530 --> 00:30:51,320
that's how many virtual cores you have

00:30:48,430 --> 00:30:52,070
so it creates these different workers

00:30:51,320 --> 00:30:53,660
and it put

00:30:52,070 --> 00:30:55,340
some in an array to keep track of it's

00:30:53,660 --> 00:30:58,430
basically a pool of workers and each

00:30:55,340 --> 00:31:00,200
time we try to invoke that cluster it

00:30:58,430 --> 00:31:02,210
grabs a worker from the pool that's

00:31:00,200 --> 00:31:04,160
currently unused and it forwards along

00:31:02,210 --> 00:31:05,840
some data so this would be us invoking

00:31:04,160 --> 00:31:07,610
cluster we pass some argument those

00:31:05,840 --> 00:31:10,400
arguments get forwarded to the worker

00:31:07,610 --> 00:31:11,480
once the worker finishes and replies

00:31:10,400 --> 00:31:14,150
with the result

00:31:11,480 --> 00:31:15,380
it adds itself back to the pool to say

00:31:14,150 --> 00:31:17,030
hey I'm not currently working on

00:31:15,380 --> 00:31:19,490
anything you can use me for a different

00:31:17,030 --> 00:31:22,760
computation and the overall promise will

00:31:19,490 --> 00:31:25,670
evaluate to that result the code for the

00:31:22,760 --> 00:31:27,590
web worker itself is really short it's

00:31:25,670 --> 00:31:29,360
an infinite loop that just receives data

00:31:27,590 --> 00:31:31,130
from the main thread it does some work

00:31:29,360 --> 00:31:33,530
and then it notifies the main thread

00:31:31,130 --> 00:31:34,970
when it's done with that computation by

00:31:33,530 --> 00:31:38,120
the way this isn't just for the browser

00:31:34,970 --> 00:31:40,520
you can use a popular facade library to

00:31:38,120 --> 00:31:42,650
write web workers in node as well with

00:31:40,520 --> 00:31:44,510
the same API and under the hood it uses

00:31:42,650 --> 00:31:47,000
native multi-threading so this isn't

00:31:44,510 --> 00:31:49,970
just for the front-end browser so you

00:31:47,000 --> 00:31:52,610
could imagine moving all kinds of CPU

00:31:49,970 --> 00:31:53,990
intensive operations with just a few

00:31:52,610 --> 00:31:55,610
lines of code you can actually get with

00:31:53,990 --> 00:31:57,620
fewer than this if you write a little

00:31:55,610 --> 00:32:00,650
utility function you can imagine moving

00:31:57,620 --> 00:32:03,140
all of these into web workers so a

00:32:00,650 --> 00:32:04,790
little bit long time so the TLDR from

00:32:03,140 --> 00:32:07,850
this really is that javascript in the

00:32:04,790 --> 00:32:10,280
browser and node.js is highly concurrent

00:32:07,850 --> 00:32:12,140
out-of-the-box so things like async

00:32:10,280 --> 00:32:15,260
appease can help us define those

00:32:12,140 --> 00:32:16,610
execution constraints thanks to the

00:32:15,260 --> 00:32:18,830
event loop we don't have to even worry

00:32:16,610 --> 00:32:20,090
about thread safety or re-entrance e or

00:32:18,830 --> 00:32:22,130
a lot of these other things you might be

00:32:20,090 --> 00:32:24,890
familiar with with language like C or

00:32:22,130 --> 00:32:26,660
Java and functional programming patterns

00:32:24,890 --> 00:32:28,580
keep us from making a mess of things

00:32:26,660 --> 00:32:30,380
just for the sake of that threading it

00:32:28,580 --> 00:32:32,780
all happens pretty seamlessly for us and

00:32:30,380 --> 00:32:35,420
if there isn't an async Web API for

00:32:32,780 --> 00:32:37,550
something you need maybe its 3d graphics

00:32:35,420 --> 00:32:39,470
related or cryptography related just

00:32:37,550 --> 00:32:41,180
write your own web worker and treat it

00:32:39,470 --> 00:32:43,580
like a native async web api

00:32:41,180 --> 00:32:45,740
so next time you're told just remember

00:32:43,580 --> 00:32:47,510
you can always bet on JavaScript to help

00:32:45,740 --> 00:32:49,430
you leverage multi-core machines and

00:32:47,510 --> 00:32:51,770
crunch there to do loops through to-do

00:32:49,430 --> 00:32:56,740
lists so you won't soak your favorite

00:32:51,770 --> 00:32:56,740
book in the shower like I did so

00:33:02,710 --> 00:33:06,910
my timeshare on this room CPU is up so

00:33:05,290 --> 00:33:08,380
if you like pretty pictures and travel

00:33:06,910 --> 00:33:11,410
stories you can hop to my landscape

00:33:08,380 --> 00:33:13,630
photography site yellow scale.com or you

00:33:11,410 --> 00:33:16,710
can find me on twitter as at nibbler

00:33:13,630 --> 00:33:16,710

YouTube URL: https://www.youtube.com/watch?v=726eZyVtC0Y


