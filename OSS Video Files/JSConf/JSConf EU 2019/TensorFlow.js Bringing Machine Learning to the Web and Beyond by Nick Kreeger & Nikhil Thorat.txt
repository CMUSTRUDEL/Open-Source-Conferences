Title: TensorFlow.js Bringing Machine Learning to the Web and Beyond by Nick Kreeger & Nikhil Thorat
Publication date: 2019-07-01
Playlist: JSConf EU 2019
Description: 
	Machine Learning is a powerful tool that offers unique opportunities for JavaScript developers. This is why we created TensorFlow.js, a library for training and deploying ML models in the browser and in Node.js. In this talk, you will learn about the TensorFlow.js ecosystem: how to bring an existing ML model into your JS app and re-train the model using your data. We’ll also go over our efforts beyond the browser to bring ML to platforms such as React Native, Raspberry Pi, and Electron, and we’ll do a live demo of some of our favorite and unique applications!

This talk will be co-presented by Nikhil Thorat.

https://2019.jsconf.eu/nick-kreeger/tensorflowjs-bringing-machine-learning-to-the-web-and-beyond.html
https://2019.jsconf.eu/nikhil-thorat/tensorflowjs-bringing-machine-learning-to-the-web-and-beyond.html
Captions: 
	00:00:00,760 --> 00:00:09,150
[Music]

00:00:05,810 --> 00:00:10,800
my name is Nikhil so we're here to

00:00:09,150 --> 00:00:13,830
talked about machine learning and

00:00:10,800 --> 00:00:15,660
JavaScript with tensorflow J's so if

00:00:13,830 --> 00:00:17,369
you're familiar at all with machine

00:00:15,660 --> 00:00:19,380
learning and data science you'll know

00:00:17,369 --> 00:00:21,330
that most of it happens in Python so

00:00:19,380 --> 00:00:23,250
this is a poll that was given by a

00:00:21,330 --> 00:00:25,680
popular data science blog called Katy

00:00:23,250 --> 00:00:28,230
nuggets and you can see that Python

00:00:25,680 --> 00:00:29,760
absolutely dominates and this is for a

00:00:28,230 --> 00:00:31,830
pretty good reason you know there has

00:00:29,760 --> 00:00:34,469
been many many years of tooling built in

00:00:31,830 --> 00:00:36,710
Python for data science from numpy to

00:00:34,469 --> 00:00:39,360
pandas to scikit-learn to tensorflow

00:00:36,710 --> 00:00:42,149
and this field is gonna continue to

00:00:39,360 --> 00:00:43,550
evolve in python and i don't have to

00:00:42,149 --> 00:00:45,600
convince the folks in this room

00:00:43,550 --> 00:00:47,430
javascript is a very very popular

00:00:45,600 --> 00:00:50,160
language this is obviously the October's

00:00:47,430 --> 00:00:53,280
survey by github and you can see that

00:00:50,160 --> 00:00:54,780
JavaScript absolutely dominates so we

00:00:53,280 --> 00:00:56,160
think that there's actually a lot of the

00:00:54,780 --> 00:00:58,520
JavaScript community and the folks in

00:00:56,160 --> 00:01:01,859
this room can bring to machine learning

00:00:58,520 --> 00:01:05,070
so who here has seen this this is

00:01:01,859 --> 00:01:06,840
tensorflow playground okay a few people

00:01:05,070 --> 00:01:09,540
but not a lot of people so I definitely

00:01:06,840 --> 00:01:11,610
recommend checking this link out this is

00:01:09,540 --> 00:01:13,560
an in-browser visualization of a neural

00:01:11,610 --> 00:01:15,840
network it was built by one of our

00:01:13,560 --> 00:01:18,000
colleagues at Google and the idea here

00:01:15,840 --> 00:01:20,369
is you can immediately change the number

00:01:18,000 --> 00:01:22,530
of layers neurons learning rate and so

00:01:20,369 --> 00:01:25,320
forth and immediately see how the neural

00:01:22,530 --> 00:01:27,210
network generalizes over a data set now

00:01:25,320 --> 00:01:28,920
this thing was a huge educational

00:01:27,210 --> 00:01:31,140
success you know it's being used in

00:01:28,920 --> 00:01:32,549
universities across the world now and in

00:01:31,140 --> 00:01:34,320
Google's own machine learning crash

00:01:32,549 --> 00:01:37,049
course so again I definitely recommend

00:01:34,320 --> 00:01:38,970
checking this out so we step back and we

00:01:37,049 --> 00:01:40,979
kind of asked ourselves you know why was

00:01:38,970 --> 00:01:42,390
this such a success like why do people

00:01:40,979 --> 00:01:44,280
care about this in browser machine

00:01:42,390 --> 00:01:46,110
learning thing at all and we kind of

00:01:44,280 --> 00:01:48,240
distilled it down into a few points so

00:01:46,110 --> 00:01:50,640
the obvious thing is that you just click

00:01:48,240 --> 00:01:52,979
a link and you get going if you've done

00:01:50,640 --> 00:01:55,380
any Python ml it's like really pain in

00:01:52,979 --> 00:01:57,149
the butt to get your drivers installed

00:01:55,380 --> 00:01:59,820
Python libraries installing that kind of

00:01:57,149 --> 00:02:00,840
thing it's super interactive you know

00:01:59,820 --> 00:02:02,100
you have buttons you have hyper

00:02:00,840 --> 00:02:04,049
parameters you can play you can

00:02:02,100 --> 00:02:06,860
immediately see how the changing the

00:02:04,049 --> 00:02:09,840
knobs affect the the the learning

00:02:06,860 --> 00:02:11,099
configuration of the model we didn't

00:02:09,840 --> 00:02:12,780
take advantage of this in the playground

00:02:11,099 --> 00:02:13,680
but you know in the JavaScript world in

00:02:12,780 --> 00:02:15,420
the browser you have

00:02:13,680 --> 00:02:16,920
cameras and microphones and standardized

00:02:15,420 --> 00:02:19,099
access to these things which you don't

00:02:16,920 --> 00:02:21,450
really get as much in the Python lab and

00:02:19,099 --> 00:02:23,129
super important to us is that you can

00:02:21,450 --> 00:02:25,170
actually make predictions locally and

00:02:23,129 --> 00:02:28,950
data can stay on the client so this is

00:02:25,170 --> 00:02:31,170
privacy-preserving so we took this and

00:02:28,950 --> 00:02:34,920
we launched a library called tensorflow

00:02:31,170 --> 00:02:38,040
JS we released it last year in March its

00:02:34,920 --> 00:02:39,480
GPU accelerated so we use WebGL to make

00:02:38,040 --> 00:02:41,790
everything fast so we actually do all

00:02:39,480 --> 00:02:43,739
the the linear algebra in fragment

00:02:41,790 --> 00:02:46,079
shaders and I'll talk a little bit about

00:02:43,739 --> 00:02:47,430
that in a second but one of the things

00:02:46,079 --> 00:02:48,659
that we do is we let you make

00:02:47,430 --> 00:02:50,549
predictions through machine learning

00:02:48,659 --> 00:02:52,500
models but we also let you train them

00:02:50,549 --> 00:02:54,180
directly in the browser or even in no

00:02:52,500 --> 00:02:57,209
Jess and we'll talk about about that as

00:02:54,180 --> 00:02:59,519
well so when designing the library you

00:02:57,209 --> 00:03:01,469
know we had a couple goals in mind one

00:02:59,519 --> 00:03:03,060
is that we wanted to empower a diverse

00:03:01,469 --> 00:03:04,439
group of Java developers like the folks

00:03:03,060 --> 00:03:05,849
in this room you know there's a lot of

00:03:04,439 --> 00:03:08,040
really awesome people in this community

00:03:05,849 --> 00:03:10,530
and we want to sort of marry these two

00:03:08,040 --> 00:03:12,329
worlds at the same time we wanted the

00:03:10,530 --> 00:03:14,219
folks who are experienced in the machine

00:03:12,329 --> 00:03:16,769
learning to be able to port their work

00:03:14,219 --> 00:03:18,510
to the web now these goals are kind of

00:03:16,769 --> 00:03:22,010
sometimes at conflict so we'll talk a

00:03:18,510 --> 00:03:23,970
little bit about how we resolve those

00:03:22,010 --> 00:03:25,620
okay so one of the principles that we

00:03:23,970 --> 00:03:28,199
had was we wanted the library to be

00:03:25,620 --> 00:03:30,150
super easy to use and we kind of leaned

00:03:28,199 --> 00:03:31,290
towards that over performance at the

00:03:30,150 --> 00:03:34,409
same time we didn't want to sacrifice

00:03:31,290 --> 00:03:37,590
any functionality for simplicity so just

00:03:34,409 --> 00:03:39,720
jumping into what that means we decided

00:03:37,590 --> 00:03:41,459
to go with this eager only approach I'm

00:03:39,720 --> 00:03:42,930
not going to go into what that means but

00:03:41,459 --> 00:03:44,400
it's a much simpler way of programming

00:03:42,930 --> 00:03:45,780
and actually most of the machine

00:03:44,400 --> 00:03:48,239
learning world is moving towards this

00:03:45,780 --> 00:03:49,379
eager approach versus a graph based

00:03:48,239 --> 00:03:51,900
approach where you actually stitch

00:03:49,379 --> 00:03:53,819
together a computation graph and execute

00:03:51,900 --> 00:03:56,579
it later and we've really wanted to be

00:03:53,819 --> 00:03:59,459
easy so we move towards eager we also

00:03:56,579 --> 00:04:01,379
provide a high level layers API which is

00:03:59,459 --> 00:04:02,849
a set of best practices in the machine

00:04:01,379 --> 00:04:04,199
learning community so you don't have to

00:04:02,849 --> 00:04:05,489
think about all the details of your

00:04:04,199 --> 00:04:08,909
linear algebra when you're constructing

00:04:05,489 --> 00:04:10,859
a model and we also provide a whole

00:04:08,909 --> 00:04:12,540
repository of pre trained models that

00:04:10,859 --> 00:04:14,250
require zero understanding of machine

00:04:12,540 --> 00:04:16,169
learning to get started and I'm going to

00:04:14,250 --> 00:04:19,229
show you a couple examples of those in a

00:04:16,169 --> 00:04:20,820
second and I want to highlight this we

00:04:19,229 --> 00:04:22,529
focus on performance when and where it

00:04:20,820 --> 00:04:24,990
matters obviously we want matrix

00:04:22,529 --> 00:04:27,180
multiplies to be fast what we did was we

00:04:24,990 --> 00:04:27,330
took individual models and we figured

00:04:27,180 --> 00:04:28,919
out

00:04:27,330 --> 00:04:33,000
how to make those individual models

00:04:28,919 --> 00:04:34,560
faster on a use case basis so as I said

00:04:33,000 --> 00:04:37,050
we don't want to actually make the

00:04:34,560 --> 00:04:39,150
library less functional so we support

00:04:37,050 --> 00:04:42,120
gradients this is fancy talk for

00:04:39,150 --> 00:04:44,009
sensitivity of each of the weights which

00:04:42,120 --> 00:04:45,870
means we can train through any operation

00:04:44,009 --> 00:04:48,000
that you use in the tensor flow chest

00:04:45,870 --> 00:04:50,250
library support a lot of the tensor flow

00:04:48,000 --> 00:04:52,020
ops 130 of them and for any of these

00:04:50,250 --> 00:04:54,389
models that we're about to show you you

00:04:52,020 --> 00:04:55,860
can actually dig down and get some of

00:04:54,389 --> 00:05:00,629
the machine learning constructs out of

00:04:55,860 --> 00:05:02,490
them if you want to okay so quickly

00:05:00,629 --> 00:05:04,740
jumping into what the technical stack

00:05:02,490 --> 00:05:06,539
looks like at the very top of the

00:05:04,740 --> 00:05:08,430
abstraction api's we have our models

00:05:06,539 --> 00:05:09,599
repo so this is set of pre trained

00:05:08,430 --> 00:05:10,949
models I'll show you a couple of those

00:05:09,599 --> 00:05:13,080
in a second require very little

00:05:10,949 --> 00:05:15,599
understanding of machine learning below

00:05:13,080 --> 00:05:17,400
that this is our layers API this is

00:05:15,599 --> 00:05:19,409
where you can construct a model you can

00:05:17,400 --> 00:05:21,479
train the model you can serialize the

00:05:19,409 --> 00:05:23,969
model for later and we'll show you some

00:05:21,479 --> 00:05:25,650
of that soon too and we also have below

00:05:23,969 --> 00:05:26,969
that our core API which is or just

00:05:25,650 --> 00:05:29,819
linear algebra kernels so these are

00:05:26,969 --> 00:05:33,150
matrix multiplies convolutions and their

00:05:29,819 --> 00:05:35,370
gradients which are derivatives so all

00:05:33,150 --> 00:05:38,099
of these api is you can sort of poke in

00:05:35,370 --> 00:05:39,690
at any of these abstraction layers all

00:05:38,099 --> 00:05:42,270
of these sit on top of WebGL in the

00:05:39,690 --> 00:05:44,789
browser we use fragment shaders to run

00:05:42,270 --> 00:05:47,339
all of our math in parallel and in node

00:05:44,789 --> 00:05:49,979
we actually bind with the N API to

00:05:47,339 --> 00:05:52,379
tensorflow C++ and what that means is if

00:05:49,979 --> 00:05:54,389
you use that same API for any of these

00:05:52,379 --> 00:05:56,250
things you immediately get the hardware

00:05:54,389 --> 00:05:58,830
acceleration that tensorflow has been

00:05:56,250 --> 00:06:00,960
working hard on for the CPU and for GPUs

00:05:58,830 --> 00:06:04,229
with CUDA and eventually we're gonna

00:06:00,960 --> 00:06:06,539
have TPU support it was also very

00:06:04,229 --> 00:06:08,370
important for us not to silo ourselves

00:06:06,539 --> 00:06:10,289
in the JavaScript world there is a whole

00:06:08,370 --> 00:06:12,120
wealth of models that are trained in the

00:06:10,289 --> 00:06:13,770
Python ecosystem that we want to take

00:06:12,120 --> 00:06:15,810
advantage of so we have converter tools

00:06:13,770 --> 00:06:17,789
that let you take a Karass model or a

00:06:15,810 --> 00:06:20,930
tensorflow Saves model and bring them

00:06:17,789 --> 00:06:23,669
back into the JavaScript world

00:06:20,930 --> 00:06:26,819
ok so let's quickly take a look at what

00:06:23,669 --> 00:06:29,159
the models repo looks like so if you

00:06:26,819 --> 00:06:31,889
check out this link these are all our

00:06:29,159 --> 00:06:34,289
pre trained models these are hosted on

00:06:31,889 --> 00:06:35,759
github and on NPM so we host all the

00:06:34,289 --> 00:06:37,979
weights and all the JavaScript for you

00:06:35,759 --> 00:06:40,060
and we have a wealth of models from

00:06:37,979 --> 00:06:42,520
object recognition to

00:06:40,060 --> 00:06:45,160
human pose detection - localization -

00:06:42,520 --> 00:06:47,110
segmentation - text classification and

00:06:45,160 --> 00:06:49,360
the list goes on just go check this link

00:06:47,110 --> 00:06:51,330
out but I want to show you one of the

00:06:49,360 --> 00:07:01,110
demos because it's fun

00:06:51,330 --> 00:07:03,669
so okay so this model is called pose net

00:07:01,110 --> 00:07:05,380
it's running completely in the browser

00:07:03,669 --> 00:07:08,020
nothing is being sent back to a server

00:07:05,380 --> 00:07:10,090
and the idea here is we take RGB images

00:07:08,020 --> 00:07:12,220
from webcam we pass it through this pose

00:07:10,090 --> 00:07:14,350
detection model that generates key

00:07:12,220 --> 00:07:16,960
points for each of you know sort of my

00:07:14,350 --> 00:07:18,040
body parts and then it returns an object

00:07:16,960 --> 00:07:19,600
that we can just render on the screen

00:07:18,040 --> 00:07:21,310
and obviously it works with two people

00:07:19,600 --> 00:07:23,530
so this is a lot of fun and we'll show

00:07:21,310 --> 00:07:27,100
you how to use one of these models in a

00:07:23,530 --> 00:07:29,080
minute the second model is very similar

00:07:27,100 --> 00:07:31,360
to pose net it's doing person

00:07:29,080 --> 00:07:33,100
segmentation so it's you know this

00:07:31,360 --> 00:07:36,490
backgrounds a little funny but basically

00:07:33,100 --> 00:07:38,110
what it does is it draws a mask of a one

00:07:36,490 --> 00:07:39,430
where it thinks is a human pose and a

00:07:38,110 --> 00:07:41,380
zero where it does where it thinks

00:07:39,430 --> 00:07:42,639
there's not so this is what this one's a

00:07:41,380 --> 00:07:44,440
lot of fun and I don't know if this is

00:07:42,639 --> 00:07:46,150
gonna show well here but one of the

00:07:44,440 --> 00:07:48,729
effects I really like is the portrait

00:07:46,150 --> 00:07:50,430
mode you can see this thing blurring so

00:07:48,729 --> 00:07:52,479
we have you know a software-based

00:07:50,430 --> 00:07:55,630
portrait mode that's running directly in

00:07:52,479 --> 00:07:56,950
the browser pretty fast okay so let's go

00:07:55,630 --> 00:07:58,539
back to the slides and I'm going to show

00:07:56,950 --> 00:08:00,760
you how that actually works and what the

00:07:58,539 --> 00:08:03,310
code looks like so that model is called

00:08:00,760 --> 00:08:04,810
body pics it's a pre trained person

00:08:03,310 --> 00:08:08,169
segmentation model that we've done a lot

00:08:04,810 --> 00:08:09,580
of work to make super fast pretty

00:08:08,169 --> 00:08:11,919
straightforward you import tensorflow

00:08:09,580 --> 00:08:13,570
jeaious and body pics to libraries we

00:08:11,919 --> 00:08:16,990
have them on NPM we host them on CDN for

00:08:13,570 --> 00:08:19,900
you we you know have a regular image tag

00:08:16,990 --> 00:08:23,050
that's it and this image is Frank now

00:08:19,900 --> 00:08:24,850
Frank is Knicks baby and he is doing a

00:08:23,050 --> 00:08:26,820
yoga pose for us so we're gonna try to

00:08:24,850 --> 00:08:29,770
figure out where Frank is in this image

00:08:26,820 --> 00:08:31,539
so first we just load the model we call

00:08:29,770 --> 00:08:33,760
a weight body picks out load and this is

00:08:31,539 --> 00:08:36,400
gonna download all of our weights these

00:08:33,760 --> 00:08:37,510
weights we host on our GCP buckets for

00:08:36,400 --> 00:08:40,450
you so you don't have to pay for any of

00:08:37,510 --> 00:08:42,070
that and then you just call one line of

00:08:40,450 --> 00:08:44,110
code SMA person segmentation on the

00:08:42,070 --> 00:08:46,209
image and you get a JSON object out and

00:08:44,110 --> 00:08:48,400
inside of that JSON object is a binary

00:08:46,209 --> 00:08:49,810
mask of where it thinks the kid is that

00:08:48,400 --> 00:08:52,480
is that simple you don't really have to

00:08:49,810 --> 00:08:53,610
understand the end all bits of this one

00:08:52,480 --> 00:08:56,610
of the other things is modeled

00:08:53,610 --> 00:08:58,320
you is parts as well so it'll tell you

00:08:56,610 --> 00:09:00,600
which pixels our face which pixels our

00:08:58,320 --> 00:09:02,970
arms and legs and so forth and we

00:09:00,600 --> 00:09:06,180
provide some fun utilities for drawing

00:09:02,970 --> 00:09:07,740
masks on top of those so you can imagine

00:09:06,180 --> 00:09:09,360
this being used for like a video game

00:09:07,740 --> 00:09:11,130
sprite you just jump around on screen

00:09:09,360 --> 00:09:15,300
and you immediately have a fun video

00:09:11,130 --> 00:09:16,649
game sprite okay so I don't have to

00:09:15,300 --> 00:09:18,360
explain this to people in the room but

00:09:16,649 --> 00:09:20,519
JavaScript runs in a ton of tunnel

00:09:18,360 --> 00:09:22,079
places and we're working hard to get

00:09:20,519 --> 00:09:24,390
tensorflow J's working in those places

00:09:22,079 --> 00:09:26,730
so we have the browser a node obviously

00:09:24,390 --> 00:09:28,350
but working on electron and react native

00:09:26,730 --> 00:09:30,120
and WeChat so we'll talk about those in

00:09:28,350 --> 00:09:31,950
a second but I want to show you some of

00:09:30,120 --> 00:09:34,529
the cool examples that we we like in

00:09:31,950 --> 00:09:37,019
these worlds so in the browser side

00:09:34,529 --> 00:09:38,279
hopefully the links are here we have a

00:09:37,019 --> 00:09:41,279
project called create ability this is

00:09:38,279 --> 00:09:43,260
one that's done by Google and it's a set

00:09:41,279 --> 00:09:46,170
of experiments around can we make

00:09:43,260 --> 00:09:48,240
interacting with music and art more

00:09:46,170 --> 00:09:49,709
accessible so we're using that pose net

00:09:48,240 --> 00:09:51,420
model that I showed you and we're

00:09:49,709 --> 00:09:53,100
actually able to play a synth with just

00:09:51,420 --> 00:09:54,690
our face this runs completely in the

00:09:53,100 --> 00:09:56,660
browser the link is there go try this

00:09:54,690 --> 00:09:58,920
after the talk please

00:09:56,660 --> 00:10:02,100
cool so then we also have a project

00:09:58,920 --> 00:10:05,820
called uber manifold not by us by uber

00:10:02,100 --> 00:10:07,470
and this project is a way to debug and

00:10:05,820 --> 00:10:08,880
understand machine learning models as

00:10:07,470 --> 00:10:10,860
their training and I actually use

00:10:08,880 --> 00:10:12,449
tensive ojs just for linear algebra so

00:10:10,860 --> 00:10:15,750
fast matrix multiplications in the

00:10:12,449 --> 00:10:18,449
browser Airbnb is also using tensorflow

00:10:15,750 --> 00:10:20,339
J's they ship a little model to the to

00:10:18,449 --> 00:10:22,410
the client so when you're about to

00:10:20,339 --> 00:10:24,300
upload a profile picture if they see a

00:10:22,410 --> 00:10:26,459
license or a government-issued passport

00:10:24,300 --> 00:10:27,779
in that in that photo they'll yell at

00:10:26,459 --> 00:10:29,490
you before they upload to their server

00:10:27,779 --> 00:10:33,390
so they don't have to own that PII on

00:10:29,490 --> 00:10:34,709
the backend on the on the desktop and

00:10:33,390 --> 00:10:36,690
node there's a project called clinic

00:10:34,709 --> 00:10:39,449
doctor and clinic doctor is a project

00:10:36,690 --> 00:10:41,910
that monitors your node application for

00:10:39,449 --> 00:10:43,920
CPU spikes and they use tensorflow dress

00:10:41,910 --> 00:10:46,620
actually to disambiguate garbage

00:10:43,920 --> 00:10:49,079
collection spikes from your CPU in your

00:10:46,620 --> 00:10:50,760
in your actual program one of my

00:10:49,079 --> 00:10:52,949
personal favorites is a project called

00:10:50,760 --> 00:10:54,690
magenta studio magenta is a team at

00:10:52,949 --> 00:10:56,459
Google that does generative music and

00:10:54,690 --> 00:10:57,930
art and they actually have an electron

00:10:56,459 --> 00:11:00,660
app that plugs directly into Ableton

00:10:57,930 --> 00:11:03,120
Live and it can generate MIDI notes on a

00:11:00,660 --> 00:11:05,010
track for you or it can generate a drum

00:11:03,120 --> 00:11:07,440
beat alongside maybe a guitar groove

00:11:05,010 --> 00:11:09,360
that you have so this is a ton of

00:11:07,440 --> 00:11:10,800
on augments and existing work fro our

00:11:09,360 --> 00:11:14,280
workflow and you know JavaScript is

00:11:10,800 --> 00:11:16,640
awesome so of course we do it there okay

00:11:14,280 --> 00:11:18,780
so this other platform called WeChat is

00:11:16,640 --> 00:11:20,850
massive in China if people don't know

00:11:18,780 --> 00:11:22,760
about it it's got a billion users lots

00:11:20,850 --> 00:11:25,230
of mini programs lots of developers and

00:11:22,760 --> 00:11:26,760
they all run a Java Script and we're

00:11:25,230 --> 00:11:29,430
working hard to get GPU acceleration

00:11:26,760 --> 00:11:30,690
stories working inside of that with that

00:11:29,430 --> 00:11:32,030
I'm gonna hand it off to Nick to talk

00:11:30,690 --> 00:11:37,280
about some other stuff

00:11:32,030 --> 00:11:40,380
thanks aquel I speak kind of highlighted

00:11:37,280 --> 00:11:42,120
JavaScript runs in a lot of places and

00:11:40,380 --> 00:11:44,430
we're starting to think of areas where

00:11:42,120 --> 00:11:48,090
we can keep expanding where you can run

00:11:44,430 --> 00:11:49,530
tensorflow j/s i want to step back and

00:11:48,090 --> 00:11:52,560
talk about our node bindings first

00:11:49,530 --> 00:11:56,610
before we dive into the next topic we

00:11:52,560 --> 00:11:58,380
launched these about a year ago and the

00:11:56,610 --> 00:12:00,450
library is great because it's super fast

00:11:58,380 --> 00:12:03,660
it uses that C library like Nickell

00:12:00,450 --> 00:12:05,880
mentioned and it's great for deploying

00:12:03,660 --> 00:12:08,760
on the servers or doing local workflows

00:12:05,880 --> 00:12:10,170
on your desktop or workstation but there

00:12:08,760 --> 00:12:12,990
are a few downsides this particular

00:12:10,170 --> 00:12:15,030
library we have one of them is the GPU

00:12:12,990 --> 00:12:17,550
acceleration requires nvidia cuda

00:12:15,030 --> 00:12:20,550
library it's a really fast library but

00:12:17,550 --> 00:12:22,590
it's very large and we at tensorflow

00:12:20,550 --> 00:12:25,230
don't currently support mac OS so

00:12:22,590 --> 00:12:26,760
there's no GPU acceleration on math and

00:12:25,230 --> 00:12:29,190
the other thing is the node package

00:12:26,760 --> 00:12:32,100
itself is a native module all built on

00:12:29,190 --> 00:12:33,690
an API and it links to the C library of

00:12:32,100 --> 00:12:35,730
tensorflow that can be really large

00:12:33,690 --> 00:12:38,580
depending on which library you're using

00:12:35,730 --> 00:12:40,800
CUDA can be around 250 megabytes or so

00:12:38,580 --> 00:12:44,940
just on Linux so it's a very large

00:12:40,800 --> 00:12:46,320
package to ship so we started to think

00:12:44,940 --> 00:12:49,680
is there something in between we can do

00:12:46,320 --> 00:12:52,710
on node and we started working really

00:12:49,680 --> 00:12:55,230
hard and launched earlier this year a

00:12:52,710 --> 00:12:57,510
new headless graphic stack for node and

00:12:55,230 --> 00:12:59,550
we launched it it's called the node - -

00:12:57,510 --> 00:13:02,070
yes package we worked hard with the

00:12:59,550 --> 00:13:04,410
chrome team here to build a headless

00:13:02,070 --> 00:13:06,300
graphic stack for that and we wanted to

00:13:04,410 --> 00:13:08,990
take that and accelerate our existing

00:13:06,300 --> 00:13:12,030
WebGL stack all headless and node and

00:13:08,990 --> 00:13:13,800
this library runs by angle and angle is

00:13:12,030 --> 00:13:16,410
the driver we ship in chrome today and

00:13:13,800 --> 00:13:18,750
it translates WebGL calls to your native

00:13:16,410 --> 00:13:20,850
system graphics stack so in Windows

00:13:18,750 --> 00:13:23,309
that's direct3d

00:13:20,850 --> 00:13:26,279
OpenGL on windows and in your native Mac

00:13:23,309 --> 00:13:27,569
OS graphic stack implementation so we

00:13:26,279 --> 00:13:30,149
think this is gonna be great for some

00:13:27,569 --> 00:13:33,839
desktop apps like electron mobile and

00:13:30,149 --> 00:13:35,519
embedded space and in devices plus this

00:13:33,839 --> 00:13:38,279
is going to bring GPU acceleration to

00:13:35,519 --> 00:13:40,139
Mac OS we're working hard to finish this

00:13:38,279 --> 00:13:41,789
up a couple things so we're hoping the

00:13:40,139 --> 00:13:46,470
launch here later in June or sometime

00:13:41,789 --> 00:13:49,589
this summer and I wanted to show a demo

00:13:46,470 --> 00:13:53,639
of this actually running we've built a

00:13:49,589 --> 00:13:56,939
really quick electron app so if I go

00:13:53,639 --> 00:13:58,169
ahead and just run my app this app uses

00:13:56,939 --> 00:14:00,359
mobile net which is one of our

00:13:58,169 --> 00:14:01,949
out-of-the-box models that does basic

00:14:00,359 --> 00:14:04,949
image classification so you can see an

00:14:01,949 --> 00:14:10,079
image and tell you what it is so as I

00:14:04,949 --> 00:14:13,470
pull up in my app here lo not the most

00:14:10,079 --> 00:14:14,609
exciting UI but we it shows the GL stack

00:14:13,470 --> 00:14:17,669
that's running you can see it's running

00:14:14,609 --> 00:14:20,339
angle with an open Geo for one core and

00:14:17,669 --> 00:14:22,859
the latest OpenGL ES stack through angle

00:14:20,339 --> 00:14:24,149
and when I click run demo what's

00:14:22,859 --> 00:14:26,819
happening it's going out it's fetching

00:14:24,149 --> 00:14:28,529
our model it's loading it and it

00:14:26,819 --> 00:14:30,839
predicted that that's a Labrador

00:14:28,529 --> 00:14:33,539
Retriever and we're running about 150

00:14:30,839 --> 00:14:35,249
milliseconds or I'm sorry running 150

00:14:33,539 --> 00:14:37,289
predictions on an image and our

00:14:35,249 --> 00:14:39,209
averaging about 23 milliseconds so

00:14:37,289 --> 00:14:42,179
that's that's very close to 30 frames a

00:14:39,209 --> 00:14:43,919
second in real time so we think this is

00:14:42,179 --> 00:14:47,729
going to be really great on the electron

00:14:43,919 --> 00:14:49,589
side it doesn't block your UI thread for

00:14:47,729 --> 00:14:52,709
doing all the displays your dispatching

00:14:49,589 --> 00:14:55,079
all these Kreml calls through the node

00:14:52,709 --> 00:14:56,669
process all with a headless GL and that

00:14:55,079 --> 00:15:01,709
package is like five to ten megabytes

00:14:56,669 --> 00:15:04,799
it's very small and I also wanted to

00:15:01,709 --> 00:15:08,220
show one other thing this is the latest

00:15:04,799 --> 00:15:11,129
type of IOT boards this is a Nvidia

00:15:08,220 --> 00:15:13,859
Jetson Nano and basically just has a big

00:15:11,129 --> 00:15:16,049
GPU stapled to the top of it and we were

00:15:13,859 --> 00:15:18,149
able to last week at this writing with

00:15:16,049 --> 00:15:21,419
this headless stack as well running that

00:15:18,149 --> 00:15:22,559
same model a note console dump is it

00:15:21,419 --> 00:15:25,139
that most exciting but we're doing

00:15:22,559 --> 00:15:29,519
around 76 milliseconds of inference time

00:15:25,139 --> 00:15:32,440
just with the very thin arm 64 build of

00:15:29,519 --> 00:15:36,190
our our node back in

00:15:32,440 --> 00:15:37,389
I also want to talk about another

00:15:36,190 --> 00:15:40,360
library we've been working really hard

00:15:37,389 --> 00:15:43,509
and it's in browser visualization for

00:15:40,360 --> 00:15:46,600
our tensorflow GS library so ounce this

00:15:43,509 --> 00:15:48,069
package it's called TF GS - biz and you

00:15:46,600 --> 00:15:50,379
can think of it as like the chrome dev

00:15:48,069 --> 00:15:52,089
tools for ML models we have this thing

00:15:50,379 --> 00:15:54,220
called the visor and it slides out and

00:15:52,089 --> 00:15:57,069
it's a canvas for painting a bunch of

00:15:54,220 --> 00:15:59,019
elements that the library provides we

00:15:57,069 --> 00:16:03,459
have a bunch of built-in charts such as

00:15:59,019 --> 00:16:05,050
loss in accuracy for ML training we also

00:16:03,459 --> 00:16:07,209
have what we call high level

00:16:05,050 --> 00:16:09,250
visualization methods this basically

00:16:07,209 --> 00:16:11,319
allows you to look at those complicated

00:16:09,250 --> 00:16:13,509
hops like convolutions which do a bunch

00:16:11,319 --> 00:16:14,920
of filters on your image while you're

00:16:13,509 --> 00:16:18,910
training and see what's happening in

00:16:14,920 --> 00:16:21,189
between each of those convolutions model

00:16:18,910 --> 00:16:23,350
evaluation utilities is another set of

00:16:21,189 --> 00:16:26,199
drawing libraries and that sort of shows

00:16:23,350 --> 00:16:28,750
you where your model is might be over

00:16:26,199 --> 00:16:31,060
biased in particular class and ways that

00:16:28,750 --> 00:16:32,589
you can sort of see how you might alter

00:16:31,060 --> 00:16:37,660
your dataset to make sure you have a

00:16:32,589 --> 00:16:38,920
very nicely trained model all right

00:16:37,660 --> 00:16:40,420
we've been talking about we've shown you

00:16:38,920 --> 00:16:42,519
a lot of stuff but we want to show you a

00:16:40,420 --> 00:16:43,779
lot of the things that Nick held myself

00:16:42,519 --> 00:16:45,189
and the team have been thinking about

00:16:43,779 --> 00:16:46,769
and where we're going forward with the

00:16:45,189 --> 00:16:48,880
project

00:16:46,769 --> 00:16:52,000
one thing is we're really excited about

00:16:48,880 --> 00:16:54,360
the current future with all the new

00:16:52,000 --> 00:16:57,430
specs that are coming down the browser

00:16:54,360 --> 00:16:59,019
especially with JavaScript on the

00:16:57,430 --> 00:17:00,009
website we have two new standards we've

00:16:59,019 --> 00:17:04,089
been looking at really hard the last

00:17:00,009 --> 00:17:06,309
couple months one of them is web GPU web

00:17:04,089 --> 00:17:07,990
GPU is the next-generation graphic stack

00:17:06,309 --> 00:17:09,370
that's coming to the browser we've been

00:17:07,990 --> 00:17:11,799
working really hard with the chrome team

00:17:09,370 --> 00:17:14,500
to try to get that implementation up and

00:17:11,799 --> 00:17:17,709
rolling another one we've been looking

00:17:14,500 --> 00:17:20,169
at is wasum now in the ml world we

00:17:17,709 --> 00:17:22,740
really need to do Sindhi to make wasum a

00:17:20,169 --> 00:17:24,850
really an effective accelerator for CPUs

00:17:22,740 --> 00:17:26,530
so we've been working really hard on

00:17:24,850 --> 00:17:27,909
that with again with the chrome team and

00:17:26,530 --> 00:17:29,860
we're hoping to have something for

00:17:27,909 --> 00:17:33,900
devices where the GPU isn't all that

00:17:29,860 --> 00:17:33,900
great we can fall back to Lawson cindy

00:17:34,710 --> 00:17:39,870
one of the great parts about the ml

00:17:37,720 --> 00:17:43,120
space is just amount of research and

00:17:39,870 --> 00:17:46,380
we're finding about every year arm all

00:17:43,120 --> 00:17:49,060
the same models have get faster from

00:17:46,380 --> 00:17:51,880
reductions in architecture or new

00:17:49,060 --> 00:17:53,050
hardware acceleration stories so every

00:17:51,880 --> 00:17:55,030
year of the models that we keep showing

00:17:53,050 --> 00:17:59,470
continue to get faster especially on

00:17:55,030 --> 00:18:01,900
edge and browser devices another great

00:17:59,470 --> 00:18:04,690
product we have at Google is Auto ml an

00:18:01,900 --> 00:18:05,710
animal solves the whole training part if

00:18:04,690 --> 00:18:07,870
you want to do an image classification

00:18:05,710 --> 00:18:10,750
problem you can give it a set of images

00:18:07,870 --> 00:18:11,980
and it uploads to the cloud and it

00:18:10,750 --> 00:18:13,840
automatically finds the right

00:18:11,980 --> 00:18:15,520
architecture for your model and then

00:18:13,840 --> 00:18:17,860
spits out the model that you can deploy

00:18:15,520 --> 00:18:19,510
on your device we're looking at some

00:18:17,860 --> 00:18:20,590
integration with that team as well to

00:18:19,510 --> 00:18:23,470
make it just a really seamless

00:18:20,590 --> 00:18:24,750
experience and the other thing that our

00:18:23,470 --> 00:18:27,130
team has been focusing on is just

00:18:24,750 --> 00:18:29,710
optimizing our existing backends

00:18:27,130 --> 00:18:32,110
so our WebGL implementation for example

00:18:29,710 --> 00:18:34,750
we worked on packing textures which is a

00:18:32,110 --> 00:18:36,610
fancy term of using less memory as as

00:18:34,750 --> 00:18:39,100
much as possible in our acceleration

00:18:36,610 --> 00:18:41,560
library and we found that speed spent a

00:18:39,100 --> 00:18:42,790
bunch of things including iOS up to 10

00:18:41,560 --> 00:18:47,560
times faster than what we were seeing

00:18:42,790 --> 00:18:49,720
before looking at the things were going

00:18:47,560 --> 00:18:51,430
to launch this summer visualization has

00:18:49,720 --> 00:18:52,660
already launched another package that we

00:18:51,430 --> 00:18:54,850
didn't really highlight it's the data

00:18:52,660 --> 00:18:57,460
library and the data library is there

00:18:54,850 --> 00:19:00,840
real easy to use package for getting

00:18:57,460 --> 00:19:02,800
stuff out of the browser microphone data

00:19:00,840 --> 00:19:04,090
webcam data you don't have to worry

00:19:02,800 --> 00:19:05,620
about converting to tensors so you can

00:19:04,090 --> 00:19:09,250
just sort of streamline these things

00:19:05,620 --> 00:19:11,110
into the braaap into your model on our

00:19:09,250 --> 00:19:14,260
platform side expanding where we run

00:19:11,110 --> 00:19:16,000
tensorflow GS as mentioned we chat the

00:19:14,260 --> 00:19:17,620
headless WebGL stuff and then we're

00:19:16,000 --> 00:19:21,090
really starting to dive into how we can

00:19:17,620 --> 00:19:23,710
provide a nice react native experience

00:19:21,090 --> 00:19:25,120
and then on our out of the box model

00:19:23,710 --> 00:19:27,340
fronts we're going to continue focusing

00:19:25,120 --> 00:19:29,500
on audio and text models as well as

00:19:27,340 --> 00:19:33,280
improving the accuracy and performance

00:19:29,500 --> 00:19:34,480
of our existing offerings what I don't

00:19:33,280 --> 00:19:37,000
want to thank you for attending our talk

00:19:34,480 --> 00:19:39,370
everything we've shown is we work purely

00:19:37,000 --> 00:19:42,940
an open source and all of our stuff is

00:19:39,370 --> 00:19:44,710
found on GS tensorflow org one of the

00:19:42,940 --> 00:19:47,500
other things we wanted to acknowledge is

00:19:44,710 --> 00:19:48,940
while Nicola and myself work at Google

00:19:47,500 --> 00:19:50,440
and we get to work on this project we've

00:19:48,940 --> 00:19:52,930
this project would not be where it's at

00:19:50,440 --> 00:19:54,520
without the large number of open source

00:19:52,930 --> 00:19:56,260
contributors we've had and we want to

00:19:54,520 --> 00:19:58,840
extend a thank you to them for all the

00:19:56,260 --> 00:19:59,770
hard work they've done and then one last

00:19:58,840 --> 00:20:01,810
plug

00:19:59,770 --> 00:20:03,910
we are actually hiring a developer

00:20:01,810 --> 00:20:06,820
advocate for our team and if anyone is

00:20:03,910 --> 00:20:09,300
interested please follow that link or

00:20:06,820 --> 00:20:11,500
come see us at the booth here at GSK

00:20:09,300 --> 00:20:15,320
that's all

00:20:11,500 --> 00:20:20,849
[Applause]

00:20:15,320 --> 00:20:20,849

YouTube URL: https://www.youtube.com/watch?v=imzedQr2tTc


