Title: llhttp - new HTTP 1.1 parser for Node.js by Fedor Indutny | JSConf EU 2019
Publication date: 2019-06-19
Playlist: JSConf EU 2019
Description: 
	Node.js has been using a derivative of nginx’s parser with a lot of customization/rewrite since its inception. Despite being fast enough, the project architecture made it very hard to maintain in a long run. To mitigate that, the author has created a tool to generate the new HTTP parser called “llhttp” from the TypeScript code in understandable, verifiable, and maintainable way. Incidentally, the performance of “llhttp” is two times better than of the old parser. In this talk we’ll walk through the basics of generating such parsers and how “llhttp” works.

https://2019.jsconf.eu/fedor-indutny/llhttp-new-http-11-parser-for-nodejs.html
Captions: 
	00:00:07,460 --> 00:00:13,050
I'm glad you came to hear about the new parser coming to Node.

00:00:13,050 --> 00:00:18,110
About who I am, I'm Fedor Indutny.

00:00:18,110 --> 00:00:21,850
Here's my Twitter and GitHub handles which are the same.

00:00:21,850 --> 00:00:24,320
And I write code at PayPal.

00:00:24,320 --> 00:00:30,260
You might know me by this dark avatar I use on GitHub and Twitter and practically everywhere

00:00:30,260 --> 00:00:32,140
else.

00:00:32,140 --> 00:00:37,100
For today talk, the slides and the presentations are already up online.

00:00:37,100 --> 00:00:42,590
If you would like, you can scan the QR code and open your browser and follow along as

00:00:42,590 --> 00:00:44,540
I'm going to present the topic.

00:00:44,540 --> 00:00:45,900
Which is llhttp.

00:00:45,900 --> 00:00:51,829
The new HTTP protocol parser for Node.js.

00:00:51,829 --> 00:00:57,440
This has deep roots into the history of Node.js.

00:00:57,440 --> 00:01:04,320
And it would be hard if not impossible not to mention the history while describing.

00:01:04,320 --> 00:01:07,430
Of course, Node.js is used to load for the front-end tooling.

00:01:07,430 --> 00:01:11,800
But originally historically it started as the backend platform.

00:01:11,800 --> 00:01:18,560
It was exclusively about building asynchronous HTTP servers.

00:01:18,560 --> 00:01:23,790
And the creator of Node, HTTP parser is what started as node.

00:01:23,790 --> 00:01:29,930
There's presentations on the importance and role and structure.

00:01:29,930 --> 00:01:35,880
It's a power Node.js event loop and it's key ever since they set up the node.

00:01:35,880 --> 00:01:40,670
And you might remember if there's a dependency, however, it is not.

00:01:40,670 --> 00:01:46,450
As an HTTP parser, it has all the dependencies that Node ever had.

00:01:46,450 --> 00:01:49,590
It leads all the dependencies in Node.

00:01:49,590 --> 00:01:56,759
Initially it was inspired by mongrel, a Ruby web server with its own parser created by

00:01:56,759 --> 00:01:57,990
web show.

00:01:57,990 --> 00:02:02,810
And later, parts Nginx code introduced in HTTP parser, the

00:02:02,810 --> 00:02:03,810
original one.

00:02:03,810 --> 00:02:07,560
And, of course, the code itself.

00:02:07,560 --> 00:02:10,619
The parser has been with us since 2009.

00:02:10,619 --> 00:02:12,969
It's been more than ten years.

00:02:12,969 --> 00:02:18,730
And in effect, Node itself has been introduced that the very conference ten years ago by

00:02:18,730 --> 00:02:19,730
Ryan.

00:02:19,730 --> 00:02:23,139
So, it's kind of a jubilee for both of those projects.

00:02:23,139 --> 00:02:29,370
And I wrote another HTTP parser to replace the original parser.

00:02:29,370 --> 00:02:36,239
So, why would anyone want to get rid of such a library?

00:02:36,239 --> 00:02:37,920
Of course, it's a fantastic library.

00:02:37,920 --> 00:02:39,389
It has been with us for ten years.

00:02:39,389 --> 00:02:41,939
It should have been worked fine.

00:02:41,939 --> 00:02:46,739
And it has many users inside of the Node.js community as well.

00:02:46,739 --> 00:02:49,059
For example, Android proxy by Google.

00:02:49,059 --> 00:02:54,930
They use it for parsing HTTP requests and it's quite a popular project as well.

00:02:54,930 --> 00:02:59,849
What makes this parser great and why did it stay?

00:02:59,849 --> 00:03:03,359
First, good enough performance.

00:03:03,359 --> 00:03:09,089
It takes quite a bit of time to invoke a C function, and parser is written in C. It takes

00:03:09,089 --> 00:03:11,909
way less time to parse the requests.

00:03:11,909 --> 00:03:15,370
I'm going to elaborate on it a bit later in this presentation.

00:03:15,370 --> 00:03:20,319
But for NodeJS purposes, it's very good performance.

00:03:20,319 --> 00:03:22,809
Couldn't be better.

00:03:22,809 --> 00:03:27,469
It also supports a lot of clients and servers that violate the HTTP specification.

00:03:27,469 --> 00:03:30,999
There are way too many of them out on the Internet.

00:03:30,999 --> 00:03:32,569
You would be surprised how many.

00:03:32,569 --> 00:03:37,139
And, of course, it was very important for early adoption of NodeJS.

00:03:37,139 --> 00:03:42,859
Because in 2009 there was even more such clients and servers out there.

00:03:42,859 --> 00:03:45,980
Another point is that original parser has a lot of test suites.

00:03:45,980 --> 00:03:52,749
So, over ten years Ryan, Ben and other maintainers of the project, including myself, have wrote

00:03:52,749 --> 00:03:58,349
quite a comprehensive test suite that covers almost every aspect of HTTP specification.

00:03:58,349 --> 00:04:00,059
So, the parser is welltested.

00:04:00,059 --> 00:04:03,219
So, that was the good points of the original parser.

00:04:03,219 --> 00:04:05,709
Now we come to other points.

00:04:05,709 --> 00:04:10,319
Unfortunately, with the HTTP library the code became quite rigid.

00:04:10,319 --> 00:04:16,150
It became impossible to move things around, to make significant changes to it.

00:04:16,150 --> 00:04:23,120
And as a consequence of this, it became impossible to maintain this library efficiently.

00:04:23,120 --> 00:04:28,919
Furthermore, as one of the maintainers of the project, I have to constantly relearn

00:04:28,919 --> 00:04:35,120
and get familiar with the parts of the codebase that I was previously familiar with before.

00:04:35,120 --> 00:04:40,870
And I did it on every pull request and still I wasn't sure if the code is going to run

00:04:40,870 --> 00:04:43,940
in the way I expected it to run.

00:04:43,940 --> 00:04:47,449
So, it could introduce some unexpected behavior.

00:04:47,449 --> 00:04:50,050
Or maybe a security vulnerability as well.

00:04:50,050 --> 00:04:52,180
Which is obviously bad.

00:04:52,180 --> 00:04:58,569
It doesn't help either that most NodeJS users and developers are familiar with JavaScript

00:04:58,569 --> 00:05:03,650
and are more comfortable with it than they are with C. So, there was not too many people

00:05:03,650 --> 00:05:07,500
interested in working on this HTTP parser.

00:05:07,500 --> 00:05:12,560
With all this in mind, several years ago I set out on a quest it make the library better

00:05:12,560 --> 00:05:16,319
and maybe a bit faster in the process.

00:05:16,319 --> 00:05:18,730
First attempts were quite conservative.

00:05:18,730 --> 00:05:21,560
So, I tried to stay with existing code as much as possible.

00:05:21,560 --> 00:05:23,190
And some of them were successful.

00:05:23,190 --> 00:05:28,389
Like replacing the parser state machine with a cross, and using it consistently not only

00:05:28,389 --> 00:05:31,550
improved the code, but also made it faster.

00:05:31,550 --> 00:05:33,129
Which was nice.

00:05:33,129 --> 00:05:35,190
Other attempts were a complete disaster.

00:05:35,190 --> 00:05:39,969
I tried to move those states into a separated function and just called them from the loop

00:05:39,969 --> 00:05:45,020
so each state would return the next state that was supposed to be executed and then

00:05:45,020 --> 00:05:47,050
the loop would run the function for it.

00:05:47,050 --> 00:05:52,949
This completely ruins the performance and I never contributed or sent it to the string.

00:05:52,949 --> 00:05:58,990
From this attempt was success or failure, the conclusion was clear.

00:05:58,990 --> 00:06:02,650
It was hard to make an improvement while staying with the existing codebase.

00:06:02,650 --> 00:06:07,810
There was no requirement to use as much code as possible, it was no longer required to

00:06:07,810 --> 00:06:11,380
make it in the same programming language as before.

00:06:11,380 --> 00:06:16,039
Why not develop it in JavaScript or maybe TypeScript instead?

00:06:16,039 --> 00:06:21,310
And, of course, JavaScript performance is quite great.

00:06:21,310 --> 00:06:26,499
But you wouldn't be surprised that it's slower than C and takes a lot of effort to reach

00:06:26,499 --> 00:06:30,550
comparable performances in the C libraries when you write programs in JavaScript.

00:06:30,550 --> 00:06:31,550
Takes a lot of effort.

00:06:31,550 --> 00:06:32,650
But it's possible.

00:06:32,650 --> 00:06:38,020
So, I wanted to get this performance optimization out of consideration.

00:06:38,020 --> 00:06:44,069
And also, I decided to just define the parser in TypeScript and still compile it down to

00:06:44,069 --> 00:06:45,069
the C library.

00:06:45,069 --> 00:06:49,009
So, the end result would be C library that was used in Node and other projects.

00:06:49,009 --> 00:06:55,400
Which was great because existing users of HTTP parser this way would be able to transition

00:06:55,400 --> 00:07:00,400
their code to the new parser and hopefully the process and the performance would not

00:07:00,400 --> 00:07:03,919
degrade so much because in the end it's the same programming language.

00:07:03,919 --> 00:07:09,490
It would have good chances of being the same speed.

00:07:09,490 --> 00:07:15,870
So, llhttp is the next major version of HTTP parser.

00:07:15,870 --> 00:07:20,389
It has the same core principles and similar API, which is almost identical.

00:07:20,389 --> 00:07:27,870
And the way they work, is they scan one character at a time.

00:07:27,870 --> 00:07:34,280
And during the process they change the internal state and they could add a header fields or

00:07:34,280 --> 00:07:39,719
maybe header values and later on body.

00:07:39,719 --> 00:07:42,159
I'm not sure if we're going to wait for this.

00:07:42,159 --> 00:07:43,159
It's quite slow.

00:07:43,159 --> 00:07:44,159
Okay.

00:07:44,159 --> 00:07:45,159
Yeah.

00:07:45,159 --> 00:07:47,490
I think you probably understand what it means now.

00:07:47,490 --> 00:07:49,189
At least to some extent.

00:07:49,189 --> 00:07:57,229
So, this can by the virtue of this one scan the parser can work without buffering anything

00:07:57,229 --> 00:07:58,229
at all.

00:07:58,229 --> 00:08:00,889
So, it doesn't allocate memory itself.

00:08:00,889 --> 00:08:06,879
And it creates especially for request bodies because it could just need the slices of original

00:08:06,879 --> 00:08:10,990
buffers that came from that work instead of allocating the coping data.

00:08:10,990 --> 00:08:16,770
So, in the core principle of the HTTP parser, it's not copying.

00:08:16,770 --> 00:08:18,370
That's important.

00:08:18,370 --> 00:08:24,330
And as soon as any amount of data arrives via a request or a single byte of request,

00:08:24,330 --> 00:08:26,529
HTTP parser is ready to process it.

00:08:26,529 --> 00:08:30,319
And it will be possibly partial because it will be health requests.

00:08:30,319 --> 00:08:36,229
And the header names, we are just seeing in this animation.

00:08:36,229 --> 00:08:43,630
In the original version of the parser, this scan was quite naturally implemented foreloop

00:08:43,630 --> 00:08:45,950
over the input.

00:08:45,950 --> 00:08:50,610
Just going by the input bytebybyte and doing some syncs.

00:08:50,610 --> 00:08:57,430
What it did, it was described by a huge which statement or all possible parsing state.

00:08:57,430 --> 00:09:02,360
Whether it's a header name, header value, whether it's value of content lengths header,

00:09:02,360 --> 00:09:09,030
it was all described by the switch statement, and they represented different states of the

00:09:09,030 --> 00:09:10,600
state machine.

00:09:10,600 --> 00:09:16,709
All of this lived in a single function or 1,000 lines of code which is quite a terrible

00:09:16,709 --> 00:09:17,709
idea.

00:09:17,709 --> 00:09:24,490
So, an obvious improvement would be to break this switch into pieces and make it such that

00:09:24,490 --> 00:09:26,940
each piece has precise action.

00:09:26,940 --> 00:09:30,250
It's sort of a unique philosophy, I guess.

00:09:30,250 --> 00:09:35,660
So, it would be just exactly about doing one small thing at a time.

00:09:35,660 --> 00:09:38,570
Go to statements would be used to jump between states.

00:09:38,570 --> 00:09:43,970
There would not be as much need for this foreloop, at least not as much.

00:09:43,970 --> 00:09:49,730
With all this in mind, how do I approach this process?

00:09:49,730 --> 00:09:59,180
I developed a domainspecific language, DSL, and created a compiler around it, LL parse,

00:09:59,180 --> 00:10:07,410
so, again, double L. And this compiler is used to describe the parsing states in terms

00:10:07,410 --> 00:10:09,660
of these actions that they perform.

00:10:09,660 --> 00:10:14,259
So, each state would have several actions assigned to them and they would perform them

00:10:14,259 --> 00:10:17,630
and move on to the next state.

00:10:17,630 --> 00:10:23,090
Because of this llparse is quite a general compiler, it can be used for other protocols

00:10:23,090 --> 00:10:24,090
as well.

00:10:24,090 --> 00:10:29,589
It works better for textual protocols, but I think it's useful.

00:10:29,589 --> 00:10:33,910
Original parser suffered from a surplus of handwritten code.

00:10:33,910 --> 00:10:39,120
I have selected a few actions that were repeated most in the original library and had DSL around

00:10:39,120 --> 00:10:40,120
them.

00:10:40,120 --> 00:10:45,670
The idea here is that I wanted the description of the new parser to be concise.

00:10:45,670 --> 00:10:50,430
So, I wanted to write code with less lines and less signals than possible.

00:10:50,430 --> 00:10:56,920
I wanted to move the most common iterations inside of the compiler so that the rest would

00:10:56,920 --> 00:11:01,050
have to do the work all over again and the original parser.

00:11:01,050 --> 00:11:06,220
Here were a few that the compiler supports.

00:11:06,220 --> 00:11:08,660
One is match.

00:11:08,660 --> 00:11:15,680
It takes a sequence, or a character of bytes and it tries to match them from the input.

00:11:15,680 --> 00:11:20,980
For example, it could be keep alive, which is the value of the headernamed connection.

00:11:20,980 --> 00:11:23,470
It's quite a common header and very important.

00:11:23,470 --> 00:11:25,899
So, it could match this sequence.

00:11:25,899 --> 00:11:31,160
And when it does, move to the next state by taking the reference to this state.

00:11:31,160 --> 00:11:36,029
And other times the parser needs to check the next character in the incoming data without

00:11:36,029 --> 00:11:37,370
actually consuming it.

00:11:37,370 --> 00:11:41,300
And it could be used for this.

00:11:41,300 --> 00:11:49,560
Takes a single character and mentions it and moves on without moving the input stream.

00:11:49,560 --> 00:11:56,569
And speaking of headers, headers like lengths, they have internal values which frankly described

00:11:56,569 --> 00:11:59,339
by strings, it's a contextual protocol.

00:11:59,339 --> 00:12:03,269
The new parser has to be able to parse the integer strings.

00:12:03,269 --> 00:12:11,180
And the way I decided to do it was to implement a select method in DSL which takes a map as

00:12:11,180 --> 00:12:12,730
an input.

00:12:12,730 --> 00:12:17,600
And this map has sequences or characters as keys.

00:12:17,600 --> 00:12:18,839
And the integers as values.

00:12:18,839 --> 00:12:25,610
So, it tries to map this sequence to the integers and just passes values along to the next state.

00:12:25,610 --> 00:12:32,940
The next state could be storing integers inside some property of the structure, or maybe walking

00:12:32,940 --> 00:12:35,850
a user code back with them.

00:12:35,850 --> 00:12:40,339
Speaking of callbacks, there is one special type of callback.

00:12:40,339 --> 00:12:47,519
It is very important in the life span of both original and the new HTTP parser.

00:12:47,519 --> 00:12:50,940
During their executions they need ranges of data.

00:12:50,940 --> 00:12:55,709
For example, header names, or headers are in this way.

00:12:55,709 --> 00:13:02,310
And begin that we have a stream of data that comes to the parser, we have to be able to

00:13:02,310 --> 00:13:07,330
mark some certain place inside of this stream as the beginning of this range.

00:13:07,330 --> 00:13:12,949
And then at some other point later on we want to set it as an ending of the range.

00:13:12,949 --> 00:13:17,069
So, between those beginning and ending, or you can see, our beginning and ending.

00:13:17,069 --> 00:13:20,649
Between them the callback is going to be invoked for every byte.

00:13:20,649 --> 00:13:26,360
And it's really, really useful for header names, header values and bodies, and other

00:13:26,360 --> 00:13:31,000
things that could be needed that spans the ranges of input.

00:13:31,000 --> 00:13:35,529
Of course, there are a couple of important actions that I have not needed in previous

00:13:35,529 --> 00:13:40,009
slides that are actually mandatory to have in this state.

00:13:40,009 --> 00:13:42,430
They call otherwise and skip to.

00:13:42,430 --> 00:13:49,600
And those specify which states of the parser should be reached next if nothing else matches

00:13:49,600 --> 00:13:50,990
inside of the current state.

00:13:50,990 --> 00:13:57,730
So, in this example, the input would be A. The parser would move to the A state, and

00:13:57,730 --> 00:14:03,029
for B, move to B and C or D or E or whatever is later.

00:14:03,029 --> 00:14:06,550
It would move to some other state.

00:14:06,550 --> 00:14:08,180
Skip to is quite similar.

00:14:08,180 --> 00:14:11,850
It's the same thing but consumes the character from the input stream.

00:14:11,850 --> 00:14:14,769
Otherwise, it does not change the input stream at all.

00:14:14,769 --> 00:14:16,140
It just moves on.

00:14:16,140 --> 00:14:23,730
So, that was a bit of description maybe too concise to be useful of DSL.

00:14:23,730 --> 00:14:30,329
And with this DSL in mind, llhttp becomes a type Script program.

00:14:30,329 --> 00:14:37,310
This program uses it to describe the actions and input as said before.

00:14:37,310 --> 00:14:41,769
Because it's a TypeScript program, or JavaScript program, really, I could split it into several

00:14:41,769 --> 00:14:44,520
sub modules and use them efficiently.

00:14:44,520 --> 00:14:45,870
And each submodule could have the subparser.

00:14:45,870 --> 00:14:49,740
This is what I use in HTTP.

00:14:49,740 --> 00:14:56,910
I have a separate parser inside of it and can use it and run it separately and can be

00:14:56,910 --> 00:15:02,860
used separately as well as a library if anyone wants it.

00:15:02,860 --> 00:15:12,009
Llparse compile this is TypeScript program down to C. And that's the main action of it.

00:15:12,009 --> 00:15:19,579
Know that because it uses a stable DSL, oh, sorry, just uses DSL, the parser doesn't need

00:15:19,579 --> 00:15:21,259
to do any parsing.

00:15:21,259 --> 00:15:24,810
It's done automatically by the JS engine.

00:15:24,810 --> 00:15:26,980
So, V8 does it for us.

00:15:26,980 --> 00:15:30,649
V8 does this itself internally.

00:15:30,649 --> 00:15:37,009
Llparse builds a graph of state which I will try to show you.

00:15:37,009 --> 00:15:38,260
It looks kind of terrible.

00:15:38,260 --> 00:15:39,420
But I probably can zoom in.

00:15:39,420 --> 00:15:40,420
Yeah.

00:15:40,420 --> 00:15:45,509
So, yeah, hear, how it looks like in practice.

00:15:45,509 --> 00:15:49,370
I can probably actually show you something more useful.

00:15:49,370 --> 00:15:56,449
So, here on the right you see ACL buy check out this.

00:15:56,449 --> 00:15:58,960
Mobile names supported by parser.

00:15:58,960 --> 00:16:01,819
And the name is matched in this of the input.

00:16:01,819 --> 00:16:07,400
It will store the integer and coding as a method inside those internal properties of

00:16:07,400 --> 00:16:08,400
parsers.

00:16:08,400 --> 00:16:11,310
It works this way more or less.

00:16:11,310 --> 00:16:15,139
I guess with a that means is the kind of graph is looking awesome.

00:16:15,139 --> 00:16:18,529
So, that's one of the reasons to have it.

00:16:18,529 --> 00:16:23,500
And another reason to have it is that llparse can do static analysis on this graph.

00:16:23,500 --> 00:16:29,339
Before in original parsers there was no way to reason about the states automatically.

00:16:29,339 --> 00:16:33,230
So, it was all described manually inside of the parser.

00:16:33,230 --> 00:16:35,389
There was just a lot of C code.

00:16:35,389 --> 00:16:39,050
And there was no way to analyze it and to do any optimizations for checks.

00:16:39,050 --> 00:16:46,910
What I can to in llparse is check the code for absence of infant loops which is possible

00:16:46,910 --> 00:16:50,259
due to otherwise so, they could be combined together.

00:16:50,259 --> 00:16:54,790
Not just making any progress over the input and just being in indefinitely.

00:16:54,790 --> 00:17:00,579
It's important to check this statically because there might be an array of conditions that

00:17:00,579 --> 00:17:01,579
could trigger it.

00:17:01,579 --> 00:17:06,860
It might not be immediately verifiable with the test suite.

00:17:06,860 --> 00:17:11,810
Speaking of optimizations, the parser could do peephole optimizations.

00:17:11,810 --> 00:17:17,880
That's a fancy name for just combining similar states together into one.

00:17:17,880 --> 00:17:24,480
This way the amount of code is reduced, and also the compiler sorry, programmer has a

00:17:24,480 --> 00:17:29,640
lot more freedom and development with the parser because they don't have to think about

00:17:29,640 --> 00:17:32,560
doing these optimizations manually in their code.

00:17:32,560 --> 00:17:38,080
So, as I said, the DSL is quite stable for llparse.

00:17:38,080 --> 00:17:42,270
So, same program could be compared to different outputs.

00:17:42,270 --> 00:17:46,670
At this moment, C and the code is wellsupported.

00:17:46,670 --> 00:17:54,100
And the code was kind of before, it was supported before the C. So, that's the reason why both

00:17:54,100 --> 00:17:57,060
projects have double L in their names.

00:17:57,060 --> 00:17:58,810
Kind of a historical reason.

00:17:58,810 --> 00:18:07,390
But in the end when I ran benchmarks, this tree C compiler worked better than the code

00:18:07,390 --> 00:18:10,450
which I spent several weeks on.

00:18:10,450 --> 00:18:12,230
It was surprising for me, maybe shocking.

00:18:12,230 --> 00:18:16,800
I had a few months to think about it.

00:18:16,800 --> 00:18:17,800
Yeah.

00:18:17,800 --> 00:18:22,180
And speaking of performance, you might be wondering how fast this new parser is given

00:18:22,180 --> 00:18:24,950
that it is not handwritten at all.

00:18:24,950 --> 00:18:30,030
But, of course, despite the maintenance issues, as I said before, the original parser has

00:18:30,030 --> 00:18:31,220
quite a bit of improvements.

00:18:31,220 --> 00:18:33,750
They're good enough, still very good.

00:18:33,750 --> 00:18:39,450
It would have been very unreasonable to replace it with something that performed significantly

00:18:39,450 --> 00:18:40,450
worse.

00:18:40,450 --> 00:18:45,330
So, ll shipping is not handwritten, it's not hand optimized.

00:18:45,330 --> 00:18:53,490
And when I ran benchmarks, I discovered that it runs twice as fast as the original parser.

00:18:53,490 --> 00:19:01,580
[ Applause ] Thank you.

00:19:01,580 --> 00:19:03,620
And here is the actual benchmark numbers.

00:19:03,620 --> 00:19:09,440
So, as you can see, both those numbers did quite well.

00:19:09,440 --> 00:19:14,890
As it presents a number of requests per second that each parser can take.

00:19:14,890 --> 00:19:19,190
And this way both parsers run in microseconds.

00:19:19,190 --> 00:19:23,470
You wouldn't ever see this on the profile logs.

00:19:23,470 --> 00:19:25,360
Just impossible to see it.

00:19:25,360 --> 00:19:29,770
And, of course, it's important to note as well that llhttp is more than two times faster

00:19:29,770 --> 00:19:31,660
than the original parser.

00:19:31,660 --> 00:19:35,210
But no one hardly cares about it.

00:19:35,210 --> 00:19:39,670
This llhttp parser is a default in Node version 12.

00:19:39,670 --> 00:19:46,960
If you are using the latest Node, I hope you do, you are already running this.

00:19:46,960 --> 00:19:52,590
And even more, you have a reason to blame me for any kinds of HTTP problems that you

00:19:52,590 --> 00:19:53,590
have.

00:19:53,590 --> 00:19:57,570
So, feel free to do so and it would be rightful.

00:19:57,570 --> 00:20:00,010
Please open GitHub.

00:20:00,010 --> 00:20:03,560
Don't just brag on Twitter how bad I am.

00:20:03,560 --> 00:20:04,560
And tag me on GitHub.

00:20:04,560 --> 00:20:09,210
I will be happy to look into it and fix it as soon as possible.

00:20:09,210 --> 00:20:14,570
As I said before, over ten years originally the parser has accumulated a comprehensive

00:20:14,570 --> 00:20:16,050
test suite.

00:20:16,050 --> 00:20:20,460
It would be really unwise to get rid of it and just start it over.

00:20:20,460 --> 00:20:23,790
So, I ported all the original tests to mark down.

00:20:23,790 --> 00:20:25,240
And the new ones.

00:20:25,240 --> 00:20:28,740
And here they are described by the markdown files.

00:20:28,740 --> 00:20:34,400
So, they completed, and I encourage you to take a look at them if you want.

00:20:34,400 --> 00:20:40,290
Because I find them the most I'm using part of the project that worked on.

00:20:40,290 --> 00:20:41,290
Yes.

00:20:41,290 --> 00:20:42,330
They're really, really fun.

00:20:42,330 --> 00:20:51,250
I'm going to give a bit more time because I see that some people scanned

00:20:51,250 --> 00:20:52,250
the codes.

00:20:52,250 --> 00:20:53,250
Okay.

00:20:53,250 --> 00:20:54,250
So, that makes it.

00:20:54,250 --> 00:20:57,820
And each markdown file contains several tests.

00:20:57,820 --> 00:21:00,010
They are separated by the headings.

00:21:00,010 --> 00:21:02,620
So, it's quite easy to read.

00:21:02,620 --> 00:21:04,220
And even easier to contribute.

00:21:04,220 --> 00:21:09,240
In fact, they had one contributor that submitted a test without asking a question how to do

00:21:09,240 --> 00:21:10,240
so.

00:21:10,240 --> 00:21:15,920
And I don't know that many projects that uses a test system that's easy to contribute.

00:21:15,920 --> 00:21:19,920
And furthermore, each test has an actual description inside of them.

00:21:19,920 --> 00:21:26,710
They have code chunks inside of markdown, code chunk for expected output, and between

00:21:26,710 --> 00:21:29,200
those you can put just any text you want.

00:21:29,200 --> 00:21:32,260
You can put hyperlinks, you can put images.

00:21:32,260 --> 00:21:35,190
You can put GIFs of pets doing stuff.

00:21:35,190 --> 00:21:38,990
So, it's quite a nice way of writing tests.

00:21:38,990 --> 00:21:43,580
And it especially works well for HTTP because it's the contextual protocol.

00:21:43,580 --> 00:21:50,340
And you can see in C where it's actually inside the test suite.

00:21:50,340 --> 00:21:51,340
Yeah.

00:21:51,340 --> 00:21:57,030
So, here's been the presence of the parser and the history of it.

00:21:57,030 --> 00:22:02,340
So, naturally I would like to talk about what's coming next.

00:22:02,340 --> 00:22:06,030
And there is room for future improvements with regards to doing more static checks in

00:22:06,030 --> 00:22:10,830
this graph I'm showing to you and doing more performance optimizations.

00:22:10,830 --> 00:22:16,860
There are forks of original parsers that use CPUspecific vector instructions which are

00:22:16,860 --> 00:22:17,860
really, really, fast.

00:22:17,860 --> 00:22:22,200
They perform better than both.

00:22:22,200 --> 00:22:24,620
Not much use for this speed bump for Node.

00:22:24,620 --> 00:22:28,300
But nevertheless, there's no reason to not explore it.

00:22:28,300 --> 00:22:33,990
I probably should do it, or I would love someone do it for me to do some.

00:22:33,990 --> 00:22:37,970
Quite ashamedly, the project is not well documented.

00:22:37,970 --> 00:22:46,290
It has quite a bit of information describing the API of llparse, but it's scattered through

00:22:46,290 --> 00:22:49,900
several dependencies and could be made more accessible.

00:22:49,900 --> 00:22:57,270
I could use help with this and I'm sure some people might find this quite entertaining

00:22:57,270 --> 00:23:01,740
as well because there's a lot of interesting moments in this parser, in this code.

00:23:01,740 --> 00:23:10,020
Finally, it would be fascinating to see different types of parsers implemented on top of llparse.

00:23:10,020 --> 00:23:14,620
Two examples that I have in mind, SMTP and protocols, they are contextual and could be

00:23:14,620 --> 00:23:17,680
implemented in llparse.

00:23:17,680 --> 00:23:24,020
I really look forward to either working on this or helping someone with this.

00:23:24,020 --> 00:23:25,480
And, yeah.

00:23:25,480 --> 00:23:34,340
Here is a link to the ll repos.

00:23:34,340 --> 00:23:37,110
It's quite easy to find on GitHub.

00:23:37,110 --> 00:23:40,370
Just under the Node.js organization.

00:23:40,370 --> 00:23:43,130
GitHub.com/Node.js/ et cetera /llhttp.

00:23:43,130 --> 00:23:45,890
So, I guess that's it.

00:23:45,890 --> 00:23:56,530

YouTube URL: https://www.youtube.com/watch?v=x3k_5Mi66sY


