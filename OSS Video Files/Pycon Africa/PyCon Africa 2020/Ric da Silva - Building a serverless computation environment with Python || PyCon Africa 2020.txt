Title: Ric da Silva - Building a serverless computation environment with Python || PyCon Africa 2020
Publication date: 2020-08-30
Playlist: PyCon Africa 2020
Description: 
	This talk will be a whistle-stop tour of a virtual machine, compiler, and DSL for orchestrating Python computation on serverless cloud technology. The goal is to be able to take existing code and get it running in a very scalable way on the cloud, with as little effort as possible. It’s easy to deploy one AWS lambda function (eg with the well known Serverless Framework), but it’s much harder to write several functions and pass data between them. The Teal project started as an experiment to see whether it’d be feasible to simplify this without resorting to simple “workflow” or “task” based approaches. The results have been promising.
There will be a demo (!) - build, test and deploy a non-trivial new data pipeline, mostly written in python, in less than 5 minutes.

Something that might have taken several hours before, or longer if you didn’t have orchestrator or task-runner infrastructure set up already. We may also cover how this makes development and CI/CD easier. Depending on audience & time, we may dive deeper into the implementation approach, and what Python features made it a great experience.
Captions: 
	00:00:17,600 --> 00:00:20,560
in the next

00:00:18,560 --> 00:00:22,800
30 minutes or so i'm going to show you a

00:00:20,560 --> 00:00:26,320
new way of thinking about cloud software

00:00:22,800 --> 00:00:26,320
and i think

00:00:26,560 --> 00:00:30,320
the programming languages that we speak

00:00:28,560 --> 00:00:33,519
and the way that we

00:00:30,320 --> 00:00:33,519
think about problems

00:00:33,920 --> 00:00:37,920
because they determine our ability to

00:00:36,559 --> 00:00:41,200
express ourselves and

00:00:37,920 --> 00:00:42,239
and therefore to solve problems

00:00:41,200 --> 00:00:44,960
so i want to show you something that

00:00:42,239 --> 00:00:46,399
i've been working on and um

00:00:44,960 --> 00:00:48,559
and i think that when you when you learn

00:00:46,399 --> 00:00:51,280
a new way to think it opens up your mind

00:00:48,559 --> 00:00:53,840
to seeing problems in a different light

00:00:51,280 --> 00:00:54,640
the project is called teal and the focus

00:00:53,840 --> 00:00:58,320
right now

00:00:54,640 --> 00:01:01,520
is is on building data pipelines

00:00:58,320 --> 00:01:04,559
powered with python of course

00:01:01,520 --> 00:01:05,600
and running on serverless technology

00:01:04,559 --> 00:01:07,840
and if you haven't come across

00:01:05,600 --> 00:01:09,520
serverless uh it's this it's this cool

00:01:07,840 --> 00:01:11,119
idea that we can we can build cloud

00:01:09,520 --> 00:01:12,240
applications

00:01:11,119 --> 00:01:15,119
without having to manage the

00:01:12,240 --> 00:01:16,960
infrastructure on which they run

00:01:15,119 --> 00:01:18,240
and that's a fantastic that's a

00:01:16,960 --> 00:01:19,520
fantastic thing

00:01:18,240 --> 00:01:21,439
but the problem is that we still have to

00:01:19,520 --> 00:01:23,759
think about that infrastructure

00:01:21,439 --> 00:01:25,520
we still have to design our applications

00:01:23,759 --> 00:01:27,759
with the infrastructure in mind

00:01:25,520 --> 00:01:29,119
and we we spend a long time up front

00:01:27,759 --> 00:01:30,799
building complicated

00:01:29,119 --> 00:01:33,280
architectures for doing things with

00:01:30,799 --> 00:01:35,040
serverless um

00:01:33,280 --> 00:01:36,400
we've sort of traded this operational

00:01:35,040 --> 00:01:37,439
power like we get this amazing

00:01:36,400 --> 00:01:39,520
scalability

00:01:37,439 --> 00:01:40,560
but we've traded that for development

00:01:39,520 --> 00:01:43,439
complexity

00:01:40,560 --> 00:01:44,079
and upfront costs in in development time

00:01:43,439 --> 00:01:46,399
we spend

00:01:44,079 --> 00:01:47,520
weeks building something that i think

00:01:46,399 --> 00:01:50,240
should really take

00:01:47,520 --> 00:01:51,040
uh minutes or hours to build because

00:01:50,240 --> 00:01:53,119
fundamentally

00:01:51,040 --> 00:01:54,079
a lot of these problems are quite simple

00:01:53,119 --> 00:01:56,799
at

00:01:54,079 --> 00:01:57,200
the heart and the best analogy that i've

00:01:56,799 --> 00:01:59,840
got

00:01:57,200 --> 00:02:01,360
is to think about think about compilers

00:01:59,840 --> 00:02:03,119
and assembly code

00:02:01,360 --> 00:02:05,280
and you know in the early days of

00:02:03,119 --> 00:02:08,720
computing we would write software

00:02:05,280 --> 00:02:09,360
in assembly code um but no one does that

00:02:08,720 --> 00:02:11,120
anymore

00:02:09,360 --> 00:02:12,400
these days we use compilers to generate

00:02:11,120 --> 00:02:14,640
the code for us or

00:02:12,400 --> 00:02:16,239
or we write in higher level languages

00:02:14,640 --> 00:02:19,680
that allow us to express

00:02:16,239 --> 00:02:20,720
things really concisely and we can do

00:02:19,680 --> 00:02:22,400
something in one line

00:02:20,720 --> 00:02:24,319
that previously would have taken pages

00:02:22,400 --> 00:02:26,080
of assembly code and i think that's

00:02:24,319 --> 00:02:26,480
fantastic and that's that's why software

00:02:26,080 --> 00:02:28,319
is

00:02:26,480 --> 00:02:30,640
eating the world as some people some

00:02:28,319 --> 00:02:34,239
people say

00:02:30,640 --> 00:02:36,480
so when i'm talking about serverless

00:02:34,239 --> 00:02:37,440
i'm really referring to functions as a

00:02:36,480 --> 00:02:39,360
service

00:02:37,440 --> 00:02:41,519
um and they're also known as cloud

00:02:39,360 --> 00:02:43,920
functions uh there are several

00:02:41,519 --> 00:02:45,680
most most cloud platforms support

00:02:43,920 --> 00:02:47,840
functions as a service

00:02:45,680 --> 00:02:49,599
and and they're great because you can

00:02:47,840 --> 00:02:51,120
take your you can take your code

00:02:49,599 --> 00:02:53,040
and you can go and deploy it on the

00:02:51,120 --> 00:02:55,120
cloud and that's really really quick

00:02:53,040 --> 00:02:57,280
really easy and you can attach your code

00:02:55,120 --> 00:03:00,080
to events that happen in the cloud

00:02:57,280 --> 00:03:01,440
and you can say when those events happen

00:03:00,080 --> 00:03:03,360
run my code

00:03:01,440 --> 00:03:04,640
and if the events don't happen your code

00:03:03,360 --> 00:03:05,840
never runs and you never pay and it's

00:03:04,640 --> 00:03:08,159
it's lovely it's wonderful

00:03:05,840 --> 00:03:09,360
um it's like the the nirvana of

00:03:08,159 --> 00:03:12,000
scalability you get

00:03:09,360 --> 00:03:13,440
you get this fully managed scaling

00:03:12,000 --> 00:03:15,840
service that goes from zero

00:03:13,440 --> 00:03:16,640
to to global scale without you having to

00:03:15,840 --> 00:03:19,599
do anything

00:03:16,640 --> 00:03:20,879
um so serverless is service is great and

00:03:19,599 --> 00:03:23,280
i think we're going to see massive

00:03:20,879 --> 00:03:24,879
massive adoption in the next five years

00:03:23,280 --> 00:03:26,239
and i think it'll become the

00:03:24,879 --> 00:03:28,319
the right way the standard way of

00:03:26,239 --> 00:03:31,120
building cloud applications

00:03:28,319 --> 00:03:32,000
um but the problem is that when you

00:03:31,120 --> 00:03:34,480
start

00:03:32,000 --> 00:03:36,560
putting logic all over the place you you

00:03:34,480 --> 00:03:38,959
end up with

00:03:36,560 --> 00:03:40,400
architectures that are hard to hard to

00:03:38,959 --> 00:03:42,000
understand as a whole

00:03:40,400 --> 00:03:44,000
you can understand the individual pieces

00:03:42,000 --> 00:03:44,799
and you can understand individual lambda

00:03:44,000 --> 00:03:46,080
functions

00:03:44,799 --> 00:03:48,400
but it's hard to understand how they

00:03:46,080 --> 00:03:50,239
interact and it's hard to test it

00:03:48,400 --> 00:03:52,319
and it's hard to it's hard to abstract

00:03:50,239 --> 00:03:53,120
it so in in the way that with software

00:03:52,319 --> 00:03:56,640
we can

00:03:53,120 --> 00:03:58,799
abstract concepts and routines and

00:03:56,640 --> 00:04:00,640
and procedures we can we can hide the

00:03:58,799 --> 00:04:03,680
details you can't really do that with

00:04:00,640 --> 00:04:06,239
a flowchart right uh a flowchart doesn't

00:04:03,680 --> 00:04:07,200
a flowchart isn't software um you can't

00:04:06,239 --> 00:04:10,640
compose them

00:04:07,200 --> 00:04:12,720
in the way you can with software um

00:04:10,640 --> 00:04:14,319
so the goal that i have really is to to

00:04:12,720 --> 00:04:17,040
say well how can we

00:04:14,319 --> 00:04:18,320
how can we make serverless feel like

00:04:17,040 --> 00:04:20,320
software again

00:04:18,320 --> 00:04:21,519
how can we make developing developing a

00:04:20,320 --> 00:04:24,320
serverless application

00:04:21,519 --> 00:04:25,759
feel like developing a traditional pure

00:04:24,320 --> 00:04:28,639
software application

00:04:25,759 --> 00:04:29,440
where we can understand everything and

00:04:28,639 --> 00:04:32,560
it's all clear

00:04:29,440 --> 00:04:34,720
in in in code rather than um

00:04:32,560 --> 00:04:36,160
diagrams um which is which is a pity

00:04:34,720 --> 00:04:36,960
because like these diagrams make us feel

00:04:36,160 --> 00:04:39,840
good

00:04:36,960 --> 00:04:41,520
uh as engineers like you know they're

00:04:39,840 --> 00:04:42,960
complicated and they're they're

00:04:41,520 --> 00:04:44,479
they're exciting and you can they've got

00:04:42,960 --> 00:04:44,880
colors and you can look at them and say

00:04:44,479 --> 00:04:47,280
well

00:04:44,880 --> 00:04:48,800
i built this super cool thing um isn't

00:04:47,280 --> 00:04:51,840
it awesome

00:04:48,800 --> 00:04:52,560
um but it's not software so we'll we'll

00:04:51,840 --> 00:04:54,720
look at

00:04:52,560 --> 00:04:56,000
an example and we'll look at how we

00:04:54,720 --> 00:04:58,479
might implement it with the traditional

00:04:56,000 --> 00:05:00,080
method and then we'll look at how we

00:04:58,479 --> 00:05:02,479
would implement it with teal

00:05:00,080 --> 00:05:04,960
and how teal lets us think about it

00:05:02,479 --> 00:05:04,960
differently

00:05:05,840 --> 00:05:11,039
the spec well the specs pretty simple

00:05:08,880 --> 00:05:12,320
there's nothing particularly interesting

00:05:11,039 --> 00:05:15,039
happening really we've got

00:05:12,320 --> 00:05:15,759
three functions and they take one

00:05:15,039 --> 00:05:18,240
parameter

00:05:15,759 --> 00:05:20,000
and the parameter is just passed from

00:05:18,240 --> 00:05:23,120
one function to the next

00:05:20,000 --> 00:05:24,320
and this is this is quite representative

00:05:23,120 --> 00:05:26,479
of

00:05:24,320 --> 00:05:28,560
of many tasks right you've got a

00:05:26,479 --> 00:05:30,880
sequence of steps that you need to

00:05:28,560 --> 00:05:31,759
need to perform and there's some data

00:05:30,880 --> 00:05:34,080
that needs to

00:05:31,759 --> 00:05:35,360
go from one step to the next step it's

00:05:34,080 --> 00:05:37,199
not particularly interesting it's a very

00:05:35,360 --> 00:05:40,479
very very common

00:05:37,199 --> 00:05:41,600
approach use case and the constraint is

00:05:40,479 --> 00:05:44,080
that

00:05:41,600 --> 00:05:45,039
each function takes several minutes and

00:05:44,080 --> 00:05:48,880
we have to use lambda

00:05:45,039 --> 00:05:50,720
because reasons like serverless great

00:05:48,880 --> 00:05:52,400
but the several minutes constraint means

00:05:50,720 --> 00:05:53,280
that each function needs to run in its

00:05:52,400 --> 00:05:55,600
own lambda

00:05:53,280 --> 00:05:57,039
because lambda has a five minute time

00:05:55,600 --> 00:05:59,360
limit

00:05:57,039 --> 00:06:01,199
so right okay well what do we do um the

00:05:59,360 --> 00:06:02,160
naive initial approach which would kind

00:06:01,199 --> 00:06:03,840
of work

00:06:02,160 --> 00:06:05,440
we're simply just passing the value from

00:06:03,840 --> 00:06:08,080
one function to next

00:06:05,440 --> 00:06:09,840
it's not particularly interesting but it

00:06:08,080 --> 00:06:11,919
would work

00:06:09,840 --> 00:06:13,840
and we would test it and we would write

00:06:11,919 --> 00:06:16,479
unit tests for our functions

00:06:13,840 --> 00:06:18,000
and that would be great and we would

00:06:16,479 --> 00:06:18,639
maybe we could build an integration test

00:06:18,000 --> 00:06:20,160
and we would

00:06:18,639 --> 00:06:22,960
use something like local stack to

00:06:20,160 --> 00:06:25,680
simulate the aws environments

00:06:22,960 --> 00:06:27,600
on our local machine um and then we

00:06:25,680 --> 00:06:30,800
would have a staging account

00:06:27,600 --> 00:06:34,000
in our aws accounts so that we can

00:06:30,800 --> 00:06:36,319
test the complete thing in a realistic

00:06:34,000 --> 00:06:37,840
environment and and that's great that's

00:06:36,319 --> 00:06:39,840
that's all good stuff

00:06:37,840 --> 00:06:41,199
um but we would start discovering that

00:06:39,840 --> 00:06:44,639
lambda is not perfect and there are

00:06:41,199 --> 00:06:46,639
edge cases so the the traditional the

00:06:44,639 --> 00:06:48,080
common way of building this sort of

00:06:46,639 --> 00:06:50,639
thing now is to

00:06:48,080 --> 00:06:51,919
is to put cues between each lambda

00:06:50,639 --> 00:06:54,639
function

00:06:51,919 --> 00:06:55,280
um an input q and essentially a failure

00:06:54,639 --> 00:06:58,080
cube

00:06:55,280 --> 00:06:58,960
so when things go wrong we we can

00:06:58,080 --> 00:07:01,759
understand

00:06:58,960 --> 00:07:02,160
the state of the system um and and this

00:07:01,759 --> 00:07:05,120
is a

00:07:02,160 --> 00:07:06,080
this is a pretty good way of building

00:07:05,120 --> 00:07:09,039
this kind of pipeline

00:07:06,080 --> 00:07:10,560
it works quite well um but there's a

00:07:09,039 --> 00:07:11,599
whole lot of manual effort

00:07:10,560 --> 00:07:13,599
because you have to do everything

00:07:11,599 --> 00:07:14,800
yourself and

00:07:13,599 --> 00:07:16,720
there's tooling that will help with this

00:07:14,800 --> 00:07:17,520
like infrastructure as code which is

00:07:16,720 --> 00:07:19,919
great

00:07:17,520 --> 00:07:21,199
um but really you're going to take a lot

00:07:19,919 --> 00:07:22,479
of time and there's going to be a whole

00:07:21,199 --> 00:07:26,160
lot of infrastructure

00:07:22,479 --> 00:07:27,199
as code each of these modules

00:07:26,160 --> 00:07:29,360
there's going to be a whole lot of work

00:07:27,199 --> 00:07:32,240
to do and testing is going to be

00:07:29,360 --> 00:07:33,680
non-trivial because again you're going

00:07:32,240 --> 00:07:36,560
to have to simulate some kind of

00:07:33,680 --> 00:07:39,360
cloud environment um or or just deploy

00:07:36,560 --> 00:07:39,360
everything to the cloud

00:07:39,680 --> 00:07:43,120
now what what i what i want from teal

00:07:42,800 --> 00:07:45,759
why

00:07:43,120 --> 00:07:47,039
why teal kind of started is well i want

00:07:45,759 --> 00:07:48,560
to use python

00:07:47,039 --> 00:07:50,080
that's a given because all my stuff is

00:07:48,560 --> 00:07:52,319
written in python already i just want to

00:07:50,080 --> 00:07:53,759
take my scripts and run them i want to

00:07:52,319 --> 00:07:56,000
be able to test

00:07:53,759 --> 00:07:57,599
all of my logic locally i don't want to

00:07:56,000 --> 00:08:00,319
have to deploy to the cloud

00:07:57,599 --> 00:08:00,960
to test the logic and and the part of

00:08:00,319 --> 00:08:02,879
that is that

00:08:00,960 --> 00:08:05,120
i don't want my logic to be in my

00:08:02,879 --> 00:08:07,919
infrastructure so if my infrastructure

00:08:05,120 --> 00:08:10,800
determines how my program functions i

00:08:07,919 --> 00:08:13,440
think that's an anti-pattern

00:08:10,800 --> 00:08:15,199
i want contextual debugging which means

00:08:13,440 --> 00:08:17,680
if i've got these three functions

00:08:15,199 --> 00:08:18,479
and one of them fails i want to know the

00:08:17,680 --> 00:08:20,080
full

00:08:18,479 --> 00:08:21,919
i want to know the full context of that

00:08:20,080 --> 00:08:23,360
failure because the value

00:08:21,919 --> 00:08:25,440
that failed this function would have

00:08:23,360 --> 00:08:27,840
come from an initial function

00:08:25,440 --> 00:08:29,599
so i want that context um i want

00:08:27,840 --> 00:08:31,360
operational support so i want to know

00:08:29,599 --> 00:08:32,880
this is kind of a given i want to know

00:08:31,360 --> 00:08:34,959
the state of my system the state of the

00:08:32,880 --> 00:08:38,880
health how it's how it's running

00:08:34,959 --> 00:08:41,360
all that kind of stuff that's a given um

00:08:38,880 --> 00:08:42,880
this is this last one's interesting i i

00:08:41,360 --> 00:08:46,000
would quite like to be able to take

00:08:42,880 --> 00:08:47,839
my application and run it on any cloud

00:08:46,000 --> 00:08:49,360
in the same way that i can write python

00:08:47,839 --> 00:08:52,160
and run it on any kind of

00:08:49,360 --> 00:08:53,920
any computer uh there's an interface or

00:08:52,160 --> 00:08:55,760
operating system there's an interface

00:08:53,920 --> 00:08:59,120
that allows that code to be

00:08:55,760 --> 00:09:01,760
run anywhere so

00:08:59,120 --> 00:09:02,560
let's let's go ahead and try some tl and

00:09:01,760 --> 00:09:06,399
see how we can

00:09:02,560 --> 00:09:10,000
implement that application

00:09:06,399 --> 00:09:15,040
i'm going to can i end this right

00:09:10,000 --> 00:09:15,040
yes happy

00:09:16,080 --> 00:09:22,240
so teal uh i said teal that was i said

00:09:20,480 --> 00:09:24,080
teal was a programming language

00:09:22,240 --> 00:09:25,760
um and initially it was embedded in

00:09:24,080 --> 00:09:27,279
python uh

00:09:25,760 --> 00:09:29,839
but it's not anymore and i'll explain

00:09:27,279 --> 00:09:32,959
why later but

00:09:29,839 --> 00:09:33,519
um there are semicolons uh i'm sorry for

00:09:32,959 --> 00:09:35,839
that

00:09:33,519 --> 00:09:38,160
and i hope i get get to come back to

00:09:35,839 --> 00:09:41,120
pycon

00:09:38,160 --> 00:09:42,000
let's do the let's do the classic thing

00:09:41,120 --> 00:09:45,839
and

00:09:42,000 --> 00:09:51,680
say hello you are

00:09:45,839 --> 00:09:54,800
all awesome

00:09:51,680 --> 00:09:56,640
show you what i've got in this directory

00:09:54,800 --> 00:09:59,120
so i'm just going to run this service

00:09:56,640 --> 00:09:59,120
file here

00:09:59,760 --> 00:10:03,440
and we get what we expect and it's

00:10:01,279 --> 00:10:04,480
printed twice because teal prints the

00:10:03,440 --> 00:10:06,240
return value

00:10:04,480 --> 00:10:07,519
um that's not a particularly interesting

00:10:06,240 --> 00:10:10,800
detail let's

00:10:07,519 --> 00:10:11,680
go and implement our pipeline we've got

00:10:10,800 --> 00:10:13,440
our

00:10:11,680 --> 00:10:14,720
code here which which does some very

00:10:13,440 --> 00:10:16,480
very basic math and i haven't even

00:10:14,720 --> 00:10:18,079
bothered to check the math so

00:10:16,480 --> 00:10:20,240
that's not important but we've got our

00:10:18,079 --> 00:10:22,720
three functions

00:10:20,240 --> 00:10:24,240
and to call them from teal we need to

00:10:22,720 --> 00:10:27,680
tell

00:10:24,240 --> 00:10:29,040
the way they live which is source.main

00:10:27,680 --> 00:10:31,360
and we also need to tell it how many

00:10:29,040 --> 00:10:32,880
arguments they take

00:10:31,360 --> 00:10:35,519
um and if you've come across foreign

00:10:32,880 --> 00:10:37,200
function foreign function interfaces

00:10:35,519 --> 00:10:38,800
that's what we're doing here we're we're

00:10:37,200 --> 00:10:40,480
telling teal where they are how to call

00:10:38,800 --> 00:10:42,800
them

00:10:40,480 --> 00:10:44,640
and then we'll define our computation

00:10:42,800 --> 00:10:48,720
pipeline

00:10:44,640 --> 00:10:52,079
compute which takes one parameter

00:10:48,720 --> 00:10:55,200
and simply calls each of those

00:10:52,079 --> 00:10:56,079
functions and we'll create a main

00:10:55,200 --> 00:10:59,600
function to

00:10:56,079 --> 00:11:03,600
to test it just pass them some random

00:10:59,600 --> 00:11:03,600
number like one um it'll be fine

00:11:03,680 --> 00:11:08,640
and if i haven't just typed something

00:11:06,480 --> 00:11:09,839
okay great we've got a number uh three

00:11:08,640 --> 00:11:11,760
yeah that's probably fine

00:11:09,839 --> 00:11:13,279
and we can see the python output coming

00:11:11,760 --> 00:11:17,040
coming through here

00:11:13,279 --> 00:11:18,560
um we can we can go ahead and deploy

00:11:17,040 --> 00:11:20,959
this straight away to

00:11:18,560 --> 00:11:21,600
to aws and i'll do it with the verbose

00:11:20,959 --> 00:11:23,760
flag on

00:11:21,600 --> 00:11:24,800
just this first time to show you sort of

00:11:23,760 --> 00:11:27,120
what's happening

00:11:24,800 --> 00:11:28,720
um essentially it's it's going away and

00:11:27,120 --> 00:11:31,839
creating or

00:11:28,720 --> 00:11:35,040
updating some infrastructure

00:11:31,839 --> 00:11:36,800
in my aws account and most of that

00:11:35,040 --> 00:11:38,399
infrastructure never changes

00:11:36,800 --> 00:11:39,839
and that's quite important thing so

00:11:38,399 --> 00:11:41,200
there's this layer of hard

00:11:39,839 --> 00:11:43,120
infrastructure that doesn't

00:11:41,200 --> 00:11:45,920
and then teal is like this soft

00:11:43,120 --> 00:11:49,200
infrastructure that sits above it

00:11:45,920 --> 00:11:52,160
so that that just takes a few seconds um

00:11:49,200 --> 00:11:52,639
and then we can then we can invoke it

00:11:52,160 --> 00:11:55,920
and

00:11:52,639 --> 00:11:56,959
that that just calls main in aws and

00:11:55,920 --> 00:12:00,880
it'll print out some

00:11:56,959 --> 00:12:03,120
standard output now

00:12:00,880 --> 00:12:04,639
our original task was to run this in

00:12:03,120 --> 00:12:06,560
three separate lambda functions

00:12:04,639 --> 00:12:08,240
which we're not doing yet this this

00:12:06,560 --> 00:12:09,360
thread column shows that they're all

00:12:08,240 --> 00:12:13,360
running in the same

00:12:09,360 --> 00:12:15,600
lambda instance or invocation

00:12:13,360 --> 00:12:17,040
so let's let's make them run in separate

00:12:15,600 --> 00:12:20,320
numbers

00:12:17,040 --> 00:12:23,279
and the way that we do that is we call

00:12:20,320 --> 00:12:23,279
them asynchronously

00:12:23,760 --> 00:12:29,839
like that and if you're new to async

00:12:27,440 --> 00:12:32,480
it really just says go and run this

00:12:29,839 --> 00:12:34,639
function in a separate thread

00:12:32,480 --> 00:12:36,160
and give me a handle to the result of

00:12:34,639 --> 00:12:38,639
that computation

00:12:36,160 --> 00:12:40,480
and then we can wait for that function

00:12:38,639 --> 00:12:42,720
to to finish completing

00:12:40,480 --> 00:12:44,720
and we'll do that with the other two

00:12:42,720 --> 00:12:46,880
[Music]

00:12:44,720 --> 00:12:46,880
g

00:12:47,920 --> 00:12:54,320
and this is h

00:12:52,639 --> 00:12:56,399
and then the only difference here is

00:12:54,320 --> 00:12:58,000
that we we're now

00:12:56,399 --> 00:13:00,160
calling our async version and we're

00:12:58,000 --> 00:13:01,839
waiting for the results to come through

00:13:00,160 --> 00:13:03,279
um and so this is our this is our

00:13:01,839 --> 00:13:07,120
pipeline

00:13:03,279 --> 00:13:10,079
and if we if we deploy that again

00:13:07,120 --> 00:13:11,519
and invoke it and and this this should

00:13:10,079 --> 00:13:14,320
only take a few seconds to

00:13:11,519 --> 00:13:16,079
to deploy even though we've quite

00:13:14,320 --> 00:13:19,200
dramatically changed

00:13:16,079 --> 00:13:22,560
our infrastructure

00:13:19,200 --> 00:13:24,720
imaginary infrastructure um

00:13:22,560 --> 00:13:26,480
now what we should see is that each of

00:13:24,720 --> 00:13:29,040
those each of those asyncs

00:13:26,480 --> 00:13:30,639
has resulted in a separate thread um to

00:13:29,040 --> 00:13:32,880
go and do that that particular function

00:13:30,639 --> 00:13:36,639
computation

00:13:32,880 --> 00:13:38,880
um starting from thread zero

00:13:36,639 --> 00:13:40,959
and there we go so we've got our output

00:13:38,880 --> 00:13:42,639
in three different threads

00:13:40,959 --> 00:13:48,959
and we can add a little bit more

00:13:42,639 --> 00:13:51,199
information here to give

00:13:48,959 --> 00:13:51,199
done

00:13:52,000 --> 00:13:55,120
and deploy that

00:13:55,600 --> 00:14:00,000
the thing that i want to point out here

00:13:57,920 --> 00:14:03,040
as we'll see in a few seconds

00:14:00,000 --> 00:14:06,800
is that while

00:14:03,040 --> 00:14:09,680
h g and f are running

00:14:06,800 --> 00:14:11,920
the thread that started them this thread

00:14:09,680 --> 00:14:14,160
is completely stopped

00:14:11,920 --> 00:14:15,839
so it's not like it's polling and you

00:14:14,160 --> 00:14:16,320
can't quite see from this display uh so

00:14:15,839 --> 00:14:18,480
you

00:14:16,320 --> 00:14:20,320
gonna have to take my word on it that

00:14:18,480 --> 00:14:21,040
thread zero is completely stopped at

00:14:20,320 --> 00:14:24,480
this point

00:14:21,040 --> 00:14:25,839
once it once it calls async uh once it

00:14:24,480 --> 00:14:27,680
calls a weight

00:14:25,839 --> 00:14:28,959
it completely stops if that value isn't

00:14:27,680 --> 00:14:30,240
ready yet

00:14:28,959 --> 00:14:32,079
um which means that you're not wasting

00:14:30,240 --> 00:14:33,199
time you're not wasting compute time and

00:14:32,079 --> 00:14:35,440
you're not spending money

00:14:33,199 --> 00:14:36,480
for a lambda function doing nothing

00:14:35,440 --> 00:14:38,800
there's no polling

00:14:36,480 --> 00:14:41,440
and there's no event loop um it's all

00:14:38,800 --> 00:14:43,600
it's all handled by the till runtime

00:14:41,440 --> 00:14:44,639
so okay cool what if we wanted to do

00:14:43,600 --> 00:14:47,040
something more interesting

00:14:44,639 --> 00:14:47,920
like compute i don't know several at the

00:14:47,040 --> 00:14:50,959
same time

00:14:47,920 --> 00:14:52,160
um all in parallel uh well okay what

00:14:50,959 --> 00:14:55,600
would that look like

00:14:52,160 --> 00:14:58,000
let me uh i'm just gonna copy

00:14:55,600 --> 00:15:00,000
that out because that'll save us a bit

00:14:58,000 --> 00:15:03,680
of time

00:15:00,000 --> 00:15:05,839
and reload that uh

00:15:03,680 --> 00:15:06,959
what are we doing well we've got our two

00:15:05,839 --> 00:15:08,880
compute lines

00:15:06,959 --> 00:15:10,000
we're computing this value a and this

00:15:08,880 --> 00:15:12,160
value b

00:15:10,000 --> 00:15:13,519
both in parallel that's what this async

00:15:12,160 --> 00:15:15,360
thing does

00:15:13,519 --> 00:15:18,800
and then we're waiting for both of those

00:15:15,360 --> 00:15:19,920
values to be to be finished to be ready

00:15:18,800 --> 00:15:22,000
and then we're doing something with that

00:15:19,920 --> 00:15:23,680
result and there's a there's some kind

00:15:22,000 --> 00:15:25,199
of branching

00:15:23,680 --> 00:15:27,360
let's let's deploy that and see what

00:15:25,199 --> 00:15:29,040
happens

00:15:27,360 --> 00:15:30,800
um and while that's going let me point

00:15:29,040 --> 00:15:34,160
out that like

00:15:30,800 --> 00:15:37,279
implementing this with with queues and

00:15:34,160 --> 00:15:40,079
lambdas and doing this manually with

00:15:37,279 --> 00:15:41,440
infrastructure would be non-trivial

00:15:40,079 --> 00:15:44,160
because you'd have to

00:15:41,440 --> 00:15:45,120
synchronize here you'd have to have have

00:15:44,160 --> 00:15:46,800
some kind of

00:15:45,120 --> 00:15:48,959
branching logic you know you'd have to

00:15:46,800 --> 00:15:51,360
have two different cues that

00:15:48,959 --> 00:15:52,639
sort of handled this branching thing um

00:15:51,360 --> 00:15:54,399
you'd have quite a big diagram which

00:15:52,639 --> 00:15:56,079
would be great for you but quite hard to

00:15:54,399 --> 00:15:57,519
do

00:15:56,079 --> 00:15:59,279
we've just done it in a few lines of

00:15:57,519 --> 00:16:02,880
code

00:15:59,279 --> 00:16:05,440
and that took 10 seconds um

00:16:02,880 --> 00:16:07,360
which is about right because the single

00:16:05,440 --> 00:16:09,279
pipeline also took 10 seconds

00:16:07,360 --> 00:16:10,639
so that kind of shows how it's it's

00:16:09,279 --> 00:16:12,320
computing them in parallel

00:16:10,639 --> 00:16:14,079
and we've got twice as many threads

00:16:12,320 --> 00:16:14,639
which again is what we would expect

00:16:14,079 --> 00:16:17,440
because

00:16:14,639 --> 00:16:18,079
it's all happening uh in parallel at the

00:16:17,440 --> 00:16:20,399
same time

00:16:18,079 --> 00:16:22,000
in in separate lambda implications so

00:16:20,399 --> 00:16:24,639
this is great this is powerful

00:16:22,000 --> 00:16:25,920
but um but be aware like you could quite

00:16:24,639 --> 00:16:28,000
easily spin up hundreds of

00:16:25,920 --> 00:16:30,720
lambda functions so that's the caveat

00:16:28,000 --> 00:16:34,720
that we'll come back to

00:16:30,720 --> 00:16:36,480
we'll look at one more example

00:16:34,720 --> 00:16:38,720
and this is another fairly common use

00:16:36,480 --> 00:16:41,360
case for serverless stuff

00:16:38,720 --> 00:16:42,800
uh so you've got your web front end and

00:16:41,360 --> 00:16:45,600
you want to

00:16:42,800 --> 00:16:46,079
do some background uh logic in your in

00:16:45,600 --> 00:16:48,320
your

00:16:46,079 --> 00:16:49,360
back end server but the problem is that

00:16:48,320 --> 00:16:51,920
logic takes

00:16:49,360 --> 00:16:53,040
some time um several minutes hours

00:16:51,920 --> 00:16:54,560
whatever

00:16:53,040 --> 00:16:57,360
and and you want your front end to

00:16:54,560 --> 00:16:59,680
respond immediately and tell the user

00:16:57,360 --> 00:17:00,480
you know we're processing um maybe your

00:16:59,680 --> 00:17:04,240
user has

00:17:00,480 --> 00:17:06,720
requested their data dumped for gdpr or

00:17:04,240 --> 00:17:07,919
something um so you've got to go and do

00:17:06,720 --> 00:17:09,199
this in the background

00:17:07,919 --> 00:17:11,760
and the traditional way of doing this

00:17:09,199 --> 00:17:15,360
would be like rabbit mq

00:17:11,760 --> 00:17:18,160
or some kind of past running process

00:17:15,360 --> 00:17:19,120
uh there are ways of doing it but the

00:17:18,160 --> 00:17:21,120
point is that you then have to go and

00:17:19,120 --> 00:17:22,959
manage that infrastructure

00:17:21,120 --> 00:17:24,559
like you would have to go and set up

00:17:22,959 --> 00:17:27,520
your your salary

00:17:24,559 --> 00:17:28,160
server or your task runner whatever it

00:17:27,520 --> 00:17:30,080
is

00:17:28,160 --> 00:17:32,240
and it's not serverless and it's it

00:17:30,080 --> 00:17:35,600
takes a while

00:17:32,240 --> 00:17:38,799
in teal it's it's one word

00:17:35,600 --> 00:17:42,000
async which says okay

00:17:38,799 --> 00:17:43,600
um when we curl this compute endpoint

00:17:42,000 --> 00:17:45,280
kick off this function and just return

00:17:43,600 --> 00:17:46,160
immediately and return something called

00:17:45,280 --> 00:17:48,400
a session id

00:17:46,160 --> 00:17:51,039
which allows the client to then um query

00:17:48,400 --> 00:17:54,400
teal and see how how the task is doing

00:17:51,039 --> 00:17:56,559
so we'll deploy that um now

00:17:54,400 --> 00:17:58,000
i went and did kill invoke which is not

00:17:56,559 --> 00:18:01,679
a good idea

00:17:58,000 --> 00:18:06,320
that's fine let's clear that

00:18:01,679 --> 00:18:06,320
uh what i wanted to do was curl

00:18:07,120 --> 00:18:10,559
uh this is a fairly simple curl we're

00:18:10,000 --> 00:18:12,640
just saying

00:18:10,559 --> 00:18:14,000
hello which is which is passing the

00:18:12,640 --> 00:18:16,000
entire lambda event

00:18:14,000 --> 00:18:17,280
to a python function which is doing

00:18:16,000 --> 00:18:19,760
something

00:18:17,280 --> 00:18:21,039
the more interesting one is is compute

00:18:19,760 --> 00:18:24,960
and

00:18:21,039 --> 00:18:28,000
um i should point out first that

00:18:24,960 --> 00:18:30,559
tl has set up the api endpoint for us

00:18:28,000 --> 00:18:31,200
and i've just set that to an environment

00:18:30,559 --> 00:18:33,840
variable

00:18:31,200 --> 00:18:34,559
so when i'm doing this call command it's

00:18:33,840 --> 00:18:36,640
it's nothing

00:18:34,559 --> 00:18:37,919
fancy i'm i'm just curling this api

00:18:36,640 --> 00:18:43,039
endpoint um

00:18:37,919 --> 00:18:45,840
and i'm passing in some data

00:18:43,039 --> 00:18:47,679
so when we do compute we get our session

00:18:45,840 --> 00:18:48,880
id out

00:18:47,679 --> 00:18:51,440
and we can then go and query that

00:18:48,880 --> 00:18:53,039
session id and check if it's done

00:18:51,440 --> 00:18:54,880
and in this case it was done because i

00:18:53,039 --> 00:18:57,200
only slept five seconds

00:18:54,880 --> 00:18:58,480
but that's great now we can go and carry

00:18:57,200 --> 00:19:00,720
on with what we were doing in the first

00:18:58,480 --> 00:19:00,720
place

00:19:01,360 --> 00:19:04,400
let's uh let's let's jump back into the

00:19:04,000 --> 00:19:07,760
yeah

00:19:04,400 --> 00:19:11,039
thanks for ignoring the semicolons um

00:19:07,760 --> 00:19:12,640
yeah like i tried really hard to

00:19:11,039 --> 00:19:14,880
so i wrote like five different parsers

00:19:12,640 --> 00:19:16,400
trying to get rid of the semicolons but

00:19:14,880 --> 00:19:16,960
turns out it's a quite a hard thing to

00:19:16,400 --> 00:19:20,640
do

00:19:16,960 --> 00:19:24,799
anyway uh let's let's jump into

00:19:20,640 --> 00:19:26,559
let's jump back into the presentation

00:19:24,799 --> 00:19:28,880
see if i can get my remote back up and

00:19:26,559 --> 00:19:28,880
running

00:19:29,520 --> 00:19:35,840
okay cool um recap what have we done

00:19:32,640 --> 00:19:37,280
well we did this pipeline um

00:19:35,840 --> 00:19:38,960
and it wasn't particularly interesting

00:19:37,280 --> 00:19:41,280
it's fairly straightforward

00:19:38,960 --> 00:19:42,720
but i think this is still better than

00:19:41,280 --> 00:19:45,600
doing it manually because

00:19:42,720 --> 00:19:47,039
we we instantly get stuff like log

00:19:45,600 --> 00:19:48,320
aggregation

00:19:47,039 --> 00:19:50,320
so there were three separate lambdas

00:19:48,320 --> 00:19:52,480
there we didn't have to do any work to

00:19:50,320 --> 00:19:53,919
pull the logs into one place and

00:19:52,480 --> 00:19:56,240
normally you'd be then

00:19:53,919 --> 00:19:57,600
you know you'd be hunting in um cloud

00:19:56,240 --> 00:19:59,200
watch or

00:19:57,600 --> 00:20:00,799
you'd be trying to manually pull these

00:19:59,200 --> 00:20:02,320
logs together and we didn't have to do

00:20:00,799 --> 00:20:05,200
any work for that

00:20:02,320 --> 00:20:06,720
um and similarly i didn't show you but

00:20:05,200 --> 00:20:09,120
if one of those functions broke

00:20:06,720 --> 00:20:09,919
we would get a nice stack trace that

00:20:09,120 --> 00:20:13,840
works across

00:20:09,919 --> 00:20:16,320
across threads so that's great

00:20:13,840 --> 00:20:17,120
we did a little bit of parallel stuff

00:20:16,320 --> 00:20:19,440
and

00:20:17,120 --> 00:20:21,200
branching which is really cool because

00:20:19,440 --> 00:20:23,440
it took a few lines and

00:20:21,200 --> 00:20:24,880
you can see what the code is doing you

00:20:23,440 --> 00:20:26,400
can test it locally

00:20:24,880 --> 00:20:28,320
um i don't think i did test this one

00:20:26,400 --> 00:20:29,679
locally just because deploying it is so

00:20:28,320 --> 00:20:31,039
easy

00:20:29,679 --> 00:20:32,840
but you could have tested it locally

00:20:31,039 --> 00:20:34,880
make sure it all works and then deploy

00:20:32,840 --> 00:20:37,440
it uh

00:20:34,880 --> 00:20:38,720
i didn't show you mapping but

00:20:37,440 --> 00:20:40,080
essentially

00:20:38,720 --> 00:20:42,159
this is like a for loop right you've got

00:20:40,080 --> 00:20:44,240
a list of values and you want to

00:20:42,159 --> 00:20:45,440
apply your function to every value in

00:20:44,240 --> 00:20:48,320
that list

00:20:45,440 --> 00:20:49,520
and until functions are first class just

00:20:48,320 --> 00:20:50,640
like python so you can pass the

00:20:49,520 --> 00:20:53,120
functions around

00:20:50,640 --> 00:20:54,240
and you can you can do functional style

00:20:53,120 --> 00:20:55,840
programming with them

00:20:54,240 --> 00:20:57,919
so that's great you can go and compute

00:20:55,840 --> 00:20:59,280
your your thing in parallel

00:20:57,919 --> 00:21:01,440
and then wait for the results to come

00:20:59,280 --> 00:21:01,440
back

00:21:01,760 --> 00:21:05,679
we talked briefly about this api um end

00:21:04,799 --> 00:21:08,000
point

00:21:05,679 --> 00:21:09,360
which which is really the thing that i

00:21:08,000 --> 00:21:11,360
love about this is the

00:21:09,360 --> 00:21:13,039
the workflow is really really simple and

00:21:11,360 --> 00:21:15,760
straightforward and it's quite slow for

00:21:13,039 --> 00:21:17,360
now like several seconds to respond

00:21:15,760 --> 00:21:19,679
but that's that's an engineering problem

00:21:17,360 --> 00:21:21,679
and that's just about optimizing tools

00:21:19,679 --> 00:21:23,039
upfront load time so that'll get that'll

00:21:21,679 --> 00:21:25,840
improve um

00:21:23,039 --> 00:21:27,840
but the workflow of just saying hey go

00:21:25,840 --> 00:21:29,360
and do this thing in the background

00:21:27,840 --> 00:21:31,120
is just great and i've been using it in

00:21:29,360 --> 00:21:34,159
another project and and just

00:21:31,120 --> 00:21:34,159
loving it so easy

00:21:34,400 --> 00:21:37,600
some things i didn't show you um a lot

00:21:36,960 --> 00:21:39,280
of this is

00:21:37,600 --> 00:21:41,200
is kind of what you would expect and

00:21:39,280 --> 00:21:44,880
it's it's really about making

00:21:41,200 --> 00:21:48,080
um the programmer life easy

00:21:44,880 --> 00:21:49,520
like if i've got a if i want to upload a

00:21:48,080 --> 00:21:51,520
file to an s3

00:21:49,520 --> 00:21:52,960
bucket which is which is an object store

00:21:51,520 --> 00:21:55,280
in aws

00:21:52,960 --> 00:21:56,480
and i want my code to run whenever a

00:21:55,280 --> 00:21:58,880
file is uploaded

00:21:56,480 --> 00:22:00,640
that event happens um i just want to

00:21:58,880 --> 00:22:04,000
modify one line

00:22:00,640 --> 00:22:05,200
in my source file that says trigger this

00:22:04,000 --> 00:22:07,840
function

00:22:05,200 --> 00:22:08,960
um and at the moment it's a much more

00:22:07,840 --> 00:22:11,520
complicated process

00:22:08,960 --> 00:22:12,080
uh we're going in configuring um a whole

00:22:11,520 --> 00:22:14,480
lot of

00:22:12,080 --> 00:22:15,760
stuff and it's not particularly fun and

00:22:14,480 --> 00:22:17,760
it's not particularly

00:22:15,760 --> 00:22:19,120
intuitive and it doesn't feel doesn't

00:22:17,760 --> 00:22:22,159
feel that nice

00:22:19,120 --> 00:22:25,039
um maybe i'm super biased in that

00:22:22,159 --> 00:22:26,320
we'll see the other things sort of what

00:22:25,039 --> 00:22:28,159
you would expect um

00:22:26,320 --> 00:22:29,919
you need to be able to customize the

00:22:28,159 --> 00:22:33,360
permissions that your function has

00:22:29,919 --> 00:22:36,000
and the build scripts and all the

00:22:33,360 --> 00:22:40,640
all the memory and all the things you'd

00:22:36,000 --> 00:22:43,679
expect in lambda

00:22:40,640 --> 00:22:45,600
now the question that

00:22:43,679 --> 00:22:46,880
the question that i want to address and

00:22:45,600 --> 00:22:49,520
and it's really important

00:22:46,880 --> 00:22:50,400
um lots of people ask me this and i ask

00:22:49,520 --> 00:22:52,960
myself this

00:22:50,400 --> 00:22:54,720
and it's why is teal why is seal not a

00:22:52,960 --> 00:22:57,360
library in python

00:22:54,720 --> 00:22:58,159
um why is it a separate thing and well

00:22:57,360 --> 00:23:01,200
the answer is that

00:22:58,159 --> 00:23:02,960
it was originally a library um that's

00:23:01,200 --> 00:23:08,080
how the project started

00:23:02,960 --> 00:23:09,760
and it was just really limited because

00:23:08,080 --> 00:23:11,760
well the problem really comes when

00:23:09,760 --> 00:23:13,440
you've got a function like this

00:23:11,760 --> 00:23:15,520
where you're doing some you're doing

00:23:13,440 --> 00:23:18,000
some computation

00:23:15,520 --> 00:23:20,080
and halfway through the function you

00:23:18,000 --> 00:23:22,480
want to stop

00:23:20,080 --> 00:23:23,600
and i couldn't figure out how to do that

00:23:22,480 --> 00:23:26,559
in python

00:23:23,600 --> 00:23:27,280
without completely obscuring the python

00:23:26,559 --> 00:23:28,960
entirely

00:23:27,280 --> 00:23:30,400
which would defeat the points but if

00:23:28,960 --> 00:23:32,720
you've got a python function

00:23:30,400 --> 00:23:34,400
and you want to stop halfway through how

00:23:32,720 --> 00:23:37,120
how on earth do you

00:23:34,400 --> 00:23:37,600
how you how do you serialize the entire

00:23:37,120 --> 00:23:39,840
state

00:23:37,600 --> 00:23:41,600
of the interpreter or sub-interpreter

00:23:39,840 --> 00:23:43,600
and put that in the disk

00:23:41,600 --> 00:23:45,039
and then at a later point pick it up

00:23:43,600 --> 00:23:46,559
again um

00:23:45,039 --> 00:23:48,799
i couldn't figure out how to do that it

00:23:46,559 --> 00:23:51,520
seemed like way too much of a task

00:23:48,799 --> 00:23:52,720
um but if you've got some ideas that

00:23:51,520 --> 00:23:53,600
would be awesome it would be really

00:23:52,720 --> 00:23:58,320
really cool

00:23:53,600 --> 00:24:01,520
to see this um 100 native in python

00:23:58,320 --> 00:24:03,679
the logic here this this halting

00:24:01,520 --> 00:24:05,600
logic that i was just talking about

00:24:03,679 --> 00:24:07,679
really says

00:24:05,600 --> 00:24:08,960
i'm thread zero and i want to use this

00:24:07,679 --> 00:24:11,840
value a

00:24:08,960 --> 00:24:12,880
now is it ready um if it's ready i can

00:24:11,840 --> 00:24:15,120
carry on running

00:24:12,880 --> 00:24:16,000
right now if it's not ready i'm gonna

00:24:15,120 --> 00:24:17,600
wait for it

00:24:16,000 --> 00:24:19,520
and and i'm gonna tell the thread that's

00:24:17,600 --> 00:24:22,799
running computing a

00:24:19,520 --> 00:24:25,520
um when you're done restart me and

00:24:22,799 --> 00:24:27,039
then i'm just going to stop entirely and

00:24:25,520 --> 00:24:29,360
when that thread does finish it'll say

00:24:27,039 --> 00:24:32,559
okay who's waiting for my results

00:24:29,360 --> 00:24:34,159
and then it'll go and pass that results

00:24:32,559 --> 00:24:36,320
to those to those functions those

00:24:34,159 --> 00:24:37,760
threads and and carry them on

00:24:36,320 --> 00:24:40,080
um so it's a bit like an implicit

00:24:37,760 --> 00:24:40,799
callback uh except that you don't have

00:24:40,080 --> 00:24:43,919
to

00:24:40,799 --> 00:24:46,159
do that logic um and there's no

00:24:43,919 --> 00:24:47,760
event loop there's no polling there's no

00:24:46,159 --> 00:24:49,840
third party service that's

00:24:47,760 --> 00:24:52,720
like coordinating all these things it

00:24:49,840 --> 00:24:57,039
all happens at run time

00:24:52,720 --> 00:24:58,480
managed by teal now

00:24:57,039 --> 00:25:00,720
we're going to do a really really quick

00:24:58,480 --> 00:25:01,279
overview of what teal looks like under

00:25:00,720 --> 00:25:04,320
the hood

00:25:01,279 --> 00:25:05,360
um this is probably like multiple talks

00:25:04,320 --> 00:25:07,440
so i'm

00:25:05,360 --> 00:25:08,480
i'm not going to go into any detail but

00:25:07,440 --> 00:25:09,919
um

00:25:08,480 --> 00:25:11,520
please come and talk to me afterwards if

00:25:09,919 --> 00:25:13,200
you want to know more

00:25:11,520 --> 00:25:14,640
it really is a virtual machine that's

00:25:13,200 --> 00:25:17,279
implemented in python

00:25:14,640 --> 00:25:18,400
and can call into python directly and

00:25:17,279 --> 00:25:21,919
it's a virtual machine

00:25:18,400 --> 00:25:24,720
in the sense that there are instructions

00:25:21,919 --> 00:25:25,279
and there's a data stack and a call

00:25:24,720 --> 00:25:28,240
stack

00:25:25,279 --> 00:25:29,679
and a standard output model and some

00:25:28,240 --> 00:25:32,480
kind of cpu

00:25:29,679 --> 00:25:33,440
some idea of a cpu that's in that's

00:25:32,480 --> 00:25:35,600
evaluating

00:25:33,440 --> 00:25:37,600
instructions and that's all very

00:25:35,600 --> 00:25:38,720
standard vm that's that's nothing

00:25:37,600 --> 00:25:41,440
particularly

00:25:38,720 --> 00:25:42,559
interesting or innovative um the cool

00:25:41,440 --> 00:25:44,400
difference is that

00:25:42,559 --> 00:25:45,840
there's this layer of of persistent

00:25:44,400 --> 00:25:48,880
storage

00:25:45,840 --> 00:25:50,400
um and you can have multiple threads and

00:25:48,880 --> 00:25:52,400
until abstracts the notion of a thread

00:25:50,400 --> 00:25:55,360
and and memory which means that

00:25:52,400 --> 00:25:56,720
you can really you can run anywhere um

00:25:55,360 --> 00:25:59,520
that has memory and

00:25:56,720 --> 00:26:01,039
and some notion of computation so in aws

00:25:59,520 --> 00:26:03,360
a thread runs on lambda

00:26:01,039 --> 00:26:04,320
on my local machine a thread just runs

00:26:03,360 --> 00:26:06,960
in a thread

00:26:04,320 --> 00:26:08,640
there's nothing interesting there and in

00:26:06,960 --> 00:26:11,279
aws the memory is

00:26:08,640 --> 00:26:13,520
dynamodb but locally the memory is just

00:26:11,279 --> 00:26:17,760
my computer's memory

00:26:13,520 --> 00:26:21,279
um the the when it's deployed to aws

00:26:17,760 --> 00:26:23,279
it looks something like this um

00:26:21,279 --> 00:26:25,120
the tlvm is in that runtime box over

00:26:23,279 --> 00:26:26,240
there and that's the kind of interesting

00:26:25,120 --> 00:26:28,480
thing that communicates

00:26:26,240 --> 00:26:30,080
with the rest of your account and there

00:26:28,480 --> 00:26:32,080
are two other apis that are

00:26:30,080 --> 00:26:33,919
worth mentioning one is the control api

00:26:32,080 --> 00:26:35,520
which does what you sort of expect it

00:26:33,919 --> 00:26:37,679
it lets you communicate with your teal

00:26:35,520 --> 00:26:40,240
instance and get logs

00:26:37,679 --> 00:26:41,200
figure out what's going on um program

00:26:40,240 --> 00:26:44,000
the code

00:26:41,200 --> 00:26:45,360
um listen sessions all that kind of

00:26:44,000 --> 00:26:47,760
stuff that's what the cli

00:26:45,360 --> 00:26:48,720
interacts with and the other one is the

00:26:47,760 --> 00:26:51,760
trigger api

00:26:48,720 --> 00:26:54,400
which is a fairly flexible generic

00:26:51,760 --> 00:26:55,600
well you can extend it interface that

00:26:54,400 --> 00:26:58,000
lets you trigger

00:26:55,600 --> 00:26:59,360
teal functions and i've implemented

00:26:58,000 --> 00:27:02,480
three triggers

00:26:59,360 --> 00:27:03,840
um but you could go and attach anything

00:27:02,480 --> 00:27:06,320
that can call lambda

00:27:03,840 --> 00:27:06,880
can call teal so you can go and modify

00:27:06,320 --> 00:27:09,279
that and

00:27:06,880 --> 00:27:11,279
add your own triggers um or third-party

00:27:09,279 --> 00:27:14,400
services

00:27:11,279 --> 00:27:15,840
uh worth mentioning there are a bunch of

00:27:14,400 --> 00:27:17,120
really awesome libraries that made this

00:27:15,840 --> 00:27:20,640
possible

00:27:17,120 --> 00:27:22,720
um it wouldn't you know save

00:27:20,640 --> 00:27:24,399
years of development time uh these these

00:27:22,720 --> 00:27:26,960
things are great uh definitely go and

00:27:24,399 --> 00:27:29,200
check them out

00:27:26,960 --> 00:27:30,399
the the compiler this is going to be

00:27:29,200 --> 00:27:32,320
also a super high level

00:27:30,399 --> 00:27:33,840
overview the teal compiler is it's

00:27:32,320 --> 00:27:36,640
nothing particularly

00:27:33,840 --> 00:27:38,559
innovative as compilers go um doing it

00:27:36,640 --> 00:27:39,919
in python has been a whole lot of fun

00:27:38,559 --> 00:27:42,399
and quite quite an interesting

00:27:39,919 --> 00:27:43,840
experience but really the goal is to go

00:27:42,399 --> 00:27:47,520
from

00:27:43,840 --> 00:27:49,679
teal text to an executable that can run

00:27:47,520 --> 00:27:52,159
on the vm that we've just talked about

00:27:49,679 --> 00:27:53,600
and and it it it comprises of a few

00:27:52,159 --> 00:27:55,679
things there

00:27:53,600 --> 00:27:58,159
but the interesting step the interesting

00:27:55,679 --> 00:28:00,720
thing is this middle optimized step

00:27:58,159 --> 00:28:03,200
where the compiler kind of has has the

00:28:00,720 --> 00:28:03,840
power to analyze our code analyze our

00:28:03,200 --> 00:28:07,120
function

00:28:03,840 --> 00:28:09,200
or our program and then modify

00:28:07,120 --> 00:28:10,880
the the executable and potentially

00:28:09,200 --> 00:28:13,200
modify the infrastructure

00:28:10,880 --> 00:28:14,240
so if we say that our function needs to

00:28:13,200 --> 00:28:16,880
be

00:28:14,240 --> 00:28:19,039
you know respond within 20 milliseconds

00:28:16,880 --> 00:28:22,720
needs to be in these regions

00:28:19,039 --> 00:28:25,279
um uh and it needs to respond to a

00:28:22,720 --> 00:28:27,360
million events at the same time

00:28:25,279 --> 00:28:28,399
well the compiler can then go okay well

00:28:27,360 --> 00:28:31,120
it needs to be

00:28:28,399 --> 00:28:32,559
attached to a kinesis instance and the

00:28:31,120 --> 00:28:34,080
compiler can just go and then sort that

00:28:32,559 --> 00:28:35,520
out for us

00:28:34,080 --> 00:28:37,279
and that's not done yet but that's the

00:28:35,520 --> 00:28:39,039
kind of thing i i think

00:28:37,279 --> 00:28:41,120
could be done and would be really really

00:28:39,039 --> 00:28:42,880
cool

00:28:41,120 --> 00:28:45,360
again a bunch of really awesome

00:28:42,880 --> 00:28:47,679
libraries that made this possible

00:28:45,360 --> 00:28:50,240
so many parser libraries in python it's

00:28:47,679 --> 00:28:50,240
fantastic

00:28:50,320 --> 00:28:55,520
okay so our checklist well

00:28:53,520 --> 00:28:56,840
we've got the top three things which is

00:28:55,520 --> 00:29:00,720
great

00:28:56,840 --> 00:29:04,799
and the bottom two things are on the way

00:29:00,720 --> 00:29:06,080
so those those i i can see something i

00:29:04,799 --> 00:29:07,919
could see this

00:29:06,080 --> 00:29:09,919
being far more powerful than it is now

00:29:07,919 --> 00:29:12,320
particularly around operational support

00:29:09,919 --> 00:29:14,080
because at the moment there's just a cli

00:29:12,320 --> 00:29:14,960
and what we really need is a dashboard

00:29:14,080 --> 00:29:17,039
where we can

00:29:14,960 --> 00:29:19,279
we can see the entire state of our

00:29:17,039 --> 00:29:22,399
system manage deployments

00:29:19,279 --> 00:29:25,279
um do stuff like one click rollbacks

00:29:22,399 --> 00:29:27,200
um blue green deployments of entire

00:29:25,279 --> 00:29:31,039
serverless applications

00:29:27,200 --> 00:29:33,200
all the kind of like really really um

00:29:31,039 --> 00:29:36,960
high level operational support stuff

00:29:33,200 --> 00:29:36,960
that is quite hard to do now

00:29:37,760 --> 00:29:42,720
some of the limitations very briefly

00:29:40,880 --> 00:29:44,240
the bandwidth i think will always be

00:29:42,720 --> 00:29:45,760
limited physically by

00:29:44,240 --> 00:29:47,840
if you've got your cpu and you've got

00:29:45,760 --> 00:29:49,120
your memory i think we'll always be

00:29:47,840 --> 00:29:51,279
limited by

00:29:49,120 --> 00:29:52,880
the data bandwidth between those two

00:29:51,279 --> 00:29:54,640
things there's there's a physical

00:29:52,880 --> 00:29:56,399
connection that is there's a network

00:29:54,640 --> 00:29:58,240
that we have to transfer

00:29:56,399 --> 00:30:00,000
stuff over so i think we're always going

00:29:58,240 --> 00:30:03,679
to be limited in bandwidth

00:30:00,000 --> 00:30:06,720
speed there lambda startup time

00:30:03,679 --> 00:30:10,080
and concurrency limits and costs

00:30:06,720 --> 00:30:12,799
those i think are not those will improve

00:30:10,080 --> 00:30:13,360
um as as lambda becomes more competitive

00:30:12,799 --> 00:30:15,039
as

00:30:13,360 --> 00:30:17,279
more players enter the cloud functions

00:30:15,039 --> 00:30:19,279
game things like startup time

00:30:17,279 --> 00:30:21,039
those will just go down the things like

00:30:19,279 --> 00:30:22,480
cost that's just going to go down

00:30:21,039 --> 00:30:24,720
because it's it's becoming more

00:30:22,480 --> 00:30:26,399
competitive um

00:30:24,720 --> 00:30:28,080
it's still worth being aware though you

00:30:26,399 --> 00:30:30,080
you want to be careful uh

00:30:28,080 --> 00:30:31,919
like the new the new denial of service

00:30:30,080 --> 00:30:34,000
is denial of wallet

00:30:31,919 --> 00:30:35,120
uh you've got to be careful about how

00:30:34,000 --> 00:30:36,799
many of these

00:30:35,120 --> 00:30:38,399
things that you spin up um but i think

00:30:36,799 --> 00:30:42,480
teal can probably help with that

00:30:38,399 --> 00:30:42,480
uh in in in the compile stage

00:30:43,360 --> 00:30:48,000
well so that's teal um as you can

00:30:46,559 --> 00:30:50,080
probably tell i'm quite

00:30:48,000 --> 00:30:51,919
i'm quite excited to see how how we can

00:30:50,080 --> 00:30:53,600
like go beyond infrastructure and

00:30:51,919 --> 00:30:55,679
quite excited to see how the cloud is

00:30:53,600 --> 00:30:57,519
going to change in the next few years

00:30:55,679 --> 00:30:59,200
um if you'd like to contribute or

00:30:57,519 --> 00:31:01,440
support this work like

00:30:59,200 --> 00:31:02,399
great reach out to me um it'd be cool to

00:31:01,440 --> 00:31:05,519
chat

00:31:02,399 --> 00:31:06,159
uh i i want to also say thank you to the

00:31:05,519 --> 00:31:09,279
organizers

00:31:06,159 --> 00:31:11,679
it's incredible this year is just

00:31:09,279 --> 00:31:12,960
completely crazy and you guys have done

00:31:11,679 --> 00:31:15,679
such a cool job

00:31:12,960 --> 00:31:16,880
uh getting this out there um i was

00:31:15,679 --> 00:31:19,600
talking to marlene earlier and

00:31:16,880 --> 00:31:20,799
the five five days of conference like

00:31:19,600 --> 00:31:23,120
that's hard

00:31:20,799 --> 00:31:23,919
that's incredibly hard and you've pulled

00:31:23,120 --> 00:31:26,240
it off so

00:31:23,919 --> 00:31:27,840
so well done um it's it's wonderful to

00:31:26,240 --> 00:31:28,240
be here and to see all the cool things

00:31:27,840 --> 00:31:31,440
that

00:31:28,240 --> 00:31:33,519
you guys are working on from daniel

00:31:31,440 --> 00:31:34,399
a question in case you'll catch it later

00:31:33,519 --> 00:31:36,159
when would you choose to use a

00:31:34,399 --> 00:31:37,840
serverless solution and when would you

00:31:36,159 --> 00:31:39,519
say docker containerization

00:31:37,840 --> 00:31:41,360
looks more suitable for a particular use

00:31:39,519 --> 00:31:42,159
case yeah this is a this is a great

00:31:41,360 --> 00:31:46,399
question

00:31:42,159 --> 00:31:49,840
so the answer is if you um if you're

00:31:46,399 --> 00:31:51,919
if you're worried about traffic changing

00:31:49,840 --> 00:31:53,039
um if you're if the demand for your

00:31:51,919 --> 00:31:55,679
service is

00:31:53,039 --> 00:31:56,720
slightly irregular then go for surplus

00:31:55,679 --> 00:31:58,720
if you've got a very

00:31:56,720 --> 00:32:00,159
regular demand for your for your service

00:31:58,720 --> 00:32:02,799
like you you can predict

00:32:00,159 --> 00:32:03,919
you know you're going to have a constant

00:32:02,799 --> 00:32:06,880
100 requests

00:32:03,919 --> 00:32:07,200
a minute um all the time no matter what

00:32:06,880 --> 00:32:09,600
then

00:32:07,200 --> 00:32:10,640
doctorization is is great and you can

00:32:09,600 --> 00:32:13,679
use kubernetes to

00:32:10,640 --> 00:32:15,200
to get some more scalability um but but

00:32:13,679 --> 00:32:16,399
the serverless platforms really start

00:32:15,200 --> 00:32:18,240
paying for themselves when

00:32:16,399 --> 00:32:19,679
you when you've got the service that

00:32:18,240 --> 00:32:22,559
might go up and down

00:32:19,679 --> 00:32:24,399
it fluctuates uh you don't know how how

00:32:22,559 --> 00:32:27,440
big it's going to need to scale

00:32:24,399 --> 00:32:28,480
um especially for new projects if i

00:32:27,440 --> 00:32:30,320
would totally recommend it for new

00:32:28,480 --> 00:32:31,840
projects because

00:32:30,320 --> 00:32:33,679
because you just get all the scalability

00:32:31,840 --> 00:32:34,640
out of the box you have no idea how big

00:32:33,679 --> 00:32:38,320
it's going to go

00:32:34,640 --> 00:32:41,600
and you can start for free the aws

00:32:38,320 --> 00:32:41,600
free tier is just massive

00:32:41,679 --> 00:32:45,120
but then again if you prefer your if you

00:32:44,080 --> 00:32:47,760
prefer

00:32:45,120 --> 00:32:49,600
particularly like web frameworks um they

00:32:47,760 --> 00:32:51,760
tend to work far better with docker

00:32:49,600 --> 00:32:54,720
with containerized solutions because you

00:32:51,760 --> 00:32:59,039
can just put them all in one box

00:32:54,720 --> 00:32:59,039
does that um it's a big it's a big topic

00:33:00,000 --> 00:33:05,039
um uh

00:33:03,039 --> 00:33:06,559
yes so i guess tl is pretty heavily tied

00:33:05,039 --> 00:33:07,919
to aws right now what's your take on

00:33:06,559 --> 00:33:11,760
doing something similar for

00:33:07,919 --> 00:33:14,640
gcp um separate inspired by teal i think

00:33:11,760 --> 00:33:15,519
yeah so the teal back end is intended to

00:33:14,640 --> 00:33:19,519
be

00:33:15,519 --> 00:33:21,760
um oh hey um hey rob

00:33:19,519 --> 00:33:22,880
the the teal back end is really intended

00:33:21,760 --> 00:33:25,919
to be um

00:33:22,880 --> 00:33:27,679
completely abstracted so yes the

00:33:25,919 --> 00:33:29,519
the idea is that someone could go and

00:33:27,679 --> 00:33:30,399
write a teal back-end for kubernetes for

00:33:29,519 --> 00:33:32,720
example

00:33:30,399 --> 00:33:34,320
passing data between kubernetes nodes

00:33:32,720 --> 00:33:36,000
that that's not really

00:33:34,320 --> 00:33:38,559
um a particular easy way of doing that

00:33:36,000 --> 00:33:39,600
right now um so yes teal absolutely

00:33:38,559 --> 00:33:42,799
could be implemented

00:33:39,600 --> 00:33:44,480
on um gcp and that's that's like

00:33:42,799 --> 00:33:45,919
that's in the that's in the plans that's

00:33:44,480 --> 00:33:47,039
in the pipeline um

00:33:45,919 --> 00:33:48,640
and if you want to come and help with

00:33:47,039 --> 00:33:53,039
that like that would be great it would

00:33:48,640 --> 00:33:54,880
be a big pr is there a beginner friendly

00:33:53,039 --> 00:33:58,720
book or ask what you'd recommend

00:33:54,880 --> 00:34:02,000
someone new to serverless um

00:33:58,720 --> 00:34:05,519
i think um there's a let me um

00:34:02,000 --> 00:34:06,880
let me post uh well i don't think

00:34:05,519 --> 00:34:09,280
i don't have the link right now there's

00:34:06,880 --> 00:34:12,399
a chap on um there's a chap called

00:34:09,280 --> 00:34:14,560
nader uh dabbit who wrote a uh

00:34:12,399 --> 00:34:16,000
a book called full stack serverless and

00:34:14,560 --> 00:34:17,440
i would go and

00:34:16,000 --> 00:34:19,359
i would recommend going checking that

00:34:17,440 --> 00:34:23,440
out it's it's pretty good

00:34:19,359 --> 00:34:23,440
um his specialty is using aws

00:34:24,560 --> 00:34:28,480
there are lots of very very good

00:34:26,079 --> 00:34:31,520
articles though on the on the web

00:34:28,480 --> 00:34:31,520
there's all kinds of good stuff

00:34:32,480 --> 00:34:35,520
how much time would you say you've saved

00:34:34,480 --> 00:34:38,639
using teal

00:34:35,520 --> 00:34:40,159
um are we counting the are we counting

00:34:38,639 --> 00:34:41,119
the the five or six months to develop

00:34:40,159 --> 00:34:45,679
till

00:34:41,119 --> 00:34:48,639
uh-huh if we don't count that um

00:34:45,679 --> 00:34:50,960
well till kind of started because last

00:34:48,639 --> 00:34:54,159
year i was working on some stuff and

00:34:50,960 --> 00:34:57,599
it i don't know it took like a few weeks

00:34:54,159 --> 00:34:59,760
to set up one of these pipelines um

00:34:57,599 --> 00:35:01,839
from scratch um and it felt like a

00:34:59,760 --> 00:35:04,160
massive chore and it felt really

00:35:01,839 --> 00:35:07,760
awkward so that was a few weeks i could

00:35:04,160 --> 00:35:09,200
do the same thing now in in like an hour

00:35:07,760 --> 00:35:10,800
so i think it's it's that order of

00:35:09,200 --> 00:35:14,000
magnitude um

00:35:10,800 --> 00:35:14,000
days days to hours

00:35:14,560 --> 00:35:17,839
now if you're starting from a place

00:35:16,560 --> 00:35:19,280
where you've already got

00:35:17,839 --> 00:35:20,320
your own framework set up and you've

00:35:19,280 --> 00:35:22,320
already built your own way of doing

00:35:20,320 --> 00:35:23,839
things that difference will be less

00:35:22,320 --> 00:35:25,680
but especially if you're starting from

00:35:23,839 --> 00:35:26,079
scratch you're going to save you're

00:35:25,680 --> 00:35:28,800
going to

00:35:26,079 --> 00:35:29,520
save tons of time because you don't have

00:35:28,800 --> 00:35:32,160
to learn about

00:35:29,520 --> 00:35:33,760
aws you don't have to implement tons of

00:35:32,160 --> 00:35:37,200
infrastructure as code

00:35:33,760 --> 00:35:37,200
um yeah

00:35:38,160 --> 00:35:41,760
weeks to days to hours

00:35:42,320 --> 00:35:45,680
have i missed some questions this is so

00:35:44,720 --> 00:35:47,040
strange i'm like

00:35:45,680 --> 00:35:51,119
i feel like i'm talking to myself and

00:35:47,040 --> 00:35:51,119
i'm just scrolling through a chat

00:35:51,520 --> 00:35:54,880
have i missed questions why did i start

00:35:54,240 --> 00:35:57,040
to

00:35:54,880 --> 00:35:58,160
why did i decide to start developing

00:35:57,040 --> 00:36:01,040
teal

00:35:58,160 --> 00:36:02,079
um yeah great great question and that

00:36:01,040 --> 00:36:04,320
sort of ties into

00:36:02,079 --> 00:36:05,440
the previous point um i think i think

00:36:04,320 --> 00:36:09,119
there are these trends

00:36:05,440 --> 00:36:10,240
in in in technology where

00:36:09,119 --> 00:36:12,480
and you can see this in several

00:36:10,240 --> 00:36:14,000
industries um where

00:36:12,480 --> 00:36:15,920
we start with like really specific

00:36:14,000 --> 00:36:18,720
hardware and

00:36:15,920 --> 00:36:19,599
and as we as we build more stuff on that

00:36:18,720 --> 00:36:21,920
hardware

00:36:19,599 --> 00:36:22,880
we we start developing software to make

00:36:21,920 --> 00:36:24,880
it easier

00:36:22,880 --> 00:36:26,880
uh you can see this with computers right

00:36:24,880 --> 00:36:29,119
we used like i said we used to

00:36:26,880 --> 00:36:30,079
build specific hardware for specific

00:36:29,119 --> 00:36:33,280
problems

00:36:30,079 --> 00:36:36,320
and then we we we moved towards

00:36:33,280 --> 00:36:37,520
general purpose cpus and now we now we

00:36:36,320 --> 00:36:39,359
just write software

00:36:37,520 --> 00:36:40,960
um and we saw this with graphics cards

00:36:39,359 --> 00:36:42,160
as well we used to have very very

00:36:40,960 --> 00:36:45,119
specific

00:36:42,160 --> 00:36:46,480
um graphics cards for specific tasks and

00:36:45,119 --> 00:36:48,960
now we have gpus

00:36:46,480 --> 00:36:49,839
with a software layer that sits on top

00:36:48,960 --> 00:36:52,240
um and i

00:36:49,839 --> 00:36:54,320
so when you see that that kind of trend

00:36:52,240 --> 00:36:56,400
um and as a software engineer

00:36:54,320 --> 00:36:58,320
general purpose is always better right

00:36:56,400 --> 00:36:59,280
um and i guess one of the reasons

00:36:58,320 --> 00:37:01,440
fundamentally is that

00:36:59,280 --> 00:37:02,960
i want to get stuff done faster and i

00:37:01,440 --> 00:37:03,599
don't want to do the boring stuff i

00:37:02,960 --> 00:37:06,480
don't want to

00:37:03,599 --> 00:37:07,680
be building um repeated scaffolding for

00:37:06,480 --> 00:37:09,680
every project

00:37:07,680 --> 00:37:12,320
so there's a couple of those things i

00:37:09,680 --> 00:37:14,640
suppose that went into it

00:37:12,320 --> 00:37:16,960
and and like i said earlier it's i was

00:37:14,640 --> 00:37:20,079
working on a project that

00:37:16,960 --> 00:37:20,079
had immediate relevance

00:37:20,640 --> 00:37:27,680
with the project um daniel yeah i think

00:37:24,000 --> 00:37:29,839
um where am i going next i i really

00:37:27,680 --> 00:37:32,000
so at the moment it's it's like version

00:37:29,839 --> 00:37:35,119
0.4 or something it's not

00:37:32,000 --> 00:37:37,200
complete in a couple of senses

00:37:35,119 --> 00:37:38,640
um and it's certainly not production

00:37:37,200 --> 00:37:40,160
ready in the sense that it needs a lot

00:37:38,640 --> 00:37:41,680
more testing

00:37:40,160 --> 00:37:44,160
i think there's a lot i think we can

00:37:41,680 --> 00:37:45,920
push the boundaries a lot more

00:37:44,160 --> 00:37:47,440
and one of the big things is

00:37:45,920 --> 00:37:49,839
infrastructure so

00:37:47,440 --> 00:37:50,640
where am i going next in the immediate

00:37:49,839 --> 00:37:52,560
future

00:37:50,640 --> 00:37:54,480
um teal needs a couple more things

00:37:52,560 --> 00:37:57,040
things like it needs an import system

00:37:54,480 --> 00:37:58,240
so we can start sharing code um it needs

00:37:57,040 --> 00:38:00,800
proper error handling

00:37:58,240 --> 00:38:03,280
um in a nice programmatic way like think

00:38:00,800 --> 00:38:06,000
exceptions that that sort of thing

00:38:03,280 --> 00:38:06,800
but cross lambda that's kind of unheard

00:38:06,000 --> 00:38:09,839
of right now

00:38:06,800 --> 00:38:11,040
um so there are a couple of immediate

00:38:09,839 --> 00:38:13,760
features that i want

00:38:11,040 --> 00:38:15,040
with teal um so those are those are like

00:38:13,760 --> 00:38:16,880
the immediate focus

00:38:15,040 --> 00:38:18,960
and then um and then it'll be about

00:38:16,880 --> 00:38:20,640
getting to a version 1.0 release

00:38:18,960 --> 00:38:23,200
and to do that it just needs to be

00:38:20,640 --> 00:38:26,079
tested in lots of different use cases

00:38:23,200 --> 00:38:26,960
and um it needs to get exposed to lots

00:38:26,079 --> 00:38:29,680
of different things

00:38:26,960 --> 00:38:30,720
and yes it's open source um thank you

00:38:29,680 --> 00:38:33,839
marlene so

00:38:30,720 --> 00:38:36,079
that's the github repo um it's

00:38:33,839 --> 00:38:37,119
it needs a ton of work that i'm around

00:38:36,079 --> 00:38:39,119
contributing

00:38:37,119 --> 00:38:40,480
um it's i'm quite new to open source and

00:38:39,119 --> 00:38:41,440
i've never maintained an open source

00:38:40,480 --> 00:38:43,920
project before

00:38:41,440 --> 00:38:45,599
so uh if you guys can can help with that

00:38:43,920 --> 00:38:49,119
i'd love it

00:38:45,599 --> 00:38:50,480
uh it's it's named teal is named after a

00:38:49,119 --> 00:38:52,400
color

00:38:50,480 --> 00:38:54,400
um i wanted a color that was like

00:38:52,400 --> 00:38:57,119
vaguely similar to the sky

00:38:54,400 --> 00:39:01,839
and i quite like blue and green so mix

00:38:57,119 --> 00:39:01,839
them both you get teal

00:39:10,880 --> 00:39:12,960

YouTube URL: https://www.youtube.com/watch?v=I8VGfOBzmF4


