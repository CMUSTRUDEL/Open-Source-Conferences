Title: Tania Allard - DevOps for Data Science   automate the boring stuff and.... || PyCon Africa 2020
Publication date: 2020-08-28
Playlist: PyCon Africa 2020
Description: 
	In this talk, I will present the concept of MLOps (kind of DevOps for ML scenarios, also referred to as DataOps or AIOps) and how adopting these practices can improve your team's workflows. You will learn how to automate some tasks within the ML lifecycle: from data transformation to model training, testing and validation, and deployment â€” making your workflows not only more seamless but your entire work more reproducible, reliable, and robust.

You do not need to be a DevOps engineer to benefit from these practices, but you can indeed leverage existing open-source tools and platforms to improve your Data Science workflows.

For completeness, I'll show a live end to end example, integrating MLOps practices for Machine Learning - from data processing to model training, validation and deployment. I will highlight the essential tips and tricks for each of the involved stages. You will leave the talk with practical recommendations and examples to get you started on adopting MLOps practices using the tools you use and love (i.e. GitHub, Tensorflow, Python and Docker).
Captions: 
	00:00:12,000 --> 00:00:14,480
right

00:00:28,840 --> 00:00:31,840
um

00:00:42,840 --> 00:00:45,840
know

00:00:56,840 --> 00:00:59,840
uh

00:01:10,840 --> 00:01:13,840
um

00:01:24,840 --> 00:01:27,840
is

00:01:38,840 --> 00:01:41,840
um

00:01:50,000 --> 00:01:55,840
what skills we're demanding

00:01:56,479 --> 00:02:05,759
um we're entering like the same phase

00:02:00,799 --> 00:02:05,759
um started

00:02:06,840 --> 00:02:09,840
um

00:02:20,840 --> 00:02:23,840
um

00:02:30,879 --> 00:02:34,840
are much more concerned about stability

00:02:33,599 --> 00:02:37,840
availability

00:02:34,840 --> 00:02:37,840
and

00:02:49,120 --> 00:02:54,239
specially um and whenever i talk about

00:02:52,319 --> 00:02:57,599
it i like going to this

00:02:54,239 --> 00:03:01,760
um definition or

00:02:57,599 --> 00:03:04,800
he says of people processes and products

00:03:01,760 --> 00:03:07,360
to enable continuous delivery of value

00:03:04,800 --> 00:03:08,480
into production and i think value is

00:03:07,360 --> 00:03:11,519
excused

00:03:08,480 --> 00:03:11,519
keyword here

00:03:11,840 --> 00:03:19,040
to be able to develop this in providing

00:03:14,959 --> 00:03:19,040
valuatory customers and software

00:03:30,840 --> 00:03:33,840
um

00:04:11,519 --> 00:04:17,359
um so if we

00:04:14,640 --> 00:04:18,959
have automation and feedback for a

00:04:17,359 --> 00:04:20,479
priority then we ensure

00:04:18,959 --> 00:04:22,400
that there are no real hands-on so that

00:04:20,479 --> 00:04:25,919
they're going to be involved in

00:04:22,400 --> 00:04:27,120
any problems when to provide early

00:04:25,919 --> 00:04:31,199
testing opportunities

00:04:27,120 --> 00:04:35,759
to all of our team members

00:04:31,199 --> 00:04:38,880
um so when we apply these principles to

00:04:35,759 --> 00:04:42,240
software engineering and this is how

00:04:38,880 --> 00:04:44,560
normal moves and when do develop well

00:04:42,240 --> 00:04:45,600
you're involved in code or you push info

00:04:44,560 --> 00:04:47,600
changes to

00:04:45,600 --> 00:04:49,280
whatever your reversion control system

00:04:47,600 --> 00:04:51,280
is going to be

00:04:49,280 --> 00:04:52,479
good or memorial and you can then be

00:04:51,280 --> 00:04:56,639
using homework

00:04:52,479 --> 00:05:00,080
or whatever um those changes

00:04:56,639 --> 00:05:02,560
uh link directly to your automated build

00:05:00,080 --> 00:05:03,360
and the deploy or whatever but you are

00:05:02,560 --> 00:05:06,080
allowed or

00:05:03,360 --> 00:05:06,639
you are unable to get immediate feedback

00:05:06,080 --> 00:05:08,720
so

00:05:06,639 --> 00:05:10,720
normally in more informational software

00:05:08,720 --> 00:05:12,960
engineering you'll have during small

00:05:10,720 --> 00:05:15,840
testing test regression tests

00:05:12,960 --> 00:05:17,600
and you can see easily which tests are

00:05:15,840 --> 00:05:20,639
passing and which ones are

00:05:17,600 --> 00:05:21,840
failing and then you can carry on

00:05:20,639 --> 00:05:24,880
interacting

00:05:21,840 --> 00:05:27,440
uh depending on which tests are

00:05:24,880 --> 00:05:28,400
passing or failing so you have little

00:05:27,440 --> 00:05:31,680
amount of time

00:05:28,400 --> 00:05:34,960
between uh developing and testing and

00:05:31,680 --> 00:05:34,960
probably releasing

00:05:35,800 --> 00:05:38,960
what it

00:05:41,120 --> 00:05:45,520
a lot of additional technical

00:05:42,880 --> 00:05:48,000
considerations that we didn't have with

00:05:45,520 --> 00:05:48,639
a traditional software hearing when it

00:05:48,000 --> 00:05:50,720
comes to

00:05:48,639 --> 00:05:52,720
machine learning we have a higher

00:05:50,720 --> 00:05:55,759
reliance on the metrics

00:05:52,720 --> 00:05:57,840
so uh done traditional psychology

00:05:55,759 --> 00:05:59,440
having tested seeing what tests has and

00:05:57,840 --> 00:06:01,360
what has done

00:05:59,440 --> 00:06:03,520
um it's not enough because sometimes we

00:06:01,360 --> 00:06:06,240
need to look at things like accuracy

00:06:03,520 --> 00:06:06,240
specifically

00:06:06,560 --> 00:06:11,759
and we are also very very guided by data

00:06:09,919 --> 00:06:12,880
visualization sometimes we need to

00:06:11,759 --> 00:06:16,240
create

00:06:12,880 --> 00:06:20,240
or um truth

00:06:16,240 --> 00:06:23,360
tables so and for us to make sense of

00:06:20,240 --> 00:06:26,479
the metrics the database and the model

00:06:23,360 --> 00:06:27,039
outputs uh themselves we also need to

00:06:26,479 --> 00:06:29,680
have

00:06:27,039 --> 00:06:30,240
a certain knowledge we have to we need

00:06:29,680 --> 00:06:33,520
to have an

00:06:30,240 --> 00:06:34,960
understanding um of what actually we're

00:06:33,520 --> 00:06:38,240
expecting to happen

00:06:34,960 --> 00:06:42,000
and how our metrics are

00:06:38,240 --> 00:06:45,680
related to um the model that or they

00:06:42,000 --> 00:06:48,560
were evolving but so far as

00:06:45,680 --> 00:06:50,400
uh i focused a lot on machine learning

00:06:48,560 --> 00:06:52,319
code i said we developed article we

00:06:50,400 --> 00:06:55,599
developed our model with push

00:06:52,319 --> 00:06:59,680
but actually working in machine learning

00:06:55,599 --> 00:07:03,440
and data science goes way beyond

00:06:59,680 --> 00:07:06,000
just reading and just creating models

00:07:03,440 --> 00:07:06,960
just creating a model so we have to

00:07:06,000 --> 00:07:09,360
think about

00:07:06,960 --> 00:07:10,400
the whole picture which is config a

00:07:09,360 --> 00:07:13,199
configurator

00:07:10,400 --> 00:07:14,639
pipeline collector data database

00:07:13,199 --> 00:07:18,560
verification

00:07:14,639 --> 00:07:22,080
analyze your code monitoring jury

00:07:18,560 --> 00:07:22,080
models or your application

00:07:22,319 --> 00:07:25,759
and because of all of these confounding

00:07:24,800 --> 00:07:28,400
factors

00:07:25,759 --> 00:07:29,039
now we are seeing a very similar trend

00:07:28,400 --> 00:07:32,240
where

00:07:29,039 --> 00:07:33,599
data scientists and artists or machine

00:07:32,240 --> 00:07:37,039
learning engineers

00:07:33,599 --> 00:07:38,960
seem to have again a disposing interest

00:07:37,039 --> 00:07:41,039
or at least opposing goals

00:07:38,960 --> 00:07:42,800
and again the data scientists need to

00:07:41,039 --> 00:07:45,520
move very very fast

00:07:42,800 --> 00:07:46,080
and we have frame rates that are very

00:07:45,520 --> 00:07:48,080
helpful

00:07:46,080 --> 00:07:49,599
and we already know for example

00:07:48,080 --> 00:07:52,000
tensorflow

00:07:49,599 --> 00:07:52,720
or keras or scientific learning or if

00:07:52,000 --> 00:07:57,039
you're using

00:07:52,720 --> 00:07:58,960
our um you really want to carry on use

00:07:57,039 --> 00:08:00,400
all those frameworks instead of having

00:07:58,960 --> 00:08:03,039
to move on to

00:08:00,400 --> 00:08:07,199
an intuitive managed machine learning

00:08:03,039 --> 00:08:07,199
pipeline or machine learning platform

00:08:10,160 --> 00:08:17,120
as a small wave between different stages

00:08:13,759 --> 00:08:20,240
uh of our pipeline whereas

00:08:17,120 --> 00:08:21,280
uh our fellows and machine learning

00:08:20,240 --> 00:08:23,840
engineers

00:08:21,280 --> 00:08:25,280
usually want to reuse the tooling

00:08:23,840 --> 00:08:27,919
platforms because

00:08:25,280 --> 00:08:28,960
uh otherwise it has several completely

00:08:27,919 --> 00:08:30,960
separate tooling

00:08:28,960 --> 00:08:32,000
platforms for engineering machine

00:08:30,960 --> 00:08:34,399
learning

00:08:32,000 --> 00:08:35,519
it becomes very really hard to maintain

00:08:34,399 --> 00:08:38,640
and keep track of

00:08:35,519 --> 00:08:42,000
everything um

00:08:38,640 --> 00:08:44,959
monitoring reliability instability and

00:08:42,000 --> 00:08:46,080
also compliance compliance software data

00:08:44,959 --> 00:08:49,680
and your

00:08:46,080 --> 00:08:49,680
data related applications

00:08:51,440 --> 00:08:59,440
um so we don't need to uh

00:08:56,320 --> 00:09:02,240
sorry or refactoring this continuous

00:08:59,440 --> 00:09:04,240
integration cycle

00:09:02,240 --> 00:09:05,600
we're not on the movement code we're

00:09:04,240 --> 00:09:08,000
also looking at

00:09:05,600 --> 00:09:09,279
how our data is changing are we

00:09:08,000 --> 00:09:11,760
collecting more data

00:09:09,279 --> 00:09:13,040
or are we doing transformations and also

00:09:11,760 --> 00:09:16,640
should be constrained

00:09:13,040 --> 00:09:18,800
about data image um the things that can

00:09:16,640 --> 00:09:21,920
be automated is not

00:09:18,800 --> 00:09:22,800
the fielding only and deploying in tests

00:09:21,920 --> 00:09:24,720
um

00:09:22,800 --> 00:09:27,920
but we can also make parts of our

00:09:24,720 --> 00:09:27,920
pipeline like training

00:09:28,000 --> 00:09:34,720
and our feedback will not come from past

00:09:31,519 --> 00:09:37,920
or um not past

00:09:34,720 --> 00:09:41,680
tests but also it's not metrics

00:09:37,920 --> 00:09:43,200
um and then averaging this part of our

00:09:41,680 --> 00:09:45,360
timelines means that we can

00:09:43,200 --> 00:09:47,519
integrate and improve our model based on

00:09:45,360 --> 00:09:52,480
our outputs our

00:09:47,519 --> 00:09:55,040
outcomes so how do we get started

00:09:52,480 --> 00:09:57,279
during uh very often when i tell people

00:09:55,040 --> 00:09:59,600
about envelopes and automating their

00:09:57,279 --> 00:10:02,640
machine learning pipelines and processes

00:09:59,600 --> 00:10:04,000
a lot of people say i work at microsoft

00:10:02,640 --> 00:10:07,600
for example so i didn't have

00:10:04,000 --> 00:10:10,240
all the 500 software engineers at my

00:10:07,600 --> 00:10:10,240
disposal

00:10:10,640 --> 00:10:15,360
and you don't need to build an entire

00:10:13,120 --> 00:10:17,519
new platform from scratch

00:10:15,360 --> 00:10:19,360
you can recycle the system that you're

00:10:17,519 --> 00:10:23,279
currently using

00:10:19,360 --> 00:10:25,680
um if you're working in

00:10:23,279 --> 00:10:27,279
data scientists and software engineers

00:10:25,680 --> 00:10:30,560
more more than likely you're going to

00:10:27,279 --> 00:10:32,880
already have a version control system

00:10:30,560 --> 00:10:34,399
whether it's get or material and they're

00:10:32,880 --> 00:10:37,680
probably going to be using

00:10:34,399 --> 00:10:38,560
and oh i know that's real development

00:10:37,680 --> 00:10:40,079
platform

00:10:38,560 --> 00:10:41,920
continuous integration and continued

00:10:40,079 --> 00:10:44,560
slavery platform this can be

00:10:41,920 --> 00:10:46,800
github with big lashes in love with big

00:10:44,560 --> 00:10:46,800
love

00:10:46,880 --> 00:10:52,560
travis or any other combination so you

00:10:50,160 --> 00:10:54,399
don't need my going to anything else you

00:10:52,560 --> 00:10:56,560
can leverage what you're currently using

00:10:54,399 --> 00:11:00,320
to collaborate

00:10:56,560 --> 00:11:02,640
um you can leverage also

00:11:00,320 --> 00:11:04,640
in those platforms to that you're

00:11:02,640 --> 00:11:05,600
already using for your deployment and

00:11:04,640 --> 00:11:07,839
for your english

00:11:05,600 --> 00:11:09,120
infrastructure management so you can

00:11:07,839 --> 00:11:12,640
carry on using

00:11:09,120 --> 00:11:16,560
uh travis matches or

00:11:12,640 --> 00:11:20,240
abayer for example or a mink i have

00:11:16,560 --> 00:11:22,800
yes um and you can mix and match

00:11:20,240 --> 00:11:23,680
um one of the nice things of being able

00:11:22,800 --> 00:11:27,200
to leverage

00:11:23,680 --> 00:11:29,519
this ecosystem is that you can keep

00:11:27,200 --> 00:11:30,880
not only your platforms but also the

00:11:29,519 --> 00:11:33,120
frameworks that you

00:11:30,880 --> 00:11:34,000
and your data scientists are familiar

00:11:33,120 --> 00:11:37,440
with

00:11:34,000 --> 00:11:38,800
and if needed you can leverage also

00:11:37,440 --> 00:11:41,519
quality

00:11:38,800 --> 00:11:42,640
and there are a lot of things that you

00:11:41,519 --> 00:11:45,040
can actually do

00:11:42,640 --> 00:11:46,880
from for example github actions and i'm

00:11:45,040 --> 00:11:49,279
going to provide some examples with this

00:11:46,880 --> 00:11:50,560
where you can actually instantiate a

00:11:49,279 --> 00:11:54,079
virtual machine

00:11:50,560 --> 00:11:54,959
um with gpus enable and do your training

00:11:54,079 --> 00:11:58,639
there

00:11:54,959 --> 00:12:02,560
without you having to manually do

00:11:58,639 --> 00:12:06,560
all of this so how do we actually

00:12:02,560 --> 00:12:09,120
how do we start we already have um

00:12:06,560 --> 00:12:11,120
these two people in our team for example

00:12:09,120 --> 00:12:13,839
the data scientists and every year

00:12:11,120 --> 00:12:16,959
machine learning engineers

00:12:13,839 --> 00:12:18,240
and machines machine learning or data

00:12:16,959 --> 00:12:20,880
scientists phones

00:12:18,240 --> 00:12:21,519
will have their own environment we're

00:12:20,880 --> 00:12:23,120
developing

00:12:21,519 --> 00:12:26,639
integrating during research and

00:12:23,120 --> 00:12:29,279
development and optimizing their models

00:12:26,639 --> 00:12:31,279
and their sre or machine learning

00:12:29,279 --> 00:12:34,720
engineers will have their own

00:12:31,279 --> 00:12:38,160
as well but what we share um

00:12:34,720 --> 00:12:40,959
or what you will share basically is

00:12:38,160 --> 00:12:44,240
this software development platform i'm

00:12:40,959 --> 00:12:48,000
using it home as an example

00:12:44,240 --> 00:12:50,560
and probably you want to

00:12:48,000 --> 00:12:51,680
use the distributed phone or something

00:12:50,560 --> 00:12:54,079
else to

00:12:51,680 --> 00:12:55,440
do the same thing and the serving or the

00:12:54,079 --> 00:12:57,680
production

00:12:55,440 --> 00:13:00,160
deployment of your products whatever

00:12:57,680 --> 00:13:01,040
that is it can also be a local soft if

00:13:00,160 --> 00:13:04,079
you're working

00:13:01,040 --> 00:13:07,839
on more research stuff and you're using

00:13:04,079 --> 00:13:07,839
your local servers

00:13:08,639 --> 00:13:14,880
um and then we also have

00:13:12,160 --> 00:13:15,200
the data rail we have the area where

00:13:14,880 --> 00:13:18,240
we're

00:13:15,200 --> 00:13:19,519
much more concerned of data and but it

00:13:18,240 --> 00:13:21,440
doesn't work a bit more

00:13:19,519 --> 00:13:23,839
towards data scientists and data

00:13:21,440 --> 00:13:27,600
engineers

00:13:23,839 --> 00:13:30,079
so to get started with envelopes as a

00:13:27,600 --> 00:13:32,079
traditional cycle the data scientists

00:13:30,079 --> 00:13:35,519
will be working under a code it could be

00:13:32,079 --> 00:13:38,240
a model

00:13:35,519 --> 00:13:41,440
and they check in their code into person

00:13:38,240 --> 00:13:44,079
control let's say github

00:13:41,440 --> 00:13:44,959
um so because we're talking about data

00:13:44,079 --> 00:13:47,760
science

00:13:44,959 --> 00:13:48,079
uh you're not normally only checking in

00:13:47,760 --> 00:13:50,560
your

00:13:48,079 --> 00:13:52,560
power but also your data and something

00:13:50,560 --> 00:13:55,680
that i really really

00:13:52,560 --> 00:14:00,320
face is dvd because it allows me

00:13:55,680 --> 00:14:02,720
not only to keep track of my code

00:14:00,320 --> 00:14:03,360
in conjunction with github but i can

00:14:02,720 --> 00:14:06,480
leverage

00:14:03,360 --> 00:14:07,519
the same heat flow and the same workflow

00:14:06,480 --> 00:14:10,959
that i've been using

00:14:07,519 --> 00:14:14,480
total key track of my hybrid parameters

00:14:10,959 --> 00:14:17,600
my model versions additional parameters

00:14:14,480 --> 00:14:17,920
and data versions um especially if these

00:14:17,600 --> 00:14:22,720
are

00:14:17,920 --> 00:14:24,800
coupled with cloud um

00:14:22,720 --> 00:14:27,279
cloud solutions to store my data for

00:14:24,800 --> 00:14:28,320
example if you're using aws or azure or

00:14:27,279 --> 00:14:31,040
gcp

00:14:28,320 --> 00:14:32,880
and it can integrate very very nicely so

00:14:31,040 --> 00:14:35,120
this is what

00:14:32,880 --> 00:14:37,680
data scientists will normally have in

00:14:35,120 --> 00:14:40,079
version control

00:14:37,680 --> 00:14:42,880
if there are changes once those changes

00:14:40,079 --> 00:14:46,079
are actually made and pushed into

00:14:42,880 --> 00:14:48,560
um my version file system it will

00:14:46,079 --> 00:14:50,240
immediately take off this ici racing

00:14:48,560 --> 00:14:52,399
pipeline and this is going to be

00:14:50,240 --> 00:14:53,839
fundamentally different from the

00:14:52,399 --> 00:14:59,440
pipelines that

00:14:53,839 --> 00:15:02,079
engineers or isrts use

00:14:59,440 --> 00:15:03,600
because i'm using github as an example

00:15:02,079 --> 00:15:05,279
i'm going to be referring to the

00:15:03,600 --> 00:15:08,800
interactions which is

00:15:05,279 --> 00:15:10,160
the platform that now they have for cicd

00:15:08,800 --> 00:15:12,160
and automation

00:15:10,160 --> 00:15:13,760
and one of the advantages is that you

00:15:12,160 --> 00:15:16,560
get uh already

00:15:13,760 --> 00:15:17,120
compute so you're using an assuring

00:15:16,560 --> 00:15:19,360
compute

00:15:17,120 --> 00:15:21,519
on the background and it actually gives

00:15:19,360 --> 00:15:22,639
you quite a good amount of it so you can

00:15:21,519 --> 00:15:26,720
start doing

00:15:22,639 --> 00:15:30,320
a lot of interesting things and but also

00:15:26,720 --> 00:15:34,000
and it's this this is an example um

00:15:30,320 --> 00:15:37,680
that i've done using you probably

00:15:34,000 --> 00:15:40,720
want to use gpus for your training

00:15:37,680 --> 00:15:41,360
uh a good thing is that he arrives done

00:15:40,720 --> 00:15:43,600
in the past

00:15:41,360 --> 00:15:45,279
spin up my virtual machines with gpus so

00:15:43,600 --> 00:15:46,959
i can keep up the training

00:15:45,279 --> 00:15:49,440
and then they commission that virtual

00:15:46,959 --> 00:15:49,440
machine

00:15:51,120 --> 00:15:55,199
but again as i said before the

00:15:53,199 --> 00:15:56,399
cincinnati for machine learning is not

00:15:55,199 --> 00:15:59,519
necessarily

00:15:56,399 --> 00:16:02,480
performed just the tests and and build a

00:15:59,519 --> 00:16:04,639
package or a product but we can also do

00:16:02,480 --> 00:16:06,839
a training run on whatever data or

00:16:04,639 --> 00:16:08,800
whatever consists data that i've already

00:16:06,839 --> 00:16:11,120
collected

00:16:08,800 --> 00:16:12,240
um so this is an example on how you

00:16:11,120 --> 00:16:15,600
would for example

00:16:12,240 --> 00:16:19,839
use it questions to do that um

00:16:15,600 --> 00:16:22,320
i normally use even latest but it makes

00:16:19,839 --> 00:16:22,880
to check out the repository instead of

00:16:22,320 --> 00:16:25,600
whatever

00:16:22,880 --> 00:16:26,880
python version you're using if you need

00:16:25,600 --> 00:16:29,920
to make sure

00:16:26,880 --> 00:16:31,839
um that during framework or your library

00:16:29,920 --> 00:16:34,160
and your model

00:16:31,839 --> 00:16:36,240
continues across different python

00:16:34,160 --> 00:16:38,480
versions you can do that

00:16:36,240 --> 00:16:39,279
um but also if you're focusing on the

00:16:38,480 --> 00:16:42,240
training

00:16:39,279 --> 00:16:42,959
only you can do and you can execute your

00:16:42,240 --> 00:16:45,839
training

00:16:42,959 --> 00:16:48,000
on your compute um very depending by

00:16:45,839 --> 00:16:50,959
default github actions only

00:16:48,000 --> 00:16:51,279
give you cpus that you can use um but

00:16:50,959 --> 00:16:54,639
it's

00:16:51,279 --> 00:16:57,759
a very different workarounds

00:16:54,639 --> 00:17:01,320
and once this is completed uh you will

00:16:57,759 --> 00:17:05,199
get a set of logs with the

00:17:01,320 --> 00:17:05,199
information um

00:17:11,439 --> 00:17:17,039
pipeline and how long it took to

00:17:14,160 --> 00:17:17,039
actually process

00:17:17,199 --> 00:17:20,880
but what happens if after you've done

00:17:19,679 --> 00:17:22,720
your training

00:17:20,880 --> 00:17:24,880
you're probably need to update your

00:17:22,720 --> 00:17:27,280
parameters or you need to

00:17:24,880 --> 00:17:28,240
um have a baseline model to compare

00:17:27,280 --> 00:17:31,280
against

00:17:28,240 --> 00:17:34,000
well there is no problem because if you

00:17:31,280 --> 00:17:35,919
you can separately also have uh for

00:17:34,000 --> 00:17:38,480
example a jumbo file with the

00:17:35,919 --> 00:17:39,280
motors that you're passing um in this

00:17:38,480 --> 00:17:43,039
case

00:17:39,280 --> 00:17:46,480
these are parameters for a vgj 19

00:17:43,039 --> 00:17:49,600
um style transfer

00:17:46,480 --> 00:17:51,840
model one paris and tensorflow so i can

00:17:49,600 --> 00:17:54,640
easily

00:17:51,840 --> 00:17:55,280
update uh the jumbo file where i'm

00:17:54,640 --> 00:17:59,039
passing

00:17:55,280 --> 00:18:02,080
those uh parameters

00:17:59,039 --> 00:18:05,200
and good information um

00:18:02,080 --> 00:18:07,039
actually dvc is working on a product

00:18:05,200 --> 00:18:09,200
called continuous machine learning

00:18:07,039 --> 00:18:10,880
which allows you to combine github

00:18:09,200 --> 00:18:13,679
actions with

00:18:10,880 --> 00:18:15,679
um the ability to add reports and

00:18:13,679 --> 00:18:19,120
metrics to your call requests

00:18:15,679 --> 00:18:21,120
so you can actually see uh the change

00:18:19,120 --> 00:18:23,520
not only injury code

00:18:21,120 --> 00:18:24,320
um but as you're doing your training you

00:18:23,520 --> 00:18:27,200
can see

00:18:24,320 --> 00:18:28,720
the the deltas or the lambdas between

00:18:27,200 --> 00:18:31,280
your and

00:18:28,720 --> 00:18:33,200
your metrics as well get information on

00:18:31,280 --> 00:18:35,280
the gpo computer that you're using or

00:18:33,200 --> 00:18:38,640
cpu completed or using

00:18:35,280 --> 00:18:41,039
and also keep track of the different uh

00:18:38,640 --> 00:18:42,960
training parameters that you have been

00:18:41,039 --> 00:18:46,559
testing

00:18:42,960 --> 00:18:48,480
you can also imagine having uh

00:18:46,559 --> 00:18:49,600
automated if you're creating a pull

00:18:48,480 --> 00:18:52,080
request

00:18:49,600 --> 00:18:53,440
probably seeing how their accuracy or

00:18:52,080 --> 00:18:56,799
any other metrics

00:18:53,440 --> 00:18:59,600
are improving or getting worse

00:18:56,799 --> 00:19:01,039
as you are tuning your parameters so

00:18:59,600 --> 00:19:04,640
this is very very helpful

00:19:01,039 --> 00:19:07,679
because um you have this

00:19:04,640 --> 00:19:09,440
published get workflow or git flow and

00:19:07,679 --> 00:19:12,640
you're adding an additional layer

00:19:09,440 --> 00:19:16,080
for machine learning on top of it

00:19:12,640 --> 00:19:18,960
and this allows to make a seamless

00:19:16,080 --> 00:19:19,440
handoff directly to your sres or machine

00:19:18,960 --> 00:19:22,720
learning

00:19:19,440 --> 00:19:25,120
engineers is there once

00:19:22,720 --> 00:19:27,760
you've done the optimization you've made

00:19:25,120 --> 00:19:31,200
sure that everything is working

00:19:27,760 --> 00:19:32,320
um you're leveraging the same platform

00:19:31,200 --> 00:19:36,080
that you both

00:19:32,320 --> 00:19:39,520
both teams share actually so the handoff

00:19:36,080 --> 00:19:42,480
is automatic directly to the sre

00:19:39,520 --> 00:19:44,559
where they can trigger the ci and cd

00:19:42,480 --> 00:19:46,960
pipeline one last time to do

00:19:44,559 --> 00:19:48,559
whatever test they need to do make sure

00:19:46,960 --> 00:19:51,360
that everything is compliant

00:19:48,559 --> 00:19:52,720
make sure that monitoring is in place

00:19:51,360 --> 00:19:56,480
and roll out

00:19:52,720 --> 00:19:57,440
seamlessly to the world and this is very

00:19:56,480 --> 00:20:00,080
very exciting

00:19:57,440 --> 00:20:00,480
because that means that you don't have

00:20:00,080 --> 00:20:03,919
to

00:20:00,480 --> 00:20:06,320
change any of the frame ranks or any of

00:20:03,919 --> 00:20:06,960
the platforms that you're already using

00:20:06,320 --> 00:20:10,240
um

00:20:06,960 --> 00:20:13,600
but just these examples that i sh are

00:20:10,240 --> 00:20:13,919
just attending time of what you can do

00:20:13,600 --> 00:20:17,280
with

00:20:13,919 --> 00:20:20,720
envelopes um if you go now to

00:20:17,280 --> 00:20:22,960
the jupiter organization github you're

00:20:20,720 --> 00:20:23,919
gonna see this repo to operate bit of

00:20:22,960 --> 00:20:27,039
action

00:20:23,919 --> 00:20:29,280
or it allows you to if you've been using

00:20:27,039 --> 00:20:30,159
different objects and binder for example

00:20:29,280 --> 00:20:32,240
to share

00:20:30,159 --> 00:20:35,039
your tutorials or your work with

00:20:32,240 --> 00:20:37,360
colleagues or

00:20:35,039 --> 00:20:38,480
you probably know that it building the

00:20:37,360 --> 00:20:40,720
docker image

00:20:38,480 --> 00:20:42,960
it can take a very long time but what

00:20:40,720 --> 00:20:47,200
about if you could actually

00:20:42,960 --> 00:20:50,159
get a link to a binder every time

00:20:47,200 --> 00:20:51,120
you create a pull request or updated a

00:20:50,159 --> 00:20:53,840
pull request

00:20:51,120 --> 00:20:56,080
or you could cache uh the creation of

00:20:53,840 --> 00:20:58,320
the docker image and then optimize

00:20:56,080 --> 00:20:59,919
um the sharing of their machine learning

00:20:58,320 --> 00:21:02,400
solutions

00:20:59,919 --> 00:21:03,679
so this there are this action allows you

00:21:02,400 --> 00:21:07,120
to do this

00:21:03,679 --> 00:21:10,080
um this is an example um

00:21:07,120 --> 00:21:10,400
using for example azure machine learning

00:21:10,080 --> 00:21:12,559
or

00:21:10,400 --> 00:21:15,200
everything all the provisioning of the

00:21:12,559 --> 00:21:18,880
workspace the compute

00:21:15,200 --> 00:21:19,360
deployment printing using the training

00:21:18,880 --> 00:21:21,360
run

00:21:19,360 --> 00:21:23,039
registering model and employee model has

00:21:21,360 --> 00:21:25,600
been automated

00:21:23,039 --> 00:21:28,799
and done through github actions and so

00:21:25,600 --> 00:21:31,520
the only once this is in place don't

00:21:28,799 --> 00:21:32,559
worry about was updating my model or my

00:21:31,520 --> 00:21:35,760
parameters

00:21:32,559 --> 00:21:37,840
and this end-to-end uh scenario was

00:21:35,760 --> 00:21:38,720
built up for me so i didn't have to

00:21:37,840 --> 00:21:41,039
worry

00:21:38,720 --> 00:21:43,039
um the colleagues i was working with

00:21:41,039 --> 00:21:46,320
didn't have to worry about

00:21:43,039 --> 00:21:48,559
having access to my machine learning

00:21:46,320 --> 00:21:49,200
workspace or my resources because they

00:21:48,559 --> 00:21:51,760
could see

00:21:49,200 --> 00:21:53,760
all the logs directly from github

00:21:51,760 --> 00:21:56,880
actions

00:21:53,760 --> 00:21:58,000
and also from hamil hussain from github

00:21:56,880 --> 00:22:00,960
has been working

00:21:58,000 --> 00:22:02,000
a lot on machine learning weapons and

00:22:00,960 --> 00:22:05,440
machine learning

00:22:02,000 --> 00:22:08,880
and operations with

00:22:05,440 --> 00:22:11,760
a different version on uh

00:22:08,880 --> 00:22:14,320
using chat ups or using commands through

00:22:11,760 --> 00:22:17,039
full request comment

00:22:14,320 --> 00:22:18,240
and it allows him to also submit the

00:22:17,039 --> 00:22:21,280
jobs and get

00:22:18,240 --> 00:22:23,919
model revolution results

00:22:21,280 --> 00:22:24,480
interesting because you can mix this

00:22:23,919 --> 00:22:26,799
with

00:22:24,480 --> 00:22:27,840
automation workflows for example to

00:22:26,799 --> 00:22:30,880
auto-label

00:22:27,840 --> 00:22:34,320
issues assigned reviews

00:22:30,880 --> 00:22:37,600
merge requests and it makes the whole

00:22:34,320 --> 00:22:39,039
the whole workflow more seamless so in

00:22:37,600 --> 00:22:42,240
brief

00:22:39,039 --> 00:22:44,240
machine learning ops review data science

00:22:42,240 --> 00:22:47,280
allows you to be more efficient with

00:22:44,240 --> 00:22:50,799
tools you use and love already as well

00:22:47,280 --> 00:22:52,640
as recycling your ecosystem um

00:22:50,799 --> 00:22:55,280
you don't i guess i said you don't need

00:22:52,640 --> 00:22:56,240
to move to a fully managed platform you

00:22:55,280 --> 00:22:58,159
can leverage

00:22:56,240 --> 00:23:00,559
all of the existing platforms and

00:22:58,159 --> 00:23:03,679
drawings that you're already using

00:23:00,559 --> 00:23:07,360
um and find a way to

00:23:03,679 --> 00:23:07,360
create a seamless workflow

00:23:07,440 --> 00:23:13,919
so this is where all these lines are

00:23:10,559 --> 00:23:15,919
going to be um after the talk it should

00:23:13,919 --> 00:23:16,480
they should be up in about 10 minutes or

00:23:15,919 --> 00:23:20,320
so at

00:23:16,480 --> 00:23:23,520
most and if you want to reach out

00:23:20,320 --> 00:23:24,880
at any time um but that this is where

00:23:23,520 --> 00:23:26,960
you can find me

00:23:24,880 --> 00:23:28,240
uh in the coming weeks i'm going to be

00:23:26,960 --> 00:23:30,960
work

00:23:28,240 --> 00:23:31,679
piece of tutorial some blogs on how to

00:23:30,960 --> 00:23:33,760
use

00:23:31,679 --> 00:23:34,840
envelopes with github actions for git

00:23:33,760 --> 00:23:37,919
lab and

00:23:34,840 --> 00:23:40,080
tensorflow and so folks can actually

00:23:37,919 --> 00:23:42,080
get started with different ways and

00:23:40,080 --> 00:23:45,200
deploying virtual machines

00:23:42,080 --> 00:23:47,120
um from from zero to

00:23:45,200 --> 00:23:48,240
something that they can then later use

00:23:47,120 --> 00:23:50,240
and scale

00:23:48,240 --> 00:23:51,600
um i think i have some time for

00:23:50,240 --> 00:23:55,120
questions

00:23:51,600 --> 00:23:56,240
um i apologize for the issue with the

00:23:55,120 --> 00:24:05,840
echo before

00:23:56,240 --> 00:24:05,840
uh butterfly in the end

00:24:09,120 --> 00:24:11,200

YouTube URL: https://www.youtube.com/watch?v=VOf62bDxWTM


