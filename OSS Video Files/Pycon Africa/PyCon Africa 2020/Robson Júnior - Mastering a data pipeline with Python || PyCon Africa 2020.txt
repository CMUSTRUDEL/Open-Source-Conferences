Title: Robson JÃºnior - Mastering a data pipeline with Python || PyCon Africa 2020
Publication date: 2020-08-29
Playlist: PyCon Africa 2020
Description: 
	Building data pipelines are a consolidated task, there are a vast number of tools that automate and help developers to create data pipelines with few clicks on the cloud. It might solve non-complex or well-defined standard problems. This presentation is a demystification of years of experience and painful mistakes using Python as a core to create reliable data pipelines and manage insanely amount of valuable data. Let's cover how each piece fits into this puzzle: data acquisition, ingestion, transformation, storage, workflow management and serving. Also, we'll walk through best practices and possible issues. We'll cover PySpark vs Dask and Pandas, Airflow, and Apache Arrow as a new approach.
Captions: 
	00:00:15,280 --> 00:00:19,279
uh

00:00:16,240 --> 00:00:21,600
good morning good evening good afternoon

00:00:19,279 --> 00:00:22,080
for everybody so you are spread along

00:00:21,600 --> 00:00:25,199
the

00:00:22,080 --> 00:00:25,599
world so it's a great pleasure to talk

00:00:25,199 --> 00:00:30,240
here

00:00:25,599 --> 00:00:32,160
again to economy

00:00:30,240 --> 00:00:33,600
it's a real pleasure for me thank you

00:00:32,160 --> 00:00:36,079
for the organization to

00:00:33,600 --> 00:00:37,520
invite me to make it possible especially

00:00:36,079 --> 00:00:41,760
in this hard times

00:00:37,520 --> 00:00:44,399
by the name of the times um

00:00:41,760 --> 00:00:47,120
i'd like to propose to you all the

00:00:44,399 --> 00:00:50,879
people that are in the shot or

00:00:47,120 --> 00:00:54,079
any other communication channel please

00:00:50,879 --> 00:00:54,800
if you have any questions please stop me

00:00:54,079 --> 00:00:57,280
send

00:00:54,800 --> 00:00:59,680
the message over the chat if i have an

00:00:57,280 --> 00:01:02,480
opportunity i can stop to

00:00:59,680 --> 00:01:02,960
to to talk and answer to you i think

00:01:02,480 --> 00:01:06,720
that's

00:01:02,960 --> 00:01:09,760
better than a q a session in the end of

00:01:06,720 --> 00:01:13,119
the top but it's up to you to

00:01:09,760 --> 00:01:16,479
to decide right but

00:01:13,119 --> 00:01:19,840
thank you so much okay

00:01:16,479 --> 00:01:22,880
my name is rob song uh i'm

00:01:19,840 --> 00:01:23,759
originally from brazil uh i moved it to

00:01:22,880 --> 00:01:27,040
berlin

00:01:23,759 --> 00:01:28,000
five four years ago to work here in

00:01:27,040 --> 00:01:30,079
berlin

00:01:28,000 --> 00:01:31,759
i had some more than 16 years of

00:01:30,079 --> 00:01:35,040
experiencing with a different

00:01:31,759 --> 00:01:35,600
kind of technology but i'm proud to say

00:01:35,040 --> 00:01:38,000
that i

00:01:35,600 --> 00:01:39,520
learned to program it with the python

00:01:38,000 --> 00:01:42,799
the python follow

00:01:39,520 --> 00:01:47,200
all my car here until now so

00:01:42,799 --> 00:01:47,200
python is part of my mica here

00:01:47,439 --> 00:01:54,479
until five years ago more or less i was

00:01:50,720 --> 00:01:56,399
deeply active on the python brazilian

00:01:54,479 --> 00:01:59,600
image and after i moved

00:01:56,399 --> 00:02:03,520
to berlin and then i was a little bit

00:01:59,600 --> 00:02:08,479
more stealth on this but

00:02:03,520 --> 00:02:10,319
if you wanted to reach me any time any

00:02:08,479 --> 00:02:11,920
any question if you want to discuss

00:02:10,319 --> 00:02:15,200
anything so you can drop

00:02:11,920 --> 00:02:18,560
me a message on telegram this cell

00:02:15,200 --> 00:02:22,800
0 ps800 or you can drop

00:02:18,560 --> 00:02:25,280
me a message on twitter or uh github

00:02:22,800 --> 00:02:26,959
actually i'm working for the game hub

00:02:25,280 --> 00:02:29,360
inside microsoft

00:02:26,959 --> 00:02:30,879
and my github is the same in this song

00:02:29,360 --> 00:02:34,480
so feel free to reach me

00:02:30,879 --> 00:02:37,519
out anytime that you want okay

00:02:34,480 --> 00:02:41,200
today my idea with the agenda is not a

00:02:37,519 --> 00:02:45,760
talk about code but talk about

00:02:41,200 --> 00:02:50,400
how python fits in the data engineer the

00:02:45,760 --> 00:02:54,160
roles around the world once that

00:02:50,400 --> 00:02:57,680
state engineer is majority dominated

00:02:54,160 --> 00:03:01,519
by java tools but

00:02:57,680 --> 00:03:01,519
the title has like a

00:03:02,159 --> 00:03:06,879
huge importance in the data engineering

00:03:06,159 --> 00:03:09,599
stuffs

00:03:06,879 --> 00:03:12,080
right uh the first thing that you talk

00:03:09,599 --> 00:03:15,040
about anatomy of a data product

00:03:12,080 --> 00:03:16,239
uh we understand what exactly is a data

00:03:15,040 --> 00:03:18,800
product

00:03:16,239 --> 00:03:20,000
uh and after you do a comparation

00:03:18,800 --> 00:03:22,000
between lambda and capital

00:03:20,000 --> 00:03:25,200
architecturally just to make sure

00:03:22,000 --> 00:03:27,760
that the things is equalized between

00:03:25,200 --> 00:03:28,480
us and then you talk about a data

00:03:27,760 --> 00:03:31,280
pipeline

00:03:28,480 --> 00:03:32,879
quality if you are a data engineer if

00:03:31,280 --> 00:03:34,879
you are trying to

00:03:32,879 --> 00:03:36,000
introduce a new technologies or

00:03:34,879 --> 00:03:39,920
techniques about

00:03:36,000 --> 00:03:41,760
data engineer uh feel free to

00:03:39,920 --> 00:03:43,760
to reach me out as well as send some

00:03:41,760 --> 00:03:46,879
message in the end

00:03:43,760 --> 00:03:48,879
uh the most important question of your

00:03:46,879 --> 00:03:51,599
talk is where the python matters

00:03:48,879 --> 00:03:53,680
because you needed to understand well

00:03:51,599 --> 00:03:55,920
which kind of tools in part if you call

00:03:53,680 --> 00:03:59,599
the libraries and title can be used

00:03:55,920 --> 00:04:02,879
to you create state-of-the-art products

00:03:59,599 --> 00:04:06,080
for data right what's happening here

00:04:02,879 --> 00:04:09,439
so uh a data product

00:04:06,080 --> 00:04:12,080
works like a software is any software

00:04:09,439 --> 00:04:12,959
so you have a basically inputs you have

00:04:12,080 --> 00:04:16,239
a process

00:04:12,959 --> 00:04:18,160
you have results in our case when you

00:04:16,239 --> 00:04:19,919
talk about the data products you are

00:04:18,160 --> 00:04:22,800
talking about how you collect

00:04:19,919 --> 00:04:24,880
the data and to understand how you

00:04:22,800 --> 00:04:28,000
collected the data you needed to

00:04:24,880 --> 00:04:31,120
to to move one step back to understand

00:04:28,000 --> 00:04:32,479
the the main concept of what is legal

00:04:31,120 --> 00:04:34,880
data

00:04:32,479 --> 00:04:36,240
big data basically is the amount of data

00:04:34,880 --> 00:04:39,120
that you collect

00:04:36,240 --> 00:04:40,320
but collected doesn't matter if you can

00:04:39,120 --> 00:04:44,479
cannot extract

00:04:40,320 --> 00:04:47,360
anything from the the data for that

00:04:44,479 --> 00:04:48,479
uh there's a theory of the five these

00:04:47,360 --> 00:04:53,199
five this means

00:04:48,479 --> 00:04:55,199
yes when you decided to have a big data

00:04:53,199 --> 00:04:55,600
and you decided to classify your data as

00:04:55,199 --> 00:04:58,080
a big

00:04:55,600 --> 00:04:58,960
data you need to understand more or less

00:04:58,080 --> 00:05:02,160
what

00:04:58,960 --> 00:05:05,680
what kind what kind of v

00:05:02,160 --> 00:05:09,280
are for example volume volume is the

00:05:05,680 --> 00:05:12,000
amount of data that you are collecting

00:05:09,280 --> 00:05:13,600
but the following doesn't matter because

00:05:12,000 --> 00:05:16,720
you needed to have a variate

00:05:13,600 --> 00:05:20,320
uh variations why because

00:05:16,720 --> 00:05:24,000
you can connect you can collect like uh

00:05:20,320 --> 00:05:27,120
text files images sounds or

00:05:24,000 --> 00:05:28,000
uh unscripted data you have like a

00:05:27,120 --> 00:05:31,120
different

00:05:28,000 --> 00:05:33,520
uh kind of data that you need to collect

00:05:31,120 --> 00:05:35,360
this is part of ingress because once you

00:05:33,520 --> 00:05:39,039
collect it you need to start

00:05:35,360 --> 00:05:39,360
it in another in a storage in general

00:05:39,039 --> 00:05:43,360
this

00:05:39,360 --> 00:05:46,240
storage is called big day data lake

00:05:43,360 --> 00:05:46,720
is like a lake when you have a lot of

00:05:46,240 --> 00:05:49,520
data

00:05:46,720 --> 00:05:50,479
and then you can swim into this data and

00:05:49,520 --> 00:05:55,039
collect

00:05:50,479 --> 00:05:58,080
where exactly what you need right

00:05:55,039 --> 00:06:00,560
when you started to process this data or

00:05:58,080 --> 00:06:01,440
when you started to get insights from

00:06:00,560 --> 00:06:04,319
this data

00:06:01,440 --> 00:06:06,479
you have a second step on this this

00:06:04,319 --> 00:06:09,840
anatomy that is the process

00:06:06,479 --> 00:06:11,759
and the process you have two mainly uh

00:06:09,840 --> 00:06:12,940
characteristics that you need to take

00:06:11,759 --> 00:06:14,560
care one is the very

00:06:12,940 --> 00:06:18,080
[Music]

00:06:14,560 --> 00:06:20,560
very very very assets that means

00:06:18,080 --> 00:06:22,319
which kind of data you are working on

00:06:20,560 --> 00:06:24,560
and the velocity

00:06:22,319 --> 00:06:25,600
does it matter if you have like terms

00:06:24,560 --> 00:06:28,960
and terabytes of

00:06:25,600 --> 00:06:29,680
data if you take two or three months to

00:06:28,960 --> 00:06:32,880
collect to

00:06:29,680 --> 00:06:34,000
to process this data so velocity is very

00:06:32,880 --> 00:06:37,280
very important as

00:06:34,000 --> 00:06:39,199
well right and this happens because

00:06:37,280 --> 00:06:41,680
when you have your data lake you will

00:06:39,199 --> 00:06:45,199
structure supersets from this data lake

00:06:41,680 --> 00:06:46,720
or you you get small chunks of this data

00:06:45,199 --> 00:06:50,080
from the data lake

00:06:46,720 --> 00:06:50,479
brings to the job in data sets and from

00:06:50,080 --> 00:06:54,720
that

00:06:50,479 --> 00:06:57,840
you start to do the magic happens right

00:06:54,720 --> 00:07:00,080
and another in another hand

00:06:57,840 --> 00:07:02,080
when you need it to regress it means you

00:07:00,080 --> 00:07:05,280
need to serve your data to your

00:07:02,080 --> 00:07:08,960
customers this your customers can be

00:07:05,280 --> 00:07:12,479
apis dashboards kpis

00:07:08,960 --> 00:07:15,199
or a simple table in a database

00:07:12,479 --> 00:07:16,960
wherever you need it to contain these

00:07:15,199 --> 00:07:19,680
and you need to trust

00:07:16,960 --> 00:07:20,800
on that this is the most important

00:07:19,680 --> 00:07:23,280
because it doesn't

00:07:20,800 --> 00:07:25,039
doesn't matter if you process you have a

00:07:23,280 --> 00:07:28,160
huge amount of data but

00:07:25,039 --> 00:07:30,800
if you cannot trust this this data

00:07:28,160 --> 00:07:31,840
uh probably you lose a lot of time on

00:07:30,800 --> 00:07:35,120
your

00:07:31,840 --> 00:07:38,639
on your job right

00:07:35,120 --> 00:07:41,599
and as i mentioned before the autonomous

00:07:38,639 --> 00:07:43,199
data product is exactly the same as a

00:07:41,599 --> 00:07:46,240
computer problem

00:07:43,199 --> 00:07:46,800
in the computer program is when you put

00:07:46,240 --> 00:07:49,840
something

00:07:46,800 --> 00:07:52,000
to the to the to to the processor

00:07:49,840 --> 00:07:53,199
so you have files you have windows you

00:07:52,000 --> 00:07:56,080
have in memory

00:07:53,199 --> 00:07:56,960
and then you you have functions and

00:07:56,080 --> 00:08:00,000
variable that

00:07:56,960 --> 00:08:03,120
manipulate these bytes and in the end

00:08:00,000 --> 00:08:05,440
the deliveries like a window an api on a

00:08:03,120 --> 00:08:09,360
result and a console

00:08:05,440 --> 00:08:12,400
if you see it works exactly the same way

00:08:09,360 --> 00:08:14,720
and if you imagine like that if

00:08:12,400 --> 00:08:16,879
a computer programming a data pipeline

00:08:14,720 --> 00:08:20,400
work is exactly the same way in the same

00:08:16,879 --> 00:08:23,680
theory the same theory for the testing

00:08:20,400 --> 00:08:26,000
for the quality assurance or how to

00:08:23,680 --> 00:08:28,400
maintain to refactor your code

00:08:26,000 --> 00:08:29,199
can be applied for this the the both

00:08:28,400 --> 00:08:32,399
scenarios

00:08:29,199 --> 00:08:34,479
right is this is very important when you

00:08:32,399 --> 00:08:36,880
talk about the date in your degener

00:08:34,479 --> 00:08:37,680
uh you have two main concepts you have

00:08:36,880 --> 00:08:40,399
the lambda

00:08:37,680 --> 00:08:42,640
and capita architecture this these

00:08:40,399 --> 00:08:46,000
architectures were developed

00:08:42,640 --> 00:08:49,440
or were described to solve problems

00:08:46,000 --> 00:08:52,240
basically based on velocity

00:08:49,440 --> 00:08:53,040
right because you needed to process a

00:08:52,240 --> 00:08:55,680
huge amount of

00:08:53,040 --> 00:08:56,959
data most part of the time but you have

00:08:55,680 --> 00:08:59,690
a slightly

00:08:56,959 --> 00:09:01,040
difference between

00:08:59,690 --> 00:09:04,560
[Music]

00:09:01,040 --> 00:09:07,600
hope for example have like a

00:09:04,560 --> 00:09:08,000
disaster recovery or if you needed to

00:09:07,600 --> 00:09:09,760
change

00:09:08,000 --> 00:09:11,760
some part of the data because we

00:09:09,760 --> 00:09:15,360
introduced a bug in your code

00:09:11,760 --> 00:09:18,160
and you needed to fix it so uh

00:09:15,360 --> 00:09:19,600
are you explaining both of these these

00:09:18,160 --> 00:09:22,240
architectures are now

00:09:19,600 --> 00:09:22,959
lovely architecture basically is the the

00:09:22,240 --> 00:09:25,120
facto

00:09:22,959 --> 00:09:26,000
uh architecture in the market uh

00:09:25,120 --> 00:09:29,120
nowadays

00:09:26,000 --> 00:09:29,680
right so uh when you started to design

00:09:29,120 --> 00:09:33,760
your

00:09:29,680 --> 00:09:35,519
architecture in in your new project when

00:09:33,760 --> 00:09:37,760
you try to introduce a new data

00:09:35,519 --> 00:09:40,399
techniques in your project

00:09:37,760 --> 00:09:41,440
you have two ways to think in data you

00:09:40,399 --> 00:09:45,120
needed to this

00:09:41,440 --> 00:09:47,920
data being processed in a real time

00:09:45,120 --> 00:09:48,720
or in a batch process batch process

00:09:47,920 --> 00:09:50,959
means

00:09:48,720 --> 00:09:52,399
you can have like a gap of time to

00:09:50,959 --> 00:09:55,760
process this data

00:09:52,399 --> 00:09:58,399
you need to answer this question first

00:09:55,760 --> 00:09:59,279
because you are collecting the data but

00:09:58,399 --> 00:10:03,519
let's imagine

00:09:59,279 --> 00:10:06,800
some scenarios you are working on a bank

00:10:03,519 --> 00:10:08,880
credit card issue for example in a bank

00:10:06,800 --> 00:10:10,240
and then people started to use these

00:10:08,880 --> 00:10:13,839
credit cards

00:10:10,240 --> 00:10:18,160
okay when it happens

00:10:13,839 --> 00:10:20,959
okay uh you needed to determine if uh

00:10:18,160 --> 00:10:21,279
a transaction is a fraud or not it

00:10:20,959 --> 00:10:24,320
should

00:10:21,279 --> 00:10:27,440
happens in real time okay

00:10:24,320 --> 00:10:29,519
it is very important for this

00:10:27,440 --> 00:10:31,120
you need to use speed layer because you

00:10:29,519 --> 00:10:32,880
receive the transaction

00:10:31,120 --> 00:10:34,240
you needed to do calculation in

00:10:32,880 --> 00:10:36,160
milliseconds

00:10:34,240 --> 00:10:38,079
you needed to use some technique in

00:10:36,160 --> 00:10:41,760
milliseconds to say

00:10:38,079 --> 00:10:42,480
this this transaction can be or not a

00:10:41,760 --> 00:10:45,360
fraud

00:10:42,480 --> 00:10:46,800
and then you can deny it or not is the

00:10:45,360 --> 00:10:50,560
first second

00:10:46,800 --> 00:10:53,360
okay the second scenario is the batch

00:10:50,560 --> 00:10:53,839
layer the batch layer basically is when

00:10:53,360 --> 00:10:56,959
you need

00:10:53,839 --> 00:11:00,720
to do aggregations for example

00:10:56,959 --> 00:11:02,880
a month a daily visit users in your

00:11:00,720 --> 00:11:06,560
website in your product

00:11:02,880 --> 00:11:09,519
along with the last 24 hours you collect

00:11:06,560 --> 00:11:12,079
all the data from these users and then

00:11:09,519 --> 00:11:14,720
when these days finishes

00:11:12,079 --> 00:11:17,040
you come in another day and process and

00:11:14,720 --> 00:11:20,480
extract all the metrics from the

00:11:17,040 --> 00:11:22,959
last batch this is the batch layer

00:11:20,480 --> 00:11:24,000
in the end you have views views means

00:11:22,959 --> 00:11:26,720
that you can

00:11:24,000 --> 00:11:28,560
clear your data means that you can see

00:11:26,720 --> 00:11:32,399
the result zr data

00:11:28,560 --> 00:11:35,839
and this goes to certain layer

00:11:32,399 --> 00:11:39,200
this is the mainly it's the main

00:11:35,839 --> 00:11:44,240
difference between uh the both

00:11:39,200 --> 00:11:48,560
layers in the architecture right

00:11:44,240 --> 00:11:51,760
99 of the the the

00:11:48,560 --> 00:11:56,480
the cases they use this kind of battery

00:11:51,760 --> 00:11:59,519
results in a battery layer

00:11:56,480 --> 00:12:02,959
and just if you need something

00:11:59,519 --> 00:12:06,240
really in real time for fraud detection

00:12:02,959 --> 00:12:09,440
or another thing more sensitive

00:12:06,240 --> 00:12:11,360
probably you use bachelor right

00:12:09,440 --> 00:12:12,880
when you use olympic architecture you

00:12:11,360 --> 00:12:16,000
have like some

00:12:12,880 --> 00:12:19,440
pros and cons uh

00:12:16,000 --> 00:12:20,720
one cons is that it's tends to be more

00:12:19,440 --> 00:12:25,120
expensive than

00:12:20,720 --> 00:12:27,120
usually because along the way you are

00:12:25,120 --> 00:12:29,040
collecting data when you started to

00:12:27,120 --> 00:12:29,760
collecting data you needed to start the

00:12:29,040 --> 00:12:32,800
data

00:12:29,760 --> 00:12:35,600
how many uh how much

00:12:32,800 --> 00:12:37,360
data you are starting step by step day

00:12:35,600 --> 00:12:39,760
by day so

00:12:37,360 --> 00:12:41,279
your view increases because you need to

00:12:39,760 --> 00:12:43,200
keep its story there's a lot of

00:12:41,279 --> 00:12:43,839
techniques to reduce this amount of

00:12:43,200 --> 00:12:46,959
money but

00:12:43,839 --> 00:12:50,320
yes this can be a problem because

00:12:46,959 --> 00:12:53,680
uh you have two problems here you have

00:12:50,320 --> 00:12:54,480
one with the previous loss around the

00:12:53,680 --> 00:12:57,120
world

00:12:54,480 --> 00:12:59,200
because sometimes you cannot keep data

00:12:57,120 --> 00:13:02,240
otherwise you can keep data

00:12:59,200 --> 00:13:08,160
right and the cost of to

00:13:02,240 --> 00:13:11,360
to keep this data uh started right

00:13:08,160 --> 00:13:14,880
uh you needed to teach your users

00:13:11,360 --> 00:13:18,320
to query data based in table data it

00:13:14,880 --> 00:13:21,200
means that for example

00:13:18,320 --> 00:13:22,480
each new data that you receive from your

00:13:21,200 --> 00:13:25,680
ingress

00:13:22,480 --> 00:13:28,880
they will never be updated or deleted

00:13:25,680 --> 00:13:30,320
they just be insate inserted let us

00:13:28,880 --> 00:13:32,959
imagine it

00:13:30,320 --> 00:13:34,079
a credit card was issued for you you

00:13:32,959 --> 00:13:37,360
have a line

00:13:34,079 --> 00:13:39,360
in your table okay now robson has a

00:13:37,360 --> 00:13:41,760
credit card

00:13:39,360 --> 00:13:42,800
the next line hobson bought some

00:13:41,760 --> 00:13:46,480
fingerprint

00:13:42,800 --> 00:13:48,000
cards next to line rob some cancel to

00:13:46,480 --> 00:13:51,839
the this

00:13:48,000 --> 00:13:55,279
credit card but you never delete

00:13:51,839 --> 00:13:57,199
the the the data are you just change the

00:13:55,279 --> 00:13:59,360
state of the data

00:13:57,199 --> 00:14:01,760
for that uh the people needed to

00:13:59,360 --> 00:14:02,399
understand how to carry the data because

00:14:01,760 --> 00:14:05,360
it's a

00:14:02,399 --> 00:14:05,360
time series

00:14:07,600 --> 00:14:16,639
way to carry your data and then

00:14:11,440 --> 00:14:20,240
you need to take care about that right

00:14:16,639 --> 00:14:22,480
uh the pros uh the idea of the lamb the

00:14:20,240 --> 00:14:23,279
contour is because they are reliable and

00:14:22,480 --> 00:14:25,519
safe ui

00:14:23,279 --> 00:14:27,600
because if you introduce a bug in your

00:14:25,519 --> 00:14:30,480
pipeline or if you lose

00:14:27,600 --> 00:14:32,160
uh part of your data you can go to your

00:14:30,480 --> 00:14:35,519
data lake again

00:14:32,160 --> 00:14:39,120
not get all that data and rebuild

00:14:35,519 --> 00:14:39,760
your pipeline right it's because they

00:14:39,120 --> 00:14:42,800
are fault

00:14:39,760 --> 00:14:45,199
tolerant because if you lose

00:14:42,800 --> 00:14:46,560
something you can go to your data lake

00:14:45,199 --> 00:14:49,040
and rebuild everything

00:14:46,560 --> 00:14:50,639
from scratch and they are really

00:14:49,040 --> 00:14:52,959
scalable because

00:14:50,639 --> 00:14:56,160
you can put more and more and more and

00:14:52,959 --> 00:14:56,160
more machines on the

00:14:56,880 --> 00:15:00,639
on your cluster and process more and

00:14:59,279 --> 00:15:03,760
more and more data

00:15:00,639 --> 00:15:06,079
as much as you want and

00:15:03,760 --> 00:15:08,639
you have like uh a nice thing that you

00:15:06,079 --> 00:15:11,360
can manage all your historical data

00:15:08,639 --> 00:15:12,639
and that's the booth the fire system

00:15:11,360 --> 00:15:15,279
it's making you

00:15:12,639 --> 00:15:17,279
more reliable and secured right in

00:15:15,279 --> 00:15:18,480
another hand so you have like premature

00:15:17,279 --> 00:15:21,360
remodeling what's

00:15:18,480 --> 00:15:22,399
what means prematurely modeling is when

00:15:21,360 --> 00:15:25,440
you try

00:15:22,399 --> 00:15:27,839
to imagine all the things right

00:15:25,440 --> 00:15:28,800
so you are trying to have like a

00:15:27,839 --> 00:15:33,680
premature

00:15:28,800 --> 00:15:35,920
uh ideas to try to model your data

00:15:33,680 --> 00:15:37,040
and then when you realize that that

00:15:35,920 --> 00:15:39,920
modeling is

00:15:37,040 --> 00:15:41,920
isn't working for you anymore it's hard

00:15:39,920 --> 00:15:45,530
to migrate

00:15:41,920 --> 00:15:47,040
that technique that you learned about

00:15:45,530 --> 00:15:50,240
[Music]

00:15:47,040 --> 00:15:53,360
extreme programming long time ago about

00:15:50,240 --> 00:15:56,639
baby steps work perfectly on here

00:15:53,360 --> 00:15:59,920
model model part of your data

00:15:56,639 --> 00:16:02,079
put in production change modeling change

00:15:59,920 --> 00:16:02,720
modeling and then you don't have problem

00:16:02,079 --> 00:16:06,639
with that

00:16:02,720 --> 00:16:08,000
right as i told it can be expensive to

00:16:06,639 --> 00:16:11,199
do with the

00:16:08,000 --> 00:16:14,240
amount of volume in the the process

00:16:11,199 --> 00:16:17,680
right and separation of

00:16:14,240 --> 00:16:19,759
concerns can be hard as well why

00:16:17,680 --> 00:16:22,000
because sometimes you have like a small

00:16:19,759 --> 00:16:25,199
library inside your job

00:16:22,000 --> 00:16:26,160
and this library is using it for both

00:16:25,199 --> 00:16:27,630
layers

00:16:26,160 --> 00:16:29,920
in the serving and the

00:16:27,630 --> 00:16:33,120
[Music]

00:16:29,920 --> 00:16:34,399
the speedy layer on the bachelor it can

00:16:33,120 --> 00:16:36,079
be problems for you

00:16:34,399 --> 00:16:38,480
it's one thing that you needed to to

00:16:36,079 --> 00:16:41,920
take care of

00:16:38,480 --> 00:16:44,600
perfect what's kappa architecture

00:16:41,920 --> 00:16:46,079
cup architecturally basically is a

00:16:44,600 --> 00:16:47,759
specialization of

00:16:46,079 --> 00:16:51,759
the speedy layer in the olympic

00:16:47,759 --> 00:16:54,800
architecture right

00:16:51,759 --> 00:16:57,600
why kappa is nothing

00:16:54,800 --> 00:16:59,600
a replacement of lambda architecture but

00:16:57,600 --> 00:17:02,480
is an alternative to provide

00:16:59,600 --> 00:17:02,880
performance why because we receive like

00:17:02,480 --> 00:17:06,880
a

00:17:02,880 --> 00:17:08,720
a lot of data and different scenarios

00:17:06,880 --> 00:17:11,760
and then you need to process all these

00:17:08,720 --> 00:17:12,959
scenarios in millisecond milliseconds or

00:17:11,760 --> 00:17:16,000
just in seconds

00:17:12,959 --> 00:17:16,640
right uh it's usually to process the

00:17:16,000 --> 00:17:18,480
stream

00:17:16,640 --> 00:17:20,480
and perform a real-time process

00:17:18,480 --> 00:17:22,480
especially for analytics

00:17:20,480 --> 00:17:23,679
imagine that you are working on

00:17:22,480 --> 00:17:26,880
e-commerce

00:17:23,679 --> 00:17:29,679
and you release it like a b test

00:17:26,880 --> 00:17:30,080
and then you want you to see in a real

00:17:29,679 --> 00:17:33,679
time

00:17:30,080 --> 00:17:36,720
how these a tests working for example

00:17:33,679 --> 00:17:40,559
right this is a perfect scenario for

00:17:36,720 --> 00:17:42,160
top architecture right but there's

00:17:40,559 --> 00:17:43,760
one thing that i love in encounter

00:17:42,160 --> 00:17:45,919
architecture that's

00:17:43,760 --> 00:17:47,200
it's permitting you to deliver new

00:17:45,919 --> 00:17:50,400
features code

00:17:47,200 --> 00:17:52,720
chains fixing bugs without

00:17:50,400 --> 00:17:53,440
any problems you just needed to deploy

00:17:52,720 --> 00:17:57,440
your code

00:17:53,440 --> 00:18:00,640
and everything you started to uh

00:17:57,440 --> 00:18:05,039
to run automatically no no

00:18:00,640 --> 00:18:09,440
no no you will probably want to break

00:18:05,039 --> 00:18:12,160
the the last the the less the code right

00:18:09,440 --> 00:18:12,960
okay in the along with the cupped

00:18:12,160 --> 00:18:16,640
architecture

00:18:12,960 --> 00:18:19,840
so we always have like a well-defined

00:18:16,640 --> 00:18:20,960
event order why remember that i

00:18:19,840 --> 00:18:23,440
explained it so

00:18:20,960 --> 00:18:24,720
if the event comes with a time stamp

00:18:23,440 --> 00:18:26,880
with a date

00:18:24,720 --> 00:18:28,720
it will never change the data is in the

00:18:26,880 --> 00:18:31,120
table right so

00:18:28,720 --> 00:18:33,120
when you go to interact with your data

00:18:31,120 --> 00:18:33,679
set if your data lake you need to keep

00:18:33,120 --> 00:18:36,160
in mind

00:18:33,679 --> 00:18:37,440
that you started to work basically in a

00:18:36,160 --> 00:18:40,480
time series

00:18:37,440 --> 00:18:43,200
okay this kind of

00:18:40,480 --> 00:18:44,480
character is well used for as they told

00:18:43,200 --> 00:18:47,600
for ads platform

00:18:44,480 --> 00:18:50,400
fraud detection socio networks

00:18:47,600 --> 00:18:52,000
and people who described this

00:18:50,400 --> 00:18:54,640
architecturally try to solve the

00:18:52,000 --> 00:18:56,799
problems of the code chains

00:18:54,640 --> 00:18:58,320
because if you need to deploy a new code

00:18:56,799 --> 00:19:03,280
change you need to stop

00:18:58,320 --> 00:19:03,280
your pipeline deploy your code

00:19:03,520 --> 00:19:07,760
line again and make sure that nothing

00:19:06,799 --> 00:19:09,919
happens

00:19:07,760 --> 00:19:12,480
the cup architecture you just deploy the

00:19:09,919 --> 00:19:16,000
code and

00:19:12,480 --> 00:19:19,200
without stop right but

00:19:16,000 --> 00:19:20,960
for uh pros you have

00:19:19,200 --> 00:19:23,120
something like that that's very

00:19:20,960 --> 00:19:26,480
important that the

00:19:23,120 --> 00:19:28,240
laby architecture use less resources

00:19:26,480 --> 00:19:31,200
than

00:19:28,240 --> 00:19:32,480
cap architecture use less resources than

00:19:31,200 --> 00:19:36,320
limited architecture

00:19:32,480 --> 00:19:36,880
right and permits you to train your

00:19:36,320 --> 00:19:40,480
machine

00:19:36,880 --> 00:19:43,200
learn in real time basis because

00:19:40,480 --> 00:19:44,720
you always have data coming to you and

00:19:43,200 --> 00:19:48,400
then you can train your

00:19:44,720 --> 00:19:50,000
machine learning models another thing

00:19:48,400 --> 00:19:51,600
that is nice about the capital

00:19:50,000 --> 00:19:55,280
architecture that instead

00:19:51,600 --> 00:19:55,280
you scale

00:19:56,000 --> 00:20:02,559
verticality you can you can

00:19:59,520 --> 00:20:04,159
scale or result horizontally it means

00:20:02,559 --> 00:20:05,280
that instead you put more and more

00:20:04,159 --> 00:20:08,159
machines you can just

00:20:05,280 --> 00:20:08,799
have like a big machine that you solve

00:20:08,159 --> 00:20:12,640
your

00:20:08,799 --> 00:20:14,480
problem right uh

00:20:12,640 --> 00:20:15,760
another hand you need to have a more

00:20:14,480 --> 00:20:19,840
techniques

00:20:15,760 --> 00:20:23,200
to handle your exceptions in your code

00:20:19,840 --> 00:20:25,360
instrumentor code handle exceptions log

00:20:23,200 --> 00:20:26,559
everything this is mandatory for this

00:20:25,360 --> 00:20:31,520
kind of architecture

00:20:26,559 --> 00:20:34,320
right and if you have some

00:20:31,520 --> 00:20:36,559
severity bug you might just stop your

00:20:34,320 --> 00:20:39,520
pipeline and then you need to fix

00:20:36,559 --> 00:20:40,080
it and then you need it to run one thing

00:20:39,520 --> 00:20:42,559
it's called

00:20:40,080 --> 00:20:43,440
backfield right but it's important

00:20:42,559 --> 00:20:47,360
that's

00:20:43,440 --> 00:20:47,360
10 of the time okay

00:20:47,679 --> 00:20:52,159
okay now you talk about the qualities of

00:20:50,480 --> 00:20:55,280
the pipeline so

00:20:52,159 --> 00:20:55,679
i for me just a small tip is that i

00:20:55,280 --> 00:20:59,840
learned

00:20:55,679 --> 00:21:02,080
in six years uh i bought my car here so

00:20:59,840 --> 00:21:03,679
i started to work as a software engineer

00:21:02,080 --> 00:21:06,400
and once

00:21:03,679 --> 00:21:08,559
one day my manager told them so you have

00:21:06,400 --> 00:21:10,720
a project about the data so learn

00:21:08,559 --> 00:21:13,039
it and start to do and then i transition

00:21:10,720 --> 00:21:15,600
like here to date engineer and i love

00:21:13,039 --> 00:21:16,720
it so it's because i'm here to to share

00:21:15,600 --> 00:21:20,000
with you

00:21:16,720 --> 00:21:21,919
right we will talk about uh quality

00:21:20,000 --> 00:21:25,440
papillion everything that i learned

00:21:21,919 --> 00:21:29,039
about the quality of data pipeline right

00:21:25,440 --> 00:21:31,440
uh the first thing that i learned

00:21:29,039 --> 00:21:33,200
it's about security security is

00:21:31,440 --> 00:21:36,159
mandatory because

00:21:33,200 --> 00:21:36,720
you have different levels uh you have

00:21:36,159 --> 00:21:39,679
different

00:21:36,720 --> 00:21:40,480
levels to access your data you have your

00:21:39,679 --> 00:21:42,559
data link

00:21:40,480 --> 00:21:43,840
you have soviet data sets you have

00:21:42,559 --> 00:21:47,360
tables ready for

00:21:43,840 --> 00:21:50,320
users and you need to define

00:21:47,360 --> 00:21:51,120
for each kind of user each kind of a

00:21:50,320 --> 00:21:53,200
person

00:21:51,120 --> 00:21:54,720
who can access your data this is the

00:21:53,200 --> 00:21:58,080
first step

00:21:54,720 --> 00:22:00,320
how you define it access level

00:21:58,080 --> 00:22:01,360
for all the data levels this is the very

00:22:00,320 --> 00:22:04,559
important

00:22:01,360 --> 00:22:08,400
because previous it matters always

00:22:04,559 --> 00:22:11,360
previous matters okay and

00:22:08,400 --> 00:22:13,039
another thing about securities try to

00:22:11,360 --> 00:22:16,720
use a common format

00:22:13,039 --> 00:22:20,240
common format means a format

00:22:16,720 --> 00:22:22,880
a data format that you can

00:22:20,240 --> 00:22:23,840
interrupt with different technologies if

00:22:22,880 --> 00:22:27,200
you want

00:22:23,840 --> 00:22:29,280
and then uh a common firm

00:22:27,200 --> 00:22:32,320
that you can trust i can give you some

00:22:29,280 --> 00:22:33,919
examples like a perky file json files

00:22:32,320 --> 00:22:36,960
apple files

00:22:33,919 --> 00:22:40,159
or another serialization format

00:22:36,960 --> 00:22:43,120
that reduces the the size

00:22:40,159 --> 00:22:44,559
security means separation of concerns as

00:22:43,120 --> 00:22:47,440
well

00:22:44,559 --> 00:22:49,280
who can change the code who can change

00:22:47,440 --> 00:22:53,200
part of the code

00:22:49,280 --> 00:22:57,520
because it's uh it's direct directly

00:22:53,200 --> 00:23:00,720
it with the the access level as well

00:22:57,520 --> 00:23:04,000
right and how you separate

00:23:00,720 --> 00:23:07,280
the separation of concerns for

00:23:04,000 --> 00:23:09,440
this part of quotes behaves to my

00:23:07,280 --> 00:23:12,480
business logic and this part of code

00:23:09,440 --> 00:23:15,360
behaves to like a macro library

00:23:12,480 --> 00:23:17,120
and then you can avoid hard decoding

00:23:15,360 --> 00:23:20,240
duplication

00:23:17,120 --> 00:23:23,600
in the data engineering pipeline is

00:23:20,240 --> 00:23:26,720
quite hard to to reach age you need

00:23:23,600 --> 00:23:29,360
to read effect during talk

00:23:26,720 --> 00:23:31,120
i spend more time with factoring and

00:23:29,360 --> 00:23:34,159
discussing my pure requests with

00:23:31,120 --> 00:23:36,880
my friends than

00:23:34,159 --> 00:23:38,159
than coding for example this just to

00:23:36,880 --> 00:23:40,880
understand but

00:23:38,159 --> 00:23:41,440
the focus is the quality of the the code

00:23:40,880 --> 00:23:46,320
and the

00:23:41,440 --> 00:23:50,240
the pipeline automation is

00:23:46,320 --> 00:23:52,480
it's common for anyone right so

00:23:50,240 --> 00:23:54,720
data pipelines are codes if you have a

00:23:52,480 --> 00:23:58,000
code you need to version your code

00:23:54,720 --> 00:24:01,039
this is uh my argument right so

00:23:58,000 --> 00:24:03,279
using it create your brains do the best

00:24:01,039 --> 00:24:05,840
for you to version your codes

00:24:03,279 --> 00:24:07,120
to review your code get the approvals

00:24:05,840 --> 00:24:09,440
right

00:24:07,120 --> 00:24:10,159
but there's one thing that's very

00:24:09,440 --> 00:24:13,600
important

00:24:10,159 --> 00:24:17,120
and i love this this this part

00:24:13,600 --> 00:24:20,400
use the power of different

00:24:17,120 --> 00:24:22,159
tech platforms so i you explain most

00:24:20,400 --> 00:24:25,679
part of the big data tools

00:24:22,159 --> 00:24:29,440
nowadays is writing in java scala

00:24:25,679 --> 00:24:33,520
i can i can for example hadoop spark

00:24:29,440 --> 00:24:34,159
flink right but they have interfaces for

00:24:33,520 --> 00:24:37,840
python

00:24:34,159 --> 00:24:40,960
as well why not use a title for that

00:24:37,840 --> 00:24:44,159
but let's the part of java

00:24:40,960 --> 00:24:47,919
because java do it well

00:24:44,159 --> 00:24:50,960
and you use python for what python

00:24:47,919 --> 00:24:54,000
performs well use the power the

00:24:50,960 --> 00:24:55,120
there's no problem with that code review

00:24:54,000 --> 00:24:58,240
a link

00:24:55,120 --> 00:24:59,760
keep your code beautiful not of course

00:24:58,240 --> 00:25:01,760
we are talking about the beautiful

00:24:59,760 --> 00:25:03,520
because people needed to read this code

00:25:01,760 --> 00:25:06,960
from the pipeline

00:25:03,520 --> 00:25:08,640
pipeline tells us a story about data

00:25:06,960 --> 00:25:10,720
it's very important different from a

00:25:08,640 --> 00:25:11,679
software that you have different ways to

00:25:10,720 --> 00:25:14,960
abstract

00:25:11,679 --> 00:25:17,120
and you have different ways to to

00:25:14,960 --> 00:25:18,080
to have your own knowledge to abstract

00:25:17,120 --> 00:25:21,840
to to make

00:25:18,080 --> 00:25:24,960
things more uh more or more easy

00:25:21,840 --> 00:25:28,720
uh in the data in the data

00:25:24,960 --> 00:25:32,080
the data pipeline codes in general uh

00:25:28,720 --> 00:25:35,120
step step by step of this the

00:25:32,080 --> 00:25:35,840
this pipeline tells a history about the

00:25:35,120 --> 00:25:37,919
data

00:25:35,840 --> 00:25:39,120
how the data are being transformed how

00:25:37,919 --> 00:25:42,159
the data are being

00:25:39,120 --> 00:25:45,440
uh changed how you need

00:25:42,159 --> 00:25:46,480
to to to change everything right and of

00:25:45,440 --> 00:25:48,960
course

00:25:46,480 --> 00:25:50,000
if you can use any kind of continuous

00:25:48,960 --> 00:25:53,600
integration

00:25:50,000 --> 00:25:55,840
integration server or or continuous

00:25:53,600 --> 00:25:59,520
deployment

00:25:55,840 --> 00:26:01,200
everything we are just the programmers

00:25:59,520 --> 00:26:04,400
because you are lazy

00:26:01,200 --> 00:26:06,480
i i hate to repeat my job so

00:26:04,400 --> 00:26:07,520
i love you to be creative but i love it

00:26:06,480 --> 00:26:10,320
to repeat

00:26:07,520 --> 00:26:10,799
my job so automate everything that you

00:26:10,320 --> 00:26:13,200
can

00:26:10,799 --> 00:26:14,240
in your in your code in your process

00:26:13,200 --> 00:26:17,120
right

00:26:14,240 --> 00:26:17,679
monitoring is another nice thing in

00:26:17,120 --> 00:26:20,960
general

00:26:17,679 --> 00:26:24,320
you introduce a lot of logs in in our

00:26:20,960 --> 00:26:27,440
in our applications right

00:26:24,320 --> 00:26:30,640
but my advice here is

00:26:27,440 --> 00:26:33,679
let the cloud helps you to monitor in

00:26:30,640 --> 00:26:36,000
your pipeline in your application right

00:26:33,679 --> 00:26:37,200
just send out the logs just to send all

00:26:36,000 --> 00:26:40,720
the metrics

00:26:37,200 --> 00:26:43,120
and set up some alarms and if

00:26:40,720 --> 00:26:44,000
something goes wrong so you receive like

00:26:43,120 --> 00:26:47,520
an email or

00:26:44,000 --> 00:26:50,320
a page or whatever but i

00:26:47,520 --> 00:26:51,760
strongly suggest you to avoid any kind

00:26:50,320 --> 00:26:54,720
of event or looking

00:26:51,760 --> 00:26:56,240
it means it's simple just to create a

00:26:54,720 --> 00:26:59,440
wrapper inside your

00:26:56,240 --> 00:27:03,279
application just to hide

00:26:59,440 --> 00:27:06,960
the the vendor that you are using

00:27:03,279 --> 00:27:09,600
for in my case i use a lot of azure

00:27:06,960 --> 00:27:11,200
but if you use amazon or google just

00:27:09,600 --> 00:27:14,559
just make sure to

00:27:11,200 --> 00:27:15,840
uh deliver everything related with

00:27:14,559 --> 00:27:20,080
monitoring

00:27:15,840 --> 00:27:24,399
to our logs to

00:27:20,080 --> 00:27:28,480
to clouds tests tests is very important

00:27:24,399 --> 00:27:30,480
as well imagining

00:27:28,480 --> 00:27:32,399
that you started to create like a new

00:27:30,480 --> 00:27:34,080
data pipeline

00:27:32,399 --> 00:27:35,840
and the first thing that you need to

00:27:34,080 --> 00:27:41,200
define is

00:27:35,840 --> 00:27:45,360
how your input you come into your system

00:27:41,200 --> 00:27:48,000
your inputs always must be deterministic

00:27:45,360 --> 00:27:49,360
you can change any time but they needed

00:27:48,000 --> 00:27:52,640
to be deterministic

00:27:49,360 --> 00:27:55,679
right because you needed to understand

00:27:52,640 --> 00:27:58,640
the behavior of your software right

00:27:55,679 --> 00:27:59,440
focus you need to test for all the

00:27:58,640 --> 00:28:02,480
pipeline

00:27:59,440 --> 00:28:04,159
as well each kind of transformation each

00:28:02,480 --> 00:28:07,520
kind of uh

00:28:04,159 --> 00:28:10,880
slightly difference in the data test it

00:28:07,520 --> 00:28:14,399
right and if you are

00:28:10,880 --> 00:28:17,840
able i need to assume it's hard for me

00:28:14,399 --> 00:28:20,640
to apply regression tests here

00:28:17,840 --> 00:28:21,840
but of course i strongly recommend you

00:28:20,640 --> 00:28:25,200
to

00:28:21,840 --> 00:28:28,240
do it okay and

00:28:25,200 --> 00:28:31,200
uh it's one thing that everybody missed

00:28:28,240 --> 00:28:32,159
is to test the third-party container

00:28:31,200 --> 00:28:35,520
tools

00:28:32,159 --> 00:28:36,320
right let's imagine a scenario you are

00:28:35,520 --> 00:28:40,240
developing

00:28:36,320 --> 00:28:41,840
a uh data pipeline

00:28:40,240 --> 00:28:43,440
and you need to and you have

00:28:41,840 --> 00:28:46,960
dependencies of your

00:28:43,440 --> 00:28:50,080
pachikafika spark for example

00:28:46,960 --> 00:28:52,799
so you get it put inside a docker

00:28:50,080 --> 00:28:55,360
and you need to test everything right

00:28:52,799 --> 00:28:55,360
together

00:28:56,159 --> 00:29:01,520
create this kind of a test and to end

00:28:58,960 --> 00:29:05,120
including all your third party companies

00:29:01,520 --> 00:29:08,240
because it's called the monkey test so

00:29:05,120 --> 00:29:10,399
once you you suddenly you drop

00:29:08,240 --> 00:29:11,520
or you shut down the kafka how your

00:29:10,399 --> 00:29:14,640
software

00:29:11,520 --> 00:29:17,200
behaves without kafka drop the

00:29:14,640 --> 00:29:18,000
spark how your software behaves without

00:29:17,200 --> 00:29:21,120
spark

00:29:18,000 --> 00:29:23,520
they are able to recover by their self

00:29:21,120 --> 00:29:24,320
you need it to have intervention your

00:29:23,520 --> 00:29:27,600
recivil

00:29:24,320 --> 00:29:30,720
alert or not so test the third party

00:29:27,600 --> 00:29:34,080
components and do mocking tests this

00:29:30,720 --> 00:29:34,080
is essential right

00:29:35,200 --> 00:29:42,799
now is the time after i talked a lot so

00:29:39,279 --> 00:29:46,399
let's understand where the title matters

00:29:42,799 --> 00:29:50,320
here okay for the first

00:29:46,399 --> 00:29:52,000
right so everybody who starts in the

00:29:50,320 --> 00:29:55,200
data engineer

00:29:52,000 --> 00:29:58,960
everybody who starts working with data

00:29:55,200 --> 00:30:02,080
i suppose that the first uh word

00:29:58,960 --> 00:30:05,360
you listen is equal it will means

00:30:02,080 --> 00:30:07,760
extract load and transform basically

00:30:05,360 --> 00:30:11,440
it's a framing work

00:30:07,760 --> 00:30:12,880
distributed computer framework that

00:30:11,440 --> 00:30:15,760
permits you to

00:30:12,880 --> 00:30:17,120
execute the code in different machines

00:30:15,760 --> 00:30:21,120
with the same result

00:30:17,120 --> 00:30:24,320
right nowadays the fact

00:30:21,120 --> 00:30:28,480
uh spark empire spark

00:30:24,320 --> 00:30:29,760
us is the the mandatory in the market of

00:30:28,480 --> 00:30:32,399
course there's a lot of

00:30:29,760 --> 00:30:34,840
uh another players but basically

00:30:32,399 --> 00:30:38,720
everybody uses park nowadays

00:30:34,840 --> 00:30:42,880
right for those who want you to use a

00:30:38,720 --> 00:30:45,360
pure python solution i recommend dusk

00:30:42,880 --> 00:30:46,640
dusk is a nice feature there's a nice

00:30:45,360 --> 00:30:49,679
feature because

00:30:46,640 --> 00:30:50,720
you can interact with the object inside

00:30:49,679 --> 00:30:53,840
the desk

00:30:50,720 --> 00:30:56,320
as you are interacting using pendants

00:30:53,840 --> 00:30:58,720
if you know how to use a pandas you can

00:30:56,320 --> 00:31:01,120
just use it lastly

00:30:58,720 --> 00:31:02,320
and do the magic you can you can

00:31:01,120 --> 00:31:04,159
distribute

00:31:02,320 --> 00:31:05,760
your process along with different

00:31:04,159 --> 00:31:09,440
machines

00:31:05,760 --> 00:31:13,279
as you are using pendants okay

00:31:09,440 --> 00:31:15,600
luigi luigi is a model in title is a

00:31:13,279 --> 00:31:16,080
liberating python that permits you to

00:31:15,600 --> 00:31:19,440
create

00:31:16,080 --> 00:31:22,559
complex pipelines it means that you can

00:31:19,440 --> 00:31:25,360
create different different tasks

00:31:22,559 --> 00:31:26,640
and you can link these different tasks

00:31:25,360 --> 00:31:30,000
and create a graph

00:31:26,640 --> 00:31:30,559
between these tasks to say if this task

00:31:30,000 --> 00:31:34,399
is

00:31:30,559 --> 00:31:37,840
runs successfully executed the next

00:31:34,399 --> 00:31:38,240
one and then is infinitive so you can

00:31:37,840 --> 00:31:41,679
have

00:31:38,240 --> 00:31:46,080
as much degrees or as much ads

00:31:41,679 --> 00:31:46,480
as you want okay if you are old school

00:31:46,080 --> 00:31:48,480
guy

00:31:46,480 --> 00:31:50,320
and he still wanted to use hadoop i

00:31:48,480 --> 00:31:54,320
recommend mer job

00:31:50,320 --> 00:31:57,440
okay if you are in amazon uh

00:31:54,320 --> 00:32:00,640
or using a book without a spark

00:31:57,440 --> 00:32:04,720
me our job is a good thing and

00:32:00,640 --> 00:32:08,080
rey is similar to to desk as well but

00:32:04,720 --> 00:32:10,080
honestly i just played a bit but i have

00:32:08,080 --> 00:32:13,039
no

00:32:10,080 --> 00:32:14,240
more information to talk about that

00:32:13,039 --> 00:32:16,399
another thing

00:32:14,240 --> 00:32:19,440
in the data in the data universe is

00:32:16,399 --> 00:32:21,240
about the stream streaming basically

00:32:19,440 --> 00:32:22,880
everybody is using in

00:32:21,240 --> 00:32:25,279
[Music]

00:32:22,880 --> 00:32:27,279
stream as well there's too many products

00:32:25,279 --> 00:32:28,000
in the market one is kafka kafka

00:32:27,279 --> 00:32:31,200
basically

00:32:28,000 --> 00:32:33,120
the fact to extreme streaming process as

00:32:31,200 --> 00:32:35,519
well but you have a score as well

00:32:33,120 --> 00:32:36,320
i never use it storm to be honest but i

00:32:35,519 --> 00:32:40,240
used a lot of

00:32:36,320 --> 00:32:43,200
kafka and you have like a

00:32:40,240 --> 00:32:43,840
title script that you can just plug into

00:32:43,200 --> 00:32:46,880
kafka

00:32:43,840 --> 00:32:47,840
and work smoothly i really recommend to

00:32:46,880 --> 00:32:51,360
you to use

00:32:47,840 --> 00:32:53,840
uh faust okay

00:32:51,360 --> 00:32:56,480
if you want to use string and if you

00:32:53,840 --> 00:32:58,320
want to use the kafka for that

00:32:56,480 --> 00:33:00,399
you can go in deeply i think that my

00:32:58,320 --> 00:33:03,279
time is about to finish but

00:33:00,399 --> 00:33:04,240
if you are interested you just drop him

00:33:03,279 --> 00:33:07,519
a mess or

00:33:04,240 --> 00:33:08,880
no question answer i can answer more for

00:33:07,519 --> 00:33:10,880
you

00:33:08,880 --> 00:33:12,320
okay when you talk about analysis

00:33:10,880 --> 00:33:14,559
analysis is not

00:33:12,320 --> 00:33:16,000
directly related with the data engineer

00:33:14,559 --> 00:33:19,679
but of course they are

00:33:16,000 --> 00:33:21,519
complements right uh pundits

00:33:19,679 --> 00:33:22,799
i think that i don't need to introduce a

00:33:21,519 --> 00:33:25,600
bunch i guess

00:33:22,799 --> 00:33:26,240
but that you do like introduce pandas is

00:33:25,600 --> 00:33:29,919
like uh

00:33:26,240 --> 00:33:31,519
the full liberty for data analysis in

00:33:29,919 --> 00:33:34,559
python right

00:33:31,519 --> 00:33:35,279
uh as i i mentioned before so they

00:33:34,559 --> 00:33:37,919
integrate

00:33:35,279 --> 00:33:38,720
perfectly with task if you want to have

00:33:37,919 --> 00:33:40,880
some

00:33:38,720 --> 00:33:42,080
pure python solution you can't

00:33:40,880 --> 00:33:45,679
aggressive

00:33:42,080 --> 00:33:49,279
with a dusk blazing

00:33:45,679 --> 00:33:51,279
is basically the same but they integrate

00:33:49,279 --> 00:33:53,919
the lupine pandas

00:33:51,279 --> 00:33:55,120
directly with the the big data and

00:33:53,919 --> 00:33:58,720
openmind

00:33:55,120 --> 00:34:02,000
is for those people who works with

00:33:58,720 --> 00:34:02,000
big data right

00:34:02,399 --> 00:34:05,600
i never worked before orange and optimus

00:34:05,120 --> 00:34:08,720
the

00:34:05,600 --> 00:34:11,839
the documentation is quite complete

00:34:08,720 --> 00:34:15,040
so you can explore more

00:34:11,839 --> 00:34:16,800
optimals i heard nice things about that

00:34:15,040 --> 00:34:19,200
especially because of data science over

00:34:16,800 --> 00:34:21,280
the flow and then you can integrate it

00:34:19,200 --> 00:34:23,839
directly with the pi spark

00:34:21,280 --> 00:34:25,119
that's awesome when i have opportunity

00:34:23,839 --> 00:34:28,800
to to work on

00:34:25,119 --> 00:34:32,720
optimals probably i you try

00:34:28,800 --> 00:34:32,720
airflow airflow is

00:34:32,960 --> 00:34:40,240
our phone is a tool that permits you to

00:34:37,200 --> 00:34:41,520
create scheduler monitors and pipeline

00:34:40,240 --> 00:34:44,639
all together in the same

00:34:41,520 --> 00:34:46,800
tool and our flow is divided in

00:34:44,639 --> 00:34:50,079
two main components they have a web

00:34:46,800 --> 00:34:53,119
server when you have the ui to control

00:34:50,079 --> 00:34:54,480
controlling and view all the health of

00:34:53,119 --> 00:34:56,320
your pipelines

00:34:54,480 --> 00:34:57,680
and you have these schedulers and

00:34:56,320 --> 00:35:01,800
workers that

00:34:57,680 --> 00:35:05,280
runs all the jobs for you and airflow is

00:35:01,800 --> 00:35:07,920
extremely extensible so

00:35:05,280 --> 00:35:08,560
independently of the two that you are

00:35:07,920 --> 00:35:12,560
using

00:35:08,560 --> 00:35:14,880
you can extend airflow to use your vr2

00:35:12,560 --> 00:35:16,160
actually i'm using with internal tools

00:35:14,880 --> 00:35:20,160
from my company

00:35:16,160 --> 00:35:23,520
i extended i used the the open source

00:35:20,160 --> 00:35:24,079
tools i really recommend you to to give

00:35:23,520 --> 00:35:27,200
a look

00:35:24,079 --> 00:35:30,000
into our flow and start to learn data

00:35:27,200 --> 00:35:33,680
engineering data pipelines directly

00:35:30,000 --> 00:35:36,240
with airflow this is my device

00:35:33,680 --> 00:35:36,800
okay testing passes is very important

00:35:36,240 --> 00:35:38,320
tonight

00:35:36,800 --> 00:35:41,119
everything is very important as you can

00:35:38,320 --> 00:35:42,880
imagine but testing so

00:35:41,119 --> 00:35:44,800
you need to test your code by

00:35:42,880 --> 00:35:48,800
pythagorean is the most

00:35:44,800 --> 00:35:50,000
mercury python 2 so very extensible

00:35:48,800 --> 00:35:53,440
domains

00:35:50,000 --> 00:35:54,960
as well so i can i can extend for

00:35:53,440 --> 00:35:59,520
different

00:35:54,960 --> 00:36:02,400
scenarios and behaviors okay

00:35:59,520 --> 00:36:02,960
nemesis permits you to generate fake

00:36:02,400 --> 00:36:05,040
data it

00:36:02,960 --> 00:36:07,040
means if you needed to generate like a

00:36:05,040 --> 00:36:10,480
huge amount of data to test

00:36:07,040 --> 00:36:13,920
one part of your uh

00:36:10,480 --> 00:36:17,119
one of your your pipeline

00:36:13,920 --> 00:36:18,240
of your party of your your model so you

00:36:17,119 --> 00:36:21,599
can use the name is

00:36:18,240 --> 00:36:25,040
s you can do with the fake db

00:36:21,599 --> 00:36:28,480
and this link that i put in my

00:36:25,040 --> 00:36:31,520
in my in my presentation is a

00:36:28,480 --> 00:36:32,320
library that permits you to create unity

00:36:31,520 --> 00:36:35,680
tests

00:36:32,320 --> 00:36:39,280
using pi spark why

00:36:35,680 --> 00:36:41,680
pi spark is a rapper over a

00:36:39,280 --> 00:36:43,359
java library a java library right so you

00:36:41,680 --> 00:36:46,160
can use python objects

00:36:43,359 --> 00:36:48,560
you use the python objects we are called

00:36:46,160 --> 00:36:51,760
execute inside the python

00:36:48,560 --> 00:36:53,520
interpreter right

00:36:51,760 --> 00:36:55,920
but sometimes you need to test the

00:36:53,520 --> 00:36:59,440
behavior in the java side

00:36:55,920 --> 00:37:02,800
these libraries permit you to write a

00:36:59,440 --> 00:37:07,119
python python test and test the

00:37:02,800 --> 00:37:10,960
the global uh the global situation

00:37:07,119 --> 00:37:10,960
okay okay

00:37:11,760 --> 00:37:15,839
when i told when i told about uh when i

00:37:15,040 --> 00:37:19,200
thought about

00:37:15,839 --> 00:37:24,079
premature modeling or how you define

00:37:19,200 --> 00:37:27,920
the schema of your your data

00:37:24,079 --> 00:37:30,960
some tools helps a lot let's imagine

00:37:27,920 --> 00:37:34,720
that today you are collecting the

00:37:30,960 --> 00:37:37,839
the the the data of the weather

00:37:34,720 --> 00:37:38,480
and then you have a temperature you need

00:37:37,839 --> 00:37:41,599
it

00:37:38,480 --> 00:37:44,720
in rain right so you

00:37:41,599 --> 00:37:46,640
you you have modeling your your

00:37:44,720 --> 00:37:50,960
application for receive

00:37:46,640 --> 00:37:54,480
those three information one month after

00:37:50,960 --> 00:37:57,920
and you validate this this input so

00:37:54,480 --> 00:37:59,680
you can you can trust that all the data

00:37:57,920 --> 00:38:03,200
that are coming to your

00:37:59,680 --> 00:38:06,000
your your system uh you can trust

00:38:03,200 --> 00:38:07,359
right one month after you need to

00:38:06,000 --> 00:38:11,119
introduce a new

00:38:07,359 --> 00:38:14,400
a new data now you have like you made it

00:38:11,119 --> 00:38:14,800
okay okay you need to go there change

00:38:14,400 --> 00:38:18,000
your

00:38:14,800 --> 00:38:20,240
schema to put a new column a new field a

00:38:18,000 --> 00:38:22,960
new document or whatever

00:38:20,240 --> 00:38:24,480
a kind of strategy that you are using

00:38:22,960 --> 00:38:28,079
and then you needed to validate

00:38:24,480 --> 00:38:32,640
this new schema making sure that the

00:38:28,079 --> 00:38:35,200
less schemas is still working right

00:38:32,640 --> 00:38:36,640
and then you need to progress it for the

00:38:35,200 --> 00:38:40,160
next steps

00:38:36,640 --> 00:38:43,920
those three three levers that i'm

00:38:40,160 --> 00:38:46,800
showing to you do exactly this right

00:38:43,920 --> 00:38:48,560
if you wanted to to validate the inputs

00:38:46,800 --> 00:38:51,599
of your application or

00:38:48,560 --> 00:38:51,920
if you want you to validate the scheme

00:38:51,599 --> 00:38:55,520
of

00:38:51,920 --> 00:38:57,119
your files you use cervelos or you can

00:38:55,520 --> 00:39:00,320
use voluptos

00:38:57,119 --> 00:39:00,960
for that for me it's mandatory for any

00:39:00,320 --> 00:39:04,000
project

00:39:00,960 --> 00:39:04,800
of data right this is my advice is for

00:39:04,000 --> 00:39:07,599
you

00:39:04,800 --> 00:39:07,920
as i told you is not a talk about code

00:39:07,599 --> 00:39:11,200
but

00:39:07,920 --> 00:39:12,880
more about the concepts and i'm totally

00:39:11,200 --> 00:39:15,920
free to

00:39:12,880 --> 00:39:16,800
to answer your questions right and

00:39:15,920 --> 00:39:20,400
that's all

00:39:16,800 --> 00:39:24,640
uh i would like to say a big thank you

00:39:20,400 --> 00:39:27,440
uh our brigado because i'm

00:39:24,640 --> 00:39:28,640
portuguese i like portuguese feel free

00:39:27,440 --> 00:39:31,839
to reach me out in

00:39:28,640 --> 00:39:35,359
my email telegram

00:39:31,839 --> 00:39:39,040
twitter whatever call me i'm

00:39:35,359 --> 00:39:41,119
more than a pleasure to to to talk to

00:39:39,040 --> 00:39:56,400
you share experience

00:39:41,119 --> 00:39:58,480
uh thank you so much everybody

00:39:56,400 --> 00:39:58,480

YouTube URL: https://www.youtube.com/watch?v=dQnKiVxO0PY


