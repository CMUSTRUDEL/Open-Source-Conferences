Title: Deep Learning o..... Using Transfer Learning to Accelerate Model Performance - Kwadwo Agyapon-Ntra
Publication date: 2019-11-23
Playlist: PyCon Africa 2019
Description: 
	Re-inventing the wheel is pointless in real-life. After burying our heads in tutorials, we still notice a huge gap between what we learnt and real-life scenarios. In this talk, we'll leap over this gap using the powerful concept of transfer learning to build our best deep learning models yet!
Captions: 
	00:00:01,230 --> 00:00:07,419
all right good morning

00:00:03,629 --> 00:00:09,790
yeah so my name is squidge oh I realize

00:00:07,419 --> 00:00:11,650
you are not Organians so you can't call

00:00:09,790 --> 00:00:15,160
me Kay oh that's what my friends call me

00:00:11,650 --> 00:00:17,320
so yeah just to get out of the way yeah

00:00:15,160 --> 00:00:20,019
so today we are talking about deep

00:00:17,320 --> 00:00:22,089
learning on steroids using transfer

00:00:20,019 --> 00:00:25,720
learning to accelerate model performance

00:00:22,089 --> 00:00:27,489
so first I need to gauge level in the

00:00:25,720 --> 00:00:32,700
room how many of us are completely new

00:00:27,489 --> 00:00:37,720
to machine learning okay how many of us

00:00:32,700 --> 00:00:39,610
advanced in was a learning you how many

00:00:37,720 --> 00:00:41,200
of you have built a model before you

00:00:39,610 --> 00:00:44,650
build a machine learning model before

00:00:41,200 --> 00:00:46,390
okay okay so some people who say they're

00:00:44,650 --> 00:00:48,010
completely new but if said we've built a

00:00:46,390 --> 00:00:52,960
model before I don't know how that works

00:00:48,010 --> 00:00:54,940
but we believe them okay so yeah a

00:00:52,960 --> 00:00:56,920
little bit about my surfaced

00:00:54,940 --> 00:00:58,510
I attended a G motor school if you are

00:00:56,920 --> 00:01:02,320
not gonna and please believe me is the

00:00:58,510 --> 00:01:06,640
best high school in Ghana I have the mic

00:01:02,320 --> 00:01:10,030
I must be right then I went to cairn UST

00:01:06,640 --> 00:01:11,860
I studied Computer Engineering I'm

00:01:10,030 --> 00:01:14,310
currently at missed the melteth

00:01:11,860 --> 00:01:15,940
entrepreneurs cough technology and

00:01:14,310 --> 00:01:18,100
through mist

00:01:15,940 --> 00:01:20,470
started a company called Macau so I'm

00:01:18,100 --> 00:01:24,550
co-founder and CTO at Macau oh I think

00:01:20,470 --> 00:01:27,580
my cosmetic and I'm also remember the

00:01:24,550 --> 00:01:29,560
practical data community I think the

00:01:27,580 --> 00:01:33,159
pilot is have also adopted me as a

00:01:29,560 --> 00:01:37,090
mentor but cuz I'm a man I can't put it

00:01:33,159 --> 00:01:39,750
up there looks funny so yeah in my spare

00:01:37,090 --> 00:01:44,260
time I'm a musician in church usually

00:01:39,750 --> 00:01:47,380
drums guitar keyboard yeah and I blog at

00:01:44,260 --> 00:01:49,990
blog birth control of X Y Z the

00:01:47,380 --> 00:01:53,200
languages I've listed down the things

00:01:49,990 --> 00:01:56,080
have played with so java used to be my

00:01:53,200 --> 00:01:59,320
native tongue but when I realized that

00:01:56,080 --> 00:02:01,840
in Python hello world script is a single

00:01:59,320 --> 00:02:05,799
line and in Java was like six lines I

00:02:01,840 --> 00:02:07,090
change my mind so yeah so this is what

00:02:05,799 --> 00:02:10,110
we are going to go through today

00:02:07,090 --> 00:02:12,580
very quickly we'll try not to keep

00:02:10,110 --> 00:02:14,180
anything long so since a lot of us say

00:02:12,580 --> 00:02:16,610
we are new to machine

00:02:14,180 --> 00:02:19,040
put a few sleds in hoping to skip them

00:02:16,610 --> 00:02:21,830
if before I already been to this but

00:02:19,040 --> 00:02:23,900
I'll just touch on the basics of not

00:02:21,830 --> 00:02:28,040
machine learning per se but deep

00:02:23,900 --> 00:02:30,819
learning okay so the basic definition of

00:02:28,040 --> 00:02:34,100
machine learning is you are taking data

00:02:30,819 --> 00:02:38,989
okay and using that data to teach your

00:02:34,100 --> 00:02:41,420
computer or machine your system to land

00:02:38,989 --> 00:02:44,660
on its own setting rules from the data

00:02:41,420 --> 00:02:46,489
so for example I can teach my computer

00:02:44,660 --> 00:02:48,080
two plus two is equal to four three plus

00:02:46,489 --> 00:02:51,019
three is equal to six seven plus seven

00:02:48,080 --> 00:02:53,930
is equal to 14 and so on give it to just

00:02:51,019 --> 00:02:57,049
so many examples and so by itself the

00:02:53,930 --> 00:02:57,980
system determines the rules so machine

00:02:57,049 --> 00:03:03,560
learning is programming a computer

00:02:57,980 --> 00:03:05,660
without explicitly putting in the rules

00:03:03,560 --> 00:03:09,620
that should be okay generates enough

00:03:05,660 --> 00:03:12,230
data so it can learn and there's a lot

00:03:09,620 --> 00:03:15,190
of machine learning foundations which we

00:03:12,230 --> 00:03:17,209
cannot go through this morning but once

00:03:15,190 --> 00:03:21,410
we are going to focus on deep learning

00:03:17,209 --> 00:03:22,910
and deep learning came about Elise in

00:03:21,410 --> 00:03:28,400
the initial stages where people were

00:03:22,910 --> 00:03:29,810
trying to simulate what was assumed to

00:03:28,400 --> 00:03:32,120
be the way the brain works

00:03:29,810 --> 00:03:34,850
okay so inside a human brain there's a

00:03:32,120 --> 00:03:36,829
lot of tiny tiny units called neurons

00:03:34,850 --> 00:03:39,260
which connect and transmit the

00:03:36,829 --> 00:03:43,190
information between each other so this

00:03:39,260 --> 00:03:47,600
is a perceptron a perceptron is for our

00:03:43,190 --> 00:03:50,950
purposes a digital neuron okay so

00:03:47,600 --> 00:03:54,590
there's some information that comes into

00:03:50,950 --> 00:03:56,269
the nucleus and then from the decision

00:03:54,590 --> 00:03:59,630
is made based on some function and then

00:03:56,269 --> 00:04:01,970
it gives an output and the perceptron is

00:03:59,630 --> 00:04:03,680
actually pretty old in terms of machine

00:04:01,970 --> 00:04:07,549
learning it came somewhere I think in

00:04:03,680 --> 00:04:10,400
the 1950s but one of the downsides of

00:04:07,549 --> 00:04:13,880
the perceptron is that it's couldn't

00:04:10,400 --> 00:04:15,709
solve a problem like this a good way to

00:04:13,880 --> 00:04:17,269
think of machine learning especially in

00:04:15,709 --> 00:04:19,340
classification is that you have a number

00:04:17,269 --> 00:04:21,260
of items that distributed a certain

00:04:19,340 --> 00:04:24,460
pattern we are trying to sort of draw a

00:04:21,260 --> 00:04:26,410
line or a calf that can divide these two

00:04:24,460 --> 00:04:31,240
these two

00:04:26,410 --> 00:04:32,800
how open is that point on this yeah so

00:04:31,240 --> 00:04:35,680
you're trying to draw a line that can

00:04:32,800 --> 00:04:38,350
divide the so maybe you have oranges and

00:04:35,680 --> 00:04:40,060
apples that can separates them okay but

00:04:38,350 --> 00:04:42,730
the problem in the perceptron is that

00:04:40,060 --> 00:04:45,460
there is no straight line you can't draw

00:04:42,730 --> 00:04:48,430
that will separate all the positives in

00:04:45,460 --> 00:04:51,010
this picture from the negatives try to

00:04:48,430 --> 00:04:52,720
do it with your mind and see there is no

00:04:51,010 --> 00:04:55,480
single straight line okay

00:04:52,720 --> 00:04:58,300
so there had to be a certain amount of

00:04:55,480 --> 00:05:00,960
complexity that was added so it was

00:04:58,300 --> 00:05:04,330
found that when you add the comp

00:05:00,960 --> 00:05:07,390
multiple perceptrons together in layers

00:05:04,330 --> 00:05:11,530
you get a neural network okay and the

00:05:07,390 --> 00:05:15,580
neural network according to certain

00:05:11,530 --> 00:05:18,130
computer science theory is what you call

00:05:15,580 --> 00:05:20,140
a universal approximator so what that

00:05:18,130 --> 00:05:22,810
means is that any problem that can be

00:05:20,140 --> 00:05:24,820
modeled as a function Fioretti curly you

00:05:22,810 --> 00:05:26,230
can have a neural network large enough

00:05:24,820 --> 00:05:29,980
to solve this problem

00:05:26,230 --> 00:05:34,060
okay the issue is that it's just

00:05:29,980 --> 00:05:36,550
theoretically if you want to practically

00:05:34,060 --> 00:05:38,260
build a single layer feed-forward

00:05:36,550 --> 00:05:40,270
network that's one type of neural

00:05:38,260 --> 00:05:42,430
network that can solve any kind of

00:05:40,270 --> 00:05:44,410
problem it's going to be too big you're

00:05:42,430 --> 00:05:47,710
going to need too much memory too much

00:05:44,410 --> 00:05:50,050
processing power so we added another I

00:05:47,710 --> 00:05:53,470
say we like ours part of them add

00:05:50,050 --> 00:05:56,110
another layer of complexity which we are

00:05:53,470 --> 00:05:59,800
going to call the multi-layer neuron

00:05:56,110 --> 00:06:02,980
Network okay so once you start to get

00:05:59,800 --> 00:06:05,020
multiple layers of neurons in your

00:06:02,980 --> 00:06:06,820
network that is when you have gone deep

00:06:05,020 --> 00:06:08,050
that's why we say you are now dealing

00:06:06,820 --> 00:06:10,870
with deep learning

00:06:08,050 --> 00:06:15,250
that's a quote by a headphone Mustafa's

00:06:10,870 --> 00:06:17,740
is a go deeper go home yeah so the way

00:06:15,250 --> 00:06:19,240
it works is your inputs you remember I

00:06:17,740 --> 00:06:21,790
said in machine learning you are given

00:06:19,240 --> 00:06:25,150
the the machine data for it to learn its

00:06:21,790 --> 00:06:27,910
own rules so the data coming in these

00:06:25,150 --> 00:06:30,430
variables they move to the network they

00:06:27,910 --> 00:06:33,340
are multiplied by setting functions from

00:06:30,430 --> 00:06:36,310
layer to layer and each layer extracts

00:06:33,340 --> 00:06:39,110
new features from the data that is going

00:06:36,310 --> 00:06:41,870
to learn from if you are actually to try

00:06:39,110 --> 00:06:43,460
and inspect the data that it's seen

00:06:41,870 --> 00:06:45,050
there you might not be able to make

00:06:43,460 --> 00:06:47,960
sense of all the data may be able to

00:06:45,050 --> 00:06:49,940
make sense of some of it but there's a

00:06:47,960 --> 00:06:53,000
certain level of complexity that make

00:06:49,940 --> 00:06:54,620
sense solely to the computer ok so it

00:06:53,000 --> 00:06:56,030
goes to the layers test track to some

00:06:54,620 --> 00:07:00,500
features and it makes its own leanings

00:06:56,030 --> 00:07:03,950
when it lands so when when the neural

00:07:00,500 --> 00:07:06,140
network learns something and checks the

00:07:03,950 --> 00:07:08,960
result that it's predicted against the

00:07:06,140 --> 00:07:12,560
actual resort that so you have you have

00:07:08,960 --> 00:07:14,960
labeled beta and you have so there's the

00:07:12,560 --> 00:07:20,420
raw input and then as the label so let's

00:07:14,960 --> 00:07:23,180
say a human being you see head legs you

00:07:20,420 --> 00:07:26,090
see two legs you see two arms and you

00:07:23,180 --> 00:07:27,680
assume that is a human being right so

00:07:26,090 --> 00:07:30,890
now if we put somebody who unfortunately

00:07:27,680 --> 00:07:32,540
had a car accidents lost an arm inside

00:07:30,890 --> 00:07:34,460
that he's still a human being but the

00:07:32,540 --> 00:07:36,200
system might predict that this is not a

00:07:34,460 --> 00:07:39,170
human being because he doesn't have two

00:07:36,200 --> 00:07:41,090
arms right so it predicts that does no

00:07:39,170 --> 00:07:43,550
human being it checks this is wrong it

00:07:41,090 --> 00:07:45,860
goes back to real and and to correct the

00:07:43,550 --> 00:07:48,140
mistakes it has made okay so that's

00:07:45,860 --> 00:07:52,000
basically how I dip in your network wax

00:07:48,140 --> 00:07:54,500
this is a serious crash course all right

00:07:52,000 --> 00:07:59,540
now what have we done with deep learning

00:07:54,500 --> 00:08:01,970
over time this graph is from imagenet

00:07:59,540 --> 00:08:04,220
classification challenge the imagenet

00:08:01,970 --> 00:08:07,610
classification challenge happens yearly

00:08:04,220 --> 00:08:10,880
and there's a data set of millions of

00:08:07,610 --> 00:08:12,530
images of just random things about I

00:08:10,880 --> 00:08:16,130
think the thousand levels in the image

00:08:12,530 --> 00:08:19,400
net data set and researchers have been

00:08:16,130 --> 00:08:24,110
trying to improve models for many years

00:08:19,400 --> 00:08:27,680
now and asad 2011 the error rate was

00:08:24,110 --> 00:08:33,320
somewhere around 26 okay yeah somewhere

00:08:27,680 --> 00:08:35,240
126 and by 2012 2012 was the first time

00:08:33,320 --> 00:08:37,250
that what you call a convolutional

00:08:35,240 --> 00:08:39,320
neural network is just another type of

00:08:37,250 --> 00:08:41,960
neural network was used on this

00:08:39,320 --> 00:08:44,660
challenge and it did a lot better than

00:08:41,960 --> 00:08:46,460
all its predecessors it brought the

00:08:44,660 --> 00:08:51,410
error e to somewhere around 16 points

00:08:46,460 --> 00:08:52,520
for and based on that breakthrough a lot

00:08:51,410 --> 00:08:59,330
of new

00:08:52,520 --> 00:09:01,190
models have come out so there's this the

00:08:59,330 --> 00:09:02,810
something it's not it's not as popular

00:09:01,190 --> 00:09:04,700
as the rest and there was the VG model

00:09:02,810 --> 00:09:08,480
which came out and then in 2014 the

00:09:04,700 --> 00:09:10,310
googoo net model and by 2015 we had

00:09:08,480 --> 00:09:14,150
passed the error rate for human beings

00:09:10,310 --> 00:09:16,400
so by 2015 neural networks way

00:09:14,150 --> 00:09:20,120
identifying objects better than human

00:09:16,400 --> 00:09:24,200
beings all right and then I mean it is

00:09:20,120 --> 00:09:24,710
simply just gone gotten better since

00:09:24,200 --> 00:09:27,170
then

00:09:24,710 --> 00:09:30,170
so neural networks are currently able to

00:09:27,170 --> 00:09:34,970
do some jobs better than humans even

00:09:30,170 --> 00:09:37,670
okay so if you follow tech news and AI

00:09:34,970 --> 00:09:40,580
news you realize that even things like

00:09:37,670 --> 00:09:42,830
predicting cancer you can take a picture

00:09:40,580 --> 00:09:45,440
of something you suspect to be cancer

00:09:42,830 --> 00:09:48,200
and have a neural network tell you

00:09:45,440 --> 00:09:50,720
whether that is cancerous or not or even

00:09:48,200 --> 00:09:54,770
if it is conscious if it is malignant or

00:09:50,720 --> 00:09:56,750
benign okay and yeah there are a lot

00:09:54,770 --> 00:09:59,950
more legendary models that have come out

00:09:56,750 --> 00:10:03,050
so Lynette was I think used to classify

00:09:59,950 --> 00:10:06,820
hand you know like hundred ten digits

00:10:03,050 --> 00:10:09,920
then the Alex net which was in this list

00:10:06,820 --> 00:10:11,780
Google net inception yet the inception

00:10:09,920 --> 00:10:14,450
model maybe I'll talk more about this

00:10:11,780 --> 00:10:17,210
later on in the resonates yeah and then

00:10:14,450 --> 00:10:22,070
there's the yellow yellow stands for you

00:10:17,210 --> 00:10:23,780
only look once and it's a really it's

00:10:22,070 --> 00:10:25,520
mind-boggling the way it works and then

00:10:23,780 --> 00:10:27,770
there's a wide wide and deep network I'm

00:10:25,520 --> 00:10:30,320
not staying too long on this cuz I get

00:10:27,770 --> 00:10:32,540
in there now the research advantage you

00:10:30,320 --> 00:10:36,770
notice that for all the models that I

00:10:32,540 --> 00:10:38,750
should or I mentioned rather as I said

00:10:36,770 --> 00:10:41,630
the image net challenge is usually for

00:10:38,750 --> 00:10:43,670
researchers okay so researchers are

00:10:41,630 --> 00:10:45,830
actually spending time to improve these

00:10:43,670 --> 00:10:48,410
models they are spending time to make

00:10:45,830 --> 00:10:50,800
sure that these models group are getting

00:10:48,410 --> 00:10:54,350
better at what they are doing every year

00:10:50,800 --> 00:10:56,270
this is the Google net and as an example

00:10:54,350 --> 00:10:58,490
of an inception model so for the

00:10:56,270 --> 00:11:01,250
inception model a simple to think about

00:10:58,490 --> 00:11:04,720
it is you have all these little little

00:11:01,250 --> 00:11:06,400
models data feeding data into each other

00:11:04,720 --> 00:11:10,360
and by the time you go through this

00:11:06,400 --> 00:11:12,490
complex soup of of confusion it comes

00:11:10,360 --> 00:11:14,230
out with a very accurate prediction okay

00:11:12,490 --> 00:11:19,360
so this was developed by Google and I

00:11:14,230 --> 00:11:23,550
think was it 2014 and for an everyday

00:11:19,360 --> 00:11:28,660
use of artificial intelligence or Python

00:11:23,550 --> 00:11:32,560
like us it's it's very hard for somebody

00:11:28,660 --> 00:11:35,620
to have that dedication to go through

00:11:32,560 --> 00:11:37,450
the painstaking process of doing this to

00:11:35,620 --> 00:11:42,010
come out with a model that's going to

00:11:37,450 --> 00:11:44,470
classify images you know so well and the

00:11:42,010 --> 00:11:45,970
reason is is simple first of all the

00:11:44,470 --> 00:11:49,690
researcher is paid to figure these

00:11:45,970 --> 00:11:51,580
things out I am NOT don't know if

00:11:49,690 --> 00:11:54,430
anybody has paid to figure out what

00:11:51,580 --> 00:11:56,470
result the researcher is working on

00:11:54,430 --> 00:11:59,890
these kind of problems all the time I

00:11:56,470 --> 00:12:03,460
have a job I'm in school you can add

00:11:59,890 --> 00:12:05,890
your excuse there the researcher

00:12:03,460 --> 00:12:07,300
probably has access to an insane amount

00:12:05,890 --> 00:12:12,100
of processing power like if you're a

00:12:07,300 --> 00:12:14,620
researcher to Google and and I'm working

00:12:12,100 --> 00:12:15,580
at Nikau I I don't have the same amount

00:12:14,620 --> 00:12:18,100
of processing power

00:12:15,580 --> 00:12:20,710
my machine does even have a GPU right I

00:12:18,100 --> 00:12:25,120
have to resort to Google cool lab and

00:12:20,710 --> 00:12:28,150
toggle kennels and alike and finally the

00:12:25,120 --> 00:12:30,580
researcher has mathematical expertise

00:12:28,150 --> 00:12:36,820
and a lot of experience in the industry

00:12:30,580 --> 00:12:40,090
and for some of us dy DX we are done

00:12:36,820 --> 00:12:44,500
yeah although I mean III was an

00:12:40,090 --> 00:12:48,490
engineering major so okay so transfer

00:12:44,500 --> 00:12:50,890
learning yeah now there isn't why I like

00:12:48,490 --> 00:12:53,740
this picture is because if it were

00:12:50,890 --> 00:12:56,589
possible for me to get I don't know

00:12:53,740 --> 00:12:58,480
Dwayne Johnson the rock if you were

00:12:56,589 --> 00:13:02,350
possible for me to exchange bodies with

00:12:58,480 --> 00:13:05,860
him and like I would be so I'll be

00:13:02,350 --> 00:13:10,420
capable of so much more by tomorrow than

00:13:05,860 --> 00:13:14,080
I am now just by you know just exchange

00:13:10,420 --> 00:13:16,240
bodies okay and I mean I've realized and

00:13:14,080 --> 00:13:17,760
III don't know anybody else who who has

00:13:16,240 --> 00:13:20,010
ever thought about this analogy

00:13:17,760 --> 00:13:22,400
that machine learning and deep learning

00:13:20,010 --> 00:13:25,470
and all these things is sewell

00:13:22,400 --> 00:13:27,990
surprisingly similar to a cannot because

00:13:25,470 --> 00:13:31,230
you are training these models with wits

00:13:27,990 --> 00:13:33,180
so there's I like to think of it this

00:13:31,230 --> 00:13:37,220
and weightlifting going on and over time

00:13:33,180 --> 00:13:40,950
a model like this has gotten a lot more

00:13:37,220 --> 00:13:43,950
buff than a model I will build from

00:13:40,950 --> 00:13:47,310
scratch you get it so this is where the

00:13:43,950 --> 00:13:50,460
power transfer learning is that is like

00:13:47,310 --> 00:13:53,340
you want to take a model that already

00:13:50,460 --> 00:13:56,640
exists it does something really well and

00:13:53,340 --> 00:14:00,690
then just apply it to your problem which

00:13:56,640 --> 00:14:03,210
might not be completely related ok so

00:14:00,690 --> 00:14:05,760
your problems might not be what's the

00:14:03,210 --> 00:14:08,520
mode was intended to fix but by virtue

00:14:05,760 --> 00:14:11,580
of the training and the fact that that

00:14:08,520 --> 00:14:14,340
model was was trained on datasets that

00:14:11,580 --> 00:14:17,010
are larger than you have access to on

00:14:14,340 --> 00:14:18,540
systems so that you know maybe if you

00:14:17,010 --> 00:14:21,960
wanted to train that mode on your system

00:14:18,540 --> 00:14:24,120
to take two weeks but somebody had like

00:14:21,960 --> 00:14:26,340
a hundred GPUs and chained it in five

00:14:24,120 --> 00:14:29,370
minutes that's not a realistic figures

00:14:26,340 --> 00:14:32,190
value Trinity may be there in Trinity in

00:14:29,370 --> 00:14:34,610
five minutes you can take what they have

00:14:32,190 --> 00:14:36,480
done and applied to your problem and

00:14:34,610 --> 00:14:40,320
surprisingly it is going to work well

00:14:36,480 --> 00:14:43,730
because that's how human beings actually

00:14:40,320 --> 00:14:46,230
wake everything you learned from say

00:14:43,730 --> 00:14:50,490
kindergarten to high school you are

00:14:46,230 --> 00:14:52,980
probably not using it now but that was

00:14:50,490 --> 00:14:57,120
the foundation upon which what you are

00:14:52,980 --> 00:14:58,830
doing now was built okay so now the

00:14:57,120 --> 00:15:02,600
simple way to look at it so here's our

00:14:58,830 --> 00:15:06,420
transfer learning wakes in a normal

00:15:02,600 --> 00:15:08,700
let's say the Google net model the whole

00:15:06,420 --> 00:15:10,650
model already exists after after you

00:15:08,700 --> 00:15:12,420
train your model it's going to land the

00:15:10,650 --> 00:15:14,340
right width that it needs to do its

00:15:12,420 --> 00:15:17,100
classification so the model exists the

00:15:14,340 --> 00:15:20,550
weights are probably saved somewhere so

00:15:17,100 --> 00:15:22,860
you don't need to Train it from scratch

00:15:20,550 --> 00:15:25,880
you can just not be using it to do your

00:15:22,860 --> 00:15:29,070
your predictions your classifications

00:15:25,880 --> 00:15:31,590
what we need to do is to take out this

00:15:29,070 --> 00:15:35,220
output layer from that model

00:15:31,590 --> 00:15:38,640
and then replace it with our own output

00:15:35,220 --> 00:15:41,370
layer so that all the widths inside the

00:15:38,640 --> 00:15:43,800
pre-trained model remain the same but

00:15:41,370 --> 00:15:46,410
now the output to say in the image Nets

00:15:43,800 --> 00:15:48,650
challenge the a thousand labels but

00:15:46,410 --> 00:15:52,320
maybe I just want to label cats and dogs

00:15:48,650 --> 00:15:54,420
the imagenet layer so the image met

00:15:52,320 --> 00:15:56,100
whatever model I used for the image net

00:15:54,420 --> 00:15:57,630
challenge is going to have a thousand

00:15:56,100 --> 00:16:00,930
outputs because there are thousand

00:15:57,630 --> 00:16:04,890
labels but my model needs to have just

00:16:00,930 --> 00:16:07,410
two so I take out that last layer and I

00:16:04,890 --> 00:16:09,240
replace it with my own last layer which

00:16:07,410 --> 00:16:11,520
just has two nodes which is going to

00:16:09,240 --> 00:16:16,050
tell me whether as a cat or a dog

00:16:11,520 --> 00:16:20,640
and then I retrain the model on my own

00:16:16,050 --> 00:16:23,190
data set of cats and dogs okay I might

00:16:20,640 --> 00:16:26,160
not have the 1 million images in image

00:16:23,190 --> 00:16:29,310
net maybe I just even have 30 images of

00:16:26,160 --> 00:16:31,200
cats and dogs but surprisingly is going

00:16:29,310 --> 00:16:36,540
to be able to take all the learnings it

00:16:31,200 --> 00:16:40,130
has here and apply it to a holistic

00:16:36,540 --> 00:16:43,380
training from the inputs I put in and

00:16:40,130 --> 00:16:46,380
you know retrain my last two outputs and

00:16:43,380 --> 00:16:48,089
perform better than if I were to write

00:16:46,380 --> 00:16:50,760
if I were to write a new model from

00:16:48,089 --> 00:16:56,610
scratch and train it on say 2000 ages of

00:16:50,760 --> 00:16:59,310
cats and dogs so this is the pre trained

00:16:56,610 --> 00:17:00,630
model we are going to change this door

00:16:59,310 --> 00:17:04,069
is not classify I'm going to change it

00:17:00,630 --> 00:17:08,569
to a new classifier new output layer and

00:17:04,069 --> 00:17:11,220
yeah randomly initialize those widths

00:17:08,569 --> 00:17:14,699
yeah the question then is where do you

00:17:11,220 --> 00:17:17,310
find these pre train models and my two

00:17:14,699 --> 00:17:19,860
recommendations for you from if you are

00:17:17,310 --> 00:17:21,439
tensorflow user and I hope you know what

00:17:19,860 --> 00:17:24,060
turns off Louis

00:17:21,439 --> 00:17:27,900
okay so tensorflow is a deep learning

00:17:24,060 --> 00:17:30,780
library created by Google and the other

00:17:27,900 --> 00:17:33,630
is the other favorites in a community

00:17:30,780 --> 00:17:36,150
spy touch PI Taj was created by Facebook

00:17:33,630 --> 00:17:37,470
okay so if you are turns off low user

00:17:36,150 --> 00:17:40,140
you probably want to go to tensorflow

00:17:37,470 --> 00:17:42,820
hub yes there's a flow dot org slash hub

00:17:40,140 --> 00:17:46,860
and you find

00:17:42,820 --> 00:17:49,840
is sort of a library of multiple

00:17:46,860 --> 00:17:52,630
pre-trained models that's do different

00:17:49,840 --> 00:17:55,240
things okay and yeah the beautiful thing

00:17:52,630 --> 00:17:57,340
is that they are actually these models

00:17:55,240 --> 00:18:00,100
where the last layers already removed

00:17:57,340 --> 00:18:02,050
for you so you can download it into your

00:18:00,100 --> 00:18:04,720
code and then you can just append your

00:18:02,050 --> 00:18:07,150
your remaining layers and then you are

00:18:04,720 --> 00:18:09,640
good to go and imp I thought so I don't

00:18:07,150 --> 00:18:10,180
use PI touch too often a few times I've

00:18:09,640 --> 00:18:13,150
done it

00:18:10,180 --> 00:18:15,910
I've used it with the fast AI library so

00:18:13,150 --> 00:18:18,580
if you are if you know tens of live

00:18:15,910 --> 00:18:22,690
probably ahead of Kira's yeah what chaos

00:18:18,580 --> 00:18:25,390
is to tensorflow is what I consider fast

00:18:22,690 --> 00:18:27,330
air to be for pint watch yeah you use it

00:18:25,390 --> 00:18:31,240
first yes it's a very beautiful library

00:18:27,330 --> 00:18:33,280
yeah so I don't know if this can be read

00:18:31,240 --> 00:18:36,370
can anybody see the code you need to

00:18:33,280 --> 00:18:39,850
turn off the light okay yeah so in terms

00:18:36,370 --> 00:18:42,370
of flow with Kira's so this URL here is

00:18:39,850 --> 00:18:47,200
a link to as you can see TF hub dots def

00:18:42,370 --> 00:18:50,290
that's the tensorflow hub link so you

00:18:47,200 --> 00:18:53,020
can find the URL for and this is the

00:18:50,290 --> 00:18:56,740
mobile net yeah the mobile net mobile

00:18:53,020 --> 00:18:59,920
net is sort of like sort of like Google

00:18:56,740 --> 00:19:02,170
net or one of those you know pre-trained

00:18:59,920 --> 00:19:04,240
models that does very well but has been

00:19:02,170 --> 00:19:06,340
optimized for so that you can use it

00:19:04,240 --> 00:19:09,130
with tensorflow light on your phone or

00:19:06,340 --> 00:19:11,380
you know any edge device so that you can

00:19:09,130 --> 00:19:15,100
have the model on device without needing

00:19:11,380 --> 00:19:18,340
to connect directly to the internet so I

00:19:15,100 --> 00:19:21,100
took a mobile net pre-trained model

00:19:18,340 --> 00:19:24,040
without the last without the output

00:19:21,100 --> 00:19:25,960
layer okay and then I'm calling it

00:19:24,040 --> 00:19:29,170
feature extractor because that's all its

00:19:25,960 --> 00:19:31,150
really doing it's going to be extracting

00:19:29,170 --> 00:19:33,580
this part of the model is going to be

00:19:31,150 --> 00:19:37,270
extracting features from your image at

00:19:33,580 --> 00:19:41,130
the same skill as it would probably in

00:19:37,270 --> 00:19:45,370
the image net challenge right and then

00:19:41,130 --> 00:19:48,610
so this is the API call hub Kerris layer

00:19:45,370 --> 00:19:51,790
so you have to import tensorflow hub to

00:19:48,610 --> 00:19:53,320
as a package so have not cast layer then

00:19:51,790 --> 00:19:55,779
you pass in the URL you pass

00:19:53,320 --> 00:19:58,299
in the input ship now if you if you've

00:19:55,779 --> 00:20:00,190
ever built a sequential model in chaos

00:19:58,299 --> 00:20:02,230
you know that the first layer has to

00:20:00,190 --> 00:20:05,350
have a particular ship

00:20:02,230 --> 00:20:08,230
they usually normalize it to a square

00:20:05,350 --> 00:20:10,299
image so this image resolution by image

00:20:08,230 --> 00:20:12,279
resolution times 3 the times 3 is there

00:20:10,299 --> 00:20:14,980
because it's an RGB picture as a color

00:20:12,279 --> 00:20:18,789
picture ok so for the 3 channels of

00:20:14,980 --> 00:20:20,889
color and then this line is very very

00:20:18,789 --> 00:20:23,830
important feature extractor dot

00:20:20,889 --> 00:20:28,659
trainable is equal to false what that

00:20:23,830 --> 00:20:32,080
means is that it should not retrain

00:20:28,659 --> 00:20:35,169
these widths all the width that have

00:20:32,080 --> 00:20:37,240
already been set up in the pre trained

00:20:35,169 --> 00:20:39,940
model should remain the same throughout

00:20:37,240 --> 00:20:43,090
the training so the way deplaning

00:20:39,940 --> 00:20:44,529
waxes that like I said it makes the

00:20:43,090 --> 00:20:45,639
prediction if it makes a mistake it goes

00:20:44,529 --> 00:20:47,620
back to Train it does that with

00:20:45,639 --> 00:20:50,049
something called back propagation with

00:20:47,620 --> 00:20:53,019
back propagation and sort of taking your

00:20:50,049 --> 00:20:55,539
errors and running it through the model

00:20:53,019 --> 00:20:56,679
in Reverse to adjust the width and then

00:20:55,539 --> 00:20:58,240
so it goes back and forth like that

00:20:56,679 --> 00:20:59,710
that's how learning happens goes back

00:20:58,240 --> 00:21:01,990
and forth so it's trained there it's

00:20:59,710 --> 00:21:04,389
very well but we are saying that it

00:21:01,990 --> 00:21:05,919
should not touch this with all the

00:21:04,389 --> 00:21:10,720
training should happen in just the

00:21:05,919 --> 00:21:13,179
output layer ok and then yeah so we set

00:21:10,720 --> 00:21:15,639
the image size ok this is a very silly

00:21:13,179 --> 00:21:19,210
mistake of mine sorry I'm using this

00:21:15,639 --> 00:21:20,980
variable here when I'm now initially I'm

00:21:19,210 --> 00:21:23,830
now initializing the variable here so

00:21:20,980 --> 00:21:27,009
that line should be up ok but once we've

00:21:23,830 --> 00:21:31,059
done this the next thing is to and this

00:21:27,009 --> 00:21:32,799
is why currencies so loved you just you

00:21:31,059 --> 00:21:34,690
say model is equal to TF no Akira's no

00:21:32,799 --> 00:21:40,000
sequential and inside the parameters is

00:21:34,690 --> 00:21:42,250
just a list of all the what the layers

00:21:40,000 --> 00:21:43,809
one by one and int arranges them and

00:21:42,250 --> 00:21:46,090
then handles everything for you so

00:21:43,809 --> 00:21:48,120
instead of what would normally have

00:21:46,090 --> 00:21:51,190
happened is that we would have created

00:21:48,120 --> 00:21:52,870
this layer this layer this layer this

00:21:51,190 --> 00:21:55,559
layer this layer this layer this lettuce

00:21:52,870 --> 00:21:58,539
lettuce led this layer by ourselves and

00:21:55,559 --> 00:22:01,830
then put it inside a sequential model

00:21:58,539 --> 00:22:04,059
for it to be created but with this all

00:22:01,830 --> 00:22:07,740
those layers would have created is

00:22:04,059 --> 00:22:09,210
coming in from this URL into this

00:22:07,740 --> 00:22:13,710
Leia and that's what we are calling

00:22:09,210 --> 00:22:15,840
feature extractor so oh yeah I did a

00:22:13,710 --> 00:22:18,690
number of silly things in this I'll

00:22:15,840 --> 00:22:20,159
switch this back up before so what we

00:22:18,690 --> 00:22:22,110
should have he has modest quantity of

00:22:20,159 --> 00:22:24,210
lockers the sequential and forgets this

00:22:22,110 --> 00:22:26,880
line here replace it in your minds with

00:22:24,210 --> 00:22:28,830
feature extractor I could actually do it

00:22:26,880 --> 00:22:31,140
right now I don't know how much time I

00:22:28,830 --> 00:22:33,590
have left so we are going to have this

00:22:31,140 --> 00:22:35,700
model is equal to the sequential

00:22:33,590 --> 00:22:37,289
sequential model we are going to have

00:22:35,700 --> 00:22:40,860
feature extractor which is going to

00:22:37,289 --> 00:22:43,049
contain the pre-trained model and then

00:22:40,860 --> 00:22:46,760
output layer is just a dance layer so

00:22:43,049 --> 00:22:50,190
just two neurons and then softmax means

00:22:46,760 --> 00:22:52,110
divide the probabilities that it is so

00:22:50,190 --> 00:22:52,890
the probability is a dog a probability

00:22:52,110 --> 00:22:55,350
is a cat

00:22:52,890 --> 00:22:57,570
just split it between the two of them

00:22:55,350 --> 00:22:59,100
okay the two nodes and the higher the

00:22:57,570 --> 00:23:02,880
one denoted the high probability wins

00:22:59,100 --> 00:23:05,340
okay essentially about it so with this

00:23:02,880 --> 00:23:09,510
we have taken the whole pre-trained

00:23:05,340 --> 00:23:12,600
model appended on outputs output layer

00:23:09,510 --> 00:23:14,640
and our model is good to go it's going

00:23:12,600 --> 00:23:17,640
to work a lot better than if we were to

00:23:14,640 --> 00:23:20,250
build it from scratch ourselves and like

00:23:17,640 --> 00:23:24,630
I said first AI is a beautiful library

00:23:20,250 --> 00:23:27,059
in fast AI all we wrote is one line we

00:23:24,630 --> 00:23:27,419
are going to say Lam is equal to convey

00:23:27,059 --> 00:23:30,000
Lena

00:23:27,419 --> 00:23:32,700
so complan is also a package from fast

00:23:30,000 --> 00:23:34,679
yeah you pass in your data and then in

00:23:32,700 --> 00:23:41,549
this case I didn't want use mobile net I

00:23:34,679 --> 00:23:43,320
used resonate but it yes yes so it's

00:23:41,549 --> 00:23:44,880
going to download it if you don't

00:23:43,320 --> 00:23:48,830
already have it downloaded it's going to

00:23:44,880 --> 00:23:58,549
download the whole resonates data for

00:23:48,830 --> 00:24:02,309
pre-trained model yes yes exactly so

00:23:58,549 --> 00:24:05,730
what about models are available through

00:24:02,309 --> 00:24:07,830
this models API you can call and it is

00:24:05,730 --> 00:24:10,590
just going to take the moods without the

00:24:07,830 --> 00:24:12,960
output layer and then you set your

00:24:10,590 --> 00:24:16,799
metrics it's basically derivative so in

00:24:12,960 --> 00:24:19,169
fact I adopted this from the first AI

00:24:16,799 --> 00:24:20,309
costs itself and what's that I think

00:24:19,169 --> 00:24:21,090
yeah I think that was also for

00:24:20,309 --> 00:24:25,260
identifying

00:24:21,090 --> 00:24:27,960
send dogs yeah and this ResNet is one of

00:24:25,260 --> 00:24:29,730
the models that has won the imagenet

00:24:27,960 --> 00:24:32,250
challenge before so you have all that

00:24:29,730 --> 00:24:34,920
power available to you in one line after

00:24:32,250 --> 00:24:37,440
this all you need to do is land outfit

00:24:34,920 --> 00:24:39,920
cycle and then it's it's changed

00:24:37,440 --> 00:24:43,020
everything for you almost automatically

00:24:39,920 --> 00:24:45,630
so what are the advantages of doing this

00:24:43,020 --> 00:24:49,110
first of all training times a whole lot

00:24:45,630 --> 00:24:50,700
faster because somebody has spent that

00:24:49,110 --> 00:24:53,700
time to change this model from scratch

00:24:50,700 --> 00:24:56,100
on about a million images you now don't

00:24:53,700 --> 00:24:59,220
need to train it that's long you can

00:24:56,100 --> 00:25:01,710
train it in five epoxy an epoch is just

00:24:59,220 --> 00:25:03,480
going over the data set once okay

00:25:01,710 --> 00:25:05,340
wondering the same five epochs I need to

00:25:03,480 --> 00:25:09,390
do to do amazingly well for you so

00:25:05,340 --> 00:25:12,090
actually one example somebody took the I

00:25:09,390 --> 00:25:15,530
think was the same resonate and put in

00:25:12,090 --> 00:25:19,080
just 30 images of baseball and cricket

00:25:15,530 --> 00:25:22,800
games and we just 30 images was able to

00:25:19,080 --> 00:25:24,900
classify - I think 98% accuracy with

00:25:22,800 --> 00:25:26,550
just 30 images to differentiate between

00:25:24,900 --> 00:25:29,150
baseball and cricket so it's not

00:25:26,550 --> 00:25:32,850
powerful so you need a lot less data

00:25:29,150 --> 00:25:36,060
sometimes as much as 100 times less - to

00:25:32,850 --> 00:25:40,080
train your model and accuracy generally

00:25:36,060 --> 00:25:42,470
improves by a huge margin final thing is

00:25:40,080 --> 00:25:45,900
smoother learning smoother learning I

00:25:42,470 --> 00:25:49,080
don't really know how I can release it

00:25:45,900 --> 00:25:50,940
for sure how that helps us but it makes

00:25:49,080 --> 00:25:53,850
your graphs look nice that's the least I

00:25:50,940 --> 00:25:57,300
can say yeah so this one I'm talking

00:25:53,850 --> 00:25:59,850
about in the cats versus dogs one so

00:25:57,300 --> 00:26:02,250
this is with tensorflow the blue line is

00:25:59,850 --> 00:26:04,080
representing the training accuracies so

00:26:02,250 --> 00:26:08,430
as you are training you know tensorflow

00:26:04,080 --> 00:26:11,310
has this API you can call to see how

00:26:08,430 --> 00:26:14,190
well you are training and the yellow

00:26:11,310 --> 00:26:17,070
line so the orange line represents the

00:26:14,190 --> 00:26:19,650
validation accuracy so the problem with

00:26:17,070 --> 00:26:21,420
training models is that sometimes your

00:26:19,650 --> 00:26:23,670
model tries to be too smart it tries to

00:26:21,420 --> 00:26:25,680
memorize your data sets and then just

00:26:23,670 --> 00:26:27,150
you know give it back to you like those

00:26:25,680 --> 00:26:29,670
students in class will just chew

00:26:27,150 --> 00:26:31,070
everything and then porn the people when

00:26:29,670 --> 00:26:32,990
you twist the question a little

00:26:31,070 --> 00:26:36,590
lost your mother tries to do that

00:26:32,990 --> 00:26:38,419
sometimes so this is your trainee

00:26:36,590 --> 00:26:41,509
inaccuracy this your validation accuracy

00:26:38,419 --> 00:26:43,450
or validation accuracy is it's testing

00:26:41,509 --> 00:26:46,970
your model on data it hasn't necessarily

00:26:43,450 --> 00:26:50,870
seen during training okay and then this

00:26:46,970 --> 00:26:52,490
is your loss your loss and your training

00:26:50,870 --> 00:26:54,980
losses the blue line and then your

00:26:52,490 --> 00:26:57,049
validation loss is the yellow line so

00:26:54,980 --> 00:26:58,549
around this point where they diverge is

00:26:57,049 --> 00:27:00,169
probably why you should stop training

00:26:58,549 --> 00:27:03,740
otherwise your over fits in your model

00:27:00,169 --> 00:27:05,960
it's just learning too much but you see

00:27:03,740 --> 00:27:08,360
that where their accuracy sort of

00:27:05,960 --> 00:27:09,850
flattens out over here although is roof

00:27:08,360 --> 00:27:15,169
we can guess this may be somewhere like

00:27:09,850 --> 00:27:18,740
82% there about this 0.8 years that the

00:27:15,169 --> 00:27:20,809
percentage so maybe it's 2% and yeah but

00:27:18,740 --> 00:27:23,240
when we come with transfer and in first

00:27:20,809 --> 00:27:27,490
of all that graph is a lot smoother it's

00:27:23,240 --> 00:27:31,370
very clear easy to see and where the

00:27:27,490 --> 00:27:34,159
validation and the validation the

00:27:31,370 --> 00:27:36,289
training intersect is somewhere around

00:27:34,159 --> 00:27:40,070
zero point nine six fact that around

00:27:36,289 --> 00:27:43,490
ninety six point five percent and this

00:27:40,070 --> 00:27:45,740
is just by Turing away or so with the

00:27:43,490 --> 00:27:48,200
first one with this we build the model

00:27:45,740 --> 00:27:51,289
from scratch chained it on so many

00:27:48,200 --> 00:27:55,190
images for I think it was a hundred box

00:27:51,289 --> 00:27:58,370
I used my hundred epochs but this one

00:27:55,190 --> 00:28:00,049
was just 60 boxes on just yeah so you

00:27:58,370 --> 00:28:03,610
can see it's yet zero to a hundred and

00:28:00,049 --> 00:28:08,269
he has zero one two three four five yeah

00:28:03,610 --> 00:28:10,580
so with just five or six epochs ninety

00:28:08,269 --> 00:28:13,129
six point five percent accuracy and I

00:28:10,580 --> 00:28:18,289
was just by beginning it with the mobile

00:28:13,129 --> 00:28:19,789
net pre-trained model so they are the

00:28:18,289 --> 00:28:23,659
notebooks are here that the slash will

00:28:19,789 --> 00:28:27,529
definitely get out so yeah don't worry

00:28:23,659 --> 00:28:29,419
about that finish in one by one all

00:28:27,529 --> 00:28:31,070
right so transfer land in a real life

00:28:29,419 --> 00:28:34,220
like I said I'm Artemis then one of the

00:28:31,070 --> 00:28:37,850
companies this year is actually using

00:28:34,220 --> 00:28:39,130
transfer learning to help with beauty

00:28:37,850 --> 00:28:42,280
and

00:28:39,130 --> 00:28:44,140
you know skin issues this this is my no

00:28:42,280 --> 00:28:47,679
cosmetic side there guys I'm sorry I

00:28:44,140 --> 00:28:49,900
couldn't find a football example yeah so

00:28:47,679 --> 00:28:52,120
is the company's at the mboga

00:28:49,900 --> 00:28:54,640
and the product is bare so what you are

00:28:52,120 --> 00:28:58,299
doing is they've taken the model that's

00:28:54,640 --> 00:29:01,720
used to predict cancer and change the

00:28:58,299 --> 00:29:03,940
output - now get different skin types so

00:29:01,720 --> 00:29:08,620
the ladies you can help me with the skin

00:29:03,940 --> 00:29:13,679
types it is it as dry skin as there

00:29:08,620 --> 00:29:13,679
should be wet skin always risky

00:29:14,730 --> 00:29:22,419
no no so they are they are trying to do

00:29:18,330 --> 00:29:25,659
you know how ladies some guys who

00:29:22,419 --> 00:29:27,520
moisturize and other some people need

00:29:25,659 --> 00:29:29,559
different skin products for different

00:29:27,520 --> 00:29:32,140
skin conditions some people have acne

00:29:29,559 --> 00:29:36,669
some people have I'm really struggling

00:29:32,140 --> 00:29:38,590
to get the yes yes so you are trying to

00:29:36,669 --> 00:29:42,370
predict that from an image so you take a

00:29:38,590 --> 00:29:45,100
selfie and then get you know your

00:29:42,370 --> 00:29:47,909
information on your skin type and then

00:29:45,100 --> 00:29:51,010
know what kind of product will help you

00:29:47,909 --> 00:29:55,030
you understand but there was no model

00:29:51,010 --> 00:29:57,730
like that for general skincare so they

00:29:55,030 --> 00:30:00,520
took a model for predicting skin cancer

00:29:57,730 --> 00:30:03,480
and then change the output so that now

00:30:00,520 --> 00:30:06,580
what they are looking for has to do with

00:30:03,480 --> 00:30:09,460
your skin type and yeah then make some

00:30:06,580 --> 00:30:12,309
inferences from that right so yeah

00:30:09,460 --> 00:30:14,380
unfortunately I'm not on that team so I

00:30:12,309 --> 00:30:15,940
can't give all the details about the

00:30:14,380 --> 00:30:19,659
technology but if you want to find out

00:30:15,940 --> 00:30:24,130
more about them you can go to a DM bulk

00:30:19,659 --> 00:30:25,750
on Instagram you you see at least a few

00:30:24,130 --> 00:30:30,070
things but when it comes out I know the

00:30:25,750 --> 00:30:32,380
ladies you jump on this way so yeah that

00:30:30,070 --> 00:30:34,540
is all for now I welcome your questions

00:30:32,380 --> 00:30:41,270
thank you

00:30:34,540 --> 00:30:41,270
[Applause]

00:30:41,780 --> 00:30:44,849
[Music]

00:30:59,170 --> 00:31:01,200
ooh

00:31:04,130 --> 00:31:55,210
I always try to swatch is possible to

00:31:47,540 --> 00:31:55,210
always try to for example when you start

00:31:58,180 --> 00:32:01,450
you see

00:32:13,760 --> 00:32:16,760
okay

00:33:19,070 --> 00:33:24,990
okay yeah so my recommendations for when

00:33:22,890 --> 00:33:27,930
you don't have a lot of computational

00:33:24,990 --> 00:33:30,780
powers cargo kennels and Google Cola

00:33:27,930 --> 00:33:34,080
because they provide free GPU at least

00:33:30,780 --> 00:33:37,500
for a period okay and if you need to

00:33:34,080 --> 00:33:40,940
exceed the free period you can click I

00:33:37,500 --> 00:33:44,850
think it's as little as fifty cents

00:33:40,940 --> 00:33:50,730
alphabets under it but these platforms

00:33:44,850 --> 00:33:54,570
will help you to access to access GPU

00:33:50,730 --> 00:33:56,340
online that can process these things for

00:33:54,570 --> 00:33:58,680
you so those are my two recommendations

00:33:56,340 --> 00:34:01,650
cargo kennels I think you need a cuddle

00:33:58,680 --> 00:34:04,620
account too everybody thinks kagu you go

00:34:01,650 --> 00:34:06,540
there just to do competitions and the

00:34:04,620 --> 00:34:09,030
like but they have a lot of learning

00:34:06,540 --> 00:34:11,190
resources as well so you yell cargill

00:34:09,030 --> 00:34:13,889
account you have free kennels you can

00:34:11,190 --> 00:34:16,260
use them and your notebooks also stored

00:34:13,889 --> 00:34:17,760
online if you want them to be publicly

00:34:16,260 --> 00:34:19,470
available you can do all that you can

00:34:17,760 --> 00:34:22,740
download them to your machine when you

00:34:19,470 --> 00:34:26,899
finally get a system with you know GPU

00:34:22,740 --> 00:34:51,629
for processing so cargo kennels and

00:34:26,899 --> 00:34:53,610
realizing Google cool um yeah okay so if

00:34:51,629 --> 00:34:56,870
you'd like to go you have if you want to

00:34:53,610 --> 00:34:56,870
continue to ask questions

00:35:02,600 --> 00:35:05,820
the first question Oh about doing

00:35:04,770 --> 00:35:09,750
something end to end

00:35:05,820 --> 00:35:10,290
yeah yeah yeah okay yeah yeah sorry

00:35:09,750 --> 00:35:12,590
about that

00:35:10,290 --> 00:35:16,170
that's because of the limitation of time

00:35:12,590 --> 00:35:19,010
it actually took I don't know it took

00:35:16,170 --> 00:35:21,960
more than the wasn't him

00:35:19,010 --> 00:35:24,780
it took more time than I had to present

00:35:21,960 --> 00:35:27,180
to actually train the models so that's I

00:35:24,780 --> 00:35:28,800
couldn't show training even will GPU

00:35:27,180 --> 00:35:30,720
online so that's how I couldn't show

00:35:28,800 --> 00:35:33,180
training like you know end to end like

00:35:30,720 --> 00:35:35,220
that and for way to host I think Google

00:35:33,180 --> 00:35:39,150
cloud platform is a very good place or

00:35:35,220 --> 00:35:42,240
if you know flash its it's easy to put

00:35:39,150 --> 00:35:44,670
you know wrap your model in a flash

00:35:42,240 --> 00:35:46,320
point in you know put it in dhaka

00:35:44,670 --> 00:35:49,470
kubernetes and put it on the Google

00:35:46,320 --> 00:35:51,630
cloud platform that that is that path I

00:35:49,470 --> 00:35:53,580
would advise because that's scalable

00:35:51,630 --> 00:35:57,330
especially the containerization and all

00:35:53,580 --> 00:35:59,340
that yeah yeah yeah so yeah if you are

00:35:57,330 --> 00:36:02,850
using something mobile so tensorflow

00:35:59,340 --> 00:36:05,700
lights you can also wrap your your model

00:36:02,850 --> 00:36:07,050
in a java application and run it on an

00:36:05,700 --> 00:36:30,890
Android device or something like that

00:36:07,050 --> 00:36:33,890
yeah was it this okay okay okay okay

00:36:30,890 --> 00:36:33,890
yes

00:36:35,010 --> 00:36:40,359
yeah typically one layer I'm yet to see

00:36:38,200 --> 00:36:43,180
somebody add more than one layer but

00:36:40,359 --> 00:36:45,250
even if you add more than one layer the

00:36:43,180 --> 00:36:46,839
last layer the last output layer should

00:36:45,250 --> 00:37:10,660
be the number of classes you are trying

00:36:46,839 --> 00:37:16,119
to you know classify yes yes how much

00:37:10,660 --> 00:37:18,940
time will it take to dream it can I can

00:37:16,119 --> 00:37:25,319
take let me see the first one to come

00:37:18,940 --> 00:37:28,920
out okay so from the example I I did

00:37:25,319 --> 00:37:31,839
yeah okay so it took it took let me say

00:37:28,920 --> 00:37:34,059
it took about 15 minutes to train on

00:37:31,839 --> 00:37:38,500
those six epochs with the mobile net

00:37:34,059 --> 00:37:39,970
layer about 15 minutes yeah yes no I

00:37:38,500 --> 00:37:41,890
have not moved

00:37:39,970 --> 00:37:47,049
no yeah I used the mobile net Slayer but

00:37:41,890 --> 00:37:51,490
I did not expose it to Android yes I

00:37:47,049 --> 00:37:55,029
just trained it no on cool up on column

00:37:51,490 --> 00:37:56,650
yes and without mobile nets that one

00:37:55,029 --> 00:37:57,160
took about an hour like I got up and

00:37:56,650 --> 00:37:59,529
left

00:37:57,160 --> 00:38:02,170
and it was training oh yeah that was

00:37:59,529 --> 00:38:05,549
training from scratch before I did it

00:38:02,170 --> 00:38:05,549
with mobile nets as a

00:38:13,240 --> 00:38:15,900
hello

00:38:47,559 --> 00:38:54,829
okay one of the problems of data science

00:38:52,069 --> 00:38:58,039
as it is is that it's to a certain

00:38:54,829 --> 00:39:01,249
extent the practitioners what we really

00:38:58,039 --> 00:39:04,400
will tell you it is still a bit of an

00:39:01,249 --> 00:39:07,279
act although it's data science to know

00:39:04,400 --> 00:39:08,599
what Warwick it develops a certain you

00:39:07,279 --> 00:39:12,109
need to develop a certain amount of

00:39:08,599 --> 00:39:14,329
intuition but however for something like

00:39:12,109 --> 00:39:17,690
the cancer thing I mentioned they are

00:39:14,329 --> 00:39:19,039
testing cancer on skin already so there

00:39:17,690 --> 00:39:21,079
was that bit of intuition if it's

00:39:19,039 --> 00:39:23,269
working for some sort of skin condition

00:39:21,079 --> 00:39:25,940
maybe it can expand and work for other

00:39:23,269 --> 00:39:29,029
things okay but let's say the way it was

00:39:25,940 --> 00:39:32,150
testing for cars different brands of

00:39:29,029 --> 00:39:34,819
cars that doesn't really relate so much

00:39:32,150 --> 00:39:36,950
to skin so I think if you can find a bit

00:39:34,819 --> 00:39:39,289
of correlation between the two domains

00:39:36,950 --> 00:39:41,569
the domain the model was built for and

00:39:39,289 --> 00:39:44,200
you may want to apply it to that's a bit

00:39:41,569 --> 00:39:46,999
of a good indicator but if you want

00:39:44,200 --> 00:39:48,769
rock-solid way to choose a model you

00:39:46,999 --> 00:39:50,960
should probably read the research papers

00:39:48,769 --> 00:39:53,299
associated with the model the people who

00:39:50,960 --> 00:39:57,079
built the model have all the math

00:39:53,299 --> 00:39:59,210
figured out and what went into building

00:39:57,079 --> 00:40:01,099
the model why they think it works as

00:39:59,210 --> 00:40:03,349
well as it does so if you able to read

00:40:01,099 --> 00:40:06,349
your research you can get a good sense

00:40:03,349 --> 00:40:12,380
of what else it might work for based on

00:40:06,349 --> 00:40:15,700
that domains attributes here so I guess

00:40:12,380 --> 00:40:15,700
this one has be enough

00:40:24,450 --> 00:40:31,600
okay what you need first of all is a

00:40:28,270 --> 00:40:33,040
willingness to learn because as you

00:40:31,600 --> 00:40:34,690
realize that any field of software

00:40:33,040 --> 00:40:40,270
engineer you never stop learning

00:40:34,690 --> 00:40:42,970
like people are doing Python - for so

00:40:40,270 --> 00:40:45,250
long now today keynote is talking about

00:40:42,970 --> 00:40:49,020
their what did you see

00:40:45,250 --> 00:40:52,840
night time on Python - like you know a

00:40:49,020 --> 00:40:54,430
sunset on Python - so you always you

00:40:52,840 --> 00:40:56,260
have to have the willingness to learn

00:40:54,430 --> 00:40:59,140
but like I said Cargill is a

00:40:56,260 --> 00:41:01,690
surprisingly good place to learn data

00:40:59,140 --> 00:41:04,000
science because they have tutorials they

00:41:01,690 --> 00:41:07,420
have so many data sets they have

00:41:04,000 --> 00:41:09,010
competitions so there's actually all

00:41:07,420 --> 00:41:11,230
those structures and one of the

00:41:09,010 --> 00:41:13,750
resources of really is this Udacity so

00:41:11,230 --> 00:41:15,670
yes even like these images you see down

00:41:13,750 --> 00:41:18,070
here it says Google Udacity tens of

00:41:15,670 --> 00:41:19,840
locos none day I don't know if you can

00:41:18,070 --> 00:41:23,230
read it yeah these images were taken

00:41:19,840 --> 00:41:25,330
from dusk also Google rolled out this

00:41:23,230 --> 00:41:27,910
new tensorflow course it's supposed to

00:41:25,330 --> 00:41:30,370
prime you for tensor flow 2.0 so

00:41:27,910 --> 00:41:33,220
actually a lot of the code that you saw

00:41:30,370 --> 00:41:35,770
there was more like tensor flow 1.3 and

00:41:33,220 --> 00:41:36,910
they are shifting to tensor flow - so

00:41:35,770 --> 00:41:41,590
like I said if you're not willing to

00:41:36,910 --> 00:41:43,960
lend you be obsolete so Udacity I've not

00:41:41,590 --> 00:41:44,800
used udemy so much but Udacity Coursera

00:41:43,960 --> 00:41:48,000
yeah

00:41:44,800 --> 00:41:51,400
Coursera under inks course is very good

00:41:48,000 --> 00:41:55,450
if you like YouTube videos see Raja Raja

00:41:51,400 --> 00:42:01,510
Rao Bhau yes I mean you guys Commission

00:41:55,450 --> 00:42:02,740
is treehouse yeah yeah there are a lot

00:42:01,510 --> 00:42:04,960
of people in this room who can answer

00:42:02,740 --> 00:42:07,180
that question on the various parts

00:42:04,960 --> 00:42:08,980
they've taken but yeah a good place

00:42:07,180 --> 00:42:09,340
where you get everything at once its

00:42:08,980 --> 00:42:11,020
cargo

00:42:09,340 --> 00:42:16,300
you have your candles you have your data

00:42:11,020 --> 00:42:19,890
you have tutorials oh yeah this stuff

00:42:16,300 --> 00:42:19,890
from scratch it's not from scratch yeah

00:42:49,200 --> 00:42:57,910
skin types and beauty yes it takes

00:42:55,749 --> 00:43:02,339
learnings from one domain you can apply

00:42:57,910 --> 00:43:02,339
to another domain like almost seamlessly

00:43:09,420 --> 00:43:16,690
for leaves that sounds interesting

00:43:13,859 --> 00:43:19,660
probably now somebody first think a leaf

00:43:16,690 --> 00:43:24,400
is green skin is not but there's

00:43:19,660 --> 00:43:26,319
actually been or there's this idea or

00:43:24,400 --> 00:43:30,059
this hypothesis that color doesn't

00:43:26,319 --> 00:43:33,460
matter as much as other features in

00:43:30,059 --> 00:43:35,859
image classification so there might

00:43:33,460 --> 00:43:39,819
actually be that possibility that maybe

00:43:35,859 --> 00:43:42,729
you can you can identify some diseased

00:43:39,819 --> 00:43:44,200
plants disease when they live by using

00:43:42,729 --> 00:43:47,499
something else originally trained for

00:43:44,200 --> 00:43:49,869
cancer yeah but a lot of the time these

00:43:47,499 --> 00:43:53,410
things tend to be research topics in the

00:43:49,869 --> 00:43:56,190
end people research on this like I said

00:43:53,410 --> 00:43:56,190
they appear to

00:43:58,480 --> 00:44:06,539

YouTube URL: https://www.youtube.com/watch?v=y-xQ8gepxo8


