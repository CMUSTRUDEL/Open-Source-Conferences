Title: 2013 SouthEast LinuxFest - Boyd Wilson - OrangeFS: Next Generation Parallel Scale out File System
Publication date: 2015-04-18
Playlist: 2013 SouthEast LinuxFest
Description: 
	2013 SouthEast LinuxFest
Boyd Wilson
OrangeFS: Next Generation Parallel Scale out File System
Captions: 
	00:00:00,000 --> 00:00:05,160
the following presentation was recorded

00:00:02,639 --> 00:00:08,280
at the 2013 southeast linux fest in

00:00:05,160 --> 00:00:10,860
charlotte north carolina it is licensed

00:00:08,280 --> 00:00:12,509
under a creative commons license for

00:00:10,860 --> 00:00:16,619
more information about the southeast

00:00:12,509 --> 00:00:19,830
linux fest visit WWF eastland TX phase

00:00:16,619 --> 00:00:21,600
or the southeast linux fest would like

00:00:19,830 --> 00:00:24,000
to thank the following diamond sponsors

00:00:21,600 --> 00:00:28,289
in 2013 for helping make these videos

00:00:24,000 --> 00:00:32,160
possible selective welcome everyone out

00:00:28,289 --> 00:00:36,090
got a few hanging on till the end I'm

00:00:32,160 --> 00:00:38,160
impressed on a Saturday yes the keynote

00:00:36,090 --> 00:00:42,239
helps that I wanted to just take a

00:00:38,160 --> 00:00:44,070
second and ask a couple questions how

00:00:42,239 --> 00:00:46,039
many of you are familiar with parallel

00:00:44,070 --> 00:00:48,809
file systems kind of know what they are

00:00:46,039 --> 00:00:50,730
connect me a show of hands how many of

00:00:48,809 --> 00:00:53,219
you have maybe not really heard of them

00:00:50,730 --> 00:00:56,670
before kind of new to them we've got a

00:00:53,219 --> 00:01:01,170
couple okay excellent want to spend the

00:00:56,670 --> 00:01:04,080
next hour talking about next-generation

00:01:01,170 --> 00:01:06,630
parallel file system kind of tell you a

00:01:04,080 --> 00:01:09,320
little more about it our agenda will be

00:01:06,630 --> 00:01:11,700
kind of just over an introduction a

00:01:09,320 --> 00:01:12,990
parallel file systems then we'll talk

00:01:11,700 --> 00:01:14,430
about the current highlights in orange

00:01:12,990 --> 00:01:16,200
FS and then we'll talk about some

00:01:14,430 --> 00:01:19,799
futures and even some research features

00:01:16,200 --> 00:01:23,009
after that if I don't talk too much stop

00:01:19,799 --> 00:01:24,930
me along the way ask questions I'll

00:01:23,009 --> 00:01:29,390
remember to repeat the question so the

00:01:24,930 --> 00:01:33,240
recording can hear it then let's dig in

00:01:29,390 --> 00:01:35,549
so a lot of words up there for a slide

00:01:33,240 --> 00:01:38,130
but orange FS next-generation parallel

00:01:35,549 --> 00:01:41,850
file system it's the next generation of

00:01:38,130 --> 00:01:47,040
PDF SPV FS has been through many years

00:01:41,850 --> 00:01:49,229
of iterations and we're actually just 23

00:01:47,040 --> 00:01:54,140
years ago started doing some heavy work

00:01:49,229 --> 00:01:58,290
bringing it to kind of modern features

00:01:54,140 --> 00:02:02,189
modern modern concepts kind of some of

00:01:58,290 --> 00:02:04,770
the basics are it distributes file data

00:02:02,189 --> 00:02:08,640
across multiple file server so you take

00:02:04,770 --> 00:02:11,280
any number of storage servers can be any

00:02:08,640 --> 00:02:13,290
type of system you want you can put you

00:02:11,280 --> 00:02:16,470
know just servers with J bods in it you

00:02:13,290 --> 00:02:18,090
could do SAS attached you could do fibre

00:02:16,470 --> 00:02:19,769
channel attached storage behind any of

00:02:18,090 --> 00:02:21,480
these you know really depending on

00:02:19,769 --> 00:02:22,950
whatever Hardware you have whatever you

00:02:21,480 --> 00:02:25,920
want to do you can even run them on

00:02:22,950 --> 00:02:28,620
instances in the cloud I'll get to that

00:02:25,920 --> 00:02:30,959
in a little bit but essentially you

00:02:28,620 --> 00:02:33,540
build a storage block you decide what

00:02:30,959 --> 00:02:35,129
your optimal performance is for your

00:02:33,540 --> 00:02:37,049
network pipe out of that and then you

00:02:35,129 --> 00:02:38,430
kind of replicate that and they don't

00:02:37,049 --> 00:02:40,110
have to be exact you know this isn't

00:02:38,430 --> 00:02:41,459
everything has to be concrete across it

00:02:40,110 --> 00:02:44,489
and you build a virtual file system

00:02:41,459 --> 00:02:46,680
across it and with that virtual file

00:02:44,489 --> 00:02:48,239
system you get the scalability and the

00:02:46,680 --> 00:02:50,310
storage capability of all the storage

00:02:48,239 --> 00:02:52,799
nodes you put into it so that's kind of

00:02:50,310 --> 00:02:54,720
the the concept no matter what client

00:02:52,799 --> 00:02:55,680
accesses they all see all the name space

00:02:54,720 --> 00:02:58,079
you know as long as they have

00:02:55,680 --> 00:03:01,590
permissions and it kind of goes from

00:02:58,079 --> 00:03:04,019
there some unique things about orange FS

00:03:01,590 --> 00:03:05,970
is it actually distributes metadata

00:03:04,019 --> 00:03:08,160
across the same storage nodes depending

00:03:05,970 --> 00:03:09,810
on your configuration so you can say oh

00:03:08,160 --> 00:03:12,060
I want a single metadata server put it

00:03:09,810 --> 00:03:14,760
over here or I can separate the metadata

00:03:12,060 --> 00:03:16,920
server metadata is ascending a lot of

00:03:14,760 --> 00:03:20,750
your file attributes permissions those

00:03:16,920 --> 00:03:23,700
types of things and with distributed

00:03:20,750 --> 00:03:26,100
file systems or parallel file systems

00:03:23,700 --> 00:03:27,660
metadata can be a performance bottleneck

00:03:26,100 --> 00:03:30,420
if you have lots of small files lots of

00:03:27,660 --> 00:03:33,359
small I oh so it's good to distribute

00:03:30,420 --> 00:03:34,980
that and you can even distribute that

00:03:33,359 --> 00:03:36,900
across SSDs and we'll get into that a

00:03:34,980 --> 00:03:38,670
little bit that's kind of that concept

00:03:36,900 --> 00:03:43,799
of aggregating and providing high

00:03:38,670 --> 00:03:47,099
performance it also has parallel clients

00:03:43,799 --> 00:03:48,510
that leverage the PDF s protocol so as

00:03:47,099 --> 00:03:51,120
you write your data across all these

00:03:48,510 --> 00:03:52,739
storage nodes you don't have to write to

00:03:51,120 --> 00:03:55,440
one place so then it kind of handles it

00:03:52,739 --> 00:03:56,819
for you is a bottleneck the client can

00:03:55,440 --> 00:03:59,099
go figure out where it needs to write

00:03:56,819 --> 00:04:01,139
and then write the data concurrently or

00:03:59,099 --> 00:04:03,480
vice versa read the data concurrently

00:04:01,139 --> 00:04:07,380
off of the storage nodes that the data

00:04:03,480 --> 00:04:10,230
striped across so we and to kind of

00:04:07,380 --> 00:04:13,169
reach out the Corps servers run on Linux

00:04:10,230 --> 00:04:16,130
but the clients we've actually have you

00:04:13,169 --> 00:04:18,570
know Linux you can do the kernel module

00:04:16,130 --> 00:04:20,310
fuse as well Mac you can do you use

00:04:18,570 --> 00:04:22,620
Windows has a Native Client and then

00:04:20,310 --> 00:04:26,790
there's a jni Java client and there's a

00:04:22,620 --> 00:04:28,380
MapReduce client for Hadoop kind of let

00:04:26,790 --> 00:04:29,970
you natively use that instead of HDFS

00:04:28,380 --> 00:04:31,920
we'll get into that work sustainable

00:04:29,970 --> 00:04:34,080
standard Colonel releases you don't need

00:04:31,920 --> 00:04:37,800
to go in and that a whole bunch of

00:04:34,080 --> 00:04:40,290
custom code it's just a kernel module in

00:04:37,800 --> 00:04:43,560
some odd and then you're ready to go or

00:04:40,290 --> 00:04:45,060
you can just use the views module if you

00:04:43,560 --> 00:04:47,850
want as well kernel modules a little

00:04:45,060 --> 00:04:49,740
faster you can do currently high

00:04:47,850 --> 00:04:53,760
availability with heartbeat between

00:04:49,740 --> 00:04:55,410
nodes doing something like drbd or dual

00:04:53,760 --> 00:04:58,020
attached to raise on the backend and you

00:04:55,410 --> 00:04:59,310
can fail over between nodes in the

00:04:58,020 --> 00:05:00,960
future we'll get into this and some

00:04:59,310 --> 00:05:02,970
slides though we're actually going to

00:05:00,960 --> 00:05:04,350
build high availability into the native

00:05:02,970 --> 00:05:06,210
file system so you don't even have to

00:05:04,350 --> 00:05:13,920
worry about that that's kind of our next

00:05:06,210 --> 00:05:15,420
big push in development so why parallel

00:05:13,920 --> 00:05:20,100
file systems where did they start where

00:05:15,420 --> 00:05:21,300
did they come from a lot of the work has

00:05:20,100 --> 00:05:24,390
been done over the years for high

00:05:21,300 --> 00:05:30,600
performance computing kind of real fixed

00:05:24,390 --> 00:05:32,640
needs fixed problems if you will and you

00:05:30,600 --> 00:05:34,320
know the code was kind of covered those

00:05:32,640 --> 00:05:36,870
problems and then if you tried to do

00:05:34,320 --> 00:05:39,090
kind of real-world usage but did fit

00:05:36,870 --> 00:05:41,100
into those use cases you know things

00:05:39,090 --> 00:05:42,930
would not work as well so it kind of

00:05:41,100 --> 00:05:44,820
started there but as we've gone over the

00:05:42,930 --> 00:05:47,340
last four years we're hardening it

00:05:44,820 --> 00:05:48,720
bringing in that you know main core main

00:05:47,340 --> 00:05:51,390
features so people can use it for

00:05:48,720 --> 00:05:52,950
everyday use you know it's really good

00:05:51,390 --> 00:05:55,620
for large data sets checkpointing

00:05:52,950 --> 00:05:57,030
visualization video storage big data

00:05:55,620 --> 00:06:00,330
analytics you know that's kind of its

00:05:57,030 --> 00:06:02,100
sweet spot anything where you're you

00:06:00,330 --> 00:06:03,630
know dealing with any size files if you

00:06:02,100 --> 00:06:05,880
need to concurrent access to terabyte

00:06:03,630 --> 00:06:08,970
files it does a very good job if it you

00:06:05,880 --> 00:06:12,990
know you need to store some unstructured

00:06:08,970 --> 00:06:16,590
data for you know 100k or one Meg files

00:06:12,990 --> 00:06:18,720
it does good I wouldn't put a ton of 4k

00:06:16,590 --> 00:06:21,090
files on it inspect a whole bunch of

00:06:18,720 --> 00:06:22,620
access just because of the metadata your

00:06:21,090 --> 00:06:24,210
metadata overhead is about the same as

00:06:22,620 --> 00:06:26,070
your file i/o we're going to do some

00:06:24,210 --> 00:06:28,340
things in the future that may help with

00:06:26,070 --> 00:06:28,340
that

00:06:28,729 --> 00:06:33,660
it also provides the ability to just

00:06:31,919 --> 00:06:35,550
kind of brink because it scales

00:06:33,660 --> 00:06:37,979
horizontally as you add storage nodes

00:06:35,550 --> 00:06:41,160
you don't have to worry about how much

00:06:37,979 --> 00:06:44,900
storage can I sit behind this NFS you

00:06:41,160 --> 00:06:46,949
know that point or NFS server and then

00:06:44,900 --> 00:06:48,509
you know because each time you add

00:06:46,949 --> 00:06:49,830
storage know the clients can access

00:06:48,509 --> 00:06:51,600
where it needs to go and get that high

00:06:49,830 --> 00:06:54,000
throughput so you can actually take a

00:06:51,600 --> 00:06:56,370
bunch of diverse NFS servers bring them

00:06:54,000 --> 00:06:58,380
together an aggregate a file system

00:06:56,370 --> 00:07:01,199
across all of them and then you kind of

00:06:58,380 --> 00:07:05,510
leverage the bandwidth and storage as it

00:07:01,199 --> 00:07:05,510
goes across all the storage nodes

00:07:06,020 --> 00:07:10,229
there's some interfaces allow you do

00:07:08,460 --> 00:07:13,740
some specific type data about

00:07:10,229 --> 00:07:15,479
dimensional arrays and portable formats

00:07:13,740 --> 00:07:16,620
I can't even remember what that means

00:07:15,479 --> 00:07:21,210
all of the oak I mean if a couple

00:07:16,620 --> 00:07:23,910
minutes formats storage servers kind of

00:07:21,210 --> 00:07:26,250
talked about this so any storage server

00:07:23,910 --> 00:07:27,840
can be an i/o or a metadata server so

00:07:26,250 --> 00:07:30,090
when you set up your configuration you

00:07:27,840 --> 00:07:32,639
go into your config file set it up you

00:07:30,090 --> 00:07:35,849
determine what wants to be what there's

00:07:32,639 --> 00:07:39,479
a 64-bit address space when you're

00:07:35,849 --> 00:07:42,900
setting up your servers where you set up

00:07:39,479 --> 00:07:44,280
ranges for each server and if you want

00:07:42,900 --> 00:07:46,590
to be able to expand the file system

00:07:44,280 --> 00:07:48,090
which currently takes you know a service

00:07:46,590 --> 00:07:53,880
restart on all the nodes but then you

00:07:48,090 --> 00:07:56,190
can add nodes as you want you have to

00:07:53,880 --> 00:07:57,630
kind of leave some reserve range and

00:07:56,190 --> 00:07:59,340
those file handles in your config file

00:07:57,630 --> 00:08:02,310
so I mean there's documentation on that

00:07:59,340 --> 00:08:03,599
but it's a good thing to point out files

00:08:02,310 --> 00:08:04,970
trifling so kind of talked about you

00:08:03,599 --> 00:08:07,530
could take a single file large file

00:08:04,970 --> 00:08:09,630
write it across multiple storage knows

00:08:07,530 --> 00:08:11,820
well sometimes you may not want a file

00:08:09,630 --> 00:08:13,440
written across all the storage nodes in

00:08:11,820 --> 00:08:15,870
my file system maybe I only want it on

00:08:13,440 --> 00:08:18,810
four nodes or eight nodes you know maybe

00:08:15,870 --> 00:08:20,580
this is a small directory and I really

00:08:18,810 --> 00:08:22,500
small files I want to store in this

00:08:20,580 --> 00:08:25,470
directory but you can configure how it

00:08:22,500 --> 00:08:26,610
striped across you know each directory

00:08:25,470 --> 00:08:28,080
you can see this directory is configured

00:08:26,610 --> 00:08:29,460
this way this directors configured that

00:08:28,080 --> 00:08:34,229
way and there's also a default across

00:08:29,460 --> 00:08:36,029
the whole file system metadata already

00:08:34,229 --> 00:08:37,770
talked about that there's kind of the

00:08:36,029 --> 00:08:42,810
clients webdav and s3 wasn't mentioned

00:08:37,770 --> 00:08:46,360
earlier same type of setup there though

00:08:42,810 --> 00:08:47,890
kind of the original design goals were

00:08:46,360 --> 00:08:51,610
configurable file striping

00:08:47,890 --> 00:08:53,290
non-contiguous i/o patterns don't get a

00:08:51,610 --> 00:08:55,029
lot into this but there's actually some

00:08:53,290 --> 00:08:57,880
optimizations in the file system to let

00:08:55,029 --> 00:09:00,100
you do n piao work so you can do

00:08:57,880 --> 00:09:01,600
concurrent access and some straited

00:09:00,100 --> 00:09:03,430
rights and some very interesting things

00:09:01,600 --> 00:09:06,149
like that if your applications need it

00:09:03,430 --> 00:09:12,220
to really beef up the performance for

00:09:06,149 --> 00:09:14,649
hpc MPI jobs you know a lot of the goal

00:09:12,220 --> 00:09:16,060
is just get out of the way of the reeds

00:09:14,649 --> 00:09:18,040
and the rights because as you're scaling

00:09:16,060 --> 00:09:20,140
you really want the data written you

00:09:18,040 --> 00:09:22,000
want it written fast and when you're

00:09:20,140 --> 00:09:23,680
dealing with this much data you're not

00:09:22,000 --> 00:09:29,070
going to be able to cash I just get it

00:09:23,680 --> 00:09:32,320
to disk and get out of the way usability

00:09:29,070 --> 00:09:33,880
very easy to install the VFS kernel

00:09:32,320 --> 00:09:35,470
module that I mentioned earlier it's

00:09:33,880 --> 00:09:41,140
really small it's not like this big huge

00:09:35,470 --> 00:09:45,940
nasty thing very easy to install modular

00:09:41,140 --> 00:09:49,779
easy to extend oh yeah if you do it kind

00:09:45,940 --> 00:09:51,490
of do a search for PV fs2 you'll see

00:09:49,779 --> 00:09:54,250
that tons of research papers have been

00:09:51,490 --> 00:09:55,870
done on it and grad students will go in

00:09:54,250 --> 00:09:57,730
and extend it and do those types of

00:09:55,870 --> 00:09:59,920
things and so as we kind of move towards

00:09:57,730 --> 00:10:01,899
orange FS wanted to keep that that tide

00:09:59,920 --> 00:10:03,520
of research so we could have very

00:10:01,899 --> 00:10:05,079
interesting things built on the file

00:10:03,520 --> 00:10:08,829
system eventually bring them into the

00:10:05,079 --> 00:10:10,720
main line so that's was very important

00:10:08,829 --> 00:10:13,300
in verse clients seem to mention that a

00:10:10,720 --> 00:10:16,899
lot here we go you know and I kind of

00:10:13,300 --> 00:10:19,690
mentioned before these file systems kind

00:10:16,899 --> 00:10:22,149
of focused on a specific set of use

00:10:19,690 --> 00:10:24,040
cases but you know as we've been

00:10:22,149 --> 00:10:25,300
developing the test cases of weed LMAO

00:10:24,040 --> 00:10:27,670
in the automated testing we've been

00:10:25,300 --> 00:10:29,290
trying to really build out the broader

00:10:27,670 --> 00:10:30,610
set of applications so you can use it

00:10:29,290 --> 00:10:33,370
with this it'll work you can use it with

00:10:30,610 --> 00:10:36,089
that it will work just fine customer and

00:10:33,370 --> 00:10:39,160
community focused completely open source

00:10:36,089 --> 00:10:41,980
we don't have or don't plan on doing any

00:10:39,160 --> 00:10:43,810
closed source add-ons or you is or

00:10:41,980 --> 00:10:46,029
anything that they'll kind of you know

00:10:43,810 --> 00:10:48,670
you have to like home holding hostage so

00:10:46,029 --> 00:10:52,079
you have to pay for them commercially

00:10:48,670 --> 00:10:52,079
viable and then enable research

00:10:52,820 --> 00:10:56,820
so one of the things you kind of face

00:10:55,440 --> 00:10:59,490
when you're working on a file system

00:10:56,820 --> 00:11:01,050
rather the competing requirements

00:10:59,490 --> 00:11:02,580
obviously have your performance or

00:11:01,050 --> 00:11:07,440
reliability and then your data

00:11:02,580 --> 00:11:08,940
consistency and as you think about

00:11:07,440 --> 00:11:10,500
different things that are important to

00:11:08,940 --> 00:11:13,830
you you might give up some of the other

00:11:10,500 --> 00:11:17,760
but you can't have all of those cases

00:11:13,830 --> 00:11:20,160
available to you all the time so what

00:11:17,760 --> 00:11:22,170
we've kind of gone to a concept of is as

00:11:20,160 --> 00:11:24,180
you're looking at this file system

00:11:22,170 --> 00:11:25,590
there's ways you can configure it to be

00:11:24,180 --> 00:11:27,990
a little more reliable or you can

00:11:25,590 --> 00:11:30,990
configure it hey consistency is more

00:11:27,990 --> 00:11:33,570
important or hey I can live with a

00:11:30,990 --> 00:11:36,510
little bit time ding consistency a

00:11:33,570 --> 00:11:38,220
little more eventual consistency and

00:11:36,510 --> 00:11:40,260
then get some of those performance

00:11:38,220 --> 00:11:42,060
benefits of that so as we're kind of

00:11:40,260 --> 00:11:43,620
heading towards version 3 there's kind

00:11:42,060 --> 00:11:44,970
of that concept of configuration you'll

00:11:43,620 --> 00:11:47,520
see a little bit of that I'm going to

00:11:44,970 --> 00:11:50,340
talk about 29 there's actually an

00:11:47,520 --> 00:11:53,610
interesting fourth period point on the

00:11:50,340 --> 00:11:57,420
pyramid which is security which kind of

00:11:53,610 --> 00:12:01,860
impacts against performance there

00:11:57,420 --> 00:12:04,740
competes against performance so the

00:12:01,860 --> 00:12:06,540
system architecture it's very

00:12:04,740 --> 00:12:08,340
straightforward modular architecture and

00:12:06,540 --> 00:12:10,290
the whole concept is there's objects and

00:12:08,340 --> 00:12:12,960
everyone's heard of object stores and

00:12:10,290 --> 00:12:14,640
knows about him but the objects

00:12:12,960 --> 00:12:16,200
essentially were designed and then a

00:12:14,640 --> 00:12:19,230
file system was built on top it was

00:12:16,200 --> 00:12:20,640
never intended to be an object store but

00:12:19,230 --> 00:12:24,300
there is an object store underneath if

00:12:20,640 --> 00:12:26,190
you understand where I'm going object

00:12:24,300 --> 00:12:27,330
store data or metadata there's kind of

00:12:26,190 --> 00:12:30,300
an interface there i'll show you in the

00:12:27,330 --> 00:12:32,250
architecture diagram how that fits you

00:12:30,300 --> 00:12:37,590
know request protocol specifies

00:12:32,250 --> 00:12:39,290
operations on one or many objects it

00:12:37,590 --> 00:12:43,140
uses a distributed database for indexing

00:12:39,290 --> 00:12:45,150
distributed metadata for the ins key

00:12:43,140 --> 00:12:46,650
value store currently we use berkeley DB

00:12:45,150 --> 00:12:49,200
we're looking at some other things for

00:12:46,650 --> 00:12:52,500
30 possibly MDB if you're familiar with

00:12:49,200 --> 00:12:55,560
that local block file system that's

00:12:52,500 --> 00:12:57,000
where we you put your data streams part

00:12:55,560 --> 00:12:58,620
of the file this one to each file it's

00:12:57,000 --> 00:13:01,160
on whatever local file system you want

00:12:58,620 --> 00:13:01,160
within that

00:13:03,400 --> 00:13:07,670
so there's kind of little overview of

00:13:05,540 --> 00:13:10,190
the architecture you can see there's

00:13:07,670 --> 00:13:12,260
some common code between the two BMI

00:13:10,190 --> 00:13:16,130
allows you to handle the multiple

00:13:12,260 --> 00:13:17,900
network protocols ibtc PMX portals you

00:13:16,130 --> 00:13:20,660
know it's very easy not very easy it's

00:13:17,900 --> 00:13:23,330
it's possible to come in and plug in

00:13:20,660 --> 00:13:26,650
other protocols and not impact any of

00:13:23,330 --> 00:13:29,540
the code up above that there's your DB

00:13:26,650 --> 00:13:31,250
on the server side your local file

00:13:29,540 --> 00:13:33,170
system trove kind of handles the rights

00:13:31,250 --> 00:13:35,270
to that so you it's an abstraction layer

00:13:33,170 --> 00:13:39,350
you can actually build another database

00:13:35,270 --> 00:13:41,600
or you know file i/o interfaces you know

00:13:39,350 --> 00:13:42,920
you can replace the i/o driver the

00:13:41,600 --> 00:13:44,240
rights to a standard file system with

00:13:42,920 --> 00:13:45,530
one the rights to an object store if you

00:13:44,240 --> 00:13:49,610
wanted it all you'd have to do is change

00:13:45,530 --> 00:13:51,800
the code right there flows or how the

00:13:49,610 --> 00:13:53,360
data is transferred from clients to

00:13:51,800 --> 00:13:55,430
server and also from servers to server

00:13:53,360 --> 00:13:57,950
so this concept of spin it up go get out

00:13:55,430 --> 00:14:01,820
of the way and let the a very fast

00:13:57,950 --> 00:14:03,980
efficient layer handle that flow is kind

00:14:01,820 --> 00:14:07,550
of embed through BMI then go where they

00:14:03,980 --> 00:14:09,110
need to go jobs the core concept is

00:14:07,550 --> 00:14:10,550
built on a series of state machines and

00:14:09,110 --> 00:14:11,720
parallel state machine so you're running

00:14:10,550 --> 00:14:13,970
through these state machines getting

00:14:11,720 --> 00:14:16,370
work done and rolling through and kind

00:14:13,970 --> 00:14:18,440
of stay out of the way and those jobs

00:14:16,370 --> 00:14:19,910
kind of manage that and then there's

00:14:18,440 --> 00:14:21,920
your system interfaces and then there's

00:14:19,910 --> 00:14:26,380
your user interfaces then obviously

00:14:21,920 --> 00:14:26,380
remain it's a kind of a little overview

00:14:26,890 --> 00:14:34,360
current highlights so any questions on

00:14:30,550 --> 00:14:34,360
the architecture of user

00:14:45,290 --> 00:14:52,620
okay so drbd is a way to provide

00:14:49,800 --> 00:14:54,420
redundancy kind of your block level

00:14:52,620 --> 00:14:56,910
failover then you can do as a heartbeat

00:14:54,420 --> 00:14:59,100
or a chorus Inc you know process

00:14:56,910 --> 00:15:00,690
failover data synchronization process

00:14:59,100 --> 00:15:02,490
failover your script says when this is

00:15:00,690 --> 00:15:11,520
unavailable this one picks up takes over

00:15:02,490 --> 00:15:15,570
them with the load it depends on how you

00:15:11,520 --> 00:15:17,940
want it if you want replication until we

00:15:15,570 --> 00:15:21,470
get and I'll get to talk about v3 and

00:15:17,940 --> 00:15:24,510
those types of things if you want

00:15:21,470 --> 00:15:26,610
everything to be up then you'll need to

00:15:24,510 --> 00:15:28,340
do it everywhere if you just you know

00:15:26,610 --> 00:15:30,990
you have to do it for the metadata

00:15:28,340 --> 00:15:33,450
because it kind of has tentacles to all

00:15:30,990 --> 00:15:35,850
the files and all the servers so even

00:15:33,450 --> 00:15:37,650
though it's kind of broken up eventually

00:15:35,850 --> 00:15:40,050
most of the files will be inaccessible

00:15:37,650 --> 00:15:42,210
if you have that just on the metadata

00:15:40,050 --> 00:15:44,370
and then the file i/o is not there

00:15:42,210 --> 00:15:46,320
you'll only just be able to not access

00:15:44,370 --> 00:15:48,330
that portion of the file so you have 32

00:15:46,320 --> 00:15:49,530
servers one's down only the files on

00:15:48,330 --> 00:15:51,410
that server will be unavailable

00:15:49,530 --> 00:15:56,220
everything else will operate just fine

00:15:51,410 --> 00:15:57,930
so that right there's replication on a

00:15:56,220 --> 00:15:59,730
mutable but most people you know that's

00:15:57,930 --> 00:16:01,470
a very small use case for read-only

00:15:59,730 --> 00:16:03,360
stuff we do some of that but the big

00:16:01,470 --> 00:16:08,130
push is to get to 30 where we have both

00:16:03,360 --> 00:16:08,640
of those we get asked that a lot and

00:16:08,130 --> 00:16:10,920
that's what we're actually

00:16:08,640 --> 00:16:13,350
reprioritizing some things so i'll get

00:16:10,920 --> 00:16:14,850
to that some of the efficiency things

00:16:13,350 --> 00:16:16,620
we've done and they kind of have a

00:16:14,850 --> 00:16:19,020
version stamp so people can see in these

00:16:16,620 --> 00:16:22,550
slides have evolved over time server to

00:16:19,020 --> 00:16:26,250
server communications where you can take

00:16:22,550 --> 00:16:27,750
essentially tree based code and if

00:16:26,250 --> 00:16:30,810
something has to happen and a lot of

00:16:27,750 --> 00:16:33,630
servers it'll you know go out and double

00:16:30,810 --> 00:16:36,600
each time and handle all the work like

00:16:33,630 --> 00:16:38,250
metadata operations and some delete type

00:16:36,600 --> 00:16:42,260
operations and file creates and those

00:16:38,250 --> 00:16:42,260
types of things yeah

00:16:42,960 --> 00:17:18,430
luster or gluster GL ok I have to the

00:16:48,370 --> 00:17:19,810
other right that one yeah right have a

00:17:18,430 --> 00:17:21,520
slide on it I'll get to it but it's

00:17:19,810 --> 00:17:22,840
essentially there's a couple of

00:17:21,520 --> 00:17:25,360
different levels of replication let me

00:17:22,840 --> 00:17:26,500
get to it and then just kind of ask that

00:17:25,360 --> 00:17:30,030
again because then you'll see a diagram

00:17:26,500 --> 00:17:32,200
and then I won't talk about it twice

00:17:30,030 --> 00:17:34,540
recent additions I thought those would

00:17:32,200 --> 00:17:36,460
be a little brighter some things you can

00:17:34,540 --> 00:17:39,100
do with metadata is you can actually

00:17:36,460 --> 00:17:41,020
store your metadata on SSD on any number

00:17:39,100 --> 00:17:44,260
of nodes helps your performance with

00:17:41,020 --> 00:17:45,910
your database behind that replicated on

00:17:44,260 --> 00:17:49,420
a mutable just talked about that windows

00:17:45,910 --> 00:17:50,890
client a lot of people didn't support

00:17:49,420 --> 00:17:53,410
windows client we went out and did that

00:17:50,890 --> 00:17:55,600
the server it all runs on linux but that

00:17:53,410 --> 00:17:59,380
gives them that parallel access for

00:17:55,600 --> 00:18:03,400
high-throughput and hyatt heiio a direct

00:17:59,380 --> 00:18:08,790
access interface this was actually kind

00:18:03,400 --> 00:18:11,410
of a request how do you build a POSIX

00:18:08,790 --> 00:18:14,230
emulation interface that you can bypass

00:18:11,410 --> 00:18:15,850
the colonel and directly access from

00:18:14,230 --> 00:18:17,680
applications I kind of get through your

00:18:15,850 --> 00:18:19,240
you know get away from an extra mem copy

00:18:17,680 --> 00:18:21,280
in those types I think so we have a full

00:18:19,240 --> 00:18:24,070
you can do an LD preload on this and

00:18:21,280 --> 00:18:25,060
we've tested lots and lots of things and

00:18:24,070 --> 00:18:26,830
if you find something else it doesn't

00:18:25,060 --> 00:18:28,680
work but it gives you that fast

00:18:26,830 --> 00:18:30,760
performance it actually gives you a

00:18:28,680 --> 00:18:33,070
little bit of buffering in there with

00:18:30,760 --> 00:18:35,380
some of these really small some of the

00:18:33,070 --> 00:18:36,970
commands like LS and whatever someone

00:18:35,380 --> 00:18:38,740
was doing an ex coffee between a file

00:18:36,970 --> 00:18:42,790
system to orange FS they're just using

00:18:38,740 --> 00:18:45,070
the standard xcopy and or not x copy

00:18:42,790 --> 00:18:49,060
they were doing are saying cause i think

00:18:45,070 --> 00:18:51,160
an ex copy our our sink and it was taken

00:18:49,060 --> 00:18:51,929
forever for each individual file to go

00:18:51,160 --> 00:18:54,570
through

00:18:51,929 --> 00:18:55,499
and that's because we were talking about

00:18:54,570 --> 00:18:59,610
windows that's why I was talking about

00:18:55,499 --> 00:19:00,779
that was weird when you and they were

00:18:59,610 --> 00:19:02,249
having this thing's taking these big

00:19:00,779 --> 00:19:03,570
files there was taking a long time to

00:19:02,249 --> 00:19:05,639
get through them and they just didn't LD

00:19:03,570 --> 00:19:07,110
preload on this library and they got

00:19:05,639 --> 00:19:08,909
like an order of magnitude performance

00:19:07,110 --> 00:19:11,519
increase just because of the way they

00:19:08,909 --> 00:19:14,070
manage things and then didn't have to go

00:19:11,519 --> 00:19:15,299
through all those extra steps I was

00:19:14,070 --> 00:19:16,590
actually surprised when they saw that

00:19:15,299 --> 00:19:23,220
but it helped them get other stuff

00:19:16,590 --> 00:19:25,440
migrated to Orange FS and it links to NP

00:19:23,220 --> 00:19:26,610
i/o and anyway there's lots of stuff

00:19:25,440 --> 00:19:29,249
there if you have more questions on that

00:19:26,610 --> 00:19:32,480
we can dig into that we also put in an

00:19:29,249 --> 00:19:35,190
optional cash on the direct interface

00:19:32,480 --> 00:19:36,809
for those use cases that need it one

00:19:35,190 --> 00:19:39,570
thing about cash on a parallel file

00:19:36,809 --> 00:19:41,249
system this cash is not coherent across

00:19:39,570 --> 00:19:43,350
all systems it's coherent across a

00:19:41,249 --> 00:19:45,090
single system so you know for multiple

00:19:43,350 --> 00:19:47,369
processes it's good but if you have a

00:19:45,090 --> 00:19:48,840
you know a process writing to something

00:19:47,369 --> 00:19:50,309
here process right into something here

00:19:48,840 --> 00:19:51,509
you know that's where you have to be

00:19:50,309 --> 00:19:53,820
careful and decide if your application

00:19:51,509 --> 00:19:55,740
can support that or not but it actually

00:19:53,820 --> 00:19:57,389
helps with some small I oh and some

00:19:55,740 --> 00:20:01,470
small things like that at the client

00:19:57,389 --> 00:20:05,610
level we built a webdav interface so you

00:20:01,470 --> 00:20:07,860
could actually take dev instead of you

00:20:05,610 --> 00:20:10,499
know the mod dad FS i think is there's a

00:20:07,860 --> 00:20:11,999
mod dag orange FS module that you can

00:20:10,499 --> 00:20:13,799
just load and then you can have full day

00:20:11,999 --> 00:20:15,809
of functionality and get the parallel

00:20:13,799 --> 00:20:18,659
access behind it and you could actually

00:20:15,809 --> 00:20:20,159
put dab on each one of your storage

00:20:18,659 --> 00:20:21,929
nodes whichever ones the client

00:20:20,159 --> 00:20:23,639
connected to they'd see the full access

00:20:21,929 --> 00:20:25,559
to the file system permissions I needed

00:20:23,639 --> 00:20:27,570
and then it would do the read and write

00:20:25,559 --> 00:20:29,610
so it's kind of a just a way to provide

00:20:27,570 --> 00:20:36,450
an alternate method to access the file

00:20:29,610 --> 00:20:38,100
system kind of as a an experiment we

00:20:36,450 --> 00:20:39,480
actually implemented s3 where your root

00:20:38,100 --> 00:20:42,539
directory is your buckets and then you

00:20:39,480 --> 00:20:45,110
have your s3 access to it you know if

00:20:42,539 --> 00:20:45,110
you wanted to

00:20:47,220 --> 00:20:52,049
so there's kind of a summary what I just

00:20:49,169 --> 00:20:56,909
went through and then here's the coming

00:20:52,049 --> 00:20:59,450
soon so one of the interesting things

00:20:56,909 --> 00:21:01,940
and jeff beck's they're actually did a

00:20:59,450 --> 00:21:06,659
majority of the work for this is

00:21:01,940 --> 00:21:08,309
actually created a a jni interface so

00:21:06,659 --> 00:21:11,100
essentially it's a jni clients you have

00:21:08,309 --> 00:21:13,890
java the talks directly to the orange FS

00:21:11,100 --> 00:21:15,720
client and you got like all the mem

00:21:13,890 --> 00:21:17,490
copies out it actually holds an object

00:21:15,720 --> 00:21:20,940
and it's actually pretty cool and then

00:21:17,490 --> 00:21:24,210
there's a hadoop mapreduce interface and

00:21:20,940 --> 00:21:26,549
what's the library name / what's the jar

00:21:24,210 --> 00:21:35,059
name that you kind of extend the

00:21:26,549 --> 00:21:35,059
filesystem class right

00:21:45,669 --> 00:21:50,750
it says the Hoodoo Praetorian it extends

00:21:48,110 --> 00:21:52,640
the filesystem class the Hadoop file

00:21:50,750 --> 00:21:55,010
system class so essentially you don't

00:21:52,640 --> 00:21:57,730
need HDFS you can have orange FS there

00:21:55,010 --> 00:22:01,910
and get the performance numbers you need

00:21:57,730 --> 00:22:03,980
through it currently because it doesn't

00:22:01,910 --> 00:22:05,120
have a replication which we're building

00:22:03,980 --> 00:22:09,320
and i'll get to and we'll talk about

00:22:05,120 --> 00:22:10,760
more and digging in details it's

00:22:09,320 --> 00:22:14,169
interesting though with the buffering

00:22:10,760 --> 00:22:16,910
we're seeing near the performance of

00:22:14,169 --> 00:22:18,950
HDFS with its local rights and if you

00:22:16,910 --> 00:22:20,900
this gives you the ability to say I want

00:22:18,950 --> 00:22:23,510
to have a scratch file system for my

00:22:20,900 --> 00:22:25,100
standard cluster or I have a file system

00:22:23,510 --> 00:22:27,110
that I want different applications to

00:22:25,100 --> 00:22:29,150
use not just to Duke then you can allow

00:22:27,110 --> 00:22:30,590
a dupe to use it and then you can be

00:22:29,150 --> 00:22:32,419
shared with other applications which

00:22:30,590 --> 00:22:33,799
opens the door it's kind of I don't have

00:22:32,419 --> 00:22:36,770
to have these boxes over here doing

00:22:33,799 --> 00:22:39,890
Hadoop and these boxes over here doing

00:22:36,770 --> 00:22:41,360
everything else in my enterprise kind of

00:22:39,890 --> 00:22:44,030
interesting when talking to one of the

00:22:41,360 --> 00:22:46,100
ebay CTOs he said you know one of the

00:22:44,030 --> 00:22:51,679
big problems they face is they have all

00:22:46,100 --> 00:22:52,970
these containers of front-end processing

00:22:51,679 --> 00:22:55,100
systems they don't have a lot of disk

00:22:52,970 --> 00:22:56,750
there was real thin real friend

00:22:55,100 --> 00:22:58,700
processing to hand their their loads and

00:22:56,750 --> 00:23:00,530
they go back and talk to the databases

00:22:58,700 --> 00:23:03,410
but there's times of year when they're

00:23:00,530 --> 00:23:05,720
those are sitting unused and he says you

00:23:03,410 --> 00:23:07,970
know whenever I run some Hadoop jobs and

00:23:05,720 --> 00:23:09,590
get some quick performance or some

00:23:07,970 --> 00:23:11,090
feedback I actually make money and the

00:23:09,590 --> 00:23:12,740
marketing officer come back and says you

00:23:11,090 --> 00:23:14,240
need to run some more of that but he has

00:23:12,740 --> 00:23:16,340
to have these different classes servers

00:23:14,240 --> 00:23:17,660
over here and he has to kind of buy them

00:23:16,340 --> 00:23:19,760
separately and there's all these cycles

00:23:17,660 --> 00:23:22,790
just kind of waiting for load to come up

00:23:19,760 --> 00:23:24,169
over here so he would you know that was

00:23:22,790 --> 00:23:26,660
one of the things that sparked this idea

00:23:24,169 --> 00:23:28,160
is now you can take these have a shared

00:23:26,660 --> 00:23:30,290
file system sitting in that container

00:23:28,160 --> 00:23:32,929
and they can sit there and be doing some

00:23:30,290 --> 00:23:35,000
Hadoop jobs while though you know the

00:23:32,929 --> 00:23:37,100
what's not Christmas essentially or

00:23:35,000 --> 00:23:38,809
whenever some whatever is being sold on

00:23:37,100 --> 00:23:40,700
ebay that's getting a bazillion hits

00:23:38,809 --> 00:23:42,770
isn't getting hit so it's kind of

00:23:40,700 --> 00:23:50,480
extends that capability for Hadoop

00:23:42,770 --> 00:23:51,950
distributed directory metadata so 29

00:23:50,480 --> 00:23:53,870
just went into beta you can download it

00:23:51,950 --> 00:23:55,940
now just a couple weeks ago so these

00:23:53,870 --> 00:23:57,929
things are available and there's

00:23:55,940 --> 00:24:01,230
actually a lot of work getting these in

00:23:57,929 --> 00:24:04,080
so essentially talked about how you can

00:24:01,230 --> 00:24:05,909
distribute the metadata for your file

00:24:04,080 --> 00:24:08,940
entries across and it's kind of done at

00:24:05,909 --> 00:24:10,080
a directory boundary just because that's

00:24:08,940 --> 00:24:11,700
how you have to do look up she have to

00:24:10,080 --> 00:24:13,169
know where things are so what we

00:24:11,700 --> 00:24:16,350
actually developed is an extensional

00:24:13,169 --> 00:24:18,779
extensible hashing algorithm that allows

00:24:16,350 --> 00:24:21,269
you to write you know if it directory

00:24:18,779 --> 00:24:23,850
hits that pre-configure number of

00:24:21,269 --> 00:24:27,179
entries 10,000 hundred thousand whatever

00:24:23,850 --> 00:24:29,249
the number is it'll split out and do a

00:24:27,179 --> 00:24:31,289
hashing mechanism to keep the directory

00:24:29,249 --> 00:24:32,820
entries across multiple servers so then

00:24:31,289 --> 00:24:34,169
you won't have a single hot spot if you

00:24:32,820 --> 00:24:36,450
have a few million files sitting in a

00:24:34,169 --> 00:24:43,889
single directory you get that scale out

00:24:36,450 --> 00:24:46,379
capability it's based on Giga plus swap

00:24:43,889 --> 00:24:47,549
nil and Garth Gibson at cme they kind of

00:24:46,379 --> 00:24:50,340
wrote this paper did the work we

00:24:47,549 --> 00:24:52,619
collaborated with them and kind of

00:24:50,340 --> 00:24:55,259
brought that into orange FS and then it

00:24:52,619 --> 00:24:56,999
was a lot of work to actually work out

00:24:55,259 --> 00:25:00,799
all the corner cases and get it so it

00:24:56,999 --> 00:25:04,440
interacts at all the different levels

00:25:00,799 --> 00:25:06,480
talked about that potential so one of

00:25:04,440 --> 00:25:09,629
the interesting things about small file

00:25:06,480 --> 00:25:11,309
performance that we're talking about was

00:25:09,629 --> 00:25:12,330
kind of a follow-on we've been thinking

00:25:11,309 --> 00:25:14,519
about this in the back of her head and

00:25:12,330 --> 00:25:17,940
then Garth went and did some research

00:25:14,519 --> 00:25:19,440
with one of his students on it and so

00:25:17,940 --> 00:25:20,700
what if you know we stripe metadata

00:25:19,440 --> 00:25:22,139
there's a stripe sighs and after you

00:25:20,700 --> 00:25:24,059
stripe you not straight a minute to

00:25:22,139 --> 00:25:25,950
stripe your data across multiple servers

00:25:24,059 --> 00:25:27,899
would if but you know what about these

00:25:25,950 --> 00:25:30,299
smaller files and they sit in one stripe

00:25:27,899 --> 00:25:32,279
what do you do with those so the concept

00:25:30,299 --> 00:25:34,950
is why don't you just take the first

00:25:32,279 --> 00:25:38,999
stripe when you're writing it and dump

00:25:34,950 --> 00:25:40,559
it directly into metadata and then which

00:25:38,999 --> 00:25:42,330
you have and there's some things to work

00:25:40,559 --> 00:25:44,159
out we're going to write it there and to

00:25:42,330 --> 00:25:46,619
the file and delete the one when it

00:25:44,159 --> 00:25:49,320
doesn't grow or there's some semantics

00:25:46,619 --> 00:25:52,529
we have to figure out what's optimal and

00:25:49,320 --> 00:25:54,600
stay out of the way though if you think

00:25:52,529 --> 00:25:55,980
about I have to go talk to metadata to

00:25:54,600 --> 00:25:57,629
find out where my file is or anything

00:25:55,980 --> 00:26:00,119
about my file and same thing with any

00:25:57,629 --> 00:26:02,249
file system would have that same read

00:26:00,119 --> 00:26:03,600
you just get the file data back and for

00:26:02,249 --> 00:26:05,309
small I oh that's you want that's what

00:26:03,600 --> 00:26:07,320
you want because your metadata is about

00:26:05,309 --> 00:26:08,639
the same size as your for KI oh so it

00:26:07,320 --> 00:26:09,309
might as well just come down at the same

00:26:08,639 --> 00:26:10,840
time

00:26:09,309 --> 00:26:16,539
and what that will provide is

00:26:10,840 --> 00:26:18,970
essentially a distributed database to

00:26:16,539 --> 00:26:20,620
store your small files in that scales

00:26:18,970 --> 00:26:22,409
out to your larger files if you need it

00:26:20,620 --> 00:26:24,879
it's all seamless to the client so

00:26:22,409 --> 00:26:30,370
that's something where you know

00:26:24,879 --> 00:26:33,279
seriously looking to implement haven't

00:26:30,370 --> 00:26:36,460
started coding on it yet but it and with

00:26:33,279 --> 00:26:38,440
oh I was mentioning CMU and Garth when

00:26:36,460 --> 00:26:40,779
they did their performance tests on it

00:26:38,440 --> 00:26:43,240
just on some kind of rudimentary design

00:26:40,779 --> 00:26:44,980
this authentic 10x performance numbers

00:26:43,240 --> 00:26:47,559
for small I oh and there's not very many

00:26:44,980 --> 00:26:49,860
things in the world today I keep saying

00:26:47,559 --> 00:26:52,389
that but then I keep hearing about it

00:26:49,860 --> 00:26:53,619
different things that like you saw that

00:26:52,389 --> 00:26:55,299
you know that's awesome I'll tell you

00:26:53,619 --> 00:26:56,860
that in a little bit hours to seconds

00:26:55,299 --> 00:26:58,299
you don't see very many things but you

00:26:56,860 --> 00:26:59,470
don't see 10x improvements on stuff that

00:26:58,299 --> 00:27:04,480
people have been looking at and thinking

00:26:59,470 --> 00:27:07,539
about for a while the other big feature

00:27:04,480 --> 00:27:11,110
in 290 is capability-based security

00:27:07,539 --> 00:27:15,850
how's that diagrams little brighter so

00:27:11,110 --> 00:27:18,700
essentially you start with a client the

00:27:15,850 --> 00:27:22,659
client will actually contact your

00:27:18,700 --> 00:27:25,509
metadata server for a request and you'll

00:27:22,659 --> 00:27:26,879
have these certificates or whatever you

00:27:25,509 --> 00:27:29,169
want we've implemented some certificates

00:27:26,879 --> 00:27:31,210
there's kind of two different methods we

00:27:29,169 --> 00:27:34,330
have kind of a standard security and

00:27:31,210 --> 00:27:35,830
then we have advanced security we're

00:27:34,330 --> 00:27:37,409
still working on the names of those but

00:27:35,830 --> 00:27:41,049
then there's you know certificate and

00:27:37,409 --> 00:27:42,429
you can essentially leverage your

00:27:41,049 --> 00:27:44,590
certificates to make that first

00:27:42,429 --> 00:27:48,100
connection to your file system and then

00:27:44,590 --> 00:27:49,629
you get basically on request each

00:27:48,100 --> 00:27:51,789
request you make you'll be given a

00:27:49,629 --> 00:27:53,379
capability and that capability allow you

00:27:51,789 --> 00:27:54,909
to do the things based on that request

00:27:53,379 --> 00:27:58,799
and then there's a timeout very short

00:27:54,909 --> 00:28:04,149
time out and it's all pki enforce or

00:27:58,799 --> 00:28:08,070
leveraging you know certificates to

00:28:04,149 --> 00:28:13,919
contact that but each server has its own

00:28:08,070 --> 00:28:16,899
signed objects to manage between them so

00:28:13,919 --> 00:28:18,580
no untrusted file systems can come in

00:28:16,899 --> 00:28:20,169
and you only have the capabilities that

00:28:18,580 --> 00:28:22,070
a user is currently accessing on the

00:28:20,169 --> 00:28:25,220
file system so you can really have

00:28:22,070 --> 00:28:27,530
trusted root come in and access systems

00:28:25,220 --> 00:28:28,610
now so it's kind of this big thing and

00:28:27,530 --> 00:28:31,130
it was a lot of work to get the

00:28:28,610 --> 00:28:32,840
performance time we're actually building

00:28:31,130 --> 00:28:35,150
in some more capability caches to get

00:28:32,840 --> 00:28:36,200
the performance numbers and back down to

00:28:35,150 --> 00:28:39,350
where we need them but it really

00:28:36,200 --> 00:28:41,150
provides that extension so if you really

00:28:39,350 --> 00:28:44,690
want to take your parallel file system

00:28:41,150 --> 00:28:47,330
allow you know Joe Windows client or Joe

00:28:44,690 --> 00:28:49,640
owns their own linux client dump data on

00:28:47,330 --> 00:28:51,740
it you really have to provide this

00:28:49,640 --> 00:28:53,990
infrastructure kind of goes out of the

00:28:51,740 --> 00:28:59,450
I'm trusting my systems my trusted root

00:28:53,990 --> 00:29:01,070
to my untrusted root things with that PK

00:28:59,450 --> 00:29:03,800
I there are some other things we can do

00:29:01,070 --> 00:29:05,330
based on if people want them we're

00:29:03,800 --> 00:29:06,830
getting a couple requests for encryption

00:29:05,330 --> 00:29:08,270
so we could leverage some of that for

00:29:06,830 --> 00:29:10,370
encryption have to do some more work

00:29:08,270 --> 00:29:12,640
when you start encrypting data key

00:29:10,370 --> 00:29:16,120
management scares the crap out of me

00:29:12,640 --> 00:29:18,710
especially in a very big diverse system

00:29:16,120 --> 00:29:21,730
the other thing is you could we don't

00:29:18,710 --> 00:29:23,930
currently do SSL over the wire but that

00:29:21,730 --> 00:29:26,990
capable there that'll probably be a next

00:29:23,930 --> 00:29:28,280
iteration and that's kind of obviously

00:29:26,990 --> 00:29:29,810
you want that but we wanted to get the

00:29:28,280 --> 00:29:36,200
capability infrastructure there first

00:29:29,810 --> 00:29:37,820
the capabilities also are very much hard

00:29:36,200 --> 00:29:40,700
not they're not hard coded they're

00:29:37,820 --> 00:29:42,830
leveraging you know the standard POSIX

00:29:40,700 --> 00:29:44,180
permission standard UNIX permissions but

00:29:42,830 --> 00:29:46,430
they're designed in such a way you can

00:29:44,180 --> 00:29:47,930
extend these capabilities and you can

00:29:46,430 --> 00:29:50,540
put other attributes and you can do

00:29:47,930 --> 00:29:51,800
attribute based authorization in the

00:29:50,540 --> 00:29:53,120
future if you want it obviously will

00:29:51,800 --> 00:29:55,310
have to plug in some other pieces it's

00:29:53,120 --> 00:29:57,590
not easy but that frameworks there to be

00:29:55,310 --> 00:29:59,810
built on this same framework and that

00:29:57,590 --> 00:30:01,160
kind of opens up the door for I mean

00:29:59,810 --> 00:30:02,540
familiar with the web space you do

00:30:01,160 --> 00:30:05,210
Samuel that type of thing you pass

00:30:02,540 --> 00:30:06,730
attributes you get authentication now

00:30:05,210 --> 00:30:10,010
you could take the same type of

00:30:06,730 --> 00:30:12,290
techniques and you could have capability

00:30:10,010 --> 00:30:15,260
not capability but you know attribute

00:30:12,290 --> 00:30:17,570
based access federated from you know

00:30:15,260 --> 00:30:21,590
it's really hard to have an ACL for

00:30:17,570 --> 00:30:22,550
someone who is not you know you don't

00:30:21,590 --> 00:30:24,140
know about I don't know who's going to

00:30:22,550 --> 00:30:26,960
come and access my file system next may

00:30:24,140 --> 00:30:29,150
come from that enterprise or that

00:30:26,960 --> 00:30:30,800
institution over there they come in and

00:30:29,150 --> 00:30:32,600
have these new role we vetted the

00:30:30,800 --> 00:30:34,670
metadata between our institutions so we

00:30:32,600 --> 00:30:35,380
trust their trust for a certain level of

00:30:34,670 --> 00:30:37,480
things

00:30:35,380 --> 00:30:41,590
and then they come in and they say boom

00:30:37,480 --> 00:30:43,540
here's my attributes I'm one of the one

00:30:41,590 --> 00:30:48,400
of the interesting things not like I'm

00:30:43,540 --> 00:30:50,080
the the person you know that the captain

00:30:48,400 --> 00:30:51,820
on watch or whatever on a submarine you

00:30:50,080 --> 00:30:53,110
know they have these big things and it's

00:30:51,820 --> 00:30:54,490
only that person who could do those

00:30:53,110 --> 00:30:56,050
things have the capability then they can

00:30:54,490 --> 00:30:58,270
do those things on the file system as

00:30:56,050 --> 00:31:00,850
opposed to when they're off duty or that

00:30:58,270 --> 00:31:01,930
type of stuff so it kind of opens that

00:31:00,850 --> 00:31:03,430
up without having to have those

00:31:01,930 --> 00:31:05,680
permissions so but that's kind of a

00:31:03,430 --> 00:31:08,590
future thing I actually have another

00:31:05,680 --> 00:31:11,620
slide but i rambled on so here's file

00:31:08,590 --> 00:31:19,360
data replication so I mentioned flows

00:31:11,620 --> 00:31:23,320
earlier our initial replication or

00:31:19,360 --> 00:31:24,400
initial you know redundancy thing was on

00:31:23,320 --> 00:31:27,250
a mutable and that was pretty

00:31:24,400 --> 00:31:29,440
straightforward you know here write it

00:31:27,250 --> 00:31:31,510
and then copied to the places after you

00:31:29,440 --> 00:31:33,070
mark the attribute that the number of

00:31:31,510 --> 00:31:37,510
copies and your market immutable then

00:31:33,070 --> 00:31:40,150
trigger the replication the next version

00:31:37,510 --> 00:31:43,390
that we're working through and were

00:31:40,150 --> 00:31:44,860
actually you know a good portion way the

00:31:43,390 --> 00:31:45,820
files are replicating and everything

00:31:44,860 --> 00:31:49,840
we're actually just having to do this

00:31:45,820 --> 00:31:52,810
stuff on top is a forked flow so

00:31:49,840 --> 00:31:55,120
essentially i write one it's too much a

00:31:52,810 --> 00:31:57,280
server and then at the server it Forks

00:31:55,120 --> 00:31:59,440
the flow and then it handles the

00:31:57,280 --> 00:32:01,480
replication so was concurrently right

00:31:59,440 --> 00:32:03,900
into its where the file needs to go

00:32:01,480 --> 00:32:07,600
there it'll actually write its replica

00:32:03,900 --> 00:32:09,610
so you know a lot of times people assume

00:32:07,600 --> 00:32:11,650
that the client and the server bandwidth

00:32:09,610 --> 00:32:14,080
are the same and that's usually not the

00:32:11,650 --> 00:32:16,300
case and especially when you want to go

00:32:14,080 --> 00:32:17,770
over to Bubba connecting over whatever

00:32:16,300 --> 00:32:20,170
or if you want to connect with something

00:32:17,770 --> 00:32:23,170
strange like you know some mobile device

00:32:20,170 --> 00:32:24,880
or whatever you know it you know the

00:32:23,170 --> 00:32:26,620
band will be choppy so you want to

00:32:24,880 --> 00:32:28,090
minimize the bandwidth to the system and

00:32:26,620 --> 00:32:30,880
then you're back in storage eels you'll

00:32:28,090 --> 00:32:32,470
have 10 gig or 56 gig and then it can

00:32:30,880 --> 00:32:34,660
handle the replication and we're

00:32:32,470 --> 00:32:37,480
actually not waiting for a writer commit

00:32:34,660 --> 00:32:39,160
we're actually splitting the flow or

00:32:37,480 --> 00:32:40,810
forking the float exactly when it hits

00:32:39,160 --> 00:32:43,150
the server and then writing the replica

00:32:40,810 --> 00:32:46,030
at the same time so it's very that the

00:32:43,150 --> 00:32:48,180
data will be consistent on two or three

00:32:46,030 --> 00:32:49,420
or four how many you configure it

00:32:48,180 --> 00:32:53,860
instances

00:32:49,420 --> 00:32:58,870
all very much real time we are going to

00:32:53,860 --> 00:33:00,580
after that come in and do a I want to

00:32:58,870 --> 00:33:02,020
get the data written I don't want the

00:33:00,580 --> 00:33:02,860
overhead on the backend for some reason

00:33:02,020 --> 00:33:05,620
I want you to come back into a

00:33:02,860 --> 00:33:09,040
background process and replicate and

00:33:05,620 --> 00:33:11,320
that's going to be more for you know if

00:33:09,040 --> 00:33:12,850
I want to do a tertiary replica to tape

00:33:11,320 --> 00:33:14,500
obviously you don't want that real-time

00:33:12,850 --> 00:33:16,480
synchronous if you do I mean it's like

00:33:14,500 --> 00:33:20,260
the everything it would like choke and

00:33:16,480 --> 00:33:21,580
die so that that'll provide that and

00:33:20,260 --> 00:33:23,440
that'll be kind of managed at a

00:33:21,580 --> 00:33:25,870
different level if you want to go to a

00:33:23,440 --> 00:33:27,370
second tier of storage even with

00:33:25,870 --> 00:33:28,870
interior those types of things will be

00:33:27,370 --> 00:33:33,730
managed with that kind of second level

00:33:28,870 --> 00:33:35,140
of Management yeah exactly yeah why

00:33:33,730 --> 00:33:37,810
dairy replication same thing you don't

00:33:35,140 --> 00:33:39,760
want that that can't be real time unless

00:33:37,810 --> 00:33:42,370
your data centers or less than 15 miles

00:33:39,760 --> 00:33:46,390
apart or whatever otherwise speed of

00:33:42,370 --> 00:33:49,410
light gets in the way she'll say that

00:33:46,390 --> 00:33:49,410
very often but it does yeah

00:33:53,639 --> 00:33:59,279
I'm probably not smart enough to answer

00:33:55,629 --> 00:33:59,279
it and I did

00:34:43,000 --> 00:34:48,820
yeah yeah it's a consistency question

00:34:50,020 --> 00:34:55,040
all right so let me see if I can repeat

00:34:52,550 --> 00:34:56,630
the question do we have some cash that

00:34:55,040 --> 00:34:58,250
allows I'm repeating the question back

00:34:56,630 --> 00:35:01,880
for the camera do we have cash that

00:34:58,250 --> 00:35:04,190
allows us to kind of make sure both

00:35:01,880 --> 00:35:06,440
replicas got written to and also do we

00:35:04,190 --> 00:35:10,010
manage and the second part we have a

00:35:06,440 --> 00:35:14,660
short version but we'll talk about that

00:35:10,010 --> 00:35:18,740
for a second the way we're managing the

00:35:14,660 --> 00:35:21,710
replication right now is get it to

00:35:18,740 --> 00:35:25,330
someplace safe and get it solid so if

00:35:21,710 --> 00:35:28,250
we're writing and one of them fails

00:35:25,330 --> 00:35:29,900
we're going to keep writing so I get out

00:35:28,250 --> 00:35:31,640
of the way let the data get written and

00:35:29,900 --> 00:35:34,820
then we'll come back in the background

00:35:31,640 --> 00:35:37,220
and we'll make sure that it gets put

00:35:34,820 --> 00:35:38,570
back on the other getting it you know

00:35:37,220 --> 00:35:39,800
the other place gets put back you know

00:35:38,570 --> 00:35:41,600
it doesn't matter which one fails

00:35:39,800 --> 00:35:43,730
there's not a primary at that point it's

00:35:41,600 --> 00:35:44,900
getting written to both places and that

00:35:43,730 --> 00:35:46,880
was your second question is there a

00:35:44,900 --> 00:35:49,040
primary and secondary which is more of a

00:35:46,880 --> 00:35:51,500
consistency question so you're right

00:35:49,040 --> 00:35:53,060
here you're right here if one of those

00:35:51,500 --> 00:35:54,410
fails i'm writing here something will

00:35:53,060 --> 00:35:55,670
come back along and get me to the end

00:35:54,410 --> 00:35:57,530
number of replicas that I need to a

00:35:55,670 --> 00:35:59,600
parallel background process talk about

00:35:57,530 --> 00:36:01,460
those in a couple minutes so yes so

00:35:59,600 --> 00:36:03,950
that's kind of how we're handling so no

00:36:01,460 --> 00:36:07,700
we're not planning on cashing any of

00:36:03,950 --> 00:36:10,040
that data because usually if you're in a

00:36:07,700 --> 00:36:13,880
failure state the failure state will

00:36:10,040 --> 00:36:16,790
probably be longer than you know that

00:36:13,880 --> 00:36:19,010
the issue and and if they both fail

00:36:16,790 --> 00:36:21,490
we'll go back to the client say the

00:36:19,010 --> 00:36:21,490
right failed

00:36:28,590 --> 00:36:37,150
matter whether you have continuity of

00:36:33,099 --> 00:36:40,570
power and the other military technology

00:36:37,150 --> 00:36:42,310
we have I guess it's common is open

00:36:40,570 --> 00:36:44,470
something memory for a while which is

00:36:42,310 --> 00:36:48,910
sort of failure if it's going to happen

00:36:44,470 --> 00:36:57,940
at all and whenever fails you would

00:36:48,910 --> 00:37:00,940
expect that over in ways that match hits

00:36:57,940 --> 00:37:03,040
that you're storing on the disk anybody

00:37:00,940 --> 00:37:07,710
to see me the only other place that you

00:37:03,040 --> 00:37:07,710
could have a tiebreaker to arbitration

00:37:09,590 --> 00:37:15,680
right and it might be once we do more

00:37:13,640 --> 00:37:18,680
in-depth testing and failover testing

00:37:15,680 --> 00:37:27,530
between these you might have to look at

00:37:18,680 --> 00:37:31,040
that so our point well taken yeah so

00:37:27,530 --> 00:37:32,750
there's and that has to let me ask the

00:37:31,040 --> 00:37:36,380
second question because the first part

00:37:32,750 --> 00:37:38,120
of that is how do we handle replica so

00:37:36,380 --> 00:37:39,320
if you have three replicas who wins or

00:37:38,120 --> 00:37:40,610
if I'm writing to something you can't

00:37:39,320 --> 00:37:42,140
have everybody right to all of them and

00:37:40,610 --> 00:37:43,160
have this loosely inconsistent thing

00:37:42,140 --> 00:37:44,660
when you're dealing with data and all

00:37:43,160 --> 00:37:46,820
these clients that just doesn't work so

00:37:44,660 --> 00:37:48,910
essentially we'll have one master for

00:37:46,820 --> 00:37:51,260
each object and then there'll be

00:37:48,910 --> 00:37:53,450
secondaries and tertiaries if you will

00:37:51,260 --> 00:37:55,010
there's just secondaries I mean there's

00:37:53,450 --> 00:37:57,770
not like a hierarchy there's just the

00:37:55,010 --> 00:38:00,290
primary and then the others so when we

00:37:57,770 --> 00:38:04,040
write to one of those if one of those

00:38:00,290 --> 00:38:05,720
fails then there's going to have to be a

00:38:04,040 --> 00:38:07,850
promotion and promotion will actually

00:38:05,720 --> 00:38:10,070
happen within the metadata and then the

00:38:07,850 --> 00:38:12,290
metadata will actually it'll have to go

00:38:10,070 --> 00:38:13,700
back and say okay you own this you

00:38:12,290 --> 00:38:15,620
change that you're pointing that you're

00:38:13,700 --> 00:38:18,500
do that so the metadata is actually the

00:38:15,620 --> 00:38:20,030
traffic cop for whose primary so that's

00:38:18,500 --> 00:38:23,240
where the consistency will be handled

00:38:20,030 --> 00:38:24,680
now as always in computer science we

00:38:23,240 --> 00:38:26,570
like to push the problem one step

00:38:24,680 --> 00:38:29,450
further so now what about who's who wins

00:38:26,570 --> 00:38:31,250
in the metadata right and then if how do

00:38:29,450 --> 00:38:34,550
you have a split brain what if what if I

00:38:31,250 --> 00:38:37,100
fail here and I'm talking here and then

00:38:34,550 --> 00:38:38,840
I'm over here so there's going to have

00:38:37,100 --> 00:38:41,360
to be some time outs and failures some

00:38:38,840 --> 00:38:42,770
retries in that code to determine that

00:38:41,360 --> 00:38:45,800
that's really all you can do is have

00:38:42,770 --> 00:38:48,740
those timeouts and failures and then

00:38:45,800 --> 00:38:51,260
come back and and if we need to we may

00:38:48,740 --> 00:38:53,510
just report a failure back or we may

00:38:51,260 --> 00:38:56,240
actually talk to appear and build a

00:38:53,510 --> 00:38:57,350
quorum if you will who knows this but

00:38:56,240 --> 00:39:02,120
when you start getting into that when

00:38:57,350 --> 00:39:04,850
you're high I oh it's you know there can

00:39:02,120 --> 00:39:06,320
be cascading delays on lots of other

00:39:04,850 --> 00:39:10,160
clients and lots of other things so

00:39:06,320 --> 00:39:11,930
that's a interesting question but most

00:39:10,160 --> 00:39:14,510
of the split blame problem is handled

00:39:11,930 --> 00:39:16,700
with your big rights at the metadata

00:39:14,510 --> 00:39:18,470
level metadata or small rights and then

00:39:16,700 --> 00:39:20,750
if you have to failover they can fail

00:39:18,470 --> 00:39:23,269
over and talk to the other one so you're

00:39:20,750 --> 00:39:25,249
what kind of avoiding it we're also

00:39:23,269 --> 00:39:30,289
it's not like this system is backing up

00:39:25,249 --> 00:39:33,069
this system and I'll get to the caches

00:39:30,289 --> 00:39:35,509
in a little bit it's essentially the

00:39:33,069 --> 00:39:38,599
primary of this object maybe on this

00:39:35,509 --> 00:39:40,909
server for file one and the primary of

00:39:38,599 --> 00:39:42,259
file object to might be on this server

00:39:40,909 --> 00:39:44,359
so we're actually distributing the

00:39:42,259 --> 00:39:45,919
primaries across the whole system to

00:39:44,359 --> 00:39:48,799
alleviate hot spots you can leverage the

00:39:45,919 --> 00:39:50,419
i/o through the whole system and then

00:39:48,799 --> 00:39:55,449
that kind of goes back and then there's

00:39:50,419 --> 00:39:57,469
going to be a cache you idg there's a

00:39:55,449 --> 00:39:58,519
we're going to be let me get to that

00:39:57,469 --> 00:39:59,809
slide and I'll talk to that and that's

00:39:58,519 --> 00:40:02,929
the split brain again because we're

00:39:59,809 --> 00:40:05,479
actually managing the we're keeping

00:40:02,929 --> 00:40:08,749
track of who can talk to who at the

00:40:05,479 --> 00:40:10,399
client level in memory kind of database

00:40:08,749 --> 00:40:13,489
and knowing because it also we need that

00:40:10,399 --> 00:40:21,559
for the who can write to what but that's

00:40:13,489 --> 00:40:22,729
a good question you know kind of my to

00:40:21,559 --> 00:40:25,959
keep talking about the other let me see

00:40:22,729 --> 00:40:28,369
if I can do this and go back to that I

00:40:25,959 --> 00:40:32,029
will just go through it okay I'll skip

00:40:28,369 --> 00:40:35,059
too many slides so we also just released

00:40:32,029 --> 00:40:36,679
a deployment of orange FS where you can

00:40:35,059 --> 00:40:38,089
actually go up to amazon came to us a

00:40:36,679 --> 00:40:39,499
super competing last year and said hey

00:40:38,089 --> 00:40:41,719
we're missing a parallel scale-out file

00:40:39,499 --> 00:40:42,769
system is part of our offering can you

00:40:41,719 --> 00:40:46,189
get one of those and put it in the

00:40:42,769 --> 00:40:47,539
amazon marketplace and so we kind of did

00:40:46,189 --> 00:40:49,880
some work went within what I met with

00:40:47,539 --> 00:40:52,069
them and so just a few weeks ago we

00:40:49,880 --> 00:40:54,769
released the capability where you can

00:40:52,069 --> 00:40:57,769
have n number of storage servers each

00:40:54,769 --> 00:40:58,999
with essentially a TBS volumes it can be

00:40:57,769 --> 00:41:01,779
configurable but the way they want it in

00:40:58,999 --> 00:41:04,130
the marketplace you have eight those are

00:41:01,779 --> 00:41:06,679
rated together for just striped

00:41:04,130 --> 00:41:08,569
essentially and then you can do four or

00:41:06,679 --> 00:41:10,579
eight or 16 of those all running in

00:41:08,569 --> 00:41:12,649
amazon and provide a scale-out file

00:41:10,579 --> 00:41:16,429
system for applications that need you

00:41:12,649 --> 00:41:18,109
know fast I owe to that so it kind of

00:41:16,429 --> 00:41:20,029
opens up the ability so you can run

00:41:18,109 --> 00:41:23,089
orange FS as you know base of your

00:41:20,029 --> 00:41:24,739
infrastructure on your metal but it also

00:41:23,089 --> 00:41:27,049
can just run in a virtual environment

00:41:24,739 --> 00:41:31,789
very easy that's actually pretty slick

00:41:27,049 --> 00:41:33,259
you go in answer a few questions if you

00:41:31,789 --> 00:41:36,139
go in push a button answer a few

00:41:33,259 --> 00:41:36,660
questions go to the next screen and then

00:41:36,139 --> 00:41:39,180
it starts

00:41:36,660 --> 00:41:40,980
the instances they all register with a

00:41:39,180 --> 00:41:42,539
database and then they kind of layer a

00:41:40,980 --> 00:41:44,819
file system automatically then you can

00:41:42,539 --> 00:41:47,460
ssh in and you can see them out so it's

00:41:44,819 --> 00:41:49,559
all there so other people can come in

00:41:47,460 --> 00:41:51,809
and put their applications in that VPC

00:41:49,559 --> 00:41:55,079
all with an ad that all is kind of built

00:41:51,809 --> 00:41:57,750
in together so it's kind of fun

00:41:55,079 --> 00:42:00,030
OpenStack has the heat project I was

00:41:57,750 --> 00:42:01,740
talking to the cloud stack folks then I

00:42:00,030 --> 00:42:03,210
was wrote down there's some

00:42:01,740 --> 00:42:04,980
implementations that they have and I'm

00:42:03,210 --> 00:42:06,780
hoping that a lot of people use leverage

00:42:04,980 --> 00:42:09,180
these cloud formation templates it's

00:42:06,780 --> 00:42:13,619
going to I took notes of that now set

00:42:09,180 --> 00:42:15,410
down the cards but with these cloud

00:42:13,619 --> 00:42:20,760
formation templates you could actually

00:42:15,410 --> 00:42:22,950
deploy V pcs NAT instances instances

00:42:20,760 --> 00:42:24,510
across all the nodes and it really just

00:42:22,950 --> 00:42:26,730
kind of makes it easy to get a real

00:42:24,510 --> 00:42:30,049
simple application configuration in the

00:42:26,730 --> 00:42:30,049
cloud it's actually pretty slick stuff

00:42:30,079 --> 00:42:37,799
so there that's that so orange fs3 so a

00:42:35,250 --> 00:42:39,480
lot of the stuff we just talked about

00:42:37,799 --> 00:42:43,260
the replication slide was a little bit

00:42:39,480 --> 00:42:44,849
out of order because we actually were

00:42:43,260 --> 00:42:47,490
planning on releasing file based

00:42:44,849 --> 00:42:50,339
replication before we released metadata

00:42:47,490 --> 00:42:53,069
replication and we're actually going to

00:42:50,339 --> 00:42:54,359
you know have to do some code work some

00:42:53,069 --> 00:42:56,430
more code testing and we're actually

00:42:54,359 --> 00:42:58,470
going to end up deleting some code so we

00:42:56,430 --> 00:42:59,670
actually decided you know after lots of

00:42:58,470 --> 00:43:01,650
feedback from people they said we want

00:42:59,670 --> 00:43:03,630
no single point of failure we want it

00:43:01,650 --> 00:43:07,289
managed make our file system come back

00:43:03,630 --> 00:43:09,270
and talk to us so we just said okay

00:43:07,289 --> 00:43:11,339
we'll change the scope at two dot one

00:43:09,270 --> 00:43:13,170
will just 29 dot one will just be bug

00:43:11,339 --> 00:43:15,420
fixes for two not nine and then we're

00:43:13,170 --> 00:43:16,740
actually going to do a full-on push and

00:43:15,420 --> 00:43:18,480
hopefully be able to have a beta which

00:43:16,740 --> 00:43:21,569
is really really aggressive in 12 months

00:43:18,480 --> 00:43:23,099
of orange fs3 and that's where all the

00:43:21,569 --> 00:43:26,460
replication all these other pieces will

00:43:23,099 --> 00:43:28,079
be so I'll talk a little bit about that

00:43:26,460 --> 00:43:30,059
there's kind of the goals fault

00:43:28,079 --> 00:43:32,369
accepting architecture security diverse

00:43:30,059 --> 00:43:33,930
access methods muttering management

00:43:32,369 --> 00:43:35,970
storage tiers and even wide area

00:43:33,930 --> 00:43:41,220
capabilities I've already kind of talked

00:43:35,970 --> 00:43:43,440
about these things so one of the pieces

00:43:41,220 --> 00:43:45,210
that we're currently developing is a

00:43:43,440 --> 00:43:46,529
background parallel processing

00:43:45,210 --> 00:43:48,150
infrastructure so you have a whole bunch

00:43:46,529 --> 00:43:50,450
of nodes in your parallel file system

00:43:48,150 --> 00:43:52,130
you know leverage it like

00:43:50,450 --> 00:43:54,890
Buster you should be able to spin up

00:43:52,130 --> 00:43:57,460
things to do stat grabbing to do

00:43:54,890 --> 00:43:59,630
calculations for directory space

00:43:57,460 --> 00:44:02,210
restrictions or charge backs or

00:43:59,630 --> 00:44:04,099
background safe SSC k processing go and

00:44:02,210 --> 00:44:06,230
see what's broken see if you can fix if

00:44:04,099 --> 00:44:07,520
you can't fix it mark it so if you do

00:44:06,230 --> 00:44:09,200
have to do something you can do a node

00:44:07,520 --> 00:44:11,150
offline as opposed to a whole file

00:44:09,200 --> 00:44:13,869
system offline and come back in two

00:44:11,150 --> 00:44:18,260
weeks and hope your file systems there

00:44:13,869 --> 00:44:19,520
it's a joke if hopefully but you know

00:44:18,260 --> 00:44:20,990
you're always worrying where you're

00:44:19,520 --> 00:44:22,520
going but when whatever comes up and

00:44:20,990 --> 00:44:24,109
you're worried about fsck you're going

00:44:22,520 --> 00:44:26,660
to you know you're just like what's my

00:44:24,109 --> 00:44:28,010
weekend going to be like so you really

00:44:26,660 --> 00:44:29,570
like to know what state it's in before

00:44:28,010 --> 00:44:31,070
you'd like to look at a report not start

00:44:29,570 --> 00:44:34,640
a process so that should be a background

00:44:31,070 --> 00:44:36,140
process that runs you should be able to

00:44:34,640 --> 00:44:37,760
do background check some comparisons

00:44:36,140 --> 00:44:38,630
between your replicas and copies and

00:44:37,760 --> 00:44:39,950
those types of things those are

00:44:38,630 --> 00:44:41,480
expensive they're getting better with

00:44:39,950 --> 00:44:44,780
the code they're putting in the CPU so

00:44:41,480 --> 00:44:48,470
you can do some of that parallel across

00:44:44,780 --> 00:44:50,540
filesystem rsync you know if you have 32

00:44:48,470 --> 00:44:51,829
nodes here if i'll dl spin up and divide

00:44:50,540 --> 00:44:54,020
out the directory hierarchy and each

00:44:51,829 --> 00:44:56,900
start pumping data over to another

00:44:54,020 --> 00:44:58,369
thirty two nodes over here or 32 28 you

00:44:56,900 --> 00:44:59,839
really just want a process is going to

00:44:58,369 --> 00:45:02,720
eight but it gives you that ability to

00:44:59,839 --> 00:45:04,280
do things in parallel nature which is

00:45:02,720 --> 00:45:07,250
why you know we built a parallel file

00:45:04,280 --> 00:45:08,900
system to begin with so that kind of is

00:45:07,250 --> 00:45:11,359
enabling that and then we'll start

00:45:08,900 --> 00:45:15,520
building those and hopefully we'll have

00:45:11,359 --> 00:45:19,640
many of those pieces in place for 30

00:45:15,520 --> 00:45:22,130
admin rest interface and it's like a go

00:45:19,640 --> 00:45:26,480
straight there so you basically have

00:45:22,130 --> 00:45:28,430
your at Apache module is what we've

00:45:26,480 --> 00:45:30,920
developed to do a basically arrest

00:45:28,430 --> 00:45:32,750
interface JSON talking to dojo toolkit

00:45:30,920 --> 00:45:36,349
sag a nice kid of a nitrous rich you I

00:45:32,750 --> 00:45:38,470
experience we're actively developing

00:45:36,349 --> 00:45:41,390
that we're going to be doing it on a

00:45:38,470 --> 00:45:43,520
cross-platform framework that allows you

00:45:41,390 --> 00:45:45,710
to do the same management on your phone

00:45:43,520 --> 00:45:47,510
if you scale it out you get a tablet

00:45:45,710 --> 00:45:49,220
view and the same you'll work on your

00:45:47,510 --> 00:45:52,730
desktop so you can actually manage it

00:45:49,220 --> 00:45:55,609
any of those levels which is nice if you

00:45:52,730 --> 00:45:58,220
want to do whatever it dojo has a nice

00:45:55,609 --> 00:46:00,109
content or screen size aware widget that

00:45:58,220 --> 00:46:01,430
were actually doing significant

00:46:00,109 --> 00:46:03,680
extension of and we've actually probably

00:46:01,430 --> 00:46:05,240
release it as an open source project

00:46:03,680 --> 00:46:09,559
outside of all these other things we're

00:46:05,240 --> 00:46:11,480
doing and it even has skins if you will

00:46:09,559 --> 00:46:13,490
so you could say hey I'm on an Android

00:46:11,480 --> 00:46:15,230
ham on an iPhone hey I'm whatever it can

00:46:13,490 --> 00:46:19,630
detect that and give you it that view

00:46:15,230 --> 00:46:19,630
it's kind of kind of a slick framework

00:46:19,930 --> 00:46:29,450
attribute-based metadata search just

00:46:25,430 --> 00:46:31,670
briefly on this one we have this nice

00:46:29,450 --> 00:46:34,250
distributed database what if I wanted to

00:46:31,670 --> 00:46:36,170
put arbitrary attributes about my files

00:46:34,250 --> 00:46:37,849
then I wanted to be able to query and

00:46:36,170 --> 00:46:39,410
read and open and right based on all

00:46:37,849 --> 00:46:41,150
those things we've actually done a proof

00:46:39,410 --> 00:46:43,730
of concept with this it actually works

00:46:41,150 --> 00:46:46,640
pretty well we've even talked about and

00:46:43,730 --> 00:46:49,069
this is on the on the border of the edge

00:46:46,640 --> 00:46:50,990
if you will but what if your client you

00:46:49,069 --> 00:46:52,520
do a query and based on your query it

00:46:50,990 --> 00:46:54,410
builds a directory and then you interact

00:46:52,520 --> 00:46:56,150
with that directory kind of a virtual

00:46:54,410 --> 00:46:58,040
directory if you will as if you would a

00:46:56,150 --> 00:47:00,880
normal file system out iterate through

00:46:58,040 --> 00:47:04,819
your files and do those types of things

00:47:00,880 --> 00:47:05,329
there's some interesting things that you

00:47:04,819 --> 00:47:06,380
know there's some interesting

00:47:05,329 --> 00:47:08,480
applications that there's some

00:47:06,380 --> 00:47:10,549
interesting problems with that too that

00:47:08,480 --> 00:47:12,079
have to be overcome but it kind of gets

00:47:10,549 --> 00:47:14,510
you away from being stuck a lot of

00:47:12,079 --> 00:47:15,859
content management systems if you look

00:47:14,510 --> 00:47:17,150
at them and they have they're stuck with

00:47:15,859 --> 00:47:20,240
our directory hierarchy and then someone

00:47:17,150 --> 00:47:21,170
comes in and move some files around and

00:47:20,240 --> 00:47:22,819
all this in your content management

00:47:21,170 --> 00:47:24,740
system can't find anything because I

00:47:22,819 --> 00:47:25,940
keep it separate in the database so

00:47:24,740 --> 00:47:29,410
either they could put a whole bunch of

00:47:25,940 --> 00:47:32,030
attributes put it in the file system so

00:47:29,410 --> 00:47:34,849
you know one is either no matter where

00:47:32,030 --> 00:47:36,200
you put it I always find it or if you

00:47:34,849 --> 00:47:38,299
move it at least I can go find out where

00:47:36,200 --> 00:47:39,290
you moved it to easily so there's kind

00:47:38,299 --> 00:47:40,970
of two different ways you can approach

00:47:39,290 --> 00:47:45,470
that but it's kind of an interesting

00:47:40,970 --> 00:47:53,809
thing so back to replication and

00:47:45,470 --> 00:47:55,250
redundancy so we're done at metadata

00:47:53,809 --> 00:47:56,869
there's one of it we talked about that

00:47:55,250 --> 00:47:58,190
policy-based location let me talk about

00:47:56,869 --> 00:48:00,040
this then we'll go back and kind of get

00:47:58,190 --> 00:48:04,549
back to the problem you're asking about

00:48:00,040 --> 00:48:07,430
so one of the things that we've

00:48:04,549 --> 00:48:08,960
developed with protiv elip the the

00:48:07,430 --> 00:48:14,869
concepts for design I guess is the right

00:48:08,960 --> 00:48:16,910
word is be able to have a compiled

00:48:14,869 --> 00:48:20,300
language that you can use to describe

00:48:16,910 --> 00:48:25,970
I where your data is going to go so if

00:48:20,300 --> 00:48:28,490
you want one copy of my files in RAC one

00:48:25,970 --> 00:48:30,830
one copy and rack to you know put

00:48:28,490 --> 00:48:32,990
attributes on my server instances and

00:48:30,830 --> 00:48:35,030
say describe what they are and then you

00:48:32,990 --> 00:48:36,920
also have an attribute that your client

00:48:35,030 --> 00:48:39,020
knows about information and then based

00:48:36,920 --> 00:48:41,030
on these policies you can say I want a

00:48:39,020 --> 00:48:43,460
copy and rac1 in rack to and data center

00:48:41,030 --> 00:48:45,680
for for everything in this directory

00:48:43,460 --> 00:48:47,420
hierarchy for this directory hierarchy I

00:48:45,680 --> 00:48:49,700
don't care just put one copy there be

00:48:47,420 --> 00:48:51,410
done with it so you get that flexibility

00:48:49,700 --> 00:48:53,990
within the file system so for this big

00:48:51,410 --> 00:48:55,160
massive file system you can't treat

00:48:53,990 --> 00:48:56,330
everything like a hammer you have to

00:48:55,160 --> 00:48:58,910
have the flexibility we already have

00:48:56,330 --> 00:49:00,260
that infrastructure with you know the

00:48:58,910 --> 00:49:01,970
striping I talked about earlier we'll

00:49:00,260 --> 00:49:04,370
just leverage that infrastructure for

00:49:01,970 --> 00:49:08,570
the replication and then also for this

00:49:04,370 --> 00:49:18,740
policy talk about syd cash next yeah so

00:49:08,570 --> 00:49:22,340
this is that the CID cash is really so

00:49:18,740 --> 00:49:23,660
right now I mentioned those 64-bit

00:49:22,340 --> 00:49:26,420
handles where you store all the files

00:49:23,660 --> 00:49:29,420
and three dot oh we've actually done

00:49:26,420 --> 00:49:31,250
this code we've ripped out all of that

00:49:29,420 --> 00:49:33,080
code and there's actually a lot of work

00:49:31,250 --> 00:49:34,910
because you have to who has the handles

00:49:33,080 --> 00:49:36,620
who's managing the handle who's holding

00:49:34,910 --> 00:49:39,170
up handle pool and I want to go use that

00:49:36,620 --> 00:49:42,680
handle and all those types of things has

00:49:39,170 --> 00:49:46,820
to happen and we did a set of tests and

00:49:42,680 --> 00:49:49,130
we've actually gone with you you IDs so

00:49:46,820 --> 00:49:50,990
we're going to go with 128 @ uu IDs for

00:49:49,130 --> 00:49:53,750
file handles so I have a 128-bit address

00:49:50,990 --> 00:49:55,190
space oh and by the way we actually have

00:49:53,750 --> 00:49:57,680
extended that we're actually going to

00:49:55,190 --> 00:50:02,390
identify our servers with 128-bit uu IDs

00:49:57,680 --> 00:50:05,900
as well so that way you'll have a you

00:50:02,390 --> 00:50:08,090
know two components that will make up a

00:50:05,900 --> 00:50:14,210
unique mechanism and what's interesting

00:50:08,090 --> 00:50:17,630
is each object identifier oid is what we

00:50:14,210 --> 00:50:19,340
call them there we go so I got these

00:50:17,630 --> 00:50:20,480
slides out of water I thought I had them

00:50:19,340 --> 00:50:21,260
in order but I guess I went through

00:50:20,480 --> 00:50:23,030
before you guys have asked good

00:50:21,260 --> 00:50:24,830
questions so I I'm wish i would have

00:50:23,030 --> 00:50:28,040
redone them so there's your object

00:50:24,830 --> 00:50:29,870
identify 128 you daddy 128-bit uuid for

00:50:28,040 --> 00:50:37,100
this SID

00:50:29,870 --> 00:50:39,110
so there is no more so your object

00:50:37,100 --> 00:50:41,480
identifier actually can sit on any

00:50:39,110 --> 00:50:43,430
server so that's actually how we handle

00:50:41,480 --> 00:50:45,620
replication your Sid and your Oh ID

00:50:43,430 --> 00:50:48,110
points to this object sitting on this

00:50:45,620 --> 00:50:49,790
server oids ID sitting on this server

00:50:48,110 --> 00:50:51,620
sitting on this server sitting on this

00:50:49,790 --> 00:50:53,780
server so that's how you're going to to

00:50:51,620 --> 00:50:56,360
do that mapping across all of them and

00:50:53,780 --> 00:50:58,730
then what's really nice is anybody who

00:50:56,360 --> 00:51:01,370
comes up with the oak you know with the

00:50:58,730 --> 00:51:04,190
uuid spec you can you're not supposed to

00:51:01,370 --> 00:51:05,960
have duplicates the other reason why we

00:51:04,190 --> 00:51:08,150
did the CID and the oyed identifier is

00:51:05,960 --> 00:51:11,780
we've actually restrict you know you can

00:51:08,150 --> 00:51:14,540
detect any duplicates by a single file

00:51:11,780 --> 00:51:16,640
system check to see if they're in there

00:51:14,540 --> 00:51:18,380
and then be able to manage it or they

00:51:16,640 --> 00:51:20,660
already have one of those you can go

00:51:18,380 --> 00:51:22,340
back and say pick another uuid so we

00:51:20,660 --> 00:51:25,070
could do some just in case the math

00:51:22,340 --> 00:51:27,950
doesn't work which you know happens

00:51:25,070 --> 00:51:31,520
sometimes but we'll put some checks in

00:51:27,950 --> 00:51:33,140
for that so it's a it's unique within

00:51:31,520 --> 00:51:36,050
the file system and there's how we'll

00:51:33,140 --> 00:51:38,630
manage the copies oids a toi te si T to

00:51:36,050 --> 00:51:40,820
IDs id3 are copies of the same one

00:51:38,630 --> 00:51:42,950
across all of those and also be using

00:51:40,820 --> 00:51:46,360
version counters across the copies to

00:51:42,950 --> 00:51:50,630
make sure things aren't messed up so now

00:51:46,360 --> 00:51:52,100
to keep track of the SIDS and the

00:51:50,630 --> 00:51:53,720
attributes that describe everything

00:51:52,100 --> 00:51:55,910
that's where we need that in-memory

00:51:53,720 --> 00:51:58,370
cache that clients have very small very

00:51:55,910 --> 00:52:02,780
fast in-memory cache that keeps track of

00:51:58,370 --> 00:52:04,640
state attributes you know with time outs

00:52:02,780 --> 00:52:07,060
but it knows where those things are so

00:52:04,640 --> 00:52:09,920
it can make intelligent decisions and

00:52:07,060 --> 00:52:14,030
connect to the appropriate servers to to

00:52:09,920 --> 00:52:15,650
do the rights that it needs to it really

00:52:14,030 --> 00:52:17,120
only affects rights reads you go hit the

00:52:15,650 --> 00:52:20,990
metadata then you know where you're

00:52:17,120 --> 00:52:25,340
going so that goes to the location and

00:52:20,990 --> 00:52:27,350
so it the CID cash will actually help us

00:52:25,340 --> 00:52:29,060
because we know the state of other

00:52:27,350 --> 00:52:31,850
servers and rocks you can have this

00:52:29,060 --> 00:52:36,110
concept behind the scenes of these

00:52:31,850 --> 00:52:37,610
servers that kind of know about confined

00:52:36,110 --> 00:52:40,100
anything very quickly kind of like your

00:52:37,610 --> 00:52:43,069
route DNS but you'll be able to talk to

00:52:40,100 --> 00:52:44,690
those to find stuff as needed

00:52:43,069 --> 00:52:46,279
without information in there that'll

00:52:44,690 --> 00:52:47,809
kind of help with split brain so if we

00:52:46,279 --> 00:52:49,699
get in a certain state we can go talk to

00:52:47,809 --> 00:52:53,019
someone else quickly that might have the

00:52:49,699 --> 00:52:57,229
same information about it to find out

00:52:53,019 --> 00:52:59,539
whether you know is this guy really down

00:52:57,229 --> 00:53:02,449
or is he just down to me but it's really

00:52:59,539 --> 00:53:04,369
what split-brain diz and so there might

00:53:02,449 --> 00:53:06,890
be a background communication it might

00:53:04,369 --> 00:53:08,150
be configurable if it's too much latency

00:53:06,890 --> 00:53:09,709
that's one of those who might have to

00:53:08,150 --> 00:53:11,420
turn on and off because if it gets in

00:53:09,709 --> 00:53:14,239
the way in a failure state but usually

00:53:11,420 --> 00:53:15,799
in a failure situation you know you just

00:53:14,239 --> 00:53:17,239
please start working again don't make me

00:53:15,799 --> 00:53:20,390
go do something is you know kind of what

00:53:17,239 --> 00:53:26,509
the sysadmin wants to do so some latency

00:53:20,390 --> 00:53:31,729
in those situations is ok I think I'm

00:53:26,509 --> 00:53:34,039
going wrong way the other thing why we

00:53:31,729 --> 00:53:38,539
went with you IDs I want to talk on this

00:53:34,039 --> 00:53:40,359
real briefly for run out of time is if I

00:53:38,539 --> 00:53:42,199
have a hundred servers in a file system

00:53:40,359 --> 00:53:45,289
you know I'm probably going to need to

00:53:42,199 --> 00:53:47,479
add 10 servers or maybe this projects

00:53:45,289 --> 00:53:49,099
you know I can take 10 servers down and

00:53:47,479 --> 00:53:50,630
allocate them to something else you

00:53:49,099 --> 00:53:53,539
really need to dynamically as an online

00:53:50,630 --> 00:53:55,819
operation bring up servers take servers

00:53:53,539 --> 00:53:56,749
down as part of your file system one of

00:53:55,819 --> 00:53:58,369
the other things that a parallel

00:53:56,749 --> 00:54:00,170
background process that I didn't mention

00:53:58,369 --> 00:54:01,489
that should be on that slide is there

00:54:00,170 --> 00:54:03,170
also needs to be something that's kind

00:54:01,489 --> 00:54:04,729
of looking for thresholds if it needs to

00:54:03,170 --> 00:54:06,410
do some background load leveling by

00:54:04,729 --> 00:54:08,029
bring up some new servers I mean want

00:54:06,410 --> 00:54:09,949
some load leveling to go back over here

00:54:08,029 --> 00:54:12,319
have a parallel background process that

00:54:09,949 --> 00:54:14,660
you know if there's this much Headroom

00:54:12,319 --> 00:54:16,489
and resources I go do it otherwise I

00:54:14,660 --> 00:54:18,140
back off and let the clients do their

00:54:16,489 --> 00:54:19,729
work so that's another thing that the

00:54:18,140 --> 00:54:22,099
parallel background process is for and

00:54:19,729 --> 00:54:23,479
right now you know people are thinking

00:54:22,099 --> 00:54:25,130
too that stuff with a single process

00:54:23,479 --> 00:54:28,099
managing stuff when we get to parallel

00:54:25,130 --> 00:54:29,809
nature you can go bloop BAM level stuff

00:54:28,099 --> 00:54:31,880
out a lot more quickly than you can with

00:54:29,809 --> 00:54:39,000
a single process piping things from here

00:54:31,880 --> 00:54:41,530
to there so

00:54:39,000 --> 00:54:42,700
kind of in that same concept and I

00:54:41,530 --> 00:54:44,320
mentioned this earlier there's two

00:54:42,700 --> 00:54:46,300
levels of metadata there's the split

00:54:44,320 --> 00:54:48,310
flow the immediate rights and then this

00:54:46,300 --> 00:54:49,870
kind of talks about then there's a okay

00:54:48,310 --> 00:54:52,420
after you're done doing your work or on

00:54:49,870 --> 00:54:54,340
an interval on a you know a sink or

00:54:52,420 --> 00:54:56,740
something like that go and copy this

00:54:54,340 --> 00:54:58,630
data over here in a separate process

00:54:56,740 --> 00:55:00,520
separate thread so it doesn't impact the

00:54:58,630 --> 00:55:03,700
clients writing and get it somewhere a

00:55:00,520 --> 00:55:06,220
little more safe for me so that's kind

00:55:03,700 --> 00:55:08,350
of what that is and that same concept

00:55:06,220 --> 00:55:10,360
can be used with hierarchical storage or

00:55:08,350 --> 00:55:11,800
with archiving or different tiers and

00:55:10,360 --> 00:55:14,020
that once we get that base

00:55:11,800 --> 00:55:15,670
infrastructure will you know look at the

00:55:14,020 --> 00:55:19,630
requirements and get the first pieces of

00:55:15,670 --> 00:55:23,050
that out there that's kind of you know

00:55:19,630 --> 00:55:25,360
the pretty version of it any questions

00:55:23,050 --> 00:55:29,100
on all that a couple other things i'll

00:55:25,360 --> 00:55:29,100
mention yeah

00:55:39,390 --> 00:55:42,390
thousand

00:55:44,190 --> 00:55:49,720
so you know I say 100 256 we have some

00:55:47,710 --> 00:55:52,210
people that have tested 500 nodes in a

00:55:49,720 --> 00:55:58,540
cluster currently shipping things around

00:55:52,210 --> 00:55:59,650
I mean it's you know when you distribute

00:55:58,540 --> 00:56:01,030
those things and that's where you kind

00:55:59,650 --> 00:56:02,770
of get to some of these things how do

00:56:01,030 --> 00:56:06,100
you localize the problems if you're only

00:56:02,770 --> 00:56:08,680
striping my file across 48 1016 nodes

00:56:06,100 --> 00:56:10,270
then that's my likelihood of file

00:56:08,680 --> 00:56:12,040
corruption and so that's where some of

00:56:10,270 --> 00:56:14,050
those things kind of help isolate it

00:56:12,040 --> 00:56:16,720
there's also some of those concepts some

00:56:14,050 --> 00:56:19,150
people want to be able to manage this

00:56:16,720 --> 00:56:20,650
very large and handle it that way some

00:56:19,150 --> 00:56:22,450
people want to have one or two and

00:56:20,650 --> 00:56:24,760
that's why you could have parallel

00:56:22,450 --> 00:56:26,860
background processes replicate between

00:56:24,760 --> 00:56:28,090
two completely separate file systems if

00:56:26,860 --> 00:56:30,190
you want so it's really depending on

00:56:28,090 --> 00:56:32,440
your use case but we didn't want to put

00:56:30,190 --> 00:56:34,960
a limit on it I mean when I say hundreds

00:56:32,440 --> 00:56:37,150
or 200 people will be happy with 32 and

00:56:34,960 --> 00:56:38,980
it's always a function of what's my

00:56:37,150 --> 00:56:41,020
network pipe into a single node how many

00:56:38,980 --> 00:56:43,150
spindles how much SSD how much data

00:56:41,020 --> 00:56:45,130
throughput can I put out of that so you

00:56:43,150 --> 00:56:46,990
want to optimize that and then you want

00:56:45,130 --> 00:56:51,370
to multiply it because there's no reason

00:56:46,990 --> 00:56:53,950
to multiply unless you've done that

00:56:51,370 --> 00:56:54,880
optimization first except for redundant

00:56:53,950 --> 00:56:56,260
so you want to put you know you don't

00:56:54,880 --> 00:56:58,150
want just one you want a few for

00:56:56,260 --> 00:57:01,060
redundancy and then you can scale out

00:56:58,150 --> 00:57:02,080
and hopefully you know we say there's a

00:57:01,060 --> 00:57:03,550
lot of stuff that we've tried to

00:57:02,080 --> 00:57:05,410
simplify things like right now we have

00:57:03,550 --> 00:57:07,300
to do the handle management we go to you

00:57:05,410 --> 00:57:10,180
IDs it's you know a mathematical problem

00:57:07,300 --> 00:57:12,370
versus a lookup problem so we're trying

00:57:10,180 --> 00:57:14,110
to manage it but distributed systems do

00:57:12,370 --> 00:57:18,330
add problem that's why you need to be

00:57:14,110 --> 00:57:18,330
always online yeah

00:57:21,140 --> 00:57:29,329
that's a good one it so when you're

00:57:27,029 --> 00:57:31,259
writing a file you can't really do that

00:57:29,329 --> 00:57:33,689
real-time because you don't have you

00:57:31,259 --> 00:57:34,859
know how big is it I mean it's not as

00:57:33,689 --> 00:57:35,910
big as it is until you're done writing

00:57:34,859 --> 00:57:36,809
to me you know when you're the file

00:57:35,910 --> 00:57:39,650
system you drinking from the firehose

00:57:36,809 --> 00:57:41,699
but for the background operations

00:57:39,650 --> 00:57:43,229
definitely oh that one's big that one

00:57:41,699 --> 00:57:44,849
small okay put a few more out there if

00:57:43,229 --> 00:57:46,619
it's small or less or whatever and

00:57:44,849 --> 00:57:56,640
that's a good that's a good interesting

00:57:46,619 --> 00:57:58,499
policy I like that one yeah so SEF it

00:57:56,640 --> 00:57:59,880
really has the rado Slayer they really

00:57:58,499 --> 00:58:03,539
don't have the file system layer baked

00:57:59,880 --> 00:58:06,109
yet and then they'll say that as well we

00:58:03,539 --> 00:58:09,059
go to when we talk all the time you know

00:58:06,109 --> 00:58:11,009
they really have an object layer where

00:58:09,059 --> 00:58:12,539
they're hitting Hughes and then writing

00:58:11,009 --> 00:58:15,150
their objects to different points and

00:58:12,539 --> 00:58:16,920
they're really using a hashing algorithm

00:58:15,150 --> 00:58:19,289
which is the same thing that Gloucester

00:58:16,920 --> 00:58:20,609
does cluster basically they say metadata

00:58:19,289 --> 00:58:23,849
is bad you know they'll tell you that

00:58:20,609 --> 00:58:25,199
and I get up and say metadata is bad and

00:58:23,849 --> 00:58:27,359
as they do a half so you can calculate

00:58:25,199 --> 00:58:29,670
it and then you can go and you can write

00:58:27,359 --> 00:58:33,390
different objects and put your copies

00:58:29,670 --> 00:58:36,420
and different objects we do have the

00:58:33,390 --> 00:58:39,509
metadata in the middle but as you see as

00:58:36,420 --> 00:58:41,339
we added the distributed metadata for

00:58:39,509 --> 00:58:42,779
directory entries I want to by the way

00:58:41,339 --> 00:58:44,160
if you stuff your small files in the

00:58:42,779 --> 00:58:45,479
database we're going to beat the pants

00:58:44,160 --> 00:58:46,949
off of these other guys we're just doing

00:58:45,479 --> 00:58:48,929
hashing file don't care if you calculate

00:58:46,949 --> 00:58:51,749
look over there you're still having to

00:58:48,929 --> 00:58:53,130
think look access versus a single read

00:58:51,749 --> 00:58:55,650
boom you get your information out of a

00:58:53,130 --> 00:58:57,719
small small data out of a database so it

00:58:55,650 --> 00:58:59,729
different philosophies very smart people

00:58:57,719 --> 00:59:01,559
both of the other file systems very

00:58:59,729 --> 00:59:03,059
smart people what's really cool is we're

00:59:01,559 --> 00:59:04,739
all working in this parallel file system

00:59:03,059 --> 00:59:07,400
space and learn from each other same

00:59:04,739 --> 00:59:07,400
with the lustre guys

00:59:18,750 --> 00:59:27,250
so the data store behind kvm or the data

00:59:22,930 --> 00:59:39,460
store building it in kvm this is really

00:59:27,250 --> 00:59:40,930
hard hit say so some people have tested

00:59:39,460 --> 00:59:47,080
that and tried that we're actually

00:59:40,930 --> 00:59:48,490
having a project writing a qemu drivers

00:59:47,080 --> 00:59:51,400
driver the right word I camera but a

00:59:48,490 --> 00:59:53,590
qemu driver that allows you to actually

00:59:51,400 --> 00:59:55,600
directly access and write stuff to

00:59:53,590 --> 00:59:57,670
Orange FS it'll use our user space

00:59:55,600 --> 00:59:59,230
library so it'll bypass the colonel if

00:59:57,670 --> 01:00:01,030
she get some performance numbers out of

00:59:59,230 --> 01:00:02,560
that we just started working on that we

01:00:01,030 --> 01:00:05,500
kind of started working on the big data

01:00:02,560 --> 01:00:09,430
Hadoop problem first because we saw the

01:00:05,500 --> 01:00:10,690
other guys were going there and and one

01:00:09,430 --> 01:00:12,310
of the big things people are saying is

01:00:10,690 --> 01:00:13,900
we've got a lot of feedback we don't

01:00:12,310 --> 01:00:15,190
want to build these complex things under

01:00:13,900 --> 01:00:16,750
the file system just make the file

01:00:15,190 --> 01:00:18,010
system replicate and resilient we don't

01:00:16,750 --> 01:00:20,650
want that out of the layer of complexity

01:00:18,010 --> 01:00:21,970
so we kind of said okay let's go build 3

01:00:20,650 --> 01:00:23,680
dot 0 and then we'll address that

01:00:21,970 --> 01:00:28,270
Performa should be really good VMs are

01:00:23,680 --> 01:00:30,400
large files qemu buffers things before

01:00:28,270 --> 01:00:39,390
it writes if you set it up right so it

01:00:30,400 --> 01:00:39,390
should do really good performance overt

01:00:45,950 --> 01:00:52,230
well there's live bird but it's really

01:00:49,339 --> 01:00:54,630
qemu which actually it yeah off to look

01:00:52,230 --> 01:00:56,880
at that I haven't doesn't have to look

01:00:54,630 --> 01:01:02,369
at that one but we haven't done that

01:00:56,880 --> 01:01:05,430
obviously so I have to look at that so I

01:01:02,369 --> 01:01:07,589
got like it's like time but any more

01:01:05,430 --> 01:01:09,089
questions I just briefly through these

01:01:07,589 --> 01:01:10,829
last few slides just for some

01:01:09,089 --> 01:01:13,140
interesting research type stuff that's

01:01:10,829 --> 01:01:15,000
happening extend capability-based

01:01:13,140 --> 01:01:19,440
security I talked about that where you

01:01:15,000 --> 01:01:21,780
could actually do access based on you

01:01:19,440 --> 01:01:23,460
know for federated people Sdn OpenFlow

01:01:21,780 --> 01:01:26,220
we're looking at working on a project

01:01:23,460 --> 01:01:28,319
that allows you to leverage open flow to

01:01:26,220 --> 01:01:30,329
optimize your band your bandwidth

01:01:28,319 --> 01:01:34,310
optimization between sites i transfers

01:01:30,329 --> 01:01:37,369
spin up a flow multiple flows and then

01:01:34,310 --> 01:01:41,130
he's told me have 30 seconds left and

01:01:37,369 --> 01:01:43,079
then parallel X is a research project

01:01:41,130 --> 01:01:45,750
where you essentially have an

01:01:43,079 --> 01:01:47,490
asynchronous hey gasp or address space

01:01:45,750 --> 01:01:49,950
that's global across multiple systems

01:01:47,490 --> 01:01:51,750
and then that will actually tear out to

01:01:49,950 --> 01:01:55,140
file system objects and they're looking

01:01:51,750 --> 01:01:57,150
at taking managing memory is the same

01:01:55,140 --> 01:01:59,160
way you manage files and it just kind of

01:01:57,150 --> 01:02:00,510
seamlessly manages it behind the scene

01:01:59,160 --> 01:02:03,089
so that's kind of a research project

01:02:00,510 --> 01:02:06,450
that's interesting vxfs is kind of the

01:02:03,089 --> 01:02:08,339
back end of that I talked about so there

01:02:06,450 --> 01:02:09,420
we go let's well learn more there's some

01:02:08,339 --> 01:02:11,400
more information which you can't read

01:02:09,420 --> 01:02:14,060
because it's orange but we'll put the

01:02:11,400 --> 01:02:17,060
slides up so y'all can download them

01:02:14,060 --> 01:02:17,060
thank

01:03:08,330 --> 01:03:13,380
most enterprises today realize that

01:03:11,130 --> 01:03:15,060
usernames and passwords alone aren't

01:03:13,380 --> 01:03:17,430
enough to keep their network seen from

01:03:15,060 --> 01:03:19,500
unauthorized intrusions that's my

01:03:17,430 --> 01:03:21,540
two-factor authentication has gotten so

01:03:19,500 --> 01:03:23,670
popular lately that adds that extra

01:03:21,540 --> 01:03:26,340
layer of protection enterprise networks

01:03:23,670 --> 01:03:28,110
need to stay safe but what you may not

01:03:26,340 --> 01:03:30,300
know is that some two-factor

01:03:28,110 --> 01:03:32,520
authentication solutions they're better

01:03:30,300 --> 01:03:35,550
than others like to factor strong

01:03:32,520 --> 01:03:37,830
authentication with wicked wicked goes

01:03:35,550 --> 01:03:39,780
beyond other authentication systems by

01:03:37,830 --> 01:03:42,840
being less expensive easier to implement

01:03:39,780 --> 01:03:45,330
and easier to use giving software-based

01:03:42,840 --> 01:03:48,180
token clients built to run on all major

01:03:45,330 --> 01:03:50,780
devices and OSS including iOS and

01:03:48,180 --> 01:03:53,130
Android these tokens utilize a

01:03:50,780 --> 01:03:55,530
public/private key combination that's

01:03:53,130 --> 01:03:57,480
generated on device so there aren't any

01:03:55,530 --> 01:04:00,000
shared secrets flying around for

01:03:57,480 --> 01:04:02,850
attackers to hijack or which require any

01:04:00,000 --> 01:04:04,710
special handling instead all keys are

01:04:02,850 --> 01:04:07,200
kept secure and private between the

01:04:04,710 --> 01:04:09,390
requesting token and your server which

01:04:07,200 --> 01:04:11,000
you control in house making it the most

01:04:09,390 --> 01:04:13,680
secure way possible to perform

01:04:11,000 --> 01:04:16,470
authentication encryption and with an

01:04:13,680 --> 01:04:19,260
extensive flexible API and support for

01:04:16,470 --> 01:04:21,240
protocols like ldap and radius wicket

01:04:19,260 --> 01:04:23,420
works with any enterprise network

01:04:21,240 --> 01:04:25,119
architecture to protect the

01:04:23,420 --> 01:04:27,609
Systems vital to your enterprise

01:04:25,119 --> 01:04:29,720
download your wicked free trial today

01:04:27,609 --> 01:04:31,490
regardless of whether you're considering

01:04:29,720 --> 01:04:33,500
two-factor authentication for the first

01:04:31,490 --> 01:04:36,530
time or just ready to ditch your

01:04:33,500 --> 01:04:38,930
existing expensive key file system we

01:04:36,530 --> 01:04:43,869
can help with easy to implement easy to

01:04:38,930 --> 01:04:43,869
use strong authentication from wicked

01:04:45,010 --> 01:04:49,309
your customers rely on your website or

01:04:47,780 --> 01:04:51,680
application if it's slower

01:04:49,309 --> 01:04:54,619
non-responsive it infuriates your users

01:04:51,680 --> 01:04:56,450
and costs you money keeping your

01:04:54,619 --> 01:04:59,970
business critical systems humming along

01:04:56,450 --> 01:05:02,280
requires insight into what they're doing

01:04:59,970 --> 01:05:04,230
your system metrics tells stories

01:05:02,280 --> 01:05:06,240
stories that can reveal performance

01:05:04,230 --> 01:05:08,580
bottlenecks resource limitations and

01:05:06,240 --> 01:05:10,140
other problems but how do you keep an

01:05:08,580 --> 01:05:12,780
eye on all of your systems performance

01:05:10,140 --> 01:05:15,840
metrics in real-time and record this

01:05:12,780 --> 01:05:17,580
data for later analysis enter longview

01:05:15,840 --> 01:05:19,590
the new way to see what's really going

01:05:17,580 --> 01:05:21,750
on under the hood the long view

01:05:19,590 --> 01:05:23,820
dashboard lets you visualize the status

01:05:21,750 --> 01:05:26,280
of all your systems providing you with a

01:05:23,820 --> 01:05:29,640
bird's-eye view of your entire fleet you

01:05:26,280 --> 01:05:32,220
can sort by cpu memory swap processes

01:05:29,640 --> 01:05:33,990
load and network usage click a specific

01:05:32,220 --> 01:05:36,390
system to access its individual

01:05:33,990 --> 01:05:38,900
dashboard then click and drag to zoom in

01:05:36,390 --> 01:05:41,310
on chokepoints and get more detail

01:05:38,900 --> 01:05:42,990
comprehensive network data including

01:05:41,310 --> 01:05:45,300
inbound and outbound traffic is

01:05:42,990 --> 01:05:46,859
available on the network tab and disk

01:05:45,300 --> 01:05:48,780
rights and free space on the disk

01:05:46,859 --> 01:05:51,630
stabbed while the process Explorer

01:05:48,780 --> 01:05:54,150
displays usage statistics for individual

01:05:51,630 --> 01:05:56,310
processes the system info tab shows

01:05:54,150 --> 01:05:58,560
listening services active connections

01:05:56,310 --> 01:06:00,690
and available updates adding long view

01:05:58,560 --> 01:06:02,400
to a system is easy just click the

01:06:00,690 --> 01:06:04,530
button copy the one line installation

01:06:02,400 --> 01:06:06,990
command then run the command on your

01:06:04,530 --> 01:06:08,700
linux system to complete the process the

01:06:06,990 --> 01:06:10,859
agent will begin collecting data and

01:06:08,700 --> 01:06:12,720
sending it to longview then the graph

01:06:10,859 --> 01:06:15,270
start rolling

01:06:12,720 --> 01:06:17,640
use longview to gain visibility into

01:06:15,270 --> 01:06:21,380
your servers so when your website or app

01:06:17,640 --> 01:06:21,380
heats up it stays up

01:06:24,570 --> 01:06:29,650
when we created asterisk over a decade

01:06:27,280 --> 01:06:31,599
ago we could not have imagined that

01:06:29,650 --> 01:06:33,790
asterisk would not only become the most

01:06:31,599 --> 01:06:35,950
widely adopted open source communication

01:06:33,790 --> 01:06:37,960
software on the planet but that it would

01:06:35,950 --> 01:06:40,480
impact the entire industry in the way

01:06:37,960 --> 01:06:42,460
that it has today asterisk has found its

01:06:40,480 --> 01:06:45,099
way in the more than 170 countries and

01:06:42,460 --> 01:06:47,050
virtually every fortune 1000 company the

01:06:45,099 --> 01:06:49,150
success of asterisk has enabled a

01:06:47,050 --> 01:06:50,560
transition of power from the hands of

01:06:49,150 --> 01:06:52,839
the traditional proprietary phone

01:06:50,560 --> 01:06:55,210
vendors into the hands of the users and

01:06:52,839 --> 01:06:57,160
administrators of phone systems using

01:06:55,210 --> 01:06:58,390
this power our customers have created

01:06:57,160 --> 01:07:00,339
all sorts of business changing

01:06:58,390 --> 01:07:02,170
applications from small office phone

01:07:00,339 --> 01:07:04,690
systems to mission-critical call centers

01:07:02,170 --> 01:07:06,310
the international carrier networks in

01:07:04,690 --> 01:07:08,080
fact there's even an entire country

01:07:06,310 --> 01:07:10,690
those communications infrastructure runs

01:07:08,080 --> 01:07:12,609
on esters the gym has always been about

01:07:10,690 --> 01:07:14,320
creating technology that expands

01:07:12,609 --> 01:07:16,510
communications capabilities in ways that

01:07:14,320 --> 01:07:17,680
we could never have imagined and that's

01:07:16,510 --> 01:07:20,440
part of what's game-changing about

01:07:17,680 --> 01:07:22,780
Digium today we're doing it again this

01:07:20,440 --> 01:07:24,880
time by introducing a new family of HD

01:07:22,780 --> 01:07:26,980
IP phones that extends control of the

01:07:24,880 --> 01:07:28,750
user all the way to the desktop the

01:07:26,980 --> 01:07:30,460
launch of these new products represents

01:07:28,750 --> 01:07:32,440
the next phase indigenous history of

01:07:30,460 --> 01:07:34,960
innovation these are the first and only

01:07:32,440 --> 01:07:36,670
IP phones designed to fully leverage the

01:07:34,960 --> 01:07:38,230
power of estrus when we first discussed

01:07:36,670 --> 01:07:40,240
our expectations for building a family

01:07:38,230 --> 01:07:42,400
of phones for use with asterisk our

01:07:40,240 --> 01:07:44,140
requirements were pretty simple we asked

01:07:42,400 --> 01:07:45,790
the team to build the phones such that

01:07:44,140 --> 01:07:47,980
they were easy to install integrate

01:07:45,790 --> 01:07:49,810
provision and use I think you'll soon

01:07:47,980 --> 01:07:52,390
agree our engineers have delivered on

01:07:49,810 --> 01:07:54,010
that goal user feedback is validating

01:07:52,390 --> 01:07:56,140
that when it comes to operation with

01:07:54,010 --> 01:07:58,570
asher space systems including our own

01:07:56,140 --> 01:08:01,119
Switchvox based product these are the

01:07:58,570 --> 01:08:02,440
easiest to use best integrated most

01:08:01,119 --> 01:08:05,020
interoperable products on the market

01:08:02,440 --> 01:08:07,020
today the digitally of phones will

01:08:05,020 --> 01:08:09,070
initially include three IP des hommes

01:08:07,020 --> 01:08:11,020
uniquely designed to complement any

01:08:09,070 --> 01:08:12,880
asterisks or Switchvox based solution

01:08:11,020 --> 01:08:15,550
these phones are different for a number

01:08:12,880 --> 01:08:18,219
of reasons first there is clue sively

01:08:15,550 --> 01:08:19,630
designed for use with esters secondly

01:08:18,219 --> 01:08:21,089
we've made it really easy to

01:08:19,630 --> 01:08:23,650
autodiscover and provision the phones

01:08:21,089 --> 01:08:25,719
next we've made it easy for the phones

01:08:23,650 --> 01:08:27,670
to access information inside of asterisk

01:08:25,719 --> 01:08:28,690
allowing tight coupling between an

01:08:27,670 --> 01:08:31,239
application and the

01:08:28,690 --> 01:08:33,400
phone additionally we've created an

01:08:31,239 --> 01:08:35,529
applications engine that allows users

01:08:33,400 --> 01:08:38,770
and developers to create and run their

01:08:35,529 --> 01:08:40,540
own apps on the phone and finally we've

01:08:38,770 --> 01:08:42,489
done all of this at a very compelling

01:08:40,540 --> 01:08:44,170
price point at Digium we're always

01:08:42,489 --> 01:08:46,270
thinking of ways to give our customers

01:08:44,170 --> 01:08:48,790
the best value in business phone systems

01:08:46,270 --> 01:08:50,380
and also give them the power to create

01:08:48,790 --> 01:08:52,540
their own solutions or any

01:08:50,380 --> 01:08:54,250
communications challenge will continue

01:08:52,540 --> 01:08:55,719
to push the boundaries not only to make

01:08:54,250 --> 01:08:57,759
Astra's cooler bastard more

01:08:55,719 --> 01:08:59,500
technologically feature-rich but to make

01:08:57,759 --> 01:09:02,020
asterisk and communications even easier

01:08:59,500 --> 01:09:05,549
and together we'll change the way the

01:09:02,020 --> 01:09:05,549
world communicates again

01:09:16,250 --> 01:09:23,430
prospects I every way this is the way to

01:09:19,740 --> 01:09:25,350
better utilize all your resources and it

01:09:23,430 --> 01:09:28,410
makes managing all your resources pretty

01:09:25,350 --> 01:09:33,270
easy all of the innovation is happening

01:09:28,410 --> 01:09:36,600
in open source the collaborative nature

01:09:33,270 --> 01:09:39,300
and of the you know of the community and

01:09:36,600 --> 01:09:41,190
the speed at which these are these you

01:09:39,300 --> 01:09:43,290
know these these deficiencies these bugs

01:09:41,190 --> 01:09:45,630
are getting discovered and then fixed is

01:09:43,290 --> 01:09:49,020
it I think that really shows the power

01:09:45,630 --> 01:09:50,880
of the of the open source community it

01:09:49,020 --> 01:09:55,080
is global and it's definitely because of

01:09:50,880 --> 01:10:01,410
the users community people are extremely

01:09:55,080 --> 01:10:03,180
friendly and always ready to help if you

01:10:01,410 --> 01:10:04,610
go an entire see any day you'll see

01:10:03,180 --> 01:10:06,720
these guys helping each other out and

01:10:04,610 --> 01:10:09,630
they're all doing it like in a selfless

01:10:06,720 --> 01:10:11,460
manner the product is transparent for

01:10:09,630 --> 01:10:15,660
everyone everyone can look at the code

01:10:11,460 --> 01:10:17,700
base everyone can see how close darkest

01:10:15,660 --> 01:10:23,550
is being built nothing nothing is

01:10:17,700 --> 01:10:26,220
proprietary everything is open in many

01:10:23,550 --> 01:10:30,390
ways it's absolutely vital to the the

01:10:26,220 --> 01:10:34,170
ongoing health card stack the most

01:10:30,390 --> 01:10:37,920
exciting event in recent memory for me

01:10:34,170 --> 01:10:40,740
was our first developer boot camp and

01:10:37,920 --> 01:10:43,380
our call gave people I gave you two

01:10:40,740 --> 01:10:47,340
weeks notice to come attend I was

01:10:43,380 --> 01:10:51,510
expecting 25 or 30 people so we ended up

01:10:47,340 --> 01:10:54,330
with 87 people and had to go get more

01:10:51,510 --> 01:10:56,880
chairs into the room twice everything

01:10:54,330 --> 01:11:00,210
within cloud computing is commodity and

01:10:56,880 --> 01:11:03,180
is open source and so I don't think that

01:11:00,210 --> 01:11:04,950
you will you'll see anywhere where open

01:11:03,180 --> 01:11:07,980
source is not pervasive in cloud

01:11:04,950 --> 01:11:10,680
computing and so i think it's i think

01:11:07,980 --> 01:11:12,060
it's an assumption i think when you talk

01:11:10,680 --> 01:11:13,170
about cloud computing you're really

01:11:12,060 --> 01:11:18,720
talking about open source cloud

01:11:13,170 --> 01:11:21,870
computing cloud sac is a robust solution

01:11:18,720 --> 01:11:24,270
for large deployments you have dozens of

01:11:21,870 --> 01:11:28,170
data centers and thousands of servers in

01:11:24,270 --> 01:11:30,840
each data centers these hardware is

01:11:28,170 --> 01:11:34,320
going to fail and cloudstack is designed

01:11:30,840 --> 01:11:37,020
to handle number one that mass scale

01:11:34,320 --> 01:11:40,200
number two it's designed to handle the

01:11:37,020 --> 01:11:43,050
failure that inevitably happens in large

01:11:40,200 --> 01:11:47,250
deployments started working on kosdaq

01:11:43,050 --> 01:11:50,520
over four years ago and it was the

01:11:47,250 --> 01:11:52,320
original set of people working on it had

01:11:50,520 --> 01:11:56,400
a background of delivering software

01:11:52,320 --> 01:12:00,660
telcos and service providers lots of QA

01:11:56,400 --> 01:12:04,260
lots of users actually using it high

01:12:00,660 --> 01:12:07,350
availability is a key feature multiple

01:12:04,260 --> 01:12:09,510
hypervisors support different network

01:12:07,350 --> 01:12:12,540
models we can pick up whatever suits you

01:12:09,510 --> 01:12:14,310
better while step management server can

01:12:12,540 --> 01:12:18,000
be deployed in different physical

01:12:14,310 --> 01:12:19,650
machines it definitely has a huge

01:12:18,000 --> 01:12:24,630
footprint it's being deployed everywhere

01:12:19,650 --> 01:12:27,210
there's a major movie studio that they

01:12:24,630 --> 01:12:30,510
were using CloudStack they were using it

01:12:27,210 --> 01:12:32,490
to transcode video and I thought that

01:12:30,510 --> 01:12:34,140
was terribly fascinating what I found

01:12:32,490 --> 01:12:37,410
more fascinating is what they did during

01:12:34,140 --> 01:12:40,200
lunch where they would spin up you know

01:12:37,410 --> 01:12:41,340
50 or 60 game servers then as soon as

01:12:40,200 --> 01:12:43,199
lunch was over they would just

01:12:41,340 --> 01:12:47,340
all the instances and go back to doing

01:12:43,199 --> 01:12:48,960
real work CloudStack is vast it touches

01:12:47,340 --> 01:12:51,030
so many different aspects and there's no

01:12:48,960 --> 01:12:53,400
one person that's kind of like a master

01:12:51,030 --> 01:12:57,540
of all those realms I think cloudstack

01:12:53,400 --> 01:12:59,760
as a project is going to be one of the

01:12:57,540 --> 01:13:03,810
leaders simply because it's some of the

01:12:59,760 --> 01:13:09,239
most feature fallen and and robust

01:13:03,810 --> 01:13:12,139
platforms out they were Adam senior

01:13:09,239 --> 01:13:12,139
living through the clouds dag

01:13:21,730 --> 01:13:23,790
you

01:13:24,880 --> 01:13:26,940

YouTube URL: https://www.youtube.com/watch?v=e4fam8lcj4A


