Title: 2014 SouthEast LinuxFest - Andy Grimm - An Introduction To CGroups
Publication date: 2015-05-02
Playlist: 2014 SouthEast LinuxFest
Description: 
	2014 SouthEast LinuxFest
Andy Grimm
An Introduction To CGroups
Captions: 
	00:00:00,060 --> 00:00:05,339
the following presentation was recorded

00:00:02,100 --> 00:00:08,189
the 2014 southeast linux fest in

00:00:05,339 --> 00:00:10,320
charlotte north carolina it is licensed

00:00:08,189 --> 00:00:15,890
under a Creative Commons license

00:00:10,320 --> 00:00:18,480
for more information visit www.mchcp.org

00:00:15,890 --> 00:00:20,750
the south east linux fest would like to

00:00:18,480 --> 00:00:22,980
thank the following diamond sponsors in

00:00:20,750 --> 00:00:25,410
2014 for helping make these videos

00:00:22,980 --> 00:00:28,380
possible ladies and gentlemen thank you

00:00:25,410 --> 00:00:31,619
for joining us here with self 2014 that

00:00:28,380 --> 00:00:33,600
is the year I yeah this is Andy Graham

00:00:31,619 --> 00:00:35,520
he's an Operations Support Engineer at

00:00:33,600 --> 00:00:38,730
Red Hat he's here to talk about cgroups

00:00:35,520 --> 00:00:42,930
I'm sure we'll all learn a lot I'll

00:00:38,730 --> 00:00:45,120
leave with you okay thanks yeah as I

00:00:42,930 --> 00:00:48,000
said I'm Andy I am an operations

00:00:45,120 --> 00:00:49,829
engineer which means that for OpenShift

00:00:48,000 --> 00:00:52,050
online I'm basically supporting the

00:00:49,829 --> 00:00:53,460
operating system underneath

00:00:52,050 --> 00:00:57,570
everyone's web apps that they're

00:00:53,460 --> 00:00:59,910
launching an open shift so it's been a

00:00:57,570 --> 00:01:03,660
really interesting exercise in trying to

00:00:59,910 --> 00:01:06,000
contain users and see groups is just one

00:01:03,660 --> 00:01:09,530
small part of what we use to do that and

00:01:06,000 --> 00:01:09,530
that's what I'd like to talk about today

00:01:10,159 --> 00:01:16,619
so just a brief rundown of how I've

00:01:13,740 --> 00:01:18,780
structured this first just a little bit

00:01:16,619 --> 00:01:21,270
about you know what see groups are and

00:01:18,780 --> 00:01:23,549
and why you should care about them then

00:01:21,270 --> 00:01:26,400
we'll talk about a couple of the most

00:01:23,549 --> 00:01:29,729
commonly used control groups and and

00:01:26,400 --> 00:01:31,409
tuna bowls and then I'll get into some

00:01:29,729 --> 00:01:33,479
of the the tools that you use to

00:01:31,409 --> 00:01:35,729
actually set up your configuration files

00:01:33,479 --> 00:01:40,290
and get your processes placed in to see

00:01:35,729 --> 00:01:42,630
groups and and then we'll talk about

00:01:40,290 --> 00:01:44,220
system D and how that kind of changed

00:01:42,630 --> 00:01:47,759
the way that C groups are being managed

00:01:44,220 --> 00:01:48,990
in newer Linux distros and as we have

00:01:47,759 --> 00:01:50,490
time maybe we'll talk about other

00:01:48,990 --> 00:01:52,110
controllers and things I don't exactly

00:01:50,490 --> 00:01:53,310
know how long in this talk is gonna take

00:01:52,110 --> 00:01:56,369
because there might be a lot of

00:01:53,310 --> 00:01:58,799
questions so things like block IO and

00:01:56,369 --> 00:02:03,240
stuff I'm leaving until the end okay so

00:01:58,799 --> 00:02:05,070
why you should all care about this so so

00:02:03,240 --> 00:02:08,340
control groups basically are for

00:02:05,070 --> 00:02:10,800
containing processes on the system so

00:02:08,340 --> 00:02:12,540
that they don't take down the system as

00:02:10,800 --> 00:02:13,210
a whole or so that you can have some

00:02:12,540 --> 00:02:15,340
reliable

00:02:13,210 --> 00:02:17,140
level of service for applications on

00:02:15,340 --> 00:02:20,770
that system so you know if you've ever

00:02:17,140 --> 00:02:22,450
had you know a bad plugin in Firefox you

00:02:20,770 --> 00:02:25,720
know a bad flash app or something take

00:02:22,450 --> 00:02:28,960
down your whole laptop or you know if

00:02:25,720 --> 00:02:30,640
you're a sysadmin and you run servers

00:02:28,960 --> 00:02:32,680
where you know you have various

00:02:30,640 --> 00:02:35,770
developers who are competing for

00:02:32,680 --> 00:02:38,110
resources cgroups is a way to sort of

00:02:35,770 --> 00:02:40,270
keep them in line and have a a peaceful

00:02:38,110 --> 00:02:41,890
multi-tenant environment where you can

00:02:40,270 --> 00:02:44,020
guarantee that everyone has a certain

00:02:41,890 --> 00:02:49,630
portion of the CPU and the memory and so

00:02:44,020 --> 00:02:51,610
on so yeah just a quick list you know

00:02:49,630 --> 00:02:55,240
you you can use cgroups to try to

00:02:51,610 --> 00:02:57,610
contain malicious and buggy apps lower

00:02:55,240 --> 00:02:59,110
the maximum latency that an app has you

00:02:57,610 --> 00:03:03,850
know when you're talking about the world

00:02:59,110 --> 00:03:06,100
of web apps is getting CPU at the right

00:03:03,850 --> 00:03:08,230
time is very important so making sure

00:03:06,100 --> 00:03:10,060
that things get sliced up you know when

00:03:08,230 --> 00:03:13,210
you're running you know 20 or 30 apps

00:03:10,060 --> 00:03:15,400
concurrently is really important and

00:03:13,210 --> 00:03:18,940
cgroups help do that you're providing

00:03:15,400 --> 00:03:21,100
more predictable performance so that you

00:03:18,940 --> 00:03:23,410
know when someone tests does a load test

00:03:21,100 --> 00:03:26,680
at one point and get sort of a certain

00:03:23,410 --> 00:03:28,660
result in their benchmark they can rely

00:03:26,680 --> 00:03:30,730
on that because you've you've sort of

00:03:28,660 --> 00:03:32,080
made a guarantee that you know this is

00:03:30,730 --> 00:03:35,140
if you don't over commit too much of

00:03:32,080 --> 00:03:36,490
course you can guarantee that they're

00:03:35,140 --> 00:03:38,770
going to get what they're allocated in

00:03:36,490 --> 00:03:40,420
their C group and just in general you

00:03:38,770 --> 00:03:43,510
know you can allow a greater utilization

00:03:40,420 --> 00:03:46,900
of your resources you know you can do

00:03:43,510 --> 00:03:48,460
higher density in your environment if

00:03:46,900 --> 00:03:54,880
you can guarantee that these apps can't

00:03:48,460 --> 00:03:56,530
step on each other as much so just to

00:03:54,880 --> 00:03:58,240
give you an idea of what all is out

00:03:56,530 --> 00:03:59,680
there there are there are a lot of

00:03:58,240 --> 00:04:01,720
controllers we won't have time to talk

00:03:59,680 --> 00:04:04,960
about all these for sure there are

00:04:01,720 --> 00:04:08,020
controllers for memory CPU Network

00:04:04,960 --> 00:04:10,780
classes which basically allow you to use

00:04:08,020 --> 00:04:13,390
a traffic controller app to throttle

00:04:10,780 --> 00:04:17,680
bandwidth and things like that there's a

00:04:13,390 --> 00:04:24,220
devices control group wait till these

00:04:17,680 --> 00:04:27,340
guys shut the door so the the devices

00:04:24,220 --> 00:04:30,490
control group allows you to actually

00:04:27,340 --> 00:04:34,840
devices on the system from processes in

00:04:30,490 --> 00:04:37,629
that group the freezer allows you to

00:04:34,840 --> 00:04:40,240
basically temporarily pause applications

00:04:37,629 --> 00:04:43,479
to potentially move them somewhere else

00:04:40,240 --> 00:04:47,740
there's a block IO for for disk IO

00:04:43,479 --> 00:04:50,199
obviously and huge TLB has to do with

00:04:47,740 --> 00:04:54,909
memory allocation and and then CPU sets

00:04:50,199 --> 00:04:57,129
has to do with basically CPU and memory

00:04:54,909 --> 00:04:58,419
pooling I'm not real familiar with that

00:04:57,129 --> 00:05:01,900
one and I don't think we'll have time

00:04:58,419 --> 00:05:04,120
for it but anyway this is how the list

00:05:01,900 --> 00:05:06,550
has grown over time you know it sort of

00:05:04,120 --> 00:05:09,569
started with CPU and memory and and then

00:05:06,550 --> 00:05:12,340
people figured out ways to implement

00:05:09,569 --> 00:05:14,229
control groups for other resources on

00:05:12,340 --> 00:05:17,039
the system that people wanted to to be

00:05:14,229 --> 00:05:21,009
able to slice up this way

00:05:17,039 --> 00:05:24,580
so the most common things that people

00:05:21,009 --> 00:05:26,710
use cgroups for are are simply limiting

00:05:24,580 --> 00:05:32,069
the amount of memory that processes can

00:05:26,710 --> 00:05:35,469
can consume and then setting a cpu quota

00:05:32,069 --> 00:05:38,830
basically saying that this c group can

00:05:35,469 --> 00:05:41,050
only use 30% of the CPUs on this system

00:05:38,830 --> 00:05:42,909
at all times and after that it should

00:05:41,050 --> 00:05:47,020
you know have to wait until the next

00:05:42,909 --> 00:05:51,719
cycle so what we'll sort of talk about

00:05:47,020 --> 00:05:51,719
those first and go through some demos

00:05:55,199 --> 00:06:03,569
so the the tools that you can use to

00:05:58,379 --> 00:06:07,949
create C groups on the fly are CG create

00:06:03,569 --> 00:06:13,740
and CG set basically all these are doing

00:06:07,949 --> 00:06:18,479
is writing to virtual files in the C

00:06:13,740 --> 00:06:21,360
group file system structure the the C

00:06:18,479 --> 00:06:23,039
group subsystems are mounted sort of

00:06:21,360 --> 00:06:25,680
like proc it's a virtual file system

00:06:23,039 --> 00:06:27,990
where you can cat things and echo things

00:06:25,680 --> 00:06:31,289
and and these are basically just helpers

00:06:27,990 --> 00:06:38,639
to to do that for you you can do the

00:06:31,289 --> 00:06:40,770
same things with make der and echo so

00:06:38,639 --> 00:06:45,539
actually I'm gonna do some quick demoing

00:06:40,770 --> 00:06:47,249
first here so yeah we can start with a

00:06:45,539 --> 00:06:49,379
simple command to see where things are

00:06:47,249 --> 00:06:52,159
mounted on your own system if you've got

00:06:49,379 --> 00:06:56,279
a laptop and you're playing along here

00:06:52,159 --> 00:07:00,360
you can use the mount command and see if

00:06:56,279 --> 00:07:10,740
you look actually it's not showing my

00:07:00,360 --> 00:07:12,990
first demo failure so there we go so if

00:07:10,740 --> 00:07:14,339
we cat proc mounts on this particular

00:07:12,990 --> 00:07:17,159
system we get something different than

00:07:14,339 --> 00:07:20,279
what mount shows us and you'll see in

00:07:17,159 --> 00:07:24,149
the list here that we have C group

00:07:20,279 --> 00:07:26,930
mounts for the various controllers so we

00:07:24,149 --> 00:07:31,259
have cpu set CPU CPU account and so on

00:07:26,930 --> 00:07:35,789
so we can go into one of these

00:07:31,259 --> 00:07:37,229
directories and there are all these

00:07:35,789 --> 00:07:41,330
helpful files some of these are

00:07:37,229 --> 00:07:44,520
read-only and some of them are writable

00:07:41,330 --> 00:07:48,839
although the permissions don't give us a

00:07:44,520 --> 00:07:51,539
good indication of that so so we can see

00:07:48,839 --> 00:07:53,849
statistics like you know the usage in

00:07:51,539 --> 00:07:55,789
bytes overall for this particular

00:07:53,849 --> 00:08:03,449
control group and and things like that

00:07:55,789 --> 00:08:07,279
so if we want to create a group here we

00:08:03,449 --> 00:08:07,279
can use CG create

00:08:07,940 --> 00:08:14,670
let's make sure I get these parameters

00:08:10,080 --> 00:08:17,310
right so we can say in the memory

00:08:14,670 --> 00:08:23,130
controller I want to create a group

00:08:17,310 --> 00:08:26,040
called foo and then if we look here we

00:08:23,130 --> 00:08:31,140
see that there's now a directory called

00:08:26,040 --> 00:08:36,030
foo and it has magically all the same

00:08:31,140 --> 00:08:39,919
things in it just the same we could do

00:08:36,030 --> 00:08:43,290
make door bar and if we see in the bar

00:08:39,919 --> 00:08:45,420
all those files just show up so

00:08:43,290 --> 00:08:50,670
basically it works the same way whether

00:08:45,420 --> 00:08:53,070
you use CG creator maker so for setting

00:08:50,670 --> 00:08:56,370
a parameter say limited bytes the

00:08:53,070 --> 00:08:57,540
default limit is something strange more

00:08:56,370 --> 00:09:06,540
memory than you could possibly have

00:08:57,540 --> 00:09:09,590
right you can do CG set - G memory make

00:09:06,540 --> 00:09:09,590
sure I get this syntax right

00:09:15,790 --> 00:09:24,930
it's actually but

00:09:26,950 --> 00:09:32,310
something like that for

00:09:40,100 --> 00:09:44,920
that strangely didn't do what I expected

00:09:42,740 --> 00:09:44,920
but

00:10:06,370 --> 00:10:13,300
that's not really what you want at all

00:10:08,110 --> 00:10:17,800
that is oh I know what it did it rounded

00:10:13,300 --> 00:10:19,360
to a page yeah so yeah that's that's a

00:10:17,800 --> 00:10:24,550
point I should have done my math right

00:10:19,360 --> 00:10:30,819
so if I took something like you know 768

00:10:24,550 --> 00:10:42,939
x 1024 or whatever that should be a good

00:10:30,819 --> 00:10:44,470
round number right so it is actually

00:10:42,939 --> 00:10:46,480
setting things properly it's just

00:10:44,470 --> 00:10:48,249
rounding to a page there but you can see

00:10:46,480 --> 00:10:53,019
CG set and echo basically do the same

00:10:48,249 --> 00:10:56,319
thing the primary reason that people use

00:10:53,019 --> 00:10:57,790
the CG helper functions is that then you

00:10:56,319 --> 00:10:59,829
don't have to worry about looking up

00:10:57,790 --> 00:11:01,629
where your mouth point is each time you

00:10:59,829 --> 00:11:04,990
can just let the controllers live where

00:11:01,629 --> 00:11:12,699
they live and and use the CG stuff to to

00:11:04,990 --> 00:11:14,199
fetch and set so next let's talk a

00:11:12,699 --> 00:11:19,089
little bit about how you place

00:11:14,199 --> 00:11:21,910
applications so CG exec is is one way

00:11:19,089 --> 00:11:24,550
where when you launch a cask you can say

00:11:21,910 --> 00:11:26,259
CG exec and and give it some

00:11:24,550 --> 00:11:28,809
command-line options to tell it which

00:11:26,259 --> 00:11:31,029
controllers you want to turn on and and

00:11:28,809 --> 00:11:36,240
then you give the command line after

00:11:31,029 --> 00:11:39,339
that CG classify is a way to take a an

00:11:36,240 --> 00:11:43,959
existing process and reclassify it into

00:11:39,339 --> 00:11:47,199
a C group Pam C group is something that

00:11:43,959 --> 00:11:49,809
you can use when users log in or when

00:11:47,199 --> 00:11:51,069
processes are launched with run user or

00:11:49,809 --> 00:11:56,829
something else that goes through the Pam

00:11:51,069 --> 00:11:59,139
stack and then CG rules engine D is yet

00:11:56,829 --> 00:12:02,199
another option that basically takes a

00:11:59,139 --> 00:12:05,529
set of potentially complex rules in a

00:12:02,199 --> 00:12:08,490
config file based on user and process

00:12:05,529 --> 00:12:13,089
name and group and things like that and

00:12:08,490 --> 00:12:17,049
basically monitors for tasks to be exact

00:12:13,089 --> 00:12:17,850
and for user ID changes and and GID

00:12:17,049 --> 00:12:19,890
change

00:12:17,850 --> 00:12:22,080
of the app and it gets it gets notified

00:12:19,890 --> 00:12:25,230
by the kernel on all of those events and

00:12:22,080 --> 00:12:26,790
and basically looks to see whether task

00:12:25,230 --> 00:12:31,140
needs to be moved to a different scene

00:12:26,790 --> 00:12:33,180
based on that and you can use just plain

00:12:31,140 --> 00:12:35,340
old echo into the file system into a

00:12:33,180 --> 00:12:37,560
file called C rooftop rocks and that

00:12:35,340 --> 00:12:43,880
works to move a task as well so we can

00:12:37,560 --> 00:12:48,780
look at some of those examples okay so

00:12:43,880 --> 00:12:57,030
let's say I have this busy wait process

00:12:48,780 --> 00:12:59,760
that I use as an example so it's very

00:12:57,030 --> 00:13:01,470
simple it's just a shell script that I

00:12:59,760 --> 00:13:05,550
guess I should move it to the top of the

00:13:01,470 --> 00:13:08,550
screen make sure that it gets on so very

00:13:05,550 --> 00:13:11,490
simple shell script that basically just

00:13:08,550 --> 00:13:15,630
counts it just does math so it can

00:13:11,490 --> 00:13:18,810
easily consume 100% of a CPU and so if I

00:13:15,630 --> 00:13:26,210
want to put that in a C group I can just

00:13:18,810 --> 00:13:26,210
do a CG exec - G CPU

00:13:36,600 --> 00:13:48,810
and then run that and now if I look at

00:13:46,120 --> 00:13:48,810
the C group

00:13:55,860 --> 00:14:00,720
I see that my process is is there I

00:13:58,740 --> 00:14:07,040
guess to show that it's the same process

00:14:00,720 --> 00:14:11,310
there's busy Adonis not s age 36 62 so

00:14:07,040 --> 00:14:13,890
that's one way to do it I can move that

00:14:11,310 --> 00:14:27,029
to another C group basically by saying

00:14:13,890 --> 00:14:31,589
echo 36 62 to see group CPU test like

00:14:27,029 --> 00:14:34,890
that and now if I go back and look at

00:14:31,589 --> 00:14:38,730
the original there are no processes in

00:14:34,890 --> 00:14:43,380
the see where the task was and it's

00:14:38,730 --> 00:14:53,540
moved into the sea group where I echoed

00:14:43,380 --> 00:14:53,540
it okay so about the configuration files

00:15:05,250 --> 00:15:11,830
okay so the way that you can configure

00:15:10,330 --> 00:15:13,210
these so that you're not always setting

00:15:11,830 --> 00:15:14,740
things on the fly because of course

00:15:13,210 --> 00:15:20,940
you're assisted min you want to only do

00:15:14,740 --> 00:15:29,460
things once is you have this cg config

00:15:20,940 --> 00:15:33,279
dot conf let's go through this with less

00:15:29,460 --> 00:15:35,200
so cg config is where you set up both

00:15:33,279 --> 00:15:38,410
the mount points for your controllers

00:15:35,200 --> 00:15:41,560
and and also the groups that you want to

00:15:38,410 --> 00:15:45,600
be on the system at runtime so first you

00:15:41,560 --> 00:15:47,920
have this mount section right here where

00:15:45,600 --> 00:15:49,860
you define which controllers are going

00:15:47,920 --> 00:15:52,860
to use you don't have to mount them all

00:15:49,860 --> 00:15:54,880
it is possible to mount controllers

00:15:52,860 --> 00:15:58,420
multiple controllers under the same

00:15:54,880 --> 00:16:01,510
mount point for example CPU and CPU

00:15:58,420 --> 00:16:03,220
account on your system might be mounted

00:16:01,510 --> 00:16:04,870
together and there might be sim linking

00:16:03,220 --> 00:16:07,990
between them and things some distros do

00:16:04,870 --> 00:16:10,779
it that way there's not any real

00:16:07,990 --> 00:16:14,440
advantage to doing that except that you

00:16:10,779 --> 00:16:15,850
have fewer mounts to look through when

00:16:14,440 --> 00:16:19,150
you're trying to figure out which tasks

00:16:15,850 --> 00:16:24,430
are where what you lose there is you

00:16:19,150 --> 00:16:27,730
can't put a task in one controller for

00:16:24,430 --> 00:16:29,350
memory and one for CPU if memory and CPU

00:16:27,730 --> 00:16:31,810
are mounted together because there's

00:16:29,350 --> 00:16:34,990
only one C group procs file for that

00:16:31,810 --> 00:16:36,550
combined mount so usually we do things

00:16:34,990 --> 00:16:38,410
separately and also you can't turn on

00:16:36,550 --> 00:16:45,610
and off controllers independently if

00:16:38,410 --> 00:16:48,490
they're mounted at the same place so

00:16:45,610 --> 00:16:53,020
here for example I've got a group for

00:16:48,490 --> 00:16:55,209
apache which i've used for some some

00:16:53,020 --> 00:16:58,660
testing so with the memory limit in

00:16:55,209 --> 00:17:01,779
bytes basically what happens when you

00:16:58,660 --> 00:17:06,850
run out of memory within your c group is

00:17:01,779 --> 00:17:08,050
your process gets killed so it turns out

00:17:06,850 --> 00:17:11,949
to be a little bit of an interesting

00:17:08,050 --> 00:17:13,569
challenge to decide what to do when

00:17:11,949 --> 00:17:14,600
processes get killed like that if you're

00:17:13,569 --> 00:17:19,030
a sysadmin you know

00:17:14,600 --> 00:17:21,410
how do you restart those or you know

00:17:19,030 --> 00:17:23,089
what state is your app going to be in

00:17:21,410 --> 00:17:25,939
when one of those gets killed is if

00:17:23,089 --> 00:17:28,309
you've ever witnessed a system boom kill

00:17:25,939 --> 00:17:29,720
event it's it's bad you usually you

00:17:28,309 --> 00:17:31,580
don't know which processes are going to

00:17:29,720 --> 00:17:34,549
get killed there's some tuning you can

00:17:31,580 --> 00:17:36,730
do but once something gets killed the

00:17:34,549 --> 00:17:39,260
whole system can be out of whack and you

00:17:36,730 --> 00:17:42,730
often just have to reboot to make sure

00:17:39,260 --> 00:17:45,260
that things are in good shape again so

00:17:42,730 --> 00:17:47,090
so really you don't want things to be um

00:17:45,260 --> 00:17:48,830
killed but but something has to happen

00:17:47,090 --> 00:17:52,159
when when the C group runs out of memory

00:17:48,830 --> 00:17:55,549
and room kill is the default so what it

00:17:52,159 --> 00:17:58,669
tries to do is there's a reclaim process

00:17:55,549 --> 00:18:00,890
that happens first where so the the

00:17:58,669 --> 00:18:04,909
memory that gets charged to a control

00:18:00,890 --> 00:18:07,130
group is it's not just you know your

00:18:04,909 --> 00:18:09,350
Malick's it's also you know your your

00:18:07,130 --> 00:18:12,169
file caches and things like that

00:18:09,350 --> 00:18:14,659
some of which can be dropped if you're

00:18:12,169 --> 00:18:16,250
running low on space so there there are

00:18:14,659 --> 00:18:17,809
processes in the kernel to try to do

00:18:16,250 --> 00:18:20,270
those things first to recover some

00:18:17,809 --> 00:18:24,710
memory but as a last resort you do get

00:18:20,270 --> 00:18:27,049
em killed the other thing to mention

00:18:24,710 --> 00:18:29,419
about how I've set this particular C

00:18:27,049 --> 00:18:32,690
group up is there's the memory limit in

00:18:29,419 --> 00:18:35,150
bytes and then there's the memory mem SW

00:18:32,690 --> 00:18:41,299
limit in bytes and that second one is

00:18:35,150 --> 00:18:43,159
memory plus swap so and basically the

00:18:41,299 --> 00:18:45,640
reason that it's a memory plus swap

00:18:43,159 --> 00:18:49,309
limit instead of just a swap limit is

00:18:45,640 --> 00:18:53,030
really you don't care how much swap an

00:18:49,309 --> 00:18:55,630
app is is using and if it's an app

00:18:53,030 --> 00:18:58,039
that's sort of idle on your system you

00:18:55,630 --> 00:19:00,919
don't care if all of it gets swapped out

00:18:58,039 --> 00:19:04,490
so it's better to to have a combined

00:19:00,919 --> 00:19:08,480
limit and let the kernel decide when

00:19:04,490 --> 00:19:10,220
things are in swap or not so you know

00:19:08,480 --> 00:19:12,799
you have the memory limit because you

00:19:10,220 --> 00:19:15,260
may actually want to conserve resident

00:19:12,799 --> 00:19:18,860
memory and and force things to swap out

00:19:15,260 --> 00:19:21,260
if they're past a certain point although

00:19:18,860 --> 00:19:23,150
that presents challenges you know if an

00:19:21,260 --> 00:19:26,030
app gets into that range where it's

00:19:23,150 --> 00:19:27,630
using more than its memory limit in

00:19:26,030 --> 00:19:31,590
bytes but less than its memory

00:19:27,630 --> 00:19:34,260
swap it might end up causing a swap d2

00:19:31,590 --> 00:19:36,360
work a lot to keep swapping things back

00:19:34,260 --> 00:19:39,300
in even though you might have free

00:19:36,360 --> 00:19:42,210
memory on your system so keep that in

00:19:39,300 --> 00:19:44,490
mind when you're sort of tuning your

00:19:42,210 --> 00:19:46,860
your groups for memory and memory plus

00:19:44,490 --> 00:19:50,190
swap that you don't you know it's

00:19:46,860 --> 00:19:51,630
expensive to make applications swap and

00:19:50,190 --> 00:19:53,850
if you've got free memory on your

00:19:51,630 --> 00:19:57,750
machine you don't necessarily want that

00:19:53,850 --> 00:19:59,670
to happen the other thing I have set

00:19:57,750 --> 00:20:04,200
here that that's that's interesting is

00:19:59,670 --> 00:20:06,180
the memory move charge at emigrate so as

00:20:04,200 --> 00:20:09,750
I mentioned there are several different

00:20:06,180 --> 00:20:13,170
ways to place processes into cgroups

00:20:09,750 --> 00:20:16,770
if you use something like Pam see group

00:20:13,170 --> 00:20:20,790
where a user's processes get si grouped

00:20:16,770 --> 00:20:22,740
immediately when they log in it's no big

00:20:20,790 --> 00:20:25,320
deal because every process that they

00:20:22,740 --> 00:20:28,350
launch is already going to be in their c

00:20:25,320 --> 00:20:30,750
group but if you're using if you're

00:20:28,350 --> 00:20:34,290
relying on things like cg rules engine d

00:20:30,750 --> 00:20:36,900
that put processes in c groups after

00:20:34,290 --> 00:20:39,270
they've already started running and

00:20:36,900 --> 00:20:42,390
consumed some memory you need to have

00:20:39,270 --> 00:20:45,030
this option turned on otherwise the task

00:20:42,390 --> 00:20:48,450
the the memory that was allocated by the

00:20:45,030 --> 00:20:50,490
process before it got moved will stay in

00:20:48,450 --> 00:20:52,500
the route c group or whatever c group it

00:20:50,490 --> 00:20:55,800
was launched as a part of not where it

00:20:52,500 --> 00:20:58,110
actually belongs so this is something

00:20:55,800 --> 00:21:00,330
that we've seen in an open shift where

00:20:58,110 --> 00:21:02,850
you know we we absolutely have to make

00:21:00,330 --> 00:21:04,410
sure that people get charged correctly

00:21:02,850 --> 00:21:06,780
for the memory that they're using we

00:21:04,410 --> 00:21:08,640
can't have them you know consume a half

00:21:06,780 --> 00:21:10,950
a gig of ram and then get placed in

00:21:08,640 --> 00:21:20,640
there c group and and have that charge

00:21:10,950 --> 00:21:22,250
not get moved okay so the the quota was

00:21:20,640 --> 00:21:24,780
the other one i was going to talk about

00:21:22,250 --> 00:21:28,320
briefly that's fairly simple to

00:21:24,780 --> 00:21:31,680
understand you know basically the the

00:21:28,320 --> 00:21:36,120
quota is in microseconds that's why the

00:21:31,680 --> 00:21:38,580
us and it is as a fraction of the

00:21:36,120 --> 00:21:40,299
scheduler period which is another

00:21:38,580 --> 00:21:49,599
setting in the C group

00:21:40,299 --> 00:21:58,479
so let's look at our CPU C group the

00:21:49,599 --> 00:22:00,489
Apache one for example how many of you

00:21:58,479 --> 00:22:04,929
are familiar with the kernel scheduler

00:22:00,489 --> 00:22:06,729
at all okay yeah so I'm not gonna go in

00:22:04,929 --> 00:22:11,769
a lot of detail about how it works but

00:22:06,729 --> 00:22:15,579
basically the scheduler has time slices

00:22:11,769 --> 00:22:19,749
and tries to you know give somewhat

00:22:15,579 --> 00:22:22,109
equal portions of CPU during each time

00:22:19,749 --> 00:22:26,200
slice to the processes that want to run

00:22:22,109 --> 00:22:28,359
and this sort of helps group processes

00:22:26,200 --> 00:22:32,019
so that when there's too much to run the

00:22:28,359 --> 00:22:36,190
kernel can have a better view of who

00:22:32,019 --> 00:22:37,959
should get how much time so now I've got

00:22:36,190 --> 00:22:40,950
this quota set to negative one right now

00:22:37,959 --> 00:22:44,019
so negative one basically means that

00:22:40,950 --> 00:22:47,139
this C group can run as much as it wants

00:22:44,019 --> 00:22:53,109
during any given time slice it will

00:22:47,139 --> 00:22:57,369
never be throttled if I were to set it

00:22:53,109 --> 00:23:02,499
to something like 30,000 which is what I

00:22:57,369 --> 00:23:06,399
had to find in the config file and a

00:23:02,499 --> 00:23:10,570
typical period is a tenth of a second so

00:23:06,399 --> 00:23:14,049
a hundred thousand microseconds those

00:23:10,570 --> 00:23:19,179
values basically say that you can use

00:23:14,049 --> 00:23:20,799
30% of one CPU on this machine the

00:23:19,179 --> 00:23:22,959
machine might have sixteen CPUs or

00:23:20,799 --> 00:23:27,219
something but you're basically saying

00:23:22,959 --> 00:23:31,779
that it can use 30% of a CPU because

00:23:27,219 --> 00:23:33,549
it's 30,000 over 100,000 here so you

00:23:31,779 --> 00:23:35,919
know if you had a if you wanted to say

00:23:33,549 --> 00:23:38,829
that a C group could use you know four

00:23:35,919 --> 00:23:43,419
CPUs you would say 400,000 out of

00:23:38,829 --> 00:23:45,570
100,000 you can use smaller periods you

00:23:43,419 --> 00:23:49,389
can use something down to I believe

00:23:45,570 --> 00:23:51,940
5,000 but when you slice things that

00:23:49,389 --> 00:23:52,470
small it basically makes the scheduler

00:23:51,940 --> 00:23:54,990
work

00:23:52,470 --> 00:23:56,909
a lot harder and it's not usually worth

00:23:54,990 --> 00:23:59,490
it because of the cost of context

00:23:56,909 --> 00:24:02,610
switching and things so so that's why we

00:23:59,490 --> 00:24:05,130
tend to use a hundred thousand here you

00:24:02,610 --> 00:24:08,610
can also go up to a full second but then

00:24:05,130 --> 00:24:10,710
you'll have potentially apps that you

00:24:08,610 --> 00:24:13,890
know run a little bit and have a visible

00:24:10,710 --> 00:24:15,210
stop before the next second and you

00:24:13,890 --> 00:24:18,390
don't necessarily want that sort of

00:24:15,210 --> 00:24:24,330
choppiness on your system so so you have

00:24:18,390 --> 00:24:27,179
to find a balance there so yeah let me

00:24:24,330 --> 00:24:30,690
go ahead and launch one of my busy wait

00:24:27,179 --> 00:24:32,480
processes in this C group and show you

00:24:30,690 --> 00:24:35,970
what happens do I still have one running

00:24:32,480 --> 00:24:37,440
let's kill that one first or actually we

00:24:35,970 --> 00:24:42,750
can just put that one in the Apache C

00:24:37,440 --> 00:24:46,020
group so if we echo 36 62 into C group

00:24:42,750 --> 00:24:47,640
procs and you can see that in my last

00:24:46,020 --> 00:24:49,380
top command it was using a hundred

00:24:47,640 --> 00:24:53,700
percent of a CPU pretty much ninety

00:24:49,380 --> 00:24:56,159
eight point six percent now we can see

00:24:53,700 --> 00:24:58,530
that it's it's being capped just under

00:24:56,159 --> 00:25:01,530
thirty percent just like we told the

00:24:58,530 --> 00:25:06,860
secret to do and of course if we were to

00:25:01,530 --> 00:25:06,860
run another busy process

00:25:13,910 --> 00:25:22,200
in the same C group then they'll have to

00:25:19,650 --> 00:25:24,960
share so now each of them is going to be

00:25:22,200 --> 00:25:27,390
around 15% and and on average they

00:25:24,960 --> 00:25:31,860
basically can't at any interval go over

00:25:27,390 --> 00:25:34,140
the the 30 30% limit and then we get

00:25:31,860 --> 00:25:42,720
some interesting stats out of this so if

00:25:34,140 --> 00:25:46,230
we look at CP you don't stat what we get

00:25:42,720 --> 00:25:49,560
here and is this okay on camera by the

00:25:46,230 --> 00:25:50,850
way can you see the whole screen okay

00:25:49,560 --> 00:25:55,290
okay

00:25:50,850 --> 00:25:59,370
so what we see here is the number of

00:25:55,290 --> 00:26:02,640
periods that of CPU accounting when

00:25:59,370 --> 00:26:05,160
something wanted to run the number of

00:26:02,640 --> 00:26:07,110
those periods when the C group was

00:26:05,160 --> 00:26:10,380
throttled in other words it exhausted

00:26:07,110 --> 00:26:12,450
its 30% allocation and the colonel said

00:26:10,380 --> 00:26:16,380
you're thrown off the processor you

00:26:12,450 --> 00:26:19,860
can't run anymore and then we see the

00:26:16,380 --> 00:26:22,800
throttle time which is basically the the

00:26:19,860 --> 00:26:25,980
time that was remaining in that time

00:26:22,800 --> 00:26:29,430
slice during which the process still

00:26:25,980 --> 00:26:32,520
wanted to run but was not allowed so you

00:26:29,430 --> 00:26:35,370
can tell as an administrator when things

00:26:32,520 --> 00:26:37,230
are you know are asking for a lot more

00:26:35,370 --> 00:26:42,720
time than you're giving them when this

00:26:37,230 --> 00:26:46,800
throttle time goes way up and one thing

00:26:42,720 --> 00:26:49,650
that people find confusing about C

00:26:46,800 --> 00:26:51,890
groups is that some numbers are measured

00:26:49,650 --> 00:26:55,080
in microseconds some are measured in

00:26:51,890 --> 00:26:57,600
nanoseconds and if you conflate those

00:26:55,080 --> 00:27:00,600
then you'll end up with some really

00:26:57,600 --> 00:27:05,760
strange stats this particular number I

00:27:00,600 --> 00:27:09,120
believe is in nanoseconds in CPU

00:27:05,760 --> 00:27:10,380
accounting which will also look at here

00:27:09,120 --> 00:27:11,910
because these go hand in hand

00:27:10,380 --> 00:27:15,980
there are also numbers that are in

00:27:11,910 --> 00:27:15,980
nanoseconds so

00:27:21,639 --> 00:27:28,339
now it is not oh because I didn't see

00:27:24,769 --> 00:27:33,289
gee exactly so interesting point here so

00:27:28,339 --> 00:27:39,499
if I now echo 36 62 to see group rocks

00:27:33,289 --> 00:27:40,940
here right now I'm immediately seeing my

00:27:39,499 --> 00:27:42,799
CPU accounting as well

00:27:40,940 --> 00:27:44,629
but when I did the CG exact I only put

00:27:42,799 --> 00:27:47,749
it in the CPU group and so I wasn't

00:27:44,629 --> 00:27:52,879
getting accounting data right so that's

00:27:47,749 --> 00:28:03,820
a number in nanoseconds and and these

00:27:52,879 --> 00:28:06,200
are in that one I believe is in

00:28:03,820 --> 00:28:11,169
milliseconds which is strange

00:28:06,200 --> 00:28:11,169
yeah or no this one might be Hertz

00:28:24,340 --> 00:28:32,690
yeah yeah so this one's in hundredths of

00:28:27,710 --> 00:28:34,790
a second so the those differences in in

00:28:32,690 --> 00:28:37,360
how things are measured can be a little

00:28:34,790 --> 00:28:37,360
bit confusing

00:28:38,530 --> 00:28:48,370
okay so right so we've talked a little

00:28:45,560 --> 00:28:53,090
bit about the metrics that you can see

00:28:48,370 --> 00:28:56,960
CPU stat CPU account usage you can see

00:28:53,090 --> 00:28:59,750
for the memory controller you can see

00:28:56,960 --> 00:29:02,480
the current usage in bytes and you can

00:28:59,750 --> 00:29:06,200
see the maximum usage in bytes so you

00:29:02,480 --> 00:29:09,470
can see whether a group has ever hit its

00:29:06,200 --> 00:29:12,140
memory limit by seeing whether the max

00:29:09,470 --> 00:29:14,150
usage for the group is equal to the

00:29:12,140 --> 00:29:17,840
limit which is which is useful sometimes

00:29:14,150 --> 00:29:20,150
you can also see the fail count for both

00:29:17,840 --> 00:29:23,030
memory and memory plus swap and

00:29:20,150 --> 00:29:27,170
basically the fail count doesn't

00:29:23,030 --> 00:29:30,080
necessarily mean that an application in

00:29:27,170 --> 00:29:32,600
the group got killed it simply means

00:29:30,080 --> 00:29:36,010
that memory was exhausted and one of

00:29:32,600 --> 00:29:39,950
those reclaim events had to happen or

00:29:36,010 --> 00:29:41,750
potentially malloc returned nonzero and

00:29:39,950 --> 00:29:44,690
said no I just can't allocate this there

00:29:41,750 --> 00:29:47,030
are other situations where memory that's

00:29:44,690 --> 00:29:50,360
already mapped but not written to when

00:29:47,030 --> 00:29:51,650
you write to it you basically go beyond

00:29:50,360 --> 00:29:53,110
the limit and that's the sort of

00:29:51,650 --> 00:29:56,030
situation where you get home killed

00:29:53,110 --> 00:29:57,980
usually just a malloc won't won't cause

00:29:56,030 --> 00:30:03,320
a kill it will cause this fail count to

00:29:57,980 --> 00:30:07,340
go up so and memory dot stat is it gives

00:30:03,320 --> 00:30:08,630
you a breakdown of go look at it the

00:30:07,340 --> 00:30:11,170
different ways in which memory is

00:30:08,630 --> 00:30:11,170
consumed

00:30:17,299 --> 00:30:24,720
so this is in the route group you know

00:30:21,360 --> 00:30:26,820
if you're not a sort of low-level kernel

00:30:24,720 --> 00:30:29,429
guy then a lot of this won't mean much

00:30:26,820 --> 00:30:32,850
to you but at least a few of them will

00:30:29,429 --> 00:30:38,520
things like RSS you know your resident

00:30:32,850 --> 00:30:42,450
memory verses swap and verses cache

00:30:38,520 --> 00:30:44,730
space and page in page out is an

00:30:42,450 --> 00:30:49,380
interesting one what that's telling you

00:30:44,730 --> 00:30:52,110
is how many pages have been charged and

00:30:49,380 --> 00:30:53,700
uncharged from this group so it tells

00:30:52,110 --> 00:30:54,990
you how much you know you've got

00:30:53,700 --> 00:30:59,750
processes coming in and out and

00:30:54,990 --> 00:31:03,059
allocating and deallocating memory so

00:30:59,750 --> 00:31:07,950
that can be useful when you see things

00:31:03,059 --> 00:31:10,470
like your system is is swapping a lot if

00:31:07,950 --> 00:31:12,179
you find a certain C group that's beyond

00:31:10,470 --> 00:31:14,399
its memory limit and into its memory

00:31:12,179 --> 00:31:17,760
plus swap limit and it's doing a lot of

00:31:14,399 --> 00:31:19,980
this page in page out that all those

00:31:17,760 --> 00:31:21,809
charges and uncharged --es could result

00:31:19,980 --> 00:31:26,669
in things having to be swapped in and

00:31:21,809 --> 00:31:36,179
swapped out so so that's that's a good

00:31:26,669 --> 00:31:37,860
metric there all right so the next thing

00:31:36,179 --> 00:31:42,679
that's probably worth talking about is

00:31:37,860 --> 00:31:45,840
is the memory oome control file and

00:31:42,679 --> 00:31:48,720
basically what that tells you is is two

00:31:45,840 --> 00:31:52,980
things it tells you whether um kill is

00:31:48,720 --> 00:32:00,679
enabled and whether the C group is

00:31:52,980 --> 00:32:04,080
currently under so very simple structure

00:32:00,679 --> 00:32:08,730
here boom kill disable is 0 which means

00:32:04,080 --> 00:32:11,309
that boom kill is enabled just strange

00:32:08,730 --> 00:32:15,090
and then under zero means that it's not

00:32:11,309 --> 00:32:18,179
currently under whom so the reason that

00:32:15,090 --> 00:32:20,399
boom kill disable came about is that

00:32:18,179 --> 00:32:23,490
someone realized that there are there

00:32:20,399 --> 00:32:25,830
are situations where being killed is is

00:32:23,490 --> 00:32:26,230
not the the most graceful thing that you

00:32:25,830 --> 00:32:28,800
can do

00:32:26,230 --> 00:32:31,900
in particular with something like Apache

00:32:28,800 --> 00:32:34,840
if you've got it running where it's you

00:32:31,900 --> 00:32:36,820
know spawning worker threads and one of

00:32:34,840 --> 00:32:38,830
those workers gets killed

00:32:36,820 --> 00:32:41,980
it'll just spawn a new one and hit its

00:32:38,830 --> 00:32:45,970
limit again so it's often better

00:32:41,980 --> 00:32:48,310
behavior to say when this c group runs

00:32:45,970 --> 00:32:51,100
out of memory just stop it

00:32:48,310 --> 00:32:53,320
don't let it process anymore and I will

00:32:51,100 --> 00:32:57,310
do something as an administrator to

00:32:53,320 --> 00:33:03,550
handle that what you have to do in that

00:32:57,310 --> 00:33:06,100
situation though is be notified so is

00:33:03,550 --> 00:33:09,220
anyone familiar with I notify and event

00:33:06,100 --> 00:33:11,560
FD and and that sort of framework to get

00:33:09,220 --> 00:33:13,360
notifications from the kernel so

00:33:11,560 --> 00:33:15,700
basically you can write code to be

00:33:13,360 --> 00:33:18,310
immediately notified when one of these

00:33:15,700 --> 00:33:21,520
events happens when when this under goes

00:33:18,310 --> 00:33:23,980
from zero to one and then you can have a

00:33:21,520 --> 00:33:25,750
process that deals with that and you

00:33:23,980 --> 00:33:28,300
know shuts down the application brings

00:33:25,750 --> 00:33:31,210
it back up cleans things up however you

00:33:28,300 --> 00:33:36,130
need to and so on so so with um kill

00:33:31,210 --> 00:33:37,720
disable that is sort of easier to do and

00:33:36,130 --> 00:33:40,900
then if you let the kernel kill things

00:33:37,720 --> 00:33:43,000
and then you try to clean up one of the

00:33:40,900 --> 00:33:46,690
tricks that I've also used is when you

00:33:43,000 --> 00:33:49,420
get that that message you can go raise

00:33:46,690 --> 00:33:51,940
the limit you know you can have your

00:33:49,420 --> 00:33:53,650
script respond by saying oh okay that

00:33:51,940 --> 00:33:54,730
app needs a little bit more memory and

00:33:53,650 --> 00:33:56,680
I'm okay with that

00:33:54,730 --> 00:33:58,450
so I'll give it a little bit more but

00:33:56,680 --> 00:34:00,010
then I'll probably restart it to get it

00:33:58,450 --> 00:34:09,840
to free whatever it's a leaked anyway

00:34:00,010 --> 00:34:12,580
but yeah that I've found helpful okay so

00:34:09,840 --> 00:34:15,670
now let's talk about the hierarchy of C

00:34:12,580 --> 00:34:18,430
groups a little bit you know the C

00:34:15,670 --> 00:34:20,980
groups are always in a hierarchy it's a

00:34:18,430 --> 00:34:23,080
tree and every task has to be somewhere

00:34:20,980 --> 00:34:25,900
in it by default things are going to be

00:34:23,080 --> 00:34:29,680
in the root of the tree unless you place

00:34:25,900 --> 00:34:33,850
them elsewhere based on rules or a CG

00:34:29,680 --> 00:34:35,680
exact call or whatever hierarchical

00:34:33,850 --> 00:34:38,050
limits are optional for memory which

00:34:35,680 --> 00:34:38,630
means that you can have a parent C group

00:34:38,050 --> 00:34:40,610
have one

00:34:38,630 --> 00:34:42,230
limit and a child have a different limit

00:34:40,610 --> 00:34:45,610
and you can make them completely

00:34:42,230 --> 00:34:48,470
unrelated there's a use hierarchy

00:34:45,610 --> 00:34:50,630
attribute that you can set to one if you

00:34:48,470 --> 00:34:52,820
would like them to be related which

00:34:50,630 --> 00:34:56,600
means that you know you can have a

00:34:52,820 --> 00:35:00,980
parent with an 8 gig memory limit and

00:34:56,600 --> 00:35:02,840
you know 10 children with you know 4 gig

00:35:00,980 --> 00:35:05,150
limits which means that there are two

00:35:02,840 --> 00:35:06,770
different ways that you can have an uma

00:35:05,150 --> 00:35:08,630
vent you can either have it in one of

00:35:06,770 --> 00:35:10,370
the children exhausting its limit or you

00:35:08,630 --> 00:35:13,670
can have all the children as an

00:35:10,370 --> 00:35:18,110
aggregate exhausting the parent limit so

00:35:13,670 --> 00:35:20,660
so you may find that to be valuable CPU

00:35:18,110 --> 00:35:24,080
settings on the other hand always impact

00:35:20,660 --> 00:35:25,580
the children so when you start doing CPU

00:35:24,080 --> 00:35:26,660
shares which we'll talk about in a

00:35:25,580 --> 00:35:29,590
minute

00:35:26,660 --> 00:35:32,360
the the shares of the parent always

00:35:29,590 --> 00:35:36,200
determine the maximum usage that the

00:35:32,360 --> 00:35:40,160
children as a whole can have and then

00:35:36,200 --> 00:35:43,460
for for block i/o the hierarchy is

00:35:40,160 --> 00:35:45,290
experimental so that means in my mind

00:35:43,460 --> 00:35:47,750
mostly it doesn't work yet you should

00:35:45,290 --> 00:35:51,500
there there is a same behavior option

00:35:47,750 --> 00:35:54,890
that you can turn on to to enforce the

00:35:51,500 --> 00:36:03,770
hierarchy but but they call it purely

00:35:54,890 --> 00:36:05,020
experimental at this point so I've

00:36:03,770 --> 00:36:08,030
already talked about a couple of these

00:36:05,020 --> 00:36:11,750
swap eNOS is the other memory tunable

00:36:08,030 --> 00:36:14,540
that that's worth mentioning so swap

00:36:11,750 --> 00:36:17,480
eNOS have has anyone ever tuned that at

00:36:14,540 --> 00:36:20,930
the system-wide level to you know okay

00:36:17,480 --> 00:36:23,720
good so this is the same idea as the

00:36:20,930 --> 00:36:26,030
system-wide swap eNOS but if you have a

00:36:23,720 --> 00:36:29,150
group for example that you would like to

00:36:26,030 --> 00:36:33,110
stay resident all the time you can set

00:36:29,150 --> 00:36:35,660
swap eNOS to zero for just that group so

00:36:33,110 --> 00:36:37,640
if you've got a one particular process

00:36:35,660 --> 00:36:39,620
that needs to be very low latency and

00:36:37,640 --> 00:36:41,840
you just can't afford to have it paging

00:36:39,620 --> 00:36:43,130
things in and out that's wha penis to

00:36:41,840 --> 00:36:45,970
zero and you're good it will stay in

00:36:43,130 --> 00:36:45,970
memory all the time

00:36:49,430 --> 00:36:55,289
right so CPU shares are very interesting

00:36:53,039 --> 00:36:57,390
it's it works kind of like the stock

00:36:55,289 --> 00:37:00,499
market kind of like getting a share of

00:36:57,390 --> 00:37:03,569
stock that it's it's worked something

00:37:00,499 --> 00:37:05,400
relative to the whole you have to know

00:37:03,569 --> 00:37:08,720
how many shares exist to really know

00:37:05,400 --> 00:37:13,289
what it is as a percentage of anything

00:37:08,720 --> 00:37:16,730
so basically we'll go through an example

00:37:13,289 --> 00:37:16,730
because this kind of get complicated

00:37:17,900 --> 00:37:23,009
so 1024 is the default that things are

00:37:21,450 --> 00:37:27,029
given if you don't if you don't go

00:37:23,009 --> 00:37:32,400
modifying things every CPU C group that

00:37:27,029 --> 00:37:34,079
you create is gonna have 1024 and as I

00:37:32,400 --> 00:37:37,380
said on the previous slide the parent

00:37:34,079 --> 00:37:39,269
will always have implicitly 1024 in

00:37:37,380 --> 00:37:43,829
relation to its children and so I made

00:37:39,269 --> 00:37:47,640
this little example where the top-level

00:37:43,829 --> 00:37:51,989
C group has 1024 there are two children

00:37:47,640 --> 00:37:57,089
each at 512 which basically if you look

00:37:51,989 --> 00:38:00,210
at just those three it's going to be 50

00:37:57,089 --> 00:38:03,660
percent for the 1024 125 percent for the

00:38:00,210 --> 00:38:06,150
512 and 25 percent you know the way the

00:38:03,660 --> 00:38:10,170
ratios work that you know because the

00:38:06,150 --> 00:38:14,940
total there is 2048 and and so you know

00:38:10,170 --> 00:38:17,549
512 over 2048 25% basically where it

00:38:14,940 --> 00:38:20,130
gets a little bit strange is when you go

00:38:17,549 --> 00:38:23,779
down here and you're looking at a

00:38:20,130 --> 00:38:27,779
process in this middle C group here

00:38:23,779 --> 00:38:30,829
versus the children here this is where

00:38:27,779 --> 00:38:35,279
the implicit 1024 comes into play so

00:38:30,829 --> 00:38:39,420
relative to these two this one has a

00:38:35,279 --> 00:38:44,400
1024 share so I did a little map of the

00:38:39,420 --> 00:38:46,559
calculations on the next slide here so I

00:38:44,400 --> 00:38:50,190
might have to toggle back and forth in

00:38:46,559 --> 00:38:54,420
between these yeah so so basically at

00:38:50,190 --> 00:38:57,450
the top level you have 2048 and then I

00:38:54,420 --> 00:39:00,180
did the math for the 50 and 25 but in

00:38:57,450 --> 00:39:01,329
this little subtree you have a 1024 a

00:39:00,180 --> 00:39:03,279
512 and a 10

00:39:01,329 --> 00:39:08,859
for even though that's not what it looks

00:39:03,279 --> 00:39:10,329
like here so so basically a process in

00:39:08,859 --> 00:39:17,349
this C group will get ten percent

00:39:10,329 --> 00:39:18,999
relative to to the whole and I've got an

00:39:17,349 --> 00:39:27,029
example that that shows that that

00:39:18,999 --> 00:39:27,029
actually works back in my history here

00:39:35,099 --> 00:39:40,890
so I've got my busy test app

00:40:15,680 --> 00:40:21,900
so I just have a little wrapper for my

00:40:20,520 --> 00:40:23,940
from my script that's basically

00:40:21,900 --> 00:40:26,160
launching these doing CG exact to launch

00:40:23,940 --> 00:40:28,230
these into the different C groups the

00:40:26,160 --> 00:40:35,720
the C groups that I have set up here in

00:40:28,230 --> 00:40:43,520
CPU have share test as the top level and

00:40:35,720 --> 00:40:43,520
it's got the 1024 shares and I've got a

00:40:44,270 --> 00:40:58,170
with 512 and B with 512 right so so

00:40:56,490 --> 00:41:07,620
those are set as they were on the slide

00:40:58,170 --> 00:41:12,440
and if we on top now you can basically

00:41:07,620 --> 00:41:12,440
see I might have an old one running dog

00:41:18,550 --> 00:41:22,710
that now these should

00:41:33,880 --> 00:41:40,570
right so there are my are my five and

00:41:36,790 --> 00:41:44,800
they're breaking down as the slide

00:41:40,570 --> 00:41:49,540
showed fifty twenty five ten ten and

00:41:44,800 --> 00:41:51,730
five is about how they're breaking down

00:41:49,540 --> 00:41:56,440
you'll see a little bit of wavering but

00:41:51,730 --> 00:41:58,480
but that's how it turns out so so

00:41:56,440 --> 00:42:00,190
calculating those shares can be a little

00:41:58,480 --> 00:42:03,090
bit strange and I would suggest not

00:42:00,190 --> 00:42:07,990
really overdoing it although in general

00:42:03,090 --> 00:42:12,340
using shares to sort of enforce what

00:42:07,990 --> 00:42:16,090
portion of the system a c group gets is

00:42:12,340 --> 00:42:18,640
a little bit better than the then

00:42:16,090 --> 00:42:21,130
throttling things because what happens

00:42:18,640 --> 00:42:24,940
when you throttle is that you can end up

00:42:21,130 --> 00:42:26,680
with a lot of unused CPU cycles you know

00:42:24,940 --> 00:42:28,720
if you've got an app that's throttled at

00:42:26,680 --> 00:42:30,700
thirty percent of a CPU and nothing else

00:42:28,720 --> 00:42:32,670
is running on the system then you're

00:42:30,700 --> 00:42:35,860
just wasting seventy percent of your CPU

00:42:32,670 --> 00:42:38,830
whereas when you're just waiting things

00:42:35,860 --> 00:42:41,440
with these shares you know as long as

00:42:38,830 --> 00:42:43,900
nothing else wants to run a C group can

00:42:41,440 --> 00:42:45,970
take the entire CPU or all of the

00:42:43,900 --> 00:42:54,870
multiple CPUs on the system and that's

00:42:45,970 --> 00:42:57,600
generally good for utilization okay so

00:42:54,870 --> 00:43:01,690
we talked a little bit about CG config

00:42:57,600 --> 00:43:05,370
already the thing that parses that is

00:43:01,690 --> 00:43:10,720
called CG config parser one thing that's

00:43:05,370 --> 00:43:13,540
interesting about that is you can you

00:43:10,720 --> 00:43:16,210
can actually make multiple CG config

00:43:13,540 --> 00:43:19,030
files and and load them there's there's

00:43:16,210 --> 00:43:22,450
one service on your distro that that

00:43:19,030 --> 00:43:24,820
loads Etsy CG config but you can run CG

00:43:22,450 --> 00:43:27,070
config parser by hand to load another

00:43:24,820 --> 00:43:29,680
file with more C groups in it

00:43:27,070 --> 00:43:33,120
the one thing that CG config parser

00:43:29,680 --> 00:43:36,340
complains about though is if you specify

00:43:33,120 --> 00:43:39,340
mounts that are already mounted than

00:43:36,340 --> 00:43:42,700
then that doesn't work well so so if you

00:43:39,340 --> 00:43:45,250
ever try to load a CG config file on the

00:43:42,700 --> 00:43:46,460
fly after your system is started up and

00:43:45,250 --> 00:43:48,170
the subsystems are mounted

00:43:46,460 --> 00:43:52,359
tasks are running and things you have to

00:43:48,170 --> 00:43:57,410
omit the mount section from your config

00:43:52,359 --> 00:44:07,700
and yeah let's talk about CG rules conf

00:43:57,410 --> 00:44:10,130
here a little bit so I have a bunch of

00:44:07,700 --> 00:44:12,500
rules for performance testing that I was

00:44:10,130 --> 00:44:17,540
doing where basically you know every

00:44:12,500 --> 00:44:19,820
user just gets put into a C group for

00:44:17,540 --> 00:44:21,920
all of these controllers and these lines

00:44:19,820 --> 00:44:25,430
are very simple it's the the first field

00:44:21,920 --> 00:44:27,890
is the user the second field is the set

00:44:25,430 --> 00:44:32,150
of controllers that you want to enable

00:44:27,890 --> 00:44:38,450
and the third line is which C group you

00:44:32,150 --> 00:44:41,050
want to put them in another technique

00:44:38,450 --> 00:44:44,089
that you can use in this file is

00:44:41,050 --> 00:44:46,250
basically you can say if you know

00:44:44,089 --> 00:44:49,400
there's a process owned by route and

00:44:46,250 --> 00:44:52,220
it's called cron D then put it in the

00:44:49,400 --> 00:44:56,530
CPU and CPU accounting groups in the

00:44:52,220 --> 00:44:58,880
cron C group throttle and cron jobs is

00:44:56,530 --> 00:45:00,890
kind of a strange thing to do because

00:44:58,880 --> 00:45:03,920
they need to run on a schedule but if

00:45:00,890 --> 00:45:10,000
you have jobs that tend to get out of

00:45:03,920 --> 00:45:12,530
control it's it's an interesting idea I

00:45:10,000 --> 00:45:14,119
yeah kind of on back and forth on

00:45:12,530 --> 00:45:16,130
whether that's a good thing for my

00:45:14,119 --> 00:45:17,930
systems or not because we we had an

00:45:16,130 --> 00:45:22,040
experience where cron jobs were taking

00:45:17,930 --> 00:45:23,780
way more processing time than I expected

00:45:22,040 --> 00:45:25,910
because every time a sysadmin noticed

00:45:23,780 --> 00:45:27,890
something that they felt they wanted to

00:45:25,910 --> 00:45:29,839
measure on the system they would just

00:45:27,890 --> 00:45:32,960
add another script and another script

00:45:29,839 --> 00:45:34,760
and yeah soon you're just spending all

00:45:32,960 --> 00:45:36,770
your time on Cron's and so we we sort of

00:45:34,760 --> 00:45:38,690
throttled it back but then we looked at

00:45:36,770 --> 00:45:40,670
the how much things were actually

00:45:38,690 --> 00:45:42,200
getting throttled and started to pare

00:45:40,670 --> 00:45:45,050
down our scripts so that it was no

00:45:42,200 --> 00:45:47,660
longer needed you know when and and when

00:45:45,050 --> 00:45:50,030
the basically the throttle time nears

00:45:47,660 --> 00:45:51,410
zero you realize oh okay we don't need

00:45:50,030 --> 00:45:56,420
to have these throttled anymore because

00:45:51,410 --> 00:45:58,460
they're actually not using that much so

00:45:56,420 --> 00:46:00,110
yeah there there are other things that

00:45:58,460 --> 00:46:02,440
you can do with CG rules like

00:46:00,110 --> 00:46:06,140
you can use groups and other things too

00:46:02,440 --> 00:46:08,480
but I usually keep this fairly simple CG

00:46:06,140 --> 00:46:11,690
rules can actually the the CG rules

00:46:08,480 --> 00:46:14,270
engine daemon can use a lot of CPU as

00:46:11,690 --> 00:46:15,950
well if you have lots of C groups

00:46:14,270 --> 00:46:18,230
defined and you're launching lots of

00:46:15,950 --> 00:46:20,480
processes every time you spawn a new

00:46:18,230 --> 00:46:22,310
process it has to handle that

00:46:20,480 --> 00:46:24,650
notification and look through its whole

00:46:22,310 --> 00:46:27,680
rule set to decide where that process

00:46:24,650 --> 00:46:35,960
should be so that can take a lot of

00:46:27,680 --> 00:46:40,100
effort ok so now let's talk about system

00:46:35,960 --> 00:46:43,450
D because really what they decided after

00:46:40,100 --> 00:46:46,070
several years of developing C group

00:46:43,450 --> 00:46:48,530
technology in the kernel and and the

00:46:46,070 --> 00:46:50,390
user space tools to deal with them I

00:46:48,530 --> 00:46:54,170
think everyone was having the same

00:46:50,390 --> 00:46:57,020
problems if you're dynamically managing

00:46:54,170 --> 00:46:58,670
C groups you end up with locking issues

00:46:57,020 --> 00:47:01,010
if you have several different processes

00:46:58,670 --> 00:47:01,520
that are creating see groups deleting C

00:47:01,010 --> 00:47:03,230
groups

00:47:01,520 --> 00:47:06,500
changing you know tuning the settings

00:47:03,230 --> 00:47:08,000
and things like that then then you you

00:47:06,500 --> 00:47:09,740
end up with lock timeouts and things

00:47:08,000 --> 00:47:12,620
because there's there's actually a

00:47:09,740 --> 00:47:14,330
global lock in the kernel for for C

00:47:12,620 --> 00:47:16,100
group changes because of some of the

00:47:14,330 --> 00:47:20,120
things that need to happen when you

00:47:16,100 --> 00:47:22,370
change the the allocations so what they

00:47:20,120 --> 00:47:26,720
decided is that there should be a single

00:47:22,370 --> 00:47:29,840
process in user space that owns C group

00:47:26,720 --> 00:47:35,720
control and now system D is that process

00:47:29,840 --> 00:47:38,270
for most Linux distros and so this means

00:47:35,720 --> 00:47:42,830
that that all the old tools like cg exec

00:47:38,270 --> 00:47:46,280
and c g classify and so on we're we're

00:47:42,830 --> 00:47:50,660
deprecated I presented them because if

00:47:46,280 --> 00:47:52,790
you're admitting rl6 or Ubuntu LTS or

00:47:50,660 --> 00:47:54,350
lots of other distros they are still

00:47:52,790 --> 00:47:57,140
quite relevant and there's no other way

00:47:54,350 --> 00:47:58,760
to do things but in the system D world

00:47:57,140 --> 00:48:03,920
everything changes and they say don't

00:47:58,760 --> 00:48:07,580
use those things so the way that the

00:48:03,920 --> 00:48:11,650
that the system D world works is there's

00:48:07,580 --> 00:48:14,619
a more defined hierarchy of group

00:48:11,650 --> 00:48:16,810
they call all of the intermediate groups

00:48:14,619 --> 00:48:21,910
that aren't Leafs at the bottom of the

00:48:16,810 --> 00:48:24,010
tree slices and there's a system slice a

00:48:21,910 --> 00:48:27,849
machine slice and a user slice by

00:48:24,010 --> 00:48:31,450
default system is for any of your demons

00:48:27,849 --> 00:48:36,099
that start up machines is for your

00:48:31,450 --> 00:48:39,339
docker containers and your QEMU VMs and

00:48:36,099 --> 00:48:45,369
things like that and then users are for

00:48:39,339 --> 00:48:48,030
user sessions and below that you have

00:48:45,369 --> 00:48:51,550
scopes and services and and basically

00:48:48,030 --> 00:48:54,089
you have a service see group for every

00:48:51,550 --> 00:48:57,670
service that starts on your system and

00:48:54,089 --> 00:49:01,690
you have scopes which are very similar

00:48:57,670 --> 00:49:08,080
for basically sessions so things like a

00:49:01,690 --> 00:49:11,650
user login so one thing that's nice is

00:49:08,080 --> 00:49:13,720
the systemd tools are pretty polished in

00:49:11,650 --> 00:49:18,670
terms of being able to look at your see

00:49:13,720 --> 00:49:29,890
groups and see what they're doing so for

00:49:18,670 --> 00:49:32,710
example I can do a system Dec GLS this

00:49:29,890 --> 00:49:34,810
will show me in a nice pager view all of

00:49:32,710 --> 00:49:36,640
these slices and scopes that are on my

00:49:34,810 --> 00:49:40,330
running system right now so you can see

00:49:36,640 --> 00:49:41,589
that in the user slice I have an SSD SSH

00:49:40,330 --> 00:49:44,680
session

00:49:41,589 --> 00:49:46,869
it's called session 1 here and and here

00:49:44,680 --> 00:49:50,680
are all the processes inside that

00:49:46,869 --> 00:49:53,050
session and then system you can see all

00:49:50,680 --> 00:49:57,390
the services policy kit audit D and so

00:49:53,050 --> 00:50:02,980
on running in their own service groups

00:49:57,390 --> 00:50:05,410
and then if we run their cg top command

00:50:02,980 --> 00:50:11,040
you actually get some statistics here

00:50:05,410 --> 00:50:15,780
now in this case I actually don't have

00:50:11,040 --> 00:50:18,400
accounting for most of the data here so

00:50:15,780 --> 00:50:24,839
let me run something that will produce

00:50:18,400 --> 00:50:24,839
some so here I can do

00:50:26,670 --> 00:50:32,219
see sure I get this right

00:50:35,260 --> 00:50:49,720
I'm gonna fall back on old commands real

00:50:37,510 --> 00:50:52,230
quick so actually I need to check my

00:50:49,720 --> 00:50:52,230
mounts here

00:50:57,690 --> 00:51:02,089
so cpu count is mounted

00:51:10,260 --> 00:51:14,420
okay this part of the demo might not

00:51:12,210 --> 00:51:14,420
work

00:51:23,900 --> 00:51:27,440
okay so there's some better stats on my

00:51:25,940 --> 00:51:29,660
laptop I'm not sure why I wasn't getting

00:51:27,440 --> 00:51:31,609
stats in my VM but but this is the kind

00:51:29,660 --> 00:51:36,380
of view that you get with with cg top

00:51:31,609 --> 00:51:39,109
from system D you can see that the the

00:51:36,380 --> 00:51:40,759
higher level parts of the hierarchy are

00:51:39,109 --> 00:51:41,990
showing aggregate stats and so they're

00:51:40,759 --> 00:51:43,460
always going to be at the top of the

00:51:41,990 --> 00:51:46,130
list you know root is always going to be

00:51:43,460 --> 00:51:48,230
using all of the CPU

00:51:46,130 --> 00:51:51,529
you know the aggregate of the children

00:51:48,230 --> 00:51:56,089
essentially so but you can see in this

00:51:51,529 --> 00:51:57,859
case that my rl6 five machines is using

00:51:56,089 --> 00:52:00,740
a whole lot of CPU because I've got all

00:51:57,859 --> 00:52:04,220
those busy processes still running over

00:52:00,740 --> 00:52:05,869
there from the earlier demo and you can

00:52:04,220 --> 00:52:07,430
see how much how much memory each of

00:52:05,869 --> 00:52:12,920
those machines is using and things like

00:52:07,430 --> 00:52:17,749
that so that's pretty useful the the way

00:52:12,920 --> 00:52:21,319
that you set your C group attributes now

00:52:17,749 --> 00:52:23,650
is with systemctl set property and what

00:52:21,319 --> 00:52:27,589
that actually does for things like

00:52:23,650 --> 00:52:31,999
services is it writes a file to Etsy

00:52:27,589 --> 00:52:34,279
that defines the attributes so that and

00:52:31,999 --> 00:52:37,190
it also it writes them to the the C

00:52:34,279 --> 00:52:39,710
group subsystem at runtime as well but

00:52:37,190 --> 00:52:46,279
but it saves them for the next boot so

00:52:39,710 --> 00:52:47,930
that they're persistent so the I should

00:52:46,279 --> 00:52:50,710
have some files in here from from

00:52:47,930 --> 00:52:50,710
previous settings

00:53:27,640 --> 00:53:31,560
okay I thought I had this setup

00:53:38,990 --> 00:53:45,190
so what I want here is something like

00:53:53,720 --> 00:53:58,300
leave that syntax right no it's not

00:53:58,610 --> 00:54:08,480
okay this is where I fall back on the

00:54:00,830 --> 00:54:13,460
internet can't have everything in memory

00:54:08,480 --> 00:54:14,870
and it didn't make my slides oh I'm

00:54:13,460 --> 00:54:18,170
running very short on time and I've

00:54:14,870 --> 00:54:21,650
missed I've missed all your cues okay

00:54:18,170 --> 00:54:23,300
I'm going to stop here and let people

00:54:21,650 --> 00:54:26,600
ask questions I apologize for running

00:54:23,300 --> 00:54:27,860
longer than I had intended to yeah I

00:54:26,600 --> 00:54:32,890
know I've kind of stumbled through some

00:54:27,860 --> 00:54:32,890
points of this so questions please oh

00:54:43,840 --> 00:54:48,410
that is a useful piece of data yeah I

00:54:46,460 --> 00:54:51,380
mean it varies based on distro but yes

00:54:48,410 --> 00:54:54,050
it is in the Lib C group tools yeah all

00:54:51,380 --> 00:54:56,660
of the all of the the legacy tools are

00:54:54,050 --> 00:54:58,820
part of the Lib C root project yeah so

00:54:56,660 --> 00:55:00,940
including the Pam module and everything

00:54:58,820 --> 00:55:00,940
else

00:55:15,000 --> 00:55:21,970
so it is so part of the the move to

00:55:18,910 --> 00:55:25,180
systemd is that everyone is implicitly

00:55:21,970 --> 00:55:28,270
using cgroups now if you're using system

00:55:25,180 --> 00:55:31,360
d then then at least at the level of

00:55:28,270 --> 00:55:33,520
things like CPU shares there there has

00:55:31,360 --> 00:55:37,930
to be something there you can't you

00:55:33,520 --> 00:55:41,670
can't have the CPU subsystem mounted and

00:55:37,930 --> 00:55:44,170
not have some sort of shares defined so

00:55:41,670 --> 00:55:48,160
yeah whether you actively do anything or

00:55:44,170 --> 00:55:49,780
not you're using C groups there and it's

00:55:48,160 --> 00:55:53,170
useful because you know you don't

00:55:49,780 --> 00:55:55,210
necessarily want your demons to get all

00:55:53,170 --> 00:55:57,370
of the time on your on your laptop and

00:55:55,210 --> 00:56:01,060
you don't want your browser to get all

00:55:57,370 --> 00:56:03,580
of the time either so yeah I don't know

00:56:01,060 --> 00:56:06,910
how much you know the average user will

00:56:03,580 --> 00:56:10,030
actually try to contain individual apps

00:56:06,910 --> 00:56:13,060
but as we move toward more people using

00:56:10,030 --> 00:56:15,190
containers for things like their web

00:56:13,060 --> 00:56:20,230
browser you absolutely will be able to

00:56:15,190 --> 00:56:22,800
do that fairly easily there another

00:56:20,230 --> 00:56:22,800
question over here

00:56:26,120 --> 00:56:34,710
so it is one of the things used sorry

00:56:32,180 --> 00:56:40,590
yeah so the question in the back was

00:56:34,710 --> 00:56:42,390
that is this what underlies lxc so

00:56:40,590 --> 00:56:44,640
containers are actually a lot of

00:56:42,390 --> 00:56:47,070
different things see groups are are one

00:56:44,640 --> 00:56:50,010
part there are also kernel namespaces

00:56:47,070 --> 00:56:53,010
which is another thing so there are

00:56:50,010 --> 00:56:56,310
various aspects as to what actually

00:56:53,010 --> 00:56:59,540
makes a container this is really just

00:56:56,310 --> 00:56:59,540
about resource management

00:57:12,500 --> 00:57:17,150
okay so the question is if you're trying

00:57:14,599 --> 00:57:19,750
to control scheduling with nice and also

00:57:17,150 --> 00:57:24,080
with cgroups how do those play together

00:57:19,750 --> 00:57:27,680
so I don't know

00:57:24,080 --> 00:57:31,810
in all cases how that would work but the

00:57:27,680 --> 00:57:34,280
the C groups would be more authoritative

00:57:31,810 --> 00:57:36,859
especially for things like the quota

00:57:34,280 --> 00:57:38,930
you know what the once you exhaust your

00:57:36,859 --> 00:57:43,010
quota you're done no matter what your

00:57:38,930 --> 00:57:46,130
nice value is right so there may be some

00:57:43,010 --> 00:57:47,900
minor shuffling that can happen and nice

00:57:46,130 --> 00:57:51,140
would still matter for processes that

00:57:47,900 --> 00:57:53,630
are in the same C group and you know

00:57:51,140 --> 00:57:56,180
that realistically you're not going to

00:57:53,630 --> 00:57:58,599
have you know hundreds of C groups on

00:57:56,180 --> 00:58:01,310
your system you're going to try to

00:57:58,599 --> 00:58:02,540
aggregate certain things into the same C

00:58:01,310 --> 00:58:04,369
group and even things like you know

00:58:02,540 --> 00:58:06,980
Firefox has multiple processes and

00:58:04,369 --> 00:58:08,359
things like that so it's not you know we

00:58:06,980 --> 00:58:10,070
don't live in a one process per see

00:58:08,359 --> 00:58:17,000
group sort of world so so nice would

00:58:10,070 --> 00:58:19,359
still have some value within a group no

00:58:17,000 --> 00:58:19,359
questions

00:58:19,780 --> 00:58:25,510
okay I hope this was useful I apologize

00:58:23,350 --> 00:58:36,730
for my somewhat lack of preparedness but

00:58:25,510 --> 00:58:38,470
I hope everybody learned something your

00:58:36,730 --> 00:58:40,000
customers rely on your website or

00:58:38,470 --> 00:58:42,400
application if it's slower

00:58:40,000 --> 00:58:45,340
non-responsive it infuriates your users

00:58:42,400 --> 00:58:47,140
and costs you money keeping your

00:58:45,340 --> 00:58:50,660
business critical systems humming along

00:58:47,140 --> 00:58:53,480
requires insight into what they're doing

00:58:50,660 --> 00:58:55,490
your system metrics tell stories stories

00:58:53,480 --> 00:58:57,740
that can reveal performance bottlenecks

00:58:55,490 --> 00:59:00,020
resource limitations and other problems

00:58:57,740 --> 00:59:02,120
but how do you keep an eye on all of

00:59:00,020 --> 00:59:04,400
your systems performance metrics in real

00:59:02,120 --> 00:59:07,280
time and record this data for a liter

00:59:04,400 --> 00:59:09,230
analysis enter long view the new way to

00:59:07,280 --> 00:59:11,270
see what's really going on under the

00:59:09,230 --> 00:59:13,460
hood the long view dashboard lets you

00:59:11,270 --> 00:59:15,380
visualize the status of all your systems

00:59:13,460 --> 00:59:18,290
providing you with a bird's-eye view of

00:59:15,380 --> 00:59:21,230
your entire fleet you can sort by CPU

00:59:18,290 --> 00:59:23,720
memory swap processes load and network

00:59:21,230 --> 00:59:26,270
usage click a specific system to access

00:59:23,720 --> 00:59:28,280
its individual dashboard then click and

00:59:26,270 --> 00:59:31,280
drag to zoom in on chokepoints and get

00:59:28,280 --> 00:59:33,290
more detail comprehensive Network data

00:59:31,280 --> 00:59:35,990
including inbound and outbound traffic

00:59:33,290 --> 00:59:37,940
is available on the network tab and disk

00:59:35,990 --> 00:59:40,100
writes and free space on the disk stab

00:59:37,940 --> 00:59:42,290
while the process Explorer displays

00:59:40,100 --> 00:59:44,870
usage statistics for individual

00:59:42,290 --> 00:59:47,030
processes the system info tab shows

00:59:44,870 --> 00:59:49,430
listening services active connections

00:59:47,030 --> 00:59:51,530
and available updates adding longview to

00:59:49,430 --> 00:59:53,780
a system is easy just click the button

00:59:51,530 --> 00:59:55,430
copy the one-line installation command

00:59:53,780 --> 00:59:58,100
then run the command on your Linux

00:59:55,430 --> 00:59:59,960
system to complete the process the agent

00:59:58,100 --> 01:00:01,910
will begin collecting data and sending

00:59:59,960 --> 01:00:03,440
it to long view then the graphs start

01:00:01,910 --> 01:00:05,960
rolling

01:00:03,440 --> 01:00:08,150
use Longview to gain visibility into

01:00:05,960 --> 01:00:12,069
your servers so when your website or app

01:00:08,150 --> 01:00:12,069

YouTube URL: https://www.youtube.com/watch?v=WvOklBUUoiw


