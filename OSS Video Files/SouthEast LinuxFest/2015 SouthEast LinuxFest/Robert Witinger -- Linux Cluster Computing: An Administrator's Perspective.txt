Title: Robert Witinger -- Linux Cluster Computing: An Administrator's Perspective
Publication date: 2017-01-25
Playlist: 2015 SouthEast LinuxFest
Description: 
	
Captions: 
	00:00:02,030 --> 00:00:10,679
so good afternoon self attendees we're

00:00:08,040 --> 00:00:15,809
going to talk about cluster computing

00:00:10,679 --> 00:00:18,570
today and that covers from super

00:00:15,809 --> 00:00:21,060
computers down to raspberry PI's so I'm

00:00:18,570 --> 00:00:24,779
Robert weidinger a lot of people call me

00:00:21,060 --> 00:00:28,050
Bob I do engineering consulting work

00:00:24,779 --> 00:00:32,160
with my company trex LLC and I'm also

00:00:28,050 --> 00:00:35,070
affiliated with ETSU high-performance

00:00:32,160 --> 00:00:39,690
computing center where I'm helping to

00:00:35,070 --> 00:00:44,040
administer a couple campus clusters so

00:00:39,690 --> 00:00:47,870
the topic here is is cluster computing

00:00:44,040 --> 00:00:52,980
and with other with a linux focus I

00:00:47,870 --> 00:00:56,219
don't know about you but I hear people

00:00:52,980 --> 00:00:59,910
saying that Linux has like a ten percent

00:00:56,219 --> 00:01:03,589
footprint or maybe even as low as a two

00:00:59,910 --> 00:01:08,189
percent footprint well that that might

00:01:03,589 --> 00:01:11,990
carry some weight in the area of desktop

00:01:08,189 --> 00:01:15,299
computing but when we turn over to

00:01:11,990 --> 00:01:19,830
supercomputing and computing clusters

00:01:15,299 --> 00:01:24,150
the scale is just flipped 180 degrees

00:01:19,830 --> 00:01:28,829
around and so it's really a Linux world

00:01:24,150 --> 00:01:31,200
in in the space of supercomputing and in

00:01:28,829 --> 00:01:34,070
cluster computing and I think in the

00:01:31,200 --> 00:01:36,720
course of the next minutes the next hour

00:01:34,070 --> 00:01:42,829
I think we're going to see why that is

00:01:36,720 --> 00:01:47,340
why why linux is such a close fit to a

00:01:42,829 --> 00:01:51,149
cluster computing so if you look at the

00:01:47,340 --> 00:01:54,930
at the top 500 supercomputer lists the

00:01:51,149 --> 00:01:57,840
top 500 computers in the world the last

00:01:54,930 --> 00:02:04,320
the last published report was from

00:01:57,840 --> 00:02:08,849
november of last year and linux ran 485

00:02:04,320 --> 00:02:11,220
out of the 500 systems now if you if you

00:02:08,849 --> 00:02:15,450
add in unix

00:02:11,220 --> 00:02:18,620
uh that brings in another 13 another

00:02:15,450 --> 00:02:23,520
two-point-six percent and that leaves

00:02:18,620 --> 00:02:29,850
one one machine on the top 500 that is

00:02:23,520 --> 00:02:32,700
running windows so if if linux is

00:02:29,850 --> 00:02:35,870
running ten percent on the desktop and

00:02:32,700 --> 00:02:39,090
Windows is running 0.2 percent on the

00:02:35,870 --> 00:02:42,060
largest computers I think that we have

00:02:39,090 --> 00:02:44,190
we have an interesting linux space over

00:02:42,060 --> 00:02:46,230
here in the supercomputer area there's

00:02:44,190 --> 00:02:49,080
also one system that's classified as

00:02:46,230 --> 00:02:52,770
mixed that window system i believe is in

00:02:49,080 --> 00:02:57,930
china and it ranks or down around 300

00:02:52,770 --> 00:03:01,520
300 plus in the 500 list it's

00:02:57,930 --> 00:03:04,290
interesting to look at how fast

00:03:01,520 --> 00:03:06,930
computing performance has been going

00:03:04,290 --> 00:03:08,820
this is a logarithmic chart so a

00:03:06,930 --> 00:03:12,480
straight line and this chart is an

00:03:08,820 --> 00:03:16,620
exponential growth and the red line in

00:03:12,480 --> 00:03:18,930
the in the middle that plots the

00:03:16,620 --> 00:03:22,280
performance of the world's fastest

00:03:18,930 --> 00:03:25,200
computer as a function of the year the

00:03:22,280 --> 00:03:28,680
the yellow line and the bottom charts

00:03:25,200 --> 00:03:32,070
the other end of the spectrum that's num

00:03:28,680 --> 00:03:37,260
that's the performance of number 500 so

00:03:32,070 --> 00:03:40,260
the top 500 ran in between those ranges

00:03:37,260 --> 00:03:44,880
the the top dark line is the summation

00:03:40,260 --> 00:03:52,280
of all computing power in the in the top

00:03:44,880 --> 00:03:55,489
500 list now the current number one

00:03:52,280 --> 00:04:02,370
computer in the world is the T on e2 in

00:03:55,489 --> 00:04:05,310
China that went online in 2013 with 33

00:04:02,370 --> 00:04:09,450
pedda flops of computing power the

00:04:05,310 --> 00:04:11,880
previous number one was the Titan from

00:04:09,450 --> 00:04:14,790
oak ridge national labs over on the

00:04:11,880 --> 00:04:18,390
other side of the mountains in Oak Ridge

00:04:14,790 --> 00:04:21,810
Tennessee they held the number one spot

00:04:18,390 --> 00:04:24,840
prior prior to that and you can see that

00:04:21,810 --> 00:04:27,120
the number one spot has been

00:04:24,840 --> 00:04:30,990
flipping back and forth between China in

00:04:27,120 --> 00:04:34,500
the US over over the last few years the

00:04:30,990 --> 00:04:39,570
in the next computer planned for Oak

00:04:34,500 --> 00:04:43,010
Ridge will be 100 petaflop plus that's

00:04:39,570 --> 00:04:45,780
planned to go online be delivered in

00:04:43,010 --> 00:04:48,210
2017 it should be in production use by

00:04:45,780 --> 00:04:51,720
2018 so if the Chinese don't do anything

00:04:48,210 --> 00:04:53,130
in the meantime we'll have we'll have

00:04:51,720 --> 00:04:57,720
the number one computer in the world

00:04:53,130 --> 00:05:01,520
back back here in the US so this is what

00:04:57,720 --> 00:05:05,669
this is what the high end of the

00:05:01,520 --> 00:05:10,010
supercomputer a spectrum looks like what

00:05:05,669 --> 00:05:14,070
you're seeing here is a long row of

00:05:10,010 --> 00:05:17,070
racks and each rack contains computing

00:05:14,070 --> 00:05:19,950
modules what you only what you don't see

00:05:17,070 --> 00:05:22,350
on this picture is that this is only one

00:05:19,950 --> 00:05:23,970
row what you have to do is picture you

00:05:22,350 --> 00:05:26,300
can't get it all in one in one

00:05:23,970 --> 00:05:31,260
photograph you have to picture a

00:05:26,300 --> 00:05:34,800
basketball court sighs data center with

00:05:31,260 --> 00:05:38,070
row after row after row of of such

00:05:34,800 --> 00:05:39,900
cabinets so that's what that's what the

00:05:38,070 --> 00:05:45,740
largest computers in the world look like

00:05:39,900 --> 00:05:50,220
today now we we got there through a

00:05:45,740 --> 00:05:52,370
through a path if you look at the at the

00:05:50,220 --> 00:05:56,870
computing computing architecture

00:05:52,370 --> 00:06:02,639
historically if we started out with

00:05:56,870 --> 00:06:05,250
small systems the the Cray one from 1975

00:06:02,639 --> 00:06:09,780
was designed by Seymour Cray who also

00:06:05,250 --> 00:06:12,960
designed the control data system 6600 he

00:06:09,780 --> 00:06:14,820
spun off his own company in based it in

00:06:12,960 --> 00:06:18,919
Chippewa Falls Wisconsin and came out

00:06:14,820 --> 00:06:24,330
with this machine the Cray one in 1975

00:06:18,919 --> 00:06:26,729
now in this architecture had a central

00:06:24,330 --> 00:06:29,039
processing unit in the case of the Cray

00:06:26,729 --> 00:06:32,669
one it was a pipelined central

00:06:29,039 --> 00:06:35,340
processing unit the idea was make make a

00:06:32,669 --> 00:06:38,009
CPU go as fast as you can and then

00:06:35,340 --> 00:06:41,879
surround it by memory

00:06:38,009 --> 00:06:47,039
so in order to do that oh they use they

00:06:41,879 --> 00:06:50,999
used pipelined instruction architecture

00:06:47,039 --> 00:06:53,930
and then they went out to get memory and

00:06:50,999 --> 00:06:58,409
bring data back from memory the

00:06:53,930 --> 00:07:02,069
limitation is the speed of light if if

00:06:58,409 --> 00:07:05,449
light goes in electricity goes 1 foot

00:07:02,069 --> 00:07:10,229
every nanosecond then a 12 and a half

00:07:05,449 --> 00:07:13,559
nanosecond clock rate is going to mean

00:07:10,229 --> 00:07:15,930
that you don't have very many feet of

00:07:13,559 --> 00:07:18,240
distance to work with and that's why

00:07:15,930 --> 00:07:20,729
what you see here is a circular

00:07:18,240 --> 00:07:22,919
arrangement so that the wires didn't

00:07:20,729 --> 00:07:25,139
have to travel so far to get out to the

00:07:22,919 --> 00:07:28,529
memory and then come back to the central

00:07:25,139 --> 00:07:31,889
processing unit so that that created

00:07:28,529 --> 00:07:34,319
that created it a limitation in how much

00:07:31,889 --> 00:07:35,999
hardware you could put in one space if

00:07:34,319 --> 00:07:37,680
he tried to make it bigger with this

00:07:35,999 --> 00:07:41,149
architecture you'd be slowing the

00:07:37,680 --> 00:07:44,419
machine down cooling was also an issue

00:07:41,149 --> 00:07:49,550
because you've put a lot of high powered

00:07:44,419 --> 00:07:52,740
equipment 115 kilowatts of power

00:07:49,550 --> 00:07:57,990
generating heat that had to be had to be

00:07:52,740 --> 00:07:59,789
dissipated so what did we get in 1975

00:07:57,990 --> 00:08:05,629
with the Cray one in terms of

00:07:59,789 --> 00:08:14,149
performance was 80 mega flops per second

00:08:05,629 --> 00:08:18,330
now by comparison we can buy these today

00:08:14,149 --> 00:08:24,559
you probably all have one Raspberry Pi

00:08:18,330 --> 00:08:29,129
version 2 has four cores and someone has

00:08:24,559 --> 00:08:34,099
done a linpack benchmark on this machine

00:08:29,129 --> 00:08:38,579
and we found that it has a 1 Giga flop

00:08:34,099 --> 00:08:41,969
performance so that means that one of

00:08:38,579 --> 00:08:48,810
these raspberry PI's has the computing

00:08:41,969 --> 00:08:51,660
power of 8 Cray one supercomputers so we

00:08:48,810 --> 00:08:54,180
live in an exciting time

00:08:51,660 --> 00:08:57,149
when a $35 piece of hard work and

00:08:54,180 --> 00:09:03,629
compete with with the earth that the

00:08:57,149 --> 00:09:05,790
world's fastest computer in 1975 so

00:09:03,629 --> 00:09:07,920
that's a little perspective but then we

00:09:05,790 --> 00:09:10,589
skipped we skip to a different

00:09:07,920 --> 00:09:15,209
architecture and this is where Linux

00:09:10,589 --> 00:09:19,410
starts to come into the the game the

00:09:15,209 --> 00:09:25,550
idea was instead of trying to build the

00:09:19,410 --> 00:09:29,930
fastest machine in uh in a centralized

00:09:25,550 --> 00:09:33,509
architecture let's use slower machines

00:09:29,930 --> 00:09:36,959
but lots of them and so the distributed

00:09:33,509 --> 00:09:40,769
architecture came about this was not the

00:09:36,959 --> 00:09:43,759
first distributed architecture machine

00:09:40,769 --> 00:09:48,769
but it was one that was successful in

00:09:43,759 --> 00:09:52,230
2004 time frame the IBM blue jean

00:09:48,769 --> 00:09:57,149
supercomputer had achieved 70 teraflops

00:09:52,230 --> 00:10:00,209
of power and it was leading the type of

00:09:57,149 --> 00:10:01,889
500 list for a little while so the idea

00:10:00,209 --> 00:10:04,439
of the distributed architecture is

00:10:01,889 --> 00:10:08,310
smaller processors very large numbers of

00:10:04,439 --> 00:10:09,990
them and then fast networking so we can

00:10:08,310 --> 00:10:13,399
get the data back and forth we're not

00:10:09,990 --> 00:10:15,630
dealing with memory data coming into a

00:10:13,399 --> 00:10:19,889
central processing unit now we're

00:10:15,630 --> 00:10:22,589
dealing with packets of information so

00:10:19,889 --> 00:10:24,600
the the software architectures were a

00:10:22,589 --> 00:10:28,319
little bit different now you're you're

00:10:24,600 --> 00:10:31,680
dealing with subdividing a task into a

00:10:28,319 --> 00:10:35,579
number of smaller problems you give them

00:10:31,680 --> 00:10:38,250
to the computing units collect the

00:10:35,579 --> 00:10:41,009
results merge them back together so this

00:10:38,250 --> 00:10:45,300
is the architecture that began in that

00:10:41,009 --> 00:10:50,160
time frame and it has served us well up

00:10:45,300 --> 00:10:55,259
to the present point in time now linux

00:10:50,160 --> 00:10:57,990
played a role in the development of the

00:10:55,259 --> 00:11:03,480
of this distributed architecture and

00:10:57,990 --> 00:11:04,499
that role goes back to the 1994 time

00:11:03,480 --> 00:11:08,039
frame with

00:11:04,499 --> 00:11:11,599
thomas sterling Donald Becker both word

00:11:08,039 --> 00:11:14,489
NASA employees they were funded to do a

00:11:11,599 --> 00:11:17,449
project that developed a

00:11:14,489 --> 00:11:20,159
high-performance computing HPC cluster

00:11:17,449 --> 00:11:23,599
using commodity off the shelf systems

00:11:20,159 --> 00:11:26,759
the idea was buy things that are cheap

00:11:23,599 --> 00:11:29,819
Network them together implement some

00:11:26,759 --> 00:11:34,049
message passing between the nodes share

00:11:29,819 --> 00:11:38,099
the file system with NFS it was all open

00:11:34,049 --> 00:11:41,669
source software back then and each

00:11:38,099 --> 00:11:44,179
system is usually identical running the

00:11:41,669 --> 00:11:46,259
same operating system same configuration

00:11:44,179 --> 00:11:49,439
although there are some heterogeneous

00:11:46,259 --> 00:11:52,019
implementations as well this some this

00:11:49,439 --> 00:11:54,989
project the Beowulf Linux cluster

00:11:52,019 --> 00:11:57,509
project was highly successful and it

00:11:54,989 --> 00:12:00,389
quickly spread throughout the various

00:11:57,509 --> 00:12:02,719
NASA research organizations and then and

00:12:00,389 --> 00:12:05,729
made its way into academic and research

00:12:02,719 --> 00:12:09,659
organizations within a year so this is

00:12:05,729 --> 00:12:13,139
what made HPC affordable for scientific

00:12:09,659 --> 00:12:18,329
communication then we have scientific

00:12:13,139 --> 00:12:21,720
computing so the the elements of a

00:12:18,329 --> 00:12:26,849
beowulf cluster or we just usually say

00:12:21,720 --> 00:12:28,919
cluster right now are these a cluster

00:12:26,849 --> 00:12:34,439
has compute nodes the more of them the

00:12:28,919 --> 00:12:36,929
better um networking we can have a wide

00:12:34,439 --> 00:12:40,439
range of networking speeds the faster

00:12:36,929 --> 00:12:43,039
the network interconnect the better we

00:12:40,439 --> 00:12:46,399
can implement very inexpensive

00:12:43,039 --> 00:12:50,119
interconnects between systems using 100

00:12:46,399 --> 00:12:52,829
megabit Ethernet or one gigabit ethernet

00:12:50,119 --> 00:12:56,639
on the other end of the spectrum the new

00:12:52,829 --> 00:13:00,479
system coming into or on l will use an

00:12:56,639 --> 00:13:03,059
InfiniBand interconnect that will be

00:13:00,479 --> 00:13:05,369
capable of supporting 23 gigabytes per

00:13:03,059 --> 00:13:08,069
second so that's the other end of the

00:13:05,369 --> 00:13:11,309
spectrum the other the other elements we

00:13:08,069 --> 00:13:14,939
usually have a shared home directory all

00:13:11,309 --> 00:13:18,209
nodes are looking at the same files in

00:13:14,939 --> 00:13:21,179
your home directory and NFS

00:13:18,209 --> 00:13:24,480
works very well for that purpose and

00:13:21,179 --> 00:13:28,519
then we need a message passing so a

00:13:24,480 --> 00:13:31,920
compute node needs to be able to receive

00:13:28,519 --> 00:13:37,439
arrays of data from other nodes and

00:13:31,920 --> 00:13:40,800
return their results this is what this

00:13:37,439 --> 00:13:44,629
is what a middle-sized cluster looks

00:13:40,800 --> 00:13:49,499
like i mentioned that i'm working with

00:13:44,629 --> 00:13:52,050
the group at ETSU in Johnson City this

00:13:49,499 --> 00:13:55,439
some what we have here are two clusters

00:13:52,050 --> 00:13:58,379
the one on the left the two racks on the

00:13:55,439 --> 00:14:04,139
left is the oldest of the two and that's

00:13:58,379 --> 00:14:06,959
a dell cluster and the two racks on the

00:14:04,139 --> 00:14:10,379
right are from hewlett-packard it's a

00:14:06,959 --> 00:14:13,639
newer cluster about 4x the performance

00:14:10,379 --> 00:14:16,439
of the one on the left so that's what

00:14:13,639 --> 00:14:19,290
that's what a typical campus cluster

00:14:16,439 --> 00:14:22,470
would look like and if we open up one of

00:14:19,290 --> 00:14:24,350
the doors and we look inside you'll see

00:14:22,470 --> 00:14:27,660
that they're they're typically blade

00:14:24,350 --> 00:14:29,309
oriented so you can pack a lot of

00:14:27,660 --> 00:14:32,160
hardware into a small amount of space

00:14:29,309 --> 00:14:35,309
you still have heat problems and you

00:14:32,160 --> 00:14:41,480
still have power problems we we we draw

00:14:35,309 --> 00:14:47,759
80 80 to 90 amps from a 208 volt 3-phase

00:14:41,480 --> 00:14:50,549
service okay 24-7 so these things are

00:14:47,759 --> 00:14:57,740
not they're not cheap to operate even if

00:14:50,549 --> 00:15:00,540
you're just counting the power bill so

00:14:57,740 --> 00:15:03,689
haven't you always wondered what what

00:15:00,540 --> 00:15:09,439
version of linux is running on on these

00:15:03,689 --> 00:15:12,329
systems well in in China they did a

00:15:09,439 --> 00:15:14,819
linux version that they called Kyle in

00:15:12,329 --> 00:15:20,279
and this is the version that's running

00:15:14,819 --> 00:15:22,559
on the Diana to system there are a

00:15:20,279 --> 00:15:25,799
number of other distributions cluster

00:15:22,559 --> 00:15:28,649
kopecks based on the topix distribution

00:15:25,799 --> 00:15:31,930
and some of these are historical because

00:15:28,649 --> 00:15:36,190
they're no longer no longer maintained

00:15:31,930 --> 00:15:39,250
um 11 alternative that a surprising

00:15:36,190 --> 00:15:43,720
number of organizations are using is

00:15:39,250 --> 00:15:46,300
actually to do your own work rather than

00:15:43,720 --> 00:15:49,930
using a cluster oriented distribution

00:15:46,300 --> 00:15:54,160
pick up a standard distribution and and

00:15:49,930 --> 00:15:58,029
then adapt adapt it to your purposes

00:15:54,160 --> 00:16:00,010
more work but you can also fine tune and

00:15:58,029 --> 00:16:02,560
so there are some good reasons for doing

00:16:00,010 --> 00:16:05,410
that there are various commercial linux

00:16:02,560 --> 00:16:07,540
distributions iBM has one that they sell

00:16:05,410 --> 00:16:09,730
with their products Cray has one that

00:16:07,540 --> 00:16:13,529
they sell with their products my

00:16:09,730 --> 00:16:17,380
favorite is is called the rocks cluster

00:16:13,529 --> 00:16:20,589
distribution and the rocks distribution

00:16:17,380 --> 00:16:24,160
is intended specifically for HPC

00:16:20,589 --> 00:16:29,170
clusters it was created at the San Diego

00:16:24,160 --> 00:16:33,700
supercomputer center in the year 2000

00:16:29,170 --> 00:16:35,890
it's a totally open source and it is

00:16:33,700 --> 00:16:39,010
currently last I looked it was running

00:16:35,890 --> 00:16:42,430
on clusters with a little over eight

00:16:39,010 --> 00:16:45,130
thousand nodes and and of course he can

00:16:42,430 --> 00:16:48,580
run it on any cluster as small as small

00:16:45,130 --> 00:16:51,160
as you want it's actively maintained the

00:16:48,580 --> 00:16:53,170
current version 6.2 was just released

00:16:51,160 --> 00:16:56,080
last month and we're just in the process

00:16:53,170 --> 00:16:59,980
of installing that version on the etsu

00:16:56,080 --> 00:17:03,820
system right now so rocks is based on

00:16:59,980 --> 00:17:07,420
centos which in turn is based on red hat

00:17:03,820 --> 00:17:11,500
enterprise linux but it adds essentials

00:17:07,420 --> 00:17:13,809
necessary for operating a cluster the

00:17:11,500 --> 00:17:16,150
message passing interface that we

00:17:13,809 --> 00:17:19,300
mentioned it has a very nice cluster

00:17:16,150 --> 00:17:21,640
aware installer so you're installing on

00:17:19,300 --> 00:17:25,050
both the front end node and also on all

00:17:21,640 --> 00:17:29,710
of the computing nodes in one

00:17:25,050 --> 00:17:31,450
well-organized installation kickstart

00:17:29,710 --> 00:17:34,450
integration we'll talk a little bit more

00:17:31,450 --> 00:17:37,510
about kick start later they have a

00:17:34,450 --> 00:17:40,620
monitoring package called ganglia it's

00:17:37,510 --> 00:17:43,700
an open source monitoring package

00:17:40,620 --> 00:17:47,690
presents a nice

00:17:43,700 --> 00:17:52,070
single pageview of nodes in the system

00:17:47,690 --> 00:17:55,760
who's up who's down and the loading on

00:17:52,070 --> 00:17:57,590
the various nodes and n scheduling we'll

00:17:55,760 --> 00:17:59,720
talk more about scheduling a couple

00:17:57,590 --> 00:18:01,250
minutes but scheduling is real important

00:17:59,720 --> 00:18:05,120
if you have scientists and researchers

00:18:01,250 --> 00:18:07,159
who like to run programs that will use a

00:18:05,120 --> 00:18:10,549
hundred percent of your CPU for two

00:18:07,159 --> 00:18:13,820
weeks then you might have some other

00:18:10,549 --> 00:18:15,590
users who would also like to be running

00:18:13,820 --> 00:18:17,960
a hundred percent of the CPU for two

00:18:15,590 --> 00:18:20,740
weeks so it's important to have some

00:18:17,960 --> 00:18:28,269
sort of a scheduling saw a package to

00:18:20,740 --> 00:18:30,880
keep that under control now if you're I

00:18:28,269 --> 00:18:33,289
expect that there are probably three

00:18:30,880 --> 00:18:36,370
groups of people in this room there are

00:18:33,289 --> 00:18:38,960
some people who are currently doing a

00:18:36,370 --> 00:18:41,870
system administration on clustered

00:18:38,960 --> 00:18:44,419
systems and there are probably some

00:18:41,870 --> 00:18:48,710
people who are interested in cluster

00:18:44,419 --> 00:18:52,130
computing may be doing it with commodity

00:18:48,710 --> 00:18:54,440
systems like raspberry PI's and but

00:18:52,130 --> 00:18:57,980
they're probably also some people who

00:18:54,440 --> 00:18:59,840
are looking at the at the job

00:18:57,980 --> 00:19:02,389
opportunities and they've noticed that

00:18:59,840 --> 00:19:04,990
huh there are quite a few job

00:19:02,389 --> 00:19:10,090
opportunities for system administrators

00:19:04,990 --> 00:19:14,539
with Linux experience and and some

00:19:10,090 --> 00:19:18,110
cluster experience so I've made a list

00:19:14,539 --> 00:19:22,100
if if you're in that category and you'd

00:19:18,110 --> 00:19:25,760
like to see yourself as a as becoming

00:19:22,100 --> 00:19:28,460
qualified to do to compete for some of

00:19:25,760 --> 00:19:32,210
these jobs this is just this is just a

00:19:28,460 --> 00:19:34,700
quick list of the topics that you would

00:19:32,210 --> 00:19:40,179
want to familiarize yourself with so

00:19:34,700 --> 00:19:40,179
that you succeed in the job interview so

00:19:40,360 --> 00:19:45,230
scripting or point-and-click that's an

00:19:43,159 --> 00:19:47,299
issue in this group I don't think we

00:19:45,230 --> 00:19:50,059
need to talk about that issue a lot

00:19:47,299 --> 00:19:52,760
because I think you understand the value

00:19:50,059 --> 00:19:54,830
of scripting but there are there are

00:19:52,760 --> 00:19:56,950
other groups that

00:19:54,830 --> 00:20:00,919
think that point and click

00:19:56,950 --> 00:20:03,559
administration is real cool and so we

00:20:00,919 --> 00:20:09,010
need to talk about that a little bit how

00:20:03,559 --> 00:20:09,010
do you keep thousands of nodes in sync a

00:20:09,640 --> 00:20:15,350
non-trivial task but one that needs to

00:20:13,309 --> 00:20:17,570
be brought under control but you have a

00:20:15,350 --> 00:20:22,279
user community you know people who are

00:20:17,570 --> 00:20:26,269
going to be needing a training support

00:20:22,279 --> 00:20:28,730
you need a strategy for supporting a

00:20:26,269 --> 00:20:31,899
unit user community that should include

00:20:28,730 --> 00:20:35,990
some quick start documentation so that

00:20:31,899 --> 00:20:39,250
users can come come up quickly without a

00:20:35,990 --> 00:20:42,200
lot of a lot of hand-holding from you

00:20:39,250 --> 00:20:46,460
uptime is important what if you have 500

00:20:42,200 --> 00:20:50,149
nodes and you know the probability of

00:20:46,460 --> 00:20:52,340
failure of one node is X well now the

00:20:50,149 --> 00:20:58,399
probability of getting a failure in your

00:20:52,340 --> 00:21:02,950
system is 500 x so you need to be you

00:20:58,399 --> 00:21:06,710
need to have a strategy that lets you

00:21:02,950 --> 00:21:09,380
bring defective nodes out of the system

00:21:06,710 --> 00:21:12,590
replace bring them back into the system

00:21:09,380 --> 00:21:16,039
without without upsetting the production

00:21:12,590 --> 00:21:19,340
that's that's going on benchmarking is

00:21:16,039 --> 00:21:24,409
important of various storage strategies

00:21:19,340 --> 00:21:27,289
to consider power strategies third-party

00:21:24,409 --> 00:21:29,720
software administration updates and then

00:21:27,289 --> 00:21:32,450
if you have an administration team with

00:21:29,720 --> 00:21:35,210
only one person then this one is trivial

00:21:32,450 --> 00:21:37,370
but if you're running a large

00:21:35,210 --> 00:21:39,620
supercomputer more than likely you've

00:21:37,370 --> 00:21:42,620
got an administration team so you need a

00:21:39,620 --> 00:21:45,440
way to keep the keep the team all on the

00:21:42,620 --> 00:21:50,029
same page so that's the that's the quick

00:21:45,440 --> 00:21:53,570
list of issues scripting versus

00:21:50,029 --> 00:21:57,529
point-and-click so if you have a task

00:21:53,570 --> 00:22:00,559
that you're only going to do once you

00:21:57,529 --> 00:22:02,210
want to write a memo so you're going to

00:22:00,559 --> 00:22:04,730
call up a word processor and start

00:22:02,210 --> 00:22:08,230
clicking around on the page and you

00:22:04,730 --> 00:22:11,890
click on the print and now you have your

00:22:08,230 --> 00:22:15,070
written that's fine but what if you need

00:22:11,890 --> 00:22:17,169
to do something twice like I want to

00:22:15,070 --> 00:22:19,150
install an operating system on machine a

00:22:17,169 --> 00:22:22,870
and now I want to install the operating

00:22:19,150 --> 00:22:26,140
system on machine be the point and click

00:22:22,870 --> 00:22:27,790
method is problematic it takes you twice

00:22:26,140 --> 00:22:33,240
as long because you have to do it twice

00:22:27,790 --> 00:22:36,340
and furthermore you might skip a step or

00:22:33,240 --> 00:22:38,410
make an error and entering a parameter

00:22:36,340 --> 00:22:40,630
so you may not end up with the same

00:22:38,410 --> 00:22:43,870
operating system on both of those

00:22:40,630 --> 00:22:47,650
systems now multiply that what if you

00:22:43,870 --> 00:22:51,610
have 50 nodes on your cluster point and

00:22:47,650 --> 00:22:53,110
click is out of the question not

00:22:51,610 --> 00:22:56,470
suitable what if you have a

00:22:53,110 --> 00:23:03,970
supercomputer with with a half a million

00:22:56,470 --> 00:23:08,140
are chords you know so scripted task

00:23:03,970 --> 00:23:12,460
automation is really the only the only

00:23:08,140 --> 00:23:16,360
game in a cluster computing and

00:23:12,460 --> 00:23:19,600
supercomputing so in my opinion this is

00:23:16,360 --> 00:23:23,590
why we don't find windows running on

00:23:19,600 --> 00:23:27,130
supercomputers and clusters because it's

00:23:23,590 --> 00:23:29,770
possible to do scripting and windows but

00:23:27,130 --> 00:23:32,710
Windows was designed first as a

00:23:29,770 --> 00:23:36,400
graphical environment and then scripting

00:23:32,710 --> 00:23:38,559
was added on top and Linux was designed

00:23:36,400 --> 00:23:41,140
the other way around the first the first

00:23:38,559 --> 00:23:43,900
Linux was a scriptable environment and

00:23:41,140 --> 00:23:47,490
then later on we added graphical on top

00:23:43,900 --> 00:23:50,110
of it because of that if you've done

00:23:47,490 --> 00:23:53,290
scripting in both environments you

00:23:50,110 --> 00:23:59,230
appreciate the power that you have in a

00:23:53,290 --> 00:24:01,660
in a Linux environment so how do we make

00:23:59,230 --> 00:24:05,830
hundreds or thousands of nodes look the

00:24:01,660 --> 00:24:08,250
same doing it by hand doesn't work so we

00:24:05,830 --> 00:24:11,530
have to we have to do it in a better way

00:24:08,250 --> 00:24:16,659
now the rocks and the Red Hat solution

00:24:11,530 --> 00:24:19,990
uses rpm packages and the end the

00:24:16,659 --> 00:24:21,330
kickstart installer to solve this

00:24:19,990 --> 00:24:25,260
problem

00:24:21,330 --> 00:24:28,080
so you define what an insta what a

00:24:25,260 --> 00:24:29,730
compute node installation looks like and

00:24:28,080 --> 00:24:31,740
remember all of these compute nodes are

00:24:29,730 --> 00:24:33,480
running a full up operating system

00:24:31,740 --> 00:24:35,510
they're operating the same operating

00:24:33,480 --> 00:24:40,910
system they're all they're all identical

00:24:35,510 --> 00:24:43,110
usually so we define what we want by

00:24:40,910 --> 00:24:47,610
deciding which are which are p.m.

00:24:43,110 --> 00:24:52,200
packages go into it and then we say kick

00:24:47,610 --> 00:24:57,030
start and kickstart is a is a tool that

00:24:52,200 --> 00:24:59,580
came out of red hat and it it does a an

00:24:57,030 --> 00:25:02,550
installation based on the rules that

00:24:59,580 --> 00:25:05,310
you've set up on that node so you can

00:25:02,550 --> 00:25:09,240
say kicks you can say kick start all of

00:25:05,310 --> 00:25:12,980
my nodes and in parallel all of your

00:25:09,240 --> 00:25:18,300
nodes are installed it can it can take a

00:25:12,980 --> 00:25:24,630
minute or two too-too-roo to update now

00:25:18,300 --> 00:25:28,700
another another tool that I find very if

00:25:24,630 --> 00:25:30,990
I need to use on a daily basis is pd SH

00:25:28,700 --> 00:25:35,640
many of you have probably already used

00:25:30,990 --> 00:25:38,190
that it's a parallel SSH program and

00:25:35,640 --> 00:25:40,890
here are a couple examples that show the

00:25:38,190 --> 00:25:44,070
power of that so if you had if you had

00:25:40,890 --> 00:25:47,940
50 compute nodes and you wanted to issue

00:25:44,070 --> 00:25:52,500
a command to all 50 nodes then you do it

00:25:47,940 --> 00:25:55,410
like this pdas h.w says you know these

00:25:52,500 --> 00:25:58,920
are the addresses of the nodes that I

00:25:55,410 --> 00:26:03,900
want to talk to hear i'm i'm addressing

00:25:58,920 --> 00:26:06,810
rack number 0 nodes 0 2 49 in that rack

00:26:03,900 --> 00:26:10,140
and i want them to run the program up

00:26:06,810 --> 00:26:12,720
time and give me the results and this is

00:26:10,140 --> 00:26:17,220
an actual an actual result that came

00:26:12,720 --> 00:26:21,530
back from her etsu cluster and you can

00:26:17,220 --> 00:26:25,680
see that we get 50 lions back with each

00:26:21,530 --> 00:26:29,910
compute node running its its command now

00:26:25,680 --> 00:26:34,650
I most of this open source software is

00:26:29,910 --> 00:26:40,050
available in standard repositories

00:26:34,650 --> 00:26:43,980
in at my home I have four raspberry PI's

00:26:40,050 --> 00:26:47,640
i call them are our PI 1 through our pie

00:26:43,980 --> 00:26:51,360
for and they're serving with the

00:26:47,640 --> 00:26:53,340
security camera duty security cameras

00:26:51,360 --> 00:26:56,640
only take a tenth of a percent of your

00:26:53,340 --> 00:27:01,140
CPU so I figured well okay I'll just set

00:26:56,640 --> 00:27:04,730
up a cluster on these spare raspberry

00:27:01,140 --> 00:27:08,460
PI's after all they're already networked

00:27:04,730 --> 00:27:11,970
so it doesn't cost anything to turn them

00:27:08,460 --> 00:27:15,810
into a cluster so here we have sending a

00:27:11,970 --> 00:27:18,720
PDS H command to for raspberry PI's

00:27:15,810 --> 00:27:22,700
asking them for their up time and we get

00:27:18,720 --> 00:27:22,700
back the same the same kind of results

00:27:23,930 --> 00:27:33,810
so uh going through the the essentials

00:27:29,700 --> 00:27:35,520
of cluster administration we we said

00:27:33,810 --> 00:27:38,880
that community building was important

00:27:35,520 --> 00:27:43,830
what we use is a cluster our cluster

00:27:38,880 --> 00:27:45,600
wiki using mediawiki so we have wiki

00:27:43,830 --> 00:27:49,650
pages that we use to communicate

00:27:45,600 --> 00:27:52,320
information to users users can develop

00:27:49,650 --> 00:27:56,040
their own pages for code exchange they

00:27:52,320 --> 00:27:59,820
can share best practices and we show

00:27:56,040 --> 00:28:03,390
users some quick starts in each of the

00:27:59,820 --> 00:28:05,520
languages so a user can come to the wiki

00:28:03,390 --> 00:28:08,370
and they have enough information so that

00:28:05,520 --> 00:28:11,400
they can actually run something in a

00:28:08,370 --> 00:28:13,290
clustered environment and then the

00:28:11,400 --> 00:28:14,880
easiest the easiest way to write a

00:28:13,290 --> 00:28:17,580
program is to have a program that

00:28:14,880 --> 00:28:21,570
already works and they can modify it to

00:28:17,580 --> 00:28:24,240
suit and start to build their own their

00:28:21,570 --> 00:28:26,910
own software so here's here's an example

00:28:24,240 --> 00:28:29,400
I won't spend a lot of time on this but

00:28:26,910 --> 00:28:31,850
the slides are available you know if you

00:28:29,400 --> 00:28:35,910
want to run this on your on your own

00:28:31,850 --> 00:28:38,190
cluster if you're implementing a

00:28:35,910 --> 00:28:43,560
raspberry pi cup cluster or if you have

00:28:38,190 --> 00:28:45,480
a larger one what we have here is an

00:28:43,560 --> 00:28:49,799
example that shows

00:28:45,480 --> 00:28:55,200
a Python program using the message

00:28:49,799 --> 00:28:57,419
passing interface on 50 nodes to do

00:28:55,200 --> 00:29:01,530
something very simple that we launched

00:28:57,419 --> 00:29:05,880
that with mpi run which is a part of the

00:29:01,530 --> 00:29:08,970
open mpi package we tell it how many

00:29:05,880 --> 00:29:12,809
nodes we want to use and then we give it

00:29:08,970 --> 00:29:14,309
a command in this case Python and

00:29:12,809 --> 00:29:15,960
there's the name of the Python program

00:29:14,309 --> 00:29:25,220
that's the command that we want it to

00:29:15,960 --> 00:29:31,559
run we have a Python library called MPI

00:29:25,220 --> 00:29:38,549
4py that knows how to support the openmp

00:29:31,559 --> 00:29:43,260
I end up using that we can then write

00:29:38,549 --> 00:29:46,650
our program now get rank rank is the

00:29:43,260 --> 00:29:50,630
name or the number of the compute node

00:29:46,650 --> 00:29:54,780
that we're talking to so we asked for 50

00:29:50,630 --> 00:29:59,870
compute nodes so we get ranked ranging

00:29:54,780 --> 00:30:02,730
from 0 up to 49 so the program itself is

00:29:59,870 --> 00:30:05,970
written much in the same way as you

00:30:02,730 --> 00:30:09,480
would see a multiple process program

00:30:05,970 --> 00:30:14,130
that Forks additional profs processes or

00:30:09,480 --> 00:30:20,790
or threads in this case we're forking on

00:30:14,130 --> 00:30:23,880
on to a another compute node so remember

00:30:20,790 --> 00:30:26,070
now each each node is going to be

00:30:23,880 --> 00:30:28,590
executing the same program at the same

00:30:26,070 --> 00:30:31,530
time that program it was in your home

00:30:28,590 --> 00:30:34,520
directory with NFS shared the home

00:30:31,530 --> 00:30:38,910
directory so that all nodes see it and

00:30:34,520 --> 00:30:43,770
when we run it we run it on all nodes at

00:30:38,910 --> 00:30:46,650
the same time now the node knows it's

00:30:43,770 --> 00:30:49,620
ranked number so we say if I'm rank 0

00:30:46,650 --> 00:30:53,130
then I'm going to be the the master and

00:30:49,620 --> 00:30:57,210
the data organizer if I'm not know 0

00:30:53,130 --> 00:30:59,290
then I'm going to be a computation

00:30:57,210 --> 00:31:02,080
element I'm going to receive my little

00:30:59,290 --> 00:31:03,910
packet of work I'm going to do my work

00:31:02,080 --> 00:31:07,930
and then I'm going to return the result

00:31:03,910 --> 00:31:11,920
so you can see how that works we just

00:31:07,930 --> 00:31:17,050
use standard Python to create an array

00:31:11,920 --> 00:31:25,240
of 100 floats and then inside that array

00:31:17,050 --> 00:31:28,110
we put a value and then we use MPI to

00:31:25,240 --> 00:31:31,330
send that array to all of the other

00:31:28,110 --> 00:31:34,870
compute nodes in the system now if

00:31:31,330 --> 00:31:37,050
you're not know 0 then you do you're

00:31:34,870 --> 00:31:42,070
doing the opposite thing concurrently

00:31:37,050 --> 00:31:46,630
where you create an empty array of the

00:31:42,070 --> 00:31:49,420
same size and then you tell MPI that you

00:31:46,630 --> 00:31:54,460
want to receive the contents of that

00:31:49,420 --> 00:31:57,880
array into it and then when you're after

00:31:54,460 --> 00:32:00,460
you've exchanged MPI communications than

00:31:57,880 --> 00:32:04,300
you do your work and send the result

00:32:00,460 --> 00:32:08,050
back so here we're printing ranked

00:32:04,300 --> 00:32:10,480
number and the last the last element is

00:32:08,050 --> 00:32:13,560
our simple computation where we're

00:32:10,480 --> 00:32:16,540
taking the first entry in the array

00:32:13,560 --> 00:32:19,630
multiplying it by PI and returning the

00:32:16,540 --> 00:32:23,320
result so it's a real simple application

00:32:19,630 --> 00:32:27,790
but you can see that the concepts can be

00:32:23,320 --> 00:32:39,130
extended arbitrarily so when we run it

00:32:27,790 --> 00:32:43,600
yes okay so

00:32:39,130 --> 00:32:49,030
is does each node get a different value

00:32:43,600 --> 00:32:54,300
it can it's up to you now in yeah in the

00:32:49,030 --> 00:32:57,460
example um in this example node 0 is

00:32:54,300 --> 00:33:02,170
creating one array that it's sending to

00:32:57,460 --> 00:33:05,200
everyone and it's common but you could

00:33:02,170 --> 00:33:07,960
code this if you had some other way to

00:33:05,200 --> 00:33:10,630
partition the program if you were doing

00:33:07,960 --> 00:33:12,760
a galaxy collision for example you'd

00:33:10,630 --> 00:33:16,720
want to send a piece of the galaxy to

00:33:12,760 --> 00:33:31,480
node 1 and another piece to no.2 and so

00:33:16,720 --> 00:33:36,490
forth so we right right so um in in that

00:33:31,480 --> 00:33:40,750
kind that kind of a program structure

00:33:36,490 --> 00:33:44,890
then node 0 would send individual

00:33:40,750 --> 00:33:48,580
packets to specific nodes and then those

00:33:44,890 --> 00:33:51,780
nodes would send individual packets back

00:33:48,580 --> 00:33:55,960
to node 0 for assembly and then it would

00:33:51,780 --> 00:33:59,440
combine those and reorganize the galaxy

00:33:55,960 --> 00:34:06,310
and send out the the next iteration of

00:33:59,440 --> 00:34:08,050
it so job scheduling we we touched on

00:34:06,310 --> 00:34:11,050
that you know how do you control the

00:34:08,050 --> 00:34:13,480
computing hogs and with with scientists

00:34:11,050 --> 00:34:16,210
and researchers they're all computing

00:34:13,480 --> 00:34:18,370
hogs they'll take all the computing

00:34:16,210 --> 00:34:23,050
resources that you've got if you have a

00:34:18,370 --> 00:34:26,550
Titan or a Tiana too they'll use it and

00:34:23,050 --> 00:34:32,710
and it makes sense because if you have a

00:34:26,550 --> 00:34:36,190
simulation that that has some some

00:34:32,710 --> 00:34:39,190
resolution if you increase the size of

00:34:36,190 --> 00:34:42,010
the of the resolution you increase your

00:34:39,190 --> 00:34:44,830
doing a galaxy simulation you instead of

00:34:42,010 --> 00:34:46,690
instead of taking an increment of 1 one

00:34:44,830 --> 00:34:50,230
light-year you go down to a tenth of a

00:34:46,690 --> 00:34:52,710
Lightyear the result is going to be more

00:34:50,230 --> 00:34:55,889
fine-grained and better so

00:34:52,710 --> 00:34:58,910
the applications tend to grow until

00:34:55,889 --> 00:35:03,060
there's no more computing power left

00:34:58,910 --> 00:35:07,859
it's the knee the nature of the nature

00:35:03,060 --> 00:35:10,280
of computing research so you've got to

00:35:07,859 --> 00:35:13,320
have a CI have a strategy for

00:35:10,280 --> 00:35:16,260
controlling computer hogs and that that

00:35:13,320 --> 00:35:18,960
strategy involves a scheduler and so

00:35:16,260 --> 00:35:23,400
when done if I go back and I look at

00:35:18,960 --> 00:35:25,980
this when I say MPI run I want 50 nodes

00:35:23,400 --> 00:35:28,710
I'm really telling this to the scheduler

00:35:25,980 --> 00:35:35,640
and the scheduler will try to work it

00:35:28,710 --> 00:35:38,640
out for me so uh the rocks distribution

00:35:35,640 --> 00:35:42,320
comes packaged with what's called grid

00:35:38,640 --> 00:35:46,200
engine or sge how much time do we live

00:35:42,320 --> 00:35:48,839
okay good so it's called grid engine or

00:35:46,200 --> 00:35:50,400
sge I'm going to try to leave Leave

00:35:48,839 --> 00:35:56,540
minutes at the end here for questions

00:35:50,400 --> 00:35:59,040
too so this is open source software and

00:35:56,540 --> 00:36:01,890
it does a good job of allocating

00:35:59,040 --> 00:36:04,890
resources you can you can specify what I

00:36:01,890 --> 00:36:08,940
need my project needs a gigabyte of

00:36:04,890 --> 00:36:11,300
memory on each node I need 200 nodes and

00:36:08,940 --> 00:36:14,760
when those resources become available

00:36:11,300 --> 00:36:20,580
then your job can start that sort of

00:36:14,760 --> 00:36:23,700
thing okay another issue is up time you

00:36:20,580 --> 00:36:28,849
want you want to maximize uptime but you

00:36:23,700 --> 00:36:31,500
also have to deal with the reality that

00:36:28,849 --> 00:36:35,130
you have a high probability of failure

00:36:31,500 --> 00:36:39,180
when you have such large systems with

00:36:35,130 --> 00:36:41,730
such large component counts so for

00:36:39,180 --> 00:36:45,660
uptime there are some tools that that

00:36:41,730 --> 00:36:48,000
help us the the ganglia program that I

00:36:45,660 --> 00:36:51,690
mentioned before comes packaged with

00:36:48,000 --> 00:36:58,560
rocks distribution it's open source it

00:36:51,690 --> 00:37:01,470
gives you a single web page with status

00:36:58,560 --> 00:37:03,720
of of nodes you can see you can see

00:37:01,470 --> 00:37:05,820
instantly how your system is loaded if

00:37:03,720 --> 00:37:07,590
you have any failures on it you can see

00:37:05,820 --> 00:37:12,000
that immediately

00:37:07,590 --> 00:37:15,190
SNMP is a good tool you'd like to

00:37:12,000 --> 00:37:16,990
oftentimes you don't have immediate

00:37:15,190 --> 00:37:19,090
access to these systems you might be

00:37:16,990 --> 00:37:22,690
administering them from remote locations

00:37:19,090 --> 00:37:26,260
so you'd like to have a kvm so that you

00:37:22,690 --> 00:37:28,920
can access the system remotely you'd

00:37:26,260 --> 00:37:33,130
like to be able to remotely power cycle

00:37:28,920 --> 00:37:35,860
individual nodes and and then watch the

00:37:33,130 --> 00:37:39,700
bios come up you'd like to be able to do

00:37:35,860 --> 00:37:43,270
all of that remotely node kick starts

00:37:39,700 --> 00:37:46,540
with concurrent with operations this is

00:37:43,270 --> 00:37:49,900
really a cool thing if you can implement

00:37:46,540 --> 00:37:52,960
this imagine that you have a you have

00:37:49,900 --> 00:37:57,180
your scheduler running sge your

00:37:52,960 --> 00:38:00,520
scheduler is taking jobs from users and

00:37:57,180 --> 00:38:03,870
allocating those jobs to the available

00:38:00,520 --> 00:38:09,720
compute nodes as as they become ready

00:38:03,870 --> 00:38:15,190
what if you injected into this system a

00:38:09,720 --> 00:38:18,070
job that says I have a new a new set of

00:38:15,190 --> 00:38:21,580
RPM packages that I want to include in

00:38:18,070 --> 00:38:25,720
the configuration I want that to be

00:38:21,580 --> 00:38:27,310
applied to all nodes so I'd like to I'd

00:38:25,720 --> 00:38:30,340
like to kick starter note I'm going to

00:38:27,310 --> 00:38:32,980
do a fresh installation take it all the

00:38:30,340 --> 00:38:37,420
way down to to the metal bring it up

00:38:32,980 --> 00:38:41,620
with with a new configuration well you

00:38:37,420 --> 00:38:46,330
give that to your scheduler as a job the

00:38:41,620 --> 00:38:50,680
scheduler goes around and finds nodes

00:38:46,330 --> 00:38:55,590
that are becoming idle they are idle now

00:38:50,680 --> 00:39:01,270
or they're becoming idle soon and it

00:38:55,590 --> 00:39:06,430
declares them not active for new jobs

00:39:01,270 --> 00:39:09,060
and it'll send them a kickstart a minute

00:39:06,430 --> 00:39:14,200
or two later that node is up to date and

00:39:09,060 --> 00:39:16,930
joins the mix meanwhile other nodes

00:39:14,200 --> 00:39:20,590
become free and so in the in the course

00:39:16,930 --> 00:39:23,980
of not a lot of time maybe 10 minutes

00:39:20,590 --> 00:39:27,340
20 minutes you've you've reinstalled all

00:39:23,980 --> 00:39:30,370
nodes without ever interrupting any of

00:39:27,340 --> 00:39:32,050
the jobs that are that are going

00:39:30,370 --> 00:39:34,420
underway it's a real powerful thing and

00:39:32,050 --> 00:39:37,930
users appreciate it because you don't

00:39:34,420 --> 00:39:41,440
have to take your system down and stop

00:39:37,930 --> 00:39:43,450
that program that has been running for a

00:39:41,440 --> 00:39:49,540
week and a half out of its two-week

00:39:43,450 --> 00:39:53,580
lifetime so benchmarking is is important

00:39:49,540 --> 00:39:56,200
the Linpack benchmark is used for

00:39:53,580 --> 00:39:59,470
computational performance in the top 500

00:39:56,200 --> 00:40:04,210
ranking and I also like to use the the

00:39:59,470 --> 00:40:06,640
bonnie + + benchmark for disk i/o if

00:40:04,210 --> 00:40:08,680
we're playing with different storage

00:40:06,640 --> 00:40:12,760
configurations we'd like to be able to

00:40:08,680 --> 00:40:17,890
have a means of measuring read and write

00:40:12,760 --> 00:40:23,590
performance in to disk so power

00:40:17,890 --> 00:40:27,250
strategies most systems that I'm

00:40:23,590 --> 00:40:31,440
familiar with our running back up power

00:40:27,250 --> 00:40:35,380
ups power on front end nodes and

00:40:31,440 --> 00:40:38,080
uncritical storage systems they

00:40:35,380 --> 00:40:41,310
typically don't take a lot of power so

00:40:38,080 --> 00:40:44,050
back backup power is feasible for that

00:40:41,310 --> 00:40:47,440
but they're running directly on the

00:40:44,050 --> 00:40:51,610
mains for the compute nodes if you have

00:40:47,440 --> 00:40:55,150
a if you have hundreds or thousands of

00:40:51,610 --> 00:40:58,740
systems running on kilowatts of power

00:40:55,150 --> 00:41:03,880
the cost of the UPS would be quite large

00:40:58,740 --> 00:41:08,890
at etsu we we generally see what may be

00:41:03,880 --> 00:41:14,290
one or maybe two power outages in a year

00:41:08,890 --> 00:41:18,220
and the impact that is not large enough

00:41:14,290 --> 00:41:21,730
to justify the cost of a UPS and we've

00:41:18,220 --> 00:41:25,350
asked other organizations and this seems

00:41:21,730 --> 00:41:27,430
to be a common practice typical power

00:41:25,350 --> 00:41:32,800
configuration I mentioned was 208

00:41:27,430 --> 00:41:34,119
three-phase it's interesting that ORNL

00:41:32,800 --> 00:41:38,019
with the

00:41:34,119 --> 00:41:40,900
titan installation they went up to 480

00:41:38,019 --> 00:41:44,019
volt power in order to reduce the

00:41:40,900 --> 00:41:47,019
diameter of the copper wiring that they

00:41:44,019 --> 00:41:50,859
needed and they claim that they saved a

00:41:47,019 --> 00:41:59,319
million dollars in copper wire costs by

00:41:50,859 --> 00:42:02,140
making that design change that's right

00:41:59,319 --> 00:42:05,769
the the observation was we have the same

00:42:02,140 --> 00:42:08,529
numbers of wires but the amount of

00:42:05,769 --> 00:42:14,950
copper in those layers is is smaller a

00:42:08,529 --> 00:42:19,480
million dollars in copper so a third

00:42:14,950 --> 00:42:24,759
party software administration okay in in

00:42:19,480 --> 00:42:28,359
a perfect world we would have all of our

00:42:24,759 --> 00:42:31,029
software located in a repository and we

00:42:28,359 --> 00:42:34,799
would yum install everything and we

00:42:31,029 --> 00:42:37,619
would be so happy because the QA

00:42:34,799 --> 00:42:42,759
organizations will have worked out the

00:42:37,619 --> 00:42:48,009
the issues and we will have a consistent

00:42:42,759 --> 00:42:51,759
system that that we're happy with that's

00:42:48,009 --> 00:42:54,519
the perfect world now in the real world

00:42:51,759 --> 00:42:58,049
in this space you've got a you've got a

00:42:54,519 --> 00:43:05,499
lot of scientific software that's

00:42:58,049 --> 00:43:08,170
sometimes old sometimes even older and a

00:43:05,499 --> 00:43:11,289
lot of this software little of this

00:43:08,170 --> 00:43:16,359
software has been merged into the

00:43:11,289 --> 00:43:19,839
repositories so you are faced with user

00:43:16,359 --> 00:43:22,680
demand for installation of third-party

00:43:19,839 --> 00:43:31,230
software there's a program called MW MW

00:43:22,680 --> 00:43:36,880
cam which will simulate a chemical

00:43:31,230 --> 00:43:42,059
molecule dine and dynamics and NW cam is

00:43:36,880 --> 00:43:45,579
a bear to build because it relies on

00:43:42,059 --> 00:43:46,690
libraries which are generations older

00:43:45,579 --> 00:43:49,750
than

00:43:46,690 --> 00:43:54,280
is installed on your system so you need

00:43:49,750 --> 00:43:56,170
you need a strategy it would be

00:43:54,280 --> 00:43:58,390
wonderful if you could just say to user

00:43:56,170 --> 00:44:02,530
as well we're only going to use stuff

00:43:58,390 --> 00:44:05,369
that's in the repository but that's not

00:44:02,530 --> 00:44:08,140
the real world we have to have a way to

00:44:05,369 --> 00:44:10,720
deal with third-party software

00:44:08,140 --> 00:44:14,890
administration now if you're on if

00:44:10,720 --> 00:44:16,630
you're on one system you'll do you'll do

00:44:14,890 --> 00:44:20,170
a tarball installation and you'll be

00:44:16,630 --> 00:44:22,000
finished but if you're on a system with

00:44:20,170 --> 00:44:23,740
hundreds or thousands of nodes you have

00:44:22,000 --> 00:44:26,680
to you have to really think carefully

00:44:23,740 --> 00:44:30,010
how am I going to do this so that all of

00:44:26,680 --> 00:44:35,170
my nodes are are in sync so there are

00:44:30,010 --> 00:44:37,869
some tools for that the rocks idea is to

00:44:35,170 --> 00:44:41,920
use rpms for everything so if you if you

00:44:37,869 --> 00:44:45,400
build a third party package you do it as

00:44:41,920 --> 00:44:50,829
an RPM rocks gives you some tools that

00:44:45,400 --> 00:44:53,230
make that pretty painless one of one of

00:44:50,829 --> 00:44:57,849
the things that I like to do is I'll

00:44:53,230 --> 00:45:00,819
make an RPM of the user local directory

00:44:57,849 --> 00:45:05,530
in its entirety and then i'll include

00:45:00,819 --> 00:45:09,310
that RPM in the kickstart package so now

00:45:05,530 --> 00:45:14,230
anything that i manually build into user

00:45:09,310 --> 00:45:16,480
local i'm assured that that that will be

00:45:14,230 --> 00:45:20,319
available on all nodes that's kind of a

00:45:16,480 --> 00:45:22,359
quick a quick solution to this that has

00:45:20,319 --> 00:45:25,030
worked out pretty well oak ridge

00:45:22,359 --> 00:45:26,950
national labs has done some good work on

00:45:25,030 --> 00:45:30,160
something that they call software tools

00:45:26,950 --> 00:45:34,890
or SW tools there's a later version of

00:45:30,160 --> 00:45:41,950
it called smithy it's on github end up

00:45:34,890 --> 00:45:45,660
SW tools is basically a build frame for

00:45:41,950 --> 00:45:50,040
a third party software so you can

00:45:45,660 --> 00:45:54,420
specify the rules for a for a build and

00:45:50,040 --> 00:45:56,950
then and then the build frame will

00:45:54,420 --> 00:45:58,990
accomplish that build for you so you can

00:45:56,950 --> 00:46:00,670
get it right once and then when you need

00:45:58,990 --> 00:46:02,619
to come back to it again neck

00:46:00,670 --> 00:46:05,109
year while you're adding in more

00:46:02,619 --> 00:46:07,900
software into the mix you don't have to

00:46:05,109 --> 00:46:09,549
go back and revisit it so that's a

00:46:07,900 --> 00:46:17,440
that's a strategy that has worked out

00:46:09,549 --> 00:46:19,839
well for them now then lastly um we we

00:46:17,440 --> 00:46:23,079
want to talk about how to keep an

00:46:19,839 --> 00:46:26,740
administration team staying on the same

00:46:23,079 --> 00:46:31,839
page so if you have a raspberry pi

00:46:26,740 --> 00:46:33,910
cluster with 44 our PI tues and you're

00:46:31,839 --> 00:46:35,740
doing the administration than this this

00:46:33,910 --> 00:46:38,140
task is easy because you're the only

00:46:35,740 --> 00:46:42,220
administrator and you have everything in

00:46:38,140 --> 00:46:44,920
your head but if you're in a campus

00:46:42,220 --> 00:46:47,589
computing environment or even worse if

00:46:44,920 --> 00:46:50,200
you're administering a system like the

00:46:47,589 --> 00:46:52,030
Titan then you need to be a little bit

00:46:50,200 --> 00:46:54,299
more organized because you've got a team

00:46:52,030 --> 00:46:57,460
of people who are involved in

00:46:54,299 --> 00:47:00,339
administering that system here here are

00:46:57,460 --> 00:47:03,280
a couple things that that I do that have

00:47:00,339 --> 00:47:06,099
really given a lot of leverage first of

00:47:03,280 --> 00:47:09,299
all if this is so simple you know we

00:47:06,099 --> 00:47:11,559
have a text file it's an admin journal

00:47:09,299 --> 00:47:15,369
file that we keep in the root directory

00:47:11,559 --> 00:47:19,660
so all admins have access to it we call

00:47:15,369 --> 00:47:24,250
it admin log and this is a it's a

00:47:19,660 --> 00:47:28,089
day-by-day chronology of hollow system

00:47:24,250 --> 00:47:30,790
is is evolving so if you're an admin on

00:47:28,089 --> 00:47:34,569
the system you make you make a change to

00:47:30,790 --> 00:47:36,849
some file or you install a piece of

00:47:34,569 --> 00:47:40,480
software then you make a note in here

00:47:36,849 --> 00:47:43,299
and all your fellow admins can see the

00:47:40,480 --> 00:47:47,650
note we also put in how to's if you've

00:47:43,299 --> 00:47:50,220
spent 15 minutes figuring out how to do

00:47:47,650 --> 00:47:54,910
something and you've worked out all the

00:47:50,220 --> 00:47:57,730
parameters to the the command lines to

00:47:54,910 --> 00:48:00,280
do something just drop a note in here

00:47:57,730 --> 00:48:04,240
tag it with how to's we can grep the

00:48:00,280 --> 00:48:06,710
admin log for how to and you can save

00:48:04,240 --> 00:48:09,830
your colleagues some time

00:48:06,710 --> 00:48:16,660
and the second one and this sometimes is

00:48:09,830 --> 00:48:21,619
helpful is to whoops okay there we go

00:48:16,660 --> 00:48:26,030
use a version control tool on your etsy

00:48:21,619 --> 00:48:31,430
directory so we use mercurial basically

00:48:26,030 --> 00:48:37,660
because it's so easy to setup CD to the

00:48:31,430 --> 00:48:40,910
etsy directory say hg in it to give it a

00:48:37,660 --> 00:48:43,849
version control and then make your

00:48:40,910 --> 00:48:47,630
initial commit hg i'm committing

00:48:43,849 --> 00:48:52,339
everything with a comment of this is my

00:48:47,630 --> 00:48:57,440
initial commit now every time we one of

00:48:52,339 --> 00:48:59,599
the administrators changes a file that's

00:48:57,440 --> 00:49:01,460
going to be logged in our version

00:48:59,599 --> 00:49:04,940
control so if i want to go back and i

00:49:01,460 --> 00:49:07,490
want to look at etsy FS tab and see the

00:49:04,940 --> 00:49:10,760
history of etsy ffs tab back to the

00:49:07,490 --> 00:49:16,339
beginning i can do that very easily then

00:49:10,760 --> 00:49:19,010
i can see who made what changes so um

00:49:16,339 --> 00:49:21,800
we're getting close to the conclusion

00:49:19,010 --> 00:49:26,780
and the conclusion is you know what's

00:49:21,800 --> 00:49:29,839
next where do we go from here the the

00:49:26,780 --> 00:49:34,369
next level is taking distributed systems

00:49:29,839 --> 00:49:38,960
into hybrid systems where we have nodes

00:49:34,369 --> 00:49:44,540
that are a combination of multi-core

00:49:38,960 --> 00:49:50,660
CPUs but also GPUs so the idea of using

00:49:44,540 --> 00:49:55,550
like an nvidia a graphics processor unit

00:49:50,660 --> 00:49:59,810
as a sub processor underneath the main

00:49:55,550 --> 00:50:03,589
node processors that's uh that's what is

00:49:59,810 --> 00:50:06,710
being leveraged on the next the next

00:50:03,589 --> 00:50:10,880
systems that are coming out titan

00:50:06,710 --> 00:50:15,460
already is using the concept then the

00:50:10,880 --> 00:50:18,730
new summit system that comes in 2017

00:50:15,460 --> 00:50:22,390
is using this concept and using it there

00:50:18,730 --> 00:50:26,940
they're only going to be using 3,400

00:50:22,390 --> 00:50:30,850
nodes so that the actual node count in

00:50:26,940 --> 00:50:32,920
in summit is going way down compared to

00:50:30,850 --> 00:50:35,680
where they were with with Titan and

00:50:32,920 --> 00:50:40,230
they're doing that with CPUs and

00:50:35,680 --> 00:50:42,760
attached GPUs in in each of those nodes

00:50:40,230 --> 00:50:46,300
that system will have a half of a

00:50:42,760 --> 00:50:50,370
terabyte of high bandwidth memory that

00:50:46,300 --> 00:50:55,300
is global and accessible to all nodes

00:50:50,370 --> 00:51:02,380
the disk capacity will be 120 petabytes

00:50:55,300 --> 00:51:05,100
and bandwidth into the storage will be

00:51:02,380 --> 00:51:08,790
is targeted at one terabyte per second

00:51:05,100 --> 00:51:14,950
the operating system is Linux it'll be

00:51:08,790 --> 00:51:19,660
the IBM Linux and a lot of the software

00:51:14,950 --> 00:51:23,530
is open source software and it's so

00:51:19,660 --> 00:51:27,490
interesting to me how linux does such a

00:51:23,530 --> 00:51:32,320
beautiful job of spanning from the most

00:51:27,490 --> 00:51:37,420
complex high-end systems down to the $35

00:51:32,320 --> 00:51:41,290
raspberry pi you can you can apt-get and

00:51:37,420 --> 00:51:43,690
open mpi into your Raspberry Pi if you

00:51:41,290 --> 00:51:46,980
want to use MPI Communications on your

00:51:43,690 --> 00:51:51,820
own home cluster and at the same time

00:51:46,980 --> 00:51:53,770
the the next generation fastest

00:51:51,820 --> 00:51:55,660
supercomputer in the world is going to

00:51:53,770 --> 00:52:00,180
be using the same open-source software

00:51:55,660 --> 00:52:03,630
to accomplish its MPI communications

00:52:00,180 --> 00:52:07,050
compilers will also be familiar to you

00:52:03,630 --> 00:52:10,650
GCC will be will be available and

00:52:07,050 --> 00:52:15,490
they've targeted 10 megawatts for the

00:52:10,650 --> 00:52:20,020
power consumption on that system so if

00:52:15,490 --> 00:52:23,590
you are currently working on a system

00:52:20,020 --> 00:52:27,940
like this then I'd like to talk with you

00:52:23,590 --> 00:52:29,340
afterwards and share best practices if

00:52:27,940 --> 00:52:32,350
you're not

00:52:29,340 --> 00:52:36,700
then maybe you could build one of these

00:52:32,350 --> 00:52:40,350
and get your feet wet with cluster

00:52:36,700 --> 00:52:43,180
computing using Linux operating system

00:52:40,350 --> 00:52:47,619
this this came from the Raspberry Pi

00:52:43,180 --> 00:52:50,680
organization their branch in Switzerland

00:52:47,619 --> 00:52:54,359
they put that little little mini cluster

00:52:50,680 --> 00:52:58,180
together with eight raspberry PI's and

00:52:54,359 --> 00:53:03,700
the slides that I showed are available

00:52:58,180 --> 00:53:05,619
online there's the URL for it and that's

00:53:03,700 --> 00:53:19,330
how to reach me if you have any email

00:53:05,619 --> 00:53:25,180
questions so open for questions yes yeah

00:53:19,330 --> 00:53:27,760
well um of course if a node goes down

00:53:25,180 --> 00:53:29,650
and a ok.let excuse me let me let me

00:53:27,760 --> 00:53:32,170
repeat the questions so that we can we

00:53:29,650 --> 00:53:33,790
can hear it across the auditorium what

00:53:32,170 --> 00:53:36,400
are the question is what were that what

00:53:33,790 --> 00:53:42,100
are the real-time consequences if we do

00:53:36,400 --> 00:53:45,160
have a node failure and a lot of that

00:53:42,100 --> 00:53:48,640
depends on how the the user has

00:53:45,160 --> 00:53:51,640
structured the software the applet the

00:53:48,640 --> 00:53:53,680
application software wants to take a big

00:53:51,640 --> 00:53:56,170
job and break it down into smaller

00:53:53,680 --> 00:53:58,690
pieces and send those pieces out and

00:53:56,170 --> 00:54:03,130
then collect results when it when it

00:53:58,690 --> 00:54:08,350
comes back if if the node if a node goes

00:54:03,130 --> 00:54:13,180
down while it's carrying out that if the

00:54:08,350 --> 00:54:17,890
application has the strategy to reissue

00:54:13,180 --> 00:54:23,230
that job packet to another node then

00:54:17,890 --> 00:54:25,570
nothing is lost and the job is is simply

00:54:23,230 --> 00:54:32,400
re executed on a different node and the

00:54:25,570 --> 00:54:32,400
results come back right

00:54:33,119 --> 00:54:38,130
we had another question over here yeah

00:54:43,349 --> 00:54:48,910
right right so the good good question

00:54:46,569 --> 00:54:51,549
what do we use for networking benchmarks

00:54:48,910 --> 00:54:55,960
there might be better networking

00:54:51,549 --> 00:55:04,200
benchmarks available what we do is DD

00:54:55,960 --> 00:55:04,200
from dev 0 to dev null over an ssh link

00:55:05,220 --> 00:55:17,890
cheap and dirty hyper look at that

00:55:14,920 --> 00:55:23,130
suggestion that hyper would be a good

00:55:17,890 --> 00:55:23,130
benchmark for network interconnect good

00:55:23,339 --> 00:55:30,299
other questions okay another question

00:55:35,339 --> 00:55:41,470
yeah ansible is actually the question

00:55:39,369 --> 00:55:45,279
was what do we what do we think about

00:55:41,470 --> 00:55:50,079
some of the new configuration tools like

00:55:45,279 --> 00:55:53,339
ansible ansible is by the way included

00:55:50,079 --> 00:55:55,839
in the rocks distribution so I know that

00:55:53,339 --> 00:55:58,239
they're using that out in out in

00:55:55,839 --> 00:56:00,130
California at there at the supercomputer

00:55:58,239 --> 00:56:01,809
center I personally don't have

00:56:00,130 --> 00:56:06,430
experience with it so I really can't

00:56:01,809 --> 00:56:08,499
comment but it may it may have some

00:56:06,430 --> 00:56:10,420
value and obviously does have some value

00:56:08,499 --> 00:56:16,859
if it was if it was included in the

00:56:10,420 --> 00:56:16,859
distribution okay question

00:56:33,230 --> 00:56:40,410
the question was do we you know we are

00:56:36,829 --> 00:56:44,369
we're interacting with users in somewhat

00:56:40,410 --> 00:56:48,990
of a support and consulting role and

00:56:44,369 --> 00:56:51,299
that is true but do we also do code code

00:56:48,990 --> 00:56:56,359
audits in order to keep people out of

00:56:51,299 --> 00:57:00,349
trouble was that the question yeah um

00:56:56,359 --> 00:57:03,960
and I think I think the best answer is

00:57:00,349 --> 00:57:06,180
no we really don't that's that's kind of

00:57:03,960 --> 00:57:13,170
outside of you have to you have to

00:57:06,180 --> 00:57:16,829
define your scope otherwise you may end

00:57:13,170 --> 00:57:18,780
up missing high priority items while

00:57:16,829 --> 00:57:22,380
you're working on lower priority items

00:57:18,780 --> 00:57:24,630
user communities I think are our

00:57:22,380 --> 00:57:28,349
thinking on user communities is that

00:57:24,630 --> 00:57:32,640
they like to help each other so our role

00:57:28,349 --> 00:57:35,400
is more along the line of providing them

00:57:32,640 --> 00:57:38,460
with tools where they can efficiently

00:57:35,400 --> 00:57:42,329
interact with each other and open an

00:57:38,460 --> 00:57:44,520
open wiki that anyone can edit you know

00:57:42,329 --> 00:57:46,650
would be a tool like that so somebody

00:57:44,520 --> 00:57:52,829
should be able to post a question and a

00:57:46,650 --> 00:58:08,220
dozen people could provide answers good

00:57:52,829 --> 00:58:10,500
question one more see SSH okay the

00:58:08,220 --> 00:58:13,710
question question was have we used see

00:58:10,500 --> 00:58:17,510
SSH for small clusters and I haven't

00:58:13,710 --> 00:58:17,510
could you can you educate us on that

00:58:21,200 --> 00:58:24,200
yeah

00:58:28,509 --> 00:58:33,650
it's a lot of fun if you have like four

00:58:30,920 --> 00:58:36,619
systems or eight systems if you type C

00:58:33,650 --> 00:58:38,420
SSH and then a list of host names or an

00:58:36,619 --> 00:58:40,759
alias which is a list of host names

00:58:38,420 --> 00:58:42,979
you'll get a terminal pop up for each

00:58:40,759 --> 00:58:45,109
server and then you get an extra

00:58:42,979 --> 00:58:46,959
terminal and anything you type in that

00:58:45,109 --> 00:58:50,539
extra terminal goes into all the terms

00:58:46,959 --> 00:58:53,449
and so I wouldn't do it for too many

00:58:50,539 --> 00:58:57,109
because you have you can type once but

00:58:53,449 --> 00:58:59,029
yeah look at each one yeah okay but

00:58:57,109 --> 00:59:04,219
first of all systems that might they

00:58:59,029 --> 00:59:07,249
might be interesting yeah there are

00:59:04,219 --> 00:59:11,150
there are other parallel tools there is

00:59:07,249 --> 00:59:14,719
a there's a parallel arcing and I'm a

00:59:11,150 --> 00:59:18,109
great fan of our sink and being able to

00:59:14,719 --> 00:59:19,849
do our synch in parallel to all of your

00:59:18,109 --> 00:59:30,410
systems at the same time i think is a

00:59:19,849 --> 00:59:33,140
great great feature yeah okay good so uh

00:59:30,410 --> 00:59:36,559
thank you all for coming good set of

00:59:33,140 --> 00:59:41,650
questions and I'll stay by behind here

00:59:36,559 --> 00:59:41,650
for a few minutes thank you

00:59:57,690 --> 00:59:59,750
you

01:00:02,870 --> 01:00:04,930
you

01:00:31,980 --> 01:00:34,040
you

01:03:18,330 --> 01:03:22,770
Citrix XenServer gives you everything

01:03:20,550 --> 01:03:25,740
you need to integrate manage and

01:03:22,770 --> 01:03:27,870
automate a virtual data center all on an

01:03:25,740 --> 01:03:30,270
enterprise-class cloud proven virtual

01:03:27,870 --> 01:03:32,910
platform and at a third of the cost of

01:03:30,270 --> 01:03:34,740
other solutions but why even bother with

01:03:32,910 --> 01:03:36,900
virtualizing your server infrastructure

01:03:34,740 --> 01:03:38,850
in the first place well let's say you

01:03:36,900 --> 01:03:41,190
have a traditional one server to one

01:03:38,850 --> 01:03:43,170
application architecture but you're

01:03:41,190 --> 01:03:45,720
running out of resources and performance

01:03:43,170 --> 01:03:48,050
is suffering once you order new server

01:03:45,720 --> 01:03:50,940
hardware you'll wait for delivery

01:03:48,050 --> 01:03:53,820
configure it install your business

01:03:50,940 --> 01:03:56,580
application stage and test the server

01:03:53,820 --> 01:03:58,770
and finally add it to your production

01:03:56,580 --> 01:04:00,960
farm if you've been through this process

01:03:58,770 --> 01:04:03,480
before you know it can take weeks or

01:04:00,960 --> 01:04:05,340
even months you also know it's a

01:04:03,480 --> 01:04:07,290
manually intensive process that will

01:04:05,340 --> 01:04:10,590
burden your team every time you outgrow

01:04:07,290 --> 01:04:12,390
your current setup with a virtual server

01:04:10,590 --> 01:04:15,180
solution you could accomplish all of

01:04:12,390 --> 01:04:17,760
that in less than half a day server

01:04:15,180 --> 01:04:19,560
virtualization software separates the OS

01:04:17,760 --> 01:04:21,990
and application from the underlying

01:04:19,560 --> 01:04:24,120
server hardware and with multiple

01:04:21,990 --> 01:04:25,860
virtual machines on a single server you

01:04:24,120 --> 01:04:28,830
can use each of them to run different

01:04:25,860 --> 01:04:30,600
os's and applications this makes it

01:04:28,830 --> 01:04:32,370
possible to move your virtual machines

01:04:30,600 --> 01:04:34,470
from one piece of hardware to another

01:04:32,370 --> 01:04:36,750
whenever you want to maximize

01:04:34,470 --> 01:04:38,700
utilization simplify maintenance or

01:04:36,750 --> 01:04:40,980
recover from a hardware failure and

01:04:38,700 --> 01:04:44,340
without slowing down your applications

01:04:40,980 --> 01:04:47,010
or users clearly server virtualization

01:04:44,340 --> 01:04:50,010
provides big benefits and Citrix

01:04:47,010 --> 01:04:52,320
XenServer provides even more since it's

01:04:50,010 --> 01:04:54,090
built on an open platform xenserver

01:04:52,320 --> 01:04:56,400
plays well with your existing hardware

01:04:54,090 --> 01:04:58,680
storage systems and IT management

01:04:56,400 --> 01:05:01,440
software as well as with the industry's

01:04:58,680 --> 01:05:03,450
leading cloud service providers best of

01:05:01,440 --> 01:05:05,160
all you can get started by downloading a

01:05:03,450 --> 01:05:08,400
fully functional production-ready

01:05:05,160 --> 01:05:10,620
version of xenserver for free after a

01:05:08,400 --> 01:05:12,750
10-minute installation process you'll

01:05:10,620 --> 01:05:14,760
see how easy it is to start virtualizing

01:05:12,750 --> 01:05:17,220
your workloads and automating your IT

01:05:14,760 --> 01:05:18,810
management processes and when you're

01:05:17,220 --> 01:05:20,730
ready for a richer set of management

01:05:18,810 --> 01:05:23,250
tools just upgrade to one of the premium

01:05:20,730 --> 01:05:25,080
editions of xenserver so whether you're

01:05:23,250 --> 01:05:27,030
interested in virtualizing servers for

01:05:25,080 --> 01:05:29,280
the first time expanding your server

01:05:27,030 --> 01:05:31,830
virtualization footprint or moving

01:05:29,280 --> 01:05:32,339
server workloads to the cloud download

01:05:31,830 --> 01:05:34,589
and install

01:05:32,339 --> 01:05:36,900
all xenserver today and see how it can

01:05:34,589 --> 01:05:40,829
help you simplify your IT environment

01:05:36,900 --> 01:05:43,069
citrix xenserver do more don't spend

01:05:40,829 --> 01:05:43,069
more

01:05:48,130 --> 01:05:52,430
your customers rely on your website or

01:05:50,900 --> 01:05:54,800
application if it's slower

01:05:52,430 --> 01:05:57,710
non-responsive it infuriates your users

01:05:54,800 --> 01:05:59,540
and costs you money keeping your

01:05:57,710 --> 01:06:03,050
business critical systems humming along

01:05:59,540 --> 01:06:05,870
requires insight into what they're doing

01:06:03,050 --> 01:06:07,880
your system metrics tell stories stories

01:06:05,870 --> 01:06:10,370
that can reveal performance bottlenecks

01:06:07,880 --> 01:06:12,410
resource limitations and other problems

01:06:10,370 --> 01:06:14,210
but how do you keep an eye on all of

01:06:12,410 --> 01:06:16,790
your systems performance metrics in

01:06:14,210 --> 01:06:19,670
real-time and record this data for later

01:06:16,790 --> 01:06:21,650
analysis enter longview the new way to

01:06:19,670 --> 01:06:23,660
see what's really going on under the

01:06:21,650 --> 01:06:25,790
hood the longview dashboard lets you

01:06:23,660 --> 01:06:27,800
visualize the status of all your systems

01:06:25,790 --> 01:06:30,530
providing you with a bird's-eye view of

01:06:27,800 --> 01:06:33,650
your entire fleet you can sort by cpu

01:06:30,530 --> 01:06:36,110
memory swap processes load and network

01:06:33,650 --> 01:06:38,690
usage click a specific system to access

01:06:36,110 --> 01:06:40,670
its individual dashboard then click and

01:06:38,690 --> 01:06:43,670
drag to zoom in on chokepoints and get

01:06:40,670 --> 01:06:45,650
more detail comprehensive network data

01:06:43,670 --> 01:06:48,380
including inbound and outbound traffic

01:06:45,650 --> 01:06:49,940
is available on the network tab and disk

01:06:48,380 --> 01:06:51,860
rights and free space on the disk

01:06:49,940 --> 01:06:54,680
stabbed while the process Explorer

01:06:51,860 --> 01:06:57,230
displays usage statistics for individual

01:06:54,680 --> 01:06:59,420
processes the system info tab shows

01:06:57,230 --> 01:07:01,640
listening services active connections

01:06:59,420 --> 01:07:03,800
and available updates adding long view

01:07:01,640 --> 01:07:05,480
to a system is easy just click the

01:07:03,800 --> 01:07:07,610
button copy the one line installation

01:07:05,480 --> 01:07:10,070
command then run the command on your

01:07:07,610 --> 01:07:11,780
linux system to complete the process the

01:07:10,070 --> 01:07:13,970
agent will begin collecting data and

01:07:11,780 --> 01:07:15,790
sending it to longview then the graphs

01:07:13,970 --> 01:07:18,370
start rolling

01:07:15,790 --> 01:07:20,740
use longview to gain visibility into

01:07:18,370 --> 01:07:24,480
your servers so when your website or app

01:07:20,740 --> 01:07:24,480
heats up it stays up

01:08:06,530 --> 01:08:08,590

YouTube URL: https://www.youtube.com/watch?v=tXAoOOqnxZM


