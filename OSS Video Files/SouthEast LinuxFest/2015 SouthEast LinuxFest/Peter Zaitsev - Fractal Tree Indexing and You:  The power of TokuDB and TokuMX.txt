Title: Peter Zaitsev - Fractal Tree Indexing and You:  The power of TokuDB and TokuMX
Publication date: 2017-01-25
Playlist: 2015 SouthEast LinuxFest
Description: 
	
Captions: 
	00:01:39,270 --> 00:01:49,060
okay okay thank you so that is

00:01:46,600 --> 00:01:52,409
essentially religion v3 is the Lydian

00:01:49,060 --> 00:01:56,619
data structure for majority of databases

00:01:52,409 --> 00:02:00,759
Oracle MySQL PostgreSQL live try to ease

00:01:56,619 --> 00:02:02,409
a whole they choose if you look

00:02:00,759 --> 00:02:07,509
at the VIII's they have a pretty good

00:02:02,409 --> 00:02:09,429
our point reads right so if you do the

00:02:07,509 --> 00:02:10,869
read of a single row right of single

00:02:09,429 --> 00:02:12,610
value froggy three it's pretty to

00:02:10,869 --> 00:02:14,590
optimal but they're also pretty

00:02:12,610 --> 00:02:18,519
expensive in right so I can we look into

00:02:14,590 --> 00:02:21,280
more details how that works now ever a

00:02:18,519 --> 00:02:23,819
quite common data structure is log

00:02:21,280 --> 00:02:28,810
structured mesh trees which have been

00:02:23,819 --> 00:02:31,410
invented in 1996 so that is a much newer

00:02:28,810 --> 00:02:35,200
data structure have been around for

00:02:31,410 --> 00:02:37,569
about 20 years now and there are also

00:02:35,200 --> 00:02:39,430
multiple implementations and variants

00:02:37,569 --> 00:02:44,500
exist right sometimes you have like two

00:02:39,430 --> 00:02:47,440
levels sometimes that you have no more

00:02:44,500 --> 00:02:50,470
than that and LS entries which is what

00:02:47,440 --> 00:02:54,480
is called a right up to my storage

00:02:50,470 --> 00:02:56,980
engine they can take right very very

00:02:54,480 --> 00:02:58,810
effectively pretty much independent on

00:02:56,980 --> 00:03:01,359
the amount of a data size which is

00:02:58,810 --> 00:03:05,170
stored in the ls empty but at the same

00:03:01,359 --> 00:03:07,329
time for point selects and for reads

00:03:05,170 --> 00:03:12,639
doing the ranges on all the data they

00:03:07,329 --> 00:03:14,889
can be are quite slow there is also

00:03:12,639 --> 00:03:17,109
another relatively popular data store

00:03:14,889 --> 00:03:20,049
which I will call a quelle no index

00:03:17,109 --> 00:03:24,040
right there people are using some sort

00:03:20,049 --> 00:03:26,799
of layout instead of actually building

00:03:24,040 --> 00:03:29,620
the index stored ratings some kind of

00:03:26,799 --> 00:03:31,569
chunks and then if you need to retrieve

00:03:29,620 --> 00:03:35,250
a date why don't we scan all those

00:03:31,569 --> 00:03:38,470
chunks probably in parallel right and

00:03:35,250 --> 00:03:40,810
get the data we need columnstore storage

00:03:38,470 --> 00:03:44,799
engine for example doing that very

00:03:40,810 --> 00:03:46,600
frequently right often also some one of

00:03:44,799 --> 00:03:48,970
partition is also been in use right

00:03:46,600 --> 00:03:50,259
leasing hey they're not only using data

00:03:48,970 --> 00:03:51,620
like colon store but they are

00:03:50,259 --> 00:03:54,290
partitioning data by

00:03:51,620 --> 00:03:56,690
a so maybe they can't find all the rows

00:03:54,290 --> 00:03:59,360
between to cloak and three o clock right

00:03:56,690 --> 00:04:01,970
through index effectivity but we can go

00:03:59,360 --> 00:04:03,680
and scan all the data for one day

00:04:01,970 --> 00:04:06,560
instead of everything to heaven a

00:04:03,680 --> 00:04:10,579
database right the approach for those

00:04:06,560 --> 00:04:13,129
data is typically it is for those family

00:04:10,579 --> 00:04:15,590
of a systems is typically they are quite

00:04:13,129 --> 00:04:19,400
good with about loads right think about

00:04:15,590 --> 00:04:22,610
Hadoop a vertical right but they may not

00:04:19,400 --> 00:04:25,010
be and they're also efficient for large

00:04:22,610 --> 00:04:28,400
reporting queries but not essentially

00:04:25,010 --> 00:04:33,740
for just seemed a little look up here

00:04:28,400 --> 00:04:37,460
and there now let's go in a little bit

00:04:33,740 --> 00:04:43,070
more look at what Harvey three indexes

00:04:37,460 --> 00:04:45,110
are look like and this kind of feels

00:04:43,070 --> 00:04:51,139
kind of sort of scientific notation

00:04:45,110 --> 00:04:53,720
right mmm you have a b-tree there we

00:04:51,139 --> 00:04:57,770
call those internal nodes which kind of

00:04:53,720 --> 00:05:01,849
lead us towards the data as pivots so

00:04:57,770 --> 00:05:05,599
what P word is essentially it tells us

00:05:01,849 --> 00:05:07,789
where to go and look up with data down

00:05:05,599 --> 00:05:10,430
below for example the P what may have a

00:05:07,789 --> 00:05:12,260
value 5 which says hey everything which

00:05:10,430 --> 00:05:14,120
is less than five should go here and

00:05:12,260 --> 00:05:16,789
everything which is more than five

00:05:14,120 --> 00:05:19,669
should go there right and then we also

00:05:16,789 --> 00:05:22,340
have a leaf nodes which would contain

00:05:19,669 --> 00:05:25,880
the actual data which is essentially

00:05:22,340 --> 00:05:29,210
sorted in in those nodes and if you have

00:05:25,880 --> 00:05:32,389
to make a lookup of the data in the in

00:05:29,210 --> 00:05:37,610
this given page we can well we can

00:05:32,389 --> 00:05:39,199
typically do are like a binary search

00:05:37,610 --> 00:05:43,210
but sometimes we have to scan the whole

00:05:39,199 --> 00:05:46,430
pages right so let's see what happens

00:05:43,210 --> 00:05:52,150
aviva BTW if you have a tree like this

00:05:46,430 --> 00:05:57,650
right and we are looking to insert our

00:05:52,150 --> 00:06:02,000
15 into that right so it will go down to

00:05:57,650 --> 00:06:03,910
the very bottom of a tree leaf nodes

00:06:02,000 --> 00:06:06,400
where data is stored and

00:06:03,910 --> 00:06:08,830
even the best case scenario assuming

00:06:06,400 --> 00:06:11,170
there is enough data on this page right

00:06:08,830 --> 00:06:14,440
we have to do a page split it will have

00:06:11,170 --> 00:06:23,140
to modify the data on that page make

00:06:14,440 --> 00:06:29,100
sense now if we do research well now we

00:06:23,140 --> 00:06:32,530
essentially no go to another descent now

00:06:29,100 --> 00:06:36,070
what is a problem in this case even our

00:06:32,530 --> 00:06:38,020
data is completely in memory everything

00:06:36,070 --> 00:06:39,640
is good right we just do an insert and

00:06:38,020 --> 00:06:42,580
they all going through its data

00:06:39,640 --> 00:06:46,660
structures and stored in them get a

00:06:42,580 --> 00:06:48,910
memory but in in a lot of cases when a

00:06:46,660 --> 00:06:52,090
data is large you cannot get the whole

00:06:48,910 --> 00:06:54,610
tree in memory what typically happens in

00:06:52,090 --> 00:06:59,050
this case is what typically there

00:06:54,610 --> 00:07:02,340
non-leaf pages of a tree are small

00:06:59,050 --> 00:07:06,310
enough so they fit in memory right and

00:07:02,340 --> 00:07:08,440
on your leaf pages only some of them

00:07:06,310 --> 00:07:11,140
often small portions will be in memory

00:07:08,440 --> 00:07:14,170
the rests have to be just on disk now to

00:07:11,140 --> 00:07:17,350
explain why the over top part can fit in

00:07:14,170 --> 00:07:19,750
memory well an amount of pointers here

00:07:17,350 --> 00:07:24,120
which will only draw kind of a couple

00:07:19,750 --> 00:07:27,580
here can be called fan out right and

00:07:24,120 --> 00:07:30,760
depend on the index I index length and

00:07:27,580 --> 00:07:34,240
the page size the fan out can be you

00:07:30,760 --> 00:07:36,490
know it can be different right but what

00:07:34,240 --> 00:07:39,690
fat final does it defines your a to

00:07:36,490 --> 00:07:42,669
between essentially top pages in Iran

00:07:39,690 --> 00:07:45,780
non-leaf pages and edit pages you think

00:07:42,669 --> 00:07:51,550
about for example y square and v3

00:07:45,780 --> 00:07:57,280
indexes in na tebe your page size is 16

00:07:51,550 --> 00:07:59,740
k right you would say now our in our

00:07:57,280 --> 00:08:02,050
value right plus the pointer like a

00:07:59,740 --> 00:08:05,110
primary key to give it consists about

00:08:02,050 --> 00:08:11,470
the 40 bytes then in this case we can

00:08:05,110 --> 00:08:14,260
fit how many 400 right values in that in

00:08:11,470 --> 00:08:16,270
its so there is going to be not two but

00:08:14,260 --> 00:08:17,449
four hundred pointers right and that

00:08:16,270 --> 00:08:21,050
means there is going to

00:08:17,449 --> 00:08:25,789
approximately 400 the little non-leaf

00:08:21,050 --> 00:08:30,409
pages as lief pages right and that means

00:08:25,789 --> 00:08:34,190
what it most likely everything you know

00:08:30,409 --> 00:08:36,409
for non-leaf pages will be in memory

00:08:34,190 --> 00:08:41,449
high probability right so that's why we

00:08:36,409 --> 00:08:45,230
only analyze obvious right but anyway so

00:08:41,449 --> 00:08:47,269
if you look at our case for data set is

00:08:45,230 --> 00:08:49,850
large ten times or more large even

00:08:47,269 --> 00:08:56,180
amount of memory when as i'm doing my

00:08:49,850 --> 00:09:00,519
rights for each each insult or I will

00:08:56,180 --> 00:09:03,139
have to do one physical I operation

00:09:00,519 --> 00:09:05,860
which is actually quite expensive right

00:09:03,139 --> 00:09:09,019
so that means if you are looking at a b3

00:09:05,860 --> 00:09:11,930
then open the iOS tour group storage

00:09:09,019 --> 00:09:15,560
performance can be very very important

00:09:11,930 --> 00:09:18,920
now in this case that is huge in a

00:09:15,560 --> 00:09:22,760
provision I ops at the AWS right if not

00:09:18,920 --> 00:09:25,399
provision iOS there is a difference like

00:09:22,760 --> 00:09:27,079
about the 6x right the same difference

00:09:25,399 --> 00:09:30,649
you can say hey if I'm using some high

00:09:27,079 --> 00:09:37,040
performance flash vs our kind of slow

00:09:30,649 --> 00:09:39,769
spinning disk the difference for the for

00:09:37,040 --> 00:09:42,980
verra the insertion can be quite quite

00:09:39,769 --> 00:09:45,139
significant so now let's talk about the

00:09:42,980 --> 00:09:47,260
fractal tease what is this data

00:09:45,139 --> 00:09:51,339
structure right how it works and how its

00:09:47,260 --> 00:09:55,389
same in different compared to be trees

00:09:51,339 --> 00:10:00,050
fractal cleats indexes was invented in

00:09:55,389 --> 00:10:02,839
2007 by some people from MIT Rogers and

00:10:00,050 --> 00:10:07,449
stony Brook's on university right so it

00:10:02,839 --> 00:10:12,410
was kind of a bunch of years of research

00:10:07,449 --> 00:10:15,829
in a way how can we optimize this old

00:10:12,410 --> 00:10:17,209
data structure of our be trees and what

00:10:15,829 --> 00:10:20,779
it was looking at a couple of things

00:10:17,209 --> 00:10:24,589
first as hub can be balanced which kind

00:10:20,779 --> 00:10:26,089
of between v3 and lsm approach to sort

00:10:24,589 --> 00:10:28,220
of both have a high-performance right

00:10:26,089 --> 00:10:30,470
speed and a decent rate speech right how

00:10:28,220 --> 00:10:33,890
can we do that

00:10:30,470 --> 00:10:36,530
an effing is what fractal trees are

00:10:33,890 --> 00:10:38,930
focused on using modern hardware and

00:10:36,530 --> 00:10:40,550
operating system effectively and what we

00:10:38,930 --> 00:10:43,520
have those days we typically have fair

00:10:40,550 --> 00:10:46,610
amount of memory we have for a lot of

00:10:43,520 --> 00:10:50,780
cpu cores right feature available to us

00:10:46,610 --> 00:10:56,200
and so on and so forth so if you look at

00:10:50,780 --> 00:10:59,870
the fractal tease they are rather

00:10:56,200 --> 00:11:02,660
similar to be trees from some extent so

00:10:59,870 --> 00:11:06,830
we will have a same kind of internal

00:11:02,660 --> 00:11:10,270
nodes right and lee nodes and you would

00:11:06,830 --> 00:11:15,880
have us pivots but what is different is

00:11:10,270 --> 00:11:18,740
what are the data modifications are not

00:11:15,880 --> 00:11:21,920
implemented applied to the data

00:11:18,740 --> 00:11:25,490
structure directly instead they are

00:11:21,920 --> 00:11:28,850
thought our other messages all right so

00:11:25,490 --> 00:11:30,590
I send send a message like hey I want to

00:11:28,850 --> 00:11:34,100
insert a row right all i want to update

00:11:30,590 --> 00:11:39,220
you and those messages are being stored

00:11:34,100 --> 00:11:42,410
on the in the buffers which apply to all

00:11:39,220 --> 00:11:49,190
internal nodes right and from that they

00:11:42,410 --> 00:11:55,820
kind of way cascade cascade down right

00:11:49,190 --> 00:11:58,520
so if a if a buffers are empty you can

00:11:55,820 --> 00:12:01,270
see it looks exactly the same as a b3

00:11:58,520 --> 00:12:08,300
and that is actually pretty good good

00:12:01,270 --> 00:12:11,090
because what that gives us is that means

00:12:08,300 --> 00:12:14,240
then fractal tree is sort of optimized

00:12:11,090 --> 00:12:17,390
if all the messages push down when a

00:12:14,240 --> 00:12:19,520
great performance can be achieved very

00:12:17,390 --> 00:12:24,290
similar to be three right we just go

00:12:19,520 --> 00:12:27,740
ahead and fetch one one block everything

00:12:24,290 --> 00:12:32,000
is a memory now what happens if you

00:12:27,740 --> 00:12:35,480
insert the value 15 well it just goes in

00:12:32,000 --> 00:12:38,540
the buffer of the root node right root

00:12:35,480 --> 00:12:42,830
node is in memory so we are not doing

00:12:38,540 --> 00:12:47,870
any i/o or whatsoever right in this case

00:12:42,830 --> 00:12:50,030
and that can take well a lot of time

00:12:47,870 --> 00:12:53,960
written this buffer feels it will spill

00:12:50,030 --> 00:12:56,870
out buffer belong chances I it's also in

00:12:53,960 --> 00:13:00,860
memory and essentially that means it

00:12:56,870 --> 00:13:03,860
will take maybe a hundred right or some

00:13:00,860 --> 00:13:06,230
sort of large number of updates go into

00:13:03,860 --> 00:13:09,760
the same kind of target page provide

00:13:06,230 --> 00:13:13,610
finally to be need to require that page

00:13:09,760 --> 00:13:16,790
have any changes being applied now what

00:13:13,610 --> 00:13:22,370
is interested in this case is this

00:13:16,790 --> 00:13:26,330
messages can go beyond simply update of

00:13:22,370 --> 00:13:28,460
the data right we can also use that to

00:13:26,330 --> 00:13:32,540
do some other messages right you can see

00:13:28,460 --> 00:13:38,030
inside elites but we can also push with

00:13:32,540 --> 00:13:40,400
changes of updates right saying hey I

00:13:38,030 --> 00:13:42,560
want to increment the value right or x

00:13:40,400 --> 00:13:45,440
that can be stored in the structure as a

00:13:42,560 --> 00:13:48,050
memory and apply it sometime later down

00:13:45,440 --> 00:13:51,590
the road or we can even do there are

00:13:48,050 --> 00:13:53,960
either table like a de colon push from

00:13:51,590 --> 00:13:57,050
message out here and it will kind of

00:13:53,960 --> 00:14:00,260
gradually propagate and restructure

00:13:57,050 --> 00:14:01,940
three down the road but the schema

00:14:00,260 --> 00:14:07,550
change you'll be essentially instant

00:14:01,940 --> 00:14:09,140
instant right so we're now if you are

00:14:07,550 --> 00:14:11,000
thinking hey that's the one who looks

00:14:09,140 --> 00:14:15,470
like a wonderful data structure so where

00:14:11,000 --> 00:14:17,960
do we get it what kind of software

00:14:15,470 --> 00:14:21,650
solutions really implement this data

00:14:17,960 --> 00:14:24,770
structures wait one is it the top ODB

00:14:21,650 --> 00:14:26,960
storage engine for my skew like a system

00:14:24,770 --> 00:14:31,790
which is mainly available in your corner

00:14:26,960 --> 00:14:35,420
server and n mariadb we also have taqwa

00:14:31,790 --> 00:14:39,500
MX which is one creepy compatible server

00:14:35,420 --> 00:14:42,500
right just kind of a complete solution

00:14:39,500 --> 00:14:45,980
then also tokyo MX s ii which is a

00:14:42,500 --> 00:14:49,640
MongoDB storage engine for one give you

00:14:45,980 --> 00:14:53,030
30 now if you are looking for something

00:14:49,640 --> 00:14:56,499
even more hardcore where is the library

00:14:53,030 --> 00:14:59,679
called like taco ft which is essentially

00:14:56,499 --> 00:15:04,689
crazy be compatible library which you

00:14:59,679 --> 00:15:10,599
can can use right to supercharge your BD

00:15:04,689 --> 00:15:11,799
be like applications so if you just look

00:15:10,599 --> 00:15:13,529
at the top would you be in my school

00:15:11,799 --> 00:15:17,009
because that is probably the most

00:15:13,529 --> 00:15:21,519
commonly huge implementation right or

00:15:17,009 --> 00:15:25,079
fractal trees those days it gives you

00:15:21,519 --> 00:15:29,349
transactions and the mvcc similar to

00:15:25,079 --> 00:15:31,089
energy v it gives you compression you

00:15:29,349 --> 00:15:33,969
can get typically much more powerful

00:15:31,089 --> 00:15:37,749
compression for lot lower overhead when

00:15:33,969 --> 00:15:40,539
its energy be it gives you hot schema

00:15:37,749 --> 00:15:43,089
changes with no table kind of cop in the

00:15:40,539 --> 00:15:48,069
quad right in it energy also loves you

00:15:43,089 --> 00:15:51,339
are online on a table in let's say MySQL

00:15:48,069 --> 00:15:53,649
56 but that requires scoping the table

00:15:51,339 --> 00:15:56,589
which is expensive and also means to

00:15:53,649 --> 00:15:58,809
have to have a double amount of disk

00:15:56,589 --> 00:16:01,720
essentially right to be able to perform

00:15:58,809 --> 00:16:04,949
at iteration we get the clustered

00:16:01,720 --> 00:16:07,109
secondary indexes read purification and

00:16:04,949 --> 00:16:14,079
efficiency right these are kind of

00:16:07,109 --> 00:16:17,970
comparison Oh for MTV and tohko DB I

00:16:14,079 --> 00:16:22,359
think what is important here is what

00:16:17,970 --> 00:16:24,999
taqwa DB is not for everything if you

00:16:22,359 --> 00:16:27,839
have all your data fits in memory right

00:16:24,999 --> 00:16:32,319
or majority of warlock load in memory

00:16:27,839 --> 00:16:35,859
then you should not be used in toco DB

00:16:32,319 --> 00:16:38,399
it will be slower if you are really

00:16:35,859 --> 00:16:42,099
having a very large data set and it's

00:16:38,399 --> 00:16:45,939
right intensive right or some logic

00:16:42,099 --> 00:16:50,679
queries are prevalent than our toca TV

00:16:45,939 --> 00:16:52,779
will often before much better now this

00:16:50,679 --> 00:16:56,379
is over talk about the algorithms right

00:16:52,779 --> 00:16:59,529
and kind of your ideas well we will know

00:16:56,379 --> 00:17:02,799
what it's possible to screw up any kind

00:16:59,529 --> 00:17:05,470
of decent algorithm plement a shin right

00:17:02,799 --> 00:17:08,730
so you need the good implementation as

00:17:05,470 --> 00:17:08,730
well as

00:17:11,209 --> 00:17:20,579
the great concepts first one is tobu TV

00:17:17,640 --> 00:17:25,380
has been around for a long time and we

00:17:20,579 --> 00:17:27,720
had done a pretty extensive QA we've

00:17:25,380 --> 00:17:30,179
talked with EB and the store and percona

00:17:27,720 --> 00:17:35,220
server and I would say from my

00:17:30,179 --> 00:17:37,409
standpoint that for the first not in the

00:17:35,220 --> 00:17:40,470
gb storage engine which actually was

00:17:37,409 --> 00:17:43,559
pretty pretty mature right because most

00:17:40,470 --> 00:17:45,120
are a changin to a kind of you can sort

00:17:43,559 --> 00:17:46,679
of can create table insert a couple of

00:17:45,120 --> 00:17:49,080
data but if you really put him into the

00:17:46,679 --> 00:17:51,510
stress they just fail and top woody was

00:17:49,080 --> 00:17:54,600
pretty robust so I would say that is the

00:17:51,510 --> 00:17:58,139
only other solar transaction storage

00:17:54,600 --> 00:18:01,019
engine be on in a gbx TV now in our

00:17:58,139 --> 00:18:02,580
frame is a real life is technology right

00:18:01,019 --> 00:18:05,539
and we worked as a partnership stock

00:18:02,580 --> 00:18:08,909
would you be at aqua tech team for a

00:18:05,539 --> 00:18:12,450
couple of years and then two months ago

00:18:08,909 --> 00:18:15,409
we apart aqua tech and novices are

00:18:12,450 --> 00:18:15,409
talkative

00:18:21,100 --> 00:18:23,160

YouTube URL: https://www.youtube.com/watch?v=uLFfs_yMEz4


