Title: Robert Beaty - From Servers to Serverless
Publication date: 2019-06-18
Playlist: 2019 SouthEast LinuxFest
Description: 
	SouthEast Linux Fest 2019
This is our journey from a traditional server based infrastructure to serverless. As a small company with an even smaller DevOps team supporting 200+ mobile apps with hundreds of thousands of users, we needed a better way to scale and support highly variable workloads. We will look at how we are solving this problem using a host of serverless and managed services, including Lambda, S3, Cloudfront, DynamoDB, API Gateway, SNS, React and more. Specific examples of the Serverless Framework and AWS SAM templates are included.
Captions: 
	00:00:00,000 --> 00:00:06,799
safety police sheriff emergency

00:00:03,210 --> 00:00:10,980
management we also do some Public Safety

00:00:06,799 --> 00:00:13,559
utilities other stuff it's not terribly

00:00:10,980 --> 00:00:14,849
pertinent other than why the problem has

00:00:13,559 --> 00:00:17,190
come up that we're trying to move to a

00:00:14,849 --> 00:00:22,230
server less system from a traditional

00:00:17,190 --> 00:00:24,689
setup so a little more details so we

00:00:22,230 --> 00:00:28,680
currently have I don't know the exact

00:00:24,689 --> 00:00:31,140
number over 200 so I'd be you know four

00:00:28,680 --> 00:00:35,250
hundred plus whatever counting iOS and

00:00:31,140 --> 00:00:39,450
Android apps sales people tell me we're

00:00:35,250 --> 00:00:41,250
in 43 states and canada and pulled it up

00:00:39,450 --> 00:00:43,050
last week just out of curiosity because

00:00:41,250 --> 00:00:44,520
i know it was getting pretty high active

00:00:43,050 --> 00:00:46,739
sessions per week so but a little over

00:00:44,520 --> 00:00:51,030
two million right now for kind of across

00:00:46,739 --> 00:00:53,070
our whole grouping so what we're seeing

00:00:51,030 --> 00:00:57,120
is a huge spike in demand for our

00:00:53,070 --> 00:00:58,890
infrastructure and there's one over guy

00:00:57,120 --> 00:01:01,739
over there that's with me and another

00:00:58,890 --> 00:01:03,719
one who couldn't make it this week then

00:01:01,739 --> 00:01:05,280
so all it's up to the three of us to

00:01:03,719 --> 00:01:08,610
handle it all so it's a little bit

00:01:05,280 --> 00:01:13,320
outpacing our capabilities to keep up

00:01:08,610 --> 00:01:17,909
with a traditional infrastructure so

00:01:13,320 --> 00:01:20,340
this is kind of look at our current

00:01:17,909 --> 00:01:22,439
lambda executions which is only a small

00:01:20,340 --> 00:01:24,500
fraction of what we actually have moved

00:01:22,439 --> 00:01:27,900
over most of it's still on our

00:01:24,500 --> 00:01:31,670
traditional stack so you know we're

00:01:27,900 --> 00:01:35,460
hidden spikes right now in the 4,000

00:01:31,670 --> 00:01:37,439
concurrency getting up higher the

00:01:35,460 --> 00:01:39,180
biggest problem with our particular

00:01:37,439 --> 00:01:41,689
activity is when people send push

00:01:39,180 --> 00:01:45,149
notifications huge spikes of

00:01:41,689 --> 00:01:48,810
instantaneous data connections coming in

00:01:45,149 --> 00:01:52,979
and then it just dies so you can kind of

00:01:48,810 --> 00:01:55,470
see the spike enos of our load well part

00:01:52,979 --> 00:01:57,270
of our problem is looking at sort of a

00:01:55,470 --> 00:01:59,159
traditional approach to that would be o

00:01:57,270 --> 00:02:03,299
auto-scaling well auto-scaling is too

00:01:59,159 --> 00:02:04,530
slow for that our spikes are over in 20

00:02:03,299 --> 00:02:07,259
30 seconds tops

00:02:04,530 --> 00:02:10,619
well hey now we have our new load so

00:02:07,259 --> 00:02:12,680
it's not terribly helpful and we can't

00:02:10,619 --> 00:02:14,180
really afford to just

00:02:12,680 --> 00:02:16,840
the infrastructure sitting there to

00:02:14,180 --> 00:02:24,379
handle those spikes and then be idle for

00:02:16,840 --> 00:02:26,659
hours and hours on end so before getting

00:02:24,379 --> 00:02:28,849
into the service part just wanted to

00:02:26,659 --> 00:02:31,670
talk about we did originally think hey

00:02:28,849 --> 00:02:33,230
we'll move to containers and that you

00:02:31,670 --> 00:02:37,459
know a container cluster hopefully that

00:02:33,230 --> 00:02:40,010
will help spins up a lot faster problem

00:02:37,459 --> 00:02:43,189
we kind of decided against doing that

00:02:40,010 --> 00:02:45,500
was still small team we've got to manage

00:02:43,189 --> 00:02:47,750
the containers now we're not really

00:02:45,500 --> 00:02:50,440
getting away from our problem of

00:02:47,750 --> 00:02:52,879
man-hours trying to keep all this going

00:02:50,440 --> 00:02:54,650
the container cluster itself can auto

00:02:52,879 --> 00:02:59,299
scale but again it's pretty slow to get

00:02:54,650 --> 00:03:01,250
moving so the original thought of doing

00:02:59,299 --> 00:03:04,540
that kind of well maybe that's not going

00:03:01,250 --> 00:03:07,730
to work for us and that was kind of when

00:03:04,540 --> 00:03:09,920
Amazon was starting to push their server

00:03:07,730 --> 00:03:14,209
less application model real heavily so

00:03:09,920 --> 00:03:16,010
we started looking at that so that is

00:03:14,209 --> 00:03:17,449
the solution that we've come up with and

00:03:16,010 --> 00:03:19,519
these are kind of a lot of the

00:03:17,449 --> 00:03:22,489
technologies that our specific data yeah

00:03:19,519 --> 00:03:24,440
AWS which we use but I know Google cloud

00:03:22,489 --> 00:03:28,010
computing measure have competing

00:03:24,440 --> 00:03:31,129
versions of most of this it's probably

00:03:28,010 --> 00:03:34,250
possible to go take the general stack to

00:03:31,129 --> 00:03:37,220
wherever you're interested in being so

00:03:34,250 --> 00:03:39,980
then really the major ones API gateway

00:03:37,220 --> 00:03:42,319
and lambda so you can run code without

00:03:39,980 --> 00:03:46,040
servers they'll you know when it's on

00:03:42,319 --> 00:03:47,989
concurrency DynamoDB is nice scaling dbb

00:03:46,040 --> 00:03:50,510
obviously there's a lot of options there

00:03:47,989 --> 00:03:55,010
our previous one was on was

00:03:50,510 --> 00:03:57,470
handled by Atlas works great and you can

00:03:55,010 --> 00:04:02,419
use RDS or any of those managed database

00:03:57,470 --> 00:04:04,669
systems web wise we went with react

00:04:02,419 --> 00:04:06,440
because it is very easy to turn that

00:04:04,669 --> 00:04:08,989
into a flat file system that you can

00:04:06,440 --> 00:04:10,879
host on s3 is a website so again trying

00:04:08,989 --> 00:04:13,459
to keep everything as scalable as

00:04:10,879 --> 00:04:17,780
possible with cloud front worldwide

00:04:13,459 --> 00:04:19,849
endpoints and then the actual you know

00:04:17,780 --> 00:04:23,450
the infrastructure it's code part we're

00:04:19,849 --> 00:04:24,150
using cloud formation Sam templates same

00:04:23,450 --> 00:04:26,280
thing

00:04:24,150 --> 00:04:27,930
just an extension on it and we're also

00:04:26,280 --> 00:04:31,520
looking and using a little bit of

00:04:27,930 --> 00:04:34,139
serverless framework which is

00:04:31,520 --> 00:04:36,720
interesting and that you can blend the

00:04:34,139 --> 00:04:38,669
clouds with those configurations if

00:04:36,720 --> 00:04:42,570
you're interested in trying to diversify

00:04:38,669 --> 00:04:45,720
your cloud so this is sort of a really

00:04:42,570 --> 00:04:48,120
basic look that infrastructure in action

00:04:45,720 --> 00:04:51,780
this this piece right here is our

00:04:48,120 --> 00:04:53,820
traditional web stack simplified of

00:04:51,780 --> 00:04:56,310
course it's a lot more horizontal than

00:04:53,820 --> 00:04:59,039
that but you know it's a load balancer

00:04:56,310 --> 00:05:02,820
web server load balancer processing file

00:04:59,039 --> 00:05:05,160
system database just as plain and simple

00:05:02,820 --> 00:05:07,289
as you can get where now we're looking

00:05:05,160 --> 00:05:10,080
at this where you know we've got some

00:05:07,289 --> 00:05:12,479
Kinesis streams coming in to help gather

00:05:10,080 --> 00:05:14,130
batch information lambdas really the

00:05:12,479 --> 00:05:15,930
workhorse center of everything and then

00:05:14,130 --> 00:05:21,300
all the auxilary services there from

00:05:15,930 --> 00:05:24,690
that list providing file storage object

00:05:21,300 --> 00:05:29,490
storage really Redis caching speed

00:05:24,690 --> 00:05:31,590
things along we use SNS for a lot of our

00:05:29,490 --> 00:05:34,110
push notifications are all SNS base for

00:05:31,590 --> 00:05:37,169
our Apps SES descent auto you know

00:05:34,110 --> 00:05:45,889
emails to all of our our clients

00:05:37,169 --> 00:05:45,889
specifically not their end users yeah

00:05:51,800 --> 00:05:58,380
so right now no but part of us wanting

00:05:56,400 --> 00:06:00,450
to go to this is we do have some clients

00:05:58,380 --> 00:06:02,130
that are kind of government based and

00:06:00,450 --> 00:06:05,640
want to say hey we want it in our gut

00:06:02,130 --> 00:06:08,460
cloud so having this all is code we

00:06:05,640 --> 00:06:10,950
could just say yeah go give us an

00:06:08,460 --> 00:06:12,930
account with the access we need and ban

00:06:10,950 --> 00:06:15,480
will have this whole thing set up for

00:06:12,930 --> 00:06:18,240
you just for your app a lot of people

00:06:15,480 --> 00:06:20,250
want that for their accounting most of

00:06:18,240 --> 00:06:21,510
our clients don't care those they just

00:06:20,250 --> 00:06:26,190
end up in our infrastructure and it's

00:06:21,510 --> 00:06:29,010
fine so just a little bit of how we've

00:06:26,190 --> 00:06:30,990
seen we're not super far along in our

00:06:29,010 --> 00:06:32,940
process yet we're just getting started

00:06:30,990 --> 00:06:36,990
so this is kind of what we've felt like

00:06:32,940 --> 00:06:40,440
some pros and cons so the serverless

00:06:36,990 --> 00:06:43,170
framework from my experience thus far

00:06:40,440 --> 00:06:45,150
seems pretty good on a complex project

00:06:43,170 --> 00:06:47,970
they have a lot of nice syntactic sugar

00:06:45,150 --> 00:06:49,770
to help you organize your project a

00:06:47,970 --> 00:06:53,640
little bit nicer than cloud formation

00:06:49,770 --> 00:06:56,430
does multiple cloud providers if that's

00:06:53,640 --> 00:07:02,570
you know you want to spread that surface

00:06:56,430 --> 00:07:04,800
risk out and that makes that super easy

00:07:02,570 --> 00:07:08,010
pretty standard you can deploy it

00:07:04,800 --> 00:07:09,960
yourself you can put it in a pipeline if

00:07:08,010 --> 00:07:11,970
you've never seen seed run that's their

00:07:09,960 --> 00:07:13,919
own product that does their pipelines

00:07:11,970 --> 00:07:16,260
for service deployments it's pretty

00:07:13,919 --> 00:07:18,390
slick we don't use it at work I use it

00:07:16,260 --> 00:07:21,030
personally and it does a great job it's

00:07:18,390 --> 00:07:23,520
free personally use so hard to complain

00:07:21,030 --> 00:07:25,980
and they have some pretty great

00:07:23,520 --> 00:07:29,970
documentation tutorials get you rolling

00:07:25,980 --> 00:07:33,660
on it from a downside it does abstract a

00:07:29,970 --> 00:07:34,950
lot so there could be some problems for

00:07:33,660 --> 00:07:36,300
you there I was stretching a little bit

00:07:34,950 --> 00:07:39,780
there's not a lot of downsides that I

00:07:36,300 --> 00:07:43,440
found so far and it's probably overkill

00:07:39,780 --> 00:07:46,230
for smaller projects we do a lot of our

00:07:43,440 --> 00:07:48,060
work is ingesting data from our clients

00:07:46,230 --> 00:07:50,340
and trying to put it more in a format

00:07:48,060 --> 00:07:52,380
that our apps are used to displaying so

00:07:50,340 --> 00:07:54,479
we have a lot of little things that are

00:07:52,380 --> 00:07:57,150
just processing data and doing a full

00:07:54,479 --> 00:07:58,190
service projects pretty overkill so most

00:07:57,150 --> 00:08:01,970
of those for us or just

00:07:58,190 --> 00:08:04,190
to be a cloud formation so like I said

00:08:01,970 --> 00:08:06,850
it does have some limitations cloud

00:08:04,190 --> 00:08:11,720
formation / Sam on complex projects

00:08:06,850 --> 00:08:14,090
typically without service application

00:08:11,720 --> 00:08:16,820
model it's literally just an extension

00:08:14,090 --> 00:08:18,350
of cloud formation that adds some of the

00:08:16,820 --> 00:08:20,600
server less stuff into it to make it a

00:08:18,350 --> 00:08:24,800
little bit easier so you can just think

00:08:20,600 --> 00:08:26,780
almost the same thing the limitations

00:08:24,800 --> 00:08:29,210
there is traditionally without this

00:08:26,780 --> 00:08:31,190
thing called CFN include a cloud

00:08:29,210 --> 00:08:33,880
formation template has to be one file so

00:08:31,190 --> 00:08:36,349
those things can get big in a hurry

00:08:33,880 --> 00:08:39,979
defining out all of your I am I am

00:08:36,349 --> 00:08:42,080
policies and everything else so that is

00:08:39,979 --> 00:08:47,780
a definite downside to just stray cloud

00:08:42,080 --> 00:08:50,480
formation in specific AWS if that's your

00:08:47,780 --> 00:08:53,150
cloud then it works great

00:08:50,480 --> 00:08:55,280
deployment via AWS CLI or pipelines you

00:08:53,150 --> 00:08:57,020
can you know put that into a code

00:08:55,280 --> 00:08:59,390
pipeline with code commit and it works

00:08:57,020 --> 00:09:02,690
great we are doing that on several of

00:08:59,390 --> 00:09:07,730
ours now so the downside I already

00:09:02,690 --> 00:09:12,950
talked about with the simplicity of one

00:09:07,730 --> 00:09:14,240
file so documentation I have found to be

00:09:12,950 --> 00:09:17,000
a little bit more difficult on cloud

00:09:14,240 --> 00:09:19,810
formation as well then serverless not a

00:09:17,000 --> 00:09:19,810
lot but a little bit

00:09:24,669 --> 00:09:29,089
this is and I'm just going to talk a

00:09:26,989 --> 00:09:32,329
little bit about why we're doing it this

00:09:29,089 --> 00:09:34,639
way with this particular one so all of

00:09:32,329 --> 00:09:37,099
our Florida sheriff's which we have

00:09:34,639 --> 00:09:39,199
quite a few want their sex offenders

00:09:37,099 --> 00:09:40,729
listed in that an app and a map it's

00:09:39,199 --> 00:09:42,879
pretty cool well you can see your PIN

00:09:40,729 --> 00:09:45,109
and kind of you know see if there's a

00:09:42,879 --> 00:09:50,169
reason for you to be worried in your

00:09:45,109 --> 00:09:55,699
area but the way the Florida law

00:09:50,169 --> 00:09:57,529
department provides that is a CSV file

00:09:55,699 --> 00:10:00,409
for each County and you can only pull

00:09:57,529 --> 00:10:02,439
one per five minutes which is kind of

00:10:00,409 --> 00:10:04,909
tedious I don't know why they do that

00:10:02,439 --> 00:10:07,489
personally I think that's crazy but

00:10:04,909 --> 00:10:09,739
that's the way they do it so well we

00:10:07,489 --> 00:10:13,069
have to do is have a whole slew of these

00:10:09,739 --> 00:10:14,149
suckers running every so often so that

00:10:13,069 --> 00:10:17,569
we can pull them down and get them

00:10:14,149 --> 00:10:19,159
updated for each day building this in a

00:10:17,569 --> 00:10:21,529
single CloudFormation template it would

00:10:19,159 --> 00:10:22,789
be pretty terrible it would be huge and

00:10:21,529 --> 00:10:24,469
adding a new ones kind of a cluster

00:10:22,789 --> 00:10:27,139
trying to figure out where to put it so

00:10:24,469 --> 00:10:29,149
what we did was we used the CFN include

00:10:27,139 --> 00:10:32,629
mentioned earlier it's the library you

00:10:29,149 --> 00:10:35,199
can use for free and what that does is

00:10:32,629 --> 00:10:38,239
just give you those include statements

00:10:35,199 --> 00:10:39,709
so you can organize your product and so

00:10:38,239 --> 00:10:41,779
we have these in functions there's an

00:10:39,709 --> 00:10:44,209
example function so next time somebody

00:10:41,779 --> 00:10:47,479
has to add one copy-paste make the

00:10:44,209 --> 00:10:50,569
appropriate adjustments and that just

00:10:47,479 --> 00:10:52,849
kind of looks like this so this is a

00:10:50,569 --> 00:10:56,929
standard Landa function defined in cloud

00:10:52,849 --> 00:10:59,479
formation you provided your handler you

00:10:56,929 --> 00:11:01,279
get a role which so you can see the get

00:10:59,479 --> 00:11:03,979
attribute this is a role we defined in

00:11:01,279 --> 00:11:06,439
another file here so you don't have to

00:11:03,979 --> 00:11:08,989
actually put the names of those you can

00:11:06,439 --> 00:11:10,489
just say hey based on this role name

00:11:08,989 --> 00:11:13,639
that I already defined in my cloud

00:11:10,489 --> 00:11:16,309
formation fetch that AR end and stick it

00:11:13,639 --> 00:11:18,889
in here for me you know your runtime

00:11:16,309 --> 00:11:20,989
memory timeouts out of publish because

00:11:18,889 --> 00:11:24,249
we want to do that and running on a

00:11:20,989 --> 00:11:26,299
schedule and then this is our kind of

00:11:24,249 --> 00:11:27,499
environment variable stuff that we have

00:11:26,299 --> 00:11:31,459
to change for the next one and the next

00:11:27,499 --> 00:11:34,599
one in excellent so the benefit for us

00:11:31,459 --> 00:11:36,310
here is hey we got a new county

00:11:34,599 --> 00:11:38,620
copy/paste

00:11:36,310 --> 00:11:40,330
run to deploy commands it's up and

00:11:38,620 --> 00:11:48,400
running we don't even have to concern

00:11:40,330 --> 00:11:49,900
ourselves with yeah yeah so so each

00:11:48,400 --> 00:11:52,360
County gets one of these little blocks

00:11:49,900 --> 00:11:53,650
as a separate yeah mph aisle and then

00:11:52,360 --> 00:11:56,560
you just put in and that include

00:11:53,650 --> 00:11:59,860
statement set in the first the basis we

00:11:56,560 --> 00:12:02,589
would call it and then you run see if

00:11:59,860 --> 00:12:04,990
any included on base it knows all those

00:12:02,589 --> 00:12:06,370
and sucks them all in and just in the

00:12:04,990 --> 00:12:08,290
background that's producing that one

00:12:06,370 --> 00:12:11,200
monolithic file for you so you're not

00:12:08,290 --> 00:12:13,630
having to manage it so if you are going

00:12:11,200 --> 00:12:15,370
to use these that is a great way to

00:12:13,630 --> 00:12:19,320
organize your project a little bit

00:12:15,370 --> 00:12:22,810
better and not have quite so much

00:12:19,320 --> 00:12:29,290
gigantic searching because it can get

00:12:22,810 --> 00:12:34,060
pretty tedious so we're gonna jump off

00:12:29,290 --> 00:12:40,300
to the server lists one is a little bit

00:12:34,060 --> 00:12:46,089
too big just pop up in a slide I felt

00:12:40,300 --> 00:12:50,230
like so and this is absolutely just

00:12:46,089 --> 00:12:52,510
their tutorial if you go to I got the

00:12:50,230 --> 00:12:55,660
pull it back up server last AG dot

00:12:52,510 --> 00:12:57,640
server list - stack comm they have a

00:12:55,660 --> 00:13:01,150
great tutorial on setting up a

00:12:57,640 --> 00:13:02,730
note-taking app of course but it goes

00:13:01,150 --> 00:13:04,300
through the process of building an API

00:13:02,730 --> 00:13:06,670
independently the front-end

00:13:04,300 --> 00:13:10,990
independently and really you can learn a

00:13:06,670 --> 00:13:13,720
ton about all of this setup from doing

00:13:10,990 --> 00:13:16,270
that and this is basically the server

00:13:13,720 --> 00:13:20,770
let's the mo file for the API that you

00:13:16,270 --> 00:13:22,630
end up with at the end of it so similar

00:13:20,770 --> 00:13:24,820
but obviously a little bit different you

00:13:22,630 --> 00:13:27,550
get some really nice little things like

00:13:24,820 --> 00:13:30,390
if you want to do staging so a dev and

00:13:27,550 --> 00:13:32,770
prod herbalist makes that really simple

00:13:30,390 --> 00:13:34,930
you can just put in some of these stage

00:13:32,770 --> 00:13:38,760
variables and when you deploy you to

00:13:34,930 --> 00:13:46,360
find a stage it shoots it out there and

00:13:38,760 --> 00:13:48,610
when you're defining your actual so the

00:13:46,360 --> 00:13:49,810
functions you'll notice they don't get

00:13:48,610 --> 00:13:51,460
named

00:13:49,810 --> 00:13:54,220
your tables don't get named everything

00:13:51,460 --> 00:13:55,600
is automatically named let's it's you

00:13:54,220 --> 00:13:58,300
know just a random string that is

00:13:55,600 --> 00:14:00,370
appended and then servile it's much like

00:13:58,300 --> 00:14:02,980
in cloud formation will allow you to

00:14:00,370 --> 00:14:05,740
just pop those in there so when you're

00:14:02,980 --> 00:14:08,560
doing your your naming you can put in

00:14:05,740 --> 00:14:10,600
this is for whatever it will append that

00:14:08,560 --> 00:14:13,960
and then your dev and your prod stages

00:14:10,600 --> 00:14:17,800
won't clobber each other so that that's

00:14:13,960 --> 00:14:20,980
pretty important there but it's pretty

00:14:17,800 --> 00:14:22,840
easy to read here you can see this one

00:14:20,980 --> 00:14:24,850
saying this one's on AWS you can have

00:14:22,840 --> 00:14:26,620
multi providers so you can find it all

00:14:24,850 --> 00:14:31,060
up is one giant application if you'd

00:14:26,620 --> 00:14:34,660
like you can set the environment

00:14:31,060 --> 00:14:36,040
variables define a role so here it's

00:14:34,660 --> 00:14:38,380
just saying it's going to have access to

00:14:36,040 --> 00:14:42,520
the Dynamo table that we are building up

00:14:38,380 --> 00:14:46,840
and here's just you know your standard

00:14:42,520 --> 00:14:51,340
kind of functions to do a note-taking

00:14:46,840 --> 00:14:53,230
app and then much like doing CF and

00:14:51,340 --> 00:14:55,770
include this has a little bit cleaner

00:14:53,230 --> 00:14:58,150
syntax of including extra files where

00:14:55,770 --> 00:15:01,089
hey I'm gonna include my table as a

00:14:58,150 --> 00:15:04,690
separate file in my s3 bucket Cognito

00:15:01,089 --> 00:15:06,370
user pool you can do all of this and

00:15:04,690 --> 00:15:09,550
cloud formation as well it's just a

00:15:06,370 --> 00:15:12,310
little bit less clean so this is where

00:15:09,550 --> 00:15:14,620
I'd say for a large project serverless

00:15:12,310 --> 00:15:20,370
for us has provided a little bit more

00:15:14,620 --> 00:15:20,370
value and being easier to handle

00:15:29,259 --> 00:15:36,559
yeah so there you go so serverless -

00:15:31,639 --> 00:15:38,420
stack calm and like I said earlier few

00:15:36,559 --> 00:15:39,949
slides back seed diaper on it's kind of

00:15:38,420 --> 00:15:42,079
their product based on that from a

00:15:39,949 --> 00:15:43,759
pipeline perspective it's super easy to

00:15:42,079 --> 00:15:45,769
put it in any pipeline you want though

00:15:43,759 --> 00:15:50,170
because you just install the server list

00:15:45,769 --> 00:15:50,170
CLI tool and go to town on it

00:15:56,930 --> 00:16:01,550
well I was a little bit faster than I

00:15:58,699 --> 00:16:09,529
didn't expected it to be so yeah any

00:16:01,550 --> 00:16:12,170
questions we were already fully on AWS

00:16:09,529 --> 00:16:13,610
before we even got started on this so it

00:16:12,170 --> 00:16:25,279
was just natural to us where were you

00:16:13,610 --> 00:16:27,110
gonna go no we have not I would give

00:16:25,279 --> 00:16:37,819
that a whirl though yeah absolutely

00:16:27,110 --> 00:16:40,670
you had so a client sending a push

00:16:37,819 --> 00:16:43,369
notification so when it lands there's

00:16:40,670 --> 00:16:45,949
calls back to let you know the analytic

00:16:43,369 --> 00:16:48,529
calls back when they actually tap on it

00:16:45,949 --> 00:16:51,920
it pulls a history of notifications and

00:16:48,529 --> 00:16:53,929
other parts of the app and so somebody

00:16:51,920 --> 00:16:56,179
says yeah I gotta send one out right now

00:16:53,929 --> 00:16:59,649
BAM it lands we see this huge spike and

00:16:56,179 --> 00:16:59,649
then it trails off very quickly

00:17:14,549 --> 00:17:17,549
yeah

00:17:20,579 --> 00:17:26,530
yeah yeah so we did it terribly when we

00:17:24,789 --> 00:17:28,449
first set it up as far as like a B PC

00:17:26,530 --> 00:17:31,780
concern and setting up our users and

00:17:28,449 --> 00:17:34,110
everything and had to come back and just

00:17:31,780 --> 00:17:37,360
completely gut it and try again yeah

00:17:34,110 --> 00:17:39,309
there are a lot of great tools now that

00:17:37,360 --> 00:17:41,230
will help you on that as far as like oh

00:17:39,309 --> 00:17:44,020
this is a great template for a standard

00:17:41,230 --> 00:17:45,130
V PC I'm trying to remember the name of

00:17:44,020 --> 00:17:50,110
L at the top of my head but they

00:17:45,130 --> 00:17:55,330
literally have a hmm yeah and they

00:17:50,110 --> 00:17:57,280
actually have a tool now that will do

00:17:55,330 --> 00:17:58,690
some validations against your set up and

00:17:57,280 --> 00:18:02,650
tell you if you're kind of under best

00:17:58,690 --> 00:18:08,020
practices I don't remember if it's yeah

00:18:02,650 --> 00:18:09,580
yeah just deploy deploy them so I would

00:18:08,020 --> 00:18:12,100
recommend looking at that tool that's

00:18:09,580 --> 00:18:14,500
from Amazon directly so when you kind of

00:18:12,100 --> 00:18:15,940
set it up you can set it up on what you

00:18:14,500 --> 00:18:17,470
think is the best practices based on

00:18:15,940 --> 00:18:19,030
stuff or deploy it and then you can

00:18:17,470 --> 00:18:23,260
actually run that and say oh yeah it

00:18:19,030 --> 00:18:26,860
fits or maybe this is out of spec to

00:18:23,260 --> 00:18:29,620
answer your portion we haven't had any

00:18:26,860 --> 00:18:32,679
issues with Amazon thus far it's working

00:18:29,620 --> 00:18:36,070
great we did actually it was kind of

00:18:32,679 --> 00:18:38,559
it's been a while now but we hit their

00:18:36,070 --> 00:18:39,760
limit on mobile analytics I think it was

00:18:38,559 --> 00:18:41,850
like a hundred and twenty apps or

00:18:39,760 --> 00:18:44,289
something and we couldn't add any more

00:18:41,850 --> 00:18:45,460
so we let them know because they didn't

00:18:44,289 --> 00:18:47,140
actually have a way to increase that

00:18:45,460 --> 00:18:49,330
quota no it's about a two-week

00:18:47,140 --> 00:18:58,000
turnaround I think and they had it built

00:18:49,330 --> 00:18:59,799
in where you can now do it they do one

00:18:58,000 --> 00:19:01,960
if you are looking at the server so I'll

00:18:59,799 --> 00:19:04,690
go ahead and tell you the base lambda

00:19:01,960 --> 00:19:06,460
limit is a thousand concurrency you can

00:19:04,690 --> 00:19:08,700
increase that but they will ask you to

00:19:06,460 --> 00:19:11,830
justify it because they have to preload

00:19:08,700 --> 00:19:15,640
resources into the region to make sure

00:19:11,830 --> 00:19:17,260
they have your load capacity so you know

00:19:15,640 --> 00:19:19,230
they'll ask you to go to your land where

00:19:17,260 --> 00:19:22,030
you can see that you're getting

00:19:19,230 --> 00:19:23,830
throttled because of your limit and you

00:19:22,030 --> 00:19:25,840
can show that and what you're expecting

00:19:23,830 --> 00:19:29,340
and I mean that's all we had to do and

00:19:25,840 --> 00:19:29,340
they were happy to bump it so

00:19:40,229 --> 00:19:45,159
yeah it's just people looking at it most

00:19:42,879 --> 00:19:47,739
of the time honestly our biggest

00:19:45,159 --> 00:19:49,139
features are who's in jail the Most

00:19:47,739 --> 00:19:51,970
Wanted and who got arrested

00:19:49,139 --> 00:19:56,349
that's what people apparently want to

00:19:51,970 --> 00:19:57,970
look at so that that's pretty it you

00:19:56,349 --> 00:20:03,580
know it varies a lot and you know widely

00:19:57,970 --> 00:20:05,259
throughout the day so yeah well and it's

00:20:03,580 --> 00:20:07,119
just no there's not a lot of demand at a

00:20:05,259 --> 00:20:08,649
given time there would be I think it's

00:20:07,119 --> 00:20:10,840
like a high profile person was gonna

00:20:08,649 --> 00:20:12,190
show up yeah so that's our biggest

00:20:10,840 --> 00:20:15,519
problem as most of our demand it's a

00:20:12,190 --> 00:20:17,590
highly unpredictable so beyond some

00:20:15,519 --> 00:20:21,479
major machine learning we we're not

00:20:17,590 --> 00:20:21,479
gonna do a good job of that I think

00:21:02,140 --> 00:21:10,120
uh yeah sure so you know in our current

00:21:06,790 --> 00:21:12,429
one if you are poor number 10,000 and

00:21:10,120 --> 00:21:14,500
one you get shoved in the queue and a

00:21:12,429 --> 00:21:17,320
ton of people come in right behind you

00:21:14,500 --> 00:21:18,790
and you're all on the queue and you know

00:21:17,320 --> 00:21:21,880
it might be four or five seconds before

00:21:18,790 --> 00:21:24,940
that kind of clears itself on a big in

00:21:21,880 --> 00:21:27,010
the worst case scenario a couple of our

00:21:24,940 --> 00:21:29,590
apps all send one simultaneously and

00:21:27,010 --> 00:21:31,000
there's you know 30,000 40,000 and

00:21:29,590 --> 00:21:33,730
coming in and they all get backlogged

00:21:31,000 --> 00:21:36,070
well you know right now we have our

00:21:33,730 --> 00:21:37,390
concurrency set at 10,000 I expect I'm

00:21:36,070 --> 00:21:39,970
gonna have to have that come up as we

00:21:37,390 --> 00:21:42,669
start migrating apps really fully onto

00:21:39,970 --> 00:21:46,030
this system and we'll ideally have 40 or

00:21:42,669 --> 00:21:47,799
50,000 as a concurrency so that there

00:21:46,030 --> 00:21:50,110
won't be any weight on those folks and

00:21:47,799 --> 00:21:52,299
that's kind of the best part about the

00:21:50,110 --> 00:21:53,620
way they're setting up LAN does hey if

00:21:52,299 --> 00:21:56,590
you can justify the need for that

00:21:53,620 --> 00:22:00,460
they're gonna give it to you and then so

00:21:56,590 --> 00:22:02,650
we won't have wait ideally of course if

00:22:00,460 --> 00:22:06,160
you're using any of their libraries to

00:22:02,650 --> 00:22:08,860
handle API gateway work actual SDKs

00:22:06,160 --> 00:22:11,799
which shotty a little bit on the mobile

00:22:08,860 --> 00:22:13,809
side I'll tell you amplify is fantastic

00:22:11,799 --> 00:22:15,580
though we've had a ton of luck with that

00:22:13,809 --> 00:22:18,179
and it will handle a lot of the retry

00:22:15,580 --> 00:22:22,350
mechanics so you may have some folks who

00:22:18,179 --> 00:22:28,059
just get bumped one retry cycle but

00:22:22,350 --> 00:22:29,770
ideally I think most of our push history

00:22:28,059 --> 00:22:31,900
lambdas running at about two or three

00:22:29,770 --> 00:22:34,929
hundred milliseconds as a response time

00:22:31,900 --> 00:22:41,200
and it's gonna I feel like gonna be

00:22:34,929 --> 00:22:43,630
great at serving that need well if

00:22:41,200 --> 00:22:45,760
you're the lucky first group it's pretty

00:22:43,630 --> 00:22:50,500
much the same if you're not then you're

00:22:45,760 --> 00:22:53,020
gonna be four or five seconds out yeah

00:22:50,500 --> 00:22:54,460
yeah and a lot of that's making sure you

00:22:53,020 --> 00:22:56,890
scale your Landers resources

00:22:54,460 --> 00:22:58,690
appropriately obviously if you just give

00:22:56,890 --> 00:23:00,549
it the base it might work

00:22:58,690 --> 00:23:03,880
am I not so a lot of that we've found

00:23:00,549 --> 00:23:06,100
trial and error because they do only

00:23:03,880 --> 00:23:08,620
allow you to change memory on lambda the

00:23:06,100 --> 00:23:09,600
CPU scales kind of in the background in

00:23:08,620 --> 00:23:14,340
a way that

00:23:09,600 --> 00:23:15,960
I'll tell you so you can run it you know

00:23:14,340 --> 00:23:18,270
we run your tests against it and kind of

00:23:15,960 --> 00:23:21,600
see oh my sweet spot is a gig or

00:23:18,270 --> 00:23:24,990
whatever because I think when we first

00:23:21,600 --> 00:23:27,630
did it we tried five twelve we were

00:23:24,990 --> 00:23:29,190
seeing six 700 milliseconds like okay

00:23:27,630 --> 00:23:30,720
we'll bump it up one and then BAM it was

00:23:29,190 --> 00:23:32,010
right back where we were expecting so we

00:23:30,720 --> 00:23:39,650
were a little CPU throttled on that

00:23:32,010 --> 00:23:39,650
lower one yeah

00:23:46,270 --> 00:23:51,970
yes that can be difficult the

00:23:50,290 --> 00:23:54,190
concurrency limit is kind of your

00:23:51,970 --> 00:23:57,640
biggest hey we're willing to you know

00:23:54,190 --> 00:24:02,590
handle this the biggest thing that we

00:23:57,640 --> 00:24:04,420
found anyway on Amazon is I think maybe

00:24:02,590 --> 00:24:06,100
now you could actually probably get AWS

00:24:04,420 --> 00:24:08,559
billing to do these but at the time it

00:24:06,100 --> 00:24:11,620
was pretty nitpicky to get it set up so

00:24:08,559 --> 00:24:15,000
we use cloud checker and just we have

00:24:11,620 --> 00:24:17,920
limits where we get deemed anytime we're

00:24:15,000 --> 00:24:19,780
surpassing some normal expectations of

00:24:17,920 --> 00:24:24,160
utilization so we can go in there and

00:24:19,780 --> 00:24:27,910
okay so you can do that too on API

00:24:24,160 --> 00:24:29,830
gateway so on a per app basis our setup

00:24:27,910 --> 00:24:31,900
is going to have a rate limit per app oh

00:24:29,830 --> 00:24:34,059
well you know the customer to up that if

00:24:31,900 --> 00:24:36,280
they feel so inclined to keep backups

00:24:34,059 --> 00:24:38,590
from happening yeah at least a little

00:24:36,280 --> 00:24:40,330
bit you know it's one of those or if

00:24:38,590 --> 00:24:42,160
people are using it's so much and

00:24:40,330 --> 00:24:43,900
they're really enjoying the utilization

00:24:42,160 --> 00:24:47,380
we'll figure out what we got to do but

00:24:43,900 --> 00:24:49,480
we keep an eye on the actual spending we

00:24:47,380 --> 00:24:51,670
do have the rate limits set both on

00:24:49,480 --> 00:24:55,470
lambda itself an individual app level on

00:24:51,670 --> 00:24:55,470
API gateway yeah

00:25:01,110 --> 00:25:06,910
so a lot of that is servantless

00:25:04,720 --> 00:25:08,980
framework helps there because you could

00:25:06,910 --> 00:25:12,130
easily just swap that over to say Google

00:25:08,980 --> 00:25:13,270
compute they've got their I don't

00:25:12,130 --> 00:25:14,770
remember what they call their functions

00:25:13,270 --> 00:25:18,400
product but they have the exact same

00:25:14,770 --> 00:25:20,410
thing so does a sure yeah so they all

00:25:18,400 --> 00:25:22,960
kind of have most of those same products

00:25:20,410 --> 00:25:24,340
there's a little bit of a it's gonna be

00:25:22,960 --> 00:25:25,780
a pain in the butt because we're using

00:25:24,340 --> 00:25:35,770
dynamo now and we got to get that out

00:25:25,780 --> 00:25:39,400
and move it but yes I'm trying to

00:25:35,770 --> 00:25:43,090
remember yeah there's there's a couple

00:25:39,400 --> 00:25:47,340
of them that have a similar concept to

00:25:43,090 --> 00:25:47,340
the you know the snippet of code running

00:25:53,400 --> 00:25:56,760
yeah yeah

00:26:03,629 --> 00:26:11,169
yes yeah it is and it's a little it's a

00:26:09,700 --> 00:26:12,639
little bit of a black box but not

00:26:11,169 --> 00:26:14,590
completely

00:26:12,639 --> 00:26:15,820
so they fire up sort of how many are

00:26:14,590 --> 00:26:17,559
containers they feel like they need to

00:26:15,820 --> 00:26:20,409
handle your load and we'll keep doing so

00:26:17,559 --> 00:26:23,649
they fire it really fast but there is

00:26:20,409 --> 00:26:27,009
the concept of a cold start so if you

00:26:23,649 --> 00:26:29,169
don't have something utilizing a lambda

00:26:27,009 --> 00:26:31,870
for I think it's ten minutes give or

00:26:29,169 --> 00:26:36,220
take it'll be two or three seconds to

00:26:31,870 --> 00:26:38,769
fire up there are some products to help

00:26:36,220 --> 00:26:41,019
you out there that are will quote warm

00:26:38,769 --> 00:26:46,149
your lambdas continuously so that

00:26:41,019 --> 00:26:48,159
there's always one ready to go we we

00:26:46,149 --> 00:26:50,529
figured just based on our utilization

00:26:48,159 --> 00:26:52,119
from looking at our current system we

00:26:50,529 --> 00:26:54,639
probably won't have that problem because

00:26:52,119 --> 00:26:56,470
most of our routes are being hit pretty

00:26:54,639 --> 00:26:59,470
routinely even if it's not a high volume

00:26:56,470 --> 00:27:03,779
but I've I've definitely looked at that

00:26:59,470 --> 00:27:03,779
there's something we need to do

00:27:11,410 --> 00:27:16,210
yeah well that was kind of what i harped

00:27:14,140 --> 00:27:18,850
on we're having to manage that now and

00:27:16,210 --> 00:27:27,400
it's just trying not to manage more

00:27:18,850 --> 00:27:28,830
machines more containers well yeah

00:27:27,400 --> 00:27:32,760
that's our biggest problem is we have

00:27:28,830 --> 00:27:32,760
less people time

00:28:00,499 --> 00:28:03,980
yeah absolutely

00:28:20,110 --> 00:28:23,860
easy two instances

00:28:32,160 --> 00:28:39,030
it should be cheaper based on just our

00:28:35,730 --> 00:28:41,610
initial we I don't remember I think it's

00:28:39,030 --> 00:28:43,410
called cloud craft maybe it allows you

00:28:41,610 --> 00:28:45,480
to make those nice little diagrams but

00:28:43,410 --> 00:28:47,670
one of the more interesting tools is if

00:28:45,480 --> 00:28:50,010
you make the diagram it will sum up the

00:28:47,670 --> 00:28:52,410
cost based on you can put in parameters

00:28:50,010 --> 00:28:54,860
of the utilization which is pretty handy

00:28:52,410 --> 00:28:54,860
so

00:56:13,400 --> 00:56:17,090

YouTube URL: https://www.youtube.com/watch?v=y6-kPpg6PW8


