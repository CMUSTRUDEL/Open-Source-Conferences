Title: Jon Akers - General High Performance Computing (HPC)
Publication date: 2019-06-19
Playlist: 2019 SouthEast LinuxFest
Description: 
	SouthEast Linux Fest
A general overview of high performance computing, ranging from base operating system construction, hardware requirements and setup, middle-ware utilization, and application use and development.
Captions: 
	00:00:00,000 --> 00:00:08,810
Texas and play with their stuff I've

00:00:04,859 --> 00:00:08,810
seen their stuff it's pretty incredible

00:00:08,840 --> 00:00:12,540
it has to save goals of this

00:00:10,679 --> 00:00:17,039
presentation is general overview of what

00:00:12,540 --> 00:00:20,490
HPC actually is and realistically what

00:00:17,039 --> 00:00:22,619
it is is taking a cluster such as what

00:00:20,490 --> 00:00:26,369
you've seen out here upfront but

00:00:22,619 --> 00:00:32,219
expanding it to massive sizes we're

00:00:26,369 --> 00:00:35,430
talking large rooms larger than this the

00:00:32,219 --> 00:00:37,380
cluster that I have deals with it fits

00:00:35,430 --> 00:00:40,670
this room and then we've got this room

00:00:37,380 --> 00:00:43,950
again for expansion at the moment

00:00:40,670 --> 00:00:46,940
hardware requirements for such a cluster

00:00:43,950 --> 00:00:50,010
and I'm going to go into detail about

00:00:46,940 --> 00:00:52,469
not just the physical Hardware for the

00:00:50,010 --> 00:00:53,250
computer but also what kind of power do

00:00:52,469 --> 00:00:55,140
you need for that

00:00:53,250 --> 00:00:56,460
what kind of cooling do you need for

00:00:55,140 --> 00:00:59,100
that what kind of you know

00:00:56,460 --> 00:01:02,180
infrastructure support base are you

00:00:59,100 --> 00:01:05,460
going to need for that it gets pretty

00:01:02,180 --> 00:01:08,970
in-depth and there's a lot of equipment

00:01:05,460 --> 00:01:12,060
you need which obviously adds to the

00:01:08,970 --> 00:01:16,320
cost software requirements for the

00:01:12,060 --> 00:01:18,750
cluster keeping it going as you expand

00:01:16,320 --> 00:01:23,400
and I deal with general performance

00:01:18,750 --> 00:01:27,299
computing we we have to deal with a lot

00:01:23,400 --> 00:01:29,790
of different customers we have

00:01:27,299 --> 00:01:32,759
applications all over the board because

00:01:29,790 --> 00:01:37,170
we support the entire university so

00:01:32,759 --> 00:01:41,509
buyout community mathematics actually

00:01:37,170 --> 00:01:46,110
not very much from computer science but

00:01:41,509 --> 00:01:48,869
astronomy physics chemistry all of these

00:01:46,110 --> 00:01:51,030
groups come in and run software on our

00:01:48,869 --> 00:01:54,030
equipment and we have to be able to

00:01:51,030 --> 00:01:58,049
support all of that which means huge

00:01:54,030 --> 00:02:01,530
codebase lots of infrastructure support

00:01:58,049 --> 00:02:03,750
lots of software support I totally don't

00:02:01,530 --> 00:02:07,610
do a lot of the software support but I

00:02:03,750 --> 00:02:07,610
can I can dance the tune

00:02:10,690 --> 00:02:15,260
what the reed users they have a lot of

00:02:13,550 --> 00:02:17,180
different software he and you could talk

00:02:15,260 --> 00:02:22,250
about any code base you can be running

00:02:17,180 --> 00:02:23,840
in Python Perl I have seen MATLAB tons

00:02:22,250 --> 00:02:28,010
and tons and tons of our code

00:02:23,840 --> 00:02:30,530
particularly from the bio community C

00:02:28,010 --> 00:02:33,440
C++ lots of Fortran from the older

00:02:30,530 --> 00:02:35,960
people from chemistry physics those guys

00:02:33,440 --> 00:02:39,850
yeah for I see some smiling faces there

00:02:35,960 --> 00:02:42,620
for Fortran we see a ton of it and

00:02:39,850 --> 00:02:44,510
there's actually reasons for having code

00:02:42,620 --> 00:02:47,210
bases like that for Fortran and C in

00:02:44,510 --> 00:02:51,170
particular and they have the strongest

00:02:47,210 --> 00:02:53,600
support for massively parallel programs

00:02:51,170 --> 00:02:56,330
so they're not running programs that are

00:02:53,600 --> 00:03:01,880
you know eight cores you know threaded

00:02:56,330 --> 00:03:03,610
they're running 30,000 cores across six

00:03:01,880 --> 00:03:06,530
three four five six hundred machines

00:03:03,610 --> 00:03:07,760
running MPI base and high speed

00:03:06,530 --> 00:03:14,840
interconnects between each of those

00:03:07,760 --> 00:03:18,470
machines so what is HPC I wrote some

00:03:14,840 --> 00:03:20,600
things up this is a fun one I looked up

00:03:18,470 --> 00:03:23,900
hey what actually defines a

00:03:20,600 --> 00:03:25,700
supercomputer and the most recent

00:03:23,900 --> 00:03:30,410
definition I could find was data from

00:03:25,700 --> 00:03:33,920
the 2007 and it was what is that 10 to

00:03:30,410 --> 00:03:39,560
the 10th floating points calculations

00:03:33,920 --> 00:03:43,370
per second you can do that now with a 4

00:03:39,560 --> 00:03:46,850
with basically just four machines for

00:03:43,370 --> 00:03:50,570
Intel machines you can do that that's

00:03:46,850 --> 00:03:52,940
how fast it's gone so when it comes to

00:03:50,570 --> 00:03:54,760
supercomputing and HP see they're

00:03:52,940 --> 00:03:59,900
actually still following Moore's law

00:03:54,760 --> 00:04:01,610
when it comes to computing as I said

00:03:59,900 --> 00:04:04,880
most common users are scientific

00:04:01,610 --> 00:04:06,880
researchers but I also know of certain

00:04:04,880 --> 00:04:10,370
computers in the financial institutions

00:04:06,880 --> 00:04:13,940
they do a lot of stuff there oil and gas

00:04:10,370 --> 00:04:15,090
is another big one computational

00:04:13,940 --> 00:04:19,739
research

00:04:15,090 --> 00:04:22,620
fluid dynamics whether weathers a big

00:04:19,739 --> 00:04:26,310
one these days it's all over the place

00:04:22,620 --> 00:04:30,840
and it can be done you just need a lot

00:04:26,310 --> 00:04:32,220
of infrastructure in support for it's

00:04:30,840 --> 00:04:35,310
just through this graph up together

00:04:32,220 --> 00:04:37,590
this is actually off of the top 500 list

00:04:35,310 --> 00:04:39,960
I threw some numbers together of the

00:04:37,590 --> 00:04:43,350
number one computer off the top 500 list

00:04:39,960 --> 00:04:46,350
for the last 15-20 years and you can see

00:04:43,350 --> 00:04:50,460
it's following Moore's law that is a

00:04:46,350 --> 00:04:54,510
logarithmic scale on the Left logarithm

00:04:50,460 --> 00:04:57,930
base 10 all the way up and it's kind of

00:04:54,510 --> 00:04:59,970
pretty much linear it is absolutely

00:04:57,930 --> 00:05:10,380
incredible the growth and it just hasn't

00:04:59,970 --> 00:05:12,240
stopped barriers system complexity you

00:05:10,380 --> 00:05:15,720
think that these little Raspberry Pi

00:05:12,240 --> 00:05:19,050
machines out here are complex when it

00:05:15,720 --> 00:05:22,320
comes to setup went until you have 500

00:05:19,050 --> 00:05:24,810
machines each with dual 10 gig

00:05:22,320 --> 00:05:27,990
connections plus 40 gig

00:05:24,810 --> 00:05:31,470
InfiniBand connections plus Gigabit

00:05:27,990 --> 00:05:38,130
Ethernet for management we use Gigabit

00:05:31,470 --> 00:05:44,000
Ethernet for management at actually it's

00:05:38,130 --> 00:05:47,580
56 its EDR HDR has run into some issues

00:05:44,000 --> 00:05:50,010
we will see some HDR stuff probably in

00:05:47,580 --> 00:05:51,750
the next six months to a year once tak

00:05:50,010 --> 00:05:54,750
has figured out how to make it work

00:05:51,750 --> 00:05:57,780
they've got TAC actually has Mellanox

00:05:54,750 --> 00:06:03,780
engineers on site right now working on

00:05:57,780 --> 00:06:05,490
Frontera to make it work so that's we're

00:06:03,780 --> 00:06:07,350
keeping in close contact with that to

00:06:05,490 --> 00:06:12,810
make sure ok have you think it's did

00:06:07,350 --> 00:06:18,840
have you fixed it ok now we can buy cost

00:06:12,810 --> 00:06:20,639
to maintain the last cluster that I had

00:06:18,840 --> 00:06:23,310
to deal with in perching purchasing we

00:06:20,639 --> 00:06:24,540
got a good deal we spent 7 million on

00:06:23,310 --> 00:06:27,240
about 11 million

00:06:24,540 --> 00:06:31,800
worth of equipment that got us 30,000

00:06:27,240 --> 00:06:36,630
cores with InfiniBand infrastructure at

00:06:31,800 --> 00:06:40,230
FDR speeds it's 56 gave it it's a look

00:06:36,630 --> 00:06:41,760
this is a costly venture so you have to

00:06:40,230 --> 00:06:47,460
have something that you're going to run

00:06:41,760 --> 00:06:49,440
it for and make it worthwhile and it's

00:06:47,460 --> 00:06:52,500
not just the computer hardware that's

00:06:49,440 --> 00:06:55,950
the costly part I would say that

00:06:52,500 --> 00:06:58,890
computer hardware was maybe 40% of the

00:06:55,950 --> 00:07:00,660
actual total cost initially and as this

00:06:58,890 --> 00:07:03,800
is just initial purchase we're not even

00:07:00,660 --> 00:07:09,390
talking all the power costs afterwards

00:07:03,800 --> 00:07:10,440
so you've got all that hardware now you

00:07:09,390 --> 00:07:13,380
have to power it somehow

00:07:10,440 --> 00:07:16,710
which means PDUs brainian power from the

00:07:13,380 --> 00:07:18,540
power company you have to have

00:07:16,710 --> 00:07:20,520
networking to your host

00:07:18,540 --> 00:07:27,140
we're running we're currently running

00:07:20,520 --> 00:07:29,340
dual 100 gigabit to to our cluster and

00:07:27,140 --> 00:07:31,320
we were fortunate we could we got that

00:07:29,340 --> 00:07:33,570
about six or seven years ago but it's a

00:07:31,320 --> 00:07:37,640
getting time to upgrade that and we'll

00:07:33,570 --> 00:07:37,640
probably go into dual 200 gigabit soon

00:07:38,510 --> 00:07:48,560
cooling power just the floor plates full

00:07:44,250 --> 00:07:48,560
force base for it it's all costly

00:07:49,250 --> 00:07:56,880
expertise there are very few people that

00:07:52,710 --> 00:07:58,920
work at this level of HPC work we need

00:07:56,880 --> 00:08:02,100
people please

00:07:58,920 --> 00:08:08,670
you know bone up and we'll hire you we

00:08:02,100 --> 00:08:11,970
need the people what I've done thought

00:08:08,670 --> 00:08:14,730
job searches for new people I get one

00:08:11,970 --> 00:08:16,830
person out of 50 that is even remotely

00:08:14,730 --> 00:08:20,460
qualified and we're gonna have to train

00:08:16,830 --> 00:08:21,990
them they're not teaching it in schools

00:08:20,460 --> 00:08:26,610
it's something that you just sort of

00:08:21,990 --> 00:08:28,590
have to love and work from there

00:08:26,610 --> 00:08:31,910
software licensing it's actually a small

00:08:28,590 --> 00:08:35,640
portion but we do run into it

00:08:31,910 --> 00:08:37,680
MATLAB site licenses when excite

00:08:35,640 --> 00:08:40,649
licenses we're actually running Red Hat

00:08:37,680 --> 00:08:43,819
proper because the university paid for a

00:08:40,649 --> 00:08:46,649
site license so we're like we'll use it

00:08:43,819 --> 00:08:49,680
so yeah we're running about two or three

00:08:46,649 --> 00:08:52,199
thousand licenses of Red Hat from just

00:08:49,680 --> 00:08:54,329
off the site license MATLAB we're using

00:08:52,199 --> 00:08:58,230
site license for a bunch of other things

00:08:54,329 --> 00:09:00,360
so licensing becomes a big deal at that

00:08:58,230 --> 00:09:02,819
scale you know a single license okay

00:09:00,360 --> 00:09:04,860
I've spent my $300 and I'm good to go

00:09:02,819 --> 00:09:09,509
not when you've got fifteen hundred

00:09:04,860 --> 00:09:11,309
machines other soft software licenses

00:09:09,509 --> 00:09:14,119
that we run into is for things like

00:09:11,309 --> 00:09:14,119
storage systems

00:09:16,850 --> 00:09:23,129
let's see storage systems mostly storage

00:09:19,949 --> 00:09:25,829
systems actually oh and scheduling

00:09:23,129 --> 00:09:27,449
systems some schedulers I've seen costs

00:09:25,829 --> 00:09:31,319
into the hundred thousand dollars a year

00:09:27,449 --> 00:09:34,439
for our system and it was like we're

00:09:31,319 --> 00:09:35,699
gonna go open-source we're gonna go open

00:09:34,439 --> 00:09:37,800
source on this and we're gonna go with

00:09:35,699 --> 00:09:39,420
us in this and this storage well we

00:09:37,800 --> 00:09:42,110
really really need the performance so

00:09:39,420 --> 00:09:45,240
okay we'll pay you that kind of thing

00:09:42,110 --> 00:09:47,999
it's always a balance of figuring out

00:09:45,240 --> 00:09:50,579
what we can afford what we cannot and

00:09:47,999 --> 00:09:55,620
what we can make do with in terms of

00:09:50,579 --> 00:09:57,089
using people instead of money so I sort

00:09:55,620 --> 00:09:58,649
of broke ins down to three layers of

00:09:57,089 --> 00:10:01,620
high performance computing you've got

00:09:58,649 --> 00:10:03,480
your hardware layer which I've sort of

00:10:01,620 --> 00:10:08,490
pretty much spoken about but we'll go

00:10:03,480 --> 00:10:12,990
into more detail oops middleware which

00:10:08,490 --> 00:10:15,029
is all the scheduling and other little

00:10:12,990 --> 00:10:19,259
software in between the hardware and the

00:10:15,029 --> 00:10:21,749
user so it's also your compilers in a

00:10:19,259 --> 00:10:23,249
bandolier stuff like that and on your

00:10:21,749 --> 00:10:24,749
applications which is you use it and I'm

00:10:23,249 --> 00:10:29,249
actually not going to go very detail

00:10:24,749 --> 00:10:31,829
with that because the application layer

00:10:29,249 --> 00:10:35,009
there are so many we have 800 different

00:10:31,829 --> 00:10:36,779
users on our system at the moment and if

00:10:35,009 --> 00:10:38,939
I showed you the applications to trip

00:10:36,779 --> 00:10:40,410
directory it just scrolls and Scrolls

00:10:38,939 --> 00:10:41,720
and Scrolls of all the different

00:10:40,410 --> 00:10:45,649
applications

00:10:41,720 --> 00:10:45,649
most of them Python

00:10:45,970 --> 00:10:52,850
hardware this is actually a picture of

00:10:48,440 --> 00:10:55,730
tack this is the Stampede cluster in at

00:10:52,850 --> 00:11:01,220
University of Texas

00:10:55,730 --> 00:11:04,120
this is oddly enough 6400 nodes five

00:11:01,220 --> 00:11:07,550
hundred and twenty-two thousand cores

00:11:04,120 --> 00:11:12,310
yeah this is a monster 260 terabytes a

00:11:07,550 --> 00:11:14,900
total of memory I've toured this thing

00:11:12,310 --> 00:11:17,300
going down the hot mild this is actually

00:11:14,900 --> 00:11:19,430
the computer room is actually divided

00:11:17,300 --> 00:11:21,980
into cold oil hot aisle and they do hot

00:11:19,430 --> 00:11:23,750
out containment so the condyles are

00:11:21,980 --> 00:11:26,920
actually contained and all that hot air

00:11:23,750 --> 00:11:30,200
is held into it just a small channel and

00:11:26,920 --> 00:11:33,680
then cooled I've gone into the hot aisle

00:11:30,200 --> 00:11:37,310
and it's like going into about 105

00:11:33,680 --> 00:11:40,720
degrees which isn't that bad I've seen

00:11:37,310 --> 00:11:43,300
worse and I've heard worse

00:11:40,720 --> 00:11:47,930
they've got 14 petabytes of storage

00:11:43,300 --> 00:11:51,170
currently but this is all kind of moot

00:11:47,930 --> 00:11:53,690
because they're putting Frontera into

00:11:51,170 --> 00:11:56,240
place right now they're probably working

00:11:53,690 --> 00:11:59,420
in there right now debugging InfiniBand

00:11:56,240 --> 00:12:04,029
most likely that's going to be 4.8

00:11:59,420 --> 00:12:05,900
teraflops of compute power and they're

00:12:04,029 --> 00:12:08,360
estimating that they're going to make it

00:12:05,900 --> 00:12:13,750
into the top 5 or top 500 list in

00:12:08,360 --> 00:12:17,570
September so that's a pretty big deal

00:12:13,750 --> 00:12:19,459
storage lots of different storage

00:12:17,570 --> 00:12:22,390
variations we have to provide storage to

00:12:19,459 --> 00:12:24,260
all of these different machines and

00:12:22,390 --> 00:12:30,470
typically it's all from a single

00:12:24,260 --> 00:12:35,839
namespace of storage NFS a scale doesn't

00:12:30,470 --> 00:12:38,120
really cut it lustre seems to be the big

00:12:35,839 --> 00:12:41,540
game player these days one because it's

00:12:38,120 --> 00:12:43,990
free and two because it does actually

00:12:41,540 --> 00:12:46,310
perform pretty well

00:12:43,990 --> 00:12:49,760
however lustre still has issues

00:12:46,310 --> 00:12:52,160
particularly with small files and on our

00:12:49,760 --> 00:12:54,410
cluster in particular we're seeing lots

00:12:52,160 --> 00:12:55,550
of users with lots and lots of small

00:12:54,410 --> 00:12:59,839
small

00:12:55,550 --> 00:13:02,089
miles our last count we did an

00:12:59,839 --> 00:13:04,730
estimation we're looking at about 70

00:13:02,089 --> 00:13:07,490
percent of the file system used that's

00:13:04,730 --> 00:13:12,980
about 2 petabytes of storage 70% of that

00:13:07,490 --> 00:13:14,870
was files all less than 64 K I've seen

00:13:12,980 --> 00:13:17,709
directories with hundreds of thousands

00:13:14,870 --> 00:13:17,709
of files in it

00:13:20,260 --> 00:13:23,529
I'm sorry

00:13:28,699 --> 00:13:33,620
that it can be it can be a number of

00:13:30,899 --> 00:13:37,500
things most likely its intermediate data

00:13:33,620 --> 00:13:39,240
that they've generated they have no clue

00:13:37,500 --> 00:13:41,399
a lot of users have no clue what they've

00:13:39,240 --> 00:13:43,949
got on this cluster it's very it's very

00:13:41,399 --> 00:13:45,959
common you know we'll ask them what is

00:13:43,949 --> 00:13:52,649
this and they're like oh I did that six

00:13:45,959 --> 00:13:56,009
years ago what injury move it well which

00:13:52,649 --> 00:13:58,980
is yet another issue is data retention a

00:13:56,009 --> 00:14:00,959
number of our professors have grants

00:13:58,980 --> 00:14:05,069
where they say you cannot you have to

00:14:00,959 --> 00:14:12,410
hold on to this data forever where do

00:14:05,069 --> 00:14:15,660
you store that it's it gets crazy

00:14:12,410 --> 00:14:20,069
these parallel file systems they do not

00:14:15,660 --> 00:14:22,310
do small files well no file system out

00:14:20,069 --> 00:14:26,300
there deals with small files very well

00:14:22,310 --> 00:14:30,629
we're starting to get some better

00:14:26,300 --> 00:14:35,819
methods for dealing with it with flash

00:14:30,629 --> 00:14:40,730
buffers data on metadata storage things

00:14:35,819 --> 00:14:44,550
like that but it's a fighting battle

00:14:40,730 --> 00:14:47,850
it's tough what we wish they would do is

00:14:44,550 --> 00:14:51,240
fix their code but we're not dealing

00:14:47,850 --> 00:14:54,809
with small small files all the time this

00:14:51,240 --> 00:14:56,459
is actually a problem with the bio

00:14:54,809 --> 00:14:58,889
community in particular because they are

00:14:56,459 --> 00:15:02,100
a very young community they're they're

00:14:58,889 --> 00:15:05,490
new to the game they they're coding

00:15:02,100 --> 00:15:09,209
practices are infantile aspect

00:15:05,490 --> 00:15:12,149
effectively you're physicists chemists

00:15:09,209 --> 00:15:16,920
they've been in a game for 50 years they

00:15:12,149 --> 00:15:18,990
were coding in Fortran 66 on CDC

00:15:16,920 --> 00:15:22,559
machines years and years and years ago

00:15:18,990 --> 00:15:24,389
where they had 64 K of RAM they know how

00:15:22,559 --> 00:15:28,319
to take code and make it really really

00:15:24,389 --> 00:15:30,660
efficient and those coding practices

00:15:28,319 --> 00:15:33,430
have boiled over to today and they still

00:15:30,660 --> 00:15:37,400
do it the biologists

00:15:33,430 --> 00:15:39,740
they've come in five six ten years ago

00:15:37,400 --> 00:15:43,130
and they've got machines with multiple

00:15:39,740 --> 00:15:47,060
gigabytes of RAM they say well let's use

00:15:43,130 --> 00:15:49,840
it and their methods for dealing with

00:15:47,060 --> 00:15:52,370
the data has exploded well beyond that

00:15:49,840 --> 00:15:54,530
to the point where I am now having to

00:15:52,370 --> 00:15:58,430
purchase at times machines that have one

00:15:54,530 --> 00:16:01,220
and a half terabytes DRAM and I can go

00:15:58,430 --> 00:16:02,570
bigger if I need to there are machines

00:16:01,220 --> 00:16:05,570
out there that'll have six terabytes and

00:16:02,570 --> 00:16:10,780
they will use it and that's just memory

00:16:05,570 --> 00:16:13,340
I wish I didn't have to do that but I do

00:16:10,780 --> 00:16:15,110
when it comes to scheduling that the

00:16:13,340 --> 00:16:22,250
this is the other half of their

00:16:15,110 --> 00:16:26,570
infantile methods for programming they

00:16:22,250 --> 00:16:30,290
will schedule programs to run for 30

00:16:26,570 --> 00:16:34,220
days or more we have a 30-day maximum

00:16:30,290 --> 00:16:35,690
run time on our cluster which is huge

00:16:34,220 --> 00:16:36,980
compared to if you if you go around to

00:16:35,690 --> 00:16:41,330
other educational institutions they're

00:16:36,980 --> 00:16:44,000
like yeah 72 hours that's our maximum or

00:16:41,330 --> 00:16:45,230
30 days and they will use it and then at

00:16:44,000 --> 00:16:48,590
the end of the 30 days they'll complain

00:16:45,230 --> 00:16:51,560
to us and say we need more and we're

00:16:48,590 --> 00:16:53,870
like no checkpoint your data how do I do

00:16:51,560 --> 00:16:55,250
that they don't have the clue they don't

00:16:53,870 --> 00:17:02,930
have the idea of how to checkpoint their

00:16:55,250 --> 00:17:08,080
data so again more battles GPFS getting

00:17:02,930 --> 00:17:11,380
bet to this gpfs is obviously the IBM

00:17:08,080 --> 00:17:13,780
variant it's expensive

00:17:11,380 --> 00:17:15,370
and it has about the same performance as

00:17:13,780 --> 00:17:17,579
lustre there might be some corner cases

00:17:15,370 --> 00:17:19,799
where better outperforms lustre and

00:17:17,579 --> 00:17:22,870
vice-versa

00:17:19,799 --> 00:17:25,959
BG FS is actually relatively new on the

00:17:22,870 --> 00:17:27,549
scene they've got a some nut thief

00:17:25,959 --> 00:17:30,309
they're known to have a bit better

00:17:27,549 --> 00:17:34,480
performance when it comes to smaller

00:17:30,309 --> 00:17:36,130
files but it's new and there are some

00:17:34,480 --> 00:17:43,090
other features that we really wish they

00:17:36,130 --> 00:17:45,130
had that they don't have yet d clustered

00:17:43,090 --> 00:17:48,720
raid so I'm kind of jumping around here

00:17:45,130 --> 00:17:50,980
but D cluster kraid raid 5 raid 6

00:17:48,720 --> 00:17:51,750
problem with that is the drives are so

00:17:50,980 --> 00:17:56,470
huge now

00:17:51,750 --> 00:17:58,240
what's your rebuild time rebuild time

00:17:56,470 --> 00:18:00,640
you know we're getting 12 terabyte

00:17:58,240 --> 00:18:03,010
drives on our systems and you do a raid

00:18:00,640 --> 00:18:05,860
8 plus to rebuild time on that is

00:18:03,010 --> 00:18:08,440
multiple days what's the chances of

00:18:05,860 --> 00:18:14,500
having a triple drive failure during

00:18:08,440 --> 00:18:16,270
that time it's not infinitely small it's

00:18:14,500 --> 00:18:17,440
actually possible and it's becoming more

00:18:16,270 --> 00:18:20,130
and more impossible as these guys get

00:18:17,440 --> 00:18:22,900
larger and the rebuild times get longer

00:18:20,130 --> 00:18:27,010
I've heard at least one time or another

00:18:22,900 --> 00:18:29,980
where there is now like a raid 7 type

00:18:27,010 --> 00:18:41,549
schema which is literally triple Drive

00:18:29,980 --> 00:18:41,549
redundancy but have they yeah okay

00:18:45,490 --> 00:18:51,770
right right well that's what effectively

00:18:49,880 --> 00:18:53,270
just a cluster grade is is they're

00:18:51,770 --> 00:18:56,660
distributing the parity across the

00:18:53,270 --> 00:18:57,590
drives in smaller chunks so and they're

00:18:56,660 --> 00:19:00,020
scattered all over the place so

00:18:57,590 --> 00:19:03,800
rebuilding a drive is just like that

00:19:00,020 --> 00:19:09,040
I've seen 12 drive a 12 terabyte drive

00:19:03,800 --> 00:19:13,160
rebuild take 15 minutes that's nothing

00:19:09,040 --> 00:19:15,590
so that they're coming out unfortunately

00:19:13,160 --> 00:19:18,340
the cluster great kind of stuff that's

00:19:15,590 --> 00:19:24,860
proprietary you're gonna pay for it but

00:19:18,340 --> 00:19:28,010
that's part of the game I believe so I'm

00:19:24,860 --> 00:19:33,380
not sure we haven't dealt with it I I

00:19:28,010 --> 00:19:36,830
know who to talk to to find out yeah

00:19:33,380 --> 00:19:42,040
I've got I've got friends and I could

00:19:36,830 --> 00:19:46,220
find out for you if you wanted okay yeah

00:19:42,040 --> 00:19:48,080
yeah yeah I'm not I'm not sure we

00:19:46,220 --> 00:19:52,190
haven't really dealt dealt into Seth

00:19:48,080 --> 00:19:52,640
it's not a huge user base on stuff at

00:19:52,190 --> 00:19:55,460
the moment

00:19:52,640 --> 00:19:59,240
luster really is the big user base these

00:19:55,460 --> 00:20:03,920
days when it comes to luck with bluster

00:19:59,240 --> 00:20:07,970
here we go top 500 list more than 50% on

00:20:03,920 --> 00:20:11,480
the top 500 list are using lustre

00:20:07,970 --> 00:20:13,940
I know attack is using it we tend to

00:20:11,480 --> 00:20:18,590
follow what TAC does because they've got

00:20:13,940 --> 00:20:21,320
the employee base to make things right

00:20:18,590 --> 00:20:25,880
and we say well that's the way we should

00:20:21,320 --> 00:20:29,600
go as I said you know life sciences oil

00:20:25,880 --> 00:20:33,350
and gas finance lots of people using it

00:20:29,600 --> 00:20:37,970
it does the job in a general way pretty

00:20:33,350 --> 00:20:42,980
well computational hardware this is the

00:20:37,970 --> 00:20:48,410
nuts and bolts we're doing here the CPUs

00:20:42,980 --> 00:20:50,720
themselves mostly Intel at this level we

00:20:48,410 --> 00:20:53,029
have seen some MD and we're seeing I

00:20:50,720 --> 00:20:57,799
think growing

00:20:53,029 --> 00:20:59,419
use with epic now but we won't see it I

00:20:57,799 --> 00:21:01,129
don't think we're gonna really see it

00:20:59,419 --> 00:21:03,350
explode until at least the second

00:21:01,129 --> 00:21:05,240
generation really comes out properly the

00:21:03,350 --> 00:21:07,519
first generation was really good for

00:21:05,240 --> 00:21:12,679
storage systems because of the increased

00:21:07,519 --> 00:21:15,440
PCI but for the compute at Intel was

00:21:12,679 --> 00:21:19,460
still beating them out with their second

00:21:15,440 --> 00:21:21,950
generation here we'll see I guess I have

00:21:19,460 --> 00:21:26,720
good hopes I like to see the competition

00:21:21,950 --> 00:21:31,429
because what the competition comes lower

00:21:26,720 --> 00:21:32,600
prices for us obviously power let's face

00:21:31,429 --> 00:21:40,340
it they're pretty much dead and you're

00:21:32,600 --> 00:21:46,429
stuck with IBM right and how good is it

00:21:40,340 --> 00:21:50,330
you know compared ibly there you go it

00:21:46,429 --> 00:21:52,999
arm we would love to see arm come up and

00:21:50,330 --> 00:21:56,090
actually start playing in this arena

00:21:52,999 --> 00:22:00,619
properly I'd love to see it it hasn't

00:21:56,090 --> 00:22:02,899
happened yet we're still hopeful GPUs

00:22:00,619 --> 00:22:04,299
let's face it NVIDIA has it pretty much

00:22:02,899 --> 00:22:09,460
down

00:22:04,299 --> 00:22:12,169
AMD they the Radeon chips they can do it

00:22:09,460 --> 00:22:14,659
they can do it they've got pretty much

00:22:12,169 --> 00:22:18,019
the same amount of capability the

00:22:14,659 --> 00:22:20,450
problem is the software base Nvidia got

00:22:18,019 --> 00:22:26,600
it right they went out there and said

00:22:20,450 --> 00:22:28,600
hey let's let's get this GPU stuff going

00:22:26,600 --> 00:22:32,019
by hiring a bunch of programmers and

00:22:28,600 --> 00:22:34,730
picking out I don't know a dozen 15 20

00:22:32,019 --> 00:22:37,279
major programs and convert them over to

00:22:34,730 --> 00:22:39,409
using GPUs as well in order to enhance

00:22:37,279 --> 00:22:43,850
them properly and giving them out for

00:22:39,409 --> 00:22:45,889
free and they kept that up and that

00:22:43,850 --> 00:22:48,980
created that for them a major user base

00:22:45,889 --> 00:22:51,610
and a code base that everybody is using

00:22:48,980 --> 00:22:54,499
now so they've got the momentum and

00:22:51,610 --> 00:22:58,389
nobody else can catch up AMD can't catch

00:22:54,499 --> 00:23:00,769
up at all intel tried with the mic fie

00:22:58,389 --> 00:23:04,749
systems I don't know if anybody's ever

00:23:00,769 --> 00:23:04,749
played with those it was horrible

00:23:05,589 --> 00:23:11,149
it's just that's the name of the game in

00:23:08,539 --> 00:23:26,059
videos the way to go and they're going

00:23:11,149 --> 00:23:27,559
to make money off of it FB yes our

00:23:26,059 --> 00:23:29,059
scheduler takes care of that so it's

00:23:27,559 --> 00:23:30,979
actually relatively monolithic and

00:23:29,059 --> 00:23:35,330
they're all connected via lustre to the

00:23:30,979 --> 00:23:37,489
same file system and then we do have so

00:23:35,330 --> 00:23:42,709
it's all when a user puts in a program

00:23:37,489 --> 00:23:45,829
into the clock into the scheduler it

00:23:42,709 --> 00:23:49,070
will be scheduled on one of the subsets

00:23:45,829 --> 00:23:49,690
of the clusters but they could get out

00:23:49,070 --> 00:23:52,820
of one

00:23:49,690 --> 00:23:55,039
you know they could get the new skylake

00:23:52,820 --> 00:23:56,899
nodes they could get the older stuff

00:23:55,039 --> 00:24:00,469
they could get our old AMD Opteron so

00:23:56,899 --> 00:24:05,539
that we have and the reason we do that

00:24:00,469 --> 00:24:09,289
is we have found that I would say 95

00:24:05,539 --> 00:24:13,219
percent if not more of our users don't

00:24:09,289 --> 00:24:16,579
care about how long the job runs they

00:24:13,219 --> 00:24:21,639
don't care all they care about is how

00:24:16,579 --> 00:24:24,529
quickly it starts running it's weird

00:24:21,639 --> 00:24:27,440
it's you know okay they don't care it

00:24:24,529 --> 00:24:28,969
could run five times longer so long as

00:24:27,440 --> 00:24:33,210
they had five seconds faster on their

00:24:28,969 --> 00:24:36,750
start time that's all they care about

00:24:33,210 --> 00:24:42,890
I see the laughing and you're like yeah

00:24:36,750 --> 00:24:47,820
it's true it's just it's a weird

00:24:42,890 --> 00:24:51,170
sociological thing where they just all

00:24:47,820 --> 00:24:51,170
they care about is when it starts

00:24:52,740 --> 00:24:58,900
FPGAs I don't really know very much

00:24:54,910 --> 00:25:01,000
about them we don't use them we do have

00:24:58,900 --> 00:25:05,380
a research group that is experimenting

00:25:01,000 --> 00:25:08,440
with them but they're small and we don't

00:25:05,380 --> 00:25:10,390
have they're very specialized is part of

00:25:08,440 --> 00:25:14,920
the problem and we're doing general HPC

00:25:10,390 --> 00:25:17,550
so if you've got a application and you

00:25:14,920 --> 00:25:20,950
need to run millions upon millions of

00:25:17,550 --> 00:25:25,870
that program FPGAs might be the way to

00:25:20,950 --> 00:25:29,770
go for us now we reconfiguring them all

00:25:25,870 --> 00:25:31,090
the time and sucking up many people read

00:25:29,770 --> 00:25:33,660
doing that reconfiguration it's not

00:25:31,090 --> 00:25:33,660
worth it for us

00:25:34,480 --> 00:25:43,000
general as I said Intel dominates AMD

00:25:38,350 --> 00:25:44,770
less than 1% of the top 500 list that

00:25:43,000 --> 00:25:50,140
I'm hoping that will climb in the next

00:25:44,770 --> 00:25:52,330
year or so but we'll see as I said epic

00:25:50,140 --> 00:25:54,600
is very highly suited for file servers

00:25:52,330 --> 00:25:54,600
yes

00:26:01,090 --> 00:26:06,400
I have high hopes you know I'd love to

00:26:05,080 --> 00:26:08,679
see great performance numbers out of

00:26:06,400 --> 00:26:13,840
that so that other people look at and

00:26:08,679 --> 00:26:17,679
say hey let's do that because that's

00:26:13,840 --> 00:26:18,880
that's what we need I mean groups like

00:26:17,679 --> 00:26:22,179
Oak Ridge

00:26:18,880 --> 00:26:25,470
tack although there's a really really

00:26:22,179 --> 00:26:28,150
big to try some of these other systems

00:26:25,470 --> 00:26:30,280
make them work and show the numbers to

00:26:28,150 --> 00:26:33,340
us so that we can say that's the way to

00:26:30,280 --> 00:26:34,260
go that that kind of system suits our

00:26:33,340 --> 00:26:41,350
needs

00:26:34,260 --> 00:26:45,490
yes Oak Ridge National Labs is what it's

00:26:41,350 --> 00:26:48,340
in Tennessee Knoxville area they are a

00:26:45,490 --> 00:26:52,690
national research lab have lots of large

00:26:48,340 --> 00:26:56,380
clusters some of which aren't visible to

00:26:52,690 --> 00:27:01,440
the public I think they do quite a bit

00:26:56,380 --> 00:27:01,440
of nuclear research that kind of thing

00:27:04,179 --> 00:27:11,110
let's see node types so breaking down a

00:27:08,500 --> 00:27:13,710
cluster we've got compute nodes which

00:27:11,110 --> 00:27:15,669
are pretty obvious they run your jobs

00:27:13,710 --> 00:27:17,710
middleware support nodes so your

00:27:15,669 --> 00:27:18,159
directory services LDAP that kind of

00:27:17,710 --> 00:27:22,270
thing

00:27:18,159 --> 00:27:24,100
DNS schedulers and user support nodes

00:27:22,270 --> 00:27:26,350
which be your web servers your wiki

00:27:24,100 --> 00:27:28,240
databases and your actual database

00:27:26,350 --> 00:27:30,510
servers for users that actually need

00:27:28,240 --> 00:27:33,309
them we're seeing a growing need for

00:27:30,510 --> 00:27:35,380
particularly the file users they have a

00:27:33,309 --> 00:27:38,429
database or three that they need to

00:27:35,380 --> 00:27:42,179
query against in order to run their data

00:27:38,429 --> 00:27:45,490
you gotta support that database somehow

00:27:42,179 --> 00:27:51,730
all of this gets made more complex by

00:27:45,490 --> 00:27:53,380
high availability so that web server

00:27:51,730 --> 00:27:55,870
needs to be highly available you know

00:27:53,380 --> 00:27:58,960
because you're promoting your systems

00:27:55,870 --> 00:28:01,270
your DNS needs to be highly available

00:27:58,960 --> 00:28:04,179
because well if your DNS server dies

00:28:01,270 --> 00:28:08,200
your entire cluster dies it's not good

00:28:04,179 --> 00:28:11,220
to have a single point of failure your

00:28:08,200 --> 00:28:14,530
database servers good idea to have it

00:28:11,220 --> 00:28:16,539
highly available where all of that used

00:28:14,530 --> 00:28:18,730
to cost quite a bit of money a lot of

00:28:16,539 --> 00:28:20,770
those things in nowadays they can be put

00:28:18,730 --> 00:28:21,700
thrown into VMs and you have a pair of

00:28:20,770 --> 00:28:23,500
here I'm just doing the high

00:28:21,700 --> 00:28:29,230
availability for you and you've got its

00:28:23,500 --> 00:28:31,780
distributed across those great GPUs I

00:28:29,230 --> 00:28:33,809
already did this but in videos pretty

00:28:31,780 --> 00:28:37,539
much the king

00:28:33,809 --> 00:28:40,440
OpenCL is just not strongly adopted just

00:28:37,539 --> 00:28:40,440
that's the way it is

00:28:40,840 --> 00:28:50,200
server room infrastructure power right

00:28:44,920 --> 00:28:54,700
now we are running 208 as our bus lines

00:28:50,200 --> 00:28:59,470
down order no what are we running we're

00:28:54,700 --> 00:29:03,610
running for 408 it's broken down 208 for

00:28:59,470 --> 00:29:06,040
each of the legs mm-hmm in all of our

00:29:03,610 --> 00:29:09,130
machines they're now talking bringing

00:29:06,040 --> 00:29:12,400
down even down at 280 in each leg and

00:29:09,130 --> 00:29:14,470
then I'll bring that down just so that

00:29:12,400 --> 00:29:17,650
we can bring the voltage up and just you

00:29:14,470 --> 00:29:20,230
get our power better each rack we're

00:29:17,650 --> 00:29:26,530
having right now we've sort of set the

00:29:20,230 --> 00:29:29,530
cutoff to be 60 amps per rack we've seen

00:29:26,530 --> 00:29:32,020
people who are doing 80 and this is all

00:29:29,530 --> 00:29:34,510
air-cooled equipment you can do more

00:29:32,020 --> 00:29:37,090
with water-cooled but with air-cooled

00:29:34,510 --> 00:29:39,580
60s sort of your limit 80 if you really

00:29:37,090 --> 00:29:42,390
push it and the folks that I I think the

00:29:39,580 --> 00:29:46,030
folks that I knew who were doing 80 had

00:29:42,390 --> 00:29:48,250
chiller doors on the rear so we don't

00:29:46,030 --> 00:29:51,220
have any Childers we're at 60 amps per

00:29:48,250 --> 00:30:02,170
rack and it gets hot it gets hot in

00:29:51,220 --> 00:30:08,080
those racks one rack 1 1 2 feet wide 48

00:30:02,170 --> 00:30:14,860
you we're probably around seven or two

00:30:08,080 --> 00:30:20,530
kW right now 700 kilowatts hundred seven

00:30:14,860 --> 00:30:23,830
hundred kilowatts yeah yeah

00:30:20,530 --> 00:30:26,940
lots of power lots and lots of power and

00:30:23,830 --> 00:30:26,940
then we have to cool that

00:30:31,330 --> 00:30:37,009
you know what this is a weird thing

00:30:34,039 --> 00:30:42,200
about University of Florida I don't know

00:30:37,009 --> 00:30:43,729
I have no clue how are we paying for

00:30:42,200 --> 00:30:49,570
this are we getting any deals from The

00:30:43,729 --> 00:30:49,570
Electric Company for this I have no idea

00:30:51,039 --> 00:31:01,309
we actually had to do have that to some

00:30:53,330 --> 00:31:05,720
extent but yes that's nice we don't get

00:31:01,309 --> 00:31:07,970
that I don't know and the reason I don't

00:31:05,720 --> 00:31:10,220
know is because the way we purchased the

00:31:07,970 --> 00:31:14,899
building we purchased it on a 99-year

00:31:10,220 --> 00:31:17,539
lease from the US Foundation who owned

00:31:14,899 --> 00:31:26,269
the building and we bought it on the

00:31:17,539 --> 00:31:28,639
terms of they pay for the power it's

00:31:26,269 --> 00:31:32,359
great we don't care

00:31:28,639 --> 00:31:34,249
I think they will care if we ever load

00:31:32,359 --> 00:31:36,049
out this room completely and all of a

00:31:34,249 --> 00:31:40,460
sudden start drawing all the power we

00:31:36,049 --> 00:31:41,869
can they will suddenly start caring with

00:31:40,460 --> 00:31:43,789
that notion and you know those

00:31:41,869 --> 00:31:45,830
constraints we actually do try to

00:31:43,789 --> 00:31:52,580
minimize our power usage and what's

00:31:45,830 --> 00:31:55,070
possible yes 50,000 square 25,000 square

00:31:52,580 --> 00:31:57,019
feet and then we've got we've actually

00:31:55,070 --> 00:31:59,690
got a second one right next door but

00:31:57,019 --> 00:32:01,940
that is more for the university

00:31:59,690 --> 00:32:04,970
infrastructure so they're billing and

00:32:01,940 --> 00:32:07,159
student grades and everything their

00:32:04,970 --> 00:32:10,789
power draw for supporting the entire

00:32:07,159 --> 00:32:13,149
rest of the university is around 150

00:32:10,789 --> 00:32:13,149
kilowatts

00:32:19,040 --> 00:32:24,720
we've had a couple of instances where oh

00:32:21,720 --> 00:32:25,800
look somebody's running Bitcoin but it's

00:32:24,720 --> 00:32:30,320
actually been a few and far between

00:32:25,800 --> 00:32:30,320
we've been somewhat lucky on that

00:32:31,100 --> 00:32:35,250
so yeah the cooling it's hot out cold

00:32:33,809 --> 00:32:40,740
I'll contain right we're not going to

00:32:35,250 --> 00:32:43,170
tainment yet but we will be obviously we

00:32:40,740 --> 00:32:46,590
need higher cooling capacity for all

00:32:43,170 --> 00:32:49,670
that heat being generated and to do that

00:32:46,590 --> 00:32:51,990
we've got multiple chillers multiple

00:32:49,670 --> 00:32:56,220
cracks which are basically air handlers

00:32:51,990 --> 00:33:02,940
and all of that is redundant all of our

00:32:56,220 --> 00:33:05,910
stuff is also fully UPS backup so power

00:33:02,940 --> 00:33:09,660
goes out UPS kicks in backup generator

00:33:05,910 --> 00:33:11,190
fires up take over the power at the

00:33:09,660 --> 00:33:14,000
moment we haven't exceeded the

00:33:11,190 --> 00:33:16,290
capability of the generator we will and

00:33:14,000 --> 00:33:25,170
then they'll have to figure something

00:33:16,290 --> 00:33:28,620
else out our our building is rated for a

00:33:25,170 --> 00:33:32,690
cat 3 hurricane which in the center of

00:33:28,620 --> 00:33:36,840
northern Florida is probably all we need

00:33:32,690 --> 00:33:41,460
if something actually hits Central

00:33:36,840 --> 00:33:43,860
Florida at cat 4 or higher the coastline

00:33:41,460 --> 00:33:45,600
is gone at that point because they've

00:33:43,860 --> 00:33:49,020
been hit with essentially a cat 6

00:33:45,600 --> 00:33:51,510
there's a lot of terrain for that cat 3

00:33:49,020 --> 00:33:53,820
to get through before it really hurts us

00:33:51,510 --> 00:33:56,059
so we're actually in a good part of the

00:33:53,820 --> 00:34:00,950
state in terms of hurricanes

00:33:56,059 --> 00:34:04,669
and excites just a hurricane you can

00:34:00,950 --> 00:34:06,080
tell them to Florida networking as I

00:34:04,669 --> 00:34:07,820
said we've got dual 100 gigabit links

00:34:06,080 --> 00:34:09,740
coming into the server room and those

00:34:07,820 --> 00:34:12,399
are our only two networking connections

00:34:09,740 --> 00:34:15,589
to the outside world on this cluster

00:34:12,399 --> 00:34:17,929
that's it everything else is inside the

00:34:15,589 --> 00:34:21,289
room and it's miles and miles and miles

00:34:17,929 --> 00:34:27,849
of networking cable but to the outside

00:34:21,289 --> 00:34:30,200
world is to fiber links will be seeing

00:34:27,849 --> 00:34:33,889
as I said we'll probably be seeing that

00:34:30,200 --> 00:34:37,490
upgraded to dual 200 gig or possibly 400

00:34:33,889 --> 00:34:40,240
at some point the nice thing about that

00:34:37,490 --> 00:34:42,770
is that that 100 gigabit link also

00:34:40,240 --> 00:34:46,690
creates a ring bus pretty much around

00:34:42,770 --> 00:34:51,980
the state so there's a full lambda rail

00:34:46,690 --> 00:34:53,869
network around the state InfiniBand

00:34:51,980 --> 00:34:54,649
where as I said we're doing 56 peak of

00:34:53,869 --> 00:34:57,109
it right now

00:34:54,649 --> 00:35:00,529
that fits six gigabit connect every

00:34:57,109 --> 00:35:04,640
compute node to each other and also to

00:35:00,529 --> 00:35:06,589
our storage except to NFS NFS is handled

00:35:04,640 --> 00:35:13,089
by a 40 gigabit and that's just our home

00:35:06,589 --> 00:35:17,329
areas oh here we go

00:35:13,089 --> 00:35:18,890
3 by 270 tons on that cooling at the

00:35:17,329 --> 00:35:22,099
moment and will probably be adding a

00:35:18,890 --> 00:35:25,010
fourth in the next year or so

00:35:22,099 --> 00:35:32,630
fiber optic is as I said dual 10 100

00:35:25,010 --> 00:35:36,020
gigabit we've got 72 hours of runtime on

00:35:32,630 --> 00:35:38,599
the generator if we go that go to go

00:35:36,020 --> 00:35:41,299
beyond that will we will probably start

00:35:38,599 --> 00:35:44,690
shutting down our systems before that

00:35:41,299 --> 00:35:47,299
happens in order to give the university

00:35:44,690 --> 00:35:48,799
infrastructure to longer times because

00:35:47,299 --> 00:35:53,450
we're just we're just research

00:35:48,799 --> 00:35:55,160
you know what research can stop but the

00:35:53,450 --> 00:35:58,339
lifeblood of the bit of the university

00:35:55,160 --> 00:36:03,109
is that other room so let them run

00:35:58,339 --> 00:36:06,339
longer as I say cat 3 hurricane and o2

00:36:03,109 --> 00:36:10,359
5,000 square-foot rooms not 25 sorry

00:36:06,339 --> 00:36:15,309
I know how big they are by sight that's

00:36:10,359 --> 00:36:21,689
about it and this is our cluster at the

00:36:15,309 --> 00:36:27,880
moment back in fall of 2015 we made

00:36:21,689 --> 00:36:30,459
113th Clemson beat us out by one that

00:36:27,880 --> 00:36:33,430
was very annoying they did it

00:36:30,459 --> 00:36:36,819
underhandedly by buying some extra GPUs

00:36:33,430 --> 00:36:40,900
and re running their code to beat us out

00:36:36,819 --> 00:36:43,029
by one it's a bit of a competition but

00:36:40,900 --> 00:36:46,749
we're actually starting to not look at

00:36:43,029 --> 00:36:52,809
the top 500 as being a useful number for

00:36:46,749 --> 00:36:54,369
us though the regions of

00:36:52,809 --> 00:36:57,489
high-performance computing has started

00:36:54,369 --> 00:37:01,539
to splinter a bit in what you're using

00:36:57,489 --> 00:37:04,109
the cluster for and in terms of pure

00:37:01,539 --> 00:37:06,579
compute power that's not everything

00:37:04,109 --> 00:37:09,839
we're now starting to look more heavily

00:37:06,579 --> 00:37:13,900
at something called the IO 500 which is

00:37:09,839 --> 00:37:15,999
looking purely at the top 500 storage

00:37:13,900 --> 00:37:20,109
systems in the country and how they

00:37:15,999 --> 00:37:22,390
perform and we think that a good

00:37:20,109 --> 00:37:29,259
combination of the two is actually much

00:37:22,390 --> 00:37:31,589
more important let's see no we're okay

00:37:29,259 --> 00:37:31,589
here we go

00:37:33,929 --> 00:37:41,259
Linux I don't know if any system out

00:37:37,959 --> 00:37:44,039
there at least in the top 500 list that

00:37:41,259 --> 00:37:44,039
doesn't use Linux

00:37:44,519 --> 00:37:51,670
right there might be one yeah but for

00:37:48,339 --> 00:37:53,789
the most part everybody uses Linux for a

00:37:51,670 --> 00:37:55,690
provisioning which is getting the

00:37:53,789 --> 00:37:56,859
operating system out to each of those

00:37:55,690 --> 00:38:03,819
nodes because we're not running around

00:37:56,859 --> 00:38:07,839
with the USB key we're using we sort of

00:38:03,819 --> 00:38:11,829
used to we're currently using Foreman

00:38:07,839 --> 00:38:14,079
and puppet which works very well for us

00:38:11,829 --> 00:38:17,440
rocks is another option that's been

00:38:14,079 --> 00:38:19,329
around longer we did use that many many

00:38:17,440 --> 00:38:25,390
years ago that's been well it's about 15

00:38:19,329 --> 00:38:26,529
years ago but it's clunky and not a lot

00:38:25,390 --> 00:38:41,529
of development has happened with it in

00:38:26,529 --> 00:38:44,289
years right yes uh-huh yes no wait

00:38:41,529 --> 00:38:50,490
it just works we just used the Red Hat

00:38:44,289 --> 00:38:53,650
kernels yeah we try to stay as close to

00:38:50,490 --> 00:38:56,680
what is provided by others as we can

00:38:53,650 --> 00:38:58,299
because we're customization yes it can

00:38:56,680 --> 00:39:01,660
be nice and it can improve things a

00:38:58,299 --> 00:39:03,359
little bit but when one thing changes

00:39:01,660 --> 00:39:05,980
and it throws all that other stuff out

00:39:03,359 --> 00:39:09,640
forget it it's not worth it it's not

00:39:05,980 --> 00:39:13,450
worth the time and our team we are 13

00:39:09,640 --> 00:39:16,089
people total for all of our research

00:39:13,450 --> 00:39:22,230
computing group and only four of us are

00:39:16,089 --> 00:39:23,549
operations so it's just not gonna happen

00:39:22,230 --> 00:39:27,009
right

00:39:23,549 --> 00:39:28,480
another provisioner but I think it's

00:39:27,009 --> 00:39:30,220
owned by Dell or at least a subsidiary

00:39:28,480 --> 00:39:34,210
go-devil or something like that I don't

00:39:30,220 --> 00:39:36,269
know commercial it's plug-and-play you

00:39:34,210 --> 00:39:38,920
know you pay for it and it just works

00:39:36,269 --> 00:39:43,660
maybe not very cleanly maybe not

00:39:38,920 --> 00:39:45,190
perfectly but if your single Direction

00:39:43,660 --> 00:39:46,930
type computing high performance

00:39:45,190 --> 00:39:48,460
computing kind of stuff and you've got

00:39:46,930 --> 00:39:51,630
one application to run across a bunch of

00:39:48,460 --> 00:39:53,880
clusters might be the way to go

00:39:51,630 --> 00:39:57,800
and makes it easier if you have a small

00:39:53,880 --> 00:40:01,440
small team scheduler we are using slurm

00:39:57,800 --> 00:40:05,460
we used to be torque and with Moab and

00:40:01,440 --> 00:40:07,140
Maui before that we were actually PBS

00:40:05,460 --> 00:40:10,110
Pro so I've actually dealt with all

00:40:07,140 --> 00:40:12,120
three of these learners the free one

00:40:10,110 --> 00:40:13,980
these days and it's got the most

00:40:12,120 --> 00:40:16,530
development happening with it right now

00:40:13,980 --> 00:40:18,660
and I think most features and it's

00:40:16,530 --> 00:40:23,400
actually documented and the things that

00:40:18,660 --> 00:40:25,380
they've documented actually work if

00:40:23,400 --> 00:40:28,320
anybody here is used Moab they

00:40:25,380 --> 00:40:30,120
understand my pain they have they had a

00:40:28,320 --> 00:40:32,220
lot of things talking in it and we'd

00:40:30,120 --> 00:40:38,660
like but it's documentation they're like

00:40:32,220 --> 00:40:41,400
it is yes right here it was bad

00:40:38,660 --> 00:40:47,550
operating systems as I said we've been

00:40:41,400 --> 00:40:49,610
using RedHat Ubuntu is out there mostly

00:40:47,550 --> 00:40:56,420
for our users our users use it a lot

00:40:49,610 --> 00:40:56,420
because it's easy and it works I guess

00:40:57,470 --> 00:41:03,770
scientific Linux I don't know if anybody

00:40:59,640 --> 00:41:03,770
heard the news but they're kind of done

00:41:04,580 --> 00:41:12,240
Suzy crate lint environment basically I

00:41:10,560 --> 00:41:17,090
think for most of the clusters you're

00:41:12,240 --> 00:41:19,860
seeing either Red Hat or sent to us I

00:41:17,090 --> 00:41:23,130
don't know if anybody uses anything else

00:41:19,860 --> 00:41:28,950
in a larger cluster but for the most

00:41:23,130 --> 00:41:32,910
part it's Red Hat provisioning as I said

00:41:28,950 --> 00:41:35,160
we're reusing forming a puppet former

00:41:32,910 --> 00:41:39,740
and puppet their open-source based on

00:41:35,160 --> 00:41:42,510
popular software rocks it's ancient

00:41:39,740 --> 00:41:46,680
nobody's using it these days except San

00:41:42,510 --> 00:41:51,290
Diego not a lot of development going on

00:41:46,680 --> 00:41:53,910
and bright again its commercial

00:41:51,290 --> 00:41:57,300
end-users software here's the end here's

00:41:53,910 --> 00:41:59,040
the the crux of the problem here lots of

00:41:57,300 --> 00:42:01,500
packages out there lots of different

00:41:59,040 --> 00:42:02,760
programs for users and they will find

00:42:01,500 --> 00:42:04,890
them and they won't ask for them to be

00:42:02,760 --> 00:42:07,440
installed or they won't install them

00:42:04,890 --> 00:42:09,150
and they will require some oddball

00:42:07,440 --> 00:42:10,769
version of Python that you don't have

00:42:09,150 --> 00:42:13,579
installed and all of a sudden you have

00:42:10,769 --> 00:42:18,779
to have that installed as well

00:42:13,579 --> 00:42:21,210
documentation you get what you get some

00:42:18,779 --> 00:42:24,239
developers document very well others

00:42:21,210 --> 00:42:27,210
here's your code and it might work it

00:42:24,239 --> 00:42:29,400
might not portability

00:42:27,210 --> 00:42:31,319
we have that problem as well you know

00:42:29,400 --> 00:42:34,470
we're running Red Hat right now we're

00:42:31,319 --> 00:42:39,690
still running Red Hat seven and we only

00:42:34,470 --> 00:42:41,249
just got to that in the last year all

00:42:39,690 --> 00:42:43,019
these people you know there's a lot of

00:42:41,249 --> 00:42:44,339
users out there who I develop my

00:42:43,019 --> 00:42:46,109
software on a boost to the latest

00:42:44,339 --> 00:42:48,660
version why don't you have these

00:42:46,109 --> 00:42:51,599
libraries in these library versions well

00:42:48,660 --> 00:42:54,569
we're running red hat and Red Hat is a

00:42:51,599 --> 00:42:58,410
little slow I know Red Hat is supposed

00:42:54,569 --> 00:43:01,559
to be going to a faster development

00:42:58,410 --> 00:43:04,559
cycle with Red Hat eight so that they

00:43:01,559 --> 00:43:06,710
actually keep up a little bit but we'll

00:43:04,559 --> 00:43:06,710
see

00:43:11,979 --> 00:43:23,089
they don't use what so the question is

00:43:20,479 --> 00:43:24,709
do I have users that don't use build

00:43:23,089 --> 00:43:28,059
agents that will replicate the the

00:43:24,709 --> 00:43:28,059
software on a cluster

00:43:37,150 --> 00:43:39,180
ah

00:43:44,940 --> 00:43:53,160
okay the way we typically do it is we

00:43:51,810 --> 00:43:56,820
actually have an applications directory

00:43:53,160 --> 00:43:59,130
and we ask that the users if they use

00:43:56,820 --> 00:44:01,320
the software or lock or they have one

00:43:59,130 --> 00:44:02,900
two or three people using it we ask that

00:44:01,320 --> 00:44:04,890
they have asked us to install it and

00:44:02,900 --> 00:44:06,600
we'll install it in the applications

00:44:04,890 --> 00:44:10,080
directory and then it's usable in the

00:44:06,600 --> 00:44:15,060
cluster just period and that seems to

00:44:10,080 --> 00:44:17,790
work pretty well it's when we get a user

00:44:15,060 --> 00:44:21,240
who says hey I use I develop this piece

00:44:17,790 --> 00:44:25,380
of software on my laptop and it's not

00:44:21,240 --> 00:44:27,020
working on your system now why we get

00:44:25,380 --> 00:44:29,450
that a lot

00:44:27,020 --> 00:44:32,850
again mostly from the bio community

00:44:29,450 --> 00:44:38,790
unfortunately and this comes to

00:44:32,850 --> 00:44:41,820
portability containers are a godsend in

00:44:38,790 --> 00:44:44,400
this case they really are where we've

00:44:41,820 --> 00:44:47,790
been using singularity which is a more

00:44:44,400 --> 00:44:53,400
secure version of docker obviously and

00:44:47,790 --> 00:44:56,520
that's been very successful the CMS

00:44:53,400 --> 00:44:59,160
program which is Large Hadron Collider

00:44:56,520 --> 00:45:02,250
it's a it's a part of the Large Hadron

00:44:59,160 --> 00:45:06,090
Collider data and their research we are

00:45:02,250 --> 00:45:08,190
a Tier two site for them and all of

00:45:06,090 --> 00:45:11,310
their software that runs on our cluster

00:45:08,190 --> 00:45:14,630
is done through singularity containers

00:45:11,310 --> 00:45:14,630
which has been wonderful

00:45:16,660 --> 00:45:26,500
so yeah I don't wobble software 26% of

00:45:22,480 --> 00:45:29,590
the omics so by omics that kind of thing

00:45:26,500 --> 00:45:32,830
soccer be not accessible through URLs

00:45:29,590 --> 00:45:37,080
published in a paper twenty-three

00:45:32,830 --> 00:45:39,250
percent so they did this software they

00:45:37,080 --> 00:45:41,290
did their paper on this based on this

00:45:39,250 --> 00:45:43,960
piece of software and the software is no

00:45:41,290 --> 00:45:49,210
longer available so you can't read

00:45:43,960 --> 00:45:52,690
reproduce the results forty-nine percent

00:45:49,210 --> 00:45:55,630
were deemed difficult to install I think

00:45:52,690 --> 00:45:57,220
that was a low estimate twenty eight

00:45:55,630 --> 00:45:58,660
percent of the tools failed to be

00:45:57,220 --> 00:46:04,960
installed due to problems on the

00:45:58,660 --> 00:46:07,180
implementation so what this is telling

00:46:04,960 --> 00:46:08,880
me is that it's kind of a mess out there

00:46:07,180 --> 00:46:16,300
it's in the scientific community in

00:46:08,880 --> 00:46:18,190
terms of end-user software and that's

00:46:16,300 --> 00:46:21,550
where things really need to be worked on

00:46:18,190 --> 00:46:23,500
and cleaned up unfortunately there's not

00:46:21,550 --> 00:46:26,710
exactly a lot of money out there to make

00:46:23,500 --> 00:46:34,560
that happen I wish there was because it

00:46:26,710 --> 00:46:38,770
would make my job a lot easier so that's

00:46:34,560 --> 00:46:41,310
pretty much all I have any questions any

00:46:38,770 --> 00:46:41,310
other questions

00:46:52,780 --> 00:47:01,610
right in a situation like that we aren't

00:46:59,180 --> 00:47:03,430
we've we've now hired a second person to

00:47:01,610 --> 00:47:05,570
help with that kind of situation

00:47:03,430 --> 00:47:10,870
actually he presented here last year

00:47:05,570 --> 00:47:13,460
Brian Bartholomew we hired him and I

00:47:10,870 --> 00:47:15,230
think he's gonna be a really good person

00:47:13,460 --> 00:47:17,750
for that so we actually do have people

00:47:15,230 --> 00:47:20,240
and they're more aimed at the viol

00:47:17,750 --> 00:47:21,290
community people because they're the

00:47:20,240 --> 00:47:24,410
ones that need the most help in that

00:47:21,290 --> 00:47:27,440
regard and that is one of the big things

00:47:24,410 --> 00:47:29,570
you know hey your software is eating up

00:47:27,440 --> 00:47:35,240
one and a half terabytes of RAM on this

00:47:29,570 --> 00:47:37,760
machine why with with like 1% CPU what

00:47:35,240 --> 00:47:39,380
is going on here we've seen that we have

00:47:37,760 --> 00:47:40,700
machines that are that big you know

00:47:39,380 --> 00:47:43,700
single machines that have one and a half

00:47:40,700 --> 00:47:46,990
terabytes of RAM and they're using all

00:47:43,700 --> 00:47:46,990
the memory for no reason whatsoever

00:47:47,680 --> 00:47:52,910
we've seen other things where why is

00:47:51,020 --> 00:47:57,130
your code we're supposed to be using

00:47:52,910 --> 00:48:00,680
these two GPUs not using them at all

00:47:57,130 --> 00:48:03,140
well oh look you've you're running the

00:48:00,680 --> 00:48:05,240
non GPU version of the software why are

00:48:03,140 --> 00:48:07,190
you doing that you know things like that

00:48:05,240 --> 00:48:09,920
so we have an actual full team but

00:48:07,190 --> 00:48:12,770
there's six of them almost half of our

00:48:09,920 --> 00:48:16,090
group is dedicated to dealing with those

00:48:12,770 --> 00:48:16,090
kinds of situations and problems

00:48:25,760 --> 00:48:35,190
uh-huh oh yeah oh yeah now usually it's

00:48:33,240 --> 00:48:37,890
just a small portion in the cluster but

00:48:35,190 --> 00:48:40,290
yeah we've seen you know a users running

00:48:37,890 --> 00:48:42,210
their software you know across multiple

00:48:40,290 --> 00:48:44,220
multiple machines and one of the nodes

00:48:42,210 --> 00:48:46,470
dies you know that hard drive for bad

00:48:44,220 --> 00:48:49,980
memory or something like that and it

00:48:46,470 --> 00:48:54,060
ruins those software runs the run the

00:48:49,980 --> 00:48:56,040
answer to that is well rerun it you know

00:48:54,060 --> 00:48:59,150
we've taken that note out of the cluster

00:48:56,040 --> 00:49:02,460
we're fixing it rerun your software

00:48:59,150 --> 00:49:07,170
rerun the job because we don't have time

00:49:02,460 --> 00:49:11,720
to try and you know fix that right we're

00:49:07,170 --> 00:49:11,720
not there's no point just rerun the job

00:49:13,250 --> 00:49:20,890
anything yes

00:49:16,569 --> 00:49:23,589
oh yes oh yeah cgroups well I don't know

00:49:20,890 --> 00:49:27,479
about we've been using cgroups more for

00:49:23,589 --> 00:49:30,130
security rather than actual tuning so

00:49:27,479 --> 00:49:32,859
the place that we typically use cgroups

00:49:30,130 --> 00:49:36,209
is in our job scheduler when the job

00:49:32,859 --> 00:49:38,589
runs on a note or collection of nodes

00:49:36,209 --> 00:49:41,259
the other thing that it does is set

00:49:38,589 --> 00:49:44,589
memory and well basically a memory

00:49:41,259 --> 00:49:48,069
constraints so hey I've requested a job

00:49:44,589 --> 00:49:50,829
to run and it has allocated to it I

00:49:48,069 --> 00:49:53,919
don't know eight gigs of RAM and you

00:49:50,829 --> 00:49:57,249
know it's gonna run for two days well

00:49:53,919 --> 00:49:59,799
see groups are used to limit that job to

00:49:57,249 --> 00:50:04,209
that eight gigs of RAM and if they try

00:49:59,799 --> 00:50:06,549
to exceed it it kills the job that's

00:50:04,209 --> 00:50:09,519
pretty much the limit of our real tuning

00:50:06,549 --> 00:50:23,349
for it it's more for job manipulation

00:50:09,519 --> 00:50:26,919
than anything yes and no ok we did all

00:50:23,349 --> 00:50:30,369
the kernel updates for it because that's

00:50:26,919 --> 00:50:34,900
not that's not a given however a lot of

00:50:30,369 --> 00:50:37,449
the spectrum abilities came from running

00:50:34,900 --> 00:50:40,630
hyper threading we don't do hyper

00:50:37,449 --> 00:50:44,199
threading we turned it off from the very

00:50:40,630 --> 00:50:46,589
beginning ten years ago when hyper

00:50:44,199 --> 00:50:49,390
threading came out we turn it off

00:50:46,589 --> 00:50:50,979
because what we were finding is it

00:50:49,390 --> 00:50:52,799
wasn't actually helping us it was

00:50:50,979 --> 00:50:55,689
actually hurting us to some extent

00:50:52,799 --> 00:50:58,029
because a lot of our software when we're

00:50:55,689 --> 00:51:01,119
running in well it's using up you know

00:50:58,029 --> 00:51:04,589
all 16 or 24 or 32 64 cores of the

00:51:01,119 --> 00:51:07,900
machine doing the exact same thing and

00:51:04,589 --> 00:51:09,519
with that kind of code hyperthreading

00:51:07,900 --> 00:51:15,609
doesn't help it actually hinders your

00:51:09,519 --> 00:51:18,429
processes it got better with the skylake

00:51:15,609 --> 00:51:22,209
nodes but we were still seeing the

00:51:18,429 --> 00:51:25,439
performance hit overall so yeah we

00:51:22,209 --> 00:51:25,439
turned it off many years ago

00:51:30,610 --> 00:51:34,280
globus yeah

00:51:32,960 --> 00:51:39,710
Clovis is pretty much the answer to

00:51:34,280 --> 00:51:41,450
everybody's problem there oh yes it's it

00:51:39,710 --> 00:51:45,950
sucks but it's better than pretty much

00:51:41,450 --> 00:51:48,830
anything else out there yes

00:51:45,950 --> 00:51:53,110
transfer of data between institutions or

00:51:48,830 --> 00:51:56,200
even between the user and the machine

00:51:53,110 --> 00:51:58,430
it's horrible it's a horrible situation

00:51:56,200 --> 00:52:00,620
that we do have this one thing called

00:51:58,430 --> 00:52:04,250
Clovis that we use I didn't go any

00:52:00,620 --> 00:52:06,710
detail on it but it's an automated

00:52:04,250 --> 00:52:09,050
system where you say hey I want these

00:52:06,710 --> 00:52:11,930
files transferred and it does it in the

00:52:09,050 --> 00:52:16,490
background for you hopefully as fast as

00:52:11,930 --> 00:52:18,440
it can sometimes not yeah you want to

00:52:16,490 --> 00:52:22,130
talk about data management we're talking

00:52:18,440 --> 00:52:24,200
right now purchasing a new lustre file

00:52:22,130 --> 00:52:26,800
system and we want to transfer all the

00:52:24,200 --> 00:52:31,130
data from the old one to the new one all

00:52:26,800 --> 00:52:35,450
to petabytes of it in tiny little 64k

00:52:31,130 --> 00:52:39,200
files it's not good it's not good at all

00:52:35,450 --> 00:52:42,080
so that's going to take us months to do

00:52:39,200 --> 00:52:44,870
the full transfer so if you can come up

00:52:42,080 --> 00:52:50,930
with a global file system that handles

00:52:44,870 --> 00:52:53,300
small files really well do it develop it

00:52:50,930 --> 00:52:55,400
and then sell it to somebody and you

00:52:53,300 --> 00:52:59,420
know go retire somewhere because that's

00:52:55,400 --> 00:53:01,690
what's going to happen I saw a question

00:52:59,420 --> 00:53:01,690
yes

00:53:11,049 --> 00:53:17,690
partially Hardware experience at least

00:53:14,479 --> 00:53:22,039
in my game it's some hardware experience

00:53:17,690 --> 00:53:30,019
in a more industrial world you know if

00:53:22,039 --> 00:53:31,759
you come out what anyone really strong

00:53:30,019 --> 00:53:36,589
Linux experience is pretty much required

00:53:31,759 --> 00:53:41,839
for us this group is a great source

00:53:36,589 --> 00:53:47,209
actually having some knowledge of the

00:53:41,839 --> 00:53:51,739
hardware and just knowing your stuff

00:53:47,209 --> 00:53:53,509
really and unfortunately what happens is

00:53:51,739 --> 00:53:56,239
that people that actually know what

00:53:53,509 --> 00:53:58,910
they're doing and know their know Linux

00:53:56,239 --> 00:54:04,420
and know the industry they're already

00:53:58,910 --> 00:54:04,420
hired they're already working yes

00:54:10,119 --> 00:54:13,540
is it a what

00:54:18,410 --> 00:54:25,520
where is that where is high-performance

00:54:20,780 --> 00:54:27,380
computing as a service heading we've

00:54:25,520 --> 00:54:32,510
looked at doing high-performance

00:54:27,380 --> 00:54:34,070
computing in the cloud the pricing for

00:54:32,510 --> 00:54:37,700
it unless you're doing unless you're

00:54:34,070 --> 00:54:40,250
very very bursty on your research so you

00:54:37,700 --> 00:54:41,330
know hey I need to do this one thing of

00:54:40,250 --> 00:54:43,880
researches and I'm not gonna come back

00:54:41,330 --> 00:54:45,890
for six years or six six months or

00:54:43,880 --> 00:54:47,750
something like that it's perfect for

00:54:45,890 --> 00:54:49,550
that and Amazon and all your other

00:54:47,750 --> 00:54:53,240
people they can do that for you if

00:54:49,550 --> 00:54:57,010
you're more consistent you need to be

00:54:53,240 --> 00:54:57,010
your own cluster it'll be cheaper

00:55:03,130 --> 00:55:16,340
uh-huh yes this is a problem that we are

00:55:13,130 --> 00:55:18,860
still fighting and we don't really have

00:55:16,340 --> 00:55:25,610
a solution for it tape libraries are one

00:55:18,860 --> 00:55:28,010
way to do it but it depends on your data

00:55:25,610 --> 00:55:29,120
access needs you know sometimes they

00:55:28,010 --> 00:55:31,160
just want to put it away and they'll

00:55:29,120 --> 00:55:34,250
never ever ever see it again and they'll

00:55:31,160 --> 00:55:37,160
never recall it again it's the people

00:55:34,250 --> 00:55:40,100
that do recall it okay now you've got to

00:55:37,160 --> 00:55:41,480
pull it out and typically when they want

00:55:40,100 --> 00:55:47,780
to pull that kind of data out they want

00:55:41,480 --> 00:55:57,530
it now unfortunately yes

00:55:47,780 --> 00:56:00,410
oh really realistically we don't have

00:55:57,530 --> 00:56:08,510
any compete as in types of MPI like open

00:56:00,410 --> 00:56:12,620
a MPI versus next to none with the users

00:56:08,510 --> 00:56:17,750
don't care as long as it works yeah yeah

00:56:12,620 --> 00:56:19,760
we have looked at are you talking in

00:56:17,750 --> 00:56:23,810
terms of the hardware or the more the

00:56:19,760 --> 00:56:25,730
MPI layer so okay and Peter yeah they

00:56:23,810 --> 00:56:28,070
don't care as long as it works as long

00:56:25,730 --> 00:56:29,420
as it builds they don't care and we help

00:56:28,070 --> 00:56:32,300
them build those kinds of applications

00:56:29,420 --> 00:56:37,790
those applications for using an open MPI

00:56:32,300 --> 00:56:41,330
or just any MPI they are not that common

00:56:37,790 --> 00:56:43,960
and the ones that are built out there or

00:56:41,330 --> 00:56:46,550
have the capability to use it are

00:56:43,960 --> 00:56:53,900
designed to use what we already provide

00:56:46,550 --> 00:56:58,700
so it just works telemetry from like

00:56:53,900 --> 00:57:05,980
monitoring we're using a host of

00:56:58,700 --> 00:57:05,980
different things uh Nagios is one Nagios

00:57:14,370 --> 00:57:18,760
remember what it is I tried to connect

00:57:17,110 --> 00:57:20,470
to it recently and it wasn't working for

00:57:18,760 --> 00:57:25,450
me so I just I just sort of let it drop

00:57:20,470 --> 00:57:28,170
out of my head so I sort of gave up for

00:57:25,450 --> 00:57:35,350
the most part though it's it's nag

00:57:28,170 --> 00:57:43,560
y-yeah so anything else you got one

00:57:35,350 --> 00:57:46,120
minute yes I have one omni path switch

00:57:43,560 --> 00:57:48,640
and a couple of cards for it and they

00:57:46,120 --> 00:57:51,400
were actually given to us as a test you

00:57:48,640 --> 00:57:55,480
know here try this out for us make it

00:57:51,400 --> 00:58:00,100
work we did it worked pretty much

00:57:55,480 --> 00:58:04,270
exactly as FDR did it was exactly the

00:58:00,100 --> 00:58:07,200
same and given that our entire group is

00:58:04,270 --> 00:58:11,860
has 15 years of experience each in

00:58:07,200 --> 00:58:13,330
dealing with Mellanox why do we switch

00:58:11,860 --> 00:58:15,010
at that point you know if you're if your

00:58:13,330 --> 00:58:16,690
entry level and just coming into it on

00:58:15,010 --> 00:58:18,870
me path would have been a good choice at

00:58:16,690 --> 00:58:24,850
that time right now

00:58:18,870 --> 00:58:26,850
Omni path 2 has been cancelled so yeah I

00:58:24,850 --> 00:58:31,420
wouldn't I wouldn't go to the Romney

00:58:26,850 --> 00:58:33,460
road these days we would have enjoyed

00:58:31,420 --> 00:58:35,170
seeing them actually come out with our

00:58:33,460 --> 00:58:37,030
new path to and actually competing

00:58:35,170 --> 00:58:43,230
because that would have kept Mellanox

00:58:37,030 --> 00:58:45,730
slash Nvidia pricing down a bit but

00:58:43,230 --> 00:58:50,010
right now the only game in town in terms

00:58:45,730 --> 00:58:50,010
of InfiniBand is going to be Mellanox

00:58:50,340 --> 00:58:58,600
however ethernet is starting to make

00:58:55,510 --> 00:59:02,250
roads into the area so we're now seeing

00:58:58,600 --> 00:59:02,250

YouTube URL: https://www.youtube.com/watch?v=EsW1q2qeEnU


