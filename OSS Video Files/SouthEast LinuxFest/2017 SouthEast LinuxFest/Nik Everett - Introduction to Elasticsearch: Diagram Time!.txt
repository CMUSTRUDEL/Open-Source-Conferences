Title: Nik Everett - Introduction to Elasticsearch: Diagram Time!
Publication date: 2018-04-05
Playlist: 2017 SouthEast LinuxFest
Description: 
	2017 SouthEast LinuxFest
Nik Everett
Introduction to Elasticsearch: Diagram Time!
Captions: 
	00:00:00,269 --> 00:00:05,190
the following presentation was recorded

00:00:02,669 --> 00:00:07,980
at the southeast linux fest in charlotte

00:00:05,190 --> 00:00:10,679
north carolina it is licensed under a

00:00:07,980 --> 00:00:12,570
creative commons license for more

00:00:10,679 --> 00:00:19,380
information about the southeast linux

00:00:12,570 --> 00:00:20,760
fest please visit www.flexsim.com it's

00:00:19,380 --> 00:00:23,220
fast would like to thank the following

00:00:20,760 --> 00:00:26,010
diamond sponsors for helping make these

00:00:23,220 --> 00:00:29,400
videos possible oh yeah I was going to

00:00:26,010 --> 00:00:37,770
say it's 90 mm convention on a Friday

00:00:29,400 --> 00:00:41,309
it's early so welcome anyway let me get

00:00:37,770 --> 00:00:45,809
back to my hand my script so I'm a Nick

00:00:41,309 --> 00:00:48,120
Everett a paid full-time contributing an

00:00:45,809 --> 00:00:50,969
okay kid I'm a paid full-time

00:00:48,120 --> 00:00:53,219
contributing to research I work for

00:00:50,969 --> 00:00:55,379
elastic before that I work for the

00:00:53,219 --> 00:01:10,080
Wikimedia Foundation on search and

00:00:55,379 --> 00:01:11,850
that's one so I've been contributing to

00:01:10,080 --> 00:01:12,390
elastic search on and off for about four

00:01:11,850 --> 00:01:15,420
years

00:01:12,390 --> 00:01:17,400
just under at this point so my plan

00:01:15,420 --> 00:01:20,759
today is to show you at a high level how

00:01:17,400 --> 00:01:22,470
elastic search works and my goal is to

00:01:20,759 --> 00:01:24,330
put as many diagrams and data structures

00:01:22,470 --> 00:01:28,110
in front of you as you can take and

00:01:24,330 --> 00:01:35,930
Friday my guess is that's about 25

00:01:28,110 --> 00:01:38,759
minutes so on and then let's do it

00:01:35,930 --> 00:01:41,189
so before I get to diagrams and data

00:01:38,759 --> 00:01:43,979
structures okay what elasticsearch is at

00:01:41,189 --> 00:01:45,509
least what we call it we say that

00:01:43,979 --> 00:01:47,759
elastic search is a distributed search

00:01:45,509 --> 00:01:50,250
and analytics engine we don't say it's a

00:01:47,759 --> 00:01:54,240
database people get angry when we say

00:01:50,250 --> 00:01:55,619
that so I highly words because because

00:01:54,240 --> 00:01:57,960
they're important I'm gonna kind of

00:01:55,619 --> 00:02:00,210
define them and as a thread throughout

00:01:57,960 --> 00:02:03,719
the rest of this talk I'll make them

00:02:00,210 --> 00:02:05,880
make more sense so loosely distributed

00:02:03,719 --> 00:02:09,179
here means that the data stored on

00:02:05,880 --> 00:02:11,730
multiple computers multiple nodes

00:02:09,179 --> 00:02:12,730
multiple processes that communicate over

00:02:11,730 --> 00:02:16,190
the network

00:02:12,730 --> 00:02:18,290
we live on separate Hardware this

00:02:16,190 --> 00:02:20,180
Hardware all has to live in the same

00:02:18,290 --> 00:02:23,120
data center at least at this point yes

00:02:20,180 --> 00:02:27,680
we're slowly getting to the point where

00:02:23,120 --> 00:02:29,180
we have cluster replication which it

00:02:27,680 --> 00:02:31,310
would allow us to replicate outside of

00:02:29,180 --> 00:02:33,380
the data and just very recently we have

00:02:31,310 --> 00:02:37,700
the ability to do the cross cluster

00:02:33,380 --> 00:02:40,610
search outside of the data center so

00:02:37,700 --> 00:02:43,040
search here means that elasticsearch has

00:02:40,610 --> 00:02:45,890
fancy full-text search mostly analysis

00:02:43,040 --> 00:02:48,350
and scoring now we'll get in a little

00:02:45,890 --> 00:02:51,650
bit of depth about analysis but I won't

00:02:48,350 --> 00:02:54,620
go into a ton of depth about scoring the

00:02:51,650 --> 00:02:57,890
upshot about scoring is in a normal

00:02:54,620 --> 00:03:00,410
database and in a normal system when you

00:02:57,890 --> 00:03:02,630
say I want to find all the documents

00:03:00,410 --> 00:03:04,460
that look like this you get back all the

00:03:02,630 --> 00:03:08,120
documents that look like this it

00:03:04,460 --> 00:03:10,820
arbitrarily yeah in whatever are in this

00:03:08,120 --> 00:03:12,980
system but elasticsearch doesn't do that

00:03:10,820 --> 00:03:15,560
is you can ask you to sort of

00:03:12,980 --> 00:03:18,980
arbitrarily but it the default is this

00:03:15,560 --> 00:03:21,650
sort maddest thing or score is applying

00:03:18,980 --> 00:03:25,310
math to your query and the document to

00:03:21,650 --> 00:03:28,400
come up with some relative scores across

00:03:25,310 --> 00:03:32,870
the other so it tries to give you the

00:03:28,400 --> 00:03:34,280
bestest document analytics here means

00:03:32,870 --> 00:03:35,750
that elasticsearch supports some fancy

00:03:34,280 --> 00:03:39,170
ways to aggregate you data and slice and

00:03:35,750 --> 00:03:41,900
dice those aggregations I won't go too

00:03:39,170 --> 00:03:43,400
deeply into depth about all the

00:03:41,900 --> 00:03:44,840
aggregations you can do you can look

00:03:43,400 --> 00:03:46,790
those up online there's no point in

00:03:44,840 --> 00:03:49,280
coming to listen to me

00:03:46,790 --> 00:03:50,140
for those but I will talk about how the

00:03:49,280 --> 00:03:52,760
aggregations

00:03:50,140 --> 00:03:55,100
how the aggregations work and the data

00:03:52,760 --> 00:03:56,989
structures that make them go and I'll

00:03:55,100 --> 00:04:01,880
give you some sort of basic example to

00:03:56,989 --> 00:04:05,060
the aggregations as you go so still not

00:04:01,880 --> 00:04:10,670
dive time the API looks like this you

00:04:05,060 --> 00:04:13,910
interact with it with HTTP you don't

00:04:10,670 --> 00:04:15,080
actually the rhythm at HTTP and because

00:04:13,910 --> 00:04:17,900
everyone can read curl

00:04:15,080 --> 00:04:21,049
I put karo on here and actually this is

00:04:17,900 --> 00:04:23,120
like a running theme years ago the only

00:04:21,049 --> 00:04:24,350
way you could file a bug report against

00:04:23,120 --> 00:04:26,210
the last exertion was with curl

00:04:24,350 --> 00:04:30,130
they were like dozen

00:04:26,210 --> 00:04:32,630
of well right now there are two dozen

00:04:30,130 --> 00:04:33,889
API like two dozen libraries that you

00:04:32,630 --> 00:04:35,360
can use to interact with elasticsearch

00:04:33,889 --> 00:04:36,740
right there's like a Java one and

00:04:35,360 --> 00:04:39,169
there's a scalar one and there's a

00:04:36,740 --> 00:04:41,599
Haskell one and there's a JavaScript is

00:04:39,169 --> 00:04:43,580
I bet that there's tons of them but I

00:04:41,599 --> 00:04:45,440
can only read a couple of programming

00:04:43,580 --> 00:04:46,310
languages and if you come to me with you

00:04:45,440 --> 00:04:48,680
know your weird

00:04:46,310 --> 00:04:51,620
Ruby with all this strange magic that's

00:04:48,680 --> 00:04:53,410
inside I can't help you right so the bug

00:04:51,620 --> 00:04:56,240
reports have to be filed with curl

00:04:53,410 --> 00:04:58,250
because everyone can read curl or at

00:04:56,240 --> 00:04:59,960
least kind of can read curl you can

00:04:58,250 --> 00:05:01,520
figure it out and most people can get a

00:04:59,960 --> 00:05:05,860
bash console and just paste it in and

00:05:01,520 --> 00:05:05,860
make it happen so this way it's curl

00:05:06,460 --> 00:05:17,750
umm.we so back to back a little bit we

00:05:15,620 --> 00:05:20,930
say on the on the github site that

00:05:17,750 --> 00:05:23,389
elasticsearch is a restful voila blah

00:05:20,930 --> 00:05:28,099
blah blah distributed analytics engine

00:05:23,389 --> 00:05:30,530
we say restful realistically what that

00:05:28,099 --> 00:05:32,900
means is that we pay attention to HTTP

00:05:30,530 --> 00:05:36,860
verbs we try to be standards compliant

00:05:32,900 --> 00:05:38,330
to the HTTP spec and we borrow restful

00:05:36,860 --> 00:05:40,520
concepts when they make sense and we

00:05:38,330 --> 00:05:41,960
totally ignore them when they don't and

00:05:40,520 --> 00:05:43,310
when you come to us and you're pedantic

00:05:41,960 --> 00:05:48,800
and you say this is not a restful

00:05:43,310 --> 00:05:51,380
database we say ok it isn't but this

00:05:48,800 --> 00:05:54,979
this actually is quite restful look what

00:05:51,380 --> 00:05:58,370
you put the document where you want it

00:05:54,979 --> 00:06:03,199
to be so this is a document here I'm way

00:05:58,370 --> 00:06:04,789
out of frame I you put the the the

00:06:03,199 --> 00:06:09,380
document see the thing and I look close

00:06:04,789 --> 00:06:11,690
the G that's the thing you're indexing

00:06:09,380 --> 00:06:16,729
you use an ATP put to put it in this

00:06:11,690 --> 00:06:20,570
three part URL so you see I've put in

00:06:16,729 --> 00:06:23,330
pink on the fourth line three things

00:06:20,570 --> 00:06:25,909
that's the that's the location of your

00:06:23,330 --> 00:06:27,590
document the first one is called the

00:06:25,909 --> 00:06:29,090
index the second one is called the

00:06:27,590 --> 00:06:32,599
height and the third one is called the

00:06:29,090 --> 00:06:35,700
ID they are all strings to us even

00:06:32,599 --> 00:06:40,500
though that's a one that's a string

00:06:35,700 --> 00:06:40,860
they don't care that it's another so

00:06:40,500 --> 00:06:43,950
yeah

00:06:40,860 --> 00:06:46,320
Ian wiki on this slide is the type or is

00:06:43,950 --> 00:06:51,230
the index sorry doc is the type and one

00:06:46,320 --> 00:06:54,450
is the ID all right

00:06:51,230 --> 00:06:56,100
so nowadays you actually can file bug

00:06:54,450 --> 00:06:57,720
reports against elastic search using

00:06:56,100 --> 00:06:59,490
another syntax this is the only other

00:06:57,720 --> 00:07:01,560
syntax that we will really accept your

00:06:59,490 --> 00:07:03,510
file bug reports and this is this funny

00:07:01,560 --> 00:07:06,510
reduced syntax that's supported by

00:07:03,510 --> 00:07:08,460
cubanos development tools and I'm gonna

00:07:06,510 --> 00:07:11,780
use that syntax this syntax from here on

00:07:08,460 --> 00:07:20,010
out because it's a lot shorter than this

00:07:11,780 --> 00:07:22,260
and it says anything so with maybe two

00:07:20,010 --> 00:07:23,970
reg X's and the half-dozen lines of

00:07:22,260 --> 00:07:26,700
JavaScript you can turn this into a curl

00:07:23,970 --> 00:07:28,020
command there's actually a button so in

00:07:26,700 --> 00:07:30,690
all the elasticsearch documentation

00:07:28,020 --> 00:07:33,060
looks like this there's a button on the

00:07:30,690 --> 00:07:36,260
website that says copy as curl it's like

00:07:33,060 --> 00:07:39,060
I wrote it it's like one wrench eggs and

00:07:36,260 --> 00:07:43,020
twelve lines of JavaScript it's not so

00:07:39,060 --> 00:07:44,520
bad but I'm gonna use this this way of

00:07:43,020 --> 00:07:46,040
writing it to save space so that you

00:07:44,520 --> 00:07:49,760
know if I write the content type and

00:07:46,040 --> 00:07:52,380
curl - age and all the other stuff

00:07:49,760 --> 00:07:54,060
sometimes I use curl to interact with

00:07:52,380 --> 00:07:56,340
elasticsearch sometimes I use kevanna to

00:07:54,060 --> 00:07:58,250
interact with elasticsearch use curl if

00:07:56,340 --> 00:08:02,130
I ever want to write a loop especially

00:07:58,250 --> 00:08:07,410
you know that's good anyway finally

00:08:02,130 --> 00:08:09,000
diagram time so this this command here

00:08:07,410 --> 00:08:11,880
where you where you put the document at

00:08:09,000 --> 00:08:14,700
a URL this is physically what happens

00:08:11,880 --> 00:08:17,970
you pick a random node any node you want

00:08:14,700 --> 00:08:19,230
doesn't matter and you throw the

00:08:17,970 --> 00:08:22,830
document like that little man that I

00:08:19,230 --> 00:08:28,290
made into any one of your notes doesn't

00:08:22,830 --> 00:08:30,600
matter and it will take it will take

00:08:28,290 --> 00:08:32,640
that three part URL and the first thing

00:08:30,600 --> 00:08:35,340
it does is it looks at the index so an

00:08:32,640 --> 00:08:37,910
index in elasticsearch is a collection

00:08:35,340 --> 00:08:40,560
of documents configured a certain way

00:08:37,910 --> 00:08:44,010
when you talk to elastic searches api

00:08:40,560 --> 00:08:45,360
you talk about indexes on disk elastic

00:08:44,010 --> 00:08:47,340
said I mean unless you search she cares

00:08:45,360 --> 00:08:49,200
about indexes but internally elastic

00:08:47,340 --> 00:08:49,680
search cares a lot more about shards

00:08:49,200 --> 00:08:51,779
which

00:08:49,680 --> 00:08:53,430
how the indexes are broken up this

00:08:51,779 --> 00:08:57,350
picture if you remove all of the arrows

00:08:53,430 --> 00:09:01,320
is of that Ian wiki index from the

00:08:57,350 --> 00:09:04,830
previous slides charted two ways

00:09:01,320 --> 00:09:09,930
replicated two ways so it may be largely

00:09:04,830 --> 00:09:13,410
but nodes 0 has e'en wiki in wiki's 0

00:09:09,930 --> 00:09:17,100
replicas and node one also has the other

00:09:13,410 --> 00:09:20,520
copy of Ian's with 0 replicas and then

00:09:17,100 --> 00:09:25,560
Ian wiki's 1 replicas on the 0 and you

00:09:20,520 --> 00:09:28,260
get the idea so when you go to put a

00:09:25,560 --> 00:09:31,050
document in the index elasticsearch

00:09:28,260 --> 00:09:34,529
takes the type and the ID squashes them

00:09:31,050 --> 00:09:37,140
together hashes them and mods them by

00:09:34,529 --> 00:09:40,380
the number of shards and pitches them on

00:09:37,140 --> 00:09:42,660
to that charm so what it'll do is it

00:09:40,380 --> 00:09:45,089
will forward the the indexing request

00:09:42,660 --> 00:09:49,320
from the node that you sent the document

00:09:45,089 --> 00:09:51,510
soon whichever one it was to the node to

00:09:49,320 --> 00:09:53,610
a node with a copy of the appropriate

00:09:51,510 --> 00:09:56,370
you are so in this case my little

00:09:53,610 --> 00:09:58,500
picture says that Ian's wiki doc one I

00:09:56,370 --> 00:10:06,900
am assuming that it hashes and goes into

00:09:58,500 --> 00:10:08,520
the two the one shard so when we have so

00:10:06,900 --> 00:10:09,810
in our case we have two shards you can

00:10:08,520 --> 00:10:11,040
have more it's fine doesn't matter

00:10:09,810 --> 00:10:13,680
oh sorry our case you can have two

00:10:11,040 --> 00:10:15,870
replicas you can have more it's fine but

00:10:13,680 --> 00:10:18,510
only one of those replicas is the

00:10:15,870 --> 00:10:22,800
primary replica and that is the replica

00:10:18,510 --> 00:10:27,959
that gets the document first so what it

00:10:22,800 --> 00:10:30,900
does is it drops the speaks of documents

00:10:27,959 --> 00:10:32,610
in that replica strands log it F sinks

00:10:30,900 --> 00:10:34,200
the trans log and buffers the document

00:10:32,610 --> 00:10:36,140
to be added to search and then fires off

00:10:34,200 --> 00:10:40,200
the request to go to the other replicas

00:10:36,140 --> 00:10:42,720
so I don't know if I can I can't stick

00:10:40,200 --> 00:10:44,310
my mouse over there anyway that firing

00:10:42,720 --> 00:10:47,029
the document off to go to the other

00:10:44,310 --> 00:10:50,279
replicas this bottom left pink arrow

00:10:47,029 --> 00:10:54,300
pink is our color so I get to use pink

00:10:50,279 --> 00:10:58,740
while my highlight that's great so the

00:10:54,300 --> 00:11:00,510
shard number one or sorry node 2 which

00:10:58,740 --> 00:11:02,670
is this replica shard does the same

00:11:00,510 --> 00:11:03,390
thing as the first shot did sticks the

00:11:02,670 --> 00:11:04,860
document in the Train

00:11:03,390 --> 00:11:06,570
log F stinks the trans log buffers the

00:11:04,860 --> 00:11:10,710
document to be written and then it

00:11:06,570 --> 00:11:13,560
replies back to node 1 or back to node 0

00:11:10,710 --> 00:11:15,330
sorry which had the primary and then the

00:11:13,560 --> 00:11:16,560
primary collects all of the replies from

00:11:15,330 --> 00:11:19,260
all the replicas in this case there's

00:11:16,560 --> 00:11:21,060
one and it immediately replies back to

00:11:19,260 --> 00:11:23,100
the user so you see this with

00:11:21,060 --> 00:11:25,170
elasticsearch all the time internally

00:11:23,100 --> 00:11:27,090
you make a request to some random node

00:11:25,170 --> 00:11:30,270
that random node forwards the request to

00:11:27,090 --> 00:11:31,830
the appropriate spot or maybe that

00:11:30,270 --> 00:11:34,050
random node Forks the request out to a

00:11:31,830 --> 00:11:35,970
bunch of places they come back and then

00:11:34,050 --> 00:11:39,780
it all sort of reverses so it's very

00:11:35,970 --> 00:11:42,360
much a the request goes out whittles

00:11:39,780 --> 00:11:46,650
around the cluster some and then the

00:11:42,360 --> 00:11:48,930
whole path is reversed so getting a

00:11:46,650 --> 00:11:52,710
document looks fairly similar to putting

00:11:48,930 --> 00:11:55,620
a document same thing happens you look

00:11:52,710 --> 00:11:57,840
up the index bye-bye of all the plays in

00:11:55,620 --> 00:12:00,930
the URL you take the type and the ID in

00:11:57,840 --> 00:12:04,080
hashem and you pick a shard in this case

00:12:00,930 --> 00:12:08,540
though elastic starts round robins which

00:12:04,080 --> 00:12:10,530
of the copies the gate comes from so

00:12:08,540 --> 00:12:12,630
even though you sent the request to node

00:12:10,530 --> 00:12:14,520
0 we still round robin it sometimes he

00:12:12,630 --> 00:12:17,910
goes to node 1 sometimes it goes to node

00:12:14,520 --> 00:12:19,050
1 sometimes it goes to node 0 matter or

00:12:17,910 --> 00:12:21,680
at least to us it doesn't matter

00:12:19,050 --> 00:12:26,040
maybe this to you but this is what we do

00:12:21,680 --> 00:12:29,460
and then node 1 fetches the document off

00:12:26,040 --> 00:12:32,670
the disk and replies to replies to node

00:12:29,460 --> 00:12:34,410
0 which then replies to you so the thing

00:12:32,670 --> 00:12:37,260
you get back is pretty much what you put

00:12:34,410 --> 00:12:40,140
in plus some metadata we put in stuff

00:12:37,260 --> 00:12:42,150
like the we add like a version into the

00:12:40,140 --> 00:12:43,620
document and we tell you what index it

00:12:42,150 --> 00:12:45,300
was stored in and a couple other things

00:12:43,620 --> 00:12:49,880
but you mostly just get back the source

00:12:45,300 --> 00:12:52,290
that you gave us so get is pretty boring

00:12:49,880 --> 00:12:57,420
let's do searches they're much more fun

00:12:52,290 --> 00:13:02,640
come on it's 9 a.m. 9 13 a.m. so this is

00:12:57,420 --> 00:13:06,450
a very simple basic search keeping in

00:13:02,640 --> 00:13:08,850
rest land or rest parlance you post to a

00:13:06,450 --> 00:13:10,440
special search endpoint I'm not sure if

00:13:08,850 --> 00:13:14,370
this is appropriate from a rest

00:13:10,440 --> 00:13:17,210
standpoint but it's what we do and then

00:13:14,370 --> 00:13:19,470
you give a JSON structure that

00:13:17,210 --> 00:13:21,420
describes the search that you want to do

00:13:19,470 --> 00:13:24,680
in this case this search says do all of

00:13:21,420 --> 00:13:28,710
the hold things Plus at a query that

00:13:24,680 --> 00:13:31,350
only returns documents that have the

00:13:28,710 --> 00:13:34,980
word small and domestic in their text

00:13:31,350 --> 00:13:39,840
field so let's go back and look at our

00:13:34,980 --> 00:13:42,420
cat document here so we are we have

00:13:39,840 --> 00:13:46,470
three fields here a title a text and a

00:13:42,420 --> 00:13:52,800
popularity score the text in this case

00:13:46,470 --> 00:13:54,210
has small and domestic so what I'm

00:13:52,800 --> 00:14:01,740
trying to do is make a search that will

00:13:54,210 --> 00:14:03,840
find this document oh and the other

00:14:01,740 --> 00:14:06,510
thing is that it ranks the ranks all the

00:14:03,840 --> 00:14:08,250
documents forever closed ranks occupants

00:14:06,510 --> 00:14:10,050
based on how small and as domestic they

00:14:08,250 --> 00:14:12,150
are and he gives you the top ten because

00:14:10,050 --> 00:14:15,090
that's the default this is how search

00:14:12,150 --> 00:14:19,880
works isn't it exciting the little man

00:14:15,090 --> 00:14:22,890
the roses request at node zero again and

00:14:19,880 --> 00:14:25,860
the first thing we have to we do is pick

00:14:22,890 --> 00:14:28,500
the index again and then we talk to all

00:14:25,860 --> 00:14:32,760
the shots same deal you see round robin

00:14:28,500 --> 00:14:37,410
again which shirt you talk to but up to

00:14:32,760 --> 00:14:39,090
the the shard zero and the shard one all

00:14:37,410 --> 00:14:40,770
right we can talk any replica of the

00:14:39,090 --> 00:14:41,940
shard zero or the shard one but we have

00:14:40,770 --> 00:14:45,200
to talk to both showed zero in the short

00:14:41,940 --> 00:14:48,840
one because we don't know on which shard

00:14:45,200 --> 00:14:51,120
has the best small and domestic

00:14:48,840 --> 00:14:52,740
documents in this case since we only put

00:14:51,120 --> 00:14:55,350
one document in the index we just don't

00:14:52,740 --> 00:14:59,040
even know which shard has any documents

00:14:55,350 --> 00:15:02,250
that so first we contact all these nodes

00:14:59,040 --> 00:15:03,570
each each shard individually counts all

00:15:02,250 --> 00:15:05,460
the matching documents and make the

00:15:03,570 --> 00:15:08,370
priority queue of the highest scoring

00:15:05,460 --> 00:15:10,080
documents returns that the node where

00:15:08,370 --> 00:15:11,760
you sent the original request merges the

00:15:10,080 --> 00:15:13,500
priority queue of the score documents

00:15:11,760 --> 00:15:14,970
now the next thing that makes is more

00:15:13,500 --> 00:15:16,650
complicated is actually in optimization

00:15:14,970 --> 00:15:19,830
but it's very important optimization

00:15:16,650 --> 00:15:21,750
I'll get into in more depth so the

00:15:19,830 --> 00:15:23,550
second thing that it does is that that

00:15:21,750 --> 00:15:24,930
node node zero that you originally sent

00:15:23,550 --> 00:15:27,240
the request to after it merges the

00:15:24,930 --> 00:15:29,220
priority queues together turns back

00:15:27,240 --> 00:15:32,279
around and requests from

00:15:29,220 --> 00:15:36,720
want to know to the actual body of the

00:15:32,279 --> 00:15:37,980
documents to return to you and you may

00:15:36,720 --> 00:15:40,019
be thinking oh that's cute right it's

00:15:37,980 --> 00:15:41,610
saving on some network transmission it

00:15:40,019 --> 00:15:43,019
doesn't have to send all of the

00:15:41,610 --> 00:15:44,639
documents and that's going to save a lot

00:15:43,019 --> 00:15:46,050
of network transmission if there are

00:15:44,639 --> 00:15:48,899
many shards or if the documents are

00:15:46,050 --> 00:15:50,939
large right so say say you've had 10

00:15:48,899 --> 00:15:51,990
shards and they all made this priority

00:15:50,939 --> 00:15:53,370
queue of documents and then they all

00:15:51,990 --> 00:15:55,439
sent back the bodies of all the

00:15:53,370 --> 00:15:58,620
documents it would be a fair amount of

00:15:55,439 --> 00:16:01,079
network overhead that you don't need but

00:15:58,620 --> 00:16:10,889
it's actually much more important than

00:16:01,079 --> 00:16:12,899
that oh it happens - in this case but it

00:16:10,889 --> 00:16:17,180
can't serve the full text of the

00:16:12,899 --> 00:16:20,129
document it's I will explain in a minute

00:16:17,180 --> 00:16:23,430
um this is actually a sequence diagram

00:16:20,129 --> 00:16:25,230
of the thing that I just described

00:16:23,430 --> 00:16:28,079
right so you send the request off to

00:16:25,230 --> 00:16:29,370
node 1 it Forks the request off so you

00:16:28,079 --> 00:16:30,899
send the request to node 0 all right

00:16:29,370 --> 00:16:34,110
it Forks the request to node 1 and node

00:16:30,899 --> 00:16:35,910
2 for the query the query phase is that

00:16:34,110 --> 00:16:37,439
thing that goes and builds the priority

00:16:35,910 --> 00:16:39,720
queue identifies two hits it comes back

00:16:37,439 --> 00:16:42,209
they come back asynchronously and when

00:16:39,720 --> 00:16:44,759
the last one comes back we kick off that

00:16:42,209 --> 00:16:46,079
fetch phase where we go oh well first we

00:16:44,759 --> 00:16:47,579
merge the priority queue is once enough

00:16:46,079 --> 00:16:49,559
of them have come back and then we kick

00:16:47,579 --> 00:16:50,759
off the fetch phase to go fetch those

00:16:49,559 --> 00:16:53,180
documents and when they finally come

00:16:50,759 --> 00:16:55,559
back we were planning to use it to you

00:16:53,180 --> 00:17:00,480
my notes say I should be 9 minutes and

00:16:55,559 --> 00:17:03,149
17 so this is going well um

00:17:00,480 --> 00:17:04,500
I would I promise I will get to your

00:17:03,149 --> 00:17:08,429
your answer very soon

00:17:04,500 --> 00:17:09,630
so it's now time to talk about data

00:17:08,429 --> 00:17:11,039
structures and the reason it's time to

00:17:09,630 --> 00:17:13,500
talk about data structures is I want to

00:17:11,039 --> 00:17:16,110
make it clear why we have to do this

00:17:13,500 --> 00:17:21,360
two-phase thing but to do that I just

00:17:16,110 --> 00:17:24,600
sort of how the queries work and how

00:17:21,360 --> 00:17:27,929
fetching the source works and then I'll

00:17:24,600 --> 00:17:30,150
get to your answer so these data

00:17:27,929 --> 00:17:31,679
structures are all internally maintained

00:17:30,150 --> 00:17:33,929
on every shard each shard gets its own

00:17:31,679 --> 00:17:35,549
copy of the data structures and builds

00:17:33,929 --> 00:17:37,830
it when when or rather each shard

00:17:35,549 --> 00:17:41,730
internally grows its own copies of the

00:17:37,830 --> 00:17:42,809
data structures and they they diverge so

00:17:41,730 --> 00:17:45,600
so

00:17:42,809 --> 00:17:48,169
sharp copy the first char the primary

00:17:45,600 --> 00:17:50,129
char copy and the replica shard copies

00:17:48,169 --> 00:17:51,629
potentially have totally different on

00:17:50,129 --> 00:17:55,350
dis structures representing the same

00:17:51,629 --> 00:17:57,870
data because they well because we only

00:17:55,350 --> 00:18:00,059
replicate the actions that are add this

00:17:57,870 --> 00:18:01,830
document and delete this document it's

00:18:00,059 --> 00:18:06,590
things like that we don't replicate the

00:18:01,830 --> 00:18:09,389
actual on disk files most of the time so

00:18:06,590 --> 00:18:12,690
the other sort of nice thing to know is

00:18:09,389 --> 00:18:16,019
that internally so inside this shard

00:18:12,690 --> 00:18:18,330
every document has an integer ID that's

00:18:16,019 --> 00:18:24,440
a it's a signed int even though we only

00:18:18,330 --> 00:18:29,340
use the 31 bits of it but it's a sign in

00:18:24,440 --> 00:18:30,539
and each document gets a different ID on

00:18:29,340 --> 00:18:34,649
a different char because we're not

00:18:30,539 --> 00:18:36,389
replicating the the actual on the

00:18:34,649 --> 00:18:38,429
structure again we're replicating the

00:18:36,389 --> 00:18:40,350
the please add this document to this

00:18:38,429 --> 00:18:46,830
index and so they will get a different

00:18:40,350 --> 00:18:48,419
synthetic integer ID so wow I talked

00:18:46,830 --> 00:18:52,730
about integer IDs

00:18:48,419 --> 00:18:56,039
this is actually how text search is done

00:18:52,730 --> 00:18:58,649
this is a data structure called a finite

00:18:56,039 --> 00:19:03,480
state transducer it's a really fancy

00:18:58,649 --> 00:19:06,539
name but yeah you have a computer

00:19:03,480 --> 00:19:08,299
science degree you have seen a finite

00:19:06,539 --> 00:19:14,340
automata before that's a thing that's

00:19:08,299 --> 00:19:16,830
designed to say this part say this word

00:19:14,340 --> 00:19:17,899
is part of this grammar it looks a lot

00:19:16,830 --> 00:19:22,289
like this too

00:19:17,899 --> 00:19:24,539
essentially there's some every time you

00:19:22,289 --> 00:19:26,159
want every time you you want to look up

00:19:24,539 --> 00:19:29,460
a letter say I wanted to look up the

00:19:26,159 --> 00:19:31,080
word cap I start at the root and I move

00:19:29,460 --> 00:19:34,409
over into the node that's the

00:19:31,080 --> 00:19:38,009
appropriate lady alright so I could

00:19:34,409 --> 00:19:39,960
trace cat up to see a and T and then I

00:19:38,009 --> 00:19:42,179
see that cat because that's the end of

00:19:39,960 --> 00:19:45,480
my word I know I'm done so I can follow

00:19:42,179 --> 00:19:47,580
the link out of it into the data

00:19:45,480 --> 00:19:50,850
structure that has points too so a

00:19:47,580 --> 00:19:51,480
finite state automata only has a yes or

00:19:50,850 --> 00:19:54,000
a No

00:19:51,480 --> 00:19:56,280
at the end of these at the end of its

00:19:54,000 --> 00:19:58,530
chains and a finite state transducer

00:19:56,280 --> 00:20:01,230
has a data structure at the end of its

00:19:58,530 --> 00:20:03,630
chain so instead of saying yes this is

00:20:01,230 --> 00:20:05,040
part of this grammar it says it is part

00:20:03,630 --> 00:20:07,560
of this grammar and you can go learn

00:20:05,040 --> 00:20:08,730
more about it over here so at the end of

00:20:07,560 --> 00:20:12,570
it at the end of this finite state

00:20:08,730 --> 00:20:15,000
transducer we have a list of document

00:20:12,570 --> 00:20:19,590
IDs these are IDs that have that have

00:20:15,000 --> 00:20:21,480
the term in them so ah just for

00:20:19,590 --> 00:20:24,120
illustrative purposes we're going to say

00:20:21,480 --> 00:20:25,590
that our document is one because it's

00:20:24,120 --> 00:20:26,940
the first one we stuck in the index so

00:20:25,590 --> 00:20:30,900
let's just call it what does that make

00:20:26,940 --> 00:20:33,390
so much easier and so you can see that

00:20:30,900 --> 00:20:36,660
the word carnivore is also represented

00:20:33,390 --> 00:20:40,670
in this structure I put a dot dot dots

00:20:36,660 --> 00:20:44,490
over here so it shares the prefix and so

00:20:40,670 --> 00:20:46,590
text searches but like a regular regular

00:20:44,490 --> 00:20:47,190
search for a term that says like I want

00:20:46,590 --> 00:20:50,010
to look up the word

00:20:47,190 --> 00:20:51,960
cat it actually just walks this data

00:20:50,010 --> 00:20:54,020
structure and then it gets the in and it

00:20:51,960 --> 00:20:57,360
moves on and it jumps to jumps to the

00:20:54,020 --> 00:21:00,210
the Associated data a prefix search

00:20:57,360 --> 00:21:03,090
walks to the end of the prefix and then

00:21:00,210 --> 00:21:04,320
it iterates over this whole tree finding

00:21:03,090 --> 00:21:06,180
all of the terms that are in there

00:21:04,320 --> 00:21:10,100
merges the document list of all the

00:21:06,180 --> 00:21:15,270
terms together and what's that reg X's

00:21:10,100 --> 00:21:16,950
create a deterministic finite automata

00:21:15,270 --> 00:21:21,210
and intersect the deterministic finite

00:21:16,950 --> 00:21:23,370
automata did the finite state transducer

00:21:21,210 --> 00:21:24,930
which is actually that's a lot of really

00:21:23,370 --> 00:21:27,240
fancy words but it's not all that

00:21:24,930 --> 00:21:30,950
complicated the way the way does it

00:21:27,240 --> 00:21:30,950
they're sort of built to be intersected

00:21:31,760 --> 00:21:38,340
so there are a bunch of other days

00:21:34,230 --> 00:21:39,540
strung out of elastic search that how

00:21:38,340 --> 00:21:40,470
are these queries but I'm not really

00:21:39,540 --> 00:21:44,700
gonna get into them because I'm

00:21:40,470 --> 00:21:46,530
absolutely not an expert in them but I

00:21:44,700 --> 00:21:49,620
will name-drop they're kind of cool you

00:21:46,530 --> 00:21:51,600
can go look them up if you want if you

00:21:49,620 --> 00:21:53,940
want to do a phrase query that is say I

00:21:51,600 --> 00:21:56,940
want to look for documents that have the

00:21:53,940 --> 00:21:59,630
word cat and then the word word cat and

00:21:56,940 --> 00:22:02,400
then the word carnivorous right after it

00:21:59,630 --> 00:22:04,710
to do that not only do you have to do

00:22:02,400 --> 00:22:07,320
these term will gums but then you have

00:22:04,710 --> 00:22:08,830
to go to another data structure which

00:22:07,320 --> 00:22:10,720
there's

00:22:08,830 --> 00:22:12,610
not shown here but there's actually a

00:22:10,720 --> 00:22:15,010
link to that data structure from the end

00:22:12,610 --> 00:22:16,990
today these journalists and that data

00:22:15,010 --> 00:22:19,780
structure is a skip list that contains

00:22:16,990 --> 00:22:22,060
all of the positions of all of the

00:22:19,780 --> 00:22:26,530
documents or all of the positions of the

00:22:22,060 --> 00:22:32,020
terms within the documents so let's look

00:22:26,530 --> 00:22:34,240
at our cat document the term the V would

00:22:32,020 --> 00:22:37,840
be at position 0 the term domestic at

00:22:34,240 --> 00:22:40,210
position 1 the term cat at position 2 so

00:22:37,840 --> 00:22:43,510
these positions are saved and they're

00:22:40,210 --> 00:22:45,070
used to power these phrase searches the

00:22:43,510 --> 00:22:47,410
other interesting data structure that we

00:22:45,070 --> 00:22:49,600
get is something called a bkd tree which

00:22:47,410 --> 00:22:52,150
is like a binary tree but but

00:22:49,600 --> 00:22:55,600
generalized to work in multiple

00:22:52,150 --> 00:22:58,120
dimensions so if you just have like if

00:22:55,600 --> 00:22:59,200
you're just indexing a number then it

00:22:58,120 --> 00:23:02,100
just sort of looks like a binary tree

00:22:59,200 --> 00:23:04,120
but if you're indexing a shape or a

00:23:02,100 --> 00:23:04,390
position on the earth or something like

00:23:04,120 --> 00:23:07,330
that

00:23:04,390 --> 00:23:09,460
then it looks more complex and I don't

00:23:07,330 --> 00:23:10,600
actually know how they work but I will

00:23:09,460 --> 00:23:15,160
name check them so you can look them up

00:23:10,600 --> 00:23:17,620
if you want but the take-home message

00:23:15,160 --> 00:23:22,030
from this slide is that what a query

00:23:17,620 --> 00:23:24,280
does is it finds those integer IDs it

00:23:22,030 --> 00:23:26,080
doesn't find the ID that you gave us it

00:23:24,280 --> 00:23:28,590
finds this synthetic integer ID that we

00:23:26,080 --> 00:23:31,060
made up when you handed a document to us

00:23:28,590 --> 00:23:33,190
and it doesn't find the documents text

00:23:31,060 --> 00:23:35,290
the documents text is off somewhere else

00:23:33,190 --> 00:23:38,080
in fact the documents text is stored in

00:23:35,290 --> 00:23:40,720
this thing called storage fields so that

00:23:38,080 --> 00:23:42,070
second phase what it does is it loads

00:23:40,720 --> 00:23:43,840
three things from the stored field it

00:23:42,070 --> 00:23:45,820
loads the ID it loads the type and it

00:23:43,840 --> 00:23:47,140
loads the original source that you gave

00:23:45,820 --> 00:23:48,640
us which we call underscore source

00:23:47,140 --> 00:23:51,730
because we have forever and I'm not

00:23:48,640 --> 00:23:52,840
actually sure why but but that's what

00:23:51,730 --> 00:23:54,580
we'd call the original thing that you

00:23:52,840 --> 00:23:57,760
gave us those things are stored in this

00:23:54,580 --> 00:24:02,350
thing called stored fields stored fields

00:23:57,760 --> 00:24:04,420
are optimized to save space so what we

00:24:02,350 --> 00:24:06,490
do is we take all of the stored fields

00:24:04,420 --> 00:24:08,710
for a document we cap them together into

00:24:06,490 --> 00:24:12,880
just a big basically a big string and

00:24:08,710 --> 00:24:16,900
then we chunk those together with other

00:24:12,880 --> 00:24:19,120
documents and then we compress them and

00:24:16,900 --> 00:24:21,460
then write that to this so when you want

00:24:19,120 --> 00:24:22,269
to go load a store field you have to go

00:24:21,460 --> 00:24:24,489
to the appropriate

00:24:22,269 --> 00:24:25,779
place on disks the appropriate chunk

00:24:24,489 --> 00:24:28,239
that has your document in it

00:24:25,779 --> 00:24:30,309
you have to uncompress far enough to get

00:24:28,239 --> 00:24:32,019
your document out and then you have to

00:24:30,309 --> 00:24:32,769
get the field that you want out of the

00:24:32,019 --> 00:24:35,709
store fields

00:24:32,769 --> 00:24:40,719
so getting looking these stored feels

00:24:35,709 --> 00:24:45,399
it's actually a fair bit of work which

00:24:40,719 --> 00:24:47,379
is why we have this face thing now now I

00:24:45,399 --> 00:24:50,859
can answer your question about why can't

00:24:47,379 --> 00:24:54,700
the first why can't why can't one shard

00:24:50,859 --> 00:24:57,039
serve the source of a document from

00:24:54,700 --> 00:24:59,769
another shard right so if another shard

00:24:57,039 --> 00:25:02,229
ran ran a query and you happen to have

00:24:59,769 --> 00:25:05,229
another copy of that char on your disk

00:25:02,229 --> 00:25:06,969
the reason why a different coffee can't

00:25:05,229 --> 00:25:09,009
serve the source is because those

00:25:06,969 --> 00:25:11,229
integer IDs they don't line up at all

00:25:09,009 --> 00:25:12,909
there's just no guarantee to think that

00:25:11,229 --> 00:25:16,320
they're that they're the same sometimes

00:25:12,909 --> 00:25:19,599
they are in particular they're the same

00:25:16,320 --> 00:25:22,359
after a shard fails and we replicate the

00:25:19,599 --> 00:25:24,489
files on disk but we actually try to do

00:25:22,359 --> 00:25:25,899
that as little as possible because it's

00:25:24,489 --> 00:25:31,539
a lot of work just a lot of data you

00:25:25,899 --> 00:25:34,769
copy around so that was an easy search

00:25:31,539 --> 00:25:37,509
let's talk about a slightly better one

00:25:34,769 --> 00:25:39,249
this search has the same query in it I

00:25:37,509 --> 00:25:44,379
squash the JSON so that it wouldn't take

00:25:39,249 --> 00:25:46,659
up so much space and then it asks the

00:25:44,379 --> 00:25:48,519
last search to do another thing when

00:25:46,659 --> 00:25:50,709
it's finding the document do you

00:25:48,519 --> 00:25:52,749
remember how I told you that elastic

00:25:50,709 --> 00:25:57,219
search bills a priority few of all of

00:25:52,749 --> 00:26:00,700
the documents on Ani shark yes good all

00:25:57,219 --> 00:26:02,109
right well it always tents them when it

00:26:00,700 --> 00:26:04,209
when it builds that priority here at the

00:26:02,109 --> 00:26:10,839
same time but you can ask it to do more

00:26:04,209 --> 00:26:12,969
things in this case well those more

00:26:10,839 --> 00:26:16,599
things could be as simple as take the

00:26:12,969 --> 00:26:20,589
average of some field in this case it

00:26:16,599 --> 00:26:24,219
says take the average min max variance

00:26:20,589 --> 00:26:26,499
and something else

00:26:24,219 --> 00:26:28,809
extended stats calculates a whole bunch

00:26:26,499 --> 00:26:31,299
of stats at the same time on this one

00:26:28,809 --> 00:26:34,779
field you can also ask you to do things

00:26:31,299 --> 00:26:35,890
like group the documents by certain

00:26:34,779 --> 00:26:37,840
field values or through

00:26:35,890 --> 00:26:39,760
the documents based on date ranges or

00:26:37,840 --> 00:26:43,390
number ranges and things like that or IP

00:26:39,760 --> 00:26:45,430
address ranges and then calculate values

00:26:43,390 --> 00:26:50,260
based on those groups so you could

00:26:45,430 --> 00:26:52,450
calculate how much like you could

00:26:50,260 --> 00:26:58,510
calculate the average inbound traffic

00:26:52,450 --> 00:27:03,790
for a certain IP address range for a

00:26:58,510 --> 00:27:06,130
certain group of nodes so remember from

00:27:03,790 --> 00:27:10,900
the last slide this these stored fields

00:27:06,130 --> 00:27:14,110
are chunked and compressed it would be a

00:27:10,900 --> 00:27:15,850
nightmare to service these requests from

00:27:14,110 --> 00:27:20,380
the store fields because you'd have to

00:27:15,850 --> 00:27:21,850
go to each one uncompress it you're

00:27:20,380 --> 00:27:23,770
probably doing them in the wrong order

00:27:21,850 --> 00:27:25,060
so they're not necessarily uncompressing

00:27:23,770 --> 00:27:28,030
them in the order that you actually want

00:27:25,060 --> 00:27:32,230
them in it would be a nightmare to serve

00:27:28,030 --> 00:27:35,470
these aggregations out of store fields

00:27:32,230 --> 00:27:38,050
so instead we use something called dock

00:27:35,470 --> 00:27:42,130
values I probably use is a third way

00:27:38,050 --> 00:27:45,490
that everything is stored on disk so if

00:27:42,130 --> 00:27:49,570
stored vo if stored fields map from the

00:27:45,490 --> 00:27:53,260
dots that synthetic ID to a list of

00:27:49,570 --> 00:27:57,010
fields to values dock values map from a

00:27:53,260 --> 00:27:58,810
field to the dock ID to the value so

00:27:57,010 --> 00:28:00,520
instead of taking all of the values and

00:27:58,810 --> 00:28:01,720
compressing them or and chunking them

00:28:00,520 --> 00:28:06,810
and compressing them together like store

00:28:01,720 --> 00:28:09,910
fields what dock values does is it does

00:28:06,810 --> 00:28:12,310
numeric tricks and look-up tables and

00:28:09,910 --> 00:28:15,520
things along those lines so it knows

00:28:12,310 --> 00:28:18,370
about statistics of the fields but how

00:28:15,520 --> 00:28:20,860
it stores them and that's how it

00:28:18,370 --> 00:28:25,120
compresses them so say for example you

00:28:20,860 --> 00:28:28,780
have only ten values ever for this

00:28:25,120 --> 00:28:32,260
particular field well the thing will

00:28:28,780 --> 00:28:33,910
know oh there are 10 values people make

00:28:32,260 --> 00:28:36,760
a lookup table for all 10 of them and

00:28:33,910 --> 00:28:40,620
then each document will get a nibble

00:28:36,760 --> 00:28:43,420
so for bits that's enough to address 10

00:28:40,620 --> 00:28:46,480
and each document will get a nibble for

00:28:43,420 --> 00:28:48,340
which value it has so you need only half

00:28:46,480 --> 00:28:49,750
a bite to store all of these values

00:28:48,340 --> 00:28:52,960
which is really good

00:28:49,750 --> 00:28:54,490
um it gets worse floating point numbers

00:28:52,960 --> 00:28:55,870
compress very poorly this is almost

00:28:54,490 --> 00:28:57,850
nothing you can do about floating point

00:28:55,870 --> 00:29:00,640
numbers they just take up a lot of space

00:28:57,850 --> 00:29:02,500
so we've been thinking about ways to

00:29:00,640 --> 00:29:05,650
make them better but if you are curious

00:29:02,500 --> 00:29:07,120
about the way that this compression

00:29:05,650 --> 00:29:08,770
works and is really quite interesting

00:29:07,120 --> 00:29:11,890
some of the best talks I've ever had

00:29:08,770 --> 00:29:13,450
look this up online and I won't steal

00:29:11,890 --> 00:29:15,520
any of their thunder but amusing

00:29:13,450 --> 00:29:17,980
algorithms and details on data

00:29:15,520 --> 00:29:19,480
structures and all about elastic search

00:29:17,980 --> 00:29:22,600
algorithms and data structures these

00:29:19,480 --> 00:29:26,500
were two years these were one two years

00:29:22,600 --> 00:29:32,100
in a row at elastic Kong great talks

00:29:26,500 --> 00:29:34,740
they were some of my favorite so

00:29:32,100 --> 00:29:40,030
remember back on that indexing slide

00:29:34,740 --> 00:29:42,970
that I said each that would try to index

00:29:40,030 --> 00:29:44,170
documents I put them in a buffer right I

00:29:42,970 --> 00:29:45,640
put them in a trans log I have to think

00:29:44,170 --> 00:29:48,670
the trans lock and I put the shards

00:29:45,640 --> 00:29:50,500
I put the documents in a buffer to be

00:29:48,670 --> 00:29:51,940
made ready for search we don't

00:29:50,500 --> 00:29:54,850
immediately make the documents ready for

00:29:51,940 --> 00:29:56,800
a search the reason for that is that all

00:29:54,850 --> 00:30:00,370
of these data structures like the finite

00:29:56,800 --> 00:30:03,550
state transducer and the duct values

00:30:00,370 --> 00:30:07,510
they're write-once rather they're

00:30:03,550 --> 00:30:09,520
immutable what that means is that you

00:30:07,510 --> 00:30:13,090
write them and then if you want to

00:30:09,520 --> 00:30:15,420
modify then you have to rewrite them and

00:30:13,090 --> 00:30:18,130
this is actually a really really useful

00:30:15,420 --> 00:30:19,930
but it's the it's sort of an interesting

00:30:18,130 --> 00:30:23,890
caveat so what what ends up happening

00:30:19,930 --> 00:30:26,970
because of this behavior is that a bunch

00:30:23,890 --> 00:30:29,710
of documents come in we buffer em up and

00:30:26,970 --> 00:30:31,240
then we build a little packet of data

00:30:29,710 --> 00:30:33,010
structures for them and save that packet

00:30:31,240 --> 00:30:34,390
to disk then more documents come in and

00:30:33,010 --> 00:30:35,470
we build another little packet and save

00:30:34,390 --> 00:30:36,670
that to this can where documents can

00:30:35,470 --> 00:30:39,610
manually build another little packet and

00:30:36,670 --> 00:30:42,090
save that the disk that packet has a

00:30:39,610 --> 00:30:44,950
special name it's called a segment and

00:30:42,090 --> 00:30:48,750
the act of building and a segment is

00:30:44,950 --> 00:30:52,630
called refreshing and elasticsearch so

00:30:48,750 --> 00:30:55,600
turns out oh the other important thing

00:30:52,630 --> 00:30:59,140
is the way that everything is done is by

00:30:55,600 --> 00:31:02,440
iterating over these segments so every

00:30:59,140 --> 00:31:03,460
single search action starts by for each

00:31:02,440 --> 00:31:05,320
segment

00:31:03,460 --> 00:31:08,649
these things collect the values and do

00:31:05,320 --> 00:31:10,360
and do something with the result having

00:31:08,649 --> 00:31:10,899
hundreds of these segments would be very

00:31:10,360 --> 00:31:14,590
slow

00:31:10,899 --> 00:31:17,470
mr. Thomas because these these data

00:31:14,590 --> 00:31:19,750
structures are sort of designed to save

00:31:17,470 --> 00:31:24,039
space when there are lots of similar

00:31:19,750 --> 00:31:26,740
documents and if these if if this if the

00:31:24,039 --> 00:31:28,840
segments are tiny then it is inefficient

00:31:26,740 --> 00:31:30,370
to run through them because there's more

00:31:28,840 --> 00:31:33,130
overhead so funny there's more on disk

00:31:30,370 --> 00:31:34,899
overhead so you've got disk caching

00:31:33,130 --> 00:31:36,520
problems and there's more memory

00:31:34,899 --> 00:31:38,679
overhead and this more CPU overhead

00:31:36,520 --> 00:31:41,140
because you have to deal with navigating

00:31:38,679 --> 00:31:43,149
those data structures so there's an

00:31:41,140 --> 00:31:46,539
asynchronous operation called merging

00:31:43,149 --> 00:31:48,970
that takes these small segments squashes

00:31:46,539 --> 00:31:52,570
them into a big segment and leaves the

00:31:48,970 --> 00:31:54,130
small seconds around until nobody needs

00:31:52,570 --> 00:31:56,559
to the small segments anymore and then

00:31:54,130 --> 00:31:57,880
deletes them and moves over so I tried

00:31:56,559 --> 00:32:02,590
to illustrate that in this line but I

00:31:57,880 --> 00:32:05,860
think it kind of sucks what this is

00:32:02,590 --> 00:32:07,510
actually the process that allows that

00:32:05,860 --> 00:32:11,260
says you remember how there are the two

00:32:07,510 --> 00:32:12,850
phases well if you modify the index in

00:32:11,260 --> 00:32:15,399
between those two phases

00:32:12,850 --> 00:32:17,529
then the second phase may not work right

00:32:15,399 --> 00:32:19,960
the document may not be there anymore

00:32:17,529 --> 00:32:23,289
may be a different version so we can't

00:32:19,960 --> 00:32:26,140
allow that what we do is we pin the

00:32:23,289 --> 00:32:29,409
segment's we pin all the old ones they

00:32:26,140 --> 00:32:31,360
still exist until that second phase is

00:32:29,409 --> 00:32:34,510
complete and the last research has this

00:32:31,360 --> 00:32:36,640
thing called scroll which is where you

00:32:34,510 --> 00:32:38,289
run a query and then you say I'll come

00:32:36,640 --> 00:32:39,669
back and get more results and get more

00:32:38,289 --> 00:32:42,490
results and get more results it's kind

00:32:39,669 --> 00:32:44,169
of like a databases cursor and just like

00:32:42,490 --> 00:32:45,940
a databases cursor it has a consistent

00:32:44,169 --> 00:32:47,950
view of the index and the way that it

00:32:45,940 --> 00:32:49,690
has that consistent view is that it

00:32:47,950 --> 00:32:51,309
keeps a pointer literally it's just

00:32:49,690 --> 00:32:54,039
reference counting in pointers to keep

00:32:51,309 --> 00:32:56,830
these files in existence and then

00:32:54,039 --> 00:33:00,220
eventually when the scroll either times

00:32:56,830 --> 00:33:01,480
however is closed is closed or finishes

00:33:00,220 --> 00:33:04,120
all its documents or something like that

00:33:01,480 --> 00:33:05,140
we can actually delete these files the

00:33:04,120 --> 00:33:08,740
other thing is that this is the only

00:33:05,140 --> 00:33:13,019
process that were claims space for

00:33:08,740 --> 00:33:16,240
deleted documents so

00:33:13,019 --> 00:33:19,210
elasticsearch works fairly similarly to

00:33:16,240 --> 00:33:22,330
unoptimized Postgres for deleted

00:33:19,210 --> 00:33:24,850
documents that means is that when a

00:33:22,330 --> 00:33:27,100
document when you make an update you

00:33:24,850 --> 00:33:29,140
have to delete the old document and add

00:33:27,100 --> 00:33:31,330
anyone and this is atomic on the shard

00:33:29,140 --> 00:33:32,799
level that's how updates work and that's

00:33:31,330 --> 00:33:36,250
how deletes work they just delete the

00:33:32,799 --> 00:33:38,559
document but all that does is it has a

00:33:36,250 --> 00:33:40,210
data structure that it's basically a

00:33:38,559 --> 00:33:43,840
bitmap that marks the documents as

00:33:40,210 --> 00:33:45,460
deleted and so those are filtered I open

00:33:43,840 --> 00:33:47,620
the queries fairly early on but they

00:33:45,460 --> 00:33:49,539
still sit around on this the only

00:33:47,620 --> 00:33:51,850
process that actually removes all that

00:33:49,539 --> 00:33:54,179
stuff off of disk for these documents is

00:33:51,850 --> 00:33:58,409
this merging process we just don't copy

00:33:54,179 --> 00:33:58,409
anything for documents that are deleted

00:34:00,720 --> 00:34:05,889
all right I promise it's not this is way

00:34:04,419 --> 00:34:09,609
over what I thought I've been Dean is a

00:34:05,889 --> 00:34:13,030
good time so let's talk about analysis

00:34:09,609 --> 00:34:14,919
because this is a this is where I start

00:34:13,030 --> 00:34:17,409
to to try to make that search stuff

00:34:14,919 --> 00:34:24,159
makes sense try to make the fancy fancy

00:34:17,409 --> 00:34:27,780
full-text search makes sense so say I

00:34:24,159 --> 00:34:30,369
want to search for the word lucky well

00:34:27,780 --> 00:34:32,800
any sane person would want to find a cat

00:34:30,369 --> 00:34:35,320
document somewhere in that list

00:34:32,800 --> 00:34:36,730
maybe not high I mean it has the word

00:34:35,320 --> 00:34:39,879
Latin it's close to the beginning of the

00:34:36,730 --> 00:34:41,200
document maybe that's important but the

00:34:39,879 --> 00:34:43,540
word Latin you should find the word

00:34:41,200 --> 00:34:47,050
Latin and if you were to take the whole

00:34:43,540 --> 00:34:48,550
the whole document and just save it or

00:34:47,050 --> 00:34:51,310
take the whole text feel right there and

00:34:48,550 --> 00:34:53,830
save it as a single term if you were to

00:34:51,310 --> 00:34:56,530
make the finite state transducer th e

00:34:53,830 --> 00:34:57,730
space D om and all that all the way

00:34:56,530 --> 00:34:59,980
around so the finite stanchion

00:34:57,730 --> 00:35:02,770
transducer was super long then the only

00:34:59,980 --> 00:35:07,750
way to find the word Latin would be to

00:35:02,770 --> 00:35:09,130
have a wild card query that has a wild

00:35:07,750 --> 00:35:10,660
card on the front and a la carte on the

00:35:09,130 --> 00:35:13,930
back and a were laughing in the middle

00:35:10,660 --> 00:35:15,339
and this is super inefficient because

00:35:13,930 --> 00:35:17,200
the way that these things have to be

00:35:15,339 --> 00:35:19,720
evaluated is you have to walk all the

00:35:17,200 --> 00:35:22,270
way up the finite state transducer and

00:35:19,720 --> 00:35:23,319
go there's no L that's going to go back

00:35:22,270 --> 00:35:25,960
you end up having to walk the entire

00:35:23,319 --> 00:35:28,300
thing and that's

00:35:25,960 --> 00:35:30,310
really really inefficient so instead

00:35:28,300 --> 00:35:34,690
what we do is we play with the text

00:35:30,310 --> 00:35:38,050
before it's indexed so the first step in

00:35:34,690 --> 00:35:40,030
this analysis is called tokenization and

00:35:38,050 --> 00:35:45,070
it's where you take the text and you

00:35:40,030 --> 00:35:47,260
divide it into words so to make this

00:35:45,070 --> 00:35:49,330
example easy I'm gonna use a stupid

00:35:47,260 --> 00:35:52,000
tokenizer just tokenize this on white

00:35:49,330 --> 00:35:54,720
space I'm not gonna use a smart one that

00:35:52,000 --> 00:35:57,339
tokenize is on like open paren and

00:35:54,720 --> 00:35:58,660
periods and stuff the real tokenizer is

00:35:57,339 --> 00:36:00,550
do that by default but I'm gonna use

00:35:58,660 --> 00:36:04,540
white space because white space makes

00:36:00,550 --> 00:36:07,150
this more illustrative so very first

00:36:04,540 --> 00:36:09,880
thing we do is we tokenize this sentence

00:36:07,150 --> 00:36:13,180
into words but if you search for latin

00:36:09,880 --> 00:36:15,520
you still won't find the word because

00:36:13,180 --> 00:36:17,230
there's that silly parenthesis and the

00:36:15,520 --> 00:36:20,770
colons and all the business you're not

00:36:17,230 --> 00:36:22,420
gonna find it so the usual next so we

00:36:20,770 --> 00:36:26,710
just do it right now it's the lower case

00:36:22,420 --> 00:36:28,690
all the terms will get to why this this

00:36:26,710 --> 00:36:30,099
works really well but pretend I'm just

00:36:28,690 --> 00:36:32,020
searching for lower case Latin for now

00:36:30,099 --> 00:36:35,380
I'll find it lower case even if it is

00:36:32,020 --> 00:36:37,450
upper case either then we apply another

00:36:35,380 --> 00:36:39,010
filter in this case the filter that I

00:36:37,450 --> 00:36:40,930
applied to make this work was called

00:36:39,010 --> 00:36:42,490
pattern replace and I just made a

00:36:40,930 --> 00:36:44,859
pattern or place that replaces things

00:36:42,490 --> 00:36:48,040
like open paren and colon and period

00:36:44,859 --> 00:36:51,250
with nothing so that gets us to this

00:36:48,040 --> 00:36:53,170
gold line the gold line is gold because

00:36:51,250 --> 00:36:54,940
it is the first line that finds the word

00:36:53,170 --> 00:36:56,890
Latin and also because gold is one of

00:36:54,940 --> 00:36:59,770
elastics official accent colors and it

00:36:56,890 --> 00:37:01,570
comes with our actually I like I really

00:36:59,770 --> 00:37:03,010
sort of make fun of this but it's so

00:37:01,570 --> 00:37:04,800
useful to have a company just hand you a

00:37:03,010 --> 00:37:07,450
slide back and say this is how you start

00:37:04,800 --> 00:37:09,730
it's really easy I don't pick accent

00:37:07,450 --> 00:37:14,710
colors or anything

00:37:09,730 --> 00:37:18,190
so the next thing often do what don't

00:37:14,710 --> 00:37:20,770
always do is do something called

00:37:18,190 --> 00:37:25,960
stemming which is where you take each

00:37:20,770 --> 00:37:29,619
one of these words and you D conjugate

00:37:25,960 --> 00:37:32,200
them so this pink line is where I

00:37:29,619 --> 00:37:34,240
applied something called paste M which

00:37:32,200 --> 00:37:37,750
is a stammer from like 1990s or

00:37:34,240 --> 00:37:39,520
something and it works really well it's

00:37:37,750 --> 00:37:41,770
it's well studied

00:37:39,520 --> 00:37:43,360
decent job of finding words so what it

00:37:41,770 --> 00:37:46,540
does is it takes your words and mangles

00:37:43,360 --> 00:37:52,560
them right so see like domestic becames

00:37:46,540 --> 00:37:55,180
becomes domestic felis becomes feely and

00:37:52,560 --> 00:37:59,080
carnivorous becomes carnivore without an

00:37:55,180 --> 00:38:01,540
e so the reason this is cool is that now

00:37:59,080 --> 00:38:02,830
you can actually find the word you can

00:38:01,540 --> 00:38:05,680
find the cat document if you search for

00:38:02,830 --> 00:38:07,930
carnivore most reasonable people who

00:38:05,680 --> 00:38:09,910
want to find information about cats if

00:38:07,930 --> 00:38:12,370
they search for Carnaval eventually

00:38:09,910 --> 00:38:15,580
right it may not be high on the list but

00:38:12,370 --> 00:38:18,970
they want to find it so the way this

00:38:15,580 --> 00:38:21,220
works the the usual way that you do

00:38:18,970 --> 00:38:24,550
these searches is that you use this

00:38:21,220 --> 00:38:27,580
thing called a match query and what that

00:38:24,550 --> 00:38:30,580
does is it runs the the text that you

00:38:27,580 --> 00:38:33,240
handed us through the same analysis

00:38:30,580 --> 00:38:36,340
chain through this same step and

00:38:33,240 --> 00:38:40,060
carnivore also becomes conver without

00:38:36,340 --> 00:38:42,210
the e so you can still find your cat on

00:38:40,060 --> 00:38:45,490
that because everyone wants to find cats

00:38:42,210 --> 00:38:48,460
now in elasticsearch as in the scene is

00:38:45,490 --> 00:38:51,610
in oh god I said Lucy I'll explain the

00:38:48,460 --> 00:38:53,650
same in a bit um in elasticsearch you

00:38:51,610 --> 00:38:55,240
can turn off this analyze the text I

00:38:53,650 --> 00:38:57,490
just gave you behavior by using a term

00:38:55,240 --> 00:39:00,340
query instead of a match query um

00:38:57,490 --> 00:39:02,950
there's technically some overhead in

00:39:00,340 --> 00:39:05,470
asking us to do a match query but it's

00:39:02,950 --> 00:39:07,510
realistically so tiny that it's I just

00:39:05,470 --> 00:39:14,970
always use math queries unless there's a

00:39:07,510 --> 00:39:14,970
really compelling reason about this so

00:39:15,040 --> 00:39:22,340
there is a trick that is fairly common

00:39:18,800 --> 00:39:24,590
and I used it at Wikipedia what you do

00:39:22,340 --> 00:39:25,940
is you analyze the text two ways you

00:39:24,590 --> 00:39:28,820
analyze the text both with and without a

00:39:25,940 --> 00:39:30,650
simmer right so basically with this does

00:39:28,820 --> 00:39:32,150
what I did to build this slide was I

00:39:30,650 --> 00:39:34,960
deleted the top three lines and moved

00:39:32,150 --> 00:39:42,050
the table up these are the same lines so

00:39:34,960 --> 00:39:43,490
the golden text the analyze text and the

00:39:42,050 --> 00:39:47,870
pink text is nee analyze text in this

00:39:43,490 --> 00:39:52,850
demo and often what's nice is to be able

00:39:47,870 --> 00:39:54,560
to find documents higher in the list if

00:39:52,850 --> 00:39:58,850
they have exactly the term that you

00:39:54,560 --> 00:40:02,840
searched well so one way to do this that

00:39:58,850 --> 00:40:05,960
works fairly well is to only apply or is

00:40:02,840 --> 00:40:07,760
to apply the stemming to one field and

00:40:05,960 --> 00:40:11,870
to not apply it to another and search on

00:40:07,760 --> 00:40:15,710
both and to explicitly say the unstamped

00:40:11,870 --> 00:40:19,070
field is worth more and it looks like

00:40:15,710 --> 00:40:20,810
that now I like this example because

00:40:19,070 --> 00:40:23,420
it's fairly real-world I mean I actually

00:40:20,810 --> 00:40:26,870
did it on a real website that really

00:40:23,420 --> 00:40:28,820
finds hits that people they think the

00:40:26,870 --> 00:40:31,010
search is okay not great but okay right

00:40:28,820 --> 00:40:32,860
like to make a great search you have to

00:40:31,010 --> 00:40:35,450
do a lot of analytics and you have to

00:40:32,860 --> 00:40:37,280
basically spy on your users and figure

00:40:35,450 --> 00:40:40,940
out whether they liked the search or not

00:40:37,280 --> 00:40:42,250
and then optimize it I think I made the

00:40:40,940 --> 00:40:45,490
best search I could without doing that

00:40:42,250 --> 00:40:49,310
so this is one of the tricks that you do

00:40:45,490 --> 00:40:50,720
and I also like this example because it

00:40:49,310 --> 00:40:51,620
shows that the elastic search query

00:40:50,720 --> 00:40:54,470
language Wow

00:40:51,620 --> 00:40:56,650
really big and bloaty's with JSON I mean

00:40:54,470 --> 00:41:00,890
this is just massive for what it does

00:40:56,650 --> 00:41:02,390
but it's eminently composable right it's

00:41:00,890 --> 00:41:03,800
obvious the places where you can stick

00:41:02,390 --> 00:41:05,210
queries or at least it should be or the

00:41:03,800 --> 00:41:08,600
documentation and if it isn't you can

00:41:05,210 --> 00:41:10,730
bug me and I'll fix it and when you

00:41:08,600 --> 00:41:12,350
stick another query in there you can use

00:41:10,730 --> 00:41:15,440
any of the other you can use the query

00:41:12,350 --> 00:41:17,120
language again right it's fully fully

00:41:15,440 --> 00:41:20,120
the queries can be fully embedded in

00:41:17,120 --> 00:41:22,790
themselves and that just works and JSON

00:41:20,120 --> 00:41:24,110
kind of actually is a good structure for

00:41:22,790 --> 00:41:25,800
that because it's sort of naturally tree

00:41:24,110 --> 00:41:28,290
based and that makes

00:41:25,800 --> 00:41:33,000
sort of nicer sometimes then a like a

00:41:28,290 --> 00:41:35,130
fancy than a fancy like way like a then

00:41:33,000 --> 00:41:37,800
a fancy like one-liner lookin query with

00:41:35,130 --> 00:41:46,100
me because JSON this with a naturally

00:41:37,800 --> 00:41:53,540
Tree of Life okay so I'm done up slides

00:41:46,100 --> 00:41:55,500
this is it well this is the last one so

00:41:53,540 --> 00:41:57,090
there's my summary there's the things

00:41:55,500 --> 00:41:59,550
that you should probably remember from

00:41:57,090 --> 00:42:01,230
this talk that I hope that you remember

00:41:59,550 --> 00:42:03,030
from this talk I hope that the data

00:42:01,230 --> 00:42:04,619
structures were interesting at least the

00:42:03,030 --> 00:42:07,260
ones that I had time to go into and that

00:42:04,619 --> 00:42:10,290
I went into it in any depth but the

00:42:07,260 --> 00:42:11,820
things to remember are that well I could

00:42:10,290 --> 00:42:13,200
just read this line but just remember

00:42:11,820 --> 00:42:15,990
these things these are the important

00:42:13,200 --> 00:42:17,640
ones particularly that request bounced

00:42:15,990 --> 00:42:19,680
around asynchronously is interesting

00:42:17,640 --> 00:42:22,170
that we write data to disk in a bunch of

00:42:19,680 --> 00:42:23,820
different ways is interesting and each

00:42:22,170 --> 00:42:27,390
different ways to optimize a different

00:42:23,820 --> 00:42:28,920
access pattern and that analysis

00:42:27,390 --> 00:42:30,450
analyzing the tech that stuff that I

00:42:28,920 --> 00:42:32,220
went into in the last slide is like

00:42:30,450 --> 00:42:35,310
super important to get a nice search

00:42:32,220 --> 00:42:37,470
experience and it's the way that you

00:42:35,310 --> 00:42:40,080
make search fast is by screwing with the

00:42:37,470 --> 00:42:44,130
text both before look before you index

00:42:40,080 --> 00:42:48,030
it and at search time rather than any

00:42:44,130 --> 00:42:49,770
sort of fancy thing that you do a query

00:42:48,030 --> 00:42:51,540
time just do the simplest possible thing

00:42:49,770 --> 00:42:53,340
at query time which is look up the text

00:42:51,540 --> 00:42:55,590
things your time to you anything you can

00:42:53,340 --> 00:42:58,410
do to transform your search problem into

00:42:55,590 --> 00:43:00,119
that and it'll be fast so that's what

00:42:58,410 --> 00:43:02,640
you can remember now I said the word

00:43:00,119 --> 00:43:10,290
leucine and earlier and I didn't explain

00:43:02,640 --> 00:43:14,960
it elasticsearch is machine is a library

00:43:10,290 --> 00:43:17,940
is a java library that implements like

00:43:14,960 --> 00:43:20,160
3/4 of this stuff elasticsearch

00:43:17,940 --> 00:43:24,300
implements things like the bouncing

00:43:20,160 --> 00:43:26,910
around the network things like well

00:43:24,300 --> 00:43:30,450
Jason the whole JSON stuff everything to

00:43:26,910 --> 00:43:33,240
do with the convention its leucine is a

00:43:30,450 --> 00:43:35,250
java library so it's working in a Java

00:43:33,240 --> 00:43:37,170
library layer but leucine implements

00:43:35,250 --> 00:43:38,940
things like dock values that implements

00:43:37,170 --> 00:43:41,970
the queries and it's the now

00:43:38,940 --> 00:43:45,030
this and elasticsearch is is built on

00:43:41,970 --> 00:43:46,560
loosing many of the elasticsearch

00:43:45,030 --> 00:43:49,380
contributors are the scene contributors

00:43:46,560 --> 00:43:51,170
not all and not all of the Lucine

00:43:49,380 --> 00:43:53,010
contributors or elasticsearch kinship

00:43:51,170 --> 00:43:56,010
machine is an Apache project

00:43:53,010 --> 00:44:03,450
elasticsearch is basically an elastic

00:43:56,010 --> 00:44:06,869
company project so that isn't to say

00:44:03,450 --> 00:44:10,050
that the scene has all this but it's

00:44:06,869 --> 00:44:11,369
kinda awful lot of the brains and a lot

00:44:10,050 --> 00:44:14,430
of the brains that I covered today are

00:44:11,369 --> 00:44:15,690
actually the scene brains mostly because

00:44:14,430 --> 00:44:17,250
it has the interesting data structures

00:44:15,690 --> 00:44:21,869
elasticsearch is just a big pile of

00:44:17,250 --> 00:44:27,050
software engineering work and yeah make

00:44:21,869 --> 00:44:30,780
it to make it all exposed over HTTP so

00:44:27,050 --> 00:44:32,730
questions yeah I'll go to the to the

00:44:30,780 --> 00:45:01,589
Creative Commons Licence questions the

00:44:32,730 --> 00:45:04,890
official trigger yeah sure

00:45:01,589 --> 00:45:06,210
so when elastics so the question was

00:45:04,890 --> 00:45:09,030
I'll repeat it so that it gets recorded

00:45:06,210 --> 00:45:12,800
is please explain how shards work you

00:45:09,030 --> 00:45:15,119
sort of glossed over that and I did so

00:45:12,800 --> 00:45:18,329
and I also didn't explain that nodes 0

00:45:15,119 --> 00:45:20,880
node 1 and node 2 are physical they're

00:45:18,329 --> 00:45:22,859
actual nodes in my mind they are

00:45:20,880 --> 00:45:24,869
different computers sitting in a data

00:45:22,859 --> 00:45:26,609
center but they could simply be

00:45:24,869 --> 00:45:34,319
different Java processes and we wouldn't

00:45:26,609 --> 00:45:37,740
notice or care so elasticsearch can be

00:45:34,319 --> 00:45:40,140
run with nodes configured in a bunch of

00:45:37,740 --> 00:45:43,190
ways a couple of ways essentially there

00:45:40,140 --> 00:45:45,900
are flags that you can turn on and off

00:45:43,190 --> 00:45:49,500
you can turn on and off whether our node

00:45:45,900 --> 00:45:51,480
head has data on disk so in my case this

00:45:49,500 --> 00:45:52,590
picture has has three nodes which are

00:45:51,480 --> 00:45:54,920
three physical machine

00:45:52,590 --> 00:45:57,150
they all have data written on this and

00:45:54,920 --> 00:45:59,130
elasticsearch has tried to balance those

00:45:57,150 --> 00:46:00,300
that data on disk is best that it can

00:45:59,130 --> 00:46:03,330
there are four things that it has to

00:46:00,300 --> 00:46:08,310
balance three ways so one just gets

00:46:03,330 --> 00:46:11,100
extra sorry so this is that the other

00:46:08,310 --> 00:46:13,620
thing about shards is is that the number

00:46:11,100 --> 00:46:15,330
of shots is set on index creation

00:46:13,620 --> 00:46:18,540
there's a special API you can use full

00:46:15,330 --> 00:46:21,390
shrink which makes it smaller but there

00:46:18,540 --> 00:46:24,900
are funny rules like it can only be you

00:46:21,390 --> 00:46:26,250
can only decrease it to a multiple or

00:46:24,900 --> 00:46:27,900
decrease it from a multiple of what it

00:46:26,250 --> 00:46:32,820
was so if you had 10 shards you can

00:46:27,900 --> 00:46:38,730
decrease the 2 or 5 or 1 any case so the

00:46:32,820 --> 00:46:40,500
process how do I describe it so these

00:46:38,730 --> 00:46:44,520
shards are these data structures on disk

00:46:40,500 --> 00:46:46,050
and most of those so internally inside

00:46:44,520 --> 00:46:49,260
elasticsearch shards are fairly

00:46:46,050 --> 00:46:54,210
independent of one another there's this

00:46:49,260 --> 00:46:56,160
rep this primary replica thing and the

00:46:54,210 --> 00:47:00,090
primary is the one where the acted that

00:46:56,160 --> 00:47:04,910
like the writes go first and then so in

00:47:00,090 --> 00:47:10,860
in my case in this picture this this

00:47:04,910 --> 00:47:13,620
shard on node 0 is the primary for this

00:47:10,860 --> 00:47:18,450
particular write operation so that means

00:47:13,620 --> 00:47:20,870
that for the Ian's wiki one char this is

00:47:18,450 --> 00:47:24,300
the the one on those 0 is the primary

00:47:20,870 --> 00:47:25,530
until the end of time rather until

00:47:24,300 --> 00:47:29,580
something goes wrong

00:47:25,530 --> 00:47:33,330
so no no's keep notes day rather shards

00:47:29,580 --> 00:47:34,890
short copies to be we talk we start

00:47:33,330 --> 00:47:39,660
talking about that a shard copies so

00:47:34,890 --> 00:47:43,710
like this guy's a shard copy and this

00:47:39,660 --> 00:47:45,630
guys are so short copies stay primary as

00:47:43,710 --> 00:47:48,830
long as they can and if something tragic

00:47:45,630 --> 00:47:51,270
happens like someone shoots no no zero

00:47:48,830 --> 00:47:53,610
no then the other note then the other

00:47:51,270 --> 00:47:55,140
copy gets promoted to the primary but

00:47:53,610 --> 00:47:58,050
otherwise the things stay primary for a

00:47:55,140 --> 00:48:02,370
while um so the other thing that makes

00:47:58,050 --> 00:48:03,990
shirting work is that we hash the

00:48:02,370 --> 00:48:05,430
document like we hashed by the type in

00:48:03,990 --> 00:48:06,540
the ID and just put the documents in

00:48:05,430 --> 00:48:09,180
there so

00:48:06,540 --> 00:48:11,760
a documents URL you can tell which

00:48:09,180 --> 00:48:13,470
started those is it like that's the

00:48:11,760 --> 00:48:15,600
magic of it there are ways that you can

00:48:13,470 --> 00:48:17,160
cheat this you can there are features

00:48:15,600 --> 00:48:20,160
like parent-child and features like

00:48:17,160 --> 00:48:22,320
routings that basically takes control

00:48:20,160 --> 00:48:24,570
from elasticsearch and says no no I know

00:48:22,320 --> 00:48:28,740
where this document goes but when you do

00:48:24,570 --> 00:48:30,920
that the ID uniqueness of IDs can get

00:48:28,740 --> 00:48:32,640
violated if you don't always do it right

00:48:30,920 --> 00:48:34,020
it's one of those keys that

00:48:32,640 --> 00:48:35,610
elasticsearch enhanced you this is you

00:48:34,020 --> 00:48:38,310
can override our starting algorithm if

00:48:35,610 --> 00:48:44,870
you feel like it just don't screw it up

00:48:38,310 --> 00:48:46,890
or you'll get duplicate IDs now um I

00:48:44,870 --> 00:49:02,880
know that was sort of a rambling talk

00:48:46,890 --> 00:49:10,680
about shards but now you get a match

00:49:02,880 --> 00:49:12,570
from any note its round-robin so the way

00:49:10,680 --> 00:49:14,370
that you get rid of duplicate duplicates

00:49:12,570 --> 00:49:17,340
in the result is by always sending the

00:49:14,370 --> 00:49:19,410
same document to the same node right so

00:49:17,340 --> 00:49:22,680
or rather always sending documents to

00:49:19,410 --> 00:49:25,740
the same shard so if the document with

00:49:22,680 --> 00:49:27,270
ID 1 gets hashed to the shard number 1

00:49:25,740 --> 00:49:28,710
it always has to get have to start

00:49:27,270 --> 00:49:31,560
number 1 or else we start to make

00:49:28,710 --> 00:49:33,840
duplicates so because they always go to

00:49:31,560 --> 00:49:35,580
the same shard you can just pick any one

00:49:33,840 --> 00:49:38,070
of those chars and get the result path

00:49:35,580 --> 00:49:40,170
now the interesting thing about this is

00:49:38,070 --> 00:49:41,700
that from a database like a

00:49:40,170 --> 00:49:44,220
transactional database point of view

00:49:41,700 --> 00:49:47,640
this has all kinds of bad properties for

00:49:44,220 --> 00:49:50,640
example you get dirty reads if the nodes

00:49:47,640 --> 00:49:54,180
crash you can get dirty reads you can

00:49:50,640 --> 00:49:56,250
get steal reads all of these things are

00:49:54,180 --> 00:49:58,590
totally possible and exacerbated by our

00:49:56,250 --> 00:50:00,000
refresh cycle so we have this cycle

00:49:58,590 --> 00:50:01,890
where we refresh every once in a while

00:50:00,000 --> 00:50:03,990
remember we remake the pec the segments

00:50:01,890 --> 00:50:05,220
we only do that by default every second

00:50:03,990 --> 00:50:06,660
and in fact when people have a high

00:50:05,220 --> 00:50:08,250
write rate we tell them to crank that up

00:50:06,660 --> 00:50:10,170
we tell them to put that at like 30

00:50:08,250 --> 00:50:13,140
seconds or a minute or something like

00:50:10,170 --> 00:50:15,180
that in that case if the nodes refresh

00:50:13,140 --> 00:50:16,950
is don't line up and they never will why

00:50:15,180 --> 00:50:18,000
would they write like just like that's

00:50:16,950 --> 00:50:20,430
how the world works

00:50:18,000 --> 00:50:22,280
then if you go to a differ

00:50:20,430 --> 00:50:24,450
no you'll actually get different

00:50:22,280 --> 00:50:26,220
documents visible you'll get the old

00:50:24,450 --> 00:50:28,320
version of a document visible over here

00:50:26,220 --> 00:50:30,390
and the new version of here and one of

00:50:28,320 --> 00:50:32,130
the ways that we fight this is by

00:50:30,390 --> 00:50:35,820
updates always being done on the primary

00:50:32,130 --> 00:50:37,620
but in truth there's actually another

00:50:35,820 --> 00:50:39,180
really great talk by a guy named a fur

00:50:37,620 --> 00:50:42,540
that you can go that you can go watch

00:50:39,180 --> 00:50:45,810
where he just blows away our consistency

00:50:42,540 --> 00:50:51,180
model he says no it's crap and actually

00:50:45,810 --> 00:50:53,490
it is but the it's getting better

00:50:51,180 --> 00:50:55,110
constantly there are a lot of smart

00:50:53,490 --> 00:50:56,880
people who are working hard on the

00:50:55,110 --> 00:50:58,590
consistency model and one of the

00:50:56,880 --> 00:51:02,460
problems with the consistency model is

00:50:58,590 --> 00:51:04,770
that dirty reads can cause if if you if

00:51:02,460 --> 00:51:06,630
you do an update so we have this we have

00:51:04,770 --> 00:51:10,920
a system for updates that allows you to

00:51:06,630 --> 00:51:12,890
do optimistic locking right you say only

00:51:10,920 --> 00:51:14,790
update this if the version is the same

00:51:12,890 --> 00:51:15,900
right we don't have any sort of locking

00:51:14,790 --> 00:51:17,490
we have this optimistic concurrency

00:51:15,900 --> 00:51:20,550
control it's the same thing Postgres as

00:51:17,490 --> 00:51:22,470
everyone's got it you say make this

00:51:20,550 --> 00:51:24,210
update only if this version matches that

00:51:22,470 --> 00:51:27,030
works great but in the case of dirty

00:51:24,210 --> 00:51:29,670
reads you can get version you can get

00:51:27,030 --> 00:51:31,980
documents back with the version that you

00:51:29,670 --> 00:51:33,900
wanted but it turns out that they

00:51:31,980 --> 00:51:34,710
actually have not the data that you

00:51:33,900 --> 00:51:39,330
thought they had

00:51:34,710 --> 00:51:41,100
I keep getting K anyway this is a

00:51:39,330 --> 00:51:43,110
problem and actually one of the ways

00:51:41,100 --> 00:51:45,150
that we that that we can fight this and

00:51:43,110 --> 00:51:48,630
that we are currently working on to

00:51:45,150 --> 00:51:51,870
fight it is that the way these dirty

00:51:48,630 --> 00:51:54,480
reads happen is when one primary fails

00:51:51,870 --> 00:51:57,120
when when the primary fails and you you

00:51:54,480 --> 00:52:00,420
read instead from a replica the the

00:51:57,120 --> 00:52:02,550
versions can diverge and if you instead

00:52:00,420 --> 00:52:06,930
of using this version numbers if you use

00:52:02,550 --> 00:52:08,340
a the sequence that the note the

00:52:06,930 --> 00:52:12,570
sequence that things were written to the

00:52:08,340 --> 00:52:14,460
primary plus the generation of the

00:52:12,570 --> 00:52:17,100
primary and that is every time a primary

00:52:14,460 --> 00:52:18,870
dies you get a new generation so if you

00:52:17,100 --> 00:52:21,330
use these two these two things together

00:52:18,870 --> 00:52:24,330
then you can prevent these these dirty

00:52:21,330 --> 00:52:26,400
updates trouble is though that update

00:52:24,330 --> 00:52:28,020
semantics isn't implemented yet it's

00:52:26,400 --> 00:52:31,350
coming but it doesn't implement it yet

00:52:28,020 --> 00:52:32,930
what that means is that elasticsearch is

00:52:31,350 --> 00:52:35,030
is very

00:52:32,930 --> 00:52:37,940
full for the things that it is useful

00:52:35,030 --> 00:52:40,130
for and that those are indexing and

00:52:37,940 --> 00:52:42,740
searching and finding data quickly but

00:52:40,130 --> 00:52:45,650
but as a primary data store I would

00:52:42,740 --> 00:52:47,809
avoid it until we get that and even then

00:52:45,650 --> 00:52:49,670
there are still other things so I didn't

00:52:47,809 --> 00:52:53,690
just so this is the consistency model I

00:52:49,670 --> 00:52:55,819
just described is how how FAR's work you

00:52:53,690 --> 00:52:57,829
put a document in the sharp and if the

00:52:55,819 --> 00:52:59,900
primary says the document is it says the

00:52:57,829 --> 00:53:01,250
document goes in the primary then you

00:52:59,900 --> 00:53:02,900
basically could reply to the user

00:53:01,250 --> 00:53:07,700
immediately and tell them yep it's in

00:53:02,900 --> 00:53:12,079
because if any of the replicas fail then

00:53:07,700 --> 00:53:14,720
they get shot so if the primary accepts

00:53:12,079 --> 00:53:17,150
a document and a replica rejects it the

00:53:14,720 --> 00:53:19,119
replica has to die that's just the way

00:53:17,150 --> 00:53:21,319
that this consistency model works and

00:53:19,119 --> 00:53:23,359
then the replica has to be rebuilt

00:53:21,319 --> 00:53:25,430
someplace else because something must be

00:53:23,359 --> 00:53:30,170
wrong with it so just blow it away from

00:53:25,430 --> 00:53:33,410
orbit the main use case is powering

00:53:30,170 --> 00:53:38,420
on-site search or powering like

00:53:33,410 --> 00:53:40,790
analytics on logs or let's see

00:53:38,420 --> 00:53:41,990
powering people will do things like

00:53:40,790 --> 00:53:43,220
they'll collect a bunch of NetFlow data

00:53:41,990 --> 00:53:46,730
and they'll dump it in and they'll

00:53:43,220 --> 00:53:49,400
analyze it it is essentially so what's

00:53:46,730 --> 00:53:51,260
great if you only write one time it

00:53:49,400 --> 00:53:53,270
works fine if you want to write multiple

00:53:51,260 --> 00:53:57,920
times but there's some other source of

00:53:53,270 --> 00:54:00,440
truth those are the two things but it is

00:53:57,920 --> 00:54:01,599
not a relational database and it's

00:54:00,440 --> 00:54:05,720
getting better

00:54:01,599 --> 00:54:08,450
but I would not trust it with my as my

00:54:05,720 --> 00:54:10,790
primary datastore that's fine I never

00:54:08,450 --> 00:54:13,040
did write so it powered the on-site

00:54:10,790 --> 00:54:14,210
search and Wikipedia right when you go

00:54:13,040 --> 00:54:16,099
to in the upper right there's a search

00:54:14,210 --> 00:54:17,450
bar you just type things in there and it

00:54:16,099 --> 00:54:19,579
finds things most people don't know

00:54:17,450 --> 00:54:24,890
about it but if you happen to use the

00:54:19,579 --> 00:54:27,530
Wikipedia app on your phone there's a

00:54:24,890 --> 00:54:29,930
search on there and I uses it and that

00:54:27,530 --> 00:54:31,940
generates tons of traffic so well most

00:54:29,930 --> 00:54:34,670
people don't know about it it still gets

00:54:31,940 --> 00:54:38,570
more search traffic than like MSN does

00:54:34,670 --> 00:54:41,570
because Wikipedia is stupidly huge so

00:54:38,570 --> 00:54:43,910
it works like it works for that and the

00:54:41,570 --> 00:54:45,410
reason it works for that is that there's

00:54:43,910 --> 00:54:47,360
a second there's a primary data store

00:54:45,410 --> 00:54:49,640
that's outside of it and that the

00:54:47,360 --> 00:54:51,740
process of keeping elasticsearch up to

00:54:49,640 --> 00:54:53,330
date is this asynchronous triggered

00:54:51,740 --> 00:54:55,850
process that happens after someone

00:54:53,330 --> 00:54:57,200
modifies a page in Wikipedia it's

00:54:55,850 --> 00:54:59,840
actually really complicated on Wikipedia

00:54:57,200 --> 00:55:03,850
because Wikipedia Wikipedia pages don't

00:54:59,840 --> 00:55:06,320
just so if you've ever edited a wiki

00:55:03,850 --> 00:55:08,480
usually if you've edited a corporate

00:55:06,320 --> 00:55:11,270
wiki what happens is you just type text

00:55:08,480 --> 00:55:15,920
in you click Save this is not how it

00:55:11,270 --> 00:55:17,570
media works you click edit and then it's

00:55:15,920 --> 00:55:19,850
a whole friggin programming language in

00:55:17,570 --> 00:55:21,050
there and you can type text but it turns

00:55:19,850 --> 00:55:25,130
out that if you want to make a certain

00:55:21,050 --> 00:55:26,120
box you invoke a template and actually

00:55:25,130 --> 00:55:29,030
if you get deep enough some of these

00:55:26,120 --> 00:55:30,470
templates are written in lua so they're

00:55:29,030 --> 00:55:32,090
like turn complete they're like full

00:55:30,470 --> 00:55:33,440
because it turns out people were writing

00:55:32,090 --> 00:55:35,060
people were abusing the tempering

00:55:33,440 --> 00:55:37,640
language to write turing-complete code

00:55:35,060 --> 00:55:38,870
like to write real code so someone was

00:55:37,640 --> 00:55:41,590
like well screw this let's just replace

00:55:38,870 --> 00:55:44,000
the really horrible templates with Lua

00:55:41,590 --> 00:55:47,570
so they did and actually work great a

00:55:44,000 --> 00:55:49,970
brand new key guy it's a really it's a

00:55:47,570 --> 00:55:51,860
great choice so anyway if you modify any

00:55:49,970 --> 00:55:53,780
of these templates you have to go and

00:55:51,860 --> 00:55:56,510
update the search index for all the

00:55:53,780 --> 00:55:58,490
pages that come from these templates so

00:55:56,510 --> 00:56:00,710
when some guy goes and modifies the

00:55:58,490 --> 00:56:02,330
template for infobox right if you ever

00:56:00,710 --> 00:56:03,230
don't we keep a Wikipedia page without

00:56:02,330 --> 00:56:05,510
an info box

00:56:03,230 --> 00:56:07,940
that's this box on the right-hand side

00:56:05,510 --> 00:56:09,860
that says like this country is you know

00:56:07,940 --> 00:56:12,800
it was founded at this time as this

00:56:09,860 --> 00:56:14,930
population you know or this species is

00:56:12,800 --> 00:56:16,790
this Latin name or whatever so this is

00:56:14,930 --> 00:56:21,020
big echo process in Wikipedia search

00:56:16,790 --> 00:56:22,460
engine with updates but so that's the

00:56:21,020 --> 00:56:24,830
use case there are lots of use cases

00:56:22,460 --> 00:56:31,520
just primary data stories are one of

00:56:24,830 --> 00:56:33,140
them yet um that was a very long answer

00:56:31,520 --> 00:56:35,060
to one question and it is very close to

00:56:33,140 --> 00:56:38,060
time for me to stop but I can keep

00:56:35,060 --> 00:56:39,830
answering questions and after I finish

00:56:38,060 --> 00:56:41,870
your video question I will be available

00:56:39,830 --> 00:56:43,670
with the table directly inside that door

00:56:41,870 --> 00:56:48,280
which is elastic statement we have a

00:56:43,670 --> 00:56:48,280
sponsor it's great shoot

00:56:49,760 --> 00:56:58,200
yeah we can do that too I mean I I do

00:56:55,530 --> 00:57:00,450
have two whole minutes to answer

00:56:58,200 --> 00:57:05,310
questions and then I can go I mean I'll

00:57:00,450 --> 00:57:07,170
be at the lake three days I will try to

00:57:05,310 --> 00:57:11,420
go to some talks though so you may miss

00:57:07,170 --> 00:57:11,420
me any other questions

00:57:18,269 --> 00:57:30,969
yeah so when I talked about statistics I

00:57:28,839 --> 00:57:32,739
actually talked about statistics that

00:57:30,969 --> 00:57:36,519
are calculated on the fly based on a

00:57:32,739 --> 00:57:40,839
query that you do so when when you do a

00:57:36,519 --> 00:57:43,029
query like this

00:57:40,839 --> 00:57:45,670
we can't service these statistics from

00:57:43,029 --> 00:57:47,650
any cache or from any pre-calculated

00:57:45,670 --> 00:57:49,569
space because you can stick any query

00:57:47,650 --> 00:57:51,749
you want here in the top right in this

00:57:49,569 --> 00:57:54,309
case you're you're only calculating the

00:57:51,749 --> 00:57:57,130
the statistics about the problem of the

00:57:54,309 --> 00:57:58,960
popularity score of pages that have the

00:57:57,130 --> 00:58:00,460
word small and domestic in them right so

00:57:58,960 --> 00:58:02,049
you get thinking about cat things about

00:58:00,460 --> 00:58:07,450
dogs and stuff but you don't get things

00:58:02,049 --> 00:58:09,579
about tigers so none of this stuff can

00:58:07,450 --> 00:58:11,079
be can be pre pre calculated this stuff

00:58:09,579 --> 00:58:12,609
is all calculated on the fly and it's

00:58:11,079 --> 00:58:14,859
all done by visiting all these documents

00:58:12,609 --> 00:58:25,509
with this doctor use doctor use data

00:58:14,859 --> 00:58:28,089
structure well it's so kind of yes it's

00:58:25,509 --> 00:58:30,190
ephemeral but there is a cache and

00:58:28,089 --> 00:58:32,049
there's a very smart cache so

00:58:30,190 --> 00:58:33,519
elasticsearch has like several different

00:58:32,049 --> 00:58:36,309
layers of caching depending on where you

00:58:33,519 --> 00:58:38,319
are certain things like filters are

00:58:36,309 --> 00:58:40,809
cache so that's the queries without

00:58:38,319 --> 00:58:42,910
score the the matching documents are

00:58:40,809 --> 00:58:45,579
cached and those work really really well

00:58:42,910 --> 00:58:49,869
because of that right once Nader nature

00:58:45,579 --> 00:58:51,759
of the data structure so that's cool the

00:58:49,869 --> 00:58:54,880
other thing that we cache is we actually

00:58:51,759 --> 00:58:56,499
cache the whole result of your query so

00:58:54,880 --> 00:58:58,539
if you came back to us within a couple

00:58:56,499 --> 00:59:00,009
of seconds and nobody else had blown the

00:58:58,539 --> 00:59:02,469
cache open yeah we could give you the

00:59:00,009 --> 00:59:04,239
same thing back and this is actually

00:59:02,469 --> 00:59:05,619
really a common use case if you believe

00:59:04,239 --> 00:59:10,089
it because what people do is they use a

00:59:05,619 --> 00:59:11,559
tool called kibana which is a it's a web

00:59:10,089 --> 00:59:14,710
app that lets you sort of slice and dice

00:59:11,559 --> 00:59:16,509
and it's it's designed for working with

00:59:14,710 --> 00:59:18,609
data that's like time-series and playing

00:59:16,509 --> 00:59:20,559
with it of making dashboards and reports

00:59:18,609 --> 00:59:22,119
on things so what'll happen to someone

00:59:20,559 --> 00:59:24,759
will make a dashboard and it'll save it

00:59:22,119 --> 00:59:27,410
and then like 50 people will open it or

00:59:24,759 --> 00:59:28,910
it'll be like on a bunch of monitors

00:59:27,410 --> 00:59:31,250
each monitor will be on computers so

00:59:28,910 --> 00:59:32,750
it's actually fairly common that we get

00:59:31,250 --> 00:59:34,700
really high cache hit rates for these

00:59:32,750 --> 00:59:36,260
dashboards now one thing that's very

00:59:34,700 --> 00:59:41,359
interesting is that if you stick a time

00:59:36,260 --> 00:59:45,890
range any especially if that time range

00:59:41,359 --> 00:59:47,869
has no in it it's for her - yes so what

00:59:45,890 --> 00:59:49,760
people often do when they when they're

00:59:47,869 --> 00:59:52,160
making these coupon dashboards is

00:59:49,760 --> 00:59:54,410
instead of writing one index they read

00:59:52,160 --> 00:59:59,839
in index per day or an index per week in

00:59:54,410 --> 01:00:01,400
an export hour or in an experiment we

00:59:59,839 --> 01:00:07,819
actually we have tools that help you

01:00:01,400 --> 01:00:11,299
whatever what we have in this cache is

01:00:07,819 --> 01:00:14,119
that before we make the cache key we

01:00:11,299 --> 01:00:16,130
rewrite the query based on statistics of

01:00:14,119 --> 01:00:18,319
the data that's on the current so this

01:00:16,130 --> 01:00:20,930
is where we do use these days for

01:00:18,319 --> 01:00:24,170
example we use the min and maximum time

01:00:20,930 --> 01:00:25,430
for a time to sit any caller any column

01:00:24,170 --> 01:00:27,410
that looks like a time or it looks like

01:00:25,430 --> 01:00:29,630
a number or anything that we can turn

01:00:27,410 --> 01:00:32,089
into the number if you have a range

01:00:29,630 --> 01:00:33,859
query which is what a time query is so

01:00:32,089 --> 01:00:36,470
you might have a huge range that says

01:00:33,859 --> 01:00:38,180
like you know a month worth of data and

01:00:36,470 --> 01:00:40,700
that actually ends up having to target

01:00:38,180 --> 01:00:46,640
30 indexes because we have maybe daily

01:00:40,700 --> 01:00:50,210
indexes and but for 28 of those indexes

01:00:46,640 --> 01:00:52,250
or 29 of those indexes it's literally

01:00:50,210 --> 01:00:54,109
hitting the entire index right it's it's

01:00:52,250 --> 01:00:57,170
the time range is across the whole index

01:00:54,109 --> 01:01:00,319
so if we rewrite that query before we

01:00:57,170 --> 01:01:04,730
make that cache key to the two sides of

01:01:00,319 --> 01:01:06,740
the index then it's the same query right

01:01:04,730 --> 01:01:08,690
so that's actually one of the fancy

01:01:06,740 --> 01:01:10,520
features in 510 oh it's called instant

01:01:08,690 --> 01:01:14,380
Cubana and the person who made it hates

01:01:10,520 --> 01:01:17,599
that name I just love that he hates it

01:01:14,380 --> 01:01:20,900
anyway he was so he on it on his on his

01:01:17,599 --> 01:01:23,029
note like in his house he captures you

01:01:20,900 --> 01:01:24,650
know performance statistics over and

01:01:23,029 --> 01:01:25,910
over and over again only about some

01:01:24,650 --> 01:01:27,799
desktop he adds or something some

01:01:25,910 --> 01:01:29,420
something you capture something is it's

01:01:27,799 --> 01:01:30,559
running all the time he's months worth

01:01:29,420 --> 01:01:32,000
of data and he's like well here's

01:01:30,559 --> 01:01:34,130
elasticsearch without again stinky

01:01:32,000 --> 01:01:38,420
bonnet and it takes like I don't know

01:01:34,130 --> 01:01:40,339
like a second two seconds to render to

01:01:38,420 --> 01:01:41,360
render this dashboard and then he goes

01:01:40,339 --> 01:01:42,770
here's the last history

01:01:41,360 --> 01:01:44,180
thank you Bona and the first time he

01:01:42,770 --> 01:01:46,340
does it it's like okay there's there's

01:01:44,180 --> 01:01:50,540
your second and then the second time

01:01:46,340 --> 01:01:54,320
it's like four milliseconds okay that's

01:01:50,540 --> 01:01:56,030
that's pretty instant uh you know couple

01:01:54,320 --> 01:01:57,440
orders of magnitude better I mean cuz

01:01:56,030 --> 01:01:59,570
it's cheating right it's caching caching

01:01:57,440 --> 01:02:04,310
is cheating but anyway you can cheat you

01:01:59,570 --> 01:02:06,200
should guess so we do but it only works

01:02:04,310 --> 01:02:08,990
for example like if the index isn't

01:02:06,200 --> 01:02:11,690
modified well actually that's very

01:02:08,990 --> 01:02:13,790
common not in the on-site search use

01:02:11,690 --> 01:02:15,470
case so Wikipedia never gets to use this

01:02:13,790 --> 01:02:17,120
cache because it's indexes are always

01:02:15,470 --> 01:02:19,640
modified and there's very long table

01:02:17,120 --> 01:02:23,630
searches so it doesn't matter but for

01:02:19,640 --> 01:02:25,880
these dashboards actually it's very

01:02:23,630 --> 01:02:29,960
common that those old indices are never

01:02:25,880 --> 01:02:39,910
modified anyway I've blown through all

01:02:29,960 --> 01:02:39,910

YouTube URL: https://www.youtube.com/watch?v=zYs6MRvWSas


