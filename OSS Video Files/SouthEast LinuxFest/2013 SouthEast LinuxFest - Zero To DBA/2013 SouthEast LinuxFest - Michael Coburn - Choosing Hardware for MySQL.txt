Title: 2013 SouthEast LinuxFest - Michael Coburn - Choosing Hardware for MySQL
Publication date: 2015-04-25
Playlist: 2013 SouthEast LinuxFest - Zero To DBA
Description: 
	2013 SouthEast LinuxFest
Michael Coburn
Choosing Hardware for MySQL
Captions: 
	00:00:00,000 --> 00:00:05,160
the following presentation was recorded

00:00:02,639 --> 00:00:08,280
at the 2013 southeast linux fest in

00:00:05,160 --> 00:00:10,860
charlotte north carolina it is licensed

00:00:08,280 --> 00:00:12,509
under a creative commons license for

00:00:10,860 --> 00:00:16,260
more information about the southeast

00:00:12,509 --> 00:00:19,680
linux fest visit WWF eastland TX

00:00:16,260 --> 00:00:21,060
phys.org the southeast linux fest would

00:00:19,680 --> 00:00:23,910
like to thank the following diamond

00:00:21,060 --> 00:00:28,199
sponsors in 2013 for helping make these

00:00:23,910 --> 00:00:33,870
videos possible I'm good here thank you

00:00:28,199 --> 00:00:36,899
everyone I want to say first off thanks

00:00:33,870 --> 00:00:38,040
for coming to my talk I know you've got

00:00:36,899 --> 00:00:39,750
a lot of different choices you can make

00:00:38,040 --> 00:00:43,170
today and I'm glad you found your way

00:00:39,750 --> 00:00:45,000
here just as a quick introduction my

00:00:43,170 --> 00:00:47,129
name is Michael Coburn I'm a consultant

00:00:45,000 --> 00:00:50,129
with percona where we do a database

00:00:47,129 --> 00:00:52,079
consulting mysql and performance really

00:00:50,129 --> 00:00:53,789
anywhere in the lamp stack we do help

00:00:52,079 --> 00:00:56,370
out some customers who are on non linux

00:00:53,789 --> 00:00:58,350
on windows and on freebsd and other

00:00:56,370 --> 00:00:59,579
things like that too so if you guys are

00:00:58,350 --> 00:01:01,469
ever in the market for needing some help

00:00:59,579 --> 00:01:04,680
with any projects or looking for support

00:01:01,469 --> 00:01:06,630
agreements were there to help you the

00:01:04,680 --> 00:01:08,670
the nature of my talk today what I'm

00:01:06,630 --> 00:01:10,439
trying to help all of you in the room is

00:01:08,670 --> 00:01:12,000
to understand what goes into a database

00:01:10,439 --> 00:01:14,520
when you're looking to source hardware

00:01:12,000 --> 00:01:16,530
for it I name the talk choosing hardware

00:01:14,520 --> 00:01:18,150
for MySQL it's applicable to any other

00:01:16,530 --> 00:01:19,770
database out there I'm going to be

00:01:18,150 --> 00:01:21,180
talking about specific things within my

00:01:19,770 --> 00:01:23,070
you all different ways that uses memory

00:01:21,180 --> 00:01:24,330
and stuff like that but if you can like

00:01:23,070 --> 00:01:25,619
maybe take a step back when you're

00:01:24,330 --> 00:01:27,390
hearing that if you're not a mysql user

00:01:25,619 --> 00:01:30,210
it'll apply to your other database

00:01:27,390 --> 00:01:31,829
product as well i'm also not going to be

00:01:30,210 --> 00:01:34,079
standing up here pushing any particular

00:01:31,829 --> 00:01:35,400
vendor i'm not going to say fusion-io is

00:01:34,079 --> 00:01:37,350
better than burden or anything like that

00:01:35,400 --> 00:01:39,479
you can make those decisions yourselves

00:01:37,350 --> 00:01:40,710
and we've got benchmarks on the SSD

00:01:39,479 --> 00:01:42,720
performance blog and things like that

00:01:40,710 --> 00:01:44,850
you can look at and evaluate those

00:01:42,720 --> 00:01:46,409
metrics i'm here more to educate you on

00:01:44,850 --> 00:01:47,700
what are some of the paradigms and

00:01:46,409 --> 00:01:53,130
thought processes you might want to go

00:01:47,700 --> 00:01:54,360
through okay so here we go so we're

00:01:53,130 --> 00:01:56,189
going to cover off a number of different

00:01:54,360 --> 00:01:57,600
sections I really want to share with you

00:01:56,189 --> 00:01:59,250
some numbers you've probably seen before

00:01:57,600 --> 00:02:00,990
we're going to talk about where things

00:01:59,250 --> 00:02:02,520
are faster than other things I'll get to

00:02:00,990 --> 00:02:04,380
that right away talk a little bit about

00:02:02,520 --> 00:02:06,630
what it means in a cpu for using a

00:02:04,380 --> 00:02:08,670
database some about the memory

00:02:06,630 --> 00:02:10,470
utilization and also how it uses disk

00:02:08,670 --> 00:02:12,840
we're going to look at what's the impact

00:02:10,470 --> 00:02:14,580
of the network on your database server

00:02:12,840 --> 00:02:16,019
touch quickly on the Amazon Cloud I'm

00:02:14,580 --> 00:02:18,269
not touting them in a particular case

00:02:16,019 --> 00:02:20,220
but AWS is the largest cloud provider so

00:02:18,269 --> 00:02:22,470
most people are most familiar with it so

00:02:20,220 --> 00:02:23,610
we just use that as a use case and then

00:02:22,470 --> 00:02:25,349
last we'll just talk about a few

00:02:23,610 --> 00:02:28,440
components of running mysql on different

00:02:25,349 --> 00:02:30,150
types of hardware okay so before I

00:02:28,440 --> 00:02:31,709
actually before I get too far can I just

00:02:30,150 --> 00:02:35,220
maybe take a quick hands in the air

00:02:31,709 --> 00:02:36,959
anybody use MySQL today okay most of you

00:02:35,220 --> 00:02:39,000
good I'm glad to see our Oracle

00:02:36,959 --> 00:02:42,480
representative this is a myschool user

00:02:39,000 --> 00:02:44,549
do are any of you I'm responsible in any

00:02:42,480 --> 00:02:46,440
regard to their offering advice or

00:02:44,549 --> 00:02:50,459
actually making the purchase orders for

00:02:46,440 --> 00:02:51,630
new hardware okay good okay good and you

00:02:50,459 --> 00:02:52,769
know this can be anywhere from your

00:02:51,630 --> 00:02:54,180
large college campuses where you're

00:02:52,769 --> 00:02:55,530
buying hundreds of servers down to maybe

00:02:54,180 --> 00:02:56,400
you know you know you're trying to

00:02:55,530 --> 00:02:58,739
figure out if you need to go to the

00:02:56,400 --> 00:03:00,720
cloud or go somewhere to some provision

00:02:58,739 --> 00:03:03,540
hardware is this kind of this slide deck

00:03:00,720 --> 00:03:04,799
should help you get through that okay I

00:03:03,540 --> 00:03:07,650
think I've touched that most of stuff I

00:03:04,799 --> 00:03:09,450
do listed as beginner intermediate feel

00:03:07,650 --> 00:03:10,530
free this is a small enough group for it

00:03:09,450 --> 00:03:11,610
if you have questions as I'm going

00:03:10,530 --> 00:03:13,079
through it just raise your hand I'm

00:03:11,610 --> 00:03:15,900
happy to stop where I'm at and we can

00:03:13,079 --> 00:03:16,739
talk it through I fully expect also that

00:03:15,900 --> 00:03:18,930
you're going to have differences of

00:03:16,739 --> 00:03:21,209
opinion where where I go on on some some

00:03:18,930 --> 00:03:22,859
of these angles so if you do and you're

00:03:21,209 --> 00:03:27,829
not afraid to share it raise it up and

00:03:22,859 --> 00:03:31,220
we can talk it through okay okay so

00:03:27,829 --> 00:03:33,480
everybody should know that in the stack

00:03:31,220 --> 00:03:35,840
likely your hard disk is going to be

00:03:33,480 --> 00:03:37,560
your bottleneck in terms of slowness

00:03:35,840 --> 00:03:39,329
okay I don't think we'll have any

00:03:37,560 --> 00:03:41,220
disagreements there on the high end

00:03:39,329 --> 00:03:42,299
you've got things like the CPU cache

00:03:41,220 --> 00:03:45,030
which are going to be faster than

00:03:42,299 --> 00:03:46,500
anything else in between we've got

00:03:45,030 --> 00:03:48,660
things like the RAM which we've labeled

00:03:46,500 --> 00:03:51,060
as memory we've got flash storage and

00:03:48,660 --> 00:03:52,470
SSD this isn't really to scale but the

00:03:51,060 --> 00:03:54,030
significance is is that you go from the

00:03:52,470 --> 00:03:55,079
bottom to the top this is that this is

00:03:54,030 --> 00:04:00,389
the metrics we're going to be working

00:03:55,079 --> 00:04:01,739
with okay okay this is a cool set of

00:04:00,389 --> 00:04:03,720
numbers that I think somebody at Google

00:04:01,739 --> 00:04:04,769
had posted a few years ago and it's made

00:04:03,720 --> 00:04:06,989
its way around the internet just little

00:04:04,769 --> 00:04:09,030
while ago again basically what it's

00:04:06,989 --> 00:04:10,319
showing is is a the ratio of getting an

00:04:09,030 --> 00:04:12,599
operation done at each of these

00:04:10,319 --> 00:04:16,200
different types of memory spot cpu

00:04:12,599 --> 00:04:17,849
registers using the network using a hard

00:04:16,200 --> 00:04:19,079
drive all these kinds of things so what

00:04:17,849 --> 00:04:21,659
I'm trying to show here though is that

00:04:19,079 --> 00:04:23,420
it's orders of magnitude faster to be

00:04:21,659 --> 00:04:24,920
doing things in the CPU

00:04:23,420 --> 00:04:26,390
then the next thing is it's faster to do

00:04:24,920 --> 00:04:28,790
things in memory between memory and the

00:04:26,390 --> 00:04:30,200
CPU and as you crawl all the way down to

00:04:28,790 --> 00:04:32,330
the network you're looking at something

00:04:30,200 --> 00:04:34,160
like 150 milliseconds to be bouncing a

00:04:32,330 --> 00:04:36,320
packet from California to another lens

00:04:34,160 --> 00:04:37,700
and back okay so try just trying to keep

00:04:36,320 --> 00:04:39,050
these these paradigms in mind these

00:04:37,700 --> 00:04:40,490
these these lengths of time it takes to

00:04:39,050 --> 00:04:44,000
do things we're going to come back to

00:04:40,490 --> 00:04:46,940
these kinds of numbers later on okay

00:04:44,000 --> 00:04:48,200
when you source for a CPU you've got a

00:04:46,940 --> 00:04:49,760
bunch of different choices that you need

00:04:48,200 --> 00:04:51,260
to factor in both from within your

00:04:49,760 --> 00:04:52,580
application also from what the hardware

00:04:51,260 --> 00:04:54,800
vendors telling you about what their

00:04:52,580 --> 00:04:56,870
CPUs can do you need to think about how

00:04:54,800 --> 00:04:58,580
scalable your app needs to be okay are

00:04:56,870 --> 00:05:00,380
you in the model where you need to put

00:04:58,580 --> 00:05:01,910
everything on a single host because your

00:05:00,380 --> 00:05:03,500
developers don't have the time to

00:05:01,910 --> 00:05:05,840
implement readwrite splitting in your

00:05:03,500 --> 00:05:07,250
application or are you already ready to

00:05:05,840 --> 00:05:09,470
be doing sharding and what you're going

00:05:07,250 --> 00:05:11,420
to do is source many many servers and

00:05:09,470 --> 00:05:13,340
only have smaller sets of data on each

00:05:11,420 --> 00:05:15,230
and you need to go with smaller sets of

00:05:13,340 --> 00:05:16,760
CPU these are things you need to decide

00:05:15,230 --> 00:05:17,450
with your development team when you're

00:05:16,760 --> 00:05:19,040
when you're coming up to your

00:05:17,450 --> 00:05:19,970
application so depending on where you're

00:05:19,040 --> 00:05:21,500
out in that space it's going to

00:05:19,970 --> 00:05:25,010
influence the CPU choices that you make

00:05:21,500 --> 00:05:26,690
okay cpus can also be a large source of

00:05:25,010 --> 00:05:28,160
mutex contention so you need to watch

00:05:26,690 --> 00:05:29,630
out that they don't become a bottleneck

00:05:28,160 --> 00:05:32,180
just by virtue of having either too many

00:05:29,630 --> 00:05:33,860
or too few course we're going to look at

00:05:32,180 --> 00:05:35,480
different types of response time and

00:05:33,860 --> 00:05:38,330
throughput that a particular CPU can

00:05:35,480 --> 00:05:40,040
deliver now there was a big race for a

00:05:38,330 --> 00:05:42,370
number of years ago where it was let's

00:05:40,040 --> 00:05:44,600
get faster clock speeds on these things

00:05:42,370 --> 00:05:46,490
every year you know you'd see going up

00:05:44,600 --> 00:05:47,870
by half a gigahertz and you know we kind

00:05:46,490 --> 00:05:50,060
of peaked at around this 3 or this 4

00:05:47,870 --> 00:05:51,260
gigahertz range right now well now we've

00:05:50,060 --> 00:05:54,260
seen a lot more of the vendors go to

00:05:51,260 --> 00:05:55,670
multi-core architecture and as that's

00:05:54,260 --> 00:05:57,560
changed as the hardware vendors have

00:05:55,670 --> 00:05:59,450
kind of led this path we followed with

00:05:57,560 --> 00:06:01,670
the applications follow that so what I

00:05:59,450 --> 00:06:03,470
mean is MySQL used to be you know let's

00:06:01,670 --> 00:06:05,090
go for single-threaded work workloads

00:06:03,470 --> 00:06:06,590
because we're seeing the CPUs get so

00:06:05,090 --> 00:06:08,390
fast that you're single threaded

00:06:06,590 --> 00:06:10,100
workload last year it's just faster by

00:06:08,390 --> 00:06:11,540
virtue of a faster cpu this year and

00:06:10,100 --> 00:06:15,140
that was good enough for most people

00:06:11,540 --> 00:06:17,360
with the change to multiple cores MySQL

00:06:15,140 --> 00:06:18,890
back in the 50 days was only happy with

00:06:17,360 --> 00:06:20,840
maybe four cores anything beyond that

00:06:18,890 --> 00:06:21,980
and it didn't really utilize them but

00:06:20,840 --> 00:06:23,840
these days you know you could be looking

00:06:21,980 --> 00:06:26,960
at numbers around twenty four cores as a

00:06:23,840 --> 00:06:28,520
sweet spot for MySQL the people from

00:06:26,960 --> 00:06:30,800
Oracle will have some some different

00:06:28,520 --> 00:06:32,090
angle on that 256 is going to introduce

00:06:30,800 --> 00:06:34,910
a whole different paradigm but if you're

00:06:32,090 --> 00:06:36,440
on a MySQL 55 implementation shopping

00:06:34,910 --> 00:06:37,260
around the 24 core is a pretty sweet

00:06:36,440 --> 00:06:38,880
spot in terms of what

00:06:37,260 --> 00:06:40,380
my school can do and what your budget is

00:06:38,880 --> 00:06:42,210
going to allow you realize as you go to

00:06:40,380 --> 00:06:43,590
more cores and fitting in a number of

00:06:42,210 --> 00:06:45,420
sockets and a server that's going to

00:06:43,590 --> 00:06:48,600
make that a much more expensive server

00:06:45,420 --> 00:06:49,920
for you to acquire okay how's the pace

00:06:48,600 --> 00:06:52,010
so far did people feel like this is

00:06:49,920 --> 00:06:58,740
enough for am I going too fast too slow

00:06:52,010 --> 00:07:00,750
so far so good ok all right ok so in a

00:06:58,740 --> 00:07:02,160
perfect world we want to see these nice

00:07:00,750 --> 00:07:04,200
little hockey stick kind of curves

00:07:02,160 --> 00:07:06,360
things are kind of plateau is you just

00:07:04,200 --> 00:07:08,430
have a few and as you get up higher with

00:07:06,360 --> 00:07:09,900
a number of CPUs things are going to go

00:07:08,430 --> 00:07:11,610
through the roof that's how it's

00:07:09,900 --> 00:07:13,530
supposed to work that's what everybody

00:07:11,610 --> 00:07:14,790
talks about in school and there's it's

00:07:13,530 --> 00:07:16,830
just the way it's supposed to be but

00:07:14,790 --> 00:07:18,510
what really happens it never really gets

00:07:16,830 --> 00:07:20,460
that high there's a lot of different

00:07:18,510 --> 00:07:21,960
bottlenecks that come into play my my

00:07:20,460 --> 00:07:23,850
work as a consultant is focused mainly

00:07:21,960 --> 00:07:26,010
on MySQL so I see a lot of the colonel

00:07:23,850 --> 00:07:28,020
mutexes and other bottlenecks at mysql

00:07:26,010 --> 00:07:30,750
introduces as you try to go to more cpus

00:07:28,020 --> 00:07:31,980
so on my school my school can be a

00:07:30,750 --> 00:07:35,550
problem when you start to get up to like

00:07:31,980 --> 00:07:37,770
this 64 range okay sometimes it can get

00:07:35,550 --> 00:07:40,260
even a bit slower again its workload

00:07:37,770 --> 00:07:41,640
dependent the best thing that you could

00:07:40,260 --> 00:07:43,350
do if you're a big enough buyer is maybe

00:07:41,640 --> 00:07:44,550
get a try and buy from your provider if

00:07:43,350 --> 00:07:46,800
you're working with dell maybe a lil

00:07:44,550 --> 00:07:48,300
shiftee a server that has 64 cores so

00:07:46,800 --> 00:07:49,860
you can give it a test and if you like

00:07:48,300 --> 00:07:51,630
you keep it and pay them for it if you

00:07:49,860 --> 00:07:53,760
don't send it back and you get lesser

00:07:51,630 --> 00:07:55,680
equipment but that's been used with the

00:07:53,760 --> 00:07:57,600
number of our own clients as a

00:07:55,680 --> 00:07:58,860
competitive advantage they can go out

00:07:57,600 --> 00:08:00,570
and source to figure out if they need to

00:07:58,860 --> 00:08:03,120
spend 20 grand on the server with a lot

00:08:00,570 --> 00:08:05,160
of CPUs throw their workload at it or do

00:08:03,120 --> 00:08:07,110
they go somewhere around 32 or 24 course

00:08:05,160 --> 00:08:08,190
so it's a way of kind of bending the

00:08:07,110 --> 00:08:09,330
vendor to say I'm going to give you a

00:08:08,190 --> 00:08:10,830
hundred thousand dollars one way or the

00:08:09,330 --> 00:08:12,500
other can you just help me out by

00:08:10,830 --> 00:08:14,850
letting me do a little trying by here

00:08:12,500 --> 00:08:16,680
okay that's hardware on the flip side if

00:08:14,850 --> 00:08:18,600
you're going to go to the cloud how easy

00:08:16,680 --> 00:08:19,650
is it to spin up a larger instance you

00:08:18,600 --> 00:08:21,150
should be doing that you should be

00:08:19,650 --> 00:08:23,370
taking advantage of the fact you have

00:08:21,150 --> 00:08:24,900
this raw capacity there try your

00:08:23,370 --> 00:08:26,700
workload on something higher until you

00:08:24,900 --> 00:08:31,590
get to this this degradation here where

00:08:26,700 --> 00:08:34,140
it starts to tip off again okay okay so

00:08:31,590 --> 00:08:36,330
when you get into mysql and i'm going to

00:08:34,140 --> 00:08:38,669
talk mostly about 55 but and as you get

00:08:36,330 --> 00:08:40,470
older versions 51 and 50 these things

00:08:38,669 --> 00:08:41,910
problems get worse it's like any piece

00:08:40,470 --> 00:08:45,660
of software it gets better as it as it

00:08:41,910 --> 00:08:47,100
ages okay so what happens a lot in mysql

00:08:45,660 --> 00:08:48,750
and this is still a problem going into

00:08:47,100 --> 00:08:49,840
56 there's a number of different kernel

00:08:48,750 --> 00:08:51,490
mutexes that happen

00:08:49,840 --> 00:08:52,930
and what effectively that means is it's

00:08:51,490 --> 00:08:55,150
going to stall out the database server

00:08:52,930 --> 00:08:58,060
for some fractional period of time okay

00:08:55,150 --> 00:08:59,440
by itself on a low low concurrency

00:08:58,060 --> 00:09:01,570
workload that's not that big of a deal

00:08:59,440 --> 00:09:03,550
but if you have a server that's doing 10

00:09:01,570 --> 00:09:05,350
or 20,000 queries per second let's just

00:09:03,550 --> 00:09:07,350
zipping along these kinds of mutex

00:09:05,350 --> 00:09:10,390
problems we're going to turn into slow

00:09:07,350 --> 00:09:12,700
stalls or slow response time to queries

00:09:10,390 --> 00:09:15,730
and depending on your application you

00:09:12,700 --> 00:09:19,030
might be very sensitive to that okay so

00:09:15,730 --> 00:09:21,100
so those are things to watch out for you

00:09:19,030 --> 00:09:22,330
also need to make sure that that other

00:09:21,100 --> 00:09:24,130
types of locks that are being held

00:09:22,330 --> 00:09:27,490
within the database don't also start to

00:09:24,130 --> 00:09:29,950
get in your way okay things like role of

00:09:27,490 --> 00:09:31,930
locks gap locking that can happen on the

00:09:29,950 --> 00:09:33,250
primary keys and inner DB those can all

00:09:31,930 --> 00:09:35,170
be sources of places where you're going

00:09:33,250 --> 00:09:40,180
to see a lock or a stall happen and

00:09:35,170 --> 00:09:42,100
potentially block other queries ok so

00:09:40,180 --> 00:09:43,720
just I guess I probably could just jump

00:09:42,100 --> 00:09:45,070
over the slide but basically things were

00:09:43,720 --> 00:09:48,070
a lot worse back in the day we've been

00:09:45,070 --> 00:09:49,870
getting better at it we'll see in 56 the

00:09:48,070 --> 00:09:52,720
adoption hasn't been as quick a guess is

00:09:49,870 --> 00:09:54,790
as we'd hoped on 56 or maybe it's going

00:09:52,720 --> 00:09:56,080
at the rate that we want but net effect

00:09:54,790 --> 00:09:58,380
is there's not a lot of customers out

00:09:56,080 --> 00:10:00,370
there yet on 56 and production so

00:09:58,380 --> 00:10:01,870
proponent feel comfortable yet quoting

00:10:00,370 --> 00:10:03,370
where where it's going to be we've got

00:10:01,870 --> 00:10:06,010
some work load tests that we've been

00:10:03,370 --> 00:10:08,260
working on some oltp load some

00:10:06,010 --> 00:10:09,550
suspension type tests so we've got some

00:10:08,260 --> 00:10:11,200
theoretical what should these workloads

00:10:09,550 --> 00:10:12,880
do but we're still waiting for probably

00:10:11,200 --> 00:10:15,160
another few months for customers to come

00:10:12,880 --> 00:10:17,590
back and say look 56 is a huge win we've

00:10:15,160 --> 00:10:19,540
eliminated a lot of new Texas but right

00:10:17,590 --> 00:10:23,860
now 55 is really what what a lot of our

00:10:19,540 --> 00:10:26,140
customers are running on ok so CPU is

00:10:23,860 --> 00:10:28,570
sticking on that topic they can be good

00:10:26,140 --> 00:10:29,740
and they can be bad having a lot of CPUs

00:10:28,570 --> 00:10:32,530
mean you can get a lot of work done

00:10:29,740 --> 00:10:34,510
that's what you'd expect where it can

00:10:32,530 --> 00:10:36,310
become a problem as as your server as a

00:10:34,510 --> 00:10:37,810
whole gets loaded and you start to get

00:10:36,310 --> 00:10:39,550
up around seventy-five eighty five

00:10:37,810 --> 00:10:41,500
percent you're going to start to notice

00:10:39,550 --> 00:10:44,140
that a lot of the jobs are starting to

00:10:41,500 --> 00:10:45,910
wait on getting access to the CPU and

00:10:44,140 --> 00:10:47,650
you may not have that visibility

00:10:45,910 --> 00:10:49,800
directly in it but as your as you're

00:10:47,650 --> 00:10:52,150
aware from a theoretical perspective

00:10:49,800 --> 00:10:53,710
jobs are starting to queue and that

00:10:52,150 --> 00:10:55,450
means if they can't get cpu time they're

00:10:53,710 --> 00:10:56,920
going to be sitting in a block State so

00:10:55,450 --> 00:10:58,600
you might be able to notice this using

00:10:56,920 --> 00:10:59,980
tools like vmstat and some other tools

00:10:58,600 --> 00:11:01,810
that are that are monitoring your system

00:10:59,980 --> 00:11:02,850
for you but what you'll find the net

00:11:01,810 --> 00:11:04,769
effect is you

00:11:02,850 --> 00:11:07,949
see performance drop off before one

00:11:04,769 --> 00:11:10,829
hundred percent cpu utilization so being

00:11:07,949 --> 00:11:12,480
low utilization is ok as you get up

00:11:10,829 --> 00:11:14,250
around fifty percent you're probably in

00:11:12,480 --> 00:11:15,569
a nice sweet spot but as you start to

00:11:14,250 --> 00:11:17,160
get up somewhere around seventy eighty

00:11:15,569 --> 00:11:18,360
percent things might start to slide off

00:11:17,160 --> 00:11:20,459
a lot it's certainly had one hundred

00:11:18,360 --> 00:11:21,839
percent you're going to be CPU bound and

00:11:20,459 --> 00:11:23,190
you're not getting as much through put

00:11:21,839 --> 00:11:24,540
your queries aren't responding as

00:11:23,190 --> 00:11:30,180
quickly as they potentially could be

00:11:24,540 --> 00:11:33,420
okay so when you're out there shopping

00:11:30,180 --> 00:11:35,459
what do you do well it depends it really

00:11:33,420 --> 00:11:37,680
does depend you do want to get the

00:11:35,459 --> 00:11:39,089
fastest CPUs you can afford you probably

00:11:37,680 --> 00:11:40,319
don't want to go to the highest end

00:11:39,089 --> 00:11:41,819
because that's where the vendor is

00:11:40,319 --> 00:11:43,199
probably got its highest margins on it

00:11:41,819 --> 00:11:44,370
it's going to cost you the most but

00:11:43,199 --> 00:11:46,980
that's that's a decision for you to make

00:11:44,370 --> 00:11:48,120
if you're flushed with VC money and you

00:11:46,980 --> 00:11:49,740
don't know what to do with it all yeah

00:11:48,120 --> 00:11:53,240
go out there and buy what you can okay

00:11:49,740 --> 00:11:56,250
but not everybody has that option so

00:11:53,240 --> 00:11:57,360
keep in mind in my screwball I won't

00:11:56,250 --> 00:11:59,490
call my another database service is

00:11:57,360 --> 00:12:01,170
probably different but in mysql one cpu

00:11:59,490 --> 00:12:03,449
is busy with one thread or what or

00:12:01,170 --> 00:12:05,250
conversely one thread is on one cpu at a

00:12:03,449 --> 00:12:07,170
time we don't yet have a way for a

00:12:05,250 --> 00:12:10,860
thread to be split across multiple CPUs

00:12:07,170 --> 00:12:13,019
okay so if you have a concurrency in

00:12:10,860 --> 00:12:15,000
your database of you know 2430 queries

00:12:13,019 --> 00:12:17,160
running you're probably going to be

00:12:15,000 --> 00:12:18,329
using all your course already I hope

00:12:17,160 --> 00:12:19,920
your database server is only doing

00:12:18,329 --> 00:12:21,389
database work so you assume those twenty

00:12:19,920 --> 00:12:23,399
four cores or dedicated to the database

00:12:21,389 --> 00:12:24,720
server but the significance is is that

00:12:23,399 --> 00:12:26,579
if you're starting to get threads

00:12:24,720 --> 00:12:28,019
running higher than the count of CPUs

00:12:26,579 --> 00:12:30,449
you have you could be starting to get

00:12:28,019 --> 00:12:32,880
yourself into a bottle next situation so

00:12:30,449 --> 00:12:34,920
watch for that again we talked about

00:12:32,880 --> 00:12:39,779
this really quickly more cores going to

00:12:34,920 --> 00:12:41,910
be more concurrency 24 maybe 32 ok most

00:12:39,779 --> 00:12:43,170
common architecture is on 64-bit I don't

00:12:41,910 --> 00:12:45,439
see a lot of customers these days on

00:12:43,170 --> 00:12:47,639
32-bit unless they made a mistake so

00:12:45,439 --> 00:12:49,709
maybe this is a little bit outdated but

00:12:47,639 --> 00:12:51,630
significance is you want to be on 64-bit

00:12:49,709 --> 00:12:53,699
I think even the smallest amazon image

00:12:51,630 --> 00:12:57,750
it one gig will already pop you onto a

00:12:53,699 --> 00:13:00,329
64-bit operating system okay so what do

00:12:57,750 --> 00:13:01,740
you do to watch this stuff well when I

00:13:00,329 --> 00:13:03,060
get on with customers I usually see two

00:13:01,740 --> 00:13:04,470
or three different customers a week I

00:13:03,060 --> 00:13:05,939
don't know anything about them until I

00:13:04,470 --> 00:13:08,220
get on to help them with the problem or

00:13:05,939 --> 00:13:09,420
help them with the project ideally the

00:13:08,220 --> 00:13:11,730
running linux because that's where I'm

00:13:09,420 --> 00:13:14,490
most comfortable fortunately most

00:13:11,730 --> 00:13:16,710
distributions have vmstat iostat and a

00:13:14,490 --> 00:13:18,390
number of basic tools always installed

00:13:16,710 --> 00:13:19,650
those are the ones I go to and these are

00:13:18,390 --> 00:13:21,120
the ones that work the best there to

00:13:19,650 --> 00:13:22,650
battle tested they've been around for

00:13:21,120 --> 00:13:24,570
years probably everybody in this room is

00:13:22,650 --> 00:13:26,700
familiar with it what are you looking

00:13:24,570 --> 00:13:27,750
for though and vmstat well I probably

00:13:26,700 --> 00:13:28,860
should have highlighted a little this a

00:13:27,750 --> 00:13:30,690
little bit better so I don't know how

00:13:28,860 --> 00:13:32,550
well we can see it in the back but I

00:13:30,690 --> 00:13:35,250
look at basically two different sections

00:13:32,550 --> 00:13:37,500
depending on I never stolen CPU here so

00:13:35,250 --> 00:13:39,210
depending on what's happening in CPU on

00:13:37,500 --> 00:13:40,680
the right-hand side these are the

00:13:39,210 --> 00:13:42,900
typical things you see it when you run

00:13:40,680 --> 00:13:44,790
top okay you're looking at where's the

00:13:42,900 --> 00:13:46,590
CPU spending its time is it in user

00:13:44,790 --> 00:13:47,940
space is it with the system is it

00:13:46,590 --> 00:13:50,370
actually idle or is it waiting on a

00:13:47,940 --> 00:13:51,600
block device somewhere in this case we

00:13:50,370 --> 00:13:53,940
see a server that's actually doing quite

00:13:51,600 --> 00:13:55,920
a bit of weight time I would say that

00:13:53,940 --> 00:13:57,570
probably anything about fifty percent is

00:13:55,920 --> 00:13:59,430
a source of concern I talk to a customer

00:13:57,570 --> 00:14:01,080
and say we probably need to do something

00:13:59,430 --> 00:14:02,400
about that disk you've got and that's

00:14:01,080 --> 00:14:04,470
usually where the promise but it could

00:14:02,400 --> 00:14:07,680
be blocked on on network as well okay

00:14:04,470 --> 00:14:09,390
the idle state and sorry the system

00:14:07,680 --> 00:14:11,100
state is more the kernel level thing

00:14:09,390 --> 00:14:12,930
you're not going to see probably too

00:14:11,100 --> 00:14:15,270
high of a number in there four per cents

00:14:12,930 --> 00:14:17,070
probably already kind of high and then

00:14:15,270 --> 00:14:19,020
the user space if you're a CPU bound

00:14:17,070 --> 00:14:20,100
workload with MySQL that's where most of

00:14:19,020 --> 00:14:21,450
the processing is going to be happening

00:14:20,100 --> 00:14:24,210
that's where you're going to see the

00:14:21,450 --> 00:14:25,980
highest numbers the other two numbers

00:14:24,210 --> 00:14:27,420
that I'll watch though for we already

00:14:25,980 --> 00:14:28,860
see we've got some high numbers in the

00:14:27,420 --> 00:14:30,540
weight column when you look over the

00:14:28,860 --> 00:14:32,790
first two columns you've got the running

00:14:30,540 --> 00:14:34,170
and then the blocked the B column is

00:14:32,790 --> 00:14:36,480
that I'd be eyeballing and saying we'll

00:14:34,170 --> 00:14:39,060
look at some point I had 11 13 10

00:14:36,480 --> 00:14:41,460
different processes or threads blocked

00:14:39,060 --> 00:14:43,110
waiting for something to happen so this

00:14:41,460 --> 00:14:45,150
server has some measure of contention

00:14:43,110 --> 00:14:48,750
going on probably with its disks that's

00:14:45,150 --> 00:14:50,310
the first place I'd look okay if you

00:14:48,750 --> 00:14:52,110
also want to take another view of it you

00:14:50,310 --> 00:14:53,940
can look at exactly what the the CPUs

00:14:52,110 --> 00:14:56,160
are doing you can use MP stat to do that

00:14:53,940 --> 00:14:58,860
okay this view here where you do p all

00:14:56,160 --> 00:15:01,350
will show a split of all the cpus and

00:14:58,860 --> 00:15:03,150
also summarize them so generally the

00:15:01,350 --> 00:15:05,040
value along the all line should match

00:15:03,150 --> 00:15:07,320
something of what vmstat is saying for

00:15:05,040 --> 00:15:09,330
where the CPU spending its time but

00:15:07,320 --> 00:15:10,920
what's significant is you can watch MP

00:15:09,330 --> 00:15:12,780
stat if you're concerned that maybe one

00:15:10,920 --> 00:15:14,850
CPUs getting pinned all the time this

00:15:12,780 --> 00:15:15,930
will very clearly show one cpu doing one

00:15:14,850 --> 00:15:19,020
hundred percent and the rest of them

00:15:15,930 --> 00:15:20,880
idle okay so in that case MP stack can

00:15:19,020 --> 00:15:22,950
help you diagnose when you've got a

00:15:20,880 --> 00:15:24,570
thread that's that's a very busy threat

00:15:22,950 --> 00:15:26,130
itself but it's not actually utilizing

00:15:24,570 --> 00:15:27,330
all your course MP stack can show you

00:15:26,130 --> 00:15:29,450
how well all your cores are being

00:15:27,330 --> 00:15:29,450
utilized

00:15:29,819 --> 00:15:37,170
okay so any questions before I move on

00:15:33,249 --> 00:15:39,310
about CPU any any angles of your own or

00:15:37,170 --> 00:15:43,860
any change differences of opinion with

00:15:39,310 --> 00:15:43,860
anything I've said or the extreme I

00:15:49,199 --> 00:15:54,120
don't have any experience without

00:15:50,829 --> 00:15:59,230
directly anybody have any opinion on it

00:15:54,120 --> 00:16:01,769
ok so just cash yeah it's my own infant

00:15:59,230 --> 00:16:04,059
unfamiliarity with with those specs but

00:16:01,769 --> 00:16:10,509
certainly having more cash on the on the

00:16:04,059 --> 00:16:12,519
CPUs is more beneficial thank you i'm

00:16:10,509 --> 00:16:14,290
sorry the question was that it was a

00:16:12,519 --> 00:16:22,720
difference between the extreme cpus and

00:16:14,290 --> 00:16:24,430
the i7s okay okay so might as well minus

00:16:22,720 --> 00:16:26,379
close the database server it uses memory

00:16:24,430 --> 00:16:28,029
why does it use memory it needs to cache

00:16:26,379 --> 00:16:29,290
things because again when we go back to

00:16:28,029 --> 00:16:31,059
that earlier slide where we talked about

00:16:29,290 --> 00:16:33,339
the speed of retrieval from different

00:16:31,059 --> 00:16:35,110
sources Ram is a lot faster than going

00:16:33,339 --> 00:16:36,639
to disk so if you can cash things in

00:16:35,110 --> 00:16:38,740
memory you're much better off in terms

00:16:36,639 --> 00:16:40,059
of responding to queries we'll talk a

00:16:38,740 --> 00:16:40,899
little bit where it actually uses it

00:16:40,059 --> 00:16:43,930
there's a number of different components

00:16:40,899 --> 00:16:45,970
of my school that do use memory we'll

00:16:43,930 --> 00:16:47,680
talk a little bit about what kind of

00:16:45,970 --> 00:16:48,970
memory size is appropriate for you how

00:16:47,680 --> 00:16:51,250
to determine what that should be and

00:16:48,970 --> 00:16:52,809
we're going to look at does it actually

00:16:51,250 --> 00:16:54,430
need to all be a memory or sometimes can

00:16:52,809 --> 00:16:58,240
you depend on the disk being fast enough

00:16:54,430 --> 00:17:00,399
to satisfy your workload okay so where

00:16:58,240 --> 00:17:02,620
does my school use memory it's got three

00:17:00,399 --> 00:17:05,530
main areas they're not all one-third

00:17:02,620 --> 00:17:07,149
one-third one-third okay by and large in

00:17:05,530 --> 00:17:09,069
assuming that you're running in or DB

00:17:07,149 --> 00:17:10,899
most customers are most people are these

00:17:09,069 --> 00:17:12,399
days if you're not running in a DB

00:17:10,899 --> 00:17:14,709
usually have a very specific use case

00:17:12,399 --> 00:17:17,829
you need full text search until inner DB

00:17:14,709 --> 00:17:18,939
5.6 so the reasons for using my sim are

00:17:17,829 --> 00:17:20,350
kind of going away but there are some

00:17:18,939 --> 00:17:22,480
nisha so i'm going to focus most of this

00:17:20,350 --> 00:17:23,949
on energy be okay well inner DB has this

00:17:22,480 --> 00:17:26,110
beautiful piece of it called the innodb

00:17:23,949 --> 00:17:28,329
buffer pool and its purpose is to cache

00:17:26,110 --> 00:17:29,950
database pages in memory point of the

00:17:28,329 --> 00:17:31,870
cash is that you avoid that disk read

00:17:29,950 --> 00:17:33,580
okay when you showed up your server it's

00:17:31,870 --> 00:17:34,960
a cold cash your queries right off the

00:17:33,580 --> 00:17:36,789
get out of the gates are kind of slow

00:17:34,960 --> 00:17:37,659
coming off the disk but once they're in

00:17:36,789 --> 00:17:41,200
memory they're going to be much more

00:17:37,659 --> 00:17:42,550
accelerated so we want to minimize the

00:17:41,200 --> 00:17:44,320
number of I off so we have to do to the

00:17:42,550 --> 00:17:45,820
disks and we all that also minimizes the

00:17:44,320 --> 00:17:47,890
latency in terms of retrieval of those

00:17:45,820 --> 00:17:51,550
database pages to satisfy a query that's

00:17:47,890 --> 00:17:52,840
why we do it okay the other two areas we

00:17:51,550 --> 00:17:55,090
talked about different types of buffers

00:17:52,840 --> 00:17:58,750
when a client connects to the database

00:17:55,090 --> 00:18:00,280
server in some cases it will before it

00:17:58,750 --> 00:18:01,780
even does a query it acquires some

00:18:00,280 --> 00:18:03,490
amount of memory that is dedicated to

00:18:01,780 --> 00:18:06,220
different types of buffers before it

00:18:03,490 --> 00:18:08,020
does any work so I've often noticed with

00:18:06,220 --> 00:18:09,190
some customers that have that that maybe

00:18:08,020 --> 00:18:10,570
don't know any better they might have

00:18:09,190 --> 00:18:11,800
two or three thousand concurrent

00:18:10,570 --> 00:18:13,180
connections all the time and they just

00:18:11,800 --> 00:18:15,220
stick around all the time and they're on

00:18:13,180 --> 00:18:17,080
a low memory box well that could lead

00:18:15,220 --> 00:18:18,670
the problems memory starvation for other

00:18:17,080 --> 00:18:20,860
things like the buffer pool because

00:18:18,670 --> 00:18:22,270
these buffers may be too Meg or for Meg

00:18:20,860 --> 00:18:24,040
here and there are times 2000

00:18:22,270 --> 00:18:27,070
connections can start to become a

00:18:24,040 --> 00:18:29,080
significant drain on a server so my

00:18:27,070 --> 00:18:30,760
point is is that just by virtue of

00:18:29,080 --> 00:18:33,280
having connections in the database you

00:18:30,760 --> 00:18:35,110
can start to see memory gets get wasted

00:18:33,280 --> 00:18:37,390
if that connection isn't doing any work

00:18:35,110 --> 00:18:38,950
its of no value to stay connected to the

00:18:37,390 --> 00:18:40,060
server it's a drain on that server it

00:18:38,950 --> 00:18:43,900
takes away resources from other

00:18:40,060 --> 00:18:45,910
components and the third part where we

00:18:43,900 --> 00:18:47,920
have some memory going is um is in

00:18:45,910 --> 00:18:50,140
things like the data frm files these

00:18:47,920 --> 00:18:51,730
things get cached in memory the bin logs

00:18:50,140 --> 00:18:53,920
these are things that are there using

00:18:51,730 --> 00:18:56,230
some measure of memory on the host the

00:18:53,920 --> 00:18:57,820
binary log or what helped us set up a

00:18:56,230 --> 00:18:59,530
replication environment so we can have

00:18:57,820 --> 00:19:02,800
slaves and offload some of our reads

00:18:59,530 --> 00:19:06,360
okay those depend on the OS cash so some

00:19:02,800 --> 00:19:06,360
measure of memory gets allocated to that

00:19:06,600 --> 00:19:13,780
okay so I'm jumping ahead I'm sorry

00:19:10,660 --> 00:19:16,420
about that so the the file system cache

00:19:13,780 --> 00:19:18,940
by and large doesn't get used by inner

00:19:16,420 --> 00:19:20,440
DB most customers depending on their

00:19:18,940 --> 00:19:22,510
setup they'll be running with a battery

00:19:20,440 --> 00:19:25,810
back to write cache and that means that

00:19:22,510 --> 00:19:28,390
you can use it a setting called Oh

00:19:25,810 --> 00:19:30,370
direct and that means that nodb is going

00:19:28,390 --> 00:19:32,110
to talk directly to the disk and avoid

00:19:30,370 --> 00:19:34,570
doing any secondary caching and memory

00:19:32,110 --> 00:19:37,300
take a step back when you're typically

00:19:34,570 --> 00:19:39,010
working with with Linux and you you read

00:19:37,300 --> 00:19:40,900
a file into memory and you make some

00:19:39,010 --> 00:19:42,940
changes to it and you save it to disk it

00:19:40,900 --> 00:19:44,770
will also remain in Linux is cache

00:19:42,940 --> 00:19:46,720
memory okay so there's there's a certain

00:19:44,770 --> 00:19:48,220
amount of this Ram if you if you are

00:19:46,720 --> 00:19:50,320
running your desktop for a while and you

00:19:48,220 --> 00:19:52,540
run top and you say well look I've got

00:19:50,320 --> 00:19:55,060
two gigs on this box and my actual RAM

00:19:52,540 --> 00:19:55,970
usage is only around 500 Meg but all the

00:19:55,060 --> 00:19:57,950
memories actually being

00:19:55,970 --> 00:19:59,060
used well if you look at your cash

00:19:57,950 --> 00:20:02,300
column you'll see that there might be

00:19:59,060 --> 00:20:04,700
1.5 gigs or some measure of memory

00:20:02,300 --> 00:20:06,740
utilized their the significance is those

00:20:04,700 --> 00:20:08,420
are caches of disk objects they've

00:20:06,740 --> 00:20:09,950
retrieved up and may be flushed out the

00:20:08,420 --> 00:20:11,570
changes but they've kept them in

00:20:09,950 --> 00:20:13,220
memories for faster retrieval for you to

00:20:11,570 --> 00:20:15,410
use later on much like the inner DB

00:20:13,220 --> 00:20:17,720
buffer pool works okay so that's great

00:20:15,410 --> 00:20:19,610
for regular Linux work but when you've

00:20:17,720 --> 00:20:21,350
got a database system that is tuned to

00:20:19,610 --> 00:20:23,120
be aware that it's running on Linux and

00:20:21,350 --> 00:20:24,860
has its own memory management for

00:20:23,120 --> 00:20:27,230
buffering data you don't want it to do

00:20:24,860 --> 00:20:29,090
that twice so when you set Oh direct you

00:20:27,230 --> 00:20:31,280
tell it bypass that Linux file cache go

00:20:29,090 --> 00:20:33,740
write to disk for your operations okay

00:20:31,280 --> 00:20:35,300
so that lets you say I can ignore for

00:20:33,740 --> 00:20:36,770
the most part that Linux file cache I

00:20:35,300 --> 00:20:42,710
can devote most of my memory to the

00:20:36,770 --> 00:20:44,090
buffer pool so the the the per session

00:20:42,710 --> 00:20:45,860
buffers that we talked about there's a

00:20:44,090 --> 00:20:48,020
variety of them the sort the joins and

00:20:45,860 --> 00:20:49,280
the read buffers some of those like I

00:20:48,020 --> 00:20:51,050
said get allocated right away some of

00:20:49,280 --> 00:20:52,700
them actually get allocated when that

00:20:51,050 --> 00:20:54,920
condition arises in the database server

00:20:52,700 --> 00:20:56,990
so if you looked at your server and you

00:20:54,920 --> 00:20:59,270
said on a connection I'm going to

00:20:56,990 --> 00:21:01,070
allocate maybe 4 Meg's to some to some

00:20:59,270 --> 00:21:02,840
buffers and then as it does more

00:21:01,070 --> 00:21:04,730
complicated joints they could start to

00:21:02,840 --> 00:21:08,060
acquire greater than 4 Meg's worth of

00:21:04,730 --> 00:21:09,920
memory utilization so what I'm trying to

00:21:08,060 --> 00:21:11,720
say is that there are some memory

00:21:09,920 --> 00:21:13,100
allocations happen immediately some that

00:21:11,720 --> 00:21:15,350
happen as you type as you issue

00:21:13,100 --> 00:21:17,270
different types of queries later on okay

00:21:15,350 --> 00:21:18,920
so these are all things that you need to

00:21:17,270 --> 00:21:20,180
factor in when you're sourcing the size

00:21:18,920 --> 00:21:25,790
of the memory that you want to use with

00:21:20,180 --> 00:21:26,990
MySQL ok so a view of a couple different

00:21:25,790 --> 00:21:30,470
ways to see how much memory is being

00:21:26,990 --> 00:21:31,520
used the the free command on my school

00:21:30,470 --> 00:21:33,140
can show you where your memory is

00:21:31,520 --> 00:21:34,400
actually being utilized and this is

00:21:33,140 --> 00:21:36,590
where I was getting into with the 2gig

00:21:34,400 --> 00:21:39,650
desktop that might have 500 Meg resident

00:21:36,590 --> 00:21:42,920
and 1.5 gig in cash this is the number

00:21:39,650 --> 00:21:44,480
over here the 16 16 649 now that's

00:21:42,920 --> 00:21:46,760
generally a number if you're running in

00:21:44,480 --> 00:21:48,380
or DB only that you can safely say well

00:21:46,760 --> 00:21:50,270
that amount of memory I could probably

00:21:48,380 --> 00:21:51,620
push over into the buffer pool if you're

00:21:50,270 --> 00:21:53,240
ready to do a restart of your database

00:21:51,620 --> 00:21:54,770
server and expand the buffer pool that's

00:21:53,240 --> 00:21:56,870
about the amount of memory that would be

00:21:54,770 --> 00:21:57,830
safe to migrate over I would be cautious

00:21:56,870 --> 00:21:59,540
though when I start to look at the

00:21:57,830 --> 00:22:01,280
server and I see some element of swap I

00:21:59,540 --> 00:22:03,620
may not want to be too aggressive with

00:22:01,280 --> 00:22:05,690
moving data into the buffer pool because

00:22:03,620 --> 00:22:07,430
memory allocated to the buffer pool will

00:22:05,690 --> 00:22:08,200
be consumed all the way as database

00:22:07,430 --> 00:22:10,630
pages get read

00:22:08,200 --> 00:22:12,580
well the impact of that if your buffer

00:22:10,630 --> 00:22:15,039
pool plus other memory requirements of

00:22:12,580 --> 00:22:17,049
MySQL get greater than the actual RAM in

00:22:15,039 --> 00:22:18,519
that server you're going to swap that's

00:22:17,049 --> 00:22:20,139
what linux is supposed to do it doesn't

00:22:18,519 --> 00:22:22,539
want to crash the binary at least as a

00:22:20,139 --> 00:22:24,519
last resort if you start swapping though

00:22:22,539 --> 00:22:26,260
that's really bad if inner DB buffer

00:22:24,519 --> 00:22:27,730
pool memory gets swapped a disc because

00:22:26,260 --> 00:22:29,919
all the algorithms that have been

00:22:27,730 --> 00:22:31,929
written or on the condition that the

00:22:29,919 --> 00:22:34,000
access to ram is extremely extremely

00:22:31,929 --> 00:22:35,740
fast and those algorithms fall apart

00:22:34,000 --> 00:22:38,440
when some component of that is actually

00:22:35,740 --> 00:22:40,929
on a slow disk so it behooves you to

00:22:38,440 --> 00:22:44,080
make a mistake by choosing a smaller set

00:22:40,929 --> 00:22:46,029
of a memory smaller enemy buffer pool

00:22:44,080 --> 00:22:47,919
size than you think you need rather than

00:22:46,029 --> 00:22:50,289
going the other end don't go too big

00:22:47,919 --> 00:22:51,700
better to go too small okay if you'd

00:22:50,289 --> 00:22:53,590
start swapping if anything in the buffer

00:22:51,700 --> 00:22:56,110
pool swaps the performance is going to

00:22:53,590 --> 00:22:57,730
go through the floor okay and this is an

00:22:56,110 --> 00:22:59,049
indication here of some swap happening

00:22:57,730 --> 00:23:00,250
it doesn't necessarily mean mysql caused

00:22:59,049 --> 00:23:01,539
it could have been some big file

00:23:00,250 --> 00:23:02,980
transfer was going on a couple of other

00:23:01,539 --> 00:23:04,779
things could have been happening but the

00:23:02,980 --> 00:23:06,220
significance is i'd be cautious on a box

00:23:04,779 --> 00:23:07,990
like that of giving too much memory to

00:23:06,220 --> 00:23:10,720
the entity buffer pool if I saw any swap

00:23:07,990 --> 00:23:12,370
happening the other view of actually how

00:23:10,720 --> 00:23:14,260
much mysql is using when you look at

00:23:12,370 --> 00:23:16,120
show engine innodb status it's going to

00:23:14,260 --> 00:23:17,830
show you how much memory is allocated to

00:23:16,120 --> 00:23:21,159
the buffer pool in terms of pages and

00:23:17,830 --> 00:23:23,440
each page is 16 k page and how many

00:23:21,159 --> 00:23:25,480
pages are actually utilized and how many

00:23:23,440 --> 00:23:26,440
were actually modified in memory now i'm

00:23:25,480 --> 00:23:28,480
going to get into this modification

00:23:26,440 --> 00:23:30,789
number later but significance right now

00:23:28,480 --> 00:23:33,549
is showing that out of the buffer pool i

00:23:30,789 --> 00:23:35,649
think this is a round two gigs the the

00:23:33,549 --> 00:23:37,120
free buffers are 0 so we've used our

00:23:35,649 --> 00:23:41,470
full our buffer pools completely filled

00:23:37,120 --> 00:23:43,809
up now of that 262,000 only 258,000 are

00:23:41,470 --> 00:23:45,519
actual cached pages because in the

00:23:43,809 --> 00:23:47,769
buffer pool restoring other things we've

00:23:45,519 --> 00:23:50,350
got adaptive hash indexes and insert

00:23:47,769 --> 00:23:51,820
buffer going on in there there's a

00:23:50,350 --> 00:23:54,039
number of different utilizations for the

00:23:51,820 --> 00:23:56,500
buffer pool beyond just cashing change

00:23:54,039 --> 00:23:57,639
pate or a database pages but by and

00:23:56,500 --> 00:24:01,179
large you can see right off the bat that

00:23:57,639 --> 00:24:02,919
most of this is cached pages okay and

00:24:01,179 --> 00:24:06,730
I'll come back to the modified in just a

00:24:02,919 --> 00:24:08,200
few minutes okay so back to this why do

00:24:06,730 --> 00:24:09,909
you want to have it in memory you want

00:24:08,200 --> 00:24:11,980
the reeds to be in memory because

00:24:09,909 --> 00:24:14,470
they're faster okay if you can minimize

00:24:11,980 --> 00:24:17,769
your disk right your disk reads your

00:24:14,470 --> 00:24:19,539
performance will be faster the the

00:24:17,769 --> 00:24:21,190
challenge is is that not everybody has

00:24:19,539 --> 00:24:21,880
the simple paradigm where they say my

00:24:21,190 --> 00:24:24,340
data set

00:24:21,880 --> 00:24:26,200
is this size and I can go to Amazon or

00:24:24,340 --> 00:24:29,050
my server that I'm getting already has

00:24:26,200 --> 00:24:31,510
this much most of the time your data set

00:24:29,050 --> 00:24:34,360
is larger than your memory okay so that

00:24:31,510 --> 00:24:36,730
presents somewhat of a problem the

00:24:34,360 --> 00:24:39,430
concept is that that we use is a working

00:24:36,730 --> 00:24:41,170
set your working set is generally

00:24:39,430 --> 00:24:43,930
somewhere between one to a hundred

00:24:41,170 --> 00:24:45,190
percent of your data set so we'll pick

00:24:43,930 --> 00:24:46,960
some using numbers here you've got a

00:24:45,190 --> 00:24:49,930
server with 50 gigs you've got a data

00:24:46,960 --> 00:24:52,000
set of 100 gigs you know that in that

00:24:49,930 --> 00:24:54,190
data set it's been around for four years

00:24:52,000 --> 00:24:57,070
and you've got it's for for your online

00:24:54,190 --> 00:24:58,360
website that maybe sells widgets you've

00:24:57,070 --> 00:25:00,790
got all of your sales history for the

00:24:58,360 --> 00:25:02,980
last four years now out of that hundred

00:25:00,790 --> 00:25:04,960
gigs you are probably not checking the

00:25:02,980 --> 00:25:07,000
sales history from three years ago or

00:25:04,960 --> 00:25:08,560
two years ago you might be once in a

00:25:07,000 --> 00:25:10,450
while doing some historical graph and

00:25:08,560 --> 00:25:11,560
looking back and forth to see how your

00:25:10,450 --> 00:25:13,600
training versus last year's sales

00:25:11,560 --> 00:25:14,860
numbers but by and large the activity in

00:25:13,600 --> 00:25:17,320
this database is going to be what was

00:25:14,860 --> 00:25:20,140
sold in last 30 days 60 or 90 days okay

00:25:17,320 --> 00:25:21,610
so out of that hundred gigs we don't

00:25:20,140 --> 00:25:22,990
know yet what the working set is but

00:25:21,610 --> 00:25:24,490
it's fairly easy to say it's going to be

00:25:22,990 --> 00:25:25,690
something less than that if your

00:25:24,490 --> 00:25:28,540
business model has been pretty steady

00:25:25,690 --> 00:25:30,730
probably one quarter of that will be the

00:25:28,540 --> 00:25:33,460
actual working set of what is actively

00:25:30,730 --> 00:25:36,430
being accessed and queried by your users

00:25:33,460 --> 00:25:39,130
by your website okay so assuming you're

00:25:36,430 --> 00:25:41,650
working set is about 25 gigs your buffer

00:25:39,130 --> 00:25:43,750
pool should be around 25 gigs that is

00:25:41,650 --> 00:25:45,880
that is your working set now on your 50

00:25:43,750 --> 00:25:47,620
gigs server beautiful all of that just

00:25:45,880 --> 00:25:49,750
fitted in memory and you can basically

00:25:47,620 --> 00:25:51,640
walk away from a problem like that but

00:25:49,750 --> 00:25:53,680
if we if we kind of change it up a

00:25:51,640 --> 00:25:55,690
little bit if we say well no no three

00:25:53,680 --> 00:25:58,150
years of my history are always active my

00:25:55,690 --> 00:25:59,560
working set is actually 75 gigs then

00:25:58,150 --> 00:26:01,210
that exceeds the RAM that you've got in

00:25:59,560 --> 00:26:02,500
that server at 50 gigs what are you

00:26:01,210 --> 00:26:08,320
going to do we need to make some

00:26:02,500 --> 00:26:10,690
trade-offs now ok so again if everything

00:26:08,320 --> 00:26:12,730
is a memory no-brainer piece of cake and

00:26:10,690 --> 00:26:14,440
for a lot of time you can get away with

00:26:12,730 --> 00:26:16,120
just buying this way you don't have to

00:26:14,440 --> 00:26:17,860
go into some complicated figuring out

00:26:16,120 --> 00:26:20,410
what the working set is you can just say

00:26:17,860 --> 00:26:22,840
look this year Amazon's biggest sale was

00:26:20,410 --> 00:26:24,730
a 68 gig box now I think they've got up

00:26:22,840 --> 00:26:26,920
to about 240 gigs or to 20 gigs

00:26:24,730 --> 00:26:28,750
something like that now it does cost a

00:26:26,920 --> 00:26:30,070
lot more but if the trade-off is you

00:26:28,750 --> 00:26:31,540
just have to throw a few more bucks at

00:26:30,070 --> 00:26:32,800
the problem that's probably a lot easier

00:26:31,540 --> 00:26:34,370
than having to do some other

00:26:32,800 --> 00:26:36,320
architectural changes that involved

00:26:34,370 --> 00:26:38,090
purrs and potential bugs and things like

00:26:36,320 --> 00:26:39,650
that so in a lot of cases it's just

00:26:38,090 --> 00:26:42,590
easier to throw money at it buy more ram

00:26:39,650 --> 00:26:44,690
for your for your AWS instance or for

00:26:42,590 --> 00:26:46,490
your physical server okay and that's

00:26:44,690 --> 00:26:48,440
that's generally what I'd recommend to a

00:26:46,490 --> 00:26:50,120
customer where they've got a working set

00:26:48,440 --> 00:26:52,280
that is somewhere around the ramp

00:26:50,120 --> 00:26:56,210
capacity or within ran that I know they

00:26:52,280 --> 00:26:57,980
can generally afford to buy it okay okay

00:26:56,210 --> 00:26:59,270
so if it doesn't though this is really

00:26:57,980 --> 00:27:00,710
where the crookston that the thinking's

00:26:59,270 --> 00:27:01,940
going to come into it if it doesn't fit

00:27:00,710 --> 00:27:04,130
in a memory we need to make a trade-off

00:27:01,940 --> 00:27:05,660
here we need to get some measure of SLA

00:27:04,130 --> 00:27:07,730
s out of the business if it's just a

00:27:05,660 --> 00:27:08,990
one-man shop doing this thing well

00:27:07,730 --> 00:27:10,220
you're probably not going to get any

00:27:08,990 --> 00:27:11,720
formalized document but if you're

00:27:10,220 --> 00:27:13,670
working with a larger company maybe they

00:27:11,720 --> 00:27:15,710
tell you that you know the queries need

00:27:13,670 --> 00:27:17,360
to come back in some order of seconds or

00:27:15,710 --> 00:27:19,280
milliseconds or something like that they

00:27:17,360 --> 00:27:20,570
give you a number to pin okay once you

00:27:19,280 --> 00:27:21,800
have that kind of a number or an

00:27:20,570 --> 00:27:23,480
understanding of how quick things need

00:27:21,800 --> 00:27:24,920
to move then you can start to look at

00:27:23,480 --> 00:27:27,200
the different types of disks that are

00:27:24,920 --> 00:27:30,020
out there and debate with your customer

00:27:27,200 --> 00:27:31,309
or with yourselves how am I going to

00:27:30,020 --> 00:27:32,929
approach this problem are we going to

00:27:31,309 --> 00:27:34,700
spend tens of thousands of dollars to

00:27:32,929 --> 00:27:36,559
buy the highest quality disk to render

00:27:34,700 --> 00:27:37,970
the quickest performance or are we is it

00:27:36,559 --> 00:27:40,429
acceptable for us to come down the

00:27:37,970 --> 00:27:42,860
spectrum maybe get SSDs instead of PCI

00:27:40,429 --> 00:27:44,990
flash or maybe get a much larger raid

00:27:42,860 --> 00:27:46,340
array of SATA drives somewhere in the

00:27:44,990 --> 00:27:50,090
mix in there is going to be where your

00:27:46,340 --> 00:27:53,210
trade off is going to happen okay okay

00:27:50,090 --> 00:27:54,650
so if all of that comes together and

00:27:53,210 --> 00:27:56,540
you're already buying the best quality

00:27:54,650 --> 00:27:57,920
disk you can you haven't been able to

00:27:56,540 --> 00:28:00,110
shard you've got the single monolithic

00:27:57,920 --> 00:28:01,280
database and things still aren't fast

00:28:00,110 --> 00:28:03,080
enough what are you going to do about it

00:28:01,280 --> 00:28:05,390
well you can still make some changes

00:28:03,080 --> 00:28:06,559
okay the first and best change to make

00:28:05,390 --> 00:28:07,880
this gets away from the hardware

00:28:06,559 --> 00:28:09,800
perspective but it applies to any

00:28:07,880 --> 00:28:11,929
database out there change the query or

00:28:09,800 --> 00:28:14,090
at least look at the query you want to

00:28:11,929 --> 00:28:16,280
read back less rose that is the goal

00:28:14,090 --> 00:28:18,679
here okay if the if the client expects

00:28:16,280 --> 00:28:20,809
to see 100 rows a perfect world is you

00:28:18,679 --> 00:28:23,120
answering the query only had to examine

00:28:20,809 --> 00:28:24,710
100 rows okay that's where we want to

00:28:23,120 --> 00:28:26,300
get to now it's not usually feasible

00:28:24,710 --> 00:28:27,620
depending on the way the data is laid

00:28:26,300 --> 00:28:30,650
out in the way joins have to happen but

00:28:27,620 --> 00:28:32,780
that's what we want to go with it where

00:28:30,650 --> 00:28:34,280
you know percona helps a lot of

00:28:32,780 --> 00:28:35,750
customers we go in and we see you know

00:28:34,280 --> 00:28:37,670
they're doing like hundreds of millions

00:28:35,750 --> 00:28:40,850
of rows and they're only returning maybe

00:28:37,670 --> 00:28:42,140
10 or 52 to the client those are classic

00:28:40,850 --> 00:28:43,400
cases where it's not even about the

00:28:42,140 --> 00:28:46,220
working set anymore it's just about

00:28:43,400 --> 00:28:48,050
query improvement happening and my

00:28:46,220 --> 00:28:50,270
reason for bringing this up is that very

00:28:48,050 --> 00:28:52,940
often the queries the database schema is

00:28:50,270 --> 00:28:54,230
neglected to the end so it behooves you

00:28:52,940 --> 00:28:55,940
to spend some time on this whether

00:28:54,230 --> 00:28:57,470
you're facing a memory problem or not

00:28:55,940 --> 00:28:58,700
just take a look at your queries you're

00:28:57,470 --> 00:29:01,850
probably looking at more data than you

00:28:58,700 --> 00:29:03,860
need to okay I've said about that maybe

00:29:01,850 --> 00:29:05,420
you can archive some data maybe your

00:29:03,860 --> 00:29:08,060
workload is such that you're sitting on

00:29:05,420 --> 00:29:09,860
five years sales history but you're oltp

00:29:08,060 --> 00:29:12,050
database that it's facing right now only

00:29:09,860 --> 00:29:13,820
needs to work with the last 30 days well

00:29:12,050 --> 00:29:15,770
archive out that data move it into a

00:29:13,820 --> 00:29:17,840
warehouse or move it onto a slave but

00:29:15,770 --> 00:29:19,820
put it elsewhere and let the app deal

00:29:17,840 --> 00:29:22,250
with having to read that data set on its

00:29:19,820 --> 00:29:23,690
own okay so by virtue of that you're

00:29:22,250 --> 00:29:26,060
going to reduce the data footprint on

00:29:23,690 --> 00:29:27,440
disk you're going to reduce hopefully

00:29:26,060 --> 00:29:29,560
the size of the indexes and the pages

00:29:27,440 --> 00:29:31,970
that are being read into memory okay

00:29:29,560 --> 00:29:34,610
there are some also other options in

00:29:31,970 --> 00:29:36,680
terms of compression within nodb you can

00:29:34,610 --> 00:29:38,330
compress at the table level that might

00:29:36,680 --> 00:29:40,100
be advantageous to some people if

00:29:38,330 --> 00:29:43,270
they're using blog or text columns that

00:29:40,100 --> 00:29:46,220
can save up a lot of dis space okay and

00:29:43,270 --> 00:29:48,500
finally this is this is a this is a case

00:29:46,220 --> 00:29:50,090
where doing it up front can often really

00:29:48,500 --> 00:29:51,260
benefit you in the long run when you

00:29:50,090 --> 00:29:53,210
start up your website and you've got

00:29:51,260 --> 00:29:55,370
this great idea you go and you just say

00:29:53,210 --> 00:29:56,600
well I don't know how big this column of

00:29:55,370 --> 00:29:58,160
ids is going to be I'm just going to

00:29:56,600 --> 00:29:59,840
make them bigint when my scroll that's

00:29:58,160 --> 00:30:01,520
eight bytes that's your primary key

00:29:59,840 --> 00:30:04,030
that's going to be appended onto other

00:30:01,520 --> 00:30:06,740
every secondary index you've got so

00:30:04,030 --> 00:30:08,240
eight bytes seems like not a big deal

00:30:06,740 --> 00:30:09,860
when you're dealing with a few thousand

00:30:08,240 --> 00:30:11,150
or hundreds of thousands of rows but as

00:30:09,860 --> 00:30:13,070
we get into data sets that are maybe

00:30:11,150 --> 00:30:16,760
measuring in millions of rows that's

00:30:13,070 --> 00:30:18,260
that's a non non insignificant amount of

00:30:16,760 --> 00:30:22,340
memory that's being utilized by too

00:30:18,260 --> 00:30:23,720
large of a column size okay where maybe

00:30:22,340 --> 00:30:25,490
you could have made a change as you gone

00:30:23,720 --> 00:30:26,870
to an int because you're still going to

00:30:25,490 --> 00:30:30,230
be able to store two billion at an

00:30:26,870 --> 00:30:32,510
unsigned value so you've got these

00:30:30,230 --> 00:30:34,010
simple fixes where you can in by by

00:30:32,510 --> 00:30:35,510
virtue of changing it from a big into an

00:30:34,010 --> 00:30:37,670
inch you can go from eight bytes 24

00:30:35,510 --> 00:30:39,770
bytes very quickly you can have the size

00:30:37,670 --> 00:30:42,170
of your primary key and off of each

00:30:39,770 --> 00:30:43,760
secondary index have a significant

00:30:42,170 --> 00:30:46,490
impact of reducing the data set size

00:30:43,760 --> 00:30:47,840
okay this you know it costs a bit in

00:30:46,490 --> 00:30:49,100
terms of your alter table there's some

00:30:47,840 --> 00:30:51,080
tools out there that help you do it in a

00:30:49,100 --> 00:30:52,730
non-blocking fashion but definitely do

00:30:51,080 --> 00:30:54,950
revisit your column types and make sure

00:30:52,730 --> 00:30:56,990
you're using the right ones ok big int

00:30:54,950 --> 00:31:00,260
is often a classic case do you need to

00:30:56,990 --> 00:31:01,110
store you know a potential count of all

00:31:00,260 --> 00:31:03,690
the ants in the

00:31:01,110 --> 00:31:06,270
world probably not you know four billion

00:31:03,690 --> 00:31:09,780
out of an int unsigned is probably going

00:31:06,270 --> 00:31:11,940
to be significant for most people okay

00:31:09,780 --> 00:31:13,440
so this is a slide that actually Peter

00:31:11,940 --> 00:31:16,170
showed yesterday that I stole from them

00:31:13,440 --> 00:31:18,660
and it shows a comparison of different

00:31:16,170 --> 00:31:20,640
types of discs and that the transactions

00:31:18,660 --> 00:31:22,220
per second that they can drive and the

00:31:20,640 --> 00:31:24,390
numbers themselves are interesting but

00:31:22,220 --> 00:31:26,820
really what I'm trying to show here is

00:31:24,390 --> 00:31:28,710
that as you go from a certain amount of

00:31:26,820 --> 00:31:30,360
memory allocated so we're talking at the

00:31:28,710 --> 00:31:33,140
bottom end of the spectrum only two gigs

00:31:30,360 --> 00:31:35,790
of a buffer pool on an 18 gig data set

00:31:33,140 --> 00:31:37,950
okay so we're saying that all that 18

00:31:35,790 --> 00:31:40,260
gigs are working set the RAM on the

00:31:37,950 --> 00:31:41,520
server is obviously greater than 22 it

00:31:40,260 --> 00:31:43,049
doesn't matter how much RAM we have

00:31:41,520 --> 00:31:45,270
we're saying we only want to cache up

00:31:43,049 --> 00:31:46,860
the two gigs in the buffer pool well

00:31:45,270 --> 00:31:49,049
when you're that makes you a disc bound

00:31:46,860 --> 00:31:50,580
workload so what we see is that the

00:31:49,049 --> 00:31:52,020
faster the drives are the more

00:31:50,580 --> 00:31:54,390
transactions per seconds you're going to

00:31:52,020 --> 00:31:55,799
get but as things move to the right and

00:31:54,390 --> 00:31:58,770
as you get to your entire working city

00:31:55,799 --> 00:31:59,940
memory they all plateau so at some

00:31:58,770 --> 00:32:01,590
measure in between is you're going to

00:31:59,940 --> 00:32:03,630
have this trade-off do you want to spend

00:32:01,590 --> 00:32:05,700
for the fusion-io and the verdant type

00:32:03,630 --> 00:32:07,110
cards the flash based ones or are you

00:32:05,700 --> 00:32:08,910
okay with a performance that may be a

00:32:07,110 --> 00:32:10,799
raid 10 on some SAS drives can deliver

00:32:08,910 --> 00:32:16,410
knowing that there is some spectrum

00:32:10,799 --> 00:32:17,520
difference in between here ok ok so this

00:32:16,410 --> 00:32:18,960
touches on something we were talking

00:32:17,520 --> 00:32:20,910
about before where things are getting

00:32:18,960 --> 00:32:23,760
buffered in a lot of cases we want to

00:32:20,910 --> 00:32:25,559
tell nodb stop buffering okay that's why

00:32:23,760 --> 00:32:27,600
we run things with 0 direct have it talk

00:32:25,559 --> 00:32:29,700
directly to the disk drives but

00:32:27,600 --> 00:32:32,370
typically in Linux the reason we do this

00:32:29,700 --> 00:32:34,110
buffering is not only for for offloading

00:32:32,370 --> 00:32:35,760
from having to do a read later but

00:32:34,110 --> 00:32:38,460
buffering it also allows us to perform

00:32:35,760 --> 00:32:40,080
sequential writes two drives let's not

00:32:38,460 --> 00:32:42,030
forget over the last you know 20 30

00:32:40,080 --> 00:32:44,880
years all we had were spinning platters

00:32:42,030 --> 00:32:46,380
and that meant that a sequential read or

00:32:44,880 --> 00:32:48,299
sequential right where orders of

00:32:46,380 --> 00:32:49,919
magnitude faster than random reads or

00:32:48,299 --> 00:32:51,210
random writes because it allowed the

00:32:49,919 --> 00:32:52,440
disc to keep spinning in a reliable

00:32:51,210 --> 00:32:53,940
fashion that fast as they can and

00:32:52,440 --> 00:32:57,600
keeping the heads in the right place

00:32:53,940 --> 00:32:59,010
okay when we go and we get these SSDs

00:32:57,600 --> 00:33:00,870
and these flash drives where there's

00:32:59,010 --> 00:33:02,669
absolutely no penalty basically for

00:33:00,870 --> 00:33:04,380
doing random operations all these

00:33:02,669 --> 00:33:06,600
algorithms that we've developed and

00:33:04,380 --> 00:33:08,850
tuned and tweaked for 30 years kind of

00:33:06,600 --> 00:33:10,260
fall flat we don't need them anymore I

00:33:08,850 --> 00:33:11,520
mean we've got different problems that

00:33:10,260 --> 00:33:12,960
come up you know we've got right

00:33:11,520 --> 00:33:14,429
leveling has to happen with these with

00:33:12,960 --> 00:33:16,169
these drive so we wear them even lean

00:33:14,429 --> 00:33:18,750
different problems come up but this

00:33:16,169 --> 00:33:21,600
sequential I 0 vs random it goes away

00:33:18,750 --> 00:33:22,890
for the most part so what we're doing is

00:33:21,600 --> 00:33:24,630
we're going to say to the OS and a lot

00:33:22,890 --> 00:33:26,490
of cases just stop trying to be smart

00:33:24,630 --> 00:33:28,020
about it we know we're saying my school

00:33:26,490 --> 00:33:32,580
knows what it's doing let it do its own

00:33:28,020 --> 00:33:34,470
work talking to the drives okay so why

00:33:32,580 --> 00:33:36,660
how does it do some of the stuff it uses

00:33:34,470 --> 00:33:37,650
the f sync call by and large okay an F

00:33:36,660 --> 00:33:39,840
stink is basically going to quiesce

00:33:37,650 --> 00:33:41,580
Whitson what's in the buffer down to the

00:33:39,840 --> 00:33:43,470
disk and makes it durable if we don't

00:33:41,580 --> 00:33:45,450
have it durable then we've got no way of

00:33:43,470 --> 00:33:47,040
knowing that if that server crashes at

00:33:45,450 --> 00:33:48,240
this point time what data are we

00:33:47,040 --> 00:33:50,550
potentially going to be exposed to

00:33:48,240 --> 00:33:51,960
losing okay the database is going to do

00:33:50,550 --> 00:33:53,790
it in its own way it's got its own

00:33:51,960 --> 00:33:55,260
series of log files that track changes

00:33:53,790 --> 00:33:58,320
through the database and then later on

00:33:55,260 --> 00:34:01,740
does its actual purge to the actual hard

00:33:58,320 --> 00:34:03,240
eibd files okay where's the the Linux

00:34:01,740 --> 00:34:04,919
file systems typically have their own

00:34:03,240 --> 00:34:07,169
journaling operations going on as well

00:34:04,919 --> 00:34:10,710
okay the EXT ones the xt three and four

00:34:07,169 --> 00:34:12,750
have a journal and so does XFS okay by

00:34:10,710 --> 00:34:14,129
us on that point don't use ext2 because

00:34:12,750 --> 00:34:15,330
it doesn't have a journal and you will

00:34:14,129 --> 00:34:18,270
probably corrupt your database if you

00:34:15,330 --> 00:34:21,179
continues than that but I probably know

00:34:18,270 --> 00:34:23,639
you sit in that so okay so how does

00:34:21,179 --> 00:34:24,869
innodb work when you're doing a read and

00:34:23,639 --> 00:34:26,190
this is kind of a step back and probably

00:34:24,869 --> 00:34:28,109
a lot of you already know this but how

00:34:26,190 --> 00:34:29,399
does it work when you do a read and it's

00:34:28,109 --> 00:34:30,510
not in memory you got to fetch it from

00:34:29,399 --> 00:34:32,429
disk because that's where the data is

00:34:30,510 --> 00:34:34,470
durable it will move it into the buffer

00:34:32,429 --> 00:34:35,879
pool okay when you do this big select

00:34:34,470 --> 00:34:37,590
and you're looking at whether it's from

00:34:35,879 --> 00:34:39,540
an index or not it's going to load these

00:34:37,590 --> 00:34:42,169
files from the disk into the buffer pool

00:34:39,540 --> 00:34:45,210
now keep in mind it's a 16k block

00:34:42,169 --> 00:34:47,369
database page it's 16k on disk and it's

00:34:45,210 --> 00:34:49,350
16 k in memory it's like a one-to-one

00:34:47,369 --> 00:34:51,090
mapping of if I fetched up three pages

00:34:49,350 --> 00:34:55,639
from the table space on disk it's the

00:34:51,090 --> 00:34:55,639
same three tables pages in memory okay

00:34:56,540 --> 00:35:00,740
sorry forgot I had transitions in it

00:35:01,700 --> 00:35:06,589
okay now when we go to actually make it

00:35:04,550 --> 00:35:08,180
change to the database the simple case

00:35:06,589 --> 00:35:10,579
is to select where you're basically it's

00:35:08,180 --> 00:35:12,230
just a pass through cash the first time

00:35:10,579 --> 00:35:13,430
through its slow cuz comes off dis now

00:35:12,230 --> 00:35:15,260
it's in the buffer pool and it's

00:35:13,430 --> 00:35:16,579
satisfied to the client assuming you

00:35:15,260 --> 00:35:18,920
have no other caching layers between

00:35:16,579 --> 00:35:20,869
from your web app to the database again

00:35:18,920 --> 00:35:22,339
you go when you read that that select

00:35:20,869 --> 00:35:23,900
again it will just fetch it from the

00:35:22,339 --> 00:35:26,240
buffer pool it avoids the disc lookup

00:35:23,900 --> 00:35:28,760
beautiful okay but now what happens when

00:35:26,240 --> 00:35:30,619
you want to change data if you've got

00:35:28,760 --> 00:35:32,900
data that's in memory or on disk it

00:35:30,619 --> 00:35:34,579
doesn't matter that data page has to be

00:35:32,900 --> 00:35:36,260
fetched up off of disk into memory

00:35:34,579 --> 00:35:38,720
before nodb is going to make a

00:35:36,260 --> 00:35:40,250
modification to it so an update

00:35:38,720 --> 00:35:42,470
statement is going to either cause a

00:35:40,250 --> 00:35:44,839
disk read or it won't but it definitely

00:35:42,470 --> 00:35:45,920
will cause some disc rights now there

00:35:44,839 --> 00:35:47,780
are two different types of rights that

00:35:45,920 --> 00:35:49,970
are going to happen the first right and

00:35:47,780 --> 00:35:51,680
this is again optimizing for the case of

00:35:49,970 --> 00:35:54,349
the spinning disk where we're going to

00:35:51,680 --> 00:35:56,510
delay as long as possible making random

00:35:54,349 --> 00:35:58,430
writes because spinning platters are

00:35:56,510 --> 00:35:59,570
slow for random writes we want to off we

00:35:58,430 --> 00:36:02,210
want to delay them as long as possible

00:35:59,570 --> 00:36:05,060
we write what's called the inner DB log

00:36:02,210 --> 00:36:07,160
file and it will keep its written in a

00:36:05,060 --> 00:36:09,200
sequential fashion so it's very quick to

00:36:07,160 --> 00:36:11,300
write it's an append only type file and

00:36:09,200 --> 00:36:13,880
it only ever gets read in the case of a

00:36:11,300 --> 00:36:15,890
crash this is effectively the journal

00:36:13,880 --> 00:36:18,410
that tracks changes in the database so

00:36:15,890 --> 00:36:21,619
how it works a rate cut write request

00:36:18,410 --> 00:36:23,540
comes in to the to the database to mysql

00:36:21,619 --> 00:36:24,890
it goes into the buffer pool and says do

00:36:23,540 --> 00:36:26,780
I have this page that i need to change

00:36:24,890 --> 00:36:28,670
if the page is already they are great it

00:36:26,780 --> 00:36:30,260
will modify the page in memory and it

00:36:28,670 --> 00:36:32,420
will be classified as a modified or a

00:36:30,260 --> 00:36:33,859
dirty page okay and what that means is

00:36:32,420 --> 00:36:36,980
this page is different in memory than it

00:36:33,859 --> 00:36:39,319
actually is on disk now it writes that

00:36:36,980 --> 00:36:41,210
the actual change set to this log file

00:36:39,319 --> 00:36:43,190
and then it can acknowledge to the

00:36:41,210 --> 00:36:45,170
client to the web app to say okay I've

00:36:43,190 --> 00:36:47,300
committed this this this is a durable

00:36:45,170 --> 00:36:48,589
right well we know it's not technically

00:36:47,300 --> 00:36:51,530
been durable because it hasn't changed

00:36:48,589 --> 00:36:53,780
the on-disk IBD file yet and the IBD

00:36:51,530 --> 00:36:55,220
file is the actual database file that

00:36:53,780 --> 00:36:57,109
you back up and that you work with it

00:36:55,220 --> 00:37:00,380
that my school works with this table

00:36:57,109 --> 00:37:01,640
space is the IBD files okay so at this

00:37:00,380 --> 00:37:02,930
point we've changed the buffer pool

00:37:01,640 --> 00:37:04,160
we've changed the log file but we

00:37:02,930 --> 00:37:06,560
haven't made any change to this table

00:37:04,160 --> 00:37:07,640
space so the significance of this but

00:37:06,560 --> 00:37:09,589
we've acknowledged the client to say

00:37:07,640 --> 00:37:11,089
it's durable so we better make sure that

00:37:09,589 --> 00:37:12,380
if the server power gets lost or

00:37:11,089 --> 00:37:13,230
something happens that when we come back

00:37:12,380 --> 00:37:15,359
up we're going to

00:37:13,230 --> 00:37:17,340
recover this well the way it works is it

00:37:15,359 --> 00:37:19,290
will go back through its log file and

00:37:17,340 --> 00:37:20,340
look for any uncommitted changes that

00:37:19,290 --> 00:37:22,230
haven't been committed to the table

00:37:20,340 --> 00:37:23,609
space and actually affect those changes

00:37:22,230 --> 00:37:25,170
and you might notice that if your

00:37:23,609 --> 00:37:27,240
database crashes and it takes a lot

00:37:25,170 --> 00:37:28,770
longer than normal to recut to restart

00:37:27,240 --> 00:37:30,600
and you're checking the log file it says

00:37:28,770 --> 00:37:31,770
it's doing crash recovery that's

00:37:30,600 --> 00:37:33,420
effectively what it's doing is it

00:37:31,770 --> 00:37:34,890
stepping through the log files and going

00:37:33,420 --> 00:37:36,600
oh I have some changes that actually

00:37:34,890 --> 00:37:38,640
weren't fully durable yet I need to make

00:37:36,600 --> 00:37:41,160
those make those make those changes to

00:37:38,640 --> 00:37:42,930
effective okay well in a perfectly

00:37:41,160 --> 00:37:44,970
running system where you might have some

00:37:42,930 --> 00:37:46,500
peaks in some valleys the database can

00:37:44,970 --> 00:37:48,390
actually go ahead and purge those

00:37:46,500 --> 00:37:49,740
modified pages out of memory it's got

00:37:48,390 --> 00:37:52,740
some background threads as will do this

00:37:49,740 --> 00:37:54,270
work for you and the benefit to this is

00:37:52,740 --> 00:37:55,980
is that it will keep those log files

00:37:54,270 --> 00:37:58,109
from having too much of a change data

00:37:55,980 --> 00:37:59,580
set in them if they get too long there's

00:37:58,109 --> 00:38:01,320
too many changes your crash recovery

00:37:59,580 --> 00:38:03,990
time is much larger so we try to keep

00:38:01,320 --> 00:38:05,940
that keep that as small as possible well

00:38:03,990 --> 00:38:07,710
if the database server gets slow and my

00:38:05,940 --> 00:38:09,390
school sense is that it will go and it

00:38:07,710 --> 00:38:10,650
will start flushing its modified pages

00:38:09,390 --> 00:38:14,160
and committing them to the table space

00:38:10,650 --> 00:38:15,630
ok so the database servers trying all

00:38:14,160 --> 00:38:17,130
these different algorithms to make sure

00:38:15,630 --> 00:38:19,140
it can flush change pages in the buffer

00:38:17,130 --> 00:38:20,940
pool to disk but it also tries to do in

00:38:19,140 --> 00:38:22,590
an intelligent way it's got algorithms

00:38:20,940 --> 00:38:24,690
built in to make those changes in

00:38:22,590 --> 00:38:27,300
contiguous blocks as often as possible

00:38:24,690 --> 00:38:29,040
with the the expectation that if they're

00:38:27,300 --> 00:38:30,510
contiguous on disk that they're probably

00:38:29,040 --> 00:38:33,000
going to translate it into a sequential

00:38:30,510 --> 00:38:35,730
right so that optimizes for the spinning

00:38:33,000 --> 00:38:37,980
platter case now when we go to SSDs and

00:38:35,730 --> 00:38:39,900
flash weather isn't that penalty where

00:38:37,980 --> 00:38:41,970
you're not trying to optimize for random

00:38:39,900 --> 00:38:43,500
writes there are some tuning options I

00:38:41,970 --> 00:38:45,480
know for sure and Percona server and I

00:38:43,500 --> 00:38:47,130
think in community version as well that

00:38:45,480 --> 00:38:48,869
you can say just flush them as you need

00:38:47,130 --> 00:38:50,220
don't try to make any like you know area

00:38:48,869 --> 00:38:53,880
based or anything else like that just

00:38:50,220 --> 00:38:55,430
flush like crazy if you can ok let me

00:38:53,880 --> 00:38:58,670
see there might be trans yeah

00:38:55,430 --> 00:38:58,670
transitions on it

00:39:01,330 --> 00:39:08,510
okay jumped ahead of myself again so

00:39:05,660 --> 00:39:10,340
this isn't uncommon i'm not i'm not very

00:39:08,510 --> 00:39:11,630
fluent beyond my squall but my

00:39:10,340 --> 00:39:13,340
understanding is that Oracle's got this

00:39:11,630 --> 00:39:14,870
concept I'd be surprised if things like

00:39:13,340 --> 00:39:16,760
postgres don't have this as well so

00:39:14,870 --> 00:39:24,230
anybody want to comment say yay or nay

00:39:16,760 --> 00:39:26,060
on that okay okay so this used to be

00:39:24,230 --> 00:39:27,170
slow we know that this is a slide deck

00:39:26,060 --> 00:39:28,820
that we've been working on for a number

00:39:27,170 --> 00:39:30,800
of years used to really easy to say that

00:39:28,820 --> 00:39:32,120
it's not the case anymore back in the

00:39:30,800 --> 00:39:33,320
day even when the flash stuff first

00:39:32,120 --> 00:39:34,640
accredited coming out it was thirty

00:39:33,320 --> 00:39:35,960
forty thousand dollars to get into it

00:39:34,640 --> 00:39:37,640
not a lot of people could afford that

00:39:35,960 --> 00:39:39,170
but these days it is considerably

00:39:37,640 --> 00:39:40,850
cheaper it's something that you should

00:39:39,170 --> 00:39:42,470
be thinking about maybe SSDs are

00:39:40,850 --> 00:39:44,480
appropriate for you but certainly the

00:39:42,470 --> 00:39:49,700
flash is a very attractive option for

00:39:44,480 --> 00:39:52,760
disk so but in some cases you still need

00:39:49,700 --> 00:39:54,140
to touch the disk okay depending on all

00:39:52,760 --> 00:39:55,310
the things we talked about with the CPUs

00:39:54,140 --> 00:39:56,750
in the memory and the disk

00:39:55,310 --> 00:39:58,130
configurations and what the buffer pool

00:39:56,750 --> 00:40:01,430
is doing you still need to touch the

00:39:58,130 --> 00:40:03,320
disk ok so the buffer pool it's going to

00:40:01,430 --> 00:40:05,660
cash it's going to cash those reads as

00:40:03,320 --> 00:40:06,920
much as possible we've talked about some

00:40:05,660 --> 00:40:09,500
of the different examples would be you

00:40:06,920 --> 00:40:11,000
know sales history maybe going back for

00:40:09,500 --> 00:40:12,950
the for the current year that that's

00:40:11,000 --> 00:40:14,420
important if you run a lot of reports

00:40:12,950 --> 00:40:15,560
based on that year you want to cash that

00:40:14,420 --> 00:40:17,270
data you don't want your accounting

00:40:15,560 --> 00:40:19,280
department telling you that things are

00:40:17,270 --> 00:40:20,750
always slow when I run this report well

00:40:19,280 --> 00:40:22,010
if that's important to them then you

00:40:20,750 --> 00:40:23,360
need to find a way of keeping that data

00:40:22,010 --> 00:40:25,520
cashed in memory may be running that

00:40:23,360 --> 00:40:27,380
query on its own outside of the regular

00:40:25,520 --> 00:40:29,300
reporting period so that it stays in the

00:40:27,380 --> 00:40:31,010
buffer pool those are tricks like that

00:40:29,300 --> 00:40:32,090
that you can use to to take advantage of

00:40:31,010 --> 00:40:36,710
the fact that the data is going to be

00:40:32,090 --> 00:40:37,880
cached in memory okay the reason I the

00:40:36,710 --> 00:40:39,260
reason I'm calling out these kinds of

00:40:37,880 --> 00:40:42,140
things is it goes back to the working

00:40:39,260 --> 00:40:44,300
set the the data set the working set all

00:40:42,140 --> 00:40:46,190
these things it's not always going to be

00:40:44,300 --> 00:40:49,010
active you're going to say well my

00:40:46,190 --> 00:40:51,050
working set might be this size but

00:40:49,010 --> 00:40:52,400
actually out of that working set the

00:40:51,050 --> 00:40:54,560
speed might only be important of

00:40:52,400 --> 00:40:56,150
something even smaller of that okay so

00:40:54,560 --> 00:40:59,000
you've almost got three different tiers

00:40:56,150 --> 00:41:00,290
of approach to the the query response

00:40:59,000 --> 00:41:02,480
time that you're trying to satisfy for

00:41:00,290 --> 00:41:04,280
your application you'll say this is my

00:41:02,480 --> 00:41:06,500
largest amount of data that I've got my

00:41:04,280 --> 00:41:08,090
100 gigs on disk something smaller than

00:41:06,500 --> 00:41:09,710
that is my working set it's something

00:41:08,090 --> 00:41:11,750
even smaller than that are the queries

00:41:09,710 --> 00:41:13,460
that I really care about making fast

00:41:11,750 --> 00:41:15,080
okay so if you're if you're bound by all

00:41:13,460 --> 00:41:16,880
these types of determinations and you

00:41:15,080 --> 00:41:18,830
say I simply can't afford to buy more

00:41:16,880 --> 00:41:20,060
more Hardware I can't put more ram at

00:41:18,830 --> 00:41:21,830
this thing whatever my working set

00:41:20,060 --> 00:41:23,390
doesn't fit in memory well then try to

00:41:21,830 --> 00:41:25,100
figure out where are the most important

00:41:23,390 --> 00:41:26,990
queries that are going on tun those as

00:41:25,100 --> 00:41:28,940
much as possible but at least make sure

00:41:26,990 --> 00:41:30,320
you can satisfy the RAM size that would

00:41:28,940 --> 00:41:33,590
satisfy the result sets that you're

00:41:30,320 --> 00:41:35,450
regularly looking at okay and it just to

00:41:33,590 --> 00:41:37,070
keep in mind that like for new sites you

00:41:35,450 --> 00:41:38,780
know only the really most recently

00:41:37,070 --> 00:41:40,910
active news posts are probably the busy

00:41:38,780 --> 00:41:42,860
ones yeah they sit on multiple years but

00:41:40,910 --> 00:41:45,290
they probably don't care about caching

00:41:42,860 --> 00:41:51,140
an article that was written a 12 or you

00:41:45,290 --> 00:41:53,840
know 18 months ago okay so can you cash

00:41:51,140 --> 00:41:56,030
rights not really because by definition

00:41:53,840 --> 00:41:59,380
you're changing data so you don't really

00:41:56,030 --> 00:42:01,820
have anything to to to stage them in but

00:41:59,380 --> 00:42:02,990
the good news is is that in a lot of

00:42:01,820 --> 00:42:05,000
cases when you're working with slower

00:42:02,990 --> 00:42:07,160
media and I mean things more like the

00:42:05,000 --> 00:42:09,530
raid arrays on SAS drives or even SSDs

00:42:07,160 --> 00:42:12,200
it does benefit you to go with a battery

00:42:09,530 --> 00:42:14,150
backed right cash and they're they're

00:42:12,200 --> 00:42:16,070
fairly common they're not generally that

00:42:14,150 --> 00:42:17,990
expensive anymore and the concept is is

00:42:16,070 --> 00:42:19,610
that when you go to make a right to a

00:42:17,990 --> 00:42:21,950
spinning platter is going to be slower

00:42:19,610 --> 00:42:23,240
if you can stage that and have it

00:42:21,950 --> 00:42:24,650
acknowledged back to the operating

00:42:23,240 --> 00:42:26,360
system we're back to the database that

00:42:24,650 --> 00:42:28,430
that right has been committed that it's

00:42:26,360 --> 00:42:30,140
safe then you're golden you can move on

00:42:28,430 --> 00:42:31,370
your database can say I committed this I

00:42:30,140 --> 00:42:33,710
can move on to doing some other

00:42:31,370 --> 00:42:35,300
operation okay the way the battery back

00:42:33,710 --> 00:42:38,150
cash work is it's got some amount

00:42:35,300 --> 00:42:40,160
measure of flash or ram and it stages

00:42:38,150 --> 00:42:42,050
that right and it waits and it does it's

00:42:40,160 --> 00:42:43,430
reordering of its actual changes to the

00:42:42,050 --> 00:42:45,530
to the spinning platters behind the

00:42:43,430 --> 00:42:48,080
scene so the rights come in from the

00:42:45,530 --> 00:42:50,000
database they get fake changed in this

00:42:48,080 --> 00:42:51,950
cache and later on get actually

00:42:50,000 --> 00:42:53,570
committed to the disks and your database

00:42:51,950 --> 00:42:55,190
server can much more quickly reply back

00:42:53,570 --> 00:42:56,930
to its clients saying okay my rights

00:42:55,190 --> 00:42:59,090
have been committed to disk we're good

00:42:56,930 --> 00:43:00,830
to move on okay and generally they come

00:42:59,090 --> 00:43:02,090
with batteries and you definitely make

00:43:00,830 --> 00:43:03,560
sure you have a battery in it because if

00:43:02,090 --> 00:43:05,240
the power goes out anything that's in

00:43:03,560 --> 00:43:07,460
RAM could potentially be lost on these

00:43:05,240 --> 00:43:09,590
battery backed right caches okay one

00:43:07,460 --> 00:43:11,180
thing to keep in mind with them is that

00:43:09,590 --> 00:43:12,470
one of the drawbacks is they have to go

00:43:11,180 --> 00:43:14,150
into a learning mode every once in a

00:43:12,470 --> 00:43:15,590
while and they said they often do this

00:43:14,150 --> 00:43:17,020
on their own schedule there are ways to

00:43:15,590 --> 00:43:19,130
implement sit but watch out for this

00:43:17,020 --> 00:43:21,320
will often Prachanda will often get a

00:43:19,130 --> 00:43:22,340
911 call it says man my databases were

00:43:21,320 --> 00:43:23,690
humming along and then suddenly

00:43:22,340 --> 00:43:26,210
performance drop through the

00:43:23,690 --> 00:43:28,130
floor the race just dropped off and it's

00:43:26,210 --> 00:43:29,750
it's awful what's going on and that's

00:43:28,130 --> 00:43:31,310
the first thing we'll often check is did

00:43:29,750 --> 00:43:32,900
your battery back to write cache go into

00:43:31,310 --> 00:43:35,000
learning mode that basically means it

00:43:32,900 --> 00:43:36,500
turns off that cash so all those rights

00:43:35,000 --> 00:43:37,970
are actually being persisted all the way

00:43:36,500 --> 00:43:39,530
down to the drive and it's much slower

00:43:37,970 --> 00:43:42,319
you're getting a lot less I ops and

00:43:39,530 --> 00:43:44,450
you're getting a lot higher latency so

00:43:42,319 --> 00:43:45,650
watch out for the learning the learning

00:43:44,450 --> 00:43:51,349
component of your battery backed right

00:43:45,650 --> 00:43:52,849
cash okay so when you're working in

00:43:51,349 --> 00:43:54,800
linux how do you how do you look at the

00:43:52,849 --> 00:43:55,760
performance of your drives because there

00:43:54,800 --> 00:43:58,849
are certainly component of buying

00:43:55,760 --> 00:44:00,680
hardware the best tool that i've been

00:43:58,849 --> 00:44:02,420
using has been PT dis tats and it's

00:44:00,680 --> 00:44:04,760
nothing more than really a fancy wrapper

00:44:02,420 --> 00:44:06,650
around the proc to STATS virtual file

00:44:04,760 --> 00:44:07,550
system ok it just kind of formats it a

00:44:06,650 --> 00:44:08,839
lot i don't know if you guys have ever

00:44:07,550 --> 00:44:10,609
catted that but it looks like line noise

00:44:08,839 --> 00:44:14,000
to me but this kind of wraps it in a

00:44:10,609 --> 00:44:15,410
nice nice view now PT dis stats is part

00:44:14,000 --> 00:44:17,420
of the Percona toolkit go and download

00:44:15,410 --> 00:44:20,089
it all day long I think we're up to

00:44:17,420 --> 00:44:22,160
version 2.2 point2 now this is built on

00:44:20,089 --> 00:44:23,690
a little bit of older one but the

00:44:22,160 --> 00:44:25,609
columns that are really significant to

00:44:23,690 --> 00:44:28,099
me are the ones that are mentioning how

00:44:25,609 --> 00:44:29,869
many ops I ops happening per second and

00:44:28,099 --> 00:44:31,819
versus how much the actual throughput is

00:44:29,869 --> 00:44:33,800
going on so you're measuring the count

00:44:31,819 --> 00:44:35,420
of disk operations at the right and the

00:44:33,800 --> 00:44:37,190
read level and then you're looking at

00:44:35,420 --> 00:44:39,530
what is the volume of data moving down

00:44:37,190 --> 00:44:42,079
to the disks the in megabytes the the

00:44:39,530 --> 00:44:43,280
read in the right load ok you need to

00:44:42,079 --> 00:44:44,510
you need to keep this in mind because

00:44:43,280 --> 00:44:46,160
your disk vendor is going to publish

00:44:44,510 --> 00:44:48,410
some spec to you they're going to say

00:44:46,160 --> 00:44:50,990
well my state of dr can do a hundred I

00:44:48,410 --> 00:44:52,670
ops per second and it can do I don't

00:44:50,990 --> 00:44:54,290
know 20 meg transfer well if you're

00:44:52,670 --> 00:44:55,250
watching with PT disqus and you start to

00:44:54,290 --> 00:44:57,079
see your numbers are getting close to

00:44:55,250 --> 00:44:58,280
that you've got a case where you need to

00:44:57,079 --> 00:45:00,170
start looking at buying some additional

00:44:58,280 --> 00:45:01,550
hardware ok you need to know what your

00:45:00,170 --> 00:45:03,349
just drives are capable of before you

00:45:01,550 --> 00:45:05,540
can draw really any true conclusions out

00:45:03,349 --> 00:45:07,369
of what what PG dispatch is showing you

00:45:05,540 --> 00:45:09,290
but it can also show you the inverse

00:45:07,369 --> 00:45:11,119
case you can say well hey man I went out

00:45:09,290 --> 00:45:13,369
and I bought 10 drives in my raid 10 and

00:45:11,119 --> 00:45:15,020
I've got a capacity of 3,000 I ops or

00:45:13,369 --> 00:45:17,329
you bought some provision I ops from AWS

00:45:15,020 --> 00:45:18,829
and you look at your your server and the

00:45:17,329 --> 00:45:20,660
server is running fine the apps it's

00:45:18,829 --> 00:45:22,280
happy and you're only doing 100 miles

00:45:20,660 --> 00:45:23,300
per second you might scratch your head

00:45:22,280 --> 00:45:25,550
for a while and say I probably I

00:45:23,300 --> 00:45:26,930
probably overbought not that you should

00:45:25,550 --> 00:45:28,280
go away from that but you know there are

00:45:26,930 --> 00:45:30,500
cases where you might have provisioned

00:45:28,280 --> 00:45:33,530
too much equipment and realize that okay

00:45:30,500 --> 00:45:35,390
maybe I'm building for the future a tool

00:45:33,530 --> 00:45:37,280
like PD to STATS token kind of 0 went on

00:45:35,390 --> 00:45:39,830
where the disk bottlenecks are or

00:45:37,280 --> 00:45:42,710
are you have some excess capacity okay

00:45:39,830 --> 00:45:44,960
so what's the difference well SSD is

00:45:42,710 --> 00:45:47,620
still going to be using a different sort

00:45:44,960 --> 00:45:49,790
SSD is still going to be used the same

00:45:47,620 --> 00:45:51,410
access methods that we're used to using

00:45:49,790 --> 00:45:52,940
with our spinning platters okay so we've

00:45:51,410 --> 00:45:54,410
got a whole bunch of different protocols

00:45:52,940 --> 00:45:55,910
we're working on for years scuzzy

00:45:54,410 --> 00:45:59,690
protocols that SSD is still going to

00:45:55,910 --> 00:46:01,730
leverage the the the raid controllers

00:45:59,690 --> 00:46:02,840
that go with SSDs make sure when you buy

00:46:01,730 --> 00:46:04,970
them that they're capable of working

00:46:02,840 --> 00:46:06,920
with an SSD don't just assume because

00:46:04,970 --> 00:46:08,990
you can plug it in your form factor fits

00:46:06,920 --> 00:46:10,790
and all that it will pray will work like

00:46:08,990 --> 00:46:12,230
a disk drive and that's great but what

00:46:10,790 --> 00:46:14,420
you might be missing out on or

00:46:12,230 --> 00:46:16,190
optimizations that the raid controller

00:46:14,420 --> 00:46:18,110
vendors built-in when they say I've got

00:46:16,190 --> 00:46:19,820
an SSD behind me I can do these extra

00:46:18,110 --> 00:46:21,950
additional features make sure you buy

00:46:19,820 --> 00:46:24,350
one of the raid array controllers that

00:46:21,950 --> 00:46:25,940
can actually take advantage of that top

00:46:24,350 --> 00:46:28,880
my head I think the adaptec the z-series

00:46:25,940 --> 00:46:33,080
are suited for doing SSD based

00:46:28,880 --> 00:46:34,640
controller disk drives okay if you got

00:46:33,080 --> 00:46:36,650
lots of bucks in your pocket flash is

00:46:34,640 --> 00:46:39,350
truly the way to go I've been helping a

00:46:36,650 --> 00:46:41,600
customer with a flash IO IO drive to and

00:46:39,350 --> 00:46:43,370
I was able to show I think about 140 I

00:46:41,600 --> 00:46:44,690
ops per second and something on the

00:46:43,370 --> 00:46:46,970
order of about a gig per second and

00:46:44,690 --> 00:46:49,070
throughput so just disgusting amount of

00:46:46,970 --> 00:46:50,720
capability and that that takes you in a

00:46:49,070 --> 00:46:52,280
whole other world where a single my

00:46:50,720 --> 00:46:54,170
school instance probably can't do that

00:46:52,280 --> 00:46:55,370
kind of work you're probably in a space

00:46:54,170 --> 00:46:57,320
or you're going to run two or three

00:46:55,370 --> 00:46:58,730
databases on that single server simply

00:46:57,320 --> 00:47:02,360
because you have so much raw disk

00:46:58,730 --> 00:47:04,130
capacity available to you okay going

00:47:02,360 --> 00:47:05,630
away from flash I'll be back down the

00:47:04,130 --> 00:47:07,610
bottom of the spectrum you know if you

00:47:05,630 --> 00:47:09,590
take a lot of our laptops these days of

00:47:07,610 --> 00:47:11,720
SSDs but if you have probably a spinning

00:47:09,590 --> 00:47:14,050
drive you're probably around 150 I ops

00:47:11,720 --> 00:47:16,580
so you're going from 150 to potentially

00:47:14,050 --> 00:47:18,200
150,000 I ops and you can buy somewhere

00:47:16,580 --> 00:47:21,080
in between that and that's where your

00:47:18,200 --> 00:47:22,670
budgets going to put you the best thing

00:47:21,080 --> 00:47:24,050
I like about the flash flow and SSDs as

00:47:22,670 --> 00:47:26,300
well though is that that latency is

00:47:24,050 --> 00:47:27,860
virtually nil so that means when we're

00:47:26,300 --> 00:47:29,570
doing our rights or our reads its

00:47:27,860 --> 00:47:31,790
there's virtually no cost to that so

00:47:29,570 --> 00:47:36,190
it's it's like almost having a second

00:47:31,790 --> 00:47:36,190
stage of RAM there it's just so fast

00:47:36,280 --> 00:47:41,420
okay so these are just some benchmarks

00:47:38,690 --> 00:47:43,550
that some Vadim tkachenko our CTO of

00:47:41,420 --> 00:47:44,720
Percona he runs the SSD performance blog

00:47:43,550 --> 00:47:48,110
and he does a lot of these types of

00:47:44,720 --> 00:47:49,850
evaluations for for disc vendors we

00:47:48,110 --> 00:47:50,589
didn't mention it oh yeah we do the

00:47:49,850 --> 00:47:53,440
models so these

00:47:50,589 --> 00:47:54,940
Intel 320s versus a RAID 10 so the

00:47:53,440 --> 00:47:56,469
vendors just give us these things and we

00:47:54,940 --> 00:47:58,809
test them out for them and we're

00:47:56,469 --> 00:48:00,009
plotting the fact that as you as we

00:47:58,809 --> 00:48:01,900
increase the number of threads these

00:48:00,009 --> 00:48:03,700
drives scale great we're getting up to

00:48:01,900 --> 00:48:05,200
32 threads here and we're seeing their

00:48:03,700 --> 00:48:07,359
disk throughput a summer up around three

00:48:05,200 --> 00:48:08,979
hundred fifty gigs makes per second so

00:48:07,359 --> 00:48:10,900
certainly less than what flash can do

00:48:08,979 --> 00:48:14,430
but for an SSD Drive that's pretty darn

00:48:10,900 --> 00:48:16,809
awesome and that's on the Intel 320

00:48:14,430 --> 00:48:19,089
published in 2011 so this is already two

00:48:16,809 --> 00:48:20,890
years old but the point is that we can

00:48:19,089 --> 00:48:23,650
get some tremendous throughput using

00:48:20,890 --> 00:48:25,930
these drives the latency as well is also

00:48:23,650 --> 00:48:27,579
very very great so we might only be

00:48:25,930 --> 00:48:29,499
doing up to about a 5 millisecond

00:48:27,579 --> 00:48:31,779
latency as we up to 32 threads which is

00:48:29,499 --> 00:48:33,069
pretty darn good but as you're going up

00:48:31,779 --> 00:48:35,319
with your with your raid array you can

00:48:33,069 --> 00:48:36,609
see that it gets as the threads increase

00:48:35,319 --> 00:48:38,289
and more work is trying to be thrown

00:48:36,609 --> 00:48:40,839
these drives the latency response time

00:48:38,289 --> 00:48:42,700
in aggregate starts to drop off so if

00:48:40,839 --> 00:48:44,259
you have a lot of different right

00:48:42,700 --> 00:48:45,609
operations in your database if you've

00:48:44,259 --> 00:48:47,979
configured it for a lot of right I Oh

00:48:45,609 --> 00:48:49,450
threads you could potentially be doing

00:48:47,979 --> 00:48:51,099
yourself a disservice to your raid array

00:48:49,450 --> 00:48:52,059
if you're trying to force it to do too

00:48:51,099 --> 00:48:54,519
much work you're making too much

00:48:52,059 --> 00:48:56,200
contention happen in the drives so be

00:48:54,519 --> 00:48:58,920
careful with with your with your

00:48:56,200 --> 00:49:01,930
standard SATA drives or your SAS drives

00:48:58,920 --> 00:49:03,039
these days SSDs and flash are definitely

00:49:01,930 --> 00:49:06,219
going to be driving a lot better

00:49:03,039 --> 00:49:07,960
performance for you okay but one thing

00:49:06,219 --> 00:49:10,539
to keep in mind as you start to fill up

00:49:07,960 --> 00:49:11,829
these drives the the problem we didn't

00:49:10,539 --> 00:49:13,450
have before we didn't have any things

00:49:11,829 --> 00:49:15,039
like garbage collection to do on the SAS

00:49:13,450 --> 00:49:16,599
drives or these seder drives they just

00:49:15,039 --> 00:49:18,549
filled up and you could use the full

00:49:16,599 --> 00:49:20,559
capacity in a way you went but with

00:49:18,549 --> 00:49:22,359
these new these new flash and SSDs

00:49:20,559 --> 00:49:23,739
they've got these little cells on them

00:49:22,359 --> 00:49:25,450
and they're trying to make sure that all

00:49:23,739 --> 00:49:27,190
the cells get used appropriately and

00:49:25,450 --> 00:49:28,779
that it wears evenly because there's

00:49:27,190 --> 00:49:30,700
only a certain number of read and write

00:49:28,779 --> 00:49:32,799
operations these cells can do now I'm

00:49:30,700 --> 00:49:34,210
not a hardware guy on this so if I'm

00:49:32,799 --> 00:49:36,130
going to start going sideways somebody

00:49:34,210 --> 00:49:37,359
please call me out on it but the the

00:49:36,130 --> 00:49:39,400
theory is that there's a bit of a black

00:49:37,359 --> 00:49:41,170
box built in there that Intel is going

00:49:39,400 --> 00:49:42,579
to say hey look i'm going to manage all

00:49:41,170 --> 00:49:43,479
of this garbage collection and making

00:49:42,579 --> 00:49:45,400
sure that the right leveling is

00:49:43,479 --> 00:49:47,289
happening appropriately but at the

00:49:45,400 --> 00:49:49,089
expense that as it goes to do this

00:49:47,289 --> 00:49:51,279
leveling it's doing additional reads and

00:49:49,089 --> 00:49:53,289
writes behind the scenes to make things

00:49:51,279 --> 00:49:55,989
get evicted and moved around and

00:49:53,289 --> 00:49:58,150
shuffled well as we get to a more full

00:49:55,989 --> 00:49:59,589
state there's a lot less open blocks for

00:49:58,150 --> 00:50:00,999
it to be doing the shuffling so

00:49:59,589 --> 00:50:02,360
performance is going to degrade because

00:50:00,999 --> 00:50:04,340
there's more ops that are happy

00:50:02,360 --> 00:50:05,480
under the scenes thus less I ops

00:50:04,340 --> 00:50:08,750
available to you at the application

00:50:05,480 --> 00:50:10,610
layer so as we start to fill these bad

00:50:08,750 --> 00:50:11,480
boys up they start to drop off now it's

00:50:10,610 --> 00:50:14,120
not like they're going to ever perform

00:50:11,480 --> 00:50:16,160
as poorly as as as the as the SAS drives

00:50:14,120 --> 00:50:17,840
and SATA and all that but the point is

00:50:16,160 --> 00:50:18,710
is that don't expect as these things get

00:50:17,840 --> 00:50:20,330
too full that they're going to be

00:50:18,710 --> 00:50:23,660
performing as well as they were at fifty

00:50:20,330 --> 00:50:25,940
percent so you know you can get these

00:50:23,660 --> 00:50:27,320
fusion-io drives around 1.2 terabytes

00:50:25,940 --> 00:50:29,330
and whatnot that's usually big enough

00:50:27,320 --> 00:50:31,010
for most people or you can come down a

00:50:29,330 --> 00:50:33,500
lot lower I think they're at the 300 of

00:50:31,010 --> 00:50:35,420
the 600 gig ranges these days so for

00:50:33,500 --> 00:50:39,800
most work most database sizes that's

00:50:35,420 --> 00:50:43,190
probably going to be adequate for you ok

00:50:39,800 --> 00:50:45,770
so again the again it's all about budget

00:50:43,190 --> 00:50:47,990
can you afford it but also can your app

00:50:45,770 --> 00:50:51,080
sustain does it need to have super low

00:50:47,990 --> 00:50:52,310
latency reads and writes on it the

00:50:51,080 --> 00:50:54,440
number of customers that I've worked

00:50:52,310 --> 00:50:55,970
with them a few in particular stick out

00:50:54,440 --> 00:50:57,590
the ones that tend to do the social

00:50:55,970 --> 00:50:59,240
media kind of work they tend to be

00:50:57,590 --> 00:51:01,010
really focused on that user experience

00:50:59,240 --> 00:51:02,930
and they want those those latency

00:51:01,010 --> 00:51:03,920
numbers to be virtually no now maybe it

00:51:02,930 --> 00:51:05,600
also happens they have a lot of VC

00:51:03,920 --> 00:51:07,160
behind them so they can afford it but

00:51:05,600 --> 00:51:08,510
they tend to just say I don't care what

00:51:07,160 --> 00:51:11,060
it's going to cost let's do the flash

00:51:08,510 --> 00:51:12,440
thing but on the other end of the

00:51:11,060 --> 00:51:15,020
spectrum I might have a guy who's

00:51:12,440 --> 00:51:16,880
helping out helping out other customers

00:51:15,020 --> 00:51:18,530
with lead tracking something like that

00:51:16,880 --> 00:51:20,480
generating leads for them well this guy

00:51:18,530 --> 00:51:22,460
his business model is all about sourcing

00:51:20,480 --> 00:51:23,600
link clicks and shoving them into a

00:51:22,460 --> 00:51:24,890
database and then reporting on them

00:51:23,600 --> 00:51:26,450
later he's going to have a high

00:51:24,890 --> 00:51:27,710
throughput of reads and writes but he

00:51:26,450 --> 00:51:29,510
doesn't really care about how long it

00:51:27,710 --> 00:51:30,860
takes to generate his reports so he

00:51:29,510 --> 00:51:32,600
might sit on a greater volume of data

00:51:30,860 --> 00:51:34,610
and be doing more I ops than our social

00:51:32,600 --> 00:51:36,500
media person might be but he's so much

00:51:34,610 --> 00:51:37,760
less sensitive to how slow the drives

00:51:36,500 --> 00:51:38,810
are going to be he doesn't really care

00:51:37,760 --> 00:51:41,030
if he's going to pay an eight

00:51:38,810 --> 00:51:42,620
millisecond penalty vs the social media

00:51:41,030 --> 00:51:44,000
guy that says you know I need sub

00:51:42,620 --> 00:51:46,010
millisecond latency when I'm accessing

00:51:44,000 --> 00:51:47,870
my desk so keep in mind this is

00:51:46,010 --> 00:51:49,310
application workload dependent it all

00:51:47,870 --> 00:51:50,840
depends on your budget but also what can

00:51:49,310 --> 00:51:54,110
your app sustain or what user experience

00:51:50,840 --> 00:51:56,210
you're trying to deliver one big thing

00:51:54,110 --> 00:51:57,650
is that as you restart mysql you're

00:51:56,210 --> 00:51:59,150
going to be basically starting up your

00:51:57,650 --> 00:52:02,720
server with an empty cache a cold cash

00:51:59,150 --> 00:52:04,610
now i know in 56 community and also in

00:52:02,720 --> 00:52:07,280
perk 1055 we implemented a feature that

00:52:04,610 --> 00:52:09,110
has a cache warming procedure and the

00:52:07,280 --> 00:52:12,020
way it works is you've got your inner to

00:52:09,110 --> 00:52:14,270
be buffer pool that has pages in it what

00:52:12,020 --> 00:52:16,160
we do you set it by virtue of every 10

00:52:14,270 --> 00:52:17,510
10 minutes it flushes our

00:52:16,160 --> 00:52:19,700
record of all the pages that are in

00:52:17,510 --> 00:52:21,049
memory to a file on disk and this file

00:52:19,700 --> 00:52:22,609
on disk might only be it's not the

00:52:21,049 --> 00:52:24,500
actual contents of the memory it's just

00:52:22,609 --> 00:52:25,760
you know 16 or 20 megs something like

00:52:24,500 --> 00:52:27,230
that there's this point it's the

00:52:25,760 --> 00:52:29,480
database pages that were in the buffer

00:52:27,230 --> 00:52:31,970
pool the last time it did it did it did

00:52:29,480 --> 00:52:33,170
a scan of the buffer pool okay so that

00:52:31,970 --> 00:52:35,000
doesn't do you anything when the server

00:52:33,170 --> 00:52:36,950
is running but after the server restarts

00:52:35,000 --> 00:52:38,569
it sees that files there it sources that

00:52:36,950 --> 00:52:40,640
file and it loads all these pages into

00:52:38,569 --> 00:52:43,130
memory so you get a warmed buffer pool

00:52:40,640 --> 00:52:44,539
after your server restarts the reason

00:52:43,130 --> 00:52:47,150
this was significant and we even had it

00:52:44,539 --> 00:52:50,119
in 55 is by and large nobody had SSDs or

00:52:47,150 --> 00:52:51,650
flash so they hated that restart my

00:52:50,119 --> 00:52:53,030
server they delay it they they never

00:52:51,650 --> 00:52:54,559
wanted to talk about doing a restart

00:52:53,030 --> 00:52:56,720
because it was so painful you know

00:52:54,559 --> 00:52:58,099
rightly so because the the spinning

00:52:56,720 --> 00:53:00,170
drives took forever to read those pages

00:52:58,099 --> 00:53:02,000
up because it's all random i/o when you

00:53:00,170 --> 00:53:04,339
do this buffer restart you still are

00:53:02,000 --> 00:53:06,020
doing random reads but at least you know

00:53:04,339 --> 00:53:07,460
which pages need to be in memory you can

00:53:06,020 --> 00:53:09,200
get your database server back into a

00:53:07,460 --> 00:53:11,630
production state much quicker because

00:53:09,200 --> 00:53:12,950
you know what the data set was that was

00:53:11,630 --> 00:53:19,789
active you know just before you shut

00:53:12,950 --> 00:53:21,230
down okay okay so this is just a quick

00:53:19,789 --> 00:53:23,119
comparison of the different rate levels

00:53:21,230 --> 00:53:25,190
and where you can get some performance

00:53:23,119 --> 00:53:26,569
tweaks out of it it's something that you

00:53:25,190 --> 00:53:29,240
know that probably most of us are all

00:53:26,569 --> 00:53:30,529
familiar with the the recommendation if

00:53:29,240 --> 00:53:31,910
you can afford it is generally we go

00:53:30,529 --> 00:53:33,470
with the raid 10 because you get the

00:53:31,910 --> 00:53:34,789
best of both worlds you get some some

00:53:33,470 --> 00:53:36,260
mirroring of the drives and plus you get

00:53:34,789 --> 00:53:38,390
a stripe across them so you get the

00:53:36,260 --> 00:53:41,210
highest throughput with the most the

00:53:38,390 --> 00:53:43,789
most redundancy built in don't ever do

00:53:41,210 --> 00:53:45,770
raid 0 on your database server now

00:53:43,789 --> 00:53:47,329
sometimes we'll recommend it for for

00:53:45,770 --> 00:53:48,799
slaves if they're disposable but

00:53:47,329 --> 00:53:50,779
generally with the raid 0 if any one of

00:53:48,799 --> 00:53:52,250
those lumps under the hood crashes your

00:53:50,779 --> 00:53:54,740
old data sets gone so it's probably not

00:53:52,250 --> 00:53:56,299
where you want to be raid 1 is fine but

00:53:54,740 --> 00:53:58,420
doesn't really help you accelerate a lot

00:53:56,299 --> 00:54:01,760
but it does give you a redundancy and

00:53:58,420 --> 00:54:03,260
raid 5 is it's fine for a read workload

00:54:01,760 --> 00:54:04,910
because you're just you have a number of

00:54:03,260 --> 00:54:06,920
different drives you can source from but

00:54:04,910 --> 00:54:08,990
a write operation is quite poor in a

00:54:06,920 --> 00:54:10,460
raid 5 array and that's because you've

00:54:08,990 --> 00:54:13,039
actually got four operations it has to

00:54:10,460 --> 00:54:15,079
do so you need to do to reads and to

00:54:13,039 --> 00:54:16,760
rights to commit a change your rate is

00:54:15,079 --> 00:54:19,039
change the actual data on disk but also

00:54:16,760 --> 00:54:21,680
commits that um the checksum value to

00:54:19,039 --> 00:54:24,349
another drive so raid five rights not

00:54:21,680 --> 00:54:25,490
very good okay generally with with a lot

00:54:24,349 --> 00:54:27,349
of customers instead of trying to get

00:54:25,490 --> 00:54:29,530
into like do I put my logs here my

00:54:27,349 --> 00:54:31,420
buffer pool they're all or sorry do I

00:54:29,530 --> 00:54:33,610
my IBD of table space they're generally

00:54:31,420 --> 00:54:41,890
a raid 10 pack everything into it and

00:54:33,610 --> 00:54:43,030
just just be done with it okay so what

00:54:41,890 --> 00:54:44,650
can you do with your with your disk

00:54:43,030 --> 00:54:46,810
caches generally this is all happening

00:54:44,650 --> 00:54:48,070
at the hardware level you don't want to

00:54:46,810 --> 00:54:49,930
be doing this in software unless you

00:54:48,070 --> 00:54:51,670
have some measure of making sure that it

00:54:49,930 --> 00:54:53,800
can be committed to disk and are not

00:54:51,670 --> 00:54:55,810
familiar with any with any of that can

00:54:53,800 --> 00:54:58,500
actually do this properly so you know

00:54:55,810 --> 00:55:01,060
you can use the the md devices using the

00:54:58,500 --> 00:55:03,040
software based raid array definitely use

00:55:01,060 --> 00:55:04,720
that it works like a champ but there's

00:55:03,040 --> 00:55:05,980
no built-in write caching that happens

00:55:04,720 --> 00:55:08,140
with that all this stuff happens at the

00:55:05,980 --> 00:55:10,960
disk controller level so you want to

00:55:08,140 --> 00:55:12,340
have it in a in a right back so that

00:55:10,960 --> 00:55:13,750
means that it's doing this caching

00:55:12,340 --> 00:55:15,850
component of rights where it will

00:55:13,750 --> 00:55:17,230
basically acknowledge to the database to

00:55:15,850 --> 00:55:18,760
say i've received your right I'll

00:55:17,230 --> 00:55:20,350
acknowledge back to the database let the

00:55:18,760 --> 00:55:21,790
database go on with its work and later

00:55:20,350 --> 00:55:27,370
on I will actually flush it to the

00:55:21,790 --> 00:55:31,180
drives okay do you go with the sander

00:55:27,370 --> 00:55:33,070
and as it depends and it's interesting

00:55:31,180 --> 00:55:35,080
because some customers are already

00:55:33,070 --> 00:55:36,400
invested into already having a San or an

00:55:35,080 --> 00:55:37,960
as environment the shop and that's just

00:55:36,400 --> 00:55:40,030
what they're the storage person says

00:55:37,960 --> 00:55:41,350
they need to do now direct attached

00:55:40,030 --> 00:55:43,570
storage is going to give you the lowest

00:55:41,350 --> 00:55:45,160
latency it just has to because there's

00:55:43,570 --> 00:55:46,960
less hops there's less things it has to

00:55:45,160 --> 00:55:49,150
go through going right through the pci

00:55:46,960 --> 00:55:51,070
bus that is that you know but as quick

00:55:49,150 --> 00:55:52,540
as you're going to get as soon as you

00:55:51,070 --> 00:55:53,770
put a sander in as know you've got if

00:55:52,540 --> 00:55:55,720
you're talking about nas we're talking

00:55:53,770 --> 00:55:57,850
about maybe ice cuz you're NFS or samba

00:55:55,720 --> 00:55:59,140
sip sharing okay now you've got Network

00:55:57,850 --> 00:56:00,550
hops to go through now you've got

00:55:59,140 --> 00:56:02,350
different protocol stacks to work with

00:56:00,550 --> 00:56:03,880
you talking about San you may be talking

00:56:02,350 --> 00:56:05,290
about fiber channel so now you've got

00:56:03,880 --> 00:56:07,480
fibre channel switches which are wicked

00:56:05,290 --> 00:56:09,340
fast but they still they still have a

00:56:07,480 --> 00:56:10,930
lot of latency that they incur I mean

00:56:09,340 --> 00:56:12,610
it's it's it's work is happening in a

00:56:10,930 --> 00:56:14,770
CPU so it's time that's going to be

00:56:12,610 --> 00:56:15,970
delayed now the advantage to it don't

00:56:14,770 --> 00:56:17,530
forget about the beautiful facts of

00:56:15,970 --> 00:56:19,120
sands and asses you can do things at the

00:56:17,530 --> 00:56:20,230
storage layer that you can't with local

00:56:19,120 --> 00:56:22,030
storage if you've got a large

00:56:20,230 --> 00:56:23,590
environment you can start snapping your

00:56:22,030 --> 00:56:25,750
data set and copying it to another

00:56:23,590 --> 00:56:27,490
server very very quickly doing all types

00:56:25,750 --> 00:56:30,010
of different types of cloning operations

00:56:27,490 --> 00:56:31,780
sands and NASA's have their place but if

00:56:30,010 --> 00:56:33,730
you're they're not necessarily

00:56:31,780 --> 00:56:38,010
appropriate if your goal is number one

00:56:33,730 --> 00:56:40,870
for performance so keep all that in mind

00:56:38,010 --> 00:56:42,100
okay I've all I've got less than two

00:56:40,870 --> 00:56:43,300
minutes so i'm going to move relatively

00:56:42,100 --> 00:56:45,340
quickly through these but

00:56:43,300 --> 00:56:46,750
one component of sourcing hardware is

00:56:45,340 --> 00:56:48,430
that you want to do a lot of alignment

00:56:46,750 --> 00:56:49,960
you want to make sure that when the

00:56:48,430 --> 00:56:51,520
database server is talking to the file

00:56:49,960 --> 00:56:52,750
system and talking to the raid

00:56:51,520 --> 00:56:54,820
controller and talking to the drives

00:56:52,750 --> 00:56:55,990
that everything is aligned okay all the

00:56:54,820 --> 00:56:58,420
sectors line up so that when we're

00:56:55,990 --> 00:57:00,490
writing blocks of 4k or 16 k that

00:56:58,420 --> 00:57:02,200
they're also 4k or 16 k all the way down

00:57:00,490 --> 00:57:03,640
to the storage level that's going to

00:57:02,200 --> 00:57:05,970
that could give you anywhere from a ten

00:57:03,640 --> 00:57:08,590
to twenty percent improvement okay

00:57:05,970 --> 00:57:10,060
network generally you're going to be

00:57:08,590 --> 00:57:11,740
working with at least gigabit if you can

00:57:10,060 --> 00:57:13,960
go even bigger that's getting to be more

00:57:11,740 --> 00:57:15,880
and more common that will generally

00:57:13,960 --> 00:57:17,290
introduce less latency so if you can

00:57:15,880 --> 00:57:18,850
afford to be 10 gigabit on your database

00:57:17,290 --> 00:57:20,290
servers go for it but generally one

00:57:18,850 --> 00:57:21,790
gigabit is what most people are using

00:57:20,290 --> 00:57:24,790
and it's it's more than adequate it

00:57:21,790 --> 00:57:26,860
there definitely do try to do trunking

00:57:24,790 --> 00:57:29,530
if you can and bonding of the devices so

00:57:26,860 --> 00:57:31,570
will often see is most physical servers

00:57:29,530 --> 00:57:32,920
will come with two nicks and they'll

00:57:31,570 --> 00:57:34,660
could they'll cable them to two separate

00:57:32,920 --> 00:57:36,790
switches and then in linux they'll

00:57:34,660 --> 00:57:38,530
create one virtual device like a bond 0

00:57:36,790 --> 00:57:40,330
and that will be in potentially an

00:57:38,530 --> 00:57:42,460
active passive mode or or they're both

00:57:40,330 --> 00:57:44,410
active going out both directions the

00:57:42,460 --> 00:57:45,880
point is is that because you've got

00:57:44,410 --> 00:57:48,490
things cable to two different switches

00:57:45,880 --> 00:57:50,350
this this device can allow for a failure

00:57:48,490 --> 00:57:52,030
of one switch or one Nick cart and still

00:57:50,350 --> 00:57:53,800
keep the whole system flowing you don't

00:57:52,030 --> 00:57:55,750
want your hardware at the Nick level or

00:57:53,800 --> 00:57:57,340
the switch level to be making your

00:57:55,750 --> 00:57:58,600
database unavailable and these are

00:57:57,340 --> 00:58:01,360
really simple things to implement so

00:57:58,600 --> 00:58:06,940
look definitely look it up bonding with

00:58:01,360 --> 00:58:08,710
in Linux is very easy to do okay what

00:58:06,940 --> 00:58:12,400
can you get with ec2 they're huge

00:58:08,710 --> 00:58:14,050
instances now you can get some up to I'm

00:58:12,400 --> 00:58:16,930
not sure if it's if it's 244 I think

00:58:14,050 --> 00:58:18,640
it's 224 but anyway um a lot of ram you

00:58:16,930 --> 00:58:20,200
can get SSD back storage now which I

00:58:18,640 --> 00:58:22,330
think they'll give you like 80,000 I ops

00:58:20,200 --> 00:58:23,890
on their system you pay a lot of money

00:58:22,330 --> 00:58:25,060
for it but if you need it it's there so

00:58:23,890 --> 00:58:29,050
you can do a lot of great things in the

00:58:25,060 --> 00:58:30,040
cloud these days EBS is we call it I'm

00:58:29,050 --> 00:58:31,570
predictable because you get a lot of

00:58:30,040 --> 00:58:32,770
noisy neighbor kind of thing going on if

00:58:31,570 --> 00:58:34,180
you've got somebody else on your shared

00:58:32,770 --> 00:58:37,240
storage they can impact the performance

00:58:34,180 --> 00:58:38,620
your database so you can get provision

00:58:37,240 --> 00:58:40,630
to I ops these days where they give you

00:58:38,620 --> 00:58:42,400
a guarantee how many I ops you're going

00:58:40,630 --> 00:58:44,380
to get out of that out of that line so

00:58:42,400 --> 00:58:47,590
if you can afford it that the p.i ops

00:58:44,380 --> 00:58:49,450
are the way to go RDS and I don't think

00:58:47,590 --> 00:58:51,400
I don't this is official or not but my

00:58:49,450 --> 00:58:54,610
take is that it's basically a front end

00:58:51,400 --> 00:58:56,680
22 ec2 back end databases so you won't

00:58:54,610 --> 00:58:58,630
necessarily get any better throughput

00:58:56,680 --> 00:59:00,339
with RDS what you will win with that and

00:58:58,630 --> 00:59:02,140
this is the Amazon relational database

00:59:00,339 --> 00:59:03,220
system they'll manage the database and

00:59:02,140 --> 00:59:04,630
all that stuff for you so you're not

00:59:03,220 --> 00:59:07,089
even buying anything you're basically

00:59:04,630 --> 00:59:08,470
paying for a database server that you

00:59:07,089 --> 00:59:09,790
can read and write against and all the

00:59:08,470 --> 00:59:11,470
other stuff gets handled automatically

00:59:09,790 --> 00:59:12,730
backups and setting up slaves that's

00:59:11,470 --> 00:59:19,480
somebody else's problem that's all

00:59:12,730 --> 00:59:21,220
within the GUI of your Amazon okay so

00:59:19,480 --> 00:59:23,950
some of the problems that we're going to

00:59:21,220 --> 00:59:25,210
run into disk i/o can connect it is

00:59:23,950 --> 00:59:26,380
always going to sneak up on you so

00:59:25,210 --> 00:59:27,910
that's what we talked a lot about the

00:59:26,380 --> 00:59:29,290
different types of disk products that

00:59:27,910 --> 00:59:31,390
you can buy out there when the database

00:59:29,290 --> 00:59:33,069
gets slow it may not be a bug in MySQL

00:59:31,390 --> 00:59:35,890
it may not be a plug it might just be

00:59:33,069 --> 00:59:37,390
your death dis or saturated conversely

00:59:35,890 --> 00:59:38,619
your cpu's can be a bottleneck we looked

00:59:37,390 --> 00:59:42,550
at some of the tools to track for that

00:59:38,619 --> 00:59:44,109
vmstat MP stat and a name even top can

00:59:42,550 --> 00:59:46,599
show you that oh look I'm a CPU bound

00:59:44,109 --> 00:59:48,220
workload or I'm bound on my i'm waiting

00:59:46,599 --> 00:59:49,960
on disk so there's a lot of different

00:59:48,220 --> 00:59:52,150
tools that it can point to to where your

00:59:49,960 --> 00:59:53,740
bottleneck is going to be don't assume

00:59:52,150 --> 00:59:55,569
that just because you can add more disk

00:59:53,740 --> 00:59:57,250
drives though or more cpus are going to

00:59:55,569 --> 00:59:59,349
fix it it might be that you need to go

00:59:57,250 --> 01:00:01,210
back and actually fix a query okay so

00:59:59,349 --> 01:00:03,480
throw money at it for a while but at

01:00:01,210 --> 01:00:06,670
some point that's not going to be enough

01:00:03,480 --> 01:00:09,069
okay with slaves replication

01:00:06,670 --> 01:00:10,660
single-threaded so the common mindset is

01:00:09,069 --> 01:00:13,030
well I have this old turbo make it a

01:00:10,660 --> 01:00:15,069
slave let's find but as that as that

01:00:13,030 --> 01:00:17,650
slave starts to pick up more workload as

01:00:15,069 --> 01:00:19,059
your app gets busier the slave won't be

01:00:17,650 --> 01:00:20,589
able to keep up necessarily with what's

01:00:19,059 --> 01:00:21,760
happening on the master because all

01:00:20,589 --> 01:00:23,380
those right events are all single

01:00:21,760 --> 01:00:25,180
threaded they're all I'm going to be

01:00:23,380 --> 01:00:26,770
applied in a single thread on the slave

01:00:25,180 --> 01:00:28,720
therefore you're going to be spinning

01:00:26,770 --> 01:00:31,329
one cpu as hot as possible and you're

01:00:28,720 --> 01:00:32,829
also going to be only able to keep up so

01:00:31,329 --> 01:00:35,140
much in terms of replication lag from

01:00:32,829 --> 01:00:36,190
the master so would often mean that it

01:00:35,140 --> 01:00:37,990
means is you need to have actually

01:00:36,190 --> 01:00:39,819
faster CPUs on your slave than you do on

01:00:37,990 --> 01:00:43,720
your master sometimes counterintuitive

01:00:39,819 --> 01:00:45,819
but something to keep in mind again I

01:00:43,720 --> 01:00:48,250
touched I touched on this quickly with

01:00:45,819 --> 01:00:49,420
the fastest flash drives out there flash

01:00:48,250 --> 01:00:50,980
drives out there you might be running

01:00:49,420 --> 01:00:53,200
multiple instances in my school on the

01:00:50,980 --> 01:00:54,579
same host simply because your cpu's

01:00:53,200 --> 01:00:55,900
aren't busy the disks aren't busy and

01:00:54,579 --> 01:00:57,790
you have capacity so there's nothing

01:00:55,900 --> 01:00:59,920
wrong with running mysql and on maybe

01:00:57,790 --> 01:01:02,500
all on 3306 on different IP addresses

01:00:59,920 --> 01:01:04,930
that you stand up or on one IP address

01:01:02,500 --> 01:01:09,250
on different ports whatever makes sense

01:01:04,930 --> 01:01:10,480
for you okay but by and large if you've

01:01:09,250 --> 01:01:12,520
got the time do your own

01:01:10,480 --> 01:01:13,690
benchmarks the SSD performance blog and

01:01:12,520 --> 01:01:14,950
Moscow performance blog and lots of

01:01:13,690 --> 01:01:17,080
people have a lot of opinions out there

01:01:14,950 --> 01:01:18,930
don't take them as if they're the only

01:01:17,080 --> 01:01:21,340
way it needs to be go and do your own

01:01:18,930 --> 01:01:22,510
sis bench is a great tool for generating

01:01:21,340 --> 01:01:25,030
different types of workloads it has a

01:01:22,510 --> 01:01:26,740
file i/o test and an OLTP test that help

01:01:25,030 --> 01:01:29,410
you generate activity against your

01:01:26,740 --> 01:01:30,940
drives also tools like jmeter can help

01:01:29,410 --> 01:01:33,130
you simulate the actual work load of

01:01:30,940 --> 01:01:35,050
your of your database or of your app it

01:01:33,130 --> 01:01:36,940
can do it a variety of different types

01:01:35,050 --> 01:01:38,350
of tests so don't be afraid to use those

01:01:36,940 --> 01:01:40,630
tests and doing your own benchmarking

01:01:38,350 --> 01:01:42,130
not only will you be able to state of

01:01:40,630 --> 01:01:43,270
your boss or convince yourself if you're

01:01:42,130 --> 01:01:44,710
the business owner that look I'm

01:01:43,270 --> 01:01:46,570
investing the money in the right place

01:01:44,710 --> 01:01:49,180
because I need it you also learn a lot

01:01:46,570 --> 01:01:51,310
about your app you just get so much

01:01:49,180 --> 01:01:53,170
deeper into how how nuanced things are

01:01:51,310 --> 01:01:54,730
when you change a few connections here

01:01:53,170 --> 01:01:56,530
or or make the queries a little bit more

01:01:54,730 --> 01:01:58,570
expensive or a little bit cheaper so

01:01:56,530 --> 01:02:01,390
benchmarking benefits you in so many

01:01:58,570 --> 01:02:03,310
different ways these are things we

01:02:01,390 --> 01:02:05,260
already talked about quite a bit getting

01:02:03,310 --> 01:02:07,150
the working set smaller is certainly

01:02:05,260 --> 01:02:09,070
where you need to be if you can do it to

01:02:07,150 --> 01:02:11,200
make things faster change the queries if

01:02:09,070 --> 01:02:12,460
you can tune the OS don't be afraid to

01:02:11,200 --> 01:02:14,310
make changes to Linux to change

01:02:12,460 --> 01:02:16,270
different ways that it caches memory or

01:02:14,310 --> 01:02:17,710
change the Edit memory killer so it

01:02:16,270 --> 01:02:19,840
doesn't kill MySQL when you start to

01:02:17,710 --> 01:02:22,359
swap things like that use the right

01:02:19,840 --> 01:02:23,710
storage engine by default energy be

01:02:22,359 --> 01:02:25,810
should be what you're using but if

01:02:23,710 --> 01:02:26,920
you're using my IM reevaluate that there

01:02:25,810 --> 01:02:30,040
are much better memory management

01:02:26,920 --> 01:02:31,090
components of inner DB you scheming your

01:02:30,040 --> 01:02:32,710
application that's where you would

01:02:31,090 --> 01:02:34,690
change maybe your queries if you had to

01:02:32,710 --> 01:02:38,290
maybe make them access less rows or add

01:02:34,690 --> 01:02:39,700
new indexes and sometimes that's worth

01:02:38,290 --> 01:02:40,810
it sometimes there's a lot of changes to

01:02:39,700 --> 01:02:41,740
your app and you could be afraid of that

01:02:40,810 --> 01:02:44,560
because it means a whole other

01:02:41,740 --> 01:02:47,200
development iteration cycle so your

01:02:44,560 --> 01:02:50,320
mileage may vary on that okay I'm sorry

01:02:47,200 --> 01:02:51,700
I'm out of time but I'm happy to stick

01:02:50,320 --> 01:02:54,070
around and chat if anybody wants to

01:02:51,700 --> 01:02:59,550
Michael koban with Percona and I'll be

01:02:54,070 --> 01:02:59,550
here all day okay

01:02:59,690 --> 01:03:04,800
most enterprises today realize that

01:03:02,490 --> 01:03:06,420
usernames and passwords alone aren't

01:03:04,800 --> 01:03:08,790
enough to keep their networks saved from

01:03:06,420 --> 01:03:10,859
unauthorized intrusions that's my

01:03:08,790 --> 01:03:12,900
two-factor authentication has gotten so

01:03:10,859 --> 01:03:15,030
popular lately that adds that extra

01:03:12,900 --> 01:03:17,700
layer of protection enterprise networks

01:03:15,030 --> 01:03:19,440
need to stay safe but what you may not

01:03:17,700 --> 01:03:21,660
know is that some two-factor

01:03:19,440 --> 01:03:23,880
authentication solutions they're better

01:03:21,660 --> 01:03:26,910
than others like two-factor strong

01:03:23,880 --> 01:03:29,190
authentication with wicked wicked goes

01:03:26,910 --> 01:03:31,140
beyond other authentication systems by

01:03:29,190 --> 01:03:34,410
being less expensive easier to implement

01:03:31,140 --> 01:03:36,690
and easier to use getting software based

01:03:34,410 --> 01:03:39,540
token clients built to run on all major

01:03:36,690 --> 01:03:42,140
devices and OSS including iOS and

01:03:39,540 --> 01:03:44,490
Android these tokens utilize a

01:03:42,140 --> 01:03:46,950
public/private key combination that's

01:03:44,490 --> 01:03:48,839
generated and on device so there are any

01:03:46,950 --> 01:03:51,359
shared secrets flying around for

01:03:48,839 --> 01:03:54,210
attackers to hijack or which require any

01:03:51,359 --> 01:03:56,069
special handling instead all keys are

01:03:54,210 --> 01:03:58,530
kept secure and private between the

01:03:56,069 --> 01:04:00,720
requesting token and your server which

01:03:58,530 --> 01:04:02,359
you control in house making it the most

01:04:00,720 --> 01:04:05,010
secure way possible to perform

01:04:02,359 --> 01:04:07,829
authentication encryption and with an

01:04:05,010 --> 01:04:10,619
extensive flexible API and support for

01:04:07,829 --> 01:04:12,569
protocols like ldap and radius wicket

01:04:10,619 --> 01:04:14,510
works with any enterprise network

01:04:12,569 --> 01:04:16,480
architecture to protect

01:04:14,510 --> 01:04:19,090
Systems vital to your enterprise

01:04:16,480 --> 01:04:21,080
download your wicked free trial today

01:04:19,090 --> 01:04:22,850
regardless of whether you're considering

01:04:21,080 --> 01:04:24,650
two-factor authentication for the first

01:04:22,850 --> 01:04:27,890
time we're just ready to ditch your

01:04:24,650 --> 01:04:30,290
existing expensive key file system we

01:04:27,890 --> 01:04:35,200
can help with easy to implement easy to

01:04:30,290 --> 01:04:35,200
use strong authentication from wicked

01:05:14,190 --> 01:05:16,250
you

01:05:22,320 --> 01:05:27,400
when we created asterisk over a decade

01:05:25,060 --> 01:05:29,350
ago we could not have imagined that

01:05:27,400 --> 01:05:31,570
asterisk would not only become the most

01:05:29,350 --> 01:05:33,700
widely adopted open source communication

01:05:31,570 --> 01:05:35,740
software on the planet but that it would

01:05:33,700 --> 01:05:38,260
impact the entire industry in the way

01:05:35,740 --> 01:05:40,240
that it has today asterisk has found its

01:05:38,260 --> 01:05:42,880
way in the more than 170 countries and

01:05:40,240 --> 01:05:44,830
virtually every fortune 1000 company the

01:05:42,880 --> 01:05:46,900
success of asterisk has enabled a

01:05:44,830 --> 01:05:48,340
transition of power from the hands of

01:05:46,900 --> 01:05:50,590
the traditional proprietary phone

01:05:48,340 --> 01:05:52,990
vendors into the hands of the users and

01:05:50,590 --> 01:05:54,940
administrators of phone systems using

01:05:52,990 --> 01:05:56,170
this power our customers have created

01:05:54,940 --> 01:05:58,119
all sorts of business changing

01:05:56,170 --> 01:05:59,950
applications from small office phone

01:05:58,119 --> 01:06:02,470
systems to mission-critical call centers

01:05:59,950 --> 01:06:04,090
to international carrier networks in

01:06:02,470 --> 01:06:05,860
fact there's even an entire country

01:06:04,090 --> 01:06:08,470
those communications infrastructure runs

01:06:05,860 --> 01:06:10,390
on esters the gym has always been about

01:06:08,470 --> 01:06:12,100
creating technology that expands

01:06:10,390 --> 01:06:14,260
communications capabilities in ways that

01:06:12,100 --> 01:06:15,460
we could never have imagined and that's

01:06:14,260 --> 01:06:17,860
part of what's game-changing about

01:06:15,460 --> 01:06:20,560
digium today we're doing it again this

01:06:17,860 --> 01:06:22,660
time by introducing a new family of HD

01:06:20,560 --> 01:06:24,760
IP phones that extends control of the

01:06:22,660 --> 01:06:26,530
user all the way to the desktop the

01:06:24,760 --> 01:06:28,240
launch of these new products represents

01:06:26,530 --> 01:06:30,310
the next phase indigenous history of

01:06:28,240 --> 01:06:32,740
innovation these are the first and only

01:06:30,310 --> 01:06:34,030
IP phones designed to fully leverage the

01:06:32,740 --> 01:06:35,740
power of asterisks when we first

01:06:34,030 --> 01:06:37,390
discussed our expectations for building

01:06:35,740 --> 01:06:40,000
a family of phones for use with asterisk

01:06:37,390 --> 01:06:41,800
our requirements were pretty simple we

01:06:40,000 --> 01:06:43,540
asked the team to build the phones such

01:06:41,800 --> 01:06:45,760
that they were easy to install integrate

01:06:43,540 --> 01:06:47,590
provision and use I think you'll soon

01:06:45,760 --> 01:06:50,170
agree our engineers have delivered on

01:06:47,590 --> 01:06:51,790
that goal user feedback is validating

01:06:50,170 --> 01:06:53,920
that when it comes to operation with

01:06:51,790 --> 01:06:56,320
astro space systems including our own

01:06:53,920 --> 01:06:58,900
Switchvox based product these are the

01:06:56,320 --> 01:07:00,220
easiest to use best integrated most

01:06:58,900 --> 01:07:02,800
interoperable products on the market

01:07:00,220 --> 01:07:04,800
today the digitally phones will

01:07:02,800 --> 01:07:06,850
initially include three IP des hommes

01:07:04,800 --> 01:07:08,800
uniquely designed to complement any

01:07:06,850 --> 01:07:10,660
asterisk or switch box based solution

01:07:08,800 --> 01:07:13,330
these phones are different for a number

01:07:10,660 --> 01:07:15,970
of reasons first there is clue sively

01:07:13,330 --> 01:07:17,410
designed for use with esters secondly

01:07:15,970 --> 01:07:19,020
we've made it really easy to

01:07:17,410 --> 01:07:21,400
autodiscover and provision the phones

01:07:19,020 --> 01:07:23,109
next we've made it easy for the phones

01:07:21,400 --> 01:07:25,050
to access information inside of

01:07:23,109 --> 01:07:27,050
asterisks allowing tight coupling

01:07:25,050 --> 01:07:29,010
between the application and the phone

01:07:27,050 --> 01:07:31,170
additionally we've created an

01:07:29,010 --> 01:07:33,300
applications engine that allows users

01:07:31,170 --> 01:07:36,540
and developers to create and run their

01:07:33,300 --> 01:07:38,310
own apps on the phone and finally we've

01:07:36,540 --> 01:07:40,260
done all of this at a very compelling

01:07:38,310 --> 01:07:41,940
price point at digium we're always

01:07:40,260 --> 01:07:44,040
thinking of ways to give our customers

01:07:41,940 --> 01:07:46,560
the best value in business phone systems

01:07:44,040 --> 01:07:48,270
and also give them the power to create

01:07:46,560 --> 01:07:50,310
their own solutions or eating

01:07:48,270 --> 01:07:52,050
communications challenge well continue

01:07:50,310 --> 01:07:53,490
to push the boundaries not only to make

01:07:52,050 --> 01:07:55,530
Astra's cooler bastard more

01:07:53,490 --> 01:07:57,270
technologically feature-rich but to make

01:07:55,530 --> 01:07:59,790
asterisk and communications even easier

01:07:57,270 --> 01:08:03,320
and together we'll change the way the

01:07:59,790 --> 01:08:03,320
world communication again

01:08:10,609 --> 01:08:14,910
your customers rely on your website or

01:08:13,410 --> 01:08:17,279
application if it's slower

01:08:14,910 --> 01:08:20,219
non-responsive it infuriates your users

01:08:17,279 --> 01:08:22,049
and costs you money keeping your

01:08:20,219 --> 01:08:25,530
business critical systems humming along

01:08:22,049 --> 01:08:28,380
requires insight into what they're doing

01:08:25,530 --> 01:08:30,360
your system metrics tell stories stories

01:08:28,380 --> 01:08:32,850
that can reveal performance bottlenecks

01:08:30,360 --> 01:08:34,770
resource limitations and other problems

01:08:32,850 --> 01:08:36,690
but how do you keep an eye on all of

01:08:34,770 --> 01:08:39,300
your systems performance metrics in

01:08:36,690 --> 01:08:42,150
real-time and record this data for later

01:08:39,300 --> 01:08:44,130
analysis enter longview the new way to

01:08:42,150 --> 01:08:46,170
see what's really going on under the

01:08:44,130 --> 01:08:48,300
hood the longview dashboard lets you

01:08:46,170 --> 01:08:50,280
visualize the status of all your systems

01:08:48,300 --> 01:08:53,190
providing you with a bird's-eye view of

01:08:50,280 --> 01:08:56,130
your entire fleet you can sort by cpu

01:08:53,190 --> 01:08:58,830
memory swap processes load and network

01:08:56,130 --> 01:09:01,170
usage click a specific system to access

01:08:58,830 --> 01:09:03,180
its individual dashboard then click and

01:09:01,170 --> 01:09:06,180
drag to zoom in on chokepoints and get

01:09:03,180 --> 01:09:08,160
more detail comprehensive network data

01:09:06,180 --> 01:09:10,860
including inbound and outbound traffic

01:09:08,160 --> 01:09:12,450
is available on the network tab and disk

01:09:10,860 --> 01:09:14,340
rights and free space on the disk

01:09:12,450 --> 01:09:17,190
stabbed while the process Explorer

01:09:14,340 --> 01:09:19,740
displays usage statistics for individual

01:09:17,190 --> 01:09:21,900
processes the system info tab shows

01:09:19,740 --> 01:09:24,150
listening services active connections

01:09:21,900 --> 01:09:26,280
and available updates adding long view

01:09:24,150 --> 01:09:27,960
to a system is easy just click the

01:09:26,280 --> 01:09:30,120
button copy the one line installation

01:09:27,960 --> 01:09:32,550
command then run the command on your

01:09:30,120 --> 01:09:34,260
linux system to complete the process the

01:09:32,550 --> 01:09:36,420
agent will begin collecting data and

01:09:34,260 --> 01:09:38,299
sending it to longview then the graph

01:09:36,420 --> 01:09:40,849
start rolling

01:09:38,299 --> 01:09:43,219
use longview to gain visibility into

01:09:40,849 --> 01:09:46,960
your servers so when your website or app

01:09:43,219 --> 01:09:46,960
heats up it stays up

01:09:50,830 --> 01:09:57,310
how's that sigh every way this is the

01:09:53,980 --> 01:09:59,470
way to better utilize all your resources

01:09:57,310 --> 01:10:02,920
and it makes managing all your resources

01:09:59,470 --> 01:10:06,750
pretty easy all of the innovation is

01:10:02,920 --> 01:10:10,240
happening in open source the

01:10:06,750 --> 01:10:12,070
collaborative nature and of the you know

01:10:10,240 --> 01:10:13,990
of the community and the speed at which

01:10:12,070 --> 01:10:16,180
these are these you know these

01:10:13,990 --> 01:10:18,460
deficiencies these bugs are getting

01:10:16,180 --> 01:10:21,070
discovered and then fixed is the thing

01:10:18,460 --> 01:10:23,800
that really shows the power of the you

01:10:21,070 --> 01:10:25,420
know of the open source community it is

01:10:23,800 --> 01:10:29,620
global and it's definitely because of

01:10:25,420 --> 01:10:35,950
the users community people are extremely

01:10:29,620 --> 01:10:37,690
friendly and always ready to help if you

01:10:35,950 --> 01:10:39,370
go an entire see any day you'll see

01:10:37,690 --> 01:10:41,260
these guys helping each other out and

01:10:39,370 --> 01:10:44,170
they're all doing it like in a selfless

01:10:41,260 --> 01:10:46,000
manner the product is transparent for

01:10:44,170 --> 01:10:50,200
everyone everyone can look at the code

01:10:46,000 --> 01:10:52,210
base everyone can see how clouds duck is

01:10:50,200 --> 01:10:58,090
being built nothing nothing is

01:10:52,210 --> 01:11:00,730
proprietary everything is open in many

01:10:58,090 --> 01:11:04,930
ways it's absolutely vital to the the

01:11:00,730 --> 01:11:08,710
ongoing health CloudStack the most

01:11:04,930 --> 01:11:12,610
exciting event in recent memory for me

01:11:08,710 --> 01:11:15,250
was our first developer boot camp

01:11:12,610 --> 01:11:17,889
and our call gave people I gave you two

01:11:15,250 --> 01:11:21,850
weeks notice to come attend I was

01:11:17,889 --> 01:11:26,050
expecting 25 or 30 people so we ended up

01:11:21,850 --> 01:11:28,869
with 87 people and had to go get more

01:11:26,050 --> 01:11:31,389
chairs into the room twice everything

01:11:28,869 --> 01:11:34,659
within cloud computing is commodity and

01:11:31,389 --> 01:11:37,719
is open source and so I don't think that

01:11:34,659 --> 01:11:39,639
you will you'll see anywhere where open

01:11:37,719 --> 01:11:43,090
sources not pervasive in cloud computing

01:11:39,639 --> 01:11:45,250
and so i think it's i think it's an

01:11:43,090 --> 01:11:46,750
assumption i think when you talk about

01:11:45,250 --> 01:11:51,580
cloud computing you're really talking

01:11:46,750 --> 01:11:53,860
about open source cloud computing cloud

01:11:51,580 --> 01:11:56,619
zac is a robust solution for large

01:11:53,860 --> 01:11:59,020
deployments you'll have dozens of data

01:11:56,619 --> 01:12:03,040
centers and thousands of servers in each

01:11:59,020 --> 01:12:06,310
data centers these hardware is going to

01:12:03,040 --> 01:12:09,520
fail and CloudStack is designed to

01:12:06,310 --> 01:12:12,010
handle number one that mass scale number

01:12:09,520 --> 01:12:14,739
two it's designed to handle the failure

01:12:12,010 --> 01:12:17,260
that inevitably happens in large

01:12:14,739 --> 01:12:20,800
deployments started working on college

01:12:17,260 --> 01:12:24,159
attack over four years ago and it was

01:12:20,800 --> 01:12:26,830
the original set of people working on it

01:12:24,159 --> 01:12:30,940
had a background of delivering software

01:12:26,830 --> 01:12:35,170
telcos and service providers lots of QA

01:12:30,940 --> 01:12:38,800
lots of users actually using it high

01:12:35,170 --> 01:12:41,860
availability is a key feature multiple

01:12:38,800 --> 01:12:43,900
hypervisors support different network

01:12:41,860 --> 01:12:46,570
models you can pick up whatever suits

01:12:43,900 --> 01:12:48,820
you better while steck management server

01:12:46,570 --> 01:12:52,510
can be deployed in different physical

01:12:48,820 --> 01:12:54,190
machines it definitely has a huge

01:12:52,510 --> 01:12:59,170
footprint it's being deployed everywhere

01:12:54,190 --> 01:13:01,750
there's a major movie studio that they

01:12:59,170 --> 01:13:04,929
were using cloudstack they were using it

01:13:01,750 --> 01:13:07,030
to transcode video and i thought that

01:13:04,929 --> 01:13:08,679
was terribly fascinating what i found

01:13:07,030 --> 01:13:11,949
more fascinating is what they did during

01:13:08,679 --> 01:13:14,710
lunch where they would spin up you know

01:13:11,949 --> 01:13:15,880
50 or 60 game servers then as soon as

01:13:14,710 --> 01:13:17,739
lunch was over they would

01:13:15,880 --> 01:13:21,850
all the instances and go back to doing

01:13:17,739 --> 01:13:23,469
real work CloudStack is vast it touches

01:13:21,850 --> 01:13:25,570
so many different aspects and there's no

01:13:23,469 --> 01:13:27,940
one person that's kind of like a master

01:13:25,570 --> 01:13:32,050
of all those realms I think clouds stack

01:13:27,940 --> 01:13:34,270
as a project is going to be one of the

01:13:32,050 --> 01:13:38,320
leaders simply because it's some of the

01:13:34,270 --> 01:13:43,780
most feature fallen and and robust

01:13:38,320 --> 01:13:46,679
platforms out they were Adams senior

01:13:43,780 --> 01:13:46,679
living for the clouds dag

01:13:59,510 --> 01:14:01,570

YouTube URL: https://www.youtube.com/watch?v=8Yt0tyGctNg


