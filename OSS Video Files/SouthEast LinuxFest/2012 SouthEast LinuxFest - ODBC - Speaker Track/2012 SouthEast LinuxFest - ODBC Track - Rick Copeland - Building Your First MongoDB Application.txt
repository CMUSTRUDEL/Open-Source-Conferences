Title: 2012 SouthEast LinuxFest - ODBC Track - Rick Copeland - Building Your First MongoDB Application
Publication date: 2013-04-06
Playlist: 2012 SouthEast LinuxFest - ODBC - Speaker Track
Description: 
	2012 SouthEast LinuxFest
Open Database Camp Speaker Track
Rick Copeland
Building Your First MongoDB Application
Captions: 
	00:00:00,000 --> 00:00:05,279
the following presentation was recorded

00:00:02,490 --> 00:00:08,040
the 2012 southeast linux fest in

00:00:05,279 --> 00:00:10,410
charlotte north carolina it is licensed

00:00:08,040 --> 00:00:12,090
under a creative commons license for

00:00:10,410 --> 00:00:16,859
more information about the southeast

00:00:12,090 --> 00:00:19,230
linux fest visit www.lend expense org

00:00:16,859 --> 00:00:21,320
the southeast linux fest would like to

00:00:19,230 --> 00:00:23,699
thank the following diamond sponsors in

00:00:21,320 --> 00:00:26,090
2012 for helping make these videos

00:00:23,699 --> 00:00:26,090
possible

00:00:43,820 --> 00:00:49,430
this is a this is a great opportunity to

00:00:47,060 --> 00:00:51,110
speak to everyone here yesterday I guess

00:00:49,430 --> 00:00:54,500
there were two entire tracks devoted to

00:00:51,110 --> 00:00:56,059
mysql today this track is devoted to

00:00:54,500 --> 00:00:59,210
databases of which I believe I'm the

00:00:56,059 --> 00:01:00,980
only no SQL database so I'm kind of

00:00:59,210 --> 00:01:04,910
incognito so if you'll just excuse me 10

00:01:00,980 --> 00:01:06,890
get my MongoDB shirt now ok so just

00:01:04,910 --> 00:01:09,830
inside here we can see that I'm MongoDB

00:01:06,890 --> 00:01:12,020
supporter so I'm going to be talking

00:01:09,830 --> 00:01:14,600
about giving your first or building your

00:01:12,020 --> 00:01:16,340
first DB DB application this is

00:01:14,600 --> 00:01:20,360
going to be more of a developer oriented

00:01:16,340 --> 00:01:22,490
talk so just to give me an idea of who

00:01:20,360 --> 00:01:24,050
is in here are there any people who

00:01:22,490 --> 00:01:26,990
consider themselves more in operations

00:01:24,050 --> 00:01:29,330
than development okay and who's more

00:01:26,990 --> 00:01:32,619
development than operations okay and

00:01:29,330 --> 00:01:34,880
what about MongoDB experience who has

00:01:32,619 --> 00:01:36,740
played around with MongoDB like

00:01:34,880 --> 00:01:39,950
downloaded it installed it and run some

00:01:36,740 --> 00:01:43,160
queries okay anybody using it for

00:01:39,950 --> 00:01:46,220
anything more than that okay so that

00:01:43,160 --> 00:01:47,570
will help me level set here so just by

00:01:46,220 --> 00:01:50,689
way of introduction of Who I am right

00:01:47,570 --> 00:01:52,759
now I'm a consultant as rock mentioned i

00:01:50,689 --> 00:01:54,229
actually just went independent of in

00:01:52,759 --> 00:01:56,689
February but before that i was at

00:01:54,229 --> 00:01:59,960
sourceforge we were an early adopter of

00:01:56,689 --> 00:02:01,610
MongoDB version 0.8 I believe was the

00:01:59,960 --> 00:02:05,000
first version that we deployed on in

00:02:01,610 --> 00:02:07,159
production I'm going to be for reference

00:02:05,000 --> 00:02:10,340
is now at version 2 122 is about to come

00:02:07,159 --> 00:02:13,630
out I also the author of a central

00:02:10,340 --> 00:02:17,090
sequel alchemy which is a Python object

00:02:13,630 --> 00:02:18,500
relational toolkit library I don't know

00:02:17,090 --> 00:02:20,090
exactly what to call it it it does all

00:02:18,500 --> 00:02:22,790
sorts of things beyond what a normal ORM

00:02:20,090 --> 00:02:25,549
does so I'm saying that by way of saying

00:02:22,790 --> 00:02:27,799
I like SQL and I like MongoDB both so

00:02:25,549 --> 00:02:29,930
I'm not trying to be adversarial in the

00:02:27,799 --> 00:02:31,970
talk and primarily my experience is

00:02:29,930 --> 00:02:33,799
coding Python but the examples here are

00:02:31,970 --> 00:02:35,269
going to be JavaScript and the reason

00:02:33,799 --> 00:02:37,400
for that is MongoDB actually ships with

00:02:35,269 --> 00:02:40,280
a JavaScript interpreter shell so that

00:02:37,400 --> 00:02:41,209
you can try out your queries so that's

00:02:40,280 --> 00:02:43,910
where the examples are going to be

00:02:41,209 --> 00:02:45,530
coming from so what you're going to

00:02:43,910 --> 00:02:46,850
learn here the first thing is you can

00:02:45,530 --> 00:02:50,120
learn is how to do data modeling in

00:02:46,850 --> 00:02:51,410
MongoDB how to write your queries in

00:02:50,120 --> 00:02:53,000
MongoDB because it's a little bit

00:02:51,410 --> 00:02:56,090
different it's a no SQL database you're

00:02:53,000 --> 00:02:57,080
not going to use SQL geospatial indexing

00:02:56,090 --> 00:02:58,640
so I'm not going to be has

00:02:57,080 --> 00:02:59,810
add support for geospatial indexing for

00:02:58,640 --> 00:03:02,120
the last couple of versions I'm not sure

00:02:59,810 --> 00:03:03,320
exactly when it was introduced but we're

00:03:02,120 --> 00:03:07,580
going to look at how to do a geospatial

00:03:03,320 --> 00:03:09,380
query how to do updates to MongoDB how

00:03:07,580 --> 00:03:11,540
to use the MapReduce engine so MongoDB

00:03:09,380 --> 00:03:13,550
includes a MapReduce implementation so

00:03:11,540 --> 00:03:14,840
you can and this is different from

00:03:13,550 --> 00:03:17,120
couchdb where that's like the only way

00:03:14,840 --> 00:03:20,480
to query your data in MongoDB it's an

00:03:17,120 --> 00:03:21,680
optional way to do bulk updates and also

00:03:20,480 --> 00:03:23,030
look at some deployment and scaling

00:03:21,680 --> 00:03:24,470
concerns in MongoDB of course everybody

00:03:23,030 --> 00:03:27,320
knows its web scale right so that's all

00:03:24,470 --> 00:03:28,910
you have to do but but more seriously

00:03:27,320 --> 00:03:30,500
how what are some of the things that you

00:03:28,910 --> 00:03:32,060
can do to ease some of the scaling

00:03:30,500 --> 00:03:33,620
problems one thing that I'm not really

00:03:32,060 --> 00:03:35,570
going to talk about is why MongoDB

00:03:33,620 --> 00:03:37,490
because it's just not what this talk is

00:03:35,570 --> 00:03:39,260
about it but we can talk about it later

00:03:37,490 --> 00:03:44,510
in the hallway trackage don't start a

00:03:39,260 --> 00:03:46,010
flame or inside the room so anyway so

00:03:44,510 --> 00:03:48,170
the way that we're going to do this is

00:03:46,010 --> 00:03:50,350
to actually go through and build an

00:03:48,170 --> 00:03:52,970
application or at least look at the data

00:03:50,350 --> 00:03:54,500
updates and manipulations we have to do

00:03:52,970 --> 00:03:56,570
to build that application so it's going

00:03:54,500 --> 00:03:58,520
to be a location-based check-in

00:03:56,570 --> 00:04:00,530
application I don't know where I got the

00:03:58,520 --> 00:04:03,830
idea from this but will call ours three

00:04:00,530 --> 00:04:05,630
triangle so just to avoid trademark

00:04:03,830 --> 00:04:07,100
problems so that there's three main

00:04:05,630 --> 00:04:08,420
things that the user can do on this

00:04:07,100 --> 00:04:10,340
application they can check they can

00:04:08,420 --> 00:04:12,080
create different locations so you can

00:04:10,340 --> 00:04:14,390
come in and you can say well my office

00:04:12,080 --> 00:04:16,459
is here and this is going to be the page

00:04:14,390 --> 00:04:18,080
for that location they can check in two

00:04:16,459 --> 00:04:19,820
locations so whenever you're look you're

00:04:18,080 --> 00:04:21,200
close to it you can check in and you can

00:04:19,820 --> 00:04:25,310
also see who else is checked in at that

00:04:21,200 --> 00:04:27,380
location so the main operations that

00:04:25,310 --> 00:04:29,630
we're going to look at is I mentioned

00:04:27,380 --> 00:04:33,290
they can users can create locations so

00:04:29,630 --> 00:04:34,370
users generate places you can also when

00:04:33,290 --> 00:04:35,660
you're checking in you need to find

00:04:34,370 --> 00:04:37,610
nearby places you're going to be able to

00:04:35,660 --> 00:04:39,050
query that and then you're also going to

00:04:37,610 --> 00:04:41,300
be able to you're going to need to

00:04:39,050 --> 00:04:43,460
record your check-ins and also we'll do

00:04:41,300 --> 00:04:45,890
some basic statistics on the check n

00:04:43,460 --> 00:04:47,570
data model so that we can see you know

00:04:45,890 --> 00:04:49,669
how many check-ins there were at a

00:04:47,570 --> 00:04:53,030
particular location on a particular day

00:04:49,669 --> 00:04:54,919
things like that and now since most

00:04:53,030 --> 00:04:56,750
people in here not MongoDB experts you

00:04:54,919 --> 00:04:58,850
haven't been using it for long or maybe

00:04:56,750 --> 00:05:00,650
you haven't used it at all I want to do

00:04:58,850 --> 00:05:02,990
a little bit of terminology mapping so

00:05:00,650 --> 00:05:04,810
in the relational what well just to

00:05:02,990 --> 00:05:08,249
level set who's used in SQL database

00:05:04,810 --> 00:05:10,259
okay good that's what I figured

00:05:08,249 --> 00:05:12,139
so in the relational world you got some

00:05:10,259 --> 00:05:14,819
of the some of the concepts map pretty

00:05:12,139 --> 00:05:16,649
straightforward in a relational database

00:05:14,819 --> 00:05:18,509
it's called a database MongoDB it calls

00:05:16,649 --> 00:05:20,519
it a database relational you call it a

00:05:18,509 --> 00:05:21,779
table in MongoDB it's called a

00:05:20,519 --> 00:05:23,099
collection and we'll get into the

00:05:21,779 --> 00:05:25,289
differences between collections and

00:05:23,099 --> 00:05:27,089
tables a little bit they're indexes in

00:05:25,289 --> 00:05:29,909
both and they serve the same purpose

00:05:27,089 --> 00:05:32,009
there are rows in a database in a

00:05:29,909 --> 00:05:34,079
relational database and documents in

00:05:32,009 --> 00:05:35,489
MongoDB and that's not a document like a

00:05:34,079 --> 00:05:38,879
word document that's a document like a

00:05:35,489 --> 00:05:44,089
JSON object and then columns we call

00:05:38,879 --> 00:05:46,739
them fields or properties in MongoDB so

00:05:44,089 --> 00:05:49,949
documents I mentioned that it's not like

00:05:46,739 --> 00:05:52,110
a smoke like a text document but it's

00:05:49,949 --> 00:05:55,229
more of a structured object so in

00:05:52,110 --> 00:05:58,829
MongoDB you have if you've used who's

00:05:55,229 --> 00:06:01,259
use Jason in here so it's the JavaScript

00:05:58,829 --> 00:06:04,019
object or yeah JavaScript object

00:06:01,259 --> 00:06:05,459
notation so mommy to me doesn't

00:06:04,019 --> 00:06:07,319
technically use JSON it uses a binary

00:06:05,459 --> 00:06:11,249
format but it's modeled after Jason is

00:06:07,319 --> 00:06:13,110
called beasts on so but you can think of

00:06:11,249 --> 00:06:14,369
it as JSON so what you store in ma going

00:06:13,110 --> 00:06:18,360
to be instead of a row is you're storing

00:06:14,369 --> 00:06:20,099
this document or we're object and you

00:06:18,360 --> 00:06:23,249
can put in primitive types it provides a

00:06:20,099 --> 00:06:25,409
little good type called an object ID you

00:06:23,249 --> 00:06:27,959
can also store real uu IDs in MongoDB

00:06:25,409 --> 00:06:29,549
you can also store primitive types so

00:06:27,959 --> 00:06:31,769
that's what value 1 in value to here are

00:06:29,549 --> 00:06:34,739
indicating and that could be an integer

00:06:31,769 --> 00:06:38,249
flow you know string datetime all the

00:06:34,739 --> 00:06:40,289
standard type things you can also store

00:06:38,249 --> 00:06:42,569
embedded objects and that's what key 3

00:06:40,289 --> 00:06:47,009
is referencing so you can have an object

00:06:42,569 --> 00:06:48,869
or an embedded document object which is

00:06:47,009 --> 00:06:50,159
kind of neat but it's not that exciting

00:06:48,869 --> 00:06:52,079
because you can always use an underscore

00:06:50,159 --> 00:06:55,229
in a in a field name and that gives you

00:06:52,079 --> 00:06:56,069
the same the same property but the other

00:06:55,229 --> 00:06:58,529
nice thing is that you can actually

00:06:56,069 --> 00:06:59,639
store embedded arrays so this allows you

00:06:58,529 --> 00:07:01,019
to do something where in like a

00:06:59,639 --> 00:07:03,959
relational database you might have a

00:07:01,019 --> 00:07:05,129
one-to-many join say a blog post if

00:07:03,959 --> 00:07:08,969
you're writing a blog post you might

00:07:05,129 --> 00:07:11,219
have a comments table and a post stable

00:07:08,969 --> 00:07:12,689
and you do one too many join in MongoDB

00:07:11,219 --> 00:07:14,369
you can actually embed those comments

00:07:12,689 --> 00:07:16,229
within the blog post so you don't have

00:07:14,369 --> 00:07:18,839
to do a joint when you're querying to

00:07:16,229 --> 00:07:22,320
display a blog page just as an example

00:07:18,839 --> 00:07:24,640
so for our applica

00:07:22,320 --> 00:07:27,940
we're going to well I should probably

00:07:24,640 --> 00:07:29,770
back up just just a minute to talk about

00:07:27,940 --> 00:07:31,870
collections so I talked about documents

00:07:29,770 --> 00:07:34,660
now a collection is a collection of

00:07:31,870 --> 00:07:36,190
documents the difference between MongoDB

00:07:34,660 --> 00:07:38,140
and or one of the differences between a

00:07:36,190 --> 00:07:40,260
MongoDB collection and a relational

00:07:38,140 --> 00:07:42,580
database table is that there is no

00:07:40,260 --> 00:07:44,950
common schema enforcement on a

00:07:42,580 --> 00:07:46,390
collection so you could have a document

00:07:44,950 --> 00:07:47,950
that represents is a user next to a

00:07:46,390 --> 00:07:49,390
document that represents a check-in and

00:07:47,950 --> 00:07:51,610
mongodb is not going to stop you it's

00:07:49,390 --> 00:07:53,710
not typically a good idea to do that but

00:07:51,610 --> 00:07:55,270
you can do whatever format because the

00:07:53,710 --> 00:07:57,310
format the schema of the documents

00:07:55,270 --> 00:07:59,470
actually stored within the document so

00:07:57,310 --> 00:08:00,970
it's kind of like the the difference

00:07:59,470 --> 00:08:02,830
between a static programming language

00:08:00,970 --> 00:08:04,810
and a dynamic programming language so

00:08:02,830 --> 00:08:07,090
the type information in a relational

00:08:04,810 --> 00:08:09,220
database lives at the table definition

00:08:07,090 --> 00:08:11,410
the type information in the in MongoDB

00:08:09,220 --> 00:08:12,910
lives with the document itself and

00:08:11,410 --> 00:08:14,440
there's advantages and disadvantages to

00:08:12,910 --> 00:08:17,860
that but just just by way of

00:08:14,440 --> 00:08:20,890
illustrating what that is so collections

00:08:17,860 --> 00:08:22,270
a logical grouping of documents so the

00:08:20,890 --> 00:08:23,740
collections that we're interested in for

00:08:22,270 --> 00:08:25,540
our application are going to be where we

00:08:23,740 --> 00:08:30,220
want to know about places and users and

00:08:25,540 --> 00:08:32,710
check-ins on collections so I mentioned

00:08:30,220 --> 00:08:34,419
there are logical grouping you can do

00:08:32,710 --> 00:08:36,250
querying on collection so all of your

00:08:34,419 --> 00:08:38,320
queries you're saying from this

00:08:36,250 --> 00:08:39,760
collection select these documents you

00:08:38,320 --> 00:08:41,620
also do all of your indexing on a per

00:08:39,760 --> 00:08:43,690
collection basis and all of your

00:08:41,620 --> 00:08:45,280
updating as well as sharding and we'll

00:08:43,690 --> 00:08:47,770
get into that MongoDB has some support

00:08:45,280 --> 00:08:49,510
for automatic sharding of collections so

00:08:47,770 --> 00:08:51,400
that's why you really want to keep the

00:08:49,510 --> 00:08:52,480
same type of data in there because all

00:08:51,400 --> 00:08:54,340
of your queries are going to be talking

00:08:52,480 --> 00:08:55,300
to one collection at a time all of your

00:08:54,340 --> 00:08:59,740
updates are going to talk to one

00:08:55,300 --> 00:09:01,900
collection at a time so let's look at

00:08:59,740 --> 00:09:04,090
designing the data model for our places

00:09:01,900 --> 00:09:05,890
collection the first idea might be hey

00:09:04,090 --> 00:09:07,030
we're going to just have a place and

00:09:05,890 --> 00:09:09,250
it's going to have the name and the

00:09:07,030 --> 00:09:10,630
address city and zip and then when we

00:09:09,250 --> 00:09:13,390
need to find a place we'll just grab

00:09:10,630 --> 00:09:15,670
that place by zip code and will limit it

00:09:13,390 --> 00:09:18,280
to 10 documents that are returned well

00:09:15,670 --> 00:09:22,320
that I mean it's it's a good first pass

00:09:18,280 --> 00:09:24,700
there's several problems with this and

00:09:22,320 --> 00:09:26,560
one of the problems is that there's

00:09:24,700 --> 00:09:30,940
probably a lot of things in area code

00:09:26,560 --> 00:09:33,130
2820 for in Charlotte so this is going

00:09:30,940 --> 00:09:34,990
to return us just a ton of documents and

00:09:33,130 --> 00:09:36,880
we'll look at how to fix that invert

00:09:34,990 --> 00:09:40,990
to another thing to notice here is the

00:09:36,880 --> 00:09:43,209
query syntax for mongodb is this you

00:09:40,990 --> 00:09:44,440
actually send in a JSON document and in

00:09:43,209 --> 00:09:45,880
this case it's kind of like a query by

00:09:44,440 --> 00:09:48,190
example there's ways to do other things

00:09:45,880 --> 00:09:49,870
other than equality queries in MongoDB

00:09:48,190 --> 00:09:51,880
but for all of those you're going to use

00:09:49,870 --> 00:09:54,730
a JSON type syntax so if you're familiar

00:09:51,880 --> 00:09:57,160
with JSON then then it'll look a little

00:09:54,730 --> 00:09:58,540
bit familiar but there are some some

00:09:57,160 --> 00:10:00,520
tricks and you've gotta it is

00:09:58,540 --> 00:10:01,540
technically another query language that

00:10:00,520 --> 00:10:04,390
you're going to have to learn to use

00:10:01,540 --> 00:10:07,750
MongoDB so you certainly can't use SQL

00:10:04,390 --> 00:10:10,750
on it but anyway there there is that so

00:10:07,750 --> 00:10:12,190
let's look at updating our places and so

00:10:10,750 --> 00:10:15,070
one of the things that we can do with

00:10:12,190 --> 00:10:16,540
updating the places is we'll go ahead

00:10:15,070 --> 00:10:19,120
and add a tags field and this is showing

00:10:16,540 --> 00:10:21,160
one of the MongoDB unique type things

00:10:19,120 --> 00:10:22,420
that you can do that's different than a

00:10:21,160 --> 00:10:25,000
relational databases we're going to have

00:10:22,420 --> 00:10:28,120
a ray of tags and then when we do our

00:10:25,000 --> 00:10:29,709
query to grab the hotel now we can say

00:10:28,120 --> 00:10:31,510
well we're looking for things into 8204

00:10:29,709 --> 00:10:35,260
that's also a hotel so we might get a

00:10:31,510 --> 00:10:36,399
smaller number of documents back one of

00:10:35,260 --> 00:10:38,649
the things to notice here is that

00:10:36,399 --> 00:10:40,630
MongoDB whenever you give it an array

00:10:38,649 --> 00:10:42,670
type field it's going to see does any

00:10:40,630 --> 00:10:45,160
element of that array match what we're

00:10:42,670 --> 00:10:46,630
asking for so this will find us anything

00:10:45,160 --> 00:10:49,209
that has hotel is one of its items

00:10:46,630 --> 00:10:54,339
inside tags and then we're still

00:10:49,209 --> 00:10:56,890
limiting it to 10 results now more

00:10:54,339 --> 00:10:58,570
interestingly we can do lat long queries

00:10:56,890 --> 00:11:00,430
and this is the geospatial query that I

00:10:58,570 --> 00:11:01,540
was talking about so when you're

00:11:00,430 --> 00:11:03,070
creating the place you're probably doing

00:11:01,540 --> 00:11:04,990
it from a cell phone so you can grab the

00:11:03,070 --> 00:11:07,300
location data and then you can insert

00:11:04,990 --> 00:11:08,860
that into a two element array and then

00:11:07,300 --> 00:11:11,770
you tell MongoDB I'd like to create an

00:11:08,860 --> 00:11:13,930
index on that field and I'd like it to

00:11:11,770 --> 00:11:15,250
be a 2d index so normally indexes are

00:11:13,930 --> 00:11:17,140
just be trees but they also have this

00:11:15,250 --> 00:11:19,990
geospatial 2d index that you can create

00:11:17,140 --> 00:11:21,490
and then when you want to do a query to

00:11:19,990 --> 00:11:23,020
find the place to check in what you do

00:11:21,490 --> 00:11:25,870
is you say I'd like to find all of the

00:11:23,020 --> 00:11:28,750
things that are near the lat/long 3580

00:11:25,870 --> 00:11:30,760
and what that will do is it will use the

00:11:28,750 --> 00:11:32,140
geospatial index and they'll sort

00:11:30,760 --> 00:11:34,300
everything in terms of their distance

00:11:32,140 --> 00:11:35,709
from that point and that's pretty much

00:11:34,300 --> 00:11:37,630
about four squares doing or sorry three

00:11:35,709 --> 00:11:39,370
triangles doing here it's just trying to

00:11:37,630 --> 00:11:41,730
give you the closest locations to your

00:11:39,370 --> 00:11:41,730
current location

00:11:41,800 --> 00:11:48,070
I mean you could you could do the

00:11:45,519 --> 00:11:50,500
question is is 2d strictly for

00:11:48,070 --> 00:11:52,870
geospatial and I don't I mean you could

00:11:50,500 --> 00:11:55,390
use it for anything it's it's going to

00:11:52,870 --> 00:11:56,649
give you the depending on which way you

00:11:55,390 --> 00:11:58,570
create the index is either going to give

00:11:56,649 --> 00:11:59,860
you a Cartesian distance from that

00:11:58,570 --> 00:12:01,630
location or it's going to give you a

00:11:59,860 --> 00:12:04,810
spherical distance that's really based

00:12:01,630 --> 00:12:07,029
on latitude and longitude so did you

00:12:04,810 --> 00:12:14,560
have a particular use case that you were

00:12:07,029 --> 00:12:15,820
wondering about okay so now for places

00:12:14,560 --> 00:12:21,040
the other thing that we wanted to do is

00:12:15,820 --> 00:12:22,060
we wanted to allow these or one of the

00:12:21,040 --> 00:12:23,890
things that we might want to do is a lot

00:12:22,060 --> 00:12:24,910
chips to be stored with the place so

00:12:23,890 --> 00:12:27,779
here we're going to go ahead and add

00:12:24,910 --> 00:12:30,250
another array field we're going to say

00:12:27,779 --> 00:12:32,649
we're going to embed this a list of

00:12:30,250 --> 00:12:34,540
documents so here I've got user is Rick

00:12:32,649 --> 00:12:36,550
you have a time stamp here which is sort

00:12:34,540 --> 00:12:38,200
of an ISO date time and then you know

00:12:36,550 --> 00:12:40,120
just a tip just a string says hey come

00:12:38,200 --> 00:12:42,640
and learn about the southeast linux fest

00:12:40,120 --> 00:12:44,490
and you can do that and that's that's

00:12:42,640 --> 00:12:46,899
maybe our final version of the places

00:12:44,490 --> 00:12:48,250
schema that we would be designing and

00:12:46,899 --> 00:12:49,870
this is kind of the process that you go

00:12:48,250 --> 00:12:52,930
through with the mommy-to-be data

00:12:49,870 --> 00:12:55,149
modeling exercise because you would you

00:12:52,930 --> 00:12:56,709
know it's it's not so much figuring out

00:12:55,149 --> 00:12:58,120
your create table sin taxes figuring out

00:12:56,709 --> 00:12:59,649
what you want the documents to look like

00:12:58,120 --> 00:13:02,079
and a lot of the time you'll do examples

00:12:59,649 --> 00:13:04,810
and and iterative development and the

00:13:02,079 --> 00:13:07,600
shell things like that so some of the

00:13:04,810 --> 00:13:09,490
queries that you might want to do here

00:13:07,600 --> 00:13:11,470
and to make these queries efficient i

00:13:09,490 --> 00:13:13,270
did mention MongoDB has indexes and so

00:13:11,470 --> 00:13:15,730
there's a couple of indexes that we want

00:13:13,270 --> 00:13:17,890
to create up front first as we want to

00:13:15,730 --> 00:13:19,240
index on tags because otherwise you know

00:13:17,890 --> 00:13:21,490
just like in any relational database

00:13:19,240 --> 00:13:22,839
MongoDB can maybe be fast it may be it

00:13:21,490 --> 00:13:24,670
may be a collection scans a little bit

00:13:22,839 --> 00:13:26,680
faster than the table scan but it still

00:13:24,670 --> 00:13:28,630
sucks okay so if you're having to visit

00:13:26,680 --> 00:13:31,329
a million documents it's going to be

00:13:28,630 --> 00:13:33,399
slow so you want to index on anything

00:13:31,329 --> 00:13:34,750
that you're going to query on and as the

00:13:33,399 --> 00:13:37,270
previous speaker said you know good

00:13:34,750 --> 00:13:39,970
indexes are very selective so you don't

00:13:37,270 --> 00:13:43,600
ever index a boolean field by itself for

00:13:39,970 --> 00:13:45,610
instance so here we going to index the

00:13:43,600 --> 00:13:47,860
tags we're going to index the name and

00:13:45,610 --> 00:13:50,589
we're going to index this this lat long

00:13:47,860 --> 00:13:52,149
as well so if you want to find places

00:13:50,589 --> 00:13:54,310
that are nearby of course we talked

00:13:52,149 --> 00:13:55,180
about that query before you can also do

00:13:54,310 --> 00:13:56,800
regular expressions

00:13:55,180 --> 00:13:58,900
searching so you can pass in a regular

00:13:56,800 --> 00:14:00,460
expression that language your language

00:13:58,900 --> 00:14:02,350
driver will if you've got a native

00:14:00,460 --> 00:14:05,710
regular expressions object then you just

00:14:02,350 --> 00:14:07,630
pass that in to the json query if you

00:14:05,710 --> 00:14:08,890
don't then there's a special syntax in

00:14:07,630 --> 00:14:12,130
JSON to say this is a regular expression

00:14:08,890 --> 00:14:14,650
don't treat it like a plain string has

00:14:12,130 --> 00:14:16,840
the same performance characteristics as

00:14:14,650 --> 00:14:19,240
the like query in SQL so you don't want

00:14:16,840 --> 00:14:20,710
to have a nun anchored regular

00:14:19,240 --> 00:14:22,270
expression search because that's going

00:14:20,710 --> 00:14:23,890
to be really slow and require a scan of

00:14:22,270 --> 00:14:27,400
the collection even if you've got an

00:14:23,890 --> 00:14:31,330
index on it it can also search arrays

00:14:27,400 --> 00:14:32,950
and the way that that is again working

00:14:31,330 --> 00:14:39,900
is it's looking for any document that

00:14:32,950 --> 00:14:39,900
has business as one of its tags yes

00:14:50,279 --> 00:14:56,550
so the question is is there what what

00:14:54,209 --> 00:15:00,060
happens when you have two documents that

00:14:56,550 --> 00:15:02,009
have a different format and one of those

00:15:00,060 --> 00:15:03,899
formats has tags as a array and one of

00:15:02,009 --> 00:15:05,550
them has tags as a string and how does

00:15:03,899 --> 00:15:07,230
the index handle that and I believe what

00:15:05,550 --> 00:15:09,540
it's going to do is on a do it on a

00:15:07,230 --> 00:15:10,620
document by document for a case so you

00:15:09,540 --> 00:15:12,839
search for business and it's going to

00:15:10,620 --> 00:15:14,490
find if it's if it's a list or an array

00:15:12,839 --> 00:15:16,920
it's going to find where that is one of

00:15:14,490 --> 00:15:18,360
the elements and where it's simply a

00:15:16,920 --> 00:15:20,399
string it's going to find an exact match

00:15:18,360 --> 00:15:21,689
for that string because the way that

00:15:20,399 --> 00:15:24,059
this is actually working is is creating

00:15:21,689 --> 00:15:26,009
an entry in the index for every element

00:15:24,059 --> 00:15:28,199
of tags or for that field and so it's

00:15:26,009 --> 00:15:30,209
gonna use that index look it up and find

00:15:28,199 --> 00:15:31,529
that oh this document matches so it's

00:15:30,209 --> 00:15:37,529
going to send that out as a result of

00:15:31,529 --> 00:15:39,540
your query so inserting and updating to

00:15:37,529 --> 00:15:41,699
insert you can either pass a document

00:15:39,540 --> 00:15:43,439
directly or you can pass a list of

00:15:41,699 --> 00:15:45,149
documents which is often a lot more

00:15:43,439 --> 00:15:47,610
efficient the same way that you would do

00:15:45,149 --> 00:15:49,589
in SQL you can pass several rows at the

00:15:47,610 --> 00:15:53,249
same time and that's going to allow it

00:15:49,589 --> 00:15:54,750
to insert these in bulk or semi volcanic

00:15:53,249 --> 00:15:57,809
say there's there's a lot better ways to

00:15:54,750 --> 00:16:00,629
do true bulk loads of your data you can

00:15:57,809 --> 00:16:03,569
also do updates in place and this is one

00:16:00,629 --> 00:16:05,000
of the things that is nice about MongoDB

00:16:03,569 --> 00:16:09,540
and it's also one of the things that is

00:16:05,000 --> 00:16:11,759
not as nice so postgresql has this multi

00:16:09,540 --> 00:16:13,769
version concurrency control and that

00:16:11,759 --> 00:16:15,899
means that readers never block writers

00:16:13,769 --> 00:16:17,490
writers & R Block readers but what that

00:16:15,899 --> 00:16:19,319
ends up doing is it's creating multiple

00:16:17,490 --> 00:16:22,319
or every time you do a write your

00:16:19,319 --> 00:16:25,230
writing the whole the whole row and in

00:16:22,319 --> 00:16:27,269
this case MongoDB does in place updates

00:16:25,230 --> 00:16:29,009
so it's not actually creating a copy of

00:16:27,269 --> 00:16:30,269
the document when it rights to it it's

00:16:29,009 --> 00:16:34,019
modifying it right there on the desk

00:16:30,269 --> 00:16:35,370
where it is and this can be very high

00:16:34,019 --> 00:16:36,899
performance but it also means that

00:16:35,370 --> 00:16:38,579
there's some tricks that you need to do

00:16:36,899 --> 00:16:40,679
to keep your data safe and there's some

00:16:38,579 --> 00:16:42,540
concurrency implications as well I'm

00:16:40,679 --> 00:16:43,949
going to be tends to be pretty fast and

00:16:42,540 --> 00:16:46,980
able to handle most of the concurrency

00:16:43,949 --> 00:16:48,540
problems that you might run into by just

00:16:46,980 --> 00:16:51,089
kind of zooming through things but

00:16:48,540 --> 00:16:53,370
there's something to be aware of in this

00:16:51,089 --> 00:16:55,499
case what we're going to do is you can

00:16:53,370 --> 00:16:58,350
use the push operator and this is one of

00:16:55,499 --> 00:17:01,050
those places where with a special syntax

00:16:58,350 --> 00:17:02,819
of JSON is kind of coming to the

00:17:01,050 --> 00:17:04,010
forefront so this dollar sign whenever

00:17:02,819 --> 00:17:08,209
you see a dollar sign at the beginning

00:17:04,010 --> 00:17:09,800
of a field named in JSON that's telling

00:17:08,209 --> 00:17:12,530
you something as something special is

00:17:09,800 --> 00:17:14,030
happening in MongoDB so you want to look

00:17:12,530 --> 00:17:16,010
at the docs if you're not familiar with

00:17:14,030 --> 00:17:18,140
it in this case push means just add that

00:17:16,010 --> 00:17:25,990
item to the back of the Ray so it's

00:17:18,140 --> 00:17:25,990
going to append it to the array sorry

00:17:29,080 --> 00:17:33,830
okay so in this case what we're doing is

00:17:31,760 --> 00:17:35,930
we pass a query to the update and a

00:17:33,830 --> 00:17:38,000
modifier so the query sorry I should

00:17:35,930 --> 00:17:40,160
have mentioned that yeah we're looking

00:17:38,000 --> 00:17:41,240
for the name of Blake hotel and since we

00:17:40,160 --> 00:17:42,860
have an index on that that's going to be

00:17:41,240 --> 00:17:44,620
relatively fast now this is one thing

00:17:42,860 --> 00:17:46,670
that if you're more familiar with SQL

00:17:44,620 --> 00:17:48,590
MongoDB is a little bit surprising is

00:17:46,670 --> 00:17:51,140
that because they want these updates to

00:17:48,590 --> 00:17:53,330
be fast then the default is update the

00:17:51,140 --> 00:17:54,650
first record that matches so the hope is

00:17:53,330 --> 00:17:57,050
that most of the time you're going to be

00:17:54,650 --> 00:17:58,660
updating a single record if you wanted

00:17:57,050 --> 00:18:00,920
to update multiple records you can pass

00:17:58,660 --> 00:18:02,090
multi equals true or sometimes there's

00:18:00,920 --> 00:18:04,550
an options object depending on the

00:18:02,090 --> 00:18:06,530
driver and that will update every

00:18:04,550 --> 00:18:07,580
matching document but by default it's

00:18:06,530 --> 00:18:09,680
going to find the first one that matches

00:18:07,580 --> 00:18:17,810
your query just going to perform the

00:18:09,680 --> 00:18:20,780
update and return so we've created the

00:18:17,810 --> 00:18:23,980
content we found some nearby places and

00:18:20,780 --> 00:18:26,900
now we can start looking at our users so

00:18:23,980 --> 00:18:29,030
and also with the check-ins the check in

00:18:26,900 --> 00:18:33,320
operation so with users I'm just going

00:18:29,030 --> 00:18:35,750
to go ahead and create the user document

00:18:33,320 --> 00:18:38,570
and then what I'm going to have is just

00:18:35,750 --> 00:18:39,860
a reference to a collection ID so I'm

00:18:38,570 --> 00:18:41,450
just can have a sequence of check-ins

00:18:39,860 --> 00:18:43,400
and the reason for this is if I'm

00:18:41,450 --> 00:18:44,750
looking at my user ID like to see you

00:18:43,400 --> 00:18:46,700
know maybe the number of check-ins or

00:18:44,750 --> 00:18:48,260
something like that so being able to

00:18:46,700 --> 00:18:50,150
just what I'm updating my user record

00:18:48,260 --> 00:18:53,480
just push and you check in on there can

00:18:50,150 --> 00:18:56,840
be pretty efficient and then we'll also

00:18:53,480 --> 00:18:58,630
have a check ins collection and the

00:18:56,840 --> 00:19:00,470
check-in is going to be kind of the

00:18:58,630 --> 00:19:02,210
collection of record and then the

00:19:00,470 --> 00:19:03,710
check-ins on a user are just kind of a

00:19:02,210 --> 00:19:06,440
reference in there now I'd call it a

00:19:03,710 --> 00:19:09,140
reference but i also have talked about

00:19:06,440 --> 00:19:10,520
how there's no you know there's no

00:19:09,140 --> 00:19:12,020
enforcement of the schema so that

00:19:10,520 --> 00:19:14,480
includes referential integrity there's

00:19:12,020 --> 00:19:15,330
no like to MongoDB every document stands

00:19:14,480 --> 00:19:17,580
alone

00:19:15,330 --> 00:19:18,960
there are no operations except for

00:19:17,580 --> 00:19:21,390
MapReduce and we'll get to that but

00:19:18,960 --> 00:19:24,480
there is no operations that like even

00:19:21,390 --> 00:19:25,680
know about referential integrity so what

00:19:24,480 --> 00:19:28,410
we're saying is we're going to treat

00:19:25,680 --> 00:19:30,240
this as a foreign key but there's no

00:19:28,410 --> 00:19:35,100
database enforcement of that as a

00:19:30,240 --> 00:19:36,780
foreign key so the check-ins collection

00:19:35,100 --> 00:19:39,660
we're going to create a couple of

00:19:36,780 --> 00:19:41,610
indexes on it and one of these indexes

00:19:39,660 --> 00:19:43,230
is going to illustrate another aspect

00:19:41,610 --> 00:19:45,660
about MongoDB indexing and that is you

00:19:43,230 --> 00:19:47,850
can have compound indexes so one of the

00:19:45,660 --> 00:19:49,710
things that is maybe a little bit less

00:19:47,850 --> 00:19:52,770
mature about MongoDB then the relational

00:19:49,710 --> 00:19:54,510
databases is for a given query MongoDB

00:19:52,770 --> 00:19:55,860
is going to use exactly or up to one

00:19:54,510 --> 00:19:58,620
index I'll put it that way to satisfy

00:19:55,860 --> 00:19:59,850
the query now since it's restricting the

00:19:58,620 --> 00:20:01,920
queries to only be on a single

00:19:59,850 --> 00:20:05,130
collection that maybe one indexes enough

00:20:01,920 --> 00:20:06,780
but really one of the things that you

00:20:05,130 --> 00:20:08,640
want to do when you're designing your

00:20:06,780 --> 00:20:10,110
application is look at the kinds of

00:20:08,640 --> 00:20:11,430
queries you're doing and if you're doing

00:20:10,110 --> 00:20:13,200
a lot of queries that are based on place

00:20:11,430 --> 00:20:14,550
and time stamp you might want to have

00:20:13,200 --> 00:20:16,260
that because that's more selective than

00:20:14,550 --> 00:20:18,960
a query just based on place or just

00:20:16,260 --> 00:20:20,190
based on time stamp and so that's what

00:20:18,960 --> 00:20:21,600
we've done here is we've created one

00:20:20,190 --> 00:20:24,690
that's a compound between place and time

00:20:21,600 --> 00:20:27,750
stamp one that's time stamp alone so

00:20:24,690 --> 00:20:31,200
here we've got and that probably should

00:20:27,750 --> 00:20:34,380
be placed ID so yeah sorry apologize for

00:20:31,200 --> 00:20:36,990
the slide there so here we've embedded

00:20:34,380 --> 00:20:40,230
the place as a sub document embedded the

00:20:36,990 --> 00:20:43,160
user as a sub document and the timestamp

00:20:40,230 --> 00:20:43,160
is just a date time

00:20:44,840 --> 00:20:50,480
ah yeah so the question is one of the

00:20:48,049 --> 00:20:53,059
numbers on the slide its place called

00:20:50,480 --> 00:20:56,150
1ts colon 1 and that's a sending or

00:20:53,059 --> 00:20:59,809
descending well one is an A sending and

00:20:56,150 --> 00:21:01,850
negative 1 would be descending so all of

00:20:59,809 --> 00:21:04,100
 db's indexes besides the

00:21:01,850 --> 00:21:07,370
geospatial RB tree indexes so it's

00:21:04,100 --> 00:21:09,620
basically just assorted think of it as a

00:21:07,370 --> 00:21:11,000
sorted list of values that appear in

00:21:09,620 --> 00:21:13,909
documents with a reference to that

00:21:11,000 --> 00:21:15,620
documents location and really the order

00:21:13,909 --> 00:21:17,240
doesn't come into play until you start

00:21:15,620 --> 00:21:19,580
doing range queries where you want

00:21:17,240 --> 00:21:21,020
something between two ranges or where

00:21:19,580 --> 00:21:23,210
you're trying to use an index to assist

00:21:21,020 --> 00:21:25,130
your sorting and then the the order can

00:21:23,210 --> 00:21:29,779
become important if you're doing say a

00:21:25,130 --> 00:21:31,730
short on two fields so I mentioned the

00:21:29,779 --> 00:21:33,440
updates and here's just a this is a

00:21:31,730 --> 00:21:35,570
complete list as of today of all of the

00:21:33,440 --> 00:21:39,679
at least according to the docks of all

00:21:35,570 --> 00:21:41,840
the updates on mongodb and so i'll just

00:21:39,679 --> 00:21:43,970
briefly run through these so set allows

00:21:41,840 --> 00:21:46,940
you to go in and modify document by

00:21:43,970 --> 00:21:48,710
setting a field unset lets you pull that

00:21:46,940 --> 00:21:50,059
document out on out and it is not

00:21:48,710 --> 00:21:52,730
present in the document once you're done

00:21:50,059 --> 00:21:54,559
you can rename fields atomically you can

00:21:52,730 --> 00:21:56,390
push on to the end of an array you can

00:21:54,559 --> 00:22:00,140
push a number of documents onto the end

00:21:56,390 --> 00:22:03,770
of an array you can pop off one document

00:22:00,140 --> 00:22:06,470
you can also pull off documents based on

00:22:03,770 --> 00:22:09,230
a query so you could actually come in

00:22:06,470 --> 00:22:11,570
and say give me all of the again back to

00:22:09,230 --> 00:22:13,100
the blog comments you can say give pop

00:22:11,570 --> 00:22:14,450
off all of the or pull all of the

00:22:13,100 --> 00:22:16,370
comments that were by this user because

00:22:14,450 --> 00:22:17,870
I know he's a spammer and it you just

00:22:16,370 --> 00:22:20,270
give it a query to check all the

00:22:17,870 --> 00:22:22,490
comments on this on this document you

00:22:20,270 --> 00:22:24,049
can also do pull all which would you

00:22:22,490 --> 00:22:27,230
know pull a number of different

00:22:24,049 --> 00:22:29,630
documents out with different different

00:22:27,230 --> 00:22:31,610
parameters and you can it's got set

00:22:29,630 --> 00:22:33,559
support so if you need to enforce

00:22:31,610 --> 00:22:35,330
uniqueness on your array you can do that

00:22:33,559 --> 00:22:36,830
and then there's also increment which

00:22:35,330 --> 00:22:38,840
will increment by a positive or negative

00:22:36,830 --> 00:22:40,880
values it's not just by one so you can

00:22:38,840 --> 00:22:42,770
use this as a counter for real-time

00:22:40,880 --> 00:22:47,210
analytics things like that and then

00:22:42,770 --> 00:22:49,520
bitwise operations are also supported so

00:22:47,210 --> 00:22:50,870
back to our operations again now we've

00:22:49,520 --> 00:22:52,909
talked about finding nearby places

00:22:50,870 --> 00:22:56,600
user-generated content recording our

00:22:52,909 --> 00:22:58,370
check-ins and also we wanted to do some

00:22:56,600 --> 00:23:00,980
simple statistics

00:22:58,370 --> 00:23:02,660
and this is going to show another aspect

00:23:00,980 --> 00:23:04,220
of Mugabe's query language and that is

00:23:02,660 --> 00:23:06,140
if you want to reach inside an object

00:23:04,220 --> 00:23:07,190
you can so in this case we're gonna see

00:23:06,140 --> 00:23:09,770
what I should have showed on my previous

00:23:07,190 --> 00:23:12,290
slide we're gonna find a place by names

00:23:09,770 --> 00:23:15,170
we say find place Nate find where place

00:23:12,290 --> 00:23:16,580
name is the Blake hotel and this will

00:23:15,170 --> 00:23:19,010
work as long as you've got an index on

00:23:16,580 --> 00:23:20,420
place name so you can reach into your

00:23:19,010 --> 00:23:24,860
objects if you've got a raise then it

00:23:20,420 --> 00:23:26,210
reaches into those arrays as well so

00:23:24,860 --> 00:23:28,730
they'll find all the check-ins we can

00:23:26,210 --> 00:23:31,280
also find the last 10 check-ins because

00:23:28,730 --> 00:23:33,890
you can pass a sort onto it and then

00:23:31,280 --> 00:23:35,800
limit that output and what the way that

00:23:33,890 --> 00:23:38,510
this is going to use the indexes now is

00:23:35,800 --> 00:23:40,700
we created an index that was on the

00:23:38,510 --> 00:23:42,740
place name and the timestamp in that

00:23:40,700 --> 00:23:43,940
order so the way that MongoDB is

00:23:42,740 --> 00:23:45,710
actually doing this is this going to

00:23:43,940 --> 00:23:47,270
scan and it's going to find where it

00:23:45,710 --> 00:23:48,980
starts matching place name and then

00:23:47,270 --> 00:23:51,350
since that index is ordered by timestamp

00:23:48,980 --> 00:23:52,760
it can just read off the first 10

00:23:51,350 --> 00:23:55,940
records on the index and return those

00:23:52,760 --> 00:24:00,830
documents and then we can also find

00:23:55,940 --> 00:24:02,900
check-ins today so find everything where

00:24:00,830 --> 00:24:06,500
the timestamp is greater than midnight

00:24:02,900 --> 00:24:07,850
this morning and then you can find and

00:24:06,500 --> 00:24:10,250
then you can do account so that's just a

00:24:07,850 --> 00:24:11,480
very simple way to do that and that's

00:24:10,250 --> 00:24:13,280
also illustrating another way that you

00:24:11,480 --> 00:24:15,200
can do queries and mongodb where it's

00:24:13,280 --> 00:24:17,059
saying great GT dollar GT means greater

00:24:15,200 --> 00:24:22,580
than this value and you can combine

00:24:17,059 --> 00:24:26,720
those in the query language as well so I

00:24:22,580 --> 00:24:28,730
promised MapReduce and here it is so in

00:24:26,720 --> 00:24:31,580
MongoDB it's got a JavaScript heritage

00:24:28,730 --> 00:24:33,070
as a database so all of the anything

00:24:31,580 --> 00:24:35,030
that's going to execute on server-side

00:24:33,070 --> 00:24:38,420
server-side code is going to end up

00:24:35,030 --> 00:24:39,740
being a JavaScript function so what we

00:24:38,420 --> 00:24:42,410
do with MapReduce first of all let me

00:24:39,740 --> 00:24:43,700
just take a pause right now who is for

00:24:42,410 --> 00:24:46,280
me with the MapReduce algorithm and what

00:24:43,700 --> 00:24:47,809
it does and who is maybe heard the name

00:24:46,280 --> 00:24:50,780
but doesn't know really what's going on

00:24:47,809 --> 00:24:52,910
ok cool so I will give a little bit of

00:24:50,780 --> 00:24:56,150
background so what MapReduce does is it

00:24:52,910 --> 00:24:58,280
it's a way to process a lot of data in

00:24:56,150 --> 00:25:00,250
parallel and the way that they do this

00:24:58,280 --> 00:25:03,440
is there's a something that Google

00:25:00,250 --> 00:25:05,270
documented in the MapReduce paper is you

00:25:03,440 --> 00:25:09,550
have one function that is run on your

00:25:05,270 --> 00:25:12,050
input and that function will generate

00:25:09,550 --> 00:25:14,210
this the input for the next

00:25:12,050 --> 00:25:16,520
which is called a reduced stage but so

00:25:14,210 --> 00:25:19,250
for every document in MongoDB it's going

00:25:16,520 --> 00:25:21,020
to run this map function and that map

00:25:19,250 --> 00:25:22,310
function can choose what the output is

00:25:21,020 --> 00:25:24,260
to the next stage so in this case we're

00:25:22,310 --> 00:25:25,850
just going to emit a new document which

00:25:24,260 --> 00:25:28,130
got a key of the place name and the

00:25:25,850 --> 00:25:31,490
value of one so this is a way that we

00:25:28,130 --> 00:25:33,560
can do counting and then once it's done

00:25:31,490 --> 00:25:35,690
the map function then there's this phase

00:25:33,560 --> 00:25:38,420
where it shuffles everything up and it

00:25:35,690 --> 00:25:40,280
groups them by key so no matter how your

00:25:38,420 --> 00:25:41,900
map function emitted things what order

00:25:40,280 --> 00:25:43,100
it emitted the keys end there's going to

00:25:41,900 --> 00:25:44,930
be the space where it groups everything

00:25:43,100 --> 00:25:46,010
everything with the same key now is in

00:25:44,930 --> 00:25:47,620
one group and then it's going to call

00:25:46,010 --> 00:25:49,730
the reduce function on that group and

00:25:47,620 --> 00:25:52,760
that's what this reduce function is here

00:25:49,730 --> 00:25:54,440
says for a given key these are all of

00:25:52,760 --> 00:25:56,540
the values and so what you're going to

00:25:54,440 --> 00:26:00,110
end up with is all of the check-ins for

00:25:56,540 --> 00:26:01,700
it's going to be called once for the you

00:26:00,110 --> 00:26:04,100
know the Blake hotel and a whole bunch

00:26:01,700 --> 00:26:05,300
of ones and then what we're going to do

00:26:04,100 --> 00:26:06,890
is we're just going to some those ones

00:26:05,300 --> 00:26:08,270
and this this array dot some is just

00:26:06,890 --> 00:26:12,860
something that MongoDB throws into the

00:26:08,270 --> 00:26:14,570
array class in in JavaScript and then

00:26:12,860 --> 00:26:16,190
once this is done this is the output of

00:26:14,570 --> 00:26:17,660
your map reduce function so it's a way

00:26:16,190 --> 00:26:20,600
that you can so this is one way that you

00:26:17,660 --> 00:26:22,790
can do a big group by in a somewhat

00:26:20,600 --> 00:26:25,970
efficient manner in a very

00:26:22,790 --> 00:26:27,950
parallelizable manner so in an ideal

00:26:25,970 --> 00:26:30,980
world MongoDB would use that parallel

00:26:27,950 --> 00:26:33,770
ISM in the real world there's a global

00:26:30,980 --> 00:26:36,350
JavaScript interpreter lock so you're

00:26:33,770 --> 00:26:37,970
going to be limited on your parallel ISM

00:26:36,350 --> 00:26:39,470
to a per server parallelism you can get

00:26:37,970 --> 00:26:40,850
around that some with sharding and we

00:26:39,470 --> 00:26:45,050
will talk a little bit about sharding

00:26:40,850 --> 00:26:47,000
but that's one of the downsides they're

00:26:45,050 --> 00:26:49,220
looking at trying to eliminate that log

00:26:47,000 --> 00:26:51,110
by going to the v8 engine right now it's

00:26:49,220 --> 00:26:53,870
on spider monkey so we'll see what

00:26:51,110 --> 00:26:55,190
happens there so to actually call this

00:26:53,870 --> 00:26:56,780
MapReduce now you just define these

00:26:55,190 --> 00:26:58,190
functions in JavaScript if you're using

00:26:56,780 --> 00:27:01,220
another language driver you can quote

00:26:58,190 --> 00:27:02,630
them and just send a string in so you

00:27:01,220 --> 00:27:04,430
call MapReduce you pass it the map

00:27:02,630 --> 00:27:05,870
function the reduce function you can

00:27:04,430 --> 00:27:07,280
also have an initial query which will

00:27:05,870 --> 00:27:09,170
reduce the amount of data that the map

00:27:07,280 --> 00:27:11,390
function has to touch and this is

00:27:09,170 --> 00:27:12,290
usually a very good idea because

00:27:11,390 --> 00:27:13,400
otherwise you're going to be scanning

00:27:12,290 --> 00:27:15,770
the whole collection when you run your

00:27:13,400 --> 00:27:16,970
MapReduce in this case I just assume

00:27:15,770 --> 00:27:19,640
that there's some now minus three hours

00:27:16,970 --> 00:27:21,410
variable that I've defined and so I'm

00:27:19,640 --> 00:27:23,180
only going to say give me all of the

00:27:21,410 --> 00:27:25,280
recent check-ins say in the last three

00:27:23,180 --> 00:27:25,890
hours and then you can also specify how

00:27:25,280 --> 00:27:29,250
you want your

00:27:25,890 --> 00:27:30,990
output to appear in this case I'm just

00:27:29,250 --> 00:27:34,890
saying give it to me in line which means

00:27:30,990 --> 00:27:36,570
return it in the re s variable you can

00:27:34,890 --> 00:27:38,220
also tell it to stick the results in a

00:27:36,570 --> 00:27:39,510
collection so you can have your results

00:27:38,220 --> 00:27:41,700
get dumped out to a collection you can

00:27:39,510 --> 00:27:44,430
have them either create a new collection

00:27:41,700 --> 00:27:46,860
or insert it into a collection / writing

00:27:44,430 --> 00:27:48,450
old data or you can even have it reduce

00:27:46,860 --> 00:27:49,890
it into a collection which is useful for

00:27:48,450 --> 00:27:53,130
doing some kind some kinds of

00:27:49,890 --> 00:27:54,900
aggregation operations because what it

00:27:53,130 --> 00:27:56,310
does is basically it runs the map

00:27:54,900 --> 00:27:57,660
produced until it's got its final result

00:27:56,310 --> 00:27:58,830
and then it looks to see is there a

00:27:57,660 --> 00:28:00,900
value that matches this other than I'll

00:27:58,830 --> 00:28:03,150
reduce one more time and so if your

00:28:00,900 --> 00:28:04,680
reduces something like a sum then it's a

00:28:03,150 --> 00:28:07,800
way to keep a running average or running

00:28:04,680 --> 00:28:10,890
count on your server so in this case you

00:28:07,800 --> 00:28:12,930
get some statistical data about the

00:28:10,890 --> 00:28:15,660
MapReduce but you also get this results

00:28:12,930 --> 00:28:18,570
sub document so you grab off the results

00:28:15,660 --> 00:28:21,240
and it comes out with the ID is whatever

00:28:18,570 --> 00:28:23,040
this key was and then the value is 17

00:28:21,240 --> 00:28:25,170
just assuming there were 17 seconds of

00:28:23,040 --> 00:28:34,350
the blake in the last three hours which

00:28:25,170 --> 00:28:36,060
is maybe optimistic so yes this ID here

00:28:34,350 --> 00:28:39,120
though of the blake hotel so when we ran

00:28:36,060 --> 00:28:41,220
the map function the emit function that

00:28:39,120 --> 00:28:43,740
map calls is actually emitting a key

00:28:41,220 --> 00:28:46,350
which is going to be ID and i probably

00:28:43,740 --> 00:28:48,510
should have mentioned that MongoDB uses

00:28:46,350 --> 00:28:52,350
underscore ID as the primary key of all

00:28:48,510 --> 00:28:54,750
of its collections and that ID can be

00:28:52,350 --> 00:28:57,390
it's it's usually an object ID this good

00:28:54,750 --> 00:28:59,370
type thing but it can be anything I

00:28:57,390 --> 00:29:00,810
don't think it likes a raise but that's

00:28:59,370 --> 00:29:04,740
the only thing that you can't put in

00:29:00,810 --> 00:29:06,780
there so you're emitting this key which

00:29:04,740 --> 00:29:09,090
is like ID and a value and then this

00:29:06,780 --> 00:29:10,440
gets its grouped by key which again is

00:29:09,090 --> 00:29:12,600
going to be the name of the hotel and

00:29:10,440 --> 00:29:15,450
then the results are all going to have

00:29:12,600 --> 00:29:20,130
the key as the ID and then the value is

00:29:15,450 --> 00:29:25,530
17 you're welcome so deployment and

00:29:20,130 --> 00:29:32,490
scaling options so back when I started

00:29:25,530 --> 00:29:36,270
using MongoDB the tensions take on data

00:29:32,490 --> 00:29:38,620
safety is there are some situations

00:29:36,270 --> 00:29:40,420
where if your server crashes

00:29:38,620 --> 00:29:43,090
that if you're using something like

00:29:40,420 --> 00:29:45,280
postgresql or MySQL then you can come

00:29:43,090 --> 00:29:47,020
back up safely but there's a lot of

00:29:45,280 --> 00:29:49,870
server crash situations where it doesn't

00:29:47,020 --> 00:29:51,580
matter whether the database is logically

00:29:49,870 --> 00:29:53,950
correct you're not going to recover from

00:29:51,580 --> 00:29:56,140
it say a lightning strike a disk failure

00:29:53,950 --> 00:29:58,030
there's nothing that can know right

00:29:56,140 --> 00:29:59,800
ahead log can protect you from a full

00:29:58,030 --> 00:30:02,290
disk failure you know because the right

00:29:59,800 --> 00:30:03,700
ahead logs gone too so their take on it

00:30:02,290 --> 00:30:06,400
was if you really want safety you have

00:30:03,700 --> 00:30:07,750
to use replication and so we're not

00:30:06,400 --> 00:30:09,480
going to worry about single server

00:30:07,750 --> 00:30:12,070
durability that was their take on it so

00:30:09,480 --> 00:30:14,080
if MongoDB crashed if you had a power

00:30:12,070 --> 00:30:15,370
failure then you had a good chance of

00:30:14,080 --> 00:30:17,260
having data corruption and you wouldn't

00:30:15,370 --> 00:30:21,130
be able to recover your database so

00:30:17,260 --> 00:30:22,540
always replicate now since this version

00:30:21,130 --> 00:30:23,980
18 they've had this right ahead log

00:30:22,540 --> 00:30:25,540
they've had single server durability not

00:30:23,980 --> 00:30:27,490
because necessarily they believe that

00:30:25,540 --> 00:30:29,290
it's that valuable but because the

00:30:27,490 --> 00:30:32,110
customers asked for it so it is there

00:30:29,290 --> 00:30:33,700
now and there at version 2 1 now about

00:30:32,110 --> 00:30:37,030
to have 22 so it's been there for a

00:30:33,700 --> 00:30:38,410
while but still there's this replication

00:30:37,030 --> 00:30:41,410
story which has been baked into MongoDB

00:30:38,410 --> 00:30:42,670
from the start and the way that you

00:30:41,410 --> 00:30:45,309
would do this if you've got say a

00:30:42,670 --> 00:30:48,550
smaller website or smaller application

00:30:45,309 --> 00:30:51,370
that is talking to MongoDB is it's got

00:30:48,550 --> 00:30:55,210
this this notion of a replica set so you

00:30:51,370 --> 00:30:56,620
set up multiple mugabe servers and one

00:30:55,210 --> 00:30:58,000
of them is configured as the primary all

00:30:56,620 --> 00:31:00,340
of your rights go to the primary and

00:30:58,000 --> 00:31:03,240
this is so like master slave replication

00:31:00,340 --> 00:31:05,350
and then all the secondaries are using a

00:31:03,240 --> 00:31:07,059
replication log to replicate from that

00:31:05,350 --> 00:31:08,590
primary you can read from the

00:31:07,059 --> 00:31:11,770
secondaries if you want that's a

00:31:08,590 --> 00:31:13,660
application configurable as to whether

00:31:11,770 --> 00:31:15,190
you allow reads to go to the secondary

00:31:13,660 --> 00:31:16,330
if you allow reads to go the secondary

00:31:15,190 --> 00:31:17,950
you may be looking at out of date data

00:31:16,330 --> 00:31:20,320
that's something you've got to decide

00:31:17,950 --> 00:31:21,940
whether you're okay with and you can do

00:31:20,320 --> 00:31:25,420
that at connection or the with a query

00:31:21,940 --> 00:31:26,440
level so that's this is kind of the base

00:31:25,420 --> 00:31:28,500
deployment you shouldn't run in

00:31:26,440 --> 00:31:31,090
production with anything less than this

00:31:28,500 --> 00:31:33,190
you can have any of the shared hosting

00:31:31,090 --> 00:31:34,179
MongoDB providers provide this out of

00:31:33,190 --> 00:31:37,690
the box there's always going to be

00:31:34,179 --> 00:31:39,010
replication something that I've alluded

00:31:37,690 --> 00:31:41,260
to but have not really talked about a

00:31:39,010 --> 00:31:44,800
lot is the sharding support in MongoDB

00:31:41,260 --> 00:31:46,750
so one of the things that mowing to be

00:31:44,800 --> 00:31:48,670
does not support is any kind of multi

00:31:46,750 --> 00:31:50,320
document or multi collection operation

00:31:48,670 --> 00:31:53,230
you know outside of MapReduce

00:31:50,320 --> 00:31:55,419
and one of the things if you've ever

00:31:53,230 --> 00:31:56,769
tried to shard a database it's really

00:31:55,419 --> 00:31:58,360
hard is to make sure that you figure out

00:31:56,769 --> 00:32:02,049
where the data all goes because you've

00:31:58,360 --> 00:32:04,750
got joins in a sequel application well

00:32:02,049 --> 00:32:07,090
mom maybe says well sharding is hard so

00:32:04,750 --> 00:32:08,350
we're just not going to allow joins and

00:32:07,090 --> 00:32:13,210
we want everything to be easily sharable

00:32:08,350 --> 00:32:14,950
so what you do is your collection you

00:32:13,210 --> 00:32:16,690
tell mommy be first of all that you want

00:32:14,950 --> 00:32:18,279
your collection sharted and you tell it

00:32:16,690 --> 00:32:20,679
what the key is to shard it on so what

00:32:18,279 --> 00:32:24,009
is the partition key you might want to

00:32:20,679 --> 00:32:25,960
use you there's different reasons to

00:32:24,009 --> 00:32:27,039
choose different keys ideally you want

00:32:25,960 --> 00:32:29,440
something that's going to balance your

00:32:27,039 --> 00:32:30,549
rights across that key space and it's

00:32:29,440 --> 00:32:31,990
going to allow your reads to be

00:32:30,549 --> 00:32:34,330
identified so that the reeds can always

00:32:31,990 --> 00:32:35,350
tell what char they're going to the nice

00:32:34,330 --> 00:32:36,580
thing about mom going to be is that it

00:32:35,350 --> 00:32:38,320
will automatically once you tell it what

00:32:36,580 --> 00:32:39,820
the key is it's going to look at usage

00:32:38,320 --> 00:32:41,710
patterns and it's going to find oh well

00:32:39,820 --> 00:32:43,240
this is a this is a hot range of this

00:32:41,710 --> 00:32:44,529
key that's getting queried a lot so I'm

00:32:43,240 --> 00:32:47,830
going to go and split that and migrate

00:32:44,529 --> 00:32:49,960
off half of it to another server and it

00:32:47,830 --> 00:32:51,429
does this kind of behind the scenes you

00:32:49,960 --> 00:32:53,259
can't affect it and you can do some

00:32:51,429 --> 00:32:55,570
manual things to tell it to migrate a

00:32:53,259 --> 00:32:58,389
short to migrate a chunk of a shard or a

00:32:55,570 --> 00:33:00,190
chunk to a different shard rather but by

00:32:58,389 --> 00:33:03,789
default it's kind of automatic now

00:33:00,190 --> 00:33:06,970
sharding and mongodb is a layer on top

00:33:03,789 --> 00:33:09,940
of replication so if you've looked at

00:33:06,970 --> 00:33:12,789
like the MySQL clustering that is

00:33:09,940 --> 00:33:15,100
charting and replication are into our

00:33:12,789 --> 00:33:18,820
tightly integrated so it kind of manages

00:33:15,100 --> 00:33:20,559
that all together in this case each one

00:33:18,820 --> 00:33:22,389
of your shards is itself a replica set

00:33:20,559 --> 00:33:24,190
and it stands alone as a DB server

00:33:22,389 --> 00:33:25,659
so you could just send queries to a

00:33:24,190 --> 00:33:29,230
single shard what you're only going to

00:33:25,659 --> 00:33:30,700
see a third of your data in this case by

00:33:29,230 --> 00:33:32,799
default you would send your queries to a

00:33:30,700 --> 00:33:35,320
routing server called s which is a

00:33:32,799 --> 00:33:38,110
pretty lightweight server that is able

00:33:35,320 --> 00:33:41,320
to send the queries to the right servers

00:33:38,110 --> 00:33:43,179
merge the results as appropriate and so

00:33:41,320 --> 00:33:44,440
I've mentioned so you got these three

00:33:43,179 --> 00:33:45,610
replica sites and then there's a fourth

00:33:44,440 --> 00:33:47,860
replica set and this doesn't have to

00:33:45,610 --> 00:33:50,110
necessarily be on separate hardware but

00:33:47,860 --> 00:33:52,809
it's three little databases or it's

00:33:50,110 --> 00:33:54,190
three little servers and these are

00:33:52,809 --> 00:33:57,850
storing your configuration data this is

00:33:54,190 --> 00:34:00,639
telling MongoDB where all the data lives

00:33:57,850 --> 00:34:02,080
you know what shard does this particular

00:34:00,639 --> 00:34:03,940
key live on

00:34:02,080 --> 00:34:06,130
and this is something that's read by the

00:34:03,940 --> 00:34:08,260
 s server at startup and it's red

00:34:06,130 --> 00:34:10,510
when it gets updated but other than that

00:34:08,260 --> 00:34:11,619
it's all cash in memory now the config

00:34:10,510 --> 00:34:13,570
servers are very important because if

00:34:11,619 --> 00:34:15,820
the config servers go down you can't

00:34:13,570 --> 00:34:18,639
migrate data anymore your data is kind

00:34:15,820 --> 00:34:20,589
of stuck where it is and so that's why

00:34:18,639 --> 00:34:22,389
they require you to have three servers

00:34:20,589 --> 00:34:24,010
there there's not like even an option

00:34:22,389 --> 00:34:25,179
saying you know I want to play fast and

00:34:24,010 --> 00:34:27,159
loose I'm just going to use one master

00:34:25,179 --> 00:34:30,190
there you have to have three servers and

00:34:27,159 --> 00:34:32,379
if the config servers do go down your

00:34:30,190 --> 00:34:34,510
short your cluster is still up it's just

00:34:32,379 --> 00:34:36,399
that data is not going to move because

00:34:34,510 --> 00:34:38,919
it can't safely migrated any of the

00:34:36,399 --> 00:34:40,210
chunks so whatever partitioning you're

00:34:38,919 --> 00:34:46,300
stuck with you're stuck with at that

00:34:40,210 --> 00:34:48,369
point so now as I said that I wouldn't

00:34:46,300 --> 00:34:51,159
talk about why MongoDB but I will talk

00:34:48,369 --> 00:34:55,270
about some places where it might be an

00:34:51,159 --> 00:34:56,470
acceptable case to use MongoDB one is if

00:34:55,270 --> 00:34:57,760
you've got a very high traffic web

00:34:56,470 --> 00:35:01,859
application and this is the whole web

00:34:57,760 --> 00:35:05,619
scale thing you know if your if your

00:35:01,859 --> 00:35:07,990
database is having some trouble keeping

00:35:05,619 --> 00:35:10,210
up with the load then I'm going to be

00:35:07,990 --> 00:35:12,580
can sometimes help with that and this

00:35:10,210 --> 00:35:14,050
really depends a lot on your the way

00:35:12,580 --> 00:35:16,420
that you've models your data can you

00:35:14,050 --> 00:35:19,089
model your data as documents that don't

00:35:16,420 --> 00:35:22,300
have these rich join relationships with

00:35:19,089 --> 00:35:25,480
other documents CMS style applications

00:35:22,300 --> 00:35:27,250
are usually a pretty good match and this

00:35:25,480 --> 00:35:31,330
is nice because or one of the reasons

00:35:27,250 --> 00:35:32,770
for this is that you have you have these

00:35:31,330 --> 00:35:34,540
very rich document types and so when

00:35:32,770 --> 00:35:36,280
you're displaying say user profile or a

00:35:34,540 --> 00:35:37,900
news item or something like that it's

00:35:36,280 --> 00:35:39,070
nice if you only have to fetch a single

00:35:37,900 --> 00:35:40,660
document and you don't have to join

00:35:39,070 --> 00:35:43,510
across multiple tables because every

00:35:40,660 --> 00:35:45,460
join is eventually could be a database

00:35:43,510 --> 00:35:48,339
or it could be a disk seek which is

00:35:45,460 --> 00:35:52,839
really time consuming social and mobile

00:35:48,339 --> 00:35:54,849
are sorry that was socially mobile CMS

00:35:52,839 --> 00:35:56,560
it's nice it does mugabe does have

00:35:54,849 --> 00:35:58,510
support for actually a file system so

00:35:56,560 --> 00:35:59,980
the previous speaker said don't put your

00:35:58,510 --> 00:36:01,060
file system in the database and mangu be

00:35:59,980 --> 00:36:04,510
says here's a file system for the

00:36:01,060 --> 00:36:05,800
database so it's really up to your

00:36:04,510 --> 00:36:09,220
particular use case whether that's a

00:36:05,800 --> 00:36:12,900
good idea the reason that we've used it

00:36:09,220 --> 00:36:15,390
we've used a summon sourceforge so

00:36:12,900 --> 00:36:16,740
we don't use it for storing the giant

00:36:15,390 --> 00:36:18,720
downloadable files like if you're

00:36:16,740 --> 00:36:20,640
downloading VLC or azureus or whatever

00:36:18,720 --> 00:36:22,800
from sourceforge that's not being served

00:36:20,640 --> 00:36:27,810
up from MongoDB but for things like

00:36:22,800 --> 00:36:29,160
attachments on tickets or logos on

00:36:27,810 --> 00:36:30,390
projects things like that we're still

00:36:29,160 --> 00:36:32,910
were shoving that in MongoDB and it's

00:36:30,390 --> 00:36:35,670
fairly fairly good at doing that kind of

00:36:32,910 --> 00:36:37,170
a thing and the benefit to using that

00:36:35,670 --> 00:36:39,410
instead of a file system of courses if

00:36:37,170 --> 00:36:42,240
you've got a single database server and

00:36:39,410 --> 00:36:44,610
eight application servers you don't have

00:36:42,240 --> 00:36:45,930
to run in FS that's that's the big

00:36:44,610 --> 00:36:47,250
benefit to me is you don't have to

00:36:45,930 --> 00:36:48,510
figure out how to share your file system

00:36:47,250 --> 00:36:50,880
you've already figured out how to share

00:36:48,510 --> 00:36:52,260
a database so use the database if it

00:36:50,880 --> 00:36:56,690
becomes a problem than just need to move

00:36:52,260 --> 00:36:56,690
it to a better solution the question

00:37:04,190 --> 00:37:10,440
yeah so the question is in relational

00:37:08,250 --> 00:37:12,240
databases you have the query plans that

00:37:10,440 --> 00:37:14,100
you can look at you can explain your

00:37:12,240 --> 00:37:16,020
queries is there something similar to

00:37:14,100 --> 00:37:18,330
that in mugabe and there is so on any

00:37:16,020 --> 00:37:20,280
query once you've constructed the query

00:37:18,330 --> 00:37:21,810
you can add a dot explain to it and it

00:37:20,280 --> 00:37:23,820
gives you back a document that it says

00:37:21,810 --> 00:37:25,140
you know what index is it using what are

00:37:23,820 --> 00:37:26,970
the different plant what are the indexes

00:37:25,140 --> 00:37:29,040
that are considered using it'll tell you

00:37:26,970 --> 00:37:31,500
how many index entries have had to scan

00:37:29,040 --> 00:37:32,700
how many documents that had to scan to

00:37:31,500 --> 00:37:34,500
actually retrieve the data and look

00:37:32,700 --> 00:37:36,570
through the document and then how many

00:37:34,500 --> 00:37:38,580
results are returned so in an ideal

00:37:36,570 --> 00:37:40,800
world those three numbers are the same

00:37:38,580 --> 00:37:42,960
right it has two skin that num you know

00:37:40,800 --> 00:37:44,760
in documents in the index in documents

00:37:42,960 --> 00:37:47,510
off of the disk and in documents were

00:37:44,760 --> 00:37:49,800
returned Mugabe also has support for

00:37:47,510 --> 00:37:51,060
index only queries which is where you're

00:37:49,800 --> 00:37:52,290
doing a query but the only thing that

00:37:51,060 --> 00:37:54,090
you're really interested in is something

00:37:52,290 --> 00:37:55,140
that you're actually indexing on and in

00:37:54,090 --> 00:37:57,090
that case it doesn't even have to hit

00:37:55,140 --> 00:37:58,410
the data where they document is stored

00:37:57,090 --> 00:38:00,330
so there's some cases where you can skip

00:37:58,410 --> 00:38:03,210
where you can return return more

00:38:00,330 --> 00:38:04,530
documents than you look at if you're

00:38:03,210 --> 00:38:06,180
only looking at things from the index

00:38:04,530 --> 00:38:08,660
but yeah there is the explained syntax

00:38:06,180 --> 00:38:08,660
is there

00:38:10,930 --> 00:38:14,840
yeah the question was are there drive

00:38:13,490 --> 00:38:16,910
what about drivers are their database

00:38:14,840 --> 00:38:19,550
drivers and there are so manga doobies

00:38:16,910 --> 00:38:22,660
protocol is a binary protocol it's not

00:38:19,550 --> 00:38:28,310
like CouchDB where it's just rest and

00:38:22,660 --> 00:38:32,530
there are drivers I know for C or it's a

00:38:28,310 --> 00:38:36,710
C++ driver actually java.net Python Ruby

00:38:32,530 --> 00:38:39,530
node go any other languages tell you

00:38:36,710 --> 00:38:44,210
whether out there I know of one are I

00:38:39,530 --> 00:38:47,119
don't know about are actually pearl yeah

00:38:44,210 --> 00:38:49,130
there are pearl so there's a there's a

00:38:47,119 --> 00:38:50,690
page on the mugabe side that tells you

00:38:49,130 --> 00:38:52,520
all the drivers and most of them are

00:38:50,690 --> 00:38:55,400
maintained by tengen which is the

00:38:52,520 --> 00:38:59,869
company behind MongoDB some of them are

00:38:55,400 --> 00:39:01,880
community maintained one of the other

00:38:59,869 --> 00:39:03,470
things that is good to use MongoDB for

00:39:01,880 --> 00:39:05,090
is this real-time analytics so because

00:39:03,470 --> 00:39:07,790
they've got these in place increment

00:39:05,090 --> 00:39:09,740
operators an update that's just

00:39:07,790 --> 00:39:11,150
incrementing a field is very very fast

00:39:09,740 --> 00:39:12,980
because all that it's needing to do is

00:39:11,150 --> 00:39:15,950
rewrite that single integer it's not

00:39:12,980 --> 00:39:18,619
having to worry about you know writing a

00:39:15,950 --> 00:39:20,210
copy of the document or whatever and so

00:39:18,619 --> 00:39:21,470
being able to do that or being able to

00:39:20,210 --> 00:39:23,119
do high speed logging really anything

00:39:21,470 --> 00:39:24,410
that's inserting is a good match for

00:39:23,119 --> 00:39:26,630
among going to be it may be an equally

00:39:24,410 --> 00:39:28,339
good match for relational database

00:39:26,630 --> 00:39:30,859
because there's no relations in it at

00:39:28,339 --> 00:39:32,089
all so when you're slogging events to a

00:39:30,859 --> 00:39:34,780
table inserting is really fast

00:39:32,089 --> 00:39:36,589
regardless of how you're doing it

00:39:34,780 --> 00:39:38,599
probably not double entry bookkeeping

00:39:36,589 --> 00:39:40,130
and the reason for this is I've

00:39:38,599 --> 00:39:43,099
mentioned many times that mugabe looks

00:39:40,130 --> 00:39:44,540
at a document as an island and if you're

00:39:43,099 --> 00:39:46,910
doing something where you absolutely

00:39:44,540 --> 00:39:50,240
have to have a matching debit and credit

00:39:46,910 --> 00:39:52,970
in two different documents then it gets

00:39:50,240 --> 00:39:54,410
really tricky so you might be able to do

00:39:52,970 --> 00:39:55,369
it with clever application logic but

00:39:54,410 --> 00:39:57,200
then what if your application crashes

00:39:55,369 --> 00:39:58,760
halfway through so there's no

00:39:57,200 --> 00:40:00,740
transactions there's no multi-document

00:39:58,760 --> 00:40:02,150
transactions i should say all of your

00:40:00,740 --> 00:40:03,650
single document updates are going to be

00:40:02,150 --> 00:40:04,910
atomic within that document but nothing

00:40:03,650 --> 00:40:07,910
that hits multiple documents is going to

00:40:04,910 --> 00:40:11,960
be atomic so that's something to keep it

00:40:07,910 --> 00:40:13,460
in mind what do you give up I mentioned

00:40:11,960 --> 00:40:16,849
you give up multi-document atomic

00:40:13,460 --> 00:40:18,740
operations you give up joins so anytime

00:40:16,849 --> 00:40:20,599
you want to do so there's ways to fake

00:40:18,740 --> 00:40:21,500
this so we had like a foreign key

00:40:20,599 --> 00:40:24,410
something we're treating

00:40:21,500 --> 00:40:26,060
foreignkey you can fake that with the

00:40:24,410 --> 00:40:27,740
application so you can you know maybe an

00:40:26,060 --> 00:40:29,330
application layer that says these two

00:40:27,740 --> 00:40:30,980
collections are related and this is the

00:40:29,330 --> 00:40:33,380
foreign key between them and so when you

00:40:30,980 --> 00:40:35,180
look up this up you know option or this

00:40:33,380 --> 00:40:36,680
attribute then it's going to do a second

00:40:35,180 --> 00:40:38,630
query to the database but again it's a

00:40:36,680 --> 00:40:40,310
second query it's not a real join and

00:40:38,630 --> 00:40:41,810
it's really pushing some of the

00:40:40,310 --> 00:40:43,100
functionality that would have existed in

00:40:41,810 --> 00:40:45,380
your relational database into the

00:40:43,100 --> 00:40:47,870
application there's no referential

00:40:45,380 --> 00:40:49,580
integrity constraints there is a unique

00:40:47,870 --> 00:40:52,070
index that you can use as long as you're

00:40:49,580 --> 00:40:54,200
not sharding on something else so that's

00:40:52,070 --> 00:40:55,550
that's a slight correctness or a small

00:40:54,200 --> 00:40:58,100
correctness guarantee that you can give

00:40:55,550 --> 00:40:59,510
as long as your collections not you know

00:40:58,100 --> 00:41:01,760
started on something else if it started

00:40:59,510 --> 00:41:02,810
on the unique index it's still fine but

00:41:01,760 --> 00:41:04,850
if it's shorted on something else

00:41:02,810 --> 00:41:09,860
MongoDB is not going to enforce unique

00:41:04,850 --> 00:41:11,750
index across multiple shards and your

00:41:09,860 --> 00:41:14,390
data model is going to be tied to your

00:41:11,750 --> 00:41:16,700
query pattern so looking at the question

00:41:14,390 --> 00:41:18,200
you know do I have a reference to

00:41:16,700 --> 00:41:19,580
another collection or do I embed it

00:41:18,200 --> 00:41:22,040
that's one of the questions that people

00:41:19,580 --> 00:41:24,800
come up with a lot you know with the

00:41:22,040 --> 00:41:26,360
blog post question do you embed the

00:41:24,800 --> 00:41:28,490
comments within the blog post or do you

00:41:26,360 --> 00:41:30,230
have them as a separate collection well

00:41:28,490 --> 00:41:32,930
there's reasons to do it either way if

00:41:30,230 --> 00:41:34,580
you are just determined to get the very

00:41:32,930 --> 00:41:36,050
fastest performance on displaying a blog

00:41:34,580 --> 00:41:38,060
post possible you're going to have to

00:41:36,050 --> 00:41:41,240
embed them but you're not going to be

00:41:38,060 --> 00:41:44,240
able to switch between maybe a threaded

00:41:41,240 --> 00:41:45,410
view and a time-based view because the

00:41:44,240 --> 00:41:48,670
order and the structure of those

00:41:45,410 --> 00:41:48,670
comments are fixed within that document

00:41:49,210 --> 00:41:54,980
so what I tell people is if you really

00:41:51,740 --> 00:41:56,840
expect your data to outlive your

00:41:54,980 --> 00:41:59,060
application significantly then mugabe

00:41:56,840 --> 00:42:00,500
might not be the best because relational

00:41:59,060 --> 00:42:02,510
databases have an extremely flexible

00:42:00,500 --> 00:42:04,580
query pattern when you've got something

00:42:02,510 --> 00:42:07,070
that's fully normalized it almost you

00:42:04,580 --> 00:42:09,560
know it's going to live forever subject

00:42:07,070 --> 00:42:11,600
to performance constraints if you've got

00:42:09,560 --> 00:42:14,050
something where you are she started with

00:42:11,600 --> 00:42:15,830
a really normalized database and then

00:42:14,050 --> 00:42:17,660
because of scale you've had to

00:42:15,830 --> 00:42:19,690
denormalize and d normalize more and

00:42:17,660 --> 00:42:21,440
denormalize more until you're as

00:42:19,690 --> 00:42:23,150
denormalized as you can get with your

00:42:21,440 --> 00:42:24,560
relational database and you're still not

00:42:23,150 --> 00:42:30,040
keeping up with the load then you might

00:42:24,560 --> 00:42:31,880
want to consider going to MongoDB so

00:42:30,040 --> 00:42:33,900
with that I've answered a few questions

00:42:31,880 --> 00:42:37,250
but are there any other

00:42:33,900 --> 00:42:37,250
questions that people like to bring up

00:42:38,600 --> 00:42:43,980
so the question is what about connection

00:42:41,370 --> 00:42:45,510
pooling and I'm not sure about other

00:42:43,980 --> 00:42:47,010
languages because I mainly use Python

00:42:45,510 --> 00:42:49,770
but in the Python driver there is built

00:42:47,010 --> 00:42:52,140
in connection pooling by default what it

00:42:49,770 --> 00:42:55,080
does is it will check out a connection

00:42:52,140 --> 00:42:56,130
in a threadlocal variable and it'll

00:42:55,080 --> 00:42:57,690
always use that connection within the

00:42:56,130 --> 00:43:01,680
thread so that you get back a consistent

00:42:57,690 --> 00:43:03,710
view of what you're doing and then it'll

00:43:01,680 --> 00:43:06,180
you know create connections as needed

00:43:03,710 --> 00:43:18,090
beyond that if you over use the

00:43:06,180 --> 00:43:19,560
connections yeah okay so the question is

00:43:18,090 --> 00:43:24,750
what's the difference between an object

00:43:19,560 --> 00:43:26,820
ID and I uuid basic right okay so an

00:43:24,750 --> 00:43:30,710
object ID is something that 10gen I

00:43:26,820 --> 00:43:34,740
think invented to be kind of default

00:43:30,710 --> 00:43:36,750
auto key for their documents now in in

00:43:34,740 --> 00:43:38,130
most relational databases you probably

00:43:36,750 --> 00:43:39,480
have an auto increment integer as your

00:43:38,130 --> 00:43:40,620
default primary key like if you don't

00:43:39,480 --> 00:43:42,470
know anything else you just throw in an

00:43:40,620 --> 00:43:44,370
auto increment integer and you're done

00:43:42,470 --> 00:43:47,430
mugabe didn't want to do that because

00:43:44,370 --> 00:43:49,230
they didn't want auto increment integers

00:43:47,430 --> 00:43:51,030
are fine on a single server but when you

00:43:49,230 --> 00:43:52,320
start sharding it's really not possible

00:43:51,030 --> 00:43:54,180
to do that efficiently because

00:43:52,320 --> 00:43:55,740
incrementing a single value across all

00:43:54,180 --> 00:43:57,510
the different tables it's it's just a

00:43:55,740 --> 00:44:01,170
pain so what they did is they came up

00:43:57,510 --> 00:44:03,300
with this object ID the object ID looks

00:44:01,170 --> 00:44:04,830
random but it's not so the most

00:44:03,300 --> 00:44:07,590
significant portions of an object ID or

00:44:04,830 --> 00:44:09,000
timestamp and then there is information

00:44:07,590 --> 00:44:10,650
about the server that generated the

00:44:09,000 --> 00:44:12,180
object ID or the client clients can also

00:44:10,650 --> 00:44:13,560
generate them and then there's a

00:44:12,180 --> 00:44:15,750
sequence number so they're guaranteed to

00:44:13,560 --> 00:44:20,190
be unique within that you know that I

00:44:15,750 --> 00:44:22,800
chillon of this particular second this

00:44:20,190 --> 00:44:26,940
machine information then they'll be

00:44:22,800 --> 00:44:29,220
generated uniquely but they're not

00:44:26,940 --> 00:44:31,770
randomly distributed so you can actually

00:44:29,220 --> 00:44:34,850
if you want a coarse-grained time sort

00:44:31,770 --> 00:44:39,300
you can sort by the ID by the object ID

00:44:34,850 --> 00:44:41,810
uu IDs are usually better for if you

00:44:39,300 --> 00:44:43,890
want something that's actually not even

00:44:41,810 --> 00:44:46,530
evenly distributed something that maybe

00:44:43,890 --> 00:44:47,550
you want to short on it an object ID is

00:44:46,530 --> 00:44:50,010
a really bad choice first

00:44:47,550 --> 00:44:52,590
because it's time increasing as they as

00:44:50,010 --> 00:44:53,790
new ones getting created then they're

00:44:52,590 --> 00:44:57,870
all going to end up going to the new

00:44:53,790 --> 00:44:59,520
shard the newest shard so using a UID

00:44:57,870 --> 00:45:00,930
there would be a good idea if your

00:44:59,520 --> 00:45:03,030
interrupt interoperating with other

00:45:00,930 --> 00:45:04,860
databases it's often a good idea to use

00:45:03,030 --> 00:45:07,560
a uuid you know these integers if you

00:45:04,860 --> 00:45:10,080
want to for your ID but that's the

00:45:07,560 --> 00:45:12,360
difference between them and beasts on

00:45:10,080 --> 00:45:14,100
which is the native format has formats

00:45:12,360 --> 00:45:16,320
for both the object ID and the uuid

00:45:14,100 --> 00:45:17,880
natively so it's storing it compact not

00:45:16,320 --> 00:45:37,830
on the string representation that you

00:45:17,880 --> 00:45:39,210
see right okay so the the question is

00:45:37,830 --> 00:45:40,860
are there any situations where you use

00:45:39,210 --> 00:45:42,840
MongoDB and a relational database and I

00:45:40,860 --> 00:45:44,250
would say absolutely like I said there's

00:45:42,840 --> 00:45:47,100
some things that mugabe doesn't do well

00:45:44,250 --> 00:45:48,540
like the double entry bookkeeping some

00:45:47,100 --> 00:45:51,720
people prefer not to even run an

00:45:48,540 --> 00:45:54,210
e-commerce website on MongoDB but maybe

00:45:51,720 --> 00:45:55,890
you maybe you want to keep your product

00:45:54,210 --> 00:45:57,810
information in MongoDB because it's nice

00:45:55,890 --> 00:45:59,900
and flexible it's a flexible schema so

00:45:57,810 --> 00:46:02,700
you don't have to have some of the crazy

00:45:59,900 --> 00:46:04,530
entity attribute value schemas that you

00:46:02,700 --> 00:46:07,410
might see in the other e-commerce

00:46:04,530 --> 00:46:09,930
solutions but maybe you want to do your

00:46:07,410 --> 00:46:11,970
shopping cart with MySQL or postgresql

00:46:09,930 --> 00:46:15,060
then that would be a good match there

00:46:11,970 --> 00:46:17,580
and there's actually some some webinars

00:46:15,060 --> 00:46:20,210
or talks or something on manga db's art

00:46:17,580 --> 00:46:22,620
engines website that talks about best

00:46:20,210 --> 00:46:26,870
practices for using relational databases

00:46:22,620 --> 00:46:26,870
and MongoDB in the same application

00:46:30,109 --> 00:46:35,250
so the question is the security aspect

00:46:32,940 --> 00:46:36,660
about the security aspect of MongoDB and

00:46:35,250 --> 00:46:40,670
are you talking about security from

00:46:36,660 --> 00:46:40,670
hackers or security from system failure

00:46:43,190 --> 00:46:54,450
sorry Oh like like a linkedin problem so

00:46:49,500 --> 00:46:58,109
the MongoDB server has a pretty basic

00:46:54,450 --> 00:47:00,830
security model and never I will say this

00:46:58,109 --> 00:47:03,030
up front don't run it over the internet

00:47:00,830 --> 00:47:06,270
because the wire protocol is not

00:47:03,030 --> 00:47:07,680
encrypted so if you want to run it over

00:47:06,270 --> 00:47:10,410
the internet use s tunnel or something

00:47:07,680 --> 00:47:12,330
like that to give it an encrypted data

00:47:10,410 --> 00:47:13,650
layer they're adding that at some point

00:47:12,330 --> 00:47:14,730
I think that there's a switch that you

00:47:13,650 --> 00:47:16,770
can do if you want to compile it from

00:47:14,730 --> 00:47:19,680
source yourself but by default it's not

00:47:16,770 --> 00:47:22,550
encrypted now if you are ok with that

00:47:19,680 --> 00:47:24,450
then there is a way to enforce logins

00:47:22,550 --> 00:47:26,099
when you're connecting to the DB

00:47:24,450 --> 00:47:28,109
server and I believe that's at the

00:47:26,099 --> 00:47:29,369
database layer or the database level so

00:47:28,109 --> 00:47:32,700
you can have any number of databases

00:47:29,369 --> 00:47:35,280
within a single server and access to

00:47:32,700 --> 00:47:37,020
that database is either yes or no based

00:47:35,280 --> 00:47:38,730
on whether you've got a login so that's

00:47:37,020 --> 00:47:40,950
the granularity it's not nearly as rich

00:47:38,730 --> 00:47:45,030
as like a relational platform like a

00:47:40,950 --> 00:47:46,589
like a MySQL I guess SQL Lite is similar

00:47:45,030 --> 00:47:50,609
you either have access to the file you

00:47:46,589 --> 00:47:52,290
don't but with with the larger server

00:47:50,609 --> 00:47:58,040
based systems they're usually a lot

00:47:52,290 --> 00:47:58,040
richer than MongoDB yeah

00:48:05,839 --> 00:48:19,439
feedback would be the recent month or

00:48:09,269 --> 00:48:20,339
three months yet there was so the

00:48:19,439 --> 00:48:22,650
question is there's been a lot of

00:48:20,339 --> 00:48:27,359
negative press about MongoDB recently

00:48:22,650 --> 00:48:29,669
and do I care to comment I guess oh so I

00:48:27,359 --> 00:48:31,469
know there's some there's some history

00:48:29,669 --> 00:48:33,719
behind there was one article that made

00:48:31,469 --> 00:48:38,369
it pretty high on hacker news and reddit

00:48:33,719 --> 00:48:39,869
that is less than well grounded there

00:48:38,369 --> 00:48:41,189
are some issues about mongodb that you

00:48:39,869 --> 00:48:45,929
have to be aware of and you should be

00:48:41,189 --> 00:48:49,079
aware of going into it like there's lots

00:48:45,929 --> 00:48:51,390
of different models for how careful do

00:48:49,079 --> 00:48:52,979
you want MongoDB to be with your data so

00:48:51,390 --> 00:48:55,499
mom maybe was in was envisioned

00:48:52,979 --> 00:48:57,029
initially as this high-speed a reactive

00:48:55,499 --> 00:48:59,880
system where if you lose a couple of

00:48:57,029 --> 00:49:04,259
documents it's not a problem so given

00:48:59,880 --> 00:49:06,299
that the default which there tengen

00:49:04,259 --> 00:49:07,650
desperately wants to change is a

00:49:06,299 --> 00:49:09,479
fire-and-forget model for your updates

00:49:07,650 --> 00:49:11,759
so when your driver says insert this

00:49:09,479 --> 00:49:13,739
record then it immediately says okay I'm

00:49:11,759 --> 00:49:17,099
done the packet hasn't even been sent on

00:49:13,739 --> 00:49:18,869
the network yet so you can change this

00:49:17,099 --> 00:49:20,549
at the connection level you can change

00:49:18,869 --> 00:49:22,890
it at the database level or the or the

00:49:20,549 --> 00:49:24,539
query level but by default that's one of

00:49:22,890 --> 00:49:26,099
the problems and so if you just grab

00:49:24,539 --> 00:49:27,659
MongoDB and you grab the default driver

00:49:26,099 --> 00:49:28,979
you start doing stuff and you're like

00:49:27,659 --> 00:49:32,719
wait a minute my last hundred updates

00:49:28,979 --> 00:49:35,279
didn't happen MongoDB sucks you know

00:49:32,719 --> 00:49:36,900
well you need to turn on safe mode and

00:49:35,279 --> 00:49:38,519
there's answers to a lot of these but

00:49:36,900 --> 00:49:41,519
it's not as easy as it should be and

00:49:38,519 --> 00:49:43,140
they need to change that there's there's

00:49:41,519 --> 00:49:45,599
other guarantees that you can make but

00:49:43,140 --> 00:49:48,419
all the time the flexibility of your of

00:49:45,599 --> 00:49:51,179
your right model can be a cause for

00:49:48,419 --> 00:49:53,369
criticism because you know you get

00:49:51,179 --> 00:49:55,769
postgresql you do an insert and you

00:49:53,369 --> 00:49:58,469
commit it it's on the desk you know

00:49:55,769 --> 00:50:00,059
there's no question about that with ma

00:49:58,469 --> 00:50:02,939
going to be maybe it is maybe doesn't

00:50:00,059 --> 00:50:04,529
depends on what your options were so on

00:50:02,939 --> 00:50:06,569
the other hand with MongoDB you can say

00:50:04,529 --> 00:50:08,119
don't return from this insert until is

00:50:06,569 --> 00:50:10,140
replicated to three data centers and

00:50:08,119 --> 00:50:10,440
that's a little bit harder to do with

00:50:10,140 --> 00:50:14,130
some of

00:50:10,440 --> 00:50:16,050
other systems and being able to

00:50:14,130 --> 00:50:17,460
determine on a update by update basis

00:50:16,050 --> 00:50:20,040
which guarantee is more important to you

00:50:17,460 --> 00:50:21,839
you know is it are you logging events

00:50:20,040 --> 00:50:23,579
that you want to do statistics on and

00:50:21,839 --> 00:50:26,160
some point of the future fire-and-forget

00:50:23,579 --> 00:50:27,990
it's probably fine are you updating a

00:50:26,160 --> 00:50:29,430
shopping cart you probably want some

00:50:27,990 --> 00:50:34,280
acknowledgement that your data is safe

00:50:29,430 --> 00:50:34,280
so yeah

00:50:47,790 --> 00:50:51,460
yes so the question is what are the best

00:50:49,930 --> 00:50:55,300
practices with security given that

00:50:51,460 --> 00:50:58,119
authentications pretty weak I would say

00:50:55,300 --> 00:51:00,880
yeah use use your firewall put put mo

00:50:58,119 --> 00:51:02,740
going to be in a safe area there are

00:51:00,880 --> 00:51:06,460
some shared mommy to be providers and

00:51:02,740 --> 00:51:10,180
the way that they provide some security

00:51:06,460 --> 00:51:12,130
is they put they require you to be

00:51:10,180 --> 00:51:13,840
running on the same cloud as they are so

00:51:12,130 --> 00:51:15,460
an amazon for instance you can have you

00:51:13,840 --> 00:51:17,410
have a public dns and you have a private

00:51:15,460 --> 00:51:19,300
dns and nobody's going to see the

00:51:17,410 --> 00:51:23,080
traffic that runs around on the amazon

00:51:19,300 --> 00:51:26,100
private network so you can you can

00:51:23,080 --> 00:51:29,290
connect that private address on amazon

00:51:26,100 --> 00:51:31,359
given that i don't know that that's as

00:51:29,290 --> 00:51:33,520
visible as it needs to be and really

00:51:31,359 --> 00:51:34,780
having ssl support i would think would

00:51:33,520 --> 00:51:39,970
be one of the first things that people

00:51:34,780 --> 00:51:43,780
would want to put in the server right

00:51:39,970 --> 00:51:45,190
any other questions ok I would love it

00:51:43,780 --> 00:51:46,990
if you would rate the talk it's just

00:51:45,190 --> 00:51:49,869
like a one question multiple choice did

00:51:46,990 --> 00:51:51,310
you like it kind of thing if you're

00:51:49,869 --> 00:51:53,320
interested in I'm going to be training i

00:51:51,310 --> 00:51:55,060
am going to be offering some training

00:51:53,320 --> 00:51:57,369
classes so you can visit the ARB orion

00:51:55,060 --> 00:51:58,869
website and if you want more information

00:51:57,369 --> 00:52:02,730
about mommy to be in general you can go

00:51:58,869 --> 00:52:07,180
mongodb org and follow me on twitter

00:52:02,730 --> 00:52:09,760
that's my company's website and one

00:52:07,180 --> 00:52:13,000
other announcement is at one-thirty i am

00:52:09,760 --> 00:52:15,730
trying to get together a no sequel Boff

00:52:13,000 --> 00:52:18,180
so come to the my sequel room for no

00:52:15,730 --> 00:52:21,130
sequel just because I Ernie's great and

00:52:18,180 --> 00:52:22,480
you can we can talk about MongoDB or

00:52:21,130 --> 00:52:26,700
Cassandra or whatever you're interested

00:52:22,480 --> 00:52:26,700
in would be great so thank

00:52:33,200 --> 00:52:39,800
just a reminder we have a survey it's

00:52:36,300 --> 00:52:39,800
available at the registration desk

00:53:15,030 --> 00:53:21,450
how's that sigh every way this is the

00:53:18,150 --> 00:53:23,610
way to better utilize all your resources

00:53:21,450 --> 00:53:27,090
and it makes managing all your resources

00:53:23,610 --> 00:53:30,920
pretty easy all of the innovation is

00:53:27,090 --> 00:53:34,380
happening in open source the

00:53:30,920 --> 00:53:36,240
collaborative nature and of the you know

00:53:34,380 --> 00:53:38,340
of the community and the speed at which

00:53:36,240 --> 00:53:40,320
these are these you know these these

00:53:38,340 --> 00:53:42,240
deficiencies these bugs are getting

00:53:40,320 --> 00:53:44,970
discovered and then fixed is that I

00:53:42,240 --> 00:53:47,940
think that really shows the power of the

00:53:44,970 --> 00:53:49,560
of the open source community it is

00:53:47,940 --> 00:53:53,790
global and it's definitely because of

00:53:49,560 --> 00:53:56,160
the users community people are extremely

00:53:53,790 --> 00:54:01,380
friendly and they're always ready to

00:53:56,160 --> 00:54:02,850
help if you go on tire see any day

00:54:01,380 --> 00:54:05,160
you'll see these guys helping each other

00:54:02,850 --> 00:54:07,560
out and they're all doing it like in a

00:54:05,160 --> 00:54:09,420
selfless manner the product is

00:54:07,560 --> 00:54:13,200
transparent for everyone everyone can

00:54:09,420 --> 00:54:15,660
look at the code base everyone can see

00:54:13,200 --> 00:54:18,240
how close darkest is being built nothing

00:54:15,660 --> 00:54:23,370
nothing is proprietary everything is

00:54:18,240 --> 00:54:28,860
open in many ways it's absolutely vital

00:54:23,370 --> 00:54:32,730
to the the unborn health CloudStack the

00:54:28,860 --> 00:54:36,630
most exciting event in recent memory for

00:54:32,730 --> 00:54:39,570
he was our first developer boot camp and

00:54:36,630 --> 00:54:43,050
our call gave people a give me two weeks

00:54:39,570 --> 00:54:47,220
notice to come attend I was expecting 25

00:54:43,050 --> 00:54:50,550
or 30 people so we ended up with 87

00:54:47,220 --> 00:54:53,370
people and had to go get more chairs

00:54:50,550 --> 00:54:56,340
into the room twice everything within

00:54:53,370 --> 00:54:59,040
cloud computing is commodity and is open

00:54:56,340 --> 00:55:01,890
source and so I don't think that you

00:54:59,040 --> 00:55:03,630
will you'll see anywhere where open

00:55:01,890 --> 00:55:06,660
source is not pervasive in cloud

00:55:03,630 --> 00:55:09,390
computing and so i think it's i think

00:55:06,660 --> 00:55:10,740
it's an assumption i think when you talk

00:55:09,390 --> 00:55:11,850
about cloud computing you're really

00:55:10,740 --> 00:55:14,450
talking about open source cloud

00:55:11,850 --> 00:55:14,450
computing

00:55:15,060 --> 00:55:20,560
CloudStack is a robust solution for

00:55:17,829 --> 00:55:22,960
large deployments you have dozens of

00:55:20,560 --> 00:55:26,829
data centers and thousands of servers in

00:55:22,960 --> 00:55:29,530
each data centers these hardware is

00:55:26,829 --> 00:55:33,010
going to fail and cloudstack is designed

00:55:29,530 --> 00:55:35,710
to handle number one that mass scale

00:55:33,010 --> 00:55:38,890
number two it's designed to handle the

00:55:35,710 --> 00:55:41,740
failure that inevitably happens in large

00:55:38,890 --> 00:55:45,940
deployments started working on cog deck

00:55:41,740 --> 00:55:49,210
over four years ago and it was the

00:55:45,940 --> 00:55:51,250
original set of people working on it had

00:55:49,210 --> 00:55:55,089
a background of delivering software to

00:55:51,250 --> 00:55:59,349
telcos and service providers lots of QA

00:55:55,089 --> 00:56:02,950
lots of users actually using it high

00:55:59,349 --> 00:56:06,040
availability is a key feature multiple

00:56:02,950 --> 00:56:08,050
hypervisors support different network

00:56:06,040 --> 00:56:10,720
models you can pick up whatever suits

00:56:08,050 --> 00:56:13,000
you better while step management server

00:56:10,720 --> 00:56:16,690
can be deployed in different physical

00:56:13,000 --> 00:56:18,339
machines it definitely has a huge

00:56:16,690 --> 00:56:23,319
footprint it's being deployed everywhere

00:56:18,339 --> 00:56:25,900
there's a major movie studio that they

00:56:23,319 --> 00:56:29,200
were using CloudStack they were using it

00:56:25,900 --> 00:56:31,180
to transcode video and I thought that

00:56:29,200 --> 00:56:32,829
was terribly fascinating what I found

00:56:31,180 --> 00:56:36,099
more fascinating is what they did during

00:56:32,829 --> 00:56:38,890
lunch where they would spin up you know

00:56:36,099 --> 00:56:40,270
50 or 60 game servers then as soon as

00:56:38,890 --> 00:56:42,190
lunch was over they would destroy all

00:56:40,270 --> 00:56:46,329
the instances and go back to doing real

00:56:42,190 --> 00:56:47,650
work CloudStack is vast it touches so

00:56:46,329 --> 00:56:49,720
many different aspects and there's no

00:56:47,650 --> 00:56:52,089
one person that's kind of like a master

00:56:49,720 --> 00:56:56,200
of all those realms I think clouds stack

00:56:52,089 --> 00:56:58,540
as a project is going to be one of the

00:56:56,200 --> 00:57:02,500
leaders simply because it's some of the

00:56:58,540 --> 00:57:06,390
most feature fallen and and robust

00:57:02,500 --> 00:57:06,390
platforms out they were

00:57:06,980 --> 00:57:10,840
I don't see your limits of the clouds

00:57:08,570 --> 00:57:10,840
dag

00:57:23,640 --> 00:57:25,700
you

00:57:29,010 --> 00:57:34,089
when we created asterisk over a decade

00:57:31,750 --> 00:57:36,039
ago we could not have imagined that

00:57:34,089 --> 00:57:38,260
asterisk would not only become the most

00:57:36,039 --> 00:57:40,390
widely adopted open source communication

00:57:38,260 --> 00:57:42,430
software on the planet but that it would

00:57:40,390 --> 00:57:44,950
impact the entire industry in the way

00:57:42,430 --> 00:57:46,930
that it has today asterisk has found its

00:57:44,950 --> 00:57:49,569
way in the more than 170 countries and

00:57:46,930 --> 00:57:51,520
virtually every fortune 1000 company the

00:57:49,569 --> 00:57:53,619
success of asterisk has enabled a

00:57:51,520 --> 00:57:55,029
transition of power from the hands of

00:57:53,619 --> 00:57:57,279
the traditional proprietary phone

00:57:55,029 --> 00:57:59,680
vendors into the hands of the users and

00:57:57,279 --> 00:58:01,630
administrators of phone systems using

00:57:59,680 --> 00:58:02,859
this power our customers have created

00:58:01,630 --> 00:58:04,809
all sorts of business changing

00:58:02,859 --> 00:58:06,640
applications from small office phone

00:58:04,809 --> 00:58:09,160
systems to mission-critical call centers

00:58:06,640 --> 00:58:10,779
to international carrier networks in

00:58:09,160 --> 00:58:12,549
fact there's even an entire country

00:58:10,779 --> 00:58:14,950
those communications infrastructure runs

00:58:12,549 --> 00:58:17,079
on esters the gym has always been about

00:58:14,950 --> 00:58:18,789
creating technology that expands

00:58:17,079 --> 00:58:20,950
communications capabilities in ways that

00:58:18,789 --> 00:58:22,150
we could never have imagined and that's

00:58:20,950 --> 00:58:24,549
part of what's game-changing about

00:58:22,150 --> 00:58:27,250
digium today we're doing it again this

00:58:24,549 --> 00:58:29,349
time by introducing a new family of HD

00:58:27,250 --> 00:58:31,450
IP phones that extends control of the

00:58:29,349 --> 00:58:33,220
user all the way to the desktop the

00:58:31,450 --> 00:58:34,930
launch of these new products represents

00:58:33,220 --> 00:58:36,880
the next phase indigenous history of

00:58:34,930 --> 00:58:39,430
innovation these are the first and only

00:58:36,880 --> 00:58:41,140
IP phones designed to fully leverage the

00:58:39,430 --> 00:58:42,670
power of estrus when we first discussed

00:58:41,140 --> 00:58:44,710
our expectations for building a family

00:58:42,670 --> 00:58:46,869
of phones for use with asterisk our

00:58:44,710 --> 00:58:48,609
requirements were pretty simple we asked

00:58:46,869 --> 00:58:50,230
the team to build the phones such that

00:58:48,609 --> 00:58:52,450
they were easy to install integrate

00:58:50,230 --> 00:58:54,279
provision and use I think you'll soon

00:58:52,450 --> 00:58:56,859
agree our engineers have delivered on

00:58:54,279 --> 00:58:58,480
that goal user feedback is validating

00:58:56,859 --> 00:59:00,609
that when it comes to operation with

00:58:58,480 --> 00:59:03,010
astro space systems including our own

00:59:00,609 --> 00:59:05,589
switchvox based product these are the

00:59:03,010 --> 00:59:06,910
easiest to use best integrated most

00:59:05,589 --> 00:59:09,490
interoperable products on the market

00:59:06,910 --> 00:59:11,490
today the digi and family phones will

00:59:09,490 --> 00:59:13,539
initially include three IP des hommes

00:59:11,490 --> 00:59:15,490
uniquely designed to complement any

00:59:13,539 --> 00:59:17,349
asterisk or switch box based solution

00:59:15,490 --> 00:59:20,020
these phones are different for a number

00:59:17,349 --> 00:59:22,660
of reasons first there is clue sively

00:59:20,020 --> 00:59:24,099
designed for use with esters secondly

00:59:22,660 --> 00:59:25,710
we've made it really easy to

00:59:24,099 --> 00:59:28,089
autodiscover and provision the phones

00:59:25,710 --> 00:59:29,799
next we've made it easy for the phones

00:59:28,089 --> 00:59:31,730
to access information inside of

00:59:29,799 --> 00:59:33,730
asterisks allowing tight coupling

00:59:31,730 --> 00:59:35,720
between the application and the phone

00:59:33,730 --> 00:59:37,880
additionally we've created an

00:59:35,720 --> 00:59:40,010
applications engineer that allows users

00:59:37,880 --> 00:59:43,220
and developers to create and run their

00:59:40,010 --> 00:59:45,020
own apps on the phone and finally we've

00:59:43,220 --> 00:59:46,970
done all of this at a very compelling

00:59:45,020 --> 00:59:48,619
price point at Digium we're always

00:59:46,970 --> 00:59:50,720
thinking of ways to give our customers

00:59:48,619 --> 00:59:53,300
the best value in business phone systems

00:59:50,720 --> 00:59:54,859
and also give them the power to create

00:59:53,300 --> 00:59:56,990
their own solutions or any

00:59:54,859 --> 00:59:58,730
communications challenge well continue

00:59:56,990 --> 01:00:00,170
to push the boundaries not only to make

00:59:58,730 --> 01:00:02,210
Astra's cooler bastard more

01:00:00,170 --> 01:00:03,830
technologically feature-rich but to make

01:00:02,210 --> 01:00:06,290
asterisk employed communications even

01:00:03,830 --> 01:00:09,700
easier and together we'll change the way

01:00:06,290 --> 01:00:09,700

YouTube URL: https://www.youtube.com/watch?v=NE3S5iPDZZk


