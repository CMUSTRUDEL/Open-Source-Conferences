Title: 2012 SouthEast LinuxFest - MySQL Training - Jimmy Yang - InnoDB Performance
Publication date: 2013-08-29
Playlist: 2012 SouthEast LinuxFest - MySQL Training - Advanced
Description: 
	2012 SouthEast LinuxFest
Advanced MySQL Training
Jimmy Yang
How Does InnoDB Optimize For Performance
Captions: 
	00:00:00,000 --> 00:00:05,279
the following presentation was recorded

00:00:02,490 --> 00:00:08,040
the 2012 southeast linux fest in

00:00:05,279 --> 00:00:10,410
charlotte north carolina it is licensed

00:00:08,040 --> 00:00:12,090
under a creative commons license for

00:00:10,410 --> 00:00:17,609
more information about the southeast

00:00:12,090 --> 00:00:19,439
linux fest visit WWDC linux pc org the

00:00:17,609 --> 00:00:22,320
southeast linux fest would like to thank

00:00:19,439 --> 00:00:24,920
the following diamond sponsors in 2012

00:00:22,320 --> 00:00:29,670
for helping make these videos possible

00:00:24,920 --> 00:00:33,899
it's at the time we just start my name

00:00:29,670 --> 00:00:37,770
is Jimmy young walk for the no dbt me

00:00:33,899 --> 00:00:46,950
Oracle so today I'm going to talk about

00:00:37,770 --> 00:00:50,899
the performance aspect of nodb in case

00:00:46,950 --> 00:00:53,280
this is a brief agenda we're going to

00:00:50,899 --> 00:00:56,610
briefly go through existing some

00:00:53,280 --> 00:00:58,850
existing performance features then after

00:00:56,610 --> 00:01:03,870
that we talk about two new releases

00:00:58,850 --> 00:01:08,760
when's 55 and 56 both happened after

00:01:03,870 --> 00:01:11,159
Oracle idea my sequel so 55 royalties is

00:01:08,760 --> 00:01:18,840
last year and we this year we're going

00:01:11,159 --> 00:01:22,820
to release 56 so does everyone here

00:01:18,840 --> 00:01:27,360
knows in od be a very familiar with it

00:01:22,820 --> 00:01:33,270
so so I briefly just goes through an 0

00:01:27,360 --> 00:01:37,229
DB is has been transitioning storage

00:01:33,270 --> 00:01:40,380
engine for my sequel since 2000 01 then

00:01:37,229 --> 00:01:44,369
after arico acquires my sequel last year

00:01:40,380 --> 00:01:47,850
it become the default storage engine it

00:01:44,369 --> 00:01:50,750
used to be my I am now the nodb become

00:01:47,850 --> 00:01:53,340
the default storage engine for my sequel

00:01:50,750 --> 00:01:55,680
so you get a my sukkah out of the box

00:01:53,340 --> 00:01:57,740
you have nodb so if you want to use

00:01:55,680 --> 00:02:00,840
other storage engine you have to specify

00:01:57,740 --> 00:02:07,979
eventually we're going to obsolete my i

00:02:00,840 --> 00:02:10,890
sin so its asset compliant it supports

00:02:07,979 --> 00:02:14,690
low-level locking

00:02:10,890 --> 00:02:18,480
it has a couple of quite innovative

00:02:14,690 --> 00:02:21,840
feature make it different from the other

00:02:18,480 --> 00:02:25,050
storage engine wednesday interlocking

00:02:21,840 --> 00:02:28,680
our user buffering and there is adaptive

00:02:25,050 --> 00:02:31,200
hash index so those are two things make

00:02:28,680 --> 00:02:34,590
it quite a unique there are other things

00:02:31,200 --> 00:02:39,030
like us bitmap before the low level 0

00:02:34,590 --> 00:02:41,340
locking but that's not i'm not going to

00:02:39,030 --> 00:02:43,890
go through that today but i just go

00:02:41,340 --> 00:02:49,500
briefly quickly on those two unique

00:02:43,890 --> 00:02:52,860
features that makes you know DB fast ok

00:02:49,500 --> 00:02:56,640
so one the first one is the insert

00:02:52,860 --> 00:03:02,239
buffering in the buffering is kind of

00:02:56,640 --> 00:03:05,670
thing says I update a secondary index

00:03:02,239 --> 00:03:09,480
sometimes the index leaf page it's now

00:03:05,670 --> 00:03:12,660
in the buffer pool and I don't need to

00:03:09,480 --> 00:03:16,709
bring this particular page into buffer I

00:03:12,660 --> 00:03:18,959
just cash it in a memory structure

00:03:16,709 --> 00:03:21,930
called a user buffering so in there

00:03:18,959 --> 00:03:25,970
buffering itself gives a special index

00:03:21,930 --> 00:03:30,810
but it's not particular to any table or

00:03:25,970 --> 00:03:33,450
any any index itself it's just a generic

00:03:30,810 --> 00:03:36,360
estructura mmmm structure buffers

00:03:33,450 --> 00:03:40,140
everything that inserts and you found

00:03:36,360 --> 00:03:44,250
that particular page the index leaf

00:03:40,140 --> 00:03:47,670
pages they are not in the buffer so the

00:03:44,250 --> 00:03:51,450
benefits is that you cash it and they

00:03:47,670 --> 00:03:55,640
make it sequin a sequential oh the next

00:03:51,450 --> 00:03:59,340
time all you also you reduce the i/o so

00:03:55,640 --> 00:04:01,650
next time some operations need to bring

00:03:59,340 --> 00:04:04,769
the sleep page backing and you found

00:04:01,650 --> 00:04:07,230
this some updates are needed for this

00:04:04,769 --> 00:04:12,750
particular page then you just merge it

00:04:07,230 --> 00:04:15,310
so full user it's transparent they don't

00:04:12,750 --> 00:04:21,350
see anything different other than

00:04:15,310 --> 00:04:25,490
maybe a slow merge activity happening so

00:04:21,350 --> 00:04:30,139
the performance study shows it's seven

00:04:25,490 --> 00:04:33,380
times faster without these things so

00:04:30,139 --> 00:04:37,270
this is a kind of very important feature

00:04:33,380 --> 00:04:42,259
that makes you know TV stands out it's

00:04:37,270 --> 00:04:44,840
in search of a lot faster than others so

00:04:42,259 --> 00:04:48,770
later I'm going to talk about in 55 we

00:04:44,840 --> 00:04:52,099
extend this to other DML for this insert

00:04:48,770 --> 00:04:54,770
offering so now the name changes you'll

00:04:52,099 --> 00:04:58,880
change buffering and no longer refer to

00:04:54,770 --> 00:05:02,780
either the buffering so it also has some

00:04:58,880 --> 00:05:09,740
benefits on a solid-state storage SSD

00:05:02,780 --> 00:05:13,669
those kind of thing okay the next one is

00:05:09,740 --> 00:05:17,990
adaptive hashing Dax again it's it's a

00:05:13,669 --> 00:05:22,190
index residen the memory and it's mimic

00:05:17,990 --> 00:05:25,070
in-memory database so it says if you can

00:05:22,190 --> 00:05:27,949
hold everything in memory then I don't

00:05:25,070 --> 00:05:31,460
need to go to disco to fetch it so the

00:05:27,949 --> 00:05:34,639
idea is that if I do some query on some

00:05:31,460 --> 00:05:38,270
kind of key value things frequently I

00:05:34,639 --> 00:05:41,930
can just catch them so use the hash

00:05:38,270 --> 00:05:44,720
index so next this query comes in also

00:05:41,930 --> 00:05:48,560
looking for the same key I don't need to

00:05:44,720 --> 00:05:51,289
go to disk I don't need to do a index at

00:05:48,560 --> 00:05:56,720
research I just go through this hashing

00:05:51,289 --> 00:06:00,099
Dax and get a value right away and by

00:05:56,720 --> 00:06:03,949
default you get like one sixty-fourth

00:06:00,099 --> 00:06:08,840
size of the buffer pool dedicated to

00:06:03,949 --> 00:06:12,259
this adaptive hash index and so it

00:06:08,840 --> 00:06:15,259
should show a notice your query pattern

00:06:12,259 --> 00:06:17,810
and if we finally keep on searching this

00:06:15,259 --> 00:06:21,500
particular key then I just catch the key

00:06:17,810 --> 00:06:22,880
value so catch the result and what next

00:06:21,500 --> 00:06:25,279
time it comes in don't need to go

00:06:22,880 --> 00:06:26,310
through all the process 22 to the query

00:06:25,279 --> 00:06:30,540
again

00:06:26,310 --> 00:06:34,190
so the performance shows two times

00:06:30,540 --> 00:06:38,250
faster and if you really do actively

00:06:34,190 --> 00:06:45,660
index join index access it's five times

00:06:38,250 --> 00:06:48,840
faster so that's another thing yeah yes

00:06:45,660 --> 00:06:51,810
yeah so it is some algorithm says well

00:06:48,840 --> 00:06:53,850
if I access this page of multiple times

00:06:51,810 --> 00:07:08,820
and they are looking for this key I just

00:06:53,850 --> 00:07:12,750
do the hash index on that yeah yes well

00:07:08,820 --> 00:07:16,770
yeah well this is a i think it's it's

00:07:12,750 --> 00:07:19,050
kind of depend on your query pattern so

00:07:16,770 --> 00:07:22,080
you're saying that I always query a

00:07:19,050 --> 00:07:24,420
unique icky I never repeat and I going

00:07:22,080 --> 00:07:27,060
to exhaust this hash index you always

00:07:24,420 --> 00:07:31,650
can beat it but this is a geneticist

00:07:27,060 --> 00:07:42,690
bench by default and it shows this kind

00:07:31,650 --> 00:07:46,680
of thing oh well ro cash well yeah a

00:07:42,690 --> 00:07:50,430
same thing but it's a hash index so I

00:07:46,680 --> 00:07:52,650
think it's more of just strictly tell

00:07:50,430 --> 00:08:00,630
you it's a hash index how we doing going

00:07:52,650 --> 00:08:03,630
to what kind of index is it so all right

00:08:00,630 --> 00:08:05,880
so that's some existing feature that

00:08:03,630 --> 00:08:08,430
makes it unique and you fast so we're

00:08:05,880 --> 00:08:11,040
just going to go to next phase and

00:08:08,430 --> 00:08:13,950
talking about the new features a new

00:08:11,040 --> 00:08:16,520
performance features seen 55 so I'm

00:08:13,950 --> 00:08:19,710
going through a lot of those features

00:08:16,520 --> 00:08:24,690
quickly there are a lot of stuff to

00:08:19,710 --> 00:08:28,140
cover I think the main idea to bring

00:08:24,690 --> 00:08:31,800
home is that in 0 DB and our quiz doing

00:08:28,140 --> 00:08:36,210
a lot of things on the performance part

00:08:31,800 --> 00:08:38,329
and making my SIA that my sequin it will

00:08:36,210 --> 00:08:43,079
d be a faster and faster

00:08:38,329 --> 00:08:47,100
so in 55 which is last year those are a

00:08:43,079 --> 00:08:51,240
list of the features the way down from

00:08:47,100 --> 00:08:57,290
the performance standpoint and I'm going

00:08:51,240 --> 00:09:00,630
to go through each of them quickly so

00:08:57,290 --> 00:09:04,649
that's the list so let's go just go each

00:09:00,630 --> 00:09:10,140
of them quickly multiple multiple buffer

00:09:04,649 --> 00:09:15,329
pool instance so this describes dl

00:09:10,140 --> 00:09:19,140
problem still it comes down to a mutex

00:09:15,329 --> 00:09:23,310
that guarded a buffer pool so a lot of

00:09:19,140 --> 00:09:28,110
structure are being guarded by this

00:09:23,310 --> 00:09:32,820
buffer for mutex and it becomes very hot

00:09:28,110 --> 00:09:37,740
mutex it's like a being acquired like a

00:09:32,820 --> 00:09:40,709
700 k per second and if you look at it

00:09:37,740 --> 00:09:45,390
it's like if held by fifty percent of

00:09:40,709 --> 00:09:49,829
the time it's been hell so next one is

00:09:45,390 --> 00:09:52,470
at the table is a performance schema I'm

00:09:49,829 --> 00:09:54,269
not sure everyone form a familiar with

00:09:52,470 --> 00:09:59,220
performance schemas that's a then

00:09:54,269 --> 00:10:05,959
there's a new feature in 55 and issues

00:09:59,220 --> 00:10:09,930
you how mutex and how those latches

00:10:05,959 --> 00:10:11,970
perform I'm going to talk about this

00:10:09,930 --> 00:10:14,310
performance came a bit later that's a

00:10:11,970 --> 00:10:20,220
new feature but that's an example just

00:10:14,310 --> 00:10:24,089
shows you how many time the ranking of

00:10:20,220 --> 00:10:28,399
after all mutex all the mutex and you

00:10:24,089 --> 00:10:28,399
see that buffer for mutexes on the top

00:10:30,649 --> 00:10:39,680
so how to solve this the solution is

00:10:35,779 --> 00:10:42,249
kind of simple we just split the buffer

00:10:39,680 --> 00:10:45,379
pool into multiple buffer pool instance

00:10:42,249 --> 00:10:49,819
so that we're splitting this buffer pool

00:10:45,379 --> 00:10:55,970
you get a kind of split a load into

00:10:49,819 --> 00:10:59,569
different pools and the analyze should

00:10:55,970 --> 00:11:03,740
set you won't be acquired how the

00:10:59,569 --> 00:11:06,139
multiple mutex across this pues so at

00:11:03,740 --> 00:11:09,889
most a time you will be doing some

00:11:06,139 --> 00:11:12,980
working while those buffer pool so

00:11:09,889 --> 00:11:17,499
that's kind of spread dia our contention

00:11:12,980 --> 00:11:23,149
and the end result is about ten percent

00:11:17,499 --> 00:11:26,660
on rewrite on a 16-core so the bleep

00:11:23,149 --> 00:11:30,459
performance is increased as well because

00:11:26,660 --> 00:11:34,129
basically you don't have this mutex

00:11:30,459 --> 00:11:36,980
contention anymore so that's why we is

00:11:34,129 --> 00:11:40,279
pretty a multiple possible so in the

00:11:36,980 --> 00:11:44,660
future we probably can bind we also can

00:11:40,279 --> 00:11:47,809
bind on a particular table to a buffer

00:11:44,660 --> 00:11:50,209
pool then if you have DBA that knows

00:11:47,809 --> 00:11:53,179
your application well then you can

00:11:50,209 --> 00:11:56,120
utilize that so that's some other

00:11:53,179 --> 00:12:01,399
benefits you will come along in the

00:11:56,120 --> 00:12:03,949
future so this is a graph shows you that

00:12:01,399 --> 00:12:08,120
when we after we actually split the

00:12:03,949 --> 00:12:13,519
buffer pool you get the steady increase

00:12:08,120 --> 00:12:18,139
of the performance so on the left side

00:12:13,519 --> 00:12:22,639
this is on the y-axis it's the TPS

00:12:18,139 --> 00:12:27,829
transaction per second so the left side

00:12:22,639 --> 00:12:31,059
is without the buffer pool spreading and

00:12:27,829 --> 00:12:34,069
the on the right side is eight possible

00:12:31,059 --> 00:12:38,660
so you can see a steady increase of deer

00:12:34,069 --> 00:12:42,139
transaction per second all right the

00:12:38,660 --> 00:12:44,209
next feature are we done in five five

00:12:42,139 --> 00:12:48,619
years yeah

00:12:44,209 --> 00:12:52,249
increase the crash recovery so crash

00:12:48,619 --> 00:12:56,179
recovery if everyone knows see comes

00:12:52,249 --> 00:12:59,029
around with three phase the skin face

00:12:56,179 --> 00:13:01,939
decides where we actually start the

00:12:59,029 --> 00:13:06,679
yellow coveri then we do we do then we

00:13:01,939 --> 00:13:11,779
do and do so there are two problems in

00:13:06,679 --> 00:13:15,439
the older nodb the first one is scans

00:13:11,779 --> 00:13:18,619
fairly slow the reason is that we need

00:13:15,439 --> 00:13:23,480
to track the hash table size so that it

00:13:18,619 --> 00:13:28,610
doesn't exhausting the buffer pool so

00:13:23,480 --> 00:13:32,179
the design the old design is not well

00:13:28,610 --> 00:13:35,449
designed it goes calculate the hash

00:13:32,179 --> 00:13:41,990
table by just traversed a list of the

00:13:35,449 --> 00:13:44,779
abraka are located so that there is a

00:13:41,990 --> 00:13:50,139
question there's a problem is that we

00:13:44,779 --> 00:13:55,519
also get the dirt page into a fresh list

00:13:50,139 --> 00:14:00,740
and this this fresh list is sorted on

00:13:55,519 --> 00:14:04,549
the LSN the that's unique ID identify

00:14:00,740 --> 00:14:08,569
the transaction so the list can be large

00:14:04,549 --> 00:14:10,670
and you need to do a linear search to

00:14:08,569 --> 00:14:14,240
place that particular page in God

00:14:10,670 --> 00:14:19,999
transaction a flush list so this is

00:14:14,240 --> 00:14:22,549
again slow so the solution are for each

00:14:19,999 --> 00:14:26,179
of them the first one we actually catch

00:14:22,549 --> 00:14:28,999
the hash table size in the header that's

00:14:26,179 --> 00:14:30,759
simple and effective so the for the

00:14:28,999 --> 00:14:34,670
second one that will actually build a

00:14:30,759 --> 00:14:39,319
structure called a red black tree that's

00:14:34,670 --> 00:14:43,100
a kind of binary tree similar to binary

00:14:39,319 --> 00:14:47,179
tree but it's also help you to to found

00:14:43,100 --> 00:14:50,720
your place quickly so whatever it is

00:14:47,179 --> 00:14:52,429
that a new buffer come see it can go

00:14:50,720 --> 00:14:55,299
through this red black tree and find

00:14:52,429 --> 00:14:55,299
your position quickly

00:14:55,899 --> 00:15:05,259
so this benchmark shows these two chains

00:15:00,860 --> 00:15:10,870
down a remarkable job to speed up the

00:15:05,259 --> 00:15:15,230
crash recovery you should look at it 51

00:15:10,870 --> 00:15:21,709
just just look at this example here I it

00:15:15,230 --> 00:15:27,110
was taking 456 minute just to do a crash

00:15:21,709 --> 00:15:29,920
recovery so that's about seven hours so

00:15:27,110 --> 00:15:33,589
that's kind of intolerable to a lot of

00:15:29,920 --> 00:15:38,540
web company or whatever that just spend

00:15:33,589 --> 00:15:41,509
that much time to actually recover now

00:15:38,540 --> 00:15:46,130
it just increased to 40 minutes those

00:15:41,509 --> 00:15:49,550
are 32 times faster and the use

00:15:46,130 --> 00:15:51,740
spreading all those different phase and

00:15:49,550 --> 00:15:55,209
you see that how much time actually was

00:15:51,740 --> 00:15:58,430
saved because of those two optimization

00:15:55,209 --> 00:16:01,880
so those simple kind of work really

00:15:58,430 --> 00:16:07,269
helps to do a lot of a remarkable job to

00:16:01,880 --> 00:16:07,269
get your performance up

00:16:11,850 --> 00:16:23,519
so again that's another db2 test shows

00:16:18,240 --> 00:16:26,970
how much faster a shortened eat on

00:16:23,519 --> 00:16:32,269
transferee hour to 20 minutes so similar

00:16:26,970 --> 00:16:32,269
result yes yeah

00:16:39,490 --> 00:16:51,089
and it doesn't go back no all right

00:16:43,930 --> 00:16:51,089
let's do it this way okay yeah

00:16:55,820 --> 00:17:12,829
aha so I using the still longer than you

00:17:03,750 --> 00:17:12,829
expected yes

00:17:14,050 --> 00:17:32,330
yeah yes well this is a rewrite test so

00:17:25,250 --> 00:17:36,050
basically oh well yeah i think its

00:17:32,330 --> 00:17:37,850
suspension while you have you can test

00:17:36,050 --> 00:17:39,350
the different ways you can specify it's

00:17:37,850 --> 00:17:45,730
a read the test or it's a real

00:17:39,350 --> 00:17:48,530
tight-assed for from this amount of the

00:17:45,730 --> 00:17:50,120
recovery I don't think it's just simple

00:17:48,530 --> 00:17:58,520
reads there will be a lot of Rights

00:17:50,120 --> 00:18:05,090
happening and yeah to bcc kind of

00:17:58,520 --> 00:18:08,590
benchmark yes yeah so it's kind of very

00:18:05,090 --> 00:18:08,590
specified to the test itself

00:18:17,580 --> 00:18:26,850
yeah yeah tvcc is more contained to a

00:18:22,200 --> 00:18:29,040
few tables so a lot of time at EPCC can

00:18:26,850 --> 00:18:36,060
have had everything in memory as its

00:18:29,040 --> 00:18:38,280
it's not a very large test okay all

00:18:36,060 --> 00:18:42,810
right so we talked about inzer buffering

00:18:38,280 --> 00:18:47,810
that's very effective now we extend this

00:18:42,810 --> 00:18:47,810
to to all kinds of including the deletes

00:18:50,510 --> 00:18:58,650
so that anything any updates and deletes

00:18:54,780 --> 00:19:03,150
any purge that going to come into the

00:18:58,650 --> 00:19:05,370
secondary index now it's cached so

00:19:03,150 --> 00:19:08,670
however next time the leaf page bringing

00:19:05,370 --> 00:19:12,000
to the buffer then you merge it so

00:19:08,670 --> 00:19:17,540
that's just group all those fragmented

00:19:12,000 --> 00:19:17,540
as random i/o into a sequential

00:19:22,070 --> 00:19:28,640
so there so that's deer were clothes

00:19:25,790 --> 00:19:31,220
that will help in this by this change

00:19:28,640 --> 00:19:34,580
buffering if it's very I Obon they have

00:19:31,220 --> 00:19:37,610
a lot of secondary index a lot of DML

00:19:34,580 --> 00:19:39,770
happening it will be benefiting from

00:19:37,610 --> 00:19:45,590
this extension of the change of

00:19:39,770 --> 00:19:49,930
buffering so yeah so another benchmark

00:19:45,590 --> 00:19:53,600
shows how faster the deletes goes so the

00:19:49,930 --> 00:19:57,620
deli used to be 50 rolls per second now

00:19:53,600 --> 00:20:01,610
it's a thousand rows per second so it's

00:19:57,620 --> 00:20:12,980
true it's a lot faster after we extend

00:20:01,610 --> 00:20:16,370
this insert buffering to the deletes ok

00:20:12,980 --> 00:20:20,990
next one is dl support for native I on

00:20:16,370 --> 00:20:24,590
linux so we used to do kind of simulated

00:20:20,990 --> 00:20:28,820
a synchronized io on all platforms

00:20:24,590 --> 00:20:32,720
except your windows similar to the aio

00:20:28,820 --> 00:20:35,540
is not really a synchronized it's still

00:20:32,720 --> 00:20:41,720
synchronized here from the OS possess

00:20:35,540 --> 00:20:46,580
perspective so now with the new Libby I

00:20:41,720 --> 00:20:50,510
all supported on the Linux we utilize

00:20:46,580 --> 00:20:54,020
this make the this Isle a synchronized

00:20:50,510 --> 00:20:58,820
so you can pump as many miles to the

00:20:54,020 --> 00:21:04,210
kernel as you want so it's truly a

00:20:58,820 --> 00:21:06,550
synchronous i/o so it just apprently

00:21:04,210 --> 00:21:10,870
give you a lot of scalability and

00:21:06,550 --> 00:21:10,870
performance enhancement

00:21:10,940 --> 00:21:18,970
ah sorry yes

00:21:29,990 --> 00:21:35,120
well it depend on and I all is sometimes

00:21:33,200 --> 00:21:37,510
I don't need to wait a complete I can

00:21:35,120 --> 00:21:37,510
just go on

00:21:47,490 --> 00:21:50,420
aha

00:21:52,040 --> 00:22:09,480
yes yeah we have a shred actual waiting

00:21:59,820 --> 00:22:15,090
that to be complete actually well we

00:22:09,480 --> 00:22:22,310
wait for the the particular request for

00:22:15,090 --> 00:22:22,310
that I owe to company yes yes yes yes

00:22:24,770 --> 00:22:31,380
okay so this is another feature called

00:22:27,900 --> 00:22:35,280
the multiple rollback segment solo

00:22:31,380 --> 00:22:39,810
backers is definitely needed when you do

00:22:35,280 --> 00:22:44,360
a logging for the any transaction so the

00:22:39,810 --> 00:22:49,650
low back used to be under one Kate's

00:22:44,360 --> 00:22:53,400
1023 so you cannot have more than one

00:22:49,650 --> 00:22:55,380
case transaction at a time otherwise you

00:22:53,400 --> 00:22:59,180
don't have enough flow by second you

00:22:55,380 --> 00:23:05,000
support that so this is the feature just

00:22:59,180 --> 00:23:08,750
increase that this is a scalability

00:23:05,000 --> 00:23:12,510
solution but also because of this

00:23:08,750 --> 00:23:16,890
increase this reduced the contention on

00:23:12,510 --> 00:23:22,950
the particular low back segment mutex so

00:23:16,890 --> 00:23:28,950
we have 128 different segments each

00:23:22,950 --> 00:23:32,010
segment has our 1k row back log so then

00:23:28,950 --> 00:23:35,030
you have 128 mutex you also like a

00:23:32,010 --> 00:23:38,600
buffalo meat axe you spread out the

00:23:35,030 --> 00:23:43,550
contention are there particular meal tax

00:23:38,600 --> 00:23:43,550
so this also helps in performance

00:23:44,750 --> 00:23:53,360
the next one is the purge is scheduling

00:23:50,110 --> 00:23:55,880
the purge I'm not sure everyone knows

00:23:53,360 --> 00:23:59,750
that purge saying its kind of happening

00:23:55,880 --> 00:24:03,550
in the background so for because of

00:23:59,750 --> 00:24:06,590
supporting MVCC when you delete a row

00:24:03,550 --> 00:24:12,080
it's not that being deleted right away

00:24:06,590 --> 00:24:14,480
and still stay in the database the only

00:24:12,080 --> 00:24:16,730
time it can be deleted is one actually

00:24:14,480 --> 00:24:19,570
there's no transaction actually need to

00:24:16,730 --> 00:24:24,170
access it so the oldest of transaction

00:24:19,570 --> 00:24:27,230
years country running is older than the

00:24:24,170 --> 00:24:31,430
this particular Rose transaction ID then

00:24:27,230 --> 00:24:35,180
this particular transaction can be this

00:24:31,430 --> 00:24:40,190
particular delete can be a purge from

00:24:35,180 --> 00:24:47,150
the cash so it was performed by the

00:24:40,190 --> 00:24:50,110
Masters read in the nodd and you know

00:24:47,150 --> 00:24:53,360
mas read do a lot of things other than

00:24:50,110 --> 00:24:56,660
do the purge we also do the check

00:24:53,360 --> 00:25:04,870
pointing it's also do the fresh the

00:24:56,660 --> 00:25:09,050
dirty page so if if it is a very high

00:25:04,870 --> 00:25:12,070
throughput of deer DML then you the

00:25:09,050 --> 00:25:15,080
purge thread the public cannot catch up

00:25:12,070 --> 00:25:19,180
in the mass red because master is our

00:25:15,080 --> 00:25:21,560
busy also if affects other activities

00:25:19,180 --> 00:25:24,230
for example you can approach the dirty

00:25:21,560 --> 00:25:30,140
page then you have to wait for the new

00:25:24,230 --> 00:25:33,740
page to bring into the buffer so the

00:25:30,140 --> 00:25:36,680
solution is actually it allocates a new

00:25:33,740 --> 00:25:42,680
data chris red for the purpose of the

00:25:36,680 --> 00:25:45,320
purging so the end result we just jump

00:25:42,680 --> 00:25:49,550
to the end result you can see the purge

00:25:45,320 --> 00:25:51,860
become more stable it used to be when

00:25:49,550 --> 00:25:57,110
you look at a TPS every once awhile it

00:25:51,860 --> 00:26:00,070
does a purge then affects all the other

00:25:57,110 --> 00:26:03,650
tivity and just the GPS goes drop down

00:26:00,070 --> 00:26:08,540
very significantly now it's getting

00:26:03,650 --> 00:26:10,460
smoothed out also the chick pointing and

00:26:08,540 --> 00:26:14,260
you see their checkpointing activity

00:26:10,460 --> 00:26:14,260
it's not affected as well

00:26:29,639 --> 00:26:35,390
alright

00:26:31,640 --> 00:26:38,660
so any questions so far is that a lot of

00:26:35,390 --> 00:26:42,530
things I think it just I'm just rumbling

00:26:38,660 --> 00:26:49,870
through all the new features sometimes

00:26:42,530 --> 00:26:49,870
it's just getting tedious yeah yeah

00:26:57,100 --> 00:27:01,540
yeah yes

00:27:09,590 --> 00:27:19,470
most people use my IM for a few reasons

00:27:14,809 --> 00:27:22,590
where is the full text search if you use

00:27:19,470 --> 00:27:29,669
food textures we support the full text

00:27:22,590 --> 00:27:34,559
search studying 56 there's a is the Jews

00:27:29,669 --> 00:27:37,559
the camp table they have pretty fast a

00:27:34,559 --> 00:27:40,760
temp table because it's

00:27:37,559 --> 00:27:44,760
non-transactional so so they have this

00:27:40,760 --> 00:27:48,570
another reason is some GIS index that's

00:27:44,760 --> 00:27:52,799
in the my i am not in the nodb but we're

00:27:48,570 --> 00:27:54,899
going to support that as well so if it

00:27:52,799 --> 00:27:59,549
depends on your application whether you

00:27:54,899 --> 00:28:03,179
use fts full-text search whether use GIS

00:27:59,549 --> 00:28:08,639
index if they don't then you can just

00:28:03,179 --> 00:28:10,769
upgrade to 2d in ODP yeah so that's two

00:28:08,639 --> 00:28:19,340
different main reason most people while

00:28:10,769 --> 00:28:19,340
still using my IM what is a

00:28:22,950 --> 00:28:35,080
so that's kind of a ddl that we not yet

00:28:29,380 --> 00:28:39,280
support we do support studying support

00:28:35,080 --> 00:28:43,810
online at Colin job Collin those kind of

00:28:39,280 --> 00:28:47,860
things but we don't support merge table

00:28:43,810 --> 00:28:54,130
also the ax from the partition we don't

00:28:47,860 --> 00:28:58,600
have native partition table in nodb but

00:28:54,130 --> 00:29:03,660
merge table yeah we it's a it's a big

00:28:58,600 --> 00:29:07,540
problem for you guys and one okay okay

00:29:03,660 --> 00:29:12,180
so why you actually merge table he needs

00:29:07,540 --> 00:29:12,180
to be just saying to table you think

00:29:12,600 --> 00:29:21,370
okay okay okay yeah this is something

00:29:19,690 --> 00:29:23,470
that we can sync off I don't see this

00:29:21,370 --> 00:29:28,410
particular on the list that they have a

00:29:23,470 --> 00:29:31,330
huge list because they can't you okay

00:29:28,410 --> 00:29:33,910
okay so they have a huge list of deer

00:29:31,330 --> 00:29:36,400
difference between my IM and in ODP

00:29:33,910 --> 00:29:40,480
because we're going to obsolete my

00:29:36,400 --> 00:29:42,700
awesome so anything that particular to

00:29:40,480 --> 00:29:46,830
elias and a lot of users are using it

00:29:42,700 --> 00:29:46,830
and we can do support it you know DP

00:29:48,000 --> 00:29:57,090
okay one one more question are you okay

00:29:54,090 --> 00:29:57,090
yeah

00:29:59,460 --> 00:30:15,940
well we're going to eventually no longer

00:30:05,380 --> 00:30:19,770
support my eyes on what you're talking

00:30:15,940 --> 00:30:23,610
about the assistant able you my sequel

00:30:19,770 --> 00:30:26,500
yeah that's this some discussion on that

00:30:23,610 --> 00:30:28,510
because there are two different system

00:30:26,500 --> 00:30:37,350
table but that's seeing my sequel it's

00:30:28,510 --> 00:30:37,350
not them in my eyes n yes

00:30:39,730 --> 00:30:45,710
are you talking about if I am those kind

00:30:42,590 --> 00:30:58,430
of thing are you talking about that fim

00:30:45,710 --> 00:30:59,990
fire all those yes know that you see

00:30:58,430 --> 00:31:07,780
talking about stop procedure of those

00:30:59,990 --> 00:31:07,780
hanging my sequel oh yeah yeah yes I

00:31:11,860 --> 00:31:18,590
well the front hours are you talking

00:31:15,950 --> 00:31:22,150
about the metadata in the all you

00:31:18,590 --> 00:31:22,150
talking about that actually user data

00:31:22,480 --> 00:31:40,600
yeah oh ok ok so those will still be

00:31:35,210 --> 00:31:40,600
there those won't won't be going away

00:31:41,230 --> 00:31:48,020
well those eventually those kind of

00:31:44,120 --> 00:31:50,750
things do you move to you know DB those

00:31:48,020 --> 00:31:55,570
kind of system information actually

00:31:50,750 --> 00:31:55,570
those will move to you know TV as well

00:32:06,990 --> 00:32:13,830
okay yes

00:32:10,960 --> 00:32:13,830
yes

00:32:19,460 --> 00:32:34,720
okay good oh I think most people will

00:32:28,820 --> 00:32:38,630
start with a 55 a lot of people stealing

00:32:34,720 --> 00:32:43,250
5156 we're going to j this year so it's

00:32:38,630 --> 00:32:47,779
now not usually people don't do right

00:32:43,250 --> 00:33:00,190
away so a stable release is 55 yeah I

00:32:47,779 --> 00:33:00,190
think you should pass by one yeah

00:33:14,480 --> 00:33:17,480
ok

00:33:36,160 --> 00:33:40,570
you're talking about the flugtag search

00:33:48,240 --> 00:34:03,430
multi Colin auto equipment okay oh ok ok

00:33:58,390 --> 00:34:07,090
so yeah that's a good one so I don't

00:34:03,430 --> 00:34:11,500
know the these planning on this

00:34:07,090 --> 00:34:15,100
multicolored auto increment part it's

00:34:11,500 --> 00:34:18,220
all at least I it not on my radar so we

00:34:15,100 --> 00:34:20,470
were going to talk about it so so you

00:34:18,220 --> 00:34:28,179
have some application used is

00:34:20,470 --> 00:34:32,050
multicolored auto increment ok ok ok so

00:34:28,179 --> 00:34:36,149
I make notes of this and we we can we

00:34:32,050 --> 00:34:36,149
can check that for you

00:34:46,710 --> 00:34:56,159
okay so this is a benchmark on the linux

00:34:51,050 --> 00:35:01,920
that's a read-only you see 55 it's a lot

00:34:56,159 --> 00:35:04,410
more scalable than 51 so that's the

00:35:01,920 --> 00:35:07,460
company all the feature we just talked

00:35:04,410 --> 00:35:21,450
about and this is the end the results

00:35:07,460 --> 00:35:30,420
yeah yes oh right right so so there's

00:35:21,450 --> 00:35:33,570
small small difference thing 558 has

00:35:30,420 --> 00:35:37,109
deed balance the scalability well this

00:35:33,570 --> 00:35:53,369
is something I need to Charlie Yeah Yeah

00:35:37,109 --> 00:36:00,109
Yeah right way yeah yeah yeah that

00:35:53,369 --> 00:36:05,810
that's something that I need to check

00:36:00,109 --> 00:36:05,810
certainly yeah you have a quick eye oh

00:36:06,320 --> 00:36:18,839
good good good okay does this one is the

00:36:14,660 --> 00:36:21,660
read/write benchmark let's see it the

00:36:18,839 --> 00:36:24,380
purple yeah sometime it's it's it's

00:36:21,660 --> 00:36:24,380
still slower

00:36:29,240 --> 00:36:40,320
let's see yeah yeah most of time yeah

00:36:36,960 --> 00:36:45,170
this one looks like it's all you memory

00:36:40,320 --> 00:36:54,230
in Saudi memory so teaching gig of ram

00:36:45,170 --> 00:36:54,230
it's one min enroll yeah yeah

00:36:59,550 --> 00:37:13,470
okay so this is a scalability test it's

00:37:07,950 --> 00:37:16,650
5 54 and 55 3 and 5 1 again that's

00:37:13,470 --> 00:37:19,680
another are read-only scalability so

00:37:16,650 --> 00:37:22,260
it's it's compared to 51 definitely date

00:37:19,680 --> 00:37:28,320
so it's a lot faster and skill a lot

00:37:22,260 --> 00:37:31,940
better okay so that the next party is

00:37:28,320 --> 00:37:36,900
also we added a lot of performance

00:37:31,940 --> 00:37:40,430
diagnosis to in 55 why is the

00:37:36,900 --> 00:37:44,990
performance schema so remember the mutex

00:37:40,430 --> 00:37:50,930
table I showed you earlier so all the

00:37:44,990 --> 00:37:56,700
mutex relied locks threads and I oh and

00:37:50,930 --> 00:37:58,230
now India our performance schema so

00:37:56,700 --> 00:38:01,410
performance schema is by default

00:37:58,230 --> 00:38:05,100
building too but it's turned off by

00:38:01,410 --> 00:38:08,840
default the reason being that is the

00:38:05,100 --> 00:38:12,390
performance key myself has some

00:38:08,840 --> 00:38:16,620
performance impact on the server so now

00:38:12,390 --> 00:38:21,840
about to three percent impact so itself

00:38:16,620 --> 00:38:26,460
it's turned off by default so what you

00:38:21,840 --> 00:38:30,240
can get is add you do some selection

00:38:26,460 --> 00:38:32,520
into this performance DB in the

00:38:30,240 --> 00:38:35,250
performance DVD is called am you texting

00:38:32,520 --> 00:38:37,500
instance table so you can just do a

00:38:35,250 --> 00:38:42,270
select and see what kind of mutex get

00:38:37,500 --> 00:38:45,990
instrumented and this is what kind of

00:38:42,270 --> 00:38:51,170
actually slat a thread is running in

00:38:45,990 --> 00:38:54,060
your database okay you also can check

00:38:51,170 --> 00:38:57,660
whether the server is being prompting

00:38:54,060 --> 00:39:00,390
some particular mutex so this shows you

00:38:57,660 --> 00:39:04,350
the thread is running on particular are

00:39:00,390 --> 00:39:06,420
lying us whatever the I and what line

00:39:04,350 --> 00:39:11,620
and that's particular mutex is being

00:39:06,420 --> 00:39:18,070
blocked and you can also

00:39:11,620 --> 00:39:21,280
and do a history table shows you that in

00:39:18,070 --> 00:39:24,190
the running history what kind of mutex

00:39:21,280 --> 00:39:30,280
how much time they spend on each of

00:39:24,190 --> 00:39:33,580
those mutex are are the blue lock so

00:39:30,280 --> 00:39:35,830
this is an example I think we show the

00:39:33,580 --> 00:39:39,520
earlier adapt of Apple mutex is on the

00:39:35,830 --> 00:39:42,220
top and said ranking or different mutex

00:39:39,520 --> 00:39:47,110
so that's for a lot of for our own

00:39:42,220 --> 00:39:50,320
development if its advanced DBA like a

00:39:47,110 --> 00:39:53,530
lot of them in Facebook and Google they

00:39:50,320 --> 00:39:59,470
also do a lot of analysis on them those

00:39:53,530 --> 00:40:02,080
kind of a hot Code section does not

00:39:59,470 --> 00:40:05,230
excuse you what kind of mutex being held

00:40:02,080 --> 00:40:08,640
and most of the time ok so we also add

00:40:05,230 --> 00:40:08,640
another one called up

00:40:19,690 --> 00:40:25,390
so about this performance schema any of

00:40:22,480 --> 00:40:28,480
you guys interested from the user

00:40:25,390 --> 00:40:33,819
standpoint actually it's not useful to

00:40:28,480 --> 00:40:39,660
you I haven't even look at it most of my

00:40:33,819 --> 00:40:39,660
think okay

00:40:54,450 --> 00:41:03,250
index index lock yeah I think that's

00:41:00,900 --> 00:41:07,240
that's a big issue I think there will be

00:41:03,250 --> 00:41:09,609
a patch coming in 56 for the index lock

00:41:07,240 --> 00:41:13,630
was discussed that because a lot of

00:41:09,609 --> 00:41:19,869
people talking about this this it's a

00:41:13,630 --> 00:41:22,569
contention point so well the index

00:41:19,869 --> 00:41:24,609
locker is when you do a lot of those

00:41:22,569 --> 00:41:27,369
operations like spreading of those

00:41:24,609 --> 00:41:30,549
things a lot of those access they

00:41:27,369 --> 00:41:41,559
actually held the index lock it's a

00:41:30,549 --> 00:41:44,140
latch it's a latch on the index yeah so

00:41:41,559 --> 00:41:46,509
for nodb I think a lot of those

00:41:44,140 --> 00:41:53,670
operations including spreading and

00:41:46,509 --> 00:41:53,670
search it's now not very optimized yeah

00:41:59,990 --> 00:42:09,600
I noticed something I think I'm not

00:42:07,830 --> 00:42:12,750
showing the Facebook patch to have

00:42:09,600 --> 00:42:15,450
something that for this but it's it's

00:42:12,750 --> 00:42:22,550
having a big problem for them to always

00:42:15,450 --> 00:42:22,550
bring it up Yeah Yeah Yeah Yeah Yeah

00:42:24,920 --> 00:42:36,930
Yeah Yeah Yeah right so so y no debe

00:42:34,830 --> 00:42:39,570
spritz all those things is sometimes i

00:42:36,930 --> 00:42:41,970
lock the holding next so ideally you

00:42:39,570 --> 00:42:45,390
don't do that because you can do like

00:42:41,970 --> 00:42:49,110
those split cam button up you just have

00:42:45,390 --> 00:42:51,030
different latch locking mechanism than

00:42:49,110 --> 00:43:00,060
the one in search so that they don't

00:42:51,030 --> 00:43:02,760
don't they don't affect each other are

00:43:00,060 --> 00:43:08,390
you seeing the hash index all those at

00:43:02,760 --> 00:43:08,390
that people have adaptive hash index

00:43:15,520 --> 00:43:18,520
ok

00:43:24,320 --> 00:43:27,320
but

00:43:42,230 --> 00:43:51,320
yeah yeah because when you split it's

00:43:49,400 --> 00:43:53,990
now it's a whole index structure is

00:43:51,320 --> 00:44:06,770
changing so if you do something Buffalo

00:43:53,990 --> 00:44:10,130
to them to know how yeah ok so we also

00:44:06,770 --> 00:44:13,930
introduced a new monitor table in the

00:44:10,130 --> 00:44:17,570
information schema it it's a basic

00:44:13,930 --> 00:44:20,930
basically a counter table so it has a

00:44:17,570 --> 00:44:24,950
lot of counter now it's about almost

00:44:20,930 --> 00:44:28,910
over 200 counters in the metrics table

00:44:24,950 --> 00:44:32,030
so you can also select from this

00:44:28,910 --> 00:44:37,310
information schema in ODB metrics table

00:44:32,030 --> 00:44:42,590
and see a lot of counters most of those

00:44:37,310 --> 00:44:46,130
countries turned off by default except

00:44:42,590 --> 00:44:47,930
those in the show in ODB status so in

00:44:46,130 --> 00:44:50,660
the inner diva status used to be a lot

00:44:47,930 --> 00:44:53,660
of country like how many buffer page

00:44:50,660 --> 00:44:56,600
read how many puffer page right those

00:44:53,660 --> 00:45:01,880
will buddy for turned on so eventually

00:44:56,600 --> 00:45:05,930
we try to substitute the chill in ODB

00:45:01,880 --> 00:45:08,600
status variable to buy this metric

00:45:05,930 --> 00:45:13,640
stable so for other countries you can

00:45:08,600 --> 00:45:14,930
turn on and off using a set command so

00:45:13,640 --> 00:45:16,340
basically you can turn around

00:45:14,930 --> 00:45:19,070
particularly like you want to know a

00:45:16,340 --> 00:45:20,930
table being open and how many times you

00:45:19,070 --> 00:45:23,420
can just say set you know d be

00:45:20,930 --> 00:45:25,810
monitoring able serve your table open

00:45:23,420 --> 00:45:28,550
that's a particular counter name and

00:45:25,810 --> 00:45:31,400
once it turned on star to continue and

00:45:28,550 --> 00:45:34,190
you can turn it off and then you can see

00:45:31,400 --> 00:45:37,010
the result so you can know for a period

00:45:34,190 --> 00:45:39,830
of time how many'd it like a how many

00:45:37,010 --> 00:45:44,530
ddl how many exert happen how many

00:45:39,830 --> 00:45:44,530
deletes happen so

00:45:44,900 --> 00:45:51,330
yeah it's still global so we will want

00:45:47,730 --> 00:46:00,830
to make it in session level but country

00:45:51,330 --> 00:46:00,830
it's still global yeah yeah yeah

00:46:02,540 --> 00:46:12,140
ok so we finish 55 we coming to 56 so

00:46:09,800 --> 00:46:16,040
again we have a lot of performance

00:46:12,140 --> 00:46:18,890
featuring five six one notable you is

00:46:16,040 --> 00:46:22,730
that Colonel mutex being spirited you to

00:46:18,890 --> 00:46:25,270
a lot of different mutex so we used to

00:46:22,730 --> 00:46:29,270
have a so called Colonel mutex it's like

00:46:25,270 --> 00:46:32,180
a server meal text is being used for a

00:46:29,270 --> 00:46:34,250
lot of purpose so it'd become also

00:46:32,180 --> 00:46:37,160
congesting other than the buffer pool

00:46:34,250 --> 00:46:41,270
mutex we'll look at it this is a like

00:46:37,160 --> 00:46:43,250
also out in the top list so when we look

00:46:41,270 --> 00:46:45,710
at the performance to kemah results and

00:46:43,250 --> 00:46:50,210
we notice that then we decide to

00:46:45,710 --> 00:46:52,940
actually split for whatever a different

00:46:50,210 --> 00:46:55,370
purpose you look at it as lock mutex

00:46:52,940 --> 00:47:00,190
lock system attacks it used to be all

00:46:55,370 --> 00:47:05,660
used use Konami attacks so we split this

00:47:00,190 --> 00:47:08,450
kernel mutex into different mutants ok

00:47:05,660 --> 00:47:10,730
multithread purge so we just talked

00:47:08,450 --> 00:47:16,910
about the purge I'll Persia affecting

00:47:10,730 --> 00:47:20,450
the air mass read it becomes master

00:47:16,910 --> 00:47:23,450
against unstable and then we decide to

00:47:20,450 --> 00:47:26,780
have a dedicated approach threat now in

00:47:23,450 --> 00:47:31,120
this 56 release you have multiple purge

00:47:26,780 --> 00:47:35,710
thread so that give you a capability of

00:47:31,120 --> 00:47:38,300
purge quickly so you can tune this

00:47:35,710 --> 00:47:41,140
because if you have a lot of deletes

00:47:38,300 --> 00:47:45,910
happening sometimes purge cannot keep up

00:47:41,140 --> 00:47:51,080
so you now have multiple shredded purge

00:47:45,910 --> 00:47:53,300
so next is that also related to the

00:47:51,080 --> 00:47:59,380
above a poo contention work talked about

00:47:53,300 --> 00:48:02,540
in 55 this actually used to be a mutex

00:47:59,380 --> 00:48:06,290
guarded these structures in the buffer

00:48:02,540 --> 00:48:09,380
pool so we split in 55 we actually split

00:48:06,290 --> 00:48:11,300
into multiple buffer pool now in this

00:48:09,380 --> 00:48:14,930
one we found out that we can just make

00:48:11,300 --> 00:48:16,430
it a lot of things actually just read so

00:48:14,930 --> 00:48:19,610
we just make it this mutex

00:48:16,430 --> 00:48:22,070
into a latch so you have sheer latch

00:48:19,610 --> 00:48:25,370
which is basically if you have multiples

00:48:22,070 --> 00:48:28,130
rather than reading it you don't they

00:48:25,370 --> 00:48:30,590
don't break each other mutex you bark at

00:48:28,130 --> 00:48:34,340
each other no matter what you read are

00:48:30,590 --> 00:48:37,790
right so for large if everyone is just

00:48:34,340 --> 00:48:41,030
looking at it you can use shell latch so

00:48:37,790 --> 00:48:44,840
you apparently improves concurrency

00:48:41,030 --> 00:48:47,750
sespe are also the performance so those

00:48:44,840 --> 00:48:50,330
that is why I bring this is the shooting

00:48:47,750 --> 00:48:52,750
example we're doing how we're doing to

00:48:50,330 --> 00:48:57,650
improve the performance so that's very

00:48:52,750 --> 00:49:00,380
detail okay so another interesting

00:48:57,650 --> 00:49:03,500
feature is that I think it has come also

00:49:00,380 --> 00:49:06,440
from the picanha you can dump and

00:49:03,500 --> 00:49:08,690
restore buffer pool for faster startup

00:49:06,440 --> 00:49:11,270
basically you can dump dump the buffer

00:49:08,690 --> 00:49:14,090
pool and the next time you start it up

00:49:11,270 --> 00:49:18,140
it just bring those all these pages into

00:49:14,090 --> 00:49:21,770
the buffer it's like a pre-loading so

00:49:18,140 --> 00:49:24,710
that you study don't need to do a warm

00:49:21,770 --> 00:49:27,500
warm up so a lot of things a lot of

00:49:24,710 --> 00:49:29,630
times people do a warm-up and now you

00:49:27,500 --> 00:49:31,640
don't need to do warm up or just bring

00:49:29,630 --> 00:49:34,250
everything used to being the buffer pool

00:49:31,640 --> 00:49:37,640
and back into the puff up after you

00:49:34,250 --> 00:49:40,070
start up so it's it's like a your

00:49:37,640 --> 00:49:42,830
computer have a hibernate kind of

00:49:40,070 --> 00:49:44,630
function I can shut it down but before I

00:49:42,830 --> 00:49:47,450
that I dump everything in the buffer

00:49:44,630 --> 00:49:48,890
next time I'll read everything you used

00:49:47,450 --> 00:49:51,620
to be in the buff opposed to you in the

00:49:48,890 --> 00:49:56,950
buffer pool so that's that's also an

00:49:51,620 --> 00:49:56,950
interesting feature yeah

00:50:02,550 --> 00:50:10,150
well so it doesn't really dump the

00:50:07,810 --> 00:50:13,690
content of the buffer pool it's just

00:50:10,150 --> 00:50:16,390
saying that buffer poo is watch page so

00:50:13,690 --> 00:50:19,420
it records the actually the page number

00:50:16,390 --> 00:50:21,760
for each buffer so next time it just

00:50:19,420 --> 00:50:27,490
read this particular page into the

00:50:21,760 --> 00:50:30,820
buffer so what it says because whatever

00:50:27,490 --> 00:50:33,340
in the buffer is just replicate or

00:50:30,820 --> 00:50:35,950
whatever on the disk so I don't need to

00:50:33,340 --> 00:50:38,860
dump the content if its twenty four gig

00:50:35,950 --> 00:50:40,720
I don't need to actually dumped 24 get

00:50:38,860 --> 00:50:51,090
to the to the disk I just dumped the

00:50:40,720 --> 00:50:51,090
page number yeah yeah yes yes

00:51:02,410 --> 00:51:08,620
yeah yeah

00:51:11,410 --> 00:51:17,380
ok so there's is a the next one is

00:51:15,099 --> 00:51:21,819
reduced contention though during the

00:51:17,380 --> 00:51:24,369
file extension so we extend if I every

00:51:21,819 --> 00:51:26,170
once awhile one lot of the space so

00:51:24,369 --> 00:51:28,329
whenever you do that you hold the mutex

00:51:26,170 --> 00:51:31,720
and that Brock's all the aisle happening

00:51:28,329 --> 00:51:34,990
so now they have using a different

00:51:31,720 --> 00:51:39,130
structure using a flag so making this

00:51:34,990 --> 00:51:40,930
mutex whole time to a very short time

00:51:39,130 --> 00:51:43,960
and we just turn on this flag saying

00:51:40,930 --> 00:51:47,170
this file is being extended and we don't

00:51:43,960 --> 00:51:53,970
block other IO happening in this

00:51:47,170 --> 00:51:58,089
particular server next one is the

00:51:53,970 --> 00:52:03,369
multiple range read and the index

00:51:58,089 --> 00:52:06,599
condition push down so that's also been

00:52:03,369 --> 00:52:09,640
down around with my sequel so in the QP

00:52:06,599 --> 00:52:13,270
it's a cooperation which query

00:52:09,640 --> 00:52:17,730
processing and the nodb so when you have

00:52:13,270 --> 00:52:21,730
a query that involve a lot of index

00:52:17,730 --> 00:52:23,349
basically do a multiple range read so

00:52:21,730 --> 00:52:26,829
you're just saying I'm going to read

00:52:23,349 --> 00:52:30,029
this range index and arrange index then

00:52:26,829 --> 00:52:34,059
that one come to in ODP we look at the

00:52:30,029 --> 00:52:36,220
Disco Brock of the one we can't agree we

00:52:34,059 --> 00:52:40,980
just sort them so that it's no longer

00:52:36,220 --> 00:52:40,980
random it's become a sequential read

00:52:50,270 --> 00:53:11,150
who has that I'm a real DB oh okay so so

00:53:05,580 --> 00:53:11,150
they actually sort on the primary key

00:53:16,100 --> 00:53:22,290
okay okay so we don't have that right

00:53:18,630 --> 00:53:25,560
now but we actually saw there on the on

00:53:22,290 --> 00:53:28,080
the blocks on the physical blocks so

00:53:25,560 --> 00:53:32,460
it's kind of similar because one is so

00:53:28,080 --> 00:53:35,370
down primary key which also depends on

00:53:32,460 --> 00:53:37,890
how frag empowerment you your your

00:53:35,370 --> 00:53:41,400
primary key is because still can be

00:53:37,890 --> 00:53:45,380
physically in different places right so

00:53:41,400 --> 00:53:48,060
but we saw down the physical block

00:53:45,380 --> 00:53:50,820
number so it's even better I think than

00:53:48,060 --> 00:53:52,170
the primary key because you have so did

00:53:50,820 --> 00:53:54,630
the primary key but it doesn't

00:53:52,170 --> 00:54:04,220
necessarily means that they are started

00:53:54,630 --> 00:54:04,220
on yeah okay okay yeah

00:54:06,170 --> 00:54:16,980
oh I think oh okay I see yeah yeah

00:54:14,609 --> 00:54:23,490
that's something we can also consider so

00:54:16,980 --> 00:54:25,590
yeah that's an interesting one okay I

00:54:23,490 --> 00:54:29,369
need to go faster they only have a few

00:54:25,590 --> 00:54:31,619
minutes left so index push down index

00:54:29,369 --> 00:54:35,940
condition push down that's I think a

00:54:31,619 --> 00:54:38,310
previous talker also talked about so

00:54:35,940 --> 00:54:40,800
instead of fetching the whole row for

00:54:38,310 --> 00:54:44,190
the result and the processing the query

00:54:40,800 --> 00:54:47,220
processing there we actually just get

00:54:44,190 --> 00:54:52,640
whatever all you need in the storage

00:54:47,220 --> 00:54:57,570
layer ok so we also added a lot of a

00:54:52,640 --> 00:55:00,599
table diagnostic table India in this

00:54:57,570 --> 00:55:02,910
release basically we also can you can

00:55:00,599 --> 00:55:04,800
dump the hope of apple into an

00:55:02,910 --> 00:55:06,869
information schema table so you look at

00:55:04,800 --> 00:55:09,030
a how many index table for which

00:55:06,869 --> 00:55:12,359
particular table are eating the a buffer

00:55:09,030 --> 00:55:14,310
pool so i think facebook using that are

00:55:12,359 --> 00:55:17,940
quite a bit to study their application

00:55:14,310 --> 00:55:21,330
so how how the buffer pool looks like at

00:55:17,940 --> 00:55:24,030
that time so we're also at the system

00:55:21,330 --> 00:55:28,410
tables information schema matches table

00:55:24,030 --> 00:55:31,680
we talked about crc32 that's a checksum

00:55:28,410 --> 00:55:35,369
now there's a hardware support for the

00:55:31,680 --> 00:55:37,859
checksum so we actually utilize that so

00:55:35,369 --> 00:55:43,349
you can do a faster checksum on that

00:55:37,859 --> 00:55:47,730
page ok so we also special handle the

00:55:43,349 --> 00:55:51,089
read-only transactions so now if you a

00:55:47,730 --> 00:55:54,720
read-only transaction now i can read

00:55:51,089 --> 00:55:57,930
only transaction we we will mark them

00:55:54,720 --> 00:56:01,589
and so that it won't be used to to

00:55:57,930 --> 00:56:03,599
generate the reader view relieve you

00:56:01,589 --> 00:56:06,720
won't filter out those read-only

00:56:03,599 --> 00:56:08,400
transactions so I also read only

00:56:06,720 --> 00:56:11,160
transaction sometimes it doesn't need a

00:56:08,400 --> 00:56:14,160
lot of those kind of lock so we also

00:56:11,160 --> 00:56:17,430
skip that so it you can see a dramatic

00:56:14,160 --> 00:56:20,490
also dramatic improvement

00:56:17,430 --> 00:56:26,940
in terms of the point is select

00:56:20,490 --> 00:56:33,059
read-only transactions so it's very

00:56:26,940 --> 00:56:38,250
obvious improvement okay so these are a

00:56:33,059 --> 00:56:40,380
list of a small improvement from on the

00:56:38,250 --> 00:56:43,440
also problem of performance-related us

00:56:40,380 --> 00:56:46,980
for example deadlock detection is p a

00:56:43,440 --> 00:56:50,160
problem so we do some optimization in

00:56:46,980 --> 00:56:54,390
terms of this graph search is in some

00:56:50,160 --> 00:56:57,349
cases it doesn't need to be recursive so

00:56:54,390 --> 00:57:02,099
also make a page size smaller because

00:56:57,349 --> 00:57:06,089
SSD sometimes it's as a 4k unit so we

00:57:02,099 --> 00:57:13,230
make it you have can have 4k page size

00:57:06,089 --> 00:57:22,380
so you don't need to read us for 16k the

00:57:13,230 --> 00:57:26,210
watch mutex of the transaction sisti

00:57:22,380 --> 00:57:33,660
yeah so why a change to a music yeah

00:57:26,210 --> 00:57:36,210
yeah yeah so but RW ok it's more

00:57:33,660 --> 00:57:37,890
expensive when you try to get a double

00:57:36,210 --> 00:57:41,790
lock if you have like this kind of

00:57:37,890 --> 00:57:44,670
transaction this kind of access to a

00:57:41,790 --> 00:57:52,369
structure quickly you just use a mutex

00:57:44,670 --> 00:57:56,520
instead of other blog yeah yeah okay so

00:57:52,369 --> 00:58:00,089
this is a position stats will be turned

00:57:56,520 --> 00:58:04,950
on by default this position stacks there

00:58:00,089 --> 00:58:11,030
is something new in 55 and also rushing

00:58:04,950 --> 00:58:14,180
they tune the frosting algorithm quickly

00:58:11,030 --> 00:58:17,790
rushing used to be unstable it's like

00:58:14,180 --> 00:58:23,040
also it's it's spiked every once a while

00:58:17,790 --> 00:58:25,140
so they have new algorithm make the

00:58:23,040 --> 00:58:28,440
freshman lamaze table so that there is a

00:58:25,140 --> 00:58:30,540
one the major four five major feature

00:58:28,440 --> 00:58:33,900
four five six is the online operation

00:58:30,540 --> 00:58:38,850
so you can do a lot of online operation

00:58:33,900 --> 00:58:42,620
in 56 release you can reputed index you

00:58:38,850 --> 00:58:47,820
can add job column change low format

00:58:42,620 --> 00:58:50,900
rename Colin add foreign key there's

00:58:47,820 --> 00:58:54,330
some catch on the foreign key part but

00:58:50,900 --> 00:59:00,150
still a lot of operation can be online

00:58:54,330 --> 00:59:08,850
for the dbl okay so this is a quick show

00:59:00,150 --> 00:59:13,100
on the oltp rewrite difference so we

00:59:08,850 --> 00:59:19,260
removed lock opens at seemed my sequel

00:59:13,100 --> 00:59:21,600
so it shows pretty good result alright

00:59:19,260 --> 00:59:23,940
so another thing is about no sequel

00:59:21,600 --> 00:59:25,680
access to energy be with memcache DS or

00:59:23,940 --> 00:59:29,040
I have another talk in the afternoon

00:59:25,680 --> 00:59:32,040
five o'clock something about this

00:59:29,040 --> 00:59:37,190
particular memcache the access to the

00:59:32,040 --> 00:59:41,850
innodb so you see some some results and

00:59:37,190 --> 00:59:45,720
fairly fast I almost similar to memcache

00:59:41,850 --> 00:59:49,350
to yourself that's down by you should

00:59:45,720 --> 00:59:51,630
nori who is downloads handle sake I'm

00:59:49,350 --> 00:59:54,420
not sure you read his his article on the

00:59:51,630 --> 00:59:57,840
handle sake so that's the benchmark he

00:59:54,420 --> 01:00:00,420
did we almost even faster than the

00:59:57,840 --> 01:00:04,470
handle or socket so I will go through

01:00:00,420 --> 01:00:08,550
that in the afternoon so okay good so we

01:00:04,470 --> 01:00:11,120
finish that almost on time and any more

01:00:08,550 --> 01:00:11,120
question

01:00:13,940 --> 01:00:20,170
all right okay thanks everyone yeah okay

01:00:57,400 --> 01:01:03,820
how's that sigh every way this is the

01:01:00,520 --> 01:01:05,980
way to better utilize all your resources

01:01:03,820 --> 01:01:09,430
and it makes managing all your resources

01:01:05,980 --> 01:01:13,260
pretty easy all of the innovation is

01:01:09,430 --> 01:01:16,780
happening in open source the

01:01:13,260 --> 01:01:18,610
collaborative nature and of the you know

01:01:16,780 --> 01:01:20,710
of the community and the speed at which

01:01:18,610 --> 01:01:22,690
these are these you know these these

01:01:20,710 --> 01:01:25,000
deficiencies these bugs are getting

01:01:22,690 --> 01:01:27,850
discovered and then fixed is the thing

01:01:25,000 --> 01:01:30,850
that really shows the power of the of

01:01:27,850 --> 01:01:33,300
the open source community it is global

01:01:30,850 --> 01:01:36,850
and it's definitely because of the users

01:01:33,300 --> 01:01:42,730
community people are extremely friendly

01:01:36,850 --> 01:01:44,560
and almost ready to help if you go an

01:01:42,730 --> 01:01:46,750
entire see any day you'll see these guys

01:01:44,560 --> 01:01:49,390
helping each other out and they're all

01:01:46,750 --> 01:01:51,070
doing it like in a selfless manner the

01:01:49,390 --> 01:01:54,090
product is transparent for everyone

01:01:51,070 --> 01:01:57,250
everyone can look at the code base

01:01:54,090 --> 01:01:59,490
everyone can see how close that is being

01:01:57,250 --> 01:02:05,020
built nothing nothing is proprietary

01:01:59,490 --> 01:02:07,600
everything is open in many ways it's

01:02:05,020 --> 01:02:12,100
absolutely vital to the the unborn

01:02:07,600 --> 01:02:16,300
health CloudStack the most exciting

01:02:12,100 --> 01:02:19,130
event in recent memory for he was our

01:02:16,300 --> 01:02:21,770
first developer boot camp

01:02:19,130 --> 01:02:24,440
and our call gave people I gave me two

01:02:21,770 --> 01:02:28,370
weeks notice to come attend I was

01:02:24,440 --> 01:02:32,630
expecting 25 or 30 people so we ended up

01:02:28,370 --> 01:02:35,390
with 87 people and had to go get board

01:02:32,630 --> 01:02:37,910
chairs in the room twice everything

01:02:35,390 --> 01:02:41,180
within cloud computing is commodity and

01:02:37,910 --> 01:02:44,240
is open source and so I don't think that

01:02:41,180 --> 01:02:46,010
you will you'll see anywhere where open

01:02:44,240 --> 01:02:49,040
source is not pervasive in cloud

01:02:46,010 --> 01:02:51,590
computing and so i think it's i think

01:02:49,040 --> 01:02:53,090
it's an assumption i think when you talk

01:02:51,590 --> 01:02:54,230
about cloud computing you're really

01:02:53,090 --> 01:02:59,780
talking about open source cloud

01:02:54,230 --> 01:03:02,810
computing cloud sac is a robust solution

01:02:59,780 --> 01:03:04,940
for large deployments you'll have dozens

01:03:02,810 --> 01:03:09,200
of data centers and thousands of servers

01:03:04,940 --> 01:03:11,900
in each data centers these hardware is

01:03:09,200 --> 01:03:15,380
going to fail and CloudStack is designed

01:03:11,900 --> 01:03:18,080
to handle number one that mass scale

01:03:15,380 --> 01:03:21,260
number two it's designed to handle the

01:03:18,080 --> 01:03:23,510
failure that inevitably happens in large

01:03:21,260 --> 01:03:27,320
deployments we started working on

01:03:23,510 --> 01:03:30,680
contact over four years ago and it was

01:03:27,320 --> 01:03:33,350
the original set of people working on it

01:03:30,680 --> 01:03:37,460
had a background of delivering software

01:03:33,350 --> 01:03:41,690
telcos and service providers lots of QA

01:03:37,460 --> 01:03:45,320
lots of users actually using it high

01:03:41,690 --> 01:03:48,410
availability is the key feature multiple

01:03:45,320 --> 01:03:50,420
hypervisors support different network

01:03:48,410 --> 01:03:53,090
models you can pick up whatever suits

01:03:50,420 --> 01:03:55,370
you better while step management server

01:03:53,090 --> 01:03:59,060
can be deployed in different physical

01:03:55,370 --> 01:04:00,710
machines it definitely has a huge

01:03:59,060 --> 01:04:05,690
footprint it's being deployed everywhere

01:04:00,710 --> 01:04:08,270
there's a major movie studio that they

01:04:05,690 --> 01:04:11,570
were using cloudstack they were using it

01:04:08,270 --> 01:04:13,550
to transcode video and i thought that

01:04:11,570 --> 01:04:15,200
was terribly fascinating what i found

01:04:13,550 --> 01:04:18,470
more fascinating is what they did during

01:04:15,200 --> 01:04:21,260
lunch where they would spin up you know

01:04:18,470 --> 01:04:22,610
50 or 60 game servers then as soon as

01:04:21,260 --> 01:04:23,240
lunch was over they would destroy all

01:04:22,610 --> 01:04:26,330
the instance

01:04:23,240 --> 01:04:29,030
compacta doing a little work CloudStack

01:04:26,330 --> 01:04:30,890
is vast it touches so many different

01:04:29,030 --> 01:04:32,690
aspects and there's no one person that's

01:04:30,890 --> 01:04:36,350
kind of like a master of all those

01:04:32,690 --> 01:04:39,230
realms I think clouds stack as a project

01:04:36,350 --> 01:04:41,510
is going to be one of the leaders simply

01:04:39,230 --> 01:04:46,190
because it's some of the most feature

01:04:41,510 --> 01:04:50,720
pulling and and robust platforms out

01:04:46,190 --> 01:04:53,200
they were Adam senior living for the

01:04:50,720 --> 01:04:53,200
clouds dag

01:05:05,999 --> 01:05:08,059
you

01:05:11,380 --> 01:05:16,460
when we created asterisk over a decade

01:05:14,120 --> 01:05:18,410
ago we could not have imagined that

01:05:16,460 --> 01:05:20,630
asterisk would not only become the most

01:05:18,410 --> 01:05:22,760
widely adopted open source communication

01:05:20,630 --> 01:05:24,800
software on the planet but that it would

01:05:22,760 --> 01:05:27,320
impact the entire industry in the way

01:05:24,800 --> 01:05:29,300
that it has today asterisk has found its

01:05:27,320 --> 01:05:31,940
way in the more than 170 countries and

01:05:29,300 --> 01:05:33,890
virtually every fortune 1000 company the

01:05:31,940 --> 01:05:35,990
success of asterisk has enabled a

01:05:33,890 --> 01:05:37,370
transition of power from the hands of

01:05:35,990 --> 01:05:39,650
the traditional proprietary phone

01:05:37,370 --> 01:05:42,050
vendors into the hands of the users and

01:05:39,650 --> 01:05:44,000
administrators of phone systems using

01:05:42,050 --> 01:05:45,230
this power our customers have created

01:05:44,000 --> 01:05:47,150
all sorts of business changing

01:05:45,230 --> 01:05:49,010
applications from small office phone

01:05:47,150 --> 01:05:51,530
systems to mission-critical call centers

01:05:49,010 --> 01:05:53,120
the international carrier networks in

01:05:51,530 --> 01:05:54,920
fact there's even an entire country

01:05:53,120 --> 01:05:57,500
those communications infrastructure runs

01:05:54,920 --> 01:05:59,450
on esters the gym has always been about

01:05:57,500 --> 01:06:01,160
creating technology that expands

01:05:59,450 --> 01:06:03,320
communications capabilities in ways that

01:06:01,160 --> 01:06:04,520
we could never have imagined and that's

01:06:03,320 --> 01:06:07,280
part of what's game-changing about

01:06:04,520 --> 01:06:09,620
Digium today we're doing it again this

01:06:07,280 --> 01:06:11,690
time by introducing a new family of HD

01:06:09,620 --> 01:06:13,820
IP phones that extends control of the

01:06:11,690 --> 01:06:15,560
user all the way to the desktop the

01:06:13,820 --> 01:06:17,270
launch of these new products represents

01:06:15,560 --> 01:06:19,370
the next phase indigenous history of

01:06:17,270 --> 01:06:21,800
innovation these are the first and only

01:06:19,370 --> 01:06:23,480
IP phones designed to fully leverage the

01:06:21,800 --> 01:06:25,040
power of esters when we first discussed

01:06:23,480 --> 01:06:27,080
our expectations for building a family

01:06:25,040 --> 01:06:29,240
of phones for use with asterisk our

01:06:27,080 --> 01:06:30,980
requirements were pretty simple we asked

01:06:29,240 --> 01:06:32,600
the team to build the phones such that

01:06:30,980 --> 01:06:34,820
they were easy to install integrate

01:06:32,600 --> 01:06:36,650
provision and use I think you'll soon

01:06:34,820 --> 01:06:39,200
agree our engineers have delivered on

01:06:36,650 --> 01:06:40,850
that goal user feedback is validating

01:06:39,200 --> 01:06:42,950
that when it comes to operation with

01:06:40,850 --> 01:06:45,380
astro space systems including our own

01:06:42,950 --> 01:06:47,960
Switchvox based product these are the

01:06:45,380 --> 01:06:49,280
easiest to use best integrated most

01:06:47,960 --> 01:06:51,860
interoperable products on the market

01:06:49,280 --> 01:06:53,830
today the Digium family phones will

01:06:51,860 --> 01:06:55,940
initially include three IP des hommes

01:06:53,830 --> 01:06:57,830
uniquely designed to complement any

01:06:55,940 --> 01:06:59,720
asterisk or switch box based solution

01:06:57,830 --> 01:07:02,390
these phones are different for a number

01:06:59,720 --> 01:07:05,030
of reasons first there is clue sively

01:07:02,390 --> 01:07:06,470
designed for use with esters secondly

01:07:05,030 --> 01:07:08,080
we've made it really easy to

01:07:06,470 --> 01:07:10,460
autodiscover and provision the phones

01:07:08,080 --> 01:07:12,560
next we've made it easy for the phones

01:07:10,460 --> 01:07:13,970
to access information inside of asterisk

01:07:12,560 --> 01:07:16,119
allowing tight cup

01:07:13,970 --> 01:07:18,080
between an application and the phone

01:07:16,119 --> 01:07:20,240
additionally we've created an

01:07:18,080 --> 01:07:22,369
applications engine that allows users

01:07:20,240 --> 01:07:24,950
and developers to create and run their

01:07:22,369 --> 01:07:27,020
own apps on the following and finally

01:07:24,950 --> 01:07:29,090
we've done all of this at a very

01:07:27,020 --> 01:07:30,770
compelling price point at digium we're

01:07:29,090 --> 01:07:32,570
always thinking of ways to give our

01:07:30,770 --> 01:07:34,940
customers the best value in business

01:07:32,570 --> 01:07:36,800
phone systems and also give them the

01:07:34,940 --> 01:07:38,960
power to create their own solutions or

01:07:36,800 --> 01:07:40,849
any communications challenge well

01:07:38,960 --> 01:07:42,500
continue to push the boundaries not only

01:07:40,849 --> 01:07:44,570
to make Astros cooler faster and more

01:07:42,500 --> 01:07:46,190
technologically feature-rich but to make

01:07:44,570 --> 01:07:48,680
asterisk and what communications even

01:07:46,190 --> 01:07:52,359
easier and together we'll change the way

01:07:48,680 --> 01:07:52,359

YouTube URL: https://www.youtube.com/watch?v=S9ooK3H-syA


