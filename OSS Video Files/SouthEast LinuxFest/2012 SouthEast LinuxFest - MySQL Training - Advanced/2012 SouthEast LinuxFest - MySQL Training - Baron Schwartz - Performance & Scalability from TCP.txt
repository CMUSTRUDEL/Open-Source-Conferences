Title: 2012 SouthEast LinuxFest - MySQL Training - Baron Schwartz - Performance & Scalability from TCP
Publication date: 2014-01-16
Playlist: 2012 SouthEast LinuxFest - MySQL Training - Advanced
Description: 
	2012 SouthEast LinuxFest
MySQL Training - Advanced
Baron Schwartz
Extracting Performance and Scalability Metrics from TCP
Captions: 
	00:00:00,000 --> 00:00:05,279
the following presentation was recorded

00:00:02,490 --> 00:00:08,040
the 2012 southeast linux fest in

00:00:05,279 --> 00:00:10,410
charlotte north carolina it is licensed

00:00:08,040 --> 00:00:12,090
under a creative commons license for

00:00:10,410 --> 00:00:16,859
more information about the southeast

00:00:12,090 --> 00:00:19,230
linux fest visit www.lend expense org

00:00:16,859 --> 00:00:21,320
the southeast linux fest would like to

00:00:19,230 --> 00:00:23,279
thank the following diamond sponsors in

00:00:21,320 --> 00:00:28,890
2012 for helping make these videos

00:00:23,279 --> 00:00:30,300
possible so quick introduction I'm Baron

00:00:28,890 --> 00:00:32,520
schwartz i'm the author of high

00:00:30,300 --> 00:00:34,590
performance mysql and i've written a

00:00:32,520 --> 00:00:37,430
number of tools for mysql including mont

00:00:34,590 --> 00:00:40,379
kid which is now in Percona toolkit

00:00:37,430 --> 00:00:42,570
percona provides support services

00:00:40,379 --> 00:00:45,450
software and engineering for the mysql

00:00:42,570 --> 00:00:47,820
database server we also provide the only

00:00:45,450 --> 00:00:51,899
open source hot backup utility for mysql

00:00:47,820 --> 00:00:53,070
and we also create pregunto server which

00:00:51,899 --> 00:00:57,000
is a performance and functionality

00:00:53,070 --> 00:00:59,399
enhanced version of mysql if you've

00:00:57,000 --> 00:01:01,430
heard of maria DB per kind of server

00:00:59,399 --> 00:01:06,740
maria DB and drizzle are the three major

00:01:01,430 --> 00:01:09,390
variations of mysql so enough about us

00:01:06,740 --> 00:01:12,390
i'm going to cover sort of a two-part

00:01:09,390 --> 00:01:16,619
talk today i'll be explaining how you

00:01:12,390 --> 00:01:18,930
can use tcp packet headers to get sort

00:01:16,619 --> 00:01:20,909
of a black box view of performance and

00:01:18,930 --> 00:01:23,369
scalability characteristics into your

00:01:20,909 --> 00:01:25,880
system and then in the second part i'll

00:01:23,369 --> 00:01:29,240
be showing you how you can apply a

00:01:25,880 --> 00:01:31,500
mathematical model to that to forecast

00:01:29,240 --> 00:01:33,509
beyond what you can observe which is

00:01:31,500 --> 00:01:36,049
kind of the holy grail of capacity

00:01:33,509 --> 00:01:38,850
planning and performance analysis is to

00:01:36,049 --> 00:01:40,320
to measure within a certain domain and

00:01:38,850 --> 00:01:44,310
then to forecast how the system might

00:01:40,320 --> 00:01:48,090
behave beyond that domain so I like

00:01:44,310 --> 00:01:49,740
tcp/ip headers tcp/ip headers are nice

00:01:48,090 --> 00:01:51,899
because you can capture them easily and

00:01:49,740 --> 00:01:54,360
on any platform and there are lots of

00:01:51,899 --> 00:01:55,950
ways that you can get them you can get

00:01:54,360 --> 00:01:57,750
them for example if you have access only

00:01:55,950 --> 00:01:59,880
to a web server and you want to know how

00:01:57,750 --> 00:02:02,040
the database server is behaving you can

00:01:59,880 --> 00:02:05,280
actually capture the the packets on the

00:02:02,040 --> 00:02:07,140
web server itself and minus the network

00:02:05,280 --> 00:02:09,929
delay you have something similar to what

00:02:07,140 --> 00:02:10,920
happens on the database server if you

00:02:09,929 --> 00:02:13,530
have

00:02:10,920 --> 00:02:15,000
a man poured on a network device in the

00:02:13,530 --> 00:02:16,500
middle you can capture off of there so

00:02:15,000 --> 00:02:19,020
basically you can get lots and lots of

00:02:16,500 --> 00:02:21,959
data with very little impact to anything

00:02:19,020 --> 00:02:24,599
and there are lots of network monitoring

00:02:21,959 --> 00:02:26,730
systems that take advantage of this I'm

00:02:24,599 --> 00:02:28,530
only using the TCP dump tool here I'm

00:02:26,730 --> 00:02:30,540
not doing anything fancy this is just

00:02:28,530 --> 00:02:35,430
it's all very straightforward vanilla

00:02:30,540 --> 00:02:37,500
unix commands and everything that i'll

00:02:35,430 --> 00:02:42,150
show you is possible to do with open

00:02:37,500 --> 00:02:43,560
source so the TCP IP packet headers are

00:02:42,150 --> 00:02:45,750
the part that I'm going to be most

00:02:43,560 --> 00:02:48,000
interested in today i have written

00:02:45,750 --> 00:02:49,980
protocol decoders for the full mysql

00:02:48,000 --> 00:02:51,810
protocol so I I know how to dig deep

00:02:49,980 --> 00:02:54,930
into the packets and get out even the

00:02:51,810 --> 00:02:56,489
encrypted or the compressed protocol I

00:02:54,930 --> 00:02:59,640
know how to get out all the data that's

00:02:56,489 --> 00:03:00,600
in the stream but I don't need that for

00:02:59,640 --> 00:03:02,069
what I'm going to be showing you today

00:03:00,600 --> 00:03:03,810
and in fact I don't even care what

00:03:02,069 --> 00:03:06,840
protocol it is as long as it's a call

00:03:03,810 --> 00:03:10,019
and response synchronous protocol all i

00:03:06,840 --> 00:03:12,030
care is when something got sent to the

00:03:10,019 --> 00:03:13,890
server and when the response came back i

00:03:12,030 --> 00:03:17,160
don't care about the the payload at all

00:03:13,890 --> 00:03:20,000
and in fact sometimes there are security

00:03:17,160 --> 00:03:23,220
or compliance concerns in play such that

00:03:20,000 --> 00:03:24,989
you couldn't get access to all of that

00:03:23,220 --> 00:03:26,489
data but you can get access to the

00:03:24,989 --> 00:03:29,489
headers because all they contain is IP

00:03:26,489 --> 00:03:31,290
addresses and port numbers so so there's

00:03:29,489 --> 00:03:35,670
nothing usually very privileged about

00:03:31,290 --> 00:03:36,959
that data and if you don't have if you

00:03:35,670 --> 00:03:38,430
don't have access to the machines

00:03:36,959 --> 00:03:42,480
themselves you can usually get someone

00:03:38,430 --> 00:03:45,390
else to give you the data easily so in

00:03:42,480 --> 00:03:47,790
this protocol like MySQL with Colin

00:03:45,390 --> 00:03:50,549
response semantics where somebody makes

00:03:47,790 --> 00:03:53,010
a call to the server and stops and waits

00:03:50,549 --> 00:03:57,109
until the response comes back IE no

00:03:53,010 --> 00:04:00,870
pipelining or no fire and forget as

00:03:57,109 --> 00:04:04,709
MongoDB allows you to do for example you

00:04:00,870 --> 00:04:08,030
can time the departure of the of the

00:04:04,709 --> 00:04:10,410
query from your application server and

00:04:08,030 --> 00:04:11,700
time the arrival back from the server

00:04:10,410 --> 00:04:15,690
and you can say that was the round-trip

00:04:11,700 --> 00:04:18,780
time of the whole of the whole query or

00:04:15,690 --> 00:04:21,750
you can go to the to the database server

00:04:18,780 --> 00:04:23,099
and time they arrival there and the

00:04:21,750 --> 00:04:23,580
departure there and say that was the

00:04:23,099 --> 00:04:25,289
time of the

00:04:23,580 --> 00:04:28,620
query now this may not be the whole

00:04:25,289 --> 00:04:30,870
truth for example the time of the first

00:04:28,620 --> 00:04:33,210
packet back from the server to the to

00:04:30,870 --> 00:04:34,560
the client that made a request may not

00:04:33,210 --> 00:04:36,870
be the time that you want to call the

00:04:34,560 --> 00:04:39,659
entire execution time of the query you

00:04:36,870 --> 00:04:41,909
might want a time from the last inbound

00:04:39,659 --> 00:04:43,020
packet to the last down Valton packet

00:04:41,909 --> 00:04:45,150
for example and there are some

00:04:43,020 --> 00:04:49,050
complexities there but in the general

00:04:45,150 --> 00:04:55,530
case if you time from the last inbound

00:04:49,050 --> 00:04:57,479
packet of to the server and and then say

00:04:55,530 --> 00:04:58,949
that the the query is finished when the

00:04:57,479 --> 00:05:00,419
first outbound packet comes back the

00:04:58,949 --> 00:05:06,930
other direction that tends to work

00:05:00,419 --> 00:05:08,669
fairly well and so what we get from tcp

00:05:06,930 --> 00:05:11,219
IP packet headers is just the IP address

00:05:08,669 --> 00:05:13,289
and the port and then TCP dump by

00:05:11,219 --> 00:05:15,120
observing gives you the time stamps the

00:05:13,289 --> 00:05:17,729
time stamps have some there's some

00:05:15,120 --> 00:05:20,550
imprecision there I have never really

00:05:17,729 --> 00:05:22,439
measured how much but that time stamps

00:05:20,550 --> 00:05:24,719
that you'll get printed out from TCB

00:05:22,439 --> 00:05:26,340
dump have six decimal places of

00:05:24,719 --> 00:05:27,990
precision you're not actually getting

00:05:26,340 --> 00:05:30,539
six decimal places probably more like

00:05:27,990 --> 00:05:32,580
four as a guess because there's some

00:05:30,539 --> 00:05:36,629
some variation in when the colonel

00:05:32,580 --> 00:05:37,830
processes packets and so forth so you

00:05:36,629 --> 00:05:39,750
can take those what I call the

00:05:37,830 --> 00:05:40,919
fundamental metrics which is the arrival

00:05:39,750 --> 00:05:43,409
on the departure and the session

00:05:40,919 --> 00:05:44,909
identifier and you can derive more

00:05:43,409 --> 00:05:47,460
metrics from them in fact you can pretty

00:05:44,909 --> 00:05:50,789
much build everything out of this so you

00:05:47,460 --> 00:05:52,680
can chop a time window and out of your

00:05:50,789 --> 00:05:54,210
stream and say here's the beginning of

00:05:52,680 --> 00:05:56,550
my observation interval here's the end

00:05:54,210 --> 00:05:57,960
and now we know the elapsed time and we

00:05:56,550 --> 00:05:59,789
know how many things happen in that

00:05:57,960 --> 00:06:03,449
elapsed time so you get queries per

00:05:59,789 --> 00:06:05,520
second which is throughput throughput as

00:06:03,449 --> 00:06:08,279
in number events rather than throughput

00:06:05,520 --> 00:06:10,050
as in size of events like bandwidth we

00:06:08,279 --> 00:06:12,960
can calculate the busy time or the

00:06:10,050 --> 00:06:15,449
portion of the time during which the

00:06:12,960 --> 00:06:17,610
system had at least one request resident

00:06:15,449 --> 00:06:19,529
and the total execution time of

00:06:17,610 --> 00:06:22,039
everything within that window just by

00:06:19,529 --> 00:06:23,849
subtracting arrival and completions and

00:06:22,039 --> 00:06:26,729
then we can use some of these

00:06:23,849 --> 00:06:28,740
fundamental laws of queuing systems such

00:06:26,729 --> 00:06:30,240
as littles law and the utilization law

00:06:28,740 --> 00:06:31,800
and we can get utilization average

00:06:30,240 --> 00:06:34,800
response time concurrency and a whole

00:06:31,800 --> 00:06:37,230
bunch more things so here's a command

00:06:34,800 --> 00:06:40,200
line that I typically use to capture

00:06:37,230 --> 00:06:42,470
these packet headers from a system and

00:06:40,200 --> 00:06:47,010
I'll go over exactly what this is about

00:06:42,470 --> 00:06:48,480
the TCP dump s 384 that's the number of

00:06:47,010 --> 00:06:50,670
bytes from each packet that I want to

00:06:48,480 --> 00:06:52,770
capture so those are the first 384 bites

00:06:50,670 --> 00:06:54,540
of each packet that represents the

00:06:52,770 --> 00:06:57,720
headers of the TCP packet and the

00:06:54,540 --> 00:06:59,100
headers of the IP packet okay so the

00:06:57,720 --> 00:07:00,840
reason that I'm doing that instead of

00:06:59,100 --> 00:07:02,370
capturing everything is that on a busy

00:07:00,840 --> 00:07:04,740
system if you try and capture too much

00:07:02,370 --> 00:07:06,570
the buffers will fill up and you'll

00:07:04,740 --> 00:07:07,860
start dropping packets there are ways

00:07:06,570 --> 00:07:10,590
that you can mitigate that you can make

00:07:07,860 --> 00:07:13,230
the buffers larger you can filter out

00:07:10,590 --> 00:07:15,390
some of the traffic for example but this

00:07:13,230 --> 00:07:19,710
capturing only the packet headers tends

00:07:15,390 --> 00:07:21,270
to work quite well dash I any means

00:07:19,710 --> 00:07:23,400
listen on all of the network interfaces

00:07:21,270 --> 00:07:25,260
and this is platform specific to Linux

00:07:23,400 --> 00:07:27,240
but on most systems of course you're

00:07:25,260 --> 00:07:32,060
going to need to specify an interface

00:07:27,240 --> 00:07:34,920
that you want to listen on n n qs

00:07:32,060 --> 00:07:37,500
prevents TCP dump from resolving IP

00:07:34,920 --> 00:07:39,090
addresses into host names because what

00:07:37,500 --> 00:07:41,820
we really care about is IP addresses

00:07:39,090 --> 00:07:43,830
here and makes the output a little bit

00:07:41,820 --> 00:07:46,140
quieter and then the four dash T's

00:07:43,830 --> 00:07:49,530
format timestamps with full precision

00:07:46,140 --> 00:07:51,000
and this long complicated expression

00:07:49,530 --> 00:07:53,160
that I've actually broken over two lines

00:07:51,000 --> 00:07:55,770
comes out of the TCP dump man page and

00:07:53,160 --> 00:07:58,980
it basically says ignore everything that

00:07:55,770 --> 00:08:00,690
is for example a knack ignore all of the

00:07:58,980 --> 00:08:03,350
things that don't carry protocol level

00:08:00,690 --> 00:08:05,850
information ignore all of these sort of

00:08:03,350 --> 00:08:08,040
setting up the the handshake for setting

00:08:05,850 --> 00:08:10,920
up a TCP connection throw all of that

00:08:08,040 --> 00:08:13,170
stuff away and only show me things that

00:08:10,920 --> 00:08:15,770
represent a payload at the next level up

00:08:13,170 --> 00:08:18,030
in in the in the seven layer model and

00:08:15,770 --> 00:08:21,120
then I'm just printing the result into

00:08:18,030 --> 00:08:23,490
this file called TCP file dot txt now in

00:08:21,120 --> 00:08:25,710
reality in a lot of cases I will use the

00:08:23,490 --> 00:08:27,690
dash W argument to TCP dump which writes

00:08:25,710 --> 00:08:29,340
the binary file out then I'll ship that

00:08:27,690 --> 00:08:30,930
binary fall off somewhere else and I'll

00:08:29,340 --> 00:08:33,000
do the rest of all of this complicated

00:08:30,930 --> 00:08:36,900
you know timestamp formatting and so

00:08:33,000 --> 00:08:42,780
forth elsewhere rather than then writing

00:08:36,900 --> 00:08:45,480
out in textual format but this this ends

00:08:42,780 --> 00:08:47,960
up printing one line per packet into

00:08:45,480 --> 00:08:47,960
this file

00:08:48,340 --> 00:08:52,990
I just mentioned about drop packets I

00:08:50,380 --> 00:08:55,480
didn't mention why it's so important the

00:08:52,990 --> 00:08:56,950
way that I am timing queries to the

00:08:55,480 --> 00:08:58,810
server as I mentioned as I'm watching

00:08:56,950 --> 00:08:59,980
for an inbound packet and an album

00:08:58,810 --> 00:09:02,650
packet that have the same session

00:08:59,980 --> 00:09:04,870
identifier IP and port and I'm

00:09:02,650 --> 00:09:06,070
correlating the two if I have dropped

00:09:04,870 --> 00:09:08,860
packets I'm going to miss some

00:09:06,070 --> 00:09:11,590
observations and I can potentially see

00:09:08,860 --> 00:09:13,540
for example an inbound packet miss the

00:09:11,590 --> 00:09:15,400
response miss the next inbound packet

00:09:13,540 --> 00:09:16,780
catch a response and then conclude that

00:09:15,400 --> 00:09:19,660
there was a very long running query

00:09:16,780 --> 00:09:21,490
where none existed and even with a very

00:09:19,660 --> 00:09:23,410
small portion of dropped packets this

00:09:21,490 --> 00:09:26,200
becomes a pretty serious problem quickly

00:09:23,410 --> 00:09:28,150
so you do need to make sure that TCP

00:09:26,200 --> 00:09:30,820
dump doesn't report that there was

00:09:28,150 --> 00:09:33,100
dropped packets you know if there were a

00:09:30,820 --> 00:09:34,990
few packets dropped okay you potentially

00:09:33,100 --> 00:09:36,700
have missed or mangled a couple of

00:09:34,990 --> 00:09:38,980
requests but if you have one percent or

00:09:36,700 --> 00:09:41,260
something like that one or two percent

00:09:38,980 --> 00:09:42,640
in my experience completely skews all of

00:09:41,260 --> 00:09:45,240
your observations so you need to be

00:09:42,640 --> 00:09:45,240
careful about that

00:09:51,590 --> 00:09:55,040
I'm sorry say again

00:10:02,580 --> 00:10:06,459
when you do a thing okay so the question

00:10:05,080 --> 00:10:07,959
is when I'm talking about dropped

00:10:06,459 --> 00:10:10,839
packets is that different from what I

00:10:07,959 --> 00:10:13,000
would get if i do a ping yeah it is TCP

00:10:10,839 --> 00:10:15,430
dump itself even if the network is not

00:10:13,000 --> 00:10:17,080
dropping any packets TCB dump is hooking

00:10:15,430 --> 00:10:18,940
into the kernel and asking to observe

00:10:17,080 --> 00:10:21,640
the stream but it's it's giving the

00:10:18,940 --> 00:10:24,100
colonel a limited buffer to observe

00:10:21,640 --> 00:10:26,260
within and if TCP dump gets too busy or

00:10:24,100 --> 00:10:29,550
a large packet comes in and ever flows

00:10:26,260 --> 00:10:32,980
that bucker that buffer the colonel will

00:10:29,550 --> 00:10:34,720
I don't know whether it's the kernel or

00:10:32,980 --> 00:10:36,850
whether TCB dump will drop the package

00:10:34,720 --> 00:10:38,440
in other words it'll say there was some

00:10:36,850 --> 00:10:41,980
data but I didn't have time to observe

00:10:38,440 --> 00:10:46,270
it okay it's not a network problem it's

00:10:41,980 --> 00:10:47,740
a TCP dump problem yeah and so if a TCP

00:10:46,270 --> 00:10:50,529
dump will print out a little bit of

00:10:47,740 --> 00:10:52,240
information to the standard error so if

00:10:50,529 --> 00:10:54,130
you're redirecting the output to a file

00:10:52,240 --> 00:10:56,860
you will still see at the end if you

00:10:54,130 --> 00:10:59,290
control C to cancel TCP dump at the end

00:10:56,860 --> 00:11:01,990
you will see captured a million packets

00:10:59,290 --> 00:11:03,670
dropped hopefully zero so there will be

00:11:01,990 --> 00:11:05,440
a little bit of meta information about

00:11:03,670 --> 00:11:07,240
the the information gathering that you

00:11:05,440 --> 00:11:09,370
did and you just want to examine that

00:11:07,240 --> 00:11:13,240
and see that you didn't get many dropped

00:11:09,370 --> 00:11:15,550
packets from TCP dump itself so this is

00:11:13,240 --> 00:11:17,410
what the data looks like each line

00:11:15,550 --> 00:11:19,600
represents a packet as I mentioned and

00:11:17,410 --> 00:11:21,910
this font kind of somehow came out very

00:11:19,600 --> 00:11:23,740
strong very small here so I hope you can

00:11:21,910 --> 00:11:27,370
see it but on the left hand side we have

00:11:23,740 --> 00:11:30,839
time stamps date and time and micro

00:11:27,370 --> 00:11:32,800
seconds as I said it's not really a

00:11:30,839 --> 00:11:36,670
reliable all the way out to the micro

00:11:32,800 --> 00:11:39,910
second level IP and then we have an IP

00:11:36,670 --> 00:11:45,490
address and a port number so we have 10

00:11:39,910 --> 00:11:47,620
124 dot 60 to 80 956 520 so that is the

00:11:45,490 --> 00:11:50,800
originating packet I gathered this data

00:11:47,620 --> 00:11:53,649
on a server on the mysql server that's

00:11:50,800 --> 00:11:55,300
the originating packet and then we have

00:11:53,649 --> 00:11:58,120
the less than symbol and the IP address

00:11:55,300 --> 00:12:02,200
of the mysql server listening on port

00:11:58,120 --> 00:12:04,360
3306 the last little bit here tcp 142

00:12:02,200 --> 00:12:05,770
indicates the number of bytes that were

00:12:04,360 --> 00:12:08,290
in the payload that we didn't capture

00:12:05,770 --> 00:12:11,140
because we only captured the the headers

00:12:08,290 --> 00:12:14,800
and then the next line after this we can

00:12:11,140 --> 00:12:20,290
see is from port 3306 the the MySQL

00:12:14,800 --> 00:12:22,990
server back to the same IP and port as

00:12:20,290 --> 00:12:25,480
we saw in the first line so those two

00:12:22,990 --> 00:12:27,670
those first two lines actually represent

00:12:25,480 --> 00:12:30,339
a packet in followed by a responding

00:12:27,670 --> 00:12:32,170
packet out and you can kind of look down

00:12:30,339 --> 00:12:34,149
through these and see the same sort of

00:12:32,170 --> 00:12:36,970
thing with some of these others on a

00:12:34,149 --> 00:12:38,769
busy system you'll have a packet going

00:12:36,970 --> 00:12:40,300
in the packet coming in from a bunch of

00:12:38,769 --> 00:12:43,180
other servers and then you'll see a

00:12:40,300 --> 00:12:46,510
packet responding to your first one so

00:12:43,180 --> 00:12:48,300
we won't necessarily see a request

00:12:46,510 --> 00:12:51,880
followed immediately by the response

00:12:48,300 --> 00:12:54,519
there will be a lot of interleaving so

00:12:51,880 --> 00:12:56,500
this is a nice textual format that we

00:12:54,519 --> 00:12:58,690
can munch with standard UNIX command

00:12:56,500 --> 00:13:00,850
line tools quite well with all canned

00:12:58,690 --> 00:13:03,910
Perl scripts and I've written a series

00:13:00,850 --> 00:13:05,410
of Perl scripts that are in the percona

00:13:03,910 --> 00:13:07,930
toolkit and i'll be showing you kind of

00:13:05,410 --> 00:13:09,970
how to how to use those so here's a

00:13:07,930 --> 00:13:12,339
little bit larger version I should have

00:13:09,970 --> 00:13:15,790
thought to show you that in case you

00:13:12,339 --> 00:13:18,760
were having troubles name so this pearl

00:13:15,790 --> 00:13:20,560
tool is called PTT CB model and that's

00:13:18,760 --> 00:13:23,070
part of Percona toolkit free open source

00:13:20,560 --> 00:13:25,990
you can download it for Briona com and

00:13:23,070 --> 00:13:27,279
by default if you give it this file that

00:13:25,990 --> 00:13:28,990
I'm showing you on the top and then

00:13:27,279 --> 00:13:31,899
redirect the output into another file

00:13:28,990 --> 00:13:34,300
that I'll call requests txt it finds

00:13:31,899 --> 00:13:36,940
correlated pairs of packets and puts

00:13:34,300 --> 00:13:40,360
them into a single line so what we have

00:13:36,940 --> 00:13:44,680
as a result here is the the start time

00:13:40,360 --> 00:13:46,930
stamp this is dot 818 202 that's the

00:13:44,680 --> 00:13:51,579
same as we see up there and the end time

00:13:46,930 --> 00:13:54,040
stamped 818 440 that's the same as the

00:13:51,579 --> 00:13:56,350
second line there the elapsed is the

00:13:54,040 --> 00:13:58,529
difference so 238 microseconds between

00:13:56,350 --> 00:14:01,320
those two and then this host port which

00:13:58,529 --> 00:14:03,430
frankly we actually ignore from here on

00:14:01,320 --> 00:14:05,050
but you can see how it's taking each

00:14:03,430 --> 00:14:06,550
pair of lines that are related to each

00:14:05,050 --> 00:14:08,160
other and producing a single line in the

00:14:06,550 --> 00:14:11,290
output which makes it convenient for

00:14:08,160 --> 00:14:14,470
processing further with yet more UNIX

00:14:11,290 --> 00:14:15,910
command line tools and we can do lots

00:14:14,470 --> 00:14:18,730
and lots of interesting stuff with this

00:14:15,910 --> 00:14:20,920
I'll start with this output and I'll

00:14:18,730 --> 00:14:22,510
show you the first set of functionality

00:14:20,920 --> 00:14:25,630
that I described which is what I call

00:14:22,510 --> 00:14:27,699
black box performance analysis so all of

00:14:25,630 --> 00:14:28,140
these plots and analysis that i'm going

00:14:27,699 --> 00:14:29,490
to show you

00:14:28,140 --> 00:14:31,980
is made from a single sample of data

00:14:29,490 --> 00:14:33,480
from a real production server it's

00:14:31,980 --> 00:14:35,250
running a ruby on rails e-commerce

00:14:33,480 --> 00:14:39,090
application and it's pretty heavily

00:14:35,250 --> 00:14:41,780
trafficked it's a fairly typical sort of

00:14:39,090 --> 00:14:44,190
online transaction processing system and

00:14:41,780 --> 00:14:46,700
you'll see a bunch of anomalies and

00:14:44,190 --> 00:14:49,730
strange things popping out in the data

00:14:46,700 --> 00:14:51,960
data is not uniform in most cases

00:14:49,730 --> 00:14:54,450
there's also some other stuff that

00:14:51,960 --> 00:14:56,100
happens on the system there are cron

00:14:54,450 --> 00:14:59,640
jobs there are other background

00:14:56,100 --> 00:15:01,620
processes there's a there are special

00:14:59,640 --> 00:15:04,170
requests that come in frequently that

00:15:01,620 --> 00:15:05,550
are not like the sort of normal requests

00:15:04,170 --> 00:15:07,140
that are constantly going in and out of

00:15:05,550 --> 00:15:10,050
the system so we'll see kind of some of

00:15:07,140 --> 00:15:11,820
those things so my black box performance

00:15:10,050 --> 00:15:15,120
analysis the first thing I do is pull up

00:15:11,820 --> 00:15:17,580
the new plot you can use other tools you

00:15:15,120 --> 00:15:20,070
could in theory use a spreadsheet but

00:15:17,580 --> 00:15:21,960
it's actually quite painful to do so so

00:15:20,070 --> 00:15:24,930
the tools that I encourage people to

00:15:21,960 --> 00:15:27,330
learn our new plot or are both of those

00:15:24,930 --> 00:15:30,660
are good ways to just take a file that

00:15:27,330 --> 00:15:32,400
has space separated words slurp it in

00:15:30,660 --> 00:15:34,950
and do interesting things with it very

00:15:32,400 --> 00:15:36,570
quickly so new plot is my tool of choice

00:15:34,950 --> 00:15:38,220
here and I kind of built some tools

00:15:36,570 --> 00:15:40,350
around it so I've I've never really

00:15:38,220 --> 00:15:44,040
learned are because I learned canoe plot

00:15:40,350 --> 00:15:45,720
first and all I'm doing here is plotting

00:15:44,040 --> 00:15:48,330
the response times of this whole sample

00:15:45,720 --> 00:15:51,330
of data which i think was 17 seconds or

00:15:48,330 --> 00:15:53,280
something like that so time moves from

00:15:51,330 --> 00:15:54,780
right to left and then I'm plotting the

00:15:53,280 --> 00:15:57,180
fourth column which was that response

00:15:54,780 --> 00:15:59,130
time the elapsed column the difference

00:15:57,180 --> 00:16:02,490
between the inbound and outbound packets

00:15:59,130 --> 00:16:05,040
so response time is on the vertical axis

00:16:02,490 --> 00:16:06,300
and you can see that most of these most

00:16:05,040 --> 00:16:09,240
of these things are actually clustered

00:16:06,300 --> 00:16:11,790
very closely done around the x-axis so

00:16:09,240 --> 00:16:15,030
the vast majority of requests to the

00:16:11,790 --> 00:16:16,800
server complete in a couple of hundred

00:16:15,030 --> 00:16:19,860
microseconds but then we have these

00:16:16,800 --> 00:16:22,770
strange sort of towers or spikes of

00:16:19,860 --> 00:16:26,220
requests that are piling up here and we

00:16:22,770 --> 00:16:27,660
also have another another pattern that

00:16:26,220 --> 00:16:30,570
I've indicated with a red line here

00:16:27,660 --> 00:16:32,040
where we've got sort of some queries

00:16:30,570 --> 00:16:34,380
that are outliers and they all look like

00:16:32,040 --> 00:16:35,760
they're about the same length so there's

00:16:34,380 --> 00:16:37,500
a couple of different patterns I can

00:16:35,760 --> 00:16:39,420
look at this data real quickly and see

00:16:37,500 --> 00:16:40,329
that there's something happening in the

00:16:39,420 --> 00:16:42,189
system that I want to

00:16:40,329 --> 00:16:43,660
more about and that is really the

00:16:42,189 --> 00:16:46,360
purpose for me of this black box

00:16:43,660 --> 00:16:48,579
performance analysis so in what I think

00:16:46,360 --> 00:16:50,230
of is kind of the bad old days if you

00:16:48,579 --> 00:16:52,839
were to do a performance analysis

00:16:50,230 --> 00:16:55,689
project on a system you might allocate

00:16:52,839 --> 00:16:57,639
four to six weeks for it to get all of

00:16:55,689 --> 00:16:59,980
your access to get your credentials get

00:16:57,639 --> 00:17:02,290
in there too you know maybe even insert

00:16:59,980 --> 00:17:07,000
new devices into the into the customers

00:17:02,290 --> 00:17:09,189
network or to install instrumentation

00:17:07,000 --> 00:17:11,559
software on their database servers and

00:17:09,189 --> 00:17:13,120
it can be a very heavy weight process

00:17:11,559 --> 00:17:14,409
and you would have a whole you know long

00:17:13,120 --> 00:17:15,909
project plan that you would have

00:17:14,409 --> 00:17:18,579
explained to the client and what the

00:17:15,909 --> 00:17:20,439
outcomes are but one of the things that

00:17:18,579 --> 00:17:22,299
you wouldn't know was is there anything

00:17:20,439 --> 00:17:24,519
even worth looking at on these systems

00:17:22,299 --> 00:17:27,880
right so you would have some sort of an

00:17:24,519 --> 00:17:30,309
assumption that this system is going to

00:17:27,880 --> 00:17:32,559
produce some fruitful results from a

00:17:30,309 --> 00:17:34,679
deep performance analysis well I just

00:17:32,559 --> 00:17:37,210
did this in like 30 seconds right and

00:17:34,679 --> 00:17:39,760
and I can tell you that there is

00:17:37,210 --> 00:17:41,320
something interesting and frankly kind

00:17:39,760 --> 00:17:43,299
of weird and disturbing happening on

00:17:41,320 --> 00:17:45,070
this system we have a lot of very

00:17:43,299 --> 00:17:47,880
uniform requests and then we have some

00:17:45,070 --> 00:17:50,500
uniformly slow requests and we have some

00:17:47,880 --> 00:17:53,110
non-uniform pile ups that are happening

00:17:50,500 --> 00:17:55,510
in the system so with basically no

00:17:53,110 --> 00:17:59,710
investment of time or energy I found

00:17:55,510 --> 00:18:02,049
that there is a significant let's say

00:17:59,710 --> 00:18:03,789
probable cause to dig deeper into these

00:18:02,049 --> 00:18:04,929
systems and it made you know it's

00:18:03,789 --> 00:18:07,120
certainly not going to be a four to

00:18:04,929 --> 00:18:09,880
six-week engagement it may be four to

00:18:07,120 --> 00:18:12,820
six hours or it may be you know days but

00:18:09,880 --> 00:18:14,350
at least we've justified looking into

00:18:12,820 --> 00:18:15,909
things more deeply before we spend a lot

00:18:14,350 --> 00:18:19,960
of somebody's time and money and do

00:18:15,909 --> 00:18:24,370
something very intrusive so these

00:18:19,960 --> 00:18:26,649
anomalies can be explained particularly

00:18:24,370 --> 00:18:28,330
the spikes here the the vertical spikes

00:18:26,649 --> 00:18:30,159
if you notice they're not completely

00:18:28,330 --> 00:18:32,620
vertical they're tilted a little bit

00:18:30,159 --> 00:18:34,299
this way that's not an optical illusion

00:18:32,620 --> 00:18:37,269
they actually are tilted that way

00:18:34,299 --> 00:18:40,480
because I plotted them in completion

00:18:37,269 --> 00:18:42,309
time order in other words the the

00:18:40,480 --> 00:18:44,260
progression of time from left to right

00:18:42,309 --> 00:18:45,909
is actually ordered according to the

00:18:44,260 --> 00:18:47,409
time that those packets the responses

00:18:45,909 --> 00:18:50,200
came back from the server to the client

00:18:47,409 --> 00:18:52,450
and this is just a side effect a happy

00:18:50,200 --> 00:18:53,570
side effect of the way that we process

00:18:52,450 --> 00:18:55,760
the data

00:18:53,570 --> 00:18:57,890
my tool that transforms the data from

00:18:55,760 --> 00:19:00,140
TCB dumps format into the next output

00:18:57,890 --> 00:19:02,240
format that I showed you it prints out a

00:19:00,140 --> 00:19:04,280
line every time it sees the response so

00:19:02,240 --> 00:19:05,570
the response represents the completion

00:19:04,280 --> 00:19:09,170
of a query and therefore by default

00:19:05,570 --> 00:19:11,300
those lines are actually being printed

00:19:09,170 --> 00:19:13,150
out in completion time order and that

00:19:11,300 --> 00:19:16,010
actually has some very nice properties

00:19:13,150 --> 00:19:17,600
lots of sort of little simple things end

00:19:16,010 --> 00:19:20,030
up having very deep meaning when you we

00:19:17,600 --> 00:19:22,430
need to dig into things like this so

00:19:20,030 --> 00:19:25,010
what's happening here that causes a

00:19:22,430 --> 00:19:27,320
spike like that to slope this way is

00:19:25,010 --> 00:19:30,280
that something is acquiring some lock

00:19:27,320 --> 00:19:33,800
other things are blocking on that and

00:19:30,280 --> 00:19:35,930
when the lock is released let's say that

00:19:33,800 --> 00:19:38,660
the first guy gets the lock here and

00:19:35,930 --> 00:19:41,540
holds it until here meanwhile this guy

00:19:38,660 --> 00:19:43,430
blocks on it and so does this one then

00:19:41,540 --> 00:19:45,350
the first one releases it the second one

00:19:43,430 --> 00:19:47,630
is able to actually do its work this

00:19:45,350 --> 00:19:49,490
yellow portion represents the the period

00:19:47,630 --> 00:19:51,050
of time that it was doing work rather

00:19:49,490 --> 00:19:54,560
than waiting for a resource to be freed

00:19:51,050 --> 00:19:55,940
up and and when n finishes then this one

00:19:54,560 --> 00:19:58,400
can do its work and so what we're really

00:19:55,940 --> 00:20:00,080
seeing here is if you're familiar with

00:19:58,400 --> 00:20:02,420
the term service time as opposed to

00:20:00,080 --> 00:20:05,630
response time services service time is

00:20:02,420 --> 00:20:07,250
the response time plus the wait time the

00:20:05,630 --> 00:20:09,650
red is the wait time the yellow is the

00:20:07,250 --> 00:20:11,240
service time and a natural consequence

00:20:09,650 --> 00:20:12,860
of plotting these things in completion

00:20:11,240 --> 00:20:15,500
orders that we get a slope to the right

00:20:12,860 --> 00:20:18,230
and here I've exaggerated it but we see

00:20:15,500 --> 00:20:20,030
the same thing in that data so the

00:20:18,230 --> 00:20:23,360
stalls in this case are select for

00:20:20,030 --> 00:20:25,430
update this particular system Ruby makes

00:20:23,360 --> 00:20:28,070
it very easy to do select for update

00:20:25,430 --> 00:20:31,160
without realizing it which is a mutually

00:20:28,070 --> 00:20:33,440
exclusive access to the data there's a

00:20:31,160 --> 00:20:35,360
dot lock syntax and what that really

00:20:33,440 --> 00:20:36,950
does is change the underlying query and

00:20:35,360 --> 00:20:39,530
to select for update without your

00:20:36,950 --> 00:20:41,030
knowing about it and you end up with the

00:20:39,530 --> 00:20:44,840
database full of select for update

00:20:41,030 --> 00:20:47,540
queries so I I lied to you a little bit

00:20:44,840 --> 00:20:50,990
I didn't capture just 384 bites on this

00:20:47,540 --> 00:20:54,530
system I captured 4096 bytes which still

00:20:50,990 --> 00:20:56,420
allowed me to to avoid any dropped

00:20:54,530 --> 00:20:58,610
packets and the customer was fine in

00:20:56,420 --> 00:21:02,750
this case the data is not proprietary to

00:20:58,610 --> 00:21:04,200
them so that gave me more of the packet

00:21:02,750 --> 00:21:05,760
and I was able to

00:21:04,200 --> 00:21:07,830
that and see that these queries were

00:21:05,760 --> 00:21:11,429
indeed the select for update so I proved

00:21:07,830 --> 00:21:14,039
my theory and i used the PT query digest

00:21:11,429 --> 00:21:16,440
tool which is another of the tools in

00:21:14,039 --> 00:21:18,960
Percona toolkit to inspect those queries

00:21:16,440 --> 00:21:21,809
and decode them it has a MySQL protocol

00:21:18,960 --> 00:21:25,169
decoder built into it and those

00:21:21,809 --> 00:21:26,940
clustered spikes are caused by things

00:21:25,169 --> 00:21:31,320
waiting for essentially waiting for the

00:21:26,940 --> 00:21:33,090
same row lock in exclusive mode so if we

00:21:31,320 --> 00:21:34,799
sell a completion times kind of pulling

00:21:33,090 --> 00:21:36,600
this pattern out very clearly maybe we

00:21:34,799 --> 00:21:40,049
can see some more information about

00:21:36,600 --> 00:21:41,220
completion times the next the next stage

00:21:40,049 --> 00:21:43,169
of charts that i'm going to show you

00:21:41,220 --> 00:21:47,159
here comes from running the tool against

00:21:43,169 --> 00:21:48,779
that second output file and there's a

00:21:47,159 --> 00:21:50,880
another mode that you can run the tool

00:21:48,779 --> 00:21:52,620
in where it'll group things into buckets

00:21:50,880 --> 00:21:54,779
of time so it'll take that that whole

00:21:52,620 --> 00:21:56,340
time series that i showed you and slice

00:21:54,779 --> 00:22:00,240
it into little intervals and within each

00:21:56,340 --> 00:22:02,070
interval we will count and aggregate the

00:22:00,240 --> 00:22:04,820
statistics in various ways for example

00:22:02,070 --> 00:22:07,049
will sum up the response times will do

00:22:04,820 --> 00:22:09,059
standard deviation over those response

00:22:07,049 --> 00:22:11,309
times and so forth and so on the most

00:22:09,059 --> 00:22:13,019
basic thing that we can do with an

00:22:11,309 --> 00:22:15,149
interval of time is just count the

00:22:13,019 --> 00:22:19,139
number of request and response that

00:22:15,149 --> 00:22:21,899
we're in it so here we've got the

00:22:19,139 --> 00:22:23,309
completion counts actually I'm counting

00:22:21,899 --> 00:22:26,100
the number of completions on the left

00:22:23,309 --> 00:22:28,289
and the number of sorry arrivals on the

00:22:26,100 --> 00:22:29,880
left and completions on the right so

00:22:28,289 --> 00:22:31,409
maybe the difference in arrivals and

00:22:29,880 --> 00:22:33,779
completions can tell us something and if

00:22:31,409 --> 00:22:36,240
you if you look at these charts you can

00:22:33,779 --> 00:22:37,409
see there are apparently some you know

00:22:36,240 --> 00:22:39,690
there are some differences for example

00:22:37,409 --> 00:22:41,190
look up in the outlier region here this

00:22:39,690 --> 00:22:43,980
pattern is a little bit different than

00:22:41,190 --> 00:22:45,480
the corresponding pattern ever here they

00:22:43,980 --> 00:22:48,269
don't quite match up and if you plot

00:22:45,480 --> 00:22:49,740
them on top of each other you think you

00:22:48,269 --> 00:22:50,940
might think that maybe if you plot them

00:22:49,740 --> 00:22:53,549
on top of each other you could see a

00:22:50,940 --> 00:22:55,200
real clear pattern but actually most of

00:22:53,549 --> 00:22:56,399
the points just obscure each other and

00:22:55,200 --> 00:22:58,919
the remaining points are kind of like

00:22:56,399 --> 00:23:01,049
well what does that mean I don't know so

00:22:58,919 --> 00:23:03,750
it ends up being basically about as

00:23:01,049 --> 00:23:07,110
revealing as looking at these graphs so

00:23:03,750 --> 00:23:08,940
this is as mentioned on the on the slide

00:23:07,110 --> 00:23:11,250
these are graphed in 25 millisecond

00:23:08,940 --> 00:23:13,200
buckets and you can kind of stare at

00:23:11,250 --> 00:23:15,179
them and you can say I don't really see

00:23:13,200 --> 00:23:16,960
anything there one of the dangers of

00:23:15,179 --> 00:23:19,029
plotting things

00:23:16,960 --> 00:23:20,559
is that we can fool ourselves by

00:23:19,029 --> 00:23:24,220
thinking there's a pattern in the graph

00:23:20,559 --> 00:23:26,950
and all meaning has a pattern but not

00:23:24,220 --> 00:23:29,020
all pattern has a meaning so it's very

00:23:26,950 --> 00:23:30,640
it's very easy to sort of you know it's

00:23:29,020 --> 00:23:32,409
like looking at clouds and seeing puppy

00:23:30,640 --> 00:23:35,049
dogs and bunnies in the clouds yeah

00:23:32,409 --> 00:23:37,990
they're just clouds so we have to be

00:23:35,049 --> 00:23:41,169
careful when we look at things that

00:23:37,990 --> 00:23:42,520
we're not it's the sort of projecting

00:23:41,169 --> 00:23:44,380
meaning into something that isn't there

00:23:42,520 --> 00:23:46,570
so this doesn't look like a very

00:23:44,380 --> 00:23:47,919
fruitful way to go but maybe if we

00:23:46,570 --> 00:23:49,539
subtract the arrivals and the

00:23:47,919 --> 00:23:52,690
completions from each other we can see a

00:23:49,539 --> 00:23:58,149
pattern and indeed that does pull out

00:23:52,690 --> 00:23:59,860
spikes now if you look here the first

00:23:58,149 --> 00:24:02,620
bullet point says five milliseconds is

00:23:59,860 --> 00:24:04,720
to fine grained if you shorten your

00:24:02,620 --> 00:24:06,760
observation window far enough you will

00:24:04,720 --> 00:24:08,620
see spikes it's just a fact of how

00:24:06,760 --> 00:24:10,149
computer systems work because there is

00:24:08,620 --> 00:24:12,850
some time delay while things are being

00:24:10,149 --> 00:24:15,220
processed inside the system and there is

00:24:12,850 --> 00:24:17,169
always some amount of queuing the

00:24:15,220 --> 00:24:19,539
question is just how much queuing is

00:24:17,169 --> 00:24:22,000
tolerable for your system if most

00:24:19,539 --> 00:24:25,480
queries are responding on this system in

00:24:22,000 --> 00:24:27,970
200 milliseconds at micro seconds then

00:24:25,480 --> 00:24:30,159
200 microseconds is probably not an

00:24:27,970 --> 00:24:33,130
abnormally long amount of time for

00:24:30,159 --> 00:24:37,080
something to pile up 5 milliseconds

00:24:33,130 --> 00:24:41,559
might be a second you know certainly a

00:24:37,080 --> 00:24:43,419
second is is not a query that I like to

00:24:41,559 --> 00:24:46,720
see when most queries are much much

00:24:43,419 --> 00:24:49,330
faster than that so I chose 200

00:24:46,720 --> 00:24:52,480
milliseconds here and that means five

00:24:49,330 --> 00:24:54,130
buckets per second so we can see that

00:24:52,480 --> 00:24:56,020
that pulls out two spikes in this data

00:24:54,130 --> 00:24:58,179
very clearly now there's an accompanying

00:24:56,020 --> 00:24:59,260
white paper for this presentation for

00:24:58,179 --> 00:25:02,470
the for the first part of this

00:24:59,260 --> 00:25:06,029
presentation on perkiness website and in

00:25:02,470 --> 00:25:08,830
that web paper I explained how i chose

00:25:06,029 --> 00:25:11,020
there's there's a heuristic or a rule of

00:25:08,830 --> 00:25:12,970
thumb for choosing what kind of

00:25:11,020 --> 00:25:16,809
aggregation interval so it's not just

00:25:12,970 --> 00:25:18,789
completely random but my point is that

00:25:16,809 --> 00:25:21,610
if you make the the aggregation interval

00:25:18,789 --> 00:25:23,679
too small you will get all spikes so

00:25:21,610 --> 00:25:25,000
basically if you look very closely into

00:25:23,679 --> 00:25:26,679
any system you're going to see that it

00:25:25,000 --> 00:25:28,270
has some versity behavior and that's

00:25:26,679 --> 00:25:30,309
just the way the computer systems work

00:25:28,270 --> 00:25:30,850
because they are networks of devices

00:25:30,309 --> 00:25:34,630
with queues

00:25:30,850 --> 00:25:37,180
in between them so here I've taken those

00:25:34,630 --> 00:25:40,030
two hundred millisecond buckets and I've

00:25:37,180 --> 00:25:41,320
drawn it as a as a chart of arrivals and

00:25:40,030 --> 00:25:43,450
completions on the left and the right

00:25:41,320 --> 00:25:45,280
and then I've shown you the subtraction

00:25:43,450 --> 00:25:48,160
between them on the right to make it

00:25:45,280 --> 00:25:50,230
clear how how this helps you pull the

00:25:48,160 --> 00:25:53,320
pattern out how that helps you pull the

00:25:50,230 --> 00:25:55,630
signal out of all of that noise right so

00:25:53,320 --> 00:25:58,450
the characteristic pattern that comes

00:25:55,630 --> 00:26:00,940
out here is you see a dip where things

00:25:58,450 --> 00:26:03,340
are stuck in the system in process and

00:26:00,940 --> 00:26:05,560
then you see a spike where they're

00:26:03,340 --> 00:26:07,930
completing after whatever that resources

00:26:05,560 --> 00:26:09,940
is released and they're all completed

00:26:07,930 --> 00:26:11,740
being in a rush and you get that very

00:26:09,940 --> 00:26:15,000
characteristic down and then up pattern

00:26:11,740 --> 00:26:17,230
if you subtract the two from each other

00:26:15,000 --> 00:26:19,060
there's a few other things that we can

00:26:17,230 --> 00:26:21,910
do I mentioned that we compute for

00:26:19,060 --> 00:26:23,890
example a standard deviation of response

00:26:21,910 --> 00:26:26,350
times those kinds of things we can also

00:26:23,890 --> 00:26:28,270
compute percentiles but one of the more

00:26:26,350 --> 00:26:31,180
interesting things for purposes of this

00:26:28,270 --> 00:26:33,340
black box analysis is to look at some

00:26:31,180 --> 00:26:35,170
measure of how variable the response

00:26:33,340 --> 00:26:37,480
times are in each little window of time

00:26:35,170 --> 00:26:40,510
and variability generally means

00:26:37,480 --> 00:26:43,870
optimized ability because things that

00:26:40,510 --> 00:26:45,700
are running with highly variable

00:26:43,870 --> 00:26:48,100
performance are things that are not

00:26:45,700 --> 00:26:49,420
running like each other and what we'd

00:26:48,100 --> 00:26:51,430
like to do is make things very very

00:26:49,420 --> 00:26:53,920
consistent if some things are running

00:26:51,430 --> 00:26:55,720
fast then why can't they all run fast so

00:26:53,920 --> 00:26:58,300
what I like to do is try and make

00:26:55,720 --> 00:26:59,980
everything run fast so we get consistent

00:26:58,300 --> 00:27:02,890
and stable and predictable performance

00:26:59,980 --> 00:27:05,470
and this metric called the variance to

00:27:02,890 --> 00:27:07,240
mean ratio helps us to do that standard

00:27:05,470 --> 00:27:08,980
deviation is also a measure of the

00:27:07,240 --> 00:27:11,740
variability but the problem is that it's

00:27:08,980 --> 00:27:13,690
units have the same magnitude as the

00:27:11,740 --> 00:27:16,180
units of the input data so it becomes

00:27:13,690 --> 00:27:18,160
difficult to compare systems for example

00:27:16,180 --> 00:27:19,990
it becomes difficult to compare a system

00:27:18,160 --> 00:27:22,870
like this where we have 200 micro second

00:27:19,990 --> 00:27:24,550
queries versus a system that has 200

00:27:22,870 --> 00:27:26,020
millisecond queries it's hard to say

00:27:24,550 --> 00:27:27,550
which one is more variable than the

00:27:26,020 --> 00:27:29,140
other or which one is better or worse

00:27:27,550 --> 00:27:31,450
than the other but if we normalize those

00:27:29,140 --> 00:27:33,730
things relative to the average response

00:27:31,450 --> 00:27:37,000
time in the system then it becomes very

00:27:33,730 --> 00:27:39,130
easy to see and that's what the variance

00:27:37,000 --> 00:27:40,810
to mean ratio gives us is a normalized

00:27:39,130 --> 00:27:44,710
measure of the dispersion of this

00:27:40,810 --> 00:27:46,840
response times so here's the same

00:27:44,710 --> 00:27:49,659
sample of data again time moving from

00:27:46,840 --> 00:27:51,490
left to right in 200 millisecond buckets

00:27:49,659 --> 00:27:54,669
and you can see some some spikes their

00:27:51,490 --> 00:28:00,429
spikes up to an index of dispersion

00:27:54,669 --> 00:28:03,010
ratio of about three and i'll show you

00:28:00,429 --> 00:28:05,320
in a moment all of these charts together

00:28:03,010 --> 00:28:06,669
so you can kind of see the the various

00:28:05,320 --> 00:28:10,059
patterns and how they correlate with

00:28:06,669 --> 00:28:11,860
each other so I'm not sure from looking

00:28:10,059 --> 00:28:13,360
at this graph exactly what's happening

00:28:11,860 --> 00:28:14,770
in here but I can tell you that

00:28:13,360 --> 00:28:17,500
something is happening that I want to

00:28:14,770 --> 00:28:19,630
look into write something I want to know

00:28:17,500 --> 00:28:22,120
why those are why those regions of time

00:28:19,630 --> 00:28:23,740
are more variable and if I captured more

00:28:22,120 --> 00:28:25,840
of the protocol as I did in this

00:28:23,740 --> 00:28:27,399
particular example then I can actually

00:28:25,840 --> 00:28:31,419
dig in and see which queries were those

00:28:27,399 --> 00:28:34,090
right so i just mentioned this i like

00:28:31,419 --> 00:28:35,980
consistency and performance so here's

00:28:34,090 --> 00:28:38,860
all three of these plots together and

00:28:35,980 --> 00:28:41,760
you can see that the spikes are of long

00:28:38,860 --> 00:28:46,210
you know these these locking spikes are

00:28:41,760 --> 00:28:48,370
exactly where the subtraction of rivals

00:28:46,210 --> 00:28:49,840
versus completion spikes are so it's

00:28:48,370 --> 00:28:53,320
basically two ways of seeing the same

00:28:49,840 --> 00:28:55,600
thing I actually prefer this second

00:28:53,320 --> 00:28:58,390
graph down on the bottom here over the

00:28:55,600 --> 00:29:00,130
the points clustered because you can you

00:28:58,390 --> 00:29:02,890
can get very sensitive with that and

00:29:00,130 --> 00:29:06,039
I've actually found some problems and

00:29:02,890 --> 00:29:09,480
systems where we didn't have such a

00:29:06,039 --> 00:29:13,600
uniform distribution of response times

00:29:09,480 --> 00:29:15,340
this this this system is very clean you

00:29:13,600 --> 00:29:17,679
know the workload is not very mixed

00:29:15,340 --> 00:29:19,870
there's some mixture of workload there

00:29:17,679 --> 00:29:21,429
but in general we've got only a few

00:29:19,870 --> 00:29:23,440
different types of queries running and

00:29:21,429 --> 00:29:26,110
when you get a system that has more

00:29:23,440 --> 00:29:28,090
diversity of query types running then

00:29:26,110 --> 00:29:30,480
that graph won't look just like a blue

00:29:28,090 --> 00:29:32,740
line with some dots it'll look more like

00:29:30,480 --> 00:29:34,710
you know somebody kind of sprayed it

00:29:32,740 --> 00:29:37,149
with this break spray can of paint and

00:29:34,710 --> 00:29:39,340
even in cases like that I found that the

00:29:37,149 --> 00:29:41,200
spike analysis can pull out the fact

00:29:39,340 --> 00:29:43,450
that there are bad things happening in

00:29:41,200 --> 00:29:47,649
there and this index of dispersion

00:29:43,450 --> 00:29:49,360
spikes on the right seems to be showing

00:29:47,649 --> 00:29:51,820
a different problem which I did not yet

00:29:49,360 --> 00:29:54,970
dig into so I can't really tell you what

00:29:51,820 --> 00:29:57,470
that problem was but some of the some of

00:29:54,970 --> 00:30:00,059
the variability in response time

00:29:57,470 --> 00:30:01,259
lines up with it it's hard to get all

00:30:00,059 --> 00:30:03,659
three of these things lined up together

00:30:01,259 --> 00:30:05,309
and not make them too small to see but I

00:30:03,659 --> 00:30:07,200
can set and tell you that some of these

00:30:05,309 --> 00:30:10,649
things line up with these very obvious

00:30:07,200 --> 00:30:13,109
spikes on the first graph and some of

00:30:10,649 --> 00:30:15,659
them dolt so there are there are other

00:30:13,109 --> 00:30:18,690
things happening in there so this is

00:30:15,659 --> 00:30:21,539
kind of academic because i took a system

00:30:18,690 --> 00:30:23,220
that I knew had some problems and I said

00:30:21,539 --> 00:30:24,450
let me prove that there are problems let

00:30:23,220 --> 00:30:26,369
me prove that we can visualize the

00:30:24,450 --> 00:30:29,039
problems easily it was very little work

00:30:26,369 --> 00:30:33,179
but this has been done by other people

00:30:29,039 --> 00:30:37,440
as well and one of my clients Aaron

00:30:33,179 --> 00:30:41,999
Brown did this with his TCP traffic for

00:30:37,440 --> 00:30:44,039
for his web cluster and this was outside

00:30:41,999 --> 00:30:49,590
of the database arena this was only on

00:30:44,039 --> 00:30:51,779
the TCP an HTTP level and he just

00:30:49,590 --> 00:30:53,309
applied the same techniques and actually

00:30:51,779 --> 00:30:57,239
what he was doing was looking for ammo

00:30:53,309 --> 00:30:58,799
to take to his network operating the the

00:30:57,239 --> 00:31:00,029
folks that were operating the data

00:30:58,799 --> 00:31:02,220
center claimed that there were no

00:31:00,029 --> 00:31:03,749
problems with the networking he used

00:31:02,220 --> 00:31:06,149
this as proof that there were problems

00:31:03,749 --> 00:31:07,830
with the networking this is aggregated

00:31:06,149 --> 00:31:09,989
in one second intervals and you can see

00:31:07,830 --> 00:31:12,809
there are times when traffic basically

00:31:09,989 --> 00:31:16,649
completely stops for one or two seconds

00:31:12,809 --> 00:31:18,539
and it's not infrequent right so it's

00:31:16,649 --> 00:31:20,279
actually happening all the time little

00:31:18,539 --> 00:31:22,679
short complete outages in the network

00:31:20,279 --> 00:31:25,499
and you you pretty much can't argue with

00:31:22,679 --> 00:31:27,690
this data so interestingly what happened

00:31:25,499 --> 00:31:29,190
here I'm going to beat up on sands for a

00:31:27,690 --> 00:31:32,009
little bit one of my favorite things to

00:31:29,190 --> 00:31:34,830
beat up on what was happening here was

00:31:32,009 --> 00:31:38,309
that they were taking sand snapshots for

00:31:34,830 --> 00:31:40,460
backups this is a cloud provider I won't

00:31:38,309 --> 00:31:43,200
mention it to protect the innocent

00:31:40,460 --> 00:31:45,989
exactly which cloud provider it was but

00:31:43,200 --> 00:31:49,340
they're taking sand snapshots and the

00:31:45,989 --> 00:31:52,049
impact of the sand snapshot was actually

00:31:49,340 --> 00:31:54,169
flowing through to the operating system

00:31:52,049 --> 00:31:57,059
of the system was running their switches

00:31:54,169 --> 00:31:58,679
and their load balancers and so it was

00:31:57,059 --> 00:32:00,869
actually freezing them briefly and

00:31:58,679 --> 00:32:03,210
causing some blocking that was cascading

00:32:00,869 --> 00:32:05,220
up through these layers so we think of

00:32:03,210 --> 00:32:07,080
sand snapshots as being instantaneous

00:32:05,220 --> 00:32:08,609
and very fast but you know they're not

00:32:07,080 --> 00:32:10,290
completely instantaneous there long

00:32:08,609 --> 00:32:12,660
enough to cause some blocking it

00:32:10,290 --> 00:32:17,070
can impact your your load balancer ball

00:32:12,660 --> 00:32:19,230
things so thus concludes part one and in

00:32:17,070 --> 00:32:20,580
part 2 i'm going to start extrapolating

00:32:19,230 --> 00:32:22,470
this out a little bit further into some

00:32:20,580 --> 00:32:23,370
mathematical models so the first thing

00:32:22,470 --> 00:32:25,830
i'm going to do is talk about

00:32:23,370 --> 00:32:30,360
scalability which is one of those things

00:32:25,830 --> 00:32:32,700
like performance or you know words like

00:32:30,360 --> 00:32:33,600
that where people talk about it casually

00:32:32,700 --> 00:32:35,910
but they don't have a real clear

00:32:33,600 --> 00:32:39,000
understanding of what exactly we're

00:32:35,910 --> 00:32:41,070
discussing and i do find it useful to

00:32:39,000 --> 00:32:43,020
have a clear understanding that we can

00:32:41,070 --> 00:32:44,790
all agree on about what specifically

00:32:43,020 --> 00:32:46,500
we're talking about here now we may have

00:32:44,790 --> 00:32:48,270
different definitions of scalability and

00:32:46,500 --> 00:32:49,230
i'm not saying that those are invalid

00:32:48,270 --> 00:32:50,850
i'm just saying that we need something

00:32:49,230 --> 00:32:52,490
clear when we're when we're talking

00:32:50,850 --> 00:32:55,230
about something very specific like this

00:32:52,490 --> 00:32:58,310
so that we can get concrete results so

00:32:55,230 --> 00:33:00,630
scalability is a equation a function and

00:32:58,310 --> 00:33:02,520
my understanding of this is not

00:33:00,630 --> 00:33:04,290
something that I developed on my own it

00:33:02,520 --> 00:33:07,170
really came from a man named Neil

00:33:04,290 --> 00:33:09,480
Gunther who's a giant in performance

00:33:07,170 --> 00:33:11,550
research and has written a number of

00:33:09,480 --> 00:33:15,150
good books I've referenced some of them

00:33:11,550 --> 00:33:17,040
in my resources section at the end he

00:33:15,150 --> 00:33:19,080
said scalability is a function he wrote

00:33:17,040 --> 00:33:20,640
it in his book I read it for a year and

00:33:19,080 --> 00:33:22,260
a half I never got that he was talking

00:33:20,640 --> 00:33:24,300
about an equation even though the

00:33:22,260 --> 00:33:25,860
equation was there I never really

00:33:24,300 --> 00:33:27,510
thought about scalability as an equation

00:33:25,860 --> 00:33:29,850
so this was kind of a light on aha

00:33:27,510 --> 00:33:31,590
moment for me where the x-axis is the

00:33:29,850 --> 00:33:33,510
number of worker units and that the

00:33:31,590 --> 00:33:36,360
y-axis is a throughput so I'll show you

00:33:33,510 --> 00:33:39,600
this in pictures so throughput on the

00:33:36,360 --> 00:33:41,010
x-axis on the y-axis here that's how

00:33:39,600 --> 00:33:42,390
much work is getting done and this is

00:33:41,010 --> 00:33:44,730
how much work we're trying to get done

00:33:42,390 --> 00:33:47,100
either by adding more resources to a

00:33:44,730 --> 00:33:48,780
system or by adding more hardware you

00:33:47,100 --> 00:33:51,480
know fire and have more threads whatever

00:33:48,780 --> 00:33:53,040
it is so the scalability function is

00:33:51,480 --> 00:33:55,920
what happens when you plot a number of

00:33:53,040 --> 00:33:57,960
these points together so linear

00:33:55,920 --> 00:34:00,080
scalability is when all of the points

00:33:57,960 --> 00:34:02,700
are in a perfectly straight line and

00:34:00,080 --> 00:34:04,530
they intersect the origin and that's

00:34:02,700 --> 00:34:06,030
actually really important one of my

00:34:04,530 --> 00:34:08,460
favorite things to do is to go to a

00:34:06,030 --> 00:34:10,110
trade show and walk by the booth of some

00:34:08,460 --> 00:34:11,700
product and they say linear scalability

00:34:10,110 --> 00:34:13,560
on their big sign and they've got a

00:34:11,700 --> 00:34:15,600
PowerPoint slideshow typically on a

00:34:13,560 --> 00:34:17,100
little kiosk and the PowerPoint

00:34:15,600 --> 00:34:18,540
slideshow at some point will flip

00:34:17,100 --> 00:34:21,240
through a slide that shows things in a

00:34:18,540 --> 00:34:23,040
straight line and if you ask them to

00:34:21,240 --> 00:34:23,700
pause there and do a little math on the

00:34:23,040 --> 00:34:25,500
numbers you will

00:34:23,700 --> 00:34:27,450
very often find that it's not truly a

00:34:25,500 --> 00:34:31,429
straight line and it actually doesn't

00:34:27,450 --> 00:34:34,470
intersect the x-axis at zero so this is

00:34:31,429 --> 00:34:36,119
linear scalability to be truly linear

00:34:34,470 --> 00:34:37,619
actually has to go right through that

00:34:36,119 --> 00:34:40,349
origin and it has to be a completely

00:34:37,619 --> 00:34:42,500
straight line okay this is also linear

00:34:40,349 --> 00:34:44,280
scalability just with a different

00:34:42,500 --> 00:34:46,169
performance characteristics so

00:34:44,280 --> 00:34:48,300
scalability and performance are somewhat

00:34:46,169 --> 00:34:53,159
orthotic orthogonal although they are

00:34:48,300 --> 00:34:55,200
related and I'm talking about this a

00:34:53,159 --> 00:34:56,820
little bit generically dr. Gunther's

00:34:55,200 --> 00:34:58,230
book talks about it more specifically in

00:34:56,820 --> 00:35:01,589
terms of software scalability and

00:34:58,230 --> 00:35:03,630
hardware scalability my my axis labeled

00:35:01,589 --> 00:35:06,300
worker units here he has two variations

00:35:03,630 --> 00:35:09,900
of his scalability discussion where he

00:35:06,300 --> 00:35:12,390
will name those threads or processors

00:35:09,900 --> 00:35:13,770
for example depending on whether he's

00:35:12,390 --> 00:35:16,020
talking about software or hardware

00:35:13,770 --> 00:35:18,320
scalability I'm sort of simplifying a

00:35:16,020 --> 00:35:20,690
little bit for purposes of illustration

00:35:18,320 --> 00:35:24,540
so these are both linear scalability

00:35:20,690 --> 00:35:25,740
this is not linear any two points form a

00:35:24,540 --> 00:35:28,170
straight line but it doesn't intersect

00:35:25,740 --> 00:35:30,089
the doesn't intersect the origin

00:35:28,170 --> 00:35:31,589
something is happening here that's

00:35:30,089 --> 00:35:32,940
costing a little bit and we're getting a

00:35:31,589 --> 00:35:35,250
little less than twice as much

00:35:32,940 --> 00:35:38,790
performance at two worker units then we

00:35:35,250 --> 00:35:41,250
were at one so this is a typical system

00:35:38,790 --> 00:35:43,200
right most systems look like this and

00:35:41,250 --> 00:35:46,050
people will say ninety eight percent

00:35:43,200 --> 00:35:47,760
linear well if you plot point one and

00:35:46,050 --> 00:35:49,410
then you plot ninety-eight percent of

00:35:47,760 --> 00:35:51,780
two and then you plot ninety-eight

00:35:49,410 --> 00:35:53,880
percent of four and you keep doing that

00:35:51,780 --> 00:35:55,980
you will find that it's not 98% linear

00:35:53,880 --> 00:35:57,540
it's actually a nice curve right so

00:35:55,980 --> 00:36:00,569
there's nothing linear about it there's

00:35:57,540 --> 00:36:02,700
there's either linear or not so what's

00:36:00,569 --> 00:36:06,510
interesting here is not whether it's

00:36:02,700 --> 00:36:07,890
linear but why it's not linear and this

00:36:06,510 --> 00:36:12,240
is where I think dr. Gunther's

00:36:07,890 --> 00:36:14,069
contribution really is in this area he

00:36:12,240 --> 00:36:18,150
explains that there's a few different

00:36:14,069 --> 00:36:20,849
things that cause systems to scale worse

00:36:18,150 --> 00:36:23,160
than linearly so the first thing is what

00:36:20,849 --> 00:36:25,589
we call serialization there is a point

00:36:23,160 --> 00:36:28,079
where all of the work has to be done in

00:36:25,589 --> 00:36:29,880
a single thread okay so i've got some

00:36:28,079 --> 00:36:31,020
processes that are working along here

00:36:29,880 --> 00:36:32,790
let's say i've got four parallel

00:36:31,020 --> 00:36:34,040
processes and they're doing their work

00:36:32,790 --> 00:36:36,060
and then they come to a point where

00:36:34,040 --> 00:36:38,010
let's say the work has to be put

00:36:36,060 --> 00:36:40,350
together this might be for exam

00:36:38,010 --> 00:36:41,730
imple the final phase of a MapReduce

00:36:40,350 --> 00:36:45,350
when all the results are put together

00:36:41,730 --> 00:36:49,890
and that represents a point where

00:36:45,350 --> 00:36:52,500
parallelism is impossible okay and after

00:36:49,890 --> 00:36:54,900
that we can do you know we can work in

00:36:52,500 --> 00:36:57,720
four parallel processes again so if we

00:36:54,900 --> 00:37:00,870
have four servers or four threads or 4

00:36:57,720 --> 00:37:03,240
CPU cores or what have you in most

00:37:00,870 --> 00:37:06,330
systems there are going to be points in

00:37:03,240 --> 00:37:08,250
a systems execution where there's at

00:37:06,330 --> 00:37:11,310
least some degree of see reality and

00:37:08,250 --> 00:37:14,130
this is called I'm dolls Lords and it's

00:37:11,310 --> 00:37:16,760
a closely related to I'm dolls law if

00:37:14,130 --> 00:37:19,290
you model what happens to a system here

00:37:16,760 --> 00:37:21,150
the intuitive way to think about this is

00:37:19,290 --> 00:37:23,190
that no matter how many worker processes

00:37:21,150 --> 00:37:25,560
we make here we can make a billion we

00:37:23,190 --> 00:37:28,020
can make infinity worker processes here

00:37:25,560 --> 00:37:30,240
and as we make more and more parallel

00:37:28,020 --> 00:37:31,860
processes these get shorter right

00:37:30,240 --> 00:37:34,170
because we're doing a divide-and-conquer

00:37:31,860 --> 00:37:36,210
approach this does not get shorter and

00:37:34,170 --> 00:37:39,150
so the shortest that you can make this

00:37:36,210 --> 00:37:41,760
this process run in is this amount of

00:37:39,150 --> 00:37:44,730
time right here so there's an asymptote

00:37:41,760 --> 00:37:47,250
as you add more and more parallel ISM to

00:37:44,730 --> 00:37:49,050
this system it asymptotically approaches

00:37:47,250 --> 00:37:50,760
a ceiling and the ceiling is the

00:37:49,050 --> 00:37:53,070
reciprocal of whatever portion that

00:37:50,760 --> 00:37:55,530
little yellow vertical bar takes so if

00:37:53,070 --> 00:37:58,080
twenty percent of your system requires

00:37:55,530 --> 00:38:00,660
some serialization then you are never

00:37:58,080 --> 00:38:03,510
going to get faster than an effective

00:38:00,660 --> 00:38:05,070
speed up of five no matter how short you

00:38:03,510 --> 00:38:07,560
make those bars on the left and the

00:38:05,070 --> 00:38:09,180
right you can't get any you can't get

00:38:07,560 --> 00:38:13,080
this system to run in any faster than

00:38:09,180 --> 00:38:15,420
that and the the mathematical equation

00:38:13,080 --> 00:38:18,420
for that is that the capacity of n

00:38:15,420 --> 00:38:20,310
workers is equal to n over 1 plus Sigma

00:38:18,420 --> 00:38:23,160
and this is the portion that has to be

00:38:20,310 --> 00:38:25,800
serialized so Sigma would be point2 in

00:38:23,160 --> 00:38:30,180
the case where twenty percent is our

00:38:25,800 --> 00:38:33,000
serial fraction so so this is the first

00:38:30,180 --> 00:38:35,190
factor of Y things behave less than

00:38:33,000 --> 00:38:36,750
linearly the second factor is what I

00:38:35,190 --> 00:38:39,360
call crosstalk it's also called

00:38:36,750 --> 00:38:42,660
contention or coherency delay there's

00:38:39,360 --> 00:38:44,640
various words for that and this is when

00:38:42,660 --> 00:38:47,100
those parallel processes have to do some

00:38:44,640 --> 00:38:48,960
synchronization between themselves and

00:38:47,100 --> 00:38:50,430
this may be at the hardware level for

00:38:48,960 --> 00:38:51,330
example waiting on a cache line to

00:38:50,430 --> 00:38:53,640
become valid or

00:38:51,330 --> 00:38:56,850
maybe some shared lock or something like

00:38:53,640 --> 00:38:59,160
that but whatever it is the important

00:38:56,850 --> 00:39:01,230
insight into this is that the number of

00:38:59,160 --> 00:39:03,960
potential channels of crosstalk there

00:39:01,230 --> 00:39:06,270
grows quadratically with the number of

00:39:03,960 --> 00:39:08,970
parallel processes and that's expressed

00:39:06,270 --> 00:39:10,980
here in this box that I've put a red the

00:39:08,970 --> 00:39:13,080
red box around this new coefficient in

00:39:10,980 --> 00:39:15,720
the equation on the bottom if you look

00:39:13,080 --> 00:39:17,790
at that kappa n times n minus 1 n times

00:39:15,720 --> 00:39:19,950
n minus 1 as it goes out to infinity is

00:39:17,790 --> 00:39:22,140
really order N squared so that's where

00:39:19,950 --> 00:39:25,280
the the quadratically increasing cost

00:39:22,140 --> 00:39:28,470
comes from and kappa is this the

00:39:25,280 --> 00:39:31,680
fraction of this workload that requires

00:39:28,470 --> 00:39:34,290
crosstalk to to get its work done so

00:39:31,680 --> 00:39:35,900
this is kind of a simplified diagram of

00:39:34,290 --> 00:39:38,130
what many real systems might look like

00:39:35,900 --> 00:39:41,040
usually much more complicated than this

00:39:38,130 --> 00:39:42,840
but you can usually model them as either

00:39:41,040 --> 00:39:45,030
a single system with some see reality

00:39:42,840 --> 00:39:46,680
and crosstalk or a network of

00:39:45,030 --> 00:39:51,000
interconnected systems with see reality

00:39:46,680 --> 00:39:54,600
and crosstalk if you plot these three

00:39:51,000 --> 00:39:56,760
functions with no crosstalk and no see

00:39:54,600 --> 00:39:59,720
reality we get a nice linear scalability

00:39:56,760 --> 00:40:02,850
curve with some see reality we get

00:39:59,720 --> 00:40:04,620
approaching an asymptote right the slope

00:40:02,850 --> 00:40:07,440
of that red line always remains positive

00:40:04,620 --> 00:40:09,990
but it becomes almost flat after some

00:40:07,440 --> 00:40:12,390
period of time and then the universal

00:40:09,990 --> 00:40:14,010
scalability law is with that next

00:40:12,390 --> 00:40:16,260
fraction added in and that's the blue

00:40:14,010 --> 00:40:18,480
line and this behaves like real systems

00:40:16,260 --> 00:40:20,220
it actually has a peak and then you get

00:40:18,480 --> 00:40:21,540
worse performance after that and if

00:40:20,220 --> 00:40:23,310
you've looked at a lot of benchmarks you

00:40:21,540 --> 00:40:25,320
know that this is very typical if you

00:40:23,310 --> 00:40:27,360
try and push things further than the

00:40:25,320 --> 00:40:29,790
limit of their capacity you'll actually

00:40:27,360 --> 00:40:34,680
get less work done by trying to do more

00:40:29,790 --> 00:40:36,960
work so most systems really behave like

00:40:34,680 --> 00:40:39,540
the blue line in some way and it's a

00:40:36,960 --> 00:40:40,920
useful model it's not a perfect model

00:40:39,540 --> 00:40:43,860
but it's a useful model for

00:40:40,920 --> 00:40:45,690
understanding system performance so our

00:40:43,860 --> 00:40:48,540
scalability modeling algorithm to bring

00:40:45,690 --> 00:40:50,760
this back to the real world is we can

00:40:48,540 --> 00:40:52,650
actually measure the throughput and

00:40:50,760 --> 00:40:55,200
concurrency which are the the axes of

00:40:52,650 --> 00:40:56,910
that plot and then we can perform a

00:40:55,200 --> 00:40:59,250
regression like you can do in your

00:40:56,910 --> 00:41:01,050
spreadsheet I use more sophisticated

00:40:59,250 --> 00:41:02,760
tools than a spreadsheet because

00:41:01,050 --> 00:41:03,450
spreadsheets typically have a real hard

00:41:02,760 --> 00:41:05,430
time whether

00:41:03,450 --> 00:41:06,540
complicated function like that and you

00:41:05,430 --> 00:41:09,150
can pull out the sigma and kappa

00:41:06,540 --> 00:41:11,580
coefficients and then you can do

00:41:09,150 --> 00:41:12,840
something hopefully and profit but

00:41:11,580 --> 00:41:16,410
hopefully what comes out the other end

00:41:12,840 --> 00:41:18,720
is useful to you so the inputs that we

00:41:16,410 --> 00:41:20,040
need our throughput and concurrency the

00:41:18,720 --> 00:41:21,150
throughput is the part that we've

00:41:20,040 --> 00:41:22,590
already talked about right you just

00:41:21,150 --> 00:41:24,750
count how many times things happen

00:41:22,590 --> 00:41:26,880
within a given window of time the

00:41:24,750 --> 00:41:28,200
concurrency is a little harder there's a

00:41:26,880 --> 00:41:31,140
few different ways that we can get at

00:41:28,200 --> 00:41:35,690
this data for my purposes I've actually

00:41:31,140 --> 00:41:38,160
built into the ppt CP model tool a

00:41:35,690 --> 00:41:41,100
little algorithm that requires the data

00:41:38,160 --> 00:41:43,950
to be sorted on the way in by a rival

00:41:41,100 --> 00:41:45,330
time and then we simply work through

00:41:43,950 --> 00:41:46,680
that stream of data and every time

00:41:45,330 --> 00:41:48,360
something arrives we increment

00:41:46,680 --> 00:41:49,920
concurrency every time it departs we

00:41:48,360 --> 00:41:52,140
keep track of the time same thing we

00:41:49,920 --> 00:41:54,780
decrement the concurrency and I'll show

00:41:52,140 --> 00:41:57,480
you a diagram that explains this time is

00:41:54,780 --> 00:42:00,080
traveling from left to right here and if

00:41:57,480 --> 00:42:04,080
our observation window begins at x 0 and

00:42:00,080 --> 00:42:05,970
some query arrives here this q1 arrives

00:42:04,080 --> 00:42:10,080
here and then runs until time for and

00:42:05,970 --> 00:42:12,000
then stops in the meantime q2 arrives

00:42:10,080 --> 00:42:14,910
and briefly here we have a concurrency

00:42:12,000 --> 00:42:18,060
of two afterwards we have a concurrency

00:42:14,910 --> 00:42:21,690
of one again and then q2 finishes at

00:42:18,060 --> 00:42:23,940
times T equals seven so our observation

00:42:21,690 --> 00:42:26,850
time is 7 units long and we've got a

00:42:23,940 --> 00:42:28,730
total query time is the sum of the area

00:42:26,850 --> 00:42:31,410
under this curve which is eight units

00:42:28,730 --> 00:42:33,330
therefore the average concurrency in

00:42:31,410 --> 00:42:36,180
this time window is eight over seven or

00:42:33,330 --> 00:42:39,690
slightly more than one so this is

00:42:36,180 --> 00:42:43,350
basically what the TCP see it peaky TCP

00:42:39,690 --> 00:42:45,690
model tool does to compute average

00:42:43,350 --> 00:42:47,190
concurrency over windows of time so now

00:42:45,690 --> 00:42:48,930
we've got the second metric that we need

00:42:47,190 --> 00:42:52,680
for this Universal scalability law

00:42:48,930 --> 00:42:56,340
modeling and we can apply the the apply

00:42:52,680 --> 00:42:59,220
that model to our to our data so here's

00:42:56,340 --> 00:43:00,780
just a I'm just illustrating the

00:42:59,220 --> 00:43:03,420
commands that you need to to get this

00:43:00,780 --> 00:43:05,910
data out of our previous data first I'm

00:43:03,420 --> 00:43:08,640
sorting the requests file into a sorted

00:43:05,910 --> 00:43:10,200
file and then I'm running the PT TCP

00:43:08,640 --> 00:43:12,660
model tool against that with the type

00:43:10,200 --> 00:43:14,770
equals requests and putting that out

00:43:12,660 --> 00:43:16,840
into what i'm calling slice to you

00:43:14,770 --> 00:43:20,770
t so now I can operate directly off of

00:43:16,840 --> 00:43:24,250
sliced txt so I'm going to use new plot

00:43:20,770 --> 00:43:28,330
and here I'm actually selected a subset

00:43:24,250 --> 00:43:30,100
of the of the points that come out at

00:43:28,330 --> 00:43:32,170
lower concurrency so I'm trying to use

00:43:30,100 --> 00:43:33,850
lower concurrences to forecast what

00:43:32,170 --> 00:43:36,910
might happen at higher concurrency which

00:43:33,850 --> 00:43:41,230
is a very typical request you know this

00:43:36,910 --> 00:43:44,830
is June we expect that in December our

00:43:41,230 --> 00:43:46,360
you know our Christmas gift online store

00:43:44,830 --> 00:43:48,160
is going to get a lot of requests and

00:43:46,360 --> 00:43:51,010
we'd like to know what's going to happen

00:43:48,160 --> 00:43:54,550
if the concurrency goes from for up to

00:43:51,010 --> 00:43:56,140
you know 12 something like that well

00:43:54,550 --> 00:43:59,260
this model says the picture is not very

00:43:56,140 --> 00:44:02,380
good looking the green points are the

00:43:59,260 --> 00:44:05,470
actual observations the red line is the

00:44:02,380 --> 00:44:09,340
model with a sigma of fourteen percent

00:44:05,470 --> 00:44:11,140
and Kappa of less than a percent there

00:44:09,340 --> 00:44:12,760
it looks like there's a very close fit

00:44:11,140 --> 00:44:15,610
here ninety-eight percent that's the

00:44:12,760 --> 00:44:18,940
standard r squared closeness of fit

00:44:15,610 --> 00:44:21,220
metric and visually you can see land and

00:44:18,940 --> 00:44:22,510
there's some fit I mean it's not as

00:44:21,220 --> 00:44:25,660
clean as it could be and I've seen

00:44:22,510 --> 00:44:27,670
systems that are cleaner than this but

00:44:25,660 --> 00:44:29,770
it looks like it might be you know some

00:44:27,670 --> 00:44:31,140
sort of useful useful projection and we

00:44:29,770 --> 00:44:34,420
can see that if we're looking at

00:44:31,140 --> 00:44:37,210
concurrency 12 for example we're not

00:44:34,420 --> 00:44:39,280
going to scale we're at that point we're

00:44:37,210 --> 00:44:40,570
probably in the we're past the leveling

00:44:39,280 --> 00:44:41,680
off and we're probably into though

00:44:40,570 --> 00:44:45,670
you're having serious performance

00:44:41,680 --> 00:44:46,930
problems level if I plot the rest of the

00:44:45,670 --> 00:44:49,630
points in there you see it's actually

00:44:46,930 --> 00:44:51,970
even worse than that so the model the

00:44:49,630 --> 00:44:54,160
universal scalability law has actually

00:44:51,970 --> 00:44:57,730
overestimated the scalability of this

00:44:54,160 --> 00:44:59,770
system another interesting thing about

00:44:57,730 --> 00:45:01,990
this is that these points are kind of

00:44:59,770 --> 00:45:04,630
more widely dispersed and that's pretty

00:45:01,990 --> 00:45:06,160
typical if you take any data set like

00:45:04,630 --> 00:45:08,020
this you will not only see that

00:45:06,160 --> 00:45:09,910
characteristic curve but you'll also see

00:45:08,020 --> 00:45:13,150
it sort of start to shotgun out more as

00:45:09,910 --> 00:45:16,150
it comes up and to the right so this can

00:45:13,150 --> 00:45:18,010
give you another indication of how well

00:45:16,150 --> 00:45:20,200
your system is behaving when it starts

00:45:18,010 --> 00:45:24,100
to become much less uniform and you

00:45:20,200 --> 00:45:27,310
start to get a less tightly clustered

00:45:24,100 --> 00:45:29,950
set of points there on the plot

00:45:27,310 --> 00:45:32,410
this is this is running in the Amazon

00:45:29,950 --> 00:45:35,070
Cloud it's on the largest amazon ec2

00:45:32,410 --> 00:45:37,780
instance which has eight virtual CPUs as

00:45:35,070 --> 00:45:40,300
a matter of practical experience I can

00:45:37,780 --> 00:45:41,920
tell you the system like this you're not

00:45:40,300 --> 00:45:44,170
going to run more than eight queries

00:45:41,920 --> 00:45:48,400
because you've only got eight CPUs right

00:45:44,170 --> 00:45:50,860
so so you can also apply your knowledge

00:45:48,400 --> 00:45:52,720
of systems and how they behave and you

00:45:50,860 --> 00:45:54,910
really need to do that you need judgment

00:45:52,720 --> 00:45:59,380
in order to interpret these graphs so i

00:45:54,910 --> 00:46:01,000
can tell you on pretty much any system i

00:45:59,380 --> 00:46:06,370
can tell you that a working concurrency

00:46:01,000 --> 00:46:07,960
on an amazon ec2 system is on a CPU

00:46:06,370 --> 00:46:11,020
bound system is less than eight on a

00:46:07,960 --> 00:46:14,380
system that has some mixture of CPU and

00:46:11,020 --> 00:46:16,090
i/o bound you may get 12 maybe if you're

00:46:14,380 --> 00:46:18,330
lucky because some things actually are

00:46:16,090 --> 00:46:21,880
off CPU while they're waiting for i/o

00:46:18,330 --> 00:46:23,470
thus effectively freeing up more cpus

00:46:21,880 --> 00:46:25,810
but you're not going to get a

00:46:23,470 --> 00:46:31,240
concurrency of 20 it just it doesn't

00:46:25,810 --> 00:46:32,920
happen performance tanks very quickly so

00:46:31,240 --> 00:46:35,620
how to approach the universal

00:46:32,920 --> 00:46:38,140
scalability law in my opinion is to to

00:46:35,620 --> 00:46:41,080
look at it in in two dimensions one is

00:46:38,140 --> 00:46:46,990
best case in one is the worst case so

00:46:41,080 --> 00:46:49,210
the worst case bounds are to say that if

00:46:46,990 --> 00:46:50,950
we get deep into the math there's

00:46:49,210 --> 00:46:52,780
something called repairmen queuing which

00:46:50,950 --> 00:46:53,740
is what am dolls loll models and then

00:46:52,780 --> 00:46:55,270
there's something which is even worse

00:46:53,740 --> 00:46:57,100
which is called synchronous repairmen

00:46:55,270 --> 00:46:59,050
queuing and that's what the universal

00:46:57,100 --> 00:47:01,390
scalability law models and this is

00:46:59,050 --> 00:47:02,710
actually if you understand what the the

00:47:01,390 --> 00:47:05,770
queuing model is I should make some

00:47:02,710 --> 00:47:07,450
diagrams for this it's a very stupid

00:47:05,770 --> 00:47:10,240
sort of queueing it's like nobody would

00:47:07,450 --> 00:47:11,650
really build a system that behaves this

00:47:10,240 --> 00:47:13,780
badly or at least not intentionally

00:47:11,650 --> 00:47:17,470
right so it's a very much of a

00:47:13,780 --> 00:47:19,390
worst-case scalability model the

00:47:17,470 --> 00:47:21,160
thinking that I'm applying here is if

00:47:19,390 --> 00:47:22,570
you are a performance engineer for

00:47:21,160 --> 00:47:24,490
example if you are performance

00:47:22,570 --> 00:47:26,740
engineering at Percona where we're

00:47:24,490 --> 00:47:29,560
trying to make my SQL work better we can

00:47:26,740 --> 00:47:31,990
use this as a reference point and say we

00:47:29,560 --> 00:47:33,700
really would like the system to perform

00:47:31,990 --> 00:47:36,190
better than the worst-case possibility

00:47:33,700 --> 00:47:38,170
right so we can we can use this model

00:47:36,190 --> 00:47:39,820
and we can say you know performance and

00:47:38,170 --> 00:47:40,120
scalability are dropping off more

00:47:39,820 --> 00:47:41,860
quickly

00:47:40,120 --> 00:47:44,080
than they should what's happening we're

00:47:41,860 --> 00:47:46,420
may be entering some range of

00:47:44,080 --> 00:47:47,800
performance characteristics where we're

00:47:46,420 --> 00:47:49,300
hitting a new bottleneck that we weren't

00:47:47,800 --> 00:47:50,890
hitting at a lower concurrency for

00:47:49,300 --> 00:47:51,910
example and we can say there's something

00:47:50,890 --> 00:47:54,010
that's happening at this higher

00:47:51,910 --> 00:47:57,400
concurrency maybe we can investigate and

00:47:54,010 --> 00:47:59,710
reduce that bottleneck so systems

00:47:57,400 --> 00:48:01,480
autoscale better than the usl right and

00:47:59,710 --> 00:48:03,250
if they don't we've got something to

00:48:01,480 --> 00:48:04,390
talk about if you don't have a model you

00:48:03,250 --> 00:48:06,700
don't really have anything to talk about

00:48:04,390 --> 00:48:09,220
I mean if you didn't have a model who's

00:48:06,700 --> 00:48:10,660
to say that the graph shouldn't go like

00:48:09,220 --> 00:48:13,810
that or the graph shouldn't go like that

00:48:10,660 --> 00:48:16,680
it would just be somebody's opinion on

00:48:13,810 --> 00:48:19,000
the other hand if you are a responsible

00:48:16,680 --> 00:48:20,170
operations engineer you know that you

00:48:19,000 --> 00:48:21,610
should never count your chicks before

00:48:20,170 --> 00:48:23,170
they hatch and so you're going to use

00:48:21,610 --> 00:48:24,910
the universal scalability law as a

00:48:23,170 --> 00:48:26,770
best-case model you're going to say

00:48:24,910 --> 00:48:28,660
that's the ceiling you know it may be a

00:48:26,770 --> 00:48:30,190
worst-case but I'm not going to count on

00:48:28,660 --> 00:48:32,230
any more than that in fact I probably

00:48:30,190 --> 00:48:35,980
ought to count on less than that and

00:48:32,230 --> 00:48:37,450
that's why we saw back here we see we

00:48:35,980 --> 00:48:41,350
really would have been wise to count on

00:48:37,450 --> 00:48:42,940
less than that red line right so be

00:48:41,350 --> 00:48:45,220
pessimistic if you're using this for

00:48:42,940 --> 00:48:50,370
capacity planning or performance

00:48:45,220 --> 00:48:53,080
forecasting purposes it's just a model

00:48:50,370 --> 00:48:55,990
we can flip the model upside down so to

00:48:53,080 --> 00:48:58,240
speak and throughput concurrency and

00:48:55,990 --> 00:49:00,700
response time have a clear mathematical

00:48:58,240 --> 00:49:03,070
relationship called littles law this is

00:49:00,700 --> 00:49:05,770
a really interesting fundamental

00:49:03,070 --> 00:49:07,960
relationship in performance mathematics

00:49:05,770 --> 00:49:10,450
or even in operations researches which

00:49:07,960 --> 00:49:12,640
is where it came from because it makes

00:49:10,450 --> 00:49:14,230
no assumptions about a lot of things

00:49:12,640 --> 00:49:16,450
that you otherwise have to put into your

00:49:14,230 --> 00:49:19,450
models so many models are very difficult

00:49:16,450 --> 00:49:21,820
to to work with because they require a

00:49:19,450 --> 00:49:23,590
lot of knowledge about the system and

00:49:21,820 --> 00:49:25,360
about the characteristics of the system

00:49:23,590 --> 00:49:27,400
for example maybe you're familiar with

00:49:25,360 --> 00:49:30,130
classical queueing theory and the Erlang

00:49:27,400 --> 00:49:32,290
C functions and so forth this beautiful

00:49:30,130 --> 00:49:35,200
elegant correct works in call centres

00:49:32,290 --> 00:49:38,860
very rarely works in database servers

00:49:35,200 --> 00:49:40,450
because you have to have and know and

00:49:38,860 --> 00:49:42,880
measure and prove that you have a

00:49:40,450 --> 00:49:44,440
certain distribution of response times

00:49:42,880 --> 00:49:47,490
and a certain distribution of inter

00:49:44,440 --> 00:49:50,470
arrival times and based on those

00:49:47,490 --> 00:49:53,050
statistical distributions you might have

00:49:50,470 --> 00:49:53,590
to apply the Erlang B or the Erlang C or

00:49:53,050 --> 00:49:55,480
one of

00:49:53,590 --> 00:49:57,520
I think there's like 17 other or lank

00:49:55,480 --> 00:49:59,350
models and they're all very difficult

00:49:57,520 --> 00:50:02,230
it's not even a closed-form equation so

00:49:59,350 --> 00:50:04,210
it's it's a it requires a lot of

00:50:02,230 --> 00:50:05,500
computation and it's not easy at all to

00:50:04,210 --> 00:50:08,710
do regressions against it into

00:50:05,500 --> 00:50:10,360
essentially it's a very difficult model

00:50:08,710 --> 00:50:12,160
to actually apply in the real world the

00:50:10,360 --> 00:50:13,900
beauty of the universal scalability law

00:50:12,160 --> 00:50:16,060
is that it's extremely practical and

00:50:13,900 --> 00:50:19,060
easy to apply and gives you some sort of

00:50:16,060 --> 00:50:22,210
a stick even though it's not perfection

00:50:19,060 --> 00:50:24,700
and littles law has similar

00:50:22,210 --> 00:50:27,940
characteristics it's independent of

00:50:24,700 --> 00:50:30,820
response time arrival distributions all

00:50:27,940 --> 00:50:32,290
of those kinds of things it works and

00:50:30,820 --> 00:50:34,320
the proof of that is actually very

00:50:32,290 --> 00:50:36,520
complicated for such a simple little law

00:50:34,320 --> 00:50:39,880
and took many years for somebody to

00:50:36,520 --> 00:50:41,860
actually prove it but this it's a simple

00:50:39,880 --> 00:50:43,330
relationship between concurrency

00:50:41,860 --> 00:50:44,620
throughput and response time so we can

00:50:43,330 --> 00:50:46,780
take those metrics that we had before

00:50:44,620 --> 00:50:48,750
just manipulate the equation a little

00:50:46,780 --> 00:50:51,460
bit and we get response time is equal to

00:50:48,750 --> 00:50:53,980
concurrency over throughput and you can

00:50:51,460 --> 00:50:56,650
apply the same model to it this is

00:50:53,980 --> 00:50:58,720
actually the same the same data here I'm

00:50:56,650 --> 00:51:00,400
just plotting it as response time

00:50:58,720 --> 00:51:02,980
instead of as throughput versus

00:51:00,400 --> 00:51:05,140
concurrency so we've still got

00:51:02,980 --> 00:51:07,630
concurrency along the x-axis here but

00:51:05,140 --> 00:51:09,790
the y axis is response time and we can

00:51:07,630 --> 00:51:12,490
use this to forecast for example again

00:51:09,790 --> 00:51:15,640
pessimistically or optimistically we can

00:51:12,490 --> 00:51:17,500
use this to forecast how long responses

00:51:15,640 --> 00:51:22,420
might start to take at a particular

00:51:17,500 --> 00:51:24,690
level of concurrency so for me that's

00:51:22,420 --> 00:51:26,890
why i call this performance forecasting

00:51:24,690 --> 00:51:28,870
because for me performance and

00:51:26,890 --> 00:51:32,650
scalability are sort of flip sides of

00:51:28,870 --> 00:51:34,420
the same coin but it doesn't do to to

00:51:32,650 --> 00:51:35,830
confuse them if you have such precise

00:51:34,420 --> 00:51:41,290
definitions that you're trying to work

00:51:35,830 --> 00:51:42,880
with one of the things that I've had bad

00:51:41,290 --> 00:51:45,670
luck with a lot is getting dirty data

00:51:42,880 --> 00:51:47,590
the universal scalability law works much

00:51:45,670 --> 00:51:49,540
better when you have nice clean data on

00:51:47,590 --> 00:51:51,100
a Wells behaved system or at least a

00:51:49,540 --> 00:51:53,980
reasonably well behaved system with not

00:51:51,100 --> 00:51:56,350
too much mixture in the workload without

00:51:53,980 --> 00:52:00,490
too much TCP dump dropping packets all

00:51:56,350 --> 00:52:02,530
of those kinds of things so you do have

00:52:00,490 --> 00:52:03,700
to actually be careful with the data

00:52:02,530 --> 00:52:05,470
that you put into it of course garbage

00:52:03,700 --> 00:52:07,330
in garbage out one of the things that

00:52:05,470 --> 00:52:09,670
I'll do is I'll do that

00:52:07,330 --> 00:52:11,590
that black box plot and I'll look for

00:52:09,670 --> 00:52:14,110
areas that have bad performance like

00:52:11,590 --> 00:52:17,560
those spikes and I'll say the system is

00:52:14,110 --> 00:52:19,570
behaving sub optimally there and I'm

00:52:17,560 --> 00:52:21,540
going to snip out those sections right

00:52:19,570 --> 00:52:24,730
I'll just throw away that little bit of

00:52:21,540 --> 00:52:27,190
the log and not try and analyze over a

00:52:24,730 --> 00:52:30,190
system that is actually clearly behaving

00:52:27,190 --> 00:52:32,020
badly at particular points in time you

00:52:30,190 --> 00:52:33,520
have to be careful with this some people

00:52:32,020 --> 00:52:37,420
say you should clean your data other

00:52:33,520 --> 00:52:39,670
people say that's just lying I've for me

00:52:37,420 --> 00:52:42,280
the balance is somewhere in between you

00:52:39,670 --> 00:52:44,350
have to for me to get good results with

00:52:42,280 --> 00:52:46,330
these kinds of things you have to assume

00:52:44,350 --> 00:52:48,130
that the system is well behaved if there

00:52:46,330 --> 00:52:49,660
are points in the system where it's not

00:52:48,130 --> 00:52:51,190
well behaved you can say what we can do

00:52:49,660 --> 00:52:54,550
something about that right maybe we can

00:52:51,190 --> 00:52:55,720
make it behave better if not then we we

00:52:54,550 --> 00:52:58,120
have to have an entirely different

00:52:55,720 --> 00:53:00,940
discussion but if we can capture a

00:52:58,120 --> 00:53:03,130
period of time over a range of different

00:53:00,940 --> 00:53:05,530
workloads a range of different

00:53:03,130 --> 00:53:08,500
concurrences where the system appears to

00:53:05,530 --> 00:53:10,120
be reasonably well behaved then it's

00:53:08,500 --> 00:53:11,650
okay to look at that as a representative

00:53:10,120 --> 00:53:13,960
sample and what you're really trying to

00:53:11,650 --> 00:53:15,940
do is not model the time during which

00:53:13,960 --> 00:53:18,160
your backups were running or the time

00:53:15,940 --> 00:53:19,930
during which your your hourly rebuild of

00:53:18,160 --> 00:53:21,010
your summary tables in the database was

00:53:19,930 --> 00:53:24,190
running or something like that right

00:53:21,010 --> 00:53:25,630
you're trying to find a fairly clear

00:53:24,190 --> 00:53:27,460
signal without some other noise

00:53:25,630 --> 00:53:30,210
intruding that that would throw a monkey

00:53:27,460 --> 00:53:32,680
wrench into your into your computations

00:53:30,210 --> 00:53:35,650
so that's kind of like the standard

00:53:32,680 --> 00:53:38,890
caveat emptor the temptation and I will

00:53:35,650 --> 00:53:40,210
certainly admit to this is to kind of

00:53:38,890 --> 00:53:42,550
see the elegance and the beauty of the

00:53:40,210 --> 00:53:45,370
universal scalability law and then start

00:53:42,550 --> 00:53:46,930
trying to do it everywhere and after a

00:53:45,370 --> 00:53:47,980
half a dozen of those you kind of start

00:53:46,930 --> 00:53:49,870
to figure out it doesn't apply

00:53:47,980 --> 00:53:52,060
everywhere you have to get good data you

00:53:49,870 --> 00:53:55,840
have to understand how to apply so forth

00:53:52,060 --> 00:53:57,430
and so on so here's some resources all

00:53:55,840 --> 00:53:59,380
of the software that I mentioned other

00:53:57,430 --> 00:54:01,690
than TCP dump can be downloaded from

00:53:59,380 --> 00:54:05,050
Percona dot-com / software it's all

00:54:01,690 --> 00:54:06,370
inside of your own a toolkit you're in a

00:54:05,050 --> 00:54:08,560
mysql talk so you ought to know about

00:54:06,370 --> 00:54:10,710
pregunta toolkit already and Neil

00:54:08,560 --> 00:54:14,020
Gunther's book gorilla capacity planning

00:54:10,710 --> 00:54:15,640
it's a very dense book there's a lot of

00:54:14,020 --> 00:54:18,640
really deep stuff in there and there's a

00:54:15,640 --> 00:54:19,960
lot of sort of he'll show you something

00:54:18,640 --> 00:54:21,040
and then you'll say and then you can do

00:54:19,960 --> 00:54:23,380
this within you go

00:54:21,040 --> 00:54:24,880
great I'm all enthused and energized and

00:54:23,380 --> 00:54:26,410
you go and you start to actually try and

00:54:24,880 --> 00:54:29,140
apply it to your systems and you go I'm

00:54:26,410 --> 00:54:32,170
lost I need somebody to help me figure

00:54:29,140 --> 00:54:33,760
this out well Neil Gunther has guerrilla

00:54:32,170 --> 00:54:36,310
capacity planning workshops where you

00:54:33,760 --> 00:54:37,600
can go and I have heard but I've not

00:54:36,310 --> 00:54:40,120
been to one that those are really

00:54:37,600 --> 00:54:43,630
hardcore and a very good investment of

00:54:40,120 --> 00:54:45,370
your time or you can look at my second

00:54:43,630 --> 00:54:48,790
white paper here forecasting mysql

00:54:45,370 --> 00:54:51,130
scalability with the universal

00:54:48,790 --> 00:54:53,230
scalability law is the rest of the title

00:54:51,130 --> 00:54:56,740
on that one those white papers are on

00:54:53,230 --> 00:54:59,740
percona calm and all that's free so you

00:54:56,740 --> 00:55:01,420
can download all that the particular

00:54:59,740 --> 00:55:03,520
thing about that white paper that I want

00:55:01,420 --> 00:55:05,770
to encourage you to look at it for is

00:55:03,520 --> 00:55:07,420
that it's there's a section of it that

00:55:05,770 --> 00:55:08,500
deals with mysql and there's a section

00:55:07,420 --> 00:55:10,090
that deals with the universal

00:55:08,500 --> 00:55:12,340
scalability law so if you get Neil

00:55:10,090 --> 00:55:14,350
Gunther's book read his book first and

00:55:12,340 --> 00:55:16,060
then read that white paper and hopefully

00:55:14,350 --> 00:55:17,800
the section in that white paper on the

00:55:16,060 --> 00:55:20,650
scalability law can kind of tie things

00:55:17,800 --> 00:55:22,270
together for you and see you help you

00:55:20,650 --> 00:55:24,400
see how to apply that in the real world

00:55:22,270 --> 00:55:25,840
because for me it actually took about a

00:55:24,400 --> 00:55:27,550
year before I was able to get some

00:55:25,840 --> 00:55:30,010
traction on this so hopefully that can

00:55:27,550 --> 00:55:31,680
help you shortcut that the MySQL

00:55:30,010 --> 00:55:34,690
performance analysis white paper

00:55:31,680 --> 00:55:35,920
contains not only the exact data that

00:55:34,690 --> 00:55:38,680
I've shown you here for the first

00:55:35,920 --> 00:55:40,330
portion of my slideshow but all of the

00:55:38,680 --> 00:55:41,980
command line arguments and everything

00:55:40,330 --> 00:55:43,570
that you need to reproduce my results

00:55:41,980 --> 00:55:46,030
and get the graphs just like I did and

00:55:43,570 --> 00:55:47,680
there's a link to the sample data itself

00:55:46,030 --> 00:55:51,520
so that you can download at our bowl of

00:55:47,680 --> 00:55:53,170
that and then these slides are at this

00:55:51,520 --> 00:55:54,820
Google URL if you if you would like

00:55:53,170 --> 00:55:56,710
those and I'm also going to give these

00:55:54,820 --> 00:55:58,920
slides to the southeast linux fest

00:55:56,710 --> 00:56:01,450
organizers so they can post them and

00:55:58,920 --> 00:56:03,160
this is my contact information i also

00:56:01,450 --> 00:56:05,590
have business cards I'm always delighted

00:56:03,160 --> 00:56:08,170
to talk with people in person or on

00:56:05,590 --> 00:56:09,940
email you can follow me on Twitter you

00:56:08,170 --> 00:56:12,310
can look me up on LinkedIn connect to me

00:56:09,940 --> 00:56:14,140
I'm always happy to talk with people and

00:56:12,310 --> 00:56:16,150
I always enjoy the discussions that come

00:56:14,140 --> 00:56:18,550
out of it I learn a lot from people

00:56:16,150 --> 00:56:19,900
who've come to this talk and then

00:56:18,550 --> 00:56:22,240
afterwards they point me in new

00:56:19,900 --> 00:56:25,060
directions most of which i have yet to

00:56:22,240 --> 00:56:27,070
follow up on time is a precious resource

00:56:25,060 --> 00:56:29,490
we have a few minutes i think for

00:56:27,070 --> 00:56:29,490
questions

00:56:30,819 --> 00:56:35,349
or yes sir

00:56:40,580 --> 00:56:52,910
in SNMP yeah so one of the things I

00:56:51,110 --> 00:56:55,250
didn't mention but one of the real

00:56:52,910 --> 00:56:57,860
motivators for this is that a lot of

00:56:55,250 --> 00:57:01,220
systems are either not instrumented or

00:56:57,860 --> 00:57:03,770
very poorly instrumented so even in a

00:57:01,220 --> 00:57:06,440
system that's completely uninstall a

00:57:03,770 --> 00:57:08,600
memcache d memcache d has a few counters

00:57:06,440 --> 00:57:09,920
right they really don't tell you

00:57:08,600 --> 00:57:14,090
anything about what's going on inside

00:57:09,920 --> 00:57:16,010
the system TCP is a great way to to get

00:57:14,090 --> 00:57:18,020
that information without having to rely

00:57:16,010 --> 00:57:20,180
on that's why I call it black box

00:57:18,020 --> 00:57:23,810
because you can kind of instrument

00:57:20,180 --> 00:57:25,670
systems externally so if you get the

00:57:23,810 --> 00:57:27,620
information directly from the

00:57:25,670 --> 00:57:31,220
application for example Oracle gives you

00:57:27,620 --> 00:57:33,050
a lot of information in the awr and a sh

00:57:31,220 --> 00:57:34,580
repositories you can get all the

00:57:33,050 --> 00:57:36,290
information directly from Oracle you

00:57:34,580 --> 00:57:38,590
don't need to do TCP dump on oracle

00:57:36,290 --> 00:57:43,820
right mysql doesn't really have that in

00:57:38,590 --> 00:57:47,060
current version mysql doesn't itself

00:57:43,820 --> 00:57:49,280
doesn't have any SNMP support no future

00:57:47,060 --> 00:57:50,900
versions of mysql mysql 5 about six in

00:57:49,280 --> 00:57:52,220
particular the performance schema is

00:57:50,900 --> 00:57:54,470
going to contain a lot of the data that

00:57:52,220 --> 00:57:56,210
we would need to do this but what if

00:57:54,470 --> 00:57:57,980
you're working on mongodb or what if you

00:57:56,210 --> 00:58:01,520
want to know the behavior of your whole

00:57:57,980 --> 00:58:02,660
web cluster of Apache servers or

00:58:01,520 --> 00:58:08,720
something like that you can still use

00:58:02,660 --> 00:58:11,590
these techniques any more questions all

00:58:08,720 --> 00:58:11,590
right thanks

00:58:20,869 --> 00:58:27,319
how's that sigh every way this is the

00:58:24,019 --> 00:58:29,480
way to better utilize all your resources

00:58:27,319 --> 00:58:32,930
and it makes managing all your resources

00:58:29,480 --> 00:58:36,759
pretty easy all of the innovation is

00:58:32,930 --> 00:58:40,279
happening in open source the

00:58:36,759 --> 00:58:42,079
collaborative nature and of the you know

00:58:40,279 --> 00:58:43,999
of the community and the speed at which

00:58:42,079 --> 00:58:46,190
these are these you know these

00:58:43,999 --> 00:58:49,369
deficiencies these bugs are getting

00:58:46,190 --> 00:58:51,470
discovered and then fixed is that really

00:58:49,369 --> 00:58:54,440
shows the power of the you know of the

00:58:51,470 --> 00:58:56,799
open source community it is global and

00:58:54,440 --> 00:59:00,349
it's definitely because of the users

00:58:56,799 --> 00:59:06,319
community people are extremely friendly

00:59:00,349 --> 00:59:08,029
and almost ready to help if you go on

00:59:06,319 --> 00:59:10,220
tire see any day you'll see these guys

00:59:08,029 --> 00:59:12,890
helping each other out and they're all

00:59:10,220 --> 00:59:14,569
doing it like in a selfless manner the

00:59:12,890 --> 00:59:17,559
product is transparent for everyone

00:59:14,569 --> 00:59:20,749
everyone can look at the code base

00:59:17,559 --> 00:59:22,990
everyone can see how close that is being

00:59:20,749 --> 00:59:28,489
built nothing nothing is proprietary

00:59:22,990 --> 00:59:31,099
everything is open in many ways it's

00:59:28,489 --> 00:59:35,569
absolutely vital to the the unborn

00:59:31,099 --> 00:59:39,799
health cloudstack the most exciting

00:59:35,569 --> 00:59:42,589
event in recent memory for me was our

00:59:39,799 --> 00:59:45,259
first developer boot camp

00:59:42,589 --> 00:59:47,900
and our call gave people I gave me two

00:59:45,259 --> 00:59:51,859
weeks notice to come attend I was

00:59:47,900 --> 00:59:56,119
expecting 25 or 30 people so we ended up

00:59:51,859 --> 00:59:58,880
with 87 people and had to go get board

00:59:56,119 --> 01:00:01,400
chairs in the room twice everything

00:59:58,880 --> 01:00:04,670
within cloud computing is commodity and

01:00:01,400 --> 01:00:07,729
is open source and so I don't think that

01:00:04,670 --> 01:00:09,499
you will you'll see anywhere where open

01:00:07,729 --> 01:00:12,529
source is not pervasive in cloud

01:00:09,499 --> 01:00:15,079
computing and so i think it's i think

01:00:12,529 --> 01:00:16,579
it's an assumption i think when you talk

01:00:15,079 --> 01:00:20,319
about cloud computing you're really

01:00:16,579 --> 01:00:20,319
talking about a source cloud computing

01:00:20,589 --> 01:00:26,660
cloud sac is a robust solution for large

01:00:23,869 --> 01:00:29,029
deployments you'll have dozens of data

01:00:26,660 --> 01:00:32,989
centers and thousands of servers in each

01:00:29,029 --> 01:00:36,319
data center is these hardware is going

01:00:32,989 --> 01:00:39,559
to fail and CloudStack is designed to

01:00:36,319 --> 01:00:42,019
handle number one that mass scale number

01:00:39,559 --> 01:00:44,749
two it's designed to handle the failure

01:00:42,019 --> 01:00:46,999
that inevitably happens in large

01:00:44,749 --> 01:00:50,809
deployments we started working on

01:00:46,999 --> 01:00:54,170
contact over four years ago and it was

01:00:50,809 --> 01:00:56,839
the original set of people working on it

01:00:54,170 --> 01:01:00,950
had a background of delivering software

01:00:56,839 --> 01:01:05,210
telcos and service providers lots of QA

01:01:00,950 --> 01:01:08,809
lots of users actually using it high

01:01:05,210 --> 01:01:11,900
availability is a key feature multiple

01:01:08,809 --> 01:01:13,910
hypervisors support different network

01:01:11,900 --> 01:01:16,579
models you can pick up whatever suits

01:01:13,910 --> 01:01:18,859
you better while step management server

01:01:16,579 --> 01:01:22,549
can be deployed in different physical

01:01:18,859 --> 01:01:24,200
machines it definitely has a huge

01:01:22,549 --> 01:01:29,180
footprint it's being deployed everywhere

01:01:24,200 --> 01:01:31,759
there's a major movie studio that they

01:01:29,180 --> 01:01:35,059
were using cloudstack they were using it

01:01:31,759 --> 01:01:37,039
to transcode video and i thought that

01:01:35,059 --> 01:01:38,690
was terribly fascinating what i found

01:01:37,039 --> 01:01:41,960
more fascinating is what they did during

01:01:38,690 --> 01:01:44,749
lunch where they would spin up you know

01:01:41,960 --> 01:01:46,130
50 or 60 game servers then as soon as

01:01:44,749 --> 01:01:46,630
lunch was over they would destroy all

01:01:46,130 --> 01:01:48,809
the guests

01:01:46,630 --> 01:01:52,210
Susan go back to doing real work

01:01:48,809 --> 01:01:53,710
cloudstack is vast it touches so many

01:01:52,210 --> 01:01:55,599
different aspects and there's no one

01:01:53,710 --> 01:01:58,269
person that's kind of like a master of

01:01:55,599 --> 01:02:02,049
all those realms I think clouds stack as

01:01:58,269 --> 01:02:04,299
a project is going to be one of the

01:02:02,049 --> 01:02:08,349
leaders simply because it's some of the

01:02:04,299 --> 01:02:13,660
most feature Poland and and robust

01:02:08,349 --> 01:02:16,680
platforms out they were I haven't seen

01:02:13,660 --> 01:02:16,680
your limits of the clouds dag

01:02:29,500 --> 01:02:31,560
you

01:02:34,880 --> 01:02:39,960
when we created asterisk over a decade

01:02:37,590 --> 01:02:41,910
ago we could not have imagined that

01:02:39,960 --> 01:02:44,100
asterisk would not only become the most

01:02:41,910 --> 01:02:46,260
widely adopted open source communication

01:02:44,100 --> 01:02:48,300
software on the planet but that it would

01:02:46,260 --> 01:02:50,820
impact the entire industry in the way

01:02:48,300 --> 01:02:52,800
that it has today asterisk has found its

01:02:50,820 --> 01:02:55,410
way in the more than 170 countries and

01:02:52,800 --> 01:02:57,390
virtually every fortune 1000 company the

01:02:55,410 --> 01:02:59,460
success of asterisk has enabled a

01:02:57,390 --> 01:03:00,869
transition of power from the hands of

01:02:59,460 --> 01:03:03,150
the traditional proprietary phone

01:03:00,869 --> 01:03:05,550
vendors into the hands of the users and

01:03:03,150 --> 01:03:07,470
administrators of phone systems using

01:03:05,550 --> 01:03:08,700
this power our customers have created

01:03:07,470 --> 01:03:10,650
all sorts of business changing

01:03:08,700 --> 01:03:12,510
applications from small office phone

01:03:10,650 --> 01:03:15,000
systems to mission-critical call centers

01:03:12,510 --> 01:03:16,619
the international carrier networks in

01:03:15,000 --> 01:03:18,420
fact there's even an entire country

01:03:16,619 --> 01:03:21,000
those communications infrastructure runs

01:03:18,420 --> 01:03:22,920
on esters the gym has always been about

01:03:21,000 --> 01:03:24,630
creating technology that expands

01:03:22,920 --> 01:03:26,820
communications capabilities in ways that

01:03:24,630 --> 01:03:28,020
we could never have imagined and that's

01:03:26,820 --> 01:03:30,390
part of what's game-changing about

01:03:28,020 --> 01:03:33,090
Digium today we're doing it again this

01:03:30,390 --> 01:03:35,190
time by introducing a new family of HD

01:03:33,090 --> 01:03:37,320
IP phones that extends control of the

01:03:35,190 --> 01:03:39,060
user all the way to the desktop the

01:03:37,320 --> 01:03:40,770
launch of these new products represents

01:03:39,060 --> 01:03:42,750
the next phase indigenous history of

01:03:40,770 --> 01:03:45,270
innovation these are the first and only

01:03:42,750 --> 01:03:46,980
IP phones designed to fully leverage the

01:03:45,270 --> 01:03:48,540
power of esters when we first discussed

01:03:46,980 --> 01:03:50,550
our expectations for building a family

01:03:48,540 --> 01:03:52,740
of phones for use with asterisks our

01:03:50,550 --> 01:03:54,450
requirements were pretty simple we asked

01:03:52,740 --> 01:03:56,100
the team to build the phones such that

01:03:54,450 --> 01:03:58,290
they were easy to install integrate

01:03:56,100 --> 01:04:00,150
provision and use I think you'll soon

01:03:58,290 --> 01:04:02,700
agree our engineers have delivered on

01:04:00,150 --> 01:04:04,350
that goal user feedback is validating

01:04:02,700 --> 01:04:06,450
that when it comes to operation with

01:04:04,350 --> 01:04:08,880
Pastor space systems including our own

01:04:06,450 --> 01:04:11,460
Switchvox based product these are the

01:04:08,880 --> 01:04:12,750
easiest to use best integrated most

01:04:11,460 --> 01:04:15,359
interoperable products on the market

01:04:12,750 --> 01:04:17,330
today the Digium family of phones will

01:04:15,359 --> 01:04:19,410
initially include three IP des hommes

01:04:17,330 --> 01:04:21,330
uniquely designed to complement any

01:04:19,410 --> 01:04:23,220
asterisk or Switchvox based solution

01:04:21,330 --> 01:04:25,890
these phones are different for a number

01:04:23,220 --> 01:04:28,530
of reasons first there is clue sively

01:04:25,890 --> 01:04:29,970
designed for use with esters secondly

01:04:28,530 --> 01:04:31,580
we've made it really easy to

01:04:29,970 --> 01:04:33,960
autodiscover and provision the phones

01:04:31,580 --> 01:04:35,640
next we've made it easy for the phones

01:04:33,960 --> 01:04:37,480
to access information inside of

01:04:35,640 --> 01:04:39,600
asterisks allowing tight couple

01:04:37,480 --> 01:04:41,590
between an application and the phone

01:04:39,600 --> 01:04:43,720
additionally we've created an

01:04:41,590 --> 01:04:45,850
applications engine that allows users

01:04:43,720 --> 01:04:49,090
and developers to create and run their

01:04:45,850 --> 01:04:50,859
own apps on the phone and finally we've

01:04:49,090 --> 01:04:52,810
done all of this at a very compelling

01:04:50,859 --> 01:04:54,490
price point at Digium we're always

01:04:52,810 --> 01:04:56,590
thinking of ways to give our customers

01:04:54,490 --> 01:04:59,109
the best value in business phone systems

01:04:56,590 --> 01:05:00,700
and also give them the power to create

01:04:59,109 --> 01:05:02,859
their own solutions or any

01:05:00,700 --> 01:05:04,600
communications challenge will continue

01:05:02,859 --> 01:05:06,040
to push the boundaries not only to make

01:05:04,600 --> 01:05:08,080
Astra's cooler bastard more

01:05:06,040 --> 01:05:09,820
technologically feature-rich but to make

01:05:08,080 --> 01:05:12,340
asterisk and communications even easier

01:05:09,820 --> 01:05:15,869
and together we'll change the way the

01:05:12,340 --> 01:05:15,869
world communicates again

01:05:51,320 --> 01:05:53,380

YouTube URL: https://www.youtube.com/watch?v=7ACRqWoamNU


