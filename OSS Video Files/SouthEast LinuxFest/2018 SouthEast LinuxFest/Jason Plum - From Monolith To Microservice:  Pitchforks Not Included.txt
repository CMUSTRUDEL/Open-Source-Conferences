Title: Jason Plum - From Monolith To Microservice:  Pitchforks Not Included
Publication date: 2019-03-22
Playlist: 2018 SouthEast LinuxFest
Description: 
	2018 SouthEast LinuxFest
Jason Plum
From Monolith To Microservice

GitLab's cloud native project brought many challenges, and several pain points to light. Jason brings his experiences turning the Omnibus GitLab into cloud native Helm charts by way of containerization and orchestration, and finding lots of latent technical debt. This will cover the hows, whys, and how on earths. #HowHardCanItBe #docker #kubernetes #ThoughtWeFixedThat
Captions: 
	00:00:00,000 --> 00:00:09,680
tell you nobody's wrong the truth is I

00:00:04,250 --> 00:00:09,680
need you to understand what actually is

00:00:10,070 --> 00:00:18,930
the suite of tools there's a suite of

00:00:16,830 --> 00:00:21,439
clips that actually wraps suggest if you

00:00:18,930 --> 00:00:27,410
just get individual command line

00:00:21,439 --> 00:00:27,410
commands it's just good what we do is

00:00:27,680 --> 00:00:39,600
people simultaneously through many huge

00:00:30,960 --> 00:00:41,579
options you can get with all the people

00:00:39,600 --> 00:00:46,320
is hard and that's the thing that we're

00:00:41,579 --> 00:00:50,250
trying to address let me make you

00:00:46,320 --> 00:00:52,890
understand that as it started up my was

00:00:50,250 --> 00:00:57,000
on a bad thing right

00:00:52,890 --> 00:00:59,550
this is to clear those past to actually

00:00:57,000 --> 00:01:01,079
having a viable product nobody can use

00:00:59,550 --> 00:01:03,120
your awesome technology if you never

00:01:01,079 --> 00:01:10,770
make it off the ground because you spend

00:01:03,120 --> 00:01:15,689
too much time doing too many things one

00:01:10,770 --> 00:01:23,909
code base just worst and most your small

00:01:15,689 --> 00:01:25,830
test cases did you placed great it's

00:01:23,909 --> 00:01:33,659
easy you've got one maybe two maybe ten

00:01:25,830 --> 00:01:36,750
guys whole product no you're not

00:01:33,659 --> 00:01:39,500
planning to be Google you're planning to

00:01:36,750 --> 00:01:39,500
ramp that way

00:01:41,680 --> 00:01:47,560
to be straightforward everything you

00:01:45,520 --> 00:01:49,750
need in one thing it's gonna make it

00:01:47,560 --> 00:01:51,610
easy for people to install and use and

00:01:49,750 --> 00:01:53,710
then you're going to be able to give

00:01:51,610 --> 00:02:00,880
that to other people to actually go and

00:01:53,710 --> 00:02:03,700
use and test and control things very

00:02:00,880 --> 00:02:06,150
very easily that is it is now you should

00:02:03,700 --> 00:02:09,910
be in protect and this piece of concrete

00:02:06,150 --> 00:02:18,040
does not change very often and the new

00:02:09,910 --> 00:02:21,430
version version every time exactly

00:02:18,040 --> 00:02:22,660
Winterfest every time every time you

00:02:21,430 --> 00:02:23,950
need to change it somebody's gotta go

00:02:22,660 --> 00:02:27,310
ahead and pull it all out put it all

00:02:23,950 --> 00:02:30,520
back in but they know the trip itself

00:02:27,310 --> 00:02:32,200
didn't be a checklist and not what

00:02:30,520 --> 00:02:35,370
didn't I do this time because I remember

00:02:32,200 --> 00:02:35,370
what I did last time

00:02:38,850 --> 00:02:46,290
the more you build bigger it gets and

00:02:42,190 --> 00:02:50,350
the bigger it gets bigger it gets

00:02:46,290 --> 00:02:51,760
ended up being massive things stand up

00:02:50,350 --> 00:02:55,870
for the landscape but they're very hard

00:02:51,760 --> 00:02:58,440
to maintain when you start to scale they

00:02:55,870 --> 00:03:01,090
become unwieldy as you need to have

00:02:58,440 --> 00:03:05,019
better than one of them to keep up with

00:03:01,090 --> 00:03:07,780
the number of users that you have on the

00:03:05,019 --> 00:03:11,550
bust it's great because we use it our

00:03:07,780 --> 00:03:11,550
customers use it's the exact same thing

00:03:15,989 --> 00:03:30,970
hundred thousand million or two hundred

00:03:23,530 --> 00:03:34,780
and sixty thousand a day needs to say

00:03:30,970 --> 00:03:36,310
Edward cheater somebody would have

00:03:34,780 --> 00:03:39,480
driven a truck up to the base and we

00:03:36,310 --> 00:03:41,050
would have watched it go bike best

00:03:39,480 --> 00:03:45,000
because

00:03:41,050 --> 00:03:55,900
the truth is once you get one bottle s

00:03:45,000 --> 00:03:58,690
how do you deal with it best now let's

00:03:55,900 --> 00:04:05,500
go back to the foundation and let me

00:03:58,690 --> 00:04:09,610
tell you what's going on so the trick is

00:04:05,500 --> 00:04:12,640
get feels easy it was designed and now

00:04:09,610 --> 00:04:17,799
it's maintained it does what it does

00:04:12,640 --> 00:04:18,520
through the repository with a hundred

00:04:17,799 --> 00:04:21,940
files

00:04:18,520 --> 00:04:22,990
it's stupidly fast your command you

00:04:21,940 --> 00:04:35,800
didn't even know something happened

00:04:22,990 --> 00:04:39,210
because it ran so fast it's a snapshot

00:04:35,800 --> 00:04:45,790
of the versions of files that you have

00:04:39,210 --> 00:04:48,610
it actually keeps a copy actually in

00:04:45,790 --> 00:04:51,550
your repository that includes if you

00:04:48,610 --> 00:04:54,810
added it deleted leave it at five times

00:04:51,550 --> 00:04:59,890
its copies they don't show up anymore

00:04:54,810 --> 00:05:04,270
these are the indexed and pointed and

00:04:59,890 --> 00:05:06,070
packed and you now have how many copies

00:05:04,270 --> 00:05:11,500
of how many things if you've been doing

00:05:06,070 --> 00:05:18,010
this for a week ten years you have a

00:05:11,500 --> 00:05:20,110
total of 25 the negative total is the

00:05:18,010 --> 00:05:22,360
more there are the more people that are

00:05:20,110 --> 00:05:29,640
involved the more branches that are the

00:05:22,360 --> 00:05:29,640
more there are the bigger that's lower

00:05:34,260 --> 00:05:42,040
watch how fast it comes down here's a

00:05:37,210 --> 00:05:45,700
hand grab a copy to check out any branch

00:05:42,040 --> 00:05:48,070
I hope you did it alone and not split

00:05:45,700 --> 00:05:50,159
one because then you're gonna wait for

00:05:48,070 --> 00:05:52,319
the clone when you try and pick out

00:05:50,159 --> 00:05:59,539
check maybe but it doesn't matter which

00:05:52,319 --> 00:05:59,539
one do it if its master and time it

00:06:00,860 --> 00:06:09,749
there are millions of lines of code and

00:06:06,679 --> 00:06:11,669
hundreds of millions of outages and

00:06:09,749 --> 00:06:14,360
branches everything else

00:06:11,669 --> 00:06:16,949
hopefully the tree you had doesn't have

00:06:14,360 --> 00:06:20,339
everybody's downstream trees it's just

00:06:16,949 --> 00:06:23,429
little subsection maintainer so we could

00:06:20,339 --> 00:06:30,509
be drinking with like this you or the

00:06:23,429 --> 00:06:32,219
500 gigabyte disk repository how many

00:06:30,509 --> 00:06:36,330
files did I just watch

00:06:32,219 --> 00:06:38,309
just doing it death everybody can

00:06:36,330 --> 00:06:43,050
actually ask to me how many files I just

00:06:38,309 --> 00:06:49,050
touch doing this here's a hit one copy

00:06:43,050 --> 00:06:51,779
to copy depending on the number of files

00:06:49,050 --> 00:06:53,999
that were actually changed and it's just

00:06:51,779 --> 00:06:57,629
somewhat optimized thanks to indexes in

00:06:53,999 --> 00:07:02,479
fact you could hit anywhere between zero

00:06:57,629 --> 00:07:05,069
files and every file in the repository

00:07:02,479 --> 00:07:07,079
so if you're making a massive sweeping

00:07:05,069 --> 00:07:25,889
change where you did was change the

00:07:07,079 --> 00:07:30,629
license you have right that's already

00:07:25,889 --> 00:07:31,860
beginning to seem a little painful now

00:07:30,629 --> 00:07:35,839
that's actually gonna be while these

00:07:31,860 --> 00:07:35,839
changes let's push those to our motor

00:07:38,569 --> 00:07:44,689
animal friends simultaneously

00:08:02,680 --> 00:08:12,520
we're not lucky enough to be streaming

00:08:05,060 --> 00:08:15,620
files where we were good mates a stream

00:08:12,520 --> 00:08:21,730
no we're going over there Gillian tiny

00:08:15,620 --> 00:08:21,730
files and that's expensive at the desk

00:08:27,370 --> 00:08:33,920
what can we do to stop okay need to

00:08:31,550 --> 00:08:35,750
address this standard practice says when

00:08:33,920 --> 00:08:39,440
you have a small system what you do to

00:08:35,750 --> 00:08:50,300
get more disk performance you're ready

00:08:39,440 --> 00:09:07,940
you stripe that's not enough we have

00:08:50,300 --> 00:09:13,000
onion what was that have don't invent

00:09:07,940 --> 00:09:13,000
the boot three 2/100

00:09:14,020 --> 00:09:20,240
just from all the places we've solved

00:09:17,870 --> 00:09:49,940
the speeding problem we haven't solved

00:09:20,240 --> 00:09:52,070
the problem to certain point and then no

00:09:49,940 --> 00:09:57,980
matter what if we wanted you to the

00:09:52,070 --> 00:10:03,200
great analogy to citizen to subway

00:09:57,980 --> 00:10:05,960
you're not gonna fit it it's not kind of

00:10:03,200 --> 00:10:08,380
work even if the bus people eat it on

00:10:05,960 --> 00:10:08,380
the other side

00:10:09,740 --> 00:10:14,870
no matter how hard with warrants we

00:10:11,990 --> 00:10:19,370
can't make NFS magic video to billions

00:10:14,870 --> 00:10:21,380
of idols the introduced to the fest it

00:10:19,370 --> 00:10:24,050
solves one problem we can now scale

00:10:21,380 --> 00:10:28,370
horizontally and we can spend the best

00:10:24,050 --> 00:10:29,960
vertically now we've got two ice cubes

00:10:28,370 --> 00:10:33,170
in one big battle that just keeps kind

00:10:29,960 --> 00:10:35,000
of breaking the edge and if this was

00:10:33,170 --> 00:10:40,220
great because it does a lot and it's

00:10:35,000 --> 00:10:41,810
easy to scale it doesn't wonders and I

00:10:40,220 --> 00:10:52,510
say small which means down into the

00:10:41,810 --> 00:10:57,190
hundreds you okay but it's in the fest

00:10:52,510 --> 00:10:57,190
because now you have both in one place

00:11:01,330 --> 00:11:08,560
so much when you have 300 touching the

00:11:05,750 --> 00:11:08,560
same set of files

00:11:12,400 --> 00:11:23,600
the bottle is then high why I did

00:11:22,520 --> 00:11:26,030
because we're taking the entire

00:11:23,600 --> 00:11:28,970
foundation to the top shake all the time

00:11:26,030 --> 00:11:35,480
and then the wind's coming over as hard

00:11:28,970 --> 00:11:43,610
as it can that didn't happen to us why

00:11:35,480 --> 00:11:46,070
not a problem answer if I have a disc I

00:11:43,610 --> 00:11:47,450
no problem and I solved that by making

00:11:46,070 --> 00:11:50,690
sure the discourse fast as I could

00:11:47,450 --> 00:11:52,340
possibly get it and then I created

00:11:50,690 --> 00:12:02,330
myself a network problem because I was

00:11:52,340 --> 00:12:10,790
now trying to access the network seems

00:12:02,330 --> 00:12:13,000
that could be simple right the answer at

00:12:10,790 --> 00:12:15,980
the time but not for long

00:12:13,000 --> 00:12:19,370
instead we've created giddily

00:12:15,980 --> 00:12:21,040
and we've taken all of this network of

00:12:19,370 --> 00:12:23,930
reading the discs and

00:12:21,040 --> 00:12:27,980
everything else gigantic requests

00:12:23,930 --> 00:12:30,110
gigantic responses and don't get me

00:12:27,980 --> 00:12:32,480
started on how old pal system caching

00:12:30,110 --> 00:12:36,280
does not work on FSN where it works add

00:12:32,480 --> 00:12:42,730
whatever the hit rate here's a hint

00:12:36,280 --> 00:12:46,040
large tiles dozens of tiny bottles know

00:12:42,730 --> 00:12:49,880
what we did was we created a service

00:12:46,040 --> 00:12:52,340
that works as a DD RPC endpoint instead

00:12:49,880 --> 00:12:54,830
of going to the local desk working with

00:12:52,340 --> 00:12:56,090
a star would be working with rather than

00:12:54,830 --> 00:12:58,220
actually trying to be able to local

00:12:56,090 --> 00:13:00,710
files and then hitting an effect and

00:12:58,220 --> 00:13:02,060
then having the network doing all of

00:13:00,710 --> 00:13:04,610
this ridiculousness

00:13:02,060 --> 00:13:10,280
back and forth creating world eventually

00:13:04,610 --> 00:13:15,280
one scale is the pipe that big we

00:13:10,280 --> 00:13:24,530
actually proxy the call through get in

00:13:15,280 --> 00:13:26,510
and replace this disk system is here why

00:13:24,530 --> 00:13:29,600
is it important to actually have the

00:13:26,510 --> 00:13:37,450
machine that has the disk the animal

00:13:29,600 --> 00:13:37,450
breeding the files for you hit cache

00:13:39,250 --> 00:13:45,740
will do a good job of reading files 50

00:13:43,190 --> 00:13:49,870
times a second especially if it's the

00:13:45,740 --> 00:13:53,120
same file do that over the network and

00:13:49,870 --> 00:13:57,650
make 300 people trying to read different

00:13:53,120 --> 00:14:01,910
files I don't have to keep track of all

00:13:57,650 --> 00:14:04,820
three hundred billion files versus this

00:14:01,910 --> 00:14:07,790
is your section of the data I want to

00:14:04,820 --> 00:14:10,820
talk to you about it 300 people only

00:14:07,790 --> 00:14:16,580
asking about this piece instead of all

00:14:10,820 --> 00:14:17,750
the pieces we stopped the problem by

00:14:16,580 --> 00:14:22,430
optimizing

00:14:17,750 --> 00:14:26,740
whether the problem is addressed small

00:14:22,430 --> 00:14:29,540
network requests small network response

00:14:26,740 --> 00:14:31,070
we ask for a death we get a little dip

00:14:29,540 --> 00:14:33,340
that we don't have to worried about

00:14:31,070 --> 00:14:35,980
actually doing the differ agent that's

00:14:33,340 --> 00:14:43,740
with SSDs in a crap-ton file cache it's

00:14:35,980 --> 00:14:48,730
doing a much better job and will this

00:14:43,740 --> 00:14:51,700
reduces but which means we can actually

00:14:48,730 --> 00:14:56,110
scale as well inside of the pipes that

00:14:51,700 --> 00:14:58,090
we have now we don't have to have api's

00:14:56,110 --> 00:15:00,850
and service nodes that actually have to

00:14:58,090 --> 00:15:08,140
have the disk which is our most

00:15:00,850 --> 00:15:11,560
expensive operation addressing the

00:15:08,140 --> 00:15:23,070
specific problem we can solve most of

00:15:11,560 --> 00:15:26,410
our scaling issues off the back question

00:15:23,070 --> 00:15:31,900
is did we scale the network by going gig

00:15:26,410 --> 00:15:33,150
10:40 routed Network we have no data

00:15:31,900 --> 00:15:35,410
center

00:15:33,150 --> 00:15:41,770
what a crazy people are using other

00:15:35,410 --> 00:15:50,980
people's computers in the question how

00:15:41,770 --> 00:15:53,010
do we what actual architects on the

00:15:50,980 --> 00:15:56,200
Ghibli project

00:15:53,010 --> 00:15:58,780
suffice to say actually we do get

00:15:56,200 --> 00:16:06,970
processes for certain operations because

00:15:58,780 --> 00:16:19,480
they're speaking everyone can interface

00:16:06,970 --> 00:16:21,490
with it you can do it if you want mother

00:16:19,480 --> 00:16:28,380
that's not falling over has a big fat

00:16:21,490 --> 00:16:28,380
under it we can focus on other problems

00:16:30,920 --> 00:16:41,089
forward right now I can have hundreds of

00:16:35,759 --> 00:16:41,089
API knows hundreds of web servers and

00:16:41,300 --> 00:16:46,110
when the end of that server died because

00:16:43,920 --> 00:16:51,930
it's got three hundred nodes trying to

00:16:46,110 --> 00:16:53,430
read three million files but now I have

00:16:51,930 --> 00:16:55,620
some other things that I need to look at

00:16:53,430 --> 00:17:05,819
it my biggest fattest should point ever

00:16:55,620 --> 00:17:07,799
have been somewhat addressed is have we

00:17:05,819 --> 00:17:12,630
looked at GV divest and replacement of

00:17:07,799 --> 00:17:15,720
NFS here's the trick if I'm access to

00:17:12,630 --> 00:17:19,309
the final of the network I'm still

00:17:15,720 --> 00:17:23,400
access to the file the whole file

00:17:19,309 --> 00:17:27,990
doesn't matter whether or not it's staff

00:17:23,400 --> 00:17:31,799
or NFS order samba it's the whole file

00:17:27,990 --> 00:17:36,030
every time relocating whether the disk

00:17:31,799 --> 00:17:38,760
access is actually done we take off the

00:17:36,030 --> 00:17:40,950
API can respond to more things regular

00:17:38,760 --> 00:17:43,049
basis we put it on to the network

00:17:40,950 --> 00:17:45,150
service we reduce that worker put and

00:17:43,049 --> 00:17:48,929
get a little optimization of the local

00:17:45,150 --> 00:17:53,880
file system cache no network file system

00:17:48,929 --> 00:17:56,370
will magically fix that ggbfs it comes

00:17:53,880 --> 00:18:00,299
along it will not magically fix that

00:17:56,370 --> 00:18:03,000
cost so any user who has to deal with

00:18:00,299 --> 00:18:07,260
gigabytes gigabytes of an individual

00:18:03,000 --> 00:18:09,030
repository that's a different story we

00:18:07,260 --> 00:18:12,750
need to operate on the entire repository

00:18:09,030 --> 00:18:16,500
at all times not on a subsection which

00:18:12,750 --> 00:18:21,890
GPFS handles does it answer that

00:18:16,500 --> 00:18:21,890
question all right so

00:18:50,460 --> 00:19:15,580
Computers somebody's gotta be just as

00:18:53,710 --> 00:19:17,140
useful screenshots not even including

00:19:15,580 --> 00:19:21,220
the gate stuff that's hundreds and

00:19:17,140 --> 00:19:23,110
terrorized if I need to make it so I can

00:19:21,220 --> 00:19:25,210
to get on one note without having to

00:19:23,110 --> 00:19:34,830
worry about if I'm going to kill my file

00:19:25,210 --> 00:19:37,420
servers what it comes down again way

00:19:34,830 --> 00:19:39,040
instead of having to deal with file

00:19:37,420 --> 00:19:41,290
server making a compliance deal with the

00:19:39,040 --> 00:19:43,450
file server ready who's ever done an N

00:19:41,290 --> 00:19:47,280
if it's to root for five hundred people

00:19:43,450 --> 00:19:49,630
at the same time one two three exactly

00:19:47,280 --> 00:19:51,820
if you have choice between two NFS

00:19:49,630 --> 00:19:53,890
server for ten people and five hundred

00:19:51,820 --> 00:20:00,730
people which one would you do for the

00:19:53,890 --> 00:20:02,080
rest of your life now imagine we wanted

00:20:00,730 --> 00:20:03,520
customers yes so you would have ten

00:20:02,080 --> 00:20:06,820
thousand people you're gonna need ten

00:20:03,520 --> 00:20:11,080
nodes I hope somebody knows how to do

00:20:06,820 --> 00:20:12,970
NFS really well right this is cool we

00:20:11,080 --> 00:20:23,200
can train them how to do this but

00:20:12,970 --> 00:20:25,090
there's a problem to make it simpler for

00:20:23,200 --> 00:20:27,490
us to actually run it's Catalan for the

00:20:25,090 --> 00:20:30,370
customer to be able to choose which way

00:20:27,490 --> 00:20:34,150
they do things we implement objects or

00:20:30,370 --> 00:20:36,260
legacy NFS behind

00:20:34,150 --> 00:20:38,660
this way you don't have to have the

00:20:36,260 --> 00:20:45,080
knowledge but we're able to be cloud

00:20:38,660 --> 00:20:49,250
native if you can to once we have the

00:20:45,080 --> 00:20:52,870
actual state separated we can now go to

00:20:49,250 --> 00:20:55,370
the concept of what our paths and cattle

00:20:52,870 --> 00:21:00,800
perspective what's the difference

00:20:55,370 --> 00:21:03,680
between the dog and the cat what makes

00:21:00,800 --> 00:21:05,750
me buddy I really don't care about his

00:21:03,680 --> 00:21:11,270
state because somebody's eventually

00:21:05,750 --> 00:21:12,010
gonna eat him right but his dog is a

00:21:11,270 --> 00:21:15,650
workhorse

00:21:12,010 --> 00:21:21,020
it's friend it's important it has to be

00:21:15,650 --> 00:21:24,800
hitter - it has to be healthy if you get

00:21:21,020 --> 00:21:30,020
one counter that it's mad you put it

00:21:24,800 --> 00:21:32,330
down your dog it stick you treat it you

00:21:30,020 --> 00:21:36,770
take it to do that you manage it you

00:21:32,330 --> 00:21:40,100
make sure it's got a happy life state

00:21:36,770 --> 00:21:41,720
with systems on the cattle the API

00:21:40,100 --> 00:21:45,620
servers that number one of the mean file

00:21:41,720 --> 00:21:47,390
service accessed the endpoints that are

00:21:45,620 --> 00:21:49,340
serving web content that don't actually

00:21:47,390 --> 00:21:51,680
have to have file sort of content

00:21:49,340 --> 00:21:54,920
anymore because they could get it from

00:21:51,680 --> 00:21:57,290
elsewhere are now cattle would have

00:21:54,920 --> 00:22:02,420
stuck with past for the state for

00:21:57,290 --> 00:22:08,150
information the our database and I'll

00:22:02,420 --> 00:22:10,910
cash register itself everything about

00:22:08,150 --> 00:22:14,660
the application now no longer caters

00:22:10,910 --> 00:22:18,590
there it is that it doesn't require it

00:22:14,660 --> 00:22:21,260
to be stealth now we can actually look

00:22:18,590 --> 00:22:23,870
at the possibility of stealing without a

00:22:21,260 --> 00:22:25,730
fight because now we don't have to have

00:22:23,870 --> 00:22:28,490
some poor fella spend 12 hours or

00:22:25,730 --> 00:22:30,440
scaling three times just to make sure we

00:22:28,490 --> 00:22:32,840
keep up with the load and so everyone's

00:22:30,440 --> 00:22:34,790
information no we never what else our

00:22:32,840 --> 00:22:37,490
modeling server did because y'all have

00:22:34,790 --> 00:22:41,100
me it's so heavy that we had to put it

00:22:37,490 --> 00:22:43,929
with 256 gigs of RAM

00:22:41,100 --> 00:22:46,390
we've never been out we get a little

00:22:43,929 --> 00:22:50,409
choked with that little pod but we never

00:22:46,390 --> 00:22:54,570
went out supporting explain to handle

00:22:50,409 --> 00:22:58,450
the pets behavior what it used to be

00:22:54,570 --> 00:23:00,460
that every single off the boss every

00:22:58,450 --> 00:23:04,210
single load and then we turn features

00:23:00,460 --> 00:23:06,789
off so we have a service type in be

00:23:04,210 --> 00:23:08,110
declared and you'd have that feature and

00:23:06,789 --> 00:23:19,020
this feature in that feature in this

00:23:08,110 --> 00:23:24,250
feature in that feature which as a to

00:23:19,020 --> 00:23:27,669
every node oh this is a definitive

00:23:24,250 --> 00:23:29,409
downside because now it's really simple

00:23:27,669 --> 00:23:31,330
because one cookie cutter and we can

00:23:29,409 --> 00:23:36,400
configure them the way we need and it

00:23:31,330 --> 00:23:41,140
works really well imagine how long it

00:23:36,400 --> 00:23:45,640
takes to start a load this process takes

00:23:41,140 --> 00:23:50,980
a minimum of two minutes and can take up

00:23:45,640 --> 00:24:03,490
to ten imaginary and sixteen new API

00:23:50,980 --> 00:24:05,289
servers because and then they have to

00:24:03,490 --> 00:24:06,490
start up and spit up and contact the

00:24:05,289 --> 00:24:09,820
remote services and make sure

00:24:06,490 --> 00:24:19,710
everything's happy so 10 to 15 minutes

00:24:09,820 --> 00:24:19,710
long scale can be started on clustering

00:24:23,190 --> 00:24:28,480
services just point but they don't

00:24:25,360 --> 00:24:39,669
actually physically fire the file system

00:24:28,480 --> 00:24:45,090
they don't have to be located content is

00:24:39,669 --> 00:24:47,530
a decision we have created containers

00:24:45,090 --> 00:24:50,330
that's an easy way for us to distribute

00:24:47,530 --> 00:24:54,560
the binaries in a controlled fashion

00:24:50,330 --> 00:24:57,620
that's why we've chosen I can take the

00:24:54,560 --> 00:25:00,590
minimum requirements and I can put them

00:24:57,620 --> 00:25:02,930
together and guarantee no matter where I

00:25:00,590 --> 00:25:12,170
go that's gonna work

00:25:02,930 --> 00:25:15,470
I could ship what I didn't have a PD API

00:25:12,170 --> 00:25:19,150
services running and I have 32 quarters

00:25:15,470 --> 00:25:19,150
already but I don't need a whole other

00:25:22,720 --> 00:25:37,630
servers let's go through the process of

00:25:33,380 --> 00:25:41,930
installing system doing system updates

00:25:37,630 --> 00:25:54,560
nobodies repos down etc etc it is

00:25:41,930 --> 00:25:57,290
optimized for zation to the outside will

00:25:54,560 --> 00:25:59,330
have some legacy dead we have one

00:25:57,290 --> 00:26:04,820
process that acts is a smart box the

00:25:59,330 --> 00:26:19,550
actual latest application because tiny

00:26:04,820 --> 00:26:21,410
files I'm talking about this process

00:26:19,550 --> 00:26:24,350
step speak sockets

00:26:21,410 --> 00:26:29,210
does it very well the problem is it

00:26:24,350 --> 00:26:33,290
doesn't speak TCP sockets and the

00:26:29,210 --> 00:26:35,360
likelihood that we're going to look it's

00:26:33,290 --> 00:26:37,190
a tiny process used to delve out

00:26:35,360 --> 00:26:39,020
application and whether it's API or

00:26:37,190 --> 00:26:44,480
service it doesn't stay without too much

00:26:39,020 --> 00:26:49,060
memory performance the thing that it

00:26:44,480 --> 00:26:51,020
likes to share the temp directory those

00:26:49,060 --> 00:26:54,920
harder than you think

00:26:51,020 --> 00:26:58,370
and when you don't have the manpower to

00:26:54,920 --> 00:27:02,140
do that so don't you just go ahead and

00:26:58,370 --> 00:27:02,140
co-locate the small thing that the baby

00:27:05,680 --> 00:27:12,920
I've been trained if you have a project

00:27:10,270 --> 00:27:16,550
you need it to be more diluted that I

00:27:12,920 --> 00:27:20,630
used to be even if you have 270 parts

00:27:16,550 --> 00:27:22,370
employees require 40 countries if you

00:27:20,630 --> 00:27:26,090
have to ship the product on the 22nd of

00:27:22,370 --> 00:27:28,820
every single what and it's gotta be good

00:27:26,090 --> 00:27:31,670
and it's gotta be better and it's

00:27:28,820 --> 00:27:35,060
actually got improved for us and our

00:27:31,670 --> 00:27:41,510
customers do we have time to do

00:27:35,060 --> 00:27:43,280
everything ideal we've done our absolute

00:27:41,510 --> 00:27:47,900
best and we continue to iterate over

00:27:43,280 --> 00:27:49,610
time we take that's look we can we take

00:27:47,900 --> 00:27:51,290
an approach that will get us there in

00:27:49,610 --> 00:27:55,870
the end but it's not necessarily the

00:27:51,290 --> 00:27:57,140
direct route to perfection this is why

00:27:55,870 --> 00:28:00,680
medallist

00:27:57,140 --> 00:28:03,560
are a good thing in the beginning but at

00:28:00,680 --> 00:28:12,020
a certain point you would have to begin

00:28:03,560 --> 00:28:14,450
the migration the micro services like

00:28:12,020 --> 00:28:15,950
can you actually tell me how much CPU

00:28:14,450 --> 00:28:25,360
and memory that process will actually

00:28:15,950 --> 00:28:27,860
need no no you know if your server needs

00:28:25,360 --> 00:28:30,320
when it's installed a service that has a

00:28:27,860 --> 00:28:51,560
one-game buddy package that unpacks to

00:28:30,320 --> 00:28:54,080
one and a half and the GPU performance

00:28:51,560 --> 00:28:59,870
on that process but if you tell it start

00:28:54,080 --> 00:29:03,050
scaling at a time no problem then how do

00:28:59,870 --> 00:29:09,050
you look balanced top web api disturbers

00:29:03,050 --> 00:29:10,910
to do this mostly but do you do end of

00:29:09,050 --> 00:29:12,590
the actual metrics I want to know how

00:29:10,910 --> 00:29:14,840
many API calls you get rich how many

00:29:12,590 --> 00:29:19,710
service call that you get

00:29:14,840 --> 00:29:21,630
you can tell my bitter which things do

00:29:19,710 --> 00:29:23,400
you actually love how happily do you

00:29:21,630 --> 00:29:31,740
load the Ottoman which actor you used to

00:29:23,400 --> 00:29:33,240
do it these questions come up do you add

00:29:31,740 --> 00:29:34,890
more services to wonder because

00:29:33,240 --> 00:29:37,500
magically you've got overhead because

00:29:34,890 --> 00:29:41,060
this thing's not doing anything which

00:29:37,500 --> 00:29:41,060
tells you you don't know what it's doing

00:29:47,060 --> 00:29:53,490
how much can you fit there are important

00:29:50,550 --> 00:29:54,720
things and can you do it automatically

00:29:53,490 --> 00:30:05,790
to do you have to think about doing it

00:29:54,720 --> 00:30:11,880
the basis you can't the biggest question

00:30:05,790 --> 00:30:15,510
is when things fall over the one we

00:30:11,880 --> 00:30:18,780
actually saw was we have a CI cluster in

00:30:15,510 --> 00:30:27,540
that question we actually have abs of

00:30:18,780 --> 00:30:30,570
last day we have 15 instances I'll get

00:30:27,540 --> 00:30:32,280
lab deployed in this cluster all of it

00:30:30,570 --> 00:30:37,470
the database the readers ghibli

00:30:32,280 --> 00:30:40,470
everything's inside it know that if you

00:30:37,470 --> 00:30:49,650
have the memory chiller trip it you can

00:30:40,470 --> 00:30:51,870
kill your entire network stack I'm not

00:30:49,650 --> 00:30:53,220
sure how we managed to do that but we

00:30:51,870 --> 00:30:55,710
went and we looked at the scheduler that

00:30:53,220 --> 00:31:00,990
turns out those processes that actually

00:30:55,710 --> 00:31:04,770
demand to getting the piece never set to

00:31:00,990 --> 00:31:14,139
ask for 500 products and it's scheduled

00:31:04,770 --> 00:31:20,480
40 of them is just a fact it was

00:31:14,139 --> 00:31:21,769
and we fixed it right away that's the

00:31:20,480 --> 00:31:24,919
process of where we're headed right now

00:31:21,769 --> 00:31:32,419
I'd like to ask what any questions in

00:31:24,919 --> 00:31:34,220
regards to talk now that point our

00:31:32,419 --> 00:31:36,799
actual target is to make what we're

00:31:34,220 --> 00:31:39,710
doing even easier than the bus install

00:31:36,799 --> 00:31:42,499
that's at all possible and any does that

00:31:39,710 --> 00:31:46,570
actually having smaller local copies you

00:31:42,499 --> 00:31:50,080
know it is a pride that is still easy

00:31:46,570 --> 00:31:54,230
for you every single upgrade that is

00:31:50,080 --> 00:31:57,440
what I do every day is make sure that's

00:31:54,230 --> 00:32:01,129
perfect for you guys I want this to be

00:31:57,440 --> 00:32:04,249
that easy but I need to be that easy at

00:32:01,129 --> 00:32:08,289
our scale and for our largest customer

00:32:04,249 --> 00:32:15,369
scale because as I just showed you you

00:32:08,289 --> 00:32:15,369
guys have artists it's hard

00:32:17,409 --> 00:32:23,480
we'll be getting beta this month alpha

00:32:21,259 --> 00:32:27,259
if you want to look at it you can please

00:32:23,480 --> 00:32:31,159
please play with it we're working on

00:32:27,259 --> 00:32:32,330
that information that were here and I

00:32:31,159 --> 00:32:40,059
will make sure that these slides are

00:32:32,330 --> 00:32:42,649
available to everyone else questions

00:32:40,059 --> 00:32:49,879
comments before we get into the whole

00:32:42,649 --> 00:32:51,889
new cycle thing I'll actually enter the

00:32:49,879 --> 00:32:52,159
ball bin doc I feel good about that for

00:32:51,889 --> 00:32:55,970
once

00:32:52,159 --> 00:32:58,639
nice all right well thanks for coming

00:32:55,970 --> 00:33:01,940
hopefully this was informative about why

00:32:58,639 --> 00:33:04,309
microservice to listen to the wrong way

00:33:01,940 --> 00:33:08,960
but let's to microservice makes a lot of

00:33:04,309 --> 00:33:11,269
sense if you actually wouldn't grow and

00:33:08,960 --> 00:33:13,249
not figure out how may times were tomten

00:33:11,269 --> 00:33:19,450
things the same time it way to God the

00:33:13,249 --> 00:33:19,450
Lego bricks work thanks

00:33:24,040 --> 00:33:30,070
and with that said who wants to go for

00:33:27,350 --> 00:33:30,070

YouTube URL: https://www.youtube.com/watch?v=dCW1-ms1A1I


