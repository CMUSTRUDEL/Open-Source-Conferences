Title: OSDC 2017 | Automating your data-center with Ansible and ManageIQ by Daniel Korn
Publication date: 2017-06-02
Playlist: OSDC 2017 | Open Source Data Center Conference
Description: 
	Managing your Data Center and Cloud/Infra resources can be a complex and challenging task. ManageIQ, the leading Open Source hybrid cloud management platform presents the operator a consistent view of the data from his cluster, helps planning future scaling, handle unexpected events and proactively identify problems and security issues. One of the most powerful features of ManageIQ is its ability to automate the orchestration of workloads and resource. In this session, I will present recent Implementation of dedicated ManageIQ Ansible modules. Using these modules simplifies bringing your Cloud and Containers into ManageIQ, and leverage its management and orchestration abilities. I will also cover using Ansible from within ManageIQ, utilizing its Automation Engine. After a short demo, youâ€™ll know how.
Captions: 
	00:00:09,750 --> 00:00:16,119
okay good morning everybody

00:00:12,639 --> 00:00:18,669
welcome again we will start now with

00:00:16,119 --> 00:00:21,489
Daniel corn he's from Red Hat and he

00:00:18,669 --> 00:00:27,899
will show us how to automate a data

00:00:21,489 --> 00:00:27,899
center with ansible and manage IQ right

00:00:29,070 --> 00:00:33,280
[Applause]

00:00:30,719 --> 00:00:37,930
thank you can you hear me

00:00:33,280 --> 00:00:41,350
yeah it's worked great so as Sebastian

00:00:37,930 --> 00:00:43,660
said the topic of today's talk is

00:00:41,350 --> 00:00:49,890
automating your data center with

00:00:43,660 --> 00:00:52,899
Antebellum njq just a little about me I

00:00:49,890 --> 00:00:56,079
work at reddit I am software engineer

00:00:52,899 --> 00:00:58,630
for almost four years and I'm a part of

00:00:56,079 --> 00:01:02,340
the container management R&D team

00:00:58,630 --> 00:01:04,689
I enjoy contributing to open source

00:01:02,340 --> 00:01:07,420
following Maccabi Tel Aviv Football Club

00:01:04,689 --> 00:01:12,130
and snowboarding not necessarily in this

00:01:07,420 --> 00:01:14,259
order and just before we begin I want to

00:01:12,130 --> 00:01:15,789
say I'm very excited to be here and if

00:01:14,259 --> 00:01:18,189
you have any questions there will be a

00:01:15,789 --> 00:01:19,719
Q&A session at the end but feel free to

00:01:18,189 --> 00:01:22,030
interrupt me and ask questions during

00:01:19,719 --> 00:01:24,759
the talk if I'll feel that I don't have

00:01:22,030 --> 00:01:30,279
enough time I'll ask you to ask it again

00:01:24,759 --> 00:01:32,590
at the end so the agenda for today we're

00:01:30,279 --> 00:01:34,869
going to start with the motivation for

00:01:32,590 --> 00:01:37,420
this effort them about to show the

00:01:34,869 --> 00:01:40,450
problem that we wanted to solve then

00:01:37,420 --> 00:01:42,369
we'll move on to present manage a queue

00:01:40,450 --> 00:01:45,429
announce table those are two key

00:01:42,369 --> 00:01:48,459
features or two key players in this

00:01:45,429 --> 00:01:50,979
solution the core of the talk will be a

00:01:48,459 --> 00:01:55,029
recent implementation of dedicated end

00:01:50,979 --> 00:01:57,369
table and two dedicated implementation

00:01:55,029 --> 00:02:01,299
of manage a queue and ocular ansible

00:01:57,369 --> 00:02:06,069
modules plus demos for both will then

00:02:01,299 --> 00:02:08,080
move to a short explanation about the

00:02:06,069 --> 00:02:10,720
current state of ansible integration in

00:02:08,080 --> 00:02:16,360
manage a queue and wrap it up with the

00:02:10,720 --> 00:02:19,540
future plans so motivation the container

00:02:16,360 --> 00:02:22,900
management team that I am a member of is

00:02:19,540 --> 00:02:25,420
its mission is to develop

00:02:22,900 --> 00:02:28,480
management solutions for container-based

00:02:25,420 --> 00:02:32,459
clustered environment mostly based on

00:02:28,480 --> 00:02:32,459
kubernetes and openshift

00:02:32,730 --> 00:02:39,700
in a show of hands how many of you heard

00:02:35,409 --> 00:02:42,970
about open shift oh nice okay so I don't

00:02:39,700 --> 00:02:44,799
really need to talk about it I'll just

00:02:42,970 --> 00:02:47,700
say that open shift is a container

00:02:44,799 --> 00:02:52,170
application platform a path based on

00:02:47,700 --> 00:02:55,109
google kubernetes it is open sourced and

00:02:52,170 --> 00:02:57,340
it is very useful to accelerate your

00:02:55,109 --> 00:03:00,129
development your application development

00:02:57,340 --> 00:03:03,010
and your Intimidator development

00:03:00,129 --> 00:03:06,159
lifecycle supply with DevOps tools and

00:03:03,010 --> 00:03:09,750
so on there is an inner team at Red Hat

00:03:06,159 --> 00:03:13,209
which is called the open shift ops team

00:03:09,750 --> 00:03:15,879
it is responsible for managing large

00:03:13,209 --> 00:03:19,299
number of open shift clusters for paying

00:03:15,879 --> 00:03:21,280
customers usually these customers they

00:03:19,299 --> 00:03:24,579
want to enjoy the benefit of running

00:03:21,280 --> 00:03:26,560
container based or open shift clusters

00:03:24,579 --> 00:03:29,799
without the need or the hole the

00:03:26,560 --> 00:03:33,750
overhead to manage these clusters so

00:03:29,799 --> 00:03:37,359
they're doing it for their customers

00:03:33,750 --> 00:03:39,069
we've been talking with the OpenShift

00:03:37,359 --> 00:03:41,530
ops for a few months now and they're

00:03:39,069 --> 00:03:44,500
really awesome we wanted to check out

00:03:41,530 --> 00:03:46,480
what are their needs to see if we can

00:03:44,500 --> 00:03:50,919
help and supply management solution for

00:03:46,480 --> 00:03:52,449
them so as I said what are the needs of

00:03:50,919 --> 00:03:54,669
the open shift ops team they need to

00:03:52,449 --> 00:03:57,370
deploy and configure open shift clusters

00:03:54,669 --> 00:04:01,540
over and over again and these can be

00:03:57,370 --> 00:04:03,040
sometimes sometimes very complex they

00:04:01,540 --> 00:04:05,319
need a fine-grained solution for

00:04:03,040 --> 00:04:07,269
monitoring meaning they need to store

00:04:05,319 --> 00:04:09,879
metrics then they need to define

00:04:07,269 --> 00:04:13,959
triggers on these metrics and receive

00:04:09,879 --> 00:04:15,489
alerts they also need to use these

00:04:13,959 --> 00:04:18,459
metrics for measuring to better

00:04:15,489 --> 00:04:19,989
understand optimization to better

00:04:18,459 --> 00:04:23,380
understand the workloads and the

00:04:19,989 --> 00:04:26,080
utilization of the clusters for these as

00:04:23,380 --> 00:04:29,740
to they're using popular popular is an

00:04:26,080 --> 00:04:30,130
open source time series database by Red

00:04:29,740 --> 00:04:34,419
Hat

00:04:30,130 --> 00:04:36,639
it is Kassandra based and this time

00:04:34,419 --> 00:04:38,860
series data be database is

00:04:36,639 --> 00:04:41,590
running inside the cluster and stores

00:04:38,860 --> 00:04:44,229
all the metrics for the open chips

00:04:41,590 --> 00:04:46,509
cluster if you want to store metrics

00:04:44,229 --> 00:04:48,699
probably a time series DB is the

00:04:46,509 --> 00:04:53,409
solution for you where every row is

00:04:48,699 --> 00:04:56,740
basically a timestamp and the value they

00:04:53,409 --> 00:04:59,650
need aggregated logging for all the

00:04:56,740 --> 00:05:01,949
hosts both for the infrastructure and

00:04:59,650 --> 00:05:05,050
the applications that they're running

00:05:01,949 --> 00:05:09,159
the elastic search is also running

00:05:05,050 --> 00:05:11,949
inside the cluster they need to have a

00:05:09,159 --> 00:05:14,080
solution for charging their customers it

00:05:11,949 --> 00:05:15,969
is based on the measuring on the metrics

00:05:14,080 --> 00:05:19,330
we've mentioned before they're just

00:05:15,969 --> 00:05:22,240
attaching a price tag over these metrics

00:05:19,330 --> 00:05:26,560
it can be CPU or memory usage but it can

00:05:22,240 --> 00:05:30,669
also be container images and many more

00:05:26,560 --> 00:05:34,719
on needs so obviously we found out that

00:05:30,669 --> 00:05:36,999
automation is the key flow of these and

00:05:34,719 --> 00:05:42,599
we wanted to help them solve this need

00:05:36,999 --> 00:05:47,589
so let's just take a step back and it is

00:05:42,599 --> 00:05:50,560
to in today's big companies they're

00:05:47,589 --> 00:05:53,139
using a various range of IT platforms

00:05:50,560 --> 00:05:55,029
for their various needs and it's

00:05:53,139 --> 00:05:57,550
becoming more clear that they need one

00:05:55,029 --> 00:06:02,979
place to look and manage all these IT

00:05:57,550 --> 00:06:04,539
environments so we basically need one

00:06:02,979 --> 00:06:06,879
open source platform to rule them all

00:06:04,539 --> 00:06:08,439
this is where manage a queue enters

00:06:06,879 --> 00:06:10,300
mange queue is the open source

00:06:08,439 --> 00:06:13,169
management management platform for

00:06:10,300 --> 00:06:16,719
hybrid IT it is the open source project

00:06:13,169 --> 00:06:20,979
that powers red head cloud firms this is

00:06:16,719 --> 00:06:23,830
the downstream version and again as we

00:06:20,979 --> 00:06:26,199
said its main purpose is to allow you

00:06:23,830 --> 00:06:29,740
looking at your at all of your IT

00:06:26,199 --> 00:06:32,159
platforms from a single pane of glass it

00:06:29,740 --> 00:06:34,779
also supply you with a rich inventory a

00:06:32,159 --> 00:06:39,189
continuous discovery for all of its

00:06:34,779 --> 00:06:41,879
entities and objects also map the

00:06:39,189 --> 00:06:44,289
relationships between those entities and

00:06:41,879 --> 00:06:47,319
another cool feature is the cross

00:06:44,289 --> 00:06:50,409
linking or cross reference for example

00:06:47,319 --> 00:06:53,409
if you are running kubernetes on

00:06:50,409 --> 00:06:56,469
of OpenStack VMs you can go from your

00:06:53,409 --> 00:07:00,069
container from your kubernetes container

00:06:56,469 --> 00:07:03,699
through the kubernetes node and then

00:07:00,069 --> 00:07:08,889
reach out to the underlying VM and even

00:07:03,699 --> 00:07:10,779
to the bare metal host they manage a

00:07:08,889 --> 00:07:12,429
queue collect metrics for performance

00:07:10,779 --> 00:07:16,719
and utilization to help you with

00:07:12,429 --> 00:07:20,830
optimization to find unused systems to

00:07:16,719 --> 00:07:22,749
do capacity planning and much more it

00:07:20,830 --> 00:07:25,300
has a cool feature of reports that you

00:07:22,749 --> 00:07:27,249
can write and then run as many times as

00:07:25,300 --> 00:07:29,649
you want and the chargeback that we

00:07:27,249 --> 00:07:33,969
talked about before is based on these

00:07:29,649 --> 00:07:37,179
reports smart set analysis is the

00:07:33,969 --> 00:07:40,029
ability to inspect objects in real time

00:07:37,179 --> 00:07:41,769
for example if we have a container image

00:07:40,029 --> 00:07:44,379
and we want to know what's inside of it

00:07:41,769 --> 00:07:46,689
we can run a scan that is called smart

00:07:44,379 --> 00:07:49,869
analysis and we can find out which

00:07:46,689 --> 00:07:53,709
packages are exactly in this container

00:07:49,869 --> 00:07:57,099
image and also for example we can test

00:07:53,709 --> 00:08:02,949
it against latest CBS using open s cap

00:07:57,099 --> 00:08:05,429
or open cap and get a get a mark for

00:08:02,949 --> 00:08:09,429
these CVS

00:08:05,429 --> 00:08:12,159
compliance is the ability to define in a

00:08:09,429 --> 00:08:16,419
free language at least of conditions

00:08:12,159 --> 00:08:19,539
that we want to enforce and if these

00:08:16,419 --> 00:08:22,059
conditions these policies can also

00:08:19,539 --> 00:08:26,289
trigger actions in case they are

00:08:22,059 --> 00:08:27,879
evaluated to true or false so if we are

00:08:26,289 --> 00:08:29,729
following the last example I gave you

00:08:27,879 --> 00:08:32,139
for smart state analysis we can

00:08:29,729 --> 00:08:35,649
determine that for every new container

00:08:32,139 --> 00:08:38,439
image in our cluster every time it gets

00:08:35,649 --> 00:08:40,659
discovered as smart state analysis

00:08:38,439 --> 00:08:43,809
begins it checks all the packages and

00:08:40,659 --> 00:08:47,319
the latest CBS and if this container

00:08:43,809 --> 00:08:51,370
image is marked as non secure for many

00:08:47,319 --> 00:08:53,529
reasons then manage a queue or will tell

00:08:51,370 --> 00:08:55,660
openshift not to use this container

00:08:53,529 --> 00:08:58,180
image anymore you know cluster so it's

00:08:55,660 --> 00:09:01,300
pretty powerful and also the smart

00:08:58,180 --> 00:09:04,080
analysis works for VMs and hosts and

00:09:01,300 --> 00:09:06,180
some other entities

00:09:04,080 --> 00:09:08,610
Service Catalog is a bundle list of

00:09:06,180 --> 00:09:11,730
resources that the end user can just

00:09:08,610 --> 00:09:17,040
order in a self-service cannot catalog

00:09:11,730 --> 00:09:20,220
based it is he can order them instead of

00:09:17,040 --> 00:09:23,040
for example opening a ticket for the IT

00:09:20,220 --> 00:09:25,140
if you want to spin a new VM instead of

00:09:23,040 --> 00:09:28,110
opening a ticket and waiting for the IT

00:09:25,140 --> 00:09:30,990
to enter he can do it for himself in the

00:09:28,110 --> 00:09:33,600
Service Catalog tenancy is a key

00:09:30,990 --> 00:09:35,850
principle in in both private and public

00:09:33,600 --> 00:09:39,900
cloud basically separation or

00:09:35,850 --> 00:09:42,390
namespacing and it also allows role role

00:09:39,900 --> 00:09:43,950
based access control every user in

00:09:42,390 --> 00:09:46,710
manage a queue is a part of a group and

00:09:43,950 --> 00:09:48,930
every group has a specific role from

00:09:46,710 --> 00:09:53,460
this role the users get their

00:09:48,930 --> 00:09:55,530
permissions automation engine is a key

00:09:53,460 --> 00:09:59,220
feature I'll explain about it in a few

00:09:55,530 --> 00:10:00,840
slides a key abstraction in manage a

00:09:59,220 --> 00:10:02,850
queue and a term that I will repeat many

00:10:00,840 --> 00:10:06,600
times this talk is provide these

00:10:02,850 --> 00:10:09,720
providers this is a key abstraction each

00:10:06,600 --> 00:10:13,530
provider is a sub component that talks

00:10:09,720 --> 00:10:16,320
to a specific IT platform so we have a

00:10:13,530 --> 00:10:18,960
provider for VMware provider for Foreman

00:10:16,320 --> 00:10:22,140
a provider for over to OpenStack and

00:10:18,960 --> 00:10:25,520
many more the way to communicate with

00:10:22,140 --> 00:10:32,070
these providers is using their native

00:10:25,520 --> 00:10:35,190
API these providers are modular every

00:10:32,070 --> 00:10:37,110
provider is developed in its own repo

00:10:35,190 --> 00:10:39,330
and separated and this is a good way to

00:10:37,110 --> 00:10:43,020
manage the lifecycle the development

00:10:39,330 --> 00:10:46,140
lifecycle for this provider and but the

00:10:43,020 --> 00:10:49,350
core the core functionality of all

00:10:46,140 --> 00:10:51,270
providers is obstructed obstructed into

00:10:49,350 --> 00:10:53,790
the core of manage a queue so you get

00:10:51,270 --> 00:10:56,040
lots of repos and each community can

00:10:53,790 --> 00:10:58,530
develop its own repos repos the end

00:10:56,040 --> 00:11:01,350
table community the over each community

00:10:58,530 --> 00:11:06,860
the OpenStack Neutron community but then

00:11:01,350 --> 00:11:09,420
the core is in the manage a cube project

00:11:06,860 --> 00:11:11,340
the cut their providers are divided into

00:11:09,420 --> 00:11:14,040
categories this is not a complete list

00:11:11,340 --> 00:11:16,500
it's just so you can get a grid a group

00:11:14,040 --> 00:11:17,670
of what we have so we have cloud

00:11:16,500 --> 00:11:20,120
providers in

00:11:17,670 --> 00:11:23,730
structured providers container providers

00:11:20,120 --> 00:11:27,720
storage providers middleware Network and

00:11:23,730 --> 00:11:30,300
configuration management now for some

00:11:27,720 --> 00:11:32,790
screenshots here you can see the

00:11:30,300 --> 00:11:35,520
container provider dashboard we have to

00:11:32,790 --> 00:11:39,150
open shift providers there with the list

00:11:35,520 --> 00:11:42,030
of entities at the top right below you

00:11:39,150 --> 00:11:43,650
can see the aggregated node utilization

00:11:42,030 --> 00:11:46,110
you can see the CPU and the memory usage

00:11:43,650 --> 00:11:50,280
you can see them also per node you have

00:11:46,110 --> 00:11:53,730
some network data and pod creation and

00:11:50,280 --> 00:11:57,960
deletion trends that can become useful

00:11:53,730 --> 00:12:00,780
if the pod keeps on crashing probably

00:11:57,960 --> 00:12:03,630
the best screen to get a bird's eye view

00:12:00,780 --> 00:12:08,010
over your cluster is the topology view

00:12:03,630 --> 00:12:10,460
you can see here in red your open ships

00:12:08,010 --> 00:12:13,230
cluster it has two nodes one with only

00:12:10,460 --> 00:12:15,780
one pod in one container and the other

00:12:13,230 --> 00:12:19,710
is super busy you can see it has lots of

00:12:15,780 --> 00:12:22,530
pods lots of services routes and whatnot

00:12:19,710 --> 00:12:25,440
and this is the summary view we have

00:12:22,530 --> 00:12:29,190
this view for every entity in manage a

00:12:25,440 --> 00:12:31,380
queue you can see the property of the of

00:12:29,190 --> 00:12:33,780
the entity some statuses about it and

00:12:31,380 --> 00:12:36,030
its relationships to other entities in

00:12:33,780 --> 00:12:39,170
the system so as I said before if you

00:12:36,030 --> 00:12:42,510
have a container that's running on

00:12:39,170 --> 00:12:43,740
kubernetes that is on an open stack

00:12:42,510 --> 00:12:48,870
you'll be able to see in the

00:12:43,740 --> 00:12:52,230
relationships how its old drill down now

00:12:48,870 --> 00:12:54,720
I mentioned the automation engine one of

00:12:52,230 --> 00:12:57,150
the key features which basically allows

00:12:54,720 --> 00:13:01,860
your operator to automate different

00:12:57,150 --> 00:13:04,110
tasks and operations so for example if

00:13:01,860 --> 00:13:06,300
your CPU usage is more you know the node

00:13:04,110 --> 00:13:09,150
is more than 80% you would want an email

00:13:06,300 --> 00:13:11,730
sent to the operations team or if you

00:13:09,150 --> 00:13:14,070
want to automate package update

00:13:11,730 --> 00:13:17,010
deployments compliance and policy

00:13:14,070 --> 00:13:18,330
security checks and whatnot this is the

00:13:17,010 --> 00:13:22,050
manager key way to do it

00:13:18,330 --> 00:13:24,870
it works with running basic Ruby scripts

00:13:22,050 --> 00:13:26,670
and you have useful methods that you can

00:13:24,870 --> 00:13:30,280
use I know it's kind of scary I'm also

00:13:26,670 --> 00:13:32,170
scared of Ruby and this is why

00:13:30,280 --> 00:13:34,600
and even though I'm a Ruby on Rails

00:13:32,170 --> 00:13:37,690
developer and this is why we want to

00:13:34,600 --> 00:13:39,730
adopt llamo as another language for the

00:13:37,690 --> 00:13:41,380
automation engine it is relevant for the

00:13:39,730 --> 00:13:46,090
Entebbe playbooks and I'll speak about

00:13:41,380 --> 00:13:48,010
it in a few slides a general best

00:13:46,090 --> 00:13:50,380
practice in the automation engine is

00:13:48,010 --> 00:13:54,700
using even a design pattern is using

00:13:50,380 --> 00:13:57,730
state machines so you define your state

00:13:54,700 --> 00:14:00,040
you put all your relevant methods inside

00:13:57,730 --> 00:14:02,200
this state and then you define the state

00:14:00,040 --> 00:14:05,980
transactions you can define that this

00:14:02,200 --> 00:14:08,440
state goes to to another state B or C

00:14:05,980 --> 00:14:10,540
you can define what happens on success

00:14:08,440 --> 00:14:14,160
on failure if you want the number of

00:14:10,540 --> 00:14:16,900
retries and this is the actual logic

00:14:14,160 --> 00:14:20,470
state machine that i've written for an

00:14:16,900 --> 00:14:22,540
open shift cluster deployment from

00:14:20,470 --> 00:14:24,130
within manage a queue using open shift

00:14:22,540 --> 00:14:27,190
ansible project I'll speak about it

00:14:24,130 --> 00:14:30,460
later but this is kind of how the logic

00:14:27,190 --> 00:14:39,910
works and think of each state as a bunch

00:14:30,460 --> 00:14:42,190
of Ruby methods yeah okay so the

00:14:39,910 --> 00:14:47,050
question was where can you find these

00:14:42,190 --> 00:14:50,230
state machines or so it's it's more it's

00:14:47,050 --> 00:14:52,120
the answer is not kind of where you can

00:14:50,230 --> 00:14:54,550
find the state machine but where you can

00:14:52,120 --> 00:14:56,380
find the automation engine abilities you

00:14:54,550 --> 00:15:00,810
define these state machines in the

00:14:56,380 --> 00:15:03,910
automation engine in manager Q and then

00:15:00,810 --> 00:15:05,860
in it you can define if you want to just

00:15:03,910 --> 00:15:09,040
write a method a Ruby method or if you

00:15:05,860 --> 00:15:11,830
want to write an actual State and if you

00:15:09,040 --> 00:15:13,750
go with a state it allows you to write

00:15:11,830 --> 00:15:16,920
more States and then define the

00:15:13,750 --> 00:15:24,970
transitions so inside manage a queue

00:15:16,920 --> 00:15:26,920
very useful have I answered great so you

00:15:24,970 --> 00:15:30,339
can also access and manipulate lots of

00:15:26,920 --> 00:15:32,589
objects from the data model not the

00:15:30,339 --> 00:15:36,730
complete data model but you can also ask

00:15:32,589 --> 00:15:39,940
for missing ones and it is a very

00:15:36,730 --> 00:15:42,900
powerful powerful tool you can use it

00:15:39,940 --> 00:15:44,470
from the UI or from the REST API and you

00:15:42,900 --> 00:15:47,140
can import

00:15:44,470 --> 00:15:56,530
Ruby scripts for automation from any git

00:15:47,140 --> 00:15:59,230
repository that you want okay so I've

00:15:56,530 --> 00:16:02,110
been using ansible for a few months now

00:15:59,230 --> 00:16:03,880
and this is kind of the feeling that I

00:16:02,110 --> 00:16:08,140
get every time that I'm using it or

00:16:03,880 --> 00:16:10,150
running it this spongebob happiness in a

00:16:08,140 --> 00:16:11,220
show of hands how many of you have heard

00:16:10,150 --> 00:16:17,380
about ansible

00:16:11,220 --> 00:16:22,020
of course how many actually used it well

00:16:17,380 --> 00:16:28,000
how many of you wrote the playbook and

00:16:22,020 --> 00:16:31,960
how many of you wrote and module ok ok

00:16:28,000 --> 00:16:33,670
so this talk so probably most of you

00:16:31,960 --> 00:16:36,210
know ansible better than I am which is

00:16:33,670 --> 00:16:39,100
great this is not an ansible

00:16:36,210 --> 00:16:42,010
presentation but I do want to explain

00:16:39,100 --> 00:16:44,110
some key principles in ansible so that

00:16:42,010 --> 00:16:46,450
all of you can understand the rest of

00:16:44,110 --> 00:16:49,270
this talk and if you of course have any

00:16:46,450 --> 00:16:51,490
questions about antigo feel free to ask

00:16:49,270 --> 00:16:57,700
me at the end of this presentation I can

00:16:51,490 --> 00:17:00,430
probably show you some cool blogs and no

00:16:57,700 --> 00:17:05,080
formal official documents that I used

00:17:00,430 --> 00:17:08,020
writing these modules so ansible is

00:17:05,080 --> 00:17:11,970
really a simple idea automation tool it

00:17:08,020 --> 00:17:14,800
is basically what it does is

00:17:11,970 --> 00:17:17,920
communicating with the relevant host

00:17:14,800 --> 00:17:20,710
they can be even your local host or

00:17:17,920 --> 00:17:23,680
remote host and it communicates over SSH

00:17:20,710 --> 00:17:26,170
it copies the modules that the programs

00:17:23,680 --> 00:17:29,530
themselves execute them and then delete

00:17:26,170 --> 00:17:31,660
them and I'll now try to and by default

00:17:29,530 --> 00:17:35,890
it's it's over SSH but you can also

00:17:31,660 --> 00:17:39,130
change it I'll just explain some key

00:17:35,890 --> 00:17:42,700
principles inventory files are ini like

00:17:39,130 --> 00:17:46,030
format of files you just throw in all of

00:17:42,700 --> 00:17:48,430
your hosts you can divide them into

00:17:46,030 --> 00:17:52,960
groups you can define variables to your

00:17:48,430 --> 00:17:57,130
list of hosts playbooks are basically

00:17:52,960 --> 00:17:57,970
lists of tasks or operations that gets

00:17:57,130 --> 00:18:01,330
executed

00:17:57,970 --> 00:18:03,190
one at a time it is written in llamÃ³

00:18:01,330 --> 00:18:05,860
which is and therefore it's very easy

00:18:03,190 --> 00:18:08,080
you don't have to be a developer you

00:18:05,860 --> 00:18:10,139
don't have to know any any language to

00:18:08,080 --> 00:18:12,700
write them it's just simple llamo and

00:18:10,139 --> 00:18:15,250
modules as said before are the actual

00:18:12,700 --> 00:18:17,559
problems that do the job behind the

00:18:15,250 --> 00:18:20,019
scenes they bring the system to your

00:18:17,559 --> 00:18:21,820
desired state at the end and this kind

00:18:20,019 --> 00:18:24,279
of connects to the principle of idea

00:18:21,820 --> 00:18:26,080
potency meaning it doesn't matter how

00:18:24,279 --> 00:18:28,240
many time you're going to run the module

00:18:26,080 --> 00:18:31,480
on the same input it will always have

00:18:28,240 --> 00:18:36,909
the same result so for example if you

00:18:31,480 --> 00:18:39,610
are if you want to copy a file and so

00:18:36,909 --> 00:18:41,379
before the module optimally before

00:18:39,610 --> 00:18:43,149
copying that file to another host it

00:18:41,379 --> 00:18:45,309
would check if that file already exists

00:18:43,149 --> 00:18:47,950
there if it doesn't exist then it will

00:18:45,309 --> 00:18:50,740
copy but if it exists optimally again it

00:18:47,950 --> 00:18:53,620
will check if the content is I then is

00:18:50,740 --> 00:18:55,929
the same in both files and only if not

00:18:53,620 --> 00:18:59,200
it would copy it so this is the meaning

00:18:55,929 --> 00:19:01,120
of kana and and this is kind of the

00:18:59,200 --> 00:19:03,909
meaning of a idiom potency i'll give

00:19:01,120 --> 00:19:06,070
other examples for the modules that I

00:19:03,909 --> 00:19:08,970
wrote a real-life example is the

00:19:06,070 --> 00:19:11,889
OpenShift ansible project under the

00:19:08,970 --> 00:19:16,149
OpenShift umbrella this project is used

00:19:11,889 --> 00:19:18,580
to deploy very complex OpenShift

00:19:16,149 --> 00:19:22,389
environment it has lots of advanced

00:19:18,580 --> 00:19:24,700
features like NFS and registries route

00:19:22,389 --> 00:19:27,879
and lots of useful things that would

00:19:24,700 --> 00:19:29,649
take someone probably a lot of time so

00:19:27,879 --> 00:19:31,419
if you're new to open shift if you want

00:19:29,649 --> 00:19:33,909
to try it and i really urge you to do so

00:19:31,419 --> 00:19:36,610
please go ahead and start with this

00:19:33,909 --> 00:19:39,610
project it will help you to just run one

00:19:36,610 --> 00:19:43,960
playbook and you'll have your open chips

00:19:39,610 --> 00:19:45,970
left already an example of inventory

00:19:43,960 --> 00:19:49,179
files so at the top you can see the

00:19:45,970 --> 00:19:52,029
three groups that we have this is a one

00:19:49,179 --> 00:19:54,340
master one node kind of cluster so very

00:19:52,029 --> 00:19:55,570
simple one you can see the that we have

00:19:54,340 --> 00:19:58,299
two variables here

00:19:55,570 --> 00:20:01,509
the deployment type and the release but

00:19:58,299 --> 00:20:03,490
the interesting part is at the NFS group

00:20:01,509 --> 00:20:06,429
so you can see the actual hosts there

00:20:03,490 --> 00:20:08,379
and if we'll take a look at the playbook

00:20:06,429 --> 00:20:11,289
this is an actual playbook which is part

00:20:08,379 --> 00:20:11,840
of open extensible so this playbook

00:20:11,289 --> 00:20:15,650
takes care

00:20:11,840 --> 00:20:18,049
of installing your NFS host it has a

00:20:15,650 --> 00:20:21,289
list of tasks as you can see each task

00:20:18,049 --> 00:20:23,570
has a name but it's not mandatory so you

00:20:21,289 --> 00:20:26,419
install your NFS utils and configure NFS

00:20:23,570 --> 00:20:31,549
we started actually this playbook has a

00:20:26,419 --> 00:20:34,070
problem it will it won't restart the NFS

00:20:31,549 --> 00:20:36,919
config if the configuration hasn't

00:20:34,070 --> 00:20:41,630
changed and it might be a problem in

00:20:36,919 --> 00:20:43,520
case the the NFS config is off and you

00:20:41,630 --> 00:20:47,320
want to start it but there was no change

00:20:43,520 --> 00:20:50,630
in the file anyway this is already fixed

00:20:47,320 --> 00:20:52,399
so after we kind of learn the key

00:20:50,630 --> 00:20:55,309
principles of ansible

00:20:52,399 --> 00:20:57,500
then I want to show you a recent

00:20:55,309 --> 00:21:00,590
implementation of dedicated an table

00:20:57,500 --> 00:21:01,880
modules and this is the core of the

00:21:00,590 --> 00:21:06,679
presentation so please if you have

00:21:01,880 --> 00:21:08,950
questions this is the time now I want to

00:21:06,679 --> 00:21:10,929
go back to the OpenShift ops team that I

00:21:08,950 --> 00:21:15,409
mentioned before

00:21:10,929 --> 00:21:17,570
so we already figured out that we have

00:21:15,409 --> 00:21:19,309
this management solution that is perfect

00:21:17,570 --> 00:21:21,890
for them is called manage a queue and

00:21:19,309 --> 00:21:23,330
they're running OpenShift clusters so

00:21:21,890 --> 00:21:25,850
let's say they're manage a queue

00:21:23,330 --> 00:21:29,710
instance is installed somewhere it can

00:21:25,850 --> 00:21:33,080
be inside the cluster it can be on a

00:21:29,710 --> 00:21:35,720
container on a VM and it doesn't really

00:21:33,080 --> 00:21:37,850
matter and they have their openshift

00:21:35,720 --> 00:21:40,399
cluster so now they want to connect

00:21:37,850 --> 00:21:42,230
these to configure the manage a queue so

00:21:40,399 --> 00:21:44,240
that they will have automatically of

00:21:42,230 --> 00:21:46,730
course so they could just let their

00:21:44,240 --> 00:21:49,809
operators start working and monitoring

00:21:46,730 --> 00:21:54,140
this cluster from within manage a queue

00:21:49,809 --> 00:21:56,330
so we cannot talk to them and realize

00:21:54,140 --> 00:21:58,940
that they already know ansible and it is

00:21:56,330 --> 00:22:02,330
a very useful tool so why not just write

00:21:58,940 --> 00:22:03,950
modules for them a dedicated manager

00:22:02,330 --> 00:22:06,080
queue modules for them so that they'll

00:22:03,950 --> 00:22:08,990
be able to use them instead of learning

00:22:06,080 --> 00:22:10,299
all about manage a queue using its UI or

00:22:08,990 --> 00:22:13,100
REST API

00:22:10,299 --> 00:22:15,669
so the answerable modules come to

00:22:13,100 --> 00:22:17,870
automate and configure different

00:22:15,669 --> 00:22:21,500
operations and use cases in manage a

00:22:17,870 --> 00:22:26,150
queue it works through manage a queues

00:22:21,500 --> 00:22:29,120
REST API and use a python-based

00:22:26,150 --> 00:22:34,670
client that we wrote and maintained it

00:22:29,120 --> 00:22:36,440
also have has an PIP package you can use

00:22:34,670 --> 00:22:38,570
if you want the link is at the end of

00:22:36,440 --> 00:22:41,180
the presentation and the choice of

00:22:38,570 --> 00:22:45,260
Python is kind of nature sense and table

00:22:41,180 --> 00:22:48,860
is a Python project the module support

00:22:45,260 --> 00:22:51,770
SSL certificate verification and you can

00:22:48,860 --> 00:22:54,020
define your environment variables it is

00:22:51,770 --> 00:22:55,520
very useful so that you won't repeat

00:22:54,020 --> 00:22:57,320
every time you write a play book you

00:22:55,520 --> 00:23:01,070
won't repeat the same variables all over

00:22:57,320 --> 00:23:02,930
again it is a work in progress so we

00:23:01,070 --> 00:23:07,220
currently have only five existing

00:23:02,930 --> 00:23:10,370
modules but we already have two pending

00:23:07,220 --> 00:23:13,640
PRS form for other modules and many more

00:23:10,370 --> 00:23:16,880
coming so I'll just mention these five

00:23:13,640 --> 00:23:19,760
the mange cube provider is used to add

00:23:16,880 --> 00:23:21,410
update or delete providers from manage a

00:23:19,760 --> 00:23:23,090
queue for example your open check

00:23:21,410 --> 00:23:26,390
provider your hoc Euler provider

00:23:23,090 --> 00:23:30,680
OpenShift or whatever every time a

00:23:26,390 --> 00:23:34,670
provider is added or updated the each of

00:23:30,680 --> 00:23:37,430
its endpoints gets verified its

00:23:34,670 --> 00:23:41,390
authentication it gets verified and only

00:23:37,430 --> 00:23:43,490
if it is valid then a refresh to the

00:23:41,390 --> 00:23:45,890
inventory is triggered so that you

00:23:43,490 --> 00:23:47,810
already have your inventory in manager

00:23:45,890 --> 00:23:49,520
queue meaning all the entities from that

00:23:47,810 --> 00:23:53,240
provider will already be in your manage

00:23:49,520 --> 00:23:56,480
a queue magic-user is again for adding

00:23:53,240 --> 00:23:59,480
updating and deleting users from manage

00:23:56,480 --> 00:24:01,640
a queue we are working on the manager

00:23:59,480 --> 00:24:05,720
queue group module which will help with

00:24:01,640 --> 00:24:08,000
the permissions custom attributes in

00:24:05,720 --> 00:24:11,420
manage a queue is basically a key value

00:24:08,000 --> 00:24:13,700
pair you can also have a section but

00:24:11,420 --> 00:24:15,620
this is for name spacing so a key value

00:24:13,700 --> 00:24:19,520
pair where every custom attributes has a

00:24:15,620 --> 00:24:21,080
name and value this value can be a date

00:24:19,520 --> 00:24:23,810
it can be a number it can be a string

00:24:21,080 --> 00:24:26,690
and I'll explain later on in the demo

00:24:23,810 --> 00:24:29,270
how they can become handy semantics you

00:24:26,690 --> 00:24:31,190
custom attributes allow you to add

00:24:29,270 --> 00:24:33,980
update or remove custom attributes on

00:24:31,190 --> 00:24:38,620
several resources there are many

00:24:33,980 --> 00:24:40,070
supported resources hosts VMs containers

00:24:38,620 --> 00:24:44,810
providers

00:24:40,070 --> 00:24:49,550
and others the last two are kinda they

00:24:44,810 --> 00:24:52,160
have the same logic they help you assign

00:24:49,550 --> 00:24:54,650
policy profiles which are sets of

00:24:52,160 --> 00:24:57,800
policies and tags over specific

00:24:54,650 --> 00:25:01,520
resources and I'll just show it an

00:24:57,800 --> 00:25:03,020
example of that in my demo and as I said

00:25:01,520 --> 00:25:06,460
before there are many mores to come

00:25:03,020 --> 00:25:10,880
concerning alert policies in tech crowd

00:25:06,460 --> 00:25:13,460
groups and and and more so this is the

00:25:10,880 --> 00:25:15,500
workflow diagram this is very basic in a

00:25:13,460 --> 00:25:19,190
few slides we'll have another one let's

00:25:15,500 --> 00:25:21,890
say our local host has n table on it a

00:25:19,190 --> 00:25:24,310
manage a queue module that we wanna work

00:25:21,890 --> 00:25:29,480
with and the manage a queue API client

00:25:24,310 --> 00:25:32,330
now we can configure from our local host

00:25:29,480 --> 00:25:35,000
arm njq instance no matter where it is

00:25:32,330 --> 00:25:37,340
we just need to know where it is or the

00:25:35,000 --> 00:25:38,990
host name for it and we can configure

00:25:37,340 --> 00:25:41,900
manage a queue or the providers

00:25:38,990 --> 00:25:44,870
themselves and from your open shift

00:25:41,900 --> 00:25:47,270
master from your open shift cluster you

00:25:44,870 --> 00:25:49,970
get all the inventory inside of manage a

00:25:47,270 --> 00:25:57,760
queue this is maybe a good time to stop

00:25:49,970 --> 00:26:00,170
if there are any questions about it ok

00:25:57,760 --> 00:26:03,860
let me know if I'm talking too fast or

00:26:00,170 --> 00:26:05,690
if something is not understood so in

00:26:03,860 --> 00:26:09,050
this demo we're going to see how we

00:26:05,690 --> 00:26:12,560
create a new user and use this user to

00:26:09,050 --> 00:26:14,390
add the new OpenShift provider then add

00:26:12,560 --> 00:26:16,310
custom attributes to this provider and

00:26:14,390 --> 00:26:28,370
then assign policy profile to the

00:26:16,310 --> 00:26:29,900
provider ok so this is my development

00:26:28,370 --> 00:26:31,460
environment and this is manage a queue

00:26:29,900 --> 00:26:35,750
as you can see I don't have any

00:26:31,460 --> 00:26:38,480
containers providers right now and as

00:26:35,750 --> 00:26:40,660
you can see the user at the top is the

00:26:38,480 --> 00:26:44,330
administrator user can you see it well

00:26:40,660 --> 00:26:48,440
also behind not that much maybe turn off

00:26:44,330 --> 00:26:51,620
the front lights let's see if you can

00:26:48,440 --> 00:26:53,510
say this so now we want to show you the

00:26:51,620 --> 00:26:57,230
playbook that I'm running

00:26:53,510 --> 00:27:04,790
you see it at the back maybe with the

00:26:57,230 --> 00:27:08,870
light closed yeah the problem is it is a

00:27:04,790 --> 00:27:11,660
recorded demo so I'll just explain

00:27:08,870 --> 00:27:13,490
what's going on here and if need if

00:27:11,660 --> 00:27:18,020
needed I'll just go over it from my

00:27:13,490 --> 00:27:19,760
laptop life so this is our playbook at

00:27:18,020 --> 00:27:22,070
the top you can see the hosts list

00:27:19,760 --> 00:27:23,630
basically we have only our local host

00:27:22,070 --> 00:27:26,300
because this is where my manager queue

00:27:23,630 --> 00:27:28,730
environment is and there are two tasks

00:27:26,300 --> 00:27:30,830
here one is the is the bigger one and

00:27:28,730 --> 00:27:34,070
the second one is just a debug task it

00:27:30,830 --> 00:27:37,400
is only to output or print the result of

00:27:34,070 --> 00:27:40,720
the last task of the previous task which

00:27:37,400 --> 00:27:42,590
is creating a new user in manage a queue

00:27:40,720 --> 00:27:45,530
basically you give it a name and then

00:27:42,590 --> 00:27:47,570
you state the the module name which in

00:27:45,530 --> 00:27:50,030
this case is manage a queue user you

00:27:47,570 --> 00:27:51,970
give it the right parameters the name

00:27:50,030 --> 00:27:54,230
the password and the group which is

00:27:51,970 --> 00:27:56,210
super administrator group so that we

00:27:54,230 --> 00:27:59,720
will be able to do whatever we want and

00:27:56,210 --> 00:28:02,660
then we just fire up the entropy level

00:27:59,720 --> 00:28:05,810
command with this playbook and wait for

00:28:02,660 --> 00:28:07,640
it to finish so this is the result of

00:28:05,810 --> 00:28:09,230
the debug you can see it successfully

00:28:07,640 --> 00:28:11,930
created the user you can see the play

00:28:09,230 --> 00:28:14,870
recap there were no failures and this is

00:28:11,930 --> 00:28:16,430
again just a basic playbook to help you

00:28:14,870 --> 00:28:21,370
understand now we're going to logout and

00:28:16,430 --> 00:28:21,370
login back with our newly created user

00:28:24,820 --> 00:28:38,030
powerful passwords of 1 2 3 and if we

00:28:32,770 --> 00:28:40,100
you can see that we have our user and go

00:28:38,030 --> 00:28:41,780
back and see that we don't have any

00:28:40,100 --> 00:28:45,350
containers provider just so you know

00:28:41,780 --> 00:28:48,830
that I'm not bluffing you in any way now

00:28:45,350 --> 00:28:53,590
we want to move on and add the openshift

00:28:48,830 --> 00:28:53,590
provider to get a little bit messy so

00:28:55,480 --> 00:29:01,310
here we have again two tasks the second

00:28:59,060 --> 00:29:03,110
we talked about adding open shift

00:29:01,310 --> 00:29:04,520
containers provided to manage a queue we

00:29:03,110 --> 00:29:07,280
have we are using the manage a queue

00:29:04,520 --> 00:29:11,060
provider module we give it a

00:29:07,280 --> 00:29:14,000
of parameters another best practice to

00:29:11,060 --> 00:29:17,360
mention worth mentioning is that every

00:29:14,000 --> 00:29:20,360
module should have a state it can be

00:29:17,360 --> 00:29:22,670
present or absent for ideal potency so

00:29:20,360 --> 00:29:25,520
if this provider is already present it

00:29:22,670 --> 00:29:28,400
won't do anything of course unless it

00:29:25,520 --> 00:29:32,360
there's an update required in its

00:29:28,400 --> 00:29:35,240
attributes but as you can see here there

00:29:32,360 --> 00:29:36,800
are two endpoints that I'm giving one is

00:29:35,240 --> 00:29:39,440
the open shipped one and the second one

00:29:36,800 --> 00:29:41,270
is for metrics it is the ocular endpoint

00:29:39,440 --> 00:29:49,670
I'm giving the hostname the port the

00:29:41,270 --> 00:29:52,190
authentication token and I'm using the

00:29:49,670 --> 00:29:54,350
user that I just created with its

00:29:52,190 --> 00:29:55,940
password and of course you don't have to

00:29:54,350 --> 00:29:57,770
write everything down here you can use

00:29:55,940 --> 00:30:01,960
environment variables or you can define

00:29:57,770 --> 00:30:04,430
some variables in another file for

00:30:01,960 --> 00:30:07,100
security reasons so we're going to fire

00:30:04,430 --> 00:30:09,890
up the antipope label command with our

00:30:07,100 --> 00:30:11,240
playbook now this task will take a

00:30:09,890 --> 00:30:13,130
little bit longer because we need to

00:30:11,240 --> 00:30:16,490
verify the authentication for our

00:30:13,130 --> 00:30:21,530
provider it times out after 60 seconds

00:30:16,490 --> 00:30:23,390
by default but you can change it so now

00:30:21,530 --> 00:30:25,190
we successfully edit the provider and

00:30:23,390 --> 00:30:27,050
you can see both authentications are

00:30:25,190 --> 00:30:29,000
valid and you can see that the refresh

00:30:27,050 --> 00:30:33,050
or maybe can see that it started

00:30:29,000 --> 00:30:35,090
refreshing the inventory we're gonna

00:30:33,050 --> 00:30:37,880
there are no failures and we're going to

00:30:35,090 --> 00:30:42,260
assume move back to the 9gq environment

00:30:37,880 --> 00:30:49,040
refresh the page and now we'll be able

00:30:42,260 --> 00:30:51,860
to see our added opentx provider sorry

00:30:49,040 --> 00:30:54,610
it's taking some time again development

00:30:51,860 --> 00:30:54,610
environment

00:31:00,030 --> 00:31:09,420
and there it is we're going to just look

00:31:04,140 --> 00:31:12,420
inside it and you can see all of its

00:31:09,420 --> 00:31:14,580
properties the hostname that we used you

00:31:12,420 --> 00:31:16,860
can see that the authentications down

00:31:14,580 --> 00:31:19,020
here are validated and that the last

00:31:16,860 --> 00:31:22,920
refresh of the inventory was less than a

00:31:19,020 --> 00:31:24,540
minute ago up on the left you can see

00:31:22,920 --> 00:31:27,210
the relationship between all the

00:31:24,540 --> 00:31:29,970
entities that it's got on the list of

00:31:27,210 --> 00:31:32,430
entities you can obviously get in to

00:31:29,970 --> 00:31:35,070
each one of them and we're going to move

00:31:32,430 --> 00:31:37,050
over to the topology view which also

00:31:35,070 --> 00:31:38,640
take a second and this is kind of the

00:31:37,050 --> 00:31:40,590
same view that I showed you in the first

00:31:38,640 --> 00:31:42,720
screenshot you can actually play with

00:31:40,590 --> 00:31:50,190
everything touch them move them around

00:31:42,720 --> 00:31:51,840
so we just added a provider to manage a

00:31:50,190 --> 00:31:53,460
queue using the manager queue modules

00:31:51,840 --> 00:31:56,940
now we want to add some custom

00:31:53,460 --> 00:31:59,850
attributes to this provider so again

00:31:56,940 --> 00:32:01,410
we're going to edit this playbook I

00:31:59,850 --> 00:32:03,510
promise in the less demo we're going to

00:32:01,410 --> 00:32:07,500
do all the play books together so it

00:32:03,510 --> 00:32:10,110
would be quicker we're just using the

00:32:07,500 --> 00:32:12,360
magic you custom attributes module at

00:32:10,110 --> 00:32:14,100
the top you can see it we state the

00:32:12,360 --> 00:32:17,850
entity type which is a provider in this

00:32:14,100 --> 00:32:19,860
case and the entity name and then state

00:32:17,850 --> 00:32:22,760
present obviously and then the list of

00:32:19,860 --> 00:32:27,240
all the key value pairs that are the

00:32:22,760 --> 00:32:29,370
custom attributes now the use case that

00:32:27,240 --> 00:32:32,160
I want to explain about is here you can

00:32:29,370 --> 00:32:35,280
see I'm going down there the expected

00:32:32,160 --> 00:32:38,910
number of nodes is defined to be two so

00:32:35,280 --> 00:32:41,580
you can actually define a compliance

00:32:38,910 --> 00:32:45,930
policy over it and make sure that once

00:32:41,580 --> 00:32:48,660
one of the nodes of this provider is is

00:32:45,930 --> 00:32:51,690
not ready or not working not accessible

00:32:48,660 --> 00:32:54,120
then you fire up an email to the

00:32:51,690 --> 00:32:57,030
operations team so this is one use case

00:32:54,120 --> 00:32:59,400
of how these custom attributes can be

00:32:57,030 --> 00:33:03,050
useful now we're just going to fire up

00:32:59,400 --> 00:33:06,630
again the n table playable command and

00:33:03,050 --> 00:33:09,230
see the entire list of custom attributes

00:33:06,630 --> 00:33:09,230
we just added

00:33:14,610 --> 00:33:19,960
we'll go back again to our man JQ

00:33:18,370 --> 00:33:24,850
environment just refresh it and you'll

00:33:19,960 --> 00:33:30,250
see a new table here for all the custom

00:33:24,850 --> 00:33:32,050
attributes that we just added and you

00:33:30,250 --> 00:33:38,050
can see the expected number of nodes is

00:33:32,050 --> 00:33:40,270
two and if you are NBA fans then i think

00:33:38,050 --> 00:33:42,070
that the MVP player for this season

00:33:40,270 --> 00:33:52,150
should be Russell Westbrook has written

00:33:42,070 --> 00:33:56,980
there now to finish this short demo

00:33:52,150 --> 00:33:59,380
we'll just go ahead and assign a politic

00:33:56,980 --> 00:34:02,320
profile to this provider this policy

00:33:59,380 --> 00:34:04,810
profile will take care of the open ASCAP

00:34:02,320 --> 00:34:06,580
scan that we talked about before so for

00:34:04,810 --> 00:34:09,160
every new image container image

00:34:06,580 --> 00:34:12,370
discovered in the cluster we want to

00:34:09,160 --> 00:34:16,360
schedule a smart site analysis scan it

00:34:12,370 --> 00:34:21,040
then run a compliance test of open ASCAP

00:34:16,360 --> 00:34:23,560
to see project the CVS and make sure

00:34:21,040 --> 00:34:28,390
that we want to use it so you can see

00:34:23,560 --> 00:34:31,419
that the you can see here that there are

00:34:28,390 --> 00:34:33,760
no the open SK policy here is not marked

00:34:31,419 --> 00:34:36,540
for this provider this is just a list of

00:34:33,760 --> 00:34:36,540
available

00:34:36,720 --> 00:34:43,350
policy profiles now again just run the

00:34:40,300 --> 00:34:43,350
antipope label command

00:34:49,760 --> 00:34:54,770
and you can see that it was successfully

00:34:52,040 --> 00:34:58,460
assigned to our provider or go back

00:34:54,770 --> 00:35:12,350
refresh the page and see the small

00:34:58,460 --> 00:35:15,800
checkmark near the policy profile just a

00:35:12,350 --> 00:35:19,100
second okay and we can actually go

00:35:15,800 --> 00:35:23,150
inside and see what policies are inside

00:35:19,100 --> 00:35:25,520
of this set so we have we are scheduling

00:35:23,150 --> 00:35:27,440
compliance after the smart set analysis

00:35:25,520 --> 00:35:29,690
and and the analysis happens after every

00:35:27,440 --> 00:35:31,690
incoming tener image then we trigger the

00:35:29,690 --> 00:35:34,040
compliance which is the open etiquette

00:35:31,690 --> 00:35:36,710
and obviously I know this is kind of

00:35:34,040 --> 00:35:40,100
frustrating but just imagine that all

00:35:36,710 --> 00:35:43,490
these actions are running within one

00:35:40,100 --> 00:35:45,710
playbook with every new cluster that is

00:35:43,490 --> 00:35:48,890
being deployed for the open shift

00:35:45,710 --> 00:35:56,690
team so we are automating this for them

00:35:48,890 --> 00:36:01,190
so we've mentioned

00:35:56,690 --> 00:36:03,230
ocular time series DB and after working

00:36:01,190 --> 00:36:04,520
with the OpenShift ops team I kind of

00:36:03,230 --> 00:36:07,250
decided what hey why not

00:36:04,520 --> 00:36:09,800
write some more ansible modules for

00:36:07,250 --> 00:36:15,470
ocular because it's kind of hard to

00:36:09,800 --> 00:36:18,230
tweak it has this REST API that is not

00:36:15,470 --> 00:36:20,960
that easy easy to use and if you already

00:36:18,230 --> 00:36:22,460
know ansible then you can just look at

00:36:20,960 --> 00:36:30,680
the parameters look at the documentation

00:36:22,460 --> 00:36:33,200
you use it so again ocular is a time

00:36:30,680 --> 00:36:34,730
series TB by Red Hat yet another one

00:36:33,200 --> 00:36:38,990
based on Cassandra

00:36:34,730 --> 00:36:43,220
it stores metrics you can define certain

00:36:38,990 --> 00:36:45,230
triggers and receive the alert it also

00:36:43,220 --> 00:36:47,480
works through the whole kilo a little

00:36:45,230 --> 00:36:49,820
stressed API and uses the Python based

00:36:47,480 --> 00:36:55,340
client and again I'm one of the

00:36:49,820 --> 00:36:58,070
maintainer and we also working on this P

00:36:55,340 --> 00:37:00,440
package for it so that you can use it

00:36:58,070 --> 00:37:03,070
more easily it also support SSL cert

00:37:00,440 --> 00:37:05,410
verification and you can define your in

00:37:03,070 --> 00:37:08,140
and variables now we have three existing

00:37:05,410 --> 00:37:12,460
modules obviously there they're going to

00:37:08,140 --> 00:37:16,540
be more I'll just explain the terms here

00:37:12,460 --> 00:37:21,580
a trigger is basically a set of

00:37:16,540 --> 00:37:24,130
conditions that you want a certain

00:37:21,580 --> 00:37:26,830
entity or send in metric to follow now

00:37:24,130 --> 00:37:29,500
what happens if you want everyone each

00:37:26,830 --> 00:37:35,550
and each one of your nodes to have at

00:37:29,500 --> 00:37:38,320
least five percent of its CPU free so

00:37:35,550 --> 00:37:40,300
you wouldn't want to define it for every

00:37:38,320 --> 00:37:42,820
node what you do is define a group

00:37:40,300 --> 00:37:45,160
trigger which is basically a class or an

00:37:42,820 --> 00:37:48,100
object that you can instantiate from and

00:37:45,160 --> 00:37:50,500
these instances are called members so we

00:37:48,100 --> 00:37:53,680
have popular alerts group mem group

00:37:50,500 --> 00:37:56,860
trigger which is for creation update and

00:37:53,680 --> 00:37:59,040
deletion of group triggers and we have

00:37:56,860 --> 00:38:03,790
the ocular alerts group member which is

00:37:59,040 --> 00:38:06,550
again quick creation update and deletion

00:38:03,790 --> 00:38:08,980
of group members group to trigger

00:38:06,550 --> 00:38:12,340
members now dampening is actually a part

00:38:08,980 --> 00:38:15,130
of the condition they are used to

00:38:12,340 --> 00:38:17,320
empower the conditions and avoid spiking

00:38:15,130 --> 00:38:19,810
so if you want your condition to be

00:38:17,320 --> 00:38:22,420
evaluated to true but you don't want it

00:38:19,810 --> 00:38:25,330
to happen after one evaluation because

00:38:22,420 --> 00:38:28,930
it might be a mistake you can set it to

00:38:25,330 --> 00:38:32,880
a number of consecutive evaluation two

00:38:28,930 --> 00:38:40,860
evaluations or end to evaluations out of

00:38:32,880 --> 00:38:46,420
M evaluations or out of a certain time

00:38:40,860 --> 00:38:48,880
so this is a dumpling now I want to take

00:38:46,420 --> 00:38:50,920
a look at go back to the work flow

00:38:48,880 --> 00:38:53,050
diagram and see that now we've added the

00:38:50,920 --> 00:38:56,740
ocular modules and the whole Keeler

00:38:53,050 --> 00:38:59,410
client the difference is now that the

00:38:56,740 --> 00:39:01,810
ocular module is working through the

00:38:59,410 --> 00:39:04,300
client to define the triggers straight

00:39:01,810 --> 00:39:08,170
to hoc Euler and not through manage a

00:39:04,300 --> 00:39:10,330
queue as for what we've seen in open

00:39:08,170 --> 00:39:12,310
chiefdom njq before you define your

00:39:10,330 --> 00:39:15,100
triggers to hoc Euler and then

00:39:12,310 --> 00:39:16,420
ocular gets its metrics from openshift

00:39:15,100 --> 00:39:20,230
from the cluster you can see

00:39:16,420 --> 00:39:21,999
the road they're going down and then the

00:39:20,230 --> 00:39:24,609
arrow sorry and then there's another

00:39:21,999 --> 00:39:26,259
arrow for hak Euler sending the alerts

00:39:24,609 --> 00:39:28,059
to manage a queue and you can the

00:39:26,259 --> 00:39:29,950
operator can actually see them from

00:39:28,059 --> 00:39:32,829
manage a queue and then use the

00:39:29,950 --> 00:39:35,680
automation engine to to do whatever he

00:39:32,829 --> 00:39:40,029
wants to send an email or or wake up

00:39:35,680 --> 00:39:42,390
someone in the middle of the night so

00:39:40,029 --> 00:39:45,400
this demonstration in this image

00:39:42,390 --> 00:39:48,309
demonstration I'll show you how to add

00:39:45,400 --> 00:39:50,410
again we'll add an opt provider but this

00:39:48,309 --> 00:39:52,269
time also we're going to add a hockey

00:39:50,410 --> 00:39:54,309
lured provider it's a different type of

00:39:52,269 --> 00:39:55,839
provider and then we're going to create

00:39:54,309 --> 00:39:58,779
a group trigger create a group member

00:39:55,839 --> 00:40:01,269
both in hoc Euler push a metric using a

00:39:58,779 --> 00:40:03,910
script it's going to be an artificial

00:40:01,269 --> 00:40:05,650
metric to hoc Euler and then we're going

00:40:03,910 --> 00:40:07,299
to receive the alert to manage a queue

00:40:05,650 --> 00:40:08,829
now just before I'm showing you the demo

00:40:07,299 --> 00:40:13,239
I want to mention that this is a work in

00:40:08,829 --> 00:40:15,130
progress so maybe some of the the icons

00:40:13,239 --> 00:40:19,569
are missing this is a feature we are

00:40:15,130 --> 00:40:21,339
actually working on right now okay so

00:40:19,569 --> 00:40:24,400
again this is my manager queue

00:40:21,339 --> 00:40:26,289
development environment we are in the

00:40:24,400 --> 00:40:31,809
monitoring area where you can see I

00:40:26,289 --> 00:40:34,539
don't have any alerts at this point now

00:40:31,809 --> 00:40:36,220
I want to show you a a new other place

00:40:34,539 --> 00:40:40,529
which is the data warehouse providers

00:40:36,220 --> 00:40:44,140
area and here I don't have any providers

00:40:40,529 --> 00:40:47,200
by now we are in table experts so all

00:40:44,140 --> 00:40:48,579
the tasks are in one playbook and we're

00:40:47,200 --> 00:40:50,170
just going to go over them the first one

00:40:48,579 --> 00:40:52,480
is adding the open shaped containers

00:40:50,170 --> 00:40:58,029
provider here I'm not debugging the

00:40:52,480 --> 00:40:59,680
output because we've already seen it you

00:40:58,029 --> 00:41:02,289
can see one of the endpoints of that

00:40:59,680 --> 00:41:05,410
open trip provider is actually the the

00:41:02,289 --> 00:41:08,019
ocular database and we're also adding a

00:41:05,410 --> 00:41:10,480
howl killer data warehouse provider also

00:41:08,019 --> 00:41:12,069
using the manager cue provider module

00:41:10,480 --> 00:41:14,499
that I've showed you before it has a

00:41:12,069 --> 00:41:17,470
different type obviously and then we're

00:41:14,499 --> 00:41:20,249
moving to the new modules for ocular

00:41:17,470 --> 00:41:23,829
alerts we are creating a group trigger

00:41:20,249 --> 00:41:27,730
using the group trigger module the

00:41:23,829 --> 00:41:30,190
tenant parameter is used for for name

00:41:27,730 --> 00:41:33,280
spacing for separation

00:41:30,190 --> 00:41:35,560
and then we can define the group ID but

00:41:33,280 --> 00:41:38,050
the very heart of the trigger is the

00:41:35,560 --> 00:41:41,400
conditions so you can see we don't want

00:41:38,050 --> 00:41:45,490
CPU to be too low and this is in percent

00:41:41,400 --> 00:41:47,440
it's a threshold kind of trigger so if

00:41:45,490 --> 00:41:50,800
the data ID the metric that we want to

00:41:47,440 --> 00:41:54,640
use kernel all CPU idle is less than 5%

00:41:50,800 --> 00:41:56,920
we want to fire up an alert and now we

00:41:54,640 --> 00:41:59,890
want to just instantiate the member of

00:41:56,920 --> 00:42:05,050
our group trigger so we're using the

00:41:59,890 --> 00:42:07,090
group number module again using the same

00:42:05,050 --> 00:42:09,550
tenant and we want to link it to the

00:42:07,090 --> 00:42:11,800
group ID of the group trigger give it an

00:42:09,550 --> 00:42:13,900
ID give it give it a description

00:42:11,800 --> 00:42:20,080
basically it's just the text that we

00:42:13,900 --> 00:42:28,770
want to show in M + JQ and this is where

00:42:20,080 --> 00:42:32,500
we map the metric to our actual node and

00:42:28,770 --> 00:42:36,790
we can also give it tags to use them

00:42:32,500 --> 00:42:41,850
within manage a queue so now we'll just

00:42:36,790 --> 00:42:45,280
fire up the antipope label command and

00:42:41,850 --> 00:42:52,450
then each task is getting executed one

00:42:45,280 --> 00:42:56,050
at a time so the open check provider was

00:42:52,450 --> 00:43:06,760
added now the hawk Euler data warehouse

00:42:56,050 --> 00:43:09,400
provider and the last two are for the

00:43:06,760 --> 00:43:16,630
ocular group trigger and hoc Euler group

00:43:09,400 --> 00:43:23,370
member now we'll just refresh this page

00:43:16,630 --> 00:43:23,370
and see the newly added ocular provider

00:43:25,200 --> 00:43:34,240
there are no icons yet sorry and we can

00:43:30,610 --> 00:43:37,720
go into it but let's let's go over to

00:43:34,240 --> 00:43:39,460
the monitoring part area and we can see

00:43:37,720 --> 00:43:43,650
that we still don't have any alerts

00:43:39,460 --> 00:43:43,650
which is great because nothing happened

00:43:43,960 --> 00:43:50,890
now we want to generate an alert so I'm

00:43:47,800 --> 00:43:53,260
logging into the VM and then to the

00:43:50,890 --> 00:43:56,800
docker container that is running the

00:43:53,260 --> 00:43:59,050
ocular instance and as you can see here

00:43:56,800 --> 00:44:01,150
I'll just stop it for a minute I'm using

00:43:59,050 --> 00:44:04,780
well some of you probably at the back

00:44:01,150 --> 00:44:07,540
end see so I'm running a simple Python

00:44:04,780 --> 00:44:10,030
script that I wrote that can send a

00:44:07,540 --> 00:44:12,490
metric with a certain value so I'm

00:44:10,030 --> 00:44:14,230
sending a metric kernel oil CPU idle

00:44:12,490 --> 00:44:17,890
which kind of familiar

00:44:14,230 --> 00:44:20,710
you may familiar from the from the

00:44:17,890 --> 00:44:22,900
playbook and then we give it the value

00:44:20,710 --> 00:44:25,089
that we want which is four it is less

00:44:22,900 --> 00:44:28,030
than five and for that reason we're

00:44:25,089 --> 00:44:37,930
going to fire up the alert so I'm just

00:44:28,030 --> 00:44:43,300
running this script and now we are

00:44:37,930 --> 00:44:46,000
expecting an alert we are refreshing the

00:44:43,300 --> 00:44:47,020
page and still there the alerts even if

00:44:46,000 --> 00:44:49,060
the alert isn't here

00:44:47,020 --> 00:44:53,320
it takes a bit time cents for every

00:44:49,060 --> 00:44:56,800
provider in manage aq mange q starts a

00:44:53,320 --> 00:44:59,320
new worker and currently the worker

00:44:56,800 --> 00:45:01,960
takes a bit time you see these are the

00:44:59,320 --> 00:45:03,900
workers before I edit them and now I'm

00:45:01,960 --> 00:45:06,460
checking the status to see if the

00:45:03,900 --> 00:45:13,630
dedicated worker for the hockey alert

00:45:06,460 --> 00:45:18,849
provider is is starting and as you can

00:45:13,630 --> 00:45:23,560
see it already started and now

00:45:18,849 --> 00:45:26,980
refreshing the alerts area again we can

00:45:23,560 --> 00:45:30,210
see our new alert we have one alert from

00:45:26,980 --> 00:45:30,210
our open shift provider

00:45:34,400 --> 00:45:42,559
and we can see the same text that we use

00:45:37,819 --> 00:45:47,500
and we can see the provider name we can

00:45:42,559 --> 00:45:47,500
see it was updated 32 seconds ago so

00:45:47,770 --> 00:45:53,660
everything is fast enough and you can

00:45:51,680 --> 00:45:59,650
also see some other details about the

00:45:53,660 --> 00:46:04,010
other that is things that we plan to add

00:45:59,650 --> 00:46:05,720
so this was the second demo now I want

00:46:04,010 --> 00:46:11,839
to talk a little about ansible

00:46:05,720 --> 00:46:17,119
integration within manage a queue so in

00:46:11,839 --> 00:46:21,670
the in this month redhead summit it was

00:46:17,119 --> 00:46:24,289
announced that from cloud forms 4.5

00:46:21,670 --> 00:46:28,430
OpenTable tower which is the enterprise

00:46:24,289 --> 00:46:32,440
version of of ansible

00:46:28,430 --> 00:46:35,960
is going to is going to be available

00:46:32,440 --> 00:46:40,819
pre-installed within man JQ open

00:46:35,960 --> 00:46:43,940
openshift so it's the N table tower is

00:46:40,819 --> 00:46:45,770
not open sourced but redhead and and

00:46:43,940 --> 00:46:47,869
people are committed to open source it

00:46:45,770 --> 00:46:50,359
and this effort is called the open tower

00:46:47,869 --> 00:46:54,049
project if you want to take a look this

00:46:50,359 --> 00:46:55,819
is the link and as I said the tower will

00:46:54,049 --> 00:46:57,859
come pre-installed in the downstream

00:46:55,819 --> 00:47:00,529
version of cloud forms but if you want

00:46:57,859 --> 00:47:02,720
to deploy it in manage a queue you were

00:47:00,529 --> 00:47:04,490
able there very simple instructions on

00:47:02,720 --> 00:47:07,910
how to do so and you will be able to use

00:47:04,490 --> 00:47:09,819
your own table tower provider now what

00:47:07,910 --> 00:47:13,220
it gives you is the opportunity to

00:47:09,819 --> 00:47:15,650
access and run play books from wherever

00:47:13,220 --> 00:47:17,420
from within manage a queue from your

00:47:15,650 --> 00:47:20,210
provider which is kind of cool and

00:47:17,420 --> 00:47:23,089
useful you can set these playbook as

00:47:20,210 --> 00:47:24,920
service catalogs for end-users you can

00:47:23,089 --> 00:47:28,970
use them in the automation you can use

00:47:24,920 --> 00:47:31,160
them for compliance and this is a

00:47:28,970 --> 00:47:32,779
screenshot of how it looks like in cloud

00:47:31,160 --> 00:47:35,619
forms you can see your end tables our

00:47:32,779 --> 00:47:39,200
providers you can see data about them

00:47:35,619 --> 00:47:41,809
the cool thing is that we have a two-way

00:47:39,200 --> 00:47:45,349
sync between cloud forms and ansible

00:47:41,809 --> 00:47:48,320
tower so you can see your group of hosts

00:47:45,349 --> 00:47:50,990
from unstable Tower in many JQ but you

00:47:48,320 --> 00:47:53,750
also use hosts managed in manage a queue

00:47:50,990 --> 00:47:56,620
in an table tower which is kind of cool

00:47:53,750 --> 00:48:00,500
you can say screenshot here and another

00:47:56,620 --> 00:48:05,840
kind of abstraction over roles in

00:48:00,500 --> 00:48:08,030
ansible roles are set of play books with

00:48:05,840 --> 00:48:10,820
predefined parameters and variables and

00:48:08,030 --> 00:48:12,830
maybe some other files so you have these

00:48:10,820 --> 00:48:15,110
job templates that you can launch from

00:48:12,830 --> 00:48:18,560
the automation or service catalog as I

00:48:15,110 --> 00:48:21,230
said before and each of these jobs can

00:48:18,560 --> 00:48:23,360
run multiple times every run is called

00:48:21,230 --> 00:48:25,760
the job and you can get some data about

00:48:23,360 --> 00:48:29,660
every run you can see a successful run

00:48:25,760 --> 00:48:34,310
of adding a host to AWS and it is a very

00:48:29,660 --> 00:48:37,910
powerful tool and as I mentioned before

00:48:34,310 --> 00:48:41,540
about antigo we do plan to adopt llamÃ³

00:48:37,910 --> 00:48:45,430
to another language in the automation

00:48:41,540 --> 00:48:48,410
engine so you would need to learn Ruby

00:48:45,430 --> 00:48:52,280
what's next what do we plan for next so

00:48:48,410 --> 00:48:54,620
we want to add new modules to extend the

00:48:52,280 --> 00:48:57,800
capabilities we have now there are at

00:48:54,620 --> 00:49:00,050
least five that will be added in the

00:48:57,800 --> 00:49:01,940
near future we're going to propose more

00:49:00,050 --> 00:49:03,560
advanced example playbooks for you to

00:49:01,940 --> 00:49:05,440
try there are a bunch of example play

00:49:03,560 --> 00:49:08,840
books already in the github repository

00:49:05,440 --> 00:49:10,790
but we want to add more and we will add

00:49:08,840 --> 00:49:15,500
them to the integral to end table galaxy

00:49:10,790 --> 00:49:17,270
for sure and we wanna the most important

00:49:15,500 --> 00:49:20,420
part is probably adding these modules

00:49:17,270 --> 00:49:23,270
both manage a queue and ocular inside of

00:49:20,420 --> 00:49:26,720
ansible project so that once you

00:49:23,270 --> 00:49:28,640
installed you up get or yum install and

00:49:26,720 --> 00:49:33,560
Sybil you will get all of these modules

00:49:28,640 --> 00:49:36,890
out-of-the-box so just to summarize what

00:49:33,560 --> 00:49:41,200
we've seen here we kind of saw how many

00:49:36,890 --> 00:49:44,480
JQ can help you manage lots of IT

00:49:41,200 --> 00:49:46,610
environments how anti-bill is a cool and

00:49:44,480 --> 00:49:49,340
simple automation tool that you can use

00:49:46,610 --> 00:49:53,090
and combining these two can really help

00:49:49,340 --> 00:49:55,580
help you with your data center

00:49:53,090 --> 00:49:59,780
automation I showed you this one example

00:49:55,580 --> 00:50:01,700
but we can think of other use cases you

00:49:59,780 --> 00:50:02,330
can use the manage a queue and ocular

00:50:01,700 --> 00:50:04,880
module

00:50:02,330 --> 00:50:10,460
and also the ansible integration within

00:50:04,880 --> 00:50:12,260
manage a queue just before we finish I

00:50:10,460 --> 00:50:14,810
want to say that we are accepting

00:50:12,260 --> 00:50:17,780
contributions right now those two repos

00:50:14,810 --> 00:50:20,150
are under my private guitar repository

00:50:17,780 --> 00:50:22,490
but of course public but under my name

00:50:20,150 --> 00:50:24,920
and we plan to move them in the new

00:50:22,490 --> 00:50:29,210
future under the mange queue and the

00:50:24,920 --> 00:50:32,090
hawk Euler umbrellas some useful links

00:50:29,210 --> 00:50:35,990
the slides and the Python client we're

00:50:32,090 --> 00:50:46,070
using from njq and for ocular and that's

00:50:35,990 --> 00:50:58,430
it thank you for listening if there are

00:50:46,070 --> 00:51:01,010
any questions hi um so in the thankful

00:50:58,430 --> 00:51:03,560
presentation was cool in the context of

00:51:01,010 --> 00:51:06,080
these state machine things you you

00:51:03,560 --> 00:51:09,470
talked a lot about how you can write

00:51:06,080 --> 00:51:11,410
Ruby functions and stuff and that will

00:51:09,470 --> 00:51:14,770
somehow

00:51:11,410 --> 00:51:17,600
yeah interact with the ends of things

00:51:14,770 --> 00:51:21,200
which are Python so I've been wondering

00:51:17,600 --> 00:51:24,080
how how does this interact and and do

00:51:21,200 --> 00:51:26,930
you - are you required with manager IQ

00:51:24,080 --> 00:51:31,790
to run both Ruby and Python together is

00:51:26,930 --> 00:51:35,630
that by design and is that cool okay so

00:51:31,790 --> 00:51:38,270
I'll try to answer I think I somehow I

00:51:35,630 --> 00:51:41,300
probably made some mess with this

00:51:38,270 --> 00:51:43,910
explanation so so I'll try to do it

00:51:41,300 --> 00:51:45,920
again shortly the automation allows you

00:51:43,910 --> 00:51:48,590
to write Ruby scripts you can write them

00:51:45,920 --> 00:51:50,990
as States in a state machine or not

00:51:48,590 --> 00:51:52,970
anyway anything written in the

00:51:50,990 --> 00:51:55,820
automation engine is now in Ruby no

00:51:52,970 --> 00:51:59,150
Python there I use Python to run to run

00:51:55,820 --> 00:52:01,190
to right the manager queue and ocular

00:51:59,150 --> 00:52:05,000
modules themselves but this is a private

00:52:01,190 --> 00:52:06,950
this is another project and I'm using

00:52:05,000 --> 00:52:08,600
Python for other scripts that I'm

00:52:06,950 --> 00:52:10,580
running because I prefer it over Ruby

00:52:08,600 --> 00:52:12,320
but when you want it to use the

00:52:10,580 --> 00:52:14,570
automation engine within manage a queue

00:52:12,320 --> 00:52:16,330
you need to write Ruby scripts now I

00:52:14,570 --> 00:52:19,790
said that we plan to

00:52:16,330 --> 00:52:21,620
yamo as another language in the

00:52:19,790 --> 00:52:25,010
automation engine so that you won't

00:52:21,620 --> 00:52:27,500
won't have to learn Ruby in order to run

00:52:25,010 --> 00:52:29,990
basic ansible labels you would just be

00:52:27,500 --> 00:52:32,630
able to write your playbooks inside

00:52:29,990 --> 00:52:36,590
manage a queue until this happens you

00:52:32,630 --> 00:52:40,550
can just write the Ruby you can just

00:52:36,590 --> 00:52:42,860
write a template string in Ruby and just

00:52:40,550 --> 00:52:45,560
convert it into y ml and write it I know

00:52:42,860 --> 00:52:47,360
it's not that comfortable but it's the

00:52:45,560 --> 00:52:48,890
way to run playbooks from within the

00:52:47,360 --> 00:52:50,990
automation engine if you just want to

00:52:48,890 --> 00:52:53,990
write them there but that's just for the

00:52:50,990 --> 00:52:58,130
meantime until we adopt llamÃ³ does that

00:52:53,990 --> 00:53:00,320
answers the question okay so no Python

00:52:58,130 --> 00:53:02,150
at all inside manage a queue I only use

00:53:00,320 --> 00:53:05,030
it for outside scripts and modules and

00:53:02,150 --> 00:53:06,830
currently in manager queue only Ruby for

00:53:05,030 --> 00:53:15,380
the automation engine and in the future

00:53:06,830 --> 00:53:17,600
we'll add Yama any more questions okay

00:53:15,380 --> 00:53:19,910
thanks for your talk um I'm actually

00:53:17,600 --> 00:53:21,530
still maybe might be even out of scope

00:53:19,910 --> 00:53:23,000
for the business question but just more

00:53:21,530 --> 00:53:26,720
curious how you actually define the

00:53:23,000 --> 00:53:28,730
state machines and secondly from the

00:53:26,720 --> 00:53:29,960
sort of system in architectural point of

00:53:28,730 --> 00:53:32,470
view of someone who wants to see what's

00:53:29,960 --> 00:53:34,940
happening in the data center how do you

00:53:32,470 --> 00:53:37,070
reason about and see all the state

00:53:34,940 --> 00:53:39,350
machine stuff unlike get a good picture

00:53:37,070 --> 00:53:41,720
you have to keep a good memory as you

00:53:39,350 --> 00:53:44,180
switch tabs or is there sort of better

00:53:41,720 --> 00:53:46,430
way to understand what's going to happen

00:53:44,180 --> 00:53:50,560
when your code runs just for safety

00:53:46,430 --> 00:53:54,380
reasons and making sure that things are

00:53:50,560 --> 00:53:57,620
okay I'm going to start with the first

00:53:54,380 --> 00:54:00,940
question about the state machines maybe

00:53:57,620 --> 00:54:05,360
can you just repeat like the engine you

00:54:00,940 --> 00:54:08,900
how you define them actually okay reason

00:54:05,360 --> 00:54:10,820
about them okay so I actually have a

00:54:08,900 --> 00:54:12,290
demo that I can show I don't think I

00:54:10,820 --> 00:54:15,050
have enough time so maybe I'll catch you

00:54:12,290 --> 00:54:17,750
in between but basically there is an

00:54:15,050 --> 00:54:21,470
area in manage a queue that concerns the

00:54:17,750 --> 00:54:23,570
automation and from there you can you

00:54:21,470 --> 00:54:25,310
define your domain and this is the way

00:54:23,570 --> 00:54:29,180
to kind of separate what you write from

00:54:25,310 --> 00:54:31,220
the rest of from

00:54:29,180 --> 00:54:33,380
rest of manager Q environment so you

00:54:31,220 --> 00:54:36,020
write your domain you define a namespace

00:54:33,380 --> 00:54:38,420
you define a class and in this class you

00:54:36,020 --> 00:54:40,579
can choose if you want to write start

00:54:38,420 --> 00:54:43,550
writing on this blank page if you want

00:54:40,579 --> 00:54:46,160
to write a method or a state when you

00:54:43,550 --> 00:54:48,619
choose a state you then need to define

00:54:46,160 --> 00:54:51,200
other states if you want them and it

00:54:48,619 --> 00:54:53,690
gives you the option just with a drag

00:54:51,200 --> 00:54:55,670
and drop or with dropdowns and you can

00:54:53,690 --> 00:54:59,240
do both to add the transitions between

00:54:55,670 --> 00:55:02,450
the states now you can see the actual

00:54:59,240 --> 00:55:05,510
run from an exploit view in manage a

00:55:02,450 --> 00:55:10,280
queue you can but if usually we run it

00:55:05,510 --> 00:55:11,180
from the rest api so we only have we can

00:55:10,280 --> 00:55:12,589
see from the logs

00:55:11,180 --> 00:55:15,349
there is an information log and you can

00:55:12,589 --> 00:55:18,410
see a recap of every state what happened

00:55:15,349 --> 00:55:21,410
there and they're kind of there stating

00:55:18,410 --> 00:55:24,619
if it was successful or if it was there

00:55:21,410 --> 00:55:27,980
was a failure and some other options I

00:55:24,619 --> 00:55:30,290
can also show you afterwards if you want

00:55:27,980 --> 00:55:32,390
the implementation I did for the open

00:55:30,290 --> 00:55:34,549
shifty installer because we write we

00:55:32,390 --> 00:55:36,290
wrote the state machine there and you

00:55:34,549 --> 00:55:38,390
can see all the methods inside of it and

00:55:36,290 --> 00:55:41,240
what happens in the different cases but

00:55:38,390 --> 00:55:44,510
this is all inside the manage a queue

00:55:41,240 --> 00:55:46,369
automation engine area cool very very

00:55:44,510 --> 00:55:49,160
cool thank you and maybe the other

00:55:46,369 --> 00:55:51,650
question if we have time I just not sure

00:55:49,160 --> 00:55:55,119
I answer it I think we're five five more

00:55:51,650 --> 00:55:55,119
minutes okay

00:55:59,460 --> 00:56:07,550
okay so normal questions then thank you

00:56:04,660 --> 00:56:14,139
again Daniel thank you

00:56:07,550 --> 00:56:14,139

YouTube URL: https://www.youtube.com/watch?v=ZsBX5J0s9C0


