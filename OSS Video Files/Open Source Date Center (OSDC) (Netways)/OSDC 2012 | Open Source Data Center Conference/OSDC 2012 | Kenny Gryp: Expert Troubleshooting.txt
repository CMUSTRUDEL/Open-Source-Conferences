Title: OSDC 2012 | Kenny Gryp: Expert Troubleshooting
Publication date: 2015-01-14
Playlist: OSDC 2012 | Open Source Data Center Conference
Description: 
	Der Vortrag gibt einen Ansatz, mit dem schon viele frustrierende Probleme schnell gelöst wurden sowie Open Source Tools, die den Prozess unterstützen.  Es werden vor allem Key Tools vom Percona Toolkit vorgestellt, die dabei helfen Probleme zu erkennen, die nicht direkt ersichtlich sind.
Captions: 
	00:00:07,220 --> 00:00:09,879
welcome back

00:00:11,469 --> 00:00:17,060
blind

00:00:13,250 --> 00:00:20,480
some but it's that doesn't matter if I'm

00:00:17,060 --> 00:00:22,939
blind we will hear Kenny group and he

00:00:20,480 --> 00:00:26,689
will speak about troubleshooting mice

00:00:22,939 --> 00:00:32,629
over my skin problems quickly so okay I

00:00:26,689 --> 00:00:36,559
I know yet 9 how many 94 slides 94

00:00:32,629 --> 00:00:42,470
slides yes so troubleshooting is quickly

00:00:36,559 --> 00:00:44,210
also slides quickly enjoy so good

00:00:42,470 --> 00:00:46,760
morning so I'm going to try to have more

00:00:44,210 --> 00:00:50,120
slides than magic later on today so he

00:00:46,760 --> 00:00:55,149
said he had 91 so I had 94 so that's

00:00:50,120 --> 00:00:58,610
good ok so I'm going to talk about

00:00:55,149 --> 00:01:01,280
expert troubleshooting and the way we

00:00:58,610 --> 00:01:05,690
troubleshoot a lot of my squirrel

00:01:01,280 --> 00:01:09,940
problems when we do some consulting at

00:01:05,690 --> 00:01:12,740
percona so this is a little bit bit oh

00:01:09,940 --> 00:01:15,039
hey window oh the chapters that I'll

00:01:12,740 --> 00:01:17,570
talk about first the problem

00:01:15,039 --> 00:01:19,729
instrumentation and then I have three

00:01:17,570 --> 00:01:21,860
different kinds of trouble shooting

00:01:19,729 --> 00:01:26,840
there are more types but i'm going to

00:01:21,860 --> 00:01:29,000
show you how two more have more insight

00:01:26,840 --> 00:01:31,520
and troubleshooting a specific query and

00:01:29,000 --> 00:01:33,049
optimizing it then global performance

00:01:31,520 --> 00:01:34,729
problems and then intermittent

00:01:33,049 --> 00:01:37,790
performance problems which are the ones

00:01:34,729 --> 00:01:43,460
that are most hard to get ok so the

00:01:37,790 --> 00:01:45,500
problem so when you have a problem you

00:01:43,460 --> 00:01:47,210
need to think again and think what is

00:01:45,500 --> 00:01:49,790
the real problem i can i can give you

00:01:47,210 --> 00:01:52,040
some example of something i recently had

00:01:49,790 --> 00:01:54,290
with some friends some discussion it's

00:01:52,040 --> 00:01:59,090
not about my squirrel it's about tom cat

00:01:54,290 --> 00:02:01,369
or some web server so i had a friend

00:01:59,090 --> 00:02:06,649
than a said tom cat is behaving weird

00:02:01,369 --> 00:02:08,540
tom cat is stalling so i told him ok I

00:02:06,649 --> 00:02:10,729
can help you or I can try to help you so

00:02:08,540 --> 00:02:12,620
what what really is the problem here so

00:02:10,729 --> 00:02:15,680
he says yeah connection pulling

00:02:12,620 --> 00:02:17,570
networking something ok no problem so

00:02:15,680 --> 00:02:21,500
what is the problem I don't know I'm

00:02:17,570 --> 00:02:24,650
looking for it ok that's not really the

00:02:21,500 --> 00:02:26,120
problem so I went on in the discussion

00:02:24,650 --> 00:02:26,990
and I they've got really mad at me

00:02:26,120 --> 00:02:28,400
because I was

00:02:26,990 --> 00:02:30,580
keeping on asking so what's the real

00:02:28,400 --> 00:02:32,960
problem that you're having here so a

00:02:30,580 --> 00:02:35,660
little bit later on they said like

00:02:32,960 --> 00:02:38,810
another person said like okay networking

00:02:35,660 --> 00:02:42,110
it's probably networking so i can see

00:02:38,810 --> 00:02:45,170
eighty two cloves wait states in with

00:02:42,110 --> 00:02:46,850
Luke by looking at netstat okay so

00:02:45,170 --> 00:02:50,660
another guy came comes in and he says

00:02:46,850 --> 00:02:54,830
okay we can change the time out for the

00:02:50,660 --> 00:02:57,220
fin wait to 20 seconds instead of the

00:02:54,830 --> 00:03:00,770
default of 60 or 180 I don't know so

00:02:57,220 --> 00:03:03,230
they were just guessing and trying to

00:03:00,770 --> 00:03:04,640
optimize something or fixing some

00:03:03,230 --> 00:03:06,530
problem that they don't even know what

00:03:04,640 --> 00:03:08,960
the problem is so I kept on laughing

00:03:06,530 --> 00:03:10,970
because time wait that's like the

00:03:08,960 --> 00:03:14,030
typical thing people do is reduce that

00:03:10,970 --> 00:03:17,510
timeout but I've never seen it actually

00:03:14,030 --> 00:03:19,580
solve anything so they went on and I

00:03:17,510 --> 00:03:23,330
really kept on asking so what's the real

00:03:19,580 --> 00:03:25,310
problem here um so they said it's a

00:03:23,330 --> 00:03:28,730
problem with the Tomcat connection pool

00:03:25,310 --> 00:03:31,220
a connection stay open so I try to

00:03:28,730 --> 00:03:33,140
rephrase myself and say hey how do you

00:03:31,220 --> 00:03:35,600
know that it's tom cat what do you see

00:03:33,140 --> 00:03:38,450
so there's nothing in the error log they

00:03:35,600 --> 00:03:40,490
mentioned um well for me there is no

00:03:38,450 --> 00:03:42,740
problem then they they have no data to

00:03:40,490 --> 00:03:45,860
prove that this is the problem so after

00:03:42,740 --> 00:03:48,050
a half a day the guy ended his job and

00:03:45,860 --> 00:03:51,560
he called me in his car and and then he

00:03:48,050 --> 00:03:54,740
really said okay the login pages keep on

00:03:51,560 --> 00:03:57,950
loading so finally after like six hours

00:03:54,740 --> 00:04:00,350
we have the problem so really what is

00:03:57,950 --> 00:04:02,450
the problem that the business or the

00:04:00,350 --> 00:04:05,750
application is facing so I see that a

00:04:02,450 --> 00:04:07,700
lot when working a lot of times when

00:04:05,750 --> 00:04:10,280
actually explaining the problem they're

00:04:07,700 --> 00:04:12,680
mentioning some kind of behavior may be

00:04:10,280 --> 00:04:14,540
a cost may be the effect and most of the

00:04:12,680 --> 00:04:18,730
times it's just the effect that they

00:04:14,540 --> 00:04:21,290
think is the problem so what I want to

00:04:18,730 --> 00:04:23,660
make sure is that you really need to

00:04:21,290 --> 00:04:28,700
step back think about what it really the

00:04:23,660 --> 00:04:31,610
problem here so don't look at at some

00:04:28,700 --> 00:04:33,980
random thing don't think it will be

00:04:31,610 --> 00:04:35,630
probably be tomcat Oh in the end it

00:04:33,980 --> 00:04:37,790
actually turned out to be the database

00:04:35,630 --> 00:04:39,590
so I don't know they spend the whole day

00:04:37,790 --> 00:04:42,890
optimizing so

00:04:39,590 --> 00:04:45,140
that's kind of bad for them so don't

00:04:42,890 --> 00:04:46,850
limit yourself in where you are looking

00:04:45,140 --> 00:04:48,830
if you say that Tomcat is the problem

00:04:46,850 --> 00:04:51,410
then you're only looking at tom cat

00:04:48,830 --> 00:04:54,530
while in fact it was just slow login

00:04:51,410 --> 00:04:57,290
which could actually be anything so

00:04:54,530 --> 00:04:59,420
don't ever trust anybody that's

00:04:57,290 --> 00:05:00,650
something I learned if a customer says

00:04:59,420 --> 00:05:02,300
something or if a colleague says

00:05:00,650 --> 00:05:04,700
something don't trust them don't trust

00:05:02,300 --> 00:05:07,280
yourself don't don't trust anybody so

00:05:04,700 --> 00:05:10,580
always try to look at data try to figure

00:05:07,280 --> 00:05:13,160
out what do I see what metrics look at

00:05:10,580 --> 00:05:15,790
your instrumentation guessing is

00:05:13,160 --> 00:05:18,110
something you might be able to do but

00:05:15,790 --> 00:05:21,020
you're actually lying a little bit to

00:05:18,110 --> 00:05:24,110
yourself and you might actually cause

00:05:21,020 --> 00:05:27,700
like in this example where tom cat was

00:05:24,110 --> 00:05:33,020
not the problem a lot of waste of time

00:05:27,700 --> 00:05:35,060
so the problem sorry I had to start with

00:05:33,020 --> 00:05:37,160
that it's not really how to troubleshoot

00:05:35,060 --> 00:05:40,160
but it's the started you need to figure

00:05:37,160 --> 00:05:42,470
it out so instrumentation so we know

00:05:40,160 --> 00:05:44,630
what the problem is now the second thing

00:05:42,470 --> 00:05:46,760
is actually we should measure so we

00:05:44,630 --> 00:05:48,980
should start measuring like a boss like

00:05:46,760 --> 00:05:54,560
that woman here she actually measures

00:05:48,980 --> 00:05:59,030
stuff what is measuring so I'm not ten

00:05:54,560 --> 00:06:02,330
percent now so I hope I'm on track um so

00:05:59,030 --> 00:06:05,900
measuring instrumentation so it is

00:06:02,330 --> 00:06:07,790
actually we do measurement some quote

00:06:05,900 --> 00:06:09,740
here from Tom DeMarco I don't know who

00:06:07,790 --> 00:06:12,080
that is but he says you can't control

00:06:09,740 --> 00:06:13,880
what you can't measure so you cannot

00:06:12,080 --> 00:06:15,350
really troubleshoot anything you cannot

00:06:13,880 --> 00:06:18,500
really optimize anything if you don't

00:06:15,350 --> 00:06:21,260
have any data to look into to see if it

00:06:18,500 --> 00:06:23,510
actually solved it or not so for example

00:06:21,260 --> 00:06:25,790
with a car you have some basic

00:06:23,510 --> 00:06:28,670
information in cards how fast is it

00:06:25,790 --> 00:06:31,220
going how far is the car going how am I

00:06:28,670 --> 00:06:33,830
consume fuel do i need all or not so

00:06:31,220 --> 00:06:37,970
everything should have instrumentation

00:06:33,830 --> 00:06:41,690
so one example here so why do we need to

00:06:37,970 --> 00:06:44,930
instrument in this example and this is

00:06:41,690 --> 00:06:47,450
is it's it's not related to the example

00:06:44,930 --> 00:06:50,390
that I gave a bunker let it turn out to

00:06:47,450 --> 00:06:53,120
be the same problem Oh imagine you have

00:06:50,390 --> 00:06:56,690
but web servers and a database and

00:06:53,120 --> 00:07:00,320
case mysql and a logon takes about 15

00:06:56,690 --> 00:07:03,260
seconds well what is the problem and in

00:07:00,320 --> 00:07:06,919
most cases people will say and guess

00:07:03,260 --> 00:07:09,710
excuse me Reapers DNS yeah and chris is

00:07:06,919 --> 00:07:14,120
gay youth a DNS but he'll be wrong and

00:07:09,710 --> 00:07:15,800
sometimes it's not always right but here

00:07:14,120 --> 00:07:19,370
we always assume that my skull is the

00:07:15,800 --> 00:07:21,470
problem you know so that's a guess so

00:07:19,370 --> 00:07:25,130
why would people guess my skull is the

00:07:21,470 --> 00:07:26,780
problem um well there enough there are

00:07:25,130 --> 00:07:28,789
more than one web server so I don't see

00:07:26,780 --> 00:07:31,220
why it would be the web server so that's

00:07:28,789 --> 00:07:33,949
some examples that people would give as

00:07:31,220 --> 00:07:37,460
explanation so if it's a database and

00:07:33,949 --> 00:07:38,720
you guess it's the database it going to

00:07:37,460 --> 00:07:40,789
be probably it's probably going to be

00:07:38,720 --> 00:07:44,680
true but you're lying again you're

00:07:40,789 --> 00:07:47,960
guessing again you're not on yourself so

00:07:44,680 --> 00:07:49,520
because of that so there isn't why you

00:07:47,960 --> 00:07:51,470
would think that there are more

00:07:49,520 --> 00:07:54,020
challenges on a database than on a web

00:07:51,470 --> 00:07:57,320
server this seems more simple than a

00:07:54,020 --> 00:07:59,330
database so that's one of the reasons so

00:07:57,320 --> 00:08:01,940
you're guessing but you're using your

00:07:59,330 --> 00:08:04,130
experience you're thinking okay I had

00:08:01,940 --> 00:08:06,500
this in the past so I'll have a look

00:08:04,130 --> 00:08:10,370
there first so that's good that you

00:08:06,500 --> 00:08:14,180
guess and look at the database first but

00:08:10,370 --> 00:08:16,039
it you should try to see if your guest

00:08:14,180 --> 00:08:18,200
is actually good you should prove is

00:08:16,039 --> 00:08:26,210
that guess that I'm making actually a

00:08:18,200 --> 00:08:27,349
good one also the proving part the here

00:08:26,210 --> 00:08:30,260
it's mentioned as it's a lot more

00:08:27,349 --> 00:08:32,779
important than knowing well proving

00:08:30,260 --> 00:08:34,580
actually is kind of motivating if I if I

00:08:32,779 --> 00:08:37,669
do some troubleshooting and I guests and

00:08:34,580 --> 00:08:39,409
I solve the problem by guessing I don't

00:08:37,669 --> 00:08:41,390
feel so good you know it's much better

00:08:39,409 --> 00:08:43,580
if I have data I can see what is

00:08:41,390 --> 00:08:45,350
happening before I'm troubleshooting

00:08:43,580 --> 00:08:47,750
something I say let's change that

00:08:45,350 --> 00:08:49,130
setting or do that optimization and then

00:08:47,750 --> 00:08:52,010
it's resolved then you can actually see

00:08:49,130 --> 00:08:57,680
data where you can see that the problem

00:08:52,010 --> 00:08:59,959
is fixed I am more happy so how do we

00:08:57,680 --> 00:09:01,640
instrument or how you measure and one of

00:08:59,959 --> 00:09:04,610
the things that we can do is we should

00:09:01,640 --> 00:09:06,089
use a sequence diagram you see the flow

00:09:04,610 --> 00:09:07,139
of information in

00:09:06,089 --> 00:09:11,279
each of the components of my

00:09:07,139 --> 00:09:13,410
applications so here is an example the

00:09:11,279 --> 00:09:17,220
logging example it the browser does a

00:09:13,410 --> 00:09:19,379
submit to the web server sometimes some

00:09:17,220 --> 00:09:23,069
cpu is spent here or some actions are

00:09:19,379 --> 00:09:25,589
done here then the user is checked if it

00:09:23,069 --> 00:09:28,499
exists on the database result has

00:09:25,589 --> 00:09:31,139
returned then what happens is the last

00:09:28,499 --> 00:09:32,670
login date is being updated and you can

00:09:31,139 --> 00:09:34,800
see this is the amount of time that it

00:09:32,670 --> 00:09:37,230
takes is that updating the last login'

00:09:34,800 --> 00:09:39,959
they takes the most time so if you if

00:09:37,230 --> 00:09:43,410
you have information like this in your

00:09:39,959 --> 00:09:45,959
application if you can make sequence

00:09:43,410 --> 00:09:49,139
diagrams like this or get similar data

00:09:45,959 --> 00:09:52,740
out of it you actually have more data to

00:09:49,139 --> 00:09:56,160
see ok last leg and take date up dating

00:09:52,740 --> 00:09:58,559
that field it takes most time ok so why

00:09:56,160 --> 00:10:01,290
are we spending a lot of time on that so

00:09:58,559 --> 00:10:02,490
we already narrowed down the problem we

00:10:01,290 --> 00:10:05,670
know we don't need to look at the web

00:10:02,490 --> 00:10:12,089
server it is the database somehow ok so

00:10:05,670 --> 00:10:13,709
let's do some analysis so here this is

00:10:12,089 --> 00:10:16,350
the update that happens we update the

00:10:13,709 --> 00:10:19,439
users table we set the last day to now

00:10:16,350 --> 00:10:22,139
we're primary key so the user ID is an

00:10:19,439 --> 00:10:23,730
ok so it's a pretty simple schema so

00:10:22,139 --> 00:10:26,490
there's a lot of columns in here and

00:10:23,730 --> 00:10:31,170
then the end one is last login date item

00:10:26,490 --> 00:10:33,509
a day time so what do we do to

00:10:31,170 --> 00:10:35,850
troubleshoot we can when that problem is

00:10:33,509 --> 00:10:37,589
happening the slow login is happening we

00:10:35,850 --> 00:10:40,079
can actually do show process list on the

00:10:37,589 --> 00:10:42,149
database so what we see here is and this

00:10:40,079 --> 00:10:43,740
is a need a very simple example we we

00:10:42,149 --> 00:10:46,199
found that something is happening with

00:10:43,740 --> 00:10:47,970
the updates and there one of them is

00:10:46,199 --> 00:10:51,209
updating and all the other ones are

00:10:47,970 --> 00:10:55,889
locked ok so you know there's something

00:10:51,209 --> 00:10:57,809
wrong with up with the update so maybe

00:10:55,889 --> 00:10:59,399
if we look at up time so if you look at

00:10:57,809 --> 00:11:01,529
up time you see the load average you can

00:10:59,399 --> 00:11:04,589
see it really doesn't come with load

00:11:01,529 --> 00:11:07,620
this problem so if you look at CPU in

00:11:04,589 --> 00:11:09,600
that case it doesn't really give you any

00:11:07,620 --> 00:11:12,269
clue if the database is a problem or not

00:11:09,600 --> 00:11:15,209
so it is ok and it is necessary to

00:11:12,269 --> 00:11:17,189
actually monitor CPU memory or usage and

00:11:15,209 --> 00:11:18,720
everything that's really helpful but in

00:11:17,189 --> 00:11:21,569
this case it

00:11:18,720 --> 00:11:23,730
say this is the prop the database is the

00:11:21,569 --> 00:11:25,560
problem here even if you look at the

00:11:23,730 --> 00:11:28,529
slow queries you can see that slow

00:11:25,560 --> 00:11:31,170
queries is still tree so value is not

00:11:28,529 --> 00:11:33,779
increasing even though the long query

00:11:31,170 --> 00:11:35,339
time so the time it has to take a query

00:11:33,779 --> 00:11:38,279
before it is written to the slow query

00:11:35,339 --> 00:11:40,439
log is set to one second even if they

00:11:38,279 --> 00:11:42,569
take longer they are not written to the

00:11:40,439 --> 00:11:45,029
slow query log reason for this is that

00:11:42,569 --> 00:11:47,610
lock time does not count towards that

00:11:45,029 --> 00:11:51,509
long query time so it is not locked to

00:11:47,610 --> 00:11:55,170
the slow query log so some problems come

00:11:51,509 --> 00:11:59,550
without load so you need to look into

00:11:55,170 --> 00:12:02,730
have that application data so guessing

00:11:59,550 --> 00:12:05,639
again try to prove your guess don't

00:12:02,730 --> 00:12:07,860
trust it try to find out how do i

00:12:05,639 --> 00:12:14,670
normally troubleshoot so guessing is

00:12:07,860 --> 00:12:18,389
bypassing but try to really prove it

00:12:14,670 --> 00:12:21,060
with data so here are some concepts

00:12:18,389 --> 00:12:23,639
about load utilization scalability so

00:12:21,060 --> 00:12:27,000
load is how much work is actually coming

00:12:23,639 --> 00:12:29,910
in how big is the backlog of my database

00:12:27,000 --> 00:12:34,610
for example so utilization is how much

00:12:29,910 --> 00:12:37,559
of the resources are used on my system

00:12:34,610 --> 00:12:39,689
scalability is what is the relationship

00:12:37,559 --> 00:12:43,050
between the utilization and our our

00:12:39,689 --> 00:12:44,910
means response time here throughput and

00:12:43,050 --> 00:12:48,660
that's what a lot of people think about

00:12:44,910 --> 00:12:52,439
and I see a typo in here how many tasks

00:12:48,660 --> 00:12:55,670
can be done per unit of time so that's X

00:12:52,439 --> 00:12:58,050
trooper many people look at troopers a

00:12:55,670 --> 00:13:01,980
performance indicator but that's not

00:12:58,050 --> 00:13:04,680
true concurrency how many tasks can we

00:13:01,980 --> 00:13:09,750
do at once i did a find replace of

00:13:04,680 --> 00:13:13,529
something so sorry capacity is how big

00:13:09,750 --> 00:13:16,019
can we set the true put without making

00:13:13,529 --> 00:13:19,350
other things are unacceptable like examp

00:13:16,019 --> 00:13:21,540
response time so the more true put we we

00:13:19,350 --> 00:13:24,089
send the more data or the more load we

00:13:21,540 --> 00:13:25,829
send to it the higher the response time

00:13:24,089 --> 00:13:29,130
will become so there's a balance that

00:13:25,829 --> 00:13:31,800
you need to find here so important is

00:13:29,130 --> 00:13:36,330
response time is the time it takes to do

00:13:31,800 --> 00:13:38,670
task true put is how many tasks can I do

00:13:36,330 --> 00:13:41,430
it at a certain in a certain amount of

00:13:38,670 --> 00:13:43,920
time so true put is not equals to the

00:13:41,430 --> 00:13:46,080
performance of the system so it is

00:13:43,920 --> 00:13:48,360
actually a relationship between all of

00:13:46,080 --> 00:13:51,839
them trooper utilization response time

00:13:48,360 --> 00:13:55,170
and capacity note that response time

00:13:51,839 --> 00:13:58,140
also includes Q so King may and will

00:13:55,170 --> 00:14:00,390
occur in the database so the service

00:13:58,140 --> 00:14:07,620
time and the wait time is the actual

00:14:00,390 --> 00:14:10,050
response time of of the task so what can

00:14:07,620 --> 00:14:12,959
we do in the database to actually

00:14:10,050 --> 00:14:16,320
measure and have good instrumentation so

00:14:12,959 --> 00:14:18,000
we can look at the error log this is

00:14:16,320 --> 00:14:20,730
just for errors it's not really

00:14:18,000 --> 00:14:23,519
measuring any load or metrics but it

00:14:20,730 --> 00:14:25,230
sometimes gives you an indication global

00:14:23,519 --> 00:14:27,510
status is a really interesting one and

00:14:25,230 --> 00:14:30,120
I'll go a little bit more in detail and

00:14:27,510 --> 00:14:32,610
show you some examples later on so

00:14:30,120 --> 00:14:35,130
engine I know DB status has some metrics

00:14:32,610 --> 00:14:37,339
that are not in show global status so

00:14:35,130 --> 00:14:39,600
you also need to include that one

00:14:37,339 --> 00:14:43,050
operating system metrics hardware

00:14:39,600 --> 00:14:45,930
metrics a load I owe you switch all

00:14:43,050 --> 00:14:47,970
those things you should measure and also

00:14:45,930 --> 00:14:49,529
the one like in the sequence diagram you

00:14:47,970 --> 00:14:52,320
should measure your response time in

00:14:49,529 --> 00:14:53,820
your applique well how many time was

00:14:52,320 --> 00:14:56,940
spending my application how many how

00:14:53,820 --> 00:14:58,800
much time was spending my web server one

00:14:56,940 --> 00:15:02,060
example of that performance in your

00:14:58,800 --> 00:15:05,399
application is an example here of a

00:15:02,060 --> 00:15:08,220
table which contains some information

00:15:05,399 --> 00:15:12,630
it's so it's a website site boardreader

00:15:08,220 --> 00:15:14,579
comp so we have some page here that was

00:15:12,630 --> 00:15:17,370
the page that was requested so you can

00:15:14,579 --> 00:15:19,290
see this is the wall clock time it's 242

00:15:17,370 --> 00:15:21,570
milliseconds and you can see where the

00:15:19,290 --> 00:15:24,630
time was spent in my squirrel it's only

00:15:21,570 --> 00:15:29,480
four milliseconds sphinx so full text

00:15:24,630 --> 00:15:32,459
search it was 83 milliseconds so it see

00:15:29,480 --> 00:15:34,470
based on that where I need to do my

00:15:32,459 --> 00:15:38,550
optimization if the response time is bad

00:15:34,470 --> 00:15:42,480
for a certain page or a certain type of

00:15:38,550 --> 00:15:44,370
pages so there's a page type here search

00:15:42,480 --> 00:15:45,170
so we can easily get some statistics out

00:15:44,370 --> 00:15:47,029
of it

00:15:45,170 --> 00:15:49,820
so you have a cap queries how much time

00:15:47,029 --> 00:15:51,620
my SQL query was sent the amount of

00:15:49,820 --> 00:15:53,600
queries could also be an indicator of

00:15:51,620 --> 00:15:55,850
increased response time because it's

00:15:53,600 --> 00:16:01,940
always sending data queries to the

00:15:55,850 --> 00:16:07,399
database this example or instrumentation

00:16:01,940 --> 00:16:09,350
for PHP is a an example that can used to

00:16:07,399 --> 00:16:12,769
get the same data so it's an open source

00:16:09,350 --> 00:16:14,360
project product for PHP you can just put

00:16:12,769 --> 00:16:16,790
the sum you have to change your

00:16:14,360 --> 00:16:18,920
application to use the class here but

00:16:16,790 --> 00:16:20,870
you can easily transform this so what

00:16:18,920 --> 00:16:23,720
happens in this case it will write

00:16:20,870 --> 00:16:26,769
patchy logs special apache logs who

00:16:23,720 --> 00:16:29,089
could but that contain that information

00:16:26,769 --> 00:16:30,709
as mentioned here and then you can have

00:16:29,089 --> 00:16:33,769
some cron jobs that actually load the

00:16:30,709 --> 00:16:35,480
data into the database if you would send

00:16:33,769 --> 00:16:37,810
it to the database immediately you're

00:16:35,480 --> 00:16:42,410
creating a bottleneck on your own here

00:16:37,810 --> 00:16:44,360
so trending is also very important if a

00:16:42,410 --> 00:16:45,829
problem occurs it is the first thing you

00:16:44,360 --> 00:16:47,810
should do is look at your graphs and

00:16:45,829 --> 00:16:50,750
find out what's the difference is there

00:16:47,810 --> 00:16:53,420
any behavior difference compared to what

00:16:50,750 --> 00:16:55,399
before that the problem happened and one

00:16:53,420 --> 00:16:57,829
example is the cacti graphs it's part of

00:16:55,399 --> 00:17:00,110
the Kona monitoring plugins so you can

00:16:57,829 --> 00:17:05,689
just freely download it there are many

00:17:00,110 --> 00:17:07,309
variants on this but those graphs for

00:17:05,689 --> 00:17:09,770
cacti contain a lot of my squirrel

00:17:07,309 --> 00:17:11,030
graphs I think it's about 100 or

00:17:09,770 --> 00:17:12,679
something like that maybe a little bit

00:17:11,030 --> 00:17:15,500
less but there's a lot of them a lot of

00:17:12,679 --> 00:17:19,549
internal MySQL counters are being

00:17:15,500 --> 00:17:21,069
graphed here so there are some variants

00:17:19,549 --> 00:17:23,959
with the similar graphs from Union

00:17:21,069 --> 00:17:30,410
ganglia whatever metering solution you

00:17:23,959 --> 00:17:33,890
have excuse me graphite oh okay I'm not

00:17:30,410 --> 00:17:35,990
into that monitoring thing yet another

00:17:33,890 --> 00:17:40,970
thing you can use so the example of that

00:17:35,990 --> 00:17:43,850
I had here with this is that it's not

00:17:40,970 --> 00:17:45,590
open source but New Relic is an APM that

00:17:43,850 --> 00:17:48,290
actually hooks up to your application

00:17:45,590 --> 00:17:49,850
that supports PHP Java other languages

00:17:48,290 --> 00:17:52,130
it just hooks up and it immediately

00:17:49,850 --> 00:17:54,080
gives it sends data to the New Relic

00:17:52,130 --> 00:17:57,200
service and you get data information

00:17:54,080 --> 00:17:58,450
about response times about your

00:17:57,200 --> 00:18:00,900
application similar

00:17:58,450 --> 00:18:03,910
to the ones mentioned in this table and

00:18:00,900 --> 00:18:05,020
in many cases applications write their

00:18:03,910 --> 00:18:11,230
own implementation of that

00:18:05,020 --> 00:18:16,270
instrumentation ok so now about really

00:18:11,230 --> 00:18:18,970
troubleshooting some problems so for a

00:18:16,270 --> 00:18:22,540
slow query these are things that I would

00:18:18,970 --> 00:18:24,970
recommend to do people know explain I

00:18:22,540 --> 00:18:27,130
guess I hope if you're optimizing a

00:18:24,970 --> 00:18:30,430
query you do explain of the Select and

00:18:27,130 --> 00:18:32,560
you see is it optimal or not its limit

00:18:30,430 --> 00:18:35,320
it's it's limited it shows you good

00:18:32,560 --> 00:18:38,560
information but it there's more that you

00:18:35,320 --> 00:18:40,450
can use to actually have more yet have

00:18:38,560 --> 00:18:43,600
more data out with more information out

00:18:40,450 --> 00:18:46,150
of it so we have show session status

00:18:43,600 --> 00:18:50,920
show profiles and some extended

00:18:46,150 --> 00:18:54,340
statistics I'll show you briefly so this

00:18:50,920 --> 00:18:57,970
is select so we explain it and this is

00:18:54,340 --> 00:19:00,310
the explain output we get so what we can

00:18:57,970 --> 00:19:03,880
see is that table cast info as used

00:19:00,310 --> 00:19:07,090
first key person ID is used and it will

00:19:03,880 --> 00:19:10,540
approximately read eight rows it will

00:19:07,090 --> 00:19:13,990
create temporary file file table and use

00:19:10,540 --> 00:19:16,000
faster so sorting has to happen the

00:19:13,990 --> 00:19:19,090
second thing so for every matching grow

00:19:16,000 --> 00:19:21,970
here it will actually do it join with

00:19:19,090 --> 00:19:24,520
the title and look up data in the title

00:19:21,970 --> 00:19:28,120
table and it will also use the primary

00:19:24,520 --> 00:19:30,880
key here so this see this is an estimate

00:19:28,120 --> 00:19:33,970
rose so this is not really the amount of

00:19:30,880 --> 00:19:37,960
row that it will read so you can say

00:19:33,970 --> 00:19:39,610
that eight times one is the amount of

00:19:37,960 --> 00:19:41,710
roads that it would read but in fact

00:19:39,610 --> 00:19:44,260
it's not really true and it in this case

00:19:41,710 --> 00:19:46,990
I'm actually giving a a good example

00:19:44,260 --> 00:19:49,690
because it's a bug in my squirrel if you

00:19:46,990 --> 00:19:51,430
looked at the session status you

00:19:49,690 --> 00:19:54,630
actually can see that it does much more

00:19:51,430 --> 00:19:56,800
than that so what do you do to

00:19:54,630 --> 00:20:00,190
information so you flush the session

00:19:56,800 --> 00:20:03,100
status so all your session counters are

00:20:00,190 --> 00:20:04,930
being set to zero you run that query not

00:20:03,100 --> 00:20:08,580
the explain so you run the Select and

00:20:04,930 --> 00:20:11,789
then you do so show status like a che

00:20:08,580 --> 00:20:13,080
you can show more there's like a

00:20:11,789 --> 00:20:15,720
more but i'll show you the handler

00:20:13,080 --> 00:20:18,359
statistics so the handler statistics is

00:20:15,720 --> 00:20:20,700
actually the handler is an api between

00:20:18,359 --> 00:20:22,529
the mysql core and the storage engine so

00:20:20,700 --> 00:20:24,269
f time my squirrel wants to read the row

00:20:22,529 --> 00:20:26,399
it will go through that handler

00:20:24,269 --> 00:20:29,759
interface and it will ask give me that

00:20:26,399 --> 00:20:31,440
row or give me do that for me so you can

00:20:29,759 --> 00:20:34,139
have counters there let's see how much

00:20:31,440 --> 00:20:37,470
times a row was requested or an index

00:20:34,139 --> 00:20:39,600
read was requested so what we see here

00:20:37,470 --> 00:20:42,029
is that one time it did handler read

00:20:39,600 --> 00:20:44,759
first so this means the number of times

00:20:42,029 --> 00:20:47,099
the first entry in an index was red so

00:20:44,759 --> 00:20:51,659
it says go to the beginning of the index

00:20:47,099 --> 00:20:55,169
and give me the first entry a handler

00:20:51,659 --> 00:20:57,389
read next I'll show you is about 14

00:20:55,169 --> 00:21:00,389
million so this means read the next

00:20:57,389 --> 00:21:03,690
index entry so this happened 14 million

00:21:00,389 --> 00:21:08,570
times what you can also see is handle

00:21:03,690 --> 00:21:11,609
read key is 13 minute so 13 million

00:21:08,570 --> 00:21:15,029
which means read a certain index entry

00:21:11,609 --> 00:21:17,210
for me so 13 million times and what we

00:21:15,029 --> 00:21:23,159
have here is handle read are in the next

00:21:17,210 --> 00:21:27,690
which means it's 24 million it is read

00:21:23,159 --> 00:21:31,499
the next row so not an index entry so

00:21:27,690 --> 00:21:34,799
what we see here is that it does not do

00:21:31,499 --> 00:21:37,080
what we saw here in the explain it does

00:21:34,799 --> 00:21:40,460
much more so it's just a small bug in

00:21:37,080 --> 00:21:42,749
the optimizer that gave the wrong output

00:21:40,460 --> 00:21:47,450
it doesn't usually happen but it can

00:21:42,749 --> 00:21:49,769
happen so this will give you that inside

00:21:47,450 --> 00:21:52,169
another interesting fact is that we have

00:21:49,769 --> 00:21:54,299
handler right here so it's also to duck

00:21:52,169 --> 00:21:56,700
4 million so it seems to match with this

00:21:54,299 --> 00:21:58,580
so what happens is that that temporary

00:21:56,700 --> 00:22:01,799
table that was actually mentioned here

00:21:58,580 --> 00:22:04,619
we know that when we do the Select we

00:22:01,799 --> 00:22:06,570
write to the four million rows so this

00:22:04,619 --> 00:22:10,200
means the temporary table was to dot 4

00:22:06,570 --> 00:22:16,109
million and the temporary table was then

00:22:10,200 --> 00:22:18,330
used for the group I so everything was

00:22:16,109 --> 00:22:19,649
red from the temporary table so here you

00:22:18,330 --> 00:22:23,190
can try to understand a little bit more

00:22:19,649 --> 00:22:24,240
what is what did my Scully do so explain

00:22:23,190 --> 00:22:26,490
is what

00:22:24,240 --> 00:22:28,620
would my scale do or what will why

00:22:26,490 --> 00:22:31,850
squirrel do but the session status

00:22:28,620 --> 00:22:34,620
showed you what it actually did

00:22:31,850 --> 00:22:36,900
profiling is the next one this is how

00:22:34,620 --> 00:22:40,320
you do it you set profile includes one

00:22:36,900 --> 00:22:42,300
and then every query you run profiling

00:22:40,320 --> 00:22:44,790
information will be stored so when you

00:22:42,300 --> 00:22:48,600
type show profiles you see by default

00:22:44,790 --> 00:22:51,150
the last 15 queries so in this case it

00:22:48,600 --> 00:22:53,700
was dis elect and it took 200 seconds

00:22:51,150 --> 00:22:56,190
what you can do then is type show

00:22:53,700 --> 00:22:58,830
profile for query one so you see query

00:22:56,190 --> 00:23:01,610
ID one that's the number you want and

00:22:58,830 --> 00:23:06,870
then you see the profiling information

00:23:01,610 --> 00:23:08,520
so I don't commonly use it some of my

00:23:06,870 --> 00:23:10,559
colleagues do but I don't find it always

00:23:08,520 --> 00:23:13,320
that interesting it's only in some cases

00:23:10,559 --> 00:23:15,480
that it is interesting but here you can

00:23:13,320 --> 00:23:17,520
see where the where in which state my

00:23:15,480 --> 00:23:20,400
squirrel was and how much time it took

00:23:17,520 --> 00:23:24,210
so we can see for 113 seconds it was

00:23:20,400 --> 00:23:26,490
copying to a temporary table we were

00:23:24,210 --> 00:23:29,940
copying a temporary table on this disc

00:23:26,490 --> 00:23:33,679
table was created the other numbers are

00:23:29,940 --> 00:23:37,890
really low and it important to know is

00:23:33,679 --> 00:23:42,059
not every state means what it says so

00:23:37,890 --> 00:23:43,770
freeing items or might actually what

00:23:42,059 --> 00:23:45,809
what does freeing items mean what will

00:23:43,770 --> 00:23:47,670
you do if that is high it's very hard to

00:23:45,809 --> 00:23:49,620
know so it doesn't really you the

00:23:47,670 --> 00:23:52,140
solution here Oh freeing up time that's

00:23:49,620 --> 00:23:54,510
how I will say its high so while set

00:23:52,140 --> 00:23:56,280
some setting so it will be lower no so

00:23:54,510 --> 00:23:59,190
it's it's you really need to look into

00:23:56,280 --> 00:24:01,290
the code to be exactly sure so I have to

00:23:59,190 --> 00:24:06,330
go to develop and then ask day they know

00:24:01,290 --> 00:24:10,110
better so profiling so might be

00:24:06,330 --> 00:24:12,330
interesting in some cases the next one

00:24:10,110 --> 00:24:15,030
is this low log statistics so this is

00:24:12,330 --> 00:24:17,910
not part of a normal my school server or

00:24:15,030 --> 00:24:20,429
the my spell enterpriser community but

00:24:17,910 --> 00:24:26,130
it is part of pro kona server and a

00:24:20,429 --> 00:24:28,890
partly part of also part of maria DB we

00:24:26,130 --> 00:24:32,400
can set the long query time to 0 which

00:24:28,890 --> 00:24:34,679
means i will log every query to the slow

00:24:32,400 --> 00:24:37,260
log and we can set the log slow

00:24:34,679 --> 00:24:37,810
verbosity to full and by default you

00:24:37,260 --> 00:24:40,840
would only

00:24:37,810 --> 00:24:43,270
this stop information in the slow log

00:24:40,840 --> 00:24:45,070
with standard my scroll but with Percona

00:24:43,270 --> 00:24:47,220
server and maria DB you actually get a

00:24:45,070 --> 00:24:49,600
lot more information so it is

00:24:47,220 --> 00:24:51,820
information that you would get out of

00:24:49,600 --> 00:24:54,850
the session status but it is logged to a

00:24:51,820 --> 00:24:56,680
file now so you can actually get some

00:24:54,850 --> 00:24:59,440
statistics out of it so you can see how

00:24:56,680 --> 00:25:03,430
many read up patients it did if there

00:24:59,440 --> 00:25:06,400
was any locking and yeah transaction

00:25:03,430 --> 00:25:08,940
locking temporary table how big the

00:25:06,400 --> 00:25:13,120
temporary table all that information

00:25:08,940 --> 00:25:14,470
like this here is stored in there you

00:25:13,120 --> 00:25:17,320
can also include the profiling

00:25:14,470 --> 00:25:18,970
information if you enabled it in the

00:25:17,320 --> 00:25:20,410
slow lock slow verbosity so it's

00:25:18,970 --> 00:25:26,230
originally created by magic I guess

00:25:20,410 --> 00:25:29,250
right you made this okay kudos okay so

00:25:26,230 --> 00:25:33,100
that was an individual query now to

00:25:29,250 --> 00:25:35,530
global performance problems I'll give

00:25:33,100 --> 00:25:37,540
you some example ninety-five percent of

00:25:35,530 --> 00:25:39,370
the response time went from 40

00:25:37,540 --> 00:25:43,120
milliseconds to 200 milliseconds that's

00:25:39,370 --> 00:25:45,940
a problem so in most cases response time

00:25:43,120 --> 00:25:48,370
is is the most important thing in most

00:25:45,940 --> 00:25:52,840
applications if it's a website you want

00:25:48,370 --> 00:25:55,270
it to respond fast I don't see a spike

00:25:52,840 --> 00:25:57,130
and a graph that gives you a text

00:25:55,270 --> 00:25:59,470
message at one a.m. in the morning I

00:25:57,130 --> 00:26:01,150
don't see that as a problem it might

00:25:59,470 --> 00:26:04,450
happen but as long as response time is

00:26:01,150 --> 00:26:06,640
good and no errors are happening I guess

00:26:04,450 --> 00:26:09,250
people would be fine you know and I

00:26:06,640 --> 00:26:11,230
don't need to wake up so i worked at

00:26:09,250 --> 00:26:13,450
some companies as a system engineer and

00:26:11,230 --> 00:26:15,820
hat on call service and if you receive

00:26:13,450 --> 00:26:18,750
300 text messages a night you you don't

00:26:15,820 --> 00:26:21,790
respond to it anymore so that happens

00:26:18,750 --> 00:26:24,160
okay so when you have global performance

00:26:21,790 --> 00:26:27,160
problems so that instrumentation becomes

00:26:24,160 --> 00:26:28,720
important now and first thing i

00:26:27,160 --> 00:26:32,350
mentioned it what you do is you go to

00:26:28,720 --> 00:26:35,260
trending like the graphs and see what is

00:26:32,350 --> 00:26:37,450
going on if you don't have those graphs

00:26:35,260 --> 00:26:40,110
or you need more granular output more

00:26:37,450 --> 00:26:43,180
more detail there's some other

00:26:40,110 --> 00:26:44,920
statistics that you can collect and i'll

00:26:43,180 --> 00:26:49,170
show you some examples some tools that

00:26:44,920 --> 00:26:51,670
you can use to get that data out of it

00:26:49,170 --> 00:26:53,890
so these are some of the tools you

00:26:51,670 --> 00:26:55,420
most people probably know iostat and

00:26:53,890 --> 00:26:58,300
peace that vmstat it shows uio

00:26:55,420 --> 00:27:01,900
statistics CPU statistics and so on

00:26:58,300 --> 00:27:04,570
these are part of Prachanda toolkit and

00:27:01,900 --> 00:27:07,330
i'll show you some of them how to use

00:27:04,570 --> 00:27:09,760
them and what they actually do but first

00:27:07,330 --> 00:27:13,330
look at the graphs I'll quickly go over

00:27:09,760 --> 00:27:15,610
it so what we have here is we've got

00:27:13,330 --> 00:27:17,620
connections what do we see what happens

00:27:15,610 --> 00:27:19,810
you can see connections as it has a

00:27:17,620 --> 00:27:22,750
small spike here does that mean anything

00:27:19,810 --> 00:27:26,170
i don't know i mean look at it try to

00:27:22,750 --> 00:27:28,240
correlate it to your problem replication

00:27:26,170 --> 00:27:29,950
you can see slaves running but it is

00:27:28,240 --> 00:27:34,120
lagging at sometimes actually

00:27:29,950 --> 00:27:35,470
permanently temporary objects so these

00:27:34,120 --> 00:27:37,540
are some of the graphs that are

00:27:35,470 --> 00:27:39,580
available in most monitoring solutions

00:27:37,540 --> 00:27:41,530
here we see that the database versus

00:27:39,580 --> 00:27:44,980
restarted so the buffer pool was empty

00:27:41,530 --> 00:27:46,840
and it was filled again so check

00:27:44,980 --> 00:27:49,690
pointing I'll not go into detail here

00:27:46,840 --> 00:27:51,070
it's not really showing a problem this

00:27:49,690 --> 00:27:54,010
is part of perc on the server and it

00:27:51,070 --> 00:27:55,270
shows you the response time I personally

00:27:54,010 --> 00:27:58,870
think that this is an interesting one

00:27:55,270 --> 00:28:02,620
because this is account this is the

00:27:58,870 --> 00:28:05,440
total sum of the response times from

00:28:02,620 --> 00:28:07,990
queries that took one micro second a one

00:28:05,440 --> 00:28:09,850
to one millisecond one millisecond to 10

00:28:07,990 --> 00:28:12,190
milliseconds 10 milliseconds to 100

00:28:09,850 --> 00:28:15,160
milliseconds 102nd to a second so you

00:28:12,190 --> 00:28:17,260
can see how the response time is on

00:28:15,160 --> 00:28:19,540
average for my queries and if it's a bad

00:28:17,260 --> 00:28:21,010
graph it's a bad example but if you look

00:28:19,540 --> 00:28:23,890
at over time you might see that

00:28:21,010 --> 00:28:27,580
everything shifts down so this means i'm

00:28:23,890 --> 00:28:30,130
sending may be more true put so my

00:28:27,580 --> 00:28:33,580
database is becoming slower so this

00:28:30,130 --> 00:28:35,770
graph might show that this is the count

00:28:33,580 --> 00:28:39,820
this is the amount of queries of a

00:28:35,770 --> 00:28:43,690
certain time so you can see that it was

00:28:39,820 --> 00:28:47,080
a spike here in green or orange so this

00:28:43,690 --> 00:28:49,750
is here so it's 10 to 100 milliseconds

00:28:47,080 --> 00:28:54,120
at 100 milliseconds to a second for

00:28:49,750 --> 00:28:59,559
example anyway

00:28:54,120 --> 00:29:03,700
what's okay PT mixed um so PT max did

00:28:59,559 --> 00:29:06,340
actually show ubel status but it it

00:29:03,700 --> 00:29:09,540
takes it from my school admin X so that

00:29:06,340 --> 00:29:13,480
the just displays show global status

00:29:09,540 --> 00:29:16,540
chose it every 10 seconds four three

00:29:13,480 --> 00:29:18,850
times so what do we have here is have

00:29:16,540 --> 00:29:20,860
all those statistics and PT max will

00:29:18,850 --> 00:29:22,840
actually arrange it in columns and it

00:29:20,860 --> 00:29:24,940
will show you the absolute value of the

00:29:22,840 --> 00:29:27,460
first time it was sure and then the

00:29:24,940 --> 00:29:30,010
difference the next time it was taken 10

00:29:27,460 --> 00:29:32,380
seconds later so here we see what is

00:29:30,010 --> 00:29:39,280
actually going on in my database I can

00:29:32,380 --> 00:29:42,850
see in 10 seconds I had 1518 inserts 10

00:29:39,280 --> 00:29:44,470
seconds later was like 3200 so he had

00:29:42,850 --> 00:29:46,480
when you have some performance problems

00:29:44,470 --> 00:29:49,690
you can look at all those things and try

00:29:46,480 --> 00:29:51,040
to understand what is going on and how

00:29:49,690 --> 00:29:54,700
is it different when the problem does

00:29:51,040 --> 00:29:58,630
not happen so the same happen here with

00:29:54,700 --> 00:30:03,970
the handler statistics they are very low

00:29:58,630 --> 00:30:07,030
for 10 seconds this just means like 3492

00:30:03,970 --> 00:30:09,250
times a certain key was read so in a

00:30:07,030 --> 00:30:12,850
certain index entry was red let's really

00:30:09,250 --> 00:30:15,970
really know so this was a mainly an idle

00:30:12,850 --> 00:30:19,080
server so you've got more information

00:30:15,970 --> 00:30:21,940
another example query cache statistics

00:30:19,080 --> 00:30:24,510
threat and then you can see the uptime

00:30:21,940 --> 00:30:27,640
is increasing seconds at each time so

00:30:24,510 --> 00:30:29,230
just to show so there's much more

00:30:27,640 --> 00:30:32,800
everything from show global variables

00:30:29,230 --> 00:30:35,080
and there so it looks at current

00:30:32,800 --> 00:30:36,730
behavior of the database and it will

00:30:35,080 --> 00:30:38,740
tell you give you some information or

00:30:36,730 --> 00:30:41,380
might give you some information maybe I

00:30:38,740 --> 00:30:44,230
need to do query optimization because I

00:30:41,380 --> 00:30:47,140
do a lot of sorting a handler read and

00:30:44,230 --> 00:30:49,840
the next is big so I need to go do query

00:30:47,140 --> 00:30:51,160
optimization I do a lot of ten tables so

00:30:49,840 --> 00:30:53,650
I need to figure out trying to figure

00:30:51,160 --> 00:30:56,559
out how much temp tables am i creating

00:30:53,650 --> 00:30:59,260
here maybe I know DB is flushing too

00:30:56,559 --> 00:31:03,940
much causing everything to stall or slow

00:30:59,260 --> 00:31:06,880
down so PT maxed I've seen some tools

00:31:03,940 --> 00:31:10,950
that just look at show global variables

00:31:06,880 --> 00:31:14,740
show global status and give you

00:31:10,950 --> 00:31:16,840
optimizations it says like okay handler

00:31:14,740 --> 00:31:21,730
I read are in the next over the last ten

00:31:16,840 --> 00:31:23,410
months so / 10 months is very big so I

00:31:21,730 --> 00:31:27,070
would recommend to change this setting

00:31:23,410 --> 00:31:28,480
to this it is not a good indication

00:31:27,070 --> 00:31:30,280
because it stretched out since the

00:31:28,480 --> 00:31:32,200
uptime of the server so that's why

00:31:30,280 --> 00:31:34,390
looking at a certain time interval like

00:31:32,200 --> 00:31:36,700
here is much to see what is actually

00:31:34,390 --> 00:31:41,500
going on now what is what is what is

00:31:36,700 --> 00:31:45,190
happening now next thing disk subsystem

00:31:41,500 --> 00:31:48,070
so most people know I ostad and it gives

00:31:45,190 --> 00:31:49,870
you I Oh statistics so tis the map of

00:31:48,070 --> 00:31:52,540
reads down amount of rights that are

00:31:49,870 --> 00:31:58,390
happening on the devices so here we see

00:31:52,540 --> 00:32:00,850
338 writes per second important

00:31:58,390 --> 00:32:03,070
information that I think is very

00:32:00,850 --> 00:32:05,920
important is the average weight and the

00:32:03,070 --> 00:32:08,140
service time so the actual response time

00:32:05,920 --> 00:32:10,600
or the average response time of reads

00:32:08,140 --> 00:32:14,260
and writes is the combination or the

00:32:10,600 --> 00:32:17,200
seller 420 plus two milliseconds so 422

00:32:14,260 --> 00:32:19,390
milliseconds is the average IO request

00:32:17,200 --> 00:32:22,210
that it the average length of an i/o

00:32:19,390 --> 00:32:25,780
request so that's a lot that's really

00:32:22,210 --> 00:32:29,320
slow ideally you want it to be much much

00:32:25,780 --> 00:32:32,230
lower utilization is at one-hundred

00:32:29,320 --> 00:32:35,890
percent here and I'm very important to

00:32:32,230 --> 00:32:38,410
know here this is just how many and how

00:32:35,890 --> 00:32:42,910
many percent of the time was there all

00:32:38,410 --> 00:32:45,210
at least what I request so most database

00:32:42,910 --> 00:32:48,040
have a disk system with more than one

00:32:45,210 --> 00:32:50,410
spindle or maybe they have an SSD or

00:32:48,040 --> 00:32:52,930
they have a rate then or whatever there

00:32:50,410 --> 00:32:55,090
is a sand beneath so this does not show

00:32:52,930 --> 00:32:58,420
that your this is saturated this just

00:32:55,090 --> 00:33:00,790
means that at any time during that

00:32:58,420 --> 00:33:03,820
calculation there was an IO Air crest

00:33:00,790 --> 00:33:08,140
busy it doesn't show you how much

00:33:03,820 --> 00:33:11,700
requests are going so don't focus too

00:33:08,140 --> 00:33:15,130
much on utilization so response time

00:33:11,700 --> 00:33:18,940
plus service time so the problem here in

00:33:15,130 --> 00:33:21,110
this current iOS that output is that it

00:33:18,940 --> 00:33:23,179
shows you the response time for

00:33:21,110 --> 00:33:25,520
some reads combined so it doesn't show

00:33:23,179 --> 00:33:28,370
you how fast were my rights and reads

00:33:25,520 --> 00:33:30,650
and one of the tools that you can use is

00:33:28,370 --> 00:33:38,330
PT disc cuts and it shows you the same

00:33:30,650 --> 00:33:40,929
information it just proc / and it shows

00:33:38,330 --> 00:33:45,830
you this information and I have it over

00:33:40,929 --> 00:33:48,920
three slides so what ya here is the

00:33:45,830 --> 00:33:52,670
reads that happened the average kilobyte

00:33:48,920 --> 00:33:55,070
of a read request read concurrency how

00:33:52,670 --> 00:33:57,740
many requests were merged and here we

00:33:55,070 --> 00:33:59,840
have the response time so for reads the

00:33:57,740 --> 00:34:03,860
average response time was for on milli

00:33:59,840 --> 00:34:07,130
second so for reads this is quite good i

00:34:03,860 --> 00:34:10,220
would say the same information is there

00:34:07,130 --> 00:34:12,919
for rights rights so we can see that

00:34:10,220 --> 00:34:16,550
right response time here is 61 seconds

00:34:12,919 --> 00:34:19,820
for the 160 right io operations with it

00:34:16,550 --> 00:34:23,679
so this is a problem here you can see

00:34:19,820 --> 00:34:26,869
disk subsystem is the problem here I

00:34:23,679 --> 00:34:30,350
would assume that 61 milliseconds is

00:34:26,869 --> 00:34:32,750
high if you have a great controller with

00:34:30,350 --> 00:34:34,669
a cash and you have a battery backup

00:34:32,750 --> 00:34:37,609
unit you can enable the write-back cache

00:34:34,669 --> 00:34:41,690
and this means that the disk system

00:34:37,609 --> 00:34:43,760
subsystem will cash it and I the actual

00:34:41,690 --> 00:34:46,159
numbers that you can get out of it with

00:34:43,760 --> 00:34:50,510
a write-back cache is 0 milliseconds so

00:34:46,159 --> 00:34:53,240
it's 600 times larger then with a

00:34:50,510 --> 00:34:55,129
write-back cache now if that cash is

00:34:53,240 --> 00:34:57,260
full and it the cash was not able to

00:34:55,129 --> 00:34:59,540
ride all the changes to disk it's going

00:34:57,260 --> 00:35:01,100
to be slow again so you need to buy the

00:34:59,540 --> 00:35:04,670
propiedad where with the appropriate

00:35:01,100 --> 00:35:06,710
cash and do the yeah use it use the

00:35:04,670 --> 00:35:09,950
proper disk subsystem for your

00:35:06,710 --> 00:35:13,609
application load but 61 milliseconds is

00:35:09,950 --> 00:35:15,830
really high with a mom EBS or yo

00:35:13,609 --> 00:35:18,609
whatever stories you use at amazon for

00:35:15,830 --> 00:35:21,650
example you have a highly unpredictable

00:35:18,609 --> 00:35:23,359
response time for your requests and it

00:35:21,650 --> 00:35:25,670
could be 10 milliseconds but it could be

00:35:23,359 --> 00:35:27,800
one second leavin so it just randomly if

00:35:25,670 --> 00:35:31,010
you look at it and you do distress it a

00:35:27,800 --> 00:35:32,750
lot with random reads and writes it it's

00:35:31,010 --> 00:35:34,460
unpredictable so it will affect your

00:35:32,750 --> 00:35:35,130
response time of your application

00:35:34,460 --> 00:35:37,900
heavily

00:35:35,130 --> 00:35:40,299
so using amazon i would say don't rely

00:35:37,900 --> 00:35:42,579
on disk too much try to keep it

00:35:40,299 --> 00:35:46,809
everything in memory and try to do reads

00:35:42,579 --> 00:35:51,640
from memory and don't write too much for

00:35:46,809 --> 00:35:53,410
example so some more information so how

00:35:51,640 --> 00:35:55,779
much it was busy so that's the

00:35:53,410 --> 00:35:58,329
utilization and then the total i owe

00:35:55,779 --> 00:36:02,200
operations per second so this PT disks

00:35:58,329 --> 00:36:05,319
that's really interesting i have an

00:36:02,200 --> 00:36:07,960
example here up on a global performance

00:36:05,319 --> 00:36:10,599
problem so what happens a drop table is

00:36:07,960 --> 00:36:14,890
being done every night and the database

00:36:10,599 --> 00:36:17,230
dolls so database hang so we were asked

00:36:14,890 --> 00:36:19,420
to look at it so what do we do the first

00:36:17,230 --> 00:36:21,579
thing we do is we look is is ready

00:36:19,420 --> 00:36:24,849
proper table enabled which means that

00:36:21,579 --> 00:36:27,819
every table gets a different table space

00:36:24,849 --> 00:36:32,109
a different file so table named doc IBD

00:36:27,819 --> 00:36:35,410
and they are using XFS so that's good

00:36:32,109 --> 00:36:37,420
because extended three and deleting

00:36:35,410 --> 00:36:40,599
files so drop table is removing that

00:36:37,420 --> 00:36:43,990
file is actually slow it's really slow

00:36:40,599 --> 00:36:46,900
so some benchmark done by magic in 2009

00:36:43,990 --> 00:36:48,760
shows that XFS is much much more

00:36:46,900 --> 00:36:51,940
efficient in that so in this case the

00:36:48,760 --> 00:36:53,650
customer they were using XFS so it was

00:36:51,940 --> 00:36:56,859
not related to the file system or

00:36:53,650 --> 00:36:58,779
anything so when the drop table was

00:36:56,859 --> 00:37:02,650
happening we did a show engine I know DB

00:36:58,779 --> 00:37:04,480
status and in the 74th action you can

00:37:02,650 --> 00:37:07,660
actually see some kind of things and

00:37:04,480 --> 00:37:10,750
it's I know it's a lot of data so things

00:37:07,660 --> 00:37:12,760
that I that you need to look at is you

00:37:10,750 --> 00:37:16,720
can see at a certain treads an internal

00:37:12,760 --> 00:37:19,029
thread in 90 DB was waiting at some

00:37:16,720 --> 00:37:21,910
point in the code some placing a quote

00:37:19,029 --> 00:37:25,059
for a certain amount of time for some

00:37:21,910 --> 00:37:27,750
mutex for some kind of looks so locks

00:37:25,059 --> 00:37:30,700
have to happen in the database to ensure

00:37:27,750 --> 00:37:33,910
something you know so only one can do a

00:37:30,700 --> 00:37:36,430
certain operation at this time to make

00:37:33,910 --> 00:37:40,000
sure that yeah the database performs

00:37:36,430 --> 00:37:42,670
good it's a maybe a bad example here so

00:37:40,000 --> 00:37:44,380
so what I I can show you here is it

00:37:42,670 --> 00:37:46,960
there's something going on with the

00:37:44,380 --> 00:37:48,410
dictionary so the I know DB dictionary

00:37:46,960 --> 00:37:50,720
so this means that

00:37:48,410 --> 00:37:52,280
and we know that if I know DB does

00:37:50,720 --> 00:37:54,500
something in the dictionary like

00:37:52,280 --> 00:37:57,260
creating a table or updating the

00:37:54,500 --> 00:37:58,790
dictionary cash it takes a lock so it

00:37:57,260 --> 00:38:00,830
takes a lock and only one can do it at

00:37:58,790 --> 00:38:02,990
the same time so what do we see here is

00:38:00,830 --> 00:38:04,490
that those locks other queries are

00:38:02,990 --> 00:38:08,930
actually waiting for that luck to be

00:38:04,490 --> 00:38:11,330
freed for 52 seconds so some query some

00:38:08,930 --> 00:38:13,250
tread some operation and I know DV is

00:38:11,330 --> 00:38:16,850
taking that long for that lock for a

00:38:13,250 --> 00:38:19,810
long time so how do we investigate so we

00:38:16,850 --> 00:38:27,230
know ok it's related to the dictionary

00:38:19,810 --> 00:38:30,830
so next thing we can do is yeah a poor

00:38:27,230 --> 00:38:34,190
man's profiler so this is a GDB stack

00:38:30,830 --> 00:38:35,990
trace so it's PTP MP and what it does it

00:38:34,190 --> 00:38:38,600
just takes a state of all the threads

00:38:35,990 --> 00:38:41,450
that are running in my squirrel and it

00:38:38,600 --> 00:38:43,960
shows the count of them so 66 threads

00:38:41,450 --> 00:38:47,690
and I know deep in my spell we're busy

00:38:43,960 --> 00:38:50,120
doing something I I Oh handler Phil I oh

00:38:47,690 --> 00:38:52,700
wait I'm not a developer so I don't know

00:38:50,120 --> 00:38:55,760
much about it so 66 threads were doing

00:38:52,700 --> 00:38:57,350
this portraits were handling some kind

00:38:55,760 --> 00:39:01,670
of connection so I removed a lot of the

00:38:57,350 --> 00:39:04,840
data because it's kind of big but most

00:39:01,670 --> 00:39:07,460
of them don't seem to show any clear

00:39:04,840 --> 00:39:09,310
indication what is wrong sometimes it

00:39:07,460 --> 00:39:12,770
does and in this example see that

00:39:09,310 --> 00:39:15,170
buffaler you invalid a tablespace it's

00:39:12,770 --> 00:39:18,800
kinda weird so you can see elite table

00:39:15,170 --> 00:39:21,800
so I just look at like that I ask Alexa

00:39:18,800 --> 00:39:23,780
to really look into the code for me so

00:39:21,800 --> 00:39:26,660
you can see that doing some operation

00:39:23,780 --> 00:39:28,360
with dropping that table so okay

00:39:26,660 --> 00:39:31,700
something is happening in that function

00:39:28,360 --> 00:39:35,540
that is taking a lock it might possibly

00:39:31,700 --> 00:39:37,520
take that lock for a long time so PT PMP

00:39:35,540 --> 00:39:40,580
shows you what are my threads doing

00:39:37,520 --> 00:39:43,240
right now so just the count of them the

00:39:40,580 --> 00:39:46,670
other thing we can do is duo profiling

00:39:43,240 --> 00:39:49,310
so we can see in a certain time span

00:39:46,670 --> 00:39:52,190
where was CPU time spent how much

00:39:49,310 --> 00:39:54,410
percent of my time was spent on some

00:39:52,190 --> 00:39:57,410
certain function might grow so this has

00:39:54,410 --> 00:39:59,810
shown that forty four percent of the

00:39:57,410 --> 00:40:01,250
time forty-two percent of the time it

00:39:59,810 --> 00:40:01,970
was actually doing that buffaler you

00:40:01,250 --> 00:40:04,930
invalidate

00:40:01,970 --> 00:40:09,320
tablespace so I use that information

00:40:04,930 --> 00:40:12,380
probably went to Alexei and then it

00:40:09,320 --> 00:40:14,480
turned out that when you have I know DB

00:40:12,380 --> 00:40:18,080
file per table equals one dropping a

00:40:14,480 --> 00:40:21,200
table removes the table space so in

00:40:18,080 --> 00:40:23,660
memory all the pages that are referring

00:40:21,200 --> 00:40:26,210
to that table space actually have to be

00:40:23,660 --> 00:40:28,609
removed from memory so when I was doing

00:40:26,210 --> 00:40:31,010
that it was holding that lock so if you

00:40:28,609 --> 00:40:33,170
have 200 gigs of memory it has to run

00:40:31,010 --> 00:40:36,290
through all that memory and remove them

00:40:33,170 --> 00:40:37,550
so that's why it takes a long time so

00:40:36,290 --> 00:40:40,040
there was some fixed and procurement

00:40:37,550 --> 00:40:43,430
server i nodi be lazy drop table that

00:40:40,040 --> 00:40:47,869
optimized it so here's a blog on how it

00:40:43,430 --> 00:40:50,260
was diagnosed and solved so if you

00:40:47,869 --> 00:40:53,869
enable that performance is increased

00:40:50,260 --> 00:40:57,230
it's also fixed in a community mysql 55

00:40:53,869 --> 00:41:00,400
20 although I heard that it's not

00:40:57,230 --> 00:41:03,680
completely fixed or some weird behavior

00:41:00,400 --> 00:41:06,619
okay so we did that and for one customer

00:41:03,680 --> 00:41:08,869
it resolved the problem however we had

00:41:06,619 --> 00:41:12,859
another customer later on that still had

00:41:08,869 --> 00:41:15,650
problems another thing we can do then is

00:41:12,859 --> 00:41:17,839
use that PT max tool so I showed you

00:41:15,650 --> 00:41:19,700
some handler statistics but there's also

00:41:17,839 --> 00:41:21,920
a lot of I know DB statistics in there

00:41:19,700 --> 00:41:24,440
and you could see that I know DB mmm

00:41:21,920 --> 00:41:26,960
adaptive hash which is the status

00:41:24,440 --> 00:41:30,490
variable and procurement server is the

00:41:26,960 --> 00:41:32,960
how big did the adaptive hash index is

00:41:30,490 --> 00:41:35,480
inside I know DB and you can see that

00:41:32,960 --> 00:41:39,050
every 10 seconds or every second in this

00:41:35,480 --> 00:41:41,300
case it was reducing a lot so that was

00:41:39,050 --> 00:41:45,619
kind of strange the adaptive hash index

00:41:41,300 --> 00:41:49,310
was shrinking so the thing was that bug

00:41:45,619 --> 00:41:53,000
fix that was done here actually did not

00:41:49,310 --> 00:41:56,720
resolve the same invalid removing of the

00:41:53,000 --> 00:42:01,130
pages of the adaptive index so this was

00:41:56,720 --> 00:42:05,300
fixed in 55 23 and that's how we

00:42:01,130 --> 00:42:08,060
troubleshoot it and found the problem so

00:42:05,300 --> 00:42:10,070
this is rare cases but it happens and

00:42:08,060 --> 00:42:12,109
with those tools you can actually have

00:42:10,070 --> 00:42:14,330
data to back up what is going on and

00:42:12,109 --> 00:42:15,530
give information passed information to

00:42:14,330 --> 00:42:17,930
development or

00:42:15,530 --> 00:42:20,300
find out what is going on a work around

00:42:17,930 --> 00:42:26,840
here is to disable the adaptive hash so

00:42:20,300 --> 00:42:32,030
that's that's a possible workaround next

00:42:26,840 --> 00:42:35,720
so next use case there's bad performance

00:42:32,030 --> 00:42:38,990
response time went up when we look at PT

00:42:35,720 --> 00:42:41,710
mext we see that handle read are in the

00:42:38,990 --> 00:42:44,840
next is very high so we see that it is

00:42:41,710 --> 00:42:47,180
86 million so if we take took a PT mixed

00:42:44,840 --> 00:42:50,150
with a difference of 10 seconds it's

00:42:47,180 --> 00:42:55,190
about 8 million rows data rows that were

00:42:50,150 --> 00:42:57,020
we read so this means okay there's a lot

00:42:55,190 --> 00:42:58,910
of those table scans going on or a big

00:42:57,020 --> 00:43:01,280
table scan is going on with that which

00:42:58,910 --> 00:43:04,820
actually impacts your performance or

00:43:01,280 --> 00:43:07,400
possibly in fact the performance so what

00:43:04,820 --> 00:43:10,220
do we do is we can go and have a look at

00:43:07,400 --> 00:43:12,920
the slow query log because we enable all

00:43:10,220 --> 00:43:15,650
the queries we lock them all and that

00:43:12,920 --> 00:43:17,510
way we can see how many rows were red so

00:43:15,650 --> 00:43:20,870
we can try to identify which query was

00:43:17,510 --> 00:43:22,610
it one of the examples here is and I'll

00:43:20,870 --> 00:43:26,540
show you those extended slow log

00:43:22,610 --> 00:43:30,230
statistics is we can have that

00:43:26,540 --> 00:43:32,720
information and what we can then to do

00:43:30,230 --> 00:43:34,820
is is if the slow log is very big we can

00:43:32,720 --> 00:43:37,040
grep through it we can use some whatever

00:43:34,820 --> 00:43:38,560
you want to do to to analyze it but

00:43:37,040 --> 00:43:40,940
there's a tool that actually

00:43:38,560 --> 00:43:43,250
investigates the slow query log so it's

00:43:40,940 --> 00:43:47,030
also part of ricotta toolkit it's a pro

00:43:43,250 --> 00:43:49,670
corner PT query digest so what it does

00:43:47,030 --> 00:43:52,610
is generates reports from different

00:43:49,670 --> 00:43:55,370
input so you have the slow query log but

00:43:52,610 --> 00:43:57,890
it can also parse bin log files look at

00:43:55,370 --> 00:44:01,550
show process list all the time it can

00:43:57,890 --> 00:44:04,010
actually parse postgresql log files the

00:44:01,550 --> 00:44:05,810
general lock but the general log only

00:44:04,010 --> 00:44:08,270
shows you the query know how long it

00:44:05,810 --> 00:44:10,940
took no statistics about it but you can

00:44:08,270 --> 00:44:14,810
also use TCP dump and capture all the

00:44:10,940 --> 00:44:17,660
network traffic and pdk digest can

00:44:14,810 --> 00:44:19,460
actually read the protocol and find out

00:44:17,660 --> 00:44:20,960
the queries that were happening get some

00:44:19,460 --> 00:44:23,810
statistics some response time

00:44:20,960 --> 00:44:26,150
information out of it it can do that it

00:44:23,810 --> 00:44:29,150
can read the MySQL protocol demand cash

00:44:26,150 --> 00:44:31,579
protocol and HTTP Burkle so commonly

00:44:29,150 --> 00:44:34,190
it's used for MySQL but note that you

00:44:31,579 --> 00:44:37,010
can do it for other things too so what

00:44:34,190 --> 00:44:39,619
does it do it does grouping and ordering

00:44:37,010 --> 00:44:44,029
of different things so everything that

00:44:39,619 --> 00:44:45,859
is actually mentioned in here you can

00:44:44,029 --> 00:44:47,630
group by you can filter on it there's a

00:44:45,859 --> 00:44:52,279
lot of flexibility that you can do here

00:44:47,630 --> 00:44:54,549
i show you some examples we can say some

00:44:52,279 --> 00:44:57,380
advanced filtering give me only selects

00:44:54,549 --> 00:45:00,520
give me the ones that do I know DB read

00:44:57,380 --> 00:45:05,839
operations give me the one that were

00:45:00,520 --> 00:45:10,640
query cache this is the example output

00:45:05,839 --> 00:45:14,089
and I'll just skip this because I have a

00:45:10,640 --> 00:45:16,220
lot of slides remaining so by default

00:45:14,089 --> 00:45:18,579
that we looked at the response time and

00:45:16,220 --> 00:45:21,230
we'll some all the response times of

00:45:18,579 --> 00:45:23,299
similar queries so similar queries is

00:45:21,230 --> 00:45:27,829
the same query but with different data

00:45:23,299 --> 00:45:32,089
values so this is a select join on table

00:45:27,829 --> 00:45:36,710
1 table 9 table 2 3 and 4 so it was

00:45:32,089 --> 00:45:38,809
called 12,000 times and of the total

00:45:36,710 --> 00:45:41,390
response time of that log file or TCP

00:45:38,809 --> 00:45:44,299
dump sixty-two percent of the response

00:45:41,390 --> 00:45:47,569
time is actually caused by this select

00:45:44,299 --> 00:45:49,819
by this particular query and you can see

00:45:47,569 --> 00:45:52,250
it's ordered by by default on the

00:45:49,819 --> 00:45:55,760
response time so when you're doing

00:45:52,250 --> 00:45:57,859
optimization well try to optimize this

00:45:55,760 --> 00:45:59,420
one instead of this one because this can

00:45:57,859 --> 00:46:01,039
give you a lot of benefit and give you a

00:45:59,420 --> 00:46:04,250
lot more resources again free up

00:46:01,039 --> 00:46:07,160
resources so this shows you this one is

00:46:04,250 --> 00:46:09,799
the 1i need to optimize so that's only

00:46:07,160 --> 00:46:12,020
the beginning of that report the next

00:46:09,799 --> 00:46:14,900
thing we see is information about query

00:46:12,020 --> 00:46:17,510
one so on the Left top you've got query

00:46:14,900 --> 00:46:20,859
one here that was run 17 times per

00:46:17,510 --> 00:46:24,319
second so it's just the first query here

00:46:20,859 --> 00:46:27,829
31 also important to know is you can

00:46:24,319 --> 00:46:30,200
look at which one which query to longest

00:46:27,829 --> 00:46:32,510
but in this case the response time for

00:46:30,200 --> 00:46:35,029
an individual query was only 112 me

00:46:32,510 --> 00:46:37,730
seconds by average so this means if you

00:46:35,029 --> 00:46:39,950
just look at the slow query log it's not

00:46:37,730 --> 00:46:42,710
the slowest one but it's just the total

00:46:39,950 --> 00:46:44,839
some detail to the amount of times

00:46:42,710 --> 00:46:46,820
that query was run was actually more

00:46:44,839 --> 00:46:48,290
than sixty-two percent so it's not

00:46:46,820 --> 00:46:50,660
always the slowest query that isn't

00:46:48,290 --> 00:46:53,599
creator taking the resources it's the

00:46:50,660 --> 00:46:56,510
one that is run most or most frequent

00:46:53,599 --> 00:46:59,240
that could cause it okay so you just

00:46:56,510 --> 00:47:01,460
have a lot of information here I'll show

00:46:59,240 --> 00:47:04,220
you minimum maximum average 95

00:47:01,460 --> 00:47:06,859
percentile of all that statistics all

00:47:04,220 --> 00:47:08,839
that information so execution time rows

00:47:06,859 --> 00:47:11,780
affected so it can help you try to

00:47:08,839 --> 00:47:14,330
troubleshoot the next thing is a query

00:47:11,780 --> 00:47:15,859
time distribution so remember that cacti

00:47:14,330 --> 00:47:18,260
graph I showed you with the query time

00:47:15,859 --> 00:47:21,109
distribution this is similar and it

00:47:18,260 --> 00:47:23,150
shows you how much of the queries were

00:47:21,109 --> 00:47:25,930
between 10 and 100 milli cat

00:47:23,150 --> 00:47:27,830
microseconds and women between 100

00:47:25,930 --> 00:47:31,760
milliseconds on one second so you can

00:47:27,830 --> 00:47:35,150
see in a lot of cases it's very fast but

00:47:31,760 --> 00:47:37,160
here it's really slow so why is that so

00:47:35,150 --> 00:47:41,630
if you look at the query it's a select

00:47:37,160 --> 00:47:44,480
from logging table so give me the user

00:47:41,630 --> 00:47:50,150
agent Mozilla for example so this is the

00:47:44,480 --> 00:47:53,720
very the data that is variable so so one

00:47:50,150 --> 00:47:56,210
explanation for this could be that the

00:47:53,720 --> 00:48:00,200
queries here didn't return any results

00:47:56,210 --> 00:48:02,150
but here it did or the queries that were

00:48:00,200 --> 00:48:03,710
run very fast they were in memory the

00:48:02,150 --> 00:48:05,599
day there was a memory and in this case

00:48:03,710 --> 00:48:09,290
it was not in memory and had to come

00:48:05,599 --> 00:48:13,130
from disk so you can see how stable that

00:48:09,290 --> 00:48:16,250
queries another thing could be that the

00:48:13,130 --> 00:48:19,580
the data that you select can also highly

00:48:16,250 --> 00:48:22,130
affect the response time one example we

00:48:19,580 --> 00:48:25,609
use in training is if you select from a

00:48:22,130 --> 00:48:27,530
movie that starts with a Zed or with a

00:48:25,609 --> 00:48:28,760
movie that starts with a tee well

00:48:27,530 --> 00:48:31,940
there's a lot of movies starting with

00:48:28,760 --> 00:48:34,460
duh so there's much more matches there

00:48:31,940 --> 00:48:37,849
so it is much slower so the data you

00:48:34,460 --> 00:48:39,500
select is also very important ptk digest

00:48:37,849 --> 00:48:41,349
can actually show you multiple queries

00:48:39,500 --> 00:48:44,119
and it can show you the worst queries

00:48:41,349 --> 00:48:46,849
immediately so you can see which one

00:48:44,119 --> 00:48:51,320
were which data which data you selected

00:48:46,849 --> 00:48:53,750
was actually slowest okay moving on this

00:48:51,320 --> 00:48:55,460
is an example by parsing the slow query

00:48:53,750 --> 00:48:55,800
log from a procurement server which has

00:48:55,460 --> 00:48:58,380
that

00:48:55,800 --> 00:49:01,470
lo slog for be enabled so you could see

00:48:58,380 --> 00:49:06,180
much more information sort merging them

00:49:01,470 --> 00:49:08,460
tables were created on disk I know DB

00:49:06,180 --> 00:49:11,130
read operations how many pay I know DB

00:49:08,460 --> 00:49:12,930
pages did that read Cory cache hit when

00:49:11,130 --> 00:49:17,180
how much percent fall sorts things like

00:49:12,930 --> 00:49:22,050
that okay so I have not much time left

00:49:17,180 --> 00:49:26,010
intermittent performance problems so

00:49:22,050 --> 00:49:27,420
we've used those tools but when you have

00:49:26,010 --> 00:49:29,850
a problem that is around happening

00:49:27,420 --> 00:49:31,560
randomly you actually yeah you can't

00:49:29,850 --> 00:49:34,440
just sit there and wait to run over

00:49:31,560 --> 00:49:37,020
commands and as example here is you

00:49:34,440 --> 00:49:39,810
can't collect or observe 45 things at

00:49:37,020 --> 00:49:41,760
the same time if it happens so there are

00:49:39,810 --> 00:49:44,160
some tools that enable you to collect

00:49:41,760 --> 00:49:47,390
data to stall some condition and then

00:49:44,160 --> 00:49:50,270
collect data so it's called PT stock and

00:49:47,390 --> 00:49:54,660
PT sift is another tool that will help

00:49:50,270 --> 00:49:56,820
ok so there's a problem happening at

00:49:54,660 --> 00:50:01,110
some random time and here's an example

00:49:56,820 --> 00:50:03,840
by using show glow global status with

00:50:01,110 --> 00:50:05,520
the amount of queries per second the

00:50:03,840 --> 00:50:06,960
amount of connections and the amount of

00:50:05,520 --> 00:50:08,820
threads that we're running so how many

00:50:06,960 --> 00:50:11,820
queries were active at the same time and

00:50:08,820 --> 00:50:15,090
you can see that it's pretty stable 700

00:50:11,820 --> 00:50:17,520
800 600 and it suddenly drops to 100 so

00:50:15,090 --> 00:50:19,230
this is wrong something changed here you

00:50:17,520 --> 00:50:21,810
can also see that there were more

00:50:19,230 --> 00:50:24,000
threads running at the same time so this

00:50:21,810 --> 00:50:25,950
is when we need to collect the data this

00:50:24,000 --> 00:50:28,080
is when we need to this is what we need

00:50:25,950 --> 00:50:32,070
to find out what is happening in those

00:50:28,080 --> 00:50:35,040
three collections that happens another

00:50:32,070 --> 00:50:37,140
way to see it is by parsing the slow

00:50:35,040 --> 00:50:39,000
query log providing that you log all the

00:50:37,140 --> 00:50:42,150
queries of course so you can see that

00:50:39,000 --> 00:50:44,850
there is a spike an increase of queries

00:50:42,150 --> 00:50:46,470
per second and suddenly it drop again so

00:50:44,850 --> 00:50:51,720
this shows you that something is going

00:50:46,470 --> 00:50:54,030
on at that time so this these examples

00:50:51,720 --> 00:50:56,850
give you some information on when is it

00:50:54,030 --> 00:50:59,910
happening and when do I need to trigger

00:50:56,850 --> 00:51:04,380
so that's a trigger that we call it so

00:50:59,910 --> 00:51:07,210
what is the condition that I see when

00:51:04,380 --> 00:51:09,700
the problem starts to happen so you

00:51:07,210 --> 00:51:11,380
like for example in this example we use

00:51:09,700 --> 00:51:13,720
threads running we can see that this is

00:51:11,380 --> 00:51:16,030
increases so it can configure PT stall

00:51:13,720 --> 00:51:18,700
to actually collect data when threads

00:51:16,030 --> 00:51:21,190
running goes above 15 in this case so

00:51:18,700 --> 00:51:24,609
when it goes above 15 automatically data

00:51:21,190 --> 00:51:27,190
will be collected this is also the

00:51:24,609 --> 00:51:31,089
default behavior so don't set it too low

00:51:27,190 --> 00:51:32,890
don't set it too high obvious reasons

00:51:31,089 --> 00:51:35,619
too low you get false positives too high

00:51:32,890 --> 00:51:37,869
and you will not always get it in most

00:51:35,619 --> 00:51:41,849
cases threads running is very good is

00:51:37,869 --> 00:51:44,200
the best one threats connected sometimes

00:51:41,849 --> 00:51:45,700
there are some others that you can

00:51:44,200 --> 00:51:48,060
create and you can create your own

00:51:45,700 --> 00:51:50,589
triggers for it and I have some examples

00:51:48,060 --> 00:51:54,099
so what value should use in this case

00:51:50,589 --> 00:51:56,410
threads running so pity stocks collects

00:51:54,099 --> 00:52:00,040
a lot of data you can actually collect

00:51:56,410 --> 00:52:02,230
that GD be so PT P&P information it can

00:52:00,040 --> 00:52:04,810
do the PO profiling for you already it

00:52:02,230 --> 00:52:08,260
can estrace and it can collect mysql

00:52:04,810 --> 00:52:11,290
data TCP dump data these are settings

00:52:08,260 --> 00:52:13,240
because s streisand gdb might in some

00:52:11,290 --> 00:52:15,550
cases crash your machine and you don't

00:52:13,240 --> 00:52:17,400
usually need it so beware when you use

00:52:15,550 --> 00:52:20,320
it that's why it is disabled by default

00:52:17,400 --> 00:52:23,830
so the threshold for tracks running was

00:52:20,320 --> 00:52:27,160
100 in this case not just the basic

00:52:23,830 --> 00:52:28,720
configuration so it stores the data it

00:52:27,160 --> 00:52:31,180
collects the data and stores it in

00:52:28,720 --> 00:52:33,849
varlet PT stock and here's an example of

00:52:31,180 --> 00:52:37,290
all the data that it collects open

00:52:33,849 --> 00:52:42,700
tables pmac process list multiple times

00:52:37,290 --> 00:52:45,580
p.s stack trace CTL values top output

00:52:42,700 --> 00:52:48,790
show global variables vmstat output

00:52:45,580 --> 00:52:51,130
overall so during for by default PT

00:52:48,790 --> 00:52:53,710
stock collects data for 30 seconds so

00:52:51,130 --> 00:52:56,920
what happened in vm start on average in

00:52:53,710 --> 00:53:00,520
30 seconds and vm stock contains what

00:52:56,920 --> 00:53:04,390
happens every second or every 10 seconds

00:53:00,520 --> 00:53:07,839
with it disk stats hostname I ODB status

00:53:04,390 --> 00:53:09,550
is multiple of them iostat disk stats

00:53:07,839 --> 00:53:11,680
there is a lot of information here and

00:53:09,550 --> 00:53:15,400
this is when the trigger happened so

00:53:11,680 --> 00:53:19,390
you've got multiple so this is 2011 07

00:53:15,400 --> 00:53:20,170
21 11 40 and this is 1110 so multiple

00:53:19,390 --> 00:53:23,619
collections

00:53:20,170 --> 00:53:25,569
happened now this is a lot of data so

00:53:23,619 --> 00:53:29,260
you need to process that so that's why

00:53:25,569 --> 00:53:31,869
PD sift is there if it works so PD sift

00:53:29,260 --> 00:53:33,730
of current directory and these are all

00:53:31,869 --> 00:53:36,099
the collections that happened you can

00:53:33,730 --> 00:53:40,329
then choose one of them and it will show

00:53:36,099 --> 00:53:42,280
you some summary of the data so here's

00:53:40,329 --> 00:53:45,400
some how many active transactions were

00:53:42,280 --> 00:53:47,230
there some basic vmstat output the

00:53:45,400 --> 00:53:50,890
process list how many queries were in

00:53:47,230 --> 00:53:52,869
which kind of state so this gives you an

00:53:50,890 --> 00:53:55,540
indication you can then go into an

00:53:52,869 --> 00:53:57,430
interactive mode and cpt max c disk

00:53:55,540 --> 00:54:01,480
stats see all the other file that are

00:53:57,430 --> 00:54:04,780
happening okay i'll have a to use cases

00:54:01,480 --> 00:54:07,000
here two examples so in this case we

00:54:04,780 --> 00:54:11,170
have query pileups and hide this guy Oh

00:54:07,000 --> 00:54:12,940
at random time so okay we don't know

00:54:11,170 --> 00:54:15,700
much we don't know what triggers it yet

00:54:12,940 --> 00:54:18,609
so let's just collect PT stock with

00:54:15,700 --> 00:54:21,010
dreads running larger than 10 so we

00:54:18,609 --> 00:54:24,819
collect the data and when we process the

00:54:21,010 --> 00:54:28,569
data we actually see in the mem info so

00:54:24,819 --> 00:54:30,400
the right back actually reduces and then

00:54:28,569 --> 00:54:33,880
grows again so that's the special thing

00:54:30,400 --> 00:54:37,299
we saw in there so right back is

00:54:33,880 --> 00:54:40,210
actually the file system cache has a

00:54:37,299 --> 00:54:41,530
write-back cache itself so you can see

00:54:40,210 --> 00:54:43,720
that the write-back cache of the

00:54:41,530 --> 00:54:45,670
Colonel's file system cache is actually

00:54:43,720 --> 00:54:48,970
going to zero and then increases again

00:54:45,670 --> 00:54:50,530
so we use threads running at first so

00:54:48,970 --> 00:54:52,540
what do we do then it's we actually

00:54:50,530 --> 00:54:55,589
changed PT stock and actually collect

00:54:52,540 --> 00:54:58,299
what ride back was starting to decrease

00:54:55,589 --> 00:55:01,839
so when we collected PD stock it

00:54:58,299 --> 00:55:05,290
collected some data at some times so

00:55:01,839 --> 00:55:08,200
here are the time that happened when the

00:55:05,290 --> 00:55:10,630
write-back cache was reducing what we

00:55:08,200 --> 00:55:13,059
noticed was that big time a collection

00:55:10,630 --> 00:55:17,170
happened the new binary log was actually

00:55:13,059 --> 00:55:20,200
created so they match the time perfectly

00:55:17,170 --> 00:55:22,720
here so ok there's something going on

00:55:20,200 --> 00:55:27,880
with the binary lives so after some

00:55:22,720 --> 00:55:32,589
investigation so you have to know with

00:55:27,880 --> 00:55:34,470
my isaam and a binary logs they are not

00:55:32,589 --> 00:55:38,860
flushed to disk by default

00:55:34,470 --> 00:55:40,960
so what happens is my skull right sit

00:55:38,860 --> 00:55:42,840
and the file system cache concussion it

00:55:40,960 --> 00:55:46,330
will not write it to disk immediately

00:55:42,840 --> 00:55:48,670
unless you set sing binlog to one for

00:55:46,330 --> 00:55:50,200
example it will sync all the changes to

00:55:48,670 --> 00:55:52,180
disk and ensure that it is written to

00:55:50,200 --> 00:55:55,150
the disk first if you don't enable that

00:55:52,180 --> 00:55:57,310
which is not enabled by default it will

00:55:55,150 --> 00:55:59,380
leave it up to the files is to do to

00:55:57,310 --> 00:56:01,660
Colonel sorry to the colonel to actually

00:55:59,380 --> 00:56:03,970
write it at some point in time so when

00:56:01,660 --> 00:56:05,980
your machine crashes or when the

00:56:03,970 --> 00:56:07,720
operating system crashes you lose data

00:56:05,980 --> 00:56:10,600
your binding logs will most likely be

00:56:07,720 --> 00:56:13,030
corrupt so what happened is when the

00:56:10,600 --> 00:56:15,490
binary log was rotated the file system

00:56:13,030 --> 00:56:18,100
cache decided let's flush those changes

00:56:15,490 --> 00:56:21,280
and write it to disk so we saw high

00:56:18,100 --> 00:56:24,340
increase of disk rights but it affected

00:56:21,280 --> 00:56:27,610
our normal response time and of the

00:56:24,340 --> 00:56:31,600
other queries so by default the file

00:56:27,610 --> 00:56:33,430
system cache is actually ten percent of

00:56:31,600 --> 00:56:35,920
the total amount of memory so if you

00:56:33,430 --> 00:56:38,830
have 200 gigs of memory 20 gig of it can

00:56:35,920 --> 00:56:42,460
be file system cache so you can use that

00:56:38,830 --> 00:56:45,280
and set it to one percent so it gets

00:56:42,460 --> 00:56:47,710
more smaller so it starts flushing those

00:56:45,280 --> 00:56:50,170
changes earlier the colonel decides to

00:56:47,710 --> 00:56:52,720
do it earlier and another thing we did

00:56:50,170 --> 00:56:55,330
is we reduce the binary log sighs from

00:56:52,720 --> 00:56:58,540
one gigabyte to 50 megabyte we just

00:56:55,330 --> 00:57:01,270
means that it will do more of those

00:56:58,540 --> 00:57:03,690
flushes and smaller flushes instead of

00:57:01,270 --> 00:57:06,790
writing one gigabyte and affecting risk

00:57:03,690 --> 00:57:08,770
are overloading disk i/o we change it to

00:57:06,790 --> 00:57:12,190
50 megabytes so the spikes were removed

00:57:08,770 --> 00:57:13,540
by just changing those settings and I've

00:57:12,190 --> 00:57:17,830
got one minute and a half remaining and

00:57:13,540 --> 00:57:19,990
have one example another problem there's

00:57:17,830 --> 00:57:22,690
a lot of lock contention inside either

00:57:19,990 --> 00:57:25,990
be the customer has no idea what's going

00:57:22,690 --> 00:57:27,790
on and we don't know what caused so what

00:57:25,990 --> 00:57:29,590
we can do is we can use our extended

00:57:27,790 --> 00:57:32,530
slow logging as in procurement server

00:57:29,590 --> 00:57:34,120
and see what lock waits there were so we

00:57:32,530 --> 00:57:37,540
can see which queries were weighted and

00:57:34,120 --> 00:57:39,730
which queries were waiting on what it's

00:57:37,540 --> 00:57:41,500
not always very easy to see it that but

00:57:39,730 --> 00:57:44,410
one way we can do it is we can configure

00:57:41,500 --> 00:57:47,080
PT stock write a script that looks at

00:57:44,410 --> 00:57:47,510
transaction luck weights or looks for

00:57:47,080 --> 00:57:49,340
long

00:57:47,510 --> 00:57:52,010
transactions and then collect data when

00:57:49,340 --> 00:57:54,830
it happens an interesting fact that I

00:57:52,010 --> 00:57:59,150
did in the past was I captured TCP dump

00:57:54,830 --> 00:58:01,250
data when it happens then we process it

00:57:59,150 --> 00:58:04,460
with PT query digest and then we see

00:58:01,250 --> 00:58:05,720
when the problem happens what is all the

00:58:04,460 --> 00:58:08,660
queries that are coming in what are

00:58:05,720 --> 00:58:10,850
those transactions doing so one example

00:58:08,660 --> 00:58:13,010
here is that we had a transaction that

00:58:10,850 --> 00:58:16,220
had some locks here and that's some

00:58:13,010 --> 00:58:18,500
changes and exactly for 14 seconds so 14

00:58:16,220 --> 00:58:21,550
seconds is a lot for transaction so

00:58:18,500 --> 00:58:24,470
other transactions we're waiting on this

00:58:21,550 --> 00:58:26,540
transaction to be committed no query was

00:58:24,470 --> 00:58:28,430
run here so it's kind of hard to see

00:58:26,540 --> 00:58:31,520
what is going on here what is that

00:58:28,430 --> 00:58:33,230
transaction doing it could be idle the

00:58:31,520 --> 00:58:36,050
application could be doing some other

00:58:33,230 --> 00:58:38,600
requests or spend some cpu cycles doing

00:58:36,050 --> 00:58:41,210
nothing but you can have the might build

00:58:38,600 --> 00:58:44,120
thread ID and do show full process list

00:58:41,210 --> 00:58:48,470
and then match the trade ID with a an

00:58:44,120 --> 00:58:51,410
ipn and a port that's one example but in

00:58:48,470 --> 00:58:57,650
this case we captured the DCPD of data

00:58:51,410 --> 00:59:00,890
and then we actually looked at we looked

00:58:57,650 --> 00:59:04,430
at that tread ID that port and we we

00:59:00,890 --> 00:59:06,680
looked what was that transaction doing

00:59:04,430 --> 00:59:09,200
afterwards so it turned out that there

00:59:06,680 --> 00:59:10,910
was an application bug and the traction

00:59:09,200 --> 00:59:12,710
was stuck in a loop so it was doing the

00:59:10,910 --> 00:59:15,740
same queries over and over again the

00:59:12,710 --> 00:59:17,090
same rights over and over again and TCP

00:59:15,740 --> 00:59:22,450
dump and PT stalled helped is to

00:59:17,090 --> 00:59:25,220
actually solve that problem so summary

00:59:22,450 --> 00:59:28,040
find out what the problem is don't try

00:59:25,220 --> 00:59:29,750
to guess try to prove your guesses have

00:59:28,040 --> 00:59:32,200
instrumentation have data to back up

00:59:29,750 --> 00:59:37,700
your troubleshooting troubleshooting

00:59:32,200 --> 00:59:40,490
data go explain when doing in optimizing

00:59:37,700 --> 00:59:42,650
individual query when you have global

00:59:40,490 --> 00:59:44,990
performance problems look at some global

00:59:42,650 --> 00:59:47,270
counters and statistics in that certain

00:59:44,990 --> 00:59:49,640
period time steps time span when the

00:59:47,270 --> 00:59:52,160
problem is happening different problems

00:59:49,640 --> 00:59:54,320
require different tools of course photo

00:59:52,160 --> 00:59:56,030
is it written performance problems PT

00:59:54,320 --> 00:59:58,580
stock has proven to be really effective

00:59:56,030 --> 01:00:01,160
in nailing it down collecting the data

00:59:58,580 --> 01:00:04,579
and helping you to troubleshoot the neck

01:00:01,160 --> 01:00:08,240
morning so that was it here are some

01:00:04,579 --> 01:00:12,640
links of the tools that we used so yeah

01:00:08,240 --> 01:00:12,640
any questions you have minus one minute

01:00:12,670 --> 01:00:25,069
you can talk to me afterwards no

01:00:16,010 --> 01:00:28,780
questions good actually I do have a

01:00:25,069 --> 01:00:34,460
question okay I I want to know how the

01:00:28,780 --> 01:00:37,789
impact of monitoring or yeah debugging

01:00:34,460 --> 01:00:40,130
is on the life-system and I assume you

01:00:37,789 --> 01:00:43,309
do this on the live system because of

01:00:40,130 --> 01:00:47,329
the arrows only a car on the on the walk

01:00:43,309 --> 01:00:51,079
loaded yes system so when of those when

01:00:47,329 --> 01:00:53,480
does it affect a lot well gdb will stall

01:00:51,079 --> 01:00:55,250
the database for a while so don't do gdb

01:00:53,480 --> 01:01:00,200
by default unless you know that you need

01:00:55,250 --> 01:01:04,130
it but most others they just do proc

01:01:00,200 --> 01:01:07,069
stop a CTL that doesn't really affect it

01:01:04,130 --> 01:01:09,980
show engine I know DB status it might

01:01:07,069 --> 01:01:12,140
cause some performance I some small

01:01:09,980 --> 01:01:14,660
locking but it's really low and usually

01:01:12,140 --> 01:01:19,539
doesn't lock it I would say if you don't

01:01:14,660 --> 01:01:30,529
do be it's not going to affect much here

01:01:19,539 --> 01:01:32,180
no I'm checking here nope yes actually

01:01:30,529 --> 01:01:33,619
no room at cenovus written a PMP

01:01:32,180 --> 01:01:36,650
replacement quick stick that can

01:01:33,619 --> 01:01:39,500
possibly make that problem a bit better

01:01:36,650 --> 01:01:41,569
okay that i have-- stall as long as GDP

01:01:39,500 --> 01:01:44,180
does dead so in what does he do it

01:01:41,569 --> 01:01:46,730
because I haven't seen it yet he is

01:01:44,180 --> 01:01:48,680
attaching himself apparently to the core

01:01:46,730 --> 01:01:51,440
image of the okay i debase and then

01:01:48,680 --> 01:01:53,420
scaling scanning the stack manually okay

01:01:51,440 --> 01:01:55,279
it works a lot better if you have a

01:01:53,420 --> 01:01:58,130
version of moisture that does not emit

01:01:55,279 --> 01:01:59,630
frame pounders okay i will i will see

01:01:58,130 --> 01:02:02,480
maybe you can change it i have not seen

01:01:59,630 --> 01:02:04,609
his blog about it yet or is it recent it

01:02:02,480 --> 01:02:06,410
is rather recent up it is about two

01:02:04,609 --> 01:02:09,109
weeks order so i was very recently on

01:02:06,410 --> 01:02:12,440
planet miles Jai okay which generally is

01:02:09,109 --> 01:02:14,630
a resource to recommend yes planet my

01:02:12,440 --> 01:02:23,859
scroll com

01:02:14,630 --> 01:02:23,859

YouTube URL: https://www.youtube.com/watch?v=FSfAQp-MBEM


