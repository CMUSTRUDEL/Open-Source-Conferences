Title: Berlin Buzzwords 2014: Andreas Neumann - Harnessing the power of YARN with Apache Twill #bbuzz
Publication date: 2014-05-28
Playlist: Berlin Buzzwords 2014 #bbuzz
Description: 
	When Apache Hadoop was first introduced to the Open Source, it was focused on implementing Google's Map/Reduce, a framework for batch processing of very large files in a distributed system. Built for running on large cluster of commodity hardware, Hadoop also included a cluster resource manager to divide the capacity of the cluster between the various Map/Reduce jobs that can run at a given time.

A Hadoop cluster, however, is not always fully utilized, and idle resources would best be used for other compute-intensive tasks like real-time stream processing, message passing, or graph algorithms. Unfortunately, the cluster resource manager was specialized in Map/Reduce execution and did not allow other types of workloads.  

Read more:
https://2014.berlinbuzzwords.de/session/harnessing-power-yarn-apache-twill

About Andreas Neumann:
https://2014.berlinbuzzwords.de/user/279/event/1

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,560 --> 00:00:11,980
welcome to my talk it's gonna be about

00:00:08,470 --> 00:00:14,260
yarn and how to make your uneasier who

00:00:11,980 --> 00:00:16,119
knows what yarn is who was here an hour

00:00:14,260 --> 00:00:21,220
ago yeah I know it

00:00:16,119 --> 00:00:23,470
okay so yarn is part of the current

00:00:21,220 --> 00:00:25,000
release of Hadoop and I do this to

00:00:23,470 --> 00:00:28,060
elephant

00:00:25,000 --> 00:00:29,500
it can handle tons of data it's it does

00:00:28,060 --> 00:00:36,070
all the heavy lifting for you when you

00:00:29,500 --> 00:00:38,610
have to do massive data processing the

00:00:36,070 --> 00:00:41,130
distributed application in Hadoop

00:00:38,610 --> 00:00:44,020
classically looks like this

00:00:41,130 --> 00:00:47,379
you recognize this threat this is a

00:00:44,020 --> 00:00:49,719
MapReduce job you have a bunch of

00:00:47,379 --> 00:00:52,719
mappers each mapper reads the split from

00:00:49,719 --> 00:00:54,550
the filesystem spits out some tuples

00:00:52,719 --> 00:00:56,500
there's a shuffle phase in between them

00:00:54,550 --> 00:00:58,600
sorting and then there's a bunch of

00:00:56,500 --> 00:01:01,000
reducers and each of them spits out data

00:00:58,600 --> 00:01:04,690
writes them to filesystem into heart

00:01:01,000 --> 00:01:06,880
files this is a very powerful pattern we

00:01:04,690 --> 00:01:12,000
can do lots of different types of data

00:01:06,880 --> 00:01:16,270
analysis but we cannot do everything

00:01:12,000 --> 00:01:19,000
however hadoo gives us an infrastructure

00:01:16,270 --> 00:01:22,119
that allows to run many different kinds

00:01:19,000 --> 00:01:24,189
of MapReduce jobs in a single cluster so

00:01:22,119 --> 00:01:27,970
here I have four different MapReduce

00:01:24,189 --> 00:01:31,960
jobs running Hadoop has a scheduler that

00:01:27,970 --> 00:01:35,799
allows me to place my computations close

00:01:31,960 --> 00:01:38,579
to the data lots of useful features but

00:01:35,799 --> 00:01:41,259
if I look closely here in this picture I

00:01:38,579 --> 00:01:43,659
see that a lot of the nodes on my

00:01:41,259 --> 00:01:45,970
cluster are actually not used because

00:01:43,659 --> 00:01:49,570
not all the time do I have enough data

00:01:45,970 --> 00:01:51,610
to analyze sometimes I have peak amounts

00:01:49,570 --> 00:01:55,149
of data and I need all the notes in my

00:01:51,610 --> 00:01:57,579
cluster sometimes I don't so what could

00:01:55,149 --> 00:01:59,320
I do with these these grey little boxes

00:01:57,579 --> 00:02:02,219
here that are right now just sitting in

00:01:59,320 --> 00:02:04,479
the data center consuming power and

00:02:02,219 --> 00:02:07,960
question is well maybe I have a data

00:02:04,479 --> 00:02:10,690
scientist in my in my lab and and he

00:02:07,960 --> 00:02:13,090
says I I'd like to write a message

00:02:10,690 --> 00:02:15,099
passing application that's also this

00:02:13,090 --> 00:02:17,349
tubular application I have here I have

00:02:15,099 --> 00:02:19,060
six processors they all talk to each

00:02:17,349 --> 00:02:21,970
other they all interact with DES

00:02:19,060 --> 00:02:25,120
somehow locally and they need to run in

00:02:21,970 --> 00:02:27,250
a cluster I might have a stream

00:02:25,120 --> 00:02:30,069
processing app right I get events they

00:02:27,250 --> 00:02:32,740
come in in real time I have processors

00:02:30,069 --> 00:02:34,959
they consume these events in real time

00:02:32,740 --> 00:02:37,780
they may write some data to a data base

00:02:34,959 --> 00:02:39,790
and may read some data but again it's a

00:02:37,780 --> 00:02:43,360
distributed application it can run in a

00:02:39,790 --> 00:02:46,989
cluster and maybe I could run that in my

00:02:43,360 --> 00:02:49,209
Hadoop cluster and if I have no

00:02:46,989 --> 00:02:52,989
important applications to run maybe I

00:02:49,209 --> 00:02:54,489
could do some testing because for

00:02:52,989 --> 00:02:56,709
example if I have some web service I

00:02:54,489 --> 00:02:59,350
want to do some load testing I could

00:02:56,709 --> 00:03:02,680
just run a test on many nodes on my

00:02:59,350 --> 00:03:05,650
cluster when I have spare capacity so I

00:03:02,680 --> 00:03:09,640
actually know lots of ways to use the

00:03:05,650 --> 00:03:10,420
spare capacity in my cluster and if I

00:03:09,640 --> 00:03:11,910
could do that

00:03:10,420 --> 00:03:14,980
then my cluster looks more like this

00:03:11,910 --> 00:03:16,450
there's still some gray notes but it

00:03:14,980 --> 00:03:17,920
looks much more diverse and I can do all

00:03:16,450 --> 00:03:20,680
these different things in a single

00:03:17,920 --> 00:03:26,049
infrastructure so this would be ideal

00:03:20,680 --> 00:03:27,820
right I'd love to do that now let me

00:03:26,049 --> 00:03:30,850
quickly explain why I would love to do

00:03:27,820 --> 00:03:34,540
that my name is andreas Norman I worked

00:03:30,850 --> 00:03:37,120
for continuity and what we have built is

00:03:34,540 --> 00:03:40,810
a product that's a developer centric big

00:03:37,120 --> 00:03:43,329
data application platform and it pretty

00:03:40,810 --> 00:03:45,940
much runs any type of processing that

00:03:43,329 --> 00:03:47,950
you have to do in the Hadoop cluster it

00:03:45,940 --> 00:03:51,820
runs real-time stream processing it runs

00:03:47,950 --> 00:03:54,790
batch analytics like MapReduce it runs

00:03:51,820 --> 00:03:59,680
we run tests there we run web services

00:03:54,790 --> 00:04:02,260
there and when we built this platform we

00:03:59,680 --> 00:04:03,790
were kind of desperate say it's about

00:04:02,260 --> 00:04:06,670
two years ago two and a half years ago

00:04:03,790 --> 00:04:08,140
and we couldn't find an easy way to run

00:04:06,670 --> 00:04:10,810
all these different things in a single

00:04:08,140 --> 00:04:14,049
cluster and the answer that we found was

00:04:10,810 --> 00:04:19,470
yarn so that was about the time that

00:04:14,049 --> 00:04:22,630
Hadoop version 2 came out and that had

00:04:19,470 --> 00:04:24,729
one major advantage over Hadoop version

00:04:22,630 --> 00:04:26,530
one in Hadoop version one there was a

00:04:24,729 --> 00:04:29,289
job tracker and the job tracker was

00:04:26,530 --> 00:04:31,930
responsible for managing the resources

00:04:29,289 --> 00:04:32,710
of the cluster and for driving the

00:04:31,930 --> 00:04:34,840
execution of

00:04:32,710 --> 00:04:36,340
produced jobs so the programming

00:04:34,840 --> 00:04:38,680
paradigm and the resource management

00:04:36,340 --> 00:04:40,420
were very tightly coupled and that was

00:04:38,680 --> 00:04:42,190
the reason why it was very hard to run

00:04:40,420 --> 00:04:46,930
anything other than MapReduce and I had

00:04:42,190 --> 00:04:49,900
to gesture with Hadoop to oh was new

00:04:46,930 --> 00:04:52,570
resource manager yarn and that separates

00:04:49,900 --> 00:04:54,970
these two tasks there's resource

00:04:52,570 --> 00:04:57,940
management and there's the programming

00:04:54,970 --> 00:05:01,620
and it allows to run pretty much

00:04:57,940 --> 00:05:04,690
anything in your heart'll cluster and

00:05:01,620 --> 00:05:06,130
how this works now is so here I have an

00:05:04,690 --> 00:05:10,750
application that I could not run in

00:05:06,130 --> 00:05:13,240
Hadoop previously and in yarn I will now

00:05:10,750 --> 00:05:16,150
have a resource manager that runs on the

00:05:13,240 --> 00:05:17,680
side and the only thing that I have to

00:05:16,150 --> 00:05:20,680
do is I have to write an application

00:05:17,680 --> 00:05:23,830
master this is one new process that I

00:05:20,680 --> 00:05:26,430
have to run it negotiates resources with

00:05:23,830 --> 00:05:30,760
the resource manager it acquires

00:05:26,430 --> 00:05:32,350
containers to run tasks in and then it

00:05:30,760 --> 00:05:35,560
drives the execution of the application

00:05:32,350 --> 00:05:37,720
in those containers so now the logic of

00:05:35,560 --> 00:05:39,970
how the application is executed is in

00:05:37,720 --> 00:05:42,100
the application master and that's my own

00:05:39,970 --> 00:05:48,280
code if I want to so I have all the

00:05:42,100 --> 00:05:49,990
power and with yarn my cluster now looks

00:05:48,280 --> 00:05:52,360
like this I have the resource manager on

00:05:49,990 --> 00:05:59,910
the side and all of my applications have

00:05:52,360 --> 00:06:06,670
their own little application master okay

00:05:59,910 --> 00:06:10,090
so far all tier good so let's look a

00:06:06,670 --> 00:06:13,480
little bit closer how yarn works so in

00:06:10,090 --> 00:06:16,420
yarn I have my cluster every node of the

00:06:13,480 --> 00:06:18,670
cluster runs a node manager and I have

00:06:16,420 --> 00:06:21,340
the yarn resource manager which sits

00:06:18,670 --> 00:06:23,560
there as the central point of control

00:06:21,340 --> 00:06:25,570
and here I have a yarn client the yarn

00:06:23,560 --> 00:06:28,120
client wants to start an application in

00:06:25,570 --> 00:06:31,240
the cluster so the first thing that

00:06:28,120 --> 00:06:33,070
happens is the yarn client needs to

00:06:31,240 --> 00:06:35,500
submit the application master to the

00:06:33,070 --> 00:06:38,050
resource manager which means it needs to

00:06:35,500 --> 00:06:40,510
bundle up a jar and some configuration

00:06:38,050 --> 00:06:41,950
and tell the resource manager I want to

00:06:40,510 --> 00:06:44,890
start an application and here's the

00:06:41,950 --> 00:06:45,960
master what the resource manager does

00:06:44,890 --> 00:06:49,370
next is

00:06:45,960 --> 00:06:52,020
find a free container in the cluster and

00:06:49,370 --> 00:06:54,780
it talks to the node manager of the note

00:06:52,020 --> 00:06:56,789
where that container is located and it

00:06:54,780 --> 00:06:58,380
tells that note manager to start the

00:06:56,789 --> 00:07:01,410
application master so now the

00:06:58,380 --> 00:07:04,860
application master is alive it's running

00:07:01,410 --> 00:07:07,199
and it can now start talking to the

00:07:04,860 --> 00:07:11,370
resource manager and ask it for more

00:07:07,199 --> 00:07:14,250
containers so now it could acquire say

00:07:11,370 --> 00:07:16,800
three containers and once it has these

00:07:14,250 --> 00:07:19,530
containers it then talks to the node

00:07:16,800 --> 00:07:21,300
managers in the cluster to start its own

00:07:19,530 --> 00:07:24,360
tasks in those containers that it

00:07:21,300 --> 00:07:26,789
received from the resource manager so

00:07:24,360 --> 00:07:29,280
this is the interaction and these steps

00:07:26,789 --> 00:07:31,560
number three and number four they can

00:07:29,280 --> 00:07:34,169
repeat so the application master can

00:07:31,560 --> 00:07:36,090
dynamically ask for more resources can

00:07:34,169 --> 00:07:39,060
give up resources and resources in this

00:07:36,090 --> 00:07:42,210
sense are always containers in the

00:07:39,060 --> 00:07:47,250
cluster with a given capacity in terms

00:07:42,210 --> 00:07:50,789
of memory or virtual cores no this looks

00:07:47,250 --> 00:07:53,190
fairly simple so I want to dive a little

00:07:50,789 --> 00:07:54,690
bit deeper so let's just look at this

00:07:53,190 --> 00:07:59,009
first step submitting the application

00:07:54,690 --> 00:08:02,759
master what does that mean so we have a

00:07:59,009 --> 00:08:05,070
we have a Java a jar file with some Java

00:08:02,759 --> 00:08:06,719
code that's the application master and

00:08:05,070 --> 00:08:09,419
we want to run that in one of the nodes

00:08:06,719 --> 00:08:12,990
of the cluster now the client has this

00:08:09,419 --> 00:08:14,969
jar file on this local file system if we

00:08:12,990 --> 00:08:17,940
just tell the resource manager find the

00:08:14,969 --> 00:08:19,500
container and run this jar in this

00:08:17,940 --> 00:08:20,880
container is going to run somewhere here

00:08:19,500 --> 00:08:23,280
and the jar is not going to be on its

00:08:20,880 --> 00:08:25,080
local file system it's not it's not

00:08:23,280 --> 00:08:26,849
gonna work it cannot access my local

00:08:25,080 --> 00:08:31,919
file system that might be my laptop

00:08:26,849 --> 00:08:34,890
right so what needs to happen is first

00:08:31,919 --> 00:08:38,279
thing the client needs to copy this jar

00:08:34,890 --> 00:08:41,099
file to the distributed file system then

00:08:38,279 --> 00:08:44,880
it submits its request to the to the

00:08:41,099 --> 00:08:47,700
resource manager and the resource

00:08:44,880 --> 00:08:50,130
manager and node manager make sure that

00:08:47,700 --> 00:08:52,709
this jar file gets copied to the local

00:08:50,130 --> 00:08:55,290
file system off the machine that hosts

00:08:52,709 --> 00:08:58,650
that container now the node manager can

00:08:55,290 --> 00:08:59,550
start the application master which can

00:08:58,650 --> 00:09:02,430
now load it from it

00:08:59,550 --> 00:09:04,410
local file system so this interaction is

00:09:02,430 --> 00:09:09,540
slightly more complex than you would

00:09:04,410 --> 00:09:11,279
think at first and if we really list all

00:09:09,540 --> 00:09:13,140
the things that the young client has to

00:09:11,279 --> 00:09:16,800
do just to start the application master

00:09:13,140 --> 00:09:18,810
its these eight steps I could go through

00:09:16,800 --> 00:09:20,670
each of these steps and I actually have

00:09:18,810 --> 00:09:23,940
roughly a page of code for each of these

00:09:20,670 --> 00:09:25,800
steps not gonna show you all of this

00:09:23,940 --> 00:09:28,890
because I mean I'm gonna show it but I'm

00:09:25,800 --> 00:09:30,600
not going to talk to it there's some

00:09:28,890 --> 00:09:32,430
interesting things here that you see

00:09:30,600 --> 00:09:36,149
that in this code I have to set up the

00:09:32,430 --> 00:09:38,190
class path for for that container I also

00:09:36,149 --> 00:09:42,870
have to set up a command this is a shell

00:09:38,190 --> 00:09:44,610
command that runs it runs a JVM and I'm

00:09:42,870 --> 00:09:48,209
actually I'm in charge of making sure

00:09:44,610 --> 00:09:51,240
that standard out and standard error are

00:09:48,209 --> 00:09:53,670
captured somewhere properly and if I if

00:09:51,240 --> 00:09:56,579
I built this command in the wrong way

00:09:53,670 --> 00:10:00,209
then nothing is gonna work and I'm gonna

00:09:56,579 --> 00:10:03,899
get a very unexpected behavior so it's

00:10:00,209 --> 00:10:07,709
quite complex and there's a lot of

00:10:03,899 --> 00:10:10,410
things you can do wrong and we if we

00:10:07,709 --> 00:10:12,660
look at all this this was only the first

00:10:10,410 --> 00:10:16,560
step right this was only submitting the

00:10:12,660 --> 00:10:18,870
application master the same kind of code

00:10:16,560 --> 00:10:21,029
is required again in the application

00:10:18,870 --> 00:10:24,420
master when it wants to start containers

00:10:21,029 --> 00:10:26,339
for the individual tasks right so we

00:10:24,420 --> 00:10:28,230
have a duplication of this code it

00:10:26,339 --> 00:10:31,920
happens once in the application master

00:10:28,230 --> 00:10:34,170
and once in the aren't lined and so so

00:10:31,920 --> 00:10:40,440
we end up writing quite a lot of Euler

00:10:34,170 --> 00:10:42,779
plates code so yarn is great nothing

00:10:40,440 --> 00:10:45,839
against that right but it is quite

00:10:42,779 --> 00:10:47,160
complex in order to write an application

00:10:45,839 --> 00:10:49,220
you need to learn three different

00:10:47,160 --> 00:10:51,959
protocols and each of them is

00:10:49,220 --> 00:10:53,850
complicated especially the protocol

00:10:51,959 --> 00:10:56,300
between the application master and the

00:10:53,850 --> 00:10:59,880
resource manager is it's an asynchronous

00:10:56,300 --> 00:11:04,380
protocol and lots of interesting race

00:10:59,880 --> 00:11:06,209
conditions can happen there what you get

00:11:04,380 --> 00:11:08,370
is really full power you get full

00:11:06,209 --> 00:11:10,579
control over all the different knobs

00:11:08,370 --> 00:11:13,040
that you can twist and turn in Hadoop

00:11:10,579 --> 00:11:16,160
but it's actually at the expense of

00:11:13,040 --> 00:11:18,949
simplicity it's the the learning curve

00:11:16,160 --> 00:11:20,869
is very very steep and I don't know how

00:11:18,949 --> 00:11:25,189
many here have actually written a yarn

00:11:20,869 --> 00:11:27,470
application once okay how many of you oh

00:11:25,189 --> 00:11:34,970
wow I know Steve has written many of

00:11:27,470 --> 00:11:36,980
them how about you did you like it yeah

00:11:34,970 --> 00:11:40,699
so I I had a lot of fun when I first did

00:11:36,980 --> 00:11:42,589
this and my first little application was

00:11:40,699 --> 00:11:44,509
over 1,000 lines of code and it really

00:11:42,589 --> 00:11:50,149
didn't do anything all it did was it was

00:11:44,509 --> 00:11:53,509
logging a single line so um so at

00:11:50,149 --> 00:11:55,489
continuity when we built our product we

00:11:53,509 --> 00:11:57,739
found ourselves reimplemented that

00:11:55,489 --> 00:11:59,119
boilerplate code over and over again for

00:11:57,739 --> 00:12:00,649
all the different things we were doing

00:11:59,119 --> 00:12:03,350
in yarn and we very quickly realized

00:12:00,649 --> 00:12:04,999
that that there must be a better way it

00:12:03,350 --> 00:12:06,559
must be there must be an easier way to

00:12:04,999 --> 00:12:08,389
do this because there are common

00:12:06,559 --> 00:12:13,910
patterns that we find again and again

00:12:08,389 --> 00:12:16,339
and so we we looked at a class of yarn

00:12:13,910 --> 00:12:19,689
applications or distributed applications

00:12:16,339 --> 00:12:23,509
and we found the similarity to

00:12:19,689 --> 00:12:26,149
multi-threaded applications many

00:12:23,509 --> 00:12:28,730
distributed applications consists of

00:12:26,149 --> 00:12:31,220
processes that run on different nodes in

00:12:28,730 --> 00:12:34,509
the system but they don't actually need

00:12:31,220 --> 00:12:37,699
to talk to each other a lot of times

00:12:34,509 --> 00:12:42,949
each one runs autonomously like a Java

00:12:37,699 --> 00:12:45,739
like a Java thread right and if I would

00:12:42,949 --> 00:12:48,079
program this in in Java as a

00:12:45,739 --> 00:12:49,939
multi-threaded application I would have

00:12:48,079 --> 00:12:51,949
utilities in Java from from the

00:12:49,939 --> 00:12:54,819
concurrent package I'd have executors

00:12:51,949 --> 00:12:57,980
and things that manage my threats for me

00:12:54,819 --> 00:13:00,889
so could we do something similar for

00:12:57,980 --> 00:13:04,069
yarn and and the answer is yes the

00:13:00,889 --> 00:13:06,529
answer is is Apache twill so this

00:13:04,069 --> 00:13:09,290
started Azzam is an internal project

00:13:06,529 --> 00:13:10,699
inside of continuity and we started

00:13:09,290 --> 00:13:13,339
talking to some people about it and

00:13:10,699 --> 00:13:14,989
there was there was a very high interest

00:13:13,339 --> 00:13:17,629
because everybody who had written yarn

00:13:14,989 --> 00:13:20,839
applications saw the need for this this

00:13:17,629 --> 00:13:22,730
simplification and the programming model

00:13:20,839 --> 00:13:24,230
we have is indeed just like Java threads

00:13:22,730 --> 00:13:26,960
you define random

00:13:24,230 --> 00:13:29,330
and then you run them in the cluster

00:13:26,960 --> 00:13:32,930
instead of running them in in in thread

00:13:29,330 --> 00:13:35,900
pools it was incubated about half a year

00:13:32,930 --> 00:13:38,480
ago we have had two releases since then

00:13:35,900 --> 00:13:41,480
the third one is in the making and the

00:13:38,480 --> 00:13:45,980
community is growing so let me show you

00:13:41,480 --> 00:13:49,310
a small example so this is an

00:13:45,980 --> 00:13:51,260
application that will run a single

00:13:49,310 --> 00:13:53,540
container or a single runnable in a

00:13:51,260 --> 00:13:58,090
cluster and all that it's going to do is

00:13:53,540 --> 00:14:01,160
it's going to log a message hello world

00:13:58,090 --> 00:14:03,020
so in order to define the application

00:14:01,160 --> 00:14:07,160
all I need to do is is define this

00:14:03,020 --> 00:14:10,000
runnable so all I need to do and then I

00:14:07,160 --> 00:14:14,710
need to start the application for that I

00:14:10,000 --> 00:14:17,420
create a yarn twill runner service which

00:14:14,710 --> 00:14:21,110
connects to the yawn resource manager

00:14:17,420 --> 00:14:25,460
and it can then start the application

00:14:21,110 --> 00:14:29,690
for me it's that simple a similar

00:14:25,460 --> 00:14:32,710
application using raw yarn api's would

00:14:29,690 --> 00:14:37,810
be Steve how many lines of code

00:14:32,710 --> 00:14:40,250
hundreds five hundredths I don't know so

00:14:37,810 --> 00:14:47,150
so this is the simplicity in the power

00:14:40,250 --> 00:14:51,350
of twelve and it's easy now what's the

00:14:47,150 --> 00:14:53,900
architecture here the idea is that in

00:14:51,350 --> 00:14:56,210
your application you define twill run a

00:14:53,900 --> 00:14:57,950
bolts and that's the only interface that

00:14:56,210 --> 00:15:00,920
you need to define your application and

00:14:57,950 --> 00:15:03,070
it's very similar to Java threads and

00:15:00,920 --> 00:15:05,330
then there's at will run our service the

00:15:03,070 --> 00:15:07,910
anything that's green here is part of

00:15:05,330 --> 00:15:10,040
the twill framework once you submit your

00:15:07,910 --> 00:15:12,710
jobs to the twill Runner that will

00:15:10,040 --> 00:15:15,890
runner will start a generic application

00:15:12,710 --> 00:15:18,650
master which knows how to negotiate with

00:15:15,890 --> 00:15:20,240
the resource manager and then all of the

00:15:18,650 --> 00:15:22,520
tasks that you've defined all the runner

00:15:20,240 --> 00:15:26,090
bolts they will run in containers and

00:15:22,520 --> 00:15:28,940
they'll be wrapped into at will we call

00:15:26,090 --> 00:15:30,660
them twelve task runners or twill I'm

00:15:28,940 --> 00:15:34,830
not exactly sure

00:15:30,660 --> 00:15:36,720
and so you really don't need to worry

00:15:34,830 --> 00:15:38,580
about how they are started all right all

00:15:36,720 --> 00:15:41,490
that boilerplate code is in the green

00:15:38,580 --> 00:15:43,410
areas in this diagram and the only

00:15:41,490 --> 00:15:46,410
protocol that you need to learn now is

00:15:43,410 --> 00:15:50,420
this API between the 12 Runner and your

00:15:46,410 --> 00:15:54,210
12 lines and it's and it's fairly easy

00:15:50,420 --> 00:15:58,620
okay so the first example we have had

00:15:54,210 --> 00:16:00,960
only a single runnable what if I need an

00:15:58,620 --> 00:16:03,300
application that has more than one type

00:16:00,960 --> 00:16:08,280
of task say I have a producer and a

00:16:03,300 --> 00:16:12,750
consumer well I can do that of course in

00:16:08,280 --> 00:16:15,420
swill so I can use a slightly more more

00:16:12,750 --> 00:16:18,510
verbose Builder pattern to define my

00:16:15,420 --> 00:16:21,060
application and now in this example it's

00:16:18,510 --> 00:16:25,350
a crawler and an indexer and so I define

00:16:21,060 --> 00:16:27,990
these two runner bolts add them to my

00:16:25,350 --> 00:16:31,920
application build it and then I can

00:16:27,990 --> 00:16:36,870
submit it just like I could submit that

00:16:31,920 --> 00:16:39,470
simple hello world that before so a lot

00:16:36,870 --> 00:16:43,470
of the complexity is is taken away and

00:16:39,470 --> 00:16:46,920
that in itself is is very helpful I

00:16:43,470 --> 00:16:49,170
think but in addition to that and and

00:16:46,920 --> 00:16:53,550
Steve mentioned that in his talk there

00:16:49,170 --> 00:16:57,080
are certain common patterns that many

00:16:53,550 --> 00:17:00,150
distributed applications implement and

00:16:57,080 --> 00:17:02,310
in addition to the simplicity that tool

00:17:00,150 --> 00:17:04,829
provides it also provides some of these

00:17:02,310 --> 00:17:07,860
patterns out of the box and you can just

00:17:04,829 --> 00:17:11,520
reuse that in your application so one of

00:17:07,860 --> 00:17:14,640
those is logging we saw in this example

00:17:11,520 --> 00:17:19,439
that typically a Hadoop application logs

00:17:14,640 --> 00:17:21,660
to some files and those files there on

00:17:19,439 --> 00:17:23,130
the local file system of the notes in

00:17:21,660 --> 00:17:26,280
the Hadoop cluster right and when the

00:17:23,130 --> 00:17:28,890
job is done the the resource manager or

00:17:26,280 --> 00:17:30,420
the node manager will copy them to HDFS

00:17:28,890 --> 00:17:35,430
and then they're available for you and

00:17:30,420 --> 00:17:38,700
so on but if you write say a real-time

00:17:35,430 --> 00:17:41,280
event stream processing engine that's

00:17:38,700 --> 00:17:44,190
never going to end it just keeps running

00:17:41,280 --> 00:17:46,170
and your your job will never terminate

00:17:44,190 --> 00:17:49,680
and so your logs will never be available

00:17:46,170 --> 00:17:52,080
in a central place and plus if it's a

00:17:49,680 --> 00:17:53,970
real-time application you would like to

00:17:52,080 --> 00:17:56,220
have insights about the behavior of your

00:17:53,970 --> 00:17:59,460
application in real time all right you

00:17:56,220 --> 00:18:01,230
want your logs in real time and that's

00:17:59,460 --> 00:18:03,480
not that easy to do

00:18:01,230 --> 00:18:06,450
but fortunately there's a great

00:18:03,480 --> 00:18:08,250
technology called Kafka so what we did

00:18:06,450 --> 00:18:10,590
in drill is when you start a twill

00:18:08,250 --> 00:18:12,450
application the application master will

00:18:10,590 --> 00:18:16,290
actually run an embedded instance of

00:18:12,450 --> 00:18:19,680
Kafka and all the tasks all the runner

00:18:16,290 --> 00:18:23,340
bolts you have when they omit locks we

00:18:19,680 --> 00:18:25,800
inject a specific log appender that

00:18:23,340 --> 00:18:27,750
sends these log messages to Kafka and

00:18:25,800 --> 00:18:32,090
now from your tool client you can

00:18:27,750 --> 00:18:32,090
retrieve those log messages in real time

00:18:32,510 --> 00:18:37,860
very nice and the good thing here again

00:18:36,060 --> 00:18:40,550
is you don't need to know how Kafka

00:18:37,860 --> 00:18:43,440
works all you need to know is how this

00:18:40,550 --> 00:18:45,840
what's the twill API to do this right

00:18:43,440 --> 00:18:49,230
and really the only thing you have to do

00:18:45,840 --> 00:18:51,300
is you have to add a log Handler and log

00:18:49,230 --> 00:18:53,940
Handler api's is just a very simple

00:18:51,300 --> 00:18:57,090
callback api on error on warning on

00:18:53,940 --> 00:18:59,460
debug and there you can just reuse an

00:18:57,090 --> 00:19:06,030
existing handler that we have or you can

00:18:59,460 --> 00:19:09,750
just write your own another feature we

00:19:06,030 --> 00:19:12,120
call it the the resource report when you

00:19:09,750 --> 00:19:14,220
start an application in the cluster it's

00:19:12,120 --> 00:19:15,990
gonna run somewhere there but you don't

00:19:14,220 --> 00:19:18,450
really know anything about it you know

00:19:15,990 --> 00:19:20,880
maybe you know it has ten nodes maybe

00:19:18,450 --> 00:19:23,070
you don't what

00:19:20,880 --> 00:19:25,470
twill does is it gives you this

00:19:23,070 --> 00:19:29,280
information as a resource report you can

00:19:25,470 --> 00:19:31,200
talk to it using rest and it'll tell you

00:19:29,280 --> 00:19:33,090
about the current state of the

00:19:31,200 --> 00:19:36,150
application how much memory is it using

00:19:33,090 --> 00:19:38,220
how many virtual course is it using how

00:19:36,150 --> 00:19:39,750
many instances are there how many

00:19:38,220 --> 00:19:42,600
instances are actually life and are

00:19:39,750 --> 00:19:46,740
still sending heartbeats what are the

00:19:42,600 --> 00:19:49,650
hosts where it's running and so on this

00:19:46,740 --> 00:19:51,570
is then registered this rest endpoint is

00:19:49,650 --> 00:19:54,510
registered as the tracking URL in yarn

00:19:51,570 --> 00:19:55,800
so when you go to the yarn UI you can

00:19:54,510 --> 00:19:56,550
just click through and you get that

00:19:55,800 --> 00:19:59,460
information

00:19:56,550 --> 00:20:02,130
but there's also a way to get that

00:19:59,460 --> 00:20:04,650
information programmatically from your

00:20:02,130 --> 00:20:08,820
client and we will see later how that

00:20:04,650 --> 00:20:10,740
can be very useful okay so now it will

00:20:08,820 --> 00:20:13,650
allows me to run an application let's

00:20:10,740 --> 00:20:15,720
say my application runs for ten hours so

00:20:13,650 --> 00:20:17,970
in the meantime I call it a day I go

00:20:15,720 --> 00:20:21,240
home close my laptop I lose the

00:20:17,970 --> 00:20:23,580
connection so now at home I open my

00:20:21,240 --> 00:20:26,400
laptop again and I'm not connected

00:20:23,580 --> 00:20:27,660
anymore right so what can I do I want to

00:20:26,400 --> 00:20:31,800
I want to connect back to that

00:20:27,660 --> 00:20:33,720
application right and of course that's a

00:20:31,800 --> 00:20:36,930
that's a pattern that everybody wants

00:20:33,720 --> 00:20:40,260
and it's will implements that using

00:20:36,930 --> 00:20:42,560
zookeeper so again this application

00:20:40,260 --> 00:20:44,760
master here it records the state

00:20:42,560 --> 00:20:48,360
especially where it's running in

00:20:44,760 --> 00:20:50,580
zookeeper and when you start a new twill

00:20:48,360 --> 00:20:52,200
client it can use that information in

00:20:50,580 --> 00:20:54,690
zookeeper to reconnect to a running

00:20:52,200 --> 00:20:56,580
application and can then get a resource

00:20:54,690 --> 00:20:59,460
report or to other things

00:20:56,580 --> 00:21:06,440
lifecycle management and the API is

00:20:59,460 --> 00:21:10,070
again our very simple command messages

00:21:06,440 --> 00:21:12,660
another very common pattern I'm running

00:21:10,070 --> 00:21:14,940
say I'm running tender scene indexers

00:21:12,660 --> 00:21:17,460
and at some point I want to take a

00:21:14,940 --> 00:21:20,490
snapshot I want them all to to flush at

00:21:17,460 --> 00:21:23,340
the same time int well you can do that

00:21:20,490 --> 00:21:27,200
by sending commands to every runnable

00:21:23,340 --> 00:21:29,730
and again this happens through zookeeper

00:21:27,200 --> 00:21:33,240
that's well client again just uses an

00:21:29,730 --> 00:21:35,640
API of the tool runner but that will

00:21:33,240 --> 00:21:38,930
then this arrow goes in the wrong

00:21:35,640 --> 00:21:42,810
direction by the way that that will then

00:21:38,930 --> 00:21:45,090
put that message into zookeeper all the

00:21:42,810 --> 00:21:48,870
tasks because they are wrapped into at

00:21:45,090 --> 00:21:52,230
will kind of a twill wrapper are

00:21:48,870 --> 00:21:54,120
actually listening and watching those

00:21:52,230 --> 00:21:56,550
zookeeper notes and when a command

00:21:54,120 --> 00:21:59,720
appears there they all have a call back

00:21:56,550 --> 00:22:05,430
and and then that command gets executed

00:21:59,720 --> 00:22:07,920
so in the runnable I just have to

00:22:05,430 --> 00:22:09,529
implement the method to handle a command

00:22:07,920 --> 00:22:16,549
and the command is just a simple

00:22:09,529 --> 00:22:19,220
simple string basically okay elastics

00:22:16,549 --> 00:22:20,929
the scaling how often do I run an

00:22:19,220 --> 00:22:23,360
application and I realize it doesn't

00:22:20,929 --> 00:22:25,759
have enough capacity I want to add five

00:22:23,360 --> 00:22:29,360
notes or maybe I'm using too much

00:22:25,759 --> 00:22:32,289
capacity I want to remove for with twill

00:22:29,360 --> 00:22:35,240
you can change that with a single call

00:22:32,289 --> 00:22:38,059
so if I started with 10 instances or I

00:22:35,240 --> 00:22:41,840
started with five instances I have a

00:22:38,059 --> 00:22:44,929
simple API using the controller to

00:22:41,840 --> 00:22:46,700
change the instances to ten internally

00:22:44,929 --> 00:22:50,919
this is also implemented as a command

00:22:46,700 --> 00:22:53,360
message but you don't need to know that

00:22:50,919 --> 00:22:55,639
next interesting topic is service

00:22:53,360 --> 00:23:00,100
discovery Steve already talked about

00:22:55,639 --> 00:23:04,460
that if you say you've run a web service

00:23:00,100 --> 00:23:07,100
in your cluster but because it runs in

00:23:04,460 --> 00:23:09,320
yarn you don't know where it's running

00:23:07,100 --> 00:23:12,230
you know it's in one of these 100 nodes

00:23:09,320 --> 00:23:14,029
I have ten instances of my Tomcat but

00:23:12,230 --> 00:23:17,330
you don't know exactly where to connect

00:23:14,029 --> 00:23:20,830
to so you need a way to discover that

00:23:17,330 --> 00:23:25,100
and int will you can do that and again

00:23:20,830 --> 00:23:29,600
using zookeeper every task can register

00:23:25,100 --> 00:23:30,980
itself and that adds this information to

00:23:29,600 --> 00:23:32,600
zookeeper what's the host where it's

00:23:30,980 --> 00:23:35,960
running and what's the port that it's

00:23:32,600 --> 00:23:37,549
that it's listening on and then through

00:23:35,960 --> 00:23:41,480
the troll client I can find out that

00:23:37,549 --> 00:23:44,899
information all right and again very

00:23:41,480 --> 00:23:46,549
simple API in that we'll we'll run a

00:23:44,899 --> 00:23:48,740
bowl I have an initialized method and

00:23:46,549 --> 00:23:51,860
that gets at will context that context

00:23:48,740 --> 00:23:53,720
gives me access to zookeeper and there

00:23:51,860 --> 00:23:57,169
for example I can announce my service

00:23:53,720 --> 00:23:58,940
and then on the client side I can just

00:23:57,169 --> 00:24:07,399
use the controller to discover that

00:23:58,940 --> 00:24:11,360
service simplicity okay one problem that

00:24:07,399 --> 00:24:13,879
we often have is I have an existing jar

00:24:11,360 --> 00:24:16,009
existing Java code and it has

00:24:13,879 --> 00:24:18,950
dependencies on some version of a

00:24:16,009 --> 00:24:21,139
library and happens to conflict with a

00:24:18,950 --> 00:24:22,920
newer version or an older version of

00:24:21,139 --> 00:24:25,800
that same library that Hadoop uses

00:24:22,920 --> 00:24:29,640
and now I'm I'm screwed I can't do

00:24:25,800 --> 00:24:33,660
anything unless I find a way to avoid

00:24:29,640 --> 00:24:36,060
loading the Hadoop one and one way of

00:24:33,660 --> 00:24:38,160
doing that is to building it to build a

00:24:36,060 --> 00:24:42,480
bundle jar that contains all the

00:24:38,160 --> 00:24:45,960
dependencies of the application and then

00:24:42,480 --> 00:24:48,240
so for example here I could have a main

00:24:45,960 --> 00:24:49,980
class may be a record class and then I

00:24:48,240 --> 00:24:52,770
need an explicit version of guava

00:24:49,980 --> 00:24:54,360
16:01 guava is one of the biggest pain

00:24:52,770 --> 00:24:57,230
points because they broke backward

00:24:54,360 --> 00:25:00,600
compatibility in a recent version and

00:24:57,230 --> 00:25:04,980
now this will be inside of my jar and I

00:25:00,600 --> 00:25:07,440
can submit that to toot will there's

00:25:04,980 --> 00:25:10,950
standard ways of building bundle jars is

00:25:07,440 --> 00:25:16,280
actually an OS GI pattern and I can then

00:25:10,950 --> 00:25:20,280
execute that int will we have done this

00:25:16,280 --> 00:25:22,440
- to run presto inside of yarn presto is

00:25:20,280 --> 00:25:25,200
a sequel engine that was built at

00:25:22,440 --> 00:25:28,020
Facebook it's similar to hive or Impala

00:25:25,200 --> 00:25:29,730
and we just wanted to know whether it's

00:25:28,020 --> 00:25:32,640
possible to run something like this in

00:25:29,730 --> 00:25:34,830
int will and it would have been

00:25:32,640 --> 00:25:37,110
straightforward if not for the version

00:25:34,830 --> 00:25:39,330
conflicts so this feature was explicitly

00:25:37,110 --> 00:25:40,830
added for running existing applications

00:25:39,330 --> 00:25:44,460
over which we don't have control

00:25:40,830 --> 00:25:50,180
we can't change their dependency

00:25:44,460 --> 00:25:52,560
versions okay last but not least

00:25:50,180 --> 00:25:55,350
distributed debugging have you ever run

00:25:52,560 --> 00:26:01,410
a distributed application and it crashes

00:25:55,350 --> 00:26:03,450
and you don't know why never and all

00:26:01,410 --> 00:26:07,550
right now you add lots of logging to the

00:26:03,450 --> 00:26:10,140
application and it doesn't crash anymore

00:26:07,550 --> 00:26:13,620
race confusion race condition is gone

00:26:10,140 --> 00:26:16,890
who knows so um wouldn't it be nice if I

00:26:13,620 --> 00:26:19,140
could just go into my IDE and say

00:26:16,890 --> 00:26:24,630
connect the debugger to this application

00:26:19,140 --> 00:26:26,880
so this runnable of that type and that's

00:26:24,630 --> 00:26:29,040
what we did with 12 so when you have an

00:26:26,880 --> 00:26:30,780
application you can start it with

00:26:29,040 --> 00:26:32,820
debugging enabled and when you do that

00:26:30,780 --> 00:26:34,550
you actually say these are the runner

00:26:32,820 --> 00:26:37,850
bolts for which I won

00:26:34,550 --> 00:26:41,840
enable debugging what twill does is it

00:26:37,850 --> 00:26:43,790
starts the JVM with the option to have

00:26:41,840 --> 00:26:47,060
the debugging port open right there's a

00:26:43,790 --> 00:26:51,410
standard Java protocol to do that by

00:26:47,060 --> 00:26:53,660
default Java won't do that and so what

00:26:51,410 --> 00:26:56,660
you have to do is you have to find the

00:26:53,660 --> 00:26:58,880
free port on the machine and then start

00:26:56,660 --> 00:27:01,970
the JVM with that option it's kind of

00:26:58,880 --> 00:27:03,740
tricky to do that because the JVM that

00:27:01,970 --> 00:27:06,890
is open for debugging does not know

00:27:03,740 --> 00:27:09,530
about its own port Java is kind of weird

00:27:06,890 --> 00:27:11,630
in that way right so um if you want to

00:27:09,530 --> 00:27:13,280
implement that yourself it's going to

00:27:11,630 --> 00:27:17,060
take you a couple days to get to make it

00:27:13,280 --> 00:27:22,220
work so int will this is all this little

00:27:17,060 --> 00:27:24,680
hacking has been done and we already saw

00:27:22,220 --> 00:27:29,540
earlier there's a way to get a resource

00:27:24,680 --> 00:27:31,100
report which informs you about where do

00:27:29,540 --> 00:27:33,980
all my run doubles run how many are

00:27:31,100 --> 00:27:36,890
there and so on right so through the

00:27:33,980 --> 00:27:38,900
same report resource report you can also

00:27:36,890 --> 00:27:41,420
find out about the debugging parts of

00:27:38,900 --> 00:27:43,670
each of the containers all right and

00:27:41,420 --> 00:27:49,520
then you just attach your IDE to it and

00:27:43,670 --> 00:27:52,550
you can debug one note here is some

00:27:49,520 --> 00:27:54,590
twill is as secure as the Hadoop cluster

00:27:52,550 --> 00:27:56,620
that you run in so if you have Kerberos

00:27:54,590 --> 00:28:00,890
enabled Twitter's totally fine with that

00:27:56,620 --> 00:28:04,610
the moment you do this you lose security

00:28:00,890 --> 00:28:07,760
because Java has no way no way to secure

00:28:04,610 --> 00:28:10,310
that debugging port so don't do it in

00:28:07,760 --> 00:28:14,930
production don't do it when you don't

00:28:10,310 --> 00:28:17,930
know that the environment is safe okay

00:28:14,930 --> 00:28:22,610
there's quite a few more features but I

00:28:17,930 --> 00:28:25,220
want to come to an end there's also

00:28:22,610 --> 00:28:27,800
quite a few features that we still have

00:28:25,220 --> 00:28:32,630
to build so right now

00:28:27,800 --> 00:28:34,400
twill has a nice API that you can use

00:28:32,630 --> 00:28:35,290
but you have to program against it in

00:28:34,400 --> 00:28:38,930
Java

00:28:35,290 --> 00:28:42,020
just for usability we just want to build

00:28:38,930 --> 00:28:43,700
lots and lots of command-line tools for

00:28:42,020 --> 00:28:45,470
example finding out the debugging part

00:28:43,700 --> 00:28:46,610
of that runnable that you started right

00:28:45,470 --> 00:28:47,340
now you have to write a little Java

00:28:46,610 --> 00:28:50,040
program

00:28:47,340 --> 00:28:54,390
and printed would be nice to have a

00:28:50,040 --> 00:28:56,250
little command-line tool so um yeah as a

00:28:54,390 --> 00:28:57,900
reminder it's an open source project if

00:28:56,250 --> 00:28:59,220
you want to contribute these are really

00:28:57,900 --> 00:29:06,810
nice little things that you can start

00:28:59,220 --> 00:29:10,020
with then there's some nice distributed

00:29:06,810 --> 00:29:12,840
application patterns I wanna say like

00:29:10,020 --> 00:29:15,330
distributed coordination let's say you

00:29:12,840 --> 00:29:17,600
want to do leader election let's say you

00:29:15,330 --> 00:29:20,130
want to do some synchronization barrier

00:29:17,600 --> 00:29:22,710
this these are things that many

00:29:20,130 --> 00:29:26,340
applications need and it's our goal to

00:29:22,710 --> 00:29:29,640
add those things to twill there's

00:29:26,340 --> 00:29:31,230
actually the the curator the Apache

00:29:29,640 --> 00:29:35,310
curator that implements some of these

00:29:31,230 --> 00:29:37,590
recipes we might include that through

00:29:35,310 --> 00:29:41,910
curator we might we don't know yet how

00:29:37,590 --> 00:29:44,130
to get it in anyway that's on the

00:29:41,910 --> 00:29:45,900
roadmap we want to be able to run on

00:29:44,130 --> 00:29:48,960
Java applications lots of data

00:29:45,900 --> 00:29:50,820
scientists love to write Python code you

00:29:48,960 --> 00:29:54,120
can't do that right now with 12 but we

00:29:50,820 --> 00:29:56,910
will assume we want to enhance the way

00:29:54,120 --> 00:29:59,910
that you can do lifecycle management of

00:29:56,910 --> 00:30:02,460
your application right now you can start

00:29:59,910 --> 00:30:05,550
it you can send commands to it and you

00:30:02,460 --> 00:30:07,080
can stop it but and you can wait for it

00:30:05,550 --> 00:30:13,350
but it would be nice if you could pause

00:30:07,080 --> 00:30:15,420
it and then resume it it would be nice

00:30:13,350 --> 00:30:17,060
if you could collect metrics in the same

00:30:15,420 --> 00:30:18,990
way that you can collect block messages

00:30:17,060 --> 00:30:20,340
now that would give you much better

00:30:18,990 --> 00:30:22,260
insights into the performance

00:30:20,340 --> 00:30:23,970
characteristics of the application where

00:30:22,260 --> 00:30:26,550
are the hot spots so I have a

00:30:23,970 --> 00:30:30,000
distribution skew or not you need

00:30:26,550 --> 00:30:31,890
metrics for that and here's one killer

00:30:30,000 --> 00:30:35,580
feature that that's currently being

00:30:31,890 --> 00:30:37,290
built is a local Runner service suppose

00:30:35,580 --> 00:30:39,660
you could run any distributed

00:30:37,290 --> 00:30:42,420
application on your laptop in memory and

00:30:39,660 --> 00:30:46,200
threads and then you could just debug

00:30:42,420 --> 00:30:47,880
you could just develop and test on your

00:30:46,200 --> 00:30:50,430
laptop and you never need to deal with a

00:30:47,880 --> 00:30:54,480
cluster until you really go and want to

00:30:50,430 --> 00:30:56,820
try that large-scale because if you look

00:30:54,480 --> 00:30:59,950
at the API sets we'll has there's not a

00:30:56,820 --> 00:31:03,160
single yarn or Hadoop dependency in

00:30:59,950 --> 00:31:04,870
all the api's are independent of yarn

00:31:03,160 --> 00:31:06,970
then there's implementations of those

00:31:04,870 --> 00:31:09,280
api's and one of them is the yarn

00:31:06,970 --> 00:31:10,830
implementation but we're currently

00:31:09,280 --> 00:31:12,820
working on a multi-threaded

00:31:10,830 --> 00:31:16,900
implementation and that would be really

00:31:12,820 --> 00:31:17,770
nice yeah and lots and lots of other

00:31:16,900 --> 00:31:23,559
things to come

00:31:17,770 --> 00:31:27,000
suggestions are welcome summary yarn is

00:31:23,559 --> 00:31:31,120
powerful it allows you to run arbitrary

00:31:27,000 --> 00:31:35,380
applications in a Hadoop cluster but

00:31:31,120 --> 00:31:37,300
you're on this complex kind of difficult

00:31:35,380 --> 00:31:40,800
to learn protocols a lot of boilerplate

00:31:37,300 --> 00:31:45,070
code steep learning curve

00:31:40,800 --> 00:31:46,750
twill makes yarn easy the programming

00:31:45,070 --> 00:31:51,250
model is similar to Java threads and

00:31:46,750 --> 00:31:53,559
everybody knows how to do that and so

00:31:51,250 --> 00:31:55,300
what you get as a sum of all these is

00:31:53,559 --> 00:31:57,940
you get a productivity boost you get all

00:31:55,300 --> 00:32:01,240
the power of yarn with the simplicity of

00:31:57,940 --> 00:32:04,120
Java threads you're going to develop

00:32:01,240 --> 00:32:09,070
distributed applications in two hours

00:32:04,120 --> 00:32:10,990
three hours instead of two months last

00:32:09,070 --> 00:32:16,900
thing to mention twill is open source

00:32:10,990 --> 00:32:19,780
it's in the Apache Incubator any open

00:32:16,900 --> 00:32:23,410
source project can only live if it's

00:32:19,780 --> 00:32:26,860
community lives so we need contributors

00:32:23,410 --> 00:32:29,170
we need committers we need people who

00:32:26,860 --> 00:32:31,990
want to volunteer to do the hard work I

00:32:29,170 --> 00:32:35,020
want on tiered who else is volunteering

00:32:31,990 --> 00:32:40,750
Steve is oh yeah you are you've you've

00:32:35,020 --> 00:32:46,270
been volunteered so it's lots of fun to

00:32:40,750 --> 00:32:48,940
work on these things so go to the

00:32:46,270 --> 00:32:51,970
websites go to the mailing list maybe

00:32:48,940 --> 00:32:53,980
you find something interesting and with

00:32:51,970 --> 00:32:59,190
that I think we have about five minutes

00:32:53,980 --> 00:32:59,190
for questions thank you

00:33:08,120 --> 00:33:16,730
hey you talked about metrics I assumed

00:33:12,360 --> 00:33:18,830
you meant the yarn metrics right like

00:33:16,730 --> 00:33:21,540
metrics metrics yes

00:33:18,830 --> 00:33:24,090
what about application metrics that

00:33:21,540 --> 00:33:25,620
that's what I was okay so yarn gives you

00:33:24,090 --> 00:33:26,910
some metrics but that is very useful

00:33:25,620 --> 00:33:29,010
because you're on doesn't know what your

00:33:26,910 --> 00:33:31,230
application is - exactly that's one

00:33:29,010 --> 00:33:34,590
thing I'm right now that this is

00:33:31,230 --> 00:33:37,050
probably not implemented yet what's your

00:33:34,590 --> 00:33:39,620
recommendation to do that just have have

00:33:37,050 --> 00:33:42,830
the application just talk to some

00:33:39,620 --> 00:33:45,420
graphite server or something or what you

00:33:42,830 --> 00:33:48,120
so so there's implementation and there's

00:33:45,420 --> 00:33:51,900
ap is right so if you look at how we do

00:33:48,120 --> 00:33:58,770
logging there's simply a simple way to

00:33:51,900 --> 00:34:01,350
emit logs right so um I would think it's

00:33:58,770 --> 00:34:03,600
not even here so it's it's simply a an

00:34:01,350 --> 00:34:06,390
SL f4j lock offender that we use for

00:34:03,600 --> 00:34:08,940
logging right for metrics I would think

00:34:06,390 --> 00:34:10,320
there there is an open-source metrics

00:34:08,940 --> 00:34:13,860
library I think it's just called metrics

00:34:10,320 --> 00:34:15,990
and it's all dapper Dapper thing and

00:34:13,860 --> 00:34:18,630
those api's are actually powerful enough

00:34:15,990 --> 00:34:21,540
and what I see is that we'll we'll have

00:34:18,630 --> 00:34:23,610
an implementation of those api's that in

00:34:21,540 --> 00:34:26,130
the background maybe uses Kafka or maybe

00:34:23,610 --> 00:34:31,640
uses something else to to collect those

00:34:26,130 --> 00:34:31,640
metrics sounds good yeah thanks

00:34:33,890 --> 00:34:40,200
hi in in Steve sake men should this the

00:34:37,710 --> 00:34:43,530
spring XD I'm just wondering how easy it

00:34:40,200 --> 00:34:46,140
would be to put Porter spring app into

00:34:43,530 --> 00:34:49,430
12 well you have to look at something

00:34:46,140 --> 00:34:54,090
yes that's a good question I haven't I

00:34:49,430 --> 00:34:58,290
can't give you any on that I I feel that

00:34:54,090 --> 00:35:02,760
spring is definitely more mature and and

00:34:58,290 --> 00:35:15,480
more powerful at this time also much

00:35:02,760 --> 00:35:24,600
more complex programming in XML no

00:35:15,480 --> 00:35:26,880
questions I don't oh there's someone he

00:35:24,600 --> 00:35:29,670
waited for you to come all the way to

00:35:26,880 --> 00:35:31,470
the front to make you walk actually I'm

00:35:29,670 --> 00:35:32,640
not a young expert but as far as I

00:35:31,470 --> 00:35:36,620
understood that my produce

00:35:32,640 --> 00:35:41,640
implementation then that runs on top of

00:35:36,620 --> 00:35:43,320
yarn is also a yarn client right so

00:35:41,640 --> 00:35:48,330
there is a young young client for

00:35:43,320 --> 00:35:49,860
MapReduce yes there there is a an

00:35:48,330 --> 00:35:52,980
application master the MapReduce

00:35:49,860 --> 00:35:55,260
application master and there is a hadith

00:35:52,980 --> 00:35:57,420
client that allows you to submit

00:35:55,260 --> 00:36:00,150
MapReduce jobs so that comes built in

00:35:57,420 --> 00:36:03,180
with Hadoop so do you know whether it

00:36:00,150 --> 00:36:06,630
will make sense to port it to twill and

00:36:03,180 --> 00:36:08,880
how much effort it will be and if you

00:36:06,630 --> 00:36:13,980
have enough features and will right now

00:36:08,880 --> 00:36:16,980
that you fully implement it I would say

00:36:13,980 --> 00:36:19,620
in theory it's possible but MapReduce is

00:36:16,980 --> 00:36:22,140
such an elaborate framework and so much

00:36:19,620 --> 00:36:25,710
work has gone into how MapReduce

00:36:22,140 --> 00:36:29,010
actually drives execution there is lots

00:36:25,710 --> 00:36:30,930
of subtleties about in what I mean how

00:36:29,010 --> 00:36:32,880
soon can you start with users there

00:36:30,930 --> 00:36:35,280
speculative execution all these things

00:36:32,880 --> 00:36:38,120
it's certainly possible int will but I

00:36:35,280 --> 00:36:38,120
wouldn't say it's natural

00:36:40,260 --> 00:36:47,670
any wallets thank you very much thank

00:36:45,610 --> 00:36:47,670

YouTube URL: https://www.youtube.com/watch?v=IyjRVzKPhUo


