Title: Berlin Buzzwords 2015: Ted Dunning -What and Why and How: Apache Drill 1.0 #bbuzz
Publication date: 2015-06-05
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	The 1.0 release of Apache Drill does SQL on Hadoop, but with some big differences. 
The biggest difference is that Drill changes SQL from a strongly typed language into a late binding language without losing performance. This allows Drill to process complex structured data in addition to relational data. By dynamically generating code that matches the data types and structures observed in the data, Drill can be both agile as well as very fast. Drill can analyze complex data directly with no ETL steps.

Drill also introduces a view-based security model that uses file-system permissions to control access to data at an extremely fine-grained level that makes secure access easy to control.

These changes have huge practical impact when it comes to writing real applications.
I will give several practical examples of how Drill makes it easier to analyze data. This will include examples of how to use Drill to analyze real complex data.

Read more:
https://2015.berlinbuzzwords.de/session/what-and-why-and-how-apache-drill-10

About Ted Dunning:
https://2015.berlinbuzzwords.de/users/ted-dunning

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,790 --> 00:00:11,380
so we have a lot of things to talk about

00:00:08,250 --> 00:00:13,900
here this is going to be about

00:00:11,380 --> 00:00:18,400
drill which just recently had a one

00:00:13,900 --> 00:00:20,680
point O release it's a big deal it's an

00:00:18,400 --> 00:00:22,570
interesting project I'm going to be

00:00:20,680 --> 00:00:25,330
talking about that the original speaker

00:00:22,570 --> 00:00:27,220
was Michael housing bloss he says that

00:00:25,330 --> 00:00:29,200
he's very sorry couldn't make it but he

00:00:27,220 --> 00:00:31,779
can't make it he had to be at a big

00:00:29,200 --> 00:00:36,100
product launch so I want to talk about

00:00:31,779 --> 00:00:39,730
drill and drill is a surprising project

00:00:36,100 --> 00:00:41,980
its sequel on Hadoop that sort of thing

00:00:39,730 --> 00:00:46,090
actually its sequel on all kinds of

00:00:41,980 --> 00:00:47,920
things and that's what Andrew Bruce said

00:00:46,090 --> 00:00:51,670
about it recently in GigaOM that it

00:00:47,920 --> 00:00:54,460
really is not just sequel on a dupe but

00:00:51,670 --> 00:00:57,040
its sequel on just about everything you

00:00:54,460 --> 00:01:00,700
you could imagine so we're going to talk

00:00:57,040 --> 00:01:04,540
about it what is it what makes it

00:01:00,700 --> 00:01:06,970
special and a little bit on how this is

00:01:04,540 --> 00:01:08,380
done now unfortunately I have a lot of

00:01:06,970 --> 00:01:10,600
slides so I'm going to have to go fast

00:01:08,380 --> 00:01:13,240
the slides will be available though for

00:01:10,600 --> 00:01:15,189
reference and you can go in it may be

00:01:13,240 --> 00:01:17,140
difficult to read some of the displays

00:01:15,189 --> 00:01:19,689
and things like that but you can go back

00:01:17,140 --> 00:01:21,280
in and take a look at it later but

00:01:19,689 --> 00:01:24,490
you're going to also try these things

00:01:21,280 --> 00:01:26,229
very easily vampire has a special by

00:01:24,490 --> 00:01:29,499
registration sort of button you can push

00:01:26,229 --> 00:01:31,630
it will spin up a five node cluster that

00:01:29,499 --> 00:01:33,999
will last for six hours and you can play

00:01:31,630 --> 00:01:35,740
with it drill will be pre-installed data

00:01:33,999 --> 00:01:37,929
will be pre-installed so you can just

00:01:35,740 --> 00:01:40,030
try it you could also just download it

00:01:37,929 --> 00:01:42,280
practically during the talk here it

00:01:40,030 --> 00:01:45,369
takes about five minutes to install you

00:01:42,280 --> 00:01:48,310
ontar it and it just runs now the first

00:01:45,369 --> 00:01:50,319
thing that drill is is its sequel you

00:01:48,310 --> 00:01:52,810
know maybe not in your family but in my

00:01:50,319 --> 00:01:54,819
family of course we had these things at

00:01:52,810 --> 00:01:57,249
home and in the kitchen and that sort of

00:01:54,819 --> 00:02:01,689
thing so this is sequel like you've

00:01:57,249 --> 00:02:04,899
always expected and always known it has

00:02:01,689 --> 00:02:07,899
the standard sort of syntax no no

00:02:04,899 --> 00:02:10,000
strange exceptions it has all of the

00:02:07,899 --> 00:02:12,340
standard types all of the decimal types

00:02:10,000 --> 00:02:15,340
the VAR binary the VAR char the

00:02:12,340 --> 00:02:18,930
different forms of doubles and so on sub

00:02:15,340 --> 00:02:23,140
queries correlated sub-queries pruning

00:02:18,930 --> 00:02:24,880
an enormous range of complex sequel

00:02:23,140 --> 00:02:28,350
constructs are there

00:02:24,880 --> 00:02:32,830
it therefore supports standard bi tools

00:02:28,350 --> 00:02:36,790
tableau anything that uses odbc excel

00:02:32,830 --> 00:02:40,600
all work with it and all of the standard

00:02:36,790 --> 00:02:43,810
hive UDF censored es also work with it

00:02:40,600 --> 00:02:47,140
works with a hive metadata catalog so

00:02:43,810 --> 00:02:49,450
it's also Punk SQL because it does a lot

00:02:47,140 --> 00:02:51,790
of different things as well starts with

00:02:49,450 --> 00:02:55,060
a standard but then extends it in some

00:02:51,790 --> 00:02:58,390
very very interesting ways notably it

00:02:55,060 --> 00:03:03,850
has more modern syntax available so that

00:02:58,390 --> 00:03:06,220
we can access very directly recursive

00:03:03,850 --> 00:03:08,440
objects so if it's an array you use

00:03:06,220 --> 00:03:10,570
square brackets to index into it if it's

00:03:08,440 --> 00:03:14,260
objects you do standard JavaScript

00:03:10,570 --> 00:03:16,630
styled dot notation to navigate into the

00:03:14,260 --> 00:03:19,210
objects that are stored in the data and

00:03:16,630 --> 00:03:21,670
those objects are first-class in drill

00:03:19,210 --> 00:03:26,640
so you really can do interesting things

00:03:21,670 --> 00:03:29,380
that way you also have file systems as

00:03:26,640 --> 00:03:33,550
organizing principles these were largely

00:03:29,380 --> 00:03:35,860
you know sequel is so old this sounds

00:03:33,550 --> 00:03:38,590
like a joke but it's not sequel is so

00:03:35,860 --> 00:03:41,080
old that it was invented effectively

00:03:38,590 --> 00:03:43,990
before modern file systems were invented

00:03:41,080 --> 00:03:47,440
so the idea of wild cards and path names

00:03:43,990 --> 00:03:50,080
are after sequel therefore sequel has

00:03:47,440 --> 00:03:53,110
nothing in it that really recognizes it

00:03:50,080 --> 00:03:56,260
drill extends that so that directories

00:03:53,110 --> 00:03:59,350
of tables can be viewed as a single

00:03:56,260 --> 00:04:01,120
table by itself and you have elements of

00:03:59,350 --> 00:04:05,230
the columns that you get back which

00:04:01,120 --> 00:04:07,750
describe the path that drill took to get

00:04:05,230 --> 00:04:10,840
to the data we also have more

00:04:07,750 --> 00:04:14,770
interesting data types we have one

00:04:10,840 --> 00:04:16,630
that's called any which means any type

00:04:14,770 --> 00:04:19,900
could be there we have maps we have

00:04:16,630 --> 00:04:23,110
lists and so on the any type is the key

00:04:19,900 --> 00:04:26,170
to another capability drill has which is

00:04:23,110 --> 00:04:29,380
late typing which is almost like dynamic

00:04:26,170 --> 00:04:31,780
typing sequel it self-regulation

00:04:29,380 --> 00:04:34,990
ordinary sequel is a strongly typed

00:04:31,780 --> 00:04:37,780
language and an early binding typed

00:04:34,990 --> 00:04:38,820
language it has to have all of the types

00:04:37,780 --> 00:04:41,490
of everything to

00:04:38,820 --> 00:04:45,930
aired in a schema before you can even

00:04:41,490 --> 00:04:48,540
parse sequel drill has extended that so

00:04:45,930 --> 00:04:50,970
you can parse with partial typing

00:04:48,540 --> 00:04:53,900
information ultimately you may just say

00:04:50,970 --> 00:04:56,160
they seem to claim that that's a table

00:04:53,900 --> 00:05:01,110
therefore I assume it has records of

00:04:56,160 --> 00:05:03,390
type any inside it now later I may find

00:05:01,110 --> 00:05:05,610
out more about the typing and I may be

00:05:03,390 --> 00:05:07,890
able to compile and optimize to a more

00:05:05,610 --> 00:05:10,350
detailed level and then the type will be

00:05:07,890 --> 00:05:12,660
resolved down to a primitive type but

00:05:10,350 --> 00:05:14,910
that will be late binding of typing and

00:05:12,660 --> 00:05:17,370
that gives some very very flexible

00:05:14,910 --> 00:05:20,280
capabilities like the ability to

00:05:17,370 --> 00:05:22,830
interrogate data where then column names

00:05:20,280 --> 00:05:25,380
are not even known until you read the

00:05:22,830 --> 00:05:27,900
data so that's exciting that that then

00:05:25,380 --> 00:05:29,310
requires a number of other operators to

00:05:27,900 --> 00:05:31,980
make that true i'm going to show you

00:05:29,310 --> 00:05:33,660
examples of that so if you have sensor

00:05:31,980 --> 00:05:36,690
analytics or if you have data that's

00:05:33,660 --> 00:05:38,970
changing its structure and its type over

00:05:36,690 --> 00:05:41,640
time you don't have to use alter table

00:05:38,970 --> 00:05:45,600
to go in and fix that you can just query

00:05:41,640 --> 00:05:47,670
the data as it is so let's talk a little

00:05:45,600 --> 00:05:49,890
bit about how it does it drill is

00:05:47,670 --> 00:05:52,230
flexible which of course leads to a

00:05:49,890 --> 00:05:55,560
certain agility and ability to jump high

00:05:52,230 --> 00:05:59,610
buildings it's flexible and it's simple

00:05:55,560 --> 00:06:01,440
to install drill you need one process to

00:05:59,610 --> 00:06:04,290
run it could be an interactive process

00:06:01,440 --> 00:06:06,120
with an embedded so-called drill bit or

00:06:04,290 --> 00:06:08,460
you could have a drill bit that runs

00:06:06,120 --> 00:06:10,650
it's a long life process on your machine

00:06:08,460 --> 00:06:12,600
like a database server even though it's

00:06:10,650 --> 00:06:15,420
not really a database or you can have

00:06:12,600 --> 00:06:18,300
clusters of them running we've tested up

00:06:15,420 --> 00:06:20,700
to hundreds of them and the design is

00:06:18,300 --> 00:06:23,670
designed carefully to avoid in squared

00:06:20,700 --> 00:06:27,210
sort of non-scale abilities it scales up

00:06:23,670 --> 00:06:30,210
quite linearly and and produces very

00:06:27,210 --> 00:06:34,980
very high performance so very very easy

00:06:30,210 --> 00:06:37,710
to build a system around drill you can

00:06:34,980 --> 00:06:40,170
do with a clustered system with map are

00:06:37,710 --> 00:06:43,710
with ordinary hadoop distributions or

00:06:40,170 --> 00:06:46,050
without on a single machine or on many

00:06:43,710 --> 00:06:48,570
machines however you want to get to the

00:06:46,050 --> 00:06:51,180
data however you want to execute it's

00:06:48,570 --> 00:06:52,620
very easy to do now part of the

00:06:51,180 --> 00:06:54,600
flexibility is not just

00:06:52,620 --> 00:06:57,650
in deployment but in the data typing

00:06:54,600 --> 00:07:02,280
itself you can imagine that data has

00:06:57,650 --> 00:07:07,880
multiple axes you can talk about how

00:07:02,280 --> 00:07:07,880
flexible the data is in terms of of

00:07:08,900 --> 00:07:16,139
whether or not it has a schema that's

00:07:13,080 --> 00:07:18,540
predefined or not at the schema end of

00:07:16,139 --> 00:07:20,520
the world is relational data where you

00:07:18,540 --> 00:07:22,919
have to have a schema in order to even

00:07:20,520 --> 00:07:25,830
store the data at all on the completely

00:07:22,919 --> 00:07:27,900
unskilled of the world you have JSON or

00:07:25,830 --> 00:07:31,680
beasts on or things like this where the

00:07:27,900 --> 00:07:36,800
data itself is the schema you can also

00:07:31,680 --> 00:07:40,260
have data which has complex data types

00:07:36,800 --> 00:07:43,590
or data which has only simple data types

00:07:40,260 --> 00:07:46,949
in very regular fields and what drill

00:07:43,590 --> 00:07:50,370
does is it takes us from the inflexible

00:07:46,949 --> 00:07:53,340
non complex world of relational data

00:07:50,370 --> 00:07:55,919
where the cod definitions of what

00:07:53,340 --> 00:07:59,300
relational data are take us directly to

00:07:55,919 --> 00:08:02,490
that definition to the completely

00:07:59,300 --> 00:08:05,360
flexible end of the world the data layer

00:08:02,490 --> 00:08:08,460
the data model inside drill is

00:08:05,360 --> 00:08:11,220
essentially JSON the data representation

00:08:08,460 --> 00:08:13,669
is not the data model is it's that

00:08:11,220 --> 00:08:16,860
flexible now obviously it can handle

00:08:13,669 --> 00:08:19,770
schema full data but it also hands

00:08:16,860 --> 00:08:22,349
handles schema-less data even in the

00:08:19,770 --> 00:08:25,169
same query even in the same table at the

00:08:22,349 --> 00:08:27,990
same time so drill doesn't require

00:08:25,169 --> 00:08:31,410
schema but it can use it the query can

00:08:27,990 --> 00:08:33,630
be planned on files or tables with or

00:08:31,410 --> 00:08:36,450
without early information and it can

00:08:33,630 --> 00:08:38,669
bind late in the planning process and it

00:08:36,450 --> 00:08:43,289
can generate code that's efficient that

00:08:38,669 --> 00:08:46,080
way the guiding principle here is the

00:08:43,289 --> 00:08:50,300
drill will operate at very high speed

00:08:46,080 --> 00:08:53,640
with no metadata centrally stored and no

00:08:50,300 --> 00:08:56,040
metadata until we read the data but it

00:08:53,640 --> 00:08:58,589
will also use that data as soon as it

00:08:56,040 --> 00:09:02,480
can get it so it will operate even

00:08:58,589 --> 00:09:05,130
faster when you have more regular data

00:09:02,480 --> 00:09:06,490
let's walk through some examples and

00:09:05,130 --> 00:09:10,209
these examples are

00:09:06,490 --> 00:09:13,180
are taken largely from the Yelp standard

00:09:10,209 --> 00:09:15,880
data set which is a dump of the Yelp

00:09:13,180 --> 00:09:18,520
database that's intended for use as

00:09:15,880 --> 00:09:20,260
research or educational purposes we

00:09:18,520 --> 00:09:22,959
can't redistribute it but we can show

00:09:20,260 --> 00:09:25,810
you examples from that it's nice because

00:09:22,959 --> 00:09:28,360
it has a couple of properties that make

00:09:25,810 --> 00:09:30,910
it very difficult to work with from the

00:09:28,360 --> 00:09:33,250
standpoint of a standard database for

00:09:30,910 --> 00:09:37,750
one thing all the data is stored in JSON

00:09:33,250 --> 00:09:39,700
in files well that that's incredibly

00:09:37,750 --> 00:09:42,490
inconvenient from a database point of

00:09:39,700 --> 00:09:44,470
view because there is no data model it's

00:09:42,490 --> 00:09:46,540
not defined ahead of time you have to

00:09:44,470 --> 00:09:49,690
kind of look at the data and understand

00:09:46,540 --> 00:09:52,290
it and here's some of the data there

00:09:49,690 --> 00:09:55,600
this is a business description of

00:09:52,290 --> 00:10:00,459
something that is on Las Vegas Boulevard

00:09:55,600 --> 00:10:02,529
in Las Vegas it sells French Steakhouse

00:10:00,459 --> 00:10:04,810
kind of food whatever that could mean

00:10:02,529 --> 00:10:07,330
it's good for dessert late nights and so

00:10:04,810 --> 00:10:09,459
on that's the example of it and you can

00:10:07,330 --> 00:10:12,160
find data in it like here are the votes

00:10:09,459 --> 00:10:15,190
that a particular business has had

00:10:12,160 --> 00:10:16,750
that's a different file in there and you

00:10:15,190 --> 00:10:20,320
can understand it because the data is

00:10:16,750 --> 00:10:24,130
well labeled and it's easy to see when

00:10:20,320 --> 00:10:27,760
the schema is integrated in there you

00:10:24,130 --> 00:10:30,100
can go from nothing to getting real

00:10:27,760 --> 00:10:33,670
query results in about two minutes with

00:10:30,100 --> 00:10:37,360
drill so installing it is nothing but

00:10:33,670 --> 00:10:39,940
untiring a tarball so running it is

00:10:37,360 --> 00:10:43,120
running a standard utility called sequel

00:10:39,940 --> 00:10:47,140
line which connects via JDBC to an

00:10:43,120 --> 00:10:49,990
embedded drill bit and from there we can

00:10:47,140 --> 00:10:52,959
directly query data in the file system

00:10:49,990 --> 00:10:55,750
this is literally all you have to do to

00:10:52,959 --> 00:10:57,459
get started with drill you can do more

00:10:55,750 --> 00:10:59,649
things if you want a large parallel

00:10:57,459 --> 00:11:02,170
instance but if you just want to try it

00:10:59,649 --> 00:11:05,170
this is how much it takes and notice

00:11:02,170 --> 00:11:08,020
here what we would normally call a table

00:11:05,170 --> 00:11:11,709
name says it's on the distributed file

00:11:08,020 --> 00:11:14,130
system in a workspace directory of

00:11:11,709 --> 00:11:17,170
predefined directory called Yelp and

00:11:14,130 --> 00:11:18,760
then there's this file called business

00:11:17,170 --> 00:11:21,550
JSON

00:11:18,760 --> 00:11:23,800
now the structure of that has state and

00:11:21,550 --> 00:11:26,470
city we're going to order it by the

00:11:23,800 --> 00:11:29,230
number of businesses and we're going to

00:11:26,470 --> 00:11:31,720
count the number of businesses there the

00:11:29,230 --> 00:11:35,380
standard sort of reporting query you'd

00:11:31,720 --> 00:11:39,160
expect except that these were from a

00:11:35,380 --> 00:11:41,830
JSON data file not from a conventional

00:11:39,160 --> 00:11:44,650
relational table we get a conventional

00:11:41,830 --> 00:11:48,870
looking relational result even though

00:11:44,650 --> 00:11:51,640
we're not querying relational data

00:11:48,870 --> 00:11:54,160
here's another example this is more

00:11:51,640 --> 00:11:56,740
complex notice that the references here

00:11:54,160 --> 00:11:59,940
have multiple dots in them so we can say

00:11:56,740 --> 00:12:03,610
well it's come down here we're going to

00:11:59,940 --> 00:12:05,770
query from said this file business JSON

00:12:03,610 --> 00:12:09,640
called be and we're going to say B dot

00:12:05,770 --> 00:12:11,770
hours dot Friday two levels of

00:12:09,640 --> 00:12:16,330
indirection because that's nested data

00:12:11,770 --> 00:12:19,120
is less than 2,200 and the closing point

00:12:16,330 --> 00:12:22,060
is greater than 22 it we're finding out

00:12:19,120 --> 00:12:24,640
what's open right now late night in Las

00:12:22,060 --> 00:12:29,200
Vegas and we can also say and there's a

00:12:24,640 --> 00:12:31,120
list that contains Mediterranean a list

00:12:29,200 --> 00:12:34,150
is a data structure but it's not a data

00:12:31,120 --> 00:12:38,590
structure that you normally query inside

00:12:34,150 --> 00:12:41,470
a sequel query so there we get olives

00:12:38,590 --> 00:12:43,240
and it's open right now as Mediterranean

00:12:41,470 --> 00:12:44,910
and restaurant there's another one which

00:12:43,240 --> 00:12:47,290
is the marrakech moroccan restaurant

00:12:44,910 --> 00:12:51,250
both of them open at ten o'clock at

00:12:47,290 --> 00:12:53,470
night in las vegas we can do all of the

00:12:51,250 --> 00:12:56,470
sort of things like we can say the

00:12:53,470 --> 00:12:58,420
business idea is in the results of

00:12:56,470 --> 00:13:02,110
another query we're going to group that

00:12:58,420 --> 00:13:04,960
by business ID having a sum of votes

00:13:02,110 --> 00:13:06,610
greater than a certain amount does this

00:13:04,960 --> 00:13:09,190
sort of correlated sub-queries works

00:13:06,610 --> 00:13:12,160
just fine all of the sort of sequel

00:13:09,190 --> 00:13:16,750
structures still apply here we get the

00:13:12,160 --> 00:13:18,610
ability to build a view now views I'm

00:13:16,750 --> 00:13:21,640
going to talk about more in a little bit

00:13:18,610 --> 00:13:24,940
but views are essentially a file that

00:13:21,640 --> 00:13:27,130
has a snippet of sequel in it so they

00:13:24,940 --> 00:13:29,680
are not materialized views their virtual

00:13:27,130 --> 00:13:31,540
views but they can be chained one view

00:13:29,680 --> 00:13:33,880
can refer to another and another

00:13:31,540 --> 00:13:35,740
the exciting thing about views is not

00:13:33,880 --> 00:13:37,870
the fact that you can chain them I could

00:13:35,740 --> 00:13:40,540
have just written the query but the fact

00:13:37,870 --> 00:13:44,290
that permissions can be delegated

00:13:40,540 --> 00:13:47,079
according to that chain one person might

00:13:44,290 --> 00:13:48,850
have permission on a table they could

00:13:47,079 --> 00:13:50,889
create a view which access to the table

00:13:48,850 --> 00:13:53,529
and they could open up the permissions

00:13:50,889 --> 00:13:55,930
on their view somebody else could have

00:13:53,529 --> 00:13:58,509
permissions to read the view but not the

00:13:55,930 --> 00:14:01,810
table well they could recreate a view

00:13:58,509 --> 00:14:04,630
the references to view this allows us to

00:14:01,810 --> 00:14:08,970
do things like on-the-fly decryption it

00:14:04,630 --> 00:14:13,360
lets us do things like line by line

00:14:08,970 --> 00:14:15,250
masking of data if we have a column

00:14:13,360 --> 00:14:18,060
which says this data has been withdrawn

00:14:15,250 --> 00:14:22,449
from public view we can do filtering

00:14:18,060 --> 00:14:25,089
that way we can also build materialized

00:14:22,449 --> 00:14:28,779
views or new tables this sort of thing

00:14:25,089 --> 00:14:31,089
we can work with repeated values that's

00:14:28,779 --> 00:14:32,800
a raise of things and this begins to be

00:14:31,089 --> 00:14:36,670
pretty exciting we can do things like

00:14:32,800 --> 00:14:40,569
flattened so before the data has these

00:14:36,670 --> 00:14:43,480
lists of categories and when we flatten

00:14:40,569 --> 00:14:47,470
it these become rows which let us do

00:14:43,480 --> 00:14:50,920
queries on contents of arrays as if they

00:14:47,470 --> 00:14:54,399
were already data that had been

00:14:50,920 --> 00:14:56,800
flattened another good use of this is if

00:14:54,399 --> 00:14:59,649
you want to compact many many many

00:14:56,800 --> 00:15:01,959
samples or many many data points into a

00:14:59,649 --> 00:15:04,870
single row in a database to make

00:15:01,959 --> 00:15:07,510
insertion and retrieval very efficient

00:15:04,870 --> 00:15:11,019
or even compact them into a binary

00:15:07,510 --> 00:15:13,720
representation flattened then can turn

00:15:11,019 --> 00:15:15,790
that back into what looks like

00:15:13,720 --> 00:15:17,769
relational data if you have a time

00:15:15,790 --> 00:15:21,360
series database you might insert a

00:15:17,769 --> 00:15:24,790
thousand samples and time Sam timestamps

00:15:21,360 --> 00:15:26,949
into the data but then when you retrieve

00:15:24,790 --> 00:15:30,069
it you've only retrieved one view they

00:15:26,949 --> 00:15:33,220
use flatten you get a thousand samples

00:15:30,069 --> 00:15:36,279
but the data is not changed is not moved

00:15:33,220 --> 00:15:38,560
is not transformed by flattened it's

00:15:36,279 --> 00:15:41,220
merely how drill thinks about the data

00:15:38,560 --> 00:15:44,889
the data is still stored in a flat

00:15:41,220 --> 00:15:48,100
primitive column based representation

00:15:44,889 --> 00:15:51,009
and so this goes at very very high

00:15:48,100 --> 00:15:52,899
speeds much faster sometimes a thousand

00:15:51,009 --> 00:15:55,540
times faster than the underlying

00:15:52,899 --> 00:15:59,079
database would allow you to operate on

00:15:55,540 --> 00:16:02,470
it if you were operating on a row by row

00:15:59,079 --> 00:16:04,839
basis so flattened is a new capability

00:16:02,470 --> 00:16:07,509
that's very exciting it's essentially a

00:16:04,839 --> 00:16:09,639
lateral view now we can do recursive

00:16:07,509 --> 00:16:13,869
things against flattened treating that

00:16:09,639 --> 00:16:16,029
as of you or as a as a sub query we can

00:16:13,869 --> 00:16:20,109
even do some interesting things one of

00:16:16,029 --> 00:16:21,459
the one of the I don't want to say

00:16:20,109 --> 00:16:23,769
beautiful I don't want to say bad i

00:16:21,459 --> 00:16:25,149
don't want to say perverse but it's all

00:16:23,769 --> 00:16:29,619
of these things one of the things that

00:16:25,149 --> 00:16:34,989
happens in no sequel databases is people

00:16:29,619 --> 00:16:38,079
put data into the column names so they

00:16:34,989 --> 00:16:40,779
because you could have sparsely

00:16:38,079 --> 00:16:43,419
populated columns you could do something

00:16:40,779 --> 00:16:45,399
like if you have a web page you could

00:16:43,419 --> 00:16:48,910
say the domains that that web pages

00:16:45,399 --> 00:16:50,649
refers to are have the columns with the

00:16:48,910 --> 00:16:53,589
name of the web domain that they refer

00:16:50,649 --> 00:16:55,629
to and then the anchor text could

00:16:53,589 --> 00:16:59,290
actually be the value in there so the

00:16:55,629 --> 00:17:01,660
column name itself is from an open set

00:16:59,290 --> 00:17:04,240
something we don't have predefined and

00:17:01,660 --> 00:17:08,139
it contains useful information itself

00:17:04,240 --> 00:17:11,529
the domain name here we have an array

00:17:08,139 --> 00:17:17,260
here's a magnified view and this is an

00:17:11,529 --> 00:17:21,610
object and the keys are time ranges so

00:17:17,260 --> 00:17:27,269
13 2 2 11 26 and so on and then these

00:17:21,610 --> 00:17:30,429
are values associated with those ranges

00:17:27,269 --> 00:17:32,440
this is a very peculiar thing where the

00:17:30,429 --> 00:17:36,130
column has a name which is the

00:17:32,440 --> 00:17:39,549
combination of two sorts of data

00:17:36,130 --> 00:17:42,639
elements doing a query against that we

00:17:39,549 --> 00:17:46,269
can use something called kv gen that

00:17:42,639 --> 00:17:50,769
converts this one object into a list of

00:17:46,269 --> 00:17:56,049
key value pairs and then we can flatten

00:17:50,769 --> 00:17:58,450
that kv jen and we could do a query so

00:17:56,049 --> 00:18:00,700
here's the result of the kv gen so

00:17:58,450 --> 00:18:04,750
before this was the name of the column

00:18:00,700 --> 00:18:07,800
and so now we have one object with a key

00:18:04,750 --> 00:18:10,720
at a value and so now we can do queries

00:18:07,800 --> 00:18:16,660
against that one value like here

00:18:10,720 --> 00:18:18,940
flattened kv gin and we get rose with

00:18:16,660 --> 00:18:22,210
those things and that means that we can

00:18:18,940 --> 00:18:27,430
then do queries flatten that and now

00:18:22,210 --> 00:18:29,650
check in key is 20 30 so how many people

00:18:27,430 --> 00:18:34,180
how many restaurants have had a check-in

00:18:29,650 --> 00:18:36,610
from eleven o'clock to midnight a very

00:18:34,180 --> 00:18:39,010
very flexible sort of query but nothing

00:18:36,610 --> 00:18:42,010
like what you could do in a normal

00:18:39,010 --> 00:18:44,500
traditional sequel database but

00:18:42,010 --> 00:18:47,980
something you have to do if you want to

00:18:44,500 --> 00:18:51,100
manipulate very very flexible no sequel

00:18:47,980 --> 00:18:53,950
data these data are the things that they

00:18:51,100 --> 00:18:55,690
come to you as they come to you it's not

00:18:53,950 --> 00:18:57,430
something you can change it's not

00:18:55,690 --> 00:18:59,680
something that you can manipulate I

00:18:57,430 --> 00:19:02,860
talked to one customer they have

00:18:59,680 --> 00:19:05,500
something like 40 or 50 million retail

00:19:02,860 --> 00:19:06,940
items that might be for sale they come

00:19:05,500 --> 00:19:10,360
from a hundred and twenty different

00:19:06,940 --> 00:19:12,730
business units and each of the business

00:19:10,360 --> 00:19:16,270
users changes their schema on average

00:19:12,730 --> 00:19:18,250
twice a year that means almost every day

00:19:16,270 --> 00:19:20,800
the schema of the collective data

00:19:18,250 --> 00:19:23,830
changes and the IT department is

00:19:20,800 --> 00:19:25,690
supposed to deal with it how are they

00:19:23,830 --> 00:19:29,020
going to deal with it they can't control

00:19:25,690 --> 00:19:32,020
it they can't even document it they have

00:19:29,020 --> 00:19:35,320
to query it even so well techniques like

00:19:32,020 --> 00:19:37,540
this would allow them to succeed drill

00:19:35,320 --> 00:19:40,390
would allow them to live in the very

00:19:37,540 --> 00:19:43,900
dynamic out of control world that they

00:19:40,390 --> 00:19:46,450
have to live in and traditional sequel

00:19:43,900 --> 00:19:49,480
systems which assume that you have a

00:19:46,450 --> 00:19:51,340
curatorial rule and control over the

00:19:49,480 --> 00:19:56,590
shape of your data would necessarily

00:19:51,340 --> 00:19:59,290
fail drill also looks at this

00:19:56,590 --> 00:20:02,830
decentralization problem and tries to

00:19:59,290 --> 00:20:05,770
apply a decentralized but still secure

00:20:02,830 --> 00:20:08,260
security model the idea is that you will

00:20:05,770 --> 00:20:10,630
have perimeter security tools like

00:20:08,260 --> 00:20:11,920
tableau or you might have sentry or

00:20:10,630 --> 00:20:14,020
something like that

00:20:11,920 --> 00:20:17,200
those are controlling which kinds of

00:20:14,020 --> 00:20:19,570
queries you can do they're trying to say

00:20:17,200 --> 00:20:22,030
you can't select against this sort of

00:20:19,570 --> 00:20:23,950
thing but they are inherently holy they

00:20:22,030 --> 00:20:25,960
have holes in them because it's very

00:20:23,950 --> 00:20:27,730
difficult to parse and understand what

00:20:25,960 --> 00:20:29,890
queries are doing and whether or not

00:20:27,730 --> 00:20:34,300
it's dangerous things but then drill

00:20:29,890 --> 00:20:37,150
also has distributed security at the

00:20:34,300 --> 00:20:40,480
file system level and the way that that

00:20:37,150 --> 00:20:42,670
works is based on these views and the

00:20:40,480 --> 00:20:46,050
ways that views allow you to delegate

00:20:42,670 --> 00:20:52,720
your read permission in controlled ways

00:20:46,050 --> 00:20:55,270
to file system cysts assets you can have

00:20:52,720 --> 00:20:57,880
a business analyst who has certain

00:20:55,270 --> 00:21:00,550
permissions and you can see a certain

00:20:57,880 --> 00:21:02,770
view of the data you can have a data

00:21:00,550 --> 00:21:05,760
scientist who has other permissions and

00:21:02,770 --> 00:21:08,680
they might be able to see the entire

00:21:05,760 --> 00:21:10,360
content of a credit card number but

00:21:08,680 --> 00:21:13,030
these are not physical copies of the

00:21:10,360 --> 00:21:17,550
data they are virtual what happens is

00:21:13,030 --> 00:21:21,640
the original data here at the bottom has

00:21:17,550 --> 00:21:25,570
rights for the DBA the DBA can build a

00:21:21,640 --> 00:21:28,180
view and on top of that Cindy might

00:21:25,570 --> 00:21:31,120
build a further view that could be

00:21:28,180 --> 00:21:34,390
accessed via queries that Frank rights

00:21:31,120 --> 00:21:36,840
by controlling who owns which things and

00:21:34,390 --> 00:21:39,520
who is allowed to read those things and

00:21:36,840 --> 00:21:42,040
what the owner is allowed to query we

00:21:39,520 --> 00:21:44,260
can provide controlled security that is

00:21:42,040 --> 00:21:47,560
rooted in the file system semantics

00:21:44,260 --> 00:21:50,710
rather than in our attempt to write a

00:21:47,560 --> 00:21:53,310
pattern of which queries Arctic will be

00:21:50,710 --> 00:21:55,840
allowed to succeed or not file system

00:21:53,310 --> 00:21:58,090
permissions are of course much simpler

00:21:55,840 --> 00:22:01,030
for people to understand and manipulate

00:21:58,090 --> 00:22:04,090
especially if they come from a security

00:22:01,030 --> 00:22:07,210
or a computer programmer sort of

00:22:04,090 --> 00:22:11,770
environment as opposed to a database

00:22:07,210 --> 00:22:13,600
administrator point of view so if we

00:22:11,770 --> 00:22:16,210
think back now this has been a lot of

00:22:13,600 --> 00:22:21,310
slides that are kind of slid by but we

00:22:16,210 --> 00:22:23,770
have logical logical views that provide

00:22:21,310 --> 00:22:25,750
security it's highly granular because

00:22:23,770 --> 00:22:28,900
you have all of the power of sequel

00:22:25,750 --> 00:22:31,330
to define what person can see or not see

00:22:28,900 --> 00:22:34,690
it's completely decentralized there's no

00:22:31,330 --> 00:22:37,660
single metadata resource that has to be

00:22:34,690 --> 00:22:41,290
up that has to be performant that you

00:22:37,660 --> 00:22:44,650
have to reload the cache of and the

00:22:41,290 --> 00:22:49,090
security allows self-service while still

00:22:44,650 --> 00:22:52,240
maintaining tight governance now as I

00:22:49,090 --> 00:22:54,730
said drills goal is to go fast with

00:22:52,240 --> 00:22:57,310
little information and do even better

00:22:54,730 --> 00:22:59,310
with lots of information so here's a

00:22:57,310 --> 00:23:05,170
little bit about how it actually works

00:22:59,310 --> 00:23:08,680
we get fully pipelined execution and so

00:23:05,170 --> 00:23:10,660
what we've got here is a execution plan

00:23:08,680 --> 00:23:14,170
and you can actually see here this this

00:23:10,660 --> 00:23:17,530
dotted line expresses where parallelism

00:23:14,170 --> 00:23:21,220
is marked in this logical plan the

00:23:17,530 --> 00:23:24,490
initial step of drill is to convert

00:23:21,220 --> 00:23:27,190
sequel into so-called logical plan which

00:23:24,490 --> 00:23:28,930
hellz logical operators here starts at

00:23:27,190 --> 00:23:31,210
the bottom with the scan then there's a

00:23:28,930 --> 00:23:33,820
producer consumer and a union exchange

00:23:31,210 --> 00:23:36,160
there is no parallel ISM expressed here

00:23:33,820 --> 00:23:39,460
and there's only as many types as we

00:23:36,160 --> 00:23:43,030
understand no and no exists at this

00:23:39,460 --> 00:23:46,480
point but what then happens is that's

00:23:43,030 --> 00:23:48,910
translated into a physical plan and then

00:23:46,480 --> 00:23:52,270
an execution plan and at this point we

00:23:48,910 --> 00:23:55,690
begin to see fragments that are executed

00:23:52,270 --> 00:23:59,050
across the cluster and part of it that's

00:23:55,690 --> 00:24:01,390
not executed across the cluster and we

00:23:59,050 --> 00:24:06,130
get data flow from the parallel bits

00:24:01,390 --> 00:24:10,000
into the non-parallel bits this process

00:24:06,130 --> 00:24:11,860
of converting from a logical plan to a

00:24:10,000 --> 00:24:16,450
physical plan and then to actual

00:24:11,860 --> 00:24:20,020
physical code occurs using the calcite

00:24:16,450 --> 00:24:21,670
query optimizer but it also uses special

00:24:20,020 --> 00:24:23,950
rules that are part of drill itself

00:24:21,670 --> 00:24:28,510
which understand the parallel execution

00:24:23,950 --> 00:24:32,260
environment drill then can generate code

00:24:28,510 --> 00:24:35,200
on the fly data streams in from the

00:24:32,260 --> 00:24:38,330
bottom of that flow data streams in in

00:24:35,200 --> 00:24:40,460
what are called row batches

00:24:38,330 --> 00:24:43,250
when they're stored in a columnar format

00:24:40,460 --> 00:24:45,500
in memory each row batch comes with

00:24:43,250 --> 00:24:48,289
what's called the empirical schema this

00:24:45,500 --> 00:24:52,090
is the schema of data types as observed

00:24:48,289 --> 00:24:55,039
in this data that we have this batch for

00:24:52,090 --> 00:24:57,649
if that schema is the same as the

00:24:55,039 --> 00:25:01,340
previous schema drill just execute the

00:24:57,649 --> 00:25:04,580
query but if it's different drill will

00:25:01,340 --> 00:25:07,899
Rio mais in this fragment regenerate the

00:25:04,580 --> 00:25:10,130
code and compile it so that we get full

00:25:07,899 --> 00:25:13,039
operational speed and you can imagine

00:25:10,130 --> 00:25:17,059
this has applicability if we have old

00:25:13,039 --> 00:25:19,669
data that has column one and at some

00:25:17,059 --> 00:25:22,909
point we decided to convert to column

00:25:19,669 --> 00:25:25,730
two with a different data type now new

00:25:22,909 --> 00:25:27,559
data will have column two so most of the

00:25:25,730 --> 00:25:30,139
data will have either column one or

00:25:27,559 --> 00:25:33,380
column two and will probably have a view

00:25:30,139 --> 00:25:35,960
which will say if column one exists then

00:25:33,380 --> 00:25:38,690
we we give you this this synthesized

00:25:35,960 --> 00:25:41,899
view if column two exists we just give

00:25:38,690 --> 00:25:44,659
you that value on the first half of the

00:25:41,899 --> 00:25:46,429
data the optimizer will throw away the

00:25:44,659 --> 00:25:49,010
case statement turn it into straight

00:25:46,429 --> 00:25:51,110
line code and always just give us column

00:25:49,010 --> 00:25:55,429
one because the empirical schema says

00:25:51,110 --> 00:25:57,950
column two is always null so we could

00:25:55,429 --> 00:25:59,899
obviously do that in the second half of

00:25:57,950 --> 00:26:01,970
the data the optimizer will throw away

00:25:59,899 --> 00:26:04,340
the fork of the case that talks about

00:26:01,970 --> 00:26:06,470
column one and again we get full speed

00:26:04,340 --> 00:26:09,440
we have no conditionals in the data

00:26:06,470 --> 00:26:11,510
processing itself and furthermore all of

00:26:09,440 --> 00:26:14,029
the object creations in all of the

00:26:11,510 --> 00:26:17,809
object references compile away as well

00:26:14,029 --> 00:26:21,559
so what's left is direct pointer access

00:26:17,809 --> 00:26:24,740
to an array of primitive objects even

00:26:21,559 --> 00:26:27,950
though we have a dynamic language which

00:26:24,740 --> 00:26:30,350
was not type specific when we originally

00:26:27,950 --> 00:26:34,010
wrote the code it's only when it's

00:26:30,350 --> 00:26:36,019
presented with a block of data that it

00:26:34,010 --> 00:26:38,360
finally compiles down to primitive code

00:26:36,019 --> 00:26:40,340
and at that point all the types are

00:26:38,360 --> 00:26:43,309
known all the types are stored in

00:26:40,340 --> 00:26:45,830
contiguous arrays so that we get full

00:26:43,309 --> 00:26:48,520
speed of the machine running on a very

00:26:45,830 --> 00:26:50,840
tight loop or even in a vectorized loop

00:26:48,520 --> 00:26:52,940
so that we get

00:26:50,840 --> 00:26:56,150
these incredibly high speeds even in a

00:26:52,940 --> 00:26:59,180
dynamic situation this optimization

00:26:56,150 --> 00:27:02,180
extends into the RPC layer which is

00:26:59,180 --> 00:27:06,920
optimized for that same vectorized sort

00:27:02,180 --> 00:27:10,970
of transfer we have optimized readers

00:27:06,920 --> 00:27:12,920
for formats like parquet where drill can

00:27:10,970 --> 00:27:15,860
do push downs into the data reader and

00:27:12,920 --> 00:27:18,860
it's a fully pipelined reader that runs

00:27:15,860 --> 00:27:20,500
much faster than the normal parquet

00:27:18,860 --> 00:27:23,540
readers that are part of the park a

00:27:20,500 --> 00:27:26,390
distribution itself drill has specific

00:27:23,540 --> 00:27:30,650
readers for its own needs that increase

00:27:26,390 --> 00:27:32,360
and accelerate that the value vector is

00:27:30,650 --> 00:27:35,090
the way that drill stores data

00:27:32,360 --> 00:27:37,190
internally this is an in-memory columnar

00:27:35,090 --> 00:27:39,710
representation that allows full

00:27:37,190 --> 00:27:42,050
vectorization of operations because it's

00:27:39,710 --> 00:27:45,770
a pure array of primitive types that are

00:27:42,050 --> 00:27:49,370
packed into congenial units that allows

00:27:45,770 --> 00:27:52,370
random access to any materialized view

00:27:49,370 --> 00:27:55,100
without any copying it allows us to

00:27:52,370 --> 00:27:57,530
fully memory shred all operations so

00:27:55,100 --> 00:28:01,100
that we get very very high access speeds

00:27:57,530 --> 00:28:03,710
it also allows us to do and interesting

00:28:01,100 --> 00:28:06,110
things all operators in drill are

00:28:03,710 --> 00:28:09,080
expressed as udfs the same that you

00:28:06,110 --> 00:28:11,300
might write what happens is you compile

00:28:09,080 --> 00:28:14,150
that the annotations that you put on

00:28:11,300 --> 00:28:17,570
your code are used to lift the source

00:28:14,150 --> 00:28:20,960
code out and put it into a generated set

00:28:17,570 --> 00:28:24,820
of code so that your code sits directly

00:28:20,960 --> 00:28:27,590
in the data path and it's encapsulated

00:28:24,820 --> 00:28:31,160
safely because you can only see the

00:28:27,590 --> 00:28:34,100
references that you have declared but

00:28:31,160 --> 00:28:35,990
the optimizer can now see across all of

00:28:34,100 --> 00:28:38,510
the code that's generated in the data

00:28:35,990 --> 00:28:41,810
path and so the objects that you think

00:28:38,510 --> 00:28:44,770
you're accessing get optimized away and

00:28:41,810 --> 00:28:48,260
turn into pure data pointer accesses

00:28:44,770 --> 00:28:50,840
this is a unique property of drill and

00:28:48,260 --> 00:28:53,570
it allows drill to run at full memory

00:28:50,840 --> 00:28:57,950
bandwidth speeds on things that look

00:28:53,570 --> 00:29:00,080
like dynamic code this runtime

00:28:57,950 --> 00:29:03,080
compilation is part of the planning

00:29:00,080 --> 00:29:07,400
process of drill which delays decisions

00:29:03,080 --> 00:29:10,010
as late as necessary to get that dynamic

00:29:07,400 --> 00:29:12,530
typing information fully resolved this

00:29:10,010 --> 00:29:15,500
is another unusual characteristic of

00:29:12,530 --> 00:29:17,780
this the ability to preserve uncertainty

00:29:15,500 --> 00:29:21,080
as long as necessary so we never

00:29:17,780 --> 00:29:23,900
generate conditional code where it's

00:29:21,080 --> 00:29:26,690
conditional on type and it wouldn't

00:29:23,900 --> 00:29:29,780
necessarily be true so the way that this

00:29:26,690 --> 00:29:33,380
actually happens is your udfs get

00:29:29,780 --> 00:29:37,070
transformed into synthetic code where we

00:29:33,380 --> 00:29:40,610
in line your code into the main query

00:29:37,070 --> 00:29:42,560
code the code model is a generated

00:29:40,610 --> 00:29:44,350
template into which your code is

00:29:42,560 --> 00:29:47,210
inserted based on the query itself

00:29:44,350 --> 00:29:50,030
Janine o is used to compile this on the

00:29:47,210 --> 00:29:53,570
fly Janine o is an on-the-fly in-memory

00:29:50,030 --> 00:29:55,490
compiler for Java and we also have byte

00:29:53,570 --> 00:29:58,160
code templates we do bytecode

00:29:55,490 --> 00:30:00,430
engineering so that we can directly

00:29:58,160 --> 00:30:03,950
insert the compiled code without

00:30:00,430 --> 00:30:06,080
recompiling the entire template that

00:30:03,950 --> 00:30:09,050
that accelerates this on the fly

00:30:06,080 --> 00:30:11,990
compiling and we generate custom byte

00:30:09,050 --> 00:30:14,950
codes as necessary to adjust the data

00:30:11,990 --> 00:30:19,690
accesses that then is optimized by the

00:30:14,950 --> 00:30:22,340
after loading by the standard Java chip

00:30:19,690 --> 00:30:26,860
the optimizations that we do in these

00:30:22,340 --> 00:30:30,350
things are done both at query time at

00:30:26,860 --> 00:30:33,380
dynamic code generation time and then at

00:30:30,350 --> 00:30:36,020
execution time we have special machine

00:30:33,380 --> 00:30:38,390
code compilation optimizations that are

00:30:36,020 --> 00:30:40,520
injected into the JIT so that we get

00:30:38,390 --> 00:30:42,830
very very high performance this removes

00:30:40,520 --> 00:30:45,380
for instance all bounds checking from

00:30:42,830 --> 00:30:48,610
safe accesses even though your code

00:30:45,380 --> 00:30:51,590
didn't even know was referencing vectors

00:30:48,610 --> 00:30:55,130
it's still able to remove those bounds

00:30:51,590 --> 00:31:00,110
checks and drive into machine native

00:30:55,130 --> 00:31:03,140
pointers the vectorization does the

00:31:00,110 --> 00:31:07,310
equivalent of running more than one row

00:31:03,140 --> 00:31:10,040
of operations at the same time by the

00:31:07,310 --> 00:31:11,010
use of vectorized instructions again you

00:31:10,040 --> 00:31:14,520
don't have to a note

00:31:11,010 --> 00:31:19,230
that in your UDF at all the simdi is

00:31:14,520 --> 00:31:23,580
brought in as possible and accelerate

00:31:19,230 --> 00:31:25,710
your code you also get advanced

00:31:23,580 --> 00:31:29,070
telemetry out of this because the entire

00:31:25,710 --> 00:31:31,950
process is instrumented and you get

00:31:29,070 --> 00:31:33,690
profiles that are written in JSON and of

00:31:31,950 --> 00:31:36,300
course you can use drill to analyze

00:31:33,690 --> 00:31:38,190
those profiles and here's the sort of

00:31:36,300 --> 00:31:41,550
thing you get out of that first of all

00:31:38,190 --> 00:31:43,950
you get a full dag which this is in the

00:31:41,550 --> 00:31:46,710
web interface for drill which expresses

00:31:43,950 --> 00:31:49,020
all of the parallel chunks you get a

00:31:46,710 --> 00:31:52,050
different color for each what's each

00:31:49,020 --> 00:31:54,620
called a fragment a fragment is a bit of

00:31:52,050 --> 00:31:58,290
code that's generated as one unit and

00:31:54,620 --> 00:32:00,930
executed in one threat of control here a

00:31:58,290 --> 00:32:02,580
query has been colored up and then on

00:32:00,930 --> 00:32:06,690
the right what you get is what's called

00:32:02,580 --> 00:32:09,780
a swim lane visualization so this light

00:32:06,690 --> 00:32:12,240
blue section here you can see is

00:32:09,780 --> 00:32:14,580
executed in multiple threads roughly a

00:32:12,240 --> 00:32:17,820
dozen threads of control across the

00:32:14,580 --> 00:32:20,430
cluster and it precedes for the most

00:32:17,820 --> 00:32:23,280
part but not entirely the light red

00:32:20,430 --> 00:32:26,100
which is the hash join here we have in

00:32:23,280 --> 00:32:30,000
parallel dark red which is a scan and

00:32:26,100 --> 00:32:32,400
project and filter section which drives

00:32:30,000 --> 00:32:35,460
ultimately into the dark green the dark

00:32:32,400 --> 00:32:37,440
green is able to start execution as data

00:32:35,460 --> 00:32:41,100
becomes available in from the light red

00:32:37,440 --> 00:32:44,250
the dark red but it's can only complete

00:32:41,100 --> 00:32:47,010
after all of its data is presented to it

00:32:44,250 --> 00:32:49,410
the last step of projection and hash

00:32:47,010 --> 00:32:52,020
aggregation the result of a group by

00:32:49,410 --> 00:32:53,970
occurs here in the light green and the

00:32:52,020 --> 00:32:56,940
final output step which doesn't show

00:32:53,970 --> 00:32:59,940
here is right there so you can see in

00:32:56,940 --> 00:33:03,480
very very fine detail what's happening

00:32:59,940 --> 00:33:06,210
when you run a drill query you can tell

00:33:03,480 --> 00:33:11,210
exactly which parts are parallelizing

00:33:06,210 --> 00:33:14,580
well and which parts are not the

00:33:11,210 --> 00:33:16,770
in-memory representation is designed to

00:33:14,580 --> 00:33:19,590
be efficient but also efficiently

00:33:16,770 --> 00:33:21,510
accessible all vectors are stored as a

00:33:19,590 --> 00:33:23,790
raise of uniform primitives and

00:33:21,510 --> 00:33:24,780
therefore can be accessed in a fully

00:33:23,790 --> 00:33:28,440
vectorized way

00:33:24,780 --> 00:33:30,600
we get column where data structures you

00:33:28,440 --> 00:33:32,310
don't see them when you write a UDF but

00:33:30,600 --> 00:33:36,450
that's what's actually being executed

00:33:32,310 --> 00:33:39,870
against and you get some support support

00:33:36,450 --> 00:33:43,020
is on is ongoing implementation is

00:33:39,870 --> 00:33:46,590
ongoing for fully compressed in memory

00:33:43,020 --> 00:33:48,570
column to representation we've tested

00:33:46,590 --> 00:33:51,510
this is a little bit of an old slide

00:33:48,570 --> 00:33:54,030
that talks about testing up to 150 nodes

00:33:51,510 --> 00:33:56,820
the ga is out and we've tested in our

00:33:54,030 --> 00:33:59,820
labs up to roughly a thousand nodes and

00:33:56,820 --> 00:34:04,710
again no scaling issues have been found

00:33:59,820 --> 00:34:08,610
at that scale so this in a very

00:34:04,710 --> 00:34:12,090
accelerated 34 minutes is an outline of

00:34:08,610 --> 00:34:15,600
what drill is useful for and how it

00:34:12,090 --> 00:34:18,780
works it's probably a bit much unless

00:34:15,600 --> 00:34:21,750
I'd like to hire you it's probably a bit

00:34:18,780 --> 00:34:23,909
much to digest in that 34 minutes but I

00:34:21,750 --> 00:34:26,730
think you can see already just little

00:34:23,909 --> 00:34:29,850
sparks hopefully sparks that will lead

00:34:26,730 --> 00:34:32,220
to fires sparks thats a data that you

00:34:29,850 --> 00:34:34,740
have now could be analyzed conveniently

00:34:32,220 --> 00:34:38,580
here either on the small scale kind of

00:34:34,740 --> 00:34:40,610
as a grandpa knock replacement or on the

00:34:38,580 --> 00:34:44,399
large scale as a data warehouse

00:34:40,610 --> 00:34:47,490
alternative data which as it is rather

00:34:44,399 --> 00:34:49,440
than after an ETL process can be

00:34:47,490 --> 00:34:51,480
processed I was talking about Neil's

00:34:49,440 --> 00:34:54,810
just the other night how we'd like to be

00:34:51,480 --> 00:34:57,540
able to pull it his luck parser in that

00:34:54,810 --> 00:35:00,540
actually drives real logs directly into

00:34:57,540 --> 00:35:03,000
their there's no reason necessarily to

00:35:00,540 --> 00:35:05,190
do ETL out of these data as long as you

00:35:03,000 --> 00:35:07,560
have a scanner and the scanner can do

00:35:05,190 --> 00:35:09,480
arbitrary levels of push down all of the

00:35:07,560 --> 00:35:11,640
data sources and drill can expose

00:35:09,480 --> 00:35:14,130
optimizer rules so that you could pull

00:35:11,640 --> 00:35:19,760
down anything you're like I just heard a

00:35:14,130 --> 00:35:22,950
guy in Sweden has put together a JDBC

00:35:19,760 --> 00:35:26,370
sub-query unit so that it accepts

00:35:22,950 --> 00:35:28,920
arbitrary pushed down into the JDBC data

00:35:26,370 --> 00:35:31,650
source so drill is flexible enough to do

00:35:28,920 --> 00:35:34,350
that so you have a data source which is

00:35:31,650 --> 00:35:37,170
in fact an entire different query engine

00:35:34,350 --> 00:35:37,690
that can look at certain tables and

00:35:37,170 --> 00:35:41,319
under

00:35:37,690 --> 00:35:43,060
stand how to process those somebody I

00:35:41,319 --> 00:35:45,490
don't even know where they are produced

00:35:43,060 --> 00:35:47,410
a query engine that does the same

00:35:45,490 --> 00:35:50,140
sort of thing took them about two weeks

00:35:47,410 --> 00:35:52,839
it's not hard there's some foreign

00:35:50,140 --> 00:35:55,810
concepts here but it's not hard to get

00:35:52,839 --> 00:35:59,530
started doing some very very cool things

00:35:55,810 --> 00:36:02,410
in drill and I'd very much like to talk

00:35:59,530 --> 00:36:04,480
to anybody who'd like to do that my name

00:36:02,410 --> 00:36:07,030
is Ted dawning I work for map are we're

00:36:04,480 --> 00:36:09,550
doing a lot with drill our customers are

00:36:07,030 --> 00:36:11,710
beginning to put it into production but

00:36:09,550 --> 00:36:14,230
I'd love to hear how you guys might use

00:36:11,710 --> 00:36:17,339
it any questions that you might have

00:36:14,230 --> 00:36:17,339

YouTube URL: https://www.youtube.com/watch?v=llEcwGCLHWA


