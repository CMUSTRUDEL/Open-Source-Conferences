Title: Berlin Buzzwords 2015: Ludwine Probst - Analytics in the age of the Internet of Things #bbuzz
Publication date: 2015-06-03
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	The Internet of things is all the rage, as it promises to produce a massive amount of various data and represents real challenges for both technology and business. Building applications that leverage this coming flood of data will require a different approach, compared to how we build common data applications today. 

Most if not all of the data acquired from connected and intelligent devices is modeled as Time Series. And extracting value from time stamped data, require some thoughtful design in storage, processing and the type of algorithms necessary to extract insights from the said data.

In this talk we intend to describe how with tools we find in today's big data ecosystem we can build powerful intelligent applications from connected devices.

Read more:
https://2015.berlinbuzzwords.de/session/analytics-age-internet-things

About Ludwine Probst:
https://2015.berlinbuzzwords.de/users/ludwine-probst

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,420 --> 00:00:11,650
okay hi everybody I'm very happy to be

00:00:09,670 --> 00:00:15,129
talking here at this new edition of

00:00:11,650 --> 00:00:17,470
birds world and in the next hour I would

00:00:15,129 --> 00:00:22,359
talked about another text in the age of

00:00:17,470 --> 00:00:26,740
the Internet of Things but ok it doesn't

00:00:22,359 --> 00:00:29,740
work okay but before that i would like

00:00:26,740 --> 00:00:33,340
to say thank you to Jim and Isabel for

00:00:29,740 --> 00:00:35,800
inviting me at both word and it's my

00:00:33,340 --> 00:00:39,400
first time here so I very happy to be

00:00:35,800 --> 00:00:42,430
here today with you and I remember the

00:00:39,400 --> 00:00:44,290
first email that Isabel sent me she

00:00:42,430 --> 00:00:47,080
tried to find good reason for me to come

00:00:44,290 --> 00:00:51,000
here to Berlin and she mention our

00:00:47,080 --> 00:00:54,450
Berlin is Ricky with a widow you know

00:00:51,000 --> 00:00:58,540
but I don't know if it's still raining

00:00:54,450 --> 00:01:02,410
today I think she was right because

00:00:58,540 --> 00:01:06,670
yesterday was very sunny and I hope the

00:01:02,410 --> 00:01:08,470
Sun come back this afternoon but to be

00:01:06,670 --> 00:01:12,700
honest i napped here I'm not here

00:01:08,470 --> 00:01:16,289
because of the widow now i'm here

00:01:12,700 --> 00:01:19,810
because i really love Germany and I

00:01:16,289 --> 00:01:22,749
really enjoyed drinking beer and eating

00:01:19,810 --> 00:01:28,359
co-host and do you have spit see in

00:01:22,749 --> 00:01:30,819
Berlin yes because ok and I used to live

00:01:28,359 --> 00:01:34,810
in germany in tuebingen some years ago

00:01:30,819 --> 00:01:38,679
and we used to drink pity in beer garden

00:01:34,810 --> 00:01:43,509
but ok I'm still confused about fitzy so

00:01:38,679 --> 00:01:45,969
I think I need to try again and I'm also

00:01:43,509 --> 00:01:51,819
talking about technical stuff too of

00:01:45,969 --> 00:01:55,810
course so ok so now a little bit about

00:01:51,819 --> 00:01:57,939
me I have studied mathematics ok my name

00:01:55,810 --> 00:02:01,479
is legion post and i have studied

00:01:57,939 --> 00:02:05,380
mathematics and after graduating with a

00:02:01,479 --> 00:02:09,940
master's degree i decided to join the IT

00:02:05,380 --> 00:02:12,930
world as a developer and today i will

00:02:09,940 --> 00:02:16,120
cut citizen data as a data engineer and

00:02:12,930 --> 00:02:19,629
citizen data is a sort of based in west

00:02:16,120 --> 00:02:22,080
in the west of France you see as well as

00:02:19,629 --> 00:02:27,180
well as you can get

00:02:22,080 --> 00:02:30,690
and with my coworker we built a platform

00:02:27,180 --> 00:02:35,130
to store collect and analyze data from

00:02:30,690 --> 00:02:40,290
sensors data and to do this i'm using

00:02:35,130 --> 00:02:44,310
spark and maybe you have guessed I like

00:02:40,290 --> 00:02:51,600
drawing so I made a lot of picture for

00:02:44,310 --> 00:02:53,490
you today so yeah something more I would

00:02:51,600 --> 00:02:56,640
like to share something I really care

00:02:53,490 --> 00:03:01,400
about it's about women in tech I don't

00:02:56,640 --> 00:03:07,950
know how many women are there today ok

00:03:01,400 --> 00:03:11,490
ok ok but I'm sure you know the woman

00:03:07,950 --> 00:03:16,530
are not much represented an IT and a

00:03:11,490 --> 00:03:18,810
technical even so some pretty are some

00:03:16,530 --> 00:03:21,660
person present that it's the lack of

00:03:18,810 --> 00:03:24,360
interest from them but I think that

00:03:21,660 --> 00:03:27,180
maybe there are not interested in IT

00:03:24,360 --> 00:03:30,200
because I don't think this is a possible

00:03:27,180 --> 00:03:33,120
way for them so that why I'm very

00:03:30,200 --> 00:03:38,250
involved in two communities such as

00:03:33,120 --> 00:03:40,530
France and ladies who could and teachers

00:03:38,250 --> 00:03:44,430
phones it's a group that connects women

00:03:40,530 --> 00:03:48,080
in IT and we want to give one to give

00:03:44,430 --> 00:03:52,260
more visibility to woman developers and

00:03:48,080 --> 00:03:54,870
inspire will model and I'm sure you know

00:03:52,260 --> 00:03:57,780
that it's often are to find female

00:03:54,870 --> 00:04:01,760
speakers so we organize coaching for

00:03:57,780 --> 00:04:05,400
this woman to increase the number and

00:04:01,760 --> 00:04:09,420
because i think that the the developer

00:04:05,400 --> 00:04:12,060
job is not yeah i think that people

00:04:09,420 --> 00:04:15,450
doesn't know what is developer we

00:04:12,060 --> 00:04:18,390
participate in event with I school

00:04:15,450 --> 00:04:21,660
student to know what is a developer and

00:04:18,390 --> 00:04:27,650
to know that women can be ugly and

00:04:21,660 --> 00:04:30,990
interested in IT so now I would like I

00:04:27,650 --> 00:04:34,360
will talk about the real topic analytics

00:04:30,990 --> 00:04:38,800
in the age of the Internet of Things

00:04:34,360 --> 00:04:42,310
so I will start by talking about what is

00:04:38,800 --> 00:04:46,409
high OT and who isn't some few example

00:04:42,310 --> 00:04:49,210
and after that i will quickly talk about

00:04:46,409 --> 00:04:53,530
collecting and storing the data from

00:04:49,210 --> 00:04:56,560
sensor from sensors and two finished and

00:04:53,530 --> 00:04:59,020
this is a funny part i would like to

00:04:56,560 --> 00:05:01,870
show you how i have thought collected

00:04:59,020 --> 00:05:06,780
and analyzed data from an accelerometer

00:05:01,870 --> 00:05:06,780
using spark Cassandra and Emily burr

00:05:07,860 --> 00:05:13,419
okay and do you guys know how many

00:05:11,080 --> 00:05:19,120
connected device do you have how many

00:05:13,419 --> 00:05:21,430
connected device yeah okay okay because

00:05:19,120 --> 00:05:25,300
I think 10 years ago you probably have

00:05:21,430 --> 00:05:29,009
said maybe one or two but today we have

00:05:25,300 --> 00:05:32,710
tablet smartphone with gps tracking

00:05:29,009 --> 00:05:36,430
accelerometer if you like to play video

00:05:32,710 --> 00:05:39,190
game you might have a game console if

00:05:36,430 --> 00:05:43,930
you like 21 you might have I don't know

00:05:39,190 --> 00:05:48,520
a SmartWatch a wristband or a pedometer

00:05:43,930 --> 00:05:51,460
and in fact when you hear about

00:05:48,520 --> 00:05:54,400
connected device it's not just about add

00:05:51,460 --> 00:05:58,229
windows always vary by it's also waivers

00:05:54,400 --> 00:06:01,089
and a kind of sensor that had joined us

00:05:58,229 --> 00:06:04,360
you have sensors in the black box of

00:06:01,089 --> 00:06:11,740
flight in cars and in electricity

00:06:04,360 --> 00:06:14,500
network and so on and now okay yeah in

00:06:11,740 --> 00:06:16,839
this picture you can see that the number

00:06:14,500 --> 00:06:20,110
of connecting device and the connection

00:06:16,839 --> 00:06:24,969
between them is just exploding some

00:06:20,110 --> 00:06:30,849
sources estimate that by 2020 there will

00:06:24,969 --> 00:06:34,089
be 150 balloon of connected devices okay

00:06:30,849 --> 00:06:37,900
now two examples as the first one is

00:06:34,089 --> 00:06:40,779
about aircraft so in a plane engine

00:06:37,900 --> 00:06:44,319
you've got a lot of sensors and these

00:06:40,779 --> 00:06:48,150
sensors can collect thousands of metrics

00:06:44,319 --> 00:06:52,230
such as altitude temperature

00:06:48,150 --> 00:06:56,370
acceleration quantity of fuel speed and

00:06:52,230 --> 00:06:59,470
it's gonna present terabyte of data so

00:06:56,370 --> 00:07:02,410
one common approach was to store and

00:06:59,470 --> 00:07:07,150
analyze this data after the fight is

00:07:02,410 --> 00:07:11,590
over but it's yeah it's kind of offline

00:07:07,150 --> 00:07:14,290
analysis but today with sand sauce you

00:07:11,590 --> 00:07:19,600
can store and analyze the data in real

00:07:14,290 --> 00:07:22,720
time so you can be more reactive and you

00:07:19,600 --> 00:07:25,840
can run for example when he told the

00:07:22,720 --> 00:07:33,820
flight the state of the flight or detect

00:07:25,840 --> 00:07:37,660
anomalies this one is okay i was

00:07:33,820 --> 00:07:40,900
watching the TV some weeks ago and there

00:07:37,660 --> 00:07:45,340
was a documentary and they were talking

00:07:40,900 --> 00:07:47,500
about this example okay and when you

00:07:45,340 --> 00:07:50,440
talk about how your tia i think in

00:07:47,500 --> 00:07:54,600
someone's it's not the sector that comes

00:07:50,440 --> 00:07:58,720
to mind and yet there is a start-up zubi

00:07:54,600 --> 00:08:01,990
the provide a key that has the connected

00:07:58,720 --> 00:08:06,280
devices and this device is connected to

00:08:01,990 --> 00:08:09,010
your car and the key gives you

00:08:06,280 --> 00:08:13,120
information directly on your smartphone

00:08:09,010 --> 00:08:16,960
okay and with this information you can

00:08:13,120 --> 00:08:22,960
monitor the activity in your car you can

00:08:16,960 --> 00:08:26,740
also locate you car and you can try to

00:08:22,960 --> 00:08:31,390
to you can improve the way you're

00:08:26,740 --> 00:08:34,360
driving but you can also compute a

00:08:31,390 --> 00:08:37,030
driving school so i don't know if it's a

00:08:34,360 --> 00:08:41,220
good news for everybody here but the Key

00:08:37,030 --> 00:08:44,560
allows you to compute a driving score so

00:08:41,220 --> 00:08:48,190
that means that insurance company can

00:08:44,560 --> 00:08:51,220
use this technology to River the safe

00:08:48,190 --> 00:08:54,860
driver and to adapt the price the

00:08:51,220 --> 00:08:59,540
insulin spies yeah

00:08:54,860 --> 00:09:03,589
I think it's funny and to finish the

00:08:59,540 --> 00:09:08,209
first part okay with just saw a few of

00:09:03,589 --> 00:09:11,029
application using IOT data so now you

00:09:08,209 --> 00:09:15,320
might ask yourself why you should care

00:09:11,029 --> 00:09:17,720
about this okay we've seen that

00:09:15,320 --> 00:09:22,930
connected device are it will work today

00:09:17,720 --> 00:09:26,899
and this device can generate a lot of

00:09:22,930 --> 00:09:30,440
valuable data and this data can be used

00:09:26,899 --> 00:09:36,920
to create better application detect

00:09:30,440 --> 00:09:40,720
anomalies or imp yes detect anomalies

00:09:36,920 --> 00:09:44,360
and to summarize analyzing this data

00:09:40,720 --> 00:09:47,420
opens up a lot of opportunities on our

00:09:44,360 --> 00:09:51,890
we do business and I'm sure you can

00:09:47,420 --> 00:09:54,890
easily image imagine how this connected

00:09:51,890 --> 00:10:04,519
device and this data can affect and

00:09:54,890 --> 00:10:08,149
change your everyday i will quickly talk

00:10:04,519 --> 00:10:13,250
about how to collect this data and the

00:10:08,149 --> 00:10:15,250
first thing is time service because the

00:10:13,250 --> 00:10:18,860
common kind of the data coming from

00:10:15,250 --> 00:10:22,370
sensors or connected devices are time

00:10:18,860 --> 00:10:26,089
service and I'm sure everybody know what

00:10:22,370 --> 00:10:29,209
is a time service so maybe the easy

00:10:26,089 --> 00:10:32,899
definition is any kind of data with the

00:10:29,209 --> 00:10:35,390
timestamp and time so we are can be

00:10:32,899 --> 00:10:39,170
found on monitoring stuff sign

00:10:35,390 --> 00:10:41,420
opposition stock market and here is just

00:10:39,170 --> 00:10:47,570
an example it's data from an

00:10:41,420 --> 00:10:54,410
accelerometer and the time so with the

00:10:47,570 --> 00:10:57,290
times I visa to the right if you want to

00:10:54,410 --> 00:11:04,130
communicate with sensor there is a lot

00:10:57,290 --> 00:11:07,670
of protocols the most people of them is

00:11:04,130 --> 00:11:08,660
MQTT and here are some of the most

00:11:07,670 --> 00:11:13,879
popular

00:11:08,660 --> 00:11:17,540
but I don't move in to the tail but for

00:11:13,879 --> 00:11:20,170
example TGS is a device to device

00:11:17,540 --> 00:11:24,050
communication its tip this with the data

00:11:20,170 --> 00:11:27,740
through other device and it's very good

00:11:24,050 --> 00:11:30,889
a few other real-time issues you can

00:11:27,740 --> 00:11:34,610
also use MQTT it's a protocol that

00:11:30,889 --> 00:11:38,079
connects device to server and it's great

00:11:34,610 --> 00:11:38,079
if you want to collect telemetry data

00:11:39,519 --> 00:11:52,009
and now of course collecting data from

00:11:47,509 --> 00:11:54,589
sensor cab can be challenging so in fact

00:11:52,009 --> 00:12:01,120
most of heights devices come with a

00:11:54,589 --> 00:12:03,649
limited CPU and memory resources so and

00:12:01,120 --> 00:12:06,139
machine-to-machine communication can

00:12:03,649 --> 00:12:10,279
generate way more data than the most

00:12:06,139 --> 00:12:12,199
application do so that means that there

00:12:10,279 --> 00:12:15,889
is a need for low-energy communication

00:12:12,199 --> 00:12:19,730
networks and this is what company like

00:12:15,889 --> 00:12:28,009
six fox weightless Aloha I try to

00:12:19,730 --> 00:12:31,880
provide okay before talking about the

00:12:28,009 --> 00:12:35,810
funny example let's talk about auto

00:12:31,880 --> 00:12:38,930
store data storing the data from

00:12:35,810 --> 00:12:42,110
connected device represent a huge scale

00:12:38,930 --> 00:12:44,779
challenge and there are several way in

00:12:42,110 --> 00:12:49,730
the market to stow efficiently time

00:12:44,779 --> 00:12:52,040
service but I thought as the world talk

00:12:49,730 --> 00:12:54,730
will focus on this topic today and

00:12:52,040 --> 00:12:58,870
tomorrow so i won't go into detail here

00:12:54,730 --> 00:13:02,329
I'm are somewhere to stop time service

00:12:58,870 --> 00:13:04,939
okay the first one is flat file if you

00:13:02,329 --> 00:13:08,050
don't have a lot of data then the which

00:13:04,939 --> 00:13:11,660
you can use a relational database or

00:13:08,050 --> 00:13:16,670
also know SQL database like the sun

00:13:11,660 --> 00:13:19,160
dried basil open testable and to

00:13:16,670 --> 00:13:21,040
conclude this part i would like to show

00:13:19,160 --> 00:13:25,070
you a picture it's

00:13:21,040 --> 00:13:30,520
it's an example of how an IOT data

00:13:25,070 --> 00:13:33,560
pipeline looks like some to the left

00:13:30,520 --> 00:13:39,140
you've got the sensor and connected

00:13:33,560 --> 00:13:43,490
device it sends the data of kafka for

00:13:39,140 --> 00:13:47,690
example are using protocols MQTT or west

00:13:43,490 --> 00:13:50,570
and a good practice is to stop the data

00:13:47,690 --> 00:13:54,140
the raw data before these two between it

00:13:50,570 --> 00:13:56,060
to other application because it can be

00:13:54,140 --> 00:14:01,810
useful in case you need to replace the

00:13:56,060 --> 00:14:05,180
stream of event for debugging and then

00:14:01,810 --> 00:14:08,990
you even can be processed in real-time

00:14:05,180 --> 00:14:11,450
using spark swimming Austin and to

00:14:08,990 --> 00:14:15,620
provide real-time result or dashboard

00:14:11,450 --> 00:14:20,089
and in the same time if you might want

00:14:15,620 --> 00:14:23,150
to store data in Cassandra HDFS for

00:14:20,089 --> 00:14:28,390
depot offline analysis using spark a

00:14:23,150 --> 00:14:36,260
duper mouth and so on so it's a sort of

00:14:28,390 --> 00:14:39,170
lambda absolute actor okay cool and now

00:14:36,260 --> 00:14:43,610
it's a funny part for me it's a concrete

00:14:39,170 --> 00:14:45,860
example so okay actually I I like

00:14:43,610 --> 00:14:50,360
training and I used to run with my

00:14:45,860 --> 00:14:53,060
friend Anna Anna is one of the member of

00:14:50,360 --> 00:14:56,780
the trestles if it's a woman developer

00:14:53,060 --> 00:15:00,680
and you know she's like a winner addict

00:14:56,780 --> 00:15:03,950
she has a smart word and as an

00:15:00,680 --> 00:15:07,280
everything necessary to monitor a

00:15:03,950 --> 00:15:11,420
winning performance so I was thinking

00:15:07,280 --> 00:15:19,100
about finding something fun to do with

00:15:11,420 --> 00:15:23,089
spot sensors and and data so I look for

00:15:19,100 --> 00:15:27,410
some data set online and I found this

00:15:23,089 --> 00:15:31,820
today very interesting it's about the

00:15:27,410 --> 00:15:34,730
user's activity prediction so the

00:15:31,820 --> 00:15:40,449
following example and the data set

00:15:34,730 --> 00:15:45,079
inspired from this study ok now the

00:15:40,449 --> 00:15:48,440
example so i have data set with data

00:15:45,079 --> 00:15:53,089
coming from an accelerometer and i would

00:15:48,440 --> 00:15:56,029
like to predict the physical activity a

00:15:53,089 --> 00:16:00,310
user is performing so i would like to

00:15:56,029 --> 00:16:04,519
know if this person is running walking

00:16:00,310 --> 00:16:10,790
going up starring dunster sitting or

00:16:04,519 --> 00:16:14,060
standing ok so actually i will use some

00:16:10,790 --> 00:16:17,779
machine learning model to perform this

00:16:14,060 --> 00:16:20,029
prediction and this is a multi-class

00:16:17,779 --> 00:16:24,910
classification problem i have six

00:16:20,029 --> 00:16:29,899
classes you're walking sitting standing

00:16:24,910 --> 00:16:33,949
jogging then substr and i can use

00:16:29,899 --> 00:16:36,410
algorithms such as decision tree random

00:16:33,949 --> 00:16:43,240
forest or multi class logistic

00:16:36,410 --> 00:16:49,430
regression now this is the global view

00:16:43,240 --> 00:16:55,160
of what i need to do so the data come

00:16:49,430 --> 00:16:58,459
from the accelerometer and the ok I a

00:16:55,160 --> 00:17:01,149
data I need to clean the data first then

00:16:58,459 --> 00:17:04,370
I will push the data into Cassandra

00:17:01,149 --> 00:17:08,270
after that I want to build my model my

00:17:04,370 --> 00:17:12,439
predictive model so i will use park and

00:17:08,270 --> 00:17:15,380
emily to do this and at the end for the

00:17:12,439 --> 00:17:19,280
put it in part I don't know if you see

00:17:15,380 --> 00:17:22,490
the picture maybe now ok for the last

00:17:19,280 --> 00:17:27,559
part is a pudding pot and ok i will use

00:17:22,490 --> 00:17:32,000
them a lip to do this the first step is

00:17:27,559 --> 00:17:35,750
collecting and storing the data so ok

00:17:32,000 --> 00:17:39,410
first year as connected devices I have

00:17:35,750 --> 00:17:42,440
an accelerometer no I have a smartphone

00:17:39,410 --> 00:17:46,190
and in this smartphone there is a lot of

00:17:42,440 --> 00:17:47,180
sensors and there is accelerometer for

00:17:46,190 --> 00:17:52,760
each

00:17:47,180 --> 00:17:56,990
and in my case so data are generated

00:17:52,760 --> 00:18:00,190
every 50 mil is Gunther okay but you can

00:17:56,990 --> 00:18:05,000
specify you know that time if you want

00:18:00,190 --> 00:18:08,480
so I have another in another aid

00:18:05,000 --> 00:18:12,290
application it collects the data and

00:18:08,480 --> 00:18:15,800
when a user is performing an activity he

00:18:12,290 --> 00:18:19,400
have to say which one okay and the data

00:18:15,800 --> 00:18:23,720
are collected in a CSV file ok this is

00:18:19,400 --> 00:18:26,960
studio study give me a CSV file and then

00:18:23,720 --> 00:18:33,530
I just took the CSV file and I'll push

00:18:26,960 --> 00:18:38,660
the data into Cassandra here this is the

00:18:33,530 --> 00:18:43,730
other data looks like it in Cassandra so

00:18:38,660 --> 00:18:47,240
I decided to use as primary key the user

00:18:43,730 --> 00:18:50,540
the activity and the timestamp and in

00:18:47,240 --> 00:18:53,270
this way as I data are directly sorted

00:18:50,540 --> 00:18:55,660
by them stop so it's very useful for the

00:18:53,270 --> 00:18:55,660
following

00:18:58,580 --> 00:19:09,370
and now it's just my data so I each row

00:19:04,970 --> 00:19:14,000
is a user idea activity a timestamp and

00:19:09,370 --> 00:19:17,120
free acceleration and yeah in the

00:19:14,000 --> 00:19:27,169
diagram here it just our looks the time

00:19:17,120 --> 00:19:32,120
service so yeah because I would like to

00:19:27,169 --> 00:19:35,600
build the predictive model and okay if

00:19:32,120 --> 00:19:37,760
you want to see the code the code is on

00:19:35,600 --> 00:19:44,600
my github account ok that is everything

00:19:37,760 --> 00:19:47,960
so but the before that just a few world

00:19:44,600 --> 00:19:53,360
about spark is anyone not familiar with

00:19:47,960 --> 00:19:55,519
park ok so the spark is a large squirrel

00:19:53,360 --> 00:20:00,169
in the mood at above possessing from

00:19:55,519 --> 00:20:04,610
work and yeah so you already know that

00:20:00,169 --> 00:20:08,990
so ok then ma lib is anyone not familiar

00:20:04,610 --> 00:20:11,480
with am a lib okay okay Emily biz the

00:20:08,990 --> 00:20:15,409
component of spot providing common

00:20:11,480 --> 00:20:17,929
machine learning algorithm and there is

00:20:15,409 --> 00:20:21,639
a lot of you know radiation

00:20:17,929 --> 00:20:27,559
classification clustering algorithm and

00:20:21,639 --> 00:20:30,100
it's directed including spark and now

00:20:27,559 --> 00:20:35,659
spark connector spark asano connector

00:20:30,100 --> 00:20:39,889
yeah okay so it lets you expose

00:20:35,659 --> 00:20:42,080
Cassandra tables are as Paco today so

00:20:39,889 --> 00:20:45,049
you can perform an ally text or

00:20:42,080 --> 00:20:51,440
permission provided by spark directly on

00:20:45,049 --> 00:20:55,220
the data stored in Cassandra okay but

00:20:51,440 --> 00:21:01,309
before I built the model I need to

00:20:55,220 --> 00:21:05,000
define the features of ok so for to do

00:21:01,309 --> 00:21:07,779
this I just observe to cope the time

00:21:05,000 --> 00:21:07,779
series representation

00:21:09,130 --> 00:21:16,880
the first of the version that we could

00:21:12,530 --> 00:21:19,310
make is that to type of activities the

00:21:16,880 --> 00:21:24,380
are repetitive activities and Static

00:21:19,310 --> 00:21:27,830
activities okay it's easy and now if you

00:21:24,380 --> 00:21:34,100
look at the graph of jogging you can see

00:21:27,830 --> 00:21:38,350
okay repetitive waves and pics and its

00:21:34,100 --> 00:21:44,450
pace about 250 milliseconds for the

00:21:38,350 --> 00:21:47,680
y-axis ok now it's for working it's

00:21:44,450 --> 00:21:57,410
quite similar but this time the pics are

00:21:47,680 --> 00:22:02,150
spaced out about 500 millisecond um yeah

00:21:57,410 --> 00:22:06,730
it's for up stir and dunster and yeah

00:22:02,150 --> 00:22:16,340
it's pretty small actually and to finish

00:22:06,730 --> 00:22:18,860
it's standing and sitting so after some

00:22:16,340 --> 00:22:22,760
tests with the film feature combination

00:22:18,860 --> 00:22:27,110
and after reading a lot of studio but

00:22:22,760 --> 00:22:30,380
this I have chosen these features so the

00:22:27,110 --> 00:22:33,910
acceleration average acceleration the

00:22:30,380 --> 00:22:36,650
variance as leverage absolute difference

00:22:33,910 --> 00:22:44,660
avoid resultant acceleration and the

00:22:36,650 --> 00:22:48,350
average time between pics ok so now yeah

00:22:44,660 --> 00:22:52,310
we I will compute I will show you how to

00:22:48,350 --> 00:22:54,310
compute this video but before that we

00:22:52,310 --> 00:22:58,670
need to clean and proper the data

00:22:54,310 --> 00:23:03,890
because it's not directly usable so for

00:22:58,670 --> 00:23:07,460
this I just made a picture to explain so

00:23:03,890 --> 00:23:11,810
you remember the data is recording in a

00:23:07,460 --> 00:23:16,370
secret sequential way and the data is

00:23:11,810 --> 00:23:18,830
collected from different user ok and at

00:23:16,370 --> 00:23:23,299
different time and date

00:23:18,830 --> 00:23:31,549
so the first things to do is to find the

00:23:23,299 --> 00:23:34,850
jumps between the record okay so yeah I

00:23:31,549 --> 00:23:38,870
don't achieve the data for each user and

00:23:34,850 --> 00:23:45,260
activity then I have sought the data by

00:23:38,870 --> 00:23:49,929
timestamp and after that yeah i have

00:23:45,260 --> 00:23:57,649
defined the jump between the record okay

00:23:49,929 --> 00:24:01,399
and for each recording intervals i need

00:23:57,649 --> 00:24:05,990
to to know their length and i need to

00:24:01,399 --> 00:24:10,519
define a window because i only have 37

00:24:05,990 --> 00:24:12,919
users it's not a lot of data so i need

00:24:10,519 --> 00:24:16,909
to define a small window five or six

00:24:12,919 --> 00:24:20,690
seconds to have a lot to have more data

00:24:16,909 --> 00:24:24,559
to have many samples as possible okay

00:24:20,690 --> 00:24:27,019
and for each window i will compute the

00:24:24,559 --> 00:24:31,130
feature for each window for each user

00:24:27,019 --> 00:24:39,889
activity i can compute the future this

00:24:31,130 --> 00:24:43,010
is the last column so here is the cut

00:24:39,889 --> 00:24:47,720
which was the data from Cassandra it's

00:24:43,010 --> 00:24:53,120
java 8 so okay i define a spark context

00:24:47,720 --> 00:24:57,889
and then here i use the spark Cassandra

00:24:53,120 --> 00:25:03,399
connector I just call so user table in

00:24:57,889 --> 00:25:03,399
Cassandra and it's great ma oddity i

00:25:04,570 --> 00:25:10,309
know i will show you how i have compute

00:25:07,610 --> 00:25:13,880
two of the feature using spark and a

00:25:10,309 --> 00:25:18,169
malleable the first one is very simple

00:25:13,880 --> 00:25:20,870
it's a min and to do this we just have

00:25:18,169 --> 00:25:24,110
to use the main function provided by

00:25:20,870 --> 00:25:27,700
emilybs oh it's very easy and the main

00:25:24,110 --> 00:25:30,400
function apply on a vector so you've got

00:25:27,700 --> 00:25:35,560
the visa mean for ox

00:25:30,400 --> 00:25:37,930
for the acceleration over X Y and said

00:25:35,560 --> 00:25:45,580
and you can apply them in directly and

00:25:37,930 --> 00:25:48,460
it returns the victor of the meaner ok

00:25:45,580 --> 00:25:54,490
now it's more complicated it's the pic

00:25:48,460 --> 00:25:56,590
it average time between the pigs so if

00:25:54,490 --> 00:26:00,130
the first time to do is to define the

00:25:56,590 --> 00:26:03,930
maximum okay to do this I just use the

00:26:00,130 --> 00:26:08,370
mud function providing by Emma lib and

00:26:03,930 --> 00:26:11,680
then I need to define what is a peek so

00:26:08,370 --> 00:26:17,680
for me a pic is the value that is

00:26:11,680 --> 00:26:24,490
greater than they will point nine times

00:26:17,680 --> 00:26:27,490
the maximum okay and to keep the pigs I

00:26:24,490 --> 00:26:33,610
just use the filter function provided by

00:26:27,490 --> 00:26:37,030
Spock here and at the end i reach with

00:26:33,610 --> 00:26:47,830
the timestamp for each peak and thought

00:26:37,030 --> 00:26:53,470
it and okay i want to compute the delta

00:26:47,830 --> 00:26:57,910
between each time stop so to do this i

00:26:53,470 --> 00:27:03,540
have used the zip function to wait one

00:26:57,910 --> 00:27:07,330
LED from two separate led you know and

00:27:03,540 --> 00:27:09,960
yeah i can compute the difference

00:27:07,330 --> 00:27:12,960
between between two successive value

00:27:09,960 --> 00:27:12,960
okay

00:27:13,080 --> 00:27:18,720
and to finish tires just use a min

00:27:15,870 --> 00:27:22,440
function to add the average time between

00:27:18,720 --> 00:27:26,720
pics but if you want to look at the code

00:27:22,440 --> 00:27:32,580
in details just go in my github account

00:27:26,720 --> 00:27:37,320
and now this is a productive part so

00:27:32,580 --> 00:27:41,250
that is a productive part but we have to

00:27:37,320 --> 00:27:44,700
choose the algorithm and just to recap

00:27:41,250 --> 00:27:48,240
we want to determine the users hard

00:27:44,700 --> 00:27:50,910
tivity from data where the possible

00:27:48,240 --> 00:27:54,690
activity are walking jogging sitting

00:27:50,910 --> 00:27:57,210
standing down stair and up star so this

00:27:54,690 --> 00:28:01,830
is a multi-class problem classification

00:27:57,210 --> 00:28:06,480
problem and emily provide you a lot of

00:28:01,830 --> 00:28:10,890
algorithm to do this so for example

00:28:06,480 --> 00:28:13,920
there is a decision trees in ma lib so

00:28:10,890 --> 00:28:18,180
the first thing to do is to split the

00:28:13,920 --> 00:28:20,640
data set so training set is used to

00:28:18,180 --> 00:28:23,280
build a predictive model and the test

00:28:20,640 --> 00:28:29,370
data set is used to validate the model

00:28:23,280 --> 00:28:32,580
and after that you just have to use the

00:28:29,370 --> 00:28:37,680
function provided by a mehleb there is a

00:28:32,580 --> 00:28:43,310
twin classic fuel function to build the

00:28:37,680 --> 00:28:47,040
model on the training data yeah i just

00:28:43,310 --> 00:28:53,450
want evaluate the model so i use a

00:28:47,040 --> 00:28:57,420
product function ok on the test data and

00:28:53,450 --> 00:29:03,020
at the end because i want to make some

00:28:57,420 --> 00:29:03,020
predictions I i save the model

00:29:06,320 --> 00:29:16,380
okay the results the wizard okay it's

00:29:12,120 --> 00:29:20,120
pretty good if we don't without concern

00:29:16,380 --> 00:29:22,590
wedding app and dunster activities so

00:29:20,120 --> 00:29:24,450
one idea would be to define more

00:29:22,590 --> 00:29:32,179
relevant features to have a better

00:29:24,450 --> 00:29:35,400
prediction model ok and ok the

00:29:32,179 --> 00:29:38,400
prediction but I wanted to make a

00:29:35,400 --> 00:29:42,720
demonstration but I had some trouble so

00:29:38,400 --> 00:29:47,789
sorry you want me running right here but

00:29:42,720 --> 00:29:52,200
ok we will pretend ok so have my

00:29:47,789 --> 00:29:56,039
smartphone with an application and we

00:29:52,200 --> 00:29:59,220
use a width API and with this

00:29:56,039 --> 00:30:02,570
application you you can collect the data

00:29:59,220 --> 00:30:05,880
and the data are directly pushed in

00:30:02,570 --> 00:30:09,210
Cassandra and this is you know I'm are

00:30:05,880 --> 00:30:11,840
my friends she coded this application so

00:30:09,210 --> 00:30:17,510
you can find it on our github account

00:30:11,840 --> 00:30:24,630
and ok the data are pushed in Cassandra

00:30:17,510 --> 00:30:28,370
and ok I when the data are registered in

00:30:24,630 --> 00:30:34,370
Cassandra and now I would like to

00:30:28,370 --> 00:30:38,309
predict which activity I was doing so

00:30:34,370 --> 00:30:42,720
the first thing is loading the models

00:30:38,309 --> 00:30:45,690
and after that i use the spike gets onto

00:30:42,720 --> 00:30:50,250
a connector to connect spark and

00:30:45,690 --> 00:30:58,700
cassandra and retrieves data and here i

00:30:50,250 --> 00:31:03,210
select the last value in the table ok i

00:30:58,700 --> 00:31:07,350
compute the future on this data and at

00:31:03,210 --> 00:31:12,620
the end i just lunch I just apply the

00:31:07,350 --> 00:31:12,620
product function to have my prediction

00:31:14,289 --> 00:31:21,850
okay so we just see how to predict the

00:31:18,710 --> 00:31:27,710
activity your user is performing but

00:31:21,850 --> 00:31:32,980
okay how can I use this result so maybe

00:31:27,710 --> 00:31:36,730
we could adapt some music our user is

00:31:32,980 --> 00:31:40,820
listening and depending on his activity

00:31:36,730 --> 00:31:46,970
we could also detect if this person is

00:31:40,820 --> 00:31:50,210
not moving enough maybe we could create

00:31:46,970 --> 00:31:54,980
a specific program from in to encourage

00:31:50,210 --> 00:31:59,620
him to purchase more activity I'm sure

00:31:54,980 --> 00:32:06,169
you can have a lot of other ID but okay

00:31:59,620 --> 00:32:12,320
and yeah I'm not good to conclude but

00:32:06,169 --> 00:32:14,090
it's the time to compute so okay of

00:32:12,320 --> 00:32:16,750
course the internet of thing brings a

00:32:14,090 --> 00:32:19,190
lot of opportunities and challenges

00:32:16,750 --> 00:32:23,289
businesses opportunities technical

00:32:19,190 --> 00:32:27,230
challenges but for me it's also a way to

00:32:23,289 --> 00:32:31,510
let out your creativity and foster many

00:32:27,230 --> 00:32:34,390
innovation so I hope it was clear enough

00:32:31,510 --> 00:32:38,860
and that you had a lot of collided on

00:32:34,390 --> 00:32:42,380
innovation application using IOT data so

00:32:38,860 --> 00:32:48,909
thank you and if you want to see the

00:32:42,380 --> 00:32:48,909
code of full application it's on this

00:32:56,160 --> 00:32:58,220

YouTube URL: https://www.youtube.com/watch?v=BJCftXhBJDk


