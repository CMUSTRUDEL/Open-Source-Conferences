Title: Berlin Buzzwords 2015: James Stanier - Detecting Events on the Web with Java, Kafka and ZooKeeper
Publication date: 2015-06-03
Playlist: Berlin Buzzwords 2015 #bbuzz
Description: 
	Brandwatch is a world-leading social media monitoring tool. We find, process and store nearly 70M mentions from the Web every day from our crawlers and firehoses. As the amount of data we find continually increases, the harder it becomes to separate the signals from the noise for our customers.

Over the last year, we have been building, experimenting and scaling a distributed cluster of JVMs that process the data from our client’s queries and detect influential mentions of their brands online and alert on unusual and important trends. We used Apache Kafka, ZooKeeper, and Spring to achieve this.

This talk explains the architecture that we built, how it performs, scales and some of the difficulties we’ve faced along the way. We’ve learned a lot in the process. We hope you'll learn from us too!

Read more:
https://2015.berlinbuzzwords.de/session/detecting-events-web-java-kafka-and-zookeeper

About James Stanier:
https://2015.berlinbuzzwords.de/users/james-stanier

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,740 --> 00:00:12,660
yeah thanks this is the point where

00:00:10,830 --> 00:00:15,070
whether my colleagues have actually come

00:00:12,660 --> 00:00:16,960
but I can't see because the light

00:00:15,070 --> 00:00:18,580
I hope they're here yeah so I'm going to

00:00:16,960 --> 00:00:21,520
talk to you today about how we built a

00:00:18,580 --> 00:00:22,869
real-time event detection system and I'm

00:00:21,520 --> 00:00:24,160
going to start by going through a bit

00:00:22,869 --> 00:00:27,789
about what the company that I work for

00:00:24,160 --> 00:00:28,900
does and show you how the platform's

00:00:27,789 --> 00:00:30,880
transform me away from a kind of

00:00:28,900 --> 00:00:31,720
historical data analysis platform into

00:00:30,880 --> 00:00:34,540
something with people want more

00:00:31,720 --> 00:00:36,280
real-time stuff and our first iteration

00:00:34,540 --> 00:00:38,110
towards doing that if I go any further

00:00:36,280 --> 00:00:40,989
I'd seen team to speak quite loud is

00:00:38,110 --> 00:00:43,870
that is that okay thumbs up yeah cool I

00:00:40,989 --> 00:00:46,000
don't to shatter your eardrums so yeah

00:00:43,870 --> 00:00:48,910
whoa this little clicker is going crazy

00:00:46,000 --> 00:00:51,340
there we go and so we're going to spend

00:00:48,910 --> 00:00:52,719
10 seconds talking about Who I am a few

00:00:51,340 --> 00:00:54,070
more seconds talking about brand watcher

00:00:52,719 --> 00:00:56,230
which is a company that I work for and

00:00:54,070 --> 00:00:57,579
the problems that we're facing we're

00:00:56,230 --> 00:01:00,219
going to talk about how we move to calf

00:00:57,579 --> 00:01:02,020
go because Kafka's awesome how we

00:01:00,219 --> 00:01:05,500
process data in this event detection

00:01:02,020 --> 00:01:08,200
system and then how we scaled up and we

00:01:05,500 --> 00:01:10,899
distributed this work into a cluster and

00:01:08,200 --> 00:01:12,220
then from this event detection system we

00:01:10,899 --> 00:01:13,450
talked about how we found some meaning

00:01:12,220 --> 00:01:15,130
from the things we were detecting in

00:01:13,450 --> 00:01:17,679
order to deliver interesting emails to

00:01:15,130 --> 00:01:22,270
our clients and I'm not going to use his

00:01:17,679 --> 00:01:24,100
clicker anymore so Who am I and it

00:01:22,270 --> 00:01:26,259
appears to be the laptop actually okay

00:01:24,100 --> 00:01:27,310
I'm James and that's about the smartest

00:01:26,259 --> 00:01:29,979
that I've looked in a very long time I

00:01:27,310 --> 00:01:31,509
was at a wedding and I usually look like

00:01:29,979 --> 00:01:34,450
this every day I do have different

00:01:31,509 --> 00:01:36,159
clothes I not wear the same thing I'm vp

00:01:34,450 --> 00:01:38,770
engineering at brandwatch and we're a

00:01:36,159 --> 00:01:40,479
start-up and a bit bigger than a regular

00:01:38,770 --> 00:01:42,939
starts at now about 300 people were in

00:01:40,479 --> 00:01:45,790
our post series be around going in Serie

00:01:42,939 --> 00:01:47,110
C and we're based in the UK we've got

00:01:45,790 --> 00:01:49,030
office in Berlin and should have gotten

00:01:47,110 --> 00:01:55,030
San Francisco and New York and various

00:01:49,030 --> 00:01:58,259
other places and what do we do I pletely

00:01:55,030 --> 00:01:58,259
having some AV issues

00:02:06,100 --> 00:02:19,670
got a very sticky arrow on the keyboard

00:02:08,989 --> 00:02:21,110
it seems living right for every four or

00:02:19,670 --> 00:02:24,830
five steps forward will have to go a few

00:02:21,110 --> 00:02:26,660
steps back and so what do we do and we

00:02:24,830 --> 00:02:28,370
do effectively social media and web

00:02:26,660 --> 00:02:29,660
listening so we have lots of web

00:02:28,370 --> 00:02:31,250
crawlers that are crawling data on the

00:02:29,660 --> 00:02:33,530
web all the time and we're processing

00:02:31,250 --> 00:02:35,090
analyzing and storing that data so that

00:02:33,530 --> 00:02:36,230
our customers can look into their

00:02:35,090 --> 00:02:39,769
dashboards and find out interesting

00:02:36,230 --> 00:02:41,390
stuff that's going on let's have a look

00:02:39,769 --> 00:02:43,280
at what the app looks like it's easiest

00:02:41,390 --> 00:02:45,080
way to explain it it's a web app when

00:02:43,280 --> 00:02:47,180
you log in if you're paying it's lots of

00:02:45,080 --> 00:02:48,920
your nice money to use our software then

00:02:47,180 --> 00:02:50,540
you can set up your dashboards which

00:02:48,920 --> 00:02:53,209
show you things that you're interested

00:02:50,540 --> 00:02:56,180
about your set up queries and then from

00:02:53,209 --> 00:02:59,450
your query will process the web for data

00:02:56,180 --> 00:03:00,890
will analyze it and will present it then

00:02:59,450 --> 00:03:02,720
there's these flexible dashboards where

00:03:00,890 --> 00:03:04,780
you can drop the data up you can tag it

00:03:02,720 --> 00:03:09,709
categorize it chart things like things

00:03:04,780 --> 00:03:11,390
and find out things that happening so

00:03:09,709 --> 00:03:13,730
we've built the platform in such a way

00:03:11,390 --> 00:03:16,030
that we allow the users to and analyze

00:03:13,730 --> 00:03:18,380
the data themselves I mean this is a

00:03:16,030 --> 00:03:20,269
custom kind of rules in categories that

00:03:18,380 --> 00:03:22,670
they've set up based on particular

00:03:20,269 --> 00:03:24,890
tweets and forum blog post coming in and

00:03:22,670 --> 00:03:27,230
taking them with particular car brands

00:03:24,890 --> 00:03:29,510
and you can chart it by sort of the two

00:03:27,230 --> 00:03:31,930
pages where things came from over the

00:03:29,510 --> 00:03:33,829
days that those things happened and

00:03:31,930 --> 00:03:34,790
there's a lot of flexibility in this

00:03:33,829 --> 00:03:36,230
platform that's what we've done really

00:03:34,790 --> 00:03:38,180
well over the last few years we've built

00:03:36,230 --> 00:03:41,030
this great framework for storing and

00:03:38,180 --> 00:03:43,220
processing data and we do various

00:03:41,030 --> 00:03:45,829
different types of classification for

00:03:43,220 --> 00:03:47,540
example we do demographics

00:03:45,829 --> 00:03:50,810
classifications based on people's

00:03:47,540 --> 00:03:52,940
Twitter profiles so for example if

00:03:50,810 --> 00:03:54,530
they're male or female what things they

00:03:52,940 --> 00:03:56,299
talk about the topics of conversation

00:03:54,530 --> 00:03:57,680
they talk about and what we try and

00:03:56,299 --> 00:03:58,910
guess what their professions are and

00:03:57,680 --> 00:04:01,730
their interests based on what they're

00:03:58,910 --> 00:04:03,200
talking about online and we use rules

00:04:01,730 --> 00:04:04,340
base classifiers and machine learning in

00:04:03,200 --> 00:04:07,069
various different techniques for this

00:04:04,340 --> 00:04:09,260
and it's not just the top level metrics

00:04:07,069 --> 00:04:10,730
that you get in the app and we've

00:04:09,260 --> 00:04:13,280
indexed everything that's matched our

00:04:10,730 --> 00:04:15,870
customers queries back to 2007 and we

00:04:13,280 --> 00:04:17,579
have quite a large solar index

00:04:15,870 --> 00:04:19,350
use a lot of age base and post res and

00:04:17,579 --> 00:04:20,489
various other things which I won't be

00:04:19,350 --> 00:04:22,290
covering in this talk because this is

00:04:20,489 --> 00:04:24,510
about this is a real time thing that we

00:04:22,290 --> 00:04:25,860
built on top of our platform but we've

00:04:24,510 --> 00:04:29,190
given talks before about various things

00:04:25,860 --> 00:04:33,240
that we use so just some numbers if I

00:04:29,190 --> 00:04:34,889
fight with this there we go and we've

00:04:33,240 --> 00:04:36,840
got about 50 instances of java web

00:04:34,889 --> 00:04:38,790
crawlers and this was kind of the first

00:04:36,840 --> 00:04:40,290
thing that was in our product we wrote

00:04:38,790 --> 00:04:42,090
them mostly in house at the time many

00:04:40,290 --> 00:04:45,139
years ago and we've extended them ever

00:04:42,090 --> 00:04:47,940
since and we're probably crawling about

00:04:45,139 --> 00:04:49,830
hun tens of hundreds or other hundreds

00:04:47,940 --> 00:04:52,889
of millions of web pages a day which we

00:04:49,830 --> 00:04:55,880
then matching in memory to our customers

00:04:52,889 --> 00:04:58,770
queries we also have historical queries

00:04:55,880 --> 00:05:00,449
where when you can set it up we can

00:04:58,770 --> 00:05:01,470
match against our historical index that

00:05:00,449 --> 00:05:04,130
we've got the goes back all those years

00:05:01,470 --> 00:05:05,880
you can get in some context in your data

00:05:04,130 --> 00:05:07,639
so you're not starting with a blank

00:05:05,880 --> 00:05:09,419
canvas when you select people searches

00:05:07,639 --> 00:05:13,020
before we go any further is the

00:05:09,419 --> 00:05:16,139
microphone distorted slightly just a

00:05:13,020 --> 00:05:22,410
little bit is that okay is that better

00:05:16,139 --> 00:05:25,039
or not yeah cool I think that's okay

00:05:22,410 --> 00:05:27,479
okay I'll carry on we process and

00:05:25,039 --> 00:05:30,210
twisted data directly from Twitter and

00:05:27,479 --> 00:05:31,860
we get the deck of hose we use power

00:05:30,210 --> 00:05:35,490
track for all the terms that match our

00:05:31,860 --> 00:05:36,900
customers queries we get dates from

00:05:35,490 --> 00:05:38,220
Weibo and discuss in many different

00:05:36,900 --> 00:05:39,960
places we've got lots and lots of fire

00:05:38,220 --> 00:05:42,360
hoses and different things coming into

00:05:39,960 --> 00:05:44,310
our system and there's about 80 million

00:05:42,360 --> 00:05:46,050
plus matches to customer queries every

00:05:44,310 --> 00:05:48,510
day so that's data going into those

00:05:46,050 --> 00:05:51,229
dashboards I shows you about does that

00:05:48,510 --> 00:05:55,500
all make sense so far some nodding good

00:05:51,229 --> 00:05:57,800
so the platform itself was used for a

00:05:55,500 --> 00:05:59,849
lot of historical and analysis and I'm

00:05:57,800 --> 00:06:03,440
extremely sorry about this but this

00:05:59,849 --> 00:06:03,440
clicker is infuriating

00:06:07,020 --> 00:06:12,400
it's okay I'll try and fight with it and

00:06:09,960 --> 00:06:14,410
so we release this product the other

00:06:12,400 --> 00:06:15,310
year and called vizia so rather than

00:06:14,410 --> 00:06:18,190
just sitting in front of your computer

00:06:15,310 --> 00:06:19,480
and digging into your dashboards we now

00:06:18,190 --> 00:06:20,860
have this really cool infographics

00:06:19,480 --> 00:06:23,230
products where if you're a company you

00:06:20,860 --> 00:06:24,880
can come along and you can have us

00:06:23,230 --> 00:06:26,860
install these awesome infographics in

00:06:24,880 --> 00:06:28,320
your lobby in your bank in your office

00:06:26,860 --> 00:06:30,700
in your command center in your business

00:06:28,320 --> 00:06:32,230
and they're a great kind of point of

00:06:30,700 --> 00:06:33,400
conversation and they were driven by the

00:06:32,230 --> 00:06:36,040
platform that we've written over the

00:06:33,400 --> 00:06:37,180
last few years and that's great this is

00:06:36,040 --> 00:06:38,860
this is the first step of people getting

00:06:37,180 --> 00:06:41,950
away from their computers to use our

00:06:38,860 --> 00:06:44,710
data and as time goes on you know you've

00:06:41,950 --> 00:06:46,690
got people accessing things on their

00:06:44,710 --> 00:06:47,980
phones on their tablets so increasingly

00:06:46,690 --> 00:06:49,750
people are kind of away from the

00:06:47,980 --> 00:06:52,000
computer when they're looking at our

00:06:49,750 --> 00:06:54,880
data and people want to find out what's

00:06:52,000 --> 00:06:57,460
happening right now really and here's an

00:06:54,880 --> 00:06:59,260
interesting picture from this is jag you

00:06:57,460 --> 00:07:04,290
were the car company does anyone own a

00:06:59,260 --> 00:07:07,900
Jaguar anyone like to earn the jugular

00:07:04,290 --> 00:07:09,970
German cars a cool head so this was

00:07:07,900 --> 00:07:11,950
there at their war room during the World

00:07:09,970 --> 00:07:13,960
War during the super bowl halftime so

00:07:11,950 --> 00:07:15,100
you've got the super bowl adverts going

00:07:13,960 --> 00:07:16,870
up at the halftime in the middle there

00:07:15,100 --> 00:07:18,550
being projected and they're using our

00:07:16,870 --> 00:07:20,470
video screens to display the data and

00:07:18,550 --> 00:07:22,210
they're on the laptop in the brand watch

00:07:20,470 --> 00:07:24,310
app and looking at all the data coming

00:07:22,210 --> 00:07:28,540
in in order to sort of see how their

00:07:24,310 --> 00:07:30,550
adverts are going down and increasingly

00:07:28,540 --> 00:07:32,890
this is happening in many different

00:07:30,550 --> 00:07:35,070
organizations and people want to be able

00:07:32,890 --> 00:07:37,870
to react to crises when they happen so

00:07:35,070 --> 00:07:40,690
for example if there's a big PR crisis

00:07:37,870 --> 00:07:42,130
with your brand or your organization you

00:07:40,690 --> 00:07:44,010
want to be able to react first before

00:07:42,130 --> 00:07:46,030
you know the press pick it up before and

00:07:44,010 --> 00:07:47,770
anybody else gets there and you can

00:07:46,030 --> 00:07:51,220
prepare your response and you can be

00:07:47,770 --> 00:07:54,070
composed when these things happen so we

00:07:51,220 --> 00:07:55,990
have a new challenge as well as this

00:07:54,070 --> 00:07:57,910
clicker and we have a new challenge so

00:07:55,990 --> 00:08:00,900
what this is is that in that picture

00:07:57,910 --> 00:08:03,940
that we had before there was a spike and

00:08:00,900 --> 00:08:05,919
people if they're logging into the app

00:08:03,940 --> 00:08:08,230
to see their data they might not have

00:08:05,919 --> 00:08:11,169
seen that when it happened so is there

00:08:08,230 --> 00:08:12,400
any way that we can build a system that

00:08:11,169 --> 00:08:13,990
can tell people when they're away from

00:08:12,400 --> 00:08:15,400
the app who maybe that was a Sunday

00:08:13,990 --> 00:08:17,430
maybe it was a Saturday people weren't

00:08:15,400 --> 00:08:19,419
actually logged in using the application

00:08:17,430 --> 00:08:20,090
tell them that something interesting is

00:08:19,419 --> 00:08:21,710
happening so

00:08:20,090 --> 00:08:24,230
can then log in and deal with a crisis

00:08:21,710 --> 00:08:27,710
so this is sort of signal from the noise

00:08:24,230 --> 00:08:29,300
problem so this is the challenge we have

00:08:27,710 --> 00:08:33,610
about it's working now that's wonderful

00:08:29,300 --> 00:08:36,260
oh it's not such a shame we've got about

00:08:33,610 --> 00:08:38,089
130,000 user queries in the system so

00:08:36,260 --> 00:08:39,260
those are lots of streams of data that

00:08:38,089 --> 00:08:40,880
we're processing and matching to

00:08:39,260 --> 00:08:42,469
different peoples queries and we've got

00:08:40,880 --> 00:08:44,779
about 18 million mentions a day going

00:08:42,469 --> 00:08:46,850
into those if we were to use our data

00:08:44,779 --> 00:08:48,740
stores that drive our platform in order

00:08:46,850 --> 00:08:51,500
to do say for example a traditional kind

00:08:48,740 --> 00:08:52,610
of SQL style breakdown query of what's

00:08:51,500 --> 00:08:54,770
happening right now what's happening

00:08:52,610 --> 00:08:57,230
right now it takes over eight hours to

00:08:54,770 --> 00:08:58,970
go over each one individually so using

00:08:57,230 --> 00:09:00,890
the platform that we've built just won't

00:08:58,970 --> 00:09:02,270
really handle this kind of thing so we

00:09:00,890 --> 00:09:03,860
need to build a new system that will be

00:09:02,270 --> 00:09:06,740
able to do it and that's what I'll talk

00:09:03,860 --> 00:09:08,120
you through today so this is a rough

00:09:06,740 --> 00:09:09,320
overview of what we built and on the

00:09:08,120 --> 00:09:13,610
left-hand side you've got our web

00:09:09,320 --> 00:09:14,570
crawlers 12 n we slapped cafe right in

00:09:13,610 --> 00:09:16,220
the middle of this because it did a

00:09:14,570 --> 00:09:18,770
wonderful job of piping our data around

00:09:16,220 --> 00:09:20,060
in this and all of the mentions that

00:09:18,770 --> 00:09:21,350
were matching people's queries we kind

00:09:20,060 --> 00:09:23,330
of liberated from the crawlers and we

00:09:21,350 --> 00:09:26,450
just put them into Kafka and then we

00:09:23,330 --> 00:09:28,400
built this self-organizing cluster which

00:09:26,450 --> 00:09:30,110
we called our signal processing cluster

00:09:28,400 --> 00:09:31,400
that's processing the data from all

00:09:30,110 --> 00:09:33,529
these queries and finding out when

00:09:31,400 --> 00:09:35,000
something interesting is happening when

00:09:33,529 --> 00:09:37,220
it's found something interesting it

00:09:35,000 --> 00:09:39,950
pipes out on a nuke Africa topic of

00:09:37,220 --> 00:09:42,410
events and then we have other processes

00:09:39,950 --> 00:09:44,120
pulling on those events looking at them

00:09:42,410 --> 00:09:45,890
analyzing them trying to see whether

00:09:44,120 --> 00:09:48,020
there's something relevant to show our

00:09:45,890 --> 00:09:50,900
customers and then we also store them

00:09:48,020 --> 00:09:53,300
today to stores at the end it's a first

00:09:50,900 --> 00:09:56,950
think Africa quick show of hands who has

00:09:53,300 --> 00:09:59,920
used kafka who uses it in production

00:09:56,950 --> 00:10:03,830
unless it's still a fair amount and

00:09:59,920 --> 00:10:05,720
who's had good experiences with it yeah

00:10:03,830 --> 00:10:09,560
I mean we've we've had a really good

00:10:05,720 --> 00:10:11,720
time where you pretty much depend on CAF

00:10:09,560 --> 00:10:13,970
canal for all the things that we do so

00:10:11,720 --> 00:10:16,029
the step one was get the matches to

00:10:13,970 --> 00:10:19,760
people's queries and put them into Kafka

00:10:16,029 --> 00:10:21,370
so what is Kafka it is who doesn't know

00:10:19,760 --> 00:10:23,690
what categories it's cool if you don't

00:10:21,370 --> 00:10:25,550
that's cool so there's this bit of the

00:10:23,690 --> 00:10:27,740
talk and those of you who know lots

00:10:25,550 --> 00:10:29,300
about it do bear with and it's a

00:10:27,740 --> 00:10:30,920
publisher subscribed messaging system

00:10:29,300 --> 00:10:32,800
and there's been so many talks today

00:10:30,920 --> 00:10:34,959
that talk about it and

00:10:32,800 --> 00:10:37,930
but unlike a traditional message broker

00:10:34,959 --> 00:10:39,550
it's a distributed commit log so I've

00:10:37,930 --> 00:10:43,899
seen it also described as the sort of

00:10:39,550 --> 00:10:45,519
the UNIX pipes of streams and it became

00:10:43,899 --> 00:10:48,490
an Apache top level projects in november

00:10:45,519 --> 00:10:50,170
2003 and it started linkedin the guys

00:10:48,490 --> 00:10:52,180
behind calf grove done a really amazing

00:10:50,170 --> 00:10:53,829
job of providing great documentation is

00:10:52,180 --> 00:10:55,899
really easy to install and get it set up

00:10:53,829 --> 00:10:56,860
and just try it out and and that's the

00:10:55,899 --> 00:10:58,779
kind of thing that drew us to the

00:10:56,860 --> 00:11:00,459
project because when there's lots of

00:10:58,779 --> 00:11:02,019
care putting around the edges you can

00:11:00,459 --> 00:11:06,760
usually tell that it's a good project

00:11:02,019 --> 00:11:08,320
underneath it's pretty fast hundreds of

00:11:06,760 --> 00:11:10,890
megabytes of rewrites per second from

00:11:08,320 --> 00:11:13,450
thousands of clients it's scalable and

00:11:10,890 --> 00:11:15,760
you have your Kafka nodes in a cluster

00:11:13,450 --> 00:11:18,160
and it's partitioned over many machines

00:11:15,760 --> 00:11:19,570
it's replica replicated rather and you

00:11:18,160 --> 00:11:21,070
can expand it without downtown you can

00:11:19,570 --> 00:11:23,230
add new nodes into the category Custer

00:11:21,070 --> 00:11:25,990
and it just gets on with this thing and

00:11:23,230 --> 00:11:27,910
it's durable and so messages that you

00:11:25,990 --> 00:11:31,029
send to a Kafka topic or persisted to

00:11:27,910 --> 00:11:32,459
disk which sounds a bit weird and then

00:11:31,029 --> 00:11:35,649
they replicated in the cluster and

00:11:32,459 --> 00:11:38,560
written to disk is a bit strange but

00:11:35,649 --> 00:11:41,940
this is a graph from a cmq from a couple

00:11:38,560 --> 00:11:44,829
years ago and the speed of sequential

00:11:41,940 --> 00:11:46,720
reads from disk is actually really good

00:11:44,829 --> 00:11:48,459
I mean it's comparable if not better

00:11:46,720 --> 00:11:50,680
than the random access in memory and

00:11:48,459 --> 00:11:52,720
because the Linux kernel does lots of

00:11:50,680 --> 00:11:55,180
clever stuff with paging so if you know

00:11:52,720 --> 00:11:56,709
where you are on disk with your

00:11:55,180 --> 00:11:57,970
particular message you're consuming and

00:11:56,709 --> 00:11:59,950
you know that everything's stored

00:11:57,970 --> 00:12:01,240
sequentially contiguously then then

00:11:59,950 --> 00:12:03,339
streaming the rest of them is actually

00:12:01,240 --> 00:12:05,470
quite a fast operation and storing to

00:12:03,339 --> 00:12:08,850
disk is really cheap and it's persistent

00:12:05,470 --> 00:12:12,820
which is great and this is a graph from

00:12:08,850 --> 00:12:14,589
Twitter themselves so they in their

00:12:12,820 --> 00:12:16,540
infrastructure that sends out data to

00:12:14,589 --> 00:12:19,089
people like us they're using cash core a

00:12:16,540 --> 00:12:20,980
lot and the blue lines on here are a

00:12:19,089 --> 00:12:23,770
load test of sending a whole other

00:12:20,980 --> 00:12:25,930
tweets at Kafka that red line is a

00:12:23,770 --> 00:12:27,459
consumer that's pulling them and you see

00:12:25,930 --> 00:12:28,750
that in their load test there gets to

00:12:27,459 --> 00:12:30,610
this point where the red line doesn't

00:12:28,750 --> 00:12:32,620
keep up with the blue line because it

00:12:30,610 --> 00:12:34,930
can't keep up anymore well that's not

00:12:32,620 --> 00:12:37,420
actually a problem because the consumer

00:12:34,930 --> 00:12:39,519
is reading from disk and messages are

00:12:37,420 --> 00:12:42,160
being pushed to disk they're just

00:12:39,519 --> 00:12:43,449
getting put in a log so the consumer

00:12:42,160 --> 00:12:45,939
can't keep up but it's okay because

00:12:43,449 --> 00:12:47,499
after a while it does catch up and you

00:12:45,939 --> 00:12:49,659
with an infrastructure that's much more

00:12:47,499 --> 00:12:51,579
flexible and bendy you don't have

00:12:49,659 --> 00:12:52,959
problems like we had originally when we

00:12:51,579 --> 00:12:54,279
started doing this without Khafre when

00:12:52,959 --> 00:12:56,829
we were quite heavily dependent on

00:12:54,279 --> 00:12:57,909
hornik you wear if Hornick you got too

00:12:56,829 --> 00:12:59,349
much back pressure it would just

00:12:57,909 --> 00:13:02,949
effectively fall over which is really

00:12:59,349 --> 00:13:04,809
bad so many thumbs up to cap for Kafka

00:13:02,949 --> 00:13:07,959
and if you're using it and for example

00:13:04,809 --> 00:13:09,759
in our crawlers we just take the message

00:13:07,959 --> 00:13:11,739
in the mention that matches the query

00:13:09,759 --> 00:13:13,989
right at the end before we persist it to

00:13:11,739 --> 00:13:16,239
our usual stores we create a new message

00:13:13,989 --> 00:13:18,009
on Caprica we send it to a new topic and

00:13:16,239 --> 00:13:20,619
we send it asynchronously in the

00:13:18,009 --> 00:13:22,929
background and it's done and that's

00:13:20,619 --> 00:13:25,929
about it for the first part and you can

00:13:22,929 --> 00:13:27,249
keep your messages in CAF go for as long

00:13:25,929 --> 00:13:29,049
as you like really you can specify in

00:13:27,249 --> 00:13:30,639
the properties if you'd like to keep

00:13:29,049 --> 00:13:33,669
them for say some amount of time for

00:13:30,639 --> 00:13:35,229
example a day or a week a month even

00:13:33,669 --> 00:13:37,299
depends how much disk space you've got

00:13:35,229 --> 00:13:39,309
or you can keep them up to a point of

00:13:37,299 --> 00:13:42,220
number of megabytes or gigabytes of disk

00:13:39,309 --> 00:13:44,049
space or both whichever happens first so

00:13:42,220 --> 00:13:46,509
you can then replay messages on the

00:13:44,049 --> 00:13:49,569
topic a week later if you want which is

00:13:46,509 --> 00:13:52,449
a really neat feature so step one is

00:13:49,569 --> 00:13:56,079
done excellent we now move on to

00:13:52,449 --> 00:13:57,909
processing so just to recap because I

00:13:56,079 --> 00:14:00,789
went off on a kafka diversion there what

00:13:57,909 --> 00:14:03,569
we're going to be talking about is how

00:14:00,789 --> 00:14:05,919
do we detect that thing when it happens

00:14:03,569 --> 00:14:07,119
so that we can tell our customers that

00:14:05,919 --> 00:14:10,479
something's happened that they should

00:14:07,119 --> 00:14:14,739
log in and have a look we're going to

00:14:10,479 --> 00:14:16,959
start off by talking about just one JVM

00:14:14,739 --> 00:14:19,329
doing this and also tracking just one

00:14:16,959 --> 00:14:22,720
type of thing so the example that we're

00:14:19,329 --> 00:14:25,149
going to use his hash tags and let's say

00:14:22,720 --> 00:14:29,319
that someone just tweeted probably about

00:14:25,149 --> 00:14:30,729
the crazy AV for example right now that

00:14:29,319 --> 00:14:33,419
is amazing actually check your watches I

00:14:30,729 --> 00:14:36,999
time this it's currently five pass for

00:14:33,419 --> 00:14:38,529
clever and someone tweeted for example

00:14:36,999 --> 00:14:41,499
about me and I'm here and I'm giving a

00:14:38,529 --> 00:14:43,059
talk and I'll crawlers do all the

00:14:41,499 --> 00:14:46,720
various things to these mention as they

00:14:43,059 --> 00:14:48,849
come in and they split up who the author

00:14:46,720 --> 00:14:51,489
is what the hashtags are in array who's

00:14:48,849 --> 00:14:54,039
being mentioned that kind of thing then

00:14:51,489 --> 00:14:55,809
the most basic level really we can just

00:14:54,039 --> 00:14:57,639
start counting these these things when

00:14:55,809 --> 00:14:59,180
they're happening so let's just think

00:14:57,639 --> 00:15:01,160
about maybe a map for

00:14:59,180 --> 00:15:03,260
poor and we can start off with a map and

00:15:01,160 --> 00:15:05,600
the key is update which can just be

00:15:03,260 --> 00:15:07,760
flawed to the hour so you can have 24

00:15:05,600 --> 00:15:09,080
hours of keys you could just have twelve

00:15:07,760 --> 00:15:13,250
o'clock one o'clock two o'clock three

00:15:09,080 --> 00:15:15,830
o'clock and then the value to that key

00:15:13,250 --> 00:15:17,480
is a multiset and you can just

00:15:15,830 --> 00:15:20,810
initialize it with the last 24 hours for

00:15:17,480 --> 00:15:22,250
example then when this tweet that we

00:15:20,810 --> 00:15:24,290
just saw came in you can have a look at

00:15:22,250 --> 00:15:25,460
the time and then you can floor it to

00:15:24,290 --> 00:15:28,640
the current hours you say four o'clock

00:15:25,460 --> 00:15:30,170
the four o'clock bucket and then you can

00:15:28,640 --> 00:15:31,880
just put those hashtags in the multiset

00:15:30,170 --> 00:15:34,280
it's a really really simple way of doing

00:15:31,880 --> 00:15:36,230
this and then you just have a count of

00:15:34,280 --> 00:15:37,520
one next to those in the multiset so

00:15:36,230 --> 00:15:39,950
that's that's the most basic level what

00:15:37,520 --> 00:15:41,180
you can be doing and okay let's say

00:15:39,950 --> 00:15:44,240
we've got these buckets we can then

00:15:41,180 --> 00:15:45,740
cycle these buckets so if using spring

00:15:44,240 --> 00:15:48,560
you can use a scheduled annotation which

00:15:45,740 --> 00:15:52,100
on the hour every hour we'll get the

00:15:48,560 --> 00:15:54,380
oldest key in our map remove it and then

00:15:52,100 --> 00:15:56,630
create a new one the the newest hour and

00:15:54,380 --> 00:15:59,150
that way you've got this sort of 24-hour

00:15:56,630 --> 00:16:02,600
cycle just going in memory in a map

00:15:59,150 --> 00:16:04,370
really simple stuff so then we've got

00:16:02,600 --> 00:16:07,250
these hashtag counts being made which is

00:16:04,370 --> 00:16:08,570
pretty straightforward so far how do we

00:16:07,250 --> 00:16:11,060
detect that something interesting has

00:16:08,570 --> 00:16:14,180
happened well we can think about it like

00:16:11,060 --> 00:16:17,060
this maybe at scheduled intervals so

00:16:14,180 --> 00:16:20,600
every minute every every hour whatever

00:16:17,060 --> 00:16:22,790
we think is necessary for each hashtag

00:16:20,600 --> 00:16:24,860
that we have we can transform that data

00:16:22,790 --> 00:16:26,960
structure into an equivalent one which

00:16:24,860 --> 00:16:29,330
is effectively time series so for each

00:16:26,960 --> 00:16:31,520
hashtag at each data point how many

00:16:29,330 --> 00:16:33,740
counts that they've been we can compare

00:16:31,520 --> 00:16:36,140
that our to our history that we've got

00:16:33,740 --> 00:16:37,640
in memory we give it a score based on

00:16:36,140 --> 00:16:39,680
the algorithm that we decide to use to

00:16:37,640 --> 00:16:42,470
detect the spike eNOS and then we can

00:16:39,680 --> 00:16:44,330
have some presets so for a given average

00:16:42,470 --> 00:16:46,040
volume of a query and one of our

00:16:44,330 --> 00:16:48,170
customers query if that score is over a

00:16:46,040 --> 00:16:50,750
threshold than we think it's probably

00:16:48,170 --> 00:16:53,330
interesting and then let's keep the work

00:16:50,750 --> 00:16:55,100
is really done so let's just send that

00:16:53,330 --> 00:16:56,750
event out on a nuke Africa topic because

00:16:55,100 --> 00:16:58,670
then we can write other applications and

00:16:56,750 --> 00:17:02,510
then stream those events and do stuff

00:16:58,670 --> 00:17:03,800
with it and and in the code itself I

00:17:02,510 --> 00:17:05,690
mean it's very very similar to this

00:17:03,800 --> 00:17:08,060
we've done the fair bit of work around

00:17:05,690 --> 00:17:10,610
and keeping the heaps down and keeping

00:17:08,060 --> 00:17:11,720
the history compacted but it's not too

00:17:10,610 --> 00:17:14,630
far off this what we

00:17:11,720 --> 00:17:16,220
doing but the issue that comes with this

00:17:14,630 --> 00:17:17,659
simple processing is not so much about

00:17:16,220 --> 00:17:18,949
the processing it's just countered like

00:17:17,659 --> 00:17:21,409
the previous talk was saying it's just

00:17:18,949 --> 00:17:23,839
counting things but the scale is the

00:17:21,409 --> 00:17:25,699
interesting bit so what we just did here

00:17:23,839 --> 00:17:29,179
is that we had a data model with

00:17:25,699 --> 00:17:30,679
counting hashtags not that exciting but

00:17:29,179 --> 00:17:32,299
there are many many different things

00:17:30,679 --> 00:17:33,620
that when we sat down with our customers

00:17:32,299 --> 00:17:35,090
before we did this project we said when

00:17:33,620 --> 00:17:36,860
you're looking at real time data what

00:17:35,090 --> 00:17:38,510
are you actually looking at in the app

00:17:36,860 --> 00:17:40,520
and what are you using to see if

00:17:38,510 --> 00:17:42,409
something interesting is happening loads

00:17:40,520 --> 00:17:44,480
of other things maybe the the links

00:17:42,409 --> 00:17:46,820
being shared any particular moment the

00:17:44,480 --> 00:17:48,080
general volume of the query the the net

00:17:46,820 --> 00:17:51,200
sentiment whether things are going

00:17:48,080 --> 00:17:52,669
positive or negative particular authors

00:17:51,200 --> 00:17:54,169
I mean there's lots of things that we

00:17:52,669 --> 00:17:56,120
have and if each of these has a

00:17:54,169 --> 00:17:59,059
different data structure you end up with

00:17:56,120 --> 00:18:01,700
just one query having these so buzzard

00:17:59,059 --> 00:18:03,320
Berlin buzzwords query but we have a lot

00:18:01,700 --> 00:18:06,140
of queries so we have a hundred thousand

00:18:03,320 --> 00:18:07,789
queries so the interesting bit is

00:18:06,140 --> 00:18:10,520
scaling and how do we distribute this

00:18:07,789 --> 00:18:14,240
out into a cluster in such a way that it

00:18:10,520 --> 00:18:16,700
continues to scale and it works so we

00:18:14,240 --> 00:18:20,720
need more JVMs so how do we share the

00:18:16,700 --> 00:18:22,220
workload so distribution of work let's

00:18:20,720 --> 00:18:24,590
move on to the next bit we looked at one

00:18:22,220 --> 00:18:27,409
JVM doing hashtags there let's think

00:18:24,590 --> 00:18:28,990
about a cluster so that box at the

00:18:27,409 --> 00:18:32,090
bottom has now become a little cloud

00:18:28,990 --> 00:18:34,250
many Jovians what are we actually

00:18:32,090 --> 00:18:36,830
distributing well it makes sense that

00:18:34,250 --> 00:18:38,390
one query one of our customers queries

00:18:36,830 --> 00:18:41,809
with a data stream is a good thing to

00:18:38,390 --> 00:18:44,570
distribute but how do we take that one

00:18:41,809 --> 00:18:46,640
query and give it to one JVM and none of

00:18:44,570 --> 00:18:48,320
the other ones just one of them where

00:18:46,640 --> 00:18:51,710
this case we use leader elections so

00:18:48,320 --> 00:18:54,909
who's familiar with leader election few

00:18:51,710 --> 00:18:57,470
people and leader election is a

00:18:54,909 --> 00:18:59,179
methodology for finding the leader for a

00:18:57,470 --> 00:19:01,070
task in a group of distribution notes

00:18:59,179 --> 00:19:03,919
you've got some number of nodes you want

00:19:01,070 --> 00:19:06,049
one of them to do it some methodology

00:19:03,919 --> 00:19:07,669
needs to pick one of those nodes so

00:19:06,049 --> 00:19:09,710
that's what we do if you want to do

00:19:07,669 --> 00:19:13,309
something like this then zookeepers

00:19:09,710 --> 00:19:15,020
really good zookeeper users cool lots of

00:19:13,309 --> 00:19:17,090
zookeeper users whose kind of like a

00:19:15,020 --> 00:19:19,340
zookeeper I guess I don't try to think

00:19:17,090 --> 00:19:21,169
the way to say not use it but you also

00:19:19,340 --> 00:19:24,110
develop with it so you may be written a

00:19:21,169 --> 00:19:27,809
feature that uses zookeeper to do stuff

00:19:24,110 --> 00:19:30,870
ok less people but it's good it's good

00:19:27,809 --> 00:19:32,250
and zookeepers a way of coordinating and

00:19:30,870 --> 00:19:33,840
managing distributed applications if

00:19:32,250 --> 00:19:36,389
you've installed stuff like HBase or

00:19:33,840 --> 00:19:38,669
HDFS or storm it always made Queen

00:19:36,389 --> 00:19:40,740
install with zookeeper as well that's

00:19:38,669 --> 00:19:41,879
because it's doing clever stuff which

00:19:40,740 --> 00:19:43,289
will be similar to what I'll just show

00:19:41,879 --> 00:19:46,169
you here and what we use for our system

00:19:43,289 --> 00:19:47,820
so zookeepers kind of like a file system

00:19:46,169 --> 00:19:50,580
or kind of like a tree depending on how

00:19:47,820 --> 00:19:51,840
you look at it and in our zookeeper

00:19:50,580 --> 00:19:53,309
cluster for example all the features

00:19:51,840 --> 00:19:54,659
that use it we have underneath

00:19:53,309 --> 00:19:57,149
brandwatch now because that's the name

00:19:54,659 --> 00:20:00,000
of the company and feature one feature

00:19:57,149 --> 00:20:02,399
two at the top level in zookeeper you'd

00:20:00,000 --> 00:20:04,139
have other things like the controllers

00:20:02,399 --> 00:20:05,759
and brokers thing for Kafka and has

00:20:04,139 --> 00:20:08,129
various things for each base if you're

00:20:05,759 --> 00:20:11,129
using it and you can use the command

00:20:08,129 --> 00:20:13,950
line interface as well and and you can

00:20:11,129 --> 00:20:15,539
do sort of LS where we are right now it

00:20:13,950 --> 00:20:17,309
will say zookeeper blah blah blah and

00:20:15,539 --> 00:20:19,019
then show me the things are underneath

00:20:17,309 --> 00:20:20,610
brokers running LS brokers and it will

00:20:19,019 --> 00:20:23,879
show you the thing so you can imagine it

00:20:20,610 --> 00:20:26,340
like that and if you're going to be

00:20:23,879 --> 00:20:27,659
doing programming using zookeeper to

00:20:26,340 --> 00:20:30,450
build your feature then we highly

00:20:27,659 --> 00:20:33,450
recommend using apache curator it's a

00:20:30,450 --> 00:20:35,340
library that netflix released the builds

00:20:33,450 --> 00:20:38,460
on top of the lower level zookeeper api

00:20:35,340 --> 00:20:40,919
and it gives you a whole bunch of

00:20:38,460 --> 00:20:42,929
recipes to work with so for example if

00:20:40,919 --> 00:20:44,730
you want to do some kind of shared

00:20:42,929 --> 00:20:46,860
reentrant lock across a cluster then

00:20:44,730 --> 00:20:48,899
they have some code that you can use to

00:20:46,860 --> 00:20:50,669
do it and likewise if you want to do

00:20:48,899 --> 00:20:52,500
some kind of leader election like we're

00:20:50,669 --> 00:20:54,659
going to be doing then they have some

00:20:52,500 --> 00:20:56,039
api's that you can use for that and it's

00:20:54,659 --> 00:20:58,289
pretty straightforward to use and the

00:20:56,039 --> 00:21:00,750
documentation is very good as well so

00:20:58,289 --> 00:21:02,970
thanks Netflix so let's think about what

00:21:00,750 --> 00:21:04,830
we're doing so in in the app customers

00:21:02,970 --> 00:21:06,480
have queries they say i want to receive

00:21:04,830 --> 00:21:07,740
emails when something interesting

00:21:06,480 --> 00:21:10,049
happens and they press a button and

00:21:07,740 --> 00:21:13,740
that's what we want this feature to be

00:21:10,049 --> 00:21:15,990
as simple as just press a button so when

00:21:13,740 --> 00:21:18,659
they press that button we're inserting a

00:21:15,990 --> 00:21:21,059
row into our postcards relational

00:21:18,659 --> 00:21:23,789
database to say that this user wants

00:21:21,059 --> 00:21:25,320
this thing so we're going to write a JVM

00:21:23,789 --> 00:21:27,059
that is then listening for what's

00:21:25,320 --> 00:21:30,360
happening in that database and when a

00:21:27,059 --> 00:21:33,600
query is enabled then it will put a

00:21:30,360 --> 00:21:35,700
query ID into zookeeper so brandwatch

00:21:33,600 --> 00:21:38,040
signals queries and put the query ID in

00:21:35,700 --> 00:21:39,270
there and likewise if they

00:21:38,040 --> 00:21:41,550
able the feature and they don't want to

00:21:39,270 --> 00:21:43,650
receive the emails anymore then that JVM

00:21:41,550 --> 00:21:46,190
will look it up find the node and just

00:21:43,650 --> 00:21:51,030
delete it does that make sense so far

00:21:46,190 --> 00:21:53,220
blank faces yeah cool so in order to get

00:21:51,030 --> 00:21:55,830
stuff out of the database so trying to

00:21:53,220 --> 00:21:58,290
work out when a thing happens and we

00:21:55,830 --> 00:22:02,010
used pgq for that and I'm not completely

00:21:58,290 --> 00:22:04,020
sold on PG q it's pretty good it was

00:22:02,010 --> 00:22:05,940
part of the londa strep location suite

00:22:04,020 --> 00:22:08,670
that skype wrote which is pretty good

00:22:05,940 --> 00:22:10,680
and it's part of that we wrote the Java

00:22:08,670 --> 00:22:12,720
consumer for it if this thing will stay

00:22:10,680 --> 00:22:14,610
still and it's on github so if you want

00:22:12,720 --> 00:22:16,410
to use it with your java apps then we

00:22:14,610 --> 00:22:19,200
did the hard work so just just use it

00:22:16,410 --> 00:22:20,910
away and you put a trigger on the table

00:22:19,200 --> 00:22:22,950
basically and every time that thing

00:22:20,910 --> 00:22:25,200
happens for example a row gets inserted

00:22:22,950 --> 00:22:27,060
into the into the table that says this

00:22:25,200 --> 00:22:30,980
user has requested the feature it sends

00:22:27,060 --> 00:22:34,020
an event on PG q and the JVM picks it up

00:22:30,980 --> 00:22:36,330
so 101 leader election for those of you

00:22:34,020 --> 00:22:38,400
are not initiated let's imagine that

00:22:36,330 --> 00:22:40,620
we've got this set up on zookeeper we

00:22:38,400 --> 00:22:43,140
have one query that's currently enabled

00:22:40,620 --> 00:22:45,120
we've got one that just gets enabled

00:22:43,140 --> 00:22:46,980
right now and we've got three JVMs

00:22:45,120 --> 00:22:50,460
listening to it for using curator then

00:22:46,980 --> 00:22:52,410
you can use the watching facility to say

00:22:50,460 --> 00:22:53,640
watch that queries node and tell me when

00:22:52,410 --> 00:22:57,450
something happens and you get a call

00:22:53,640 --> 00:22:59,760
back so this one 268 589 queries just

00:22:57,450 --> 00:23:02,760
got added right now the JVM will be

00:22:59,760 --> 00:23:04,380
watching the queries mode and when that

00:23:02,760 --> 00:23:05,970
gets added they all get a call back to

00:23:04,380 --> 00:23:07,320
say hey there's this you know what are

00:23:05,970 --> 00:23:09,210
you going to do about it and at that

00:23:07,320 --> 00:23:12,420
point in your code you say start leader

00:23:09,210 --> 00:23:14,520
election then it's a race what happens

00:23:12,420 --> 00:23:16,740
is each JVM will try and write an

00:23:14,520 --> 00:23:19,920
ephemeral sequential node underneath

00:23:16,740 --> 00:23:21,660
that ID so it's ephemeral because if the

00:23:19,920 --> 00:23:23,960
connection between zookeeper and the JVM

00:23:21,660 --> 00:23:27,330
is lost then that node will disappear

00:23:23,960 --> 00:23:28,470
when the acts and timeout it's

00:23:27,330 --> 00:23:30,840
sequential because the one that gets

00:23:28,470 --> 00:23:32,340
there first gets number one the one this

00:23:30,840 --> 00:23:35,220
they're saving this number two so the

00:23:32,340 --> 00:23:37,440
one who wins wins the job that's leader

00:23:35,220 --> 00:23:39,780
election basically so then what happens

00:23:37,440 --> 00:23:41,160
if you want to deal with failover so the

00:23:39,780 --> 00:23:43,260
let's say the leader is dead at this

00:23:41,160 --> 00:23:45,780
point then because it's an ephemeral

00:23:43,260 --> 00:23:48,720
node that node disappears it drops off

00:23:45,780 --> 00:23:50,610
and then it initiates the next stage of

00:23:48,720 --> 00:23:51,890
leader election where the second one in

00:23:50,610 --> 00:23:53,660
line gets the lead

00:23:51,890 --> 00:23:56,690
ship and then it processes the job and

00:23:53,660 --> 00:23:58,780
then if that one comes back it joins the

00:23:56,690 --> 00:24:01,340
back of the queue does that make sense

00:23:58,780 --> 00:24:04,400
so that's roughly how leader election

00:24:01,340 --> 00:24:05,810
works and we used it for this system in

00:24:04,400 --> 00:24:09,710
order to distribute the queries in

00:24:05,810 --> 00:24:11,630
different JVMs so there we go each time

00:24:09,710 --> 00:24:14,390
someone turns on the feature the note

00:24:11,630 --> 00:24:16,460
gets added we do leader election one of

00:24:14,390 --> 00:24:18,080
the jvm is in the cluster will get that

00:24:16,460 --> 00:24:20,080
they'll create the data structures and

00:24:18,080 --> 00:24:24,500
then you'll start consuming the buckets

00:24:20,080 --> 00:24:26,840
of data from Kafka so are we almost

00:24:24,500 --> 00:24:28,310
there well yes yes I know and the thing

00:24:26,840 --> 00:24:30,200
is is that we're processing long-running

00:24:28,310 --> 00:24:33,380
jobs there are some queries of been in

00:24:30,200 --> 00:24:35,030
our system for years and so we're

00:24:33,380 --> 00:24:37,280
distributing these jobs that aren't just

00:24:35,030 --> 00:24:38,750
a quick fire and forget they persist for

00:24:37,280 --> 00:24:41,570
a very long time potentially

00:24:38,750 --> 00:24:43,430
indefinitely so the workers that are

00:24:41,570 --> 00:24:45,380
distributing the load can they get

00:24:43,430 --> 00:24:47,600
overloaded and the answer is yes they

00:24:45,380 --> 00:24:49,070
can so one way to get around this is

00:24:47,600 --> 00:24:50,450
that we did load testing on these

00:24:49,070 --> 00:24:52,390
workers that were keeping stuff in

00:24:50,450 --> 00:24:55,520
memory and doing the spike detection and

00:24:52,390 --> 00:24:57,860
we profile the JVMs under the worst

00:24:55,520 --> 00:24:59,780
cases to find out the maximum heap they

00:24:57,860 --> 00:25:01,280
use for certain numbers of numbers of

00:24:59,780 --> 00:25:04,130
queries and we set that as a constant

00:25:01,280 --> 00:25:06,500
and it's configurable and we altered the

00:25:04,130 --> 00:25:08,900
leader election algorithm slightly in

00:25:06,500 --> 00:25:09,710
that when they win leadership they check

00:25:08,900 --> 00:25:12,050
to see whether they're already

00:25:09,710 --> 00:25:13,670
processing too many queries and if they

00:25:12,050 --> 00:25:15,140
are then they back out of leader

00:25:13,670 --> 00:25:18,200
election they pass it on to the next

00:25:15,140 --> 00:25:19,940
person and that works pretty well it

00:25:18,200 --> 00:25:22,670
means that no one node in that system

00:25:19,940 --> 00:25:24,280
can take on too much work but we're not

00:25:22,670 --> 00:25:26,510
actually all the way there yet because

00:25:24,280 --> 00:25:28,430
there's still an educator in that case

00:25:26,510 --> 00:25:31,370
where if all of your workers in your

00:25:28,430 --> 00:25:32,990
cluster all at max capacity then you can

00:25:31,370 --> 00:25:34,700
get this kind of infinite election

00:25:32,990 --> 00:25:36,440
problem where each of them says I can't

00:25:34,700 --> 00:25:37,670
do the job give it to the next one then

00:25:36,440 --> 00:25:39,470
that one says no I can't do it either

00:25:37,670 --> 00:25:41,000
and it gives it gives it on and then

00:25:39,470 --> 00:25:42,830
they just keep spinning and spinning and

00:25:41,000 --> 00:25:44,330
spinning I mean you should never really

00:25:42,830 --> 00:25:45,530
get into this situation hopefully you

00:25:44,330 --> 00:25:47,330
have enough resources in your cluster

00:25:45,530 --> 00:25:49,010
but it's still an educator you have to

00:25:47,330 --> 00:25:51,920
deal with potentially in case you ever

00:25:49,010 --> 00:25:53,510
did and the way that we we programmed

00:25:51,920 --> 00:25:55,700
around that edge case was that the

00:25:53,510 --> 00:25:58,220
worker code has a very short-lived cash

00:25:55,700 --> 00:26:00,290
just like a guava loading cash that just

00:25:58,220 --> 00:26:03,110
keeps a note if it refuses a particular

00:26:00,290 --> 00:26:04,460
query keeps it in memory and then we

00:26:03,110 --> 00:26:05,180
know that because all those know is that

00:26:04,460 --> 00:26:06,500
if everyone

00:26:05,180 --> 00:26:07,970
sure that everyone else in the

00:26:06,500 --> 00:26:09,680
leadership election process will get a

00:26:07,970 --> 00:26:11,930
fair Turner trying to process the query

00:26:09,680 --> 00:26:13,310
and then if it comes back around within

00:26:11,930 --> 00:26:16,310
the time period that it's in the cache

00:26:13,310 --> 00:26:18,050
then we know that nobody can do it and

00:26:16,310 --> 00:26:19,310
that's a really big problem and we've

00:26:18,050 --> 00:26:20,390
never gotten that situation because we

00:26:19,310 --> 00:26:22,550
always have enough workers spun up

00:26:20,390 --> 00:26:24,740
however at this point you might want to

00:26:22,550 --> 00:26:26,660
message your team send them a horrible

00:26:24,740 --> 00:26:28,760
text message maybe if you're really

00:26:26,660 --> 00:26:30,530
clever use a patchy meses to spin up

00:26:28,760 --> 00:26:31,910
some new workers or some kind of other

00:26:30,530 --> 00:26:34,160
elastic arrangement that you're using

00:26:31,910 --> 00:26:35,360
but that's a neat way that we got round

00:26:34,160 --> 00:26:37,520
of that a problem I thought it was quite

00:26:35,360 --> 00:26:39,380
proud of that so stay if we're having

00:26:37,520 --> 00:26:41,660
these workers deal with failover then

00:26:39,380 --> 00:26:44,210
they're keeping like 24 hours of data in

00:26:41,660 --> 00:26:47,060
memory at any given time so there needs

00:26:44,210 --> 00:26:49,910
to be some way that they can recover if

00:26:47,060 --> 00:26:51,590
leader drops from one to another they've

00:26:49,910 --> 00:26:53,600
lost that 24 hours of data so where does

00:26:51,590 --> 00:26:54,800
it come from and and that's why we do

00:26:53,600 --> 00:26:56,900
snapshotting so I'm not going to go into

00:26:54,800 --> 00:26:58,400
huge detail here however each of the

00:26:56,900 --> 00:27:01,460
workers are regularly snapshotting their

00:26:58,400 --> 00:27:03,290
data into HBase all the time and using a

00:27:01,460 --> 00:27:04,970
combination of some serialization and

00:27:03,290 --> 00:27:06,830
cry oh we managed to get it down to sort

00:27:04,970 --> 00:27:08,930
of naught point three not point four

00:27:06,830 --> 00:27:12,170
megabytes per query from a really large

00:27:08,930 --> 00:27:14,420
amount of JVM heap which is great and so

00:27:12,170 --> 00:27:16,550
we just regularly snapshot out if a

00:27:14,420 --> 00:27:17,930
worker dies maybe within five seconds

00:27:16,550 --> 00:27:19,670
another one's picked it back up we might

00:27:17,930 --> 00:27:21,200
have lost five seconds worth of mentions

00:27:19,670 --> 00:27:23,420
but if you were just trying to find

00:27:21,200 --> 00:27:26,510
events on a rough curve that's probably

00:27:23,420 --> 00:27:28,940
okay to deal with that so we've sort of

00:27:26,510 --> 00:27:30,110
done at this point to here where we have

00:27:28,940 --> 00:27:33,110
all the mentions coming out of our

00:27:30,110 --> 00:27:34,520
crawlers they're going into our cluster

00:27:33,110 --> 00:27:36,170
of nodes that are computing that when

00:27:34,520 --> 00:27:39,380
events are happening they're piping it

00:27:36,170 --> 00:27:40,850
out on a nuke Africa topic cool so the

00:27:39,380 --> 00:27:44,180
last bit of the talk is about finding

00:27:40,850 --> 00:27:45,490
meaning in these events so we want to

00:27:44,180 --> 00:27:47,960
have all these events that are happening

00:27:45,490 --> 00:27:49,520
and we want to deliver something concise

00:27:47,960 --> 00:27:51,650
and interesting into our customers in

00:27:49,520 --> 00:27:55,000
boxes there isn't spammy that hopefully

00:27:51,650 --> 00:27:58,730
means something so for example this is a

00:27:55,000 --> 00:28:00,440
real email from the system and when we

00:27:58,730 --> 00:28:03,410
were tracking our own launch of the

00:28:00,440 --> 00:28:04,490
product that I'm talking to you about we

00:28:03,410 --> 00:28:07,280
receive this email when a particular

00:28:04,490 --> 00:28:08,870
blog posted about it and lots of people

00:28:07,280 --> 00:28:11,930
started talking about it so we want to

00:28:08,870 --> 00:28:13,490
send them that for example the United

00:28:11,930 --> 00:28:16,910
States is trending for this particular

00:28:13,490 --> 00:28:18,509
query and it's that many mentions 132 in

00:28:16,910 --> 00:28:20,999
the last 41 minutes

00:28:18,509 --> 00:28:22,499
some topics of roughly the conversation

00:28:20,999 --> 00:28:25,049
what it's about and then also some

00:28:22,499 --> 00:28:27,329
influential mentions that we found at

00:28:25,049 --> 00:28:28,499
the time so we want to gather all this

00:28:27,329 --> 00:28:31,769
stuff up and then send it to the

00:28:28,499 --> 00:28:34,529
customer so firstly just to get some

00:28:31,769 --> 00:28:36,269
topics for example if there was a trend

00:28:34,529 --> 00:28:38,249
going on at the moment for the biebers

00:28:36,269 --> 00:28:40,829
hashtag then there might be a whole load

00:28:38,249 --> 00:28:42,179
of noisy text knocking around in this in

00:28:40,829 --> 00:28:43,679
this data song once we go off to our

00:28:42,179 --> 00:28:45,749
data stores and we say give me a random

00:28:43,679 --> 00:28:47,279
sample of data but it might turn out

00:28:45,749 --> 00:28:49,469
that if you do topic our rhythm on it

00:28:47,279 --> 00:28:51,329
like tf-idf or something similar then

00:28:49,469 --> 00:28:53,190
you'll get some fairly concise topics so

00:28:51,329 --> 00:28:55,529
that's that's fairly so overall with

00:28:53,190 --> 00:28:57,359
existing techniques not too interesting

00:28:55,529 --> 00:28:59,369
but it's a neat way of seeing at a

00:28:57,359 --> 00:29:00,779
glance what's going on but we want to

00:28:59,369 --> 00:29:03,779
send them one email we don't want to

00:29:00,779 --> 00:29:05,459
send them for example if bebas was

00:29:03,779 --> 00:29:07,409
trending and also the brand watch query

00:29:05,459 --> 00:29:08,999
had a general volume increase and also

00:29:07,409 --> 00:29:10,559
berlin was trending at the same time in

00:29:08,999 --> 00:29:12,779
the same query and the number of tweets

00:29:10,559 --> 00:29:14,369
from Germany had gone up we don't want

00:29:12,779 --> 00:29:15,629
to send four emails to our customers

00:29:14,369 --> 00:29:17,489
that were about the same thing because

00:29:15,629 --> 00:29:18,749
that would be really rubbish and so we

00:29:17,489 --> 00:29:20,789
want some way of being able to group

00:29:18,749 --> 00:29:24,959
them together to give them one email

00:29:20,789 --> 00:29:28,919
from all these different events what did

00:29:24,959 --> 00:29:32,339
we do firstly we look at granularity so

00:29:28,919 --> 00:29:34,319
for example a hashtag like bebas is more

00:29:32,339 --> 00:29:36,179
granular than a general increase in

00:29:34,319 --> 00:29:39,329
volume so we have a decision tree of

00:29:36,179 --> 00:29:41,459
granularity so that people will

00:29:39,329 --> 00:29:43,139
hopefully get something that is a

00:29:41,459 --> 00:29:45,359
granular event that describes what's

00:29:43,139 --> 00:29:46,799
going on also text similarity so if

00:29:45,359 --> 00:29:48,899
there are four different events at one

00:29:46,799 --> 00:29:51,059
given time we'll look at the similarity

00:29:48,899 --> 00:29:53,039
of the text to work out roughly if

00:29:51,059 --> 00:29:55,139
they're the same thing or not using some

00:29:53,039 --> 00:29:56,609
heuristics and we'll also look at the

00:29:55,139 --> 00:29:59,009
shape of the volume spotlighting in

00:29:56,609 --> 00:30:00,629
these events to see are they or are they

00:29:59,009 --> 00:30:02,129
not roughly happening at the same time

00:30:00,629 --> 00:30:04,409
with the same volumes and do a heuristic

00:30:02,129 --> 00:30:06,869
comparison between the two and if you

00:30:04,409 --> 00:30:08,669
combine all those three things then you

00:30:06,869 --> 00:30:12,179
can sort of plot them on a imaginary

00:30:08,669 --> 00:30:13,739
graph like this where we have volume up

00:30:12,179 --> 00:30:15,209
the side and then the granularity lon

00:30:13,739 --> 00:30:16,499
the bottom and we want to pick the thing

00:30:15,209 --> 00:30:18,419
that's the highest volume and the

00:30:16,499 --> 00:30:20,099
highest granularity and that becomes

00:30:18,419 --> 00:30:21,359
what we sort of called the hero of the

00:30:20,099 --> 00:30:23,009
email which is the thing that you get

00:30:21,359 --> 00:30:24,749
along the top that says this is

00:30:23,009 --> 00:30:26,459
happening and you get the volume on that

00:30:24,749 --> 00:30:28,079
spot line for it and then everything

00:30:26,459 --> 00:30:31,499
else gets relegated to sort of beneath

00:30:28,079 --> 00:30:31,920
the fold on the email for example during

00:30:31,499 --> 00:30:34,860
the

00:30:31,920 --> 00:30:36,420
debate in the UK elections and this

00:30:34,860 --> 00:30:38,880
particular tweet came out from the drum

00:30:36,420 --> 00:30:40,470
we released some data about the

00:30:38,880 --> 00:30:43,080
different things going on during the

00:30:40,470 --> 00:30:45,090
debate the drum posted it and we

00:30:43,080 --> 00:30:46,260
detected that was the most granular most

00:30:45,090 --> 00:30:48,810
interesting thing that was happening

00:30:46,260 --> 00:30:50,130
right now and then all these other

00:30:48,810 --> 00:30:52,200
things were happening for example

00:30:50,130 --> 00:30:54,150
hashtag leaders debate all these other

00:30:52,200 --> 00:30:55,680
things being pointed to we kind of

00:30:54,150 --> 00:30:57,000
relegated to beneath the fold so our

00:30:55,680 --> 00:31:00,060
customers didn't get loads of emails I

00:30:57,000 --> 00:31:01,290
just get one so hopefully that makes

00:31:00,060 --> 00:31:03,690
sense about that grouping that we were

00:31:01,290 --> 00:31:05,370
doing there so just some some closing

00:31:03,690 --> 00:31:07,440
remarks here I mean this is our first

00:31:05,370 --> 00:31:09,900
kind of foray into a sort of streaming

00:31:07,440 --> 00:31:12,420
in memory sort of real-time pipeline

00:31:09,900 --> 00:31:13,980
system and because we spent a lot of

00:31:12,420 --> 00:31:15,810
time over the last few years building

00:31:13,980 --> 00:31:17,700
out a really good at analytics platform

00:31:15,810 --> 00:31:20,610
and we're trying to build more things on

00:31:17,700 --> 00:31:22,560
top of this now for example for people

00:31:20,610 --> 00:31:25,050
to request custom filters for their

00:31:22,560 --> 00:31:28,230
streams before they get the detected

00:31:25,050 --> 00:31:30,450
signals so that we can then put another

00:31:28,230 --> 00:31:31,920
JVM in the pipeline which is doing

00:31:30,450 --> 00:31:33,780
filtering and then piping things out on

00:31:31,920 --> 00:31:35,160
another kafka topic and then you end up

00:31:33,780 --> 00:31:36,540
kind of composing these different

00:31:35,160 --> 00:31:39,270
streams of data as they become more

00:31:36,540 --> 00:31:40,980
enriched more interesting and then other

00:31:39,270 --> 00:31:43,940
people can build other apps based on it

00:31:40,980 --> 00:31:46,590
as well so our infographics panel are

00:31:43,940 --> 00:31:48,120
visiting can start consuming these

00:31:46,590 --> 00:31:50,820
events as they come out of Kafka and

00:31:48,120 --> 00:31:52,710
then for example if in their query and

00:31:50,820 --> 00:31:54,240
event happens you can then change the

00:31:52,710 --> 00:31:55,320
configuration of those displays to say

00:31:54,240 --> 00:31:57,780
hey this thing is happening right now

00:31:55,320 --> 00:31:59,700
and the architecture solves the problem

00:31:57,780 --> 00:32:01,230
anyway if you want to laugh at me

00:31:59,700 --> 00:32:03,360
because of AV trolls and that's my

00:32:01,230 --> 00:32:05,730
Twitter handle I like talking to

00:32:03,360 --> 00:32:08,070
like-minded people and please do say

00:32:05,730 --> 00:32:10,740
hello and that's about it so any

00:32:08,070 --> 00:32:13,700
questions and answers whoa that was

00:32:10,740 --> 00:32:13,700

YouTube URL: https://www.youtube.com/watch?v=TpSVh5MbJL8


