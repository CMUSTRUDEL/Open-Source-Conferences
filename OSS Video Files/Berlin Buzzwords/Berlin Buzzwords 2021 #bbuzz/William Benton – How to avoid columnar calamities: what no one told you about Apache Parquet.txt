Title: William Benton – How to avoid columnar calamities: what no one told you about Apache Parquet
Publication date: 2021-06-25
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	If you're dealing with structured data at scale, it's a safe bet that you're depending on Apache Parquet in at least a few parts of your pipeline. Parquet is a sensible default choice for storing structured data at rest because of two major advantages:  its efficiency and its ubiquity.  While Parquet's storage efficiency enables dramatically improved time and space performance for query jobs, its ubiquity may be even more valuable.  Since Parquet readers and writers are available in a wide range of languages and ecosystems, the Parquet format can support a range of applications across the data lifecycle, including data engineering and ETL jobs, query engines, and machine learning pipelines.

However, the ubiquity of Parquet readers and writers hides some complexity:  if you don't take care, some of the advantages of Parquet can be lost in translation as you move tables from Hadoop, Flink, or Spark jobs to Python machine learning code.  This talk will help you understand Parquet more fully in order to use it more effectively, with an eye towards the special challenges that might arise in polyglot environments.  We'll level-set with a quick overview of how Parquet works and why it's so efficient.  We'll then dive in to the type, encoding, and compression options available and discuss when each is most appropriate.  You'll learn how to interrogate and understand Parquet metadata, and you'll learn about some of the challenges you'll run into when sharing data between JVM-based data engineering pipelines and Python-based machine learning pipelines.  You'll leave this talk with a better understanding of Parquet and a roadmap pointing you away from some interoperability and performance pitfalls.

Speaker:
William Benton – https://2021.berlinbuzzwords.de/member/william-benton

More: https://2021.berlinbuzzwords.de/session/how-avoid-columnar-calamities-what-no-one-told-you-about-apache-parquet
Captions: 
	00:00:08,639 --> 00:00:10,800
here

00:00:09,519 --> 00:00:12,799
buzzwords is one of my favorite

00:00:10,800 --> 00:00:14,400
conferences

00:00:12,799 --> 00:00:17,440
and today i'm going to talk about one of

00:00:14,400 --> 00:00:19,119
my favorite topics with computing myths

00:00:17,440 --> 00:00:21,680
and it's actually one of my favorite

00:00:19,119 --> 00:00:24,800
kinds of computing myths

00:00:21,680 --> 00:00:25,840
and that people can do can they

00:00:24,800 --> 00:00:28,720
recognize

00:00:25,840 --> 00:00:30,320
breakdown and how they're false so

00:00:28,720 --> 00:00:33,120
here's a little bit about me

00:00:30,320 --> 00:00:34,719
um i'm currently working on data science

00:00:33,120 --> 00:00:37,360
product strategy at nvidia

00:00:34,719 --> 00:00:38,960
in strolls i've done data science and

00:00:37,360 --> 00:00:39,760
engineering management and emerging

00:00:38,960 --> 00:00:42,559
technology

00:00:39,760 --> 00:00:44,719
in sort of the programming languages

00:00:42,559 --> 00:00:47,920
distributed computing

00:00:44,719 --> 00:00:51,600
and space so i came to

00:00:47,920 --> 00:00:52,239
machine learning data sound that's gonna

00:00:51,600 --> 00:00:55,039
sort of

00:00:52,239 --> 00:00:56,239
influence the background that i provide

00:00:55,039 --> 00:00:59,680
in this talk

00:00:56,239 --> 00:01:01,760
as well so um that's that's sort of the

00:00:59,680 --> 00:01:03,680
high-level view of who's talking to you

00:01:01,760 --> 00:01:05,840
i should mention that while i work for

00:01:03,680 --> 00:01:09,760
nvidia i don't speak for nvidia these

00:01:05,840 --> 00:01:12,640
are my own opinions in this talk um

00:01:09,760 --> 00:01:12,960
but i want to start with a question and

00:01:12,640 --> 00:01:16,080
um

00:01:12,960 --> 00:01:19,600
anyone can provide their

00:01:16,080 --> 00:01:20,000
own responses but i want to think about

00:01:19,600 --> 00:01:22,240
it

00:01:20,000 --> 00:01:24,960
and that's some of them about computing

00:01:22,240 --> 00:01:28,000
that we still believe

00:01:24,960 --> 00:01:31,439
and to give you an idea of the kind of

00:01:28,000 --> 00:01:31,439
thing that i'm uh

00:01:31,680 --> 00:01:37,920
i'm thinking about here uh one of these

00:01:35,360 --> 00:01:38,880
one of these such myths is write once

00:01:37,920 --> 00:01:42,079
run anywhere

00:01:38,880 --> 00:01:44,000
for java right it's mostly true it's not

00:01:42,079 --> 00:01:47,520
entirely true

00:01:44,000 --> 00:01:49,759
but it's true enough to be useful

00:01:47,520 --> 00:01:52,479
right and once you understand why it's

00:01:49,759 --> 00:01:54,320
true and also where it breaks down

00:01:52,479 --> 00:01:56,960
you can really get a lot of the benefits

00:01:54,320 --> 00:02:00,240
out of the java ecosystem

00:01:56,960 --> 00:02:02,079
so think about the myths that you've

00:02:00,240 --> 00:02:03,680
learned were myths and that you still

00:02:02,079 --> 00:02:05,759
believe anyway

00:02:03,680 --> 00:02:08,959
and we'll talk about a couple of these

00:02:05,759 --> 00:02:10,640
in this talk so here's what the rest of

00:02:08,959 --> 00:02:11,680
the talk is going to look like

00:02:10,640 --> 00:02:14,080
we're going to start with some

00:02:11,680 --> 00:02:17,120
background sort of explaining

00:02:14,080 --> 00:02:21,200
how computer systems work and

00:02:17,120 --> 00:02:22,879
talking about talking about why

00:02:21,200 --> 00:02:26,080
things have to work the way they do to

00:02:22,879 --> 00:02:28,400
be efficient and will sort of motivate

00:02:26,080 --> 00:02:29,599
column number formats in general in that

00:02:28,400 --> 00:02:31,200
prologue

00:02:29,599 --> 00:02:32,800
then we'll talk about why you might want

00:02:31,200 --> 00:02:36,000
to use apache parquet

00:02:32,800 --> 00:02:39,120
in particular uh we'll look

00:02:36,000 --> 00:02:41,200
at how parquet gets

00:02:39,120 --> 00:02:42,879
good performance uh both in terms of

00:02:41,200 --> 00:02:45,440
space and speed

00:02:42,879 --> 00:02:46,720
and then we'll see some of the limits of

00:02:45,440 --> 00:02:48,720
one of the myths

00:02:46,720 --> 00:02:50,480
that we'll look at about part k which

00:02:48,720 --> 00:02:52,560
are some of the potential

00:02:50,480 --> 00:02:54,239
uh performance and interoperability

00:02:52,560 --> 00:02:57,920
problems you might run into

00:02:54,239 --> 00:02:59,920
using parquet in a polyglot environment

00:02:57,920 --> 00:03:01,760
and then finally um you know with it

00:02:59,920 --> 00:03:03,680
with a story we want a good denouement

00:03:01,760 --> 00:03:05,599
we want a happy ending

00:03:03,680 --> 00:03:07,760
in this talk we have a demo instead so

00:03:05,599 --> 00:03:09,519
we'll look at a demo of sort of how to

00:03:07,760 --> 00:03:11,680
identify these problems and work around

00:03:09,519 --> 00:03:14,080
them

00:03:11,680 --> 00:03:15,360
so i want to start by talking about why

00:03:14,080 --> 00:03:17,440
commoner formats in

00:03:15,360 --> 00:03:19,280
general and the title of this talk does

00:03:17,440 --> 00:03:21,440
include the phrase what no one told you

00:03:19,280 --> 00:03:23,040
about apache parquet i have to apologize

00:03:21,440 --> 00:03:25,519
because i'm going to start

00:03:23,040 --> 00:03:27,040
by level setting with some things that

00:03:25,519 --> 00:03:29,440
people may have told you already

00:03:27,040 --> 00:03:30,879
about parquet about columnar formats

00:03:29,440 --> 00:03:32,720
more generally

00:03:30,879 --> 00:03:34,720
and about some background about computer

00:03:32,720 --> 00:03:37,280
systems to illustrate why these formats

00:03:34,720 --> 00:03:37,280
make sense

00:03:37,599 --> 00:03:41,440
but first i have some more questions if

00:03:40,159 --> 00:03:45,360
we were all in the same room

00:03:41,440 --> 00:03:45,360
this would be easier but this is

00:03:45,599 --> 00:03:50,159
sort of something to think about for

00:03:46,959 --> 00:03:52,560
those of you who have python background

00:03:50,159 --> 00:03:54,480
i'm going to look at this code code

00:03:52,560 --> 00:03:57,200
example

00:03:54,480 --> 00:03:57,200
we're going to see

00:03:58,400 --> 00:04:05,040
two ways to change

00:04:01,519 --> 00:04:05,040
every element in an array

00:04:06,480 --> 00:04:09,680
the first one is to loop through

00:04:08,799 --> 00:04:15,840
explicitly

00:04:09,680 --> 00:04:15,840
and multiply each element by

00:04:16,880 --> 00:04:20,320
loop through each element by

00:04:20,799 --> 00:04:27,199
index and then

00:04:24,080 --> 00:04:29,120
multiply each one by four

00:04:27,199 --> 00:04:30,560
the second way is to use a vectorized

00:04:29,120 --> 00:04:34,160
operation

00:04:30,560 --> 00:04:36,400
in python and multiply the entire array

00:04:34,160 --> 00:04:37,919
by four at once

00:04:36,400 --> 00:04:39,919
uh those of you who are python

00:04:37,919 --> 00:04:43,840
programmers any thoughts about which of

00:04:39,919 --> 00:04:43,840
these is going to be faster

00:04:46,240 --> 00:04:50,800
so it's nice when it works out this way

00:04:48,320 --> 00:04:52,320
but the shorter code is also faster in

00:04:50,800 --> 00:04:53,680
this case because since we're not doing

00:04:52,320 --> 00:04:56,320
explicit looping

00:04:53,680 --> 00:04:57,040
we can operate on essentially every

00:04:56,320 --> 00:05:00,240
element

00:04:57,040 --> 00:05:02,240
in the vector in one library call

00:05:00,240 --> 00:05:03,759
and we get a lot of benefits and we can

00:05:02,240 --> 00:05:05,199
take advantage of parallelism and

00:05:03,759 --> 00:05:07,759
hardware and all sorts of other

00:05:05,199 --> 00:05:09,520
advantages as well so this is a question

00:05:07,759 --> 00:05:11,280
about which is faster this is one for

00:05:09,520 --> 00:05:12,639
people with a python background maybe

00:05:11,280 --> 00:05:13,440
maybe the data scientists in the

00:05:12,639 --> 00:05:14,800
audience

00:05:13,440 --> 00:05:16,639
i have another one for the data

00:05:14,800 --> 00:05:18,479
engineers in the audience

00:05:16,639 --> 00:05:19,680
which is if we're looking at an analytic

00:05:18,479 --> 00:05:22,000
database

00:05:19,680 --> 00:05:24,240
which one of these kinds of queries is

00:05:22,000 --> 00:05:26,800
going to be more common

00:05:24,240 --> 00:05:27,759
and we have a table with three floats

00:05:26,800 --> 00:05:30,720
and a string

00:05:27,759 --> 00:05:31,440
in it and the first option is that we're

00:05:30,720 --> 00:05:34,320
going to do some

00:05:31,440 --> 00:05:35,600
aggregates on one of the float columns

00:05:34,320 --> 00:05:39,840
and we're going to group by

00:05:35,600 --> 00:05:42,320
the value in the string column

00:05:39,840 --> 00:05:43,039
the second option is that we're going to

00:05:42,320 --> 00:05:47,520
combine

00:05:43,039 --> 00:05:47,520
every value in a row in some way

00:05:47,600 --> 00:05:51,199
into a single value or that we're going

00:05:49,360 --> 00:05:53,039
to use every value in a row

00:05:51,199 --> 00:05:54,800
so i mean you might say neither of these

00:05:53,039 --> 00:05:56,800
is more common these these both sort of

00:05:54,800 --> 00:05:59,280
look suspicious but the question is are

00:05:56,800 --> 00:06:02,160
we more likely to operate on every value

00:05:59,280 --> 00:06:05,199
in a few columns in an analytic context

00:06:02,160 --> 00:06:08,240
or are we more likely to operate on

00:06:05,199 --> 00:06:09,840
every value in a row and

00:06:08,240 --> 00:06:11,840
the answer is really going to be it

00:06:09,840 --> 00:06:13,520
depends but i think in a lot of analytic

00:06:11,840 --> 00:06:16,319
contexts you're much more likely to

00:06:13,520 --> 00:06:18,400
operate on every value in a column

00:06:16,319 --> 00:06:20,240
than you are to need to worry about

00:06:18,400 --> 00:06:23,680
every column in an individual

00:06:20,240 --> 00:06:27,840
row so

00:06:23,680 --> 00:06:29,280
with that context of sort of why we

00:06:27,840 --> 00:06:32,000
why we want to worry about doing

00:06:29,280 --> 00:06:34,479
operations a collection at a time

00:06:32,000 --> 00:06:35,199
and that we think that maybe operating

00:06:34,479 --> 00:06:37,120
on

00:06:35,199 --> 00:06:39,039
columns at a time might be faster than

00:06:37,120 --> 00:06:42,080
operating

00:06:39,039 --> 00:06:44,479
dive a little deeper and see why

00:06:42,080 --> 00:06:46,000
this is faster on computer systems to

00:06:44,479 --> 00:06:47,600
operate this way and why

00:06:46,000 --> 00:06:50,319
we can benefit from these things being

00:06:47,600 --> 00:06:53,360
more common on computer systems

00:06:50,319 --> 00:06:55,120
so to do this we're going to look at

00:06:53,360 --> 00:06:56,880
the way memory is organized in a

00:06:55,120 --> 00:06:58,560
computer and we have

00:06:56,880 --> 00:07:00,960
in any computer we have a memory

00:06:58,560 --> 00:07:03,680
hierarchy where we have very small

00:07:00,960 --> 00:07:05,680
but very fast memory at the top of the

00:07:03,680 --> 00:07:06,880
hierarchy and we have very large but

00:07:05,680 --> 00:07:09,360
very slow memory

00:07:06,880 --> 00:07:10,639
at the bottom of the hierarchy and what

00:07:09,360 --> 00:07:13,199
this looks like is this

00:07:10,639 --> 00:07:14,080
and this is sort of adapted from a

00:07:13,199 --> 00:07:16,400
contemporary

00:07:14,080 --> 00:07:17,759
real processor but the values are sort

00:07:16,400 --> 00:07:20,639
of turned into ranges

00:07:17,759 --> 00:07:21,759
in in some cases so that it's a little

00:07:20,639 --> 00:07:23,360
more general

00:07:21,759 --> 00:07:25,680
but these are these are recent numbers

00:07:23,360 --> 00:07:28,080
from within the last few years

00:07:25,680 --> 00:07:30,960
so at the top of the memory hierarchy

00:07:28,080 --> 00:07:34,080
your processor has a bunch of registers

00:07:30,960 --> 00:07:36,160
these are individual locations that hold

00:07:34,080 --> 00:07:37,599
individual values and you have hundreds

00:07:36,160 --> 00:07:39,599
of these per core so you have a few

00:07:37,599 --> 00:07:42,880
kilobytes of registers

00:07:39,599 --> 00:07:46,319
per core and you can access

00:07:42,880 --> 00:07:48,400
a register in a single cycle

00:07:46,319 --> 00:07:50,080
so if you have a three gigahertz

00:07:48,400 --> 00:07:52,160
processor this is a third of a

00:07:50,080 --> 00:07:53,840
nanosecond if you have a four gigahertz

00:07:52,160 --> 00:07:55,680
processor this is a quarter of a

00:07:53,840 --> 00:07:58,000
nanosecond this is extremely fast this

00:07:55,680 --> 00:07:59,759
is as fast as you can do anything

00:07:58,000 --> 00:08:01,120
some registers take more than one cycle

00:07:59,759 --> 00:08:02,960
to access

00:08:01,120 --> 00:08:05,360
again we're sort of dealing at a high

00:08:02,960 --> 00:08:08,000
level here

00:08:05,360 --> 00:08:09,440
the next level of the memory hierarchy

00:08:08,000 --> 00:08:11,759
is level one cache

00:08:09,440 --> 00:08:15,039
um where we have tens of kilobytes you

00:08:11,759 --> 00:08:18,400
know 32 or 64 kilobytes per core

00:08:15,039 --> 00:08:20,560
um we have instructions uh so we program

00:08:18,400 --> 00:08:22,400
and data in separate caches

00:08:20,560 --> 00:08:23,759
and these caches are organized in what

00:08:22,400 --> 00:08:25,039
we call lines

00:08:23,759 --> 00:08:28,720
so this means that the cache is

00:08:25,039 --> 00:08:30,879
addressed 64 bytes at a time

00:08:28,720 --> 00:08:32,640
now this is not as fast as the registers

00:08:30,879 --> 00:08:35,599
but we have more of it

00:08:32,640 --> 00:08:36,479
so it takes four or five cycles so again

00:08:35,599 --> 00:08:38,640
between one

00:08:36,479 --> 00:08:40,479
and you know one and two thirds one and

00:08:38,640 --> 00:08:43,919
two nanoseconds to access

00:08:40,479 --> 00:08:45,760
a value in the l1 cache now one thing i

00:08:43,919 --> 00:08:46,959
want to call out in particular about the

00:08:45,760 --> 00:08:49,680
l1 cache

00:08:46,959 --> 00:08:51,519
is this aspect of it being organized in

00:08:49,680 --> 00:08:52,080
lines and what this means is that you

00:08:51,519 --> 00:08:55,120
can't just

00:08:52,080 --> 00:08:57,360
load a single value into a cache if we

00:08:55,120 --> 00:08:59,279
want to load a value from memory and

00:08:57,360 --> 00:09:02,080
have it in our cache so we can put it in

00:08:59,279 --> 00:09:04,000
a register or operate it on it quickly

00:09:02,080 --> 00:09:05,519
we're actually going to load not just

00:09:04,000 --> 00:09:09,040
that value

00:09:05,519 --> 00:09:09,680
but the 32 or 64 bytes surrounding that

00:09:09,040 --> 00:09:11,519
value

00:09:09,680 --> 00:09:14,320
right we have to load at that level of

00:09:11,519 --> 00:09:15,920
granularity but again this is very fast

00:09:14,320 --> 00:09:17,360
and this is why it can be very fast

00:09:15,920 --> 00:09:20,240
because we have these restrictions on

00:09:17,360 --> 00:09:23,680
how we use it and because it's small

00:09:20,240 --> 00:09:25,920
so next up we have the l2 cache and

00:09:23,680 --> 00:09:27,600
modern processors have rather a lot of

00:09:25,920 --> 00:09:29,519
this they have you know around a

00:09:27,600 --> 00:09:32,000
megabyte per core

00:09:29,519 --> 00:09:33,839
and you know you have a computer

00:09:32,000 --> 00:09:35,920
architects can choose whether or not to

00:09:33,839 --> 00:09:36,720
include the values in the l2 cache or

00:09:35,920 --> 00:09:38,720
not

00:09:36,720 --> 00:09:40,399
in many designs they do include the

00:09:38,720 --> 00:09:42,880
values in the l1 cache

00:09:40,399 --> 00:09:43,680
again these are organized in lines but

00:09:42,880 --> 00:09:46,959
they're

00:09:43,680 --> 00:09:52,320
you know about two to three times

00:09:46,959 --> 00:09:54,240
slower than the l1 cache

00:09:52,320 --> 00:09:57,200
now in a modern processor we don't just

00:09:54,240 --> 00:09:59,360
have one core we have several cores

00:09:57,200 --> 00:10:00,880
um and these these diagrams are more or

00:09:59,360 --> 00:10:04,240
less to scale at this point

00:10:00,880 --> 00:10:06,640
um we have we have several cores and

00:10:04,240 --> 00:10:09,279
we have a cache that's shared across all

00:10:06,640 --> 00:10:11,279
of those cores and that's the l3 cache

00:10:09,279 --> 00:10:13,040
so in some designs this includes the

00:10:11,279 --> 00:10:16,000
values that are in

00:10:13,040 --> 00:10:17,440
the smaller caches above it in the

00:10:16,000 --> 00:10:19,760
memory hierarchy

00:10:17,440 --> 00:10:21,279
um in many designs it doesn't but in

00:10:19,760 --> 00:10:22,800
those designs it can include what's

00:10:21,279 --> 00:10:23,360
called a victim cache which is that if

00:10:22,800 --> 00:10:26,480
something

00:10:23,360 --> 00:10:28,000
is put out of the cache it will land in

00:10:26,480 --> 00:10:28,399
the l3 cache that you could bring it

00:10:28,000 --> 00:10:30,160
back

00:10:28,399 --> 00:10:32,000
because sometimes things that expire

00:10:30,160 --> 00:10:34,399
from a cache

00:10:32,000 --> 00:10:35,760
may get put back in pretty quickly and

00:10:34,399 --> 00:10:38,079
we can access this

00:10:35,760 --> 00:10:38,880
still relatively quickly but you know 10

00:10:38,079 --> 00:10:42,720
to 20 times

00:10:38,880 --> 00:10:44,959
slower than a register or i'm sorry uh

00:10:42,720 --> 00:10:46,079
10 to 20 times slower than the the l1

00:10:44,959 --> 00:10:49,680
cache and and

00:10:46,079 --> 00:10:51,760
so so 40 to

00:10:49,680 --> 00:10:53,440
40 to 80 times slower than the the

00:10:51,760 --> 00:10:56,560
registers

00:10:53,440 --> 00:10:59,120
um when we look at main memory

00:10:56,560 --> 00:11:00,240
the memory on our cpu looks tiny by

00:10:59,120 --> 00:11:02,880
comparison

00:11:00,240 --> 00:11:04,399
um in a typical workstation or a desktop

00:11:02,880 --> 00:11:06,079
computer or laptop or

00:11:04,399 --> 00:11:08,160
even a cell phone at this point you have

00:11:06,079 --> 00:11:09,440
tens to hundreds of gigabytes of main

00:11:08,160 --> 00:11:10,959
memory

00:11:09,440 --> 00:11:13,360
obviously your main memory is shared

00:11:10,959 --> 00:11:16,800
across cores in most conventional

00:11:13,360 --> 00:11:17,839
consumer computers and you can address

00:11:16,800 --> 00:11:22,079
this memory

00:11:17,839 --> 00:11:23,680
a page you know in pages a page is

00:11:22,079 --> 00:11:25,519
you know a unit of memory that the

00:11:23,680 --> 00:11:28,079
operating system and

00:11:25,519 --> 00:11:29,600
the processor cooperate to manage and

00:11:28,079 --> 00:11:31,600
this is much slower right

00:11:29,600 --> 00:11:34,320
accessing a value in main memory takes

00:11:31,600 --> 00:11:36,640
between 150 and 400 cycles

00:11:34,320 --> 00:11:38,880
so the way to think about this is that

00:11:36,640 --> 00:11:40,880
if you have a four gigahertz processor

00:11:38,880 --> 00:11:44,240
and everything you need to do requires

00:11:40,880 --> 00:11:44,240
loading a value for memory

00:11:44,320 --> 00:11:47,440
you're only going to be able to use 1

00:11:45,680 --> 00:11:50,720
400th of your performance

00:11:47,440 --> 00:11:52,000
right if it takes 400 cycles to access

00:11:50,720 --> 00:11:54,639
main memory

00:11:52,000 --> 00:11:56,880
so we really want to have as many values

00:11:54,639 --> 00:11:59,839
as we operate on in the caches

00:11:56,880 --> 00:12:01,440
we want to we want to exploit the fact

00:11:59,839 --> 00:12:02,000
that we're loading data that are close

00:12:01,440 --> 00:12:05,600
together

00:12:02,000 --> 00:12:08,480
in those caches and then finally

00:12:05,600 --> 00:12:10,160
memory itself is even dwarfed by the

00:12:08,480 --> 00:12:11,519
kinds of disks that we have

00:12:10,160 --> 00:12:13,519
and the disk can be hundreds of

00:12:11,519 --> 00:12:16,880
gigabytes or terabytes

00:12:13,519 --> 00:12:19,600
um but the uh the disks are actually

00:12:16,880 --> 00:12:21,440
um the disks are actually measured in

00:12:19,600 --> 00:12:23,120
milliseconds rather than in nanoseconds

00:12:21,440 --> 00:12:25,760
so there's a typo on this slide it's not

00:12:23,120 --> 00:12:26,560
150 to 400 cycles this is milliseconds

00:12:25,760 --> 00:12:30,320
so this is

00:12:26,560 --> 00:12:34,959
this is a million times slower than

00:12:30,320 --> 00:12:38,320
than memory at this point or then than

00:12:34,959 --> 00:12:39,600
than caches so

00:12:38,320 --> 00:12:40,959
we really need to be careful about

00:12:39,600 --> 00:12:42,160
accessing the disk if we're going to

00:12:40,959 --> 00:12:45,200
access the disk

00:12:42,160 --> 00:12:46,160
all the time um you know we're really

00:12:45,200 --> 00:12:47,920
not going to be getting

00:12:46,160 --> 00:12:49,360
the best possible performance we can get

00:12:47,920 --> 00:12:50,880
from our computer system so we need to

00:12:49,360 --> 00:12:52,000
access the disk in a way that's

00:12:50,880 --> 00:12:53,760
effective

00:12:52,000 --> 00:12:55,040
now what is effective well you might

00:12:53,760 --> 00:12:57,040
think well a disk

00:12:55,040 --> 00:12:59,040
i mean i have files on my disk i can

00:12:57,040 --> 00:13:00,639
access wherever i want i can seek to

00:12:59,040 --> 00:13:02,320
some point on the disk and read and i

00:13:00,639 --> 00:13:04,160
can seek to some other point

00:13:02,320 --> 00:13:06,079
but that's not the most efficient way to

00:13:04,160 --> 00:13:07,839
do it and

00:13:06,079 --> 00:13:09,200
an interesting quote from almost two

00:13:07,839 --> 00:13:11,360
decades ago from

00:13:09,200 --> 00:13:12,639
database pioneer jim gray in an

00:13:11,360 --> 00:13:15,680
interview

00:13:12,639 --> 00:13:18,720
um i think still holds true today

00:13:15,680 --> 00:13:20,160
and you know this is this is again 2003

00:13:18,720 --> 00:13:22,240
context but

00:13:20,160 --> 00:13:24,560
gray was looking forward to a future

00:13:22,240 --> 00:13:27,519
where we might have 20 terabyte disks

00:13:24,560 --> 00:13:29,920
in commodity hardware and he says well

00:13:27,519 --> 00:13:31,680
if you have 200 accesses per second on a

00:13:29,920 --> 00:13:33,360
disk and if you only read

00:13:31,680 --> 00:13:35,519
a few kilobytes every time you hit the

00:13:33,360 --> 00:13:37,519
disk it'll take you a year

00:13:35,519 --> 00:13:40,639
to read all the data on that 20 terabyte

00:13:37,519 --> 00:13:43,199
disk but if you

00:13:40,639 --> 00:13:44,800
go to if you go to sequential access and

00:13:43,199 --> 00:13:47,279
you read more of the disk at once and

00:13:44,800 --> 00:13:49,360
you read the disk in order

00:13:47,279 --> 00:13:51,440
you can actually read through that disc

00:13:49,360 --> 00:13:53,279
in a day rather than a year

00:13:51,440 --> 00:13:54,480
so it's it's really uh it's really a

00:13:53,279 --> 00:13:56,639
remarkable

00:13:54,480 --> 00:13:58,880
advantage you get from treating the disc

00:13:56,639 --> 00:14:00,240
like a sequential access device like we

00:13:58,880 --> 00:14:02,320
like we were talking about with the

00:14:00,240 --> 00:14:03,600
caches where you're reading contiguous

00:14:02,320 --> 00:14:04,720
blocks of memory you want to read

00:14:03,600 --> 00:14:07,680
contiguous

00:14:04,720 --> 00:14:09,279
blocks of your disk gray's takeaway here

00:14:07,680 --> 00:14:10,959
was that programmers have to think of

00:14:09,279 --> 00:14:13,760
the disk as a sequential device

00:14:10,959 --> 00:14:15,680
rather than as a random access device

00:14:13,760 --> 00:14:17,760
and you might say well we have we have

00:14:15,680 --> 00:14:20,000
ssds we have nvme now

00:14:17,760 --> 00:14:21,440
this point actually still holds uh maybe

00:14:20,000 --> 00:14:23,199
to a lesser extent than it does with

00:14:21,440 --> 00:14:25,199
spinning disks but it still holds that

00:14:23,199 --> 00:14:27,440
you're going to get the best performance

00:14:25,199 --> 00:14:28,480
by accessing things that are in order

00:14:27,440 --> 00:14:30,160
and close together

00:14:28,480 --> 00:14:31,920
this is sort of a fundamental principle

00:14:30,160 --> 00:14:33,360
of computer systems it's easy to predict

00:14:31,920 --> 00:14:35,040
what's going to happen next

00:14:33,360 --> 00:14:37,040
it's easy to do the right thing with

00:14:35,040 --> 00:14:39,680
what what happens so

00:14:37,040 --> 00:14:40,240
how does this apply to data processing

00:14:39,680 --> 00:14:42,800
well

00:14:40,240 --> 00:14:44,240
let's look at our example an example

00:14:42,800 --> 00:14:46,320
data set that we'll use for the rest of

00:14:44,240 --> 00:14:48,079
the talk and our case study here is for

00:14:46,320 --> 00:14:50,160
a hyper local payment service

00:14:48,079 --> 00:14:52,560
for places that are within walking

00:14:50,160 --> 00:14:54,959
distance of alexander plots

00:14:52,560 --> 00:14:57,519
so if we look at this data we have time

00:14:54,959 --> 00:14:59,600
stamps we have user ids

00:14:57,519 --> 00:15:01,519
we have transaction amounts and we have

00:14:59,600 --> 00:15:04,720
the neighborhood that the tran

00:15:01,519 --> 00:15:06,639
transaction took place in and

00:15:04,720 --> 00:15:08,800
if we think about these logically as a

00:15:06,639 --> 00:15:09,920
table we might want to picture them like

00:15:08,800 --> 00:15:12,079
this

00:15:09,920 --> 00:15:13,600
now if we had these in a row oriented

00:15:12,079 --> 00:15:16,000
format where we're going to pack these

00:15:13,600 --> 00:15:16,720
on the disk a row at a time where values

00:15:16,000 --> 00:15:18,800
in rows

00:15:16,720 --> 00:15:20,959
are close to one another values in rows

00:15:18,800 --> 00:15:26,800
have that sort of locality

00:15:20,959 --> 00:15:28,800
then it might look like this so

00:15:26,800 --> 00:15:30,639
in this row oriented representation our

00:15:28,800 --> 00:15:31,839
data are packed in together pretty

00:15:30,639 --> 00:15:34,480
nicely

00:15:31,839 --> 00:15:36,240
um this probably doesn't take up as much

00:15:34,480 --> 00:15:38,399
space as it would to sort of

00:15:36,240 --> 00:15:39,519
have a have a more human-friendly

00:15:38,399 --> 00:15:41,199
representation

00:15:39,519 --> 00:15:42,639
but let's see how this representation

00:15:41,199 --> 00:15:45,120
works for running

00:15:42,639 --> 00:15:47,279
an analytic query of the sort that we

00:15:45,120 --> 00:15:49,040
want to do in a data processing system

00:15:47,279 --> 00:15:51,040
so this is just a very simple one this

00:15:49,040 --> 00:15:54,480
is how much money has each

00:15:51,040 --> 00:15:56,480
user spent and in order to do this

00:15:54,480 --> 00:15:59,120
transaction we have to scan through

00:15:56,480 --> 00:16:00,720
the whole file and for every row we have

00:15:59,120 --> 00:16:02,480
to get the user id

00:16:00,720 --> 00:16:04,240
and the amount and then we add up those

00:16:02,480 --> 00:16:07,519
user ids for each for

00:16:04,240 --> 00:16:07,519
those amounts for each user

00:16:07,759 --> 00:16:10,560
so we're going to see something that

00:16:09,199 --> 00:16:11,199
looks like this where we're only

00:16:10,560 --> 00:16:14,720
accessing

00:16:11,199 --> 00:16:14,720
some subset of the data

00:16:15,680 --> 00:16:20,320
now this is actually sort of worse than

00:16:18,959 --> 00:16:22,480
it appears

00:16:20,320 --> 00:16:23,759
because remember all of those things we

00:16:22,480 --> 00:16:24,959
just talked about with the memory

00:16:23,759 --> 00:16:26,639
hierarchy right

00:16:24,959 --> 00:16:28,160
you're reading data sequentially so

00:16:26,639 --> 00:16:30,000
you're reading a lot of data that you're

00:16:28,160 --> 00:16:32,079
ultimately not going to use

00:16:30,000 --> 00:16:33,839
and in fact you're reading data into

00:16:32,079 --> 00:16:36,800
caches that you're not going to use

00:16:33,839 --> 00:16:39,120
so you're necessarily accessing your

00:16:36,800 --> 00:16:42,000
fastest most precious memory

00:16:39,120 --> 00:16:43,120
in a really wasteful way so we can't

00:16:42,000 --> 00:16:44,800
just read the bytes that we're

00:16:43,120 --> 00:16:47,279
interested in we have to read

00:16:44,800 --> 00:16:49,360
the disk sequentially and to get that

00:16:47,279 --> 00:16:52,160
data from main memory into our cpu we

00:16:49,360 --> 00:16:54,560
need to read cache line size chunks

00:16:52,160 --> 00:16:55,360
so in this case the representation of

00:16:54,560 --> 00:16:59,040
our first row

00:16:55,360 --> 00:17:00,480
is 38 bytes long if we have 64 byte

00:16:59,040 --> 00:17:03,519
cache lines we're going to use

00:17:00,480 --> 00:17:05,679
three cache lines to read five rows and

00:17:03,519 --> 00:17:06,720
nearly all of that very fast memory is

00:17:05,679 --> 00:17:08,799
going to be wasted

00:17:06,720 --> 00:17:10,160
because we only care about the 14 bytes

00:17:08,799 --> 00:17:12,079
i've highlighted here

00:17:10,160 --> 00:17:14,880
that contain our user id and the

00:17:12,079 --> 00:17:14,880
transaction amount

00:17:14,959 --> 00:17:19,439
i hope this seems like we can do better

00:17:17,039 --> 00:17:21,280
right and in fact we can and one of the

00:17:19,439 --> 00:17:22,000
ways we can do better is to transpose

00:17:21,280 --> 00:17:23,760
our data

00:17:22,000 --> 00:17:26,240
so instead of storing a record for each

00:17:23,760 --> 00:17:28,079
row we store a file of records

00:17:26,240 --> 00:17:30,319
for each column and that will look like

00:17:28,079 --> 00:17:30,319
this

00:17:31,600 --> 00:17:35,840
so if we're implementing a query that

00:17:34,080 --> 00:17:38,320
accesses only two of these columns

00:17:35,840 --> 00:17:40,559
we don't need to read the other values

00:17:38,320 --> 00:17:40,559
um

00:17:41,120 --> 00:17:44,080
and we don't need to care about them

00:17:42,480 --> 00:17:46,160
right we're accessing values we care

00:17:44,080 --> 00:17:47,919
about we're accessing them sequentially

00:17:46,160 --> 00:17:49,520
and we're doing everything basically as

00:17:47,919 --> 00:17:51,039
quickly as the system will allow at

00:17:49,520 --> 00:17:52,960
every level this is what computer

00:17:51,039 --> 00:17:54,640
systems were designed to do

00:17:52,960 --> 00:17:56,400
so if you remember nothing else about

00:17:54,640 --> 00:17:58,480
columnar storage from this talk

00:17:56,400 --> 00:18:00,320
remember this because analytic queries

00:17:58,480 --> 00:18:01,600
are more likely to do something to every

00:18:00,320 --> 00:18:03,520
value in a column

00:18:01,600 --> 00:18:06,240
than to do something to everything in a

00:18:03,520 --> 00:18:08,240
row column or formats can be

00:18:06,240 --> 00:18:10,559
far more efficient for than row oriented

00:18:08,240 --> 00:18:12,000
formats for analytic databases

00:18:10,559 --> 00:18:13,840
so there are lots of other advantages to

00:18:12,000 --> 00:18:14,480
columnar formats we'll talk about those

00:18:13,840 --> 00:18:15,919
soon

00:18:14,480 --> 00:18:17,919
but for now let's talk about the high

00:18:15,919 --> 00:18:21,120
level value proposition for part k let's

00:18:17,919 --> 00:18:22,799
look at the parquet myths

00:18:21,120 --> 00:18:24,240
and there are two parts to this myth

00:18:22,799 --> 00:18:25,679
that i want to call out

00:18:24,240 --> 00:18:27,840
the first one is that par k is

00:18:25,679 --> 00:18:29,919
ubiquitous if we think about a typical

00:18:27,840 --> 00:18:32,080
data science discovery workflow

00:18:29,919 --> 00:18:33,679
you have a lot of different stages from

00:18:32,080 --> 00:18:35,919
sort of deciding whether or not

00:18:33,679 --> 00:18:37,600
you even have a problem to solve to data

00:18:35,919 --> 00:18:40,240
engineering and model training

00:18:37,600 --> 00:18:42,559
to finally building a production system

00:18:40,240 --> 00:18:44,880
that has to sort of live and evolve

00:18:42,559 --> 00:18:45,679
with the data that you're seeing in the

00:18:44,880 --> 00:18:47,600
real world

00:18:45,679 --> 00:18:49,280
and you also have a bunch of people

00:18:47,600 --> 00:18:51,120
working on these systems

00:18:49,280 --> 00:18:53,600
you have data scientists and business

00:18:51,120 --> 00:18:54,640
analysts working on the sort of problem

00:18:53,600 --> 00:18:56,160
defining and

00:18:54,640 --> 00:18:59,039
exploratory analytics part of the

00:18:56,160 --> 00:19:01,120
problem you have data engineers focused

00:18:59,039 --> 00:19:01,840
on that early stage of making the data

00:19:01,120 --> 00:19:05,200
accessible

00:19:01,840 --> 00:19:07,440
available clean and efficient

00:19:05,200 --> 00:19:08,960
then you have that sort of inner loop of

00:19:07,440 --> 00:19:10,000
machine learning model development that

00:19:08,960 --> 00:19:12,880
a lot of people focus

00:19:10,000 --> 00:19:13,840
on and then finally we have a production

00:19:12,880 --> 00:19:15,760
deployment

00:19:13,840 --> 00:19:17,840
and in each of these phases people are

00:19:15,760 --> 00:19:20,559
going to be using different tools

00:19:17,840 --> 00:19:22,559
that work well for their environment so

00:19:20,559 --> 00:19:25,120
a lot of data engineering jobs

00:19:22,559 --> 00:19:28,640
happen in the jvm and that sort of big

00:19:25,120 --> 00:19:28,640
data hadoop ecosystem

00:19:28,880 --> 00:19:32,400
a lot of data science is happening with

00:19:31,039 --> 00:19:35,360
tools like python

00:19:32,400 --> 00:19:36,880
r and julia and in the production

00:19:35,360 --> 00:19:38,080
environment it's really the wild west

00:19:36,880 --> 00:19:40,000
it's going to be a combination

00:19:38,080 --> 00:19:41,679
of a lot of these things as well as some

00:19:40,000 --> 00:19:44,480
specialized

00:19:41,679 --> 00:19:44,880
tools that are you know maybe written in

00:19:44,480 --> 00:19:47,280
c

00:19:44,880 --> 00:19:48,320
plus that that are for high latency or

00:19:47,280 --> 00:19:51,520
low latency

00:19:48,320 --> 00:19:53,200
serving for example now the fact that

00:19:51,520 --> 00:19:54,640
parquet is available in all of these

00:19:53,200 --> 00:19:56,400
environments is a huge

00:19:54,640 --> 00:19:58,080
selling point and that's sort of the

00:19:56,400 --> 00:19:58,640
myth right that you can use parquet

00:19:58,080 --> 00:20:00,240
everywhere

00:19:58,640 --> 00:20:02,640
we'll see where this myth breaks down in

00:20:00,240 --> 00:20:02,640
a little bit

00:20:03,760 --> 00:20:07,440
another advantage is that parquet

00:20:05,600 --> 00:20:08,320
creates smaller files and is thus more

00:20:07,440 --> 00:20:10,000
efficient

00:20:08,320 --> 00:20:11,600
so here's a recent example from my own

00:20:10,000 --> 00:20:11,919
work that's pretty representative if we

00:20:11,600 --> 00:20:14,400
have

00:20:11,919 --> 00:20:16,159
50 million records of synthetic payments

00:20:14,400 --> 00:20:18,240
data a little more interesting schema

00:20:16,159 --> 00:20:20,400
than the one we saw in our example

00:20:18,240 --> 00:20:21,280
that's about two and a half gigabytes of

00:20:20,400 --> 00:20:25,039
csv

00:20:21,280 --> 00:20:27,280
and under 500 megabytes is par k so

00:20:25,039 --> 00:20:28,240
csv to part k is a totally unfair

00:20:27,280 --> 00:20:30,559
comparison

00:20:28,240 --> 00:20:32,640
because csv is a textual format and

00:20:30,559 --> 00:20:34,640
there's way more overhead to store

00:20:32,640 --> 00:20:36,960
numeric values and you know all kinds of

00:20:34,640 --> 00:20:38,640
values but the amazing thing is that

00:20:36,960 --> 00:20:42,000
even if we compress

00:20:38,640 --> 00:20:43,679
this csv file with gzip the output is

00:20:42,000 --> 00:20:45,679
still bigger than the parquet file

00:20:43,679 --> 00:20:47,120
so even if we're exploiting redundancy

00:20:45,679 --> 00:20:48,960
in the text of our records

00:20:47,120 --> 00:20:50,720
parque is going to come out ahead and

00:20:48,960 --> 00:20:52,159
that part k representation is going to

00:20:50,720 --> 00:20:52,880
be directly useful for supporting

00:20:52,159 --> 00:20:55,280
queries

00:20:52,880 --> 00:20:56,799
whereas the gzip csv is not and those

00:20:55,280 --> 00:20:58,559
smaller files will lead to faster

00:20:56,799 --> 00:21:00,720
processing

00:20:58,559 --> 00:21:03,600
so let's look at how parquet actually

00:21:00,720 --> 00:21:07,200
accomplishes some of these things

00:21:03,600 --> 00:21:09,679
again consider our tabular oriented data

00:21:07,200 --> 00:21:10,880
that we've transposed into a columnar

00:21:09,679 --> 00:21:12,400
format

00:21:10,880 --> 00:21:13,919
so if we're doing analytic queries with

00:21:12,400 --> 00:21:15,760
these data we've already gotten some

00:21:13,919 --> 00:21:17,440
benefits just by separating things into

00:21:15,760 --> 00:21:19,280
columns because we only have to read the

00:21:17,440 --> 00:21:21,200
values we care about and they're next to

00:21:19,280 --> 00:21:22,080
each other so they're spatially local to

00:21:21,200 --> 00:21:23,520
one another

00:21:22,080 --> 00:21:26,000
but there are more things we can do as

00:21:23,520 --> 00:21:29,200
well the first thing we can do

00:21:26,000 --> 00:21:30,559
is if we have repeated values in a field

00:21:29,200 --> 00:21:32,559
like time stamps as

00:21:30,559 --> 00:21:34,640
this is a very common case instead of

00:21:32,559 --> 00:21:36,960
storing each one explicitly we can store

00:21:34,640 --> 00:21:38,720
them as runs so i can say instead of

00:21:36,960 --> 00:21:40,799
having this first time stamp twice i can

00:21:38,720 --> 00:21:43,039
say two and then the value

00:21:40,799 --> 00:21:46,000
and so on for these other examples this

00:21:43,039 --> 00:21:49,440
can save us a lot of space and time

00:21:46,000 --> 00:21:51,840
the second thing we can do is to store

00:21:49,440 --> 00:21:53,600
low cardinality values in a dictionary

00:21:51,840 --> 00:21:56,320
and replace each value with its

00:21:53,600 --> 00:21:57,760
key in the dictionary these keys are

00:21:56,320 --> 00:21:59,039
typically going to be a lot smaller than

00:21:57,760 --> 00:22:00,080
the value they're mapping to

00:21:59,039 --> 00:22:01,760
especially if we're talking about

00:22:00,080 --> 00:22:03,039
strings so this can save us a lot of

00:22:01,760 --> 00:22:04,159
space and here we've done this with

00:22:03,039 --> 00:22:06,480
neighborhoods

00:22:04,159 --> 00:22:07,600
so instead of storing each neighborhood

00:22:06,480 --> 00:22:09,440
specifically

00:22:07,600 --> 00:22:10,799
we keep an index of neighborhoods and we

00:22:09,440 --> 00:22:11,919
just store

00:22:10,799 --> 00:22:13,840
a dictionary of neighborhoods we just

00:22:11,919 --> 00:22:15,919
store the index of each particular

00:22:13,840 --> 00:22:19,200
transaction neighborhood

00:22:15,919 --> 00:22:22,080
in the column now

00:22:19,200 --> 00:22:23,919
whether we've used these encoding tricks

00:22:22,080 --> 00:22:24,559
or not we can also use a general purpose

00:22:23,919 --> 00:22:27,120
compression

00:22:24,559 --> 00:22:28,000
algorithm to compress each column so

00:22:27,120 --> 00:22:30,799
that we're saving

00:22:28,000 --> 00:22:33,200
some additional space another thing

00:22:30,799 --> 00:22:36,720
parquet can do to improve

00:22:33,200 --> 00:22:39,039
performance is what's called predicate

00:22:36,720 --> 00:22:41,200
and the idea behind predicate put

00:22:39,039 --> 00:22:43,840
metadata for each of these

00:22:41,200 --> 00:22:45,200
indicating some copies that are in them

00:22:43,840 --> 00:22:49,120
so if

00:22:45,200 --> 00:22:51,840
this if we partition file into

00:22:49,120 --> 00:22:52,720
files and we if it looks like this want

00:22:51,840 --> 00:22:57,120
to consider

00:22:52,720 --> 00:23:00,240
subset of the time i don't even need to

00:22:57,120 --> 00:23:03,039
save our data we can ignore that

00:23:00,240 --> 00:23:04,880
grouping similarly if we want if we're

00:23:03,039 --> 00:23:06,480
interested in a value that only appears

00:23:04,880 --> 00:23:08,000
in a subset of our data like in this

00:23:06,480 --> 00:23:12,159
case we only have kreitzberg

00:23:08,000 --> 00:23:13,520
in the set of records on the left

00:23:12,159 --> 00:23:16,559
we don't need to look at the set of

00:23:13,520 --> 00:23:16,559
records on the right

00:23:16,960 --> 00:23:21,600
so i said logical file and this is this

00:23:19,679 --> 00:23:23,039
is a little bit of a white lie

00:23:21,600 --> 00:23:25,200
in some cases we can actually have

00:23:23,039 --> 00:23:27,280
multiple logical files in a single

00:23:25,200 --> 00:23:29,360
physical file and part k calls these row

00:23:27,280 --> 00:23:31,600
groups

00:23:29,360 --> 00:23:33,440
means the columns for a subset of rows

00:23:31,600 --> 00:23:35,280
in a data set as well as the metadata

00:23:33,440 --> 00:23:36,159
for each so if we had a single parquet

00:23:35,280 --> 00:23:39,120
file

00:23:36,159 --> 00:23:39,919
we might have two row groups in that

00:23:39,120 --> 00:23:41,120
file

00:23:39,919 --> 00:23:43,039
and this doesn't change anything about

00:23:41,120 --> 00:23:43,679
the way predicate pushdown works because

00:23:43,039 --> 00:23:46,159
we can

00:23:43,679 --> 00:23:48,080
treat these as logical files the query

00:23:46,159 --> 00:23:49,279
engine can seek to a particular part of

00:23:48,080 --> 00:23:52,640
the file

00:23:49,279 --> 00:23:53,520
and read the values that we're

00:23:52,640 --> 00:23:57,039
interested in

00:23:53,520 --> 00:23:59,200
sequentially another wrinkle is if we're

00:23:57,039 --> 00:24:01,440
dealing with part k files generated on a

00:23:59,200 --> 00:24:03,039
cluster from a spark or hadoop job

00:24:01,440 --> 00:24:05,600
in this case we actually will have a

00:24:03,039 --> 00:24:07,679
directory full of parquet files that

00:24:05,600 --> 00:24:09,039
we can treat transparently as a single

00:24:07,679 --> 00:24:10,320
parquet data set

00:24:09,039 --> 00:24:13,120
and each one of these is going to

00:24:10,320 --> 00:24:14,159
correspond to row groups generated from

00:24:13,120 --> 00:24:17,360
a partition

00:24:14,159 --> 00:24:19,520
of our original data set

00:24:17,360 --> 00:24:21,360
so we can inspect the metadata of a data

00:24:19,520 --> 00:24:23,279
set stored in parquet with the parquet

00:24:21,360 --> 00:24:24,480
tools command line utility and this is a

00:24:23,279 --> 00:24:26,720
command that provides

00:24:24,480 --> 00:24:28,799
several sub-commands to examine metadata

00:24:26,720 --> 00:24:30,880
encodings compression and actual data in

00:24:28,799 --> 00:24:32,320
a parquet file or directory

00:24:30,880 --> 00:24:34,640
it'll provide a ton of output we're

00:24:32,320 --> 00:24:36,159
going to look at a little bit at a time

00:24:34,640 --> 00:24:38,000
so here we can see that we're dealing

00:24:36,159 --> 00:24:39,039
with a per k file that has multiple

00:24:38,000 --> 00:24:41,679
parts

00:24:39,039 --> 00:24:43,440
that was generated with apache spark and

00:24:41,679 --> 00:24:45,200
that spark stored some metadata about

00:24:43,440 --> 00:24:46,880
the schema

00:24:45,200 --> 00:24:50,720
the next part of this file shows us

00:24:46,880 --> 00:24:50,720
parquet's schema for this file

00:24:51,200 --> 00:24:54,480
and as we read on in the output we have

00:24:52,720 --> 00:24:56,400
the metadata for each row group

00:24:54,480 --> 00:24:57,919
this has a lot of useful detail in it

00:24:56,400 --> 00:24:59,919
and it can tell us about how a query

00:24:57,919 --> 00:25:01,840
engine can handle our data efficiently

00:24:59,919 --> 00:25:04,240
by examining that metadata

00:25:01,840 --> 00:25:06,559
first up is the row count and the total

00:25:04,240 --> 00:25:08,320
size of values in the row group

00:25:06,559 --> 00:25:10,559
and then for each field we have the data

00:25:08,320 --> 00:25:10,559
type

00:25:11,120 --> 00:25:15,919
compression type and compression ratio

00:25:14,400 --> 00:25:17,840
and we can see in this case that the

00:25:15,919 --> 00:25:20,000
time stamping coding

00:25:17,840 --> 00:25:23,279
saved us over 50 percent of the space

00:25:20,000 --> 00:25:25,279
relative to the wrong values

00:25:23,279 --> 00:25:27,360
we also see the column encodings here so

00:25:25,279 --> 00:25:27,760
we see that we have dictionary encodings

00:25:27,360 --> 00:25:30,400
for

00:25:27,760 --> 00:25:30,400
a lot of these

00:25:31,279 --> 00:25:35,600
and finally we have some metadata about

00:25:33,760 --> 00:25:38,159
the kinds of values that we can take

00:25:35,600 --> 00:25:41,120
that we have in each column

00:25:38,159 --> 00:25:43,760
so these things put together can really

00:25:41,120 --> 00:25:46,880
provide us some

00:25:43,760 --> 00:25:49,360
some benefits as as query processing

00:25:46,880 --> 00:25:50,880
engines so let's see where the myths

00:25:49,360 --> 00:25:52,720
break down though

00:25:50,880 --> 00:25:53,919
and we really want to focus on this

00:25:52,720 --> 00:25:56,320
handoff

00:25:53,919 --> 00:25:57,600
between data engineers and data

00:25:56,320 --> 00:26:00,799
scientists

00:25:57,600 --> 00:26:02,880
where parque's ubiquity breaks down and

00:26:00,799 --> 00:26:04,640
if we think about taking from a jvm

00:26:02,880 --> 00:26:08,159
based

00:26:04,640 --> 00:26:11,200
data engineering pipeline to a python

00:26:08,159 --> 00:26:13,039
based feature engineering pipeline we

00:26:11,200 --> 00:26:14,799
might be thinking about going to pandas

00:26:13,039 --> 00:26:16,159
so the first problem you run into is

00:26:14,799 --> 00:26:18,000
availability so

00:26:16,159 --> 00:26:19,279
pandas has an api method to let you read

00:26:18,000 --> 00:26:20,799
a parquet file

00:26:19,279 --> 00:26:22,320
but you'll have to install some other

00:26:20,799 --> 00:26:24,559
libraries to use it

00:26:22,320 --> 00:26:25,360
now pandas gives you two options in this

00:26:24,559 --> 00:26:27,840
error message

00:26:25,360 --> 00:26:29,760
fast parque and paero uh there are

00:26:27,840 --> 00:26:32,080
trade-offs between each

00:26:29,760 --> 00:26:33,520
in practice i've found piero has been

00:26:32,080 --> 00:26:36,320
the best for my projects and that's what

00:26:33,520 --> 00:26:38,000
i'll focus on in the rest of the talk

00:26:36,320 --> 00:26:39,840
another problem is the capabilities of

00:26:38,000 --> 00:26:41,520
your implementations so

00:26:39,840 --> 00:26:43,039
this is the compression types that

00:26:41,520 --> 00:26:44,960
parque supports

00:26:43,039 --> 00:26:46,240
um some of these will get you really

00:26:44,960 --> 00:26:48,000
great results if you're in an

00:26:46,240 --> 00:26:50,320
environment that supports them

00:26:48,000 --> 00:26:52,000
but snappy and gzip are going to be the

00:26:50,320 --> 00:26:53,679
ones that are most widely available and

00:26:52,000 --> 00:26:56,320
those are a good safe bet

00:26:53,679 --> 00:26:57,440
until you know about what the

00:26:56,320 --> 00:27:00,320
environment you're running in

00:26:57,440 --> 00:27:01,600
is going to support another problem is

00:27:00,320 --> 00:27:03,679
that if we're reading

00:27:01,600 --> 00:27:04,880
a parquet file into something like a

00:27:03,679 --> 00:27:06,880
pandas data frame

00:27:04,880 --> 00:27:08,240
these dictionary encoded strings can get

00:27:06,880 --> 00:27:11,039
materialized on read

00:27:08,240 --> 00:27:13,360
so instead of this nice compact

00:27:11,039 --> 00:27:14,640
dictionary encoded representation

00:27:13,360 --> 00:27:17,360
which we might want to use as a

00:27:14,640 --> 00:27:20,240
categorical in pandas

00:27:17,360 --> 00:27:21,679
we have this long list of strings right

00:27:20,240 --> 00:27:22,480
this is a problem that we'll see how to

00:27:21,679 --> 00:27:26,000
work around

00:27:22,480 --> 00:27:27,919
in the demo the last problem

00:27:26,000 --> 00:27:29,840
is related to parquet tools itself

00:27:27,919 --> 00:27:31,600
parquet tools is super useful

00:27:29,840 --> 00:27:33,360
but it's been deprecated upstream and

00:27:31,600 --> 00:27:35,600
removed from the parquet repo so if you

00:27:33,360 --> 00:27:37,200
look for it this is what you'll get

00:27:35,600 --> 00:27:39,120
as a workaround you can pull an older

00:27:37,200 --> 00:27:41,360
version of parquet tools from maven or

00:27:39,120 --> 00:27:43,120
install it via the homebrew tool

00:27:41,360 --> 00:27:45,039
and there's also an aero-based version

00:27:43,120 --> 00:27:47,440
of parquet tools that runs in python

00:27:45,039 --> 00:27:49,919
under development

00:27:47,440 --> 00:27:51,360
so i want to quickly go through and see

00:27:49,919 --> 00:27:54,799
some of these problems in

00:27:51,360 --> 00:27:58,399
action with our demo

00:27:54,799 --> 00:28:03,120
and what we're going to see

00:27:58,399 --> 00:28:04,960
is loading a data frame from spark

00:28:03,120 --> 00:28:06,799
and then seeing how pandas

00:28:04,960 --> 00:28:10,399
inappropriately materializes

00:28:06,799 --> 00:28:10,399
these um

00:28:10,480 --> 00:28:13,840
these dictionary encoded fields and how

00:28:12,240 --> 00:28:17,840
we can work around that

00:28:13,840 --> 00:28:17,840
so here we have a

00:28:18,080 --> 00:28:24,640
parquet file um in spark

00:28:21,120 --> 00:28:26,799
and we're gonna look at the schema here

00:28:24,640 --> 00:28:28,240
and then look at the first 10 rows and

00:28:26,799 --> 00:28:30,000
see if it makes sense

00:28:28,240 --> 00:28:32,080
so we have our amount we have our

00:28:30,000 --> 00:28:33,360
neighborhood our timestamp our user id

00:28:32,080 --> 00:28:34,000
we have everything we expect to see

00:28:33,360 --> 00:28:35,840
there

00:28:34,000 --> 00:28:37,520
now if we look at the first 10 rows

00:28:35,840 --> 00:28:39,200
again this is looking about like we

00:28:37,520 --> 00:28:40,880
expect we have a few more neighborhoods

00:28:39,200 --> 00:28:44,640
in this data set

00:28:40,880 --> 00:28:47,039
um and but the data the data look

00:28:44,640 --> 00:28:47,840
look pretty sensible so now we're going

00:28:47,039 --> 00:28:50,640
to go down

00:28:47,840 --> 00:28:51,279
and read we're going to look at the

00:28:50,640 --> 00:28:54,399
parquet

00:28:51,279 --> 00:28:56,159
metadata again with parquet tools and

00:28:54,399 --> 00:28:56,840
we're going to go ahead and read that

00:28:56,159 --> 00:28:59,840
into

00:28:56,840 --> 00:28:59,840
pandas

00:29:08,000 --> 00:29:12,960
as you can see we have the size the

00:29:09,919 --> 00:29:15,360
value count

00:29:12,960 --> 00:29:16,159
the sort of field metadata and the

00:29:15,360 --> 00:29:26,480
encodings

00:29:16,159 --> 00:29:28,559
all that we expect to see there

00:29:26,480 --> 00:29:29,520
now when we actually read these into

00:29:28,559 --> 00:29:31,840
pandas though

00:29:29,520 --> 00:29:33,520
um so we see crucially we note that our

00:29:31,840 --> 00:29:35,919
neighborhood is dictionary encoded

00:29:33,520 --> 00:29:38,080
right and when we when we read these

00:29:35,919 --> 00:29:39,840
into

00:29:38,080 --> 00:29:43,279
when we read these into pandas we're

00:29:39,840 --> 00:29:43,279
going to see an issue

00:29:49,120 --> 00:29:53,120
we notice that the neighborhood actually

00:29:50,960 --> 00:29:54,080
takes up less space than the value count

00:29:53,120 --> 00:29:57,120
because uh

00:29:54,080 --> 00:29:58,799
because of the dictionary encoding

00:29:57,120 --> 00:30:00,640
so that's uh that's a real advantage

00:29:58,799 --> 00:30:02,159
there and when we have the metadata for

00:30:00,640 --> 00:30:08,000
what values are in

00:30:02,159 --> 00:30:10,080
in that column

00:30:08,000 --> 00:30:11,840
we'll see that the time stamp again is

00:30:10,080 --> 00:30:14,240
is compressed because of the run length

00:30:11,840 --> 00:30:14,240
encoding

00:30:21,360 --> 00:30:24,720
okay so if we see what happens when we

00:30:22,720 --> 00:30:26,880
try and read these into pandas

00:30:24,720 --> 00:30:27,760
we get a pandas data frame like we would

00:30:26,880 --> 00:30:29,919
expect

00:30:27,760 --> 00:30:31,760
with the read parquet method i have pi

00:30:29,919 --> 00:30:36,640
arrow installed here

00:30:31,760 --> 00:30:39,039
that looks looks pretty good but

00:30:36,640 --> 00:30:40,399
these strings have all been materialized

00:30:39,039 --> 00:30:43,120
so instead of having a nice

00:30:40,399 --> 00:30:44,720
pandas categorical which we could use

00:30:43,120 --> 00:30:46,640
more or less directly for exploratory

00:30:44,720 --> 00:30:48,240
analysis or to train a model

00:30:46,640 --> 00:30:50,080
we are actually storing these as python

00:30:48,240 --> 00:30:51,679
objects so they're even taking up more

00:30:50,080 --> 00:30:53,919
space than they would as strings

00:30:51,679 --> 00:31:05,840
in this case so we thought we've had a

00:30:53,919 --> 00:31:05,840
problem with the round trip here

00:31:06,880 --> 00:31:10,799
so we could actually convert that column

00:31:08,960 --> 00:31:12,240
to categoricals

00:31:10,799 --> 00:31:14,880
which we're going to do here and we see

00:31:12,240 --> 00:31:18,399
that if we if we save the categorical

00:31:14,880 --> 00:31:20,159
valued column from pandas

00:31:18,399 --> 00:31:21,679
we actually can recover that type

00:31:20,159 --> 00:31:24,320
information

00:31:21,679 --> 00:31:25,840
that we're interested in but this sort

00:31:24,320 --> 00:31:27,760
of defeats the purpose of having an

00:31:25,840 --> 00:31:29,120
interchange format right if you say well

00:31:27,760 --> 00:31:30,640
i'm going to hand this file over to a

00:31:29,120 --> 00:31:32,960
data science team and they're going to

00:31:30,640 --> 00:31:35,519
have to rewrite it to make use of it

00:31:32,960 --> 00:31:35,519
efficiently

00:31:37,440 --> 00:31:40,799
so if we look at this this round trip

00:31:39,519 --> 00:31:42,799
here we're going to get the types we

00:31:40,799 --> 00:31:46,080
expect we see that this is a category

00:31:42,799 --> 00:31:49,679
instead of an object so

00:31:46,080 --> 00:31:51,600
we can use pi arrow the pyro api

00:31:49,679 --> 00:31:53,600
directly to sort of have more control

00:31:51,600 --> 00:31:56,320
over how we read

00:31:53,600 --> 00:31:56,320
this in

00:31:59,600 --> 00:32:03,919
and as we can see we can we can read a

00:32:02,240 --> 00:32:06,720
table

00:32:03,919 --> 00:32:06,720
with pi arrow

00:32:12,080 --> 00:32:16,399
and if we look at that table we have um

00:32:14,720 --> 00:32:18,000
a string rather than a python object

00:32:16,399 --> 00:32:20,480
which is a step in the right direction

00:32:18,000 --> 00:32:20,480
and the

00:32:22,159 --> 00:32:25,840
the arrow is a columnar representation

00:32:24,880 --> 00:32:27,440
so we know that that's going to be

00:32:25,840 --> 00:32:29,600
dictionary encoded as well

00:32:27,440 --> 00:32:32,240
but if we convert this to pandas again

00:32:29,600 --> 00:32:36,320
we've gone back to an object

00:32:32,240 --> 00:32:36,320
so what we want to do instead

00:32:40,840 --> 00:32:43,919
is

00:32:42,240 --> 00:32:45,919
that we want to read some columns and

00:32:43,919 --> 00:32:49,360
preserve that dictionary metadata so

00:32:45,919 --> 00:32:49,360
i'll show you what this looks like here

00:32:51,919 --> 00:32:55,360
and we're just going to specify a list

00:32:53,600 --> 00:32:57,840
of columns that we're going to read as a

00:32:55,360 --> 00:32:57,840
dictionary

00:33:00,640 --> 00:33:04,000
so now if we look at that table

00:33:04,399 --> 00:33:10,240
we see that it's a dictionary if we

00:33:07,519 --> 00:33:12,880
convert it to pandas

00:33:10,240 --> 00:33:13,679
we're going to maintain that categorical

00:33:12,880 --> 00:33:16,080
type

00:33:13,679 --> 00:33:17,440
we're running a little short on time so

00:33:16,080 --> 00:33:19,279
i have some more code

00:33:17,440 --> 00:33:20,640
that's available from a blog post that

00:33:19,279 --> 00:33:23,279
you can see on how to

00:33:20,640 --> 00:33:24,799
inspect parquet files but we'll skip

00:33:23,279 --> 00:33:27,600
that part of the demo and we'll just go

00:33:24,799 --> 00:33:30,559
ahead to our conclusions

00:33:27,600 --> 00:33:31,360
so thanks everyone for your time um i

00:33:30,559 --> 00:33:35,760
hope that

00:33:31,360 --> 00:33:38,000
hope that hope that you're

00:33:35,760 --> 00:33:39,279
thinking more about some computing myths

00:33:38,000 --> 00:33:41,039
that have uh

00:33:39,279 --> 00:33:42,799
that you've discovered are false and

00:33:41,039 --> 00:33:44,720
that

00:33:42,799 --> 00:33:45,919
that you realize are useful anyway and i

00:33:44,720 --> 00:33:49,039
think that parque

00:33:45,919 --> 00:33:50,320
um is not perfectly ubiquitous and it

00:33:49,039 --> 00:33:52,000
doesn't always get you perfect

00:33:50,320 --> 00:33:53,679
performance but if you're careful about

00:33:52,000 --> 00:33:56,240
how it works you can get really

00:33:53,679 --> 00:34:00,559
excellent results

00:33:56,240 --> 00:34:00,559
so here's what we talked about today

00:34:00,880 --> 00:34:04,159
we first talked about the organization

00:34:02,640 --> 00:34:06,240
of computer systems we talked about

00:34:04,159 --> 00:34:09,119
these principles of locality

00:34:06,240 --> 00:34:09,919
we talked about how these things fit

00:34:09,119 --> 00:34:11,760
together

00:34:09,919 --> 00:34:13,440
and how to get the best performance out

00:34:11,760 --> 00:34:14,720
of computer systems by reading things

00:34:13,440 --> 00:34:16,560
sequentially

00:34:14,720 --> 00:34:18,839
operating on values that are close

00:34:16,560 --> 00:34:20,879
together

00:34:18,839 --> 00:34:23,679
and

00:34:20,879 --> 00:34:25,359
we saw how a row oriented format can

00:34:23,679 --> 00:34:28,720
have really bad performance

00:34:25,359 --> 00:34:30,480
for analytic queries and for caches

00:34:28,720 --> 00:34:32,399
and i hope everyone is noticing that i'm

00:34:30,480 --> 00:34:33,359
actually choosing a column-oriented

00:34:32,399 --> 00:34:36,879
format for these

00:34:33,359 --> 00:34:38,720
summary slides uh

00:34:36,879 --> 00:34:40,000
the next thing we looked at was how

00:34:38,720 --> 00:34:43,119
parquet

00:34:40,000 --> 00:34:45,119
can get good performance by techniques

00:34:43,119 --> 00:34:46,560
like column encoding

00:34:45,119 --> 00:34:48,960
run length encoding and dictionary

00:34:46,560 --> 00:34:52,639
encoding and then predicate push down

00:34:48,960 --> 00:34:55,520
to only consider the parts of files that

00:34:52,639 --> 00:34:56,800
a query is actually interested in and

00:34:55,520 --> 00:34:58,079
then finally we looked at some

00:34:56,800 --> 00:35:03,440
interoperability

00:34:58,079 --> 00:35:06,480
challenges um that uh

00:35:03,440 --> 00:35:09,680
you might run into taking part k from

00:35:06,480 --> 00:35:12,320
an environment like the jbm

00:35:09,680 --> 00:35:16,160
to an environment like the python data

00:35:12,320 --> 00:35:18,720
ecosystem for example

00:35:16,160 --> 00:35:20,160
and we saw some solutions by using the

00:35:18,720 --> 00:35:23,040
arrow apis

00:35:20,160 --> 00:35:24,640
directly to sort of work around some of

00:35:23,040 --> 00:35:27,520
those challenges

00:35:24,640 --> 00:35:28,320
so um again i didn't i cut the demo a

00:35:27,520 --> 00:35:31,040
little bit short

00:35:28,320 --> 00:35:32,880
but the the full uh interactive notebook

00:35:31,040 --> 00:35:35,160
version of that demo is available

00:35:32,880 --> 00:35:36,320
from a link on my blog

00:35:35,160 --> 00:35:39,280
chatbo.freevariable.com

00:35:36,320 --> 00:35:40,960
if you search that site for parquet

00:35:39,280 --> 00:35:42,560
you'll get a link to the

00:35:40,960 --> 00:35:44,800
github repo with that notebook and

00:35:42,560 --> 00:35:46,960
there's a buzzwords branch

00:35:44,800 --> 00:35:48,240
on that repo that has the berlin

00:35:46,960 --> 00:35:51,440
payments data set

00:35:48,240 --> 00:35:53,920
um on it so please keep in touch

00:35:51,440 --> 00:35:55,680
uh twitter and github are are great ways

00:35:53,920 --> 00:35:58,320
to reach me i'm at will be

00:35:55,680 --> 00:35:58,800
on both and you can send me an email at

00:35:58,320 --> 00:36:02,320
will

00:35:58,800 --> 00:36:05,920
will be nvidia.com and i think

00:36:02,320 --> 00:36:07,599
uh since we have a break now i think

00:36:05,920 --> 00:36:09,119
uh the moderators are telling me we have

00:36:07,599 --> 00:36:11,599
time for a couple of questions

00:36:09,119 --> 00:36:12,480
so i'd i'd appreciate any questions you

00:36:11,599 --> 00:36:15,760
have folks

00:36:12,480 --> 00:36:17,280
thanks again for your time thank you for

00:36:15,760 --> 00:36:19,040
the great talk was definitely a great

00:36:17,280 --> 00:36:19,839
introduction on different pieces of this

00:36:19,040 --> 00:36:22,000
tech as well

00:36:19,839 --> 00:36:23,839
and we do have a few questions while we

00:36:22,000 --> 00:36:25,680
have like a break after this one

00:36:23,839 --> 00:36:26,960
so first question is basically what is

00:36:25,680 --> 00:36:29,599
your opinion on

00:36:26,960 --> 00:36:30,960
orc versus parque there's like another

00:36:29,599 --> 00:36:33,040
format

00:36:30,960 --> 00:36:34,480
that's that's a good question so i mean

00:36:33,040 --> 00:36:37,040
from my perspective

00:36:34,480 --> 00:36:37,760
um there there are advantages to both

00:36:37,040 --> 00:36:40,720
there's

00:36:37,760 --> 00:36:42,960
uh the question is orc versus parquet

00:36:40,720 --> 00:36:46,160
and

00:36:42,960 --> 00:36:47,520
i know um i know some people have had

00:36:46,160 --> 00:36:49,440
great success with orc

00:36:47,520 --> 00:36:50,560
i've i've used parkade because of its

00:36:49,440 --> 00:36:52,880
ubiquity

00:36:50,560 --> 00:36:54,880
um you know really in in more

00:36:52,880 --> 00:36:56,800
applications um

00:36:54,880 --> 00:36:58,640
and i think i think parquet has sort of

00:36:56,800 --> 00:37:01,599
a little bit better coverage

00:36:58,640 --> 00:37:02,320
in the ecosystem but you know certainly

00:37:01,599 --> 00:37:04,160
there are

00:37:02,320 --> 00:37:05,760
there are performance advantages to orc

00:37:04,160 --> 00:37:09,760
in some applications and it's always

00:37:05,760 --> 00:37:12,000
worth measuring and checking

00:37:09,760 --> 00:37:13,520
yeah sounds good and maybe uh another

00:37:12,000 --> 00:37:14,880
question from my side

00:37:13,520 --> 00:37:16,640
now we're talking about synchronously

00:37:14,880 --> 00:37:18,160
right so you mentioned you know like cpu

00:37:16,640 --> 00:37:20,480
and caches and everything else

00:37:18,160 --> 00:37:22,160
i've seen some companies also um

00:37:20,480 --> 00:37:23,680
advocating and saying like hey

00:37:22,160 --> 00:37:25,440
your data computations is going to be

00:37:23,680 --> 00:37:26,800
like on gpu right and we're not talking

00:37:25,440 --> 00:37:28,720
about like machine learning kind of

00:37:26,800 --> 00:37:30,480
computations but like a normal

00:37:28,720 --> 00:37:31,440
search and indexes and sums right what

00:37:30,480 --> 00:37:32,800
do you think about that is it's

00:37:31,440 --> 00:37:34,480
something that makes it faster

00:37:32,800 --> 00:37:36,480
or overhead of gpu is actually like

00:37:34,480 --> 00:37:37,920
taking it away

00:37:36,480 --> 00:37:39,760
so i mean this is a great this is a

00:37:37,920 --> 00:37:40,640
great question like i mentioned that i

00:37:39,760 --> 00:37:43,599
work on

00:37:40,640 --> 00:37:45,440
i work on apache spark and um you know

00:37:43,599 --> 00:37:47,280
some of what i work on at nvidia is

00:37:45,440 --> 00:37:49,760
is actually the product strategy for

00:37:47,280 --> 00:37:51,200
apache spark on gpus

00:37:49,760 --> 00:37:53,920
i mean again i'm not speaking for my

00:37:51,200 --> 00:37:56,560
employer um i think that

00:37:53,920 --> 00:37:58,640
columnar formats really open up

00:37:56,560 --> 00:38:00,480
accelerated computing to a lot of these

00:37:58,640 --> 00:38:02,480
applications right and it's it's

00:38:00,480 --> 00:38:03,920
i mean it's a case where gpus can

00:38:02,480 --> 00:38:06,320
accelerate what we think of as

00:38:03,920 --> 00:38:08,640
traditional database work

00:38:06,320 --> 00:38:10,320
and i mean it's one of these things

00:38:08,640 --> 00:38:12,160
where in a lot of cases the devil is in

00:38:10,320 --> 00:38:14,079
the details right you have to be careful

00:38:12,160 --> 00:38:16,079
about how you use things but

00:38:14,079 --> 00:38:18,079
if you have data that are in columnar

00:38:16,079 --> 00:38:20,240
formats if you have queries that operate

00:38:18,079 --> 00:38:21,440
a column at a time and if you can do

00:38:20,240 --> 00:38:23,200
enough work

00:38:21,440 --> 00:38:26,000
i mean there is some cost in getting

00:38:23,200 --> 00:38:27,599
data from main memory to gpu memory and

00:38:26,000 --> 00:38:30,720
back if you can do enough work

00:38:27,599 --> 00:38:32,400
over a task to amortize that out you can

00:38:30,720 --> 00:38:35,359
get good results so

00:38:32,400 --> 00:38:36,160
um you know i've i've seen in in

00:38:35,359 --> 00:38:38,480
realistic

00:38:36,160 --> 00:38:41,440
uh you know spark workloads uh

00:38:38,480 --> 00:38:41,920
acceleration of 3x to 5x on on dataframe

00:38:41,440 --> 00:38:47,839
jobs

00:38:41,920 --> 00:38:47,839
right with spark on gpus so

00:39:03,760 --> 00:39:05,839

YouTube URL: https://www.youtube.com/watch?v=kgBlZYH2Yp8


