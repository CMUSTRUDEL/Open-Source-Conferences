Title: Dmitry Kan & Max Irwin – Vector Search: Ask Me Anything!
Publication date: 2021-06-29
Playlist: Berlin Buzzwords 2021 #bbuzz
Description: 
	Get to know about vector search and ask Dmitry Kan & Max Irwin anything you need to know! This session is presented by "Haystack – The search relevance conference" and hosted by Charlie Hull.

Speaker:
Dmitry Kan – https://2021.berlinbuzzwords.de/member/dmitry-kan
Max Irwin – https://2021.berlinbuzzwords.de/member/max-irwin

More: https://2021.berlinbuzzwords.de/session/ask-me-anything-vector-search
Captions: 
	00:00:07,520 --> 00:00:10,400
hello

00:00:08,720 --> 00:00:12,240
uh good morning good evening good

00:00:10,400 --> 00:00:12,880
afternoon good day wherever you are in

00:00:12,240 --> 00:00:15,440
the world

00:00:12,880 --> 00:00:16,720
and welcome to berlin buzzwords my

00:00:15,440 --> 00:00:19,840
name's charlie hull

00:00:16,720 --> 00:00:21,520
um i'm from open source connections uh

00:00:19,840 --> 00:00:23,119
we're the search and relevance people

00:00:21,520 --> 00:00:25,279
and we're sponsoring berlin buzzwords

00:00:23,119 --> 00:00:28,560
very happy to do that do check out our

00:00:25,279 --> 00:00:31,199
partner our booth in the partner area so

00:00:28,560 --> 00:00:32,880
this talk actually is presented by the

00:00:31,199 --> 00:00:34,320
haystack conference for partnering with

00:00:32,880 --> 00:00:36,559
buzzwords this year

00:00:34,320 --> 00:00:38,320
um with haystack we aim to share great

00:00:36,559 --> 00:00:40,960
talks on search and relevance

00:00:38,320 --> 00:00:42,000
and bring the community together um

00:00:40,960 --> 00:00:44,160
currently we're running

00:00:42,000 --> 00:00:46,160
a haystack live meetup every few weeks

00:00:44,160 --> 00:00:47,680
i'll drop a link into the chat

00:00:46,160 --> 00:00:49,280
uh you're very welcome to join that

00:00:47,680 --> 00:00:50,239
we've got nearly 800 people come along

00:00:49,280 --> 00:00:51,600
to those talks

00:00:50,239 --> 00:00:53,760
and later this year we're evening

00:00:51,600 --> 00:00:54,719
opening hoping to start running physical

00:00:53,760 --> 00:00:57,039
events again

00:00:54,719 --> 00:00:58,000
fingers crossed uh do keep an eye on the

00:00:57,039 --> 00:00:59,440
haystack website

00:00:58,000 --> 00:01:01,440
and i'll post a link to that into the

00:00:59,440 --> 00:01:04,239
chat as well

00:01:01,440 --> 00:01:04,879
but anyway back to tonight's uh ask me

00:01:04,239 --> 00:01:07,600
anything

00:01:04,879 --> 00:01:09,200
so vector search it's the next big thing

00:01:07,600 --> 00:01:10,720
in search right

00:01:09,200 --> 00:01:13,360
well how do you actually do vector

00:01:10,720 --> 00:01:16,799
search why should you consider using it

00:01:13,360 --> 00:01:19,759
does it work how does it work is it

00:01:16,799 --> 00:01:23,360
fast is it slow might it be better than

00:01:19,759 --> 00:01:24,880
good old text search with tfidf

00:01:23,360 --> 00:01:26,640
what are the pros and cons is it even

00:01:24,880 --> 00:01:28,400
ready for mainstream use yet

00:01:26,640 --> 00:01:29,600
well i'm very happy to say to help

00:01:28,400 --> 00:01:31,840
answer some of these questions and we

00:01:29,600 --> 00:01:34,799
have two luminaries of the search world

00:01:31,840 --> 00:01:35,680
we have dmitri khan of silo ai and my

00:01:34,799 --> 00:01:39,040
colleague max

00:01:35,680 --> 00:01:40,320
irwin from open source connections

00:01:39,040 --> 00:01:43,040
we're going to try and answer these

00:01:40,320 --> 00:01:43,360
questions uh debitry and max i'm going

00:01:43,040 --> 00:01:45,680
to

00:01:43,360 --> 00:01:47,040
ask you to introduce yourselves and also

00:01:45,680 --> 00:01:49,360
maybe as a quick uh

00:01:47,040 --> 00:01:51,360
story about how you got so interested in

00:01:49,360 --> 00:01:53,600
this topic so to meet him maybe

00:01:51,360 --> 00:01:54,479
you can kick us off yeah thanks charlie

00:01:53,600 --> 00:01:57,520
hi everyone

00:01:54,479 --> 00:02:00,640
um glad to be here uh so yes

00:01:57,520 --> 00:02:03,040
i'm dmitry khan go by dima for shirt

00:02:00,640 --> 00:02:04,479
i'm currently a principal ai scientist

00:02:03,040 --> 00:02:06,960
with silo ai

00:02:04,479 --> 00:02:08,239
it's the largest private ai lab in the

00:02:06,960 --> 00:02:10,479
nordics

00:02:08,239 --> 00:02:12,800
and i'm currently leading a team of ai

00:02:10,479 --> 00:02:16,160
scientists and search engineers building

00:02:12,800 --> 00:02:18,239
new experiences for web scale search

00:02:16,160 --> 00:02:20,080
so how did i end up in this topic of

00:02:18,239 --> 00:02:20,959
vector search it has been a hobby topic

00:02:20,080 --> 00:02:23,440
for me since

00:02:20,959 --> 00:02:25,360
august last year well apparently there

00:02:23,440 --> 00:02:28,000
was nothing better to do

00:02:25,360 --> 00:02:30,400
and from the first experiment i have set

00:02:28,000 --> 00:02:32,400
out to evaluate vector search from

00:02:30,400 --> 00:02:34,000
the feasibility and production readiness

00:02:32,400 --> 00:02:36,879
point of view

00:02:34,000 --> 00:02:39,360
and it turned out that both solar and

00:02:36,879 --> 00:02:42,480
elasticsearch support vector search

00:02:39,360 --> 00:02:44,319
well technically for solar i had to take

00:02:42,480 --> 00:02:46,560
a custom query plug-in

00:02:44,319 --> 00:02:49,440
into use and for elasticsearch i came

00:02:46,560 --> 00:02:52,160
across elastic and then implementation

00:02:49,440 --> 00:02:53,519
and another goal of mine was to publish

00:02:52,160 --> 00:02:55,920
my findings

00:02:53,519 --> 00:02:58,720
on medium and this helped me to attract

00:02:55,920 --> 00:03:00,640
attention from the larger community

00:02:58,720 --> 00:03:02,640
leading to testing a commercial

00:03:00,640 --> 00:03:04,959
implementation of vector search on

00:03:02,640 --> 00:03:06,800
custom apu boards

00:03:04,959 --> 00:03:08,080
and according to my most recent

00:03:06,800 --> 00:03:10,480
experiment um

00:03:08,080 --> 00:03:11,280
you know this custom solution was the

00:03:10,480 --> 00:03:13,680
best

00:03:11,280 --> 00:03:15,519
um and the second best was um

00:03:13,680 --> 00:03:17,360
elasticsearch

00:03:15,519 --> 00:03:18,959
so i'm continuing my experimentation in

00:03:17,360 --> 00:03:22,480
this area it's really really

00:03:18,959 --> 00:03:23,440
interesting topic for me fantastic

00:03:22,480 --> 00:03:27,280
thanks steven

00:03:23,440 --> 00:03:28,720
uh max hey everybody i'm max irwin i'm a

00:03:27,280 --> 00:03:29,680
managing consultant at open source

00:03:28,720 --> 00:03:31,040
connections

00:03:29,680 --> 00:03:33,360
uh i've been working in the search

00:03:31,040 --> 00:03:34,720
domain for about 10 years now maybe a

00:03:33,360 --> 00:03:37,200
little bit longer

00:03:34,720 --> 00:03:38,319
i started learning and using nlp in

00:03:37,200 --> 00:03:41,920
2015.

00:03:38,319 --> 00:03:43,440
my initial area of research was actually

00:03:41,920 --> 00:03:46,480
knowledge graph extraction

00:03:43,440 --> 00:03:48,959
and vocabulary extraction

00:03:46,480 --> 00:03:49,840
um and i still tinker there occasionally

00:03:48,959 --> 00:03:52,720
but

00:03:49,840 --> 00:03:53,760
i fell into the natural progression of

00:03:52,720 --> 00:03:56,319
nlp

00:03:53,760 --> 00:03:57,519
into uh large language models the the

00:03:56,319 --> 00:04:00,799
burt stuff

00:03:57,519 --> 00:04:03,040
in the past three years these days i'm

00:04:00,799 --> 00:04:05,840
actively working on

00:04:03,040 --> 00:04:07,760
working with clients and trying to bring

00:04:05,840 --> 00:04:09,280
these models and merge them with the

00:04:07,760 --> 00:04:12,799
practical tools that we use

00:04:09,280 --> 00:04:14,400
day-to-day in search technology i'm also

00:04:12,799 --> 00:04:16,959
writing a couple chapters

00:04:14,400 --> 00:04:18,959
for the book ai powered search by trade

00:04:16,959 --> 00:04:20,959
ranger with doug turnbull

00:04:18,959 --> 00:04:23,280
my chapters are about using large

00:04:20,959 --> 00:04:24,880
language models with vector search for

00:04:23,280 --> 00:04:26,400
autocomplete semantic search and

00:04:24,880 --> 00:04:27,919
question answering

00:04:26,400 --> 00:04:29,600
i'm focused specifically again on

00:04:27,919 --> 00:04:31,199
practical tooling and use and the use

00:04:29,600 --> 00:04:33,199
cases for practitioners

00:04:31,199 --> 00:04:34,560
and trying to bring all this cool stuff

00:04:33,199 --> 00:04:37,199
that happens in

00:04:34,560 --> 00:04:38,880
ivy ivory towers of academia and google

00:04:37,199 --> 00:04:39,919
and bing into the hands of just us

00:04:38,880 --> 00:04:42,000
regular folks

00:04:39,919 --> 00:04:44,800
who are trying to ship ship smaller

00:04:42,000 --> 00:04:47,919
products day to day

00:04:44,800 --> 00:04:48,880
fantastic thanks max so the way this is

00:04:47,919 --> 00:04:52,080
going to work

00:04:48,880 --> 00:04:54,080
um you can submit questions on vector

00:04:52,080 --> 00:04:56,960
search for dimitri max

00:04:54,080 --> 00:04:57,440
in the in the usual fashion in the chat

00:04:56,960 --> 00:04:59,680
um

00:04:57,440 --> 00:05:01,600
but we also we thought we'd uh get ahead

00:04:59,680 --> 00:05:02,240
of ourselves a little and we asked the

00:05:01,600 --> 00:05:03,840
community

00:05:02,240 --> 00:05:05,759
a couple weeks ago to send us some

00:05:03,840 --> 00:05:08,160
questions to get us kicked off and uh

00:05:05,759 --> 00:05:10,479
maybe to inspire some of your questions

00:05:08,160 --> 00:05:12,639
so we're going to start with those um

00:05:10,479 --> 00:05:14,080
hopefully this uh this will be useful uh

00:05:12,639 --> 00:05:15,360
so we're going to kick off with our

00:05:14,080 --> 00:05:17,280
first question

00:05:15,360 --> 00:05:19,039
and uh forgive me i may have to read

00:05:17,280 --> 00:05:20,560
this from the document because it's

00:05:19,039 --> 00:05:22,880
complicated

00:05:20,560 --> 00:05:24,160
uh our first question um and i'm sorry

00:05:22,880 --> 00:05:25,440
we don't have uh

00:05:24,160 --> 00:05:26,639
the people who ask these questions

00:05:25,440 --> 00:05:28,160
written down here but maybe you'll

00:05:26,639 --> 00:05:30,320
recognize them yourself

00:05:28,160 --> 00:05:32,240
um a lot of machine learning

00:05:30,320 --> 00:05:35,759
applications use the

00:05:32,240 --> 00:05:38,000
face of vice and noi or an nms lib

00:05:35,759 --> 00:05:40,560
behind a simple web service for

00:05:38,000 --> 00:05:42,720
approximate nearest neighbor retrieval

00:05:40,560 --> 00:05:44,720
for example in recommender systems this

00:05:42,720 --> 00:05:46,479
works well for simple applications

00:05:44,720 --> 00:05:48,400
but when efficient filtering is required

00:05:46,479 --> 00:05:49,840
it seems you need to take the leap to a

00:05:48,400 --> 00:05:52,320
fully fledged search system

00:05:49,840 --> 00:05:54,160
elasticsearch vesper etc

00:05:52,320 --> 00:05:57,120
do you think there's an unserviced niche

00:05:54,160 --> 00:05:58,639
for a face or vice plus filter tool

00:05:57,120 --> 00:06:00,319
or do you think the additional benefits

00:05:58,639 --> 00:06:03,199
of a search system like best

00:06:00,319 --> 00:06:04,639
vespa pays for the additional complexity

00:06:03,199 --> 00:06:08,639
it brings i'm gonna ask

00:06:04,639 --> 00:06:12,639
this to the demon oh yeah thank you

00:06:08,639 --> 00:06:15,280
um well if you are in the elastics

00:06:12,639 --> 00:06:15,840
search world as i am uh you have two

00:06:15,280 --> 00:06:18,720
options

00:06:15,840 --> 00:06:20,319
so um i already mentioned the elastic uh

00:06:18,720 --> 00:06:23,440
nn plugin

00:06:20,319 --> 00:06:26,000
it basically implements an lsh

00:06:23,440 --> 00:06:27,280
locality sensitive hashing algorithm and

00:06:26,000 --> 00:06:29,600
then if you want to

00:06:27,280 --> 00:06:31,840
live dangerously you can also go and

00:06:29,600 --> 00:06:34,479
check out open distro and

00:06:31,840 --> 00:06:36,639
they implement like a graph method um

00:06:34,479 --> 00:06:39,280
and it's basically like offhip

00:06:36,639 --> 00:06:40,720
uh so it builds like uh it's implemented

00:06:39,280 --> 00:06:43,919
in c plus plus

00:06:40,720 --> 00:06:44,240
and um elastic and then plugin supports

00:06:43,919 --> 00:06:47,919
free

00:06:44,240 --> 00:06:49,599
filtering so you can it's it's it's a

00:06:47,919 --> 00:06:51,280
it's a typical use case i would say in

00:06:49,599 --> 00:06:52,639
many search engines when you have a

00:06:51,280 --> 00:06:55,599
number of you know

00:06:52,639 --> 00:06:56,400
parameters that you want to filter your

00:06:55,599 --> 00:06:59,280
search down

00:06:56,400 --> 00:07:01,759
first and then you will run an a n

00:06:59,280 --> 00:07:04,080
algorithm on top of that

00:07:01,759 --> 00:07:04,800
i'd say whichever methods you choose you

00:07:04,080 --> 00:07:08,000
need to

00:07:04,800 --> 00:07:10,400
carefully select the hyper parameters uh

00:07:08,000 --> 00:07:11,840
that each of these algorithms um you

00:07:10,400 --> 00:07:13,520
know offer

00:07:11,840 --> 00:07:16,000
in order to bring the best you know

00:07:13,520 --> 00:07:18,479
performance in terms of indexing speed

00:07:16,000 --> 00:07:19,599
versus recall versus like memory

00:07:18,479 --> 00:07:22,639
consumed

00:07:19,599 --> 00:07:24,880
during indexing and during search and

00:07:22,639 --> 00:07:26,080
i'd say um at least according to the

00:07:24,880 --> 00:07:28,720
papers um

00:07:26,080 --> 00:07:29,599
you know the the graph method the

00:07:28,720 --> 00:07:31,280
hierarchical

00:07:29,599 --> 00:07:32,880
navigable small world graph method

00:07:31,280 --> 00:07:35,840
scales well to

00:07:32,880 --> 00:07:37,680
uh multi-core architectures and it has

00:07:35,840 --> 00:07:39,759
like a bunch of heuristics there as well

00:07:37,680 --> 00:07:41,440
to avoid like local minima

00:07:39,759 --> 00:07:43,199
when it builds the graph and it builds a

00:07:41,440 --> 00:07:46,240
well-connected graph as well

00:07:43,199 --> 00:07:49,120
for like really large set of nodes

00:07:46,240 --> 00:07:50,080
um but you know like if you go back to

00:07:49,120 --> 00:07:52,639
the scene

00:07:50,080 --> 00:07:53,120
building a graph for each segment might

00:07:52,639 --> 00:07:55,440
become

00:07:53,120 --> 00:07:57,520
super expensive and so you should

00:07:55,440 --> 00:08:00,240
consider merging segments

00:07:57,520 --> 00:08:01,360
down into one segment before uh serving

00:08:00,240 --> 00:08:04,400
queries

00:08:01,360 --> 00:08:07,520
um and so generally i think combining

00:08:04,400 --> 00:08:08,800
filtering with an a n in one single you

00:08:07,520 --> 00:08:11,840
know pass

00:08:08,800 --> 00:08:12,319
is is a wise decision because you know

00:08:11,840 --> 00:08:14,639
if you

00:08:12,319 --> 00:08:15,599
offer like a multi-step retrieval where

00:08:14,639 --> 00:08:17,680
you will like

00:08:15,599 --> 00:08:18,800
first retrieve something then filter

00:08:17,680 --> 00:08:21,599
down and then

00:08:18,800 --> 00:08:24,160
you know re-rank now this will this will

00:08:21,599 --> 00:08:26,639
likely suffer from low speed

00:08:24,160 --> 00:08:28,720
or low recall of both so so i think

00:08:26,639 --> 00:08:29,599
combining this into one single phase is

00:08:28,720 --> 00:08:34,800
really nice and

00:08:29,599 --> 00:08:38,560
and wise solution max what do you think

00:08:34,800 --> 00:08:40,560
uh i think that um yes to both i think

00:08:38,560 --> 00:08:42,880
there's a there is a

00:08:40,560 --> 00:08:44,000
openness for a niche in the face plus

00:08:42,880 --> 00:08:47,760
filter

00:08:44,000 --> 00:08:51,040
um and i uh but i think that there are

00:08:47,760 --> 00:08:51,680
you know huge things that elasticsearch

00:08:51,040 --> 00:08:53,680
and vespa

00:08:51,680 --> 00:08:54,959
for example bring to the table so if

00:08:53,680 --> 00:08:57,120
you're going to if you're going to build

00:08:54,959 --> 00:08:59,519
something on top of for example nms lab

00:08:57,120 --> 00:09:01,200
or face or another vector search uh

00:08:59,519 --> 00:09:02,959
library

00:09:01,200 --> 00:09:04,000
you're you're basically doing the same

00:09:02,959 --> 00:09:05,519
thing as if you were going to start

00:09:04,000 --> 00:09:06,959
building a search engine off of lucien

00:09:05,519 --> 00:09:08,800
you can do it but you're going to miss

00:09:06,959 --> 00:09:11,080
out on all the things that we take for

00:09:08,800 --> 00:09:13,120
granted with devops and

00:09:11,080 --> 00:09:15,600
configurability and deployment and

00:09:13,120 --> 00:09:18,480
sharding replication and all that stuff

00:09:15,600 --> 00:09:19,120
um so you probably shouldn't roll your

00:09:18,480 --> 00:09:20,800
own

00:09:19,120 --> 00:09:22,399
like that and chuck it into production

00:09:20,800 --> 00:09:26,480
you're going to have a very

00:09:22,399 --> 00:09:26,480
very hard time with that um

00:09:26,800 --> 00:09:30,800
zema already mentioned you know the

00:09:28,480 --> 00:09:32,240
stuff that elastic is working on in some

00:09:30,800 --> 00:09:33,839
areas there

00:09:32,240 --> 00:09:37,200
there are some new players that are

00:09:33,839 --> 00:09:40,399
coming out like gina ai we bb-8 milvis

00:09:37,200 --> 00:09:41,360
pinecone are a couple examples that are

00:09:40,399 --> 00:09:44,399
trying to

00:09:41,360 --> 00:09:46,240
fill that niche um but those are

00:09:44,399 --> 00:09:47,839
you know the they're newer they're

00:09:46,240 --> 00:09:49,920
startups they're uh

00:09:47,839 --> 00:09:51,920
there's it is it is risky if you want to

00:09:49,920 --> 00:09:54,480
build some you know an existing

00:09:51,920 --> 00:09:55,360
big product on top of one of those newer

00:09:54,480 --> 00:09:58,399
systems

00:09:55,360 --> 00:10:00,080
um you can check out vespa which is uh

00:09:58,399 --> 00:10:02,079
definitely the mature product in this

00:10:00,080 --> 00:10:04,160
space but i think there are a lot of

00:10:02,079 --> 00:10:06,079
a lot of options you can look at and

00:10:04,160 --> 00:10:09,120
consider but definitely do the research

00:10:06,079 --> 00:10:10,959
and make an informed decision

00:10:09,120 --> 00:10:12,480
fantastic i will mention actually we've

00:10:10,959 --> 00:10:15,200
had a couple of these vector search

00:10:12,480 --> 00:10:16,640
engines uh presenting at haystack live

00:10:15,200 --> 00:10:18,399
so you can go back and check those out

00:10:16,640 --> 00:10:19,760
they're on our youtube channel

00:10:18,399 --> 00:10:22,160
um so i'm going to move on to the next

00:10:19,760 --> 00:10:22,160
question

00:10:22,800 --> 00:10:26,079
sometimes information is encoded in the

00:10:24,800 --> 00:10:27,760
language people use

00:10:26,079 --> 00:10:29,360
i mean layman's terms for layman's

00:10:27,760 --> 00:10:30,720
content or professional terms

00:10:29,360 --> 00:10:32,079
professional content

00:10:30,720 --> 00:10:34,800
so in medicine you might have very

00:10:32,079 --> 00:10:36,640
different results for acute myocardial

00:10:34,800 --> 00:10:38,160
infarction and heart attack

00:10:36,640 --> 00:10:40,240
how do you model these differences as

00:10:38,160 --> 00:10:42,640
input for a language model

00:10:40,240 --> 00:10:44,079
um but all are vectors not the answer

00:10:42,640 --> 00:10:45,440
here for where there are domains where

00:10:44,079 --> 00:10:48,560
there's information

00:10:45,440 --> 00:10:50,000
in the meaning but also in the terms uh

00:10:48,560 --> 00:10:51,200
max do you want to kick us off on this

00:10:50,000 --> 00:10:54,079
one

00:10:51,200 --> 00:10:56,480
yeah so this is this is the classic nlp

00:10:54,079 --> 00:10:58,800
vocabulary mismatch problem but not even

00:10:56,480 --> 00:11:00,000
not even nlp just the search vocabulary

00:10:58,800 --> 00:11:03,040
mismatch problem you have a corpus

00:11:00,000 --> 00:11:04,720
of text that contains one uh

00:11:03,040 --> 00:11:06,640
one type of language and then you have

00:11:04,720 --> 00:11:07,680
people searching using a different type

00:11:06,640 --> 00:11:11,440
of language

00:11:07,680 --> 00:11:13,839
um there are a couple things here so

00:11:11,440 --> 00:11:14,959
first of all with vector search you know

00:11:13,839 --> 00:11:16,240
it's not like this

00:11:14,959 --> 00:11:17,839
magic thing that you're just going to

00:11:16,240 --> 00:11:18,880
throw it out there and replace

00:11:17,839 --> 00:11:20,640
everything that you're doing

00:11:18,880 --> 00:11:22,399
you know you there are a lot of tools

00:11:20,640 --> 00:11:23,279
that you can use that we've been using

00:11:22,399 --> 00:11:24,560
for years

00:11:23,279 --> 00:11:26,480
um and traditionally this has been

00:11:24,560 --> 00:11:28,959
solved with synonyms and knowledge

00:11:26,480 --> 00:11:30,640
graphs right so you can you can do a map

00:11:28,959 --> 00:11:33,440
so if you see a term that's not in your

00:11:30,640 --> 00:11:35,839
corpus you can map to the

00:11:33,440 --> 00:11:37,519
to the language that's in your in your

00:11:35,839 --> 00:11:41,360
corpus and in your index

00:11:37,519 --> 00:11:42,560
um there are

00:11:41,360 --> 00:11:44,240
in terms of bringing this stuff into

00:11:42,560 --> 00:11:45,519
large language models you can try some

00:11:44,240 --> 00:11:47,600
hacks of

00:11:45,519 --> 00:11:49,440
you know fine-tuning by adding

00:11:47,600 --> 00:11:52,240
additional content

00:11:49,440 --> 00:11:54,240
to your model that contains uh the

00:11:52,240 --> 00:11:57,440
language that you want to include

00:11:54,240 --> 00:11:58,320
but no matter what the the large

00:11:57,440 --> 00:12:00,880
language model was

00:11:58,320 --> 00:12:02,720
was trained on an initial vocabulary um

00:12:00,880 --> 00:12:04,560
and that vocabulary is limited so in

00:12:02,720 --> 00:12:05,839
invert you have like word pieces and the

00:12:04,560 --> 00:12:09,279
word pieces are like 30

00:12:05,839 --> 00:12:11,279
000 um initial word pieces so

00:12:09,279 --> 00:12:13,440
if your language deviates from that

00:12:11,279 --> 00:12:15,839
significantly then even fine tuning may

00:12:13,440 --> 00:12:17,680
not really help that much

00:12:15,839 --> 00:12:19,440
um and you can try training your own

00:12:17,680 --> 00:12:20,880
model and setting your own vocabulary

00:12:19,440 --> 00:12:23,200
with the merged

00:12:20,880 --> 00:12:24,079
vocab set and merge content set but

00:12:23,200 --> 00:12:26,240
that's you know

00:12:24,079 --> 00:12:27,360
expensive and typically out of the reach

00:12:26,240 --> 00:12:29,600
for most teams

00:12:27,360 --> 00:12:30,480
um but you know if if you have the

00:12:29,600 --> 00:12:34,240
resources

00:12:30,480 --> 00:12:36,560
uh you know you can you can try that and

00:12:34,240 --> 00:12:37,279
you know as a hypothesis and test and

00:12:36,560 --> 00:12:40,079
see how it

00:12:37,279 --> 00:12:41,600
plays out diva what's your view on this

00:12:40,079 --> 00:12:44,320
one

00:12:41,600 --> 00:12:45,600
yeah um i think it's kind of cool when

00:12:44,320 --> 00:12:47,680
you throw like a

00:12:45,600 --> 00:12:49,519
bird model for instance at search and

00:12:47,680 --> 00:12:52,079
you type mathematics and it tells you

00:12:49,519 --> 00:12:52,800
you know geometry or linear algebra in

00:12:52,079 --> 00:12:55,519
response

00:12:52,800 --> 00:12:57,040
it's kind of all cool and fancy but i

00:12:55,519 --> 00:12:58,320
think when it comes you know to a

00:12:57,040 --> 00:13:00,959
specific domain

00:12:58,320 --> 00:13:02,720
you know like financial or healthcare

00:13:00,959 --> 00:13:04,320
whatever you have

00:13:02,720 --> 00:13:05,760
i don't think it will capture it so

00:13:04,320 --> 00:13:07,600
easily and so

00:13:05,760 --> 00:13:09,920
i agree with max there like you you

00:13:07,600 --> 00:13:12,320
really need to fine-tune your model

00:13:09,920 --> 00:13:14,399
uh on the data which might be super

00:13:12,320 --> 00:13:15,920
expensive as well depending on the size

00:13:14,399 --> 00:13:18,000
of your corpora

00:13:15,920 --> 00:13:20,079
uh but at the same time do you really

00:13:18,000 --> 00:13:22,399
want to go and attack that problem

00:13:20,079 --> 00:13:24,399
from from the you know large scale model

00:13:22,399 --> 00:13:24,959
or do you want to just go and configure

00:13:24,399 --> 00:13:27,440
that

00:13:24,959 --> 00:13:28,800
old-fashioned dictionary which will work

00:13:27,440 --> 00:13:31,600
quite well because

00:13:28,800 --> 00:13:33,680
it's a controlled way you know to offer

00:13:31,600 --> 00:13:36,480
this experience to your users

00:13:33,680 --> 00:13:38,320
and and why why to pay so much uh you

00:13:36,480 --> 00:13:39,760
know money to train a model when you

00:13:38,320 --> 00:13:43,279
don't see an exact

00:13:39,760 --> 00:13:45,519
application for it and um yeah i mean

00:13:43,279 --> 00:13:46,880
i think we will also cover some topics

00:13:45,519 --> 00:13:49,120
in the future

00:13:46,880 --> 00:13:50,399
during today but like also establish a

00:13:49,120 --> 00:13:53,120
baseline for your search

00:13:50,399 --> 00:13:54,160
like know how how it performs now before

00:13:53,120 --> 00:13:57,279
you venture into

00:13:54,160 --> 00:14:00,320
into vector model

00:13:57,279 --> 00:14:02,000
very sensible uh find try the stuff that

00:14:00,320 --> 00:14:04,399
you know works before you try the stuff

00:14:02,000 --> 00:14:07,600
that you don't know if it works

00:14:04,399 --> 00:14:09,839
um so our next question um

00:14:07,600 --> 00:14:11,680
somebody's noticed that uh instagram

00:14:09,839 --> 00:14:12,399
music uses some kind of language model

00:14:11,680 --> 00:14:14,079
now

00:14:12,399 --> 00:14:15,440
and if you search for a capitan the

00:14:14,079 --> 00:14:16,880
french word for captain

00:14:15,440 --> 00:14:18,800
to find french songs that are called

00:14:16,880 --> 00:14:20,560
capitaine uh english

00:14:18,800 --> 00:14:22,160
songs about captains are actually not

00:14:20,560 --> 00:14:24,160
relevant

00:14:22,160 --> 00:14:25,920
how do we avoid losing the information

00:14:24,160 --> 00:14:26,639
contained in the exact words when we

00:14:25,920 --> 00:14:28,839
search with

00:14:26,639 --> 00:14:30,160
with meaning as you might have with a

00:14:28,839 --> 00:14:32,480
vector

00:14:30,160 --> 00:14:32,480
to me

00:14:33,279 --> 00:14:38,480
yeah um so actually um

00:14:36,320 --> 00:14:40,079
as a matter of fact i i'm building uh

00:14:38,480 --> 00:14:43,120
with my team like a

00:14:40,079 --> 00:14:45,839
multilingual uh search engine

00:14:43,120 --> 00:14:47,839
and um we basically have like

00:14:45,839 --> 00:14:48,480
independent indices for different

00:14:47,839 --> 00:14:51,360
languages

00:14:48,480 --> 00:14:53,760
and so when query comes in we do our

00:14:51,360 --> 00:14:56,399
best to detect a language and so

00:14:53,760 --> 00:14:58,240
then we will like send the query into

00:14:56,399 --> 00:15:01,279
the specific

00:14:58,240 --> 00:15:01,920
index so there is like a high likelihood

00:15:01,279 --> 00:15:05,199
that

00:15:01,920 --> 00:15:05,680
it will capture uh the semantics of what

00:15:05,199 --> 00:15:09,920
you need

00:15:05,680 --> 00:15:11,519
even even like without vector search um

00:15:09,920 --> 00:15:13,199
but other than that i think if you if

00:15:11,519 --> 00:15:14,320
you already implemented like vector

00:15:13,199 --> 00:15:17,199
search give users

00:15:14,320 --> 00:15:18,160
control in the in in your user interface

00:15:17,199 --> 00:15:19,760
like if they

00:15:18,160 --> 00:15:22,079
if the if they don't agree with the

00:15:19,760 --> 00:15:23,519
results and they clearly see that search

00:15:22,079 --> 00:15:25,440
engine didn't nail it

00:15:23,519 --> 00:15:27,600
you know just give them tools to go back

00:15:25,440 --> 00:15:31,279
to like old-fashioned lexical

00:15:27,600 --> 00:15:33,120
uh search with with exact match so

00:15:31,279 --> 00:15:34,399
that's what i would recommend and i

00:15:33,120 --> 00:15:36,800
guess you could also

00:15:34,399 --> 00:15:38,839
try some things like language detection

00:15:36,800 --> 00:15:43,279
um

00:15:38,839 --> 00:15:46,560
yeah max what do you think

00:15:43,279 --> 00:15:47,199
yeah i think uh the important lesson is

00:15:46,560 --> 00:15:49,120
that

00:15:47,199 --> 00:15:51,040
uh don't don't just throw away your

00:15:49,120 --> 00:15:54,399
existing search stack

00:15:51,040 --> 00:15:56,160
um and uh replace it with with vector

00:15:54,399 --> 00:15:58,560
search right away you know it's it's

00:15:56,160 --> 00:16:00,160
it's another uh it's another feature

00:15:58,560 --> 00:16:03,440
that you would use

00:16:00,160 --> 00:16:04,880
um so when somebody and and it's it's

00:16:03,440 --> 00:16:06,639
important to take a step back and think

00:16:04,880 --> 00:16:08,320
of the the problems that your

00:16:06,639 --> 00:16:09,839
users have the information needs that

00:16:08,320 --> 00:16:11,120
your users have so if

00:16:09,839 --> 00:16:12,880
somebody approaches your search bar and

00:16:11,120 --> 00:16:15,040
they search for something in quotes or

00:16:12,880 --> 00:16:16,880
they're looking for an exact term

00:16:15,040 --> 00:16:18,880
give give them what what they want you

00:16:16,880 --> 00:16:22,720
know people have been trained on

00:16:18,880 --> 00:16:25,839
keyword search since like the early 90s

00:16:22,720 --> 00:16:29,120
so there's a lot of

00:16:25,839 --> 00:16:30,800
cultural uh cultural stuff that's

00:16:29,120 --> 00:16:32,880
embedded in just searching for

00:16:30,800 --> 00:16:33,839
nouns and not providing any other

00:16:32,880 --> 00:16:35,680
language so

00:16:33,839 --> 00:16:37,759
when that happens don't don't throw out

00:16:35,680 --> 00:16:40,959
the ability to do the exact match

00:16:37,759 --> 00:16:43,440
um and you know

00:16:40,959 --> 00:16:45,279
do additional things you know use use

00:16:43,440 --> 00:16:48,560
diversity of search results you know

00:16:45,279 --> 00:16:49,440
do some federation maybe do some stuff

00:16:48,560 --> 00:16:51,199
to bring in

00:16:49,440 --> 00:16:53,519
other things so you get both the best of

00:16:51,199 --> 00:16:55,600
both worlds you get the exact matching

00:16:53,519 --> 00:16:57,440
where people have very very fine control

00:16:55,600 --> 00:17:00,079
over what they're retrieving

00:16:57,440 --> 00:17:01,440
um and then you also get that that juicy

00:17:00,079 --> 00:17:04,480
semantic meaning

00:17:01,440 --> 00:17:06,959
uh relationship from vector search um

00:17:04,480 --> 00:17:09,360
and combine the two for uh for a better

00:17:06,959 --> 00:17:12,400
experience

00:17:09,360 --> 00:17:15,199
fantastic so um while we're um

00:17:12,400 --> 00:17:17,039
uh asking these pre-canned questions uh

00:17:15,199 --> 00:17:19,280
do remember to submit your own questions

00:17:17,039 --> 00:17:20,799
using the the questions tab on the right

00:17:19,280 --> 00:17:21,360
of this presentation as you're watching

00:17:20,799 --> 00:17:24,480
us

00:17:21,360 --> 00:17:26,480
and we'll ask our experts here um

00:17:24,480 --> 00:17:28,000
i've got a a quick question i'm going to

00:17:26,480 --> 00:17:29,840
answer myself actually

00:17:28,000 --> 00:17:31,760
somebody said they have experience of

00:17:29,840 --> 00:17:32,720
search and keyword search and building

00:17:31,760 --> 00:17:34,480
taxonomies

00:17:32,720 --> 00:17:35,919
and they find it hard to work in these

00:17:34,480 --> 00:17:38,720
fields um

00:17:35,919 --> 00:17:40,880
i will recommend relevant slack which uh

00:17:38,720 --> 00:17:42,240
i'll drop a link into the chat

00:17:40,880 --> 00:17:44,000
and there's a jobs channel there so if

00:17:42,240 --> 00:17:45,280
you want to do that maybe go on to

00:17:44,000 --> 00:17:46,720
working in some of the more advanced

00:17:45,280 --> 00:17:49,200
fields like vector search

00:17:46,720 --> 00:17:50,480
that's a good place to start so our next

00:17:49,200 --> 00:17:52,080
submitted question

00:17:50,480 --> 00:17:54,480
um i'll have to read this one quickly uh

00:17:52,080 --> 00:17:56,960
carefully because it's complicated

00:17:54,480 --> 00:17:59,520
um so we see some patterns that have

00:17:56,960 --> 00:18:01,200
emerged in the space of dense retrieval

00:17:59,520 --> 00:18:03,200
both from the research side as well in

00:18:01,200 --> 00:18:04,400
the industry what are your thoughts in

00:18:03,200 --> 00:18:06,000
what's coming next

00:18:04,400 --> 00:18:07,679
in dense retrieval where are things

00:18:06,000 --> 00:18:09,120
heading and what will people need to do

00:18:07,679 --> 00:18:10,799
to prepare

00:18:09,120 --> 00:18:14,720
uh demo do you want to start us on this

00:18:10,799 --> 00:18:16,160
one oh yeah for sure thanks charlie um

00:18:14,720 --> 00:18:18,160
i think there is like a lot of

00:18:16,160 --> 00:18:21,280
development going on in this area

00:18:18,160 --> 00:18:23,840
so i would um dearly recommend you the

00:18:21,280 --> 00:18:25,760
beer paper if you haven't read it yet

00:18:23,840 --> 00:18:28,000
i'll try to share the link later but

00:18:25,760 --> 00:18:29,120
it's it's it's it's an excellent

00:18:28,000 --> 00:18:31,760
benchmark

00:18:29,120 --> 00:18:33,360
you know where they compare you know

00:18:31,760 --> 00:18:35,919
dense methods against

00:18:33,360 --> 00:18:39,039
re-ranking methods against lexical uh

00:18:35,919 --> 00:18:42,400
matching using tf idea for bm25

00:18:39,039 --> 00:18:44,320
and um then you can

00:18:42,400 --> 00:18:46,000
like this paper establishes like the

00:18:44,320 --> 00:18:47,520
baseline of understanding what's going

00:18:46,000 --> 00:18:49,919
on in this area

00:18:47,520 --> 00:18:50,799
um and then uh they've been like some

00:18:49,919 --> 00:18:53,280
really uh

00:18:50,799 --> 00:18:54,080
cool uh papers recently for instance

00:18:53,280 --> 00:18:57,120
training

00:18:54,080 --> 00:19:00,240
uh embedding model like on byte level

00:18:57,120 --> 00:19:02,559
so this helps you to um

00:19:00,240 --> 00:19:03,600
you know solve some daunting issues with

00:19:02,559 --> 00:19:06,400
misspelling and

00:19:03,600 --> 00:19:08,080
and other related problems and then

00:19:06,400 --> 00:19:08,960
another paper applies four year

00:19:08,080 --> 00:19:11,600
transform

00:19:08,960 --> 00:19:12,000
to improve you know the speed of birth

00:19:11,600 --> 00:19:14,559
and

00:19:12,000 --> 00:19:15,600
it basically became seven seven times

00:19:14,559 --> 00:19:18,960
faster

00:19:15,600 --> 00:19:20,960
with like 92 percent accuracy so

00:19:18,960 --> 00:19:23,039
i'd say the community is moving ahead on

00:19:20,960 --> 00:19:26,080
solving this like various issues

00:19:23,039 --> 00:19:27,760
um with the embeddings because um these

00:19:26,080 --> 00:19:30,640
players actually do use

00:19:27,760 --> 00:19:32,799
them in production so in in in the

00:19:30,640 --> 00:19:35,840
client that i'm working for right now

00:19:32,799 --> 00:19:37,360
uh we are using uh like advanced methods

00:19:35,840 --> 00:19:40,720
i will not name it

00:19:37,360 --> 00:19:44,320
but it basically gives really

00:19:40,720 --> 00:19:46,799
good results on dcg um

00:19:44,320 --> 00:19:47,679
and another thing from this beer paper

00:19:46,799 --> 00:19:51,360
is that

00:19:47,679 --> 00:19:52,240
um you know like dense dense retrieval

00:19:51,360 --> 00:19:54,720
methods

00:19:52,240 --> 00:19:55,720
will not generalize well so like they

00:19:54,720 --> 00:19:58,720
will beat like

00:19:55,720 --> 00:20:01,679
bm25 only when the model was

00:19:58,720 --> 00:20:02,960
um trained on on on the same domain as

00:20:01,679 --> 00:20:05,760
the queries

00:20:02,960 --> 00:20:07,760
um and also what's interesting and

00:20:05,760 --> 00:20:10,240
important to understand is like

00:20:07,760 --> 00:20:11,280
when you apply vector search in your

00:20:10,240 --> 00:20:12,880
domain

00:20:11,280 --> 00:20:14,880
uh depending on the size of the

00:20:12,880 --> 00:20:18,000
documents you need to pick

00:20:14,880 --> 00:20:20,240
uh the similarity metric very carefully

00:20:18,000 --> 00:20:23,200
because for instance cosign uh

00:20:20,240 --> 00:20:26,320
similarity will favor shorter documents

00:20:23,200 --> 00:20:27,600
while dot product will favor you know

00:20:26,320 --> 00:20:29,280
longer documents

00:20:27,600 --> 00:20:30,640
so maybe you need to have some kind of

00:20:29,280 --> 00:20:33,039
combination of this

00:20:30,640 --> 00:20:35,039
you know metrics or like a dynamic

00:20:33,039 --> 00:20:36,159
selection of the metric depending on the

00:20:35,039 --> 00:20:39,919
use case

00:20:36,159 --> 00:20:42,159
or the the query intent um and also like

00:20:39,919 --> 00:20:43,600
performance of vector search at large

00:20:42,159 --> 00:20:47,360
you know it's an unsolved

00:20:43,600 --> 00:20:49,440
issue uh so you need to be looking at

00:20:47,360 --> 00:20:52,400
a bunch of like model configuration

00:20:49,440 --> 00:20:54,880
parameters that will work best for you

00:20:52,400 --> 00:20:56,400
uh and sort of like like that's my

00:20:54,880 --> 00:20:59,039
personal advice

00:20:56,400 --> 00:21:01,039
pay less attention to the error margins

00:20:59,039 --> 00:21:03,440
reported by big players because what

00:21:01,039 --> 00:21:05,520
works for them might not work for you

00:21:03,440 --> 00:21:08,240
and i will try to share some some some

00:21:05,520 --> 00:21:10,159
papers with you later as well so

00:21:08,240 --> 00:21:12,640
well we're lucky to have uh joe

00:21:10,159 --> 00:21:14,000
christian burgum and uh josh devins in

00:21:12,640 --> 00:21:15,440
the channel and they're uh they'll be

00:21:14,000 --> 00:21:17,679
our link buddies tonight so thank you

00:21:15,440 --> 00:21:20,320
guys for posting links to the papers

00:21:17,679 --> 00:21:21,600
uh so you've got more more reading to do

00:21:20,320 --> 00:21:23,520
max what do you think where are things

00:21:21,600 --> 00:21:26,080
heading

00:21:23,520 --> 00:21:26,720
uh yeah great great question so when

00:21:26,080 --> 00:21:29,039
this

00:21:26,720 --> 00:21:30,480
stuff first started showing up like you

00:21:29,039 --> 00:21:32,400
know three years ago

00:21:30,480 --> 00:21:33,520
two three years ago um it was mostly

00:21:32,400 --> 00:21:36,640
focused on

00:21:33,520 --> 00:21:37,600
uh retrieval and matching and ranking

00:21:36,640 --> 00:21:39,520
you know for near

00:21:37,600 --> 00:21:41,919
replacing not maybe not replacing but

00:21:39,520 --> 00:21:45,360
using uh approximate nearest neighbor

00:21:41,919 --> 00:21:46,000
instead of bm25 as your as your matching

00:21:45,360 --> 00:21:49,120
and ranking

00:21:46,000 --> 00:21:51,760
uh signals i

00:21:49,120 --> 00:21:52,880
think that what we've seen recently and

00:21:51,760 --> 00:21:54,159
the things that you really should

00:21:52,880 --> 00:21:56,880
prepare yourselves for

00:21:54,159 --> 00:21:58,000
are how it's this technology and these

00:21:56,880 --> 00:22:00,320
techniques

00:21:58,000 --> 00:22:02,080
with vector search are being used for

00:22:00,320 --> 00:22:06,320
the entire search experience

00:22:02,080 --> 00:22:09,280
so it's auto complete it's spelling

00:22:06,320 --> 00:22:09,280
query rewriting

00:22:10,159 --> 00:22:14,240
it's like snippeting and highlighting

00:22:12,240 --> 00:22:18,320
you know question answering

00:22:14,240 --> 00:22:20,559
um recommendations personalization

00:22:18,320 --> 00:22:22,720
classification and enrichment like all

00:22:20,559 --> 00:22:24,880
of these aspects that we think about in

00:22:22,720 --> 00:22:27,840
a full search experience

00:22:24,880 --> 00:22:29,440
we're seeing um we see that google and

00:22:27,840 --> 00:22:31,280
bing are now using these

00:22:29,440 --> 00:22:32,960
day-to-day you can do a web search on

00:22:31,280 --> 00:22:34,240
either of those engines or any of the

00:22:32,960 --> 00:22:38,159
engines that use

00:22:34,240 --> 00:22:39,919
bing uh for example well

00:22:38,159 --> 00:22:41,679
if you look at the page rendered you can

00:22:39,919 --> 00:22:44,880
you can tell that it's

00:22:41,679 --> 00:22:46,640
using this technology um and

00:22:44,880 --> 00:22:48,480
the way it always follows with this

00:22:46,640 --> 00:22:49,919
technology is you pay attention what the

00:22:48,480 --> 00:22:51,600
to what the people with the billions of

00:22:49,919 --> 00:22:53,760
dollars are doing and

00:22:51,600 --> 00:22:55,440
sooner or later it's going to fold into

00:22:53,760 --> 00:22:56,960
into the little fish

00:22:55,440 --> 00:23:00,000
you know folks like us that are trying

00:22:56,960 --> 00:23:02,880
to do the day-to-day stuff

00:23:00,000 --> 00:23:03,679
so i recommend that you focus on the

00:23:02,880 --> 00:23:07,120
fundamentals

00:23:03,679 --> 00:23:08,400
of how these technologies work we

00:23:07,120 --> 00:23:10,000
read the papers and if you don't

00:23:08,400 --> 00:23:10,799
understand the papers of the map that's

00:23:10,000 --> 00:23:12,799
fine

00:23:10,799 --> 00:23:15,120
um get involved with the community play

00:23:12,799 --> 00:23:17,840
around with the huge face

00:23:15,120 --> 00:23:18,320
uh stuff try out some collab notebooks

00:23:17,840 --> 00:23:21,679
that people

00:23:18,320 --> 00:23:24,080
have published just to get a feel of

00:23:21,679 --> 00:23:25,679
you know how this technology works and

00:23:24,080 --> 00:23:27,600
then

00:23:25,679 --> 00:23:29,280
apply it to apply it to your own

00:23:27,600 --> 00:23:31,679
problems and explore

00:23:29,280 --> 00:23:32,640
you know and tinker and see what's

00:23:31,679 --> 00:23:34,960
possible and see

00:23:32,640 --> 00:23:36,799
see the problems that you run into just

00:23:34,960 --> 00:23:38,159
keep yourself fresh with experience

00:23:36,799 --> 00:23:38,720
because that's you know that's how we

00:23:38,159 --> 00:23:40,400
learn

00:23:38,720 --> 00:23:42,000
and that's how we go forward with with

00:23:40,400 --> 00:23:43,120
all these new technologies and anytime

00:23:42,000 --> 00:23:45,520
something comes up

00:23:43,120 --> 00:23:47,600
you just got to keep playing with it and

00:23:45,520 --> 00:23:49,200
the state of the art the soda world

00:23:47,600 --> 00:23:50,720
we're we'll just keep pushing forward

00:23:49,200 --> 00:23:51,440
and the community will just keep pushing

00:23:50,720 --> 00:23:54,320
forward just

00:23:51,440 --> 00:23:55,840
you know follow what's going on um

00:23:54,320 --> 00:23:58,640
follow the community and

00:23:55,840 --> 00:24:01,760
and see what interests you and learn

00:23:58,640 --> 00:24:01,760
where you feel you have gaps

00:24:02,080 --> 00:24:05,919
thanks max so we've got a question

00:24:03,600 --> 00:24:06,320
actually submitted uh online i'm going

00:24:05,919 --> 00:24:08,720
to

00:24:06,320 --> 00:24:09,760
to wedge it in here uh while we work

00:24:08,720 --> 00:24:13,919
through our pre uh

00:24:09,760 --> 00:24:16,080
our pre-can questions um so i

00:24:13,919 --> 00:24:17,520
somebody asks um isn't the

00:24:16,080 --> 00:24:19,039
aforementioned pre-filtering

00:24:17,520 --> 00:24:20,159
counter-intuitive at least for

00:24:19,039 --> 00:24:22,000
e-commerce

00:24:20,159 --> 00:24:23,679
cannot we cannot know beforehand for

00:24:22,000 --> 00:24:26,080
unregistered customers whether they want

00:24:23,679 --> 00:24:27,600
to filter by color or price range

00:24:26,080 --> 00:24:33,840
now do we know what that refers to in

00:24:27,600 --> 00:24:33,840
our previous conversation

00:24:34,159 --> 00:24:37,760
um i might need a bit more color there

00:24:37,120 --> 00:24:39,840
but

00:24:37,760 --> 00:24:41,200
it probably refers to our i think the

00:24:39,840 --> 00:24:44,559
when we were talking about

00:24:41,200 --> 00:24:47,279
um doing pre-filtering um

00:24:44,559 --> 00:24:48,880
maybe up for language i guess but yeah

00:24:47,279 --> 00:24:50,480
i'm not entirely sure

00:24:48,880 --> 00:24:53,279
yeah i guess if i understand the

00:24:50,480 --> 00:24:55,840
question right is that um

00:24:53,279 --> 00:24:57,679
if if we apply f let's say we choose

00:24:55,840 --> 00:24:59,840
between let's say price and size

00:24:57,679 --> 00:25:00,799
right so we have two filters in the

00:24:59,840 --> 00:25:02,960
search engine

00:25:00,799 --> 00:25:04,080
now we have an option just to run the

00:25:02,960 --> 00:25:06,559
vector search on

00:25:04,080 --> 00:25:07,760
everything and then basically you know

00:25:06,559 --> 00:25:10,799
uh do some

00:25:07,760 --> 00:25:11,600
post filtering or smart ranking and and

00:25:10,799 --> 00:25:14,159
maybe show

00:25:11,600 --> 00:25:15,279
two groups of results you know by size

00:25:14,159 --> 00:25:19,120
and and by

00:25:15,279 --> 00:25:21,120
by color whatever it is um but

00:25:19,120 --> 00:25:23,200
the way i see the way i look at it is

00:25:21,120 --> 00:25:25,679
that you will be also bound by

00:25:23,200 --> 00:25:26,320
by speed of light so like when you

00:25:25,679 --> 00:25:29,279
execute

00:25:26,320 --> 00:25:30,159
execute a vector search right you you

00:25:29,279 --> 00:25:32,240
will face

00:25:30,159 --> 00:25:34,559
uh performance issues there will be like

00:25:32,240 --> 00:25:35,039
a bottleneck like if you look at my blog

00:25:34,559 --> 00:25:37,360
post

00:25:35,039 --> 00:25:39,200
um i will i will share the link as well

00:25:37,360 --> 00:25:40,720
sorry i don't have access to the chat

00:25:39,200 --> 00:25:43,520
right now but the thing is that

00:25:40,720 --> 00:25:44,799
uh it's it's quite expensive it's super

00:25:43,520 --> 00:25:47,200
expensive it's like

00:25:44,799 --> 00:25:48,960
more than a second uh what it takes to

00:25:47,200 --> 00:25:52,400
run one single search so

00:25:48,960 --> 00:25:52,880
you do want to pre-filter you know the

00:25:52,400 --> 00:25:54,799
space

00:25:52,880 --> 00:25:56,559
basically you are entering a new space

00:25:54,799 --> 00:25:59,440
of your documents right and now you

00:25:56,559 --> 00:26:01,120
you run your vector search with some

00:25:59,440 --> 00:26:03,840
similarity metric

00:26:01,120 --> 00:26:04,240
and you are sort of like searching in

00:26:03,840 --> 00:26:06,480
that

00:26:04,240 --> 00:26:07,919
local subspace of your documents is it

00:26:06,480 --> 00:26:10,480
good experience or not

00:26:07,919 --> 00:26:11,200
it's up to your ux it's up to what you

00:26:10,480 --> 00:26:14,799
are delivering

00:26:11,200 --> 00:26:17,039
uh in the product uh so uh maybe

00:26:14,799 --> 00:26:19,279
still offer the tools to the user if

00:26:17,039 --> 00:26:20,880
user disagrees you know with the results

00:26:19,279 --> 00:26:21,919
and you have some hints there that hey

00:26:20,880 --> 00:26:23,600
we applied

00:26:21,919 --> 00:26:25,279
some method that maybe we think it's the

00:26:23,600 --> 00:26:27,440
best but here are the tools if you

00:26:25,279 --> 00:26:30,240
disagree go and filter

00:26:27,440 --> 00:26:31,120
out yourself or maybe don't feel there

00:26:30,240 --> 00:26:33,440
so

00:26:31,120 --> 00:26:34,720
that that would be my answer great i

00:26:33,440 --> 00:26:36,880
hope that answers your question

00:26:34,720 --> 00:26:38,240
i'm going to skip on to one of our our

00:26:36,880 --> 00:26:39,679
previous questions here

00:26:38,240 --> 00:26:41,279
uh because i think that this might cover

00:26:39,679 --> 00:26:44,240
quite a few uh people's uh

00:26:41,279 --> 00:26:45,919
requests but content length is an

00:26:44,240 --> 00:26:47,200
interesting one isn't it uh because

00:26:45,919 --> 00:26:48,960
obviously you know we know in

00:26:47,200 --> 00:26:50,720
in text matching content length can

00:26:48,960 --> 00:26:52,960
affect you know the very weighting of

00:26:50,720 --> 00:26:54,880
the various uh fields we use in our in

00:26:52,960 --> 00:26:57,360
our ranking formula but

00:26:54,880 --> 00:26:58,159
uh where is there a content lens sweet

00:26:57,360 --> 00:27:00,080
spot where

00:26:58,159 --> 00:27:01,600
dense vectors have a clear advantage

00:27:00,080 --> 00:27:06,159
over sparse vectors

00:27:01,600 --> 00:27:08,640
playing tfidf max

00:27:06,159 --> 00:27:09,200
uh no there there there is and there

00:27:08,640 --> 00:27:11,840
isn't

00:27:09,200 --> 00:27:12,880
um so if you look at you know if you're

00:27:11,840 --> 00:27:15,919
getting embeddings

00:27:12,880 --> 00:27:18,080
for text if you look at the model

00:27:15,919 --> 00:27:19,600
you know the model will be limited by

00:27:18,080 --> 00:27:20,000
you know you'll have some limitation on

00:27:19,600 --> 00:27:22,399
the number

00:27:20,000 --> 00:27:23,120
of tokens that you can pass into the

00:27:22,399 --> 00:27:26,159
model

00:27:23,120 --> 00:27:28,399
in one step um and

00:27:26,159 --> 00:27:29,440
so that that's an upfront limitation of

00:27:28,399 --> 00:27:32,799
the model

00:27:29,440 --> 00:27:34,799
and architecture that you choose um

00:27:32,799 --> 00:27:37,120
there are a lot of efforts now to remove

00:27:34,799 --> 00:27:40,240
that barrier to to make things longer

00:27:37,120 --> 00:27:41,760
and longer um i would

00:27:40,240 --> 00:27:44,080
i would ask the question you know

00:27:41,760 --> 00:27:46,480
assuming that that there were some

00:27:44,080 --> 00:27:48,000
if there wasn't any limit uh ask

00:27:46,480 --> 00:27:50,240
yourself the same question

00:27:48,000 --> 00:27:51,440
just with bm25 how would how would you

00:27:50,240 --> 00:27:53,760
do this like

00:27:51,440 --> 00:27:55,600
and i think in a lot of cases it's

00:27:53,760 --> 00:27:57,679
important to

00:27:55,600 --> 00:27:58,960
not not just generalize but take a step

00:27:57,679 --> 00:28:00,480
back and look

00:27:58,960 --> 00:28:03,200
at the problem like what does it mean to

00:28:00,480 --> 00:28:06,320
have a relevant document and a relevant

00:28:03,200 --> 00:28:07,600
piece of information right we there was

00:28:06,320 --> 00:28:10,880
a

00:28:07,600 --> 00:28:12,159
my my colleague um bertrand you know

00:28:10,880 --> 00:28:14,240
he asked a question you know he had a

00:28:12,159 --> 00:28:16,480
client who was trying to index a

00:28:14,240 --> 00:28:17,360
document that was hundreds of megabytes

00:28:16,480 --> 00:28:18,880
and and

00:28:17,360 --> 00:28:20,880
you know you're wondering well what is

00:28:18,880 --> 00:28:21,200
what does that mean to have a relevant

00:28:20,880 --> 00:28:22,559
hit

00:28:21,200 --> 00:28:24,080
on a document that's hundreds of

00:28:22,559 --> 00:28:24,480
megabytes in length you know that could

00:28:24,080 --> 00:28:27,120
be

00:28:24,480 --> 00:28:27,520
you can contain like a lot of wikipedia

00:28:27,120 --> 00:28:30,240
in that

00:28:27,520 --> 00:28:31,760
you know that's so much knowledge so

00:28:30,240 --> 00:28:35,120
there's this idea of

00:28:31,760 --> 00:28:38,320
well how do you carve up

00:28:35,120 --> 00:28:39,120
the text for what you want for your

00:28:38,320 --> 00:28:41,279
domain

00:28:39,120 --> 00:28:42,399
and your customer's needs where do you

00:28:41,279 --> 00:28:44,320
where do you draw the line

00:28:42,399 --> 00:28:45,919
are people looking for a specific answer

00:28:44,320 --> 00:28:48,799
are they looking for a passage

00:28:45,919 --> 00:28:50,000
are they looking for entire books um or

00:28:48,799 --> 00:28:53,039
chapters

00:28:50,000 --> 00:28:53,840
uh and that varies from need to need

00:28:53,039 --> 00:28:56,399
even

00:28:53,840 --> 00:28:57,520
you know even even in the domain you

00:28:56,399 --> 00:28:59,120
know you might have

00:28:57,520 --> 00:29:00,159
situations where you say okay i'm going

00:28:59,120 --> 00:29:01,840
to give you the whole thing back or i'm

00:29:00,159 --> 00:29:05,760
just going to give you this one snippet

00:29:01,840 --> 00:29:09,360
so in terms of the technology limitation

00:29:05,760 --> 00:29:11,679
um that exists but even even then like

00:29:09,360 --> 00:29:12,640
understand how you're cutting stuff up

00:29:11,679 --> 00:29:15,440
and how

00:29:12,640 --> 00:29:16,000
you want to surface relevant relevant

00:29:15,440 --> 00:29:18,720
data

00:29:16,000 --> 00:29:19,039
and you know vector search there is kind

00:29:18,720 --> 00:29:21,039
of

00:29:19,039 --> 00:29:23,039
the app the afterthought it's like okay

00:29:21,039 --> 00:29:24,480
well i have this similarity function

00:29:23,039 --> 00:29:26,080
um and i'm just going to apply that and

00:29:24,480 --> 00:29:30,159
get a score uh

00:29:26,080 --> 00:29:31,200
to to the texts that i have

00:29:30,159 --> 00:29:33,360
what do you think demo do you think

00:29:31,200 --> 00:29:36,399
there's a sweet spot where it on

00:29:33,360 --> 00:29:39,440
content length uh i think if there is a

00:29:36,399 --> 00:29:40,960
sweet spot it's definitely before 512

00:29:39,440 --> 00:29:43,840
word pieces because

00:29:40,960 --> 00:29:45,679
all neural you know approaches has have

00:29:43,840 --> 00:29:46,799
this limit and maybe eventually this

00:29:45,679 --> 00:29:50,799
will be lifted

00:29:46,799 --> 00:29:53,760
but at this point if you if you read the

00:29:50,799 --> 00:29:55,520
paper that i mentioned they actually

00:29:53,760 --> 00:29:56,320
they actually mentioned this limitation

00:29:55,520 --> 00:29:59,039
there

00:29:56,320 --> 00:30:00,559
um but the question is again like do you

00:29:59,039 --> 00:30:04,320
even need that much

00:30:00,559 --> 00:30:06,000
um you know like if you take a really

00:30:04,320 --> 00:30:09,039
long document like max

00:30:06,000 --> 00:30:11,120
we explained just now i i think if it

00:30:09,039 --> 00:30:13,360
has like a a really diverse set

00:30:11,120 --> 00:30:15,279
set up like topics in it like if you

00:30:13,360 --> 00:30:16,960
have like thousands of pages in that

00:30:15,279 --> 00:30:18,640
document it's like a copy base from

00:30:16,960 --> 00:30:20,960
wikipedia or something

00:30:18,640 --> 00:30:22,640
uh you know imagine clustering this you

00:30:20,960 --> 00:30:26,080
know let's say you're using

00:30:22,640 --> 00:30:27,520
uh the graph method and in the graph

00:30:26,080 --> 00:30:31,120
method you will have like

00:30:27,520 --> 00:30:32,720
this really big you know what hotspots

00:30:31,120 --> 00:30:34,720
and then this document will be like

00:30:32,720 --> 00:30:35,440
connected to a bunch of other documents

00:30:34,720 --> 00:30:38,399
and

00:30:35,440 --> 00:30:38,799
does it help your user i'm not sure so

00:30:38,399 --> 00:30:42,080
what

00:30:38,799 --> 00:30:44,080
what i would do is probably try to like

00:30:42,080 --> 00:30:45,679
dissect your document in a number of

00:30:44,080 --> 00:30:47,279
like meaningful blocks

00:30:45,679 --> 00:30:48,720
so for instance let's say you have a

00:30:47,279 --> 00:30:51,039
section which is like

00:30:48,720 --> 00:30:52,080
about a specific topic or introduction

00:30:51,039 --> 00:30:54,720
or like whatever

00:30:52,080 --> 00:30:55,679
the mid part of that document um and

00:30:54,720 --> 00:30:56,880
then

00:30:55,679 --> 00:30:58,960
you know you could you could for

00:30:56,880 --> 00:31:01,600
instance go and index those specific

00:30:58,960 --> 00:31:04,240
sections in in a separate field and then

00:31:01,600 --> 00:31:06,480
use bm25 as your baseline you don't even

00:31:04,240 --> 00:31:08,159
need the vector search there right

00:31:06,480 --> 00:31:10,080
then another approach is that you could

00:31:08,159 --> 00:31:12,080
summarize the document then the question

00:31:10,080 --> 00:31:13,919
is if you have thousands of pages can

00:31:12,080 --> 00:31:14,880
you actually summarize that document i

00:31:13,919 --> 00:31:17,120
don't think so

00:31:14,880 --> 00:31:18,159
like you you will probably need a number

00:31:17,120 --> 00:31:20,159
of summaries

00:31:18,159 --> 00:31:22,080
and then you could of course encode that

00:31:20,159 --> 00:31:23,919
those as vectors using like

00:31:22,080 --> 00:31:25,279
whatever birth like model or whatever

00:31:23,919 --> 00:31:28,559
you you would like

00:31:25,279 --> 00:31:30,960
um so i i would say like step

00:31:28,559 --> 00:31:32,559
back from from like thinking is that

00:31:30,960 --> 00:31:35,440
vector search that's going to solve

00:31:32,559 --> 00:31:35,840
my all of my problems is it bm25 is it

00:31:35,440 --> 00:31:39,360
some

00:31:35,840 --> 00:31:40,080
some not invented yet method and think

00:31:39,360 --> 00:31:42,720
about

00:31:40,080 --> 00:31:44,720
what is in your data like ask your

00:31:42,720 --> 00:31:46,399
domain experts to annotate those

00:31:44,720 --> 00:31:47,760
documents so you actually have those

00:31:46,399 --> 00:31:50,320
building blocks

00:31:47,760 --> 00:31:51,760
at your hands and you can go and like

00:31:50,320 --> 00:31:52,559
you know experiment with different

00:31:51,760 --> 00:31:55,360
methods and

00:31:52,559 --> 00:31:56,320
have some sensible baseline i think bm25

00:31:55,360 --> 00:31:59,200
is a proven

00:31:56,320 --> 00:32:01,519
proven baseline at the moment and so you

00:31:59,200 --> 00:32:03,200
know play off of that

00:32:01,519 --> 00:32:04,880
that that i think would be my

00:32:03,200 --> 00:32:07,039
recommendation here

00:32:04,880 --> 00:32:08,799
great thank you so i'm going to just uh

00:32:07,039 --> 00:32:10,480
flip to a question from the audience

00:32:08,799 --> 00:32:12,000
uh we've got it's been it's been highly

00:32:10,480 --> 00:32:13,440
voted and uh

00:32:12,000 --> 00:32:15,519
somebody has asked how does hit

00:32:13,440 --> 00:32:18,880
highlighting work in a vector search

00:32:15,519 --> 00:32:22,000
world max do you want to take that one

00:32:18,880 --> 00:32:26,000
oh that's a great question so um the way

00:32:22,000 --> 00:32:28,240
hit highlighting works is uh

00:32:26,000 --> 00:32:29,760
so you you have a large language model

00:32:28,240 --> 00:32:33,519
and it's pre-trained

00:32:29,760 --> 00:32:35,039
uh you have a pre-trained model um the i

00:32:33,519 --> 00:32:36,720
i'll i'll talk specifically about the

00:32:35,039 --> 00:32:38,320
question answering

00:32:36,720 --> 00:32:40,640
aspect of this because this is a form of

00:32:38,320 --> 00:32:43,840
hit highlighting for closed domain

00:32:40,640 --> 00:32:43,840
question answer there's there's

00:32:55,200 --> 00:33:01,919
have the passage uh

00:32:58,320 --> 00:33:02,640
the query and the thing that you want to

00:33:01,919 --> 00:33:05,360
highlight

00:33:02,640 --> 00:33:06,000
right uh so those three things is what

00:33:05,360 --> 00:33:08,159
you need for

00:33:06,000 --> 00:33:09,679
for training and test data to fine-tune

00:33:08,159 --> 00:33:12,480
your model

00:33:09,679 --> 00:33:13,919
so it it will learn in the fine-tuning

00:33:12,480 --> 00:33:16,399
task

00:33:13,919 --> 00:33:16,960
given this passage and given this query

00:33:16,399 --> 00:33:20,399
you know

00:33:16,960 --> 00:33:21,120
what what should i what's the word or

00:33:20,399 --> 00:33:24,240
words

00:33:21,120 --> 00:33:25,039
that i should uh present um and

00:33:24,240 --> 00:33:27,440
highlight

00:33:25,039 --> 00:33:28,159
um and it doesn't make up text it it

00:33:27,440 --> 00:33:30,720
always it's

00:33:28,159 --> 00:33:31,760
it's it basically gives you positioning

00:33:30,720 --> 00:33:34,320
um which works

00:33:31,760 --> 00:33:35,440
very similar to highlighting right so

00:33:34,320 --> 00:33:39,120
you fine-tune

00:33:35,440 --> 00:33:42,799
this model on um on your task

00:33:39,120 --> 00:33:44,880
on your data and then you have the model

00:33:42,799 --> 00:33:46,159
and then when you are using this thing

00:33:44,880 --> 00:33:49,440
in production

00:33:46,159 --> 00:33:52,720
um you get your search results back

00:33:49,440 --> 00:33:55,600
uh from a n or bm25 or whatever

00:33:52,720 --> 00:33:56,799
and you pass in the passages uh that

00:33:55,600 --> 00:33:59,200
come back in your results

00:33:56,799 --> 00:34:00,640
into this other model and then it

00:33:59,200 --> 00:34:01,679
returns the positioning for you and then

00:34:00,640 --> 00:34:02,880
you can use

00:34:01,679 --> 00:34:04,240
highlighting there or you could just

00:34:02,880 --> 00:34:05,679
call it out and you don't have to

00:34:04,240 --> 00:34:06,960
highlight it in place you can just say

00:34:05,679 --> 00:34:10,079
here's your answer

00:34:06,960 --> 00:34:14,159
right so that's that's pretty much

00:34:10,079 --> 00:34:17,040
uh how it works i'm trying to remember

00:34:14,159 --> 00:34:19,200
there's a specific data set uh that's

00:34:17,040 --> 00:34:22,720
available

00:34:19,200 --> 00:34:24,639
that it's a it's uh

00:34:22,720 --> 00:34:25,919
it starts with an s but it's escaping me

00:34:24,639 --> 00:34:27,040
right now because i'm having a brain

00:34:25,919 --> 00:34:28,079
freeze while i'm trying to talk and

00:34:27,040 --> 00:34:30,480
answer questions

00:34:28,079 --> 00:34:31,520
uh but when i remember i'll i'll i'll

00:34:30,480 --> 00:34:35,839
chuck it into the chat

00:34:31,520 --> 00:34:35,839
in the in the breakout session

00:34:37,839 --> 00:34:40,960
great demo what do you think in

00:34:39,440 --> 00:34:43,359
highlighting

00:34:40,960 --> 00:34:44,720
yeah i think it's um it's kind of

00:34:43,359 --> 00:34:48,320
challenging because

00:34:44,720 --> 00:34:49,919
um if you if you sort of like um

00:34:48,320 --> 00:34:51,839
if you're just entering this area let's

00:34:49,919 --> 00:34:53,280
say you as i gave you an example

00:34:51,839 --> 00:34:55,679
very simple right you you type

00:34:53,280 --> 00:34:59,040
mathematics and it gives you like

00:34:55,679 --> 00:35:00,800
linear algebra like can you go and

00:34:59,040 --> 00:35:02,240
highlight linear algebra having

00:35:00,800 --> 00:35:05,599
mathematics now

00:35:02,240 --> 00:35:08,160
so you need to have some way of

00:35:05,599 --> 00:35:08,720
knowing the distance right so like okay

00:35:08,160 --> 00:35:11,280
between

00:35:08,720 --> 00:35:13,040
um mathematics and linear algebra there

00:35:11,280 --> 00:35:15,520
is like the smallest distance

00:35:13,040 --> 00:35:17,200
and the model should tell you that so it

00:35:15,520 --> 00:35:18,160
like you could you could apply like a

00:35:17,200 --> 00:35:19,760
layer in the

00:35:18,160 --> 00:35:22,000
in the model let's say let's say

00:35:19,760 --> 00:35:24,400
attention layer and then see okay

00:35:22,000 --> 00:35:25,599
which of these words correlate best with

00:35:24,400 --> 00:35:27,839
the query right

00:35:25,599 --> 00:35:29,119
and this is what what i think max

00:35:27,839 --> 00:35:31,440
alluded to as well

00:35:29,119 --> 00:35:32,240
so let's say you know document is

00:35:31,440 --> 00:35:33,839
returned

00:35:32,240 --> 00:35:36,320
and there are like a number of passages

00:35:33,839 --> 00:35:37,920
there that highly correlate

00:35:36,320 --> 00:35:39,680
you know with the queries so you can go

00:35:37,920 --> 00:35:41,599
and highlight them but the question is

00:35:39,680 --> 00:35:43,359
should you highlight the whole passage

00:35:41,599 --> 00:35:44,000
or can you actually build a method that

00:35:43,359 --> 00:35:46,400
will actually

00:35:44,000 --> 00:35:47,280
highlight individual most prominent

00:35:46,400 --> 00:35:49,760
words that

00:35:47,280 --> 00:35:51,520
contribute to to answering your question

00:35:49,760 --> 00:35:53,040
this is what highlighters usually do

00:35:51,520 --> 00:35:53,599
right when you go to google and you type

00:35:53,040 --> 00:35:55,440
something

00:35:53,599 --> 00:35:57,440
it actually highlights you the the

00:35:55,440 --> 00:35:58,480
actual you know words to pay attention

00:35:57,440 --> 00:36:00,480
to and i think

00:35:58,480 --> 00:36:01,520
you can you can apply like an attention

00:36:00,480 --> 00:36:03,520
layer again

00:36:01,520 --> 00:36:05,040
i would need to go and double check that

00:36:03,520 --> 00:36:06,800
but but this is

00:36:05,040 --> 00:36:09,040
this is the direction in which i would

00:36:06,800 --> 00:36:09,920
go um as well and i think there are some

00:36:09,040 --> 00:36:12,400
other methods

00:36:09,920 --> 00:36:13,520
somebody mentioned to me like um you

00:36:12,400 --> 00:36:15,920
know

00:36:13,520 --> 00:36:17,920
decrypting the the vectors back to words

00:36:15,920 --> 00:36:20,160
and then trying to see the overlap

00:36:17,920 --> 00:36:22,400
but i'm not sure if it's like shooting

00:36:20,160 --> 00:36:24,400
from a canon

00:36:22,400 --> 00:36:26,880
but i think attention layer might might

00:36:24,400 --> 00:36:28,480
work better so yeah

00:36:26,880 --> 00:36:29,920
i i did remember the name of the data

00:36:28,480 --> 00:36:33,119
set it's a squad

00:36:29,920 --> 00:36:34,480
is the task

00:36:33,119 --> 00:36:38,079
one of our link buddies has already

00:36:34,480 --> 00:36:38,079
posted that in the chat absolutely

00:36:38,839 --> 00:36:44,320
kevin so

00:36:41,440 --> 00:36:44,960
we've got our um let's uh have a look at

00:36:44,320 --> 00:36:48,640
one of our

00:36:44,960 --> 00:36:50,480
our set questions again um

00:36:48,640 --> 00:36:54,400
and this is an interesting one what a

00:36:50,480 --> 00:36:57,839
good and bad use cases for vector search

00:36:54,400 --> 00:36:59,280
and um fema do you want to start us with

00:36:57,839 --> 00:37:03,040
that one

00:36:59,280 --> 00:37:04,800
sure um this is actually an interesting

00:37:03,040 --> 00:37:07,839
question because i was thinking like

00:37:04,800 --> 00:37:11,599
in principle you can represent any

00:37:07,839 --> 00:37:14,480
object as a vector the question is

00:37:11,599 --> 00:37:16,400
do you have a good model to do that you

00:37:14,480 --> 00:37:18,640
know you could in principle take

00:37:16,400 --> 00:37:20,400
well it's known that you can take image

00:37:18,640 --> 00:37:24,240
you can take

00:37:20,400 --> 00:37:25,040
sound text um maybe even like a virus

00:37:24,240 --> 00:37:26,640
signature

00:37:25,040 --> 00:37:28,160
right if you're like in the into

00:37:26,640 --> 00:37:31,920
antivirus world

00:37:28,160 --> 00:37:35,040
um then um i still think that

00:37:31,920 --> 00:37:38,079
it's important to pick the right

00:37:35,040 --> 00:37:41,200
similarity metric because you know

00:37:38,079 --> 00:37:41,760
for different objects um they will have

00:37:41,200 --> 00:37:43,520
different

00:37:41,760 --> 00:37:45,599
like structure in the vector like let's

00:37:43,520 --> 00:37:46,480
say it's a dense vector or like you have

00:37:45,599 --> 00:37:48,800
a sift

00:37:46,480 --> 00:37:50,160
data structure um they will have

00:37:48,800 --> 00:37:52,640
different characteristics

00:37:50,160 --> 00:37:54,480
and so again if you read that bigger

00:37:52,640 --> 00:37:57,599
paper you will see that different

00:37:54,480 --> 00:37:59,520
you know models uh will generalize or

00:37:57,599 --> 00:37:59,920
not generalize so you'll have to retrain

00:37:59,520 --> 00:38:02,160
it

00:37:59,920 --> 00:38:03,359
to that specific object and so i think

00:38:02,160 --> 00:38:05,599
in general

00:38:03,359 --> 00:38:08,079
you know vector search has like a really

00:38:05,599 --> 00:38:10,000
wide applicability area and probably

00:38:08,079 --> 00:38:13,280
that's why we see so many

00:38:10,000 --> 00:38:15,520
new interesting startups um

00:38:13,280 --> 00:38:17,680
and open source projects in this in this

00:38:15,520 --> 00:38:19,440
field

00:38:17,680 --> 00:38:21,280
but when it comes to like implementing

00:38:19,440 --> 00:38:24,000
sort of coming to the bad side

00:38:21,280 --> 00:38:25,920
like if you if you throw like uh some

00:38:24,000 --> 00:38:29,200
dance vector approach

00:38:25,920 --> 00:38:31,359
to all of your queries probably

00:38:29,200 --> 00:38:32,880
you may end up in a situation that users

00:38:31,359 --> 00:38:34,800
will be like scratching their head and

00:38:32,880 --> 00:38:36,800
thinking what's going on here like

00:38:34,800 --> 00:38:38,400
i'm looking for this specific thing and

00:38:36,800 --> 00:38:40,800
it and it's telling me about some

00:38:38,400 --> 00:38:43,440
similar thing that i'm not interested in

00:38:40,800 --> 00:38:44,320
i'm interested in that specific thing

00:38:43,440 --> 00:38:48,000
and so

00:38:44,320 --> 00:38:49,280
this is again the great point to step

00:38:48,000 --> 00:38:50,800
back and think about

00:38:49,280 --> 00:38:52,480
establishing the baseline for your

00:38:50,800 --> 00:38:55,920
search engine um

00:38:52,480 --> 00:38:59,520
i happen to be a committer at cupid

00:38:55,920 --> 00:39:01,839
uh and so great tool open source

00:38:59,520 --> 00:39:03,359
use it or use some other tool to

00:39:01,839 --> 00:39:06,000
establish the baseline

00:39:03,359 --> 00:39:07,440
you know i'm doing it with my team

00:39:06,000 --> 00:39:10,160
currently with a number of

00:39:07,440 --> 00:39:12,480
for a number of languages and you will

00:39:10,160 --> 00:39:13,280
learn a ton from from establishing the

00:39:12,480 --> 00:39:16,480
baseline

00:39:13,280 --> 00:39:18,480
trust me like ranging from

00:39:16,480 --> 00:39:20,240
hey you have some problems in the

00:39:18,480 --> 00:39:23,760
formatting of the document

00:39:20,240 --> 00:39:26,960
you know to source uh authority

00:39:23,760 --> 00:39:28,320
or you know freshness of some of the

00:39:26,960 --> 00:39:31,599
documents and so on

00:39:28,320 --> 00:39:34,640
so work with your domain experts there

00:39:31,599 --> 00:39:38,240
and then consider any of the

00:39:34,640 --> 00:39:40,720
um you know ranking methods

00:39:38,240 --> 00:39:43,200
like even ltr learning to rank as a

00:39:40,720 --> 00:39:45,520
black box okay i have the baseline

00:39:43,200 --> 00:39:47,119
now i can go and apply uh you know

00:39:45,520 --> 00:39:49,520
different methods one by one

00:39:47,119 --> 00:39:51,680
and see which one wins and so what other

00:39:49,520 --> 00:39:54,320
team is doing in our company is that

00:39:51,680 --> 00:39:55,680
they systematically train uh dance

00:39:54,320 --> 00:39:57,839
retrieval methods

00:39:55,680 --> 00:39:58,800
tune some parameters and they have the

00:39:57,839 --> 00:40:02,000
leaderboard

00:39:58,800 --> 00:40:05,520
of all of those um with respect to

00:40:02,000 --> 00:40:08,079
a specific score like gcg on a and dcg

00:40:05,520 --> 00:40:10,160
and then they also can compute the same

00:40:08,079 --> 00:40:13,200
metrics on their rival

00:40:10,160 --> 00:40:15,359
um you know on their rivals and

00:40:13,200 --> 00:40:17,920
and then that's like a sweet spot where

00:40:15,359 --> 00:40:19,680
you want to be

00:40:17,920 --> 00:40:22,800
max what do you think on this one good

00:40:19,680 --> 00:40:26,240
or bad use cases for vector search

00:40:22,800 --> 00:40:29,280
yeah um so i'll tell you

00:40:26,240 --> 00:40:31,359
the the biggest leap that i think

00:40:29,280 --> 00:40:33,359
most people are going to have to make

00:40:31,359 --> 00:40:35,440
into vector search mentally

00:40:33,359 --> 00:40:36,960
is that you know if you come from an

00:40:35,440 --> 00:40:39,040
inverted index

00:40:36,960 --> 00:40:40,240
you're very used to a certain way of

00:40:39,040 --> 00:40:43,440
thinking where

00:40:40,240 --> 00:40:44,960
you have uh you have your index of a set

00:40:43,440 --> 00:40:46,720
number of terms and maybe you have some

00:40:44,960 --> 00:40:49,760
synonyms and then

00:40:46,720 --> 00:40:51,760
you basically do a match and a lookup

00:40:49,760 --> 00:40:53,119
in that index directly and then you use

00:40:51,760 --> 00:40:56,240
bm 25

00:40:53,119 --> 00:40:58,079
for similarity scoring with approximate

00:40:56,240 --> 00:41:00,800
nearest neighbor searching

00:40:58,079 --> 00:41:01,599
and vector searching it's kind of like

00:41:00,800 --> 00:41:03,920
this

00:41:01,599 --> 00:41:05,040
leap into there's this one step that you

00:41:03,920 --> 00:41:08,079
do for both

00:41:05,040 --> 00:41:08,880
it's like you get stuff back that

00:41:08,079 --> 00:41:10,560
matches

00:41:08,880 --> 00:41:12,400
and then there's a score behind it all

00:41:10,560 --> 00:41:16,319
in all at once right

00:41:12,400 --> 00:41:19,760
um so that's i i think that

00:41:16,319 --> 00:41:23,200
if you get over that

00:41:19,760 --> 00:41:24,000
that first hump of switching your brain

00:41:23,200 --> 00:41:27,359
into that

00:41:24,000 --> 00:41:30,000
i think a lot of the use cases uh

00:41:27,359 --> 00:41:31,599
good or bad may come naturally when

00:41:30,000 --> 00:41:33,119
you're thinking about how to apply this

00:41:31,599 --> 00:41:34,720
into your domain and i can't

00:41:33,119 --> 00:41:36,720
unfortunately i can't really tell your

00:41:34,720 --> 00:41:38,800
brain how to make that switch it comes

00:41:36,720 --> 00:41:42,000
with a lot of playing around and

00:41:38,800 --> 00:41:43,760
and and learning and figuring it out um

00:41:42,000 --> 00:41:44,240
but i'll i'll give you some do's and

00:41:43,760 --> 00:41:46,960
don'ts

00:41:44,240 --> 00:41:48,400
uh instead of uh you know good and bad

00:41:46,960 --> 00:41:50,160
use cases because i think there's a

00:41:48,400 --> 00:41:52,319
whole bunch of stuff that you can try

00:41:50,160 --> 00:41:53,440
and do and you may it may end up

00:41:52,319 --> 00:41:54,560
successful

00:41:53,440 --> 00:41:57,200
it's really hard to answer that

00:41:54,560 --> 00:41:58,319
generally so i'll say like some some

00:41:57,200 --> 00:42:00,079
don'ts is

00:41:58,319 --> 00:42:02,079
you know when you have vectors that come

00:42:00,079 --> 00:42:04,240
from multiple passages

00:42:02,079 --> 00:42:05,440
don't try to just average them together

00:42:04,240 --> 00:42:07,680
uh because you you know

00:42:05,440 --> 00:42:09,040
to try to increase performance or reduce

00:42:07,680 --> 00:42:10,800
the space

00:42:09,040 --> 00:42:14,400
costs that you have that that's not

00:42:10,800 --> 00:42:16,560
going to work don't try to do that stuff

00:42:14,400 --> 00:42:18,079
don't use a pre-trained model without

00:42:16,560 --> 00:42:20,319
first understanding

00:42:18,079 --> 00:42:22,240
what it was trained on uh and the

00:42:20,319 --> 00:42:24,400
vocabulary that it contains

00:42:22,240 --> 00:42:26,160
and then also its limitations compared

00:42:24,400 --> 00:42:27,680
to your domain don't just like

00:42:26,160 --> 00:42:29,359
pick a random pre-trained model and be

00:42:27,680 --> 00:42:31,040
like oh this is what they used in this

00:42:29,359 --> 00:42:32,880
look notebook i'm going to use this one

00:42:31,040 --> 00:42:33,839
right under understand the model that

00:42:32,880 --> 00:42:38,560
you're choosing

00:42:33,839 --> 00:42:40,400
and using and then and then fine tune it

00:42:38,560 --> 00:42:43,440
and don't don't just use vector

00:42:40,400 --> 00:42:45,200
similarity as your only feature

00:42:43,440 --> 00:42:46,800
for ranking you know you have a lot of

00:42:45,200 --> 00:42:49,839
stuff that you can use

00:42:46,800 --> 00:42:51,760
you know we talk about uh

00:42:49,839 --> 00:42:53,920
search you know when you're surfacing

00:42:51,760 --> 00:42:55,680
results you don't just use bm25 you use

00:42:53,920 --> 00:42:57,520
bm25 and you have function scores for

00:42:55,680 --> 00:42:59,680
like oh the recency of the date

00:42:57,520 --> 00:43:01,359
uh you know the the rating on the

00:42:59,680 --> 00:43:02,000
product and you know all kinds of other

00:43:01,359 --> 00:43:04,800
features

00:43:02,000 --> 00:43:06,560
that combine to make up total relevance

00:43:04,800 --> 00:43:07,920
uh for a document when

00:43:06,560 --> 00:43:10,400
when somebody's searching for an

00:43:07,920 --> 00:43:13,680
information need um

00:43:10,400 --> 00:43:15,040
so that's some stuff into into some dots

00:43:13,680 --> 00:43:17,280
some do's is like

00:43:15,040 --> 00:43:18,560
do split up your documents into good

00:43:17,280 --> 00:43:20,240
passages

00:43:18,560 --> 00:43:22,079
in the size that fits your architecture

00:43:20,240 --> 00:43:24,640
your domain your use cases

00:43:22,079 --> 00:43:26,000
um and then you know you can investigate

00:43:24,640 --> 00:43:27,599
instead of averaging you can look at

00:43:26,000 --> 00:43:30,720
things like distillation

00:43:27,599 --> 00:43:31,839
uh summarization uh pca other other

00:43:30,720 --> 00:43:33,839
techniques

00:43:31,839 --> 00:43:34,960
quantization to try to get the

00:43:33,839 --> 00:43:37,599
performance

00:43:34,960 --> 00:43:38,160
uh there because you can't just dump raw

00:43:37,599 --> 00:43:40,400
vectors

00:43:38,160 --> 00:43:41,359
right now into your index for entire

00:43:40,400 --> 00:43:43,760
documents

00:43:41,359 --> 00:43:44,800
you just your compute and your disk will

00:43:43,760 --> 00:43:46,640
hate you

00:43:44,800 --> 00:43:48,319
and your ram will hate you for that so

00:43:46,640 --> 00:43:52,319
you you will have to find a way

00:43:48,319 --> 00:43:54,800
to get to get there um

00:43:52,319 --> 00:43:55,760
learn and fine-tune the models i think

00:43:54,800 --> 00:43:57,839
this is the most

00:43:55,760 --> 00:43:59,440
probably the most important thing when

00:43:57,839 --> 00:44:00,640
you are solving a problem for your

00:43:59,440 --> 00:44:04,960
domain

00:44:00,640 --> 00:44:08,240
um the use cases for your product

00:44:04,960 --> 00:44:10,400
will require you to

00:44:08,240 --> 00:44:11,359
figure out exactly what you want what

00:44:10,400 --> 00:44:14,960
your starting point

00:44:11,359 --> 00:44:15,760
will be and how you tune it for the task

00:44:14,960 --> 00:44:18,000
at hand

00:44:15,760 --> 00:44:19,680
so you may have a a bunch of a bunch of

00:44:18,000 --> 00:44:21,040
uk use cases that you want to use this

00:44:19,680 --> 00:44:22,079
technology for

00:44:21,040 --> 00:44:24,240
i mentioned some before like

00:44:22,079 --> 00:44:25,599
autocomplete spelling query writing you

00:44:24,240 --> 00:44:27,440
can you can do a whole bunch of things

00:44:25,599 --> 00:44:29,520
so so understand that

00:44:27,440 --> 00:44:30,560
these may all require different models

00:44:29,520 --> 00:44:32,079
and different

00:44:30,560 --> 00:44:35,280
architectures for your need and

00:44:32,079 --> 00:44:35,280
different fine-tuning tasks

00:44:35,680 --> 00:44:42,400
and yeah use use this as an additional

00:44:39,599 --> 00:44:43,359
features and as an additive thing for

00:44:42,400 --> 00:44:47,359
your experience

00:44:43,359 --> 00:44:49,599
and your ranking and your retrieval um

00:44:47,359 --> 00:44:50,960
it's it's gonna be it's going to be

00:44:49,599 --> 00:44:52,480
additive it's not going to be like i'm

00:44:50,960 --> 00:44:55,119
going to replace the whole thing

00:44:52,480 --> 00:44:55,839
right now with vector search uh it's

00:44:55,119 --> 00:44:59,119
it's another

00:44:55,839 --> 00:45:01,280
extremely powerful feature uh for search

00:44:59,119 --> 00:45:02,480
um and use what you know and have

00:45:01,280 --> 00:45:04,880
learned

00:45:02,480 --> 00:45:05,920
already and and combine it and play

00:45:04,880 --> 00:45:08,480
around with it and

00:45:05,920 --> 00:45:11,440
you know and see how it folds naturally

00:45:08,480 --> 00:45:14,400
into your stack and into your domain

00:45:11,440 --> 00:45:16,000
thanks max so i'm just going to jump to

00:45:14,400 --> 00:45:17,200
it one of the questions submitted by the

00:45:16,000 --> 00:45:19,760
audience here

00:45:17,200 --> 00:45:22,319
um we've got a question what about

00:45:19,760 --> 00:45:24,319
active learning to improve vector search

00:45:22,319 --> 00:45:27,359
meaning tagging the user inputs and then

00:45:24,319 --> 00:45:29,760
updating or filtering the vectors

00:45:27,359 --> 00:45:30,480
what do you think you know yeah it's a

00:45:29,760 --> 00:45:34,000
great question

00:45:30,480 --> 00:45:36,000
i think uh you can do that uh

00:45:34,000 --> 00:45:37,760
so there are like uh if you if you enter

00:45:36,000 --> 00:45:40,079
dance dance um

00:45:37,760 --> 00:45:41,760
retrieval methods then there i actually

00:45:40,079 --> 00:45:45,200
don't remember the method name

00:45:41,760 --> 00:45:48,400
uh but all everything is in the paper um

00:45:45,200 --> 00:45:51,520
so one method is that you can combine um

00:45:48,400 --> 00:45:53,920
the document with the queries that

00:45:51,520 --> 00:45:57,119
you know naturally match this this

00:45:53,920 --> 00:45:59,200
document and so you will

00:45:57,119 --> 00:46:01,119
bubble up the prominence of the of that

00:45:59,200 --> 00:46:02,880
document during search and so

00:46:01,119 --> 00:46:04,720
in principle i'm thinking why not you

00:46:02,880 --> 00:46:07,760
can apply an active learning

00:46:04,720 --> 00:46:10,800
uh you know approach here where

00:46:07,760 --> 00:46:14,000
you will identify the the relevant

00:46:10,800 --> 00:46:15,440
uh queries for a specific document you

00:46:14,000 --> 00:46:17,920
will need to build some system for that

00:46:15,440 --> 00:46:21,760
i guess you could use cupid i guess

00:46:17,920 --> 00:46:24,000
and so you would go and update the

00:46:21,760 --> 00:46:25,040
the document vector with those new

00:46:24,000 --> 00:46:28,160
queries

00:46:25,040 --> 00:46:28,960
and so next time around users are

00:46:28,160 --> 00:46:31,760
searching

00:46:28,960 --> 00:46:33,680
with the queries like this uh you will

00:46:31,760 --> 00:46:36,560
have those documents bubbling up

00:46:33,680 --> 00:46:37,119
um to the top right so in principle yes

00:46:36,560 --> 00:46:40,079
i think

00:46:37,119 --> 00:46:41,359
yes and you should actually in general i

00:46:40,079 --> 00:46:44,400
like the idea

00:46:41,359 --> 00:46:47,520
of uh you know seeing your search engine

00:46:44,400 --> 00:46:51,200
as an evolving model as an evolving

00:46:47,520 --> 00:46:54,319
organism where you should you should

00:46:51,200 --> 00:46:55,040
think creatively like what else can we

00:46:54,319 --> 00:46:57,280
do

00:46:55,040 --> 00:47:00,079
to actually establish this pipeline of

00:46:57,280 --> 00:47:03,520
um ideas and improvements because

00:47:00,079 --> 00:47:06,400
uh it like i've seen cases when

00:47:03,520 --> 00:47:08,480
you know let's say we apply a specific

00:47:06,400 --> 00:47:10,560
um

00:47:08,480 --> 00:47:11,920
vector space model like in principle

00:47:10,560 --> 00:47:14,960
bm25 right

00:47:11,920 --> 00:47:15,599
and then we just stop looking forward we

00:47:14,960 --> 00:47:17,440
just

00:47:15,599 --> 00:47:18,640
you know we just think okay everything

00:47:17,440 --> 00:47:21,119
is in the data

00:47:18,640 --> 00:47:22,079
but it's not true you like you will

00:47:21,119 --> 00:47:24,160
notice that

00:47:22,079 --> 00:47:26,000
in the production you will you will see

00:47:24,160 --> 00:47:28,319
decline in ctr

00:47:26,000 --> 00:47:29,520
or you will see decline like in what we

00:47:28,319 --> 00:47:31,119
call exposure

00:47:29,520 --> 00:47:33,119
which is probably not not like a common

00:47:31,119 --> 00:47:34,000
metric used but it's basically how often

00:47:33,119 --> 00:47:36,000
do we show

00:47:34,000 --> 00:47:37,520
the results from our search engine so if

00:47:36,000 --> 00:47:40,640
you see any decline there

00:47:37,520 --> 00:47:43,040
like take those queries and

00:47:40,640 --> 00:47:44,480
you know throw them into cupid or some

00:47:43,040 --> 00:47:47,359
other system where you can

00:47:44,480 --> 00:47:48,079
investigate them with magnifying glass

00:47:47,359 --> 00:47:50,480
and then

00:47:48,079 --> 00:47:52,160
looking at all the ways you can encode

00:47:50,480 --> 00:47:54,000
additional signal from those

00:47:52,160 --> 00:47:56,480
from those queries and documents into

00:47:54,000 --> 00:47:56,480
your model

00:47:58,000 --> 00:48:05,200
i hope that answers the question but

00:48:01,760 --> 00:48:08,240
yeah what do you think max

00:48:05,200 --> 00:48:11,040
i i totally agree

00:48:08,240 --> 00:48:12,240
um i i just have one very important

00:48:11,040 --> 00:48:14,400
point that i think you need to

00:48:12,240 --> 00:48:16,400
consider when doing active learning is

00:48:14,400 --> 00:48:19,599
you need to be very careful of bias

00:48:16,400 --> 00:48:21,680
um and thinking about who as

00:48:19,599 --> 00:48:23,119
as a model uh prompt has presented to

00:48:21,680 --> 00:48:24,400
you of whether it's good or bad and then

00:48:23,119 --> 00:48:26,640
you want to update the model

00:48:24,400 --> 00:48:28,240
based on your reaction it's very easy to

00:48:26,640 --> 00:48:29,680
just kind of quit very quickly go

00:48:28,240 --> 00:48:31,599
through it and forget

00:48:29,680 --> 00:48:33,680
that you are a subjective and biased

00:48:31,599 --> 00:48:35,119
individual um everybody is in their own

00:48:33,680 --> 00:48:38,559
way

00:48:35,119 --> 00:48:41,040
and if you are taking even uh

00:48:38,559 --> 00:48:42,079
crowdsourced data uh from this or or

00:48:41,040 --> 00:48:45,119
data from

00:48:42,079 --> 00:48:46,480
uh customers or or users of your product

00:48:45,119 --> 00:48:47,599
to do active learning there's there's

00:48:46,480 --> 00:48:49,520
gonna be bias there

00:48:47,599 --> 00:48:51,200
also so there are teams that are really

00:48:49,520 --> 00:48:52,960
good with this who are used to

00:48:51,200 --> 00:48:54,240
dealing with this with learning to rank

00:48:52,960 --> 00:48:56,720
um data sets

00:48:54,240 --> 00:48:57,520
um but if you're new to this and you

00:48:56,720 --> 00:49:00,000
know and

00:48:57,520 --> 00:49:03,359
you you're used to kind of capturing

00:49:00,000 --> 00:49:06,160
judgments at a small scale

00:49:03,359 --> 00:49:07,599
try to remember that you probably want

00:49:06,160 --> 00:49:10,880
to get more than one

00:49:07,599 --> 00:49:12,559
opinion on things and you want to

00:49:10,880 --> 00:49:14,559
understand

00:49:12,559 --> 00:49:16,000
consensus and disagreement and have

00:49:14,559 --> 00:49:19,760
discussions about them

00:49:16,000 --> 00:49:21,440
um instead of just you as one person

00:49:19,760 --> 00:49:22,960
like update model update model update

00:49:21,440 --> 00:49:24,640
model because it's just gonna

00:49:22,960 --> 00:49:27,280
you're gonna over fit to your own to

00:49:24,640 --> 00:49:30,720
your own uh desires and wishes

00:49:27,280 --> 00:49:34,319
um and that may drift uh from

00:49:30,720 --> 00:49:36,480
what uh what your users actually want

00:49:34,319 --> 00:49:38,640
maybe i also wanted to add and this is

00:49:36,480 --> 00:49:41,040
like a topic dear to my heart

00:49:38,640 --> 00:49:42,480
try to release more frequently because

00:49:41,040 --> 00:49:44,720
if you if you spend

00:49:42,480 --> 00:49:45,920
a bunch of time thinking about oh i have

00:49:44,720 --> 00:49:47,599
this cool idea

00:49:45,920 --> 00:49:49,520
you know i just need another couple of

00:49:47,599 --> 00:49:51,119
weeks to to polish it

00:49:49,520 --> 00:49:53,200
by the time you release it you know the

00:49:51,119 --> 00:49:54,160
season might be a way and you just will

00:49:53,200 --> 00:49:56,880
not nail it

00:49:54,160 --> 00:49:58,720
and we see some interesting use case in

00:49:56,880 --> 00:50:01,200
our search engine right now when

00:49:58,720 --> 00:50:02,640
you know ctr all of a sudden went down

00:50:01,200 --> 00:50:05,119
for a specific language

00:50:02,640 --> 00:50:07,119
but we we've done no release and we are

00:50:05,119 --> 00:50:07,680
like just figuring out what's going on

00:50:07,119 --> 00:50:09,760
here

00:50:07,680 --> 00:50:12,160
right so when you start work from that

00:50:09,760 --> 00:50:12,640
angle like and go backwards to your

00:50:12,160 --> 00:50:15,280
model

00:50:12,640 --> 00:50:16,960
like there is like a long path there and

00:50:15,280 --> 00:50:19,680
and you can generate a bunch of ideas

00:50:16,960 --> 00:50:19,680
what you can try

00:50:20,160 --> 00:50:24,800
great thank you okay so we've got a

00:50:22,720 --> 00:50:26,559
doozy of a question coming up next we're

00:50:24,800 --> 00:50:28,720
from the submitted by the uh the

00:50:26,559 --> 00:50:29,200
audience and i'm wondering who this are

00:50:28,720 --> 00:50:32,960
that this

00:50:29,200 --> 00:50:33,520
is um so i'll read this out it's a long

00:50:32,960 --> 00:50:35,040
one

00:50:33,520 --> 00:50:36,960
in order to make vector search

00:50:35,040 --> 00:50:38,960
performance an approximate nearest

00:50:36,960 --> 00:50:43,040
neighbor approach is typically applied

00:50:38,960 --> 00:50:44,720
so leucine has hmsw says vaspa

00:50:43,040 --> 00:50:46,480
given that these a n techniques

00:50:44,720 --> 00:50:48,160
essentially partition the vector space

00:50:46,480 --> 00:50:50,800
into a smaller neighborhood

00:50:48,160 --> 00:50:51,200
it seems natural to shard large indexes

00:50:50,800 --> 00:50:53,599
by

00:50:51,200 --> 00:50:55,760
a m neighborhood so that queries could

00:50:53,599 --> 00:50:57,040
be routed to specific neighborhoods on

00:50:55,760 --> 00:50:58,800
specific nodes

00:50:57,040 --> 00:51:00,240
and then we can obviously use for

00:50:58,800 --> 00:51:01,760
performance neighborhoods with more

00:51:00,240 --> 00:51:02,880
queries could have more replicas handle

00:51:01,760 --> 00:51:04,720
nodes

00:51:02,880 --> 00:51:06,480
this will prevent the entire index from

00:51:04,720 --> 00:51:07,440
being needed to be searched in every

00:51:06,480 --> 00:51:08,720
query

00:51:07,440 --> 00:51:10,720
could this be useful for enormous

00:51:08,720 --> 00:51:11,599
indexes such as for an open web search

00:51:10,720 --> 00:51:12,720
engine

00:51:11,599 --> 00:51:14,319
and what are your thoughts and how

00:51:12,720 --> 00:51:15,839
feasible this would be to implement with

00:51:14,319 --> 00:51:18,319
solar vesper elastic

00:51:15,839 --> 00:51:19,359
et cetera using hmsw or similar

00:51:18,319 --> 00:51:21,920
algorithms

00:51:19,359 --> 00:51:24,400
so that's a bit of a mouthful um who

00:51:21,920 --> 00:51:27,520
wants to take that one first

00:51:24,400 --> 00:51:28,319
uh maybe i'll maybe i'll take a a stab

00:51:27,520 --> 00:51:31,839
at it so i

00:51:28,319 --> 00:51:35,280
i recently reread what won uh one

00:51:31,839 --> 00:51:38,880
hnsw paper um

00:51:35,280 --> 00:51:40,160
uh last week uh and i

00:51:38,880 --> 00:51:42,079
because i really want to understand how

00:51:40,160 --> 00:51:43,359
this thing works and it's one of those

00:51:42,079 --> 00:51:45,680
things where it's

00:51:43,359 --> 00:51:46,480
casually offhand mentioned in the paper

00:51:45,680 --> 00:51:49,520
of

00:51:46,480 --> 00:51:51,359
well this thing is you can shard this

00:51:49,520 --> 00:51:53,440
um i don't think using those exact words

00:51:51,359 --> 00:51:54,240
but due to the nature of navigable small

00:51:53,440 --> 00:51:56,480
world

00:51:54,240 --> 00:51:57,520
and and neighborhoods you can

00:51:56,480 --> 00:52:00,400
effectively

00:51:57,520 --> 00:52:01,760
uh shard and split this out uh and and

00:52:00,400 --> 00:52:03,760
then it'll it'll work

00:52:01,760 --> 00:52:05,760
like that's how it's kind of presented

00:52:03,760 --> 00:52:07,200
in the paper um but there's no like

00:52:05,760 --> 00:52:10,559
implementation detail

00:52:07,200 --> 00:52:12,720
of course uh so i think that

00:52:10,559 --> 00:52:14,000
you definitely are gonna have to do this

00:52:12,720 --> 00:52:15,599
um it is

00:52:14,000 --> 00:52:17,440
it is possible i don't know the

00:52:15,599 --> 00:52:19,520
techniques to do it but

00:52:17,440 --> 00:52:20,720
and i don't know how vespa works i don't

00:52:19,520 --> 00:52:24,559
know how uh

00:52:20,720 --> 00:52:26,240
because lucine um lucina has asian sw

00:52:24,559 --> 00:52:27,760
but solar and elastic are going to be

00:52:26,240 --> 00:52:29,040
responsible for the sharding of the

00:52:27,760 --> 00:52:32,319
lucian indices

00:52:29,040 --> 00:52:33,040
so i think that that's probably a huge

00:52:32,319 --> 00:52:35,520
barrier

00:52:33,040 --> 00:52:37,280
to getting this stuff into solar and

00:52:35,520 --> 00:52:39,280
elastic i don't know if josh is working

00:52:37,280 --> 00:52:42,319
on this right now for elastic

00:52:39,280 --> 00:52:44,400
um josh and steam or

00:52:42,319 --> 00:52:46,240
i think that joe christian might have

00:52:44,400 --> 00:52:47,119
some comments here about how it works in

00:52:46,240 --> 00:52:50,559
vespa

00:52:47,119 --> 00:52:52,559
um but it should be possible and i think

00:52:50,559 --> 00:52:54,800
it's going to be absolutely necessary

00:52:52,559 --> 00:52:56,800
uh and i'm hoping that you know i'm just

00:52:54,800 --> 00:53:00,640
kind of sitting around waiting for

00:52:56,800 --> 00:53:02,160
uh lucene 9 to shift into the last

00:53:00,640 --> 00:53:03,520
into elastic and solar and all this

00:53:02,160 --> 00:53:05,040
stuff to magically appear i know that's

00:53:03,520 --> 00:53:06,880
not gonna happen it requires

00:53:05,040 --> 00:53:08,079
a lot of hard work from a lot of

00:53:06,880 --> 00:53:10,400
hard-working people

00:53:08,079 --> 00:53:12,240
um but i i think this is absolutely

00:53:10,400 --> 00:53:14,319
necessary

00:53:12,240 --> 00:53:16,960
okay what do you think dima you're

00:53:14,319 --> 00:53:20,839
working on a big search engine

00:53:16,960 --> 00:53:22,000
yes uh actually think about tf idf and

00:53:20,839 --> 00:53:25,760
bm25

00:53:22,000 --> 00:53:28,160
when you have let's say 100 shards

00:53:25,760 --> 00:53:30,160
and your query comes in you have some

00:53:28,160 --> 00:53:32,319
sort of router component which will

00:53:30,160 --> 00:53:34,559
forward it to independent charts

00:53:32,319 --> 00:53:35,359
it will it will search for the document

00:53:34,559 --> 00:53:38,319
score them

00:53:35,359 --> 00:53:40,000
and then return you let's say top and

00:53:38,319 --> 00:53:44,000
from each chart

00:53:40,000 --> 00:53:46,160
ah these uh you know scores compatible

00:53:44,000 --> 00:53:47,599
i have a strong conviction that they are

00:53:46,160 --> 00:53:50,079
not why because

00:53:47,599 --> 00:53:50,640
every shard will have their own like

00:53:50,079 --> 00:53:54,720
term

00:53:50,640 --> 00:53:56,800
level statistics um document length

00:53:54,720 --> 00:53:58,480
which is like local to that chart and

00:53:56,800 --> 00:53:59,359
there are some solutions which you can

00:53:58,480 --> 00:54:01,520
for instance

00:53:59,359 --> 00:54:02,559
you know where you can build a global

00:54:01,520 --> 00:54:06,319
idea

00:54:02,559 --> 00:54:09,040
right so um idf which will be

00:54:06,319 --> 00:54:11,119
like globally updatable like uh

00:54:09,040 --> 00:54:13,520
distributed cache whatever and

00:54:11,119 --> 00:54:15,440
probably you will run into some race

00:54:13,520 --> 00:54:17,680
conditions there i'm pretty sure

00:54:15,440 --> 00:54:20,160
but but there are ways to attack it

00:54:17,680 --> 00:54:20,800
right so i think the same exactly same

00:54:20,160 --> 00:54:24,000
problem

00:54:20,800 --> 00:54:27,200
exists in in our traditional

00:54:24,000 --> 00:54:29,200
you know lovely bm 25 search now

00:54:27,200 --> 00:54:30,800
if you enter into the graph search all

00:54:29,200 --> 00:54:33,920
into like um

00:54:30,800 --> 00:54:34,640
uh clustered search if you pick that

00:54:33,920 --> 00:54:38,000
paper

00:54:34,640 --> 00:54:39,920
the hierarchical small world navigable

00:54:38,000 --> 00:54:42,079
small world graph it's so mouthful that

00:54:39,920 --> 00:54:43,520
i keep keep reminding myself what's the

00:54:42,079 --> 00:54:46,400
order of letters there

00:54:43,520 --> 00:54:47,839
but that method actually explicitly

00:54:46,400 --> 00:54:51,359
states in the paper

00:54:47,839 --> 00:54:54,400
that it's not compatible with the uh

00:54:51,359 --> 00:54:57,280
distributed search and they do mention

00:54:54,400 --> 00:54:58,880
you know like this famous mathematicians

00:54:57,280 --> 00:55:02,079
from 19th century

00:54:58,880 --> 00:55:04,559
that proof is obvious and then they die

00:55:02,079 --> 00:55:06,240
and then like 100 years after somebody

00:55:04,559 --> 00:55:08,400
tries to prove that that

00:55:06,240 --> 00:55:09,359
theorem and then they you know die

00:55:08,400 --> 00:55:13,119
almost as well

00:55:09,359 --> 00:55:13,599
so i think and then they say actually

00:55:13,119 --> 00:55:15,520
that

00:55:13,599 --> 00:55:17,680
the previous incarnation of that

00:55:15,520 --> 00:55:20,400
algorithm when you remove the age

00:55:17,680 --> 00:55:21,359
so it's not hierarchical it's just a

00:55:20,400 --> 00:55:25,119
navigable

00:55:21,359 --> 00:55:27,040
small world graph that's a perfect match

00:55:25,119 --> 00:55:27,920
for the distributed search engine that's

00:55:27,040 --> 00:55:29,680
what they say

00:55:27,920 --> 00:55:31,200
but again you need to go and check it

00:55:29,680 --> 00:55:32,880
for yourself i don't think that

00:55:31,200 --> 00:55:34,400
you should easily trust everything

00:55:32,880 --> 00:55:37,599
that's written in papers

00:55:34,400 --> 00:55:39,119
you know go and try it for yourself yeah

00:55:37,599 --> 00:55:40,240
there were a lot of typos in that paper

00:55:39,119 --> 00:55:43,599
so that should be

00:55:40,240 --> 00:55:45,680
yeah so what i'm taking away from this

00:55:43,599 --> 00:55:47,520
is people in the street don't always

00:55:45,680 --> 00:55:50,880
trust people in academia

00:55:47,520 --> 00:55:52,559
and also that some of these these areas

00:55:50,880 --> 00:55:54,319
of mass are effectively cursed

00:55:52,559 --> 00:55:55,680
and you should navigate them with a

00:55:54,319 --> 00:55:57,359
great deal of caution

00:55:55,680 --> 00:56:00,720
it seems that people die if you get too

00:55:57,359 --> 00:56:03,359
close i'm a bit worried by this

00:56:00,720 --> 00:56:04,400
cursed mathematics i love that idea okay

00:56:03,359 --> 00:56:06,400
well we've got um

00:56:04,400 --> 00:56:08,079
another few minutes we're actually going

00:56:06,400 --> 00:56:10,559
to uh run on a little

00:56:08,079 --> 00:56:11,200
uh later than our published end date end

00:56:10,559 --> 00:56:12,720
time

00:56:11,200 --> 00:56:14,240
today because we're the last session of

00:56:12,720 --> 00:56:15,520
the day so we're not going to be jumping

00:56:14,240 --> 00:56:17,040
into the breakout room

00:56:15,520 --> 00:56:18,079
you're welcome to stay with us we'd love

00:56:17,040 --> 00:56:18,640
you to stay with us we're gonna try and

00:56:18,079 --> 00:56:20,079
get through

00:56:18,640 --> 00:56:21,680
a few more questions maybe for an extra

00:56:20,079 --> 00:56:23,440
10 minutes at the end of this session

00:56:21,680 --> 00:56:25,040
but i must just for completeness mention

00:56:23,440 --> 00:56:27,359
that at the same time

00:56:25,040 --> 00:56:28,720
we have the workshop uh on digital and

00:56:27,359 --> 00:56:31,359
ethics running in

00:56:28,720 --> 00:56:32,319
the machine house and of course there's

00:56:31,359 --> 00:56:35,040
a spatial lounge

00:56:32,319 --> 00:56:36,319
for um socializing outside the sessions

00:56:35,040 --> 00:56:38,640
but if you're gonna stay with us we've

00:56:36,319 --> 00:56:41,839
got some more questions to get through

00:56:38,640 --> 00:56:44,240
so let's see what else we have um

00:56:41,839 --> 00:56:45,599
let's have a look we've got well there's

00:56:44,240 --> 00:56:47,280
a quick one here maybe you can answer

00:56:45,599 --> 00:56:48,960
quite quickly how could gpus be

00:56:47,280 --> 00:56:50,160
leveraged to improve the vector scoring

00:56:48,960 --> 00:56:51,680
calculations

00:56:50,160 --> 00:56:53,040
and i'm going to ask that to dima

00:56:51,680 --> 00:56:54,400
because i believe you looked at this is

00:56:53,040 --> 00:56:56,400
the gsi

00:56:54,400 --> 00:56:58,079
um application you looked at those using

00:56:56,400 --> 00:57:00,720
a gpu isn't it

00:56:58,079 --> 00:57:02,000
yeah gsi is using so they've built their

00:57:00,720 --> 00:57:05,040
own custom

00:57:02,000 --> 00:57:08,079
apu board so it's like associative

00:57:05,040 --> 00:57:09,520
processing unit so it's not cpu it's not

00:57:08,079 --> 00:57:11,760
gpu it's like

00:57:09,520 --> 00:57:12,960
something they're custom you know

00:57:11,760 --> 00:57:16,400
implementation

00:57:12,960 --> 00:57:17,280
and um it's it's particularly friendly

00:57:16,400 --> 00:57:20,799
with

00:57:17,280 --> 00:57:21,599
matrix you know multiplication and

00:57:20,799 --> 00:57:26,160
whatnot

00:57:21,599 --> 00:57:28,160
so so basically um

00:57:26,160 --> 00:57:30,640
the the the method i think i think they

00:57:28,160 --> 00:57:32,880
have a bunch of like um

00:57:30,640 --> 00:57:34,960
uh weight there with the ram so they use

00:57:32,880 --> 00:57:36,400
a lot of ram and i'm not sure exactly

00:57:34,960 --> 00:57:38,160
how this board is structured but

00:57:36,400 --> 00:57:40,559
basically they can even ship that board

00:57:38,160 --> 00:57:42,079
to you and you can try it um

00:57:40,559 --> 00:57:44,000
but basically that was the fastest

00:57:42,079 --> 00:57:45,760
method that i have seen and and i

00:57:44,000 --> 00:57:49,200
benchmarked you know if you

00:57:45,760 --> 00:57:52,480
look into my blog post i think

00:57:49,200 --> 00:57:53,440
the scale of difference was like 70

00:57:52,480 --> 00:57:56,799
milliseconds

00:57:53,440 --> 00:57:59,119
versus like 1.5 seconds for the vanilla

00:57:56,799 --> 00:58:01,040
elastic search uh vector search

00:57:59,119 --> 00:58:02,400
so that's like a huge huge difference

00:58:01,040 --> 00:58:05,440
but then again

00:58:02,400 --> 00:58:07,280
in order in order to to use that method

00:58:05,440 --> 00:58:08,960
i had to

00:58:07,280 --> 00:58:11,119
and and i'm sure the team is going to

00:58:08,960 --> 00:58:11,680
iterate on this but i had to prepare

00:58:11,119 --> 00:58:14,319
like

00:58:11,680 --> 00:58:16,160
a numpy array that i would um and it

00:58:14,319 --> 00:58:19,760
took me like four days to

00:58:16,160 --> 00:58:21,680
to embed um one million documents

00:58:19,760 --> 00:58:23,920
in into that space and then ship that

00:58:21,680 --> 00:58:26,079
array and so they uploaded that

00:58:23,920 --> 00:58:28,000
it didn't take too long to index and

00:58:26,079 --> 00:58:30,799
then it was super super fast

00:58:28,000 --> 00:58:32,240
um but then again this is kind of like a

00:58:30,799 --> 00:58:35,599
hybrid approach

00:58:32,240 --> 00:58:37,280
to my sense because you can you can run

00:58:35,599 --> 00:58:40,640
it on premise you'll have to pay

00:58:37,280 --> 00:58:42,799
right uh but but then can you actually

00:58:40,640 --> 00:58:43,760
emulate something like this without an

00:58:42,799 --> 00:58:46,559
apu

00:58:43,760 --> 00:58:48,799
uh and then for the gpus i think the the

00:58:46,559 --> 00:58:49,359
beer paper as well uh mentions something

00:58:48,799 --> 00:58:50,960
if

00:58:49,359 --> 00:58:52,480
i remember correctly that you can

00:58:50,960 --> 00:58:54,880
actually use gpus to

00:58:52,480 --> 00:58:55,760
to speed up uh your search engine for

00:58:54,880 --> 00:58:59,040
the vector

00:58:55,760 --> 00:59:00,640
yeah there was a

00:58:59,040 --> 00:59:03,040
it's funny that this question was asked

00:59:00,640 --> 00:59:06,640
because i i haven't tried it yet

00:59:03,040 --> 00:59:08,079
but two days ago i stumbled across a

00:59:06,640 --> 00:59:11,200
repo in github

00:59:08,079 --> 00:59:14,000
uh called cu hnsw

00:59:11,200 --> 00:59:15,119
which has been you know it looks like

00:59:14,000 --> 00:59:19,760
it's a couple months of

00:59:15,119 --> 00:59:21,119
coding that claims to use cuda with hmsw

00:59:19,760 --> 00:59:23,200
but again i haven't installed it or

00:59:21,119 --> 00:59:26,079
played with it uh

00:59:23,200 --> 00:59:28,400
but it's something to look into if you

00:59:26,079 --> 00:59:30,839
want to just tinker

00:59:28,400 --> 00:59:32,640
and you have a nvidia card that's

00:59:30,839 --> 00:59:34,400
capable

00:59:32,640 --> 00:59:36,799
right well then drop the link into the

00:59:34,400 --> 00:59:38,000
uh into the chat if you have it

00:59:36,799 --> 00:59:39,760
i don't have access to the chat i'll

00:59:38,000 --> 00:59:41,280
drop it into the into our chat charlie

00:59:39,760 --> 00:59:43,920
and then you can relay it into uh

00:59:41,280 --> 00:59:44,559
there we go through the magic of copy

00:59:43,920 --> 00:59:47,119
and paste

00:59:44,559 --> 00:59:48,559
i shall put it in for everyone no no

00:59:47,119 --> 00:59:50,079
affiliation i just found this thing and

00:59:48,559 --> 00:59:50,480
i started to say i'm gonna look at this

00:59:50,079 --> 00:59:52,160
later

00:59:50,480 --> 00:59:53,680
which we all know when get upstars that

00:59:52,160 --> 00:59:56,319
never happens um

00:59:53,680 --> 00:59:57,280
but but yeah if you're really interested

00:59:56,319 --> 00:59:58,640
you can go

00:59:57,280 --> 01:00:00,720
try to install it and see if you can get

00:59:58,640 --> 01:00:03,359
stuff indexed okay

01:00:00,720 --> 01:00:04,079
so um we've got a a quick question here

01:00:03,359 --> 01:00:07,359
i'm going to ask

01:00:04,079 --> 01:00:07,359
about um

01:00:09,040 --> 01:00:13,200
actually uh i'm not sure this is vector

01:00:12,160 --> 01:00:15,599
search related

01:00:13,200 --> 01:00:17,280
um somebody is asked about seasonality

01:00:15,599 --> 01:00:20,799
and fine tuning how can we

01:00:17,280 --> 01:00:22,400
infer when to update uh maybe a small

01:00:20,799 --> 01:00:23,920
decrease in click metrics would be

01:00:22,400 --> 01:00:24,880
enough or is there a better way for this

01:00:23,920 --> 01:00:26,880
kind of problem

01:00:24,880 --> 01:00:28,160
uh do you wanna ask does that apply to

01:00:26,880 --> 01:00:30,079
vector search is that

01:00:28,160 --> 01:00:32,000
referring back to something earlier

01:00:30,079 --> 01:00:35,440
actually i think it applies to

01:00:32,000 --> 01:00:38,480
um embedding at large um

01:00:35,440 --> 01:00:40,640
i i will try to give you that paper but

01:00:38,480 --> 01:00:42,640
i don't remember from top of my head

01:00:40,640 --> 01:00:44,000
basically the paper was dealing with

01:00:42,640 --> 01:00:47,520
seasonality change

01:00:44,000 --> 01:00:48,720
by you know um basically you can compute

01:00:47,520 --> 01:00:50,799
like a

01:00:48,720 --> 01:00:52,880
a stable date range with which you can

01:00:50,799 --> 01:00:54,880
tag the terms and then you embed them

01:00:52,880 --> 01:00:56,480
and so the embedding will also have the

01:00:54,880 --> 01:00:59,359
term as well as the date

01:00:56,480 --> 01:01:01,040
the date range right and and then you

01:00:59,359 --> 01:01:02,720
know when you search for instance you

01:01:01,040 --> 01:01:04,720
can also account for like

01:01:02,720 --> 01:01:05,839
okay what what season i am in you can

01:01:04,720 --> 01:01:07,520
definitely know that

01:01:05,839 --> 01:01:09,520
which which date range you fall in and

01:01:07,520 --> 01:01:12,160
then you attach that to your term

01:01:09,520 --> 01:01:13,920
it almost sounds like payload payload

01:01:12,160 --> 01:01:15,760
based search if you know what i mean

01:01:13,920 --> 01:01:17,920
right so let's say you have a term and

01:01:15,760 --> 01:01:18,240
then you can add some characteristics to

01:01:17,920 --> 01:01:20,559
it

01:01:18,240 --> 01:01:21,839
and then during the search you can you

01:01:20,559 --> 01:01:24,559
can pre-filter

01:01:21,839 --> 01:01:25,040
or like filter the terms that fall into

01:01:24,559 --> 01:01:29,280
the

01:01:25,040 --> 01:01:32,000
the specific um category set let's say

01:01:29,280 --> 01:01:33,520
uh part of speech tag or something else

01:01:32,000 --> 01:01:35,359
that you might encode there

01:01:33,520 --> 01:01:36,799
so something similar so that paper is

01:01:35,359 --> 01:01:38,799
really interesting

01:01:36,799 --> 01:01:40,640
i don't know if they have a practical

01:01:38,799 --> 01:01:41,599
implementation i think the code is on

01:01:40,640 --> 01:01:44,640
github

01:01:41,599 --> 01:01:46,880
so if you're interested i i will try to

01:01:44,640 --> 01:01:49,119
to find that paper and post it as well

01:01:46,880 --> 01:01:49,119
yeah

01:01:49,359 --> 01:01:56,480
okay um

01:01:52,559 --> 01:01:57,599
so uh let's go on to our next question

01:01:56,480 --> 01:02:00,880
from the audience here

01:01:57,599 --> 01:02:01,680
um so we talked a bit about a n coming

01:02:00,880 --> 01:02:05,119
into

01:02:01,680 --> 01:02:06,240
uh lucy nine and this is an interesting

01:02:05,119 --> 01:02:08,480
question will this be an

01:02:06,240 --> 01:02:10,880
easy to use feature when it's exposed in

01:02:08,480 --> 01:02:12,559
elastic search and solar

01:02:10,880 --> 01:02:14,480
do you think it'll be easy to use for

01:02:12,559 --> 01:02:17,280
people once they can access it that way

01:02:14,480 --> 01:02:17,280
max what do you think

01:02:17,599 --> 01:02:24,079
um i honestly think you know

01:02:20,720 --> 01:02:27,599
the both of the the the elastic team

01:02:24,079 --> 01:02:28,319
and the solar community uh write amazing

01:02:27,599 --> 01:02:31,359
software

01:02:28,319 --> 01:02:34,160
right and i think that

01:02:31,359 --> 01:02:35,839
it will definitely be usable um and it

01:02:34,160 --> 01:02:39,119
should be straightforward to use

01:02:35,839 --> 01:02:42,480
because at the heart of it the stuff

01:02:39,119 --> 01:02:44,319
from from a user perspective uh

01:02:42,480 --> 01:02:46,480
isn't really that complicated you know

01:02:44,319 --> 01:02:47,119
you can go and you can install nms live

01:02:46,480 --> 01:02:49,359
right now

01:02:47,119 --> 01:02:50,960
in index stuff in python and like three

01:02:49,359 --> 01:02:52,240
lines of code and then you can query it

01:02:50,960 --> 01:02:53,119
in like a couple lines of code i think

01:02:52,240 --> 01:02:55,599
the hard part

01:02:53,119 --> 01:02:57,280
really is getting the vectors and and

01:02:55,599 --> 01:03:00,319
understanding what you're matching on

01:02:57,280 --> 01:03:03,760
um so i think that once once this is

01:03:00,319 --> 01:03:05,839
available uh in solar inelastic

01:03:03,760 --> 01:03:07,039
um i imagine that it'll be pretty

01:03:05,839 --> 01:03:08,400
straightforward it'll probably just be

01:03:07,039 --> 01:03:09,119
like you know you're gonna have a dense

01:03:08,400 --> 01:03:10,799
vector field

01:03:09,119 --> 01:03:12,240
and you're gonna specify the analyzer

01:03:10,799 --> 01:03:14,240
and the similarity function

01:03:12,240 --> 01:03:15,680
and you'll be able to you'll be able to

01:03:14,240 --> 01:03:18,400
query it

01:03:15,680 --> 01:03:19,359
i don't see it being much more difficult

01:03:18,400 --> 01:03:21,599
than that i think the

01:03:19,359 --> 01:03:23,119
the hard part is the hard stuff

01:03:21,599 --> 01:03:24,640
certainly rests on the shoulders of the

01:03:23,119 --> 01:03:27,280
implementation teams

01:03:24,640 --> 01:03:28,240
at elasticsearch and and in the solar

01:03:27,280 --> 01:03:30,000
community

01:03:28,240 --> 01:03:31,599
who have to think about all the crazy

01:03:30,000 --> 01:03:34,400
stuff like sharding and

01:03:31,599 --> 01:03:34,720
performance and memory and heap and all

01:03:34,400 --> 01:03:38,160
that

01:03:34,720 --> 01:03:38,960
crazy stuff that you know users of the

01:03:38,160 --> 01:03:40,319
tools don't

01:03:38,960 --> 01:03:42,160
necessarily have to worry about right

01:03:40,319 --> 01:03:45,599
away um but that's something that

01:03:42,160 --> 01:03:48,000
is gonna also fold into

01:03:45,599 --> 01:03:48,960
your operations in production of like

01:03:48,000 --> 01:03:51,680
well

01:03:48,960 --> 01:03:53,440
how much memory do i give the jvm if i'm

01:03:51,680 --> 01:03:56,000
using dense vector search

01:03:53,440 --> 01:03:58,400
um how how should i what's my sharing

01:03:56,000 --> 01:04:02,160
strategy going to look like uh

01:03:58,400 --> 01:04:04,720
is this going to impact you know my uh

01:04:02,160 --> 01:04:05,920
my high availability and disaster

01:04:04,720 --> 01:04:07,440
recovery strategies

01:04:05,920 --> 01:04:08,960
you know is it going to be is it going

01:04:07,440 --> 01:04:11,119
to make my index huge

01:04:08,960 --> 01:04:12,079
and my memory really big so you know i'm

01:04:11,119 --> 01:04:13,599
going to have to

01:04:12,079 --> 01:04:15,119
really not worry about my budget i think

01:04:13,599 --> 01:04:16,319
those are probably product level

01:04:15,119 --> 01:04:17,039
questions that are going to come into

01:04:16,319 --> 01:04:19,760
play

01:04:17,039 --> 01:04:21,200
and we'll see when we can actually

01:04:19,760 --> 01:04:23,760
benchmark

01:04:21,200 --> 01:04:25,200
when this technology is available to us

01:04:23,760 --> 01:04:29,039
in these engines and we can start

01:04:25,200 --> 01:04:29,039
indexing stuff and seeing how to use it

01:04:29,280 --> 01:04:32,319
what do you think timo i mean you've

01:04:30,559 --> 01:04:35,200
tried these things in your blog posts

01:04:32,319 --> 01:04:35,839
uh series uh do you think once once it's

01:04:35,200 --> 01:04:37,200
uh

01:04:35,839 --> 01:04:40,559
it's going to be easy to use from a

01:04:37,200 --> 01:04:43,200
practical sense um i like

01:04:40,559 --> 01:04:45,440
the implementation when it stays inside

01:04:43,200 --> 01:04:48,000
the gvm if you're on gvm

01:04:45,440 --> 01:04:50,000
because if you go off here what what

01:04:48,000 --> 01:04:50,480
will happen is that it's so hard to

01:04:50,000 --> 01:04:52,559
measure

01:04:50,480 --> 01:04:54,559
like how much memory you should give it

01:04:52,559 --> 01:04:55,599
and and usually these algorithms are

01:04:54,559 --> 01:04:59,520
super greedy

01:04:55,599 --> 01:05:02,079
actually for your information h and sw

01:04:59,520 --> 01:05:04,000
algorithm is very greedy on ram

01:05:02,079 --> 01:05:06,000
you do have some hyper parameters that

01:05:04,000 --> 01:05:08,400
you can tune and kind of lower the

01:05:06,000 --> 01:05:09,039
the ram consumption at the expense of

01:05:08,400 --> 01:05:12,480
like

01:05:09,039 --> 01:05:14,480
uh the quality of the index um

01:05:12,480 --> 01:05:16,000
so that's the indexing trend trade-off

01:05:14,480 --> 01:05:17,760
and then you have the search trade-off

01:05:16,000 --> 01:05:19,200
where you can also alter some hyper

01:05:17,760 --> 01:05:21,359
parameters there

01:05:19,200 --> 01:05:22,480
so but but having said that i still like

01:05:21,359 --> 01:05:25,119
the idea of let's say

01:05:22,480 --> 01:05:27,119
if i'm on jvm give me every tool that's

01:05:25,119 --> 01:05:29,119
on jvm i don't want to go off hip

01:05:27,119 --> 01:05:30,319
even though it sounds sexy to go of

01:05:29,119 --> 01:05:32,559
heave but

01:05:30,319 --> 01:05:34,400
i don't think it's it's super practical

01:05:32,559 --> 01:05:36,319
and again maybe i will be proven wrong

01:05:34,400 --> 01:05:38,160
in some time but for now i i would

01:05:36,319 --> 01:05:39,680
choose this approach versus you know

01:05:38,160 --> 01:05:41,839
let's say open distro

01:05:39,680 --> 01:05:44,079
which offers you off-heap implementation

01:05:41,839 --> 01:05:45,760
of hmsw because i've run

01:05:44,079 --> 01:05:48,400
into a number of issues i don't want to

01:05:45,760 --> 01:05:50,480
say that i i'm like um

01:05:48,400 --> 01:05:51,520
dissatisfied with open distro open

01:05:50,480 --> 01:05:54,319
digital is a nice

01:05:51,520 --> 01:05:55,520
you know great way of you know solving a

01:05:54,319 --> 01:05:58,079
bunch of issues

01:05:55,520 --> 01:05:59,119
uh and also like scaling your system and

01:05:58,079 --> 01:06:01,039
also elastic

01:05:59,119 --> 01:06:02,799
itself elasticsearch you know the

01:06:01,039 --> 01:06:05,520
vanilla one doesn't have

01:06:02,799 --> 01:06:06,880
uh any any uh you know algorithm

01:06:05,520 --> 01:06:09,920
implemented yet

01:06:06,880 --> 01:06:12,559
um but again um

01:06:09,920 --> 01:06:14,559
i just well maybe it's just tough luck

01:06:12,559 --> 01:06:16,720
but i wasn't able to index one million

01:06:14,559 --> 01:06:17,760
vectors with open distro it just it just

01:06:16,720 --> 01:06:19,760
crashed on me

01:06:17,760 --> 01:06:21,680
really really badly and i spent multiple

01:06:19,760 --> 01:06:23,760
days figuring out what's going on

01:06:21,680 --> 01:06:25,119
and maybe i just need to give it like a

01:06:23,760 --> 01:06:27,520
really large machine

01:06:25,119 --> 01:06:28,799
and then just so like throw money at the

01:06:27,520 --> 01:06:33,599
problem right

01:06:28,799 --> 01:06:35,760
which i don't want to do so um

01:06:33,599 --> 01:06:37,440
another thing uh the practical

01:06:35,760 --> 01:06:38,559
perspective and i think max mentioned

01:06:37,440 --> 01:06:40,319
that

01:06:38,559 --> 01:06:42,480
when you will index you know when you

01:06:40,319 --> 01:06:45,200
compete in beddings don't choose

01:06:42,480 --> 01:06:47,200
uh high dimensionality because it's it's

01:06:45,200 --> 01:06:50,880
so it's so appealing to choose like

01:06:47,200 --> 01:06:53,920
you know 768 dimensions vanilla you know

01:06:50,880 --> 01:06:56,480
uncased vert model and hope for the best

01:06:53,920 --> 01:06:58,880
the problem is that the index size will

01:06:56,480 --> 01:06:59,760
be super huge if you look at the bare

01:06:58,880 --> 01:07:04,319
paper

01:06:59,760 --> 01:07:05,039
and you compare the uh bm25 to one of

01:07:04,319 --> 01:07:08,559
the dense

01:07:05,039 --> 01:07:12,000
uh dense vectors uh that dance

01:07:08,559 --> 01:07:14,000
model the difference was yeah it's here

01:07:12,000 --> 01:07:15,119
i made it i made a note the difference

01:07:14,000 --> 01:07:18,400
is that

01:07:15,119 --> 01:07:21,520
uh the colbert model is like

01:07:18,400 --> 01:07:24,640
900 gigabytes versus

01:07:21,520 --> 01:07:26,480
18 gigabytes for bm25

01:07:24,640 --> 01:07:28,319
that's like huge difference like in

01:07:26,480 --> 01:07:29,440
terms of cost in terms of memory in

01:07:28,319 --> 01:07:32,319
terms of retrieval

01:07:29,440 --> 01:07:34,559
and remember listen like it tries its

01:07:32,319 --> 01:07:37,760
best to cache the fields

01:07:34,559 --> 01:07:40,079
but like will it be working okay for

01:07:37,760 --> 01:07:43,039
super large segments and super large

01:07:40,079 --> 01:07:45,920
dictionaries probably not so like

01:07:43,039 --> 01:07:45,920
be careful there

01:07:47,920 --> 01:07:51,760
yes yes well you can always uh solve

01:07:50,640 --> 01:07:55,200
problems with

01:07:51,760 --> 01:07:56,960
more memory obviously um

01:07:55,200 --> 01:07:58,480
so uh we're coming to the end of our

01:07:56,960 --> 01:08:01,359
time slot here and

01:07:58,480 --> 01:08:03,039
uh i want to just just round us off here

01:08:01,359 --> 01:08:04,640
um i'm afraid we haven't got to

01:08:03,039 --> 01:08:06,240
everyone's questions in the chat here we

01:08:04,640 --> 01:08:07,839
didn't get to everyone's questions from

01:08:06,240 --> 01:08:09,839
our pre-submitted list

01:08:07,839 --> 01:08:11,440
but uh i do want to thank everybody who

01:08:09,839 --> 01:08:14,079
submitted a question

01:08:11,440 --> 01:08:15,440
and uh i hope you've uh hope you've got

01:08:14,079 --> 01:08:18,719
yours answered

01:08:15,440 --> 01:08:21,440
um secondly uh huge thanks to both max

01:08:18,719 --> 01:08:22,799
and dima for uh working so hard on this

01:08:21,440 --> 01:08:24,400
we've done quite a lot of work ahead

01:08:22,799 --> 01:08:25,759
ahead of time to make sure we give you

01:08:24,400 --> 01:08:39,839
some really quality content here so

01:08:25,759 --> 01:08:39,839
thank you both

01:08:46,640 --> 01:08:48,719

YouTube URL: https://www.youtube.com/watch?v=blFe2yOD1WA


