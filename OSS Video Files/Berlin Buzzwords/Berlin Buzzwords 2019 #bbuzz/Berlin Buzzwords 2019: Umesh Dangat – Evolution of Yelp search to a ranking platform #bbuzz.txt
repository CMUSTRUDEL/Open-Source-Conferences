Title: Berlin Buzzwords 2019: Umesh Dangat – Evolution of Yelp search to a ranking platform #bbuzz
Publication date: 2019-06-27
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	Yelp’s core business search was one of the oldest systems at Yelp designed well before the advent of ElasticSearch. While this system served Yelp well for a few years, we were getting close to a point where the original search infrastructure architecture was not sufficient to solve modern day search problems.

This talk will detail:
1) How Yelp’s search engineers decoupled the search infrastructure from search relevance.
2) The challenges associated with transferring complex custom Apache Lucene based ranking and text analysis functionality to ElasticSearch.
3) The benefits of offloading search infrastructure to ElasticSearch and
4) Finally the dividends it paid by allowing us to further leverage our technological investment in ElasticSearch, by hosting machine learning models in ElasticSearch by using Learning to Rank plugin, and making contributions to it.

Read more:
https://2019.berlinbuzzwords.de/19/session/evolution-yelp-search-ranking-platform

About Umesh Dangat:
https://2019.berlinbuzzwords.de/users/umesh-dangat

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,830 --> 00:00:10,930
hello all thank you for coming to the

00:00:09,330 --> 00:00:13,600
talk as

00:00:10,930 --> 00:00:16,180
introduced my name is Uma Shankar I'm a

00:00:13,600 --> 00:00:18,430
search engineer at Yelp and today I'm

00:00:16,180 --> 00:00:20,980
going to talk about our migration from a

00:00:18,430 --> 00:00:23,320
custom distributed leucine based search

00:00:20,980 --> 00:00:26,740
infrastructure to a one based on elastic

00:00:23,320 --> 00:00:28,510
search before we begin a quick word on

00:00:26,740 --> 00:00:32,320
yelps mission it is connecting people

00:00:28,510 --> 00:00:33,699
with great local businesses here are

00:00:32,320 --> 00:00:35,650
some of the numbers I'm allowed to share

00:00:33,699 --> 00:00:38,860
because these were out in our last

00:00:35,650 --> 00:00:42,070
latest earnings call the important

00:00:38,860 --> 00:00:44,560
things here are as of n of Q 1 2019 we

00:00:42,070 --> 00:00:46,720
have 184 million reviews all of which

00:00:44,560 --> 00:00:49,960
are searchable the monthly average of

00:00:46,720 --> 00:00:53,170
unique visitors who was at Yelp in the

00:00:49,960 --> 00:00:56,020
quarter was 100 million combining the

00:00:53,170 --> 00:00:59,100
website and the app and this translates

00:00:56,020 --> 00:01:03,910
to billions of queries served per year

00:00:59,100 --> 00:01:07,300
by our search all right so this is a

00:01:03,910 --> 00:01:10,780
screenshot of our dub-dub-dub website

00:01:07,300 --> 00:01:12,820
page but the app looks similar so far

00:01:10,780 --> 00:01:13,810
when I say Yelp search or Yelp course

00:01:12,820 --> 00:01:17,260
search I am essentially talking about

00:01:13,810 --> 00:01:20,140
this page here if you see there's a box

00:01:17,260 --> 00:01:23,740
of free text which is used by our

00:01:20,140 --> 00:01:25,960
customers to type in let's say food or

00:01:23,740 --> 00:01:28,450
delivery look up for businesses by name

00:01:25,960 --> 00:01:30,909
like McDonald's maybe and more recently

00:01:28,450 --> 00:01:33,640
also things like services plumbers or

00:01:30,909 --> 00:01:35,650
you want a quote from a plumber or to

00:01:33,640 --> 00:01:37,060
fix something else and there's a

00:01:35,650 --> 00:01:38,950
location component as well which is

00:01:37,060 --> 00:01:42,689
other box here this is going to be

00:01:38,950 --> 00:01:46,060
important of in the talk later as well

00:01:42,689 --> 00:01:49,210
cool so how did our search architecture

00:01:46,060 --> 00:01:52,540
look like until recently one thing to

00:01:49,210 --> 00:01:55,840
keep in mind is Yelp was founded in 2004

00:01:52,540 --> 00:01:57,880
and I think such codebase was pretty

00:01:55,840 --> 00:01:59,110
much one of the early code bases at Yale

00:01:57,880 --> 00:02:00,850
because those functionalities search

00:01:59,110 --> 00:02:03,939
functionality has existed ever since

00:02:00,850 --> 00:02:06,490
Yelp as existed so these decisions were

00:02:03,939 --> 00:02:08,290
made in like 2006 7 maybe so we didn't

00:02:06,490 --> 00:02:11,440
obviously have elasticsearch or we

00:02:08,290 --> 00:02:13,420
probably didn't have solar either so the

00:02:11,440 --> 00:02:15,760
developers back then resulta used lucy

00:02:13,420 --> 00:02:17,799
and of course we ran to the problem of

00:02:15,760 --> 00:02:19,870
scale so we decided to distribute to

00:02:17,799 --> 00:02:22,020
scene and manage an auto say this

00:02:19,870 --> 00:02:30,690
cluster ourselves

00:02:22,020 --> 00:02:32,640
so here I'm showing the belief search

00:02:30,690 --> 00:02:34,590
nodes what I mean by a leaf search node

00:02:32,640 --> 00:02:36,930
is each node essentially serves one

00:02:34,590 --> 00:02:39,270
Lucene index and very simply put it's a

00:02:36,930 --> 00:02:42,510
master of follower architecture backed

00:02:39,270 --> 00:02:45,180
by arrest so then next in the quest goes

00:02:42,510 --> 00:02:47,370
to a master which takes the rights which

00:02:45,180 --> 00:02:49,110
is written to Lucene index periodically

00:02:47,370 --> 00:02:51,030
which is typically every three to four

00:02:49,110 --> 00:02:53,400
hours we would snapshot this index to s

00:02:51,030 --> 00:02:56,010
3 and then the read and then the

00:02:53,400 --> 00:02:58,140
followers which were a pool of followers

00:02:56,010 --> 00:03:00,270
as I will talk about it later they would

00:02:58,140 --> 00:03:02,310
be also restarted periodically pull

00:03:00,270 --> 00:03:05,430
these for leucine indexes from s3 and

00:03:02,310 --> 00:03:09,930
serve the queries alright and as I said

00:03:05,430 --> 00:03:12,420
before this works only on one node per

00:03:09,930 --> 00:03:13,890
GB M so obviously ardena does not fit in

00:03:12,420 --> 00:03:16,740
one node so what do we do

00:03:13,890 --> 00:03:19,230
of course we shard so this brings

00:03:16,740 --> 00:03:22,020
certain complexities now so like I

00:03:19,230 --> 00:03:24,900
mentioned before our business model the

00:03:22,020 --> 00:03:26,280
search is really naturally sharded on

00:03:24,900 --> 00:03:28,800
geography because you're looking for

00:03:26,280 --> 00:03:30,780
residence near you or in a particular

00:03:28,800 --> 00:03:32,520
city or you looking for a plumber near

00:03:30,780 --> 00:03:35,580
your house or whatever so we would short

00:03:32,520 --> 00:03:37,410
them geographically and then now we need

00:03:35,580 --> 00:03:40,350
to put a coordinator service in front of

00:03:37,410 --> 00:03:42,240
this the task of this is kind of similar

00:03:40,350 --> 00:03:44,810
to the elasticsearch coordinator these

00:03:42,240 --> 00:03:47,280
days where it gets a request it routes

00:03:44,810 --> 00:03:51,330
to the correct indexing node or the

00:03:47,280 --> 00:03:52,830
search node and the rest is the same the

00:03:51,330 --> 00:03:54,540
one detail that is missing here which is

00:03:52,830 --> 00:03:56,700
also taken care of by the coordinator is

00:03:54,540 --> 00:03:58,920
kind of the scatter gather what that

00:03:56,700 --> 00:04:01,020
means is if you see the shard Lucene

00:03:58,920 --> 00:04:04,020
follower for example that is further

00:04:01,020 --> 00:04:05,280
sharded what we called micro shots so

00:04:04,020 --> 00:04:08,190
that allows us some more parallelism so

00:04:05,280 --> 00:04:10,350
the coordinator would send a broadcast

00:04:08,190 --> 00:04:12,690
to like scatter request to all the micro

00:04:10,350 --> 00:04:14,820
shots get back the result from all the

00:04:12,690 --> 00:04:17,310
micro sorts and then do a resort or

00:04:14,820 --> 00:04:19,680
merge sort kind of so as you can see

00:04:17,310 --> 00:04:22,290
this is quickly getting complicated

00:04:19,680 --> 00:04:24,720
because we could runs potentially most

00:04:22,290 --> 00:04:27,420
of our ranking in the you know seen

00:04:24,720 --> 00:04:28,860
followers but then if the results are

00:04:27,420 --> 00:04:31,140
really tiny the relevant stream could

00:04:28,860 --> 00:04:33,540
also run some of the ranking or the more

00:04:31,140 --> 00:04:35,220
expensive one in the coordinator service

00:04:33,540 --> 00:04:38,430
and they talk about it later how this is

00:04:35,220 --> 00:04:40,380
not the best thing to do so now that we

00:04:38,430 --> 00:04:43,350
know a bit about the system what are the

00:04:40,380 --> 00:04:45,840
issues with the system like I said once

00:04:43,350 --> 00:04:47,580
initially when we began it was maybe a

00:04:45,840 --> 00:04:49,290
handful of engineers and the goal was

00:04:47,580 --> 00:04:52,350
let's get search up and running but with

00:04:49,290 --> 00:04:54,120
time the team grew we had specialized

00:04:52,350 --> 00:04:57,110
roles and this became a department of

00:04:54,120 --> 00:04:59,400
probably 30 plus people there were rules

00:04:57,110 --> 00:05:01,500
specific rules for specific people who

00:04:59,400 --> 00:05:04,620
were motivated to do specific tasks for

00:05:01,500 --> 00:05:06,840
example the relevant experts their

00:05:04,620 --> 00:05:09,600
motivation or primary goal was let's

00:05:06,840 --> 00:05:11,460
make the results look better from a

00:05:09,600 --> 00:05:12,479
quality perspective and the

00:05:11,460 --> 00:05:14,820
infrastructure team on the other hand

00:05:12,479 --> 00:05:16,500
had an orthogonal kind of a primary goal

00:05:14,820 --> 00:05:18,470
which was availability of the system and

00:05:16,500 --> 00:05:20,490
performance unreliability

00:05:18,470 --> 00:05:22,229
so what happens is when your code base

00:05:20,490 --> 00:05:24,660
is not designed from the start or the

00:05:22,229 --> 00:05:26,190
get-go to handle these two cross-cutting

00:05:24,660 --> 00:05:27,930
concerns separately the code is

00:05:26,190 --> 00:05:30,000
entangled so you try to make change in

00:05:27,930 --> 00:05:32,780
the relevance it's really hard to not

00:05:30,000 --> 00:05:35,850
break something or really slow down

00:05:32,780 --> 00:05:38,669
maybe deleting saifa queries and vice

00:05:35,850 --> 00:05:39,990
versa if you try to port out let's say

00:05:38,669 --> 00:05:41,729
some of the shouting logically shard

00:05:39,990 --> 00:05:43,380
it's really hard to not break some of

00:05:41,729 --> 00:05:46,830
the relevancy thereby causing a

00:05:43,380 --> 00:05:48,720
regression yeah a third of this the

00:05:46,830 --> 00:05:51,030
iteration speed is really slow because

00:05:48,720 --> 00:05:52,229
for me for example I work on a search

00:05:51,030 --> 00:05:53,970
infrastructure so for me it's really

00:05:52,229 --> 00:05:55,889
hard to understand why we are running

00:05:53,970 --> 00:05:58,050
certain kinds of scores or anchors with

00:05:55,889 --> 00:06:02,910
these models and it's hard to just

00:05:58,050 --> 00:06:04,050
isolate my changes from this codebase it

00:06:02,910 --> 00:06:06,810
was an operational burden of course

00:06:04,050 --> 00:06:10,260
because 2006 or 7 when we began this

00:06:06,810 --> 00:06:12,389
compared to 2015 or 16 when we wanted to

00:06:10,260 --> 00:06:16,590
replicate this the size of data had

00:06:12,389 --> 00:06:18,750
grown tremendously so our typical fix

00:06:16,590 --> 00:06:21,889
was ok let's throw more instances let's

00:06:18,750 --> 00:06:25,380
shout again let's add more replicas for

00:06:21,889 --> 00:06:27,419
parallelization and or also add

00:06:25,380 --> 00:06:29,280
microcharts what this means is our

00:06:27,419 --> 00:06:31,650
cluster gets bigger the code pushes gets

00:06:29,280 --> 00:06:33,599
lower note how I said that our

00:06:31,650 --> 00:06:35,820
rankers also ran and those scenes so

00:06:33,599 --> 00:06:37,229
ever this is a team of multiple number

00:06:35,820 --> 00:06:39,030
of engineers now trying to push code

00:06:37,229 --> 00:06:41,010
multiple times a week sometimes multiple

00:06:39,030 --> 00:06:42,930
times a day we have to do a rolling

00:06:41,010 --> 00:06:44,520
restart of the entire cluster and the

00:06:42,930 --> 00:06:46,370
bigger the cluster the by nature of it

00:06:44,520 --> 00:06:49,580
it's going to be slower

00:06:46,370 --> 00:06:53,210
and there was more fun besides of just

00:06:49,580 --> 00:06:55,660
slow code pushes we also loved the heap

00:06:53,210 --> 00:06:58,280
so we put a lot of stuff in the heap and

00:06:55,660 --> 00:07:00,260
the first heap such weight I mean it's

00:06:58,280 --> 00:07:01,220
the same story I guess everywhere 80 x16

00:07:00,260 --> 00:07:05,240
cakes 30 cakes

00:07:01,220 --> 00:07:09,320
hello sub the wall DC's so yeah I'll

00:07:05,240 --> 00:07:10,340
talk about that too and what primarily

00:07:09,320 --> 00:07:11,420
was happening but at least the

00:07:10,340 --> 00:07:13,070
infrastructure team was he was spending

00:07:11,420 --> 00:07:17,630
more time maintaining the system rather

00:07:13,070 --> 00:07:19,490
than writing new features another thing

00:07:17,630 --> 00:07:21,530
that happened was it was really getting

00:07:19,490 --> 00:07:22,910
hard to add new features so for example

00:07:21,530 --> 00:07:24,890
business wanted to add things like

00:07:22,910 --> 00:07:26,330
delivery you want to find out all the

00:07:24,890 --> 00:07:28,640
restaurants that deliver in the next 15

00:07:26,330 --> 00:07:31,670
minutes or you want to book a table at a

00:07:28,640 --> 00:07:32,930
restaurant for some time without some

00:07:31,670 --> 00:07:35,360
sort of real-time indexing this is

00:07:32,930 --> 00:07:37,610
really hard to get one of the other big

00:07:35,360 --> 00:07:39,320
issues was analyzers could not be simply

00:07:37,610 --> 00:07:41,120
iterated upon because that meant a

00:07:39,320 --> 00:07:43,220
complete back full complete back film

00:07:41,120 --> 00:07:45,050
and some we had to go take the time spin

00:07:43,220 --> 00:07:48,160
up a battle cluster do all the indexing

00:07:45,050 --> 00:07:52,310
from source and it's just too much of a

00:07:48,160 --> 00:07:55,600
chore to do cool so now that we are

00:07:52,310 --> 00:07:57,440
convinced that we needed a newer system

00:07:55,600 --> 00:07:59,240
what are the requirements of the system

00:07:57,440 --> 00:08:02,120
well the one requirement handed down to

00:07:59,240 --> 00:08:05,390
us from management was since this is

00:08:02,120 --> 00:08:07,400
mostly an infrastructure project we need

00:08:05,390 --> 00:08:10,100
the mandate was we cannot cause

00:08:07,400 --> 00:08:12,380
regressions in the relevance or the

00:08:10,100 --> 00:08:15,200
quality maybe some edge cases are fine

00:08:12,380 --> 00:08:16,910
but we really cannot say ok you can't

00:08:15,200 --> 00:08:19,760
rank the results the same way so that's

00:08:16,910 --> 00:08:22,880
one thing which meant we had to go open

00:08:19,760 --> 00:08:24,260
our leaf search node which for the most

00:08:22,880 --> 00:08:25,670
part we treated as a black box now we

00:08:24,260 --> 00:08:27,890
have to open it up and look inside it

00:08:25,670 --> 00:08:30,110
and see what it is doing and how can we

00:08:27,890 --> 00:08:32,780
put these components out into

00:08:30,110 --> 00:08:35,500
elasticsearch so I don't talk about the

00:08:32,780 --> 00:08:38,240
indexing here but it's pretty similar

00:08:35,500 --> 00:08:40,000
except the ranking part so let's look at

00:08:38,240 --> 00:08:43,700
a search query a search query comes in

00:08:40,000 --> 00:08:47,170
again this is a rest rest behind rest

00:08:43,700 --> 00:08:49,580
API so then we generate a leucine query

00:08:47,170 --> 00:08:51,620
which is fine we could potentially map

00:08:49,580 --> 00:08:54,500
this to something in elasticsearch maybe

00:08:51,620 --> 00:08:56,900
then there's an analysis component which

00:08:54,500 --> 00:08:58,520
is a bunch of Java classes of course

00:08:56,900 --> 00:09:00,370
that is the ranking now what is the

00:08:58,520 --> 00:09:03,050
ranking do we have

00:09:00,370 --> 00:09:06,200
Lucien's quarters queries and weights

00:09:03,050 --> 00:09:07,880
and we rely on the Lucille Index but we

00:09:06,200 --> 00:09:10,250
also rely on like I said before the Java

00:09:07,880 --> 00:09:12,310
heap okay what does the heap have the

00:09:10,250 --> 00:09:14,600
heap has things like business field cash

00:09:12,310 --> 00:09:17,030
yes we still use field cash because

00:09:14,600 --> 00:09:19,190
again this is old code base and it says

00:09:17,030 --> 00:09:22,190
we started with leucine - I think we did

00:09:19,190 --> 00:09:25,630
one port the leucine three and still

00:09:22,190 --> 00:09:28,340
have the field cash in and it quickly

00:09:25,630 --> 00:09:30,230
started adding features to it or more

00:09:28,340 --> 00:09:31,430
fields to it rather and then there is

00:09:30,230 --> 00:09:33,620
this interesting piece here called the

00:09:31,430 --> 00:09:36,200
miscellaneous data so like I said before

00:09:33,620 --> 00:09:37,790
we would have a lot of different

00:09:36,200 --> 00:09:41,440
engineers working on this codebase

00:09:37,790 --> 00:09:43,250
typically who would be the users of the

00:09:41,440 --> 00:09:44,240
infrastructure but in this case they

00:09:43,250 --> 00:09:45,920
were the ones writing the code that

00:09:44,240 --> 00:09:48,440
allows engineers so let's say I want to

00:09:45,920 --> 00:09:50,450
add a new feature called CTR or a

00:09:48,440 --> 00:09:52,220
click-through rate what they said

00:09:50,450 --> 00:09:54,590
potentially what is typically means is

00:09:52,220 --> 00:09:57,650
in the search and kind of adds world is

00:09:54,590 --> 00:10:00,770
for a given business what are the top K

00:09:57,650 --> 00:10:01,910
queries that it was clicked for this

00:10:00,770 --> 00:10:03,680
really helps you like squared up this

00:10:01,910 --> 00:10:05,870
bedroom now this cannot be represented

00:10:03,680 --> 00:10:07,910
easily in a field cache so we just put

00:10:05,870 --> 00:10:10,960
this in a map because why not we have

00:10:07,910 --> 00:10:13,910
access to maps and this is kept growing

00:10:10,960 --> 00:10:16,640
school so coming back to what we need to

00:10:13,910 --> 00:10:18,230
port over this is somebody of the

00:10:16,640 --> 00:10:23,630
previous slide mean to port over the

00:10:18,230 --> 00:10:26,720
ranking the analyzers the data on Java

00:10:23,630 --> 00:10:29,660
heap and some advanced features like

00:10:26,720 --> 00:10:32,930
highlights and logging by logging what I

00:10:29,660 --> 00:10:35,930
mean is the kind of you sent back the

00:10:32,930 --> 00:10:37,610
dictionary of the top key scores and the

00:10:35,930 --> 00:10:39,830
reason for the score such that let's say

00:10:37,610 --> 00:10:41,930
it's a dictionary of feature two double

00:10:39,830 --> 00:10:43,490
where the feature is that will feature

00:10:41,930 --> 00:10:45,470
and this double is the score of that

00:10:43,490 --> 00:10:47,930
feature so this helps us our offline

00:10:45,470 --> 00:10:51,860
training to know how to retrain the

00:10:47,930 --> 00:10:53,060
model so the other teams that Yelp had

00:10:51,860 --> 00:10:55,010
been using elastic search for the

00:10:53,060 --> 00:10:57,890
smaller use cases so this seemed like a

00:10:55,010 --> 00:10:59,690
natural fit and it was JVM based again

00:10:57,890 --> 00:11:03,230
so we said ok since we have a lot of

00:10:59,690 --> 00:11:05,420
code in Java Vlasic so charges plug-in

00:11:03,230 --> 00:11:09,370
API architecture where we can plug in

00:11:05,420 --> 00:11:09,370
our Java code so let's see how our

00:11:09,920 --> 00:11:15,149
components map to the plugins so for

00:11:14,249 --> 00:11:16,679
pretty much most part there's a

00:11:15,149 --> 00:11:19,019
one-to-one mapping there's a script

00:11:16,679 --> 00:11:21,329
plug-in there's a analysis plug-in that

00:11:19,019 --> 00:11:22,819
is dock values especially the later

00:11:21,329 --> 00:11:25,619
versions of the scene and elasticsearch

00:11:22,819 --> 00:11:27,089
and then there is this overarching like

00:11:25,619 --> 00:11:30,809
search plug-in which pretty much can

00:11:27,089 --> 00:11:34,739
overwrite anything so let's take a look

00:11:30,809 --> 00:11:37,319
at of them one by one now it's a custom

00:11:34,739 --> 00:11:39,749
ranking again we need to house our

00:11:37,319 --> 00:11:41,610
scoring code in the script plug-in the

00:11:39,749 --> 00:11:44,489
key here is elasticsearch provides you

00:11:41,610 --> 00:11:46,139
different entry points and you kind of

00:11:44,489 --> 00:11:48,119
need it's like a boilerplate code but

00:11:46,139 --> 00:11:49,829
you need to put your code in these

00:11:48,119 --> 00:11:51,119
different sections and what's

00:11:49,829 --> 00:11:53,029
interesting is you need to know your

00:11:51,119 --> 00:11:55,230
score so the lowest level is

00:11:53,029 --> 00:11:57,720
elasticsearch will call your for

00:11:55,230 --> 00:12:00,360
examples search script dot one has

00:11:57,720 --> 00:12:01,910
double on every single document so this

00:12:00,360 --> 00:12:05,329
import from performance because you

00:12:01,910 --> 00:12:07,679
cannot do like expensive operations here

00:12:05,329 --> 00:12:10,319
then that is code which it calls at a

00:12:07,679 --> 00:12:11,879
per segment level

00:12:10,319 --> 00:12:15,209
the other interesting thing here is with

00:12:11,879 --> 00:12:16,889
elasticsearch one shard comprises sorry

00:12:15,209 --> 00:12:19,439
of multiple segments and it goes

00:12:16,889 --> 00:12:21,720
linearly over all the segments so if you

00:12:19,439 --> 00:12:22,919
can do something just once but query

00:12:21,720 --> 00:12:25,829
porsche are you would rather do it at

00:12:22,919 --> 00:12:27,899
the per shard level not a segment and

00:12:25,829 --> 00:12:29,790
this helps like gain performance so for

00:12:27,899 --> 00:12:33,239
example we would ship a lot of query

00:12:29,790 --> 00:12:35,639
parameters over from our service to

00:12:33,239 --> 00:12:37,230
elastic search and these would be JSON

00:12:35,639 --> 00:12:39,059
for the most part it could be a parts of

00:12:37,230 --> 00:12:41,309
your model which we had to be sterilized

00:12:39,059 --> 00:12:43,439
so doing that at the start level makes

00:12:41,309 --> 00:12:44,759
more sense and for segments because then

00:12:43,439 --> 00:12:45,929
it's because if you have shard has many

00:12:44,759 --> 00:12:47,939
many segments especially if you have

00:12:45,929 --> 00:12:49,799
real time indexing then it's going to be

00:12:47,939 --> 00:12:52,019
slow and then there are certain things

00:12:49,799 --> 00:12:53,869
you can do just once per JVM instance

00:12:52,019 --> 00:12:56,699
which is like plug-in instantiation

00:12:53,869 --> 00:12:59,610
against the key part here is you should

00:12:56,699 --> 00:13:01,829
know the Scopes and yes changes these

00:12:59,610 --> 00:13:04,110
names and the factories and the leaf

00:13:01,829 --> 00:13:07,529
factories around a lot so the best way

00:13:04,110 --> 00:13:09,449
to do this is every new version once a

00:13:07,529 --> 00:13:13,019
code compiles just turn on your favorite

00:13:09,449 --> 00:13:15,899
debugger or editor and step through like

00:13:13,019 --> 00:13:19,110
for a couple of documents the analyzes

00:13:15,899 --> 00:13:21,029
what some fun to so on the face of it

00:13:19,110 --> 00:13:21,760
okay we have analysis plug-in and we can

00:13:21,029 --> 00:13:23,860
use

00:13:21,760 --> 00:13:26,019
get analyzers and dropper code there the

00:13:23,860 --> 00:13:29,589
one issue for us was we were using a

00:13:26,019 --> 00:13:31,990
much older version of the scene now the

00:13:29,589 --> 00:13:34,449
bright fix which is second bullet point

00:13:31,990 --> 00:13:36,070
here is let's upgrade all this to the

00:13:34,449 --> 00:13:37,720
later version of the scene but we don't

00:13:36,070 --> 00:13:39,730
know how that would actually change the

00:13:37,720 --> 00:13:41,649
behavior that means now another

00:13:39,730 --> 00:13:44,290
potential for regression in our results

00:13:41,649 --> 00:13:47,709
which we didn't want so the quick fix

00:13:44,290 --> 00:13:50,220
our hack in this case was using shading

00:13:47,709 --> 00:13:52,990
the shading is like a plugin provided by

00:13:50,220 --> 00:13:57,730
certain build tools for example maven

00:13:52,990 --> 00:13:59,500
this is a maven XML taken out of the

00:13:57,730 --> 00:14:01,690
screenshot taken out of the our

00:13:59,500 --> 00:14:04,510
symbol where we could relocate your arc

00:14:01,690 --> 00:14:08,350
Apache Luc in to come yell search

00:14:04,510 --> 00:14:10,029
old-school ar-ar-ar quick Apache so what

00:14:08,350 --> 00:14:12,430
can happen then is we take this jar now

00:14:10,029 --> 00:14:14,380
and drop it on elasticsearch so when you

00:14:12,430 --> 00:14:15,850
import org Apache l-leucine it's going

00:14:14,380 --> 00:14:17,800
to use the later one which elasticsearch

00:14:15,850 --> 00:14:20,110
has but when you import calm Yelp search

00:14:17,800 --> 00:14:22,660
it's going to use the older Lucene so we

00:14:20,110 --> 00:14:25,779
had this bridge in analyzers where at

00:14:22,660 --> 00:14:27,040
the entry point of the analysis code we

00:14:25,779 --> 00:14:28,660
would have a wrapper analyzer which

00:14:27,040 --> 00:14:32,139
called a role analyzer now this is

00:14:28,660 --> 00:14:34,540
tricky and it's quite risky because the

00:14:32,139 --> 00:14:35,709
bridge definitely like breaks on certain

00:14:34,540 --> 00:14:37,690
edge cases like it worked for us for

00:14:35,709 --> 00:14:40,720
highlighting and stuff because things

00:14:37,690 --> 00:14:41,620
like offsets they just like losing get

00:14:40,720 --> 00:14:43,600
stricter and stricter with like

00:14:41,620 --> 00:14:45,040
backwards doing offsets and stuff so it

00:14:43,600 --> 00:14:46,420
could potentially break I'm not saying

00:14:45,040 --> 00:14:47,699
Dundas in production but if you want to

00:14:46,420 --> 00:14:52,720
get something up and running quickly

00:14:47,699 --> 00:14:55,540
just kind of work for us of course data

00:14:52,720 --> 00:14:57,399
off the Java heap that was a pretty much

00:14:55,540 --> 00:14:59,350
one of the big wins of going to es like

00:14:57,399 --> 00:15:01,420
we just move everything to document

00:14:59,350 --> 00:15:04,029
values the nice thing was we were able

00:15:01,420 --> 00:15:06,190
to run a ranker completely oblivious of

00:15:04,029 --> 00:15:08,290
the back end so the rancor would have an

00:15:06,190 --> 00:15:10,690
API which would say document dot get the

00:15:08,290 --> 00:15:16,959
field name and then the implementation

00:15:10,690 --> 00:15:20,040
was in this case using scripts one

00:15:16,959 --> 00:15:23,230
interesting thing we had to add to the

00:15:20,040 --> 00:15:25,990
elastic search as a patch was the CTR

00:15:23,230 --> 00:15:28,389
data like I mentioned before elastic sis

00:15:25,990 --> 00:15:29,649
had the ability to store blobs but we

00:15:28,389 --> 00:15:33,730
couldn't really read them as dock values

00:15:29,649 --> 00:15:34,980
in scripts so we had to like structure

00:15:33,730 --> 00:15:37,079
our own data as a

00:15:34,980 --> 00:15:38,940
before put it in and you could read it

00:15:37,079 --> 00:15:40,829
out and because it's your own custom

00:15:38,940 --> 00:15:44,449
format it's really fast too so that's

00:15:40,829 --> 00:15:48,060
how we cut around like not having the

00:15:44,449 --> 00:15:49,800
CTR in the heap certain other features

00:15:48,060 --> 00:15:52,079
like highlights called components these

00:15:49,800 --> 00:15:53,579
are also implementable you need need to

00:15:52,079 --> 00:15:55,170
look at some of the documentation is not

00:15:53,579 --> 00:15:56,910
great but you need to look at the

00:15:55,170 --> 00:15:59,360
effects of phase look at some

00:15:56,910 --> 00:16:01,350
implementations and go from there I

00:15:59,360 --> 00:16:03,510
could spend a lot more time talking

00:16:01,350 --> 00:16:06,149
about performance but here's some

00:16:03,510 --> 00:16:07,769
highlights use the profile API it's

00:16:06,149 --> 00:16:09,269
really cool it tells it order sort of

00:16:07,769 --> 00:16:11,610
things like okay aggregations are

00:16:09,269 --> 00:16:16,079
released slow global on tinel's are the

00:16:11,610 --> 00:16:18,570
cause of it like I said before charts

00:16:16,079 --> 00:16:20,850
scale up to a point then there is the

00:16:18,570 --> 00:16:24,149
overhead of just maintaining them dock

00:16:20,850 --> 00:16:25,680
values is good and doing simple things

00:16:24,149 --> 00:16:27,180
like just doing J stock if a system is

00:16:25,680 --> 00:16:29,550
slow will tell you okay what's on top of

00:16:27,180 --> 00:16:32,399
my stack all the time CMS did not work

00:16:29,550 --> 00:16:34,560
for us we had a thrust at launch for a

00:16:32,399 --> 00:16:37,170
few weeks before we went live and every

00:16:34,560 --> 00:16:40,620
single day CMS caused a lot of issues so

00:16:37,170 --> 00:16:43,529
we've been using g1 alright so now that

00:16:40,620 --> 00:16:46,139
we have moved over how does a search

00:16:43,529 --> 00:16:48,630
architecture what are the benefits of

00:16:46,139 --> 00:16:49,980
this we don't have to be with the

00:16:48,630 --> 00:16:52,139
thousands of lines of code now which is

00:16:49,980 --> 00:16:54,690
managed by elasticsearch our on call is

00:16:52,139 --> 00:16:57,209
not happier I think and more importantly

00:16:54,690 --> 00:17:00,860
this is like unlocked other teams at

00:16:57,209 --> 00:17:03,240
Yelp to essentially run the similar

00:17:00,860 --> 00:17:05,100
filtering ranking analysis and whatnot

00:17:03,240 --> 00:17:08,579
on their own data because we can't Rob

00:17:05,100 --> 00:17:11,669
these plugins on their clusters like ads

00:17:08,579 --> 00:17:12,780
for example or request a code what is

00:17:11,669 --> 00:17:17,370
the other new functionality that we

00:17:12,780 --> 00:17:20,490
added to using yes which would have been

00:17:17,370 --> 00:17:23,610
harder otherwise one is hosting our

00:17:20,490 --> 00:17:24,929
models elasticsearch so before so before

00:17:23,610 --> 00:17:27,360
this we were passing a lot of the model

00:17:24,929 --> 00:17:28,830
in the query itself and some other teams

00:17:27,360 --> 00:17:31,650
started doing stuff like let's pull out

00:17:28,830 --> 00:17:32,100
the data from es hit the network

00:17:31,650 --> 00:17:33,660
bandwidth

00:17:32,100 --> 00:17:35,669
keep pulling out till that point and

00:17:33,660 --> 00:17:37,740
then rescore outside and model service

00:17:35,669 --> 00:17:40,830
that doesn't really scale so how could

00:17:37,740 --> 00:17:42,090
we score on elasticsearch luckily we

00:17:40,830 --> 00:17:45,990
found this plugin colouring to rank

00:17:42,090 --> 00:17:47,940
developed by OSC the idea here is post

00:17:45,990 --> 00:17:52,170
your features and models to yes

00:17:47,940 --> 00:17:54,390
separately offline and then in compute

00:17:52,170 --> 00:17:57,170
time you can actually calculate this

00:17:54,390 --> 00:17:59,190
course I'll go into it on this slide so

00:17:57,170 --> 00:18:01,580
here what we do is we upload the

00:17:59,190 --> 00:18:04,320
features and models by our REST API

00:18:01,580 --> 00:18:05,880
annual learning to rank hey my feature

00:18:04,320 --> 00:18:08,610
one is just my plugin which is a

00:18:05,880 --> 00:18:09,840
function score query and then it let it

00:18:08,610 --> 00:18:11,730
do what it wants to do with feature one

00:18:09,840 --> 00:18:13,320
- another feature could be a painless

00:18:11,730 --> 00:18:15,390
script a feature could be a leucine

00:18:13,320 --> 00:18:16,860
derived expression and so on and then

00:18:15,390 --> 00:18:17,940
you push the model which combines all

00:18:16,860 --> 00:18:19,320
these features and tells it how to

00:18:17,940 --> 00:18:21,840
compute in the case of a linear model

00:18:19,320 --> 00:18:23,160
it's just a linear math equation we also

00:18:21,840 --> 00:18:25,980
use actually boost in production which

00:18:23,160 --> 00:18:28,170
is more of a tree form so if every

00:18:25,980 --> 00:18:30,030
document we do this then it comes back

00:18:28,170 --> 00:18:33,890
to the plugin it does the final compute

00:18:30,030 --> 00:18:36,540
and it gives us the result so this way

00:18:33,890 --> 00:18:38,220
the es query is now really tiny we just

00:18:36,540 --> 00:18:41,790
need to send in the model name and the

00:18:38,220 --> 00:18:43,740
query time parameters so as of today

00:18:41,790 --> 00:18:45,030
Yelp has been a collaborator to the ITR

00:18:43,740 --> 00:18:46,320
it didn't really work out of the box for

00:18:45,030 --> 00:18:48,480
us because of some of the advanced use

00:18:46,320 --> 00:18:50,820
cases and I talked about it in this

00:18:48,480 --> 00:18:54,330
haystack talk which I gave some time

00:18:50,820 --> 00:18:57,150
last month and it had some performance

00:18:54,330 --> 00:18:58,680
issues which we had to fix too but we

00:18:57,150 --> 00:19:01,290
use it today for many of our critical

00:18:58,680 --> 00:19:04,100
workflows and if you guys were

00:19:01,290 --> 00:19:06,330
considering like hosting models in yes

00:19:04,100 --> 00:19:10,110
consider using this contributions are

00:19:06,330 --> 00:19:13,080
welcome to finally we are hiring across

00:19:10,110 --> 00:19:15,600
the board and also for search and this

00:19:13,080 --> 00:19:20,220
some of our blogs I have written a blog

00:19:15,600 --> 00:19:24,140
post about our migration too and that's

00:19:20,220 --> 00:19:27,439
it yes thank you very much

00:19:24,140 --> 00:19:27,439
[Applause]

00:19:28,929 --> 00:19:48,019
maybe we can have one short question yes

00:19:36,100 --> 00:19:51,379
I won't be short I don't know what your

00:19:48,019 --> 00:19:54,799
answer but D you said you know goal was

00:19:51,379 --> 00:19:57,559
not to change ranking at all so I'm

00:19:54,799 --> 00:20:01,129
curious how did you validate that how

00:19:57,559 --> 00:20:06,320
did we elevate that Oh for the most part

00:20:01,129 --> 00:20:09,590
we didn't so like I said we we ran into

00:20:06,320 --> 00:20:10,669
issues like analyzers or highlights of

00:20:09,590 --> 00:20:12,649
broken so we had to go out this

00:20:10,669 --> 00:20:14,000
conversation with like product or

00:20:12,649 --> 00:20:15,919
management okay highlights uh broken in

00:20:14,000 --> 00:20:18,259
these cases do you really care and it

00:20:15,919 --> 00:20:19,700
would be like maybe we don't but but I

00:20:18,259 --> 00:20:21,830
guess what more more important was we

00:20:19,700 --> 00:20:24,139
had to get a POC out in like a time

00:20:21,830 --> 00:20:26,629
bound at window well let's say 80 to 90%

00:20:24,139 --> 00:20:27,799
of stuff worked which is what approach

00:20:26,629 --> 00:20:29,450
worked well and then you could argue

00:20:27,799 --> 00:20:31,460
about oh but here all the wins we are

00:20:29,450 --> 00:20:32,840
having you don't have to do management

00:20:31,460 --> 00:20:33,769
of the cluster on-call is up here you

00:20:32,840 --> 00:20:34,970
have better

00:20:33,769 --> 00:20:37,190
there's no attrition people are not

00:20:34,970 --> 00:20:39,259
leaving the job so that kind of balance

00:20:37,190 --> 00:20:40,549
out with that cases yes so now that

00:20:39,259 --> 00:20:41,870
you've learned that maybe you didn't

00:20:40,549 --> 00:20:43,970
that wasn't such a concern

00:20:41,870 --> 00:20:47,210
could you make deeper changes in the

00:20:43,970 --> 00:20:49,669
analyzers without worrying so much like

00:20:47,210 --> 00:20:51,440
porting them all to newer Lucene are you

00:20:49,669 --> 00:20:55,700
gonna any way this is I'll ask you

00:20:51,440 --> 00:21:00,880
alright okay okay note that was short

00:20:55,700 --> 00:21:06,259
question again let's think wish again

00:21:00,880 --> 00:21:06,259

YouTube URL: https://www.youtube.com/watch?v=ygIEHfEdIfs


