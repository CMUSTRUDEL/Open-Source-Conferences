Title: Berlin Buzzwords 2019: Nick Burch â€“ Building an AI ML powered text search system #bbuzz
Publication date: 2019-06-28
Playlist: Berlin Buzzwords 2019 #bbuzz
Description: 
	There are some great Open Source text search / information retrieval systems, such as Apache SOLR and ElasticSearch. But could an AI / ML powered solution do better? And how would you even go about building one?

Based on our experiences building a knowledge base / Q&A system, we'll guide you through the process. Learn how to get your text into a format that AI / ML techniques can work on, and how to build a simple model and recommender. Then it's Deep Learning and Neural Networks, and finally updating the models with real user feedback. Oh, and comparing it to a traditional search engine, to see if it's actually any better ...

Read more:
https://2019.berlinbuzzwords.de/19/session/building-aiml-powered-text-search-system

About Nick Burch:
https://2019.berlinbuzzwords.de/users/nick-burch

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,330 --> 00:00:12,019
so my name's Nick Burch

00:00:08,719 --> 00:00:14,690
CTO and head of AI development Quantic 8

00:00:12,019 --> 00:00:16,129
which is a firm that helps out with

00:00:14,690 --> 00:00:18,560
clinical trials we've got a lot of

00:00:16,129 --> 00:00:22,970
mathematicians and statisticians doing

00:00:18,560 --> 00:00:26,029
analysis I'm gonna show some source code

00:00:22,970 --> 00:00:27,800
in the slides during the talk I've only

00:00:26,029 --> 00:00:30,710
put in little snippets that are relevant

00:00:27,800 --> 00:00:33,559
but I have the whole thing available as

00:00:30,710 --> 00:00:35,719
a ipython notebook so you can have a

00:00:33,559 --> 00:00:38,059
look at more of the context now if you'd

00:00:35,719 --> 00:00:39,980
like and then also later you can clone

00:00:38,059 --> 00:00:43,460
that notebook and try and customize it

00:00:39,980 --> 00:00:46,030
for your own needs so nice little QR

00:00:43,460 --> 00:00:50,149
code hopefully it can work for everyone

00:00:46,030 --> 00:00:52,550
ok so it's not gonna be your typical AI

00:00:50,149 --> 00:00:53,960
talk and can explain a little bit about

00:00:52,550 --> 00:00:55,850
the kind of problem that I've got to

00:00:53,960 --> 00:00:59,359
solve and then I'm gonna look at how we

00:00:55,850 --> 00:01:00,829
can do AI for text how we can make it

00:00:59,359 --> 00:01:03,050
better and then at the very end I'm

00:01:00,829 --> 00:01:04,370
gonna give a whole bunch of resources so

00:01:03,050 --> 00:01:05,870
that if you're interested in this sort

00:01:04,370 --> 00:01:08,030
of thing it's the sort of problem that

00:01:05,870 --> 00:01:11,000
you've got you'll have some pointers on

00:01:08,030 --> 00:01:15,140
how to go off and learn some more so

00:01:11,000 --> 00:01:17,470
what is an AI an ml and why is it the

00:01:15,140 --> 00:01:22,520
buzzword at burning buzzwords this year

00:01:17,470 --> 00:01:24,920
so AI artificial intelligence ml machine

00:01:22,520 --> 00:01:27,530
learning and Larry Tesla's theorem is

00:01:24,920 --> 00:01:31,040
that AI is whatever hasn't been done yet

00:01:27,530 --> 00:01:32,990
and ml is whatever we can do today some

00:01:31,040 --> 00:01:35,690
other people say that if you're raising

00:01:32,990 --> 00:01:41,660
VC funds it's AI if you're hiring staff

00:01:35,690 --> 00:01:44,540
its ml ok but why today so the first big

00:01:41,660 --> 00:01:47,210
AI bubble was in the mid 1980s and there

00:01:44,540 --> 00:01:50,750
was over a billion US dollars raised in

00:01:47,210 --> 00:01:53,900
VC funding that was mostly AI for expert

00:01:50,750 --> 00:01:56,090
systems they had two big problems one of

00:01:53,900 --> 00:01:58,910
them is that wasn't enough training data

00:01:56,090 --> 00:02:01,100
available to build their AI is to train

00:01:58,910 --> 00:02:03,350
their AIS and the second problem was

00:02:01,100 --> 00:02:05,090
that in the 1980s it was cheaper to

00:02:03,350 --> 00:02:08,420
employ an expert than it was to buy the

00:02:05,090 --> 00:02:10,819
computers we're back again today so

00:02:08,420 --> 00:02:12,980
Moore's law to the rescue 1 million US

00:02:10,819 --> 00:02:14,739
dollars worth of computing power in 1985

00:02:12,980 --> 00:02:17,390
it's less than $1 today

00:02:14,739 --> 00:02:19,069
what's more Amazon will rent you a

00:02:17,390 --> 00:02:22,250
machine with a whole terabyte of memory

00:02:19,069 --> 00:02:25,160
for about the cost of a latte an hour

00:02:22,250 --> 00:02:27,770
okay you can rent from them a full

00:02:25,160 --> 00:02:30,290
terabyte memory machine for 25 bucks an

00:02:27,770 --> 00:02:32,360
hour so a whole bunch of problems that

00:02:30,290 --> 00:02:34,640
used to need more computers than would

00:02:32,360 --> 00:02:37,520
fit in this room are now 25 bucks an

00:02:34,640 --> 00:02:39,200
hour yeah first thing and then we've got

00:02:37,520 --> 00:02:41,840
a lot more data available to train our

00:02:39,200 --> 00:02:44,209
models on whereas you used to have a few

00:02:41,840 --> 00:02:45,650
records we've now got terabytes and

00:02:44,209 --> 00:02:48,980
petabytes of records that we can train

00:02:45,650 --> 00:02:51,050
on and the other big thing is all the

00:02:48,980 --> 00:02:53,120
open source libraries and frameworks you

00:02:51,050 --> 00:02:55,570
used to have to hire computer scientists

00:02:53,120 --> 00:02:57,530
to write you're open to write your a I

00:02:55,570 --> 00:02:59,750
library so that you could then get your

00:02:57,530 --> 00:03:01,880
data scientists to train it it's just

00:02:59,750 --> 00:03:03,470
three lines of Python now five lines of

00:03:01,880 --> 00:03:05,360
Java it's amazing there's all these

00:03:03,470 --> 00:03:08,180
libraries out there that make it easy so

00:03:05,360 --> 00:03:10,790
you can focus on the data and on your

00:03:08,180 --> 00:03:13,959
model not on how the hell do I build one

00:03:10,790 --> 00:03:18,130
of these things okay machine learning

00:03:13,959 --> 00:03:18,130
xkcd everyone seen this one before

00:03:18,370 --> 00:03:22,580
be aware that some of it is just

00:03:20,780 --> 00:03:26,870
cheating with your hyper parameters

00:03:22,580 --> 00:03:29,180
until the right answer comes out you can

00:03:26,870 --> 00:03:31,489
do amazing things with AI nml and you

00:03:29,180 --> 00:03:33,620
can also do terrible terrible things

00:03:31,489 --> 00:03:35,290
just try and have some quality metrics

00:03:33,620 --> 00:03:39,590
that give you an idea of what's going on

00:03:35,290 --> 00:03:43,970
okay so in your typical AI ml demo you

00:03:39,590 --> 00:03:47,390
have images images a call make for good

00:03:43,970 --> 00:03:49,280
demos so let's do a little bit of

00:03:47,390 --> 00:03:54,290
audience participation labeling some

00:03:49,280 --> 00:03:56,390
data it's this dogs or cats dogs okay

00:03:54,290 --> 00:04:02,180
what about this one is it dogs or cats

00:03:56,390 --> 00:04:03,860
ah okay so the AI is only going to be as

00:04:02,180 --> 00:04:06,410
good as the questions and the training

00:04:03,860 --> 00:04:08,450
data so if you give an AI that's trained

00:04:06,410 --> 00:04:11,090
to recognize dogs and cats a picture of

00:04:08,450 --> 00:04:13,190
a koala it's not going to give you the

00:04:11,090 --> 00:04:15,310
right answer okay let's generalize what

00:04:13,190 --> 00:04:20,660
kind of animal is this one

00:04:15,310 --> 00:04:22,790
kangaroo okay this one this one bat okay

00:04:20,660 --> 00:04:24,770
but if you're not careful your AI will

00:04:22,790 --> 00:04:29,470
say that's a dog because you know four

00:04:24,770 --> 00:04:29,470
legs low to the ground and this one

00:04:30,889 --> 00:04:37,610
now this one is an echidna so if you're

00:04:35,150 --> 00:04:39,169
getting a load of humans to classify

00:04:37,610 --> 00:04:41,539
your images and they don't know what's

00:04:39,169 --> 00:04:43,340
in the image they can't give you the

00:04:41,539 --> 00:04:47,210
training data that your AO is going to

00:04:43,340 --> 00:04:50,300
need so image classification is pretty

00:04:47,210 --> 00:04:54,740
cool as long as your humans are able to

00:04:50,300 --> 00:04:55,279
give you the right training data but my

00:04:54,740 --> 00:04:57,789
data

00:04:55,279 --> 00:05:00,560
doesn't look like that I mean cooler's

00:04:57,789 --> 00:05:02,120
Australian animals are they they they

00:05:00,560 --> 00:05:04,779
don't represent what I've got at work

00:05:02,120 --> 00:05:06,889
what I've got at work is stuff like this

00:05:04,779 --> 00:05:08,330
anyone recognising these kind of things

00:05:06,889 --> 00:05:11,029
you've got a lot of these at work

00:05:08,330 --> 00:05:13,729
you got spreadsheets you've got Word

00:05:11,029 --> 00:05:14,360
documents you've got lots and lots of

00:05:13,729 --> 00:05:17,629
data

00:05:14,360 --> 00:05:19,759
you've got Q & A all that kind of thing

00:05:17,629 --> 00:05:21,650
so this is the kind of stuff that I've

00:05:19,759 --> 00:05:25,729
got a lot of and I'm hoping that most of

00:05:21,650 --> 00:05:27,740
you also have a lot of and saying is

00:05:25,729 --> 00:05:31,279
this a cat or a dog or a wombats not

00:05:27,740 --> 00:05:33,259
really going to cut it so now if you did

00:05:31,279 --> 00:05:35,300
want image classification there was a

00:05:33,259 --> 00:05:37,789
really good one last year on satellite

00:05:35,300 --> 00:05:39,199
imagery and if you really wanted one

00:05:37,789 --> 00:05:42,020
that's just on the numeric model

00:05:39,199 --> 00:05:43,580
fiddling numeric model fitting there was

00:05:42,020 --> 00:05:44,719
one two years ago where they went

00:05:43,580 --> 00:05:46,099
through all of it and again they've got

00:05:44,719 --> 00:05:46,550
the code so if that was your sort of

00:05:46,099 --> 00:05:48,969
thing

00:05:46,550 --> 00:05:51,469
Berlin buzzwords has covered you before

00:05:48,969 --> 00:05:56,000
but what we're interested in today is

00:05:51,469 --> 00:05:58,039
text so I have lots and lots of

00:05:56,000 --> 00:06:00,169
documents I've got policies I've got

00:05:58,039 --> 00:06:01,490
procedures I've got training guides I've

00:06:00,169 --> 00:06:03,649
got help information

00:06:01,490 --> 00:06:06,289
I've got RFPs and all that sort of thing

00:06:03,649 --> 00:06:09,919
I also have a whole load of people's

00:06:06,289 --> 00:06:11,270
medical data trial data but for ethical

00:06:09,919 --> 00:06:13,430
and compliance reasons I'm not allowed

00:06:11,270 --> 00:06:14,750
to touch that have to get ethics

00:06:13,430 --> 00:06:16,569
committee approval and so on so I'm not

00:06:14,750 --> 00:06:18,800
going to touch on any of the work

00:06:16,569 --> 00:06:21,649
medical data stuff I'm only looking at

00:06:18,800 --> 00:06:23,389
the text that we've got but I think a

00:06:21,649 --> 00:06:27,620
lot of us do have lots and lots of text

00:06:23,389 --> 00:06:29,719
out there so I need to do a whole load

00:06:27,620 --> 00:06:32,089
of in exact searching over these

00:06:29,719 --> 00:06:34,729
documents so for example I've got a

00:06:32,089 --> 00:06:36,680
whole bunch of project training and help

00:06:34,729 --> 00:06:38,300
stuff and I've got someone who's new to

00:06:36,680 --> 00:06:39,889
the project and they come in and they're

00:06:38,300 --> 00:06:41,659
like okay so I need to do this thing

00:06:39,889 --> 00:06:43,099
here's the general term and they look in

00:06:41,659 --> 00:06:44,990
the training manual and it uses the

00:06:43,099 --> 00:06:47,210
project specific naming

00:06:44,990 --> 00:06:49,310
we've got a lot of abbreviations in our

00:06:47,210 --> 00:06:51,170
company we've got a lot of weird naming

00:06:49,310 --> 00:06:53,000
that we use I think a lot of you also

00:06:51,170 --> 00:06:55,520
have that the size of your company goes

00:06:53,000 --> 00:06:57,650
up the number of abbreviations and weird

00:06:55,520 --> 00:06:59,930
for sources kind of goes up so at the

00:06:57,650 --> 00:07:01,520
moment our workaround is that people use

00:06:59,930 --> 00:07:03,860
the project just message their team lead

00:07:01,520 --> 00:07:06,310
and say hey how do I do this there's

00:07:03,860 --> 00:07:09,410
some definite scaling problems with that

00:07:06,310 --> 00:07:11,180
another problem we're a kind of

00:07:09,410 --> 00:07:13,040
consulting firm we deal with lots of big

00:07:11,180 --> 00:07:14,900
customers and they keep sending us

00:07:13,040 --> 00:07:17,210
questionnaires and those questionnaires

00:07:14,900 --> 00:07:19,610
come in in the format of the customer

00:07:17,210 --> 00:07:21,350
not in our format and they all use

00:07:19,610 --> 00:07:23,840
different wording to describe the same

00:07:21,350 --> 00:07:25,730
thing so at the moment lots of really

00:07:23,840 --> 00:07:29,210
busy people have to keep reentering the

00:07:25,730 --> 00:07:30,650
same answers into the RFP questionnaires

00:07:29,210 --> 00:07:32,480
even though they altered it through

00:07:30,650 --> 00:07:34,790
before because the different companies

00:07:32,480 --> 00:07:37,040
use different naming and the sales guys

00:07:34,790 --> 00:07:40,750
don't understand fully what we do so

00:07:37,040 --> 00:07:44,900
they can't do the in exact matching so

00:07:40,750 --> 00:07:46,400
can we can we do something now I can't

00:07:44,900 --> 00:07:48,530
share with you all of my training

00:07:46,400 --> 00:07:50,600
material and I can't share with you all

00:07:48,530 --> 00:07:51,680
of the RFP responses if you want an RFP

00:07:50,600 --> 00:07:54,050
response must you've got to come and

00:07:51,680 --> 00:07:56,690
contract with us but what I do have is

00:07:54,050 --> 00:07:58,970
all of the berlin buzzword talks so

00:07:56,690 --> 00:08:00,770
we've got titles and we got abstracts

00:07:58,970 --> 00:08:03,610
and we've got classifications so let's

00:08:00,770 --> 00:08:07,670
see if we can use these as a proxy for

00:08:03,610 --> 00:08:09,020
doing some text and somatic ok you've

00:08:07,670 --> 00:08:10,880
all been on the website you've all seen

00:08:09,020 --> 00:08:12,860
things like this so we've got speaker

00:08:10,880 --> 00:08:18,680
we've got the track we've got the

00:08:12,860 --> 00:08:19,910
abstract all sorts of text here so what

00:08:18,680 --> 00:08:22,220
we're going to try and do is partly

00:08:19,910 --> 00:08:23,930
clustering so what kind of talks are

00:08:22,220 --> 00:08:26,930
similar to what other kind of talks

00:08:23,930 --> 00:08:28,400
what words in those talks are similar to

00:08:26,930 --> 00:08:29,990
what other words in those talks and

00:08:28,400 --> 00:08:32,990
partly it's going to be a recommendation

00:08:29,990 --> 00:08:35,000
problem so if you went to one talk and

00:08:32,990 --> 00:08:36,260
you're interested in search then what

00:08:35,000 --> 00:08:38,330
other talks are you going to be

00:08:36,260 --> 00:08:41,060
interested in but it's not exact

00:08:38,330 --> 00:08:43,940
matching I don't have classification

00:08:41,060 --> 00:08:45,950
labels and I didn't go around last year

00:08:43,940 --> 00:08:47,600
pigeonholing every single person and

00:08:45,950 --> 00:08:49,190
saying which talks did you go to and

00:08:47,600 --> 00:08:52,010
which exact keywords did they match I

00:08:49,190 --> 00:08:54,020
haven't got that and it does have to

00:08:52,010 --> 00:08:56,450
cope with people who give funny talk

00:08:54,020 --> 00:08:58,529
titles and cool talk titles which

00:08:56,450 --> 00:09:00,699
sometimes I must admit is myself

00:08:58,529 --> 00:09:03,279
so we've got to deal with in exact

00:09:00,699 --> 00:09:05,439
matching here but that maps onto my

00:09:03,279 --> 00:09:07,149
problems at work where people use weird

00:09:05,439 --> 00:09:11,319
naming and weird abbreviations and

00:09:07,149 --> 00:09:14,049
people don't know those so first issue

00:09:11,319 --> 00:09:15,610
my a IML frameworks don't like word

00:09:14,049 --> 00:09:18,670
documents and they don't like

00:09:15,610 --> 00:09:20,619
spreadsheets luckily Apache tikka its

00:09:18,670 --> 00:09:23,049
project that hides all of that

00:09:20,619 --> 00:09:24,639
complexity it's in Java you feed it a

00:09:23,049 --> 00:09:26,799
thing you like I don't know what this is

00:09:24,639 --> 00:09:29,730
figure it out and it gives you back some

00:09:26,799 --> 00:09:32,499
nice clean HTML that we can then process

00:09:29,730 --> 00:09:33,790
so at work that's what we do we feed in

00:09:32,499 --> 00:09:36,639
all of our spreadsheets all of our

00:09:33,790 --> 00:09:39,309
policy Word documents outcomes HTML

00:09:36,639 --> 00:09:41,649
which hung it up based on the the slides

00:09:39,309 --> 00:09:44,410
or the tables and then we turn now to

00:09:41,649 --> 00:09:45,639
JSON I could cheat for this talk so I

00:09:44,410 --> 00:09:47,470
just use beautifulsoup

00:09:45,639 --> 00:09:50,350
scraped the whole of the Berlin

00:09:47,470 --> 00:09:53,410
buzzwords website and spat out a load of

00:09:50,350 --> 00:09:57,730
simple JSON so level track abstract

00:09:53,410 --> 00:09:59,199
title URL all nice and easy so taking

00:09:57,730 --> 00:10:04,989
all the Berlin buzzword talks put it in

00:09:59,199 --> 00:10:06,339
JSON we set know just as the ML

00:10:04,989 --> 00:10:11,189
frameworks don't work with spreadsheets

00:10:06,339 --> 00:10:14,499
they also don't work with JSON of text

00:10:11,189 --> 00:10:18,220
so what do we need well what we mostly

00:10:14,499 --> 00:10:22,059
need is values between minus 0 so minus

00:10:18,220 --> 00:10:23,589
1 and plus 1 or 0 and 1 and we need one

00:10:22,059 --> 00:10:25,509
value for each feature of the thing that

00:10:23,589 --> 00:10:27,309
we're going to learn on it could be a

00:10:25,509 --> 00:10:29,470
really sparse one with a handful of

00:10:27,309 --> 00:10:32,049
nonzero values or it could be a really

00:10:29,470 --> 00:10:33,639
dense one we're almost everything set we

00:10:32,049 --> 00:10:35,350
can have loads of features but that

00:10:33,639 --> 00:10:41,529
means we need loads more memory and bit

00:10:35,350 --> 00:10:43,119
more CPU but what we've got is text does

00:10:41,529 --> 00:10:45,610
that look like a bunch of ones and

00:10:43,119 --> 00:10:47,769
zeroes I mean yeah we could turn that

00:10:45,610 --> 00:10:49,169
into the ascii hex codes and get a load

00:10:47,769 --> 00:10:51,129
of ones and zeroes but that's probably

00:10:49,169 --> 00:10:57,689
not going to be the best feature

00:10:51,129 --> 00:11:01,689
representation so few wording things so

00:10:57,689 --> 00:11:03,879
features are the input variables so one

00:11:01,689 --> 00:11:05,529
specific aspect of the thing that we're

00:11:03,879 --> 00:11:07,149
trying to predict yet could be someone's

00:11:05,529 --> 00:11:09,039
height it could be someone's weight it

00:11:07,149 --> 00:11:10,270
could be the first RGB channel in an

00:11:09,039 --> 00:11:12,339
image so the

00:11:10,270 --> 00:11:16,870
we're going to feed in multiple features

00:11:12,339 --> 00:11:18,610
to our model and a lot of the work goes

00:11:16,870 --> 00:11:22,060
on to selecting what is the right

00:11:18,610 --> 00:11:24,760
feature now a label is a single value

00:11:22,060 --> 00:11:26,980
that all of those features represent so

00:11:24,760 --> 00:11:28,899
if we feed in all the image data all the

00:11:26,980 --> 00:11:30,910
different RGB channels those are our

00:11:28,899 --> 00:11:33,820
features and the label it should say

00:11:30,910 --> 00:11:36,010
this is a dog this is a cat or we might

00:11:33,820 --> 00:11:38,170
feed in a whole bunch information about

00:11:36,010 --> 00:11:40,330
a house and say this is where it is this

00:11:38,170 --> 00:11:42,550
is how many bedrooms it's got this is

00:11:40,330 --> 00:11:43,779
what color its painted and I want you to

00:11:42,550 --> 00:11:46,060
predict that this is how much the house

00:11:43,779 --> 00:11:48,430
is worth okay

00:11:46,060 --> 00:11:50,230
training is the process by which we

00:11:48,430 --> 00:11:53,200
stuff a load of features into a model

00:11:50,230 --> 00:11:54,670
and it builds model and then inference

00:11:53,200 --> 00:11:57,029
is where we stuff a load of brand new

00:11:54,670 --> 00:12:00,160
features in and it gives us an answer

00:11:57,029 --> 00:12:02,860
that's all new to you have a look at the

00:12:00,160 --> 00:12:06,730
Google crash course they've got some bit

00:12:02,860 --> 00:12:09,670
more detail in there and so a little bit

00:12:06,730 --> 00:12:12,310
more regression is all about predicting

00:12:09,670 --> 00:12:14,560
continuous values here's the location

00:12:12,310 --> 00:12:16,360
number of bedrooms give me a answer

00:12:14,560 --> 00:12:19,120
between 1 & 2 million for how much this

00:12:16,360 --> 00:12:22,420
house is worth classification is for

00:12:19,120 --> 00:12:25,360
discrete values here's an image dog cat

00:12:22,420 --> 00:12:27,070
wombat give me one specific answer and

00:12:25,360 --> 00:12:29,589
then clustering is where you're not

00:12:27,070 --> 00:12:31,510
actually sure what goes together see you

00:12:29,589 --> 00:12:32,920
like here's a lot of images kind of

00:12:31,510 --> 00:12:34,720
figure out which ones are like each

00:12:32,920 --> 00:12:37,740
other and stuff them together please

00:12:34,720 --> 00:12:41,290
so that's unsupervised machine learning

00:12:37,740 --> 00:12:43,930
okay so we've got our text and we need a

00:12:41,290 --> 00:12:46,600
load of ones and zeros the first thing

00:12:43,930 --> 00:12:48,430
that we have to do is tokenization so

00:12:46,600 --> 00:12:50,380
going to turn all of those sentences all

00:12:48,430 --> 00:12:52,240
of those paragraphs down into little

00:12:50,380 --> 00:12:53,829
chunks and the very simple way to do

00:12:52,240 --> 00:12:56,980
that is just split on whitespace and

00:12:53,829 --> 00:12:59,320
punctuation if that's new to you any

00:12:56,980 --> 00:13:00,700
kind of Lucene intro talk will will help

00:12:59,320 --> 00:13:04,180
you there we're going to take it and

00:13:00,700 --> 00:13:06,010
split down into individual words okay

00:13:04,180 --> 00:13:09,100
now we're going to build a term

00:13:06,010 --> 00:13:11,740
dictionary so for each individual term

00:13:09,100 --> 00:13:14,079
that we've broken up each token we're

00:13:11,740 --> 00:13:16,959
going to give it an index so basically a

00:13:14,079 --> 00:13:19,060
giant list dictionary lookup so we've

00:13:16,959 --> 00:13:22,060
got mouse ran up the clock nice and easy

00:13:19,060 --> 00:13:24,040
that's the first one so 1 2 3 4 5 and

00:13:22,060 --> 00:13:28,360
then the mouse ran down

00:13:24,040 --> 00:13:31,000
the one Mouse to ran three down six so

00:13:28,360 --> 00:13:34,089
we've got from our text to a load of

00:13:31,000 --> 00:13:35,860
term indexes we're getting there it's

00:13:34,089 --> 00:13:39,759
not still ones and zeros but but we've

00:13:35,860 --> 00:13:41,920
got some numbers so unique index unique

00:13:39,759 --> 00:13:46,509
ID for each term and then figure out

00:13:41,920 --> 00:13:51,819
which terms go where now the trick is to

00:13:46,509 --> 00:13:53,920
invert that so the two main ways out

00:13:51,819 --> 00:13:56,310
there are one hot encoding where

00:13:53,920 --> 00:13:58,269
everything is either 1 or 0 or

00:13:56,310 --> 00:14:00,430
continuous bag-of-words

00:13:58,269 --> 00:14:03,610
so the number of times that each word

00:14:00,430 --> 00:14:06,089
occurs so in the first sentence here the

00:14:03,610 --> 00:14:08,940
mouse ran up the clock the occurs twice

00:14:06,089 --> 00:14:12,699
so for the term for the it's gonna be 2

00:14:08,940 --> 00:14:16,620
and then everything else is 1 or 0 so

00:14:12,699 --> 00:14:20,440
almost there and then our final trick is

00:14:16,620 --> 00:14:23,350
tf-idf so if a document is going to

00:14:20,440 --> 00:14:26,560
contain a term a lot so if a document

00:14:23,350 --> 00:14:28,810
keeps using the word cat then probably

00:14:26,560 --> 00:14:30,850
when someone searching for cat we want

00:14:28,810 --> 00:14:34,660
the document with cat in a lot to come

00:14:30,850 --> 00:14:38,889
up and if we've got sort of phrase query

00:14:34,660 --> 00:14:41,260
and we're looking for the black cat and

00:14:38,889 --> 00:14:43,779
almost every document we have contains

00:14:41,260 --> 00:14:46,630
the word the' then that's probably not

00:14:43,779 --> 00:14:48,819
that relevant to our query but if almost

00:14:46,630 --> 00:14:49,750
no documents contain the word cat then

00:14:48,819 --> 00:14:51,910
that's probably going to be the most

00:14:49,750 --> 00:14:54,250
important bit in our query so we want to

00:14:51,910 --> 00:14:57,310
boost the terms that are rare and push

00:14:54,250 --> 00:14:59,500
down the terms that are quite common ok

00:14:57,310 --> 00:15:01,839
and then if our document is really

00:14:59,500 --> 00:15:03,940
really long it's going to have loads of

00:15:01,839 --> 00:15:05,529
words in it so it's not going to be

00:15:03,940 --> 00:15:07,209
quite as relevant as a really short

00:15:05,529 --> 00:15:09,160
document because the terms are going to

00:15:07,209 --> 00:15:11,079
be more important in that so we want to

00:15:09,160 --> 00:15:13,300
wait the rarer terms higher the common

00:15:11,079 --> 00:15:15,459
terms lower want to wait the longer

00:15:13,300 --> 00:15:20,620
documents lower the shorter documents

00:15:15,459 --> 00:15:23,529
fire and tf-idf is the simplest way to

00:15:20,620 --> 00:15:25,540
do this and it is the one that is most

00:15:23,529 --> 00:15:27,040
commonly implemented in all of the

00:15:25,540 --> 00:15:30,189
libraries that you'll be working with

00:15:27,040 --> 00:15:31,959
it's not the best so BM 25 is another

00:15:30,189 --> 00:15:33,339
one there were a few more talks at

00:15:31,959 --> 00:15:34,899
Berlin buzzwords as well in the past

00:15:33,339 --> 00:15:37,690
about better ways of doing it

00:15:34,899 --> 00:15:40,870
but it has the advantage of being

00:15:37,690 --> 00:15:42,880
relatively simple and whatever language

00:15:40,870 --> 00:15:45,130
whatever framework you are trying to

00:15:42,880 --> 00:15:46,720
play with it's gonna be there so you

00:15:45,130 --> 00:15:48,610
don't actually have to worry about the

00:15:46,720 --> 00:15:50,620
maths behind this the implementation

00:15:48,610 --> 00:15:54,130
details behind this you can just say

00:15:50,620 --> 00:15:55,330
import tf-idf require tf-idf and it's

00:15:54,130 --> 00:15:56,710
just gonna be there it's going to be

00:15:55,330 --> 00:15:58,750
implemented it's gonna be unit tested

00:15:56,710 --> 00:16:01,180
and we don't have to worry too much on

00:15:58,750 --> 00:16:04,180
the details and what's going to happen

00:16:01,180 --> 00:16:06,220
is we're going to feed it a load of text

00:16:04,180 --> 00:16:07,720
it's going to tokenize it for us it's

00:16:06,220 --> 00:16:09,100
going to build the term dictionary it's

00:16:07,720 --> 00:16:12,280
going to calculate the scores and we're

00:16:09,100 --> 00:16:16,120
going to get back values between 0 and 1

00:16:12,280 --> 00:16:18,240
0 that term does not occur 1 that term

00:16:16,120 --> 00:16:20,650
is really important in that document so

00:16:18,240 --> 00:16:24,610
we've got our ones and zeros so we're

00:16:20,650 --> 00:16:27,040
looking good but my next challenge

00:16:24,610 --> 00:16:29,710
is that I don't actually know what the

00:16:27,040 --> 00:16:31,240
right answer is I haven't gone round to

00:16:29,710 --> 00:16:33,160
all of you and asked you which talks you

00:16:31,240 --> 00:16:35,080
wanted to see and which search terms you

00:16:33,160 --> 00:16:37,030
were looking for I haven't managed to go

00:16:35,080 --> 00:16:39,370
round all the new starters on my

00:16:37,030 --> 00:16:41,700
projects at work and ask them what they

00:16:39,370 --> 00:16:45,160
were trying to find and see what they

00:16:41,700 --> 00:16:46,900
needed you can feed that in later but

00:16:45,160 --> 00:16:50,350
right at the moment I don't know the

00:16:46,900 --> 00:16:52,150
right answer and so I can't do a simple

00:16:50,350 --> 00:16:54,070
classification I can't train the model

00:16:52,150 --> 00:16:55,090
and say here is my query here is the

00:16:54,070 --> 00:16:57,460
talk that you should match because I

00:16:55,090 --> 00:16:59,920
don't know it so I have to do a little

00:16:57,460 --> 00:17:01,210
bit of fuzziness so what we're going to

00:16:59,920 --> 00:17:03,640
start with is just simple text

00:17:01,210 --> 00:17:05,949
similarity the same kind of way that it

00:17:03,640 --> 00:17:08,560
works in Lucene in solar and elastic

00:17:05,949 --> 00:17:09,910
we're going to say look for terms that

00:17:08,560 --> 00:17:14,079
are similar to other terms and match

00:17:09,910 --> 00:17:16,209
based on that so first a little bit of

00:17:14,079 --> 00:17:17,319
AI we're going to build a classification

00:17:16,209 --> 00:17:19,360
model for our talks

00:17:17,319 --> 00:17:21,480
and we're going to feed in the title in

00:17:19,360 --> 00:17:24,610
the abstract chuck it through a tf-idf

00:17:21,480 --> 00:17:28,060
then we're gonna ask a model to classify

00:17:24,610 --> 00:17:30,790
a query cluster it and say which talk is

00:17:28,060 --> 00:17:33,130
most like our query and then finally

00:17:30,790 --> 00:17:35,860
we're going to do a matching around and

00:17:33,130 --> 00:17:39,250
say just based on simple text similarity

00:17:35,860 --> 00:17:43,420
which are the talks are like that encode

00:17:39,250 --> 00:17:47,020
it looks like this so build up our

00:17:43,420 --> 00:17:49,060
tf-idf vector find out how many things

00:17:47,020 --> 00:17:51,340
are in it so in this case I've got 294

00:17:49,060 --> 00:17:53,500
talks and it came out as

00:17:51,340 --> 00:17:55,120
mm different terms I'm going to

00:17:53,500 --> 00:17:57,400
calculate the similarity between each

00:17:55,120 --> 00:18:00,210
talk in each other talk I mean use a

00:17:57,400 --> 00:18:03,900
multinomial naive bayes really simple

00:18:00,210 --> 00:18:08,470
but quite powerful ai framework and

00:18:03,900 --> 00:18:11,350
going to learn and build a model so this

00:18:08,470 --> 00:18:14,470
probably would have taken in the 1980s a

00:18:11,350 --> 00:18:17,260
man year or two to do and we've done it

00:18:14,470 --> 00:18:20,740
in less than ten lines of Python

00:18:17,260 --> 00:18:23,380
it is wonderful living in the future and

00:18:20,740 --> 00:18:25,570
this is all done with scikit-learn which

00:18:23,380 --> 00:18:28,060
is a Python library for machine learning

00:18:25,570 --> 00:18:30,010
other libraries exist other languages

00:18:28,060 --> 00:18:31,120
exist pretty much whatever you're going

00:18:30,010 --> 00:18:32,740
to want to do it in it's going to be

00:18:31,120 --> 00:18:34,960
available the reason that we're picking

00:18:32,740 --> 00:18:36,990
scikit-learn here is that we're

00:18:34,960 --> 00:18:40,690
optimizing for developer productivity

00:18:36,990 --> 00:18:42,640
it's a bit slower than tensorflow but

00:18:40,690 --> 00:18:44,800
it's really easy to follow and it's

00:18:42,640 --> 00:18:46,600
really easy for me to train my new data

00:18:44,800 --> 00:18:49,630
scientists in how it works or a

00:18:46,600 --> 00:18:51,550
tensorflow super fast but you could have

00:18:49,630 --> 00:18:53,530
a lot of knowledge to start before all

00:18:51,550 --> 00:18:54,520
the documentation make sense so I'd say

00:18:53,530 --> 00:18:57,670
if you're new to all this

00:18:54,520 --> 00:18:59,740
pick something simple later on when

00:18:57,670 --> 00:19:01,780
you're models got a lot bigger you got a

00:18:59,740 --> 00:19:03,910
lot more complexity then go down one of

00:19:01,780 --> 00:19:06,130
the super fast routes but trying to

00:19:03,910 --> 00:19:07,780
learn machine learning and tensorflow at

00:19:06,130 --> 00:19:09,700
the same time is a bit more of a

00:19:07,780 --> 00:19:14,650
challenge and especially if you're not

00:19:09,700 --> 00:19:17,430
just doing cat or hot dog so yeah here's

00:19:14,650 --> 00:19:20,860
our code and then finally to do a query

00:19:17,430 --> 00:19:24,450
we feed in some text we ask the model to

00:19:20,860 --> 00:19:28,000
predict the talk most like it then we

00:19:24,450 --> 00:19:29,590
figure out which what the score is so

00:19:28,000 --> 00:19:32,530
what the similarity is between each talk

00:19:29,590 --> 00:19:34,840
sort it by their similarity to the talk

00:19:32,530 --> 00:19:38,070
that I model has suggested and then

00:19:34,840 --> 00:19:42,010
print those out not the best way but

00:19:38,070 --> 00:19:45,790
surprisingly effective so let's try a

00:19:42,010 --> 00:19:48,400
live demo this is hopefully going to

00:19:45,790 --> 00:19:49,780
work so here is the ipython notebook

00:19:48,400 --> 00:19:55,090
that we were having a look at earlier

00:19:49,780 --> 00:19:56,560
and we built up our model already we try

00:19:55,090 --> 00:19:59,320
and make that text a bit bigger for you

00:19:56,560 --> 00:20:01,060
so as you see it's the same kind of code

00:19:59,320 --> 00:20:04,460
that I've just shown on the screen

00:20:01,060 --> 00:20:10,260
before and then

00:20:04,460 --> 00:20:12,720
would someone like to suggest a talk

00:20:10,260 --> 00:20:17,300
title or a query or something for us to

00:20:12,720 --> 00:20:32,520
work on someone near the front maybe

00:20:17,300 --> 00:20:40,340
okay let's try no I didn't think it

00:20:32,520 --> 00:20:42,930
actually took that like demo yep I

00:20:40,340 --> 00:20:45,600
sometimes get this wrong alright so here

00:20:42,930 --> 00:20:47,040
we are here are some of the talks that

00:20:45,600 --> 00:20:55,070
it's recommended for machine learning

00:20:47,040 --> 00:20:59,100
and it's not that great actually

00:20:55,070 --> 00:21:02,190
it's okay but it's not amazing so what

00:20:59,100 --> 00:21:04,620
can we do so the next thing we can try

00:21:02,190 --> 00:21:06,510
is clustering so a clustering is where

00:21:04,620 --> 00:21:08,520
we want the machine learning system to

00:21:06,510 --> 00:21:12,060
figure out what is similar to other

00:21:08,520 --> 00:21:13,650
things without the help of a label we've

00:21:12,060 --> 00:21:15,740
got the label that's classification

00:21:13,650 --> 00:21:18,300
that's dog that's the hot dog easy

00:21:15,740 --> 00:21:22,070
clustering is where we don't quite know

00:21:18,300 --> 00:21:25,920
upfront what the right answer should be

00:21:22,070 --> 00:21:28,320
so the best one to start with is usually

00:21:25,920 --> 00:21:30,120
k-means so it comes from signal

00:21:28,320 --> 00:21:33,120
processing so we're going to group end

00:21:30,120 --> 00:21:34,320
things into K groups and we're going to

00:21:33,120 --> 00:21:38,510
do that in a way where we're trying to

00:21:34,320 --> 00:21:43,080
minimize the error so how many clusters

00:21:38,510 --> 00:21:46,110
so I'm if we've got 294 talks and when

00:21:43,080 --> 00:21:48,960
you make 294 clusters we've got 0 error

00:21:46,110 --> 00:21:50,970
every talk is in its own cluster it's

00:21:48,960 --> 00:21:53,340
not really actually helped us with the

00:21:50,970 --> 00:21:54,840
grouping though if we have one single

00:21:53,340 --> 00:21:56,760
cluster and put everything in together

00:21:54,840 --> 00:21:58,980
then we're gonna have the maximum error

00:21:56,760 --> 00:22:01,380
and again we haven't really caught

00:21:58,980 --> 00:22:04,380
anything useful so we sort of need

00:22:01,380 --> 00:22:05,700
something in between the two where most

00:22:04,380 --> 00:22:09,360
things are grouped with other things

00:22:05,700 --> 00:22:12,360
like them and the errors fairly low if

00:22:09,360 --> 00:22:13,860
you know what your labels are there's a

00:22:12,360 --> 00:22:16,800
whole bunch of techniques you can use

00:22:13,860 --> 00:22:17,460
for figuring out which cluster size is

00:22:16,800 --> 00:22:19,170
best for you

00:22:17,460 --> 00:22:21,960
but I haven't got that because I don't

00:22:19,170 --> 00:22:23,340
actually know the right answer so the

00:22:21,960 --> 00:22:25,380
main two we've got available

00:22:23,340 --> 00:22:27,030
our average silhouette and gap statistic

00:22:25,380 --> 00:22:28,980
measures which try and give us an idea

00:22:27,030 --> 00:22:33,300
of how effective things are fitting in

00:22:28,980 --> 00:22:34,890
our cluster I'm now the next problem

00:22:33,300 --> 00:22:37,080
with k-means is it's not completely

00:22:34,890 --> 00:22:39,570
deterministic it sort of wanders down

00:22:37,080 --> 00:22:42,090
the graph until it finds a nice low

00:22:39,570 --> 00:22:43,500
point and stops now it might have

00:22:42,090 --> 00:22:45,540
wandered a little way down and found a

00:22:43,500 --> 00:22:47,310
little bump and got stuck in a sort of

00:22:45,540 --> 00:22:49,470
ditch halfway down the hill or it might

00:22:47,310 --> 00:22:50,580
make it all the way to the bottom so we

00:22:49,470 --> 00:22:52,020
have to run it a whole bunch of

00:22:50,580 --> 00:22:54,150
different time starting in different

00:22:52,020 --> 00:22:55,980
places and then take the lowest point

00:22:54,150 --> 00:22:57,780
that it's reached so this is the next

00:22:55,980 --> 00:22:59,910
thing to know that your machine learning

00:22:57,780 --> 00:23:01,470
journey is it's not always going to give

00:22:59,910 --> 00:23:03,150
you the same answer each time you run it

00:23:01,470 --> 00:23:04,740
and you have to run it a bunch of times

00:23:03,150 --> 00:23:07,770
to be sure that you've got the best

00:23:04,740 --> 00:23:09,810
answer possible when you had your nice

00:23:07,770 --> 00:23:11,310
simple linear program that was going to

00:23:09,810 --> 00:23:12,900
do some filtering and then give you an

00:23:11,310 --> 00:23:14,370
answer you ran at once there's the

00:23:12,900 --> 00:23:16,440
answer you run it again there's the same

00:23:14,370 --> 00:23:18,360
answer machine learning doesn't always

00:23:16,440 --> 00:23:20,460
work like that if you have exactly the

00:23:18,360 --> 00:23:22,170
same seed each time and you're not using

00:23:20,460 --> 00:23:23,580
the randomness and using the same size

00:23:22,170 --> 00:23:25,950
steps you should be able to get the same

00:23:23,580 --> 00:23:27,360
answer each time but if you're picking a

00:23:25,950 --> 00:23:29,160
different random seed each time you run

00:23:27,360 --> 00:23:30,990
it may be picking different parameters

00:23:29,160 --> 00:23:33,720
you could get a different answer out on

00:23:30,990 --> 00:23:36,960
the same input data using the same code

00:23:33,720 --> 00:23:38,430
just based on these random seeds that

00:23:36,960 --> 00:23:39,180
could mean that the next time you run it

00:23:38,430 --> 00:23:43,560
it gets better

00:23:39,180 --> 00:23:45,840
or it might get worse if you care about

00:23:43,560 --> 00:23:48,510
that make a note of the seed and when

00:23:45,840 --> 00:23:50,130
you save the model save all the seeds

00:23:48,510 --> 00:23:53,280
and the parameters that we used to build

00:23:50,130 --> 00:23:54,660
it so you can recreate it otherwise you

00:23:53,280 --> 00:23:57,420
end up in situation where you build this

00:23:54,660 --> 00:23:58,800
amazing recommenda model and then you've

00:23:57,420 --> 00:24:00,270
also come to you and says oh that's

00:23:58,800 --> 00:24:02,340
wonderful so now we've got a little bit

00:24:00,270 --> 00:24:03,390
more data can we add that in and you go

00:24:02,340 --> 00:24:07,740
hmm

00:24:03,390 --> 00:24:09,090
no your models probably not let me stuck

00:24:07,740 --> 00:24:10,530
in time so make sure that you've

00:24:09,090 --> 00:24:12,390
captured everything that went into

00:24:10,530 --> 00:24:14,340
building it which is not just the data

00:24:12,390 --> 00:24:16,830
and not just the feature extraction

00:24:14,340 --> 00:24:18,420
it's also all of the hyper parameters

00:24:16,830 --> 00:24:19,800
that you fed it like the number of steps

00:24:18,420 --> 00:24:22,320
and the random seats so that you can

00:24:19,800 --> 00:24:24,330
recreate it so we're gonna have to run

00:24:22,320 --> 00:24:26,280
our k-means clustering a few times at

00:24:24,330 --> 00:24:28,659
each point and then try and see which

00:24:26,280 --> 00:24:32,779
size cluster is going to work best

00:24:28,659 --> 00:24:34,279
so encode we're gonna have a range of

00:24:32,779 --> 00:24:36,679
fluster sizes that we're gonna try and

00:24:34,279 --> 00:24:39,740
for each one we're going to build a

00:24:36,679 --> 00:24:41,690
clustering and then we're going to take

00:24:39,740 --> 00:24:44,029
the silhouette score to try and figure

00:24:41,690 --> 00:24:45,470
out roughly how accurate it is and then

00:24:44,029 --> 00:24:48,080
at the end we're going to sort and

00:24:45,470 --> 00:24:49,990
figure out which one was best so we run

00:24:48,080 --> 00:24:52,519
that and it's a lot slower than the

00:24:49,990 --> 00:24:56,330
naive phase and we end up with something

00:24:52,519 --> 00:24:58,759
like this so as you see start off with

00:24:56,330 --> 00:25:01,490
only a few clusters the accuracy it's

00:24:58,759 --> 00:25:03,230
not that great if we end up up in the

00:25:01,490 --> 00:25:04,730
top right we've got a lot more clusters

00:25:03,230 --> 00:25:06,799
but then we've got actually less

00:25:04,730 --> 00:25:09,019
grouping together each cluster has fewer

00:25:06,799 --> 00:25:11,659
things in and the schools going up but

00:25:09,019 --> 00:25:14,240
as we move up there's local maxima

00:25:11,659 --> 00:25:16,190
minima it's not just a nice smooth

00:25:14,240 --> 00:25:17,600
straight line some cluster sizes are

00:25:16,190 --> 00:25:19,549
better than others just based on our

00:25:17,600 --> 00:25:22,279
input data so we're going to look at

00:25:19,549 --> 00:25:25,129
this and say right well we want about 50

00:25:22,279 --> 00:25:26,720
clusters based on finger in the air

00:25:25,129 --> 00:25:30,200
guess we think that's about as many is

00:25:26,720 --> 00:25:31,669
going to be the ideal so about 6 talks

00:25:30,200 --> 00:25:33,519
in each cluster so then we're looking

00:25:31,669 --> 00:25:36,889
for somewhere around the 50 mark where

00:25:33,519 --> 00:25:38,720
we've got a nice high value and then

00:25:36,889 --> 00:25:41,539
we'll take that as the best one to go

00:25:38,720 --> 00:25:43,519
for but again there's not a single

00:25:41,539 --> 00:25:46,309
simple answer you're going to have to

00:25:43,519 --> 00:25:48,169
start dealing with uncertainty dealing

00:25:46,309 --> 00:25:51,139
with errors dealing with things that

00:25:48,169 --> 00:25:51,830
don't move in a nice smooth fashion and

00:25:51,139 --> 00:25:52,490
you're gonna have to get comfortable

00:25:51,830 --> 00:25:54,350
with it

00:25:52,490 --> 00:25:56,629
which for a lot of us used to nice

00:25:54,350 --> 00:26:01,220
deterministic programs is a bit bit of a

00:25:56,629 --> 00:26:02,929
change okay so we had a twenty to thirty

00:26:01,220 --> 00:26:05,090
thousand different dimensions two

00:26:02,929 --> 00:26:07,690
different terms and we're going to bring

00:26:05,090 --> 00:26:11,600
that down to about fifty fifty clusters

00:26:07,690 --> 00:26:15,679
now how do we see how that works on the

00:26:11,600 --> 00:26:18,830
whole our brains like about a maximum of

00:26:15,679 --> 00:26:21,649
three or four dimensions so you can have

00:26:18,830 --> 00:26:25,639
a 3d plot 3d different axis and then

00:26:21,649 --> 00:26:27,110
have different colors and that is about

00:26:25,639 --> 00:26:29,749
the limit that you can really cope with

00:26:27,110 --> 00:26:31,159
and even that's advanced and two to

00:26:29,749 --> 00:26:34,249
three dimensions is about what we can

00:26:31,159 --> 00:26:35,809
cope with but we started off with 30,000

00:26:34,249 --> 00:26:38,600
and we've just reduced it down to 50

00:26:35,809 --> 00:26:40,789
we're not gonna be able to get a nice

00:26:38,600 --> 00:26:42,520
pretty graph that we can look at and say

00:26:40,789 --> 00:26:44,860
yes that one's awesome

00:26:42,520 --> 00:26:48,040
one's worse we're going to have to throw

00:26:44,860 --> 00:26:51,340
away some more information so techniques

00:26:48,040 --> 00:26:52,540
like t-sne and pca let you do that throw

00:26:51,340 --> 00:26:54,850
away a whole bunch of the dimensions

00:26:52,540 --> 00:26:57,240
while keeping some of the information

00:26:54,850 --> 00:27:00,430
some of the relationships but not all

00:26:57,240 --> 00:27:02,470
just be aware that you might build a

00:27:00,430 --> 00:27:03,880
model feed it into a TSN a look at it

00:27:02,470 --> 00:27:06,820
and say oh that's beautiful we're all

00:27:03,880 --> 00:27:09,370
set but because it's mushed all the

00:27:06,820 --> 00:27:10,980
different dimensions down that might not

00:27:09,370 --> 00:27:14,110
mean it's perfect

00:27:10,980 --> 00:27:16,540
equally if it looks terrible in t-sne it

00:27:14,110 --> 00:27:20,440
might still be a good model these are

00:27:16,540 --> 00:27:24,630
kind of rough visual guides for us but

00:27:20,440 --> 00:27:28,210
they're not perfect answers so this is a

00:27:24,630 --> 00:27:30,550
TSN a plot and things are reasonably

00:27:28,210 --> 00:27:33,100
spaced out so that's probably quite good

00:27:30,550 --> 00:27:34,480
if everything was really close together

00:27:33,100 --> 00:27:35,890
then it wouldn't actually have done much

00:27:34,480 --> 00:27:38,380
clustering the fact that it's managed to

00:27:35,890 --> 00:27:40,780
group the different talks into different

00:27:38,380 --> 00:27:43,570
separate clusters seems to give us an

00:27:40,780 --> 00:27:46,570
idea that it's worked ok and it's group

00:27:43,570 --> 00:27:47,800
things together but I've got 50

00:27:46,570 --> 00:27:49,570
dimensions and I've just squished them

00:27:47,800 --> 00:27:51,820
into till on the page so I can't be

00:27:49,570 --> 00:27:56,910
certain so the only thing really to do

00:27:51,820 --> 00:27:59,920
is to test it now this was our raw data

00:27:56,910 --> 00:28:01,810
so this is the fifty thousand 330

00:27:59,920 --> 00:28:04,270
thousand different dimensions and then

00:28:01,810 --> 00:28:07,360
I've just plotted it in two dimensions

00:28:04,270 --> 00:28:10,600
and then the color is the cluster that

00:28:07,360 --> 00:28:15,280
it put things in now as I've got fifty

00:28:10,600 --> 00:28:17,260
different clusters and most of you are a

00:28:15,280 --> 00:28:19,720
long way from the screen and it's a bit

00:28:17,260 --> 00:28:22,720
hard to tell the different colors how

00:28:19,720 --> 00:28:24,550
well that's worked because I've got 15

00:28:22,720 --> 00:28:27,940
different yellows I've got 15 different

00:28:24,550 --> 00:28:29,800
blues so again you can have lovely

00:28:27,940 --> 00:28:32,920
pretty graphs but they don't necessarily

00:28:29,800 --> 00:28:35,080
help you in telling whether or not this

00:28:32,920 --> 00:28:37,150
has worked if you can get nice clean

00:28:35,080 --> 00:28:39,130
training data get your humans out there

00:28:37,150 --> 00:28:41,490
to go and classify things give you

00:28:39,130 --> 00:28:43,420
proper answers and do proper statistics

00:28:41,490 --> 00:28:50,140
trying to look at this and be like is

00:28:43,420 --> 00:28:53,980
that okay hmm maybe so and next a I

00:28:50,140 --> 00:28:55,929
approach is to identify the optimal

00:28:53,980 --> 00:28:58,480
cluster size which in this case seems

00:28:55,929 --> 00:29:01,990
b51 build the k-means clustering at that

00:28:58,480 --> 00:29:04,269
size match the text of our query into a

00:29:01,990 --> 00:29:07,360
cluster find the center of that cluster

00:29:04,269 --> 00:29:09,490
and then do regular sort of loosing

00:29:07,360 --> 00:29:15,700
style text similarity matching from

00:29:09,490 --> 00:29:17,679
there here's the code so with the

00:29:15,700 --> 00:29:19,419
k-means clustering it's going to group

00:29:17,679 --> 00:29:22,029
the stalks together and then it's going

00:29:19,419 --> 00:29:24,340
to tell us the center of that cluster

00:29:22,029 --> 00:29:25,840
and that center is going to be in the

00:29:24,340 --> 00:29:28,210
tf-idf space so it's going to be a

00:29:25,840 --> 00:29:29,830
virtual talk that is the middle of all

00:29:28,210 --> 00:29:31,419
of the other talks in the cluster so

00:29:29,830 --> 00:29:37,659
we're going to match on to that and work

00:29:31,419 --> 00:29:39,460
from there so does it work I'll get you

00:29:37,659 --> 00:29:50,409
to shout out some more query terms and

00:29:39,460 --> 00:29:56,139
we'll see if it's any better so who

00:29:50,409 --> 00:30:06,580
wants to suggest a query machine

00:29:56,139 --> 00:30:10,749
learning let's run it okay so here we

00:30:06,580 --> 00:30:12,309
are so these are what it thinks are the

00:30:10,749 --> 00:30:13,710
best talks and machine learning how to

00:30:12,309 --> 00:30:16,299
start company based on machine learning

00:30:13,710 --> 00:30:18,759
okay that one seems okay what makes

00:30:16,299 --> 00:30:21,820
machine learning algorithms work data

00:30:18,759 --> 00:30:24,249
preparation business intelligence yeah I

00:30:21,820 --> 00:30:25,809
think that one's worked okay what's some

00:30:24,249 --> 00:30:28,119
reasonable things and some of these

00:30:25,809 --> 00:30:29,740
don't actually contain the word the

00:30:28,119 --> 00:30:31,690
exact words machine learning so that's

00:30:29,740 --> 00:30:38,830
also quite good because we want to do

00:30:31,690 --> 00:30:40,570
similar ish sings and if you want to

00:30:38,830 --> 00:30:42,879
have a play the the notebook is there

00:30:40,570 --> 00:30:45,309
you can type in your very worst queries

00:30:42,879 --> 00:30:47,139
later date have a play around play

00:30:45,309 --> 00:30:50,860
around became in size and see how it

00:30:47,139 --> 00:30:53,769
does okay so the next kind of question

00:30:50,860 --> 00:30:55,629
is we've got the talk yes we know which

00:30:53,769 --> 00:30:58,990
year each of the berlin bus web talks

00:30:55,629 --> 00:31:01,269
are from equally on my RFP responses i

00:30:58,990 --> 00:31:03,730
know which year we gave those answers to

00:31:01,269 --> 00:31:05,259
a customer for my training material i

00:31:03,730 --> 00:31:07,450
know which year that training was given

00:31:05,259 --> 00:31:08,410
in so what what if i want to include

00:31:07,450 --> 00:31:11,760
that

00:31:08,410 --> 00:31:14,470
now we can't easily add it as a feature

00:31:11,760 --> 00:31:16,270
because when we're doing the query we

00:31:14,470 --> 00:31:21,670
don't have a year like the talk has a

00:31:16,270 --> 00:31:26,230
year query doesn't um if we add it at

00:31:21,670 --> 00:31:29,350
scoring time that's a bit harder because

00:31:26,230 --> 00:31:31,870
we're not scoring the query we're

00:31:29,350 --> 00:31:34,510
finding a similar talk to a query and

00:31:31,870 --> 00:31:36,040
then scoring based on that so if we were

00:31:34,510 --> 00:31:38,440
to actually had leucine we could do

00:31:36,040 --> 00:31:40,570
better because of the way it's working

00:31:38,440 --> 00:31:42,520
and so ideally we want to feed it into

00:31:40,570 --> 00:31:45,100
the model before we do the scoring now

00:31:42,520 --> 00:31:48,460
after but if we reduce the tf-idf

00:31:45,100 --> 00:31:51,760
weights by some factor based on the year

00:31:48,460 --> 00:31:53,560
we're changing where in the dimensional

00:31:51,760 --> 00:31:55,510
space they are and we might actually end

00:31:53,560 --> 00:31:58,690
up pushing talks into the wrong pluster

00:31:55,510 --> 00:32:02,740
just by reducing the beasts so it's not

00:31:58,690 --> 00:32:05,290
actually as easy as we'd hope for a next

00:32:02,740 --> 00:32:07,360
problem is that our data isn't long-term

00:32:05,290 --> 00:32:09,550
static all being well those can be

00:32:07,360 --> 00:32:10,990
Berlin bells words 11 next year and

00:32:09,550 --> 00:32:17,050
we're going to be then adding in

00:32:10,990 --> 00:32:18,640
additional talks likewise my training

00:32:17,050 --> 00:32:20,140
people at work are still writing new

00:32:18,640 --> 00:32:21,220
training and they keep feeding that in

00:32:20,140 --> 00:32:25,390
so we're going to have to keep

00:32:21,220 --> 00:32:27,820
rebuilding our model now let's say I was

00:32:25,390 --> 00:32:30,700
to force all of you to stay in the room

00:32:27,820 --> 00:32:32,350
not go to lunch get out a copy of the

00:32:30,700 --> 00:32:34,000
current program and scribble down what

00:32:32,350 --> 00:32:36,280
queries you'd have given for each of the

00:32:34,000 --> 00:32:38,470
talks in the program you'd probably hate

00:32:36,280 --> 00:32:41,380
me for that but we could get that data

00:32:38,470 --> 00:32:44,460
and then you'll come back in a year's

00:32:41,380 --> 00:32:46,870
time and it's not pretty classified

00:32:44,460 --> 00:32:50,320
because I didn't you talks in and we

00:32:46,870 --> 00:32:52,840
haven't got the classification so how do

00:32:50,320 --> 00:32:54,490
we even if we know the right answer for

00:32:52,840 --> 00:32:56,200
the query today how do we find out what

00:32:54,490 --> 00:32:58,090
the answer is for tomorrow so we're

00:32:56,200 --> 00:33:01,660
going to need to factor in some sort of

00:32:58,090 --> 00:33:03,970
known correct versus brand new data and

00:33:01,660 --> 00:33:07,330
make sure that the ml isn't prioritizing

00:33:03,970 --> 00:33:09,370
too much the well-known existing data at

00:33:07,330 --> 00:33:12,400
the expense of brand new data so the

00:33:09,370 --> 00:33:13,930
novelty factor which I don't actually

00:33:12,400 --> 00:33:14,980
have a good answer for right now but I'm

00:33:13,930 --> 00:33:17,200
just saying if you're thinking about

00:33:14,980 --> 00:33:18,820
your data and building your models think

00:33:17,200 --> 00:33:21,400
about what happens when brand new data

00:33:18,820 --> 00:33:23,020
gets fed in

00:33:21,400 --> 00:33:26,830
okay a little bit more on the

00:33:23,020 --> 00:33:28,240
tokenization and stop words you've come

00:33:26,830 --> 00:33:30,010
from a leucine elastic background you

00:33:28,240 --> 00:33:34,059
know all about this but if there's some

00:33:30,010 --> 00:33:36,280
very common words like the a they those

00:33:34,059 --> 00:33:37,990
kind of words that crop up loads we want

00:33:36,280 --> 00:33:40,510
to throw them away because it's going to

00:33:37,990 --> 00:33:42,730
shrink the size of our tf-idf matrix

00:33:40,510 --> 00:33:45,040
smaller size of the matrix the less

00:33:42,730 --> 00:33:46,930
memory we need and the faster our

00:33:45,040 --> 00:33:48,760
calculations are going to run but be

00:33:46,930 --> 00:33:51,309
aware that you need to have the right

00:33:48,760 --> 00:33:54,390
stop words firstly for your language and

00:33:51,309 --> 00:33:56,980
secondly for the domain of your text

00:33:54,390 --> 00:33:59,530
it's no good taking one that is trained

00:33:56,980 --> 00:34:01,840
on Wikipedia movie titles and then

00:33:59,530 --> 00:34:03,700
feeding it into a load of data that's

00:34:01,840 --> 00:34:05,550
talking about clinical trial processing

00:34:03,700 --> 00:34:08,409
it's not necessary gonna work so well

00:34:05,550 --> 00:34:10,720
next thing stemming if we've got a whole

00:34:08,409 --> 00:34:13,629
bunch of different forms of a word like

00:34:10,720 --> 00:34:15,760
talk talks talks talking they all

00:34:13,629 --> 00:34:17,440
represent the same thing so if we've got

00:34:15,760 --> 00:34:19,720
a language model we can trim all those

00:34:17,440 --> 00:34:23,169
back to the same word and then we can do

00:34:19,720 --> 00:34:28,450
an exact match on Nik is talking when we

00:34:23,169 --> 00:34:30,429
query for talked another interesting

00:34:28,450 --> 00:34:33,550
trick is engrams

00:34:30,429 --> 00:34:35,500
so if we're doing word based engrams we

00:34:33,550 --> 00:34:38,350
can just take every word as a single

00:34:35,500 --> 00:34:41,860
thing there's word uni Graham's all we

00:34:38,350 --> 00:34:45,190
can do word by Graham's so if we say

00:34:41,860 --> 00:34:47,320
Nick is talking then we've got Nick is

00:34:45,190 --> 00:34:50,020
and is talking those are at to you by

00:34:47,320 --> 00:34:53,800
Graham's so that lets us do poor man's

00:34:50,020 --> 00:34:55,419
phrase query it's important because we

00:34:53,800 --> 00:34:57,670
haven't got a lovely query parser like

00:34:55,419 --> 00:35:00,310
inducing and if we're doing stuff on

00:34:57,670 --> 00:35:03,030
characters then we could have trigrams

00:35:00,310 --> 00:35:07,660
so the program's of hello are h-e-l-l-o

00:35:03,030 --> 00:35:10,570
ello so if someone has made a typo then

00:35:07,660 --> 00:35:14,440
the use of these trigrams might allow us

00:35:10,570 --> 00:35:16,090
to do a correction on their typos but

00:35:14,440 --> 00:35:18,550
you do lose some of the information

00:35:16,090 --> 00:35:21,240
about where those three letters come in

00:35:18,550 --> 00:35:27,070
the word and you might end up matching

00:35:21,240 --> 00:35:29,440
just on some common pattern like ist

00:35:27,070 --> 00:35:31,690
that crops up in all sorts of places in

00:35:29,440 --> 00:35:33,070
english-language words so you might say

00:35:31,690 --> 00:35:34,870
oh well we're looking for something that

00:35:33,070 --> 00:35:36,310
has the trigram ist and you

00:35:34,870 --> 00:35:37,810
got holo two completely irrelevant words

00:35:36,310 --> 00:35:41,080
coming through so there's some

00:35:37,810 --> 00:35:44,380
trade-offs we made here final thing

00:35:41,080 --> 00:35:48,480
whatever you do has to be the same for

00:35:44,380 --> 00:35:50,500
query and model building if you have

00:35:48,480 --> 00:35:51,820
different stop words if you've got

00:35:50,500 --> 00:35:53,620
different tokenization different

00:35:51,820 --> 00:35:55,420
stemming then your query won't match

00:35:53,620 --> 00:35:59,980
anymore and you won't get sensible

00:35:55,420 --> 00:36:03,070
answers okay next thing to wear of is

00:35:59,980 --> 00:36:06,910
feature extraction and embeddings so

00:36:03,070 --> 00:36:09,970
even from just 300 talks we had 30,000

00:36:06,910 --> 00:36:13,060
terms come out and even the tf-idf

00:36:09,970 --> 00:36:15,250
matrix most of the values were 0 so it's

00:36:13,060 --> 00:36:17,950
a sparse matrix it's can take up a

00:36:15,250 --> 00:36:19,990
reasonable amount of memory if we're

00:36:17,950 --> 00:36:22,540
working with Bayesian and k-means there

00:36:19,990 --> 00:36:25,480
are ok with 30,000 terms they can cope

00:36:22,540 --> 00:36:29,020
I'm reasonably fast they don't mind and

00:36:25,480 --> 00:36:32,500
neural networks not so much newer

00:36:29,020 --> 00:36:36,130
networks like 50 maybe a hundred inputs

00:36:32,500 --> 00:36:37,750
total yeah we can you stop words we can

00:36:36,130 --> 00:36:40,390
use stemming that might get us down from

00:36:37,750 --> 00:36:43,570
30,000 to 20,000 but that's still a lot

00:36:40,390 --> 00:36:44,920
more than 50 so if we wanna move on to

00:36:43,570 --> 00:36:47,130
using your networks we need to think

00:36:44,920 --> 00:36:49,540
about ways to reduce the dimensionality

00:36:47,130 --> 00:36:51,610
now we've already seen a little bit of

00:36:49,540 --> 00:36:53,320
that with the t-sne we're just so that

00:36:51,610 --> 00:36:55,270
our eyes could cope with it we reduce

00:36:53,320 --> 00:36:56,440
the dimensionality down to two but our

00:36:55,270 --> 00:36:59,950
neural networks are going to need the

00:36:56,440 --> 00:37:00,580
reduction there and so if this is all

00:36:59,950 --> 00:37:02,170
new to you

00:37:00,580 --> 00:37:03,580
I'm scikit-learn I've got a great piece

00:37:02,170 --> 00:37:06,280
on it and then Google have a good piece

00:37:03,580 --> 00:37:08,860
on it as well but the the way of turning

00:37:06,280 --> 00:37:10,510
our Rohrer features into a much smaller

00:37:08,860 --> 00:37:17,620
set for your network it's generally

00:37:10,510 --> 00:37:20,260
known as embedding right ok one of the

00:37:17,620 --> 00:37:22,990
most popular ways of doing the embedding

00:37:20,260 --> 00:37:26,620
in text is word Tyvek was originally

00:37:22,990 --> 00:37:28,390
developed by Google and it is actually

00:37:26,620 --> 00:37:29,890
based on a neural network itself but you

00:37:28,390 --> 00:37:32,650
tend to use it to pre-process your data

00:37:29,890 --> 00:37:35,260
before you give it to your own your

00:37:32,650 --> 00:37:38,860
network and if you give it enough text

00:37:35,260 --> 00:37:42,760
it can make predictions based on a words

00:37:38,860 --> 00:37:46,630
meaning so if you say figure out the

00:37:42,760 --> 00:37:47,840
vector between man and boy okay now find

00:37:46,630 --> 00:37:49,970
the point

00:37:47,840 --> 00:37:52,400
in the embedding forewoman apply the

00:37:49,970 --> 00:37:55,280
same vector distance and see what word

00:37:52,400 --> 00:37:56,500
we get to and then you get a girl if you

00:37:55,280 --> 00:37:58,220
trained it right

00:37:56,500 --> 00:38:01,700
unfortunately there's this thing called

00:37:58,220 --> 00:38:05,090
bias where if you fed it a lot of human

00:38:01,700 --> 00:38:08,030
written text and you might say man is

00:38:05,090 --> 00:38:09,410
too this job and woman is too and you

00:38:08,030 --> 00:38:11,780
get a sexist answer out because if you

00:38:09,410 --> 00:38:13,760
fed in sexist training data which

00:38:11,780 --> 00:38:15,320
actually is most of the training data

00:38:13,760 --> 00:38:17,570
out there because most of us have our

00:38:15,320 --> 00:38:20,600
biases when we're writing language then

00:38:17,570 --> 00:38:22,520
you can end up training a biased AI but

00:38:20,600 --> 00:38:24,020
assuming that you've got the right kind

00:38:22,520 --> 00:38:26,000
of thing you get lovely things like this

00:38:24,020 --> 00:38:28,400
where it's figured out the relationships

00:38:26,000 --> 00:38:30,170
between a whole bunch of words and how

00:38:28,400 --> 00:38:32,930
they interact with each other and done

00:38:30,170 --> 00:38:34,610
it in a vector space so that when we

00:38:32,930 --> 00:38:37,310
feed that into the neural network and we

00:38:34,610 --> 00:38:40,370
train and we do queries it can figure

00:38:37,310 --> 00:38:42,020
out some parts of speech figure out some

00:38:40,370 --> 00:38:43,600
parts of relationships and give us good

00:38:42,020 --> 00:38:46,520
answers

00:38:43,600 --> 00:38:47,960
so it's worth having a play with words

00:38:46,520 --> 00:38:49,850
avec if you want to do anything around

00:38:47,960 --> 00:38:51,650
this and there's a whole bunch of

00:38:49,850 --> 00:38:53,710
implementations of it available and

00:38:51,650 --> 00:38:56,690
Google have got quite a good intro to it

00:38:53,710 --> 00:38:59,210
keep neural networks who hears come

00:38:56,690 --> 00:39:00,710
across neural networks a little bit of

00:38:59,210 --> 00:39:04,730
audience participation before you fall

00:39:00,710 --> 00:39:07,100
asleep okay so the system is built up of

00:39:04,730 --> 00:39:08,540
a whole bunch of layers you have an

00:39:07,100 --> 00:39:10,610
input layer where you're feeding your

00:39:08,540 --> 00:39:11,780
features in an output layer which is

00:39:10,610 --> 00:39:14,750
where you want to get your answer out

00:39:11,780 --> 00:39:16,610
and then a bunch of hidden layers in

00:39:14,750 --> 00:39:18,710
between that the system has figured out

00:39:16,610 --> 00:39:20,900
what they should be so you go to the

00:39:18,710 --> 00:39:22,850
neural network system you say this is my

00:39:20,900 --> 00:39:25,100
input that's the prediction I want you

00:39:22,850 --> 00:39:26,870
to make you figure out how to glue all

00:39:25,100 --> 00:39:35,210
of these different bits together for me

00:39:26,870 --> 00:39:37,970
and then where we go I'm the more layers

00:39:35,210 --> 00:39:39,830
you have potentially the better answer

00:39:37,970 --> 00:39:41,330
you're going to get but the more work

00:39:39,830 --> 00:39:44,540
that's going to go on in the training

00:39:41,330 --> 00:39:46,760
and the more inputs and outputs you have

00:39:44,540 --> 00:39:53,270
again the more work that it has to do in

00:39:46,760 --> 00:39:54,980
figuring out the right layer think about

00:39:53,270 --> 00:39:57,740
what kind of outputs you're going to

00:39:54,980 --> 00:39:59,450
want if you need something that's going

00:39:57,740 --> 00:40:00,900
to be a cat or a dog you need to

00:39:59,450 --> 00:40:03,180
constrain your outputs

00:40:00,900 --> 00:40:06,870
that the probability of cat or dog adds

00:40:03,180 --> 00:40:08,310
up to 100 if you say tell me roughly

00:40:06,870 --> 00:40:10,730
what's in this image then something that

00:40:08,310 --> 00:40:13,380
comes back and says 80% chance of dog

00:40:10,730 --> 00:40:15,930
70% chance of cat that's probably okay

00:40:13,380 --> 00:40:18,510
but if what you really wanted to know is

00:40:15,930 --> 00:40:22,020
is this the right talk you want a single

00:40:18,510 --> 00:40:23,280
answer the more layers you put in the

00:40:22,020 --> 00:40:25,380
longer it's going to take to train and

00:40:23,280 --> 00:40:27,810
this is an iterative process you keep

00:40:25,380 --> 00:40:29,580
running it suggesting that it adds some

00:40:27,810 --> 00:40:31,320
extra layers in or add some extra

00:40:29,580 --> 00:40:33,660
neurons in or throw away some neurons

00:40:31,320 --> 00:40:35,520
and then urea ate the score and you keep

00:40:33,660 --> 00:40:41,790
going until the score basically doesn't

00:40:35,520 --> 00:40:45,570
change okay now if we know what the

00:40:41,790 --> 00:40:48,170
model should be predicting then we can

00:40:45,570 --> 00:40:51,570
train and we can evaluate the model and

00:40:48,170 --> 00:40:54,060
let's say we've got 300 talks and we've

00:40:51,570 --> 00:40:58,470
got a load of answers now if we train

00:40:54,060 --> 00:40:59,790
the model on all of that input data we

00:40:58,470 --> 00:41:01,740
have no way of knowing how well it's

00:40:59,790 --> 00:41:04,320
done because we've got nothing left to

00:41:01,740 --> 00:41:06,930
test to it if we train it on three

00:41:04,320 --> 00:41:08,940
pieces of input data and keep 3000 back

00:41:06,930 --> 00:41:10,680
to test with we can be really sure how

00:41:08,940 --> 00:41:13,080
well it's done but it's not going to

00:41:10,680 --> 00:41:15,840
have learnt much so we're going to have

00:41:13,080 --> 00:41:18,180
to do this trade-off of our input data

00:41:15,840 --> 00:41:23,010
which is nicely labeled into the

00:41:18,180 --> 00:41:25,200
training part and the testing part if we

00:41:23,010 --> 00:41:26,760
give the model too much data then it can

00:41:25,200 --> 00:41:28,350
over fit and it can learn specific

00:41:26,760 --> 00:41:30,680
attributes of our test data that's not

00:41:28,350 --> 00:41:32,640
present in the rest of our real data and

00:41:30,680 --> 00:41:36,020
another thing to look at is if you've

00:41:32,640 --> 00:41:38,790
not got that much data you can split

00:41:36,020 --> 00:41:40,560
shuffle it all up do a split for test

00:41:38,790 --> 00:41:42,570
and train get an answer shuffle it

00:41:40,560 --> 00:41:43,680
around again do the same test and train

00:41:42,570 --> 00:41:45,450
and make sure that you're getting

00:41:43,680 --> 00:41:47,460
roughly the same kind of accuracy each

00:41:45,450 --> 00:41:49,380
time that gives you an idea that your

00:41:47,460 --> 00:41:50,700
model is fairly stable and it's not

00:41:49,380 --> 00:41:54,570
doing too much overfitting

00:41:50,700 --> 00:41:57,090
so that's cross validation hyper

00:41:54,570 --> 00:41:59,370
parameters the hyper parameter is

00:41:57,090 --> 00:42:01,490
anything that we're tuning or selecting

00:41:59,370 --> 00:42:03,660
and changing in the machine learning

00:42:01,490 --> 00:42:06,720
that's not part of the data in the

00:42:03,660 --> 00:42:08,970
features so for our k-means example one

00:42:06,720 --> 00:42:10,590
of the type of rameters was the number

00:42:08,970 --> 00:42:13,050
of clusters that we're breaking it down

00:42:10,590 --> 00:42:14,220
into and quite often it's going to be

00:42:13,050 --> 00:42:17,099
the seeds the

00:42:14,220 --> 00:42:18,660
that's the number of layers how much to

00:42:17,099 --> 00:42:19,920
change between iterations all those kind

00:42:18,660 --> 00:42:21,540
of things if you pick the wrong

00:42:19,920 --> 00:42:23,730
parameters your machine learning or get

00:42:21,540 --> 00:42:27,090
stuck like half way down the hill in a

00:42:23,730 --> 00:42:29,940
little little bump yeah it might just

00:42:27,090 --> 00:42:32,190
take forever to complete so the hard

00:42:29,940 --> 00:42:34,109
bits in machine learning tend to be

00:42:32,190 --> 00:42:38,090
picking the appropriate features and

00:42:34,109 --> 00:42:38,090
picking the appropriate hyper parameters

00:42:38,270 --> 00:42:43,500
it's a lot of work a lot of

00:42:40,500 --> 00:42:46,320
experimentation and Google did a study

00:42:43,500 --> 00:42:49,050
last year on the hyper from to picking

00:42:46,320 --> 00:42:51,750
and they said it is cheaper to have a

00:42:49,050 --> 00:42:54,090
data scientist in California picking -

00:42:51,750 --> 00:42:57,180
parameters for them to have a whole

00:42:54,090 --> 00:42:58,800
extra set of machine learning trying to

00:42:57,180 --> 00:43:00,720
optimize the hyper parameters of another

00:42:58,800 --> 00:43:02,880
machine learning but that was a year ago

00:43:00,720 --> 00:43:05,310
and probably in California now it's

00:43:02,880 --> 00:43:06,990
betters have an AI tuning your X today

00:43:05,310 --> 00:43:08,970
is but anywhere else in the world

00:43:06,990 --> 00:43:10,260
probably be better off with humans maybe

00:43:08,970 --> 00:43:12,180
in five years that will have changed

00:43:10,260 --> 00:43:13,320
again but for now we have to have the

00:43:12,180 --> 00:43:15,060
humans looking at it and saying or I

00:43:13,320 --> 00:43:16,650
think I'm going to want roughly this

00:43:15,060 --> 00:43:18,380
kind of many steps based on my past

00:43:16,650 --> 00:43:21,200
experience and then my AI should

00:43:18,380 --> 00:43:26,190
converge on the answer quite quickly

00:43:21,200 --> 00:43:27,510
okay need to think about errors and if

00:43:26,190 --> 00:43:31,520
we've got something that's supposed to

00:43:27,510 --> 00:43:35,849
say cancer not cancer and we feed it the

00:43:31,520 --> 00:43:38,700
the diagnosis and the health records of

00:43:35,849 --> 00:43:40,830
a person and it could say they have

00:43:38,700 --> 00:43:42,300
cancer and they do so that's a true

00:43:40,830 --> 00:43:44,339
positive could say they're clear from

00:43:42,300 --> 00:43:46,619
cancer and they don't that's a true

00:43:44,339 --> 00:43:48,119
negative or I could say nope they're all

00:43:46,619 --> 00:43:50,700
clear no cancer and they've really got

00:43:48,119 --> 00:43:52,800
it so that's false negative or it might

00:43:50,700 --> 00:43:56,460
say someone who's clear that they've got

00:43:52,800 --> 00:43:58,950
cancer so that's a false positive now if

00:43:56,460 --> 00:44:00,000
you're detecting cancer what happens if

00:43:58,950 --> 00:44:02,520
we give someone the all-clear that's

00:44:00,000 --> 00:44:03,960
actually got a tumor or what happens

00:44:02,520 --> 00:44:05,070
someone who doesn't have a tumor and

00:44:03,960 --> 00:44:06,660
we've just given them a load of

00:44:05,070 --> 00:44:08,820
chemotherapy so you've got to think

00:44:06,660 --> 00:44:11,550
about the impact of your model and the

00:44:08,820 --> 00:44:13,770
impact on the errors of your model other

00:44:11,550 --> 00:44:16,109
things think about is the precision the

00:44:13,770 --> 00:44:17,849
recall and the confidence so the

00:44:16,109 --> 00:44:20,460
precision is how much correct results

00:44:17,849 --> 00:44:22,320
correct values in our results the recall

00:44:20,460 --> 00:44:26,190
is how many is the correct results we

00:44:22,320 --> 00:44:27,900
actually gave to you so if we said here

00:44:26,190 --> 00:44:30,119
are five answers

00:44:27,900 --> 00:44:33,599
and four of them were correct then

00:44:30,119 --> 00:44:35,130
that's an 80% but if we gave you five

00:44:33,599 --> 00:44:37,470
answers and there are actually a million

00:44:35,130 --> 00:44:39,539
possible answers then maybe our records

00:44:37,470 --> 00:44:41,430
pretty terrible a lot of the models can

00:44:39,539 --> 00:44:42,930
tell us how sure they are that they

00:44:41,430 --> 00:44:45,059
could be knew the right answer so that's

00:44:42,930 --> 00:44:46,680
the confidence so it might say I think

00:44:45,059 --> 00:44:48,930
this is a dog but I'm only five percent

00:44:46,680 --> 00:44:50,849
sure and you say or maybe we won't trust

00:44:48,930 --> 00:44:52,260
that equally it says that's definitely a

00:44:50,849 --> 00:44:53,910
dog 99 percent accuracy

00:44:52,260 --> 00:44:56,789
99 percent confidence say okay well it's

00:44:53,910 --> 00:44:59,010
probably okay okay already mentioned

00:44:56,789 --> 00:45:01,440
biases a little bit your data sets are

00:44:59,010 --> 00:45:02,490
probably gonna be biased certainly if

00:45:01,440 --> 00:45:03,960
you're working with text written by

00:45:02,490 --> 00:45:07,829
humans it's definitely gonna be biased

00:45:03,960 --> 00:45:09,690
your a I can find extra features so you

00:45:07,829 --> 00:45:12,450
might say oh I'm a bit worried about the

00:45:09,690 --> 00:45:14,369
bias in my input data song at a high

00:45:12,450 --> 00:45:16,710
gender but I'm gonna leave in the name

00:45:14,369 --> 00:45:18,000
of the author and you're AI will be like

00:45:16,710 --> 00:45:20,220
oh I'm gonna learn what female names

00:45:18,000 --> 00:45:22,020
look like equally you say oh I'm a bit

00:45:20,220 --> 00:45:23,670
worried about the racism inherent in my

00:45:22,020 --> 00:45:25,529
data so I'm going to leave out the race

00:45:23,670 --> 00:45:26,849
field but you've left in the postal code

00:45:25,529 --> 00:45:28,740
or zip code or the first elementary

00:45:26,849 --> 00:45:30,420
school and it turns out in your city

00:45:28,740 --> 00:45:32,190
people of different races tend to live

00:45:30,420 --> 00:45:34,109
in different places or you're a is just

00:45:32,190 --> 00:45:35,549
learn that just figure out the race even

00:45:34,109 --> 00:45:38,039
though you didn't do it to it so think

00:45:35,549 --> 00:45:39,299
about the bias think about how people

00:45:38,039 --> 00:45:41,069
are going to use your data how you can

00:45:39,299 --> 00:45:42,750
use the model and make sure that you

00:45:41,069 --> 00:45:45,180
correct for it or make them aware of it

00:45:42,750 --> 00:45:46,710
and don't reuse the model there was a

00:45:45,180 --> 00:45:49,410
really good intro yesterday it'll be up

00:45:46,710 --> 00:45:51,799
on YouTube very soon about the bias and

00:45:49,410 --> 00:45:55,109
text and the ways to correct for that

00:45:51,799 --> 00:45:56,430
okay natural language processing I'll

00:45:55,109 --> 00:45:57,900
skip over that we have really got time

00:45:56,430 --> 00:45:59,940
that the slides are be up

00:45:57,900 --> 00:46:02,579
dr. QA there was a really good talk

00:45:59,940 --> 00:46:05,400
yesterday on this it's a thing developed

00:46:02,579 --> 00:46:07,349
by Facebook for pulling out specific

00:46:05,400 --> 00:46:09,180
answers from text trained on Wikipedia

00:46:07,349 --> 00:46:10,200
looks really interesting haven't played

00:46:09,180 --> 00:46:13,260
with it yet only heard of it yesterday

00:46:10,200 --> 00:46:16,710
but that looks good final question would

00:46:13,260 --> 00:46:19,140
leucine have done better probably for my

00:46:16,710 --> 00:46:21,420
specific case probably a fully tuned

00:46:19,140 --> 00:46:23,400
leucine elastic cluster something like

00:46:21,420 --> 00:46:26,520
that would have done better it certainly

00:46:23,400 --> 00:46:28,260
would have had a better ability to scale

00:46:26,520 --> 00:46:30,089
up to really really large datasets

00:46:28,260 --> 00:46:33,240
almost all the ML techniques need

00:46:30,089 --> 00:46:35,730
everything a memory leucine doesn't but

00:46:33,240 --> 00:46:38,460
as a way to teach a lot of my

00:46:35,730 --> 00:46:40,380
statisticians about AI n ml using the

00:46:38,460 --> 00:46:41,530
kind of data that they understand and as

00:46:40,380 --> 00:46:43,660
a way to put some of the

00:46:41,530 --> 00:46:45,370
ai nml stuff into production in my

00:46:43,660 --> 00:46:47,710
company it was wonderful

00:46:45,370 --> 00:46:49,690
so it was worth doing just not worth

00:46:47,710 --> 00:46:52,240
doing as a pure search project so if

00:46:49,690 --> 00:46:54,400
you're looking for a way to learn AI and

00:46:52,240 --> 00:46:56,100
you've got text this is really great if

00:46:54,400 --> 00:47:00,630
you think this is going to replace

00:46:56,100 --> 00:47:00,630
elasticsearch it's probably not okay

00:47:00,900 --> 00:47:05,650
both Microsoft Anna and Google let you

00:47:04,360 --> 00:47:07,570
have a play with all of this stuff

00:47:05,650 --> 00:47:10,810
batteries included there's some links

00:47:07,570 --> 00:47:12,250
there and slides will be up on the

00:47:10,810 --> 00:47:14,230
website soon but I've got a whole bunch

00:47:12,250 --> 00:47:18,730
of resources in here if you want to

00:47:14,230 --> 00:47:21,730
learn some more okay everyone is hungry

00:47:18,730 --> 00:47:24,070
run away now anyone who wants to ask me

00:47:21,730 --> 00:47:27,340
questions we can do any into a lunch

00:47:24,070 --> 00:47:31,179
break okay thanks

00:47:27,340 --> 00:47:31,179

YouTube URL: https://www.youtube.com/watch?v=uYVdm8t241o


