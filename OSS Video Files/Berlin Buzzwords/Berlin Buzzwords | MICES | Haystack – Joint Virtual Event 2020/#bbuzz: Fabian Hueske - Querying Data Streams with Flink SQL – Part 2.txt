Title: #bbuzz: Fabian Hueske - Querying Data Streams with Flink SQL – Part 2
Publication date: 2020-09-10
Playlist: Berlin Buzzwords | MICES | Haystack – Joint Virtual Event 2020
Description: 
	More: https://berlinbuzzwords.de/session/qu...

Apache Flink supports SQL as a unified API for stream and batch processing. SQL is easier to use than Flink’s lower-level APIs and covers a wide variety of use cases. In this hands-on tutorial you will learn how to run SQL queries on data streams with Apache Flink. We will look at the concepts behind continuous queries and dynamic tables and will show you how to solve different use cases with streaming SQL, including enriching and joining streaming data, computing windowed aggregations, and maintaining materialized views in external storage systems.

Prerequisites:
 - No prior knowledge of Apache Flink is required. We assume basic knowledge of SQL
 - You will need a computer with at least 8 GB RAM and Docker installed. To save time during the event, we would also like to ask you to set up the tutorial environment beforehand by following the instructions at https://github.com/ververica/sql-trai...
Captions: 
	00:00:13,120 --> 00:00:17,920
okay

00:00:14,080 --> 00:00:17,920
let's start

00:00:20,560 --> 00:00:23,600
so far we've talked about apache flank

00:00:22,800 --> 00:00:27,119
um

00:00:23,600 --> 00:00:27,760
or fling sql without not really going

00:00:27,119 --> 00:00:31,279
into

00:00:27,760 --> 00:00:34,000
the topic of time however time is a

00:00:31,279 --> 00:00:35,120
is usually a very important uh important

00:00:34,000 --> 00:00:38,000
aspect of

00:00:35,120 --> 00:00:38,879
stream processing so there's like lots

00:00:38,000 --> 00:00:42,160
of

00:00:38,879 --> 00:00:43,840
lots of different situations when you

00:00:42,160 --> 00:00:45,680
want to work with time in stream

00:00:43,840 --> 00:00:48,559
processing um

00:00:45,680 --> 00:00:49,760
some examples are here if you'd like to

00:00:48,559 --> 00:00:52,239
aggregate data

00:00:49,760 --> 00:00:53,120
based on time something like compute an

00:00:52,239 --> 00:00:56,640
average

00:00:53,120 --> 00:00:59,120
of the last one minute or

00:00:56,640 --> 00:01:01,760
count how many orders we receive where

00:00:59,120 --> 00:01:04,960
uh received within the last hour

00:01:01,760 --> 00:01:06,240
um also enriching streaming data with uh

00:01:04,960 --> 00:01:08,799
data from other sources

00:01:06,240 --> 00:01:09,680
like uh join my screen with the most

00:01:08,799 --> 00:01:12,880
recent

00:01:09,680 --> 00:01:14,799
exchange rate is quite common

00:01:12,880 --> 00:01:16,159
or even if you want to do some kind of

00:01:14,799 --> 00:01:20,720
pattern matching or

00:01:16,159 --> 00:01:23,200
rule evaluation uh for instance

00:01:20,720 --> 00:01:24,240
emit an alert if there were three

00:01:23,200 --> 00:01:27,600
answers of

00:01:24,240 --> 00:01:29,040
unsuccessful attempts uh to lock into my

00:01:27,600 --> 00:01:32,159
service or

00:01:29,040 --> 00:01:35,680
whatever within the last five minutes so

00:01:32,159 --> 00:01:38,960
all of these examples have some

00:01:35,680 --> 00:01:42,560
some temporal component right um

00:01:38,960 --> 00:01:46,159
you uh always kind of like want to bound

00:01:42,560 --> 00:01:49,280
um some kind of evaluation or

00:01:46,159 --> 00:01:52,560
computer computation um in

00:01:49,280 --> 00:01:55,439
within some some time range

00:01:52,560 --> 00:01:56,640
and for many of these use cases uh

00:01:55,439 --> 00:01:59,920
common types of data

00:01:56,640 --> 00:02:03,119
is user interactions when you want to uh

00:01:59,920 --> 00:02:06,560
analyze for instance click data

00:02:03,119 --> 00:02:09,119
from websites or mobile apps log data

00:02:06,560 --> 00:02:10,160
coming from applications machines

00:02:09,119 --> 00:02:14,400
transactions or

00:02:10,160 --> 00:02:14,400
some kind of sensor and

00:02:15,920 --> 00:02:22,480
when you want to do that on

00:02:19,280 --> 00:02:25,440
dynamic tables there's a there's a few

00:02:22,480 --> 00:02:26,879
characteristics that these queries

00:02:25,440 --> 00:02:29,520
typically have

00:02:26,879 --> 00:02:30,480
so first of all the input tables are

00:02:29,520 --> 00:02:32,160
typically

00:02:30,480 --> 00:02:34,800
append only so you basically get a

00:02:32,160 --> 00:02:34,800
stream of

00:02:35,040 --> 00:02:40,319
all events and uh none of the rows

00:02:38,319 --> 00:02:41,519
in your and the table that you write

00:02:40,319 --> 00:02:44,640
your queries on

00:02:41,519 --> 00:02:48,160
are uh ever updated

00:02:44,640 --> 00:02:50,319
um the schema of such a table or defines

00:02:48,160 --> 00:02:51,280
some kind of time event so uh yesterday

00:02:50,319 --> 00:02:53,360
we've seen

00:02:51,280 --> 00:02:54,800
uh when we talked about this uh ddl

00:02:53,360 --> 00:02:58,720
subjects of the battery flank

00:02:54,800 --> 00:03:03,519
we've seen this small watermark clause

00:02:58,720 --> 00:03:07,360
that defines the event time property

00:03:03,519 --> 00:03:10,000
offer of a table and you basically need

00:03:07,360 --> 00:03:12,560
such a such a time attribute in your

00:03:10,000 --> 00:03:17,200
table to in order to be able to

00:03:12,560 --> 00:03:20,720
write queries that work with time

00:03:17,200 --> 00:03:23,120
a query that works with um with time

00:03:20,720 --> 00:03:24,720
usually consists of uh like i call it

00:03:23,120 --> 00:03:26,560
row at the time operators

00:03:24,720 --> 00:03:30,080
uh something like a simple filter or

00:03:26,560 --> 00:03:31,920
projection basically an operator that

00:03:30,080 --> 00:03:33,200
can can be evaluated by looking at a

00:03:31,920 --> 00:03:37,280
single row

00:03:33,200 --> 00:03:40,400
um and so called temporal operators

00:03:37,280 --> 00:03:44,159
uh such as window aggregations

00:03:40,400 --> 00:03:46,239
um joints that work based on time

00:03:44,159 --> 00:03:47,599
or pedal matching that is applied based

00:03:46,239 --> 00:03:50,560
on some

00:03:47,599 --> 00:03:52,560
uh tempura or within a temporal or

00:03:50,560 --> 00:03:54,799
timeout

00:03:52,560 --> 00:03:56,239
so all of these operators are like like

00:03:54,799 --> 00:03:58,640
if you look at what

00:03:56,239 --> 00:04:00,000
uh people usually build when they work

00:03:58,640 --> 00:04:03,840
with uh flinx data stream

00:04:00,000 --> 00:04:05,599
api or some other stream process api

00:04:03,840 --> 00:04:08,000
these are kind of like the traditional

00:04:05,599 --> 00:04:10,959
stream processing operators operations

00:04:08,000 --> 00:04:15,040
uh window allegations

00:04:10,959 --> 00:04:17,040
of joints and so on

00:04:15,040 --> 00:04:18,720
and then when you basically apply

00:04:17,040 --> 00:04:22,079
subject query

00:04:18,720 --> 00:04:24,880
on such an append only table

00:04:22,079 --> 00:04:25,840
then the output table is also an append

00:04:24,880 --> 00:04:29,120
only table

00:04:25,840 --> 00:04:31,120
which means that it only emits rows

00:04:29,120 --> 00:04:33,919
and every row that is submitted will

00:04:31,120 --> 00:04:33,919
never be updated

00:04:34,160 --> 00:04:38,479
so let's first have a look at how you

00:04:36,720 --> 00:04:41,680
can define

00:04:38,479 --> 00:04:44,960
time attributes in a page of link

00:04:41,680 --> 00:04:47,759
so how is this uh really done

00:04:44,960 --> 00:04:48,320
so and if if you're like a bit familiar

00:04:47,759 --> 00:04:50,320
with how

00:04:48,320 --> 00:04:51,600
apache flink works or flint's status

00:04:50,320 --> 00:04:54,320
from api works

00:04:51,600 --> 00:04:56,080
um influence data stream api um when

00:04:54,320 --> 00:04:57,919
you're using

00:04:56,080 --> 00:05:00,080
there's two different modes of time

00:04:57,919 --> 00:05:03,759
there's event time and processing time

00:05:00,080 --> 00:05:06,960
um event time is defined

00:05:03,759 --> 00:05:07,680
by uh basically each record is being

00:05:06,960 --> 00:05:10,960
processed

00:05:07,680 --> 00:05:14,800
based on a timestamp timestamp that is

00:05:10,960 --> 00:05:18,000
uh part of the data so the record itself

00:05:14,800 --> 00:05:20,960
tells the system hey

00:05:18,000 --> 00:05:20,960
my record is

00:05:21,039 --> 00:05:24,080
or this event happened at this point in

00:05:23,120 --> 00:05:27,600
time

00:05:24,080 --> 00:05:28,000
so you can process the data really based

00:05:27,600 --> 00:05:31,280
on

00:05:28,000 --> 00:05:35,360
some some actual data this is uh this is

00:05:31,280 --> 00:05:37,680
called event time and processing time is

00:05:35,360 --> 00:05:39,520
a mode where data is being processed

00:05:37,680 --> 00:05:42,720
based on the time

00:05:39,520 --> 00:05:44,240
of the machine um when the record is

00:05:42,720 --> 00:05:45,680
processed so

00:05:44,240 --> 00:05:47,440
you can think of it having a stream of

00:05:45,680 --> 00:05:50,720
data and then

00:05:47,440 --> 00:05:51,680
an event enters the stream processing

00:05:50,720 --> 00:05:53,840
application

00:05:51,680 --> 00:05:55,440
and if you then want to group data on

00:05:53,840 --> 00:05:57,280
time um

00:05:55,440 --> 00:05:59,039
based for instance uh grouping data on

00:05:57,280 --> 00:06:00,800
10 minutes and the machine that

00:05:59,039 --> 00:06:03,759
processes the data will say okay

00:06:00,800 --> 00:06:04,319
what time is it now it's let's say 12

00:06:03,759 --> 00:06:06,240
o'clock

00:06:04,319 --> 00:06:07,919
and then if you group by 10 minutes then

00:06:06,240 --> 00:06:09,840
after 10 minutes

00:06:07,919 --> 00:06:10,960
based on the machine time of the

00:06:09,840 --> 00:06:12,400
processing machine

00:06:10,960 --> 00:06:16,160
it will close the window perform the

00:06:12,400 --> 00:06:16,160
computation um

00:06:16,400 --> 00:06:20,560
so there's these different types of time

00:06:18,880 --> 00:06:22,720
in a patch of link event

00:06:20,560 --> 00:06:24,000
and processing time and both can be

00:06:22,720 --> 00:06:26,720
handled with a

00:06:24,000 --> 00:06:26,720
fling seeker

00:06:27,600 --> 00:06:31,360
in order to to to give access to time

00:06:31,120 --> 00:06:34,400
and

00:06:31,360 --> 00:06:36,400
query a timestamp needs to be needs to

00:06:34,400 --> 00:06:39,520
be part of the table schema

00:06:36,400 --> 00:06:42,000
and um these timestamps are of the

00:06:39,520 --> 00:06:45,120
regular zebra typestream type so they're

00:06:42,000 --> 00:06:47,680
pretty much just uh um it's a

00:06:45,120 --> 00:06:48,479
it's a sub tab or extends the secret

00:06:47,680 --> 00:06:52,000
timestamp type

00:06:48,479 --> 00:06:53,680
but they behave exactly like like

00:06:52,000 --> 00:06:55,520
you can do with these timestamps

00:06:53,680 --> 00:06:57,840
whatever you can also do with a secret

00:06:55,520 --> 00:07:00,720
timestamp

00:06:57,840 --> 00:07:03,520
and as we seen before these time

00:07:00,720 --> 00:07:06,240
attributes are declared the table schema

00:07:03,520 --> 00:07:06,880
so how does it look for for event time

00:07:06,240 --> 00:07:09,599
so

00:07:06,880 --> 00:07:12,000
for event time you basically have to

00:07:09,599 --> 00:07:12,000
define

00:07:12,960 --> 00:07:18,400
a time stamp as part of the table

00:07:16,000 --> 00:07:19,919
schema here we call it click time and

00:07:18,400 --> 00:07:23,199
it's of type timestamp

00:07:19,919 --> 00:07:25,919
three and this is an actual uh

00:07:23,199 --> 00:07:26,560
a field that is provided by the that is

00:07:25,919 --> 00:07:30,400
really

00:07:26,560 --> 00:07:32,080
part of the data so the um

00:07:30,400 --> 00:07:34,319
if this is a table backed by for

00:07:32,080 --> 00:07:38,160
instance by patrick kafka

00:07:34,319 --> 00:07:40,960
with the jason uh format then the uh

00:07:38,160 --> 00:07:42,160
js records that we read from apache

00:07:40,960 --> 00:07:45,360
kafka

00:07:42,160 --> 00:07:48,000
should have these this c time

00:07:45,360 --> 00:07:48,639
attribute with an extra timestamp so

00:07:48,000 --> 00:07:50,400
it's

00:07:48,639 --> 00:07:52,720
it's actual data that is provided by the

00:07:50,400 --> 00:07:52,720
data

00:07:53,520 --> 00:08:00,080
and in addition to this timestamp field

00:07:57,199 --> 00:08:02,560
we need to define some kind of watermark

00:08:00,080 --> 00:08:05,840
a watermark

00:08:02,560 --> 00:08:07,840
watermarks are in flink meta records

00:08:05,840 --> 00:08:10,080
that are generated based on the

00:08:07,840 --> 00:08:10,879
timestamps that are being observed so

00:08:10,080 --> 00:08:14,080
you see

00:08:10,879 --> 00:08:17,120
here that we define a watermark for this

00:08:14,080 --> 00:08:20,560
event time attribute c time

00:08:17,120 --> 00:08:22,800
and we define it as c time minus

00:08:20,560 --> 00:08:24,000
two minutes so what this basically means

00:08:22,800 --> 00:08:26,960
is

00:08:24,000 --> 00:08:28,080
that the uh watermark that the system

00:08:26,960 --> 00:08:31,280
sees

00:08:28,080 --> 00:08:35,200
um is always um

00:08:31,280 --> 00:08:37,200
the uh highest

00:08:35,200 --> 00:08:38,560
uh c term attribute that was seen by the

00:08:37,200 --> 00:08:41,760
system uh

00:08:38,560 --> 00:08:42,719
minus two minutes so um if the c time

00:08:41,760 --> 00:08:47,040
attribute

00:08:42,719 --> 00:08:50,160
um uh is uh is sustaining in time

00:08:47,040 --> 00:08:52,320
um then also the watermark well

00:08:50,160 --> 00:08:54,320
well about the same but it's always two

00:08:52,320 --> 00:08:57,760
minutes behind the maximum time

00:08:54,320 --> 00:08:58,080
and we do this uh we basically subtract

00:08:57,760 --> 00:09:00,640
these

00:08:58,080 --> 00:09:01,760
two minutes uh in order to be able to

00:09:00,640 --> 00:09:04,560
account for

00:09:01,760 --> 00:09:05,360
records that arrive out of order so

00:09:04,560 --> 00:09:06,959
flink

00:09:05,360 --> 00:09:09,360
is a distributed system and most of the

00:09:06,959 --> 00:09:11,519
uh most of the systems

00:09:09,360 --> 00:09:12,640
that we reach data from are also

00:09:11,519 --> 00:09:15,040
distributed systems

00:09:12,640 --> 00:09:15,920
so it's really hard to guarantee order

00:09:15,040 --> 00:09:20,160
in these

00:09:15,920 --> 00:09:20,160
in these systems also

00:09:21,760 --> 00:09:25,680
also there is the the case that even the

00:09:24,160 --> 00:09:27,200
data that is written to apache kafka

00:09:25,680 --> 00:09:29,760
might already be out of order

00:09:27,200 --> 00:09:30,720
so it's really rare that you can work

00:09:29,760 --> 00:09:33,839
with data

00:09:30,720 --> 00:09:36,800
that has a really exact time water

00:09:33,839 --> 00:09:39,519
so the watermark here is a mechanism to

00:09:36,800 --> 00:09:39,519
basically to

00:09:40,640 --> 00:09:43,920
to account for this out of hardness or

00:09:43,120 --> 00:09:46,160
in this case

00:09:43,920 --> 00:09:47,519
in this definition here we basically

00:09:46,160 --> 00:09:50,560
give

00:09:47,519 --> 00:09:55,920
the c time attribute like a

00:09:50,560 --> 00:09:59,120
two two minute margin to be out of order

00:09:55,920 --> 00:10:00,880
and um the operators

00:09:59,120 --> 00:10:02,240
that flink uses internally these

00:10:00,880 --> 00:10:04,399
time-based operators for window

00:10:02,240 --> 00:10:06,560
aggregations and so on

00:10:04,399 --> 00:10:08,320
they basically look at the watermark

00:10:06,560 --> 00:10:09,920
records that are being generated

00:10:08,320 --> 00:10:11,600
automatically generated

00:10:09,920 --> 00:10:12,959
and based on the watermark they

00:10:11,600 --> 00:10:14,880
determine what's

00:10:12,959 --> 00:10:17,680
what the current time is and based on

00:10:14,880 --> 00:10:19,760
this time they perform their there

00:10:17,680 --> 00:10:21,040
the computation and also reason about

00:10:19,760 --> 00:10:23,360
data completeness

00:10:21,040 --> 00:10:25,040
so for instance when there is a

00:10:23,360 --> 00:10:26,399
computation that should be performed at

00:10:25,040 --> 00:10:27,350
12 o'clock

00:10:26,399 --> 00:10:29,519
then

00:10:27,350 --> 00:10:31,839
[Music]

00:10:29,519 --> 00:10:33,120
an operator will wait for the water for

00:10:31,839 --> 00:10:36,800
a watermark that is

00:10:33,120 --> 00:10:38,000
at least um what did they say

00:10:36,800 --> 00:10:39,760
and there is a computation that should

00:10:38,000 --> 00:10:41,519
be performed at 12 o'clock and the

00:10:39,760 --> 00:10:42,640
operator will wait for a watermark that

00:10:41,519 --> 00:10:45,519
is at least

00:10:42,640 --> 00:10:46,079
12 o'clock so before the watermark

00:10:45,519 --> 00:10:48,399
hasn't reached

00:10:46,079 --> 00:10:49,760
12 o'clock the operator will will not

00:10:48,399 --> 00:10:51,230
perform the computation but once the

00:10:49,760 --> 00:10:52,800
watermark

00:10:51,230 --> 00:10:56,320
[Music]

00:10:52,800 --> 00:10:59,600
is at 12 o'clock or later then it

00:10:56,320 --> 00:11:01,440
knows basically that it has seen all the

00:10:59,600 --> 00:11:03,120
data

00:11:01,440 --> 00:11:04,880
up to 12 o'clock and then performs the

00:11:03,120 --> 00:11:08,560
computation

00:11:04,880 --> 00:11:09,120
so depending on how you how you choose

00:11:08,560 --> 00:11:12,240
this

00:11:09,120 --> 00:11:15,110
this interval here um

00:11:12,240 --> 00:11:16,560
this this margin um

00:11:15,110 --> 00:11:20,160
[Music]

00:11:16,560 --> 00:11:22,640
you can basically tune um

00:11:20,160 --> 00:11:23,839
tune the completeness versus the latency

00:11:22,640 --> 00:11:27,360
of your results

00:11:23,839 --> 00:11:28,079
if you uh um subtract like a large

00:11:27,360 --> 00:11:29,680
interval

00:11:28,079 --> 00:11:32,000
from the from the click animate group

00:11:29,680 --> 00:11:36,399
let's say you subtract

00:11:32,000 --> 00:11:36,800
one hour then a computation will kind of

00:11:36,399 --> 00:11:39,920
be

00:11:36,800 --> 00:11:44,640
performed um one hour

00:11:39,920 --> 00:11:47,200
after the highest

00:11:44,640 --> 00:11:48,720
the click time with the highest

00:11:47,200 --> 00:11:51,440
attribute was

00:11:48,720 --> 00:11:53,279
highest value was here so you get the

00:11:51,440 --> 00:11:55,440
result probably much later

00:11:53,279 --> 00:11:57,920
but since you have very very large

00:11:55,440 --> 00:12:01,120
margin to wait for late data

00:11:57,920 --> 00:12:03,680
you can also be sure that the result is

00:12:01,120 --> 00:12:05,600
is quite complete if you make sure to

00:12:03,680 --> 00:12:09,600
make the margin very small

00:12:05,600 --> 00:12:13,279
like let's say only five seconds

00:12:09,600 --> 00:12:16,399
then you get um

00:12:13,279 --> 00:12:18,560
the result uh very soon after the

00:12:16,399 --> 00:12:20,880
after the click time attribute pass the

00:12:18,560 --> 00:12:24,079
uh pass the computation boundary

00:12:20,880 --> 00:12:26,079
but it might be that some of the data

00:12:24,079 --> 00:12:29,120
the data that was laid is not really

00:12:26,079 --> 00:12:29,120
part of the computation

00:12:30,160 --> 00:12:35,279
um for processing time the

00:12:33,200 --> 00:12:36,399
attribute is defined a little bit

00:12:35,279 --> 00:12:39,279
differently

00:12:36,399 --> 00:12:40,399
so here basically a processing time

00:12:39,279 --> 00:12:43,680
attribute is

00:12:40,399 --> 00:12:47,120
virtual it doesn't hold any data so um

00:12:43,680 --> 00:12:48,240
instead when the query accesses this

00:12:47,120 --> 00:12:51,360
attribute

00:12:48,240 --> 00:12:53,120
it basically looks up the current

00:12:51,360 --> 00:12:54,480
local time of the of the machine that is

00:12:53,120 --> 00:12:56,560
processing this attribute that is

00:12:54,480 --> 00:12:59,680
performing this uh

00:12:56,560 --> 00:13:00,160
evaluation of the attribute so in this

00:12:59,680 --> 00:13:02,560
case

00:13:00,160 --> 00:13:03,600
if there is if we would have this clicks

00:13:02,560 --> 00:13:06,639
table

00:13:03,600 --> 00:13:10,000
defined based on a kafka topic then

00:13:06,639 --> 00:13:12,639
the the records

00:13:10,000 --> 00:13:13,680
that we ingest from kafka would not have

00:13:12,639 --> 00:13:15,839
the click time attribute

00:13:13,680 --> 00:13:17,120
but it would just be added as a kind of

00:13:15,839 --> 00:13:20,160
virtual attribute

00:13:17,120 --> 00:13:24,160
that is basically um

00:13:20,160 --> 00:13:24,160
evaluated whenever it has been accessed

00:13:25,200 --> 00:13:29,200
at the same time you can also use the

00:13:26,720 --> 00:13:31,440
skilltime attribute just as a regular

00:13:29,200 --> 00:13:32,959
timestamp but whenever you access it

00:13:31,440 --> 00:13:35,519
basically it

00:13:32,959 --> 00:13:36,079
will just carry the local time of the

00:13:35,519 --> 00:13:38,880
machine

00:13:36,079 --> 00:13:39,680
and there and hence it's not necessarily

00:13:38,880 --> 00:13:43,199
a

00:13:39,680 --> 00:13:43,199
deterministic value that you get back

00:13:43,839 --> 00:13:47,839
so basically once you define these time

00:13:45,600 --> 00:13:51,279
attributes you can

00:13:47,839 --> 00:13:52,560
use them kind of like interchangeably so

00:13:51,279 --> 00:13:55,600
later on it doesn't really matter

00:13:52,560 --> 00:13:55,600
whether a time

00:13:55,920 --> 00:13:59,199
time attribute is an event time

00:13:57,279 --> 00:14:00,639
attribute or processing type attribute

00:13:59,199 --> 00:14:01,760
whatever you can do with an event

00:14:00,639 --> 00:14:03,199
attribute you can also do with the

00:14:01,760 --> 00:14:07,600
processing time attribute

00:14:03,199 --> 00:14:09,920
however of course the semantics of

00:14:07,600 --> 00:14:12,160
uh are a bit different whereas in event

00:14:09,920 --> 00:14:13,440
time you use the actual time and actual

00:14:12,160 --> 00:14:15,199
timestamp

00:14:13,440 --> 00:14:16,639
that is coming with the data and hence

00:14:15,199 --> 00:14:20,720
is very then like

00:14:16,639 --> 00:14:22,160
precise and exact if you define the

00:14:20,720 --> 00:14:25,360
time attribute as a processing time

00:14:22,160 --> 00:14:25,360
attribute then it's

00:14:25,440 --> 00:14:30,800
not not really deterministic

00:14:28,800 --> 00:14:32,639
what you get because it's really based

00:14:30,800 --> 00:14:34,160
on the

00:14:32,639 --> 00:14:36,560
on the time when the record is being

00:14:34,160 --> 00:14:36,560
processed

00:14:38,079 --> 00:14:43,440
okay um let's um talk about

00:14:41,760 --> 00:14:46,959
temple operators basically operators

00:14:43,440 --> 00:14:48,639
that work on time so

00:14:46,959 --> 00:14:52,240
what all of these operators kind of have

00:14:48,639 --> 00:14:56,240
in common is that they

00:14:52,240 --> 00:14:59,040
process records by or associating

00:14:56,240 --> 00:15:00,560
different records based on some

00:14:59,040 --> 00:15:02,880
temporary condition

00:15:00,560 --> 00:15:05,120
so for instance you can do a group by

00:15:02,880 --> 00:15:08,320
window aggregation which is

00:15:05,120 --> 00:15:12,079
grouping data based on a

00:15:08,320 --> 00:15:15,199
time window you collect all records

00:15:12,079 --> 00:15:17,040
that are fall in the same in the same

00:15:15,199 --> 00:15:18,480
time window for instance if you compute

00:15:17,040 --> 00:15:22,079
hourly windows

00:15:18,480 --> 00:15:22,079
then a group by

00:15:22,560 --> 00:15:27,120
group by within hourly window will

00:15:25,120 --> 00:15:31,040
aggregate all records

00:15:27,120 --> 00:15:35,040
that are have a have a

00:15:31,040 --> 00:15:37,680
event have a timestamp from 12 to 1

00:15:35,040 --> 00:15:38,880
or those fall into a group or records

00:15:37,680 --> 00:15:41,040
that are from

00:15:38,880 --> 00:15:43,120
one to two fall into another group from

00:15:41,040 --> 00:15:46,079
two to three the next group and so on

00:15:43,120 --> 00:15:47,279
so basically this is a group by window

00:15:46,079 --> 00:15:50,480
application

00:15:47,279 --> 00:15:53,680
over window aggregation uses the uh

00:15:50,480 --> 00:15:54,560
sql over uh over clause i will have a

00:15:53,680 --> 00:15:58,000
look about that

00:15:54,560 --> 00:16:01,680
uh how he has a bit later

00:15:58,000 --> 00:16:04,160
in this case um the data needs to be

00:16:01,680 --> 00:16:04,880
or the the over clause needs to uh needs

00:16:04,160 --> 00:16:07,199
to be defined

00:16:04,880 --> 00:16:08,000
such that the data is ordered on time

00:16:07,199 --> 00:16:11,440
there's a

00:16:08,000 --> 00:16:14,959
time would not join which joins

00:16:11,440 --> 00:16:17,680
two streams based on a condition where

00:16:14,959 --> 00:16:19,440
one record is not

00:16:17,680 --> 00:16:22,959
not further apart than a certain time

00:16:19,440 --> 00:16:26,000
boundary in the other stream

00:16:22,959 --> 00:16:27,120
there is a join uh with a so-called

00:16:26,000 --> 00:16:30,800
temporal table

00:16:27,120 --> 00:16:33,440
which is a joint that looks up if

00:16:30,800 --> 00:16:34,480
you have a stream of records and for

00:16:33,440 --> 00:16:37,279
every record

00:16:34,480 --> 00:16:38,560
you do a lookup into another table uh

00:16:37,279 --> 00:16:41,600
based on the

00:16:38,560 --> 00:16:43,120
uh based on the timestamp of the of the

00:16:41,600 --> 00:16:43,839
record and you want to get the most

00:16:43,120 --> 00:16:45,920
recent

00:16:43,839 --> 00:16:47,600
version of the other table the table

00:16:45,920 --> 00:16:49,120
stretching over time

00:16:47,600 --> 00:16:51,120
you can get the most recent version that

00:16:49,120 --> 00:16:54,480
was uh

00:16:51,120 --> 00:16:56,560
valid uh for for for the time of this

00:16:54,480 --> 00:16:58,240
record which has been uh produced

00:16:56,560 --> 00:17:00,160
and also the pattern matching is also

00:16:58,240 --> 00:17:02,399
follows temporal conditions

00:17:00,160 --> 00:17:03,680
um what these operators basically do

00:17:02,399 --> 00:17:05,919
they track

00:17:03,680 --> 00:17:07,600
the progress in time to decide when

00:17:05,919 --> 00:17:11,120
input is complete

00:17:07,600 --> 00:17:12,160
so if your attribute is an event time

00:17:11,120 --> 00:17:16,400
attribute

00:17:12,160 --> 00:17:19,600
then the operators track time by

00:17:16,400 --> 00:17:20,959
looking at the event time at the

00:17:19,600 --> 00:17:24,400
watermarks

00:17:20,959 --> 00:17:26,480
so um when you have an event time

00:17:24,400 --> 00:17:28,079
operation and you want to perform a

00:17:26,480 --> 00:17:30,160
computation at

00:17:28,079 --> 00:17:32,720
12 o'clock then the operator will do

00:17:30,160 --> 00:17:35,840
that when the uh

00:17:32,720 --> 00:17:38,960
when a watermark is received that is uh

00:17:35,840 --> 00:17:41,200
past 12 o'clock if you're

00:17:38,960 --> 00:17:42,160
doing a computation based on processing

00:17:41,200 --> 00:17:44,160
time

00:17:42,160 --> 00:17:45,760
that should happen at 12 o'clock then

00:17:44,160 --> 00:17:47,039
the operator will basically look at its

00:17:45,760 --> 00:17:50,000
uh

00:17:47,039 --> 00:17:51,520
local clock and when the once the clock

00:17:50,000 --> 00:17:53,679
is past 12 o'clock

00:17:51,520 --> 00:17:56,160
um then the couple tags will be will be

00:17:53,679 --> 00:18:00,480
performed

00:17:56,160 --> 00:18:02,799
um since the operators can really

00:18:00,480 --> 00:18:04,799
track the progress and make a decision

00:18:02,799 --> 00:18:07,840
when the input is complete

00:18:04,799 --> 00:18:12,000
they can emit

00:18:07,840 --> 00:18:15,360
final result rows so results that

00:18:12,000 --> 00:18:18,640
never have to be updated again this is a

00:18:15,360 --> 00:18:22,240
very nice property because

00:18:18,640 --> 00:18:24,720
dealing with updates in your downstream

00:18:22,240 --> 00:18:26,080
tasks or systems is always always a

00:18:24,720 --> 00:18:28,080
hassle if you

00:18:26,080 --> 00:18:29,600
have a have a way to determine that the

00:18:28,080 --> 00:18:32,080
computation is complete

00:18:29,600 --> 00:18:32,640
uh based on time that's a that's a very

00:18:32,080 --> 00:18:37,360
uh

00:18:32,640 --> 00:18:40,080
convenient feature but it's not only

00:18:37,360 --> 00:18:40,080
it's not only the

00:18:40,799 --> 00:18:46,720
a nice property that you can

00:18:43,840 --> 00:18:48,080
emit final results the other property is

00:18:46,720 --> 00:18:49,840
that these operators can also

00:18:48,080 --> 00:18:52,000
automatically clean up their state

00:18:49,840 --> 00:18:53,760
because once they produce the final

00:18:52,000 --> 00:18:55,280
result a result that they never need to

00:18:53,760 --> 00:18:57,520
update again

00:18:55,280 --> 00:18:58,720
they can also remove all the state that

00:18:57,520 --> 00:19:01,520
was associated

00:18:58,720 --> 00:19:03,440
with this result or that was needed to

00:19:01,520 --> 00:19:05,360
compute this result as soon as the

00:19:03,440 --> 00:19:08,160
operator knows that some

00:19:05,360 --> 00:19:09,280
some state is not being not never being

00:19:08,160 --> 00:19:11,919
used again

00:19:09,280 --> 00:19:13,600
it can automatically clean up the state

00:19:11,919 --> 00:19:17,360
and hence you don't have this

00:19:13,600 --> 00:19:20,559
uh situation where uh state accumulates

00:19:17,360 --> 00:19:24,240
over a larger time uh

00:19:20,559 --> 00:19:25,200
uh over uh the over the time that the

00:19:24,240 --> 00:19:27,120
cure is running

00:19:25,200 --> 00:19:28,960
but instead when you have uh can you

00:19:27,120 --> 00:19:33,120
define your computation in a way

00:19:28,960 --> 00:19:34,720
that um the query

00:19:33,120 --> 00:19:37,840
defines a temporary balance of the

00:19:34,720 --> 00:19:40,960
operators then

00:19:37,840 --> 00:19:44,720
the the operators that process the data

00:19:40,960 --> 00:19:47,360
know when they can remove the state

00:19:44,720 --> 00:19:49,840
and hence the query can pretty much run

00:19:47,360 --> 00:19:49,840
forever

00:19:50,880 --> 00:19:54,160
in order to make this work uh the temp

00:19:53,200 --> 00:19:57,520
operators

00:19:54,160 --> 00:19:58,559
kind of need to uh need a reference to

00:19:57,520 --> 00:20:01,520
the time attribute

00:19:58,559 --> 00:20:01,840
that we specified in the uh in the table

00:20:01,520 --> 00:20:05,039
uh

00:20:01,840 --> 00:20:06,400
in the ddr clause so all of these

00:20:05,039 --> 00:20:09,600
temporary operators

00:20:06,400 --> 00:20:12,320
uh somewhere in there uh

00:20:09,600 --> 00:20:14,480
when you define the query you need to

00:20:12,320 --> 00:20:17,760
reference the time attribute and this

00:20:14,480 --> 00:20:18,320
uh works just with a regular sql center

00:20:17,760 --> 00:20:20,880
example

00:20:18,320 --> 00:20:21,600
i'll see some examples how this works

00:20:20,880 --> 00:20:25,840
based on

00:20:21,600 --> 00:20:25,840
temporary aggregation so

00:20:26,400 --> 00:20:30,159
link supports two different types of

00:20:28,240 --> 00:20:33,280
temporal applications

00:20:30,159 --> 00:20:34,880
i've talked about this before these are

00:20:33,280 --> 00:20:36,640
the group by window aggregation and the

00:20:34,880 --> 00:20:39,200
other window aggregations

00:20:36,640 --> 00:20:41,520
and uh we'll talk about both of these

00:20:39,200 --> 00:20:43,840
different types of aggregations

00:20:41,520 --> 00:20:45,120
now and just use this very simple

00:20:43,840 --> 00:20:48,720
example table

00:20:45,120 --> 00:20:52,559
and we assume that c time here is an

00:20:48,720 --> 00:20:53,600
event time attribute although as i said

00:20:52,559 --> 00:20:56,559
it doesn't really matter it could also

00:20:53,600 --> 00:20:56,559
be a processing dimension

00:20:59,360 --> 00:21:06,159
okay so let's say we want to compute

00:21:03,120 --> 00:21:08,480
the number of clicks per hour and user

00:21:06,159 --> 00:21:09,840
then this basically would translate to a

00:21:08,480 --> 00:21:11,760
group a

00:21:09,840 --> 00:21:14,960
or to a query that uses a group by

00:21:11,760 --> 00:21:14,960
window education like this

00:21:15,120 --> 00:21:21,760
we have a query that just reads

00:21:18,640 --> 00:21:22,559
from clips um then we have a group by

00:21:21,760 --> 00:21:25,760
clause

00:21:22,559 --> 00:21:26,400
we put the user into the group by clause

00:21:25,760 --> 00:21:28,640
because

00:21:26,400 --> 00:21:30,000
we want to compute the clicks per user

00:21:28,640 --> 00:21:32,559
but also per hour

00:21:30,000 --> 00:21:33,520
so and therefore we add this function

00:21:32,559 --> 00:21:37,600
call here called

00:21:33,520 --> 00:21:41,840
tumble tumble is a function that

00:21:37,600 --> 00:21:44,880
you can think of it as a function that

00:21:41,840 --> 00:21:48,799
generates a

00:21:44,880 --> 00:21:50,080
window id and we provide here the click

00:21:48,799 --> 00:21:51,360
time attribute this is the time

00:21:50,080 --> 00:21:54,720
attribute

00:21:51,360 --> 00:21:58,320
and we end a time interval of

00:21:54,720 --> 00:22:00,559
one of one hour

00:21:58,320 --> 00:22:00,559
and

00:22:01,520 --> 00:22:09,600
this will now uh basically perform

00:22:05,600 --> 00:22:12,720
uh uh all the the data will be grouped

00:22:09,600 --> 00:22:15,360
into uh into indicated groups based on

00:22:12,720 --> 00:22:16,960
a user and for every user in in the

00:22:15,360 --> 00:22:20,720
window

00:22:16,960 --> 00:22:23,600
of one hour so we have a have a

00:22:20,720 --> 00:22:23,600
group for

00:22:24,159 --> 00:22:29,760
the time from 12 to 1 from one to two

00:22:27,919 --> 00:22:31,440
from two to three and so on

00:22:29,760 --> 00:22:33,760
and the windows by default are kind of

00:22:31,440 --> 00:22:36,960
like aligned to

00:22:33,760 --> 00:22:40,640
um are aligned

00:22:36,960 --> 00:22:44,240
to uh the the epoch time which is

00:22:40,640 --> 00:22:47,679
like the um first of january

00:22:44,240 --> 00:22:51,520
uh or uh midnight at uh

00:22:47,679 --> 00:22:56,080
of first of january uh 1970 basically

00:22:51,520 --> 00:22:59,280
like the unix timestamp zero

00:22:56,080 --> 00:23:01,039
so um so we group the data here

00:22:59,280 --> 00:23:03,039
and then the select clause we just say

00:23:01,039 --> 00:23:04,240
uh we want to have the user we want to

00:23:03,039 --> 00:23:06,640
have account

00:23:04,240 --> 00:23:07,360
and there is this function tumble end

00:23:06,640 --> 00:23:10,799
which

00:23:07,360 --> 00:23:13,280
returns the timestamp and timestamp

00:23:10,799 --> 00:23:14,799
of the of the window so for the window

00:23:13,280 --> 00:23:17,760
from twelve to one

00:23:14,799 --> 00:23:19,919
uh tumble and function would return one

00:23:17,760 --> 00:23:23,039
o'clock for the window from

00:23:19,919 --> 00:23:26,000
one to two with return two and so on

00:23:23,039 --> 00:23:27,120
there's also a template start function

00:23:26,000 --> 00:23:31,039
that

00:23:27,120 --> 00:23:34,640
returns the the start of the

00:23:31,039 --> 00:23:37,200
start time of the window and you see

00:23:34,640 --> 00:23:37,919
here we have uh we referenced the click

00:23:37,200 --> 00:23:41,679
time attribute

00:23:37,919 --> 00:23:44,720
twice um in the tumble function

00:23:41,679 --> 00:23:46,000
here and here um and

00:23:44,720 --> 00:23:48,960
when you define the query you actually

00:23:46,000 --> 00:23:50,880
need to specify the

00:23:48,960 --> 00:23:52,480
this party exactly the same in the

00:23:50,880 --> 00:23:53,600
select clause as in the in the grouper

00:23:52,480 --> 00:23:57,440
clause otherwise

00:23:53,600 --> 00:24:00,320
you will get an error so how

00:23:57,440 --> 00:24:02,000
would this query be be executed now so

00:24:00,320 --> 00:24:03,120
let's say we have this clicks table here

00:24:02,000 --> 00:24:07,120
and the query is

00:24:03,120 --> 00:24:10,159
already running uh we get some data

00:24:07,120 --> 00:24:12,320
um the data would be uh basically

00:24:10,159 --> 00:24:14,799
grouped by the hour

00:24:12,320 --> 00:24:17,440
and uh for the for the first hour it

00:24:14,799 --> 00:24:19,679
would produce some some some result

00:24:17,440 --> 00:24:21,279
for the next hour we will also get some

00:24:19,679 --> 00:24:24,559
result uh and for the

00:24:21,279 --> 00:24:28,080
uh uh third hour then

00:24:24,559 --> 00:24:31,360
then again and as you can see the query

00:24:28,080 --> 00:24:34,480
always appends the result uh the

00:24:31,360 --> 00:24:37,440
result rows to the to the table whenever

00:24:34,480 --> 00:24:38,480
um the computation can be uh can be

00:24:37,440 --> 00:24:40,480
performed

00:24:38,480 --> 00:24:42,320
and you see here we have the timestamps

00:24:40,480 --> 00:24:44,480
here that kind of fallen through the

00:24:42,320 --> 00:24:45,360
window range from 12 o'clock to one

00:24:44,480 --> 00:24:48,400
o'clock

00:24:45,360 --> 00:24:52,159
and the tumble end function here

00:24:48,400 --> 00:24:56,240
returns the end timestamp of the window

00:24:52,159 --> 00:24:56,240
here of one o'clock

00:24:59,520 --> 00:25:06,080
there is not only the tumble function to

00:25:03,840 --> 00:25:07,760
that you can use to group data on uh

00:25:06,080 --> 00:25:09,279
there is also two other functions so

00:25:07,760 --> 00:25:11,120
tumblr basically looks like this if you

00:25:09,279 --> 00:25:12,960
have a

00:25:11,120 --> 00:25:14,799
tumblr function of t here is the time

00:25:12,960 --> 00:25:18,960
attribute of interval two hours

00:25:14,799 --> 00:25:22,960
it will have uh non overlapping

00:25:18,960 --> 00:25:26,960
or slice the slice time to

00:25:22,960 --> 00:25:30,799
non overlapping windows of two hours

00:25:26,960 --> 00:25:33,840
if you use the so-called hop window

00:25:30,799 --> 00:25:36,320
you uh specify two intervals

00:25:33,840 --> 00:25:37,840
one interval the first interval is the

00:25:36,320 --> 00:25:41,279
size of the window

00:25:37,840 --> 00:25:44,480
and the second interval is the

00:25:41,279 --> 00:25:45,279
um step size in which the windows are

00:25:44,480 --> 00:25:47,520
shifted

00:25:45,279 --> 00:25:49,600
so if for instance here if we have a

00:25:47,520 --> 00:25:53,520
window set of two hours and a

00:25:49,600 --> 00:25:56,799
step size of one hour then every hour a

00:25:53,520 --> 00:25:59,120
new window is being started

00:25:56,799 --> 00:26:01,120
which then lasts for two hours this also

00:25:59,120 --> 00:26:03,919
means that

00:26:01,120 --> 00:26:05,039
all records are always being assigned to

00:26:03,919 --> 00:26:07,120
two windows

00:26:05,039 --> 00:26:08,960
so since this window is overlapping so

00:26:07,120 --> 00:26:10,400
this record is part of

00:26:08,960 --> 00:26:12,080
part of this window but also part of

00:26:10,400 --> 00:26:13,840
this window

00:26:12,080 --> 00:26:15,679
and so on and that's basically how we

00:26:13,840 --> 00:26:17,919
can have overlapping windows

00:26:15,679 --> 00:26:20,320
and this can be used for some kind of

00:26:17,919 --> 00:26:20,320
like uh

00:26:21,360 --> 00:26:25,039
sliding uh sliding smoothing for

00:26:23,760 --> 00:26:27,039
instance

00:26:25,039 --> 00:26:29,279
um and then there is also the session

00:26:27,039 --> 00:26:34,159
window

00:26:29,279 --> 00:26:37,440
sorry there's a question in the chat

00:26:34,159 --> 00:26:37,440
oh okay thanks for

00:26:38,110 --> 00:26:43,360
[Music]

00:26:41,039 --> 00:26:43,360
um

00:26:45,760 --> 00:26:53,039
so um the

00:26:49,600 --> 00:26:56,640
yeah so the this is a good question

00:26:53,039 --> 00:26:59,840
so there is basically um

00:26:56,640 --> 00:27:02,080
so the question i suppose you can

00:26:59,840 --> 00:27:04,960
see the question but the question is if

00:27:02,080 --> 00:27:08,000
the window is from 12 to

00:27:04,960 --> 00:27:11,440
from 12 to 1 shouldn't uh

00:27:08,000 --> 00:27:14,799
the record from 12 o'clock

00:27:11,440 --> 00:27:18,559
also be in the earlier window so in fact

00:27:14,799 --> 00:27:22,000
i was a little bit imprecise so the end

00:27:18,559 --> 00:27:24,799
range is exclusive so everything

00:27:22,000 --> 00:27:26,480
if you have the in the tumble function

00:27:24,799 --> 00:27:29,360
so a window from

00:27:26,480 --> 00:27:30,159
12 o'clock a tumble window that is one

00:27:29,360 --> 00:27:32,480
hour

00:27:30,159 --> 00:27:33,440
i would start at 12 o'clock and would

00:27:32,480 --> 00:27:36,720
close just

00:27:33,440 --> 00:27:40,720
before one o'clock so 12 o'clock

00:27:36,720 --> 00:27:41,360
95 95 999 would be included in the

00:27:40,720 --> 00:27:45,360
window

00:27:41,360 --> 00:27:47,840
but uh 13 o'clock would not be

00:27:45,360 --> 00:27:49,039
so it's uh the end timestamp here is

00:27:47,840 --> 00:27:53,840
basically the

00:27:49,039 --> 00:27:57,279
um not not part

00:27:53,840 --> 00:27:59,919
a record with uh that had a timestamp of

00:27:57,279 --> 00:28:02,399
of one o'clock would not be part of this

00:27:59,919 --> 00:28:07,360
window but be part of the next window

00:28:02,399 --> 00:28:07,360
there is not only the

00:28:07,440 --> 00:28:10,799
tumble start and tumble and function

00:28:09,360 --> 00:28:14,320
there is also the super

00:28:10,799 --> 00:28:18,080
tumbler road time function

00:28:14,320 --> 00:28:21,360
and this function uh returns the valid

00:28:18,080 --> 00:28:24,320
uh event developed times

00:28:21,360 --> 00:28:25,840
time attribute again so another an

00:28:24,320 --> 00:28:28,880
attribute on which you can

00:28:25,840 --> 00:28:32,320
do uh next

00:28:28,880 --> 00:28:37,120
follow-up time operations and uh

00:28:32,320 --> 00:28:45,840
this is exactly uh the end of the

00:28:37,120 --> 00:28:45,840
of the window so for instance

00:28:46,159 --> 00:28:49,840
maybe i guess that was a little bit

00:28:47,520 --> 00:28:53,120
confusing um so if we

00:28:49,840 --> 00:28:54,799
have a tumblr window of i'm just

00:28:53,120 --> 00:28:59,840
chatting write writing something in the

00:28:54,799 --> 00:28:59,840
chat now

00:29:01,039 --> 00:29:05,440
if i have this window then

00:29:03,660 --> 00:29:10,240
[Music]

00:29:05,440 --> 00:29:10,240
tap it start for the window from

00:29:11,039 --> 00:29:15,840
uh twelve to one time start would be

00:29:16,640 --> 00:29:27,840
let's return this number uh

00:29:20,640 --> 00:29:27,840
and would return

00:29:27,919 --> 00:29:41,600
this and tumblr

00:29:31,039 --> 00:29:45,520
road time would return

00:29:41,600 --> 00:29:48,000
um this and tumble road time is

00:29:45,520 --> 00:29:49,200
uh tumble start and tumble and are just

00:29:48,000 --> 00:29:52,840
regular timestamps

00:29:49,200 --> 00:29:54,159
they can cannot be used for further time

00:29:52,840 --> 00:29:57,919
operations

00:29:54,159 --> 00:29:59,520
the reason for that is that they're not

00:29:57,919 --> 00:30:00,960
really in line with the with the

00:29:59,520 --> 00:30:02,159
watermarks generated by the system

00:30:00,960 --> 00:30:06,559
anymore

00:30:02,159 --> 00:30:09,679
whereas tumbler road time is still

00:30:06,559 --> 00:30:11,600
aligned with the uh with the watermarks

00:30:09,679 --> 00:30:13,279
that the query uh

00:30:11,600 --> 00:30:15,120
processes and therefore you could

00:30:13,279 --> 00:30:18,399
perform for instance

00:30:15,120 --> 00:30:20,000
another group by operation based on

00:30:18,399 --> 00:30:23,840
uh based on the attribute that you get

00:30:20,000 --> 00:30:23,840
from tumblr rota

00:30:40,399 --> 00:30:43,200
okay um

00:30:43,520 --> 00:30:48,159
so in addition to the temple and top

00:30:45,840 --> 00:30:51,279
windows there's also the uh

00:30:48,159 --> 00:30:52,960
session window where you again provide a

00:30:51,279 --> 00:30:54,720
time attribute

00:30:52,960 --> 00:30:56,880
and then an interval but this interval

00:30:54,720 --> 00:30:57,760
is does not specify the size of the

00:30:56,880 --> 00:31:00,240
window

00:30:57,760 --> 00:31:01,279
but rather it specifies the size of a

00:31:00,240 --> 00:31:04,640
gap

00:31:01,279 --> 00:31:07,360
so basically the data is then

00:31:04,640 --> 00:31:09,279
grouped based on gaps of inactivity

00:31:07,360 --> 00:31:12,080
inactivity here

00:31:09,279 --> 00:31:13,360
means not seeing a record within this

00:31:12,080 --> 00:31:16,960
time range

00:31:13,360 --> 00:31:17,760
so if we have a session window of 30

00:31:16,960 --> 00:31:22,080
minutes defined

00:31:17,760 --> 00:31:25,840
we would get here for this data here one

00:31:22,080 --> 00:31:27,919
session uh with these five records

00:31:25,840 --> 00:31:29,760
then we would have a gap that is larger

00:31:27,919 --> 00:31:32,320
than 30 minutes

00:31:29,760 --> 00:31:33,760
hence after 30 minutes this window will

00:31:32,320 --> 00:31:36,960
be closed

00:31:33,760 --> 00:31:38,240
and then as soon as the next record is

00:31:36,960 --> 00:31:41,360
received

00:31:38,240 --> 00:31:43,519
the new window is a new

00:31:41,360 --> 00:31:45,679
session windows started and data is

00:31:43,519 --> 00:31:49,039
added as long as

00:31:45,679 --> 00:31:49,760
there's no gap of 30 min of at least 30

00:31:49,039 --> 00:31:53,039
minutes

00:31:49,760 --> 00:31:54,480
and once we find a gap of these 30

00:31:53,039 --> 00:31:55,840
minutes

00:31:54,480 --> 00:31:57,600
this window is again close the

00:31:55,840 --> 00:31:58,240
computation is performed and when the

00:31:57,600 --> 00:32:04,320
next

00:31:58,240 --> 00:32:04,320
record is received and you win is opened

00:32:07,440 --> 00:32:11,760
um so these group by group by winning

00:32:10,799 --> 00:32:14,240
allegations

00:32:11,760 --> 00:32:15,519
like once one way how you can group data

00:32:14,240 --> 00:32:18,320
based on

00:32:15,519 --> 00:32:20,000
time the other one is this support over

00:32:18,320 --> 00:32:28,399
window application

00:32:20,000 --> 00:32:30,960
let me quickly check um

00:32:28,399 --> 00:32:30,960
let's see

00:32:40,840 --> 00:32:43,840
okay

00:32:45,919 --> 00:32:49,840
no idea how this works um

00:32:50,640 --> 00:32:54,799
anyway um do you know how the

00:32:54,840 --> 00:33:00,080
i um

00:32:57,919 --> 00:33:02,799
are you aware how uh sql over windows

00:33:00,080 --> 00:33:05,600
work or should i uh

00:33:02,799 --> 00:33:05,600
go into that a bit

00:33:06,480 --> 00:33:12,960
i think it's not a okay yeah so it's a

00:33:10,399 --> 00:33:14,480
rather it's i think it's been part of

00:33:12,960 --> 00:33:16,399
the uh

00:33:14,480 --> 00:33:18,640
sql standard for for quite some time but

00:33:16,399 --> 00:33:20,640
it's not used very often

00:33:18,640 --> 00:33:23,279
um however i think in the in the context

00:33:20,640 --> 00:33:26,480
of streaming it's actually a very nice

00:33:23,279 --> 00:33:29,360
nice way to a nice

00:33:26,480 --> 00:33:30,320
nice feature you can work with streaming

00:33:29,360 --> 00:33:34,640
data

00:33:30,320 --> 00:33:36,799
so um so one example what you can do

00:33:34,640 --> 00:33:39,279
with these over windows is

00:33:36,799 --> 00:33:40,399
imagine we have this uh click clicks

00:33:39,279 --> 00:33:43,600
table

00:33:40,399 --> 00:33:46,080
uh which gets a new record

00:33:43,600 --> 00:33:47,600
for every click that a user is doing so

00:33:46,080 --> 00:33:48,880
let's say we want to compute for every

00:33:47,600 --> 00:33:52,000
click that was done

00:33:48,880 --> 00:33:55,279
how often this url was clicked uh

00:33:52,000 --> 00:33:57,039
in the last in the previous two hours

00:33:55,279 --> 00:33:59,039
so we kind of like need to perform

00:33:57,039 --> 00:34:00,080
computation for every input row we're

00:33:59,039 --> 00:34:02,640
not

00:34:00,080 --> 00:34:03,840
uh reducing the data but we want based

00:34:02,640 --> 00:34:05,600
on a on a

00:34:03,840 --> 00:34:06,880
single row we want to look two hours

00:34:05,600 --> 00:34:10,639
back in time and count

00:34:06,880 --> 00:34:11,280
how often the uh the row was clicked and

00:34:10,639 --> 00:34:14,480
for this

00:34:11,280 --> 00:34:15,119
there is uh this secret syntax again

00:34:14,480 --> 00:34:16,639
this is

00:34:15,119 --> 00:34:19,359
standard sequence netflix it's nothing

00:34:16,639 --> 00:34:22,399
that we invented

00:34:19,359 --> 00:34:23,760
and here you can define a so-called

00:34:22,399 --> 00:34:27,200
window

00:34:23,760 --> 00:34:30,320
uh window and give it an alias

00:34:27,200 --> 00:34:33,440
here we give it the alias a w and

00:34:30,320 --> 00:34:36,000
then the window is defined

00:34:33,440 --> 00:34:37,040
based on these three clauses the first

00:34:36,000 --> 00:34:40,240
one is a

00:34:37,040 --> 00:34:43,839
partition by clause here we partition

00:34:40,240 --> 00:34:44,480
by url because we kind of want to

00:34:43,839 --> 00:34:48,159
perform

00:34:44,480 --> 00:34:51,839
or want to group perform a computation

00:34:48,159 --> 00:34:51,839
and aggregation based on the url

00:34:52,000 --> 00:34:55,119
so we want to know how often each

00:34:54,159 --> 00:34:57,200
individual u

00:34:55,119 --> 00:34:58,880
each url was was clicked so we

00:34:57,200 --> 00:35:01,599
partitioned by url

00:34:58,880 --> 00:35:02,400
uh we have to give an order by claw

00:35:01,599 --> 00:35:03,920
order

00:35:02,400 --> 00:35:05,920
condition here and we here in the order

00:35:03,920 --> 00:35:09,359
by clause we put the

00:35:05,920 --> 00:35:12,320
click time so here again this is the

00:35:09,359 --> 00:35:13,040
the point where we have to tell tell the

00:35:12,320 --> 00:35:15,440
system

00:35:13,040 --> 00:35:16,880
here we want to perform this operation

00:35:15,440 --> 00:35:18,800
based on

00:35:16,880 --> 00:35:20,640
based on our time attribute that the

00:35:18,800 --> 00:35:24,720
table provides

00:35:20,640 --> 00:35:26,960
and then you can perform a range

00:35:24,720 --> 00:35:28,640
that is basically that depends on how

00:35:26,960 --> 00:35:32,000
the data is ordered

00:35:28,640 --> 00:35:34,000
and the partition basically tells which

00:35:32,000 --> 00:35:38,560
data is included into the

00:35:34,000 --> 00:35:41,359
uh into this partition and

00:35:38,560 --> 00:35:41,920
here we define the range as between

00:35:41,359 --> 00:35:46,079
interval

00:35:41,920 --> 00:35:48,160
2 hours preceding and the current row

00:35:46,079 --> 00:35:51,440
so when you can when you when you think

00:35:48,160 --> 00:35:53,200
of a of a row it will uh

00:35:51,440 --> 00:35:54,960
perform a computation here and we

00:35:53,200 --> 00:35:57,280
basically say we want to perform a

00:35:54,960 --> 00:36:01,200
current application over this window

00:35:57,280 --> 00:36:05,599
then when we when the system processes

00:36:01,200 --> 00:36:09,359
a click coming from clicks it will

00:36:05,599 --> 00:36:13,040
look what's the url for this click

00:36:09,359 --> 00:36:16,160
it will look what are all the other urls

00:36:13,040 --> 00:36:20,480
uh um

00:36:16,160 --> 00:36:24,320
that i've uh how often was this url

00:36:20,480 --> 00:36:27,440
clicked within the last two hours

00:36:24,320 --> 00:36:29,760
um and the data

00:36:27,440 --> 00:36:30,720
within these last two hours is ordered

00:36:29,760 --> 00:36:33,520
by

00:36:30,720 --> 00:36:34,160
by this uh whether by the time attribute

00:36:33,520 --> 00:36:36,160
i have a

00:36:34,160 --> 00:36:37,599
little example here let's uh let's hope

00:36:36,160 --> 00:36:42,240
that this makes it

00:36:37,599 --> 00:36:44,800
a bit clear so here we say uh count over

00:36:42,240 --> 00:36:45,599
order by t so we i left the partition

00:36:44,800 --> 00:36:48,240
part back

00:36:45,599 --> 00:36:49,520
uh out here because it just just

00:36:48,240 --> 00:36:51,839
complicate things

00:36:49,520 --> 00:36:55,839
let's just focus on on the order by

00:36:51,839 --> 00:36:55,839
clause and the range part

00:36:56,079 --> 00:37:02,160
and if we know get some data

00:36:59,280 --> 00:37:03,520
yeah we get a single record here we get

00:37:02,160 --> 00:37:06,880
the record

00:37:03,520 --> 00:37:11,200
we have to look two hours back and

00:37:06,880 --> 00:37:13,200
let's say there was no data for this um

00:37:11,200 --> 00:37:16,160
this is the first record that we see and

00:37:13,200 --> 00:37:18,320
then the count aggregation will return

00:37:16,160 --> 00:37:19,839
one for this record so we get the next

00:37:18,320 --> 00:37:21,760
record

00:37:19,839 --> 00:37:23,599
um from this record we look again two

00:37:21,760 --> 00:37:25,520
hours back and we see

00:37:23,599 --> 00:37:28,160
hey there was a record and it's exactly

00:37:25,520 --> 00:37:32,400
this record hence the count for this

00:37:28,160 --> 00:37:34,160
is uh is two we get the next record

00:37:32,400 --> 00:37:36,400
here again all the three are still

00:37:34,160 --> 00:37:38,880
falling to this window

00:37:36,400 --> 00:37:39,680
the count is three we get the next

00:37:38,880 --> 00:37:43,119
record

00:37:39,680 --> 00:37:45,839
these two are not no longer part of the

00:37:43,119 --> 00:37:47,040
uh are more than two hours apart from

00:37:45,839 --> 00:37:48,480
this new record here

00:37:47,040 --> 00:37:50,240
that's why they're not part of the

00:37:48,480 --> 00:37:53,680
computation so the

00:37:50,240 --> 00:37:54,640
uh the account aggregation here returns

00:37:53,680 --> 00:37:58,000
two

00:37:54,640 --> 00:38:00,079
um another two three

00:37:58,000 --> 00:38:01,119
and four and you can do pretty much

00:38:00,079 --> 00:38:03,440
every any

00:38:01,119 --> 00:38:05,119
uh aggregation function here can be uh

00:38:03,440 --> 00:38:08,000
can be evaluated over such a

00:38:05,119 --> 00:38:08,800
such a window you get also some values

00:38:08,000 --> 00:38:10,480
of

00:38:08,800 --> 00:38:12,079
some some values of records that are

00:38:10,480 --> 00:38:15,520
within these two hours

00:38:12,079 --> 00:38:17,359
or you can compute min max average and

00:38:15,520 --> 00:38:21,200
so on

00:38:17,359 --> 00:38:24,720
um yeah so this is a fairly

00:38:21,200 --> 00:38:28,079
uh fairly convenient uh

00:38:24,720 --> 00:38:31,119
or powerful syntax for doing lots of

00:38:28,079 --> 00:38:33,760
uh lots of interesting things over

00:38:31,119 --> 00:38:36,160
over streams that are like naturally all

00:38:33,760 --> 00:38:39,520
in by time

00:38:36,160 --> 00:38:39,520
let me quickly check

00:38:39,920 --> 00:38:48,079
if this um

00:38:43,359 --> 00:38:48,079
was that clear how it works oh yes

00:38:49,440 --> 00:38:56,000
yes please um the order by

00:38:52,800 --> 00:38:57,760
um argument that's basically to indicate

00:38:56,000 --> 00:39:00,720
what the range

00:38:57,760 --> 00:39:03,359
should look at right it doesn't order

00:39:00,720 --> 00:39:06,640
anything by itself

00:39:03,359 --> 00:39:08,800
um yes um

00:39:06,640 --> 00:39:10,480
so you could also also think of if you

00:39:08,800 --> 00:39:14,720
have an aggregation function that would

00:39:10,480 --> 00:39:17,839
something like gender last for the first

00:39:14,720 --> 00:39:18,880
value of the group then the order

00:39:17,839 --> 00:39:22,640
matters

00:39:18,880 --> 00:39:22,640
the system here does not really

00:39:24,880 --> 00:39:28,880
doesn't really order the data

00:39:26,960 --> 00:39:32,800
unnecessarily it would basically

00:39:28,880 --> 00:39:36,160
uh um it's really needed so

00:39:32,800 --> 00:39:40,160
like from from a sequence point of view

00:39:36,160 --> 00:39:43,920
uh secret does not work on

00:39:40,160 --> 00:39:46,880
order data right it always works on on

00:39:43,920 --> 00:39:47,680
on sets of data so we kind of like need

00:39:46,880 --> 00:39:52,560
to

00:39:47,680 --> 00:39:55,119
explicitly tell uh tell

00:39:52,560 --> 00:39:56,480
any database it wants to evaluate an

00:39:55,119 --> 00:39:59,760
over window

00:39:56,480 --> 00:40:03,760
how should the data be be ordered so

00:39:59,760 --> 00:40:06,240
in plain sql uh this also works on

00:40:03,760 --> 00:40:07,680
basically honor any any audit attributes

00:40:06,240 --> 00:40:09,920
so not only on time

00:40:07,680 --> 00:40:11,119
so you could also like in a regular

00:40:09,920 --> 00:40:13,520
database you could

00:40:11,119 --> 00:40:14,319
have an overview that just brought us

00:40:13,520 --> 00:40:17,440
some

00:40:14,319 --> 00:40:20,480
some numeric values and then

00:40:17,440 --> 00:40:21,599
performs the computation here in our

00:40:20,480 --> 00:40:24,800
context here

00:40:21,599 --> 00:40:28,000
we only support these over if you

00:40:24,800 --> 00:40:30,319
order on time and that's pretty much

00:40:28,000 --> 00:40:33,359
because we can like work on

00:40:30,319 --> 00:40:35,520
evolving data and

00:40:33,359 --> 00:40:37,680
it only works if we assume the data is

00:40:35,520 --> 00:40:40,400
already ordered which is the case

00:40:37,680 --> 00:40:42,160
if we order on time if we would have to

00:40:40,400 --> 00:40:44,960
order on anything else

00:40:42,160 --> 00:40:46,480
we could never really finish the order

00:40:44,960 --> 00:40:49,040
because we would have to wait for more

00:40:46,480 --> 00:40:49,040
data to see

00:41:01,280 --> 00:41:04,319
okay so um

00:41:04,480 --> 00:41:09,839
there's one more thing with respect to

00:41:07,040 --> 00:41:12,000
time attributes that is like

00:41:09,839 --> 00:41:13,040
i said these are basically regular

00:41:12,000 --> 00:41:15,359
timestamps

00:41:13,040 --> 00:41:16,480
but they have this uh special property

00:41:15,359 --> 00:41:18,839
that flink

00:41:16,480 --> 00:41:21,520
basically knows that these time systems

00:41:18,839 --> 00:41:25,839
are

00:41:21,520 --> 00:41:27,839
kind of like ascending um and uh

00:41:25,839 --> 00:41:29,440
ordered with a little bit possibly with

00:41:27,839 --> 00:41:33,040
a little bit of odorless

00:41:29,440 --> 00:41:36,240
but uh for that we have the watermarks

00:41:33,040 --> 00:41:36,880
so um it might happen or depending on

00:41:36,240 --> 00:41:38,960
what you do

00:41:36,880 --> 00:41:39,920
how you use these time attributes it

00:41:38,960 --> 00:41:43,040
might happen that an

00:41:39,920 --> 00:41:46,160
event time attribute is uh

00:41:43,040 --> 00:41:48,720
converted or basically yeah is being

00:41:46,160 --> 00:41:51,599
basically converted into a just regular

00:41:48,720 --> 00:41:55,280
timestamp it cannot be used

00:41:51,599 --> 00:41:55,920
as a time attribute so for instance when

00:41:55,280 --> 00:41:58,560
you have a

00:41:55,920 --> 00:41:59,440
regular timestamp you could not you

00:41:58,560 --> 00:42:01,920
cannot use

00:41:59,440 --> 00:42:03,440
a regular timestamp here in this order

00:42:01,920 --> 00:42:06,640
by clause because

00:42:03,440 --> 00:42:10,960
um flink would not know that this is uh

00:42:06,640 --> 00:42:14,240
this times timestamp is is ascending

00:42:10,960 --> 00:42:17,040
i could not evaluate this

00:42:14,240 --> 00:42:18,800
or perform this computation properly so

00:42:17,040 --> 00:42:22,800
it really needs to be

00:42:18,800 --> 00:42:27,119
an attribute that isn't

00:42:22,800 --> 00:42:29,359
as an uh proper time attribute

00:42:27,119 --> 00:42:31,440
which means flint knows it's ascending

00:42:29,359 --> 00:42:32,800
if it's just a timestamp any any kind of

00:42:31,440 --> 00:42:35,119
timestamp you can also

00:42:32,800 --> 00:42:36,319
have tables with whatever time sims you

00:42:35,119 --> 00:42:38,640
want

00:42:36,319 --> 00:42:39,599
but in that case flink lacks the

00:42:38,640 --> 00:42:41,920
knowledge

00:42:39,599 --> 00:42:44,000
now that it's ascending and cannot

00:42:41,920 --> 00:42:47,520
really perform the computation

00:42:44,000 --> 00:42:49,440
and it could happen that you have a time

00:42:47,520 --> 00:42:52,720
attribute and that it kind of

00:42:49,440 --> 00:42:56,400
loses this time property

00:42:52,720 --> 00:42:58,000
so when this happens um yeah as i said

00:42:56,400 --> 00:43:00,319
the event attribute becomes just a

00:42:58,000 --> 00:43:01,920
regular timestamp

00:43:00,319 --> 00:43:04,160
and it cannot be used in these template

00:43:01,920 --> 00:43:06,160
operations anymore and this

00:43:04,160 --> 00:43:09,119
happens for instance once you try to

00:43:06,160 --> 00:43:12,000
modify the time attribute

00:43:09,119 --> 00:43:12,640
for instance if you do something like a

00:43:12,000 --> 00:43:14,079
like this

00:43:12,640 --> 00:43:17,119
flow operation if you float the

00:43:14,079 --> 00:43:19,680
timestamp to a minute um

00:43:17,119 --> 00:43:20,720
then the the result of this will not get

00:43:19,680 --> 00:43:22,720
an

00:43:20,720 --> 00:43:24,480
event time attribute anymore but it

00:43:22,720 --> 00:43:27,520
would just be a

00:43:24,480 --> 00:43:29,520
regular timestamp um we do that for

00:43:27,520 --> 00:43:30,560
any kind of computation here so there's

00:43:29,520 --> 00:43:33,599
also ways

00:43:30,560 --> 00:43:36,960
that you uh that you could for instance

00:43:33,599 --> 00:43:38,240
just uh just add a constant to the time

00:43:36,960 --> 00:43:39,119
and then you would say yeah okay it's

00:43:38,240 --> 00:43:41,280
still

00:43:39,119 --> 00:43:42,880
if i add one minute to every timestamp

00:43:41,280 --> 00:43:46,160
it is still ordered

00:43:42,880 --> 00:43:47,599
but um we didn't make the system smart

00:43:46,160 --> 00:43:48,480
enough to really figure out what's the

00:43:47,599 --> 00:43:50,960
semantics

00:43:48,480 --> 00:43:52,560
of a of an expression that you apply on

00:43:50,960 --> 00:43:54,720
the on the timestamp so

00:43:52,560 --> 00:43:55,920
whenever you use such a time stamp in an

00:43:54,720 --> 00:43:57,760
expression

00:43:55,920 --> 00:43:59,680
the result is just a regular time stamp

00:43:57,760 --> 00:44:01,599
it's not an uh not an inventive

00:43:59,680 --> 00:44:06,400
attribute

00:44:01,599 --> 00:44:06,400
so that's uh one one way basically to

00:44:06,720 --> 00:44:12,240
lose the the time property and

00:44:09,839 --> 00:44:13,280
uh the other one if you use it in an

00:44:12,240 --> 00:44:17,280
operator

00:44:13,280 --> 00:44:20,640
that does not preserve the uh order

00:44:17,280 --> 00:44:24,319
uh in in in the output so

00:44:20,640 --> 00:44:27,520
there's uh for instance uh

00:44:24,319 --> 00:44:30,880
some uh some example here

00:44:27,520 --> 00:44:32,319
would be um if you use a non-windowed

00:44:30,880 --> 00:44:34,960
aggregation and you put the

00:44:32,319 --> 00:44:35,440
clip timestamp into the group by clause

00:44:34,960 --> 00:44:38,240
then you

00:44:35,440 --> 00:44:38,960
you can do that you would basically

00:44:38,240 --> 00:44:42,720
group on the

00:44:38,960 --> 00:44:45,440
uh on the click time here but

00:44:42,720 --> 00:44:46,560
the output of this grouper operator

00:44:45,440 --> 00:44:49,680
operator

00:44:46,560 --> 00:44:51,200
would first of all would be updated

00:44:49,680 --> 00:44:52,240
whenever there's a new record coming

00:44:51,200 --> 00:44:55,440
from clicks

00:44:52,240 --> 00:44:56,960
um and it would not be in the in the

00:44:55,440 --> 00:44:59,599
timestamp order anymore

00:44:56,960 --> 00:45:00,800
so the output of this query would uh the

00:44:59,599 --> 00:45:04,000
the

00:45:00,800 --> 00:45:07,280
output of the query uh would not be

00:45:04,000 --> 00:45:10,640
ordered on clicktime anymore and hence

00:45:07,280 --> 00:45:12,400
the system has to convert it down into a

00:45:10,640 --> 00:45:14,079
regular timestep attribute and the same

00:45:12,400 --> 00:45:17,599
also holds for joints

00:45:14,079 --> 00:45:20,319
that don't have a temporal condition

00:45:17,599 --> 00:45:22,000
we will talk about that later in detail

00:45:20,319 --> 00:45:24,000
but

00:45:22,000 --> 00:45:25,119
you can think of this as you have a have

00:45:24,000 --> 00:45:28,720
a table of with

00:45:25,119 --> 00:45:31,760
some data some records here

00:45:28,720 --> 00:45:34,000
um that let's say that arrived

00:45:31,760 --> 00:45:35,359
you started the query one hour ago and

00:45:34,000 --> 00:45:38,400
you now have the data of

00:45:35,359 --> 00:45:41,520
one hour here if no record comes from

00:45:38,400 --> 00:45:44,560
for for the other table it can join with

00:45:41,520 --> 00:45:45,680
any record in the table so we could join

00:45:44,560 --> 00:45:46,720
with the first record

00:45:45,680 --> 00:45:48,800
and then you have to forward the

00:45:46,720 --> 00:45:50,800
timestamp of the first record

00:45:48,800 --> 00:45:52,160
then another record comes and joins with

00:45:50,800 --> 00:45:54,560
the with the last one

00:45:52,160 --> 00:45:55,599
so you have to forward the record of the

00:45:54,560 --> 00:45:57,200
last one and then another

00:45:55,599 --> 00:46:00,240
one comes and joins again with the first

00:45:57,200 --> 00:46:03,040
one so the order of the timestamp of the

00:46:00,240 --> 00:46:04,240
of the result is absolutely out of order

00:46:03,040 --> 00:46:06,480
and

00:46:04,240 --> 00:46:09,359
hence we cannot really use it as a as a

00:46:06,480 --> 00:46:11,920
time attribute anymore

00:46:09,359 --> 00:46:13,760
for processing time attributes this this

00:46:11,920 --> 00:46:18,000
situation is a little bit easier

00:46:13,760 --> 00:46:20,640
because there we always

00:46:18,000 --> 00:46:21,359
just query the time from the from the

00:46:20,640 --> 00:46:24,720
system

00:46:21,359 --> 00:46:26,640
so here we just use the uh

00:46:24,720 --> 00:46:28,079
use the condition when the present time

00:46:26,640 --> 00:46:30,400
attribute is modified

00:46:28,079 --> 00:46:32,720
then it also becomes just a regular

00:46:30,400 --> 00:46:36,240
timestamp and it's not a

00:46:32,720 --> 00:46:36,240
not another time attribute anymore

00:46:36,640 --> 00:46:43,599
so yeah to summarize many of the

00:46:40,960 --> 00:46:44,720
traditional streaming stream processing

00:46:43,599 --> 00:46:47,760
operations can be

00:46:44,720 --> 00:46:53,599
can be done with a sql as well

00:46:47,760 --> 00:46:53,599
and flink provides tamper operators

00:46:53,920 --> 00:46:58,400
for that to do that efficiently and with

00:46:57,200 --> 00:47:01,920
the

00:46:58,400 --> 00:47:02,480
small small state sizes um the input of

00:47:01,920 --> 00:47:04,000
these

00:47:02,480 --> 00:47:05,760
input and output of these queries have

00:47:04,000 --> 00:47:06,319
to be append only tables or the input

00:47:05,760 --> 00:47:07,599
have to

00:47:06,319 --> 00:47:09,359
have to be applied only tables in the

00:47:07,599 --> 00:47:11,599
output then automatically are apparent

00:47:09,359 --> 00:47:14,800
only tables

00:47:11,599 --> 00:47:17,359
these queries should only use these

00:47:14,800 --> 00:47:19,680
record at the time operators like

00:47:17,359 --> 00:47:20,880
filters the where clause or the select

00:47:19,680 --> 00:47:25,839
clause

00:47:20,880 --> 00:47:25,839
or these special time table operators

00:47:26,319 --> 00:47:30,319
time attributes are defined in the table

00:47:27,839 --> 00:47:34,079
schema in the ddl

00:47:30,319 --> 00:47:35,520
you can define event time and or process

00:47:34,079 --> 00:47:39,520
time adwords you can actually

00:47:35,520 --> 00:47:40,960
also define tablets that have both

00:47:39,520 --> 00:47:43,520
and then when the query is actually

00:47:40,960 --> 00:47:45,760
being processed these

00:47:43,520 --> 00:47:48,720
template operators process the data

00:47:45,760 --> 00:47:52,559
based on these time attributes

00:47:48,720 --> 00:47:54,640
and the output is always final results

00:47:52,559 --> 00:47:55,680
that's also why the output is only by

00:47:54,640 --> 00:47:58,319
only tables

00:47:55,680 --> 00:47:59,599
and these operators also automatically

00:47:58,319 --> 00:48:03,680
clean up the state

00:47:59,599 --> 00:48:03,680
when as time moves forward

00:48:05,359 --> 00:48:10,240
okay then let's have a look at some of

00:48:08,240 --> 00:48:13,359
the exercises

00:48:10,240 --> 00:48:17,119
um i would say

00:48:13,359 --> 00:48:20,319
uh um i'll give you again

00:48:17,119 --> 00:48:23,760
a few minutes that can uh

00:48:20,319 --> 00:48:25,470
play with the with the uh or this

00:48:23,760 --> 00:48:26,800
system so

00:48:25,470 --> 00:48:29,920
[Music]

00:48:26,800 --> 00:48:29,920
um it's here

00:48:30,160 --> 00:48:34,160
number three curious and time and

00:48:33,280 --> 00:48:37,119
there's a

00:48:34,160 --> 00:48:38,720
few exercises for this and one for a

00:48:37,119 --> 00:48:40,480
group by window aggregation and one for

00:48:38,720 --> 00:48:44,240
an over window application

00:48:40,480 --> 00:48:49,359
um yeah just

00:48:44,240 --> 00:48:52,720
let's say at um

00:48:49,359 --> 00:48:54,960
7 30 we continue you can just um

00:48:52,720 --> 00:48:56,240
yeah see how far you get if you have any

00:48:54,960 --> 00:48:59,760
questions uh yeah

00:48:56,240 --> 00:49:03,839
let me know and then we can discuss

00:48:59,760 --> 00:49:03,839
uh the solution afterwards

00:49:23,520 --> 00:49:28,079
all right let's have a look at the

00:49:26,319 --> 00:49:33,760
exercise so

00:49:28,079 --> 00:49:33,760
the um task here was to

00:49:34,240 --> 00:49:37,520
count the number of arriving and

00:49:36,319 --> 00:49:40,800
departing rights

00:49:37,520 --> 00:49:44,160
per area in minutes of fi

00:49:40,800 --> 00:49:46,720
in windows of five minutes

00:49:44,160 --> 00:49:46,720
so the

00:49:49,280 --> 00:49:53,680
and we're only interested in events that

00:49:51,040 --> 00:49:56,160
start and end in new york city

00:49:53,680 --> 00:49:57,040
let's start or end in new york city and

00:49:56,160 --> 00:49:59,280
areas

00:49:57,040 --> 00:50:00,800
with at least five arriving and

00:49:59,280 --> 00:50:04,400
departing rights

00:50:00,800 --> 00:50:08,400
so this is the uh the query here

00:50:04,400 --> 00:50:08,400
that's the the result

00:50:08,480 --> 00:50:16,079
so we are reading from the rights table

00:50:12,720 --> 00:50:18,800
we filter on the

00:50:16,079 --> 00:50:20,079
using this user different function is in

00:50:18,800 --> 00:50:24,240
new york city

00:50:20,079 --> 00:50:26,160
and then we group on the area id because

00:50:24,240 --> 00:50:29,200
we want to

00:50:26,160 --> 00:50:31,920
want to count per area

00:50:29,200 --> 00:50:32,640
we also want to distinguish between

00:50:31,920 --> 00:50:36,480
starting and

00:50:32,640 --> 00:50:38,480
ending right so that's why we put this

00:50:36,480 --> 00:50:40,079
boolean variable this start here into

00:50:38,480 --> 00:50:42,640
the group by class as well

00:50:40,079 --> 00:50:44,720
and then we define the tumble tumbler

00:50:42,640 --> 00:50:47,760
window of five minutes

00:50:44,720 --> 00:50:50,400
um and finally in the select clause we

00:50:47,760 --> 00:50:52,000
kind of repeat all of these things here

00:50:50,400 --> 00:50:53,359
putting the tumble n function here

00:50:52,000 --> 00:50:56,880
instead of tumble

00:50:53,359 --> 00:51:00,800
and during the count aggregation

00:50:56,880 --> 00:51:03,119
so if we paste this query here

00:51:00,800 --> 00:51:03,119
and

00:51:04,880 --> 00:51:10,160
write it then

00:51:11,119 --> 00:51:18,240
yeah there we go um

00:51:14,960 --> 00:51:20,240
so this is the area id this is uh

00:51:18,240 --> 00:51:21,359
for a starting right and this is for an

00:51:20,240 --> 00:51:25,119
ending right

00:51:21,359 --> 00:51:29,359
and here's the count

00:51:25,119 --> 00:51:33,920
and since we have the

00:51:29,359 --> 00:51:37,839
window of size of five minutes

00:51:33,920 --> 00:51:38,480
we now and we're basically feeding data

00:51:37,839 --> 00:51:42,319
at uh

00:51:38,480 --> 00:51:45,359
the speed of 10x um into the system

00:51:42,319 --> 00:51:48,839
we are um seeing

00:51:45,359 --> 00:51:51,839
new events wait a second

00:51:48,839 --> 00:51:56,319
uh five minutes are

00:51:51,839 --> 00:51:59,359
300 seconds so every every 30 seconds

00:51:56,319 --> 00:52:00,000
the system can complete a new window

00:51:59,359 --> 00:52:03,440
aggregation

00:52:00,000 --> 00:52:07,359
every 30 seconds therefore we see

00:52:03,440 --> 00:52:07,359
uh new data arriving here

00:52:07,680 --> 00:52:12,240
so and that's uh also kind of like an

00:52:10,319 --> 00:52:15,359
indication that uh

00:52:12,240 --> 00:52:17,680
uh that we are working with uh

00:52:15,359 --> 00:52:18,400
live data here so that data is fed into

00:52:17,680 --> 00:52:21,599
the

00:52:18,400 --> 00:52:22,960
kafka topic it is the query reads it out

00:52:21,599 --> 00:52:25,280
of the kaka topic

00:52:22,960 --> 00:52:26,240
but it waits until it has seen enough

00:52:25,280 --> 00:52:30,559
data

00:52:26,240 --> 00:52:35,839
to then finalize the computation and

00:52:30,559 --> 00:52:38,400
produce a result for the last

00:52:35,839 --> 00:52:39,040
five minutes in event time this is also

00:52:38,400 --> 00:52:42,000
a good

00:52:39,040 --> 00:52:43,359
um good indication that we are working

00:52:42,000 --> 00:52:46,640
with event time here

00:52:43,359 --> 00:52:51,520
if you would use processing time um

00:52:46,640 --> 00:52:54,319
and we would perform this uh or if we

00:52:51,520 --> 00:52:56,960
would run this query on a on a process

00:52:54,319 --> 00:52:59,920
time attribute if right time here was

00:52:56,960 --> 00:53:01,119
specified as a process time attribute

00:52:59,920 --> 00:53:04,000
then the system

00:53:01,119 --> 00:53:06,079
would actually always wait five minutes

00:53:04,000 --> 00:53:08,720
because the five minutes then

00:53:06,079 --> 00:53:11,599
based on the um based on the machine

00:53:08,720 --> 00:53:15,839
time of my computer

00:53:11,599 --> 00:53:17,440
so um but since we're using event type

00:53:15,839 --> 00:53:20,079
here there's also this possibility

00:53:17,440 --> 00:53:20,079
basically to

00:53:20,160 --> 00:53:26,319
speed up speed up uh processing

00:53:23,680 --> 00:53:28,640
um it has also the nice property for

00:53:26,319 --> 00:53:32,160
instance that if we uh

00:53:28,640 --> 00:53:33,040
would read data from uh i feel reading

00:53:32,160 --> 00:53:35,040
data

00:53:33,040 --> 00:53:37,119
uh from the cup from a kafka topic that

00:53:35,040 --> 00:53:40,480
has already some data in there

00:53:37,119 --> 00:53:40,480
all the data gets properly

00:53:40,640 --> 00:53:44,000
properly assigned to the right windows

00:53:42,240 --> 00:53:47,359
because we're working with the real data

00:53:44,000 --> 00:53:50,559
if this was like a um

00:53:47,359 --> 00:53:53,359
it was a processing time time stem

00:53:50,559 --> 00:53:54,160
we would uh basically add as much data

00:53:53,359 --> 00:53:56,640
as we can

00:53:54,160 --> 00:53:57,359
within five minutes i'm not all looking

00:53:56,640 --> 00:54:00,400
at any of

00:53:57,359 --> 00:54:00,400
any any time step

00:54:01,839 --> 00:54:06,240
um for the open window over over window

00:54:05,119 --> 00:54:09,280
application query

00:54:06,240 --> 00:54:12,480
here the task is to

00:54:09,280 --> 00:54:15,680
basically for every uh

00:54:12,480 --> 00:54:17,280
for every uh departing uh for every

00:54:15,680 --> 00:54:21,200
write start event

00:54:17,280 --> 00:54:25,839
we want to see um

00:54:21,200 --> 00:54:25,839
we want to compute um

00:54:27,680 --> 00:54:35,200
for for every the task is to

00:54:31,760 --> 00:54:37,280
to basically identify areas uh uh from

00:54:35,200 --> 00:54:39,680
which more than 10 people left by taxi

00:54:37,280 --> 00:54:44,400
in the last 10 minutes

00:54:39,680 --> 00:54:49,760
so for that we want to emit a new event

00:54:44,400 --> 00:54:49,760
for every in euro for every

00:54:49,920 --> 00:54:53,599
ride departing event where this

00:54:52,160 --> 00:54:56,559
condition basically is

00:54:53,599 --> 00:54:57,280
is fulfilled the query looks like this

00:54:56,559 --> 00:54:58,799
it is a

00:54:57,280 --> 00:55:01,040
nested theory in this case so let's

00:54:58,799 --> 00:55:04,400
first have a look at this

00:55:01,040 --> 00:55:04,400
at the at the inaccurate here

00:55:05,359 --> 00:55:12,960
we um it's actually

00:55:08,640 --> 00:55:12,960
three times necessity um

00:55:14,000 --> 00:55:18,559
so uh the first query here is a simple

00:55:16,559 --> 00:55:23,520
selection and projection so

00:55:18,559 --> 00:55:26,000
we read from rights and

00:55:23,520 --> 00:55:27,359
filter only on on the start events

00:55:26,000 --> 00:55:28,079
because we're only interested in start

00:55:27,359 --> 00:55:30,079
events

00:55:28,079 --> 00:55:32,839
and then we do this projection here

00:55:30,079 --> 00:55:35,359
computing the area id

00:55:32,839 --> 00:55:36,160
um and select the right time and the

00:55:35,359 --> 00:55:37,359
passenger

00:55:36,160 --> 00:55:39,119
because those are the fields that we

00:55:37,359 --> 00:55:40,240
need for the uh for the later

00:55:39,119 --> 00:55:42,960
computation

00:55:40,240 --> 00:55:44,240
so this is um after this one we only

00:55:42,960 --> 00:55:46,640
have the start events

00:55:44,240 --> 00:55:48,960
and did some precalculations here for

00:55:46,640 --> 00:55:52,799
the area id um

00:55:48,960 --> 00:55:56,400
then we define a window here again

00:55:52,799 --> 00:55:58,240
yes w we partition on the area id

00:55:56,400 --> 00:56:00,000
because

00:55:58,240 --> 00:56:02,000
um we basically want to perform these

00:56:00,000 --> 00:56:05,280
computations in the context of the

00:56:02,000 --> 00:56:08,799
area id order on the right time

00:56:05,280 --> 00:56:12,160
and then basically on a range of the

00:56:08,799 --> 00:56:15,440
of the current row and all rows

00:56:12,160 --> 00:56:18,880
in the range that were were being

00:56:15,440 --> 00:56:21,119
received 10 minutes before the current

00:56:18,880 --> 00:56:21,119
row

00:56:21,359 --> 00:56:25,359
um yeah and this range here exactly is

00:56:24,880 --> 00:56:29,119
based

00:56:25,359 --> 00:56:31,839
on based on this right time

00:56:29,119 --> 00:56:32,319
attribute here so what do we do with

00:56:31,839 --> 00:56:34,960
this

00:56:32,319 --> 00:56:35,920
window so we use it to in this sum

00:56:34,960 --> 00:56:38,400
computation

00:56:35,920 --> 00:56:39,920
we basically sum the passenger account

00:56:38,400 --> 00:56:43,359
over the last

00:56:39,920 --> 00:56:46,400
over this uh over this window and

00:56:43,359 --> 00:56:50,000
then we have the area id we have the

00:56:46,400 --> 00:56:53,520
right time of the uh

00:56:50,000 --> 00:56:55,440
this is the timestamp of the

00:56:53,520 --> 00:56:56,880
of the of the row that we're currently

00:56:55,440 --> 00:57:00,240
processing

00:56:56,880 --> 00:57:03,359
and then the sum of all the passengers

00:57:00,240 --> 00:57:05,839
that were within this area um

00:57:03,359 --> 00:57:07,680
uh 10 minutes before before this uh

00:57:05,839 --> 00:57:10,559
right start event

00:57:07,680 --> 00:57:12,319
so this is this query and then since we

00:57:10,559 --> 00:57:15,440
only interested in

00:57:12,319 --> 00:57:18,480
in areas where this people count this uh

00:57:15,440 --> 00:57:22,640
people leaving count was greater than 10

00:57:18,480 --> 00:57:26,240
we then put it here again from clause

00:57:22,640 --> 00:57:30,480
and assign a put filter on there

00:57:26,240 --> 00:57:32,240
and only interested in people on that

00:57:30,480 --> 00:57:33,680
into events where more than 10 people

00:57:32,240 --> 00:57:36,240
left

00:57:33,680 --> 00:57:36,240
so we can

00:57:37,359 --> 00:57:41,839
simply run this query here

00:57:50,240 --> 00:57:55,839
and this is basically then how it looks

00:57:58,480 --> 00:58:02,559
um you could we could also have

00:58:00,000 --> 00:58:02,960
basically we there's no need really to

00:58:02,559 --> 00:58:05,359
nest

00:58:02,960 --> 00:58:07,280
the queries this deep we cannot just

00:58:05,359 --> 00:58:08,799
could also define views and then use the

00:58:07,280 --> 00:58:12,799
views

00:58:08,799 --> 00:58:14,640
and to

00:58:12,799 --> 00:58:18,720
basically about this deep curiness and

00:58:14,640 --> 00:58:18,720
then as nesting of curious

00:58:20,559 --> 00:58:28,559
see now this question

00:58:23,680 --> 00:58:28,559
no not a question um

00:58:31,680 --> 00:58:38,160
okay um so

00:58:35,040 --> 00:58:40,960
um what do we

00:58:38,160 --> 00:58:42,000
want to do next so um i think we can

00:58:40,960 --> 00:58:45,040
just

00:58:42,000 --> 00:58:49,520
continue the uh with the next exercise

00:58:45,040 --> 00:58:55,040
and namely with the um sorry

00:58:49,520 --> 00:58:57,520
um namely with the

00:58:55,040 --> 00:58:58,960
other exercise to write data to external

00:58:57,520 --> 00:59:01,839
tables

00:58:58,960 --> 00:59:03,680
yesterday we did this part maintaining

00:59:01,839 --> 00:59:07,680
it continuously updated

00:59:03,680 --> 00:59:08,400
view in my sequel we can do a similar

00:59:07,680 --> 00:59:10,799
thing

00:59:08,400 --> 00:59:12,720
for writing an append only table to

00:59:10,799 --> 00:59:15,359
kafka

00:59:12,720 --> 00:59:15,920
it basically works pretty similar to

00:59:15,359 --> 00:59:17,680
what we

00:59:15,920 --> 00:59:21,599
what we did before again there's like

00:59:17,680 --> 00:59:25,359
the create table statement here

00:59:21,599 --> 00:59:29,920
with all the properties being being set

00:59:25,359 --> 00:59:29,920
and yeah then you can

00:59:30,960 --> 00:59:36,960
write a query that writes to this table

00:59:34,319 --> 00:59:38,160
and if you want to check whether it's

00:59:36,960 --> 00:59:40,640
working or not

00:59:38,160 --> 00:59:41,520
you can run this docker compose command

00:59:40,640 --> 00:59:43,680
that

00:59:41,520 --> 00:59:45,359
basically uses kafka's uh so-called

00:59:43,680 --> 00:59:48,480
console consumer

00:59:45,359 --> 00:59:50,960
which reads from this topic

00:59:48,480 --> 00:59:52,079
that the table that is basically the

00:59:50,960 --> 00:59:54,480
topic backing

00:59:52,079 --> 00:59:56,160
the table that we defined here then you

00:59:54,480 --> 00:59:57,680
can see

00:59:56,160 --> 01:00:00,319
if the query actually wrote something

00:59:57,680 --> 01:00:01,839
into this topic or not

01:00:00,319 --> 01:00:03,760
and of course you can again then also

01:00:01,839 --> 01:00:06,640
check the flink web ui

01:00:03,760 --> 01:00:08,400
to see how the query looks and cancel it

01:00:06,640 --> 01:00:12,160
from there

01:00:08,400 --> 01:00:14,079
so i would uh suggest that you're

01:00:12,160 --> 01:00:15,359
doing this exercise now maybe for the

01:00:14,079 --> 01:00:18,640
next

01:00:15,359 --> 01:00:20,480
um yeah

01:00:18,640 --> 01:00:22,559
seven minutes or five five to seven

01:00:20,480 --> 01:00:23,359
minutes so whenever you're done just let

01:00:22,559 --> 01:00:27,359
me know

01:00:23,359 --> 01:00:31,119
and after that we can

01:00:27,359 --> 01:00:34,960
talk a bit about joints in

01:00:31,119 --> 01:00:34,960
what kind of joints you can do with

01:00:40,839 --> 01:00:43,839
flink

01:00:54,559 --> 01:01:00,240
all right that's uh yes

01:00:57,920 --> 01:01:01,040
please uh this is going really fast when

01:01:00,240 --> 01:01:03,440
i look at the

01:01:01,040 --> 01:01:04,160
kafka consumer that's because it's

01:01:03,440 --> 01:01:07,680
starting

01:01:04,160 --> 01:01:09,599
from the start of the topic

01:01:07,680 --> 01:01:10,880
the table that we created this bed is

01:01:09,599 --> 01:01:13,920
basically

01:01:10,880 --> 01:01:18,559
creating a consumer that starts from

01:01:13,920 --> 01:01:18,559
the start of the topic yeah so um

01:01:18,799 --> 01:01:23,200
that the table of the straights table um

01:01:21,280 --> 01:01:25,280
we configure that basically you always

01:01:23,200 --> 01:01:28,480
read from the beginning of the topic

01:01:25,280 --> 01:01:30,720
so actually the longer you keep the

01:01:28,480 --> 01:01:32,160
demo environment open the more data is

01:01:30,720 --> 01:01:34,799
already in the topic

01:01:32,160 --> 01:01:35,440
so in the beginning it goes really fast

01:01:34,799 --> 01:01:38,799
and then

01:01:35,440 --> 01:01:41,920
when it comes to the to the end of the

01:01:38,799 --> 01:01:44,079
end of the stream or uh then it

01:01:41,920 --> 01:01:48,000
basically starts to slow down

01:01:44,079 --> 01:01:51,280
that's the startup mode

01:01:48,000 --> 01:01:54,400
um let me

01:01:51,280 --> 01:01:57,839
it says earliest offset yes exactly well

01:01:54,400 --> 01:02:00,010
this in this case it does not this is

01:01:57,839 --> 01:02:01,440
actually not really um

01:02:00,010 --> 01:02:04,319
[Music]

01:02:01,440 --> 01:02:05,680
it doesn't have an influence on the uh

01:02:04,319 --> 01:02:06,000
on the exercise that we are doing

01:02:05,680 --> 01:02:09,200
because

01:02:06,000 --> 01:02:12,720
we are writing to uh

01:02:09,200 --> 01:02:16,400
to this uh passenger counts right

01:02:12,720 --> 01:02:19,520
um so you see this this behavior because

01:02:16,400 --> 01:02:21,839
right exactly it's the right table is

01:02:19,520 --> 01:02:24,880
also defined with this uh

01:02:21,839 --> 01:02:27,839
with this startup mode so for the uh

01:02:24,880 --> 01:02:29,440
yeah when you know which read from this

01:02:27,839 --> 01:02:32,799
table again

01:02:29,440 --> 01:02:34,160
um yeah then it would basically always

01:02:32,799 --> 01:02:37,599
read from the from the beginning

01:02:34,160 --> 01:02:37,599
actually this is something that we could

01:02:38,400 --> 01:02:45,520
even try it should actually work

01:02:42,960 --> 01:02:46,839
so let's say we are creating this table

01:02:45,520 --> 01:02:50,400
now

01:02:46,839 --> 01:02:52,079
um i'm a little bit lazy

01:02:50,400 --> 01:02:54,960
so the cure here is fairly

01:02:52,079 --> 01:02:58,960
straightforward it's uh we're just uh

01:02:54,960 --> 01:02:59,520
um doing a tumbling group eye of 10

01:02:58,960 --> 01:03:02,079
minutes

01:02:59,520 --> 01:03:02,880
and then take the start of the tunnel

01:03:02,079 --> 01:03:04,280
and so the

01:03:02,880 --> 01:03:06,319
first time stamp and the

01:03:04,280 --> 01:03:08,240
[Music]

01:03:06,319 --> 01:03:10,319
the first time that is part of the data

01:03:08,240 --> 01:03:12,559
and the first times

01:03:10,319 --> 01:03:14,720
first time step that is part of the

01:03:12,559 --> 01:03:17,200
window the first time that is

01:03:14,720 --> 01:03:19,280
not part of the window anymore and then

01:03:17,200 --> 01:03:22,319
compute the count

01:03:19,280 --> 01:03:26,079
and say insert into this

01:03:22,319 --> 01:03:28,000
uh and if we run this now it's described

01:03:26,079 --> 01:03:32,720
to the

01:03:28,000 --> 01:03:32,720
fling cluster symbol of the dashboard

01:03:33,200 --> 01:03:37,839
we can see this because still running

01:03:35,920 --> 01:03:41,119
from yesterday

01:03:37,839 --> 01:03:43,280
so i get this query here

01:03:41,119 --> 01:03:43,280
and

01:03:49,839 --> 01:03:55,200
from 10 min passenger

01:03:56,839 --> 01:03:59,839
pounds

01:04:07,280 --> 01:04:13,839
34 let's

01:04:23,760 --> 01:04:29,359
oh yeah okay it's for every 10 minutes

01:04:27,200 --> 01:04:29,359
so

01:04:30,480 --> 01:04:35,599
and yeah since it's 10x for every 10

01:04:33,520 --> 01:04:38,000
minutes that

01:04:35,599 --> 01:04:39,359
for every minute that we see a new

01:04:38,000 --> 01:04:42,240
record every minute

01:04:39,359 --> 01:04:43,839
so if you said it's going really fast i

01:04:42,240 --> 01:04:44,160
you know i assume maybe you didn't stop

01:04:43,839 --> 01:04:48,720
the

01:04:44,160 --> 01:04:48,720
uh that my brandman since yesterday

01:04:51,280 --> 01:04:58,720
um yeah and now if you again we can even

01:04:54,720 --> 01:04:59,440
now query the uh query the table that is

01:04:58,720 --> 01:05:00,799
uh

01:04:59,440 --> 01:05:03,680
that we're writing to with the other

01:05:00,799 --> 01:05:03,680
query that we started

01:05:07,200 --> 01:05:10,640
okay um

01:05:12,720 --> 01:05:17,200
let's cancel this query um

01:05:17,280 --> 01:05:23,359
then i would suggest we now continue

01:05:19,280 --> 01:05:27,119
with the um

01:05:23,359 --> 01:05:37,839
with some slides on

01:05:27,119 --> 01:05:37,839
joining streaming data

01:05:41,280 --> 01:05:46,079
what time is it okay half an hour and

01:05:43,760 --> 01:05:48,079
yeah

01:05:46,079 --> 01:05:49,119
that might be enough or might not be

01:05:48,079 --> 01:05:52,240
enough um

01:05:49,119 --> 01:05:53,760
yeah but let's see um

01:05:52,240 --> 01:05:56,400
if you want to stay longer i'm also

01:05:53,760 --> 01:05:58,640
happy to uh to finish these uh

01:05:56,400 --> 01:06:00,000
these slides even if we go over time um

01:05:58,640 --> 01:06:03,200
yeah

01:06:00,000 --> 01:06:06,960
okay so um joining tables so

01:06:03,200 --> 01:06:08,799
um joining is always a bit of a

01:06:06,960 --> 01:06:10,640
interesting topic when it comes to

01:06:08,799 --> 01:06:13,760
streaming

01:06:10,640 --> 01:06:15,920
in like the uh regular sql world

01:06:13,760 --> 01:06:18,319
joints are very well understood there's

01:06:15,920 --> 01:06:21,359
different types of joints inner joins

01:06:18,319 --> 01:06:23,599
outer joins you have

01:06:21,359 --> 01:06:24,480
different types of predicates that you

01:06:23,599 --> 01:06:27,680
can use to

01:06:24,480 --> 01:06:30,400
associate rate rows with each other

01:06:27,680 --> 01:06:31,680
most usually it's equality predicates

01:06:30,400 --> 01:06:32,000
where you say some attribute and this

01:06:31,680 --> 01:06:34,000
table

01:06:32,000 --> 01:06:35,200
should be equal to the to a predicate in

01:06:34,000 --> 01:06:37,359
this table

01:06:35,200 --> 01:06:38,720
um database systems have different join

01:06:37,359 --> 01:06:42,240
algorithms that

01:06:38,720 --> 01:06:45,359
they use to speed up

01:06:42,240 --> 01:06:49,119
speed up joints in different situations

01:06:45,359 --> 01:06:51,680
and so on and um in

01:06:49,119 --> 01:06:52,720
traditional sql this all works very well

01:06:51,680 --> 01:06:55,839
because

01:06:52,720 --> 01:06:56,960
all data is basically available when

01:06:55,839 --> 01:06:58,960
when a journal is being processed when

01:06:56,960 --> 01:07:00,960
you started here with adjoin

01:06:58,960 --> 01:07:02,400
as i said yesterday conceptually the

01:07:00,960 --> 01:07:05,520
system takes a snapshot of

01:07:02,400 --> 01:07:09,839
all tables involved and then it

01:07:05,520 --> 01:07:13,039
can can be found outside um

01:07:09,839 --> 01:07:14,880
joining dynamic tables is uh or

01:07:13,039 --> 01:07:16,880
streams is often considered to be kind

01:07:14,880 --> 01:07:18,319
of like a challenge

01:07:16,880 --> 01:07:21,119
first of all because these tables are

01:07:18,319 --> 01:07:23,440
constantly changing

01:07:21,119 --> 01:07:23,440
um

01:07:24,480 --> 01:07:30,079
and if you want to basically join tables

01:07:28,400 --> 01:07:31,920
with a temporal condition

01:07:30,079 --> 01:07:33,119
then these tablets should be pet only

01:07:31,920 --> 01:07:37,280
tables

01:07:33,119 --> 01:07:38,799
and um when people talk about joining

01:07:37,280 --> 01:07:40,160
streaming data they often have very

01:07:38,799 --> 01:07:41,920
different have different scenarios in

01:07:40,160 --> 01:07:44,079
mind

01:07:41,920 --> 01:07:44,960
so usually when you talk about streaming

01:07:44,079 --> 01:07:47,200
joints

01:07:44,960 --> 01:07:48,559
uh all people are involved first kind of

01:07:47,200 --> 01:07:50,000
likely to get a

01:07:48,559 --> 01:07:52,079
common understanding of what they're

01:07:50,000 --> 01:07:56,559
what they're really talking about

01:07:52,079 --> 01:08:00,000
um in flink sql we support

01:07:56,559 --> 01:08:02,079
three different ways to to join dynamic

01:08:00,000 --> 01:08:03,680
tables so tables that are changing over

01:08:02,079 --> 01:08:05,440
time

01:08:03,680 --> 01:08:07,440
the first one is called time window

01:08:05,440 --> 01:08:09,039
joints

01:08:07,440 --> 01:08:11,520
the community of the flying community

01:08:09,039 --> 01:08:12,880
agreed to rename this to interval joints

01:08:11,520 --> 01:08:15,520
so if you look at the flink

01:08:12,880 --> 01:08:16,400
documentation uh in one of the next

01:08:15,520 --> 01:08:18,159
releases

01:08:16,400 --> 01:08:19,520
you will probably won't find taboo

01:08:18,159 --> 01:08:21,440
neutron anymore but it will be called

01:08:19,520 --> 01:08:24,400
interval join

01:08:21,440 --> 01:08:25,199
there's joints with so-called temporal

01:08:24,400 --> 01:08:27,440
tables

01:08:25,199 --> 01:08:29,600
and then something that we can like call

01:08:27,440 --> 01:08:32,319
regular joints

01:08:29,600 --> 01:08:32,799
and that's pretty much because the first

01:08:32,319 --> 01:08:34,560
two

01:08:32,799 --> 01:08:36,560
are working with uh special time

01:08:34,560 --> 01:08:39,759
properties and the other ones

01:08:36,560 --> 01:08:40,880
don't so that's basically the joints

01:08:39,759 --> 01:08:45,520
that you're

01:08:40,880 --> 01:08:45,520
kind of would would know from

01:08:45,920 --> 01:08:54,480
yeah using using sql and regular tables

01:08:51,199 --> 01:08:56,799
okay how do these joints behave um

01:08:54,480 --> 01:08:58,239
so the typewriter join uh the use case

01:08:56,799 --> 01:09:01,359
for for for this

01:08:58,239 --> 01:09:03,040
tablet join is that you can want to

01:09:01,359 --> 01:09:05,920
associate

01:09:03,040 --> 01:09:06,400
rows of two tables uh with each other

01:09:05,920 --> 01:09:10,000
based

01:09:06,400 --> 01:09:13,199
on uh uh

01:09:10,000 --> 01:09:16,719
temporal proximity so the rows

01:09:13,199 --> 01:09:20,400
should be the rows that join should be

01:09:16,719 --> 01:09:23,839
close to each other based on some uh

01:09:20,400 --> 01:09:25,600
time boundary so here we have uh two

01:09:23,839 --> 01:09:28,799
tables we have the adds

01:09:25,600 --> 01:09:32,159
at service table this is like the uh

01:09:28,799 --> 01:09:35,359
a table where we get one

01:09:32,159 --> 01:09:36,239
record uh whenever we serve a net to a

01:09:35,359 --> 01:09:39,920
user

01:09:36,239 --> 01:09:43,359
so s time is the serving time um

01:09:39,920 --> 01:09:46,319
for uh for a user and then we're serving

01:09:43,359 --> 01:09:48,799
on for for some on some url so you can

01:09:46,319 --> 01:09:51,600
think of this yeah

01:09:48,799 --> 01:09:52,719
as yeah we know the user we know uh the

01:09:51,600 --> 01:09:56,159
url that the user

01:09:52,719 --> 01:09:56,400
visited and we served some ad we served

01:09:56,159 --> 01:09:59,679
an

01:09:56,400 --> 01:10:02,480
ad for this uh for this link

01:09:59,679 --> 01:10:04,159
to the user mary at this point in time

01:10:02,480 --> 01:10:06,400
and

01:10:04,159 --> 01:10:07,199
here is a clicks table and this clicks

01:10:06,400 --> 01:10:09,440
table

01:10:07,199 --> 01:10:10,400
basically has all the clicks so whenever

01:10:09,440 --> 01:10:12,320
a user

01:10:10,400 --> 01:10:13,760
clicked on a link we also record the

01:10:12,320 --> 01:10:16,640
time and the user

01:10:13,760 --> 01:10:17,199
so and if you would like to know for

01:10:16,640 --> 01:10:21,840
instance

01:10:17,199 --> 01:10:24,159
of find all the urls that were clicked

01:10:21,840 --> 01:10:25,920
within five seconds after they were

01:10:24,159 --> 01:10:27,600
served as an ad to the user

01:10:25,920 --> 01:10:29,600
then this is something that could be

01:10:27,600 --> 01:10:32,880
defined you solved using this

01:10:29,600 --> 01:10:35,760
tablet.join so here if you look at it

01:10:32,880 --> 01:10:37,440
we have this uh this ad here we serve

01:10:35,760 --> 01:10:41,600
and add to user mary

01:10:37,440 --> 01:10:45,760
for this article uh with id3

01:10:41,600 --> 01:10:49,920
at 11 85 13

01:10:45,760 --> 01:10:49,920
and there is no click for this

01:10:53,360 --> 01:10:59,840
there is no click for this uh particular

01:10:56,800 --> 01:10:59,840
within five seconds

01:11:00,080 --> 01:11:03,280
you can see this this year was clicked

01:11:02,480 --> 01:11:06,320
uh about

01:11:03,280 --> 01:11:08,880
one minute or about two minutes later

01:11:06,320 --> 01:11:10,400
after it was uh served so it's kind of

01:11:08,880 --> 01:11:14,640
like falls out of this five

01:11:10,400 --> 01:11:17,679
five seconds window whereas the next

01:11:14,640 --> 01:11:22,960
next url that was for user bob

01:11:17,679 --> 01:11:24,719
at id1 was clicked here

01:11:22,960 --> 01:11:26,719
within two seconds after it was served

01:11:24,719 --> 01:11:28,800
to bob and that's why it's

01:11:26,719 --> 01:11:30,480
part of the results table so whenever

01:11:28,800 --> 01:11:33,040
you want to join

01:11:30,480 --> 01:11:34,320
events from two streams that are close

01:11:33,040 --> 01:11:37,679
to each other based on

01:11:34,320 --> 01:11:40,080
some temporary boundary then this

01:11:37,679 --> 01:11:42,560
time we're not joining the is what

01:11:40,080 --> 01:11:46,640
you're looking for

01:11:42,560 --> 01:11:49,840
so here um it's defined in a

01:11:46,640 --> 01:11:52,640
um i have a more more precise definition

01:11:49,840 --> 01:11:54,080
so time winner join joins records of two

01:11:52,640 --> 01:11:55,679
append only tables

01:11:54,080 --> 01:11:57,199
such that the time attributes of the

01:11:55,679 --> 01:11:58,800
joint records are not more than a

01:11:57,199 --> 01:12:02,560
specified

01:11:58,800 --> 01:12:02,560
window interval apart from each other

01:12:07,360 --> 01:12:11,520
so here this illustration basically says

01:12:09,760 --> 01:12:15,040
um

01:12:11,520 --> 01:12:16,239
here the uh this shape here basically

01:12:15,040 --> 01:12:19,840
indicates

01:12:16,239 --> 01:12:21,280
the uh the time range that this record

01:12:19,840 --> 01:12:24,960
is looking for

01:12:21,280 --> 01:12:26,960
so you can you can create the range in

01:12:24,960 --> 01:12:29,280
both directions you can say

01:12:26,960 --> 01:12:31,280
um this record basically wants to join

01:12:29,280 --> 01:12:36,159
with everything that is

01:12:31,280 --> 01:12:39,280
one hour arrived um

01:12:36,159 --> 01:12:39,280
one hour earlier

01:12:39,440 --> 01:12:43,120
from from an interval from one hour

01:12:41,360 --> 01:12:46,159
earlier to 15 minutes

01:12:43,120 --> 01:12:50,080
later and defined

01:12:46,159 --> 01:12:52,320
this join the other record

01:12:50,080 --> 01:12:53,600
range is exactly the other way around so

01:12:52,320 --> 01:12:55,199
this record here

01:12:53,600 --> 01:12:56,640
would join with everything that arrived

01:12:55,199 --> 01:12:59,679
15 minutes earlier

01:12:56,640 --> 01:13:00,080
up to one hour later and for instance

01:12:59,679 --> 01:13:02,960
here

01:13:00,080 --> 01:13:04,239
you can see that these two records here

01:13:02,960 --> 01:13:07,280
basically

01:13:04,239 --> 01:13:10,880
meet each other because this one arrived

01:13:07,280 --> 01:13:11,920
less than one hour earlier then this one

01:13:10,880 --> 01:13:13,679
here and

01:13:11,920 --> 01:13:17,120
those two records here would then match

01:13:13,679 --> 01:13:19,840
and produce a drawing result

01:13:17,120 --> 01:13:20,880
where is this one here doesn't see

01:13:19,840 --> 01:13:23,440
anything

01:13:20,880 --> 01:13:24,800
uh in its uh range and hence it's not

01:13:23,440 --> 01:13:28,320
shot

01:13:24,800 --> 01:13:32,640
um the syntax for this um is also just

01:13:28,320 --> 01:13:35,760
standard sql syntax however again

01:13:32,640 --> 01:13:37,520
the you can't like need to specify write

01:13:35,760 --> 01:13:41,600
the join in a certain way

01:13:37,520 --> 01:13:45,040
uh whether or give a appropriate

01:13:41,600 --> 01:13:46,560
join condition such that flink will

01:13:45,040 --> 01:13:50,000
understand this

01:13:46,560 --> 01:13:51,199
um this uh these these intervals and

01:13:50,000 --> 01:13:54,320
ranges

01:13:51,199 --> 01:13:57,760
so um if you specify a query like this

01:13:54,320 --> 01:14:01,199
um a and b should be tablets that are

01:13:57,760 --> 01:14:03,679
um append only so they only receive new

01:14:01,199 --> 01:14:03,679
records

01:14:04,480 --> 01:14:10,080
we'll never update any records then

01:14:07,679 --> 01:14:11,280
there needs to be some kind of equality

01:14:10,080 --> 01:14:15,360
predicate

01:14:11,280 --> 01:14:17,280
so here we join some some id

01:14:15,360 --> 01:14:18,719
and then there is a predicate that

01:14:17,280 --> 01:14:22,320
defines a

01:14:18,719 --> 01:14:25,440
closed window around

01:14:22,320 --> 01:14:26,880
the time attributes of a and b so the

01:14:25,440 --> 01:14:30,000
easiest way to specify this

01:14:26,880 --> 01:14:33,199
is if you have unlike e t and

01:14:30,000 --> 01:14:34,560
a t and a and b t are the time

01:14:33,199 --> 01:14:37,679
attributes of a and

01:14:34,560 --> 01:14:38,880
b so you can specify the the time

01:14:37,679 --> 01:14:42,159
attribute of a

01:14:38,880 --> 01:14:45,840
should be between the time attribute

01:14:42,159 --> 01:14:49,199
of t minus some time

01:14:45,840 --> 01:14:53,120
and b uh

01:14:49,199 --> 01:14:56,480
and bt plus some interval and this way

01:14:53,120 --> 01:14:59,760
um you um

01:14:56,480 --> 01:15:03,120
form a closed closed range

01:14:59,760 --> 01:15:05,760
between these two closed range

01:15:03,120 --> 01:15:07,840
because you're specifying a lower bound

01:15:05,760 --> 01:15:11,040
and upper bound

01:15:07,840 --> 01:15:14,560
that a has to has to match against

01:15:11,040 --> 01:15:16,640
you could also specify a t equals bt

01:15:14,560 --> 01:15:19,280
but then the timestamps need to be

01:15:16,640 --> 01:15:23,040
exactly the same

01:15:19,280 --> 01:15:25,040
and if you don't say that a t equals bt

01:15:23,040 --> 01:15:27,280
then you have to specify like an upper a

01:15:25,040 --> 01:15:29,280
lower bound and an upper bound and

01:15:27,280 --> 01:15:30,320
you can either do this with a between

01:15:29,280 --> 01:15:33,760
predicate or with

01:15:30,320 --> 01:15:38,159
a two uh two two range

01:15:33,760 --> 01:15:41,760
predicates where eighty uh

01:15:38,159 --> 01:15:44,800
larger bt minus this and 80

01:15:41,760 --> 01:15:45,760
smaller than bt this but the important

01:15:44,800 --> 01:15:48,400
thing is that like

01:15:45,760 --> 01:15:49,600
as i said the range that you're defining

01:15:48,400 --> 01:15:53,199
needs to be

01:15:49,600 --> 01:15:57,760
needs to be closed

01:15:53,199 --> 01:16:01,040
so if we want to solve the

01:15:57,760 --> 01:16:02,719
task that we had here before then

01:16:01,040 --> 01:16:04,480
the query would look like this we would

01:16:02,719 --> 01:16:07,600
have the

01:16:04,480 --> 01:16:10,159
clicks tab and the service table

01:16:07,600 --> 01:16:12,640
we would join on the url because we're

01:16:10,159 --> 01:16:12,640
interested

01:16:13,040 --> 01:16:16,960
on the ul and the user here because

01:16:16,080 --> 01:16:19,760
we're interested

01:16:16,960 --> 01:16:21,520
all only on events where the url matches

01:16:19,760 --> 01:16:23,520
and the user matches

01:16:21,520 --> 01:16:24,719
and then we would specify that the click

01:16:23,520 --> 01:16:27,840
time

01:16:24,719 --> 01:16:30,480
should be between the serving time

01:16:27,840 --> 01:16:31,760
and the serving time plus an interval of

01:16:30,480 --> 01:16:34,800
five seconds

01:16:31,760 --> 01:16:36,960
so here we don't subtract it but it's

01:16:34,800 --> 01:16:38,400
the lower bound here is basically the

01:16:36,960 --> 01:16:41,760
serving time it's

01:16:38,400 --> 01:16:44,480
not really possible that the user clicks

01:16:41,760 --> 01:16:46,560
before the ad was served but from the

01:16:44,480 --> 01:16:49,840
time when that's over served

01:16:46,560 --> 01:16:52,480
to five seconds after that um

01:16:49,840 --> 01:16:55,520
we want to basically join if a click

01:16:52,480 --> 01:16:55,520
happened within this time

01:16:58,159 --> 01:17:03,040
oh okay there's a little bit more so

01:17:01,440 --> 01:17:05,040
in terms of execution if you're curious

01:17:03,040 --> 01:17:07,760
like how this executes

01:17:05,040 --> 01:17:08,239
um what the operator that performs this

01:17:07,760 --> 01:17:11,920
join

01:17:08,239 --> 01:17:14,960
in turn does it basically keeps

01:17:11,920 --> 01:17:15,440
the the the tail of both streams in

01:17:14,960 --> 01:17:17,520
state

01:17:15,440 --> 01:17:18,880
and but only the this uh this part of

01:17:17,520 --> 01:17:23,040
the of the of the table

01:17:18,880 --> 01:17:25,840
that is needed to answer the join

01:17:23,040 --> 01:17:26,480
and once the time progresses such that

01:17:25,840 --> 01:17:29,840
the

01:17:26,480 --> 01:17:32,719
rows uh fall out of the

01:17:29,840 --> 01:17:33,280
the john range they removed from state

01:17:32,719 --> 01:17:37,760
and

01:17:33,280 --> 01:17:39,760
uh therefore um

01:17:37,760 --> 01:17:41,040
the the large basically the larger the

01:17:39,760 --> 01:17:44,800
time it ever gets

01:17:41,040 --> 01:17:46,719
that you're specifying the more uh state

01:17:44,800 --> 01:17:48,000
uh is set up by the by the query

01:17:46,719 --> 01:17:50,719
operator

01:17:48,000 --> 01:17:51,440
um something that can always happen in

01:17:50,719 --> 01:17:54,159
uh

01:17:51,440 --> 01:17:54,560
in in event time processing is that if

01:17:54,159 --> 01:17:58,239
both

01:17:54,560 --> 01:18:01,520
tables have kind like a different

01:17:58,239 --> 01:18:03,600
different timing um on there's

01:18:01,520 --> 01:18:05,440
some some skew between the data of both

01:18:03,600 --> 01:18:09,440
tables in that case

01:18:05,440 --> 01:18:11,600
um kind of the join

01:18:09,440 --> 01:18:13,520
operates at the speed of the slowest

01:18:11,600 --> 01:18:15,760
table

01:18:13,520 --> 01:18:17,280
and this means that more data for the

01:18:15,760 --> 01:18:20,080
for the other table for the faster table

01:18:17,280 --> 01:18:20,080
needs to be buffered

01:18:21,760 --> 01:18:29,280
um yeah joints with temporal tables

01:18:26,080 --> 01:18:31,840
so the use case here is um

01:18:29,280 --> 01:18:31,840
that we

01:18:32,960 --> 01:18:37,120
kind like have again two tabs we have a

01:18:35,440 --> 01:18:40,320
clicks table here that we had before and

01:18:37,120 --> 01:18:44,960
then some kind of user history table

01:18:40,320 --> 01:18:48,239
where we basically

01:18:44,960 --> 01:18:50,880
this is a table that stores

01:18:48,239 --> 01:18:51,760
different versions or basically stores

01:18:50,880 --> 01:18:56,480
the history of

01:18:51,760 --> 01:18:59,280
a of a user and whenever a user changes

01:18:56,480 --> 01:19:01,360
um the subscription then a new record is

01:18:59,280 --> 01:19:02,080
added to this uh user's table history

01:19:01,360 --> 01:19:04,480
tab

01:19:02,080 --> 01:19:05,679
uh this history table is therefore like

01:19:04,480 --> 01:19:08,560
append only

01:19:05,679 --> 01:19:09,440
so we don't it's not modeled that there

01:19:08,560 --> 01:19:12,320
is

01:19:09,440 --> 01:19:13,920
that the user id is a unique is a

01:19:12,320 --> 01:19:14,560
primary key and we simply update the

01:19:13,920 --> 01:19:16,960
field

01:19:14,560 --> 01:19:18,080
but instead uh it's modeled in a way

01:19:16,960 --> 01:19:20,560
that we keep

01:19:18,080 --> 01:19:22,400
uh all different versions that whenever

01:19:20,560 --> 01:19:23,040
something changes we just append a new

01:19:22,400 --> 01:19:26,719
record

01:19:23,040 --> 01:19:30,400
with a with a new version time

01:19:26,719 --> 01:19:33,600
so um and if now we have a

01:19:30,400 --> 01:19:34,960
have this clicks table here and the user

01:19:33,600 --> 01:19:37,920
history table here

01:19:34,960 --> 01:19:38,800
what we basically want to do is um we

01:19:37,920 --> 01:19:42,480
want to join

01:19:38,800 --> 01:19:44,560
each uh click here

01:19:42,480 --> 01:19:45,760
with the current subscription status of

01:19:44,560 --> 01:19:48,080
the user

01:19:45,760 --> 01:19:50,159
so if we get this record here for mary

01:19:48,080 --> 01:19:52,400
uh at 12 o'clock

01:19:50,159 --> 01:19:53,199
uh we basically want to conceptually do

01:19:52,400 --> 01:19:56,080
a lookup in the

01:19:53,199 --> 01:19:56,719
in the users table here and join it with

01:19:56,080 --> 01:19:59,840
the

01:19:56,719 --> 01:20:02,960
latest value for mary at this time

01:19:59,840 --> 01:20:07,600
so latest value here for mary is

01:20:02,960 --> 01:20:11,120
um is the version at 10 o'clock

01:20:07,600 --> 01:20:13,920
and therefore we join the subscription

01:20:11,120 --> 01:20:16,719
for this record at a later point in time

01:20:13,920 --> 01:20:16,719
at 15 o'clock

01:20:16,840 --> 01:20:21,679
um there's another click

01:20:19,040 --> 01:20:22,159
of the zameri uh this time we have to

01:20:21,679 --> 01:20:25,360
look

01:20:22,159 --> 01:20:28,480
uh up the current version for uh for

01:20:25,360 --> 01:20:31,600
uh three o'clock

01:20:28,480 --> 01:20:34,960
and in the meantime mary had

01:20:31,600 --> 01:20:38,480
changed her subscription status

01:20:34,960 --> 01:20:42,080
um to paid and hence we need to join the

01:20:38,480 --> 01:20:45,760
paid stadium so there is a

01:20:42,080 --> 01:20:48,800
something that is important here that

01:20:45,760 --> 01:20:49,280
one usually doesn't really uh cease on

01:20:48,800 --> 01:20:51,600
the first

01:20:49,280 --> 01:20:52,400
side and this is this temporal

01:20:51,600 --> 01:20:55,840
relationship

01:20:52,400 --> 01:21:00,480
between the click time here

01:20:55,840 --> 01:21:02,800
between the time stem and the uh

01:21:00,480 --> 01:21:03,840
and the inversion time the important

01:21:02,800 --> 01:21:06,719
thing is if

01:21:03,840 --> 01:21:08,960
we would model this query basically as a

01:21:06,719 --> 01:21:12,880
simple join without a temporal con

01:21:08,960 --> 01:21:15,600
temporal condition but have instead a

01:21:12,880 --> 01:21:18,000
table here where we would where the user

01:21:15,600 --> 01:21:19,840
would be

01:21:18,000 --> 01:21:21,920
like a primary key and we would simply

01:21:19,840 --> 01:21:23,920
update the field here

01:21:21,920 --> 01:21:25,280
as soon as we would do an update here

01:21:23,920 --> 01:21:28,000
and we specify the

01:21:25,280 --> 01:21:29,520
query we want to evaluate it with

01:21:28,000 --> 01:21:32,480
regular sql semantics

01:21:29,520 --> 01:21:34,480
as soon as we would change the

01:21:32,480 --> 01:21:37,920
subscription of a user

01:21:34,480 --> 01:21:39,920
we would need to update all

01:21:37,920 --> 01:21:42,159
result rows that we ever processed for

01:21:39,920 --> 01:21:45,120
this user as well

01:21:42,159 --> 01:21:46,400
because if this is treated as a as a

01:21:45,120 --> 01:21:49,679
table that is

01:21:46,400 --> 01:21:51,520
um that that can change its records

01:21:49,679 --> 01:21:53,600
at any point in time we also need to be

01:21:51,520 --> 01:21:57,280
able to update the result

01:21:53,600 --> 01:22:00,480
and this also means

01:21:57,280 --> 01:22:02,080
that we would need to store the four

01:22:00,480 --> 01:22:03,520
clicks table to be able to update the

01:22:02,080 --> 01:22:06,719
result

01:22:03,520 --> 01:22:07,440
so um if you want to avoid that we kind

01:22:06,719 --> 01:22:10,719
of

01:22:07,440 --> 01:22:12,800
somehow need to encode this

01:22:10,719 --> 01:22:15,199
this temporary relationship into the

01:22:12,800 --> 01:22:20,480
join that we always want to join

01:22:15,199 --> 01:22:20,480
this record with the most recent version

01:22:22,560 --> 01:22:29,120
that was available before this uh

01:22:26,080 --> 01:22:32,560
this time stamp so

01:22:29,120 --> 01:22:35,520
um here the definition

01:22:32,560 --> 01:22:38,080
is a temporary table gives access to the

01:22:35,520 --> 01:22:39,679
history of a dynamic table

01:22:38,080 --> 01:22:41,520
by joining with the temporary table

01:22:39,679 --> 01:22:43,280
records of an append

01:22:41,520 --> 01:22:45,120
only table can be joined with the

01:22:43,280 --> 01:22:47,840
version of the dynamic table

01:22:45,120 --> 01:22:49,840
that corresponds to that timestamp so if

01:22:47,840 --> 01:22:50,639
we have this if this is the append early

01:22:49,840 --> 01:22:52,400
table here

01:22:50,639 --> 01:22:53,760
this is the clicks table in our previous

01:22:52,400 --> 01:22:57,040
example and this is the

01:22:53,760 --> 01:22:58,639
user history table then if we have a

01:22:57,040 --> 01:22:59,520
record at this point in time it would

01:22:58,639 --> 01:23:01,600
join

01:22:59,520 --> 01:23:03,360
with the record at this time if we have

01:23:01,600 --> 01:23:04,960
a record here it would join with a

01:23:03,360 --> 01:23:06,719
not with this because there's a new

01:23:04,960 --> 01:23:08,480
version here simply

01:23:06,719 --> 01:23:10,320
this and also join with this this will

01:23:08,480 --> 01:23:13,199
also join with this

01:23:10,320 --> 01:23:14,480
here then we get an update but there is

01:23:13,199 --> 01:23:17,199
no record on this

01:23:14,480 --> 01:23:18,639
uh on the pen only table the next record

01:23:17,199 --> 01:23:21,280
here on the pen on the table and then

01:23:18,639 --> 01:23:23,280
gets again the latest version so we

01:23:21,280 --> 01:23:25,520
always

01:23:23,280 --> 01:23:28,000
associating each record on the pen only

01:23:25,520 --> 01:23:31,679
table with the most

01:23:28,000 --> 01:23:31,679
recent version in the temporary table

01:23:32,840 --> 01:23:39,360
um this

01:23:36,000 --> 01:23:43,360
kinda needs uh means we have um

01:23:39,360 --> 01:23:46,719
the the the temporary tablets defined um

01:23:43,360 --> 01:23:50,880
kind of as a as a parameterized or as a

01:23:46,719 --> 01:23:54,320
parameterized view on this history table

01:23:50,880 --> 01:23:54,320
that basically means that we can

01:23:54,719 --> 01:23:57,920
query the history table for certain

01:23:57,040 --> 01:24:03,520
points in time

01:23:57,920 --> 01:24:06,800
so if we have this history table here

01:24:03,520 --> 01:24:08,880
and it also needs to have a unique heavy

01:24:06,800 --> 01:24:11,920
unique e field

01:24:08,880 --> 01:24:14,639
um if we have this history table here

01:24:11,920 --> 01:24:15,280
and we want to get the most recent

01:24:14,639 --> 01:24:18,320
version

01:24:15,280 --> 01:24:21,360
at uh 12 uh

01:24:18,320 --> 01:24:23,360
1203 then

01:24:21,360 --> 01:24:25,360
the values that would correspond to the

01:24:23,360 --> 01:24:28,800
most recent version here

01:24:25,360 --> 01:24:32,080
are these so we would get the b value

01:24:28,800 --> 01:24:35,679
it's from 12 o'clock the a value is from

01:24:32,080 --> 01:24:38,960
12 1201 and the c value would

01:24:35,679 --> 01:24:42,080
from 1203 if you would later go ahead

01:24:38,960 --> 01:24:45,120
and ask the same question that

01:24:42,080 --> 01:24:46,159
for for the time 1206 we get different

01:24:45,120 --> 01:24:48,400
values

01:24:46,159 --> 01:24:49,920
so we get a well okay for c it's the

01:24:48,400 --> 01:24:51,040
same value because nothing was changed

01:24:49,920 --> 01:24:54,000
in the meantime

01:24:51,040 --> 01:24:55,760
but uh a was changed b was changed and

01:24:54,000 --> 01:25:00,080
there is even a new record for

01:24:55,760 --> 01:25:00,080
uh for for d at this time

01:25:01,760 --> 01:25:07,760
um in flink sql we model these template

01:25:04,960 --> 01:25:09,600
tables as a

01:25:07,760 --> 01:25:12,080
table valued function that catalog needs

01:25:09,600 --> 01:25:16,480
to be defined on the

01:25:12,080 --> 01:25:19,840
on the history table um

01:25:16,480 --> 01:25:19,840
so and this uh

01:25:19,920 --> 01:25:23,120
and this is basically what we also did

01:25:21,440 --> 01:25:25,040
in the in the exercise with this

01:25:23,120 --> 01:25:26,719
driver driver changes here with the

01:25:25,040 --> 01:25:30,080
driver changes table

01:25:26,719 --> 01:25:32,719
uh is the history table and um on this

01:25:30,080 --> 01:25:35,360
we define this

01:25:32,719 --> 01:25:36,800
builder function that can be used to

01:25:35,360 --> 01:25:39,120
access different fields

01:25:36,800 --> 01:25:40,560
i think that's probably all a little bit

01:25:39,120 --> 01:25:44,159
abstract but

01:25:40,560 --> 01:25:47,360
let's have a look at how this how this

01:25:44,159 --> 01:25:48,960
looks looks in in sql so we have this

01:25:47,360 --> 01:25:52,400
table a which is this

01:25:48,960 --> 01:25:55,360
append only table and then

01:25:52,400 --> 01:25:56,239
we join this this is the standard sql

01:25:55,360 --> 01:25:59,600
syntax

01:25:56,239 --> 01:26:00,719
for using it our table table valued

01:25:59,600 --> 01:26:03,440
function

01:26:00,719 --> 01:26:04,239
so it's a lateral table and we pass in

01:26:03,440 --> 01:26:06,560
the

01:26:04,239 --> 01:26:08,000
time attribute of a as a parameter and

01:26:06,560 --> 01:26:10,719
this basically means

01:26:08,000 --> 01:26:11,760
that we want to get the value of this

01:26:10,719 --> 01:26:15,280
function here

01:26:11,760 --> 01:26:19,040
at time um

01:26:15,280 --> 01:26:21,280
at the time for of of the current record

01:26:19,040 --> 01:26:23,040
so for every record you can you can

01:26:21,280 --> 01:26:26,960
think of it as

01:26:23,040 --> 01:26:30,320
as follows um for every record of a

01:26:26,960 --> 01:26:31,840
we basically do a lookup in the in this

01:26:30,320 --> 01:26:32,560
in this table function in the temporary

01:26:31,840 --> 01:26:35,360
table

01:26:32,560 --> 01:26:37,040
and we for for the lookup we need the

01:26:35,360 --> 01:26:39,440
time step because we want to get the

01:26:37,040 --> 01:26:40,560
most recent version with respect to this

01:26:39,440 --> 01:26:44,719
time step

01:26:40,560 --> 01:26:47,760
and then we do an equality predicate

01:26:44,719 --> 01:26:53,280
we do an uh equality join

01:26:47,760 --> 01:26:53,280
a predicate here on the

01:26:54,480 --> 01:27:00,000
on the unique key of b so it's basically

01:26:57,840 --> 01:27:03,520
modeled as a simple lookup

01:27:00,000 --> 01:27:04,960
against the temporal table based on the

01:27:03,520 --> 01:27:08,239
time

01:27:04,960 --> 01:27:09,920
so for the uh exercise that we did for

01:27:08,239 --> 01:27:12,080
the exam that we did before

01:27:09,920 --> 01:27:13,520
you would have this clicks table c we

01:27:12,080 --> 01:27:16,000
would have a

01:27:13,520 --> 01:27:17,600
uh a joint with the lateral table here

01:27:16,000 --> 01:27:20,719
with this function users

01:27:17,600 --> 01:27:22,560
users is a function that is defined on

01:27:20,719 --> 01:27:26,080
the user history

01:27:22,560 --> 01:27:28,239
we provide the click time

01:27:26,080 --> 01:27:29,360
and the the click time of the of each

01:27:28,239 --> 01:27:32,480
click record

01:27:29,360 --> 01:27:35,920
and then we join on

01:27:32,480 --> 01:27:41,120
the user of the click with the

01:27:35,920 --> 01:27:41,120
id of these user subscriptions tab

01:27:44,840 --> 01:27:50,239
um

01:27:46,560 --> 01:27:50,239
for the execution this is um

01:27:53,440 --> 01:27:58,639
what basically happens is internally is

01:27:55,679 --> 01:27:58,639
that the

01:27:59,040 --> 01:28:05,920
um for this temporal table for this

01:28:03,120 --> 01:28:08,320
users table where we kind of need to be

01:28:05,920 --> 01:28:12,080
able to look up different versions

01:28:08,320 --> 01:28:13,920
um we

01:28:12,080 --> 01:28:15,600
need to keep a few records in state

01:28:13,920 --> 01:28:18,719
namely uh

01:28:15,600 --> 01:28:20,480
for each for each unique value of the

01:28:18,719 --> 01:28:21,040
letter table we keep the most recent

01:28:20,480 --> 01:28:25,040
version

01:28:21,040 --> 01:28:27,920
in in in state and

01:28:25,040 --> 01:28:28,480
for the clicks table we don't need to we

01:28:27,920 --> 01:28:32,000
don't

01:28:28,480 --> 01:28:33,520
store any any uh any of these records in

01:28:32,000 --> 01:28:35,420
instead we don't need to materialize

01:28:33,520 --> 01:28:36,719
them because

01:28:35,420 --> 01:28:39,280
[Music]

01:28:36,719 --> 01:28:39,280
the uh

01:28:40,159 --> 01:28:43,600
we know that we can for every of these

01:28:42,400 --> 01:28:45,760
uh for every

01:28:43,600 --> 01:28:47,199
row from the clicks table we can simply

01:28:45,760 --> 01:28:49,600
do the lookup

01:28:47,199 --> 01:28:51,199
and since we have this this uh this

01:28:49,600 --> 01:28:53,199
temporal condition

01:28:51,199 --> 01:28:54,239
um that we always want to get the most

01:28:53,199 --> 01:28:57,840
recent version

01:28:54,239 --> 01:29:00,960
we can simply do the lookup join the uh

01:28:57,840 --> 01:29:04,000
result together and emit the result so

01:29:00,960 --> 01:29:05,280
we don't need to hold any of our any

01:29:04,000 --> 01:29:07,520
record of c

01:29:05,280 --> 01:29:08,960
instead but only the most recent version

01:29:07,520 --> 01:29:12,800
of the

01:29:08,960 --> 01:29:12,800
of the office of this temporary table

01:29:19,440 --> 01:29:25,840
and that's maybe

01:29:28,159 --> 01:29:31,440
now this is always a bit uh

01:29:31,760 --> 01:29:37,920
tricky to explain i hope it uh

01:29:34,960 --> 01:29:40,239
made sense uh to some extent we have

01:29:37,920 --> 01:29:44,239
some exercises also for that in the uh

01:29:40,239 --> 01:29:47,280
in the um um

01:29:44,239 --> 01:29:48,960
in the in the week in the repository so

01:29:47,280 --> 01:29:51,600
you can

01:29:48,960 --> 01:29:52,000
use that and to to play around with this

01:29:51,600 --> 01:29:57,360
concept

01:29:52,000 --> 01:29:57,360
of temporal joining of temporary tables

01:29:57,840 --> 01:30:03,679
okay now let me briefly go over the

01:30:01,440 --> 01:30:04,800
like regular join which is actually the

01:30:03,679 --> 01:30:08,639
join that you

01:30:04,800 --> 01:30:13,600
kind of know from i should know from sql

01:30:08,639 --> 01:30:13,600
already um here we are

01:30:15,120 --> 01:30:18,840
have again two tables there we want to

01:30:16,639 --> 01:30:20,159
join one is this clicks tab with click

01:30:18,840 --> 01:30:24,000
events

01:30:20,159 --> 01:30:26,080
and the other one is sit down i see it's

01:30:24,000 --> 01:30:28,320
a little bit messed up here

01:30:26,080 --> 01:30:28,320
um

01:30:29,840 --> 01:30:34,000
oh no it looks better so one is the

01:30:32,320 --> 01:30:35,679
clicks header and the other one is a

01:30:34,000 --> 01:30:39,520
users table

01:30:35,679 --> 01:30:41,520
so here we modeled more of this exactly

01:30:39,520 --> 01:30:45,199
as i said before with the table that is

01:30:41,520 --> 01:30:48,320
just updated there is no

01:30:45,199 --> 01:30:50,480
we don't track any version so uh

01:30:48,320 --> 01:30:51,520
let's say we have um the clicks this is

01:30:50,480 --> 01:30:53,760
the click stability

01:30:51,520 --> 01:30:54,719
at 12 o'clock and this is the user's

01:30:53,760 --> 01:30:57,280
table at 12 o'clock

01:30:54,719 --> 01:30:58,480
if we join them together with a just

01:30:57,280 --> 01:31:01,679
regular join

01:30:58,480 --> 01:31:05,040
then we would have mary we would

01:31:01,679 --> 01:31:05,679
count the number of clicks um and we

01:31:05,040 --> 01:31:09,760
join it with

01:31:05,679 --> 01:31:12,960
uh the current subscription same for bob

01:31:09,760 --> 01:31:16,800
and uh everything's fine at 12 o'clock

01:31:12,960 --> 01:31:19,040
if now the user's table changes

01:31:16,800 --> 01:31:21,199
at one o'clock we need to update the

01:31:19,040 --> 01:31:24,400
result that we computed before so

01:31:21,199 --> 01:31:26,719
at sorry at uh

01:31:24,400 --> 01:31:28,320
one o'clock murray changes her

01:31:26,719 --> 01:31:30,639
subscription to paid

01:31:28,320 --> 01:31:31,520
so this means we now kind of need to

01:31:30,639 --> 01:31:33,199
update

01:31:31,520 --> 01:31:35,040
the result that we produced before

01:31:33,199 --> 01:31:38,719
because it's not valid anymore

01:31:35,040 --> 01:31:41,840
so uh the subscription here

01:31:38,719 --> 01:31:44,800
changes from free to paid

01:31:41,840 --> 01:31:46,239
and if now the clicks table changes at

01:31:44,800 --> 01:31:48,480
01:31:46,239 --> 01:31:50,080
uh at two o'clock and we get another

01:31:48,480 --> 01:31:53,360
record for mary

01:31:50,080 --> 01:31:55,440
then we need to again

01:31:53,360 --> 01:31:57,600
update this result because we also want

01:31:55,440 --> 01:32:00,960
to like count the

01:31:57,600 --> 01:32:04,239
number of clicks and now the the current

01:32:00,960 --> 01:32:08,719
uh increases from uh to

01:32:04,239 --> 01:32:10,239
from one to two so you see

01:32:08,719 --> 01:32:12,880
at any point in time when something

01:32:10,239 --> 01:32:16,480
changes in either of the of both tables

01:32:12,880 --> 01:32:19,679
we need to update the result and

01:32:16,480 --> 01:32:21,600
in order to be able to do that we need

01:32:19,679 --> 01:32:25,360
to keep

01:32:21,600 --> 01:32:27,760
both tables completely

01:32:25,360 --> 01:32:29,199
in state because uh anything can happen

01:32:27,760 --> 01:32:30,159
at any point in time we always need to

01:32:29,199 --> 01:32:31,840
be able to

01:32:30,159 --> 01:32:34,000
update the result there is no temporary

01:32:31,840 --> 01:32:36,320
boundary uh

01:32:34,000 --> 01:32:37,760
for for the computation that would say

01:32:36,320 --> 01:32:38,800
at this point in time you can be sure

01:32:37,760 --> 01:32:41,040
that

01:32:38,800 --> 01:32:42,560
the result will never change this is not

01:32:41,040 --> 01:32:45,679
there so

01:32:42,560 --> 01:32:48,960
um we need to keep

01:32:45,679 --> 01:32:51,520
all data from both tables

01:32:48,960 --> 01:32:51,520
in state

01:32:52,239 --> 01:32:59,760
the syntax for this looks uh just as

01:32:56,000 --> 01:33:04,320
any join in in sql right

01:32:59,760 --> 01:33:04,320
you have tables a and b

01:33:04,639 --> 01:33:08,560
and you just give the join condition in

01:33:07,199 --> 01:33:11,360
the in the where clause

01:33:08,560 --> 01:33:13,040
uh you can also specify them with the

01:33:11,360 --> 01:33:16,719
with the

01:33:13,040 --> 01:33:20,159
join clause so a joins b on

01:33:16,719 --> 01:33:22,719
uh a uh i a id equals b

01:33:20,159 --> 01:33:24,000
id so both of both join sentences are

01:33:22,719 --> 01:33:27,199
supported

01:33:24,000 --> 01:33:29,280
um yeah but since

01:33:27,199 --> 01:33:32,480
a and b are both completely held into

01:33:29,280 --> 01:33:36,320
memory um

01:33:32,480 --> 01:33:40,639
it's kind of like um advisable

01:33:36,320 --> 01:33:43,280
um that both input tables are

01:33:40,639 --> 01:33:44,239
not append only and growing very fast

01:33:43,280 --> 01:33:46,639
because

01:33:44,239 --> 01:33:47,840
you just need to buffer all of the data

01:33:46,639 --> 01:33:51,280
unless you specify

01:33:47,840 --> 01:33:55,360
this idle state retention and then

01:33:51,280 --> 01:33:55,360
you might get inconsistent results

01:33:55,920 --> 01:34:01,679
so the use case for

01:33:58,960 --> 01:34:02,560
the query that would implement this here

01:34:01,679 --> 01:34:06,159
would

01:34:02,560 --> 01:34:08,080
be this we have

01:34:06,159 --> 01:34:09,440
the clicks table we group on the user

01:34:08,080 --> 01:34:11,760
account per user

01:34:09,440 --> 01:34:12,560
and then join this result with the users

01:34:11,760 --> 01:34:15,920
table

01:34:12,560 --> 01:34:20,159
on the id user field

01:34:15,920 --> 01:34:22,400
and this way we can uh

01:34:20,159 --> 01:34:23,679
the the system translates this into a

01:34:22,400 --> 01:34:26,480
query where

01:34:23,679 --> 01:34:28,719
we first basically do the aggregation

01:34:26,480 --> 01:34:32,159
here on the clicks table so we have

01:34:28,719 --> 01:34:35,120
for every you we have a for every user

01:34:32,159 --> 01:34:37,040
we keep the current uh count of clicks

01:34:35,120 --> 01:34:38,560
and for every user we also have

01:34:37,040 --> 01:34:40,880
we also have the users table on the

01:34:38,560 --> 01:34:42,800
other side both are

01:34:40,880 --> 01:34:44,400
kind of like updating tables that are

01:34:42,800 --> 01:34:47,760
updated per user

01:34:44,400 --> 01:34:49,760
and hence not growing very large uh when

01:34:47,760 --> 01:34:53,040
a new click is added

01:34:49,760 --> 01:34:53,600
um it doesn't add a new row unless it's

01:34:53,040 --> 01:34:55,760
a

01:34:53,600 --> 01:34:57,360
new user but if it's a user that was

01:34:55,760 --> 01:35:00,159
already there you just have to update

01:34:57,360 --> 01:35:03,119
the count but not add a new row to this

01:35:00,159 --> 01:35:04,480
table and both of these tables the

01:35:03,119 --> 01:35:08,000
result of this query

01:35:04,480 --> 01:35:12,159
and the users table are held

01:35:08,000 --> 01:35:12,159
completely in the state of the join

01:35:12,840 --> 01:35:15,840
operator

01:35:18,960 --> 01:35:22,960
um yeah so i think i've already said

01:35:21,840 --> 01:35:24,560
this before as well

01:35:22,960 --> 01:35:26,560
so regular joints can forward time

01:35:24,560 --> 01:35:31,280
attributes um

01:35:26,560 --> 01:35:31,280
because they um

01:35:31,440 --> 01:35:35,040
any record can join with any other

01:35:33,119 --> 01:35:38,159
record at any point in time so the

01:35:35,040 --> 01:35:41,600
order of outputs is uh of

01:35:38,159 --> 01:35:43,810
the emitted rows is

01:35:41,600 --> 01:35:45,199
pretty much random so they

01:35:43,810 --> 01:35:47,840
[Music]

01:35:45,199 --> 01:35:52,000
cannot that the watermark alignment

01:35:47,840 --> 01:35:52,000
basically is then lost

01:35:54,960 --> 01:36:02,159
all right so we have some exercises for

01:35:58,080 --> 01:36:02,159
for joining these dynamic tables um

01:36:02,880 --> 01:36:10,719
i think the tutorial time is

01:36:06,960 --> 01:36:12,320
over if you want to um

01:36:10,719 --> 01:36:13,840
spend some time looking into these

01:36:12,320 --> 01:36:16,880
exercises uh

01:36:13,840 --> 01:36:18,639
uh feel free to do so i'm

01:36:16,880 --> 01:36:20,639
happy to hang around for a couple more

01:36:18,639 --> 01:36:24,880
minutes if there's any questions

01:36:20,639 --> 01:36:27,840
um if not um

01:36:24,880 --> 01:36:28,960
all of the exercises are here in the

01:36:27,840 --> 01:36:32,320
wiki you can just

01:36:28,960 --> 01:36:36,159
uh play around that there is another

01:36:32,320 --> 01:36:38,320
uh topic about these uh match recognize

01:36:36,159 --> 01:36:40,159
clauses uh all of the slides that are

01:36:38,320 --> 01:36:42,000
shown are always linked in the

01:36:40,159 --> 01:36:44,320
in each of the pages here so if you

01:36:42,000 --> 01:36:46,320
click for instance here on the

01:36:44,320 --> 01:36:48,159
pattern matching with let's recognize

01:36:46,320 --> 01:36:52,000
click on this link here

01:36:48,159 --> 01:36:56,080
there's the uh pdf for this slide

01:36:52,000 --> 01:36:59,840
set you can just study it yourself

01:36:56,080 --> 01:36:59,840
and also do the exercises um

01:37:01,920 --> 01:37:10,400
okay so i'd say uh

01:37:06,159 --> 01:37:13,520
this is it um i hope um

01:37:10,400 --> 01:37:15,520
you had fun learned something um

01:37:13,520 --> 01:37:17,600
yeah if you want to want to do the

01:37:15,520 --> 01:37:20,400
drawing exercises feel free to

01:37:17,600 --> 01:37:21,440
as i said uh have a look at that if not

01:37:20,400 --> 01:37:23,119
uh

01:37:21,440 --> 01:37:25,520
enjoy the rest of the conference and the

01:37:23,119 --> 01:37:27,600
other talks um

01:37:25,520 --> 01:37:28,719
and yeah if there's any any issues any

01:37:27,600 --> 01:37:32,000
questions

01:37:28,719 --> 01:37:34,080
the flink user making this is very very

01:37:32,000 --> 01:37:35,920
friendly and

01:37:34,080 --> 01:37:38,719
answers a lot of questions are we also

01:37:35,920 --> 01:37:41,440
quite active on stack overflow

01:37:38,719 --> 01:37:43,520
or yeah feel free to open an issue on

01:37:41,440 --> 01:37:45,920
the

01:37:43,520 --> 01:37:47,679
training repository yeah whatever works

01:37:45,920 --> 01:38:03,840
best for you

01:37:47,679 --> 01:38:03,840
thank you

01:38:08,719 --> 01:38:10,800

YouTube URL: https://www.youtube.com/watch?v=gV4gNax7yuw


