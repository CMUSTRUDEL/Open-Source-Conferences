Title: #bbuzz: Stephan Ewen – From Stream Processor to Event-driven Database with Stateful Functions
Publication date: 2020-07-02
Playlist: Berlin Buzzwords | MICES | Haystack – Joint Virtual Event 2020
Description: 
	More: https://berlinbuzzwords.de/session/stream-processor-event-driven-database-stateful-functions

Orchestration frameworks like Kubernetes have made dealing with stateless applications very easy. But for stateful applications, we are still clinging to the ancient wisdom that state shall be someone else's problem: just put it in a database! Because of that, we are still struggling with the same issues of data consistency and complex failure semantics as decades ago. Developing stateful applications in a scalable and resilient way is still hard, especially when they span multiple (mirco)services.

Stream Processors, like Apache Flink, have solved similar problems in the area of event-processing. By rethinking the relationship between state, messaging, and computation, stream processing applications are out-of-the-box scalable and consistent.
 
Is it possible to bring some of these ideas to the space of general-purpose applications and (micro) services?

The Apache Flink project has recently added a new subproject called "Stateful Functions" (https://statefun.io/) that tries to achieve exactly that. In Stateful Functions, the Flink effectively becomes an event-driven database that works together with containerized event-driven functions to form a new building block for scalable and consistent applications. In this talk, we present the Stateful Functions project. We show how its small change in responsibilities between database and applications goes surprisingly far in solving the problem of consistency and failure semantics for applications, and additionally makes it blend in very with current serverless technologies, like AWS Lambda, knative, etc.
Captions: 
	00:01:38,840 --> 00:01:44,640
foreign hey everyone welcome back

00:01:41,439 --> 00:01:46,960
um up next we have stefan ewen and he's

00:01:44,640 --> 00:01:48,960
going to talk about uh stream processing

00:01:46,960 --> 00:01:50,320
and event driven databases with stateful

00:01:48,960 --> 00:01:53,119
functions

00:01:50,320 --> 00:01:54,399
again bring your questions to the studio

00:01:53,119 --> 00:01:56,240
channel on slack

00:01:54,399 --> 00:01:58,719
and we'll ask them at the very end of

00:01:56,240 --> 00:02:01,280
the session stefan

00:01:58,719 --> 00:02:01,280
thanks josh

00:02:02,159 --> 00:02:08,720
hello everyone this is uh i'm stephen

00:02:06,399 --> 00:02:10,000
i'm very happy to be here again at

00:02:08,720 --> 00:02:13,280
berlin buzzwords in the

00:02:10,000 --> 00:02:15,840
like in the virtual edition um this year

00:02:13,280 --> 00:02:17,520
um yeah i'll be talking about um about

00:02:15,840 --> 00:02:19,360
stateful functions and about

00:02:17,520 --> 00:02:21,680
yeah it's work we're doing in the um

00:02:19,360 --> 00:02:24,160
apache fling project it's a it's

00:02:21,680 --> 00:02:26,000
a way how we think about the evolution

00:02:24,160 --> 00:02:29,040
of um stream processing

00:02:26,000 --> 00:02:32,000
towards to it's something that you know

00:02:29,040 --> 00:02:32,959
we we started calling um an event-driven

00:02:32,000 --> 00:02:35,760
database and

00:02:32,959 --> 00:02:37,440
yeah i'm excited to be here today tell

00:02:35,760 --> 00:02:40,239
the story

00:02:37,440 --> 00:02:41,120
so before before jumping in just uh one

00:02:40,239 --> 00:02:43,360
slide with uh

00:02:41,120 --> 00:02:44,400
maybe background about um myself and the

00:02:43,360 --> 00:02:47,680
company i work for

00:02:44,400 --> 00:02:50,480
um we're um with america where the

00:02:47,680 --> 00:02:51,440
um company formerly known as data

00:02:50,480 --> 00:02:53,920
artisans

00:02:51,440 --> 00:02:54,640
um we're founded by the by the original

00:02:53,920 --> 00:02:56,959
creators of

00:02:54,640 --> 00:02:58,080
um of apache flink and that's what we're

00:02:56,959 --> 00:03:00,080
doing still

00:02:58,080 --> 00:03:01,680
day-to-day most of the time developing

00:03:00,080 --> 00:03:04,319
um open source stream processing

00:03:01,680 --> 00:03:06,000
technology in the apache flink project

00:03:04,319 --> 00:03:08,000
um we're also offering an enterprise

00:03:06,000 --> 00:03:11,440
stream processing platform

00:03:08,000 --> 00:03:12,080
and um yeah the company started as data

00:03:11,440 --> 00:03:14,720
artisans

00:03:12,080 --> 00:03:16,239
it's now called verica that's because a

00:03:14,720 --> 00:03:17,440
little more than half a year ago it was

00:03:16,239 --> 00:03:19,120
actually abide

00:03:17,440 --> 00:03:21,120
acquired by the alibaba group so it's

00:03:19,120 --> 00:03:22,480
part of the alibaba group ecosystem

00:03:21,120 --> 00:03:27,599
right now and

00:03:22,480 --> 00:03:27,599
um yeah we rebranded as as part of that

00:03:27,840 --> 00:03:31,360
okay jumping into the um jumping into

00:03:30,159 --> 00:03:35,599
the

00:03:31,360 --> 00:03:37,760
the main the main talk here um

00:03:35,599 --> 00:03:38,879
the the original title is is a bit of a

00:03:37,760 --> 00:03:40,720
mouthful like uh

00:03:38,879 --> 00:03:42,239
stream processors and event driven

00:03:40,720 --> 00:03:43,680
databases or from stream processor to

00:03:42,239 --> 00:03:44,879
event driven database with stateful

00:03:43,680 --> 00:03:47,120
functions um i thought

00:03:44,879 --> 00:03:48,239
maybe another title like i could have

00:03:47,120 --> 00:03:50,000
picked that was

00:03:48,239 --> 00:03:51,360
a bit a bit shorter but might also

00:03:50,000 --> 00:03:52,400
describe pretty well what we're trying

00:03:51,360 --> 00:03:56,640
to do here is

00:03:52,400 --> 00:03:58,560
um the quest for stateful serverless

00:03:56,640 --> 00:04:01,200
so stateful serverless what is that

00:03:58,560 --> 00:04:02,239
supposed to be so serverless is is this

00:04:01,200 --> 00:04:04,319
big trend happening

00:04:02,239 --> 00:04:05,680
and and computing these days right i

00:04:04,319 --> 00:04:07,360
mean some people associate it with

00:04:05,680 --> 00:04:08,720
things like amazon lambda but it's

00:04:07,360 --> 00:04:10,720
really this much broader

00:04:08,720 --> 00:04:11,840
trend to yeah to not be thinking about

00:04:10,720 --> 00:04:13,680
physical

00:04:11,840 --> 00:04:14,959
um instances of hardware and software

00:04:13,680 --> 00:04:17,519
and so on and

00:04:14,959 --> 00:04:18,880
um serverless has made a pretty good

00:04:17,519 --> 00:04:22,079
headway when it comes to

00:04:18,880 --> 00:04:23,120
um to to be able to handle um stateless

00:04:22,079 --> 00:04:24,800
applications but

00:04:23,120 --> 00:04:26,240
handling stateful applications in a

00:04:24,800 --> 00:04:29,600
serverless way is still

00:04:26,240 --> 00:04:31,759
so somewhat of a s still a challenge and

00:04:29,600 --> 00:04:33,440
um yeah part of what we've been doing in

00:04:31,759 --> 00:04:35,040
the stateful functions project is trying

00:04:33,440 --> 00:04:37,440
to look an answer for how to how to

00:04:35,040 --> 00:04:39,759
simplify this

00:04:37,440 --> 00:04:40,880
and um i think i'm going to open this

00:04:39,759 --> 00:04:45,680
talk with a bit of a

00:04:40,880 --> 00:04:48,000
of a daring thesis so um

00:04:45,680 --> 00:04:49,120
the like the hypothesis of this stable

00:04:48,000 --> 00:04:51,919
function project is

00:04:49,120 --> 00:04:53,040
that stream processors are going to be

00:04:51,919 --> 00:04:55,600
in the future

00:04:53,040 --> 00:04:56,400
to event-driven serverless application

00:04:55,600 --> 00:04:59,280
what the

00:04:56,400 --> 00:05:01,120
the database is the sql databases or the

00:04:59,280 --> 00:05:04,479
key value stores are to the crud

00:05:01,120 --> 00:05:07,199
application um today and

00:05:04,479 --> 00:05:08,240
um yeah i hope i can back up this thesis

00:05:07,199 --> 00:05:09,919
and

00:05:08,240 --> 00:05:11,840
get to get uh get the audience very

00:05:09,919 --> 00:05:13,360
excited about um

00:05:11,840 --> 00:05:15,280
what that means and why why this is

00:05:13,360 --> 00:05:16,160
actually really interesting um avenue to

00:05:15,280 --> 00:05:18,400
pursue

00:05:16,160 --> 00:05:21,120
and and the way we're building we're

00:05:18,400 --> 00:05:22,639
building applications

00:05:21,120 --> 00:05:24,639
so let's actually dive in let's let's

00:05:22,639 --> 00:05:27,039
dive in into building

00:05:24,639 --> 00:05:29,039
stateful applications in the serverless

00:05:27,039 --> 00:05:30,000
era so how do we how do we start with

00:05:29,039 --> 00:05:33,120
that

00:05:30,000 --> 00:05:34,720
um let's actually start with just

00:05:33,120 --> 00:05:36,400
building applications in this

00:05:34,720 --> 00:05:39,840
and the serverless era and actually

00:05:36,400 --> 00:05:42,720
ignore stateful just for a second

00:05:39,840 --> 00:05:43,520
so the um the the core building block

00:05:42,720 --> 00:05:46,080
that

00:05:43,520 --> 00:05:47,840
um that that that comes up again and

00:05:46,080 --> 00:05:50,240
again in pretty much

00:05:47,840 --> 00:05:52,400
um all modern infrastructure is this

00:05:50,240 --> 00:05:53,600
this unit of often of an event-driven

00:05:52,400 --> 00:05:54,960
function and that

00:05:53,600 --> 00:05:57,360
that can be you know it can be a

00:05:54,960 --> 00:05:59,039
function that is deployed as an

00:05:57,360 --> 00:06:01,039
event-driven function and k-native it

00:05:59,039 --> 00:06:01,919
can be in can be the interface with

00:06:01,039 --> 00:06:05,120
which you program

00:06:01,919 --> 00:06:08,240
aws lambda or any of the other

00:06:05,120 --> 00:06:10,000
serverless function compute yeah

00:06:08,240 --> 00:06:12,240
platforms on on any of the other cloud

00:06:10,000 --> 00:06:14,479
providers but it's also

00:06:12,240 --> 00:06:15,600
it's also a very a very common pattern

00:06:14,479 --> 00:06:18,240
outside of out

00:06:15,600 --> 00:06:20,000
outside of those ecosystems this event

00:06:18,240 --> 00:06:21,919
driven function is the core of of

00:06:20,000 --> 00:06:24,639
my stream processing technology be that

00:06:21,919 --> 00:06:27,520
in flink and kafka

00:06:24,639 --> 00:06:28,160
it's also what um what is in some sense

00:06:27,520 --> 00:06:31,520
the unit of

00:06:28,160 --> 00:06:33,600
um of actor programming and actor is

00:06:31,520 --> 00:06:34,800
is also in some in some sense in event

00:06:33,600 --> 00:06:36,479
driven functions so

00:06:34,800 --> 00:06:38,639
taking this as a starting point seems

00:06:36,479 --> 00:06:41,759
like a pretty good idea

00:06:38,639 --> 00:06:44,080
um when when starting to work on

00:06:41,759 --> 00:06:45,280
on on something like you know stateful

00:06:44,080 --> 00:06:48,479
stateful serverless

00:06:45,280 --> 00:06:49,680
um event-driven applications

00:06:48,479 --> 00:06:50,880
and there's there's some really nice

00:06:49,680 --> 00:06:51,919
properties like in it's in its

00:06:50,880 --> 00:06:54,240
simplicity it

00:06:51,919 --> 00:06:54,960
it gives us the ability to be really

00:06:54,240 --> 00:06:58,160
highly

00:06:54,960 --> 00:06:59,919
elastic um scale out um scale in scale

00:06:58,160 --> 00:07:02,160
to zero really fast

00:06:59,919 --> 00:07:04,240
and and this characteristic is also what

00:07:02,160 --> 00:07:05,520
i think defined a lot of the success of

00:07:04,240 --> 00:07:08,400
um

00:07:05,520 --> 00:07:08,400
of this abstraction

00:07:08,960 --> 00:07:15,919
so this is i think so far

00:07:13,120 --> 00:07:17,280
this has been um in in the industry a

00:07:15,919 --> 00:07:19,840
pretty big success story

00:07:17,280 --> 00:07:21,039
when it comes to building stateless

00:07:19,840 --> 00:07:22,639
applications

00:07:21,039 --> 00:07:24,160
however if we're trying to to build

00:07:22,639 --> 00:07:24,800
state full applications i think we're

00:07:24,160 --> 00:07:27,039
losing

00:07:24,800 --> 00:07:28,160
a lot of the of the niceness that um

00:07:27,039 --> 00:07:31,680
that we

00:07:28,160 --> 00:07:34,000
that we have in in this technology so

00:07:31,680 --> 00:07:35,599
building stateful applications means now

00:07:34,000 --> 00:07:38,960
we're pulling in something like

00:07:35,599 --> 00:07:41,919
a database and that's easily where

00:07:38,960 --> 00:07:43,520
where things start to um i want to say

00:07:41,919 --> 00:07:44,000
fall apart but with the let's say the

00:07:43,520 --> 00:07:45,919
smoothness

00:07:44,000 --> 00:07:47,120
of our serverless application

00:07:45,919 --> 00:07:50,080
development

00:07:47,120 --> 00:07:51,759
um yeah stops and where things become

00:07:50,080 --> 00:07:53,840
become rough edgy

00:07:51,759 --> 00:07:55,199
so all of a sudden you know we have to

00:07:53,840 --> 00:07:57,599
really worry about

00:07:55,199 --> 00:07:59,440
how do we actually talk to the database

00:07:57,599 --> 00:08:00,400
like what what kind of protocol do we

00:07:59,440 --> 00:08:03,120
employ to

00:08:00,400 --> 00:08:03,440
to guarantee state consistency um and

00:08:03,120 --> 00:08:05,440
it's

00:08:03,440 --> 00:08:07,280
it's not it doesn't just stop with um

00:08:05,440 --> 00:08:09,039
saying sure i'm gonna use the database

00:08:07,280 --> 00:08:10,560
that supports transactions and so on we

00:08:09,039 --> 00:08:13,120
still have to worry about

00:08:10,560 --> 00:08:15,280
um about the different different

00:08:13,120 --> 00:08:17,280
instances

00:08:15,280 --> 00:08:19,199
looking at stale information or trying

00:08:17,280 --> 00:08:20,960
to aggregate different

00:08:19,199 --> 00:08:23,120
different data from different snapshots

00:08:20,960 --> 00:08:26,240
and so on

00:08:23,120 --> 00:08:28,639
we see very often that while the well

00:08:26,240 --> 00:08:32,159
the stateless part

00:08:28,639 --> 00:08:33,919
is is infinitely scalable infinitely

00:08:32,159 --> 00:08:36,719
i mean as much as your club rider is

00:08:33,919 --> 00:08:36,719
willing to provide

00:08:37,279 --> 00:08:40,560
very often the bottleneck isn't isn't

00:08:39,599 --> 00:08:42,560
actually in the

00:08:40,560 --> 00:08:44,159
in the stateless part itself in the

00:08:42,560 --> 00:08:44,959
lambda functions the bottleneck starts

00:08:44,159 --> 00:08:48,080
to become the

00:08:44,959 --> 00:08:50,240
the um access to data in the database

00:08:48,080 --> 00:08:51,440
so you're you're making a request takes

00:08:50,240 --> 00:08:53,519
a while to um

00:08:51,440 --> 00:08:54,880
to process and respond and while you're

00:08:53,519 --> 00:08:56,320
you're scaling out the

00:08:54,880 --> 00:08:58,000
the functions to be able to handle more

00:08:56,320 --> 00:08:59,279
of these requests at the same time it

00:08:58,000 --> 00:09:00,560
doesn't really help the application

00:08:59,279 --> 00:09:02,080
because the bottleneck isn't

00:09:00,560 --> 00:09:03,600
isn't the function itself it's actually

00:09:02,080 --> 00:09:05,920
the database

00:09:03,600 --> 00:09:06,880
it can actually make things even worse

00:09:05,920 --> 00:09:08,640
so if

00:09:06,880 --> 00:09:10,399
um if you're actually scaling the

00:09:08,640 --> 00:09:12,000
stateless part too much because you see

00:09:10,399 --> 00:09:13,839
that a lot of the functions are starting

00:09:12,000 --> 00:09:15,279
to take a long time to execute just

00:09:13,839 --> 00:09:16,640
because they're waiting for the database

00:09:15,279 --> 00:09:17,839
to process the requests

00:09:16,640 --> 00:09:19,040
you're starting you're scaling this out

00:09:17,839 --> 00:09:20,800
more and more you're hammering the

00:09:19,040 --> 00:09:22,720
database with even more requests and all

00:09:20,800 --> 00:09:26,240
of a sudden you start to see like

00:09:22,720 --> 00:09:27,440
um request limiting or you see you see

00:09:26,240 --> 00:09:30,240
failures due to denied

00:09:27,440 --> 00:09:31,839
connections and so on and um well well

00:09:30,240 --> 00:09:34,399
all of this is

00:09:31,839 --> 00:09:35,920
is in some sense solvable with the right

00:09:34,399 --> 00:09:36,880
tricks and techniques it's it's just

00:09:35,920 --> 00:09:38,320
something where

00:09:36,880 --> 00:09:40,240
the whole serverless experience is

00:09:38,320 --> 00:09:41,680
starting to to fall apart it's

00:09:40,240 --> 00:09:43,279
something where you know state is just

00:09:41,680 --> 00:09:44,720
inherently not serverless in this

00:09:43,279 --> 00:09:46,320
in this situation that's something you

00:09:44,720 --> 00:09:47,760
have to explicitly worry about you have

00:09:46,320 --> 00:09:49,279
to manage you have to

00:09:47,760 --> 00:09:51,519
think about there being a physical

00:09:49,279 --> 00:09:53,760
database with limited

00:09:51,519 --> 00:09:56,160
amount of connections with supported

00:09:53,760 --> 00:09:59,360
request rates and so on

00:09:56,160 --> 00:10:02,800
so this is really part of the problem

00:09:59,360 --> 00:10:02,800
we're looking to solve here

00:10:02,880 --> 00:10:08,800
another another part where um

00:10:06,800 --> 00:10:10,079
that's that's partly related to the

00:10:08,800 --> 00:10:11,839
stateful serverless

00:10:10,079 --> 00:10:14,160
space but in general also a big

00:10:11,839 --> 00:10:17,040
limitation of the of the ecosystem of

00:10:14,160 --> 00:10:18,959
um yeah of serverless applications is

00:10:17,040 --> 00:10:20,160
how do we actually compose more complex

00:10:18,959 --> 00:10:21,839
applications so

00:10:20,160 --> 00:10:23,360
how do we go from the point of having

00:10:21,839 --> 00:10:25,680
individual functions that

00:10:23,360 --> 00:10:27,920
do one task to having you know more

00:10:25,680 --> 00:10:29,440
complex applications that

00:10:27,920 --> 00:10:31,519
in the general in the general case

00:10:29,440 --> 00:10:32,240
message each other or rpc each other to

00:10:31,519 --> 00:10:35,120
you know to

00:10:32,240 --> 00:10:36,160
aggregate different information um to

00:10:35,120 --> 00:10:38,399
compose a final

00:10:36,160 --> 00:10:40,240
response to the original request and

00:10:38,399 --> 00:10:41,760
there are solutions like workflows of

00:10:40,240 --> 00:10:44,079
serverless functions but

00:10:41,760 --> 00:10:44,880
all of these are like very special case

00:10:44,079 --> 00:10:46,320
don't really

00:10:44,880 --> 00:10:49,200
don't really form much of a general

00:10:46,320 --> 00:10:49,200
solution yet

00:10:49,360 --> 00:10:53,200
so so much for for the for the problem

00:10:51,279 --> 00:10:54,959
space um

00:10:53,200 --> 00:10:56,320
what i'd like to introduce now is the is

00:10:54,959 --> 00:10:57,920
the work we've been doing in the in the

00:10:56,320 --> 00:11:00,320
state for functions project and

00:10:57,920 --> 00:11:01,839
um like try to explain how we're how

00:11:00,320 --> 00:11:02,240
we're looking to address some of these

00:11:01,839 --> 00:11:03,519
um

00:11:02,240 --> 00:11:05,279
some of these issues that we see in

00:11:03,519 --> 00:11:07,279
applications there and um

00:11:05,279 --> 00:11:08,880
once i've you know once i've motivated

00:11:07,279 --> 00:11:09,760
this there's a there's a demo to it's

00:11:08,880 --> 00:11:12,959
the end

00:11:09,760 --> 00:11:14,560
um showing how you can can do a simple

00:11:12,959 --> 00:11:15,920
stateful serverless machine learning

00:11:14,560 --> 00:11:20,079
classifier system

00:11:15,920 --> 00:11:22,079
based on that so the the core of

00:11:20,079 --> 00:11:24,320
of the of the stateful functions project

00:11:22,079 --> 00:11:25,680
is i guess you

00:11:24,320 --> 00:11:27,680
you will have guessed it from the name

00:11:25,680 --> 00:11:28,000
is the idea of building applications

00:11:27,680 --> 00:11:30,000
actually

00:11:28,000 --> 00:11:31,519
not with stateless functions but with

00:11:30,000 --> 00:11:34,720
stateful functions

00:11:31,519 --> 00:11:35,200
so um like this this picture is somehow

00:11:34,720 --> 00:11:38,560
the

00:11:35,200 --> 00:11:40,480
like the the bird's eye view of um of a

00:11:38,560 --> 00:11:43,200
stateful function application

00:11:40,480 --> 00:11:44,480
um in the core it consists of a lot of

00:11:43,200 --> 00:11:48,000
functions that

00:11:44,480 --> 00:11:50,240
that treats data as as um yes

00:11:48,000 --> 00:11:51,040
almost as local variables like a

00:11:50,240 --> 00:11:53,760
property you would

00:11:51,040 --> 00:11:56,079
you'd find in you know having having

00:11:53,760 --> 00:11:58,560
just persistent local local variables in

00:11:56,079 --> 00:12:00,079
a regular java program not not something

00:11:58,560 --> 00:12:01,680
that is you know a proxy towards a

00:12:00,079 --> 00:12:04,160
database and so on but really just

00:12:01,680 --> 00:12:05,120
constant time access to um to local

00:12:04,160 --> 00:12:07,200
state

00:12:05,120 --> 00:12:08,480
um that that gets rid of a lot of the of

00:12:07,200 --> 00:12:13,360
the problems of actually

00:12:08,480 --> 00:12:13,360
uh dealing with state um

00:12:13,440 --> 00:12:17,279
there are multiple instances of these of

00:12:15,920 --> 00:12:18,880
these functions you can think of them

00:12:17,279 --> 00:12:19,839
like in the same way as you have in an

00:12:18,880 --> 00:12:21,600
actor programming you would have

00:12:19,839 --> 00:12:22,160
multiple instances of these of these

00:12:21,600 --> 00:12:24,560
actors

00:12:22,160 --> 00:12:26,560
and they they basically invoke each

00:12:24,560 --> 00:12:28,880
other they send each other messages

00:12:26,560 --> 00:12:29,760
um take the responses and and process

00:12:28,880 --> 00:12:32,480
them

00:12:29,760 --> 00:12:33,120
and the um the second part that is

00:12:32,480 --> 00:12:35,760
really

00:12:33,120 --> 00:12:37,760
um a big deal that we um that we paid

00:12:35,760 --> 00:12:39,120
attention to here is trying to

00:12:37,760 --> 00:12:40,800
trying to get a lot of the common

00:12:39,120 --> 00:12:41,760
problems of this interaction out of the

00:12:40,800 --> 00:12:43,760
way so

00:12:41,760 --> 00:12:45,680
assuming that if you have one function

00:12:43,760 --> 00:12:47,200
that that message is another and is

00:12:45,680 --> 00:12:48,399
expecting a response from that function

00:12:47,200 --> 00:12:50,240
you can actually

00:12:48,399 --> 00:12:52,160
assume that this reliably happens

00:12:50,240 --> 00:12:54,399
exactly once um

00:12:52,160 --> 00:12:56,079
you you can probably already see like in

00:12:54,399 --> 00:12:57,519
the terminology and also in the kind of

00:12:56,079 --> 00:12:57,760
guarantees we're going to give here this

00:12:57,519 --> 00:12:59,440
is

00:12:57,760 --> 00:13:01,200
this is clearly coming a little bit from

00:12:59,440 --> 00:13:02,079
the direction of data stream processing

00:13:01,200 --> 00:13:04,079
which is

00:13:02,079 --> 00:13:06,079
um what we're working on um in the

00:13:04,079 --> 00:13:09,040
apache flink project pretty much

00:13:06,079 --> 00:13:10,800
most of the time so yeah these these

00:13:09,040 --> 00:13:12,639
guarantees that that stateful function

00:13:10,800 --> 00:13:14,560
is here is trying to give you is in a

00:13:12,639 --> 00:13:16,480
very are very similar guarantees to what

00:13:14,560 --> 00:13:17,200
our modern stream processors do want to

00:13:16,480 --> 00:13:19,279
give you

00:13:17,200 --> 00:13:21,120
namely consistent local state and the

00:13:19,279 --> 00:13:22,880
ability for for functions to talk with

00:13:21,120 --> 00:13:23,600
each other with exactly one's guarantees

00:13:22,880 --> 00:13:25,760
that means

00:13:23,600 --> 00:13:27,040
a message that you send is guaranteed to

00:13:25,760 --> 00:13:29,600
arrive and it's going to

00:13:27,040 --> 00:13:30,240
to arrive once if something happens on

00:13:29,600 --> 00:13:33,600
the way

00:13:30,240 --> 00:13:35,519
the whole system will consistently undo

00:13:33,600 --> 00:13:36,160
certain changes both on the receiver and

00:13:35,519 --> 00:13:39,120
on the

00:13:36,160 --> 00:13:42,639
sender side to be able to to retry it

00:13:39,120 --> 00:13:42,639
without duplicating any effects

00:13:42,959 --> 00:13:46,160
the whole thing is actually built to to

00:13:45,120 --> 00:13:48,320
work without

00:13:46,160 --> 00:13:49,279
without having to manage a database in

00:13:48,320 --> 00:13:52,880
the background

00:13:49,279 --> 00:13:54,720
so um state management that happens uh

00:13:52,880 --> 00:13:56,160
in the function doesn't actually in the

00:13:54,720 --> 00:13:57,440
in the background actually propagate to

00:13:56,160 --> 00:14:00,560
a database but it's

00:13:57,440 --> 00:14:03,279
asynchronously snapshotted to um

00:14:00,560 --> 00:14:04,399
to smart storage something like s3 s3 or

00:14:03,279 --> 00:14:07,199
hdfs or

00:14:04,399 --> 00:14:09,680
other other mass distributed file

00:14:07,199 --> 00:14:09,680
systems

00:14:10,720 --> 00:14:14,160
and yeah the the way you actually

00:14:12,800 --> 00:14:17,120
program this um

00:14:14,160 --> 00:14:18,800
in the newest version um we support both

00:14:17,120 --> 00:14:21,440
java and python

00:14:18,800 --> 00:14:22,320
is is very much i think i would say akin

00:14:21,440 --> 00:14:24,000
to a very

00:14:22,320 --> 00:14:25,519
to a very lightweight actor programming

00:14:24,000 --> 00:14:30,240
api um

00:14:25,519 --> 00:14:33,360
this is this is a simple example in um

00:14:30,240 --> 00:14:34,959
in yeah that takes a message um

00:14:33,360 --> 00:14:36,320
looks a little bit at you know what is

00:14:34,959 --> 00:14:38,000
what is the type of the message how

00:14:36,320 --> 00:14:39,839
should i react to it is it a

00:14:38,000 --> 00:14:41,920
um is it a vector that i should uh

00:14:39,839 --> 00:14:43,839
compute a classification for or is it

00:14:41,920 --> 00:14:44,959
a feedback with which i should update my

00:14:43,839 --> 00:14:46,880
model and then

00:14:44,959 --> 00:14:49,120
you can actually you know if you look at

00:14:46,880 --> 00:14:50,880
the code below it's not a 100 complete

00:14:49,120 --> 00:14:52,480
example but it gives you a rough idea

00:14:50,880 --> 00:14:54,320
in how you just access state from the

00:14:52,480 --> 00:14:56,839
local context um

00:14:54,320 --> 00:14:58,000
do some actions and send out a result

00:14:56,839 --> 00:14:59,760
message

00:14:58,000 --> 00:15:02,079
this is kind of from the the api

00:14:59,760 --> 00:15:04,560
perspective the the core

00:15:02,079 --> 00:15:05,360
of um of the idea behind you know

00:15:04,560 --> 00:15:06,959
building

00:15:05,360 --> 00:15:10,320
building applications with stateful

00:15:06,959 --> 00:15:12,399
functions and um

00:15:10,320 --> 00:15:13,920
i hope we kind of i hope it kind of

00:15:12,399 --> 00:15:15,519
explains how at least from the you know

00:15:13,920 --> 00:15:16,320
from the programming abstraction this

00:15:15,519 --> 00:15:18,079
kind of

00:15:16,320 --> 00:15:19,199
helps you to get rid of thinking about a

00:15:18,079 --> 00:15:20,639
database in the background because

00:15:19,199 --> 00:15:22,560
you're thinking just about functions

00:15:20,639 --> 00:15:24,320
with the local variables of state

00:15:22,560 --> 00:15:26,079
and you don't have to worry about the

00:15:24,320 --> 00:15:28,959
composition of functions in

00:15:26,079 --> 00:15:30,480
in in ways that are um you know we have

00:15:28,959 --> 00:15:32,880
to worry about fall tolerance

00:15:30,480 --> 00:15:34,720
and and failover because it it gives you

00:15:32,880 --> 00:15:35,680
the this kind of stream processing like

00:15:34,720 --> 00:15:37,600
exactly once

00:15:35,680 --> 00:15:40,000
guarantees across the communication of a

00:15:37,600 --> 00:15:42,800
lot of functions

00:15:40,000 --> 00:15:44,160
um for those of you that have actually

00:15:42,800 --> 00:15:45,759
followed the stream processing and

00:15:44,160 --> 00:15:47,279
apache flink space a bit they

00:15:45,759 --> 00:15:48,800
they will probably recognize that this

00:15:47,279 --> 00:15:50,160
is very reminiscent of a lot of stuff

00:15:48,800 --> 00:15:50,480
that is happening here so what's really

00:15:50,160 --> 00:15:53,120
the

00:15:50,480 --> 00:15:54,800
the main difference um there's a lot of

00:15:53,120 --> 00:15:56,720
difference in how it works in the

00:15:54,800 --> 00:15:58,480
in the background um which i'll i come

00:15:56,720 --> 00:16:00,000
to in a bit but also from the

00:15:58,480 --> 00:16:02,160
from the programming abstractions

00:16:00,000 --> 00:16:05,360
perspective there are differences

00:16:02,160 --> 00:16:08,720
um such as um

00:16:05,360 --> 00:16:09,440
the um yeah the the topology and stream

00:16:08,720 --> 00:16:11,920
processing

00:16:09,440 --> 00:16:13,040
is is usually a directed exactly graph

00:16:11,920 --> 00:16:15,600
that you predefine

00:16:13,040 --> 00:16:16,720
so um if you if you build a stream

00:16:15,600 --> 00:16:18,800
processing application

00:16:16,720 --> 00:16:20,160
usually start with um some data sources

00:16:18,800 --> 00:16:21,600
and then you say okay i'm going to apply

00:16:20,160 --> 00:16:22,880
maybe a filter transformation here in

00:16:21,600 --> 00:16:24,240
map transformation and then i'm feeding

00:16:22,880 --> 00:16:25,600
this into the left side of a join then

00:16:24,240 --> 00:16:27,199
there's another stream i'm feeding it to

00:16:25,600 --> 00:16:29,519
the right side of a join and then i'm

00:16:27,199 --> 00:16:31,279
applying and let's say aggregation by a

00:16:29,519 --> 00:16:34,639
certain by a certain

00:16:31,279 --> 00:16:37,279
grouping here so as the last step

00:16:34,639 --> 00:16:39,680
um in in contrast to that the idea of um

00:16:37,279 --> 00:16:41,920
of stateful functions is really to be

00:16:39,680 --> 00:16:43,360
to be much more low level and flexible

00:16:41,920 --> 00:16:46,000
as um

00:16:43,360 --> 00:16:48,000
as you as you kind of need it for a lot

00:16:46,000 --> 00:16:50,720
of applications so you're not defining

00:16:48,000 --> 00:16:52,240
your your data flow a priori you you're

00:16:50,720 --> 00:16:54,160
basically just deploying functions and

00:16:52,240 --> 00:16:55,519
they can dynamically at runtime decide

00:16:54,160 --> 00:16:57,120
who they talk to that just

00:16:55,519 --> 00:16:59,040
send message to a logical address and

00:16:57,120 --> 00:17:02,000
they await a response from there

00:16:59,040 --> 00:17:02,399
um they can communicate in patterns that

00:17:02,000 --> 00:17:03,920
include

00:17:02,399 --> 00:17:05,760
like cyclic messaging which you cannot

00:17:03,920 --> 00:17:06,240
do in stream processing and they have a

00:17:05,760 --> 00:17:08,720
very

00:17:06,240 --> 00:17:10,240
dynamic nature in in how they um how

00:17:08,720 --> 00:17:11,199
they are created and how they occupy

00:17:10,240 --> 00:17:13,520
resources

00:17:11,199 --> 00:17:14,880
with the stream processing more has like

00:17:13,520 --> 00:17:16,559
fixed pipelines that you know they can

00:17:14,880 --> 00:17:18,400
be scaled in and out but at any point in

00:17:16,559 --> 00:17:21,919
time they actually have a

00:17:18,400 --> 00:17:21,919
certain fixed set of resources

00:17:22,000 --> 00:17:26,480
um as such the the idea behind several

00:17:24,640 --> 00:17:28,400
functions actually much closer to

00:17:26,480 --> 00:17:31,360
something that i think has been often

00:17:28,400 --> 00:17:32,880
called virtual stateful actors

00:17:31,360 --> 00:17:35,280
but with very high consistency

00:17:32,880 --> 00:17:35,679
guarantees like consistent local state

00:17:35,280 --> 00:17:38,080
and

00:17:35,679 --> 00:17:39,760
exactly once messaging guarantees so if

00:17:38,080 --> 00:17:42,320
you're coming from this space if you're

00:17:39,760 --> 00:17:44,000
um if you're for example an aka

00:17:42,320 --> 00:17:44,720
programmer or so you can think of safer

00:17:44,000 --> 00:17:47,840
functions as

00:17:44,720 --> 00:17:49,440
a version that um that makes an

00:17:47,840 --> 00:17:52,400
opinionated choice in how

00:17:49,440 --> 00:17:54,240
how these certain configurations should

00:17:52,400 --> 00:17:57,360
be chosen for example you don't have

00:17:54,240 --> 00:18:00,640
you don't have um a super um

00:17:57,360 --> 00:18:02,880
flexible system of like supervision and

00:18:00,640 --> 00:18:04,080
um deciding what you do if you know if

00:18:02,880 --> 00:18:05,840
an exception

00:18:04,080 --> 00:18:07,919
um happens or so but but rather the

00:18:05,840 --> 00:18:10,000
system makes an opinionated choice to

00:18:07,919 --> 00:18:10,720
say okay we're we're opting completely

00:18:10,000 --> 00:18:14,160
here for

00:18:10,720 --> 00:18:17,679
um for strong consistency guarantees

00:18:14,160 --> 00:18:20,880
and we're for example um

00:18:17,679 --> 00:18:23,760
not not remaining available under under

00:18:20,880 --> 00:18:24,400
a uh under network partition so while

00:18:23,760 --> 00:18:26,400
you know with

00:18:24,400 --> 00:18:28,080
with actor systems like like aka they

00:18:26,400 --> 00:18:28,720
give you this very flexible primitives

00:18:28,080 --> 00:18:31,600
with

00:18:28,720 --> 00:18:33,280
heartbeating and and watching and

00:18:31,600 --> 00:18:34,000
supervision you can for example also

00:18:33,280 --> 00:18:35,919
build

00:18:34,000 --> 00:18:37,600
ap systems and so on stanford functions

00:18:35,919 --> 00:18:38,960
is really an opinionated choice towards

00:18:37,600 --> 00:18:41,440
a cp system

00:18:38,960 --> 00:18:44,720
that is um in that way actually making

00:18:41,440 --> 00:18:48,240
the apis quite a bit simpler

00:18:44,720 --> 00:18:50,799
so from the api perspective um that is

00:18:48,240 --> 00:18:51,679
uh pretty much it one one big part that

00:18:50,799 --> 00:18:53,360
um

00:18:51,679 --> 00:18:55,120
that this is the question now how do we

00:18:53,360 --> 00:18:56,559
actually handle handle state the

00:18:55,120 --> 00:18:58,400
serverless way because we kind of

00:18:56,559 --> 00:18:59,120
touched only on yeah sure we don't want

00:18:58,400 --> 00:19:00,320
to have this

00:18:59,120 --> 00:19:03,440
we don't want to have a database in the

00:19:00,320 --> 00:19:06,080
background we don't want to um yeah

00:19:03,440 --> 00:19:07,840
be forced to um to deal with connections

00:19:06,080 --> 00:19:09,280
and so we just want to pretend that we

00:19:07,840 --> 00:19:10,000
have persistent local state and then

00:19:09,280 --> 00:19:11,760
there's some

00:19:10,000 --> 00:19:13,120
snapshots in the background so i admit

00:19:11,760 --> 00:19:13,760
there was a bit hand-wavy in the first

00:19:13,120 --> 00:19:16,640
and

00:19:13,760 --> 00:19:19,280
first part but it was i was so on

00:19:16,640 --> 00:19:20,880
purpose just to focus on the um

00:19:19,280 --> 00:19:23,440
on the aspect of like what what is the

00:19:20,880 --> 00:19:26,559
api towards the user what abstraction

00:19:23,440 --> 00:19:28,480
can can the user um expect here

00:19:26,559 --> 00:19:31,039
in the second part i'd i'd like to dive

00:19:28,480 --> 00:19:32,559
a bit into how does actually this um

00:19:31,039 --> 00:19:34,799
how does it actually work underneath the

00:19:32,559 --> 00:19:35,440
hood how do how does the system give

00:19:34,799 --> 00:19:37,919
these

00:19:35,440 --> 00:19:38,960
um consistency guarantees and still

00:19:37,919 --> 00:19:41,760
actually maintain

00:19:38,960 --> 00:19:43,280
the this nice serverless elasticity

00:19:41,760 --> 00:19:46,160
without sacrificing anything on the

00:19:43,280 --> 00:19:46,160
stateful side

00:19:46,240 --> 00:19:49,200
so if you if you look at the at the

00:19:47,840 --> 00:19:50,240
literature for this there's actually

00:19:49,200 --> 00:19:51,919
quite a bit of

00:19:50,240 --> 00:19:53,760
work and also research on the area and

00:19:51,919 --> 00:19:55,120
how do you actually add consistent state

00:19:53,760 --> 00:19:56,799
to serverless systems and

00:19:55,120 --> 00:19:58,799
there are quite a few approaches that

00:19:56,799 --> 00:20:00,080
that center around around something like

00:19:58,799 --> 00:20:02,720
this where you have

00:20:00,080 --> 00:20:03,440
um you have your compute layer um

00:20:02,720 --> 00:20:06,640
basically

00:20:03,440 --> 00:20:07,919
something like aws lambda just very fast

00:20:06,640 --> 00:20:09,440
elastically scalable

00:20:07,919 --> 00:20:11,120
stateless functions and then you have a

00:20:09,440 --> 00:20:12,720
layer that is

00:20:11,120 --> 00:20:14,240
responsible for basically presenting the

00:20:12,720 --> 00:20:15,760
state to that layer there's databases in

00:20:14,240 --> 00:20:17,520
the background but this middle layer

00:20:15,760 --> 00:20:20,240
kind of through crashing and proxying

00:20:17,520 --> 00:20:21,840
is trying to abstract that away from you

00:20:20,240 --> 00:20:23,600
that's actually explicitly not what

00:20:21,840 --> 00:20:25,280
we've been trying to do here it's it's a

00:20:23,600 --> 00:20:27,600
possible approach but it

00:20:25,280 --> 00:20:29,440
um it is something that we we took a bit

00:20:27,600 --> 00:20:32,080
of a look at initially and

00:20:29,440 --> 00:20:33,039
um it's it's very complicated um in the

00:20:32,080 --> 00:20:35,440
end to do it

00:20:33,039 --> 00:20:37,200
um correctly and efficiently and there's

00:20:35,440 --> 00:20:38,320
actually a there's a slight trick i

00:20:37,200 --> 00:20:41,120
think you can do to

00:20:38,320 --> 00:20:42,159
um to to still gain um a lot of the

00:20:41,120 --> 00:20:45,280
benefits

00:20:42,159 --> 00:20:47,440
but um yeah with with uh with

00:20:45,280 --> 00:20:50,159
with much um with a much simpler

00:20:47,440 --> 00:20:52,960
approach in the end

00:20:50,159 --> 00:20:53,360
and to to kind of motivate that maybe um

00:20:52,960 --> 00:20:56,640
let's

00:20:53,360 --> 00:20:58,080
let's let's do a quick like um a thought

00:20:56,640 --> 00:21:01,360
experiment on

00:20:58,080 --> 00:21:03,840
um on challenges and approaches to to um

00:21:01,360 --> 00:21:05,200
to consistency in in these distributed

00:21:03,840 --> 00:21:07,360
applications

00:21:05,200 --> 00:21:08,480
so let's assume here we have um we have

00:21:07,360 --> 00:21:10,559
three different

00:21:08,480 --> 00:21:11,919
different applications like you know

00:21:10,559 --> 00:21:15,120
types of functions that

00:21:11,919 --> 00:21:17,039
talk to some some database dynamodb

00:21:15,120 --> 00:21:18,159
cassandra h based elastic or so on the

00:21:17,039 --> 00:21:21,440
background

00:21:18,159 --> 00:21:23,200
um and yeah these

00:21:21,440 --> 00:21:25,600
let's let's assume they form um

00:21:23,200 --> 00:21:27,679
something like a microservice each and

00:21:25,600 --> 00:21:30,000
um an interaction with the application

00:21:27,679 --> 00:21:31,520
it starts um with the api gateway

00:21:30,000 --> 00:21:32,880
and one of the functions and then these

00:21:31,520 --> 00:21:33,840
functions also have to talk to other

00:21:32,880 --> 00:21:35,520
functions too

00:21:33,840 --> 00:21:37,360
to in the end do their work to you know

00:21:35,520 --> 00:21:40,000
request data from other services update

00:21:37,360 --> 00:21:44,480
data and other services

00:21:40,000 --> 00:21:47,039
okay um the the first um

00:21:44,480 --> 00:21:49,200
first thing that happens is that there

00:21:47,039 --> 00:21:53,360
is a request to the first service

00:21:49,200 --> 00:21:55,679
it looks at the um at the database it um

00:21:53,360 --> 00:21:58,799
updates uh something and then it sends a

00:21:55,679 --> 00:22:00,880
message to the second service

00:21:58,799 --> 00:22:03,280
which in turn also updates something in

00:22:00,880 --> 00:22:05,520
the database

00:22:03,280 --> 00:22:06,960
now let's assume in this case here we

00:22:05,520 --> 00:22:10,320
have a

00:22:06,960 --> 00:22:11,919
we have a failure and we didn't get a

00:22:10,320 --> 00:22:13,280
response from the second service back to

00:22:11,919 --> 00:22:14,799
the to the first service so the second

00:22:13,280 --> 00:22:16,400
function actually didn't didn't tell the

00:22:14,799 --> 00:22:18,240
first function okay you know

00:22:16,400 --> 00:22:19,679
everything everything went through now

00:22:18,240 --> 00:22:21,360
we're in a bit of a tricky situation

00:22:19,679 --> 00:22:22,880
because we don't quite know did it go

00:22:21,360 --> 00:22:23,440
through it did not go through do i have

00:22:22,880 --> 00:22:25,360
to

00:22:23,440 --> 00:22:27,039
like retry it or will it really result

00:22:25,360 --> 00:22:29,440
in a duplicate um

00:22:27,039 --> 00:22:30,960
did it actually go go through and not

00:22:29,440 --> 00:22:33,039
just miss the acknowledgement or

00:22:30,960 --> 00:22:34,000
or yeah just it's it's this general

00:22:33,039 --> 00:22:36,080
problem um

00:22:34,000 --> 00:22:38,159
to general's problem that that is hard

00:22:36,080 --> 00:22:38,559
to solve in distributed systems and

00:22:38,159 --> 00:22:40,559
there's

00:22:38,559 --> 00:22:41,840
there's lots of work in in applications

00:22:40,559 --> 00:22:42,720
and protocols and so on try to work

00:22:41,840 --> 00:22:44,159
around it but it

00:22:42,720 --> 00:22:46,480
it's it's always an issue you have to

00:22:44,159 --> 00:22:50,159
worry about in in one or the other

00:22:46,480 --> 00:22:51,840
way now one thing we can try and do is

00:22:50,159 --> 00:22:54,240
we can just try to reverse a little bit

00:22:51,840 --> 00:22:57,280
the the role between the application and

00:22:54,240 --> 00:22:58,320
um the database here so let's assume

00:22:57,280 --> 00:22:59,840
just for a second that

00:22:58,320 --> 00:23:01,679
you know instead of the api get we're

00:22:59,840 --> 00:23:04,159
actually talking to lambda here and

00:23:01,679 --> 00:23:05,919
um sending sending the request there and

00:23:04,159 --> 00:23:08,240
then lambda talking to the database

00:23:05,919 --> 00:23:10,320
it would actually first send it to the

00:23:08,240 --> 00:23:13,360
database and then the database would

00:23:10,320 --> 00:23:14,240
um you know like record it associate it

00:23:13,360 --> 00:23:17,360
probably with

00:23:14,240 --> 00:23:19,280
um some some entity that that it belongs

00:23:17,360 --> 00:23:22,799
to let's say user id or so

00:23:19,280 --> 00:23:24,960
and then from there call call a function

00:23:22,799 --> 00:23:26,559
get the request back and then talk to uh

00:23:24,960 --> 00:23:28,080
send it back to the database for the end

00:23:26,559 --> 00:23:28,640
for the next service which in turn would

00:23:28,080 --> 00:23:31,520
also

00:23:28,640 --> 00:23:33,360
you know invoke invoke the function if

00:23:31,520 --> 00:23:34,799
we actually have the problem now that we

00:23:33,360 --> 00:23:36,880
that we see a failure in that in the

00:23:34,799 --> 00:23:40,159
transmission we're in a much easier

00:23:36,880 --> 00:23:41,919
um place actually um or in a much better

00:23:40,159 --> 00:23:43,520
place to solve this problem because on

00:23:41,919 --> 00:23:44,799
on the on the database layer we're

00:23:43,520 --> 00:23:46,960
handling both the state

00:23:44,799 --> 00:23:47,840
now and the messaging and once we do

00:23:46,960 --> 00:23:49,679
that

00:23:47,840 --> 00:23:52,080
there we can actually employ a lot of

00:23:49,679 --> 00:23:53,840
like very very known proven protocols in

00:23:52,080 --> 00:23:54,320
a very generic way to actually make sure

00:23:53,840 --> 00:23:56,880
that

00:23:54,320 --> 00:23:58,480
the updates to to state and and

00:23:56,880 --> 00:24:00,159
messaging that this happens in

00:23:58,480 --> 00:24:02,159
like in an atomic way that does not

00:24:00,159 --> 00:24:05,360
cause loss or duplicates

00:24:02,159 --> 00:24:09,600
and we sort of have a way to make

00:24:05,360 --> 00:24:13,360
all our um all our invocations to

00:24:09,600 --> 00:24:16,799
to lambda functions pretty much yeah

00:24:13,360 --> 00:24:18,480
stateless item quite important um

00:24:16,799 --> 00:24:19,600
so if we actually have to call this

00:24:18,480 --> 00:24:20,880
function again it actually doesn't

00:24:19,600 --> 00:24:22,480
matter because that function does no

00:24:20,880 --> 00:24:24,159
longer make a decision about sending a

00:24:22,480 --> 00:24:25,760
message or about triggering an update

00:24:24,159 --> 00:24:27,520
all these decisions are now just

00:24:25,760 --> 00:24:29,760
generically made down inside the

00:24:27,520 --> 00:24:32,240
database system

00:24:29,760 --> 00:24:33,120
so in some sense what what we're what

00:24:32,240 --> 00:24:34,799
we're

00:24:33,120 --> 00:24:37,200
what we really need to employ this trick

00:24:34,799 --> 00:24:38,720
is is kind of yeah this inversion about

00:24:37,200 --> 00:24:39,760
application applications and data

00:24:38,720 --> 00:24:41,600
interact so

00:24:39,760 --> 00:24:43,200
rather than having an application that

00:24:41,600 --> 00:24:44,640
takes a request talks to the database

00:24:43,200 --> 00:24:46,559
and gives a response

00:24:44,640 --> 00:24:48,000
we actually have something like i

00:24:46,559 --> 00:24:49,440
actually see it on the slide already

00:24:48,000 --> 00:24:51,440
something like a stream processor that

00:24:49,440 --> 00:24:53,440
takes this stream of requests

00:24:51,440 --> 00:24:56,080
and then calls our applications and and

00:24:53,440 --> 00:24:58,080
gives a stream of responses

00:24:56,080 --> 00:24:59,520
and if we do this the right way then we

00:24:58,080 --> 00:25:02,720
can yeah we can

00:24:59,520 --> 00:25:04,080
just keep using applications um in the

00:25:02,720 --> 00:25:05,840
building them the exact same way as

00:25:04,080 --> 00:25:07,120
before and we just

00:25:05,840 --> 00:25:09,520
swap the database with the stream

00:25:07,120 --> 00:25:13,200
processor and we can pretty much

00:25:09,520 --> 00:25:15,760
can pretty much go and um we've gained

00:25:13,200 --> 00:25:16,880
a very a very nice way of building

00:25:15,760 --> 00:25:20,159
stateful

00:25:16,880 --> 00:25:23,840
um therefore systems here

00:25:20,159 --> 00:25:25,760
um it also means that we're we're really

00:25:23,840 --> 00:25:27,919
switching a little bit the the roles of

00:25:25,760 --> 00:25:29,600
of who is actually in charge of you know

00:25:27,919 --> 00:25:30,880
driving the entire application and the

00:25:29,600 --> 00:25:31,840
in the classical sense it's the

00:25:30,880 --> 00:25:33,840
application that

00:25:31,840 --> 00:25:35,039
it retrieves the request and it's in

00:25:33,840 --> 00:25:36,880
charge of you know

00:25:35,039 --> 00:25:38,240
making response requests and responses

00:25:36,880 --> 00:25:39,679
to the database and the database pretty

00:25:38,240 --> 00:25:40,799
much reacts to those

00:25:39,679 --> 00:25:42,400
on the right-hand side we have the

00:25:40,799 --> 00:25:43,360
stream processor deciding when it's the

00:25:42,400 --> 00:25:44,640
right

00:25:43,360 --> 00:25:46,880
when it's the right moment to actually

00:25:44,640 --> 00:25:50,159
invoke the application with a certain

00:25:46,880 --> 00:25:51,679
piece of piece of computation that we

00:25:50,159 --> 00:25:53,919
need to do

00:25:51,679 --> 00:25:55,760
so applying this may be true to

00:25:53,919 --> 00:25:57,279
something like

00:25:55,760 --> 00:25:58,480
something like the aws stack if you're

00:25:57,279 --> 00:26:00,000
familiar with this it would actually

00:25:58,480 --> 00:26:02,640
mean that instead of

00:26:00,000 --> 00:26:04,000
um let's say we're we're building an

00:26:02,640 --> 00:26:06,480
application that that

00:26:04,000 --> 00:26:07,919
processes data from um from kinesis

00:26:06,480 --> 00:26:10,640
which is a like a

00:26:07,919 --> 00:26:12,000
streaming message queue here um rather

00:26:10,640 --> 00:26:13,440
than then building it in

00:26:12,000 --> 00:26:15,360
in the way that you would find it on on

00:26:13,440 --> 00:26:16,799
the amazon block here like define your

00:26:15,360 --> 00:26:17,919
lambda functions to consume data from

00:26:16,799 --> 00:26:20,400
kinesis and then work

00:26:17,919 --> 00:26:22,240
around dynamodb it actually would

00:26:20,400 --> 00:26:24,559
actually say like the first consumer

00:26:22,240 --> 00:26:25,679
for of these events is actually the

00:26:24,559 --> 00:26:27,679
stream processor and then the stream

00:26:25,679 --> 00:26:30,799
processor talks through the api gateway

00:26:27,679 --> 00:26:30,799
to the lambda functions

00:26:31,360 --> 00:26:35,039
and it's it's actually worth noting that

00:26:33,279 --> 00:26:36,480
we kind of solved two of the most cited

00:26:35,039 --> 00:26:39,039
problems of of the whole

00:26:36,480 --> 00:26:39,600
um the whole serverless space with that

00:26:39,039 --> 00:26:41,919
like

00:26:39,600 --> 00:26:43,840
consistent scalable state and messaging

00:26:41,919 --> 00:26:45,200
and composition

00:26:43,840 --> 00:26:47,039
um for the sake of time because we

00:26:45,200 --> 00:26:48,080
started a little late i'm i'm going to

00:26:47,039 --> 00:26:52,159
skip over the

00:26:48,080 --> 00:26:53,760
um over the recap of apache flink here

00:26:52,159 --> 00:26:55,919
just mentioning really quick apache

00:26:53,760 --> 00:26:56,559
flink is this stream processing system

00:26:55,919 --> 00:26:57,679
that

00:26:56,559 --> 00:26:59,520
that working on it's kind of the

00:26:57,679 --> 00:27:00,159
umbrella project of of stateful

00:26:59,520 --> 00:27:03,279
functions

00:27:00,159 --> 00:27:04,000
and the um in its core it's really an

00:27:03,279 --> 00:27:06,480
engine that

00:27:04,000 --> 00:27:08,320
that pushes streams through operations

00:27:06,480 --> 00:27:11,360
and in the background

00:27:08,320 --> 00:27:13,200
um takes uh consistent asynchronous

00:27:11,360 --> 00:27:14,720
snapshots of the streaming pipeline in

00:27:13,200 --> 00:27:16,799
order to recover them and it has these

00:27:14,720 --> 00:27:19,200
interesting properties of being able to

00:27:16,799 --> 00:27:20,880
give you exactly once guarantees for

00:27:19,200 --> 00:27:23,120
your state and your messaging

00:27:20,880 --> 00:27:24,640
without actually needing a ton of

00:27:23,120 --> 00:27:27,120
coordination overhead

00:27:24,640 --> 00:27:29,520
um if you haven't actually looked at

00:27:27,120 --> 00:27:31,120
that apache flink at all so far i

00:27:29,520 --> 00:27:32,480
cannot hardly recommend it take it take

00:27:31,120 --> 00:27:34,240
a look it's a really interesting project

00:27:32,480 --> 00:27:37,919
i might be a biased person but

00:27:34,240 --> 00:27:37,919
i i do honestly believe that

00:27:38,480 --> 00:27:45,360
so back to back to stateful functions

00:27:42,240 --> 00:27:45,840
itself so as i mentioned this this is

00:27:45,360 --> 00:27:47,600
built

00:27:45,840 --> 00:27:49,760
on on stream processing technology in

00:27:47,600 --> 00:27:52,240
this case specifically on apache flink

00:27:49,760 --> 00:27:52,880
if you actually deploy um if you

00:27:52,240 --> 00:27:54,480
actually

00:27:52,880 --> 00:27:56,640
use it in production what you like what

00:27:54,480 --> 00:27:59,840
you actually see is that in the core

00:27:56,640 --> 00:28:02,240
you deploy you deploy a yeah

00:27:59,840 --> 00:28:03,520
a cluster of flink with stateful

00:28:02,240 --> 00:28:05,279
functions pretty much like you would

00:28:03,520 --> 00:28:08,240
otherwise deploy a database

00:28:05,279 --> 00:28:10,240
and you basically um you basically

00:28:08,240 --> 00:28:11,840
register modules ingress modules or so

00:28:10,240 --> 00:28:14,640
that say okay here are the events

00:28:11,840 --> 00:28:16,480
that that you just that you consume that

00:28:14,640 --> 00:28:18,000
you um that you react to and then you

00:28:16,480 --> 00:28:19,679
can actually register

00:28:18,000 --> 00:28:21,200
certain modules or functions that may

00:28:19,679 --> 00:28:24,799
result on um as

00:28:21,200 --> 00:28:28,000
a separate um kubernetes deployments or

00:28:24,799 --> 00:28:29,520
um may result behind an api gateway um

00:28:28,000 --> 00:28:32,080
if if you're talking about you know

00:28:29,520 --> 00:28:35,360
serverless functions to to actually

00:28:32,080 --> 00:28:37,919
um execute execute the logic

00:28:35,360 --> 00:28:39,360
and um yeah let me actually quickly

00:28:37,919 --> 00:28:41,600
quickly show you what um

00:28:39,360 --> 00:28:42,880
what this looks like if you actually use

00:28:41,600 --> 00:28:46,720
it

00:28:42,880 --> 00:28:48,880
in for real application

00:28:46,720 --> 00:28:50,720
so the the use case that i've picked is

00:28:48,880 --> 00:28:51,760
actually a um

00:28:50,720 --> 00:28:54,480
it's actually a machine learning

00:28:51,760 --> 00:28:57,840
application um which is taking

00:28:54,480 --> 00:29:00,720
a stream of user events and

00:28:57,840 --> 00:29:02,240
is outputting um like a fraud risk score

00:29:00,720 --> 00:29:03,760
for that

00:29:02,240 --> 00:29:05,600
so the the way that this application

00:29:03,760 --> 00:29:07,520
works is that every event first runs

00:29:05,600 --> 00:29:08,880
through a set of statistical um

00:29:07,520 --> 00:29:10,480
statistical functions that collect

00:29:08,880 --> 00:29:11,200
certain aggregates like what is the time

00:29:10,480 --> 00:29:13,279
since you know

00:29:11,200 --> 00:29:14,799
that user did another transaction what

00:29:13,279 --> 00:29:16,240
is the what is the

00:29:14,799 --> 00:29:18,640
the number of times they have used it

00:29:16,240 --> 00:29:21,200
for this sort of um for this sort of

00:29:18,640 --> 00:29:23,120
uh yeah product or how many times have

00:29:21,200 --> 00:29:25,039
they used it in that country and so on

00:29:23,120 --> 00:29:26,159
so think of it as yeah as different

00:29:25,039 --> 00:29:29,360
aggregates of

00:29:26,159 --> 00:29:30,960
such of such features and then we pass

00:29:29,360 --> 00:29:32,640
it actually through a classifier module

00:29:30,960 --> 00:29:35,520
so the classifier

00:29:32,640 --> 00:29:36,320
is is a as a python simple python

00:29:35,520 --> 00:29:39,520
machine learning

00:29:36,320 --> 00:29:41,520
um algorithm um which which uses

00:29:39,520 --> 00:29:43,120
five different we actually uses uh five

00:29:41,520 --> 00:29:46,480
different algorithms here

00:29:43,120 --> 00:29:48,720
um to that represent different ways of

00:29:46,480 --> 00:29:50,799
of classifying the fraud and the idea

00:29:48,720 --> 00:29:51,600
here is it it depends on what kind of

00:29:50,799 --> 00:29:53,520
persona

00:29:51,600 --> 00:29:54,720
the user is which model actually gives

00:29:53,520 --> 00:29:56,880
the the most accurate

00:29:54,720 --> 00:29:58,000
um accurate prediction whether this is a

00:29:56,880 --> 00:29:59,679
fraud or not

00:29:58,000 --> 00:30:01,200
so some somebody who is you know mainly

00:29:59,679 --> 00:30:02,880
an online shopper mainly an offline shop

00:30:01,200 --> 00:30:05,360
or somebody that travels a lot travels

00:30:02,880 --> 00:30:07,120
travels little um it's actually um it's

00:30:05,360 --> 00:30:08,799
quite a popular model to have this um to

00:30:07,120 --> 00:30:10,640
have this multiple different models and

00:30:08,799 --> 00:30:11,760
then try to to pick the one that is most

00:30:10,640 --> 00:30:13,520
accurate for the user

00:30:11,760 --> 00:30:15,360
and an approach to do this is this

00:30:13,520 --> 00:30:17,120
multi-armed bandit or

00:30:15,360 --> 00:30:19,919
or k bandits where you or you're

00:30:17,120 --> 00:30:22,000
emulating these um you know like this

00:30:19,919 --> 00:30:23,440
bandit slot machines and you're actually

00:30:22,000 --> 00:30:24,159
saying the one that gives me the highest

00:30:23,440 --> 00:30:26,480
reward

00:30:24,159 --> 00:30:28,720
that's that's the the one that decides

00:30:26,480 --> 00:30:30,559
for for the model that i pick

00:30:28,720 --> 00:30:32,320
so this is also a stateful thing because

00:30:30,559 --> 00:30:32,880
we need to remember how many times did

00:30:32,320 --> 00:30:35,360
we pick

00:30:32,880 --> 00:30:37,120
um individual individual models and what

00:30:35,360 --> 00:30:38,559
was the what was the accuracy what was

00:30:37,120 --> 00:30:40,880
the reward we got in the end for this

00:30:38,559 --> 00:30:40,880
model

00:30:41,200 --> 00:30:45,440
um if we implement this and this um in

00:30:43,600 --> 00:30:46,880
the state for functions approach what we

00:30:45,440 --> 00:30:48,399
what we have to do on the

00:30:46,880 --> 00:30:50,320
let's say on the on the flink side on

00:30:48,399 --> 00:30:52,159
the event-driven database side is we

00:30:50,320 --> 00:30:55,520
have to register an ingress model

00:30:52,159 --> 00:30:56,799
for um for the different type of

00:30:55,520 --> 00:31:00,000
requests that come in

00:30:56,799 --> 00:31:02,000
in this case it's it's requests um

00:31:00,000 --> 00:31:03,200
here the type url is a demo sparse

00:31:02,000 --> 00:31:04,960
vector that is

00:31:03,200 --> 00:31:07,279
a vector that we want to get classified

00:31:04,960 --> 00:31:09,039
and then prediction feedback

00:31:07,279 --> 00:31:10,799
which is you know once we know it was it

00:31:09,039 --> 00:31:13,600
actually a fraud or not

00:31:10,799 --> 00:31:14,880
in hindsight feedback to the model and

00:31:13,600 --> 00:31:16,880
then on the right hand side this is

00:31:14,880 --> 00:31:19,279
basically all it takes in order to say

00:31:16,880 --> 00:31:20,720
let's let's define let's register a

00:31:19,279 --> 00:31:23,840
function model

00:31:20,720 --> 00:31:26,080
a function module to be invoked here

00:31:23,840 --> 00:31:27,600
and then this is the same the same code

00:31:26,080 --> 00:31:29,279
i showed earlier

00:31:27,600 --> 00:31:30,720
this is pretty much what it looks like

00:31:29,279 --> 00:31:34,000
to implement such a function it's pretty

00:31:30,720 --> 00:31:36,480
it's pretty compact code in the end

00:31:34,000 --> 00:31:38,000
so let's actually um let's actually take

00:31:36,480 --> 00:31:40,880
two minutes and just see how

00:31:38,000 --> 00:31:42,559
how this looks like if we run this i

00:31:40,880 --> 00:31:43,919
have to quickly

00:31:42,559 --> 00:31:47,279
see how do we do this with the

00:31:43,919 --> 00:31:51,039
presentation here

00:31:47,279 --> 00:31:54,320
okay does this work

00:31:51,039 --> 00:31:55,039
okay i just hit play it's a pre-recorded

00:31:54,320 --> 00:31:57,200
demo for

00:31:55,039 --> 00:31:58,880
um for the sake of being easy to

00:31:57,200 --> 00:32:02,559
broadcast here

00:31:58,880 --> 00:32:04,399
okay um so

00:32:02,559 --> 00:32:06,399
the the application that we're seeing

00:32:04,399 --> 00:32:07,440
here is outputting our is visualizing on

00:32:06,399 --> 00:32:10,000
the right-hand side

00:32:07,440 --> 00:32:11,440
um our our average fraud score and we

00:32:10,000 --> 00:32:11,679
can we can probably see that something

00:32:11,440 --> 00:32:12,880
is

00:32:11,679 --> 00:32:15,519
something's off here a little bit

00:32:12,880 --> 00:32:16,960
because you know 0.8 of every

00:32:15,519 --> 00:32:18,320
transaction being fraudulent

00:32:16,960 --> 00:32:20,640
they will probably misclassifying

00:32:18,320 --> 00:32:22,320
something here so over time of this demo

00:32:20,640 --> 00:32:25,279
we want to repair this

00:32:22,320 --> 00:32:26,000
let's look quickly at um at what what we

00:32:25,279 --> 00:32:29,919
have here

00:32:26,000 --> 00:32:30,720
running and this is really an absolute

00:32:29,919 --> 00:32:32,559
standard

00:32:30,720 --> 00:32:34,720
kubernetes deployment as you would

00:32:32,559 --> 00:32:36,559
actually deploy you know

00:32:34,720 --> 00:32:38,080
let's say a database on kubernetes and

00:32:36,559 --> 00:32:38,640
an application now the interesting part

00:32:38,080 --> 00:32:39,840
is

00:32:38,640 --> 00:32:40,960
because flink works with this

00:32:39,840 --> 00:32:42,000
asynchronous snapshots and the

00:32:40,960 --> 00:32:43,840
background to something

00:32:42,000 --> 00:32:45,600
like in this case we're running this on

00:32:43,840 --> 00:32:46,880
google cloud so google cloud storage we

00:32:45,600 --> 00:32:47,679
actually don't even need stateful sets

00:32:46,880 --> 00:32:49,919
here so we're

00:32:47,679 --> 00:32:51,919
actually running state less processes

00:32:49,919 --> 00:32:55,039
here for the master and the worker

00:32:51,919 --> 00:32:56,480
and then a few the um you see

00:32:55,039 --> 00:32:58,640
they're called python workers here in

00:32:56,480 --> 00:33:00,559
the in the entry um

00:32:58,640 --> 00:33:03,279
for for the actual um for the actual

00:33:00,559 --> 00:33:03,279
functions so

00:33:03,440 --> 00:33:10,799
and we can we can actually you know now

00:33:06,880 --> 00:33:12,640
um scale these these stateless workers

00:33:10,799 --> 00:33:16,640
in the in the exact same way as we would

00:33:12,640 --> 00:33:18,480
scale any other any other application

00:33:16,640 --> 00:33:20,240
if we would run this for example on on

00:33:18,480 --> 00:33:21,519
aws we would actually see that

00:33:20,240 --> 00:33:23,039
you know it would actually scale

00:33:21,519 --> 00:33:24,720
automatically depend depending on the

00:33:23,039 --> 00:33:26,399
request rate or we could just add in

00:33:24,720 --> 00:33:27,039
this kubernetes example here in auto

00:33:26,399 --> 00:33:28,960
scaling group

00:33:27,039 --> 00:33:31,360
to scale it for us and this demo we

00:33:28,960 --> 00:33:33,120
scale it manually though

00:33:31,360 --> 00:33:34,799
another thing that we can can pretty

00:33:33,120 --> 00:33:37,519
easily do here is just

00:33:34,799 --> 00:33:40,000
swap the the container image for the

00:33:37,519 --> 00:33:42,320
functions in order to for example apply

00:33:40,000 --> 00:33:44,240
a new version of the software that has

00:33:42,320 --> 00:33:47,039
that has a patch

00:33:44,240 --> 00:33:49,440
that that fixes the the classification

00:33:47,039 --> 00:33:51,440
for example we can see that

00:33:49,440 --> 00:33:53,279
i don't know cannot see this well here

00:33:51,440 --> 00:33:57,039
because this screen

00:33:53,279 --> 00:34:00,159
is cut off at the bottom

00:33:57,039 --> 00:34:02,159
ah now we can see it better yeah and um

00:34:00,159 --> 00:34:04,000
so this repairs um this repairs our

00:34:02,159 --> 00:34:04,960
deployment what is interesting to see

00:34:04,000 --> 00:34:06,960
here is that

00:34:04,960 --> 00:34:08,720
in in the course of this entire um

00:34:06,960 --> 00:34:10,399
deployment we actually did not get any

00:34:08,720 --> 00:34:12,159
any disruption of the

00:34:10,399 --> 00:34:14,480
of the system and we didn't actually

00:34:12,159 --> 00:34:15,200
have to do anything in our code to worry

00:34:14,480 --> 00:34:17,760
about

00:34:15,200 --> 00:34:19,119
okay how do we deal with certain old

00:34:17,760 --> 00:34:20,560
versions of the code running certain new

00:34:19,119 --> 00:34:22,320
versions of the code running how do we

00:34:20,560 --> 00:34:24,399
deal with um

00:34:22,320 --> 00:34:25,760
yeah how do we deal with concurrent

00:34:24,399 --> 00:34:27,679
access to

00:34:25,760 --> 00:34:29,200
to certain entries and so on so all of

00:34:27,679 --> 00:34:34,639
this is pretty much

00:34:29,200 --> 00:34:38,079
solved by the system out of the box

00:34:34,639 --> 00:34:41,839
all right and with that i'm

00:34:38,079 --> 00:34:45,040
pretty much at the end of this talk um

00:34:41,839 --> 00:34:45,679
yeah the um that's it that's what we're

00:34:45,040 --> 00:34:49,119
um that

00:34:45,679 --> 00:34:51,119
what we're currently developing see it's

00:34:49,119 --> 00:34:53,040
in a nutshell let's say it's really in a

00:34:51,119 --> 00:34:53,919
system that that tries to to give you

00:34:53,040 --> 00:34:55,520
this

00:34:53,919 --> 00:34:57,280
the stateful serverless programming

00:34:55,520 --> 00:35:00,640
abstraction

00:34:57,280 --> 00:35:02,000
akin to you know stateful actors um

00:35:00,640 --> 00:35:04,240
working with a stream processor in the

00:35:02,000 --> 00:35:07,760
background

00:35:04,240 --> 00:35:09,040
and yeah it's an it's a fairly new

00:35:07,760 --> 00:35:11,280
project it's open

00:35:09,040 --> 00:35:12,240
for contribution if if you're um if

00:35:11,280 --> 00:35:15,440
you're interested

00:35:12,240 --> 00:35:17,200
um in it and with that out

00:35:15,440 --> 00:35:18,880
like to conclude the talk thank you very

00:35:17,200 --> 00:35:21,359
much

00:35:18,880 --> 00:35:22,480
so just imagine a virtual room full of

00:35:21,359 --> 00:35:24,079
people clapping

00:35:22,480 --> 00:35:26,240
and they're out there clapping so thank

00:35:24,079 --> 00:35:28,320
you for your talk uh

00:35:26,240 --> 00:35:29,599
we don't have any questions in the slack

00:35:28,320 --> 00:35:31,599
channel right now

00:35:29,599 --> 00:35:32,720
uh i would remind people to join the

00:35:31,599 --> 00:35:35,440
breakout

00:35:32,720 --> 00:35:36,640
group great breakout room in jitsi uh

00:35:35,440 --> 00:35:39,200
which you will be in

00:35:36,640 --> 00:35:40,480
after this um i have one really quick

00:35:39,200 --> 00:35:41,040
question because we're really out of

00:35:40,480 --> 00:35:42,839
time

00:35:41,040 --> 00:35:45,520
what do you think are the ideal use

00:35:42,839 --> 00:35:46,880
cases so compared to compared to

00:35:45,520 --> 00:35:49,280
what you showed and what other people

00:35:46,880 --> 00:35:50,160
might use what do you find is like the

00:35:49,280 --> 00:35:54,000
real

00:35:50,160 --> 00:35:55,119
yeah um let me try and give a very short

00:35:54,000 --> 00:35:56,960
answer to this there's

00:35:55,119 --> 00:35:58,560
there's a lot to it i think actually

00:35:56,960 --> 00:36:01,200
something like i showed in this demo

00:35:58,560 --> 00:36:02,960
like distributed um like doing

00:36:01,200 --> 00:36:05,040
distributed feature vectors

00:36:02,960 --> 00:36:06,880
um for for machine learning classifiers

00:36:05,040 --> 00:36:08,400
is actually very a very good fit

00:36:06,880 --> 00:36:10,240
for this type of applications another

00:36:08,400 --> 00:36:12,160
one is actually um

00:36:10,240 --> 00:36:13,760
like maintaining distributed um

00:36:12,160 --> 00:36:16,560
statistics and aggregates for

00:36:13,760 --> 00:36:18,320
um for iot or so use cases where you

00:36:16,560 --> 00:36:20,079
have lots of decentralized sensors and

00:36:18,320 --> 00:36:21,839
what you want to keep is

00:36:20,079 --> 00:36:23,119
an overview of you know what are the

00:36:21,839 --> 00:36:24,800
individual um

00:36:23,119 --> 00:36:26,400
what is happening in certain areas in

00:36:24,800 --> 00:36:28,000
certain regions and

00:36:26,400 --> 00:36:29,359
you have for example the sensors have

00:36:28,000 --> 00:36:29,920
spiky load so you're really interested

00:36:29,359 --> 00:36:32,800
in this

00:36:29,920 --> 00:36:33,599
um very elastic system um we've actually

00:36:32,800 --> 00:36:35,680
played around with

00:36:33,599 --> 00:36:37,119
a bunch of use cases we've actually even

00:36:35,680 --> 00:36:39,119
like prototyped a small

00:36:37,119 --> 00:36:40,640
um like gaming backline for for a

00:36:39,119 --> 00:36:42,240
browser game and this and so on so

00:36:40,640 --> 00:36:43,040
there's there's tons of stuff you can do

00:36:42,240 --> 00:36:44,720
yeah

00:36:43,040 --> 00:36:46,320
um i think we're only beginning to

00:36:44,720 --> 00:36:47,599
really understand

00:36:46,320 --> 00:36:49,119
what you can do with this i would say in

00:36:47,599 --> 00:36:50,400
the long run the goal of this project is

00:36:49,119 --> 00:36:52,000
try to make

00:36:50,400 --> 00:36:54,640
pretty much everything that that you

00:36:52,000 --> 00:36:56,560
currently set up your own web server

00:36:54,640 --> 00:36:58,240
style application for make it possible

00:36:56,560 --> 00:36:59,839
to build something like that on this

00:36:58,240 --> 00:37:00,320
abstraction all right but there's a way

00:36:59,839 --> 00:37:03,920
to go

00:37:00,320 --> 00:37:03,920
look forward to it all right thanks

00:37:06,839 --> 00:37:09,839
again

00:37:22,560 --> 00:37:24,640

YouTube URL: https://www.youtube.com/watch?v=K2vgV5afUl4


