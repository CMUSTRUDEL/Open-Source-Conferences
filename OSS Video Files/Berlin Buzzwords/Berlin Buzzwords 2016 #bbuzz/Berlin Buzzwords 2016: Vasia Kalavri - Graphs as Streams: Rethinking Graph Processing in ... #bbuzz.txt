Title: Berlin Buzzwords 2016: Vasia Kalavri - Graphs as Streams: Rethinking Graph Processing in ... #bbuzz
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Vasia Kalavri talking about "Graphs as Streams: Rethinking Graph Processing in the Streaming Era".

Streaming is the latest hot topic in the big data world. We want to process data immediately and continuously. Modern stream processors have matured significantly and offer exceptional features, including sub-second latencies, high throughput, fault-tolerance, and seamless integration with various data sources and sinks.

Many sources of streaming data consist of related or connected events: user interactions in a social network, web page clicks, movie ratings, product purchases. These connected events can be naturally represented as edges in an evolving graph.

In this talk I will explain how we can leverage a powerful stream processor, such as Apache Flink, and academic research of the past two decades, to build graph streaming applications. I will describe how we can model graphs as streams and how we can compute graph properties without storing and managing the graph state. 

I will introduce useful graph summary data structures and show how they allow us to build graph algorithms in the streaming model, such as connected components, bipartiteness detection, and distance estimation.

Read more:
https://2016.berlinbuzzwords.de/session/graphs-streams-rethinking-graph-processing-streaming-era

About Vasia Kalavri:
https://2016.berlinbuzzwords.de/users/vasia-kalavri

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,689 --> 00:00:09,719
thank you hello everyone thank you very

00:00:07,020 --> 00:00:11,880
much for coming to my talk I'm very

00:00:09,719 --> 00:00:13,559
excited to talk to you today about my

00:00:11,880 --> 00:00:16,740
favorite topic which is graphs and

00:00:13,559 --> 00:00:20,100
apparently Berlin buzzwords very topic

00:00:16,740 --> 00:00:22,170
with these streams so yeah stream all

00:00:20,100 --> 00:00:24,900
the things all this conference is about

00:00:22,170 --> 00:00:27,449
streaming if you look at the accepted

00:00:24,900 --> 00:00:30,570
talks at least 10 of them have the word

00:00:27,449 --> 00:00:33,480
stream or streaming in their titles and

00:00:30,570 --> 00:00:35,969
I don't think that's a coincidence we

00:00:33,480 --> 00:00:39,239
have very good streaming technology out

00:00:35,969 --> 00:00:41,790
there we can do amazing things we have

00:00:39,239 --> 00:00:44,520
very low latency we have systems that

00:00:41,790 --> 00:00:47,180
gives us very high throughput good fault

00:00:44,520 --> 00:00:50,430
tolerance guarantee is very nice api's

00:00:47,180 --> 00:00:53,850
the whole ecosystem is thriving really

00:00:50,430 --> 00:00:58,170
and not only we have these good systems

00:00:53,850 --> 00:01:01,469
but also users are very good at shifting

00:00:58,170 --> 00:01:02,940
their mindset very fast from a bad way

00:01:01,469 --> 00:01:05,610
of thinking to a streaming way of

00:01:02,940 --> 00:01:08,460
thinking so we can already do more than

00:01:05,610 --> 00:01:11,280
just counting words we can already do

00:01:08,460 --> 00:01:14,400
complex deven event processing we can

00:01:11,280 --> 00:01:16,560
already do online machine learning we

00:01:14,400 --> 00:01:20,820
can even do streaming sequel I mean this

00:01:16,560 --> 00:01:22,830
is a very exciting time um but what I

00:01:20,820 --> 00:01:25,080
want to share with you today is my

00:01:22,830 --> 00:01:28,560
thoughts on why even though we can do

00:01:25,080 --> 00:01:30,960
all of this amazing stuff why are we

00:01:28,560 --> 00:01:34,829
still stuck in the past when it comes to

00:01:30,960 --> 00:01:37,530
graph processing what about graph

00:01:34,829 --> 00:01:40,530
processing graphs are very dynamic all

00:01:37,530 --> 00:01:44,130
of the applications we have social

00:01:40,530 --> 00:01:46,320
networks purchases ratings everything is

00:01:44,130 --> 00:01:49,740
things events that happen in real time

00:01:46,320 --> 00:01:56,250
however we don't have any libraries for

00:01:49,740 --> 00:01:57,990
graph streaming right why is that um so

00:01:56,250 --> 00:02:00,780
far we've been doing graph processing in

00:01:57,990 --> 00:02:03,689
a very specific way we usually have a

00:02:00,780 --> 00:02:05,850
graph stored in disk we bring it into

00:02:03,689 --> 00:02:08,670
memory we load it into several machines

00:02:05,850 --> 00:02:11,099
like probably partitioned then we do

00:02:08,670 --> 00:02:12,959
some processing we compute and change

00:02:11,099 --> 00:02:13,720
the graph structure or the values of the

00:02:12,959 --> 00:02:16,360
vertices

00:02:13,720 --> 00:02:18,730
and then after the processing is done we

00:02:16,360 --> 00:02:21,490
go back and store it to disk and read

00:02:18,730 --> 00:02:26,650
the result this is this is the way we do

00:02:21,490 --> 00:02:29,050
graph processing today well if all you

00:02:26,650 --> 00:02:31,150
need is to analyze a static graph over

00:02:29,050 --> 00:02:34,210
and over again this model is great right

00:02:31,150 --> 00:02:35,800
I have no problem with that but if you

00:02:34,210 --> 00:02:39,010
want to do something more interesting

00:02:35,800 --> 00:02:42,220
like for example see how PageRank

00:02:39,010 --> 00:02:45,760
changes when your graph changes or how

00:02:42,220 --> 00:02:48,700
your graph might be disconnected if you

00:02:45,760 --> 00:02:51,010
know a user deletes their account or

00:02:48,700 --> 00:02:53,050
something like that then with this model

00:02:51,010 --> 00:02:56,410
that we have today we have to read you

00:02:53,050 --> 00:02:59,620
to redo the whole computation so what we

00:02:56,410 --> 00:03:01,300
have today is slow you have to wait for

00:02:59,620 --> 00:03:04,090
the whole processing to finish before

00:03:01,300 --> 00:03:07,120
you can see any result it's expensive

00:03:04,090 --> 00:03:10,740
because we have to do partitioning and

00:03:07,120 --> 00:03:12,730
you have to replicate in probably to

00:03:10,740 --> 00:03:16,480
minimize the communication between

00:03:12,730 --> 00:03:19,959
machines it has been shown that is many

00:03:16,480 --> 00:03:22,090
times much more expensive and resource

00:03:19,959 --> 00:03:25,959
hungry than if you would run the same

00:03:22,090 --> 00:03:27,700
thing on a laptop and well if your graph

00:03:25,959 --> 00:03:30,550
changes we have to recompute everything

00:03:27,700 --> 00:03:36,670
so this is a very very bad model for

00:03:30,550 --> 00:03:38,709
dynamic graphs m and of course grab

00:03:36,670 --> 00:03:41,980
streaming is not it's not an easy thing

00:03:38,709 --> 00:03:45,010
that's why we don't have anything yet so

00:03:41,980 --> 00:03:47,470
there are many challenges that don't

00:03:45,010 --> 00:03:50,680
appear in other areas of streaming

00:03:47,470 --> 00:03:53,470
applications first we have to maintain

00:03:50,680 --> 00:03:56,110
somehow this graph structure because in

00:03:53,470 --> 00:03:58,510
the core of graph applications are the

00:03:56,110 --> 00:04:00,850
graphs themselves we need to know what

00:03:58,510 --> 00:04:02,980
are the neighbors of its vertex we need

00:04:00,850 --> 00:04:05,350
to know the path we need to traverse the

00:04:02,980 --> 00:04:07,470
graph right so we need to somehow

00:04:05,350 --> 00:04:11,260
efficiently maintain this structure

00:04:07,470 --> 00:04:14,140
somewhere then we need to maintain

00:04:11,260 --> 00:04:16,720
up-to-date results when when they input

00:04:14,140 --> 00:04:18,790
changes and we need to compute on on

00:04:16,720 --> 00:04:21,190
fresh state only so in streaming

00:04:18,790 --> 00:04:25,330
applications usually we are interested

00:04:21,190 --> 00:04:27,270
in the in the latest state so how do we

00:04:25,330 --> 00:04:31,259
maintain this dynamic

00:04:27,270 --> 00:04:33,620
graph in memory at all times so we can

00:04:31,259 --> 00:04:36,000
compute our streaming applications well

00:04:33,620 --> 00:04:38,220
what if I told you you don't need to

00:04:36,000 --> 00:04:40,620
store the graph to analyze a graph you

00:04:38,220 --> 00:04:45,000
don't need the structure of the graph to

00:04:40,620 --> 00:04:46,860
get useful metrics from a graph right

00:04:45,000 --> 00:04:50,370
this is this is different from what

00:04:46,860 --> 00:04:53,009
we've doing so far but it's possible and

00:04:50,370 --> 00:04:55,699
it's not a new idea it's something that

00:04:53,009 --> 00:04:59,400
was actually introduced 20 years ago or

00:04:55,699 --> 00:05:03,050
even earlier in a quite different

00:04:59,400 --> 00:05:06,780
context so grab streaming is a concept

00:05:03,050 --> 00:05:08,310
developed in academia to solve a quite

00:05:06,780 --> 00:05:10,169
different problem from what we have

00:05:08,310 --> 00:05:13,199
today but I think we can learn something

00:05:10,169 --> 00:05:15,479
from it so the problem they were trying

00:05:13,199 --> 00:05:17,130
to solve then was that we have a very

00:05:15,479 --> 00:05:20,639
big graph that does not fit in our

00:05:17,130 --> 00:05:22,650
limited memory it does fit in disk but

00:05:20,639 --> 00:05:26,129
we can probably stream it through memory

00:05:22,650 --> 00:05:28,919
may be several times not too many only

00:05:26,129 --> 00:05:31,919
few passes we allow and then try to

00:05:28,919 --> 00:05:36,630
compute something over this this stream

00:05:31,919 --> 00:05:39,750
and give result so am a core component

00:05:36,630 --> 00:05:43,080
of this model is graph summaries the

00:05:39,750 --> 00:05:45,509
idea here is that if you have a huge

00:05:43,080 --> 00:05:47,580
graph and you have an algorithm that you

00:05:45,509 --> 00:05:50,909
need to run on this graph to get some

00:05:47,580 --> 00:05:53,099
result and if you if you stream it

00:05:50,909 --> 00:05:55,349
through memory maybe you can keep part

00:05:53,099 --> 00:05:57,539
of it like a summary of it some compact

00:05:55,349 --> 00:05:59,759
representation that will will fit in

00:05:57,539 --> 00:06:02,370
your limited memory maybe since your

00:05:59,759 --> 00:06:04,650
algorithm and a bit and then get the

00:06:02,370 --> 00:06:06,389
same or a similar result to what you

00:06:04,650 --> 00:06:08,810
would get if you would run your

00:06:06,389 --> 00:06:13,199
algorithm on there on the big graph and

00:06:08,810 --> 00:06:16,860
some examples of these summaries are

00:06:13,199 --> 00:06:20,759
Spanish for computing if the if a graph

00:06:16,860 --> 00:06:24,419
is connected and to compute distances

00:06:20,759 --> 00:06:26,880
between any two vertices specifiers is

00:06:24,419 --> 00:06:29,190
another summary to estimate cuts in the

00:06:26,880 --> 00:06:31,259
graph you we have neighborhood sketches

00:06:29,190 --> 00:06:33,169
and all other kinds of things that have

00:06:31,259 --> 00:06:35,789
been developed over the years

00:06:33,169 --> 00:06:37,469
unfortunately I don't have time to give

00:06:35,789 --> 00:06:40,080
you examples for all of this since this

00:06:37,469 --> 00:06:41,040
is a short slot but I will give you an

00:06:40,080 --> 00:06:45,240
example of

00:06:41,040 --> 00:06:47,730
simple summary and in the word count of

00:06:45,240 --> 00:06:52,410
graph processing so are you familiar

00:06:47,730 --> 00:06:55,050
with connected components yes okay some

00:06:52,410 --> 00:06:57,150
of you so okay the problem is the

00:06:55,050 --> 00:07:01,050
following we have a graph and we want to

00:06:57,150 --> 00:07:02,370
compute the connected components of the

00:07:01,050 --> 00:07:05,940
graph the connect a connected component

00:07:02,370 --> 00:07:08,550
is a sub graph of the original graph

00:07:05,940 --> 00:07:10,830
where there is a path between any two

00:07:08,550 --> 00:07:13,020
vertices so for example here this is a

00:07:10,830 --> 00:07:15,150
connected component by component because

00:07:13,020 --> 00:07:17,390
you can go from any vertex to any other

00:07:15,150 --> 00:07:20,850
vertex and that's a different one right

00:07:17,390 --> 00:07:24,540
so the way we do this in a bad way is

00:07:20,850 --> 00:07:27,240
that we assign a label to its vertex and

00:07:24,540 --> 00:07:30,000
then we iterate over the graph and in

00:07:27,240 --> 00:07:32,100
every iteration a vertex sends messages

00:07:30,000 --> 00:07:34,770
to its neighbors and says this is my

00:07:32,100 --> 00:07:38,160
label and then when a vertex receives

00:07:34,770 --> 00:07:41,100
the messages it picks the minimum one so

00:07:38,160 --> 00:07:43,470
after a few iterations the labels

00:07:41,100 --> 00:07:46,200
propagate in the component and in the

00:07:43,470 --> 00:07:48,000
end they will all the vertices belonging

00:07:46,200 --> 00:07:52,320
to the same component will have the same

00:07:48,000 --> 00:07:55,110
label so for example these messages will

00:07:52,320 --> 00:07:57,150
go around in iteration zero in iteration

00:07:55,110 --> 00:08:00,300
1 some of the vertices will change their

00:07:57,150 --> 00:08:03,060
values again we send around messages and

00:08:00,300 --> 00:08:04,650
so on we continue until all the word

00:08:03,060 --> 00:08:07,290
this is inside the same component have

00:08:04,650 --> 00:08:12,210
the same label right this is how we do

00:08:07,290 --> 00:08:14,670
it in a batch way now what if i told you

00:08:12,210 --> 00:08:18,120
that we can do this without iterations

00:08:14,670 --> 00:08:20,490
and without ever storing the graph in

00:08:18,120 --> 00:08:23,060
memory we don't need to know who's

00:08:20,490 --> 00:08:26,310
neighbor with whom we only need to keep

00:08:23,060 --> 00:08:29,250
the right graph summary in this case at

00:08:26,310 --> 00:08:32,220
this joint set or union find if you if

00:08:29,250 --> 00:08:34,410
you want and we only need to store the

00:08:32,220 --> 00:08:36,419
component IDs and what vertices belong

00:08:34,410 --> 00:08:38,849
in that component we don't need to store

00:08:36,419 --> 00:08:41,729
the whole graph the edges and everything

00:08:38,849 --> 00:08:44,340
else so let's see how this would work we

00:08:41,729 --> 00:08:47,190
have a stream of edges coming we get the

00:08:44,340 --> 00:08:49,020
first edge 13 we haven't seen it before

00:08:47,190 --> 00:08:53,670
so we create a new component with these

00:08:49,020 --> 00:08:54,350
two vertices inside the component we get

00:08:53,670 --> 00:08:57,380
the second

00:08:54,350 --> 00:09:00,620
25 we it doesn't exist in an existing

00:08:57,380 --> 00:09:03,350
component so we create a new one and we

00:09:00,620 --> 00:09:07,790
always Tuesday ID the minimum of the

00:09:03,350 --> 00:09:10,190
vertices inside the component for 55

00:09:07,790 --> 00:09:14,420
exists already in component 2 so we just

00:09:10,190 --> 00:09:17,420
add 4 over there 67 we check our

00:09:14,420 --> 00:09:21,080
existing components nothing is there so

00:09:17,420 --> 00:09:24,800
we create a new one 68 will put eight in

00:09:21,080 --> 00:09:26,690
the component 624 does nothing because

00:09:24,800 --> 00:09:31,250
we already have this information so we

00:09:26,690 --> 00:09:33,680
can throw the edge away 343 belongs to

00:09:31,250 --> 00:09:35,720
component 1 and 4 belongs to component 2

00:09:33,680 --> 00:09:38,450
so we now know that there is an edge

00:09:35,720 --> 00:09:41,000
between some vertices in these two and

00:09:38,450 --> 00:09:43,880
we can merge these two components into

00:09:41,000 --> 00:09:47,630
one picking again the minimum component

00:09:43,880 --> 00:09:49,940
ID and we continue like this right

00:09:47,630 --> 00:09:52,190
without needing to to store the graph

00:09:49,940 --> 00:09:54,650
ever and of course we can do this in a

00:09:52,190 --> 00:09:57,620
distributed way as well so we can have

00:09:54,650 --> 00:09:59,480
several streams going to different

00:09:57,620 --> 00:10:02,930
partitions or different different nodes

00:09:59,480 --> 00:10:05,900
nodes computing local summaries and then

00:10:02,930 --> 00:10:11,150
periodically merge into a single stream

00:10:05,900 --> 00:10:12,980
where we get our result so that's an

00:10:11,150 --> 00:10:15,110
algorithm that was developed really long

00:10:12,980 --> 00:10:18,860
ago but we somehow forgot about it and

00:10:15,110 --> 00:10:21,620
we started doing it the bath way the bad

00:10:18,860 --> 00:10:24,890
news about all this research 20 years

00:10:21,620 --> 00:10:26,630
ago is that it had a slightly different

00:10:24,890 --> 00:10:29,090
motivation that what we really need

00:10:26,630 --> 00:10:33,020
today so the problem they were trying to

00:10:29,090 --> 00:10:34,880
solve was assuming an a bounded graph it

00:10:33,020 --> 00:10:37,850
was assuming that we have a graph it's

00:10:34,880 --> 00:10:39,770
too big but it's not endless like the

00:10:37,850 --> 00:10:42,040
streams resume today so what we need

00:10:39,770 --> 00:10:44,390
today is a bit different in a sense that

00:10:42,040 --> 00:10:46,790
we want to continuously process

00:10:44,390 --> 00:10:50,890
something continuously changing probably

00:10:46,790 --> 00:10:53,630
forever the second problem is that since

00:10:50,890 --> 00:10:58,370
this research assumes that the graph is

00:10:53,630 --> 00:11:00,110
bounded some of the algorithms developed

00:10:58,370 --> 00:11:03,260
assume that we know the number of

00:11:00,110 --> 00:11:05,030
vertices or the number of edges and the

00:11:03,260 --> 00:11:07,670
last problem is that most of these

00:11:05,030 --> 00:11:08,420
algorithms developed back then were

00:11:07,670 --> 00:11:11,839
developed for

00:11:08,420 --> 00:11:14,660
threaded execution the good news is that

00:11:11,839 --> 00:11:16,880
we live in a different reality than 220

00:11:14,660 --> 00:11:20,089
years ago so memory is getting bigger

00:11:16,880 --> 00:11:22,899
and it's getting super and we know now

00:11:20,089 --> 00:11:26,930
how to design distributed algorithms so

00:11:22,899 --> 00:11:29,180
the idea is what if we get inspired by

00:11:26,930 --> 00:11:31,100
that research and try to relax maybe the

00:11:29,180 --> 00:11:33,860
assumptions that they had maybe not

00:11:31,100 --> 00:11:37,010
create so strict summaries and try to

00:11:33,860 --> 00:11:38,810
evolve these algorithms to bring them to

00:11:37,010 --> 00:11:40,639
the setting that we have today and the

00:11:38,810 --> 00:11:43,820
needs and requirements that we have

00:11:40,639 --> 00:11:46,370
today and that's what I'm trying to do

00:11:43,820 --> 00:11:48,980
with a colleague of mine at kate's in

00:11:46,370 --> 00:11:50,600
Stockholm we have built a graph

00:11:48,980 --> 00:11:57,290
streaming prototype on top of hibachi

00:11:50,600 --> 00:11:59,209
fling called jelly stream so if you're

00:11:57,290 --> 00:12:02,959
familiar with fling if you went to any

00:11:59,209 --> 00:12:05,209
of the talks fling has two api's one for

00:12:02,959 --> 00:12:08,600
bats one for streaming so for the bats

00:12:05,209 --> 00:12:10,639
API we have a graph processing API

00:12:08,600 --> 00:12:17,420
called jelly for static graphs and

00:12:10,639 --> 00:12:20,899
iterative algorithms and all of this so

00:12:17,420 --> 00:12:23,500
what the jelly stream would be is an IP

00:12:20,899 --> 00:12:26,870
I on top of the streaming API of link

00:12:23,500 --> 00:12:30,680
for dynamic graphs single pass

00:12:26,870 --> 00:12:35,470
algorithms using summaries and probably

00:12:30,680 --> 00:12:39,380
giving you approximate computations so

00:12:35,470 --> 00:12:40,940
sorry with that so yeah the de streaming

00:12:39,380 --> 00:12:44,120
connected components that we saw before

00:12:40,940 --> 00:12:45,800
in a distributed setting we could

00:12:44,120 --> 00:12:49,070
implement it in the streaming API of

00:12:45,800 --> 00:12:52,510
link very simply like this we have an

00:12:49,070 --> 00:12:55,370
edge stream a stream of edges basically

00:12:52,510 --> 00:12:57,680
first we just partition the edge stream

00:12:55,370 --> 00:13:00,170
well here I just partition by the source

00:12:57,680 --> 00:13:02,329
ID but you could partition in a smarter

00:13:00,170 --> 00:13:05,420
way if you want to so we send different

00:13:02,329 --> 00:13:08,240
edges to different partitions and then

00:13:05,420 --> 00:13:11,120
we define every how much time do we need

00:13:08,240 --> 00:13:14,449
the merge to happen with with that time

00:13:11,120 --> 00:13:17,269
window in flink and then we need to

00:13:14,449 --> 00:13:19,220
provide how to do the merge so when you

00:13:17,269 --> 00:13:21,440
receive an edge and you have your local

00:13:19,220 --> 00:13:22,250
summary how do you merge this adds to

00:13:21,440 --> 00:13:25,070
your local some

00:13:22,250 --> 00:13:26,690
basically what i showed before that if i

00:13:25,070 --> 00:13:29,840
haven't seen the edge before you create

00:13:26,690 --> 00:13:31,550
a new component or if it connects two

00:13:29,840 --> 00:13:34,000
different ones you have to merge them so

00:13:31,550 --> 00:13:37,490
this is what the UDF they would do and

00:13:34,000 --> 00:13:40,570
then you need to define how would you

00:13:37,490 --> 00:13:45,890
merge the local states into a global

00:13:40,570 --> 00:13:47,450
state and actually with with the API we

00:13:45,890 --> 00:13:50,870
have built you don't even need to do all

00:13:47,450 --> 00:13:53,450
of this because first we have built

00:13:50,870 --> 00:13:56,150
several algorithms that you can use

00:13:53,450 --> 00:13:58,100
yourself just by calling the library

00:13:56,150 --> 00:14:00,050
method so except from connected

00:13:58,100 --> 00:14:03,560
components you can also do by partners

00:14:00,050 --> 00:14:05,930
check some triangle count estimation or

00:14:03,560 --> 00:14:09,530
window triangle count and some other

00:14:05,930 --> 00:14:13,250
continues aggregates and we also have

00:14:09,530 --> 00:14:15,920
more high-level abstractions so the at

00:14:13,250 --> 00:14:18,770
this format of them algorithm that we

00:14:15,920 --> 00:14:20,810
saw that you have local states and then

00:14:18,770 --> 00:14:23,390
you merge them periodically we have seen

00:14:20,810 --> 00:14:25,940
them in other algorithms as a pattern so

00:14:23,390 --> 00:14:31,010
we offer an abstraction to build this

00:14:25,940 --> 00:14:34,970
kind of algorithms more easily so if you

00:14:31,010 --> 00:14:37,490
liked what I presented today you feel

00:14:34,970 --> 00:14:40,910
free to check the repository this is not

00:14:37,490 --> 00:14:44,150
part of hibachi fling it's as I said an

00:14:40,910 --> 00:14:47,180
experimental API it's our vision to make

00:14:44,150 --> 00:14:49,910
people stop thinking like vertices and

00:14:47,180 --> 00:14:53,839
start thinking like I don't know in a

00:14:49,910 --> 00:14:56,300
more modern streaming way I have also

00:14:53,839 --> 00:14:58,460
collected a list of graph streaming

00:14:56,300 --> 00:14:59,740
papers if you're interested in this area

00:14:58,460 --> 00:15:02,960
and you want to see what has happened

00:14:59,740 --> 00:15:05,750
and what algorithms you can implement in

00:15:02,960 --> 00:15:07,880
this model and there is a related talk

00:15:05,750 --> 00:15:10,700
that mean my colleague gave at force

00:15:07,880 --> 00:15:12,950
them it's more it's an extensive

00:15:10,700 --> 00:15:14,750
extended version of this one it has more

00:15:12,950 --> 00:15:18,610
and more examples if you want to check

00:15:14,750 --> 00:15:18,610
it out thank you very much

00:15:20,850 --> 00:15:37,389
Thank You Axl do we have any questions

00:15:26,170 --> 00:15:39,839
please haha any more questions no now

00:15:37,389 --> 00:15:48,309
you have to ask something about graphs

00:15:39,839 --> 00:15:51,670
alright just more like a suggestion so

00:15:48,309 --> 00:15:53,949
yeah when the Hadoop started so this

00:15:51,670 --> 00:15:56,410
batch processing there was always also a

00:15:53,949 --> 00:15:58,600
lot of ideas in cloud air specifically

00:15:56,410 --> 00:16:01,209
how to handle these graph problems in

00:15:58,600 --> 00:16:03,339
the batch world and I think it like

00:16:01,209 --> 00:16:06,009
there was also this page rank how you

00:16:03,339 --> 00:16:08,980
could do paid rent in map reuse and so

00:16:06,009 --> 00:16:11,559
probably could take something from their

00:16:08,980 --> 00:16:13,449
experience in this area so yeah yeah

00:16:11,559 --> 00:16:15,369
sure I mean this is the same thing right

00:16:13,449 --> 00:16:18,999
I'm trying to use the technology we have

00:16:15,369 --> 00:16:21,040
today to bring the problems I like up to

00:16:18,999 --> 00:16:24,910
date and make use of the tools we have

00:16:21,040 --> 00:16:36,399
exactly it's the same thing sure thank

00:16:24,910 --> 00:16:38,170
you any more questions ok sure ok either

00:16:36,399 --> 00:16:44,230
you didn't get anything or you got

00:16:38,170 --> 00:16:48,100
everything oh no no more you yeah oh you

00:16:44,230 --> 00:16:53,470
don't have a question um so I have yeah

00:16:48,100 --> 00:16:55,600
yeah my tuition would tell me that if

00:16:53,470 --> 00:16:56,980
you do strewing processing of graphs you

00:16:55,600 --> 00:17:01,299
assume that the processing is a kind of

00:16:56,980 --> 00:17:03,730
linear so you mean the complexity yes

00:17:01,299 --> 00:17:06,010
yeah so what about the problems that are

00:17:03,730 --> 00:17:08,010
would data theoretically pole polynomial

00:17:06,010 --> 00:17:11,529
or exponential yes I would your

00:17:08,010 --> 00:17:14,110
streaming mode sure it's not necessarily

00:17:11,529 --> 00:17:17,470
linear processing and not all problems

00:17:14,110 --> 00:17:20,079
are possible in this model of course the

00:17:17,470 --> 00:17:21,549
idea here is more that you can change

00:17:20,079 --> 00:17:23,709
the algorithm a bit or you can

00:17:21,549 --> 00:17:26,079
approximate the result so for connected

00:17:23,709 --> 00:17:28,750
components that was an easy example what

00:17:26,079 --> 00:17:30,429
I showed and you get an exact result you

00:17:28,750 --> 00:17:33,610
get the same result as we would get with

00:17:30,429 --> 00:17:35,230
buds but other algorithms like Pedro

00:17:33,610 --> 00:17:36,940
angkor distances and these kind of

00:17:35,230 --> 00:17:39,190
things that would give you errors in the

00:17:36,940 --> 00:17:41,010
end so you don't compute the exact same

00:17:39,190 --> 00:17:43,030
thing as you would compute with batch

00:17:41,010 --> 00:17:46,390
processing but sometimes it's good

00:17:43,030 --> 00:17:47,950
enough right and and because you compute

00:17:46,390 --> 00:17:49,809
on the summary so you don't have all the

00:17:47,950 --> 00:17:54,580
information that you would have on the

00:17:49,809 --> 00:18:00,490
on the big graph sure we have time to

00:17:54,580 --> 00:18:02,500
take one more question awesome just

00:18:00,490 --> 00:18:10,179
going to be there in a jiffy ok so you

00:18:02,500 --> 00:18:12,040
were shy hi my question is do these

00:18:10,179 --> 00:18:14,140
algorithms also work if you think about

00:18:12,040 --> 00:18:16,179
removing edges or removing vertices from

00:18:14,140 --> 00:18:20,260
the graph yeah that's a very good

00:18:16,179 --> 00:18:21,760
question so exhibitions are easy most of

00:18:20,260 --> 00:18:23,320
these the algorithms that have been

00:18:21,760 --> 00:18:25,630
developed our about ed's additions but

00:18:23,320 --> 00:18:29,440
there are also algorithms for edge

00:18:25,630 --> 00:18:32,980
deletions where you usually have the

00:18:29,440 --> 00:18:35,080
original graph somehow somewhere stored

00:18:32,980 --> 00:18:36,700
and then you update the summary in real

00:18:35,080 --> 00:18:40,419
time and then you just query the summary

00:18:36,700 --> 00:18:42,580
but if this is what I meant by relaxing

00:18:40,419 --> 00:18:45,520
the assumptions that used to exist

00:18:42,580 --> 00:18:48,160
because now we don't have such limited

00:18:45,520 --> 00:18:49,960
memory or these kind of boundaries that

00:18:48,160 --> 00:18:51,880
we used to have then so you can do these

00:18:49,960 --> 00:18:54,610
things more easily than you could back

00:18:51,880 --> 00:18:57,790
then yeah but yeah there are more

00:18:54,610 --> 00:19:01,299
complex the deletions for sure but also

00:18:57,790 --> 00:19:08,710
they're more they're not so usual as the

00:19:01,299 --> 00:19:10,570
additions usually yeah last chance no

00:19:08,710 --> 00:19:15,360
that's cool ok you can always catch me

00:19:10,570 --> 00:19:15,360
up later thank you thank you so much

00:19:16,350 --> 00:19:18,410

YouTube URL: https://www.youtube.com/watch?v=0W-fB0-nGjE


