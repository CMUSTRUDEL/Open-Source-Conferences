Title: Berlin Buzzwords 2016: Shalin Shekhar Mangar - Parallel SQL & Streaming Expressions in Apache Solr 6
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Apache Solr is a powerful search and analytics engine with features such as full-text search, faceting, joins, sorting and capable of handling large amounts of data across a large number of servers. However, with all that power and scalability comes complexity. 

Solr 6 supports a Parallel SQL feature which provides a simplified, well-known interface to your data in Solr, performs key operations such as sorts and shuffling inside Solr for massive speedups, provides best-practices based query optimization and by leveraging the scalability of SolrCloud and a clever implementation, allows you to throw massive amounts of computation power behind analytical queries.

In this talk, we will explore the why, what and how of Parallel SQL and its building block Streaming Expressions in Solr 6 with a hint of the exciting new developments around this feature.

This is a talk sponsored by LucidWorks.

Read more:
https://2016.berlinbuzzwords.de/session/parallel-sql-and-streaming-expressions-apache-solr-6

About Shalin Shekhar Mangar:
https://2016.berlinbuzzwords.de/users/shalin-shekhar-mangar

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,480 --> 00:00:08,639
cool so thank you guys for coming my

00:00:05,730 --> 00:00:10,620
name is Shallon shakin monger I work at

00:00:08,639 --> 00:00:14,070
lucid works and one of the commuters on

00:00:10,620 --> 00:00:15,960
apache Lucene solar and a PMC member i

00:00:14,070 --> 00:00:18,240
have been working with lucid works for

00:00:15,960 --> 00:00:20,730
the past three years mostly full time on

00:00:18,240 --> 00:00:23,039
solar before that I've worked at a will

00:00:20,730 --> 00:00:25,500
where I vogue Donna and a few very large

00:00:23,039 --> 00:00:30,300
scale solar deployments specifically the

00:00:25,500 --> 00:00:31,710
one for AOL webmail so I'm sure a lot of

00:00:30,300 --> 00:00:34,020
you are already familiar with solar

00:00:31,710 --> 00:00:36,660
solar is the enterprise standard for

00:00:34,020 --> 00:00:38,040
search we have a lot of watching finite

00:00:36,660 --> 00:00:40,379
companies who use solar from day to day

00:00:38,040 --> 00:00:41,760
in fact most likely you already use

00:00:40,379 --> 00:00:43,860
solar even if you don't use it directly

00:00:41,760 --> 00:00:45,660
because you consume it through some

00:00:43,860 --> 00:00:49,110
service or some company which internally

00:00:45,660 --> 00:00:51,989
uses it it's a full-text search engine

00:00:49,110 --> 00:00:54,270
you basically send in documents and you

00:00:51,989 --> 00:00:57,780
send in full text queries you can also

00:00:54,270 --> 00:01:01,379
facet into facets sorry sergeant sticks

00:00:57,780 --> 00:01:02,820
and aggregations on top of that data you

00:01:01,379 --> 00:01:04,470
have language detection it's a

00:01:02,820 --> 00:01:06,960
completely modular system so you can

00:01:04,470 --> 00:01:10,170
plug in almost anything and in fact most

00:01:06,960 --> 00:01:12,510
expert users do plug in things like

00:01:10,170 --> 00:01:17,490
query parsers or ranking and things like

00:01:12,510 --> 00:01:20,759
that part of solar is what we call as

00:01:17,490 --> 00:01:22,619
solar cloud which is the system that you

00:01:20,759 --> 00:01:26,520
deploy on a large number of nodes and

00:01:22,619 --> 00:01:28,200
which allows you to scale you can add

00:01:26,520 --> 00:01:32,430
nodes you can split charge you can

00:01:28,200 --> 00:01:34,110
replicate etc etc we are specifically

00:01:32,430 --> 00:01:36,689
going to talk about a new feature which

00:01:34,110 --> 00:01:40,380
was introduced in solar 6 that is

00:01:36,689 --> 00:01:43,409
parallel SQL and actually parallel SQL

00:01:40,380 --> 00:01:46,040
is just one part of that feature because

00:01:43,409 --> 00:01:49,110
there is a whole building block of

00:01:46,040 --> 00:01:51,780
streaming transformations and streaming

00:01:49,110 --> 00:01:54,000
expressions on which the panel SQL stuff

00:01:51,780 --> 00:01:55,920
is built on so what we are going to do

00:01:54,000 --> 00:01:57,659
in this presentation is we are going to

00:01:55,920 --> 00:01:59,880
start from the parallel scale stuff

00:01:57,659 --> 00:02:02,310
because that's the most easiest to

00:01:59,880 --> 00:02:04,799
understand and then I'm going to tell

00:02:02,310 --> 00:02:06,540
you how to use it with solar the already

00:02:04,799 --> 00:02:08,670
leased versions and then we are going to

00:02:06,540 --> 00:02:10,679
dive it into the internals of this and

00:02:08,670 --> 00:02:13,100
we're going to see how it is internally

00:02:10,679 --> 00:02:16,280
implemented and what it is capable of

00:02:13,100 --> 00:02:18,830
okay so the first question is why

00:02:16,280 --> 00:02:21,470
implement SQL in solar why now like so

00:02:18,830 --> 00:02:24,020
let's been around for a long time so I

00:02:21,470 --> 00:02:26,840
think the reason mainly is ease of use

00:02:24,020 --> 00:02:28,850
because solar is it so you know it's

00:02:26,840 --> 00:02:32,120
it's very powerful but it's also quite

00:02:28,850 --> 00:02:33,890
complex so with SQL you basically have

00:02:32,120 --> 00:02:35,720
an easy way to carry the system which is

00:02:33,890 --> 00:02:37,700
very very well-known there is a whole

00:02:35,720 --> 00:02:41,450
lot of tooling available which can work

00:02:37,700 --> 00:02:45,620
with a with a system that exposes a JDBC

00:02:41,450 --> 00:02:48,050
endpoint right the other thing is if you

00:02:45,620 --> 00:02:50,930
have a system which speaks SQL then

00:02:48,050 --> 00:02:53,450
internally we can compile it and we can

00:02:50,930 --> 00:02:55,820
execute that query according to the most

00:02:53,450 --> 00:02:57,410
efficient way possible so there's a lot

00:02:55,820 --> 00:02:58,730
of work being done that area I don't

00:02:57,410 --> 00:03:02,000
think they're quite there yet we don't

00:02:58,730 --> 00:03:04,400
do a whole lot of automatic optimization

00:03:02,000 --> 00:03:07,610
right now but we have the possibility to

00:03:04,400 --> 00:03:10,670
do that so the political stuff is very

00:03:07,610 --> 00:03:12,710
very new it was just released in 6.0 the

00:03:10,670 --> 00:03:14,660
first point release of it was made

00:03:12,710 --> 00:03:16,970
actually a week back six point zero

00:03:14,660 --> 00:03:19,850
point one which fixes a few more bugs in

00:03:16,970 --> 00:03:21,980
it so it's a little bit rough around the

00:03:19,850 --> 00:03:24,740
edges because it's still under active

00:03:21,980 --> 00:03:27,230
development but it the whole thing

00:03:24,740 --> 00:03:29,570
actually is quite powerful and it has

00:03:27,230 --> 00:03:33,920
uses beyond SQL as well which we are

00:03:29,570 --> 00:03:36,380
going to see at the end of the slides so

00:03:33,920 --> 00:03:38,660
what is parallel skill first of all why

00:03:36,380 --> 00:03:41,360
why do I call it parallel SQL and not

00:03:38,660 --> 00:03:43,580
just SQL the reason is that any query

00:03:41,360 --> 00:03:45,770
that you make first of all it's it's a

00:03:43,580 --> 00:03:47,300
solar cloud only feature so it only

00:03:45,770 --> 00:03:49,370
works with solar cloud if you're using

00:03:47,300 --> 00:03:52,070
the old style master-slave replication

00:03:49,370 --> 00:03:54,740
you know you can't use SQL in that it

00:03:52,070 --> 00:03:56,360
has to be select loud so when you

00:03:54,740 --> 00:03:59,450
execute a query on solar cloud it can

00:03:56,360 --> 00:04:01,790
actually go to each replica of each

00:03:59,450 --> 00:04:04,130
shard ask for a subset of data and

00:04:01,790 --> 00:04:05,600
operate on that data moyes the results

00:04:04,130 --> 00:04:09,500
and give it back to you so it all

00:04:05,600 --> 00:04:11,570
happens in parallel so this is not there

00:04:09,500 --> 00:04:13,520
are many systems which which do things

00:04:11,570 --> 00:04:16,040
like that for example hive and Impala

00:04:13,520 --> 00:04:19,090
and all these systems speak SQL but they

00:04:16,040 --> 00:04:21,470
are mostly made for you know

00:04:19,090 --> 00:04:25,160
long-running analytical workloads on

00:04:21,470 --> 00:04:26,840
extremely large amounts of data and on

00:04:25,160 --> 00:04:29,240
raw data which is not pre pro

00:04:26,840 --> 00:04:31,100
just like you know indexed in a in a

00:04:29,240 --> 00:04:34,010
search engine so what's happening here

00:04:31,100 --> 00:04:35,510
is we can use the best parts of the

00:04:34,010 --> 00:04:38,120
search engine to do certain things which

00:04:35,510 --> 00:04:40,310
are most easily done inside the search

00:04:38,120 --> 00:04:42,229
engine and then we can do that the

00:04:40,310 --> 00:04:43,460
intensive parts the ones for example the

00:04:42,229 --> 00:04:45,889
joints involved which are not done very

00:04:43,460 --> 00:04:47,600
well by search engines externally inside

00:04:45,889 --> 00:04:51,860
a worker collection and we're going to

00:04:47,600 --> 00:04:53,600
cover that in a bit so the SQL is

00:04:51,860 --> 00:04:56,479
parallely executed across solar cloud

00:04:53,600 --> 00:04:58,400
instances it is compiled internally to

00:04:56,479 --> 00:05:03,740
what we call streaming expressions and

00:04:58,400 --> 00:05:06,200
the streaming io API in in when you

00:05:03,740 --> 00:05:08,060
write this SQL the the solar cloud

00:05:06,200 --> 00:05:10,639
collection that you already have is what

00:05:08,060 --> 00:05:12,919
is the table so if you say select star

00:05:10,639 --> 00:05:14,540
from collection one or select star from

00:05:12,919 --> 00:05:16,580
collection 2 or whatever your collection

00:05:14,540 --> 00:05:19,010
name is right so each collection is

00:05:16,580 --> 00:05:22,910
automatically exposed as a table in this

00:05:19,010 --> 00:05:25,760
SQL and the soul eject line the Java

00:05:22,910 --> 00:05:28,430
client that we have already ships with a

00:05:25,760 --> 00:05:30,050
thin jdbc client it's not completely

00:05:28,430 --> 00:05:31,789
full-featured jaidev's a client because

00:05:30,050 --> 00:05:34,400
there are lots of things inside jdbc

00:05:31,789 --> 00:05:36,590
which we don't implement and for that

00:05:34,400 --> 00:05:38,210
reason them you might find a few tools

00:05:36,590 --> 00:05:40,039
which refuse to work with solar right

00:05:38,210 --> 00:05:42,380
now because they might require some

00:05:40,039 --> 00:05:45,020
capabilities which we do not expose so

00:05:42,380 --> 00:05:48,169
what is happening is people are using

00:05:45,020 --> 00:05:50,030
one or a few tools as the reference and

00:05:48,169 --> 00:05:51,950
trying to ensure that we are compatible

00:05:50,030 --> 00:05:54,260
with them and you will probably see that

00:05:51,950 --> 00:05:57,530
list of tools being expanded as this

00:05:54,260 --> 00:05:59,270
feature becomes more and more mature so

00:05:57,530 --> 00:06:01,520
the first one that is being used is the

00:05:59,270 --> 00:06:03,860
DB visualizer and there are a few folks

00:06:01,520 --> 00:06:05,979
who are working to ensure that apache

00:06:03,860 --> 00:06:08,450
zeppelin which is a visualization tool

00:06:05,979 --> 00:06:10,669
basically a notebook style visualization

00:06:08,450 --> 00:06:14,180
tool that also works with the solar JDBC

00:06:10,669 --> 00:06:19,400
driver so let's dive into the SQL

00:06:14,180 --> 00:06:21,889
interface of solar there are two ways in

00:06:19,400 --> 00:06:24,169
which the SQL is executed inside solar

00:06:21,889 --> 00:06:26,780
cloud so as I said there are there is

00:06:24,169 --> 00:06:28,610
probably work which is going to happen

00:06:26,780 --> 00:06:30,710
which will make some of these decisions

00:06:28,610 --> 00:06:32,780
automatically for you in the future but

00:06:30,710 --> 00:06:35,390
right now you have to consciously choose

00:06:32,780 --> 00:06:37,460
between two different implementations

00:06:35,390 --> 00:06:38,599
depending on the kind of data and the

00:06:37,460 --> 00:06:40,620
kind of queries that you're gonna make

00:06:38,599 --> 00:06:43,380
the first one is what we call it

00:06:40,620 --> 00:06:46,410
SQL / BAP reduce and the second one is

00:06:43,380 --> 00:06:48,780
SQL / facets in the first one what is

00:06:46,410 --> 00:06:50,910
happening is the first one is basically

00:06:48,780 --> 00:06:52,860
suited for when you have a very high

00:06:50,910 --> 00:06:54,570
cardinality and you want to do

00:06:52,860 --> 00:06:56,220
aggregations you want to do counts or

00:06:54,570 --> 00:06:58,620
some or min or max or things like that

00:06:56,220 --> 00:07:01,760
on top of it in the second one you have

00:06:58,620 --> 00:07:07,350
SQL / facets in which all this

00:07:01,760 --> 00:07:09,900
aggregation and all this unique the keys

00:07:07,350 --> 00:07:11,910
are actually computed inside a single

00:07:09,900 --> 00:07:14,130
solar instance so you if you are already

00:07:11,910 --> 00:07:16,650
familiar with facets what are facets you

00:07:14,130 --> 00:07:19,560
get the top terms for a given field

00:07:16,650 --> 00:07:21,389
sorted by some count right so in a way

00:07:19,560 --> 00:07:23,520
you are d duplicating them and operating

00:07:21,389 --> 00:07:26,520
on that data so if you're doing SQ lower

00:07:23,520 --> 00:07:28,830
facets then it is using facets to get

00:07:26,520 --> 00:07:31,350
that topped and list and then operating

00:07:28,830 --> 00:07:33,419
on top of that okay so in that way it is

00:07:31,350 --> 00:07:36,360
actually pretty fast but that doesn't

00:07:33,419 --> 00:07:38,160
work well if you have to get all the

00:07:36,360 --> 00:07:40,410
facets all the top terms out of the

00:07:38,160 --> 00:07:42,539
index because that will you know blow up

00:07:40,410 --> 00:07:43,620
the memory in when you want to do

00:07:42,539 --> 00:07:46,229
something like that it's prolly better

00:07:43,620 --> 00:07:50,190
to switch to SQL or MapReduce and not do

00:07:46,229 --> 00:07:52,410
a scale over facets the SQL where clause

00:07:50,190 --> 00:07:54,419
is basically a solar query so you can do

00:07:52,410 --> 00:07:56,669
range queries you can do you know face

00:07:54,419 --> 00:07:58,680
queries whatever is possible with solar

00:07:56,669 --> 00:08:02,610
that same kind of query you can actually

00:07:58,680 --> 00:08:05,610
put inside the very laws there is also

00:08:02,610 --> 00:08:08,760
an HTTP endpoint so you can make a query

00:08:05,610 --> 00:08:12,330
to slash SQL and we'll see an example

00:08:08,760 --> 00:08:14,849
here this is probably a good example so

00:08:12,330 --> 00:08:18,270
in this case what we have is we have a

00:08:14,849 --> 00:08:19,229
collection which has the end wrong data

00:08:18,270 --> 00:08:21,570
set if you're familiar with that

00:08:19,229 --> 00:08:24,060
basically the company and draw until

00:08:21,570 --> 00:08:25,710
there was a huge email set which was

00:08:24,060 --> 00:08:27,510
leaked out of it so each document here

00:08:25,710 --> 00:08:31,560
is an email and what we are doing is we

00:08:27,510 --> 00:08:33,900
are saying from this end on data set I

00:08:31,560 --> 00:08:36,719
want to find the emails to which the

00:08:33,900 --> 00:08:38,370
most emails were sent okay so this is

00:08:36,719 --> 00:08:40,409
giving out a list of addresses to which

00:08:38,370 --> 00:08:42,380
the most emails were sent out so you can

00:08:40,409 --> 00:08:44,490
see we do a group by we do an order by

00:08:42,380 --> 00:08:47,040
there is no where clause but you can

00:08:44,490 --> 00:08:49,610
obviously add a at a where Clause here

00:08:47,040 --> 00:08:49,610
as well so

00:08:52,500 --> 00:08:58,260
the where Clause as i said is basically

00:08:55,590 --> 00:09:00,120
an SQL query so you can do a simple term

00:08:58,260 --> 00:09:01,890
search you can do a phrase search you

00:09:00,120 --> 00:09:03,720
can you arrange search any kind of

00:09:01,890 --> 00:09:05,340
search that is supported by solar so

00:09:03,720 --> 00:09:09,270
this is also varied slightly differs

00:09:05,340 --> 00:09:12,000
from a regular SQL expression because in

00:09:09,270 --> 00:09:13,860
SQL you could also do some number less

00:09:12,000 --> 00:09:16,620
than 10 right but that won't directly

00:09:13,860 --> 00:09:17,970
work here with solar you have to express

00:09:16,620 --> 00:09:19,950
that as a range query which is

00:09:17,970 --> 00:09:21,810
understood by solar I am assuming that

00:09:19,950 --> 00:09:23,340
that it's a small limitation it will

00:09:21,810 --> 00:09:24,930
probably go away at some point but right

00:09:23,340 --> 00:09:27,120
now that is what it is so if you are

00:09:24,930 --> 00:09:30,410
going to try this feature on solo 6.0

00:09:27,120 --> 00:09:33,780
then you have to keep this thing in mind

00:09:30,410 --> 00:09:36,120
you can obviously provide more than one

00:09:33,780 --> 00:09:37,620
clause and you can join them in and make

00:09:36,120 --> 00:09:41,400
an arbitrary boolean expression out of

00:09:37,620 --> 00:09:43,560
it and that will all work you can also

00:09:41,400 --> 00:09:47,190
do select distinct the silica distinct

00:09:43,560 --> 00:09:48,900
is always pushed down to it can be

00:09:47,190 --> 00:09:52,470
pushed down to solar or it can do the

00:09:48,900 --> 00:09:54,120
MapReduce approach in which case the the

00:09:52,470 --> 00:09:58,920
terms are exported to some worker node

00:09:54,120 --> 00:10:00,870
where they are aggregated the stacks

00:09:58,920 --> 00:10:04,320
aggregation actually used that starts

00:10:00,870 --> 00:10:06,330
component inside solar I'm a kind of

00:10:04,320 --> 00:10:08,250
assuming a lot of inside solar knowledge

00:10:06,330 --> 00:10:09,900
for this talk so in case there's

00:10:08,250 --> 00:10:11,640
something not very clear please feel

00:10:09,900 --> 00:10:13,110
free to ask a question during the

00:10:11,640 --> 00:10:15,300
question time or you can come meet me

00:10:13,110 --> 00:10:16,620
after the talk because I'm going to talk

00:10:15,300 --> 00:10:17,880
about stats component and all these

00:10:16,620 --> 00:10:19,830
things if you're not familiar so low

00:10:17,880 --> 00:10:22,620
then you might find a bit odd but I

00:10:19,830 --> 00:10:26,940
think to explain these concepts I have

00:10:22,620 --> 00:10:28,980
to skip over certain things okay the sad

00:10:26,940 --> 00:10:31,110
segregation are always pushed down to

00:10:28,980 --> 00:10:32,370
solar so the starch component is the one

00:10:31,110 --> 00:10:35,720
which is going to compute all these

00:10:32,370 --> 00:10:38,220
aggregations for you it does a

00:10:35,720 --> 00:10:40,680
approximate count it can do min max

00:10:38,220 --> 00:10:44,400
exoteric set some average all those

00:10:40,680 --> 00:10:46,230
things the only exception is when you do

00:10:44,400 --> 00:10:48,839
group bias if you're doing group buys

00:10:46,230 --> 00:10:50,280
then it's not done by the search

00:10:48,839 --> 00:10:56,820
component it is actually computed

00:10:50,280 --> 00:10:59,160
externally for efficiency reasons so you

00:10:56,820 --> 00:11:01,080
guys are all familiar with SQL this is

00:10:59,160 --> 00:11:03,870
nothing special right it's it's just in

00:11:01,080 --> 00:11:06,089
simple a skill expression you have a

00:11:03,870 --> 00:11:09,259
group by I have a having you have

00:11:06,089 --> 00:11:12,620
order by and all those kind of things

00:11:09,259 --> 00:11:14,699
the interesting thing to note here is

00:11:12,620 --> 00:11:17,009
when you use the MapReduce

00:11:14,699 --> 00:11:19,459
implementation you can join across

00:11:17,009 --> 00:11:22,230
collections you can even join across

00:11:19,459 --> 00:11:24,809
different solar clusters by providing

00:11:22,230 --> 00:11:27,180
the Zika address you can even combine

00:11:24,809 --> 00:11:28,999
data from different external sources for

00:11:27,180 --> 00:11:31,769
example there is a source for an

00:11:28,999 --> 00:11:33,779
external jdbc databases so if you can

00:11:31,769 --> 00:11:36,240
connect connect to that you can join

00:11:33,779 --> 00:11:38,490
data between your solar instance and the

00:11:36,240 --> 00:11:40,649
data being kept in some other jdbc

00:11:38,490 --> 00:11:42,360
compliant database so this makes the

00:11:40,649 --> 00:11:44,249
whole thing very very powerful you can

00:11:42,360 --> 00:11:48,149
you know you can join between arbitrary

00:11:44,249 --> 00:11:49,800
data sources and you don't have to worry

00:11:48,149 --> 00:11:51,779
a lot about how much data you are

00:11:49,800 --> 00:11:53,579
joining because this whole thing does

00:11:51,779 --> 00:11:56,129
not keep a lot of things in memory it's

00:11:53,579 --> 00:11:57,990
all streaming okay so it doesn't it you

00:11:56,129 --> 00:12:00,059
know it doesn't spill to disk it just

00:11:57,990 --> 00:12:02,370
keeps on streaming data and it stream

00:12:00,059 --> 00:12:04,079
sorts of stuff on the fly so you're not

00:12:02,370 --> 00:12:05,759
going to be worried about worry too much

00:12:04,079 --> 00:12:07,439
about how much memory you are going to

00:12:05,759 --> 00:12:13,589
consume by these joints it's all just

00:12:07,439 --> 00:12:16,769
going to work the JDBC driver as I said

00:12:13,589 --> 00:12:19,470
it's part of the solar J jar that we

00:12:16,769 --> 00:12:21,839
shipped with solar it already provides

00:12:19,470 --> 00:12:24,089
solar cloud away load balancing so it

00:12:21,839 --> 00:12:26,009
will it knows the cluster state it knows

00:12:24,089 --> 00:12:28,079
how many shots you have it knows how

00:12:26,009 --> 00:12:29,639
many replicas you have it will ensure

00:12:28,079 --> 00:12:31,860
that the query goes to the right place

00:12:29,639 --> 00:12:33,420
it will randomly select some node and

00:12:31,860 --> 00:12:35,699
send the skill segment to that which

00:12:33,420 --> 00:12:40,259
will again you know pan out the query to

00:12:35,699 --> 00:12:42,389
all of the nodes you can choose whether

00:12:40,259 --> 00:12:44,970
you're going to use the MapReduce or the

00:12:42,389 --> 00:12:47,309
facet style aggregation by specifying a

00:12:44,970 --> 00:12:49,050
parameter called the aggregation mode so

00:12:47,309 --> 00:12:52,259
that aggregation mode is specified as

00:12:49,050 --> 00:12:54,689
part of the JDBC connect string so as

00:12:52,259 --> 00:12:57,420
you can see you have jdbc Colin solar /

00:12:54,689 --> 00:12:59,279
/ the Zika connection string the

00:12:57,420 --> 00:13:01,050
collection equals to the collection name

00:12:59,279 --> 00:13:06,779
and the aggregation mode equal to facet

00:13:01,050 --> 00:13:09,809
in this case okay any questions until

00:13:06,779 --> 00:13:14,360
now this is this is just the most

00:13:09,809 --> 00:13:14,360
simplest usage part of SQL yes

00:13:15,490 --> 00:13:29,649
I don't think the necessary data is

00:13:27,240 --> 00:13:31,630
supported right now this is just the

00:13:29,649 --> 00:13:33,370
first cut of the feature I think it just

00:13:31,630 --> 00:13:37,029
assumes that each document is basically

00:13:33,370 --> 00:13:39,520
a couple but what I think what you can

00:13:37,029 --> 00:13:40,959
do is if you're not going to omit both

00:13:39,520 --> 00:13:42,850
the parent and the child at the same

00:13:40,959 --> 00:13:44,680
time if you're going to omit for example

00:13:42,850 --> 00:13:47,290
just the child documents then it

00:13:44,680 --> 00:13:48,610
probably can still work so if you have

00:13:47,290 --> 00:13:50,560
if you can structure a query which will

00:13:48,610 --> 00:13:52,360
limit just a child documents from one

00:13:50,560 --> 00:13:54,490
place then you can join it with the

00:13:52,360 --> 00:13:58,690
child documents of another collection so

00:13:54,490 --> 00:14:00,490
that's possible but it can't like it

00:13:58,690 --> 00:14:06,010
can't execute on a complete block at one

00:14:00,490 --> 00:14:08,580
time so with that let's go a little bit

00:14:06,010 --> 00:14:11,649
deep into how it is actually implemented

00:14:08,580 --> 00:14:13,540
there are five important concepts that

00:14:11,649 --> 00:14:18,360
you need to understand in order to

00:14:13,540 --> 00:14:20,980
completely use this feature thank you

00:14:18,360 --> 00:14:23,730
those five things are this there's a

00:14:20,980 --> 00:14:26,320
streaming API which is actually almost

00:14:23,730 --> 00:14:27,760
completely inside solar J there is

00:14:26,320 --> 00:14:30,399
something called a streaming expressions

00:14:27,760 --> 00:14:32,829
you have the concept of shuffling which

00:14:30,399 --> 00:14:35,589
is basically partitioning plus sorting

00:14:32,829 --> 00:14:37,149
and streaming out results you have

00:14:35,589 --> 00:14:39,370
something called worker collections and

00:14:37,149 --> 00:14:44,399
then of course the parallel scale stuff

00:14:39,370 --> 00:14:49,570
so let's go over each of them one by one

00:14:44,399 --> 00:14:51,010
so first is the streaming API the

00:14:49,570 --> 00:14:53,020
streaming API was actually the first

00:14:51,010 --> 00:14:55,839
thing that was built it is actually

00:14:53,020 --> 00:14:57,970
partially in fact a lot of it was

00:14:55,839 --> 00:15:00,310
already available in the 5x releases

00:14:57,970 --> 00:15:03,940
because that's when it was started being

00:15:00,310 --> 00:15:06,730
it started being developed the streaming

00:15:03,940 --> 00:15:09,490
API is basically it's just java classes

00:15:06,730 --> 00:15:12,760
so you use those java classes to compose

00:15:09,490 --> 00:15:14,589
queries you specify you know your

00:15:12,760 --> 00:15:16,180
transformations or you if you want a

00:15:14,589 --> 00:15:17,950
group or if you in a count or if you

00:15:16,180 --> 00:15:19,779
want to sum or if you want to have a

00:15:17,950 --> 00:15:22,089
where clause and things like that so you

00:15:19,779 --> 00:15:24,490
write code to build that and then you

00:15:22,089 --> 00:15:27,010
send it to solar and say execute this

00:15:24,490 --> 00:15:28,990
and give me the results in a streaming

00:15:27,010 --> 00:15:32,560
fashion okay so that

00:15:28,990 --> 00:15:34,750
basically what it is and what it

00:15:32,560 --> 00:15:36,940
operates on our tuples what's a topple a

00:15:34,750 --> 00:15:39,670
double is basically just a list of key

00:15:36,940 --> 00:15:42,640
value pairs okay so you have a key value

00:15:39,670 --> 00:15:45,190
key value key value streaming in and the

00:15:42,640 --> 00:15:47,140
last one is what we call as an end of

00:15:45,190 --> 00:15:49,690
file double that tupple basically says

00:15:47,140 --> 00:15:52,480
end of file true so when you see that

00:15:49,690 --> 00:15:54,520
you stop okay so this is all streaming

00:15:52,480 --> 00:15:57,130
so you never sure how many results

00:15:54,520 --> 00:15:59,290
you're going to get you always have to

00:15:57,130 --> 00:16:01,420
look at the last couple okay so if you

00:15:59,290 --> 00:16:03,130
find end of file is just wrong it's very

00:16:01,420 --> 00:16:06,040
actually very similar to the job I oh

00:16:03,130 --> 00:16:07,959
it's I mean you basically have rappers

00:16:06,040 --> 00:16:10,959
and decorators and it this also works in

00:16:07,959 --> 00:16:12,910
quite the same way so there are two

00:16:10,959 --> 00:16:14,290
parts for this you have a streaming

00:16:12,910 --> 00:16:16,270
transformation and you have the

00:16:14,290 --> 00:16:18,250
streaming aggregations transformations

00:16:16,270 --> 00:16:21,240
transform the data so you can do things

00:16:18,250 --> 00:16:23,649
like group by roll-up Union intersection

00:16:21,240 --> 00:16:26,560
compliments things like that with

00:16:23,649 --> 00:16:28,540
streaming aggregations you perform some

00:16:26,560 --> 00:16:30,610
functions which collect data over some

00:16:28,540 --> 00:16:35,050
buckets so for example you can do count

00:16:30,610 --> 00:16:38,350
average min Max etc etc right so pretty

00:16:35,050 --> 00:16:40,740
simple now comes streaming expressions

00:16:38,350 --> 00:16:42,910
so what is streaming expressions

00:16:40,740 --> 00:16:44,589
streaming expressions it's it's

00:16:42,910 --> 00:16:49,540
basically a query language which was

00:16:44,589 --> 00:16:51,130
built to specify so streaming is great

00:16:49,540 --> 00:16:52,990
you can do everything with streaming io

00:16:51,130 --> 00:16:55,800
the reason why we needed streaming

00:16:52,990 --> 00:16:58,329
fishings was twofold the first one was

00:16:55,800 --> 00:17:00,100
streaming io is only accessible to Java

00:16:58,329 --> 00:17:02,290
developers you have to write Java code

00:17:00,100 --> 00:17:03,790
to do anything and you don't want don't

00:17:02,290 --> 00:17:05,770
always want to write Java code to do the

00:17:03,790 --> 00:17:07,900
most simplest tasks so there should be a

00:17:05,770 --> 00:17:10,300
way to do more complex tasks without

00:17:07,900 --> 00:17:14,260
writing Java code right the second thing

00:17:10,300 --> 00:17:17,470
was when you perform when you execute an

00:17:14,260 --> 00:17:21,309
SQL statement on some node that node has

00:17:17,470 --> 00:17:22,780
to send that whole thing again to some

00:17:21,309 --> 00:17:25,120
of the worker nodes or some of the

00:17:22,780 --> 00:17:27,970
replicas for it to actually be executed

00:17:25,120 --> 00:17:29,830
and that is only part of the whole query

00:17:27,970 --> 00:17:32,260
plan it's not the complete SQL statement

00:17:29,830 --> 00:17:33,910
so we needed a way to represent what is

00:17:32,260 --> 00:17:35,980
going to happen on each of those nodes

00:17:33,910 --> 00:17:37,960
or each of those replicas so that they

00:17:35,980 --> 00:17:39,669
can be executed so the streaming

00:17:37,960 --> 00:17:42,100
expression is basically a query language

00:17:39,669 --> 00:17:42,880
as well as a civilization format for

00:17:42,100 --> 00:17:45,280
parallel

00:17:42,880 --> 00:17:46,720
SQL and later we will see that there are

00:17:45,280 --> 00:17:48,910
there some other work being done which

00:17:46,720 --> 00:17:52,630
will be which will it will always also

00:17:48,910 --> 00:17:55,390
be useful for so the streaming

00:17:52,630 --> 00:17:57,370
expressions come when you compile them

00:17:55,390 --> 00:17:59,350
they actually compile to the trouble

00:17:57,370 --> 00:18:02,380
stream objects double stream objects are

00:17:59,350 --> 00:18:04,780
part of the streaming io API so topple

00:18:02,380 --> 00:18:06,790
stream is basically a stream of tuples

00:18:04,780 --> 00:18:11,710
which are coming in as I said the last

00:18:06,790 --> 00:18:14,260
one would be an UF double you can also

00:18:11,710 --> 00:18:17,470
send a streaming expression directly to

00:18:14,260 --> 00:18:20,200
solar or why I HTTP in fact that is how

00:18:17,470 --> 00:18:22,420
it is that is how part of the current

00:18:20,200 --> 00:18:24,490
plan is communicated to other replicas

00:18:22,420 --> 00:18:31,900
when you're parallel cable is being

00:18:24,490 --> 00:18:34,510
executed so this is an example of a

00:18:31,900 --> 00:18:41,740
streaming expression again we are

00:18:34,510 --> 00:18:44,680
looking at the Enron emails dataset what

00:18:41,740 --> 00:18:47,920
it is trying to do here is it is trying

00:18:44,680 --> 00:18:52,750
to give you the data of which were the

00:18:47,920 --> 00:18:55,060
addresses to which flowers for sent from

00:18:52,750 --> 00:18:57,790
1-800 flowers or basically emails from

00:18:55,060 --> 00:18:59,530
email for sent from the email belonging

00:18:57,790 --> 00:19:01,810
to 1 800 flowers which is a common

00:18:59,530 --> 00:19:05,620
flowers vendor in in the u.s. so you

00:19:01,810 --> 00:19:07,480
have expression equal to search the

00:19:05,620 --> 00:19:10,960
collection name is end on emails the

00:19:07,480 --> 00:19:15,070
query is from 1800 flowers star so any

00:19:10,960 --> 00:19:17,380
mail matching 1800 flowers will match

00:19:15,070 --> 00:19:20,170
this query the fields that you want is

00:19:17,380 --> 00:19:23,050
from n 2 and we want to sort by the from

00:19:20,170 --> 00:19:25,990
okay so in the result set you will see

00:19:23,050 --> 00:19:28,000
that you get from a United flowers

00:19:25,990 --> 00:19:30,100
different email addresses the two are

00:19:28,000 --> 00:19:32,290
the addresses from belonging to

00:19:30,100 --> 00:19:35,220
employees of Enron and at the end you

00:19:32,290 --> 00:19:38,380
see you f so the response is actually

00:19:35,220 --> 00:19:41,610
exactly the same if you were to write a

00:19:38,380 --> 00:19:43,510
Java program with the streaming IO API

00:19:41,610 --> 00:19:45,280
except that in this case it is

00:19:43,510 --> 00:19:47,680
automatically compiled and executed for

00:19:45,280 --> 00:19:49,930
you without writing any Java code ok and

00:19:47,680 --> 00:19:52,630
this is Polly well this is a very very

00:19:49,930 --> 00:19:54,700
simple example you can nest the

00:19:52,630 --> 00:19:56,620
expression so for example i have this

00:19:54,700 --> 00:19:58,750
search i can try to

00:19:56,620 --> 00:20:01,270
to completely nest this within a group

00:19:58,750 --> 00:20:03,520
by or account or things like that so you

00:20:01,270 --> 00:20:04,930
can create very very complex nested

00:20:03,520 --> 00:20:07,480
structures and do a lot of very

00:20:04,930 --> 00:20:09,340
interesting things with it in fact you

00:20:07,480 --> 00:20:11,830
can also paralyzed this so if you want

00:20:09,340 --> 00:20:13,540
to for example group by you can do the

00:20:11,830 --> 00:20:14,620
group by in parallel on different vocal

00:20:13,540 --> 00:20:24,330
nodes and there is a streaming

00:20:14,620 --> 00:20:26,620
expression for that also okay so

00:20:24,330 --> 00:20:29,500
streaming expressions are off to ties

00:20:26,620 --> 00:20:31,750
basically the first one is a stream

00:20:29,500 --> 00:20:35,650
source so these are the expressions

00:20:31,750 --> 00:20:37,420
which emit the streams which can later

00:20:35,650 --> 00:20:39,850
be consumed and you can do certain

00:20:37,420 --> 00:20:42,670
things with it so for example you have

00:20:39,850 --> 00:20:45,010
stream sources such as a search so a

00:20:42,670 --> 00:20:47,800
search result will emit the tuples or

00:20:45,010 --> 00:20:49,870
you can have a JDBC source or a facet

00:20:47,800 --> 00:20:51,700
source or a starch source or a topic

00:20:49,870 --> 00:20:53,170
source so what's a topic source the

00:20:51,700 --> 00:20:55,330
topic source is a little bit interesting

00:20:53,170 --> 00:20:57,940
because what it allows you to do is to

00:20:55,330 --> 00:20:59,500
subscribe to a given query and then

00:20:57,940 --> 00:21:01,120
whenever a new document comes which

00:20:59,500 --> 00:21:03,460
matches that query you can get a

00:21:01,120 --> 00:21:04,809
response back you can get an you can get

00:21:03,460 --> 00:21:07,300
a callback and then you can do something

00:21:04,809 --> 00:21:09,340
useful with it okay so this is something

00:21:07,300 --> 00:21:10,990
which is still new and it is being

00:21:09,340 --> 00:21:12,910
flushed out I don't think it's quite

00:21:10,990 --> 00:21:18,040
ready to use yet but it will be

00:21:12,910 --> 00:21:20,020
interesting how it how it pans out the

00:21:18,040 --> 00:21:23,050
second kinds of expressions are

00:21:20,020 --> 00:21:25,780
decorators the decorators vApp they wrap

00:21:23,050 --> 00:21:27,429
around other stream functions and they

00:21:25,780 --> 00:21:29,410
perform operations so for example you

00:21:27,429 --> 00:21:31,030
can do a compliment or a hash join or a

00:21:29,410 --> 00:21:33,520
partitioning or intersect and

00:21:31,030 --> 00:21:36,760
interesting things like that right so

00:21:33,520 --> 00:21:39,670
you will if you we have the solar

00:21:36,760 --> 00:21:41,200
reference guide which which we in which

00:21:39,670 --> 00:21:42,460
we have a page which details all the

00:21:41,200 --> 00:21:48,940
string expressions which are available

00:21:42,460 --> 00:21:50,890
and that list is expanding most but not

00:21:48,940 --> 00:21:53,020
all of the streaming expression

00:21:50,890 --> 00:21:56,620
functions can be parallelized across

00:21:53,020 --> 00:21:58,600
different collections so the ones which

00:21:56,620 --> 00:22:00,640
can be paralyzed usually accept a

00:21:58,600 --> 00:22:03,429
parameter called workers in which you

00:22:00,640 --> 00:22:05,860
say i want for workers or i want 11

00:22:03,429 --> 00:22:07,540
workers and so on and so forth and that

00:22:05,860 --> 00:22:10,020
may number of nodes will be used for the

00:22:07,540 --> 00:22:10,020
paralyzation

00:22:11,260 --> 00:22:15,740
now without we come to shuffling

00:22:13,700 --> 00:22:17,390
shuffling is probably one of the most

00:22:15,740 --> 00:22:20,210
important concepts because it determines

00:22:17,390 --> 00:22:22,630
the performance of your streaming

00:22:20,210 --> 00:22:25,370
expression or your or your SQL statement

00:22:22,630 --> 00:22:27,830
this is where the aggregation mode is

00:22:25,370 --> 00:22:30,140
actually internally used because what

00:22:27,830 --> 00:22:32,809
happens is so what is shuffling

00:22:30,140 --> 00:22:35,390
shuffling is basically partitioning and

00:22:32,809 --> 00:22:37,669
stream sorting results ok so you

00:22:35,390 --> 00:22:42,350
partition the results and you sort them

00:22:37,669 --> 00:22:46,340
and you stream them ok so the sorting is

00:22:42,350 --> 00:22:48,110
done by the / export handler if you guys

00:22:46,340 --> 00:22:51,169
don't know what the / export handler

00:22:48,110 --> 00:22:54,380
it's a request online inside solar it

00:22:51,169 --> 00:22:57,230
operates on Doc value fields what's a

00:22:54,380 --> 00:22:58,880
doc value doc value is a it's a

00:22:57,230 --> 00:23:01,610
column-oriented store so basically all

00:22:58,880 --> 00:23:04,909
values of a given field sorted and

00:23:01,610 --> 00:23:06,380
deduplicated store together okay so when

00:23:04,909 --> 00:23:08,240
you have such a data structure available

00:23:06,380 --> 00:23:10,610
on the disk if you want to just stream

00:23:08,240 --> 00:23:13,159
it out in a sorted fashion it's very

00:23:10,610 --> 00:23:15,230
easy right you just seek to the right

00:23:13,159 --> 00:23:17,450
point in just stream out stuff which is

00:23:15,230 --> 00:23:19,730
relevant to you okay you might apply a

00:23:17,450 --> 00:23:21,799
function to figure out which one should

00:23:19,730 --> 00:23:24,710
be streamed out but it's like it's

00:23:21,799 --> 00:23:25,909
extremely fast so we have a few clients

00:23:24,710 --> 00:23:28,070
who are actually using this in

00:23:25,909 --> 00:23:30,289
production and they tell us that with a

00:23:28,070 --> 00:23:32,870
few fields they can do about 800,000

00:23:30,289 --> 00:23:34,760
tuples per second per node of shuffling

00:23:32,870 --> 00:23:36,889
that's pretty fast so if you're doing it

00:23:34,760 --> 00:23:38,840
in parallel across a large cluster you

00:23:36,889 --> 00:23:41,090
can do very complex analytical queries

00:23:38,840 --> 00:23:43,460
and still get results in sub second or a

00:23:41,090 --> 00:23:48,799
few second times okay and that's pretty

00:23:43,460 --> 00:23:53,059
powerful so the sorting is done by the /

00:23:48,799 --> 00:23:54,380
export handler you must use doc values

00:23:53,059 --> 00:23:56,929
for the fields which you want to use

00:23:54,380 --> 00:23:58,760
here that is a limitation but I think

00:23:56,929 --> 00:24:01,309
using doc well is in general is anyway

00:23:58,760 --> 00:24:04,580
good idea if you using complex faceting

00:24:01,309 --> 00:24:06,529
or sorting etc the partitioning is done

00:24:04,580 --> 00:24:08,269
by what we call a hash queue partial

00:24:06,529 --> 00:24:10,850
plug in it's basically a hashing

00:24:08,269 --> 00:24:13,730
function you basically give it the

00:24:10,850 --> 00:24:16,100
number of worker nodes and it uses one

00:24:13,730 --> 00:24:18,830
or more fields values so it goes over

00:24:16,100 --> 00:24:21,620
the value for each document applies the

00:24:18,830 --> 00:24:23,750
hash function sees on which worker node

00:24:21,620 --> 00:24:25,850
that hash functions value falls to

00:24:23,750 --> 00:24:29,630
then that worker node will emit value

00:24:25,850 --> 00:24:32,270
for that particular document so if you

00:24:29,630 --> 00:24:34,910
have five workers each worker gets one

00:24:32,270 --> 00:24:38,830
fifth of the total results to process so

00:24:34,910 --> 00:24:38,830
that that is how it happens internally

00:24:39,490 --> 00:24:44,480
the moment this the moment you send a

00:24:42,830 --> 00:24:47,660
request to the / export handler on a

00:24:44,480 --> 00:24:50,660
given node it basically starts streaming

00:24:47,660 --> 00:24:53,180
instantly and it just keeps on swimming

00:24:50,660 --> 00:24:55,130
until the data aims okay so on the

00:24:53,180 --> 00:24:56,750
worker node get starts getting the data

00:24:55,130 --> 00:25:00,110
almost immediately and it can start

00:24:56,750 --> 00:25:02,330
doing useful stuff with it so this is

00:25:00,110 --> 00:25:04,160
not really a replacement for Hadoop or

00:25:02,330 --> 00:25:05,360
or basically high over all those kind of

00:25:04,160 --> 00:25:08,660
systems where you have to wait for

00:25:05,360 --> 00:25:11,060
minutes it is not built for that purpose

00:25:08,660 --> 00:25:13,130
in mind it is built where you have a

00:25:11,060 --> 00:25:15,110
decent or a large amount of data in

00:25:13,130 --> 00:25:18,140
solar and you want to do stuff which

00:25:15,110 --> 00:25:20,630
maybe takes a few seconds or sub seconds

00:25:18,140 --> 00:25:21,560
it's not suitable when you want to do

00:25:20,630 --> 00:25:24,440
some stuff which is going to take

00:25:21,560 --> 00:25:25,910
minutes and minutes of your time okay so

00:25:24,440 --> 00:25:28,640
because it's all streaming it's all

00:25:25,910 --> 00:25:31,790
pretty fast and the good thing about

00:25:28,640 --> 00:25:34,940
this is because it is all streaming and

00:25:31,790 --> 00:25:36,770
it is all happening really fast and it

00:25:34,940 --> 00:25:38,900
is happening in parallel if you can

00:25:36,770 --> 00:25:41,540
afford to throw a lot of hardware at it

00:25:38,900 --> 00:25:43,070
you can scale it really well so even if

00:25:41,540 --> 00:25:45,050
you have very very complex queries you

00:25:43,070 --> 00:25:46,730
can still get the data you can still get

00:25:45,050 --> 00:25:52,100
your responses in a small amount of time

00:25:46,730 --> 00:25:54,980
because you can use all that hardware so

00:25:52,100 --> 00:25:58,010
all replicas shuffle in parallel for the

00:25:54,980 --> 00:26:02,780
same query which allows for very large

00:25:58,010 --> 00:26:05,420
throughputs the Verger collection is

00:26:02,780 --> 00:26:08,060
basically it's just a made up name

00:26:05,420 --> 00:26:10,370
really the vocal collection is just like

00:26:08,060 --> 00:26:12,410
any other solo cloud collection it

00:26:10,370 --> 00:26:14,840
doesn't even have to be a separate

00:26:12,410 --> 00:26:16,850
collection and by default it is the same

00:26:14,840 --> 00:26:19,850
collection which holds the data which

00:26:16,850 --> 00:26:22,640
you are trying to operate on but if you

00:26:19,850 --> 00:26:24,560
really do want to separate the the major

00:26:22,640 --> 00:26:26,870
processing from the place the data

00:26:24,560 --> 00:26:29,150
actually lives then you can create a new

00:26:26,870 --> 00:26:31,610
collection and say that this is my

00:26:29,150 --> 00:26:33,650
worker collection and then all the all

00:26:31,610 --> 00:26:35,810
the difficult stuff all the major

00:26:33,650 --> 00:26:37,090
processing the aggregations will happen

00:26:35,810 --> 00:26:39,310
on those nodes

00:26:37,090 --> 00:26:41,200
okay so by default the worker collection

00:26:39,310 --> 00:26:42,850
is the same as the collection which

00:26:41,200 --> 00:26:49,720
holds your data but you can choose to

00:26:42,850 --> 00:26:52,510
separate it out okay so it so this guy

00:26:49,720 --> 00:26:55,360
performs the aggregations there is an

00:26:52,510 --> 00:26:57,730
HTTP endpoint called / stream which is

00:26:55,360 --> 00:27:00,250
which has to be available and actually

00:26:57,730 --> 00:27:02,320
that endpoint is by default available in

00:27:00,250 --> 00:27:04,930
solar 6 on all collections so you don't

00:27:02,320 --> 00:27:08,140
have to do anything extraoral to enable

00:27:04,930 --> 00:27:10,960
this as I said it might just be empty or

00:27:08,140 --> 00:27:12,310
you might just created you know just in

00:27:10,960 --> 00:27:14,110
time or you might just keep it around

00:27:12,310 --> 00:27:20,770
with some empty nodes and not use it for

00:27:14,110 --> 00:27:23,680
any other purposes then you send in an

00:27:20,770 --> 00:27:26,860
SQL to solar what happens is we use the

00:27:23,680 --> 00:27:29,050
presto SQL parcel which is a parser

00:27:26,860 --> 00:27:31,330
created by Facebook so that parser

00:27:29,050 --> 00:27:34,810
internally compiles that SQL statement

00:27:31,330 --> 00:27:36,970
to the streaming io API is the streaming

00:27:34,810 --> 00:27:39,160
io API is RC lies to swimming

00:27:36,970 --> 00:27:41,770
expressions and then send to each worker

00:27:39,160 --> 00:27:44,380
nodes and the worker nodes make requests

00:27:41,770 --> 00:27:46,300
to each replica of each shard and get

00:27:44,380 --> 00:27:50,320
the appropriate data out of it for

00:27:46,300 --> 00:27:52,980
further processing so here we have a

00:27:50,320 --> 00:27:56,080
diagram which which shows so this is

00:27:52,980 --> 00:27:58,990
example where where we are going to use

00:27:56,080 --> 00:28:01,420
the aggregation mode of MapReduce so the

00:27:58,990 --> 00:28:03,730
client send sent in a skill statement to

00:28:01,420 --> 00:28:06,010
the / SQL handler on some node this can

00:28:03,730 --> 00:28:08,050
be any node part of the collection away

00:28:06,010 --> 00:28:10,390
from the collection as long as it's you

00:28:08,050 --> 00:28:14,770
know as long as it's inside the cluster

00:28:10,390 --> 00:28:17,050
yerb you're good so use in this SQL

00:28:14,770 --> 00:28:18,970
statement you probably had five worker

00:28:17,050 --> 00:28:21,040
collections sorry five worker nodes as

00:28:18,970 --> 00:28:23,380
part of a worker collection so you have

00:28:21,040 --> 00:28:25,300
five workers as you can so this is an

00:28:23,380 --> 00:28:28,360
interesting difference between a regular

00:28:25,300 --> 00:28:30,490
distributed search and this SQL

00:28:28,360 --> 00:28:33,100
execution in a regular distributed

00:28:30,490 --> 00:28:36,460
search solar would choose one replica

00:28:33,100 --> 00:28:39,370
from each shard right and it would send

00:28:36,460 --> 00:28:41,200
there is the query to that replica get

00:28:39,370 --> 00:28:43,210
the responses from all the shots merge

00:28:41,200 --> 00:28:46,210
and give it back to you so at any given

00:28:43,210 --> 00:28:48,910
time your query is using one replica

00:28:46,210 --> 00:28:50,650
from each chart but in this case your

00:28:48,910 --> 00:28:53,650
query is using all

00:28:50,650 --> 00:28:56,290
replicas from all the shards okay so by

00:28:53,650 --> 00:28:58,660
adding more replicas or by splitting and

00:28:56,290 --> 00:29:00,310
creating more shots you can put massive

00:28:58,660 --> 00:29:02,650
amounts of computation power behind a

00:29:00,310 --> 00:29:05,200
single query which means you can do very

00:29:02,650 --> 00:29:07,150
complex stuff very very fast okay so

00:29:05,200 --> 00:29:08,620
this is an interesting difference

00:29:07,150 --> 00:29:11,020
between the regular this which search

00:29:08,620 --> 00:29:13,360
and this one so you have this skill

00:29:11,020 --> 00:29:15,550
handler which parts the query created a

00:29:13,360 --> 00:29:17,170
streaming io representation of it which

00:29:15,550 --> 00:29:19,000
was serialized to swimming expressions

00:29:17,170 --> 00:29:21,430
that expression was sent to each other

00:29:19,000 --> 00:29:23,740
worker nodes the worker nodes again

00:29:21,430 --> 00:29:26,200
requested data by using the / export

00:29:23,740 --> 00:29:27,970
handler or maybe they use the facet

00:29:26,200 --> 00:29:29,890
method in case you were using the first

00:29:27,970 --> 00:29:32,020
method in this case we're not so they

00:29:29,890 --> 00:29:34,480
will send requests to one replica from

00:29:32,020 --> 00:29:36,220
each chart every worker will get one

00:29:34,480 --> 00:29:39,310
fifth of the overall data to process

00:29:36,220 --> 00:29:41,260
they will roll it up and then they will

00:29:39,310 --> 00:29:43,570
send the whole response back there's

00:29:41,260 --> 00:29:45,040
good handler so this is all happening in

00:29:43,570 --> 00:29:46,810
a streaming fashion there's nothing

00:29:45,040 --> 00:29:55,210
which is being kept to memory or being

00:29:46,810 --> 00:30:01,770
spilled to disk here okay so any

00:29:55,210 --> 00:30:01,770
questions until this point yes

00:30:10,230 --> 00:30:18,370
everywhere how do you schedule your i/o

00:30:15,270 --> 00:30:23,309
capacity basically it's totally possibly

00:30:18,370 --> 00:30:25,960
to jam everything suggests yeah so so

00:30:23,309 --> 00:30:27,429
this is probably not going to be useful

00:30:25,960 --> 00:30:29,950
if you are also going to use it for

00:30:27,429 --> 00:30:31,179
real-time queries because you are

00:30:29,950 --> 00:30:33,490
basically going to suck up all the

00:30:31,179 --> 00:30:36,580
bandwidth available right but then this

00:30:33,490 --> 00:30:38,049
example is an example of very high

00:30:36,580 --> 00:30:39,940
throughput very high cardinality

00:30:38,049 --> 00:30:41,590
aggregation happening on a lot of data

00:30:39,940 --> 00:30:45,640
in which case you want all that

00:30:41,590 --> 00:30:47,440
computation power ok so again it depends

00:30:45,640 --> 00:30:49,090
on your use case if you you you probably

00:30:47,440 --> 00:30:51,580
wouldn't want to see anyway it's a bad

00:30:49,090 --> 00:30:53,620
idea to mix very heavy analytical

00:30:51,580 --> 00:30:56,080
workloads with real-time query workloads

00:30:53,620 --> 00:30:57,720
right that's probably the a good advice

00:30:56,080 --> 00:31:01,240
so you have to separate them out anyway

00:30:57,720 --> 00:31:07,950
ok so this would probably be a bad idea

00:31:01,240 --> 00:31:07,950
for the use case that you described yes

00:31:13,849 --> 00:31:16,849
search

00:31:27,180 --> 00:31:32,380
well it depends for example if you have

00:31:29,610 --> 00:31:34,290
heavy distribute join requirements then

00:31:32,380 --> 00:31:36,850
this poly would be the only way to do it

00:31:34,290 --> 00:31:38,440
unless those features also get it see

00:31:36,850 --> 00:31:40,360
the problem is when you have distributed

00:31:38,440 --> 00:31:42,970
joints it becomes more and more

00:31:40,360 --> 00:31:45,670
difficult to specify as it as part of a

00:31:42,970 --> 00:31:48,190
classical solar query this way it's much

00:31:45,670 --> 00:31:52,210
more easier because you can nest stuff

00:31:48,190 --> 00:31:54,130
and build more complex expressions so in

00:31:52,210 --> 00:31:56,290
fact I know of someone who is actually

00:31:54,130 --> 00:31:57,610
using it for regular search actually

00:31:56,290 --> 00:32:00,160
planning to use it for regular search

00:31:57,610 --> 00:32:02,350
the only drawback here is because it is

00:32:00,160 --> 00:32:03,850
streaming you are not going to get you

00:32:02,350 --> 00:32:06,580
go you're not going to know the number

00:32:03,850 --> 00:32:09,490
of results to show to the user so you

00:32:06,580 --> 00:32:11,740
can even right now you can use it as a

00:32:09,490 --> 00:32:15,810
replacement of classical solar query but

00:32:11,740 --> 00:32:15,810
you know that there's a limitation to it

00:32:19,170 --> 00:32:26,950
now there's no pagination here so you

00:32:24,580 --> 00:32:28,900
can provide a limit laws if you're using

00:32:26,950 --> 00:32:31,300
SQL you can do a limit and you can say I

00:32:28,900 --> 00:32:33,430
just want the top 100 results so if you

00:32:31,300 --> 00:32:35,650
if you actually in fact if you actually

00:32:33,430 --> 00:32:37,720
provide a limit loss then you don't

00:32:35,650 --> 00:32:39,610
really have to operate on Doc values you

00:32:37,720 --> 00:32:41,140
can also get this the stored fees and

00:32:39,610 --> 00:32:44,710
you can also use the regular solar

00:32:41,140 --> 00:32:47,110
ranking but if you want to do analytical

00:32:44,710 --> 00:32:50,170
stuff and then you can do exports of the

00:32:47,110 --> 00:32:51,670
complete data sets so exporting complete

00:32:50,170 --> 00:32:53,550
data sets has not been a very strong

00:32:51,670 --> 00:32:57,280
point of search engines which is why the

00:32:53,550 --> 00:32:59,380
the cursor mark feature was developed to

00:32:57,280 --> 00:33:01,690
solar that allows you to paginate very

00:32:59,380 --> 00:33:07,680
deep but this guy is actually built for

00:33:01,690 --> 00:33:07,680
streaming out entire result sites yes

00:33:18,970 --> 00:33:23,990
that's a great question so why was the

00:33:21,320 --> 00:33:26,600
presto parcel picked I I think the

00:33:23,990 --> 00:33:29,510
reason that Joey who initially wrote

00:33:26,600 --> 00:33:31,610
this system gave was so he considered

00:33:29,510 --> 00:33:33,590
calcite as well but calcite was far more

00:33:31,610 --> 00:33:35,960
involved because it had its optimizer

00:33:33,590 --> 00:33:37,790
and all those things so the API was far

00:33:35,960 --> 00:33:39,200
more difficult for him to grasp at that

00:33:37,790 --> 00:33:41,600
time and he just wanted to get something

00:33:39,200 --> 00:33:44,270
up and running in fact now there is a

00:33:41,600 --> 00:33:46,220
gia issue where he wants to move away

00:33:44,270 --> 00:33:47,990
from presto and start using calcite

00:33:46,220 --> 00:33:51,230
because he wants to use that optimizer

00:33:47,990 --> 00:33:52,970
and all the stuff yeah so it's actually

00:33:51,230 --> 00:34:01,400
one of you know in one of my slides on

00:33:52,970 --> 00:34:03,860
the next things which are ya alright so

00:34:01,400 --> 00:34:06,410
just quick two minutes on what's next

00:34:03,860 --> 00:34:09,139
what's happening so in 6.1 you will see

00:34:06,410 --> 00:34:10,760
a graph traversals with streaming

00:34:09,139 --> 00:34:12,260
expressions so this is interesting

00:34:10,760 --> 00:34:14,149
because right now you have seen that

00:34:12,260 --> 00:34:16,610
panel SQL is compiled to swimming

00:34:14,149 --> 00:34:18,379
expressions what they plan is eventually

00:34:16,610 --> 00:34:20,330
to have a gremlin language

00:34:18,379 --> 00:34:22,010
instrumentation which is also compiled

00:34:20,330 --> 00:34:23,810
to swimming expressions so then you will

00:34:22,010 --> 00:34:26,240
have a gremlin language implementation

00:34:23,810 --> 00:34:28,220
inside solar which can do distributed

00:34:26,240 --> 00:34:31,610
graph traversals across collections

00:34:28,220 --> 00:34:33,560
maybe okay so we already all we already

00:34:31,610 --> 00:34:35,149
have a function for shortest path we

00:34:33,560 --> 00:34:38,179
also have functions for random node

00:34:35,149 --> 00:34:40,700
walking you can provide a query provide

00:34:38,179 --> 00:34:42,440
filters and start walking nodes and

00:34:40,700 --> 00:34:44,480
collect all the nodes you can also

00:34:42,440 --> 00:34:46,669
record all the edges and then use it in

00:34:44,480 --> 00:34:48,679
some place there is already a graph

00:34:46,669 --> 00:34:50,629
email response format so if you want to

00:34:48,679 --> 00:34:52,909
visualize it in something which

00:34:50,629 --> 00:34:55,310
understands graph ml you can do that and

00:34:52,909 --> 00:34:57,410
this is just the start you will you will

00:34:55,310 --> 00:34:59,630
probably see a lot more happening in the

00:34:57,410 --> 00:35:01,820
graph part this is probably its own talk

00:34:59,630 --> 00:35:05,480
now on its own this is such a such a

00:35:01,820 --> 00:35:08,030
vast topic the second interesting thing

00:35:05,480 --> 00:35:10,880
is there is an implementation of a

00:35:08,030 --> 00:35:13,190
logistic regression query which is

00:35:10,880 --> 00:35:16,370
implemented as a streaming expression so

00:35:13,190 --> 00:35:18,890
you can use documents inside solar to

00:35:16,370 --> 00:35:21,020
train models and then you can use them

00:35:18,890 --> 00:35:23,570
in some other way and how you can use

00:35:21,020 --> 00:35:24,230
them is you can probably use the top

00:35:23,570 --> 00:35:25,940
extremes that

00:35:24,230 --> 00:35:29,510
mentioned earlier you can subscribe to

00:35:25,940 --> 00:35:31,880
something get an alert you know execute

00:35:29,510 --> 00:35:33,619
that document against a model which is

00:35:31,880 --> 00:35:35,210
already trained and then make some

00:35:33,619 --> 00:35:37,369
decision and send some alert to some

00:35:35,210 --> 00:35:38,869
place so for example you can see hey

00:35:37,369 --> 00:35:40,790
this document is very very important to

00:35:38,869 --> 00:35:43,130
me or maybe that customer wants it or

00:35:40,790 --> 00:35:45,140
something maybe more complex so I think

00:35:43,130 --> 00:35:46,970
some of the use cases behind all these

00:35:45,140 --> 00:35:49,310
things are not quite clear even to the

00:35:46,970 --> 00:35:51,560
people who are implementing this they're

00:35:49,310 --> 00:35:53,840
implementing this because it is yeah no

00:35:51,560 --> 00:35:55,910
seriously I don't think the use cases

00:35:53,840 --> 00:35:58,040
are quite clear to them it's just it's

00:35:55,910 --> 00:36:00,230
possible now which whereas it was not

00:35:58,040 --> 00:36:01,820
possible or it was not very easy earlier

00:36:00,230 --> 00:36:03,830
and I think people are just waiting to

00:36:01,820 --> 00:36:06,380
see what kind of use cases the users

00:36:03,830 --> 00:36:07,490
come up with okay and then the

00:36:06,380 --> 00:36:10,540
development will probably adjust

00:36:07,490 --> 00:36:12,590
automatically because I know there was a

00:36:10,540 --> 00:36:15,109
logistic regression part and the graph

00:36:12,590 --> 00:36:16,490
traversal part was started almost at the

00:36:15,109 --> 00:36:18,230
same time but there was a lot more

00:36:16,490 --> 00:36:19,940
interest in the graph traversal part so

00:36:18,230 --> 00:36:21,680
that's where the focus happened and it's

00:36:19,940 --> 00:36:24,190
actually going to be release with 6.1

00:36:21,680 --> 00:36:27,950
it's already committed to the solar

00:36:24,190 --> 00:36:29,510
master branch right now so I'm probably

00:36:27,950 --> 00:36:31,040
gonna see you you probably gonna see the

00:36:29,510 --> 00:36:34,369
logic deviation and some other

00:36:31,040 --> 00:36:38,140
algorithms implemented as more important

00:36:34,369 --> 00:36:38,140
volved and start building stuff with it

00:36:39,369 --> 00:36:45,140
you can do alerts using the topics and

00:36:43,280 --> 00:36:46,940
the model streams there is also

00:36:45,140 --> 00:36:48,770
something called a daemon stream a demon

00:36:46,940 --> 00:36:51,560
stream is something which is like a

00:36:48,770 --> 00:36:53,359
demon it it is running all the time okay

00:36:51,560 --> 00:36:55,310
so you have a new document coming in it

00:36:53,359 --> 00:36:57,230
smashed that demon stream can actually

00:36:55,310 --> 00:36:59,420
send that alert to you so it's not just

00:36:57,230 --> 00:37:01,190
based on the request it's something

00:36:59,420 --> 00:37:03,859
which is there all the time and can do

00:37:01,190 --> 00:37:05,900
stuff in the background you also have

00:37:03,859 --> 00:37:08,300
something called an update stream so

00:37:05,900 --> 00:37:11,780
right now it's just for queries but

00:37:08,300 --> 00:37:13,730
hopefully you will also support things

00:37:11,780 --> 00:37:16,430
like select into so you can do some

00:37:13,730 --> 00:37:18,830
solar query some sorry some SQL query

00:37:16,430 --> 00:37:21,590
and then get the responses and probably

00:37:18,830 --> 00:37:23,450
update it into a difference or maybe the

00:37:21,590 --> 00:37:27,590
same sort of collection so that should

00:37:23,450 --> 00:37:29,450
also be possible very very soon as I

00:37:27,590 --> 00:37:32,600
said calcite integration is being worked

00:37:29,450 --> 00:37:34,760
on presto is going to go away it will be

00:37:32,600 --> 00:37:37,430
calcite all throughout jdbc support is

00:37:34,760 --> 00:37:38,090
being expanded more and more new kinds

00:37:37,430 --> 00:37:41,510
of tools are

00:37:38,090 --> 00:37:42,950
being supported and certified and the

00:37:41,510 --> 00:37:44,150
top extreme and models team are also

00:37:42,950 --> 00:37:46,640
going to be used for publish-subscribe

00:37:44,150 --> 00:37:49,250
so there are lots of ideas are lots of

00:37:46,640 --> 00:37:50,690
GI issues which are open a lot of them

00:37:49,250 --> 00:37:51,860
don't have patches right now some of

00:37:50,690 --> 00:37:53,780
them do some of them are already

00:37:51,860 --> 00:37:54,890
committed this is actually a great time

00:37:53,780 --> 00:37:57,230
to get involved with this feature

00:37:54,890 --> 00:37:59,090
because even we don't know where it is

00:37:57,230 --> 00:38:02,090
going to go I think it's all dependent

00:37:59,090 --> 00:38:04,640
on what users build with it and what is

00:38:02,090 --> 00:38:06,350
the interest of the community so with

00:38:04,640 --> 00:38:08,660
that I am going to close this

00:38:06,350 --> 00:38:11,000
presentation if you do we have time for

00:38:08,660 --> 00:38:18,020
questions Thank You Charlene I think we

00:38:11,000 --> 00:38:21,260
have time for only one question ok no

00:38:18,020 --> 00:38:23,270
questions probably they can reach out to

00:38:21,260 --> 00:38:26,060
your flying ok we have a coffee break

00:38:23,270 --> 00:38:28,690
anytime all right thank you so much for

00:38:26,060 --> 00:38:28,690

YouTube URL: https://www.youtube.com/watch?v=oOaMPsQ_RkU


