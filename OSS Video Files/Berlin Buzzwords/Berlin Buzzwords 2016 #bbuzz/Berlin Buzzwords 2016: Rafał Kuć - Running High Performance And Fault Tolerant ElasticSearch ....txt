Title: Berlin Buzzwords 2016: Rafał Kuć - Running High Performance And Fault Tolerant ElasticSearch ...
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	We’ve learned how to run Docker containers. And we’ve learned how to run ElasticSearch. However, to run containerized ElasticSearch nodes and to do that effectively -- and at scale -- takes a little more knowledge and work. Sure, containers can be easily started and stopped; but how do you do that with ElasticSearch inside them?

In this talk we’ll quickly run over the basic Docker+ElasticSearch setup and focus on harder problems:
- Architecting for ElasticSearch fault tolerance and high availability in containerized setup - using sharding, replication, node and shard-awareness for keeping your cluster green
- Running ElasticSearch in different modes with re-usability in mind
- Optimizing and tuning ElasticSearch for popular use cases like ELK
- Ops/Devops - monitoring ElasticSearch & Docker together - which metrics to watch, what they mean, how to act on them and first of all, how to watch them

Read more:
https://2016.berlinbuzzwords.de/session/running-high-performance-and-fault-tolerant-elasticsearch-clusters-docker

About Rafał Kuć:
https://2016.berlinbuzzwords.de/users/rafal-kuc

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,179 --> 00:00:08,250
hello everyone nice to see you here and

00:00:05,790 --> 00:00:11,280
welcome to do the second talk here in

00:00:08,250 --> 00:00:13,320
castle house I'll talk a bit on

00:00:11,280 --> 00:00:17,910
elasticsearch in doctor and how to run

00:00:13,320 --> 00:00:21,180
those two together to make use of them a

00:00:17,910 --> 00:00:23,910
briefly introduction I'm an engineer in

00:00:21,180 --> 00:00:27,269
semantics group I do trainings I'm a

00:00:23,910 --> 00:00:31,590
consultant basically all of person who

00:00:27,269 --> 00:00:37,010
goes all around the stack of our of our

00:00:31,590 --> 00:00:40,140
business and today we'll get on with

00:00:37,010 --> 00:00:42,300
three things first of all docker then

00:00:40,140 --> 00:00:43,950
elasticsearch and finally a few metrics

00:00:42,300 --> 00:00:48,539
at the end that you should pay attention

00:00:43,950 --> 00:00:51,270
to whatever running elasticsearch on a

00:00:48,539 --> 00:00:54,020
traditional bare metal on vm or in

00:00:51,270 --> 00:00:57,300
docker especially those were chosen for

00:00:54,020 --> 00:01:00,660
containers so first of all a few things

00:00:57,300 --> 00:01:03,059
about what we are used to right now so

00:01:00,660 --> 00:01:04,710
every one of us developers are used to

00:01:03,059 --> 00:01:07,770
the development environment when we do

00:01:04,710 --> 00:01:09,570
code we test this stuff initially then

00:01:07,770 --> 00:01:12,540
we get on with the test environment

00:01:09,570 --> 00:01:15,840
where people test stuff together right

00:01:12,540 --> 00:01:18,210
so we have parts of the application

00:01:15,840 --> 00:01:21,000
coming from multiple developers that are

00:01:18,210 --> 00:01:22,860
connected together and tests on some

00:01:21,000 --> 00:01:25,380
kind of test environment some larger

00:01:22,860 --> 00:01:28,320
organizations may allow and actually

00:01:25,380 --> 00:01:32,280
allow and do use quality assurance teams

00:01:28,320 --> 00:01:34,409
and QA environments where those are

00:01:32,280 --> 00:01:36,720
closer to production but still not there

00:01:34,409 --> 00:01:38,400
and people do test if something fails

00:01:36,720 --> 00:01:41,520
they get back to the test and

00:01:38,400 --> 00:01:43,590
development and the cycle goes on until

00:01:41,520 --> 00:01:47,299
we actually end up in the production

00:01:43,590 --> 00:01:51,299
environment where all those things run

00:01:47,299 --> 00:01:53,130
for our clients or for us depending on

00:01:51,299 --> 00:01:55,770
what the applications are the problems

00:01:53,130 --> 00:01:58,229
that come with it is there is at least

00:01:55,770 --> 00:02:01,350
three of them the main ones first of all

00:01:58,229 --> 00:02:03,840
the resources are not utilized in a 80

00:02:01,350 --> 00:02:06,329
or 90 or hundred percent way so that

00:02:03,840 --> 00:02:08,849
means that we are more or less losing

00:02:06,329 --> 00:02:12,450
money because if we over provision our

00:02:08,849 --> 00:02:13,530
servers like here we have some kind of

00:02:12,450 --> 00:02:15,900
processing power

00:02:13,530 --> 00:02:18,090
that we do not use and we do not want

00:02:15,900 --> 00:02:20,100
that of course some overhead is needed

00:02:18,090 --> 00:02:23,580
always right because we need to be

00:02:20,100 --> 00:02:26,420
prepared for those spikes in usage and

00:02:23,580 --> 00:02:29,580
all of that however still the

00:02:26,420 --> 00:02:32,010
over-provisioning is usually money that

00:02:29,580 --> 00:02:34,200
we lose and the final the third thing

00:02:32,010 --> 00:02:36,360
that we can talk about here is that

00:02:34,200 --> 00:02:38,069
those environments are usually not the

00:02:36,360 --> 00:02:40,890
same there are differences in the

00:02:38,069 --> 00:02:44,670
operating systems the libraries that

00:02:40,890 --> 00:02:47,580
they run the hardware itself so there

00:02:44,670 --> 00:02:52,350
are problems I suppose you all heard it

00:02:47,580 --> 00:02:54,870
works for me so and and I think this is

00:02:52,350 --> 00:02:57,239
a problematic way a problematic thing

00:02:54,870 --> 00:03:00,180
for developers to actually go there look

00:02:57,239 --> 00:03:02,910
okay this is a library problem let's fix

00:03:00,180 --> 00:03:05,610
it that let's update and go and go on

00:03:02,910 --> 00:03:08,519
with development so instead of running

00:03:05,610 --> 00:03:10,739
in a traditional bare metal or virtual

00:03:08,519 --> 00:03:13,400
machines we can put in our case

00:03:10,739 --> 00:03:16,830
elasticsearch in a container a small

00:03:13,400 --> 00:03:19,170
lightweight piece of software and put it

00:03:16,830 --> 00:03:21,540
on all of those environments in the same

00:03:19,170 --> 00:03:25,019
way with the same libraries and being

00:03:21,540 --> 00:03:27,720
sure that all of that will be run in the

00:03:25,019 --> 00:03:30,660
same manner but the question is why

00:03:27,720 --> 00:03:33,120
docker three things that I could think

00:03:30,660 --> 00:03:36,450
of is it's lightweight it's based on

00:03:33,120 --> 00:03:38,870
open standards and it's secure so more

00:03:36,450 --> 00:03:42,269
or less everything we need for running

00:03:38,870 --> 00:03:45,180
successful applications right and but

00:03:42,269 --> 00:03:46,980
why doctor again if we will look at the

00:03:45,180 --> 00:03:48,989
traditional virtual machine and how

00:03:46,980 --> 00:03:50,910
that's run we have a hardware layer at

00:03:48,989 --> 00:03:53,730
the bottom then we have a host operating

00:03:50,910 --> 00:03:55,739
system that runs the hardware that's

00:03:53,730 --> 00:03:59,010
something that we need on top of that we

00:03:55,739 --> 00:04:03,660
have a hypervisor process that controls

00:03:59,010 --> 00:04:06,299
the virtual machine and allows it to run

00:04:03,660 --> 00:04:08,880
guest operating systems those operating

00:04:06,299 --> 00:04:11,430
systems that are a part of each virtual

00:04:08,880 --> 00:04:13,049
machine this is an overhead of a virtual

00:04:11,430 --> 00:04:15,780
machine itself because it needs a

00:04:13,049 --> 00:04:17,370
separate operating system on top of that

00:04:15,780 --> 00:04:20,640
we have libraries for the application

00:04:17,370 --> 00:04:22,320
and finally the application itself this

00:04:20,640 --> 00:04:25,140
is how the traditional virtual machine

00:04:22,320 --> 00:04:27,010
stack looks like then we have the

00:04:25,140 --> 00:04:29,380
container stack that

00:04:27,010 --> 00:04:31,060
but the bottom looks very similar we

00:04:29,380 --> 00:04:32,860
have a hardware layer and the host

00:04:31,060 --> 00:04:37,000
operating system we can't get rid of

00:04:32,860 --> 00:04:39,580
that yet then we have more or less a

00:04:37,000 --> 00:04:41,530
hypervisor process in our case it will

00:04:39,580 --> 00:04:43,600
be a doctor in gene that controls the

00:04:41,530 --> 00:04:46,450
containers and allows them to actually

00:04:43,600 --> 00:04:48,730
run finally without the guest operating

00:04:46,450 --> 00:04:51,160
system we have a small lightweight

00:04:48,730 --> 00:04:53,560
container that instead of having the

00:04:51,160 --> 00:04:56,230
full operating system provides us only

00:04:53,560 --> 00:04:58,060
with the needed parts and allow us to

00:04:56,230 --> 00:05:00,970
quickly and easily deploy and run

00:04:58,060 --> 00:05:05,410
application with its libraries without

00:05:00,970 --> 00:05:08,230
any issues at all so as you can see we

00:05:05,410 --> 00:05:11,020
gain we remove the guest operating

00:05:08,230 --> 00:05:14,950
system from the equation and we gain

00:05:11,020 --> 00:05:17,920
some resources needed for running the

00:05:14,950 --> 00:05:20,590
Dead part of the of the stack why

00:05:17,920 --> 00:05:23,320
elasticsearch distributed by design

00:05:20,590 --> 00:05:26,020
based on the scene with great features

00:05:23,320 --> 00:05:29,020
lots of features search aggregation

00:05:26,020 --> 00:05:32,080
monitoring api's all the api's that

00:05:29,020 --> 00:05:34,420
allow you to control and work with the

00:05:32,080 --> 00:05:36,340
clusters themselves of course talk to

00:05:34,420 --> 00:05:39,010
the we talked to eat with JSON it

00:05:36,340 --> 00:05:44,590
responds with JSON and it has a REST API

00:05:39,010 --> 00:05:46,750
that's easily usable for us so now how

00:05:44,590 --> 00:05:48,310
to run elasticsearch on docker and again

00:05:46,750 --> 00:05:51,310
this is a very straightforward process

00:05:48,310 --> 00:05:53,200
we just type dr. run minus D and specify

00:05:51,310 --> 00:05:55,920
the name of the container which in our

00:05:53,200 --> 00:05:59,410
case is the official elasticsearch

00:05:55,920 --> 00:06:02,860
container and things start we can also

00:05:59,410 --> 00:06:04,480
run things like say latest or use the

00:06:02,860 --> 00:06:06,700
version that we are actually interested

00:06:04,480 --> 00:06:09,880
in like 2 point 0 or anything like that

00:06:06,700 --> 00:06:12,640
and things will do start automatically

00:06:09,880 --> 00:06:14,800
for us so dr. will download the needed

00:06:12,640 --> 00:06:17,110
container either from the official

00:06:14,800 --> 00:06:19,810
repositories or from private cab and

00:06:17,110 --> 00:06:23,080
we'll start the container itself we can

00:06:19,810 --> 00:06:26,560
also provide names for the containers so

00:06:23,080 --> 00:06:29,560
with they are easier to operate we can

00:06:26,560 --> 00:06:32,080
provide environment variables like

00:06:29,560 --> 00:06:35,080
having elasticsearch to use a certain

00:06:32,080 --> 00:06:37,330
keep like here with minus e switch and

00:06:35,080 --> 00:06:38,689
providing the proper environment

00:06:37,330 --> 00:06:41,449
variable

00:06:38,689 --> 00:06:43,519
understood by elasticsearch or provide

00:06:41,449 --> 00:06:46,839
some additional properties like here

00:06:43,519 --> 00:06:49,489
minus D nodename bebas which will make

00:06:46,839 --> 00:06:52,539
elasticsearch container use the node

00:06:49,489 --> 00:06:55,369
name and start a name with a given node

00:06:52,539 --> 00:06:59,779
that's the basics of running however

00:06:55,369 --> 00:07:02,479
when you run multiple containers on a

00:06:59,779 --> 00:07:04,610
single very metal machine because we

00:07:02,479 --> 00:07:06,619
usually want to do that because we want

00:07:04,610 --> 00:07:08,899
to maximize the usage of our hardware

00:07:06,619 --> 00:07:10,669
not to lose money we want to put some

00:07:08,899 --> 00:07:12,979
constraints on the containers so they

00:07:10,669 --> 00:07:15,379
are not using all of the resources that

00:07:12,979 --> 00:07:17,539
are available on the machine imagine

00:07:15,379 --> 00:07:20,959
that one of your containers ran into GC

00:07:17,539 --> 00:07:25,189
issues or memory or iOS or anything like

00:07:20,959 --> 00:07:28,610
that then it can eat up memory it can

00:07:25,189 --> 00:07:31,669
adapt CPUs and we don't want to do that

00:07:28,610 --> 00:07:33,829
we don't want it to do that so we can

00:07:31,669 --> 00:07:36,499
for example put constraints on the usage

00:07:33,829 --> 00:07:39,259
of the memory like with minus M switch

00:07:36,499 --> 00:07:41,479
and space and specify to G which means I

00:07:39,259 --> 00:07:45,889
container only use two gigabytes of

00:07:41,479 --> 00:07:48,079
memory at most we can disable swap or by

00:07:45,889 --> 00:07:49,579
the way all those all those constraints

00:07:48,079 --> 00:07:51,050
and commands are available in the

00:07:49,579 --> 00:07:53,689
reference documentation of da car

00:07:51,050 --> 00:07:55,159
engines so the link is in the bottom so

00:07:53,689 --> 00:07:58,879
you can look it up those are only

00:07:55,159 --> 00:08:01,579
examples in addition to that we have the

00:07:58,879 --> 00:08:04,939
availability of specifying which course

00:08:01,579 --> 00:08:07,939
of CPU we want we want to run with the

00:08:04,939 --> 00:08:10,819
container so we can only limit some if

00:08:07,939 --> 00:08:13,069
we have 24 core cpu like xion intel

00:08:10,819 --> 00:08:15,739
processors we can just say ok that

00:08:13,069 --> 00:08:18,289
container will use processing CPUs

00:08:15,739 --> 00:08:20,839
enumerated one and three and that's all

00:08:18,289 --> 00:08:23,239
nothing else in addition to that we can

00:08:20,839 --> 00:08:27,159
also put quote on the cpu further

00:08:23,239 --> 00:08:30,949
limiting down the number of cycles the

00:08:27,159 --> 00:08:32,839
container is a actually able to use the

00:08:30,949 --> 00:08:35,539
good practices around that is we should

00:08:32,839 --> 00:08:38,180
limit container memory because we don't

00:08:35,539 --> 00:08:40,430
want it to use all of that all of the

00:08:38,180 --> 00:08:42,759
memories the large amount of memories

00:08:40,430 --> 00:08:45,559
with having in our bare metal machines

00:08:42,759 --> 00:08:49,639
we should account for the i/o cash

00:08:45,559 --> 00:08:51,500
that's especially true for elastic

00:08:49,639 --> 00:08:52,440
search we should limit the amount of CPU

00:08:51,500 --> 00:08:54,170
cores room

00:08:52,440 --> 00:08:56,490
remembering about the garbage collector

00:08:54,170 --> 00:08:58,770
because if we don't remember about

00:08:56,490 --> 00:09:01,110
garbage collector and we only constraint

00:08:58,770 --> 00:09:03,360
on some amount of course for the

00:09:01,110 --> 00:09:05,790
container we may end up with container

00:09:03,360 --> 00:09:10,610
not being able to run properly because

00:09:05,790 --> 00:09:15,120
GC will start to give issues of course

00:09:10,610 --> 00:09:17,730
we can provide things like properties to

00:09:15,120 --> 00:09:20,160
elasticsearch when running the it in the

00:09:17,730 --> 00:09:22,140
docker container but we can also create

00:09:20,160 --> 00:09:24,770
our own images that are optimized for

00:09:22,140 --> 00:09:27,690
our use cases right so for example here

00:09:24,770 --> 00:09:30,450
we create the dockerfile something a

00:09:27,690 --> 00:09:33,090
file really really a text file called

00:09:30,450 --> 00:09:35,400
docker file and we specify it contents

00:09:33,090 --> 00:09:39,870
here it is a very very simple example of

00:09:35,400 --> 00:09:41,790
how you create an image actually so from

00:09:39,870 --> 00:09:44,700
elasticsearch means that it is from the

00:09:41,790 --> 00:09:46,590
official elasticsearch container and we

00:09:44,700 --> 00:09:48,330
will add a local file called elastic

00:09:46,590 --> 00:09:50,850
search gamble and put it in the

00:09:48,330 --> 00:09:53,040
configuration director of the good of

00:09:50,850 --> 00:09:55,680
the container then a simple build

00:09:53,040 --> 00:09:58,350
command will give us the ability to run

00:09:55,680 --> 00:10:04,770
to build the container and run it

00:09:58,350 --> 00:10:06,840
without further modifying that those

00:10:04,770 --> 00:10:08,970
work to thinks some configuration and

00:10:06,840 --> 00:10:11,490
constraints then we have to deal with

00:10:08,970 --> 00:10:14,940
memory by default the container doesn't

00:10:11,490 --> 00:10:17,970
expose any network outside of each of it

00:10:14,940 --> 00:10:19,680
running so whenever you run the elastic

00:10:17,970 --> 00:10:22,110
search on doctor and you try to for

00:10:19,680 --> 00:10:23,850
example go to localhost 9200 you won't

00:10:22,110 --> 00:10:27,210
be able to connect to that container and

00:10:23,850 --> 00:10:30,300
that's where port forwarding by 44

00:10:27,210 --> 00:10:32,580
docker gets into play with minus P we

00:10:30,300 --> 00:10:34,470
can tell which parts from the container

00:10:32,580 --> 00:10:36,690
should be exposed outside of the

00:10:34,470 --> 00:10:40,430
container itself here we exposed to

00:10:36,690 --> 00:10:43,650
ports 9200 for HTTP connectivity and

00:10:40,430 --> 00:10:46,950
9300 for transport client connectivity

00:10:43,650 --> 00:10:50,040
plastic surg now we'll be able to use

00:10:46,950 --> 00:10:53,160
the container outside of its own network

00:10:50,040 --> 00:10:55,650
in docker in addition to that we can

00:10:53,160 --> 00:10:58,160
lick link containers together to create

00:10:55,650 --> 00:11:02,040
a very simple plaster for example on

00:10:58,160 --> 00:11:04,110
local machine to do that we use the

00:11:02,040 --> 00:11:05,580
minus minus link and we provide the name

00:11:04,110 --> 00:11:09,060
of the container that we want

00:11:05,580 --> 00:11:11,310
the starting container to link to so

00:11:09,060 --> 00:11:14,100
here we link the container that will

00:11:11,310 --> 00:11:17,340
just run we'll try to run to the

00:11:14,100 --> 00:11:20,550
container called es1 and we specify the

00:11:17,340 --> 00:11:25,650
Zen unicast hosts for the container to

00:11:20,550 --> 00:11:28,350
actually know which elasticsearch node

00:11:25,650 --> 00:11:31,230
to connect to hear it would connect to

00:11:28,350 --> 00:11:33,990
the es one means meaning that they would

00:11:31,230 --> 00:11:37,290
actually create a cluster in addition to

00:11:33,990 --> 00:11:39,630
the when starting and when the discovery

00:11:37,290 --> 00:11:45,180
kicks in in elastic search whenever

00:11:39,630 --> 00:11:46,890
creating your own containers remember to

00:11:45,180 --> 00:11:49,290
add two things first the network

00:11:46,890 --> 00:11:51,540
published host and then the standard

00:11:49,290 --> 00:11:53,280
discoveries and ink unicast host to be

00:11:51,540 --> 00:11:57,420
able to actually connect multiple

00:11:53,280 --> 00:12:00,090
containers to each other next thing the

00:11:57,420 --> 00:12:05,160
good practices is about actually

00:12:00,090 --> 00:12:08,310
configuring a network to separate part

00:12:05,160 --> 00:12:11,070
of it for elasticsearch cluster use the

00:12:08,310 --> 00:12:14,130
common names for doctor and common host

00:12:11,070 --> 00:12:15,810
names so that you actually know when

00:12:14,130 --> 00:12:19,170
you're looking at the containers what's

00:12:15,810 --> 00:12:22,560
happening there expose only needed ports

00:12:19,170 --> 00:12:24,990
so don't expose any anything unless you

00:12:22,560 --> 00:12:28,860
need it this is good for security

00:12:24,990 --> 00:12:33,210
reasons and finally to have a good

00:12:28,860 --> 00:12:35,220
plaster and expose a sorry point the

00:12:33,210 --> 00:12:37,290
data and client notes only to the master

00:12:35,220 --> 00:12:40,080
node so they could connect to each other

00:12:37,290 --> 00:12:42,330
they don't need to see anything apart

00:12:40,080 --> 00:12:44,520
from that of course they will talk to

00:12:42,330 --> 00:12:48,780
each other internally but whenever

00:12:44,520 --> 00:12:51,990
starting up and when the discovery needs

00:12:48,780 --> 00:12:55,490
to actually run you need to only point

00:12:51,990 --> 00:12:59,400
the data and client notes to the masters

00:12:55,490 --> 00:13:03,000
mmm finally dealing with storage by

00:12:59,400 --> 00:13:04,740
default the data in your container will

00:13:03,000 --> 00:13:06,780
be stored in users share elasticsearch

00:13:04,740 --> 00:13:10,140
data however the problem that comes with

00:13:06,780 --> 00:13:12,210
it is that it is not persistent so

00:13:10,140 --> 00:13:15,990
whenever container goes down or you kill

00:13:12,210 --> 00:13:18,270
it the data will go away there are two

00:13:15,990 --> 00:13:19,379
things we can do first of all we can map

00:13:18,270 --> 00:13:21,959
the directories

00:13:19,379 --> 00:13:24,299
from the container to our local disks

00:13:21,959 --> 00:13:27,569
like here we map the user sure

00:13:24,299 --> 00:13:32,879
elasticsearch data to elasticsearch data

00:13:27,569 --> 00:13:34,769
on our local bare metal machine and it

00:13:32,879 --> 00:13:37,439
will stay that way and the data will be

00:13:34,769 --> 00:13:41,159
there keep in mind permissions you need

00:13:37,439 --> 00:13:44,039
to have properly set permissions for the

00:13:41,159 --> 00:13:46,229
inside process to be able to access the

00:13:44,039 --> 00:13:48,720
files on the disk of the or host

00:13:46,229 --> 00:13:51,809
operating system and the second thing is

00:13:48,720 --> 00:13:55,679
using sorry is using the data only

00:13:51,809 --> 00:13:58,139
docker volumes which are persisted and

00:13:55,679 --> 00:14:00,419
can be shared between containers so they

00:13:58,139 --> 00:14:02,279
bypass the Union file system then can be

00:14:00,419 --> 00:14:06,720
shared between containers as we just

00:14:02,279 --> 00:14:10,349
said and the container can be deleted

00:14:06,720 --> 00:14:13,470
and the data will still be persisted in

00:14:10,349 --> 00:14:16,379
a state on a disk inside as a separate

00:14:13,470 --> 00:14:19,379
volume container so how to create them

00:14:16,379 --> 00:14:22,649
it's as simple as running the following

00:14:19,379 --> 00:14:26,549
the following command docker create we

00:14:22,649 --> 00:14:29,369
map some part of the sorry some part of

00:14:26,549 --> 00:14:31,679
our local disk to that user share

00:14:29,369 --> 00:14:34,619
elasticsearch data we provide it with a

00:14:31,679 --> 00:14:38,009
name it's needed like here yes data this

00:14:34,619 --> 00:14:41,220
is the name of the container and finally

00:14:38,009 --> 00:14:43,409
when running docker and the proper

00:14:41,220 --> 00:14:46,259
container the elasticsearch container

00:14:43,409 --> 00:14:50,279
itself we can say volumes from and give

00:14:46,259 --> 00:14:53,759
that name and that we that we've used so

00:14:50,279 --> 00:14:56,129
that so that the container running

00:14:53,759 --> 00:15:01,709
elasticsearch will be you will be using

00:14:56,129 --> 00:15:04,439
the volume container that we've just

00:15:01,709 --> 00:15:08,629
created so this is about docker itself

00:15:04,439 --> 00:15:11,489
how to run highly available clusters on

00:15:08,629 --> 00:15:15,299
with elastic search remember about a few

00:15:11,489 --> 00:15:18,539
things first of all divided the roles of

00:15:15,299 --> 00:15:20,339
your notes so masternodes should there

00:15:18,539 --> 00:15:22,439
should be only master notes only data

00:15:20,339 --> 00:15:24,509
nodes and only client notes so master

00:15:22,439 --> 00:15:29,699
notes are not overloaded with the data

00:15:24,509 --> 00:15:31,949
and and color and sorry queries in

00:15:29,699 --> 00:15:32,889
addition to that remember about setting

00:15:31,949 --> 00:15:35,470
the minimum master

00:15:32,889 --> 00:15:38,350
notes2 fifty percent plus one master

00:15:35,470 --> 00:15:41,470
eligible notes that will help you with

00:15:38,350 --> 00:15:44,470
network splits and avoiding data

00:15:41,470 --> 00:15:45,730
corruption how to run those it's as

00:15:44,470 --> 00:15:48,220
simple as providing the proper

00:15:45,730 --> 00:15:50,769
parameters for the elastic search

00:15:48,220 --> 00:15:52,869
container on docker we said node master

00:15:50,769 --> 00:15:54,910
equals true no data equals false and

00:15:52,869 --> 00:15:57,609
note that the client equals false and we

00:15:54,910 --> 00:15:59,799
have a running master we do the same for

00:15:57,609 --> 00:16:03,279
the client and we can do the same for

00:15:59,799 --> 00:16:06,279
the data node just different different

00:16:03,279 --> 00:16:09,549
place to set to set true of course if

00:16:06,279 --> 00:16:11,549
we're running time based data which

00:16:09,549 --> 00:16:16,269
elasticsearch is great for we can also

00:16:11,549 --> 00:16:19,419
help each other meaning we and doctor

00:16:16,269 --> 00:16:22,720
can help us to run the multiple tiers in

00:16:19,419 --> 00:16:26,559
our architecture so usually you will end

00:16:22,720 --> 00:16:28,929
up with having cotton cold tears the hot

00:16:26,559 --> 00:16:32,259
code the hot air for the recent data

00:16:28,929 --> 00:16:35,559
real-time searches with all the with all

00:16:32,259 --> 00:16:39,100
the indexing happening and finally the

00:16:35,559 --> 00:16:42,249
cold data the archive for for for that

00:16:39,100 --> 00:16:45,100
however instead of creating different

00:16:42,249 --> 00:16:46,839
hardware how instead of putting

00:16:45,100 --> 00:16:49,299
different hardware there we can put

00:16:46,839 --> 00:16:52,809
different constraints on our containers

00:16:49,299 --> 00:16:55,720
and just say hey elasticsearch minus

00:16:52,809 --> 00:16:58,029
denote dot tag equals hot and then

00:16:55,720 --> 00:17:01,329
during index creation we just use the

00:16:58,029 --> 00:17:03,759
standard routing the location to put the

00:17:01,329 --> 00:17:06,069
index in a proper place now if the

00:17:03,759 --> 00:17:09,100
container has more cpus and more memory

00:17:06,069 --> 00:17:12,010
it can handle real time data well still

00:17:09,100 --> 00:17:15,159
have the same flexibility of moving

00:17:12,010 --> 00:17:18,250
containers around starting them stopping

00:17:15,159 --> 00:17:21,339
them on demand and all of that of course

00:17:18,250 --> 00:17:23,589
moving that data is also very easy as

00:17:21,339 --> 00:17:27,279
it's a part of elastic search api

00:17:23,589 --> 00:17:29,470
finally as i have 2 minutes left i would

00:17:27,279 --> 00:17:32,380
like to tell you a few things around

00:17:29,470 --> 00:17:36,210
metrics that you should take care about

00:17:32,380 --> 00:17:39,130
whenever dealing with containerized

00:17:36,210 --> 00:17:42,490
elasticsearch environment so first of

00:17:39,130 --> 00:17:46,120
all keep in mind that health api and

00:17:42,490 --> 00:17:48,630
charts API will give you the idea

00:17:46,120 --> 00:17:51,940
the top level view of the cluster

00:17:48,630 --> 00:17:54,400
monitor your CPU usage because that will

00:17:51,940 --> 00:17:57,010
help you knowing what's during the

00:17:54,400 --> 00:17:58,900
container halma how much stress you

00:17:57,010 --> 00:18:01,450
actually put on the container itself

00:17:58,900 --> 00:18:03,640
it's close to one hundred percent in

00:18:01,450 --> 00:18:05,740
usage that means that you don't have the

00:18:03,640 --> 00:18:07,630
overhead of spikes that's bad because

00:18:05,740 --> 00:18:10,030
elasticsearch and the cluster itself

00:18:07,630 --> 00:18:11,860
will crash whatever its bags happen or

00:18:10,030 --> 00:18:13,180
or you won't be able to use

00:18:11,860 --> 00:18:15,490
elasticsearch because it will be

00:18:13,180 --> 00:18:17,590
overloaded keep in mind that the memory

00:18:15,490 --> 00:18:20,830
usage is also helpful for you especially

00:18:17,590 --> 00:18:24,070
on the graphs where you can see if you

00:18:20,830 --> 00:18:25,780
need more memory more constraints loosen

00:18:24,070 --> 00:18:28,960
up the constraints for elastic search or

00:18:25,780 --> 00:18:31,240
not in addition to that I owe usage is

00:18:28,960 --> 00:18:33,880
again your friend because that will

00:18:31,240 --> 00:18:36,760
allow you to see and especially with the

00:18:33,880 --> 00:18:39,940
correlation with merges and requests

00:18:36,760 --> 00:18:42,130
rates with what's happening there if

00:18:39,940 --> 00:18:44,380
that's normal or maybe that spike there

00:18:42,130 --> 00:18:46,540
is about the merges and we have to do

00:18:44,380 --> 00:18:48,700
something about them loosen up and allow

00:18:46,540 --> 00:18:52,300
a longer tail of segments to be there

00:18:48,700 --> 00:18:55,059
for us to be properly running then the

00:18:52,300 --> 00:18:57,370
JVM heap and the garbage collection

00:18:55,059 --> 00:19:02,410
statistics allow us to see what's there

00:18:57,370 --> 00:19:04,870
in the memory of our JVMs and how the

00:19:02,410 --> 00:19:06,610
heap is actually being cleared up and

00:19:04,870 --> 00:19:12,610
how garbage collection works usually

00:19:06,610 --> 00:19:15,280
won't have fast but often and very fast

00:19:12,610 --> 00:19:18,160
garbage collection instead of one but

00:19:15,280 --> 00:19:22,480
longer which can lead us stop the world

00:19:18,160 --> 00:19:24,640
DC event request and latency allows us

00:19:22,480 --> 00:19:27,790
to actually see what how we are using

00:19:24,640 --> 00:19:30,429
our elasticsearch what's there if the

00:19:27,790 --> 00:19:32,620
spikes there is something we know that

00:19:30,429 --> 00:19:36,550
will occur on or something that happened

00:19:32,620 --> 00:19:38,960
and we should take a look in that if you

00:19:36,550 --> 00:19:42,230
are using

00:19:38,960 --> 00:19:45,740
a tool elasticsearch and dog values

00:19:42,230 --> 00:19:48,380
field data cache is mostly not an issue

00:19:45,740 --> 00:19:50,779
for you but if you still do analyze or

00:19:48,380 --> 00:19:53,510
if you still use aggregation or analyze

00:19:50,779 --> 00:19:57,380
fields keep in mind field data can kill

00:19:53,510 --> 00:19:59,450
you finally indexing again something to

00:19:57,380 --> 00:20:02,120
look for because you will probably get a

00:19:59,450 --> 00:20:05,390
lot of indexing in your clusters

00:20:02,120 --> 00:20:08,450
especially if you're doing analysis on

00:20:05,390 --> 00:20:11,179
time based data they tell the last ones

00:20:08,450 --> 00:20:14,059
the Refresh time which will help you

00:20:11,179 --> 00:20:16,220
with seeing if you are actually okay

00:20:14,059 --> 00:20:18,590
with refresh you have or if it's too

00:20:16,220 --> 00:20:22,270
often and how often it happens finally

00:20:18,590 --> 00:20:26,000
the merge time which will help you

00:20:22,270 --> 00:20:29,090
knowing what how your I always used and

00:20:26,000 --> 00:20:30,529
all of that so because we only have 20

00:20:29,090 --> 00:20:34,130
minutes I will do if you have any

00:20:30,529 --> 00:20:36,590
questions to me I would like you to get

00:20:34,130 --> 00:20:39,740
here i'll be here standing and I answer

00:20:36,590 --> 00:20:41,390
them all for now that's all thank you

00:20:39,740 --> 00:20:44,419
very much for listening I know it's been

00:20:41,390 --> 00:20:46,279
very short and fast but we only have 20

00:20:44,419 --> 00:20:48,020
minutes by the way if you keen on that

00:20:46,279 --> 00:20:50,870
stuff we are hiring at some attacks

00:20:48,020 --> 00:20:53,080
thank you and enjoy the rest of the

00:20:50,870 --> 00:20:53,080
conference

00:20:56,250 --> 00:21:00,970
in stuff I will take one question and

00:20:58,900 --> 00:21:09,160
then we have a short break before the

00:21:00,970 --> 00:21:12,330
next talk how do you supervise

00:21:09,160 --> 00:21:17,290
containers and how do you handle

00:21:12,330 --> 00:21:18,970
container failures actually that depends

00:21:17,290 --> 00:21:20,830
on what you actually want to do some how

00:21:18,970 --> 00:21:23,410
to handle contain your container

00:21:20,830 --> 00:21:25,600
failures right elasticsearch along with

00:21:23,410 --> 00:21:27,490
the container itself can be started

00:21:25,600 --> 00:21:29,050
without the niche for example if you

00:21:27,490 --> 00:21:32,320
have a monitoring software that will

00:21:29,050 --> 00:21:34,510
allow you to react on some kind of alert

00:21:32,320 --> 00:21:36,580
like nodes going down for example at

00:21:34,510 --> 00:21:39,040
bare metal server went down you can just

00:21:36,580 --> 00:21:41,890
spin up new containers at the perfect

00:21:39,040 --> 00:21:43,960
thing around elasticsearch that will be

00:21:41,890 --> 00:21:46,120
replicated the data will be replicated

00:21:43,960 --> 00:21:49,300
without any issues you can also use some

00:21:46,120 --> 00:21:52,360
kind of other more sophisticated

00:21:49,300 --> 00:21:54,130
solutions like metals and do the all

00:21:52,360 --> 00:21:56,080
that spinning up and scaling

00:21:54,130 --> 00:21:58,810
automatically so depending on what you

00:21:56,080 --> 00:22:00,670
actually want to use their you have an

00:21:58,810 --> 00:22:02,500
options for example meses is a good

00:22:00,670 --> 00:22:05,520
thing to look at if you would like to

00:22:02,500 --> 00:22:07,920
have something that automatically reacts

00:22:05,520 --> 00:22:11,200
towards being done with the containers

00:22:07,920 --> 00:22:13,840
right now but that's a different

00:22:11,200 --> 00:22:16,450
different topics oh yeah all right let's

00:22:13,840 --> 00:22:20,670
take the speaking again okay if you have

00:22:16,450 --> 00:22:20,670

YouTube URL: https://www.youtube.com/watch?v=D2zR-6Tke8o


