Title: Berlin Buzzwords 2016: Christoph Tavan - Live-Hack: Analyzing 7 years of Buzzwords at Scale #bbuzz
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	We're coming together for Berlin Buzzwords' 7th edition and over the course of the years a lot has changed in the Big Data Technology ecosystem. Once-hot buzzwords have vanished and new buzzwords arose.

While you would probably have written a MapReduce job in Java to crawl the web and analyze it on a massive scale this has now become much simpler with tools like Spark and Flink at hand.

I want to do a live coding session where I show that today it is possible to write a scalable web crawler and analytics tool which scrapes the past 6 years of Berlin Buzzwords (websites) and shows some interesting insights in the Big Data trends of the past 6 years. While I will run the tool on the very limited data set of the historical Berlin Buzzwords websites I want to highlight that it would in principle scale to crawl millions of websites and analyze petabytes of data.

Read more:

About Christoph Tavan:

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,270 --> 00:00:08,040
Jules okay thank you for the

00:00:05,370 --> 00:00:12,599
introduction and welcome so you're

00:00:08,040 --> 00:00:15,269
almost done last two sessions for today

00:00:12,599 --> 00:00:19,500
I hope you enjoyed this year's buzzword

00:00:15,269 --> 00:00:23,039
so far and my talk today is going to be

00:00:19,500 --> 00:00:26,150
something like a little recap of what

00:00:23,039 --> 00:00:29,550
happened over the last seven years

00:00:26,150 --> 00:00:33,870
because its seventh Burton buzz words so

00:00:29,550 --> 00:00:36,300
thank you ready for joining I wanted to

00:00:33,870 --> 00:00:40,980
start my talk with a little hands

00:00:36,300 --> 00:00:45,899
raising so for whom of you is this the

00:00:40,980 --> 00:00:49,440
first Berlin buzzwords okay quite a few

00:00:45,899 --> 00:00:53,480
and who did anyone of you attend the

00:00:49,440 --> 00:00:58,949
very first building buzz words in 2010

00:00:53,480 --> 00:01:03,120
12 cool and like something more than

00:00:58,949 --> 00:01:09,900
than than twice attending okay also

00:01:03,120 --> 00:01:11,729
quite a few so yeah I'm christov working

00:01:09,900 --> 00:01:14,340
as a CEO at mb are targeting we're a

00:01:11,729 --> 00:01:17,520
real-time bidding on an advertising

00:01:14,340 --> 00:01:20,250
company and I've been attending Berlin

00:01:17,520 --> 00:01:23,009
buzzword since 2012 so I missed the

00:01:20,250 --> 00:01:25,170
first two years but since then I've been

00:01:23,009 --> 00:01:32,970
a regular visitor and I've given my

00:01:25,170 --> 00:01:36,030
first talk last year and well it came to

00:01:32,970 --> 00:01:37,829
me that I was really wondering well now

00:01:36,030 --> 00:01:40,650
this conference is about buzz words but

00:01:37,829 --> 00:01:43,079
what were these buzzwords again over the

00:01:40,650 --> 00:01:45,840
last 10 years and I realized there are

00:01:43,079 --> 00:01:47,970
obviously some buzz words that were

00:01:45,840 --> 00:01:51,030
really like hot topics in one year and

00:01:47,970 --> 00:01:52,829
no one ever talked about it again in the

00:01:51,030 --> 00:01:54,720
locker in the next year and then there

00:01:52,829 --> 00:01:56,820
were other buzzwords who were like

00:01:54,720 --> 00:02:00,540
trending and becoming more and more

00:01:56,820 --> 00:02:03,840
important over the years so I don't know

00:02:00,540 --> 00:02:07,350
just to mention a few I put up some

00:02:03,840 --> 00:02:09,209
logos on this slide I don't know is

00:02:07,350 --> 00:02:11,370
anybody still talking about Apache

00:02:09,209 --> 00:02:13,780
mahout I remember it being a very

00:02:11,370 --> 00:02:16,380
important topic in two thousand

00:02:13,780 --> 00:02:18,880
12 when I joined for the first time

00:02:16,380 --> 00:02:20,620
similar for a pet GH bass on the other

00:02:18,880 --> 00:02:24,090
hand we have topics like link which is

00:02:20,620 --> 00:02:26,770
all over the place this year for example

00:02:24,090 --> 00:02:29,350
but I thought since we are like it's a

00:02:26,770 --> 00:02:32,709
tech called a tech conference and we

00:02:29,350 --> 00:02:35,100
were all sort of quantitative people it

00:02:32,709 --> 00:02:38,610
should actually be possible to answer

00:02:35,100 --> 00:02:41,650
this question in a quantitative way so

00:02:38,610 --> 00:02:46,830
what were the actual buzzwords 2010 2

00:02:41,650 --> 00:02:49,209
2016 let's try to quantify that and I

00:02:46,830 --> 00:02:51,330
think a lot of stuff has happened over

00:02:49,209 --> 00:02:53,650
the past seven years that will actually

00:02:51,330 --> 00:02:57,250
should actually make it fairly easy to

00:02:53,650 --> 00:03:01,360
analyze that so my plan for today is to

00:02:57,250 --> 00:03:03,580
basically scrape the websites of the

00:03:01,360 --> 00:03:07,180
seven conferences which are still

00:03:03,580 --> 00:03:10,450
available on sub domains under building

00:03:07,180 --> 00:03:13,900
buzz words d and then extract and

00:03:10,450 --> 00:03:19,630
analyze the buzzwords so yeah that's the

00:03:13,900 --> 00:03:24,160
plan for today and yeah sure I want to

00:03:19,630 --> 00:03:27,100
do that live I want to kind of see if I

00:03:24,160 --> 00:03:28,510
can can do it in a scalable manner and I

00:03:27,100 --> 00:03:33,640
have something like 30 minutes to do

00:03:28,510 --> 00:03:39,060
that so let's see if you can if we can

00:03:33,640 --> 00:03:43,900
manage so first step will be scraped the

00:03:39,060 --> 00:03:45,310
historic websites so if you want to do

00:03:43,900 --> 00:03:48,880
web scraping there are basically two

00:03:45,310 --> 00:03:51,400
options in general you can either simply

00:03:48,880 --> 00:03:54,070
create everything and then try to filter

00:03:51,400 --> 00:03:58,269
and make sense out of your content later

00:03:54,070 --> 00:04:00,220
this is particularly or I would say this

00:03:58,269 --> 00:04:02,350
is the approach when you basically don't

00:04:00,220 --> 00:04:04,359
know yet what you're looking for in

00:04:02,350 --> 00:04:06,519
particular you have no idea about the

00:04:04,359 --> 00:04:10,150
structure of the content that you will

00:04:06,519 --> 00:04:14,590
be scraping or you can do the more like

00:04:10,150 --> 00:04:16,930
a tailored targeted away or like the

00:04:14,590 --> 00:04:20,289
more manual way if you already know what

00:04:16,930 --> 00:04:22,090
you're looking for then you can

00:04:20,289 --> 00:04:23,650
basically try to only scrape that

00:04:22,090 --> 00:04:26,400
content that you're really interested in

00:04:23,650 --> 00:04:26,400
in the first place

00:04:26,410 --> 00:04:32,680
I mean they're of course tons of am I

00:04:29,740 --> 00:04:35,470
still there yeah okay so there of course

00:04:32,680 --> 00:04:36,940
lots of options that are open source

00:04:35,470 --> 00:04:41,250
projects that help you help you with

00:04:36,940 --> 00:04:45,250
this so I mean I think one of the most

00:04:41,250 --> 00:04:48,490
well-known software projects for

00:04:45,250 --> 00:04:51,010
scraping which has been there ever since

00:04:48,490 --> 00:04:53,290
we were talking about Hadoop stuff is

00:04:51,010 --> 00:04:56,640
Apache notch it's still an active

00:04:53,290 --> 00:04:58,900
development and it's really like

00:04:56,640 --> 00:05:03,490
probably the first choice if you want to

00:04:58,900 --> 00:05:05,560
do a large-scale web scraping with an

00:05:03,490 --> 00:05:09,040
open source project but then there are

00:05:05,560 --> 00:05:13,080
smaller more tailored or like then

00:05:09,040 --> 00:05:16,510
there's a solution for like this more

00:05:13,080 --> 00:05:19,330
targeted scraping approach that I found

00:05:16,510 --> 00:05:22,060
which is Python library called scrapie

00:05:19,330 --> 00:05:25,600
or scrape I I don't know how that's

00:05:22,060 --> 00:05:29,530
pronounced so while the notch one is

00:05:25,600 --> 00:05:31,480
definitely the huge scalable thing I

00:05:29,530 --> 00:05:34,810
think for scraping the Berlin buzzwords

00:05:31,480 --> 00:05:39,670
websites the other one will do as well

00:05:34,810 --> 00:05:41,740
so here I'm going to use scrapy and it's

00:05:39,670 --> 00:05:44,580
actually pretty well-documented very

00:05:41,740 --> 00:05:49,660
nice project so this is taken from the

00:05:44,580 --> 00:05:53,460
home page and you all you need to do

00:05:49,660 --> 00:05:58,300
basically to run your own scrapers is to

00:05:53,460 --> 00:06:01,600
extend a spider a class that that's

00:05:58,300 --> 00:06:03,460
create exposes and then you specify some

00:06:01,600 --> 00:06:07,030
start URLs whereas cape scrape it will

00:06:03,460 --> 00:06:10,180
start and you specify at ours method

00:06:07,030 --> 00:06:14,890
that part is the content of this side

00:06:10,180 --> 00:06:16,540
and tells crappy what to do for example

00:06:14,890 --> 00:06:17,980
with the links that are found if those

00:06:16,540 --> 00:06:23,380
things shall be followed and so on and

00:06:17,980 --> 00:06:25,990
so forth and then here you can specify a

00:06:23,380 --> 00:06:31,140
call back of what scrape you should

00:06:25,990 --> 00:06:31,140
shall do if it visited a link and

00:06:31,690 --> 00:06:42,260
let me see so I've written can you read

00:06:40,190 --> 00:06:50,830
that actually shall I make it a big bit

00:06:42,260 --> 00:06:57,320
bigger or bigger better still bigger

00:06:50,830 --> 00:07:00,800
okay so yeah all I need to do is define

00:06:57,320 --> 00:07:07,700
this class or extend to crawl spider

00:07:00,800 --> 00:07:10,070
class then here I basically specify

00:07:07,700 --> 00:07:12,560
allowed domains which is basically just

00:07:10,070 --> 00:07:15,800
to make sure that my crawler doesn't

00:07:12,560 --> 00:07:18,500
leave the Berlin buzzwords website and I

00:07:15,800 --> 00:07:21,220
specify the start URLs where I basically

00:07:18,500 --> 00:07:28,600
explicitly put all the prefixes from

00:07:21,220 --> 00:07:28,600
2010 2 2016 which is available under www

00:07:29,260 --> 00:07:36,920
and then there is some more magic which

00:07:31,880 --> 00:07:40,550
I will talk about in a minute but what

00:07:36,920 --> 00:07:43,400
that all ends up with is a parse method

00:07:40,550 --> 00:07:46,550
that parses the HTML content of these of

00:07:43,400 --> 00:07:48,560
these sites and amid some data and as

00:07:46,550 --> 00:07:50,540
you can already see here I'm looking for

00:07:48,560 --> 00:07:53,180
some very particular data so I'm looking

00:07:50,540 --> 00:07:55,160
for the title of the page and i'm

00:07:53,180 --> 00:07:58,580
particularly looking for the session

00:07:55,160 --> 00:08:00,080
abstract pages actually I'm looking for

00:07:58,580 --> 00:08:02,960
the content which is basically the

00:08:00,080 --> 00:08:06,620
session abstract and I'm also extracting

00:08:02,960 --> 00:08:08,840
the speakers of these sessions and I'm

00:08:06,620 --> 00:08:15,890
also storing the link so more about that

00:08:08,840 --> 00:08:23,570
later so since that will take a moment

00:08:15,890 --> 00:08:27,590
let me just run this in the background

00:08:23,570 --> 00:08:31,930
so as you can see this is the class that

00:08:27,590 --> 00:08:31,930
I just showed you and I will now

00:08:32,530 --> 00:08:39,500
activate my virtual environment and then

00:08:35,210 --> 00:08:41,600
I will run this spider so it comes with

00:08:39,500 --> 00:08:44,169
a tool called sporadic Scrappy's as run

00:08:41,600 --> 00:08:49,060
spider I just have to provide my

00:08:44,169 --> 00:08:58,360
class and I can specify an s3 location

00:08:49,060 --> 00:09:02,290
as an output so okay so while I will

00:08:58,360 --> 00:09:04,810
continue with some some slides hopefully

00:09:02,290 --> 00:09:08,560
it's greatly will now crawl all the web

00:09:04,810 --> 00:09:11,320
pages from 2010 to this year in the

00:09:08,560 --> 00:09:21,550
background and place the results on an

00:09:11,320 --> 00:09:24,370
s3 bucket all right while trying that

00:09:21,550 --> 00:09:28,480
out I actually realized that scraping

00:09:24,370 --> 00:09:31,720
web pages is still quite hard and so for

00:09:28,480 --> 00:09:36,190
example I realized that the website from

00:09:31,720 --> 00:09:37,949
2010 2 2012 didn't come with the

00:09:36,190 --> 00:09:40,930
content-type header I mean you can't

00:09:37,949 --> 00:09:43,899
read it here but simply the response

00:09:40,930 --> 00:09:46,029
header content type is missing and that

00:09:43,899 --> 00:09:48,640
makes greatly think it's not a web page

00:09:46,029 --> 00:09:51,490
but something else and it will simply

00:09:48,640 --> 00:09:54,339
not pars it so one of the additional

00:09:51,490 --> 00:09:57,930
code that you saw in the in that crappy

00:09:54,339 --> 00:10:01,089
file was actually a workaround to

00:09:57,930 --> 00:10:05,769
artificially set this HTTP header for

00:10:01,089 --> 00:10:08,589
these old web pages then another thing

00:10:05,769 --> 00:10:11,800
which actually wasn't that easy was to

00:10:08,589 --> 00:10:13,660
identify what page is actually a session

00:10:11,800 --> 00:10:16,120
abstract page because I want to restrict

00:10:13,660 --> 00:10:19,870
myself to the session abstracts and the

00:10:16,120 --> 00:10:22,480
analysis and and what is not and I

00:10:19,870 --> 00:10:25,839
initially thought well there is a an

00:10:22,480 --> 00:10:28,390
element within CSS class this date

00:10:25,839 --> 00:10:31,569
display single and it turns out to be

00:10:28,390 --> 00:10:35,260
there in two thousand ten and eleven but

00:10:31,569 --> 00:10:37,949
not 12 and 13 and so on so but there are

00:10:35,260 --> 00:10:40,959
other fields that actually show that so

00:10:37,949 --> 00:10:45,639
figure that out how to identify a

00:10:40,959 --> 00:10:49,089
session page same for the speaker how do

00:10:45,639 --> 00:10:50,470
i get the speaker again is it one filled

00:10:49,089 --> 00:10:52,630
in all the pages no apparently

00:10:50,470 --> 00:10:57,699
technology has changed in the meantime

00:10:52,630 --> 00:11:04,679
so i have different selectors for

00:10:57,699 --> 00:11:10,839
different years and then as well for the

00:11:04,679 --> 00:11:17,350
session abstract it was also hidden in

00:11:10,839 --> 00:11:24,569
different HTML elements so let me check

00:11:17,350 --> 00:11:24,569
how scrape he's doing it's still working

00:11:26,220 --> 00:11:39,999
okay so I have one suggestion to well or

00:11:36,009 --> 00:11:41,889
first of all I can draw an intermediate

00:11:39,999 --> 00:11:45,519
conclusion that basically scraping the

00:11:41,889 --> 00:11:47,109
web is still pretty hard even in 2016

00:11:45,519 --> 00:11:51,879
especially if you're trying to scrape

00:11:47,109 --> 00:11:54,939
content which is made available in a

00:11:51,879 --> 00:11:58,869
form that not that's not very scraper

00:11:54,939 --> 00:12:03,059
friendly so actually it does make sense

00:11:58,869 --> 00:12:06,249
to structure web pages with proper HTML

00:12:03,059 --> 00:12:09,699
so that they can so that actually also

00:12:06,249 --> 00:12:12,249
machines can understand them and i think

00:12:09,699 --> 00:12:14,139
it's a it's quite an impressive job that

00:12:12,249 --> 00:12:17,049
search engine companies like Google and

00:12:14,139 --> 00:12:20,199
so on are doing by still being able to

00:12:17,049 --> 00:12:25,980
somehow make sense out of not so well

00:12:20,199 --> 00:12:31,109
designed HTML pages yeah let's see if

00:12:25,980 --> 00:12:35,639
the content is there now so it isn't I

00:12:31,109 --> 00:12:41,169
suggest not to not lose lose any time I

00:12:35,639 --> 00:12:43,839
will simply use a file that I have

00:12:41,169 --> 00:12:45,429
crawled before i was expecting myself to

00:12:43,839 --> 00:12:46,689
take a little longer talking so that

00:12:45,429 --> 00:12:50,859
scrape you could finish in the

00:12:46,689 --> 00:12:54,489
background but instead i want to

00:12:50,859 --> 00:12:55,809
continue with the analysis and that

00:12:54,489 --> 00:13:05,109
should be the empty more interesting

00:12:55,809 --> 00:13:07,679
part so to analyze that data i was

00:13:05,109 --> 00:13:11,110
actually looking for a suitable a

00:13:07,679 --> 00:13:11,379
suitable solution to do that in a way

00:13:11,110 --> 00:13:14,829
with

00:13:11,379 --> 00:13:17,199
which can be easily presented so a few

00:13:14,829 --> 00:13:20,859
years ago interactive notebooks came up

00:13:17,199 --> 00:13:23,470
which allow you to manipulate data and

00:13:20,859 --> 00:13:27,279
have some sort of distributed computing

00:13:23,470 --> 00:13:31,059
engine in the background so you edit

00:13:27,279 --> 00:13:33,129
your data as if or you you you and can

00:13:31,059 --> 00:13:35,729
analyze the data as if it was like on

00:13:33,129 --> 00:13:39,039
your local machine but in fact you have

00:13:35,729 --> 00:13:40,509
an arbitrarily big cluster in the

00:13:39,039 --> 00:13:42,939
background that does the actual

00:13:40,509 --> 00:13:46,089
computations but still you get your

00:13:42,939 --> 00:13:49,799
results back in a very nice way and

00:13:46,089 --> 00:13:52,509
there are some commercial solutions

00:13:49,799 --> 00:13:55,239
which I just listed here but there are

00:13:52,509 --> 00:13:58,269
also very great open-source alternatives

00:13:55,239 --> 00:14:02,139
like Jupiter which was previously known

00:13:58,269 --> 00:14:04,499
as ipython notebooks or Zeppelin is a is

00:14:02,139 --> 00:14:07,929
a very young and promising project and

00:14:04,499 --> 00:14:09,909
if you're intending to use spark there's

00:14:07,929 --> 00:14:12,519
a project called spark notebook where

00:14:09,909 --> 00:14:14,169
you can download a whole bundle which

00:14:12,519 --> 00:14:16,929
includes spark and everything else and

00:14:14,169 --> 00:14:20,259
you just unzip it and run it and you

00:14:16,929 --> 00:14:23,409
have a fully running low local of course

00:14:20,259 --> 00:14:25,659
in that case a spark notebook so I mean

00:14:23,409 --> 00:14:27,989
the dropping of these open source things

00:14:25,659 --> 00:14:30,549
is of course that you have to somehow

00:14:27,989 --> 00:14:35,619
provide urine the infrastructure on your

00:14:30,549 --> 00:14:41,379
own but it's open source and for those

00:14:35,619 --> 00:14:42,729
commercial solutions they will provide

00:14:41,379 --> 00:14:46,959
you with the infrastructure and you

00:14:42,729 --> 00:14:52,269
basically have a cloud like paper paper

00:14:46,959 --> 00:14:56,199
use pricing usually and for my analysis

00:14:52,269 --> 00:14:59,919
I will I made some very arbitrary choice

00:14:56,199 --> 00:15:04,859
and I pick data bricks which is a made

00:14:59,919 --> 00:15:04,859
by the people behind apache spark and i

00:15:05,249 --> 00:15:12,279
will now switch over to that so i will

00:15:10,299 --> 00:15:14,319
follow the Golden Rule and as its shown

00:15:12,279 --> 00:15:16,089
in Wikipedia it says you should always

00:15:14,319 --> 00:15:20,100
do live coding during conference talks

00:15:16,089 --> 00:15:24,189
and I will do that now and hope that

00:15:20,100 --> 00:15:24,970
internet connection will work ok as you

00:15:24,189 --> 00:15:28,329
see

00:15:24,970 --> 00:15:34,170
rape is still not finished so I will use

00:15:28,329 --> 00:15:37,899
the file which I have always great so

00:15:34,170 --> 00:15:42,310
this is how it looks like a better I

00:15:37,899 --> 00:15:44,740
have to make it bigger again it's it's a

00:15:42,310 --> 00:15:48,850
notebook you can write commands there

00:15:44,740 --> 00:15:52,060
they're executed server side and you get

00:15:48,850 --> 00:15:55,240
the presentation of the results so all I

00:15:52,060 --> 00:15:58,689
did so far was preparing it with some

00:15:55,240 --> 00:16:02,410
imports some import statements which I

00:15:58,689 --> 00:16:04,899
will run now and the first time I run

00:16:02,410 --> 00:16:07,540
something I'm being asked if I want to

00:16:04,899 --> 00:16:12,420
spoil a cluster and i'm here on the

00:16:07,540 --> 00:16:12,420
Community Edition which will launch some

00:16:12,660 --> 00:16:19,389
spark one point six point one cluster

00:16:15,639 --> 00:16:22,870
with six gigabytes of RAM and I think

00:16:19,389 --> 00:16:24,370
it's all running on on AWS but in the

00:16:22,870 --> 00:16:29,290
paid version you can basically spawn

00:16:24,370 --> 00:16:33,730
arbitrarily big clusters in there okay

00:16:29,290 --> 00:16:36,730
that's it then in the next field i have

00:16:33,730 --> 00:16:39,819
my AWS credentials which i have hidden

00:16:36,730 --> 00:16:43,740
here and then this is basically some

00:16:39,819 --> 00:16:46,509
code which i copied from the data bricks

00:16:43,740 --> 00:16:51,550
documentation which is what would shows

00:16:46,509 --> 00:16:53,800
you how to import your data i will give

00:16:51,550 --> 00:16:56,740
it a last ride oh it's crappy finished

00:16:53,800 --> 00:17:02,110
so after six minutes bit slower than

00:16:56,740 --> 00:17:04,209
than before scraping managed to to

00:17:02,110 --> 00:17:09,520
scrape all the websites from last seven

00:17:04,209 --> 00:17:15,030
years and it put the stuff into an s3

00:17:09,520 --> 00:17:18,610
bucket be bus 2016 as you can see here

00:17:15,030 --> 00:17:23,679
and it's simply json objects line

00:17:18,610 --> 00:17:32,500
separated so i can actually mount this

00:17:23,679 --> 00:17:33,670
bucket in data bricks which is what this

00:17:32,500 --> 00:17:36,670
code does

00:17:33,670 --> 00:17:39,700
well it's frozen exception here because

00:17:36,670 --> 00:17:49,620
director is already mounted and I can

00:17:39,700 --> 00:17:56,320
have a look at the contents so oh okay

00:17:49,620 --> 00:18:00,130
seems like I didn't set the AWS

00:17:56,320 --> 00:18:04,810
credentials correctly so my data is not

00:18:00,130 --> 00:18:15,880
there i will then instead use a

00:18:04,810 --> 00:18:22,020
different bucket where i have this all

00:18:15,880 --> 00:18:26,320
years jason lines file which i wanted to

00:18:22,020 --> 00:18:31,480
to put into that bucket still available

00:18:26,320 --> 00:18:35,590
sorry for that okay so i have my bucket

00:18:31,480 --> 00:18:37,990
with this file first thing i want to do

00:18:35,590 --> 00:18:41,050
is reading that file because i want to

00:18:37,990 --> 00:18:46,510
work with that data so i will go ahead

00:18:41,050 --> 00:18:50,980
and say i will use the sparks equal

00:18:46,510 --> 00:18:53,530
context here it's a nice nice rather new

00:18:50,980 --> 00:18:58,240
interface of spark which allows you to

00:18:53,530 --> 00:19:02,130
do sequel like and also data frame like

00:18:58,240 --> 00:19:07,890
operations on your data and it has a

00:19:02,130 --> 00:19:19,000
read Jason method which I can use to

00:19:07,890 --> 00:19:24,790
read this Jason phone and then I can

00:19:19,000 --> 00:19:28,320
basically register this data as a temp

00:19:24,790 --> 00:19:33,420
table and let's call it be both raw and

00:19:28,320 --> 00:19:37,210
then I can go ahead and say display

00:19:33,420 --> 00:19:40,150
something like sequel contacts dot

00:19:37,210 --> 00:19:42,760
sequel and then i can type any sequel

00:19:40,150 --> 00:19:46,210
command and can treat it just like as if

00:19:42,760 --> 00:19:47,430
it was a likely database table so i can

00:19:46,210 --> 00:19:55,480
say

00:19:47,430 --> 00:20:05,530
star from bee buzz roll limit 10 like

00:19:55,480 --> 00:20:09,610
that and in fact it shows me the data so

00:20:05,530 --> 00:20:13,060
what I realize here is that apparently

00:20:09,610 --> 00:20:15,580
in the scraping it didn't work perfectly

00:20:13,060 --> 00:20:18,460
well so I don't only have session pages

00:20:15,580 --> 00:20:23,050
here but I apparently also have user

00:20:18,460 --> 00:20:26,920
pages so let's maybe look at that in a

00:20:23,050 --> 00:20:37,900
bit more detail where content not equals

00:20:26,920 --> 00:20:43,320
empty okay but now I have I already see

00:20:37,900 --> 00:20:46,270
that that I have session abstracts here

00:20:43,320 --> 00:20:51,070
so maybe some of you saw this learning

00:20:46,270 --> 00:20:53,650
to rank talked earlier this day okay and

00:20:51,070 --> 00:20:56,970
now I want to go ahead and and really

00:20:53,650 --> 00:21:00,640
draw some conclusions from this data so

00:20:56,970 --> 00:21:03,000
if you want to do natural language

00:21:00,640 --> 00:21:06,070
processing I mean oh there are of course

00:21:03,000 --> 00:21:07,240
great great alternatives for dads so

00:21:06,070 --> 00:21:10,180
there are natural language processing

00:21:07,240 --> 00:21:15,340
libraries that help you with tokenizing

00:21:10,180 --> 00:21:17,080
and cleaning up your your string that

00:21:15,340 --> 00:21:20,620
would be a little bit overkill for this

00:21:17,080 --> 00:21:24,820
talk so I will simply go ahead and just

00:21:20,620 --> 00:21:29,230
apply some very simple transformations

00:21:24,820 --> 00:21:30,970
on this text to be able to get a get

00:21:29,230 --> 00:21:34,660
some meaning meaningful results all of

00:21:30,970 --> 00:21:37,900
it so basically first thing I want to do

00:21:34,660 --> 00:21:39,760
is because I want to count words later

00:21:37,900 --> 00:21:46,630
and find out which we're actually the

00:21:39,760 --> 00:21:50,170
the buzzwords in the years I will first

00:21:46,630 --> 00:21:54,400
of all lower case the contents to not

00:21:50,170 --> 00:21:59,080
like to not have any problems with with

00:21:54,400 --> 00:22:04,380
case sensitiveness well then

00:21:59,080 --> 00:22:09,220
as you can see there are still lots of

00:22:04,380 --> 00:22:13,960
yeah lots of dots and commas and so on

00:22:09,220 --> 00:22:15,700
which are of course also posing some

00:22:13,960 --> 00:22:19,600
problems when when you want to when you

00:22:15,700 --> 00:22:26,679
want to analyze the text so let's remove

00:22:19,600 --> 00:22:30,580
that to not stress your your time too

00:22:26,679 --> 00:22:34,600
much i will copy some code which does

00:22:30,580 --> 00:22:42,010
that so here i have prepared some code

00:22:34,600 --> 00:22:45,370
which basically all that it does it runs

00:22:42,010 --> 00:22:47,620
a regular expression and its first of

00:22:45,370 --> 00:22:50,710
all substitutes all multiple white

00:22:47,620 --> 00:22:53,289
spaces by one white space and what it

00:22:50,710 --> 00:22:56,769
does as well is it basically substitutes

00:22:53,289 --> 00:23:01,899
any character that is not like a number

00:22:56,769 --> 00:23:04,120
or a letter yeah it just removes them

00:23:01,899 --> 00:23:09,250
and it also removes trailing and leading

00:23:04,120 --> 00:23:11,289
spaces and like spark sequel has it has

00:23:09,250 --> 00:23:13,480
a nice or as it has a pretty easy way to

00:23:11,289 --> 00:23:16,210
register user defined functions you

00:23:13,480 --> 00:23:20,049
simply say sequel context register

00:23:16,210 --> 00:23:22,299
function and then you can register any

00:23:20,049 --> 00:23:24,820
arbitrary a Python function that you

00:23:22,299 --> 00:23:27,789
defined here and you can later apply it

00:23:24,820 --> 00:23:29,889
in a sequel query so that's basically

00:23:27,789 --> 00:23:32,409
what's being done here so I registered

00:23:29,889 --> 00:23:38,139
at cleaning function and I use it here

00:23:32,409 --> 00:23:44,289
in the sequel expression I can run that

00:23:38,139 --> 00:23:46,029
again ok as you can see comparing to

00:23:44,289 --> 00:23:49,059
here so you have learning to rank and

00:23:46,029 --> 00:23:59,440
then like parentheses and a comma and so

00:23:49,059 --> 00:24:02,139
on this now all has been removed and it

00:23:59,440 --> 00:24:04,450
already looks much better so if I would

00:24:02,139 --> 00:24:06,250
run a word count on that now I would of

00:24:04,450 --> 00:24:10,040
course have a problem at all these stop

00:24:06,250 --> 00:24:12,560
words like off and in and and

00:24:10,040 --> 00:24:18,170
so on and so forth would definitely be

00:24:12,560 --> 00:24:22,100
the highest-ranking words so I'm going

00:24:18,170 --> 00:24:24,050
to go ahead and remove stop words and I

00:24:22,100 --> 00:24:31,480
also don't want to bore you too much and

00:24:24,050 --> 00:24:34,160
we'll copy some more code so data breaks

00:24:31,480 --> 00:24:39,890
provides the stop words file and some of

00:24:34,160 --> 00:24:50,300
their s3 buckets so I just use that can

00:24:39,890 --> 00:24:56,420
I have a look at it oh yes ah so you can

00:24:50,300 --> 00:24:59,470
see typical list of stop words and I

00:24:56,420 --> 00:25:07,550
define another function which will

00:24:59,470 --> 00:25:10,940
simply remove those toppers so like the

00:25:07,550 --> 00:25:13,550
naive way would be to simply nest these

00:25:10,940 --> 00:25:17,060
user-defined functions in the sparks

00:25:13,550 --> 00:25:19,340
equal expression but unfortunately that

00:25:17,060 --> 00:25:23,930
doesn't work because there is a balance

00:25:19,340 --> 00:25:27,920
park it's it's known and not yet fixed

00:25:23,930 --> 00:25:31,960
and so unfortunately I have to register

00:25:27,920 --> 00:25:34,550
another rapper which I called clear all

00:25:31,960 --> 00:25:36,740
which will nest my user defined

00:25:34,550 --> 00:25:40,340
functions so first of all it will clean

00:25:36,740 --> 00:25:46,480
the string then second it will remove

00:25:40,340 --> 00:25:52,970
the stopper and I can run this again and

00:25:46,480 --> 00:25:59,200
I should already have a much better text

00:25:52,970 --> 00:26:02,060
that I can now finally analyzed there's

00:25:59,200 --> 00:26:04,100
another thing which I want to get rid of

00:26:02,060 --> 00:26:08,330
and i will also just copy and paste that

00:26:04,100 --> 00:26:10,490
it's a called limit limit ization so you

00:26:08,330 --> 00:26:12,530
have plurals and singular of the same

00:26:10,490 --> 00:26:16,490
word and I have a very cheap version

00:26:12,530 --> 00:26:20,840
here so i just want to remove all the SS

00:26:16,490 --> 00:26:25,010
in the end of in the end

00:26:20,840 --> 00:26:32,029
of a word so that I don't have these as

00:26:25,010 --> 00:26:34,789
two two words so I don't know where

00:26:32,029 --> 00:26:38,950
whoops compa companies that's of course

00:26:34,789 --> 00:26:48,260
a bad example because it will groups ah

00:26:38,950 --> 00:26:50,600
because it will where was it never mind

00:26:48,260 --> 00:26:53,029
you you get the picture so I just don't

00:26:50,600 --> 00:26:55,399
want to want to have the plural and

00:26:53,029 --> 00:26:57,799
singular of the same word being counted

00:26:55,399 --> 00:26:59,840
as two different words and then final

00:26:57,799 --> 00:27:03,440
step and I promise this is the last one

00:26:59,840 --> 00:27:05,510
in the preparation phase and there again

00:27:03,440 --> 00:27:09,320
I mean there are probably of course

00:27:05,510 --> 00:27:11,330
libraries for that that helps you like

00:27:09,320 --> 00:27:13,250
detecting that something like big data

00:27:11,330 --> 00:27:14,990
should not be treated as big and data

00:27:13,250 --> 00:27:17,510
and open source should not be treated as

00:27:14,990 --> 00:27:21,860
open and source but instead as one token

00:27:17,510 --> 00:27:28,880
and I have a very cheap variant of that

00:27:21,860 --> 00:27:32,870
which I will simply run okay so finally

00:27:28,880 --> 00:27:41,179
we should have some rather clean content

00:27:32,870 --> 00:27:44,840
and I will now go ahead and from my

00:27:41,179 --> 00:27:47,059
initially scraped raw content I will

00:27:44,840 --> 00:27:50,779
create a new table which contains the

00:27:47,059 --> 00:27:54,649
clean version of it so I select the link

00:27:50,779 --> 00:27:56,899
the speakers I extract with this

00:27:54,649 --> 00:28:01,490
impression the year from the link and i

00:27:56,899 --> 00:28:04,549
clear I clean the the title and the

00:28:01,490 --> 00:28:06,620
content and I concatenate title and

00:28:04,549 --> 00:28:16,669
content into a body which I will now

00:28:06,620 --> 00:28:19,039
analyze oops already better but still

00:28:16,669 --> 00:28:21,919
okay we still have these users pages in

00:28:19,039 --> 00:28:27,380
here so we should filter them out as

00:28:21,919 --> 00:28:32,720
well and there is another expression for

00:28:27,380 --> 00:28:34,580
that fairly simple which simply simply

00:28:32,720 --> 00:28:39,140
says if the link is not lie

00:28:34,580 --> 00:28:40,909
/ content or / session or if the title

00:28:39,140 --> 00:28:43,039
is something like lunch or coffee break

00:28:40,909 --> 00:28:52,250
and so on we don't want to consider this

00:28:43,039 --> 00:28:56,860
document okay and I'm finally I finally

00:28:52,250 --> 00:29:03,710
have a table which contains cleaned and

00:28:56,860 --> 00:29:08,620
like queryable data and I can now do

00:29:03,710 --> 00:29:08,620
word count on that or I can first of all

00:29:09,549 --> 00:29:17,000
count the number of documents so i can i

00:29:13,840 --> 00:29:21,740
registered my sessions here as a as a

00:29:17,000 --> 00:29:24,470
table and i can simply say i want to

00:29:21,740 --> 00:29:27,080
group these these sessions by year and i

00:29:24,470 --> 00:29:31,159
want to count them and i want to order

00:29:27,080 --> 00:29:33,289
it by ear and then data breaks give me

00:29:31,159 --> 00:29:37,220
gives me this nice visualization so i

00:29:33,289 --> 00:29:39,830
can actually see Oh in 2010 it says 10

00:29:37,220 --> 00:29:42,470
it says only 10 sessions which is not

00:29:39,830 --> 00:29:45,649
not really true problems rather that the

00:29:42,470 --> 00:29:48,380
website doesn't contain all the sessions

00:29:45,649 --> 00:29:49,760
anymore but I checked for the other

00:29:48,380 --> 00:29:52,549
years that these numbers are actually

00:29:49,760 --> 00:29:55,039
fairly correct so two thousand twelve

00:29:52,549 --> 00:29:58,279
and fourteen were the years with the

00:29:55,039 --> 00:30:01,279
most talks in 2013 they were indeed a

00:29:58,279 --> 00:30:07,639
lot less talks and it's actually fairly

00:30:01,279 --> 00:30:14,510
stable in the in the last few years ok

00:30:07,639 --> 00:30:17,870
that's just talks I now wanna have a

00:30:14,510 --> 00:30:23,600
look at speakers so who were the top

00:30:17,870 --> 00:30:27,350
speakers over the years so for this I am

00:30:23,600 --> 00:30:30,889
simply going to do some word count

00:30:27,350 --> 00:30:35,299
basically so in my table I have a if you

00:30:30,889 --> 00:30:37,730
remember I have a column called speakers

00:30:35,299 --> 00:30:40,190
and this column already contains an

00:30:37,730 --> 00:30:44,480
array because there was some talks where

00:30:40,190 --> 00:30:46,840
there were multiple speakers so I'm

00:30:44,480 --> 00:30:49,870
gonna access that here so

00:30:46,840 --> 00:30:57,000
right so session is my table i can write

00:30:49,870 --> 00:31:04,330
i want to select the speakers i want a

00:30:57,000 --> 00:31:07,540
flat map that because this is a spark

00:31:04,330 --> 00:31:11,470
data frame basically it will when you

00:31:07,540 --> 00:31:15,160
iterate or when you map over over over a

00:31:11,470 --> 00:31:18,580
column it gives you row objects where

00:31:15,160 --> 00:31:20,560
you then have to access the field once

00:31:18,580 --> 00:31:26,560
again so the field is called speakers

00:31:20,560 --> 00:31:31,740
and its property of this line then I do

00:31:26,560 --> 00:31:36,130
the canonical world word count with it

00:31:31,740 --> 00:31:40,950
so my flat map basically explodes the

00:31:36,130 --> 00:31:45,400
speaker arrays and my map produces the

00:31:40,950 --> 00:31:56,400
word count pairs and then I reduce by

00:31:45,400 --> 00:31:59,110
key groups and to transform it back

00:31:56,400 --> 00:32:03,760
reduce by he does the actual counting

00:31:59,110 --> 00:32:09,580
and tend to transform it back to a spark

00:32:03,760 --> 00:32:13,270
data frame I create a row object which

00:32:09,580 --> 00:32:19,030
contains the speaker and the number of

00:32:13,270 --> 00:32:25,390
talks and then I have to wrap all of

00:32:19,030 --> 00:32:32,340
that into a sequel context dot create

00:32:25,390 --> 00:32:36,790
data frame and I can order this by

00:32:32,340 --> 00:32:41,490
number of talks and I can say sending

00:32:36,790 --> 00:32:41,490
false because I want to order it

00:32:42,600 --> 00:32:50,200
descending and now the question is who

00:32:47,050 --> 00:32:55,240
would you guess was the top speaker of

00:32:50,200 --> 00:32:58,740
Berlin buzzwords any guesses ok that was

00:32:55,240 --> 00:32:58,740
obvious but who are a second

00:33:00,880 --> 00:33:17,090
not bad so um sessions in fact you were

00:33:12,740 --> 00:33:20,510
quite good so first place is Ted Dunning

00:33:17,090 --> 00:33:23,840
with nine talks so more than there were

00:33:20,510 --> 00:33:26,420
buzz words actually and then grant Eric

00:33:23,840 --> 00:33:28,040
and over all of them with six talks i

00:33:26,420 --> 00:33:30,050
think these numbers are not even really

00:33:28,040 --> 00:33:33,410
correct because as i said some talks

00:33:30,050 --> 00:33:35,900
from 2010 or missing so i guess all of

00:33:33,410 --> 00:33:40,310
them gave a talk and in all of the seven

00:33:35,900 --> 00:33:44,900
years well and then there's many people

00:33:40,310 --> 00:33:50,690
also was just one talk okay so no big

00:33:44,900 --> 00:33:53,030
surprises on this end now let's look at

00:33:50,690 --> 00:33:54,440
the buzz words because that was my final

00:33:53,030 --> 00:33:57,560
promise and I'm running a little bit out

00:33:54,440 --> 00:34:04,640
of time so i don't i will not i will

00:33:57,560 --> 00:34:07,820
copy and paste the relevant commands so

00:34:04,640 --> 00:34:11,450
what would you say is the single most

00:34:07,820 --> 00:34:14,450
buzz word or the buzzword that happened

00:34:11,450 --> 00:34:18,200
at the debt that appeared the most well

00:34:14,450 --> 00:34:20,929
its data who would have guessed and any

00:34:18,200 --> 00:34:24,020
of things like Apache and Hadoop and use

00:34:20,929 --> 00:34:26,149
and so on and so forth but I would what

00:34:24,020 --> 00:34:31,090
I actually was asking in the beginning

00:34:26,149 --> 00:34:36,380
was how did that develop over the years

00:34:31,090 --> 00:34:40,240
so let me copy and paste some more code

00:34:36,380 --> 00:34:40,240
to be finally able to look at some

00:34:40,960 --> 00:34:49,880
graphs so basically what i've been doing

00:34:46,250 --> 00:34:52,850
here is word count per year and we can

00:34:49,880 --> 00:34:55,730
now actually draw graphs that that show

00:34:52,850 --> 00:34:57,590
us the word counts per year so is there

00:34:55,730 --> 00:34:59,930
are there any particular buzzwords that

00:34:57,590 --> 00:35:05,710
you're interested in to see the

00:34:59,930 --> 00:35:09,610
development over the years otherwise i

00:35:05,710 --> 00:35:09,610
will start with

00:35:09,920 --> 00:35:28,040
those streaming frameworks and I will

00:35:18,549 --> 00:35:31,930
oops make plot out of this ah how can I

00:35:28,040 --> 00:35:41,270
know sorry I have to make this smaller

00:35:31,930 --> 00:35:44,089
ones okay so that's the relative

00:35:41,270 --> 00:35:46,369
occurrence of the words storms barking

00:35:44,089 --> 00:35:48,589
fling so basically the number of that

00:35:46,369 --> 00:35:53,720
word count over total count of words

00:35:48,589 --> 00:35:55,579
over the years and as you can see flink

00:35:53,720 --> 00:36:00,920
took over sparked this year at least at

00:35:55,579 --> 00:36:03,109
berlin buzzword in truth and that's

00:36:00,920 --> 00:36:06,230
actually quite a quite a quite great

00:36:03,109 --> 00:36:09,140
friend i would say well it hasn't it

00:36:06,230 --> 00:36:15,230
didn't even exist in 2014 and spark was

00:36:09,140 --> 00:36:18,530
already already there it's quite obvious

00:36:15,230 --> 00:36:23,599
that now it's really something people

00:36:18,530 --> 00:36:26,319
are talking about any other things that

00:36:23,599 --> 00:36:26,319
you're interested in

00:36:31,900 --> 00:36:40,569
Kafka or I can basically edit edit to

00:36:34,900 --> 00:36:43,000
this graph may be okay cough guys even

00:36:40,569 --> 00:36:46,690
more popular than fling probably because

00:36:43,000 --> 00:36:57,849
it always comes in in conjunction with

00:36:46,690 --> 00:36:58,990
it let's try batch and stream Oh looks

00:36:57,849 --> 00:37:05,730
like we're really in the age of

00:36:58,990 --> 00:37:05,730
screaming now okay anything else

00:37:06,990 --> 00:37:20,740
otherwise since i'm running a bit out of

00:37:09,670 --> 00:37:26,760
time let me conclude oops okay I tried

00:37:20,740 --> 00:37:29,349
it live it worked kind of scalable well

00:37:26,760 --> 00:37:31,539
the analysis part in principle was

00:37:29,349 --> 00:37:34,180
scalable because you as I said you can

00:37:31,539 --> 00:37:38,380
run an arbitrarily large sparkless than

00:37:34,180 --> 00:37:42,069
the in the background in 30 minutes also

00:37:38,380 --> 00:37:45,400
kind of but if I remember what it would

00:37:42,069 --> 00:37:49,569
have taken me in 2010 I would probably

00:37:45,400 --> 00:37:51,940
not have even walked through this like

00:37:49,569 --> 00:37:56,430
classical MapReduce example back then in

00:37:51,940 --> 00:37:59,049
30 minutes so I think it's actually

00:37:56,430 --> 00:38:01,059
obvious that there were quite quite some

00:37:59,049 --> 00:38:04,690
advancements over the last seven years

00:38:01,059 --> 00:38:09,130
and yeah what were my conclusion so

00:38:04,690 --> 00:38:11,529
scraping is still hard even in 2016 we

00:38:09,130 --> 00:38:15,220
have the number one top speaker of

00:38:11,529 --> 00:38:17,950
Berlin buzz words which is obvious some

00:38:15,220 --> 00:38:19,510
other speakers who were we apparently

00:38:17,950 --> 00:38:22,000
really have something important to say

00:38:19,510 --> 00:38:26,289
every year so I think that's also quite

00:38:22,000 --> 00:38:30,099
impressive flink seems to be a bigger

00:38:26,289 --> 00:38:31,839
buzz word and sparked this year I found

00:38:30,099 --> 00:38:33,760
that interesting as well and as I said

00:38:31,839 --> 00:38:37,569
we were clearly in the age of streaming

00:38:33,760 --> 00:38:42,369
now well who would have guessed but i

00:38:37,569 --> 00:38:44,740
think it's apparent so yeah I hope or

00:38:42,369 --> 00:38:45,210
thanks for staying with me so long I

00:38:44,740 --> 00:38:49,440
hope I

00:38:45,210 --> 00:38:52,500
and bore you too much and just confirmed

00:38:49,440 --> 00:38:55,470
and quantified what you had expected

00:38:52,500 --> 00:38:57,990
before I will put up all the code on

00:38:55,470 --> 00:39:01,350
github and the slides will be online as

00:38:57,990 --> 00:39:04,410
well of course and get in touch on

00:39:01,350 --> 00:39:07,680
twitter or catch me after the talk and I

00:39:04,410 --> 00:39:09,740
fear we only have time for one more

00:39:07,680 --> 00:39:12,540
question thanks for that cur stuff

00:39:09,740 --> 00:39:20,070
thanks for that do we have questions or

00:39:12,540 --> 00:39:24,900
comments in the audience seems like

00:39:20,070 --> 00:39:27,410
we're good thanks again to Christophe ok

00:39:24,900 --> 00:39:27,410

YouTube URL: https://www.youtube.com/watch?v=ShGWOVWjKIU


