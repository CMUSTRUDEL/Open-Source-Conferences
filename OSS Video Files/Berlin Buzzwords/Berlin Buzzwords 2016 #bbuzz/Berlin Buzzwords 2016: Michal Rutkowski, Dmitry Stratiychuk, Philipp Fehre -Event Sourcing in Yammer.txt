Title: Berlin Buzzwords 2016: Michal Rutkowski, Dmitry Stratiychuk, Philipp Fehre -Event Sourcing in Yammer
Publication date: 2016-06-12
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Event Sourcing brings the promise of highly-scalable and loosely-coupled systems that are performant, reliable, and maintainable. It looked like a perfect solution for Yammer's reliability and performance challenges, but nothing comes for free!

Only slightly over a year ago, Yammer's entire system was either based on synchronous calls or Ruby workers and RabbitMQ. For a while, we have been moving performance-critical components out of the Ruby on Rails monolith toward Dropwizard-based services. This has served us well, but with increased reliability requirements, the pressure to simplify and decouple our system's architecture also increased.

Over the course of the last year, we first created a prototype implementation of Event Sourcing and, after validating the idea, have been moving it to a managed Azure Event Hubs based solution. 

We are going to cover not only how to migrate to a new technology, but also look at how to change organizational thinking from a synchronous world to one of event streams. We will tell the war stories of our migration from a self-hosted Kafka cluster to a solution based in the cloud.

Read more:
https://2016.berlinbuzzwords.de/session/event-sourcing-yammer

About Michal Rutkowski:
https://2016.berlinbuzzwords.de/users/michal-rutkowski

About Dmitry Stratiychuk:
https://2016.berlinbuzzwords.de/users/dmitry-stratiychuk

About Philipp Fehre:
https://2016.berlinbuzzwords.de/users/philipp-fehre

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:03,500 --> 00:00:08,580
the mic on yes it is i guess so hello

00:00:06,330 --> 00:00:10,860
I'm Mohammad kofsky and this is joint

00:00:08,580 --> 00:00:13,290
work with my colleagues Dmitry strategic

00:00:10,860 --> 00:00:15,240
in Philip fair so Dmitry had to leave

00:00:13,290 --> 00:00:18,150
unfortunately all ready to cut his plane

00:00:15,240 --> 00:00:21,060
but Philip is here so we can talk to him

00:00:18,150 --> 00:00:23,100
and we afterwards if you want and we

00:00:21,060 --> 00:00:25,740
form part of we are part of a team or we

00:00:23,100 --> 00:00:29,789
we are the team called death SOA team

00:00:25,740 --> 00:00:34,469
and and this work this is about the work

00:00:29,789 --> 00:00:40,590
we did recently over several projects ok

00:00:34,469 --> 00:00:44,430
so can we fix the alignment but ok fair

00:00:40,590 --> 00:00:46,860
enough so yeah so briefly what does this

00:00:44,430 --> 00:00:48,719
talk about so i will first tell you a

00:00:46,860 --> 00:00:51,390
bit about the challenges we face which

00:00:48,719 --> 00:00:53,010
kind of led to this work then i will

00:00:51,390 --> 00:00:56,489
discuss why we actually turn to events

00:00:53,010 --> 00:00:58,289
or sink as a solution and the bulk of

00:00:56,489 --> 00:01:00,510
the talk will be about how we rolled it

00:00:58,289 --> 00:01:03,510
out and what we've learned from that

00:01:00,510 --> 00:01:05,519
roll out and I will conclude with the

00:01:03,510 --> 00:01:10,439
kind of future work we want to do in

00:01:05,519 --> 00:01:12,869
this area so what is yeah mer Yammer as

00:01:10,439 --> 00:01:14,430
the words say it's a enterprise social

00:01:12,869 --> 00:01:16,619
network but what that really means is

00:01:14,430 --> 00:01:18,689
it's a tool which helps teams

00:01:16,619 --> 00:01:20,820
collaborate we try to focus that

00:01:18,689 --> 00:01:24,450
collaboration within groups but we also

00:01:20,820 --> 00:01:27,299
provide more broader spectrum like a

00:01:24,450 --> 00:01:28,770
broader audience discussions and also we

00:01:27,299 --> 00:01:30,479
provide private discussions so there are

00:01:28,770 --> 00:01:33,240
quite a lot of features if you look at

00:01:30,479 --> 00:01:35,790
the those two slides the left-hand side

00:01:33,240 --> 00:01:37,640
shows the inbox view so this is the kind

00:01:35,790 --> 00:01:40,320
of content which is related to you and

00:01:37,640 --> 00:01:42,329
what you haven't read or left for later

00:01:40,320 --> 00:01:44,899
and you're on the right hand side you

00:01:42,329 --> 00:01:47,070
see a group so this is actually the

00:01:44,899 --> 00:01:49,710
Yammer engineering group so that's where

00:01:47,070 --> 00:01:52,439
we describe the broad engineering team

00:01:49,710 --> 00:01:55,770
discusses stuff so our core features

00:01:52,439 --> 00:01:58,259
message posting and messaging if you

00:01:55,770 --> 00:02:00,299
like but in reality if you look at the

00:01:58,259 --> 00:02:02,759
site a single message triggers a lot a

00:02:00,299 --> 00:02:04,049
single message posted event triggers a

00:02:02,759 --> 00:02:05,549
lot of actions which are powered by

00:02:04,049 --> 00:02:08,429
different components which are

00:02:05,549 --> 00:02:09,869
relatively independent so a message is

00:02:08,429 --> 00:02:11,790
typically address to somebody so it has

00:02:09,869 --> 00:02:13,010
to end up in your inbox or to address

00:02:11,790 --> 00:02:14,720
these inbox

00:02:13,010 --> 00:02:16,159
this most likely is posted in the

00:02:14,720 --> 00:02:19,010
context of a group so we want to deliver

00:02:16,159 --> 00:02:21,230
to a group but we also have aggregation

00:02:19,010 --> 00:02:24,680
of use for messages so if somebody is

00:02:21,230 --> 00:02:27,260
following me they will also have a view

00:02:24,680 --> 00:02:29,599
which shows my messages or messages of

00:02:27,260 --> 00:02:32,150
all the people they follow and if I'm

00:02:29,599 --> 00:02:35,329
very popular then that can be actually

00:02:32,150 --> 00:02:38,659
an expensive thing to compute and but

00:02:35,329 --> 00:02:40,010
also message posting triggers a ranking

00:02:38,659 --> 00:02:43,040
system so you see on the right hand side

00:02:40,010 --> 00:02:45,560
there's a little window which has my

00:02:43,040 --> 00:02:47,569
contacts and it's sorted by kind of

00:02:45,560 --> 00:02:50,209
popularity if you like but this again

00:02:47,569 --> 00:02:53,030
that can be affected by who I post to

00:02:50,209 --> 00:02:56,180
and who who's messages I like a reply to

00:02:53,030 --> 00:02:58,940
etc also on their left hand side you

00:02:56,180 --> 00:03:01,909
have the list of groups they have counts

00:02:58,940 --> 00:03:03,920
these need to be updated I have there's

00:03:01,909 --> 00:03:05,389
some real-time notifications depending

00:03:03,920 --> 00:03:07,940
like if I get something to my inbox some

00:03:05,389 --> 00:03:12,650
action happens again this is another

00:03:07,940 --> 00:03:15,459
flow so the gist of it is that a single

00:03:12,650 --> 00:03:22,329
event actually parcel of systems and

00:03:15,459 --> 00:03:25,519
impacts a lot of systems and so we are

00:03:22,329 --> 00:03:30,169
we're kind of a consumer product in the

00:03:25,519 --> 00:03:31,879
sense that we are actually trying to

00:03:30,169 --> 00:03:33,739
discover what our consumers need and

00:03:31,879 --> 00:03:37,040
what actually makes them engage in our

00:03:33,739 --> 00:03:38,959
product but at the same time where we're

00:03:37,040 --> 00:03:40,459
a corporate product so people use Yammer

00:03:38,959 --> 00:03:42,379
they actually quite often pay a license

00:03:40,459 --> 00:03:45,049
feed these days to actually get work

00:03:42,379 --> 00:03:46,910
done so to make that happen I mean to

00:03:45,049 --> 00:03:49,549
make them believe that they can get the

00:03:46,910 --> 00:03:53,840
work done we commit to an SLA so they

00:03:49,549 --> 00:03:57,739
can count on us being up and our

00:03:53,840 --> 00:04:00,680
internal external facing SLA is 99 75 so

00:03:57,739 --> 00:04:02,419
99 percent 75 point 75 there's roughly

00:04:00,680 --> 00:04:06,919
40 minutes of downtime a month and

00:04:02,419 --> 00:04:08,569
that's not very that's not a lot so and

00:04:06,919 --> 00:04:11,209
if we don't meet that sli we have to pay

00:04:08,569 --> 00:04:13,459
money sits and our reputation is hurt as

00:04:11,209 --> 00:04:16,430
well so that's very important but also

00:04:13,459 --> 00:04:18,109
since we are trying to attract customers

00:04:16,430 --> 00:04:20,120
is not like yummers not adapted for

00:04:18,109 --> 00:04:21,739
top-down decisions we want to have

00:04:20,120 --> 00:04:24,440
provide a good quality experience of

00:04:21,739 --> 00:04:26,180
performances big chunk of it but

00:04:24,440 --> 00:04:26,750
internally was important to us its

00:04:26,180 --> 00:04:29,300
velocity

00:04:26,750 --> 00:04:30,680
a so maybe you've heard some other kind

00:04:29,300 --> 00:04:33,170
of more product focused talks from

00:04:30,680 --> 00:04:34,850
Yammer but we measure everything and we

00:04:33,170 --> 00:04:38,960
drive our product decisions based on

00:04:34,850 --> 00:04:41,390
metrics we run AP tests and we see how

00:04:38,960 --> 00:04:44,180
we will behave and if a feature is

00:04:41,390 --> 00:04:46,610
wanted or is used then we keep it if not

00:04:44,180 --> 00:04:48,800
we potentially scrape scrape it so in

00:04:46,610 --> 00:04:50,300
that context putting too much spending

00:04:48,800 --> 00:04:52,580
too much time building a first version

00:04:50,300 --> 00:04:53,780
of feature just doesn't work because if

00:04:52,580 --> 00:04:55,880
we have eighty percent chance but the

00:04:53,780 --> 00:04:58,720
future will stay we don't want to invest

00:04:55,880 --> 00:05:03,860
too much because it just is too costly

00:04:58,720 --> 00:05:08,780
but what's important is that these two

00:05:03,860 --> 00:05:10,760
are a bit slide odds right it's if you

00:05:08,780 --> 00:05:13,130
want to deliver things fast your is very

00:05:10,760 --> 00:05:15,140
difficult to meteor sli so the team

00:05:13,130 --> 00:05:18,310
Philip and Demetri and I are working and

00:05:15,140 --> 00:05:21,530
it's its focus is actually to help our

00:05:18,310 --> 00:05:24,140
engineering organization meet these two

00:05:21,530 --> 00:05:27,290
potentially conflicting requirements so

00:05:24,140 --> 00:05:29,180
we want to enable people fast feature

00:05:27,290 --> 00:05:32,810
building but at the same time not

00:05:29,180 --> 00:05:34,669
compromising our sleigh and in broad

00:05:32,810 --> 00:05:36,800
strokes what we do is we drive

00:05:34,669 --> 00:05:38,720
discussion and we try to adopt better

00:05:36,800 --> 00:05:41,120
archit better patterns around mostly

00:05:38,720 --> 00:05:44,780
around the architecture but we also try

00:05:41,120 --> 00:05:46,880
to build tooling and or adopt if there's

00:05:44,780 --> 00:05:50,240
something of the shelf to make that more

00:05:46,880 --> 00:05:53,510
make that possible so to give you an

00:05:50,240 --> 00:05:55,130
example of what kind of work we do is we

00:05:53,510 --> 00:05:56,840
are currently working on better tooling

00:05:55,130 --> 00:05:59,600
for process and processed for release

00:05:56,840 --> 00:06:00,919
management we have quite advanced

00:05:59,600 --> 00:06:03,740
continuous delivery but there's always

00:06:00,919 --> 00:06:05,180
room for improvement we also want to get

00:06:03,740 --> 00:06:08,300
more advanced testing involves likes

00:06:05,180 --> 00:06:09,830
inferences load testing we before things

00:06:08,300 --> 00:06:12,680
are release of it we don't have

00:06:09,830 --> 00:06:15,950
performance regressions we also drive

00:06:12,680 --> 00:06:18,050
kind of discussion and tooling for best

00:06:15,950 --> 00:06:20,810
service for best practices around

00:06:18,050 --> 00:06:22,550
service design and development so we

00:06:20,810 --> 00:06:24,710
encourage hire people to test for

00:06:22,550 --> 00:06:27,710
failure especially kind of late latency

00:06:24,710 --> 00:06:30,970
type fail around higher Layton sees we

00:06:27,710 --> 00:06:32,960
build tools for would help engineers

00:06:30,970 --> 00:06:34,460
well meet their quality of service

00:06:32,960 --> 00:06:36,320
guarantees this is not to be confused

00:06:34,460 --> 00:06:37,789
with the external SLI we want still our

00:06:36,320 --> 00:06:40,940
components to kind of commit to some

00:06:37,789 --> 00:06:43,520
sort of quality of service sli and

00:06:40,940 --> 00:06:46,250
make it easy for engineers actually meet

00:06:43,520 --> 00:06:47,840
that commitment but we also do a lot of

00:06:46,250 --> 00:06:50,540
work around inter-services integration

00:06:47,840 --> 00:06:57,590
patterns and this talk will be mostly

00:06:50,540 --> 00:06:59,960
about this so this will be a familiar

00:06:57,590 --> 00:07:01,370
story probably to most people but Yammer

00:06:59,960 --> 00:07:04,060
started as a small start-up it was a

00:07:01,370 --> 00:07:08,240
ruby on rails mana app back by postgres

00:07:04,060 --> 00:07:10,400
very easy to develop very quick great

00:07:08,240 --> 00:07:12,170
but as we became successful more

00:07:10,400 --> 00:07:16,310
features were developed it just grew and

00:07:12,170 --> 00:07:20,420
it grew to a quiet unwieldy sighs both

00:07:16,310 --> 00:07:23,570
in terms of management like maintenance

00:07:20,420 --> 00:07:26,480
but also kind of operational concerns it

00:07:23,570 --> 00:07:27,620
was difficult to deploy at single point

00:07:26,480 --> 00:07:29,360
of failure it was very difficult to

00:07:27,620 --> 00:07:30,830
develop features because the sheer size

00:07:29,360 --> 00:07:34,450
of the codebase was such but it was very

00:07:30,830 --> 00:07:37,340
difficult to know what's happening and

00:07:34,450 --> 00:07:39,380
also performance was hurting because

00:07:37,340 --> 00:07:43,400
we're reaching the limits of our

00:07:39,380 --> 00:07:45,140
postgres DB so what we started doing is

00:07:43,400 --> 00:07:49,370
we started extracting the performance

00:07:45,140 --> 00:07:52,370
critical components out of the app that

00:07:49,370 --> 00:07:54,500
was that's how drop wizard was born was

00:07:52,370 --> 00:07:56,900
born actually of the first few such

00:07:54,500 --> 00:07:59,690
extractions the typical pattern was that

00:07:56,900 --> 00:08:02,540
we would use rabbit as to facilitate an

00:07:59,690 --> 00:08:04,850
asynchronous right to the extracted

00:08:02,540 --> 00:08:06,800
functionality that functionality would

00:08:04,850 --> 00:08:08,330
usually have its own data store and

00:08:06,800 --> 00:08:09,680
would provide some sort of a

00:08:08,330 --> 00:08:12,169
materialization of a more complex

00:08:09,680 --> 00:08:18,320
expensive view which would then be back

00:08:12,169 --> 00:08:21,320
the actual and rails moon app but as we

00:08:18,320 --> 00:08:23,630
went on we started extracting more we

00:08:21,320 --> 00:08:26,330
started actually creating user facing

00:08:23,630 --> 00:08:29,300
services that requires authorization is

00:08:26,330 --> 00:08:31,430
an authentication access control so we

00:08:29,300 --> 00:08:34,219
had to create this as services we

00:08:31,430 --> 00:08:35,510
stopped we started trying to limit the

00:08:34,219 --> 00:08:37,520
amount of code we add to the monitor app

00:08:35,510 --> 00:08:38,780
because we didn't want to make it grow

00:08:37,520 --> 00:08:41,089
we actually wanted to make it make it

00:08:38,780 --> 00:08:44,770
smaller so this is going quite complex

00:08:41,089 --> 00:08:47,780
and we are quite early adopters of

00:08:44,770 --> 00:08:51,589
extracting things into services so but

00:08:47,780 --> 00:08:54,320
by around the time I joined that's was

00:08:51,589 --> 00:08:57,200
the service dependency graph in the amur

00:08:54,320 --> 00:08:59,990
quite difficult to comprehend and that

00:08:57,200 --> 00:09:03,320
was mid-2014 so that's three years ago

00:08:59,990 --> 00:09:05,960
today nobody even attempt to draw our

00:09:03,320 --> 00:09:09,110
defensive graph I think we have 100

00:09:05,960 --> 00:09:11,450
something services few hundred nodes we

00:09:09,110 --> 00:09:15,350
operated in our own DC we are moving to

00:09:11,450 --> 00:09:18,520
her but it's basically there are

00:09:15,350 --> 00:09:21,350
multiple it causes multiple pain points

00:09:18,520 --> 00:09:23,120
because we arrived effectively at a

00:09:21,350 --> 00:09:27,470
distributed model if and we try to get

00:09:23,120 --> 00:09:30,080
out of that so what were the real issues

00:09:27,470 --> 00:09:32,750
we faced so our feature development

00:09:30,080 --> 00:09:36,170
slowed down quite a bit we have too many

00:09:32,750 --> 00:09:38,840
inter-service dependencies which makes

00:09:36,170 --> 00:09:40,850
it difficult to build something our

00:09:38,840 --> 00:09:42,530
services are pretty chatty which

00:09:40,850 --> 00:09:44,240
effectively means that we haven't drawn

00:09:42,530 --> 00:09:46,460
our boundaries like the main boundaries

00:09:44,240 --> 00:09:47,780
well so developing a new concept

00:09:46,460 --> 00:09:49,880
typically requires iterating over

00:09:47,780 --> 00:09:54,200
multiple services which is way more

00:09:49,880 --> 00:09:56,990
expensive and it should be and we have

00:09:54,200 --> 00:09:58,820
too many inter-service as their enter

00:09:56,990 --> 00:10:02,240
team and cross timezone dependencies so

00:09:58,820 --> 00:10:04,400
different services are kind of maybe not

00:10:02,240 --> 00:10:06,380
own but maintained or expertise around

00:10:04,400 --> 00:10:10,880
them is quite often contained in one

00:10:06,380 --> 00:10:12,830
team which is local to an office that's

00:10:10,880 --> 00:10:15,890
again if you have features which cross

00:10:12,830 --> 00:10:18,110
multiple like multiple which go across

00:10:15,890 --> 00:10:19,850
multiple services that's again quite a

00:10:18,110 --> 00:10:25,040
bit of a headache for a project team to

00:10:19,850 --> 00:10:27,500
roll out a feature in such situation but

00:10:25,040 --> 00:10:30,440
not only that but it also made it

00:10:27,500 --> 00:10:31,940
difficult for us to meet our SLA we had

00:10:30,440 --> 00:10:33,860
too many external dependencies on the

00:10:31,940 --> 00:10:35,270
Reid and bow and right paths that means

00:10:33,860 --> 00:10:38,450
the chances of failure were actually

00:10:35,270 --> 00:10:40,640
pretty high and making that the real

00:10:38,450 --> 00:10:42,200
right path resilient required quite a

00:10:40,640 --> 00:10:44,030
lot of investment because every

00:10:42,200 --> 00:10:47,120
component had to be super resilient more

00:10:44,030 --> 00:10:50,060
cerveny would expect we had a shirt DB

00:10:47,120 --> 00:10:53,240
again a nice an type well nice a common

00:10:50,060 --> 00:10:57,040
anti-pattern slows us down single point

00:10:53,240 --> 00:10:59,270
of failure easy to go easy to break

00:10:57,040 --> 00:11:02,270
furthermore with such a complex

00:10:59,270 --> 00:11:03,680
dependency graph we it was beyond

00:11:02,270 --> 00:11:05,240
comprehension so we had an expected

00:11:03,680 --> 00:11:06,470
transitive transitive dependencies which

00:11:05,240 --> 00:11:07,880
would typically we discovered using

00:11:06,470 --> 00:11:10,760
during a and out

00:11:07,880 --> 00:11:12,050
through cascading failures and there's

00:11:10,760 --> 00:11:13,490
this there's a lot of good practice

00:11:12,050 --> 00:11:15,470
around inter-service communication like

00:11:13,490 --> 00:11:18,440
circle breaking to prevent cascading

00:11:15,470 --> 00:11:20,030
failures but still we manage to see

00:11:18,440 --> 00:11:22,970
quite a few of those because of the

00:11:20,030 --> 00:11:26,060
complexity of our graph and again

00:11:22,970 --> 00:11:27,860
because it was so complex it's difficult

00:11:26,060 --> 00:11:31,370
to cut to test I mean the amount of

00:11:27,860 --> 00:11:32,840
tests Kate complexity is immense so it

00:11:31,370 --> 00:11:34,640
was actually relatively easy to roll out

00:11:32,840 --> 00:11:37,940
the breaking code change which will slip

00:11:34,640 --> 00:11:41,540
through the cracks so about a year ago

00:11:37,940 --> 00:11:44,810
it was really bad I would say so we look

00:11:41,540 --> 00:11:47,690
towards events or sink so there's a very

00:11:44,810 --> 00:11:48,920
good article on msdn under the storm

00:11:47,690 --> 00:11:52,160
events or things that's where i took the

00:11:48,920 --> 00:11:55,130
diagram from but basically what we have

00:11:52,160 --> 00:11:59,990
here is that instead of keeping the end

00:11:55,130 --> 00:12:03,010
state of the system we focus on the

00:11:59,990 --> 00:12:08,320
events that lead to the state change and

00:12:03,010 --> 00:12:10,580
we keep them in an event store and our

00:12:08,320 --> 00:12:12,650
views are searched from services would

00:12:10,580 --> 00:12:16,550
actually subscribe to these events in

00:12:12,650 --> 00:12:19,010
some fashion and materialized view so a

00:12:16,550 --> 00:12:21,980
new feature would typically be a new

00:12:19,010 --> 00:12:23,360
view on an existing events stream but

00:12:21,980 --> 00:12:26,210
sometimes you will also add an event

00:12:23,360 --> 00:12:28,850
stream so here we this is a very simple

00:12:26,210 --> 00:12:30,860
example we have a cart with items so the

00:12:28,850 --> 00:12:33,710
vents are create a card at an item

00:12:30,860 --> 00:12:35,960
remove an item and the shopping cart

00:12:33,710 --> 00:12:38,990
view kind of common one would hear would

00:12:35,960 --> 00:12:42,350
be to the material as the current state

00:12:38,990 --> 00:12:43,850
of the of the of the basket of the

00:12:42,350 --> 00:12:45,710
shopping cart but it also could feed an

00:12:43,850 --> 00:12:47,870
analytic system which kind of tries to

00:12:45,710 --> 00:12:51,050
correlate items which are similar as

00:12:47,870 --> 00:12:54,350
stuff in there completely independent

00:12:51,050 --> 00:12:58,070
way so what we took away from that and

00:12:54,350 --> 00:13:01,790
what was important to us was but for a

00:12:58,070 --> 00:13:03,830
given piece of domain we have one data

00:13:01,790 --> 00:13:05,750
owner service which coordinates the

00:13:03,830 --> 00:13:09,830
rights and that's the system which

00:13:05,750 --> 00:13:11,870
persists the version of the data in the

00:13:09,830 --> 00:13:14,690
in the state in the primary sort of the

00:13:11,870 --> 00:13:16,310
record its database and it publishes an

00:13:14,690 --> 00:13:18,290
event but this kind of update happened

00:13:16,310 --> 00:13:20,220
that no emotions got published this

00:13:18,290 --> 00:13:23,250
method could create it

00:13:20,220 --> 00:13:25,830
and we have multiple view services which

00:13:23,250 --> 00:13:29,460
listen to those events and update their

00:13:25,830 --> 00:13:33,090
local state by solidi b and the

00:13:29,460 --> 00:13:37,860
researcher from these services so what

00:13:33,090 --> 00:13:39,690
we're after is changing this into

00:13:37,860 --> 00:13:41,880
something more like this i mean i

00:13:39,690 --> 00:13:44,760
haven't read on that diagram and it's

00:13:41,880 --> 00:13:46,920
just more high-level but think of it

00:13:44,760 --> 00:13:49,890
this way a message comes in there's a

00:13:46,920 --> 00:13:53,340
data owner for the message model it

00:13:49,890 --> 00:13:55,830
publishes the event log and then we have

00:13:53,340 --> 00:13:57,210
a view for a group so it materialized

00:13:55,830 --> 00:13:59,550
the group view where that message was

00:13:57,210 --> 00:14:01,460
posted the inbox so delivers to all the

00:13:59,550 --> 00:14:04,290
people who should get that message

00:14:01,460 --> 00:14:06,120
potentially a system which scent which

00:14:04,290 --> 00:14:08,070
reacts the message and sends real-time

00:14:06,120 --> 00:14:11,630
and notification push notification to

00:14:08,070 --> 00:14:14,370
mobile to mobile clients there's a

00:14:11,630 --> 00:14:17,370
subscriber which listens to those events

00:14:14,370 --> 00:14:20,670
to see who messages with whom so if we

00:14:17,370 --> 00:14:22,230
could provide better relevance and but

00:14:20,670 --> 00:14:24,360
what's crucial all these systems are

00:14:22,230 --> 00:14:26,880
completely independent so if one of them

00:14:24,360 --> 00:14:29,100
fails none of them are affected adding a

00:14:26,880 --> 00:14:33,720
new system a new feature which I don't

00:14:29,100 --> 00:14:35,700
know checks what the which tracks when

00:14:33,720 --> 00:14:37,320
the user was online so that I can maybe

00:14:35,700 --> 00:14:38,790
send them a summary if they were offline

00:14:37,320 --> 00:14:41,130
it's just adding a new subscriber

00:14:38,790 --> 00:14:43,290
completely independent of previous

00:14:41,130 --> 00:14:45,060
existing features well all it cares

00:14:43,290 --> 00:14:50,220
about this message is being sent read

00:14:45,060 --> 00:14:52,740
and this kind of stuff and so why is

00:14:50,220 --> 00:14:54,150
this appealing to kind of if we are

00:14:52,740 --> 00:14:56,040
looking to solve our previous problems

00:14:54,150 --> 00:14:57,060
well we have less like those view

00:14:56,040 --> 00:14:58,770
services because they provide

00:14:57,060 --> 00:15:01,380
materialized views we have less learn

00:14:58,770 --> 00:15:04,350
time dependencies that affects our SLA

00:15:01,380 --> 00:15:06,570
but also a performance we have much less

00:15:04,350 --> 00:15:08,160
chattiness so again it is good for

00:15:06,570 --> 00:15:09,690
performance but also helps our velocity

00:15:08,160 --> 00:15:11,310
because we kind of operate within a

00:15:09,690 --> 00:15:15,270
single service when we are developing a

00:15:11,310 --> 00:15:16,350
feature if loose coupling serve variant

00:15:15,270 --> 00:15:18,210
on chat in essence the runtime

00:15:16,350 --> 00:15:22,920
dependencies but applications in

00:15:18,210 --> 00:15:24,930
generally more modular so and we publish

00:15:22,920 --> 00:15:26,160
events not commands I think that's an

00:15:24,930 --> 00:15:27,630
important point that's probably

00:15:26,160 --> 00:15:29,910
something one of the bigger challenges

00:15:27,630 --> 00:15:32,070
of rolling this out because we use so

00:15:29,910 --> 00:15:33,960
many is we so often used queues in the

00:15:32,070 --> 00:15:36,390
past people tend to think

00:15:33,960 --> 00:15:38,280
of in terms of publishing commands but

00:15:36,390 --> 00:15:39,840
commands provide pub coupling because

00:15:38,280 --> 00:15:41,760
they're from particular sender to a

00:15:39,840 --> 00:15:44,160
particular receiver and what we're after

00:15:41,760 --> 00:15:45,510
here is about a universal message which

00:15:44,160 --> 00:15:49,110
everybody can subscribe to and take

00:15:45,510 --> 00:15:51,720
whatever I want be the difference is

00:15:49,110 --> 00:15:54,120
instead of do this said I did this and

00:15:51,720 --> 00:15:56,100
you do whatever you want you know what

00:15:54,120 --> 00:15:57,270
you should do and in a sense it's also

00:15:56,100 --> 00:15:59,220
provides better encapsulation of

00:15:57,270 --> 00:16:03,440
services because the recipient knows

00:15:59,220 --> 00:16:03,440
what how to react relevant the emitter

00:16:03,560 --> 00:16:09,570
and it also makes it cheap to set up and

00:16:07,080 --> 00:16:11,010
backfill a new service we and start

00:16:09,570 --> 00:16:16,080
using it immediately without affecting

00:16:11,010 --> 00:16:17,580
anything else so what were the

00:16:16,080 --> 00:16:20,550
challenges we face when we started

00:16:17,580 --> 00:16:22,500
rolling this rolling this out so first

00:16:20,550 --> 00:16:24,210
of all we can it's a big change so we

00:16:22,500 --> 00:16:26,670
can't roll it over night round out

00:16:24,210 --> 00:16:28,260
overnight but more importantly there are

00:16:26,670 --> 00:16:30,090
quite a few risks associated with it

00:16:28,260 --> 00:16:31,350
what we looked at and what you've would

00:16:30,090 --> 00:16:33,660
have we've seen in the past were

00:16:31,350 --> 00:16:36,420
typically toy examples which we see it

00:16:33,660 --> 00:16:39,030
during conference talks which kind of

00:16:36,420 --> 00:16:41,490
our focus on exemplifying the idea but

00:16:39,030 --> 00:16:42,810
like they have no way of addressing the

00:16:41,490 --> 00:16:44,730
real pain points you will experience

00:16:42,810 --> 00:16:47,190
when you run this this kind of approach

00:16:44,730 --> 00:16:49,860
in production on a complex system which

00:16:47,190 --> 00:16:51,270
is constantly changing and so the

00:16:49,860 --> 00:16:54,300
concerns we had was can this actually

00:16:51,270 --> 00:16:56,210
deliver like will the benefits not be

00:16:54,300 --> 00:16:58,770
outweighed by the costs which will face

00:16:56,210 --> 00:17:01,380
how long will it actually take for us to

00:16:58,770 --> 00:17:04,410
learn how to do it properly I mean we

00:17:01,380 --> 00:17:07,080
haven't done it before and what stack to

00:17:04,410 --> 00:17:10,620
use this will require center of middle

00:17:07,080 --> 00:17:12,330
were in our application and like what is

00:17:10,620 --> 00:17:14,220
the cost like how what's the cost of

00:17:12,330 --> 00:17:16,500
onboarding the technology to for that of

00:17:14,220 --> 00:17:17,880
the which was used by that stack because

00:17:16,500 --> 00:17:20,160
you need to have you need to train

00:17:17,880 --> 00:17:21,600
people how to deal with uncle issues you

00:17:20,160 --> 00:17:23,670
have to make it make sure that this

00:17:21,600 --> 00:17:26,010
happens across time zones in a sustained

00:17:23,670 --> 00:17:28,380
in a sustainable fashion so these are

00:17:26,010 --> 00:17:31,890
actually high risks and potential high

00:17:28,380 --> 00:17:34,830
costs so at a high level we had two

00:17:31,890 --> 00:17:36,030
challenges we needed to validate event

00:17:34,830 --> 00:17:39,600
sourcing see if it's actually worthwhile

00:17:36,030 --> 00:17:42,810
and if it is we wanted to choose the

00:17:39,600 --> 00:17:44,280
best stack but ideally we would like to

00:17:42,810 --> 00:17:46,830
decouple these two we would like to

00:17:44,280 --> 00:17:47,850
first validate before we make the big

00:17:46,830 --> 00:17:50,730
investment in the text

00:17:47,850 --> 00:17:52,590
back so because if we validate early and

00:17:50,730 --> 00:17:54,539
deliver value early then we actually

00:17:52,590 --> 00:17:58,860
have tangible evidence that we need to

00:17:54,539 --> 00:18:02,640
invest in choosing the text back so what

00:17:58,860 --> 00:18:05,520
we did was we chose a legacy system

00:18:02,640 --> 00:18:07,950
which we had it was called vent it was

00:18:05,520 --> 00:18:10,830
at some point intended for venting but

00:18:07,950 --> 00:18:15,030
it was used in one particular scenario

00:18:10,830 --> 00:18:16,980
and it's kind of forgotten and it also

00:18:15,030 --> 00:18:19,590
had a somewhat awkward design because it

00:18:16,980 --> 00:18:22,409
was fronted with an HTTP drop proxy

00:18:19,590 --> 00:18:24,330
bison drop with a little salt sink there

00:18:22,409 --> 00:18:26,970
was a Kafka back end and there was a

00:18:24,330 --> 00:18:28,080
HTTP spout which was again a drop with

00:18:26,970 --> 00:18:31,140
her service which was subscribing to

00:18:28,080 --> 00:18:34,650
Kafka and relying events which is red

00:18:31,140 --> 00:18:36,150
and we had some operational experience

00:18:34,650 --> 00:18:38,000
with Kafka because we use it for our

00:18:36,150 --> 00:18:40,169
logging pipeline we also use it for

00:18:38,000 --> 00:18:44,700
should be we used to use it for our

00:18:40,169 --> 00:18:46,470
metrics tripping pipeline so importantly

00:18:44,700 --> 00:18:50,299
so this system was allowing us to model

00:18:46,470 --> 00:18:53,190
the kind of pop sub event log backs

00:18:50,299 --> 00:18:55,049
concept and it was built of components

00:18:53,190 --> 00:18:56,940
we're familiar with even though it was

00:18:55,049 --> 00:18:59,970
super centralized so it provided again a

00:18:56,940 --> 00:19:01,980
single point of failure and it was had a

00:18:59,970 --> 00:19:04,980
lot of cruft which wasn't really clear

00:19:01,980 --> 00:19:07,610
why we needed it long term it's in these

00:19:04,980 --> 00:19:10,289
are maintenance costs violent points etc

00:19:07,610 --> 00:19:11,490
actually the reading part is a single

00:19:10,289 --> 00:19:14,340
point of failure if somebody breaks the

00:19:11,490 --> 00:19:17,730
configure we could potentially take the

00:19:14,340 --> 00:19:19,130
whole application out and but crucially

00:19:17,730 --> 00:19:22,500
it was built of familiar components

00:19:19,130 --> 00:19:25,320
we're already operating relatively well

00:19:22,500 --> 00:19:30,240
so that minimized our tech risk and

00:19:25,320 --> 00:19:31,740
allows us to focus on validation and one

00:19:30,240 --> 00:19:33,990
of the downsides which is via

00:19:31,740 --> 00:19:35,730
centralization actually short term was a

00:19:33,990 --> 00:19:37,230
benefit because it allowed us of it

00:19:35,730 --> 00:19:38,850
right quickly if we were to update all

00:19:37,230 --> 00:19:40,020
the clients all the time each time we

00:19:38,850 --> 00:19:42,470
discover something we did something

00:19:40,020 --> 00:19:49,230
wrong it would be a massive pain point

00:19:42,470 --> 00:19:51,870
and slow down so the work we did

00:19:49,230 --> 00:19:53,700
initially was we operationalized that

00:19:51,870 --> 00:19:56,730
system fervor so we made sure that it

00:19:53,700 --> 00:19:58,590
doesn't have some critical bugs which it

00:19:56,730 --> 00:20:01,690
had because it was somewhat neglected

00:19:58,590 --> 00:20:04,750
and we established we worked out an

00:20:01,690 --> 00:20:05,950
api and semantics which was independent

00:20:04,750 --> 00:20:07,990
of the input implementation this is

00:20:05,950 --> 00:20:09,490
something we could move forward even if

00:20:07,990 --> 00:20:11,769
we remove the proxies and we started

00:20:09,490 --> 00:20:13,960
using pull model versus the push model

00:20:11,769 --> 00:20:17,710
which the HTTP proxy kind of enforced on

00:20:13,960 --> 00:20:19,090
us and we also built to link which

00:20:17,710 --> 00:20:21,340
actually made it easier for our

00:20:19,090 --> 00:20:24,039
customers would build consumers of the

00:20:21,340 --> 00:20:25,809
of the vent streams it allowed them to

00:20:24,039 --> 00:20:30,549
monitor the health of the consumer as

00:20:25,809 --> 00:20:33,399
well as managing the events and we built

00:20:30,549 --> 00:20:34,840
end-to-end test Suites one kind of

00:20:33,399 --> 00:20:37,960
around correctness of the system like

00:20:34,840 --> 00:20:40,120
not losing data and stuff and of

00:20:37,960 --> 00:20:42,490
important different if its treated as

00:20:40,120 --> 00:20:43,960
persistent and we also created fru put

00:20:42,490 --> 00:20:46,230
and loud put low test so that

00:20:43,960 --> 00:20:49,960
occasionally we we could comfortably

00:20:46,230 --> 00:20:55,360
iterate on the system without risking

00:20:49,960 --> 00:20:57,070
performance degradation and so and this

00:20:55,360 --> 00:20:58,629
is quite important because this will

00:20:57,070 --> 00:21:00,909
help us quite relatively quickly to move

00:20:58,629 --> 00:21:04,779
to the next stack it's like the stack of

00:21:00,909 --> 00:21:07,389
choice once we think it's worthwhile so

00:21:04,779 --> 00:21:08,529
to give you an example when we made it

00:21:07,389 --> 00:21:10,240
possible to generate this kind of

00:21:08,529 --> 00:21:13,389
dashboards for every consumer very

00:21:10,240 --> 00:21:14,919
easily we use a tool called wavefront we

00:21:13,389 --> 00:21:17,620
push our metrics to it and this is our

00:21:14,919 --> 00:21:19,240
visualization so on the top left corner

00:21:17,620 --> 00:21:21,009
is probably the most important top left

00:21:19,240 --> 00:21:22,480
here most important metric is the

00:21:21,009 --> 00:21:26,169
consumer lag if the consumers are

00:21:22,480 --> 00:21:27,879
lagging too much it basically means well

00:21:26,169 --> 00:21:29,320
they have they're in trouble so that's

00:21:27,879 --> 00:21:32,769
probably what people want to monitor our

00:21:29,320 --> 00:21:33,879
an important thing of that of wave front

00:21:32,769 --> 00:21:35,559
is that actually it makes it super easy

00:21:33,879 --> 00:21:39,970
to programmatically and automatically

00:21:35,559 --> 00:21:41,259
set up alerts so this kind of removes a

00:21:39,970 --> 00:21:42,549
lot of friction around setting up any

00:21:41,259 --> 00:21:44,500
because consumer and providing a quality

00:21:42,549 --> 00:21:46,360
experience but we also have more kind of

00:21:44,500 --> 00:21:50,080
fine greenview like hum end-to-end

00:21:46,360 --> 00:21:53,980
latency processing rates type of errors

00:21:50,080 --> 00:21:57,480
we see etc so this is but we also

00:21:53,980 --> 00:22:01,240
provided management tools so this is

00:21:57,480 --> 00:22:03,100
like a finger an edge case we have to

00:22:01,240 --> 00:22:04,840
face when you do this kind of

00:22:03,100 --> 00:22:07,389
transaction log system is you actually

00:22:04,840 --> 00:22:09,100
can end up with events which are logical

00:22:07,389 --> 00:22:10,539
corrupt I mean we are hoping for the

00:22:09,100 --> 00:22:12,519
system itself doesn't corrupt met

00:22:10,539 --> 00:22:14,179
messages I think there's a version of

00:22:12,519 --> 00:22:16,129
kafka which actually corrupts

00:22:14,179 --> 00:22:17,570
using it when it there's a core you have

00:22:16,129 --> 00:22:19,879
to work around the data corruption when

00:22:17,570 --> 00:22:22,730
using snappy but that can be resolved

00:22:19,879 --> 00:22:24,230
but at an application domain level you

00:22:22,730 --> 00:22:26,360
will also have poison pills would

00:22:24,230 --> 00:22:27,950
basically cannot messages which the

00:22:26,360 --> 00:22:32,600
consumer cannot process and doesn't know

00:22:27,950 --> 00:22:34,549
what to do so so this tool is basically

00:22:32,600 --> 00:22:37,190
allows us to once we detect where the

00:22:34,549 --> 00:22:39,440
consumer is stuck by it's like like

00:22:37,190 --> 00:22:41,389
growing we can actually investigate why

00:22:39,440 --> 00:22:43,429
if we know it's not the consumer failing

00:22:41,389 --> 00:22:44,509
because of operational reasons can

00:22:43,429 --> 00:22:46,519
actually look at the message which

00:22:44,509 --> 00:22:48,499
causes the problem we can put it to a

00:22:46,519 --> 00:22:51,529
hospital to unblock immediately and have

00:22:48,499 --> 00:22:55,549
quick mean time to recover like good

00:22:51,529 --> 00:22:57,080
mean NP TR and or and we all we can

00:22:55,549 --> 00:22:58,970
actually look at it and investigate it

00:22:57,080 --> 00:23:02,509
and see what's the actual cause and was

00:22:58,970 --> 00:23:08,389
the long-term resolution and this

00:23:02,509 --> 00:23:10,369
unfortunately is used quite a lot so but

00:23:08,389 --> 00:23:12,529
the ultimate validation of the idea is

00:23:10,369 --> 00:23:15,379
to have projects or systems which

00:23:12,529 --> 00:23:18,139
benefited from what we did and this is

00:23:15,379 --> 00:23:21,379
this is the view by the end I think end

00:23:18,139 --> 00:23:26,649
of October last year when we finish this

00:23:21,379 --> 00:23:29,149
first phase and this was around this was

00:23:26,649 --> 00:23:30,799
its focuses on messages creation because

00:23:29,149 --> 00:23:32,240
this is the topic common to all the

00:23:30,799 --> 00:23:34,580
components would I listed here but

00:23:32,240 --> 00:23:37,249
there's more basically yeah this is the

00:23:34,580 --> 00:23:40,669
core event message is created in the

00:23:37,249 --> 00:23:43,429
past our rails rails application would

00:23:40,669 --> 00:23:46,759
post this event to multiple rabid queues

00:23:43,429 --> 00:23:49,820
and then each pipeline will have its own

00:23:46,759 --> 00:23:54,249
worker doing something now it actually

00:23:49,820 --> 00:23:58,159
is posted once and everybody is the same

00:23:54,249 --> 00:24:00,830
event it helped rewrite hours it might

00:23:58,159 --> 00:24:03,110
it really helped our rewrite search

00:24:00,830 --> 00:24:07,759
project we moved to elasticsearch from a

00:24:03,110 --> 00:24:09,379
custom solution mmm it helped our data

00:24:07,759 --> 00:24:10,789
experts project which was which is very

00:24:09,379 --> 00:24:14,210
important for our customer for legal

00:24:10,789 --> 00:24:18,110
reasons but was very old and frequently

00:24:14,210 --> 00:24:20,269
failing and it also helped our message

00:24:18,110 --> 00:24:22,340
delivery as I said in the past there are

00:24:20,269 --> 00:24:24,559
multiple views we must materialize them

00:24:22,340 --> 00:24:26,450
on right and the old system this was

00:24:24,559 --> 00:24:27,440
done in one transaction and these

00:24:26,450 --> 00:24:28,909
aggregate views like

00:24:27,440 --> 00:24:33,039
who fought the four people who follow me

00:24:28,909 --> 00:24:35,960
or etc their complex their complex and

00:24:33,039 --> 00:24:38,870
costly to compute so they actually could

00:24:35,960 --> 00:24:41,269
cause failures on our inbox and group

00:24:38,870 --> 00:24:42,559
delivery whereas probably people don't

00:24:41,269 --> 00:24:44,299
care so much about the aggregations

00:24:42,559 --> 00:24:46,220
where's inbox and group delivery

00:24:44,299 --> 00:24:50,360
supercritical and we want to decouple

00:24:46,220 --> 00:24:53,299
them and this event log concept made it

00:24:50,360 --> 00:24:57,710
super made it very easy to actually do

00:24:53,299 --> 00:25:03,379
that so what kind of problems we face

00:24:57,710 --> 00:25:04,549
because it wasn't all rosy so this was

00:25:03,379 --> 00:25:06,289
actually probably one of the biggest

00:25:04,549 --> 00:25:09,080
problems which we still haven't resolved

00:25:06,289 --> 00:25:11,450
it's we're kind of turning a blind eye

00:25:09,080 --> 00:25:17,840
on it so what to actually publish in our

00:25:11,450 --> 00:25:20,629
events because ideally would publish IDs

00:25:17,840 --> 00:25:22,820
like this model change and this is the

00:25:20,629 --> 00:25:25,610
version after the change so you can

00:25:22,820 --> 00:25:27,169
actually access the state at the event

00:25:25,610 --> 00:25:28,700
emission time but that requires

00:25:27,169 --> 00:25:34,250
immutable version data which we don't

00:25:28,700 --> 00:25:36,529
have in most places and it also requires

00:25:34,250 --> 00:25:38,570
you to have uniform resource identifier

00:25:36,529 --> 00:25:41,690
than well I mean we obviously do have

00:25:38,570 --> 00:25:45,019
those but we many places they are full

00:25:41,690 --> 00:25:46,549
of our different conventions so we're

00:25:45,019 --> 00:25:49,250
trying to address this obviously but

00:25:46,549 --> 00:25:51,500
this is a transitional problem so I

00:25:49,250 --> 00:25:54,889
think in in quite a few places where the

00:25:51,500 --> 00:25:57,379
size was actually a problem we should

00:25:54,889 --> 00:25:59,960
lucky enough to have version data and we

00:25:57,379 --> 00:26:03,820
use actually identify errs but in other

00:25:59,960 --> 00:26:06,409
places we are publishing the whole data

00:26:03,820 --> 00:26:09,110
where we can or we are trying to work

00:26:06,409 --> 00:26:12,399
around this but ideally you want to go

00:26:09,110 --> 00:26:15,850
to a mutable data and your eyes and

00:26:12,399 --> 00:26:18,889
something we've discovered is actually

00:26:15,850 --> 00:26:21,580
that as the application grows well

00:26:18,889 --> 00:26:24,409
there's a single model owner which

00:26:21,580 --> 00:26:26,480
coordinates the right actually as we

00:26:24,409 --> 00:26:27,980
build features we enrich the model so

00:26:26,480 --> 00:26:31,250
the different enrichments may have

00:26:27,980 --> 00:26:32,690
different owners but it's because we

00:26:31,250 --> 00:26:34,759
don't want to have a topic explosion we

00:26:32,690 --> 00:26:36,139
want to have it conceptually grow with

00:26:34,759 --> 00:26:38,149
the number of models we have not with

00:26:36,139 --> 00:26:41,090
the number of features which come and go

00:26:38,149 --> 00:26:45,800
and we will want to share a topic

00:26:41,090 --> 00:26:47,870
and we had to actually learn like we had

00:26:45,800 --> 00:26:49,610
this is something we were challenged

00:26:47,870 --> 00:26:51,080
initially we were kind of lost like our

00:26:49,610 --> 00:26:52,760
consumers were failing because somebody

00:26:51,080 --> 00:26:55,130
some peas are publishing something new

00:26:52,760 --> 00:26:58,280
and that's why this tool live later

00:26:55,130 --> 00:27:01,340
earlier showed about for handling bad

00:26:58,280 --> 00:27:03,470
messages was used quite often but yeah

00:27:01,340 --> 00:27:05,300
we're at the moment I think it's very

00:27:03,470 --> 00:27:07,340
and it doesn't happen I mean people

00:27:05,300 --> 00:27:09,530
we've learned how to write our consumers

00:27:07,340 --> 00:27:10,760
in a resilient fashion so we know what

00:27:09,530 --> 00:27:13,310
we are interested in and if it's not

00:27:10,760 --> 00:27:18,080
what we are what we want we can skip it

00:27:13,310 --> 00:27:19,430
and just move on so yeah there's a yeah

00:27:18,080 --> 00:27:22,370
we learned that we are actually sharing

00:27:19,430 --> 00:27:24,230
data streams and and that this can be

00:27:22,370 --> 00:27:26,060
costly there is also add option

00:27:24,230 --> 00:27:28,670
challenges this is kind of a more

00:27:26,060 --> 00:27:30,920
organizational problem than software

00:27:28,670 --> 00:27:34,730
architectural problem it is a big part

00:27:30,920 --> 00:27:37,790
of paradigm shift especially this bit

00:27:34,730 --> 00:27:39,620
moving from commands to events and we

00:27:37,790 --> 00:27:41,120
have three offices in two time zones and

00:27:39,620 --> 00:27:43,280
there are eight hour difference there's

00:27:41,120 --> 00:27:45,950
a night hour difference and the team

00:27:43,280 --> 00:27:49,430
which develops this worked on it mostly

00:27:45,950 --> 00:27:51,680
is in London so knowledge dissemination

00:27:49,430 --> 00:27:55,100
in an organization of I think two

00:27:51,680 --> 00:27:57,050
hundred engineers takes time at the

00:27:55,100 --> 00:27:59,750
moment it means that I quite often am on

00:27:57,050 --> 00:28:02,150
a call late at night trying to help

00:27:59,750 --> 00:28:05,150
people use like start using this and

00:28:02,150 --> 00:28:07,520
long term I'm hoping like as people use

00:28:05,150 --> 00:28:09,760
it more there are more examples which it

00:28:07,520 --> 00:28:11,990
won't be required but this is a cost

00:28:09,760 --> 00:28:15,470
furthermore reaction of experts on this

00:28:11,990 --> 00:28:17,810
either I mean we were probably working

00:28:15,470 --> 00:28:20,540
closest to it we know most about it but

00:28:17,810 --> 00:28:23,330
we're still learning so that's also

00:28:20,540 --> 00:28:24,860
something we have to accept but good

00:28:23,330 --> 00:28:26,960
news is but even if it's in perfect it

00:28:24,860 --> 00:28:29,180
actually had been big impact on network

00:28:26,960 --> 00:28:30,740
it really helped it really the coupled a

00:28:29,180 --> 00:28:33,530
lot of teams allowed them to build

00:28:30,740 --> 00:28:38,300
things faster and in a more resilient

00:28:33,530 --> 00:28:40,100
way dealing with performance reliability

00:28:38,300 --> 00:28:42,110
concerns much later than they usually

00:28:40,100 --> 00:28:46,730
would have to because they work in

00:28:42,110 --> 00:28:48,170
isolation of other components one

00:28:46,730 --> 00:28:50,900
favorite we discovered and we kind of

00:28:48,170 --> 00:28:52,490
didn't know explicitly in before I mean

00:28:50,900 --> 00:28:54,410
it's no big news but it was something

00:28:52,490 --> 00:28:55,399
which came out of this work it was

00:28:54,410 --> 00:28:59,409
hidden in our

00:28:55,399 --> 00:29:02,119
system before that we we have workflows

00:28:59,409 --> 00:29:03,859
so basically and what I've highlighted

00:29:02,119 --> 00:29:05,960
one of the work folks would we get which

00:29:03,859 --> 00:29:09,739
which is quite explicit in our pipeline

00:29:05,960 --> 00:29:13,879
is this delivery to inbox group and

00:29:09,739 --> 00:29:16,580
aggregations is actually it's it has to

00:29:13,879 --> 00:29:18,289
be coordinated to an extent and the

00:29:16,580 --> 00:29:20,509
coordinator is that the delivery service

00:29:18,289 --> 00:29:22,789
that the service which listen to some

00:29:20,509 --> 00:29:25,369
event and translates into events which

00:29:22,789 --> 00:29:27,769
then those systems listen to to an

00:29:25,369 --> 00:29:31,460
extent so they use the event log it is

00:29:27,769 --> 00:29:34,249
an ok usage but actually we have to do a

00:29:31,460 --> 00:29:37,190
lot of plumbing as in we have to

00:29:34,249 --> 00:29:39,139
actually make sure we have to maintain a

00:29:37,190 --> 00:29:41,509
state machine we have to make sure that

00:29:39,139 --> 00:29:42,979
things transition correctly this is

00:29:41,509 --> 00:29:45,169
long-term we don't want to do that

00:29:42,979 --> 00:29:47,119
manually we we want this to be solved

00:29:45,169 --> 00:29:49,940
for us we want to have a higher level of

00:29:47,119 --> 00:29:51,649
abstraction so more or less like this an

00:29:49,940 --> 00:29:53,899
event but the message good creator comes

00:29:51,649 --> 00:29:56,779
in the delivery system picks it up and

00:29:53,899 --> 00:30:00,739
it distributes the task to the three

00:29:56,779 --> 00:30:03,320
different deliveries and once it's

00:30:00,739 --> 00:30:06,379
finished it's like a fort for drawing

00:30:03,320 --> 00:30:08,149
type of job once it's finished it

00:30:06,379 --> 00:30:10,070
publishes back the state change okay

00:30:08,149 --> 00:30:12,320
this message has been delivered you can

00:30:10,070 --> 00:30:19,099
maybe notify the mobile clients because

00:30:12,320 --> 00:30:21,289
the view is already persisted so so if

00:30:19,099 --> 00:30:22,399
you look at it what's workflows really

00:30:21,289 --> 00:30:24,200
are from our point of view this is like

00:30:22,399 --> 00:30:25,909
a transformation logic which lives

00:30:24,200 --> 00:30:28,429
outside of the view service boundaries

00:30:25,909 --> 00:30:29,960
it's quite often more complex it might

00:30:28,429 --> 00:30:33,109
require retries that you want to maybe

00:30:29,960 --> 00:30:34,849
scale it out and because it's especially

00:30:33,109 --> 00:30:36,919
like a good example where you want to

00:30:34,849 --> 00:30:38,599
scale it out is we have something called

00:30:36,919 --> 00:30:40,279
an announcement the group can have up to

00:30:38,599 --> 00:30:41,570
30,000 people when you post an

00:30:40,279 --> 00:30:43,429
announcement you want to deliver that

00:30:41,570 --> 00:30:45,440
announcement to everybody that's a big

00:30:43,429 --> 00:30:49,099
fan out if you're doing materialization

00:30:45,440 --> 00:30:50,839
right so that you would like to like you

00:30:49,099 --> 00:30:52,909
want to chunk it up make it do some of

00:30:50,839 --> 00:30:56,119
this work in parallel and retry the jobs

00:30:52,909 --> 00:31:00,240
but failed so this is effectively stream

00:30:56,119 --> 00:31:02,460
processing see QRS kind of conceptually

00:31:00,240 --> 00:31:03,720
and yes we can express them but as I

00:31:02,460 --> 00:31:05,250
said before we have to do too much

00:31:03,720 --> 00:31:07,679
manual work about setting up the

00:31:05,250 --> 00:31:09,120
coordination where's we would like to

00:31:07,679 --> 00:31:10,860
just model to work flow because that's

00:31:09,120 --> 00:31:12,480
what that's the domain model is a

00:31:10,860 --> 00:31:15,210
workflow it's not whether we publish to

00:31:12,480 --> 00:31:16,410
this and read from that so we basically

00:31:15,210 --> 00:31:17,790
are looking for a higher level of

00:31:16,410 --> 00:31:19,800
abstraction and I will come back to this

00:31:17,790 --> 00:31:21,360
later in the talk but this is the kind

00:31:19,800 --> 00:31:27,330
of thing we've discovered and this is

00:31:21,360 --> 00:31:30,600
like an open problem for us and so

00:31:27,330 --> 00:31:32,640
what's the future because this is not

00:31:30,600 --> 00:31:34,740
finished work so we want to move the

00:31:32,640 --> 00:31:36,630
fully managed solution so as I've

00:31:34,740 --> 00:31:39,660
mentioned earlier we are running running

00:31:36,630 --> 00:31:42,090
Kafka and we actually run running it in

00:31:39,660 --> 00:31:44,160
our own data center which basically

00:31:42,090 --> 00:31:46,950
means a lot of headaches dealing with

00:31:44,160 --> 00:31:48,510
outages like house going down for

00:31:46,950 --> 00:31:50,540
physical reasons the actual instance

00:31:48,510 --> 00:31:52,800
having problems because of something and

00:31:50,540 --> 00:31:55,860
if we want to scale we have to do it

00:31:52,800 --> 00:32:01,130
effectively manually so that's not great

00:31:55,860 --> 00:32:04,140
that costs us operational resources and

00:32:01,130 --> 00:32:09,440
we would like to provide our X bindings

00:32:04,140 --> 00:32:12,270
because it's like event log is

00:32:09,440 --> 00:32:13,920
effectively an event stream and RX is so

00:32:12,270 --> 00:32:17,490
well suited so how many people use

00:32:13,920 --> 00:32:23,460
directs just too ok how many people are

00:32:17,490 --> 00:32:25,320
familiar with it ok so it's it's

00:32:23,460 --> 00:32:29,130
basically reactive stream processing so

00:32:25,320 --> 00:32:30,990
I think like looking at talks about

00:32:29,130 --> 00:32:32,700
flank I think that expose a similar API

00:32:30,990 --> 00:32:35,960
basically have stream of events you can

00:32:32,700 --> 00:32:39,030
map you can filter you can aggregate etc

00:32:35,960 --> 00:32:41,309
it comes from i means I don't know where

00:32:39,030 --> 00:32:47,130
it was originally invented but it's been

00:32:41,309 --> 00:32:48,690
popularized by Netflix recently and we

00:32:47,130 --> 00:32:51,870
want to remove the centralization HTTP

00:32:48,690 --> 00:32:54,030
proxy and that are ex-library would be

00:32:51,870 --> 00:32:57,929
very useful for that and we want to find

00:32:54,030 --> 00:32:59,730
a solution for the workflows so that we

00:32:57,929 --> 00:33:02,240
have ongoing so coming back to this

00:32:59,730 --> 00:33:04,440
managed solution we have an ongoing

00:33:02,240 --> 00:33:06,720
migration to event hubs well we are a

00:33:04,440 --> 00:33:09,150
subsidiary of microsoft's so it's kind

00:33:06,720 --> 00:33:12,179
of natural to go to usher but event hubs

00:33:09,150 --> 00:33:13,929
are basically an event log offering like

00:33:12,179 --> 00:33:16,360
Kafka recognizes but it's fully man

00:33:13,929 --> 00:33:19,059
in this house integer so that means but

00:33:16,360 --> 00:33:20,529
for us if there if if a host which is

00:33:19,059 --> 00:33:21,999
responsible for some partitions goes

00:33:20,529 --> 00:33:24,610
down that happens behind the scenes we

00:33:21,999 --> 00:33:25,809
don't know about it even and we don't

00:33:24,610 --> 00:33:29,139
have to deal with provisioning in any

00:33:25,809 --> 00:33:33,690
way we just simply move a slider we have

00:33:29,139 --> 00:33:37,090
more transaction units so that's big

00:33:33,690 --> 00:33:40,749
operational benefit for us it's mqp

00:33:37,090 --> 00:33:42,909
point one point oh well use that

00:33:40,749 --> 00:33:44,850
protocol so that means interoperable it

00:33:42,909 --> 00:33:48,639
is not tied to any particular language

00:33:44,850 --> 00:33:51,940
and its successful use internally and

00:33:48,639 --> 00:33:54,159
externally actually we use it or we have

00:33:51,940 --> 00:33:56,860
already migrated our Kafka metrics Kafka

00:33:54,159 --> 00:33:59,529
to this to event hubs the reason is a

00:33:56,860 --> 00:34:00,879
different concern for us to move this

00:33:59,529 --> 00:34:02,610
part of the system to vent hubs is

00:34:00,879 --> 00:34:06,519
because requirements are very different

00:34:02,610 --> 00:34:08,669
metrics can lose data and obviously we

00:34:06,519 --> 00:34:11,169
don't want it but it's acceptable and

00:34:08,669 --> 00:34:13,569
it's obviously throughput oriented

00:34:11,169 --> 00:34:15,730
whereas we are much more latency

00:34:13,569 --> 00:34:17,230
oriented and like we want to minimize

00:34:15,730 --> 00:34:20,049
latency because it drives user

00:34:17,230 --> 00:34:24,220
experience and we can also stata we want

00:34:20,049 --> 00:34:25,960
to publish synchronously and we're also

00:34:24,220 --> 00:34:29,799
working as part of this work we are

00:34:25,960 --> 00:34:31,179
building the RX java sdk we are using we

00:34:29,799 --> 00:34:34,359
are building it on top of the utterer

00:34:31,179 --> 00:34:36,669
sdk which is provided by a service

00:34:34,359 --> 00:34:38,049
fabric team des des kay is powered by

00:34:36,669 --> 00:34:41,169
present ray which is I think the only

00:34:38,049 --> 00:34:43,389
implementation of of MVP one point 0 at

00:34:41,169 --> 00:34:46,809
the moment but it provides also some

00:34:43,389 --> 00:34:48,280
sort of of the higher-level concerns for

00:34:46,809 --> 00:34:49,480
us it deals with higher level concerns

00:34:48,280 --> 00:34:51,879
which we don't want to deal with

00:34:49,480 --> 00:34:53,559
basically it provides us of the tracking

00:34:51,879 --> 00:34:55,149
so it allows us to keep track where in

00:34:53,559 --> 00:34:57,059
the event stream we are in case of a

00:34:55,149 --> 00:34:59,950
restart failure in this kind of scenario

00:34:57,059 --> 00:35:04,299
plus I assume everybody is familiar with

00:34:59,950 --> 00:35:06,130
Kafka but just briefly there's a Kafka

00:35:04,299 --> 00:35:09,450
as a concept of a topic and the topic is

00:35:06,130 --> 00:35:13,000
Charlotte across multiple partitions and

00:35:09,450 --> 00:35:15,819
that allows to scale processing for

00:35:13,000 --> 00:35:17,230
fruit put but what that means in our

00:35:15,819 --> 00:35:20,079
kind of scenario we want to have one

00:35:17,230 --> 00:35:21,520
consumer / shard because we want to

00:35:20,079 --> 00:35:24,069
process events sequentially one after

00:35:21,520 --> 00:35:26,750
another so the problem we are facing is

00:35:24,069 --> 00:35:30,530
if we are scaling our consumers out

00:35:26,750 --> 00:35:32,120
we while we try one of them can die at

00:35:30,530 --> 00:35:33,860
some point and we want it we want to

00:35:32,120 --> 00:35:36,590
somebody else resume but we want to have

00:35:33,860 --> 00:35:40,270
only one and we want to have them evenly

00:35:36,590 --> 00:35:42,950
spread across the VMS so that's an

00:35:40,270 --> 00:35:44,420
interesting problem but it's not our

00:35:42,950 --> 00:35:47,570
business domain so we don't want to deal

00:35:44,420 --> 00:35:49,700
with it so that's our that's why we are

00:35:47,570 --> 00:35:51,200
using the sdk for measure because there

00:35:49,700 --> 00:35:53,420
are for instance JMS bindings if

00:35:51,200 --> 00:35:59,090
somebody is not so much interested in

00:35:53,420 --> 00:36:00,110
these in these issues and and we are

00:35:59,090 --> 00:36:03,190
effectively raising the level of

00:36:00,110 --> 00:36:06,680
abstraction we hide the whole amqp

00:36:03,190 --> 00:36:09,230
tracking file / kind of business and

00:36:06,680 --> 00:36:11,060
we're providing and observable here we

00:36:09,230 --> 00:36:15,040
go there's your stream of events map it

00:36:11,060 --> 00:36:20,510
transform it do whatever you want but

00:36:15,040 --> 00:36:22,250
this is ongoing work and going forward

00:36:20,510 --> 00:36:24,140
yes I coming back to the workflows this

00:36:22,250 --> 00:36:27,320
is something which is more in the future

00:36:24,140 --> 00:36:32,060
we are looking to use our service fabric

00:36:27,320 --> 00:36:35,210
reliable actors this is a high level

00:36:32,060 --> 00:36:37,910
pass offering for murderer it's quite

00:36:35,210 --> 00:36:39,920
widely used within a juror and it powers

00:36:37,910 --> 00:36:41,840
I think event hubs and all the

00:36:39,920 --> 00:36:46,820
management sites for instance for

00:36:41,840 --> 00:36:48,740
forever and it's based on a project

00:36:46,820 --> 00:36:50,210
Orleans this is a research project from

00:36:48,740 --> 00:36:53,600
which I think has an open source

00:36:50,210 --> 00:36:55,760
implementation now it's based it was

00:36:53,600 --> 00:36:58,850
came out of microsoft research and it

00:36:55,760 --> 00:37:01,940
was actually successful used for halo to

00:36:58,850 --> 00:37:06,410
keep track of user stats they use actors

00:37:01,940 --> 00:37:08,960
to represent users and they manage all

00:37:06,410 --> 00:37:11,180
their kind of loading unloading from

00:37:08,960 --> 00:37:13,340
memory when the user comes online and it

00:37:11,180 --> 00:37:17,950
allowed them to build a very responsive

00:37:13,340 --> 00:37:17,950
and highly scalable experience for halo

00:37:18,160 --> 00:37:25,640
so yeah to summarize yeah if by the way

00:37:24,200 --> 00:37:28,250
just to finish up this is publicly

00:37:25,640 --> 00:37:30,350
available and I think it's available for

00:37:28,250 --> 00:37:36,710
dotnet but they are working as we speak

00:37:30,350 --> 00:37:37,490
on I've on the java java linux mmm set

00:37:36,710 --> 00:37:39,020
up

00:37:37,490 --> 00:37:42,080
and you can actually run it locally as

00:37:39,020 --> 00:37:48,920
well if you want and it's pretty easy to

00:37:42,080 --> 00:37:51,020
use so just to summarize we successfully

00:37:48,920 --> 00:37:53,570
used event sourcing to solve our SLA and

00:37:51,020 --> 00:37:55,850
velocity problems which we inflicted

00:37:53,570 --> 00:37:59,420
ourselves using building a massive

00:37:55,850 --> 00:38:00,560
monolith and then distributing it and it

00:37:59,420 --> 00:38:02,420
actually helped us address both

00:38:00,560 --> 00:38:06,619
architectural and organizational aspects

00:38:02,420 --> 00:38:07,910
of the problem which was nice and what

00:38:06,619 --> 00:38:09,470
was important for us and actually

00:38:07,910 --> 00:38:12,710
getting this project through was that we

00:38:09,470 --> 00:38:14,330
focus on the internet if approach which

00:38:12,710 --> 00:38:17,690
allowed us to reduce risk and deliver

00:38:14,330 --> 00:38:20,420
value early and this is still ongoing

00:38:17,690 --> 00:38:23,240
work so yeah it's not finished and

00:38:20,420 --> 00:38:31,250
hopefully if we'll continue so yeah

00:38:23,240 --> 00:38:32,900
thank you are there any questions thank

00:38:31,250 --> 00:38:34,580
you for your talk we just have two

00:38:32,900 --> 00:38:37,340
minutes the question need to be really

00:38:34,580 --> 00:38:44,930
short sorry because we have a closing

00:38:37,340 --> 00:38:47,330
session how do we okay at six well

00:38:44,930 --> 00:38:49,490
actually I have two questions um the

00:38:47,330 --> 00:38:51,500
first one is how do you deal with a

00:38:49,490 --> 00:38:53,480
long-term persistence of the events do

00:38:51,500 --> 00:38:55,609
you store them for longer than well

00:38:53,480 --> 00:38:56,810
maybe a couple of days or how do you

00:38:55,609 --> 00:39:01,430
deal with that and the second question

00:38:56,810 --> 00:39:04,220
is how do you previous failure in in the

00:39:01,430 --> 00:39:05,930
different consumers what happens if some

00:39:04,220 --> 00:39:07,640
if there is some back in the consumer

00:39:05,930 --> 00:39:10,280
the typical approach and events sourcing

00:39:07,640 --> 00:39:15,320
is to just recalculate the whole lock

00:39:10,280 --> 00:39:16,430
how are you dealing with that so so we

00:39:15,320 --> 00:39:18,290
wanted to have this kind of ideal

00:39:16,430 --> 00:39:21,460
scenario and this is the one Kafka or

00:39:18,290 --> 00:39:23,390
what comes next is kind of the whole log

00:39:21,460 --> 00:39:27,770
unfortunately we cannot do that because

00:39:23,390 --> 00:39:30,950
we have compliance concerns and we have

00:39:27,770 --> 00:39:32,540
to enable easy deletion of PII data and

00:39:30,950 --> 00:39:36,770
that would be very difficult to do in

00:39:32,540 --> 00:39:39,560
Kafka and basically our customers when

00:39:36,770 --> 00:39:41,300
they stopped using Yammer or of a 65 of

00:39:39,560 --> 00:39:43,460
rank they have a guarantee that within

00:39:41,300 --> 00:39:46,940
some number of days their data just

00:39:43,460 --> 00:39:49,280
disappears so for that we actually use

00:39:46,940 --> 00:39:51,250
the that's why we mentioned that there's

00:39:49,280 --> 00:39:56,510
this data owner who

00:39:51,250 --> 00:40:00,530
database and then so we use Kafka or

00:39:56,510 --> 00:40:02,599
event log a bit like a more more like a

00:40:00,530 --> 00:40:04,790
transport layer the moment so if we need

00:40:02,599 --> 00:40:06,530
to we could put like if we move to

00:40:04,790 --> 00:40:08,450
immutable version data we could use the

00:40:06,530 --> 00:40:11,240
primary data source which is the data is

00:40:08,450 --> 00:40:14,329
written in the service which receives

00:40:11,240 --> 00:40:16,400
the request before it publishes to the

00:40:14,329 --> 00:40:18,770
event log we could use it to regenerate

00:40:16,400 --> 00:40:24,290
the events and get consumers to reply

00:40:18,770 --> 00:40:29,240
and the African was yeah it was like

00:40:24,290 --> 00:40:31,640
about restoring a consumer we actually

00:40:29,240 --> 00:40:35,089
recently had a scenario we had to

00:40:31,640 --> 00:40:41,180
restart it from backup and replied the

00:40:35,089 --> 00:40:42,799
difference do we have more questions can

00:40:41,180 --> 00:40:45,190
we please take it offline because we

00:40:42,799 --> 00:40:49,250
have a closing session on castle house

00:40:45,190 --> 00:40:56,980
okay thank you ladies and gentlemen for

00:40:49,250 --> 00:40:56,980
your presence thank you cube okay

00:41:03,600 --> 00:41:05,660

YouTube URL: https://www.youtube.com/watch?v=SFD8AHXmDyQ


