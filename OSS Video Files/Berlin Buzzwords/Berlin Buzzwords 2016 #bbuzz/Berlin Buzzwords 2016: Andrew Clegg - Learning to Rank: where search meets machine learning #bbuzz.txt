Title: Berlin Buzzwords 2016: Andrew Clegg - Learning to Rank: where search meets machine learning #bbuzz
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Learning to Rank (LTR), once the domain of academic researchers in machine learning and information retrieval, has begun to make great headway in practical applications on the web. Its tools and techniques offer a new way to think about challenges in relevance ranking, personalization, localization, ad targeting and multimedia search, but it shares enough conceptual foundations with traditional search relevance that it’s easy for hands-on engineers to get started with.

In this talk, Andrew will introduce the field and its key concepts, before diving into one of its best-known algorithms, Ranking SVM, which adapts Support Vector Machines to ranking tasks instead of classification problems.

With real examples taken from work at Etsy and elsewhere, he’ll talk about how you can use this algorithm and others like it to incorporate a huge variety of features into your search ranking model: query-specific term weights, implicit user feedback, temporal and geographic data, and even image features. And he’ll touch on applications of LTR beyond traditional search, including ad click prediction and content-based recommendations.

No past experience of machine learning will be required. Attendees can expect to leave this talk with an understanding of LTR and its applications, and enough insight into Ranking SVM to enable them to experiment with ranking models on their own data.

Read more:
https://2016.berlinbuzzwords.de/session/learning-rank-where-search-meets-machine-learning

About Andrew Clegg:
https://2016.berlinbuzzwords.de/users/andrew-clegg

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:03,560 --> 00:00:10,410
hello hi I'm Andy I'm a data scientist

00:00:07,799 --> 00:00:13,259
at Etsy the global marketplace for

00:00:10,410 --> 00:00:16,379
handmade goods vintage goods and arts

00:00:13,259 --> 00:00:19,170
and crafts and it's great to be back at

00:00:16,379 --> 00:00:19,800
Berlin buzzwords and my sound is gone no

00:00:19,170 --> 00:00:23,220
it's okay

00:00:19,800 --> 00:00:27,119
so hi my talks about learning to rank or

00:00:23,220 --> 00:00:29,429
LTR a field which applies the methods of

00:00:27,119 --> 00:00:32,340
machine learning to the challenges of

00:00:29,429 --> 00:00:34,200
search rovings ranking it's quite a big

00:00:32,340 --> 00:00:36,690
topic so I'm hoping to give you an

00:00:34,200 --> 00:00:41,250
introduction along with some pointers to

00:00:36,690 --> 00:00:43,050
more information first i'm going to set

00:00:41,250 --> 00:00:45,989
the scene by introducing the problem

00:00:43,050 --> 00:00:48,090
that ltr' tries to solve then i'll talk

00:00:45,989 --> 00:00:50,100
a bit about how to turn documents or

00:00:48,090 --> 00:00:52,289
other items from your site or product

00:00:50,100 --> 00:00:54,390
into a representation that machine

00:00:52,289 --> 00:00:55,829
learning algorithm can train on and then

00:00:54,390 --> 00:00:58,109
i'll describe how that training process

00:00:55,829 --> 00:01:01,140
works using the example of support

00:00:58,109 --> 00:01:02,789
vector machines or SVM's and then at the

00:01:01,140 --> 00:01:05,400
end i'll talk about some of the issues

00:01:02,789 --> 00:01:10,080
you might encounter around using ltr'

00:01:05,400 --> 00:01:12,420
and production so to introduce the topic

00:01:10,080 --> 00:01:14,880
let's talk quickly about how search

00:01:12,420 --> 00:01:16,320
relevance ranking typically works and

00:01:14,880 --> 00:01:18,659
we'll keep it fairly brief because this

00:01:16,320 --> 00:01:20,640
is buzzwords this is the search track so

00:01:18,659 --> 00:01:25,619
I guess it has probably be familiar to

00:01:20,640 --> 00:01:27,750
many of you so imagine you're running an

00:01:25,619 --> 00:01:29,700
e-commerce site and your items consist

00:01:27,750 --> 00:01:33,210
of product titles or descriptions like

00:01:29,700 --> 00:01:33,900
say purple hand-woven unicorn hair

00:01:33,210 --> 00:01:36,750
sweater

00:01:33,900 --> 00:01:38,790
now when you index these items into a

00:01:36,750 --> 00:01:40,380
search engine like Lucene they're

00:01:38,790 --> 00:01:43,290
represented internally as a collection

00:01:40,380 --> 00:01:44,970
of terms and associated weights based on

00:01:43,290 --> 00:01:48,869
their turn frequencies and their

00:01:44,970 --> 00:01:50,909
document frequencies now when you user

00:01:48,869 --> 00:01:52,619
enters a query the query terms are

00:01:50,909 --> 00:01:55,159
assigned weights based on their document

00:01:52,619 --> 00:01:58,049
frequencies and we can think of the term

00:01:55,159 --> 00:02:01,200
sorry the item in the query as sparse

00:01:58,049 --> 00:02:04,619
term vectors in other words key value

00:02:01,200 --> 00:02:06,180
maps where the keys are terms and the

00:02:04,619 --> 00:02:08,879
values of the weights associated with

00:02:06,180 --> 00:02:11,430
those terms now any terms not present in

00:02:08,879 --> 00:02:14,209
a particular term vector implicitly have

00:02:11,430 --> 00:02:14,209
a value of zero

00:02:14,310 --> 00:02:19,660
so for each item that contains the query

00:02:17,110 --> 00:02:22,180
terms y either passes any filters that

00:02:19,660 --> 00:02:23,740
your search engine is applied the search

00:02:22,180 --> 00:02:27,160
end will calculate the cosine similarity

00:02:23,740 --> 00:02:28,360
between the query and the item if you

00:02:27,160 --> 00:02:30,010
think of the query in the item as

00:02:28,360 --> 00:02:31,870
vectors in a multi-dimensional space

00:02:30,010 --> 00:02:35,020
it's just the cosine of the angle

00:02:31,870 --> 00:02:37,390
between them so then if you sort the

00:02:35,020 --> 00:02:39,990
items by that score in descending order

00:02:37,390 --> 00:02:43,270
that will give you the search ranking

00:02:39,990 --> 00:02:44,860
now this is a huge oversimplification of

00:02:43,270 --> 00:02:46,600
something of how something like Lucene

00:02:44,860 --> 00:02:48,760
actually scores documents under the

00:02:46,600 --> 00:02:52,840
covers but it's close enough for the

00:02:48,760 --> 00:02:53,800
purposes of the example now things get a

00:02:52,840 --> 00:02:56,590
bit more complex

00:02:53,800 --> 00:02:58,240
if each item has multiple fields like

00:02:56,590 --> 00:03:01,870
say a news article where you might have

00:02:58,240 --> 00:03:03,940
title body text and comments the search

00:03:01,870 --> 00:03:06,040
engine will score the query against each

00:03:03,940 --> 00:03:08,440
of those fields separately and then

00:03:06,040 --> 00:03:11,050
combine the scores scaling them by

00:03:08,440 --> 00:03:13,390
whatever constants you provide this lets

00:03:11,050 --> 00:03:15,730
you weight hits against the title more

00:03:13,390 --> 00:03:20,470
or hits against the comment section less

00:03:15,730 --> 00:03:22,090
for example now you might also want to

00:03:20,470 --> 00:03:24,520
modify the relevance score by other

00:03:22,090 --> 00:03:27,190
external factors like the items

00:03:24,520 --> 00:03:29,080
popularity or age or even its proximity

00:03:27,190 --> 00:03:30,010
to the user for example if you're

00:03:29,080 --> 00:03:32,020
ranking

00:03:30,010 --> 00:03:34,630
hotels or restaurants or something like

00:03:32,020 --> 00:03:36,580
that you might even want to multiply the

00:03:34,630 --> 00:03:39,460
relevant score by an arbitrary constant

00:03:36,580 --> 00:03:41,170
here one point five or two point naught

00:03:39,460 --> 00:03:43,330
or something if the user has previously

00:03:41,170 --> 00:03:45,840
favorited that item in order to start

00:03:43,330 --> 00:03:47,920
personalizing the search results

00:03:45,840 --> 00:03:50,770
you probably need to experiment with

00:03:47,920 --> 00:03:53,410
different scaling constants and in fact

00:03:50,770 --> 00:03:55,480
different scaling formulae to actually

00:03:53,410 --> 00:03:58,990
weight the original textual similarity

00:03:55,480 --> 00:04:00,490
against all these other factors so let's

00:03:58,990 --> 00:04:03,010
instead just think of each of these as a

00:04:00,490 --> 00:04:04,630
function of the original score and the

00:04:03,010 --> 00:04:08,050
other signals that you're taking into

00:04:04,630 --> 00:04:09,790
account you know age or distance or a

00:04:08,050 --> 00:04:13,180
binary flag like user has favorited this

00:04:09,790 --> 00:04:18,340
item the functions will encapsulate any

00:04:13,180 --> 00:04:20,049
scaling constants that you've set but

00:04:18,340 --> 00:04:22,630
then how can we combine all of these

00:04:20,049 --> 00:04:25,460
different factors into a single overall

00:04:22,630 --> 00:04:26,990
scoring function in a principled way

00:04:25,460 --> 00:04:29,210
a function of all of these different

00:04:26,990 --> 00:04:32,000
signals and the original relevant scores

00:04:29,210 --> 00:04:34,699
and then how can we keep the individual

00:04:32,000 --> 00:04:35,360
scaling factors up-to-date without them

00:04:34,699 --> 00:04:37,099
becoming

00:04:35,360 --> 00:04:42,410
magic numbers that you end up trusting

00:04:37,099 --> 00:04:44,150
without ever revisiting or retesting so

00:04:42,410 --> 00:04:45,650
one way to approach this challenge is to

00:04:44,150 --> 00:04:47,990
treat search relevance as a machine

00:04:45,650 --> 00:04:49,370
learning problem and learn this overall

00:04:47,990 --> 00:04:52,130
ranking function from historical data

00:04:49,370 --> 00:04:58,580
and this is the essence of learnings

00:04:52,130 --> 00:05:01,400
ranked so to do this you need to treat

00:04:58,580 --> 00:05:03,440
each item as a sparse vector of features

00:05:01,400 --> 00:05:05,300
with weights and this is a

00:05:03,440 --> 00:05:08,570
generalization of the idea of a term

00:05:05,300 --> 00:05:11,449
vector the features can include terms in

00:05:08,570 --> 00:05:14,120
specific fields with their tf-idf weight

00:05:11,449 --> 00:05:17,210
for example hair appears in the title

00:05:14,120 --> 00:05:18,889
field and its tf-idf weight is 0.25 in

00:05:17,210 --> 00:05:21,349
this case but it could also include

00:05:18,889 --> 00:05:23,870
other attributes of the item or even

00:05:21,349 --> 00:05:28,250
attributes that depend on the user the

00:05:23,870 --> 00:05:30,259
query or the context a query time each

00:05:28,250 --> 00:05:32,659
feature has a value which could be a

00:05:30,259 --> 00:05:35,090
floating-point number or just a one for

00:05:32,659 --> 00:05:36,770
present the weighted sum of these

00:05:35,090 --> 00:05:40,639
feature values gives you a relevant

00:05:36,770 --> 00:05:44,150
score that you can sort by but whether

00:05:40,639 --> 00:05:45,560
those feature weights come from so the

00:05:44,150 --> 00:05:48,289
output of the machine learning process

00:05:45,560 --> 00:05:50,930
is called a model which is just a weight

00:05:48,289 --> 00:05:53,960
for every feature found in any item in

00:05:50,930 --> 00:05:56,870
the training data so it's also just a

00:05:53,960 --> 00:05:59,870
map from feature names to values

00:05:56,870 --> 00:06:02,389
I'll talk shortly about how the training

00:05:59,870 --> 00:06:04,610
process actually finds those weights so

00:06:02,389 --> 00:06:06,620
notice here that scoring an item against

00:06:04,610 --> 00:06:09,110
a model by taking the weighted sum of

00:06:06,620 --> 00:06:11,330
its features is analogous to scoring an

00:06:09,110 --> 00:06:15,130
item gets to query by taking the cosine

00:06:11,330 --> 00:06:15,130
similarity of the item in the query

00:06:16,150 --> 00:06:21,080
before we train the model we need to

00:06:18,469 --> 00:06:22,610
provide a target ranking and this is

00:06:21,080 --> 00:06:24,860
sometimes called the ground truth or

00:06:22,610 --> 00:06:26,389
gold standard so this is the ideal

00:06:24,860 --> 00:06:27,979
ranking that the model wallet writer

00:06:26,389 --> 00:06:31,120
will try to approximate and then

00:06:27,979 --> 00:06:33,469
generalize from now in traditional

00:06:31,120 --> 00:06:35,599
academic information retrieval research

00:06:33,469 --> 00:06:37,950
this will be made based on manual

00:06:35,599 --> 00:06:41,590
relevance labeling by experts

00:06:37,950 --> 00:06:43,480
but in the online context you can mine

00:06:41,590 --> 00:06:47,980
your site search logs to build the

00:06:43,480 --> 00:06:50,080
target ranking from historical data so

00:06:47,980 --> 00:06:53,140
the key idea of this is that each time a

00:06:50,080 --> 00:06:55,420
user runs a query and then click some

00:06:53,140 --> 00:06:57,610
results but ignores others they're

00:06:55,420 --> 00:06:59,290
providing an implicit signal that some

00:06:57,610 --> 00:07:01,900
items are more relevant to that query

00:06:59,290 --> 00:07:04,330
than others are now that's the noisy

00:07:01,900 --> 00:07:06,790
signal but aggregated over many user

00:07:04,330 --> 00:07:08,680
sessions it provides a consensus

00:07:06,790 --> 00:07:10,180
judgment about the comparative relevance

00:07:08,680 --> 00:07:15,610
to the results that you served for each

00:07:10,180 --> 00:07:17,500
query during training the learning

00:07:15,610 --> 00:07:19,500
algorithm will iteratively modify the

00:07:17,500 --> 00:07:21,490
weights on the features have seen

00:07:19,500 --> 00:07:23,590
starting generally with random weights

00:07:21,490 --> 00:07:25,480
and then after each change it will

00:07:23,590 --> 00:07:27,430
compare the target ranking to the

00:07:25,480 --> 00:07:31,510
ranking that it would get if it had used

00:07:27,430 --> 00:07:33,880
the current weights if the ranking isn't

00:07:31,510 --> 00:07:35,350
correct it will modify the weights in a

00:07:33,880 --> 00:07:38,110
direction that's likely to improve the

00:07:35,350 --> 00:07:39,700
ranking and then try again and this

00:07:38,110 --> 00:07:42,760
continues until the ranking stops

00:07:39,700 --> 00:07:44,560
improving that's called convergence now

00:07:42,760 --> 00:07:46,120
this this process is generally these

00:07:44,560 --> 00:07:48,130
days implemented using an algorithm

00:07:46,120 --> 00:07:50,080
called gradient descent at least a large

00:07:48,130 --> 00:07:53,020
scale or some variant of gradient

00:07:50,080 --> 00:07:54,430
descent again this is a very big

00:07:53,020 --> 00:07:57,190
simplification but it illustrates the

00:07:54,430 --> 00:07:58,690
general idea I'm not going to go into

00:07:57,190 --> 00:08:01,210
the maths of how gradient descent works

00:07:58,690 --> 00:08:06,580
because that would be you know a whole

00:08:01,210 --> 00:08:07,660
lecture series in itself now I'm going

00:08:06,580 --> 00:08:10,030
to talk a little bit about building

00:08:07,660 --> 00:08:11,500
features to represent items but also to

00:08:10,030 --> 00:08:13,840
represent queries and other contextual

00:08:11,500 --> 00:08:16,420
information this is the part of data

00:08:13,840 --> 00:08:19,660
science which is generally more like an

00:08:16,420 --> 00:08:21,400
art than a science and we're having good

00:08:19,660 --> 00:08:25,990
knowledge of your domain comes in and

00:08:21,400 --> 00:08:27,670
really essential so any attribute that

00:08:25,990 --> 00:08:30,550
describes an item can be used as a

00:08:27,670 --> 00:08:32,560
feature now it could include terms in

00:08:30,550 --> 00:08:35,350
particular fields like the title or

00:08:32,560 --> 00:08:37,030
description or tags the from a taxonomy

00:08:35,350 --> 00:08:39,700
that are associated with that item and

00:08:37,030 --> 00:08:41,680
you could use the tf-idf weights of

00:08:39,700 --> 00:08:44,290
those items as the values of those

00:08:41,680 --> 00:08:45,760
features or you could just use one to

00:08:44,290 --> 00:08:48,070
mean present and leave them out if

00:08:45,760 --> 00:08:49,930
they're absent I'm not going to give any

00:08:48,070 --> 00:08:51,460
advice about what works better than what

00:08:49,930 --> 00:08:52,780
because actually

00:08:51,460 --> 00:08:54,670
that's very much dependent on your own

00:08:52,780 --> 00:08:57,400
data sir in your own domain of usage so

00:08:54,670 --> 00:08:59,560
experimentation is key you can also use

00:08:57,400 --> 00:09:02,850
metadata like historical click rates or

00:08:59,560 --> 00:09:04,630
conversion rates or pricing information

00:09:02,850 --> 00:09:06,370
or if you want to get bit more

00:09:04,630 --> 00:09:09,130
sophisticated you can pre-process the

00:09:06,370 --> 00:09:12,130
items we say a topic modeling algorithm

00:09:09,130 --> 00:09:14,590
like Lda or LSI or a clustering

00:09:12,130 --> 00:09:16,900
algorithm or even a neural network and

00:09:14,590 --> 00:09:20,670
then include the outputs of those

00:09:16,900 --> 00:09:23,590
algorithms as features to represent

00:09:20,670 --> 00:09:26,230
attributes of the document now some

00:09:23,590 --> 00:09:28,270
colleagues of mine wrote a paper for

00:09:26,230 --> 00:09:30,130
this year's kdd conference that

00:09:28,270 --> 00:09:33,340
describes combining textual features

00:09:30,130 --> 00:09:35,340
from product descriptions with image

00:09:33,340 --> 00:09:37,480
features from those products photographs

00:09:35,340 --> 00:09:40,240
extracted using a convolutional neural

00:09:37,480 --> 00:09:42,220
network which is called images don't lie

00:09:40,240 --> 00:09:44,560
transferring deep visual semantic

00:09:42,220 --> 00:09:46,870
features to large-scale multimodal

00:09:44,560 --> 00:09:48,760
learning to rank so if you're interested

00:09:46,870 --> 00:09:54,580
in how that works you can look up that

00:09:48,760 --> 00:09:55,900
reference online now all of these

00:09:54,580 --> 00:09:58,600
features just describe the items

00:09:55,900 --> 00:10:00,850
themselves so far so a ranking model

00:09:58,600 --> 00:10:03,580
that's learnt using only those features

00:10:00,850 --> 00:10:06,370
will just provide a global kind of

00:10:03,580 --> 00:10:09,160
quality or click ability score that can

00:10:06,370 --> 00:10:11,050
be useful in some settings but usually

00:10:09,160 --> 00:10:12,690
we want to be able to to rank the items

00:10:11,050 --> 00:10:15,280
with respect to a particular query

00:10:12,690 --> 00:10:16,270
because that's what you need to do for a

00:10:15,280 --> 00:10:19,390
set of search results

00:10:16,270 --> 00:10:21,790
I want simple ways to calculate the

00:10:19,390 --> 00:10:23,320
relevance normally and then use the

00:10:21,790 --> 00:10:26,980
global quality score from your machine

00:10:23,320 --> 00:10:28,690
learning model as modifier flat but that

00:10:26,980 --> 00:10:30,700
means you still have to manually decide

00:10:28,690 --> 00:10:32,680
how to weight those two scores with

00:10:30,700 --> 00:10:34,030
respect to each other so it's kind of

00:10:32,680 --> 00:10:37,570
step backwards to where we were at the

00:10:34,030 --> 00:10:40,090
start another way is to let each

00:10:37,570 --> 00:10:42,010
training instance describe not just an

00:10:40,090 --> 00:10:44,500
item but an item in the context of a

00:10:42,010 --> 00:10:46,570
specific query by adding features that

00:10:44,500 --> 00:10:48,730
describe the query that was run at the

00:10:46,570 --> 00:10:51,670
time or the relationship between the

00:10:48,730 --> 00:10:53,410
query and the item now you can actually

00:10:51,670 --> 00:10:56,830
incorporate traditional relevant scores

00:10:53,410 --> 00:10:58,960
like tf-idf or BM 25 here and it's fine

00:10:56,830 --> 00:11:00,900
to use more than one of them and let the

00:10:58,960 --> 00:11:04,060
model work out which is most important

00:11:00,900 --> 00:11:05,150
at training time and you can also just

00:11:04,060 --> 00:11:07,010
use features that just

00:11:05,150 --> 00:11:08,990
the query itself for example linguistic

00:11:07,010 --> 00:11:10,460
features or some kind of query

00:11:08,990 --> 00:11:14,180
segmentation or query categorization

00:11:10,460 --> 00:11:17,000
features and just as an aside here if

00:11:14,180 --> 00:11:19,430
you have any features that aren't in the

00:11:17,000 --> 00:11:21,529
range 0 to 1 it's best to rescale them

00:11:19,430 --> 00:11:22,940
so they are because it makes it easier

00:11:21,529 --> 00:11:25,070
for the model to converge and it also

00:11:22,940 --> 00:11:26,660
makes it easier to interpret the weights

00:11:25,070 --> 00:11:34,880
of those models as feature importance

00:11:26,660 --> 00:11:37,400
later on now the most fine-grained way

00:11:34,880 --> 00:11:40,220
to model context is to include terms

00:11:37,400 --> 00:11:43,400
from the queries themselves in these

00:11:40,220 --> 00:11:45,470
query item interaction vectors by

00:11:43,400 --> 00:11:47,390
building composite features for each

00:11:45,470 --> 00:11:49,370
combination of a query term that

00:11:47,390 --> 00:11:51,950
appeared in the query and some appeared

00:11:49,370 --> 00:11:54,350
in a field in the item like I've done

00:11:51,950 --> 00:11:56,720
here this lets the model learn implicit

00:11:54,350 --> 00:11:58,820
associations between those terms but a

00:11:56,720 --> 00:11:59,900
very high computational cost you get a

00:11:58,820 --> 00:12:03,080
very large model with a lot of features

00:11:59,900 --> 00:12:05,480
in it you could even use this approach

00:12:03,080 --> 00:12:08,930
to learn a model for recommendations or

00:12:05,480 --> 00:12:11,270
personalization instead of explicit

00:12:08,930 --> 00:12:13,550
search queries by including terms

00:12:11,270 --> 00:12:19,310
representing the page or session context

00:12:13,550 --> 00:12:22,040
or the users themselves but in general

00:12:19,310 --> 00:12:23,630
the best way is to train a separate

00:12:22,040 --> 00:12:26,089
model for each query that appears in

00:12:23,630 --> 00:12:28,700
your logs or maybe just the top end most

00:12:26,089 --> 00:12:32,330
common queries or maybe enough queries

00:12:28,700 --> 00:12:34,130
to cover the majority of searches then

00:12:32,330 --> 00:12:36,470
you can fall back to using traditional

00:12:34,130 --> 00:12:37,880
turn-based relevance ranking when a user

00:12:36,470 --> 00:12:40,130
runs a query that there isn't a model

00:12:37,880 --> 00:12:41,540
for for the rest of the talk for

00:12:40,130 --> 00:12:43,089
simplicity I'm just going to assume that

00:12:41,540 --> 00:12:45,050
we're working in this model in this

00:12:43,089 --> 00:12:50,089
paradigm with a separate model for each

00:12:45,050 --> 00:12:51,980
query now I'm going to talk a bit about

00:12:50,089 --> 00:12:53,510
how to actually train this model using

00:12:51,980 --> 00:12:54,500
the example of support vector machines

00:12:53,510 --> 00:12:56,750
or SVM's

00:12:54,500 --> 00:12:59,240
these are used widely in classification

00:12:56,750 --> 00:13:00,709
tasks and pretty much any

00:12:59,240 --> 00:13:04,310
general-purpose machine learning library

00:13:00,709 --> 00:13:06,080
will come with an SVM implementation if

00:13:04,310 --> 00:13:08,480
you're just starting out the Python

00:13:06,080 --> 00:13:10,610
package scikit-learn is a very good

00:13:08,480 --> 00:13:15,490
place to get going because it has great

00:13:10,610 --> 00:13:15,490
documentation and is an easy API

00:13:17,760 --> 00:13:21,730
so first let's take a quick digression

00:13:19,720 --> 00:13:24,850
to talk about how you train a binary

00:13:21,730 --> 00:13:27,670
classifier that is a classifier with two

00:13:24,850 --> 00:13:29,950
classes like a spam detector each

00:13:27,670 --> 00:13:32,260
training instance in this case consists

00:13:29,950 --> 00:13:34,990
of a single example so a single email in

00:13:32,260 --> 00:13:38,500
the spam scenario and a label which will

00:13:34,990 --> 00:13:41,050
be positive plus one for spam emails and

00:13:38,500 --> 00:13:43,390
negative minus 1 for non-spam emails I

00:13:41,050 --> 00:13:45,310
some will have to prepare all of your

00:13:43,390 --> 00:13:46,930
training data by manually tighten those

00:13:45,310 --> 00:13:49,530
unless you have a way of crowd sourcing

00:13:46,930 --> 00:13:49,530
now or something

00:13:50,550 --> 00:13:55,990
SVM's work by treating each feature in

00:13:52,990 --> 00:13:58,150
the model as a dimension in a space so

00:13:55,990 --> 00:14:01,330
each training instance corresponds to

00:13:58,150 --> 00:14:03,040
point in in that space in this image

00:14:01,330 --> 00:14:04,660
there are only two dimensions because

00:14:03,040 --> 00:14:07,150
any more than that starts getting very

00:14:04,660 --> 00:14:09,640
hard to visualize but in reality you

00:14:07,150 --> 00:14:11,680
might have thousands or even potentially

00:14:09,640 --> 00:14:13,840
millions of features in the model so

00:14:11,680 --> 00:14:17,980
thousands or millions of dimensions in

00:14:13,840 --> 00:14:20,280
our space then the SVM trainer will

00:14:17,980 --> 00:14:24,640
learn where the best dividing line or

00:14:20,280 --> 00:14:26,740
hyperplane in the terminology falls to

00:14:24,640 --> 00:14:30,550
where to place the dividing line so as

00:14:26,740 --> 00:14:34,120
to best split between positive and

00:14:30,550 --> 00:14:35,800
negative examples that's cool it's

00:14:34,120 --> 00:14:38,260
called max margin classification because

00:14:35,800 --> 00:14:40,000
you can kind of see that that dividing

00:14:38,260 --> 00:14:41,380
line in the middle the black line could

00:14:40,000 --> 00:14:43,930
be tilted to the left or to the right

00:14:41,380 --> 00:14:45,940
slightly and it would still separate the

00:14:43,930 --> 00:14:48,010
positive and negative examples but

00:14:45,940 --> 00:14:52,210
there's only one unique place to put it

00:14:48,010 --> 00:14:54,280
that maximizes the margin between the

00:14:52,210 --> 00:14:57,300
line and any example on either side so

00:14:54,280 --> 00:14:57,300
that makes it more robust to outliers

00:14:58,140 --> 00:15:03,520
then once you've trained the model you

00:15:01,180 --> 00:15:06,250
can just classify new items as being

00:15:03,520 --> 00:15:09,100
positive or negative based on which side

00:15:06,250 --> 00:15:13,110
of that line they fall on and yes this

00:15:09,100 --> 00:15:13,110
is also a very simplified explanation

00:15:13,410 --> 00:15:17,440
now you can think of the feature weights

00:15:15,520 --> 00:15:19,780
and the modelers defining another line

00:15:17,440 --> 00:15:21,990
which is perpendicular to that boundary

00:15:19,780 --> 00:15:21,990
line

00:15:23,610 --> 00:15:27,660
but how can we use this same approach

00:15:25,200 --> 00:15:29,310
for ranking well in the ranking context

00:15:27,660 --> 00:15:31,980
we don't just want each example to be

00:15:29,310 --> 00:15:34,170
classified as positive or negative with

00:15:31,980 --> 00:15:37,860
respect to the boundary line

00:15:34,170 --> 00:15:39,839
we actually want to know how far along

00:15:37,860 --> 00:15:42,769
this perpendicular line each example

00:15:39,839 --> 00:15:47,459
Falls how positive or how negative it is

00:15:42,769 --> 00:15:49,470
so number one is the most positive and

00:15:47,459 --> 00:15:50,940
this one down in the far right corner

00:15:49,470 --> 00:15:53,459
that I have numbered is the most

00:15:50,940 --> 00:15:54,990
negative and you can see how we've kind

00:15:53,459 --> 00:15:59,279
of ignored the other dimension of the

00:15:54,990 --> 00:16:01,320
model projected those items onto the

00:15:59,279 --> 00:16:05,160
line and we're just numbering them in

00:16:01,320 --> 00:16:06,450
order where they fall along that line so

00:16:05,160 --> 00:16:09,930
the the approach that I'm going to

00:16:06,450 --> 00:16:12,540
describe to train an SVM to do this was

00:16:09,930 --> 00:16:14,820
first presented in 2003 in this paper

00:16:12,540 --> 00:16:17,640
called optimizing search engines using

00:16:14,820 --> 00:16:19,380
click-through data so it's it's kind of

00:16:17,640 --> 00:16:21,510
old now this isn't state-of-the-art as

00:16:19,380 --> 00:16:25,980
learning to rank goes but it's fairly

00:16:21,510 --> 00:16:33,540
easy to understand fairly seminal paper

00:16:25,980 --> 00:16:36,959
and also scales quite well so the way we

00:16:33,540 --> 00:16:39,120
approach this problem relies on a like a

00:16:36,959 --> 00:16:43,470
cunning bit of pre-processing before you

00:16:39,120 --> 00:16:45,779
start training the model instead of

00:16:43,470 --> 00:16:47,730
training the SVM learner on individual

00:16:45,779 --> 00:16:50,160
items as you would with the classifier

00:16:47,730 --> 00:16:52,140
you train it on pairs of items where a

00:16:50,160 --> 00:16:54,600
user expressed a preference for one item

00:16:52,140 --> 00:16:56,160
over the other the model then learns to

00:16:54,600 --> 00:16:58,800
mimic those pairwise preference

00:16:56,160 --> 00:17:01,199
judgments and generalize from them to

00:16:58,800 --> 00:17:03,060
new data essentially it learns to

00:17:01,199 --> 00:17:05,490
classify pairs of items as either

00:17:03,060 --> 00:17:08,010
correctly or incorrectly ordered based

00:17:05,490 --> 00:17:12,419
on what users have done in the past on

00:17:08,010 --> 00:17:14,130
your side so because SVM two classifiers

00:17:12,419 --> 00:17:16,530
we still need to provide a class label

00:17:14,130 --> 00:17:20,250
this is plus one if the user preferred

00:17:16,530 --> 00:17:21,839
item one to item 2 ie the two items are

00:17:20,250 --> 00:17:24,929
correctly ordered with regard to a

00:17:21,839 --> 00:17:26,880
specific search session and it's minus 1

00:17:24,929 --> 00:17:29,250
if the user preferred item 2 to item 1

00:17:26,880 --> 00:17:30,750
so they're incorrectly ordered we

00:17:29,250 --> 00:17:32,250
sometimes call the members of each pair

00:17:30,750 --> 00:17:34,350
the winner or the loser depending on

00:17:32,250 --> 00:17:35,470
which one the user preferred in that

00:17:34,350 --> 00:17:38,740
particular

00:17:35,470 --> 00:17:40,299
action in your logs before we start

00:17:38,740 --> 00:17:42,070
training we need to convert those pairs

00:17:40,299 --> 00:17:44,289
of item vectors into a single vector

00:17:42,070 --> 00:17:47,650
that describes the differences between

00:17:44,289 --> 00:17:50,080
the two items so how do you define the

00:17:47,650 --> 00:17:51,580
difference between two vectors it's easy

00:17:50,080 --> 00:17:55,840
you just subtract one vector from the

00:17:51,580 --> 00:17:57,880
other so say here we've got item 1 and

00:17:55,840 --> 00:17:59,380
the features that make it up and we've

00:17:57,880 --> 00:18:02,950
got item 2 and the features that make

00:17:59,380 --> 00:18:05,140
that up and we subtract item 2 from item

00:18:02,950 --> 00:18:06,549
1 and we get a single vector that

00:18:05,140 --> 00:18:08,890
describes the differences between those

00:18:06,549 --> 00:18:11,169
two items you maritally remember that

00:18:08,890 --> 00:18:13,929
any missing features are implicitly 0 so

00:18:11,169 --> 00:18:17,280
I've shown those in gray any features

00:18:13,929 --> 00:18:21,309
with the same value in item 1 and item 2

00:18:17,280 --> 00:18:23,500
for example title purple here will be 0

00:18:21,309 --> 00:18:26,320
in the resulting vector so you can just

00:18:23,500 --> 00:18:29,230
leave them out intuitively that makes

00:18:26,320 --> 00:18:31,030
sense because if if the loop winner and

00:18:29,230 --> 00:18:34,150
loser of it is of a preference decision

00:18:31,030 --> 00:18:36,340
both contain the same feature or if it's

00:18:34,150 --> 00:18:38,409
a constant or if it's a continuous

00:18:36,340 --> 00:18:39,940
feature have the same value then it

00:18:38,409 --> 00:18:42,640
means that the learner can't learn

00:18:39,940 --> 00:18:48,039
anything about that feature from that

00:18:42,640 --> 00:18:49,270
particular preference decision so when

00:18:48,039 --> 00:18:51,280
you pass a training instance with a

00:18:49,270 --> 00:18:52,659
positive label to the learner you're

00:18:51,280 --> 00:18:54,940
telling it to learn that those feature

00:18:52,659 --> 00:18:59,020
differences are associated with item 1

00:18:54,940 --> 00:19:00,669
being preferred to item 2 and if you

00:18:59,020 --> 00:19:02,260
switch the sign up and provide the same

00:19:00,669 --> 00:19:04,510
training instance with a negative label

00:19:02,260 --> 00:19:06,220
you tell it that the future differences

00:19:04,510 --> 00:19:08,260
are associated with item 2 being the

00:19:06,220 --> 00:19:12,039
first item 1 and what people typically

00:19:08,260 --> 00:19:13,750
do is just randomly train on half of

00:19:12,039 --> 00:19:14,890
their half of those pairs in the correct

00:19:13,750 --> 00:19:16,900
order and half those pairs in the

00:19:14,890 --> 00:19:19,090
incorrect order and then the the learner

00:19:16,900 --> 00:19:22,080
can learn positive and negative

00:19:19,090 --> 00:19:27,070
associations between features and

00:19:22,080 --> 00:19:28,480
preference decisions now even though

00:19:27,070 --> 00:19:31,270
you've trained the model on differences

00:19:28,480 --> 00:19:33,490
between items you still need to apply it

00:19:31,270 --> 00:19:39,039
to individual items to obtain a ranking

00:19:33,490 --> 00:19:42,250
score for each one so that what that

00:19:39,039 --> 00:19:44,049
means intuitively is that an item score

00:19:42,250 --> 00:19:45,789
should be positively affected by having

00:19:44,049 --> 00:19:48,299
features that are often found in the

00:19:45,789 --> 00:19:50,519
winner of a preference decision

00:19:48,299 --> 00:19:53,190
because they'll get a positive score in

00:19:50,519 --> 00:19:54,869
the weights in the model and we

00:19:53,190 --> 00:19:56,309
negatively affected by having features

00:19:54,869 --> 00:19:58,109
they're often found in the loser

00:19:56,309 --> 00:20:02,789
preference decision because they'll have

00:19:58,109 --> 00:20:04,649
a negative way in the model so you get

00:20:02,789 --> 00:20:06,690
the feature values of each item in a set

00:20:04,649 --> 00:20:07,950
of search results and you calculate

00:20:06,690 --> 00:20:09,989
their weighted sum using the weights

00:20:07,950 --> 00:20:12,779
from the model that's where we started

00:20:09,989 --> 00:20:14,519
and then you just order the results in

00:20:12,779 --> 00:20:17,419
descending order of those scores and

00:20:14,519 --> 00:20:20,159
that gives you the ranking that you need

00:20:17,419 --> 00:20:21,719
so as I said it's it's not exactly a

00:20:20,159 --> 00:20:23,309
state of the art method there are

00:20:21,719 --> 00:20:25,649
machine learning methods that are

00:20:23,309 --> 00:20:28,619
specific for learning to rank what they

00:20:25,649 --> 00:20:30,029
actually take into account the the total

00:20:28,619 --> 00:20:33,259
ordering of the list for example rather

00:20:30,029 --> 00:20:37,109
than just individual pairwise

00:20:33,259 --> 00:20:38,429
rearrangements but you know it's a it's

00:20:37,109 --> 00:20:40,979
a seminal method it's a good place to

00:20:38,429 --> 00:20:42,299
start and it scales well especially if

00:20:40,979 --> 00:20:45,570
you're training separate models for each

00:20:42,299 --> 00:20:47,369
query in parallel there's a good paper

00:20:45,570 --> 00:20:49,529
from Google called large-scale learning

00:20:47,369 --> 00:20:58,169
to rank which demonstrates how to do

00:20:49,529 --> 00:21:00,359
that at Google scales okay so before we

00:20:58,169 --> 00:21:01,979
finish let's talk a bit about some

00:21:00,359 --> 00:21:03,659
practical issues that you might want to

00:21:01,979 --> 00:21:09,359
consider if you're using ltr' and

00:21:03,659 --> 00:21:11,639
production first off you need to think

00:21:09,359 --> 00:21:14,129
about when and where to calculate the

00:21:11,639 --> 00:21:15,779
ranking scores for the items so the

00:21:14,129 --> 00:21:18,690
models going to be trained offline

00:21:15,779 --> 00:21:21,059
probably using a batch process or it

00:21:18,690 --> 00:21:22,649
could be trained you iteratively using a

00:21:21,059 --> 00:21:26,700
stream of new data if you've got

00:21:22,649 --> 00:21:27,959
streaming data ingestion especially if

00:21:26,700 --> 00:21:29,789
you're using gradient descent because

00:21:27,959 --> 00:21:32,279
that's a training method which works

00:21:29,789 --> 00:21:34,829
very well with iterative updates as new

00:21:32,279 --> 00:21:37,679
data comes in but you still need to

00:21:34,829 --> 00:21:41,219
apply the model to individual items to

00:21:37,679 --> 00:21:46,079
get their ranking scores as in perform

00:21:41,219 --> 00:21:48,299
that weighted sum operation the simplest

00:21:46,079 --> 00:21:51,239
way in engineering terms is to also

00:21:48,299 --> 00:21:53,129
apply the model offline in something

00:21:51,239 --> 00:21:57,779
like a dupe or some other scheduled task

00:21:53,129 --> 00:22:00,029
or near line if if you have heard of

00:21:57,779 --> 00:22:02,220
that latest buzzword in something like

00:22:00,029 --> 00:22:05,280
spark so you're you're keeping your rank

00:22:02,220 --> 00:22:07,679
is up to date close to when new data

00:22:05,280 --> 00:22:09,720
arrives so in other words what you do in

00:22:07,679 --> 00:22:12,929
this scenario is build a static pre

00:22:09,720 --> 00:22:14,850
ranked result set for for each query

00:22:12,929 --> 00:22:16,320
that you want to build a model for you

00:22:14,850 --> 00:22:19,140
know that could be your top 10,000

00:22:16,320 --> 00:22:20,880
queries or something like that but it

00:22:19,140 --> 00:22:24,030
might not be computationally feasible to

00:22:20,880 --> 00:22:26,460
do that for every item under every query

00:22:24,030 --> 00:22:31,520
because you know that could be a lot of

00:22:26,460 --> 00:22:34,590
query item pairs another option is to

00:22:31,520 --> 00:22:37,470
calculate the ranking score for each

00:22:34,590 --> 00:22:39,539
item at query time after you retrieve a

00:22:37,470 --> 00:22:42,059
set of items matching the query from

00:22:39,539 --> 00:22:43,530
your search engine so this you need to

00:22:42,059 --> 00:22:46,470
catch all the model weights in memory

00:22:43,530 --> 00:22:48,780
and in the search server or in some

00:22:46,470 --> 00:22:52,890
separate key value store or something

00:22:48,780 --> 00:22:55,740
and then bills or retrieve the feature

00:22:52,890 --> 00:22:57,809
vectors for each item for a search or

00:22:55,740 --> 00:22:59,880
database query or some other key value

00:22:57,809 --> 00:23:02,520
store lookup and then if you're using

00:22:59,880 --> 00:23:04,530
contextual features from the query or

00:23:02,520 --> 00:23:05,940
the pager context or whatever then the

00:23:04,530 --> 00:23:08,309
application layer could kind of fill

00:23:05,940 --> 00:23:11,700
those in concatenate them with the with

00:23:08,309 --> 00:23:15,299
the feature describing each individual

00:23:11,700 --> 00:23:18,059
item and then you perform the the

00:23:15,299 --> 00:23:20,789
weighted sum between the model and each

00:23:18,059 --> 00:23:23,340
item on the fly and then sort by that

00:23:20,789 --> 00:23:26,370
result and then of course you can cache

00:23:23,340 --> 00:23:29,640
those those scores in the context of the

00:23:26,370 --> 00:23:31,440
query because you know any contextual

00:23:29,640 --> 00:23:35,580
features that you add these ones on the

00:23:31,440 --> 00:23:37,559
left there you wouldn't want to ignore

00:23:35,580 --> 00:23:40,470
those when you're caching scores that

00:23:37,559 --> 00:23:44,270
result from from doing that score

00:23:40,470 --> 00:23:44,270
calculation on several items

00:23:45,260 --> 00:23:51,210
now that can be very expensive to do on

00:23:48,659 --> 00:23:53,429
the fly for every single item especially

00:23:51,210 --> 00:23:56,940
for queries that have very broad

00:23:53,429 --> 00:23:59,700
coverage so quite a popular compromise

00:23:56,940 --> 00:24:01,470
is to initially rank the results by the

00:23:59,700 --> 00:24:04,679
term based relevant score that your

00:24:01,470 --> 00:24:08,419
search engine gives you and then to rear

00:24:04,679 --> 00:24:11,210
ank only the top k results using the

00:24:08,419 --> 00:24:14,760
dynamic method from the previous slide

00:24:11,210 --> 00:24:17,960
so you can adjust the value of K up and

00:24:14,760 --> 00:24:20,760
down to as a trade-off between cost and

00:24:17,960 --> 00:24:23,130
ranking accuracy there's a talk at

00:24:20,760 --> 00:24:25,830
leucine revolution last year called

00:24:23,130 --> 00:24:31,710
learning to rank in solar which showed

00:24:25,830 --> 00:24:33,120
how to do this with a solar plugin so

00:24:31,710 --> 00:24:36,299
here's an example of how that works when

00:24:33,120 --> 00:24:39,510
K equals 5 the initial ranking on the

00:24:36,299 --> 00:24:42,270
left is based on leucine relevant score

00:24:39,510 --> 00:24:44,270
for each item and then you calculate the

00:24:42,270 --> 00:24:46,520
SVM ranking school for the top five hits

00:24:44,270 --> 00:24:49,350
using that weighted sum against the

00:24:46,520 --> 00:24:52,140
machine learning model and then yuri

00:24:49,350 --> 00:24:54,630
ranked those by that score and then the

00:24:52,140 --> 00:24:56,640
ordering of any items from position six

00:24:54,630 --> 00:24:59,549
and below is unaffected you just use the

00:24:56,640 --> 00:25:00,960
original ranking for those this is

00:24:59,549 --> 00:25:03,330
actually a general kind of top case

00:25:00,960 --> 00:25:08,130
strategy there are that you can perform

00:25:03,330 --> 00:25:09,210
these days using using using plugins of

00:25:08,130 --> 00:25:10,440
any kind they don't have to be machine

00:25:09,210 --> 00:25:11,940
learning if you go any other kind of

00:25:10,440 --> 00:25:13,110
like complex scoring function that you

00:25:11,940 --> 00:25:15,270
just want to apply to the top few

00:25:13,110 --> 00:25:17,279
results then this is a good strategy in

00:25:15,270 --> 00:25:22,529
general because quite often people don't

00:25:17,279 --> 00:25:23,820
look past the top few results anyway so

00:25:22,529 --> 00:25:25,500
finally it's important to make sure that

00:25:23,820 --> 00:25:27,990
you're solving the right problem here

00:25:25,500 --> 00:25:29,909
the model that you train will learn to

00:25:27,990 --> 00:25:33,059
approximate any target ranking that you

00:25:29,909 --> 00:25:35,250
give it given enough data so you have to

00:25:33,059 --> 00:25:36,659
make sure that that target ranking

00:25:35,250 --> 00:25:40,760
reflects what you want to achieve

00:25:36,659 --> 00:25:40,760
reflects you all your business problems

00:25:40,789 --> 00:25:46,289
one aspect of that is avoiding feedback

00:25:44,220 --> 00:25:47,309
loops and so-called filter bubbles you

00:25:46,289 --> 00:25:49,500
know if you're learning if you're

00:25:47,309 --> 00:25:51,600
building a target ranking and then

00:25:49,500 --> 00:25:53,220
presenting search results based on that

00:25:51,600 --> 00:25:56,010
and then using clicks on those same

00:25:53,220 --> 00:25:57,990
search results to improve the the model

00:25:56,010 --> 00:25:59,400
and so on and so on

00:25:57,990 --> 00:26:02,300
can see how that gets kind of circular

00:25:59,400 --> 00:26:04,770
it introduces a feedback loop so you

00:26:02,300 --> 00:26:08,240
have to be careful not to train your

00:26:04,770 --> 00:26:10,380
model to just recreate existing rankings

00:26:08,240 --> 00:26:13,170
one aspect of that is you need to make

00:26:10,380 --> 00:26:15,840
sure that you give new content a chance

00:26:13,170 --> 00:26:17,400
to actually earn some clicks so you get

00:26:15,840 --> 00:26:23,100
some signal about how popular or

00:26:17,400 --> 00:26:24,630
unpopular it is so you can do that by

00:26:23,100 --> 00:26:28,320
introducing some level of randomization

00:26:24,630 --> 00:26:30,240
into search results like artificially

00:26:28,320 --> 00:26:33,750
promoting items to see see whether

00:26:30,240 --> 00:26:35,670
anyone bites if you like you could also

00:26:33,750 --> 00:26:38,700
to avoid the feedback loop you could

00:26:35,670 --> 00:26:41,190
train the model on one product feature

00:26:38,700 --> 00:26:44,880
like your search page and then use the

00:26:41,190 --> 00:26:46,320
model to to perform ranking for a

00:26:44,880 --> 00:26:49,530
totally different feature like maybe

00:26:46,320 --> 00:26:49,860
your insight ad placements or something

00:26:49,530 --> 00:26:51,450
like that

00:26:49,860 --> 00:26:54,059
promoted listings if you're doing some

00:26:51,450 --> 00:26:55,260
kind of product search because then

00:26:54,059 --> 00:26:56,670
there's there's no feedback loop you're

00:26:55,260 --> 00:27:00,570
learning here and applying the model

00:26:56,670 --> 00:27:02,280
there you also need to consider the

00:27:00,570 --> 00:27:05,429
effects of position bias in the training

00:27:02,280 --> 00:27:07,350
data so that's the tendency for users to

00:27:05,429 --> 00:27:10,860
click on items just because they appear

00:27:07,350 --> 00:27:13,140
higher in the results there are a bunch

00:27:10,860 --> 00:27:15,300
of different strategies for mitigating

00:27:13,140 --> 00:27:17,790
this and they all kind of have pros and

00:27:15,300 --> 00:27:19,980
cons and you know you could do a talk

00:27:17,790 --> 00:27:24,650
just on how to how to do those in

00:27:19,980 --> 00:27:27,030
general so I would recommend that if

00:27:24,650 --> 00:27:28,410
you're interested in pursuing this in

00:27:27,030 --> 00:27:30,450
production then talk to your data

00:27:28,410 --> 00:27:31,920
science team because they probably will

00:27:30,450 --> 00:27:34,020
have some good ideas about how to remove

00:27:31,920 --> 00:27:36,720
remove those sources of bias or at least

00:27:34,020 --> 00:27:39,510
account for them or correct for them

00:27:36,720 --> 00:27:41,490
when you apply the model and good a/b

00:27:39,510 --> 00:27:42,480
testing is absolutely essential so some

00:27:41,490 --> 00:27:45,620
of these will work better in some

00:27:42,480 --> 00:27:45,620
contexts than others

00:27:53,430 --> 00:27:58,230
I mentioned that you need to ensure that

00:27:55,590 --> 00:28:01,080
the target ranking matches the behavior

00:27:58,230 --> 00:28:03,270
that you're trying to promote so ranking

00:28:01,080 --> 00:28:05,940
by click popularity alone might be fine

00:28:03,270 --> 00:28:09,150
for ad placement if you get paid by the

00:28:05,940 --> 00:28:11,490
click but in search results a click

00:28:09,150 --> 00:28:13,740
alone isn't necessarily a guarantee of

00:28:11,490 --> 00:28:15,360
relevance you know a user might

00:28:13,740 --> 00:28:16,890
click-through to something and then

00:28:15,360 --> 00:28:18,600
immediately click back or they might

00:28:16,890 --> 00:28:21,570
click-through to something and then

00:28:18,600 --> 00:28:23,010
immediately leave your site so you might

00:28:21,570 --> 00:28:25,080
want to actually filter the click locks

00:28:23,010 --> 00:28:30,990
to disregard those click backs and those

00:28:25,080 --> 00:28:32,820
bounces you can also take other signals

00:28:30,990 --> 00:28:35,640
apart from just clicks into account if

00:28:32,820 --> 00:28:38,880
you want to try and promote behavior of

00:28:35,640 --> 00:28:40,950
different kinds so an example of that

00:28:38,880 --> 00:28:43,680
would be you might want to build a

00:28:40,950 --> 00:28:46,530
target ranking which places articles

00:28:43,680 --> 00:28:47,640
that were often shared at the top then

00:28:46,530 --> 00:28:49,620
articles that were less shared in

00:28:47,640 --> 00:28:52,080
articles which were often read and to

00:28:49,620 --> 00:28:54,120
end but not you know not necessarily

00:28:52,080 --> 00:28:55,680
shared and then below that articles

00:28:54,120 --> 00:28:57,450
which were often clicked but not

00:28:55,680 --> 00:28:59,580
necessarily read end to end so you have

00:28:57,450 --> 00:29:02,910
different bands that might interleave

00:28:59,580 --> 00:29:04,590
slightly at the edges and then you're

00:29:02,910 --> 00:29:07,650
the model that you train based on that

00:29:04,590 --> 00:29:09,210
target ranking will learn to present new

00:29:07,650 --> 00:29:13,100
content eventually based on its

00:29:09,210 --> 00:29:13,100
likelihood of resulting in those actions

00:29:13,280 --> 00:29:17,160
so we're kind of getting towards the end

00:29:15,780 --> 00:29:20,100
I know it's been a very very brief

00:29:17,160 --> 00:29:22,620
overview with a lot of different ideas

00:29:20,100 --> 00:29:25,410
in it but hopefully a useful

00:29:22,620 --> 00:29:26,610
introduction to the field I know

00:29:25,410 --> 00:29:28,400
everyone's probably starting to slump a

00:29:26,610 --> 00:29:30,990
bit as it's getting close to lunchtime

00:29:28,400 --> 00:29:32,880
if you want to learn more about how

00:29:30,990 --> 00:29:35,210
different approaches and different

00:29:32,880 --> 00:29:37,080
learning algorithms work in this context

00:29:35,210 --> 00:29:38,490
it's worth checking out this book

00:29:37,080 --> 00:29:40,260
learning to rank for information

00:29:38,490 --> 00:29:42,960
retrieval which is very comprehensive

00:29:40,260 --> 00:29:45,060
survey of the various different

00:29:42,960 --> 00:29:47,790
approaches and the pros and cons of each

00:29:45,060 --> 00:29:50,520
one and what what again it doesn't

00:29:47,790 --> 00:29:52,260
actually cover in detail is the feature

00:29:50,520 --> 00:29:54,090
engineering side of things like how to

00:29:52,260 --> 00:29:56,850
choose which features work best for your

00:29:54,090 --> 00:29:58,740
data because everybody's data nobody

00:29:56,850 --> 00:30:00,270
uses very different so that's something

00:29:58,740 --> 00:30:01,560
that you can only really arrive at

00:30:00,270 --> 00:30:03,540
through a little bit of trial and error

00:30:01,560 --> 00:30:06,320
at the end of the day you can put pretty

00:30:03,540 --> 00:30:08,210
much any feature into a model and if you

00:30:06,320 --> 00:30:09,769
configure the learner properly again to

00:30:08,210 --> 00:30:12,470
beat your data scientists about making

00:30:09,769 --> 00:30:14,870
sure you do that right then it should

00:30:12,470 --> 00:30:16,120
learn to just ignore ones which are no

00:30:14,870 --> 00:30:19,070
use at all

00:30:16,120 --> 00:30:20,750
so I'm around for the rest today so feel

00:30:19,070 --> 00:30:22,929
free to come and find me and if you want

00:30:20,750 --> 00:30:25,669
to talk about any of this in more detail

00:30:22,929 --> 00:30:27,049
also just as a final note we're looking

00:30:25,669 --> 00:30:29,330
for engineers at the moment in data

00:30:27,049 --> 00:30:31,340
science data engineering search ranking

00:30:29,330 --> 00:30:32,960
and search infrastructure so if you're

00:30:31,340 --> 00:30:34,360
interested in problems like these then

00:30:32,960 --> 00:30:44,330
then please get in touch

00:30:34,360 --> 00:30:47,899
thank you in the front we have some time

00:30:44,330 --> 00:30:50,830
for questions hello thanks for the nice

00:30:47,899 --> 00:30:54,919
talk I have a couple of questions sure

00:30:50,830 --> 00:30:57,289
you said that your training on pairwise

00:30:54,919 --> 00:31:03,039
training examples so this means you're

00:30:57,289 --> 00:31:07,460
actually learning a preference function

00:31:03,039 --> 00:31:10,850
however then how do you use this

00:31:07,460 --> 00:31:15,710
preference function to extract features

00:31:10,850 --> 00:31:17,929
per item and rank them it's it's kind of

00:31:15,710 --> 00:31:19,490
hard to get your head round but it took

00:31:17,929 --> 00:31:23,679
me a while for this to find it sink in

00:31:19,490 --> 00:31:27,379
but because the the model will learn

00:31:23,679 --> 00:31:30,679
positive weights for features that tend

00:31:27,379 --> 00:31:32,389
to appear as the winner of a parent so

00:31:30,679 --> 00:31:34,549
literally positive as in greater than

00:31:32,389 --> 00:31:37,879
zero and it will learn negative weights

00:31:34,549 --> 00:31:40,250
for features that tend to appear in the

00:31:37,879 --> 00:31:42,049
loser of a pair so if you kind of

00:31:40,250 --> 00:31:44,450
average that out across all of the pairs

00:31:42,049 --> 00:31:47,360
that you see in your data then when you

00:31:44,450 --> 00:31:49,610
get a new item if you just do the the

00:31:47,360 --> 00:31:52,669
dot product the weighted sum between the

00:31:49,610 --> 00:31:54,639
items features and the features that

00:31:52,669 --> 00:31:59,899
your model has learned it will push

00:31:54,639 --> 00:32:02,120
items that share features with typical

00:31:59,899 --> 00:32:03,679
winners higher in the list and it will

00:32:02,120 --> 00:32:05,179
push items that share features with

00:32:03,679 --> 00:32:08,929
typical losers lower down the list

00:32:05,179 --> 00:32:10,100
because the winners features tend be

00:32:08,929 --> 00:32:13,460
positive the loose ones tend to be

00:32:10,100 --> 00:32:14,840
negative and there's a proof that I

00:32:13,460 --> 00:32:17,000
think was in one of the papers that I

00:32:14,840 --> 00:32:17,639
cited that eventually given enough data

00:32:17,000 --> 00:32:20,309
the

00:32:17,639 --> 00:32:22,169
learn to reconstruct the exact ranking

00:32:20,309 --> 00:32:24,329
that you fed into it based on those

00:32:22,169 --> 00:32:26,489
pairs in real life you might not

00:32:24,329 --> 00:32:28,349
necessarily want to use every single

00:32:26,489 --> 00:32:31,409
pair of results from every single search

00:32:28,349 --> 00:32:33,899
because you know say you present 20

00:32:31,409 --> 00:32:36,809
items and the user clicks on one then

00:32:33,899 --> 00:32:41,129
each search session gives you 19 you

00:32:36,809 --> 00:32:42,809
know different pairs then actually then

00:32:41,129 --> 00:32:44,099
that could actually cause a big

00:32:42,809 --> 00:32:45,899
explosion in the map states you have to

00:32:44,099 --> 00:32:48,059
train on so a large scale for something

00:32:45,899 --> 00:32:50,519
that Google paper people actually sample

00:32:48,059 --> 00:32:53,339
from pairs but also you know given

00:32:50,519 --> 00:32:55,679
enough given an unbiased sampling

00:32:53,339 --> 00:32:57,749
eventually the ranking will converge on

00:32:55,679 --> 00:33:00,269
the original target ranking okay thank

00:32:57,749 --> 00:33:05,339
you my second question I saw in your

00:33:00,269 --> 00:33:08,879
input sets you have conversion rate for

00:33:05,339 --> 00:33:12,719
items however this is not an observable

00:33:08,879 --> 00:33:17,369
variable to the user by the time he does

00:33:12,719 --> 00:33:19,979
his search query so how do you think

00:33:17,369 --> 00:33:22,229
this is a relevant feature for learning

00:33:19,979 --> 00:33:23,639
well it can act as a proxy for other

00:33:22,229 --> 00:33:28,320
features that you haven't explicitly

00:33:23,639 --> 00:33:31,379
modeled so for example maybe you haven't

00:33:28,320 --> 00:33:35,609
put in price or distance to the user as

00:33:31,379 --> 00:33:38,849
a feature but maybe your users actually

00:33:35,609 --> 00:33:43,309
often make a purchase decision based on

00:33:38,849 --> 00:33:47,459
price or distance then by putting in

00:33:43,309 --> 00:33:48,869
conversion rate then you can that will

00:33:47,459 --> 00:33:51,539
actually act as a kind of noisy proxy

00:33:48,869 --> 00:33:53,129
for that in the model it'll capture any

00:33:51,539 --> 00:33:56,339
missing things that might be important

00:33:53,129 --> 00:33:59,579
what can do thank you very much my final

00:33:56,339 --> 00:34:07,109
question how do you calculate your

00:33:59,579 --> 00:34:10,379
precision and call recall so typically

00:34:07,109 --> 00:34:11,849
for for assessing these models you would

00:34:10,379 --> 00:34:16,109
use something other than precision and

00:34:11,849 --> 00:34:18,149
recall because they they assume a kind

00:34:16,109 --> 00:34:20,269
of hard cutoff between relevant and not

00:34:18,149 --> 00:34:25,109
relevant but there are some other

00:34:20,269 --> 00:34:27,480
evaluation metrics for example a typical

00:34:25,109 --> 00:34:30,090
one is called normalized discounted

00:34:27,480 --> 00:34:32,850
cumulative gain or MD CG

00:34:30,090 --> 00:34:36,360
which looks at the actual rank order of

00:34:32,850 --> 00:34:38,100
the hits and gives more results two hits

00:34:36,360 --> 00:34:40,590
but yeah more weight two hits near at

00:34:38,100 --> 00:34:42,750
the top so it means it's more important

00:34:40,590 --> 00:34:45,990
for the model to reconstruct the the

00:34:42,750 --> 00:34:49,260
upper part of the search results

00:34:45,990 --> 00:34:51,570
correctly so again this this book also

00:34:49,260 --> 00:34:53,820
covers different evaluation metrics and

00:34:51,570 --> 00:34:55,620
the pros and cons and how to fit those

00:34:53,820 --> 00:34:59,300
two different business needs and that

00:34:55,620 --> 00:34:59,300
kind of thing thank you very much

00:34:59,690 --> 00:35:10,200
are there further questions we have time

00:35:04,020 --> 00:35:13,290
for 20 questions thank you for the talk

00:35:10,200 --> 00:35:18,390
how do you handle missing data when you

00:35:13,290 --> 00:35:20,910
have distraction of the pair how do you

00:35:18,390 --> 00:35:23,250
handle that for example in one result

00:35:20,910 --> 00:35:26,100
you have a lot a very long feature set

00:35:23,250 --> 00:35:31,440
and yet one most of the features are

00:35:26,100 --> 00:35:33,690
missing well I'm I'm not sure what how

00:35:31,440 --> 00:35:35,880
you would get missing features in this

00:35:33,690 --> 00:35:38,220
instance because if it's your your own

00:35:35,880 --> 00:35:41,400
inventory on your website and you're

00:35:38,220 --> 00:35:46,140
using features like you know text or

00:35:41,400 --> 00:35:50,490
other tokens category oh right yes yeah

00:35:46,140 --> 00:35:53,430
so I mean it usually you can just kind

00:35:50,490 --> 00:35:56,760
of leave those out it depends on what

00:35:53,430 --> 00:35:59,970
the what the proportion of you know

00:35:56,760 --> 00:36:02,130
correctly completed items there are and

00:35:59,970 --> 00:36:05,550
once with missing data I mean obviously

00:36:02,130 --> 00:36:08,910
the the more the more cases of missing

00:36:05,550 --> 00:36:12,510
data you encounter the harder it will be

00:36:08,910 --> 00:36:17,880
overall for the model to use that

00:36:12,510 --> 00:36:20,070
feature in a meaningful way but I mean

00:36:17,880 --> 00:36:21,480
the advantage of using a wide variety of

00:36:20,070 --> 00:36:22,980
different kinds of features is that the

00:36:21,480 --> 00:36:26,640
individual weights on each of them tend

00:36:22,980 --> 00:36:28,050
to be quite small so even if you do have

00:36:26,640 --> 00:36:30,810
items that are missing a particular

00:36:28,050 --> 00:36:33,210
feature and just leaving those out of

00:36:30,810 --> 00:36:34,530
the term Veck of the feature vector for

00:36:33,210 --> 00:36:42,150
that item isn't necessarily a

00:36:34,530 --> 00:36:43,230
showstopper so could you give us thank

00:36:42,150 --> 00:36:45,570
you for the dog could

00:36:43,230 --> 00:36:49,109
give us some rough estimate of how

00:36:45,570 --> 00:36:51,840
better is using re-ranking after a

00:36:49,109 --> 00:36:54,480
tf-idf or this is what I got from your

00:36:51,840 --> 00:36:56,850
tablet you're actually using leucine or

00:36:54,480 --> 00:36:59,820
some search engine first and then you do

00:36:56,850 --> 00:37:01,859
some rewriting so in or adduction or I

00:36:59,820 --> 00:37:05,700
would like to know a rough number of how

00:37:01,859 --> 00:37:06,990
better it is so two things to say one is

00:37:05,700 --> 00:37:10,790
that none of the things I've described

00:37:06,990 --> 00:37:13,830
are actually in production at Etsy yet

00:37:10,790 --> 00:37:15,900
but if you look at that paper from kdd

00:37:13,830 --> 00:37:18,990
this year the images don't lie one

00:37:15,900 --> 00:37:21,380
that's got some numbers on the uplift in

00:37:18,990 --> 00:37:24,420
the mdc-t metric that i just mentioned

00:37:21,380 --> 00:37:25,500
by using image features as well as text

00:37:24,420 --> 00:37:27,330
features but I can't remember off the

00:37:25,500 --> 00:37:29,700
top of my head all that is but the thing

00:37:27,330 --> 00:37:32,310
is I mean these things are all very very

00:37:29,700 --> 00:37:34,290
dependent on the particular data set

00:37:32,310 --> 00:37:36,960
that you use and this is why in academic

00:37:34,290 --> 00:37:38,970
IR research people publish standardized

00:37:36,960 --> 00:37:40,830
data sets and everybody tests against

00:37:38,970 --> 00:37:43,820
the same one because quite frequently

00:37:40,830 --> 00:37:47,040
the results you get on one will not be

00:37:43,820 --> 00:37:48,960
in any way sort of good predictors of

00:37:47,040 --> 00:37:50,910
the differences and results of get not

00:37:48,960 --> 00:37:53,580
on another one the features will all be

00:37:50,910 --> 00:37:54,869
different the amount of missing data

00:37:53,580 --> 00:37:55,619
however will be different and I've

00:37:54,869 --> 00:37:57,660
showed you that you have will be

00:37:55,619 --> 00:38:01,020
different so yeah I would steer away

00:37:57,660 --> 00:38:03,540
from kind of saying expect a 5% increase

00:38:01,020 --> 00:38:05,520
or expect that a 2% increase or anything

00:38:03,540 --> 00:38:10,020
like that because it really does depend

00:38:05,520 --> 00:38:14,330
on your domain in your data okay let's

00:38:10,020 --> 00:38:14,330

YouTube URL: https://www.youtube.com/watch?v=dKppAG0cdkM


