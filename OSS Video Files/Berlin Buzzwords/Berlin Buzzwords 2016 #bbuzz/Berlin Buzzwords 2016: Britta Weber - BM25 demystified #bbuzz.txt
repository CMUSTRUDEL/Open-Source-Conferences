Title: Berlin Buzzwords 2016: Britta Weber - BM25 demystified #bbuzz
Publication date: 2016-06-11
Playlist: Berlin Buzzwords 2016 #bbuzz
Description: 
	Lucene will change the default scoring from TF/IDF to BM25 in the next major release. So unless you really enjoy surprises you better learn about it now! TF/IDF was easy enough to understand intuitively but how is it with BM25? What do all these parameters do? And what do people mean when they say it is "probabilistic"? 

In this talk I will tell the story of how we came from the Probability Ranking Principle to BM25 with a minimum of math and a maximum of explaining. I will also show how BM25 differs from TF/IDF, what it means in practice and give and intuition on what the parameters of this method actually do. You will leave this talk feeling good about Lucene changing the default.

Read more:
https://2016.berlinbuzzwords.de/session/scoring-human-beings

About Britta Weber:
https://2016.berlinbuzzwords.de/users/britta-weber

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:02,659 --> 00:00:06,930
okay

00:00:03,870 --> 00:00:10,280
so i'm britta i'm a developer at elastic

00:00:06,930 --> 00:00:13,320
and I work on elastic search core and

00:00:10,280 --> 00:00:17,490
today I'm going to talk about BM 25

00:00:13,320 --> 00:00:19,170
which is a method to sort documents that

00:00:17,490 --> 00:00:22,890
contain natural language text like

00:00:19,170 --> 00:00:25,050
articles or tweets or males according to

00:00:22,890 --> 00:00:27,779
their relevance to some keywords okay so

00:00:25,050 --> 00:00:29,099
this is about keyword search and the

00:00:27,779 --> 00:00:32,489
reason why I'll be talking about it is

00:00:29,099 --> 00:00:34,020
because from Lucene 6 on with the next

00:00:32,489 --> 00:00:35,579
major release the scheme will be

00:00:34,020 --> 00:00:39,210
changing the default which is currently

00:00:35,579 --> 00:00:42,450
tf-idf to be m25 and so will elastic

00:00:39,210 --> 00:00:45,690
search and so I guess we'll someone so

00:00:42,450 --> 00:00:46,950
maybe solar device yeah okay so now is a

00:00:45,690 --> 00:00:48,510
good time to learn about it because

00:00:46,950 --> 00:00:49,800
what's the stuff with the new release

00:00:48,510 --> 00:00:51,870
and you're scoring might be a little

00:00:49,800 --> 00:00:55,469
different and that's why I'm gonna talk

00:00:51,870 --> 00:00:57,899
about it so so usually when I talk to

00:00:55,469 --> 00:00:59,579
people about Bo 25 or what it didn't

00:00:57,899 --> 00:01:02,399
know anything about it and say okay so

00:00:59,579 --> 00:01:03,510
what's BM 25 they usually go alike and

00:01:02,399 --> 00:01:05,489
you all know because you've stared at

00:01:03,510 --> 00:01:08,250
the slide for 10 minutes now they say

00:01:05,489 --> 00:01:10,700
okay that's the probabilistic approach

00:01:08,250 --> 00:01:13,350
to scoring and I had this conversation

00:01:10,700 --> 00:01:15,270
which some people never understood what

00:01:13,350 --> 00:01:16,799
it means and then with one colleague and

00:01:15,270 --> 00:01:19,290
I said so what does it mean anything I

00:01:16,799 --> 00:01:20,369
don't know you're the one who knows the

00:01:19,290 --> 00:01:22,290
math you'll figure it out

00:01:20,369 --> 00:01:25,350
or even better give a talk about it so

00:01:22,290 --> 00:01:26,850
this is where I am here thought I should

00:01:25,350 --> 00:01:29,369
figure out what's probabilistic about it

00:01:26,850 --> 00:01:32,189
and then give a talk about it so I went

00:01:29,369 --> 00:01:36,509
to look at this thing and so here it is

00:01:32,189 --> 00:01:37,950
this is p.m. 25 in all its glory and I

00:01:36,509 --> 00:01:39,960
don't know if you immediately see

00:01:37,950 --> 00:01:43,369
something probabilistic about it here

00:01:39,960 --> 00:01:45,960
where's the probabilities who sees it ok

00:01:43,369 --> 00:01:49,950
ok so my first reaction was more like

00:01:45,960 --> 00:01:52,220
that got a little scared because I had

00:01:49,950 --> 00:01:55,860
to talk the abstract or a submit it and

00:01:52,220 --> 00:01:57,930
get it ok um ok but I promise that this

00:01:55,860 --> 00:01:59,130
is actually not as complicated as might

00:01:57,930 --> 00:02:01,530
seem at first glance

00:01:59,130 --> 00:02:04,740
actually it's it was super trivial but

00:02:01,530 --> 00:02:06,299
it's a sort of easy to explain and we're

00:02:04,740 --> 00:02:09,690
gonna go through all the different parts

00:02:06,299 --> 00:02:11,700
of that during my talk but before we do

00:02:09,690 --> 00:02:12,440
that it is worth maybe spending a few

00:02:11,700 --> 00:02:13,800
minutes

00:02:12,440 --> 00:02:15,570
remembering

00:02:13,800 --> 00:02:18,000
why we should even bother to come up

00:02:15,570 --> 00:02:20,070
with such a monster why is this even so

00:02:18,000 --> 00:02:25,050
complicated either why's it so

00:02:20,070 --> 00:02:26,280
complicated to keyword search so some of

00:02:25,050 --> 00:02:27,840
you didn't even have that problem

00:02:26,280 --> 00:02:29,160
sometimes when you use a search engine

00:02:27,840 --> 00:02:32,010
for something you're not so interested

00:02:29,160 --> 00:02:33,740
in any relevancy or any ordering of your

00:02:32,010 --> 00:02:36,840
documents but you're only interested in

00:02:33,740 --> 00:02:38,700
finding something or maybe only counting

00:02:36,840 --> 00:02:41,630
so if you have some hard criteria like a

00:02:38,700 --> 00:02:43,800
particular date or an order item or

00:02:41,630 --> 00:02:45,930
particular price range and you just want

00:02:43,800 --> 00:02:48,240
to know which document has this criteria

00:02:45,930 --> 00:02:50,150
or how many have this criteria you don't

00:02:48,240 --> 00:02:52,890
care in which order they are returned

00:02:50,150 --> 00:02:55,590
when you search in text it's usually a

00:02:52,890 --> 00:02:57,360
little more problematic because when you

00:02:55,590 --> 00:02:59,040
do a keyword search many documents might

00:02:57,360 --> 00:03:04,070
match but you want to find those that

00:02:59,040 --> 00:03:06,290
best match your information need okay

00:03:04,070 --> 00:03:09,330
but this is a little bit problematic

00:03:06,290 --> 00:03:12,120
because language by itself is fuzzy

00:03:09,330 --> 00:03:14,880
right languages were both so many words

00:03:12,120 --> 00:03:17,670
that are in there don't even need for

00:03:14,880 --> 00:03:21,540
anything then of course words are

00:03:17,670 --> 00:03:23,250
ambivalent and documents can cover many

00:03:21,540 --> 00:03:25,020
topics and it's not clear just from your

00:03:23,250 --> 00:03:26,730
keywords if this document covers any

00:03:25,020 --> 00:03:27,810
topic that you're interested in or has

00:03:26,730 --> 00:03:30,150
your information need

00:03:27,810 --> 00:03:32,489
so that's tricky and on the other side

00:03:30,150 --> 00:03:34,650
what is even more tricky or what's also

00:03:32,489 --> 00:03:36,030
tricky is for you how do you formulate a

00:03:34,650 --> 00:03:37,880
search how do you oppress your

00:03:36,030 --> 00:03:41,280
information lead into a few keywords

00:03:37,880 --> 00:03:42,600
okay in consider for example consider

00:03:41,280 --> 00:03:44,520
this example you have some sort of

00:03:42,600 --> 00:03:46,350
database where people that want to apply

00:03:44,520 --> 00:03:47,640
at your company put in their profile

00:03:46,350 --> 00:03:49,200
right and it can put in okay so what

00:03:47,640 --> 00:03:51,209
kind of languages do they speack how old

00:03:49,200 --> 00:03:53,550
are they how much working experience do

00:03:51,209 --> 00:03:55,410
they have do they want to what what do

00:03:53,550 --> 00:03:56,700
they want to earn and you can filter by

00:03:55,410 --> 00:03:58,140
all these criterias but when you look

00:03:56,700 --> 00:03:59,850
for somebody that actually matches your

00:03:58,140 --> 00:04:01,410
company or matches your needs you

00:03:59,850 --> 00:04:03,239
usually look at the self description

00:04:01,410 --> 00:04:04,770
what do they write about themselves and

00:04:03,239 --> 00:04:06,630
I suppose you had this database and you

00:04:04,770 --> 00:04:08,459
would want to find someone who matches

00:04:06,630 --> 00:04:09,989
your criteria who fits well into your

00:04:08,459 --> 00:04:12,390
team who brings all the stuff that you

00:04:09,989 --> 00:04:13,650
really need to fill this job and you

00:04:12,390 --> 00:04:15,450
would look in the South description when

00:04:13,650 --> 00:04:17,459
I build a search engine hey how do you

00:04:15,450 --> 00:04:19,019
put that anyone somebody who's a quick

00:04:17,459 --> 00:04:21,000
learner you want somebody who works hard

00:04:19,019 --> 00:04:23,070
you when somebody was reliable enduring

00:04:21,000 --> 00:04:25,289
and but you only have this search

00:04:23,070 --> 00:04:26,700
interface so what you type might be

00:04:25,289 --> 00:04:30,230
something like well hard

00:04:26,700 --> 00:04:33,540
working self-motivated masochist and

00:04:30,230 --> 00:04:35,400
this is a really really inaccurate

00:04:33,540 --> 00:04:37,290
description of your actual information

00:04:35,400 --> 00:04:39,090
need okay so when you having to build a

00:04:37,290 --> 00:04:40,980
search engine it deals with natural

00:04:39,090 --> 00:04:42,330
language text on keyword queries on the

00:04:40,980 --> 00:04:44,340
one hand the search editing has since

00:04:42,330 --> 00:04:45,900
really verbose and really ambivalent

00:04:44,340 --> 00:04:47,790
text and on the other hand it has this

00:04:45,900 --> 00:04:49,770
information it was just pressed into two

00:04:47,790 --> 00:04:51,690
or three key words so it's all super

00:04:49,770 --> 00:04:54,150
inaccurate and fuzzy and it has to match

00:04:51,690 --> 00:04:56,010
these two things together to get the

00:04:54,150 --> 00:04:58,590
document that actually relevant for the

00:04:56,010 --> 00:04:59,760
user and this is a super hard problem as

00:04:58,590 --> 00:05:01,590
you can imagine because you have so

00:04:59,760 --> 00:05:02,910
little information available this is why

00:05:01,590 --> 00:05:05,040
it's so hard there has been so much

00:05:02,910 --> 00:05:09,480
research on it and also why I'm giving

00:05:05,040 --> 00:05:12,330
now 30 minutes talk about it okay so

00:05:09,480 --> 00:05:13,380
what's the purpose of my talk so the

00:05:12,330 --> 00:05:15,360
first thing is we're going to go through

00:05:13,380 --> 00:05:16,470
all these terms in this equation I'm

00:05:15,360 --> 00:05:20,040
going to show you what they actually

00:05:16,470 --> 00:05:21,900
mean and also in particular what these

00:05:20,040 --> 00:05:23,820
parameters do see some parameters

00:05:21,900 --> 00:05:24,690
they're gonna discuss them later what

00:05:23,820 --> 00:05:26,580
they do in practice

00:05:24,690 --> 00:05:27,510
what does it mean for your scoring and

00:05:26,580 --> 00:05:33,600
what's going to happen through the

00:05:27,510 --> 00:05:35,910
scores I will also talk about why PM 25

00:05:33,600 --> 00:05:37,770
has label probabilistic and this is

00:05:35,910 --> 00:05:39,570
actually the major part of this talk and

00:05:37,770 --> 00:05:41,130
to be absolutely honest it has not much

00:05:39,570 --> 00:05:42,990
practical relevance for you this is

00:05:41,130 --> 00:05:45,620
mainly for your entertainment and so

00:05:42,990 --> 00:05:49,050
that you can later on go and show off

00:05:45,620 --> 00:05:52,530
okay so I hope that I'll be able to

00:05:49,050 --> 00:05:54,000
convince you that switching to beyond 25

00:05:52,530 --> 00:05:55,410
is the right thing to do and that's

00:05:54,000 --> 00:05:57,300
actually the hardest part of the talk

00:05:55,410 --> 00:06:01,110
I'm not sure if I'll be able to convince

00:05:57,300 --> 00:06:02,430
you but but I hope and again I hope that

00:06:01,110 --> 00:06:03,870
you're able to learn some buzz words

00:06:02,430 --> 00:06:05,070
that you can show off with during the

00:06:03,870 --> 00:06:10,260
breaks although there's not so many now

00:06:05,070 --> 00:06:12,800
more but yeah okay so before we talk

00:06:10,260 --> 00:06:15,120
about being 25 or the details of pm 25

00:06:12,800 --> 00:06:17,790
quick remind them what the current

00:06:15,120 --> 00:06:20,040
default is currently folders tf-idf and

00:06:17,790 --> 00:06:21,750
we stick with this little artificial

00:06:20,040 --> 00:06:23,340
example we're looking for an intern I

00:06:21,750 --> 00:06:26,100
will see you later why we need so many

00:06:23,340 --> 00:06:28,530
interns so we're looking for an intern

00:06:26,100 --> 00:06:30,060
and we look at the self description for

00:06:28,530 --> 00:06:31,710
self-motivated hard-working masochist

00:06:30,060 --> 00:06:33,090
and we want to find order the

00:06:31,710 --> 00:06:35,100
applications that there are many because

00:06:33,090 --> 00:06:36,690
your company is very successful you want

00:06:35,100 --> 00:06:39,199
to order the applications by their

00:06:36,690 --> 00:06:41,400
relevance to these this keyword for me

00:06:39,199 --> 00:06:43,830
then the only evidence that we actually

00:06:41,400 --> 00:06:46,229
have for that something is relevant or

00:06:43,830 --> 00:06:47,970
not is what is called the term

00:06:46,229 --> 00:06:50,340
frequencies and that it's the number of

00:06:47,970 --> 00:06:53,550
times these key words that you type in

00:06:50,340 --> 00:06:56,310
are contained in the text okay so what

00:06:53,550 --> 00:06:58,320
you do is you go go through the text and

00:06:56,310 --> 00:06:59,760
count how often are these two key words

00:06:58,320 --> 00:07:02,790
in there that's the term frequency for

00:06:59,760 --> 00:07:04,169
each of these terms and as you know I

00:07:02,790 --> 00:07:06,419
mean it's tricky even to figure out

00:07:04,169 --> 00:07:08,729
where what start where what ends how to

00:07:06,419 --> 00:07:10,050
lowercase them and what-have-you this is

00:07:08,729 --> 00:07:12,630
all the same part so we just assume we

00:07:10,050 --> 00:07:15,630
have that thing okay so we get to turn

00:07:12,630 --> 00:07:17,880
frequencies and from this tf-idf

00:07:15,630 --> 00:07:20,760
computes some score by which the

00:07:17,880 --> 00:07:22,440
document is ordered and there is just

00:07:20,760 --> 00:07:25,500
summarizing it very very quickly so

00:07:22,440 --> 00:07:27,900
there's three major tweaks okay first is

00:07:25,500 --> 00:07:29,760
we take this term frequency sum this up

00:07:27,900 --> 00:07:32,160
for each key word that matches and we

00:07:29,760 --> 00:07:34,500
say more is better okay so the higher

00:07:32,160 --> 00:07:36,780
the term frequency the more score it

00:07:34,500 --> 00:07:38,970
gets and this is a it's not a linear

00:07:36,780 --> 00:07:40,139
function it's a square root of the term

00:07:38,970 --> 00:07:43,289
frequency but this is basically what

00:07:40,139 --> 00:07:45,780
tf-idf and leucine does right now okay

00:07:43,289 --> 00:07:47,760
this is the first thing it's

00:07:45,780 --> 00:07:50,099
unfortunately a little tricky to just

00:07:47,760 --> 00:07:52,710
use that because if you have very common

00:07:50,099 --> 00:07:55,440
terms for example the or a or who and

00:07:52,710 --> 00:07:57,120
use the terms that occur in nearly every

00:07:55,440 --> 00:07:58,680
English document that you're looking at

00:07:57,120 --> 00:08:01,380
so the term frequency will be rather

00:07:58,680 --> 00:08:03,389
high in each English document so if a

00:08:01,380 --> 00:08:04,979
user types one of these words in their

00:08:03,389 --> 00:08:08,419
search query this will screw up your

00:08:04,979 --> 00:08:10,500
score completely okay this is why I this

00:08:08,419 --> 00:08:11,639
criteria is weighted by something else

00:08:10,500 --> 00:08:14,099
it's called the inverse document

00:08:11,639 --> 00:08:17,610
frequency which basically means that

00:08:14,099 --> 00:08:19,410
common words or words that appear more

00:08:17,610 --> 00:08:21,840
of them in your corpus that are common

00:08:19,410 --> 00:08:23,430
to many documents are less important

00:08:21,840 --> 00:08:25,979
okay and this is called the inverse

00:08:23,430 --> 00:08:27,930
document frequency so document frequency

00:08:25,979 --> 00:08:30,120
is how often does or in how many

00:08:27,930 --> 00:08:31,590
documents does a term occur and inverse

00:08:30,120 --> 00:08:33,209
document frequency means okay so the

00:08:31,590 --> 00:08:35,219
more of them it occurs the lower this

00:08:33,209 --> 00:08:37,349
value gets so this is this higher term

00:08:35,219 --> 00:08:38,640
frequency meets lower score and this is

00:08:37,349 --> 00:08:41,570
actually multiplied with this term

00:08:38,640 --> 00:08:44,610
frequency and then it's all summed up

00:08:41,570 --> 00:08:46,350
okay that's the second tweak and the

00:08:44,610 --> 00:08:48,390
third is and I imagine for example you

00:08:46,350 --> 00:08:49,650
have a tweet that Metro swallow has a

00:08:48,390 --> 00:08:51,600
certain term frequency and you have a

00:08:49,650 --> 00:08:52,800
book has the same terrific

00:08:51,600 --> 00:08:54,899
frequency and

00:08:52,800 --> 00:08:57,000
you might imagine that this tweet is

00:08:54,899 --> 00:08:58,800
actually about that term whereas a book

00:08:57,000 --> 00:09:00,870
that has a thousand pages and the term

00:08:58,800 --> 00:09:02,970
only occurs five times it's maybe about

00:09:00,870 --> 00:09:05,519
something completely different okay

00:09:02,970 --> 00:09:08,700
and to also incorporate this intuition

00:09:05,519 --> 00:09:11,430
into tf-idf we've seen now also uses the

00:09:08,700 --> 00:09:13,350
length of the document and the length of

00:09:11,430 --> 00:09:16,230
the document means how many terms are

00:09:13,350 --> 00:09:18,740
contained in your field okay and again

00:09:16,230 --> 00:09:20,940
the more terms are in there the less

00:09:18,740 --> 00:09:22,829
well relevant the whole document

00:09:20,940 --> 00:09:24,690
actually is so this is here and this

00:09:22,829 --> 00:09:27,930
also take one divided by the square-root

00:09:24,690 --> 00:09:30,120
right so shorter higher score longer

00:09:27,930 --> 00:09:35,690
lower score this is a three major things

00:09:30,120 --> 00:09:40,410
in the scene okay there's one more thing

00:09:35,690 --> 00:09:41,220
that was seen this was tf-idf and i

00:09:40,410 --> 00:09:43,740
consider for example the following

00:09:41,220 --> 00:09:45,390
example you have so you're looking for

00:09:43,740 --> 00:09:46,500
something you wanna do a holiday in

00:09:45,390 --> 00:09:48,149
China and you're looking for documents

00:09:46,500 --> 00:09:49,589
that match that to get a description of

00:09:48,149 --> 00:09:51,240
what's good what's not good and so on

00:09:49,589 --> 00:09:53,700
and so forth and yet these two documents

00:09:51,240 --> 00:09:55,110
one is describes my holiday in Beijing

00:09:53,700 --> 00:09:57,920
whereas the other one is the economic

00:09:55,110 --> 00:10:01,320
development of citron from 1920 to 1930

00:09:57,920 --> 00:10:04,230
them both will probably contain the word

00:10:01,320 --> 00:10:07,709
China rather often holiday might only be

00:10:04,230 --> 00:10:10,050
contained in this blog post right but if

00:10:07,709 --> 00:10:11,880
this document contains China very very

00:10:10,050 --> 00:10:13,560
often it has the same length and this

00:10:11,880 --> 00:10:15,060
only sometimes and hold the only

00:10:13,560 --> 00:10:17,640
sometimes this one will score higher

00:10:15,060 --> 00:10:21,990
even though it's definitely not what you

00:10:17,640 --> 00:10:24,240
really intend to find right so and this

00:10:21,990 --> 00:10:27,870
stems from the fact that tf-idf always

00:10:24,240 --> 00:10:29,399
assumes more is better and to adjust

00:10:27,870 --> 00:10:30,870
your score again a little bit to that

00:10:29,399 --> 00:10:33,600
Lucina something that's called the

00:10:30,870 --> 00:10:36,149
cohort factor and in roughly what it

00:10:33,600 --> 00:10:38,370
does it rewards documents that match

00:10:36,149 --> 00:10:40,860
more than one query term so this one

00:10:38,370 --> 00:10:42,029
would be adjusted accordingly so that it

00:10:40,860 --> 00:10:44,010
scores higher than the one that only

00:10:42,029 --> 00:10:45,390
matches one query term okay this is a

00:10:44,010 --> 00:10:48,029
hack it's a little bit of a hack and

00:10:45,390 --> 00:10:52,850
bull query and you'll see developers

00:10:48,029 --> 00:10:52,850
here okay I can trust arrangement

00:10:54,829 --> 00:11:01,470
oh yeah the art of the scene program has

00:10:59,130 --> 00:11:03,090
made this hack so

00:11:01,470 --> 00:11:04,740
okay so what's wrong with you if I def

00:11:03,090 --> 00:11:07,020
I'm in TNS actually for tonight's right

00:11:04,740 --> 00:11:09,440
that's been successful since oh what

00:11:07,020 --> 00:11:09,440
just happened

00:11:17,890 --> 00:11:20,670
oh boo

00:11:26,070 --> 00:11:30,660
yeah I'm sorry it's the rest of God huh

00:11:40,110 --> 00:11:46,120
okay good okay see if I do as I said

00:11:44,590 --> 00:11:48,220
successful since the very beginning it

00:11:46,120 --> 00:11:49,900
was the score the the first scoring

00:11:48,220 --> 00:11:51,940
algorithm they had and it's still the

00:11:49,900 --> 00:11:54,130
default right so successful since the

00:11:51,940 --> 00:11:55,720
beginning of 15 it's pretty well studied

00:11:54,130 --> 00:11:57,250
it is super easy to understand as you

00:11:55,720 --> 00:12:00,580
just saw I hope um

00:11:57,250 --> 00:12:03,370
and it's well it's a one size fits most

00:12:00,580 --> 00:12:06,730
it most people are more or less happy

00:12:03,370 --> 00:12:09,190
with it so the question is well why

00:12:06,730 --> 00:12:10,240
don't even bother way why would we have

00:12:09,190 --> 00:12:13,870
to come up with something else

00:12:10,240 --> 00:12:15,130
and the thing is that even yes it is a

00:12:13,870 --> 00:12:15,940
heuristic but it also means it's

00:12:15,130 --> 00:12:17,470
somewhat a guess

00:12:15,940 --> 00:12:21,070
it's somebody sat down and thought okay

00:12:17,470 --> 00:12:22,120
so um if I add up TF that's nice if I

00:12:21,070 --> 00:12:23,740
take the square root is even a little

00:12:22,120 --> 00:12:27,430
bit better so let's take the square root

00:12:23,740 --> 00:12:28,660
or okay if I divide by the length that's

00:12:27,430 --> 00:12:30,460
fine but if you divide by the square

00:12:28,660 --> 00:12:32,080
root of four legs that's also nice so

00:12:30,460 --> 00:12:34,210
try all these different things and then

00:12:32,080 --> 00:12:35,890
this is this is the final result and the

00:12:34,210 --> 00:12:37,750
question is maybe maybe we can do better

00:12:35,890 --> 00:12:39,340
maybe can be a little bit smarter about

00:12:37,750 --> 00:12:45,220
it and then my score might be better

00:12:39,340 --> 00:12:48,580
that was the basic idea okay so how did

00:12:45,220 --> 00:12:50,680
we get to be m25 and it all starts with

00:12:48,580 --> 00:12:52,900
something that is called the probability

00:12:50,680 --> 00:12:54,400
ranking principle and I'll just give you

00:12:52,900 --> 00:12:55,570
the abridged version it's a much longer

00:12:54,400 --> 00:12:58,120
version of that and a much better

00:12:55,570 --> 00:13:00,940
definition but basically what it said is

00:12:58,120 --> 00:13:03,190
is if retrieve documents are ordered by

00:13:00,940 --> 00:13:05,410
a decreasing probability of relevance on

00:13:03,190 --> 00:13:07,270
the data available then the systems

00:13:05,410 --> 00:13:11,350
effectiveness is the best that can be

00:13:07,270 --> 00:13:14,080
obtained from the data which by itself

00:13:11,350 --> 00:13:15,010
maybe sounds a little trivial because I

00:13:14,080 --> 00:13:17,740
mean you could think okay you have your

00:13:15,010 --> 00:13:19,150
document that just has some probability

00:13:17,740 --> 00:13:20,440
that it's relevant and of course the one

00:13:19,150 --> 00:13:21,820
that has the highest probability should

00:13:20,440 --> 00:13:26,350
be upfront and the other should be

00:13:21,820 --> 00:13:27,850
scored lower right so um there is two

00:13:26,350 --> 00:13:30,730
things that are actually really exciting

00:13:27,850 --> 00:13:35,650
about it and I mean the basic idea is

00:13:30,730 --> 00:13:36,460
you you try to put your intuition into

00:13:35,650 --> 00:13:39,040
some

00:13:36,460 --> 00:13:41,350
medical framework of probabilities right

00:13:39,040 --> 00:13:42,780
and this means on the one hand if you

00:13:41,350 --> 00:13:45,460
actually managed to put it into some

00:13:42,780 --> 00:13:47,350
probabilistic framework you might

00:13:45,460 --> 00:13:49,900
actually be able to incorporate prior

00:13:47,350 --> 00:13:51,310
knowledge on your data into your scoring

00:13:49,900 --> 00:13:51,730
algorithm meaning you can do machine

00:13:51,310 --> 00:13:54,640
learning

00:13:51,730 --> 00:13:57,010
yeah so that's the one thing that's

00:13:54,640 --> 00:13:58,030
exciting about it and in the other is if

00:13:57,010 --> 00:13:59,650
you manage to put it into a

00:13:58,030 --> 00:14:01,150
probabilistic framework you don't have

00:13:59,650 --> 00:14:02,740
to do the math because hundreds of

00:14:01,150 --> 00:14:04,240
mathematicians have done the work

00:14:02,740 --> 00:14:07,780
already for you you just have to look up

00:14:04,240 --> 00:14:09,280
at the right places and so so that's the

00:14:07,780 --> 00:14:12,010
cool thing about trying to use a

00:14:09,280 --> 00:14:13,060
probabilistic framework it also means

00:14:12,010 --> 00:14:15,280
that now we're going to do a little bit

00:14:13,060 --> 00:14:18,310
of math okay so for the next 20 minutes

00:14:15,280 --> 00:14:20,410
or so think it's mathematicians even if

00:14:18,310 --> 00:14:24,240
you're not into math okay by that I mean

00:14:20,410 --> 00:14:27,100
let go of all practical considerations

00:14:24,240 --> 00:14:28,900
you don't care how many CPUs you need or

00:14:27,100 --> 00:14:30,700
how many infants you need to hire if

00:14:28,900 --> 00:14:32,620
they jump from the ruler here right and

00:14:30,700 --> 00:14:38,020
the other is think of yourself as

00:14:32,620 --> 00:14:40,990
super-smart why are you laughing no

00:14:38,020 --> 00:14:42,340
seriously it's you might say I mean I'm

00:14:40,990 --> 00:14:43,540
not sure if I get to the world enough to

00:14:42,340 --> 00:14:44,500
actually explain everything on the next

00:14:43,540 --> 00:14:46,060
slides if you don't get it immediately

00:14:44,500 --> 00:14:52,600
don't worry you're super smart you could

00:14:46,060 --> 00:14:55,060
figure it out at home okay so okay okay

00:14:52,600 --> 00:14:56,740
so what's the basic idea uh separating

00:14:55,060 --> 00:15:00,100
two fancy machine learning what do we

00:14:56,740 --> 00:15:02,350
want to do okay so we try to estimate

00:15:00,100 --> 00:15:03,940
the probability of relevancy and we

00:15:02,350 --> 00:15:07,000
start with a simplification that is we

00:15:03,940 --> 00:15:08,950
say okay relevance is binary document is

00:15:07,000 --> 00:15:12,460
relevant given a query or a document is

00:15:08,950 --> 00:15:14,620
not relevant and note that even though

00:15:12,460 --> 00:15:16,240
this is have one zero it does not mean

00:15:14,620 --> 00:15:18,010
that the probability is 1 0 the

00:15:16,240 --> 00:15:20,140
probability can still be a float right

00:15:18,010 --> 00:15:23,730
but in first ok relevance is something

00:15:20,140 --> 00:15:25,810
that's binary it cannot be half relevant

00:15:23,730 --> 00:15:27,310
okay and now what we could do

00:15:25,810 --> 00:15:29,320
potentially to gather some data is we

00:15:27,310 --> 00:15:31,120
could have our interns give them a

00:15:29,320 --> 00:15:32,800
document give them a query and then they

00:15:31,120 --> 00:15:33,400
tell us ok this is relevant oh this is

00:15:32,800 --> 00:15:37,230
not relevant

00:15:33,400 --> 00:15:40,620
hey and then the hope is that we get

00:15:37,230 --> 00:15:43,420
they can use this data to actually

00:15:40,620 --> 00:15:45,130
estimate the probability of relevancy

00:15:43,420 --> 00:15:47,890
given some query that's the basic idea

00:15:45,130 --> 00:15:49,970
so we get all our interns we let them

00:15:47,890 --> 00:15:55,339
click all day

00:15:49,970 --> 00:15:57,620
then we end up with a set come on

00:15:55,339 --> 00:15:59,680
so it works actually you have users

00:15:57,620 --> 00:16:03,019
right how many can you use user clicks

00:15:59,680 --> 00:16:04,670
don't need all these infants okay

00:16:03,019 --> 00:16:06,110
so you want to have the set of all the

00:16:04,670 --> 00:16:07,310
documents per query and that some of

00:16:06,110 --> 00:16:12,259
those are relevant and some of those are

00:16:07,310 --> 00:16:13,430
not relevant okay so this is the machine

00:16:12,259 --> 00:16:15,949
learning part we're gonna see later how

00:16:13,430 --> 00:16:17,540
this goes but not a mousepad what does

00:16:15,949 --> 00:16:21,230
this actually mean in math probability

00:16:17,540 --> 00:16:22,879
of relevancy and in math how it actually

00:16:21,230 --> 00:16:25,189
looks like is we want to estimate the

00:16:22,879 --> 00:16:27,949
probability that the relevancy is one

00:16:25,189 --> 00:16:29,629
given a document and a query okay so

00:16:27,949 --> 00:16:31,819
this is the the relevant sister random

00:16:29,629 --> 00:16:34,579
variable can be 100 can't be 0 and this

00:16:31,819 --> 00:16:35,930
this bar here means okay given that so

00:16:34,579 --> 00:16:37,670
given for some document and some query

00:16:35,930 --> 00:16:39,319
give me what the relevance if the

00:16:37,670 --> 00:16:43,360
probability that the relevancy is one

00:16:39,319 --> 00:16:45,920
item P just means the probability and

00:16:43,360 --> 00:16:48,110
just it's just a suppose you're not too

00:16:45,920 --> 00:16:49,790
familiar with that the basic idea is you

00:16:48,110 --> 00:16:52,129
have some list right yes all your

00:16:49,790 --> 00:16:53,810
documents and this is for one query all

00:16:52,129 --> 00:16:55,610
your documents and relevance is one this

00:16:53,810 --> 00:16:57,680
we don't not interested in and you want

00:16:55,610 --> 00:17:00,050
to get these numbers and then order the

00:16:57,680 --> 00:17:01,610
documents by well this number highest

00:17:00,050 --> 00:17:03,199
gets up in front so in this case

00:17:01,610 --> 00:17:05,510
document 3 would be highest but we don't

00:17:03,199 --> 00:17:07,189
know what's here so okay the problem is

00:17:05,510 --> 00:17:08,809
that you need this list for all

00:17:07,189 --> 00:17:09,559
documents that you have in all documents

00:17:08,809 --> 00:17:11,569
that you haven't seen yet

00:17:09,559 --> 00:17:12,980
and you need it for each query that you

00:17:11,569 --> 00:17:17,209
have in this particular formulation

00:17:12,980 --> 00:17:21,380
right it is just a basic concept which

00:17:17,209 --> 00:17:22,579
is not super helpful right now and now

00:17:21,380 --> 00:17:24,110
here comes the part where the other

00:17:22,579 --> 00:17:25,640
exciting hard way I said before okay so

00:17:24,110 --> 00:17:27,199
it's good that it's in math because the

00:17:25,640 --> 00:17:28,850
math means we can't just look up the the

00:17:27,199 --> 00:17:31,250
places that we need and somebody else

00:17:28,850 --> 00:17:32,720
will spend the work already for us so

00:17:31,250 --> 00:17:35,419
what we what we need is we want to try

00:17:32,720 --> 00:17:37,309
get this this formulation of the problem

00:17:35,419 --> 00:17:39,770
into something that we can actually use

00:17:37,309 --> 00:17:41,330
meaning we want something that just like

00:17:39,770 --> 00:17:43,490
tf--idf or you can take the term

00:17:41,330 --> 00:17:44,240
frequencies and from these term

00:17:43,490 --> 00:17:47,990
frequencies

00:17:44,240 --> 00:17:49,580
estimate this probability right so we

00:17:47,990 --> 00:17:51,320
have to reformulate that in terms of

00:17:49,580 --> 00:17:53,059
term frequencies we really have to make

00:17:51,320 --> 00:17:56,299
some independence assumptions and so on

00:17:53,059 --> 00:17:58,280
and so forth okay and I said before

00:17:56,299 --> 00:17:59,570
somebody else's done that already so I'm

00:17:58,280 --> 00:18:01,860
not going to show exactly how that goes

00:17:59,570 --> 00:18:03,810
just gonna say here be math

00:18:01,860 --> 00:18:05,550
if you if you want to know the details

00:18:03,810 --> 00:18:07,560
the absolute details of how this

00:18:05,550 --> 00:18:09,510
computation works it's not super lengthy

00:18:07,560 --> 00:18:11,820
or hard to explain but if it wouldn't

00:18:09,510 --> 00:18:13,410
fit in the talk um you can look it up in

00:18:11,820 --> 00:18:15,330
this paper the probabilistic relevance

00:18:13,410 --> 00:18:17,370
framework beyond 25 and beyond that's an

00:18:15,330 --> 00:18:21,740
exceptionally well written paper it's

00:18:17,370 --> 00:18:21,740
it's really what seriously 15 minutes Oh

00:18:22,340 --> 00:18:33,030
what time is it okay

00:18:31,620 --> 00:18:36,810
read this paper if you want to know the

00:18:33,030 --> 00:18:40,440
details I don't want a thing okay so

00:18:36,810 --> 00:18:42,150
they did all this computation try to fit

00:18:40,440 --> 00:18:44,820
in the term frequencies and so on and so

00:18:42,150 --> 00:18:46,260
forth and get to some final result I'm

00:18:44,820 --> 00:18:47,940
just gonna discuss the result and then

00:18:46,260 --> 00:18:51,920
what comes after that okay this is the

00:18:47,940 --> 00:18:56,250
final oh yeah here's a W that's a wait

00:18:51,920 --> 00:18:57,360
that's a W of the okay so what we are

00:18:56,250 --> 00:18:59,460
now but something that's actually not a

00:18:57,360 --> 00:19:01,260
probability in between this computation

00:18:59,460 --> 00:19:03,180
we got rid of the constraint that it has

00:19:01,260 --> 00:19:04,680
to be a probability instead it's just

00:19:03,180 --> 00:19:06,450
some weight that would order the

00:19:04,680 --> 00:19:08,790
documents the same way that an actual

00:19:06,450 --> 00:19:10,230
probability would but it was interesting

00:19:08,790 --> 00:19:12,090
here is the right hand side so this

00:19:10,230 --> 00:19:14,280
little Sigma just means okay sum up all

00:19:12,090 --> 00:19:16,050
the terms in the query where the term

00:19:14,280 --> 00:19:18,090
frequency in this document is greater

00:19:16,050 --> 00:19:21,000
than zero here just sum all of this up

00:19:18,090 --> 00:19:22,920
and and these parts here these

00:19:21,000 --> 00:19:25,650
probabilities what this actually mean is

00:19:22,920 --> 00:19:27,360
we have a list so we have a list for the

00:19:25,650 --> 00:19:29,190
probability of the term frequency of

00:19:27,360 --> 00:19:31,230
hard-working is 1 given that the

00:19:29,190 --> 00:19:32,820
relevancy is 1 the term frequency of

00:19:31,230 --> 00:19:34,680
hardworking is 1 given that the valency

00:19:32,820 --> 00:19:36,330
0 term frequency of hardworking is to

00:19:34,680 --> 00:19:38,520
given the to relevance of 1 and so on

00:19:36,330 --> 00:19:40,170
and so forth and for each of these terms

00:19:38,520 --> 00:19:42,660
in our corpus we need this list of

00:19:40,170 --> 00:19:45,690
numbers and in the same way we also need

00:19:42,660 --> 00:19:48,150
the same for hard-working does not occur

00:19:45,690 --> 00:19:49,800
in a document and if you think and this

00:19:48,150 --> 00:19:51,120
is still a little weird is this much

00:19:49,800 --> 00:19:52,800
better than what we had before because

00:19:51,120 --> 00:19:56,130
what we now need is just to maintain one

00:19:52,800 --> 00:19:57,630
list per term in our documents and if we

00:19:56,130 --> 00:19:59,370
have this list and if you have that

00:19:57,630 --> 00:20:00,750
somewhere stored then once the query

00:19:59,370 --> 00:20:02,880
comes in we can just look up these

00:20:00,750 --> 00:20:04,680
values in this list plug it in here sum

00:20:02,880 --> 00:20:08,280
it up and be done and we had a perfect

00:20:04,680 --> 00:20:09,210
relevancy score okay but then of course

00:20:08,280 --> 00:20:11,850
the question is well where do we get

00:20:09,210 --> 00:20:14,950
this list from it's a little better than

00:20:11,850 --> 00:20:19,010
before but where do we get them from

00:20:14,950 --> 00:20:22,100
okay so how do we estimate this

00:20:19,010 --> 00:20:23,870
probabilities I first shot at that is we

00:20:22,100 --> 00:20:26,120
make a in dramatic but useful

00:20:23,870 --> 00:20:28,280
simplification as we use the binary

00:20:26,120 --> 00:20:30,500
independence model we say we don't care

00:20:28,280 --> 00:20:32,809
about frequencies at all we only care

00:20:30,500 --> 00:20:34,790
about if a term occurs in a document of

00:20:32,809 --> 00:20:36,740
it doesn't occur in a document and this

00:20:34,790 --> 00:20:38,059
sometimes makes sense in practice too if

00:20:36,740 --> 00:20:40,010
you look in the tweets or a chat

00:20:38,059 --> 00:20:41,870
messages where you wouldn't think that

00:20:40,010 --> 00:20:44,600
the term occurs more often than once a

00:20:41,870 --> 00:20:45,740
way you wouldn't care if it does okay so

00:20:44,600 --> 00:20:48,410
in that case you can actually make that

00:20:45,740 --> 00:20:48,830
assumption and then per query and per

00:20:48,410 --> 00:20:50,570
term

00:20:48,830 --> 00:20:53,840
you only have or per term you only have

00:20:50,570 --> 00:20:55,700
a set that contains well documents that

00:20:53,840 --> 00:20:58,220
are not relevant and do not contain the

00:20:55,700 --> 00:20:59,870
query term some are relevant some

00:20:58,220 --> 00:21:03,440
contain the quarter at some are relevant

00:20:59,870 --> 00:21:05,510
and contain the query term right and if

00:21:03,440 --> 00:21:09,380
we had this set for each of our terms

00:21:05,510 --> 00:21:11,480
because her infant pixel endlessly if we

00:21:09,380 --> 00:21:13,490
could get these numbers maybe we can put

00:21:11,480 --> 00:21:18,230
estimate as probabilities from these

00:21:13,490 --> 00:21:19,669
numbers okay and we can so this is the

00:21:18,230 --> 00:21:21,559
way this would go I would say okay

00:21:19,669 --> 00:21:23,990
probability that the frequency is 1

00:21:21,559 --> 00:21:25,669
given that the relevancy is 1 is really

00:21:23,990 --> 00:21:28,820
just the relevant documents that contain

00:21:25,669 --> 00:21:31,669
the term divided by the relevant

00:21:28,820 --> 00:21:33,470
documents this is this probability it's

00:21:31,669 --> 00:21:34,640
a max maximum likelihood estimate and if

00:21:33,470 --> 00:21:39,650
you're in the statistics you might say

00:21:34,640 --> 00:21:40,730
well now but okay and there's some

00:21:39,650 --> 00:21:42,679
smoothing factors there that are not

00:21:40,730 --> 00:21:45,169
super important for the course of this

00:21:42,679 --> 00:21:46,460
talk but anyway if the headers numbers

00:21:45,169 --> 00:21:48,320
this is how we actually could compute

00:21:46,460 --> 00:21:50,419
that number and then we could do the

00:21:48,320 --> 00:21:52,820
same for frequencies one given relevancy

00:21:50,419 --> 00:21:55,120
is zero right and then get the frequency

00:21:52,820 --> 00:21:58,370
is zero just by one - the other thing

00:21:55,120 --> 00:22:00,110
okay and then for frequency - irrelevant

00:21:58,370 --> 00:22:02,169
so we don't care right we could spirit

00:22:00,110 --> 00:22:07,669
this binary independence assumption

00:22:02,169 --> 00:22:09,290
so to summarize right we take these sets

00:22:07,669 --> 00:22:11,299
right we compute these four

00:22:09,290 --> 00:22:13,419
probabilities we plug this in to this

00:22:11,299 --> 00:22:16,160
weight equation into these four terms

00:22:13,419 --> 00:22:17,780
whenever we encounter a term sum them up

00:22:16,160 --> 00:22:19,460
for each of the query terms where that

00:22:17,780 --> 00:22:23,270
actually occurs and then we have our

00:22:19,460 --> 00:22:26,090
perfect score okay

00:22:23,270 --> 00:22:29,779
and if we do that if we plug if we plug

00:22:26,090 --> 00:22:31,850
these these these terms that we just saw

00:22:29,779 --> 00:22:33,980
really in here what we end up with is

00:22:31,850 --> 00:22:35,299
the Robertson Spike Jonze wait and this

00:22:33,980 --> 00:22:36,980
is something that you might have might

00:22:35,299 --> 00:22:38,809
not have heard ever since but something

00:22:36,980 --> 00:22:40,520
you can impress people with if somebody

00:22:38,809 --> 00:22:42,559
says okay oh yeah I'm losing the scene

00:22:40,520 --> 00:22:46,760
sex yeah it's uses the Robertson spark

00:22:42,559 --> 00:22:48,260
Jones wait okay anyway so this is what

00:22:46,760 --> 00:22:49,909
you ended up it so you have these this

00:22:48,260 --> 00:22:52,010
this equation yeah this is really just

00:22:49,909 --> 00:22:55,909
the counts that are in these sets right

00:22:52,010 --> 00:22:57,049
and this is how it was derived okay so

00:22:55,909 --> 00:22:58,789
if you have an unlimited supply of

00:22:57,049 --> 00:23:00,860
insurance you let them click all day you

00:22:58,789 --> 00:23:03,500
get these sets you compute for each of

00:23:00,860 --> 00:23:05,419
the terms compute this number end up

00:23:03,500 --> 00:23:07,159
with one list for a motivated work in

00:23:05,419 --> 00:23:08,419
experience and so on and so forth and

00:23:07,159 --> 00:23:11,149
then whenever something matches the

00:23:08,419 --> 00:23:12,110
query you just sum these numbers up for

00:23:11,149 --> 00:23:14,270
these terms and then you get your

00:23:12,110 --> 00:23:17,600
perfect score that's the basic idea of

00:23:14,270 --> 00:23:20,600
that unfortunately we don't have that

00:23:17,600 --> 00:23:22,399
normally and the fun thing is you can

00:23:20,600 --> 00:23:24,740
still use the Robertson spike jonze wait

00:23:22,399 --> 00:23:27,080
but make a really funny assumption and

00:23:24,740 --> 00:23:30,500
that is that the number of documents

00:23:27,080 --> 00:23:31,820
that are relevant is zero which which

00:23:30,500 --> 00:23:32,899
sounds a little odd in the very

00:23:31,820 --> 00:23:35,480
beginning but if you actually do the

00:23:32,899 --> 00:23:36,950
math go back and set this to zero here

00:23:35,480 --> 00:23:38,990
then you actually end up with something

00:23:36,950 --> 00:23:40,399
doesn't just vanish but you end up with

00:23:38,990 --> 00:23:42,380
something that's actually useful and

00:23:40,399 --> 00:23:46,370
this is called the inverse document

00:23:42,380 --> 00:23:49,010
frequency for 4b m25 just to give you an

00:23:46,370 --> 00:23:50,870
idea how that looks like so this is on a

00:23:49,010 --> 00:23:52,399
logarithmic scale here you have the

00:23:50,870 --> 00:23:54,049
document frequency you have the inverse

00:23:52,399 --> 00:23:56,330
document frequency I can in logarithmic

00:23:54,049 --> 00:23:59,539
scale you can see okay it decreases

00:23:56,330 --> 00:24:03,049
right from 10 and then to 1 and then it

00:23:59,539 --> 00:24:05,090
decreases even further to 0 and this in

00:24:03,049 --> 00:24:07,190
comparison to the the IDF that you get

00:24:05,090 --> 00:24:08,990
from tf-idf decreases decreases but then

00:24:07,190 --> 00:24:12,380
stays the same and what this means is

00:24:08,990 --> 00:24:14,529
that very very common words are scaled

00:24:12,380 --> 00:24:17,149
even lower than they would be in tf-idf

00:24:14,529 --> 00:24:23,809
hey so this is just a major difference

00:24:17,149 --> 00:24:25,250
here ok so it's that part it's the

00:24:23,809 --> 00:24:27,740
inverse document frequency that says

00:24:25,250 --> 00:24:29,720
okay how popular is the term actually in

00:24:27,740 --> 00:24:31,039
the corpus it comes from this Robertson

00:24:29,720 --> 00:24:32,510
Spock Jones bike and the assumption that

00:24:31,039 --> 00:24:34,980
relevant document or number of relevant

00:24:32,510 --> 00:24:38,700
documents is 0

00:24:34,980 --> 00:24:40,110
okay so now second part we said okay we

00:24:38,700 --> 00:24:43,080
don't care about TM frequencies

00:24:40,110 --> 00:24:44,730
that's what if we do care about turn

00:24:43,080 --> 00:24:46,290
frequencies right what does the term

00:24:44,730 --> 00:24:48,120
frequency tell us about relevancy and

00:24:46,290 --> 00:24:51,690
then tf-idf it was easy we said okay

00:24:48,120 --> 00:24:52,800
more it's just better but for BM twenty

00:24:51,690 --> 00:24:55,410
five people were asking actually a

00:24:52,800 --> 00:24:56,910
different question and it was well what

00:24:55,410 --> 00:24:59,460
does the term if we can see actually

00:24:56,910 --> 00:25:02,970
tell us about if a document is about a

00:24:59,460 --> 00:25:05,130
term or not about a term this is a this

00:25:02,970 --> 00:25:06,540
property is called elite Ness and it's a

00:25:05,130 --> 00:25:09,420
little weird concept so I'll give you an

00:25:06,540 --> 00:25:11,790
example example four liters if you vary

00:25:09,420 --> 00:25:14,460
some some look for the term tourism in

00:25:11,790 --> 00:25:16,680
India PD pages you will find the word

00:25:14,460 --> 00:25:20,910
tourism on nearly every page that is

00:25:16,680 --> 00:25:23,730
about a country nearly every page okay

00:25:20,910 --> 00:25:25,470
but these these pages are not actually

00:25:23,730 --> 00:25:26,820
about tourism right there is a pages

00:25:25,470 --> 00:25:28,500
that are dedicated to tourism like

00:25:26,820 --> 00:25:30,090
there's a page for ecotourism or there's

00:25:28,500 --> 00:25:31,290
a page for doctor is omit these are

00:25:30,090 --> 00:25:33,120
actually about tourism the others are

00:25:31,290 --> 00:25:35,280
not so just because it occurs that

00:25:33,120 --> 00:25:37,290
doesn't mean it's actually the document

00:25:35,280 --> 00:25:39,540
is about this particular term this might

00:25:37,290 --> 00:25:42,480
be something that is important for a

00:25:39,540 --> 00:25:44,070
scoring so the questions can we can we

00:25:42,480 --> 00:25:45,540
use a prior knowledge on the

00:25:44,070 --> 00:25:47,960
distribution of term frequency and

00:25:45,540 --> 00:25:50,970
delete this to get an even better result

00:25:47,960 --> 00:25:53,430
okay and the idea the basic idea is we

00:25:50,970 --> 00:25:55,680
have two cases we say a document is not

00:25:53,430 --> 00:25:58,470
about what is described by the term and

00:25:55,680 --> 00:26:00,090
I way we would probably assume that the

00:25:58,470 --> 00:26:02,360
term frequencies are distributed as such

00:26:00,090 --> 00:26:05,340
so the probability that this document

00:26:02,360 --> 00:26:07,260
for to observe this term frequency in a

00:26:05,340 --> 00:26:09,210
document that not actually is about that

00:26:07,260 --> 00:26:12,090
term would be higher than that the term

00:26:09,210 --> 00:26:13,770
frequency is higher right and then if

00:26:12,090 --> 00:26:17,790
the document actually is about the term

00:26:13,770 --> 00:26:19,110
we would usually assume that well the

00:26:17,790 --> 00:26:21,480
probability that we observe a higher

00:26:19,110 --> 00:26:23,700
term frequency is also higher if the

00:26:21,480 --> 00:26:24,930
document is about that term note that

00:26:23,700 --> 00:26:26,790
this might not always be the case right

00:26:24,930 --> 00:26:28,980
this red line might also be here right

00:26:26,790 --> 00:26:32,310
or somewhere else but this is the this

00:26:28,980 --> 00:26:33,960
is the basic assumption okay so we need

00:26:32,310 --> 00:26:35,670
to get this distribution once for the

00:26:33,960 --> 00:26:37,020
documents that are not about the term

00:26:35,670 --> 00:26:39,540
and once for those that are about the

00:26:37,020 --> 00:26:40,980
term it so we need in many documents and

00:26:39,540 --> 00:26:44,580
have different term frequencies and

00:26:40,980 --> 00:26:45,900
we'll see in a minute what we do so we

00:26:44,580 --> 00:26:47,340
need a different documents with

00:26:45,900 --> 00:26:48,630
different term frequencies and again as

00:26:47,340 --> 00:26:50,070
our intern or

00:26:48,630 --> 00:26:52,560
here's this document here is this term

00:26:50,070 --> 00:26:54,840
is this term actually elite to this

00:26:52,560 --> 00:26:56,340
document okay okay then our intents will

00:26:54,840 --> 00:26:58,050
go ahead all right

00:26:56,340 --> 00:26:59,400
hopefully they say yeah it's elite or

00:26:58,050 --> 00:27:01,140
it's not elite but we need many more

00:26:59,400 --> 00:27:02,550
right many more because we need all

00:27:01,140 --> 00:27:05,790
these different frequencies - hello -

00:27:02,550 --> 00:27:08,970
okay so we need more inference click all

00:27:05,790 --> 00:27:11,610
date do that so they may get a notion of

00:27:08,970 --> 00:27:14,010
a lightness but then a question is a

00:27:11,610 --> 00:27:16,260
case that we know it's elite but we do

00:27:14,010 --> 00:27:17,970
not know yet is it relevant or is it not

00:27:16,260 --> 00:27:20,310
it's the document relevant or not to our

00:27:17,970 --> 00:27:23,000
query right so we need another

00:27:20,310 --> 00:27:26,970
relationship of elite nurse and

00:27:23,000 --> 00:27:28,740
relevancy okay and here so it's right

00:27:26,970 --> 00:27:31,140
these curves here how does the title

00:27:28,740 --> 00:27:32,430
relevancy I won't get into here is we

00:27:31,140 --> 00:27:35,010
could do the same trick that we did

00:27:32,430 --> 00:27:37,650
before right you can say okay we have

00:27:35,010 --> 00:27:39,180
another distribution with the

00:27:37,650 --> 00:27:40,620
probability of elite nurse given

00:27:39,180 --> 00:27:42,000
relevancy and if we know the elite nurse

00:27:40,620 --> 00:27:43,320
already and can tie this other

00:27:42,000 --> 00:27:45,120
distribution into that maybe we get

00:27:43,320 --> 00:27:46,850
something better out of it and here I'm

00:27:45,120 --> 00:27:49,200
growing a little faster because yeah

00:27:46,850 --> 00:27:50,880
that have that much time but we would do

00:27:49,200 --> 00:27:51,930
the same trick as before we try to get

00:27:50,880 --> 00:27:53,760
our sets because this is a binary

00:27:51,930 --> 00:27:56,700
variable it's a binary thing so we can

00:27:53,760 --> 00:27:58,200
just take these sets again compute a

00:27:56,700 --> 00:28:00,720
have elite documents have relevant

00:27:58,200 --> 00:28:02,340
documents have elite documents that are

00:28:00,720 --> 00:28:04,650
relevant on some that are neither and

00:28:02,340 --> 00:28:07,530
then try from that to estimate estimate

00:28:04,650 --> 00:28:09,300
this probability okay but it means we

00:28:07,530 --> 00:28:13,050
need to set okay so we need even more

00:28:09,300 --> 00:28:14,340
interns okay but suppose we had that

00:28:13,050 --> 00:28:15,870
again we're mathematicians and bear with

00:28:14,340 --> 00:28:17,070
me just one more minute right so we're

00:28:15,870 --> 00:28:18,870
mathematicians we don't care okay we

00:28:17,070 --> 00:28:20,340
have all that we can get as many interns

00:28:18,870 --> 00:28:21,900
as we want so we can get this

00:28:20,340 --> 00:28:23,160
distribution of the term frequency given

00:28:21,900 --> 00:28:24,900
the elite nurse we can get the

00:28:23,160 --> 00:28:26,970
probability of elite as given relevancy

00:28:24,900 --> 00:28:29,070
right we can try to combine this two

00:28:26,970 --> 00:28:30,200
into a probability of frequency given

00:28:29,070 --> 00:28:32,040
elite this and this is really what

00:28:30,200 --> 00:28:34,110
relevancy and this is really what's the

00:28:32,040 --> 00:28:36,000
one what we want yeah plug this in here

00:28:34,110 --> 00:28:39,690
and then hopefully get something that we

00:28:36,000 --> 00:28:41,100
can use in practice okay and again here

00:28:39,690 --> 00:28:42,360
do math I'm not going to show you that's

00:28:41,100 --> 00:28:48,510
not so much that happens there to be

00:28:42,360 --> 00:28:50,610
honest so here we met and we get to so

00:28:48,510 --> 00:28:54,240
okay something that is actually too long

00:28:50,610 --> 00:28:56,160
to fit on the slide it doesn't really

00:28:54,240 --> 00:28:57,690
help so all the math all the result of

00:28:56,160 --> 00:28:59,730
other people doesn't really help we get

00:28:57,690 --> 00:29:01,320
something that is pretty nasty and then

00:28:59,730 --> 00:29:02,250
this paper that I cited before this all

00:29:01,320 --> 00:29:04,380
described in there

00:29:02,250 --> 00:29:06,450
you can take a look and it just quote

00:29:04,380 --> 00:29:09,150
from that that the result is a somewhat

00:29:06,450 --> 00:29:10,470
messy formula and furthermore we do not

00:29:09,150 --> 00:29:13,140
generally know the values of the

00:29:10,470 --> 00:29:14,669
parameters or have an easy way to

00:29:13,140 --> 00:29:18,480
estimate them because we don't have all

00:29:14,669 --> 00:29:20,010
these interns and that's a bummer

00:29:18,480 --> 00:29:24,000
and I think it was also a bummer for the

00:29:20,010 --> 00:29:27,630
office I guess of pier 35 and to me I

00:29:24,000 --> 00:29:30,240
think I think the major achievement of

00:29:27,630 --> 00:29:34,169
the authors of beyond 25 at this point

00:29:30,240 --> 00:29:36,419
was not just to give up and say hey okay

00:29:34,169 --> 00:29:38,640
we reach the dead and there is nothing

00:29:36,419 --> 00:29:40,950
we can do but to still cling on to that

00:29:38,640 --> 00:29:41,610
and make something out of that okay so

00:29:40,950 --> 00:29:43,890
what did they do

00:29:41,610 --> 00:29:46,230
I found a video on YouTube where guy

00:29:43,890 --> 00:29:51,059
described said he says they took a leap

00:29:46,230 --> 00:29:56,130
of faith okay so what is this leap of

00:29:51,059 --> 00:29:58,320
faith L they say well okay so we cannot

00:29:56,130 --> 00:30:01,880
really get out the proper shape of this

00:29:58,320 --> 00:30:04,770
this monster which I didn't show you but

00:30:01,880 --> 00:30:06,450
we can still have some user Mouse and

00:30:04,770 --> 00:30:08,010
get some description out of that so for

00:30:06,450 --> 00:30:09,690
example we know that this curve would

00:30:08,010 --> 00:30:11,909
start at 0 we know it would increase

00:30:09,690 --> 00:30:13,770
monotonically we know what it would

00:30:11,909 --> 00:30:15,929
approach a maximum at some point and

00:30:13,770 --> 00:30:17,400
then not any further and the maximum

00:30:15,929 --> 00:30:20,640
would be the inverse document frequency

00:30:17,400 --> 00:30:22,740
that we computed before which is nice

00:30:20,640 --> 00:30:24,809
okay so they said hey we just use

00:30:22,740 --> 00:30:28,500
something similar even though we don't

00:30:24,809 --> 00:30:30,179
know what it is and so what they came up

00:30:28,500 --> 00:30:32,220
with was called the term frequency

00:30:30,179 --> 00:30:33,960
saturation curve and that basically

00:30:32,220 --> 00:30:35,730
looks like this I take the TRO frequency

00:30:33,960 --> 00:30:37,470
but you don't just sum them up or some

00:30:35,730 --> 00:30:39,690
the square root up but you divided by

00:30:37,470 --> 00:30:42,120
the term frequency plus some parameter

00:30:39,690 --> 00:30:45,360
and as you can see as term frequency

00:30:42,120 --> 00:30:50,150
grows this whole term will approach 1

00:30:45,360 --> 00:30:52,710
right I'm speaking as quick as I can

00:30:50,150 --> 00:30:54,539
okay and this is here multiplied by the

00:30:52,710 --> 00:30:56,370
IDF so this parameter here you can

00:30:54,539 --> 00:31:00,179
choose it freely I think the default is

00:30:56,370 --> 00:31:01,950
2 right now somebody came and so if you

00:31:00,179 --> 00:31:05,340
have if I have a higher K it'll approach

00:31:01,950 --> 00:31:07,770
the slower if you have a smaller K it'll

00:31:05,340 --> 00:31:09,990
approach it quicker okay and this is the

00:31:07,770 --> 00:31:12,870
so this is the basic difference also to

00:31:09,990 --> 00:31:14,010
to tf-idf because in tf-idf the square

00:31:12,870 --> 00:31:14,920
root of the term frequency then we'll

00:31:14,010 --> 00:31:20,950
just grow

00:31:14,920 --> 00:31:22,870
infinitely right okay so we are here

00:31:20,950 --> 00:31:26,190
this is the part the last part of the

00:31:22,870 --> 00:31:27,370
this is a saturation curve of being 25

00:31:26,190 --> 00:31:28,990
okay

00:31:27,370 --> 00:31:31,630
and now finally and then I'm gonna cover

00:31:28,990 --> 00:31:33,550
this a little more quicker um so one

00:31:31,630 --> 00:31:34,600
thing that that it was not really

00:31:33,550 --> 00:31:35,920
mentioning when I talked about the

00:31:34,600 --> 00:31:38,080
Poisson distribution is we sort of

00:31:35,920 --> 00:31:39,700
assumed that all documents have the same

00:31:38,080 --> 00:31:42,010
length okay and this is something that

00:31:39,700 --> 00:31:43,630
also doesn't work for a b25 we have to

00:31:42,010 --> 00:31:45,760
somehow take the lengths into account

00:31:43,630 --> 00:31:49,480
and the way they did it is they say okay

00:31:45,760 --> 00:31:52,060
the interpolate between one and the

00:31:49,480 --> 00:31:53,920
darker than the the average document

00:31:52,060 --> 00:31:56,890
length and have this effector to this

00:31:53,920 --> 00:31:59,980
Kay okay so this is an interpolation of

00:31:56,890 --> 00:32:01,990
one and the average document length and

00:31:59,980 --> 00:32:03,490
this is important later on they did take

00:32:01,990 --> 00:32:04,960
the average document lengths and not

00:32:03,490 --> 00:32:06,520
just lengths or the square root of the

00:32:04,960 --> 00:32:07,930
lengths or something like that this is

00:32:06,520 --> 00:32:10,210
something relevant if to what you

00:32:07,930 --> 00:32:12,400
encounter in your corpus and just to

00:32:10,210 --> 00:32:15,100
give you an idea what that does now this

00:32:12,400 --> 00:32:16,390
is here's the document length right and

00:32:15,100 --> 00:32:18,430
here's a score that would be computed

00:32:16,390 --> 00:32:20,590
for different parameters again B is a

00:32:18,430 --> 00:32:24,430
parameter if you choose B to be very

00:32:20,590 --> 00:32:26,200
small it will have little influence on

00:32:24,430 --> 00:32:27,580
the on the score or little influence on

00:32:26,200 --> 00:32:29,230
the difference of the score if you

00:32:27,580 --> 00:32:30,790
choose B to be a little bigger it'll

00:32:29,230 --> 00:32:34,090
have more influence that this would be

00:32:30,790 --> 00:32:37,060
this this black curve here again this is

00:32:34,090 --> 00:32:38,560
different to two tf-idf where while you

00:32:37,060 --> 00:32:40,030
still have some decrease but you don't

00:32:38,560 --> 00:32:43,410
have the flexibility to actually choose

00:32:40,030 --> 00:32:49,930
how much influence the legs actually has

00:32:43,410 --> 00:32:53,110
okay so we're done this is a V and 55

00:32:49,930 --> 00:32:54,790
and this is all the parameters and let

00:32:53,110 --> 00:32:56,860
you see so we have the IDF how popular

00:32:54,790 --> 00:32:58,540
is the term in the corpus limit the

00:32:56,860 --> 00:33:03,460
influence of the term frequency and then

00:32:58,540 --> 00:33:05,650
also the lengths waiting okay so and so

00:33:03,460 --> 00:33:08,740
finally question is B m25 probabilistic

00:33:05,650 --> 00:33:09,880
I mean I showed you not all of the

00:33:08,740 --> 00:33:13,810
approximations but some of the

00:33:09,880 --> 00:33:15,670
approximations and as I said the it is

00:33:13,810 --> 00:33:19,810
originally probabilistic but since it's

00:33:15,670 --> 00:33:21,640
impossible to get the only possible to

00:33:19,810 --> 00:33:24,430
get a probability right with unlimited

00:33:21,640 --> 00:33:26,800
data I would say no it's not really it's

00:33:24,430 --> 00:33:28,630
inspired by probabilistic ranking this

00:33:26,800 --> 00:33:31,750
is also from this YouTube video

00:33:28,630 --> 00:33:33,580
and I would totally agree okay I shot

00:33:31,750 --> 00:33:35,500
history just to give you an idea what

00:33:33,580 --> 00:33:38,020
time frame were talking about it started

00:33:35,500 --> 00:33:40,240
about 1975 when they had this Robertson

00:33:38,020 --> 00:33:42,040
Spike Jonze wait and probably

00:33:40,240 --> 00:33:43,540
probability ranking principle and all

00:33:42,040 --> 00:33:47,860
this Poisson distribution that's what it

00:33:43,540 --> 00:33:49,990
means here and and it took until 1994

00:33:47,860 --> 00:33:52,150
until the final beyond 25 was actually

00:33:49,990 --> 00:33:54,100
published right and after that was the

00:33:52,150 --> 00:33:57,940
first to see in release but then still

00:33:54,100 --> 00:34:00,940
took tf-idf and then only in 2011 David

00:33:57,940 --> 00:34:02,380
named esky and it's a guy who

00:34:00,940 --> 00:34:04,500
participated in a google Summer of Code

00:34:02,380 --> 00:34:07,000
together with Robert Moore actually made

00:34:04,500 --> 00:34:09,130
similarities in lucien pluggable and

00:34:07,000 --> 00:34:12,160
also implemented beyond 25 and it took

00:34:09,130 --> 00:34:14,530
until now so 2016 till actually default

00:34:12,160 --> 00:34:16,800
was switched to beyond 25 right so just

00:34:14,530 --> 00:34:19,660
to give you an idea how long it took

00:34:16,800 --> 00:34:24,340
okay so well I got about scoring and

00:34:19,660 --> 00:34:25,810
p.m. 25 now it gets tricky there is some

00:34:24,340 --> 00:34:28,150
there's some pros and there's not pros

00:34:25,810 --> 00:34:31,990
with beyond 25 so one is this frequency

00:34:28,150 --> 00:34:34,750
cutoff I so tf-idf common words

00:34:31,990 --> 00:34:36,460
influence the score much more than they

00:34:34,750 --> 00:34:38,260
would possibly be and 25 right so

00:34:36,460 --> 00:34:41,440
because beyond 25 naturally limits it

00:34:38,260 --> 00:34:42,850
limits the influence okay it also means

00:34:41,440 --> 00:34:44,530
that we don't need this court factor

00:34:42,850 --> 00:34:46,510
hack anymore if you remember the example

00:34:44,530 --> 00:34:48,640
with China and the blog post about

00:34:46,510 --> 00:34:50,770
citron and in purpose and this other

00:34:48,640 --> 00:34:52,930
Oracle so attract you could actually

00:34:50,770 --> 00:34:53,800
switch it off if you're if you're using

00:34:52,930 --> 00:34:55,930
elasticsearch

00:34:53,800 --> 00:34:58,240
you can switch it off by index similar

00:34:55,930 --> 00:35:03,120
if you don't default or type p.m. 25 and

00:34:58,240 --> 00:35:05,260
then it'll not be used anymore okay so

00:35:03,120 --> 00:35:07,180
other benefits of no I'm not sure I

00:35:05,260 --> 00:35:09,190
should advertise that too much as you

00:35:07,180 --> 00:35:11,020
can potentially tweak the parameters all

00:35:09,190 --> 00:35:12,670
that's tedious and I'm not sure if it's

00:35:11,020 --> 00:35:13,990
really worth it

00:35:12,670 --> 00:35:15,310
but you can if you want if you're using

00:35:13,990 --> 00:35:16,990
elasticsearch you close your index

00:35:15,310 --> 00:35:19,180
update your mappings and then reopen the

00:35:16,990 --> 00:35:22,390
index and then it'll use different

00:35:19,180 --> 00:35:23,710
parameters the thing that's more

00:35:22,390 --> 00:35:25,090
interesting is that this whole paper

00:35:23,710 --> 00:35:26,800
actually describes a mathematical

00:35:25,090 --> 00:35:28,810
framework to build non textual features

00:35:26,800 --> 00:35:31,630
into your scoring so if you're looking

00:35:28,810 --> 00:35:33,520
into adding additional signals to your

00:35:31,630 --> 00:35:35,200
score as might be worth looking at the

00:35:33,520 --> 00:35:39,810
details there they have a dedicated

00:35:35,200 --> 00:35:39,810
chapter for that okay one warning

00:35:39,970 --> 00:35:43,690
tf-idf has an automatic boost for short

00:35:41,830 --> 00:35:45,010
field so for title fields for example if

00:35:43,690 --> 00:35:46,810
you're using title fields right now and

00:35:45,010 --> 00:35:49,150
rely on this automatic boost it will not

00:35:46,810 --> 00:35:51,280
work as well or not work as well well

00:35:49,150 --> 00:35:52,960
we're different with BM 25 because BM 25

00:35:51,280 --> 00:35:54,940
takes the average documents length into

00:35:52,960 --> 00:35:56,140
account and adjusts accordingly

00:35:54,940 --> 00:36:00,990
okay so it's just a little bit of

00:35:56,140 --> 00:36:04,800
warming okay and I was it better finally

00:36:00,990 --> 00:36:06,940
literacy says yes challenger said yes

00:36:04,800 --> 00:36:10,300
users some users say so

00:36:06,940 --> 00:36:11,920
Lusine developers say so a guy works at

00:36:10,300 --> 00:36:14,619
elastic had a blog post about it had to

00:36:11,920 --> 00:36:18,340
fill in it was so but actually we don't

00:36:14,619 --> 00:36:19,720
know making an educated guess here so it

00:36:18,340 --> 00:36:21,970
depends on the features of your corpus

00:36:19,720 --> 00:36:23,500
and it defines and depends on how your

00:36:21,970 --> 00:36:26,230
queries look like we believe it will be

00:36:23,500 --> 00:36:28,210
better but yeah you'll have to try it

00:36:26,230 --> 00:36:29,530
out and you can try it out right now if

00:36:28,210 --> 00:36:30,700
you losing elasticsearch you can

00:36:29,530 --> 00:36:33,760
actually try it out by closing your

00:36:30,700 --> 00:36:35,320
index updating the similarity

00:36:33,760 --> 00:36:39,099
accordingly opening it again and then

00:36:35,320 --> 00:36:41,530
see what happens okay and then here is

00:36:39,099 --> 00:36:46,210
some useful literature if you want to

00:36:41,530 --> 00:36:48,690
read that stuff up okay and that's the

00:36:46,210 --> 00:36:48,690
end of my talk

00:36:58,110 --> 00:37:01,230
thank you

00:37:07,110 --> 00:37:17,250
too much thanks a lot

00:37:13,750 --> 00:37:17,250

YouTube URL: https://www.youtube.com/watch?v=v3Ko0CwgTZ0


