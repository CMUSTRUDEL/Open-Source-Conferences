Title: Berlin Buzzwords 2017: Steve Loughran - What does rename() do? #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	We software developers take for granted the notion of  "a filesystem", with its paths, directories, files and operations. Yet when it comes to distributed filesystems, those notions built from years of using desktop systems actually constraining us to a metaphor which is no longer sustainable

This talk looks at our foundational preconceptions from the perspective of trying to define a single operation in Hadoop HDFS, rename(), what it takes to implement it in a distributed filesystem —and what has to be done to mimic that behaviour when working with an object store.

Preconceptions about rename()'s semantics are deeply embedded in large scale applications such as Apache MapReduce, Apache Hive, Apache Spark and the like, being the operation used to atomically commit work —and so do not work the way we think they do on Object Stores like Amazon S3.

We have to rethink our strategies for committing distributed work, with Hadoop's new "S3Guard committer" being the example of the world we have to move to. The time of renaming files is over.

Read more:
https://2017.berlinbuzzwords.de/17/session/what-does-rename-do

About Steve Loughran:
https://2017.berlinbuzzwords.de/users/steve-loughran

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:07,190 --> 00:00:11,660
five ones

00:00:10,310 --> 00:00:12,860
also turning up even if it's because

00:00:11,660 --> 00:00:13,300
you've only accidentally turned up

00:00:12,860 --> 00:00:16,360
instead

00:00:13,300 --> 00:00:19,810
your thoughts next and I may talk about

00:00:16,360 --> 00:00:21,670
rename which sounds an odd topic but

00:00:19,810 --> 00:00:24,460
actually I'm talking about the whole

00:00:21,670 --> 00:00:26,320
problem of how do we persist in recover

00:00:24,460 --> 00:00:29,230
state in why do we persistent recover

00:00:26,320 --> 00:00:33,340
state an answer is we do that so we can

00:00:29,230 --> 00:00:34,900
get what our data back later this is how

00:00:33,340 --> 00:00:37,060
we used to save state we used to have a

00:00:34,900 --> 00:00:39,489
little dog boxes we used to there was an

00:00:37,060 --> 00:00:41,140
API designed for a single process nice

00:00:39,489 --> 00:00:42,430
and simple there Nick's nodding in

00:00:41,140 --> 00:00:44,829
familiarity because they still have

00:00:42,430 --> 00:00:47,649
these at home this is a 6502 bootloader

00:00:44,829 --> 00:00:49,449
by the way having moved all the hard

00:00:47,649 --> 00:00:51,820
disks finally we had gigabytes worth of

00:00:49,449 --> 00:00:54,789
data we had multiple users but multiple

00:00:51,820 --> 00:00:57,039
processes this is where POSIX came from

00:00:54,789 --> 00:00:58,989
POSIX is the one through API for storage

00:00:57,039 --> 00:01:02,679
we have files we have directories we

00:00:58,989 --> 00:01:04,360
have renamed and we can open files but a

00:01:02,679 --> 00:01:06,850
guarantee that they're not there before

00:01:04,360 --> 00:01:09,250
this is what most programs are built on

00:01:06,850 --> 00:01:12,040
the assumption are in a hard disk hands

00:01:09,250 --> 00:01:14,110
up who's got a hard disk that's really

00:01:12,040 --> 00:01:16,150
good hands up who's got a multiple

00:01:14,110 --> 00:01:18,000
exabyte data storage facility somewhere

00:01:16,150 --> 00:01:20,590
in a desert near a hydroelectric plant

00:01:18,000 --> 00:01:22,480
everybody using cloud storage has one of

00:01:20,590 --> 00:01:25,420
these hands up who's using s3 as your

00:01:22,480 --> 00:01:28,120
storage photos on facebook yeah that's

00:01:25,420 --> 00:01:30,670
exactly it so thing is we've moved on

00:01:28,120 --> 00:01:33,490
from floppy disks to buildings you have

00:01:30,670 --> 00:01:35,500
to drive around with a golf cart and yet

00:01:33,490 --> 00:01:39,030
we're still we still rely on things like

00:01:35,500 --> 00:01:39,030
rename to actually get our work done

00:01:39,660 --> 00:01:45,100
because we've evolved models and API in

00:01:42,970 --> 00:01:48,280
our brains and in our code to deal with

00:01:45,100 --> 00:01:50,770
data the most fun enough one of the core

00:01:48,280 --> 00:01:54,820
models is actually relational algebra or

00:01:50,770 --> 00:01:56,650
is it's known sequel it you use that

00:01:54,820 --> 00:01:58,480
it's somebody else's problem to deal

00:01:56,650 --> 00:02:00,070
with how things get stored you have to

00:01:58,480 --> 00:02:02,170
go back transactions in their isolation

00:02:00,070 --> 00:02:07,060
but generally it's somebody else's

00:02:02,170 --> 00:02:08,500
problem take a step down give into the

00:02:07,060 --> 00:02:10,509
world where I live in which is actually

00:02:08,500 --> 00:02:12,790
the layer underneath things like sequel

00:02:10,509 --> 00:02:14,500
and other stuff where we're we're still

00:02:12,790 --> 00:02:17,050
trying to maintain that metaphor now

00:02:14,500 --> 00:02:19,209
we've got a POSIX API similar ish our

00:02:17,050 --> 00:02:22,570
file systems we still have files and

00:02:19,209 --> 00:02:24,970
directories but now now we're working in

00:02:22,570 --> 00:02:26,650
those giant data centers the file

00:02:24,970 --> 00:02:29,170
systems are distributed

00:02:26,650 --> 00:02:31,810
would wear behind that single API the

00:02:29,170 --> 00:02:34,930
interface all the main form Hadoop stack

00:02:31,810 --> 00:02:37,989
applications work underneath we wrote it

00:02:34,930 --> 00:02:40,659
for HDFS but now we glue in all the

00:02:37,989 --> 00:02:42,730
object stores handler in the audience

00:02:40,659 --> 00:02:46,060
who is using any of those applications

00:02:42,730 --> 00:02:47,379
at the top keep your hands up if you're

00:02:46,060 --> 00:02:50,290
working with any cloud object stores

00:02:47,379 --> 00:02:56,680
from them okay two or three people up

00:02:50,290 --> 00:02:57,970
there now a core part of this in your

00:02:56,680 --> 00:03:00,430
code if you're using as a destination

00:02:57,970 --> 00:03:02,799
for this work is we absolutely rely on

00:03:00,430 --> 00:03:05,590
renamed as the way of committing our

00:03:02,799 --> 00:03:09,190
work you're doing any query in edit

00:03:05,590 --> 00:03:13,420
MapReduce spark whatever we copy the

00:03:09,190 --> 00:03:16,390
data but mr. slide actually we rename

00:03:13,420 --> 00:03:18,519
stuff we you write your data into a temp

00:03:16,390 --> 00:03:20,230
directory in your final destination you

00:03:18,519 --> 00:03:22,690
can have hundreds of thousands of tasks

00:03:20,230 --> 00:03:24,569
running you can have tasks speculating

00:03:22,690 --> 00:03:27,400
working on the same data simultaneously

00:03:24,569 --> 00:03:29,980
the first one that finishes sends a

00:03:27,400 --> 00:03:32,590
message to the job manager and says I'm

00:03:29,980 --> 00:03:36,430
done job manager if it's happy with it

00:03:32,590 --> 00:03:39,060
says ok you're ready to commit and we

00:03:36,430 --> 00:03:41,950
can use we can commit that and single

00:03:39,060 --> 00:03:43,660
transaction this works because rely on

00:03:41,950 --> 00:03:46,900
the fact that data we store in Hadoop

00:03:43,660 --> 00:03:48,549
HDFS all the data the terabytes where

00:03:46,900 --> 00:03:50,829
the data lives scattered across the

00:03:48,549 --> 00:03:52,720
cluster and data notes but we have a

00:03:50,829 --> 00:03:54,879
single metadata store the name node

00:03:52,720 --> 00:03:57,910
which actually stores our directories

00:03:54,879 --> 00:03:59,560
and trees the metadata so the commit

00:03:57,910 --> 00:04:01,569
operation only takes place in that

00:03:59,560 --> 00:04:02,260
single server we can lock a bit of the

00:04:01,569 --> 00:04:04,449
filesystem

00:04:02,260 --> 00:04:06,699
we can do a transaction we can save it

00:04:04,449 --> 00:04:10,000
it's essentially a database with

00:04:06,699 --> 00:04:15,400
database operations so nice and simple

00:04:10,000 --> 00:04:17,669
we do a rename in contrast Amazon s3

00:04:15,400 --> 00:04:21,010
we've put a lot of effort into making

00:04:17,669 --> 00:04:23,349
the object store look just like a file

00:04:21,010 --> 00:04:25,870
system to keep all those people writing

00:04:23,349 --> 00:04:28,389
the code above happy it looks like a

00:04:25,870 --> 00:04:30,580
file system except it's just one of

00:04:28,389 --> 00:04:33,460
those metaphors that if you push hard it

00:04:30,580 --> 00:04:36,400
will absolutely collapse on you here's a

00:04:33,460 --> 00:04:38,349
problem there is no matter data there is

00:04:36,400 --> 00:04:40,380
no name no there is just a model in your

00:04:38,349 --> 00:04:42,960
head of what you think is one

00:04:40,380 --> 00:04:44,730
on the API alone in reality your data

00:04:42,960 --> 00:04:47,700
gets stored over different shards and

00:04:44,730 --> 00:04:50,490
the location of your data the specific

00:04:47,700 --> 00:04:54,150
shard you use is determined by a hash on

00:04:50,490 --> 00:04:56,610
the file name alone that means you can't

00:04:54,150 --> 00:04:59,310
rename a file there is no file to rename

00:04:56,610 --> 00:05:00,480
their only blob and if you want to give

00:04:59,310 --> 00:05:02,190
it a different name you actually have to

00:05:00,480 --> 00:05:05,300
copy it from one machine to another

00:05:02,190 --> 00:05:07,980
which takes about six megabytes a second

00:05:05,300 --> 00:05:12,660
so to do a rename we pretend we're doing

00:05:07,980 --> 00:05:15,810
a rename we do a list we do an explicit

00:05:12,660 --> 00:05:18,740
copy of every single block of data and

00:05:15,810 --> 00:05:24,360
then finally we delete the old craft

00:05:18,740 --> 00:05:26,880
people using s3 as a destination for

00:05:24,360 --> 00:05:29,370
work in the MapReduce and especially

00:05:26,880 --> 00:05:31,770
SPARC these days they talk to us and

00:05:29,370 --> 00:05:33,390
they say hey your transactions are

00:05:31,770 --> 00:05:35,190
taking really low why is at the end of

00:05:33,390 --> 00:05:36,960
my process I've done all the work and my

00:05:35,190 --> 00:05:39,120
machine just sits there not doing

00:05:36,960 --> 00:05:40,740
anything for about 10 minutes it worked

00:05:39,120 --> 00:05:43,470
really well in development and the

00:05:40,740 --> 00:05:45,480
answer is is because that coffee

00:05:43,470 --> 00:05:48,240
operations is Primus portion to your

00:05:45,480 --> 00:05:49,740
data size but the thing you have to

00:05:48,240 --> 00:05:51,350
worry about is not the time it takes to

00:05:49,740 --> 00:05:53,760
commit if they don't lift up above

00:05:51,350 --> 00:05:56,940
because the list to work we have to have

00:05:53,760 --> 00:06:00,300
a consistent way of listing all the data

00:05:56,940 --> 00:06:02,850
in the object store and Amazon s3 does

00:06:00,300 --> 00:06:05,970
not list data reliably so you may

00:06:02,850 --> 00:06:09,240
actually miss the output of a single

00:06:05,970 --> 00:06:11,850
task one or two files we do the copy we

00:06:09,240 --> 00:06:13,830
delete everything and your code can keep

00:06:11,850 --> 00:06:15,390
going happily not realizing that

00:06:13,830 --> 00:06:18,180
actually you've generated corrupt data

00:06:15,390 --> 00:06:19,770
and it can take a while to propagate the

00:06:18,180 --> 00:06:21,540
worst thing is everything appears to

00:06:19,770 --> 00:06:22,920
work really well during development only

00:06:21,540 --> 00:06:25,020
when you go into production it goes

00:06:22,920 --> 00:06:27,090
wrong mostly when there's only

00:06:25,020 --> 00:06:30,510
intermittent misbehaviors on s3 that it

00:06:27,090 --> 00:06:32,490
really becomes visible so that's a

00:06:30,510 --> 00:06:35,010
problem another problem in fixing and

00:06:32,490 --> 00:06:37,950
the way to do it is we throw out all our

00:06:35,010 --> 00:06:39,870
assumptions about data about storage

00:06:37,950 --> 00:06:41,580
about files and say this is an object

00:06:39,870 --> 00:06:44,430
store let's embrace that fact

00:06:41,580 --> 00:06:47,970
let's stop hiding from it and pretending

00:06:44,430 --> 00:06:50,039
that it's actually a filesystem let's go

00:06:47,970 --> 00:06:51,749
with what Amazon office

00:06:50,039 --> 00:06:53,809
and the secret is here actually is they

00:06:51,749 --> 00:06:57,089
use something called multi-part uploads

00:06:53,809 --> 00:06:59,219
where we can write data to a single

00:06:57,089 --> 00:07:01,589
address we can start extend an operation

00:06:59,219 --> 00:07:03,599
which is effectively transacted to say I

00:07:01,589 --> 00:07:05,789
want to write my data to the object

00:07:03,599 --> 00:07:08,219
store you get a URL back and then can do

00:07:05,789 --> 00:07:10,830
repeated post to that file but it

00:07:08,219 --> 00:07:13,589
doesn't come into existence until issue

00:07:10,830 --> 00:07:15,899
the final post saying create the object

00:07:13,589 --> 00:07:18,509
here is the order D tag list of main

00:07:15,899 --> 00:07:21,119
division uploads we've been using this

00:07:18,509 --> 00:07:25,199
for a long time in the output of when

00:07:21,119 --> 00:07:28,110
you're writing stuff to s3 by the Hadoop

00:07:25,199 --> 00:07:29,729
F 3 F 3 NS create lines but we've just

00:07:28,110 --> 00:07:31,800
been doing on the same process so you

00:07:29,729 --> 00:07:34,050
write your stream you close it using a

00:07:31,800 --> 00:07:35,610
POSIX API nice and always well but it

00:07:34,050 --> 00:07:38,069
turns out we can be more devious about

00:07:35,610 --> 00:07:40,289
that we can upload the individual blocks

00:07:38,069 --> 00:07:43,169
for mumping individual process as we go

00:07:40,289 --> 00:07:45,930
along but we can commit the data on a

00:07:43,169 --> 00:07:47,759
different machine or even abort it so we

00:07:45,930 --> 00:07:50,819
change the transaction operation not

00:07:47,759 --> 00:07:52,830
from a rename to commit but more the job

00:07:50,819 --> 00:07:54,779
manager decides whether to actually post

00:07:52,830 --> 00:07:57,569
the completion operation of those rights

00:07:54,779 --> 00:07:59,189
so put the stuff up there once we're

00:07:57,569 --> 00:08:04,259
actually happy with it the task can

00:07:59,189 --> 00:08:05,969
communicate and we can decide there and

00:08:04,259 --> 00:08:08,189
then whether to upgrade this stuff or

00:08:05,969 --> 00:08:09,870
not so we got the two pending uploads we

00:08:08,189 --> 00:08:11,459
do a list that requires consistency

00:08:09,870 --> 00:08:14,309
separate problem I'll ignore that one

00:08:11,459 --> 00:08:16,499
and we just do a post so that we're

00:08:14,309 --> 00:08:20,699
using the transactions built into the

00:08:16,499 --> 00:08:22,620
object store so we can get away with all

00:08:20,699 --> 00:08:23,759
this stuff working friends actively I'm

00:08:22,620 --> 00:08:25,349
actually going to give a demo of this

00:08:23,759 --> 00:08:28,439
I'm get it working actually this is my

00:08:25,349 --> 00:08:30,330
smart unit test not particularly

00:08:28,439 --> 00:08:34,229
exciting but we can actually simulate

00:08:30,330 --> 00:08:36,120
the two different commits operations and

00:08:34,229 --> 00:08:38,130
we have a special mode now in the s3

00:08:36,120 --> 00:08:41,250
client will return inconsistency on we

00:08:38,130 --> 00:08:42,269
can add a lag on deletion this wouldn't

00:08:41,250 --> 00:08:45,990
take a while because we're over slow

00:08:42,269 --> 00:08:47,670
Network I'll go back to talking so if

00:08:45,990 --> 00:08:49,230
you actually turn the inconsistency on

00:08:47,670 --> 00:08:50,970
then everything dramatically breaks

00:08:49,230 --> 00:08:53,190
every time and we can show that the fall

00:08:50,970 --> 00:08:56,370
out commits us the normal one is both

00:08:53,190 --> 00:08:59,339
slow and in the presence of

00:08:56,370 --> 00:09:00,930
inconsistency leads to corrupt data so

00:08:59,339 --> 00:09:02,430
we have to get rid of it and that's what

00:09:00,930 --> 00:09:03,310
I've done basically this code down

00:09:02,430 --> 00:09:05,380
exists you can

00:09:03,310 --> 00:09:08,680
download it we're going to feed it back

00:09:05,380 --> 00:09:10,240
into the dupes read before long for

00:09:08,680 --> 00:09:11,710
coming out later in the year and then

00:09:10,240 --> 00:09:15,640
you'll be able to use it from a dig Map

00:09:11,710 --> 00:09:24,400
Reduce and spark this is code finish yep

00:09:15,640 --> 00:09:26,650
no still going on this one so step one

00:09:24,400 --> 00:09:28,980
we change how we commit data we're

00:09:26,650 --> 00:09:32,020
affecting the first big corruption from

00:09:28,980 --> 00:09:33,520
but there's a lot more in that POSIX

00:09:32,020 --> 00:09:36,850
world that we have to look at and say is

00:09:33,520 --> 00:09:38,320
it dead is it obsolete how would we do

00:09:36,850 --> 00:09:40,390
it differently given me assuming an

00:09:38,320 --> 00:09:42,220
object's daughter and the key one is

00:09:40,390 --> 00:09:45,070
this whole notion of I'm going to open a

00:09:42,220 --> 00:09:47,110
stream of data and read it by seeking

00:09:45,070 --> 00:09:49,930
sporadically it's probably the one we

00:09:47,110 --> 00:09:51,820
got to look at the same dead for things

00:09:49,930 --> 00:09:54,730
like HTTP request especially looking

00:09:51,820 --> 00:09:58,990
HTTP - coming along we actually want to

00:09:54,730 --> 00:10:01,360
issue over leaves no bulk requests of

00:09:58,990 --> 00:10:02,710
byte arrays saying here are three here

00:10:01,360 --> 00:10:05,740
are three different offsets within this

00:10:02,710 --> 00:10:08,470
very large multi-gigabyte object let me

00:10:05,740 --> 00:10:11,320
do get from them overnight because right

00:10:08,470 --> 00:10:14,980
now you read an input string your

00:10:11,320 --> 00:10:17,920
process goes okay give me the data from

00:10:14,980 --> 00:10:20,020
offset 10k 200 kilobytes of it we do

00:10:17,920 --> 00:10:23,260
that read then immediately the client

00:10:20,020 --> 00:10:26,290
says oh I want this extra data here and

00:10:23,260 --> 00:10:27,670
when so the filesystem we have no idea

00:10:26,290 --> 00:10:29,800
what's actually going to be needed next

00:10:27,670 --> 00:10:31,540
your program does especially for

00:10:29,800 --> 00:10:34,540
actually using a column data format like

00:10:31,540 --> 00:10:37,089
or campaka in those exactly in advance

00:10:34,540 --> 00:10:39,250
what it's going to be skipping so can we

00:10:37,089 --> 00:10:43,120
actually move the api's on to doing this

00:10:39,250 --> 00:10:45,850
world or turns even look at it what ap

00:10:43,120 --> 00:10:47,680
is can we implement in the file systems

00:10:45,850 --> 00:10:49,060
and the object stores that application

00:10:47,680 --> 00:10:50,530
users are actually going to take up on

00:10:49,060 --> 00:10:52,780
because I could write they put the

00:10:50,530 --> 00:10:53,770
effort in write this stuff and if it

00:10:52,780 --> 00:10:56,860
doesn't get used it's just kind of

00:10:53,770 --> 00:10:58,150
wasted so anybody work in this layer get

00:10:56,860 --> 00:11:02,200
in touch and we'll think about what to

00:10:58,150 --> 00:11:04,540
do now did that finish yeah I've got two

00:11:02,200 --> 00:11:06,400
tests doing a commit first the new one

00:11:04,540 --> 00:11:09,100
nice and happy takes a while give the

00:11:06,400 --> 00:11:10,930
Diagnostics times everything dealing on

00:11:09,100 --> 00:11:13,330
big long random pause and it's sales

00:11:10,930 --> 00:11:15,010
because there was no data there and that

00:11:13,330 --> 00:11:16,120
this is this is the default state right

00:11:15,010 --> 00:11:17,220
now you'll get you're working in this

00:11:16,120 --> 00:11:19,500
really fear failure

00:11:17,220 --> 00:11:20,670
because your code won't have assertions

00:11:19,500 --> 00:11:22,770
about the number of files I get

00:11:20,670 --> 00:11:24,720
generated you'll just say run the query

00:11:22,770 --> 00:11:26,460
query returns orders well except there

00:11:24,720 --> 00:11:28,440
is no data there later on or you're

00:11:26,460 --> 00:11:31,020
missing you're missing a couple of parts

00:11:28,440 --> 00:11:34,470
of your data and that's why right now I

00:11:31,020 --> 00:11:37,980
would not recommend anyone using s3 as a

00:11:34,470 --> 00:11:41,340
destination of work to from a duplex

00:11:37,980 --> 00:11:44,610
does anyone do that in the room from if

00:11:41,340 --> 00:11:46,350
you keep your hands down now so it's

00:11:44,610 --> 00:11:49,530
really dangerous it looks nice but it's

00:11:46,350 --> 00:11:50,970
really dangerous so stop it we will have

00:11:49,530 --> 00:11:52,260
a fix right now coming out late in a

00:11:50,970 --> 00:11:54,450
year if you really in a rush to do it

00:11:52,260 --> 00:11:56,580
now a big chunk of the code I'm using on

00:11:54,450 --> 00:11:59,520
is actually based on something from

00:11:56,580 --> 00:12:01,050
Netflix okay so you go to Netflix code

00:11:59,520 --> 00:12:03,690
repository and you can pick up what

00:12:01,050 --> 00:12:06,330
we've been using so we need to rethink

00:12:03,690 --> 00:12:10,440
when you look at POSIX and say is POSIX

00:12:06,330 --> 00:12:14,070
dead for the new fastest answer is maybe

00:12:10,440 --> 00:12:16,530
that the API can survive but the other

00:12:14,070 --> 00:12:18,690
thing is there is one more storage model

00:12:16,530 --> 00:12:21,270
coming and it's actually high speed

00:12:18,690 --> 00:12:22,680
non-volatile memory attached to the

00:12:21,270 --> 00:12:25,590
mainboard of your service of your

00:12:22,680 --> 00:12:27,570
laptops if there's less people like

00:12:25,590 --> 00:12:29,970
Intel working on you're getting FS B's

00:12:27,570 --> 00:12:32,580
that will go on cards right now you can

00:12:29,970 --> 00:12:33,720
slot in their generation of stuff

00:12:32,580 --> 00:12:36,090
they're promising is going to be even

00:12:33,720 --> 00:12:39,930
faster it's not going to be as fast as

00:12:36,090 --> 00:12:41,340
DRAM maybe 10 x hundred X slower but it

00:12:39,930 --> 00:12:43,140
will fit straight into main memory

00:12:41,340 --> 00:12:47,130
you'll be able to address it for your

00:12:43,140 --> 00:12:49,200
program and when your program goes down

00:12:47,130 --> 00:12:51,660
and comes back up or your state will be

00:12:49,200 --> 00:12:53,460
there in a memory so you can even bypass

00:12:51,660 --> 00:12:58,110
the loading and saving face you can just

00:12:53,460 --> 00:13:00,990
map it straight in now again there is a

00:12:58,110 --> 00:13:02,580
POSIX API here I'm using C at this point

00:13:00,990 --> 00:13:04,770
as it's the language you can get at it

00:13:02,580 --> 00:13:07,350
where you can basically here's a file

00:13:04,770 --> 00:13:08,910
I'm going to map it straight into memory

00:13:07,350 --> 00:13:12,570
and then you can do pointer operations

00:13:08,910 --> 00:13:14,220
on it so I can define a C struct map it

00:13:12,570 --> 00:13:16,530
into memory work with it and then save

00:13:14,220 --> 00:13:20,250
it back that is what we have right now

00:13:16,530 --> 00:13:23,130
and it's there does anyone in the room

00:13:20,250 --> 00:13:25,490
you are usually doing this okay it does

00:13:23,130 --> 00:13:28,440
work today with POSIX but it works

00:13:25,490 --> 00:13:30,300
because we're in charge of when things

00:13:28,440 --> 00:13:30,450
get synchronized we really are writing

00:13:30,300 --> 00:13:33,270
it

00:13:30,450 --> 00:13:35,730
to a file system so I can do stuff like

00:13:33,270 --> 00:13:37,470
I can take a field in a record I can

00:13:35,730 --> 00:13:39,630
just add 5 to it it might be an atomic

00:13:37,470 --> 00:13:43,080
increment operation I could then copy

00:13:39,630 --> 00:13:44,730
that field 1 - field - again if it's a

00:13:43,080 --> 00:13:47,130
multi-threaded process I might need to

00:13:44,730 --> 00:13:48,180
put a lock on it so I can get away with

00:13:47,130 --> 00:13:51,750
it because I know we don't actually

00:13:48,180 --> 00:13:55,260
synchronize to the end if we're looking

00:13:51,750 --> 00:13:59,340
at non-volatile memory that's gone now

00:13:55,260 --> 00:14:02,340
each write operation to the file system

00:13:59,340 --> 00:14:04,260
to your memory is potentially write to

00:14:02,340 --> 00:14:07,350
the store so I increment that first

00:14:04,260 --> 00:14:09,750
operator final an current field 1 if

00:14:07,350 --> 00:14:13,170
your process clashes at that point your

00:14:09,750 --> 00:14:15,720
your struct may not be consistent I do a

00:14:13,170 --> 00:14:17,430
field copy still one field - yeah I've

00:14:15,720 --> 00:14:20,370
done it now my struct is now consistent

00:14:17,430 --> 00:14:23,280
my data is now correct but what happens

00:14:20,370 --> 00:14:25,650
if the CPU has only got that data in

00:14:23,280 --> 00:14:27,720
level one cache it's not been written

00:14:25,650 --> 00:14:29,490
back to the non-volatile memory yet so

00:14:27,720 --> 00:14:31,430
your code Gary's on thinking hey I've

00:14:29,490 --> 00:14:34,440
written my data structure aren't I happy

00:14:31,430 --> 00:14:35,970
but in fact it's not persisted your

00:14:34,440 --> 00:14:38,100
system crashes you come back up again

00:14:35,970 --> 00:14:41,610
you're in an unknown state so

00:14:38,100 --> 00:14:45,330
effectively we've moved the transaction

00:14:41,610 --> 00:14:46,920
problem away from the file system the

00:14:45,330 --> 00:14:48,990
opposite direction from the object store

00:14:46,920 --> 00:14:52,770
and now it's how we access data in

00:14:48,990 --> 00:14:54,780
memory I'm not working lining this there

00:14:52,770 --> 00:14:56,400
are people doing it an academic space

00:14:54,780 --> 00:14:58,680
already there's lots of papers you can

00:14:56,400 --> 00:15:01,500
read on it if you want the key point is

00:14:58,680 --> 00:15:04,200
nobody quite knows yet what is the best

00:15:01,500 --> 00:15:06,720
API a model to work with here it

00:15:04,200 --> 00:15:09,150
actually looks very similar the research

00:15:06,720 --> 00:15:11,250
stuff is about using things like log

00:15:09,150 --> 00:15:14,340
structured format since stuff log

00:15:11,250 --> 00:15:16,680
structure itself where I write new

00:15:14,340 --> 00:15:19,140
records I don't ever do overwrite fields

00:15:16,680 --> 00:15:21,780
in place I create new new obstruct new

00:15:19,140 --> 00:15:23,880
records then update references to it own

00:15:21,780 --> 00:15:25,770
by the way I can't use absolute pointers

00:15:23,880 --> 00:15:27,360
anymore because you've got to use offset

00:15:25,770 --> 00:15:28,950
references or something like that

00:15:27,360 --> 00:15:31,650
because of course memory addresses

00:15:28,950 --> 00:15:33,450
change so it's not going to be free in

00:15:31,650 --> 00:15:36,270
this well we have great opportunities

00:15:33,450 --> 00:15:38,400
for speed and performance but it's going

00:15:36,270 --> 00:15:40,980
to require us to rethink what our

00:15:38,400 --> 00:15:42,570
applications do we're going to rethink

00:15:40,980 --> 00:15:43,830
how we do transactions and maybe we're

00:15:42,570 --> 00:15:45,180
going to have to go back to see

00:15:43,830 --> 00:15:48,480
okay because it's the language of

00:15:45,180 --> 00:15:50,370
pointers and other languages on top I'm

00:15:48,480 --> 00:15:52,560
pointing at Java in particular are going

00:15:50,370 --> 00:15:54,060
to have to rethink how we model memory

00:15:52,560 --> 00:15:59,670
if you want to take advantage of this

00:15:54,060 --> 00:16:02,010
world so key point nouns storage moving

00:15:59,670 --> 00:16:02,880
in two ways we started off on a sloppy

00:16:02,010 --> 00:16:05,130
in the hard-disk

00:16:02,880 --> 00:16:08,820
one direction we're in two things the

00:16:05,130 --> 00:16:11,550
size of Facebook and POSIX I think we're

00:16:08,820 --> 00:16:13,890
hacking it the API is to make them look

00:16:11,550 --> 00:16:16,320
like POSIX out there but the metaphor is

00:16:13,890 --> 00:16:17,459
really starting to fall apart and we're

00:16:16,320 --> 00:16:20,070
going to need to do something there

00:16:17,459 --> 00:16:22,440
but the other direction against the hard

00:16:20,070 --> 00:16:23,970
disk has become an SSD the SSD is moving

00:16:22,440 --> 00:16:25,260
on to the mainboard the chip

00:16:23,970 --> 00:16:27,930
manufacturers are saying we're going to

00:16:25,260 --> 00:16:30,000
go from faster again POSIX

00:16:27,930 --> 00:16:31,860
POSIX doesn't fit into this world you

00:16:30,000 --> 00:16:33,779
can make it look like it does we've had

00:16:31,860 --> 00:16:36,420
RAM disk with a drama fest for a long

00:16:33,779 --> 00:16:39,029
time but to really really get to the

00:16:36,420 --> 00:16:41,459
benefits of this new world we're going

00:16:39,029 --> 00:16:44,730
to have to go back to pointer references

00:16:41,459 --> 00:16:47,100
and somehow get into the languages and

00:16:44,730 --> 00:16:50,850
the API is a model of transact goodness

00:16:47,100 --> 00:16:53,399
into that dress and finally sequel will

00:16:50,850 --> 00:16:55,410
survive or variants thereof okay if you

00:16:53,399 --> 00:16:57,029
live in that space it becomes somebody

00:16:55,410 --> 00:16:59,250
else's problem you'd better make sure

00:16:57,029 --> 00:17:01,709
they get it right you better understand

00:16:59,250 --> 00:17:03,750
how your database does any form of

00:17:01,709 --> 00:17:08,900
transaction but otherwise you're pushing

00:17:03,750 --> 00:17:11,819
it down to people and it's not you so

00:17:08,900 --> 00:17:14,939
we're very short time for questions so

00:17:11,819 --> 00:17:15,569
are there any questions okay scoot

00:17:14,939 --> 00:17:22,429
around real fast

00:17:15,569 --> 00:17:22,429
[Applause]

00:17:22,559 --> 00:17:27,429
hi hi so I'm doing everything I

00:17:25,299 --> 00:17:29,890
shouldn't do with all that reading files

00:17:27,429 --> 00:17:33,520
from history writing to them honestly I

00:17:29,890 --> 00:17:35,590
didn't really run into any problems of

00:17:33,520 --> 00:17:37,360
genomic because that is small but what

00:17:35,590 --> 00:17:38,679
should I do if I do end problems you're

00:17:37,360 --> 00:17:42,029
running on a strike yes

00:17:38,679 --> 00:17:43,870
stop it much where to next question

00:17:42,029 --> 00:17:45,580
you're not even going to know you've got

00:17:43,870 --> 00:17:46,900
a problem maybe you could leave chat but

00:17:45,580 --> 00:17:48,700
otherwise you won't it's only notice

00:17:46,900 --> 00:17:51,580
you've got corruptions okay what intro

00:17:48,700 --> 00:17:53,500
so my stuff you can put it on to

00:17:51,580 --> 00:17:55,029
something like HDFS and then copy it

00:17:53,500 --> 00:17:56,620
over at the end of your work okay you

00:17:55,029 --> 00:17:58,840
get better performance there

00:17:56,620 --> 00:18:00,970
if using Microsoft Azure storage it's

00:17:58,840 --> 00:18:04,740
actually fast and consistent so it all

00:18:00,970 --> 00:18:08,950
works nicely okay but s3 is unreliable

00:18:04,740 --> 00:18:10,630
the enemy is normally list consistency

00:18:08,950 --> 00:18:11,950
so even if you get everything a unique

00:18:10,630 --> 00:18:14,919
name you don't going to worry about

00:18:11,950 --> 00:18:17,679
updating consistency but the listings it

00:18:14,919 --> 00:18:19,470
can be slow to discover data it can be

00:18:17,679 --> 00:18:22,929
slow to find deleted data

00:18:19,470 --> 00:18:24,850
everyone's code assumes everything is

00:18:22,929 --> 00:18:27,220
consistent okay I don't think that's

00:18:24,850 --> 00:18:28,659
those api's inside little mental model

00:18:27,220 --> 00:18:30,899
on the head we're all stuck in floppy

00:18:28,659 --> 00:18:39,179
disk land

00:18:30,899 --> 00:18:39,179
thanks all right two other questions

00:18:42,290 --> 00:18:51,020
I Steve go talk so that you didn't

00:18:47,600 --> 00:18:53,240
mention e/m or FF which Amazon have

00:18:51,020 --> 00:18:54,740
produced and Netflix as you know also

00:18:53,240 --> 00:18:56,810
have center and Spotify had done

00:18:54,740 --> 00:18:59,810
something similar okay we all right

00:18:56,810 --> 00:19:02,300
what's your opinion on them okay we are

00:18:59,810 --> 00:19:03,530
implementing something in Hadoop which

00:19:02,300 --> 00:19:05,720
actually all these things that use

00:19:03,530 --> 00:19:11,660
DynamoDB is a consistent metadata store

00:19:05,720 --> 00:19:13,700
we actually have something in Hadoop

00:19:11,660 --> 00:19:15,350
coming up that way - in fact I rerun my

00:19:13,700 --> 00:19:18,380
test with a - D

00:19:15,350 --> 00:19:19,790
I think it's local Dynamo I can probably

00:19:18,380 --> 00:19:22,100
actually get it working where we use

00:19:19,790 --> 00:19:23,690
Dynamo for this stuff as well what it

00:19:22,100 --> 00:19:25,850
actually delivers is two things you get

00:19:23,690 --> 00:19:27,860
the consistency to rename work but

00:19:25,850 --> 00:19:29,600
you're still using your completing of

00:19:27,860 --> 00:19:31,820
transactions and operation it takes lots

00:19:29,600 --> 00:19:34,250
of time okay so that's the promise all

00:19:31,820 --> 00:19:35,810
taking time to commit which is why I've

00:19:34,250 --> 00:19:37,310
been collaborated with Netflix on this

00:19:35,810 --> 00:19:38,570
faster committer because they have that

00:19:37,310 --> 00:19:41,020
commit lei problem

00:19:38,570 --> 00:19:44,150
and because DynamoDB runs up large bills

00:19:41,020 --> 00:19:46,310
so amazon they're committed to it the

00:19:44,150 --> 00:19:49,340
thing we're doing seagard yes it's the

00:19:46,310 --> 00:19:50,890
place from Game of Thrones is going to

00:19:49,340 --> 00:19:54,290
deliver it - what

00:19:50,890 --> 00:19:58,040
they also deliver that IMDB it's a lot

00:19:54,290 --> 00:19:59,240
lot faster - list we do a get in HDFS so

00:19:58,040 --> 00:19:59,720
actually see the file exists to list

00:19:59,240 --> 00:20:01,940
something

00:19:59,720 --> 00:20:03,380
it takes about 400 milliseconds usually

00:20:01,940 --> 00:20:05,930
pauses in the logs while we list

00:20:03,380 --> 00:20:07,730
directories no one and that really kills

00:20:05,930 --> 00:20:10,580
performance at the beginning of any

00:20:07,730 --> 00:20:12,560
query hi very smart query where it

00:20:10,580 --> 00:20:14,630
enumerates the directory or worse it

00:20:12,560 --> 00:20:16,490
does a directory tree walk to say what

00:20:14,630 --> 00:20:19,400
data do I have and that's a real

00:20:16,490 --> 00:20:21,410
performance killer dynamodb you can

00:20:19,400 --> 00:20:23,030
actually get it really fast the problem

00:20:21,410 --> 00:20:25,280
is you do have to pay upfront for your I

00:20:23,030 --> 00:20:29,120
ops you get billed more for it so it's a

00:20:25,280 --> 00:20:30,380
trade of cost versus time if you want to

00:20:29,120 --> 00:20:32,270
learn more about storage Jim you can

00:20:30,380 --> 00:20:33,790
come and ask me afterwards you know

00:20:32,270 --> 00:20:37,400
maybe start a project on it

00:20:33,790 --> 00:20:40,040
okay we're out of time if you have more

00:20:37,400 --> 00:20:43,000
questions when we later I'll see you

00:20:40,040 --> 00:20:43,000
later let's thank him again

00:20:44,010 --> 00:20:47,809
you

00:20:44,720 --> 00:20:47,809

YouTube URL: https://www.youtube.com/watch?v=UOE2m_XUr3U


