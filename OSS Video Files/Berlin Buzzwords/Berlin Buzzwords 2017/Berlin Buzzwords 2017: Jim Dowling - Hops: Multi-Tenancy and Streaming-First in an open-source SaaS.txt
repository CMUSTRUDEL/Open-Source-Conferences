Title: Berlin Buzzwords 2017: Jim Dowling - Hops: Multi-Tenancy and Streaming-First in an open-source SaaS
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Hops is a new European version of Hadoop that introduces new concepts to Hadoop to enable multi-tenant Streaming-as-a-Service. In particular, Hops introduces the abstractions: projects, datasets and users. Projects are containers for datasets and users, and are aimed at removing the need for users to manage and launch clusters today, as clusters are currently the only strong mechanims for isolating users and their data from one another.

In this talk we will discuss the challenges in building multi-tenant streaming applications on both Spark and Flink over YARN using Hops concepts. Our platform, called Hopsworks, is in an entirely UI-driven environment built with only open-source software. We also show how we use the ELK stack (Elasticsearch, Logstash, and Kibana) for logging and debugging running Spark streaming applications, how we use Grafana and InfluxDB for monitoring Spark streaming applications, and finally how Apache Zeppelin can provide interactive visualizations and charts to end-users. We will also show how applications are run within a 'project' on a YARN cluster with the novel property that applications are metered and charged to projects. We will also discuss our experiences running streaming-as-a-service on a cluster in Sweden with over 150 users (as of early 2017).  

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,410 --> 00:00:11,440
large yes thank you yes my name is Jim

00:00:09,250 --> 00:00:12,740
I'm actually representing logical clocks

00:00:11,440 --> 00:00:14,750
we have a start-up come

00:00:12,740 --> 00:00:17,060
using this work so we have our name down

00:00:14,750 --> 00:00:18,800
here at the bottom corner I'm going to

00:00:17,060 --> 00:00:20,900
talk so if you've you've heard of helps

00:00:18,800 --> 00:00:22,520
a lot of you haven't

00:00:20,900 --> 00:00:24,290
we're not based in the valley I guess

00:00:22,520 --> 00:00:25,730
you know we're European or European

00:00:24,290 --> 00:00:28,279
distribution Hadoop and we try to get

00:00:25,730 --> 00:00:30,769
the word out there we do our best but

00:00:28,279 --> 00:00:33,320
you know you should have heard of us I

00:00:30,769 --> 00:00:35,239
guess if you read a lot of the the you

00:00:33,320 --> 00:00:36,980
know the blogosphere because we have

00:00:35,239 --> 00:00:40,010
actually the fastest distribution of

00:00:36,980 --> 00:00:42,470
Hadoop by a good margin so we had a

00:00:40,010 --> 00:00:44,720
paper earlier this year at use next past

00:00:42,470 --> 00:00:46,430
where in collaboration with Spotify so

00:00:44,720 --> 00:00:48,769
on Spotify his workload their Hadoop

00:00:46,430 --> 00:00:51,589
workload we worked with Oracle on this

00:00:48,769 --> 00:00:53,600
as well but we had 16 times the

00:00:51,589 --> 00:00:55,400
throughput of HDFS the Hadoop file

00:00:53,600 --> 00:00:58,190
system so we got about 1.2 million

00:00:55,400 --> 00:01:00,500
operations per second and we can have

00:00:58,190 --> 00:01:02,180
clusters that are more than an order of

00:01:00,500 --> 00:01:04,430
magnitude larger than existing to do

00:01:02,180 --> 00:01:06,799
cluster so you know 37 times the number

00:01:04,430 --> 00:01:09,500
of files is a reasonably conservative

00:01:06,799 --> 00:01:10,700
estimate of how big we can go recently

00:01:09,500 --> 00:01:12,530
the last couple of weeks we won the

00:01:10,700 --> 00:01:15,710
Triple E scale challenge for this year

00:01:12,530 --> 00:01:17,000
so like we have a bunch of them we've

00:01:15,710 --> 00:01:19,640
done a lot of research over number of

00:01:17,000 --> 00:01:21,890
years to get the the underlying file

00:01:19,640 --> 00:01:23,149
system to this level and the way we did

00:01:21,890 --> 00:01:25,130
it was that if you're familiar with

00:01:23,149 --> 00:01:26,539
Hadoop there's a in the Hadoop file

00:01:25,130 --> 00:01:28,100
system you have something called a name

00:01:26,539 --> 00:01:30,579
node which stores the metadata for the

00:01:28,100 --> 00:01:33,530
file system so we're distributed systems

00:01:30,579 --> 00:01:35,810
researchers what we did was we move the

00:01:33,530 --> 00:01:38,119
main the name node state from the heap

00:01:35,810 --> 00:01:41,210
of the JVM into an in-memory distributed

00:01:38,119 --> 00:01:42,829
database and basically that helped us to

00:01:41,210 --> 00:01:46,490
scale it it's a new sequel database

00:01:42,829 --> 00:01:48,289
called my sequel cluster now I'm not

00:01:46,490 --> 00:01:49,789
here to talk about that today if you

00:01:48,289 --> 00:01:52,520
want to read the opponent you can go to

00:01:49,789 --> 00:01:54,890
our website or we have papers and plenty

00:01:52,520 --> 00:01:57,469
of presentations to look at I'm going to

00:01:54,890 --> 00:01:59,619
talk about streaming on platform so

00:01:57,469 --> 00:02:01,819
streaming as a service in particular

00:01:59,619 --> 00:02:04,009
spark and flink they're the kind of main

00:02:01,819 --> 00:02:06,710
platforms that we support we also

00:02:04,009 --> 00:02:09,380
support cask as a service and we're

00:02:06,710 --> 00:02:10,610
working hard on tensorflow right now so

00:02:09,380 --> 00:02:12,140
this is running in production we're

00:02:10,610 --> 00:02:14,480
running we have a cluster in northern

00:02:12,140 --> 00:02:18,380
Sweden and Lully oh we've got 150 users

00:02:14,480 --> 00:02:22,040
and we have a number of users doing

00:02:18,380 --> 00:02:23,720
streaming right now so I'm going to talk

00:02:22,040 --> 00:02:25,460
about is the journey we had in head to

00:02:23,720 --> 00:02:26,600
head you get to it like a production

00:02:25,460 --> 00:02:28,340
ready

00:02:26,600 --> 00:02:32,000
platform what do we need to add two hops

00:02:28,340 --> 00:02:33,740
to to bring it up to speed so the one

00:02:32,000 --> 00:02:35,300
thing that is interesting about Sweden

00:02:33,740 --> 00:02:38,420
is you know that labor is expensive

00:02:35,300 --> 00:02:41,180
right so cleaners taxi drivers sis

00:02:38,420 --> 00:02:42,860
admin's they're very expensive so what

00:02:41,180 --> 00:02:45,740
we wanted to build was a self-service

00:02:42,860 --> 00:02:47,570
streaming platform and that means that

00:02:45,740 --> 00:02:49,460
users like this is Obama here in case

00:02:47,570 --> 00:02:51,170
you're wondering if it is we want to

00:02:49,460 --> 00:02:53,600
help him to spark up by himself with a

00:02:51,170 --> 00:02:55,780
bit of slinky that should be Flint but

00:02:53,600 --> 00:02:59,270
flink whatever okay bad joke

00:02:55,780 --> 00:03:00,770
so the basics of a stream processing

00:02:59,270 --> 00:03:02,210
platform are that you're going to have

00:03:00,770 --> 00:03:05,120
some streaming engine maybe it's going

00:03:02,210 --> 00:03:08,390
to be flank or spark and there's other

00:03:05,120 --> 00:03:09,830
ones like data torrent product apex

00:03:08,390 --> 00:03:11,870
which I heard it talked about earlier

00:03:09,830 --> 00:03:14,000
and but they're going to take data in

00:03:11,870 --> 00:03:16,060
there's going to be ingress some pipes

00:03:14,000 --> 00:03:18,350
bringing data in from its source and

00:03:16,060 --> 00:03:20,480
then you're going to write your data out

00:03:18,350 --> 00:03:23,720
somewhere probably to a sink but there's

00:03:20,480 --> 00:03:25,490
more services a basic streaming platform

00:03:23,720 --> 00:03:27,920
will have some way of looking at online

00:03:25,490 --> 00:03:29,660
logs so you're going to have to debug

00:03:27,920 --> 00:03:31,040
applications as the Runnings you want

00:03:29,660 --> 00:03:32,720
them to be able to write to some log

00:03:31,040 --> 00:03:34,640
where you can read the logs as the

00:03:32,720 --> 00:03:36,260
streaming app is running similarly you

00:03:34,640 --> 00:03:37,370
want be able to monitor that application

00:03:36,260 --> 00:03:39,980
as it's running so you need to be able

00:03:37,370 --> 00:03:41,300
to get notifications if something's

00:03:39,980 --> 00:03:43,400
going around you might want to look at

00:03:41,300 --> 00:03:46,430
the you know memory utilization CP

00:03:43,400 --> 00:03:48,860
utilization if it's lagging or not and

00:03:46,430 --> 00:03:51,080
then your streaming application will

00:03:48,860 --> 00:03:54,020
also have to support high availability

00:03:51,080 --> 00:03:56,120
so if it crashes it should restart and

00:03:54,020 --> 00:03:58,460
it should reprocess any data that it

00:03:56,120 --> 00:04:00,860
missed and typically streaming engines

00:03:58,460 --> 00:04:03,680
will will need some form of storage on

00:04:00,860 --> 00:04:05,630
which to write checkpoints we're also

00:04:03,680 --> 00:04:07,850
right ahead log so there's a typical

00:04:05,630 --> 00:04:08,900
mechanisms used to recover from failures

00:04:07,850 --> 00:04:10,820
you're going to have a right ahead log

00:04:08,900 --> 00:04:12,470
and then some checkpoints that you

00:04:10,820 --> 00:04:15,530
recover from and then you may go back to

00:04:12,470 --> 00:04:18,140
Kafka or wherever to to process any data

00:04:15,530 --> 00:04:20,420
that you missed so that's a basic stream

00:04:18,140 --> 00:04:21,680
platform but what we have to do is we

00:04:20,420 --> 00:04:24,680
had wanted to build a platform around

00:04:21,680 --> 00:04:26,990
hops since are kind of our clouded that

00:04:24,680 --> 00:04:29,330
we're building on and we looked at

00:04:26,990 --> 00:04:32,750
casket basically for the for the pipe

00:04:29,330 --> 00:04:34,220
where the data is coming in we looked at

00:04:32,750 --> 00:04:36,320
a lot of different tools for how to do

00:04:34,220 --> 00:04:38,810
monitoring and we ended up on Griffin

00:04:36,320 --> 00:04:39,880
and in Flex DB I know there are not lots

00:04:38,810 --> 00:04:42,070
of other ones like for me

00:04:39,880 --> 00:04:44,470
and so on I'm going to talk about the

00:04:42,070 --> 00:04:46,660
ones that we've looked at we looked at

00:04:44,470 --> 00:04:50,680
ELQ stock the elastic logstash in Cabana

00:04:46,660 --> 00:04:51,730
for the logging and for doing UI so if

00:04:50,680 --> 00:04:53,950
you're doing any interactive and

00:04:51,730 --> 00:04:55,690
analytics of data maybe produced by your

00:04:53,950 --> 00:04:57,460
streaming platform we're supporting

00:04:55,690 --> 00:04:58,680
Jupiter and Zeppelin now there are a

00:04:57,460 --> 00:05:01,090
number of other platforms out there

00:04:58,680 --> 00:05:02,380
these are all open source stuff so the

00:05:01,090 --> 00:05:04,840
whole platform is open source so that

00:05:02,380 --> 00:05:06,910
was a kind of a prerequisite for us at

00:05:04,840 --> 00:05:08,950
the beginning okay so this is our

00:05:06,910 --> 00:05:09,790
platform if you if you want to look at

00:05:08,950 --> 00:05:12,820
it I don't know if you can see that

00:05:09,790 --> 00:05:15,190
particularly well resolutions a bit off

00:05:12,820 --> 00:05:17,830
but we're basically supporting casket as

00:05:15,190 --> 00:05:19,390
a pipe for for incoming data you can

00:05:17,830 --> 00:05:23,710
write your streaming up in slink or

00:05:19,390 --> 00:05:25,510
spark we support our HDFS compliance

00:05:23,710 --> 00:05:27,250
it's a drop-in replacement for HDFS

00:05:25,510 --> 00:05:30,970
helps FS and we also support your on

00:05:27,250 --> 00:05:32,800
currently version 273 of the loop and we

00:05:30,970 --> 00:05:34,600
support also structured streaming so you

00:05:32,800 --> 00:05:37,090
can write your spark application to

00:05:34,600 --> 00:05:38,980
park' and then do analytics directly

00:05:37,090 --> 00:05:42,520
from park' I'll give an example do demo

00:05:38,980 --> 00:05:44,320
that later and then finally for logging

00:05:42,520 --> 00:05:46,420
and monitoring I'm going to talk a bit

00:05:44,320 --> 00:05:48,880
about elastic and qivana that we use for

00:05:46,420 --> 00:05:51,130
logging and then Griffin in folks DB for

00:05:48,880 --> 00:05:52,600
monitoring now we also support my sequel

00:05:51,130 --> 00:05:54,490
custard the back end so you can use that

00:05:52,600 --> 00:05:57,150
if you want to as it as I think

00:05:54,490 --> 00:05:59,020
typically people don't but it's there

00:05:57,150 --> 00:06:00,490
the other thing that's interesting for

00:05:59,020 --> 00:06:01,750
from our perspective and I guess from a

00:06:00,490 --> 00:06:03,820
lot of people in the room is that we

00:06:01,750 --> 00:06:07,660
have this new law coming into effect

00:06:03,820 --> 00:06:09,280
next year GDP or and it is law right and

00:06:07,660 --> 00:06:10,630
it will come into effect then and I

00:06:09,280 --> 00:06:12,520
think a lot of people are in denial of

00:06:10,630 --> 00:06:14,530
the implications of it so it has

00:06:12,520 --> 00:06:16,420
implications for sensitive data private

00:06:14,530 --> 00:06:19,900
data you have to think about issues like

00:06:16,420 --> 00:06:22,680
data retention you have to have auditing

00:06:19,900 --> 00:06:25,000
for the data and you need and then

00:06:22,680 --> 00:06:28,120
citizens have rights you have right to

00:06:25,000 --> 00:06:30,820
be forgotten and so on so this has a lot

00:06:28,120 --> 00:06:32,740
of implications for how you build data

00:06:30,820 --> 00:06:35,100
processing platforms and in particular

00:06:32,740 --> 00:06:37,510
you have the issue of privacy by design

00:06:35,100 --> 00:06:39,250
so that's kind of a requirement to GDP

00:06:37,510 --> 00:06:42,100
or so how do you ensure that your system

00:06:39,250 --> 00:06:44,770
will support privacy in its actual

00:06:42,100 --> 00:06:48,250
architecture so I'm going to talk a bit

00:06:44,770 --> 00:06:49,870
about how we do that we basically have a

00:06:48,250 --> 00:06:52,150
number of new abstractions that we've

00:06:49,870 --> 00:06:53,230
introduced into Hadoop and they make it

00:06:52,150 --> 00:06:54,940
easier for us to

00:06:53,230 --> 00:06:57,160
support multiple users on the same

00:06:54,940 --> 00:06:59,980
platform so multiple tenants that is

00:06:57,160 --> 00:07:01,570
over multi-tenancy for stream processing

00:06:59,980 --> 00:07:02,890
so the first abstraction we have is

00:07:01,570 --> 00:07:04,510
something called Project and what a

00:07:02,890 --> 00:07:07,270
project is is is basically a github

00:07:04,510 --> 00:07:08,680
project so if you want of a project you

00:07:07,270 --> 00:07:11,920
can create us it's quick and cheap

00:07:08,680 --> 00:07:13,420
degres you can manage the project if

00:07:11,920 --> 00:07:15,220
you're the owner of the project you can

00:07:13,420 --> 00:07:18,010
have datasets in your project you can

00:07:15,220 --> 00:07:19,060
add members your project remove them I'm

00:07:18,010 --> 00:07:20,350
going to actually split over and do a

00:07:19,060 --> 00:07:22,720
little demo while we're doing the see

00:07:20,350 --> 00:07:25,990
you get a feel for what I'm talking

00:07:22,720 --> 00:07:27,520
about so actually let me go to a new

00:07:25,990 --> 00:07:34,030
project this one I haven't logged in

00:07:27,520 --> 00:07:35,020
here so just create new in here so ok so

00:07:34,030 --> 00:07:36,280
it's actually we have we've got a bunch

00:07:35,020 --> 00:07:38,200
of Tours I'm just going to close the

00:07:36,280 --> 00:07:39,850
tour to the beginning but basically you

00:07:38,200 --> 00:07:41,260
have projects in your platform so if I

00:07:39,850 --> 00:07:45,070
want to create a new one called Bebo's

00:07:41,260 --> 00:07:46,900
here you just create it like that we had

00:07:45,070 --> 00:07:48,010
a number of services and my projects are

00:07:46,900 --> 00:07:50,380
going to add up here on the right-hand

00:07:48,010 --> 00:07:52,600
side so a project is the unit of

00:07:50,380 --> 00:07:55,320
isolation so any programs I run within

00:07:52,600 --> 00:07:58,000
it will be sandbox within that

00:07:55,320 --> 00:07:59,800
environment and I won't be able to copy

00:07:58,000 --> 00:08:01,450
data out of the project if I don't have

00:07:59,800 --> 00:08:04,780
a role that's allowed to do dance from

00:08:01,450 --> 00:08:06,760
another data owner and the projects will

00:08:04,780 --> 00:08:08,020
basically be cheap and dirty so the

00:08:06,760 --> 00:08:10,450
equivalent of clusters right if you're

00:08:08,020 --> 00:08:12,730
running any s3 or Amazon or if you're

00:08:10,450 --> 00:08:14,440
running on as you're typically you would

00:08:12,730 --> 00:08:16,000
spin up a cluster to do this it would be

00:08:14,440 --> 00:08:18,460
your kind of unit of isolation but this

00:08:16,000 --> 00:08:21,430
is a managed platform so for us a

00:08:18,460 --> 00:08:23,730
project is the unit of isolation and

00:08:21,430 --> 00:08:26,110
because it being within you do your work

00:08:23,730 --> 00:08:28,600
so when you have a project what we also

00:08:26,110 --> 00:08:30,700
want to be able to do is share your

00:08:28,600 --> 00:08:33,010
datasets across projects because I said

00:08:30,700 --> 00:08:35,290
already it's like a universal ation but

00:08:33,010 --> 00:08:37,240
what if I if I have a data set it could

00:08:35,290 --> 00:08:38,919
be very large I'd like to share it with

00:08:37,240 --> 00:08:41,200
another project I don't want to have to

00:08:38,919 --> 00:08:44,440
copy the data and typically that's what

00:08:41,200 --> 00:08:46,120
you would do in a you know a different

00:08:44,440 --> 00:08:48,340
environment where you were worried about

00:08:46,120 --> 00:08:49,930
maybe allowing users access the data

00:08:48,340 --> 00:08:52,800
they might copy it to someplace so not

00:08:49,930 --> 00:08:55,900
load copier - so if I create a data set

00:08:52,800 --> 00:08:57,670
let's create two projects here another

00:08:55,900 --> 00:09:00,630
one here we close up I just turn off

00:08:57,670 --> 00:09:00,630
these towards for the moment

00:09:04,120 --> 00:09:08,570
besides creating a second project called

00:09:06,290 --> 00:09:10,490
hello and I'm going to go in now I'm

00:09:08,570 --> 00:09:11,900
inside the project hello can you see

00:09:10,490 --> 00:09:14,990
that there yes okay I think I'll just

00:09:11,900 --> 00:09:16,250
make it fullscreen okay so what I'm

00:09:14,990 --> 00:09:23,840
going to do is just create a little data

00:09:16,250 --> 00:09:25,520
set here I'll call it my my data now

00:09:23,840 --> 00:09:26,810
that data would set with searchable but

00:09:25,520 --> 00:09:28,460
I can share it by basically

00:09:26,810 --> 00:09:30,130
right-clicking on us I can share it with

00:09:28,460 --> 00:09:33,440
the other project that I created earlier

00:09:30,130 --> 00:09:34,910
Debose and that's all I basically need

00:09:33,440 --> 00:09:37,010
to do so it's kind of like Dropbox to

00:09:34,910 --> 00:09:39,980
share the data set if I go back to my

00:09:37,010 --> 00:09:42,200
other project this one here Bebo's what

00:09:39,980 --> 00:09:44,480
see happens is that it appeared in here

00:09:42,200 --> 00:09:46,550
so this is the data set from below I can

00:09:44,480 --> 00:09:48,200
click on it to say fine I accept us

00:09:46,550 --> 00:09:50,240
because I didn't ask for that I have to

00:09:48,200 --> 00:09:51,860
ask me if I want to include us and

00:09:50,240 --> 00:09:54,260
that's basically sharing data set

00:09:51,860 --> 00:09:56,030
security between projects so we could

00:09:54,260 --> 00:09:58,610
have shared that data set right only or

00:09:56,030 --> 00:10:00,920
read write or read only but it didn't

00:09:58,610 --> 00:10:02,480
cost the for each project you also have

00:10:00,920 --> 00:10:04,130
quotas I'll talk about it in a minute

00:10:02,480 --> 00:10:05,840
but it's not going to add to the quota

00:10:04,130 --> 00:10:09,320
of this project it's not going to add to

00:10:05,840 --> 00:10:11,060
the amount of space that I consume so

00:10:09,320 --> 00:10:14,420
we're sharing data is not copying data

00:10:11,060 --> 00:10:17,540
it's basically linking in this case the

00:10:14,420 --> 00:10:18,800
HTS data set across two projects I'll

00:10:17,540 --> 00:10:22,850
show later on that we can do the same

00:10:18,800 --> 00:10:25,310
thing for Casca topics an example now

00:10:22,850 --> 00:10:26,600
our platform supports Lincoln spark as I

00:10:25,310 --> 00:10:29,270
mentioned already we also support

00:10:26,600 --> 00:10:31,280
tensorflow spark and tensor flow and

00:10:29,270 --> 00:10:33,790
casket we're not we're not supporting

00:10:31,280 --> 00:10:35,990
MapReduce right now we haven't had any

00:10:33,790 --> 00:10:37,670
demand for us even though it's obviously

00:10:35,990 --> 00:10:40,300
power to the platform that works but in

00:10:37,670 --> 00:10:42,560
the UI we're not even supporting it I

00:10:40,300 --> 00:10:44,360
don't know this is very little around

00:10:42,560 --> 00:10:45,710
first so then the other thing that you

00:10:44,360 --> 00:10:47,540
need to do in if you're going to have a

00:10:45,710 --> 00:10:49,340
UI driven platform like we have is you

00:10:47,540 --> 00:10:51,740
have to have notebooks at some levels so

00:10:49,340 --> 00:10:53,600
we started supporting just Zeppelin and

00:10:51,740 --> 00:10:55,640
we found that there are a lot of data

00:10:53,600 --> 00:10:57,830
scientists and files and people who just

00:10:55,640 --> 00:11:00,110
want to use Jupiter so we spend a lot of

00:10:57,830 --> 00:11:01,370
effort adding Jupiter to it and then the

00:11:00,110 --> 00:11:05,480
other way you can run jobs is you can

00:11:01,370 --> 00:11:07,310
launch them in in a job launcher I can

00:11:05,480 --> 00:11:10,520
jump back and have a quick look at a job

00:11:07,310 --> 00:11:12,260
here so now I'm inside a project here so

00:11:10,520 --> 00:11:13,370
the jobs basically look like these ones

00:11:12,260 --> 00:11:16,850
here

00:11:13,370 --> 00:11:18,380
you can create a new job you can pick a

00:11:16,850 --> 00:11:21,050
name for it pick your platform

00:11:18,380 --> 00:11:23,120
tensorflow sparks link and so on and

00:11:21,050 --> 00:11:25,279
that those jobs can then be launched

00:11:23,120 --> 00:11:27,020
it's like a job scheduler like you would

00:11:25,279 --> 00:11:28,839
have in a and things like that you can

00:11:27,020 --> 00:11:31,730
have them launch a particular times

00:11:28,839 --> 00:11:33,110
schedules there's no way of changing

00:11:31,730 --> 00:11:35,029
them together right now but it's

00:11:33,110 --> 00:11:39,589
basically a way for launching and

00:11:35,029 --> 00:11:41,600
managing jobs okay another thing that

00:11:39,589 --> 00:11:43,100
pythons surprising is affecting

00:11:41,600 --> 00:11:44,930
everything we're doing because python is

00:11:43,100 --> 00:11:48,820
growing so much in use on Hadoop

00:11:44,930 --> 00:11:51,050
platforms that Python users demand

00:11:48,820 --> 00:11:53,600
access to different versions of

00:11:51,050 --> 00:11:55,880
libraries and currently if you're

00:11:53,600 --> 00:11:57,950
running in a Hadoop style environment

00:11:55,880 --> 00:12:00,050
and you're running with Scala or Java

00:11:57,950 --> 00:12:02,270
you can just build a big fat jar with

00:12:00,050 --> 00:12:04,220
all your dependencies and run it and you

00:12:02,270 --> 00:12:06,320
have no problems but in Python they

00:12:04,220 --> 00:12:08,930
don't have a support for building hot

00:12:06,320 --> 00:12:10,279
jars uber cars you can have eggs but

00:12:08,930 --> 00:12:11,779
eggs may have dependencies and other

00:12:10,279 --> 00:12:14,800
eggs and there's no way of packaging

00:12:11,779 --> 00:12:17,180
them together no easy way for users so

00:12:14,800 --> 00:12:19,130
what we've been doing a lot of with is

00:12:17,180 --> 00:12:20,930
adding support for Conda to our

00:12:19,130 --> 00:12:22,339
abstractions so I don't have you heard a

00:12:20,930 --> 00:12:24,650
con that counters basically a package

00:12:22,339 --> 00:12:29,510
manager for Python I'll just go back and

00:12:24,650 --> 00:12:33,020
show you how it works here so here I

00:12:29,510 --> 00:12:34,160
have a a particular project I don't you

00:12:33,020 --> 00:12:35,779
can see it on the screen there's a

00:12:34,160 --> 00:12:39,140
little bit I can zoom in a bit I guess

00:12:35,779 --> 00:12:42,290
so I can search for a library in Conda

00:12:39,140 --> 00:12:43,670
in so I just search for panda and

00:12:42,290 --> 00:12:46,130
because that's the net and then I can

00:12:43,670 --> 00:12:48,770
pick my version let's say take the Pam

00:12:46,130 --> 00:12:50,870
the data reader and then that gets

00:12:48,770 --> 00:12:52,070
installed so here I have some libraries

00:12:50,870 --> 00:12:53,420
that were installed around this one is

00:12:52,070 --> 00:12:55,700
currently installing you can see but

00:12:53,420 --> 00:12:56,990
panda sequel is installed earlier on so

00:12:55,700 --> 00:12:58,400
what's happening here is that each

00:12:56,990 --> 00:12:59,839
project can have their own libraries

00:12:58,400 --> 00:13:04,820
their own version of tensorflow their

00:12:59,839 --> 00:13:07,700
own version of numpy and the way we're

00:13:04,820 --> 00:13:09,589
doing it is that we're actually copying

00:13:07,700 --> 00:13:12,410
the we're creating a virtual environment

00:13:09,589 --> 00:13:13,670
on every node in the system so we have

00:13:12,410 --> 00:13:15,650
an agent running on every node in the

00:13:13,670 --> 00:13:16,940
system they get commands to basically

00:13:15,650 --> 00:13:19,010
say create an environment for this

00:13:16,940 --> 00:13:21,020
project and then they'll get commands

00:13:19,010 --> 00:13:22,940
like install this particular library for

00:13:21,020 --> 00:13:24,560
this count environment and when your

00:13:22,940 --> 00:13:26,980
jobs launch on Pais parkour and

00:13:24,560 --> 00:13:30,130
tensorflow then they launch within that

00:13:26,980 --> 00:13:31,600
the environment no other Hadoop distros

00:13:30,130 --> 00:13:35,920
supports anything like this

00:13:31,600 --> 00:13:39,520
currently okay I'm going to move on a

00:13:35,920 --> 00:13:40,840
bit now to I talked about projects

00:13:39,520 --> 00:13:42,610
already but let's think of it from our

00:13:40,840 --> 00:13:44,290
abstract perspective and then I look at

00:13:42,610 --> 00:13:47,170
an example a use case that we have with

00:13:44,290 --> 00:13:49,570
an IOT company so a project is basically

00:13:47,170 --> 00:13:52,000
a grouping of users and data so here I

00:13:49,570 --> 00:13:54,640
can see three different users and four

00:13:52,000 --> 00:13:56,380
different data sets or data sources so

00:13:54,640 --> 00:13:59,140
we can have Casca topics you can have a

00:13:56,380 --> 00:14:01,930
database for example in hive or you

00:13:59,140 --> 00:14:04,000
could have a subtree in HDFS so if you

00:14:01,930 --> 00:14:06,430
draw any line around those users and

00:14:04,000 --> 00:14:08,110
data sets you get a project so that's

00:14:06,430 --> 00:14:10,420
the only restriction here is that a

00:14:08,110 --> 00:14:12,430
project sorry a data set has to have a

00:14:10,420 --> 00:14:14,560
home project but otherwise you can draw

00:14:12,430 --> 00:14:17,770
any lines around these whatever way you

00:14:14,560 --> 00:14:19,750
want so that you know when you when you

00:14:17,770 --> 00:14:21,430
setup in a company you might have one

00:14:19,750 --> 00:14:22,930
project for every one the company is a

00:14:21,430 --> 00:14:24,730
member of it with the company database

00:14:22,930 --> 00:14:26,890
and then when teams want to work on

00:14:24,730 --> 00:14:28,210
different activities or maybe different

00:14:26,890 --> 00:14:30,910
departments would have their own

00:14:28,210 --> 00:14:33,670
projects but it becomes quite a natural

00:14:30,910 --> 00:14:36,640
way of assigning responsibility and

00:14:33,670 --> 00:14:38,110
ownership within an organization so as I

00:14:36,640 --> 00:14:39,430
mentioned we work with Spotify quite a

00:14:38,110 --> 00:14:41,500
lot and you may know that they're moving

00:14:39,430 --> 00:14:43,600
towards Google Cloud so one of the big

00:14:41,500 --> 00:14:46,480
problems they had was lots of orphaned

00:14:43,600 --> 00:14:47,950
workflows on datasets so the workflows

00:14:46,480 --> 00:14:50,350
are running everyday here we are

00:14:47,950 --> 00:14:51,640
nobody knew who could run it you know

00:14:50,350 --> 00:14:53,260
people who have a stay of turnover

00:14:51,640 --> 00:14:55,090
within the company the same goes for

00:14:53,260 --> 00:14:57,580
datasets you know who's responsible for

00:14:55,090 --> 00:14:58,690
that so in our particular model there's

00:14:57,580 --> 00:15:01,210
always going to be an owner for a

00:14:58,690 --> 00:15:03,010
project and it would be quite clear if

00:15:01,210 --> 00:15:04,740
that person leaves an organization you

00:15:03,010 --> 00:15:06,970
can find someone to take over that role

00:15:04,740 --> 00:15:08,980
okay so I'm going to give an example of

00:15:06,970 --> 00:15:12,850
an IOT platform that we're working with

00:15:08,980 --> 00:15:15,790
a noisy vendor in in Stockholm and what

00:15:12,850 --> 00:15:17,050
they're doing is they have have IOT

00:15:15,790 --> 00:15:19,540
devices there that like you know

00:15:17,050 --> 00:15:21,240
factories or on cruise ships or lots of

00:15:19,540 --> 00:15:24,640
different places and they have gateways

00:15:21,240 --> 00:15:26,980
off site and the the gateways talk to a

00:15:24,640 --> 00:15:28,900
number of cloud servers to aggregate the

00:15:26,980 --> 00:15:31,060
data and then they want to pull all this

00:15:28,900 --> 00:15:33,250
data into a you know a data like

00:15:31,060 --> 00:15:35,410
platform where they can give access to

00:15:33,250 --> 00:15:38,320
their users to do analysis of the of the

00:15:35,410 --> 00:15:39,649
IOT data and so the main requirement

00:15:38,320 --> 00:15:42,019
here is the multi-tenancy one

00:15:39,649 --> 00:15:44,959
you could run a different cluster for

00:15:42,019 --> 00:15:46,129
every company that you're supporting but

00:15:44,959 --> 00:15:47,779
in this case we want to support a

00:15:46,129 --> 00:15:50,389
multi-tenant platform world that

00:15:47,779 --> 00:15:53,420
customers can run on the same single

00:15:50,389 --> 00:15:54,860
platform now in reality it's going to be

00:15:53,420 --> 00:15:58,160
a little bit more complex than this this

00:15:54,860 --> 00:16:02,869
company have customers on AWS on Google

00:15:58,160 --> 00:16:06,079
cloud on Azure and you need to bring all

00:16:02,869 --> 00:16:07,339
those together into the same platform so

00:16:06,079 --> 00:16:08,509
this is the way we do it with our

00:16:07,339 --> 00:16:11,779
abstractions remember we have these

00:16:08,509 --> 00:16:14,240
projects datasets and users the the

00:16:11,779 --> 00:16:16,040
company has a casket topic for taking

00:16:14,240 --> 00:16:17,899
all the data in from the sensors and

00:16:16,040 --> 00:16:20,059
that data will flow into this casket

00:16:17,899 --> 00:16:22,279
topic for every company so give a

00:16:20,059 --> 00:16:26,360
company acne we'll have a project and

00:16:22,279 --> 00:16:29,720
that project will have datasets in HDFS

00:16:26,360 --> 00:16:33,199
but also topic in Casca that you can see

00:16:29,720 --> 00:16:34,550
there so the first streaming application

00:16:33,199 --> 00:16:37,129
takes the data coming in and then

00:16:34,550 --> 00:16:40,369
redirects it to each company's topic and

00:16:37,129 --> 00:16:43,249
data set and then the company itself can

00:16:40,369 --> 00:16:46,220
manage access to that data so they can

00:16:43,249 --> 00:16:49,009
add the users that they want to do in

00:16:46,220 --> 00:16:50,870
our analytics owners and and so on the

00:16:49,009 --> 00:16:52,819
company the IT company itself can then

00:16:50,870 --> 00:16:55,249
generate you know generic analytics

00:16:52,819 --> 00:16:56,569
reports and sell them to companies but

00:16:55,249 --> 00:16:57,980
companies will often want to do their

00:16:56,569 --> 00:17:00,949
own custom analytics which they can do

00:16:57,980 --> 00:17:02,179
in our platform so the alternative to

00:17:00,949 --> 00:17:04,640
this if you were thinking I'm going to

00:17:02,179 --> 00:17:06,079
do this task 3 you might say well ok we

00:17:04,640 --> 00:17:09,020
would you know we'll write our data to a

00:17:06,079 --> 00:17:11,299
bucket in s3 and it will give access to

00:17:09,020 --> 00:17:12,829
the company but in that case the company

00:17:11,299 --> 00:17:14,990
loses control of the data they're

00:17:12,829 --> 00:17:16,909
basically giving it to the company and

00:17:14,990 --> 00:17:18,829
so this way the company the IT company

00:17:16,909 --> 00:17:21,260
retains ownership of their data and

00:17:18,829 --> 00:17:23,059
access to it so one thing I didn't

00:17:21,260 --> 00:17:26,929
mention about users and projects is that

00:17:23,059 --> 00:17:29,120
we have roles now you know when we talk

00:17:26,929 --> 00:17:30,679
to different users and different domains

00:17:29,120 --> 00:17:33,200
they all want to have lots and lots of

00:17:30,679 --> 00:17:34,880
different roles GDP or talk specifically

00:17:33,200 --> 00:17:36,529
about two particular roles a data

00:17:34,880 --> 00:17:38,990
controller which we call a data owner

00:17:36,529 --> 00:17:41,510
and then a data processor so somebody

00:17:38,990 --> 00:17:44,450
who's doing analysis on the actual data

00:17:41,510 --> 00:17:46,520
so in our case the data owner is able to

00:17:44,450 --> 00:17:47,990
import data into a project exported apps

00:17:46,520 --> 00:17:50,000
so they're responsible for the data

00:17:47,990 --> 00:17:51,380
they're also responsible for adding and

00:17:50,000 --> 00:17:52,720
removing people from the project and

00:17:51,380 --> 00:17:55,210
sharing data or

00:17:52,720 --> 00:17:56,980
topics in casco between projects data

00:17:55,210 --> 00:17:59,080
processors our data scientists just do

00:17:56,980 --> 00:18:00,940
analytics so they can upload jars they

00:17:59,080 --> 00:18:02,440
can look at their logs that they've

00:18:00,940 --> 00:18:04,750
generated but they can't copy data

00:18:02,440 --> 00:18:06,340
anywhere so what's kind of unique in our

00:18:04,750 --> 00:18:08,260
platform compared to others is that the

00:18:06,340 --> 00:18:10,570
users do all this management themselves

00:18:08,260 --> 00:18:13,679
you don't need to talk to assisted men

00:18:10,570 --> 00:18:16,419
who add some rules in Ranger or in

00:18:13,679 --> 00:18:18,970
century basically users can do all this

00:18:16,419 --> 00:18:21,309
work by themselves in a kind of manner

00:18:18,970 --> 00:18:24,309
that's familiar to them you get style I

00:18:21,309 --> 00:18:26,950
guess I mentioned this already for

00:18:24,309 --> 00:18:29,860
projects of quotas so because we have

00:18:26,950 --> 00:18:32,169
all our metadata in our own database we

00:18:29,860 --> 00:18:35,260
can extend that as we want to and one

00:18:32,169 --> 00:18:36,880
thing we added was quotas to yarn so you

00:18:35,260 --> 00:18:38,890
don't have quotas naturally in yarn

00:18:36,880 --> 00:18:40,299
we've added them so basically when a

00:18:38,890 --> 00:18:43,840
container starts when the container

00:18:40,299 --> 00:18:45,820
stops we we can increment the time taken

00:18:43,840 --> 00:18:48,250
within a database and charge that to a

00:18:45,820 --> 00:18:49,659
project and I guess one interesting

00:18:48,250 --> 00:18:52,870
feature of that is once you have quotas

00:18:49,659 --> 00:18:55,030
it becomes an easy mechanism with which

00:18:52,870 --> 00:18:57,309
you can handle elastic demand on your

00:18:55,030 --> 00:18:59,620
cluster so in our cluster in northern

00:18:57,309 --> 00:19:01,870
Sweden if it's highly loaded the price

00:18:59,620 --> 00:19:04,000
goes up and if it slowly load the price

00:19:01,870 --> 00:19:06,309
goes down and that way users can

00:19:04,000 --> 00:19:12,220
hopefully expand and shrink their demand

00:19:06,309 --> 00:19:14,110
based on the the time of day ok so I'm

00:19:12,220 --> 00:19:16,299
going to look at the the tooling that

00:19:14,110 --> 00:19:17,799
we've built around helps works or

00:19:16,299 --> 00:19:19,570
platform so we're building as I said

00:19:17,799 --> 00:19:22,870
before in our Hadoop distribution code

00:19:19,570 --> 00:19:25,390
helps to do and we added Casca blck

00:19:22,870 --> 00:19:28,120
stack and graph a Netflix TV and Jupiter

00:19:25,390 --> 00:19:30,850
as well as a plan and all of this is

00:19:28,120 --> 00:19:33,070
actually multi-tenant so you these

00:19:30,850 --> 00:19:34,870
services themselves some of them support

00:19:33,070 --> 00:19:38,320
authentication and authorization some of

00:19:34,870 --> 00:19:40,030
them don't we front them with reverse

00:19:38,320 --> 00:19:41,679
proxies so reverse proxy servers

00:19:40,030 --> 00:19:46,030
WebSocket proxies where we can do the

00:19:41,679 --> 00:19:48,850
actual access control as necessary but

00:19:46,030 --> 00:19:50,440
if you look at Kafka this is not easy to

00:19:48,850 --> 00:19:54,070
read so I'll do a demo

00:19:50,440 --> 00:19:56,760
instead you bit easier okay so let's go

00:19:54,070 --> 00:19:56,760
to Casca here

00:19:58,850 --> 00:20:11,659
there's a Crashdown either okay one

00:20:06,769 --> 00:20:19,159
second here so Google Chrome is appeared

00:20:11,659 --> 00:20:21,380
to crash let me try us now okay

00:20:19,159 --> 00:20:23,899
there's there's NetBeans decide to start

00:20:21,380 --> 00:20:26,240
me there one second okay

00:20:23,899 --> 00:20:27,799
here we go Kafka all right let me just

00:20:26,240 --> 00:20:31,370
make it I think it's a full screen thing

00:20:27,799 --> 00:20:33,080
this is a this is Kafka on in a project

00:20:31,370 --> 00:20:33,529
the project I created around called bit

00:20:33,080 --> 00:20:37,100
doors

00:20:33,529 --> 00:20:42,289
there goes NetBeans okay I admit I use

00:20:37,100 --> 00:20:44,809
NetBeans okay so what if you're you're

00:20:42,289 --> 00:20:47,149
running caster you you probably be using

00:20:44,809 --> 00:20:50,629
something like confluence Data Platform

00:20:47,149 --> 00:20:52,309
or maybe am or I am but you've probably

00:20:50,629 --> 00:20:54,169
familiar with the notion that topics

00:20:52,309 --> 00:20:55,190
typically have a scheme associated with

00:20:54,169 --> 00:20:58,820
them so if you're going to push data

00:20:55,190 --> 00:21:01,429
into a topic often it's useful to have a

00:20:58,820 --> 00:21:03,409
schema so we're supporting the same as

00:21:01,429 --> 00:21:05,659
confluent and Avro schema registry for

00:21:03,409 --> 00:21:08,600
topics so each topic let's say I create

00:21:05,659 --> 00:21:12,470
a topic here called Steve because he's a

00:21:08,600 --> 00:21:14,389
heckler down the back and I can pick a

00:21:12,470 --> 00:21:15,620
schema to associated with it and schemas

00:21:14,389 --> 00:21:18,769
can be versions of course you can

00:21:15,620 --> 00:21:20,990
upgrade them so so now we've basically

00:21:18,769 --> 00:21:22,340
created a topic now if your work at any

00:21:20,990 --> 00:21:23,750
other Hadoop platform that's a

00:21:22,340 --> 00:21:24,590
non-trivial thing to do you know you're

00:21:23,750 --> 00:21:27,320
going to probably talk to an

00:21:24,590 --> 00:21:29,090
administrator to do it for you to give

00:21:27,320 --> 00:21:31,820
access to other people outside of this

00:21:29,090 --> 00:21:33,649
project the ability to read or write to

00:21:31,820 --> 00:21:36,679
that topic would also be a painful

00:21:33,649 --> 00:21:39,350
experience in our case I can just select

00:21:36,679 --> 00:21:41,570
another project and that project can

00:21:39,350 --> 00:21:42,830
then so the project of crater there on

00:21:41,570 --> 00:21:45,259
that project

00:21:42,830 --> 00:21:47,870
hello can now read or write to that

00:21:45,259 --> 00:21:50,870
topic if I wanted to get more funky with

00:21:47,870 --> 00:21:55,009
the permissions I can get into the ACLs

00:21:50,870 --> 00:21:56,570
that are supported by confluent it was

00:21:55,009 --> 00:21:58,250
actually part of casket sales much as

00:21:56,570 --> 00:22:00,049
confluent but typically we've never

00:21:58,250 --> 00:22:01,820
experienced anyone once actually get

00:22:00,049 --> 00:22:03,049
that low-level alright so you can you

00:22:01,820 --> 00:22:06,159
can do quite a lot with these simple

00:22:03,049 --> 00:22:10,159
abstractions of data owner data

00:22:06,159 --> 00:22:11,629
scientist and then sharing topics across

00:22:10,159 --> 00:22:12,650
projects so if I go back to the low

00:22:11,629 --> 00:22:15,290
project will see the

00:22:12,650 --> 00:22:16,880
that topic appears in here so Steve so

00:22:15,290 --> 00:22:20,690
now I can write projects that can access

00:22:16,880 --> 00:22:27,050
that particular project if any questions

00:22:20,690 --> 00:22:29,090
just shout or heckle the school okay so

00:22:27,050 --> 00:22:31,760
the summer experience with working with

00:22:29,090 --> 00:22:34,220
Kafka on spark streaming or link it

00:22:31,760 --> 00:22:35,420
doesn't really matter is that if you're

00:22:34,220 --> 00:22:36,770
going to provide a self-service you

00:22:35,420 --> 00:22:38,270
right the question is what do you want

00:22:36,770 --> 00:22:39,620
users to be able to change what do you

00:22:38,270 --> 00:22:41,150
want them to be able to optimize there's

00:22:39,620 --> 00:22:42,800
lots of things in Kafka you can change

00:22:41,150 --> 00:22:45,830
you can change data retention periods

00:22:42,800 --> 00:22:47,690
you have quotas now recently in casco

00:22:45,830 --> 00:22:49,070
where you can specify the amount of data

00:22:47,690 --> 00:22:52,040
that can be read and written from a

00:22:49,070 --> 00:22:54,140
topic basically we're only providing two

00:22:52,040 --> 00:22:56,330
metrics they can tune one is how many

00:22:54,140 --> 00:22:58,190
topics do I have in my project and then

00:22:56,330 --> 00:22:59,960
how many partitions do I have per topic

00:22:58,190 --> 00:23:01,670
and you can go a long way with this so

00:22:59,960 --> 00:23:03,980
typically if you're building a streaming

00:23:01,670 --> 00:23:05,480
app often you will try and match the

00:23:03,980 --> 00:23:07,220
number of executors with the number of

00:23:05,480 --> 00:23:08,930
partitions that's a pretty

00:23:07,220 --> 00:23:10,130
straightforward thing to do and then you

00:23:08,930 --> 00:23:11,600
want to make sure that the data that

00:23:10,130 --> 00:23:12,890
you're reading and writing or your

00:23:11,600 --> 00:23:15,320
writing that's being written to your

00:23:12,890 --> 00:23:17,450
topics is balanced across the the

00:23:15,320 --> 00:23:18,770
partitions so that no executors are

00:23:17,450 --> 00:23:20,240
doing a lot more work than other

00:23:18,770 --> 00:23:22,730
executors that you won't like some

00:23:20,240 --> 00:23:24,080
balance there so if users get that prior

00:23:22,730 --> 00:23:26,030
that they can do this and they still

00:23:24,080 --> 00:23:28,040
need further optimization then you can

00:23:26,030 --> 00:23:30,650
do it offline once with an administrator

00:23:28,040 --> 00:23:32,210
but typically this is we found that this

00:23:30,650 --> 00:23:36,320
is enough to give users for for

00:23:32,210 --> 00:23:38,810
self-service so logging was the next

00:23:36,320 --> 00:23:41,450
thing that I mention that the yarn if

00:23:38,810 --> 00:23:44,150
you work on yarn as your cluster manager

00:23:41,450 --> 00:23:46,040
and we we use yarn and if you're running

00:23:44,150 --> 00:23:47,720
a spark streaming or a flink straining

00:23:46,040 --> 00:23:50,150
job and it's writing to your logs and

00:23:47,720 --> 00:23:51,590
yarn they will only get aggregated when

00:23:50,150 --> 00:23:53,270
the application completes

00:23:51,590 --> 00:23:56,150
so an application finishes and that's

00:23:53,270 --> 00:23:57,950
pretty useless if you're in it in the

00:23:56,150 --> 00:24:00,290
yarn environment because you want to get

00:23:57,950 --> 00:24:02,150
the logs that they're being produced so

00:24:00,290 --> 00:24:03,860
what you need to do is you need to add

00:24:02,150 --> 00:24:05,900
some kind of support for collecting logs

00:24:03,860 --> 00:24:07,340
and we looked at a bunch of different

00:24:05,900 --> 00:24:09,560
ways of doing it and we we ended up

00:24:07,340 --> 00:24:11,870
looking at log stash elastic in Cabana

00:24:09,560 --> 00:24:14,030
and the way to do it if you're writing a

00:24:11,870 --> 00:24:16,040
simple spark application is you we ought

00:24:14,030 --> 00:24:18,410
to configure log4j and spark for example

00:24:16,040 --> 00:24:19,790
that will just like to log stash so the

00:24:18,410 --> 00:24:22,430
user doesn't even need to think about it

00:24:19,790 --> 00:24:25,550
they just still log4j info or to Vogue

00:24:22,430 --> 00:24:26,220
and it ends up in in in their particular

00:24:25,550 --> 00:24:28,970
logs

00:24:26,220 --> 00:24:31,500
that will see an example of later on

00:24:28,970 --> 00:24:33,890
okay it kind of looks like that and I'll

00:24:31,500 --> 00:24:38,400
do to do a demo of asana in a minute

00:24:33,890 --> 00:24:40,080
then the other one is monitoring so if

00:24:38,400 --> 00:24:42,000
you're familiar with SPARC this is first

00:24:40,080 --> 00:24:43,950
Park in particular it is quite good

00:24:42,000 --> 00:24:46,260
support for for monitoring you can

00:24:43,950 --> 00:24:48,780
supply metrics our properties file when

00:24:46,260 --> 00:24:50,340
you launch a spark job and what the

00:24:48,780 --> 00:24:53,669
SPARC job will do is it will write its

00:24:50,340 --> 00:24:56,640
metrics so things like related to the

00:24:53,669 --> 00:24:57,929
JVM a heap size usage you can you can

00:24:56,640 --> 00:25:00,570
extend it to your own add your own

00:24:57,929 --> 00:25:02,370
custom metrics as well but basically you

00:25:00,570 --> 00:25:03,900
can configure it to write to JMX graph

00:25:02,370 --> 00:25:06,510
ice or to serve let's see a sphere

00:25:03,900 --> 00:25:08,809
console or even a large output so in our

00:25:06,510 --> 00:25:11,429
case we're writing to a graphite sink

00:25:08,809 --> 00:25:13,530
plane graphite is actually just in flux

00:25:11,429 --> 00:25:17,190
DB so there's no graphics or where it's

00:25:13,530 --> 00:25:19,500
just an infix DB server the other ways

00:25:17,190 --> 00:25:21,030
of getting doing resource monitoring

00:25:19,500 --> 00:25:23,940
through applications at least in spark

00:25:21,030 --> 00:25:26,850
in the latest version is you can for any

00:25:23,940 --> 00:25:28,650
given spark application a structured

00:25:26,850 --> 00:25:31,039
streaming application you can write a

00:25:28,650 --> 00:25:33,570
structured query listener and that can

00:25:31,039 --> 00:25:36,240
for example write to casket if you want

00:25:33,570 --> 00:25:40,140
as well and you can inspect from a

00:25:36,240 --> 00:25:42,750
casket topic or you can write to again

00:25:40,140 --> 00:25:45,299
the same graphite sink if you running

00:25:42,750 --> 00:25:46,799
many queries within a single spark

00:25:45,299 --> 00:25:49,110
session so many structured streaming

00:25:46,799 --> 00:25:51,780
creator the same session you can use the

00:25:49,110 --> 00:25:55,470
streaming query listener to do something

00:25:51,780 --> 00:25:59,900
similar okay I'll do demo this in a

00:25:55,470 --> 00:26:03,030
second and then we do support notebooks

00:25:59,900 --> 00:26:05,039
it may not seem relevant but you know at

00:26:03,030 --> 00:26:06,900
some level you're going to somehow do an

00:26:05,039 --> 00:26:10,230
analysis of the data coming out so you

00:26:06,900 --> 00:26:13,620
may have a database or you may use Kafka

00:26:10,230 --> 00:26:15,870
as a sink and from there then you serve

00:26:13,620 --> 00:26:17,159
your data to your to your users but you

00:26:15,870 --> 00:26:20,220
can also do quite a lot with just

00:26:17,159 --> 00:26:22,289
appling and Jupiter and we support both

00:26:20,220 --> 00:26:23,610
of them so Jupiter it just to give you

00:26:22,289 --> 00:26:25,919
an idea of the kind of challenges you

00:26:23,610 --> 00:26:29,100
have with supporting a notebook this is

00:26:25,919 --> 00:26:32,400
a web application and if you allow users

00:26:29,100 --> 00:26:35,399
to run spark in client mode or think for

00:26:32,400 --> 00:26:38,119
that matter and what will happen is that

00:26:35,399 --> 00:26:40,339
they can launch drivers on the same sir

00:26:38,119 --> 00:26:41,899
as your web application server and if

00:26:40,339 --> 00:26:44,479
you run a workshop with 30 or 40 people

00:26:41,899 --> 00:26:46,669
and they're all running drivers with 4 8

00:26:44,479 --> 00:26:49,339
gigabytes then you can have trouble and

00:26:46,669 --> 00:26:52,459
we did to begin with so what we did was

00:26:49,339 --> 00:26:55,069
we moved over to using a rest server in

00:26:52,459 --> 00:26:57,109
particular for spark called Livi so the

00:26:55,069 --> 00:26:58,669
driver is never launched locally on the

00:26:57,109 --> 00:27:01,669
web application server instead it's

00:26:58,669 --> 00:27:03,739
launched on the iron cluster and if you

00:27:01,669 --> 00:27:06,019
are familiar with Jupiter there's a

00:27:03,739 --> 00:27:08,119
kernel called spark magic that windows

00:27:06,019 --> 00:27:10,549
azure uses we're using the same one and

00:27:08,119 --> 00:27:12,739
but then we had some issues in both in

00:27:10,549 --> 00:27:15,079
Zeppelin and Jupiter related to how can

00:27:12,739 --> 00:27:16,999
we get our notebooks to be you know

00:27:15,079 --> 00:27:18,979
visible across to all users and across

00:27:16,999 --> 00:27:21,319
all instances of our web application and

00:27:18,979 --> 00:27:25,339
the simple solution is to put them in

00:27:21,319 --> 00:27:27,229
HDFS but there was no content manager

00:27:25,339 --> 00:27:29,689
for Jupiter of HDFS we wrote one and the

00:27:27,229 --> 00:27:31,849
same goes for for Zeppelin so that code

00:27:29,689 --> 00:27:34,149
is available if you're interested in

00:27:31,849 --> 00:27:36,649
github

00:27:34,149 --> 00:27:39,019
okay so Livi kind of looks like this you

00:27:36,649 --> 00:27:40,849
know you basically a REST API and then

00:27:39,019 --> 00:27:44,149
in our case the Jupiter kernel or the

00:27:40,849 --> 00:27:49,399
the Zeppelin interpreter talk to Livia

00:27:44,149 --> 00:27:50,959
and run the Jobson errand yarn okay

00:27:49,399 --> 00:27:52,759
let's go back and have a quick look at

00:27:50,959 --> 00:27:59,089
some of those things that I was talking

00:27:52,759 --> 00:28:02,589
about right so I'm going to do a tour I

00:27:59,089 --> 00:28:07,639
think just to generate some of them here

00:28:02,589 --> 00:28:10,069
so I'll do a calf Couture because this

00:28:07,639 --> 00:28:11,869
is both a bit streaming so what I

00:28:10,069 --> 00:28:13,249
clicked on will start the tour we have a

00:28:11,869 --> 00:28:16,459
number of tours rogue we're going to add

00:28:13,249 --> 00:28:17,959
more tours you can see we have tours for

00:28:16,459 --> 00:28:20,739
spark and Casca there but I'm going to

00:28:17,959 --> 00:28:23,059
do the the casket or just to begin with

00:28:20,739 --> 00:28:25,069
so what it's doing I'm just going to

00:28:23,059 --> 00:28:27,049
click Next and follow along it's going

00:28:25,069 --> 00:28:28,759
to create a schema for me an avro schema

00:28:27,049 --> 00:28:30,499
it's just filled one in for me there

00:28:28,759 --> 00:28:32,569
it's going to validate the schema that's

00:28:30,499 --> 00:28:34,279
done and now it's going to create a

00:28:32,569 --> 00:28:36,769
topic I did this already so I'm just

00:28:34,279 --> 00:28:38,449
going to click through it you can change

00:28:36,769 --> 00:28:40,249
number of partitions there and now it's

00:28:38,449 --> 00:28:42,229
going to create a job so firstly it's

00:28:40,249 --> 00:28:43,579
going to create a in this case it's

00:28:42,229 --> 00:28:45,469
going to be a spark producer it's going

00:28:43,579 --> 00:28:46,389
to write to that casket topic that I

00:28:45,469 --> 00:28:48,799
created

00:28:46,389 --> 00:28:51,000
it's just picking out a jar file from

00:28:48,799 --> 00:28:53,760
the hdfs there

00:28:51,000 --> 00:28:55,289
that jar file actually had the classpath

00:28:53,760 --> 00:28:57,299
in its manifest so it picked that out

00:28:55,289 --> 00:29:00,360
and then these are the configuration

00:28:57,299 --> 00:29:02,539
parameters for free yarn such that one's

00:29:00,360 --> 00:29:07,679
creators now going to create a consumer

00:29:02,539 --> 00:29:10,409
it consumer name the jar file and then

00:29:07,679 --> 00:29:12,390
the name of the class and you can see

00:29:10,409 --> 00:29:14,100
here we have the an argument to call

00:29:12,390 --> 00:29:16,919
consumer all this code is on github if

00:29:14,100 --> 00:29:19,650
you're curious and then I'm going to run

00:29:16,919 --> 00:29:21,870
us okay so I'll just run the this is our

00:29:19,650 --> 00:29:24,570
pricing model that I mentioned the one X

00:29:21,870 --> 00:29:26,730
and then I'm going to launch the

00:29:24,570 --> 00:29:30,720
consumer so it's still one X o'clock

00:29:26,730 --> 00:29:34,799
white lower load ok so they're running

00:29:30,720 --> 00:29:36,860
now let me just show you the UI so when

00:29:34,799 --> 00:29:39,510
the job starts running you can basically

00:29:36,860 --> 00:29:41,100
inspect the spark UI for your job you

00:29:39,510 --> 00:29:44,460
can go to yarn to have a look at the job

00:29:41,100 --> 00:29:48,120
you can go to cabana to have a look at

00:29:44,460 --> 00:29:49,500
the loads being written in what's

00:29:48,120 --> 00:29:51,809
interesting with Cubana actually is that

00:29:49,500 --> 00:29:53,190
if you if you can't use cabana to do

00:29:51,809 --> 00:29:54,840
graphing you know you can use log for

00:29:53,190 --> 00:29:55,950
data just to write out some state that

00:29:54,840 --> 00:29:58,909
you're interested in your application

00:29:55,950 --> 00:30:01,620
and then you can just visualize this by

00:29:58,909 --> 00:30:05,220
using built in visualization tools in

00:30:01,620 --> 00:30:07,350
cabana and then we have metrics there's

00:30:05,220 --> 00:30:08,940
not that many metrics on this side but

00:30:07,350 --> 00:30:10,230
there's more on the consumer so I can go

00:30:08,940 --> 00:30:12,630
back to the consumer and see our

00:30:10,230 --> 00:30:14,820
consumers running here in this case this

00:30:12,630 --> 00:30:16,020
is SPARC structured streaming so you're

00:30:14,820 --> 00:30:18,120
going to you're going to have this SQL

00:30:16,020 --> 00:30:20,400
tab in SPARC structured streaming that

00:30:18,120 --> 00:30:23,429
you don't have in normal streaming and

00:30:20,400 --> 00:30:25,020
then the metrics if I go back we can see

00:30:23,429 --> 00:30:27,320
here you can see a bunch of executors

00:30:25,020 --> 00:30:29,309
have run and they've written to HDFS and

00:30:27,320 --> 00:30:32,789
what this is done actually in this

00:30:29,309 --> 00:30:35,429
example it's writing to a park a file

00:30:32,789 --> 00:30:39,330
that's this one here or is it this one

00:30:35,429 --> 00:30:42,659
here and so this this has basically a

00:30:39,330 --> 00:30:45,090
bunch of parque files in there so I

00:30:42,659 --> 00:30:46,559
could go and run it on Zeppelin but I've

00:30:45,090 --> 00:30:48,059
run it earlier I'm running out of time

00:30:46,559 --> 00:30:50,520
so I'll just show you what I did or oh

00:30:48,059 --> 00:30:53,070
that was on the crashed okay let's go

00:30:50,520 --> 00:30:56,360
back here I can log in as admin here I

00:30:53,070 --> 00:30:56,360
guess it's a design user here

00:30:58,690 --> 00:31:04,359
okay there wasn't that user other this

00:31:00,909 --> 00:31:12,879
different user that too many accounts on

00:31:04,359 --> 00:31:14,739
here okay so yeah just pull this one up

00:31:12,879 --> 00:31:18,190
so this is basically doing analytics on

00:31:14,739 --> 00:31:19,989
the on the the parks which structured

00:31:18,190 --> 00:31:21,999
streaming file as the data is coming in

00:31:19,989 --> 00:31:23,830
and you can you can even do an eigen

00:31:21,999 --> 00:31:26,799
angular front-end to refresh that if you

00:31:23,830 --> 00:31:28,119
want to while it's going in okay I want

00:31:26,799 --> 00:31:30,929
to just talk a little because I have

00:31:28,119 --> 00:31:33,399
only a few minutes left to talk about an

00:31:30,929 --> 00:31:36,399
API we've added here to make it easier

00:31:33,399 --> 00:31:38,679
to write streaming applications here we

00:31:36,399 --> 00:31:40,330
go okay so this is a simple spark

00:31:38,679 --> 00:31:41,559
structured streaming program you'll see

00:31:40,330 --> 00:31:42,039
here you'll see it on the data breaks

00:31:41,559 --> 00:31:44,109
blog

00:31:42,039 --> 00:31:45,700
it basically says you need to have a

00:31:44,109 --> 00:31:48,309
query you need to have an input source

00:31:45,700 --> 00:31:49,960
and I put sync and you need to trigger

00:31:48,309 --> 00:31:51,519
the query periodically you need to say

00:31:49,960 --> 00:31:52,809
where you can write your check points to

00:31:51,519 --> 00:31:54,759
and you think okay that's a nice example

00:31:52,809 --> 00:31:57,759
but there's quite a lot of stuff missing

00:31:54,759 --> 00:31:59,289
from us for example you know where's the

00:31:57,759 --> 00:32:00,729
camp where the endpoint - Kafka

00:31:59,289 --> 00:32:02,249
what are my credentials for connecting

00:32:00,729 --> 00:32:04,899
to Kali I'm going to do this securely

00:32:02,249 --> 00:32:06,039
automated schema registry endpoint how

00:32:04,899 --> 00:32:07,690
do i shut down the application

00:32:06,039 --> 00:32:09,190
gracefully where do I get my monitoring

00:32:07,690 --> 00:32:10,330
their properties files so actually what

00:32:09,190 --> 00:32:13,179
we're doing is hiding all of this

00:32:10,330 --> 00:32:14,349
complexity inside an API so all that

00:32:13,179 --> 00:32:16,029
code that you would write here on the

00:32:14,349 --> 00:32:18,009
left the framework knows about all of

00:32:16,029 --> 00:32:19,779
these things it knows the locations it

00:32:18,009 --> 00:32:21,879
has a service registry it knows about

00:32:19,779 --> 00:32:25,419
the certificates it's copied the

00:32:21,879 --> 00:32:28,450
certificates out to the to the tasks to

00:32:25,419 --> 00:32:29,409
the tasks in spark and the yarn is going

00:32:28,450 --> 00:32:31,090
to clean them up when they're when

00:32:29,409 --> 00:32:32,799
finished so basically all you need to do

00:32:31,090 --> 00:32:34,720
is say get me a spark producer or flink

00:32:32,799 --> 00:32:36,609
producer and then you can work with it

00:32:34,720 --> 00:32:38,830
and the same goes for the for the

00:32:36,609 --> 00:32:40,299
consumer so the consumer will be look

00:32:38,830 --> 00:32:42,609
pretty simple so your programs will come

00:32:40,299 --> 00:32:43,960
quite nice and straightforward but

00:32:42,609 --> 00:32:45,340
they're more production ready and that

00:32:43,960 --> 00:32:48,129
they're handling security and now you're

00:32:45,340 --> 00:32:52,080
considering all the services that you're

00:32:48,129 --> 00:32:55,149
going to use as syncs and you know these

00:32:52,080 --> 00:33:00,399
schema registry and can cast a broker

00:32:55,149 --> 00:33:01,629
and so on so the platform we have a lot

00:33:00,399 --> 00:33:03,789
of people working on this in a decent

00:33:01,629 --> 00:33:06,309
stop government we're going to produce

00:33:03,789 --> 00:33:07,269
quite a few new features in the next few

00:33:06,309 --> 00:33:09,190
months I'll just give you an

00:33:07,269 --> 00:33:11,510
introduction to a couple of them they're

00:33:09,190 --> 00:33:12,890
mostly aimed at data scientists so now

00:33:11,510 --> 00:33:14,810
streaming so reduce interest in

00:33:12,890 --> 00:33:17,690
streaming this may not be as relevant

00:33:14,810 --> 00:33:19,850
for you one of them is sharing of

00:33:17,690 --> 00:33:21,200
datasets globally so if you have image

00:33:19,850 --> 00:33:22,970
in that for example which is a large

00:33:21,200 --> 00:33:25,550
data set of several hundred gigabytes

00:33:22,970 --> 00:33:26,840
and you'd like to get access to it what

00:33:25,550 --> 00:33:28,940
we'll have here is a way for you to

00:33:26,840 --> 00:33:31,730
search for that and just download it to

00:33:28,940 --> 00:33:33,140
your house works cluster and if you have

00:33:31,730 --> 00:33:34,610
your own data set you're interested in

00:33:33,140 --> 00:33:36,170
and you want to publish it make it

00:33:34,610 --> 00:33:37,880
available to people you just right click

00:33:36,170 --> 00:33:39,410
on publish it and it will become

00:33:37,880 --> 00:33:42,380
available for anyone else's to search

00:33:39,410 --> 00:33:45,920
for so it's basically open data which

00:33:42,380 --> 00:33:47,720
they do back end we hope that people in

00:33:45,920 --> 00:33:49,610
ten surfer will look at assist well

00:33:47,720 --> 00:33:52,670
because we have no support for GP you as

00:33:49,610 --> 00:33:54,350
a resource in yarn we're supporting

00:33:52,670 --> 00:33:56,510
tensorflow on SPARC and then we have

00:33:54,350 --> 00:34:01,130
also distributed native tensorflow

00:33:56,510 --> 00:34:03,230
version running our file system we've

00:34:01,130 --> 00:34:05,450
lots of things going on one of them is

00:34:03,230 --> 00:34:09,020
putting the small files in HDFS which is

00:34:05,450 --> 00:34:10,700
a quite a source of a lot of problems

00:34:09,020 --> 00:34:12,440
for a lot of people we're putting it in

00:34:10,700 --> 00:34:13,760
the database so any file under a

00:34:12,440 --> 00:34:16,220
kilobyte will be in memory in the

00:34:13,760 --> 00:34:18,910
database and files between one kilobyte

00:34:16,220 --> 00:34:21,830
and 32 kilobytes were storing on SSD and

00:34:18,910 --> 00:34:23,830
the database supports on column disk so

00:34:21,830 --> 00:34:27,260
that's basically how we're doing is

00:34:23,830 --> 00:34:28,640
we're also supporting we're working on

00:34:27,260 --> 00:34:30,800
this isn't finished work but we're

00:34:28,640 --> 00:34:33,170
working on making the filesystem highly

00:34:30,800 --> 00:34:36,740
available across availability zones so

00:34:33,170 --> 00:34:38,870
if you want to run this on Amazon and

00:34:36,740 --> 00:34:41,960
you would like to be resilient to it a

00:34:38,870 --> 00:34:43,550
whole availability zone crashing this

00:34:41,960 --> 00:34:45,740
might be of interest to you similarly if

00:34:43,550 --> 00:34:47,060
you're running on Prem and you have two

00:34:45,740 --> 00:34:49,340
big clusters and you'd like to replicate

00:34:47,060 --> 00:34:52,220
across and then this may also be of

00:34:49,340 --> 00:34:55,490
interest to you another thing that we've

00:34:52,220 --> 00:34:57,950
done is related to the file system again

00:34:55,490 --> 00:34:59,810
is that we have support for hive and the

00:34:57,950 --> 00:35:01,970
hive metadata is typically you'll see in

00:34:59,810 --> 00:35:04,370
a my sequel database well we're already

00:35:01,970 --> 00:35:06,140
using in my sequel database so what we

00:35:04,370 --> 00:35:08,960
did was we added foreign keys from the

00:35:06,140 --> 00:35:12,140
hive metadata to the backing files in

00:35:08,960 --> 00:35:13,760
HDFS and what that means is in practice

00:35:12,140 --> 00:35:15,290
I don't know if you can see it here but

00:35:13,760 --> 00:35:18,800
there's two tables here one is called

00:35:15,290 --> 00:35:20,780
websites and web sales and what happens

00:35:18,800 --> 00:35:23,120
if I do this and the command line if I

00:35:20,780 --> 00:35:25,520
go to HDFS and remove the website web

00:35:23,120 --> 00:35:28,160
sales subtree but if you did that in

00:35:25,520 --> 00:35:29,780
normal hive your hive will be broken but

00:35:28,160 --> 00:35:31,070
in our case it's just automatically

00:35:29,780 --> 00:35:33,290
cleaned up because we have strong

00:35:31,070 --> 00:35:37,340
consistency now for the hive meta data

00:35:33,290 --> 00:35:39,610
so that's what foreign keys give us ok

00:35:37,340 --> 00:35:42,260
so that's that's basically yes we have

00:35:39,610 --> 00:35:43,550
ocular Europe's only Hadoop distribution

00:35:42,260 --> 00:35:45,800
perhaps the dupe it's completely

00:35:43,550 --> 00:35:48,200
open-source everything all Apache

00:35:45,800 --> 00:35:49,850
licensed and it's not just there for

00:35:48,200 --> 00:35:53,480
bigger and faster clusters we're also

00:35:49,850 --> 00:35:55,340
building a data platform and in that

00:35:53,480 --> 00:35:57,320
platform we're adding first-class

00:35:55,340 --> 00:35:59,360
support for streaming and Python amongst

00:35:57,320 --> 00:36:00,620
other things and we're agnostic to

00:35:59,360 --> 00:36:03,920
whether you're interested in flicker

00:36:00,620 --> 00:36:05,660
spark we love both of them so lots of

00:36:03,920 --> 00:36:07,690
people worked on the project this is

00:36:05,660 --> 00:36:09,980
there's some of them sitting down here

00:36:07,690 --> 00:36:12,080
and we have a bunch of users and

00:36:09,980 --> 00:36:14,030
customers and if you're interested in

00:36:12,080 --> 00:36:16,130
the project you can if you're incident

00:36:14,030 --> 00:36:17,600
contributing just talk to me interested

00:36:16,130 --> 00:36:19,700
in doing research on the platform that's

00:36:17,600 --> 00:36:24,350
great you can also just follow us on

00:36:19,700 --> 00:36:29,590
Twitter like us on github or just talk

00:36:24,350 --> 00:36:29,590
to us on on slack thank you

00:36:29,680 --> 00:36:34,459
[Music]

00:36:35,690 --> 00:36:51,089
we do have time for one maybe two

00:36:38,339 --> 00:36:53,039
questions I actually have one under

00:36:51,089 --> 00:36:56,789
health questions so our first question

00:36:53,039 --> 00:36:58,920
is since you want to abstract away some

00:36:56,789 --> 00:37:02,460
of those nitty gritty details and try to

00:36:58,920 --> 00:37:04,079
provide this UI where everything does

00:37:02,460 --> 00:37:05,789
right you've solved already a number of

00:37:04,079 --> 00:37:08,400
things like the logging so that they

00:37:05,789 --> 00:37:12,240
have access to things are you also

00:37:08,400 --> 00:37:14,130
thinking about perhaps using beam as an

00:37:12,240 --> 00:37:17,609
abstraction layer for for the

00:37:14,130 --> 00:37:19,109
programming since I think it would

00:37:17,609 --> 00:37:20,549
complement because you have solved some

00:37:19,109 --> 00:37:24,450
of those operational things that are

00:37:20,549 --> 00:37:26,130
around it now why not let users also get

00:37:24,450 --> 00:37:28,650
a little bit away from those native

00:37:26,130 --> 00:37:30,539
interfaces and then the other thing I

00:37:28,650 --> 00:37:34,260
just wanted to have confirmation you can

00:37:30,539 --> 00:37:37,140
deploy this on cloud and on cram it's

00:37:34,260 --> 00:37:38,520
completely open source yes we expect

00:37:37,140 --> 00:37:40,200
when we have automated support for

00:37:38,520 --> 00:37:42,359
installing this with chef and we have a

00:37:40,200 --> 00:37:44,190
tool called caramel you can click your

00:37:42,359 --> 00:37:46,260
way to an Amazon cluster it's a bit four

00:37:44,190 --> 00:37:48,960
clicks I think if you're doing it on

00:37:46,260 --> 00:37:51,900
prime you just have to have your cluster

00:37:48,960 --> 00:37:53,789
set up with SSH access into machines and

00:37:51,900 --> 00:37:55,289
then this caramel which is nor

00:37:53,789 --> 00:37:57,900
castration tool for chef will run all

00:37:55,289 --> 00:37:59,760
the chef's cookbooks on the other point

00:37:57,900 --> 00:38:01,950
beam we actually we implemented the

00:37:59,760 --> 00:38:04,440
interpreter for beam in Zeppelin because

00:38:01,950 --> 00:38:06,480
we wanted beam as a first-class we

00:38:04,440 --> 00:38:08,339
believed in blame I wasn't saying we

00:38:06,480 --> 00:38:09,900
don't believe in it anymore but we

00:38:08,339 --> 00:38:12,029
weren't primarily looking at beam on

00:38:09,900 --> 00:38:14,940
flink now if you're familiar with being

00:38:12,029 --> 00:38:16,710
on slink you'll know that and it only

00:38:14,940 --> 00:38:18,359
runs in what's called attached mode that

00:38:16,710 --> 00:38:21,420
means that the same client has to be

00:38:18,359 --> 00:38:22,980
attached well being runs there and it

00:38:21,420 --> 00:38:24,869
doesn't work in detached mode now the

00:38:22,980 --> 00:38:27,180
run would attach mode is that if we were

00:38:24,869 --> 00:38:30,180
to run that then we have to think big

00:38:27,180 --> 00:38:32,099
bunch of jars or dependencies including

00:38:30,180 --> 00:38:34,079
nettie which is a different version

00:38:32,099 --> 00:38:36,539
which conflicts with our version so we

00:38:34,079 --> 00:38:39,480
can't run think in attached mode as it

00:38:36,539 --> 00:38:41,520
currently stands there is a Jireh flip

00:38:39,480 --> 00:38:43,609
on going for fling to provide a REST API

00:38:41,520 --> 00:38:45,960
for yarn which would solve this for us

00:38:43,609 --> 00:38:47,550
but it's not the area so we'll add it

00:38:45,960 --> 00:38:50,220
when it's there

00:38:47,550 --> 00:38:51,780
apex sure we could do the same thing you

00:38:50,220 --> 00:38:54,090
know it's not it's not much work to add

00:38:51,780 --> 00:38:55,500
support for for being to our platform

00:38:54,090 --> 00:38:57,180
it's quite you know it's quite

00:38:55,500 --> 00:39:00,540
straightforward I'm jiggly apex would be

00:38:57,180 --> 00:39:04,430
easy enough so we gladly accept peers

00:39:00,540 --> 00:39:04,430
and contributions we would love that

00:39:05,060 --> 00:39:10,619
okay um first we're going to have a

00:39:08,400 --> 00:39:12,270
break and I'll have an hour break you

00:39:10,619 --> 00:39:13,980
feel free to stay here and continue the

00:39:12,270 --> 00:39:15,630
discussion but officially thank you Jim

00:39:13,980 --> 00:39:22,769
for the presentation

00:39:15,630 --> 00:39:22,769

YouTube URL: https://www.youtube.com/watch?v=fNeks6JdrrE


