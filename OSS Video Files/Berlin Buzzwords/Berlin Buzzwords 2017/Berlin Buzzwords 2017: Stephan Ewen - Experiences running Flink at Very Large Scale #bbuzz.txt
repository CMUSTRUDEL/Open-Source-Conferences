Title: Berlin Buzzwords 2017: Stephan Ewen - Experiences running Flink at Very Large Scale #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	This talk shares experiences from deploying and tuning Flink steam processing applications for very large scale. We share lessons learned from users, contributors, and our own experiments about running demanding streaming jobs at scale. 

The talk will explain what aspects currently render a job as particularly demanding, show how to configure and tune a large scale Flink job, and outline what the Flink community is working on to make the out-of-the-box for experience as smooth as possible. We will, for example, dive into - analyzing and tuning checkpointing - selecting and configuring state backends - understanding common bottlenecks - understanding and configuring network parameters.

Read more:
https://2017.berlinbuzzwords.de/17/session/experiences-running-flink-very-large-scale

About Stephan Ewen:
https://2017.berlinbuzzwords.de/users/stephan-ewen

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,480 --> 00:00:12,710
one is kind of how they started viewing

00:00:09,650 --> 00:00:14,510
Apache chief link and the second one

00:00:12,710 --> 00:00:16,790
like what what were the things they

00:00:14,510 --> 00:00:18,200
figured out are important to pay

00:00:16,790 --> 00:00:21,950
attention to when you operate it at

00:00:18,200 --> 00:00:23,960
large scale so I'm some of the use cases

00:00:21,950 --> 00:00:25,279
that that these lessons learned are

00:00:23,960 --> 00:00:27,650
taking from here here are just a few

00:00:25,279 --> 00:00:29,029
that that I mentioned there they're more

00:00:27,650 --> 00:00:31,550
for which we've gathered that but here

00:00:29,029 --> 00:00:33,079
just a few from from which explicitly

00:00:31,550 --> 00:00:36,649
some of these lessons learned are taking

00:00:33,079 --> 00:00:39,820
so first one is we're working after a

00:00:36,649 --> 00:00:42,730
while now with with Netflix to establish

00:00:39,820 --> 00:00:44,840
infrastructure for for various use cases

00:00:42,730 --> 00:00:47,300
amongst that streaming streaming

00:00:44,840 --> 00:00:49,070
ingestion and modeling of user

00:00:47,300 --> 00:00:51,289
interaction sessions the interesting

00:00:49,070 --> 00:00:52,550
takeaway for us from that is both both

00:00:51,289 --> 00:00:54,559
in the in the way we've learned about

00:00:52,550 --> 00:00:56,089
what artifacts are what problems occur

00:00:54,559 --> 00:00:58,629
at scale especially because they're

00:00:56,089 --> 00:01:01,039
running everything on Amazon and the

00:00:58,629 --> 00:01:03,980
peculiarities of like the Amazon

00:01:01,039 --> 00:01:06,320
container engines and the and the

00:01:03,980 --> 00:01:08,690
behavior of s3 and so on and also

00:01:06,320 --> 00:01:09,950
because of the the types of jobs they're

00:01:08,690 --> 00:01:11,960
running which are an interesting mix of

00:01:09,950 --> 00:01:15,080
stateless jobs jobs with small States

00:01:11,960 --> 00:01:17,810
and jobs with very very large estate I'm

00:01:15,080 --> 00:01:19,000
just to give you an idea of what okay

00:01:17,810 --> 00:01:21,740
this looks it looks much better

00:01:19,000 --> 00:01:25,579
originally this is I think gets lost

00:01:21,740 --> 00:01:27,409
somewhere in the video cable like the

00:01:25,579 --> 00:01:31,130
the scale that this is that this is

00:01:27,409 --> 00:01:32,899
running is is quite quite significant

00:01:31,130 --> 00:01:36,229
it's running like link is running in in

00:01:32,899 --> 00:01:38,119
over 3,000 container images together

00:01:36,229 --> 00:01:41,810
with 4,000 kafka brokers and and

00:01:38,119 --> 00:01:43,310
hundreds of streams another of the use

00:01:41,810 --> 00:01:45,979
case is that that some of these lessons

00:01:43,310 --> 00:01:48,619
learned here are are taking from is is

00:01:45,979 --> 00:01:50,899
our collaboration with Alibaba Alibaba

00:01:48,619 --> 00:01:53,270
has a system called blink which is based

00:01:50,899 --> 00:01:56,689
on flink it's if you wish an adoption of

00:01:53,270 --> 00:01:58,789
link with with which is like more

00:01:56,689 --> 00:02:02,149
integrated with their with the way their

00:01:58,789 --> 00:02:02,600
yarn cluster is set up and so on and the

00:02:02,149 --> 00:02:04,609
way they were

00:02:02,600 --> 00:02:06,259
you know the integration with their you

00:02:04,609 --> 00:02:08,420
know operating metric system and all of

00:02:06,259 --> 00:02:10,429
that it's it's been when it started out

00:02:08,420 --> 00:02:11,690
a fairly significant difference from

00:02:10,429 --> 00:02:13,160
flink but now it's a very small

00:02:11,690 --> 00:02:15,110
difference from language sort of works

00:02:13,160 --> 00:02:18,170
very hard together with them to kind of

00:02:15,110 --> 00:02:19,640
merge merge most of the two systems so

00:02:18,170 --> 00:02:21,090
they're they're very similar these state

00:02:19,640 --> 00:02:23,580
today

00:02:21,090 --> 00:02:26,220
and yeah the the scale that they're

00:02:23,580 --> 00:02:28,620
running this on is probably even even

00:02:26,220 --> 00:02:29,700
even larger so they're they're single

00:02:28,620 --> 00:02:31,410
fling jobs running on more than

00:02:29,700 --> 00:02:33,480
thousands of notes with tens of

00:02:31,410 --> 00:02:36,209
terabytes of like in in process state

00:02:33,480 --> 00:02:39,209
and one of the really cool things that

00:02:36,209 --> 00:02:41,069
this thing thing does is when when

00:02:39,209 --> 00:02:42,599
there's this crazy shopping holiday in

00:02:41,069 --> 00:02:44,160
China called the singles day which is

00:02:42,599 --> 00:02:47,580
roughly like the Chinese equivalent of

00:02:44,160 --> 00:02:49,890
the Black Friday but in the US and the

00:02:47,580 --> 00:02:52,110
the real time like the real time search

00:02:49,890 --> 00:02:54,090
optimization to figure out which which

00:02:52,110 --> 00:02:55,769
products should be you know ranked up

00:02:54,090 --> 00:02:57,209
and down and so on depending on on

00:02:55,769 --> 00:02:59,069
trends and so on sexually running on

00:02:57,209 --> 00:03:02,730
this on this stream computation system

00:02:59,069 --> 00:03:05,010
which is which is pretty significant and

00:03:02,730 --> 00:03:07,080
and one other use case ad that we've

00:03:05,010 --> 00:03:08,370
taken a few interesting lessons learned

00:03:07,080 --> 00:03:10,799
from especially for the first section

00:03:08,370 --> 00:03:14,640
like how do we use path link these days

00:03:10,799 --> 00:03:16,980
arm is from um from that use case it's a

00:03:14,640 --> 00:03:19,620
social network called Drive trap but the

00:03:16,980 --> 00:03:23,430
other guys that used to do top gear now

00:03:19,620 --> 00:03:25,650
do the Grand Tour and they their team

00:03:23,430 --> 00:03:27,239
has obviously not the three themselves

00:03:25,650 --> 00:03:28,890
but they're like the Technic technical

00:03:27,239 --> 00:03:30,840
team has actually implemented the social

00:03:28,890 --> 00:03:32,340
network if you wish almost completely on

00:03:30,840 --> 00:03:34,950
top of stream processing so everything

00:03:32,340 --> 00:03:37,140
comes enters every user interaction

00:03:34,950 --> 00:03:39,329
comes is locked into in this case Kafka

00:03:37,140 --> 00:03:41,190
and then you have a stream processor

00:03:39,329 --> 00:03:43,069
that consumes this lock of actions and

00:03:41,190 --> 00:03:46,140
computes the view of the world as it's a

00:03:43,069 --> 00:03:48,329
to be presented to all the users on the

00:03:46,140 --> 00:03:49,920
website and then it's mirrored out to

00:03:48,329 --> 00:03:53,069
elasticsearch and readies to be actually

00:03:49,920 --> 00:03:54,989
served by the by the read layer so this

00:03:53,069 --> 00:03:56,910
this doesn't run it quite the scale as

00:03:54,989 --> 00:03:58,709
the others do but it's kind of it's an

00:03:56,910 --> 00:04:00,239
interesting complexity in itself because

00:03:58,709 --> 00:04:02,280
it's almost the entire application of

00:04:00,239 --> 00:04:03,510
that social network that runs in the

00:04:02,280 --> 00:04:07,730
stream processor not just you know like

00:04:03,510 --> 00:04:10,200
individual parts that support it and

00:04:07,730 --> 00:04:12,209
like I'd like to start with the first

00:04:10,200 --> 00:04:14,430
part like what have we learned about how

00:04:12,209 --> 00:04:16,169
users actually view flink that was there

00:04:14,430 --> 00:04:17,760
was kind of an interesting process

00:04:16,169 --> 00:04:19,709
process for us because you know we

00:04:17,760 --> 00:04:20,940
always try to explain what what flink is

00:04:19,709 --> 00:04:23,669
to users and once in a while we actually

00:04:20,940 --> 00:04:25,020
try to listen and okay if you explain

00:04:23,669 --> 00:04:26,280
flank to us now how would you actually

00:04:25,020 --> 00:04:27,450
describe it it was very interesting

00:04:26,280 --> 00:04:28,919
maybe some of them describe it

00:04:27,450 --> 00:04:32,580
completely different than we would

00:04:28,919 --> 00:04:35,610
describe it and here's something we we

00:04:32,580 --> 00:04:39,790
learned that's actually interesting

00:04:35,610 --> 00:04:41,410
so many of us still does okay we we've

00:04:39,790 --> 00:04:45,240
you've linked these days actually as a

00:04:41,410 --> 00:04:48,780
as a system for you know pretty generic

00:04:45,240 --> 00:04:51,640
stateful event-driven processing meaning

00:04:48,780 --> 00:04:53,110
you have a system that that that you

00:04:51,640 --> 00:04:54,880
take is you take as a building block for

00:04:53,110 --> 00:04:56,920
implementing stateful services stateful

00:04:54,880 --> 00:04:59,500
micro services it reacts to events to

00:04:56,920 --> 00:05:01,210
calls it has it has application state

00:04:59,500 --> 00:05:03,610
that it maintains and it triggers other

00:05:01,210 --> 00:05:04,840
actions and it's it's responsible for

00:05:03,610 --> 00:05:06,250
maintaining the consistency and

00:05:04,840 --> 00:05:10,000
durability in the persistence of all

00:05:06,250 --> 00:05:11,470
that that application state incidentally

00:05:10,000 --> 00:05:12,730
without a database that's that would be

00:05:11,470 --> 00:05:16,000
the classical way to do it

00:05:12,730 --> 00:05:17,380
so it's kind of a framework that kind of

00:05:16,000 --> 00:05:19,990
you goes more to the left side a

00:05:17,380 --> 00:05:22,300
framework for event-driven applications

00:05:19,990 --> 00:05:24,820
to build them based on on patterns like

00:05:22,300 --> 00:05:28,420
event sourcing or arm command query

00:05:24,820 --> 00:05:32,440
responsibility segregation then there's

00:05:28,420 --> 00:05:33,790
of course users that say yeah so it's a

00:05:32,440 --> 00:05:34,870
stream processing framework you know you

00:05:33,790 --> 00:05:36,310
have your streams of events and you

00:05:34,870 --> 00:05:37,900
compute over the streams of events you

00:05:36,310 --> 00:05:41,680
do windows session windows tumbling

00:05:37,900 --> 00:05:43,540
windows and all of that and of course a

00:05:41,680 --> 00:05:46,450
lot of users still feud as a batch

00:05:43,540 --> 00:05:48,160
processing framework so we've kind of as

00:05:46,450 --> 00:05:50,020
kind of organized this like this view

00:05:48,160 --> 00:05:51,520
that we learned about it as this it's

00:05:50,020 --> 00:05:53,080
kind of different different crowds I

00:05:51,520 --> 00:05:55,530
would say that the users come from that

00:05:53,080 --> 00:05:57,610
describe it in these different angles

00:05:55,530 --> 00:05:59,920
the crowd that describes it as

00:05:57,610 --> 00:06:03,100
event-driven applications is usually

00:05:59,920 --> 00:06:05,890
exactly armed teams that that build

00:06:03,100 --> 00:06:07,300
applications the you know the front

00:06:05,890 --> 00:06:10,810
front and back current of the life of

00:06:07,300 --> 00:06:12,670
the live services of teams versus the

00:06:10,810 --> 00:06:14,470
other the other teams are often like the

00:06:12,670 --> 00:06:16,300
data teams and the companies that say

00:06:14,470 --> 00:06:18,730
you know for us it's a stream processor

00:06:16,300 --> 00:06:20,800
or a batch processor but the kind of

00:06:18,730 --> 00:06:22,660
common substrate is that it's a system

00:06:20,800 --> 00:06:26,770
that's built actually on stateful event

00:06:22,660 --> 00:06:30,370
processing and the the most interesting

00:06:26,770 --> 00:06:32,860
description I've heard how how users

00:06:30,370 --> 00:06:35,890
view flink is actually it's a system for

00:06:32,860 --> 00:06:38,470
actually realizing the the need memory

00:06:35,890 --> 00:06:42,370
image model for replications and

00:06:38,470 --> 00:06:44,490
persistence so what does that mean um if

00:06:42,370 --> 00:06:47,720
you want to if you want to build a

00:06:44,490 --> 00:06:49,760
distributed stateful application

00:06:47,720 --> 00:06:52,580
um this is a very interesting pattern to

00:06:49,760 --> 00:06:54,380
do it um based on based on the idea of

00:06:52,580 --> 00:06:56,120
event sourcing every time you do it you

00:06:54,380 --> 00:06:58,490
want to do an interaction with that with

00:06:56,120 --> 00:07:00,320
that application you create an event

00:06:58,490 --> 00:07:01,790
that describes the application you put

00:07:00,320 --> 00:07:03,500
it into a log that where it is

00:07:01,790 --> 00:07:05,870
persistent and then you let actually the

00:07:03,500 --> 00:07:07,580
application are process it and yep and

00:07:05,870 --> 00:07:09,290
then the application becomes very very

00:07:07,580 --> 00:07:10,670
simple it's just it's just a process

00:07:09,290 --> 00:07:12,440
that consumes an event and update some

00:07:10,670 --> 00:07:13,730
arbitrary memory data structures you

00:07:12,440 --> 00:07:16,910
know like it would be a standalone

00:07:13,730 --> 00:07:19,160
process nothing nothing more there's no

00:07:16,910 --> 00:07:20,450
there's no abstraction that makes

00:07:19,160 --> 00:07:22,100
actually these data structures in

00:07:20,450 --> 00:07:26,330
hindsight go against you know like a

00:07:22,100 --> 00:07:28,520
database fire and or EMM framework or

00:07:26,330 --> 00:07:30,250
whatever it's really just like you would

00:07:28,520 --> 00:07:33,410
have a new standalone java application

00:07:30,250 --> 00:07:35,690
and then periodically blink actually

00:07:33,410 --> 00:07:37,280
takes your snapshot of that of that

00:07:35,690 --> 00:07:40,820
thing that's like the the memory image

00:07:37,280 --> 00:07:42,800
and uses that for persistence and and

00:07:40,820 --> 00:07:44,450
when a failure happens what it does is

00:07:42,800 --> 00:07:46,040
it restores you the memory image and

00:07:44,450 --> 00:07:47,840
replace you all the events that have

00:07:46,040 --> 00:07:50,300
happened since the since net failure

00:07:47,840 --> 00:07:52,490
just just viewed like that there's

00:07:50,300 --> 00:07:54,020
actually no there's nothing that's

00:07:52,490 --> 00:07:56,320
particular to stream processing here

00:07:54,020 --> 00:07:59,780
it's just a mechanism to actually have

00:07:56,320 --> 00:08:01,880
processes with state that run and you

00:07:59,780 --> 00:08:03,350
make them you make them recoverable or

00:08:01,880 --> 00:08:05,180
you make them you make them for tolerant

00:08:03,350 --> 00:08:06,680
in a very efficient way because while

00:08:05,180 --> 00:08:07,820
you're actually processing with and

00:08:06,680 --> 00:08:09,020
interacting with these local data

00:08:07,820 --> 00:08:11,060
structures you worry about nothing right

00:08:09,020 --> 00:08:12,620
there's there's no additional cost that

00:08:11,060 --> 00:08:14,120
you pay for any persistence and so on

00:08:12,620 --> 00:08:15,830
this just like once in a while of Ekron

00:08:14,120 --> 00:08:19,070
process that does you a snapshot

00:08:15,830 --> 00:08:21,290
persistence of that memory image and and

00:08:19,070 --> 00:08:22,820
then blink would actually be if you wish

00:08:21,290 --> 00:08:25,280
a distributed instantiation of that

00:08:22,820 --> 00:08:26,870
system so you have events coming in and

00:08:25,280 --> 00:08:28,100
you have a lot of individual processes

00:08:26,870 --> 00:08:30,140
that just consume the events and

00:08:28,100 --> 00:08:31,820
manipulate their internal state and do

00:08:30,140 --> 00:08:33,500
something and I'm flinging the system

00:08:31,820 --> 00:08:36,950
that kind of keeps this whole thing for

00:08:33,500 --> 00:08:39,500
tolerant and and consistent in case of

00:08:36,950 --> 00:08:41,750
in case of failures so there were some

00:08:39,500 --> 00:08:44,030
there is a very interesting interesting

00:08:41,750 --> 00:08:46,040
lesson for me that is how how we found

00:08:44,030 --> 00:08:48,500
quite a few users actually describing

00:08:46,040 --> 00:08:51,170
back the system to us and these all

00:08:48,500 --> 00:08:53,210
terms like event sourcing and and memory

00:08:51,170 --> 00:08:57,380
image actually terms that have been have

00:08:53,210 --> 00:09:00,200
been coined before by um you know by by

00:08:57,380 --> 00:09:01,550
by people that work in the in the space

00:09:00,200 --> 00:09:03,110
of application engineering the

00:09:01,550 --> 00:09:04,850
come up with design patterns Darren's on

00:09:03,110 --> 00:09:08,750
and I just turned out this fits the

00:09:04,850 --> 00:09:11,800
whole idea of links so well so in the oh

00:09:08,750 --> 00:09:11,800
this looks horrible

00:09:12,459 --> 00:09:17,269
this should be this should be gloriously

00:09:15,440 --> 00:09:22,670
yellow glowing bubbles over there just

00:09:17,269 --> 00:09:25,579
just picture them as such so the the

00:09:22,670 --> 00:09:27,440
whole way that then fling operates in a

00:09:25,579 --> 00:09:28,850
distributed fashion is actually you know

00:09:27,440 --> 00:09:30,620
you have this do you have these

00:09:28,850 --> 00:09:34,180
connected pieces of distributed

00:09:30,620 --> 00:09:38,329
communication attached with some

00:09:34,180 --> 00:09:39,950
embedded state that for all means to the

00:09:38,329 --> 00:09:42,680
application programmer actually reacts

00:09:39,950 --> 00:09:44,570
as as local state at memory speed and

00:09:42,680 --> 00:09:46,250
you just have have events that flow

00:09:44,570 --> 00:09:48,079
through that that manipulate this state

00:09:46,250 --> 00:09:49,670
and someone to the wires link scans over

00:09:48,079 --> 00:09:51,230
the whole thing and take city snapshot

00:09:49,670 --> 00:09:53,180
and make sure everything is everything

00:09:51,230 --> 00:09:55,370
is consistent and because there's such

00:09:53,180 --> 00:09:56,600
this in flink is designed to have kind

00:09:55,370 --> 00:09:59,320
of a loose coupling between those

00:09:56,600 --> 00:10:02,240
between those things you can actually um

00:09:59,320 --> 00:10:04,370
you can restore or you can restore um

00:10:02,240 --> 00:10:07,209
the state of these computations from the

00:10:04,370 --> 00:10:09,890
snapshot or you can actually alter the

00:10:07,209 --> 00:10:11,899
computation or the the whole whole

00:10:09,890 --> 00:10:13,490
structure of how how computation depends

00:10:11,899 --> 00:10:15,020
on each other and still restores because

00:10:13,490 --> 00:10:17,360
there's like a loose coupling between um

00:10:15,020 --> 00:10:19,370
this state and the computation and it's

00:10:17,360 --> 00:10:20,750
every time you restore it um it's kind

00:10:19,370 --> 00:10:22,310
of it's a matching procedure that

00:10:20,750 --> 00:10:25,360
matches the state into the computation

00:10:22,310 --> 00:10:28,640
so it's kind of a an interesting

00:10:25,360 --> 00:10:32,050
application building framework in some

00:10:28,640 --> 00:10:34,399
sense based on yeah based on the idea of

00:10:32,050 --> 00:10:38,209
it has so many names event sourcing

00:10:34,399 --> 00:10:39,620
reactive programming but but in essence

00:10:38,209 --> 00:10:44,329
together with local state for

00:10:39,620 --> 00:10:46,520
computation and and snapshots so another

00:10:44,329 --> 00:10:49,070
way to view this would be actually to

00:10:46,520 --> 00:10:51,920
say if the if the classical way of

00:10:49,070 --> 00:10:53,300
building building applications is you

00:10:51,920 --> 00:10:55,250
know you have a you have a layer of

00:10:53,300 --> 00:10:58,610
compute and you have a layer of a

00:10:55,250 --> 00:11:01,550
database for persistence what's what's

00:10:58,610 --> 00:11:05,209
link really gives you is an architecture

00:11:01,550 --> 00:11:06,920
to to change this into you do you do

00:11:05,209 --> 00:11:08,959
require persistent storage for streams

00:11:06,920 --> 00:11:10,940
something like like a log something like

00:11:08,959 --> 00:11:12,320
Kafka so but then it gives you a very

00:11:10,940 --> 00:11:14,329
good building block to actually say

00:11:12,320 --> 00:11:15,500
transform this to an architecture where

00:11:14,329 --> 00:11:17,660
application state is

00:11:15,500 --> 00:11:20,360
that is completely completely local and

00:11:17,660 --> 00:11:22,370
it just interacts with our with with

00:11:20,360 --> 00:11:29,540
storage in a like snap shot persistence

00:11:22,370 --> 00:11:31,700
mechanism alright so what this will

00:11:29,540 --> 00:11:36,380
actually this may actually now create

00:11:31,700 --> 00:11:37,970
create some some some confusion in in

00:11:36,380 --> 00:11:39,320
the mind of trying to okay piece that

00:11:37,970 --> 00:11:42,710
together okay if it's that building

00:11:39,320 --> 00:11:44,570
block you know it's probably not not

00:11:42,710 --> 00:11:45,950
very hard to imagine how such a building

00:11:44,570 --> 00:11:47,270
block is a really nice building block

00:11:45,950 --> 00:11:48,890
for screen processing because stream

00:11:47,270 --> 00:11:50,780
processing is really exactly there to

00:11:48,890 --> 00:11:52,580
take events and you you try to put them

00:11:50,780 --> 00:11:54,140
into perspective of each other with the

00:11:52,580 --> 00:11:55,940
help of some local state and this local

00:11:54,140 --> 00:11:58,250
state you know the simplest case is just

00:11:55,940 --> 00:12:00,080
a counter per window right or it's a

00:11:58,250 --> 00:12:01,730
it's the state of a session or anything

00:12:00,080 --> 00:12:03,410
right so this actually gives you arm

00:12:01,730 --> 00:12:06,170
gives you the interesting building

00:12:03,410 --> 00:12:07,550
blocks just from the runtime there's an

00:12:06,170 --> 00:12:09,830
there's an aspect in here that I haven't

00:12:07,550 --> 00:12:11,240
actually talked about much and I don't

00:12:09,830 --> 00:12:12,710
have the time today to talk about that

00:12:11,240 --> 00:12:14,180
but this is the the handling of time

00:12:12,710 --> 00:12:15,890
that we built into flink which is kind

00:12:14,180 --> 00:12:17,750
of the second ingredient that that then

00:12:15,890 --> 00:12:19,160
helps it to make make it a really really

00:12:17,750 --> 00:12:21,890
good match for stream processing

00:12:19,160 --> 00:12:25,190
primitives to track progress in event

00:12:21,890 --> 00:12:27,460
time completeness of data and so on so

00:12:25,190 --> 00:12:30,500
because it it seems like this is a very

00:12:27,460 --> 00:12:31,970
fairly primitive set of or a fairly

00:12:30,500 --> 00:12:33,770
basic and general set of building

00:12:31,970 --> 00:12:35,960
primitives that is very powerful for

00:12:33,770 --> 00:12:37,220
these different use cases things

00:12:35,960 --> 00:12:39,280
actually come now come up with a

00:12:37,220 --> 00:12:41,420
different a different set of layers so

00:12:39,280 --> 00:12:45,140
there's also something we interestingly

00:12:41,420 --> 00:12:46,490
learned from from users how they if they

00:12:45,140 --> 00:12:49,339
if they look at filling today how they

00:12:46,490 --> 00:12:52,670
how they want to approach it and um the

00:12:49,339 --> 00:12:54,170
the latest set of of users actually have

00:12:52,670 --> 00:12:56,300
this interesting transition how they go

00:12:54,170 --> 00:12:58,670
from from coarse-grained to ever more

00:12:56,300 --> 00:13:01,760
fine-grained levels of abstraction so

00:12:58,670 --> 00:13:03,800
the the most the most basic primitives

00:13:01,760 --> 00:13:05,510
is on the on the bottom layer it really

00:13:03,800 --> 00:13:08,690
gives you just this events times and

00:13:05,510 --> 00:13:10,460
snapshots and so on slightly more more

00:13:08,690 --> 00:13:12,170
high-level is the data streams API which

00:13:10,460 --> 00:13:13,700
gives you the DSL for stream processing

00:13:12,170 --> 00:13:17,480
and batch processing and then on top of

00:13:13,700 --> 00:13:20,030
this um primitives for our API is for um

00:13:17,480 --> 00:13:23,360
for streaming sequel the table API is

00:13:20,030 --> 00:13:25,910
kind of a an embedded DSL that is that

00:13:23,360 --> 00:13:28,100
is roughly the same as as SQL and you

00:13:25,910 --> 00:13:29,220
can you can kind of navigate this this

00:13:28,100 --> 00:13:31,259
layers of abstraction

00:13:29,220 --> 00:13:34,410
on what you want to do if you want to if

00:13:31,259 --> 00:13:36,060
you want to just build an application

00:13:34,410 --> 00:13:38,310
that generates some insights from this

00:13:36,060 --> 00:13:39,689
from a stream of events you may start on

00:13:38,310 --> 00:13:41,910
that level if you then want something

00:13:39,689 --> 00:13:43,860
slightly more complex that you know that

00:13:41,910 --> 00:13:47,430
has a very custom way of doing of

00:13:43,860 --> 00:13:49,290
deriving deriving you know statistics

00:13:47,430 --> 00:13:51,269
over over windows of state over time

00:13:49,290 --> 00:13:52,500
then you go a level below and if you

00:13:51,269 --> 00:13:55,100
actually want to build really just a

00:13:52,500 --> 00:13:58,680
custom application that that reacts to

00:13:55,100 --> 00:14:00,839
that reacts to events then then you go

00:13:58,680 --> 00:14:02,160
even one level below and the interesting

00:14:00,839 --> 00:14:03,660
thing is you can mix all these levels in

00:14:02,160 --> 00:14:06,269
the same application and and we do

00:14:03,660 --> 00:14:08,459
actually see that as as progress as

00:14:06,269 --> 00:14:10,470
projects go on and go on and go on and

00:14:08,459 --> 00:14:11,699
they try to that they come to the point

00:14:10,470 --> 00:14:13,649
that they say okay we've actually built

00:14:11,699 --> 00:14:15,269
this now can we actually even reflect

00:14:13,649 --> 00:14:16,920
that characteristic in the real in the

00:14:15,269 --> 00:14:18,750
real time program can we reflect that

00:14:16,920 --> 00:14:19,980
more and can we reflect that other

00:14:18,750 --> 00:14:21,689
characteristic they start actually

00:14:19,980 --> 00:14:23,550
moving down that stack bit by bit by bit

00:14:21,689 --> 00:14:25,379
so we've actually seen a lot of folks

00:14:23,550 --> 00:14:27,660
that that actually moved from the data

00:14:25,379 --> 00:14:29,399
stream API from from how you define

00:14:27,660 --> 00:14:30,990
Windows they're just to the to the layer

00:14:29,399 --> 00:14:32,250
one below where they say okay just give

00:14:30,990 --> 00:14:34,559
me are betrayed state give me some

00:14:32,250 --> 00:14:36,149
timers make sure it's consistent and

00:14:34,559 --> 00:14:39,360
I'll just I just wired together whatever

00:14:36,149 --> 00:14:41,129
I want um don't don't dictate me any API

00:14:39,360 --> 00:14:42,680
also just give me computing state and

00:14:41,129 --> 00:14:46,250
I'll do the rest

00:14:42,680 --> 00:14:49,139
all right so that that is kind of a how

00:14:46,250 --> 00:14:51,449
power of your flink can evolved over

00:14:49,139 --> 00:14:54,230
time with with what we what we saw how

00:14:51,449 --> 00:14:57,470
how our users are using it

00:14:54,230 --> 00:15:00,389
there's also another part of it that

00:14:57,470 --> 00:15:03,720
where we learned kind of how it behaves

00:15:00,389 --> 00:15:07,769
in an operational context that are that

00:15:03,720 --> 00:15:10,500
I'd like to share and I'd like to start

00:15:07,769 --> 00:15:14,309
actually with a with a very neat arc

00:15:10,500 --> 00:15:17,339
inside and that is that the event stream

00:15:14,309 --> 00:15:20,279
pipeline in general is a it's something

00:15:17,339 --> 00:15:22,230
that works so if you just piece together

00:15:20,279 --> 00:15:24,629
the streaming and your compute and so on

00:15:22,230 --> 00:15:25,769
this is this kind of it's a very robust

00:15:24,629 --> 00:15:27,540
thing there's not a lot of like very

00:15:25,769 --> 00:15:29,069
complicated memory management or here

00:15:27,540 --> 00:15:29,879
you're there are parameters that you

00:15:29,069 --> 00:15:33,360
need to chew in here and they're

00:15:29,879 --> 00:15:36,480
involved that ports just works there are

00:15:33,360 --> 00:15:38,100
of course things that that that that

00:15:36,480 --> 00:15:39,990
come up again and again and here they're

00:15:38,100 --> 00:15:41,220
if you like more more general insights

00:15:39,990 --> 00:15:42,480
and then there's one that I would like

00:15:41,220 --> 00:15:46,290
to actually spend some

00:15:42,480 --> 00:15:48,120
I'm on iterating so their view obvious

00:15:46,290 --> 00:15:51,029
things like okay dependency conflicts

00:15:48,120 --> 00:15:52,829
are probably the thing that I have the

00:15:51,029 --> 00:15:54,209
feeling that users spent most time on

00:15:52,829 --> 00:15:57,870
their way to production solving

00:15:54,209 --> 00:15:59,610
dependency conflicts these days or rough

00:15:57,870 --> 00:16:01,350
edges around the deployment ecosystem

00:15:59,610 --> 00:16:03,209
because it's really a it's really a

00:16:01,350 --> 00:16:05,910
crazy space everything behaves and

00:16:03,209 --> 00:16:08,810
evolves kind of in a different way yarn

00:16:05,910 --> 00:16:12,089
masons doctor all the security

00:16:08,810 --> 00:16:14,370
infrastructure there's this fancy idea

00:16:12,089 --> 00:16:16,019
of overlay networks in container engines

00:16:14,370 --> 00:16:17,519
which is conceptually really nice thing

00:16:16,019 --> 00:16:18,899
but messes up everything for the systems

00:16:17,519 --> 00:16:20,910
that actually run inside them and have

00:16:18,899 --> 00:16:22,949
to do service discovery now all of a

00:16:20,910 --> 00:16:24,779
sudden very different so these are these

00:16:22,949 --> 00:16:27,240
are things that are like obviously on

00:16:24,779 --> 00:16:29,370
the in the space around around flink

00:16:27,240 --> 00:16:33,839
that um that have to be paid attention

00:16:29,370 --> 00:16:37,610
on and not another thing that we kind of

00:16:33,839 --> 00:16:41,430
realized and where we where we plan to

00:16:37,610 --> 00:16:42,990
invest some work in is that we we've

00:16:41,430 --> 00:16:45,300
seen that the dependency on any external

00:16:42,990 --> 00:16:47,639
system eventually causes avoidable

00:16:45,300 --> 00:16:50,069
downtime if you wish so the snapshots

00:16:47,639 --> 00:16:52,709
that that flink takes at the moment have

00:16:50,069 --> 00:16:55,079
to go somewhere in most cases it's HDFS

00:16:52,709 --> 00:16:56,250
s3 and NFS and you would actually you

00:16:55,079 --> 00:16:58,079
would actually think that most companies

00:16:56,250 --> 00:16:59,610
have two HDFS cluster well under control

00:16:58,079 --> 00:17:01,560
or s3 is something that's generally

00:16:59,610 --> 00:17:04,230
available but apparently that's not

00:17:01,560 --> 00:17:05,730
always the case so the I don't know if

00:17:04,230 --> 00:17:07,380
you remember this a few weeks ago when

00:17:05,730 --> 00:17:08,730
s3 had this downtime half the internet

00:17:07,380 --> 00:17:10,350
stopped working that's also when we got

00:17:08,730 --> 00:17:12,689
this flood of emails like okay all our

00:17:10,350 --> 00:17:15,839
fling clusters kind of on Amazon you

00:17:12,689 --> 00:17:18,750
know they fail to checkpoint obviously

00:17:15,839 --> 00:17:20,490
because there's s3 is down and there's

00:17:18,750 --> 00:17:22,290
there's very interested this there's a

00:17:20,490 --> 00:17:23,520
few things that we can actually do so

00:17:22,290 --> 00:17:25,079
we've kind of changed I think the

00:17:23,520 --> 00:17:27,660
mindset since then a little bit ends and

00:17:25,079 --> 00:17:29,490
under thought okay let's actually try

00:17:27,660 --> 00:17:30,900
and really make it as independent as

00:17:29,490 --> 00:17:33,000
possible in the future of all of these

00:17:30,900 --> 00:17:35,370
dependencies while they you know exploit

00:17:33,000 --> 00:17:36,990
them while they work but don't don't be

00:17:35,370 --> 00:17:42,480
blocked by them for the times that they

00:17:36,990 --> 00:17:43,830
don't work um perhaps your realization

00:17:42,480 --> 00:17:46,350
sounded like something that we would

00:17:43,830 --> 00:17:48,390
almost consider as a soft problem when

00:17:46,350 --> 00:17:50,850
we're still doing that same processing

00:17:48,390 --> 00:17:53,400
in the early days or more even before

00:17:50,850 --> 00:17:56,080
that batch processing but it in

00:17:53,400 --> 00:18:00,340
streaming the whole the who is you

00:17:56,080 --> 00:18:02,799
lies a can of worms has actually been

00:18:00,340 --> 00:18:06,570
opened again and and come back as a as a

00:18:02,799 --> 00:18:09,519
very different beast first of all

00:18:06,570 --> 00:18:10,929
streaming has different patterns with

00:18:09,519 --> 00:18:13,659
which it interacts with data structures

00:18:10,929 --> 00:18:15,220
which make industrialization some of the

00:18:13,659 --> 00:18:16,570
tricks that that we added to flink to

00:18:15,220 --> 00:18:19,240
make serialization cheap and batch not

00:18:16,570 --> 00:18:20,980
quite as efficient but even even more

00:18:19,240 --> 00:18:22,779
important thing is that all of a sudden

00:18:20,980 --> 00:18:24,250
remember this figure from few slides

00:18:22,779 --> 00:18:26,320
back where it said that flink actually

00:18:24,250 --> 00:18:27,640
start owning start holding the state the

00:18:26,320 --> 00:18:29,620
compute end the stay together and not

00:18:27,640 --> 00:18:31,510
the database anymore which actually

00:18:29,620 --> 00:18:33,159
means that you would you want to start

00:18:31,510 --> 00:18:34,960
doing the same things with the

00:18:33,159 --> 00:18:37,419
statements linked as you used to do with

00:18:34,960 --> 00:18:39,549
the database and that means you would

00:18:37,419 --> 00:18:41,620
actually want to like version it evolve

00:18:39,549 --> 00:18:43,480
it over time that means evolving the

00:18:41,620 --> 00:18:45,070
implementation of your sterilizers or

00:18:43,480 --> 00:18:47,740
fling serializers but also you know just

00:18:45,070 --> 00:18:49,779
regular schema evolution you have you

00:18:47,740 --> 00:18:51,250
started out storing you know session

00:18:49,779 --> 00:18:52,870
with a certain amount of information

00:18:51,250 --> 00:18:55,510
about users you want to drop some and

00:18:52,870 --> 00:18:59,320
add some other it changes the shape of

00:18:55,510 --> 00:19:02,590
the state it changes if you wish the um

00:18:59,320 --> 00:19:04,659
it changes the classes that you use in

00:19:02,590 --> 00:19:06,970
your in your variables in the memory in

00:19:04,659 --> 00:19:09,639
the memory image right so all of a

00:19:06,970 --> 00:19:12,610
sudden um what we need there is a way to

00:19:09,639 --> 00:19:14,169
allow users to kind of in hindsight fix

00:19:12,610 --> 00:19:16,090
that and correct that because most of

00:19:14,169 --> 00:19:17,799
them just start out programming and

00:19:16,090 --> 00:19:20,080
saying you know I'm such a nice easy

00:19:17,799 --> 00:19:21,519
thing I'll just program and then a few

00:19:20,080 --> 00:19:23,019
months later they figure out okay damn I

00:19:21,519 --> 00:19:25,210
actually overlooked something so now I

00:19:23,019 --> 00:19:26,919
have to kind of evolve everything in

00:19:25,210 --> 00:19:28,870
this in this memory image and put it

00:19:26,919 --> 00:19:30,970
into a newer form so this is something

00:19:28,870 --> 00:19:32,830
where we started working on and putting

00:19:30,970 --> 00:19:34,510
a lot more effort and kind of you can

00:19:32,830 --> 00:19:39,639
think of it as a schema evolution of

00:19:34,510 --> 00:19:41,889
application internal state um so much

00:19:39,639 --> 00:19:43,929
for the for the kind of more more

00:19:41,889 --> 00:19:45,279
high-level other the lessons learned

00:19:43,929 --> 00:19:46,779
that I want to touch only lightly upon

00:19:45,279 --> 00:19:48,760
the one that we want to go into a little

00:19:46,779 --> 00:19:50,710
more detail is actually the fact that

00:19:48,760 --> 00:19:52,720
robustly checkpointing is if you wish

00:19:50,710 --> 00:19:55,090
then the most important part of running

00:19:52,720 --> 00:20:00,309
a large-scale a large-scale flink

00:19:55,090 --> 00:20:04,210
application and i'd like to kind of go

00:20:00,309 --> 00:20:05,799
into this and and if if you give a few

00:20:04,210 --> 00:20:07,600
pointers like how do you do get some

00:20:05,799 --> 00:20:10,030
insights whether whether these things

00:20:07,600 --> 00:20:12,970
are all going you know Petrey and easy

00:20:10,030 --> 00:20:14,800
or if something if something causes

00:20:12,970 --> 00:20:17,170
checkpoints to take way longer than you

00:20:14,800 --> 00:20:18,790
think or cost way more than you would

00:20:17,170 --> 00:20:20,080
would imagine that would cost how do you

00:20:18,790 --> 00:20:21,400
actually get at the bottom of that what

00:20:20,080 --> 00:20:24,400
is usually the course and what are kind

00:20:21,400 --> 00:20:27,430
of ongoing ongoing trends in order to

00:20:24,400 --> 00:20:35,580
like to keep continually improving on

00:20:27,430 --> 00:20:38,560
that so again um so the the basic

00:20:35,580 --> 00:20:40,990
mechanism of checkpoint against link is

00:20:38,560 --> 00:20:43,560
is the following assuming we have a lock

00:20:40,990 --> 00:20:46,390
of input events at some point in time

00:20:43,560 --> 00:20:50,320
the system triggers a checkpoint and

00:20:46,390 --> 00:20:52,120
that that is marked by the source tasks

00:20:50,320 --> 00:20:53,890
of the streaming computation injecting a

00:20:52,120 --> 00:20:55,720
checkpoint area and that checkpoint

00:20:53,890 --> 00:20:57,760
barrier flows through and whenever it

00:20:55,720 --> 00:21:00,160
reaches a stateful operation it marks

00:20:57,760 --> 00:21:01,870
that it marks the alignment point to the

00:21:00,160 --> 00:21:04,000
updates to the state data structures at

00:21:01,870 --> 00:21:06,250
which point that particular snapshot has

00:21:04,000 --> 00:21:09,280
to be taken and where you have to

00:21:06,250 --> 00:21:10,960
actually set the metadata to so you know

00:21:09,280 --> 00:21:14,200
that you know you can recover from

00:21:10,960 --> 00:21:15,760
exactly at that point so it's injecting

00:21:14,200 --> 00:21:18,730
these barriers then flowing through the

00:21:15,760 --> 00:21:20,200
stream triggering the snapshots so that

00:21:18,730 --> 00:21:22,480
sounds that sounds quite easy there's

00:21:20,200 --> 00:21:24,970
one little nifty detail in all of that

00:21:22,480 --> 00:21:27,130
and that is in order to get proper

00:21:24,970 --> 00:21:30,430
exactly one semantics there's there's a

00:21:27,130 --> 00:21:33,850
step that that I think many users are

00:21:30,430 --> 00:21:35,410
not not really too too aware of just

00:21:33,850 --> 00:21:38,620
because you know you rarely see it

00:21:35,410 --> 00:21:41,070
happening when you actually run it and

00:21:38,620 --> 00:21:45,520
that is the that is the alignment phase

00:21:41,070 --> 00:21:47,640
so think of it as as the following when

00:21:45,520 --> 00:21:49,810
when you have different pieces of

00:21:47,640 --> 00:21:50,830
computation running around and at some

00:21:49,810 --> 00:21:53,140
point you want to establish a

00:21:50,830 --> 00:21:54,760
synchronous point between them you can

00:21:53,140 --> 00:21:57,040
you can think of that as a point where

00:21:54,760 --> 00:21:59,020
you have to do a little bit of you know

00:21:57,040 --> 00:22:00,910
like bookkeeping and making sure that I

00:21:59,020 --> 00:22:02,410
say in the database space these

00:22:00,910 --> 00:22:04,120
transactions would have to still be

00:22:02,410 --> 00:22:05,230
accounted for here while these shouldn't

00:22:04,120 --> 00:22:07,090
be accounted for you know you have to

00:22:05,230 --> 00:22:08,680
kind of establish that level and say now

00:22:07,090 --> 00:22:10,540
I have a now I have a consistent view

00:22:08,680 --> 00:22:13,270
over all the different states and of the

00:22:10,540 --> 00:22:15,700
computation and I can I can use this as

00:22:13,270 --> 00:22:17,500
a as a as a consistent snapshot across

00:22:15,700 --> 00:22:19,720
everything and that is kind of the

00:22:17,500 --> 00:22:21,910
equivalent to that if you if you log get

00:22:19,720 --> 00:22:23,350
distributed um distributed transactions

00:22:21,910 --> 00:22:23,870
would be the alignment phase and sling

00:22:23,350 --> 00:22:26,000
snap

00:22:23,870 --> 00:22:28,400
right so there's this checkpoint

00:22:26,000 --> 00:22:30,680
barriers coming from various streams and

00:22:28,400 --> 00:22:32,240
the operator actually has to say okay my

00:22:30,680 --> 00:22:33,559
snapshot has to reflect everything

00:22:32,240 --> 00:22:35,510
before the barriers are nothing behind

00:22:33,559 --> 00:22:37,280
the barriers so what it will do it will

00:22:35,510 --> 00:22:39,800
actually once it receives barriers from

00:22:37,280 --> 00:22:41,300
one of the streams start either holding

00:22:39,800 --> 00:22:42,980
back or buffering up a little bit of

00:22:41,300 --> 00:22:45,200
data from that stream until it's it's in

00:22:42,980 --> 00:22:46,490
the other barriers and once it's

00:22:45,200 --> 00:22:49,180
actually seen that then it will actually

00:22:46,490 --> 00:22:51,770
emit a variant say okay here's the

00:22:49,180 --> 00:22:54,700
here's the the point from my downstream

00:22:51,770 --> 00:22:57,740
that marks at that point of alignment

00:22:54,700 --> 00:23:00,830
okay I think this is very hard to read

00:22:57,740 --> 00:23:05,990
but okay let me let me try and explain

00:23:00,830 --> 00:23:07,790
it a bit so this is so dude usually that

00:23:05,990 --> 00:23:09,230
just that just works works very easy

00:23:07,790 --> 00:23:11,360
like this alignments take take

00:23:09,230 --> 00:23:15,550
milliseconds or so around the check

00:23:11,360 --> 00:23:17,840
point and um in cases when you see

00:23:15,550 --> 00:23:20,120
checkpoints not you know not going

00:23:17,840 --> 00:23:21,140
through as fast as the USS you used to

00:23:20,120 --> 00:23:22,490
you know you're triggering checkpoints

00:23:21,140 --> 00:23:24,350
every few seconds they go through fast

00:23:22,490 --> 00:23:26,510
and then once in a while you see okay

00:23:24,350 --> 00:23:29,600
here's here's one that that takes a

00:23:26,510 --> 00:23:30,800
little longer there there are a few

00:23:29,600 --> 00:23:32,660
tools that you can actually use to

00:23:30,800 --> 00:23:35,960
exactly try and figure out whether this

00:23:32,660 --> 00:23:37,850
is actually a problem or not one of the

00:23:35,960 --> 00:23:39,950
most useful ones is the is actually the

00:23:37,850 --> 00:23:42,020
fling flink web UI that you can use to

00:23:39,950 --> 00:23:43,580
draw it draw some inserts from that so

00:23:42,020 --> 00:23:44,929
it gives you some numbers like what was

00:23:43,580 --> 00:23:47,420
the end-to-end duration of a checkpoint

00:23:44,929 --> 00:23:48,830
what was the size of a checkpoint and

00:23:47,420 --> 00:23:51,710
what was the time they were spending

00:23:48,830 --> 00:23:53,390
alignment and if you if you actually

00:23:51,710 --> 00:23:55,429
then look at the subtasks you see even

00:23:53,390 --> 00:23:57,890
more details like how much time did the

00:23:55,429 --> 00:24:00,200
checkpoint spent on on materializing the

00:23:57,890 --> 00:24:01,580
on taking this this image snapshot in a

00:24:00,200 --> 00:24:03,710
synchronous way in the astronauts way

00:24:01,580 --> 00:24:05,090
how long did in alignment to take how

00:24:03,710 --> 00:24:06,770
many bytes did it actually have to

00:24:05,090 --> 00:24:10,220
buffer and how long did the whole thing

00:24:06,770 --> 00:24:12,080
take end-to-end so if you if you'd then

00:24:10,220 --> 00:24:13,580
dissect the the checkpoints you'll

00:24:12,080 --> 00:24:15,559
actually see that these like these

00:24:13,580 --> 00:24:17,809
numbers all kind of refer to different

00:24:15,559 --> 00:24:21,200
different characteristics of behaviors

00:24:17,809 --> 00:24:22,760
of the distributed systems so the the

00:24:21,200 --> 00:24:25,670
duration that the alignment takes the

00:24:22,760 --> 00:24:27,170
amount of data buffered means how long

00:24:25,670 --> 00:24:28,790
how long does it actually take to

00:24:27,170 --> 00:24:33,200
establish like a point where everything

00:24:28,790 --> 00:24:36,050
is everything kind of lined lines up for

00:24:33,200 --> 00:24:37,630
a snapshot obviously you want this to be

00:24:36,050 --> 00:24:39,700
as fast as possible how long

00:24:37,630 --> 00:24:41,530
snap shock take synchronous versus

00:24:39,700 --> 00:24:43,000
asynchronous part synchronous port means

00:24:41,530 --> 00:24:45,310
how long is the pipeline actually

00:24:43,000 --> 00:24:47,650
interrupted for processing between

00:24:45,310 --> 00:24:49,030
around a snapshot and cannot actually

00:24:47,650 --> 00:24:50,620
take the next event and continue

00:24:49,030 --> 00:24:52,690
processing it and I synchronous means

00:24:50,620 --> 00:24:54,790
how long does it take in the background

00:24:52,690 --> 00:24:57,610
- let's say persist this to HDFS to s3

00:24:54,790 --> 00:24:59,230
or whatever and then there's the entry

00:24:57,610 --> 00:25:00,880
and duration and this there's actually

00:24:59,230 --> 00:25:03,610
an interesting hidden metric in there if

00:25:00,880 --> 00:25:05,110
you wish which is if you take the

00:25:03,610 --> 00:25:07,180
end-to-end delay at the end-to-end

00:25:05,110 --> 00:25:08,920
duration and subject the synchronous and

00:25:07,180 --> 00:25:11,260
the asynchronous part and if you wish

00:25:08,920 --> 00:25:12,820
even the alignment duration then you can

00:25:11,260 --> 00:25:14,620
figure out how long did it actually take

00:25:12,820 --> 00:25:15,940
from when the system trigger to snapshot

00:25:14,620 --> 00:25:17,470
for everything to flow through and the

00:25:15,940 --> 00:25:18,850
barriers to actually reach the operator

00:25:17,470 --> 00:25:20,860
to take it snapshot so you can actually

00:25:18,850 --> 00:25:22,890
see how far is it delayed is the late

00:25:20,860 --> 00:25:26,560
other later operators kind of delayed

00:25:22,890 --> 00:25:29,500
rather than are compared to the earlier

00:25:26,560 --> 00:25:31,810
operators so if these if these numbers

00:25:29,500 --> 00:25:33,550
actually don't look as if these numbers

00:25:31,810 --> 00:25:34,870
look like this then then this is easy on

00:25:33,550 --> 00:25:36,970
the other hand this was running you know

00:25:34,870 --> 00:25:38,560
like on a for virtual processes on my

00:25:36,970 --> 00:25:41,350
laptop so this isn't actually you know

00:25:38,560 --> 00:25:43,540
this isn't a large-scale screenshot from

00:25:41,350 --> 00:25:44,830
a large-scale implementation but if you

00:25:43,540 --> 00:25:48,640
want to if you actually see these

00:25:44,830 --> 00:25:51,430
numbers and and some of them are are too

00:25:48,640 --> 00:25:53,530
high here's is what this usually means

00:25:51,430 --> 00:25:56,740
if you if you're working in your system

00:25:53,530 --> 00:25:58,870
so if you have a very long delay until a

00:25:56,740 --> 00:26:00,190
checkpoint is triggered that that

00:25:58,870 --> 00:26:02,050
typically means that you're operating

00:26:00,190 --> 00:26:05,800
under a constant back pressure which

00:26:02,050 --> 00:26:07,210
means that at least for what the system

00:26:05,800 --> 00:26:08,830
is doing at that particular point in

00:26:07,210 --> 00:26:10,360
time it's actually under provision so

00:26:08,830 --> 00:26:11,590
you try to do more than the machines can

00:26:10,360 --> 00:26:12,790
get through in that particular point in

00:26:11,590 --> 00:26:14,560
time and then you know Flinx back

00:26:12,790 --> 00:26:17,290
pressure mechanism kicks in and just

00:26:14,560 --> 00:26:18,700
makes the whole pipeline adjust to the

00:26:17,290 --> 00:26:21,760
slowest part because otherwise it would

00:26:18,700 --> 00:26:25,480
it without just overflow if the snapshot

00:26:21,760 --> 00:26:27,640
to take just very long then it it can

00:26:25,480 --> 00:26:29,260
usually it usually means that you know

00:26:27,640 --> 00:26:31,210
it could either be that the bandwidth to

00:26:29,260 --> 00:26:34,780
your storage is really crappy this is

00:26:31,210 --> 00:26:36,670
actually has actually happened it could

00:26:34,780 --> 00:26:38,860
also mean that you're just keeping a lot

00:26:36,670 --> 00:26:40,690
of state on the machine and it it down

00:26:38,860 --> 00:26:43,330
it actually means that per checkpoint

00:26:40,690 --> 00:26:45,310
you have to do too much work blink 1.3 a

00:26:43,330 --> 00:26:47,650
release incremental checkpoint so that

00:26:45,310 --> 00:26:49,750
checkpoints actually transfer the diffs

00:26:47,650 --> 00:26:51,950
over over previous checkpoints which has

00:26:49,750 --> 00:26:56,539
actually made this problem go

00:26:51,950 --> 00:26:58,190
for many users away and then we have we

00:26:56,539 --> 00:27:00,350
have the alignment duration what I was

00:26:58,190 --> 00:27:02,360
talking about earlier so this is in some

00:27:00,350 --> 00:27:03,769
sense I think the most important

00:27:02,360 --> 00:27:07,070
robustness metric because even if the

00:27:03,769 --> 00:27:08,059
others are high yeah if the others are

00:27:07,070 --> 00:27:09,409
high you know if you're in the back

00:27:08,059 --> 00:27:11,179
pressure situation you may still be

00:27:09,409 --> 00:27:12,860
working fairly well if you're taking

00:27:11,179 --> 00:27:14,269
long to checkpoint large state this may

00:27:12,860 --> 00:27:16,039
still be well but if your alignments get

00:27:14,269 --> 00:27:17,269
kind of thrown off and this is something

00:27:16,039 --> 00:27:19,460
you may want to look into

00:27:17,269 --> 00:27:20,840
so what could Edward are actually

00:27:19,460 --> 00:27:23,269
typical situations where these

00:27:20,840 --> 00:27:25,880
alignments start costing costing a lot

00:27:23,269 --> 00:27:28,820
and again I'm going back to the

00:27:25,880 --> 00:27:31,130
comparison I try to make a few a few our

00:27:28,820 --> 00:27:32,659
slides back that was that these

00:27:31,130 --> 00:27:34,580
alignments in in flanker and stream

00:27:32,659 --> 00:27:36,830
processing they kind of correspond to if

00:27:34,580 --> 00:27:38,360
you're running like if you're running

00:27:36,830 --> 00:27:40,820
distributed databases and to try to

00:27:38,360 --> 00:27:42,590
establish like kind of consistent points

00:27:40,820 --> 00:27:45,230
these are the points we have to take

00:27:42,590 --> 00:27:48,080
certain you have to you have to take

00:27:45,230 --> 00:27:49,760
certain um give to establish a a common

00:27:48,080 --> 00:27:51,289
denominator way say ok this transaction

00:27:49,760 --> 00:27:52,970
has actually completed in all my

00:27:51,289 --> 00:27:57,200
parallel charts versus this has not and

00:27:52,970 --> 00:27:59,059
so on right and what can happen in in

00:27:57,200 --> 00:28:00,740
such a system is for example that you

00:27:59,059 --> 00:28:02,330
know you're computing a very large

00:28:00,740 --> 00:28:03,529
aggregate or you're computing very large

00:28:02,330 --> 00:28:04,909
windows and streaming and you're

00:28:03,529 --> 00:28:06,440
emitting it right at the point in time

00:28:04,909 --> 00:28:08,360
when you do a checkpoint and it just so

00:28:06,440 --> 00:28:09,710
happens that this huge data is queue so

00:28:08,360 --> 00:28:12,470
it only affects one node and all the

00:28:09,710 --> 00:28:13,820
others are doing very well this think of

00:28:12,470 --> 00:28:15,679
it as you know the transaction would

00:28:13,820 --> 00:28:17,360
have effect one short very heavily and

00:28:15,679 --> 00:28:19,730
do a lot on that and all of the others

00:28:17,360 --> 00:28:20,899
it would be good in that case the others

00:28:19,730 --> 00:28:23,330
could still not commit the transaction

00:28:20,899 --> 00:28:25,639
before the other shard is done so this

00:28:23,330 --> 00:28:27,110
is kind of the equivalent to that you

00:28:25,639 --> 00:28:28,220
know that this it's just very secured

00:28:27,110 --> 00:28:31,010
work on one node or the

00:28:28,220 --> 00:28:32,809
the other equivalent of that would be I

00:28:31,010 --> 00:28:36,130
know it is just like temporarily stored

00:28:32,809 --> 00:28:38,240
by something like garbage collection and

00:28:36,130 --> 00:28:39,769
you know because link doesn't really

00:28:38,240 --> 00:28:41,480
work like a transactional system but

00:28:39,769 --> 00:28:43,490
like a streaming system a-- tries to

00:28:41,480 --> 00:28:45,830
make progress but some of the work will

00:28:43,490 --> 00:28:47,990
actually back up if certain notes say ok

00:28:45,830 --> 00:28:49,429
i'm actually as part of this alignment i

00:28:47,990 --> 00:28:50,750
can I cannot make progress here so

00:28:49,429 --> 00:28:52,100
there's there's going to be a little bit

00:28:50,750 --> 00:28:54,289
of back pressure built up along these

00:28:52,100 --> 00:28:55,669
cases and in some sense the most

00:28:54,289 --> 00:28:57,049
important thing that we've learned in

00:28:55,669 --> 00:28:59,389
order to keep the whole thing running

00:28:57,049 --> 00:29:01,309
well is make sure that these builds are

00:28:59,389 --> 00:29:03,710
build ups of like pressure around

00:29:01,309 --> 00:29:04,690
alignment they they are resolved very

00:29:03,710 --> 00:29:10,029
fast

00:29:04,690 --> 00:29:11,919
so and that that led to two things that

00:29:10,029 --> 00:29:15,429
we actually introduced into flink first

00:29:11,919 --> 00:29:17,019
was um a setting where you say give the

00:29:15,429 --> 00:29:18,879
system a minimum time between check

00:29:17,019 --> 00:29:21,309
points and I would actually say that if

00:29:18,879 --> 00:29:22,809
you run this large today this is almost

00:29:21,309 --> 00:29:24,580
the most important thing to set in

00:29:22,809 --> 00:29:26,799
checkpointing you don't I would actually

00:29:24,580 --> 00:29:28,869
almost argue that we drop the check

00:29:26,799 --> 00:29:30,909
point interval setting and actually

00:29:28,869 --> 00:29:33,039
purely work with with that or at least

00:29:30,909 --> 00:29:37,090
with something that takes this into

00:29:33,039 --> 00:29:39,129
account as as a policy think of it as

00:29:37,090 --> 00:29:40,479
the following way you could just tell

00:29:39,129 --> 00:29:42,369
the system you know to check points as

00:29:40,479 --> 00:29:44,559
fast as you can but always make sure

00:29:42,369 --> 00:29:46,599
that you have two seconds of pure

00:29:44,559 --> 00:29:48,159
progress between check points where you

00:29:46,599 --> 00:29:51,580
know we're not sharing bandwidth with

00:29:48,159 --> 00:29:54,369
storing the the snapshots in in whatever

00:29:51,580 --> 00:29:56,139
system has three HDFS and so on but just

00:29:54,369 --> 00:29:57,879
make pure progress on your computation

00:29:56,139 --> 00:30:00,039
don't don't do any resources on

00:29:57,879 --> 00:30:01,869
something else and then given that you

00:30:00,039 --> 00:30:03,099
fulfill this policy to check points as

00:30:01,869 --> 00:30:05,019
fast as possible this seems to be

00:30:03,099 --> 00:30:08,049
something that that has has worked

00:30:05,019 --> 00:30:09,729
really well for um for users that said

00:30:08,049 --> 00:30:11,979
it just said the Check Point interval to

00:30:09,729 --> 00:30:13,869
a very low value and then set a minimum

00:30:11,979 --> 00:30:16,629
time between check points the other

00:30:13,869 --> 00:30:19,720
thing that we can observed is that the

00:30:16,629 --> 00:30:22,299
more we the more asynchronous work a

00:30:19,720 --> 00:30:25,690
check point can do that the more these

00:30:22,299 --> 00:30:27,340
problems just seem to go away so that

00:30:25,690 --> 00:30:28,840
the cheaper the alignments get because

00:30:27,340 --> 00:30:30,190
they're they're smaller interruptions

00:30:28,840 --> 00:30:32,259
that cause because the build up of back

00:30:30,190 --> 00:30:34,570
pressure and that is that is what we've

00:30:32,259 --> 00:30:36,039
been actually working in like in

00:30:34,570 --> 00:30:37,960
response to these observations over the

00:30:36,039 --> 00:30:39,820
last of the last months a lot like

00:30:37,960 --> 00:30:41,409
making sure more and more and more stuff

00:30:39,820 --> 00:30:44,529
actually gets asynchronous so if you

00:30:41,409 --> 00:30:46,330
look at flink 1.2 they'd only had a sink

00:30:44,529 --> 00:30:48,039
on the snapshots for the rocks to be set

00:30:46,330 --> 00:30:49,749
back end and in one to one there was

00:30:48,039 --> 00:30:51,399
kind of a hidden feature to do it on the

00:30:49,749 --> 00:30:54,399
on the estate back-end that he actually

00:30:51,399 --> 00:30:56,590
keeps it in as plain Java objects on the

00:30:54,399 --> 00:30:58,720
heap and flink one three this actually

00:30:56,590 --> 00:31:01,059
became the the default option and

00:30:58,720 --> 00:31:02,859
operative state also became um became

00:31:01,059 --> 00:31:04,389
asynchronous and fling one four we now

00:31:02,859 --> 00:31:05,799
have an open pull request to also make

00:31:04,389 --> 00:31:09,669
timers and everything and synchronously

00:31:05,799 --> 00:31:13,690
are persisted so moving that moving that

00:31:09,669 --> 00:31:16,269
along another thing that we kind of

00:31:13,690 --> 00:31:18,100
realized is that we always we're always

00:31:16,269 --> 00:31:19,419
arguing between should

00:31:18,100 --> 00:31:21,940
what should we actually make the default

00:31:19,419 --> 00:31:23,980
choice for a state back end state back

00:31:21,940 --> 00:31:26,080
end in flink defines both the data

00:31:23,980 --> 00:31:28,240
structure that keeps in the end your

00:31:26,080 --> 00:31:29,919
your in memory variables especially if

00:31:28,240 --> 00:31:31,570
they're organized by key and you can in

00:31:29,919 --> 00:31:33,309
theory swap them in out of memory

00:31:31,570 --> 00:31:37,480
depending of computation for a key is

00:31:33,309 --> 00:31:39,130
actually hot or not there they're kind

00:31:37,480 --> 00:31:42,669
of two prominent ones one that just

00:31:39,130 --> 00:31:45,250
keeps it really as as pure pure memory

00:31:42,669 --> 00:31:47,289
of pure Java data structures and memory

00:31:45,250 --> 00:31:49,360
verses that serialize it into Roxie be

00:31:47,289 --> 00:31:51,760
back and forth and this is kind of the

00:31:49,360 --> 00:31:54,370
flowchart we we sort of came up with to

00:31:51,760 --> 00:31:55,809
to help to help users make the decision

00:31:54,370 --> 00:31:57,610
what what should they take if you have

00:31:55,809 --> 00:31:59,559
stayed that is larger than memory and

00:31:57,610 --> 00:32:01,750
obviously you need to pick Roxie be if

00:31:59,559 --> 00:32:03,340
you're comfortably within actually the

00:32:01,750 --> 00:32:05,289
memory of a machine then it's actually

00:32:03,340 --> 00:32:07,419
very interesting to trade to kind of

00:32:05,289 --> 00:32:09,700
look at how expensive is it to move

00:32:07,419 --> 00:32:11,799
these objects between as you realized

00:32:09,700 --> 00:32:12,730
form of heat and on he began whenever

00:32:11,799 --> 00:32:14,289
you want to compute on them you

00:32:12,730 --> 00:32:15,280
obviously need them on heap whenever you

00:32:14,289 --> 00:32:18,700
want to purchase them you would need

00:32:15,280 --> 00:32:20,200
them off heap how does your data rate

00:32:18,700 --> 00:32:22,210
effect that you know the cost of

00:32:20,200 --> 00:32:24,400
civilization and if yeah so this loader

00:32:22,210 --> 00:32:26,880
has kind of been a good help to do that

00:32:24,400 --> 00:32:31,409
it's a bit simplified but it it kind of

00:32:26,880 --> 00:32:33,820
gets the soul visceral yeah

00:32:31,409 --> 00:32:36,820
decision decision process roughly

00:32:33,820 --> 00:32:38,200
roughly map down I think we're running

00:32:36,820 --> 00:32:40,900
out of time

00:32:38,200 --> 00:32:43,330
and with that that's actually perfect

00:32:40,900 --> 00:32:45,340
because I'm also I'm also pretty much

00:32:43,330 --> 00:32:47,820
done done with the presentation there's

00:32:45,340 --> 00:32:50,409
just two things I would like to mention

00:32:47,820 --> 00:32:51,580
if you if you're actually interesting in

00:32:50,409 --> 00:32:53,320
the interest in the stream processing

00:32:51,580 --> 00:32:55,179
space or if you're working with flink

00:32:53,320 --> 00:32:57,429
and you like to arm you'd like to share

00:32:55,179 --> 00:33:00,130
some of your your personal lessons learn

00:32:57,429 --> 00:33:02,049
to use cases or just you know just

00:33:00,130 --> 00:33:03,429
here's the thought of what would be

00:33:02,049 --> 00:33:04,419
really cool in stream processing and you

00:33:03,429 --> 00:33:07,240
want to share it with a with the

00:33:04,419 --> 00:33:09,400
community around around that um at part

00:33:07,240 --> 00:33:12,190
there's a conference called fling

00:33:09,400 --> 00:33:14,409
forward that is taking place right here

00:33:12,190 --> 00:33:16,539
exactly where brilliant possibilities in

00:33:14,409 --> 00:33:19,030
a few months and the call for submission

00:33:16,539 --> 00:33:20,890
is still open so both of your if you're

00:33:19,030 --> 00:33:21,820
interested to be a speaker or you're

00:33:20,890 --> 00:33:26,470
just interested to learn more about

00:33:21,820 --> 00:33:29,620
stream processing very happy to yeah to

00:33:26,470 --> 00:33:31,620
meet you there and if you actually if

00:33:29,620 --> 00:33:33,330
you actually like the Searle work of

00:33:31,620 --> 00:33:35,340
stream processing apache fling cuts on

00:33:33,330 --> 00:33:38,280
the whole like real-time application

00:33:35,340 --> 00:33:40,320
echo system and you want to you'd like

00:33:38,280 --> 00:33:42,200
to work work on this full-time then come

00:33:40,320 --> 00:33:45,680
talk to us and we also have a booth and

00:33:42,200 --> 00:33:48,380
in the palais so feel free to stop by

00:33:45,680 --> 00:33:48,640
thanks for faced tougher

00:33:48,380 --> 00:33:54,699
[Applause]

00:33:48,640 --> 00:33:54,699

YouTube URL: https://www.youtube.com/watch?v=ct9cHlegI-U


