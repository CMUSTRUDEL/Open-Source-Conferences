Title: Berlin Buzzwords 2017: Erik Onnen - Optimization of Public Cloud for Efficiency and Scale #bbuz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	Twelve months ago, Cloudability's operations team set out on an ambitious project designed to control AWS spending while simultaneously adopting automation best practices and improving overall efficiency. This talk will highlight lessons learned in optimization of AWS operations resulting in a spending reduction of over 50% while simultaneously doubling the improvement of resource utilization and growing top line company revenue.

Specific topics will include Cloudability's use of automation tools including Puppet, Docker and Packer in addition to AWS-specific tools like Lambda functions, Elastic Container Service, the EC2 Spot Market, Auto Scaling Groups and AWS Aurora. 

This talk will cover specific elements of operating a SaaS infrastructure for cloud efficiency but should be applicable to all users of cloud computing.

This talk is presented by Cloudability.

Read more:
https://2017.berlinbuzzwords.de/17/session/optimization-public-cloud-efficiency-and-scale

About Erik Onnen:
https://2017.berlinbuzzwords.de/users/erik-onnen-0

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:06,470 --> 00:00:11,940
I'll apologize up front I'm less than 48

00:00:09,690 --> 00:00:13,740
hours in Germany from the west coast so

00:00:11,940 --> 00:00:15,270
I'm a bit jet-lagged I also picked up a

00:00:13,740 --> 00:00:16,770
cold along the way so I'm probably going

00:00:15,270 --> 00:00:18,420
to drink both these waters as I as I

00:00:16,770 --> 00:00:20,220
going through the talk real quickly

00:00:18,420 --> 00:00:21,720
before I get started

00:00:20,220 --> 00:00:22,679
show hands in the audience number of

00:00:21,720 --> 00:00:27,380
people who are running production

00:00:22,679 --> 00:00:31,589
workloads in either AWS or GC PE roger

00:00:27,380 --> 00:00:33,270
half the audience or so ok so as

00:00:31,589 --> 00:00:34,560
mentioned I'm Aragon and I'm the

00:00:33,270 --> 00:00:37,260
vice-president engineering at the

00:00:34,560 --> 00:00:38,520
company called credibility I predominate

00:00:37,260 --> 00:00:40,380
have a distributed systems and

00:00:38,520 --> 00:00:41,220
operations background the majority of

00:00:40,380 --> 00:00:42,960
this talk is going to be sort of

00:00:41,220 --> 00:00:45,900
operations focused in terms of how we

00:00:42,960 --> 00:00:47,400
scale my team and cloud ability we'll go

00:00:45,900 --> 00:00:48,750
into a little bit about what cloud

00:00:47,400 --> 00:00:50,010
ability does is a product I'm not going

00:00:48,750 --> 00:00:52,440
to try and dwell on that in this talk

00:00:50,010 --> 00:00:53,850
this is more focused on how we've

00:00:52,440 --> 00:00:56,490
actually changed some our own internal

00:00:53,850 --> 00:00:58,620
operational policies so a real brief

00:00:56,490 --> 00:01:00,240
history about cloud ability we were

00:00:58,620 --> 00:01:01,950
funded in 2010 in Portland Oregon

00:01:00,240 --> 00:01:03,750
Portland if you're not familiar is

00:01:01,950 --> 00:01:07,409
between Seattle and the Bay Area on the

00:01:03,750 --> 00:01:08,790
west coast we our mission in life is to

00:01:07,409 --> 00:01:10,620
help our customers make the most

00:01:08,790 --> 00:01:12,060
effective use possible of public cloud

00:01:10,620 --> 00:01:13,560
and I'll go into a little bit of detail

00:01:12,060 --> 00:01:16,230
about what I mean by public cloud in a

00:01:13,560 --> 00:01:17,610
moment we are a pure SAS offering which

00:01:16,230 --> 00:01:19,440
means we don't operate a data center

00:01:17,610 --> 00:01:21,420
everything that we do is completely

00:01:19,440 --> 00:01:23,880
based in AWS for the most part we run a

00:01:21,420 --> 00:01:26,270
little bit of arms infrastructure in GCP

00:01:23,880 --> 00:01:28,650
Google compute but for the most part

00:01:26,270 --> 00:01:30,210
every bit of our offering is operating

00:01:28,650 --> 00:01:31,500
in Amazon Web Services and that'll be

00:01:30,210 --> 00:01:33,240
the focus of this discussion

00:01:31,500 --> 00:01:35,550
that's that most of what I'll talk about

00:01:33,240 --> 00:01:37,140
today is fairly applicable to the other

00:01:35,550 --> 00:01:39,930
major cloud computing platforms there's

00:01:37,140 --> 00:01:41,310
not very much AWS centric in this talk

00:01:39,930 --> 00:01:43,530
it just happens to be what we use to

00:01:41,310 --> 00:01:45,300
operate our infrastructure one thing I

00:01:43,530 --> 00:01:46,860
did want to emphasize is that as in

00:01:45,300 --> 00:01:48,690
startup we followed what I would

00:01:46,860 --> 00:01:51,180
characterize is a pretty typical startup

00:01:48,690 --> 00:01:53,520
path meaning in the early days we grew

00:01:51,180 --> 00:01:54,870
very quickly and if we encountered

00:01:53,520 --> 00:01:56,250
certain problems usually we tried to

00:01:54,870 --> 00:01:57,690
just spend our way out of those problems

00:01:56,250 --> 00:01:59,280
we didn't really focus on engineering

00:01:57,690 --> 00:02:02,040
first principles per se we're trying to

00:01:59,280 --> 00:02:04,260
ship features very quickly and that was

00:02:02,040 --> 00:02:05,520
what we favored we also did what was

00:02:04,260 --> 00:02:07,350
comfortable meaning what did the team at

00:02:05,520 --> 00:02:08,549
the time understand how to operate what

00:02:07,350 --> 00:02:10,979
were they familiar with use those

00:02:08,549 --> 00:02:12,269
technologies ship features as rapidly as

00:02:10,979 --> 00:02:14,219
possible get them market test them and

00:02:12,269 --> 00:02:15,270
move on and over time that becomes

00:02:14,219 --> 00:02:17,160
something that

00:02:15,270 --> 00:02:19,020
that sort of neglect for how we're using

00:02:17,160 --> 00:02:20,670
cloud resources is something that

00:02:19,020 --> 00:02:21,960
ultimately will catch up with you and

00:02:20,670 --> 00:02:24,960
that's going to be a big part of the

00:02:21,960 --> 00:02:26,640
focus of this talk so if I could sum up

00:02:24,960 --> 00:02:29,010
this talk in terms of memes it would be

00:02:26,640 --> 00:02:30,390
two things I will be playing the the

00:02:29,010 --> 00:02:33,150
role of the old man yelling of the cloud

00:02:30,390 --> 00:02:35,760
or grandpa Simpson but effectively this

00:02:33,150 --> 00:02:37,980
is a journey of how we got good at

00:02:35,760 --> 00:02:40,140
operating AWS cloud and so when I joined

00:02:37,980 --> 00:02:41,910
the company in 2015 we're doing what we

00:02:40,140 --> 00:02:43,290
needed to provide value to our customers

00:02:41,910 --> 00:02:45,510
but we weren't really keeping our own

00:02:43,290 --> 00:02:47,640
house in order and we over time had to

00:02:45,510 --> 00:02:49,410
learn how to properly operate cloud so

00:02:47,640 --> 00:02:51,000
that we could likely try and do for our

00:02:49,410 --> 00:02:53,330
customers extract the maximum value out

00:02:51,000 --> 00:02:55,920
of how we were consuming cloud resources

00:02:53,330 --> 00:02:58,440
so very quickly I'm going to cover some

00:02:55,920 --> 00:02:59,850
terminology that I'll throw around a lot

00:02:58,440 --> 00:03:02,160
of acronyms in this talk so that I can

00:02:59,850 --> 00:03:04,170
not articulate them every time I'll do a

00:03:02,160 --> 00:03:05,520
quick history of our use of cloud

00:03:04,170 --> 00:03:07,440
computing and then I'm going to go

00:03:05,520 --> 00:03:09,060
through a high-level overview of what we

00:03:07,440 --> 00:03:11,340
change in terms of how we operate our

00:03:09,060 --> 00:03:12,810
own internal teams that will then play

00:03:11,340 --> 00:03:15,570
into sort of our journey of cloud

00:03:12,810 --> 00:03:17,910
efficiency and some specific changes

00:03:15,570 --> 00:03:20,100
that we made and then we'll dig into

00:03:17,910 --> 00:03:21,600
some specific case studies around areas

00:03:20,100 --> 00:03:23,160
where we have pointed improvements where

00:03:21,600 --> 00:03:25,200
we want to improve how we were using

00:03:23,160 --> 00:03:26,940
cloud and I think about a little bit of

00:03:25,200 --> 00:03:29,520
time for Q&A at the end so some

00:03:26,940 --> 00:03:31,140
high-level technical terminology when I

00:03:29,520 --> 00:03:32,550
say public cloud I may use that

00:03:31,140 --> 00:03:33,840
interchangeably with the term called

00:03:32,550 --> 00:03:35,010
paths that's an acronym for

00:03:33,840 --> 00:03:36,810
platform-as-a-service

00:03:35,010 --> 00:03:38,700
I basically mean the same thing for both

00:03:36,810 --> 00:03:40,830
of those and in every case you can look

00:03:38,700 --> 00:03:43,380
at that as either AWS Amazon Web

00:03:40,830 --> 00:03:46,080
Services Microsoft Azure or GCP Google

00:03:43,380 --> 00:03:47,459
compute platform that's at least in the

00:03:46,080 --> 00:03:49,430
context of this talk what I mean when

00:03:47,459 --> 00:03:51,000
I'm talking about pass or public cloud

00:03:49,430 --> 00:03:52,830
oftentimes there's a negative

00:03:51,000 --> 00:03:54,690
connotation around public cloud people

00:03:52,830 --> 00:03:56,670
think oh it's insecure and it's not

00:03:54,690 --> 00:03:59,580
well-managed that's a bit of a misnomer

00:03:56,670 --> 00:04:00,840
in every case these days modern best

00:03:59,580 --> 00:04:02,670
practices would have some sort of

00:04:00,840 --> 00:04:04,860
Software Defined Networking like PCs and

00:04:02,670 --> 00:04:06,000
firewalls and various platform services

00:04:04,860 --> 00:04:07,650
in front of things just because it's

00:04:06,000 --> 00:04:09,240
public cloud doesn't imply an inherent

00:04:07,650 --> 00:04:11,660
level of insecurity

00:04:09,240 --> 00:04:14,670
this talk is also about efficiency so

00:04:11,660 --> 00:04:16,140
efficiency in this regard means if I

00:04:14,670 --> 00:04:17,669
spend a dollar with a cloud provider I

00:04:16,140 --> 00:04:19,109
spend a euro with the cloud provider and

00:04:17,669 --> 00:04:21,120
I getting the maximum value for that

00:04:19,109 --> 00:04:22,410
dollar my operating my infrastructure

00:04:21,120 --> 00:04:24,390
well and then there's another component

00:04:22,410 --> 00:04:26,010
of this talk which is scale and scale

00:04:24,390 --> 00:04:27,300
we'll have two meetings in this talk the

00:04:26,010 --> 00:04:28,919
first meeting is sort of the

00:04:27,300 --> 00:04:30,569
additional meaning of as our

00:04:28,919 --> 00:04:33,090
infrastructure grows as we're operating

00:04:30,569 --> 00:04:34,470
more resources within public cloud are

00:04:33,090 --> 00:04:35,789
we able to do that without making

00:04:34,470 --> 00:04:37,919
significant changes in our engineering

00:04:35,789 --> 00:04:40,050
infrastructure but it'll also refer to

00:04:37,919 --> 00:04:42,120
scale in terms of how my team operates

00:04:40,050 --> 00:04:44,190
meaning can we do more with fewer people

00:04:42,120 --> 00:04:46,740
or can we continue to grow the business

00:04:44,190 --> 00:04:48,479
as a meaningful platform without needing

00:04:46,740 --> 00:04:50,669
to throw a bunch of headcount at the

00:04:48,479 --> 00:04:51,930
problem and hire a bunch of people can

00:04:50,669 --> 00:04:55,020
we continue evolving our business

00:04:51,930 --> 00:04:58,110
without significant pain efficiency and

00:04:55,020 --> 00:04:59,580
scale are definitely not always going to

00:04:58,110 --> 00:05:02,460
co-occur especially in an early-stage

00:04:59,580 --> 00:05:04,169
startup so while we may be able to scale

00:05:02,460 --> 00:05:06,449
easily by throwing money at a problem

00:05:04,169 --> 00:05:07,770
that doesn't necessarily mean that we're

00:05:06,449 --> 00:05:09,840
efficient in terms of how you use cloud

00:05:07,770 --> 00:05:11,669
resources likewise you can be highly

00:05:09,840 --> 00:05:13,560
efficient and be completely unscalable

00:05:11,669 --> 00:05:15,150
so you can be super efficient it's been

00:05:13,560 --> 00:05:16,259
very little money in clouds but not be

00:05:15,150 --> 00:05:17,340
able to scale your business or your

00:05:16,259 --> 00:05:20,490
infrastructure and not be able to bring

00:05:17,340 --> 00:05:22,830
on new customers easily and so evolving

00:05:20,490 --> 00:05:24,180
both of those at the same time is really

00:05:22,830 --> 00:05:26,009
where a lot of the secret sauce from

00:05:24,180 --> 00:05:28,650
this talk comes in and then I'll often

00:05:26,009 --> 00:05:29,819
use the term compute resources that just

00:05:28,650 --> 00:05:32,580
basically means there's a thing that

00:05:29,819 --> 00:05:34,380
we're paying for in our case in AWS so

00:05:32,580 --> 00:05:36,690
most commonly people think of that think

00:05:34,380 --> 00:05:38,190
of resources as an ec2 node but

00:05:36,690 --> 00:05:39,779
resources could also be something like

00:05:38,190 --> 00:05:42,180
an auto scaling group or it could also

00:05:39,779 --> 00:05:43,830
be an ECL cluster pretty much anything

00:05:42,180 --> 00:05:45,960
that Amazon is going to charge you for

00:05:43,830 --> 00:05:49,050
would be categorized as a resource and

00:05:45,960 --> 00:05:50,930
the terms at this time so if you could

00:05:49,050 --> 00:05:54,449
put yourself into a time machine and

00:05:50,930 --> 00:05:56,009
rewind about 10 to 15 years this is

00:05:54,449 --> 00:05:58,199
largely what my life looked like I

00:05:56,009 --> 00:05:59,729
literally spend lots of time in data

00:05:58,199 --> 00:06:02,580
centers this is not me this is actually

00:05:59,729 --> 00:06:06,479
a picture of the Oregon Google Data

00:06:02,580 --> 00:06:08,370
Center that they run with GCP cloud but

00:06:06,479 --> 00:06:10,199
effectively I spent a lot of times in

00:06:08,370 --> 00:06:11,699
racks and data centers spending many

00:06:10,199 --> 00:06:13,650
years sort of honing the craft of how do

00:06:11,699 --> 00:06:16,740
we operate data center infrastructure

00:06:13,650 --> 00:06:18,180
this when I started engaging in the

00:06:16,740 --> 00:06:19,860
industry there weren't things like

00:06:18,180 --> 00:06:20,940
puppet and chef config management was

00:06:19,860 --> 00:06:23,490
really just sort of getting off the

00:06:20,940 --> 00:06:24,690
ground and over time we learned okay

00:06:23,490 --> 00:06:26,129
well how do we operate data center as

00:06:24,690 --> 00:06:27,210
well it was an unknown thing we

00:06:26,129 --> 00:06:30,599
eventually got better at it we thought

00:06:27,210 --> 00:06:33,090
we had to discipline mastered and and we

00:06:30,599 --> 00:06:36,029
sort of plotted on then along starting

00:06:33,090 --> 00:06:38,670
in about 2007 up through 2009 we started

00:06:36,029 --> 00:06:40,410
seeing AWS really emerge

00:06:38,670 --> 00:06:41,760
and and that sort of changed a lot of

00:06:40,410 --> 00:06:42,810
things in terms of what we thought we

00:06:41,760 --> 00:06:46,200
knew about how to operate our

00:06:42,810 --> 00:06:48,150
infrastructure so when I drink loud

00:06:46,200 --> 00:06:50,400
ability one of the things that I

00:06:48,150 --> 00:06:51,750
initially did was step back look at our

00:06:50,400 --> 00:06:54,000
infrastructure look at how we were

00:06:51,750 --> 00:06:55,920
operating things and see where I thought

00:06:54,000 --> 00:06:58,440
we needed to pay some attention and

00:06:55,920 --> 00:06:59,940
effectively at the time in 2015 we were

00:06:58,440 --> 00:07:02,100
operating our data center like a cloud

00:06:59,940 --> 00:07:03,660
so what does that mean

00:07:02,100 --> 00:07:05,640
means the number of things as a handful

00:07:03,660 --> 00:07:07,440
examples that I can point to we we never

00:07:05,640 --> 00:07:10,170
really trued up decisions or reconciled

00:07:07,440 --> 00:07:12,270
value meaning as a team spun up a

00:07:10,170 --> 00:07:13,950
handful of ec2 servers did we step back

00:07:12,270 --> 00:07:15,480
over time and look at those ec2 servers

00:07:13,950 --> 00:07:17,580
where was it a good decision to use the

00:07:15,480 --> 00:07:18,960
instance size that we use was a good

00:07:17,580 --> 00:07:21,810
decision to use the family that we chose

00:07:18,960 --> 00:07:23,190
were they well utilized over time or did

00:07:21,810 --> 00:07:24,630
somebody just spin them up and walk away

00:07:23,190 --> 00:07:26,340
from them if it was a test environment

00:07:24,630 --> 00:07:29,760
was anybody even paying any attention to

00:07:26,340 --> 00:07:31,440
that over time we didn't really have any

00:07:29,760 --> 00:07:33,600
sort of science around capacity planning

00:07:31,440 --> 00:07:34,950
so if we needed something we click the

00:07:33,600 --> 00:07:36,510
button we turned it on we provisioned

00:07:34,950 --> 00:07:37,680
the resource but we didn't step back and

00:07:36,510 --> 00:07:39,150
say ok well what do we think we're

00:07:37,680 --> 00:07:40,740
trending over time what do we expect

00:07:39,150 --> 00:07:43,350
where do you expect to be in terms of

00:07:40,740 --> 00:07:45,930
our consumption cloud resources say 12

00:07:43,350 --> 00:07:48,300
or 24 months out into the future and

00:07:45,930 --> 00:07:49,740
also point out that our platform in

00:07:48,300 --> 00:07:51,540
terms of the service we're offering was

00:07:49,740 --> 00:07:54,840
not being very adaptive to changes in

00:07:51,540 --> 00:07:56,970
AWS ecosystem so if you don't follow

00:07:54,840 --> 00:07:58,590
what Amazon is doing with AWS they're

00:07:56,970 --> 00:08:00,170
innovating at a breakneck speed they're

00:07:58,590 --> 00:08:03,210
constantly shipping net new products

00:08:00,170 --> 00:08:05,190
over the last 12 months they had over a

00:08:03,210 --> 00:08:06,630
thousand major new releases that's not

00:08:05,190 --> 00:08:07,980
necessarily linked in that new product

00:08:06,630 --> 00:08:09,660
about what counts as sort of a minor

00:08:07,980 --> 00:08:12,600
product iteration release or taking a

00:08:09,660 --> 00:08:14,040
net new product market and we've quite

00:08:12,600 --> 00:08:15,870
frankly weren't being adaptive and

00:08:14,040 --> 00:08:18,660
taking advantage of services that the

00:08:15,870 --> 00:08:20,100
platform was bringing to market another

00:08:18,660 --> 00:08:21,840
concrete example of this is we were

00:08:20,100 --> 00:08:23,640
running one virtual machine Pro workload

00:08:21,840 --> 00:08:25,500
so for example we had an asynchronous

00:08:23,640 --> 00:08:27,420
consumer that was reading a message off

00:08:25,500 --> 00:08:29,130
the queue we would have deployment unit

00:08:27,420 --> 00:08:30,750
that would deploy to is one or more

00:08:29,130 --> 00:08:32,820
virtual machines that would consume that

00:08:30,750 --> 00:08:34,620
queue but that was kind of the extent of

00:08:32,820 --> 00:08:35,940
it right we wouldn't have say multiple

00:08:34,620 --> 00:08:37,830
workloads running on virtual machines

00:08:35,940 --> 00:08:39,510
and oftentimes if something was working

00:08:37,830 --> 00:08:41,360
we would step back and not touch it and

00:08:39,510 --> 00:08:44,070
then move on to the next task at hand

00:08:41,360 --> 00:08:45,120
this is effectively not all that

00:08:44,070 --> 00:08:47,160
uncommon in terms of how you would

00:08:45,120 --> 00:08:48,480
operate a data center but for all of

00:08:47,160 --> 00:08:49,800
these things I would contend that these

00:08:48,480 --> 00:08:50,430
are not the right way that you should be

00:08:49,800 --> 00:08:53,160
operating

00:08:50,430 --> 00:08:54,240
efficiently in public club and then

00:08:53,160 --> 00:08:56,339
there were handful of other things that

00:08:54,240 --> 00:08:57,720
we needed to change at the time we sort

00:08:56,339 --> 00:09:00,000
of lacked accountability or ownership

00:08:57,720 --> 00:09:02,100
over resources so it was not uncommon to

00:09:00,000 --> 00:09:04,140
go find a server running somewhere and

00:09:02,100 --> 00:09:07,290
we knew how I was configured because it

00:09:04,140 --> 00:09:09,240
was in our puppet infrastructure but we

00:09:07,290 --> 00:09:10,890
weren't quite sure who the actual owner

00:09:09,240 --> 00:09:12,209
of that was so if something was running

00:09:10,890 --> 00:09:13,920
a trip in the red and it was at a

00:09:12,209 --> 00:09:15,390
hundred percent CPU utilization wasn't

00:09:13,920 --> 00:09:19,020
necessarily easy to go track down who's

00:09:15,390 --> 00:09:20,130
responsible for that service we had very

00:09:19,020 --> 00:09:21,240
little financial leverage of our

00:09:20,130 --> 00:09:22,740
infrastructure and I'll get into what

00:09:21,240 --> 00:09:25,440
that means in a bit more details would

00:09:22,740 --> 00:09:26,670
go to the talk and quite frankly our

00:09:25,440 --> 00:09:28,980
growth in cloud spend was not

00:09:26,670 --> 00:09:30,720
sustainable so we were spending

00:09:28,980 --> 00:09:32,490
significantly more and more each month

00:09:30,720 --> 00:09:34,230
with Amazon as we grew our business and

00:09:32,490 --> 00:09:35,490
we needed to step back and assess why is

00:09:34,230 --> 00:09:37,140
this the case this is something we can

00:09:35,490 --> 00:09:38,070
actually get under control or is this

00:09:37,140 --> 00:09:39,690
something that's just going to continue

00:09:38,070 --> 00:09:42,480
to spiral forever and we need to figure

00:09:39,690 --> 00:09:43,649
out what to do and lastly we wanted to

00:09:42,480 --> 00:09:48,270
be able to tell enough an incredible

00:09:43,649 --> 00:09:50,010
story so you at the time in 2015 and

00:09:48,270 --> 00:09:52,170
running into 2016 we had a great

00:09:50,010 --> 00:09:53,730
platform for our customers and we were

00:09:52,170 --> 00:09:55,440
helping them manage their cloud a fish

00:09:53,730 --> 00:09:57,270
their cloud sort of resource utilization

00:09:55,440 --> 00:09:58,890
efficiently but we weren't actually

00:09:57,270 --> 00:10:01,170
applying those same best practices to

00:09:58,890 --> 00:10:02,190
our own internal use of cloud and so

00:10:01,170 --> 00:10:04,320
that's what the majority has taught

00:10:02,190 --> 00:10:06,510
focuses on is how do we actually change

00:10:04,320 --> 00:10:07,890
our operational policies to make better

00:10:06,510 --> 00:10:10,410
use of cloud so there are number of

00:10:07,890 --> 00:10:12,600
changes we enacted in particular we

00:10:10,410 --> 00:10:14,310
changed some team structure we changed

00:10:12,600 --> 00:10:16,320
our some fundamental pieces of our

00:10:14,310 --> 00:10:18,270
architecture we changed our basic

00:10:16,320 --> 00:10:20,130
approach to how we do operations in the

00:10:18,270 --> 00:10:23,250
cloud and then we changed our approach

00:10:20,130 --> 00:10:25,529
to cloud usage in general so dig in a

00:10:23,250 --> 00:10:27,510
bit more there our team structure we

00:10:25,529 --> 00:10:29,430
effectively really reoriented our teams

00:10:27,510 --> 00:10:31,650
to be much more functionally aligned

00:10:29,430 --> 00:10:33,240
around pieces of our architecture so one

00:10:31,650 --> 00:10:35,550
of the offerings that we have for our

00:10:33,240 --> 00:10:38,850
customers is analytics around how you're

00:10:35,550 --> 00:10:40,800
consuming cloud resources and as any

00:10:38,850 --> 00:10:42,570
good analytics companies want to do we

00:10:40,800 --> 00:10:45,029
have a data ingestion pipeline that

00:10:42,570 --> 00:10:46,560
pulls data down moves it into sort of a

00:10:45,029 --> 00:10:48,390
data warehouse type infrastructure I'll

00:10:46,560 --> 00:10:50,279
go over some details of what that

00:10:48,390 --> 00:10:51,990
pipeline does but at the time we started

00:10:50,279 --> 00:10:54,270
this sort of team reorientation we

00:10:51,990 --> 00:10:55,560
couldn't actually have a clear owner of

00:10:54,270 --> 00:10:57,060
the pipeline function in or did we have

00:10:55,560 --> 00:10:58,380
a clear owner of say the analytics

00:10:57,060 --> 00:10:59,610
function we have what would

00:10:58,380 --> 00:11:01,890
traditionally be called full stack

00:10:59,610 --> 00:11:02,620
developers and everybody kind of dabbled

00:11:01,890 --> 00:11:04,720
in every piece

00:11:02,620 --> 00:11:06,940
the infrastructure and so we set out to

00:11:04,720 --> 00:11:08,320
sort of to specialize in certain areas

00:11:06,940 --> 00:11:09,880
of the architecture and to have better

00:11:08,320 --> 00:11:11,950
accountability around those areas of the

00:11:09,880 --> 00:11:14,140
architecture we implemented what is

00:11:11,950 --> 00:11:15,790
commonly called an SR remodel site

00:11:14,140 --> 00:11:18,490
reliability engineers the acronym from

00:11:15,790 --> 00:11:20,560
Google and what this means in short is

00:11:18,490 --> 00:11:22,210
that if you're writing a piece of code

00:11:20,560 --> 00:11:23,650
you are going to be the one that deploys

00:11:22,210 --> 00:11:24,760
it to the production environment you are

00:11:23,650 --> 00:11:26,440
going to be the one that is accountable

00:11:24,760 --> 00:11:27,760
for when it alerts if it breaks in the

00:11:26,440 --> 00:11:29,050
middle of the night you're the one

00:11:27,760 --> 00:11:30,550
that's going to get paged not an

00:11:29,050 --> 00:11:32,200
Operations team and we push that

00:11:30,550 --> 00:11:34,990
accountability down into individual

00:11:32,200 --> 00:11:36,700
development teams as part of that each

00:11:34,990 --> 00:11:38,920
of these functional teams that own the

00:11:36,700 --> 00:11:40,990
part of our architecture was responsible

00:11:38,920 --> 00:11:42,160
for KPIs around efficiency and we'll go

00:11:40,990 --> 00:11:44,230
into some examples of what those look

00:11:42,160 --> 00:11:46,690
like but KPI being and key performance

00:11:44,230 --> 00:11:50,110
indicator and you could look this as an

00:11:46,690 --> 00:11:53,080
example this would be our my utilization

00:11:50,110 --> 00:11:55,390
of my ec2 servers above 75% or more or

00:11:53,080 --> 00:11:57,010
am I just wasteful e spending up new vc2

00:11:55,390 --> 00:11:58,300
servers when I don't need them am i

00:11:57,010 --> 00:11:59,860
letting them linger and not turning them

00:11:58,300 --> 00:12:02,170
off when I don't need them like being

00:11:59,860 --> 00:12:03,820
elastic with my infrastructure those are

00:12:02,170 --> 00:12:05,290
some examples of KPIs that we

00:12:03,820 --> 00:12:08,260
implemented for individual functional

00:12:05,290 --> 00:12:10,090
teams and then last thing we also had

00:12:08,260 --> 00:12:12,280
for each team a notion of a unit

00:12:10,090 --> 00:12:13,420
economic that they were responsible for

00:12:12,280 --> 00:12:14,920
providing to the business and I'll

00:12:13,420 --> 00:12:17,110
provide some concrete examples of that a

00:12:14,920 --> 00:12:18,480
bit later on the architectural upfront

00:12:17,110 --> 00:12:20,530
we made a conscious decision to

00:12:18,480 --> 00:12:23,410
specifically embrace needed cloud

00:12:20,530 --> 00:12:24,790
platform and tools so there's going to

00:12:23,410 --> 00:12:26,590
be a lot of concrete examples of that in

00:12:24,790 --> 00:12:28,630
the talk but effectively we wanted to

00:12:26,590 --> 00:12:30,010
stop ignoring what AWS was doing around

00:12:28,630 --> 00:12:32,200
us and to leverage God as best as we

00:12:30,010 --> 00:12:34,330
possibly could while also focusing on

00:12:32,200 --> 00:12:35,770
things that we were good at and adding

00:12:34,330 --> 00:12:37,180
value on top of the platform but not

00:12:35,770 --> 00:12:38,200
just operating infrastructure for the

00:12:37,180 --> 00:12:40,330
sake of operating additional

00:12:38,200 --> 00:12:41,620
infrastructure and in certain cases we

00:12:40,330 --> 00:12:42,940
wanted to identify opportunities where

00:12:41,620 --> 00:12:45,430
we could actually simplify some of our

00:12:42,940 --> 00:12:47,020
architecture and maybe relax the needs

00:12:45,430 --> 00:12:48,400
as they were related to the business and

00:12:47,020 --> 00:12:52,060
they've an example of that a bit later

00:12:48,400 --> 00:12:53,500
in the talk in regards to the operations

00:12:52,060 --> 00:12:55,510
team we completely revamped that

00:12:53,500 --> 00:12:57,220
function within our infrastructure so we

00:12:55,510 --> 00:12:58,930
wanted our operations team to rather

00:12:57,220 --> 00:13:00,370
than being a barrier or somebody who

00:12:58,930 --> 00:13:01,810
received a piece of code from an

00:13:00,370 --> 00:13:03,910
engineering team we wanted our

00:13:01,810 --> 00:13:05,770
operations team to actually be an

00:13:03,910 --> 00:13:07,600
enabler so we set out to make sure that

00:13:05,770 --> 00:13:09,610
they would become the experts in

00:13:07,600 --> 00:13:11,530
platform capabilities meaning they're

00:13:09,610 --> 00:13:11,740
responsible for keeping tabs on what M

00:13:11,530 --> 00:13:14,110
is

00:13:11,740 --> 00:13:15,130
is doing they then take that they digest

00:13:14,110 --> 00:13:16,840
that given their knowledge of our

00:13:15,130 --> 00:13:18,400
internal systems and they actually

00:13:16,840 --> 00:13:21,430
become a leverage function for our

00:13:18,400 --> 00:13:23,260
engineering teams so they may see a

00:13:21,430 --> 00:13:24,910
change in an auto scaling group for

00:13:23,260 --> 00:13:26,320
example and in the way Amazon manages

00:13:24,910 --> 00:13:27,940
cloud formation templates relative to

00:13:26,320 --> 00:13:29,410
auto scaling groups and they'll turn

00:13:27,940 --> 00:13:31,330
around and produce an example of that

00:13:29,410 --> 00:13:32,500
back to the engineering team offer that

00:13:31,330 --> 00:13:33,790
up as hey here's something that you

00:13:32,500 --> 00:13:35,110
could leverage that we think would help

00:13:33,790 --> 00:13:37,240
this particular service that you're

00:13:35,110 --> 00:13:39,340
maintaining their job is no longer to

00:13:37,240 --> 00:13:41,620
operate code for people it was to more

00:13:39,340 --> 00:13:42,970
impactful II enable the engineers

00:13:41,620 --> 00:13:46,090
themselves that were actually deploying

00:13:42,970 --> 00:13:47,950
code the obstacle in our environment

00:13:46,090 --> 00:13:50,050
have responsibility for shared services

00:13:47,950 --> 00:13:52,180
so things like our elk stack or log

00:13:50,050 --> 00:13:54,130
aggregation our metrics monitoring and

00:13:52,180 --> 00:13:56,110
alerting infrastructure they sustain

00:13:54,130 --> 00:13:57,310
that in that infrastructure but it's a

00:13:56,110 --> 00:13:59,620
tool that is used by individual

00:13:57,310 --> 00:14:01,090
engineering teams themselves and then

00:13:59,620 --> 00:14:04,030
they kept some traditional duties as

00:14:01,090 --> 00:14:06,340
part of this in terms of month being

00:14:04,030 --> 00:14:07,510
security resources for the teams but the

00:14:06,340 --> 00:14:09,130
key takeaway here is that we really

00:14:07,510 --> 00:14:10,480
changed them from being somebody who's

00:14:09,130 --> 00:14:11,710
on the other side of the fence somebody

00:14:10,480 --> 00:14:13,540
who is in sort of an adversarial

00:14:11,710 --> 00:14:14,980
contentious relationship to being an

00:14:13,540 --> 00:14:17,620
enabler for the engineering teams and a

00:14:14,980 --> 00:14:20,380
partner to the engineering teams so that

00:14:17,620 --> 00:14:22,360
lets the oh sorry I glossed over one

00:14:20,380 --> 00:14:24,580
last thing originally that last bullet

00:14:22,360 --> 00:14:26,440
point was eat our own dog food which is

00:14:24,580 --> 00:14:27,970
sort of an industry saying my marketing

00:14:26,440 --> 00:14:30,430
team didn't like that so we called this

00:14:27,970 --> 00:14:31,990
drink our own champagne but this

00:14:30,430 --> 00:14:33,460
basically means take our own product

00:14:31,990 --> 00:14:35,470
apply it to how we operate our

00:14:33,460 --> 00:14:36,880
infrastructure and feed that back into

00:14:35,470 --> 00:14:38,290
our product to make it a better stronger

00:14:36,880 --> 00:14:39,670
product based on how we're actually

00:14:38,290 --> 00:14:42,850
doing the thing that our product is

00:14:39,670 --> 00:14:44,890
meant to do so the remainder of the talk

00:14:42,850 --> 00:14:46,900
is going to go through what I call the

00:14:44,890 --> 00:14:49,300
the journey of cloud efficiency and it's

00:14:46,900 --> 00:14:51,670
broken down into four stages I'm going

00:14:49,300 --> 00:14:53,680
to frame this relative to our specific

00:14:51,670 --> 00:14:55,930
experience with AWS but I can tell you

00:14:53,680 --> 00:14:57,880
from what we see from our customers this

00:14:55,930 --> 00:14:59,110
is a very common sort of evolution in

00:14:57,880 --> 00:15:03,700
terms of how you adopt cloud

00:14:59,110 --> 00:15:05,740
infrastructure in the the stages

00:15:03,700 --> 00:15:07,690
themselves aren't really measured by any

00:15:05,740 --> 00:15:09,160
metric so that sort of up into the right

00:15:07,690 --> 00:15:10,510
gradient in the area underneath that

00:15:09,160 --> 00:15:12,070
doesn't really qualify anything it's

00:15:10,510 --> 00:15:14,080
just meant to convey a level of

00:15:12,070 --> 00:15:15,540
sophistication and a level of effort

00:15:14,080 --> 00:15:20,140
that you need to put in to continue

00:15:15,540 --> 00:15:21,820
doing cloud well effectively so the

00:15:20,140 --> 00:15:23,020
first year visibility is a pretty

00:15:21,820 --> 00:15:25,150
straightforward thing but you'd be

00:15:23,020 --> 00:15:25,640
surprised how many people don't get it

00:15:25,150 --> 00:15:27,740
right

00:15:25,640 --> 00:15:29,089
and it really starts with just simply

00:15:27,740 --> 00:15:30,620
tagging all the resources that you're

00:15:29,089 --> 00:15:31,610
using inside of an infrastructure and

00:15:30,620 --> 00:15:33,230
that probably sounds like a pretty

00:15:31,610 --> 00:15:35,779
obvious thing to this group but I've

00:15:33,230 --> 00:15:37,040
lost track of the number of customer

00:15:35,779 --> 00:15:39,380
deployments that I've seen of our

00:15:37,040 --> 00:15:41,540
software that had little to no tagging

00:15:39,380 --> 00:15:43,310
policies it's to a point where now best

00:15:41,540 --> 00:15:45,440
practice in the industry is basically to

00:15:43,310 --> 00:15:47,209
terminate an ec2 instance if it doesn't

00:15:45,440 --> 00:15:48,529
adhere to a tagging policy when it's

00:15:47,209 --> 00:15:51,079
launched and to do that as quickly as

00:15:48,529 --> 00:15:52,519
possible so for example one of our

00:15:51,079 --> 00:15:53,899
customers you literally cannot launch

00:15:52,519 --> 00:15:55,700
infrastructure in their environment

00:15:53,899 --> 00:15:58,519
unless it meets the specific tagging

00:15:55,700 --> 00:16:00,589
policy around that ec2 infrastructure if

00:15:58,519 --> 00:16:02,390
you adhere to this this then has a lot

00:16:00,589 --> 00:16:03,890
of side benefits and side effects that

00:16:02,390 --> 00:16:07,430
you can build on as you move through

00:16:03,890 --> 00:16:08,510
this journey of cloud efficiency but it

00:16:07,430 --> 00:16:10,310
really does start with tagging

00:16:08,510 --> 00:16:12,079
unfortunately we can't tag everything in

00:16:10,310 --> 00:16:14,149
AWS today there are just some resource

00:16:12,079 --> 00:16:15,920
types that cannot be tagged but Amazon

00:16:14,149 --> 00:16:18,560
usually fills those gaps pretty quickly

00:16:15,920 --> 00:16:20,570
and I would also argue that this is a

00:16:18,560 --> 00:16:22,279
net new thing in terms of the ability to

00:16:20,570 --> 00:16:24,290
tag resources in a precision that we

00:16:22,279 --> 00:16:25,519
have around resource visibility is not

00:16:24,290 --> 00:16:27,290
something we had back in that data

00:16:25,519 --> 00:16:29,029
center world so it's a bit foreign if

00:16:27,290 --> 00:16:30,230
you're coming from operating a data

00:16:29,029 --> 00:16:31,579
center at scale in terms of how you

00:16:30,230 --> 00:16:33,529
operate your cloud infrastructure this

00:16:31,579 --> 00:16:35,750
notion of adding decorative metadata

00:16:33,529 --> 00:16:37,910
around resources and things that let you

00:16:35,750 --> 00:16:40,160
put resources into meaningful groups is

00:16:37,910 --> 00:16:43,279
a relatively new and learned skill that

00:16:40,160 --> 00:16:44,839
that we've had to adopt once we have

00:16:43,279 --> 00:16:46,820
tagging then we can start to put

00:16:44,839 --> 00:16:48,320
resource consumption into groups along

00:16:46,820 --> 00:16:49,820
with those functional teams so we can

00:16:48,320 --> 00:16:52,100
actually start to get a better sense of

00:16:49,820 --> 00:16:54,019
how an individual team is consuming

00:16:52,100 --> 00:16:56,060
resources on the cloud you can contrast

00:16:54,019 --> 00:16:57,949
this with previously everything was just

00:16:56,060 --> 00:16:59,660
kind of thrown into a production

00:16:57,949 --> 00:17:00,740
environment account or a staging

00:16:59,660 --> 00:17:02,630
environment account or a dev environment

00:17:00,740 --> 00:17:04,640
account but you would have to go track

00:17:02,630 --> 00:17:06,439
down individuals and say are you

00:17:04,640 --> 00:17:07,819
operating this server is so yes okay

00:17:06,439 --> 00:17:09,290
great now I understand that this dollar

00:17:07,819 --> 00:17:11,360
amount goes to this team but where does

00:17:09,290 --> 00:17:13,100
everything else go with proper tagging

00:17:11,360 --> 00:17:15,319
we can actually start to put cost and

00:17:13,100 --> 00:17:17,240
resource consumption utilization into

00:17:15,319 --> 00:17:18,770
buckets that belong to a team and then

00:17:17,240 --> 00:17:20,299
have more meaningful conversations with

00:17:18,770 --> 00:17:22,040
those teams about what they're using

00:17:20,299 --> 00:17:23,650
what they're spending where they think

00:17:22,040 --> 00:17:26,689
they're going with their infrastructure

00:17:23,650 --> 00:17:28,339
one of the nice side effects of this is

00:17:26,689 --> 00:17:30,320
that now that we can quantify how an

00:17:28,339 --> 00:17:32,450
individual team is behaving so for

00:17:30,320 --> 00:17:34,290
example to contrast our pipeline team

00:17:32,450 --> 00:17:36,840
with our analytics engine team

00:17:34,290 --> 00:17:38,520
for our recommendation team when one

00:17:36,840 --> 00:17:39,720
team has a key breakthrough in terms of

00:17:38,520 --> 00:17:41,490
how they're operating infrastructure

00:17:39,720 --> 00:17:43,110
they have a quantifiable thing that they

00:17:41,490 --> 00:17:45,660
can look at and they can say for example

00:17:43,110 --> 00:17:47,010
we started using spa and by using spot

00:17:45,660 --> 00:17:49,800
instances we were able to reduce our

00:17:47,010 --> 00:17:51,060
cost by 75% that is work load that then

00:17:49,800 --> 00:17:53,100
becomes a bit competitive with other

00:17:51,060 --> 00:17:54,540
teams they see that benefit they see

00:17:53,100 --> 00:17:56,550
that measured impact and they step back

00:17:54,540 --> 00:17:58,080
and say okay how could we implement

00:17:56,550 --> 00:18:00,090
something similar on our side and

00:17:58,080 --> 00:18:01,830
overall everybody benefits once you've

00:18:00,090 --> 00:18:05,130
got sort of measured consumption of

00:18:01,830 --> 00:18:08,550
resources in infrastructure so stage 2

00:18:05,130 --> 00:18:09,510
is what we typically call in our little

00:18:08,550 --> 00:18:11,700
corner of the industry financial

00:18:09,510 --> 00:18:13,770
leverage and I won't spend too much time

00:18:11,700 --> 00:18:15,360
digging into this but effectively

00:18:13,770 --> 00:18:17,250
financial leverage in terms of public

00:18:15,360 --> 00:18:18,570
cloud amounts to if you make a

00:18:17,250 --> 00:18:20,370
commitment to spend a certain amount of

00:18:18,570 --> 00:18:22,980
dollars you can get discounted pricing

00:18:20,370 --> 00:18:26,880
and in the Amazon world this is known as

00:18:22,980 --> 00:18:28,320
our eyes or reserved instances that's a

00:18:26,880 --> 00:18:30,630
bit of a misnomer these days the

00:18:28,320 --> 00:18:33,450
industry is quickly converging away from

00:18:30,630 --> 00:18:35,460
the notion of I want to have this kind

00:18:33,450 --> 00:18:37,800
of pricing for a single host and what's

00:18:35,460 --> 00:18:40,290
actually happening now is that people

00:18:37,800 --> 00:18:42,300
are adding up base compute units so you

00:18:40,290 --> 00:18:44,670
could look at this for example and say

00:18:42,300 --> 00:18:46,530
of all the ec2 hosts I'm running I have

00:18:44,670 --> 00:18:48,960
a thousand CPU cores that are part of

00:18:46,530 --> 00:18:51,270
that infrastructure and of that thousand

00:18:48,960 --> 00:18:53,010
CPU cores if I take a probabilistic

00:18:51,270 --> 00:18:55,590
model around how our resource

00:18:53,010 --> 00:18:57,420
consumption is changing over time I can

00:18:55,590 --> 00:19:00,000
actually project that I think I'm going

00:18:57,420 --> 00:19:02,550
to end up keeping say 750 of that

00:19:00,000 --> 00:19:03,870
thousand so I want to cover 750,000 with

00:19:02,550 --> 00:19:06,450
discounted pricing by making a

00:19:03,870 --> 00:19:08,520
commitment in our case we were able to

00:19:06,450 --> 00:19:11,640
leverage our own tool drink our own

00:19:08,520 --> 00:19:13,170
champagne effectively to attain about 90

00:19:11,640 --> 00:19:14,730
percent RI coverage for specific

00:19:13,170 --> 00:19:16,710
workloads and for each of those

00:19:14,730 --> 00:19:18,420
workloads immediately out of the game we

00:19:16,710 --> 00:19:19,860
get a 30% saving was your engineering

00:19:18,420 --> 00:19:21,870
effort we're driving our price down by

00:19:19,860 --> 00:19:22,920
30% just by figuring out what do we

00:19:21,870 --> 00:19:24,810
think we're going to continue to use

00:19:22,920 --> 00:19:26,190
over time but the nice thing is recently

00:19:24,810 --> 00:19:28,140
we've been able to step away from is

00:19:26,190 --> 00:19:29,310
this server going to step around and

00:19:28,140 --> 00:19:31,110
look at in aggregate what are the

00:19:29,310 --> 00:19:32,310
compute units we're using how many of

00:19:31,110 --> 00:19:33,780
those compute units do we think we're

00:19:32,310 --> 00:19:37,050
going to keep overtime and divorce stops

00:19:33,780 --> 00:19:39,140
the idea of specific hosts to other

00:19:37,050 --> 00:19:40,740
things all throughout there real quickly

00:19:39,140 --> 00:19:42,570
sorry what I'm saying I'll throw out

00:19:40,740 --> 00:19:43,980
there real quickly something a lot of

00:19:42,570 --> 00:19:45,840
people overlook in terms of Finance

00:19:43,980 --> 00:19:47,700
leverage is the secondary market it's

00:19:45,840 --> 00:19:49,110
one of my favorite things about me to be

00:19:47,700 --> 00:19:52,260
West this notion that I can go buy a

00:19:49,110 --> 00:19:54,840
reserved instance from AWS without that

00:19:52,260 --> 00:19:57,510
extended duration commitment so to put

00:19:54,840 --> 00:20:00,360
an example on this this morning I ended

00:19:57,510 --> 00:20:01,830
up buying about 30 reserved instances

00:20:00,360 --> 00:20:04,140
with just a 30-day window

00:20:01,830 --> 00:20:05,549
for one of my teams 30 days is pretty

00:20:04,140 --> 00:20:06,929
small and I'm comfortable making that

00:20:05,549 --> 00:20:08,580
commitment it's a lot different than

00:20:06,929 --> 00:20:10,350
making a 12 month commitment for 30

00:20:08,580 --> 00:20:13,169
reserved instances and I was able to

00:20:10,350 --> 00:20:14,700
save them I think was $2,000 without any

00:20:13,169 --> 00:20:16,740
involvement on my time so about five

00:20:14,700 --> 00:20:21,270
minutes of my time saved that particular

00:20:16,740 --> 00:20:23,940
team $2,000 or so so we look at the

00:20:21,270 --> 00:20:25,860
extent of the journey the first two

00:20:23,940 --> 00:20:27,330
stages there's a deliberate dividing

00:20:25,860 --> 00:20:29,070
line between the first two stages and

00:20:27,330 --> 00:20:30,600
the reason for that is we can attain the

00:20:29,070 --> 00:20:32,640
first two stages in terms of visibility

00:20:30,600 --> 00:20:34,470
and financial leverage without really

00:20:32,640 --> 00:20:35,970
involving the engineering teams we don't

00:20:34,470 --> 00:20:37,860
need an engineering team to come in and

00:20:35,970 --> 00:20:39,780
write code we don't need to change our

00:20:37,860 --> 00:20:41,370
operational policies per se tagging is

00:20:39,780 --> 00:20:43,110
quite straightforward once you get it

00:20:41,370 --> 00:20:46,260
based into like a chef infrastructure or

00:20:43,110 --> 00:20:48,120
into some basic AWS configurations but

00:20:46,260 --> 00:20:49,740
to really continue to do cloud well

00:20:48,120 --> 00:20:51,840
effectively to obtain more cloud

00:20:49,740 --> 00:20:53,250
efficiency now we have to start looking

00:20:51,840 --> 00:20:54,960
at changing the ways that we actually

00:20:53,250 --> 00:20:56,250
operate the infrastructure and getting

00:20:54,960 --> 00:20:57,809
the engineering team involved and that's

00:20:56,250 --> 00:21:01,080
about stage 3 and stage 4 are going to

00:20:57,809 --> 00:21:02,880
be about so as we dig into stage 3 how

00:21:01,080 --> 00:21:04,620
we changed our operational practices

00:21:02,880 --> 00:21:06,210
we're going to look at a handful of

00:21:04,620 --> 00:21:08,429
specific initiatives that we kicked off

00:21:06,210 --> 00:21:09,960
that allowed us to continue to extract

00:21:08,429 --> 00:21:15,030
more value out of clouds continue to

00:21:09,960 --> 00:21:17,730
have more efficiency excuse me so

00:21:15,030 --> 00:21:19,770
initiative number one we effectively

00:21:17,730 --> 00:21:21,330
when we kicked off this broader effort

00:21:19,770 --> 00:21:23,549
we step back and we looked at different

00:21:21,330 --> 00:21:25,080
workloads across our environment and

00:21:23,549 --> 00:21:26,760
decided where we wanted to target some

00:21:25,080 --> 00:21:28,590
specific places that we weren't happy

00:21:26,760 --> 00:21:30,390
with whether that was how much those

00:21:28,590 --> 00:21:32,309
areas are costing us keep in mind now we

00:21:30,390 --> 00:21:33,780
have good visibility into which pieces

00:21:32,309 --> 00:21:35,850
of the architecture are costing us money

00:21:33,780 --> 00:21:38,309
and we can put pointed efforts behind

00:21:35,850 --> 00:21:40,410
reducing spend in certain areas or if we

00:21:38,309 --> 00:21:42,150
had certain areas where we weren't happy

00:21:40,410 --> 00:21:43,500
with the architecture we could step back

00:21:42,150 --> 00:21:45,660
and say how do we make this more cloud

00:21:43,500 --> 00:21:46,950
native how do we use best practices of

00:21:45,660 --> 00:21:48,330
cloud as opposed to what we've been

00:21:46,950 --> 00:21:50,429
doing for the last four or five years

00:21:48,330 --> 00:21:52,409
and so the first one of those was

00:21:50,429 --> 00:21:54,809
effectively re architecting our data

00:21:52,409 --> 00:21:56,380
pipeline so two years ago we had

00:21:54,809 --> 00:22:00,430
something that looked similar

00:21:56,380 --> 00:22:02,080
to this we had a data ingestion set of

00:22:00,430 --> 00:22:03,760
servers that would run some jobs on a

00:22:02,080 --> 00:22:05,620
periodic basis they would integrate with

00:22:03,760 --> 00:22:07,150
AWS they would pull down cloud watch

00:22:05,620 --> 00:22:08,290
metrics they would pull those in they

00:22:07,150 --> 00:22:10,870
would write them to a react times

00:22:08,290 --> 00:22:13,300
basically a time series schema on top of

00:22:10,870 --> 00:22:15,850
a react cluster at its peak that was

00:22:13,300 --> 00:22:17,470
upwards of 30 different node 30 nodes

00:22:15,850 --> 00:22:19,000
running some pretty significant

00:22:17,470 --> 00:22:20,770
infrastructure at the end of the at the

00:22:19,000 --> 00:22:22,390
end of its life is running on larger i2

00:22:20,770 --> 00:22:24,850
infrastructure

00:22:22,390 --> 00:22:27,010
once the time series dated and written

00:22:24,850 --> 00:22:28,480
to react we put a message into rescue we

00:22:27,010 --> 00:22:29,680
didn't have a different set of hosts

00:22:28,480 --> 00:22:31,960
that would pick up that message out of

00:22:29,680 --> 00:22:33,760
rescue then go read the data back out of

00:22:31,960 --> 00:22:35,190
react start to process it and ultimately

00:22:33,760 --> 00:22:37,000
write it into a my sequel data store

00:22:35,190 --> 00:22:39,220
there are a number of problems with this

00:22:37,000 --> 00:22:41,320
architecture for us first one being that

00:22:39,220 --> 00:22:42,310
a lot of the data ingestion side of

00:22:41,320 --> 00:22:44,080
things and a lot of the rescued

00:22:42,310 --> 00:22:45,880
consumers were frequently idle they

00:22:44,080 --> 00:22:47,920
would be they would wake up they would

00:22:45,880 --> 00:22:49,390
do some work for maybe 15 minutes and

00:22:47,920 --> 00:22:52,180
then they would basically go back to

00:22:49,390 --> 00:22:53,770
sleep and nothing would happen for 75%

00:22:52,180 --> 00:22:55,300
of the time on these hosts so we had

00:22:53,770 --> 00:22:56,920
sort of burst scale that we had to deal

00:22:55,300 --> 00:22:58,750
with but the way that we were operating

00:22:56,920 --> 00:23:00,160
at the time we weren't scaling up or

00:22:58,750 --> 00:23:01,930
down we just had a fleet of machines

00:23:00,160 --> 00:23:03,730
that would wake up grab some data into a

00:23:01,930 --> 00:23:07,120
database and then go back to sleep

00:23:03,730 --> 00:23:09,610
and so what we ended up changing that

00:23:07,120 --> 00:23:12,280
architecture to was to be significantly

00:23:09,610 --> 00:23:14,050
more cloud native so now the way this

00:23:12,280 --> 00:23:15,970
looks today is we have lambda functions

00:23:14,050 --> 00:23:17,860
that run on a cron schedule so there's

00:23:15,970 --> 00:23:19,600
no sort of self scheduling that's done

00:23:17,860 --> 00:23:21,100
as an independent function those lambda

00:23:19,600 --> 00:23:22,390
functions have a tiny bit of state that

00:23:21,100 --> 00:23:24,880
they need to maintain which they write

00:23:22,390 --> 00:23:27,370
at dynamodb just so we know when certain

00:23:24,880 --> 00:23:30,610
fetches are happening etc they now write

00:23:27,370 --> 00:23:32,560
messages into SNS topics or SNS queues

00:23:30,610 --> 00:23:34,930
as opposed to rescue which is sort of

00:23:32,560 --> 00:23:36,910
another facility that AWS provides for

00:23:34,930 --> 00:23:38,350
us and then the consumers of that are

00:23:36,910 --> 00:23:40,300
effectively operated on top of

00:23:38,350 --> 00:23:43,480
auto-scaling groups those auto-scaling

00:23:40,300 --> 00:23:45,790
groups are backed by spot instances as

00:23:43,480 --> 00:23:47,170
opposed to long-running durable ec2

00:23:45,790 --> 00:23:48,190
hosts that we have the reason about are

00:23:47,170 --> 00:23:50,800
we're going to keep them around forever

00:23:48,190 --> 00:23:52,360
in this case this workload spins up in

00:23:50,800 --> 00:23:54,730
result to a mess or in response to a

00:23:52,360 --> 00:23:56,560
message being in EQ processes and data

00:23:54,730 --> 00:23:58,720
and then effectively those hosts go away

00:23:56,560 --> 00:24:01,300
because we're doing this on spot we save

00:23:58,720 --> 00:24:03,670
we end up spending about 25% compared to

00:24:01,300 --> 00:24:06,040
what the on-demand rate is for a similar

00:24:03,670 --> 00:24:07,450
workload likewise we got rid of the time

00:24:06,040 --> 00:24:08,080
series database altogether

00:24:07,450 --> 00:24:09,460
so the

00:24:08,080 --> 00:24:11,559
consumers that are reading from cloud

00:24:09,460 --> 00:24:14,470
water effectively buffering data they'll

00:24:11,559 --> 00:24:16,419
then write that into s3 files one of the

00:24:14,470 --> 00:24:18,640
nice facilities of s3 is that when you

00:24:16,419 --> 00:24:21,610
finish writing a file you can have AWS

00:24:18,640 --> 00:24:23,230
subsequently emit an SNS notification so

00:24:21,610 --> 00:24:25,059
different message goes out into a

00:24:23,230 --> 00:24:26,710
different SMS queue and then we have a

00:24:25,059 --> 00:24:29,110
second set of consumers that are running

00:24:26,710 --> 00:24:30,669
on ECS in the form of docker containers

00:24:29,110 --> 00:24:32,529
they will read that message out of queue

00:24:30,669 --> 00:24:35,019
process the file write a different file

00:24:32,529 --> 00:24:36,640
to an s3 bucket this case it ends up

00:24:35,019 --> 00:24:38,740
being a park a file format which we then

00:24:36,640 --> 00:24:40,389
push further downstream so a couple of

00:24:38,740 --> 00:24:42,399
benefits of this one it scales

00:24:40,389 --> 00:24:44,799
elastically so as there's more work load

00:24:42,399 --> 00:24:46,299
things scale up they do the work and

00:24:44,799 --> 00:24:49,269
then the host literally go it they're

00:24:46,299 --> 00:24:50,830
not left standing around - we eliminate

00:24:49,269 --> 00:24:52,450
an entire database so we were able to

00:24:50,830 --> 00:24:55,750
get rid of about 30 different nodes in

00:24:52,450 --> 00:24:57,279
our infrastructure which ended up

00:24:55,750 --> 00:24:59,200
netting out looking similar to this so

00:24:57,279 --> 00:25:00,250
we were able to remove a significant

00:24:59,200 --> 00:25:04,149
chunk of our infrastructure that

00:25:00,250 --> 00:25:07,389
basically was a large not invented here

00:25:04,149 --> 00:25:08,590
syndrome relic that being our react

00:25:07,389 --> 00:25:09,730
cluster was something weren't good at

00:25:08,590 --> 00:25:11,679
operating and something we didn't really

00:25:09,730 --> 00:25:12,789
know very well and we just picked off

00:25:11,679 --> 00:25:13,990
the shelf because we felt a little bit

00:25:12,789 --> 00:25:16,149
comfortable with it but it wasn't really

00:25:13,990 --> 00:25:17,710
our core competency our monthly spend

00:25:16,149 --> 00:25:19,090
were able to recover over ten thousand

00:25:17,710 --> 00:25:22,419
euro just by making this single

00:25:19,090 --> 00:25:23,889
architectural change and then there's a

00:25:22,419 --> 00:25:25,600
significant reduction in operational

00:25:23,889 --> 00:25:27,399
complexity so we're no longer operating

00:25:25,600 --> 00:25:28,870
a database we're no longer operating 30

00:25:27,399 --> 00:25:31,029
different nodes to implement this react

00:25:28,870 --> 00:25:33,760
cluster we fell back to sort of first

00:25:31,029 --> 00:25:35,440
principles of moving around files simple

00:25:33,760 --> 00:25:36,850
events processing those files

00:25:35,440 --> 00:25:38,620
elastically and throwing away of

00:25:36,850 --> 00:25:40,870
instruction when we were done with it

00:25:38,620 --> 00:25:42,519
you can see that's a little bit hard to

00:25:40,870 --> 00:25:44,139
read but this is kind of a monthly spend

00:25:42,519 --> 00:25:45,190
for this particular team again remember

00:25:44,139 --> 00:25:47,380
we have visibility into what these

00:25:45,190 --> 00:25:49,419
individual teams are doing because we've

00:25:47,380 --> 00:25:51,039
taken the time to tag things and the

00:25:49,419 --> 00:25:53,200
monthly spent for this individual team

00:25:51,039 --> 00:25:55,510
was on a significant downward trajectory

00:25:53,200 --> 00:25:57,610
the slight uptick at the end of it was

00:25:55,510 --> 00:25:59,230
when we adjusted data for one of AWS is

00:25:57,610 --> 00:26:01,179
largest customers we brought them on

00:25:59,230 --> 00:26:03,490
board and so there's a slight uptick but

00:26:01,179 --> 00:26:05,710
we were able to scale that dynamically

00:26:03,490 --> 00:26:07,799
without changing any infrastructure our

00:26:05,710 --> 00:26:10,570
react lustre was no longer on fire and

00:26:07,799 --> 00:26:12,639
we were able to take that into stride as

00:26:10,570 --> 00:26:13,929
some perspective this particular

00:26:12,639 --> 00:26:16,600
infrastructure right now for us on

00:26:13,929 --> 00:26:18,460
average process is about 115,000 pieces

00:26:16,600 --> 00:26:20,529
of data per second although that's a

00:26:18,460 --> 00:26:21,350
very first you workload it's not

00:26:20,529 --> 00:26:22,789
constantly

00:26:21,350 --> 00:26:23,929
being at that so it's more like there'll

00:26:22,789 --> 00:26:25,400
be a million pieces of data the

00:26:23,929 --> 00:26:26,840
commander it'll process that throwaways

00:26:25,400 --> 00:26:28,130
from the construction of 20 million

00:26:26,840 --> 00:26:29,539
pieces of data that will come in or

00:26:28,130 --> 00:26:30,549
process it will throw a single

00:26:29,539 --> 00:26:32,980
construction

00:26:30,549 --> 00:26:34,880
how does fits into the overall

00:26:32,980 --> 00:26:37,940
perspective for this individual team

00:26:34,880 --> 00:26:39,410
this is a breakdown of many people think

00:26:37,940 --> 00:26:41,360
that when you run in ec2 instances a

00:26:39,410 --> 00:26:43,039
single line item of cost that it's one

00:26:41,360 --> 00:26:44,450
particular piece of data that's not

00:26:43,039 --> 00:26:46,309
actually the case there's a lot of

00:26:44,450 --> 00:26:48,020
nuance that goes into what it means to

00:26:46,309 --> 00:26:50,090
operate in piece of ec2 infrastructure

00:26:48,020 --> 00:26:53,900
and in this particular case that the

00:26:50,090 --> 00:26:56,000
purple zoom in is us no longer operating

00:26:53,900 --> 00:26:57,830
significant EBS volumes that were

00:26:56,000 --> 00:27:01,159
previously attached to that react

00:26:57,830 --> 00:27:03,289
cluster so as some context there we had

00:27:01,159 --> 00:27:04,340
effectively had to use large EBS volumes

00:27:03,289 --> 00:27:05,780
though to get the throughput that we

00:27:04,340 --> 00:27:08,090
needed out of that react cluster and

00:27:05,780 --> 00:27:09,679
that was a significant portion of our c2

00:27:08,090 --> 00:27:11,630
span that we were able to just basically

00:27:09,679 --> 00:27:13,429
take off the table by simply using s3

00:27:11,630 --> 00:27:17,270
when we didn't need more complicated

00:27:13,429 --> 00:27:18,440
data store so the the second sort of use

00:27:17,270 --> 00:27:21,250
case in terms of our operational

00:27:18,440 --> 00:27:24,770
efficiency here was a migration of a

00:27:21,250 --> 00:27:31,100
seven terabyte seven node my sequel data

00:27:24,770 --> 00:27:33,230
warehouse cluster this was effectively

00:27:31,100 --> 00:27:36,559
mandated by the fact that we were

00:27:33,230 --> 00:27:38,240
running RDS for my sequel and RDS my

00:27:36,559 --> 00:27:39,559
sequel RDS has a hard limit of about

00:27:38,240 --> 00:27:40,970
seven terabytes so we were basically

00:27:39,559 --> 00:27:42,980
running out of the ability to add more

00:27:40,970 --> 00:27:44,840
data to this particular database and the

00:27:42,980 --> 00:27:47,360
natural migration for this in our case

00:27:44,840 --> 00:27:50,690
was to move to Amazon Aurora this is a

00:27:47,360 --> 00:27:52,700
good example in our environment of using

00:27:50,690 --> 00:27:53,720
platform native technologies as opposed

00:27:52,700 --> 00:27:55,669
to trying to operate something

00:27:53,720 --> 00:27:58,659
themselves and so the high level

00:27:55,669 --> 00:28:01,100
takeaway of what we gain by this was our

00:27:58,659 --> 00:28:03,799
90th percentile latency for select

00:28:01,100 --> 00:28:05,510
queries on RDS my sequel was around 360

00:28:03,799 --> 00:28:07,429
seconds keep in mind these numbers are

00:28:05,510 --> 00:28:09,500
not stunning in terms of the 90th

00:28:07,429 --> 00:28:10,880
percentile latency but this was a data

00:28:09,500 --> 00:28:12,740
warehouse right so these were all flying

00:28:10,880 --> 00:28:14,659
batch jobs were effectively being run to

00:28:12,740 --> 00:28:15,950
be normalized data that would then be

00:28:14,659 --> 00:28:18,440
written out to a more efficient store to

00:28:15,950 --> 00:28:21,289
hand off to customers by virtue of

00:28:18,440 --> 00:28:22,820
moving just to Aurora so this was almost

00:28:21,289 --> 00:28:24,230
no code change I'll say like maybe a

00:28:22,820 --> 00:28:26,210
couple lines of code and maybe some

00:28:24,230 --> 00:28:27,559
configuration changes by virtually

00:28:26,210 --> 00:28:29,419
moving to Aurora we were able to get

00:28:27,559 --> 00:28:30,020
United 4 sent I'll select latency down

00:28:29,419 --> 00:28:32,810
to 100

00:28:30,020 --> 00:28:34,970
any seconds there's an ocean in terms of

00:28:32,810 --> 00:28:37,580
RDS my sequel of provision i--once or TI

00:28:34,970 --> 00:28:40,550
offs we're able to go from having to pay

00:28:37,580 --> 00:28:42,620
AWS for 30,000 TI offs to zero because

00:28:40,550 --> 00:28:44,330
we're doesn't have an ocean of PIOs

00:28:42,620 --> 00:28:47,540
and we didn't need that for a capacity

00:28:44,330 --> 00:28:49,730
with aurora fun fact the side note AWS

00:28:47,540 --> 00:28:51,950
will allow you to purchase 30,000 PIOs

00:28:49,730 --> 00:28:54,020
for RDS y sequel and in reality my

00:28:51,950 --> 00:28:55,820
sequel engine can only use 23,000 of

00:28:54,020 --> 00:28:57,260
those so you can basically buy more than

00:28:55,820 --> 00:29:00,440
you even theoretically use with my

00:28:57,260 --> 00:29:03,160
sequel engine on RDS and then an

00:29:00,440 --> 00:29:05,390
unintended side effect that was the

00:29:03,160 --> 00:29:07,130
results of doing his work was that our

00:29:05,390 --> 00:29:09,800
provision time for an individual replica

00:29:07,130 --> 00:29:12,500
went from 30 hours on RDS twice equal to

00:29:09,800 --> 00:29:13,340
seven minutes with aurora this is if

00:29:12,500 --> 00:29:15,590
you're not familiar with Aurora

00:29:13,340 --> 00:29:17,540
effectively the secret sauce behind it

00:29:15,590 --> 00:29:19,250
is a distributed file system that is

00:29:17,540 --> 00:29:21,890
eventually consistent based on a log

00:29:19,250 --> 00:29:23,840
structure merge approach and the aurora

00:29:21,890 --> 00:29:25,490
engines themselves are just cpu and

00:29:23,840 --> 00:29:27,260
memory on top of that distributed file

00:29:25,490 --> 00:29:29,480
system so spinning up a new replica is

00:29:27,260 --> 00:29:31,400
really just copying around cache for the

00:29:29,480 --> 00:29:33,350
new nodes in terms of the read replicas

00:29:31,400 --> 00:29:35,210
what this meant for us is that we could

00:29:33,350 --> 00:29:36,770
actually take this data warehouse and be

00:29:35,210 --> 00:29:38,090
elastic with it which is something we

00:29:36,770 --> 00:29:39,290
didn't anticipate out of the gate but it

00:29:38,090 --> 00:29:40,610
was a really cool side effect of

00:29:39,290 --> 00:29:43,400
adopting this platform native technology

00:29:40,610 --> 00:29:45,640
so an example that would be if we had a

00:29:43,400 --> 00:29:48,650
large batch job that had to hammer the

00:29:45,640 --> 00:29:50,900
data warehouse that normally would have

00:29:48,650 --> 00:29:52,670
taken seven hours on my sequel RDS we

00:29:50,900 --> 00:29:54,230
could spin up an Aurora node we could

00:29:52,670 --> 00:29:56,060
run through the large batch job that

00:29:54,230 --> 00:29:57,350
would take about 20-30 minutes and then

00:29:56,060 --> 00:29:59,360
we could throw that node away for four

00:29:57,350 --> 00:30:02,780
or five hours because we could stand up

00:29:59,360 --> 00:30:05,260
a replicas so quick our DML or our data

00:30:02,780 --> 00:30:08,020
manipulation replication time went from

00:30:05,260 --> 00:30:10,850
the worst case there's our 99th

00:30:08,020 --> 00:30:13,220
percentile replication lag went from

00:30:10,850 --> 00:30:14,720
seven minutes to 20 milliseconds or or

00:30:13,220 --> 00:30:16,760
is very efficient in terms of right

00:30:14,720 --> 00:30:18,470
replication and our failure mode

00:30:16,760 --> 00:30:21,050
operations got significantly better

00:30:18,470 --> 00:30:23,750
so Aurora does a lot of management of

00:30:21,050 --> 00:30:25,670
partition detection of election of

00:30:23,750 --> 00:30:28,220
master replicas failover things like

00:30:25,670 --> 00:30:31,250
that that we had to do manually in a

00:30:28,220 --> 00:30:32,450
RDS my sequel universe and if you zoom

00:30:31,250 --> 00:30:33,860
out a little bit you look at what does

00:30:32,450 --> 00:30:36,590
it actually cost us at the end of the

00:30:33,860 --> 00:30:38,660
day we ended up spending about 75 or

00:30:36,590 --> 00:30:40,670
about 25 percent less to operate the

00:30:38,660 --> 00:30:41,299
Aurora cluster in terms of dollar for

00:30:40,670 --> 00:30:45,409
dollar compared

00:30:41,299 --> 00:30:47,690
as compared to RDS my sequel the next

00:30:45,409 --> 00:30:49,970
use case here is a migration of our

00:30:47,690 --> 00:30:52,399
HBase cluster from I to to i3 instance

00:30:49,970 --> 00:30:55,009
families and I called this this

00:30:52,399 --> 00:30:56,690
particular story for us platform

00:30:55,009 --> 00:31:00,710
adaptation and really what I mean by

00:30:56,690 --> 00:31:02,659
that is because we're paying attention

00:31:00,710 --> 00:31:04,070
to the changes that Amazon is making to

00:31:02,659 --> 00:31:05,059
their infrastructure we're looking at

00:31:04,070 --> 00:31:07,190
the innovation they're doing and we're

00:31:05,059 --> 00:31:09,559
taking advantage of that in a dynamic

00:31:07,190 --> 00:31:12,080
adaptive way we're able to migrate a

00:31:09,559 --> 00:31:14,690
specific workload from I - family - I

00:31:12,080 --> 00:31:16,309
three family one of the reasons that was

00:31:14,690 --> 00:31:18,529
compelling so it's a bit hard to see but

00:31:16,309 --> 00:31:21,049
this is effectively a bonny output for

00:31:18,529 --> 00:31:22,609
the local SSDs on the ITU's in the i3 s

00:31:21,049 --> 00:31:26,570
and there's two things that I'll call

00:31:22,609 --> 00:31:28,399
out the first is that the random

00:31:26,570 --> 00:31:30,970
sequence II improved by an order of

00:31:28,399 --> 00:31:33,710
magnitude between I - and the i3 family

00:31:30,970 --> 00:31:36,470
likewise then the the raw numbers

00:31:33,710 --> 00:31:38,450
improved from especially in the read

00:31:36,470 --> 00:31:41,119
side we got more than a 3x improvement

00:31:38,450 --> 00:31:43,279
from 580 megabits per second to 128

00:31:41,119 --> 00:31:45,649
megabits per second this is simply by

00:31:43,279 --> 00:31:49,359
migrating a workload or right sizing a

00:31:45,649 --> 00:31:52,190
workload from an i - to an i3 family and

00:31:49,359 --> 00:31:55,399
at a higher level the hardware is fairly

00:31:52,190 --> 00:31:57,470
equivalent so same number of V CPUs same

00:31:55,399 --> 00:31:59,090
amount of RAM the local stores you

00:31:57,470 --> 00:32:01,340
actually get more storage but more

00:31:59,090 --> 00:32:03,980
importantly the network interconnect on

00:32:01,340 --> 00:32:05,929
the i3 family actually give us a 40

00:32:03,980 --> 00:32:08,059
gigabit per second interconnect by

00:32:05,929 --> 00:32:10,039
moving from i2 to i3 what then then for

00:32:08,059 --> 00:32:12,049
us is that we can move away from a thing

00:32:10,039 --> 00:32:13,759
called placement groups in terms of ec2

00:32:12,049 --> 00:32:15,529
which meant that everything was

00:32:13,759 --> 00:32:17,330
operating in a single AC and we can move

00:32:15,529 --> 00:32:18,889
to having a multiple AV deployment

00:32:17,330 --> 00:32:20,359
because now the 40 gigabit interconnect

00:32:18,889 --> 00:32:24,019
removed network bandwidth as a

00:32:20,359 --> 00:32:25,129
constraint for us and then really the so

00:32:24,019 --> 00:32:26,720
there's a couple other good side effects

00:32:25,129 --> 00:32:29,509
here I'll skip over the rest of them but

00:32:26,720 --> 00:32:31,249
one of the cooler things is that we were

00:32:29,509 --> 00:32:33,889
able to do this but also reduce cost at

00:32:31,249 --> 00:32:35,509
the same time so however they managed to

00:32:33,889 --> 00:32:37,369
do it Amazon has been able to engineer

00:32:35,509 --> 00:32:39,999
differences between the i2 and the i3

00:32:37,369 --> 00:32:45,080
Hardware family and reducing price by

00:32:39,999 --> 00:32:46,009
over $4 per hour I'll go through this

00:32:45,080 --> 00:32:48,230
pretty quickly because we're running

00:32:46,009 --> 00:32:51,680
short on time but we also undertook a

00:32:48,230 --> 00:32:53,150
significant containerization effort and

00:32:51,680 --> 00:32:54,980
effectively everything that's playing

00:32:53,150 --> 00:32:57,020
the containerization side a couple of

00:32:54,980 --> 00:32:58,280
highlights for us really the reason we

00:32:57,020 --> 00:32:59,630
set out with this particular container

00:32:58,280 --> 00:33:02,090
is a shoe initiative is because we have

00:32:59,630 --> 00:33:03,350
poor utilization on a lot of our PC to

00:33:02,090 --> 00:33:05,840
hosts so if you go back to that notion

00:33:03,350 --> 00:33:07,310
of we had one workload per VM that would

00:33:05,840 --> 00:33:09,650
wake up do a little bit and then go back

00:33:07,310 --> 00:33:11,330
to sleep that was largely idle for 75%

00:33:09,650 --> 00:33:13,100
of the time by virtue of adopting

00:33:11,330 --> 00:33:15,230
containers were able to move to a bin

00:33:13,100 --> 00:33:17,450
packing strategy where we would layer

00:33:15,230 --> 00:33:19,760
workloads on top of each other get

00:33:17,450 --> 00:33:22,130
effectively upwards of 75% utilization

00:33:19,760 --> 00:33:23,650
of those CPUs for example on the ec2

00:33:22,130 --> 00:33:26,240
hosts that we're offering the containers

00:33:23,650 --> 00:33:30,050
which on the whole gave us a utilization

00:33:26,240 --> 00:33:31,100
improvement of over 50% efficiency for

00:33:30,050 --> 00:33:33,110
the hosts that were backing those

00:33:31,100 --> 00:33:34,910
containers and by virtue of turning off

00:33:33,110 --> 00:33:37,160
the things that we're periodically doing

00:33:34,910 --> 00:33:38,840
work but not up the full time that we're

00:33:37,160 --> 00:33:41,690
not fully utilized right we were

00:33:38,840 --> 00:33:43,190
actually able to save 60% in terms of

00:33:41,690 --> 00:33:45,830
the ec2 infrastructure for this

00:33:43,190 --> 00:33:47,180
particular workload this also got us

00:33:45,830 --> 00:33:48,440
some cool side effects in terms of being

00:33:47,180 --> 00:33:50,060
able to do things like blue green

00:33:48,440 --> 00:33:51,350
deploys through our Jenkins deployment

00:33:50,060 --> 00:33:53,000
right now for a new deployment

00:33:51,350 --> 00:33:54,890
well ship a new container out we'll

00:33:53,000 --> 00:33:56,690
switch back and forth between blue green

00:33:54,890 --> 00:33:58,760
deploys and our jenkins infrastructure

00:33:56,690 --> 00:34:00,170
is actually capable of changing an al

00:33:58,760 --> 00:34:01,580
beer and application load balancer from

00:34:00,170 --> 00:34:02,720
the blue deployment to the green

00:34:01,580 --> 00:34:04,160
deployment we can do things like

00:34:02,720 --> 00:34:06,080
automated smoke tests between them we

00:34:04,160 --> 00:34:07,400
have a very clear rollback path again

00:34:06,080 --> 00:34:10,100
all leveraging platform native

00:34:07,400 --> 00:34:14,030
capabilities we made significant use of

00:34:10,100 --> 00:34:15,410
ec2 spot so that was for some specific

00:34:14,030 --> 00:34:17,690
workloads so things like time

00:34:15,410 --> 00:34:20,480
insensitive Map Reduce drops or EMR jobs

00:34:17,690 --> 00:34:23,060
I say time insensitive EMR drops because

00:34:20,480 --> 00:34:24,320
if you're going to run an EMR job on

00:34:23,060 --> 00:34:26,210
spot you have to be prepared that it's

00:34:24,320 --> 00:34:29,390
going to go away that's kind of the

00:34:26,210 --> 00:34:31,160
caveat of spot and if you don't engineer

00:34:29,390 --> 00:34:32,720
accordingly or schedule your workloads

00:34:31,160 --> 00:34:34,850
accordingly then you'll get bitten by

00:34:32,720 --> 00:34:36,800
spots but has a ton of cost-saving

00:34:34,850 --> 00:34:38,930
potential but at the end of the day if

00:34:36,800 --> 00:34:40,340
you don't take certain concessions into

00:34:38,930 --> 00:34:41,480
account it's ultimately not going to be

00:34:40,340 --> 00:34:42,740
more efficient for you you're not going

00:34:41,480 --> 00:34:45,350
to get things done on it that you need

00:34:42,740 --> 00:34:47,480
to get done the net takeaway for us is

00:34:45,350 --> 00:34:49,820
that by moving certain workloads to spot

00:34:47,480 --> 00:34:51,710
we have able to save over 40,000 euro

00:34:49,820 --> 00:34:53,870
per month in terms of what we would be

00:34:51,710 --> 00:34:55,550
spending it on demand but again this

00:34:53,870 --> 00:34:57,470
requires engineering effort this isn't

00:34:55,550 --> 00:34:59,570
something we just get for free by

00:34:57,470 --> 00:35:01,010
flipping a switch and saying yes you

00:34:59,570 --> 00:35:02,450
spot in this case spots a lot more

00:35:01,010 --> 00:35:03,609
complex than that

00:35:02,450 --> 00:35:06,339
there's

00:35:03,609 --> 00:35:07,539
many many nuances to doing spot well and

00:35:06,339 --> 00:35:10,839
I won't have time to go through all of

00:35:07,539 --> 00:35:13,210
them here but effectively we ended up

00:35:10,839 --> 00:35:15,009
taking a machine learning approach to

00:35:13,210 --> 00:35:17,349
how we create predictive models around

00:35:15,009 --> 00:35:18,759
spot and then trying to figure out when

00:35:17,349 --> 00:35:20,710
does it make sense to use spot given

00:35:18,759 --> 00:35:22,029
those machine learning models and where

00:35:20,710 --> 00:35:23,019
we think the spot market is going what

00:35:22,029 --> 00:35:24,549
we think the probability of the

00:35:23,019 --> 00:35:26,890
likelihood of termination of a spot

00:35:24,549 --> 00:35:28,059
instances and this is something that we

00:35:26,890 --> 00:35:29,529
effectively had to build in-house

00:35:28,059 --> 00:35:31,359
because we weren't happy with the AWS

00:35:29,529 --> 00:35:33,279
tools we didn't get everything we needed

00:35:31,359 --> 00:35:35,619
out of spot lock and spot sweep for

00:35:33,279 --> 00:35:38,289
example and then one thing a quickly

00:35:35,619 --> 00:35:40,630
point out most people overlook the

00:35:38,289 --> 00:35:42,759
fundamental basics of spot in the sense

00:35:40,630 --> 00:35:44,109
that there's a specific case where you

00:35:42,759 --> 00:35:46,269
shouldn't use spot which is if you have

00:35:44,109 --> 00:35:48,099
unused our eyes so if you pay for a

00:35:46,269 --> 00:35:49,779
reserved instance and you can create a

00:35:48,099 --> 00:35:51,130
probabilistic model around the fact that

00:35:49,779 --> 00:35:53,230
you're not going to use that reserved

00:35:51,130 --> 00:35:55,089
instance then spending money on spot is

00:35:53,230 --> 00:35:56,349
actually going to cost you more in the

00:35:55,089 --> 00:35:58,720
long run because you should have used

00:35:56,349 --> 00:36:00,849
the unused reserved instance meaning an

00:35:58,720 --> 00:36:02,470
RI is it's not cost are going to pay for

00:36:00,849 --> 00:36:04,420
it you should use that before you should

00:36:02,470 --> 00:36:05,739
use spot but modeling that is a

00:36:04,420 --> 00:36:08,019
complicated thing it's not always

00:36:05,739 --> 00:36:09,460
trivial to figure out should I use and

00:36:08,019 --> 00:36:13,960
you see to instance to take advantage of

00:36:09,460 --> 00:36:15,759
an unused RI or not and then lastly

00:36:13,960 --> 00:36:17,230
there's an important notion when you

00:36:15,759 --> 00:36:18,489
operate a SAS company so I live it to

00:36:17,230 --> 00:36:21,489
this at the beginning of the talk of

00:36:18,489 --> 00:36:23,440
what we call gross margin so as we sell

00:36:21,489 --> 00:36:26,380
more dollars of software to our

00:36:23,440 --> 00:36:28,960
customers there's a nonzero costs to

00:36:26,380 --> 00:36:31,359
operating our infrastructure and the

00:36:28,960 --> 00:36:33,519
Delta between that cost or cogs cost of

00:36:31,359 --> 00:36:35,499
goods sold and top-line revenue is what

00:36:33,519 --> 00:36:37,539
we call gross margin so if we build up

00:36:35,499 --> 00:36:39,519
everything we've talked to so far in

00:36:37,539 --> 00:36:41,950
terms of visibility into the spend in

00:36:39,519 --> 00:36:43,900
terms of financial leverage in terms of

00:36:41,950 --> 00:36:45,880
optimizing our infrastructure that has

00:36:43,900 --> 00:36:47,799
some really cool side effects for us we

00:36:45,880 --> 00:36:49,239
can now start to do things like look at

00:36:47,799 --> 00:36:51,009
what it cost us to ship an individual

00:36:49,239 --> 00:36:52,989
feature look at what it cost us to

00:36:51,009 --> 00:36:54,160
operate a specific customer or operate

00:36:52,989 --> 00:36:55,809
our infrastructure for a specific

00:36:54,160 --> 00:36:57,430
customer and this is what I mean when I

00:36:55,809 --> 00:36:59,200
say we have visibility into unit

00:36:57,430 --> 00:37:00,430
economics meaning I can go to our

00:36:59,200 --> 00:37:01,839
product team and say this is what it

00:37:00,430 --> 00:37:03,190
costs to operate our infrastructure for

00:37:01,839 --> 00:37:04,660
this customer so what should we be

00:37:03,190 --> 00:37:06,069
charging that customer what's the margin

00:37:04,660 --> 00:37:08,380
that we want to make on this particular

00:37:06,069 --> 00:37:10,329
feature set this lets us make better

00:37:08,380 --> 00:37:12,249
engineering decisions because we can

00:37:10,329 --> 00:37:14,079
focus on core competencies and value add

00:37:12,249 --> 00:37:15,809
as opposed to operating infrastructure

00:37:14,079 --> 00:37:17,290
we can figure out where we should focus

00:37:15,809 --> 00:37:18,910
optimization efforts with

00:37:17,290 --> 00:37:20,230
in our infrastructure we wouldn't be

00:37:18,910 --> 00:37:21,430
able to do this if we weren't

00:37:20,230 --> 00:37:22,720
experienced in doing it already

00:37:21,430 --> 00:37:24,340
and if we didn't have good visualization

00:37:22,720 --> 00:37:25,960
and good financial leverage and how we

00:37:24,340 --> 00:37:27,910
operate our infrastructure this is

00:37:25,960 --> 00:37:31,570
really sort of the culmination of all

00:37:27,910 --> 00:37:33,940
the three previous steps there's a thing

00:37:31,570 --> 00:37:35,020
in the states that not all not

00:37:33,940 --> 00:37:36,340
everything was roses meaning not

00:37:35,020 --> 00:37:38,470
everything went great there were a ton

00:37:36,340 --> 00:37:40,060
of lessons learned doing this like I

00:37:38,470 --> 00:37:42,580
said the rate of change in AWS is

00:37:40,060 --> 00:37:44,020
staggering definitely need to be

00:37:42,580 --> 00:37:45,700
cautious with spending commitments you

00:37:44,020 --> 00:37:46,780
can certainly over by our eyes if we're

00:37:45,700 --> 00:37:48,280
going to make significant changes to

00:37:46,780 --> 00:37:49,870
your infrastructure that's a things that

00:37:48,280 --> 00:37:52,060
you have to be careful with the spot is

00:37:49,870 --> 00:37:53,440
definitely its own special snowflake and

00:37:52,060 --> 00:37:56,290
if you do it wrong it can end up costing

00:37:53,440 --> 00:37:58,300
me more money at the end of the day um a

00:37:56,290 --> 00:38:00,220
couple other cool examples that I won't

00:37:58,300 --> 00:38:01,720
have time to go into and then lastly

00:38:00,220 --> 00:38:04,030
I'll mention there is one downside

00:38:01,720 --> 00:38:05,830
theoretically to leaning into these

00:38:04,030 --> 00:38:07,180
platforms heavily to making more use of

00:38:05,830 --> 00:38:09,220
the native teachers which is vendor

00:38:07,180 --> 00:38:11,050
lock-in all right so if I make use of

00:38:09,220 --> 00:38:13,570
Aurora and there's not an Aurora analog

00:38:11,050 --> 00:38:14,950
on one of the other platforms what does

00:38:13,570 --> 00:38:17,080
that mean if I decide I want to leave

00:38:14,950 --> 00:38:19,030
AWS this isn't something that concerned

00:38:17,080 --> 00:38:21,730
us but it is something that's probably a

00:38:19,030 --> 00:38:23,620
concern for several people so if I can

00:38:21,730 --> 00:38:27,370
leave it with one thought it would be

00:38:23,620 --> 00:38:28,540
that while we got good at operating data

00:38:27,370 --> 00:38:30,550
centers and there were certain best

00:38:28,540 --> 00:38:32,440
practices there that is not what it

00:38:30,550 --> 00:38:33,550
looks like to effectively do cloud well

00:38:32,440 --> 00:38:35,980
there's a lot of things we have to

00:38:33,550 --> 00:38:38,830
change as cloud evolved as the platform

00:38:35,980 --> 00:38:40,060
offers new features to us and if we lean

00:38:38,830 --> 00:38:42,310
into those if we do those well and

00:38:40,060 --> 00:38:44,590
become good effective operators of

00:38:42,310 --> 00:38:45,940
public cloud then we can save a

00:38:44,590 --> 00:38:47,530
significant amount of money in our case

00:38:45,940 --> 00:38:50,290
we're able to cut our infrastructure

00:38:47,530 --> 00:38:52,120
cost by over 50% which is several

00:38:50,290 --> 00:38:53,380
million dollars a year I love that

00:38:52,120 --> 00:38:54,700
because then I can go back to my boss

00:38:53,380 --> 00:38:57,490
and make in case I get to hire more

00:38:54,700 --> 00:38:59,380
engineers and this is a good feedback

00:38:57,490 --> 00:39:01,300
cycle in terms of our product and and

00:38:59,380 --> 00:39:05,370
how we set our own experiences back into

00:39:01,300 --> 00:39:05,370
our product so thanks

00:39:06,690 --> 00:39:09,900
[Music]

00:39:07,400 --> 00:39:12,870
[Applause]

00:39:09,900 --> 00:39:16,570
thank you very much Eric

00:39:12,870 --> 00:39:18,880
we actually are already on time and as

00:39:16,570 --> 00:39:20,740
the barbecue starting to downstairs and

00:39:18,880 --> 00:39:22,420
you want to collect your voters for food

00:39:20,740 --> 00:39:24,520
because there are vultures but before we

00:39:22,420 --> 00:39:27,040
go to barbecue take your just downstairs

00:39:24,520 --> 00:39:29,230
as well so thank you very much Erica but

00:39:27,040 --> 00:39:30,550
let's take the questions down there and

00:39:29,230 --> 00:39:33,450
you'll be more efficient with the beauty

00:39:30,550 --> 00:39:37,580
always better right thank you much

00:39:33,450 --> 00:39:37,580

YouTube URL: https://www.youtube.com/watch?v=xsu2axSQXgg


