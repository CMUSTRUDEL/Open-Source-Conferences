Title: Berlin Buzzwords 2017: Stefan Vetter, Thomas Fricke - Rolling out Enterprise Kubernetes Clouds @ SAP
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	In this talk we give insights in how we have set up several Kubernetes clouds for SAP. We tell the whole story, from PoC state, first developer installations, testing until production. We implemented on premises, in internal and external IaaS clouds. We used Docker and Rkt, rolled out database applications and implemented deployment pipelines. Special applications have special needs, so we tweaked parameters.

At the end, we implemented several self-installing, self-hosted, self-healing and extendable Kubernetes clusters, which allow application deployment on scale for cutting edge case involving high performance databases and number crunching applications.

Read more:
https://2017.berlinbuzzwords.de/17/session/rolling-out-enterprise-kubernetes-clouds-sap

About Stefan Vetter:
https://2017.berlinbuzzwords.de/users/stefan-vetter

About Thomas Fricke:
https://2017.berlinbuzzwords.de/users/thomas-fricke

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:07,030 --> 00:00:16,119
thank you so well yeah I'm the global

00:00:12,460 --> 00:00:21,509
topic container technology at sa P so we

00:00:16,119 --> 00:00:25,150
in our department are creating the

00:00:21,509 --> 00:00:29,200
architecture to deploy kubernetes at a

00:00:25,150 --> 00:00:34,960
JP and Thomas basically is working

00:00:29,200 --> 00:00:36,700
together with us so Samuel yes so this

00:00:34,960 --> 00:00:39,210
is the second talk at the Berlin

00:00:36,700 --> 00:00:41,710
buzzword so I've been here last year

00:00:39,210 --> 00:00:45,070
exactly about this topic but without

00:00:41,710 --> 00:00:48,400
Stefan so has developed a little bit and

00:00:45,070 --> 00:00:50,500
actually everybody knows know there is

00:00:48,400 --> 00:00:54,070
something like docker and everybody's

00:00:50,500 --> 00:00:58,510
talking about micro services but if you

00:00:54,070 --> 00:01:02,790
come to a startup like SAT which is a

00:00:58,510 --> 00:01:06,100
big company with a big business and big

00:01:02,790 --> 00:01:10,090
container then you face completely

00:01:06,100 --> 00:01:13,530
different problems so if you switch to

00:01:10,090 --> 00:01:16,630
the next sheet so then we will see what

00:01:13,530 --> 00:01:18,999
they told us containers are for shipping

00:01:16,630 --> 00:01:21,969
we build containers it's a unique format

00:01:18,999 --> 00:01:26,049
and you can roll or container and then

00:01:21,969 --> 00:01:29,770
if you it's like any other technology if

00:01:26,049 --> 00:01:32,249
you put something out in the wild people

00:01:29,770 --> 00:01:36,579
play with it and people do things and

00:01:32,249 --> 00:01:39,539
then the scene is changing so the next

00:01:36,579 --> 00:01:43,569
shows what people are also doing become

00:01:39,539 --> 00:01:50,520
containers so housing in containers this

00:01:43,569 --> 00:01:50,520
was not intended but somehow yeah looks

00:01:50,729 --> 00:01:58,090
looks usable you can have a house in

00:01:54,009 --> 00:02:01,959
containers like the thing we had if you

00:01:58,090 --> 00:02:05,159
talk about containers and micro services

00:02:01,959 --> 00:02:08,920
was mostly intended to run stateless

00:02:05,159 --> 00:02:12,280
services in containers or no data you

00:02:08,920 --> 00:02:14,319
know the kettle and eps picture so

00:02:12,280 --> 00:02:19,120
China's in production have been

00:02:14,319 --> 00:02:20,950
considered as pets and then if as a

00:02:19,120 --> 00:02:24,220
syllabus Carolyn is if you don't need

00:02:20,950 --> 00:02:29,260
them anymore far away but then this is a

00:02:24,220 --> 00:02:31,660
picture from turn off us so it's how

00:02:29,260 --> 00:02:35,590
they see the way of dealing with

00:02:31,660 --> 00:02:38,709
legacies of everybody who has survived

00:02:35,590 --> 00:02:41,319
three months of having business in my

00:02:38,709 --> 00:02:44,170
experience as legacy software everybody

00:02:41,319 --> 00:02:46,810
every startup after three months is kind

00:02:44,170 --> 00:02:50,050
of this dragon and then if you are

00:02:46,810 --> 00:02:53,050
successful this dragon is making the

00:02:50,050 --> 00:02:57,220
money for you and therefore you cannot

00:02:53,050 --> 00:03:02,110
kill the dragon because he wants your

00:02:57,220 --> 00:03:04,660
income more less so you are you have to

00:03:02,110 --> 00:03:07,780
deal with it so this is a picture of you

00:03:04,660 --> 00:03:11,350
see yes let's do cloud native up a

00:03:07,780 --> 00:03:13,840
little bit and that's exactly what we

00:03:11,350 --> 00:03:16,299
say is it as a PDF more than one dragon

00:03:13,840 --> 00:03:19,150
there a lot of dragons there and you see

00:03:16,299 --> 00:03:22,750
cloud architecture they do the wizardry

00:03:19,150 --> 00:03:24,940
try to influence the entire beast you

00:03:22,750 --> 00:03:28,810
see the line of debt

00:03:24,940 --> 00:03:31,209
project managers lying around sis admins

00:03:28,810 --> 00:03:34,000
and database admins trying to fight them

00:03:31,209 --> 00:03:34,780
senior developers try to keep it under

00:03:34,000 --> 00:03:38,650
control

00:03:34,780 --> 00:03:41,019
so exactly the picture you you

00:03:38,650 --> 00:03:44,109
foundation think the guy's exactly

00:03:41,019 --> 00:03:46,209
understood what's happening and the

00:03:44,109 --> 00:03:48,070
opposite is also true if you have no

00:03:46,209 --> 00:03:52,299
legacy you don't have a business and to

00:03:48,070 --> 00:03:53,680
be to be honest the next picture people

00:03:52,299 --> 00:03:56,829
are doing something completely different

00:03:53,680 --> 00:04:00,100
with its containers then we have

00:03:56,829 --> 00:04:01,750
imagined Google is known to run

00:04:00,100 --> 00:04:04,690
everything in container so they have

00:04:01,750 --> 00:04:07,329
must have found a way of running even

00:04:04,690 --> 00:04:10,480
their windows in the Google cloud it

00:04:07,329 --> 00:04:13,480
container somehow solution is normally

00:04:10,480 --> 00:04:15,430
your protec a VM inside the container

00:04:13,480 --> 00:04:18,090
which is reversing the thing you would

00:04:15,430 --> 00:04:22,049
expect and put

00:04:18,090 --> 00:04:27,150
put a container around a hypervisor

00:04:22,049 --> 00:04:29,070
which is weird and what I always tell

00:04:27,150 --> 00:04:32,430
people in training this is not the first

00:04:29,070 --> 00:04:34,830
thing you should do with a container but

00:04:32,430 --> 00:04:39,330
if you go to customers and they say oh

00:04:34,830 --> 00:04:42,270
we have this as a PR 2 system r2 not our

00:04:39,330 --> 00:04:44,220
fleet it's even older than r3 and it's

00:04:42,270 --> 00:04:45,510
running on Windows servers only which

00:04:44,220 --> 00:04:49,320
are very ordered we have paying

00:04:45,510 --> 00:04:52,890
customers which pay us not to be

00:04:49,320 --> 00:04:55,620
migrated to the latest technology it's

00:04:52,890 --> 00:05:00,060
quite impossible to say no and actually

00:04:55,620 --> 00:05:04,340
it works so we tested it and you see the

00:05:00,060 --> 00:05:07,740
final or really book is coming out in

00:05:04,340 --> 00:05:12,270
the next week so windows in kubernetes

00:05:07,740 --> 00:05:15,300
definitely is a topic and this picture

00:05:12,270 --> 00:05:21,360
is from liberals Polyphemus it's a

00:05:15,300 --> 00:05:23,370
living fossil so this way you have an

00:05:21,360 --> 00:05:25,200
imagination what's really happening out

00:05:23,370 --> 00:05:28,200
there if a customer has a business that

00:05:25,200 --> 00:05:31,410
wants to move its business into the

00:05:28,200 --> 00:05:34,169
container and in kubernetes world but

00:05:31,410 --> 00:05:37,470
and that's the cake that's wrong I mean

00:05:34,169 --> 00:05:41,100
there's also a use case to run Windows

00:05:37,470 --> 00:05:43,890
and containers for example um you have

00:05:41,100 --> 00:05:46,410
good infrastructure like we have a lot

00:05:43,890 --> 00:05:49,350
of ethical we are building software for

00:05:46,410 --> 00:05:51,300
line logs for Windows for whatever yeah

00:05:49,350 --> 00:05:54,710
different versions of this different

00:05:51,300 --> 00:05:58,020
versions of that so we are now moving to

00:05:54,710 --> 00:06:01,470
both our stuff and tests Horrible's and

00:05:58,020 --> 00:06:04,470
do optimizations in containers but what

00:06:01,470 --> 00:06:06,990
about Windows because we also need to do

00:06:04,470 --> 00:06:09,150
the same stuff for Windows so should we

00:06:06,990 --> 00:06:10,890
run to infrastructures like a container

00:06:09,150 --> 00:06:13,200
infrastructure and a window server

00:06:10,890 --> 00:06:15,960
infrastructure probably in a VM and for

00:06:13,200 --> 00:06:18,590
infrastructure or should we just move

00:06:15,960 --> 00:06:22,200
the windows VMs into containers though

00:06:18,590 --> 00:06:23,789
so what we surely do is we build up a

00:06:22,200 --> 00:06:27,029
kubernetes cluster

00:06:23,789 --> 00:06:29,969
we put the lining spills into containers

00:06:27,029 --> 00:06:32,159
and we put the Windows virtual machine

00:06:29,969 --> 00:06:34,289
into containers because windows

00:06:32,159 --> 00:06:37,580
containers are not ready as of now you

00:06:34,289 --> 00:06:40,949
cannot use that in production so we

00:06:37,580 --> 00:06:44,759
basically build our software then in a

00:06:40,949 --> 00:06:46,740
VM on the container yeah and the

00:06:44,759 --> 00:06:49,559
interesting part is after we have done

00:06:46,740 --> 00:06:52,999
this they told us oh it's less pain than

00:06:49,559 --> 00:06:55,379
running windows the windows way so

00:06:52,999 --> 00:06:58,499
containers are not solving the problem

00:06:55,379 --> 00:07:01,559
but they are kind of relief mitigation

00:06:58,499 --> 00:07:04,919
of the pain of running Windows systems

00:07:01,559 --> 00:07:07,169
in containers so this is kind of what

00:07:04,919 --> 00:07:09,599
you can expect if you go to real

00:07:07,169 --> 00:07:14,039
customers with the real business and it

00:07:09,599 --> 00:07:16,379
seems to work and we there are recipes

00:07:14,039 --> 00:07:19,139
in the net how to do it took our

00:07:16,379 --> 00:07:21,509
smallest two or three weeks to do the

00:07:19,139 --> 00:07:27,330
entire ecosystem around when you have

00:07:21,509 --> 00:07:28,800
this kind of solution yeah and okay we

00:07:27,330 --> 00:07:30,629
talked a lot about companies I cannot

00:07:28,800 --> 00:07:34,020
expect that everybody of you knows what

00:07:30,629 --> 00:07:35,819
kubernetes is communities is now in the

00:07:34,020 --> 00:07:38,370
moment one of the fastest developing

00:07:35,819 --> 00:07:40,800
open source projects it's from Google

00:07:38,370 --> 00:07:45,449
Google infrastructure for everybody else

00:07:40,800 --> 00:07:48,270
it GP part the meaning of this thing is

00:07:45,449 --> 00:07:50,689
you have the same root of the word as

00:07:48,270 --> 00:07:54,080
governor or cybernetics so it's

00:07:50,689 --> 00:07:58,979
kubernetes is governing the entire

00:07:54,080 --> 00:08:02,279
container system google has an older

00:07:58,979 --> 00:08:04,770
system which is a kind of joke with this

00:08:02,279 --> 00:08:09,389
is about they call it bark and the box

00:08:04,770 --> 00:08:12,330
you might know live in cubes so that is

00:08:09,389 --> 00:08:16,259
kind of an internal google joke for us

00:08:12,330 --> 00:08:20,279
important it's in our entire open source

00:08:16,259 --> 00:08:23,189
ecosystem it's written in gold and the

00:08:20,279 --> 00:08:26,029
idea is not to manage machines anymore

00:08:23,189 --> 00:08:28,180
if you look into the open stack of

00:08:26,029 --> 00:08:31,030
virtualization environment of

00:08:28,180 --> 00:08:35,290
VMware or the other cloud it's all about

00:08:31,030 --> 00:08:37,300
how I manage my machines and this is not

00:08:35,290 --> 00:08:40,330
about managing machines the outcome of

00:08:37,300 --> 00:08:42,400
kubernetes lazar must be you manage your

00:08:40,330 --> 00:08:44,470
applications not your machines anymore

00:08:42,400 --> 00:08:48,940
so it's well-suited for DevOps

00:08:44,470 --> 00:08:50,800
environment and that's what is the

00:08:48,940 --> 00:08:53,040
intention behind it so you want to get

00:08:50,800 --> 00:08:56,920
away of the pain of running hardware

00:08:53,040 --> 00:08:59,170
this is a promise but I think so

00:08:56,920 --> 00:09:03,970
delivered something so to take over at

00:08:59,170 --> 00:09:06,850
this point what Thomas just described is

00:09:03,970 --> 00:09:11,230
you know your application needs some

00:09:06,850 --> 00:09:15,130
amount of CPU some amount of memory and

00:09:11,230 --> 00:09:17,860
stuff like this yeah before containers

00:09:15,130 --> 00:09:20,320
before kubernetes you were just going

00:09:17,860 --> 00:09:25,210
there and saying okay I need a machine

00:09:20,320 --> 00:09:30,040
or a VM that has let's say 12 cm 12

00:09:25,210 --> 00:09:33,460
cores and like 60 kms of RAM that I can

00:09:30,040 --> 00:09:35,950
execute my application with container

00:09:33,460 --> 00:09:38,110
infrastructure and kubernetes you

00:09:35,950 --> 00:09:40,390
basically describe that in one manifest

00:09:38,110 --> 00:09:42,820
and then you just deploy your

00:09:40,390 --> 00:09:45,280
application once twice three times four

00:09:42,820 --> 00:09:49,030
times doesn't matter and kubernetes

00:09:45,280 --> 00:09:51,610
takes takes over to schedule this on one

00:09:49,030 --> 00:09:54,960
of the nodes inside the cluster which

00:09:51,610 --> 00:09:57,130
basically offers to share the

00:09:54,960 --> 00:09:59,200
infrastructure the hardware between

00:09:57,130 --> 00:10:00,790
multiple applications so you can even

00:09:59,200 --> 00:10:03,630
run multiple attack applications in

00:10:00,790 --> 00:10:06,340
parallel on the same hardware now and

00:10:03,630 --> 00:10:08,740
the point is you describe it in that

00:10:06,340 --> 00:10:10,570
definition for your applications you

00:10:08,740 --> 00:10:12,610
don't have to describe a virtual machine

00:10:10,570 --> 00:10:14,410
you don't have to describe an operating

00:10:12,610 --> 00:10:16,180
system you don't have to describe

00:10:14,410 --> 00:10:18,160
anything about it you just describe your

00:10:16,180 --> 00:10:20,290
container and what you need for it and

00:10:18,160 --> 00:10:20,950
then you deploy it anywhere on

00:10:20,290 --> 00:10:24,130
googliness

00:10:20,950 --> 00:10:27,070
that's all and that makes things

00:10:24,130 --> 00:10:30,130
much more easy and also comes along with

00:10:27,070 --> 00:10:33,850
the DevOps abroad because the depth now

00:10:30,130 --> 00:10:37,420
take over the hops photo without you

00:10:33,850 --> 00:10:40,290
having to drop at the point yeah and

00:10:37,420 --> 00:10:43,960
this leads to the next slide because

00:10:40,290 --> 00:10:47,770
here we have a ten thousand six zero

00:10:43,960 --> 00:10:50,590
view on kubernetes basically so you have

00:10:47,770 --> 00:10:53,140
multiple possibilities to work with

00:10:50,590 --> 00:10:57,730
kubernetes basically the final one is a

00:10:53,140 --> 00:10:59,530
behind so they eat the highway connects

00:10:57,730 --> 00:11:03,250
to the API server and the server

00:10:59,530 --> 00:11:04,780
basically puts the informations in to

00:11:03,250 --> 00:11:07,060
f.2d and the schedulers and the

00:11:04,780 --> 00:11:10,180
controller to take over the information

00:11:07,060 --> 00:11:13,030
from edge and the CLE basically

00:11:10,180 --> 00:11:15,850
implements the API and talks for the API

00:11:13,030 --> 00:11:19,360
server as well in the UI is just an

00:11:15,850 --> 00:11:22,600
application to do the sales now and at

00:11:19,360 --> 00:11:25,360
the end of all this is communicating

00:11:22,600 --> 00:11:28,330
with cubelets cubelet is basically the

00:11:25,360 --> 00:11:31,240
local administration application on the

00:11:28,330 --> 00:11:33,970
real machines that orchestrates the

00:11:31,240 --> 00:11:38,200
container runtime that is running on the

00:11:33,970 --> 00:11:39,850
machine to both the containers or to run

00:11:38,200 --> 00:11:44,160
the containers basically inside the

00:11:39,850 --> 00:11:47,590
machine so what you really care about is

00:11:44,160 --> 00:11:50,260
your are either someone or an

00:11:47,590 --> 00:11:52,540
application or whatever yeah you use an

00:11:50,260 --> 00:11:58,260
API and you have a container class or

00:11:52,540 --> 00:12:01,750
damnit you don't need anything else so

00:11:58,260 --> 00:12:04,270
yeah so and what we also find this we

00:12:01,750 --> 00:12:07,270
have if we deploy an application for

00:12:04,270 --> 00:12:09,280
example there are very valuable patterns

00:12:07,270 --> 00:12:13,090
for example the Diploma now is a

00:12:09,280 --> 00:12:16,210
first-class citizen of kubernetes so if

00:12:13,090 --> 00:12:19,240
you do deployment the first thing which

00:12:16,210 --> 00:12:22,540
is created is a replica set and the

00:12:19,240 --> 00:12:26,080
wavelet concert is creating actually the

00:12:22,540 --> 00:12:28,330
number of applications or a number of

00:12:26,080 --> 00:12:31,050
pots which are collections of containers

00:12:28,330 --> 00:12:33,660
you need so you're all out

00:12:31,050 --> 00:12:37,110
any application through a replicant in

00:12:33,660 --> 00:12:40,110
the replica set chaos that exactly the

00:12:37,110 --> 00:12:41,850
number you want to have is deployed

00:12:40,110 --> 00:12:44,790
somewhere in your cluster if your

00:12:41,850 --> 00:12:46,890
cluster is the soda machines big it has

00:12:44,790 --> 00:12:49,730
it as a scheduler where to place my

00:12:46,890 --> 00:12:53,550
application where can I put them and

00:12:49,730 --> 00:12:57,720
spread them over the cluster and if you

00:12:53,550 --> 00:13:00,839
do an update one in future another

00:12:57,720 --> 00:13:05,550
replicas set is spawned and you get

00:13:00,839 --> 00:13:08,279
another a replica somewhere and then it

00:13:05,550 --> 00:13:10,680
should disappear here but there okay did

00:13:08,279 --> 00:13:13,170
not survive everything from power point

00:13:10,680 --> 00:13:16,200
but don't matter you get a new replica

00:13:13,170 --> 00:13:19,130
set with a new world and then it's a

00:13:16,200 --> 00:13:22,890
well-defined thing that you do a rolling

00:13:19,130 --> 00:13:26,399
roll art in a replica set from a new

00:13:22,890 --> 00:13:30,089
volume to an old world and you can even

00:13:26,399 --> 00:13:33,480
roll back if you if you announce the

00:13:30,089 --> 00:13:37,079
image and something you know works well

00:13:33,480 --> 00:13:40,170
old also would stop if something breaks

00:13:37,079 --> 00:13:43,459
if you have an image which is not valid

00:13:40,170 --> 00:13:46,079
or somehow of the readiness and saliva

00:13:43,459 --> 00:13:49,440
health probes of the container are not

00:13:46,079 --> 00:13:52,980
working so their role does not wipe out

00:13:49,440 --> 00:13:55,350
your entire service because this can be

00:13:52,980 --> 00:13:58,020
connected to an another kubernetes

00:13:55,350 --> 00:14:01,350
entity at service which collects all

00:13:58,020 --> 00:14:03,810
your applications into a single thing

00:14:01,350 --> 00:14:06,839
and does a round-robin around it so this

00:14:03,810 --> 00:14:09,510
is kind first time I've seen rolling

00:14:06,839 --> 00:14:12,060
update as a first class citizen in

00:14:09,510 --> 00:14:14,610
equipment in an orchestration cluster

00:14:12,060 --> 00:14:16,920
and by the way you don't have to do

00:14:14,610 --> 00:14:19,079
rolling updates you can also do

00:14:16,920 --> 00:14:22,440
Bluegreen deployments as you see blue

00:14:19,079 --> 00:14:24,149
and green so you can say okay I want to

00:14:22,440 --> 00:14:28,680
have my new application now deployed

00:14:24,149 --> 00:14:30,360
here but I just want to have 20% of the

00:14:28,680 --> 00:14:32,970
traffic go into the new application

00:14:30,360 --> 00:14:34,740
because I don't want to have if there's

00:14:32,970 --> 00:14:37,740
some back in or something like that I

00:14:34,740 --> 00:14:41,610
want to not to fail all the customers

00:14:37,740 --> 00:14:43,170
but only every fifth customer so I do a

00:14:41,610 --> 00:14:44,880
Bluegreen employment so I have both

00:14:43,170 --> 00:14:47,280
versions of my application running in

00:14:44,880 --> 00:14:49,590
the cluster and kubernetes takes care of

00:14:47,280 --> 00:14:53,070
directing the loads to the different

00:14:49,590 --> 00:14:54,750
plots and the different versions so if I

00:14:53,070 --> 00:14:56,310
see there is an error in the new version

00:14:54,750 --> 00:14:59,750
I can just draw it back

00:14:56,310 --> 00:15:01,470
so all fine old words in there and

00:14:59,750 --> 00:15:05,340
customers running with the old version

00:15:01,470 --> 00:15:08,520
or so but if I see everything works out

00:15:05,340 --> 00:15:11,070
then I can surely remove the blue parts

00:15:08,520 --> 00:15:14,340
or the old version and leave the

00:15:11,070 --> 00:15:17,490
customers only to the wing pod now it is

00:15:14,340 --> 00:15:20,220
quite outstanding because before I've

00:15:17,490 --> 00:15:23,100
been an inner God up in one bigger

00:15:20,220 --> 00:15:25,290
involve in Internet company here and we

00:15:23,100 --> 00:15:28,800
needed I think three or four years to

00:15:25,290 --> 00:15:33,170
implement for all applications on that

00:15:28,800 --> 00:15:36,150
platform a rolling update and quite of

00:15:33,170 --> 00:15:38,670
stable and successful way of deploying

00:15:36,150 --> 00:15:41,760
applications as role in updating them

00:15:38,670 --> 00:15:44,790
without service interruption and this is

00:15:41,760 --> 00:15:47,700
the result service interruption is quite

00:15:44,790 --> 00:15:51,030
important because this means that you

00:15:47,700 --> 00:15:53,310
can do continuous live deployments and

00:15:51,030 --> 00:15:58,440
things like this and you don't have to

00:15:53,310 --> 00:16:00,420
care about versions you simply say to

00:15:58,440 --> 00:16:02,460
the developers your version has to

00:16:00,420 --> 00:16:06,780
comply with other versions plus minus

00:16:02,460 --> 00:16:08,850
one or two minor version that you don't

00:16:06,780 --> 00:16:12,300
break the interfaces to fascist this

00:16:08,850 --> 00:16:14,820
means to have a always one platform

00:16:12,300 --> 00:16:18,600
where you can really do multiple

00:16:14,820 --> 00:16:20,190
deployments a day so but we don't want

00:16:18,600 --> 00:16:22,980
to say that kubernetes solve the

00:16:20,190 --> 00:16:25,650
problems of updates and also solve the

00:16:22,980 --> 00:16:28,350
problems that you might have a downtime

00:16:25,650 --> 00:16:31,530
because if you're running for example

00:16:28,350 --> 00:16:33,600
databases and the databases needs to

00:16:31,530 --> 00:16:35,970
converge the data from one version to

00:16:33,600 --> 00:16:38,370
another usually need the downtime

00:16:35,970 --> 00:16:39,750
because you cannot run one version and

00:16:38,370 --> 00:16:42,860
the other version in parallel with the

00:16:39,750 --> 00:16:45,180
same data store yeah so there are

00:16:42,860 --> 00:16:47,920
applications where you cannot do it

00:16:45,180 --> 00:16:50,559
and there are also applications like

00:16:47,920 --> 00:16:54,009
if you have an application server that

00:16:50,559 --> 00:16:55,629
doesn't support murky influences so you

00:16:54,009 --> 00:16:58,179
have to store everything in one

00:16:55,629 --> 00:17:00,759
application server instead of in two so

00:16:58,179 --> 00:17:03,459
then you cannot run to port and download

00:17:00,759 --> 00:17:06,159
now so this means you have to either

00:17:03,459 --> 00:17:06,909
switch directly which is also possible

00:17:06,159 --> 00:17:10,179
in Kannada

00:17:06,909 --> 00:17:14,319
so basically replace it whether

00:17:10,179 --> 00:17:17,079
deployment so as soon as the new pod get

00:17:14,319 --> 00:17:19,089
healthy you remove the old one and

00:17:17,079 --> 00:17:23,409
switch completely to the new one yeah

00:17:19,089 --> 00:17:25,179
but yeah so kubernetes doesn't solve all

00:17:23,409 --> 00:17:28,419
the problems because kubernetes doesn't

00:17:25,179 --> 00:17:30,789
or isn't able to join your application

00:17:28,419 --> 00:17:33,429
to look into your application to change

00:17:30,789 --> 00:17:34,899
your application to add support for

00:17:33,429 --> 00:17:38,080
things that your application doesn't

00:17:34,899 --> 00:17:40,120
support so only what is possible with

00:17:38,080 --> 00:17:42,399
your application get much more easy with

00:17:40,120 --> 00:17:45,220
kubernetes because you don't have to

00:17:42,399 --> 00:17:48,190
reinstall operating system you don't

00:17:45,220 --> 00:17:50,740
have to update your virtual machine or

00:17:48,190 --> 00:17:52,480
your real hardware you don't have to

00:17:50,740 --> 00:17:54,580
care about updates scenarios because

00:17:52,480 --> 00:17:58,389
well the container you just exchange the

00:17:54,580 --> 00:18:01,690
application no its overall environment

00:17:58,389 --> 00:18:04,809
so you don't have to update an

00:18:01,690 --> 00:18:08,740
application within the container you

00:18:04,809 --> 00:18:12,669
just exchange it that's done yeah so so

00:18:08,740 --> 00:18:15,309
and if you look into a typical more

00:18:12,669 --> 00:18:20,019
sophisticated applications that you see

00:18:15,309 --> 00:18:21,940
would not only have databases and the

00:18:20,019 --> 00:18:25,899
web portal you also have hidden layers

00:18:21,940 --> 00:18:27,610
for example the load balancer is part of

00:18:25,899 --> 00:18:29,710
your application because you might have

00:18:27,610 --> 00:18:33,700
load balancer rules if you ever played

00:18:29,710 --> 00:18:34,630
with f5 I rules and you know what I'm

00:18:33,700 --> 00:18:38,889
talking about

00:18:34,630 --> 00:18:41,350
and you see there are stateless layers

00:18:38,889 --> 00:18:43,659
for example the the upper four and they

00:18:41,350 --> 00:18:45,970
are stateful layers so you have kind of

00:18:43,659 --> 00:18:48,909
storage you have your sequel databases

00:18:45,970 --> 00:18:51,460
your no sequel database and you should

00:18:48,909 --> 00:18:55,110
not underestimate the state in your

00:18:51,460 --> 00:18:58,809
messaging system if you're on a Kafka a

00:18:55,110 --> 00:19:00,000
kind of RabbitMQ or zero and Q are any

00:18:58,809 --> 00:19:02,790
messaging system

00:19:00,000 --> 00:19:04,770
messaging system has state and is

00:19:02,790 --> 00:19:09,750
therefore part of the persistent layer

00:19:04,770 --> 00:19:14,390
and this way you can make everything

00:19:09,750 --> 00:19:16,890
except these layout status so if you

00:19:14,390 --> 00:19:19,620
separate your applications then you have

00:19:16,890 --> 00:19:22,020
the business logic on this layer you

00:19:19,620 --> 00:19:24,030
have might have a reddish character is

00:19:22,020 --> 00:19:26,580
not really stateful because it can be

00:19:24,030 --> 00:19:28,890
regenerated on the fly and you have the

00:19:26,580 --> 00:19:30,840
web portal traces to the outside and you

00:19:28,890 --> 00:19:33,830
have the low terms or rules and

00:19:30,840 --> 00:19:36,840
therefore it's absolutely important to

00:19:33,830 --> 00:19:41,130
before you start a project to identify

00:19:36,840 --> 00:19:46,680
the states for layers and anything which

00:19:41,130 --> 00:19:48,450
is not stable the kettle part can be put

00:19:46,680 --> 00:19:50,910
into kubernetes immediately without

00:19:48,450 --> 00:19:54,030
hassle so it's quite easy to put these

00:19:50,910 --> 00:19:56,220
stateless applications in and then you

00:19:54,030 --> 00:19:58,380
can do other evolving updates but if you

00:19:56,220 --> 00:20:01,020
have database every database Manas has

00:19:58,380 --> 00:20:03,990
its own replication idea if you're

00:20:01,020 --> 00:20:07,800
looking to post grants or into MongoDB

00:20:03,990 --> 00:20:10,020
or you name it every replication is

00:20:07,800 --> 00:20:14,310
different and you have to handle

00:20:10,020 --> 00:20:16,710
database by database if you have to

00:20:14,310 --> 00:20:20,480
bring a database into kubernetes this is

00:20:16,710 --> 00:20:23,340
now possible with stateful sets they are

00:20:20,480 --> 00:20:25,290
something which is located on a machine

00:20:23,340 --> 00:20:28,440
where you might have a hard disk you

00:20:25,290 --> 00:20:31,260
might have SSDs for your data and then

00:20:28,440 --> 00:20:36,060
you can run a beast like Hana in memory

00:20:31,260 --> 00:20:39,810
which is backed by kind of disk space

00:20:36,060 --> 00:20:43,710
and then you can run even Hana databases

00:20:39,810 --> 00:20:45,930
in incriminated and last year everybody

00:20:43,710 --> 00:20:49,230
discuss things like are containers ready

00:20:45,930 --> 00:20:52,350
for production is this prepare for the

00:20:49,230 --> 00:20:55,350
interface and I would say the SFSP at

00:20:52,350 --> 00:20:56,970
the enterprise company and if Hana is

00:20:55,350 --> 00:21:00,780
something you would run in production

00:20:56,970 --> 00:21:05,700
which is more less occasional oh but you

00:21:00,780 --> 00:21:08,760
can also stay with out stateless

00:21:05,700 --> 00:21:11,070
application sets and run stateful

00:21:08,760 --> 00:21:12,659
applications because if you have our

00:21:11,070 --> 00:21:15,659
first layer that has a

00:21:12,659 --> 00:21:18,570
tribution over the overall cluster then

00:21:15,659 --> 00:21:20,849
you're able to connect to the data on

00:21:18,570 --> 00:21:22,590
every node so it doesn't matter if you

00:21:20,849 --> 00:21:25,649
slow the data locally to this node

00:21:22,590 --> 00:21:27,599
because it's also a viable on any other

00:21:25,649 --> 00:21:30,989
node in the cluster and this is

00:21:27,599 --> 00:21:34,710
something for example how we also work

00:21:30,989 --> 00:21:38,070
on to get the distributed storage engine

00:21:34,710 --> 00:21:39,779
to automatically detect the disks in the

00:21:38,070 --> 00:21:42,450
cluster nodes in the kubernetes cluster

00:21:39,779 --> 00:21:48,690
and offer them to the applications on

00:21:42,450 --> 00:21:52,679
kubernetes so like I find right so the

00:21:48,690 --> 00:21:57,499
ecosystem we are working on is basically

00:21:52,679 --> 00:22:01,820
what you see here so we have a Korra has

00:21:57,499 --> 00:22:04,769
currently delivered as container lineups

00:22:01,820 --> 00:22:08,549
we are using the container runtime

00:22:04,769 --> 00:22:11,249
rocket I move here better because

00:22:08,549 --> 00:22:12,109
otherwise you might hear this sound

00:22:11,249 --> 00:22:16,080
again

00:22:12,109 --> 00:22:18,479
so we are using Rockets as the container

00:22:16,080 --> 00:22:22,049
runtime I mean most of you might know

00:22:18,479 --> 00:22:24,479
docker instead why you we provide we use

00:22:22,049 --> 00:22:28,409
rocket while most of the people use

00:22:24,479 --> 00:22:32,519
docker well I will explain that in deep

00:22:28,409 --> 00:22:36,269
later but in general Rockets doesn't

00:22:32,519 --> 00:22:38,940
offer full rights right away so you have

00:22:36,269 --> 00:22:41,009
to give every single right to the

00:22:38,940 --> 00:22:42,899
application in the container while the

00:22:41,009 --> 00:22:45,419
doctor offers the full rights right away

00:22:42,899 --> 00:22:51,059
so for example if you start a container

00:22:45,419 --> 00:22:55,799
of rockets in kubernetes you will be the

00:22:51,059 --> 00:22:58,109
user named root but root can have to

00:22:55,799 --> 00:23:01,889
change mods to a file it can it will

00:22:58,109 --> 00:23:06,090
shown it cannot to a zoo not a zoo do

00:23:01,889 --> 00:23:07,249
nothing it just doesn't have rights even

00:23:06,090 --> 00:23:09,599
though it's named rudy

00:23:07,249 --> 00:23:11,789
well talker everything like this is

00:23:09,599 --> 00:23:13,770
possible so you have to manually remove

00:23:11,789 --> 00:23:16,080
the rights the dock

00:23:13,770 --> 00:23:18,600
while you have to manually add those

00:23:16,080 --> 00:23:21,960
with rockets and that's basically why we

00:23:18,600 --> 00:23:24,240
decided for rocket that was the first

00:23:21,960 --> 00:23:24,920
decision there's another one coming up

00:23:24,240 --> 00:23:28,320
later

00:23:24,920 --> 00:23:30,540
yeah we're using Jenkins and Nexus to

00:23:28,320 --> 00:23:32,340
integrate the container build pipelines

00:23:30,540 --> 00:23:35,640
and the lifecycle management and the

00:23:32,340 --> 00:23:38,280
security checking we use Co scale to

00:23:35,640 --> 00:23:43,650
monitor our kubernetes clusters because

00:23:38,280 --> 00:23:46,520
our core skill is in my opinion the most

00:23:43,650 --> 00:23:50,370
advanced monitoring tool for kubernetes

00:23:46,520 --> 00:23:53,100
right now the code kale just to explain

00:23:50,370 --> 00:23:54,810
it a little what Co CL you deploy a

00:23:53,100 --> 00:23:57,750
different set to your kubernetes cluster

00:23:54,810 --> 00:23:59,640
and every node yugi-boy into the

00:23:57,750 --> 00:24:01,890
kubernetes cluster will be automatically

00:23:59,640 --> 00:24:03,870
monitored as well as all the containers

00:24:01,890 --> 00:24:06,510
in the classroom will be automatically

00:24:03,870 --> 00:24:08,310
managed monitored because Co scale

00:24:06,510 --> 00:24:12,060
directly integrates of the kubernetes

00:24:08,310 --> 00:24:14,760
api and was a container engine and with

00:24:12,060 --> 00:24:16,700
the servers so you monitor the full

00:24:14,760 --> 00:24:21,590
stack right away without doing anything

00:24:16,700 --> 00:24:25,290
you just run Co scale SVD for sure is

00:24:21,590 --> 00:24:29,400
the key value stored at kubernetes users

00:24:25,290 --> 00:24:33,030
and we are using flannel in the small

00:24:29,400 --> 00:24:35,370
clusters for development and calico is

00:24:33,030 --> 00:24:43,020
meant for the bracken clusters of

00:24:35,370 --> 00:24:44,160
multi-tenancy so um yeah yeah what will

00:24:43,020 --> 00:24:47,160
we do in the future

00:24:44,160 --> 00:24:50,430
I think that's a interesting story

00:24:47,160 --> 00:24:52,740
so yeah what would all that also

00:24:50,430 --> 00:24:56,940
describes why we do is rocket right now

00:24:52,740 --> 00:24:59,850
that's another point we have a secure

00:24:56,940 --> 00:25:03,020
pot manifest meaning we don't give the

00:24:59,850 --> 00:25:05,840
pot any right like the containers yeah

00:25:03,020 --> 00:25:10,500
what kubernetes one four one five

00:25:05,840 --> 00:25:12,930
rockets had each each container had a

00:25:10,500 --> 00:25:15,320
rocket process so not like the docker

00:25:12,930 --> 00:25:18,120
you have a demin to run the containers

00:25:15,320 --> 00:25:20,150
with rockets you have a binary running

00:25:18,120 --> 00:25:22,560
one container or

00:25:20,150 --> 00:25:26,360
reconfiguring and stating one container

00:25:22,560 --> 00:25:30,360
and which is not the case of docker yeah

00:25:26,360 --> 00:25:34,290
the same manifests except of the API

00:25:30,360 --> 00:25:37,530
change in kubernetes you can use for

00:25:34,290 --> 00:25:40,350
kubernetes with the Cree implementation

00:25:37,530 --> 00:25:43,680
CRI means container runtime interface

00:25:40,350 --> 00:25:46,440
it's one more the interfaces the first

00:25:43,680 --> 00:25:49,980
was CNI the container network interface

00:25:46,440 --> 00:25:52,380
to make it possible that you can just

00:25:49,980 --> 00:25:56,040
change the network plug-in and continue

00:25:52,380 --> 00:25:58,410
working and here with GRI you see you

00:25:56,040 --> 00:26:01,410
can just exchange the container runtime

00:25:58,410 --> 00:26:03,900
this is a little broken I'm sorry so the

00:26:01,410 --> 00:26:05,040
first one is container Lee which is now

00:26:03,900 --> 00:26:07,770
maintained by the cloud native

00:26:05,040 --> 00:26:10,710
Foundation which was the container

00:26:07,770 --> 00:26:12,900
runtime used by docker and created by

00:26:10,710 --> 00:26:16,500
docker you have the choice for rocket

00:26:12,900 --> 00:26:21,240
labs maintained by Korres you can use

00:26:16,500 --> 00:26:25,980
cRIO by Red Hat and do the raised I

00:26:21,240 --> 00:26:28,680
think two months ago of let's say GA

00:26:25,980 --> 00:26:30,450
relief of um OCIE

00:26:28,680 --> 00:26:33,900
which is also a container run time

00:26:30,450 --> 00:26:36,660
working with the CRI and at the end you

00:26:33,900 --> 00:26:38,340
exactly have the same picture so you

00:26:36,660 --> 00:26:41,130
don't have to change your manifest

00:26:38,340 --> 00:26:43,370
except of the API changes when moving

00:26:41,130 --> 00:26:47,610
from one kubernetes version to the other

00:26:43,370 --> 00:26:50,340
yeah so the challenges are the

00:26:47,610 --> 00:26:53,030
Futurecast we are working on which we

00:26:50,340 --> 00:26:58,470
are implementing in our infrastructure

00:26:53,030 --> 00:27:05,480
is large networks meaning a couple of

00:26:58,470 --> 00:27:09,810
hundreds kubernetes nodes and also

00:27:05,480 --> 00:27:14,100
multi-tenancy with in the clusters as

00:27:09,810 --> 00:27:16,710
well as distributed clusters meaning how

00:27:14,100 --> 00:27:20,160
what kubernetes you can set up multiple

00:27:16,710 --> 00:27:22,800
clusters for example you have a data

00:27:20,160 --> 00:27:24,660
center in germany you have a data center

00:27:22,800 --> 00:27:29,020
in u.s. you have a data center in france

00:27:24,660 --> 00:27:31,570
in belgium and wherever else yeah

00:27:29,020 --> 00:27:34,630
and you have in each data center or

00:27:31,570 --> 00:27:37,210
kubernetes cluster then you can build up

00:27:34,630 --> 00:27:39,280
a classic Federation and you can

00:27:37,210 --> 00:27:41,350
administrate all those kubernetes

00:27:39,280 --> 00:27:44,890
clusters in all the different reasons

00:27:41,350 --> 00:27:47,559
and data centers over one API of a one

00:27:44,890 --> 00:27:51,040
control plane so you just execute one

00:27:47,559 --> 00:27:53,050
command and it will be done in each data

00:27:51,040 --> 00:27:55,630
center if you run it for each data

00:27:53,050 --> 00:27:57,880
center or if you just say ok I'm

00:27:55,630 --> 00:28:00,700
connecting to the German data center but

00:27:57,880 --> 00:28:03,610
I want the UF data center to change the

00:28:00,700 --> 00:28:05,290
version this is possible you don't have

00:28:03,610 --> 00:28:09,550
to care about it to Banaras takes care

00:28:05,290 --> 00:28:13,980
of this now distributed databases and

00:28:09,550 --> 00:28:17,920
GPUs for machine learning is also some

00:28:13,980 --> 00:28:21,450
topic we're currently working on yeah so

00:28:17,920 --> 00:28:24,820
so this is an example for how we handle

00:28:21,450 --> 00:28:27,160
big networks so effectively if you look

00:28:24,820 --> 00:28:30,970
into the basic network model of inators

00:28:27,160 --> 00:28:34,450
you'll see it's using a Class B Network

00:28:30,970 --> 00:28:40,630
so 10 some fixed number and then you

00:28:34,450 --> 00:28:42,640
have two digits or two to two digits

00:28:40,630 --> 00:28:46,600
less or two to two numbers left for

00:28:42,640 --> 00:28:50,910
addressing the node and for the port but

00:28:46,600 --> 00:28:57,070
this means that we are limited to 250

00:28:50,910 --> 00:29:01,120
for containers inside a machine of 254

00:28:57,070 --> 00:29:04,480
containers or pots in a cinema Fenian

00:29:01,120 --> 00:29:06,610
you will notice easily that the modern

00:29:04,480 --> 00:29:09,340
machines are handling more than

00:29:06,610 --> 00:29:12,450
thousands of containers so even there

00:29:09,340 --> 00:29:15,520
are examples even that you can handle

00:29:12,450 --> 00:29:19,570
2700 toka nginx containers on a

00:29:15,520 --> 00:29:23,530
raspberry P so this means this model for

00:29:19,570 --> 00:29:26,679
large machines is limited and the second

00:29:23,530 --> 00:29:32,620
thing is even harder in the standard

00:29:26,679 --> 00:29:35,470
model if you only have 255 addresses for

00:29:32,620 --> 00:29:36,759
your note and this limits you to exactly

00:29:35,470 --> 00:29:38,679
this

00:29:36,759 --> 00:29:41,619
network sighs and we are going into a

00:29:38,679 --> 00:29:43,659
direction where we really soon will see

00:29:41,619 --> 00:29:47,950
this limit and then we have to exchange

00:29:43,659 --> 00:29:49,320
the network model and this is possible

00:29:47,950 --> 00:29:53,440
because we have

00:29:49,320 --> 00:29:58,929
CNI plug-in and you can use this

00:29:53,440 --> 00:30:01,929
container network interface to handle to

00:29:58,929 --> 00:30:04,330
integrate and remove the container in

00:30:01,929 --> 00:30:08,139
your network so it's called all the time

00:30:04,330 --> 00:30:11,950
in new container changes its life cycle

00:30:08,139 --> 00:30:16,110
so if a new container is created you get

00:30:11,950 --> 00:30:20,470
a list of parameters which can be used

00:30:16,110 --> 00:30:25,600
to integrate the pot into the network

00:30:20,470 --> 00:30:28,509
and then they have a demon this is a cat

00:30:25,600 --> 00:30:30,970
from calico project calico is doing it

00:30:28,509 --> 00:30:32,710
and they have another cat named chosen

00:30:30,970 --> 00:30:36,039
for the demon there the felix daemon

00:30:32,710 --> 00:30:40,570
which does the routing entity iptables

00:30:36,039 --> 00:30:45,309
and this is not enough because in a big

00:30:40,570 --> 00:30:49,629
network you have to communicate the IP

00:30:45,309 --> 00:30:53,529
Jesus IP routes and effectively they

00:30:49,629 --> 00:30:56,200
solve the problem at calico turning a

00:30:53,529 --> 00:30:58,240
node into an entire data center so we

00:30:56,200 --> 00:31:00,610
use the border gateway protocol which is

00:30:58,240 --> 00:31:03,610
collecting all the internet route

00:31:00,610 --> 00:31:05,350
information and put it into a kubernetes

00:31:03,610 --> 00:31:07,509
cluster it's not connected to the BGP

00:31:05,350 --> 00:31:09,909
outside so this would be a severe

00:31:07,509 --> 00:31:13,929
security problem but they use the same

00:31:09,909 --> 00:31:16,090
technology have a demon but you can

00:31:13,929 --> 00:31:18,940
exchange it by any other border gateway

00:31:16,090 --> 00:31:21,039
protocol daemon and then it's connecting

00:31:18,940 --> 00:31:24,639
it to outside route reflectors that you

00:31:21,039 --> 00:31:26,379
have really huge clusters which are

00:31:24,639 --> 00:31:29,350
informed about the routes inside the

00:31:26,379 --> 00:31:31,929
network and the ordinary network have

00:31:29,350 --> 00:31:34,419
was an overlay network this was

00:31:31,929 --> 00:31:36,700
tunneling IP over IP without the

00:31:34,419 --> 00:31:38,590
encryption things like this is also

00:31:36,700 --> 00:31:41,049
going away and they connect to the

00:31:38,590 --> 00:31:43,559
physical fabric which mean you can

00:31:41,049 --> 00:31:45,860
integrate third party products from or

00:31:43,559 --> 00:31:48,890
software-defined network Venice

00:31:45,860 --> 00:31:51,970
and get the full performance of your 10

00:31:48,890 --> 00:31:55,600
or 40 or 100 gigabyte networks in

00:31:51,970 --> 00:31:57,590
kubernetes plots which is quite of

00:31:55,600 --> 00:32:00,500
interesting if you want to run high in

00:31:57,590 --> 00:32:04,000
network workloads in kubernetes yeah and

00:32:00,500 --> 00:32:08,929
also this I mean we separated our

00:32:04,000 --> 00:32:11,890
networks in kubernetes so our kubernetes

00:32:08,929 --> 00:32:17,690
infrastructure in our own data center

00:32:11,890 --> 00:32:20,659
have a different network for deploying

00:32:17,690 --> 00:32:23,570
and pulling applications containers and

00:32:20,659 --> 00:32:25,940
stuff like that and a different network

00:32:23,570 --> 00:32:28,100
for the internal cluster communication

00:32:25,940 --> 00:32:30,830
as well as a different network if you

00:32:28,100 --> 00:32:32,480
want to attach remote storage as well as

00:32:30,830 --> 00:32:34,130
we have a different network for the

00:32:32,480 --> 00:32:36,830
outside communication of the kubernetes

00:32:34,130 --> 00:32:40,220
cluster and if you count all this

00:32:36,830 --> 00:32:43,850
together and then think about that s ap

00:32:40,220 --> 00:32:47,240
is currently running more than 150,000

00:32:43,850 --> 00:32:50,929
servers in their own data centers plus

00:32:47,240 --> 00:32:55,639
the colocation data centers class you

00:32:50,929 --> 00:32:59,980
know one one one year so incoming we

00:32:55,639 --> 00:33:03,950
have like around I think at the moment

00:32:59,980 --> 00:33:10,120
300,000 servers where s AP is running on

00:33:03,950 --> 00:33:15,679
so this is nothing you can run what's

00:33:10,120 --> 00:33:18,470
244 of 254 nodes in a groove native

00:33:15,679 --> 00:33:20,510
customers then you have to build like

00:33:18,470 --> 00:33:23,870
thousands of kubernetes classes and this

00:33:20,510 --> 00:33:24,639
is just incredible so we will not do

00:33:23,870 --> 00:33:30,080
that

00:33:24,639 --> 00:33:33,309
and why why we use calico I mean there

00:33:30,080 --> 00:33:36,440
are others also running with VTP and

00:33:33,309 --> 00:33:42,110
offering this these solutions likewise

00:33:36,440 --> 00:33:44,750
to calico but basically we we know a lot

00:33:42,110 --> 00:33:47,659
of companies that use calico at scale

00:33:44,750 --> 00:33:49,909
and they are very experienced in that

00:33:47,659 --> 00:33:51,679
area so we are coming from the OpenStack

00:33:49,909 --> 00:33:53,299
community and have a lot of experience

00:33:51,679 --> 00:33:55,370
with certain they turn no into the

00:33:53,299 --> 00:33:55,760
kunais business as a lot of companies

00:33:55,370 --> 00:33:59,270
which

00:33:55,760 --> 00:34:03,500
experiences Olmstead yeah like neuron

00:33:59,270 --> 00:34:06,170
test yeah which was basically the number

00:34:03,500 --> 00:34:09,470
one contributed to OpenStack and they

00:34:06,170 --> 00:34:13,580
are today they basically decided I think

00:34:09,470 --> 00:34:15,740
one and a half years ago that's the

00:34:13,580 --> 00:34:20,120
future marking for them is no more open

00:34:15,740 --> 00:34:22,490
deck but it's kubernetes and I think

00:34:20,120 --> 00:34:24,919
officially it was said a couple of days

00:34:22,490 --> 00:34:28,520
ago that they are now moving more into

00:34:24,919 --> 00:34:31,159
kubernetes and putting down the

00:34:28,520 --> 00:34:34,370
OpenStack as that so I think they locked

00:34:31,159 --> 00:34:39,560
it in to court-martial product yeah now

00:34:34,370 --> 00:34:41,510
but we have to proceed ok so next is ok

00:34:39,560 --> 00:34:43,790
what really interesting is about

00:34:41,510 --> 00:34:45,710
database you have might have about this

00:34:43,790 --> 00:34:50,870
little white rabbit called cap theorem

00:34:45,710 --> 00:34:53,330
and on the other side you have the 12

00:34:50,870 --> 00:34:55,850
sector philosophy or how to run stated

00:34:53,330 --> 00:34:58,760
systems here you see the nice of the

00:34:55,850 --> 00:35:01,730
holy to a sector grail and everybody of

00:34:58,760 --> 00:35:05,660
you who knows the movie from multipliers

00:35:01,730 --> 00:35:10,100
and I think this little innocent rabbit

00:35:05,660 --> 00:35:13,190
is killing these Knights for breakfast

00:35:10,100 --> 00:35:16,150
so what we kind of need is this Holy

00:35:13,190 --> 00:35:20,690
Hand Grenade of Antioch here which is

00:35:16,150 --> 00:35:23,470
orchestrating our workload for for

00:35:20,690 --> 00:35:26,150
distributed databases we are not really

00:35:23,470 --> 00:35:29,060
we don't have a real solution up to know

00:35:26,150 --> 00:35:32,570
what we have ideas about this and so

00:35:29,060 --> 00:35:36,790
this is a real challenge but this reread

00:35:32,570 --> 00:35:38,840
databases have always been very

00:35:36,790 --> 00:35:40,880
complicated and challenging and this

00:35:38,840 --> 00:35:44,360
does not go away if you run it in

00:35:40,880 --> 00:35:46,700
communities now just a hat is at this

00:35:44,360 --> 00:35:49,820
point we already have a solution for a

00:35:46,700 --> 00:35:52,220
CD which is more or less a distributed

00:35:49,820 --> 00:35:55,640
database even though it's called a key

00:35:52,220 --> 00:35:57,020
value store but our kubernetes custer's

00:35:55,640 --> 00:36:00,210
internally

00:35:57,020 --> 00:36:03,570
the FCC store they are based on

00:36:00,210 --> 00:36:06,750
themselves so we don't maintain the head

00:36:03,570 --> 00:36:09,270
city cluster and we don't use something

00:36:06,750 --> 00:36:11,700
like that the operator from korra's to

00:36:09,270 --> 00:36:15,330
maintain our a city cluster we basically

00:36:11,700 --> 00:36:15,900
let kubernetes do the work yes next

00:36:15,330 --> 00:36:19,920
challenge

00:36:15,900 --> 00:36:22,790
so yeah machine learning I mean I don't

00:36:19,920 --> 00:36:26,010
know if you guys heard from dub Korea

00:36:22,790 --> 00:36:29,790
Sofia is the new machine learning

00:36:26,010 --> 00:36:34,080
product just presented at the last a

00:36:29,790 --> 00:36:36,480
fire which was in June or something at

00:36:34,080 --> 00:36:39,180
the beginning of June I think I don't

00:36:36,480 --> 00:36:42,330
remember the real date but sub clear

00:36:39,180 --> 00:36:45,660
from the architectural perspective is

00:36:42,330 --> 00:36:48,180
working with kubernetes so Sofia

00:36:45,660 --> 00:36:51,270
integrates kubernetes for machine

00:36:48,180 --> 00:36:54,140
learning proposals and we are continuing

00:36:51,270 --> 00:36:59,330
our work about the integration and

00:36:54,140 --> 00:37:04,410
pushing onto NVIDIA and also some others

00:36:59,330 --> 00:37:06,210
to integrate multi-tenancy in GPUs which

00:37:04,410 --> 00:37:08,550
is not possible at the moment because if

00:37:06,210 --> 00:37:11,010
you saw four graphics well but really I

00:37:08,550 --> 00:37:15,240
don't care they should make it possible

00:37:11,010 --> 00:37:17,310
I mean you know and we need it and not

00:37:15,240 --> 00:37:18,720
only we need it basically everyone that

00:37:17,310 --> 00:37:21,630
wants to do machine learning and

00:37:18,720 --> 00:37:24,360
artificial intelligence that GPUs will

00:37:21,630 --> 00:37:27,300
someday in time need it because you

00:37:24,360 --> 00:37:29,310
don't want to run a GPU every now and

00:37:27,300 --> 00:37:32,430
when you have a load you want to share

00:37:29,310 --> 00:37:36,540
the GPU and you want to run the stuff in

00:37:32,430 --> 00:37:41,910
parallel if possible so it means they

00:37:36,540 --> 00:37:45,750
just need to implement it okay so we are

00:37:41,910 --> 00:37:49,040
basically at the end of the presentation

00:37:45,750 --> 00:37:50,770
now are there any questions

00:37:49,040 --> 00:37:58,240
yep

00:37:50,770 --> 00:38:00,550
I think you get a microphone regarding

00:37:58,240 --> 00:38:03,480
to the network why don't you just go

00:38:00,550 --> 00:38:07,210
with plain Network managed outside of

00:38:03,480 --> 00:38:10,360
container network interface because of

00:38:07,210 --> 00:38:13,570
your in your scale that you describe it

00:38:10,360 --> 00:38:16,840
it might make sense I'm asking have you

00:38:13,570 --> 00:38:19,360
considered well basically we considered

00:38:16,840 --> 00:38:24,010
a lot of stuff and we thought about a

00:38:19,360 --> 00:38:26,770
lot of stuff but having a network

00:38:24,010 --> 00:38:31,920
outside of kubernetes means that network

00:38:26,770 --> 00:38:31,920
has to be maintained Pam

00:38:32,550 --> 00:38:37,600
well yes sure there's a network that

00:38:35,200 --> 00:38:40,240
exists around but this network is not

00:38:37,600 --> 00:38:41,980
maintaining the containers using the

00:38:40,240 --> 00:38:43,840
kubernetes cluster and you need to

00:38:41,980 --> 00:38:45,880
integrate the containers in the

00:38:43,840 --> 00:38:49,660
kubernetes cuttle which would each other

00:38:45,880 --> 00:38:51,790
and you need to be able to access the

00:38:49,660 --> 00:38:54,520
containers I allowed balancing in the

00:38:51,790 --> 00:38:56,590
kubernetes cluster from outside and you

00:38:54,520 --> 00:39:00,430
want that to be dynamic so seven

00:38:56,590 --> 00:39:03,070
effectively the kubernetes of death data

00:39:00,430 --> 00:39:06,940
center on steroids with moving around

00:39:03,070 --> 00:39:09,490
port and ending in a performance that no

00:39:06,940 --> 00:39:13,030
real hardware of our software hardware

00:39:09,490 --> 00:39:15,760
is able to handle this automatically so

00:39:13,030 --> 00:39:18,640
many manually adding these things is

00:39:15,760 --> 00:39:21,310
absolutely impossible and the speed of

00:39:18,640 --> 00:39:24,460
container spawning and being removed is

00:39:21,310 --> 00:39:27,010
so fast that you need kind of data

00:39:24,460 --> 00:39:29,740
center technology autumn eyes yeah the

00:39:27,010 --> 00:39:32,560
point is for example just just to

00:39:29,740 --> 00:39:35,050
overcome this for a moment you have a

00:39:32,560 --> 00:39:38,800
kubernetes cluster yeah your Coronado

00:39:35,050 --> 00:39:41,080
starter has 100 nodes yeah 100 physical

00:39:38,800 --> 00:39:44,260
nodes that have physical addresses in

00:39:41,080 --> 00:39:47,200
the network layer yeah but on those 100

00:39:44,260 --> 00:39:49,869
nodes you have an application of five

00:39:47,200 --> 00:39:53,770
containers those five containers are

00:39:49,869 --> 00:39:56,680
running on three nodes now if you come

00:39:53,770 --> 00:39:58,540
from outside you don't know where to

00:39:56,680 --> 00:40:01,839
find those pots because the information

00:39:58,540 --> 00:40:04,689
is in kubernetes it's not outside

00:40:01,839 --> 00:40:08,019
so what you can do is you can basically

00:40:04,689 --> 00:40:11,349
have load balancer outside to address

00:40:08,019 --> 00:40:14,769
the kubernetes cluster on one of the

00:40:11,349 --> 00:40:17,469
pots on one of the node when the queue

00:40:14,769 --> 00:40:19,359
proxy will then forward this request to

00:40:17,469 --> 00:40:22,239
the real node where the container is

00:40:19,359 --> 00:40:25,239
running and answer answering the request

00:40:22,239 --> 00:40:27,039
but you don't want that because what you

00:40:25,239 --> 00:40:28,689
want is you want to have a direct

00:40:27,039 --> 00:40:31,569
request to the node and the direct

00:40:28,689 --> 00:40:33,880
answer outside so what you want is a

00:40:31,569 --> 00:40:36,369
software-defined never orchestrated by

00:40:33,880 --> 00:40:39,699
kubernetes the only possibility

00:40:36,369 --> 00:40:42,549
otherwise you have is to have for

00:40:39,699 --> 00:40:45,119
example a pipe load balancer and have an

00:40:42,549 --> 00:40:48,219
ingress implementation in kubernetes to

00:40:45,119 --> 00:40:52,239
orchestrate a 5 load balancer but if you

00:40:48,219 --> 00:40:54,969
come to high changing and a really big

00:40:52,239 --> 00:40:57,670
kubernetes cluster the f5 load balancer

00:40:54,969 --> 00:41:00,219
will just stop working or basically

00:40:57,670 --> 00:41:02,529
implement the rules probably a minute

00:41:00,219 --> 00:41:05,469
after it changed and your service is

00:41:02,529 --> 00:41:06,849
down a minute and then something you

00:41:05,469 --> 00:41:08,859
don't want to have I think you can

00:41:06,849 --> 00:41:11,019
discover the more details yeah I think I

00:41:08,859 --> 00:41:12,429
think you should and it is great

00:41:11,019 --> 00:41:13,719
opportunity for you to scattered India

00:41:12,429 --> 00:41:15,459
because you have half an hour a coffee

00:41:13,719 --> 00:41:18,429
break right now so if you can take all

00:41:15,459 --> 00:41:22,019
the cases into the coffee break Thank

00:41:18,429 --> 00:41:22,019
You Thomas thank you Stefan

00:41:23,390 --> 00:41:25,450

YouTube URL: https://www.youtube.com/watch?v=spuuoZLxJfs


