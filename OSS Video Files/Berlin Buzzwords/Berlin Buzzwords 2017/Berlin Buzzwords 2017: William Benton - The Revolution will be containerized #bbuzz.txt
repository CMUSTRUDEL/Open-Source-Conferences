Title: Berlin Buzzwords 2017: William Benton - The Revolution will be containerized #bbuzz
Publication date: 2017-06-15
Playlist: Berlin Buzzwords 2017
Description: 
	William Benton talking about "The Revolution Will Be Containerized: Architecting the Insightful Applications of Tomorrow".

The Revolution will be containerized: Architecting the insightful applicaions of Tomorrow
Linux containers are increasingly popular with application developers: they offer improved elasticity, fault-tolerance, and portability between different public and private clouds, along with an unbeatable development workflow.

It’s hard to imagine a technology that has had more impact on application developers in the last decade than containers, with the possible exception of ubiquitous analytics. Indeed, analytics is no longer a separate workload that occasionally generates reports on things that happened yesterday; instead, it pulses beneath the rhythms of contemporary business and supports today’s most interesting and vital applications. Since applications depend on analytic capabilities, it makes good sense to deploy our data-processing frameworks alongside our applications.

In this talk, you’ll learn from our expertise deploying Apache Spark and other data-processing frameworks in Linux containers on Kubernetes. We’ll explain what containers are and why you should care about them. We'll cover the benefits of containerizing applications, architectures for analytic applications that make sense in containers, and how to handle external data sources.

You’ll also get practical advice on how to ensure security and isolation, how to achieve high performance, and how to sidestep and negotiate potential challenges. Throughout the talk, we’ll refer back to concrete lessons we’ve learned about containerized analytic jobs ranging from interactive notebooks to production applications. You’ll leave inspired and enabled to deploy high-performance analytic applications without giving up the security you need or the developer-friendly workflow you want.

Read more:
https://2017.berlinbuzzwords.de/17/session/revolution-will-be-containerized-architecting-insightful-applications-tomorrow

About William Benton:
https://2017.berlinbuzzwords.de/users/william-benton

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,960 --> 00:00:10,049
thank you so much for joining me for

00:00:07,950 --> 00:00:11,190
this last session it's an honor to be

00:00:10,049 --> 00:00:12,570
here and I'm really grateful for your

00:00:11,190 --> 00:00:14,850
time and attention especially at this

00:00:12,570 --> 00:00:16,590
point in the week my name is Wil Benton

00:00:14,850 --> 00:00:18,900
and I'm a software engineer at Red Hat I

00:00:16,590 --> 00:00:20,910
work on a team that works at the

00:00:18,900 --> 00:00:22,320
intersection of distributed systems data

00:00:20,910 --> 00:00:24,090
science and software engineering and

00:00:22,320 --> 00:00:26,520
today I'm going to tell you why we're

00:00:24,090 --> 00:00:28,619
become really excited about containers

00:00:26,520 --> 00:00:30,420
and container orchestration for

00:00:28,619 --> 00:00:31,980
intelligent applications and by

00:00:30,420 --> 00:00:33,390
intelligent applications I just mean

00:00:31,980 --> 00:00:35,760
applications that have a significant

00:00:33,390 --> 00:00:40,649
analytics component but first I'm going

00:00:35,760 --> 00:00:42,030
to start with some history I bet you

00:00:40,649 --> 00:00:42,570
didn't think I'd go back to the second

00:00:42,030 --> 00:00:45,120
century

00:00:42,570 --> 00:00:46,739
this is ptolemy of alexandria he

00:00:45,120 --> 00:00:49,590
proposed a geocentric model of the

00:00:46,739 --> 00:00:52,559
cosmos imagine the entire universe as a

00:00:49,590 --> 00:00:54,870
set of concentric spheres and calculated

00:00:52,559 --> 00:00:56,489
the sizes of each and the distances to

00:00:54,870 --> 00:00:59,280
each of the heavenly bodies and the

00:00:56,489 --> 00:01:01,440
positions of things now now we know that

00:00:59,280 --> 00:01:04,350
this is wrong but the surprising part

00:01:01,440 --> 00:01:06,299
about Tollan Ptolemaic astronomy is that

00:01:04,350 --> 00:01:07,560
it was actually pretty useful if you

00:01:06,299 --> 00:01:09,090
were willing to put up with a super

00:01:07,560 --> 00:01:11,190
complicated model and make an adjustment

00:01:09,090 --> 00:01:12,270
of a few percent every couple years the

00:01:11,190 --> 00:01:14,310
things didn't get too out of whack you

00:01:12,270 --> 00:01:18,180
could you could use it for agriculture

00:01:14,310 --> 00:01:20,369
and navigation and so on and this is

00:01:18,180 --> 00:01:22,500
what people used until the 16th century

00:01:20,369 --> 00:01:24,270
when Copernicus said well no actually

00:01:22,500 --> 00:01:27,060
the Sun is at the center of the universe

00:01:24,270 --> 00:01:28,470
and this model had several benefits it

00:01:27,060 --> 00:01:30,900
was simpler it required fewer

00:01:28,470 --> 00:01:32,790
adjustments it explained more things and

00:01:30,900 --> 00:01:34,470
it was substantially closer to the truth

00:01:32,790 --> 00:01:38,430
although it's still not not perfect

00:01:34,470 --> 00:01:40,380
right so the interesting thing about

00:01:38,430 --> 00:01:42,270
this is that we like to see human

00:01:40,380 --> 00:01:44,159
progress or the progress of science as

00:01:42,270 --> 00:01:45,869
sort of a cumulative thing right we're

00:01:44,159 --> 00:01:48,299
we're building on everyone's

00:01:45,869 --> 00:01:49,890
accomplishments before us we're standing

00:01:48,299 --> 00:01:52,680
on the shoulders of increasingly large

00:01:49,890 --> 00:01:55,170
giants but 20th century philosopher of

00:01:52,680 --> 00:01:57,030
science Thomas Kuhn actually challenged

00:01:55,170 --> 00:01:59,520
this idea by introducing the concept of

00:01:57,030 --> 00:02:02,009
a scientific revolution and a paradigm

00:01:59,520 --> 00:02:04,560
shift when we go from Ptolemy to

00:02:02,009 --> 00:02:06,299
Copernicus we have to throw away a lot

00:02:04,560 --> 00:02:07,890
of the work we did to make sense of the

00:02:06,299 --> 00:02:09,239
cosmos and to make sense of what we done

00:02:07,890 --> 00:02:11,340
like all that work you did to make

00:02:09,239 --> 00:02:13,439
adjustments to the the geocentric model

00:02:11,340 --> 00:02:15,540
is useless once you have a heliocentric

00:02:13,439 --> 00:02:17,400
model so really human progress looks a

00:02:15,540 --> 00:02:18,430
lot more like this you do some things

00:02:17,400 --> 00:02:20,530
you make some

00:02:18,430 --> 00:02:21,970
and you have to throw that paradigm away

00:02:20,530 --> 00:02:24,040
and the cop with a new one

00:02:21,970 --> 00:02:25,209
so Coons book on this topic is called

00:02:24,040 --> 00:02:26,769
the structure of scientific revolutions

00:02:25,209 --> 00:02:28,480
and it's worth reading if you're

00:02:26,769 --> 00:02:30,790
interested in philosophy of science or

00:02:28,480 --> 00:02:32,860
the history of ideas well what does this

00:02:30,790 --> 00:02:34,599
have to do with analytics well for a

00:02:32,860 --> 00:02:37,390
long time we've been operating under a

00:02:34,599 --> 00:02:40,030
cluster centric model where you have a

00:02:37,390 --> 00:02:41,799
compute cluster and you know analytics

00:02:40,030 --> 00:02:43,390
is something you run on your computer as

00:02:41,799 --> 00:02:46,450
a separate workload maybe you devote

00:02:43,390 --> 00:02:48,159
that to generating reports maybe

00:02:46,450 --> 00:02:50,560
occasionally you do some batch model

00:02:48,159 --> 00:02:52,690
training but the demands on this are not

00:02:50,560 --> 00:02:55,329
that great now like the Ptolemaic model

00:02:52,690 --> 00:02:56,560
this paradigm works adequately as long

00:02:55,329 --> 00:02:58,900
as we don't push it too hard but

00:02:56,560 --> 00:03:01,599
increasingly people are pushing it they

00:02:58,900 --> 00:03:05,829
want to run applications in this model

00:03:01,599 --> 00:03:07,599
as well they want to run interactive

00:03:05,829 --> 00:03:09,189
queries and notebooks they want to run

00:03:07,599 --> 00:03:10,930
stream processing and people have done a

00:03:09,189 --> 00:03:13,090
lot of really clever things to extend

00:03:10,930 --> 00:03:14,409
this model and make it work here but I

00:03:13,090 --> 00:03:16,359
think we're seeing a paradigm shift

00:03:14,409 --> 00:03:17,680
where analytics isn't just a separate

00:03:16,359 --> 00:03:20,170
workload that we run on a separate

00:03:17,680 --> 00:03:21,700
analytics cluster analytics is really

00:03:20,170 --> 00:03:23,440
something that underlies a lot of

00:03:21,700 --> 00:03:25,419
interesting applications right if you

00:03:23,440 --> 00:03:27,639
think about the applications you use the

00:03:25,419 --> 00:03:29,680
most the ones that demand your attention

00:03:27,639 --> 00:03:30,730
the ones that demand your money the ones

00:03:29,680 --> 00:03:32,609
that are on the home screen of your

00:03:30,730 --> 00:03:34,900
phone those things probably all have

00:03:32,609 --> 00:03:37,180
significant analytics components so we

00:03:34,900 --> 00:03:38,590
really want to see a model where instead

00:03:37,180 --> 00:03:40,750
of thinking about what can we run on our

00:03:38,590 --> 00:03:43,180
computer we want to think about what do

00:03:40,750 --> 00:03:45,489
our apps require we want to go from a

00:03:43,180 --> 00:03:51,400
cluster centric model to an app centric

00:03:45,489 --> 00:03:53,199
model cluster centric model no longer

00:03:51,400 --> 00:03:56,470
makes sense if analytics is no longer

00:03:53,199 --> 00:03:57,760
something we just run on the side so in

00:03:56,470 --> 00:04:00,549
the rest of this talk I'm going to

00:03:57,760 --> 00:04:02,560
introduce containers Linux containers

00:04:00,549 --> 00:04:04,030
and explain why you might want to care

00:04:02,560 --> 00:04:06,400
about them for developing and deploying

00:04:04,030 --> 00:04:08,519
your applications I'll present some

00:04:06,400 --> 00:04:10,690
architectures for running intelligent

00:04:08,519 --> 00:04:12,669
applications in containers and I'll do a

00:04:10,690 --> 00:04:15,310
little bit of history on analytic

00:04:12,669 --> 00:04:16,750
architectures from the past we'll talk

00:04:15,310 --> 00:04:18,070
about some practical things that you

00:04:16,750 --> 00:04:20,620
have to worry about to make sure that

00:04:18,070 --> 00:04:23,620
your containers run correctly and are

00:04:20,620 --> 00:04:26,800
safe and have high performance and I'll

00:04:23,620 --> 00:04:28,659
show you where you can go from here so

00:04:26,800 --> 00:04:31,690
to start off how many people in here

00:04:28,659 --> 00:04:33,680
have used Linux containers before

00:04:31,690 --> 00:04:36,620
okay how many of you have a Linux

00:04:33,680 --> 00:04:40,280
container in production somewhere great

00:04:36,620 --> 00:04:42,680
so a lot of people have an idea of what

00:04:40,280 --> 00:04:44,630
a container is but if you ask people to

00:04:42,680 --> 00:04:46,790
define containers you often get sort of

00:04:44,630 --> 00:04:48,980
a fuzzy I know if it I see I know it if

00:04:46,790 --> 00:04:50,690
I see it kind of answer because we

00:04:48,980 --> 00:04:53,360
really associate containers with a

00:04:50,690 --> 00:04:55,040
constellation of capabilities rather

00:04:53,360 --> 00:04:56,300
than with a sort of technical

00:04:55,040 --> 00:04:57,800
implementation so you'll get answers

00:04:56,300 --> 00:05:00,230
like Oh a container is really like a

00:04:57,800 --> 00:05:02,270
lightweight virtual machine or it's a

00:05:00,230 --> 00:05:03,920
way that I can isolate my applications

00:05:02,270 --> 00:05:06,080
from one another and they're not going

00:05:03,920 --> 00:05:07,310
to interfere with one another and some

00:05:06,080 --> 00:05:08,990
of them just say well this is this is a

00:05:07,310 --> 00:05:10,550
packaging format this is this is like a

00:05:08,990 --> 00:05:14,690
docker image right this is something I

00:05:10,550 --> 00:05:16,670
run in kubernetes and all of these

00:05:14,690 --> 00:05:19,100
things have some truth to them but

00:05:16,670 --> 00:05:20,810
they're all wrong in subtle ways right

00:05:19,100 --> 00:05:21,890
so to figure out why these things are

00:05:20,810 --> 00:05:24,350
wrong let's look what a container

00:05:21,890 --> 00:05:26,810
actually is and we'll start by looking

00:05:24,350 --> 00:05:28,490
at the humble Linux process when you

00:05:26,810 --> 00:05:31,100
have an ordinary process on a Linux

00:05:28,490 --> 00:05:32,900
system you have an environment you have

00:05:31,100 --> 00:05:34,610
an executable and you have pointers to

00:05:32,900 --> 00:05:36,530
some kernel resources now some of these

00:05:34,610 --> 00:05:38,450
kernel resources are namespace

00:05:36,530 --> 00:05:42,160
like your process table your root

00:05:38,450 --> 00:05:44,540
filesystem and your network route if

00:05:42,160 --> 00:05:46,220
you're running in a container that just

00:05:44,540 --> 00:05:48,919
means that the kernel can change these

00:05:46,220 --> 00:05:50,450
namespaces to control what you see so

00:05:48,919 --> 00:05:52,790
instead of seeing the same process table

00:05:50,450 --> 00:05:54,650
as everyone else on the same host you

00:05:52,790 --> 00:05:57,110
might see a different process table

00:05:54,650 --> 00:05:59,000
maybe it only includes you instead of

00:05:57,110 --> 00:06:02,000
seeing the same root filesystem

00:05:59,000 --> 00:06:03,680
as the init process on your host you

00:06:02,000 --> 00:06:05,780
might be running in a subdirectory of

00:06:03,680 --> 00:06:07,790
that root filesystem and your network

00:06:05,780 --> 00:06:09,080
routes you may have some new routes you

00:06:07,790 --> 00:06:11,120
may not have all the routes that other

00:06:09,080 --> 00:06:15,500
processes have we may builder out

00:06:11,120 --> 00:06:17,840
services directly to this container but

00:06:15,500 --> 00:06:19,190
other processes on the system can see

00:06:17,840 --> 00:06:21,729
this process that's running in the

00:06:19,190 --> 00:06:24,380
container they know that it's there and

00:06:21,729 --> 00:06:25,700
sometimes this process itself can tell

00:06:24,380 --> 00:06:27,770
that it's running on a container on

00:06:25,700 --> 00:06:29,540
another system so a container runtime

00:06:27,770 --> 00:06:31,190
just provides a convenient way to wrap

00:06:29,540 --> 00:06:32,960
all this stuff up together and package

00:06:31,190 --> 00:06:35,780
up a base file system image so you can

00:06:32,960 --> 00:06:37,729
use it by contrast and you can also

00:06:35,780 --> 00:06:39,009
impose some resource limits on on

00:06:37,729 --> 00:06:42,879
containers

00:06:39,009 --> 00:06:46,509
by I'm sorry that's in miles per hour by

00:06:42,879 --> 00:06:48,729
contrast virtual machine hypervisor

00:06:46,509 --> 00:06:51,189
runs an actual operating system kernel

00:06:48,729 --> 00:06:53,740
as a process and if you're running in a

00:06:51,189 --> 00:06:54,999
virtual machine you can't tell that you

00:06:53,740 --> 00:06:57,039
don't have a whole machine to yourself

00:06:54,999 --> 00:06:59,680
unless there's a serious bug in the

00:06:57,039 --> 00:07:01,419
hypervisor and other processes running

00:06:59,680 --> 00:07:03,009
on the same host your virtual machine is

00:07:01,419 --> 00:07:04,569
running on they just see that you have a

00:07:03,009 --> 00:07:06,460
virtual machine hypervisor running they

00:07:04,569 --> 00:07:08,379
can't look inside and see what processes

00:07:06,460 --> 00:07:11,219
you're running in that virtualized

00:07:08,379 --> 00:07:13,599
operating system so a container

00:07:11,219 --> 00:07:15,879
addresses some of the same use cases as

00:07:13,599 --> 00:07:17,379
VMs but it's not a lightweight VM right

00:07:15,879 --> 00:07:19,289
if it's a completely different thing and

00:07:17,379 --> 00:07:21,729
it has some different trade-offs

00:07:19,289 --> 00:07:24,699
similarly because not every resource

00:07:21,729 --> 00:07:26,830
that you can access from a Linux process

00:07:24,699 --> 00:07:30,669
is namespace the container is not a way

00:07:26,830 --> 00:07:33,819
to totally isolate a provide reasonable

00:07:30,669 --> 00:07:35,949
isolation at very low cost and a

00:07:33,819 --> 00:07:39,159
container is not just something you run

00:07:35,949 --> 00:07:41,800
in docker or kubernetes or a system that

00:07:39,159 --> 00:07:43,209
that orchestrates containers on you're

00:07:41,800 --> 00:07:44,709
really running in a container all the

00:07:43,209 --> 00:07:46,839
time you just might be running in a

00:07:44,709 --> 00:07:48,580
trivial one right because you're still

00:07:46,839 --> 00:07:50,080
running a process with namespaces you

00:07:48,580 --> 00:07:53,319
just might have the same namespaces as

00:07:50,080 --> 00:07:55,889
everyone else so when we talk about

00:07:53,319 --> 00:07:58,779
building applications out of containers

00:07:55,889 --> 00:08:01,089
usually people talk about combining them

00:07:58,779 --> 00:08:03,189
together in micro service architectures

00:08:01,089 --> 00:08:05,050
and a micro service architecture is

00:08:03,189 --> 00:08:09,399
basically where you just have some

00:08:05,050 --> 00:08:12,759
lightweight modular and generally

00:08:09,399 --> 00:08:15,279
stateless processes that have

00:08:12,759 --> 00:08:19,269
well-defined interfaces and contracts

00:08:15,279 --> 00:08:21,490
and can work well together and this is

00:08:19,269 --> 00:08:25,139
what we would deploy on a container

00:08:21,490 --> 00:08:26,769
platform like kubernetes now

00:08:25,139 --> 00:08:29,349
service-oriented architectures are

00:08:26,769 --> 00:08:31,300
nothing new and micro services are not

00:08:29,349 --> 00:08:33,579
free of trade-offs but the trade-offs

00:08:31,300 --> 00:08:35,019
they have are actually pretty good for

00:08:33,579 --> 00:08:37,539
the kinds of applications we want to do

00:08:35,019 --> 00:08:39,550
and we can see what some of the

00:08:37,539 --> 00:08:42,789
advantages are for operators and

00:08:39,550 --> 00:08:44,829
developers for operators micro services

00:08:42,789 --> 00:08:46,720
are really easy to scale up if you have

00:08:44,829 --> 00:08:49,120
a large single machine you can run as

00:08:46,720 --> 00:08:51,790
many micro services on it as the machine

00:08:49,120 --> 00:08:52,790
can stand if you're large single machine

00:08:51,790 --> 00:08:55,010
is no longer

00:08:52,790 --> 00:08:57,020
to run your application you can scale

00:08:55,010 --> 00:08:58,670
out by moving these services to

00:08:57,020 --> 00:08:59,750
different machines since they

00:08:58,670 --> 00:09:01,160
communicate through well-defined

00:08:59,750 --> 00:09:02,900
interfaces they don't have to be

00:09:01,160 --> 00:09:04,910
co-located on the same physical hardware

00:09:02,900 --> 00:09:07,700
in fact if these are stateless

00:09:04,910 --> 00:09:09,110
components and any one of them can you

00:09:07,700 --> 00:09:10,640
can replace the one to do the job then

00:09:09,110 --> 00:09:12,800
you get these other nice benefits like

00:09:10,640 --> 00:09:14,420
you can run a bunch of copies of one of

00:09:12,800 --> 00:09:17,240
these services behind a load balancing

00:09:14,420 --> 00:09:21,650
proxy or if one of them crashes and goes

00:09:17,240 --> 00:09:23,150
away you can replace it trivially micro

00:09:21,650 --> 00:09:26,240
services have great trade-offs for

00:09:23,150 --> 00:09:28,190
developers as well because stateless

00:09:26,240 --> 00:09:30,260
services are easier to test in debug

00:09:28,190 --> 00:09:32,420
than stateful services how many times

00:09:30,260 --> 00:09:34,970
have you like tried to reproduce some

00:09:32,420 --> 00:09:36,980
sequence of events to reproduce a bug in

00:09:34,970 --> 00:09:39,050
a complicated system it's pretty tough

00:09:36,980 --> 00:09:41,360
but with micro services you're almost

00:09:39,050 --> 00:09:42,530
dealing with a bit so this is a bit of a

00:09:41,360 --> 00:09:44,360
stretch but you're almost dealing with

00:09:42,530 --> 00:09:46,670
pure functions right you just sort of

00:09:44,360 --> 00:09:51,320
need to say I have an API I have a

00:09:46,670 --> 00:09:53,420
contract and does what I get satisfy

00:09:51,320 --> 00:09:55,340
that contract or not and if it doesn't

00:09:53,420 --> 00:09:58,760
you know you have a bug and you know

00:09:55,340 --> 00:10:00,320
where to look for the bug another really

00:09:58,760 --> 00:10:02,720
huge advantage of micro services for

00:10:00,320 --> 00:10:05,330
developers is that you have a

00:10:02,720 --> 00:10:07,580
possibility to develop a great workflow

00:10:05,330 --> 00:10:09,710
and we saw this in gal there's talk in

00:10:07,580 --> 00:10:12,980
the last session where you can have

00:10:09,710 --> 00:10:16,550
tooling that checks for a new commit in

00:10:12,980 --> 00:10:18,260
a git repository and when when it sees a

00:10:16,550 --> 00:10:19,970
new commit it fires off continuous

00:10:18,260 --> 00:10:22,760
integration if continuous integration

00:10:19,970 --> 00:10:24,710
succeeds it builds a new image with your

00:10:22,760 --> 00:10:26,630
changed code and it pushes it into

00:10:24,710 --> 00:10:28,520
production seamlessly without you having

00:10:26,630 --> 00:10:31,670
to do anything about it you just commit

00:10:28,520 --> 00:10:34,330
if it works maybe you sign off on it but

00:10:31,670 --> 00:10:36,440
you automatically get that upgrade and

00:10:34,330 --> 00:10:38,510
since continuous integration and

00:10:36,440 --> 00:10:39,350
continuous deployment it's if you really

00:10:38,510 --> 00:10:41,510
think about it it's just a way to

00:10:39,350 --> 00:10:43,700
orchestrate an experiment right so this

00:10:41,510 --> 00:10:46,370
is not just good for developers it's

00:10:43,700 --> 00:10:47,870
also good for data scientists how many

00:10:46,370 --> 00:10:50,330
of you have gotten a notebook from a

00:10:47,870 --> 00:10:51,770
colleague that you couldn't run on your

00:10:50,330 --> 00:10:54,800
machine and get the same results

00:10:51,770 --> 00:10:55,730
anyone know books are for reproducible

00:10:54,800 --> 00:10:58,340
research but they're not always

00:10:55,730 --> 00:10:59,720
reproducible but if you have a container

00:10:58,340 --> 00:11:01,550
workflow like this where you have the

00:10:59,720 --> 00:11:05,060
entire environment that you run it in

00:11:01,550 --> 00:11:06,170
packaged up in a neat way and then you

00:11:05,060 --> 00:11:08,029
have continuous integration

00:11:06,170 --> 00:11:12,019
you can get these better guarantees and

00:11:08,029 --> 00:11:13,690
really get more reproducible results so

00:11:12,019 --> 00:11:16,100
another term that we talked about with

00:11:13,690 --> 00:11:17,839
containerized applications is this idea

00:11:16,100 --> 00:11:20,750
of cloud native applications in the

00:11:17,839 --> 00:11:23,810
cloud native computing foundation is an

00:11:20,750 --> 00:11:25,370
organization that's designed to sort of

00:11:23,810 --> 00:11:27,050
help people design these kinds of

00:11:25,370 --> 00:11:28,399
applications and advocate for them and

00:11:27,050 --> 00:11:30,139
their definition is that we have

00:11:28,399 --> 00:11:32,660
applications that are containerized

00:11:30,139 --> 00:11:34,370
which we've covered that are micro

00:11:32,660 --> 00:11:36,589
service-oriented which we've covered and

00:11:34,370 --> 00:11:38,149
that are dynamically orchestrated which

00:11:36,589 --> 00:11:40,670
basically just means that they can scale

00:11:38,149 --> 00:11:42,050
themselves out elastically now the

00:11:40,670 --> 00:11:44,060
interesting thing about these

00:11:42,050 --> 00:11:46,070
definitions is that if we think about

00:11:44,060 --> 00:11:48,579
contemporary analytics frameworks like

00:11:46,070 --> 00:11:51,019
Apache spark and Apache flink

00:11:48,579 --> 00:11:53,529
they scale out elastically right these

00:11:51,019 --> 00:11:56,000
things are dynamically orchestrated and

00:11:53,529 --> 00:11:57,649
the thing that might be less obvious is

00:11:56,000 --> 00:11:59,149
that these things are also micro

00:11:57,649 --> 00:12:01,220
service-oriented but I'll show how that

00:11:59,149 --> 00:12:03,440
works on the next slide but I think it's

00:12:01,220 --> 00:12:05,089
fair to say that if we have two out of

00:12:03,440 --> 00:12:06,940
three of these the contemporary

00:12:05,089 --> 00:12:09,260
analytics frameworks we want to use

00:12:06,940 --> 00:12:10,550
might not be cloud native but they're at

00:12:09,260 --> 00:12:13,430
least cloud naturalised

00:12:10,550 --> 00:12:16,040
right so let's see how micro services

00:12:13,430 --> 00:12:17,990
fit into something like spark if we

00:12:16,040 --> 00:12:19,279
think about how spark works we have a

00:12:17,990 --> 00:12:22,459
model where we have a distributed

00:12:19,279 --> 00:12:24,920
collection that's in chunks of memory on

00:12:22,459 --> 00:12:28,940
various executor processes and we have a

00:12:24,920 --> 00:12:30,740
master which distributes tasks to each

00:12:28,940 --> 00:12:33,140
of these executor x' which then

00:12:30,740 --> 00:12:35,420
calculate the results so these executor

00:12:33,140 --> 00:12:37,579
czar essentially microservices to

00:12:35,420 --> 00:12:40,519
calculate the values of partitions and

00:12:37,579 --> 00:12:42,290
in fact with spark these things are

00:12:40,519 --> 00:12:44,180
essentially stateless if we ignore cache

00:12:42,290 --> 00:12:48,860
which which we can do because it's an

00:12:44,180 --> 00:12:53,269
optimization right I'm sorry it's late

00:12:48,860 --> 00:12:54,860
in the day but but if we if we if one of

00:12:53,269 --> 00:12:57,019
these goes away we have the lineage

00:12:54,860 --> 00:12:58,880
graph for the RDD or the data frame and

00:12:57,019 --> 00:13:00,800
we know how to reconstruct it so these

00:12:58,880 --> 00:13:03,980
things are essentially microservices

00:13:00,800 --> 00:13:05,209
to calculate the values of partitions ok

00:13:03,980 --> 00:13:07,190
so that was a sort of whirlwind

00:13:05,209 --> 00:13:09,019
introduction to containers micro

00:13:07,190 --> 00:13:11,660
services and cloud native applications I

00:13:09,019 --> 00:13:13,490
want to talk now about architectures for

00:13:11,660 --> 00:13:15,079
applications but I'm going to start by

00:13:13,490 --> 00:13:16,830
contrasting them with architectures

00:13:15,079 --> 00:13:19,540
people have used in the past

00:13:16,830 --> 00:13:21,280
let's look at the classic transaction

00:13:19,540 --> 00:13:24,430
processing database and analytic

00:13:21,280 --> 00:13:26,890
processing database to start with in

00:13:24,430 --> 00:13:29,320
this setup we have events that we're

00:13:26,890 --> 00:13:31,030
going to transform and we have events

00:13:29,320 --> 00:13:32,170
that come directly from users we're

00:13:31,030 --> 00:13:34,000
going to federate these with some

00:13:32,170 --> 00:13:36,220
business logic do some other

00:13:34,000 --> 00:13:39,910
transformations and put them into a

00:13:36,220 --> 00:13:44,560
database that's optimized for concurrent

00:13:39,910 --> 00:13:46,480
rights and and fast commits now this

00:13:44,560 --> 00:13:48,010
database is not going to be suitable for

00:13:46,480 --> 00:13:49,330
analytic processing it's probably not

00:13:48,010 --> 00:13:51,520
even going to be suitable for sort of

00:13:49,330 --> 00:13:52,930
simple aggregates and it's the thing

00:13:51,520 --> 00:13:54,340
that our business is running on so we're

00:13:52,930 --> 00:13:55,570
not going to put analytic processing on

00:13:54,340 --> 00:13:57,520
it anyway right we don't want to put

00:13:55,570 --> 00:13:59,530
anything on the critical path so we're

00:13:57,520 --> 00:14:01,870
periodically going to mirror the data

00:13:59,530 --> 00:14:03,370
from this database to a different

00:14:01,870 --> 00:14:05,460
database that's optimized for a

00:14:03,370 --> 00:14:08,020
different use case that's optimized for

00:14:05,460 --> 00:14:10,420
reads that's optimized for complicated

00:14:08,020 --> 00:14:13,120
queries and we'll use that to support

00:14:10,420 --> 00:14:14,680
analysis which is you know often in this

00:14:13,120 --> 00:14:16,000
kind of architecture we're talking about

00:14:14,680 --> 00:14:17,650
reporting we're talking about taking

00:14:16,000 --> 00:14:20,280
multi-dimensional data and putting it on

00:14:17,650 --> 00:14:23,020
a spreadsheet but maybe we're also

00:14:20,280 --> 00:14:25,120
training something and sending that back

00:14:23,020 --> 00:14:28,120
to our application to use in how it

00:14:25,120 --> 00:14:30,190
transforms the raw data we see and

00:14:28,120 --> 00:14:33,640
finally we can support interactive

00:14:30,190 --> 00:14:35,890
queries by analysts as well so this is a

00:14:33,640 --> 00:14:37,600
set up that you know we've all seen this

00:14:35,890 --> 00:14:39,339
in the wild right people have people

00:14:37,600 --> 00:14:41,650
have done this for a long time it works

00:14:39,339 --> 00:14:43,990
pretty well databases are great you have

00:14:41,650 --> 00:14:47,530
joins you have a lot of really useful

00:14:43,990 --> 00:14:50,170
functionality and databases but what you

00:14:47,530 --> 00:14:51,730
don't have is you don't really have a

00:14:50,170 --> 00:14:54,010
great way to scale out the transaction

00:14:51,730 --> 00:14:55,480
processing part or historically you

00:14:54,010 --> 00:14:57,160
haven't I mean people are people are

00:14:55,480 --> 00:14:59,890
working on this right this is this is an

00:14:57,160 --> 00:15:01,600
interesting active problem so you can't

00:14:59,890 --> 00:15:04,000
get come on to descale out with this and

00:15:01,600 --> 00:15:05,680
the analytic processing you have sequel

00:15:04,000 --> 00:15:07,540
and you have stored procedures but if

00:15:05,680 --> 00:15:09,520
you want to do anything sort of with

00:15:07,540 --> 00:15:11,500
training a machine learning model it's a

00:15:09,520 --> 00:15:14,230
little more painful to do in a database

00:15:11,500 --> 00:15:17,350
right so this is not perfect for the

00:15:14,230 --> 00:15:20,589
kinds of apps we want to write and it

00:15:17,350 --> 00:15:22,350
has some limitations the the sort of

00:15:20,589 --> 00:15:25,360
Hadoop style data Lake architecture

00:15:22,350 --> 00:15:28,660
addresses those limitations by saying

00:15:25,360 --> 00:15:30,579
well we have a lot of commodity hardware

00:15:28,660 --> 00:15:32,619
and we can provide scale out storage

00:15:30,579 --> 00:15:34,480
that hardware and oh yeah one of the

00:15:32,619 --> 00:15:36,129
problems with this transaction

00:15:34,480 --> 00:15:38,110
processing databases we don't have the

00:15:36,129 --> 00:15:40,179
raw data around so if we realize we made

00:15:38,110 --> 00:15:42,369
a mistake with transforming it we have

00:15:40,179 --> 00:15:44,860
no way to recover what we did unless we

00:15:42,369 --> 00:15:46,089
keep a keep a log somewhere so with it

00:15:44,860 --> 00:15:48,009
we're just going to just going to

00:15:46,089 --> 00:15:50,619
archive all the raw data to our

00:15:48,009 --> 00:15:52,149
distributed file system and we get scale

00:15:50,619 --> 00:15:54,579
out storage and then we'll write our

00:15:52,149 --> 00:15:57,549
compute jobs so that these compute jobs

00:15:54,579 --> 00:15:59,470
migrate to where the data are so if I'm

00:15:57,549 --> 00:16:01,540
operating on some some part of the data

00:15:59,470 --> 00:16:03,100
I'll have a job that runs on it and

00:16:01,540 --> 00:16:04,600
these these jobs can communicate and

00:16:03,100 --> 00:16:06,730
shuffle around and write the results

00:16:04,600 --> 00:16:09,040
back to the distributed file system so

00:16:06,730 --> 00:16:10,959
this is a great way to get scale out

00:16:09,040 --> 00:16:13,540
storage and scale up compute on

00:16:10,959 --> 00:16:15,939
commodity hardware and it's that's been

00:16:13,540 --> 00:16:18,639
it's been a pretty exciting idea for you

00:16:15,939 --> 00:16:20,290
know over ten years now the problem that

00:16:18,639 --> 00:16:23,559
both of these architectures have though

00:16:20,290 --> 00:16:25,449
is that they're both great ways to sort

00:16:23,559 --> 00:16:27,339
of do analytics as a workload but

00:16:25,449 --> 00:16:29,529
they're not necessarily awesome places

00:16:27,339 --> 00:16:31,629
for applications because there's not

00:16:29,529 --> 00:16:34,119
really a natural place for all the kinds

00:16:31,629 --> 00:16:35,889
of applications we want to run in the

00:16:34,119 --> 00:16:37,989
first case with the with the databases

00:16:35,889 --> 00:16:40,029
you don't you have to manage and

00:16:37,989 --> 00:16:41,649
schedule applications outside of the

00:16:40,029 --> 00:16:42,879
database right and you have to do it in

00:16:41,649 --> 00:16:44,290
such a way that's sensitive to other

00:16:42,879 --> 00:16:46,029
demands on your database your

00:16:44,290 --> 00:16:48,579
transaction processing database can't go

00:16:46,029 --> 00:16:51,850
down or else you can't do any more

00:16:48,579 --> 00:16:53,739
business right and so you need to decide

00:16:51,850 --> 00:16:55,989
which clients to prioritize you need to

00:16:53,739 --> 00:16:59,350
do rate limiting and so on in the second

00:16:55,989 --> 00:17:01,299
case you know you can you can run

00:16:59,350 --> 00:17:03,999
applications that are implemented with

00:17:01,299 --> 00:17:05,380
the new MapReduce or on yarn but you

00:17:03,999 --> 00:17:07,449
know maybe that's not the kind of

00:17:05,380 --> 00:17:09,100
application you wrote right so there's

00:17:07,449 --> 00:17:11,949
another sort of integration challenge

00:17:09,100 --> 00:17:13,630
there and you also can't scale out these

00:17:11,949 --> 00:17:16,539
compute and storage independently

00:17:13,630 --> 00:17:18,659
because you know you basically need to

00:17:16,539 --> 00:17:24,549
have as many machines devoted to this as

00:17:18,659 --> 00:17:26,500
you have voted to your storage so I'm

00:17:24,549 --> 00:17:28,179
going to argue that architectures that

00:17:26,500 --> 00:17:30,970
separate analytics from applications

00:17:28,179 --> 00:17:32,409
again only make sense if analytics is a

00:17:30,970 --> 00:17:34,269
separate work load we really want to

00:17:32,409 --> 00:17:36,460
look at an architecture where we're

00:17:34,269 --> 00:17:38,559
considering the analytic demands of

00:17:36,460 --> 00:17:39,690
individual applications and that's how

00:17:38,559 --> 00:17:42,240
we want to deploy

00:17:39,690 --> 00:17:44,309
applications so I want to propose a

00:17:42,240 --> 00:17:45,929
really high-level architecture that you

00:17:44,309 --> 00:17:50,669
can use that makes sense for doing these

00:17:45,929 --> 00:17:53,100
analytic applications in containers at a

00:17:50,669 --> 00:17:55,649
high level what is your intelligent

00:17:53,100 --> 00:17:57,149
application doing well it's getting data

00:17:55,649 --> 00:17:59,009
from a bunch of different sources it's

00:17:57,149 --> 00:18:00,629
getting a stream of events right it's

00:17:59,009 --> 00:18:03,450
getting structured data from databases

00:18:00,629 --> 00:18:05,340
it's getting unstructured data maybe

00:18:03,450 --> 00:18:07,230
from file or object storage and I'm

00:18:05,340 --> 00:18:09,120
going to try not to raise Steve's ire by

00:18:07,230 --> 00:18:11,850
talking positively about object storage

00:18:09,120 --> 00:18:14,009
in this talk but it's going to transform

00:18:11,850 --> 00:18:17,039
data from those sources and it's going

00:18:14,009 --> 00:18:19,230
to federate the transform data and it's

00:18:17,039 --> 00:18:21,029
probably going to archive that transform

00:18:19,230 --> 00:18:23,039
data or maybe archive their raw data

00:18:21,029 --> 00:18:24,120
somewhere then we're going to do

00:18:23,039 --> 00:18:25,559
something interesting with that data

00:18:24,120 --> 00:18:27,679
right we need to learn from it we need

00:18:25,559 --> 00:18:30,200
to use it to make our application better

00:18:27,679 --> 00:18:33,000
so we're going to train a model and that

00:18:30,200 --> 00:18:35,700
model you know maybe that's going to be

00:18:33,000 --> 00:18:37,169
a service that we run as an individual

00:18:35,700 --> 00:18:38,580
micro service maybe it's going to be an

00:18:37,169 --> 00:18:40,080
object that just stores a bunch of

00:18:38,580 --> 00:18:41,789
coefficients that we store in an

00:18:40,080 --> 00:18:46,919
in-memory data grid like in finis ban

00:18:41,789 --> 00:18:48,750
and we might also use these models to

00:18:46,919 --> 00:18:51,629
influence how we transform incoming data

00:18:48,750 --> 00:18:55,350
you know to deal with to deal with model

00:18:51,629 --> 00:18:58,549
drift and so on so we also need to

00:18:55,350 --> 00:19:00,750
support some user interface components

00:18:58,549 --> 00:19:02,789
you know maybe there's a developer you

00:19:00,750 --> 00:19:04,559
is you can add new business rules or

00:19:02,789 --> 00:19:05,720
explicitly add them all that you've

00:19:04,559 --> 00:19:08,129
trained outside of the application

00:19:05,720 --> 00:19:09,990
there's the actual UI for the

00:19:08,129 --> 00:19:13,559
application which is maybe maybe a

00:19:09,990 --> 00:19:15,929
website or maybe a mobile app or the

00:19:13,559 --> 00:19:17,639
backend for a mobile app a reporting

00:19:15,929 --> 00:19:19,200
interface for the business side and the

00:19:17,639 --> 00:19:21,539
management interface to make sure that

00:19:19,200 --> 00:19:25,440
the service is running appropriately and

00:19:21,539 --> 00:19:27,090
has has decent latency and so on so in

00:19:25,440 --> 00:19:30,179
this diagram I'm basically using blue

00:19:27,090 --> 00:19:32,580
for storage persistent or ephemeral

00:19:30,179 --> 00:19:34,590
storage I'm using orange for compute I'm

00:19:32,580 --> 00:19:38,220
using green for user interface

00:19:34,590 --> 00:19:40,019
components now the storage the

00:19:38,220 --> 00:19:44,789
persistent storage is going to outlive

00:19:40,019 --> 00:19:47,850
any deployment of our app so it's going

00:19:44,789 --> 00:19:50,250
to live outside of containers but this

00:19:47,850 --> 00:19:53,929
operational storage this model cache we

00:19:50,250 --> 00:19:53,929
have can live in a contain

00:19:54,920 --> 00:20:01,800
the UIs are often just sort of simple

00:19:58,590 --> 00:20:02,970
views in tech into the application state

00:20:01,800 --> 00:20:04,559
they're going to be reading from that

00:20:02,970 --> 00:20:06,510
operational store they're going to be

00:20:04,559 --> 00:20:08,550
interacting with components that are

00:20:06,510 --> 00:20:10,770
interacting with persistent storage so

00:20:08,550 --> 00:20:13,980
we can easily run those in stateless

00:20:10,770 --> 00:20:16,890
containers as well now you might say and

00:20:13,980 --> 00:20:18,210
then the compute part in orange as we've

00:20:16,890 --> 00:20:20,460
discussed those are already micro

00:20:18,210 --> 00:20:22,860
services right so you can run those in

00:20:20,460 --> 00:20:25,140
stateless containers as well now you

00:20:22,860 --> 00:20:26,460
might say well great so I really want to

00:20:25,140 --> 00:20:29,280
run my application in containers I

00:20:26,460 --> 00:20:31,110
already have a spark cluster so why

00:20:29,280 --> 00:20:33,870
don't I just schedule my applications

00:20:31,110 --> 00:20:35,760
alongside my spark cluster right well

00:20:33,870 --> 00:20:38,190
then you get this issue where you need

00:20:35,760 --> 00:20:40,080
to sort of manage the manage the

00:20:38,190 --> 00:20:42,000
scheduling so that you're you're dealing

00:20:40,080 --> 00:20:43,140
with a scheduler for for spark jobs

00:20:42,000 --> 00:20:45,030
you're dealing with scheduler for

00:20:43,140 --> 00:20:47,010
application components they need to

00:20:45,030 --> 00:20:50,179
cooperate so it's really not a good

00:20:47,010 --> 00:20:51,990
scene it's not ideal right and

00:20:50,179 --> 00:20:54,059
multi-tenant clean food clusters are

00:20:51,990 --> 00:20:55,950
pretty hard to manage right I don't

00:20:54,059 --> 00:20:57,570
think there's anyone argue with that I I

00:20:55,950 --> 00:21:01,559
think that's a non-controversial point

00:20:57,570 --> 00:21:03,300
but I don't know no one has willingly

00:21:01,559 --> 00:21:05,760
argued with me on that in my past but

00:21:03,300 --> 00:21:07,380
I'm always curious right so so a better

00:21:05,760 --> 00:21:08,940
model that we've seen is to take this

00:21:07,380 --> 00:21:09,480
cluster centric model and turned it

00:21:08,940 --> 00:21:11,640
inside out

00:21:09,480 --> 00:21:13,110
go to an app centric model and actually

00:21:11,640 --> 00:21:15,240
put the compute clusters in the

00:21:13,110 --> 00:21:17,880
application we run everything under

00:21:15,240 --> 00:21:20,550
container orchestration in in kubernetes

00:21:17,880 --> 00:21:22,830
or in openshift which is an application

00:21:20,550 --> 00:21:24,480
platform built on kubernetes and we just

00:21:22,830 --> 00:21:26,250
say well hey we can get our

00:21:24,480 --> 00:21:28,350
multi-tenancy at the container

00:21:26,250 --> 00:21:30,690
orchestration level we can run all of

00:21:28,350 --> 00:21:32,550
these things together they're cheap to

00:21:30,690 --> 00:21:36,030
setup and teardown and we can schedule

00:21:32,550 --> 00:21:37,980
application components along with the

00:21:36,030 --> 00:21:41,550
compute resources they depend on we can

00:21:37,980 --> 00:21:43,200
scale these out as we need to and again

00:21:41,550 --> 00:21:44,700
these analytic components are just micro

00:21:43,200 --> 00:21:49,800
services they work really well in

00:21:44,700 --> 00:21:53,190
containers well they work really well in

00:21:49,800 --> 00:21:54,960
containers once you cover a few

00:21:53,190 --> 00:21:56,640
potential stumbling blocks and that's

00:21:54,960 --> 00:21:58,260
what we're going to talk about now we'll

00:21:56,640 --> 00:21:59,850
start with correctness including

00:21:58,260 --> 00:22:01,110
security and then we'll talk about

00:21:59,850 --> 00:22:04,350
performance

00:22:01,110 --> 00:22:06,690
and after this part of the talk I hope

00:22:04,350 --> 00:22:09,090
you'll you'll know how to put put

00:22:06,690 --> 00:22:10,860
containers into practice in a way that

00:22:09,090 --> 00:22:14,130
will in a way they'll work really well

00:22:10,860 --> 00:22:15,900
for you first of all I want to talk

00:22:14,130 --> 00:22:17,400
about security I think with any computer

00:22:15,900 --> 00:22:19,950
security topic especially with

00:22:17,400 --> 00:22:22,710
containers you need to think about the

00:22:19,950 --> 00:22:24,300
continuum of trade-offs you have right

00:22:22,710 --> 00:22:26,850
and decide what you're comfortable with

00:22:24,300 --> 00:22:28,950
and so I want to start by explicitly

00:22:26,850 --> 00:22:31,830
examining the continuum of trade-offs we

00:22:28,950 --> 00:22:34,590
have let's think about one way to get a

00:22:31,830 --> 00:22:36,300
whole bunch of job a whole bunch of

00:22:34,590 --> 00:22:40,470
computers doing a whole bunch of

00:22:36,300 --> 00:22:42,210
computation individual computers doing

00:22:40,470 --> 00:22:46,170
their own thing not connected by a

00:22:42,210 --> 00:22:47,550
network right it's pretty secure right

00:22:46,170 --> 00:22:49,020
none of these can interfere with each

00:22:47,550 --> 00:22:51,540
other but it's also not very interesting

00:22:49,020 --> 00:22:53,300
because they can't cooperate or

00:22:51,540 --> 00:22:56,340
communicate it's not not very flexible

00:22:53,300 --> 00:22:57,960
so how about instead we take a bunch of

00:22:56,340 --> 00:23:00,690
computers that are connected by a

00:22:57,960 --> 00:23:02,400
network if we if we do this together we

00:23:00,690 --> 00:23:05,400
can run different services on different

00:23:02,400 --> 00:23:07,380
dedicated machines now your whole system

00:23:05,400 --> 00:23:09,270
is probably going to be affected if one

00:23:07,380 --> 00:23:12,150
service starts misbehaving or crashes

00:23:09,270 --> 00:23:13,770
but if a service or an operating system

00:23:12,150 --> 00:23:15,810
on one of these machines crashes it's

00:23:13,770 --> 00:23:18,750
probably not going to make the rest of

00:23:15,810 --> 00:23:20,040
the system crash and communication

00:23:18,750 --> 00:23:21,900
between these machines is always going

00:23:20,040 --> 00:23:24,000
to happen in well-defined ways it's

00:23:21,900 --> 00:23:26,670
going to happen via message passing via

00:23:24,000 --> 00:23:28,860
an explicitly shared file system via

00:23:26,670 --> 00:23:31,020
something that you can understand and

00:23:28,860 --> 00:23:35,130
control which is going to limit the

00:23:31,020 --> 00:23:36,840
potential for problems if something

00:23:35,130 --> 00:23:39,780
misbehaves and tries to write something

00:23:36,840 --> 00:23:42,120
that something else has to trust so

00:23:39,780 --> 00:23:44,760
going a little finer grained we could

00:23:42,120 --> 00:23:47,580
look at the idea of running a bunch of

00:23:44,760 --> 00:23:50,820
virtual machines on the same physical

00:23:47,580 --> 00:23:52,620
machine we have a little we have a look

00:23:50,820 --> 00:23:55,830
we can pack a bunch of bunch more

00:23:52,620 --> 00:23:57,780
processes that are isolated on a smaller

00:23:55,830 --> 00:23:59,430
amount of hardware but we're paying some

00:23:57,780 --> 00:24:01,140
non-trivial overhead for all of these

00:23:59,430 --> 00:24:03,770
hypervisors and all of the operating

00:24:01,140 --> 00:24:06,540
systems that we're running in them and

00:24:03,770 --> 00:24:08,400
if one of these crashes it's not going

00:24:06,540 --> 00:24:09,870
to take down the others but if the host

00:24:08,400 --> 00:24:11,430
crashes it's going to take down

00:24:09,870 --> 00:24:13,840
everything

00:24:11,430 --> 00:24:17,230
we can go still finer-grained

00:24:13,840 --> 00:24:20,260
and imagine running multiple containers

00:24:17,230 --> 00:24:23,140
in multiple containers with services on

00:24:20,260 --> 00:24:25,060
the same host now containers offer

00:24:23,140 --> 00:24:27,670
extremely low overhead like almost

00:24:25,060 --> 00:24:29,110
imperceptible overhead and the name

00:24:27,670 --> 00:24:32,350
spacing and photo mechanisms we have

00:24:29,110 --> 00:24:33,490
offer pretty good isolation typically

00:24:32,350 --> 00:24:35,440
your containers aren't going to be

00:24:33,490 --> 00:24:37,330
sharing our file system which eliminates

00:24:35,440 --> 00:24:39,580
a large class of exploits where one

00:24:37,330 --> 00:24:45,040
process over writes a file than another

00:24:39,580 --> 00:24:47,230
process trusts our last option for the

00:24:45,040 --> 00:24:51,430
most for the lowest overhead is to just

00:24:47,230 --> 00:24:53,250
run every service as a regular process

00:24:51,430 --> 00:24:55,450
in the same namespace on the same host

00:24:53,250 --> 00:24:57,850
there's not really any advantage to

00:24:55,450 --> 00:25:00,430
doing this over running processes and

00:24:57,850 --> 00:25:02,290
containers but there's no isolation so

00:25:00,430 --> 00:25:04,180
there are disadvantages please don't do

00:25:02,290 --> 00:25:05,860
this I think that the trade-offs

00:25:04,180 --> 00:25:08,350
containers offer actually make a lot of

00:25:05,860 --> 00:25:10,450
sense you can get nearly no overhead and

00:25:08,350 --> 00:25:11,590
a reasonable amount of isolation but

00:25:10,450 --> 00:25:13,890
there are still some things you can do

00:25:11,590 --> 00:25:16,810
to improve the isolation that you get

00:25:13,890 --> 00:25:18,580
the first thing you do is don't trust

00:25:16,810 --> 00:25:19,870
that isolation or write remember

00:25:18,580 --> 00:25:20,650
containers do not provide complete

00:25:19,870 --> 00:25:23,500
isolation

00:25:20,650 --> 00:25:25,600
if you run SELinux you can dramatically

00:25:23,500 --> 00:25:27,580
limit your exposure to bugs in your

00:25:25,600 --> 00:25:29,890
container runtime or to malicious code

00:25:27,580 --> 00:25:32,050
running in a container su Linux

00:25:29,890 --> 00:25:33,850
effectively walls off processes and

00:25:32,050 --> 00:25:36,040
files meaning that even if something

00:25:33,850 --> 00:25:37,990
escapes the container or can see outside

00:25:36,040 --> 00:25:39,490
of its namespaces it won't have

00:25:37,990 --> 00:25:41,830
unrestricted access to the rest of your

00:25:39,490 --> 00:25:43,450
hosts and in the last six months or so

00:25:41,830 --> 00:25:45,760
people who are running selinux and

00:25:43,450 --> 00:25:47,920
production were totally protected from a

00:25:45,760 --> 00:25:52,210
zero-day exploit and docker so this is

00:25:47,920 --> 00:25:53,770
actually a real-world concern the second

00:25:52,210 --> 00:25:56,350
thing to remember is that for the most

00:25:53,770 --> 00:25:58,170
part users are not namespaced so if

00:25:56,350 --> 00:26:00,490
you're running as root in a container

00:25:58,170 --> 00:26:02,530
you're running is wrote on your hosts a

00:26:00,490 --> 00:26:05,170
containerized process that's running is

00:26:02,530 --> 00:26:07,330
root and somehow changes or escapes its

00:26:05,170 --> 00:26:10,660
namespaces can wreak havoc on your

00:26:07,330 --> 00:26:12,310
system in general you don't want to run

00:26:10,660 --> 00:26:14,040
things as root in containers for the

00:26:12,310 --> 00:26:16,540
same reason you don't want to run

00:26:14,040 --> 00:26:19,930
ordinary processes right why you don't

00:26:16,540 --> 00:26:22,540
want to pipe you know some random shell

00:26:19,930 --> 00:26:24,730
script from the Internet to bash as root

00:26:22,540 --> 00:26:26,800
namespaces for user IDs have been under

00:26:24,730 --> 00:26:28,480
development and they've been about six

00:26:26,800 --> 00:26:30,160
months to a year away for quite a while

00:26:28,480 --> 00:26:32,170
but I don't think many people are

00:26:30,160 --> 00:26:34,060
running them in production yet they are

00:26:32,170 --> 00:26:36,160
an experimental option in recent Linux

00:26:34,060 --> 00:26:37,890
kernels and docker releases but it's

00:26:36,160 --> 00:26:41,170
still still on the horizon

00:26:37,890 --> 00:26:42,820
another concern especially if you're

00:26:41,170 --> 00:26:44,770
doing contemporary analytics is that you

00:26:42,820 --> 00:26:48,280
might not have a password file in your

00:26:44,770 --> 00:26:49,810
container so a lot of libraries that you

00:26:48,280 --> 00:26:52,000
want to use including the Hadoop file

00:26:49,810 --> 00:26:53,800
system library will want to look up the

00:26:52,000 --> 00:26:55,270
currently active user from the user ID

00:26:53,800 --> 00:26:55,990
in the password file to figure out what

00:26:55,270 --> 00:26:58,030
their name is

00:26:55,990 --> 00:26:59,430
now if you don't have a password file

00:26:58,030 --> 00:27:01,690
that's going to fail and crash

00:26:59,430 --> 00:27:03,550
fortunately there's a program called NSS

00:27:01,690 --> 00:27:07,150
wrapper that will let you run arbitrary

00:27:03,550 --> 00:27:08,590
programs with pretend password files so

00:27:07,150 --> 00:27:13,840
that they can look up the user you're

00:27:08,590 --> 00:27:15,310
currently running as another security

00:27:13,840 --> 00:27:17,920
issue we might have to worry about is a

00:27:15,310 --> 00:27:20,260
denial of service name spacing provides

00:27:17,920 --> 00:27:22,300
really good isolation for resources that

00:27:20,260 --> 00:27:24,190
are named spaced but not every resource

00:27:22,300 --> 00:27:30,700
is named spaced and you could imagine

00:27:24,190 --> 00:27:32,380
that a process could allocate a lot of

00:27:30,700 --> 00:27:34,420
resources that are not named spaced and

00:27:32,380 --> 00:27:37,000
prevent other processes from making

00:27:34,420 --> 00:27:38,890
progress a more dramatic form of denial

00:27:37,000 --> 00:27:40,570
of service the stems from the fact that

00:27:38,890 --> 00:27:44,620
we're all running on the same kernel and

00:27:40,570 --> 00:27:46,000
you can crash the host right if we crash

00:27:44,620 --> 00:27:48,040
the host we've essentially denied

00:27:46,000 --> 00:27:48,490
service to anything else running on the

00:27:48,040 --> 00:27:50,560
host

00:27:48,490 --> 00:27:52,630
unfortunately kernel panics from user

00:27:50,560 --> 00:27:54,550
space code are still pretty rare but

00:27:52,630 --> 00:27:56,530
this is a good reason to test everything

00:27:54,550 --> 00:27:58,330
and have good continuous integration and

00:27:56,530 --> 00:27:59,650
make sure that you're pretty confident

00:27:58,330 --> 00:28:03,370
that the code works before you put it

00:27:59,650 --> 00:28:05,560
into production the last security if you

00:28:03,370 --> 00:28:08,320
will look at is an interesting one for

00:28:05,560 --> 00:28:09,700
containerized applications if we think

00:28:08,320 --> 00:28:11,170
about the fact that persistent storage

00:28:09,700 --> 00:28:12,880
is usually going to live outside of

00:28:11,170 --> 00:28:15,670
containers and we're usually an access

00:28:12,880 --> 00:28:17,680
it via a service interface like HDFS or

00:28:15,670 --> 00:28:21,370
an object store or a different kind of

00:28:17,680 --> 00:28:23,200
shared file system we are going to have

00:28:21,370 --> 00:28:24,960
credentials to access that and since our

00:28:23,200 --> 00:28:26,950
container images are typically immutable

00:28:24,960 --> 00:28:28,990
and you're going to be using the same

00:28:26,950 --> 00:28:30,700
image in development tests in production

00:28:28,990 --> 00:28:32,620
because you want to benefit from your

00:28:30,700 --> 00:28:35,789
continuous integration right you need

00:28:32,620 --> 00:28:37,929
some place to keep these credentials

00:28:35,789 --> 00:28:39,879
the first thing you can do which you

00:28:37,929 --> 00:28:44,039
which you don't want to do is actually

00:28:39,879 --> 00:28:46,649
keep these in source control bad idea I

00:28:44,039 --> 00:28:49,539
don't need to elaborate on that do I

00:28:46,649 --> 00:28:52,179
didn't think so the second thing you can

00:28:49,539 --> 00:28:54,639
do is you can actually store sensitive

00:28:52,179 --> 00:28:56,279
information in the environment and use

00:28:54,639 --> 00:28:58,779
your container runtime to configure that

00:28:56,279 --> 00:29:02,199
it's possible this would leak out but

00:28:58,779 --> 00:29:04,690
this is so much better than then using

00:29:02,199 --> 00:29:07,149
source control that it's it's it's

00:29:04,690 --> 00:29:09,009
probably okay and the third and best

00:29:07,149 --> 00:29:10,659
thing to do is to use a dedicated secret

00:29:09,009 --> 00:29:12,789
management service like the secrets

00:29:10,659 --> 00:29:14,349
mechanism in kubernetes or a standalone

00:29:12,789 --> 00:29:17,979
service like a vault something that's

00:29:14,349 --> 00:29:20,259
designed to hold secrets is going to

00:29:17,979 --> 00:29:23,409
give you flexibility and security and

00:29:20,259 --> 00:29:27,519
that's really where you want to go with

00:29:23,409 --> 00:29:29,440
managing credentials and secrets okay so

00:29:27,519 --> 00:29:32,949
we've talked about correctness now I'd

00:29:29,440 --> 00:29:34,899
like to talk about performance and the

00:29:32,949 --> 00:29:37,479
first thing you might say which is my

00:29:34,899 --> 00:29:39,279
first performance pitfall is will all

00:29:37,479 --> 00:29:40,959
this security talk has me really nervous

00:29:39,279 --> 00:29:44,349
I bet I could just run a container

00:29:40,959 --> 00:29:46,690
inside a hypervisor and if I ran all my

00:29:44,349 --> 00:29:47,679
containers inside hypervisors I'd be

00:29:46,690 --> 00:29:50,739
okay right

00:29:47,679 --> 00:29:52,989
well hypervisors introduced kind of a

00:29:50,739 --> 00:29:55,659
ton of overhead right like on the order

00:29:52,989 --> 00:29:57,999
of ten percent or so and if you can use

00:29:55,659 --> 00:29:59,679
more lightweight isolation mechanisms

00:29:57,999 --> 00:30:01,329
you can preserve your performance so

00:29:59,679 --> 00:30:03,190
that's the first thing I say is just use

00:30:01,329 --> 00:30:05,319
the lightweight isolation mechanisms

00:30:03,190 --> 00:30:06,999
that make sense for containers and

00:30:05,319 --> 00:30:09,759
except that the trade-offs or security

00:30:06,999 --> 00:30:11,499
are pretty good anecdotally a lot of

00:30:09,759 --> 00:30:13,719
people are concerned about the impact

00:30:11,499 --> 00:30:15,819
that this virtual network routing will

00:30:13,719 --> 00:30:17,589
have on a data intensive application a

00:30:15,819 --> 00:30:19,119
colleague of mine has done a lot of

00:30:17,589 --> 00:30:21,789
testing with machine learning workloads

00:30:19,119 --> 00:30:26,739
and she's shown that there's typically

00:30:21,789 --> 00:30:28,749
around a 5% impact there's really

00:30:26,739 --> 00:30:31,719
minimal impact on overall application

00:30:28,749 --> 00:30:33,699
performance and in many cases the impact

00:30:31,719 --> 00:30:36,789
of running in containers versus not

00:30:33,699 --> 00:30:37,929
running hairs is lost in the noise one

00:30:36,789 --> 00:30:39,279
thing that you do have to worry about

00:30:37,929 --> 00:30:42,849
though is the performance of your i/o

00:30:39,279 --> 00:30:44,019
configuration if you have a disk mounted

00:30:42,849 --> 00:30:45,700
on the container and it's a loopback

00:30:44,019 --> 00:30:46,419
device you'll have very poor performance

00:30:45,700 --> 00:30:48,489
for any

00:30:46,419 --> 00:30:49,899
has to hit that disk so there are best

00:30:48,489 --> 00:30:51,789
practices for using disks with

00:30:49,899 --> 00:30:54,450
containers and definitely make sure to

00:30:51,789 --> 00:30:57,159
check that out and keep that in mind

00:30:54,450 --> 00:30:59,259
another surprising issue with containers

00:30:57,159 --> 00:31:01,419
and performance is interaction between

00:30:59,259 --> 00:31:03,489
resource quotas and common optimizations

00:31:01,419 --> 00:31:05,889
for example your default garbage

00:31:03,489 --> 00:31:08,109
collection configuration may use the JVM

00:31:05,889 --> 00:31:09,309
s parallel GC where you're tuned for

00:31:08,109 --> 00:31:11,559
throughput and you're going to burn a

00:31:09,309 --> 00:31:15,429
lot of extra cycles in order to get good

00:31:11,559 --> 00:31:17,350
throughput a colleague of mine has shown

00:31:15,429 --> 00:31:19,239
that in containers when you're in a CPU

00:31:17,350 --> 00:31:21,369
constrained environment it may be better

00:31:19,239 --> 00:31:23,289
to trade a little bit of throughput or a

00:31:21,369 --> 00:31:24,970
little bit of latency for not burning

00:31:23,289 --> 00:31:28,299
all your CPU quota on the garbage

00:31:24,970 --> 00:31:35,139
collector another interesting issue with

00:31:28,299 --> 00:31:37,960
containers is the idea of some clever

00:31:35,139 --> 00:31:40,029
optimizations that certain applications

00:31:37,960 --> 00:31:44,200
use that have surprising impact in

00:31:40,029 --> 00:31:46,149
containers if you consider spark spark

00:31:44,200 --> 00:31:47,950
uses the operating system buffer cache

00:31:46,149 --> 00:31:50,080
in the shuffle basically when you have a

00:31:47,950 --> 00:31:52,269
shuffle and spark you write to disk but

00:31:50,080 --> 00:31:54,100
you don't sink the assumption is that

00:31:52,269 --> 00:31:56,289
that data is never going to hit the disk

00:31:54,100 --> 00:32:01,210
and that you're just getting some off

00:31:56,289 --> 00:32:02,919
heap storage for free and if you run out

00:32:01,210 --> 00:32:04,419
of actual physical memory it will get

00:32:02,919 --> 00:32:06,639
will hit the disk but ideally it won't

00:32:04,419 --> 00:32:08,559
now this is a great optimization in the

00:32:06,639 --> 00:32:11,559
general cases it's clever its elegant

00:32:08,559 --> 00:32:12,909
it's nice but that buffer cache usage

00:32:11,559 --> 00:32:14,529
counts against your memory quota if

00:32:12,909 --> 00:32:19,899
you're running in a container so you

00:32:14,529 --> 00:32:21,549
need to think about that the last of

00:32:19,899 --> 00:32:22,989
surprising interaction between the JVM

00:32:21,549 --> 00:32:25,389
and containers I want to mention is

00:32:22,989 --> 00:32:27,239
memory and for a long time the JVM has

00:32:25,389 --> 00:32:31,330
not been aware of quotas so you could

00:32:27,239 --> 00:32:33,609
happily ask the JVM to give you more

00:32:31,330 --> 00:32:35,109
memory than your memory quota would

00:32:33,609 --> 00:32:36,489
allow and you would only find out that

00:32:35,109 --> 00:32:38,529
it was a problem when the kernel killed

00:32:36,489 --> 00:32:41,529
you because you exceeded your resource

00:32:38,529 --> 00:32:43,119
limit another subtle problem is that the

00:32:41,529 --> 00:32:45,299
Java runtimes notion of available

00:32:43,119 --> 00:32:47,649
processor cores didn't take into account

00:32:45,299 --> 00:32:50,980
CPU resource limits that might be

00:32:47,649 --> 00:32:52,809
applied to your container so if you're

00:32:50,980 --> 00:32:54,369
using a recent build of open JDK I'm

00:32:52,809 --> 00:32:55,210
delighted to tell you that this isn't a

00:32:54,369 --> 00:32:57,099
problem anymore

00:32:55,210 --> 00:32:58,690
if not you'll need to worry about

00:32:57,099 --> 00:32:59,840
setting these limits manually and in

00:32:58,690 --> 00:33:01,340
conjunction with whatever

00:32:59,840 --> 00:33:03,440
as you're imposing on your containers

00:33:01,340 --> 00:33:06,289
and here's what this looks like in a

00:33:03,440 --> 00:33:09,470
recent OpenJDK it's past build 131 I

00:33:06,289 --> 00:33:13,820
think of open JDK 8 and in recent built

00:33:09,470 --> 00:33:15,500
to open JDK 9 but to get C group memory

00:33:13,820 --> 00:33:17,720
limits for your heap on the Java you

00:33:15,500 --> 00:33:20,960
just use this experimental option here

00:33:17,720 --> 00:33:22,820
and for CPU the runtime get runtime

00:33:20,960 --> 00:33:27,679
available processors method will do the

00:33:22,820 --> 00:33:29,510
right thing in recent open JDK so I want

00:33:27,679 --> 00:33:30,890
to wrap up now by quickly reiterating

00:33:29,510 --> 00:33:32,840
what we've talked about and show you how

00:33:30,890 --> 00:33:36,559
to get involved and use these techniques

00:33:32,840 --> 00:33:38,630
for your own applications the cluster

00:33:36,559 --> 00:33:40,279
centric model made sense when analytics

00:33:38,630 --> 00:33:41,779
was a separate workload that ran

00:33:40,279 --> 00:33:43,610
alongside the rest of our businesses but

00:33:41,779 --> 00:33:45,529
that's no longer the case as we've seen

00:33:43,610 --> 00:33:47,990
as we're as we're continuing to see

00:33:45,529 --> 00:33:51,020
there's a revolution underway from this

00:33:47,990 --> 00:33:52,720
cluster centric model to an app centric

00:33:51,020 --> 00:33:56,000
model where we care about apps and

00:33:52,720 --> 00:33:57,500
analytics really underlie every

00:33:56,000 --> 00:33:59,860
important capability that we want to

00:33:57,500 --> 00:34:02,480
provide to our customers or to our users

00:33:59,860 --> 00:34:04,880
we introduced the ideas of containers

00:34:02,480 --> 00:34:06,710
container orchestration micro services

00:34:04,880 --> 00:34:08,210
and cloud native applications which are

00:34:06,710 --> 00:34:10,339
currently hot topics in general

00:34:08,210 --> 00:34:11,990
application development but we also

00:34:10,339 --> 00:34:14,990
discussed some concrete details of how

00:34:11,990 --> 00:34:18,310
you can take these concepts and apply

00:34:14,990 --> 00:34:21,349
analytics in those contexts as well on

00:34:18,310 --> 00:34:23,089
the architectural front we saw that

00:34:21,349 --> 00:34:24,800
fortunately many of the frameworks we

00:34:23,089 --> 00:34:25,940
want to use are already cloud native

00:34:24,800 --> 00:34:27,440
they're already a great fit for

00:34:25,940 --> 00:34:29,869
containers with a little bit of extra

00:34:27,440 --> 00:34:31,760
work we've seen that you can embed

00:34:29,869 --> 00:34:33,500
compute clusters in apps and get

00:34:31,760 --> 00:34:37,220
multi-tenancy at the resource manager

00:34:33,500 --> 00:34:39,290
level and we've talked about how you can

00:34:37,220 --> 00:34:40,879
use storage outside of containers and

00:34:39,290 --> 00:34:41,710
access it through service interfaces or

00:34:40,879 --> 00:34:47,240
api's

00:34:41,710 --> 00:34:49,580
on the correctness front we talked about

00:34:47,240 --> 00:34:51,320
some common sense security things like

00:34:49,580 --> 00:34:52,960
don't run in as wrote in the container

00:34:51,320 --> 00:34:56,419
just because you're in a container and

00:34:52,960 --> 00:35:00,530
use selinux to minimize your exposure to

00:34:56,419 --> 00:35:03,820
malicious code and bugs and really be

00:35:00,530 --> 00:35:03,820
careful with your secrets

00:35:06,290 --> 00:35:10,319
performance takeaways take advantage of

00:35:09,630 --> 00:35:11,460
containers

00:35:10,319 --> 00:35:14,099
don't put your containers and

00:35:11,460 --> 00:35:15,869
hypervisors don't worry about

00:35:14,099 --> 00:35:18,119
virtualized networking measure

00:35:15,869 --> 00:35:19,650
everything but virtualized disk is

00:35:18,119 --> 00:35:21,950
probably going to be a bigger problem

00:35:19,650 --> 00:35:24,750
for you than virtualized networking and

00:35:21,950 --> 00:35:26,940
again measure everything optimizations

00:35:24,750 --> 00:35:29,819
that are awesome outside of containers

00:35:26,940 --> 00:35:31,140
may have a really surprising impact when

00:35:29,819 --> 00:35:33,119
you haven't used them inside containers

00:35:31,140 --> 00:35:36,270
like using the buffer caches extra off

00:35:33,119 --> 00:35:38,640
heap storage so fortunately we've done a

00:35:36,270 --> 00:35:41,550
lot of the hard work for you if you're

00:35:38,640 --> 00:35:43,920
interested in running spark on OpenShift

00:35:41,550 --> 00:35:45,780
and kubernetes my team has an open

00:35:43,920 --> 00:35:47,940
source project called rad on linux do

00:35:45,780 --> 00:35:50,599
where you can go to get some tooling to

00:35:47,940 --> 00:35:53,180
spin up a spark cluster in containers

00:35:50,599 --> 00:35:55,140
alongside your application a

00:35:53,180 --> 00:35:57,569
containerized spark distribution we have

00:35:55,140 --> 00:35:59,490
some example applications for how you

00:35:57,569 --> 00:36:03,300
can sort of take advantage of different

00:35:59,490 --> 00:36:04,800
aspects of this architecture thank you

00:36:03,300 --> 00:36:06,720
so much for your time and attention I

00:36:04,800 --> 00:36:08,400
time an attention are always precious

00:36:06,720 --> 00:36:10,530
but they're especially so at the end of

00:36:08,400 --> 00:36:12,030
a great conference if you're like me

00:36:10,530 --> 00:36:13,109
you're exhausted but you're ready to get

00:36:12,030 --> 00:36:15,240
back to work and you have some good

00:36:13,109 --> 00:36:16,740
ideas if some of those ideas involve

00:36:15,240 --> 00:36:18,829
putting your next application in

00:36:16,740 --> 00:36:20,910
containers I'd love to hear from you and

00:36:18,829 --> 00:36:22,829
if you're interested in doing open

00:36:20,910 --> 00:36:24,359
source work on a global remote team at

00:36:22,829 --> 00:36:25,680
the intersection of distributed systems

00:36:24,359 --> 00:36:27,299
data science and software engineering

00:36:25,680 --> 00:36:29,190
I'm I'd really like to hear a few

00:36:27,299 --> 00:36:31,619
because it's the last slide in my talk

00:36:29,190 --> 00:36:40,290
so I have to say that we're hiring thank

00:36:31,619 --> 00:36:44,270
you thanks for the talk we've time for a

00:36:40,290 --> 00:36:44,270
couple of questions if anyone has any

00:36:45,079 --> 00:36:52,410
I've got one um so you mentioned the

00:36:48,420 --> 00:36:54,990
resource limits at kubernetes and things

00:36:52,410 --> 00:36:56,849
like that provides good ways of like

00:36:54,990 --> 00:36:59,700
querying what those limits are for

00:36:56,849 --> 00:37:03,540
monitoring kind of purposes or do you

00:36:59,700 --> 00:37:06,990
run into that kind of unexpected barrier

00:37:03,540 --> 00:37:09,599
often in practice in practice we don't

00:37:06,990 --> 00:37:11,160
and we did things before before we had

00:37:09,599 --> 00:37:13,170
the open JDK support we sort of did

00:37:11,160 --> 00:37:14,280
things the the simple way right of

00:37:13,170 --> 00:37:15,569
saying like well we're going to set

00:37:14,280 --> 00:37:18,299
these resource limits and can John

00:37:15,569 --> 00:37:19,589
on on our GDK in conjunction with the

00:37:18,299 --> 00:37:21,509
resource limits we have on the container

00:37:19,589 --> 00:37:23,729
but yeah you can interrogate this stuff

00:37:21,509 --> 00:37:34,619
and you you know when you set it up do

00:37:23,729 --> 00:37:36,839
so so we've got a big I think a good

00:37:34,619 --> 00:37:39,509
picture on how you imagine it for the

00:37:36,839 --> 00:37:42,599
compute part and you said then storage

00:37:39,509 --> 00:37:45,599
comes from somewhere like electricity

00:37:42,599 --> 00:37:49,009
comes from the wall so what would you

00:37:45,599 --> 00:37:51,930
suggest if you want to complete this

00:37:49,009 --> 00:37:54,599
architecture and we also need a storage

00:37:51,930 --> 00:37:57,959
layer would you then say still run in

00:37:54,599 --> 00:37:59,699
HDFS cluster next to it or what would be

00:37:57,959 --> 00:38:01,140
your suggestions I think the right

00:37:59,699 --> 00:38:03,239
answer to that is it depends right and I

00:38:01,140 --> 00:38:06,150
know you already have HDFS right so I

00:38:03,239 --> 00:38:07,680
would say you can run HDFS as a peer to

00:38:06,150 --> 00:38:11,369
Container orchestration and I think that

00:38:07,680 --> 00:38:14,249
works pretty well you don't have you

00:38:11,369 --> 00:38:16,259
don't have the locality but there's a

00:38:14,249 --> 00:38:18,119
lot of interesting sort of debate about

00:38:16,259 --> 00:38:19,859
whether or not you are really benefiting

00:38:18,119 --> 00:38:25,170
from locality as much as you thought you

00:38:19,859 --> 00:38:26,459
were that is an amazing argument do you

00:38:25,170 --> 00:38:28,049
have materials for that

00:38:26,459 --> 00:38:29,369
well maybe you can let me give you a

00:38:28,049 --> 00:38:41,630
look let me give you something up line

00:38:29,369 --> 00:38:44,459
yeah I have a reference I just said the

00:38:41,630 --> 00:38:46,920
for the frameworks that all running on a

00:38:44,459 --> 00:38:49,349
cluster today you can basically package

00:38:46,920 --> 00:38:52,039
them into containers and spin them up on

00:38:49,349 --> 00:38:54,509
containers I'm curious if I wanted to

00:38:52,039 --> 00:38:56,459
dynamic scaling where really the

00:38:54,509 --> 00:38:58,920
framework itself makes the decision that

00:38:56,459 --> 00:39:01,199
it wants to acquire more resources how

00:38:58,920 --> 00:39:03,479
would that play with that approach

00:39:01,199 --> 00:39:05,759
that's a great question so what we have

00:39:03,479 --> 00:39:07,799
actually on our project is we have a

00:39:05,759 --> 00:39:10,440
service that sort of pays attention to

00:39:07,799 --> 00:39:11,880
SPARC metrics and communicates with

00:39:10,440 --> 00:39:14,519
kubernetes and says hey give me another

00:39:11,880 --> 00:39:16,259
container because if you have sparks

00:39:14,519 --> 00:39:18,180
dynamic resource allocation enabled we

00:39:16,259 --> 00:39:20,160
say give me another container and spin

00:39:18,180 --> 00:39:21,539
it up the technical details that we're

00:39:20,160 --> 00:39:23,819
running a standalone spark cluster

00:39:21,539 --> 00:39:26,580
inside kubernetes so it looks to the

00:39:23,819 --> 00:39:28,710
standalone spark cluster as if

00:39:26,580 --> 00:39:36,390
a new machine just showed up and checked

00:39:28,710 --> 00:39:38,430
in with your master okay

00:39:36,390 --> 00:39:42,720
I think we're just a bad at a time

00:39:38,430 --> 00:39:45,060
thanks again to will the final event of

00:39:42,720 --> 00:39:47,760
the day is just about to start in castle

00:39:45,060 --> 00:39:50,120
house so you're all welcome to go over

00:39:47,760 --> 00:39:53,070
there and for the closing session and

00:39:50,120 --> 00:39:56,729
let's thank the speaker one last time

00:39:53,070 --> 00:39:56,729

YouTube URL: https://www.youtube.com/watch?v=4sooT4UfAJw


