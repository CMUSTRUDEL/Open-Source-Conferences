Title: #Haystack: Jacopo Tagliabue - Few-shot and zero-shot personalization using deep architectures.
Publication date: 2020-07-02
Playlist: Haystack - Joint Virtual Event 2020
Description: 
	Full Title: "Not all those who browse are lost": few-shot and zero-shot personalization for digital commerce using deep architectures. 

More: https://berlinbuzzwords.de/session/not-all-those-who-browse-are-lost-few-shot-and-zero-shot-personalization-digital-commerce

Personalization in IR is one of the hottest topics in the AI-takes-all economy: we should not aim to be "just" semantically relevant, but also tailor results to users' preferences and intent. However, personalization in digital commerce is easier said than done: most shoppers visit a given store no more than twice a year, and bounce rates across verticals show that it is important to personalize as early as possible. In this talk we share effective strategies to tackle the challenge of "in-session personalization" in NLP and IR tasks, starting from the straightforward case of "one-shop" personalization and then generalizing to more. On the business side, we argue using industry benchmarks and data from our network that in-session personalization is a fundamental part of any relevance journey in the hyper-competitive e-commerce market. On the tech side, we build on the latest deep learning trends to show how increasingly sophisticated representations of real-time intent can power personalization in product search. Once dense architectures are in place, we are ready to tackle the challenge of "transfer learning": can shopper's intent be transferred from one shop to another without annotated data? Using insights from lexical learning, sessions from different shops can be projected in the same space to power "zero-shot" personalization for downstream NLP services; finally, we prove with quantitative and qualitative benchmarks that zero-shot predictions are a significant improvement over industry baselines.
Captions: 
	00:00:08,770 --> 00:00:12,670
I used to say when I'm the last

00:00:10,750 --> 00:00:15,460
presenter that conference I used to say

00:00:12,670 --> 00:00:17,710
that I hate to be the one before you and

00:00:15,460 --> 00:00:19,510
a beer or wine but I guess the cool

00:00:17,710 --> 00:00:21,670
thing is about virtual conferences is

00:00:19,510 --> 00:00:23,290
that you can actually add wine while you

00:00:21,670 --> 00:00:25,020
listen to my part and it's probably

00:00:23,290 --> 00:00:27,580
gonna make it actually more interesting

00:00:25,020 --> 00:00:31,290
so thanks so much for the introduction

00:00:27,580 --> 00:00:34,120
charlie like a very quick overview of

00:00:31,290 --> 00:00:35,739
who I am and what we do a caballo

00:00:34,120 --> 00:00:37,390
since I guess you all of Google so you

00:00:35,739 --> 00:00:39,460
can actually you know search that

00:00:37,390 --> 00:00:40,930
yourself with more time since we have a

00:00:39,460 --> 00:00:42,820
lot of interesting things to say today

00:00:40,930 --> 00:00:44,680
so I used to be the founder of a

00:00:42,820 --> 00:00:46,690
start-up in Silicon Valley - so these

00:00:44,680 --> 00:00:49,720
are the three founders and obviously the

00:00:46,690 --> 00:00:52,239
more and someone and the funny one - xur

00:00:49,720 --> 00:00:55,180
was recently acquired last year by North

00:00:52,239 --> 00:00:57,489
American unicorn caballo - basically

00:00:55,180 --> 00:01:00,640
further enhance the AI and NLP

00:00:57,489 --> 00:01:04,360
capabilities of the company for those of

00:01:00,640 --> 00:01:07,500
you who do know caballo caballo is a

00:01:04,360 --> 00:01:11,470
like AI PowerSearch recommendation

00:01:07,500 --> 00:01:13,630
engine with five and employs

00:01:11,470 --> 00:01:15,970
approximately a thousand customer

00:01:13,630 --> 00:01:17,440
deployments Cabrera is a total of more

00:01:15,970 --> 00:01:19,750
than 300 million dollars in the last

00:01:17,440 --> 00:01:20,830
couple of years in particular last year

00:01:19,750 --> 00:01:24,240
cobia raised two hundred million dollars

00:01:20,830 --> 00:01:27,159
to achieve the price status of unicorn

00:01:24,240 --> 00:01:28,659
and again like six months it's like no

00:01:27,159 --> 00:01:31,150
more than six months ago nine months ago

00:01:28,659 --> 00:01:32,650
now they acquired my own startup and

00:01:31,150 --> 00:01:37,659
I've been the leader a scientist of

00:01:32,650 --> 00:01:39,820
caballo that's part before diving deep

00:01:37,659 --> 00:01:41,979
into the material today let's let's get

00:01:39,820 --> 00:01:43,960
into into credits this is one of my

00:01:41,979 --> 00:01:45,310
favorite quote so if you steal from 100

00:01:43,960 --> 00:01:47,170
plugins you steal from many it's

00:01:45,310 --> 00:01:50,020
research it's a bunch of people we

00:01:47,170 --> 00:01:53,110
really want to thank so Christine look

00:01:50,020 --> 00:01:55,390
at zero and Federico Federico is a

00:01:53,110 --> 00:01:58,240
postdoc fellow at Bocconi University in

00:01:55,390 --> 00:02:00,490
Italy Christine Lucca and Shiro are my

00:01:58,240 --> 00:02:02,259
colleagues at creo and this work is a

00:02:00,490 --> 00:02:03,340
joint work with them so nothing that you

00:02:02,259 --> 00:02:05,200
will see today would be impossible

00:02:03,340 --> 00:02:06,759
without their help and of course it's

00:02:05,200 --> 00:02:08,739
you know it's it's customary to change

00:02:06,759 --> 00:02:12,190
this is occasion if there's any mistake

00:02:08,739 --> 00:02:15,760
or any errors in this talk I'm sure it's

00:02:12,190 --> 00:02:17,919
that fault and not mine so today we're

00:02:15,760 --> 00:02:21,639
gonna discuss of a very very very

00:02:17,919 --> 00:02:25,989
important use cases in commerce this is

00:02:21,639 --> 00:02:28,720
to to user to shoppers that goes into

00:02:25,989 --> 00:02:31,239
into into any commercial one is bob

00:02:28,720 --> 00:02:33,130
injuries in hand bob is a basketball fan

00:02:31,239 --> 00:02:34,510
so it browse for some basketball product

00:02:33,130 --> 00:02:37,269
and then you start typing something in

00:02:34,510 --> 00:02:40,209
the search bar N and then we want

00:02:37,269 --> 00:02:42,040
ideally the e-commerce shop to actually

00:02:40,209 --> 00:02:44,889
recognize his intent and provide very

00:02:42,040 --> 00:02:46,810
relevant things like Nike brown shoes or

00:02:44,889 --> 00:02:48,130
NBA jersey or something like that and

00:02:46,810 --> 00:02:50,440
he's a tennis fan

00:02:48,130 --> 00:02:52,120
she's a tennis fan so and really like

00:02:50,440 --> 00:02:53,769
Stanley she's browsing for tennis

00:02:52,120 --> 00:02:55,389
rackets and then a tennis skirts and so

00:02:53,769 --> 00:02:57,310
when she types em in the same sport

00:02:55,389 --> 00:02:59,799
apparel shop we wanted the shop to

00:02:57,310 --> 00:03:01,389
recognize that and propose something

00:02:59,799 --> 00:03:02,799
like Nidal rocket or Knight women's

00:03:01,389 --> 00:03:04,989
shoes and so on and so forth

00:03:02,799 --> 00:03:07,840
BOM Anand need not to be necessarily

00:03:04,989 --> 00:03:09,489
logged in and above Ana needs you know

00:03:07,840 --> 00:03:12,040
they may be the first time they actually

00:03:09,489 --> 00:03:13,930
go into this website so what we're gonna

00:03:12,040 --> 00:03:15,940
discuss today is how we're gonna build

00:03:13,930 --> 00:03:17,380
this type of experience using the latest

00:03:15,940 --> 00:03:21,310
tools from deep learning and our

00:03:17,380 --> 00:03:23,949
research club some fact about e-commerce

00:03:21,310 --> 00:03:26,739
for those of you that I mean what you

00:03:23,949 --> 00:03:28,989
know a lot about search but maybe not

00:03:26,739 --> 00:03:30,880
about the industry space so real website

00:03:28,989 --> 00:03:32,650
by real website I mean you know not

00:03:30,880 --> 00:03:34,120
Amazon not eBay not Salon like you know

00:03:32,650 --> 00:03:36,160
the vast majority website you are

00:03:34,120 --> 00:03:37,989
actually gonna browse on I have two big

00:03:36,160 --> 00:03:40,810
problems one is high bounce rate which

00:03:37,989 --> 00:03:41,229
means that as when user goes on a

00:03:40,810 --> 00:03:43,060
website

00:03:41,229 --> 00:03:46,239
after a few interaction they typically

00:03:43,060 --> 00:03:48,070
get out of it so it's very hard to keep

00:03:46,239 --> 00:03:50,949
using on your website the second one is

00:03:48,070 --> 00:03:52,449
that the user base is very small which

00:03:50,949 --> 00:03:54,250
means that most of the people actually

00:03:52,449 --> 00:03:55,840
come back to the website two or three

00:03:54,250 --> 00:03:58,780
times in an entire year

00:03:55,840 --> 00:04:00,609
these two facts combined for two

00:03:58,780 --> 00:04:03,130
important generalization that we need to

00:04:00,609 --> 00:04:04,479
keep in mind when we discuss

00:04:03,130 --> 00:04:06,579
personalization commerce

00:04:04,479 --> 00:04:07,989
first one is personalization need to

00:04:06,579 --> 00:04:09,880
happen as early as possible in the

00:04:07,989 --> 00:04:10,419
journey and with as little user data as

00:04:09,880 --> 00:04:12,220
possible

00:04:10,419 --> 00:04:14,040
as early as possible because if you

00:04:12,220 --> 00:04:17,320
don't provide a personalized experience

00:04:14,040 --> 00:04:19,329
people will leave little user did as

00:04:17,320 --> 00:04:21,669
possible because as we discussed very

00:04:19,329 --> 00:04:22,810
few users will actually come back two or

00:04:21,669 --> 00:04:24,490
three more times

00:04:22,810 --> 00:04:27,509
so the actual amount of data you have

00:04:24,490 --> 00:04:29,740
about a single user it's very very small

00:04:27,509 --> 00:04:31,629
which you know all these things together

00:04:29,740 --> 00:04:34,360
imply that every personalization

00:04:31,629 --> 00:04:36,069
solution out there that relies on user

00:04:34,360 --> 00:04:38,289
three are basically not covering the

00:04:36,069 --> 00:04:39,939
vast majority of user so they are useful

00:04:38,289 --> 00:04:42,129
for you know this small portion of user

00:04:39,939 --> 00:04:44,740
that comes back but a vast majority user

00:04:42,129 --> 00:04:51,639
will still not be basically benefit from

00:04:44,740 --> 00:04:53,289
anything like that so the other fact

00:04:51,639 --> 00:04:55,330
that I want to convey about e-commerce

00:04:53,289 --> 00:04:57,129
is that session information is rich so

00:04:55,330 --> 00:04:59,199
when people go on our website even if

00:04:57,129 --> 00:05:01,449
they're not really logged in what they

00:04:59,199 --> 00:05:02,949
do typically follow an intent or a trend

00:05:01,449 --> 00:05:05,409
so this is like a sample from a real

00:05:02,949 --> 00:05:07,509
session of one of our customer this is

00:05:05,409 --> 00:05:09,279
an again she's just browsing for a guest

00:05:07,509 --> 00:05:11,620
t-shirt she's actually on searching for

00:05:09,279 --> 00:05:14,800
a guest t-shirt she click on another

00:05:11,620 --> 00:05:16,779
t-shirts and now if you ask what is

00:05:14,800 --> 00:05:18,520
she's gonna buy what is the most likely

00:05:16,779 --> 00:05:19,900
item she's gonna buy she's gonna buy one

00:05:18,520 --> 00:05:22,599
she's gonna buy two or she's gonna buy

00:05:19,900 --> 00:05:24,400
three the answer that most people give

00:05:22,599 --> 00:05:25,840
to this question is obviously one which

00:05:24,400 --> 00:05:27,340
is actually what happened in practice in

00:05:25,840 --> 00:05:30,969
the session that actually took place on

00:05:27,340 --> 00:05:33,370
the shop how do we know that as humans

00:05:30,969 --> 00:05:35,439
but we kind of clearly recognize the

00:05:33,370 --> 00:05:38,080
intent which is buying a packet like a

00:05:35,439 --> 00:05:39,849
t-shirt for women and we also recognize

00:05:38,080 --> 00:05:41,860
in this case brand awareness like you

00:05:39,849 --> 00:05:44,379
know she only browsed things for guests

00:05:41,860 --> 00:05:47,949
and she explicitly used language yes

00:05:44,379 --> 00:05:51,879
t-shirt to actually single out those

00:05:47,949 --> 00:05:54,699
product in fact if you take so this is

00:05:51,879 --> 00:05:57,819
the top searches that are issued in a

00:05:54,699 --> 00:05:59,889
real sport apparel shop from different

00:05:57,819 --> 00:06:02,139
section the website and as you see the

00:05:59,889 --> 00:06:03,819
linguistic behavior of the users changes

00:06:02,139 --> 00:06:06,069
drastically depending on the session of

00:06:03,819 --> 00:06:08,110
the website you're in again in somehow

00:06:06,069 --> 00:06:10,300
reinforcing the idea that what happens

00:06:08,110 --> 00:06:13,060
within a session or what a business near

00:06:10,300 --> 00:06:17,139
real-time is very very relevant to

00:06:13,060 --> 00:06:19,150
provide personalized NLP capabilities so

00:06:17,139 --> 00:06:21,610
now that the problem is clear we need to

00:06:19,150 --> 00:06:23,229
answer two questions so how we can to

00:06:21,610 --> 00:06:24,939
answer the questions like how can we

00:06:23,229 --> 00:06:26,050
teach sessions to machine so how we can

00:06:24,939 --> 00:06:27,610
give machine the same kind of

00:06:26,050 --> 00:06:29,979
understanding of what the intent is in a

00:06:27,610 --> 00:06:32,139
session and then once you do that how we

00:06:29,979 --> 00:06:33,759
can use these information so the way in

00:06:32,139 --> 00:06:35,830
which we understand intent to

00:06:33,759 --> 00:06:37,270
personalize language behavior we're

00:06:35,830 --> 00:06:40,000
gonna do you know we're gonna tackle

00:06:37,270 --> 00:06:41,650
these two questions in turn the first

00:06:40,000 --> 00:06:43,930
thing we're gonna do is that we're gonna

00:06:41,650 --> 00:06:47,589
build a vector space using deep learning

00:06:43,930 --> 00:06:48,130
we're gonna exploit technique noses work

00:06:47,589 --> 00:06:50,980
to back

00:06:48,130 --> 00:06:53,290
which many of you will be familiar with

00:06:50,980 --> 00:06:55,540
that Trey Granger discussed briefly

00:06:53,290 --> 00:06:56,620
about that like two stalks ago so we're

00:06:55,540 --> 00:06:58,300
not going to spend so much time on it

00:06:56,620 --> 00:07:02,140
but the general idea is that you can

00:06:58,300 --> 00:07:03,670
build a dense space of words by

00:07:02,140 --> 00:07:05,260
exploiting the fact that similar words

00:07:03,670 --> 00:07:07,150
appeared together in similar context

00:07:05,260 --> 00:07:08,980
right we're going to do the same but

00:07:07,150 --> 00:07:10,540
we're going to say with products because

00:07:08,980 --> 00:07:13,300
that's what people interacted with when

00:07:10,540 --> 00:07:14,560
they actually browse your web site the

00:07:13,300 --> 00:07:16,150
intuition is the same like similar

00:07:14,560 --> 00:07:19,210
products have been in similar browsing

00:07:16,150 --> 00:07:21,880
context it's kind of the machine

00:07:19,210 --> 00:07:23,620
learning counterpart to the saying of

00:07:21,880 --> 00:07:26,170
you can you know you know a lot of a man

00:07:23,620 --> 00:07:27,490
by the company keeps right this is the

00:07:26,170 --> 00:07:28,930
kind of same things like you know a lot

00:07:27,490 --> 00:07:31,120
about a product you can learn a lot

00:07:28,930 --> 00:07:32,860
about products by the company keeps in

00:07:31,120 --> 00:07:34,390
people session so if you think of

00:07:32,860 --> 00:07:35,830
typical word to vac training you will

00:07:34,390 --> 00:07:38,830
have something like you know talking in

00:07:35,830 --> 00:07:41,140
a session the cat is on the mat and this

00:07:38,830 --> 00:07:42,400
token are passed to desire government

00:07:41,140 --> 00:07:44,200
that's basically is going to be a dense

00:07:42,400 --> 00:07:46,930
representation of all these tokens like

00:07:44,200 --> 00:07:48,220
the cat is on what we're doing is proud

00:07:46,930 --> 00:07:50,140
to back is we're going to fit the same

00:07:48,220 --> 00:07:51,460
algún it's called Steve Graham I'm gonna

00:07:50,140 --> 00:07:53,530
fill this in my groin we're gonna fit

00:07:51,460 --> 00:07:55,360
products in a session so for example

00:07:53,530 --> 00:07:57,720
this is a ski team session and we're

00:07:55,360 --> 00:08:00,310
gonna fit this product to the argument

00:07:57,720 --> 00:08:02,250
what happens and this is a real vector

00:08:00,310 --> 00:08:05,800
space what happens when you do this in

00:08:02,250 --> 00:08:08,140
in in with real session data from you

00:08:05,800 --> 00:08:10,660
know hundreds of thousands of users is

00:08:08,140 --> 00:08:13,800
that you come up with a space where

00:08:10,660 --> 00:08:16,690
products are located depending on

00:08:13,800 --> 00:08:18,910
basically their latent properties so

00:08:16,690 --> 00:08:23,170
similar properties will be closer in the

00:08:18,910 --> 00:08:25,840
space if we understand product as a

00:08:23,170 --> 00:08:28,870
space now we have a way of representing

00:08:25,840 --> 00:08:34,240
user session as basically walk or path

00:08:28,870 --> 00:08:36,430
into that space so similar the sneakers

00:08:34,240 --> 00:08:39,580
would be in similar part of the of the

00:08:36,430 --> 00:08:42,840
of the space and if you imagine like

00:08:39,580 --> 00:08:44,950
representing a session of of a shopper

00:08:42,840 --> 00:08:46,210
that's looking for different pair of

00:08:44,950 --> 00:08:49,210
sneakers what what you're actually

00:08:46,210 --> 00:08:50,890
seeing it's some money in being in one

00:08:49,210 --> 00:08:53,920
part of the space is opposed to the

00:08:50,890 --> 00:08:56,710
other so what as humans we understand is

00:08:53,920 --> 00:08:58,120
your activity team or your interests or

00:08:56,710 --> 00:09:00,910
what people in commerce see because same

00:08:58,120 --> 00:09:04,030
intent is represented for machine

00:09:00,910 --> 00:09:05,890
as portion of this space again there's a

00:09:04,030 --> 00:09:07,810
clear analogy here you can tell a lot

00:09:05,890 --> 00:09:09,820
about people preferences if they say to

00:09:07,810 --> 00:09:14,790
you that they go on vacation on a Lulu

00:09:09,820 --> 00:09:17,920
or if they're going on vacation in Maine

00:09:14,790 --> 00:09:19,450
in the same way you can understand a lot

00:09:17,920 --> 00:09:23,550
about a person if you know where the

00:09:19,450 --> 00:09:26,440
person is in this in this abstract space

00:09:23,550 --> 00:09:28,810
so the way in which represent session is

00:09:26,440 --> 00:09:30,340
basically we every time the user is

00:09:28,810 --> 00:09:32,350
interacting with a product on your

00:09:30,340 --> 00:09:34,300
website we're going to capture that

00:09:32,350 --> 00:09:36,790
interaction and we're gonna place these

00:09:34,300 --> 00:09:39,070
users in the part of the space when that

00:09:36,790 --> 00:09:40,630
product is the more product you see the

00:09:39,070 --> 00:09:42,790
more basically remove this centroid

00:09:40,630 --> 00:09:45,010
around and so that is going to be our

00:09:42,790 --> 00:09:46,390
representation of your session the cool

00:09:45,010 --> 00:09:48,610
thing about this method is that it can

00:09:46,390 --> 00:09:51,220
be built in a completely unsupervised

00:09:48,610 --> 00:09:54,700
way right so as long as you have a way

00:09:51,220 --> 00:09:57,220
to track user interaction you can fit

00:09:54,700 --> 00:09:59,710
this to a proper back model and get

00:09:57,220 --> 00:10:01,690
automatically the space with no human

00:09:59,710 --> 00:10:04,900
intervention so all of these can be done

00:10:01,690 --> 00:10:07,150
at scale across many clients now the

00:10:04,900 --> 00:10:09,280
second question is how do we personalize

00:10:07,150 --> 00:10:10,930
the language remember that we want to

00:10:09,280 --> 00:10:12,850
provide Bob and Ann with different

00:10:10,930 --> 00:10:15,040
language suggestion how do personalized

00:10:12,850 --> 00:10:17,020
language based on this based on this

00:10:15,040 --> 00:10:18,850
information the answer to this is what

00:10:17,020 --> 00:10:21,160
it's called conditional language model

00:10:18,850 --> 00:10:22,810
so a language model generally you may

00:10:21,160 --> 00:10:24,460
you may you may you may probably know

00:10:22,810 --> 00:10:26,380
this it's just a probabilistic model

00:10:24,460 --> 00:10:29,140
they would have signed to any e-commerce

00:10:26,380 --> 00:10:31,540
a probability for any query for example

00:10:29,140 --> 00:10:33,610
if your if your shop is selling sport

00:10:31,540 --> 00:10:35,680
apparel the language model for your shop

00:10:33,610 --> 00:10:38,110
who tends to say that the probability of

00:10:35,680 --> 00:10:39,850
the word shoes in a query is much higher

00:10:38,110 --> 00:10:41,740
than the probability of the word - right

00:10:39,850 --> 00:10:45,310
because your query your shop is all

00:10:41,740 --> 00:10:47,710
about sport on the other hand if you're

00:10:45,310 --> 00:10:49,780
if you're dealing with an electronic

00:10:47,710 --> 00:10:51,910
shop your language model would probably

00:10:49,780 --> 00:10:53,680
tell you that the probability of iPhone

00:10:51,910 --> 00:10:55,150
is way bigger than the probability of

00:10:53,680 --> 00:10:56,740
shoes just because you know that that's

00:10:55,150 --> 00:10:58,810
what basically people are searching and

00:10:56,740 --> 00:11:01,930
buying on your on your shoes on your

00:10:58,810 --> 00:11:03,880
shop a conditional language model goes

00:11:01,930 --> 00:11:05,140
one step further so now we don't have

00:11:03,880 --> 00:11:07,360
just a model there are science

00:11:05,140 --> 00:11:09,400
probability to query we have a model

00:11:07,360 --> 00:11:11,650
that ascends provi to query taking into

00:11:09,400 --> 00:11:13,570
account the context so take into account

00:11:11,650 --> 00:11:14,890
the fact that for example you were

00:11:13,570 --> 00:11:16,950
browsing basketballs

00:11:14,890 --> 00:11:20,800
or you were browsing the family section

00:11:16,950 --> 00:11:22,630
we're gonna do that with the general

00:11:20,800 --> 00:11:24,730
architecture in deep learning which is

00:11:22,630 --> 00:11:27,250
called the encoder/decoder architecture

00:11:24,730 --> 00:11:29,980
the idea here is that you have basically

00:11:27,250 --> 00:11:33,010
two neural network one your network

00:11:29,980 --> 00:11:36,640
which takes which has the task of

00:11:33,010 --> 00:11:38,980
encoding in a in a single Aten space the

00:11:36,640 --> 00:11:40,630
information about the session as we saw

00:11:38,980 --> 00:11:43,510
information about the session is

00:11:40,630 --> 00:11:45,370
captured for us using products or using

00:11:43,510 --> 00:11:49,210
the product space that we generated and

00:11:45,370 --> 00:11:51,040
then the encoded session is fed to a

00:11:49,210 --> 00:11:54,670
decoder network which is another network

00:11:51,040 --> 00:11:59,440
that has the the job of starting from

00:11:54,670 --> 00:12:02,860
that lattin's state basically generate

00:11:59,440 --> 00:12:04,480
the language we want in our case again

00:12:02,860 --> 00:12:06,430
the first part is gonna is gonna is

00:12:04,480 --> 00:12:08,500
going to be provided by prof. track so

00:12:06,430 --> 00:12:10,480
our skipper model and the second part is

00:12:08,500 --> 00:12:12,280
provided by a type on your a recurrent

00:12:10,480 --> 00:12:14,890
neural network which is known as LS TM

00:12:12,280 --> 00:12:17,020
which is the peripheral network in case

00:12:14,890 --> 00:12:19,210
you want to deal with with language and

00:12:17,020 --> 00:12:20,830
you know generating sequence of things

00:12:19,210 --> 00:12:23,650
in our case generating sequence of

00:12:20,830 --> 00:12:25,270
characters so the answer to our second

00:12:23,650 --> 00:12:28,780
question which is how can you session to

00:12:25,270 --> 00:12:30,400
personalized languages well we take the

00:12:28,780 --> 00:12:32,440
encoder decoder model from the deep

00:12:30,400 --> 00:12:34,240
learning literature and we use it as our

00:12:32,440 --> 00:12:35,980
conditional language model so in this

00:12:34,240 --> 00:12:38,590
case language probabilities so the

00:12:35,980 --> 00:12:40,600
probability of nicely brown shoes versus

00:12:38,590 --> 00:12:43,450
natal racket will depend both on

00:12:40,600 --> 00:12:47,320
linguistic information that is how much

00:12:43,450 --> 00:12:49,420
natal and an IKE our query direct

00:12:47,320 --> 00:12:51,010
popular in the e-commerce and session

00:12:49,420 --> 00:12:53,620
data which is you know based on the fact

00:12:51,010 --> 00:12:55,360
that you know annum Bob this very

00:12:53,620 --> 00:12:57,100
different part of the product space so

00:12:55,360 --> 00:12:58,810
probably they would expect the behavior

00:12:57,100 --> 00:13:03,220
of the search part to reflect those

00:12:58,810 --> 00:13:06,190
real-time intent so does it work well

00:13:03,220 --> 00:13:10,180
the too long did the transfer is yes and

00:13:06,190 --> 00:13:13,680
we extensively test this these our

00:13:10,180 --> 00:13:17,590
search idea against you know some

00:13:13,680 --> 00:13:21,370
industry and research baseline not gonna

00:13:17,590 --> 00:13:23,410
spend like an awful amount of time on on

00:13:21,370 --> 00:13:25,390
these numbers as there's like the

00:13:23,410 --> 00:13:27,550
presentation as all the links to the

00:13:25,390 --> 00:13:29,020
actual research papers and the things we

00:13:27,550 --> 00:13:30,880
publish an open source code

00:13:29,020 --> 00:13:32,740
as I think you know it's it's it's more

00:13:30,880 --> 00:13:35,170
interesting if we discuss the general

00:13:32,740 --> 00:13:37,300
vibe instead of the numbers but what you

00:13:35,170 --> 00:13:39,390
can see here so we basically test our

00:13:37,300 --> 00:13:43,090
method which is called vector sequence

00:13:39,390 --> 00:13:45,970
with different lengths on the on the

00:13:43,090 --> 00:13:48,100
suggestion bar so zero is when nothing

00:13:45,970 --> 00:13:49,510
has been typed so is when the user just

00:13:48,100 --> 00:13:52,630
click on the search bar and you have to

00:13:49,510 --> 00:13:54,370
basically infer everything SL equals one

00:13:52,630 --> 00:13:56,220
is that when the user type one character

00:13:54,370 --> 00:13:59,080
SL equals two is when the user actually

00:13:56,220 --> 00:14:01,390
type two characters we bench my design

00:13:59,080 --> 00:14:03,070
in popularity which is what most people

00:14:01,390 --> 00:14:03,700
are doing in the industry I think it's a

00:14:03,070 --> 00:14:05,860
fair assessment

00:14:03,700 --> 00:14:07,180
so basically ranking queries suggestion

00:14:05,860 --> 00:14:10,390
based on you know how popular they are

00:14:07,180 --> 00:14:12,250
and we try different way in which we can

00:14:10,390 --> 00:14:13,990
use dense vectors to personalize

00:14:12,250 --> 00:14:16,750
experience one is called image to

00:14:13,990 --> 00:14:18,700
sequence which instead of using the deep

00:14:16,750 --> 00:14:20,710
rod of space that we we explained is

00:14:18,700 --> 00:14:22,450
using the images of the product cut out

00:14:20,710 --> 00:14:24,400
so the idea here is that when the user

00:14:22,450 --> 00:14:26,440
interact with some product in a session

00:14:24,400 --> 00:14:28,600
yet struct without convolutional neural

00:14:26,440 --> 00:14:30,190
network deep features from that image

00:14:28,600 --> 00:14:32,290
from the image of the product and use

00:14:30,190 --> 00:14:34,240
that in your encoder but the cool thing

00:14:32,290 --> 00:14:36,760
about encoder decoder architectures that

00:14:34,240 --> 00:14:38,440
they're very general so you can swap in

00:14:36,760 --> 00:14:40,450
and swap out different encoding and

00:14:38,440 --> 00:14:42,100
basically with basically no changes to

00:14:40,450 --> 00:14:44,380
the underlying code you can train many

00:14:42,100 --> 00:14:46,420
different models search to protract is a

00:14:44,380 --> 00:14:48,790
is a is a different alternative to the

00:14:46,420 --> 00:14:51,520
full encoder decoder ranking still based

00:14:48,790 --> 00:14:53,530
on on deep factors panel just that we

00:14:51,520 --> 00:14:55,900
play slightly different flavor and

00:14:53,530 --> 00:14:57,670
vector sequence is our model which as

00:14:55,900 --> 00:15:00,880
you see outperform all the other models

00:14:57,670 --> 00:15:03,040
by a significant margin in particular

00:15:00,880 --> 00:15:06,520
with the empty query is 10x so it is ten

00:15:03,040 --> 00:15:09,810
times better in MRI than the than the

00:15:06,520 --> 00:15:12,420
typical frequency based model any still

00:15:09,810 --> 00:15:15,430
more you know more than twice as much

00:15:12,420 --> 00:15:17,830
accurate with one character queries if

00:15:15,430 --> 00:15:20,980
you want to see like real example of

00:15:17,830 --> 00:15:22,420
what would happen and with the model so

00:15:20,980 --> 00:15:24,340
these are the products these are like

00:15:22,420 --> 00:15:26,050
first session the product is an image of

00:15:24,340 --> 00:15:27,730
the product that has been interacted

00:15:26,050 --> 00:15:29,740
with with the user the seed is the

00:15:27,730 --> 00:15:30,910
lecture that has been typed and then we

00:15:29,740 --> 00:15:33,010
have this distinguishing between

00:15:30,910 --> 00:15:35,140
popularity and the encoder decoder

00:15:33,010 --> 00:15:37,150
model that we propose this query

00:15:35,140 --> 00:15:38,680
untranslated so there are region from

00:15:37,150 --> 00:15:40,660
different language and that's why

00:15:38,680 --> 00:15:41,760
sometimes you know the see that and be

00:15:40,660 --> 00:15:43,709
in the

00:15:41,760 --> 00:15:45,690
and the end this thing doesn't really

00:15:43,709 --> 00:15:47,940
match but it gives you like a good

00:15:45,690 --> 00:15:49,800
flavor of how well the model is

00:15:47,940 --> 00:15:51,510
capturing their lying intention like if

00:15:49,800 --> 00:15:54,050
you take for example the second row you

00:15:51,510 --> 00:15:56,459
have a tennis racket the CDs are and

00:15:54,050 --> 00:15:59,339
obviously the popularity model you know

00:15:56,459 --> 00:16:02,610
tennis is popular in in Italy but not so

00:15:59,339 --> 00:16:04,800
much so the things are way more popular

00:16:02,610 --> 00:16:07,470
and so the model will suggest you know

00:16:04,800 --> 00:16:09,149
Reebok CrossFit but the model that we

00:16:07,470 --> 00:16:11,430
built actually is able to capture the

00:16:09,149 --> 00:16:14,040
intent the family's intent and actually

00:16:11,430 --> 00:16:15,570
propose tennis racket as the best as the

00:16:14,040 --> 00:16:17,190
best suggestion and you see the other

00:16:15,570 --> 00:16:20,399
the other it can pose well I think it's

00:16:17,190 --> 00:16:23,490
it's very it's very easy to get why the

00:16:20,399 --> 00:16:27,630
model is qualitatively way better than a

00:16:23,490 --> 00:16:30,750
pure frequency based model so now that

00:16:27,630 --> 00:16:33,209
we now that we know we capture session

00:16:30,750 --> 00:16:35,190
intent so we don't assume anything about

00:16:33,209 --> 00:16:36,839
the user except the interaction within

00:16:35,190 --> 00:16:39,380
the current session and now that we know

00:16:36,839 --> 00:16:41,820
how to generate language model

00:16:39,380 --> 00:16:47,880
probability based on that we're going to

00:16:41,820 --> 00:16:50,730
take this one step further so since it's

00:16:47,880 --> 00:16:53,339
very very very very hard to get user

00:16:50,730 --> 00:16:55,890
coming back to your shop the question is

00:16:53,339 --> 00:17:00,390
what if what if context is from a

00:16:55,890 --> 00:17:01,649
different shop so now we discussed you

00:17:00,390 --> 00:17:05,250
know we discussed that it's it's very

00:17:01,649 --> 00:17:08,160
important to to be able to personalize

00:17:05,250 --> 00:17:09,980
the experience of the user with as

00:17:08,160 --> 00:17:11,730
little data as possible from one website

00:17:09,980 --> 00:17:13,829
now we're going to take these two

00:17:11,730 --> 00:17:15,870
extreme and we're gonna we're going to

00:17:13,829 --> 00:17:18,500
try and personalize pub experience when

00:17:15,870 --> 00:17:23,669
Bob is browsing a basketball product on

00:17:18,500 --> 00:17:25,770
on shop number one then you leave shop

00:17:23,669 --> 00:17:27,600
number one it goes on shop number two

00:17:25,770 --> 00:17:30,419
and the first thing he does is press M

00:17:27,600 --> 00:17:33,150
on shop number two so the question is

00:17:30,419 --> 00:17:35,100
shop number two never so Bob before shop

00:17:33,150 --> 00:17:36,630
number two may or may not be affiliated

00:17:35,100 --> 00:17:38,880
with shop number one we're gonna discuss

00:17:36,630 --> 00:17:41,610
that later and the question is can we

00:17:38,880 --> 00:17:44,220
actually personalize Bob experience with

00:17:41,610 --> 00:17:47,990
zero literally zero data point on shop

00:17:44,220 --> 00:17:50,640
number two to see how that is even

00:17:47,990 --> 00:17:52,710
theoretically possible it may be good to

00:17:50,640 --> 00:17:55,350
like you know explore a sample of the

00:17:52,710 --> 00:17:58,410
product base for two shops in the

00:17:55,350 --> 00:18:00,300
Sport apparel business as you can see

00:17:58,410 --> 00:18:01,860
here the shops obviously are different

00:18:00,300 --> 00:18:03,450
this space is gonna be different for the

00:18:01,860 --> 00:18:04,860
proper you know they have different

00:18:03,450 --> 00:18:06,450
catalogs and you know different

00:18:04,860 --> 00:18:08,640
different direction may have very

00:18:06,450 --> 00:18:11,490
different traffic but there are some

00:18:08,640 --> 00:18:14,070
analogy now things are actually in the

00:18:11,490 --> 00:18:16,230
space in the in the case in the in the

00:18:14,070 --> 00:18:19,470
simple case you can see that snowboards

00:18:16,230 --> 00:18:21,630
and and a soccer ball a can of in the

00:18:19,470 --> 00:18:23,970
same position in shop 1 and shop two if

00:18:21,630 --> 00:18:26,970
you flip the space with the

00:18:23,970 --> 00:18:30,150
transformation this thing should remind

00:18:26,970 --> 00:18:32,460
you of NLP literature where people

00:18:30,150 --> 00:18:34,890
actually add the same observation about

00:18:32,460 --> 00:18:36,840
word to vac remember the word vector we

00:18:34,890 --> 00:18:38,010
discussed well let's imagine that

00:18:36,840 --> 00:18:40,170
instead of having shops you have

00:18:38,010 --> 00:18:42,330
languages so now you have English and

00:18:40,170 --> 00:18:44,040
you have Spanish and the idea is that

00:18:42,330 --> 00:18:46,110
you will train your vectors and then you

00:18:44,040 --> 00:18:48,390
project your vectors into into a space

00:18:46,110 --> 00:18:51,390
what'd you find out I think this is this

00:18:48,390 --> 00:18:53,550
is pretty cool is that English and

00:18:51,390 --> 00:18:56,580
Spanish you can immediately draw like

00:18:53,550 --> 00:18:59,130
some sort of analogy of what four is in

00:18:56,580 --> 00:19:00,660
one side and four is in the other so the

00:18:59,130 --> 00:19:03,090
idea is that if these things are not

00:19:00,660 --> 00:19:05,070
exactly the same but somehow they're

00:19:03,090 --> 00:19:07,740
topologically similar maybe there's a

00:19:05,070 --> 00:19:10,020
way to go from one into the other you

00:19:07,740 --> 00:19:13,050
can actually exploit these you know

00:19:10,020 --> 00:19:14,430
analogy even further if you know how you

00:19:13,050 --> 00:19:18,240
know neural translation model actually

00:19:14,430 --> 00:19:19,740
work into these days so if you go and

00:19:18,240 --> 00:19:21,930
google translate and you and your side

00:19:19,740 --> 00:19:23,970
may be actually kinda means I like talks

00:19:21,930 --> 00:19:25,980
in Italian and you want that to be

00:19:23,970 --> 00:19:30,000
translated in French what happens

00:19:25,980 --> 00:19:32,340
simplifying a bit is again another sort

00:19:30,000 --> 00:19:33,870
of encoding and decoding so yang the

00:19:32,340 --> 00:19:36,030
scene there are two neural network one

00:19:33,870 --> 00:19:37,380
which is taking the English or the

00:19:36,030 --> 00:19:39,750
Italian or whatever whatever language

00:19:37,380 --> 00:19:40,980
you want is encoding into Latin space

00:19:39,750 --> 00:19:43,950
and then there's a neural network that

00:19:40,980 --> 00:19:46,500
decodes it's in the target space so what

00:19:43,950 --> 00:19:48,750
we did again following the analogy with

00:19:46,500 --> 00:19:52,260
the NLP word is that we're treating

00:19:48,750 --> 00:19:54,870
shops as languages so what we train a

00:19:52,260 --> 00:19:57,690
deeply neuron model to do we train a

00:19:54,870 --> 00:20:00,330
model to basically translate from

00:19:57,690 --> 00:20:03,210
products in one space to product into

00:20:00,330 --> 00:20:04,890
another space in the same sense you can

00:20:03,210 --> 00:20:07,260
train a language model that you can

00:20:04,890 --> 00:20:08,669
actually that you can actually translate

00:20:07,260 --> 00:20:11,879
between French

00:20:08,669 --> 00:20:17,039
English or English and Germany so the

00:20:11,879 --> 00:20:18,779
results are very good again we call it

00:20:17,039 --> 00:20:20,489
zero shot in France because in shop -

00:20:18,779 --> 00:20:22,139
you have no information about Bob so the

00:20:20,489 --> 00:20:24,269
only things you can do is that you can

00:20:22,139 --> 00:20:26,489
move the intent then you learn a shot

00:20:24,269 --> 00:20:28,769
one using Proctor back you translate it

00:20:26,489 --> 00:20:30,359
using an Iran translation model and then

00:20:28,769 --> 00:20:32,820
you use that to condition your your

00:20:30,359 --> 00:20:34,409
probability as you can see like three

00:20:32,820 --> 00:20:35,940
different we benchmark three four and

00:20:34,409 --> 00:20:38,730
model one is the non-personalized which

00:20:35,940 --> 00:20:41,070
is what basically everybody's doing at

00:20:38,730 --> 00:20:42,480
the moment so if the shopper is new to

00:20:41,070 --> 00:20:43,739
this website we're going to count it as

00:20:42,480 --> 00:20:45,779
view so there's no personalization

00:20:43,739 --> 00:20:49,019
involved weights there is an

00:20:45,779 --> 00:20:50,549
unsupervised version in which you it's a

00:20:49,019 --> 00:20:52,799
bit complex but in which you use

00:20:50,549 --> 00:20:55,230
basically the images into catalogue to

00:20:52,799 --> 00:20:57,480
build some sort of guide for the

00:20:55,230 --> 00:20:59,690
alignment of these two factor space and

00:20:57,480 --> 00:21:02,220
the supervised translation that we just

00:20:59,690 --> 00:21:05,070
discussed a bit more as you can see

00:21:02,220 --> 00:21:07,830
obviously the proposed model vastly

00:21:05,070 --> 00:21:10,139
outperforms the non-personalized

00:21:07,830 --> 00:21:11,730
baseline and even the unsupervised

00:21:10,139 --> 00:21:14,580
version so the version in which you

00:21:11,730 --> 00:21:15,899
don't have any data when a user goes

00:21:14,580 --> 00:21:18,179
from one shop to the other so the

00:21:15,899 --> 00:21:20,580
version is completely unsupervised it's

00:21:18,179 --> 00:21:27,989
still better than the non

00:21:20,580 --> 00:21:30,179
personalization so as for the conclusion

00:21:27,989 --> 00:21:33,419
and next step and then I think we have a

00:21:30,179 --> 00:21:37,169
bit of time to discuss the details and

00:21:33,419 --> 00:21:38,909
you know like the use cases well this

00:21:37,169 --> 00:21:41,009
whole idea of personalizing things with

00:21:38,909 --> 00:21:42,929
intent it's very scalable as it can

00:21:41,009 --> 00:21:44,820
build it can be built in a completely

00:21:42,929 --> 00:21:46,470
unsupervised fashion and it can build in

00:21:44,820 --> 00:21:49,200
a very scalable fashion either for very

00:21:46,470 --> 00:21:50,820
big for very big ecommerce and can be

00:21:49,200 --> 00:21:52,739
used to inject personalization in all

00:21:50,820 --> 00:21:54,629
deep architecture that you want let's

00:21:52,739 --> 00:21:57,539
take another case of type-ahead

00:21:54,629 --> 00:22:00,899
now we're not trying to predict the word

00:21:57,539 --> 00:22:03,809
itself like an Nike but we're trying to

00:22:00,899 --> 00:22:05,609
suggest the category to narrow down your

00:22:03,809 --> 00:22:07,350
result I mean if you go on most

00:22:05,609 --> 00:22:09,629
ecommerce but you know Amazon eBay and

00:22:07,350 --> 00:22:12,299
so on once you start typing sometime the

00:22:09,629 --> 00:22:14,850
e-commerce will nod you in selecting a

00:22:12,299 --> 00:22:17,279
specific category or specific facet in

00:22:14,850 --> 00:22:19,739
which we execute the search right would

00:22:17,279 --> 00:22:22,380
it be nice if that category will all

00:22:19,739 --> 00:22:23,790
would also be complete

00:22:22,380 --> 00:22:26,160
personalized depending on what you're

00:22:23,790 --> 00:22:28,560
doing and you can basically use the same

00:22:26,160 --> 00:22:30,120
idea of you know plot to vac encoder

00:22:28,560 --> 00:22:32,250
decoding and so on and support you can

00:22:30,120 --> 00:22:34,590
basic applied the same idea to provide

00:22:32,250 --> 00:22:36,620
people with personalized category

00:22:34,590 --> 00:22:38,190
suggestions not just suggestion itself

00:22:36,620 --> 00:22:40,590
if you want

00:22:38,190 --> 00:22:43,260
we recently share like open source code

00:22:40,590 --> 00:22:46,650
in a paper to actually get you started

00:22:43,260 --> 00:22:48,810
with this problem if you want to learn

00:22:46,650 --> 00:22:50,670
more as I understand we cover a lot of

00:22:48,810 --> 00:22:53,700
things and obviously we have to skip

00:22:50,670 --> 00:22:56,610
over a lot of technical details you can

00:22:53,700 --> 00:22:59,550
obviously the load our papers and and

00:22:56,610 --> 00:23:03,180
and research work we presented you know

00:22:59,550 --> 00:23:04,560
this work with at the web conference in

00:23:03,180 --> 00:23:07,380
Taipei we're going to present part of

00:23:04,560 --> 00:23:10,650
this work at ACL in July I mean

00:23:07,380 --> 00:23:13,170
virtually in July and the work is public

00:23:10,650 --> 00:23:16,980
and often we also share code and

00:23:13,170 --> 00:23:20,280
implementation if you want to take part

00:23:16,980 --> 00:23:22,800
in our experiments or work with us on

00:23:20,280 --> 00:23:24,240
specific things please get in touch we

00:23:22,800 --> 00:23:27,330
already have like live collaboration

00:23:24,240 --> 00:23:29,880
with world-class institution like Max of

00:23:27,330 --> 00:23:31,470
research Bocconi University and

00:23:29,880 --> 00:23:34,560
researcher from all around the world

00:23:31,470 --> 00:23:37,380
join us to improve the state of the art

00:23:34,560 --> 00:23:40,290
of NLP nai in commerce and search in

00:23:37,380 --> 00:23:42,450
general if you prefer something a bit

00:23:40,290 --> 00:23:45,480
lighter than full research paper we also

00:23:42,450 --> 00:23:48,360
try to blog and popularize and

00:23:45,480 --> 00:23:51,660
evangelize the field in a more with more

00:23:48,360 --> 00:23:53,940
a more gentle touch so please go on our

00:23:51,660 --> 00:23:55,620
website and you will find like

00:23:53,940 --> 00:23:57,360
high-level description about these use

00:23:55,620 --> 00:23:59,520
cases with a more of a let's say

00:23:57,360 --> 00:24:03,960
industry angle than just a pure

00:23:59,520 --> 00:24:06,240
scientific angle obviously we touch only

00:24:03,960 --> 00:24:08,490
like a like a tiny portion of what is

00:24:06,240 --> 00:24:11,160
the what is the possibilities of

00:24:08,490 --> 00:24:13,890
personalization in commerce but

00:24:11,160 --> 00:24:16,320
hopefully with we we got the impression

00:24:13,890 --> 00:24:18,720
of the amount of information that it's

00:24:16,320 --> 00:24:20,280
hidden in a session and how many cool

00:24:18,720 --> 00:24:23,160
things we can do if you find a way to

00:24:20,280 --> 00:24:25,020
unlock them I always like to finish my

00:24:23,160 --> 00:24:27,870
thoughts with the we record from Alan

00:24:25,020 --> 00:24:30,210
Turing to week to whom we base gave her

00:24:27,870 --> 00:24:31,740
everything and we can always see a short

00:24:30,210 --> 00:24:34,620
distance ahead but we can see plenty

00:24:31,740 --> 00:24:35,940
there the needs to be done as always say

00:24:34,620 --> 00:24:38,700
let's not forget

00:24:35,940 --> 00:24:45,809
it's up to us to get it done thanks so

00:24:38,700 --> 00:24:47,309
much for for listening to this fantastic

00:24:45,809 --> 00:24:49,740
thank you very cocoa

00:24:47,309 --> 00:24:52,740
we've got certainly got some questions

00:24:49,740 --> 00:24:56,250
in the channel for you so I'll start off

00:24:52,740 --> 00:24:57,809
with a question from Matteo what's the

00:24:56,250 --> 00:25:00,090
strategy to apply this approach to

00:24:57,809 --> 00:25:01,649
e-commerce sites that are new or that

00:25:00,090 --> 00:25:05,730
haven't properly collected user

00:25:01,649 --> 00:25:09,149
interactions in the past you have very

00:25:05,730 --> 00:25:13,409
very good questions so for the within

00:25:09,149 --> 00:25:15,570
shop case I would suggest to start with

00:25:13,409 --> 00:25:17,669
the image version that we that we

00:25:15,570 --> 00:25:19,889
briefly discuss and that is discussed at

00:25:17,669 --> 00:25:21,809
length in the paper the idea is that you

00:25:19,889 --> 00:25:23,100
can jump start instead of waiting to

00:25:21,809 --> 00:25:25,590
utak for you to collect enough

00:25:23,100 --> 00:25:27,750
interaction to train a proper route to

00:25:25,590 --> 00:25:29,850
back model which may take a couple of

00:25:27,750 --> 00:25:32,399
months or even more depending on the

00:25:29,850 --> 00:25:35,039
traffic if you can just collect like you

00:25:32,399 --> 00:25:36,809
know interactions and use the images in

00:25:35,039 --> 00:25:38,970
the catalog which never changes and

00:25:36,809 --> 00:25:40,320
they're available at day one you can try

00:25:38,970 --> 00:25:42,629
and use that to basically build a

00:25:40,320 --> 00:25:45,360
personalization strategy as for the same

00:25:42,629 --> 00:25:47,460
question cross shop that really depends

00:25:45,360 --> 00:25:48,840
like the best thing is that like some of

00:25:47,460 --> 00:25:52,590
the biggest retailers in the world a

00:25:48,840 --> 00:25:54,870
multi group brand gap West Nike and so

00:25:52,590 --> 00:25:57,240
on so ideally they probably have

00:25:54,870 --> 00:25:58,980
historical data on what people do when

00:25:57,240 --> 00:26:01,320
they move from one brand to the other

00:25:58,980 --> 00:26:03,299
and in that case you can use the

00:26:01,320 --> 00:26:05,159
supervised translation method that I

00:26:03,299 --> 00:26:06,870
explained but there's another method

00:26:05,159 --> 00:26:09,360
which what we call unsupervised

00:26:06,870 --> 00:26:11,669
which doesn't rely on any cross tracking

00:26:09,360 --> 00:26:13,919
so as long as we have data from shop one

00:26:11,669 --> 00:26:16,379
and data from shop B let's say banana

00:26:13,919 --> 00:26:18,929
republic and gap as long as you have

00:26:16,379 --> 00:26:20,970
those data separately you can use the

00:26:18,929 --> 00:26:23,039
method we propose to align this space

00:26:20,970 --> 00:26:27,570
and then you can do basically zero shot

00:26:23,039 --> 00:26:32,070
inference okay thank you so our next

00:26:27,570 --> 00:26:33,690
question is from Jim Walker you said you

00:26:32,070 --> 00:26:35,519
had a slide referencing an industry

00:26:33,690 --> 00:26:37,620
baseline you were able to exceed by 10

00:26:35,519 --> 00:26:41,009
times can you clarify what that

00:26:37,620 --> 00:26:43,019
benchmark is yes surely I mean by it by

00:26:41,009 --> 00:26:45,480
industry baseline a means a noisy

00:26:43,019 --> 00:26:47,250
channel models when like when dipandi

00:26:45,480 --> 00:26:49,379
when the when the language model is

00:26:47,250 --> 00:26:49,710
estimated as a pure language model so

00:26:49,379 --> 00:26:51,659
not

00:26:49,710 --> 00:26:54,539
our model and is estimated purely from

00:26:51,659 --> 00:26:58,740
empirical frequencies yeah so that that

00:26:54,539 --> 00:27:00,630
would be will be I mean I would say as a

00:26:58,740 --> 00:27:03,090
reason approximation of like non

00:27:00,630 --> 00:27:04,860
sophisticated approach in the industry

00:27:03,090 --> 00:27:06,750
but also the one that's clearly more

00:27:04,860 --> 00:27:08,549
common as all the other baseline are

00:27:06,750 --> 00:27:10,110
deep learning based which are way more

00:27:08,549 --> 00:27:12,600
sophisticated in fact are more accurate

00:27:10,110 --> 00:27:13,740
than than this simple heuristic but then

00:27:12,600 --> 00:27:15,899
if you actually go and see what

00:27:13,740 --> 00:27:17,940
retailers are doing nowadays the number

00:27:15,899 --> 00:27:20,370
of retailers they will actually have

00:27:17,940 --> 00:27:22,740
already deep learning in place would be

00:27:20,370 --> 00:27:24,690
like a like a like incredible minority

00:27:22,740 --> 00:27:27,000
so when I say industry I understand is a

00:27:24,690 --> 00:27:28,529
generalization but I think I mean this

00:27:27,000 --> 00:27:31,309
is landed in my experience in the

00:27:28,529 --> 00:27:33,950
individual business okay thank you okay

00:27:31,309 --> 00:27:36,929
while that answers your question

00:27:33,950 --> 00:27:39,450
andreas factor how do you handle the

00:27:36,929 --> 00:27:42,720
cold start problem for new words phrases

00:27:39,450 --> 00:27:45,740
new brands new product names D so there

00:27:42,720 --> 00:27:50,850
are two things you can do so what one so

00:27:45,740 --> 00:27:52,980
everything we do in the in the NL in the

00:27:50,850 --> 00:27:55,470
type I'd space is based on what it's

00:27:52,980 --> 00:27:57,539
normally known as the retain memory rank

00:27:55,470 --> 00:27:59,700
kind of idea so you have a very fast

00:27:57,539 --> 00:28:01,500
model that approves first a bunch of

00:27:59,700 --> 00:28:03,929
suggestion and then use deep learning or

00:28:01,500 --> 00:28:06,960
very sophisticated stuff to Ray rank

00:28:03,929 --> 00:28:09,090
things so since you cannot really

00:28:06,960 --> 00:28:11,340
suggest things that didn't appear before

00:28:09,090 --> 00:28:13,020
if there's not a probability there that

00:28:11,340 --> 00:28:15,270
doesn't really that doesn't really

00:28:13,020 --> 00:28:16,590
happen on the linguistic side so the

00:28:15,270 --> 00:28:18,809
cold start problem for the linguist if I

00:28:16,590 --> 00:28:20,100
is not really a problem for products is

00:28:18,809 --> 00:28:23,490
more interesting we have a public web

00:28:20,100 --> 00:28:25,200
and other like publication in in machine

00:28:23,490 --> 00:28:27,120
learning conference coming up and the

00:28:25,200 --> 00:28:29,130
idea is that you do two things first you

00:28:27,120 --> 00:28:31,049
train a proctor back model based on all

00:28:29,130 --> 00:28:33,330
the interaction of your website then you

00:28:31,049 --> 00:28:35,460
discard the vectors that has been

00:28:33,330 --> 00:28:37,860
generated for rare sk use or of course

00:28:35,460 --> 00:28:41,190
new SKU won't even be there but then use

00:28:37,860 --> 00:28:42,870
another model to basically fake or infer

00:28:41,190 --> 00:28:45,000
the position of these new or rail

00:28:42,870 --> 00:28:46,830
vectors into the space so for that

00:28:45,000 --> 00:28:50,130
without weather long it was a longer

00:28:46,830 --> 00:28:51,929
another talk another paper to to present

00:28:50,130 --> 00:28:53,700
about be super happy to share you I mean

00:28:51,929 --> 00:28:57,899
if you reach out to me like privately I

00:28:53,700 --> 00:28:59,250
can share the draft of the work that's

00:28:57,899 --> 00:29:01,919
are saying thank you

00:28:59,250 --> 00:29:03,360
diva asks if you conducted online

00:29:01,919 --> 00:29:07,890
evaluation in addition to

00:29:03,360 --> 00:29:11,400
of an evaluation for this one not not

00:29:07,890 --> 00:29:12,870
now so we did online evaluation for the

00:29:11,400 --> 00:29:17,610
I don't know if you still see my screen

00:29:12,870 --> 00:29:20,490
do you see McLean no no okay okay but

00:29:17,610 --> 00:29:22,590
yeah so at some example screens visible

00:29:20,490 --> 00:29:24,090
now okay yeah okay so that's a no point

00:29:22,590 --> 00:29:26,400
like I mentioned the fact that you can

00:29:24,090 --> 00:29:28,260
use the same kind of architecture with

00:29:26,400 --> 00:29:31,380
some twisties obviously but you can use

00:29:28,260 --> 00:29:34,679
that to personalize the category in

00:29:31,380 --> 00:29:37,679
type-ahead for that we did some online

00:29:34,679 --> 00:29:39,630
testing and and improve like

00:29:37,679 --> 00:29:41,940
statistically significant uplift of

00:29:39,630 --> 00:29:44,340
course the magnitude of the of leap will

00:29:41,940 --> 00:29:46,440
heavily depend on how good the system

00:29:44,340 --> 00:29:47,970
was in the first place so if we're

00:29:46,440 --> 00:29:49,710
always testing against ourselves which

00:29:47,970 --> 00:29:51,720
we are already using deploy which were

00:29:49,710 --> 00:29:53,580
ready using good models the uplift is

00:29:51,720 --> 00:29:55,830
marginal but if you think of applying

00:29:53,580 --> 00:29:57,540
that to a standard numbers MySpace line

00:29:55,830 --> 00:30:01,590
the uplift would be of course much

00:29:57,540 --> 00:30:03,570
bigger okay okay thank you not in US how

00:30:01,590 --> 00:30:06,299
do you detect or handle the change of

00:30:03,570 --> 00:30:08,100
user intent I are you searching for two

00:30:06,299 --> 00:30:10,980
related items in the same session like a

00:30:08,100 --> 00:30:12,570
shirt and a pair of trousers that's a

00:30:10,980 --> 00:30:14,220
very good question so what happens when

00:30:12,570 --> 00:30:18,390
you look I mean at least when you look

00:30:14,220 --> 00:30:20,280
at at the typical customer like it sites

00:30:18,390 --> 00:30:21,750
customers say people making I don't know

00:30:20,280 --> 00:30:22,860
you know between between twenty-five and

00:30:21,750 --> 00:30:26,250
a hundred million dollars online

00:30:22,860 --> 00:30:27,660
revenues so Alex are ranking between ten

00:30:26,250 --> 00:30:29,730
thousand a hundred thousand just to give

00:30:27,660 --> 00:30:32,490
you like a frame of reference so bid to

00:30:29,730 --> 00:30:33,630
make ecommerce what we find out at

00:30:32,490 --> 00:30:36,809
leasing the verticals that we know very

00:30:33,630 --> 00:30:39,330
well is that change of intent for people

00:30:36,809 --> 00:30:41,700
is not as frequent as you may as you may

00:30:39,330 --> 00:30:44,309
imagine so when people go on a web site

00:30:41,700 --> 00:30:45,900
like a lot of time they tends to be in

00:30:44,309 --> 00:30:48,000
the sport opera busy for games they tend

00:30:45,900 --> 00:30:50,370
to be mono activity that's not always

00:30:48,000 --> 00:30:52,169
true though so and what what happened

00:30:50,370 --> 00:30:53,700
there you can do a bunch of things you

00:30:52,169 --> 00:30:55,860
can either take instead of taking

00:30:53,700 --> 00:30:57,660
imagine imagine following this person in

00:30:55,860 --> 00:30:59,460
the product space right now basically

00:30:57,660 --> 00:31:01,650
what you're saying changing of intent

00:30:59,460 --> 00:31:04,020
meaning that you go from one part of the

00:31:01,650 --> 00:31:06,660
product space and you suddenly go to

00:31:04,020 --> 00:31:08,460
another part so what you can do when you

00:31:06,660 --> 00:31:10,650
build this representation you can either

00:31:08,460 --> 00:31:12,750
discard all the information so you can

00:31:10,650 --> 00:31:14,130
for example weight the vectors you know

00:31:12,750 --> 00:31:17,289
by recency like you know like

00:31:14,130 --> 00:31:19,179
exponential discounting you know older

00:31:17,289 --> 00:31:21,760
older product you interacted with so

00:31:19,179 --> 00:31:23,320
this session will very much react to the

00:31:21,760 --> 00:31:25,149
latest thing you're doing so that's one

00:31:23,320 --> 00:31:26,860
option the other option again because

00:31:25,149 --> 00:31:29,620
encoder/decoder is so flexible is that

00:31:26,860 --> 00:31:31,059
you can replace the encoder we propose

00:31:29,620 --> 00:31:32,740
which is the centroid of all the

00:31:31,059 --> 00:31:34,210
products you interacted with and you can

00:31:32,740 --> 00:31:36,039
actually use the net HTM that as well

00:31:34,210 --> 00:31:37,929
you can basically do sequence scenes and

00:31:36,039 --> 00:31:39,970
sequence out so now the model will be

00:31:37,929 --> 00:31:41,740
able to condition is give you basically

00:31:39,970 --> 00:31:44,529
the entire sequence of product that you

00:31:41,740 --> 00:31:46,179
that you fit in we add benchmarks on

00:31:44,529 --> 00:31:48,159
that but the truth is is that it's

00:31:46,179 --> 00:31:49,570
marginally in our cases it was

00:31:48,159 --> 00:31:52,299
marginally better than the average

00:31:49,570 --> 00:31:54,039
account without waybig like we don't

00:31:52,299 --> 00:31:55,870
women were more sophistication and

00:31:54,039 --> 00:31:58,059
complexity in training and the point so

00:31:55,870 --> 00:31:59,799
we drop that but in theory if you have

00:31:58,059 --> 00:32:02,490
enough data and your use case supported

00:31:59,799 --> 00:32:05,740
it's a simple change in the encoder part

00:32:02,490 --> 00:32:08,559
okay okay there's one final question

00:32:05,740 --> 00:32:10,570
here another one from who says do you

00:32:08,559 --> 00:32:14,860
think the encoder decoder network we

00:32:10,570 --> 00:32:17,980
work for other inputs like documents for

00:32:14,860 --> 00:32:20,799
inputs as in we can encode documents you

00:32:17,980 --> 00:32:22,899
interacted weeds and and then you

00:32:20,799 --> 00:32:24,909
generate language yes

00:32:22,899 --> 00:32:27,220
the problem with documents is that the

00:32:24,909 --> 00:32:29,500
representation is Oracle is less

00:32:27,220 --> 00:32:31,480
straightforward then with either images

00:32:29,500 --> 00:32:33,940
which is you know CNN and that's

00:32:31,480 --> 00:32:35,889
basically done or brought - wette prod

00:32:33,940 --> 00:32:38,169
vectors which is again like prod two

00:32:35,889 --> 00:32:38,889
vectors now I would say it's it's a

00:32:38,169 --> 00:32:40,840
fairly stable

00:32:38,889 --> 00:32:43,419
it's a FedEx stable technology used by

00:32:40,840 --> 00:32:45,130
yes if you have short documents you know

00:32:43,419 --> 00:32:46,990
collection of sentence in source one and

00:32:45,130 --> 00:32:49,600
you want to use like the latest encoded

00:32:46,990 --> 00:32:51,370
metal X a sentence bird just to make up

00:32:49,600 --> 00:32:52,750
like a practical example you could

00:32:51,370 --> 00:32:54,669
probably do the same like if you have

00:32:52,750 --> 00:32:56,049
user interact with documents you encode

00:32:54,669 --> 00:32:57,940
the documents that user interact with

00:32:56,049 --> 00:33:00,460
with sentence bird and then you feed

00:32:57,940 --> 00:33:02,950
that as your encoder and then you should

00:33:00,460 --> 00:33:05,590
be able to get realistic type I'd

00:33:02,950 --> 00:33:06,940
completion based on the on the on the

00:33:05,590 --> 00:33:09,820
quality on the semantics of these

00:33:06,940 --> 00:33:13,090
documents but the overall quality of

00:33:09,820 --> 00:33:14,440
what we did is heavily dependent on the

00:33:13,090 --> 00:33:16,389
quality of the representation of the

00:33:14,440 --> 00:33:19,090
intent which in our case brought back

00:33:16,389 --> 00:33:21,190
work exceedingly well and we had

00:33:19,090 --> 00:33:23,830
extensive tests before going down that

00:33:21,190 --> 00:33:25,809
road so we we made sure first that

00:33:23,830 --> 00:33:27,159
Proctor vac really capture what's what

00:33:25,809 --> 00:33:29,169
you know the latent dimensions of

00:33:27,159 --> 00:33:30,820
products in commerce and then we went

00:33:29,169 --> 00:33:31,180
down the road if you can get the same

00:33:30,820 --> 00:33:33,160
level

00:33:31,180 --> 00:33:35,080
assurance in document space for your use

00:33:33,160 --> 00:33:38,620
cases there's no reason to think that it

00:33:35,080 --> 00:33:40,330
didn't work okay fantastic

00:33:38,620 --> 00:33:43,050
thank you so much a couple I think we're

00:33:40,330 --> 00:33:46,030
done with our questions thanks to you

00:33:43,050 --> 00:33:50,070
I'm going to bring this to a close thank

00:33:46,030 --> 00:33:50,070
you very much for your talk thanks much

00:33:56,350 --> 00:33:58,410

YouTube URL: https://www.youtube.com/watch?v=PFfSiE4CGPY


