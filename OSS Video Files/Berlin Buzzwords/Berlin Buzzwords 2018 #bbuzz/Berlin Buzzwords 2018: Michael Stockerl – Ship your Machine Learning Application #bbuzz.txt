Title: Berlin Buzzwords 2018: Michael Stockerl â€“ Ship your Machine Learning Application #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	A classifier labeling Van Gogh drawings as invoices and a chatbot insulting users on Twitter are only two examples of Machine Learning (ML) models, which went wild as soon as they hit production. Although evaluated on a test set, in the face of unseen data machine learning models oftentimes behave in an unpredictable way. Depending on the application, such a model may lead to decreasing revenue, bad reputation or even a threat to the health of people.

To ensure a stable rollout of new models into production, we have to promote machine learning models to first class citiziens in the Continuous Delivery pipeline. Kubernetes and Apache Kafka are two great tools to support the rollout of new machine learning models in a (semi-) automated way. I will show a pipeline built with these tools, which will lead to more confidence in your deployments and happier users.

Read more:
https://2018.berlinbuzzwords.de/18/session/ship-your-machine-learning-application

About Michael Stockerl:
https://2018.berlinbuzzwords.de/users/michael-stockerl

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:05,170 --> 00:00:13,670
hi so my name is Mitch token and I'm

00:00:11,719 --> 00:00:16,730
here to tell you how we screwed up

00:00:13,670 --> 00:00:20,150
basically two years ago and what we

00:00:16,730 --> 00:00:23,060
learned out of it I was working there

00:00:20,150 --> 00:00:25,720
back there in a company and it's

00:00:23,060 --> 00:00:28,280
basically the biggest webpage of Germany

00:00:25,720 --> 00:00:31,039
and we had a simple task we should build

00:00:28,280 --> 00:00:32,809
a recommender system for our webpage and

00:00:31,039 --> 00:00:34,579
we thought yay cool let's try out all

00:00:32,809 --> 00:00:37,370
the cool new technology and build a

00:00:34,579 --> 00:00:40,250
recommender with the amount of theta we

00:00:37,370 --> 00:00:43,370
have and we came up with one and after

00:00:40,250 --> 00:00:47,200
two weeks implementation we delivered

00:00:43,370 --> 00:00:49,550
our first recommender with an a/b test

00:00:47,200 --> 00:00:53,390
everything looked good we even had a

00:00:49,550 --> 00:00:56,090
like a increase time on the page of 14%

00:00:53,390 --> 00:00:58,100
and the people were clicking like crazy

00:00:56,090 --> 00:01:00,620
on our links so we went to all my

00:00:58,100 --> 00:01:02,960
naturist and told them ok release it we

00:01:00,620 --> 00:01:06,130
need it now we are losing money when we

00:01:02,960 --> 00:01:09,409
don't do it however after releasing it

00:01:06,130 --> 00:01:12,079
some friends of us we're asking us ok

00:01:09,409 --> 00:01:15,249
what are you doing there it's totally

00:01:12,079 --> 00:01:17,749
 and you're only showing porn stuff

00:01:15,249 --> 00:01:21,020
wave form and there was real content

00:01:17,749 --> 00:01:23,420
now it's porn and we were totally under

00:01:21,020 --> 00:01:27,889
estimating the uses with our user base

00:01:23,420 --> 00:01:32,270
to recommender another story is I was

00:01:27,889 --> 00:01:35,090
working for another company where we had

00:01:32,270 --> 00:01:37,340
a task classifying documents so when

00:01:35,090 --> 00:01:39,200
there is an invoice we should classify

00:01:37,340 --> 00:01:41,179
it as an invoice if there's a contract

00:01:39,200 --> 00:01:44,659
which were classified as a contract and

00:01:41,179 --> 00:01:47,779
so on and we basically had only one big

00:01:44,659 --> 00:01:50,689
customer and this customer was their

00:01:47,779 --> 00:01:53,149
German mail delivery and the CEO of this

00:01:50,689 --> 00:01:55,130
German mail delivery was testing our

00:01:53,149 --> 00:01:58,340
system and we prepared like crazy

00:01:55,130 --> 00:02:02,270
shipped a new model right before their

00:01:58,340 --> 00:02:04,759
milestone and then their user again the

00:02:02,270 --> 00:02:08,360
CEO did what we didn't expect it it used

00:02:04,759 --> 00:02:11,209
it in a way that we wouldn't assume and

00:02:08,360 --> 00:02:14,180
basically he uploaded some drawings of

00:02:11,209 --> 00:02:15,590
Franco to our system and we were

00:02:14,180 --> 00:02:18,460
classifying everything as an invoice

00:02:15,590 --> 00:02:18,460
because our

00:02:18,770 --> 00:02:22,400
in learning algorithm basically ever

00:02:20,330 --> 00:02:26,120
fitted to invoices because we wanted to

00:02:22,400 --> 00:02:27,980
make sure that the invoice case works so

00:02:26,120 --> 00:02:29,830
the managers again we're not super happy

00:02:27,980 --> 00:02:33,020
with us

00:02:29,830 --> 00:02:35,600
in both cases the brawler was basically

00:02:33,020 --> 00:02:38,360
our test data did not really match our

00:02:35,600 --> 00:02:41,810
life data so we had our sumption x' in

00:02:38,360 --> 00:02:43,940
our test set which basically the user

00:02:41,810 --> 00:02:47,210
don't care about and we have to make

00:02:43,940 --> 00:02:51,320
sure that the live data is tested and

00:02:47,210 --> 00:02:53,210
not all tested itself another problem

00:02:51,320 --> 00:02:56,500
especially in the first case was that we

00:02:53,210 --> 00:02:59,750
deployed something to production and it

00:02:56,500 --> 00:03:04,310
been there for a while user could make

00:02:59,750 --> 00:03:06,230
some stuff and then it broke totally and

00:03:04,310 --> 00:03:09,320
until we got the real feedback from a

00:03:06,230 --> 00:03:11,510
user that it's broke it was too late for

00:03:09,320 --> 00:03:16,820
us to see ok this was a commit we made

00:03:11,510 --> 00:03:19,370
which really broke our whole system and

00:03:16,820 --> 00:03:22,880
the last problem was that we were not

00:03:19,370 --> 00:03:25,670
able to reproduce what we did before we

00:03:22,880 --> 00:03:29,230
deploy the stuff so basically it was

00:03:25,670 --> 00:03:33,050
cowboy style we hacked a model together

00:03:29,230 --> 00:03:35,720
deployed it and hope the best so we

00:03:33,050 --> 00:03:39,200
totally forgot with which test sets we

00:03:35,720 --> 00:03:42,320
used we forgot which hyper parameters we

00:03:39,200 --> 00:03:47,650
trained and so fixing a barque was

00:03:42,320 --> 00:03:47,650
always redoing it at all all over again

00:03:47,770 --> 00:03:54,560
yeah now I'm at the Nemo tomb and I had

00:03:52,130 --> 00:03:58,340
time to think about ok how could we

00:03:54,560 --> 00:04:00,650
improve the situation for us and also

00:03:58,340 --> 00:04:04,640
for our startups shortly about on

00:04:00,650 --> 00:04:07,220
Dyneema tomb what isn't anymore to stand

00:04:04,640 --> 00:04:10,130
a Titan a claims that we are the

00:04:07,220 --> 00:04:13,459
Stanford of Bavaria basically we are a

00:04:10,130 --> 00:04:15,830
non-profit entrepreneurship Center which

00:04:13,459 --> 00:04:18,049
tries to help startups in every stage to

00:04:15,830 --> 00:04:21,620
become successful so we help them with

00:04:18,049 --> 00:04:24,070
their first idea I'm teaming up until

00:04:21,620 --> 00:04:28,129
venture capital and help them to build

00:04:24,070 --> 00:04:30,270
secure scalable companies

00:04:28,129 --> 00:04:32,250
in addition to that we also work

00:04:30,270 --> 00:04:33,870
together with a lot of big corporates to

00:04:32,250 --> 00:04:36,330
help them to stay competitive and

00:04:33,870 --> 00:04:39,539
innovative for example some of our

00:04:36,330 --> 00:04:41,729
partners our BMW time layer and Audi and

00:04:39,539 --> 00:04:45,300
also in the tech side like Google and

00:04:41,729 --> 00:04:47,970
Facebook are our partners and we have

00:04:45,300 --> 00:04:50,490
some cool projects like Hyperloop we

00:04:47,970 --> 00:04:53,580
build some robot this stuff like that so

00:04:50,490 --> 00:04:58,259
if you're interested in high-tech check

00:04:53,580 --> 00:05:00,840
out on the NEEMO tune so how do we

00:04:58,259 --> 00:05:02,789
actually release a model with our

00:05:00,840 --> 00:05:06,389
startups and I will use it as an example

00:05:02,789 --> 00:05:13,919
of the document classifier as an example

00:05:06,389 --> 00:05:16,080
to go through the whole process so the

00:05:13,919 --> 00:05:17,610
most important step in the machine

00:05:16,080 --> 00:05:19,349
learning pipeline is always a

00:05:17,610 --> 00:05:21,569
pre-processing so we have to make sure

00:05:19,349 --> 00:05:25,560
that the data is clean enough and fits

00:05:21,569 --> 00:05:28,319
to our model we use Kafka to store our

00:05:25,560 --> 00:05:31,889
training data and we have like a first

00:05:28,319 --> 00:05:34,620
one which stores the raw data and we

00:05:31,889 --> 00:05:38,449
process it in two ways like one for

00:05:34,620 --> 00:05:42,210
training set and one for test set and we

00:05:38,449 --> 00:05:44,370
named that topics with the git commit of

00:05:42,210 --> 00:05:47,940
the preprocessor to make sure that we

00:05:44,370 --> 00:05:49,949
always know which one we use and also

00:05:47,940 --> 00:05:53,610
that we can't roll back and we don't

00:05:49,949 --> 00:05:56,370
have clashing names of our topics this

00:05:53,610 --> 00:05:58,919
works pretty good as long as you don't

00:05:56,370 --> 00:06:01,650
change anything in the preprocessor if

00:05:58,919 --> 00:06:04,469
you change the preprocessor everything

00:06:01,650 --> 00:06:07,620
has to recalculate it the whole pipeline

00:06:04,469 --> 00:06:10,409
has to go through again so this is kind

00:06:07,620 --> 00:06:15,509
of one of the bottlenecks we facing

00:06:10,409 --> 00:06:17,460
right now and so somebody pushes some

00:06:15,509 --> 00:06:21,270
code to production or near to production

00:06:17,460 --> 00:06:22,949
but to get and we trained our candidate

00:06:21,270 --> 00:06:24,800
out of the training data set this is

00:06:22,949 --> 00:06:28,080
pretty normal

00:06:24,800 --> 00:06:30,479
our data scientists or engineers can do

00:06:28,080 --> 00:06:35,039
that also locally so they have access to

00:06:30,479 --> 00:06:37,409
the training topics so they can build

00:06:35,039 --> 00:06:40,110
with the real data we using also for the

00:06:37,409 --> 00:06:41,380
build process locally which makes it

00:06:40,110 --> 00:06:45,190
much easier for them

00:06:41,380 --> 00:06:49,120
to feel like they would work in

00:06:45,190 --> 00:06:53,080
production as soon as we've got our

00:06:49,120 --> 00:06:56,170
candidate model we use the live model

00:06:53,080 --> 00:06:58,870
which is like currently life and rerun

00:06:56,170 --> 00:07:02,800
the whole test again just to make sure

00:06:58,870 --> 00:07:05,890
that it's like order to have a baseline

00:07:02,800 --> 00:07:08,410
because our test set is always involving

00:07:05,890 --> 00:07:09,520
we're using different test sets all the

00:07:08,410 --> 00:07:12,310
time

00:07:09,520 --> 00:07:16,240
to make sure that we don't our fit in

00:07:12,310 --> 00:07:19,180
one direction and so we create another

00:07:16,240 --> 00:07:21,130
baseline for our new model to see

00:07:19,180 --> 00:07:25,350
whether it's better or worse than the

00:07:21,130 --> 00:07:28,630
old one so we just rerun everything

00:07:25,350 --> 00:07:31,060
again and then we do the same for the

00:07:28,630 --> 00:07:33,010
new model so we we evaluate the new

00:07:31,060 --> 00:07:35,020
model and then we compare because we

00:07:33,010 --> 00:07:37,330
don't really know how good is good in

00:07:35,020 --> 00:07:38,590
our production system but we assume

00:07:37,330 --> 00:07:43,870
everything which is better than the old

00:07:38,590 --> 00:07:45,970
one is really nice to have so when it's

00:07:43,870 --> 00:07:49,530
better than the old one we go with this

00:07:45,970 --> 00:07:52,990
one if it's slightly or comparable

00:07:49,530 --> 00:07:54,700
perhaps we just try it out and when it's

00:07:52,990 --> 00:07:59,410
worse then we don't even try it out so

00:07:54,700 --> 00:08:02,260
we go on with that like in the case when

00:07:59,410 --> 00:08:05,380
it's it's good enough we we tag it in

00:08:02,260 --> 00:08:09,010
our get history as a good model and we

00:08:05,380 --> 00:08:10,600
publish it to our object storage as also

00:08:09,010 --> 00:08:14,320
IBM is one of our partners we're using

00:08:10,600 --> 00:08:17,860
IBM for that but you can use basically

00:08:14,320 --> 00:08:26,050
everything like s3 or something like

00:08:17,860 --> 00:08:28,360
that okay until now this is pretty basic

00:08:26,050 --> 00:08:31,450
and even the research is doing that

00:08:28,360 --> 00:08:33,340
so the using a training set that using a

00:08:31,450 --> 00:08:35,710
test set they compare it to see which

00:08:33,340 --> 00:08:39,430
one is better and this is why basically

00:08:35,710 --> 00:08:41,289
what we also done before why we want to

00:08:39,430 --> 00:08:45,760
test our model in production and see how

00:08:41,289 --> 00:08:48,700
it behaves there for that we built a

00:08:45,760 --> 00:08:51,670
real service with the model so we

00:08:48,700 --> 00:08:53,650
decoupled the service from the model

00:08:51,670 --> 00:08:55,209
itself to make sure that a data

00:08:53,650 --> 00:08:58,869
scientist can work independently

00:08:55,209 --> 00:09:02,199
from an app developer and this again

00:08:58,869 --> 00:09:04,589
works as long as you don't change the P

00:09:02,199 --> 00:09:07,410
processor but it gives you some kind of

00:09:04,589 --> 00:09:13,089
in dependencies between the two

00:09:07,410 --> 00:09:16,089
disciplines so when either the app

00:09:13,089 --> 00:09:19,420
developer or the data scientist wants to

00:09:16,089 --> 00:09:20,499
push something we merge the branch we

00:09:19,420 --> 00:09:23,110
build a docker image

00:09:20,499 --> 00:09:25,769
pull there the model and then we run

00:09:23,110 --> 00:09:28,179
basic unit tests and integration tests

00:09:25,769 --> 00:09:31,569
then we make sure to include some corner

00:09:28,179 --> 00:09:36,040
cases we expect for example create a van

00:09:31,569 --> 00:09:37,929
Gogh drawing and to see whether it's

00:09:36,040 --> 00:09:41,740
always another other document and not an

00:09:37,929 --> 00:09:43,389
invoice because some corner cases should

00:09:41,740 --> 00:09:45,910
not happen in production and it's

00:09:43,389 --> 00:09:49,809
basically a real unit test but most of

00:09:45,910 --> 00:09:51,879
the time you cannot really test your

00:09:49,809 --> 00:09:54,910
model with unit tests or integration

00:09:51,879 --> 00:09:59,920
tests because they behave sometimes

00:09:54,910 --> 00:10:01,420
strange not always as predicted so you

00:09:59,920 --> 00:10:04,990
will have a lot of failing tests if you

00:10:01,420 --> 00:10:06,490
do test everything with unit tests so we

00:10:04,990 --> 00:10:10,420
just make sure that like the basic

00:10:06,490 --> 00:10:11,290
functionality stays the same if I would

00:10:10,420 --> 00:10:13,329
say lat

00:10:11,290 --> 00:10:15,579
I would make sure that their highest

00:10:13,329 --> 00:10:22,119
paid ad is always recommended for

00:10:15,579 --> 00:10:25,420
example when all the tests pass we

00:10:22,119 --> 00:10:29,589
publish the model to our continual

00:10:25,420 --> 00:10:32,639
registry again on IBM and then it's

00:10:29,589 --> 00:10:36,819
accessible for our kubernetes cluster

00:10:32,639 --> 00:10:41,709
and we simply run a deployment for our

00:10:36,819 --> 00:10:43,449
service in the kubernetes cluster so the

00:10:41,709 --> 00:10:46,209
deployment makes sure that there is

00:10:43,449 --> 00:10:49,269
always three instances running and when

00:10:46,209 --> 00:10:51,160
we change the model or the service that

00:10:49,269 --> 00:10:54,420
it's done in a way that the user doesn't

00:10:51,160 --> 00:10:57,329
notice so it first removes one instance

00:10:54,420 --> 00:11:01,019
starts a new one see whether it works

00:10:57,329 --> 00:11:04,120
and goes to the second one and so on and

00:11:01,019 --> 00:11:08,570
the classification is pretty simple so

00:11:04,120 --> 00:11:10,570
we have an incoming topic where older

00:11:08,570 --> 00:11:13,040
data is stored in a pre-processed way

00:11:10,570 --> 00:11:16,280
then their service itself is just

00:11:13,040 --> 00:11:25,280
classifying the stuff and I'll put it

00:11:16,280 --> 00:11:28,850
into a life topic to test a new model we

00:11:25,280 --> 00:11:31,130
deploy a cannery instance and it

00:11:28,850 --> 00:11:36,020
basically does the same it just

00:11:31,130 --> 00:11:40,250
published stuff into a cannery topic so

00:11:36,020 --> 00:11:43,700
the life talk types will surf the web

00:11:40,250 --> 00:11:48,800
page and the cannery will be like there

00:11:43,700 --> 00:11:51,310
is nothing to surf from but both topics

00:11:48,800 --> 00:11:53,660
basically contain the same information

00:11:51,310 --> 00:12:00,860
it's just a model with the tablet

00:11:53,660 --> 00:12:05,320
prediction which is different and to

00:12:00,860 --> 00:12:07,250
find like examples where we have a

00:12:05,320 --> 00:12:10,790
classification where we are not sure

00:12:07,250 --> 00:12:15,860
about we join the two topics and have a

00:12:10,790 --> 00:12:19,010
spot checker input queue and also like

00:12:15,860 --> 00:12:20,600
again spot checking is pretty simple we

00:12:19,010 --> 00:12:23,030
take the examples where the two models

00:12:20,600 --> 00:12:25,310
cannot agree on a talk type and we show

00:12:23,030 --> 00:12:28,820
it to the one who deploys or if it's

00:12:25,310 --> 00:12:31,790
more domain knowledge involved we show

00:12:28,820 --> 00:12:35,360
it to somebody who can classify the

00:12:31,790 --> 00:12:37,040
stuff so in this case a human being

00:12:35,360 --> 00:12:41,390
should tell me if it's an invoice a

00:12:37,040 --> 00:12:44,690
contract or other and we go through a

00:12:41,390 --> 00:12:47,540
couple of them it always depends how

00:12:44,690 --> 00:12:52,610
many documents we need to see a

00:12:47,540 --> 00:12:56,600
difference between the two models in

00:12:52,610 --> 00:12:58,730
that way we kind of build up our test

00:12:56,600 --> 00:13:00,950
data automatically so with every

00:12:58,730 --> 00:13:04,100
deployment our tests say the test data

00:13:00,950 --> 00:13:08,000
set grows which is cool but it does not

00:13:04,100 --> 00:13:12,920
work if you have to comply to some data

00:13:08,000 --> 00:13:15,980
privacy issues so as long as no user

00:13:12,920 --> 00:13:18,700
data is involved this can work to build

00:13:15,980 --> 00:13:18,700
up your test dataset

00:13:19,550 --> 00:13:26,060
and then it's basically just a decision

00:13:23,870 --> 00:13:28,340
based on a dashboard so the one who

00:13:26,060 --> 00:13:30,140
deploys looks at a dashboard and makes

00:13:28,340 --> 00:13:36,830
an educated guess whether it's better or

00:13:30,140 --> 00:13:40,610
or not so there's just like a part of it

00:13:36,830 --> 00:13:42,800
here but we for example money tour

00:13:40,610 --> 00:13:46,430
what is the precision on the live system

00:13:42,800 --> 00:13:49,430
based on on user feedback so whenever we

00:13:46,430 --> 00:13:53,830
see a drop and like a precision of user

00:13:49,430 --> 00:13:57,980
feedback we might want to do something

00:13:53,830 --> 00:14:01,340
when we deploy or in beginning of the

00:13:57,980 --> 00:14:04,520
deployment we also check whether the

00:14:01,340 --> 00:14:06,440
cannery and the life prediction have the

00:14:04,520 --> 00:14:08,000
same distribution on a test set because

00:14:06,440 --> 00:14:14,540
we know the distribution on the tested

00:14:08,000 --> 00:14:16,220
and it should not really be different on

00:14:14,540 --> 00:14:19,190
the two models if there is a big

00:14:16,220 --> 00:14:22,010
difference we better don't deploy the

00:14:19,190 --> 00:14:24,440
stuff because this was the case with our

00:14:22,010 --> 00:14:26,450
invoice classify everything as an

00:14:24,440 --> 00:14:30,230
invoice we would have seen it on a test

00:14:26,450 --> 00:14:33,170
at distribution already and this is

00:14:30,230 --> 00:14:36,590
basically the last step these are the

00:14:33,170 --> 00:14:39,440
classifications of the spot checker and

00:14:36,590 --> 00:14:43,880
as we taking mainly examples where the

00:14:39,440 --> 00:14:46,730
two differs you break quickly see which

00:14:43,880 --> 00:14:52,730
one is better on the tested on their

00:14:46,730 --> 00:14:56,690
life data and in this case it was pretty

00:14:52,730 --> 00:14:59,390
safe to deploy the new version although

00:14:56,690 --> 00:15:07,490
we didn't have like a lot of examples

00:14:59,390 --> 00:15:10,670
running and then we deploy it

00:15:07,490 --> 00:15:13,000
we still monitor it because then the new

00:15:10,670 --> 00:15:15,440
one is in production and all the

00:15:13,000 --> 00:15:19,400
production metrics applied to this one

00:15:15,440 --> 00:15:23,420
and like after a couple of hours we

00:15:19,400 --> 00:15:26,000
assume that it's okay depends

00:15:23,420 --> 00:15:28,130
always on the traffic so with startups

00:15:26,000 --> 00:15:30,730
it's most of the time pretty difficult

00:15:28,130 --> 00:15:33,260
because they don't have too much traffic

00:15:30,730 --> 00:15:37,100
but you cannot destroy too much

00:15:33,260 --> 00:15:44,420
startup because they don't have uses

00:15:37,100 --> 00:15:47,630
anyway not all of them like it's working

00:15:44,420 --> 00:15:50,210
pretty good with most of their like use

00:15:47,630 --> 00:15:52,100
cases where we're using it but there are

00:15:50,210 --> 00:15:55,510
some limitations as I already mentioned

00:15:52,100 --> 00:16:00,020
when you like change the preprocessor

00:15:55,510 --> 00:16:03,760
it's kind of difficult to make sure that

00:16:00,020 --> 00:16:09,080
it's still working that not one of the

00:16:03,760 --> 00:16:11,150
classifiers is crashing the data privacy

00:16:09,080 --> 00:16:14,470
might be an issue like in our case it

00:16:11,150 --> 00:16:16,610
was not a problem because we anonymize

00:16:14,470 --> 00:16:18,680
every document anyway right in the

00:16:16,610 --> 00:16:23,120
beginning this was like one requirement

00:16:18,680 --> 00:16:25,580
of the German mail delivery service so

00:16:23,120 --> 00:16:27,560
we could store just analyze features and

00:16:25,580 --> 00:16:29,450
that's good

00:16:27,560 --> 00:16:31,460
and it basically only works for

00:16:29,450 --> 00:16:34,190
classification use cases where a human

00:16:31,460 --> 00:16:36,730
being can tell whether this is this

00:16:34,190 --> 00:16:38,420
class or that one so we have another

00:16:36,730 --> 00:16:41,750
application right now it's about

00:16:38,420 --> 00:16:44,240
predictive maintenance for trucks and we

00:16:41,750 --> 00:16:46,480
do it based on the canvas data and we

00:16:44,240 --> 00:16:49,220
want to predict two weeks in advance

00:16:46,480 --> 00:16:51,890
whether this truck will break down or

00:16:49,220 --> 00:16:54,890
not and I have no clue about Campos data

00:16:51,890 --> 00:16:58,000
and when I see it it's basically nothing

00:16:54,890 --> 00:17:00,590
for me so we cannot really tell based on

00:16:58,000 --> 00:17:02,450
sample samples whether the

00:17:00,590 --> 00:17:05,480
classification was right or wrong we can

00:17:02,450 --> 00:17:07,850
only tell after two weeks and when a

00:17:05,480 --> 00:17:11,510
truck breaks down after two weeks with

00:17:07,850 --> 00:17:14,199
some precious load and we didn't know

00:17:11,510 --> 00:17:17,570
that might be not good for our startup

00:17:14,199 --> 00:17:19,220
so we're currently working on that and

00:17:17,570 --> 00:17:21,230
if you want to have more details there

00:17:19,220 --> 00:17:26,810
is Anastasia who is basically working on

00:17:21,230 --> 00:17:31,100
that so ask her if you want to get more

00:17:26,810 --> 00:17:33,620
information about this use case and

00:17:31,100 --> 00:17:35,630
that's all I wanted to tell you like if

00:17:33,620 --> 00:17:39,400
you have more question come afterwards

00:17:35,630 --> 00:17:41,440
or reach me out on email or Twitter

00:17:39,400 --> 00:17:44,500
thank you

00:17:41,440 --> 00:17:47,559
[Applause]

00:17:44,500 --> 00:17:47,559
[Music]

00:17:48,409 --> 00:18:00,390
other questions I I'm just curious about

00:17:58,350 --> 00:18:04,200
if any what effect type arrives what

00:18:00,390 --> 00:18:06,929
happens to this system like in case when

00:18:04,200 --> 00:18:09,120
contract invoices and maybe some other

00:18:06,929 --> 00:18:12,929
artifact type arrives so we changed the

00:18:09,120 --> 00:18:14,549
entire processing the thing and I mean

00:18:12,929 --> 00:18:15,990
that entire pipeline changes

00:18:14,549 --> 00:18:20,010
you mean when we introduce you classes

00:18:15,990 --> 00:18:23,039
or like what happens when we introduce

00:18:20,010 --> 00:18:24,510
new classes or do you mean something

00:18:23,039 --> 00:18:28,370
else yeah maybe

00:18:24,510 --> 00:18:31,590
okay when we introduce new classes

00:18:28,370 --> 00:18:34,970
basically we start all over again

00:18:31,590 --> 00:18:39,539
because most of the others documents

00:18:34,970 --> 00:18:42,240
might be one of these documents and if

00:18:39,539 --> 00:18:45,750
we train with like other is this type of

00:18:42,240 --> 00:18:51,059
document it will have some British

00:18:45,750 --> 00:18:53,809
precision problems so at least we try to

00:18:51,059 --> 00:18:58,890
find there the classes in the other

00:18:53,809 --> 00:19:01,429
documents and we run like create all the

00:18:58,890 --> 00:19:01,429
topics new

00:19:04,340 --> 00:19:13,370
and what's the same with their with the

00:19:10,400 --> 00:19:15,980
web page where we build a recommender we

00:19:13,370 --> 00:19:18,950
had to classify whether content is good

00:19:15,980 --> 00:19:21,380
or not and first we trained with three

00:19:18,950 --> 00:19:24,560
classes like good bad and medium and

00:19:21,380 --> 00:19:29,870
then our product owner wanted to have

00:19:24,560 --> 00:19:32,180
good media and bad and delete and it's

00:19:29,870 --> 00:19:33,950
really hard to like strange stuff if

00:19:32,180 --> 00:19:37,010
everything is marked is bad

00:19:33,950 --> 00:19:39,290
if there's a new delete class perhaps

00:19:37,010 --> 00:19:41,470
there is some overlapping stuff going on

00:19:39,290 --> 00:19:41,470
there

00:19:41,830 --> 00:19:56,910
last question cool thank you thank you

00:19:50,330 --> 00:19:56,910

YouTube URL: https://www.youtube.com/watch?v=16oIh0fAs0Q


