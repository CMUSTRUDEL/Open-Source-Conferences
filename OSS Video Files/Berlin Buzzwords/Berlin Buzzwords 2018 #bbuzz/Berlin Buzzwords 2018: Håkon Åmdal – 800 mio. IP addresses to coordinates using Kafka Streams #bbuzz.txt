Title: Berlin Buzzwords 2018: Håkon Åmdal – 800 mio. IP addresses to coordinates using Kafka Streams #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Håkon Åmdal talking about "Translating 800 million IP addresses to coordinates each day using Kafka Streams".

The Schibsted Data Platform is the global processing hub for data in Schibsted, and we receive roughly 800 million user behaviour events from more than 40 sites worldwide each day. The Data Platform’s responsibility is not only to collect, structure, and index the incoming data, but also add extra value by adding additional information to the events, known as enrichments.

To offer targeted advertising based on location, the Data Platform enriches all incoming events using an API that will translate IP addresses into coordinates. To do this in real-time and at scale, with sub-second latencies, we utilize Kafka and Kafka Streams.

In this presentation, I will introduce Apache Kafka, Kafka Streams, the Kafka Streams DSL and the Processor API to explain how it can be used for branching, caching, bulking, asynchronous HTTP lookups, and joining. I will also talk about experiences related to operations, performance, and scaling.

Read more:
https://2018.berlinbuzzwords.de/18/session/translating-800-million-ip-addresses-coordinates-each-day-using-kafka-streams

About Håkon Åmdal:
https://2018.berlinbuzzwords.de/users/hakon-amdal

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:04,570 --> 00:00:11,590
so I'm here to tell a story a story

00:00:08,410 --> 00:00:13,389
about how we use utilize Kafka and Kafka

00:00:11,590 --> 00:00:15,490
streams in our company to solve

00:00:13,389 --> 00:00:19,509
interesting problems and interesting use

00:00:15,490 --> 00:00:23,079
cases but I think it's useful because

00:00:19,509 --> 00:00:25,720
this is the first time I'm at Berlin

00:00:23,079 --> 00:00:27,880
buzzwords whatsoever so it's interesting

00:00:25,720 --> 00:00:29,320
for me to know who is the audience so I

00:00:27,880 --> 00:00:31,689
have some categories here I was hoping

00:00:29,320 --> 00:00:34,210
people could raise their hands when they

00:00:31,689 --> 00:00:36,130
feel they belong to that category I use

00:00:34,210 --> 00:00:40,150
Kafka but I need to know if Kafka

00:00:36,130 --> 00:00:42,910
streams is something for me okay cool I

00:00:40,150 --> 00:00:45,910
think you're in the right in the right

00:00:42,910 --> 00:00:48,130
room I use other streaming frameworks

00:00:45,910 --> 00:00:50,829
like flint spark screaming or Samsa but

00:00:48,130 --> 00:00:55,660
I'm not particularly familiar with Kafka

00:00:50,829 --> 00:00:57,430
streams some cool I use Kafka streams

00:00:55,660 --> 00:00:59,680
and I'm just here to learn how you guys

00:00:57,430 --> 00:01:02,200
did it nice

00:00:59,680 --> 00:01:03,910
I'm really hoping to meet you guys after

00:01:02,200 --> 00:01:06,399
the presentation too so course come see

00:01:03,910 --> 00:01:09,820
me we have a lot to discuss who's new to

00:01:06,399 --> 00:01:13,780
Kafka okay I have something for you guys

00:01:09,820 --> 00:01:16,900
too so today I'm going to to tell you a

00:01:13,780 --> 00:01:19,720
story I need to provide some context to

00:01:16,900 --> 00:01:21,940
you because I think it matters because

00:01:19,720 --> 00:01:24,070
we you need to understand the scope of

00:01:21,940 --> 00:01:25,540
the problem we're solving and I'm going

00:01:24,070 --> 00:01:27,520
to give a brief introduction to the

00:01:25,540 --> 00:01:29,470
technologies we're using which is Kafka

00:01:27,520 --> 00:01:31,240
and Kafka streams and then we're going

00:01:29,470 --> 00:01:34,060
to build an application here on the

00:01:31,240 --> 00:01:37,080
slide thank you take one line of code at

00:01:34,060 --> 00:01:40,180
the time and I promise you I present

00:01:37,080 --> 00:01:43,390
100% of the lines of code that interacts

00:01:40,180 --> 00:01:46,090
with the Kafka streams API that actually

00:01:43,390 --> 00:01:48,010
solve this solve this problem and then

00:01:46,090 --> 00:01:51,810
we're going to talk a little about how

00:01:48,010 --> 00:01:54,280
to put our app into production how we

00:01:51,810 --> 00:01:58,090
how we put the app into production and

00:01:54,280 --> 00:01:59,860
how like sort of the choices we had to

00:01:58,090 --> 00:02:02,140
make and the problems we ran into and

00:01:59,860 --> 00:02:04,150
then we'll have a really short slide

00:02:02,140 --> 00:02:08,189
about higher the conclusions and what

00:02:04,150 --> 00:02:08,189
we've learned during this presentation

00:02:08,700 --> 00:02:14,739
so my name is fokin humble I'm a data

00:02:12,159 --> 00:02:16,870
engineer in shipstead I'm sorry I don't

00:02:14,739 --> 00:02:20,249
work for confluence even though I have

00:02:16,870 --> 00:02:20,249
this amazing Kafka t-shirt

00:02:20,250 --> 00:02:24,700
and this is as I told you this is the

00:02:23,110 --> 00:02:27,190
first time at Berlin best words and I'm

00:02:24,700 --> 00:02:29,500
particularly found of stream processing

00:02:27,190 --> 00:02:31,840
and you probably noticed that during

00:02:29,500 --> 00:02:34,560
this presentation it's a little hard

00:02:31,840 --> 00:02:37,239
talking about shipstead in Germany

00:02:34,560 --> 00:02:39,610
shipstead isn't a very strong brand in

00:02:37,239 --> 00:02:41,019
itself but it has a lot of local brands

00:02:39,610 --> 00:02:43,330
and I noticed there are a lot of people

00:02:41,019 --> 00:02:47,380
from France there and we do own Leben

00:02:43,330 --> 00:02:50,380
quoi so ship that owns a lot of media

00:02:47,380 --> 00:02:52,810
sites they're particularly big in in

00:02:50,380 --> 00:02:55,060
Norway and Sweden and we do also own

00:02:52,810 --> 00:02:59,290
these marketplaces for classified ads in

00:02:55,060 --> 00:03:01,930
Sweden Norway France Italy Spain and so

00:02:59,290 --> 00:03:06,340
on and we also have some other growth

00:03:01,930 --> 00:03:10,140
concepts and all of these sites they

00:03:06,340 --> 00:03:13,480
implement the shipstead custom tracker

00:03:10,140 --> 00:03:16,650
we have a tracker for iOS for Android

00:03:13,480 --> 00:03:18,970
and for the web trackers and these

00:03:16,650 --> 00:03:21,459
trackers they generate sort of this

00:03:18,970 --> 00:03:24,070
clickstream data we're like you they

00:03:21,459 --> 00:03:26,620
send a signal every time you click a

00:03:24,070 --> 00:03:29,950
link or view an item on these sites to a

00:03:26,620 --> 00:03:32,620
data collection service which we wear

00:03:29,950 --> 00:03:34,870
all the events end up in an AWS key

00:03:32,620 --> 00:03:37,090
Nessie stream here we split the stream

00:03:34,870 --> 00:03:40,720
into two different pipelines we have a

00:03:37,090 --> 00:03:43,840
more traditional batch processing

00:03:40,720 --> 00:03:46,299
pipeline where we run batch jobs mostly

00:03:43,840 --> 00:03:49,959
spark some other stuff as well where we

00:03:46,299 --> 00:03:52,150
use AWS s3 as sort of the backing store

00:03:49,959 --> 00:03:54,280
for this and the other one is the

00:03:52,150 --> 00:03:55,840
streaming pipeline it comes with some

00:03:54,280 --> 00:03:57,910
different delivery guarantees it's much

00:03:55,840 --> 00:04:02,290
more timely than the batch pipeline of

00:03:57,910 --> 00:04:03,930
course and and this is where sort of

00:04:02,290 --> 00:04:06,700
this is Kafka by streaming platform

00:04:03,930 --> 00:04:11,500
which I'm going to sort of talk about

00:04:06,700 --> 00:04:14,260
today and we do I mean I've seen like

00:04:11,500 --> 00:04:16,450
some sponsors here they brag about like

00:04:14,260 --> 00:04:18,760
half and trillion events each day we are

00:04:16,450 --> 00:04:21,519
not at that scale but we're fairly large

00:04:18,760 --> 00:04:24,430
we collect somewhere between 700 and 800

00:04:21,519 --> 00:04:27,970
million events each day and that's on

00:04:24,430 --> 00:04:30,820
average so at peak hours it's around 2

00:04:27,970 --> 00:04:31,820
million events during the evenings in 2

00:04:30,820 --> 00:04:33,800
million events

00:04:31,820 --> 00:04:40,730
each minute and that's during the

00:04:33,800 --> 00:04:42,890
evenings in in Europe and even though

00:04:40,730 --> 00:04:45,650
but this number is large enough that

00:04:42,890 --> 00:04:48,530
we're talking about we need solution

00:04:45,650 --> 00:04:50,240
that scales we cannot run this on a

00:04:48,530 --> 00:04:51,940
single thread on a single machine we

00:04:50,240 --> 00:04:56,690
need a distributed system to solve

00:04:51,940 --> 00:04:59,330
problems in this scope we use the

00:04:56,690 --> 00:05:01,990
streaming platform for a lot of things

00:04:59,330 --> 00:05:06,020
in shipstead and I could talk on and on

00:05:01,990 --> 00:05:09,110
about all the cool things we do we but

00:05:06,020 --> 00:05:10,880
to scope this talk we're going to talk

00:05:09,110 --> 00:05:14,540
about targeted advertising in shipstead

00:05:10,880 --> 00:05:16,580
because what we do is the end user will

00:05:14,540 --> 00:05:20,480
enter a page and will get signals from

00:05:16,580 --> 00:05:23,660
that user entering that page we use our

00:05:20,480 --> 00:05:26,180
streaming platform to do some some

00:05:23,660 --> 00:05:27,920
transforms some filtering and sort of

00:05:26,180 --> 00:05:30,470
forward that data to use your

00:05:27,920 --> 00:05:32,930
segmentation engine where a user based

00:05:30,470 --> 00:05:34,760
on its behavior is sort of gets its

00:05:32,930 --> 00:05:36,350
gender and age and we have some other

00:05:34,760 --> 00:05:40,820
models running as well get that

00:05:36,350 --> 00:05:44,660
predicted and that will in turn result

00:05:40,820 --> 00:05:46,400
in targeted ads for that user so it's

00:05:44,660 --> 00:05:48,440
really important that this happens fast

00:05:46,400 --> 00:05:50,510
ideally we want the user to enter the

00:05:48,440 --> 00:05:52,730
front page say of a news page and by the

00:05:50,510 --> 00:05:55,780
time we clicked the article there there

00:05:52,730 --> 00:05:58,670
will be a relevant ad displayed to him

00:05:55,780 --> 00:06:00,980
at the very next page view and and

00:05:58,670 --> 00:06:02,510
needless to say this is this is big

00:06:00,980 --> 00:06:05,210
business this is really really big

00:06:02,510 --> 00:06:07,220
business so whatever downtime we have

00:06:05,210 --> 00:06:09,430
whatever data quality issues we have

00:06:07,220 --> 00:06:12,140
whatever completeness issues we have

00:06:09,430 --> 00:06:21,650
will affect the total revenue of

00:06:12,140 --> 00:06:24,380
shipstead ok so the business guys and i

00:06:21,650 --> 00:06:27,440
mean it's pretty obvious that if you

00:06:24,380 --> 00:06:29,300
wanna sell stuff location is a very good

00:06:27,440 --> 00:06:31,270
thing to know about a user because then

00:06:29,300 --> 00:06:37,040
you can have some location-based

00:06:31,270 --> 00:06:40,100
targeted advertising so a team in

00:06:37,040 --> 00:06:41,540
shipstead that's not my team but this is

00:06:40,100 --> 00:06:44,240
used throughout shipstead for several

00:06:41,540 --> 00:06:45,309
services we have this location API where

00:06:44,240 --> 00:06:50,499
you can

00:06:45,309 --> 00:06:52,569
it's an HTTP service where you can add

00:06:50,499 --> 00:06:55,479
an IP address or even IP address and

00:06:52,569 --> 00:06:58,059
coordinates as input and get then get

00:06:55,479 --> 00:07:00,819
like the coordinates and the reverse

00:06:58,059 --> 00:07:04,029
geocode components like zip code and

00:07:00,819 --> 00:07:05,709
country in return and I talked with

00:07:04,029 --> 00:07:07,479
someone yesterday I think he's here in

00:07:05,709 --> 00:07:09,309
the room he said why don't you just keep

00:07:07,479 --> 00:07:10,839
all of this in memory and the short

00:07:09,309 --> 00:07:12,819
answer is then it wouldn't be as

00:07:10,839 --> 00:07:14,529
interesting standing here and talking to

00:07:12,819 --> 00:07:19,679
me today because part of the complexity

00:07:14,529 --> 00:07:22,959
comes from this API the long answer is

00:07:19,679 --> 00:07:25,059
there are some some logic there we do

00:07:22,959 --> 00:07:28,059
run our own models we do need to look up

00:07:25,059 --> 00:07:30,909
reverse geocoding service that makes it

00:07:28,059 --> 00:07:34,569
and we use it throughout shipstead so

00:07:30,909 --> 00:07:38,879
that makes it like it made and that is

00:07:34,569 --> 00:07:43,959
why it's sort of behind an HTTP API so

00:07:38,879 --> 00:07:46,809
the idea here is to sort of make

00:07:43,959 --> 00:07:49,239
something that's something being the the

00:07:46,809 --> 00:07:50,799
question mark the blue box with a

00:07:49,239 --> 00:07:53,110
question mark within our streaming

00:07:50,799 --> 00:07:54,610
platform and I mean we could put

00:07:53,110 --> 00:07:57,159
everything into the use of segmentation

00:07:54,610 --> 00:08:00,249
engine but then we would only have this

00:07:57,159 --> 00:08:02,589
data for only user segmentation if we

00:08:00,249 --> 00:08:05,409
sort of move it into the central

00:08:02,589 --> 00:08:08,860
streaming platform of shipstead then all

00:08:05,409 --> 00:08:10,839
of the the users of the streaming

00:08:08,860 --> 00:08:14,110
platform would have the benefit of extra

00:08:10,839 --> 00:08:16,149
enrichments in their events and this is

00:08:14,110 --> 00:08:19,949
sort of what we're going to to dive into

00:08:16,149 --> 00:08:22,899
today there are some requirements

00:08:19,949 --> 00:08:25,659
contradictory requirements even I mean

00:08:22,899 --> 00:08:29,469
latency is paramount here with the

00:08:25,659 --> 00:08:31,360
events need to to come in a timely

00:08:29,469 --> 00:08:34,569
fashion because that will affect the

00:08:31,360 --> 00:08:36,610
performance of the targeted ads and it's

00:08:34,569 --> 00:08:37,959
sort of a very crucial part of the event

00:08:36,610 --> 00:08:40,360
- you like to have this piece of

00:08:37,959 --> 00:08:41,949
location information and these are

00:08:40,360 --> 00:08:44,529
contradictory because you can't really

00:08:41,949 --> 00:08:45,939
have both if the API go down but the

00:08:44,529 --> 00:08:47,589
essence here is you need a button you

00:08:45,939 --> 00:08:52,240
can tune the trade-off between the two

00:08:47,589 --> 00:08:54,790
of them as I told you guys earlier we

00:08:52,240 --> 00:08:58,430
have a substantial amount of events as

00:08:54,790 --> 00:08:59,990
not a lot but still a roughly

00:08:58,430 --> 00:09:02,480
billion events each day is something we

00:08:59,990 --> 00:09:04,839
need the system we need our system to

00:09:02,480 --> 00:09:07,880
handle that perhaps more importantly

00:09:04,839 --> 00:09:13,570
we're in the news business and breaking

00:09:07,880 --> 00:09:16,279
news do happen this is from inner region

00:09:13,570 --> 00:09:18,850
in the region site and you can see the

00:09:16,279 --> 00:09:21,230
traffic increases by five times during a

00:09:18,850 --> 00:09:23,899
period of two minutes and that that's

00:09:21,230 --> 00:09:27,410
when a push notification goes out for a

00:09:23,899 --> 00:09:29,330
particular breaking news event and it's

00:09:27,410 --> 00:09:31,220
the location API itself because it

00:09:29,330 --> 00:09:33,050
doesn't scale to look up one event at

00:09:31,220 --> 00:09:37,700
the time you need to book the incoming

00:09:33,050 --> 00:09:40,130
events and look them up together you it

00:09:37,700 --> 00:09:42,320
does it's rate limited so we need to

00:09:40,130 --> 00:09:47,589
apply some back pressure on the client

00:09:42,320 --> 00:09:47,589
and it can't be slow and it it can fail

00:09:51,550 --> 00:09:55,630
okay so let's talk about Kafka

00:09:57,139 --> 00:10:03,739
Kafka is based on a very simple I'd say

00:10:01,549 --> 00:10:07,939
a very simple data structure called the

00:10:03,739 --> 00:10:11,749
log I'm not sure the exact definition of

00:10:07,939 --> 00:10:15,829
the log but it's something where writers

00:10:11,749 --> 00:10:18,109
append to you can have multiple writers

00:10:15,829 --> 00:10:20,769
and then you can have a set of consumers

00:10:18,109 --> 00:10:23,569
consuming this log in sort of whatever

00:10:20,769 --> 00:10:25,369
speed they want and they normally start

00:10:23,569 --> 00:10:31,819
from the beginning and process the the

00:10:25,369 --> 00:10:33,619
events Kafka offers something very

00:10:31,819 --> 00:10:35,540
similar to a log or I mean it's it's

00:10:33,619 --> 00:10:38,199
still a log but they call it it's a

00:10:35,540 --> 00:10:42,669
logical name called the topic where each

00:10:38,199 --> 00:10:46,069
topic is a set of independent partitions

00:10:42,669 --> 00:10:49,489
where sort of the semantics are that

00:10:46,069 --> 00:10:51,919
have rights within writes and reads

00:10:49,489 --> 00:10:54,439
within the partition is ordered but in

00:10:51,919 --> 00:10:56,359
between the partitions there is no

00:10:54,439 --> 00:11:01,100
particular ordering you cannot guarantee

00:10:56,359 --> 00:11:04,429
ordering and the reason why you split it

00:11:01,100 --> 00:11:06,290
up in partitions is is because that's

00:11:04,429 --> 00:11:08,360
how you make this technology scale

00:11:06,290 --> 00:11:11,239
because it doesn't work to only have one

00:11:08,360 --> 00:11:18,079
single log for for a system that

00:11:11,239 --> 00:11:20,899
produces one billion events each day a

00:11:18,079 --> 00:11:23,839
log entry in Kafka consists of three

00:11:20,899 --> 00:11:27,319
items you have a key that can be pretty

00:11:23,839 --> 00:11:29,629
much anything you want as well or any

00:11:27,319 --> 00:11:32,299
bites you want I mean it's a value

00:11:29,629 --> 00:11:36,470
contains the value which also has the

00:11:32,299 --> 00:11:38,419
same possibility to to contain whatever

00:11:36,470 --> 00:11:40,610
byte sequence you want and then there's

00:11:38,419 --> 00:11:44,049
a timestamp and I'll come back to all of

00:11:40,610 --> 00:11:48,289
these three later in the presentation so

00:11:44,049 --> 00:11:53,720
Kafka provides these topics these sort

00:11:48,289 --> 00:11:55,609
of distributed logs at scale and they

00:11:53,720 --> 00:11:57,980
offer replication for these topics as

00:11:55,609 --> 00:12:00,350
well and and you normally run this is in

00:11:57,980 --> 00:12:02,769
a Kafka cluster or I mean you have to

00:12:00,350 --> 00:12:06,470
have a Kafka cluster to run Kafka I mean

00:12:02,769 --> 00:12:09,079
and there are a set of applications that

00:12:06,470 --> 00:12:10,730
sort of uses this Kafka gesture you have

00:12:09,079 --> 00:12:12,800
producers that

00:12:10,730 --> 00:12:15,139
some produce and write data to the

00:12:12,800 --> 00:12:17,269
topics consumers that will consume data

00:12:15,139 --> 00:12:20,180
maybe build up some internal state or do

00:12:17,269 --> 00:12:27,410
some processing there's a separate class

00:12:20,180 --> 00:12:28,970
of of applications that that you can

00:12:27,410 --> 00:12:30,769
call connectors where you can sort of

00:12:28,970 --> 00:12:33,260
connect the changelog from your database

00:12:30,769 --> 00:12:34,910
or the other way around to keep Kafka

00:12:33,260 --> 00:12:37,010
and your database in sync and then you

00:12:34,910 --> 00:12:39,350
have this dream process your apps which

00:12:37,010 --> 00:12:42,279
I would reads and writes to the Kafka

00:12:39,350 --> 00:12:45,550
cluster and in the same operations and

00:12:42,279 --> 00:12:49,100
and they can have more cool stuff like

00:12:45,550 --> 00:12:50,690
joins aggregates group eyes and that

00:12:49,100 --> 00:12:57,800
kind of thing and this is where you find

00:12:50,690 --> 00:13:00,170
Kafka streams although so the topic is

00:12:57,800 --> 00:13:01,760
the topic and the way they distributed

00:13:00,170 --> 00:13:05,540
the way they scale is sort of that the

00:13:01,760 --> 00:13:07,220
main thing about Kafka that that's sort

00:13:05,540 --> 00:13:09,649
of the brilliance of it but there is one

00:13:07,220 --> 00:13:12,139
one other concept that at least in my

00:13:09,649 --> 00:13:15,380
own opinion is equally important and

00:13:12,139 --> 00:13:18,170
that's the that's the abstraction of a

00:13:15,380 --> 00:13:20,810
Kafka consumer group because in our case

00:13:18,170 --> 00:13:23,839
on the slide here we have a consumer

00:13:20,810 --> 00:13:26,120
Kafka consumer that consumes from 12

00:13:23,839 --> 00:13:28,399
partitions and they this sort of and you

00:13:26,120 --> 00:13:31,100
have if you have three and three threads

00:13:28,399 --> 00:13:34,160
stay even out so they process four

00:13:31,100 --> 00:13:36,500
partitions each however it could be like

00:13:34,160 --> 00:13:38,089
this event this breaking news like the

00:13:36,500 --> 00:13:40,040
event volume increases and you're going

00:13:38,089 --> 00:13:42,230
to need more power to process this and

00:13:40,040 --> 00:13:44,930
you can actually just start another

00:13:42,230 --> 00:13:46,490
consumer thread and that doesn't even

00:13:44,930 --> 00:13:48,620
need to be on the same machine that can

00:13:46,490 --> 00:13:51,050
be an entirely different machine

00:13:48,620 --> 00:13:53,949
entirely different container or anything

00:13:51,050 --> 00:13:57,050
and Kafka will behind the scenes

00:13:53,949 --> 00:13:58,880
redistribute the load so and this way

00:13:57,050 --> 00:14:02,380
you can scale your application as long

00:13:58,880 --> 00:14:02,380
as you have enough partitions

00:14:06,210 --> 00:14:13,560
okay so let's that's sort of the better

00:14:10,540 --> 00:14:15,820
the context that the Technol like the

00:14:13,560 --> 00:14:17,710
the business case and we talked a little

00:14:15,820 --> 00:14:20,740
about like the technology we're going to

00:14:17,710 --> 00:14:22,780
use to solve this problem so let's start

00:14:20,740 --> 00:14:23,770
developing the actual application that

00:14:22,780 --> 00:14:27,550
will do this

00:14:23,770 --> 00:14:30,340
these lookups for us and as you guessed

00:14:27,550 --> 00:14:34,350
we're using Kafka streams to do that so

00:14:30,340 --> 00:14:37,660
very very simplified the original set up

00:14:34,350 --> 00:14:40,480
looks like this we have the firehose

00:14:37,660 --> 00:14:42,340
containing all of the events that we

00:14:40,480 --> 00:14:44,800
ingest into the pipeline and we have a

00:14:42,340 --> 00:14:48,010
filter and transform component that will

00:14:44,800 --> 00:14:50,500
filter the events and only forward those

00:14:48,010 --> 00:14:55,000
that are relevant to the advertisement

00:14:50,500 --> 00:14:58,180
team and the segmentation engine yeah

00:14:55,000 --> 00:14:59,770
and this app also it's not shown here on

00:14:58,180 --> 00:15:01,840
the slide it probably should this sort

00:14:59,770 --> 00:15:03,730
of is the main workhorse of the

00:15:01,840 --> 00:15:05,680
streaming data platform so this this

00:15:03,730 --> 00:15:08,470
filter and transform component there's a

00:15:05,680 --> 00:15:10,750
lot of the work in the data platform and

00:15:08,470 --> 00:15:14,170
it writes to several topics and have

00:15:10,750 --> 00:15:19,060
many many use cases so we kind of want

00:15:14,170 --> 00:15:20,050
to leave that component alone so I mean

00:15:19,060 --> 00:15:22,600
but that's the brilliant about

00:15:20,050 --> 00:15:24,700
brilliance about Kafka you can have

00:15:22,600 --> 00:15:28,420
multiple consumers consuming from the

00:15:24,700 --> 00:15:30,670
same topic so it felt safe to create

00:15:28,420 --> 00:15:34,150
something new something that didn't

00:15:30,670 --> 00:15:36,010
affect the already running system I mean

00:15:34,150 --> 00:15:39,700
that affects advertising but a lot of

00:15:36,010 --> 00:15:42,160
other teams as well and we wanted it to

00:15:39,700 --> 00:15:46,750
look up the API and create a known and

00:15:42,160 --> 00:15:48,970
known topic with the location data so to

00:15:46,750 --> 00:15:51,790
set up a Kafka streams application you

00:15:48,970 --> 00:15:54,760
need to come config parameters you need

00:15:51,790 --> 00:15:57,130
to set the application name or

00:15:54,760 --> 00:16:00,070
application ID and you also need to

00:15:57,130 --> 00:16:04,210
specify the address of one of the Kafka

00:16:00,070 --> 00:16:06,490
brokers in your cluster then you create

00:16:04,210 --> 00:16:07,780
this case dream builder class and this

00:16:06,490 --> 00:16:09,880
is where you create the actual

00:16:07,780 --> 00:16:12,190
application the actual topology and I am

00:16:09,880 --> 00:16:14,200
multiple slides on that later but once

00:16:12,190 --> 00:16:17,110
your topology is ready you create the

00:16:14,200 --> 00:16:19,190
Kafka streams instance and you start it

00:16:17,110 --> 00:16:21,319
and then you

00:16:19,190 --> 00:16:26,149
it's a good practice to add a shutdown

00:16:21,319 --> 00:16:29,629
hook as well so you can handle shutdowns

00:16:26,149 --> 00:16:32,269
gracefully and that's it and this is it

00:16:29,629 --> 00:16:34,519
doesn't require any except for of course

00:16:32,269 --> 00:16:37,370
having your Kafka brokers up this is a

00:16:34,519 --> 00:16:39,529
standalone JVM application you don't

00:16:37,370 --> 00:16:43,040
need any particular infrastructure you

00:16:39,529 --> 00:16:45,740
don't need yarn or anything to run this

00:16:43,040 --> 00:16:48,050
it's just a library and that's sort of

00:16:45,740 --> 00:16:52,750
one of the things I really like about

00:16:48,050 --> 00:16:52,750
Kafka as cough cough cough cough dreams

00:16:55,269 --> 00:17:04,150
okay so let's do the first attempt to

00:16:57,620 --> 00:17:06,919
read the firehose we set up a stream

00:17:04,150 --> 00:17:09,110
where we where we specify the name of

00:17:06,919 --> 00:17:11,510
the topic and we specified specify

00:17:09,110 --> 00:17:14,750
something called the sword a sword is

00:17:11,510 --> 00:17:17,539
short for sterilizer deserialize ER or

00:17:14,750 --> 00:17:21,919
something like that and and that sort of

00:17:17,539 --> 00:17:24,850
is is how Kafka knows how to to sort of

00:17:21,919 --> 00:17:30,830
translate the bytes on the topics into

00:17:24,850 --> 00:17:32,600
Java objects and vice-versa so a Kafka

00:17:30,830 --> 00:17:35,210
stream comes with a built-in cert for

00:17:32,600 --> 00:17:37,640
Strings but it doesn't come with any

00:17:35,210 --> 00:17:40,940
JSON support and we use Jason and

00:17:37,640 --> 00:17:43,940
shipstead I'm sorry so we have to create

00:17:40,940 --> 00:17:46,070
our own custom jason sword to solve this

00:17:43,940 --> 00:17:49,490
problem and doing so is fairly

00:17:46,070 --> 00:17:53,960
straightforward you implement an

00:17:49,490 --> 00:17:55,039
interface where you need to override in

00:17:53,960 --> 00:17:58,010
short you need to override the

00:17:55,039 --> 00:18:00,620
deserialize and serialize methods in our

00:17:58,010 --> 00:18:05,960
case we use jackson to to perform this

00:18:00,620 --> 00:18:07,970
for us and yeah that's it we did we

00:18:05,960 --> 00:18:10,220
specify the code how to go from from

00:18:07,970 --> 00:18:14,360
bytes to jason nodes and from jason

00:18:10,220 --> 00:18:18,140
notes to bytes so this is how it looks

00:18:14,360 --> 00:18:21,740
like now and i can tell you already this

00:18:18,140 --> 00:18:24,380
doesn't really work I don't expect you

00:18:21,740 --> 00:18:25,909
guys to read the entire slide here there

00:18:24,380 --> 00:18:28,850
are some hints of what happened it's

00:18:25,909 --> 00:18:33,039
some failed to deserialize Jason parse

00:18:28,850 --> 00:18:35,679
exception pending shut down that

00:18:33,039 --> 00:18:38,259
so it turns out I had this was my local

00:18:35,679 --> 00:18:42,429
development moment I had some garbage in

00:18:38,259 --> 00:18:45,369
my topic that didn't really parse as

00:18:42,429 --> 00:18:47,080
Jason and you guys might think well but

00:18:45,369 --> 00:18:50,379
in production don't you always have

00:18:47,080 --> 00:18:52,360
Jason sort of but I mean you do get

00:18:50,379 --> 00:18:55,269
garbage in your pipelines and we need to

00:18:52,360 --> 00:18:57,220
be able to handle that so what we need

00:18:55,269 --> 00:18:59,889
to do is sort of take back control so we

00:18:57,220 --> 00:19:07,330
want to handle the parsing ourselves

00:18:59,889 --> 00:19:10,240
within within the topology so we instead

00:19:07,330 --> 00:19:15,129
of using this Jason Jason node surd we

00:19:10,240 --> 00:19:18,009
use a byte cert and then we map the

00:19:15,129 --> 00:19:20,379
values ourselves but this time we wrap

00:19:18,009 --> 00:19:23,919
it in a try I mean we do a try-catch

00:19:20,379 --> 00:19:26,169
operation the Scala functional way and

00:19:23,919 --> 00:19:29,409
we only include those values that

00:19:26,169 --> 00:19:32,950
actually parses and so we add a filter

00:19:29,409 --> 00:19:37,690
and then we we sort of get the results

00:19:32,950 --> 00:19:40,749
of the successful parts parcels and so

00:19:37,690 --> 00:19:42,249
here I introduced the map values which

00:19:40,749 --> 00:19:45,039
you can call in the stream and also also

00:19:42,249 --> 00:19:47,049
a filter but what they say it when

00:19:45,039 --> 00:19:49,419
there's a filter and there's a map there

00:19:47,049 --> 00:19:51,399
is also a flat map and luckily kafka

00:19:49,419 --> 00:19:55,539
stream provides that to us so we made

00:19:51,399 --> 00:19:59,039
that a little simpler so now we have a

00:19:55,539 --> 00:20:03,970
stream of string keys and Jason old

00:19:59,039 --> 00:20:06,129
values we need to to work with we need

00:20:03,970 --> 00:20:08,649
to turn these these jason old into

00:20:06,129 --> 00:20:11,320
request objects that looks like this

00:20:08,649 --> 00:20:12,789
i told you i was going to show you all

00:20:11,320 --> 00:20:14,049
the lines of the code i'm not going to

00:20:12,789 --> 00:20:16,539
show you this it doesn't really matter

00:20:14,049 --> 00:20:18,610
it's adjacent node to request function

00:20:16,539 --> 00:20:26,019
that will sort of extract the relevant

00:20:18,610 --> 00:20:30,789
values so we will map all of these these

00:20:26,019 --> 00:20:33,220
jason nodes into into request objects

00:20:30,789 --> 00:20:35,259
using my values and not now i'm going to

00:20:33,220 --> 00:20:36,669
introduce to you a new function on the k

00:20:35,259 --> 00:20:39,429
string class which is called peak

00:20:36,669 --> 00:20:41,019
because I'm interesting in how many of

00:20:39,429 --> 00:20:43,090
these events we can use so peak is a

00:20:41,019 --> 00:20:45,750
very nice function to handle

00:20:43,090 --> 00:20:47,760
side-effects that lets you inspect each

00:20:45,750 --> 00:20:49,820
like inspect like look at every single

00:20:47,760 --> 00:20:53,670
element with AK without actually

00:20:49,820 --> 00:20:56,340
modifying them so this is perfect to to

00:20:53,670 --> 00:20:58,500
increase metrics for instance to to

00:20:56,340 --> 00:21:04,070
measure the performance and the quality

00:20:58,500 --> 00:21:06,570
of the pipeline and then for all of the

00:21:04,070 --> 00:21:09,090
request objects that actually has a

00:21:06,570 --> 00:21:16,230
value we do a flat map and we end up

00:21:09,090 --> 00:21:19,230
with the stream of requests okay

00:21:16,230 --> 00:21:22,530
let's produce the output so based on the

00:21:19,230 --> 00:21:26,420
stream with requests we hand it over to

00:21:22,530 --> 00:21:31,890
a transformer a location API transformer

00:21:26,420 --> 00:21:34,380
and we're also curious about how this

00:21:31,890 --> 00:21:36,780
transformer performs like we need to see

00:21:34,380 --> 00:21:41,190
how many coordinates were successfully

00:21:36,780 --> 00:21:43,860
looked up and how many like we didn't

00:21:41,190 --> 00:21:46,020
find and when we're done we have a

00:21:43,860 --> 00:21:50,760
similar inverse function where we met

00:21:46,020 --> 00:21:55,440
from from response objects into JSON and

00:21:50,760 --> 00:21:57,810
then we put it back on the Kafka cluster

00:21:55,440 --> 00:21:59,100
to the location data topic and now you

00:21:57,810 --> 00:22:03,930
guys are hold on hold on what's

00:21:59,100 --> 00:22:07,080
happening here what is this do you

00:22:03,930 --> 00:22:09,210
remember that I told you we cannot look

00:22:07,080 --> 00:22:13,020
up one single event at a time we need to

00:22:09,210 --> 00:22:16,320
do some bulking of requests well so it

00:22:13,020 --> 00:22:19,260
turns out in order to do bulking we

00:22:16,320 --> 00:22:22,620
cannot easily use the the sort of

00:22:19,260 --> 00:22:24,870
functionality that the Kafka streams DSL

00:22:22,620 --> 00:22:27,900
provides because Kafka streams DSL which

00:22:24,870 --> 00:22:29,970
I've showed you so far looks very much

00:22:27,900 --> 00:22:32,610
like how a bright spark code how you'd

00:22:29,970 --> 00:22:35,070
write in functional programming and so

00:22:32,610 --> 00:22:37,950
on but in order to do the bulking and

00:22:35,070 --> 00:22:41,520
work on multiple events items at a time

00:22:37,950 --> 00:22:44,610
we need to use something called the

00:22:41,520 --> 00:22:47,820
Kafka streams processor API and the

00:22:44,610 --> 00:22:51,750
processor API is quite large in itself

00:22:47,820 --> 00:22:54,240
but one of the interfaces in this

00:22:51,750 --> 00:22:56,760
process right API is something called

00:22:54,240 --> 00:22:58,740
the transformer the transformer has four

00:22:56,760 --> 00:22:59,160
function it has an initialize and a

00:22:58,740 --> 00:23:02,430
closed

00:22:59,160 --> 00:23:05,670
function and then it has two methods one

00:23:02,430 --> 00:23:08,040
it's called transform and that one is

00:23:05,670 --> 00:23:10,980
called every time on each single event

00:23:08,040 --> 00:23:14,610
in the stream and the second one is

00:23:10,980 --> 00:23:18,270
called punctuate which is a method that

00:23:14,610 --> 00:23:20,090
is called periodically and this is what

00:23:18,270 --> 00:23:27,420
we're going to use to actually trigger

00:23:20,090 --> 00:23:31,320
requests to the API so to set it up we

00:23:27,420 --> 00:23:35,240
store the processor context that that

00:23:31,320 --> 00:23:38,040
comes into - through the unit function

00:23:35,240 --> 00:23:40,230
we also schedule punctuate to be called

00:23:38,040 --> 00:23:43,410
like we just have to pick a number so we

00:23:40,230 --> 00:23:45,960
picked 500 milliseconds so now punctuate

00:23:43,410 --> 00:23:48,720
will be called every 500 milliseconds

00:23:45,960 --> 00:23:50,490
and there are also two more things here

00:23:48,720 --> 00:23:53,130
in the slide that are there's a buffer

00:23:50,490 --> 00:23:55,790
which is where we'll keep our events and

00:23:53,130 --> 00:23:59,160
tickle will look them up and there's a

00:23:55,790 --> 00:24:00,990
location API client which is I mean it's

00:23:59,160 --> 00:24:01,440
it's out of scope to show you how that

00:24:00,990 --> 00:24:04,530
works

00:24:01,440 --> 00:24:06,210
it's an HTTP client where we can that

00:24:04,530 --> 00:24:14,010
inputs request objects and return

00:24:06,210 --> 00:24:16,650
response objects the transform function

00:24:14,010 --> 00:24:18,990
is super simple because every time and

00:24:16,650 --> 00:24:20,580
we see a new event in the stream we want

00:24:18,990 --> 00:24:22,740
to add it to the buffer and nothing more

00:24:20,580 --> 00:24:24,510
we could have returned the value here

00:24:22,740 --> 00:24:26,460
but we don't want to so that's why we

00:24:24,510 --> 00:24:29,700
returned no we the only thing we do is

00:24:26,460 --> 00:24:33,900
we add this tuple to the buffer the fun

00:24:29,700 --> 00:24:36,870
part is mr. punctuated method because

00:24:33,900 --> 00:24:38,610
here this is Scala by the way I guess

00:24:36,870 --> 00:24:42,780
most of you guys already figured that

00:24:38,610 --> 00:24:45,660
out we take all the requests in the

00:24:42,780 --> 00:24:48,180
buffer and we group them in sort of the

00:24:45,660 --> 00:24:51,720
size that is optimal for the API which

00:24:48,180 --> 00:24:54,900
is in our case is 250 and we do this

00:24:51,720 --> 00:24:57,990
boat Locker lookup operation and then we

00:24:54,900 --> 00:24:59,970
do some let me sort of look up all the

00:24:57,990 --> 00:25:02,610
requests we await the results and then

00:24:59,970 --> 00:25:04,620
we look up the corresponding keys for

00:25:02,610 --> 00:25:08,190
for all the requests we have stored and

00:25:04,620 --> 00:25:10,880
then we call context forward with our

00:25:08,190 --> 00:25:13,020
response and that way we're emitting

00:25:10,880 --> 00:25:17,850
data down to like

00:25:13,020 --> 00:25:21,630
the downstream elements however

00:25:17,850 --> 00:25:23,640
unfortunately our API only returns

00:25:21,630 --> 00:25:27,480
successful lookups we need to sort of

00:25:23,640 --> 00:25:30,480
iterate over all the keys we didn't find

00:25:27,480 --> 00:25:33,000
and where we omit like these non values

00:25:30,480 --> 00:25:35,670
because those are really important to we

00:25:33,000 --> 00:25:38,190
don't wanna we want to forward as many

00:25:35,670 --> 00:25:42,270
events from this transformer as we got

00:25:38,190 --> 00:25:44,700
in after we did after we've sort of

00:25:42,270 --> 00:25:46,560
committed sorry after we forwarded all

00:25:44,700 --> 00:25:49,530
the events we're supposed to forward

00:25:46,560 --> 00:25:52,530
then we commit everything and clear the

00:25:49,530 --> 00:25:56,280
buffer and we return nothing because

00:25:52,530 --> 00:25:59,430
we've already returned what we wanted to

00:25:56,280 --> 00:26:01,230
return and I mean this doesn't really

00:25:59,430 --> 00:26:03,690
matter what's on this slide here except

00:26:01,230 --> 00:26:05,490
for what I've sort of marked here and

00:26:03,690 --> 00:26:08,940
that is you have the possibility to

00:26:05,490 --> 00:26:13,650
forward an arbitrary amount of events in

00:26:08,940 --> 00:26:16,530
this in this using this process for API

00:26:13,650 --> 00:26:19,590
and that's and that's how we solve our

00:26:16,530 --> 00:26:22,230
problem okay just a small recap this is

00:26:19,590 --> 00:26:23,550
actually except for the more advanced

00:26:22,230 --> 00:26:25,620
transformer this is how our application

00:26:23,550 --> 00:26:27,960
looks like and honestly I think it's

00:26:25,620 --> 00:26:30,990
quite easy to to reason about that this

00:26:27,960 --> 00:26:32,520
sort of looks right and this is like the

00:26:30,990 --> 00:26:35,370
development time of such application

00:26:32,520 --> 00:26:38,610
isn't that long there's one more problem

00:26:35,370 --> 00:26:40,710
though and we haven't joined the streams

00:26:38,610 --> 00:26:43,920
like its location data without anything

00:26:40,710 --> 00:26:48,810
else is useless so let's join Kafka

00:26:43,920 --> 00:26:51,630
stream supports joints what we do is we

00:26:48,810 --> 00:26:54,870
create two streams one for location data

00:26:51,630 --> 00:26:56,400
and one for this relevant user data we

00:26:54,870 --> 00:26:57,810
call the joint operation on the stream

00:26:56,400 --> 00:26:59,940
and then we specify the stream we want

00:26:57,810 --> 00:27:01,890
to join with and this is an inner join

00:26:59,940 --> 00:27:05,250
that means you need events from both

00:27:01,890 --> 00:27:07,620
streams in order to to join them and

00:27:05,250 --> 00:27:09,540
then you specify the function they'd

00:27:07,620 --> 00:27:11,550
like the joint function in our case we

00:27:09,540 --> 00:27:15,840
just mutate the JSON object we set the

00:27:11,550 --> 00:27:20,520
location in the user data object and and

00:27:15,840 --> 00:27:22,380
inject location event then we specified

00:27:20,520 --> 00:27:25,410
join window I have a slide on that

00:27:22,380 --> 00:27:26,680
coming and right next after this so I'll

00:27:25,410 --> 00:27:29,020
explain it then

00:27:26,680 --> 00:27:32,050
and then actually we need to specify the

00:27:29,020 --> 00:27:34,390
search for this join and the reason that

00:27:32,050 --> 00:27:36,670
the first one is the the search for key

00:27:34,390 --> 00:27:39,850
and the second the two after that is

00:27:36,670 --> 00:27:41,740
third for that two values in the stream

00:27:39,850 --> 00:27:45,520
and the reason why we need to do that is

00:27:41,740 --> 00:27:48,120
because join is stateful operation so it

00:27:45,520 --> 00:27:51,190
actually materialized the join in a

00:27:48,120 --> 00:27:52,720
change log topic behind-the-scenes so it

00:27:51,190 --> 00:27:55,900
needs to be able to serialize and

00:27:52,720 --> 00:27:58,710
deserialize these values and then we for

00:27:55,900 --> 00:28:03,040
relate to this user data with location

00:27:58,710 --> 00:28:04,630
topic you about join Windows is I'm not

00:28:03,040 --> 00:28:07,450
sure if you remember from earlier

00:28:04,630 --> 00:28:10,360
presentation I said each cough country

00:28:07,450 --> 00:28:13,360
has a key a value and a timestamp so far

00:28:10,360 --> 00:28:15,910
we've only focused on the value now it's

00:28:13,360 --> 00:28:19,120
time to like but the join uses the key

00:28:15,910 --> 00:28:22,240
and the timestamp because of course two

00:28:19,120 --> 00:28:24,220
keys we leave our keys unchanged during

00:28:22,240 --> 00:28:27,970
this processing we never touch them so

00:28:24,220 --> 00:28:31,030
and the keys will be the same for the

00:28:27,970 --> 00:28:33,430
for both the load like the relevant user

00:28:31,030 --> 00:28:35,650
data event and also the corresponding

00:28:33,430 --> 00:28:37,660
location data event however for

00:28:35,650 --> 00:28:39,700
something to qualify for a join the key

00:28:37,660 --> 00:28:41,860
obviously needs to be the same but you

00:28:39,700 --> 00:28:44,860
also need to be within a specific time

00:28:41,860 --> 00:28:47,710
window so that means the location event

00:28:44,860 --> 00:28:50,320
needs to sort of arrive within 10

00:28:47,710 --> 00:28:53,530
seconds either 10 seconds before and

00:28:50,320 --> 00:28:56,860
which is impossible in our case no it's

00:28:53,530 --> 00:28:58,300
not by the way or 10 seconds after it

00:28:56,860 --> 00:29:00,220
needs to come in between that window

00:28:58,300 --> 00:29:05,200
else it doesn't really qualify for the

00:29:00,220 --> 00:29:07,240
join and the reason why we picked this

00:29:05,200 --> 00:29:10,720
window is like if we don't see this

00:29:07,240 --> 00:29:15,520
event after 10 seconds it's no longer

00:29:10,720 --> 00:29:18,040
usable for advertising purposes we have

00:29:15,520 --> 00:29:20,200
some okay so we now let's put everything

00:29:18,040 --> 00:29:22,600
into sort of deploy it put it into

00:29:20,200 --> 00:29:26,920
production and I'll tell you guys what

00:29:22,600 --> 00:29:30,160
works and what doesn't work at least in

00:29:26,920 --> 00:29:33,190
our experience so first we put this

00:29:30,160 --> 00:29:35,530
thing into production and I can't say

00:29:33,190 --> 00:29:39,790
nothing more that this really worked and

00:29:35,530 --> 00:29:40,429
it worked quite well I'd say this is the

00:29:39,790 --> 00:29:43,549
latency

00:29:40,429 --> 00:29:45,919
measurements with the 500 millisecond

00:29:43,549 --> 00:29:47,840
punctuated punctuation interval we had

00:29:45,919 --> 00:29:50,269
the latency between 400 and 500

00:29:47,840 --> 00:29:53,330
milliseconds extra on each event for

00:29:50,269 --> 00:29:55,519
this turns out I P addresses tend to be

00:29:53,330 --> 00:29:57,710
sent to see a lot of the same IP

00:29:55,519 --> 00:30:00,259
addresses and like the location API will

00:29:57,710 --> 00:30:02,240
always return not always but for the

00:30:00,259 --> 00:30:04,490
course of 24 hours even know normally

00:30:02,240 --> 00:30:06,350
return the same values for a specific IP

00:30:04,490 --> 00:30:09,470
address so we implemented a named memory

00:30:06,350 --> 00:30:12,950
cache using guava and that sort of

00:30:09,470 --> 00:30:16,309
reduced the latency to 80 milliseconds

00:30:12,950 --> 00:30:19,249
perhaps and then we reduced the

00:30:16,309 --> 00:30:20,990
punctuation interval to 100 milliseconds

00:30:19,249 --> 00:30:23,869
and now we're down to 2 somewhere

00:30:20,990 --> 00:30:27,590
between 30 and 40 milliseconds latency

00:30:23,869 --> 00:30:30,350
and that's additional to what they I

00:30:27,590 --> 00:30:33,169
mean this is this is the time it takes

00:30:30,350 --> 00:30:35,119
for the app I showed you from when it

00:30:33,169 --> 00:30:37,340
ceased an event like it picks it up from

00:30:35,119 --> 00:30:39,350
the stream until it writes it back to

00:30:37,340 --> 00:30:42,289
the stream and I said this is this is

00:30:39,350 --> 00:30:46,100
absolutely good this is a very decent

00:30:42,289 --> 00:30:49,100
result we needed to implement the join

00:30:46,100 --> 00:30:51,320
code I showed you as well and sort of

00:30:49,100 --> 00:30:53,990
this was a very simple piece of code so

00:30:51,320 --> 00:31:00,590
well why not use this workhorse of ours

00:30:53,990 --> 00:31:02,690
to to do to join their great idea this

00:31:00,590 --> 00:31:06,259
is this is a graph showing the event

00:31:02,690 --> 00:31:08,419
volume that we work like that is being

00:31:06,259 --> 00:31:11,509
processed at a time we deployed the join

00:31:08,419 --> 00:31:13,879
and like the event volume yeah it

00:31:11,509 --> 00:31:15,169
dropped dramatically and this is very

00:31:13,879 --> 00:31:16,999
interesting and this is something you

00:31:15,169 --> 00:31:19,100
should be aware of - when you develop

00:31:16,999 --> 00:31:22,249
Kafka streams application because what

00:31:19,100 --> 00:31:25,580
happen it's like we we do this red black

00:31:22,249 --> 00:31:28,519
style deployment where we have an old

00:31:25,580 --> 00:31:31,159
cluster and then we deploy a new cluster

00:31:28,519 --> 00:31:33,679
I mean they have more threads than three

00:31:31,159 --> 00:31:38,030
each of course

00:31:33,679 --> 00:31:41,490
okay so when we deploy a new new cluster

00:31:38,030 --> 00:31:44,460
the kafka consumer group or like behind

00:31:41,490 --> 00:31:46,380
the scenes will try to distribute this

00:31:44,460 --> 00:31:48,539
is the fire hose that is represented

00:31:46,380 --> 00:31:50,490
with these green arrows to the new

00:31:48,539 --> 00:31:53,190
cluster and I mean this is everyone's

00:31:50,490 --> 00:31:55,669
happy about this however the new cluster

00:31:53,190 --> 00:31:59,669
will also start processing the new input

00:31:55,669 --> 00:32:05,100
topic which is contains the location

00:31:59,669 --> 00:32:07,350
data and so far so good what happens now

00:32:05,100 --> 00:32:09,390
is the new cluster see so there's this

00:32:07,350 --> 00:32:12,030
consumer group it doesn't really consume

00:32:09,390 --> 00:32:13,770
this new location data topic so it tries

00:32:12,030 --> 00:32:15,720
to hand it over to the old cluster and

00:32:13,770 --> 00:32:18,360
the whole cluster it doesn't have any

00:32:15,720 --> 00:32:22,380
cold even so this thing yeah it goes

00:32:18,360 --> 00:32:25,470
down and you think we should be fine

00:32:22,380 --> 00:32:29,880
by sort of you hardly like I mean

00:32:25,470 --> 00:32:32,880
removing this old cluster completely and

00:32:29,880 --> 00:32:35,280
sort of now only the new cluster is here

00:32:32,880 --> 00:32:37,950
but this is super unhappy to about not

00:32:35,280 --> 00:32:40,559
being able to that the other cluster

00:32:37,950 --> 00:32:42,590
died so now we have nothing and this is

00:32:40,559 --> 00:32:46,860
sort of what happened

00:32:42,590 --> 00:32:49,169
so we did a new attempt we this time we

00:32:46,860 --> 00:32:51,450
had a control we scaled down our entire

00:32:49,169 --> 00:32:53,490
old cluster first and we scaled up the

00:32:51,450 --> 00:32:56,610
new one and that word for ten minutes

00:32:53,490 --> 00:32:58,799
and yeah we gave up after that we're not

00:32:56,610 --> 00:33:02,669
touching that up anymore with anymore

00:32:58,799 --> 00:33:05,490
joints I'll come back to that later mmm

00:33:02,669 --> 00:33:07,650
but we did see a very interesting fault

00:33:05,490 --> 00:33:10,380
which I haven't seen in a while it was a

00:33:07,650 --> 00:33:12,570
segmentation fault I'm pretty sure

00:33:10,380 --> 00:33:16,200
that's not really what you know their

00:33:12,570 --> 00:33:17,780
actual error is but we were maybe we

00:33:16,200 --> 00:33:21,210
were lucky maybe we did some good work

00:33:17,780 --> 00:33:22,620
figuring out what happened but it's that

00:33:21,210 --> 00:33:24,690
the problem was with the joint window

00:33:22,620 --> 00:33:26,880
because even though we have specified a

00:33:24,690 --> 00:33:29,700
joint mean of ten seconds that doesn't

00:33:26,880 --> 00:33:32,730
the joint is still has a retention time

00:33:29,700 --> 00:33:34,409
of 24 hours so that means every time it

00:33:32,730 --> 00:33:36,419
sees an event it need to browse all

00:33:34,409 --> 00:33:39,960
those perhaps they have they of course

00:33:36,419 --> 00:33:42,570
have a more much more a much better data

00:33:39,960 --> 00:33:44,370
structure than a linear search but still

00:33:42,570 --> 00:33:47,740
it will have to keep all of those 800

00:33:44,370 --> 00:33:50,380
million events in in the join window

00:33:47,740 --> 00:33:54,430
or in the joint so you can actually

00:33:50,380 --> 00:33:59,140
specify to reduce the join windows

00:33:54,430 --> 00:34:01,450
substantially I set it to reset it to 30

00:33:59,140 --> 00:34:04,300
seconds so that means after 30 seconds

00:34:01,450 --> 00:34:06,100
like whatever whatever is in your joint

00:34:04,300 --> 00:34:10,750
is lost and I mean this is fine for our

00:34:06,100 --> 00:34:12,970
case and yeah we learned something new

00:34:10,750 --> 00:34:16,660
also we're not touching this filter and

00:34:12,970 --> 00:34:18,190
transform application anymore because

00:34:16,660 --> 00:34:20,550
our team started getting really bad

00:34:18,190 --> 00:34:25,180
reputation for not providing a

00:34:20,550 --> 00:34:27,880
sufficiently good service so we

00:34:25,180 --> 00:34:32,010
implemented the new in a new application

00:34:27,880 --> 00:34:32,010
and yeah if it worked

00:34:32,490 --> 00:34:37,900
performance I mean I used to be a little

00:34:35,830 --> 00:34:39,550
happy about this performance I'm no

00:34:37,900 --> 00:34:43,570
longer happy about this performance

00:34:39,550 --> 00:34:46,300
because in what this slide shows is that

00:34:43,570 --> 00:34:48,490
like the actual a latency of doing the

00:34:46,300 --> 00:34:50,830
HTTP lookups it's it's very small

00:34:48,490 --> 00:34:57,360
compared to the overhead of doing the

00:34:50,830 --> 00:35:01,210
joints and so on and it turned out this

00:34:57,360 --> 00:35:03,340
solution like we wanted a solution that

00:35:01,210 --> 00:35:09,070
could handle errors in the location API

00:35:03,340 --> 00:35:12,370
or in the like errors in the location

00:35:09,070 --> 00:35:14,740
transformer itself by like splitting it

00:35:12,370 --> 00:35:16,870
up having one app for joins one app for

00:35:14,740 --> 00:35:19,240
location transformer but we didn't get

00:35:16,870 --> 00:35:22,270
any of these flexibility at all because

00:35:19,240 --> 00:35:23,830
I mean if this crashes then I mean this

00:35:22,270 --> 00:35:27,640
could crash I mean this could crash

00:35:23,830 --> 00:35:29,890
separately this location data topic will

00:35:27,640 --> 00:35:33,550
go dry there will be no events and since

00:35:29,890 --> 00:35:35,890
we specified inner join this thing goes

00:35:33,550 --> 00:35:38,820
try to so we've sort of gained nothing

00:35:35,890 --> 00:35:44,500
about having three applications here

00:35:38,820 --> 00:35:48,400
another thing is related to cost I'm

00:35:44,500 --> 00:35:51,070
trying to to show you guys some

00:35:48,400 --> 00:35:52,690
proportions when it comes to the cluster

00:35:51,070 --> 00:35:55,540
size because it doesn't matter how many

00:35:52,690 --> 00:35:56,940
squares are within each application but

00:35:55,540 --> 00:36:00,400
the important thing is there's

00:35:56,940 --> 00:36:01,509
proportions so the main workhorse in our

00:36:00,400 --> 00:36:03,249
streaming application that

00:36:01,509 --> 00:36:04,899
trance transform the cafetorium

00:36:03,249 --> 00:36:08,709
supplication would normally run with

00:36:04,899 --> 00:36:11,259
about eight notes and the much much

00:36:08,709 --> 00:36:13,149
simpler location API component would

00:36:11,259 --> 00:36:16,239
have somewhere between three and five

00:36:13,149 --> 00:36:19,389
nodes on average for however this thing

00:36:16,239 --> 00:36:21,999
would have 15 and not now being nice I

00:36:19,389 --> 00:36:25,649
saw 20 and 22 at some points to like

00:36:21,999 --> 00:36:33,159
keeping this join and running this is is

00:36:25,649 --> 00:36:38,019
I'd say expensive so yeah we we run this

00:36:33,159 --> 00:36:41,139
for a while and it worked but yeah we

00:36:38,019 --> 00:36:44,109
fixed it we actually dropped doing the

00:36:41,139 --> 00:36:45,789
join whatsoever so we would use the

00:36:44,109 --> 00:36:48,429
location transformer to create a

00:36:45,789 --> 00:36:51,219
relevant user data with location topic

00:36:48,429 --> 00:36:55,449
directly from this location transformer

00:36:51,219 --> 00:36:58,299
and that turn turned out to be much more

00:36:55,449 --> 00:37:00,969
cost efficient and much more I had much

00:36:58,299 --> 00:37:03,429
much lower latency as I showed you on

00:37:00,969 --> 00:37:05,169
the previous slide and to tune this

00:37:03,429 --> 00:37:06,999
trade-off between completeness and

00:37:05,169 --> 00:37:09,699
latency we have a custom circuit breaker

00:37:06,999 --> 00:37:15,159
here rather than trying to tune it at

00:37:09,699 --> 00:37:19,059
the join so I think concluding this

00:37:15,159 --> 00:37:23,589
presentation is we can do that in four

00:37:19,059 --> 00:37:25,749
simple bullets I say that Kafka streams

00:37:23,589 --> 00:37:27,369
or first sort of this straightforward

00:37:25,749 --> 00:37:29,729
application development because it's

00:37:27,369 --> 00:37:33,249
just an app that runs on your computer

00:37:29,729 --> 00:37:35,679
and as long as you only use the Kafka

00:37:33,249 --> 00:37:38,289
stream DSL it feels very familiar if

00:37:35,679 --> 00:37:40,149
you're sort of used to other frameworks

00:37:38,289 --> 00:37:42,549
like spark or if you're used to

00:37:40,149 --> 00:37:45,699
functional programming I think it scales

00:37:42,549 --> 00:37:48,279
pretty well for the basic stuff it's I

00:37:45,699 --> 00:37:49,899
mean we have to get up to two million

00:37:48,279 --> 00:37:55,269
events each minute and this application

00:37:49,899 --> 00:37:57,699
handle it no problem you should perhaps

00:37:55,269 --> 00:37:59,889
that at least this is something we've

00:37:57,699 --> 00:38:02,380
learned not only from doing this project

00:37:59,889 --> 00:38:04,539
but similar project is that the Kafka

00:38:02,380 --> 00:38:06,999
way of doing things is to have many

00:38:04,539 --> 00:38:09,159
smaller applications so if you want to

00:38:06,999 --> 00:38:13,089
go all-in on Kafka streams you should

00:38:09,159 --> 00:38:15,400
probably make sure you keep the cost of

00:38:13,089 --> 00:38:17,499
deploying new applications running you

00:38:15,400 --> 00:38:20,740
applications you should keep that cost

00:38:17,499 --> 00:38:25,299
as low as possible and in general I'd

00:38:20,740 --> 00:38:27,789
encourage some ya to be a little careful

00:38:25,299 --> 00:38:30,249
when it comes to these stateful

00:38:27,789 --> 00:38:33,279
operations because they work we've

00:38:30,249 --> 00:38:36,309
proven that they work but they can be

00:38:33,279 --> 00:38:40,769
very expensive and might not give the

00:38:36,309 --> 00:38:43,619
flexibility that that you think they may

00:38:40,769 --> 00:38:47,970
so by that I conclude my presentation

00:38:43,619 --> 00:38:47,970
and open up for questions

00:39:01,050 --> 00:39:09,670
hey thanks for showing your learnings

00:39:04,780 --> 00:39:12,580
yeah when you think about the the nodes

00:39:09,670 --> 00:39:17,500
and then I'm the application size that

00:39:12,580 --> 00:39:20,350
is not that is the actual code

00:39:17,500 --> 00:39:22,870
processing the streams not the casket

00:39:20,350 --> 00:39:24,490
cluster that's the cold processing

00:39:22,870 --> 00:39:26,200
littering the Kafka cluster is something

00:39:24,490 --> 00:39:28,000
different that does

00:39:26,200 --> 00:39:30,820
Casca streams have an impact on the

00:39:28,000 --> 00:39:32,680
casket cluster sometimes it does because

00:39:30,820 --> 00:39:34,570
it can start writing a lot of

00:39:32,680 --> 00:39:36,820
intermediate topics and those

00:39:34,570 --> 00:39:39,040
intermediate topics might not have the

00:39:36,820 --> 00:39:40,990
replication factor that we wanted so

00:39:39,040 --> 00:39:47,080
that can stall some of the applications

00:39:40,990 --> 00:39:49,720
if a broker goes offline cool things and

00:39:47,080 --> 00:39:53,050
I saw that you use fire hose on Kafka

00:39:49,720 --> 00:39:55,780
fire hoses they a Douglas fir oh no fire

00:39:53,050 --> 00:39:58,450
hose is sort of my name for a topic that

00:39:55,780 --> 00:40:04,650
contains everything and the name of the

00:39:58,450 --> 00:40:04,650
topic is fire hose thanks

00:40:09,470 --> 00:40:12,950
other questions

00:40:17,130 --> 00:40:22,450
thanks for a great presentation thank

00:40:19,780 --> 00:40:24,310
you said that you had some problems were

00:40:22,450 --> 00:40:27,130
the joints and I noticed that was

00:40:24,310 --> 00:40:29,320
between two streams yeah and then you

00:40:27,130 --> 00:40:31,090
fold it for that solution and try

00:40:29,320 --> 00:40:34,150
something else do you do still use

00:40:31,090 --> 00:40:37,030
joints between streams and streams or

00:40:34,150 --> 00:40:42,610
streams and tables anywhere else we

00:40:37,030 --> 00:40:44,950
don't and yeah no we don't and I tried

00:40:42,610 --> 00:40:47,350
actually using global K tables for the

00:40:44,950 --> 00:40:51,070
cash like to store the results for the

00:40:47,350 --> 00:40:58,360
lookups that didn't work at all okay

00:40:51,070 --> 00:40:59,710
cool Thanks you know why did you

00:40:58,360 --> 00:41:01,990
conclude that you need smaller

00:40:59,710 --> 00:41:05,110
deployments instead of multiple

00:41:01,990 --> 00:41:07,660
topologies in the same because of the

00:41:05,110 --> 00:41:11,430
issue with this you know the saw crash

00:41:07,660 --> 00:41:16,240
and fire on my slides this thing yeah I

00:41:11,430 --> 00:41:18,910
mean for this like these applications we

00:41:16,240 --> 00:41:22,060
run in our streaming platform there we

00:41:18,910 --> 00:41:25,510
don't want any downtime on this and in

00:41:22,060 --> 00:41:26,980
order to add like multiple topologies to

00:41:25,510 --> 00:41:28,450
an application you actually need to do a

00:41:26,980 --> 00:41:31,380
full scale down before you scale up

00:41:28,450 --> 00:41:34,930
again and that's the reason why we chose

00:41:31,380 --> 00:41:36,400
like that thank you and and we also have

00:41:34,930 --> 00:41:38,620
a set up in ships that we're deploying

00:41:36,400 --> 00:41:39,820
applications is is fairly

00:41:38,620 --> 00:41:41,380
straightforward

00:41:39,820 --> 00:41:44,650
so that means it doesn't really add much

00:41:41,380 --> 00:41:47,070
cost but it adds benefits only the

00:41:44,650 --> 00:41:47,070
benefits

00:41:57,790 --> 00:42:06,010
the last question in this last image of

00:42:04,360 --> 00:42:10,600
the architecture with the circuit

00:42:06,010 --> 00:42:15,460
breaker um just need to burn some

00:42:10,600 --> 00:42:20,350
clusters first let me see this is

00:42:15,460 --> 00:42:23,470
exactly so if if the location API fails

00:42:20,350 --> 00:42:25,060
is the message still forwarded yes so

00:42:23,470 --> 00:42:28,060
anything like it's very easy for us to

00:42:25,060 --> 00:42:29,980
tune that circuit breaker because we we

00:42:28,060 --> 00:42:31,120
can always like for every one we start

00:42:29,980 --> 00:42:33,280
trying to look up and then we just

00:42:31,120 --> 00:42:37,000
timeout and forward the original events

00:42:33,280 --> 00:42:38,620
so I wanted to use the join to tune this

00:42:37,000 --> 00:42:42,090
parameter but I couldn't get it to work

00:42:38,620 --> 00:42:45,730
because the only applicable join with

00:42:42,090 --> 00:42:48,220
was the inner join if you meet me later

00:42:45,730 --> 00:42:52,120
I can tell you why a left join doesn't

00:42:48,220 --> 00:42:55,300
work so by sort of moving that

00:42:52,120 --> 00:42:57,970
responsibility into the transformer we

00:42:55,300 --> 00:42:59,680
had a very easy opportunity to to choose

00:42:57,970 --> 00:43:02,650
how long we would wait for the location

00:42:59,680 --> 00:43:08,390
I'd be able to respond does that answer

00:43:02,650 --> 00:43:16,890
your question thank you

00:43:08,390 --> 00:43:16,890

YouTube URL: https://www.youtube.com/watch?v=Rxsz0hSG30A


