Title: Berlin Buzzwords 2018: Sophie Watson – What they didn’t teach you in Grad School #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Sophie Watson talking about "From Research to Production: What they didn’t teach you in Grad School".

Academic researchers find novel solutions to thorny problems in idealized environments. A research background is excellent preparation for advancing the state of the art, but newly-minted professional data scientists can find themselves in industry with an arsenal of problem-solving techniques that are not as potent as they seemed in graduate school:  data sets are larger and messier, solutions are judged by their outcomes rather than by their novelty, and products, unlike publications, require ongoing maintenance and support.

This talk will draw on the speaker’s experience bringing a mathematics research background to a team in industry. We will show both the challenges that data scientists face when entering industry from academia and the unique skills that they bring from their research background. We shall frame the discussion with a running example of cutting-edge statistical research embodied in an imperfect implementation. We’ll demonstrate iterative refinements to our implementation, showing how to take a research prototype to production code, with particular attention to real-world pitfalls that might not appear in a researcher’s daily work. Finally, we’ll show how trained researchers can turn their background into a superpower for applied teams in industry.

Early-career attendees who are considering joining industry from academia will learn how to navigate the challenges they’ll face on a mixed team and how to best use their gifts and skills in a new environment. Established practitioners will learn how to support, engage, and nurture their colleagues who are transitioning from academia. Everyone will learn how to adapt implementations and ideas from the research world for production applications.

Read more:
https://2018.berlinbuzzwords.de/18/session/research-production-what-they-didnt-teach-you-grad-school

About Sophie Watson:
https://2018.berlinbuzzwords.de/users/sophie-watson

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:04,570 --> 00:00:10,309
all right hi I'm Sophie I work at Red

00:00:08,000 --> 00:00:12,560
Hat as a software engineer and I'm part

00:00:10,309 --> 00:00:14,570
of a team whose focus is on designing

00:00:12,560 --> 00:00:16,100
intelligent applications to running

00:00:14,570 --> 00:00:18,380
containers on the cloud

00:00:16,100 --> 00:00:20,240
now when I say intelligent applications

00:00:18,380 --> 00:00:22,250
what I mean is applications which use

00:00:20,240 --> 00:00:26,270
machine learning or artificial

00:00:22,250 --> 00:00:28,279
intelligence nearly nine months ago I

00:00:26,270 --> 00:00:30,800
lived a very different life as a PhD

00:00:28,279 --> 00:00:33,170
student I spent four years at the

00:00:30,800 --> 00:00:35,360
University of Bristol getting a PhD from

00:00:33,170 --> 00:00:37,430
the Department of Mathematics there is a

00:00:35,360 --> 00:00:41,030
screenshot of the front cover of my

00:00:37,430 --> 00:00:42,890
thesis as proof my PhD was based in the

00:00:41,030 --> 00:00:44,719
statistics group and it focused on

00:00:42,890 --> 00:00:47,750
making inference for complex models

00:00:44,719 --> 00:00:50,960
represented here by this grey box maybe

00:00:47,750 --> 00:00:52,850
it's not so great anymore um so we were

00:00:50,960 --> 00:00:55,039
working in the Big Data regime in the

00:00:52,850 --> 00:00:57,230
sense that these models took in high

00:00:55,039 --> 00:01:00,109
dimensional parameters and spat out high

00:00:57,230 --> 00:01:01,820
dimensional data most of the models we

00:01:00,109 --> 00:01:04,159
working with were of complex ecological

00:01:01,820 --> 00:01:05,780
systems and I spent a lot of time

00:01:04,159 --> 00:01:10,880
working with the model of everybody's

00:01:05,780 --> 00:01:12,860
favorite animal the earthworm so on the

00:01:10,880 --> 00:01:14,510
surface my work here in industry is the

00:01:12,860 --> 00:01:16,790
same as it used to be I'm still doing

00:01:14,510 --> 00:01:18,530
statistics and programming I still have

00:01:16,790 --> 00:01:21,290
weekly meetings with a mentor and I

00:01:18,530 --> 00:01:22,760
still power my days with coffee but what

00:01:21,290 --> 00:01:24,770
I want to talk to you about in the next

00:01:22,760 --> 00:01:26,750
15 minutes is what's different what

00:01:24,770 --> 00:01:29,870
lives in the grey section of that Venn

00:01:26,750 --> 00:01:31,850
diagram now a sensible question to ask

00:01:29,870 --> 00:01:34,970
yourself at this point is why should you

00:01:31,850 --> 00:01:38,600
care well who here is a grad student or

00:01:34,970 --> 00:01:40,760
has recently graduated so this could be

00:01:38,600 --> 00:01:42,590
you and that's so long and even if you

00:01:40,760 --> 00:01:44,240
do decide to stay in academia you'll

00:01:42,590 --> 00:01:45,590
probably have to lay eyes with industry

00:01:44,240 --> 00:01:47,410
at some point so it's important to

00:01:45,590 --> 00:01:50,090
understand where they're coming from

00:01:47,410 --> 00:01:51,560
everyone else well it doesn't take a

00:01:50,090 --> 00:01:53,180
statistician to tell you that it's

00:01:51,560 --> 00:01:54,860
highly likely that you will at some

00:01:53,180 --> 00:01:57,080
point in your career work with someone

00:01:54,860 --> 00:01:58,580
who is or was a grad student so

00:01:57,080 --> 00:02:00,020
hopefully you can gain insight into

00:01:58,580 --> 00:02:01,820
where they're coming from and how you

00:02:00,020 --> 00:02:05,630
can support them as they turn up on day

00:02:01,820 --> 00:02:07,130
one at your office's door so to

00:02:05,630 --> 00:02:10,369
structure my talk we'll look at three

00:02:07,130 --> 00:02:11,870
objectives so both academia and industry

00:02:10,369 --> 00:02:13,790
we'll begin by talking about the goals

00:02:11,870 --> 00:02:16,370
of the work what are the notable aims

00:02:13,790 --> 00:02:18,410
and achievements will then look at what

00:02:16,370 --> 00:02:20,450
drives the work or what's the incent

00:02:18,410 --> 00:02:23,090
and finally we'll look at some barriers

00:02:20,450 --> 00:02:26,150
to progress in both academia and in

00:02:23,090 --> 00:02:28,550
industry so let's dive in and think

00:02:26,150 --> 00:02:30,260
about goals now important and think

00:02:28,550 --> 00:02:32,239
about in order to think about goals it

00:02:30,260 --> 00:02:33,920
helps us to have a specific task in mind

00:02:32,239 --> 00:02:36,890
and the task I want you to think about

00:02:33,920 --> 00:02:38,510
is building a recommendation engine from

00:02:36,890 --> 00:02:40,520
what film we should watch tonight after

00:02:38,510 --> 00:02:42,590
we've gone out for dinner to who we

00:02:40,520 --> 00:02:44,540
should follow on social media many of

00:02:42,590 --> 00:02:46,459
today's most engaging and commercially

00:02:44,540 --> 00:02:48,920
important applications are providing

00:02:46,459 --> 00:02:50,420
personalized experiences to users and

00:02:48,920 --> 00:02:52,220
they're able to make personalized

00:02:50,420 --> 00:02:55,310
recommendations quickly and efficiently

00:02:52,220 --> 00:02:57,290
and in fact I've spent some some of my

00:02:55,310 --> 00:02:59,989
time here at Red Hat working on building

00:02:57,290 --> 00:03:02,830
a recommendation engine but what we're

00:02:59,989 --> 00:03:05,090
going to think about the task as now is

00:03:02,830 --> 00:03:10,060
recommendation engines from the point of

00:03:05,090 --> 00:03:12,530
academia now in academia the goal is

00:03:10,060 --> 00:03:14,450
publications and in order to get a

00:03:12,530 --> 00:03:17,360
publication you've got to do something

00:03:14,450 --> 00:03:18,950
that no one else has done before one of

00:03:17,360 --> 00:03:21,319
the leading algorithms for

00:03:18,950 --> 00:03:23,600
recommendation engines is alternating

00:03:21,319 --> 00:03:25,730
these squares and if I do a google

00:03:23,600 --> 00:03:27,620
scholar search for papers on alternating

00:03:25,730 --> 00:03:29,420
least squares and just look at the

00:03:27,620 --> 00:03:32,660
papers this year already there's already

00:03:29,420 --> 00:03:35,780
over 3,300 of them so doing something

00:03:32,660 --> 00:03:37,760
new isn't an easy feat but if I was

00:03:35,780 --> 00:03:39,560
going to I'd probably set off by

00:03:37,760 --> 00:03:41,690
following this little flow chart here

00:03:39,560 --> 00:03:43,850
and at some point I'd stop and I'd say

00:03:41,690 --> 00:03:46,400
okay I've done better than what came

00:03:43,850 --> 00:03:48,500
before how would I know that I'd done

00:03:46,400 --> 00:03:51,230
better well I'd probably run my

00:03:48,500 --> 00:03:52,970
algorithm on a static data set but

00:03:51,230 --> 00:03:54,859
someone else had run their algorithm on

00:03:52,970 --> 00:03:57,079
in their paper and I'd show that I've

00:03:54,859 --> 00:04:01,489
got some reduction of error great I've

00:03:57,079 --> 00:04:04,970
got myself a publication so let's take

00:04:01,489 --> 00:04:07,220
such a paper such an algorithm and put

00:04:04,970 --> 00:04:08,989
it into production now the algorithm

00:04:07,220 --> 00:04:11,150
we're going to use improves on previous

00:04:08,989 --> 00:04:13,970
algorithms by accounting for temporal

00:04:11,150 --> 00:04:17,780
effects and it's legitimate it's real

00:04:13,970 --> 00:04:19,910
it's cited by 4416 people when I took

00:04:17,780 --> 00:04:22,460
this data probably more by now

00:04:19,910 --> 00:04:24,410
in order to implement it we're going to

00:04:22,460 --> 00:04:27,560
need some data so the data we're going

00:04:24,410 --> 00:04:29,659
to use is the movie lens project data so

00:04:27,560 --> 00:04:31,860
this was collected by the group lens

00:04:29,659 --> 00:04:34,889
research group at the University

00:04:31,860 --> 00:04:37,830
Minnesota and the key point is that

00:04:34,889 --> 00:04:40,650
there's 26 million ratings in them so

00:04:37,830 --> 00:04:43,620
we've got ourselves a lot of data as the

00:04:40,650 --> 00:04:47,250
name suggests this is ratings that users

00:04:43,620 --> 00:04:48,780
have made about films so let's pretend

00:04:47,250 --> 00:04:50,550
that I'm the customer and we're building

00:04:48,780 --> 00:04:52,259
this recommendation to give me a

00:04:50,550 --> 00:04:54,689
suggestion for what film I should watch

00:04:52,259 --> 00:04:56,310
now I've actually rated over a hundred

00:04:54,689 --> 00:04:58,259
films I'm just showing you a snippet

00:04:56,310 --> 00:05:00,870
here so you can see what I like in

00:04:58,259 --> 00:05:04,139
general I like kids films and I dislike

00:05:00,870 --> 00:05:06,719
scary movies so in this next cell I'm

00:05:04,139 --> 00:05:09,479
appending the ratings that I made to the

00:05:06,719 --> 00:05:12,870
26 million ratings in that movie lens

00:05:09,479 --> 00:05:15,330
dataset and then in the final cell I go

00:05:12,870 --> 00:05:16,830
ahead and I build a model now you'll

00:05:15,330 --> 00:05:19,409
have to take my word for it that those

00:05:16,830 --> 00:05:22,279
three parameters rank iterations and

00:05:19,409 --> 00:05:24,900
lambda have been selected optimally so

00:05:22,279 --> 00:05:27,719
let's talk more about that last line

00:05:24,900 --> 00:05:29,939
where we build a model this ALS train

00:05:27,719 --> 00:05:32,610
function implements the algorithm in

00:05:29,939 --> 00:05:34,620
that paper that I showed you earlier but

00:05:32,610 --> 00:05:37,139
this isn't cold I wrote I'm using an

00:05:34,620 --> 00:05:38,879
off-the-shelf implementation and this to

00:05:37,139 --> 00:05:41,759
me was the first huge difference between

00:05:38,879 --> 00:05:43,409
research and production the idea of

00:05:41,759 --> 00:05:45,300
using some code that someone else has

00:05:43,409 --> 00:05:47,610
written was not something I've done or

00:05:45,300 --> 00:05:50,400
been encouraged to do throughout my PhD

00:05:47,610 --> 00:05:52,680
and yet brings so many advantages so

00:05:50,400 --> 00:05:54,449
this code is tried and tested and it

00:05:52,680 --> 00:05:57,659
does what it says it will because loads

00:05:54,449 --> 00:05:59,520
of other people have used it first when

00:05:57,659 --> 00:06:01,349
I went to write up my thesis I had to

00:05:59,520 --> 00:06:03,750
rerun some code that I had written in my

00:06:01,349 --> 00:06:06,539
second year and you know I submit this

00:06:03,750 --> 00:06:08,279
to conferences and put in papers and all

00:06:06,539 --> 00:06:09,900
of a sudden I figure out that this code

00:06:08,279 --> 00:06:11,550
isn't doing what I thought it was and

00:06:09,900 --> 00:06:13,110
you know it's called I'd written but

00:06:11,550 --> 00:06:18,180
that's not gonna happen here this code

00:06:13,110 --> 00:06:20,430
is robust so I'm coding in Python here

00:06:18,180 --> 00:06:23,310
and this code lives in the PI Spock ml

00:06:20,430 --> 00:06:27,270
Lib recommendation and package so that's

00:06:23,310 --> 00:06:29,430
Apache spark and Python sparks designed

00:06:27,270 --> 00:06:31,289
for scale out over a large cluster and

00:06:29,430 --> 00:06:33,599
in fact it sort of does all of the work

00:06:31,289 --> 00:06:36,150
for you so within reason you don't have

00:06:33,599 --> 00:06:37,800
to worry about the scaling what happens

00:06:36,150 --> 00:06:39,779
on a basic level is that the driver

00:06:37,800 --> 00:06:41,789
program sends off the words these

00:06:39,779 --> 00:06:44,350
individual workers known as spark

00:06:41,789 --> 00:06:45,970
executors and it runs the task

00:06:44,350 --> 00:06:48,190
and then it returns output to the driver

00:06:45,970 --> 00:06:50,050
node so this allows data to be analyzed

00:06:48,190 --> 00:06:52,090
in parallel and it doesn't take any

00:06:50,050 --> 00:06:54,130
overhead for me I don't really need to

00:06:52,090 --> 00:06:56,560
know what's going on and that also came

00:06:54,130 --> 00:06:59,020
as a huge shock I've done some parallel

00:06:56,560 --> 00:07:00,850
computing during my PhD and in general

00:06:59,020 --> 00:07:02,920
I'd call did something up in a day or so

00:07:00,850 --> 00:07:06,310
and then I'd spend about six months

00:07:02,920 --> 00:07:07,900
debugging it so Apache spark really

00:07:06,310 --> 00:07:09,880
gives us this scaling power and it

00:07:07,900 --> 00:07:12,520
wasn't something that I'd even heard of

00:07:09,880 --> 00:07:14,140
until I turned up in industry and the

00:07:12,520 --> 00:07:16,360
recommendation engine called now runs

00:07:14,140 --> 00:07:19,600
quickly even on that twenty six million

00:07:16,360 --> 00:07:21,520
ratings dataset so I always thought I

00:07:19,600 --> 00:07:24,010
was working with big data when I was

00:07:21,520 --> 00:07:25,690
doing my PhD but in practice I always

00:07:24,010 --> 00:07:28,060
knew how much data there was and it

00:07:25,690 --> 00:07:29,560
could all be processed on one computer

00:07:28,060 --> 00:07:31,510
even if it meant that I just had to

00:07:29,560 --> 00:07:33,700
leave it running for the weekend of go

00:07:31,510 --> 00:07:35,950
and have a few extra coffees so I'd

00:07:33,700 --> 00:07:40,180
never really appreciated the truly big

00:07:35,950 --> 00:07:42,190
data is big so let's head back to the

00:07:40,180 --> 00:07:45,160
recommendation engine and get some

00:07:42,190 --> 00:07:47,530
ratings so in this first line I asked

00:07:45,160 --> 00:07:51,130
the model that we built using that tried

00:07:47,530 --> 00:07:54,280
and tested algorithm to give predictions

00:07:51,130 --> 00:07:56,710
for all the films I have not seen and in

00:07:54,280 --> 00:07:59,050
the second line I asked for the top ten

00:07:56,710 --> 00:08:03,190
recommendations for me to be returned

00:07:59,050 --> 00:08:05,080
now unless arrows plus Massacre is some

00:08:03,190 --> 00:08:08,730
Disney film I just haven't heard of

00:08:05,080 --> 00:08:11,200
these recommendations don't look so good

00:08:08,730 --> 00:08:13,420
so this isn't gonna fly in production

00:08:11,200 --> 00:08:14,920
but that algorithm is published that has

00:08:13,420 --> 00:08:16,900
lots of citations and their positive

00:08:14,920 --> 00:08:19,360
citations it's not people saying this

00:08:16,900 --> 00:08:21,520
doesn't work and I trained it add

00:08:19,360 --> 00:08:24,760
optimal parameter values so what's gone

00:08:21,520 --> 00:08:27,070
wrong well the third number in every

00:08:24,760 --> 00:08:29,950
triplet here is how many people rated

00:08:27,070 --> 00:08:32,050
those films so you can see for the top

00:08:29,950 --> 00:08:34,539
rated film for myself only one of the

00:08:32,050 --> 00:08:38,020
person one person in that whole 26

00:08:34,539 --> 00:08:39,550
million rated it now their opinions on

00:08:38,020 --> 00:08:42,070
the films that I rated must have

00:08:39,550 --> 00:08:43,660
coincided with my opinions but they also

00:08:42,070 --> 00:08:46,570
rated this film highly and so it's

00:08:43,660 --> 00:08:49,300
suggested to me and those are well cited

00:08:46,570 --> 00:08:51,040
published algorithm is failing we don't

00:08:49,300 --> 00:08:54,310
want this in production so that brings

00:08:51,040 --> 00:08:56,440
us nicely on to industry goals the goal

00:08:54,310 --> 00:08:57,730
here is to build a recommendation engine

00:08:56,440 --> 00:08:59,290
that works where

00:08:57,730 --> 00:09:01,839
works means improves the overall

00:08:59,290 --> 00:09:03,850
performance of our application by

00:09:01,839 --> 00:09:06,040
helping us meet some business objectives

00:09:03,850 --> 00:09:08,529
there's gonna be some metric that were

00:09:06,040 --> 00:09:11,259
optimizing for but it's not mean squared

00:09:08,529 --> 00:09:14,739
error of the parameters of the model for

00:09:11,259 --> 00:09:18,970
example so what we're missing right now

00:09:14,739 --> 00:09:20,739
is the sensible recommendations and it

00:09:18,970 --> 00:09:22,720
turns out all we have to do to get these

00:09:20,739 --> 00:09:24,939
is filter out films that have a low

00:09:22,720 --> 00:09:27,879
number of folds so I filtered out from

00:09:24,939 --> 00:09:29,470
seven rated by fewer than 500 people and

00:09:27,879 --> 00:09:32,290
all of the sudden these recommendations

00:09:29,470 --> 00:09:35,019
look much better now that filtering

00:09:32,290 --> 00:09:37,720
process isn't amending alternatingly

00:09:35,019 --> 00:09:39,549
squares it's not novel tons of people

00:09:37,720 --> 00:09:41,230
have done it before me and it's not

00:09:39,549 --> 00:09:43,299
gonna get me a publication or burn me a

00:09:41,230 --> 00:09:48,790
research price but it works

00:09:43,299 --> 00:09:51,579
I could ship this okay so let's stop

00:09:48,790 --> 00:09:54,819
briefly about personal incentives when I

00:09:51,579 --> 00:09:57,160
started my PhD my main motivation was to

00:09:54,819 --> 00:09:59,109
be a world-class research I wanted my

00:09:57,160 --> 00:10:01,179
name and lights I wanted citations

00:09:59,109 --> 00:10:03,669
coming out of my ears I wanted it all

00:10:01,179 --> 00:10:05,879
that quickly fizzled away in the next

00:10:03,669 --> 00:10:09,009
year or so I wanted to be a reasonable

00:10:05,879 --> 00:10:10,959
PhD student and sadly all the time that

00:10:09,009 --> 00:10:13,119
could be fizzled away in getting a job

00:10:10,959 --> 00:10:16,869
getting a PhD so that I could go and get

00:10:13,119 --> 00:10:19,569
a job so my personal incentives were

00:10:16,869 --> 00:10:21,609
driven by my supervisors incentives but

00:10:19,569 --> 00:10:23,739
in general what I do doesn't affect him

00:10:21,609 --> 00:10:26,970
he's already got more PhD students

00:10:23,739 --> 00:10:30,910
filling the place that I left behind um

00:10:26,970 --> 00:10:35,350
so it's generally just me striving to

00:10:30,910 --> 00:10:38,019
get that PhD now when I first rolled up

00:10:35,350 --> 00:10:41,499
an industry after grad school the main

00:10:38,019 --> 00:10:44,499
incentive was being paid money that

00:10:41,499 --> 00:10:46,869
quickly changed um I wanted to work that

00:10:44,499 --> 00:10:49,089
my company and my team are proud of why

00:10:46,869 --> 00:10:51,789
well for one that makes me feel good and

00:10:49,089 --> 00:10:53,709
arguably that's the same in research but

00:10:51,789 --> 00:10:55,869
here there's a much bigger picture by

00:10:53,709 --> 00:10:58,629
helping my team achieve goals

00:10:55,869 --> 00:11:01,749
I feel valued and I feel spoiled I

00:10:58,629 --> 00:11:03,730
wanted to do better so working as part

00:11:01,749 --> 00:11:05,919
of a team was by no means unexpected to

00:11:03,730 --> 00:11:07,899
me but it was much more of an adjustment

00:11:05,919 --> 00:11:09,970
than I imagined I found it very

00:11:07,899 --> 00:11:10,940
difficult to know whether I'm asking for

00:11:09,970 --> 00:11:12,470
too much help

00:11:10,940 --> 00:11:15,190
enough help whether I should work on my

00:11:12,470 --> 00:11:17,480
own whether I should collaborate and

00:11:15,190 --> 00:11:19,130
communicating what I do is now a vital

00:11:17,480 --> 00:11:21,230
importance when I was a grad student

00:11:19,130 --> 00:11:23,660
everyone had some vague idea of what I

00:11:21,230 --> 00:11:25,820
did but no one really knows the details

00:11:23,660 --> 00:11:27,440
all of a sudden not only does my team

00:11:25,820 --> 00:11:34,310
need to know what I'm doing but they

00:11:27,440 --> 00:11:35,720
actually care I think okay so in the

00:11:34,310 --> 00:11:38,390
last couple of minutes let's talk about

00:11:35,720 --> 00:11:40,640
some boundaries to progress in both

00:11:38,390 --> 00:11:42,770
settings I think this fellows are nicely

00:11:40,640 --> 00:11:44,630
from Lara's talk earlier if he's still

00:11:42,770 --> 00:11:47,420
around he talked about some common

00:11:44,630 --> 00:11:50,150
pitfalls that we might fall into so I

00:11:47,420 --> 00:11:54,170
feel like constraints the main

00:11:50,150 --> 00:11:56,390
constraint in both settings is time so

00:11:54,170 --> 00:11:59,450
long gone are the days of spending ten

00:11:56,390 --> 00:12:02,390
years doing your PhD in the UK if you do

00:11:59,450 --> 00:12:07,430
not hand in your PhD thesis within four

00:12:02,390 --> 00:12:10,040
years you automatically fail but Finnish

00:12:07,430 --> 00:12:11,930
doesn't really mean finished the last

00:12:10,040 --> 00:12:14,210
chapter of my thesis was entitled

00:12:11,930 --> 00:12:15,350
further work and there's already a PhD

00:12:14,210 --> 00:12:18,350
students at my desk

00:12:15,350 --> 00:12:20,900
picking up where I left off so it's fine

00:12:18,350 --> 00:12:22,550
furthermore if I decided that I wanted

00:12:20,900 --> 00:12:24,440
to spend a month thinking about

00:12:22,550 --> 00:12:26,810
something completely pointless but

00:12:24,440 --> 00:12:27,230
vaguely mathematical everyone was happy

00:12:26,810 --> 00:12:29,750
with that

00:12:27,230 --> 00:12:32,840
it didn't add to my thesis but that was

00:12:29,750 --> 00:12:34,700
cool with that in mind I think your

00:12:32,840 --> 00:12:36,650
incentives and your goals have to be

00:12:34,700 --> 00:12:41,450
stronger in academia in order to drive

00:12:36,650 --> 00:12:42,890
you forward in production the notion of

00:12:41,450 --> 00:12:45,590
deadlines are more frequent and much

00:12:42,890 --> 00:12:47,120
more concrete particularly if we're

00:12:45,590 --> 00:12:49,850
working towards a release date or a

00:12:47,120 --> 00:12:51,920
customer's timeline but I'm never the

00:12:49,850 --> 00:12:53,390
last person to work on a project and

00:12:51,920 --> 00:12:56,210
with that in mind I've got to think more

00:12:53,390 --> 00:12:58,010
about how I spend my time so could I use

00:12:56,210 --> 00:12:59,390
my statistics background to get an

00:12:58,010 --> 00:13:01,310
incremental improvement in that

00:12:59,390 --> 00:13:03,530
recommendation engine if I spent the

00:13:01,310 --> 00:13:06,170
next 10 hours 10 days 10 months working

00:13:03,530 --> 00:13:07,730
on it yeah definitely but is that worth

00:13:06,170 --> 00:13:10,940
while given that we've got something

00:13:07,730 --> 00:13:12,500
that works probably not so I have to

00:13:10,940 --> 00:13:16,790
think more about when to stop in

00:13:12,500 --> 00:13:18,589
production how done is done now we

00:13:16,790 --> 00:13:20,300
touched on the size of data sets then we

00:13:18,589 --> 00:13:22,220
talked about scaling out using Apache

00:13:20,300 --> 00:13:24,209
spark but something I hadn't appreciated

00:13:22,220 --> 00:13:26,309
is how difficult it is to

00:13:24,209 --> 00:13:28,829
we get decent data for training and

00:13:26,309 --> 00:13:30,540
development so in research the day or

00:13:28,829 --> 00:13:32,339
had always been handed to me it was data

00:13:30,540 --> 00:13:34,319
that someone else had used in their

00:13:32,339 --> 00:13:36,779
paper I wanted to run my algorithm on

00:13:34,319 --> 00:13:40,559
that exact same dataset to show that I

00:13:36,779 --> 00:13:41,850
did better or compare my results but in

00:13:40,559 --> 00:13:44,670
production I want to make things that

00:13:41,850 --> 00:13:46,519
are new and real so I need real data and

00:13:44,670 --> 00:13:51,269
it's just not there for the taking the

00:13:46,519 --> 00:13:56,160
only time the first time I was handed a

00:13:51,269 --> 00:13:58,619
dataset in my new job it had not been

00:13:56,160 --> 00:14:01,860
cleaned and I had not appreciated that

00:13:58,619 --> 00:14:04,470
data cleansing was even a thing but I

00:14:01,860 --> 00:14:07,529
thought this dataset was huge and it was

00:14:04,470 --> 00:14:09,480
a CSV and I thought well I've got pH D

00:14:07,529 --> 00:14:14,339
it's separated by commas how hard can it

00:14:09,480 --> 00:14:16,259
be so on that note if you're a grad

00:14:14,339 --> 00:14:18,119
student I hope that you're prepared to

00:14:16,259 --> 00:14:20,040
stand on the shoulders of giants use

00:14:18,119 --> 00:14:22,110
code that already exists and don't try

00:14:20,040 --> 00:14:23,550
to reinvent the wheel and keep your

00:14:22,110 --> 00:14:26,220
goals in mind because they're going to

00:14:23,550 --> 00:14:27,949
drive you if you're in industry please

00:14:26,220 --> 00:14:32,129
be open to being asked for help and

00:14:27,949 --> 00:14:33,869
don't see it as a sign of weakness you a

00:14:32,129 --> 00:14:35,189
lot of people potentially think that

00:14:33,869 --> 00:14:38,249
grad students know we're all but

00:14:35,189 --> 00:14:40,439
actually we know very little um you know

00:14:38,249 --> 00:14:43,199
something very detailed about a very

00:14:40,439 --> 00:14:43,920
minor thing but we do have many great

00:14:43,199 --> 00:14:45,990
skills

00:14:43,920 --> 00:14:48,629
so please exploit those and turn us into

00:14:45,990 --> 00:14:50,790
great co-workers so you can find me on

00:14:48,629 --> 00:14:52,439
Twitter that's my email address and this

00:14:50,790 --> 00:14:54,449
URL down here is where we keep all of

00:14:52,439 --> 00:14:57,589
the information about the recommendation

00:14:54,449 --> 00:14:57,589
engine the my team built

00:14:59,449 --> 00:15:03,290
thank you very much Sophie

00:15:04,440 --> 00:15:07,749

YouTube URL: https://www.youtube.com/watch?v=s3WbEfoxRjs


