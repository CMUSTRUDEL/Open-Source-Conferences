Title: Berlin Buzzwords 2018: Doug Turnbull & Tommaso Teofili â€“ The Neural Search Frontier #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Is search the next industry to be revolutionized by deep learning? Lately researchers have been applying neural networks to search applications, with impressive gains. Search users use different language than what's contained in the corpus. For example, doctors create articles discussing jargon like 'myocardial infarction' but patients search use lay-terms like 'heart attack'.  

Mapping vocabularies using expert created taxonomies or word embeddings (word2vec, LDA, etc) can help. Manual approaches can take a great amount of work or don't map between searcher and document vocabulary. When clear associations between relevant documents and queries can be made, neural search can learn the patterns between query and document language embeddings, with tremendous gains on text search. Such embeddings can also be used to provide alternative representations of the user queries in order to better capture the user intents.

Read more:
https://2018.berlinbuzzwords.de/18/session/neural-search-frontier

About Doug Turnbull:
https://2018.berlinbuzzwords.de/users/doug-turnbull

About Tommaso Teofili:
https://2018.berlinbuzzwords.de/users/tommaso-teofili

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:04,550 --> 00:00:10,010
so as as you saying I'm Doug Turnbull I

00:00:07,910 --> 00:00:11,780
wrote the book relevant search here's

00:00:10,010 --> 00:00:15,020
all my information I work for a company

00:00:11,780 --> 00:00:16,940
open source connections where we help

00:00:15,020 --> 00:00:20,029
search teams reach their highest

00:00:16,940 --> 00:00:21,560
potential in terms of mostly that means

00:00:20,029 --> 00:00:24,460
relevance and delivering higher value

00:00:21,560 --> 00:00:26,570
for their customers as in consulting and

00:00:24,460 --> 00:00:28,340
my name is tamas that they awfully

00:00:26,570 --> 00:00:31,160
worked for Adobe as a computer scientist

00:00:28,340 --> 00:00:35,660
and also an Apache Software Foundation

00:00:31,160 --> 00:00:39,320
member in yeah I'm very interested in

00:00:35,660 --> 00:00:43,250
the search field and topics and you're

00:00:39,320 --> 00:00:46,250
writing a book yeah yeah it's a it's a

00:00:43,250 --> 00:00:48,829
meet now so I hope to be that to be

00:00:46,250 --> 00:00:52,489
finished by end of this year so yeah I

00:00:48,829 --> 00:00:55,700
mean playing paper it's exciting when

00:00:52,489 --> 00:00:57,380
you get it in paper ok so today we're

00:00:55,700 --> 00:00:59,239
going to be talking about deep learning

00:00:57,380 --> 00:01:01,489
and search and can deep learning be a

00:00:59,239 --> 00:01:04,250
thing that can really have a big impact

00:01:01,489 --> 00:01:06,020
in the search landscape and I want to

00:01:04,250 --> 00:01:08,360
talk to start by talking about I'm gonna

00:01:06,020 --> 00:01:10,280
run through some slides and for me

00:01:08,360 --> 00:01:12,560
personally this is doing this talk has

00:01:10,280 --> 00:01:13,969
been an educational opportunity and one

00:01:12,560 --> 00:01:16,700
of the things I always try to imbue to

00:01:13,969 --> 00:01:20,060
people is you don't have to be a deep

00:01:16,700 --> 00:01:22,310
expert in a topic like deep learning or

00:01:20,060 --> 00:01:24,679
machine learn an LP to give a talk and

00:01:22,310 --> 00:01:26,389
often the best speakers are people and

00:01:24,679 --> 00:01:28,189
bloggers and that sort of thing are

00:01:26,389 --> 00:01:31,219
people actually learning as they're

00:01:28,189 --> 00:01:32,569
going so I want to I say that to

00:01:31,219 --> 00:01:35,179
encourage other people to feel like they

00:01:32,569 --> 00:01:36,799
should feel safe giving a talk even even

00:01:35,179 --> 00:01:43,759
when they're becoming familiar with the

00:01:36,799 --> 00:01:46,279
topic so there we go so what often

00:01:43,759 --> 00:01:48,439
happens with search this is a very

00:01:46,279 --> 00:01:50,119
common problem in search there's kind of

00:01:48,439 --> 00:01:52,899
two specific things that I'm going to

00:01:50,119 --> 00:01:55,909
talk about what is this matching problem

00:01:52,899 --> 00:01:57,709
almost all of must search clients that

00:01:55,909 --> 00:01:59,929
we work with have a vocabulary mismatch

00:01:57,709 --> 00:02:03,020
problem where you have searchers and

00:01:59,929 --> 00:02:04,579
this is like somebody this is basically

00:02:03,020 --> 00:02:07,069
how my dad would search the law

00:02:04,579 --> 00:02:08,840
searching for a dog catcher and you have

00:02:07,069 --> 00:02:14,450
a bunch of laws that say animal control

00:02:08,840 --> 00:02:16,070
law right and and and this is a common

00:02:14,450 --> 00:02:17,940
problem in search and we spend a lot of

00:02:16,070 --> 00:02:20,160
time trying to work through

00:02:17,940 --> 00:02:21,900
these problems and I really like

00:02:20,160 --> 00:02:23,820
Giovanni's talk this morning that was

00:02:21,900 --> 00:02:26,610
about a lot of the you know manual

00:02:23,820 --> 00:02:28,170
search management that we do and a lot

00:02:26,610 --> 00:02:29,850
of our work we see the same kinds of

00:02:28,170 --> 00:02:31,830
things where it's actually one of the

00:02:29,850 --> 00:02:34,230
secret bullets of relevance is to have a

00:02:31,830 --> 00:02:36,090
great taxonomist or librarian who's

00:02:34,230 --> 00:02:39,090
manually curating the mapping between

00:02:36,090 --> 00:02:40,710
how searchers consider talked about

00:02:39,090 --> 00:02:42,840
their content and how the corpus talks

00:02:40,710 --> 00:02:45,270
about the content and I have a talk

00:02:42,840 --> 00:02:48,680
taxonomical semantical magical search

00:02:45,270 --> 00:02:52,170
that I gave that if you're interested

00:02:48,680 --> 00:02:53,940
this is uh obviously one of the things

00:02:52,170 --> 00:02:55,830
I'm curious about is I also have many

00:02:53,940 --> 00:02:58,590
clients who just don't want to get

00:02:55,830 --> 00:03:00,630
involved in this kind of work or they or

00:02:58,590 --> 00:03:02,790
the domain is too large to really build

00:03:00,630 --> 00:03:05,610
a this kind of controlled vocabulary

00:03:02,790 --> 00:03:07,890
taxonomy to solve this problem and so

00:03:05,610 --> 00:03:10,590
deep learning is exciting to me from

00:03:07,890 --> 00:03:12,360
that point of view because you see this

00:03:10,590 --> 00:03:14,400
is sort of a feature engineering thing a

00:03:12,360 --> 00:03:16,800
manual feature engineering thing and one

00:03:14,400 --> 00:03:18,780
of the themes of deep learning is for

00:03:16,800 --> 00:03:21,930
text and images there's all these layton

00:03:18,780 --> 00:03:23,820
rich features why are we creating all of

00:03:21,930 --> 00:03:25,739
these manual features for these things

00:03:23,820 --> 00:03:30,330
when deep learning helps us learn these

00:03:25,739 --> 00:03:31,890
abstractions right ranking is sort of

00:03:30,330 --> 00:03:34,080
the other side so you think I'm matching

00:03:31,890 --> 00:03:35,790
and ranking and of course ranking is

00:03:34,080 --> 00:03:37,980
very challenging we have all of these

00:03:35,790 --> 00:03:39,570
ways of querying our our search engines

00:03:37,980 --> 00:03:43,650
so learn elasticsearch they have a very

00:03:39,570 --> 00:03:44,880
rich query DSL we are always fine-tuning

00:03:43,650 --> 00:03:47,070
these things right there's all these

00:03:44,880 --> 00:03:49,890
weird heuristics tf-idf stoller

00:03:47,070 --> 00:03:53,340
elasticsearch I mean tf-idf is just some

00:03:49,890 --> 00:03:55,500
like thing that came this you know so I

00:03:53,340 --> 00:03:57,810
was on a Twitter thread once for someone

00:03:55,500 --> 00:04:00,840
was saying people who don't really

00:03:57,810 --> 00:04:02,160
understand how search works they do all

00:04:00,840 --> 00:04:04,320
these hacks but I'm pretty sure that

00:04:02,160 --> 00:04:05,730
everyone including me when they're

00:04:04,320 --> 00:04:07,860
actually solving a real evans problem

00:04:05,730 --> 00:04:10,620
everything feels like a hack and that

00:04:07,860 --> 00:04:13,470
goes for tf-idf - I mean tf-idf s is

00:04:10,620 --> 00:04:15,600
statistic that just came out of people

00:04:13,470 --> 00:04:18,120
playing with numbers until it turned out

00:04:15,600 --> 00:04:20,820
it was the best given some relevance

00:04:18,120 --> 00:04:22,710
judgments and all of these things are

00:04:20,820 --> 00:04:26,100
kind of like heuristics for getting

00:04:22,710 --> 00:04:28,289
close to what the user wants whereas in

00:04:26,100 --> 00:04:31,410
deep learning deep learning helps us

00:04:28,289 --> 00:04:32,910
sort of maybe get deeper than that

00:04:31,410 --> 00:04:34,440
and of course we have learning to rank

00:04:32,910 --> 00:04:36,660
and learning to rank as a bit is a

00:04:34,440 --> 00:04:38,550
different field than deep learning but

00:04:36,660 --> 00:04:41,010
learning to rank isn't perfect either

00:04:38,550 --> 00:04:42,840
learning to rank comes with its own

00:04:41,010 --> 00:04:44,820
problems it's only as good as your

00:04:42,840 --> 00:04:48,420
features and those features of course

00:04:44,820 --> 00:04:50,040
are just based on this stuff so if your

00:04:48,420 --> 00:04:51,840
features aren't mapping between dog

00:04:50,040 --> 00:04:56,460
catcher and animal control officer

00:04:51,840 --> 00:04:58,230
you're still going to have problems it's

00:04:56,460 --> 00:05:00,030
the first thing the first stop on our

00:04:58,230 --> 00:05:03,270
deep learning journey and and when I

00:05:00,030 --> 00:05:05,310
look at these and again inspired by what

00:05:03,270 --> 00:05:07,760
you see in deep learning for NLP deep

00:05:05,310 --> 00:05:10,740
learning for images are there ways to do

00:05:07,760 --> 00:05:13,890
to learn better feature representations

00:05:10,740 --> 00:05:16,040
that aren't based on things that are

00:05:13,890 --> 00:05:19,170
sort of in a layer of abstraction that

00:05:16,040 --> 00:05:22,020
maybe a machine would learn but aren't

00:05:19,170 --> 00:05:23,970
in a language that we could access and

00:05:22,020 --> 00:05:28,830
how many people have used word to Veck

00:05:23,970 --> 00:05:31,080
before I think we're do Veck so so how

00:05:28,830 --> 00:05:32,960
many people have used layton let's see

00:05:31,080 --> 00:05:36,810
if I can say this right darisha lay

00:05:32,960 --> 00:05:38,550
allocation Lda yeah so you have these

00:05:36,810 --> 00:05:40,620
sort of these sorts of topics and you

00:05:38,550 --> 00:05:43,380
can build what are called embeddings out

00:05:40,620 --> 00:05:45,150
of them and embeddings are great because

00:05:43,380 --> 00:05:47,160
what you're doing with them is you're

00:05:45,150 --> 00:05:50,030
remembering something about the context

00:05:47,160 --> 00:05:53,310
that those words tend to appear in and

00:05:50,030 --> 00:05:56,330
you know I swear I did this without

00:05:53,310 --> 00:05:59,160
knowing what the keynote talk was but

00:05:56,330 --> 00:06:02,130
cryptocurrency is hyped question mark

00:05:59,160 --> 00:06:04,410
appear you know Bitcoin hype seemed to

00:06:02,130 --> 00:06:05,910
appear in similar context and one of the

00:06:04,410 --> 00:06:07,620
great things about word embeddings is

00:06:05,910 --> 00:06:10,980
they're they're recording this

00:06:07,620 --> 00:06:12,450
information you have these situations or

00:06:10,980 --> 00:06:16,560
cancel and confirm are actually

00:06:12,450 --> 00:06:18,300
appearing in similar contexts so weird

00:06:16,560 --> 00:06:21,120
embeddings are really vectors right

00:06:18,300 --> 00:06:24,720
they're n-dimensional vectors in a some

00:06:21,120 --> 00:06:26,190
vector space and of course they're

00:06:24,720 --> 00:06:29,460
probably not two-dimensional vectors

00:06:26,190 --> 00:06:31,070
they're probably often 300 dimensional

00:06:29,460 --> 00:06:33,630
vectors is a number that jumps out a lot

00:06:31,070 --> 00:06:36,360
but when you map them in a vector space

00:06:33,630 --> 00:06:38,940
you can see words that occur in similar

00:06:36,360 --> 00:06:42,630
contexts occur together this is the goal

00:06:38,940 --> 00:06:45,650
of a good embedding and say you see that

00:06:42,630 --> 00:06:45,650
in both situations

00:06:46,760 --> 00:06:52,340
of course search is also based on a

00:06:49,610 --> 00:06:56,570
vector similarity right we have our

00:06:52,340 --> 00:06:59,870
query up there and we try we have our

00:06:56,570 --> 00:07:01,010
query terms you know regulation we're

00:06:59,870 --> 00:07:03,170
trying to find the documents that are

00:07:01,010 --> 00:07:04,850
about regulation we're trying to find

00:07:03,170 --> 00:07:09,020
the documents that are about Bitcoin

00:07:04,850 --> 00:07:10,640
right and upper right you know sort of

00:07:09,020 --> 00:07:13,700
represents our query the farther in the

00:07:10,640 --> 00:07:17,270
upper right we get the more about the

00:07:13,700 --> 00:07:19,160
document is to our query and so we sort

00:07:17,270 --> 00:07:22,880
of have this notion that aboutness is

00:07:19,160 --> 00:07:24,920
tf-idf for each of these terms and so

00:07:22,880 --> 00:07:27,620
the closer our doc gets to having more

00:07:24,920 --> 00:07:29,240
of each the more it's going to be rated

00:07:27,620 --> 00:07:32,570
relevant because it's closer to where

00:07:29,240 --> 00:07:35,300
our query is this is also a kind of

00:07:32,570 --> 00:07:37,520
vector similarity and of course the

00:07:35,300 --> 00:07:40,760
question that often comes out this is a

00:07:37,520 --> 00:07:42,320
hypothesis and I've claimed it I say it

00:07:40,760 --> 00:07:44,900
as a hypothesis because I want to be

00:07:42,320 --> 00:07:48,410
clear that you know I have going down

00:07:44,900 --> 00:07:51,710
the chain of saying I'm going to take my

00:07:48,410 --> 00:07:53,450
data straight out of Word avec latent

00:07:51,710 --> 00:07:55,700
semantic analysis Lda

00:07:53,450 --> 00:07:58,040
and just put it my search engine and

00:07:55,700 --> 00:08:00,550
everything will just be fine right and i

00:07:58,040 --> 00:08:04,850
pathi says is that this embedding

00:08:00,550 --> 00:08:06,800
similarity where we have maybe we've

00:08:04,850 --> 00:08:08,390
done the same thing with our documents

00:08:06,800 --> 00:08:10,190
and it has you know we have an embedding

00:08:08,390 --> 00:08:14,120
for a document but this embedding

00:08:10,190 --> 00:08:16,190
similarity is somehow related to this

00:08:14,120 --> 00:08:19,970
aboutness similarity that relevance

00:08:16,190 --> 00:08:21,980
tries to capture and this is a

00:08:19,970 --> 00:08:23,060
hypothesis that works out sometimes you

00:08:21,980 --> 00:08:27,140
can see on the bottom right

00:08:23,060 --> 00:08:29,720
it appears to be working however in some

00:08:27,140 --> 00:08:31,070
this hypothesis does not always hold and

00:08:29,720 --> 00:08:33,349
this is something important to take away

00:08:31,070 --> 00:08:35,390
you know this is a great example I

00:08:33,349 --> 00:08:39,050
actually heard this you know chat BOTS

00:08:35,390 --> 00:08:41,120
do a lot of support and this is a very

00:08:39,050 --> 00:08:44,090
related field is that uses a lot of

00:08:41,120 --> 00:08:46,370
embeddings answering the question I

00:08:44,090 --> 00:08:49,460
would like to confirm my my reservation

00:08:46,370 --> 00:08:51,200
and you respond with oh are you sure you

00:08:49,460 --> 00:08:53,420
want to cancel your reservation is is a

00:08:51,200 --> 00:08:56,400
bad that's a bad time you're having

00:08:53,420 --> 00:08:58,020
so this hypothesis doesn't always hold

00:08:56,400 --> 00:09:00,030
and it's important to know that it's

00:08:58,020 --> 00:09:02,630
hypothesis it's also important to know

00:09:00,030 --> 00:09:04,470
that tf-idf itself is a hypothesis

00:09:02,630 --> 00:09:06,210
measurement of about Ness

00:09:04,470 --> 00:09:11,370
I should say that you know that often

00:09:06,210 --> 00:09:13,200
doesn't work out too so context alone

00:09:11,370 --> 00:09:15,450
isn't enough and I think it's good to

00:09:13,200 --> 00:09:17,970
point out and this comes up a lot in

00:09:15,450 --> 00:09:19,500
Tomaso's book there are ways just in the

00:09:17,970 --> 00:09:21,270
same way we do a lot of data modeling

00:09:19,500 --> 00:09:22,890
and search engines there's actually a

00:09:21,270 --> 00:09:25,320
lot of things that you do before your

00:09:22,890 --> 00:09:26,790
data gets to word go back one thing that

00:09:25,320 --> 00:09:29,550
comes up that's actually in the word

00:09:26,790 --> 00:09:33,540
defective at paper is they make sure to

00:09:29,550 --> 00:09:35,970
pull out the entities the phrases that

00:09:33,540 --> 00:09:38,220
you should really consider one thing so

00:09:35,970 --> 00:09:41,010
Boston Globe is treated as one word in

00:09:38,220 --> 00:09:43,740
that vocabulary that's in the original

00:09:41,010 --> 00:09:45,420
word to vector box so that you're not

00:09:43,740 --> 00:09:48,210
confusing Boston Globe the newspaper

00:09:45,420 --> 00:09:51,570
with Boston the city or Globe they're

00:09:48,210 --> 00:09:53,820
treated as separate so and there are

00:09:51,570 --> 00:09:56,760
other things to do we could we could use

00:09:53,820 --> 00:09:58,890
other factors of our words the sentiment

00:09:56,760 --> 00:10:02,690
of the language you know confirm and

00:09:58,890 --> 00:10:05,580
cancel usually will have different sent

00:10:02,690 --> 00:10:07,710
sentiments with cancel obviously maybe

00:10:05,580 --> 00:10:10,530
someone's yelling at the search engine

00:10:07,710 --> 00:10:14,250
or something synonyms and all kinds of

00:10:10,530 --> 00:10:21,660
other ways of doing this parts of speech

00:10:14,250 --> 00:10:26,100
is another one so when one low-hanging

00:10:21,660 --> 00:10:31,760
fruit is do you want to talk about this

00:10:26,100 --> 00:10:35,700
library sure yeah so I think one of the

00:10:31,760 --> 00:10:39,210
key things in this talk is also I mean

00:10:35,700 --> 00:10:41,360
getting his two things one thing is

00:10:39,210 --> 00:10:44,520
getting a general understanding of how

00:10:41,360 --> 00:10:46,350
deep learning can be useful in the

00:10:44,520 --> 00:10:50,520
context of search but the other thing is

00:10:46,350 --> 00:10:54,450
also kind of get a few quick ideas or

00:10:50,520 --> 00:10:57,990
things that you as the audience can try

00:10:54,450 --> 00:10:59,850
out in your projects so that that's the

00:10:57,990 --> 00:11:02,700
idea but the so-called low-hanging

00:10:59,850 --> 00:11:05,070
fruits so so if the probability

00:11:02,700 --> 00:11:07,339
distribution of words in the corpus can

00:11:05,070 --> 00:11:09,410
provide enough information

00:11:07,339 --> 00:11:11,930
to predict whether two words appears in

00:11:09,410 --> 00:11:15,320
similar context and that's exactly the

00:11:11,930 --> 00:11:18,290
slide that Doug just showed up then we

00:11:15,320 --> 00:11:21,529
can kind of use them as synonyms or I

00:11:18,290 --> 00:11:24,380
mean not a strictly synonyms in a way

00:11:21,529 --> 00:11:27,170
they told us to school to think about

00:11:24,380 --> 00:11:33,230
cinnamon synonyms but basically things

00:11:27,170 --> 00:11:35,990
that make sense to see the words that

00:11:33,230 --> 00:11:39,620
make sense to be used to replace one

00:11:35,990 --> 00:11:44,089
another and that's kind of the query

00:11:39,620 --> 00:11:46,670
expansion kind of thing so I think

00:11:44,089 --> 00:11:49,970
that's one thing where you can use kind

00:11:46,670 --> 00:11:51,889
of adjusted versions of word Tyvek for

00:11:49,970 --> 00:11:56,470
example or basically word embeddings

00:11:51,889 --> 00:12:00,199
that also can takes take in in account

00:11:56,470 --> 00:12:02,360
sentiment or other things that can

00:12:00,199 --> 00:12:05,720
mitigate the problem about for example

00:12:02,360 --> 00:12:10,329
cancel and confirm and then you can you

00:12:05,720 --> 00:12:13,490
can use them to learn query expansion

00:12:10,329 --> 00:12:15,500
very very effective query expansion

00:12:13,490 --> 00:12:18,949
algorithms that you can use under the

00:12:15,500 --> 00:12:21,110
hood so that's the idea about so

00:12:18,949 --> 00:12:23,060
cryptocurrency and Bitcoin I mean you

00:12:21,110 --> 00:12:26,540
cannot type you can you may not type

00:12:23,060 --> 00:12:29,660
cryptocurrency in the in a query but the

00:12:26,540 --> 00:12:31,579
the search engine would turn it into

00:12:29,660 --> 00:12:33,740
Bitcoin on the road and fight two

00:12:31,579 --> 00:12:35,810
different queries you know to

00:12:33,740 --> 00:12:38,720
queries with cryptocurrency and Bitcoin

00:12:35,810 --> 00:12:45,920
using that and this is kind of expected

00:12:38,720 --> 00:12:48,680
to raise the the recall yeah so there

00:12:45,920 --> 00:12:51,680
can often be still a mismatch because

00:12:48,680 --> 00:12:53,089
when people use word avec or all of

00:12:51,680 --> 00:12:55,399
these tools when they're building

00:12:53,089 --> 00:12:57,829
embeddings they're still fundamentally

00:12:55,399 --> 00:13:00,829
using their corpus to do this for the

00:12:57,829 --> 00:13:02,410
most part usually they're running it

00:13:00,829 --> 00:13:04,880
against a corpus and they're learning

00:13:02,410 --> 00:13:07,699
similarities and legalese and not Laye

00:13:04,880 --> 00:13:10,819
speak so still we have the same problem

00:13:07,699 --> 00:13:13,100
and may not mean I solve that this the

00:13:10,819 --> 00:13:13,459
problem for everything and it depends a

00:13:13,100 --> 00:13:15,500
lot

00:13:13,459 --> 00:13:19,100
everything depends and I'm a consultant

00:13:15,500 --> 00:13:20,080
so I say it depends it depends on what

00:13:19,100 --> 00:13:22,300
your corpus is

00:13:20,080 --> 00:13:24,010
and how how much overlap there is

00:13:22,300 --> 00:13:26,529
between your search language and your

00:13:24,010 --> 00:13:28,630
corpus if you're supporting lawyers may

00:13:26,529 --> 00:13:32,560
be great if you're supporting non

00:13:28,630 --> 00:13:35,020
lawyers may not be great so one thing I

00:13:32,560 --> 00:13:37,899
ask myself a lot is can we build our

00:13:35,020 --> 00:13:41,200
first step on the neural network trained

00:13:37,899 --> 00:13:43,959
is can we build better embeddings can we

00:13:41,200 --> 00:13:45,790
build embeddings that get closer to our

00:13:43,959 --> 00:13:48,910
searchers notion of relevance

00:13:45,790 --> 00:13:51,130
you know maybe so you know and I think

00:13:48,910 --> 00:13:52,839
it's a good this is a good thing I think

00:13:51,130 --> 00:13:55,330
everyone I'm gonna go through exactly

00:13:52,839 --> 00:13:57,250
how this stuff works I sort of feel like

00:13:55,330 --> 00:13:58,510
they should pretty soon they'll be they

00:13:57,250 --> 00:14:00,190
should be teaching this stuff in high

00:13:58,510 --> 00:14:02,140
school like this machine learning stuff

00:14:00,190 --> 00:14:03,760
it shouldn't just be about coding we

00:14:02,140 --> 00:14:05,410
need to get to this stuff in high school

00:14:03,760 --> 00:14:08,709
and I think it's anything something

00:14:05,410 --> 00:14:10,209
anyone can really understand so the word

00:14:08,709 --> 00:14:12,279
Tyvek model is relatively

00:14:10,209 --> 00:14:14,680
straightforward and it's a great thing

00:14:12,279 --> 00:14:15,670
to start to start to learn about when

00:14:14,680 --> 00:14:17,529
you're doing this kind of machine

00:14:15,670 --> 00:14:19,450
learning and once you learn about it

00:14:17,529 --> 00:14:22,209
then you can hack it and do crazy things

00:14:19,450 --> 00:14:24,970
with it you basically have this very

00:14:22,209 --> 00:14:27,550
simple table that's storing and

00:14:24,970 --> 00:14:32,500
embedding for each term in this case

00:14:27,550 --> 00:14:35,560
energy and Bitcoin and we're taking

00:14:32,500 --> 00:14:37,150
those terms we have a dot product and

00:14:35,560 --> 00:14:39,160
you can imagine this is initialized

00:14:37,150 --> 00:14:41,770
randomly this may not even be it's a

00:14:39,160 --> 00:14:44,279
just a poor bottle take a dot product

00:14:41,770 --> 00:14:46,810
which is just that math up there a

00:14:44,279 --> 00:14:50,200
sigmoid which really just forces

00:14:46,810 --> 00:14:52,060
everything to zero to one and if it's

00:14:50,200 --> 00:14:54,370
close to one its the prediction of the

00:14:52,060 --> 00:14:55,959
model that this is a true context but

00:14:54,370 --> 00:14:58,120
this is something these are true context

00:14:55,959 --> 00:15:00,130
words close to zero the prediction is

00:14:58,120 --> 00:15:03,850
it's a false context it's not an actual

00:15:00,130 --> 00:15:06,010
context word so maybe if Bitcoin and

00:15:03,850 --> 00:15:09,700
energy were in the same context the

00:15:06,010 --> 00:15:11,950
model predicted 0.67 okay we're getting

00:15:09,700 --> 00:15:13,180
we have some it's close to you know if

00:15:11,950 --> 00:15:15,279
we think about this prediction as a

00:15:13,180 --> 00:15:17,320
probability of being in the same context

00:15:15,279 --> 00:15:19,630
of occurring in the same context then

00:15:17,320 --> 00:15:25,060
you know we're two-thirds of the way

00:15:19,630 --> 00:15:27,250
there and the goal is the arrows got a

00:15:25,060 --> 00:15:29,980
little misaligned but the goal here is

00:15:27,250 --> 00:15:33,270
as we now that we have maybe we randomly

00:15:29,980 --> 00:15:35,430
set this up but we know the real answer

00:15:33,270 --> 00:15:37,920
when we're training the goal is to shift

00:15:35,430 --> 00:15:41,460
the stuff that's in the true context up

00:15:37,920 --> 00:15:44,130
and move the stuff that's not actually

00:15:41,460 --> 00:15:45,750
sharing in context down we want this

00:15:44,130 --> 00:15:47,130
number this prediction to go down we

00:15:45,750 --> 00:15:50,690
want that prediction to go up

00:15:47,130 --> 00:15:54,540
so our model becomes more accurate and

00:15:50,690 --> 00:15:56,010
this is using I think this is using an

00:15:54,540 --> 00:15:58,050
interesting approach called negative

00:15:56,010 --> 00:16:00,630
sampling which i think is the easiest to

00:15:58,050 --> 00:16:02,670
get into and what negative sampling does

00:16:00,630 --> 00:16:04,380
is say okay I've got this term Bitcoin

00:16:02,670 --> 00:16:06,300
I'm trying to learn about I've got a

00:16:04,380 --> 00:16:08,670
true context word for my training data

00:16:06,300 --> 00:16:10,590
and I'm randomly selecting some negative

00:16:08,670 --> 00:16:12,510
words that I know don't occur with that

00:16:10,590 --> 00:16:15,210
and what's interesting about this is

00:16:12,510 --> 00:16:16,770
learning to rank also has an issue where

00:16:15,210 --> 00:16:18,810
it's very important to have lots of

00:16:16,770 --> 00:16:22,230
negative training data and so there's

00:16:18,810 --> 00:16:23,670
there's some like interesting symmetries

00:16:22,230 --> 00:16:25,890
here or something in the universe that

00:16:23,670 --> 00:16:31,580
we're learning about and the question is

00:16:25,890 --> 00:16:35,340
how do we tweak this and so we have this

00:16:31,580 --> 00:16:37,260
big scary math thing and you don't need

00:16:35,340 --> 00:16:40,140
to be intimidated by this big scary math

00:16:37,260 --> 00:16:44,010
thing but what is happening is and I'm

00:16:40,140 --> 00:16:46,410
just gonna go ahead and these that this

00:16:44,010 --> 00:16:49,290
stuff in here that's just the model that

00:16:46,410 --> 00:16:53,760
I just told you about 1 over 1 plus e to

00:16:49,290 --> 00:16:56,700
something is a sigmoid VC are a dot

00:16:53,760 --> 00:17:00,240
product of two embeddings in this case

00:16:56,700 --> 00:17:02,040
it's the true context and we take away

00:17:00,240 --> 00:17:04,589
you know this is what we want to go up

00:17:02,040 --> 00:17:06,959
the true context because this is what

00:17:04,589 --> 00:17:10,320
our you know this is what we want to go

00:17:06,959 --> 00:17:14,370
up we want this value to go up in these

00:17:10,320 --> 00:17:18,660
values to go down and so this whole

00:17:14,370 --> 00:17:20,370
function is designed to be maximized ok

00:17:18,660 --> 00:17:22,080
so you know how do we how do we maximize

00:17:20,370 --> 00:17:24,930
that and I'm not going to get into the

00:17:22,080 --> 00:17:27,330
to the weeds of gradient descent or in

00:17:24,930 --> 00:17:28,890
this case ascent but the idea is if we

00:17:27,330 --> 00:17:30,870
take the derivative of that function we

00:17:28,890 --> 00:17:33,930
told you about we know which direction

00:17:30,870 --> 00:17:36,120
in each of our the V here is the Bitcoin

00:17:33,930 --> 00:17:39,330
in each of our bitcoins direction to

00:17:36,120 --> 00:17:42,870
push that number to make that that the

00:17:39,330 --> 00:17:44,310
that loss or that likelihood higher that

00:17:42,870 --> 00:17:47,850
we're getting something more accurate

00:17:44,310 --> 00:17:50,340
and then you talk about this idea and

00:17:47,850 --> 00:17:52,230
Deve learning of back propagation so

00:17:50,340 --> 00:17:55,110
back propagation is where we take that

00:17:52,230 --> 00:17:56,850
that thing we learned about about this

00:17:55,110 --> 00:17:59,520
loss function and we propagate it back

00:17:56,850 --> 00:18:01,080
to the other weights and deep of course

00:17:59,520 --> 00:18:04,200
you may know that deep learning

00:18:01,080 --> 00:18:06,350
that's deep it when we do deep parts of

00:18:04,200 --> 00:18:08,940
it we actually have several layers of

00:18:06,350 --> 00:18:11,310
things to keep propagating back and back

00:18:08,940 --> 00:18:13,170
and hopefully keep maximizing or

00:18:11,310 --> 00:18:14,730
minimizing when you say minimize the

00:18:13,170 --> 00:18:18,690
loss in this case that's maximizing

00:18:14,730 --> 00:18:20,490
something so that's what when you hear

00:18:18,690 --> 00:18:22,260
people talk about back propagation it's

00:18:20,490 --> 00:18:24,210
really just sort of doing this kind of

00:18:22,260 --> 00:18:27,030
learning and there's not magic here it's

00:18:24,210 --> 00:18:29,700
just math it's math that I feel like if

00:18:27,030 --> 00:18:31,320
more of us understood we would all make

00:18:29,700 --> 00:18:34,710
better decisions and our jobs in our

00:18:31,320 --> 00:18:37,650
lives and fall for the silly AI

00:18:34,710 --> 00:18:42,330
advertising a bit less because people

00:18:37,650 --> 00:18:44,930
will say this is this AI of course we

00:18:42,330 --> 00:18:48,450
can do the same kind of thing with

00:18:44,930 --> 00:18:50,370
documents in this case this docked avec

00:18:48,450 --> 00:18:51,990
uses what's called paragraph embeddings

00:18:50,370 --> 00:18:53,580
and a paragraph could be a whole

00:18:51,990 --> 00:18:55,830
document it could be a subset of a

00:18:53,580 --> 00:18:59,490
document and we can do the same kinds of

00:18:55,830 --> 00:19:01,980
things so we can tweak these guys you

00:18:59,490 --> 00:19:03,960
know here is Bitcoin here is a true

00:19:01,980 --> 00:19:06,390
document that it occurred in we can

00:19:03,960 --> 00:19:09,030
tweak that prediction to be up here's

00:19:06,390 --> 00:19:10,610
Bitcoin and a document it that is

00:19:09,030 --> 00:19:15,420
unassociated with it and we want that

00:19:10,610 --> 00:19:18,450
prediction to go down and in this COI

00:19:15,420 --> 00:19:19,680
and in this model you know right now

00:19:18,450 --> 00:19:22,260
this is still tweaking the Bitcoin

00:19:19,680 --> 00:19:24,360
vector but you're you are learning both

00:19:22,260 --> 00:19:25,830
the document embeddings the paragraph

00:19:24,360 --> 00:19:30,420
embeddings and the document the same

00:19:25,830 --> 00:19:32,040
time if you notice I'm leaving you

00:19:30,420 --> 00:19:33,660
Easter eggs in the upper right if you

00:19:32,040 --> 00:19:35,940
get these slides you can click on links

00:19:33,660 --> 00:19:40,500
and follow to learn more stuff so you

00:19:35,940 --> 00:19:44,250
want to take this one way so these are

00:19:40,500 --> 00:19:45,900
the low-hanging fruit so similar word

00:19:44,250 --> 00:19:48,060
embeddings lie close to one another

00:19:45,900 --> 00:19:51,270
I mean similar in semantics so that's

00:19:48,060 --> 00:19:54,300
the the kind of results of word of word

00:19:51,270 --> 00:19:56,160
to like and other kind of similar

00:19:54,300 --> 00:19:58,930
algorithms about word embeddings and the

00:19:56,160 --> 00:20:03,610
same stands for paragraph factors

00:19:58,930 --> 00:20:07,960
and document embeddings in general so an

00:20:03,610 --> 00:20:11,410
other research have shown that words

00:20:07,960 --> 00:20:13,809
appear often close to the documents that

00:20:11,410 --> 00:20:19,559
they are more represented into so if

00:20:13,809 --> 00:20:22,690
again if we think about two to Lda and

00:20:19,559 --> 00:20:25,870
how we can we can kind of think of using

00:20:22,690 --> 00:20:29,800
that together with word embeddings to

00:20:25,870 --> 00:20:33,160
discover topics about about documents

00:20:29,800 --> 00:20:39,059
but just looking at the position of

00:20:33,160 --> 00:20:42,850
words into this embedding space and so

00:20:39,059 --> 00:20:45,850
but as a search engineer if you think

00:20:42,850 --> 00:20:50,500
about your search project we've always

00:20:45,850 --> 00:20:52,840
or I mean we mostly use our time

00:20:50,500 --> 00:20:55,420
thinking about terms and on analyzers

00:20:52,840 --> 00:20:58,240
and tokenizer z' and filters and stuff

00:20:55,420 --> 00:21:02,950
like that just to speak the ricean api's

00:20:58,240 --> 00:21:07,450
in the ricean api's so is this going to

00:21:02,950 --> 00:21:10,660
change all all of this so did anyone say

00:21:07,450 --> 00:21:13,330
terms when it comes it comes to

00:21:10,660 --> 00:21:15,760
retrieval or frequencies when it comes

00:21:13,330 --> 00:21:19,360
to rent Kings so how these things work

00:21:15,760 --> 00:21:22,809
together with the statistical models we

00:21:19,360 --> 00:21:25,540
are like now we have for example leucine

00:21:22,809 --> 00:21:31,530
uses beyond 25 with which is a kind of

00:21:25,540 --> 00:21:34,690
statistical algorithm for ranking so

00:21:31,530 --> 00:21:40,720
this is not really low hanging fruit

00:21:34,690 --> 00:21:44,230
it's not so low and the the thing we can

00:21:40,720 --> 00:21:47,380
do and the experiments have done by the

00:21:44,230 --> 00:21:52,270
way I've started kind of the same way as

00:21:47,380 --> 00:21:55,630
TAC started so is the there is this hype

00:21:52,270 --> 00:21:57,250
about word Tyvek and the embeddings and

00:21:55,630 --> 00:22:00,100
the neural networks and stuff like that

00:21:57,250 --> 00:22:03,820
so does that really work in the context

00:22:00,100 --> 00:22:07,060
of search so let's see and I encourage

00:22:03,820 --> 00:22:10,179
you to try it out and think about not

00:22:07,060 --> 00:22:13,570
just as these

00:22:10,179 --> 00:22:16,240
tools as a kind of magic but as things

00:22:13,570 --> 00:22:18,789
that we need to understand in order to

00:22:16,240 --> 00:22:24,490
make them useful for for us at the end

00:22:18,789 --> 00:22:27,940
of the day and to jump a bit forward I

00:22:24,490 --> 00:22:29,799
think in terms of my experience in terms

00:22:27,940 --> 00:22:31,960
of retrieval is that terms and vectors

00:22:29,799 --> 00:22:35,590
and frequencies and distances in the

00:22:31,960 --> 00:22:38,230
embedding space work well together

00:22:35,590 --> 00:22:42,220
so the the old knowledge and the old

00:22:38,230 --> 00:22:46,090
models also to say models work work well

00:22:42,220 --> 00:22:49,049
in conjunction with this stuff and you

00:22:46,090 --> 00:22:52,749
may realize that each of these models

00:22:49,049 --> 00:22:58,090
feel also gaps in the algorithms from

00:22:52,749 --> 00:23:00,759
the other model great so I think some

00:22:58,090 --> 00:23:02,049
things I think about and again this is

00:23:00,759 --> 00:23:04,389
the frontier so we're thinking about how

00:23:02,049 --> 00:23:07,710
we can push this and I actually like

00:23:04,389 --> 00:23:09,970
sharing I could go ahead and probably

00:23:07,710 --> 00:23:12,730
similarly get a patent for some of these

00:23:09,970 --> 00:23:14,409
ideas I'm sure but I'm sure I'm not the

00:23:12,730 --> 00:23:15,879
only one who's thought of this stuff but

00:23:14,409 --> 00:23:17,049
I really like to share if I have an idea

00:23:15,879 --> 00:23:18,909
I want to share it out there as much as

00:23:17,049 --> 00:23:21,850
much as possible and one of the thoughts

00:23:18,909 --> 00:23:23,769
you know crazy idea I had is can you

00:23:21,850 --> 00:23:27,669
take this and build relevance based

00:23:23,769 --> 00:23:30,909
embeddings can we take our get to like a

00:23:27,669 --> 00:23:32,320
single vector space so often you know we

00:23:30,909 --> 00:23:34,749
keep talking about vector spaces can we

00:23:32,320 --> 00:23:37,210
use deep learning to learn the not just

00:23:34,749 --> 00:23:39,100
the document vector space or the vector

00:23:37,210 --> 00:23:41,619
space of the searcher to get one vector

00:23:39,100 --> 00:23:46,059
space that sort of a similarity will get

00:23:41,619 --> 00:23:48,279
tell you query document similarity in in

00:23:46,059 --> 00:23:51,700
one space and one thing you think about

00:23:48,279 --> 00:23:55,960
is can we use this negative sampling to

00:23:51,700 --> 00:23:57,940
get sort of a relevance based embedding

00:23:55,960 --> 00:23:59,710
because we have a lot of supervised data

00:23:57,940 --> 00:24:01,450
right often if you're doing any wanting

00:23:59,710 --> 00:24:02,860
to rank you might know that this

00:24:01,450 --> 00:24:05,320
document is relevant and these are

00:24:02,860 --> 00:24:06,850
irrelevant can you learn can you do the

00:24:05,320 --> 00:24:10,629
same negative sampling technique I just

00:24:06,850 --> 00:24:12,850
showed you to learn to push push this

00:24:10,629 --> 00:24:15,129
one this vector space for Bitcoin the

00:24:12,850 --> 00:24:17,139
document so that it will when exposed to

00:24:15,129 --> 00:24:19,779
a query that's relevant for it will

00:24:17,139 --> 00:24:21,279
return closer to one and when it's

00:24:19,779 --> 00:24:23,960
exposed to a query it's not relevant

00:24:21,279 --> 00:24:27,590
work for it will return something

00:24:23,960 --> 00:24:29,980
closer to zero you could of course the

00:24:27,590 --> 00:24:32,150
challenge is these embeddings are not

00:24:29,980 --> 00:24:33,980
generalizable they're based on queries

00:24:32,150 --> 00:24:35,780
and documents we've already seen we're

00:24:33,980 --> 00:24:38,960
maintaining a giant table of these

00:24:35,780 --> 00:24:41,810
things so we hope we need to have a lot

00:24:38,960 --> 00:24:43,520
of data to store okay all of the Bitcoin

00:24:41,810 --> 00:24:45,170
nettings and all the document embedding

00:24:43,520 --> 00:24:46,820
is that sort of thing which if you're

00:24:45,170 --> 00:24:49,390
doing embeddings anyway perhaps you're

00:24:46,820 --> 00:24:49,390
already doing that

00:24:50,500 --> 00:24:55,550
can we pre train you know if we pre

00:24:53,060 --> 00:24:58,100
train with our corpus or our sessions

00:24:55,550 --> 00:24:59,870
and then start to tweak that's another

00:24:58,100 --> 00:25:01,850
idea so maybe we start with almost like

00:24:59,870 --> 00:25:04,910
a Bayesian prior of this is what our

00:25:01,850 --> 00:25:06,800
corpus says and then keep making having

00:25:04,910 --> 00:25:08,420
an evolution maybe even an evolutionary

00:25:06,800 --> 00:25:11,330
approach over time to move our

00:25:08,420 --> 00:25:13,340
embeddings away from the document space

00:25:11,330 --> 00:25:17,540
and towards the searcher space it's

00:25:13,340 --> 00:25:19,430
another thought I think to one thing you

00:25:17,540 --> 00:25:21,050
can do is just take our your query

00:25:19,430 --> 00:25:22,730
vectors and sort of average them closer

00:25:21,050 --> 00:25:24,710
you know the documents that are relevant

00:25:22,730 --> 00:25:26,840
for them and just move them into the

00:25:24,710 --> 00:25:29,390
document space so if you know that

00:25:26,840 --> 00:25:32,450
bitcoin hype is in this in this area

00:25:29,390 --> 00:25:34,850
then you can average the relevant

00:25:32,450 --> 00:25:41,390
documents and get a push it into sort of

00:25:34,850 --> 00:25:42,980
the document embedding space so one

00:25:41,390 --> 00:25:45,920
thing I wanted to mention and I thought

00:25:42,980 --> 00:25:47,990
of this as I was in the mobility talk he

00:25:45,920 --> 00:25:48,860
talked about ranking it as a that's a

00:25:47,990 --> 00:25:51,080
sort of an LTR

00:25:48,860 --> 00:25:53,390
learning neural network LCR

00:25:51,080 --> 00:25:54,440
implementation well one thing I do want

00:25:53,390 --> 00:25:56,630
to mention this is sort of another

00:25:54,440 --> 00:25:58,850
low-hanging fruit is in learning to rank

00:25:56,630 --> 00:26:00,440
implementations embeddings are often

00:25:58,850 --> 00:26:02,180
some of the best features that people

00:26:00,440 --> 00:26:04,190
get gained from I've heard that from

00:26:02,180 --> 00:26:07,250
multiple people in teams independently

00:26:04,190 --> 00:26:09,920
so I want you guys to you know realize

00:26:07,250 --> 00:26:11,690
this you may be able to take this data

00:26:09,920 --> 00:26:13,640
and use it in the context of learning to

00:26:11,690 --> 00:26:15,260
rank along with traditional features

00:26:13,640 --> 00:26:18,740
like Tomaso says in traditional

00:26:15,260 --> 00:26:23,840
relevance work to get something to help

00:26:18,740 --> 00:26:29,120
yourself so let's see if we can do this

00:26:23,840 --> 00:26:31,850
in 14 minutes and do a demo language

00:26:29,120 --> 00:26:34,580
models so language models are about

00:26:31,850 --> 00:26:36,080
predicting text and what I'm going to

00:26:34,580 --> 00:26:37,910
talk about and this I might in the next

00:26:36,080 --> 00:26:39,260
session is you know

00:26:37,910 --> 00:26:42,700
beddings are great way to get started

00:26:39,260 --> 00:26:44,840
but language models I think especially

00:26:42,700 --> 00:26:46,850
recurrent neural network based language

00:26:44,840 --> 00:26:48,710
models I think in five years because

00:26:46,850 --> 00:26:51,650
should are going to be things in every

00:26:48,710 --> 00:26:53,060
search engineers toolbox and I'm really

00:26:51,650 --> 00:26:55,070
excited about them and what language

00:26:53,060 --> 00:26:58,760
models do is basically if you're not

00:26:55,070 --> 00:27:01,280
familiar they're predicting text eat

00:26:58,760 --> 00:27:03,440
pizza and you may say well this will

00:27:01,280 --> 00:27:05,690
obviously make such as if I'm texting

00:27:03,440 --> 00:27:07,520
someone I want auto suggests but also

00:27:05,690 --> 00:27:09,320
make sense if you have existing text and

00:27:07,520 --> 00:27:09,890
you're like what goes with this texts

00:27:09,320 --> 00:27:11,930
okay

00:27:09,890 --> 00:27:14,480
you know you can almost imagine a graph

00:27:11,930 --> 00:27:15,890
of this thing might inspire this next

00:27:14,480 --> 00:27:17,900
thing which might inspire this next

00:27:15,890 --> 00:27:23,470
thing so there's a lot of capability

00:27:17,900 --> 00:27:26,960
there for for doing some expansion and

00:27:23,470 --> 00:27:28,640
when people teach about recurrent neural

00:27:26,960 --> 00:27:30,650
networks they often start with saying

00:27:28,640 --> 00:27:32,680
why regular deep learning doesn't work

00:27:30,650 --> 00:27:35,390
well for it but I think it's actually

00:27:32,680 --> 00:27:36,860
maybe because I'm come from a search

00:27:35,390 --> 00:27:39,200
background it's actually easier to start

00:27:36,860 --> 00:27:41,930
from a traditional language model like a

00:27:39,200 --> 00:27:43,970
Markov language model and a Markov model

00:27:41,930 --> 00:27:47,590
basically you can think about it as just

00:27:43,970 --> 00:27:50,660
a transition matrix if we start with eat

00:27:47,590 --> 00:27:53,540
there is a high probability of eat pizza

00:27:50,660 --> 00:27:56,270
there is a very low probability of eaten

00:27:53,540 --> 00:27:58,010
nap and a slightly higher probability of

00:27:56,270 --> 00:28:02,840
each chair just because it's a noun

00:27:58,010 --> 00:28:05,180
right cat high probability of nap low

00:28:02,840 --> 00:28:08,930
probability of cat and hopefully no

00:28:05,180 --> 00:28:11,870
one's eating cat pizza so you can

00:28:08,930 --> 00:28:13,820
imagine this is like if I have a word I

00:28:11,870 --> 00:28:17,000
can predict the next one you can also

00:28:13,820 --> 00:28:19,490
then Te'o if I do eat pizza I might say

00:28:17,000 --> 00:28:21,440
okay well what comes after pizza and I

00:28:19,490 --> 00:28:23,750
could say oh maybe there's another word

00:28:21,440 --> 00:28:26,630
and you can keep like generating text

00:28:23,750 --> 00:28:28,790
forever and back in the early 2000s

00:28:26,630 --> 00:28:30,290
there was a lot of silly web things like

00:28:28,790 --> 00:28:32,330
automatically generating research papers

00:28:30,290 --> 00:28:36,350
that I think more or less were based on

00:28:32,330 --> 00:28:38,600
this kind of approach now the next

00:28:36,350 --> 00:28:41,150
question is you start to think what if I

00:28:38,600 --> 00:28:45,050
represent my word as an embedding so

00:28:41,150 --> 00:28:47,750
here's the eat embedding can I build a

00:28:45,050 --> 00:28:50,000
transition matrix that gives me the

00:28:47,750 --> 00:28:53,420
embedding of the next word

00:28:50,000 --> 00:28:55,700
and indeed with a Markov model if you

00:28:53,420 --> 00:28:57,920
have you can actually sort of do this

00:28:55,700 --> 00:28:59,060
you you get kind of weights and you

00:28:57,920 --> 00:29:03,020
might learn these weights through back

00:28:59,060 --> 00:29:05,180
propagation of what's the best way and

00:29:03,020 --> 00:29:10,310
again if we're gonna do basically a dot

00:29:05,180 --> 00:29:13,610
product if we look at if we have this

00:29:10,310 --> 00:29:16,070
kind of embedding and we say okay how

00:29:13,610 --> 00:29:18,050
much should for position zero

00:29:16,070 --> 00:29:21,140
how much for position one of the source

00:29:18,050 --> 00:29:23,600
of embedding count and so on and so

00:29:21,140 --> 00:29:25,640
forth and so you can you take this and

00:29:23,600 --> 00:29:27,890
you and you can multiply it through and

00:29:25,640 --> 00:29:29,690
get the embedding of the next word so

00:29:27,890 --> 00:29:35,600
transition matrices need not strictly

00:29:29,690 --> 00:29:37,610
apply to to that and both of these cases

00:29:35,600 --> 00:29:41,150
okay that's interesting but in both of

00:29:37,610 --> 00:29:42,710
these cases really require context so

00:29:41,150 --> 00:29:45,380
far we've just looked at the word before

00:29:42,710 --> 00:29:48,380
and the weakness for these language

00:29:45,380 --> 00:29:54,100
models is we don't know that the race is

00:29:48,380 --> 00:29:57,320
on eat dust right

00:29:54,100 --> 00:29:59,690
so if we have some context we know dust

00:29:57,320 --> 00:30:07,160
is very likely to be a word in this

00:29:59,690 --> 00:30:09,500
sentence so how do we get context so an

00:30:07,160 --> 00:30:12,470
old embedding this is just what I showed

00:30:09,500 --> 00:30:13,850
you if we have the eaten bedding we can

00:30:12,470 --> 00:30:16,460
sort of predict the embedding of the

00:30:13,850 --> 00:30:20,000
next word so this is sort of a the

00:30:16,460 --> 00:30:24,350
transition we're going from input to the

00:30:20,000 --> 00:30:27,620
next word okay so this is just what I

00:30:24,350 --> 00:30:30,620
showed you before and the next question

00:30:27,620 --> 00:30:33,590
becomes can I use this information about

00:30:30,620 --> 00:30:37,400
the past state to do something sort of

00:30:33,590 --> 00:30:41,540
with to predict the next state and okay

00:30:37,400 --> 00:30:44,810
we get the next word pizza maybe comes

00:30:41,540 --> 00:30:45,980
through here input again this is another

00:30:44,810 --> 00:30:48,020
transition matrix

00:30:45,980 --> 00:30:51,670
I just put dot dot dot to a new

00:30:48,020 --> 00:30:55,900
embedding to predict what might go there

00:30:51,670 --> 00:30:58,490
right everything we've done so far and

00:30:55,900 --> 00:31:01,250
then this kind of interesting thing

00:30:58,490 --> 00:31:03,860
happens if we could think about almost

00:31:01,250 --> 00:31:08,650
to transition matrices

00:31:03,860 --> 00:31:12,770
go from previous context to new context

00:31:08,650 --> 00:31:15,950
that also bleeds in the current what we

00:31:12,770 --> 00:31:17,960
just fed in as input we could somehow

00:31:15,950 --> 00:31:19,700
learn the right way through machine

00:31:17,960 --> 00:31:25,880
learning to balance those together and

00:31:19,700 --> 00:31:26,720
come create the next context and so on

00:31:25,880 --> 00:31:29,990
and so forth

00:31:26,720 --> 00:31:32,720
and I haven't used the word neural

00:31:29,990 --> 00:31:34,490
network yet and then you could have sort

00:31:32,720 --> 00:31:35,840
of a prediction the output embedding and

00:31:34,490 --> 00:31:37,250
need not even be embeddings you could

00:31:35,840 --> 00:31:39,320
actually just have a large set of

00:31:37,250 --> 00:31:43,580
vocabulary but embeddings are usually

00:31:39,320 --> 00:31:45,799
used and at any state you can say okay

00:31:43,580 --> 00:31:48,500
what's the likely word at this point

00:31:45,799 --> 00:31:50,330
given what have you seen before and you

00:31:48,500 --> 00:31:53,120
can keep doing this pattern over and

00:31:50,330 --> 00:31:54,650
over and you know what the right

00:31:53,120 --> 00:31:57,350
embedding should be because you know the

00:31:54,650 --> 00:31:59,120
words that go in each spot so with that

00:31:57,350 --> 00:32:01,730
right knowledge at each output you can

00:31:59,120 --> 00:32:03,770
do back propagation to learn all of

00:32:01,730 --> 00:32:08,179
these weights to get your model

00:32:03,770 --> 00:32:10,070
increasingly accurate in other words we

00:32:08,179 --> 00:32:13,370
might have this simpler view races on

00:32:10,070 --> 00:32:16,730
eat and we do all of these things here's

00:32:13,370 --> 00:32:20,419
our X - hidden X - hidden X - hidden and

00:32:16,730 --> 00:32:22,280
then finally we output something and we

00:32:20,419 --> 00:32:24,410
have our transitions at each hidden

00:32:22,280 --> 00:32:25,910
state and this is really just what a

00:32:24,410 --> 00:32:28,040
recurrent neural network is it's really

00:32:25,910 --> 00:32:30,580
a set of Markov models chained together

00:32:28,040 --> 00:32:36,470
where you learn all the transitions

00:32:30,580 --> 00:32:38,090
through back propagation now it for

00:32:36,470 --> 00:32:39,679
search another low-hanging fruit is

00:32:38,090 --> 00:32:43,280
it's obvious to imagine how we might

00:32:39,679 --> 00:32:47,929
inject contextually relevant items into

00:32:43,280 --> 00:32:49,850
here using this sort of model and of

00:32:47,929 --> 00:32:50,929
course it's not necessarily a silver

00:32:49,850 --> 00:32:53,929
bullet because we're still in this

00:32:50,929 --> 00:32:55,669
situation we've we were able to model

00:32:53,929 --> 00:32:57,230
our corpus well or maybe our Searchers

00:32:55,669 --> 00:32:59,059
vocabulary but we're still in the

00:32:57,230 --> 00:33:00,559
situation where we're not we're not

00:32:59,059 --> 00:33:03,230
learning the ideal sort of language

00:33:00,559 --> 00:33:05,450
model that connects both of them and

00:33:03,230 --> 00:33:07,700
that's where we get to and I think this

00:33:05,450 --> 00:33:11,450
is really where this stuff gets really

00:33:07,700 --> 00:33:14,120
exciting so of course we can make our

00:33:11,450 --> 00:33:15,050
sessions documents right this is a very

00:33:14,120 --> 00:33:17,520
common thing to do

00:33:15,050 --> 00:33:21,660
you could build embeddings just in that

00:33:17,520 --> 00:33:23,340
space and I sort of already said this we

00:33:21,660 --> 00:33:27,480
could have our document search term and

00:33:23,340 --> 00:33:31,170
we could do this sort of LTR sorts of

00:33:27,480 --> 00:33:34,830
things but what is really interesting is

00:33:31,170 --> 00:33:38,040
this new new exciting field of neural

00:33:34,830 --> 00:33:41,640
translation and this is an encoder

00:33:38,040 --> 00:33:44,960
decoder a framework you hear this sort

00:33:41,640 --> 00:33:49,170
of thing and we have like the races on

00:33:44,960 --> 00:33:56,700
and there's German should I try it Renee

00:33:49,170 --> 00:34:00,210
renin East in good ok and what what

00:33:56,700 --> 00:34:02,420
you're doing here is you start and you

00:34:00,210 --> 00:34:04,950
get sort of this hidden state between

00:34:02,420 --> 00:34:07,560
one neural network and another that's

00:34:04,950 --> 00:34:08,820
primes the next neural network when

00:34:07,560 --> 00:34:11,850
you're doing recurrent neural networks

00:34:08,820 --> 00:34:15,149
and that actually is enough information

00:34:11,850 --> 00:34:18,270
it turns out to begin to translate this

00:34:15,149 --> 00:34:20,100
information you do enough training with

00:34:18,270 --> 00:34:21,840
the actual translation and it this

00:34:20,100 --> 00:34:24,990
neural network becomes a translator of

00:34:21,840 --> 00:34:27,870
sorts and it's kind of its kind of

00:34:24,990 --> 00:34:30,090
amazing how how that works and by the

00:34:27,870 --> 00:34:31,260
way I'm talking about recurrent neural

00:34:30,090 --> 00:34:33,929
networks

00:34:31,260 --> 00:34:35,700
there are many architectures of RN ends

00:34:33,929 --> 00:34:38,040
and I'm just not going to get into in

00:34:35,700 --> 00:34:39,960
this talk there's a great blog article

00:34:38,040 --> 00:34:44,730
seek to seek the clown car of deep

00:34:39,960 --> 00:34:48,510
learning so you can imagine could we

00:34:44,730 --> 00:34:50,310
translate our documents to queries could

00:34:48,510 --> 00:34:53,340
we take a document animal control law

00:34:50,310 --> 00:34:56,190
and we know what queries might come out

00:34:53,340 --> 00:34:57,900
and we can sort of do this sort of

00:34:56,190 --> 00:35:00,960
translation between the two languages

00:34:57,900 --> 00:35:06,030
and can our ranking be a sense of how

00:35:00,960 --> 00:35:07,530
likely this this is going to happen how

00:35:06,030 --> 00:35:10,440
likely this is going to be relevant or

00:35:07,530 --> 00:35:12,390
not relevant I think I think we can I

00:35:10,440 --> 00:35:16,410
don't know if any was really doing this

00:35:12,390 --> 00:35:19,230
anywhere the other thing is can we use

00:35:16,410 --> 00:35:21,660
graded judgments and of course these

00:35:19,230 --> 00:35:22,980
predictions are sort of and you can

00:35:21,660 --> 00:35:24,390
think of those word embeddings for the

00:35:22,980 --> 00:35:27,390
words we're predicting or they would

00:35:24,390 --> 00:35:29,310
actually be the vocabulary probability

00:35:27,390 --> 00:35:31,200
distribution of our large vocabulary and

00:35:29,310 --> 00:35:33,060
you can imagine we might

00:35:31,200 --> 00:35:36,119
to wait our training samples so what

00:35:33,060 --> 00:35:38,579
should come out at any given point based

00:35:36,119 --> 00:35:39,900
on some notion of relevance to say these

00:35:38,579 --> 00:35:41,790
these are actually this is very

00:35:39,900 --> 00:35:43,290
important for this document these are

00:35:41,790 --> 00:35:46,560
moderately important and that sort of

00:35:43,290 --> 00:35:50,940
thing so that's another possibility I

00:35:46,560 --> 00:35:53,970
think that could be exciting the next

00:35:50,940 --> 00:35:56,670
level is this idea of thought vectors

00:35:53,970 --> 00:35:58,530
that you might hear about and this is

00:35:56,670 --> 00:36:00,480
something called skip thought vectors

00:35:58,530 --> 00:36:02,790
which is a kind of sentence to Veck and

00:36:00,480 --> 00:36:04,920
this is interesting because queries

00:36:02,790 --> 00:36:06,089
often come in this form of this stuff on

00:36:04,920 --> 00:36:08,730
the right there are a little there a

00:36:06,089 --> 00:36:12,300
couple terms they're not huge and you

00:36:08,730 --> 00:36:14,849
can even think about this as possibly a

00:36:12,300 --> 00:36:17,609
way to look before and after what the

00:36:14,849 --> 00:36:20,849
user is typing in a query box we type we

00:36:17,609 --> 00:36:22,530
send in its fleece was white as snow and

00:36:20,849 --> 00:36:26,430
the idea with sentence to Veck or you

00:36:22,530 --> 00:36:28,800
seeked these vectors with a sentence

00:36:26,430 --> 00:36:32,490
before in sentence after what this

00:36:28,800 --> 00:36:35,010
becomes is sort of a embedding for the

00:36:32,490 --> 00:36:38,490
sentence it's sort of encoding the

00:36:35,010 --> 00:36:40,560
semantic meeting before and after and I

00:36:38,490 --> 00:36:44,099
think about this as like can you look

00:36:40,560 --> 00:36:46,819
across queries across user sessions and

00:36:44,099 --> 00:36:49,800
do a similar kind of thing could we take

00:36:46,819 --> 00:36:52,440
one user's query that occurred before or

00:36:49,800 --> 00:36:54,660
after and sort of see some kind of

00:36:52,440 --> 00:36:56,430
relationship there or relationship

00:36:54,660 --> 00:36:58,800
between the document and those queries

00:36:56,430 --> 00:37:00,510
and I don't know I think there's a lot

00:36:58,800 --> 00:37:03,780
of this is about the frontier right I

00:37:00,510 --> 00:37:06,660
encourage all of you to to work on this

00:37:03,780 --> 00:37:08,670
so I'm not sure we're actually have

00:37:06,660 --> 00:37:11,310
we've got a try ok go that's what I mean

00:37:08,670 --> 00:37:13,260
it and we're gonna Tomas is gonna do a

00:37:11,310 --> 00:37:19,640
quick demo we should have scheduled four

00:37:13,260 --> 00:37:27,150
hours for this talk so as I said before

00:37:19,640 --> 00:37:29,190
I think the core idea here is that we we

00:37:27,150 --> 00:37:33,180
are not sure yet if that's going to be a

00:37:29,190 --> 00:37:35,400
silver bullet so the demo is about

00:37:33,180 --> 00:37:39,329
bringing some kind of a scientific view

00:37:35,400 --> 00:37:41,700
on this thing with experiments and the

00:37:39,329 --> 00:37:44,420
other thing is about showing things out

00:37:41,700 --> 00:37:50,120
the things work out in

00:37:44,420 --> 00:37:54,200
life with real data so I've basically

00:37:50,120 --> 00:38:00,080
used stuff from this project which is

00:37:54,200 --> 00:38:02,780
called listen for IR which from from a

00:38:00,080 --> 00:38:07,190
university is basically losing a set of

00:38:02,780 --> 00:38:10,970
tools to to experiment with do

00:38:07,190 --> 00:38:13,820
experiments with listen and but there

00:38:10,970 --> 00:38:16,070
are more than this out there that is

00:38:13,820 --> 00:38:20,140
also this tool called an cerini which is

00:38:16,070 --> 00:38:25,270
basically as the same the same idea so

00:38:20,140 --> 00:38:28,250
I've used this the data sent from the

00:38:25,270 --> 00:38:30,530
association of computer machinery which

00:38:28,250 --> 00:38:35,930
is a small one it is just three thousand

00:38:30,530 --> 00:38:39,100
knocks and basically I've made running

00:38:35,930 --> 00:38:41,540
all these ducts indexing and searching

00:38:39,100 --> 00:38:47,930
using different ranking models so

00:38:41,540 --> 00:38:50,060
basically using the m25 tf-idf and some

00:38:47,930 --> 00:38:54,140
other similarity classes that are

00:38:50,060 --> 00:38:56,180
available in loosen together with word

00:38:54,140 --> 00:39:02,330
embeddings and particle factors and

00:38:56,180 --> 00:39:06,950
since we don't have time I will directly

00:39:02,330 --> 00:39:14,270
go to the results and it's all up on

00:39:06,950 --> 00:39:17,810
github so this show Suites up very well

00:39:14,270 --> 00:39:21,110
but basically what we have is that there

00:39:17,810 --> 00:39:24,220
is skip the second line for a second

00:39:21,110 --> 00:39:27,200
it's the class they're basically the end

00:39:24,220 --> 00:39:30,050
ECG column is the second column is

00:39:27,200 --> 00:39:33,190
basically between basically the higher

00:39:30,050 --> 00:39:36,190
is the is is the better and we have that

00:39:33,190 --> 00:39:41,120
classic similar similarity which is

00:39:36,190 --> 00:39:41,750
tf-idf basically performed better than

00:39:41,120 --> 00:39:43,670
anyone else

00:39:41,750 --> 00:39:48,860
so it's surprised it's not a silver

00:39:43,670 --> 00:39:50,510
bullet beyond 25 is very load diverged

00:39:48,860 --> 00:39:53,240
from randomness which is another model

00:39:50,510 --> 00:39:56,000
it's kind of low as well and paragraph

00:39:53,240 --> 00:39:56,930
vector and were were vectors ranking

00:39:56,000 --> 00:40:01,640
models

00:39:56,930 --> 00:40:05,540
are slightly below classic similar ideas

00:40:01,640 --> 00:40:10,430
so it doesn't work but it's not really

00:40:05,540 --> 00:40:12,920
the case so we have 3000 dogs which is

00:40:10,430 --> 00:40:14,960
really not enough for I mean in this is

00:40:12,920 --> 00:40:18,109
kind of true for most of machine

00:40:14,960 --> 00:40:22,220
learning we need quite some some stuff

00:40:18,109 --> 00:40:27,410
quite some data and so this first result

00:40:22,220 --> 00:40:30,290
was was generated retrieving the first

00:40:27,410 --> 00:40:34,730
100 relevant possibly relevant documents

00:40:30,290 --> 00:40:38,030
for each query and for such a small data

00:40:34,730 --> 00:40:43,040
set this was probably not not the right

00:40:38,030 --> 00:40:46,970
choice so let's see what happens when we

00:40:43,040 --> 00:40:53,089
have 10 when we retrieve only the top 10

00:40:46,970 --> 00:40:57,020
and we top 10 we have that again we have

00:40:53,089 --> 00:41:01,059
the classic is slightly over paragraph

00:40:57,020 --> 00:41:05,559
factors but not that much anymore and

00:41:01,059 --> 00:41:09,109
surprisingly enough this LTS thing is a

00:41:05,559 --> 00:41:13,849
small regression model that use a neural

00:41:09,109 --> 00:41:18,410
network to basically use statistics

00:41:13,849 --> 00:41:20,210
about about terms to learn to score in

00:41:18,410 --> 00:41:23,420
an unsupervised way and actually that

00:41:20,210 --> 00:41:26,990
was the turn out is to perform the

00:41:23,420 --> 00:41:30,140
better but as I said at a certain point

00:41:26,990 --> 00:41:31,700
the best comes with mixing the old

00:41:30,140 --> 00:41:36,140
knowledge so to say with the new

00:41:31,700 --> 00:41:39,200
knowledge and so mixing the paragraph

00:41:36,140 --> 00:41:43,990
vectors ranking together with language

00:41:39,200 --> 00:41:48,349
modeling delayed similarity performed

00:41:43,990 --> 00:41:51,890
best slightly below what vector with BM

00:41:48,349 --> 00:41:54,440
25 so this is the kind of experiments I

00:41:51,890 --> 00:41:56,809
encourage you to do when it comes to

00:41:54,440 --> 00:41:59,359
your search projects so really try out

00:41:56,809 --> 00:42:01,910
different things think about the data

00:41:59,359 --> 00:42:04,250
you have and what kind of things might

00:42:01,910 --> 00:42:05,869
sense or might not sense to use so in

00:42:04,250 --> 00:42:08,630
this in this case probably three

00:42:05,869 --> 00:42:10,500
thousand dots is not enough for

00:42:08,630 --> 00:42:12,510
paragraph vectors and word back

00:42:10,500 --> 00:42:18,119
vectors based rankings to outperform

00:42:12,510 --> 00:42:21,630
along the basic models so I try to make

00:42:18,119 --> 00:42:25,830
it as quick as possible so if the other

00:42:21,630 --> 00:42:26,730
thing is we've prepared a small demo

00:42:25,830 --> 00:42:31,290
using flink

00:42:26,730 --> 00:42:34,170
to ingest tweets about those tags

00:42:31,290 --> 00:42:36,650
they're burning bots were burning boxes

00:42:34,170 --> 00:42:40,430
mm hatre seen deep learning whatever and

00:42:36,650 --> 00:42:44,460
store them into continued continuously

00:42:40,430 --> 00:42:46,680
index them and run a pre fixed query

00:42:44,460 --> 00:42:49,680
against them to see how the relevance

00:42:46,680 --> 00:42:55,430
changes over time when and what kind of

00:42:49,680 --> 00:42:58,940
results we have and with my ugly jQuery

00:42:55,430 --> 00:43:03,030
capabilities I kind of made this ongoing

00:42:58,940 --> 00:43:05,400
CSV basically so you can see that so the

00:43:03,030 --> 00:43:09,300
query run is a something lappa about

00:43:05,400 --> 00:43:14,849
neural search deep learning and at first

00:43:09,300 --> 00:43:18,690
we have that PM 25 return this this as

00:43:14,849 --> 00:43:21,050
the as the top tweet and class classic

00:43:18,690 --> 00:43:25,140
which is tf-idf deep learning and fonts

00:43:21,050 --> 00:43:30,720
and document rankings returned the same

00:43:25,140 --> 00:43:34,140
as beyond 25 but basically going down so

00:43:30,720 --> 00:43:39,630
we have that the UH 35 just lost deep

00:43:34,140 --> 00:43:41,430
learning and document embeddings Michael

00:43:39,630 --> 00:43:43,410
Jordan not the one for the basketball

00:43:41,430 --> 00:43:45,900
player words us that deep learn is going

00:43:43,410 --> 00:43:48,480
to be lead to bad medical whatever so

00:43:45,900 --> 00:43:52,290
it's and this is the kind of things that

00:43:48,480 --> 00:43:55,619
is important to do in real life so as

00:43:52,290 --> 00:43:57,390
the data changes see how the relevance

00:43:55,619 --> 00:44:01,320
changes and what kind of documents you

00:43:57,390 --> 00:44:04,589
get if they are relevant or not and if

00:44:01,320 --> 00:44:08,040
you look again language model Dirac led

00:44:04,589 --> 00:44:10,170
basically returns the first top results

00:44:08,040 --> 00:44:13,320
that it used to return at the first time

00:44:10,170 --> 00:44:16,200
so it doesn't adapt it seems it is less

00:44:13,320 --> 00:44:20,220
flexible than the document embedding

00:44:16,200 --> 00:44:22,890
ranking to the to the data that changes

00:44:20,220 --> 00:44:24,250
in the index so that's something that

00:44:22,890 --> 00:44:27,100
for example let's

00:44:24,250 --> 00:44:29,650
that's one quick thing to learn from

00:44:27,100 --> 00:44:32,020
this quick experiment and since we have

00:44:29,650 --> 00:44:38,430
no more time or kind of no more time I'm

00:44:32,020 --> 00:44:43,630
going to skip the other parts yeah so

00:44:38,430 --> 00:44:47,800
two gotta go to the end yes and I think

00:44:43,630 --> 00:44:49,780
we'll get clapped off soon so basically

00:44:47,800 --> 00:44:52,450
I think some takeaways for us for this

00:44:49,780 --> 00:44:55,510
are you know mixing there's no silver

00:44:52,450 --> 00:44:57,430
bullet you know there's no magic

00:44:55,510 --> 00:44:59,770
cognitive search unicorns that are gonna

00:44:57,430 --> 00:45:03,880
come and save your everyone's jobs or

00:44:59,770 --> 00:45:04,900
take everyone's jobs yet one thing that

00:45:03,880 --> 00:45:08,590
I think is important to take away is

00:45:04,900 --> 00:45:10,660
really showing tokenizing text and any

00:45:08,590 --> 00:45:12,180
thing can really be in an embedding

00:45:10,660 --> 00:45:14,110
space deep learning is good at

00:45:12,180 --> 00:45:16,330
representations of all of these things

00:45:14,110 --> 00:45:18,460
and vectors and I talked about queries

00:45:16,330 --> 00:45:19,990
and documents queries can mean users we

00:45:18,460 --> 00:45:22,390
can talk about images all these things

00:45:19,990 --> 00:45:23,950
can be vector and in relevant search we

00:45:22,390 --> 00:45:26,520
say everything can be tokenized and I

00:45:23,950 --> 00:45:29,740
think those things very much dovetail

00:45:26,520 --> 00:45:31,240
and solar in the S community need to get

00:45:29,740 --> 00:45:33,660
better at first-class vector support

00:45:31,240 --> 00:45:36,400
raise your hand if you know about Vespa

00:45:33,660 --> 00:45:39,280
so some people ok Vespa does this very

00:45:36,400 --> 00:45:41,920
well and so learning s sort of it's kind

00:45:39,280 --> 00:45:44,200
of painful to get that work so in the

00:45:41,920 --> 00:45:47,140
India API you can see there is it's very

00:45:44,200 --> 00:45:50,440
hard to see how can I fit a vector into

00:45:47,140 --> 00:45:52,360
that API so I mean that's something that

00:45:50,440 --> 00:45:53,680
probably will will or will not evolve

00:45:52,360 --> 00:45:58,030
over time but it's something to think

00:45:53,680 --> 00:46:00,790
about so how to make these changes also

00:45:58,030 --> 00:46:01,930
in the software we use is this is this

00:46:00,790 --> 00:46:03,790
whatever you think we've done is in

00:46:01,930 --> 00:46:07,510
supervised learning is this gonna be the

00:46:03,790 --> 00:46:09,220
future and we haven't really how much do

00:46:07,510 --> 00:46:10,630
you do with unsupervised learning versus

00:46:09,220 --> 00:46:12,760
learning Trank where there's cliques and

00:46:10,630 --> 00:46:14,320
you have a lot of labeled data can we do

00:46:12,760 --> 00:46:16,450
better with unsupervised learning I mean

00:46:14,320 --> 00:46:19,090
all of these things are questioned and

00:46:16,450 --> 00:46:20,380
finally I there's this slack community

00:46:19,090 --> 00:46:21,730
that we have we talk about search

00:46:20,380 --> 00:46:24,430
relevance issues I really encourage

00:46:21,730 --> 00:46:26,350
everyone to join we talk about plugins

00:46:24,430 --> 00:46:28,540
there's even a jobs board there's

00:46:26,350 --> 00:46:29,830
conferences we of course hope that

00:46:28,540 --> 00:46:32,110
everyone knows about haystack our

00:46:29,830 --> 00:46:34,510
conference that what the community did

00:46:32,110 --> 00:46:36,490
book authors are there to talk about

00:46:34,510 --> 00:46:37,360
directly at these issues so please join

00:46:36,490 --> 00:46:40,480
us there if you

00:46:37,360 --> 00:46:41,680
questions so okay thank you uh sorry

00:46:40,480 --> 00:46:47,660
we're going to Rupp you

00:46:41,680 --> 00:46:47,660

YouTube URL: https://www.youtube.com/watch?v=33UR9uQlCpE


