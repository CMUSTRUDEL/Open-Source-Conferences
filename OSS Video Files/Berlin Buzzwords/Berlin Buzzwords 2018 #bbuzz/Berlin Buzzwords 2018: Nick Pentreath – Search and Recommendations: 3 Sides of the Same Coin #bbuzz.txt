Title: Berlin Buzzwords 2018: Nick Pentreath â€“ Search and Recommendations: 3 Sides of the Same Coin #bbuzz
Publication date: 2018-06-13
Playlist: Berlin Buzzwords 2018 #bbuzz
Description: 
	Recommendation engines are one of the most well-known, widely-used and highest value use cases for applied machine learning. Search and recommender systems are closely linked, often co-existing and intermingling. Indeed, modern search applications at scale typically involve significant elements of machine learning, while personalization systems rely heavily on and are deeply integrated with search engines. In this session, I will explore this link between search and recommendations.

In particular, I will cover three of the most common approaches for using search engines to serve personalized recommendation models. I call these the score then search, native search and custom ranking approaches. I will detail each approach, comparing it with the others in terms of various considerations important for production systems at scale, including the architecture, schemas, performance, quality and flexibility aspects. Finally, I will also contrast these model-based approaches with what is achievable using pure search.

Read more: 
https://2018.berlinbuzzwords.de/18/session/search-and-recommendations-3-sides-same-coin

About Nick Pentreath:
https://2018.berlinbuzzwords.de/users/nick-pentreath

Website: https://berlinbuzzwords.de/
Twitter: https://twitter.com/berlinbuzzwords
LinkedIn: https://www.linkedin.com/showcase/berlin-buzzwords/ 
Reddit: https://www.reddit.com/r/berlinbuzzwords/
Captions: 
	00:00:04,940 --> 00:00:11,010
so I'm Nick Penn truth ml Nick on

00:00:08,520 --> 00:00:14,100
Twitter and github I'm a principal

00:00:11,010 --> 00:00:15,900
engineer at IBM where I work for code a

00:00:14,100 --> 00:00:19,080
which is the Center for open source data

00:00:15,900 --> 00:00:21,780
and AI technologies I focus on machine

00:00:19,080 --> 00:00:23,760
learning deep learning AI and I'm an

00:00:21,780 --> 00:00:26,040
Apache spark emitter and PMC member and

00:00:23,760 --> 00:00:28,550
I've written a fairly out-of-date book

00:00:26,040 --> 00:00:30,660
on machine learning with spark

00:00:28,550 --> 00:00:32,369
so before we start just a little bit

00:00:30,660 --> 00:00:34,680
about code a it was formally known as

00:00:32,369 --> 00:00:36,989
the spark Technology Center and was

00:00:34,680 --> 00:00:40,160
formed by IBM to to focus on Apache

00:00:36,989 --> 00:00:43,379
spark in the surrounding ecosystem and

00:00:40,160 --> 00:00:45,859
over the course of its its history it

00:00:43,379 --> 00:00:49,109
expanded that mission to really focus on

00:00:45,859 --> 00:00:51,899
AI and deep learning and machine

00:00:49,109 --> 00:00:54,269
learning data science in general so now

00:00:51,899 --> 00:00:57,329
we have rebranded it as code a and we

00:00:54,269 --> 00:00:59,999
focus on enabling the into end AI life

00:00:57,329 --> 00:01:03,120
cycle in the enterprise so we focus on

00:00:59,999 --> 00:01:04,739
spark as well as the Python data science

00:01:03,120 --> 00:01:07,320
stack deep learning frameworks and we've

00:01:04,739 --> 00:01:09,840
got a couple of projects that we've

00:01:07,320 --> 00:01:11,820
released the model acid exchange and the

00:01:09,840 --> 00:01:12,960
fabric for deep learning which I'll

00:01:11,820 --> 00:01:15,960
mention a little bit at the end if we

00:01:12,960 --> 00:01:18,240
have time so today we will start with a

00:01:15,960 --> 00:01:20,039
little overview of recommender systems

00:01:18,240 --> 00:01:21,509
and then look at search and

00:01:20,039 --> 00:01:23,159
recommendations and how they how they

00:01:21,509 --> 00:01:26,009
are integrated and how you can use

00:01:23,159 --> 00:01:28,799
search engines to serve recommender

00:01:26,009 --> 00:01:30,210
models and in particular the three sides

00:01:28,799 --> 00:01:33,479
of the coin so that the three different

00:01:30,210 --> 00:01:36,030
broad approaches that I see to to do

00:01:33,479 --> 00:01:39,680
that and finally end off with some

00:01:36,030 --> 00:01:42,240
performance evaluations and conclusion

00:01:39,680 --> 00:01:44,520
so recommender systems are one of the

00:01:42,240 --> 00:01:46,259
earliest and certainly most high-value

00:01:44,520 --> 00:01:48,030
use cases of machine learning that we've

00:01:46,259 --> 00:01:49,979
seen you know each and every one of us

00:01:48,030 --> 00:01:52,079
are not in our daily lives comes into

00:01:49,979 --> 00:01:54,719
contact with a multitude of recommender

00:01:52,079 --> 00:01:58,229
systems if every day so whether you're

00:01:54,719 --> 00:02:02,549
browsing and your online store you know

00:01:58,229 --> 00:02:05,429
streaming music looking at YouTube using

00:02:02,549 --> 00:02:06,659
your social network apps you're coming

00:02:05,429 --> 00:02:08,220
into contact with some form of

00:02:06,659 --> 00:02:11,760
recommendation and personalization

00:02:08,220 --> 00:02:13,860
system and this is not just pervasive in

00:02:11,760 --> 00:02:15,480
the sense of you're affecting our lives

00:02:13,860 --> 00:02:19,050
but it but it's pervasive in the sense

00:02:15,480 --> 00:02:20,370
of economic impact and value so if we

00:02:19,050 --> 00:02:22,079
can improve the recommendation and

00:02:20,370 --> 00:02:24,349
personalization system

00:02:22,079 --> 00:02:27,930
there's real money to be made there so

00:02:24,349 --> 00:02:29,549
Amazon for example about 30% of the

00:02:27,930 --> 00:02:32,069
bottom line is accounted for by the

00:02:29,549 --> 00:02:33,450
recommender system for companies like

00:02:32,069 --> 00:02:35,640
Netflix and other streaming sites it

00:02:33,450 --> 00:02:38,129
might be as high as 70 or 80 for ad

00:02:35,640 --> 00:02:41,700
targeting a lot depends on these these

00:02:38,129 --> 00:02:43,769
systems and models so in your

00:02:41,700 --> 00:02:46,950
recommendation engine you have two types

00:02:43,769 --> 00:02:48,359
of entities users and items the users

00:02:46,950 --> 00:02:50,489
are self-explanatory and without them

00:02:48,359 --> 00:02:52,349
there is no system and the items can be

00:02:50,489 --> 00:02:54,359
anything in this case perhaps you're a

00:02:52,349 --> 00:02:56,760
movie and attached to each of those

00:02:54,359 --> 00:02:59,909
users and items are pieces of metadata

00:02:56,760 --> 00:03:03,510
and activity data so for users it might

00:02:59,909 --> 00:03:05,790
be demographics geolocation for items

00:03:03,510 --> 00:03:08,819
that might be categories tags and the

00:03:05,790 --> 00:03:11,310
content and that aggregated activity

00:03:08,819 --> 00:03:13,079
data might be for the for a movie you

00:03:11,310 --> 00:03:15,090
know the number of likes the number of

00:03:13,079 --> 00:03:17,579
players when it was last played so this

00:03:15,090 --> 00:03:20,150
is an indicator of what is the activity

00:03:17,579 --> 00:03:23,730
around that

00:03:20,150 --> 00:03:28,109
so our system requires us to use this

00:03:23,730 --> 00:03:30,269
metadata and this content in some way so

00:03:28,109 --> 00:03:32,669
for example we want to do filtering and

00:03:30,269 --> 00:03:33,840
grouping we might want to show

00:03:32,669 --> 00:03:37,229
recommendations that are based on a

00:03:33,840 --> 00:03:40,109
category we might only want to show a

00:03:37,229 --> 00:03:41,579
popular items or not so popular items if

00:03:40,109 --> 00:03:43,879
we want sort of longtail recommendations

00:03:41,579 --> 00:03:47,519
we might want to show more recent items

00:03:43,879 --> 00:03:49,620
we also need to apply business rules so

00:03:47,519 --> 00:03:51,569
for example based on age we don't want

00:03:49,620 --> 00:03:53,639
to show age restricted content to

00:03:51,569 --> 00:03:56,250
younger viewers we also might have

00:03:53,639 --> 00:04:01,199
geographical constraints you know data

00:03:56,250 --> 00:04:02,849
privacy regulation so the core piece of

00:04:01,199 --> 00:04:05,099
data that we care about in a recommender

00:04:02,849 --> 00:04:06,930
system is the event this is a user

00:04:05,099 --> 00:04:08,639
interactions every time a user comes and

00:04:06,930 --> 00:04:09,829
interacts with our system they're

00:04:08,639 --> 00:04:11,879
telling us a little bit about themselves

00:04:09,829 --> 00:04:13,680
most of the examples that you see in

00:04:11,879 --> 00:04:15,569
recommender systems and building the

00:04:13,680 --> 00:04:18,090
models or all around explicit preference

00:04:15,569 --> 00:04:20,909
data so someone says I give this movie a

00:04:18,090 --> 00:04:23,190
rating but in most cases the vast

00:04:20,909 --> 00:04:25,560
majority of data available is of the

00:04:23,190 --> 00:04:27,150
implicit type so a user comes along and

00:04:25,560 --> 00:04:29,039
they interacting with the system they

00:04:27,150 --> 00:04:30,960
don't specifically tell you I really

00:04:29,039 --> 00:04:32,880
like this movie here's a rating instead

00:04:30,960 --> 00:04:35,639
you have page views head to cards

00:04:32,880 --> 00:04:37,460
purchases and you have you know

00:04:35,639 --> 00:04:40,139
plays follows all these kind of implicit

00:04:37,460 --> 00:04:42,090
indicators of preference that may mean

00:04:40,139 --> 00:04:44,069
that the user likes that data item but

00:04:42,090 --> 00:04:46,439
it may not so a pageview is a light

00:04:44,069 --> 00:04:47,729
indicator of preference and ad saccade

00:04:46,439 --> 00:04:49,650
might be a stronger one and a purchase

00:04:47,729 --> 00:04:51,090
might be the strongest but even if

00:04:49,650 --> 00:04:52,409
someone purchases something it doesn't

00:04:51,090 --> 00:04:54,180
necessarily mean they like it because

00:04:52,409 --> 00:04:55,770
later on they may you know give a

00:04:54,180 --> 00:04:57,509
negative review or even return that item

00:04:55,770 --> 00:04:59,909
and unless your system captures that you

00:04:57,509 --> 00:05:01,499
will never actually know that so these

00:04:59,909 --> 00:05:05,699
events give us an indication about what

00:05:01,499 --> 00:05:08,599
user preferences are and attached to

00:05:05,699 --> 00:05:10,949
each one of these events is a context so

00:05:08,599 --> 00:05:12,479
every time a user comes and interacts

00:05:10,949 --> 00:05:14,699
with that system they're using a

00:05:12,479 --> 00:05:17,250
specific browser at a specific time of

00:05:14,699 --> 00:05:19,289
day there's a geolocation attached to it

00:05:17,250 --> 00:05:21,150
and context matters for recommendation

00:05:19,289 --> 00:05:23,610
because you we may want to recommend for

00:05:21,150 --> 00:05:24,930
example different movies to a user based

00:05:23,610 --> 00:05:26,279
on whether they are sitting at home in

00:05:24,930 --> 00:05:27,810
the evening or whether they're on their

00:05:26,279 --> 00:05:33,419
commute to work or whether they're at

00:05:27,810 --> 00:05:35,159
work perhaps for example so since most

00:05:33,419 --> 00:05:36,629
of this data is implicit we have to

00:05:35,159 --> 00:05:38,759
think about how to handle implicit data

00:05:36,629 --> 00:05:40,349
and broadly speaking you can either

00:05:38,759 --> 00:05:43,139
incorporate it into the model directly

00:05:40,349 --> 00:05:44,789
and you'll see some examples of that

00:05:43,139 --> 00:05:46,949
later or you can try and attach some

00:05:44,789 --> 00:05:50,430
sort of weighting scheme yeah so all of

00:05:46,949 --> 00:05:52,979
this binary 0 1 implicit data can have a

00:05:50,430 --> 00:05:56,399
weight attached so a page view might be

00:05:52,979 --> 00:05:59,219
a 1 for example and a jacquard might be

00:05:56,399 --> 00:06:00,839
a 3 a purchase might be a 5 so this is

00:05:59,219 --> 00:06:02,849
difficult to to necessarily do in a

00:06:00,839 --> 00:06:05,699
principled way but you can you can

00:06:02,849 --> 00:06:07,949
weight add these weights to the event

00:06:05,699 --> 00:06:09,000
and then use a standard model but we

00:06:07,949 --> 00:06:11,689
definitely have to think about how to

00:06:09,000 --> 00:06:13,979
handle this in the system

00:06:11,689 --> 00:06:15,870
another key elements of recommendation

00:06:13,979 --> 00:06:17,490
engines is the cold start problem so

00:06:15,870 --> 00:06:19,259
when a new user or item comes into the

00:06:17,490 --> 00:06:22,169
system that is called start for new

00:06:19,259 --> 00:06:23,699
items we have no historical data so we

00:06:22,169 --> 00:06:25,649
don't have a model for them and

00:06:23,699 --> 00:06:26,310
typically one needs to fall back to use

00:06:25,649 --> 00:06:29,099
basslines

00:06:26,310 --> 00:06:31,620
or item content to try and create some

00:06:29,099 --> 00:06:33,750
sort of recommendation a new or unknown

00:06:31,620 --> 00:06:35,399
user might even either be a completely

00:06:33,750 --> 00:06:37,289
new user to the system or perhaps

00:06:35,399 --> 00:06:39,899
they're anonymous they're browsing using

00:06:37,289 --> 00:06:41,729
using a new device or they have ad

00:06:39,899 --> 00:06:44,399
blockers or whatever the case may be but

00:06:41,729 --> 00:06:46,440
in that case again we have no historical

00:06:44,399 --> 00:06:48,910
data for them and we have some context

00:06:46,440 --> 00:06:50,950
data but potentially very limited

00:06:48,910 --> 00:06:52,300
so we cannot directly use most of the

00:06:50,950 --> 00:06:55,120
kind of collaborative filtering based

00:06:52,300 --> 00:06:56,200
models that we would normally use except

00:06:55,120 --> 00:06:57,790
for the fact that we can try and use

00:06:56,200 --> 00:06:59,980
item similarity for let's say the

00:06:57,790 --> 00:07:03,400
current item that the user is viewing if

00:06:59,980 --> 00:07:05,410
we have built a model for that item all

00:07:03,400 --> 00:07:07,360
the typically we try to represent the

00:07:05,410 --> 00:07:08,770
user as some sort of aggregation of the

00:07:07,360 --> 00:07:11,290
items in their session as they're

00:07:08,770 --> 00:07:14,350
browsing so we try and build up that

00:07:11,290 --> 00:07:15,970
that user representation on the fly and

00:07:14,350 --> 00:07:17,710
in some cases contextual models can

00:07:15,970 --> 00:07:19,960
incorporate by the context data and the

00:07:17,710 --> 00:07:24,880
short term history of that user during

00:07:19,960 --> 00:07:26,770
that session so prediction in a

00:07:24,880 --> 00:07:28,900
recommending recommender system is all

00:07:26,770 --> 00:07:30,730
about ranking we have to take all the

00:07:28,900 --> 00:07:32,650
available content or items that we have

00:07:30,730 --> 00:07:34,690
in our system every once you present the

00:07:32,650 --> 00:07:36,240
user a list and that list needs to be

00:07:34,690 --> 00:07:38,320
ranked in order of our estimated

00:07:36,240 --> 00:07:40,390
estimate of the preference of the user

00:07:38,320 --> 00:07:41,650
so in other words by likelihood that we

00:07:40,390 --> 00:07:43,570
think the user will interact with that

00:07:41,650 --> 00:07:45,610
item and typically we have very very

00:07:43,570 --> 00:07:50,130
large item sets and we only want to

00:07:45,610 --> 00:07:50,130
return a very very small set five or ten

00:07:51,330 --> 00:07:55,210
some of the serving requirements that we

00:07:53,560 --> 00:07:56,440
have for serving recommendation models

00:07:55,210 --> 00:07:59,260
this is not exhaustive but these are

00:07:56,440 --> 00:08:01,060
some key ones as we've mentioned we

00:07:59,260 --> 00:08:03,670
serving is about ranking large number of

00:08:01,060 --> 00:08:06,430
items so we need to be able to have a

00:08:03,670 --> 00:08:08,050
ranking system in almost all cases we

00:08:06,430 --> 00:08:09,460
want to do be able to do some sort of

00:08:08,050 --> 00:08:11,470
filtering whether by categories

00:08:09,460 --> 00:08:14,200
popularity time price to your location

00:08:11,470 --> 00:08:15,730
any combination slice of slicing and

00:08:14,200 --> 00:08:18,040
dicing the metadata that we have around

00:08:15,730 --> 00:08:20,530
items or users we want to be able to

00:08:18,040 --> 00:08:21,820
filter based on that we'd ideally like

00:08:20,530 --> 00:08:23,620
to use all the data we have available

00:08:21,820 --> 00:08:25,450
that prediction time in particular

00:08:23,620 --> 00:08:27,220
content and context because in

00:08:25,450 --> 00:08:29,380
especially in the cold start problem

00:08:27,220 --> 00:08:30,970
that is a rich data that we can use to

00:08:29,380 --> 00:08:33,400
still make them you're a principal

00:08:30,970 --> 00:08:35,680
prediction we need to scale both with

00:08:33,400 --> 00:08:37,510
the item set and the feature set so the

00:08:35,680 --> 00:08:39,820
item set naturally as we get more items

00:08:37,510 --> 00:08:41,849
we need to scale that serving system and

00:08:39,820 --> 00:08:44,020
the feature set as we add more and more

00:08:41,849 --> 00:08:45,730
features that are used in the model or

00:08:44,020 --> 00:08:47,500
more and more contextual and metadata

00:08:45,730 --> 00:08:49,480
that's used in the model we also need to

00:08:47,500 --> 00:08:52,150
scale their computation we need a handle

00:08:49,480 --> 00:08:53,980
cold start so but the system needs to

00:08:52,150 --> 00:08:56,080
perhaps incorporate this additional data

00:08:53,980 --> 00:08:58,240
that we can use to handle cold start and

00:08:56,080 --> 00:08:59,920
we also need to you know have some sort

00:08:58,240 --> 00:09:02,470
of content-based fallback perhaps or

00:08:59,920 --> 00:09:03,910
item aggregation capability

00:09:02,470 --> 00:09:05,590
and finally we would ideally like to

00:09:03,910 --> 00:09:08,560
easily incorporate a new preference data

00:09:05,590 --> 00:09:10,390
so we train models simply or fold into

00:09:08,560 --> 00:09:16,090
an existing model without doing a full

00:09:10,390 --> 00:09:17,890
retraining so that's a brief well answer

00:09:16,090 --> 00:09:20,520
of recommendation engines and in

00:09:17,890 --> 00:09:22,330
particular what we need to serve them I

00:09:20,520 --> 00:09:24,370
will talk about search and

00:09:22,330 --> 00:09:26,650
recommendations and how they can

00:09:24,370 --> 00:09:29,350
interlock but first we'll just take a

00:09:26,650 --> 00:09:30,730
little detour into some of the sort of

00:09:29,350 --> 00:09:33,190
core models that we're going to discuss

00:09:30,730 --> 00:09:34,840
today so the ratings matrix is at the

00:09:33,190 --> 00:09:37,060
the center of most collaborative

00:09:34,840 --> 00:09:39,310
filtering approaches and this represents

00:09:37,060 --> 00:09:41,560
the the user interactions in this form

00:09:39,310 --> 00:09:43,270
of the sparse matrix so the users as

00:09:41,560 --> 00:09:45,250
rows and the items as columns in this

00:09:43,270 --> 00:09:47,020
case movies and each interactional

00:09:45,250 --> 00:09:49,870
rating that the user gives to a movie is

00:09:47,020 --> 00:09:51,720
represented here so you'll notice it is

00:09:49,870 --> 00:09:54,940
sparse and not all users rate or movies

00:09:51,720 --> 00:09:56,800
and it's very large and our goal is

00:09:54,940 --> 00:09:58,770
really to follow that matrix in we need

00:09:56,800 --> 00:10:01,750
to predict for those missing entries

00:09:58,770 --> 00:10:04,720
what are going to be the highest ranked

00:10:01,750 --> 00:10:07,150
in terms of preference so one of the

00:10:04,720 --> 00:10:09,880
core earlier models is item 2 item

00:10:07,150 --> 00:10:12,310
co-occurrence and effectively we take

00:10:09,880 --> 00:10:14,050
that big matrix and we multiply by the

00:10:12,310 --> 00:10:16,750
transpose of the Med of the same matrix

00:10:14,050 --> 00:10:19,470
and we get a coherence matrix and each

00:10:16,750 --> 00:10:21,820
entry specifies that that a

00:10:19,470 --> 00:10:23,650
co-occurrence happen between the item

00:10:21,820 --> 00:10:26,470
and the other atom so in other words

00:10:23,650 --> 00:10:30,880
they were they were interacted with by

00:10:26,470 --> 00:10:32,260
the same user so this is a this is

00:10:30,880 --> 00:10:34,240
typically done in a pre-computation

00:10:32,260 --> 00:10:36,880
fashion so we'd like to pre-compute that

00:10:34,240 --> 00:10:39,010
entire big matrix offline and then when

00:10:36,880 --> 00:10:41,560
scoring we can either compute the item

00:10:39,010 --> 00:10:44,230
so add some similarity on-the-fly or we

00:10:41,560 --> 00:10:48,250
can again represent the user as a kind

00:10:44,230 --> 00:10:50,500
of combination of their previous items

00:10:48,250 --> 00:10:52,150
that they've interacted with and that is

00:10:50,500 --> 00:10:54,970
effectively a dummy item and then we can

00:10:52,150 --> 00:11:00,790
use that to to get these similar items

00:10:54,970 --> 00:11:03,940
and make a recommendation another way of

00:11:00,790 --> 00:11:05,230
doing this is to try to factorize that

00:11:03,940 --> 00:11:08,740
matrix so we use a matrix factorization

00:11:05,230 --> 00:11:10,360
technique and this is really about using

00:11:08,740 --> 00:11:13,360
a model-based approach to actually try

00:11:10,360 --> 00:11:15,520
to complete that matrix so one typical

00:11:13,360 --> 00:11:16,300
approach is to split it into two smaller

00:11:15,520 --> 00:11:17,740
much smaller

00:11:16,300 --> 00:11:19,810
Oh cease and try and minimize the

00:11:17,740 --> 00:11:21,720
reconstruction error so we want to when

00:11:19,810 --> 00:11:25,210
we multiply those two matrices together

00:11:21,720 --> 00:11:28,780
get the best estimate of that original

00:11:25,210 --> 00:11:31,570
matrix and this is nice because it works

00:11:28,780 --> 00:11:33,220
really well in practice there's really

00:11:31,570 --> 00:11:35,050
efficient and scalable algorithms for it

00:11:33,220 --> 00:11:37,240
it's one of the best performing single

00:11:35,050 --> 00:11:39,730
models that that are typically in use

00:11:37,240 --> 00:11:41,740
and prediction is really simple you just

00:11:39,730 --> 00:11:43,840
simply take for a user recommendation

00:11:41,740 --> 00:11:45,670
that use a vector and we do a dot

00:11:43,840 --> 00:11:47,830
product between all the item vectors and

00:11:45,670 --> 00:11:49,510
similarly for height some similarity we

00:11:47,830 --> 00:11:51,580
just take the item vector and we compute

00:11:49,510 --> 00:11:53,920
a similarity metric cosine similarity or

00:11:51,580 --> 00:11:55,330
something like that and it can handle

00:11:53,920 --> 00:11:57,340
this implicit data that we mentioned

00:11:55,330 --> 00:12:00,790
before by weighting so there's a form of

00:11:57,340 --> 00:12:02,470
this model where those ratings are

00:12:00,790 --> 00:12:04,450
treated the ratings are treated as

00:12:02,470 --> 00:12:06,340
weights of a binary kind of indicator

00:12:04,450 --> 00:12:07,660
matrix and by applying the weighting

00:12:06,340 --> 00:12:09,130
scheme I mentioned earlier you can just

00:12:07,660 --> 00:12:14,350
use the same model and you get pretty

00:12:09,130 --> 00:12:16,300
good results so we've seen that scoring

00:12:14,350 --> 00:12:18,430
and recommendation engines is ranking

00:12:16,300 --> 00:12:21,220
given a user in a context we ranked

00:12:18,430 --> 00:12:27,880
available items in order of the chance

00:12:21,220 --> 00:12:29,500
that a user will interact with them and

00:12:27,880 --> 00:12:32,860
this looks really similar to a search

00:12:29,500 --> 00:12:35,080
engine so given a query we compute some

00:12:32,860 --> 00:12:37,060
similarity over our entire document set

00:12:35,080 --> 00:12:39,910
and we sort the items based on that

00:12:37,060 --> 00:12:44,260
similarity score and we return a ranked

00:12:39,910 --> 00:12:47,140
list so this really makes the question

00:12:44,260 --> 00:12:48,910
can we use a search engine to serve our

00:12:47,140 --> 00:12:52,140
recommendations because they look like

00:12:48,910 --> 00:12:54,820
they're doing pretty much the same thing

00:12:52,140 --> 00:12:58,990
well at a high level does a search

00:12:54,820 --> 00:13:01,120
engine meet our requirements well it's

00:12:58,990 --> 00:13:03,490
custom-made and specifically designed to

00:13:01,120 --> 00:13:07,180
rank large sets of items so we're good

00:13:03,490 --> 00:13:10,390
there filtering is core to search engine

00:13:07,180 --> 00:13:13,500
so that looks good can we use all their

00:13:10,390 --> 00:13:15,610
debt prediction time well it depends

00:13:13,500 --> 00:13:17,890
scalability with that height subsets and

00:13:15,610 --> 00:13:19,360
feature set is baked into the search

00:13:17,890 --> 00:13:21,340
engine and most of them have high bay

00:13:19,360 --> 00:13:25,390
high availability elastic scaling these

00:13:21,340 --> 00:13:28,270
days can handle cold start well again it

00:13:25,390 --> 00:13:29,590
depends can you easily incorporate new

00:13:28,270 --> 00:13:32,310
preference data

00:13:29,590 --> 00:13:35,290
depends so what does it depend on well

00:13:32,310 --> 00:13:38,020
firstly the the serving and scalability

00:13:35,290 --> 00:13:41,350
it depends on you using the inverted

00:13:38,020 --> 00:13:43,690
index so the search engine yeah that's

00:13:41,350 --> 00:13:46,810
the real Corvette and the way that it

00:13:43,690 --> 00:13:49,990
can scale and handle queries really fast

00:13:46,810 --> 00:13:53,980
so we need to massage our problem to fit

00:13:49,990 --> 00:13:56,530
into that in that model and for the it

00:13:53,980 --> 00:13:59,290
depends components that really is model

00:13:56,530 --> 00:14:00,610
dependent so whether you can use all the

00:13:59,290 --> 00:14:02,620
data prediction time depends on what

00:14:00,610 --> 00:14:04,030
model you're using the model itself and

00:14:02,620 --> 00:14:06,700
the computation itself needs to do that

00:14:04,030 --> 00:14:08,590
and whether you can handle cold start

00:14:06,700 --> 00:14:11,290
and incorporate new data again depends

00:14:08,590 --> 00:14:14,080
on the model but as long as the model

00:14:11,290 --> 00:14:15,820
supports it there should be in theory a

00:14:14,080 --> 00:14:17,590
way to incorporate it into the search

00:14:15,820 --> 00:14:22,420
engine in particular though the cold

00:14:17,590 --> 00:14:25,270
start fall backs for content-based okay

00:14:22,420 --> 00:14:27,190
so this seems like a good idea we've got

00:14:25,270 --> 00:14:29,140
a search engine that looks like it does

00:14:27,190 --> 00:14:30,280
the same thing as a recommender and we

00:14:29,140 --> 00:14:32,920
should be able to use the same machinery

00:14:30,280 --> 00:14:35,080
so how do we do that well there many

00:14:32,920 --> 00:14:37,780
more approaches but I I sort of see

00:14:35,080 --> 00:14:40,450
three main approaches score then search

00:14:37,780 --> 00:14:43,930
native search and custom ranking and

00:14:40,450 --> 00:14:46,750
we'll go through each of them so school

00:14:43,930 --> 00:14:48,760
then search is the least integrated

00:14:46,750 --> 00:14:52,330
approach and indeed it's actually based

00:14:48,760 --> 00:14:55,810
on as it says scoring and then searching

00:14:52,330 --> 00:14:58,330
so it's two systems and you typically

00:14:55,810 --> 00:15:00,760
either use a scoring system to complete

00:14:58,330 --> 00:15:02,980
the row recommendations first and then

00:15:00,760 --> 00:15:04,510
use the search engine to falter to get

00:15:02,980 --> 00:15:06,490
the results or you can flip it around

00:15:04,510 --> 00:15:09,490
and then your first fault of the results

00:15:06,490 --> 00:15:10,810
or the candidate items at least feed

00:15:09,490 --> 00:15:13,930
them into the scoring system and then

00:15:10,810 --> 00:15:16,270
compute your scores so in most search

00:15:13,930 --> 00:15:17,650
engines you once you've got from the

00:15:16,270 --> 00:15:19,480
scoring system at the top there once

00:15:17,650 --> 00:15:21,190
you've got the IDS you can pass those

00:15:19,480 --> 00:15:23,380
IDs as one of the filters into your

00:15:21,190 --> 00:15:27,940
search engine and you get your results

00:15:23,380 --> 00:15:29,890
it and likewise at the bottom your the

00:15:27,940 --> 00:15:33,190
search engine can spit out a set of IDs

00:15:29,890 --> 00:15:36,090
that that satisfy your filters and then

00:15:33,190 --> 00:15:37,930
you can use that to to only score the

00:15:36,090 --> 00:15:40,290
relevant documents in your scoring

00:15:37,930 --> 00:15:40,290
system

00:15:40,800 --> 00:15:47,380
so what are the trade-offs eeeh

00:15:44,970 --> 00:15:49,030
the first advantage is that you have

00:15:47,380 --> 00:15:50,920
complete flexibility in the model that

00:15:49,030 --> 00:15:53,500
you can score so having a dedicated

00:15:50,920 --> 00:15:56,470
scoring system means you can potentially

00:15:53,500 --> 00:15:58,690
use very rich contextual models feature

00:15:56,470 --> 00:16:00,850
models maybe deep learning models for

00:15:58,690 --> 00:16:02,620
extracting that rich content and you can

00:16:00,850 --> 00:16:04,990
really focus on optimizing at score and

00:16:02,620 --> 00:16:07,180
component and get it as as fast as

00:16:04,990 --> 00:16:08,470
possible the downside and one of the

00:16:07,180 --> 00:16:11,170
major ones in my view is that you have

00:16:08,470 --> 00:16:12,760
to maintain at least in two systems so

00:16:11,170 --> 00:16:14,280
in some cases this may be unavoidable if

00:16:12,760 --> 00:16:17,280
you want to use a particular model but

00:16:14,280 --> 00:16:20,770
maintaining your each additional system

00:16:17,280 --> 00:16:23,890
requires a lot of overhead DevOps and a

00:16:20,770 --> 00:16:24,970
lot of more things that can go wrong but

00:16:23,890 --> 00:16:27,610
then you've also got this filtering

00:16:24,970 --> 00:16:29,710
challenge and that chapter says that

00:16:27,610 --> 00:16:31,360
let's say you want you you're scoring

00:16:29,710 --> 00:16:33,730
and then you're searching that scoring

00:16:31,360 --> 00:16:36,160
system has to spit out a set of

00:16:33,730 --> 00:16:40,570
candidate IDs that you are then post

00:16:36,160 --> 00:16:43,150
faulted and if you don't complete enough

00:16:40,570 --> 00:16:45,250
candidates then you might end up in a

00:16:43,150 --> 00:16:47,320
case where you don't get enough

00:16:45,250 --> 00:16:49,540
recommendations because after applying

00:16:47,320 --> 00:16:50,500
your metadata filtering categories and

00:16:49,540 --> 00:16:52,270
so on

00:16:50,500 --> 00:16:54,940
you might you might actually not not

00:16:52,270 --> 00:16:57,550
have a result set so it's it's a

00:16:54,940 --> 00:16:59,080
difficult balance to strike how many row

00:16:57,550 --> 00:17:00,790
recommendations do you compute in the

00:16:59,080 --> 00:17:04,420
scoring stage to pass into the filtering

00:17:00,790 --> 00:17:05,770
stage so in some cases that might you

00:17:04,420 --> 00:17:09,550
know it might make sense to filter first

00:17:05,770 --> 00:17:10,860
and then score but but you might you

00:17:09,550 --> 00:17:13,570
might have similar challenges there and

00:17:10,860 --> 00:17:16,630
and then adding that round trip between

00:17:13,570 --> 00:17:19,300
systems actually means that your overall

00:17:16,630 --> 00:17:21,040
system performance can be a lot of a lot

00:17:19,300 --> 00:17:23,949
slower than you think so the scoring in

00:17:21,040 --> 00:17:25,510
peace can be really fast but I've been

00:17:23,949 --> 00:17:30,060
adding the search and the filtering and

00:17:25,510 --> 00:17:32,920
round trips between them can kill that

00:17:30,060 --> 00:17:34,120
so the second option is okay let's let's

00:17:32,920 --> 00:17:35,770
move all the way to the other end of the

00:17:34,120 --> 00:17:38,140
spectrum and have a completely

00:17:35,770 --> 00:17:41,100
integrated system so this is what I term

00:17:38,140 --> 00:17:43,390
native search this is where we want to

00:17:41,100 --> 00:17:45,580
effectively take that model and put it

00:17:43,390 --> 00:17:48,370
in a format that the search engine can

00:17:45,580 --> 00:17:50,560
just use without any modification and

00:17:48,370 --> 00:17:52,240
typically enough pretty much in all

00:17:50,560 --> 00:17:54,309
cases this requires pre-computation

00:17:52,240 --> 00:17:56,919
so you want to pre-compute that model

00:17:54,309 --> 00:17:59,470
crunch all the numbers and you know

00:17:56,919 --> 00:18:02,470
throw your massive big data cluster edit

00:17:59,470 --> 00:18:06,970
and then index those results in a way

00:18:02,470 --> 00:18:09,490
that makes search faster so broadly

00:18:06,970 --> 00:18:11,529
speaking one of the the main approaches

00:18:09,490 --> 00:18:13,809
to this is to use the co-occurrence

00:18:11,529 --> 00:18:15,850
matrix approach so you take that

00:18:13,809 --> 00:18:18,899
pre-computed co-occurrence matrix that

00:18:15,850 --> 00:18:21,789
you did offline and your index it and

00:18:18,899 --> 00:18:23,799
effectively what you need index is for

00:18:21,789 --> 00:18:26,590
each item you need to index the most

00:18:23,799 --> 00:18:29,710
similar items to that so this means

00:18:26,590 --> 00:18:31,480
actually for each item doing the full

00:18:29,710 --> 00:18:34,149
pre-computation of one of the most

00:18:31,480 --> 00:18:35,590
similar items now if you're thinking

00:18:34,149 --> 00:18:37,440
that this is a lot of work it is a lot

00:18:35,590 --> 00:18:39,809
of work so doing a brute-force

00:18:37,440 --> 00:18:43,149
pre-computation approach of this nature

00:18:39,809 --> 00:18:45,429
scales very very badly or flight' even

00:18:43,149 --> 00:18:47,289
so it reaches a point where you need to

00:18:45,429 --> 00:18:48,880
do something smart and that's something

00:18:47,289 --> 00:18:52,240
smart is typically some form of Thresh

00:18:48,880 --> 00:18:55,390
holding so you can either threshold

00:18:52,240 --> 00:18:56,950
based on a score as you go but there's

00:18:55,390 --> 00:18:59,169
some smart ways to do that in a

00:18:56,950 --> 00:19:02,500
principled way using the log likelihood

00:18:59,169 --> 00:19:04,809
ratio and this is a I mentioned the

00:19:02,500 --> 00:19:05,770
links later but this is done in in some

00:19:04,809 --> 00:19:09,460
other literature and some of the

00:19:05,770 --> 00:19:10,809
projects out there on github but the

00:19:09,460 --> 00:19:14,200
core idea is once you've indexed it in

00:19:10,809 --> 00:19:17,020
that form then search just becomes a

00:19:14,200 --> 00:19:18,909
standard search query so if you're if

00:19:17,020 --> 00:19:21,070
you either represent if you represent

00:19:18,909 --> 00:19:23,740
the user as the items that they've

00:19:21,070 --> 00:19:26,039
previously interacted with then you just

00:19:23,740 --> 00:19:30,850
issue those item IDs as the query string

00:19:26,039 --> 00:19:33,070
and you get back the results so because

00:19:30,850 --> 00:19:34,809
you've done a lot of work up front and

00:19:33,070 --> 00:19:36,610
you pre computed everything and you've

00:19:34,809 --> 00:19:37,809
indexed it in the correct way you can

00:19:36,610 --> 00:19:41,020
just drop it straight into your search

00:19:37,809 --> 00:19:44,289
engine and it does exactly what you what

00:19:41,020 --> 00:19:46,450
you need so the great thing there is

00:19:44,289 --> 00:19:48,580
that it's one system and you don't have

00:19:46,450 --> 00:19:51,070
to change the search engine at all you

00:19:48,580 --> 00:19:54,520
do all the work offline query time it's

00:19:51,070 --> 00:19:56,860
really really fast so you know 20

00:19:54,520 --> 00:19:58,590
milliseconds 50 milliseconds and because

00:19:56,860 --> 00:20:01,299
it fits exactly into the search mold

00:19:58,590 --> 00:20:04,240
it'll it'll tin it'll and you threshold

00:20:01,299 --> 00:20:05,510
it right this is important it scales

00:20:04,240 --> 00:20:07,100
really well

00:20:05,510 --> 00:20:09,200
even as the item set and that kind of

00:20:07,100 --> 00:20:10,850
features hid that you're using scales up

00:20:09,200 --> 00:20:14,240
this thus approach will still remain

00:20:10,850 --> 00:20:15,740
really fast and depending on what model

00:20:14,240 --> 00:20:18,440
or what approach you use you can use

00:20:15,740 --> 00:20:20,150
almost all your your data so the

00:20:18,440 --> 00:20:23,360
particular model that I referred to you

00:20:20,150 --> 00:20:26,240
later in the link is a cross

00:20:23,360 --> 00:20:28,309
co-occurrence model so that completes

00:20:26,240 --> 00:20:29,900
just not just let's say on purchases but

00:20:28,309 --> 00:20:33,260
on the cross co-occurrence between

00:20:29,900 --> 00:20:34,910
purchases and pageviews between content

00:20:33,260 --> 00:20:38,090
tags and pageviews between any kind of

00:20:34,910 --> 00:20:39,679
item metadata and use a preference later

00:20:38,090 --> 00:20:41,270
that you can think of you can correlate

00:20:39,679 --> 00:20:43,549
it back to what you care about which is

00:20:41,270 --> 00:20:47,540
ultimately let's say a purchase or you

00:20:43,549 --> 00:20:49,880
know or a play or a stream so that's

00:20:47,540 --> 00:20:51,169
great and that query time you can you

00:20:49,880 --> 00:20:52,340
can construct these multiple queries

00:20:51,169 --> 00:20:55,070
that take into account each of those

00:20:52,340 --> 00:20:57,559
those components but you really have to

00:20:55,070 --> 00:21:01,010
decide what to compute upfront so you

00:20:57,559 --> 00:21:04,640
have to make that decision yeah as a as

00:21:01,010 --> 00:21:07,309
a modeler and of course the more me the

00:21:04,640 --> 00:21:09,230
more you do and the more data you put in

00:21:07,309 --> 00:21:11,960
the more complex that computation is

00:21:09,230 --> 00:21:14,960
going to be one of the key things here

00:21:11,960 --> 00:21:20,650
is that is no ordering retained in the

00:21:14,960 --> 00:21:20,650
index terms so in the raw computation

00:21:21,220 --> 00:21:26,059
using a threshold approach or log

00:21:24,200 --> 00:21:29,780
likelihood ratio you these these ones

00:21:26,059 --> 00:21:31,790
are actually scores and that score has a

00:21:29,780 --> 00:21:35,690
an interpretation that that the higher

00:21:31,790 --> 00:21:38,390
it is the more kind of interesting that

00:21:35,690 --> 00:21:39,919
co-occurrences and and you don't really

00:21:38,390 --> 00:21:45,169
retain that when you index it in this

00:21:39,919 --> 00:21:49,690
way so it's very difficult to to really

00:21:45,169 --> 00:21:52,340
keep that that concept of ordering going

00:21:49,690 --> 00:21:53,870
and then finally there's it's a lot more

00:21:52,340 --> 00:21:56,660
difficult to include the rich content

00:21:53,870 --> 00:21:58,820
data so textual data you can include by

00:21:56,660 --> 00:22:01,970
using a kind of bag of words and similar

00:21:58,820 --> 00:22:03,590
approaches but if you want to use images

00:22:01,970 --> 00:22:05,179
audio for example it's difficult to

00:22:03,590 --> 00:22:07,040
extract that those features in a way

00:22:05,179 --> 00:22:10,610
that you can apply it in in this

00:22:07,040 --> 00:22:12,290
approach so this is implemented in the

00:22:10,610 --> 00:22:16,340
Universal recommender and the mahute

00:22:12,290 --> 00:22:17,690
correlated cross occurrence algorithm so

00:22:16,340 --> 00:22:19,669
if you want to know more those are the

00:22:17,690 --> 00:22:23,309
places to go

00:22:19,669 --> 00:22:25,429
okay the third side of the coin is one

00:22:23,309 --> 00:22:29,700
that I've done quite a bit of work on

00:22:25,429 --> 00:22:31,019
and this is the custom ranking so the

00:22:29,700 --> 00:22:33,320
key here is that we want to combine the

00:22:31,019 --> 00:22:35,639
scoring system and the search engine

00:22:33,320 --> 00:22:37,169
into one system and we want to do

00:22:35,639 --> 00:22:38,960
scoring and filtering at the same time

00:22:37,169 --> 00:22:40,740
online so in real time

00:22:38,960 --> 00:22:46,249
so typically we were not going to

00:22:40,740 --> 00:22:48,419
pre-compute here so how does this work

00:22:46,249 --> 00:22:50,249
well as we've seen before the search

00:22:48,419 --> 00:22:53,249
engine and I recommend I look fairly

00:22:50,249 --> 00:22:55,980
similar your search ranking works more

00:22:53,249 --> 00:22:57,779
or less like this we take a query we

00:22:55,980 --> 00:23:00,210
extract that query into a term vector

00:22:57,779 --> 00:23:01,980
that represents the search terms and

00:23:00,210 --> 00:23:03,929
then we are scoring phase is computing

00:23:01,980 --> 00:23:06,809
the similarity typically some form of

00:23:03,929 --> 00:23:08,659
cosine similarity between that query

00:23:06,809 --> 00:23:11,009
vector and each one of our documents and

00:23:08,659 --> 00:23:14,009
obviously the documents that that fits a

00:23:11,009 --> 00:23:18,389
filter and then we sorting is pretty

00:23:14,009 --> 00:23:19,919
trivial which we sort and we rank so can

00:23:18,389 --> 00:23:26,159
we use the same machinery exactly this

00:23:19,919 --> 00:23:27,600
machinery for recommendations well at

00:23:26,159 --> 00:23:29,999
the analysis phase we just give it a

00:23:27,600 --> 00:23:31,860
user and typically that's a user item

00:23:29,999 --> 00:23:34,649
vector so that doesn't really work in

00:23:31,860 --> 00:23:36,749
the built-in mechanism the term vectors

00:23:34,649 --> 00:23:40,139
are not the same term vectors as we have

00:23:36,749 --> 00:23:43,470
in the typical search query so they're

00:23:40,139 --> 00:23:45,210
kind of just raw double arrays and

00:23:43,470 --> 00:23:49,019
they're not these kind of binary term

00:23:45,210 --> 00:23:52,230
vectors the scoring is again not the

00:23:49,019 --> 00:23:55,129
same but the core of it is that we want

00:23:52,230 --> 00:23:57,059
to compute some some similarity or

00:23:55,129 --> 00:23:59,129
custom metric against each of those

00:23:57,059 --> 00:24:00,779
documents and then once you've got that

00:23:59,129 --> 00:24:05,820
well the ranking part is exactly the

00:24:00,779 --> 00:24:09,019
same so how can we bend the search

00:24:05,820 --> 00:24:11,070
engine to fit our to fit our well I

00:24:09,019 --> 00:24:13,080
should just point out I'm illustrating

00:24:11,070 --> 00:24:13,980
this with elasticsearch because that's

00:24:13,080 --> 00:24:17,279
what I've worked with but it's not

00:24:13,980 --> 00:24:20,369
limited to that so the first is that we

00:24:17,279 --> 00:24:22,559
want to tackle this analyzer step so we

00:24:20,369 --> 00:24:24,299
start with a row vector and we can use a

00:24:22,559 --> 00:24:25,950
custom analyzer to represent that in a

00:24:24,299 --> 00:24:27,960
way which is going to make our lives

00:24:25,950 --> 00:24:31,200
easier later and this is a delimited

00:24:27,960 --> 00:24:32,170
payload filter so this is a something

00:24:31,200 --> 00:24:34,060
that's not

00:24:32,170 --> 00:24:36,520
really that commonly used but

00:24:34,060 --> 00:24:39,010
effectively it allows you to attach a

00:24:36,520 --> 00:24:41,860
payload and the payload is typically you

00:24:39,010 --> 00:24:47,950
know a double or float number to each

00:24:41,860 --> 00:24:51,400
term so here we actually use the this

00:24:47,950 --> 00:24:53,220
pipe delimited string and the numbers to

00:24:51,400 --> 00:24:55,600
the left of the pipe represent the

00:24:53,220 --> 00:24:57,610
vector indices so those are going to be

00:24:55,600 --> 00:24:59,380
our terms and the numbers to the right

00:24:57,610 --> 00:25:01,360
are are our payloads which are vector

00:24:59,380 --> 00:25:03,580
values so if you look at the way the

00:25:01,360 --> 00:25:06,730
term vector looks here you can see that

00:25:03,580 --> 00:25:09,340
the term is 0 which is the first your

00:25:06,730 --> 00:25:11,890
index and our vector and the payload is

00:25:09,340 --> 00:25:14,010
is a binary version but it's it's this

00:25:11,890 --> 00:25:17,800
float to payload that we care about so

00:25:14,010 --> 00:25:19,810
once you've done that we need to use

00:25:17,800 --> 00:25:21,820
this payload to be something useful and

00:25:19,810 --> 00:25:26,020
here we're going to use a custom

00:25:21,820 --> 00:25:28,330
function score query or nona script so

00:25:26,020 --> 00:25:29,920
we take the the vector which is our

00:25:28,330 --> 00:25:31,900
query let's say our user or our item

00:25:29,920 --> 00:25:35,080
vector and we got to pass it into our

00:25:31,900 --> 00:25:37,000
script and more that's what we do is we

00:25:35,080 --> 00:25:38,710
extract those payloads for each term in

00:25:37,000 --> 00:25:40,240
the index and we iterate over each term

00:25:38,710 --> 00:25:42,220
in that index and we compute the score

00:25:40,240 --> 00:25:45,040
which is just that payload with the

00:25:42,220 --> 00:25:47,230
vector value times the value of the

00:25:45,040 --> 00:25:48,730
query vector at that index so this is

00:25:47,230 --> 00:25:52,830
exactly dot product and if we normalize

00:25:48,730 --> 00:25:52,830
it it becomes exactly cosine similarity

00:25:54,360 --> 00:25:59,250
so now what we've got is a user item

00:25:57,310 --> 00:26:03,250
vector that we can analyze into a form

00:25:59,250 --> 00:26:05,410
that can be fed into search term vectors

00:26:03,250 --> 00:26:07,300
we have a custom scoring function that

00:26:05,410 --> 00:26:09,100
can score each of those query vectors

00:26:07,300 --> 00:26:11,820
against our document set and then

00:26:09,100 --> 00:26:14,470
ranking is pretty much exactly the same

00:26:11,820 --> 00:26:15,460
so we ticked all these boxes and it

00:26:14,470 --> 00:26:18,730
could actually use exactly the same

00:26:15,460 --> 00:26:22,630
machinery to score these matrix

00:26:18,730 --> 00:26:24,070
factorization factor models and what's

00:26:22,630 --> 00:26:28,510
nice here is that we get the search for

00:26:24,070 --> 00:26:30,250
free so the core scoring function is is

00:26:28,510 --> 00:26:32,830
replaced so instead of using the

00:26:30,250 --> 00:26:35,200
built-in search similarity we use this

00:26:32,830 --> 00:26:37,300
as courier dot product or cosine

00:26:35,200 --> 00:26:38,520
similarity but of course we can mix and

00:26:37,300 --> 00:26:41,440
match that there are different ways to

00:26:38,520 --> 00:26:44,440
to blend the the built-in scoring

00:26:41,440 --> 00:26:47,150
functions and the custom one

00:26:44,440 --> 00:26:50,150
we get the filtering for free so all of

00:26:47,150 --> 00:26:52,549
these tags metadata activity data we can

00:26:50,150 --> 00:26:54,650
slice and dice exactly as we please and

00:26:52,549 --> 00:26:57,049
we can issue any arbitrary search query'

00:26:54,650 --> 00:27:00,080
has the the meta query for the scoring

00:26:57,049 --> 00:27:01,910
function so it'll work exactly as a

00:27:00,080 --> 00:27:03,230
normal search query adjust that all

00:27:01,910 --> 00:27:05,270
we're changing is the way that those

00:27:03,230 --> 00:27:08,690
documents are scored so we get you know

00:27:05,270 --> 00:27:10,340
the we get the filtering we get free

00:27:08,690 --> 00:27:15,290
text search we get any of the

00:27:10,340 --> 00:27:19,150
geolocation and date map type of queries

00:27:15,290 --> 00:27:22,010
all of that for free in one system so

00:27:19,150 --> 00:27:25,390
that's the key benefit here is that we

00:27:22,010 --> 00:27:27,110
can combine these systems into one and

00:27:25,390 --> 00:27:28,910
potentially we can incorporate these

00:27:27,110 --> 00:27:32,240
richer models which I've just shown a

00:27:28,910 --> 00:27:34,070
way to represent a kind of simple matrix

00:27:32,240 --> 00:27:36,290
factorization model but if we think more

00:27:34,070 --> 00:27:39,140
generally about your embedding models

00:27:36,290 --> 00:27:41,360
where we can have different in vectors

00:27:39,140 --> 00:27:43,250
that represent the users and the items

00:27:41,360 --> 00:27:46,419
and the contextual data and the content

00:27:43,250 --> 00:27:48,559
data including you know potentially

00:27:46,419 --> 00:27:50,809
extracted features from your deep

00:27:48,559 --> 00:27:53,480
learning model for example for your

00:27:50,809 --> 00:27:55,669
images and audio we can potentially use

00:27:53,480 --> 00:27:59,840
that same representation here to make

00:27:55,669 --> 00:28:04,100
our to make the scoring work so it has

00:27:59,840 --> 00:28:07,220
its limitations because the scales sort

00:28:04,100 --> 00:28:08,840
of okay at the moment so as you make

00:28:07,220 --> 00:28:11,090
those victors longer and bigger and

00:28:08,840 --> 00:28:12,380
bigger higher and higher dimension and

00:28:11,090 --> 00:28:13,520
as you add more and more vectors you're

00:28:12,380 --> 00:28:16,580
adding a significantly to the

00:28:13,520 --> 00:28:19,460
computation that occurs and so it scales

00:28:16,580 --> 00:28:20,450
up to a point but you passed a certain

00:28:19,460 --> 00:28:22,480
point you're not going to be able to

00:28:20,450 --> 00:28:26,809
incorporate all the all of those models

00:28:22,480 --> 00:28:28,370
but really this is combining these two

00:28:26,809 --> 00:28:30,710
approaches these two extremes you know

00:28:28,370 --> 00:28:33,140
the the pure scoring and separating that

00:28:30,710 --> 00:28:34,309
system with the pure in the native

00:28:33,140 --> 00:28:36,169
search and integrating those systems

00:28:34,309 --> 00:28:37,940
completely and you it sort of sits in

00:28:36,169 --> 00:28:39,260
the middle and so you get a bit of the

00:28:37,940 --> 00:28:41,419
best of both worlds but of course you

00:28:39,260 --> 00:28:43,070
get drawbacks with that so it does

00:28:41,419 --> 00:28:44,210
require a custom plugin for your search

00:28:43,070 --> 00:28:45,860
engineer you know if you're running on a

00:28:44,210 --> 00:28:50,030
very managed environments client

00:28:45,860 --> 00:28:52,520
environment that might be a problem so

00:28:50,030 --> 00:28:54,200
this is a this is out there on github as

00:28:52,520 --> 00:28:56,640
the elasticsearch vector scoring plugin

00:28:54,200 --> 00:29:01,740
this is a version for solar which Amish

00:28:56,640 --> 00:29:04,110
later and also a code pattern on IBM

00:29:01,740 --> 00:29:09,360
code IBM's open source developer site

00:29:04,110 --> 00:29:10,470
that you can go and check out okay so a

00:29:09,360 --> 00:29:12,840
little bit about performance and

00:29:10,470 --> 00:29:14,220
comparing some of these approaches so

00:29:12,840 --> 00:29:17,250
this is the custom scoring performance

00:29:14,220 --> 00:29:19,950
and as you can see for for small item

00:29:17,250 --> 00:29:22,470
sets this is brute-force computations or

00:29:19,950 --> 00:29:24,570
scoring all all items with no filtering

00:29:22,470 --> 00:29:26,880
or anything like that for small item

00:29:24,570 --> 00:29:29,610
sets it works pretty well and it's quite

00:29:26,880 --> 00:29:32,190
fast but you can kind of see that in

00:29:29,610 --> 00:29:34,770
particular for large item sets and as we

00:29:32,190 --> 00:29:37,070
scale this vector size it gets slower

00:29:34,770 --> 00:29:37,070
and slower

00:29:37,940 --> 00:29:42,420
likewise you know we can we can try and

00:29:40,350 --> 00:29:44,130
scale especially at the high end we can

00:29:42,420 --> 00:29:48,930
scale this computation by adding shards

00:29:44,130 --> 00:29:50,190
to our cluster so at low low numbers of

00:29:48,930 --> 00:29:53,190
items adding shards doesn't really

00:29:50,190 --> 00:29:54,980
matter nor and actually once you're past

00:29:53,190 --> 00:29:57,330
the certain points it hurts performance

00:29:54,980 --> 00:29:59,190
but for larger items that makes sense

00:29:57,330 --> 00:30:01,340
you're adding adding shards distributes

00:29:59,190 --> 00:30:05,660
a computation across one or more nodes

00:30:01,340 --> 00:30:07,680
or more processes and we get a speed-up

00:30:05,660 --> 00:30:08,970
but you know the number of shards that

00:30:07,680 --> 00:30:11,400
you might apply to this to get that

00:30:08,970 --> 00:30:13,200
speed-up might be a lot larger than you

00:30:11,400 --> 00:30:16,800
would otherwise use for you for that

00:30:13,200 --> 00:30:18,330
particular index so what about comparing

00:30:16,800 --> 00:30:22,920
to the score then search approach well

00:30:18,330 --> 00:30:24,150
in this case for a large item set we we

00:30:22,920 --> 00:30:26,670
can see that they're actually quite

00:30:24,150 --> 00:30:32,310
similar and the score then search

00:30:26,670 --> 00:30:35,250
approach is a little bit worse so the

00:30:32,310 --> 00:30:37,530
scoring piece of that is actually really

00:30:35,250 --> 00:30:39,710
tiny so the peer scoring computation

00:30:37,530 --> 00:30:42,210
which is just you know matrix vector

00:30:39,710 --> 00:30:43,500
operation is really really fast and you

00:30:42,210 --> 00:30:44,280
can make it a little bit faster but it's

00:30:43,500 --> 00:30:46,980
not going to make that much difference

00:30:44,280 --> 00:30:49,040
what really gets you is you're the the

00:30:46,980 --> 00:30:50,940
sorting and the searching

00:30:49,040 --> 00:30:52,290
and that's difficult to get away from

00:30:50,940 --> 00:30:55,890
you know you can improve that a little

00:30:52,290 --> 00:30:58,230
bit with with your with filtering and

00:30:55,890 --> 00:31:03,810
but effectively you're incurring up that

00:30:58,230 --> 00:31:05,550
round-trip that I mentioned earlier so

00:31:03,810 --> 00:31:06,800
one way to scale the scoring of this

00:31:05,550 --> 00:31:09,670
brute force approach is by using

00:31:06,800 --> 00:31:12,940
locality sensitive hashing

00:31:09,670 --> 00:31:14,980
and in this case what that is really

00:31:12,940 --> 00:31:16,330
doing is applying some kind of

00:31:14,980 --> 00:31:19,650
pre-computation

00:31:16,330 --> 00:31:19,650
or thresholded

00:31:20,280 --> 00:31:25,870
to that item set so if we're finding the

00:31:23,230 --> 00:31:28,990
most similar items in a set we are

00:31:25,870 --> 00:31:31,360
effectively using LSH to only search in

00:31:28,990 --> 00:31:33,280
certain buckets to find that item so

00:31:31,360 --> 00:31:35,050
this is kind of this is fairly analogous

00:31:33,280 --> 00:31:36,630
to the pre-computation we did in the

00:31:35,050 --> 00:31:39,850
native search approach for co-occurrence

00:31:36,630 --> 00:31:41,830
we do a an exhaustive computation but

00:31:39,850 --> 00:31:44,770
instead of doing all the the work we

00:31:41,830 --> 00:31:46,540
threshold it in some way and Alice H is

00:31:44,770 --> 00:31:48,310
doing something similar so not too

00:31:46,540 --> 00:31:50,920
surprisingly you know we can cut that

00:31:48,310 --> 00:31:52,410
down to around 50 milliseconds which is

00:31:50,920 --> 00:31:55,720
in the range of the native search

00:31:52,410 --> 00:31:57,640
approach so by applying some pre

00:31:55,720 --> 00:32:00,610
computation we get to a similar

00:31:57,640 --> 00:32:01,890
performance but we also had had some of

00:32:00,610 --> 00:32:04,180
the drawbacks from that approach so

00:32:01,890 --> 00:32:07,000
because we've pre computed in Alice H

00:32:04,180 --> 00:32:09,100
index we only search in certain buckets

00:32:07,000 --> 00:32:11,020
we might be effectively missing some

00:32:09,100 --> 00:32:13,450
potential candidate items and some good

00:32:11,020 --> 00:32:14,920
recommendations so we dramatically cut

00:32:13,450 --> 00:32:23,230
down the work that we need to do at at

00:32:14,920 --> 00:32:25,390
run time but we we lose flexibility okay

00:32:23,230 --> 00:32:26,470
I'm going to very much very briefly

00:32:25,390 --> 00:32:28,510
mention a couple of peer search

00:32:26,470 --> 00:32:30,700
approaches that you can look at we don't

00:32:28,510 --> 00:32:31,960
just in the interest of time so for

00:32:30,700 --> 00:32:34,270
constant similarity you can just use

00:32:31,960 --> 00:32:35,470
Bolton more like this queries which

00:32:34,270 --> 00:32:36,730
works pretty well if you don't have a

00:32:35,470 --> 00:32:39,220
lot of interaction data where's a

00:32:36,730 --> 00:32:40,330
fallback and then something that that's

00:32:39,220 --> 00:32:42,490
quite interesting is to look at

00:32:40,330 --> 00:32:43,720
significant terms queries so again I

00:32:42,490 --> 00:32:45,640
went to I wouldn't spend too much time

00:32:43,720 --> 00:32:47,560
on this and you can come and speak to me

00:32:45,640 --> 00:32:49,900
afterwards if you're interested but you

00:32:47,560 --> 00:32:51,700
can effectively use a two-stage query by

00:32:49,900 --> 00:32:53,710
first getting the set of interactions

00:32:51,700 --> 00:32:54,970
for let's say user and so you can see

00:32:53,710 --> 00:32:57,070
the items that they have interacted with

00:32:54,970 --> 00:32:58,960
in the recent past and then you have a

00:32:57,070 --> 00:33:01,600
second query which is a significant

00:32:58,960 --> 00:33:04,090
terms aggregation which uses that item

00:33:01,600 --> 00:33:05,320
set as the background set and the model

00:33:04,090 --> 00:33:07,870
that is built into that will will

00:33:05,320 --> 00:33:09,280
naturally surface the interesting

00:33:07,870 --> 00:33:12,340
co-occurrences so it's a slightly

00:33:09,280 --> 00:33:14,800
different algorithm an algorithmic

00:33:12,340 --> 00:33:17,800
approach to a cur occurrence time

00:33:14,800 --> 00:33:19,450
problem but you get very similar results

00:33:17,800 --> 00:33:20,980
and what's nice there is that there's no

00:33:19,450 --> 00:33:22,230
pre computation involved you do it all

00:33:20,980 --> 00:33:24,780
at runtime

00:33:22,230 --> 00:33:25,770
so that maybe a bit slower than the

00:33:24,780 --> 00:33:30,450
other approaches but it's definitely

00:33:25,770 --> 00:33:32,790
worth looking at okay so just to

00:33:30,450 --> 00:33:34,559
conclude as I mentioned for the custom

00:33:32,790 --> 00:33:36,600
ranking approaches there's a solar

00:33:34,559 --> 00:33:38,220
version I actually came across today

00:33:36,600 --> 00:33:39,870
this is an improved performance version

00:33:38,220 --> 00:33:42,090
of the plug-in that I wrote for

00:33:39,870 --> 00:33:43,410
elasticsearch so it'll be really

00:33:42,090 --> 00:33:46,830
interesting to see what the impact is

00:33:43,410 --> 00:33:48,059
there I mean they claim a you're up to a

00:33:46,830 --> 00:33:49,650
kind of ten times performance

00:33:48,059 --> 00:33:51,570
improvement so that makes those numbers

00:33:49,650 --> 00:33:56,550
that I showed before significantly

00:33:51,570 --> 00:33:58,530
better and you know I'd like to dig

00:33:56,550 --> 00:34:00,809
deeper into the Racine internals to see

00:33:58,530 --> 00:34:03,390
if we can get the benefits of doing kind

00:34:00,809 --> 00:34:05,790
of bad matrix vector math as well as the

00:34:03,390 --> 00:34:09,600
the custom scoring it was part of the

00:34:05,790 --> 00:34:13,310
custom scoring to get speed ups so in

00:34:09,600 --> 00:34:16,139
summary we have this sort of spectrum of

00:34:13,310 --> 00:34:18,179
flex maximum model flexibility three to

00:34:16,139 --> 00:34:19,230
maximum search integration score then

00:34:18,179 --> 00:34:20,790
search sits on the one end of the

00:34:19,230 --> 00:34:22,740
spectrum native search sits on the other

00:34:20,790 --> 00:34:25,169
custom ranking is kind of in the middle

00:34:22,740 --> 00:34:27,990
so they all have different trade-offs

00:34:25,169 --> 00:34:29,669
and cost the benefits but these are the

00:34:27,990 --> 00:34:31,740
three approaches and you know it's

00:34:29,669 --> 00:34:35,429
obviously up to you to pick the one that

00:34:31,740 --> 00:34:39,389
suits your model and your your

00:34:35,429 --> 00:34:42,450
architecture okay so thanks very much

00:34:39,389 --> 00:34:43,619
for your time I'd encourage you to go

00:34:42,450 --> 00:34:46,440
and check out co.org

00:34:43,619 --> 00:34:48,750
as well as the the IBM code patterns and

00:34:46,440 --> 00:34:51,060
IBM cloud signup links if you want to

00:34:48,750 --> 00:34:52,830
know more and I'll just say I just want

00:34:51,060 --> 00:34:55,260
to briefly mention that IBM issued a

00:34:52,830 --> 00:34:57,990
call for code which is a global

00:34:55,260 --> 00:35:00,869
initiative to create open source

00:34:57,990 --> 00:35:04,080
disaster mitigation solutions and

00:35:00,869 --> 00:35:05,700
there's a $200,000 grand prize which is

00:35:04,080 --> 00:35:08,100
which is really interesting so please go

00:35:05,700 --> 00:35:10,020
and check it out and I have six t-shirts

00:35:08,100 --> 00:35:12,540
for that which which I'm happy to give

00:35:10,020 --> 00:35:14,750
away now unfortunately only medium sized

00:35:12,540 --> 00:35:17,930
but I've got six first-come first-serve

00:35:14,750 --> 00:35:17,930
thanks very much

00:35:22,560 --> 00:35:36,790
so we have five minute question so um

00:35:34,090 --> 00:35:40,870
thank you but and what I didn't get is

00:35:36,790 --> 00:35:42,790
you said that the the third superior

00:35:40,870 --> 00:35:45,580
approach doesn't use any pre-computation

00:35:42,790 --> 00:35:47,620
but as I see it you use some kind of

00:35:45,580 --> 00:35:50,560
metric factors in factorization output

00:35:47,620 --> 00:35:52,740
for this so the vectors you feed into

00:35:50,560 --> 00:35:56,080
the index they come from somewhere right

00:35:52,740 --> 00:35:58,030
correct yeah that's the same so

00:35:56,080 --> 00:36:01,840
computation wise the same amount like an

00:35:58,030 --> 00:36:05,670
item to item co-occurrence matrix it

00:36:01,840 --> 00:36:08,110
probably is similar overall so if you

00:36:05,670 --> 00:36:10,240
the SP computation involved it's true

00:36:08,110 --> 00:36:12,160
sir you've got to train a model I mean

00:36:10,240 --> 00:36:14,130
in all of them not even in the school

00:36:12,160 --> 00:36:18,010
then search approach is pre-computation

00:36:14,130 --> 00:36:19,480
because you need a model first compared

00:36:18,010 --> 00:36:21,400
to the the very smart way of doing

00:36:19,480 --> 00:36:23,200
co-occurrence so with some threshold or

00:36:21,400 --> 00:36:25,000
a lot likelihood ratio probably the

00:36:23,200 --> 00:36:27,010
overall computation is is roughly

00:36:25,000 --> 00:36:30,070
similar but generally a matrix

00:36:27,010 --> 00:36:32,490
factorization via LS or will gradient

00:36:30,070 --> 00:36:35,650
descent on you know is fairly efficient

00:36:32,490 --> 00:36:37,330
and you don't need to then exhaustively

00:36:35,650 --> 00:36:40,300
pre compute all the recommendations so

00:36:37,330 --> 00:36:42,490
that I should be more specific

00:36:40,300 --> 00:36:43,990
the pre-computation is about computing

00:36:42,490 --> 00:36:47,940
the recommendations not necessarily the

00:36:43,990 --> 00:36:47,940
model thank you

00:36:56,089 --> 00:36:59,599
other question

00:37:04,510 --> 00:37:08,000
so thank you okay thank you

00:37:07,040 --> 00:37:11,110
[Applause]

00:37:08,000 --> 00:37:11,110

YouTube URL: https://www.youtube.com/watch?v=7qie8NyXVag


