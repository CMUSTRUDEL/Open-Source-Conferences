Title: Be Lazy and get Good OpenMP Performance
Publication date: 2020-10-06
Playlist: SC20 OpenMP Booth Talks
Description: 
	This presentation, delivered by Ruud van der Pas of Oracle, is part of the OpenMP Booth Talk series created for Supercomputing 2020. 



For the PDF of this talk + PDFs & Videos of the full series (as they are completed), visit us at https://www.openmp.org/events/openmp-sc20/#boothtalks
Captions: 
	00:00:00,160 --> 00:00:03,919
welcome to the openmp se20 booth talk

00:00:03,040 --> 00:00:05,680
series

00:00:03,919 --> 00:00:07,520
my name is ruth van der pass and i work

00:00:05,680 --> 00:00:09,840
at oracle in the oracle linux

00:00:07,520 --> 00:00:12,559
engineering organization

00:00:09,840 --> 00:00:12,880
i am a performance engineer and i look

00:00:12,559 --> 00:00:16,160
at

00:00:12,880 --> 00:00:18,080
application performance but my main

00:00:16,160 --> 00:00:20,560
focus is on tools for performance

00:00:18,080 --> 00:00:22,000
analysis and in this talk i'd like to

00:00:20,560 --> 00:00:23,840
share with you

00:00:22,000 --> 00:00:26,000
my experiences with openmp and

00:00:23,840 --> 00:00:28,080
performance in particular

00:00:26,000 --> 00:00:29,119
i'd like to show you ways how to get

00:00:28,080 --> 00:00:30,960
good performance

00:00:29,119 --> 00:00:33,040
out of your openmp program with a

00:00:30,960 --> 00:00:34,160
minimal effort there's always some

00:00:33,040 --> 00:00:37,520
effort

00:00:34,160 --> 00:00:40,320
needed that's uh there's no escape but

00:00:37,520 --> 00:00:40,879
as i will show the it's really minimal

00:00:40,320 --> 00:00:43,920
and

00:00:40,879 --> 00:00:47,360
the impact can be tremendous so stay

00:00:43,920 --> 00:00:47,360
tuned and let's get started

00:00:47,600 --> 00:00:51,360
there's a common and persistent myth

00:00:49,520 --> 00:00:53,680
that openmp does not scale

00:00:51,360 --> 00:00:57,280
i still hear and see that way too often

00:00:53,680 --> 00:00:59,440
and it's just too simple to be true

00:00:57,280 --> 00:01:01,680
openmp is a programming model a

00:00:59,440 --> 00:01:02,960
programming model in itself can not not

00:01:01,680 --> 00:01:04,960
scale

00:01:02,960 --> 00:01:07,280
think about it it's like when you want

00:01:04,960 --> 00:01:09,439
to cook a dish and you have your recipe

00:01:07,280 --> 00:01:12,080
and your ingredients

00:01:09,439 --> 00:01:14,159
if you mess up on the ingredients then

00:01:12,080 --> 00:01:15,520
your recipe will fail the dish you you

00:01:14,159 --> 00:01:18,560
prepare will probably taste

00:01:15,520 --> 00:01:21,840
horribly and it's the same with openmp

00:01:18,560 --> 00:01:24,799
openmp has ingredients for you

00:01:21,840 --> 00:01:25,520
to create a parallel program you have to

00:01:24,799 --> 00:01:27,520
use the right

00:01:25,520 --> 00:01:28,640
ingredients and you have to use them in

00:01:27,520 --> 00:01:30,560
the right way

00:01:28,640 --> 00:01:32,960
in order to have a successful parallel

00:01:30,560 --> 00:01:32,960
program

00:01:34,479 --> 00:01:38,799
so what cannot not scale what can be in

00:01:37,200 --> 00:01:41,840
the way of your scalability

00:01:38,799 --> 00:01:43,119
are a couple of things it could be the

00:01:41,840 --> 00:01:44,799
tools that you use

00:01:43,119 --> 00:01:46,799
for example the compiler may have a

00:01:44,799 --> 00:01:48,640
performance glitch

00:01:46,799 --> 00:01:50,320
that could be an issue with the library

00:01:48,640 --> 00:01:52,399
that you're using maybe

00:01:50,320 --> 00:01:54,960
you're using an openmp runtime that has

00:01:52,399 --> 00:01:55,759
a feature that's not very well matured

00:01:54,960 --> 00:01:58,079
yet

00:01:55,759 --> 00:01:59,600
and it pulls your leg although not

00:01:58,079 --> 00:02:02,000
likely all these things

00:01:59,600 --> 00:02:03,600
are are possible and should not be

00:02:02,000 --> 00:02:05,759
excluded

00:02:03,600 --> 00:02:07,840
another reason could be at a hardware

00:02:05,759 --> 00:02:09,280
level that there's a mismatch between

00:02:07,840 --> 00:02:11,520
the system that you're using

00:02:09,280 --> 00:02:12,879
and the resource requirements for

00:02:11,520 --> 00:02:15,120
example let's say

00:02:12,879 --> 00:02:17,520
your application is very bandwidth

00:02:15,120 --> 00:02:20,000
hungry you need lots of bandwidth

00:02:17,520 --> 00:02:21,440
as you're adding threads at some point

00:02:20,000 --> 00:02:22,800
maybe the system that you're using

00:02:21,440 --> 00:02:24,319
cannot sustain

00:02:22,800 --> 00:02:26,000
the pressure on the memory system

00:02:24,319 --> 00:02:26,959
anymore cannot deliver the bandwidth

00:02:26,000 --> 00:02:29,120
that you need

00:02:26,959 --> 00:02:30,720
and as a result the scalability will

00:02:29,120 --> 00:02:32,560
suffer and um

00:02:30,720 --> 00:02:34,080
your program will stop scaling and in

00:02:32,560 --> 00:02:36,080
the worst case it'll even

00:02:34,080 --> 00:02:37,440
you the scaling will go down as you add

00:02:36,080 --> 00:02:39,840
threads

00:02:37,440 --> 00:02:40,560
these are all things that can happen

00:02:39,840 --> 00:02:42,800
what i see

00:02:40,560 --> 00:02:44,879
in practice though is the the most

00:02:42,800 --> 00:02:48,480
likely culprit here

00:02:44,879 --> 00:02:51,360
is actually you the user makes a mistake

00:02:48,480 --> 00:02:52,400
violates an openmp performance rule that

00:02:51,360 --> 00:02:55,040
you don't know

00:02:52,400 --> 00:02:55,760
but you violate it and as a as a

00:02:55,040 --> 00:02:59,120
consequence

00:02:55,760 --> 00:03:00,720
the performance will suffer in this talk

00:02:59,120 --> 00:03:02,480
i'd like to give you those rules i'd

00:03:00,720 --> 00:03:04,319
like to give you the rules

00:03:02,480 --> 00:03:08,400
the tips and the tricks how to get good

00:03:04,319 --> 00:03:08,400
performance out of your openmp program

00:03:09,760 --> 00:03:15,040
so we're going to talk about the basics

00:03:13,440 --> 00:03:16,640
and if you follow the guidelines that

00:03:15,040 --> 00:03:19,840
i'm going to give you should expect

00:03:16,640 --> 00:03:21,760
decent performance and an openmp

00:03:19,840 --> 00:03:23,760
compiler and runtime system should do

00:03:21,760 --> 00:03:26,159
the right thing for you

00:03:23,760 --> 00:03:27,440
you may not get blazing scalability to

00:03:26,159 --> 00:03:29,280
thousands of course

00:03:27,440 --> 00:03:31,040
but it definitely gets you going and you

00:03:29,280 --> 00:03:34,239
should expect again

00:03:31,040 --> 00:03:36,159
decent performance certainly if you ever

00:03:34,239 --> 00:03:37,200
have to go to the openmp performance

00:03:36,159 --> 00:03:39,519
court

00:03:37,200 --> 00:03:42,159
the lawyers there will not have any case

00:03:39,519 --> 00:03:42,159
against you

00:03:42,879 --> 00:03:46,480
the ease of use of openmp is a mixed

00:03:44,879 --> 00:03:48,159
blessing it's great

00:03:46,480 --> 00:03:50,959
things just work as you would expect

00:03:48,159 --> 00:03:52,799
them ideas are easy and quick to

00:03:50,959 --> 00:03:54,080
implement and it gets you going very

00:03:52,799 --> 00:03:56,000
quickly

00:03:54,080 --> 00:03:57,840
but some constructs are more expensive

00:03:56,000 --> 00:03:59,120
than others and you may not know that

00:03:57,840 --> 00:04:00,959
but you have to know

00:03:59,120 --> 00:04:02,400
you have to know what is the right sort

00:04:00,959 --> 00:04:06,080
of

00:04:02,400 --> 00:04:08,239
tool that i can use to solve my parallel

00:04:06,080 --> 00:04:10,159
computing problem and if you pick the

00:04:08,239 --> 00:04:13,519
wrong one

00:04:10,159 --> 00:04:15,040
then performance may suffer so

00:04:13,519 --> 00:04:18,000
again that's what i'm going to talk

00:04:15,040 --> 00:04:20,880
about in this in this presentation

00:04:18,000 --> 00:04:22,720
also if you write dumb code you probably

00:04:20,880 --> 00:04:24,960
get done performance

00:04:22,720 --> 00:04:26,720
actually i can make that stronger you

00:04:24,960 --> 00:04:28,960
will get done performance

00:04:26,720 --> 00:04:30,479
the reason is is that openmp is very

00:04:28,960 --> 00:04:32,800
prescriptive

00:04:30,479 --> 00:04:33,840
you tell the openmp compiler what to do

00:04:32,800 --> 00:04:36,960
and it will do so

00:04:33,840 --> 00:04:37,440
it will follow what you tell it to do so

00:04:36,960 --> 00:04:39,759
if you

00:04:37,440 --> 00:04:41,840
have some dumb advice the compiler will

00:04:39,759 --> 00:04:42,560
follow the dumb advice and generate bad

00:04:41,840 --> 00:04:45,199
code

00:04:42,560 --> 00:04:45,919
and for compilers it's very hard to fix

00:04:45,199 --> 00:04:48,080
that

00:04:45,919 --> 00:04:50,639
sometimes it's impossible sometimes the

00:04:48,080 --> 00:04:52,639
tech compiler technology isn't there yet

00:04:50,639 --> 00:04:56,639
to help you fixing things so the

00:04:52,639 --> 00:04:59,199
responsibility is on your shoulders

00:04:56,639 --> 00:05:00,400
in any case don't blow him open and pee

00:04:59,199 --> 00:05:02,080
please

00:05:00,400 --> 00:05:04,160
in the next section i'm going to give

00:05:02,080 --> 00:05:06,800
you tips and tricks how to avoid

00:05:04,160 --> 00:05:07,680
writing dumb code and as you will see

00:05:06,800 --> 00:05:10,320
this will get you

00:05:07,680 --> 00:05:11,759
very very far in achieving efficient

00:05:10,320 --> 00:05:13,680
openmp

00:05:11,759 --> 00:05:16,400
it all starts with single thread

00:05:13,680 --> 00:05:18,320
performance it's often overlooked

00:05:16,400 --> 00:05:20,720
but you really have to pay attention to

00:05:18,320 --> 00:05:23,039
that and the reason is very simple

00:05:20,720 --> 00:05:24,000
what do you think if your code performed

00:05:23,039 --> 00:05:25,520
badly on a single

00:05:24,000 --> 00:05:28,639
chord what do you think will happen with

00:05:25,520 --> 00:05:30,960
10 or 20 or or higher core counts

00:05:28,639 --> 00:05:32,720
my claim is it'll get worse and the

00:05:30,960 --> 00:05:34,800
reason is that very often

00:05:32,720 --> 00:05:36,639
poor performance on a single core means

00:05:34,800 --> 00:05:38,400
poor memory performance you're not using

00:05:36,639 --> 00:05:39,600
the memory system and the caches in the

00:05:38,400 --> 00:05:42,240
right way

00:05:39,600 --> 00:05:44,000
well when you multiply that with 10 say

00:05:42,240 --> 00:05:46,000
so you're running on 10 cores

00:05:44,000 --> 00:05:48,560
that will just get worse you put a lot

00:05:46,000 --> 00:05:51,199
of burden onto your system interconnect

00:05:48,560 --> 00:05:52,800
and your code will stop scaling much

00:05:51,199 --> 00:05:55,600
sooner than

00:05:52,800 --> 00:05:58,720
needed so again don't forget about

00:05:55,600 --> 00:05:58,720
single thread performance

00:05:59,039 --> 00:06:03,680
also remember scalability can mask poor

00:06:02,880 --> 00:06:06,479
performance

00:06:03,680 --> 00:06:07,039
it happens to be that a slow code scales

00:06:06,479 --> 00:06:09,039
better

00:06:07,039 --> 00:06:11,039
the reason is very simple the overhead

00:06:09,039 --> 00:06:12,400
that comes with with parallel computing

00:06:11,039 --> 00:06:14,560
is less dominant

00:06:12,400 --> 00:06:16,240
but at the end of the day although it

00:06:14,560 --> 00:06:18,639
scales better

00:06:16,240 --> 00:06:21,280
that code may still be slower and often

00:06:18,639 --> 00:06:23,759
it is so don't be blinded by scalability

00:06:21,280 --> 00:06:25,360
always look at the time to solution as

00:06:23,759 --> 00:06:27,360
well

00:06:25,360 --> 00:06:28,880
i'm now going to give a set of basic

00:06:27,360 --> 00:06:30,319
rules that applies to

00:06:28,880 --> 00:06:32,080
pretty much everybody in every

00:06:30,319 --> 00:06:34,319
application the first

00:06:32,080 --> 00:06:35,840
golden rule is do not parallelize what

00:06:34,319 --> 00:06:38,479
does not matter

00:06:35,840 --> 00:06:39,919
that seems so so trivial but too often i

00:06:38,479 --> 00:06:41,360
see people parallelize

00:06:39,919 --> 00:06:44,319
parts of their code that really don't

00:06:41,360 --> 00:06:47,199
matter now what you need to do

00:06:44,319 --> 00:06:48,000
is use user profiling tool pick whatever

00:06:47,199 --> 00:06:50,720
you like i don't

00:06:48,000 --> 00:06:51,120
care but let the profiling tool guide

00:06:50,720 --> 00:06:53,520
you

00:06:51,120 --> 00:06:55,520
where you spend most of your time and

00:06:53,520 --> 00:06:57,120
that's where you start parallelizing

00:06:55,520 --> 00:06:58,880
don't parallelize something that does

00:06:57,120 --> 00:07:01,680
not contribute to

00:06:58,880 --> 00:07:03,199
to the total execution time because you

00:07:01,680 --> 00:07:04,160
even run the risk that the parallel

00:07:03,199 --> 00:07:06,800
computing

00:07:04,160 --> 00:07:08,560
introduces overhead that will make that

00:07:06,800 --> 00:07:09,360
part of the code slower because that's

00:07:08,560 --> 00:07:11,919
not enough

00:07:09,360 --> 00:07:14,560
work done to compensate for the overhead

00:07:11,919 --> 00:07:16,400
so always use a profiling tool

00:07:14,560 --> 00:07:19,440
that'll tell you where the time is spent

00:07:16,400 --> 00:07:22,080
and that's where you start parallelizing

00:07:19,440 --> 00:07:23,199
another golden rule is don't share data

00:07:22,080 --> 00:07:25,599
unless you have to

00:07:23,199 --> 00:07:26,960
sharing data is a really great feature

00:07:25,599 --> 00:07:29,280
in openmp

00:07:26,960 --> 00:07:30,160
and it's very convenient but in some

00:07:29,280 --> 00:07:32,479
cases

00:07:30,160 --> 00:07:34,319
there's a cost associated with it a

00:07:32,479 --> 00:07:36,800
performance cost

00:07:34,319 --> 00:07:39,199
and the best advice i can give is use

00:07:36,800 --> 00:07:41,840
private data where possible

00:07:39,199 --> 00:07:42,880
and only share data when you have to

00:07:41,840 --> 00:07:46,000
that simple rule

00:07:42,880 --> 00:07:48,800
already helps in addressing openmp

00:07:46,000 --> 00:07:51,280
performance issues

00:07:48,800 --> 00:07:52,000
another one is that one parallel four is

00:07:51,280 --> 00:07:55,039
fine

00:07:52,000 --> 00:07:56,639
multiple back to back that's evil

00:07:55,039 --> 00:07:59,039
and i'm going to say a little bit more

00:07:56,639 --> 00:08:00,400
about that soon but that's another

00:07:59,039 --> 00:08:02,240
thing that i see in too many

00:08:00,400 --> 00:08:04,400
applications all these parallel for

00:08:02,240 --> 00:08:08,800
loops or do loops in fortran

00:08:04,400 --> 00:08:08,800
back to back that's really a bad idea

00:08:09,120 --> 00:08:13,680
another golden rule is think big and

00:08:12,000 --> 00:08:14,560
maximize the size of the parallel

00:08:13,680 --> 00:08:18,080
regions what do

00:08:14,560 --> 00:08:19,440
i mean with that ideally you have just

00:08:18,080 --> 00:08:21,599
one parallel region

00:08:19,440 --> 00:08:23,120
and all the world the work is

00:08:21,599 --> 00:08:25,199
concentrated in that

00:08:23,120 --> 00:08:27,759
and the reason is because a parallel

00:08:25,199 --> 00:08:30,319
region is relatively expensive

00:08:27,759 --> 00:08:32,880
it also ends with a barrier and a barely

00:08:30,319 --> 00:08:35,360
barrier is potentially very costly

00:08:32,880 --> 00:08:37,120
so you want to minimize those and you do

00:08:35,360 --> 00:08:38,640
that by maximizing the size of the

00:08:37,120 --> 00:08:41,120
parallel region

00:08:38,640 --> 00:08:42,080
try to have as little parallel regions

00:08:41,120 --> 00:08:44,720
as possible

00:08:42,080 --> 00:08:46,800
and put as much work into a parallel

00:08:44,720 --> 00:08:48,880
region as you can

00:08:46,800 --> 00:08:51,440
and here's an example of what i meant

00:08:48,880 --> 00:08:53,760
with those parallel for loops

00:08:51,440 --> 00:08:55,440
let's say you have a bunch of loops and

00:08:53,760 --> 00:08:55,760
they can all be parallelized you will

00:08:55,440 --> 00:08:57,920
get

00:08:55,760 --> 00:08:58,959
the right result when you do that it's

00:08:57,920 --> 00:09:01,200
very tempting to

00:08:58,959 --> 00:09:03,440
use a pragma omp parallel for and

00:09:01,200 --> 00:09:06,000
parallelize each individual loop

00:09:03,440 --> 00:09:08,800
i've seen that in numerous codes and in

00:09:06,000 --> 00:09:11,839
as many numerous codes i fixed it

00:09:08,800 --> 00:09:13,920
because it's a bad idea

00:09:11,839 --> 00:09:15,200
think about the cost associated with the

00:09:13,920 --> 00:09:17,920
parallel region

00:09:15,200 --> 00:09:19,760
well each parallel four is is a parallel

00:09:17,920 --> 00:09:22,080
region so you get that cost

00:09:19,760 --> 00:09:23,600
so each time you you get there you'll

00:09:22,080 --> 00:09:25,680
get that cost

00:09:23,600 --> 00:09:26,640
and what's probably even worse there's

00:09:25,680 --> 00:09:28,399
no potential

00:09:26,640 --> 00:09:29,760
for the no weight clause which is a

00:09:28,399 --> 00:09:32,720
really very powerful

00:09:29,760 --> 00:09:34,560
clause to omit the barrier at the end of

00:09:32,720 --> 00:09:37,120
the construct

00:09:34,560 --> 00:09:38,640
since you cannot have no weight on the

00:09:37,120 --> 00:09:40,959
parallel region

00:09:38,640 --> 00:09:41,839
the parallel 4 is stuck and has all

00:09:40,959 --> 00:09:44,720
those barriers

00:09:41,839 --> 00:09:45,839
a really bad idea this is a much better

00:09:44,720 --> 00:09:48,880
approach

00:09:45,839 --> 00:09:52,080
there's one single parallel region omp

00:09:48,880 --> 00:09:54,000
parallel and inside that parallel region

00:09:52,080 --> 00:09:55,920
you have your pragma on p4 to

00:09:54,000 --> 00:09:59,360
parallelize those loops

00:09:55,920 --> 00:10:00,080
now note that should not be omp parallel

00:09:59,360 --> 00:10:02,000
00:10:00,080 --> 00:10:04,800
inside the parallel region that's nested

00:10:02,000 --> 00:10:06,959
parallelism that's completely

00:10:04,800 --> 00:10:08,959
not needed here and and will have

00:10:06,959 --> 00:10:11,760
disastrous effects on performance

00:10:08,959 --> 00:10:13,519
you just have a simple pragma omp4 so

00:10:11,760 --> 00:10:16,079
you have the parallel on the outside and

00:10:13,519 --> 00:10:18,480
the omp4 on the inside

00:10:16,079 --> 00:10:19,600
it also opens up opportunities for the

00:10:18,480 --> 00:10:22,160
no weight

00:10:19,600 --> 00:10:22,720
as you probably know the no way omits

00:10:22,160 --> 00:10:24,320
the

00:10:22,720 --> 00:10:25,760
implied barrier at the end of a

00:10:24,320 --> 00:10:28,880
construct

00:10:25,760 --> 00:10:32,320
and um sometimes that barrier is not

00:10:28,880 --> 00:10:34,399
not needed barriers are there for safety

00:10:32,320 --> 00:10:35,360
and sometimes you need them but openmp

00:10:34,399 --> 00:10:38,320
by

00:10:35,360 --> 00:10:40,480
by design is a very safe language and it

00:10:38,320 --> 00:10:42,399
inserts a barrier where it may not be

00:10:40,480 --> 00:10:43,760
needed and with the no weight clause you

00:10:42,399 --> 00:10:45,920
can get rid of it

00:10:43,760 --> 00:10:46,880
certainly the one at the very last loop

00:10:45,920 --> 00:10:48,480
is redundant

00:10:46,880 --> 00:10:51,200
because there's a barrier at the end of

00:10:48,480 --> 00:10:54,079
the parallel region anyhow

00:10:51,200 --> 00:10:56,000
now admittedly a smart compiler could do

00:10:54,079 --> 00:10:57,920
that for you but i don't think compiler

00:10:56,000 --> 00:10:59,760
technology has progress to the level

00:10:57,920 --> 00:11:00,320
that it will actually remove that no

00:10:59,760 --> 00:11:03,120
weight

00:11:00,320 --> 00:11:05,040
without that barrier sorry so it's

00:11:03,120 --> 00:11:07,040
better for you to include the no weight

00:11:05,040 --> 00:11:08,720
and at least shave off one barrier but

00:11:07,040 --> 00:11:10,640
maybe even more

00:11:08,720 --> 00:11:12,480
again you get a cost only once and

00:11:10,640 --> 00:11:14,959
there's more opportunities to

00:11:12,480 --> 00:11:16,720
use the no weight clause it performs

00:11:14,959 --> 00:11:19,279
much better and you'll be surprised how

00:11:16,720 --> 00:11:19,279
much better

00:11:20,079 --> 00:11:26,000
a little bit more about parallel regions

00:11:23,279 --> 00:11:27,839
as i already said several times a

00:11:26,000 --> 00:11:30,079
parallel region carries a relatively

00:11:27,839 --> 00:11:31,920
high overhead

00:11:30,079 --> 00:11:33,519
and the goal is to minimize the number

00:11:31,920 --> 00:11:36,959
of times a parallel region

00:11:33,519 --> 00:11:39,440
is encountered why do i say that

00:11:36,959 --> 00:11:40,800
i see too many nested loops where deep

00:11:39,440 --> 00:11:42,640
inside the loop nest

00:11:40,800 --> 00:11:44,959
you'll find a parallel region maybe a

00:11:42,640 --> 00:11:46,399
parallel 4 or parallel do in case of

00:11:44,959 --> 00:11:48,240
fortran

00:11:46,399 --> 00:11:50,160
well that's a really bad idea because

00:11:48,240 --> 00:11:50,480
that parallel region the overhead with

00:11:50,160 --> 00:11:52,880
that

00:11:50,480 --> 00:11:54,320
and the barrier i executed each time you

00:11:52,880 --> 00:11:57,200
go through the outer loops

00:11:54,320 --> 00:11:58,480
and that could be many many times one

00:11:57,200 --> 00:12:01,120
sort of classical trick

00:11:58,480 --> 00:12:02,399
is to push that parallel region outward

00:12:01,120 --> 00:12:04,800
and embed the whole

00:12:02,399 --> 00:12:06,720
loop nest in a parallel region there are

00:12:04,800 --> 00:12:10,560
examples out there

00:12:06,720 --> 00:12:14,079
that will show you how to do that

00:12:10,560 --> 00:12:16,000
a little bit more on the basics again

00:12:14,079 --> 00:12:17,519
the no weight clause as simple as it is

00:12:16,000 --> 00:12:19,279
it's extremely powerful

00:12:17,519 --> 00:12:20,880
barriers are expensive you don't want

00:12:19,279 --> 00:12:23,279
them unless you need them

00:12:20,880 --> 00:12:24,399
so identify where you can use the no

00:12:23,279 --> 00:12:25,839
weight clause

00:12:24,399 --> 00:12:27,519
you're probably not going to do that in

00:12:25,839 --> 00:12:29,120
the first first open b

00:12:27,519 --> 00:12:30,639
version of your program but once you

00:12:29,120 --> 00:12:31,519
have it running you have the correct

00:12:30,639 --> 00:12:33,360
results

00:12:31,519 --> 00:12:37,120
try to see if you can use the no weight

00:12:33,360 --> 00:12:37,120
clause and get rid of those barriers

00:12:37,440 --> 00:12:42,079
the one thing you got to watch out is of

00:12:39,920 --> 00:12:44,079
course don't introduce data races so do

00:12:42,079 --> 00:12:44,800
this we care do this one by one and make

00:12:44,079 --> 00:12:46,959
sure you get

00:12:44,800 --> 00:12:50,560
the correct results because it is easy

00:12:46,959 --> 00:12:52,560
to introduce a data race that way

00:12:50,560 --> 00:12:54,800
another powerful feature is the schedule

00:12:52,560 --> 00:12:56,959
clause in case you have low balancing

00:12:54,800 --> 00:12:58,240
issues not all threads perform the same

00:12:56,959 --> 00:13:00,480
amount of work

00:12:58,240 --> 00:13:03,040
the schedule clause with the options

00:13:00,480 --> 00:13:05,279
like dynamic and guided can do magic

00:13:03,040 --> 00:13:06,399
and again you'll be surprised how much

00:13:05,279 --> 00:13:08,639
you can gain by just

00:13:06,399 --> 00:13:10,000
changing the schedule clause on your

00:13:08,639 --> 00:13:13,279
parallel for loop

00:13:10,000 --> 00:13:15,920
so again think about that

00:13:13,279 --> 00:13:16,800
for all these things is use a profiling

00:13:15,920 --> 00:13:18,720
tool

00:13:16,800 --> 00:13:20,959
you have to use a good profiling tool

00:13:18,720 --> 00:13:22,320
and find those opportunities find out

00:13:20,959 --> 00:13:25,519
without a load balancing

00:13:22,320 --> 00:13:28,320
find out where barriers are and and

00:13:25,519 --> 00:13:28,320
and tackle them

00:13:29,279 --> 00:13:33,200
as i've said several times already every

00:13:32,000 --> 00:13:35,519
barrier matters

00:13:33,200 --> 00:13:36,959
you need them they are needed they use

00:13:35,519 --> 00:13:38,880
them with care

00:13:36,959 --> 00:13:41,440
the same is true for locks in critical

00:13:38,880 --> 00:13:43,360
regions critical regions are

00:13:41,440 --> 00:13:45,199
pretty much needed in every parallel

00:13:43,360 --> 00:13:47,040
program but

00:13:45,199 --> 00:13:49,519
depending on what you do in the critical

00:13:47,040 --> 00:13:51,120
region an atomic operation may provide

00:13:49,519 --> 00:13:53,120
the same functionality

00:13:51,120 --> 00:13:55,279
but at a much lower cost atomic

00:13:53,120 --> 00:13:58,160
operations are much more efficient

00:13:55,279 --> 00:14:00,880
than fully fully blown critical regions

00:13:58,160 --> 00:14:03,680
so think about atomic operations as

00:14:00,880 --> 00:14:04,800
a good alternative for example and again

00:14:03,680 --> 00:14:06,720
minimize

00:14:04,800 --> 00:14:10,160
minimize the locking and the critical

00:14:06,720 --> 00:14:10,160
regions as much as you can

00:14:10,399 --> 00:14:14,320
at the end of the day everything matters

00:14:13,279 --> 00:14:17,120
that's

00:14:14,320 --> 00:14:17,680
there is amdahl's law after all so every

00:14:17,120 --> 00:14:20,720
every

00:14:17,680 --> 00:14:23,040
every small overhead gets out of hand

00:14:20,720 --> 00:14:24,800
very quickly and sooner than you like

00:14:23,040 --> 00:14:27,440
and when you think about it

00:14:24,800 --> 00:14:28,000
um amnes law applies here for example a

00:14:27,440 --> 00:14:31,120
critical

00:14:28,000 --> 00:14:32,800
region tends to serialize the operation

00:14:31,120 --> 00:14:33,360
so you have a serial part in your

00:14:32,800 --> 00:14:35,760
program

00:14:33,360 --> 00:14:36,959
well and those law tells us that that

00:14:35,760 --> 00:14:40,959
part dominates

00:14:36,959 --> 00:14:42,959
very quickly so use those contract

00:14:40,959 --> 00:14:45,839
constructs to get the right answers but

00:14:42,959 --> 00:14:45,839
use them with care

00:14:48,399 --> 00:14:51,600
the list i've just given

00:14:51,839 --> 00:14:55,279
gets you going it it's actually

00:14:53,839 --> 00:14:57,920
surprising how

00:14:55,279 --> 00:15:00,000
how much you can gain by following these

00:14:57,920 --> 00:15:02,560
pretty simple guidelines

00:15:00,000 --> 00:15:03,120
but that's what i call the low hanging

00:15:02,560 --> 00:15:06,880
fruit

00:15:03,120 --> 00:15:08,240
it's there and for you to to handle it

00:15:06,880 --> 00:15:10,399
there's some fruit that's actually a

00:15:08,240 --> 00:15:13,279
little bit higher up the tree

00:15:10,399 --> 00:15:15,120
still very very important to tackle and

00:15:13,279 --> 00:15:17,279
it's all about memory access

00:15:15,120 --> 00:15:19,600
so in the second part of this talk i

00:15:17,279 --> 00:15:21,920
will cover that

00:15:19,600 --> 00:15:22,880
the good thing about openmp is that

00:15:21,920 --> 00:15:25,440
memory access

00:15:22,880 --> 00:15:26,560
just happens you need access to a

00:15:25,440 --> 00:15:28,399
variable a

00:15:26,560 --> 00:15:31,199
you'll get it the system will take care

00:15:28,399 --> 00:15:34,000
of it so that's really good

00:15:31,199 --> 00:15:34,320
there are two things to watch out for as

00:15:34,000 --> 00:15:37,759
you

00:15:34,320 --> 00:15:37,759
as you access your data

00:15:37,920 --> 00:15:42,560
they're called non-uniform memory access

00:15:40,079 --> 00:15:43,920
pneuma for short and false sharing and

00:15:42,560 --> 00:15:46,800
i'm going to explain them

00:15:43,920 --> 00:15:47,120
in the next couple of slides before i do

00:15:46,800 --> 00:15:49,759
that

00:15:47,120 --> 00:15:50,720
i want to explain that both have nothing

00:15:49,759 --> 00:15:53,680
to do with

00:15:50,720 --> 00:15:55,120
openmp they're characteristic of using a

00:15:53,680 --> 00:15:57,199
shared memory architecture

00:15:55,120 --> 00:15:59,440
it's it goes back to the way a shared

00:15:57,199 --> 00:16:01,440
memory architecture is built

00:15:59,440 --> 00:16:02,800
and if you would write the same same

00:16:01,440 --> 00:16:06,240
construct in

00:16:02,800 --> 00:16:06,800
piece that say and it you'll suffer from

00:16:06,240 --> 00:16:08,800
pneuma

00:16:06,800 --> 00:16:12,639
and and maybe fall sharing as well so

00:16:08,800 --> 00:16:14,959
again this has nothing to do with openmp

00:16:12,639 --> 00:16:16,480
you're using openimpedo and these are

00:16:14,959 --> 00:16:19,120
real things pneuma is real

00:16:16,480 --> 00:16:21,199
false sharing is real so they may impact

00:16:19,120 --> 00:16:22,000
your openmp performance and i'm going to

00:16:21,199 --> 00:16:24,560
say a little bit more

00:16:22,000 --> 00:16:24,560
about that

00:16:25,920 --> 00:16:32,480
this is a diagram of a generic common

00:16:29,440 --> 00:16:34,240
contemporary pneuma system in other

00:16:32,480 --> 00:16:37,199
words this is what many systems

00:16:34,240 --> 00:16:40,240
look like out on the market today and

00:16:37,199 --> 00:16:42,720
i'm showing you a system with four nodes

00:16:40,240 --> 00:16:44,079
the four nodes what we see the green

00:16:42,720 --> 00:16:46,959
boxes are the cores

00:16:44,079 --> 00:16:47,920
so each node has a set of cores the

00:16:46,959 --> 00:16:51,120
purple box is

00:16:47,920 --> 00:16:52,639
llc the last level cache underneath

00:16:51,120 --> 00:16:54,240
there could be lower level caches but

00:16:52,639 --> 00:16:56,160
there's always a last level cache that

00:16:54,240 --> 00:16:58,320
connects to the memory

00:16:56,160 --> 00:17:00,000
but the most striking thing in this

00:16:58,320 --> 00:17:01,279
picture is that memory is physically

00:17:00,000 --> 00:17:04,559
distributed

00:17:01,279 --> 00:17:08,400
each node has one quarter 25

00:17:04,559 --> 00:17:09,520
of the memory so a node owns a portion

00:17:08,400 --> 00:17:11,839
of the memory

00:17:09,520 --> 00:17:13,039
the magic happens in that cache coherent

00:17:11,839 --> 00:17:15,439
interconnect

00:17:13,039 --> 00:17:17,760
that knows what's happening in the

00:17:15,439 --> 00:17:20,880
system and if you need your variable a

00:17:17,760 --> 00:17:21,439
it'll figure out where it is and and

00:17:20,880 --> 00:17:24,240
it'll

00:17:21,439 --> 00:17:25,919
get it to you so that's really beautiful

00:17:24,240 --> 00:17:27,120
from a programming point of view you

00:17:25,919 --> 00:17:29,120
don't know that the

00:17:27,120 --> 00:17:30,160
the architecture is highly distributed

00:17:29,120 --> 00:17:32,400
under the hood

00:17:30,160 --> 00:17:34,320
to you it appears as a whole bunch of

00:17:32,400 --> 00:17:38,799
course and one big

00:17:34,320 --> 00:17:38,799
memory underneath it's different

00:17:39,120 --> 00:17:42,799
so this is what i call the developer

00:17:40,880 --> 00:17:45,520
view you've got your threads

00:17:42,799 --> 00:17:46,720
you have your memory where your data is

00:17:45,520 --> 00:17:49,520
and there's a magic

00:17:46,720 --> 00:17:51,520
that glues it all together so when you

00:17:49,520 --> 00:17:54,160
use an operating system command to

00:17:51,520 --> 00:17:55,679
tell you what the system looks like for

00:17:54,160 --> 00:17:58,160
example you use top

00:17:55,679 --> 00:17:59,919
on a linux system it'll just show you

00:17:58,160 --> 00:18:01,200
how much memory you have and how many

00:17:59,919 --> 00:18:04,320
threads are running

00:18:01,200 --> 00:18:07,360
and it won't show you what's going on

00:18:04,320 --> 00:18:08,480
there are linux commands that will tell

00:18:07,360 --> 00:18:10,720
you but

00:18:08,480 --> 00:18:13,280
the system view is what we call a single

00:18:10,720 --> 00:18:16,480
system image there's one memory

00:18:13,280 --> 00:18:19,919
and there's a pool of threads but again

00:18:16,480 --> 00:18:19,919
under the hood it looks different

00:18:20,080 --> 00:18:24,559
so the way to describe pneuma is that

00:18:22,559 --> 00:18:26,720
memory is physically distributed

00:18:24,559 --> 00:18:28,640
but logically shared it's scattered over

00:18:26,720 --> 00:18:30,960
the system you don't see it to you

00:18:28,640 --> 00:18:34,000
there's one memory

00:18:30,960 --> 00:18:35,919
you share data in a transparent way all

00:18:34,000 --> 00:18:37,760
threads can access the shared data

00:18:35,919 --> 00:18:39,520
again regardless of where the data

00:18:37,760 --> 00:18:41,440
actually is

00:18:39,520 --> 00:18:43,120
so you don't know where the data is and

00:18:41,440 --> 00:18:44,880
it doesn't matter for correctness you

00:18:43,120 --> 00:18:46,880
will get the data

00:18:44,880 --> 00:18:49,600
but it does matter for performance where

00:18:46,880 --> 00:18:49,600
your data is

00:18:49,840 --> 00:18:55,760
and that's shown in this this diagram

00:18:52,960 --> 00:18:57,919
i have my thread that's the purple box

00:18:55,760 --> 00:19:01,120
executing somewhere in the system

00:18:57,919 --> 00:19:03,360
okay so it executes over there and if it

00:19:01,120 --> 00:19:05,919
needs some data the good case

00:19:03,360 --> 00:19:07,440
is where there's local local access the

00:19:05,919 --> 00:19:09,360
data is in what we call your local

00:19:07,440 --> 00:19:10,000
memory the memory the part of the memory

00:19:09,360 --> 00:19:13,360
connected

00:19:10,000 --> 00:19:15,039
to to where your program is executing

00:19:13,360 --> 00:19:17,679
where your thread is running i should

00:19:15,039 --> 00:19:19,760
say that's the fastest way to access

00:19:17,679 --> 00:19:20,799
data that's the optimal case that's the

00:19:19,760 --> 00:19:24,000
goal

00:19:20,799 --> 00:19:26,240
but what could happen is that

00:19:24,000 --> 00:19:28,160
the data is further away and on large

00:19:26,240 --> 00:19:30,080
systems it could be really far away

00:19:28,160 --> 00:19:32,559
this is like what we what we say one

00:19:30,080 --> 00:19:34,799
hope but it could be multiple hops away

00:19:32,559 --> 00:19:36,559
and it can take a while to get your data

00:19:34,799 --> 00:19:39,120
and when i say takes a while

00:19:36,559 --> 00:19:40,960
that's of course on the scale of things

00:19:39,120 --> 00:19:42,640
while the system is fetching your data

00:19:40,960 --> 00:19:43,760
you could do a lot of computations for

00:19:42,640 --> 00:19:46,720
example

00:19:43,760 --> 00:19:47,520
so it's wasted time and with pneuma what

00:19:46,720 --> 00:19:49,520
you'd like to do

00:19:47,520 --> 00:19:51,600
is avoid this situation as much as

00:19:49,520 --> 00:19:52,400
possible whenever a threat needs the

00:19:51,600 --> 00:19:55,120
data

00:19:52,400 --> 00:19:58,799
it should be as close by as possible

00:19:55,120 --> 00:19:58,799
that's the goal of newmar tuning

00:19:58,880 --> 00:20:03,520
now whether you like it or not numa is

00:20:01,360 --> 00:20:06,320
here to stay

00:20:03,520 --> 00:20:08,400
the reason it was introduced in systems

00:20:06,320 --> 00:20:09,120
was that it provides more scalable

00:20:08,400 --> 00:20:12,000
bandwidth

00:20:09,120 --> 00:20:13,600
each as you add nodes you add you add

00:20:12,000 --> 00:20:16,159
bandwidth

00:20:13,600 --> 00:20:18,159
and for example a benchmark like stream

00:20:16,159 --> 00:20:20,480
exploits that and shows you how much you

00:20:18,159 --> 00:20:22,640
can get out of the system and that those

00:20:20,480 --> 00:20:24,720
are usually very impressive numbers

00:20:22,640 --> 00:20:26,400
and the reason is that stream benchmark

00:20:24,720 --> 00:20:29,360
has been optimized

00:20:26,400 --> 00:20:31,039
for you to get local local memory access

00:20:29,360 --> 00:20:33,600
not remote

00:20:31,039 --> 00:20:34,320
you as a developer may have to look into

00:20:33,600 --> 00:20:36,559
that as well

00:20:34,320 --> 00:20:37,919
depending on how sensitive your program

00:20:36,559 --> 00:20:41,440
is to where your data

00:20:37,919 --> 00:20:44,320
is in the system certainly as

00:20:41,440 --> 00:20:46,159
core and in particular node counts go up

00:20:44,320 --> 00:20:48,159
pneuma increasingly matters it's not

00:20:46,159 --> 00:20:49,840
something you can ignore

00:20:48,159 --> 00:20:51,280
hopefully your application is not

00:20:49,840 --> 00:20:53,919
sensitive to it

00:20:51,280 --> 00:20:55,200
but if it is then you have to consider

00:20:53,919 --> 00:20:57,360
it

00:20:55,200 --> 00:20:58,640
the good news is that openmp has great

00:20:57,360 --> 00:21:01,919
support for pneuma

00:20:58,640 --> 00:21:02,559
very extensive set the feature continues

00:21:01,919 --> 00:21:04,880
to be

00:21:02,559 --> 00:21:05,919
expanded in subsequent releases of the

00:21:04,880 --> 00:21:09,280
standard

00:21:05,919 --> 00:21:10,559
so um openmp has something to help you

00:21:09,280 --> 00:21:12,080
out

00:21:10,559 --> 00:21:14,559
unfortunately it's beyond the scope of

00:21:12,080 --> 00:21:15,919
this talk to talk about luma tuning

00:21:14,559 --> 00:21:17,919
but just know there's a lot of

00:21:15,919 --> 00:21:20,559
information out there and openmp

00:21:17,919 --> 00:21:21,760
has numerous support to help you master

00:21:20,559 --> 00:21:23,520
that architecture

00:21:21,760 --> 00:21:24,880
the last thing i want to talk about is

00:21:23,520 --> 00:21:26,799
false sharing

00:21:24,880 --> 00:21:28,640
for sharing is actually one of those

00:21:26,799 --> 00:21:29,360
things that that's at the end of the

00:21:28,640 --> 00:21:31,440
checklist

00:21:29,360 --> 00:21:33,840
you start looking into it if nothing

00:21:31,440 --> 00:21:35,600
else explains your scalability issues

00:21:33,840 --> 00:21:36,880
it's one of those things that may happen

00:21:35,600 --> 00:21:38,880
it's not very likely

00:21:36,880 --> 00:21:40,480
but you can't exclude it so it's better

00:21:38,880 --> 00:21:42,159
to know about it

00:21:40,480 --> 00:21:44,240
while sharing occurs when multiple

00:21:42,159 --> 00:21:46,320
threads modify the same cache line at

00:21:44,240 --> 00:21:48,080
the same time and it's under

00:21:46,320 --> 00:21:50,000
it's important to understand that all

00:21:48,080 --> 00:21:52,320
three conditions have to be met

00:21:50,000 --> 00:21:54,240
so we talk about multiple threads

00:21:52,320 --> 00:21:55,039
there's a relatively small portion of

00:21:54,240 --> 00:21:57,360
data

00:21:55,039 --> 00:21:58,240
that's updated at the same time for

00:21:57,360 --> 00:22:00,720
example

00:21:58,240 --> 00:22:01,360
multiple threads access different

00:22:00,720 --> 00:22:03,280
different

00:22:01,360 --> 00:22:05,280
portions of a vector but that vector is

00:22:03,280 --> 00:22:07,280
very short so they're all hitting on the

00:22:05,280 --> 00:22:10,880
same cache line or cache lines

00:22:07,280 --> 00:22:14,159
that's when when false sharing occurs

00:22:10,880 --> 00:22:15,760
why is that so bad well this results in

00:22:14,159 --> 00:22:16,640
the cache line to move through the

00:22:15,760 --> 00:22:19,360
system

00:22:16,640 --> 00:22:20,320
because each time you do an update on on

00:22:19,360 --> 00:22:22,080
a cache line you

00:22:20,320 --> 00:22:23,360
need to have that cache line in your

00:22:22,080 --> 00:22:25,280
cache

00:22:23,360 --> 00:22:27,200
so if it was elsewhere because of a

00:22:25,280 --> 00:22:27,760
previous update it will have to travel

00:22:27,200 --> 00:22:30,559
to you

00:22:27,760 --> 00:22:33,039
you do your update and then the next one

00:22:30,559 --> 00:22:35,120
will do the same so history repeats

00:22:33,039 --> 00:22:36,960
and as a result the line starts

00:22:35,120 --> 00:22:39,440
ping-ponging through the system

00:22:36,960 --> 00:22:40,320
and that's that's expensive that costs

00:22:39,440 --> 00:22:42,799
time

00:22:40,320 --> 00:22:44,000
there's an additional cost each cash

00:22:42,799 --> 00:22:45,679
line has

00:22:44,000 --> 00:22:47,440
status bits there's a cash coherence

00:22:45,679 --> 00:22:49,520
protocol that

00:22:47,440 --> 00:22:51,600
that explains what states there are and

00:22:49,520 --> 00:22:53,280
how you transition between states

00:22:51,600 --> 00:22:55,760
updating those bids takes a little bit

00:22:53,280 --> 00:22:57,760
of time but that's that's a secondary

00:22:55,760 --> 00:22:59,440
issue compared to the line ping-ponging

00:22:57,760 --> 00:23:01,520
through your system that's the biggest

00:22:59,440 --> 00:23:03,919
thing to worry about

00:23:01,520 --> 00:23:05,840
now false sharing happens throughout the

00:23:03,919 --> 00:23:08,000
execution of the program

00:23:05,840 --> 00:23:10,000
and if it's if it's not too frequent

00:23:08,000 --> 00:23:11,919
that's okay that just happens once in a

00:23:10,000 --> 00:23:14,000
while and that's fine

00:23:11,919 --> 00:23:14,960
it's not okay if this happens very

00:23:14,000 --> 00:23:17,440
frequently

00:23:14,960 --> 00:23:18,480
if it's in the heart of your algorithm

00:23:17,440 --> 00:23:20,400
that's when

00:23:18,480 --> 00:23:23,120
when you have a noticeable impact on

00:23:20,400 --> 00:23:27,679
performance and you should look into

00:23:23,120 --> 00:23:27,679
into fall sharing trying to fix it

00:23:28,480 --> 00:23:31,440
here's an example

00:23:31,520 --> 00:23:35,520
there's a parallel region and a parallel

00:23:34,240 --> 00:23:38,000
region

00:23:35,520 --> 00:23:40,000
assigns zero to a vector and that's

00:23:38,000 --> 00:23:41,039
that's executed in parallel by multiple

00:23:40,000 --> 00:23:43,520
threads

00:23:41,039 --> 00:23:44,559
and the indexing to the vector is given

00:23:43,520 --> 00:23:46,960
by the thread id

00:23:44,559 --> 00:23:48,559
so essentially each thread initializes

00:23:46,960 --> 00:23:52,960
one element of the vector

00:23:48,559 --> 00:23:54,720
to zero why is that bad well

00:23:52,960 --> 00:23:56,400
we just described the conditions for

00:23:54,720 --> 00:24:00,400
paul shane to occur

00:23:56,400 --> 00:24:01,919
it's a short vector spanning just a few

00:24:00,400 --> 00:24:04,559
cache lines maybe one

00:24:01,919 --> 00:24:06,000
or a few more and the the line is

00:24:04,559 --> 00:24:08,080
modified the elements in the line are

00:24:06,000 --> 00:24:10,159
modified so this has all the ingredients

00:24:08,080 --> 00:24:12,400
for false shank to occur

00:24:10,159 --> 00:24:14,559
and the line will start moving through

00:24:12,400 --> 00:24:17,120
uh through the system

00:24:14,559 --> 00:24:18,640
and here's an example on four threads we

00:24:17,120 --> 00:24:21,679
have four threads the

00:24:18,640 --> 00:24:23,200
vector a is four long time is from top

00:24:21,679 --> 00:24:25,679
to bottom in this diagram

00:24:23,200 --> 00:24:27,039
and we'll start with the first update so

00:24:25,679 --> 00:24:29,279
thread zero

00:24:27,039 --> 00:24:30,880
presumably does the update it will get

00:24:29,279 --> 00:24:32,400
the cache line that a0

00:24:30,880 --> 00:24:35,039
is part of and it will do its

00:24:32,400 --> 00:24:38,640
modification that's fine

00:24:35,039 --> 00:24:40,080
the next one may be done by thread

00:24:38,640 --> 00:24:42,000
number three and that

00:24:40,080 --> 00:24:43,840
that means that wherever that number

00:24:42,000 --> 00:24:45,919
three is executing

00:24:43,840 --> 00:24:47,039
the line will have to move to so the

00:24:45,919 --> 00:24:49,679
cache line will move

00:24:47,039 --> 00:24:51,039
wherever it is and then then it can do

00:24:49,679 --> 00:24:53,600
the update

00:24:51,039 --> 00:24:54,400
likewise for thread number two again the

00:24:53,600 --> 00:24:56,720
line could

00:24:54,400 --> 00:24:57,440
could move throughout the system and

00:24:56,720 --> 00:25:00,000
finally

00:24:57,440 --> 00:25:01,200
the last one so throughout this process

00:25:00,000 --> 00:25:03,120
the line is

00:25:01,200 --> 00:25:04,559
is ping-ponging through the system from

00:25:03,120 --> 00:25:07,200
cache to cache

00:25:04,559 --> 00:25:07,600
and that takes time and that slows you

00:25:07,200 --> 00:25:10,480
down

00:25:07,600 --> 00:25:11,279
and in my experience false sharing if it

00:25:10,480 --> 00:25:14,799
happens

00:25:11,279 --> 00:25:18,080
it's usually pretty bad

00:25:14,799 --> 00:25:19,840
so here's your homework follow the

00:25:18,080 --> 00:25:20,880
guidelines i've just given and in this

00:25:19,840 --> 00:25:22,880
order sort of

00:25:20,880 --> 00:25:25,200
um i i started with the low hanging

00:25:22,880 --> 00:25:26,320
fruit those are all really easy things

00:25:25,200 --> 00:25:28,400
to do i think

00:25:26,320 --> 00:25:30,480
certainly easy easy to do some

00:25:28,400 --> 00:25:33,279
experimentation give it a try

00:25:30,480 --> 00:25:37,039
and you'll be surprised the small change

00:25:33,279 --> 00:25:40,400
can give you a huge boost in performance

00:25:37,039 --> 00:25:43,440
give it a try but always make a profile

00:25:40,400 --> 00:25:44,320
before and after the change you profile

00:25:43,440 --> 00:25:46,240
your code

00:25:44,320 --> 00:25:48,320
you you tackle a certain part of your

00:25:46,240 --> 00:25:49,760
program and your profile again to see

00:25:48,320 --> 00:25:52,159
what happened

00:25:49,760 --> 00:25:53,120
and the reason is is that the the devil

00:25:52,159 --> 00:25:54,559
is in the details

00:25:53,120 --> 00:25:56,320
details sometimes make all the

00:25:54,559 --> 00:25:58,159
difference and maybe something doesn't

00:25:56,320 --> 00:25:59,919
work out as you might expect it

00:25:58,159 --> 00:26:02,720
so always check with your favorite

00:25:59,919 --> 00:26:02,720
profiling tool

00:26:03,039 --> 00:26:07,039
and eventually if you still have a

00:26:05,840 --> 00:26:09,600
performance mystery

00:26:07,039 --> 00:26:10,960
and you can't explain poor scalability

00:26:09,600 --> 00:26:12,799
that you're seeing

00:26:10,960 --> 00:26:14,880
start thinking about pneuma it could be

00:26:12,799 --> 00:26:17,520
that numa is affecting you

00:26:14,880 --> 00:26:18,640
and once you have eliminated or tackled

00:26:17,520 --> 00:26:20,559
pneuma

00:26:18,640 --> 00:26:22,320
you still see scalability problems it

00:26:20,559 --> 00:26:23,120
could be false sharing in the worst case

00:26:22,320 --> 00:26:26,640
you have both

00:26:23,120 --> 00:26:28,480
but hopefully not numa is much more

00:26:26,640 --> 00:26:31,440
common than false sharing but again

00:26:28,480 --> 00:26:32,480
you need to consider both so thank you

00:26:31,440 --> 00:26:35,919
for your attention

00:26:32,480 --> 00:26:38,400
as always stay tuned and remember

00:26:35,919 --> 00:26:39,679
it's not that openmp doesn't scale it's

00:26:38,400 --> 00:26:42,720
that bad openmp

00:26:39,679 --> 00:26:45,760
does not scale think about remember that

00:26:42,720 --> 00:26:47,360
please before you go there's one more

00:26:45,760 --> 00:26:50,159
thing i wanted to point out

00:26:47,360 --> 00:26:52,559
there's a really good website openmp.org

00:26:50,159 --> 00:26:54,400
that's where you find the specifications

00:26:52,559 --> 00:26:55,840
there's a forum for all your questions

00:26:54,400 --> 00:26:58,799
there are reference guides there's a lot

00:26:55,840 --> 00:27:01,919
of material there are blog articles

00:26:58,799 --> 00:27:03,520
papers so please check out openmp.org

00:27:01,919 --> 00:27:05,760
it's a great source of technical

00:27:03,520 --> 00:27:08,320
information about openmp

00:27:05,760 --> 00:27:09,440
and uh specifically um the videos and

00:27:08,320 --> 00:27:12,159
pdfs of

00:27:09,440 --> 00:27:13,360
these openmp se20 presentations in the

00:27:12,159 --> 00:27:16,320
booth talk series

00:27:13,360 --> 00:27:17,760
will all be posted and made available on

00:27:16,320 --> 00:27:21,360
the website mentioned here

00:27:17,760 --> 00:27:22,240
so enjoy good luck and on to the next

00:27:21,360 --> 00:27:27,440
time

00:27:22,240 --> 00:27:27,440

YouTube URL: https://www.youtube.com/watch?v=N7UD9opM4jw


