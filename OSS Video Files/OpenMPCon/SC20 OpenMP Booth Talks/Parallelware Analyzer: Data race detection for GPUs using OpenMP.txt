Title: Parallelware Analyzer: Data race detection for GPUs using OpenMP
Publication date: 2020-10-16
Playlist: SC20 OpenMP Booth Talks
Description: 
	This presentation, delivered by Manuel Arenaz of Appentra, is part of the OpenMP Booth Talk series created for Supercomputing 2020. A PDF of this presentation as well as more videos from this series can be downloaded at https://www.openmp.org/events/openmp-sc20/
Captions: 
	00:00:02,879 --> 00:00:06,240
hello

00:00:03,600 --> 00:00:06,960
hello everybody it's a pleasure to be

00:00:06,240 --> 00:00:09,760
here

00:00:06,960 --> 00:00:11,679
uh one more year presenting i was

00:00:09,760 --> 00:00:14,080
talking the openp

00:00:11,679 --> 00:00:16,560
booth this time we have to do it

00:00:14,080 --> 00:00:18,480
virtually we cannot meet in person but

00:00:16,560 --> 00:00:20,960
hopefully next year we will be able to

00:00:18,480 --> 00:00:23,760
meet in person again so

00:00:20,960 --> 00:00:25,519
today i'm gonna talk about the latest

00:00:23,760 --> 00:00:27,199
news about our

00:00:25,519 --> 00:00:29,439
apentras parallelware tools in

00:00:27,199 --> 00:00:32,960
particular parallelware analyzer

00:00:29,439 --> 00:00:33,760
and one topic that has attracted a lot

00:00:32,960 --> 00:00:36,399
of attention

00:00:33,760 --> 00:00:37,520
in the hpc community that is database

00:00:36,399 --> 00:00:40,079
detection for

00:00:37,520 --> 00:00:40,640
graphical processing units using openmp

00:00:40,079 --> 00:00:42,239
so

00:00:40,640 --> 00:00:44,000
this is the title of my presentation

00:00:42,239 --> 00:00:45,280
data range detection for gpus using

00:00:44,000 --> 00:00:47,360
openmp

00:00:45,280 --> 00:00:49,440
my name is manuel renath i am ceo and

00:00:47,360 --> 00:00:52,160
co-founder of aperta solutions

00:00:49,440 --> 00:00:53,120
that is a startup company that is

00:00:52,160 --> 00:00:54,879
developing

00:00:53,120 --> 00:00:56,160
and releasing products based on the

00:00:54,879 --> 00:00:58,239
parallel where

00:00:56,160 --> 00:00:59,680
static analysis technology specializing

00:00:58,239 --> 00:01:04,479
in parallelism

00:00:59,680 --> 00:01:06,080
so what are the major challenges in gpu

00:01:04,479 --> 00:01:09,600
programming today

00:01:06,080 --> 00:01:13,119
okay in general developing bug free cc

00:01:09,600 --> 00:01:16,000
plus fortune or a mixture of district

00:01:13,119 --> 00:01:17,360
programming languages parallel code is

00:01:16,000 --> 00:01:19,200
much more complex than developing

00:01:17,360 --> 00:01:21,520
sequential software

00:01:19,200 --> 00:01:23,439
the one of the main reasons is that

00:01:21,520 --> 00:01:25,360
fixing and finding

00:01:23,439 --> 00:01:27,200
bugs in parallel software let's call

00:01:25,360 --> 00:01:28,720
them parallel backs

00:01:27,200 --> 00:01:31,520
it's very difficult and time consuming

00:01:28,720 --> 00:01:34,400
because usually what we have is a

00:01:31,520 --> 00:01:35,520
bug in parallel code appears 99 percent

00:01:34,400 --> 00:01:39,280
of the time

00:01:35,520 --> 00:01:40,640
and just the pro the code the code runs

00:01:39,280 --> 00:01:43,680
correctly 99

00:01:40,640 --> 00:01:44,320
of the time and fails just one percent

00:01:43,680 --> 00:01:46,399
of the time

00:01:44,320 --> 00:01:47,920
what this means is that many times it's

00:01:46,399 --> 00:01:49,119
very difficult for developers to

00:01:47,920 --> 00:01:51,360
reproduce

00:01:49,119 --> 00:01:52,320
an error that appears in software that

00:01:51,360 --> 00:01:55,759
has been released

00:01:52,320 --> 00:01:57,520
for production and this is general of

00:01:55,759 --> 00:02:00,320
parallel software development

00:01:57,520 --> 00:02:01,040
and this is even more difficult for gpus

00:02:00,320 --> 00:02:03,040
where

00:02:01,040 --> 00:02:04,159
we have to offload the computations of

00:02:03,040 --> 00:02:07,200
load the data

00:02:04,159 --> 00:02:08,959
to the gpu and run the code not in our

00:02:07,200 --> 00:02:09,599
computer but in a different device

00:02:08,959 --> 00:02:13,040
attached

00:02:09,599 --> 00:02:14,959
to the to the cpu so it's even more

00:02:13,040 --> 00:02:18,160
difficult and we don't have

00:02:14,959 --> 00:02:20,080
uh tools at this moment that are as

00:02:18,160 --> 00:02:22,239
efficient as

00:02:20,080 --> 00:02:23,599
tools for finding bugs and fixing packs

00:02:22,239 --> 00:02:26,319
in the cpu

00:02:23,599 --> 00:02:28,959
so in order to take advantage of the

00:02:26,319 --> 00:02:30,480
huge performance promised by gpus

00:02:28,959 --> 00:02:32,560
developers need to address two main

00:02:30,480 --> 00:02:34,239
challenges challenge number one and the

00:02:32,560 --> 00:02:36,800
more important one

00:02:34,239 --> 00:02:39,120
is data movement what this means is that

00:02:36,800 --> 00:02:41,920
when you move data from the

00:02:39,120 --> 00:02:44,400
cpu memory to the gpu memory you need to

00:02:41,920 --> 00:02:47,440
guarantee that the correct data is moved

00:02:44,400 --> 00:02:50,480
from cpu to gpu that the data

00:02:47,440 --> 00:02:53,280
that the gpu uses is the correct one

00:02:50,480 --> 00:02:53,920
you don't have a stale data on the gpu

00:02:53,280 --> 00:02:56,319
memory

00:02:53,920 --> 00:02:57,440
that will produce wrong results and then

00:02:56,319 --> 00:02:59,440
you transfer back

00:02:57,440 --> 00:03:00,640
all the results from the gpu memory to

00:02:59,440 --> 00:03:03,680
the cpu so you need to

00:03:00,640 --> 00:03:05,120
keep all the data properly synchronized

00:03:03,680 --> 00:03:06,239
for your program between the cpu memory

00:03:05,120 --> 00:03:08,800
and the gpu memory

00:03:06,239 --> 00:03:10,720
and this is the most challenging issue

00:03:08,800 --> 00:03:13,200
that developers need to address

00:03:10,720 --> 00:03:16,000
the number the second one is data races

00:03:13,200 --> 00:03:17,440
this is related to parallelism so

00:03:16,000 --> 00:03:19,360
when you have a loop for instance you

00:03:17,440 --> 00:03:20,640
need to run it in parallel in

00:03:19,360 --> 00:03:23,200
multi-solid mode

00:03:20,640 --> 00:03:24,159
so in general the same typical problems

00:03:23,200 --> 00:03:26,879
that you have

00:03:24,159 --> 00:03:27,200
in multi-threaded execution on a cpu you

00:03:26,879 --> 00:03:30,400
have

00:03:27,200 --> 00:03:33,519
similar problems on the

00:03:30,400 --> 00:03:34,959
multi-threaded execution of the gpu

00:03:33,519 --> 00:03:38,319
so these are the two main challenges

00:03:34,959 --> 00:03:41,120
data movement and databases

00:03:38,319 --> 00:03:43,360
so how can we help programmers and in

00:03:41,120 --> 00:03:45,680
particular gpu programmers

00:03:43,360 --> 00:03:47,840
gp program is very hard and usually very

00:03:45,680 --> 00:03:50,480
interesting for your code because

00:03:47,840 --> 00:03:51,040
in order to port a single piece of code

00:03:50,480 --> 00:03:53,360
a loop

00:03:51,040 --> 00:03:54,560
to the gpu and run efficiently you need

00:03:53,360 --> 00:03:57,040
usually to make

00:03:54,560 --> 00:03:58,080
major changes to your code not just

00:03:57,040 --> 00:03:59,920
recording the loop

00:03:58,080 --> 00:04:02,720
you need to recode the data structure

00:03:59,920 --> 00:04:04,799
record the design reinitialize data

00:04:02,720 --> 00:04:06,159
and propagate all of these changes

00:04:04,799 --> 00:04:08,799
across all your functions

00:04:06,159 --> 00:04:09,760
all your classes all the code until the

00:04:08,799 --> 00:04:12,000
point where the

00:04:09,760 --> 00:04:12,959
target loop that you want to parallelize

00:04:12,000 --> 00:04:15,920
is executed

00:04:12,959 --> 00:04:16,880
so in general this makes gpu programming

00:04:15,920 --> 00:04:19,199
much harder

00:04:16,880 --> 00:04:21,199
and much more interesting than

00:04:19,199 --> 00:04:24,479
developing multi-threading code for

00:04:21,199 --> 00:04:26,720
cpu for instance so which are the major

00:04:24,479 --> 00:04:30,240
efforts that the gpu programmer

00:04:26,720 --> 00:04:33,280
needs to address or put focus

00:04:30,240 --> 00:04:33,919
on number one detection we need to

00:04:33,280 --> 00:04:36,560
detect

00:04:33,919 --> 00:04:38,880
parallel backs either data races or data

00:04:36,560 --> 00:04:41,680
movement issues

00:04:38,880 --> 00:04:44,160
verification number two whenever there

00:04:41,680 --> 00:04:46,960
is a code that is already parallel

00:04:44,160 --> 00:04:48,000
is the developer certain that the code

00:04:46,960 --> 00:04:50,400
is correct

00:04:48,000 --> 00:04:51,680
will run correctly and free of data race

00:04:50,400 --> 00:04:54,080
and data movement issues

00:04:51,680 --> 00:04:57,360
this is a different type of development

00:04:54,080 --> 00:04:59,600
that the if the programmer needs to do

00:04:57,360 --> 00:05:00,639
discovering opportunities so you have a

00:04:59,600 --> 00:05:02,800
piece of code with

00:05:00,639 --> 00:05:04,720
loops already parallelized and you want

00:05:02,800 --> 00:05:05,840
new loops that you want to convert into

00:05:04,720 --> 00:05:08,320
parallel codes

00:05:05,840 --> 00:05:09,360
and run them offload them to the gpu so

00:05:08,320 --> 00:05:12,479
that's again

00:05:09,360 --> 00:05:15,120
a third effort for the gpu programmer

00:05:12,479 --> 00:05:16,479
and finally implementation when you

00:05:15,120 --> 00:05:18,240
discover an opportunity you need to

00:05:16,479 --> 00:05:20,080
implement and code different versions

00:05:18,240 --> 00:05:20,560
for the gpu and make changes to your

00:05:20,080 --> 00:05:22,320
code

00:05:20,560 --> 00:05:24,560
until you find the one that performs

00:05:22,320 --> 00:05:27,360
better for your code on a target

00:05:24,560 --> 00:05:28,639
gpu so in the end these are the these

00:05:27,360 --> 00:05:30,560
are four

00:05:28,639 --> 00:05:32,800
tasks that the gpu programmer needs to

00:05:30,560 --> 00:05:34,400
do and they they need to do it

00:05:32,800 --> 00:05:36,320
iteratively through the development life

00:05:34,400 --> 00:05:38,560
cycle many times

00:05:36,320 --> 00:05:39,919
since the beginning when they start to

00:05:38,560 --> 00:05:42,320
work on a code

00:05:39,919 --> 00:05:45,039
until the end and they finish porting

00:05:42,320 --> 00:05:48,479
that go to the gpu

00:05:45,039 --> 00:05:50,320
so clearly there is agreement in our

00:05:48,479 --> 00:05:52,639
community that new development tools

00:05:50,320 --> 00:05:54,160
need are needed to improve programmers

00:05:52,639 --> 00:05:56,080
productivity in general

00:05:54,160 --> 00:05:57,280
and particularly for gpus as they

00:05:56,080 --> 00:06:00,240
promise huge

00:05:57,280 --> 00:06:00,560
computational power and they need help

00:06:00,240 --> 00:06:02,720
in

00:06:00,560 --> 00:06:04,800
finding and fixing parallel backs both

00:06:02,720 --> 00:06:06,800
data races and data movement issues

00:06:04,800 --> 00:06:07,840
and helping also important to prevent

00:06:06,800 --> 00:06:09,759
parallel redux

00:06:07,840 --> 00:06:11,360
if we can help the developers to provide

00:06:09,759 --> 00:06:14,960
the code in such a manner

00:06:11,360 --> 00:06:17,440
that they can minimize the probability

00:06:14,960 --> 00:06:19,120
of a parallel back appearing they will

00:06:17,440 --> 00:06:22,160
save they can save

00:06:19,120 --> 00:06:23,520
a lot of time and many many

00:06:22,160 --> 00:06:24,880
dollars at the end of the day for the

00:06:23,520 --> 00:06:26,000
company for the organization they are

00:06:24,880 --> 00:06:29,600
working for

00:06:26,000 --> 00:06:31,440
okay so um

00:06:29,600 --> 00:06:33,600
we are collaborating in efforts

00:06:31,440 --> 00:06:34,960
worldwide in the us and in europe and

00:06:33,600 --> 00:06:38,479
with other

00:06:34,960 --> 00:06:41,120
customers and partners in

00:06:38,479 --> 00:06:42,080
across the world in trying to

00:06:41,120 --> 00:06:46,800
standardize

00:06:42,080 --> 00:06:48,240
a process to develop and

00:06:46,800 --> 00:06:50,160
establish parallel programming best

00:06:48,240 --> 00:06:50,960
practices what experts have in their

00:06:50,160 --> 00:06:53,840
minds

00:06:50,960 --> 00:06:54,560
we want to put it in written write it

00:06:53,840 --> 00:06:57,280
down

00:06:54,560 --> 00:06:59,199
so that we can have all that information

00:06:57,280 --> 00:07:01,919
collected in one single place

00:06:59,199 --> 00:07:04,560
accepted by the community and ideally

00:07:01,919 --> 00:07:07,280
maintained by the community

00:07:04,560 --> 00:07:07,840
and also uh have the possibility to

00:07:07,280 --> 00:07:11,039
create

00:07:07,840 --> 00:07:12,080
tools that can automate and re all many

00:07:11,039 --> 00:07:13,199
of the tasks

00:07:12,080 --> 00:07:15,919
that the developer needs to do

00:07:13,199 --> 00:07:16,560
repeatedly so from these collaboration

00:07:15,919 --> 00:07:19,199
efforts

00:07:16,560 --> 00:07:20,639
we have come up with three stages for

00:07:19,199 --> 00:07:23,759
the parallelization

00:07:20,639 --> 00:07:26,400
process generic stage one is prepare

00:07:23,759 --> 00:07:29,840
your code for parallelism

00:07:26,400 --> 00:07:31,440
even before starting to code and add any

00:07:29,840 --> 00:07:34,479
openmp programmers for instance to your

00:07:31,440 --> 00:07:37,280
code think about how the code is written

00:07:34,479 --> 00:07:38,720
the functions that are created in both

00:07:37,280 --> 00:07:42,000
the data structures

00:07:38,720 --> 00:07:45,520
how they are the data really laid out in

00:07:42,000 --> 00:07:47,520
in memory how the data are used by the

00:07:45,520 --> 00:07:48,879
loop when the code is executing on the

00:07:47,520 --> 00:07:51,440
cpu

00:07:48,879 --> 00:07:52,560
typical problem that we address here is

00:07:51,440 --> 00:07:54,160
try to find

00:07:52,560 --> 00:07:56,720
a data structure that is an array of

00:07:54,160 --> 00:07:58,400
structs and convert it into

00:07:56,720 --> 00:08:00,080
plane arrays or structure for race

00:07:58,400 --> 00:08:03,039
because these

00:08:00,080 --> 00:08:03,840
are better these are data structures

00:08:03,039 --> 00:08:06,639
that are

00:08:03,840 --> 00:08:07,599
better prepared for parallelism so stage

00:08:06,639 --> 00:08:09,039
number one

00:08:07,599 --> 00:08:11,440
many things that you can do in your code

00:08:09,039 --> 00:08:13,759
to prepare the code for parallelism

00:08:11,440 --> 00:08:16,000
stage number two you already know your

00:08:13,759 --> 00:08:17,680
code you have analyzed and prepared for

00:08:16,000 --> 00:08:20,000
a listing but you have not added any

00:08:17,680 --> 00:08:22,560
single parallel semantics to open

00:08:20,000 --> 00:08:23,199
the progress for instance so then you

00:08:22,560 --> 00:08:25,039
need to

00:08:23,199 --> 00:08:27,280
understand the semantics of the code and

00:08:25,039 --> 00:08:29,440
what loops can be converted into a

00:08:27,280 --> 00:08:31,280
parallel equivalent typical loops that

00:08:29,440 --> 00:08:34,800
compute reduction operations

00:08:31,280 --> 00:08:36,240
can we execute the reduction in parallel

00:08:34,800 --> 00:08:37,919
with the appropriate synchronization to

00:08:36,240 --> 00:08:38,560
guarantee that the result will be

00:08:37,919 --> 00:08:41,760
correct

00:08:38,560 --> 00:08:42,399
first and second that the runtime of the

00:08:41,760 --> 00:08:45,120
code

00:08:42,399 --> 00:08:45,600
will be faster so this is stage number

00:08:45,120 --> 00:08:48,560
two

00:08:45,600 --> 00:08:50,240
we don't really care about increasing

00:08:48,560 --> 00:08:52,399
the performance we want that first

00:08:50,240 --> 00:08:55,279
version that runs correctly

00:08:52,399 --> 00:08:56,720
many times it slows down the runtime of

00:08:55,279 --> 00:08:59,680
the original version but we

00:08:56,720 --> 00:09:00,560
have a starting point to optimize the

00:08:59,680 --> 00:09:02,240
parallel code

00:09:00,560 --> 00:09:04,720
and this is the goal of stage number

00:09:02,240 --> 00:09:06,160
three so step number three is optimizing

00:09:04,720 --> 00:09:07,120
your parallel code and here we can

00:09:06,160 --> 00:09:09,440
optimize

00:09:07,120 --> 00:09:10,240
in many different dimensions optimize

00:09:09,440 --> 00:09:13,519
concurrency

00:09:10,240 --> 00:09:15,680
by reducing synchronization variables

00:09:13,519 --> 00:09:16,959
remove implicit barriers that are not

00:09:15,680 --> 00:09:18,800
needed for your call

00:09:16,959 --> 00:09:21,600
you can optimize for data locality

00:09:18,800 --> 00:09:24,560
typical exploit raw major

00:09:21,600 --> 00:09:25,360
data accesses in c or column major data

00:09:24,560 --> 00:09:28,320
accesses in

00:09:25,360 --> 00:09:29,440
fortran data affinity load balancing

00:09:28,320 --> 00:09:31,279
issues with

00:09:29,440 --> 00:09:32,800
different types of scheduling static

00:09:31,279 --> 00:09:36,880
static one dynamic

00:09:32,800 --> 00:09:38,959
runtime that openmp provides so we can

00:09:36,880 --> 00:09:40,959
use many different dimensions to

00:09:38,959 --> 00:09:42,000
optimize the parallel code that we have

00:09:40,959 --> 00:09:45,440
created

00:09:42,000 --> 00:09:47,360
and you can see that tcr this there is

00:09:45,440 --> 00:09:49,200
something that is common to the three

00:09:47,360 --> 00:09:52,240
stages that is

00:09:49,200 --> 00:09:54,399
very fine finding bags fixing bags

00:09:52,240 --> 00:09:56,480
they verify that the code is correct and

00:09:54,399 --> 00:09:59,120
this is repeated in every single

00:09:56,480 --> 00:10:00,880
step that you do in every single stage

00:09:59,120 --> 00:10:04,079
and you can see this

00:10:00,880 --> 00:10:05,760
common box in stage 1

00:10:04,079 --> 00:10:07,839
verify correctness stage 2 and various

00:10:05,760 --> 00:10:10,959
stage number 3.

00:10:07,839 --> 00:10:12,800
so remember three stages invest time in

00:10:10,959 --> 00:10:14,560
preparing your code

00:10:12,800 --> 00:10:16,240
step number two invest time in

00:10:14,560 --> 00:10:17,600
understanding your code and causing a

00:10:16,240 --> 00:10:20,079
first version without

00:10:17,600 --> 00:10:21,279
really worrying too much about

00:10:20,079 --> 00:10:24,000
performance

00:10:21,279 --> 00:10:24,880
and stage number three care about

00:10:24,000 --> 00:10:28,160
performance

00:10:24,880 --> 00:10:30,959
okay so how can we ensure

00:10:28,160 --> 00:10:32,720
a parallel programming best practices

00:10:30,959 --> 00:10:34,959
okay we need to essentially

00:10:32,720 --> 00:10:36,480
the approach needs is based on two

00:10:34,959 --> 00:10:38,240
pillars

00:10:36,480 --> 00:10:39,920
pillar number one let me begin on the

00:10:38,240 --> 00:10:42,480
right open catalog of

00:10:39,920 --> 00:10:43,200
defects and recommendations we need to

00:10:42,480 --> 00:10:45,920
write down

00:10:43,200 --> 00:10:48,079
all the expertise of experts in a

00:10:45,920 --> 00:10:50,640
catalog of

00:10:48,079 --> 00:10:53,200
defects common errors explain why these

00:10:50,640 --> 00:10:55,600
errors are important

00:10:53,200 --> 00:10:56,959
when they appear and how to fix them and

00:10:55,600 --> 00:10:58,959
recommendations

00:10:56,959 --> 00:11:01,519
how can we write the code in a way that

00:10:58,959 --> 00:11:03,200
is more amenable for parallelism

00:11:01,519 --> 00:11:05,440
how can we detect the situation and

00:11:03,200 --> 00:11:06,000
which is the code change that we need to

00:11:05,440 --> 00:11:08,399
do

00:11:06,000 --> 00:11:10,399
to prepare the code for parallelism so

00:11:08,399 --> 00:11:12,880
this open catalog you can see

00:11:10,399 --> 00:11:14,720
we have created an open catalog based on

00:11:12,880 --> 00:11:15,600
the our collaborations with the hpc

00:11:14,720 --> 00:11:18,000
community

00:11:15,600 --> 00:11:20,480
and you can discover many checks many

00:11:18,000 --> 00:11:23,360
defects and recommendations that are

00:11:20,480 --> 00:11:25,120
available there and also with this

00:11:23,360 --> 00:11:27,120
knowledge you can learn from it

00:11:25,120 --> 00:11:28,160
and apply it to your code if you are

00:11:27,120 --> 00:11:31,760
coding

00:11:28,160 --> 00:11:33,839
just a simple 200 lines of code

00:11:31,760 --> 00:11:35,200
application you can do it by hand but

00:11:33,839 --> 00:11:37,600
whenever we go

00:11:35,200 --> 00:11:38,399
to big codes of millions of lines of

00:11:37,600 --> 00:11:40,320
code

00:11:38,399 --> 00:11:41,920
what really helps in product in

00:11:40,320 --> 00:11:42,480
increasing productivity of the developer

00:11:41,920 --> 00:11:46,399
is

00:11:42,480 --> 00:11:48,160
to have tools that can check your code

00:11:46,399 --> 00:11:50,240
against this catalog of the effects and

00:11:48,160 --> 00:11:52,160
recommendations and suggest

00:11:50,240 --> 00:11:54,959
recommendations to prepare the code and

00:11:52,160 --> 00:11:56,000
suggest defects or errors that have been

00:11:54,959 --> 00:11:58,000
found in your code

00:11:56,000 --> 00:12:00,079
and this will speed up the development

00:11:58,000 --> 00:12:03,440
effort and this is where

00:12:00,079 --> 00:12:05,040
parallel analyzer tool comes into play

00:12:03,440 --> 00:12:06,880
and this whole approach that we have

00:12:05,040 --> 00:12:07,600
been working on for more than one year

00:12:06,880 --> 00:12:09,920
now

00:12:07,600 --> 00:12:11,440
has recently received the prestigious

00:12:09,920 --> 00:12:14,160
innovation rather prize

00:12:11,440 --> 00:12:14,720
to the innovation science category this

00:12:14,160 --> 00:12:18,079
year

00:12:14,720 --> 00:12:21,519
this award was honored to us

00:12:18,079 --> 00:12:24,959
in september just one month ago so

00:12:21,519 --> 00:12:29,680
we are really

00:12:24,959 --> 00:12:31,920
excited that the community is

00:12:29,680 --> 00:12:33,440
taking or adopting this approach and is

00:12:31,920 --> 00:12:35,600
behind it

00:12:33,440 --> 00:12:37,279
so what about paraguay analyzer power

00:12:35,600 --> 00:12:39,360
analysis was first presented as an

00:12:37,279 --> 00:12:42,399
emerging technology

00:12:39,360 --> 00:12:46,480
at sca team one year

00:12:42,399 --> 00:12:48,880
of development has come up with a set of

00:12:46,480 --> 00:12:49,519
parallel command line tools that can

00:12:48,880 --> 00:12:51,680
help you

00:12:49,519 --> 00:12:53,040
both to test and debug parallel code

00:12:51,680 --> 00:12:55,360
finding and fixing

00:12:53,040 --> 00:12:56,720
risk conditions and data movement issues

00:12:55,360 --> 00:12:58,160
and also help you during the coding

00:12:56,720 --> 00:12:59,440
process where you have to call different

00:12:58,160 --> 00:13:02,320
versions of the code

00:12:59,440 --> 00:13:03,600
so you have four tools in the suite at

00:13:02,320 --> 00:13:06,880
this moment

00:13:03,600 --> 00:13:10,160
pw report pw check

00:13:06,880 --> 00:13:13,200
pw loops and pw directives so

00:13:10,160 --> 00:13:15,519
all of this the shape of analyzer

00:13:13,200 --> 00:13:18,000
has been developed in conjunction with

00:13:15,519 --> 00:13:20,160
partners in the pica maestro

00:13:18,000 --> 00:13:21,200
projects in the european union are now

00:13:20,160 --> 00:13:23,760
recently at the

00:13:21,200 --> 00:13:24,720
mid-year mid of this year we have also

00:13:23,760 --> 00:13:26,320
started

00:13:24,720 --> 00:13:28,800
a project with the orange national

00:13:26,320 --> 00:13:29,519
laboratory to push data registration for

00:13:28,800 --> 00:13:31,519
gpus

00:13:29,519 --> 00:13:34,079
using the parallel analyzer approach and

00:13:31,519 --> 00:13:38,399
the catalog of defense recommendations

00:13:34,079 --> 00:13:39,120
so this is an example output of pw

00:13:38,399 --> 00:13:41,279
report

00:13:39,120 --> 00:13:43,279
what this pw report is your friend is

00:13:41,279 --> 00:13:45,360
the entry point to analyze a code

00:13:43,279 --> 00:13:46,320
and to check the status of the code from

00:13:45,360 --> 00:13:48,480
time to time

00:13:46,320 --> 00:13:50,160
because it provides you a summary of

00:13:48,480 --> 00:13:51,920
code coverage in terms of

00:13:50,160 --> 00:13:53,360
files functions loop that were

00:13:51,920 --> 00:13:56,639
successfully analyzed

00:13:53,360 --> 00:13:59,440
and also a summary of metrics

00:13:56,639 --> 00:14:01,519
in terms of recommendations defects

00:13:59,440 --> 00:14:03,600
opportunities for parallelization

00:14:01,519 --> 00:14:05,199
databases that have been found and

00:14:03,600 --> 00:14:07,360
database free loops that have been

00:14:05,199 --> 00:14:10,639
verified by the two

00:14:07,360 --> 00:14:13,279
okay and it also suggests new commands

00:14:10,639 --> 00:14:14,320
of the other tools of the parallel

00:14:13,279 --> 00:14:17,360
analyzer suite

00:14:14,320 --> 00:14:20,079
pw looks pw derivatives okay

00:14:17,360 --> 00:14:21,279
so remember report pw report is your

00:14:20,079 --> 00:14:24,800
friend

00:14:21,279 --> 00:14:25,360
pw check is the tool that is designed to

00:14:24,800 --> 00:14:28,000
check

00:14:25,360 --> 00:14:29,360
and find data races and data movement

00:14:28,000 --> 00:14:31,920
issues in your comments

00:14:29,360 --> 00:14:32,639
so the help will provide you with the

00:14:31,920 --> 00:14:34,880
list of

00:14:32,639 --> 00:14:35,839
defects and recommendations currently

00:14:34,880 --> 00:14:37,519
supported

00:14:35,839 --> 00:14:38,720
by the tool and essentially we are

00:14:37,519 --> 00:14:40,639
supporting all the effects and

00:14:38,720 --> 00:14:44,880
recommendations that are publicly

00:14:40,639 --> 00:14:47,920
and open available in the catalog

00:14:44,880 --> 00:14:49,839
of defense recommendations so

00:14:47,920 --> 00:14:51,519
let me show you in this presentation

00:14:49,839 --> 00:14:53,360
just a glimpse

00:14:51,519 --> 00:14:54,720
three examples one example for each of

00:14:53,360 --> 00:14:57,760
these stages

00:14:54,720 --> 00:14:59,760
of these best practices recommendations

00:14:57,760 --> 00:15:01,760
for parallel programming and for gpu

00:14:59,760 --> 00:15:04,320
let's begin with the stage number one

00:15:01,760 --> 00:15:07,519
preparation of code for parallelism

00:15:04,320 --> 00:15:10,000
and let me bring to your attention

00:15:07,519 --> 00:15:10,639
one very typical example one of the

00:15:10,000 --> 00:15:14,320
major

00:15:10,639 --> 00:15:14,800
problems of coding a code for open mp or

00:15:14,320 --> 00:15:18,079
openness

00:15:14,800 --> 00:15:20,079
senior database standards is handling

00:15:18,079 --> 00:15:22,079
the data scoping properly

00:15:20,079 --> 00:15:24,480
when a variable needs to be privatized

00:15:22,079 --> 00:15:26,639
needs to be shared needs to be reduced

00:15:24,480 --> 00:15:27,519
when it needs additional synchronization

00:15:26,639 --> 00:15:30,480
to guarantee

00:15:27,519 --> 00:15:31,600
correctness so here you have an example

00:15:30,480 --> 00:15:34,399
pwr

00:15:31,600 --> 00:15:35,040
002 declare scalar variables in the

00:15:34,399 --> 00:15:38,160
smallest

00:15:35,040 --> 00:15:39,600
possible scope and this is just an

00:15:38,160 --> 00:15:41,519
example of the information available in

00:15:39,600 --> 00:15:43,920
the catalog where you can see

00:15:41,519 --> 00:15:44,959
the code before and after the

00:15:43,920 --> 00:15:46,320
recommendation

00:15:44,959 --> 00:15:48,800
and if you see that in this case you

00:15:46,320 --> 00:15:51,440
depend your code to declare

00:15:48,800 --> 00:15:53,040
this scalar variable t inside the loop

00:15:51,440 --> 00:15:57,040
you can even

00:15:53,040 --> 00:15:59,759
avoid the need to handle the variable t

00:15:57,040 --> 00:16:01,920
in the clauses of openmp it simplifies

00:15:59,759 --> 00:16:03,920
the implementation of openmp

00:16:01,920 --> 00:16:05,680
so if it simplifies implementation

00:16:03,920 --> 00:16:07,839
simplifies the maintenance

00:16:05,680 --> 00:16:09,040
and also prevents bugs from appearing

00:16:07,839 --> 00:16:11,680
because you may be

00:16:09,040 --> 00:16:12,560
sharing or privatizing tea in a wrong

00:16:11,680 --> 00:16:15,519
manner

00:16:12,560 --> 00:16:16,560
in your in in bitcoins okay so this is

00:16:15,519 --> 00:16:19,360
one example

00:16:16,560 --> 00:16:22,320
related to a big uh an important topic

00:16:19,360 --> 00:16:23,920
that is data scoping and i want to

00:16:22,320 --> 00:16:25,839
remark here

00:16:23,920 --> 00:16:27,120
the nature of the recommendations the

00:16:25,839 --> 00:16:28,959
preventive nature

00:16:27,120 --> 00:16:30,240
it can help you to prevent parallel

00:16:28,959 --> 00:16:32,399
backs from appearing

00:16:30,240 --> 00:16:33,759
simplifying the coding the parallel

00:16:32,399 --> 00:16:35,759
coding process which is

00:16:33,759 --> 00:16:38,560
really important for productivity and

00:16:35,759 --> 00:16:40,800
results for the developer

00:16:38,560 --> 00:16:42,880
an example of stage number two in step

00:16:40,800 --> 00:16:44,959
number two we are worried about

00:16:42,880 --> 00:16:46,959
creating the first parallel version of

00:16:44,959 --> 00:16:48,800
our goal without caring about

00:16:46,959 --> 00:16:50,959
performance but having something that

00:16:48,800 --> 00:16:54,000
works and works currently provides

00:16:50,959 --> 00:16:56,160
correct numerical results

00:16:54,000 --> 00:16:58,240
so in this case we have selected an

00:16:56,160 --> 00:17:00,079
important problem that is deep copy

00:16:58,240 --> 00:17:02,720
deep copy when you go to gpu and you

00:17:00,079 --> 00:17:06,559
have complex data structures

00:17:02,720 --> 00:17:09,120
you need to manually implement in openmp

00:17:06,559 --> 00:17:10,880
how this pointers to extracts of

00:17:09,120 --> 00:17:12,319
pointers to structs to point the

00:17:10,880 --> 00:17:14,880
substrate nested

00:17:12,319 --> 00:17:15,919
the structure of pointers are mapped to

00:17:14,880 --> 00:17:18,959
the gpu

00:17:15,919 --> 00:17:22,400
okay so here we can detect

00:17:18,959 --> 00:17:25,360
in in the in analyzes through pwd

00:17:22,400 --> 00:17:26,799
06 missing the copy of non-contiguous

00:17:25,360 --> 00:17:29,200
data to the gpu

00:17:26,799 --> 00:17:32,480
we can check if what you are

00:17:29,200 --> 00:17:35,360
transferring in a map clause of openmp

00:17:32,480 --> 00:17:37,120
is contiguous in data or not if it is

00:17:35,360 --> 00:17:39,520
not contiguous then

00:17:37,120 --> 00:17:40,160
openmp by default will not manage data

00:17:39,520 --> 00:17:43,600
transfer

00:17:40,160 --> 00:17:45,280
correctly so you will need to fix it

00:17:43,600 --> 00:17:46,880
in in the mechanism with the mechanisms

00:17:45,280 --> 00:17:50,160
that openmp provides

00:17:46,880 --> 00:17:52,880
one way is to provide exact ranges

00:17:50,160 --> 00:17:53,600
of data that can be that need to be

00:17:52,880 --> 00:17:56,480
transferred

00:17:53,600 --> 00:17:58,240
for instance in a double pointer or

00:17:56,480 --> 00:17:58,799
using best practice recommendations that

00:17:58,240 --> 00:18:02,240
is

00:17:58,799 --> 00:18:05,280
use enter data and exit data to map

00:18:02,240 --> 00:18:08,720
all the data

00:18:05,280 --> 00:18:11,840
and follow the pointers to the gpu okay

00:18:08,720 --> 00:18:15,120
so again deep copy a big problem we can

00:18:11,840 --> 00:18:18,160
detect effects in big in

00:18:15,120 --> 00:18:21,360
in big application calls and remember

00:18:18,160 --> 00:18:21,840
defects are about finding and fixing

00:18:21,360 --> 00:18:24,880
backs

00:18:21,840 --> 00:18:25,440
we can say this is the pack that you

00:18:24,880 --> 00:18:27,120
have

00:18:25,440 --> 00:18:28,960
and this is the solution for the back

00:18:27,120 --> 00:18:30,320
you can suggest how to write correct

00:18:28,960 --> 00:18:32,720
parallel

00:18:30,320 --> 00:18:34,720
and in some cases even regulate the code

00:18:32,720 --> 00:18:37,360
for you

00:18:34,720 --> 00:18:39,280
and finally stage number three now we

00:18:37,360 --> 00:18:41,679
really care about performance

00:18:39,280 --> 00:18:43,760
what i mentioned do we need to optimize

00:18:41,679 --> 00:18:47,360
to increase the performance of

00:18:43,760 --> 00:18:47,919
our parallel and in this case we have

00:18:47,360 --> 00:18:50,080
brought

00:18:47,919 --> 00:18:51,120
a perspective recommendation that has

00:18:50,080 --> 00:18:55,039
been published in

00:18:51,120 --> 00:18:57,679
iwomp papers for instance

00:18:55,039 --> 00:18:58,480
that is when you are in on the cpu you

00:18:57,679 --> 00:19:00,799
typically

00:18:58,480 --> 00:19:02,000
are recommended to use parallel 4 but

00:19:00,799 --> 00:19:04,720
this doesn't map well

00:19:02,000 --> 00:19:05,039
to the gpu because in the gpu you can

00:19:04,720 --> 00:19:08,480
have

00:19:05,039 --> 00:19:10,640
different compilers that are mapping and

00:19:08,480 --> 00:19:12,480
work sharing constructs in a different

00:19:10,640 --> 00:19:15,440
way to the target

00:19:12,480 --> 00:19:17,360
platform so for instance for the gpu it

00:19:15,440 --> 00:19:20,400
is best practice recommendation to use

00:19:17,360 --> 00:19:22,320
not parallel for but instead target

00:19:20,400 --> 00:19:24,960
teams distribute parallel 4

00:19:22,320 --> 00:19:27,120
and even additionally cindy to exploit

00:19:24,960 --> 00:19:30,799
all the computational power of a gpu

00:19:27,120 --> 00:19:33,280
should you delegate on the gpu compiler

00:19:30,799 --> 00:19:34,640
to create the threads in the appropriate

00:19:33,280 --> 00:19:37,440
manner so that they

00:19:34,640 --> 00:19:38,640
exploit all the massive computational

00:19:37,440 --> 00:19:40,960
power of the gpu

00:19:38,640 --> 00:19:42,559
so here we really care about performance

00:19:40,960 --> 00:19:46,080
so other examples are

00:19:42,559 --> 00:19:48,720
collapsing loops or using raw major or

00:19:46,080 --> 00:19:51,600
column major data accesses in

00:19:48,720 --> 00:19:52,880
in c or fortran so there are many ways

00:19:51,600 --> 00:19:55,200
in which we can help

00:19:52,880 --> 00:19:56,240
help you to optimize the performance of

00:19:55,200 --> 00:19:58,720
your call

00:19:56,240 --> 00:20:00,480
and these are just three examples of the

00:19:58,720 --> 00:20:02,640
whole catalog here you can see

00:20:00,480 --> 00:20:04,559
the current status of the catalog as of

00:20:02,640 --> 00:20:05,120
october but now we are already working

00:20:04,559 --> 00:20:07,280
on

00:20:05,120 --> 00:20:09,280
five to seven more defects and

00:20:07,280 --> 00:20:12,559
recommendations that will be published

00:20:09,280 --> 00:20:13,520
before the sea so stay tuned with the

00:20:12,559 --> 00:20:15,840
catalog

00:20:13,520 --> 00:20:16,960
quotes what effects and recommendations

00:20:15,840 --> 00:20:19,360
apply

00:20:16,960 --> 00:20:21,280
to in general parallel programming and

00:20:19,360 --> 00:20:22,640
in particular to gpu programming

00:20:21,280 --> 00:20:24,960
and here you have highlighted at this

00:20:22,640 --> 00:20:25,840
moment the ones that are related to gpu

00:20:24,960 --> 00:20:27,760
programming

00:20:25,840 --> 00:20:28,960
two defects defect number three defect

00:20:27,760 --> 00:20:30,400
number six

00:20:28,960 --> 00:20:31,679
and about the recommendations there are

00:20:30,400 --> 00:20:33,440
some of them that are related

00:20:31,679 --> 00:20:35,600
specifically to openmp

00:20:33,440 --> 00:20:36,559
but many of them are not about openmp

00:20:35,600 --> 00:20:38,640
openscc or

00:20:36,559 --> 00:20:39,840
how to implement the parallelism they

00:20:38,640 --> 00:20:43,440
are about how you code

00:20:39,840 --> 00:20:45,360
in c or fortran so for instance declare

00:20:43,440 --> 00:20:48,720
global variables as function parameters

00:20:45,360 --> 00:20:51,280
or declare the variables in the smallest

00:20:48,720 --> 00:20:52,480
possible scope or explicitly declare

00:20:51,280 --> 00:20:56,080
pure functions

00:20:52,480 --> 00:20:58,880
are different way coding styles

00:20:56,080 --> 00:21:00,640
for you to write your code in such a way

00:20:58,880 --> 00:21:01,600
that your code will be better mapped by

00:21:00,640 --> 00:21:04,000
openmp

00:21:01,600 --> 00:21:05,600
to the target hardware platform in the

00:21:04,000 --> 00:21:08,400
end you will have a better code

00:21:05,600 --> 00:21:10,720
higher quality less development effort

00:21:08,400 --> 00:21:14,880
less maintenance effort

00:21:10,720 --> 00:21:17,039
so please watch the catalog

00:21:14,880 --> 00:21:19,520
and the changes feel free to contact us

00:21:17,039 --> 00:21:22,880
if you are interested in collaborating

00:21:19,520 --> 00:21:24,159
in populating this catalogue with new

00:21:22,880 --> 00:21:26,880
defense and recommendations and

00:21:24,159 --> 00:21:28,720
collaborating this hpc community effort

00:21:26,880 --> 00:21:29,679
and also we have published and we will

00:21:28,720 --> 00:21:31,600
regularly publish

00:21:29,679 --> 00:21:32,960
tips to avoid for instance risk

00:21:31,600 --> 00:21:34,799
conditions for gpus

00:21:32,960 --> 00:21:37,280
you can download it for free from our

00:21:34,799 --> 00:21:38,960
website where we describe

00:21:37,280 --> 00:21:40,720
some of the different recommendations

00:21:38,960 --> 00:21:44,400
that apply to

00:21:40,720 --> 00:21:48,240
gpu programming and that's it

00:21:44,400 --> 00:21:50,720
so um we really hope that

00:21:48,240 --> 00:21:51,679
you are as excited as we are about this

00:21:50,720 --> 00:21:53,520
new

00:21:51,679 --> 00:21:55,440
approach to parallel programming based

00:21:53,520 --> 00:21:58,080
on these best practice recommendations

00:21:55,440 --> 00:22:00,320
by experts of our svc community

00:21:58,080 --> 00:22:01,760
and in particular you can apply this to

00:22:00,320 --> 00:22:05,520
gpu programming

00:22:01,760 --> 00:22:07,520
to improve the quality the performance

00:22:05,520 --> 00:22:08,799
and reduce the development effort of

00:22:07,520 --> 00:22:10,880
your gpu programming

00:22:08,799 --> 00:22:12,080
program for the most powerful

00:22:10,880 --> 00:22:14,799
supercomputers in the world

00:22:12,080 --> 00:22:16,559
so feel free to reach out and contact me

00:22:14,799 --> 00:22:18,559
if you are interested in

00:22:16,559 --> 00:22:19,919
staying tuned or collaborating with us

00:22:18,559 --> 00:22:22,320
with us in any manner

00:22:19,919 --> 00:22:24,320
and feel free to download open the

00:22:22,320 --> 00:22:27,840
catalog and download our tools

00:22:24,320 --> 00:22:27,840

YouTube URL: https://www.youtube.com/watch?v=HiDNLr62ebQ


