Title: OpenMP in Exascale Numerical Libraries
Publication date: 2020-11-06
Playlist: SC20 OpenMP Booth Talks
Description: 
	This presentation was delivered by Piotr Luszczek of Univ. of Tennessee in collaboration with Hartwig Anzt of Karlsruhe Institute of Technology as well as Mark Gates, Piotr Luszczek and Stanimire Tomov of Univ. of Tennessee. This is part of the OpenMP Booth Talk series created for Supercomputing 2020. A PDF of this presentation as well as more videos from this series can be downloaded at link.openmp.org/sc20
Captions: 
	00:00:03,760 --> 00:00:07,200
hello everybody

00:00:04,799 --> 00:00:09,440
my name is pierre luzczek i'm from the

00:00:07,200 --> 00:00:11,759
university of tennessee

00:00:09,440 --> 00:00:13,360
and i'll be talking to you about today

00:00:11,759 --> 00:00:17,119
about the use of openmp

00:00:13,360 --> 00:00:19,279
in exoscale numerical libraries

00:00:17,119 --> 00:00:21,359
my co-authors are hartwick anz from

00:00:19,279 --> 00:00:22,880
karlsruhe institute of technology

00:00:21,359 --> 00:00:24,960
and my colleagues from the university of

00:00:22,880 --> 00:00:28,960
tennessee mark gates

00:00:24,960 --> 00:00:31,439
and stonymere thomas let me start with

00:00:28,960 --> 00:00:32,960
talking about the scope of the the

00:00:31,439 --> 00:00:34,000
libraries and the platforms that they

00:00:32,960 --> 00:00:38,320
target

00:00:34,000 --> 00:00:40,239
so on the left is a lot of detail about

00:00:38,320 --> 00:00:43,600
these libraries we have four of them

00:00:40,239 --> 00:00:44,000
ginkgo magma plasma and slate and they

00:00:43,600 --> 00:00:47,120
roughly

00:00:44,000 --> 00:00:49,360
correspond to sparse

00:00:47,120 --> 00:00:50,320
sparse methods and iterative methods for

00:00:49,360 --> 00:00:52,559
ginkgo

00:00:50,320 --> 00:00:54,079
magma is mostly dense linear algebra and

00:00:52,559 --> 00:00:56,000
eigenvalue in svds

00:00:54,079 --> 00:00:58,399
and includes also some iterative methods

00:00:56,000 --> 00:01:01,760
with preconditioners and spar storage

00:00:58,399 --> 00:01:04,239
plasma is mostly a dense linear algebra

00:01:01,760 --> 00:01:05,840
singular values and eigenvalues and it

00:01:04,239 --> 00:01:08,640
targets openmp

00:01:05,840 --> 00:01:10,560
for tasking and finally slate is a

00:01:08,640 --> 00:01:13,360
distributed version

00:01:10,560 --> 00:01:15,520
of the libraries that i mentioned it

00:01:13,360 --> 00:01:18,479
mostly covers um

00:01:15,520 --> 00:01:19,920
that's linear algebra and and targets

00:01:18,479 --> 00:01:21,840
gpus

00:01:19,920 --> 00:01:23,439
as well as uh some sort of an

00:01:21,840 --> 00:01:24,560
interconnect that it accesses through

00:01:23,439 --> 00:01:26,799
mpi

00:01:24,560 --> 00:01:28,720
the these are exoskelet libraries

00:01:26,799 --> 00:01:31,119
because we target

00:01:28,720 --> 00:01:32,320
optimize and develop on daily basis for

00:01:31,119 --> 00:01:35,360
um

00:01:32,320 --> 00:01:37,280
a large installations at doe

00:01:35,360 --> 00:01:39,119
and other facilities so on the right

00:01:37,280 --> 00:01:42,399
there are some examples of those

00:01:39,119 --> 00:01:44,000
nvidia with cuda 10 and 11 amd with hip

00:01:42,399 --> 00:01:46,799
and rocking platforms

00:01:44,000 --> 00:01:47,439
and finally intel and the dpc plus plus

00:01:46,799 --> 00:01:50,159
development

00:01:47,439 --> 00:01:50,880
platform but the overarching goal is to

00:01:50,159 --> 00:01:52,880
show

00:01:50,880 --> 00:01:54,720
how these are just lower level bits and

00:01:52,880 --> 00:01:58,079
on top of it is

00:01:54,720 --> 00:01:58,560
is openmp and the testing is performed

00:01:58,079 --> 00:02:00,399
with the

00:01:58,560 --> 00:02:02,479
continuous integration and continuous

00:02:00,399 --> 00:02:07,280
development that we have set up

00:02:02,479 --> 00:02:09,679
on x86 power and arm processors

00:02:07,280 --> 00:02:10,319
so what is our general portability

00:02:09,679 --> 00:02:12,480
approach

00:02:10,319 --> 00:02:14,080
to make these libraries portable and at

00:02:12,480 --> 00:02:17,360
the same at the same time

00:02:14,080 --> 00:02:20,080
perform very well on multiple targets

00:02:17,360 --> 00:02:21,280
so we try to stick to common interfaces

00:02:20,080 --> 00:02:22,319
that have been established over the

00:02:21,280 --> 00:02:25,440
decades

00:02:22,319 --> 00:02:26,800
and they were developed in some of our

00:02:25,440 --> 00:02:28,879
groups

00:02:26,800 --> 00:02:29,840
and these are mostly a blossom lapak

00:02:28,879 --> 00:02:32,959
libraries

00:02:29,840 --> 00:02:35,599
that now have been implemented

00:02:32,959 --> 00:02:36,239
and ported and optimized on multiple

00:02:35,599 --> 00:02:39,280
platforms

00:02:36,239 --> 00:02:41,120
and accelerators by vendors so

00:02:39,280 --> 00:02:42,480
this is an example of a call to matrix

00:02:41,120 --> 00:02:44,879
matrix multiply

00:02:42,480 --> 00:02:46,080
in and it's different naming depending

00:02:44,879 --> 00:02:50,319
on which library you use

00:02:46,080 --> 00:02:53,360
either hip cuda or perhaps mkl

00:02:50,319 --> 00:02:55,360
we use a lot of abstractions programming

00:02:53,360 --> 00:02:57,120
abstractions that take user data and

00:02:55,360 --> 00:03:01,040
provide very practical

00:02:57,120 --> 00:03:02,080
uh object structure that maps this data

00:03:01,040 --> 00:03:06,239
to a lower level

00:03:02,080 --> 00:03:08,879
uh hardware uh constructs and

00:03:06,239 --> 00:03:09,599
we focus uh very heavily on the user

00:03:08,879 --> 00:03:11,200
experience

00:03:09,599 --> 00:03:13,360
so when they encounter these libraries

00:03:11,200 --> 00:03:16,000
they have a very easy time

00:03:13,360 --> 00:03:16,959
to uh to express their algorithms that

00:03:16,000 --> 00:03:19,840
mostly

00:03:16,959 --> 00:03:20,720
pertain to matrices vectors and and

00:03:19,840 --> 00:03:23,120
things such as

00:03:20,720 --> 00:03:24,560
execution policy so the user can specify

00:03:23,120 --> 00:03:25,760
whether they want to run it on the house

00:03:24,560 --> 00:03:29,280
on the device

00:03:25,760 --> 00:03:31,680
and a lot of our algorithms are very uh

00:03:29,280 --> 00:03:33,519
generic in the sense that we program

00:03:31,680 --> 00:03:36,560
against generic data types

00:03:33,519 --> 00:03:39,519
and uh they get specified down

00:03:36,560 --> 00:03:41,680
at the lower levels and the testing is

00:03:39,519 --> 00:03:44,879
is mostly done on concrete types to

00:03:41,680 --> 00:03:47,840
to test whether the the libraries work

00:03:44,879 --> 00:03:49,680
across the uh the important uh important

00:03:47,840 --> 00:03:53,680
matrices and vectors and the uh

00:03:49,680 --> 00:03:56,480
elements so in ginkgo um

00:03:53,680 --> 00:03:58,159
we have an openmp backend that basically

00:03:56,480 --> 00:03:59,120
makes the functionality of the entire

00:03:58,159 --> 00:04:01,599
library

00:03:59,120 --> 00:04:02,319
available on any on any hardware that

00:04:01,599 --> 00:04:05,519
supports

00:04:02,319 --> 00:04:05,920
uh supports openmp and that that would

00:04:05,519 --> 00:04:09,439
include

00:04:05,920 --> 00:04:12,000
pretty much any modern cpu processor

00:04:09,439 --> 00:04:13,599
because the sparse calculations are loop

00:04:12,000 --> 00:04:16,799
heavy

00:04:13,599 --> 00:04:17,359
we have very ubiquitous use of parallel

00:04:16,799 --> 00:04:19,040
00:04:17,359 --> 00:04:20,479
throughout the entire codebase of this

00:04:19,040 --> 00:04:23,600
particular backend

00:04:20,479 --> 00:04:25,759
but because we want response

00:04:23,600 --> 00:04:28,000
operations we want memory utilization to

00:04:25,759 --> 00:04:31,440
be very very high

00:04:28,000 --> 00:04:32,560
there there's a very um advanced use

00:04:31,440 --> 00:04:34,720
atomics

00:04:32,560 --> 00:04:36,400
and there's there's also not just simple

00:04:34,720 --> 00:04:38,800
atomic statement but the

00:04:36,400 --> 00:04:39,600
a lot of code specifies whether the

00:04:38,800 --> 00:04:42,639
atomics

00:04:39,600 --> 00:04:44,880
are read right or perhaps update and

00:04:42,639 --> 00:04:47,840
that allows the openmp to optimize

00:04:44,880 --> 00:04:49,520
very well and use the memory of them of

00:04:47,840 --> 00:04:52,320
the target very well

00:04:49,520 --> 00:04:54,560
and uh there are also a very clever

00:04:52,320 --> 00:04:56,320
reductions that that are necessary for

00:04:54,560 --> 00:04:58,960
the sparse operations that go

00:04:56,320 --> 00:05:00,800
either across rows or columns depending

00:04:58,960 --> 00:05:03,680
on the sparse storage format

00:05:00,800 --> 00:05:05,680
and um some of the reductions are very

00:05:03,680 --> 00:05:06,639
standard that you would use in in most

00:05:05,680 --> 00:05:09,919
textbooks

00:05:06,639 --> 00:05:11,840
such as arithmetic reductions and

00:05:09,919 --> 00:05:14,240
logical operators the first ones are

00:05:11,840 --> 00:05:16,000
mostly for arithmetic the others are

00:05:14,240 --> 00:05:17,759
for the matrix structure but they're

00:05:16,000 --> 00:05:20,560
also declared reductions that are very

00:05:17,759 --> 00:05:24,000
specific to sparse operations

00:05:20,560 --> 00:05:26,400
on sparse matrices and if you compare

00:05:24,000 --> 00:05:27,039
that approach to the approach taken in

00:05:26,400 --> 00:05:30,080
ginkgo

00:05:27,039 --> 00:05:31,440
to uh to maintain its cuda or hip

00:05:30,080 --> 00:05:34,960
beckons

00:05:31,440 --> 00:05:37,280
you can see that the the image gets

00:05:34,960 --> 00:05:38,720
immediately much more complicated so

00:05:37,280 --> 00:05:40,639
porting the uh

00:05:38,720 --> 00:05:42,960
the the cuda back and there was an

00:05:40,639 --> 00:05:45,520
initial back end in the um

00:05:42,960 --> 00:05:48,000
in the ginkgo library to hip required a

00:05:45,520 --> 00:05:50,080
lot of redesign and a lot of code motion

00:05:48,000 --> 00:05:52,000
that is uh exemplified right here with

00:05:50,080 --> 00:05:54,800
this uh this flow diagram

00:05:52,000 --> 00:05:56,400
that kind of tells you how how much uh

00:05:54,800 --> 00:05:59,759
code lines

00:05:56,400 --> 00:06:02,560
were moved from uh between cuda and

00:05:59,759 --> 00:06:04,319
hip and to the common common components

00:06:02,560 --> 00:06:06,639
so that that required resign

00:06:04,319 --> 00:06:08,240
however the the moving from one target

00:06:06,639 --> 00:06:11,759
openmp target to another

00:06:08,240 --> 00:06:13,680
does not require this kind of um

00:06:11,759 --> 00:06:15,919
this kind of code reshuffling it just

00:06:13,680 --> 00:06:19,039
comes out of the box

00:06:15,919 --> 00:06:21,120
um so uh

00:06:19,039 --> 00:06:22,400
again this is to stress the the

00:06:21,120 --> 00:06:25,840
situation of openmp

00:06:22,400 --> 00:06:27,120
that it remains the uh portable and

00:06:25,840 --> 00:06:29,600
efficient target

00:06:27,120 --> 00:06:30,639
for most of the places that support

00:06:29,600 --> 00:06:32,400
openmp

00:06:30,639 --> 00:06:33,759
and we know from the users that that

00:06:32,400 --> 00:06:35,840
that this is the the reference

00:06:33,759 --> 00:06:37,600
implementation that most of the others

00:06:35,840 --> 00:06:40,960
are compensate compared against

00:06:37,600 --> 00:06:43,039
especially for the for the correctness

00:06:40,960 --> 00:06:45,039
cuda and hip are relevant alternatives

00:06:43,039 --> 00:06:46,479
for ginkgo and they would give you a

00:06:45,039 --> 00:06:48,880
good performance on their

00:06:46,479 --> 00:06:49,759
relevant hardware targets but of course

00:06:48,880 --> 00:06:53,199
as i mentioned

00:06:49,759 --> 00:06:56,000
they required the required porting

00:06:53,199 --> 00:06:56,880
and so the the saving grace for the

00:06:56,000 --> 00:06:58,720
porting from

00:06:56,880 --> 00:07:00,240
cuda to hip was that there's a lot of

00:06:58,720 --> 00:07:01,520
similarity in syntax

00:07:00,240 --> 00:07:03,759
there are already a lot of tools

00:07:01,520 --> 00:07:06,800
available uh

00:07:03,759 --> 00:07:09,840
uh for for for making this sport

00:07:06,800 --> 00:07:10,400
boarding exercise and and also the as

00:07:09,840 --> 00:07:12,240
part of the

00:07:10,400 --> 00:07:14,240
porting exercise which partially made it

00:07:12,240 --> 00:07:17,680
hard is that the performance

00:07:14,240 --> 00:07:20,160
had to be roughly comparable because

00:07:17,680 --> 00:07:22,000
between the cuda and hip back ends and

00:07:20,160 --> 00:07:23,680
it wasn't just a matter of functionality

00:07:22,000 --> 00:07:24,960
but also performance because that's what

00:07:23,680 --> 00:07:27,840
our users expect

00:07:24,960 --> 00:07:30,960
so moving on to uh to another library

00:07:27,840 --> 00:07:34,479
that was also developed primarily

00:07:30,960 --> 00:07:37,120
for for gpus is is magma library

00:07:34,479 --> 00:07:39,840
so mango library is is actually not just

00:07:37,120 --> 00:07:42,240
a gpu library it has a lot of hybrid

00:07:39,840 --> 00:07:44,160
algorithms and what it means for for the

00:07:42,240 --> 00:07:44,800
magma library is that both the host

00:07:44,160 --> 00:07:47,039
processor

00:07:44,800 --> 00:07:48,560
and the accelerator they are engaged

00:07:47,039 --> 00:07:50,639
throughout the algorithm and have to

00:07:48,560 --> 00:07:54,319
remain

00:07:50,639 --> 00:07:57,039
efficient so that means that for uh

00:07:54,319 --> 00:08:00,160
we magma has to maintain a very

00:07:57,039 --> 00:08:03,599
efficient implementation of the uh

00:08:00,160 --> 00:08:05,520
of the host processor uh code to uh to

00:08:03,599 --> 00:08:08,639
keep up with sometimes very

00:08:05,520 --> 00:08:09,039
very heavy accelerator heavy uh notes of

00:08:08,639 --> 00:08:12,160
these

00:08:09,039 --> 00:08:17,840
modern exercise exascale platforms so

00:08:12,160 --> 00:08:20,400
we uh we use openmp to maintain this um

00:08:17,840 --> 00:08:21,520
this very high parallelism whenever we

00:08:20,400 --> 00:08:24,000
cannot have

00:08:21,520 --> 00:08:25,199
whenever we cannot access blas or lapack

00:08:24,000 --> 00:08:28,319
libraries

00:08:25,199 --> 00:08:31,840
so openmp reduces our

00:08:28,319 --> 00:08:32,320
development effort on the on on the part

00:08:31,840 --> 00:08:36,080
of the

00:08:32,320 --> 00:08:39,200
the cpu uh part of the algorithm

00:08:36,080 --> 00:08:42,080
and some portions uh might be very

00:08:39,200 --> 00:08:43,039
actually numerically sensitive and for

00:08:42,080 --> 00:08:46,880
those we use

00:08:43,039 --> 00:08:49,440
more advanced features in in openmp

00:08:46,880 --> 00:08:51,040
uh and if you look at the uh the

00:08:49,440 --> 00:08:54,320
functionality that is uh

00:08:51,040 --> 00:08:55,920
that is developed in in magma

00:08:54,320 --> 00:08:57,839
but is relevant on the on the

00:08:55,920 --> 00:09:00,320
accelerator side of the

00:08:57,839 --> 00:09:01,839
of the hardware stack uh there is

00:09:00,320 --> 00:09:03,680
there's a lot of scope and a lot of

00:09:01,839 --> 00:09:04,399
algorithms that actually expose over

00:09:03,680 --> 00:09:06,839
time

00:09:04,399 --> 00:09:08,800
some problems in the in defender vendor

00:09:06,839 --> 00:09:11,519
stacks

00:09:08,800 --> 00:09:13,040
so these have to be uh fixed and they

00:09:11,519 --> 00:09:15,040
were part of the of kind of the

00:09:13,040 --> 00:09:16,800
development effort that that we

00:09:15,040 --> 00:09:19,680
that had to be undertaken just like i

00:09:16,800 --> 00:09:23,120
talked about it during the um

00:09:19,680 --> 00:09:26,800
the port of gingko from cuda to hip

00:09:23,120 --> 00:09:28,720
and right now um we can say

00:09:26,800 --> 00:09:30,560
that a majority of the functionality of

00:09:28,720 --> 00:09:32,720
magma is available

00:09:30,560 --> 00:09:34,480
and is functional and most of it is

00:09:32,720 --> 00:09:36,640
actually very good performance and is

00:09:34,480 --> 00:09:38,640
and is available for for download

00:09:36,640 --> 00:09:40,480
so just to give you a taste of the

00:09:38,640 --> 00:09:45,040
results of uh

00:09:40,480 --> 00:09:48,320
of magma on the uh on a platform

00:09:45,040 --> 00:09:51,920
that is not original uh cuda platform

00:09:48,320 --> 00:09:54,959
this case i'm showing from mi5 and mi 50

00:09:51,920 --> 00:09:58,240
on the last computer intensive

00:09:54,959 --> 00:10:00,720
code that achieves very high performance

00:09:58,240 --> 00:10:01,279
you can see that the uh the chart on the

00:10:00,720 --> 00:10:04,000
left

00:10:01,279 --> 00:10:04,959
shows the the numbers in gigaflops and

00:10:04,000 --> 00:10:07,680
the higher

00:10:04,959 --> 00:10:08,560
the higher value is is better and we are

00:10:07,680 --> 00:10:11,680
compare

00:10:08,560 --> 00:10:13,839
the hip plus versus the the plus that is

00:10:11,680 --> 00:10:17,279
available in magma and that we called uh

00:10:13,839 --> 00:10:20,560
hip magma and so you see that the uh

00:10:17,279 --> 00:10:20,880
the performance approach is very closely

00:10:20,560 --> 00:10:24,000
the

00:10:20,880 --> 00:10:24,640
the theoretical peak for matrices of of

00:10:24,000 --> 00:10:27,120
sizes

00:10:24,640 --> 00:10:29,360
from about a thousand to twenty thousand

00:10:27,120 --> 00:10:32,320
and on the right is an example of a

00:10:29,360 --> 00:10:36,720
kernel that is memory bound and

00:10:32,320 --> 00:10:38,720
for this uh for this particular kernel

00:10:36,720 --> 00:10:39,839
the the performance is a little bit

00:10:38,720 --> 00:10:42,079
lower

00:10:39,839 --> 00:10:42,959
but but also a good performance is is

00:10:42,079 --> 00:10:46,079
achieved

00:10:42,959 --> 00:10:49,360
so uh so this is the uh the portability

00:10:46,079 --> 00:10:52,079
effort in in magma now moving on to uh

00:10:49,360 --> 00:10:54,160
to the plasma library let me first start

00:10:52,079 --> 00:10:56,399
with showing the uh

00:10:54,160 --> 00:10:59,360
this software stack of the of the plasma

00:10:56,399 --> 00:11:01,519
library so you see that the

00:10:59,360 --> 00:11:04,000
on the right heavily featured in the in

00:11:01,519 --> 00:11:07,600
this um

00:11:04,000 --> 00:11:09,760
in this diagram is openmp in fact

00:11:07,600 --> 00:11:10,720
a plasma would not be able to exist in

00:11:09,760 --> 00:11:14,320
its current form

00:11:10,720 --> 00:11:14,640
without openmp because plasma is based

00:11:14,320 --> 00:11:17,440
on

00:11:14,640 --> 00:11:18,320
openmp tasking and data dependence

00:11:17,440 --> 00:11:22,959
clauses

00:11:18,320 --> 00:11:26,000
so you can see that the on the multicore

00:11:22,959 --> 00:11:28,560
hardware it uses either the task

00:11:26,000 --> 00:11:29,760
at a task pragma or it uses task loop

00:11:28,560 --> 00:11:32,880
pragma to uh

00:11:29,760 --> 00:11:35,600
to create a lot of tasks

00:11:32,880 --> 00:11:37,279
uh for the for the platform and also

00:11:35,600 --> 00:11:39,120
uses data clauses to track the

00:11:37,279 --> 00:11:40,800
dependencies between

00:11:39,120 --> 00:11:42,800
between these tasks and i will talk

00:11:40,800 --> 00:11:45,040
about how uh how these are

00:11:42,800 --> 00:11:46,640
achieved in in the next slides and for

00:11:45,040 --> 00:11:50,000
the accelerators with the

00:11:46,640 --> 00:11:52,399
plasma depends for openmp of for data

00:11:50,000 --> 00:11:55,680
transfers and offloading of the kernels

00:11:52,399 --> 00:11:56,000
uh to the accelerator device so let's

00:11:55,680 --> 00:11:59,440
now

00:11:56,000 --> 00:12:00,000
move to why openmp tasking is very

00:11:59,440 --> 00:12:02,880
important

00:12:00,000 --> 00:12:03,600
in in plasma so this is an example of a

00:12:02,880 --> 00:12:07,279
linear

00:12:03,600 --> 00:12:10,160
algebra operation called chileski

00:12:07,279 --> 00:12:11,440
and czeleski allows us to use a

00:12:10,160 --> 00:12:13,600
factorization

00:12:11,440 --> 00:12:16,079
and later on perform the inversion of

00:12:13,600 --> 00:12:19,120
the matrix using that factorization

00:12:16,079 --> 00:12:22,240
and in at higher level this

00:12:19,120 --> 00:12:24,560
is two three independent operations

00:12:22,240 --> 00:12:25,519
one is called dpotrf the other one is

00:12:24,560 --> 00:12:29,600
the la

00:12:25,519 --> 00:12:33,279
um and the final one is dttrtri

00:12:29,600 --> 00:12:35,760
again the names are uh are very um

00:12:33,279 --> 00:12:39,040
meaningful for the for the practitioners

00:12:35,760 --> 00:12:41,760
but perhaps they are less meaningful to

00:12:39,040 --> 00:12:42,160
the common users of openmp the point is

00:12:41,760 --> 00:12:44,399
that

00:12:42,160 --> 00:12:45,200
the first step is a computationally

00:12:44,399 --> 00:12:47,600
heavy

00:12:45,200 --> 00:12:49,279
uh factorization and the next two steps

00:12:47,600 --> 00:12:50,959
perform the actual inversion

00:12:49,279 --> 00:12:52,560
and if you look at the the tasks that

00:12:50,959 --> 00:12:54,720
are involved in this operation

00:12:52,560 --> 00:12:55,680
they are represented as direct accurate

00:12:54,720 --> 00:12:59,360
graphs that are on

00:12:55,680 --> 00:13:02,560
on the right and so uh

00:12:59,360 --> 00:13:05,600
data tracking in openmp allows us to uh

00:13:02,560 --> 00:13:07,680
operate on these on these dags very

00:13:05,600 --> 00:13:09,680
efficiently and do the optimization on

00:13:07,680 --> 00:13:11,279
the flight without actually coding any

00:13:09,680 --> 00:13:14,720
of this optimization

00:13:11,279 --> 00:13:17,200
inside inside plasma so let me show you

00:13:14,720 --> 00:13:18,480
exactly what i mean on the left is are

00:13:17,200 --> 00:13:21,279
the two dags

00:13:18,480 --> 00:13:23,519
and one is the dag when we actually uh

00:13:21,279 --> 00:13:24,800
treat each operation the factorization

00:13:23,519 --> 00:13:27,360
and inversions

00:13:24,800 --> 00:13:28,000
as a separate operation so the dax have

00:13:27,360 --> 00:13:31,120
a

00:13:28,000 --> 00:13:34,800
a barrier between them on the right is

00:13:31,120 --> 00:13:35,519
exactly the same dag but but now it is

00:13:34,800 --> 00:13:38,639
merged

00:13:35,519 --> 00:13:42,000
into a into a single dag and

00:13:38,639 --> 00:13:43,839
the only the only

00:13:42,000 --> 00:13:46,240
difference is that we actually draw

00:13:43,839 --> 00:13:48,880
arrows between the tasks

00:13:46,240 --> 00:13:49,360
in those three dacs and we merge them

00:13:48,880 --> 00:13:52,240
together

00:13:49,360 --> 00:13:54,240
based on the uh based on the data

00:13:52,240 --> 00:13:55,040
dependence and the data dependence is it

00:13:54,240 --> 00:13:59,040
tracked

00:13:55,040 --> 00:14:00,800
fully by the by the openmp uh runtime

00:13:59,040 --> 00:14:02,959
and so what does it do to the

00:14:00,800 --> 00:14:07,360
performance is

00:14:02,959 --> 00:14:10,639
is shown in this um in this

00:14:07,360 --> 00:14:12,480
slide that shows the uh up on top the

00:14:10,639 --> 00:14:12,959
trace when we have all these three darks

00:14:12,480 --> 00:14:16,639
as being

00:14:12,959 --> 00:14:18,880
independent of each other and not

00:14:16,639 --> 00:14:21,040
not communicating data dependencies

00:14:18,880 --> 00:14:24,079
between one operation and the next

00:14:21,040 --> 00:14:25,519
uh down below is what happens when we in

00:14:24,079 --> 00:14:28,000
plasma just allow

00:14:25,519 --> 00:14:29,040
the openmp to manage the data

00:14:28,000 --> 00:14:31,120
dependencies

00:14:29,040 --> 00:14:33,360
and the parallelism in between those

00:14:31,120 --> 00:14:35,279
dacs you can see that

00:14:33,360 --> 00:14:36,399
because the time passes from left to

00:14:35,279 --> 00:14:38,800
right to right

00:14:36,399 --> 00:14:39,920
as as is the case for most of the traces

00:14:38,800 --> 00:14:43,199
you can see

00:14:39,920 --> 00:14:44,959
that the there's a very large reduction

00:14:43,199 --> 00:14:47,920
of the of the time to uh

00:14:44,959 --> 00:14:50,079
complete the the entire operation to the

00:14:47,920 --> 00:14:51,040
extent that that the last operation the

00:14:50,079 --> 00:14:54,320
light blue

00:14:51,040 --> 00:14:56,399
colored tasks are mostly for free

00:14:54,320 --> 00:14:57,440
because that that time is reduced due to

00:14:56,399 --> 00:14:59,120
the overlap and

00:14:57,440 --> 00:15:00,800
tracking the dependencies automatically

00:14:59,120 --> 00:15:03,279
by the

00:15:00,800 --> 00:15:04,240
openmp runtime so let me just move

00:15:03,279 --> 00:15:07,279
finally to the

00:15:04,240 --> 00:15:07,760
to the last library in my presentation

00:15:07,279 --> 00:15:10,399
which is

00:15:07,760 --> 00:15:11,040
which is slide and slide as i mentioned

00:15:10,399 --> 00:15:12,720
combines

00:15:11,040 --> 00:15:15,519
a lot of things from the previous three

00:15:12,720 --> 00:15:18,639
libraries and it targets

00:15:15,519 --> 00:15:21,279
a lot of things uh a lot of

00:15:18,639 --> 00:15:23,199
hardware platforms that the other

00:15:21,279 --> 00:15:23,760
libraries target but in addition to

00:15:23,199 --> 00:15:25,199
those

00:15:23,760 --> 00:15:27,839
so in addition to the multi-core

00:15:25,199 --> 00:15:31,440
processors and the gpu accelerators

00:15:27,839 --> 00:15:34,160
it also targets a distributed memory so

00:15:31,440 --> 00:15:36,560
so it has to use some sort of a library

00:15:34,160 --> 00:15:40,800
in our case for portability

00:15:36,560 --> 00:15:43,360
uh we use a mpi in a multi-threaded mode

00:15:40,800 --> 00:15:44,320
to communicate between the nodes the uh

00:15:43,360 --> 00:15:46,880
the algorithmic

00:15:44,320 --> 00:15:48,160
scope of slate is is very large and

00:15:46,880 --> 00:15:50,399
growing

00:15:48,160 --> 00:15:52,320
with every release so we have all the

00:15:50,399 --> 00:15:54,320
dense algorithms

00:15:52,320 --> 00:15:55,759
that that you would expect in in in

00:15:54,320 --> 00:15:58,399
libraries such as magma

00:15:55,759 --> 00:15:58,959
or or lapak or skellypack we also have

00:15:58,399 --> 00:16:02,240
different

00:15:58,959 --> 00:16:04,639
matrix types and storage storage format

00:16:02,240 --> 00:16:06,880
to cover all the all the cases that

00:16:04,639 --> 00:16:08,399
a lot of applications require and we

00:16:06,880 --> 00:16:12,240
also have a a

00:16:08,399 --> 00:16:14,399
new breed of of algorithms that are um

00:16:12,240 --> 00:16:16,480
they are data sparse they take advantage

00:16:14,399 --> 00:16:19,600
of low rank of of the data

00:16:16,480 --> 00:16:22,480
and um and they uh they allowed

00:16:19,600 --> 00:16:24,240
for much much faster execution however

00:16:22,480 --> 00:16:26,560
in in a sense to coordinate

00:16:24,240 --> 00:16:28,320
all these pieces so the gpu kernels and

00:16:26,560 --> 00:16:31,440
the multi-core

00:16:28,320 --> 00:16:32,880
processors and the invoking of mpi the

00:16:31,440 --> 00:16:34,880
coordination is done by

00:16:32,880 --> 00:16:36,560
openmp tasks and data dependence

00:16:34,880 --> 00:16:40,000
tracking that is done by

00:16:36,560 --> 00:16:42,320
by openmp it is quite similar

00:16:40,000 --> 00:16:43,920
to what happens in in plasma again this

00:16:42,320 --> 00:16:45,440
is a short presentation i don't have the

00:16:43,920 --> 00:16:48,079
time to go into the details

00:16:45,440 --> 00:16:48,639
i encourage you to visit the the web

00:16:48,079 --> 00:16:52,480
page for

00:16:48,639 --> 00:16:55,839
for more details and finally

00:16:52,480 --> 00:16:56,160
let me let me finish by encouraging you

00:16:55,839 --> 00:16:58,639
to

00:16:56,160 --> 00:17:00,240
to look at other videos for the for the

00:16:58,639 --> 00:17:02,639
openmp available at the

00:17:00,240 --> 00:17:05,839
sc20 conference thank you very much for

00:17:02,639 --> 00:17:05,839

YouTube URL: https://www.youtube.com/watch?v=bmz-NqihvVg


