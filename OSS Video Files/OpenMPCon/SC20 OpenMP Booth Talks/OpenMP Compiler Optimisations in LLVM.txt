Title: OpenMP Compiler Optimisations in LLVM
Publication date: 2020-11-06
Playlist: SC20 OpenMP Booth Talks
Description: 
	This presentation, delivered by Johannes Doerfert of Argonne National Laboratory, is part of the OpenMP Booth Talk series created for Supercomputing 2020. A PDF of this presentation as well as more videos from this series can be downloaded at link.openmp.org/sc20
Captions: 
	00:00:07,040 --> 00:00:09,760
hi everyone

00:00:08,000 --> 00:00:11,280
my name is johannes darfur i work at

00:00:09,760 --> 00:00:14,719
cargo national laboratory

00:00:11,280 --> 00:00:16,800
and i'm going to present our self

00:00:14,719 --> 00:00:18,720
effort or the more generic effort of

00:00:16,800 --> 00:00:21,439
openmp compiler optimizations in the

00:00:18,720 --> 00:00:25,519
llvm compiler framework today

00:00:21,439 --> 00:00:27,359
now this talk is adapted from our llvm

00:00:25,519 --> 00:00:30,240
developers talk that we gave

00:00:27,359 --> 00:00:32,160
a few weeks back and if you follow this

00:00:30,240 --> 00:00:34,320
url you can actually find a recording of

00:00:32,160 --> 00:00:37,440
the talk

00:00:34,320 --> 00:00:38,239
so this is this is um overlaps quite a

00:00:37,440 --> 00:00:40,000
bit but this

00:00:38,239 --> 00:00:42,000
i'm kind of my perspective on a couple

00:00:40,000 --> 00:00:42,719
of things and a little bit of updates as

00:00:42,000 --> 00:00:46,879
we speak

00:00:42,719 --> 00:00:49,360
though the slides are fairly similar

00:00:46,879 --> 00:00:50,480
let's start when you think about openmp

00:00:49,360 --> 00:00:54,559
and llvm

00:00:50,480 --> 00:00:56,960
what you usually think about is clang

00:00:54,559 --> 00:00:58,960
clangs open and p handling so you see

00:00:56,960 --> 00:01:01,120
the front end it has an open v parser

00:00:58,960 --> 00:01:02,640
open p semantic analysis maybe with

00:01:01,120 --> 00:01:05,040
warnings and errors

00:01:02,640 --> 00:01:06,400
and an openmp code generation part that

00:01:05,040 --> 00:01:08,479
is what you usually associate with

00:01:06,400 --> 00:01:10,960
openmp and lvm

00:01:08,479 --> 00:01:13,200
now arguably love comes with a bunch of

00:01:10,960 --> 00:01:13,760
openmp runtimes which are also part of

00:01:13,200 --> 00:01:16,960
the

00:01:13,760 --> 00:01:19,360
overall project so there is lib which is

00:01:16,960 --> 00:01:21,439
the classic host openmp runtime

00:01:19,360 --> 00:01:23,119
in their offloading runtimes some of

00:01:21,439 --> 00:01:24,479
which run on the host some of which run

00:01:23,119 --> 00:01:27,200
on the device

00:01:24,479 --> 00:01:28,640
all of which is kind of part of openmp

00:01:27,200 --> 00:01:32,320
in llvm

00:01:28,640 --> 00:01:34,720
now as many of you probably know

00:01:32,320 --> 00:01:36,640
um there is a second openmp front-end

00:01:34,720 --> 00:01:40,320
coming to the lrvm

00:01:36,640 --> 00:01:41,119
framework so we will have flang or we

00:01:40,320 --> 00:01:43,840
already have

00:01:41,119 --> 00:01:45,119
flank as a fortran front end under the

00:01:43,840 --> 00:01:47,280
elevm umbrella

00:01:45,119 --> 00:01:49,040
which has an openmp parser an openmp

00:01:47,280 --> 00:01:49,920
semantic analysis in the normal code

00:01:49,040 --> 00:01:51,840
generation

00:01:49,920 --> 00:01:54,000
and as you can now see that is a lot of

00:01:51,840 --> 00:01:55,920
repetition here compared to clang

00:01:54,000 --> 00:01:57,920
that is why especially the code

00:01:55,920 --> 00:01:59,759
generation part is split out into

00:01:57,920 --> 00:02:00,719
something that is called the openmp ir

00:01:59,759 --> 00:02:03,840
builder

00:02:00,719 --> 00:02:06,399
it's front and independent and it favors

00:02:03,840 --> 00:02:08,720
simple and expressive lvmir that can be

00:02:06,399 --> 00:02:11,120
analyzed and optimized

00:02:08,720 --> 00:02:12,560
better and it's also reusable for

00:02:11,120 --> 00:02:15,599
non-openmp parallelism

00:02:12,560 --> 00:02:17,120
that is either open acc but also if you

00:02:15,599 --> 00:02:19,440
come from a different language that

00:02:17,120 --> 00:02:21,760
doesn't have openmp you can still

00:02:19,440 --> 00:02:23,840
piggyback on the openmp runtime and

00:02:21,760 --> 00:02:27,920
optimizations

00:02:23,840 --> 00:02:30,720
now what this what this enables us to do

00:02:27,920 --> 00:02:31,360
is really to optimize openmp as part of

00:02:30,720 --> 00:02:34,400
the

00:02:31,360 --> 00:02:37,440
as part of the llvm optimization

00:02:34,400 --> 00:02:40,400
pipeline the path that we introduced

00:02:37,440 --> 00:02:41,840
into llvm11 is called openmp opt

00:02:40,400 --> 00:02:44,160
it is an interest procedural

00:02:41,840 --> 00:02:45,040
optimization path that runs by default

00:02:44,160 --> 00:02:48,560
if you specify

00:02:45,040 --> 00:02:50,239
o2 or o3 and it already contains host

00:02:48,560 --> 00:02:52,480
and device optimizations

00:02:50,239 --> 00:02:55,120
though we are still working on more so

00:02:52,480 --> 00:02:56,319
this is just like very early stages of

00:02:55,120 --> 00:02:58,239
this effort

00:02:56,319 --> 00:03:00,879
and but you can see that it's already in

00:02:58,239 --> 00:03:04,239
there it runs by default and you can see

00:03:00,879 --> 00:03:05,440
the results right now if you download

00:03:04,239 --> 00:03:07,840
lvm11

00:03:05,440 --> 00:03:09,280
but you should keep in mind that this is

00:03:07,840 --> 00:03:11,840
an ongoing effort

00:03:09,280 --> 00:03:13,599
in on the docs page that is linked that

00:03:11,840 --> 00:03:14,400
where the link is shown in the top left

00:03:13,599 --> 00:03:17,360
corner

00:03:14,400 --> 00:03:19,440
you can like we're going to continue

00:03:17,360 --> 00:03:21,680
adding more information about this so

00:03:19,440 --> 00:03:23,680
you should regularly visit the

00:03:21,680 --> 00:03:25,519
documentation page you should regularly

00:03:23,680 --> 00:03:27,680
build a new llvm in case you're

00:03:25,519 --> 00:03:29,519
interested in new features but also new

00:03:27,680 --> 00:03:31,920
optimizations

00:03:29,519 --> 00:03:35,760
that said the rest of the talk was will

00:03:31,920 --> 00:03:35,760
be kind of specific about openmp

00:03:36,159 --> 00:03:40,560
one one of our very um fundamental

00:03:39,280 --> 00:03:42,959
design goals here

00:03:40,560 --> 00:03:44,720
is uh that we want to report every

00:03:42,959 --> 00:03:46,239
successful and failed optimization and

00:03:44,720 --> 00:03:47,200
this is something joseph uber from

00:03:46,239 --> 00:03:51,200
oakridge

00:03:47,200 --> 00:03:53,599
is mainly working on and how that looks

00:03:51,200 --> 00:03:55,200
um let's i can i can most easily

00:03:53,599 --> 00:03:58,400
describe a very simple example

00:03:55,200 --> 00:04:01,120
so you have some simple openmp code

00:03:58,400 --> 00:04:02,799
and you call a couple of openmp runtime

00:04:01,120 --> 00:04:04,239
functions and you have a couple of

00:04:02,799 --> 00:04:06,720
directives

00:04:04,239 --> 00:04:07,840
and what you can do what the openmp up

00:04:06,720 --> 00:04:10,000
pass now does

00:04:07,840 --> 00:04:12,840
is it actually eliminates some of these

00:04:10,000 --> 00:04:14,400
runtime calls if it can predict the

00:04:12,840 --> 00:04:16,320
result

00:04:14,400 --> 00:04:18,160
what that helps you is you don't you not

00:04:16,320 --> 00:04:20,160
only have less runtime calls but you

00:04:18,160 --> 00:04:23,360
also have better static analysis

00:04:20,160 --> 00:04:25,440
afterwards which is which is great um

00:04:23,360 --> 00:04:28,320
for for high level optimizations as we

00:04:25,440 --> 00:04:30,160
come to later and

00:04:28,320 --> 00:04:31,680
if you want to know if something like

00:04:30,160 --> 00:04:34,800
this happened you can

00:04:31,680 --> 00:04:37,680
um you can actually run clang

00:04:34,800 --> 00:04:38,560
and ask it for remarks optimization

00:04:37,680 --> 00:04:42,240
remarks

00:04:38,560 --> 00:04:42,560
so minus our pass equal openmp opt gives

00:04:42,240 --> 00:04:44,800
you

00:04:42,560 --> 00:04:46,320
optimization remarks and then if you if

00:04:44,800 --> 00:04:49,360
you also add minus g

00:04:46,320 --> 00:04:51,919
you get um source locations properly

00:04:49,360 --> 00:04:53,280
and as you can see here it will tell you

00:04:51,919 --> 00:04:55,600
that there are these on

00:04:53,280 --> 00:04:57,199
get thread limit calls that have been

00:04:55,600 --> 00:04:59,360
deduplicated

00:04:57,199 --> 00:05:00,479
so you don't actually need to call it

00:04:59,360 --> 00:05:02,479
twice in a row

00:05:00,479 --> 00:05:04,240
you just can call it once and you used

00:05:02,479 --> 00:05:06,800
it use the result twice

00:05:04,240 --> 00:05:09,199
that's basically what this says however

00:05:06,800 --> 00:05:11,280
as you can imagine

00:05:09,199 --> 00:05:13,120
there is it is hard to express

00:05:11,280 --> 00:05:14,400
everything in these remarks which are

00:05:13,120 --> 00:05:17,120
kind of command line

00:05:14,400 --> 00:05:19,039
short texts what we really want to do is

00:05:17,120 --> 00:05:20,960
we want to communicate and explain the

00:05:19,039 --> 00:05:22,400
implementation details to the user in a

00:05:20,960 --> 00:05:25,919
way that is understandable

00:05:22,400 --> 00:05:28,240
and can be acted upon now

00:05:25,919 --> 00:05:30,320
if we take a little bit more comp a

00:05:28,240 --> 00:05:33,520
complicated example but it's still

00:05:30,320 --> 00:05:34,320
really simple and we run remarks on this

00:05:33,520 --> 00:05:36,560
one

00:05:34,320 --> 00:05:38,960
what you will see is a wall of text

00:05:36,560 --> 00:05:41,360
which is arguably not what you want

00:05:38,960 --> 00:05:43,360
but it is really hard to describe these

00:05:41,360 --> 00:05:46,960
things in this text format

00:05:43,360 --> 00:05:48,800
um on the command line so while you see

00:05:46,960 --> 00:05:50,320
this and if you want you can read this

00:05:48,800 --> 00:05:51,919
and try to understand this what will

00:05:50,320 --> 00:05:54,160
actually happen is we will build an

00:05:51,919 --> 00:05:55,199
openmp advisor and we will build an

00:05:54,160 --> 00:05:58,960
openmp

00:05:55,199 --> 00:06:00,639
information information web page

00:05:58,960 --> 00:06:04,160
documentation web page

00:06:00,639 --> 00:06:05,919
and the advisor you can run it

00:06:04,160 --> 00:06:07,840
it's it's part of the current jet

00:06:05,919 --> 00:06:09,759
repository will be part of lvm 12. you

00:06:07,840 --> 00:06:11,680
can run it and it will kind of summarize

00:06:09,759 --> 00:06:12,080
information for you and it tries to kind

00:06:11,680 --> 00:06:14,000
of

00:06:12,080 --> 00:06:15,919
uh over time it will help you to

00:06:14,000 --> 00:06:17,680
understand what is going on

00:06:15,919 --> 00:06:19,120
in a more interactive way in a more

00:06:17,680 --> 00:06:21,919
user-friendly way

00:06:19,120 --> 00:06:23,120
until then you can find optimization

00:06:21,919 --> 00:06:25,520
remark explanation

00:06:23,120 --> 00:06:27,199
examples faqs and so on and so forth on

00:06:25,520 --> 00:06:28,479
our documentation page that was linked

00:06:27,199 --> 00:06:30,960
earlier already

00:06:28,479 --> 00:06:32,800
where we will gradually add them over

00:06:30,960 --> 00:06:33,440
time so it's fairly new it's fairly

00:06:32,800 --> 00:06:35,039
empty

00:06:33,440 --> 00:06:37,440
but that is the place where these things

00:06:35,039 --> 00:06:40,160
will be explained

00:06:37,440 --> 00:06:41,120
and one while we are working on this

00:06:40,160 --> 00:06:43,039
kind of static

00:06:41,120 --> 00:06:44,240
angle so statically providing better

00:06:43,039 --> 00:06:46,000
information to the user

00:06:44,240 --> 00:06:48,080
we're also working on the runtime angles

00:06:46,000 --> 00:06:51,039
so we introduced this slip-on target

00:06:48,080 --> 00:06:51,759
info environment variable that if you

00:06:51,039 --> 00:06:54,800
set it

00:06:51,759 --> 00:06:56,880
with any um clang build it doesn't need

00:06:54,800 --> 00:06:59,039
to be a debug build or anything

00:06:56,880 --> 00:07:00,560
but if you set it and then you run a

00:06:59,039 --> 00:07:02,400
target region

00:07:00,560 --> 00:07:04,000
it will give you information about what

00:07:02,400 --> 00:07:05,759
is happening so it will tell you about

00:07:04,000 --> 00:07:06,960
the cuda blocks the threads the warp

00:07:05,759 --> 00:07:10,000
sizes

00:07:06,960 --> 00:07:11,759
um in in what mode the um

00:07:10,000 --> 00:07:13,680
kernel was launched and so on and so

00:07:11,759 --> 00:07:15,039
forth so a lot of kind of high level

00:07:13,680 --> 00:07:18,560
information

00:07:15,039 --> 00:07:20,479
um from the perspective of the runtime

00:07:18,560 --> 00:07:22,400
are provided here though they are low

00:07:20,479 --> 00:07:24,479
level from the perspective of openmp

00:07:22,400 --> 00:07:27,039
because it's about the implementation

00:07:24,479 --> 00:07:27,919
but with all of this will eventually be

00:07:27,039 --> 00:07:30,880
kind of

00:07:27,919 --> 00:07:34,560
exposed to the advisor interface and

00:07:30,880 --> 00:07:37,759
summarized through the advisor interface

00:07:34,560 --> 00:07:40,000
okay let's switch gears for a second um

00:07:37,759 --> 00:07:42,080
on the static optimization side one of

00:07:40,000 --> 00:07:44,240
the things we really want to do is we

00:07:42,080 --> 00:07:46,560
we want to avoid people doing kind of

00:07:44,240 --> 00:07:48,400
manual low level optimizations

00:07:46,560 --> 00:07:50,560
when they have openmp code and we

00:07:48,400 --> 00:07:51,759
already did studies we know that openmp

00:07:50,560 --> 00:07:54,879
code hinders

00:07:51,759 --> 00:07:56,319
um various existing optimizations so

00:07:54,879 --> 00:07:58,879
this is something that

00:07:56,319 --> 00:07:59,599
that people tend to do to recover that

00:07:58,879 --> 00:08:03,120
loss

00:07:59,599 --> 00:08:03,840
however um we can actually help here as

00:08:03,120 --> 00:08:06,160
well

00:08:03,840 --> 00:08:08,560
and we're well this is already built

00:08:06,160 --> 00:08:12,160
into openmp opt in llvm

00:08:08,560 --> 00:08:14,960
where um if you have

00:08:12,160 --> 00:08:16,000
runtime calls we can potentially predict

00:08:14,960 --> 00:08:18,400
their result

00:08:16,000 --> 00:08:20,639
even if if we don't don't deduplicate

00:08:18,400 --> 00:08:21,840
them but we can just predict the result

00:08:20,639 --> 00:08:24,080
and replace them with

00:08:21,840 --> 00:08:25,599
with the result instead so if you look

00:08:24,080 --> 00:08:27,199
at this example you have a parallel

00:08:25,599 --> 00:08:29,520
region and you call bar

00:08:27,199 --> 00:08:31,120
in if inside of bar you check if you're

00:08:29,520 --> 00:08:33,440
in a parallel region

00:08:31,120 --> 00:08:35,039
and what you can do after you inline

00:08:33,440 --> 00:08:36,959
this for example

00:08:35,039 --> 00:08:39,120
you can really you can really say okay

00:08:36,959 --> 00:08:42,800
after i invite bar into foo

00:08:39,120 --> 00:08:43,519
all this um all this code that is not in

00:08:42,800 --> 00:08:45,839
the

00:08:43,519 --> 00:08:47,440
um or that is not in the red part here

00:08:45,839 --> 00:08:49,200
can be deleted because we already

00:08:47,440 --> 00:08:51,279
know that we're in a parallel region

00:08:49,200 --> 00:08:52,160
right so this is a little bit of

00:08:51,279 --> 00:08:54,320
simplified

00:08:52,160 --> 00:08:55,200
uh view on this but it gives you the

00:08:54,320 --> 00:08:57,040
idea so

00:08:55,200 --> 00:08:58,320
all these internal control variables

00:08:57,040 --> 00:09:02,000
that are basically

00:08:58,320 --> 00:09:04,480
set and checked with these runtime calls

00:09:02,000 --> 00:09:06,080
we can track statically and try to

00:09:04,480 --> 00:09:09,040
replace the getters with

00:09:06,080 --> 00:09:10,480
known values based on directives that we

00:09:09,040 --> 00:09:15,200
see and based on

00:09:10,480 --> 00:09:17,600
setters that we see now

00:09:15,200 --> 00:09:19,680
while low level optimizations and trying

00:09:17,600 --> 00:09:20,800
to kind of avoid these low level runtime

00:09:19,680 --> 00:09:23,920
calls is great

00:09:20,800 --> 00:09:26,560
but the the main point of this really is

00:09:23,920 --> 00:09:27,920
to enable more high level optimizations

00:09:26,560 --> 00:09:30,160
so yogis works

00:09:27,920 --> 00:09:31,440
at lawrence livermore and he is

00:09:30,160 --> 00:09:33,519
currently building

00:09:31,440 --> 00:09:34,959
various high level optimizations into

00:09:33,519 --> 00:09:36,959
openmp opt

00:09:34,959 --> 00:09:38,399
and what is what is most active we're

00:09:36,959 --> 00:09:39,279
working on is the parallel region

00:09:38,399 --> 00:09:42,399
merging

00:09:39,279 --> 00:09:44,720
so this is already inside llvm

00:09:42,399 --> 00:09:45,680
um the current git version so if you

00:09:44,720 --> 00:09:47,760
download it this

00:09:45,680 --> 00:09:50,000
this will actually happen for you so if

00:09:47,760 --> 00:09:51,680
you have adjacent parallel regions you

00:09:50,000 --> 00:09:54,640
don't have to activate all threats

00:09:51,680 --> 00:09:56,640
do the first computation have a barrier

00:09:54,640 --> 00:09:58,800
deactivate all threats more or less like

00:09:56,640 --> 00:10:01,760
like at least

00:09:58,800 --> 00:10:02,320
make them go to to sleep some somehow

00:10:01,760 --> 00:10:03,920
and then

00:10:02,320 --> 00:10:05,839
activate them again for the next pearl

00:10:03,920 --> 00:10:07,760
region what you can instead do is

00:10:05,839 --> 00:10:10,240
activate them only once and have like a

00:10:07,760 --> 00:10:11,920
pragma barrier instead in between

00:10:10,240 --> 00:10:13,440
and we will actually work on removing

00:10:11,920 --> 00:10:15,519
these barriers as well but

00:10:13,440 --> 00:10:16,640
first step is merging these merge these

00:10:15,519 --> 00:10:20,000
parallel regions

00:10:16,640 --> 00:10:22,160
and that can be um as of now we are in

00:10:20,000 --> 00:10:24,560
the process of extending that to allow

00:10:22,160 --> 00:10:25,760
sequential code in between so where we

00:10:24,560 --> 00:10:28,800
guard the

00:10:25,760 --> 00:10:29,440
intermediate code which can really help

00:10:28,800 --> 00:10:35,040
you

00:10:29,440 --> 00:10:35,040
uh in the long run because it exposes

00:10:35,160 --> 00:10:39,600
optimizations inside these parallel

00:10:38,160 --> 00:10:41,760
regions like inside these bigger

00:10:39,600 --> 00:10:44,399
parallel regions you can now have more

00:10:41,760 --> 00:10:48,320
context to do optimizations which was

00:10:44,399 --> 00:10:50,399
harder if you split them apart

00:10:48,320 --> 00:10:52,640
especially when we get to gpus this is

00:10:50,399 --> 00:10:53,920
also very helpful because on gpus

00:10:52,640 --> 00:10:54,720
parallel regions work a little

00:10:53,920 --> 00:10:58,079
differently

00:10:54,720 --> 00:11:02,160
and this will really um lower the openmp

00:10:58,079 --> 00:11:02,160
overhead that people currently observe

00:11:02,399 --> 00:11:08,560
okay now on top of

00:11:05,680 --> 00:11:10,240
these icv trackings and these high-level

00:11:08,560 --> 00:11:12,800
optimizations

00:11:10,240 --> 00:11:14,160
gpus are very important and one thing

00:11:12,800 --> 00:11:17,680
that comes

00:11:14,160 --> 00:11:19,519
up a lot is memory transfer latencies

00:11:17,680 --> 00:11:21,440
where your memory is and when it is

00:11:19,519 --> 00:11:23,279
where is really important for you and it

00:11:21,440 --> 00:11:25,600
is kind of hard to manage it manually so

00:11:23,279 --> 00:11:28,320
what we're actually providing here

00:11:25,600 --> 00:11:30,240
are latency hiding optimizations these

00:11:28,320 --> 00:11:32,399
are currently under development parts of

00:11:30,240 --> 00:11:34,720
which is merged part of which is still

00:11:32,399 --> 00:11:36,959
is still out there but i are going to

00:11:34,720 --> 00:11:39,680
explain like two of the main ideas here

00:11:36,959 --> 00:11:41,440
go for the um dev talk for a little bit

00:11:39,680 --> 00:11:42,000
more details and if you're interested in

00:11:41,440 --> 00:11:45,600
any of this

00:11:42,000 --> 00:11:48,720
just contact us so

00:11:45,600 --> 00:11:49,360
the idea here is that if we see a a

00:11:48,720 --> 00:11:52,160
mapping

00:11:49,360 --> 00:11:53,440
of data to a device what we really want

00:11:52,160 --> 00:11:55,760
to do is we want to

00:11:53,440 --> 00:11:57,760
like issue that mapping issue a memory

00:11:55,760 --> 00:11:59,920
copy as early as possible

00:11:57,760 --> 00:12:01,760
and wait for it to finish as late as

00:11:59,920 --> 00:12:02,800
possible because everything that is in

00:12:01,760 --> 00:12:06,160
between

00:12:02,800 --> 00:12:09,120
of the issue and the weight is now

00:12:06,160 --> 00:12:11,760
is now executed while and hides the

00:12:09,120 --> 00:12:13,680
latency of the actual memory copy

00:12:11,760 --> 00:12:15,360
so if we have this this situation here

00:12:13,680 --> 00:12:16,480
we have some computation that it can

00:12:15,360 --> 00:12:18,800
unrelated and then we

00:12:16,480 --> 00:12:19,920
we map some data to the device and then

00:12:18,800 --> 00:12:21,680
we have a kernel

00:12:19,920 --> 00:12:24,959
what we really want to make out of this

00:12:21,680 --> 00:12:26,320
is we want to first map the data to the

00:12:24,959 --> 00:12:28,880
device

00:12:26,320 --> 00:12:30,880
asynchronously so we want to not wait

00:12:28,880 --> 00:12:32,480
for it to actually go to the device we

00:12:30,880 --> 00:12:35,680
really want to just say okay

00:12:32,480 --> 00:12:38,639
issue the copy and then later we

00:12:35,680 --> 00:12:40,480
wait for the copy to finish such that we

00:12:38,639 --> 00:12:42,240
preserve correctness here

00:12:40,480 --> 00:12:44,079
but now everything that is some

00:12:42,240 --> 00:12:44,959
computation like in this in the same

00:12:44,079 --> 00:12:48,240
computation

00:12:44,959 --> 00:12:51,920
um call is kind of hidden

00:12:48,240 --> 00:12:53,920
heights the latency of the data mapping

00:12:51,920 --> 00:12:55,279
now obviously you have to prove a lot of

00:12:53,920 --> 00:12:58,560
things here

00:12:55,279 --> 00:13:00,800
but again through the remarks we can

00:12:58,560 --> 00:13:02,000
really interact with the user and and

00:13:00,800 --> 00:13:05,040
use the love

00:13:02,000 --> 00:13:06,320
sorry the openmp assume directive to get

00:13:05,040 --> 00:13:08,720
the user to

00:13:06,320 --> 00:13:10,399
um provide us with this with sufficient

00:13:08,720 --> 00:13:12,560
information to make these

00:13:10,399 --> 00:13:14,560
transformations happening in this case

00:13:12,560 --> 00:13:15,839
it was sufficient to really have the

00:13:14,560 --> 00:13:18,240
restrict on the

00:13:15,839 --> 00:13:20,079
on the pointer a and we will be able to

00:13:18,240 --> 00:13:23,279
actually do this

00:13:20,079 --> 00:13:25,680
if the restrict is is there so this is

00:13:23,279 --> 00:13:27,680
not as far-fetched as it might seem

00:13:25,680 --> 00:13:28,880
now if you have a situation where you

00:13:27,680 --> 00:13:32,560
actually map

00:13:28,880 --> 00:13:34,560
to from which is the default for target

00:13:32,560 --> 00:13:36,560
and then you do something and like on

00:13:34,560 --> 00:13:39,440
the device and then you come back

00:13:36,560 --> 00:13:41,360
and then you map to from again it what

00:13:39,440 --> 00:13:43,120
you really want to do is you want to map

00:13:41,360 --> 00:13:44,639
to the device once and you want to map

00:13:43,120 --> 00:13:46,880
from the device once

00:13:44,639 --> 00:13:48,000
and our what we're doing that the way we

00:13:46,880 --> 00:13:49,920
develop this latency

00:13:48,000 --> 00:13:51,600
hiding technique is really going to

00:13:49,920 --> 00:13:54,240
allow us later

00:13:51,600 --> 00:13:56,800
to remove copies all together not only

00:13:54,240 --> 00:13:58,720
to hide latency but to remove copies

00:13:56,800 --> 00:14:02,000
under this basically the same conditions

00:13:58,720 --> 00:14:06,560
as we highlight nancy

00:14:02,000 --> 00:14:09,760
okay now when it comes to this

00:14:06,560 --> 00:14:10,160
memory transfer optimizations one thing

00:14:09,760 --> 00:14:12,240
is

00:14:10,160 --> 00:14:13,360
is really important here to see is that

00:14:12,240 --> 00:14:15,040
while we can do

00:14:13,360 --> 00:14:16,720
certain things while only looking at

00:14:15,040 --> 00:14:18,240
host code

00:14:16,720 --> 00:14:19,839
at the end of the day what you really

00:14:18,240 --> 00:14:20,240
want to do is you want to look at host

00:14:19,839 --> 00:14:24,079
code

00:14:20,240 --> 00:14:26,240
and target code at the same time

00:14:24,079 --> 00:14:28,079
and if you look at a compilation flow of

00:14:26,240 --> 00:14:29,440
openmp right now in most compilers

00:14:28,079 --> 00:14:32,399
including lrvm

00:14:29,440 --> 00:14:33,120
that is not as simple as it might sound

00:14:32,399 --> 00:14:35,519
for that

00:14:33,120 --> 00:14:36,560
to make to form to make that happen

00:14:35,519 --> 00:14:39,680
chile is working

00:14:36,560 --> 00:14:41,040
on heterogeneous lvm ir modules which is

00:14:39,680 --> 00:14:43,920
an

00:14:41,040 --> 00:14:45,760
you can find a rfc on the lvm dev list

00:14:43,920 --> 00:14:48,480
under this link on there

00:14:45,760 --> 00:14:48,959
but i'm going to explain the the general

00:14:48,480 --> 00:14:52,079
idea

00:14:48,959 --> 00:14:53,839
in like one very simple use case first

00:14:52,079 --> 00:14:55,920
so let's assume you have some user code

00:14:53,839 --> 00:14:58,639
which is a single c file and openmp

00:14:55,920 --> 00:14:59,680
everything is in us the host and the

00:14:58,639 --> 00:15:01,920
device code is in

00:14:59,680 --> 00:15:03,279
in the same file right now what the

00:15:01,920 --> 00:15:06,240
compiler does out of this

00:15:03,279 --> 00:15:07,440
is it actually splits it into two files

00:15:06,240 --> 00:15:09,360
like under the hood

00:15:07,440 --> 00:15:11,360
it doesn't split it into c files as

00:15:09,360 --> 00:15:12,880
shown here but for simplicity you can

00:15:11,360 --> 00:15:15,519
assume that

00:15:12,880 --> 00:15:16,720
and what it will do it will try to

00:15:15,519 --> 00:15:18,560
offload

00:15:16,720 --> 00:15:19,920
and if that fails it will go to the host

00:15:18,560 --> 00:15:22,399
fallback code

00:15:19,920 --> 00:15:23,279
and now if you take a regular compiler

00:15:22,399 --> 00:15:26,079
what will happen

00:15:23,279 --> 00:15:27,199
in this case really is it will replace

00:15:26,079 --> 00:15:30,399
these uses of n

00:15:27,199 --> 00:15:31,279
in the host version with the constant

00:15:30,399 --> 00:15:33,680
value

00:15:31,279 --> 00:15:35,519
but not in the device version it will it

00:15:33,680 --> 00:15:36,880
will still kind of wait for the value to

00:15:35,519 --> 00:15:39,040
be sent from the host and then

00:15:36,880 --> 00:15:40,560
use that kind of variable value instead

00:15:39,040 --> 00:15:42,800
of the constant that we

00:15:40,560 --> 00:15:44,720
on the host side know the problem is

00:15:42,800 --> 00:15:45,120
really the constant is part of the host

00:15:44,720 --> 00:15:48,240
code

00:15:45,120 --> 00:15:49,920
not part of the device code and that is

00:15:48,240 --> 00:15:51,600
that is unfortunate because these

00:15:49,920 --> 00:15:53,839
constants can obviously be very

00:15:51,600 --> 00:15:55,839
helpful when it comes to like loop trip

00:15:53,839 --> 00:15:57,839
counts and rolling vectorization your

00:15:55,839 --> 00:15:59,440
name

00:15:57,839 --> 00:16:02,320
so what we're actually going to do is

00:15:59,440 --> 00:16:06,079
we're going to have a heterogeneous

00:16:02,320 --> 00:16:07,600
um translation unit like lvmr file like

00:16:06,079 --> 00:16:10,000
here it's again shown as c

00:16:07,600 --> 00:16:11,839
code in reality it's not c code but

00:16:10,000 --> 00:16:14,079
other vmir

00:16:11,839 --> 00:16:14,880
but the idea is the same so what it

00:16:14,079 --> 00:16:17,199
really says

00:16:14,880 --> 00:16:18,079
is there are now the same functions

00:16:17,199 --> 00:16:20,399
everything is

00:16:18,079 --> 00:16:21,920
more or less the same as it was before

00:16:20,399 --> 00:16:23,279
the difference is that the all these

00:16:21,920 --> 00:16:26,320
functions now have an

00:16:23,279 --> 00:16:28,720
annotation which target um

00:16:26,320 --> 00:16:30,320
they are compiled for target zero for

00:16:28,720 --> 00:16:32,079
the foo function and target one for

00:16:30,320 --> 00:16:34,720
device function seven

00:16:32,079 --> 00:16:36,160
so they are actually going to be

00:16:34,720 --> 00:16:38,639
compiled into different

00:16:36,160 --> 00:16:42,399
assembly like one maybe let's say x86

00:16:38,639 --> 00:16:43,920
and the other one maybe amd gpu

00:16:42,399 --> 00:16:46,480
but then eventually we will probably

00:16:43,920 --> 00:16:48,480
split those again but for the time being

00:16:46,480 --> 00:16:50,639
we keep them in the same

00:16:48,480 --> 00:16:52,160
file in the same scope such that we can

00:16:50,639 --> 00:16:55,279
actually do this

00:16:52,160 --> 00:16:58,560
um constant propagation across

00:16:55,279 --> 00:16:59,920
the device host binder boundary and that

00:16:58,560 --> 00:17:01,279
will actually happen if

00:16:59,920 --> 00:17:03,199
because we have these callback

00:17:01,279 --> 00:17:04,720
annotations already and if you want to

00:17:03,199 --> 00:17:06,319
read up more about that

00:17:04,720 --> 00:17:08,799
please follow that link to the callback

00:17:06,319 --> 00:17:12,319
annotations to see how

00:17:08,799 --> 00:17:16,640
this indirection is actually overcome

00:17:12,319 --> 00:17:18,480
through the callbacks okay

00:17:16,640 --> 00:17:20,319
finally i want to acknowledge our

00:17:18,480 --> 00:17:20,880
support for the solve is as part of the

00:17:20,319 --> 00:17:24,480
ecp

00:17:20,880 --> 00:17:26,079
project and as i mentioned early on

00:17:24,480 --> 00:17:28,240
there were a lot of people involved in

00:17:26,079 --> 00:17:29,280
this and i really like reused the slides

00:17:28,240 --> 00:17:31,360
you saw the names

00:17:29,280 --> 00:17:32,400
in the affiliations during the during

00:17:31,360 --> 00:17:34,559
the talk

00:17:32,400 --> 00:17:36,559
and uh you should feel free to contact

00:17:34,559 --> 00:17:38,960
us you should feel free to

00:17:36,559 --> 00:17:41,039
join our weekly meeting that we have

00:17:38,960 --> 00:17:43,360
about openmp and llvm

00:17:41,039 --> 00:17:45,760
we also have a dedicated openmp

00:17:43,360 --> 00:17:48,880
optimization in other vm meeting

00:17:45,760 --> 00:17:49,520
that is frequented by people that that

00:17:48,880 --> 00:17:51,919
are really

00:17:49,520 --> 00:17:52,880
interested in doing the actual work and

00:17:51,919 --> 00:17:56,240
not only just

00:17:52,880 --> 00:17:56,559
observing um please reach out if any of

00:17:56,240 --> 00:17:58,480
this

00:17:56,559 --> 00:18:00,080
sounds uh sounds interesting to you if

00:17:58,480 --> 00:18:01,200
you want to like participate get more

00:18:00,080 --> 00:18:08,480
information

00:18:01,200 --> 00:18:08,480

YouTube URL: https://www.youtube.com/watch?v=uG5dGvWQu-0


