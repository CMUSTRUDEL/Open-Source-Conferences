Title: Intel Compiler and Runtime Support for OpenMP 4.5 Offloading
Publication date: 2016-11-21
Playlist: SC16 OpenMP Booth Talks
Description: 
	Rakesh Krishnaiyer, Intel
SC16 OpenMP Booth talk, November 2016 Salt Lake City
Captions: 
	00:00:02,840 --> 00:00:09,420
so to motivate this presentation so here

00:00:07,379 --> 00:00:12,570
is a simple example that puts together

00:00:09,420 --> 00:00:14,910
all the different pieces of openmp so we

00:00:12,570 --> 00:00:17,520
want to do the offloading using this

00:00:14,910 --> 00:00:21,330
target constrict and here you can see a

00:00:17,520 --> 00:00:23,160
region of code where you're you want

00:00:21,330 --> 00:00:27,180
this region to be executed on the device

00:00:23,160 --> 00:00:29,730
but inside that region you have a 0 MP

00:00:27,180 --> 00:00:31,859
parallel for and then for the innermost

00:00:29,730 --> 00:00:34,950
loop we are using the openmp simdi

00:00:31,859 --> 00:00:37,760
constructs so and and in addition you

00:00:34,950 --> 00:00:40,860
can see that the innermost loop uses a

00:00:37,760 --> 00:00:44,000
function call and that function call is

00:00:40,860 --> 00:00:47,430
again you have to declare it as to be

00:00:44,000 --> 00:00:49,559
executed on the device and you also make

00:00:47,430 --> 00:00:52,920
a symbian able function out of it so if

00:00:49,559 --> 00:00:55,440
you can call the vectorized version of

00:00:52,920 --> 00:00:58,649
the function inside this loop when the

00:00:55,440 --> 00:01:02,190
compiler is vectorizing this OMP simdi

00:00:58,649 --> 00:01:04,500
loop so this is putting together all the

00:01:02,190 --> 00:01:07,680
three distinct important pieces of

00:01:04,500 --> 00:01:10,790
openmp that you can do today using open

00:01:07,680 --> 00:01:10,790
mp4 point 0 + 4.5

00:01:12,130 --> 00:01:20,070
so the opening p 4.2 supports

00:01:16,869 --> 00:01:24,340
accelerators and coprocessors so the

00:01:20,070 --> 00:01:27,070
device model to begin with is supporting

00:01:24,340 --> 00:01:30,250
only accelerators or coprocessors of the

00:01:27,070 --> 00:01:37,270
same kind from one post so that's how it

00:01:30,250 --> 00:01:39,189
is defined today both in 4.5 so the

00:01:37,270 --> 00:01:42,429
openmp has this concept of a data

00:01:39,189 --> 00:01:46,060
environment so you can have a region of

00:01:42,429 --> 00:01:50,110
code where you define a data environment

00:01:46,060 --> 00:01:54,970
and then for that target region you

00:01:50,110 --> 00:01:57,849
specify the data structures that you are

00:01:54,970 --> 00:02:00,520
mapping from the hose to the device so

00:01:57,849 --> 00:02:03,189
this is a scope data environment region

00:02:00,520 --> 00:02:06,189
so at the beginning of this region you

00:02:03,189 --> 00:02:09,220
are saying that I want map the two means

00:02:06,189 --> 00:02:12,549
from the hose to the device and the from

00:02:09,220 --> 00:02:15,430
is you map it back once the region is

00:02:12,549 --> 00:02:19,799
completed execution on the device so

00:02:15,430 --> 00:02:22,750
here you can see that the mapping of the

00:02:19,799 --> 00:02:24,609
array as well as digital scalar variable

00:02:22,750 --> 00:02:27,579
C and D happens at the beginning of the

00:02:24,609 --> 00:02:32,049
data environment and for the duration of

00:02:27,579 --> 00:02:34,329
this data environment these variables

00:02:32,049 --> 00:02:38,290
will be available on the target device

00:02:34,329 --> 00:02:40,989
and at the end of the region you map the

00:02:38,290 --> 00:02:44,790
result in a back to the host using this

00:02:40,989 --> 00:02:47,500
eight using this map from a 02 count

00:02:44,790 --> 00:02:53,109
this is a more complicated example that

00:02:47,500 --> 00:02:55,540
shows 20 MP target process inside the

00:02:53,109 --> 00:02:57,760
data environment and in between you are

00:02:55,540 --> 00:02:59,440
doing some work on the force so the data

00:02:57,760 --> 00:03:01,510
environment defines the region and

00:02:59,440 --> 00:03:04,120
inside that you can have multiple

00:03:01,510 --> 00:03:06,970
constructs of target constructs which

00:03:04,120 --> 00:03:09,880
define what needs to be executed on the

00:03:06,970 --> 00:03:12,790
target and each of these users OMP

00:03:09,880 --> 00:03:16,090
parallel for for the work partitioning

00:03:12,790 --> 00:03:19,230
among the threads on the device and in

00:03:16,090 --> 00:03:19,230
the thing you are doing some more fun

00:03:21,210 --> 00:03:29,460
so Victoria Victoria CLE this looks like

00:03:25,740 --> 00:03:31,650
this from the host you when you

00:03:29,460 --> 00:03:32,670
encounter the first data environment you

00:03:31,650 --> 00:03:34,530
are doing the allocation of the

00:03:32,670 --> 00:03:37,620
variables that are defined in the data

00:03:34,530 --> 00:03:42,600
environment on the target and then when

00:03:37,620 --> 00:03:45,870
you you actually do the transfer of

00:03:42,600 --> 00:03:49,740
anything that is defined at the data

00:03:45,870 --> 00:03:52,980
environment level and then you when you

00:03:49,740 --> 00:03:55,710
an encounter the target conflict that's

00:03:52,980 --> 00:03:57,920
when the actual execution happens on the

00:03:55,710 --> 00:04:02,580
device and finally when the data

00:03:57,920 --> 00:04:06,180
environment scope is ending you transfer

00:04:02,580 --> 00:04:08,460
the data whatever is defined as from

00:04:06,180 --> 00:04:11,720
some the device back to the hooks using

00:04:08,460 --> 00:04:11,720
this number four

00:04:13,230 --> 00:04:20,860
this is a another example that shows the

00:04:17,400 --> 00:04:22,710
num teams and the distribute constructs

00:04:20,860 --> 00:04:26,560
that are also present in opening theme

00:04:22,710 --> 00:04:29,050
4.0 so here are you were you have a

00:04:26,560 --> 00:04:32,110
target region and then you are saying

00:04:29,050 --> 00:04:34,900
that you want to form a set of teams and

00:04:32,110 --> 00:04:38,110
you are defining the number of teams to

00:04:34,900 --> 00:04:40,990
be 468 and each King having a thread

00:04:38,110 --> 00:04:43,540
limit of 4 so you can think of this as

00:04:40,990 --> 00:04:47,680
like you can you want to offload onto a

00:04:43,540 --> 00:04:50,160
se a que el processor with 68 codes and

00:04:47,680 --> 00:04:55,120
with each code having four threads

00:04:50,160 --> 00:04:57,760
inside that code so here the K loop is

00:04:55,120 --> 00:05:01,480
getting distributed by hand or blocked

00:04:57,760 --> 00:05:04,660
by hand and each of those partitions

00:05:01,480 --> 00:05:07,090
goes to 80 and when it comes to the

00:05:04,660 --> 00:05:10,330
wimpy parallel for that is where the

00:05:07,090 --> 00:05:12,370
threads inside the team take part like

00:05:10,330 --> 00:05:14,470
so the master thread in each team starts

00:05:12,370 --> 00:05:16,240
executing here and when it reaches here

00:05:14,470 --> 00:05:18,040
that is where the work partitioning

00:05:16,240 --> 00:05:21,610
among the threads inside the team

00:05:18,040 --> 00:05:24,790
happens so and and at the end of it and

00:05:21,610 --> 00:05:26,530
you you are translating the data back

00:05:24,790 --> 00:05:28,540
from be so you are doing some

00:05:26,530 --> 00:05:31,180
computation on thee and note that you

00:05:28,540 --> 00:05:33,340
are declared that this function needs to

00:05:31,180 --> 00:05:36,120
be compiled and has to be defined on the

00:05:33,340 --> 00:05:36,120
target device

00:05:37,070 --> 00:05:44,770
so these are some of the 4.5 features

00:05:40,250 --> 00:05:47,990
and all the openmp 4.5 offload

00:05:44,770 --> 00:05:51,110
constructs are supported in the Intel

00:05:47,990 --> 00:05:54,470
17-point o compiler so this is a quick

00:05:51,110 --> 00:05:56,990
summary of the major pieces that have

00:05:54,470 --> 00:05:59,480
been added in 4.5 so we have this if

00:05:56,990 --> 00:06:02,120
clauses like you can you can have a

00:05:59,480 --> 00:06:04,730
combined construct and you can say if

00:06:02,120 --> 00:06:08,000
that applies to only the parallel part

00:06:04,730 --> 00:06:11,300
or the target part so that is a new

00:06:08,000 --> 00:06:14,000
addition in 4.5 you have this concept of

00:06:11,300 --> 00:06:16,400
a device pointer so instead of having

00:06:14,000 --> 00:06:19,480
all the data getting mapped from the

00:06:16,400 --> 00:06:23,780
host to the device if you want to

00:06:19,480 --> 00:06:26,210
transfer data on to something that is

00:06:23,780 --> 00:06:28,810
allocated on the device itself you can

00:06:26,210 --> 00:06:31,100
use this use device pointer this is a

00:06:28,810 --> 00:06:32,930
significant addition to the programming

00:06:31,100 --> 00:06:34,880
model and you will be able to express

00:06:32,930 --> 00:06:37,490
many more things using use device

00:06:34,880 --> 00:06:40,100
pointer and it doesn't require like it

00:06:37,490 --> 00:06:42,500
gets rid of this requirement that you

00:06:40,100 --> 00:06:45,140
need to have the same data structure on

00:06:42,500 --> 00:06:47,060
the host as well as a target so you so

00:06:45,140 --> 00:06:49,160
now you can have some data structures

00:06:47,060 --> 00:06:52,040
only on the target and you can use a

00:06:49,160 --> 00:06:54,620
bigger array on the horse and map it on

00:06:52,040 --> 00:06:58,280
to the smaller re on the device using

00:06:54,620 --> 00:07:01,280
this concept the deferred map constrict

00:06:58,280 --> 00:07:04,220
is like if you have multiple Global

00:07:01,280 --> 00:07:06,200
arrays and you don't want to map all of

00:07:04,220 --> 00:07:09,410
them at the same time on to the target

00:07:06,200 --> 00:07:11,810
because the size will exceed the limits

00:07:09,410 --> 00:07:14,960
of the device then you can use this link

00:07:11,810 --> 00:07:17,240
on straight and it basically will will

00:07:14,960 --> 00:07:21,170
do the mapping only when the target

00:07:17,240 --> 00:07:23,390
construct is encounter the openmp 4.5

00:07:21,170 --> 00:07:25,570
combined constructs these basically

00:07:23,390 --> 00:07:28,340
combine like simpler way of specifying

00:07:25,570 --> 00:07:31,700
the device execution as well as the

00:07:28,340 --> 00:07:34,730
parallelization and the simdi are all in

00:07:31,700 --> 00:07:38,150
one single constant instead of multiple

00:07:34,730 --> 00:07:40,460
lines you can do that today and there

00:07:38,150 --> 00:07:43,250
are also some additions to the clauses

00:07:40,460 --> 00:07:46,130
photo MP target the similar things that

00:07:43,250 --> 00:07:47,780
are supported 40 MP parallel for you can

00:07:46,130 --> 00:07:50,630
do the same thing for target like the

00:07:47,780 --> 00:07:53,690
top you can define a variable as private

00:07:50,630 --> 00:07:56,780
or first private or and also the DS

00:07:53,690 --> 00:08:00,080
device pointer and the default map has

00:07:56,780 --> 00:08:03,080
been changed to like any scalar variable

00:08:00,080 --> 00:08:07,640
gets mapped as true from in the 4.5 this

00:08:03,080 --> 00:08:09,440
is a change from the four point oh so if

00:08:07,640 --> 00:08:11,060
you are used to four point over you may

00:08:09,440 --> 00:08:15,470
want to look at this a little bit more

00:08:11,060 --> 00:08:18,350
carefully and the hashtag no MP target

00:08:15,470 --> 00:08:21,200
data it supports this use device pointer

00:08:18,350 --> 00:08:24,320
which is similar to this these two go

00:08:21,200 --> 00:08:25,880
together and I also mentioned the

00:08:24,320 --> 00:08:28,370
strange addition here so this is

00:08:25,880 --> 00:08:30,440
something that only the Intel compilers

00:08:28,370 --> 00:08:33,890
own syntax supports today and we are

00:08:30,440 --> 00:08:37,990
trying to look into how we can push this

00:08:33,890 --> 00:08:37,990
into openmp for a future version

00:08:38,740 --> 00:08:44,410
so this is a one-page summary of the

00:08:41,890 --> 00:08:47,980
Xeon Phi processor programming models

00:08:44,410 --> 00:08:52,180
that covers both the KNC and the KL so

00:08:47,980 --> 00:08:55,089
the kenal self food systems what we call

00:08:52,180 --> 00:08:57,220
servers and you can that's like a

00:08:55,089 --> 00:09:00,070
regular xeon you can start your program

00:08:57,220 --> 00:09:03,100
there and it's a standalone machine

00:09:00,070 --> 00:09:05,290
running Linux and you can use the cane

00:09:03,100 --> 00:09:08,980
of that way you can use a bunch of

00:09:05,290 --> 00:09:12,640
candles in MPI and OpenMP so you can

00:09:08,980 --> 00:09:17,709
have a cluster running MPI and then use

00:09:12,640 --> 00:09:21,399
OpenMP are within a node you can also

00:09:17,709 --> 00:09:23,770
have used the compiler offload with the

00:09:21,399 --> 00:09:25,899
self boot k neural systems so this is

00:09:23,770 --> 00:09:28,480
intended as a migration path if you have

00:09:25,899 --> 00:09:30,580
existing offload programs that have been

00:09:28,480 --> 00:09:33,730
running on K and C this is a easy way to

00:09:30,580 --> 00:09:35,740
do it and you it basically uses the

00:09:33,730 --> 00:09:38,680
fabric so the computation starts on a

00:09:35,740 --> 00:09:41,140
xeon post and you use a fabric instead

00:09:38,680 --> 00:09:43,600
of the pci express as the transportation

00:09:41,140 --> 00:09:45,339
this is what we call offload over fabric

00:09:43,600 --> 00:09:48,070
I have a couple of slides later that

00:09:45,339 --> 00:09:50,649
explained this in more detail the KNC

00:09:48,070 --> 00:09:53,140
coprocessor or the KNL coprocessor

00:09:50,649 --> 00:09:55,060
programming model so you can forget

00:09:53,140 --> 00:09:57,820
about the PCIe and run the whole program

00:09:55,060 --> 00:09:59,320
on the coprocessor itself this was

00:09:57,820 --> 00:10:01,120
supported in KNC and it will be

00:09:59,320 --> 00:10:04,480
continuing to be supported given on the

00:10:01,120 --> 00:10:06,640
kml card and so you are basically using

00:10:04,480 --> 00:10:10,089
the coprocessor as a standalone machine

00:10:06,640 --> 00:10:13,240
or you can use the MPI plus OpenMP so

00:10:10,089 --> 00:10:18,010
the MPI nodes on the hose and then

00:10:13,240 --> 00:10:20,380
though openmp on the horse as well as

00:10:18,010 --> 00:10:22,209
the card and then you can use OpenMP

00:10:20,380 --> 00:10:26,920
between the card that's not a way of

00:10:22,209 --> 00:10:30,910
using it and the compiler offload is is

00:10:26,920 --> 00:10:33,040
another common usage in the KNC where

00:10:30,910 --> 00:10:36,130
the computation charts on the force and

00:10:33,040 --> 00:10:39,279
over the PCI Express you use the KNC

00:10:36,130 --> 00:10:42,540
card as offload target device for open

00:10:39,279 --> 00:10:42,540
mp4 or 4.1

00:10:42,620 --> 00:10:50,430
so just to give more detail on the

00:10:47,880 --> 00:10:54,060
offload over fabric so you been you're

00:10:50,430 --> 00:10:56,190
so this is the offload over fabric part

00:10:54,060 --> 00:10:58,950
how it looks like so to begin with let

00:10:56,190 --> 00:11:01,800
us look at how the coprocessor looks

00:10:58,950 --> 00:11:03,780
like so you have a yawn node and then

00:11:01,800 --> 00:11:06,030
the two coprocessors say for example

00:11:03,780 --> 00:11:10,650
connected to the Zeon oh and you have a

00:11:06,030 --> 00:11:13,230
bunch of them and the Zeon node uses the

00:11:10,650 --> 00:11:18,320
offload programming model to offload on

00:11:13,230 --> 00:11:22,020
to the two devices when you come to the

00:11:18,320 --> 00:11:24,840
KML offload over fabric again you have a

00:11:22,020 --> 00:11:27,240
bunch of Zeon nodes and these are KNL

00:11:24,840 --> 00:11:30,480
self good systems that are connected to

00:11:27,240 --> 00:11:33,090
wire the fabric with the Zeon nodes so

00:11:30,480 --> 00:11:35,100
the computation starts on the Zeon and

00:11:33,090 --> 00:11:37,200
we use the same offload programming

00:11:35,100 --> 00:11:39,390
model but instead of using the core

00:11:37,200 --> 00:11:42,300
process your you have a way of

00:11:39,390 --> 00:11:44,490
identifying these devices the the what

00:11:42,300 --> 00:11:45,870
we call devices is the cane or sell food

00:11:44,490 --> 00:11:49,170
systems that are connected by other

00:11:45,870 --> 00:11:51,900
fabric and you can use the same open mp4

00:11:49,170 --> 00:11:54,930
point 0 + 4.5 constructs to offload on

00:11:51,900 --> 00:11:56,850
to these devices and the way in which

00:11:54,930 --> 00:11:59,040
you do this you have to use a set of

00:11:56,850 --> 00:12:01,110
environment variables to map from the

00:11:59,040 --> 00:12:03,660
sea on node to the set of devices and

00:12:01,110 --> 00:12:06,480
you can see that in the next slide so

00:12:03,660 --> 00:12:08,940
here the same example that we had here

00:12:06,480 --> 00:12:10,920
where there are six devices we are

00:12:08,940 --> 00:12:13,560
specifying that using the six offload

00:12:10,920 --> 00:12:18,150
nodes here and they are numbered 30 to

00:12:13,560 --> 00:12:22,380
35 and this causes just mean that it's a

00:12:18,150 --> 00:12:25,620
que el node using the ofi interface open

00:12:22,380 --> 00:12:28,830
fabric interface and for each of the

00:12:25,620 --> 00:12:31,380
Xeon nodes you specify the offload

00:12:28,830 --> 00:12:34,200
devices to be a subset of all the

00:12:31,380 --> 00:12:36,930
available 6 so the same set of optimal

00:12:34,200 --> 00:12:40,020
nodes in is used in all the MPI ranks

00:12:36,930 --> 00:12:42,960
but use a subset distinct subset in each

00:12:40,020 --> 00:12:45,120
of those for the off light of devices to

00:12:42,960 --> 00:12:51,450
say that you are offloading only two

00:12:45,120 --> 00:12:55,050
distinct devices from each xeon oh so

00:12:51,450 --> 00:12:58,680
this is a one slide summary of how you

00:12:55,050 --> 00:13:02,820
target for K and C and K and L using the

00:12:58,680 --> 00:13:05,550
17.0 Intel compiler so the option dash

00:13:02,820 --> 00:13:08,000
offload r equals Mike means that you are

00:13:05,550 --> 00:13:11,730
compiling for K and C coprocessor

00:13:08,000 --> 00:13:14,820
offloading to Intel Xeon Phi KNL you use

00:13:11,730 --> 00:13:16,200
the mic a page 512 and then if you are

00:13:14,820 --> 00:13:18,029
using the offload over fabric

00:13:16,200 --> 00:13:19,770
configuration you had also specify these

00:13:18,029 --> 00:13:22,589
offload nodes as we saw in the previous

00:13:19,770 --> 00:13:26,130
slide so what we will have is the

00:13:22,589 --> 00:13:28,320
programs written either using like using

00:13:26,130 --> 00:13:30,450
the offload the programming model openmp

00:13:28,320 --> 00:13:32,790
programming model the same binary will

00:13:30,450 --> 00:13:35,640
work either in the offload fabric mode

00:13:32,790 --> 00:13:39,089
or the pci card based coprocessor moved

00:13:35,640 --> 00:13:44,460
in on a an app and the program is always

00:13:39,089 --> 00:13:46,830
initiated from his Ianto so let us look

00:13:44,460 --> 00:13:50,339
at a few of the new features in openmp

00:13:46,830 --> 00:13:54,720
4.5 so this is the unstructured data

00:13:50,339 --> 00:13:56,700
mapping example so in for photo

00:13:54,720 --> 00:13:59,339
everything has to be defined by this

00:13:56,700 --> 00:14:02,880
data environment that got set up in a

00:13:59,339 --> 00:14:05,100
lexical scope and that we are relaxing

00:14:02,880 --> 00:14:09,630
by using this unstructured data mapping

00:14:05,100 --> 00:14:12,589
so you can have a routine that calls

00:14:09,630 --> 00:14:17,310
other routines and inside each of these

00:14:12,589 --> 00:14:19,740
you want to transfer the data from the

00:14:17,310 --> 00:14:22,529
host to the device in this first routine

00:14:19,740 --> 00:14:26,010
foo and then that's where you use the

00:14:22,529 --> 00:14:29,190
Stargate enter data map to a and then

00:14:26,010 --> 00:14:31,700
you do some work there the array is used

00:14:29,190 --> 00:14:35,720
here and then you can do some other work

00:14:31,700 --> 00:14:39,000
on the device using this only target by

00:14:35,720 --> 00:14:41,220
using in this routine device work to

00:14:39,000 --> 00:14:43,440
which executes on the target and finally

00:14:41,220 --> 00:14:46,800
when you are calling this third routine

00:14:43,440 --> 00:14:48,660
bar inside that you are doing against of

00:14:46,800 --> 00:14:50,400
work on the device but at the end of it

00:14:48,660 --> 00:14:52,080
you are saying that you want you are

00:14:50,400 --> 00:14:53,670
done with this particular data mapping

00:14:52,080 --> 00:14:54,150
and you are transferring it back to the

00:14:53,670 --> 00:14:57,510
whole

00:14:54,150 --> 00:15:00,540
and this kind of thing is possible only

00:14:57,510 --> 00:15:03,290
using this 4.5 you cannot do this using

00:15:00,540 --> 00:15:03,290
four point oh

00:15:04,130 --> 00:15:10,440
this is another example that shows the a

00:15:06,750 --> 00:15:12,960
synchronous execution in 4.5 so you have

00:15:10,440 --> 00:15:14,970
so what this program simple program is

00:15:12,960 --> 00:15:17,910
doing is it's computing the product of

00:15:14,970 --> 00:15:20,580
two vectors given and we do but half of

00:15:17,910 --> 00:15:22,800
it is being done on the force and how it

00:15:20,580 --> 00:15:24,840
is being done on the device and both are

00:15:22,800 --> 00:15:27,150
happening simultaneously so the way you

00:15:24,840 --> 00:15:30,330
do it is you have a right now empty

00:15:27,150 --> 00:15:32,520
parallel and then though on the host and

00:15:30,330 --> 00:15:36,420
then though on the master thread on the

00:15:32,520 --> 00:15:41,190
host initiates this target concentrate

00:15:36,420 --> 00:15:42,980
and notice there's no weight on the boss

00:15:41,190 --> 00:15:47,550
that means that the master thread

00:15:42,980 --> 00:15:50,070
initiates this device execution and it

00:15:47,550 --> 00:15:52,020
goes ahead and does other stuff useful

00:15:50,070 --> 00:15:54,030
stuff on the horse so this is the part

00:15:52,020 --> 00:15:56,360
that is doing the half of the

00:15:54,030 --> 00:15:59,340
computation the second half of the

00:15:56,360 --> 00:16:02,280
computation here and note that we use

00:15:59,340 --> 00:16:03,840
the dynamic scheduling here because one

00:16:02,280 --> 00:16:06,720
of the threads is busy doing other stuff

00:16:03,840 --> 00:16:08,780
so in order to make sure the load

00:16:06,720 --> 00:16:12,510
balancing is better you use the dynamic

00:16:08,780 --> 00:16:14,610
scheduling here but there is an implicit

00:16:12,510 --> 00:16:16,350
barrier at the end of this that make

00:16:14,610 --> 00:16:19,110
sure that oh the target and device

00:16:16,350 --> 00:16:20,460
computations are done and then at this

00:16:19,110 --> 00:16:23,340
point everything is done and you can

00:16:20,460 --> 00:16:26,730
print out your values so this is a

00:16:23,340 --> 00:16:28,620
powerful way of making programs that

00:16:26,730 --> 00:16:30,150
have portions that are running on the

00:16:28,620 --> 00:16:31,980
horse and at the same time you want to

00:16:30,150 --> 00:16:35,630
do something on the target and this is

00:16:31,980 --> 00:16:35,630
supported in 4.5

00:16:36,179 --> 00:16:43,479
so this is a collection of simple

00:16:39,819 --> 00:16:47,109
benchmarks that we we have in house that

00:16:43,479 --> 00:16:50,379
we run I using the openmp offload

00:16:47,109 --> 00:16:52,089
versions as well as our own internal do

00:16:50,379 --> 00:16:56,049
versions their language extensions for

00:16:52,089 --> 00:17:00,369
offload so these constructs are Leo Kahn

00:16:56,049 --> 00:17:02,049
predates OpenMP but the internally the

00:17:00,369 --> 00:17:03,759
implementation for both of them is more

00:17:02,049 --> 00:17:06,069
or less similar both of the map to the

00:17:03,759 --> 00:17:09,100
similar ir and the same runtime is used

00:17:06,069 --> 00:17:10,720
for both so we don't expect if much a

00:17:09,100 --> 00:17:12,279
large performance difference between the

00:17:10,720 --> 00:17:16,509
two and that's exactly what the graph is

00:17:12,279 --> 00:17:18,429
showing this note the range here is just

00:17:16,509 --> 00:17:20,860
between point nine seven and one point

00:17:18,429 --> 00:17:24,569
zero one so the performance is more or

00:17:20,860 --> 00:17:24,569
less similar for all of these versions

00:17:26,930 --> 00:17:34,800
this is another slide I just want to put

00:17:30,960 --> 00:17:37,770
it up there because the Intel compilers

00:17:34,800 --> 00:17:40,320
of load programming model was used for

00:17:37,770 --> 00:17:43,200
one of the Gordon Bell submissions in AC

00:17:40,320 --> 00:17:46,260
14 and this is a research project

00:17:43,200 --> 00:17:48,000
project that is furthering the

00:17:46,260 --> 00:17:52,850
understanding of earthquakes by using

00:17:48,000 --> 00:17:55,740
numerical simulation and their entire

00:17:52,850 --> 00:17:57,750
programming model was based on this

00:17:55,740 --> 00:18:01,230
awful program model on to the KNC

00:17:57,750 --> 00:18:04,050
coprocessor at that time 2014 and you

00:18:01,230 --> 00:18:07,590
basically use the interview that was

00:18:04,050 --> 00:18:09,510
what we had at that time and it uses a

00:18:07,590 --> 00:18:11,520
pragma directives for a success data

00:18:09,510 --> 00:18:17,310
transfers and program execution of the

00:18:11,520 --> 00:18:19,350
Xeon Phi device so please take a look

00:18:17,310 --> 00:18:22,080
there are a lot more details in this

00:18:19,350 --> 00:18:24,860
link which talks which gives a link to

00:18:22,080 --> 00:18:24,860
the paper aspect

00:18:24,980 --> 00:18:36,040
yeah I think that's all I had for the

00:18:29,630 --> 00:18:36,040

YouTube URL: https://www.youtube.com/watch?v=acmvWjbJjBo


