Title: Sorting Things Out With Tasks
Publication date: 2016-11-21
Playlist: SC16 OpenMP Booth Talks
Description: 
	Ruud van der Pas, Oracle
SC16 OpenMP Booth talk - November 2016 Salt Lake City
Captions: 
	00:00:00,410 --> 00:00:04,799
alright good afternoon thank you for

00:00:03,240 --> 00:00:07,370
being here and listening to this talk

00:00:04,799 --> 00:00:10,230
it's going to be about asking and

00:00:07,370 --> 00:00:12,599
tasking is has been an opening p for

00:00:10,230 --> 00:00:15,929
quite a while but we feel that not

00:00:12,599 --> 00:00:17,910
enough people use it and i think that's

00:00:15,929 --> 00:00:20,820
because it's quite intimidating it's

00:00:17,910 --> 00:00:22,740
some sort of a unconventional concept

00:00:20,820 --> 00:00:25,019
within OpenMP but it actually is quite

00:00:22,740 --> 00:00:27,539
powerful so the whole goal of this talk

00:00:25,019 --> 00:00:33,860
is to make you more familiar with how to

00:00:27,539 --> 00:00:36,090
asking works in OpenMP in the old days

00:00:33,860 --> 00:00:38,040
from an opening people interview

00:00:36,090 --> 00:00:44,190
everything had to be known when you had

00:00:38,040 --> 00:00:47,520
a look everything had to be known when

00:00:44,190 --> 00:00:50,309
you had sections parallel sections there

00:00:47,520 --> 00:00:52,829
was a finite number of sections that

00:00:50,309 --> 00:00:57,000
countable so everything had to be known

00:00:52,829 --> 00:00:59,190
and that got increasingly difficult with

00:00:57,000 --> 00:01:01,949
more dynamic algorithms in the standard

00:00:59,190 --> 00:01:03,989
example is when you when you go through

00:01:01,949 --> 00:01:08,340
a linked list you don't know when the

00:01:03,989 --> 00:01:13,890
list will will end so see if I can move

00:01:08,340 --> 00:01:15,810
this a little bit usually there was some

00:01:13,890 --> 00:01:19,500
sort of a solution but it was ugly at

00:01:15,810 --> 00:01:22,500
best and that's what white asking was

00:01:19,500 --> 00:01:24,299
put into OpenMP and it was built upon an

00:01:22,500 --> 00:01:26,670
earlier tasking implementation in

00:01:24,299 --> 00:01:29,850
another compiler so there was already

00:01:26,670 --> 00:01:33,390
some prior experience and that came in

00:01:29,850 --> 00:01:38,100
OpenMP and again I'm going to try to

00:01:33,390 --> 00:01:41,670
show you how that all works and there's

00:01:38,100 --> 00:01:44,670
a big but no formal terminology

00:01:41,670 --> 00:01:46,500
definitions and all of that stuff I'm

00:01:44,670 --> 00:01:49,950
just going to explain it in normal

00:01:46,500 --> 00:01:51,810
readable understandable words the

00:01:49,950 --> 00:01:54,000
lawyers have written the specifications

00:01:51,810 --> 00:01:56,280
and I'm not going to do that so what's a

00:01:54,000 --> 00:02:00,090
task a task is a it's a chunk of work

00:01:56,280 --> 00:02:02,070
and your responsibility is you guarantee

00:02:00,090 --> 00:02:05,159
to the runtime systems that tasks can be

00:02:02,070 --> 00:02:06,509
executed simultaneously that's pretty

00:02:05,159 --> 00:02:10,979
much the only thing you need to worry

00:02:06,509 --> 00:02:12,780
about and this is how you do that i'll

00:02:10,979 --> 00:02:15,930
try to show very little code

00:02:12,780 --> 00:02:18,600
actually but sometimes I have to provide

00:02:15,930 --> 00:02:20,310
my OMP task and whatever you put in a

00:02:18,600 --> 00:02:25,560
code block that's going to be that

00:02:20,310 --> 00:02:27,690
independent portion of work the rest is

00:02:25,560 --> 00:02:28,980
under control of the runtime system now

00:02:27,690 --> 00:02:31,440
that's a mixed blessing because

00:02:28,980 --> 00:02:34,680
sometimes you want some more control and

00:02:31,440 --> 00:02:37,440
that's on that's happening now as as we

00:02:34,680 --> 00:02:39,230
move into future releases of openmp

00:02:37,440 --> 00:02:42,600
there's going to be more control over

00:02:39,230 --> 00:02:45,810
tasks okay right now you don't have a

00:02:42,600 --> 00:02:49,590
lot but it's it started coming for

00:02:45,810 --> 00:02:52,530
example when our tasks completed so

00:02:49,590 --> 00:02:54,570
internally they put on a queue and IQ is

00:02:52,530 --> 00:02:56,250
being depleted as you execute the

00:02:54,570 --> 00:02:58,830
program when when you have the guarantee

00:02:56,250 --> 00:03:00,980
that the task that all the task have

00:02:58,830 --> 00:03:02,850
completed there are implicit task

00:03:00,980 --> 00:03:04,230
scheduling points where this is

00:03:02,850 --> 00:03:09,870
guaranteed or you can put them in

00:03:04,230 --> 00:03:14,300
yourself now just for those of you who

00:03:09,870 --> 00:03:19,079
want to study things in all detail

00:03:14,300 --> 00:03:23,820
here's the following advice when it yes

00:03:19,079 --> 00:03:25,739
and this is what it looks like this time

00:03:23,820 --> 00:03:28,620
it stands for recognized the fabulous

00:03:25,739 --> 00:03:30,900
masters and we have this awfully

00:03:28,620 --> 00:03:33,750
good-looking guy in this shirt you may

00:03:30,900 --> 00:03:35,400
find him or her in this booth and they

00:03:33,750 --> 00:03:37,410
are on booth duty and they're more than

00:03:35,400 --> 00:03:40,410
willing to help you and explain you all

00:03:37,410 --> 00:03:42,739
the all the ins and outs of openmp

00:03:40,410 --> 00:03:46,140
that's why I'm not wearing that shirt

00:03:42,739 --> 00:03:48,299
okay all right let's get into the meat

00:03:46,140 --> 00:03:51,209
of things that asking concept in OpenMP

00:03:48,299 --> 00:03:54,890
here's the kind of the idea how you're

00:03:51,209 --> 00:03:59,160
supposed to use tasks there's one thread

00:03:54,890 --> 00:04:01,470
that will generate the tasks these tasks

00:03:59,160 --> 00:04:04,290
are being put onto the queue so as they

00:04:01,470 --> 00:04:07,109
are generated other threads that are

00:04:04,290 --> 00:04:10,829
available to execute work they'll start

00:04:07,109 --> 00:04:12,720
depleting that queue yeah so and

00:04:10,829 --> 00:04:15,209
eventually when this first thread has

00:04:12,720 --> 00:04:17,669
finished it can join the gang and start

00:04:15,209 --> 00:04:19,859
executing as well and as I said at some

00:04:17,669 --> 00:04:21,750
point these tasks are finished it's

00:04:19,859 --> 00:04:24,390
well-defined when that is and they're

00:04:21,750 --> 00:04:26,300
employed point and you can enforce task

00:04:24,390 --> 00:04:29,780
execution to be

00:04:26,300 --> 00:04:34,350
completed before your program continues

00:04:29,780 --> 00:04:37,020
so again your your responsibilities you

00:04:34,350 --> 00:04:39,330
identify the task you use the pragma 1p

00:04:37,020 --> 00:04:43,710
task and you put them into a parallel

00:04:39,330 --> 00:04:46,200
region and then the runtime system it

00:04:43,710 --> 00:04:49,650
will encounter those tasks start

00:04:46,200 --> 00:04:52,410
executing them and that's up to you and

00:04:49,650 --> 00:04:55,100
on your way okay one of the things is

00:04:52,410 --> 00:04:57,420
there's a notion of deferred tasks

00:04:55,100 --> 00:05:01,290
there's going to be a thing like task

00:04:57,420 --> 00:05:03,180
priorities so this gradually ways to

00:05:01,290 --> 00:05:06,090
control it but by and large this is how

00:05:03,180 --> 00:05:08,340
it how it all works the important thing

00:05:06,090 --> 00:05:10,770
is there's a task synchronization point

00:05:08,340 --> 00:05:13,890
and at that point tasks are being

00:05:10,770 --> 00:05:15,870
executed and again they're implied and

00:05:13,890 --> 00:05:17,220
explicit it's a little bit like the

00:05:15,870 --> 00:05:21,570
barrier you know you have implied

00:05:17,220 --> 00:05:25,020
barriers and explicit barriers so i'm

00:05:21,570 --> 00:05:26,760
going to show you one example and i try

00:05:25,020 --> 00:05:29,160
to find the simplest of simplest

00:05:26,760 --> 00:05:30,840
examples because i think one of the

00:05:29,160 --> 00:05:33,510
mistakes we make when we introduced

00:05:30,840 --> 00:05:36,480
asking the examples were too complicated

00:05:33,510 --> 00:05:42,330
to specific and i found one you'll see

00:05:36,480 --> 00:05:45,090
me only using print statements so your

00:05:42,330 --> 00:05:48,030
task is you have to write a program that

00:05:45,090 --> 00:05:51,570
either prints a race car or a car race

00:05:48,030 --> 00:05:57,390
and maximize the parallelism in in that

00:05:51,570 --> 00:06:00,150
task all right well this will be the

00:05:57,390 --> 00:06:02,250
sequential version 3 print statements

00:06:00,150 --> 00:06:04,050
not necessarily the most efficient way

00:06:02,250 --> 00:06:06,030
to do that print but okay I got three

00:06:04,050 --> 00:06:09,060
chunks of work doing a print statement

00:06:06,030 --> 00:06:13,020
and of course whatever print is a race

00:06:09,060 --> 00:06:15,950
car but it's not parallel naively I

00:06:13,020 --> 00:06:18,900
could embed this in a parallel region

00:06:15,950 --> 00:06:21,180
but within OpenMP the roll is all

00:06:18,900 --> 00:06:25,320
threads execute all code in the parallel

00:06:21,180 --> 00:06:26,850
region so I don't like asking questions

00:06:25,320 --> 00:06:29,760
to the audience so these are all with

00:06:26,850 --> 00:06:32,340
Oracle questions there will be some kind

00:06:29,760 --> 00:06:35,760
of question later on but what will this

00:06:32,340 --> 00:06:38,790
print well it will actually print an

00:06:35,760 --> 00:06:39,990
arbitrary combination of a race car door

00:06:38,790 --> 00:06:41,880
race car but in a

00:06:39,990 --> 00:06:44,010
striped order because we're still in the

00:06:41,880 --> 00:06:46,140
parallel region so you could have a a

00:06:44,010 --> 00:06:48,390
race race car and all sort of

00:06:46,140 --> 00:06:50,490
permutations of that although not all

00:06:48,390 --> 00:06:52,200
possible combinations because the print

00:06:50,490 --> 00:06:55,350
statements in the parallel region will

00:06:52,200 --> 00:06:57,270
be executed sequentially ok but this

00:06:55,350 --> 00:06:59,880
these are possible outcomes but it

00:06:57,270 --> 00:07:06,450
doesn't print what we got asked to

00:06:59,880 --> 00:07:08,460
deliver so while we could cheat and put

00:07:06,450 --> 00:07:11,430
this into a single region and then we'll

00:07:08,460 --> 00:07:15,630
get a race car but we'll always of

00:07:11,430 --> 00:07:18,270
course get a race car being printed so

00:07:15,630 --> 00:07:21,840
that's pretty bored and certainly no

00:07:18,270 --> 00:07:24,960
parallelism here well this is where

00:07:21,840 --> 00:07:27,450
tasking comes in what we could do we

00:07:24,960 --> 00:07:31,410
could make printing race and printing

00:07:27,450 --> 00:07:34,890
car each a task now there's a funny

00:07:31,410 --> 00:07:37,440
thing here that's one of those confusing

00:07:34,890 --> 00:07:42,120
things note that i still have my OMP

00:07:37,440 --> 00:07:43,980
single because i want one thread and i'm

00:07:42,120 --> 00:07:48,470
going to slow down a bit here i want one

00:07:43,980 --> 00:07:51,330
thread to generate those two tasks

00:07:48,470 --> 00:07:54,630
otherwise i'll have input on two threads

00:07:51,330 --> 00:07:56,190
i have four tasks or two times the

00:07:54,630 --> 00:07:58,530
number of threads that i have so that's

00:07:56,190 --> 00:08:01,620
not what i want the one of the

00:07:58,530 --> 00:08:03,810
conceptual issues with tasking is the

00:08:01,620 --> 00:08:08,070
task could not necessarily execute it

00:08:03,810 --> 00:08:11,910
where you see it so the tasks are

00:08:08,070 --> 00:08:16,140
generated here but I only executed at

00:08:11,910 --> 00:08:21,030
the task synchronization point and one

00:08:16,140 --> 00:08:23,760
of those is the barrier ok so you have

00:08:21,030 --> 00:08:25,830
to think as tasks being generated and

00:08:23,760 --> 00:08:27,030
executed and that's decoupled that

00:08:25,830 --> 00:08:28,740
that's a kind of a different way of

00:08:27,030 --> 00:08:30,810
thinking and makes tasking a little

00:08:28,740 --> 00:08:34,760
little awkward especially in the

00:08:30,810 --> 00:08:38,370
beginning so what will this print well

00:08:34,760 --> 00:08:43,260
depending on which task get executed we

00:08:38,370 --> 00:08:45,960
achieved our goal and I hope that is

00:08:43,260 --> 00:08:50,730
clear that this is a simple way to get

00:08:45,960 --> 00:08:54,650
this done and to preempt a question you

00:08:50,730 --> 00:08:54,650
can do this with parallel sections

00:08:56,260 --> 00:09:03,710
well you know you're very good students

00:08:59,300 --> 00:09:06,890
you did well and quickly so now let's

00:09:03,710 --> 00:09:09,110
add something to the sentence I want to

00:09:06,890 --> 00:09:13,130
have the sentence and with is fun to

00:09:09,110 --> 00:09:15,529
watch and as I found usual when I took

00:09:13,130 --> 00:09:17,510
classes I got to use this hint from my

00:09:15,529 --> 00:09:19,070
professor that I don't even understand

00:09:17,510 --> 00:09:20,510
what you're trying to tell me so the

00:09:19,070 --> 00:09:22,190
useless hint here is use a print

00:09:20,510 --> 00:09:27,010
statement of course we have to use a

00:09:22,190 --> 00:09:30,410
print statement for them all right so

00:09:27,010 --> 00:09:33,820
what we do is we have our tasks and in

00:09:30,410 --> 00:09:38,600
red is the new thing to be added to it

00:09:33,820 --> 00:09:42,100
now here's the challenge this will most

00:09:38,600 --> 00:09:46,820
likely not do what you think it will do

00:09:42,100 --> 00:09:48,890
anybody who cares to guess why by the

00:09:46,820 --> 00:09:55,460
way the most active participant will get

00:09:48,890 --> 00:09:58,900
a t-shirt so yep okay well as it all is

00:09:55,460 --> 00:09:58,900
both because

00:10:02,040 --> 00:10:04,880
secure

00:10:05,660 --> 00:10:09,830
exactly I think that was what you're

00:10:07,790 --> 00:10:13,850
trying to say yeah oh yeah you don't

00:10:09,830 --> 00:10:15,530
have that guarantee and indeed this is

00:10:13,850 --> 00:10:17,630
the kind of thing I rented a couple of

00:10:15,530 --> 00:10:20,420
times and you get fairly broken English

00:10:17,630 --> 00:10:22,970
out of your out of your program because

00:10:20,420 --> 00:10:25,430
indeed as we said I should say that on

00:10:22,970 --> 00:10:29,510
the microphone as well that you don't

00:10:25,430 --> 00:10:32,180
know the task typically will be executed

00:10:29,510 --> 00:10:35,000
after that print statement because the

00:10:32,180 --> 00:10:38,180
barrier is a task synchronization point

00:10:35,000 --> 00:10:40,220
and both the single and the parallel

00:10:38,180 --> 00:10:41,810
have an implied barrier so the first

00:10:40,220 --> 00:10:44,360
barrier you hit is the one that is

00:10:41,810 --> 00:10:46,280
implied with the single and that's where

00:10:44,360 --> 00:10:51,350
the task will be executed but meanwhile

00:10:46,280 --> 00:10:53,360
you already printed a is fun to watch so

00:10:51,350 --> 00:10:55,280
that's why the a was always first

00:10:53,360 --> 00:10:58,190
because that was the sequential order so

00:10:55,280 --> 00:11:04,550
you got it right and that kind of it

00:10:58,190 --> 00:11:08,200
takes a while to get used to and what we

00:11:04,550 --> 00:11:11,240
have is the task wait the task way is

00:11:08,200 --> 00:11:13,640
the task is task synchronization point

00:11:11,240 --> 00:11:16,930
an explicit one so what you'll do is

00:11:13,640 --> 00:11:21,770
when you put in the task way to enforce

00:11:16,930 --> 00:11:23,510
execution of the children tasks and then

00:11:21,770 --> 00:11:25,310
you know when you print is fun to watch

00:11:23,510 --> 00:11:28,700
all the tasks have been executed and we

00:11:25,310 --> 00:11:35,650
achieve our goal so the solution is

00:11:28,700 --> 00:11:39,230
quite easy no and it works as advertised

00:11:35,650 --> 00:11:41,690
the last example I want to show that was

00:11:39,230 --> 00:11:44,840
the whole goal of this talk is show a

00:11:41,690 --> 00:11:47,510
more real world example so set the stage

00:11:44,840 --> 00:11:52,460
now and I started looking at the

00:11:47,510 --> 00:11:55,100
quicksort algorithm and that's what I'm

00:11:52,460 --> 00:11:57,650
now going to do I'm you may be familiar

00:11:55,100 --> 00:11:59,810
with it and if so I'm sorry for going

00:11:57,650 --> 00:12:01,970
through the whole algorithm but it's

00:11:59,810 --> 00:12:03,710
quite commonly used and there's a lot of

00:12:01,970 --> 00:12:06,130
sorting algorithms but I picked the

00:12:03,710 --> 00:12:09,170
quicksort and it uses a

00:12:06,130 --> 00:12:12,350
divide-and-conquer strategy and asking

00:12:09,170 --> 00:12:14,930
tasking is perfect for certain class of

00:12:12,350 --> 00:12:17,030
algorithms recursive algorithms I

00:12:14,930 --> 00:12:18,980
mentioned the linked list and divide and

00:12:17,030 --> 00:12:21,860
conquer there's a very natural mapping

00:12:18,980 --> 00:12:25,699
as I hope to show to the algorithm and

00:12:21,860 --> 00:12:27,740
the tasks though the main steps in the

00:12:25,699 --> 00:12:30,949
algorithm and again I try to show as

00:12:27,740 --> 00:12:34,579
little code as possible you choose what

00:12:30,949 --> 00:12:39,079
is called the pivot and you split the

00:12:34,579 --> 00:12:42,170
array at the pivot point and you're

00:12:39,079 --> 00:12:44,240
going to move the elements in such a way

00:12:42,170 --> 00:12:47,750
that all elements to the left of the

00:12:44,240 --> 00:12:50,089
pivot are smaller and to the right are

00:12:47,750 --> 00:12:52,579
larger they're not necessarily sorted

00:12:50,089 --> 00:12:55,720
among themselves but you know there's a

00:12:52,579 --> 00:12:59,839
dividing line between the values and

00:12:55,720 --> 00:13:01,880
then of course you can repeat that for

00:12:59,839 --> 00:13:06,290
the left and right part and you have

00:13:01,880 --> 00:13:08,839
your policy until you're done so that's

00:13:06,290 --> 00:13:10,190
the high-level steps that you need to

00:13:08,839 --> 00:13:15,110
take and this is where the parallelism

00:13:10,190 --> 00:13:18,139
comes in so here's a very simple example

00:13:15,110 --> 00:13:19,699
and I try to use color coding I'm not

00:13:18,139 --> 00:13:21,320
really good at those animations and

00:13:19,699 --> 00:13:23,660
usually animations go too quick for me

00:13:21,320 --> 00:13:26,660
to get them anyhow so I'll do that step

00:13:23,660 --> 00:13:29,959
by step so here's my initial these are

00:13:26,660 --> 00:13:32,959
my initial values the one mark Greene is

00:13:29,959 --> 00:13:34,459
my pivot and one of the parameters in

00:13:32,959 --> 00:13:36,769
this algorithm is how do you choose your

00:13:34,459 --> 00:13:38,750
pivot there have been a lot of studies

00:13:36,769 --> 00:13:41,230
on how that affects the efficiency of

00:13:38,750 --> 00:13:44,920
the algorithm here for load balancing

00:13:41,230 --> 00:13:47,209
reasons I'd like to choose the middle

00:13:44,920 --> 00:13:49,399
although you don't have any load

00:13:47,209 --> 00:13:51,319
balancing as you go through the data for

00:13:49,399 --> 00:13:57,560
the wrong but it doesn't seem like a bad

00:13:51,319 --> 00:14:00,889
choice so I choose that pivot I keep I

00:13:57,560 --> 00:14:04,459
remember the index value and so I store

00:14:00,889 --> 00:14:05,630
that and what I mark in red are the

00:14:04,459 --> 00:14:08,329
elements that are going to be

00:14:05,630 --> 00:14:10,810
interchanged because what I want to do I

00:14:08,329 --> 00:14:13,550
want to move the pivot out of the way

00:14:10,810 --> 00:14:15,319
well one thing is it's all in memory you

00:14:13,550 --> 00:14:18,800
don't need any additional memory so you

00:14:15,319 --> 00:14:20,899
you swap it with the last element in the

00:14:18,800 --> 00:14:25,760
array so nine will go to seven and

00:14:20,899 --> 00:14:27,649
advisor version ok so that's my next

00:14:25,760 --> 00:14:29,329
step in my algorithm and now what I'm

00:14:27,649 --> 00:14:32,480
going to do I'm going to scan the array

00:14:29,329 --> 00:14:34,660
starting with element 0 and

00:14:32,480 --> 00:14:39,019
any element that is less than the pivot

00:14:34,660 --> 00:14:41,800
will be moved there so with eight

00:14:39,019 --> 00:14:47,000
nothing will happen because it's it's

00:14:41,800 --> 00:14:49,279
bigger than than 75 is less than seven

00:14:47,000 --> 00:14:50,720
so five will move so what makes the

00:14:49,279 --> 00:14:53,529
algorithm a little hard to read there's

00:14:50,720 --> 00:14:56,389
another pointer that keeps track of

00:14:53,529 --> 00:14:59,899
places you filled so what's going to

00:14:56,389 --> 00:15:04,370
happen next is 8 and 55 will actually

00:14:59,899 --> 00:15:05,839
move and eight will be pushed out so

00:15:04,370 --> 00:15:09,440
that's the next step and that's because

00:15:05,839 --> 00:15:12,860
5 is less than seven so that's the new

00:15:09,440 --> 00:15:16,220
situation we're done with five now okay

00:15:12,860 --> 00:15:18,380
and we move on as we move through the

00:15:16,220 --> 00:15:22,459
array there's not much to be done until

00:15:18,380 --> 00:15:27,459
we hit three when we hear three we again

00:15:22,459 --> 00:15:34,579
going to swap that with eight all right

00:15:27,459 --> 00:15:38,360
okay so that's the new situation we have

00:15:34,579 --> 00:15:41,630
moved that pivot out of the way as all

00:15:38,360 --> 00:15:44,839
the elements have been scanned we

00:15:41,630 --> 00:15:46,970
restore the pivot and now we have

00:15:44,839 --> 00:15:49,160
completed that sweep over the array and

00:15:46,970 --> 00:15:53,240
indeed these values or less these are

00:15:49,160 --> 00:15:56,810
higher and and we have our peril ism so

00:15:53,240 --> 00:15:59,360
we got seven and we repeat for the left

00:15:56,810 --> 00:16:02,870
and right branch and indica and all you

00:15:59,360 --> 00:16:04,940
do is make these tasks and you call

00:16:02,870 --> 00:16:10,850
yourself again so it's a recursive

00:16:04,940 --> 00:16:14,260
algorithm splitting things so here's the

00:16:10,850 --> 00:16:16,790
sequential version always a bit tedious

00:16:14,260 --> 00:16:21,110
awkward to be that recursive algorithm

00:16:16,790 --> 00:16:22,850
but you you you go through this until

00:16:21,110 --> 00:16:24,589
you've kind of you're done you know are

00:16:22,850 --> 00:16:27,589
no longer have elements you sort and

00:16:24,589 --> 00:16:30,860
that's controlled through this test so

00:16:27,589 --> 00:16:32,930
if the the lower value is less than the

00:16:30,860 --> 00:16:35,329
high value index value you still have

00:16:32,930 --> 00:16:39,250
work to do so you do this petitioning

00:16:35,329 --> 00:16:41,180
this one will return that index value

00:16:39,250 --> 00:16:43,300
like in the middle of the array

00:16:41,180 --> 00:16:45,550
initially and

00:16:43,300 --> 00:16:50,220
and you call yourself for the left and

00:16:45,550 --> 00:16:50,220
the right branch and this actually works

00:16:51,600 --> 00:17:02,800
so if you want to do that with tasking I

00:16:55,890 --> 00:17:04,839
make both branches a task and I haven't

00:17:02,800 --> 00:17:07,720
talked about the data scoping yet the

00:17:04,839 --> 00:17:13,449
data scoping in tasking is quite subtle

00:17:07,720 --> 00:17:15,130
to say politically correct it's you have

00:17:13,449 --> 00:17:17,380
to really think about it there are good

00:17:15,130 --> 00:17:19,000
defaults the default is first private

00:17:17,380 --> 00:17:21,970
that actually makes sense when you think

00:17:19,000 --> 00:17:24,819
about it i'm not in favor of relying on

00:17:21,970 --> 00:17:26,439
those default data scoping rules it's

00:17:24,819 --> 00:17:29,020
very good practice to think about it

00:17:26,439 --> 00:17:30,250
yourself and it may be a little hard in

00:17:29,020 --> 00:17:34,420
the beginning but it's quite rewarding

00:17:30,250 --> 00:17:38,140
so what I usually do is myself so in

00:17:34,420 --> 00:17:40,240
this case we want to have all tasks to

00:17:38,140 --> 00:17:42,160
be able to access any element in that

00:17:40,240 --> 00:17:44,710
vector because I don't know what work

00:17:42,160 --> 00:17:47,559
right I know what it will go but I don't

00:17:44,710 --> 00:17:49,600
have any restrictions so each task can

00:17:47,559 --> 00:17:53,669
access any element in the in the vector

00:17:49,600 --> 00:17:58,120
so I make it shared I hope that is clear

00:17:53,669 --> 00:18:00,250
these are first private so they inherit

00:17:58,120 --> 00:18:02,200
the initial value and that's what is

00:18:00,250 --> 00:18:03,880
being used because i'm not going to

00:18:02,200 --> 00:18:07,750
modify them are just going to read them

00:18:03,880 --> 00:18:14,470
in in the next nesting level of this

00:18:07,750 --> 00:18:18,370
recursion I need to have the driver part

00:18:14,470 --> 00:18:20,290
and the driver and that's why I had that

00:18:18,370 --> 00:18:23,080
lengthy introduction hopefully that

00:18:20,290 --> 00:18:27,700
comes as no surprise anymore that I only

00:18:23,080 --> 00:18:29,950
have a parallel well our region and I

00:18:27,700 --> 00:18:34,260
just call the quicksort it's the first

00:18:29,950 --> 00:18:36,429
call and I put it in a single and

00:18:34,260 --> 00:18:38,290
because I'm a little bit paranoid I

00:18:36,429 --> 00:18:40,179
don't want to have two barriers the

00:18:38,290 --> 00:18:42,250
single has an implied barrier the

00:18:40,179 --> 00:18:44,950
parallel region has a barrier I can't

00:18:42,250 --> 00:18:46,690
get rid of so I use in no wait because

00:18:44,950 --> 00:18:48,669
there's no reason to have an additional

00:18:46,690 --> 00:18:50,890
barrier admittedly the second one is

00:18:48,669 --> 00:18:56,410
cheap to execute but why waste the

00:18:50,890 --> 00:18:59,620
cycles so so this actually works I mean

00:18:56,410 --> 00:19:06,010
that's that's pretty much straight from

00:18:59,620 --> 00:19:08,050
my code but we're tasking and I didn't

00:19:06,010 --> 00:19:10,180
have time to really go into that detail

00:19:08,050 --> 00:19:13,150
there are going to be some parameters

00:19:10,180 --> 00:19:14,770
you have to play with for example you

00:19:13,150 --> 00:19:16,450
don't want to generate too many tasks

00:19:14,770 --> 00:19:19,210
eventually you only have a few elements

00:19:16,450 --> 00:19:22,210
to sort that's way quicker to do that

00:19:19,210 --> 00:19:24,550
sequentially so pretty much every

00:19:22,210 --> 00:19:27,970
recursive divide and conquer algorithm

00:19:24,550 --> 00:19:30,670
with tasking has a cut-off where you

00:19:27,970 --> 00:19:32,650
have in your code you have a test if

00:19:30,670 --> 00:19:34,030
there's not enough work to do like if

00:19:32,650 --> 00:19:36,040
you only have this number of elements

00:19:34,030 --> 00:19:41,320
left just call the sequential version

00:19:36,040 --> 00:19:43,000
now in OpenMP there's a formal system

00:19:41,320 --> 00:19:45,640
that's how people did that in in the

00:19:43,000 --> 00:19:47,230
first release of tasking soon there was

00:19:45,640 --> 00:19:50,290
a more elegant solution called the if

00:19:47,230 --> 00:19:52,360
clause where you have the if clause on

00:19:50,290 --> 00:19:58,090
the task which essentially does the same

00:19:52,360 --> 00:20:00,660
it will stop generating tasks okay the

00:19:58,090 --> 00:20:04,600
center merger ball the merger ball will

00:20:00,660 --> 00:20:06,820
avoid again replicating the data

00:20:04,600 --> 00:20:08,920
environment because each task will carry

00:20:06,820 --> 00:20:10,990
his own data environment and with

00:20:08,920 --> 00:20:13,810
thousands of tasks your memory

00:20:10,990 --> 00:20:15,760
consumption may get quite high the final

00:20:13,810 --> 00:20:17,740
clause is somewhat likely if there's a

00:20:15,760 --> 00:20:21,660
subtle difference between the two so you

00:20:17,740 --> 00:20:24,340
have ways to control it unfortunately

00:20:21,660 --> 00:20:27,240
the way it is you'll have to experiment

00:20:24,340 --> 00:20:30,100
some with that if you don't use these

00:20:27,240 --> 00:20:35,110
the cases that I've seen usually you

00:20:30,100 --> 00:20:39,460
don't get good scalability aversion so

00:20:35,110 --> 00:20:41,110
what I did I ran this on a spark system

00:20:39,460 --> 00:20:46,830
that's why work in the spark or

00:20:41,110 --> 00:20:49,510
processor organization excuse me and

00:20:46,830 --> 00:20:52,120
that's just to give you a feel for that

00:20:49,510 --> 00:20:54,640
this is a very naive implementation of

00:20:52,120 --> 00:20:56,820
quicksort I mean this much smarter

00:20:54,640 --> 00:20:59,260
implementations out given the simplicity

00:20:56,820 --> 00:21:02,350
it's actually nice to see how well it

00:20:59,260 --> 00:21:05,260
scales the blue the bar chart is the run

00:21:02,350 --> 00:21:07,510
time elapsed time in seconds so from 30

00:21:05,260 --> 00:21:09,710
seconds I get it down to about point 7

00:21:07,510 --> 00:21:11,990
of course there's a diminishing return

00:21:09,710 --> 00:21:14,779
but I could still use 128 threads in a

00:21:11,990 --> 00:21:16,850
some sort of a meaningful way an overall

00:21:14,779 --> 00:21:18,260
that gives me a speed up relative to the

00:21:16,850 --> 00:21:20,990
singles their performance of about

00:21:18,260 --> 00:21:23,450
forty-five by the way I also tweak those

00:21:20,990 --> 00:21:25,700
parameters to make sure that a single

00:21:23,450 --> 00:21:28,039
thread performance is pretty much the

00:21:25,700 --> 00:21:29,570
same as the sequential performance it's

00:21:28,039 --> 00:21:31,820
another thing you want to do in open and

00:21:29,570 --> 00:21:33,440
p you want to make sure that you don't

00:21:31,820 --> 00:21:35,720
lose too much because of the OpenAPI

00:21:33,440 --> 00:21:39,320
infrastructure so this is a reasonably

00:21:35,720 --> 00:21:43,130
fair speed up and not bad at all I hope

00:21:39,320 --> 00:21:45,860
you agree and ours is visibly pleased

00:21:43,130 --> 00:21:49,789
with it so to summarize we no longer

00:21:45,860 --> 00:21:51,830
need to know everything and for certain

00:21:49,789 --> 00:21:54,500
types of algorithm tasking is really

00:21:51,830 --> 00:21:56,529
your friend and we start seeing more and

00:21:54,500 --> 00:21:59,450
more usage of tasking actually as a

00:21:56,529 --> 00:22:01,549
little sidestep yesterday in the openmp

00:21:59,450 --> 00:22:04,370
tutorial was mentioned when you use

00:22:01,549 --> 00:22:06,559
accelerators one of the beauties of

00:22:04,370 --> 00:22:09,080
opening p is you can combine all that

00:22:06,559 --> 00:22:12,200
stuff so you can put your accelerator

00:22:09,080 --> 00:22:14,240
offload work in a task and meanwhile

00:22:12,200 --> 00:22:16,760
another task does all the work you know

00:22:14,240 --> 00:22:18,350
very asynchronous computation so think

00:22:16,760 --> 00:22:21,529
about it think about task in a more

00:22:18,350 --> 00:22:23,840
general way certainly for certain

00:22:21,529 --> 00:22:26,929
algorithms that I mentioned it's really

00:22:23,840 --> 00:22:28,909
a nice fit you will have to do some

00:22:26,929 --> 00:22:31,250
additional children like I said you have

00:22:28,909 --> 00:22:34,580
to play these clauses have been put in

00:22:31,250 --> 00:22:38,029
for a good reason it's not a pretty

00:22:34,580 --> 00:22:43,730
story but it's the way it is and and

00:22:38,029 --> 00:22:46,279
remember we do have our masters we have

00:22:43,730 --> 00:22:49,299
one master now so bug him with all your

00:22:46,279 --> 00:22:51,590
questions so i'm off to hook and I

00:22:49,299 --> 00:22:53,990
always finish with this one that's a

00:22:51,590 --> 00:22:56,450
different talk when people say OpenMP

00:22:53,990 --> 00:23:00,260
doesn't scale I like to change it to say

00:22:56,450 --> 00:23:03,520
bad open and P doesn't scale good does

00:23:00,260 --> 00:23:03,520

YouTube URL: https://www.youtube.com/watch?v=SN6IQnNsm28


