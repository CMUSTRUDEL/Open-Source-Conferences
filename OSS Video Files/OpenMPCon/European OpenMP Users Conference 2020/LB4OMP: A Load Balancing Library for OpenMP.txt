Title: LB4OMP: A Load Balancing Library for OpenMP
Publication date: 2020-12-21
Playlist: European OpenMP Users Conference 2020
Description: 
	This talk was presented at the 3rd European OpenMP Users Conference in 2020

Presented by : Jonas KorndÃ¶rfer, University of Basel

Conference Website: https://openmpusers.org
Follow us: https://twitter.com/openmp_users

Presentation Abstract :
The OpenMP standard specifies only three loop scheduling techniques. This hinders research on novel scheduling techniques since a fair comparison with other existing techniques from the literature is not feasible for multithreaded applications using OpenMP. The three scheduling techniques available in OpenMP may not achieve the highest performance for arbitrary application-system pairs. We will start the talk by introducing LB4OMP, an extended LLVM OpenMP runtime library that implements fourteen dynamic loop self-scheduling (DLS) techniques in addition to those in the standard OpenMP runtime implementations. Via the eighteen algorithms, LB4OMP offers improved performance to application-system pairs in the presence of unpredictable variations in the execution environment. LB4OMP also includes performance measurement features to collect detailed information of the execution of parallel loops with OpenMP. These features facilitate understanding the impact of load balancing of OpenMP loops on application performance. The features support the measurement of the parallel loop execution time, each threadâ€™s execution time, the mean and standard deviation of the iterations execution time, and the chunk of iterations self-scheduled by each thread in every scheduling step. LB4OMP is open-source (available at https://github.com/unibas-dmi-hpc/LB4OMP) and can easily be used (and even extended) by OpenMP developers. We will illustrate the use of the scheduling techniques implemented in LB4OMP, the library features, and present the performance results and their analysis for a selection of the experiments we conducted using 1 application and 3 systems. We will show that the newly implemented scheduling techniques outperform the standard ones by up to 13.33% (with default chunk size). For a given application-system pair we will use LB4OMP to identify the highest performing combination of scheduling techniques. Also, we will show the performance improvements that are otherwise unachievable by the OpenMP standard scheduling options alone by bridging the gap between the state of the art according to the literature and state of the practice of load balancing with LB4OMP. We will conclude the talk by discussing potential extensions of this work, such as automatically load balancing OpenMP applications.
Captions: 
	00:00:03,919 --> 00:00:06,560
um

00:00:04,480 --> 00:00:08,480
i'd now like to welcome uh jonas

00:00:06,560 --> 00:00:11,200
kondorfer he's a phd student

00:00:08,480 --> 00:00:12,240
in the hpc group at the university of

00:00:11,200 --> 00:00:14,559
basel

00:00:12,240 --> 00:00:16,080
um i'm able to share your screen and and

00:00:14,559 --> 00:00:19,439
we're looking forward to hearing your

00:00:16,080 --> 00:00:20,720
your presentation okay uh hello can you

00:00:19,439 --> 00:00:24,800
hear me

00:00:20,720 --> 00:00:30,000
yep okay thank you tom i will

00:00:24,800 --> 00:00:33,600
share the recording i made here so just

00:00:30,000 --> 00:00:35,920
let's see is it looking good for you

00:00:33,600 --> 00:00:36,960
is it a full screen or something that's

00:00:35,920 --> 00:00:41,840
full screen

00:00:36,960 --> 00:00:41,840
okay so share computer sound

00:00:42,640 --> 00:00:46,480
okay so i'll play it

00:00:46,559 --> 00:00:50,160
hello everyone my name is jonas miller

00:00:49,280 --> 00:00:52,320
kondrfur

00:00:50,160 --> 00:00:53,680
and i'm here today to present to you

00:00:52,320 --> 00:00:57,680
lv4mp

00:00:53,680 --> 00:01:01,440
a load balancing library for openmp

00:00:57,680 --> 00:01:03,039
now just a brief outline uh

00:01:01,440 --> 00:01:04,640
i will start by talking a little bit

00:01:03,039 --> 00:01:07,040
about our motivation

00:01:04,640 --> 00:01:09,040
to create the library uh the history of

00:01:07,040 --> 00:01:11,280
lb for mp from where it come from

00:01:09,040 --> 00:01:13,280
and then the library itself with

00:01:11,280 --> 00:01:14,960
scheduling techniques it contains

00:01:13,280 --> 00:01:17,280
which performance measurement features

00:01:14,960 --> 00:01:20,320
it contains and

00:01:17,280 --> 00:01:20,960
how to use it then we'll have a look at

00:01:20,320 --> 00:01:23,520
some

00:01:20,960 --> 00:01:24,000
performance analysis that we conducted

00:01:23,520 --> 00:01:26,560
with

00:01:24,000 --> 00:01:27,840
lb4mp and finally some take-home

00:01:26,560 --> 00:01:29,759
messages

00:01:27,840 --> 00:01:31,840
it's important to highlight that this

00:01:29,759 --> 00:01:34,320
project is partially founded by the

00:01:31,840 --> 00:01:36,720
swiss national science foundation

00:01:34,320 --> 00:01:38,240
and by the project mls multi-level

00:01:36,720 --> 00:01:39,520
scheduling in large-scale

00:01:38,240 --> 00:01:41,600
high-performance

00:01:39,520 --> 00:01:43,680
pairs on the right you can also see some

00:01:41,600 --> 00:01:46,479
pictures of the team involved in this

00:01:43,680 --> 00:01:47,200
work which composed by professor felina

00:01:46,479 --> 00:01:50,079
charba

00:01:47,200 --> 00:01:51,119
the head of the group ali mohammed ahmed

00:01:50,079 --> 00:01:54,720
elemi

00:01:51,119 --> 00:01:57,200
and myself as for our motivation

00:01:54,720 --> 00:01:59,119
uh well loading balance is a well-known

00:01:57,200 --> 00:02:01,200
performance degradation factor it

00:01:59,119 --> 00:02:03,280
lowered the performance of applications

00:02:01,200 --> 00:02:05,439
it caused the waste of resources and

00:02:03,280 --> 00:02:07,600
energy and it can increase

00:02:05,439 --> 00:02:09,599
the waiting times in job queues which

00:02:07,600 --> 00:02:12,720
will affect a lot of people

00:02:09,599 --> 00:02:16,319
in supercomputers nowadays

00:02:12,720 --> 00:02:17,599
and furthermore there is a huge amount

00:02:16,319 --> 00:02:21,440
of literature

00:02:17,599 --> 00:02:24,800
and research that

00:02:21,440 --> 00:02:25,680
proposed load balancing method that have

00:02:24,800 --> 00:02:28,640
never

00:02:25,680 --> 00:02:29,200
been really implemented in any library

00:02:28,640 --> 00:02:32,319
and

00:02:29,200 --> 00:02:33,120
that are not available to anyone to

00:02:32,319 --> 00:02:35,599
simply use

00:02:33,120 --> 00:02:37,680
them and try to achieve a higher

00:02:35,599 --> 00:02:41,200
performance with them in

00:02:37,680 --> 00:02:42,400
their own application so the lack of an

00:02:41,200 --> 00:02:45,200
implementation for

00:02:42,400 --> 00:02:47,599
such scheduling techniques and load

00:02:45,200 --> 00:02:50,800
balancing methods in general

00:02:47,599 --> 00:02:52,879
hinders the research for novel methods

00:02:50,800 --> 00:02:55,120
since the comparison with what was

00:02:52,879 --> 00:02:59,200
published previously proposed

00:02:55,120 --> 00:03:02,000
is not possible and

00:02:59,200 --> 00:03:02,879
furthermore it also may hinder the

00:03:02,000 --> 00:03:06,080
performance

00:03:02,879 --> 00:03:09,440
that is unachievable with

00:03:06,080 --> 00:03:12,480
what is currently available

00:03:09,440 --> 00:03:13,040
now a little bit about from where lb for

00:03:12,480 --> 00:03:16,480
mp

00:03:13,040 --> 00:03:18,159
come from so in 2018 we started our

00:03:16,480 --> 00:03:21,280
first efforts to implement

00:03:18,159 --> 00:03:22,400
some macro scheduling techniques to the

00:03:21,280 --> 00:03:25,280
gnu

00:03:22,400 --> 00:03:26,000
openmp runtime library and this work was

00:03:25,280 --> 00:03:29,599
published at

00:03:26,000 --> 00:03:32,159
iwomp and with this work we

00:03:29,599 --> 00:03:33,120
had some interesting result achieving

00:03:32,159 --> 00:03:34,959
some

00:03:33,120 --> 00:03:36,319
nice performance and higher performance

00:03:34,959 --> 00:03:38,799
than the

00:03:36,319 --> 00:03:40,239
standard scheduling techniques so we

00:03:38,799 --> 00:03:44,400
decided to approach the

00:03:40,239 --> 00:03:46,159
llvm openmp runtime library since it is

00:03:44,400 --> 00:03:48,720
more compatible with different

00:03:46,159 --> 00:03:51,920
distributions such as the gnu

00:03:48,720 --> 00:03:55,120
and intel and then

00:03:51,920 --> 00:03:56,720
we also explored this runtime library

00:03:55,120 --> 00:03:59,760
and we implemented one more

00:03:56,720 --> 00:04:03,840
scheduling technique and at this point

00:03:59,760 --> 00:04:05,200
we realized that llvm was a good target

00:04:03,840 --> 00:04:09,120
and we decided to

00:04:05,200 --> 00:04:11,439
expand our work by gathering as

00:04:09,120 --> 00:04:13,519
much as we could from the literature and

00:04:11,439 --> 00:04:16,639
implementing

00:04:13,519 --> 00:04:19,919
everything we could in the llvm

00:04:16,639 --> 00:04:23,759
openmp runtime library once again

00:04:19,919 --> 00:04:27,440
and that was a poster published at uh

00:04:23,759 --> 00:04:31,360
supercomputing and that is actually a

00:04:27,440 --> 00:04:33,919
very early version of lb for omp

00:04:31,360 --> 00:04:34,400
and then we arrive to today ufl before

00:04:33,919 --> 00:04:36,000
mp

00:04:34,400 --> 00:04:37,520
that comprises some performance

00:04:36,000 --> 00:04:39,120
measurement features and the day

00:04:37,520 --> 00:04:42,639
scheduling techniques

00:04:39,120 --> 00:04:44,160
and we kindly like to see it as a swiss

00:04:42,639 --> 00:04:48,240
army knife

00:04:44,160 --> 00:04:51,840
of load balancing for openmp

00:04:48,240 --> 00:04:53,199
in a nutshell lb4mp is a load balancing

00:04:51,840 --> 00:04:56,479
library for openmp

00:04:53,199 --> 00:04:57,280
it bridges the gap between the state of

00:04:56,479 --> 00:05:00,400
the art

00:04:57,280 --> 00:05:02,479
of the literature about load balancing

00:05:00,400 --> 00:05:04,160
and the state of the practice of load

00:05:02,479 --> 00:05:07,840
balancing multi-threaded

00:05:04,160 --> 00:05:11,360
applications it's based on the llvm

00:05:07,840 --> 00:05:14,400
openmp runtime library and

00:05:11,360 --> 00:05:16,479
it comprises nine dynamic

00:05:14,400 --> 00:05:18,000
and non-adaptive self-scheduling

00:05:16,479 --> 00:05:20,080
techniques and eight

00:05:18,000 --> 00:05:21,199
dynamic and adaptive self-scheduling

00:05:20,080 --> 00:05:23,680
techniques

00:05:21,199 --> 00:05:26,240
and it also contains some performance

00:05:23,680 --> 00:05:29,199
measurement features

00:05:26,240 --> 00:05:30,479
and the lb4mp is available on github

00:05:29,199 --> 00:05:34,320
it's opensport

00:05:30,479 --> 00:05:36,880
and everyone is welcome to try it

00:05:34,320 --> 00:05:39,280
now which scheduling techniques are

00:05:36,880 --> 00:05:41,600
available in lb for mp

00:05:39,280 --> 00:05:42,880
it contains the standard static

00:05:41,600 --> 00:05:44,800
scheduling technique

00:05:42,880 --> 00:05:46,960
it contains the nine dynamic and

00:05:44,800 --> 00:05:47,600
non-adaptive self sketching techniques

00:05:46,960 --> 00:05:51,440
which are

00:05:47,600 --> 00:05:53,120
the ones in the screen and it contains

00:05:51,440 --> 00:05:55,039
eight dynamic and adaptive

00:05:53,120 --> 00:05:57,039
self-sketching techniques

00:05:55,039 --> 00:05:58,400
it's important to highlight here that

00:05:57,039 --> 00:06:00,400
this is the first time

00:05:58,400 --> 00:06:02,240
dynamic and adaptive self-catching

00:06:00,400 --> 00:06:04,800
techniques have been implemented to

00:06:02,240 --> 00:06:08,160
openmp and we will see later on the

00:06:04,800 --> 00:06:11,759
results are pretty interesting

00:06:08,160 --> 00:06:13,440
and they are very important since

00:06:11,759 --> 00:06:15,440
they are the only ones that are capable

00:06:13,440 --> 00:06:18,160
of collecting information

00:06:15,440 --> 00:06:19,280
about the execution of previous trunk of

00:06:18,160 --> 00:06:22,240
iterations

00:06:19,280 --> 00:06:23,199
during the execution of an application

00:06:22,240 --> 00:06:26,720
and by doing so

00:06:23,199 --> 00:06:27,680
they can change the amount of iterations

00:06:26,720 --> 00:06:31,120
that each trade

00:06:27,680 --> 00:06:32,639
will receive during the execution

00:06:31,120 --> 00:06:34,000
the following are the performance

00:06:32,639 --> 00:06:36,639
measurement features that are

00:06:34,000 --> 00:06:39,759
implemented in lb for omp

00:06:36,639 --> 00:06:44,240
the first one is about collecting

00:06:39,759 --> 00:06:46,560
the execution time of each thread in

00:06:44,240 --> 00:06:47,680
executing the loop so it prints the

00:06:46,560 --> 00:06:49,680
values in

00:06:47,680 --> 00:06:50,720
csv file format

00:06:49,680 --> 00:06:52,800
[Music]

00:06:50,720 --> 00:06:54,400
that bring the looper currency which is

00:06:52,800 --> 00:06:56,400
basically a counter

00:06:54,400 --> 00:06:57,759
that registers how many times the same

00:06:56,400 --> 00:07:00,080
loop was executed

00:06:57,759 --> 00:07:01,919
and that's main important for time

00:07:00,080 --> 00:07:05,360
stepping applications for instance that

00:07:01,919 --> 00:07:07,919
executed the same loop many times

00:07:05,360 --> 00:07:09,199
then it prints the location which

00:07:07,919 --> 00:07:11,759
indicates

00:07:09,199 --> 00:07:14,319
the function name and the line of code

00:07:11,759 --> 00:07:16,000
where you can find the respective loop

00:07:14,319 --> 00:07:18,160
the number of iterations of the loop the

00:07:16,000 --> 00:07:19,520
thread id and the respective execution

00:07:18,160 --> 00:07:23,199
time

00:07:19,520 --> 00:07:25,680
then it we also allow the

00:07:23,199 --> 00:07:26,960
collection of the parallel execution

00:07:25,680 --> 00:07:31,039
time of the loop

00:07:26,960 --> 00:07:33,039
which also prints the values in csv

00:07:31,039 --> 00:07:34,400
and then we implemented the

00:07:33,039 --> 00:07:38,639
functionality that

00:07:34,400 --> 00:07:41,680
that we entered every scheduling round

00:07:38,639 --> 00:07:44,160
or more specifically

00:07:41,680 --> 00:07:45,440
every chunk of iterations that was

00:07:44,160 --> 00:07:47,919
scheduled

00:07:45,440 --> 00:07:49,120
to every trade for every scheduling

00:07:47,919 --> 00:07:53,360
round

00:07:49,120 --> 00:07:55,840
and this also printed the values in csv

00:07:53,360 --> 00:07:57,360
it prints again the location it brings

00:07:55,840 --> 00:08:00,639
the lower bound

00:07:57,360 --> 00:08:03,840
and the upper bound so in openmp

00:08:00,639 --> 00:08:06,960
what happens is you have a central queue

00:08:03,840 --> 00:08:10,080
of iterations and

00:08:06,960 --> 00:08:13,520
each thread identifies or knows

00:08:10,080 --> 00:08:15,759
which part of this queue uh

00:08:13,520 --> 00:08:17,039
it's supposed to execute by knowing it's

00:08:15,759 --> 00:08:20,240
lower and upper

00:08:17,039 --> 00:08:20,720
bound so we registered this also and

00:08:20,240 --> 00:08:22,879
then

00:08:20,720 --> 00:08:24,960
we've registered the chunk size or the

00:08:22,879 --> 00:08:27,840
amount of iterations that each trade we

00:08:24,960 --> 00:08:29,919
received and the thread that received

00:08:27,840 --> 00:08:32,000
this amount of iterations

00:08:29,919 --> 00:08:33,760
it's important to highlight that this

00:08:32,000 --> 00:08:35,839
functionality can create

00:08:33,760 --> 00:08:37,360
really large files depending on the

00:08:35,839 --> 00:08:40,399
amount of iterations

00:08:37,360 --> 00:08:43,839
of the target loop it can grow

00:08:40,399 --> 00:08:47,040
very very quick and finally

00:08:43,839 --> 00:08:50,640
we have the profiling functionality

00:08:47,040 --> 00:08:53,200
this is a functionality that

00:08:50,640 --> 00:08:54,160
works slightly different than the other

00:08:53,200 --> 00:08:57,519
we will be

00:08:54,160 --> 00:09:00,959
tuned and it was developed

00:08:57,519 --> 00:09:03,360
mainly to facilitate the usage of

00:09:00,959 --> 00:09:05,200
other scheduling techniques that require

00:09:03,360 --> 00:09:08,480
profiling information

00:09:05,200 --> 00:09:10,560
so it collects the mean

00:09:08,480 --> 00:09:13,040
iteration execution time and the

00:09:10,560 --> 00:09:16,160
standard deviation of the iterations of

00:09:13,040 --> 00:09:16,160
a respective loop

00:09:16,720 --> 00:09:20,480
the usage of lb4mp is pretty

00:09:18,720 --> 00:09:21,120
straightforward and the first thing one

00:09:20,480 --> 00:09:23,440
has to do

00:09:21,120 --> 00:09:24,240
it to check if the target loops already

00:09:23,440 --> 00:09:27,519
contain

00:09:24,240 --> 00:09:29,120
the schedule runtime clause if that's

00:09:27,519 --> 00:09:31,120
the case you don't even have to

00:09:29,120 --> 00:09:33,519
recompile the application

00:09:31,120 --> 00:09:34,160
however you have to make sure that the

00:09:33,519 --> 00:09:36,720
loop

00:09:34,160 --> 00:09:38,640
you want to use the scheduling technique

00:09:36,720 --> 00:09:42,160
in lb for mp

00:09:38,640 --> 00:09:44,959
are using the schedule runtime code

00:09:42,160 --> 00:09:46,560
the second thing you have to link lv4mp

00:09:44,959 --> 00:09:50,480
with your application

00:09:46,560 --> 00:09:51,839
and to do that you can add the path to

00:09:50,480 --> 00:09:55,360
the compiled

00:09:51,839 --> 00:09:58,399
lb for mp to the environment variable

00:09:55,360 --> 00:10:00,399
ld library path finally

00:09:58,399 --> 00:10:01,600
to select a scheduling technique it

00:10:00,399 --> 00:10:04,480
worked in the same way

00:10:01,600 --> 00:10:06,240
as the standard way and you can export

00:10:04,480 --> 00:10:08,160
to the environment variable omp

00:10:06,240 --> 00:10:10,160
schedule and define the scheduling

00:10:08,160 --> 00:10:13,440
technique in the chunk size

00:10:10,160 --> 00:10:15,600
and in the current version of lb per mp

00:10:13,440 --> 00:10:18,720
we also expect

00:10:15,600 --> 00:10:23,200
a variable called kmp cpu speed

00:10:18,720 --> 00:10:26,240
which is expecting the clock frequency

00:10:23,200 --> 00:10:28,160
of the target machined and that's used

00:10:26,240 --> 00:10:33,839
for some timing functions

00:10:28,160 --> 00:10:33,839
that provide that are of lower overhead

00:10:34,000 --> 00:10:38,079
to use the performance measurement

00:10:36,320 --> 00:10:40,959
features

00:10:38,079 --> 00:10:42,800
and configure them it is done also to

00:10:40,959 --> 00:10:45,440
environment variables

00:10:42,800 --> 00:10:46,240
and to collect each trend in each

00:10:45,440 --> 00:10:48,320
parallel loop

00:10:46,240 --> 00:10:50,000
execution time you have to provide the

00:10:48,320 --> 00:10:53,680
environment variable pmp

00:10:50,000 --> 00:10:55,680
time loop and by doing so it already

00:10:53,680 --> 00:10:56,720
activates the functionality and you have

00:10:55,680 --> 00:11:00,320
to provide

00:10:56,720 --> 00:11:02,000
a path and a file where the data will be

00:11:00,320 --> 00:11:04,640
stored

00:11:02,000 --> 00:11:05,839
to collect each scheduling round you

00:11:04,640 --> 00:11:08,079
have to export

00:11:05,839 --> 00:11:09,839
the environment variable kmp print

00:11:08,079 --> 00:11:13,360
chunks

00:11:09,839 --> 00:11:17,040
and and and just activate it so problem

00:11:13,360 --> 00:11:20,320
put one on it and you have also to once

00:11:17,040 --> 00:11:22,959
again provide the kmp time loops

00:11:20,320 --> 00:11:25,279
with the path where you want to store

00:11:22,959 --> 00:11:29,760
this data

00:11:25,279 --> 00:11:33,279
finally to use the profiling technique

00:11:29,760 --> 00:11:37,120
uh you have to export omp schedule

00:11:33,279 --> 00:11:39,519
and choose profiling and you also have

00:11:37,120 --> 00:11:40,320
to export another environment variable

00:11:39,519 --> 00:11:44,959
that is

00:11:40,320 --> 00:11:48,000
emp profile data that is expecting

00:11:44,959 --> 00:11:51,760
also a path where the profile will be

00:11:48,000 --> 00:11:51,760
the profiling will be stored

00:11:51,839 --> 00:11:55,920
for our performance evaluation we

00:11:53,519 --> 00:11:58,480
approached an application called sphinx

00:11:55,920 --> 00:12:02,399
it's a smoothed particle hydrodynamic

00:11:58,480 --> 00:12:03,360
code that is used in astrophytic for

00:12:02,399 --> 00:12:06,480
astrophysics

00:12:03,360 --> 00:12:08,079
simulations such as the collision of

00:12:06,480 --> 00:12:11,600
bars

00:12:08,079 --> 00:12:14,560
it's a time stepping code so we executed

00:12:11,600 --> 00:12:18,000
the 20 time step

00:12:14,560 --> 00:12:21,440
of the simulation and each has

00:12:18,000 --> 00:12:22,959
1 million iterations the loops that we

00:12:21,440 --> 00:12:25,760
modified

00:12:22,959 --> 00:12:26,639
that is that we added a schedule runtime

00:12:25,760 --> 00:12:29,680
to them

00:12:26,639 --> 00:12:31,279
were loop l0 which is the find neighbors

00:12:29,680 --> 00:12:33,519
operation so it basically just

00:12:31,279 --> 00:12:34,560
identifies which particles are close to

00:12:33,519 --> 00:12:37,600
each other

00:12:34,560 --> 00:12:41,120
and l1 which

00:12:37,600 --> 00:12:44,560
performs the uh some math to calculate

00:12:41,120 --> 00:12:48,240
gravity which is uh how the each

00:12:44,560 --> 00:12:51,279
particle interacts with each other

00:12:48,240 --> 00:12:54,320
uh we executed this application in three

00:12:51,279 --> 00:12:57,839
node types so type a b and three

00:12:54,320 --> 00:13:00,880
and uh we always execute the application

00:12:57,839 --> 00:13:02,959
five times on each node

00:13:00,880 --> 00:13:04,560
uh the metrics that we evaluate the

00:13:02,959 --> 00:13:06,560
third we evaluated the parallel

00:13:04,560 --> 00:13:07,279
execution time of the application as a

00:13:06,560 --> 00:13:10,240
whole but

00:13:07,279 --> 00:13:11,519
we also look at the exclusive execution

00:13:10,240 --> 00:13:15,760
time of each

00:13:11,519 --> 00:13:17,839
loop and by having this information of

00:13:15,760 --> 00:13:20,959
the execution time of each loop

00:13:17,839 --> 00:13:24,240
we can calculate how much performance is

00:13:20,959 --> 00:13:26,639
lost by executing the whole application

00:13:24,240 --> 00:13:28,000
with a single scheduling technique so

00:13:26,639 --> 00:13:30,639
since we have

00:13:28,000 --> 00:13:31,920
the different times for every loop we

00:13:30,639 --> 00:13:33,760
can see which

00:13:31,920 --> 00:13:35,600
is the best scheduling technique for

00:13:33,760 --> 00:13:38,320
each loop

00:13:35,600 --> 00:13:39,040
lb for omp and the sphinx were compiled

00:13:38,320 --> 00:13:42,480
with

00:13:39,040 --> 00:13:42,959
intel and the threads were configured

00:13:42,480 --> 00:13:47,839
with

00:13:42,959 --> 00:13:49,120
omp place scores and omp proc bind close

00:13:47,839 --> 00:13:52,560
here we have our

00:13:49,120 --> 00:13:55,120
first result for sphinx executing on

00:13:52,560 --> 00:13:57,120
node type a

00:13:55,120 --> 00:13:59,839
on the x-axis you can see the scheduling

00:13:57,120 --> 00:14:02,480
techniques and on the y-axis you see the

00:13:59,839 --> 00:14:04,000
parallel execution time

00:14:02,480 --> 00:14:05,839
you can see that there are different

00:14:04,000 --> 00:14:09,040
colors for the bars

00:14:05,839 --> 00:14:09,360
and these are identifying uh from which

00:14:09,040 --> 00:14:12,160
loop

00:14:09,360 --> 00:14:13,040
these measurements come from so in light

00:14:12,160 --> 00:14:16,399
green

00:14:13,040 --> 00:14:20,320
is representing loop l0

00:14:16,399 --> 00:14:21,519
in dark green it's representing loop l1

00:14:20,320 --> 00:14:24,240
which is actually the most

00:14:21,519 --> 00:14:27,680
time-consuming loop i think

00:14:24,240 --> 00:14:30,399
and in dark blue is the time

00:14:27,680 --> 00:14:31,040
outside of the loops so basically

00:14:30,399 --> 00:14:34,160
anything

00:14:31,040 --> 00:14:37,839
that was not measured by or was not

00:14:34,160 --> 00:14:41,279
influenced by the scheduling techniques

00:14:37,839 --> 00:14:44,880
the background

00:14:41,279 --> 00:14:46,800
of the plot identifies from where the

00:14:44,880 --> 00:14:48,959
techniques come from let's say like this

00:14:46,800 --> 00:14:50,880
so in white background you have

00:14:48,959 --> 00:14:53,360
the openmp standard scheduling

00:14:50,880 --> 00:14:55,680
techniques in gray background

00:14:53,360 --> 00:14:57,040
you have trapezoid self scheduling which

00:14:55,680 --> 00:15:00,480
was a technique that was

00:14:57,040 --> 00:15:02,160
already implemented in the llvm openmp

00:15:00,480 --> 00:15:05,279
runtime library

00:15:02,160 --> 00:15:08,800
and in green background you have

00:15:05,279 --> 00:15:12,000
the techniques implemented in lb for mp

00:15:08,800 --> 00:15:15,120
you probably noticed also the pink

00:15:12,000 --> 00:15:16,399
background which is showing and

00:15:15,120 --> 00:15:18,800
highlighting

00:15:16,399 --> 00:15:21,120
the performance the achievable

00:15:18,800 --> 00:15:24,480
performance with the best combination

00:15:21,120 --> 00:15:24,480
of scheduling techniques

00:15:25,120 --> 00:15:33,199
we also have some red rectangles

00:15:28,240 --> 00:15:36,880
uh around some of the bars in this case

00:15:33,199 --> 00:15:38,880
both are on the sc bar

00:15:36,880 --> 00:15:40,160
and these rectangles are highlighting

00:15:38,880 --> 00:15:44,240
which was the best

00:15:40,160 --> 00:15:44,240
scheduling technique for a given loop

00:15:45,440 --> 00:15:50,320
we can see that the best scheduling

00:15:48,240 --> 00:15:51,360
technique is a combination of techniques

00:15:50,320 --> 00:15:55,199
in this case

00:15:51,360 --> 00:15:59,519
it is twice

00:15:55,199 --> 00:16:02,160
fsc and it's important to highlight that

00:15:59,519 --> 00:16:04,480
the performance the percentages shown

00:16:02,160 --> 00:16:05,360
on top of the bars represent how much

00:16:04,480 --> 00:16:08,880
performance is

00:16:05,360 --> 00:16:12,560
lost uh by

00:16:08,880 --> 00:16:15,920
executing the the application with

00:16:12,560 --> 00:16:18,480
a single technique

00:16:15,920 --> 00:16:20,320
and here we can see that the best

00:16:18,480 --> 00:16:21,759
combination of scheduling techniques or

00:16:20,320 --> 00:16:25,440
in this case

00:16:21,759 --> 00:16:28,560
only fsc achieved up to 13

00:16:25,440 --> 00:16:30,720
around 13 percent higher performance

00:16:28,560 --> 00:16:31,680
than the best standard which in this

00:16:30,720 --> 00:16:35,360
case was

00:16:31,680 --> 00:16:38,000
guided self scheduling and

00:16:35,360 --> 00:16:39,360
we can also see that the adaptive

00:16:38,000 --> 00:16:42,560
techniques for instance

00:16:39,360 --> 00:16:45,600
maf also outperformed the

00:16:42,560 --> 00:16:49,920
gss by up to 9.5

00:16:45,600 --> 00:16:50,800
9.6 so that's a very impressive result i

00:16:49,920 --> 00:16:53,199
think

00:16:50,800 --> 00:16:55,440
the adaptive techniques tend to cause

00:16:53,199 --> 00:16:58,160
slightly higher overhead

00:16:55,440 --> 00:16:59,199
but at the same time they were more

00:16:58,160 --> 00:17:02,560
capable of

00:16:59,199 --> 00:17:06,880
balancing the load and by doing so

00:17:02,560 --> 00:17:09,360
uh achieving higher performance than gss

00:17:06,880 --> 00:17:10,480
now here we have the results for sphinx

00:17:09,360 --> 00:17:13,520
executing on

00:17:10,480 --> 00:17:16,000
node type b

00:17:13,520 --> 00:17:16,959
the plots are configured in the same way

00:17:16,000 --> 00:17:20,880
as

00:17:16,959 --> 00:17:21,199
the previous plot and here we can notice

00:17:20,880 --> 00:17:23,520
that

00:17:21,199 --> 00:17:25,839
the best is indeed the combination of

00:17:23,520 --> 00:17:29,760
different scheduling techniques per loop

00:17:25,839 --> 00:17:32,960
in this case fsc and maf

00:17:29,760 --> 00:17:36,400
together compose best

00:17:32,960 --> 00:17:39,520
we should also notice that fsc

00:17:36,400 --> 00:17:42,880
is not an adaptive scheduling technique

00:17:39,520 --> 00:17:46,000
and it was not able to

00:17:42,880 --> 00:17:48,559
achieve the same high performance as we

00:17:46,000 --> 00:17:50,000
saw in the previous plot so in this case

00:17:48,559 --> 00:17:54,000
for this system

00:17:50,000 --> 00:17:55,440
uh fsc end up achieving uh 23 percent

00:17:54,000 --> 00:17:58,559
lower performance

00:17:55,440 --> 00:17:59,520
than the best combination and we should

00:17:58,559 --> 00:18:03,760
also highlight

00:17:59,520 --> 00:18:03,760
that the adaptive techniques

00:18:03,840 --> 00:18:11,039
were able to maintain high performance

00:18:07,600 --> 00:18:12,240
between the previous node type and this

00:18:11,039 --> 00:18:16,160
node type

00:18:12,240 --> 00:18:19,520
even af was still able to beat

00:18:16,160 --> 00:18:22,240
gss and total performance gss by up to

00:18:19,520 --> 00:18:24,880
0.7

00:18:22,240 --> 00:18:25,280
finally we have the results for sphinx

00:18:24,880 --> 00:18:29,039
on

00:18:25,280 --> 00:18:32,160
node type c uh here we can see that

00:18:29,039 --> 00:18:34,000
the best combination is once again

00:18:32,160 --> 00:18:35,840
two different scheduling techniques one

00:18:34,000 --> 00:18:39,120
for each loop

00:18:35,840 --> 00:18:41,120
and it is fse and maf

00:18:39,120 --> 00:18:42,240
again however it's important to

00:18:41,120 --> 00:18:46,880
highlight that

00:18:42,240 --> 00:18:49,360
now fsc in this case fsc was once again

00:18:46,880 --> 00:18:50,720
achieving very high performance and

00:18:49,360 --> 00:18:53,200
being basically

00:18:50,720 --> 00:18:56,000
achieving basically the same performance

00:18:53,200 --> 00:18:58,400
as the best combination

00:18:56,000 --> 00:18:59,919
here we can see that best outperformed

00:18:58,400 --> 00:19:04,160
the best standard by

00:18:59,919 --> 00:19:07,600
up to 12 or almost 13 percent

00:19:04,160 --> 00:19:10,480
and we should also highlight once

00:19:07,600 --> 00:19:11,120
again that the adaptive techniques or in

00:19:10,480 --> 00:19:14,640
this case

00:19:11,120 --> 00:19:15,440
maf outperformed also the standard ones

00:19:14,640 --> 00:19:18,720
by

00:19:15,440 --> 00:19:18,720
up to ten percent

00:19:19,600 --> 00:19:23,120
now some take home messages uh first of

00:19:22,320 --> 00:19:26,640
all

00:19:23,120 --> 00:19:29,039
lb for mp bridges the gap between

00:19:26,640 --> 00:19:31,200
what is in the literature and what is

00:19:29,039 --> 00:19:34,320
actually implemented and being used

00:19:31,200 --> 00:19:35,440
for the load balancing much traded

00:19:34,320 --> 00:19:38,480
applications

00:19:35,440 --> 00:19:42,480
it contains 14 additional to the

00:19:38,480 --> 00:19:45,679
openmp standard scheduling techniques

00:19:42,480 --> 00:19:46,880
and it is a first and necessary step for

00:19:45,679 --> 00:19:50,000
the implementation

00:19:46,880 --> 00:19:50,880
of an auto tuning or an automatic load

00:19:50,000 --> 00:19:54,080
balancing

00:19:50,880 --> 00:19:56,320
approach for openmp by looking at the

00:19:54,080 --> 00:19:59,120
results we can see that in most

00:19:56,320 --> 00:20:00,559
cases best is a combination of different

00:19:59,120 --> 00:20:03,840
scheduling techniques

00:20:00,559 --> 00:20:04,640
however we understand that it's quite

00:20:03,840 --> 00:20:08,000
impractical

00:20:04,640 --> 00:20:10,400
to find out which is

00:20:08,000 --> 00:20:14,240
the correct combination since the amount

00:20:10,400 --> 00:20:17,039
of experiments is very huge

00:20:14,240 --> 00:20:19,039
for that the dynamic and adaptive

00:20:17,039 --> 00:20:21,440
self-scheduling techniques are quite

00:20:19,039 --> 00:20:24,159
promising alternative to reach a

00:20:21,440 --> 00:20:27,600
performance that is comparable to best

00:20:24,159 --> 00:20:29,679
or that's close to best since

00:20:27,600 --> 00:20:31,520
they are more capable of adapting to

00:20:29,679 --> 00:20:35,039
different systems and

00:20:31,520 --> 00:20:37,120
maybe different workloads

00:20:35,039 --> 00:20:38,080
now what we are going to do next we are

00:20:37,120 --> 00:20:40,480
going to

00:20:38,080 --> 00:20:41,440
work on these techniques to patch and

00:20:40,480 --> 00:20:45,760
upstream them

00:20:41,440 --> 00:20:49,120
to the official llvm repository

00:20:45,760 --> 00:20:53,039
and we also are already working on

00:20:49,120 --> 00:20:56,240
an automatic approach for openmp

00:20:53,039 --> 00:21:00,000
for achieving the performance of best

00:20:56,240 --> 00:21:04,000
uh i would like to welcome everyone to

00:21:00,000 --> 00:21:07,679
check out our github and check out lb4mp

00:21:04,000 --> 00:21:09,919
and maybe you can even find out that

00:21:07,679 --> 00:21:11,840
your application can achieve a higher

00:21:09,919 --> 00:21:17,840
performance

00:21:11,840 --> 00:21:17,840
now i'm here open for questions

00:21:18,000 --> 00:21:22,000
that's great thank you very much uh

00:21:20,240 --> 00:21:23,600
jonas that was really interesting i'm

00:21:22,000 --> 00:21:26,559
very pleased to hear that you are

00:21:23,600 --> 00:21:28,480
working to contribute um some of your uh

00:21:26,559 --> 00:21:31,280
findings and scheduling approaches into

00:21:28,480 --> 00:21:33,360
into llvm runtimes for openmp so that's

00:21:31,280 --> 00:21:35,039
great

00:21:33,360 --> 00:21:36,640
there's a couple of questions come in uh

00:21:35,039 --> 00:21:40,000
the first was from

00:21:36,640 --> 00:21:40,480
mats uh braussen who says what is taking

00:21:40,000 --> 00:21:42,640
time

00:21:40,480 --> 00:21:43,520
in the loops with poor dynamic

00:21:42,640 --> 00:21:46,320
scheduling

00:21:43,520 --> 00:21:49,360
was it a poor memory location or

00:21:46,320 --> 00:21:51,840
scheduling overhead or something else

00:21:49,360 --> 00:21:52,559
yeah so yeah i saw the question before

00:21:51,840 --> 00:21:56,000
it

00:21:52,559 --> 00:21:58,159
it's kind of a tricky question how can i

00:21:56,000 --> 00:21:58,159
say

00:21:59,280 --> 00:22:05,200
so if you can see poor memory location

00:22:03,039 --> 00:22:07,760
as part of a schedule overhead also if

00:22:05,200 --> 00:22:11,520
you take for instance

00:22:07,760 --> 00:22:14,000
self scheduling that is a ss

00:22:11,520 --> 00:22:15,440
it will give a chunk of one iteration

00:22:14,000 --> 00:22:17,520
for each trade

00:22:15,440 --> 00:22:20,080
for each trade for each scheduling round

00:22:17,520 --> 00:22:22,240
so the threads are just consuming and

00:22:20,080 --> 00:22:24,559
this iterations are going everywhere so

00:22:22,240 --> 00:22:27,679
you always have a higher

00:22:24,559 --> 00:22:30,799
amount of cash misses and all of this

00:22:27,679 --> 00:22:34,880
so that is how can i say it's not

00:22:30,799 --> 00:22:38,080
simply saying it is um

00:22:34,880 --> 00:22:39,600
a problem of memory or or just a

00:22:38,080 --> 00:22:42,400
scheduling of your

00:22:39,600 --> 00:22:43,840
one thing is for sure if you have to

00:22:42,400 --> 00:22:46,159
execute

00:22:43,840 --> 00:22:46,960
more scheduling rounds so if you have to

00:22:46,159 --> 00:22:49,760
request

00:22:46,960 --> 00:22:52,000
work more times then you have a higher

00:22:49,760 --> 00:22:55,440
scheduling overhead but

00:22:52,000 --> 00:22:59,760
it also creates more uh memory problems

00:22:55,440 --> 00:23:03,120
so locality problems

00:22:59,760 --> 00:23:05,919
yeah i don't know basically

00:23:03,120 --> 00:23:07,760
thanks um i think another question

00:23:05,919 --> 00:23:10,960
that's that might be related is from uh

00:23:07,760 --> 00:23:13,520
oliver marsden who says um how does

00:23:10,960 --> 00:23:14,000
your approaches uh behave with first

00:23:13,520 --> 00:23:15,679
touch

00:23:14,000 --> 00:23:18,159
initialization of arrays on on

00:23:15,679 --> 00:23:21,360
multi-socket systems

00:23:18,159 --> 00:23:23,440
i to be honest i also see this one i am

00:23:21,360 --> 00:23:26,000
not really sure if i understand the

00:23:23,440 --> 00:23:26,000
question

00:23:26,799 --> 00:23:30,880
so i think i think it's related to if

00:23:28,720 --> 00:23:31,440
you if you start moving tasks around

00:23:30,880 --> 00:23:34,080
between

00:23:31,440 --> 00:23:35,360
between the pneuma domains how do you

00:23:34,080 --> 00:23:37,280
make sure that you

00:23:35,360 --> 00:23:38,720
take the memory with you or do you place

00:23:37,280 --> 00:23:41,760
do you schedule the tasks no

00:23:38,720 --> 00:23:45,360
i think it's located so yeah

00:23:41,760 --> 00:23:45,919
we the scheduling techniques don't

00:23:45,360 --> 00:23:49,360
really

00:23:45,919 --> 00:23:52,000
take care of this you basically just

00:23:49,360 --> 00:23:53,520
they basically just calculate a chunk of

00:23:52,000 --> 00:23:56,000
uh

00:23:53,520 --> 00:23:56,799
iterations and they and the threads will

00:23:56,000 --> 00:23:58,480
request and

00:23:56,799 --> 00:24:00,720
they will give this chunk of iterations

00:23:58,480 --> 00:24:02,240
to the thread but if it's located on a

00:24:00,720 --> 00:24:04,720
separated socket

00:24:02,240 --> 00:24:05,600
or if it's migrating from one socket to

00:24:04,720 --> 00:24:08,640
another it is

00:24:05,600 --> 00:24:08,640
this is not controlled

00:24:08,799 --> 00:24:12,080
okay that's brilliant there's one more

00:24:10,480 --> 00:24:13,120
question in the q a but i think i'll ask

00:24:12,080 --> 00:24:16,640
if you can take that

00:24:13,120 --> 00:24:18,880
uh in and reply in text that's the right

00:24:16,640 --> 00:24:21,120
we're at a short break now um just to

00:24:18,880 --> 00:24:23,440
give everybody a quick break and step

00:24:21,120 --> 00:24:24,559
away from the screen maybe make a quick

00:24:23,440 --> 00:24:28,000
drink or something

00:24:24,559 --> 00:24:29,600
uh so we'll be back at um 2 30

00:24:28,000 --> 00:24:32,640
um which is just in a couple of minutes

00:24:29,600 --> 00:24:35,679
now for the next talk uh see you

00:24:32,640 --> 00:24:40,480
see you then thanks thanks jonas yeah

00:24:35,679 --> 00:24:40,480

YouTube URL: https://www.youtube.com/watch?v=IKLMw8-FJxg


