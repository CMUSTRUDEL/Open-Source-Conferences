Title: Hybrid Parallelisation Challenges in Complex CFD Application
Publication date: 2020-12-21
Playlist: European OpenMP Users Conference 2020
Description: 
	This talk was presented at the 3rd European OpenMP Users Conference in 2020

Presented by : Jamil Appa, Zenotech

Conference Website: https://openmpusers.org
Follow us: https://twitter.com/openmp_users

Presentation Abstract :
In the development of parallel applications that make use of multiple parallelisation techniques including the use of third party parallel libraries, the correct use of OpenMP can be very challenging. We make use of MPI, threads, OpenMP, SIMD, CUDA and SYCL to provide efficient parallelism and the widest hardware support. We will present the challenges we faced developing zCFD to operate efficiently at scale for multiple architectures.
Captions: 
	00:00:04,720 --> 00:00:10,080
okay i'd like to uh welcome jamil appa

00:00:07,600 --> 00:00:11,519
he's the director and co-founder of

00:00:10,080 --> 00:00:14,880
xenotech limited

00:00:11,519 --> 00:00:16,080
i'm sure he'll introduce um the company

00:00:14,880 --> 00:00:18,320
but it's a a company

00:00:16,080 --> 00:00:20,000
that's based down in bristol um that

00:00:18,320 --> 00:00:23,039
does a lot of work with

00:00:20,000 --> 00:00:25,439
cfd and so over to you jamil um

00:00:23,039 --> 00:00:26,720
yes so i'm jim nappa uh i'm co-founder

00:00:25,439 --> 00:00:28,560
of xenotech

00:00:26,720 --> 00:00:30,000
um and i'll be talking to you today a

00:00:28,560 --> 00:00:31,359
little bit about

00:00:30,000 --> 00:00:33,840
some of the challenges i suppose we

00:00:31,359 --> 00:00:36,399
faced in in developing

00:00:33,840 --> 00:00:37,520
uh one of our products uh which is a cfd

00:00:36,399 --> 00:00:39,920
tool

00:00:37,520 --> 00:00:42,559
which uses a whole raft of different

00:00:39,920 --> 00:00:44,879
parallelization techniques

00:00:42,559 --> 00:00:46,559
a personal background is um so as i'm

00:00:44,879 --> 00:00:48,960
coming to this from a very much from a

00:00:46,559 --> 00:00:51,199
sort of an engineering point of view and

00:00:48,960 --> 00:00:53,280
fell into the the computer science piece

00:00:51,199 --> 00:00:54,320
but my colleague james sharp who has

00:00:53,280 --> 00:00:57,680
contributed to this

00:00:54,320 --> 00:00:59,840
uh this talk um is his background is

00:00:57,680 --> 00:01:01,920
computer science and math so so as a

00:00:59,840 --> 00:01:02,719
team within xenotech so we're we're

00:01:01,920 --> 00:01:05,760
stick strong

00:01:02,719 --> 00:01:06,720
um and as uh as tom pointed out we're

00:01:05,760 --> 00:01:09,360
based in bristol

00:01:06,720 --> 00:01:10,840
um and we have a combination of computer

00:01:09,360 --> 00:01:14,000
scientists engineers

00:01:10,840 --> 00:01:17,119
mathematicians uh physicists so we're

00:01:14,000 --> 00:01:20,479
we're quite a mixed bag

00:01:17,119 --> 00:01:22,400
um yeah we started off in in 2012

00:01:20,479 --> 00:01:24,000
and all our backgrounds i suppose are

00:01:22,400 --> 00:01:26,720
from the aerospace and

00:01:24,000 --> 00:01:27,680
defense sector uh and sort of brought

00:01:26,720 --> 00:01:30,079
the team together

00:01:27,680 --> 00:01:31,520
uh in uh sort of the two of us started

00:01:30,079 --> 00:01:32,720
in 2012 and so we're gradually bringing

00:01:31,520 --> 00:01:35,280
the team together over

00:01:32,720 --> 00:01:35,920
since then we have two main products uh

00:01:35,280 --> 00:01:38,240
one of them

00:01:35,920 --> 00:01:39,520
is the cfd solver which i'll be talking

00:01:38,240 --> 00:01:41,920
to you about today

00:01:39,520 --> 00:01:43,280
uh and our second product is uh

00:01:41,920 --> 00:01:44,479
effectively the best way of describing

00:01:43,280 --> 00:01:47,920
it is that it's a

00:01:44,479 --> 00:01:49,520
it's a portal to hpc uh cloud uh and by

00:01:47,920 --> 00:01:50,079
hpc cloud i mean you've been explored a

00:01:49,520 --> 00:01:53,360
sense

00:01:50,079 --> 00:01:54,720
of the typical cloud like aws and azure

00:01:53,360 --> 00:01:56,320
but also

00:01:54,720 --> 00:01:58,320
some of the academic super computers as

00:01:56,320 --> 00:01:59,680
well so we uh we broker access

00:01:58,320 --> 00:02:03,360
commercial access

00:01:59,680 --> 00:02:06,479
to those um those types of facilities

00:02:03,360 --> 00:02:09,599
um yeah so on on the cfd front um

00:02:06,479 --> 00:02:11,200
we very much uh were working so the team

00:02:09,599 --> 00:02:12,879
all together was previously working

00:02:11,200 --> 00:02:14,800
within the aerospace and defense sector

00:02:12,879 --> 00:02:18,000
developing these types of tools

00:02:14,800 --> 00:02:19,440
um for an internal customer um

00:02:18,000 --> 00:02:20,800
so for the internal for the engineers to

00:02:19,440 --> 00:02:22,560
use it internally within within the

00:02:20,800 --> 00:02:24,959
organization um

00:02:22,560 --> 00:02:26,239
and we sort of sort of had the thoughts

00:02:24,959 --> 00:02:27,760
of actually these the kind of techniques

00:02:26,239 --> 00:02:30,879
that we were developing would be

00:02:27,760 --> 00:02:31,840
uh of abuse and of interest to a wider

00:02:30,879 --> 00:02:33,519
community than just

00:02:31,840 --> 00:02:34,879
the uh the aerospace and defense

00:02:33,519 --> 00:02:36,640
community and

00:02:34,879 --> 00:02:38,319
hence the reason for uh for starting up

00:02:36,640 --> 00:02:39,760
xenotech um

00:02:38,319 --> 00:02:41,440
and i had the pleasure i suppose of

00:02:39,760 --> 00:02:41,920
starting with a totally clean sheet of

00:02:41,440 --> 00:02:43,680
paper

00:02:41,920 --> 00:02:44,959
in 2012 and writing something from

00:02:43,680 --> 00:02:48,239
scratch

00:02:44,959 --> 00:02:50,400
which um is is very infrequent i suppose

00:02:48,239 --> 00:02:52,879
in in the world of sort of hpc

00:02:50,400 --> 00:02:54,160
and uh and these types of these types of

00:02:52,879 --> 00:02:55,440
bits of software so we sort of decided

00:02:54,160 --> 00:02:56,560
to pull together the best in class

00:02:55,440 --> 00:02:59,760
algorithms

00:02:56,560 --> 00:03:02,239
um and really with the view of trying to

00:02:59,760 --> 00:03:04,000
make sure that we were i suppose as

00:03:02,239 --> 00:03:07,519
future-proof as possible so

00:03:04,000 --> 00:03:10,000
um given it was parallelism

00:03:07,519 --> 00:03:10,959
is sort of the the key to keep things

00:03:10,000 --> 00:03:13,120
going forward and it's just

00:03:10,959 --> 00:03:15,360
how do we express that parallelism in

00:03:13,120 --> 00:03:16,879
such a way that we can take benefit of

00:03:15,360 --> 00:03:18,560
whatever comes next because there's

00:03:16,879 --> 00:03:20,560
going to be new frameworks and

00:03:18,560 --> 00:03:22,640
and new processes coming out is making

00:03:20,560 --> 00:03:25,519
sure as best as we can

00:03:22,640 --> 00:03:26,720
is to delay it out in that sense just to

00:03:25,519 --> 00:03:27,360
give you some examples what i mean by

00:03:26,720 --> 00:03:30,480
cfd

00:03:27,360 --> 00:03:32,080
and complex cfd here's

00:03:30,480 --> 00:03:33,840
it looks like a simple example it's flow

00:03:32,080 --> 00:03:37,440
over over a building

00:03:33,840 --> 00:03:38,560
um and that's relatively simple

00:03:37,440 --> 00:03:41,680
geometrically

00:03:38,560 --> 00:03:45,200
but the physics of the flows is is

00:03:41,680 --> 00:03:46,640
really complex um and this is of a

00:03:45,200 --> 00:03:48,080
particular case that we've been we've

00:03:46,640 --> 00:03:49,120
been testing and this particular solver

00:03:48,080 --> 00:03:51,440
that we're running here is the

00:03:49,120 --> 00:03:52,879
we're using a discontinuous galactic and

00:03:51,440 --> 00:03:54,080
high order formulation

00:03:52,879 --> 00:03:56,799
uh which we're solving in this

00:03:54,080 --> 00:03:58,560
particular case um

00:03:56,799 --> 00:03:59,840
i suppose it is similar to what you've

00:03:58,560 --> 00:04:00,959
seen from the met office for

00:03:59,840 --> 00:04:02,879
discontinuous good luck in

00:04:00,959 --> 00:04:04,080
sort of a it's the halfway house between

00:04:02,879 --> 00:04:05,519
finite volume and

00:04:04,080 --> 00:04:07,439
and full finite element it's going to be

00:04:05,519 --> 00:04:10,480
the best way of describing it

00:04:07,439 --> 00:04:14,239
um give you another example

00:04:10,480 --> 00:04:17,280
um this is flow over the landing gear

00:04:14,239 --> 00:04:19,600
of uh of an airplane and it's the kind

00:04:17,280 --> 00:04:21,280
of things the way we would be solving

00:04:19,600 --> 00:04:23,040
these types of flows with the view of

00:04:21,280 --> 00:04:25,199
trying to predict the um

00:04:23,040 --> 00:04:28,639
the acoustics the noise being generated

00:04:25,199 --> 00:04:30,479
from from these types of structures

00:04:28,639 --> 00:04:32,160
for for aircraft actually when they when

00:04:30,479 --> 00:04:32,880
they come into land most of the noise

00:04:32,160 --> 00:04:34,880
that you hear

00:04:32,880 --> 00:04:36,000
as they come in um it's actually not

00:04:34,880 --> 00:04:38,240
from the uh

00:04:36,000 --> 00:04:39,520
it's not from the jet engines uh anymore

00:04:38,240 --> 00:04:40,880
it's actually from from everything else

00:04:39,520 --> 00:04:42,560
that's hanging off the aircraft

00:04:40,880 --> 00:04:44,080
but it needs to hang up four nights so

00:04:42,560 --> 00:04:46,240
when it's coming down to land so

00:04:44,080 --> 00:04:48,240
under carriage flaps and the like um

00:04:46,240 --> 00:04:50,160
generate the the bulk of the noise

00:04:48,240 --> 00:04:52,479
uh as it comes into as it comes into

00:04:50,160 --> 00:04:54,720
land uh so being able to sort of predict

00:04:52,479 --> 00:04:56,720
and design these uh

00:04:54,720 --> 00:04:58,240
these entities is important and these

00:04:56,720 --> 00:05:00,479
kind of calculations do take a

00:04:58,240 --> 00:05:01,840
they take a long time um partly because

00:05:00,479 --> 00:05:04,639
they have to be uh

00:05:01,840 --> 00:05:06,000
uh time accurate um and and solving

00:05:04,639 --> 00:05:09,280
acoustics on them can be

00:05:06,000 --> 00:05:11,120
uh can be time-consuming as well

00:05:09,280 --> 00:05:13,360
here's something slightly slightly

00:05:11,120 --> 00:05:15,360
simpler but with more complex physics i

00:05:13,360 --> 00:05:18,639
suppose involved in that this is a

00:05:15,360 --> 00:05:21,759
vortex hitting a shock wave example

00:05:18,639 --> 00:05:23,759
um it gives you some nice nice nice flow

00:05:21,759 --> 00:05:25,120
features as things sort of all mix and

00:05:23,759 --> 00:05:26,240
you've got shock waves going going all

00:05:25,120 --> 00:05:28,479
over the place

00:05:26,240 --> 00:05:29,600
um again these are sort of these these

00:05:28,479 --> 00:05:31,360
high speed flows

00:05:29,600 --> 00:05:33,360
uh are important in certain industries

00:05:31,360 --> 00:05:34,720
as well so it gives you to give you an

00:05:33,360 --> 00:05:35,120
idea of the kind of range of things that

00:05:34,720 --> 00:05:37,919
we do

00:05:35,120 --> 00:05:38,560
all the way from low speed flows around

00:05:37,919 --> 00:05:40,880
buildings

00:05:38,560 --> 00:05:41,600
uh all the way to more high speed flows

00:05:40,880 --> 00:05:43,440
i suppose

00:05:41,600 --> 00:05:44,800
which you can see which you can see here

00:05:43,440 --> 00:05:46,639
and this is all encompassed within

00:05:44,800 --> 00:05:48,240
within a single solver so

00:05:46,639 --> 00:05:50,560
it's it's making sure that we've got all

00:05:48,240 --> 00:05:51,759
the the right algorithms in that in that

00:05:50,560 --> 00:05:55,440
framework to analysis

00:05:51,759 --> 00:05:58,479
of that range of that range of speeds um

00:05:55,440 --> 00:05:58,479
is is key

00:06:00,080 --> 00:06:03,280
something a little bit more detail about

00:06:01,440 --> 00:06:05,840
the about the code itself

00:06:03,280 --> 00:06:08,479
um so obviously when i first started out

00:06:05,840 --> 00:06:11,680
c plus plus 11 had just hit the streets

00:06:08,479 --> 00:06:13,600
um and the the support

00:06:11,680 --> 00:06:15,280
from uh the compiler support for c plus

00:06:13,600 --> 00:06:17,440
plus 11 at the time was

00:06:15,280 --> 00:06:19,199
was patchy um you were still having to

00:06:17,440 --> 00:06:20,960
use sort of

00:06:19,199 --> 00:06:22,720
c plus plus compilers and used

00:06:20,960 --> 00:06:24,240
components to try and get up to that to

00:06:22,720 --> 00:06:24,639
the uh to what was being offered in c

00:06:24,240 --> 00:06:27,840
plus

00:06:24,639 --> 00:06:29,919
11. um obviously since then um

00:06:27,840 --> 00:06:31,440
17 has come out with a whole bunch of

00:06:29,919 --> 00:06:33,680
new additions as well

00:06:31,440 --> 00:06:35,600
um so i would say the core of our code

00:06:33,680 --> 00:06:37,520
we do make use of some c plus plus 17

00:06:35,600 --> 00:06:39,759
features but it's not it's not huge

00:06:37,520 --> 00:06:40,720
um we're gradually migrating across to

00:06:39,759 --> 00:06:42,319
that um

00:06:40,720 --> 00:06:44,319
but the core the core is all written in

00:06:42,319 --> 00:06:47,120
c plus um

00:06:44,319 --> 00:06:48,880
we front all of that with python um and

00:06:47,120 --> 00:06:49,360
that's purely for ease of integration

00:06:48,880 --> 00:06:52,160
into

00:06:49,360 --> 00:06:52,880
uh into our customers processes um but

00:06:52,160 --> 00:06:54,720
it also

00:06:52,880 --> 00:06:56,560
in terms of from a usability point of

00:06:54,720 --> 00:06:59,520
view and as it has

00:06:56,560 --> 00:07:02,000
i i use as expected to customize what

00:06:59,520 --> 00:07:04,319
we're doing relatively simply um

00:07:02,000 --> 00:07:06,240
because it's uh because it's it's set

00:07:04,319 --> 00:07:08,319
within with with python we've just very

00:07:06,240 --> 00:07:10,960
recently actually moved across to

00:07:08,319 --> 00:07:12,560
the python three um there's a little bit

00:07:10,960 --> 00:07:14,639
a little bit a little bit of a headache

00:07:12,560 --> 00:07:17,039
um but that's that's done now uh and

00:07:14,639 --> 00:07:18,639
that works uh that works nicely

00:07:17,039 --> 00:07:21,280
and again just for information we use uh

00:07:18,639 --> 00:07:23,599
boost python as the means of

00:07:21,280 --> 00:07:25,919
gluing the two together uh and we find

00:07:23,599 --> 00:07:27,840
that works uh that works really well

00:07:25,919 --> 00:07:29,599
from a parallel point of view uh we make

00:07:27,840 --> 00:07:32,880
use of mpi

00:07:29,599 --> 00:07:36,000
for multi-process

00:07:32,880 --> 00:07:37,840
parallelism um and we tend to run

00:07:36,000 --> 00:07:40,880
this is not not sort of enforcing the

00:07:37,840 --> 00:07:43,199
users but but mostly by default

00:07:40,880 --> 00:07:44,319
the application runs one mpi task for

00:07:43,199 --> 00:07:47,360
numa region

00:07:44,319 --> 00:07:49,199
um which uh you know previously that was

00:07:47,360 --> 00:07:50,720
one per socket on the cpu side but

00:07:49,199 --> 00:07:52,479
obviously with

00:07:50,720 --> 00:07:54,160
with the new amd processors coming out

00:07:52,479 --> 00:07:57,599
that's a little bit more complicated

00:07:54,160 --> 00:08:01,120
um or we use one mpi process per device

00:07:57,599 --> 00:08:04,000
if we are targeting uh gpus for example

00:08:01,120 --> 00:08:04,319
um so that's the typical way we would uh

00:08:04,000 --> 00:08:06,879
the

00:08:04,319 --> 00:08:07,759
the application would start up um we

00:08:06,879 --> 00:08:10,960
also make use

00:08:07,759 --> 00:08:14,000
of a library called uh called nickel

00:08:10,960 --> 00:08:15,520
from nvidia um and when we're when we're

00:08:14,000 --> 00:08:18,319
running on gpus we use

00:08:15,520 --> 00:08:19,840
we use that library to do uh into gpu

00:08:18,319 --> 00:08:22,080
comms

00:08:19,840 --> 00:08:24,000
two reasons for it uh obviously one of

00:08:22,080 --> 00:08:26,000
the uh one of the bits it is highly

00:08:24,000 --> 00:08:28,800
tuned obviously to make use of nv

00:08:26,000 --> 00:08:29,919
link uh between the gpus uh when you're

00:08:28,800 --> 00:08:33,039
on a node

00:08:29,919 --> 00:08:36,399
um but also it is um

00:08:33,039 --> 00:08:39,360
it will use or offload you'll do rdma

00:08:36,399 --> 00:08:41,599
over using gpu direct over the network

00:08:39,360 --> 00:08:43,519
as well um

00:08:41,599 --> 00:08:46,399
and that then actually doesn't require

00:08:43,519 --> 00:08:48,959
us to have our mpi layer

00:08:46,399 --> 00:08:51,360
uh effectively cudaware so we can we can

00:08:48,959 --> 00:08:53,600
and you can mix and match nickel and mpi

00:08:51,360 --> 00:08:56,000
and they do work nicely together so your

00:08:53,600 --> 00:08:58,800
mpi layer can be very much very generic

00:08:56,000 --> 00:09:00,000
um and you can leave sort of the the gpu

00:08:58,800 --> 00:09:03,120
aware part of

00:09:00,000 --> 00:09:04,880
your communications up to nickel um

00:09:03,120 --> 00:09:06,399
and that does become for us at least

00:09:04,880 --> 00:09:08,560
where we're distributing we're trying to

00:09:06,399 --> 00:09:10,320
distribute this code commercially

00:09:08,560 --> 00:09:11,920
the portability of those distributions

00:09:10,320 --> 00:09:13,839
becomes important and trying to

00:09:11,920 --> 00:09:15,839
make sure that your mpi distribution

00:09:13,839 --> 00:09:19,279
that you have is portable

00:09:15,839 --> 00:09:21,680
um and supports things like cuda is

00:09:19,279 --> 00:09:23,120
at least today a bit of a headache so

00:09:21,680 --> 00:09:24,640
actually the combination of these two

00:09:23,120 --> 00:09:26,560
actually delivers that delivers that

00:09:24,640 --> 00:09:29,680
requirement

00:09:26,560 --> 00:09:31,360
uh once we're within an mpi process we

00:09:29,680 --> 00:09:35,600
use a combination of threads

00:09:31,360 --> 00:09:38,560
um and beneath that we then use openmp

00:09:35,600 --> 00:09:40,560
or cuda depending on on on the

00:09:38,560 --> 00:09:41,839
architectures that we're targeting

00:09:40,560 --> 00:09:43,519
and the reason for sort of fronting

00:09:41,839 --> 00:09:45,440
everything using threads is it allows us

00:09:43,519 --> 00:09:46,320
to decouple certain operations so for

00:09:45,440 --> 00:09:49,600
example we

00:09:46,320 --> 00:09:51,600
uh to allow us to overlap mpi operations

00:09:49,600 --> 00:09:54,959
with other with other compute

00:09:51,600 --> 00:09:57,279
um a lot of our mpi traffic is happening

00:09:54,959 --> 00:09:59,120
on a dedicated thread

00:09:57,279 --> 00:10:00,399
um so it allows us to do some some

00:09:59,120 --> 00:10:02,160
overlapping um

00:10:00,399 --> 00:10:04,000
but also it becomes it becomes helpful

00:10:02,160 --> 00:10:05,760
for other things which are happening

00:10:04,000 --> 00:10:07,360
uh within the within the solver to allow

00:10:05,760 --> 00:10:09,920
us to overlap

00:10:07,360 --> 00:10:11,920
um to overlap tasks which which are

00:10:09,920 --> 00:10:13,440
happening um i'll come back to

00:10:11,920 --> 00:10:15,120
some of the headaches that that brings a

00:10:13,440 --> 00:10:17,040
bit later on but yeah so you've got

00:10:15,120 --> 00:10:18,399
parallelism from an mpi point of view

00:10:17,040 --> 00:10:19,920
powers and from a

00:10:18,399 --> 00:10:21,440
thread's point of view and then below

00:10:19,920 --> 00:10:21,920
that you've got probabilism from an open

00:10:21,440 --> 00:10:23,360
mp

00:10:21,920 --> 00:10:25,040
or cuda point of view and i suppose you

00:10:23,360 --> 00:10:26,480
could go down one level deeper than that

00:10:25,040 --> 00:10:28,720
and you've also got vectorization

00:10:26,480 --> 00:10:31,839
motherhood as well

00:10:28,720 --> 00:10:33,440
um we've got minimal device specific

00:10:31,839 --> 00:10:34,720
code i'd say we haven't got a huge

00:10:33,440 --> 00:10:36,959
number of lines which are sort of very

00:10:34,720 --> 00:10:39,440
specific to one architecture

00:10:36,959 --> 00:10:41,519
or the nexus for example uh cuda's

00:10:39,440 --> 00:10:44,079
kernel syntax or

00:10:41,519 --> 00:10:45,440
even some of the openmp pragmas um

00:10:44,079 --> 00:10:46,800
they're not sort of liberally spread

00:10:45,440 --> 00:10:50,079
around the code

00:10:46,800 --> 00:10:50,720
um we sort of hide that away from from

00:10:50,079 --> 00:10:52,240
the

00:10:50,720 --> 00:10:54,399
from the developer i suppose in a

00:10:52,240 --> 00:10:56,320
similar way to the the the talk

00:10:54,399 --> 00:10:58,000
from the from the met office around the

00:10:56,320 --> 00:11:01,120
separation of concerns

00:10:58,000 --> 00:11:02,959
we try and separate out the uh the the

00:11:01,120 --> 00:11:04,480
complexity sometimes of targeting

00:11:02,959 --> 00:11:07,200
specific hardware

00:11:04,480 --> 00:11:08,240
from the uh the algorithm itself from

00:11:07,200 --> 00:11:11,600
the mathematics

00:11:08,240 --> 00:11:13,279
um things like gpus we it uses runtime

00:11:11,600 --> 00:11:15,200
introspection so we actually goes in and

00:11:13,279 --> 00:11:17,040
has a look at the kernels

00:11:15,200 --> 00:11:18,560
and to decide on the the launch

00:11:17,040 --> 00:11:20,240
parameters that they use for those

00:11:18,560 --> 00:11:22,320
particular devices

00:11:20,240 --> 00:11:25,120
um and we're using a lot of the the

00:11:22,320 --> 00:11:27,440
mechanisms of c plus plus i suppose to

00:11:25,120 --> 00:11:28,560
to allow for the compiler to do the

00:11:27,440 --> 00:11:30,880
heavy lifting

00:11:28,560 --> 00:11:33,600
um so these these code paths whether the

00:11:30,880 --> 00:11:37,120
cuda code path the openmp code path

00:11:33,600 --> 00:11:37,920
um is built and compiled into this into

00:11:37,120 --> 00:11:40,720
these libraries

00:11:37,920 --> 00:11:42,320
um but and that is basically down to

00:11:40,720 --> 00:11:43,279
depending on which compiler is being

00:11:42,320 --> 00:11:45,600
used so

00:11:43,279 --> 00:11:47,440
if you're using nvcc for example it will

00:11:45,600 --> 00:11:48,720
compile the the cuda code path

00:11:47,440 --> 00:11:51,040
if you're using and we're going to use

00:11:48,720 --> 00:11:52,800
intel compiler using the intel compiler

00:11:51,040 --> 00:11:54,160
it would be the openmp code path which

00:11:52,800 --> 00:11:56,079
is which is done and that's just done

00:11:54,160 --> 00:11:57,680
automatically behind those things so

00:11:56,079 --> 00:11:59,600
the compiler is doing a lot of a lot of

00:11:57,680 --> 00:12:03,120
heavy lifting for you

00:11:59,600 --> 00:12:05,279
um again back in this is back in

00:12:03,120 --> 00:12:07,200
starting in 2011 we were just using sort

00:12:05,279 --> 00:12:08,880
of functions lambdas were starting

00:12:07,200 --> 00:12:10,399
starting to appear with c plus plus 11

00:12:08,880 --> 00:12:11,839
but yeah it uses sort of a functor

00:12:10,399 --> 00:12:14,160
lambda pattern

00:12:11,839 --> 00:12:15,120
to inject these parallel kernels at

00:12:14,160 --> 00:12:17,040
compile time

00:12:15,120 --> 00:12:18,639
into these various code paths so again

00:12:17,040 --> 00:12:22,480
all of this is being done

00:12:18,639 --> 00:12:24,480
is is being done by the compiler um

00:12:22,480 --> 00:12:25,920
and deciding which which ones to pull in

00:12:24,480 --> 00:12:29,200
uh at which time

00:12:25,920 --> 00:12:31,200
um we do have a few device specific

00:12:29,200 --> 00:12:31,680
parallel kernels uh there's some cases

00:12:31,200 --> 00:12:35,120
which

00:12:31,680 --> 00:12:36,800
um it is it's just not possible to write

00:12:35,120 --> 00:12:40,560
something which is totally generic

00:12:36,800 --> 00:12:41,839
um i'm trying to think of things like um

00:12:40,560 --> 00:12:43,680
where we're doing sort of parallel

00:12:41,839 --> 00:12:45,519
summations and trying to sort of

00:12:43,680 --> 00:12:46,959
rejuvenate maximize accuracy when we

00:12:45,519 --> 00:12:48,160
when we do those summations and we're

00:12:46,959 --> 00:12:50,880
doing some we have to use

00:12:48,160 --> 00:12:51,519
uh kahan summation to try and reduce the

00:12:50,880 --> 00:12:54,160
error there

00:12:51,519 --> 00:12:56,560
um that's quite hard to do in a totally

00:12:54,160 --> 00:12:58,480
generic way um so we do have a few

00:12:56,560 --> 00:12:59,760
a few specific kernels but in the most

00:12:58,480 --> 00:13:02,240
most of the kernels and

00:12:59,760 --> 00:13:04,240
and we're talking here of order of

00:13:02,240 --> 00:13:08,480
several hundred kernels

00:13:04,240 --> 00:13:09,519
um in uh in in one of the in one of the

00:13:08,480 --> 00:13:12,320
solvers

00:13:09,519 --> 00:13:13,680
uh are all generic and they're generic

00:13:12,320 --> 00:13:16,000
whether they're open

00:13:13,680 --> 00:13:16,880
or being run through cuda it's the same

00:13:16,000 --> 00:13:20,240
piece of code

00:13:16,880 --> 00:13:22,800
um and i'll show you an example later

00:13:20,240 --> 00:13:24,320
um this issue of memory spaces uh when

00:13:22,800 --> 00:13:26,000
you're talking about being able to work

00:13:24,320 --> 00:13:29,120
with multiple devices and we handle

00:13:26,000 --> 00:13:30,079
different memory spaces by um by storing

00:13:29,120 --> 00:13:31,440
multiple pointers

00:13:30,079 --> 00:13:33,200
to the different memory spaces so we've

00:13:31,440 --> 00:13:34,079
got this concept of i suppose it's

00:13:33,200 --> 00:13:36,480
coming into the

00:13:34,079 --> 00:13:37,440
parallel c plus plus concept of a

00:13:36,480 --> 00:13:39,279
multi-point

00:13:37,440 --> 00:13:41,600
um which uh points to different memory

00:13:39,279 --> 00:13:42,800
spaces and again the compiler depending

00:13:41,600 --> 00:13:45,920
on the code path it's

00:13:42,800 --> 00:13:46,800
it's it's compiling for will use the

00:13:45,920 --> 00:13:48,320
appropriate

00:13:46,800 --> 00:13:50,000
version of that pointer for the memory

00:13:48,320 --> 00:13:50,880
space appropriate for that particular

00:13:50,000 --> 00:13:53,600
code path

00:13:50,880 --> 00:13:55,120
um so again the the compiler is doing

00:13:53,600 --> 00:13:57,360
the work of deciding

00:13:55,120 --> 00:13:58,320
which one to use under the hood the uh

00:13:57,360 --> 00:14:01,360
the developer

00:13:58,320 --> 00:14:03,519
doesn't see any of that at all

00:14:01,360 --> 00:14:04,639
um and the other issues which tend to

00:14:03,519 --> 00:14:08,480
hit us is things like

00:14:04,639 --> 00:14:09,839
uh memory layout um so things like

00:14:08,480 --> 00:14:11,199
when to use an array of structure and

00:14:09,839 --> 00:14:12,399
when you use structures of arrays and

00:14:11,199 --> 00:14:14,000
again these things

00:14:12,399 --> 00:14:15,440
depending on architecture actually then

00:14:14,000 --> 00:14:16,560
depending on the algorithm that you're

00:14:15,440 --> 00:14:20,160
using as well

00:14:16,560 --> 00:14:21,760
uh vary um and that again can be runtime

00:14:20,160 --> 00:14:22,639
configured using trades so again these

00:14:21,760 --> 00:14:25,040
traits

00:14:22,639 --> 00:14:26,720
can be dependent on the the path that's

00:14:25,040 --> 00:14:28,399
been the compar the code path that's

00:14:26,720 --> 00:14:29,760
being compiled for

00:14:28,399 --> 00:14:31,440
and you can make these decisions so for

00:14:29,760 --> 00:14:32,880
example padding and alignment and all

00:14:31,440 --> 00:14:35,279
those kind of things which you might

00:14:32,880 --> 00:14:36,880
which are important when it comes to uh

00:14:35,279 --> 00:14:39,920
performance and vectorization

00:14:36,880 --> 00:14:43,120
um is all compiled it's all

00:14:39,920 --> 00:14:46,079
decided for at compile time um so

00:14:43,120 --> 00:14:47,760
we we do rely on the compiler doing uh

00:14:46,079 --> 00:14:50,399
doing a lot of a lot of heavy lifting

00:14:47,760 --> 00:14:50,399
work for us

00:14:50,800 --> 00:14:55,600
um just a few facts and figures um yeah

00:14:54,000 --> 00:14:57,600
we use as i mentioned we use the intel

00:14:55,600 --> 00:15:00,560
tool chain um and very much that is for

00:14:57,600 --> 00:15:04,160
portability so one of the issues with

00:15:00,560 --> 00:15:06,959
trying to use um some of the uh

00:15:04,160 --> 00:15:08,639
other mpi implementations for example

00:15:06,959 --> 00:15:09,360
their portability between different

00:15:08,639 --> 00:15:12,800
systems

00:15:09,360 --> 00:15:14,720
uh is it's difficult because they tend

00:15:12,800 --> 00:15:17,279
to sort of link into

00:15:14,720 --> 00:15:19,199
uh very specific uh especially

00:15:17,279 --> 00:15:21,199
infiniband libraries

00:15:19,199 --> 00:15:22,720
which you can't then take from one

00:15:21,199 --> 00:15:24,959
system to the next

00:15:22,720 --> 00:15:26,000
um so the intel tool chain actually

00:15:24,959 --> 00:15:27,839
gives us that portability

00:15:26,000 --> 00:15:29,519
between different systems and that that

00:15:27,839 --> 00:15:31,360
works that works great for us

00:15:29,519 --> 00:15:32,639
the other beauty that the intel tool

00:15:31,360 --> 00:15:36,000
chain delivers uh

00:15:32,639 --> 00:15:38,160
is from a cmd point of view it allows us

00:15:36,000 --> 00:15:41,040
to target multiple architectures

00:15:38,160 --> 00:15:42,959
uh intel architectures within one one

00:15:41,040 --> 00:15:46,000
one executable so it will then

00:15:42,959 --> 00:15:47,839
automatically uh choose the uh the

00:15:46,000 --> 00:15:48,639
vectorization which is appropriate for

00:15:47,839 --> 00:15:51,360
the underlying

00:15:48,639 --> 00:15:53,120
hardware that's being run on at the time

00:15:51,360 --> 00:15:55,360
and that's that's a great bonus for us

00:15:53,120 --> 00:15:57,440
because we don't have to then compile

00:15:55,360 --> 00:16:00,240
a huge different number of variants of

00:15:57,440 --> 00:16:02,560
the code we can we can deliver a single

00:16:00,240 --> 00:16:05,040
uh a single code which uh allows us to

00:16:02,560 --> 00:16:06,959
target a huge number of architectures um

00:16:05,040 --> 00:16:08,399
automatically and it does does a

00:16:06,959 --> 00:16:09,440
reasonable job at trying to decide which

00:16:08,399 --> 00:16:12,800
is the best

00:16:09,440 --> 00:16:14,160
uh vectorization uh support for various

00:16:12,800 --> 00:16:16,720
parts of the code uh

00:16:14,160 --> 00:16:18,160
to deliver um one of the things the

00:16:16,720 --> 00:16:20,240
other things we do we independently

00:16:18,160 --> 00:16:22,399
build all the dependencies

00:16:20,240 --> 00:16:23,759
so we have control over of all the build

00:16:22,399 --> 00:16:26,079
parameters and again i'll come back to

00:16:23,759 --> 00:16:28,480
why that's why that's important uh

00:16:26,079 --> 00:16:29,600
in in in some of the challenges that we

00:16:28,480 --> 00:16:31,199
have a little bit later

00:16:29,600 --> 00:16:33,040
but it does give us then the ability to

00:16:31,199 --> 00:16:34,320
lock down on on build parameters and

00:16:33,040 --> 00:16:36,000
versions um

00:16:34,320 --> 00:16:38,639
and we build things all the way from

00:16:36,000 --> 00:16:39,759
python to even open ssl

00:16:38,639 --> 00:16:41,680
because the systems that we're

00:16:39,759 --> 00:16:44,320
delivering the code on to don't

00:16:41,680 --> 00:16:45,759
necessarily have

00:16:44,320 --> 00:16:47,920
these types of libraries which are up to

00:16:45,759 --> 00:16:49,199
date so we carry all of these things

00:16:47,920 --> 00:16:51,120
with us

00:16:49,199 --> 00:16:52,720
just to make sure that we know which

00:16:51,120 --> 00:16:53,279
versions we are so if something does go

00:16:52,720 --> 00:16:55,120
wrong

00:16:53,279 --> 00:16:56,560
it is out it is truly our fault it's not

00:16:55,120 --> 00:16:58,399
something which is

00:16:56,560 --> 00:16:59,600
um due to a particular version of

00:16:58,399 --> 00:17:01,600
software on the

00:16:59,600 --> 00:17:03,120
on the end user system and from the

00:17:01,600 --> 00:17:05,839
build point of view we use

00:17:03,120 --> 00:17:06,480
bazel from google in combination with

00:17:05,839 --> 00:17:09,520
cmake

00:17:06,480 --> 00:17:10,880
and ninja on the build side and the

00:17:09,520 --> 00:17:12,959
combination of all of those i think from

00:17:10,880 --> 00:17:14,400
a parallel build point of view gives us

00:17:12,959 --> 00:17:16,559
the right features of bazel gives us

00:17:14,400 --> 00:17:18,000
sort of the automatically sealed

00:17:16,559 --> 00:17:20,480
builds so we know exactly what we're

00:17:18,000 --> 00:17:20,959
building uh ninja gives us the powers

00:17:20,480 --> 00:17:22,880
and the

00:17:20,959 --> 00:17:24,079
the build priorities in peace um but

00:17:22,880 --> 00:17:24,720
yeah just to give you an idea so we're

00:17:24,079 --> 00:17:26,480
building

00:17:24,720 --> 00:17:29,120
and we build things like power view

00:17:26,480 --> 00:17:31,520
we're building the the trionos libraries

00:17:29,120 --> 00:17:32,160
uh so these are the two big ones uh also

00:17:31,520 --> 00:17:35,200
with all

00:17:32,160 --> 00:17:37,200
our solvers as well um it takes it takes

00:17:35,200 --> 00:17:38,480
around an hour to build on 56 cores so

00:17:37,200 --> 00:17:40,559
there's a lot there's there's a lot

00:17:38,480 --> 00:17:42,880
being built each time

00:17:40,559 --> 00:17:44,799
test cycles that we run on jenkins can

00:17:42,880 --> 00:17:47,520
take up to 24 hours depending how busy

00:17:44,799 --> 00:17:48,400
various clusters that we use to test on

00:17:47,520 --> 00:17:50,640
um

00:17:48,400 --> 00:17:52,000
and once you've packaged everything up

00:17:50,640 --> 00:17:54,080
um including all the runtime

00:17:52,000 --> 00:17:56,559
dependencies from the likes of intel and

00:17:54,080 --> 00:17:58,080
mkl and all the cuda dependent and

00:17:56,559 --> 00:18:00,799
or coolers and everything else that

00:17:58,080 --> 00:18:01,520
comes along you have a you have a table

00:18:00,799 --> 00:18:04,000
which is of

00:18:01,520 --> 00:18:05,679
about two and a half gigs in size um so

00:18:04,000 --> 00:18:08,960
it's not insignificant

00:18:05,679 --> 00:18:10,320
um but yeah some of the uh and it's less

00:18:08,960 --> 00:18:12,080
our code which is big it's actually a

00:18:10,320 --> 00:18:13,679
lot of the runtime libraries so

00:18:12,080 --> 00:18:16,480
runtime libraries which come with cuda

00:18:13,679 --> 00:18:19,200
and uh and the intel tool chain

00:18:16,480 --> 00:18:20,480
uh do consume a huge amount of space um

00:18:19,200 --> 00:18:21,600
but just give an idea it gives you an

00:18:20,480 --> 00:18:23,120
idea of the kind of stuff

00:18:21,600 --> 00:18:24,880
we also on the on the container side

00:18:23,120 --> 00:18:25,840
make use of singularity sometimes when

00:18:24,880 --> 00:18:28,000
uh

00:18:25,840 --> 00:18:28,880
when yeah trying to get make sure the

00:18:28,000 --> 00:18:30,320
end end user

00:18:28,880 --> 00:18:32,160
the support on the end user system

00:18:30,320 --> 00:18:35,600
doesn't quite match and we can we can

00:18:32,160 --> 00:18:37,039
deliver things in containers as well

00:18:35,600 --> 00:18:38,880
just give a quick idea what the what

00:18:37,039 --> 00:18:39,360
sort of the the code ends up looking

00:18:38,880 --> 00:18:42,400
like

00:18:39,360 --> 00:18:43,679
um so this is if you look at it honestly

00:18:42,400 --> 00:18:46,400
just looks it looks as much as

00:18:43,679 --> 00:18:47,840
a c as c plus plus um but just sort of

00:18:46,400 --> 00:18:51,679
just take you take you down there

00:18:47,840 --> 00:18:54,080
um so for example the the model constant

00:18:51,679 --> 00:18:55,440
uh that's actually expands into a macro

00:18:54,080 --> 00:18:57,120
obviously on the likes of

00:18:55,440 --> 00:18:58,559
on gpus there's different memories

00:18:57,120 --> 00:18:59,200
there's there's constant memory there's

00:18:58,559 --> 00:19:01,039
loads of this

00:18:59,200 --> 00:19:02,320
there's uh locally shared memory there's

00:19:01,039 --> 00:19:04,160
global memory

00:19:02,320 --> 00:19:05,679
um and the constants that we use within

00:19:04,160 --> 00:19:07,440
the solver on the gpu at least are

00:19:05,679 --> 00:19:10,480
mapped into constant memory

00:19:07,440 --> 00:19:11,840
uh on the cpu side it is just uh it's

00:19:10,480 --> 00:19:13,760
just a constant which is which is

00:19:11,840 --> 00:19:15,919
declared within the solver

00:19:13,760 --> 00:19:17,360
so depending on the code path the the

00:19:15,919 --> 00:19:18,000
compilers which are coming down through

00:19:17,360 --> 00:19:20,080
this

00:19:18,000 --> 00:19:21,120
that model constant macro there then

00:19:20,080 --> 00:19:24,080
will then

00:19:21,120 --> 00:19:26,400
target the appropriate memory um to pick

00:19:24,080 --> 00:19:28,799
out that constant that's one example

00:19:26,400 --> 00:19:29,760
um obviously you can see the cmd

00:19:28,799 --> 00:19:31,840
alignment there

00:19:29,760 --> 00:19:33,120
uh keyword which is which which is being

00:19:31,840 --> 00:19:34,960
used

00:19:33,120 --> 00:19:38,080
again that's something which is expanded

00:19:34,960 --> 00:19:39,760
depending on on the code path

00:19:38,080 --> 00:19:41,679
that align as keyword obviously is

00:19:39,760 --> 00:19:42,320
important on the on the cpu side but not

00:19:41,679 --> 00:19:44,960
on

00:19:42,320 --> 00:19:47,120
not on the gpu side um but then

00:19:44,960 --> 00:19:49,840
everything else in terms of the

00:19:47,120 --> 00:19:51,440
loops that you can see below um

00:19:49,840 --> 00:19:54,480
effectively hidden behind the scenes

00:19:51,440 --> 00:19:57,600
are our c plus bus operators

00:19:54,480 --> 00:19:59,840
um but as you can see they effectively

00:19:57,600 --> 00:20:02,320
for sense and purposes appear as as

00:19:59,840 --> 00:20:04,320
normal sort of array accesses

00:20:02,320 --> 00:20:06,400
but interestingly behind the scenes we

00:20:04,320 --> 00:20:08,000
can change the layouts of all of this of

00:20:06,400 --> 00:20:09,360
this memory from array of structures to

00:20:08,000 --> 00:20:11,840
structures of arrays

00:20:09,360 --> 00:20:13,120
we can change the padding and again we

00:20:11,840 --> 00:20:16,080
can change the alignment

00:20:13,120 --> 00:20:17,520
uh but from a a assigned to sort of

00:20:16,080 --> 00:20:20,240
developer point of view

00:20:17,520 --> 00:20:21,600
this code stays exactly the same so

00:20:20,240 --> 00:20:23,520
we're sort of trying to get to the point

00:20:21,600 --> 00:20:24,640
where yeah you write it once and compile

00:20:23,520 --> 00:20:27,280
it multiple times

00:20:24,640 --> 00:20:28,400
um and target the appropriate hardware

00:20:27,280 --> 00:20:30,240
uh accordingly

00:20:28,400 --> 00:20:31,919
um but yeah that gives you it gives you

00:20:30,240 --> 00:20:33,360
an example of what the what

00:20:31,919 --> 00:20:35,840
sort of the code under the hood looks

00:20:33,360 --> 00:20:35,840
like

00:20:36,320 --> 00:20:40,320
so coming to some of the um some of the

00:20:38,880 --> 00:20:42,880
challenges that we face

00:20:40,320 --> 00:20:44,320
in terms of developing this um as you

00:20:42,880 --> 00:20:45,760
can imagine as i've already mentioned

00:20:44,320 --> 00:20:48,080
we're putting in quite a few third-party

00:20:45,760 --> 00:20:49,039
libraries and especially when it comes

00:20:48,080 --> 00:20:50,880
to openmp

00:20:49,039 --> 00:20:52,320
and i can be almost the same the same is

00:20:50,880 --> 00:20:54,880
true of mpi

00:20:52,320 --> 00:20:57,360
um ensuring sort of consistency of the

00:20:54,880 --> 00:20:57,919
use of openmp can be complex so for

00:20:57,360 --> 00:21:00,880
example

00:20:57,919 --> 00:21:02,640
if if i downloaded uh the truenos

00:21:00,880 --> 00:21:03,919
library and let's say it was a pre-built

00:21:02,640 --> 00:21:06,720
version of it

00:21:03,919 --> 00:21:07,360
um and they had built it against uh lib

00:21:06,720 --> 00:21:10,880
gomp

00:21:07,360 --> 00:21:12,400
um and i was using lib uh the the intel

00:21:10,880 --> 00:21:15,360
version the iop

00:21:12,400 --> 00:21:16,720
um you run into all sorts of sorts of

00:21:15,360 --> 00:21:18,080
issues um

00:21:16,720 --> 00:21:19,280
so we're in a lucky position at the

00:21:18,080 --> 00:21:20,960
moment of being able to compile

00:21:19,280 --> 00:21:22,080
everything and having control over the

00:21:20,960 --> 00:21:23,520
build parameters of all these

00:21:22,080 --> 00:21:24,080
third-party libraries but there are

00:21:23,520 --> 00:21:26,000
cases

00:21:24,080 --> 00:21:27,520
i can see coming into the future where

00:21:26,000 --> 00:21:28,840
we're going to be wanting to use

00:21:27,520 --> 00:21:31,600
third-party libraries which come

00:21:28,840 --> 00:21:33,520
pre-compiled and making sure those these

00:21:31,600 --> 00:21:35,760
things are consistent it can become

00:21:33,520 --> 00:21:37,360
more more and more complicated so

00:21:35,760 --> 00:21:39,679
dealing with that is something

00:21:37,360 --> 00:21:41,679
is something of a challenge um we've

00:21:39,679 --> 00:21:45,280
also found some of the openmp

00:21:41,679 --> 00:21:47,360
using some of the openmpcmd features um

00:21:45,280 --> 00:21:48,960
does interfere with sort of the

00:21:47,360 --> 00:21:50,080
automatic vectorization in some

00:21:48,960 --> 00:21:52,720
compilers so

00:21:50,080 --> 00:21:53,919
you didn't sort of get the the uh the

00:21:52,720 --> 00:21:56,240
consistent use of that

00:21:53,919 --> 00:21:58,159
um so we've actually turned off uh the

00:21:56,240 --> 00:22:00,320
openmp cindy features

00:21:58,159 --> 00:22:01,679
uh because it seemed to be conflicting

00:22:00,320 --> 00:22:02,880
with some of the optimizations which

00:22:01,679 --> 00:22:06,159
were happening

00:22:02,880 --> 00:22:09,200
um by default in the in in the compiler

00:22:06,159 --> 00:22:10,960
uh that we were using um so that's

00:22:09,200 --> 00:22:12,400
that's an interesting one that we've

00:22:10,960 --> 00:22:14,159
come across as well

00:22:12,400 --> 00:22:16,000
and then obviously controlling what

00:22:14,159 --> 00:22:18,159
opening pds from multiple threads as i

00:22:16,000 --> 00:22:20,960
mentioned we we use uh

00:22:18,159 --> 00:22:22,559
sort of threads at the top level um and

00:22:20,960 --> 00:22:25,840
if you imagine if you have

00:22:22,559 --> 00:22:26,320
openmp loops being launched in two of

00:22:25,840 --> 00:22:29,120
those

00:22:26,320 --> 00:22:30,400
threads separately um you can obviously

00:22:29,120 --> 00:22:31,840
get you can just resource or

00:22:30,400 --> 00:22:33,200
you can exhaust all your resources

00:22:31,840 --> 00:22:34,240
because of it because they've got a

00:22:33,200 --> 00:22:36,400
happy run

00:22:34,240 --> 00:22:37,520
um interestingly you'd be interesting to

00:22:36,400 --> 00:22:39,760
see how the

00:22:37,520 --> 00:22:41,039
house how the developments in in sickle

00:22:39,760 --> 00:22:42,559
and sickle cues

00:22:41,039 --> 00:22:44,640
actually may end up being a solution to

00:22:42,559 --> 00:22:47,760
this um because then

00:22:44,640 --> 00:22:49,520
you're relying on uh on sickle to take a

00:22:47,760 --> 00:22:50,799
little bit of that management overhead

00:22:49,520 --> 00:22:52,480
away so

00:22:50,799 --> 00:22:55,840
um so that that would be an interesting

00:22:52,480 --> 00:22:58,880
one to keep to keep an eye on

00:22:55,840 --> 00:23:01,120
um a few more challenges um

00:22:58,880 --> 00:23:02,559
and for very for very tight loops of

00:23:01,120 --> 00:23:04,159
variable trip counts yeah

00:23:02,559 --> 00:23:05,760
loading balance i think some of the

00:23:04,159 --> 00:23:09,039
questions that came up in the last talk

00:23:05,760 --> 00:23:09,039
was sort of alluding to this

00:23:09,120 --> 00:23:13,039
yeah the overhead of creating these

00:23:11,039 --> 00:23:13,679
openness so how do we how do we deal

00:23:13,039 --> 00:23:16,320
with that

00:23:13,679 --> 00:23:18,000
um and one time scheduling using

00:23:16,320 --> 00:23:20,159
environment variables as i said

00:23:18,000 --> 00:23:21,360
we've got let's say we've got 200 odd

00:23:20,159 --> 00:23:24,559
kernels um

00:23:21,360 --> 00:23:26,000
appearing in uh in this application

00:23:24,559 --> 00:23:27,840
actually trying to control all of that

00:23:26,000 --> 00:23:31,520
using environment variables

00:23:27,840 --> 00:23:33,360
is um it's just not possible um it gets

00:23:31,520 --> 00:23:34,720
it's not it's it's not something which

00:23:33,360 --> 00:23:37,200
which works so

00:23:34,720 --> 00:23:38,240
so having other ways of being able to

00:23:37,200 --> 00:23:40,480
schedule

00:23:38,240 --> 00:23:42,000
um these these openmp loops or

00:23:40,480 --> 00:23:42,799
controlling the scheduling of these

00:23:42,000 --> 00:23:45,200
these openmp

00:23:42,799 --> 00:23:46,640
loops is would be of uh would be of

00:23:45,200 --> 00:23:50,480
interest to us

00:23:46,640 --> 00:23:52,880
um i think for the last talk um

00:23:50,480 --> 00:23:54,080
effect the answers that that the the the

00:23:52,880 --> 00:23:56,720
third point here of having

00:23:54,080 --> 00:23:58,080
more loop scheduling schemes um and i

00:23:56,720 --> 00:23:59,200
think that's that's something

00:23:58,080 --> 00:24:01,440
i think we'll probably start we'll have

00:23:59,200 --> 00:24:04,640
a look at the uh the lb for openmp

00:24:01,440 --> 00:24:06,240
um library to see how this um how this

00:24:04,640 --> 00:24:08,799
works so

00:24:06,240 --> 00:24:09,520
our loops tend to be um yeah they can be

00:24:08,799 --> 00:24:12,159
imbalanced

00:24:09,520 --> 00:24:12,720
um and also you have you have certain

00:24:12,159 --> 00:24:13,919
loops and

00:24:12,720 --> 00:24:15,760
actually in the metal store you're

00:24:13,919 --> 00:24:18,400
talking about multigrid

00:24:15,760 --> 00:24:19,760
where you have certain kernels which are

00:24:18,400 --> 00:24:22,480
used

00:24:19,760 --> 00:24:24,000
over different meshes so you have a you

00:24:22,480 --> 00:24:25,600
have the same kernel being used at one

00:24:24,000 --> 00:24:27,039
point on a very fine mesh

00:24:25,600 --> 00:24:28,720
and then suddenly it's being used on a

00:24:27,039 --> 00:24:30,000
very coarse mesh

00:24:28,720 --> 00:24:31,520
and making sure that you've got the

00:24:30,000 --> 00:24:33,440
right the right scheduling algorithm

00:24:31,520 --> 00:24:36,480
that allows you to span

00:24:33,440 --> 00:24:39,600
those different scales of loop size

00:24:36,480 --> 00:24:41,360
um but also and and low in imbalance as

00:24:39,600 --> 00:24:43,120
well so the balancing might change as

00:24:41,360 --> 00:24:45,360
well between those two

00:24:43,120 --> 00:24:46,880
so being able to do that dynamically in

00:24:45,360 --> 00:24:48,080
some way or being have the logic to

00:24:46,880 --> 00:24:49,600
express that

00:24:48,080 --> 00:24:51,919
uh is is something with something of

00:24:49,600 --> 00:24:53,679
interest um

00:24:51,919 --> 00:24:55,600
and this then and you also would be good

00:24:53,679 --> 00:24:57,120
to sort of have pregnant-based support

00:24:55,600 --> 00:24:59,440
to change the algorithms as i was sort

00:24:57,120 --> 00:25:00,080
of mentioning there is just somehow add

00:24:59,440 --> 00:25:02,960
this this

00:25:00,080 --> 00:25:04,640
ability to uh to add more logic in in

00:25:02,960 --> 00:25:05,520
some way i don't know quite sure how you

00:25:04,640 --> 00:25:07,200
do that

00:25:05,520 --> 00:25:08,400
um whether you can do that you do that

00:25:07,200 --> 00:25:09,679
externally you'll be able to use the

00:25:08,400 --> 00:25:12,159
pragma to point to

00:25:09,679 --> 00:25:14,000
something some other logic which uh

00:25:12,159 --> 00:25:16,320
which allow you to help you to decide

00:25:14,000 --> 00:25:18,000
i suppose it's in a similar way to the

00:25:16,320 --> 00:25:19,840
way that we tend to use on

00:25:18,000 --> 00:25:21,600
on cuda where we're using sort of

00:25:19,840 --> 00:25:23,039
runtime introspection to sort of look at

00:25:21,600 --> 00:25:24,640
what the kernel is doing

00:25:23,039 --> 00:25:26,159
we've got some we've got we know what

00:25:24,640 --> 00:25:28,400
the sizes of the uh

00:25:26,159 --> 00:25:30,240
the the loop is going to be and then

00:25:28,400 --> 00:25:33,120
make a decision at one time

00:25:30,240 --> 00:25:35,760
um so maybe the ability to do that uh to

00:25:33,120 --> 00:25:39,120
deal with those kind of complexes um

00:25:35,760 --> 00:25:41,039
obviously that openmp has an api to uh

00:25:39,120 --> 00:25:43,039
to to do that but whether you can sort

00:25:41,039 --> 00:25:44,960
of express that using uh

00:25:43,039 --> 00:25:47,200
using the pragmas would be would be of

00:25:44,960 --> 00:25:48,640
interest

00:25:47,200 --> 00:25:50,080
yeah other than that those are all my

00:25:48,640 --> 00:25:51,919
challenges for the audience any

00:25:50,080 --> 00:25:53,360
questions

00:25:51,919 --> 00:25:55,600
thanks a lot for your talk jamil that

00:25:53,360 --> 00:25:56,080
was um really interesting in particular

00:25:55,600 --> 00:25:57,840
the

00:25:56,080 --> 00:25:59,600
list of challenges that you that you're

00:25:57,840 --> 00:26:01,840
facing and and how maybe some of those

00:25:59,600 --> 00:26:03,200
might be solved with uh openmp like like

00:26:01,840 --> 00:26:04,960
the meta directives or

00:26:03,200 --> 00:26:07,039
or the variants that that you were

00:26:04,960 --> 00:26:09,120
alluding to at the end

00:26:07,039 --> 00:26:10,640
um i think we'll uh in the interest of

00:26:09,120 --> 00:26:13,039
time i ask you to take some

00:26:10,640 --> 00:26:13,840
questions in in the q a uh yeah if

00:26:13,039 --> 00:26:15,440
that's all right

00:26:13,840 --> 00:26:20,159
that's fine that's brilliant thanks a

00:26:15,440 --> 00:26:20,159

YouTube URL: https://www.youtube.com/watch?v=ZGz2D2ITPsw


