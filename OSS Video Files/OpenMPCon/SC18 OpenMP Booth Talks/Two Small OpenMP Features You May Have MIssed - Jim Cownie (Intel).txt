Title: Two Small OpenMP Features You May Have MIssed - Jim Cownie (Intel)
Publication date: 2018-11-17
Playlist: SC18 OpenMP Booth Talks
Description: 
	SC18 OpenMP Booth Talk - November 13, 2018, Dallas TX
Slides at https://www.openmp.org/wp-content/uploads/SC18-BoothTalks-Cownie.pdf
Captions: 
	00:00:00,199 --> 00:00:06,420
okay so I'm going to talk a little bit

00:00:02,850 --> 00:00:11,460
about rather small features in OpenMP

00:00:06,420 --> 00:00:14,849
but useful ones OpenMP as we as we know

00:00:11,460 --> 00:00:16,590
has been around for a long time and we

00:00:14,849 --> 00:00:19,710
develop it we maintain compatibility

00:00:16,590 --> 00:00:23,820
with previous versions and along the way

00:00:19,710 --> 00:00:25,680
we introduce small changes but don't you

00:00:23,820 --> 00:00:27,810
don't have to use these things that had

00:00:25,680 --> 00:00:30,539
their new advances in in the way that

00:00:27,810 --> 00:00:32,759
you can use them but they could

00:00:30,539 --> 00:00:36,739
potentially be useful in your codes and

00:00:32,759 --> 00:00:39,360
so these are these probably account for

00:00:36,739 --> 00:00:42,899
50 lines in the standard rather than

00:00:39,360 --> 00:00:44,760
being the five line things that number

00:00:42,899 --> 00:00:47,070
of our people get up get obsessed with

00:00:44,760 --> 00:00:49,350
and therefore it's very easy to miss

00:00:47,070 --> 00:00:51,510
them and to not notice that they're

00:00:49,350 --> 00:00:53,370
there and so I'm just going to point out

00:00:51,510 --> 00:00:55,800
that we do have these new features that

00:00:53,370 --> 00:00:57,329
they are potentially useful and so there

00:00:55,800 --> 00:01:00,600
are two things that we're going to talk

00:00:57,329 --> 00:01:02,789
about one is non-monotonic dynamic

00:01:00,600 --> 00:01:04,890
schedules and one of the reasons you

00:01:02,789 --> 00:01:07,140
need to know about that is that they

00:01:04,890 --> 00:01:10,229
will become well they have become the

00:01:07,140 --> 00:01:13,830
default for dynamic schedules in openmp

00:01:10,229 --> 00:01:16,710
five and then the second one is hints

00:01:13,830 --> 00:01:20,090
that you can apply to synchronization to

00:01:16,710 --> 00:01:23,100
synchronization constructs such as locks

00:01:20,090 --> 00:01:25,770
critical sections and in openmp five

00:01:23,100 --> 00:01:29,400
Atomics and those allow you to access

00:01:25,770 --> 00:01:31,409
hardware features on some vendors

00:01:29,400 --> 00:01:34,049
hardware in particular on Intel Hardware

00:01:31,409 --> 00:01:37,259
on IBM Hardware in ways that are very

00:01:34,049 --> 00:01:39,150
easy for you to put in that don't make

00:01:37,259 --> 00:01:40,530
your code non portable and that

00:01:39,150 --> 00:01:42,000
potentially can have significant

00:01:40,530 --> 00:01:44,610
performance improvements as we'll show

00:01:42,000 --> 00:01:47,640
so we'll start with the lock hints

00:01:44,610 --> 00:01:51,149
because those are to some extent more

00:01:47,640 --> 00:01:57,570
important so this is the non monotonic

00:01:51,149 --> 00:02:00,780
dynamic schedule which long what what is

00:01:57,570 --> 00:02:03,810
he actually about we've had dynamic

00:02:00,780 --> 00:02:07,110
schedules forever they were an MP 1.0

00:02:03,810 --> 00:02:11,489
I'm sure and people use them and we

00:02:07,110 --> 00:02:13,530
understand we understand them but we've

00:02:11,489 --> 00:02:19,710
changed the

00:02:13,530 --> 00:02:23,520
we claret okay we clarified the

00:02:19,710 --> 00:02:28,200
semantics of de monotonic schedules in

00:02:23,520 --> 00:02:31,800
OpenMP v or lin OpenMP 4.5 and in openmp

00:02:28,200 --> 00:02:33,600
5 and so let's look at this piece of

00:02:31,800 --> 00:02:36,900
code here that we have on the right we

00:02:33,600 --> 00:02:39,240
have a parallel region we set an a

00:02:36,900 --> 00:02:40,830
thread local variable so this is inside

00:02:39,240 --> 00:02:42,959
the parallel region each thread hazard

00:02:40,830 --> 00:02:46,560
has a cup of this variable and it's

00:02:42,959 --> 00:02:50,070
called mine then we run this schedule

00:02:46,560 --> 00:02:53,820
dynamic loop handing out the iterations

00:02:50,070 --> 00:02:55,890
from 1 to N and each thread looks to see

00:02:53,820 --> 00:02:59,100
whether the iteration it's got got

00:02:55,890 --> 00:03:01,290
allocated is below the previous highest

00:02:59,100 --> 00:03:04,530
iteration that it had and it's a it

00:03:01,290 --> 00:03:07,470
aborts our eyes it updates its value of

00:03:04,530 --> 00:03:10,739
the maximum iteration it's seen the

00:03:07,470 --> 00:03:14,370
question is can that code abort does the

00:03:10,739 --> 00:03:19,640
standard allow that code to abort that

00:03:14,370 --> 00:03:22,459
was not clear in open M before because

00:03:19,640 --> 00:03:26,100
the way that the standard was written

00:03:22,459 --> 00:03:27,900
sort of suggested that what's happening

00:03:26,100 --> 00:03:29,970
in the implementation of the schedule

00:03:27,900 --> 00:03:31,440
dynamic is that there's one global

00:03:29,970 --> 00:03:34,110
counter which is being atomically

00:03:31,440 --> 00:03:37,190
incremented and therefore there's no

00:03:34,110 --> 00:03:39,660
possible way that any thread can see an

00:03:37,190 --> 00:03:41,940
iteration that's lower than the one that

00:03:39,660 --> 00:03:44,070
it previously saw because that global

00:03:41,940 --> 00:03:47,329
counter is incremented and it's pulling

00:03:44,070 --> 00:03:52,230
values from the global counter however

00:03:47,329 --> 00:03:53,910
that was only well after a lot of

00:03:52,230 --> 00:03:56,810
political discussion in the standards

00:03:53,910 --> 00:03:59,760
group we decided that that was not a

00:03:56,810 --> 00:04:01,620
specification it was merely an example

00:03:59,760 --> 00:04:03,510
of how the standard should could be

00:04:01,620 --> 00:04:06,150
implemented and therefore the other

00:04:03,510 --> 00:04:08,670
implementations that allow that to abort

00:04:06,150 --> 00:04:11,250
are possible that all sounds very

00:04:08,670 --> 00:04:13,049
abstract why would why would you care

00:04:11,250 --> 00:04:15,660
why does it make any difference what

00:04:13,049 --> 00:04:17,729
what's what are you going on about well

00:04:15,660 --> 00:04:21,810
the reason it matters is that if you

00:04:17,729 --> 00:04:24,030
have a dynamic schedule implemented with

00:04:21,810 --> 00:04:26,620
that centralized atomic increment and

00:04:24,030 --> 00:04:29,260
you have small amounts of info

00:04:26,620 --> 00:04:31,389
of work in the loop you have a lot of

00:04:29,260 --> 00:04:34,090
contention on the cash line that holds

00:04:31,389 --> 00:04:37,030
that atomic variable and you have many

00:04:34,090 --> 00:04:39,130
Atomics attempting to operate on it at

00:04:37,030 --> 00:04:42,210
the same time and that can perform very

00:04:39,130 --> 00:04:45,580
badly on even on Intel machines

00:04:42,210 --> 00:04:46,990
therefore what you want to be able to do

00:04:45,580 --> 00:04:50,440
is to use old an alternative

00:04:46,990 --> 00:04:53,919
implementation in which you slice up the

00:04:50,440 --> 00:04:55,960
work between the threads initially each

00:04:53,919 --> 00:04:57,580
thread can then operate on its own chunk

00:04:55,960 --> 00:05:01,120
of work just as it would have done if it

00:04:57,580 --> 00:05:02,560
were a static schedule and then when it

00:05:01,120 --> 00:05:05,500
runs out of work it can go to another

00:05:02,560 --> 00:05:07,330
thread and steal other other iterations

00:05:05,500 --> 00:05:11,139
and that way you remove all of the cost

00:05:07,330 --> 00:05:15,040
of those Atomics but in that schedule

00:05:11,139 --> 00:05:17,139
viously you can get this code would

00:05:15,040 --> 00:05:18,910
abort because you could consider what

00:05:17,139 --> 00:05:20,650
happens if the threat that had the last

00:05:18,910 --> 00:05:23,229
set of iterations that includes the

00:05:20,650 --> 00:05:25,690
highest one executes all its iterations

00:05:23,229 --> 00:05:27,610
it's executed the highest iteration in

00:05:25,690 --> 00:05:29,169
the whole set and then it goes and

00:05:27,610 --> 00:05:31,360
steals and iteration from someone else

00:05:29,169 --> 00:05:33,669
that's clearly going to be less than the

00:05:31,360 --> 00:05:38,590
highest one in the whole set which would

00:05:33,669 --> 00:05:41,440
mean that code aborts in OpenMP 4.5 we

00:05:38,590 --> 00:05:43,690
added qualifiers to the dynamic schedule

00:05:41,440 --> 00:05:45,849
so you can say monotonic and non

00:05:43,690 --> 00:05:48,070
monotonic but we weren't actually clear

00:05:45,849 --> 00:05:48,580
about what it meant if you didn't say

00:05:48,070 --> 00:05:52,120
that

00:05:48,580 --> 00:05:54,250
in openmp 5 the standard says that the

00:05:52,120 --> 00:05:58,210
unqualified dynamic schedule is a non

00:05:54,250 --> 00:06:01,389
monotonic and therefore if your code is

00:05:58,210 --> 00:06:04,960
written in a way that relies on this

00:06:01,389 --> 00:06:08,740
property it potentially will break when

00:06:04,960 --> 00:06:14,770
OpenMP 5 is implemented so you need to

00:06:08,740 --> 00:06:17,410
know about that here's some measurements

00:06:14,770 --> 00:06:20,020
that I made showing that the overhead

00:06:17,410 --> 00:06:22,510
there so what we have we have a number

00:06:20,020 --> 00:06:24,190
of cores along the bottom here up to 28

00:06:22,510 --> 00:06:29,910
I think on the machine that I was using

00:06:24,190 --> 00:06:32,530
and the cost of doing the scheduling

00:06:29,910 --> 00:06:35,590
depending on the amount of work that we

00:06:32,530 --> 00:06:39,150
do in each iteration so if we only have

00:06:35,590 --> 00:06:41,490
500 our DTSC ticks of

00:06:39,150 --> 00:06:44,220
which is pretty small amount of time at

00:06:41,490 --> 00:06:49,560
a two point whatever it is 2.7 gigahertz

00:06:44,220 --> 00:06:51,810
clock then you get a cost of doing this

00:06:49,560 --> 00:06:53,430
scheduling like this which is really

00:06:51,810 --> 00:06:55,530
quite depressing because here we're

00:06:53,430 --> 00:06:57,990
seeing over 2000 iterations of

00:06:55,530 --> 00:07:00,210
scheduling cost to execute 500

00:06:57,990 --> 00:07:02,070
iterations of work which doesn't seem

00:07:00,210 --> 00:07:05,310
like a good deal

00:07:02,070 --> 00:07:07,229
obviously as we add more work that the

00:07:05,310 --> 00:07:09,660
contention on the on the lock creases

00:07:07,229 --> 00:07:11,340
and we come down to these two this line

00:07:09,660 --> 00:07:14,130
here which is basically just the cost of

00:07:11,340 --> 00:07:16,889
the atomic in the first place if you do

00:07:14,130 --> 00:07:18,419
static scheduling that's the fastest of

00:07:16,889 --> 00:07:19,800
all then it has no contention and it

00:07:18,419 --> 00:07:22,650
gives you these red lines at the bottom

00:07:19,800 --> 00:07:25,050
but if we do a non monotonic dynamic

00:07:22,650 --> 00:07:27,030
schedule using the implementation that I

00:07:25,050 --> 00:07:29,910
was talking about you get a performance

00:07:27,030 --> 00:07:31,500
like these green lines I would rather

00:07:29,910 --> 00:07:34,169
have a performance like the green line

00:07:31,500 --> 00:07:38,360
then like the blue line and that's what

00:07:34,169 --> 00:07:38,360
the standard now allows us to implement

00:07:39,860 --> 00:07:45,930
so here are the advantages it's

00:07:43,200 --> 00:07:48,620
significantly the cost is the scheduling

00:07:45,930 --> 00:07:51,539
scope cost is significantly lower

00:07:48,620 --> 00:07:55,320
because the iteration distribution

00:07:51,539 --> 00:07:58,229
starts off being static you get more

00:07:55,320 --> 00:08:00,120
more like you're more likely if there's

00:07:58,229 --> 00:08:02,940
only a little bit of load imbalance to

00:08:00,120 --> 00:08:06,870
get good cash reuse then you would have

00:08:02,940 --> 00:08:09,750
done with the atomic based the similar

00:08:06,870 --> 00:08:14,340
Tomic increment based dynamic schedule

00:08:09,750 --> 00:08:16,050
and it handles the load imbalance better

00:08:14,340 --> 00:08:18,479
than a static schedule which doesn't

00:08:16,050 --> 00:08:21,750
handle load imbalance at all so it's not

00:08:18,479 --> 00:08:23,580
hard to do better than that however it's

00:08:21,750 --> 00:08:25,560
still slightly more expensive than a

00:08:23,580 --> 00:08:27,900
static schedule so if static schedule is

00:08:25,560 --> 00:08:30,210
appropriate continue to use it and by

00:08:27,900 --> 00:08:33,060
default the static schedule is is the

00:08:30,210 --> 00:08:37,070
schedule that most implementations give

00:08:33,060 --> 00:08:37,070
you if you don't specify anything at all

00:08:37,530 --> 00:08:43,860
so we looked at this real code impasse

00:08:40,620 --> 00:08:44,970
ocean with some collaborators whose

00:08:43,860 --> 00:08:49,170
names are on the beginning of the slide

00:08:44,970 --> 00:08:52,650
and it's an ocean system simulation just

00:08:49,170 --> 00:08:54,780
around 230,000 lines of Fortran so it's

00:08:52,650 --> 00:08:57,510
it's not a huge code but it's not a

00:08:54,780 --> 00:08:58,920
trivial code either and it's a science

00:08:57,510 --> 00:09:03,270
code it's a real code it's not a

00:08:58,920 --> 00:09:04,680
benchmark using this workload we ran one

00:09:03,270 --> 00:09:07,710
simulated day

00:09:04,680 --> 00:09:09,180
it's an MPI and OpenMP code and it

00:09:07,710 --> 00:09:11,040
actually they already were using

00:09:09,180 --> 00:09:13,380
schedule of runtime for all of their

00:09:11,040 --> 00:09:14,820
loops so doing this experiment was very

00:09:13,380 --> 00:09:19,350
easy we just had to change the schedule

00:09:14,820 --> 00:09:23,340
in the environment and here's the

00:09:19,350 --> 00:09:25,680
performance that we saw so this is the

00:09:23,340 --> 00:09:28,680
performance versus a static schedule so

00:09:25,680 --> 00:09:31,530
static schedule is a hundred percent it

00:09:28,680 --> 00:09:34,980
performs at this line here and here's

00:09:31,530 --> 00:09:37,080
the fake the performance if you use the

00:09:34,980 --> 00:09:38,700
two different dynamic schedules so with

00:09:37,080 --> 00:09:41,430
a monotonic dynamic schedule the

00:09:38,700 --> 00:09:44,220
performance is bad and gets worse and

00:09:41,430 --> 00:09:46,140
worse and worse with the non monotonic

00:09:44,220 --> 00:09:48,330
schedule we actually do slightly better

00:09:46,140 --> 00:09:50,970
than static in a number of cases and

00:09:48,330 --> 00:09:54,270
we're within spitting distance as static

00:09:50,970 --> 00:09:56,250
in the other cases so there is clearly

00:09:54,270 --> 00:09:59,640
some amount of load imbalance in this

00:09:56,250 --> 00:10:03,360
code and we're managing to to exploit

00:09:59,640 --> 00:10:06,480
that to go slightly faster now this

00:10:03,360 --> 00:10:09,270
didn't unfortunately change the change

00:10:06,480 --> 00:10:11,930
the fact that for most of the empaths

00:10:09,270 --> 00:10:14,850
cases or even for that for this case

00:10:11,930 --> 00:10:17,640
using many MPI processes and few a few

00:10:14,850 --> 00:10:20,339
OpenMP threads and one opening B thread

00:10:17,640 --> 00:10:24,360
in each was gave even higher performance

00:10:20,339 --> 00:10:27,089
so it did change it from being having

00:10:24,360 --> 00:10:29,100
one thread per MPI process to having two

00:10:27,089 --> 00:10:31,740
threads for MPI process so we've got

00:10:29,100 --> 00:10:37,560
some openmp parallelism to do better

00:10:31,740 --> 00:10:39,510
than the MPI parallelism so what this is

00:10:37,560 --> 00:10:41,430
saying is that you can apply this in a

00:10:39,510 --> 00:10:44,810
real code and you can see a difference

00:10:41,430 --> 00:10:44,810
and you can see an advantage

00:10:45,740 --> 00:10:51,750
so conclusion Don this thing you need to

00:10:49,770 --> 00:10:54,650
understand it because it's gonna hit you

00:10:51,750 --> 00:10:57,210
whether you wanted it or not the

00:10:54,650 --> 00:11:00,110
compilers are going to change the run

00:10:57,210 --> 00:11:03,270
times are going to change probably and

00:11:00,110 --> 00:11:06,360
that that may affect your code it's

00:11:03,270 --> 00:11:07,980
possible that implementations may not

00:11:06,360 --> 00:11:11,360
bother to enable it even though they're

00:11:07,980 --> 00:11:16,350
allowed to because if you think about it

00:11:11,360 --> 00:11:18,930
the the monotonic schedule could arise

00:11:16,350 --> 00:11:22,590
even though you said non monotonic so

00:11:18,930 --> 00:11:24,300
you can't tell by inspecting the set of

00:11:22,590 --> 00:11:26,250
iterations how they're handed out which

00:11:24,300 --> 00:11:28,530
schedule was actually used if it looks

00:11:26,250 --> 00:11:30,750
like a monotonic one and so the

00:11:28,530 --> 00:11:33,270
implementer can argue well I'm doing non

00:11:30,750 --> 00:11:35,450
monotonic and you just happen every time

00:11:33,270 --> 00:11:37,740
you look you just happen to see a

00:11:35,450 --> 00:11:39,840
monotonic one well I there's nothing I

00:11:37,740 --> 00:11:44,160
can do about that that's just bad luck

00:11:39,840 --> 00:11:46,950
and the reason that you might want to do

00:11:44,160 --> 00:11:49,730
that as a vendor is because that is safe

00:11:46,950 --> 00:11:51,990
it's not gonna break anyone's code

00:11:49,730 --> 00:11:54,450
exactly what we're going to do at Intel

00:11:51,990 --> 00:11:56,370
is still to be determined but I think

00:11:54,450 --> 00:11:58,830
that we're moving in the direction of we

00:11:56,370 --> 00:12:00,510
will implement the default as non

00:11:58,830 --> 00:12:03,240
monotonic but we'll provide a

00:12:00,510 --> 00:12:06,000
non-standard chiken environment variable

00:12:03,240 --> 00:12:08,930
that you can set that says just make

00:12:06,000 --> 00:12:11,910
everything monotonic again please

00:12:08,930 --> 00:12:14,640
it can provide useful performance and

00:12:11,910 --> 00:12:17,100
the code changes that you need to make

00:12:14,640 --> 00:12:18,780
to enforce that by setting the monitor

00:12:17,100 --> 00:12:22,920
by changing the schedule that are

00:12:18,780 --> 00:12:27,270
relatively small in your code and it's

00:12:22,920 --> 00:12:28,740
worth playing with so use it okay anyone

00:12:27,270 --> 00:12:31,760
want to ask questions on that

00:12:28,740 --> 00:12:35,280
or shall we move on to the other feature

00:12:31,760 --> 00:12:37,250
everyone's looking too stunned okay

00:12:35,280 --> 00:12:40,790
we'll move on to the next one

00:12:37,250 --> 00:12:40,790
synchronization hints

00:12:40,800 --> 00:12:47,110
so here we're talking about a way to for

00:12:45,280 --> 00:12:49,330
you to give more information to the

00:12:47,110 --> 00:12:52,090
OpenMP implementation in in particular

00:12:49,330 --> 00:12:53,590
the open MP runtime about the properties

00:12:52,090 --> 00:12:55,990
of the critical sections that you have

00:12:53,590 --> 00:12:57,730
in your code you have a critical section

00:12:55,990 --> 00:13:00,160
in your code either implemented with

00:12:57,730 --> 00:13:03,280
OpenMP lockup with an explicit open MP

00:13:00,160 --> 00:13:06,790
lock where the pragma are critical or

00:13:03,280 --> 00:13:08,530
even atomic operations and the way that

00:13:06,790 --> 00:13:11,590
that happened and the reason that's

00:13:08,530 --> 00:13:13,810
useful is that different implementations

00:13:11,590 --> 00:13:16,360
of that in the runtime have different

00:13:13,810 --> 00:13:18,010
performance properties and therefore you

00:13:16,360 --> 00:13:19,720
can gain performance by using an

00:13:18,010 --> 00:13:23,560
appropriate implementation in the

00:13:19,720 --> 00:13:26,290
runtime that's achieved with these hints

00:13:23,560 --> 00:13:28,060
that in OpenMP 4.5 had the name on lock

00:13:26,290 --> 00:13:30,730
in something because they were only

00:13:28,060 --> 00:13:34,120
applicable to locks main critical

00:13:30,730 --> 00:13:36,220
sections in open MP 5 they changed their

00:13:34,120 --> 00:13:38,200
names to UM syncing something or other

00:13:36,220 --> 00:13:40,510
but the lock link names are still there

00:13:38,200 --> 00:13:41,890
in case you're already using it them in

00:13:40,510 --> 00:13:48,730
which case why are you listening to this

00:13:41,890 --> 00:13:51,100
presentation so why why do I want to do

00:13:48,730 --> 00:13:52,240
this well different lock implementations

00:13:51,100 --> 00:13:53,920
have very different performance

00:13:52,240 --> 00:13:55,600
properties so the time to wake up on

00:13:53,920 --> 00:13:57,340
lock release to transfer that the

00:13:55,600 --> 00:13:59,590
information about the fact that the lock

00:13:57,340 --> 00:14:01,120
is free to the next threat that needs is

00:13:59,590 --> 00:14:03,790
trying to claim the lock can be very

00:14:01,120 --> 00:14:05,460
different between locks spin locks or

00:14:03,790 --> 00:14:07,660
queuing locks

00:14:05,460 --> 00:14:09,040
similarly the cost of contention

00:14:07,660 --> 00:14:10,960
interference from threads that are

00:14:09,040 --> 00:14:14,170
waiting on threads that are still

00:14:10,960 --> 00:14:18,970
executing can be different fairness is

00:14:14,170 --> 00:14:21,130
different and also the cost of entering

00:14:18,970 --> 00:14:25,480
the lock in the first place so a Malik

00:14:21,130 --> 00:14:28,660
Romi Scott type queuing lock is fair has

00:14:25,480 --> 00:14:31,360
a low interference but it's quite

00:14:28,660 --> 00:14:33,730
expensive any code path through it takes

00:14:31,360 --> 00:14:35,980
a longer than us then a very simple spin

00:14:33,730 --> 00:14:38,020
lock so if you have a highly uncontained

00:14:35,980 --> 00:14:39,400
adat that's very rarely there are other

00:14:38,020 --> 00:14:42,190
two threads trying to enter the critical

00:14:39,400 --> 00:14:43,990
section a spin lock will outperform the

00:14:42,190 --> 00:14:46,570
other lock even though when you're in

00:14:43,990 --> 00:14:48,430
the high contention the other the melech

00:14:46,570 --> 00:14:48,940
Romi type queuing lock will perform

00:14:48,430 --> 00:14:51,370
better

00:14:48,940 --> 00:14:52,819
therefore it's that the runtime can't

00:14:51,370 --> 00:14:54,109
easily tell

00:14:52,819 --> 00:14:57,859
the properties are of your critical

00:14:54,109 --> 00:15:00,169
section so it's worth you telling it and

00:14:57,859 --> 00:15:01,759
you know you can go and investigate and

00:15:00,169 --> 00:15:05,179
find that there are eight different lock

00:15:01,759 --> 00:15:08,509
implementations in the LLVM run time not

00:15:05,179 --> 00:15:10,699
that all of them would be useful here it

00:15:08,509 --> 00:15:11,989
also enables passing these hints also

00:15:10,699 --> 00:15:14,089
enables the use of advanced hardware

00:15:11,989 --> 00:15:16,299
features so in particular Intel

00:15:14,089 --> 00:15:18,970
processors have this feature called

00:15:16,299 --> 00:15:21,799
transactional synchronization extensions

00:15:18,970 --> 00:15:23,119
abbreviated to TSX IBM have something

00:15:21,799 --> 00:15:28,459
similar in power eight and other

00:15:23,119 --> 00:15:30,799
processes and that allows the the

00:15:28,459 --> 00:15:33,019
hardware to speculate inside a critical

00:15:30,799 --> 00:15:35,629
region and therefore to execute the

00:15:33,019 --> 00:15:37,579
critical region in more places than one

00:15:35,629 --> 00:15:40,279
even though it's inside a critical

00:15:37,579 --> 00:15:42,559
region and only abort that if there's

00:15:40,279 --> 00:15:44,539
actually a conflict that would cause you

00:15:42,559 --> 00:15:48,229
to be able to notice that the the

00:15:44,539 --> 00:15:50,869
isolation was being broken so how do you

00:15:48,229 --> 00:15:52,910
use them well you change the place where

00:15:50,869 --> 00:15:54,679
you had a call to unpin it lock to init

00:15:52,910 --> 00:15:57,559
lock with hint and you add the hint and

00:15:54,679 --> 00:15:59,299
that's it you don't have to go and find

00:15:57,559 --> 00:16:02,329
every place in the code where you're

00:15:59,299 --> 00:16:03,859
doing set lock and unset lock just the

00:16:02,329 --> 00:16:06,589
initialization of the lock is all that

00:16:03,859 --> 00:16:08,209
you have to change and similarly you

00:16:06,589 --> 00:16:10,519
apply a hint to a critical statement

00:16:08,209 --> 00:16:12,739
there are a few constraints there it

00:16:10,519 --> 00:16:15,199
must have a name so that you know if

00:16:12,739 --> 00:16:17,600
there are many different instance

00:16:15,199 --> 00:16:20,179
lexical instances of that same critical

00:16:17,600 --> 00:16:22,309
section which you're trying to exclude

00:16:20,179 --> 00:16:24,229
you need to name them name it so that

00:16:22,309 --> 00:16:28,220
they they know they all know to use the

00:16:24,229 --> 00:16:30,139
same lock implementation and they must

00:16:28,220 --> 00:16:31,999
all have the same lock implementation so

00:16:30,139 --> 00:16:33,589
when you name name it and put a hint on

00:16:31,999 --> 00:16:36,189
one of them you'd need to name all the

00:16:33,589 --> 00:16:39,709
others the same and put a hint on them

00:16:36,189 --> 00:16:42,289
the hints have no semantic implications

00:16:39,709 --> 00:16:45,769
at all and implementation is entirely

00:16:42,289 --> 00:16:48,649
free to ignore them completely so they

00:16:45,769 --> 00:16:50,239
are hints you're saying hey runtime I'm

00:16:48,649 --> 00:16:52,669
giving you more information please use

00:16:50,239 --> 00:16:55,879
it it can go I don't care I'm not gonna

00:16:52,669 --> 00:16:59,659
bother which makes them very easy to

00:16:55,879 --> 00:17:01,850
implement in and not contentious in the

00:16:59,659 --> 00:17:04,419
standards body because people can't say

00:17:01,850 --> 00:17:06,669
you just cause me a lot of work

00:17:04,419 --> 00:17:09,129
so mutual exclusion is still guaranteed

00:17:06,669 --> 00:17:13,509
and an implementation can completely

00:17:09,129 --> 00:17:15,699
ignore them but we hope it won't so your

00:17:13,509 --> 00:17:18,069
expressing properties of the lock in the

00:17:15,699 --> 00:17:20,230
critical section contended you're

00:17:18,069 --> 00:17:22,209
expecting many threads to be waiting so

00:17:20,230 --> 00:17:24,069
it's kind of suggesting to the run time

00:17:22,209 --> 00:17:24,639
that maybe a fair queuing lock is a good

00:17:24,069 --> 00:17:27,879
thing to use

00:17:24,639 --> 00:17:29,350
hunc intended we don't expect many

00:17:27,879 --> 00:17:29,970
threads to be arriving here at the same

00:17:29,350 --> 00:17:32,799
time

00:17:29,970 --> 00:17:35,440
so therefore user an unfair spin lock

00:17:32,799 --> 00:17:37,269
and we can also hint to use speculation

00:17:35,440 --> 00:17:39,340
which is would be TSX on the Intel

00:17:37,269 --> 00:17:42,789
machines and and IBM's Hardware

00:17:39,340 --> 00:17:45,489
implementation or to say don't don't

00:17:42,789 --> 00:17:47,679
ever use speculation actually it's

00:17:45,489 --> 00:17:49,899
unlikely that you would use speculation

00:17:47,679 --> 00:17:55,929
without being hinted to do that but you

00:17:49,899 --> 00:17:57,249
can say both things so TSX can give you

00:17:55,929 --> 00:17:59,379
the performance of a fine grain

00:17:57,249 --> 00:18:00,850
reader/writer lock but without you

00:17:59,379 --> 00:18:02,769
having to go in and implement everything

00:18:00,850 --> 00:18:04,090
and change your code to implement a fine

00:18:02,769 --> 00:18:06,940
grain read or write a lock

00:18:04,090 --> 00:18:09,609
so the hardware monitors the hardware

00:18:06,940 --> 00:18:11,859
enters a speculative execution state it

00:18:09,609 --> 00:18:14,350
doesn't let any rights get globe become

00:18:11,859 --> 00:18:15,789
globally visible and it monitors the

00:18:14,350 --> 00:18:17,499
read and write sets inside the

00:18:15,789 --> 00:18:19,179
transaction to determine whether there

00:18:17,499 --> 00:18:20,859
are any conflicts which it can do

00:18:19,179 --> 00:18:24,549
because of the cache coherency protocol

00:18:20,859 --> 00:18:26,019
and then when and so the writes inside

00:18:24,549 --> 00:18:29,169
the transaction aren't seen until the

00:18:26,019 --> 00:18:30,429
transaction commits and so if it aborts

00:18:29,169 --> 00:18:32,830
those rights never happened

00:18:30,429 --> 00:18:35,320
fun no one can see them they can't of

00:18:32,830 --> 00:18:36,789
course to conflict it has the property

00:18:35,320 --> 00:18:38,049
that the in the Intel implementation

00:18:36,789 --> 00:18:41,799
that there are no forward progress

00:18:38,049 --> 00:18:45,789
guarantees so you could potentially have

00:18:41,799 --> 00:18:47,230
to to create critical sections

00:18:45,789 --> 00:18:48,999
speculative sections and they each may

00:18:47,230 --> 00:18:50,409
need to invalidate each other all the

00:18:48,999 --> 00:18:50,799
time and neither of them makes forward

00:18:50,409 --> 00:18:53,350
progress

00:18:50,799 --> 00:18:55,619
that's not a very good property but what

00:18:53,350 --> 00:18:58,179
it does mean all that it means is that

00:18:55,619 --> 00:18:59,619
though those of us who are implementing

00:18:58,179 --> 00:19:01,960
this in the runtime library you have to

00:18:59,619 --> 00:19:03,489
ensure that we have a backup strategy so

00:19:01,960 --> 00:19:05,169
that when we see too much contention we

00:19:03,489 --> 00:19:07,059
go to some other lock which will

00:19:05,169 --> 00:19:08,619
guarantee forward progress and that's

00:19:07,059 --> 00:19:11,660
all in the runtime so you don't have to

00:19:08,619 --> 00:19:16,160
worry about it that's my problem

00:19:11,660 --> 00:19:17,960
so you could potentially detect that

00:19:16,160 --> 00:19:19,640
this is going on because you could read

00:19:17,960 --> 00:19:22,610
timestamps inside all the critical

00:19:19,640 --> 00:19:24,050
sections and see hey I'm seeing I'm in

00:19:22,610 --> 00:19:26,960
the you know every threads in the same

00:19:24,050 --> 00:19:28,580
critical section at the same time but

00:19:26,960 --> 00:19:33,050
that's a pretty weird thing to be doing

00:19:28,580 --> 00:19:35,660
and so I'm not too worried about that so

00:19:33,050 --> 00:19:38,060
the example that we're using here is to

00:19:35,660 --> 00:19:41,480
say okay let's I've got some program

00:19:38,060 --> 00:19:44,630
it's using a stud unordered map which is

00:19:41,480 --> 00:19:46,880
just a hash table to map from an

00:19:44,630 --> 00:19:48,950
unsigned 32-bit integer to another

00:19:46,880 --> 00:19:51,890
unsigned 32-bit integer and I want to

00:19:48,950 --> 00:19:54,410
use that inside a and openmp code well

00:19:51,890 --> 00:19:56,720
what I'm gonna do is I'm gonna build

00:19:54,410 --> 00:19:58,970
myself a locked hash class like this and

00:19:56,720 --> 00:20:01,100
I put it on lock in there and when I

00:19:58,970 --> 00:20:03,500
initialize the lock I initialize the

00:20:01,100 --> 00:20:04,100
lock and then when I insert ID I take

00:20:03,500 --> 00:20:05,810
the lock

00:20:04,100 --> 00:20:07,880
I do the insertion and I on set the lock

00:20:05,810 --> 00:20:10,400
and similarly when I do a lock up I look

00:20:07,880 --> 00:20:14,630
up I take the lock I find find the

00:20:10,400 --> 00:20:17,840
result and I understand a lot this is it

00:20:14,630 --> 00:20:19,970
this is a very simple way of wrapping up

00:20:17,840 --> 00:20:21,470
a function that isn't thread safe and

00:20:19,970 --> 00:20:24,890
making it thread safe so I can use it in

00:20:21,470 --> 00:20:29,750
OpenMP and that's what the code without

00:20:24,890 --> 00:20:31,690
the red orange or this is would do what

00:20:29,750 --> 00:20:33,500
I've also done here though is use the

00:20:31,690 --> 00:20:35,990
lock with hint

00:20:33,500 --> 00:20:38,000
so I pass in a hint when I run the

00:20:35,990 --> 00:20:40,700
constructor of this and I passed that

00:20:38,000 --> 00:20:42,200
into the into the into the init lock and

00:20:40,700 --> 00:20:43,730
those are those right changes in red are

00:20:42,200 --> 00:20:45,710
the only changes I had to make to do

00:20:43,730 --> 00:20:46,940
that there are no changes you see notice

00:20:45,710 --> 00:20:52,700
no changes here where I'm sitting and

00:20:46,940 --> 00:20:56,090
unsetting the lock and when I run that

00:20:52,700 --> 00:20:58,880
code so here I'm running this code on on

00:20:56,090 --> 00:21:02,180
a similar machine on a skylake machine

00:20:58,880 --> 00:21:04,400
with up to twenty eight cores and I'm

00:21:02,180 --> 00:21:05,990
doing all the threads are doing lookups

00:21:04,400 --> 00:21:08,300
or insertions on random elements of a

00:21:05,990 --> 00:21:09,980
ten thousand entry or a entry hash and

00:21:08,300 --> 00:21:12,140
I'm measuring three different

00:21:09,980 --> 00:21:13,070
proportions of that all insertions 50%

00:21:12,140 --> 00:21:16,700
of each all lookups

00:21:13,070 --> 00:21:20,210
I'm running one thread per core and if I

00:21:16,700 --> 00:21:22,730
use the sort of default lock hint have

00:21:20,210 --> 00:21:23,710
uncontained Eid I get this performance

00:21:22,730 --> 00:21:25,750
in red

00:21:23,710 --> 00:21:27,310
which is kind of what you'd expect all

00:21:25,750 --> 00:21:28,990
of the threads are trying to be in the

00:21:27,310 --> 00:21:31,270
critical section at the same time they

00:21:28,990 --> 00:21:33,010
can't be there for adding threads

00:21:31,270 --> 00:21:35,140
doesn't get me any performance

00:21:33,010 --> 00:21:38,650
improvement how can it all of the time

00:21:35,140 --> 00:21:42,400
is serialized however when I pass in the

00:21:38,650 --> 00:21:43,660
lock in speculative I get this very nice

00:21:42,400 --> 00:21:45,340
performance that performance with

00:21:43,660 --> 00:21:47,590
increasing almost linearly as I add

00:21:45,340 --> 00:21:49,240
threads and that's because the implant

00:21:47,590 --> 00:21:50,830
without looking at it

00:21:49,240 --> 00:21:53,290
inside the implementation of the hash

00:21:50,830 --> 00:21:56,590
table you can speculate that what

00:21:53,290 --> 00:21:58,720
happens is it hashes the value it goes

00:21:56,590 --> 00:22:00,720
and looks at in that bucket maybe it

00:21:58,720 --> 00:22:03,220
changed from that bucket and therefore

00:22:00,720 --> 00:22:04,780
multiple threads actually are not

00:22:03,220 --> 00:22:06,490
accessing the same memory at the same

00:22:04,780 --> 00:22:07,990
time even though they're protecting the

00:22:06,490 --> 00:22:10,990
integrity of the whole data structure

00:22:07,990 --> 00:22:13,030
and therefore using the speculative

00:22:10,990 --> 00:22:15,190
execution allows all the threads to be

00:22:13,030 --> 00:22:16,540
executing in that code inside the

00:22:15,190 --> 00:22:18,400
critical section touching different

00:22:16,540 --> 00:22:20,020
buckets in the hash table without

00:22:18,400 --> 00:22:23,680
interfering with each other and we get

00:22:20,020 --> 00:22:30,160
this nice performance improvement from

00:22:23,680 --> 00:22:31,960
that two line change so that was really

00:22:30,160 --> 00:22:34,390
nice this is really good I can use this

00:22:31,960 --> 00:22:37,180
stuff for everything can't I so just to

00:22:34,390 --> 00:22:39,820
say that doesn't work I tried another

00:22:37,180 --> 00:22:41,560
experiment where I'm trying to replace a

00:22:39,820 --> 00:22:43,780
set of Atomics so suppose I'm doing a

00:22:41,560 --> 00:22:45,790
set of contiguous Atomics on and on and

00:22:43,780 --> 00:22:49,590
on an entry in an array and I'm adding

00:22:45,790 --> 00:22:52,000
1.02 to all these entries in the array

00:22:49,590 --> 00:22:55,630
shouldn't you know can I can I instead

00:22:52,000 --> 00:22:58,450
of doing it with atomic take a critical

00:22:55,630 --> 00:23:00,910
you know take a lock and use a

00:22:58,450 --> 00:23:04,660
speculative lot it seems like that might

00:23:00,910 --> 00:23:07,750
might work too unfortunately well it

00:23:04,660 --> 00:23:10,360
works in a few in one case more or less

00:23:07,750 --> 00:23:13,230
but most of the time actually the

00:23:10,360 --> 00:23:15,820
Atomics are still better so this isn't a

00:23:13,230 --> 00:23:20,470
replacement for everything but it is

00:23:15,820 --> 00:23:23,440
potentially a useful thing to look at so

00:23:20,470 --> 00:23:26,380
they don't fix everything they can be

00:23:23,440 --> 00:23:28,180
ignored so that you're not going to hurt

00:23:26,380 --> 00:23:29,920
your codes portability by putting them

00:23:28,180 --> 00:23:33,040
in and where they but they can give you

00:23:29,920 --> 00:23:36,480
a significant gains as we saw so

00:23:33,040 --> 00:23:39,470
consider using them it's very easy

00:23:36,480 --> 00:23:43,110
you potentially can have have big guns

00:23:39,470 --> 00:23:46,470
and so the overall conclusions of the of

00:23:43,110 --> 00:23:50,850
the whole talk are open the is evolving

00:23:46,470 --> 00:23:53,970
and is evolving in ways which actually

00:23:50,850 --> 00:23:56,490
quite small are useful and it's worth

00:23:53,970 --> 00:23:58,890
knowing about those things and these

00:23:56,490 --> 00:24:00,690
small changes can be quite easy to apply

00:23:58,890 --> 00:24:02,669
to your code they're not things that

00:24:00,690 --> 00:24:04,830
require you to restructure your code or

00:24:02,669 --> 00:24:06,929
go and touch every line in your code or

00:24:04,830 --> 00:24:11,669
any of these things so think of using

00:24:06,929 --> 00:24:14,400
them and I have to acknowledge my

00:24:11,669 --> 00:24:17,669
collaborators who who did the the work

00:24:14,400 --> 00:24:19,049
on impasse oh and since I'm from Intel I

00:24:17,669 --> 00:24:21,480
have to give you detailed test

00:24:19,049 --> 00:24:24,120
configuration information about the

00:24:21,480 --> 00:24:26,520
machines which were used when we did the

00:24:24,120 --> 00:24:28,290
testing exactly the properties of the

00:24:26,520 --> 00:24:30,480
compilers and so on so that you can go

00:24:28,290 --> 00:24:33,929
and replicate this you can't replicate

00:24:30,480 --> 00:24:35,700
the 10th of September 2018 but you can

00:24:33,929 --> 00:24:38,730
replicate the rest of this yourself and

00:24:35,700 --> 00:24:40,140
validate or send me mail and tell me I'm

00:24:38,730 --> 00:24:42,750
an idiot and I made some horrible

00:24:40,140 --> 00:24:45,900
mistake and I have to show you a legal

00:24:42,750 --> 00:24:48,419
disclaimer that says this guy works from

00:24:45,900 --> 00:24:50,730
Intel he used the Intel compilers the

00:24:48,419 --> 00:24:52,470
Intel compilers may not optimize as well

00:24:50,730 --> 00:24:55,740
for other people's processes as they do

00:24:52,470 --> 00:24:58,940
for Intel thank you very much

00:24:55,740 --> 00:24:58,940

YouTube URL: https://www.youtube.com/watch?v=Kw_6HcRqT24


