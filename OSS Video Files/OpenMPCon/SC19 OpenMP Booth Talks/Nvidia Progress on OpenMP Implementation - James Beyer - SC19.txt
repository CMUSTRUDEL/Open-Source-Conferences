Title: Nvidia Progress on OpenMP Implementation - James Beyer - SC19
Publication date: 2019-11-25
Playlist: SC19 OpenMP Booth Talks
Description: 
	SC19 November 19, 2019 Denver
Captions: 
	00:00:00,030 --> 00:00:06,299
all right so I'm gonna talk a bit about

00:00:03,440 --> 00:00:08,220
Nvidia and openmp we've been involved

00:00:06,299 --> 00:00:09,900
with OpenMP for a long time and one of

00:00:08,220 --> 00:00:13,469
the complaints that we've gotten is

00:00:09,900 --> 00:00:16,020
Nvidia / PGI doesn't have an open MP

00:00:13,469 --> 00:00:18,720
five-o compiler well we don't really

00:00:16,020 --> 00:00:21,390
have one yet but we talked about the

00:00:18,720 --> 00:00:22,980
precursors of it all right thanks I'll

00:00:21,390 --> 00:00:27,119
eat it if I have to just keep reminding

00:00:22,980 --> 00:00:37,290
me see if these slides will look for

00:00:27,119 --> 00:00:44,149
graphs that's interesting my slides are

00:00:37,290 --> 00:00:44,149
moving let's just do this

00:00:51,590 --> 00:00:58,190
there we go all right so I'm I'm gonna

00:00:56,180 --> 00:01:00,380
go a very very brief bit about what

00:00:58,190 --> 00:01:02,840
OpenMP is mainly because I'm gonna give

00:01:00,380 --> 00:01:05,150
comments about what it is not the

00:01:02,840 --> 00:01:08,390
specification itself then I'll talk

00:01:05,150 --> 00:01:11,030
about n vo and P which is the opening PM

00:01:08,390 --> 00:01:14,750
implementation we have that it's is CPU

00:01:11,030 --> 00:01:16,580
and GPU aware and then talk a bit about

00:01:14,750 --> 00:01:18,260
future work and depending how long it

00:01:16,580 --> 00:01:24,290
takes I may talk more down here than up

00:01:18,260 --> 00:01:26,210
here so what is OpenMP so these are the

00:01:24,290 --> 00:01:28,550
constructs that really matter to us in

00:01:26,210 --> 00:01:30,500
my opinion there's a parallel construct

00:01:28,550 --> 00:01:32,960
which starts multiple threads there's

00:01:30,500 --> 00:01:35,360
all of the loop constructs that cause

00:01:32,960 --> 00:01:38,080
you to be able to cause those threads to

00:01:35,360 --> 00:01:40,490
work together then there's the task

00:01:38,080 --> 00:01:42,950
construct which is kind of this

00:01:40,490 --> 00:01:44,960
precursor to lambdas enclosures and all

00:01:42,950 --> 00:01:47,270
this stuff as far as openmp is concerned

00:01:44,960 --> 00:01:49,130
so openmp as i passed for a while it's

00:01:47,270 --> 00:01:51,170
just a if you look think of it as a

00:01:49,130 --> 00:01:55,100
lambda that gets deferred that's all it

00:01:51,170 --> 00:01:59,030
is target which is a horrible compromise

00:01:55,100 --> 00:02:00,679
teams which starts up multiple teams of

00:01:59,030 --> 00:02:03,440
threads which are a league-high

00:02:00,679 --> 00:02:04,940
within a target constructs so it's now

00:02:03,440 --> 00:02:07,910
can be pulled out and executed outside

00:02:04,940 --> 00:02:09,890
of a target construct so that you end up

00:02:07,910 --> 00:02:13,520
with this thing that has limited

00:02:09,890 --> 00:02:15,770
communication between itself on the CPU

00:02:13,520 --> 00:02:17,480
and so many of the CPUs and Intel

00:02:15,770 --> 00:02:20,180
actually is the one who pushed to get

00:02:17,480 --> 00:02:21,440
this onto the CPU the CPUs are getting

00:02:20,180 --> 00:02:22,700
big enough that they're Numa within

00:02:21,440 --> 00:02:24,230
themselves so you don't want to

00:02:22,700 --> 00:02:25,849
communicate if you don't have to so this

00:02:24,230 --> 00:02:28,520
tells us you're not going to communicate

00:02:25,849 --> 00:02:31,400
and then the distributor's is the way

00:02:28,520 --> 00:02:33,709
that teams work together so you can

00:02:31,400 --> 00:02:35,480
actually take these put them up here and

00:02:33,709 --> 00:02:37,220
awesome.this start shrinking down and at

00:02:35,480 --> 00:02:41,360
the end of the talk I'll talk about that

00:02:37,220 --> 00:02:43,250
a little bit so this is a slide if

00:02:41,360 --> 00:02:45,260
you're here earlier this morning you're

00:02:43,250 --> 00:02:47,360
I put this slide up of what open md5

00:02:45,260 --> 00:02:49,730
looks like there's a bunch of stuff up

00:02:47,360 --> 00:02:51,290
there it's a cool slide until I put it

00:02:49,730 --> 00:02:54,680
up there the more interesting slide is

00:02:51,290 --> 00:02:57,860
this one and so this is where we're at

00:02:54,680 --> 00:02:59,659
today the blue is the interesting part

00:02:57,860 --> 00:03:01,879
because that's the stuff the CPU side of

00:02:59,659 --> 00:03:04,700
things that we have fully implemented or

00:03:01,879 --> 00:03:04,970
reasonably fully implemented the the

00:03:04,700 --> 00:03:07,820
green

00:03:04,970 --> 00:03:09,440
is the GPU offload side as your I said

00:03:07,820 --> 00:03:11,990
this morning that's not been released

00:03:09,440 --> 00:03:13,760
completely so we're talking about it you

00:03:11,990 --> 00:03:16,040
can go see them talk about it in the

00:03:13,760 --> 00:03:22,490
Nvidia booth but it's not something you

00:03:16,040 --> 00:03:25,130
can download and use right now so this

00:03:22,490 --> 00:03:27,980
new Nvidia OpenMP runtime is actually

00:03:25,130 --> 00:03:31,640
based on the LLVM runtime we picked it

00:03:27,980 --> 00:03:33,230
up and tore all the guts out of it kept

00:03:31,640 --> 00:03:36,860
the interfaces and reimplemented

00:03:33,230 --> 00:03:40,340
everything we did this that we could

00:03:36,860 --> 00:03:42,740
extend it to understand both the CPU and

00:03:40,340 --> 00:03:45,140
the GPU so it we actually can reuse a

00:03:42,740 --> 00:03:48,770
lot of the code both on the CPU and the

00:03:45,140 --> 00:03:52,370
GPU and have them understand what's

00:03:48,770 --> 00:03:55,160
going on in a reasonable manner we do

00:03:52,370 --> 00:04:00,110
have some GPU unique interfaces right

00:03:55,160 --> 00:04:02,270
now they're mainly unique because nobody

00:04:00,110 --> 00:04:05,900
else's we haven't figured out how the

00:04:02,270 --> 00:04:07,220
playing is going to do it so maybe we'll

00:04:05,900 --> 00:04:10,730
standardize later right now they're

00:04:07,220 --> 00:04:13,430
different the big thing here here I

00:04:10,730 --> 00:04:16,220
talked about it earlier we use the same

00:04:13,430 --> 00:04:18,140
present table that open ACC users so you

00:04:16,220 --> 00:04:20,060
have automatic interaction between open

00:04:18,140 --> 00:04:23,360
ACC parts of your code and open MP parts

00:04:20,060 --> 00:04:27,050
your code this runtime started out as a

00:04:23,360 --> 00:04:29,210
3-1 implementation we had no aspirations

00:04:27,050 --> 00:04:31,880
actually of going beyond 3-1 originally

00:04:29,210 --> 00:04:33,590
because that was the the code base that

00:04:31,880 --> 00:04:37,479
we we started with saying this is what

00:04:33,590 --> 00:04:40,130
we need to get running onto the GPU then

00:04:37,479 --> 00:04:42,890
PGI said we need a new runtime for our

00:04:40,130 --> 00:04:44,150
all of yum compiler and you have

00:04:42,890 --> 00:04:46,250
something that works reasonably well and

00:04:44,150 --> 00:04:49,180
understands GPUs so also we became a

00:04:46,250 --> 00:04:52,040
five-o compiler runtime and compilers

00:04:49,180 --> 00:04:54,020
big limitation we have tasks implemented

00:04:52,040 --> 00:04:55,669
but they're really three one tasks

00:04:54,020 --> 00:04:57,200
anything that's beyond three one we

00:04:55,669 --> 00:04:59,930
really haven't implemented yet it's just

00:04:57,200 --> 00:05:01,160
not there and one of the dependencies is

00:04:59,930 --> 00:05:04,300
just nothing we don't even know any

00:05:01,160 --> 00:05:04,300
implemented in our stuff yet

00:05:05,660 --> 00:05:09,170
so our goal and there's a reason there's

00:05:08,120 --> 00:05:10,790
no numbers there because I don't care

00:05:09,170 --> 00:05:13,670
about the numbers our goal was to have

00:05:10,790 --> 00:05:16,580
these lines basically be the same so the

00:05:13,670 --> 00:05:19,360
blue side is what ships with playing

00:05:16,580 --> 00:05:21,980
right now with LVM and the reddish

00:05:19,360 --> 00:05:25,100
orange whatever it looks more orange on

00:05:21,980 --> 00:05:28,580
my display here is the performance of

00:05:25,100 --> 00:05:30,740
the env o and P so as you can see it's

00:05:28,580 --> 00:05:34,250
fairly flat this is missing because of a

00:05:30,740 --> 00:05:37,190
bug in the compiler this is faster

00:05:34,250 --> 00:05:39,500
because one of our developers spent a

00:05:37,190 --> 00:05:41,240
week staring at the code and find one

00:05:39,500 --> 00:05:47,600
minor change and he could make it faster

00:05:41,240 --> 00:05:51,650
in our system oh this is the part that

00:05:47,600 --> 00:05:53,030
I've more since was the next slide so we

00:05:51,650 --> 00:05:56,120
don't have any of the sim DS stuff done

00:05:53,030 --> 00:05:57,290
the if you talk to the Cray people which

00:05:56,120 --> 00:05:59,510
I was one of the great people that they

00:05:57,290 --> 00:06:01,520
did did this decision back then they

00:05:59,510 --> 00:06:06,050
ignored the SMD it was actually just a

00:06:01,520 --> 00:06:09,170
bit we set in the the loop structure

00:06:06,050 --> 00:06:13,850
saying that try to symbolize this thing

00:06:09,170 --> 00:06:15,140
try and vectorize it PGI is taking a

00:06:13,850 --> 00:06:16,760
similar approach they're gonna try now

00:06:15,140 --> 00:06:19,730
to affect your eyes we'll come back to

00:06:16,760 --> 00:06:21,550
sim D when they have time OMP OMP that's

00:06:19,730 --> 00:06:23,930
a huge part of the specification and

00:06:21,550 --> 00:06:25,370
it's not a priority that's why it's not

00:06:23,930 --> 00:06:27,740
there it's not that if we don't think

00:06:25,370 --> 00:06:31,960
that it's useful it's just it's a lot of

00:06:27,740 --> 00:06:34,610
work and we have to pick our battles

00:06:31,960 --> 00:06:36,140
DevOps again we haven't done anything

00:06:34,610 --> 00:06:39,800
with dependencies yet so why would we

00:06:36,140 --> 00:06:41,690
have Depok scan again it's just we're

00:06:39,800 --> 00:06:44,510
not there we have to get that far

00:06:41,690 --> 00:06:46,550
allocate there's a lot of discussion

00:06:44,510 --> 00:06:50,000
around allocate on whether or not we

00:06:46,550 --> 00:06:52,910
will ever implement it it's just it's a

00:06:50,000 --> 00:06:55,010
really complex beast and until we see

00:06:52,910 --> 00:06:57,530
use cases that actually benefit from it

00:06:55,010 --> 00:06:59,210
and there's things in the wild that say

00:06:57,530 --> 00:07:01,940
we have to implement it we're gonna

00:06:59,210 --> 00:07:05,210
probably keep back from it the clear

00:07:01,940 --> 00:07:07,220
reduction is is again it's just time

00:07:05,210 --> 00:07:09,740
it's a big thing to do again it's a lot

00:07:07,220 --> 00:07:11,210
of infrastructure to add and we just

00:07:09,740 --> 00:07:12,410
have to have the time to do it and it's

00:07:11,210 --> 00:07:15,890
a lot of infrastructure both in the

00:07:12,410 --> 00:07:18,220
compiler and in the runtime declare

00:07:15,890 --> 00:07:19,610
mapper again infrastructure of time

00:07:18,220 --> 00:07:21,020
combine how are you

00:07:19,610 --> 00:07:24,800
constructs this is an interesting one

00:07:21,020 --> 00:07:26,449
because you think if you have one part

00:07:24,800 --> 00:07:28,669
of it you'd have all the parts of it but

00:07:26,449 --> 00:07:30,889
if you had come to your eyes talk

00:07:28,669 --> 00:07:33,080
they're DJs picking and choosing what

00:07:30,889 --> 00:07:35,210
they want to implement so that you get

00:07:33,080 --> 00:07:37,340
as close to open ACC performance with

00:07:35,210 --> 00:07:40,699
your openmp as you can so they want our

00:07:37,340 --> 00:07:41,719
users to be able to have a look at the

00:07:40,699 --> 00:07:43,430
code say ok we're getting good

00:07:41,719 --> 00:07:44,569
performance we won't don't want them

00:07:43,430 --> 00:07:45,680
coming back and complaining they're

00:07:44,569 --> 00:07:48,830
getting bad performance because they

00:07:45,680 --> 00:07:51,530
broke bad openmp so that's the reason

00:07:48,830 --> 00:07:53,330
right now in the future and we'll have

00:07:51,530 --> 00:07:56,629
to keep up with whatever clang does but

00:07:53,330 --> 00:07:58,729
it's just it's a fact of life so but we

00:07:56,629 --> 00:08:01,009
again we have to do something and this

00:07:58,729 --> 00:08:03,830
is where we're at and then the meta

00:08:01,009 --> 00:08:05,930
directors this is something we don't

00:08:03,830 --> 00:08:07,729
even know to implement yet we've had a

00:08:05,930 --> 00:08:09,110
next slide I'll talk about meta

00:08:07,729 --> 00:08:10,310
directors a little bit more but we're

00:08:09,110 --> 00:08:12,020
trying to figure that one out because we

00:08:10,310 --> 00:08:14,020
need it we know we need it we it's a

00:08:12,020 --> 00:08:16,699
really important feature that makes

00:08:14,020 --> 00:08:19,699
openmp useful for the CPU and the GPU

00:08:16,699 --> 00:08:21,529
and if we don't have it for both then a

00:08:19,699 --> 00:08:24,020
lot of the what if you know the PGI

00:08:21,529 --> 00:08:26,990
compiler it's been known for its ability

00:08:24,020 --> 00:08:30,319
to generate code that works on multiple

00:08:26,990 --> 00:08:33,199
different CPUs and different GPU type

00:08:30,319 --> 00:08:34,729
things right now we're only nvidia gpus

00:08:33,199 --> 00:08:36,380
because AMD went away and all these

00:08:34,729 --> 00:08:39,800
other things went away as far as PGI was

00:08:36,380 --> 00:08:41,120
concerned but we still our users need to

00:08:39,800 --> 00:08:42,680
be able to say ok I want this to run out

00:08:41,120 --> 00:08:44,600
for me on the CPU or I want to run out

00:08:42,680 --> 00:08:48,940
from the other GPU and not have

00:08:44,600 --> 00:08:48,940
overheads in place from one or the other

00:08:48,970 --> 00:08:55,459
all right so this is the part that I

00:08:53,540 --> 00:08:57,079
wanted to talk about the most so right

00:08:55,459 --> 00:08:58,730
now we're looking at 5:1 so we're gonna

00:08:57,079 --> 00:09:00,140
be a five-o compiler five ones in the

00:08:58,730 --> 00:09:02,390
future we're still trying to figure out

00:09:00,140 --> 00:09:07,040
what 5:1 matters but what we need to

00:09:02,390 --> 00:09:08,690
implement and Jeff and I have to figure

00:09:07,040 --> 00:09:13,490
out between us we can actually try and

00:09:08,690 --> 00:09:14,990
convince PGI what it is as well but one

00:09:13,490 --> 00:09:16,850
of the things we've actively used this

00:09:14,990 --> 00:09:21,709
new runtime to do some experiments we've

00:09:16,850 --> 00:09:23,240
actually done things that other members

00:09:21,709 --> 00:09:24,829
of the language committee have proposed

00:09:23,240 --> 00:09:26,149
and we've played around with them to see

00:09:24,829 --> 00:09:28,880
how they work but what were the

00:09:26,149 --> 00:09:30,380
overheads and what could we do so how

00:09:28,880 --> 00:09:32,990
could we actually exploit things on the

00:09:30,380 --> 00:09:35,240
GPU how can we do things on the CPU

00:09:32,990 --> 00:09:37,370
and we've actually got some numbers back

00:09:35,240 --> 00:09:38,840
that we found we're much better than

00:09:37,370 --> 00:09:41,510
what people were saying they're much

00:09:38,840 --> 00:09:43,630
more much overly pessimistic on the

00:09:41,510 --> 00:09:46,280
expectations so we're happy with that

00:09:43,630 --> 00:09:48,680
we have a task loop implementation our

00:09:46,280 --> 00:09:50,330
task implementation is quite possibly

00:09:48,680 --> 00:09:52,640
the most brain-dead implementation you

00:09:50,330 --> 00:09:54,470
can ever put in a runtime but we don't

00:09:52,640 --> 00:09:56,660
have a compiler to tie to it and we

00:09:54,470 --> 00:09:58,760
don't have any any benchmarks to tie to

00:09:56,660 --> 00:10:00,110
that compiler so we have no idea what we

00:09:58,760 --> 00:10:04,010
need to do there do we even care

00:10:00,110 --> 00:10:05,630
so until tell the compiler team gets

00:10:04,010 --> 00:10:08,390
benchmark and the benchmark actually

00:10:05,630 --> 00:10:09,800
needs performance we're gonna have a bad

00:10:08,390 --> 00:10:12,020
implementation but we do have an

00:10:09,800 --> 00:10:15,560
implementation which is took very little

00:10:12,020 --> 00:10:18,350
time to do I mentioned earlier the meta

00:10:15,560 --> 00:10:23,030
directors the meta directors veteran

00:10:18,350 --> 00:10:24,800
five-o are flatly broken and you can't

00:10:23,030 --> 00:10:26,870
actually do with them what we need to be

00:10:24,800 --> 00:10:28,190
able to do at compile time you're

00:10:26,870 --> 00:10:30,410
supposed to be able to choose am i

00:10:28,190 --> 00:10:31,670
running where and optimize your code are

00:10:30,410 --> 00:10:32,150
you running on the CPU i running on the

00:10:31,670 --> 00:10:34,100
GPU

00:10:32,150 --> 00:10:37,270
turns out the way we actually wrote it

00:10:34,100 --> 00:10:40,070
in the specification is either

00:10:37,270 --> 00:10:41,830
misinterpreted by one part of the the

00:10:40,070 --> 00:10:43,910
language committee or the other

00:10:41,830 --> 00:10:46,010
whichever part is wrong

00:10:43,910 --> 00:10:48,020
doesn't matter what matters is users

00:10:46,010 --> 00:10:49,640
can't write code that's portable and

00:10:48,020 --> 00:10:52,520
that's the bullet we knew so we need to

00:10:49,640 --> 00:10:56,180
fix that in five one so video will be

00:10:52,520 --> 00:10:59,060
working very hard to get that fixed PG I

00:10:56,180 --> 00:11:01,730
discovered the problem Nvidia is driving

00:10:59,060 --> 00:11:03,980
forward as hard as we can and everybody

00:11:01,730 --> 00:11:06,440
else has jumped on it and will have a

00:11:03,980 --> 00:11:09,020
solution it's just a matter of this is

00:11:06,440 --> 00:11:10,670
really really important to us

00:11:09,020 --> 00:11:12,380
so the to feature things that are

00:11:10,670 --> 00:11:15,170
interesting to me that are future

00:11:12,380 --> 00:11:17,150
looking for six o-type time thing do we

00:11:15,170 --> 00:11:18,770
really need target teams parallel and

00:11:17,150 --> 00:11:22,610
tasks we have all of these different

00:11:18,770 --> 00:11:24,050
ways of starting parallelism and if you

00:11:22,610 --> 00:11:26,600
look at target target actually

00:11:24,050 --> 00:11:28,730
explicitly says it's a task it's just a

00:11:26,600 --> 00:11:31,970
special kind of task that runs work or

00:11:28,730 --> 00:11:35,720
someplace else so the task could have

00:11:31,970 --> 00:11:39,380
been what we use teams is really

00:11:35,720 --> 00:11:41,720
parallel but we didn't want to put a

00:11:39,380 --> 00:11:43,190
clause on parallel because if we put a

00:11:41,720 --> 00:11:44,720
clause on parallel parallel goes from

00:11:43,190 --> 00:11:45,680
being synchrony being able to

00:11:44,720 --> 00:11:46,490
synchronize to not being able to

00:11:45,680 --> 00:11:48,590
synchronize

00:11:46,490 --> 00:11:51,800
but do we really need either of these

00:11:48,590 --> 00:11:53,600
actually because if we take these and

00:11:51,800 --> 00:11:55,520
think about them as just a unit of work

00:11:53,600 --> 00:11:57,170
that needs to be done and say okay a

00:11:55,520 --> 00:11:59,420
task and it is a unit of work that could

00:11:57,170 --> 00:12:01,850
have multiple threads executed we can

00:11:59,420 --> 00:12:04,130
fold all three of these into tasks we

00:12:01,850 --> 00:12:07,010
have a single execution engine the task

00:12:04,130 --> 00:12:11,750
that gets scheduled someplace in run is

00:12:07,010 --> 00:12:13,940
run by some number of threads and this

00:12:11,750 --> 00:12:16,370
is something that we've we've talked

00:12:13,940 --> 00:12:17,660
about for about a year and we keep

00:12:16,370 --> 00:12:19,340
pushing it off because it's not

00:12:17,660 --> 00:12:21,980
something we can do without a major

00:12:19,340 --> 00:12:23,900
change in the specification so we'll

00:12:21,980 --> 00:12:24,440
start pushing on this for 6:02 see what

00:12:23,900 --> 00:12:28,100
happens

00:12:24,440 --> 00:12:29,930
and then the other really interesting

00:12:28,100 --> 00:12:32,540
thing is if you look at all of the the

00:12:29,930 --> 00:12:34,100
tasking tutorials they tell you to do a

00:12:32,540 --> 00:12:36,020
parallel master and then a for loop

00:12:34,100 --> 00:12:38,350
around a task and that's how you get

00:12:36,020 --> 00:12:41,660
tasks spawned and neck and execute them

00:12:38,350 --> 00:12:43,130
why do we need the parallel master the

00:12:41,660 --> 00:12:45,380
only reason we need the parallel master

00:12:43,130 --> 00:12:47,510
is because tasks need to have threads

00:12:45,380 --> 00:12:50,030
available to them to be scheduled on and

00:12:47,510 --> 00:12:52,660
parallel is the only way right now in

00:12:50,030 --> 00:12:57,500
OpenMP to get those threads available

00:12:52,660 --> 00:12:59,740
and we've shown to ourselves that this

00:12:57,500 --> 00:13:02,630
is a bad idea and there there are

00:12:59,740 --> 00:13:06,020
relatively low overhead ways to fix that

00:13:02,630 --> 00:13:07,430
problem so that's another thing that the

00:13:06,020 --> 00:13:12,520
language committee has been looking at

00:13:07,430 --> 00:13:12,520

YouTube URL: https://www.youtube.com/watch?v=nS0Zn_t3ofc


