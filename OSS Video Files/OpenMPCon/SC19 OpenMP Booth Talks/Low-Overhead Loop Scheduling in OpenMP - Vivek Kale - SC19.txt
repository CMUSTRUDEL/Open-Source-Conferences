Title: Low-Overhead Loop Scheduling in OpenMP - Vivek Kale - SC19
Publication date: 2019-11-25
Playlist: SC19 OpenMP Booth Talks
Description: 
	November 20, 2019, SC19 Denver
Captions: 
	00:00:00,920 --> 00:00:04,140
[Music]

00:00:04,609 --> 00:00:11,460
hi everyone my name is Vivek Kalle I'm

00:00:08,340 --> 00:00:16,080
going to speak to you today about a

00:00:11,460 --> 00:00:20,250
technique to use in openmp called low

00:00:16,080 --> 00:00:21,960
overhead loop scheduling for improving

00:00:20,250 --> 00:00:28,560
the performance of scientific

00:00:21,960 --> 00:00:34,680
applications that use MPI plus OpenMP so

00:00:28,560 --> 00:00:39,989
this is a part of the solve project and

00:00:34,680 --> 00:00:47,460
solve is an e CP sub project that it

00:00:39,989 --> 00:00:51,090
runs from 2017 to 2023 the idea of solve

00:00:47,460 --> 00:00:54,870
is to have an exascale ready OpenMP that

00:00:51,090 --> 00:00:58,050
will be able to be deployed for

00:00:54,870 --> 00:01:01,649
applications that are running on

00:00:58,050 --> 00:01:05,850
exascale supercomputers in this talk i

00:01:01,649 --> 00:01:08,640
am going to focus on strategies within

00:01:05,850 --> 00:01:13,979
this solve framework that have to do

00:01:08,640 --> 00:01:17,720
with these two sub layers and that is

00:01:13,979 --> 00:01:22,259
the runtime system here and the

00:01:17,720 --> 00:01:25,950
compilers of solve and at the top of

00:01:22,259 --> 00:01:29,040
that this transparent layer is the open

00:01:25,950 --> 00:01:33,060
MP specification that's where all the

00:01:29,040 --> 00:01:35,880
language committee does the deciding of

00:01:33,060 --> 00:01:38,369
new features and so this is kind of the

00:01:35,880 --> 00:01:40,500
prototyping of new research features

00:01:38,369 --> 00:01:42,600
that we are doing within the solve

00:01:40,500 --> 00:01:47,369
project this one particular one being

00:01:42,600 --> 00:01:54,110
louver loop scheduling so let's take a

00:01:47,369 --> 00:01:54,110
step back and think about the of these

00:01:54,560 --> 00:02:03,200
HPC applications and what do they look

00:01:57,600 --> 00:02:06,840
like well so you first have this

00:02:03,200 --> 00:02:10,970
typically an MPI init and then followed

00:02:06,840 --> 00:02:13,970
by this time step loop which is

00:02:10,970 --> 00:02:17,150
outer iteration and then within that

00:02:13,970 --> 00:02:19,610
alteration there's a foreign exchange or

00:02:17,150 --> 00:02:25,250
some sign of either blocking or non

00:02:19,610 --> 00:02:28,010
blocking MPI communication and that

00:02:25,250 --> 00:02:30,530
could be a loose and that's a loosely or

00:02:28,010 --> 00:02:36,760
both bulk synchronous MPI collective

00:02:30,530 --> 00:02:40,190
communication within that region is this

00:02:36,760 --> 00:02:44,090
computation portion or computation

00:02:40,190 --> 00:02:47,480
region and you can have multiple regions

00:02:44,090 --> 00:02:50,870
like this this is the this is just I've

00:02:47,480 --> 00:02:52,340
just made this for conciseness and also

00:02:50,870 --> 00:02:54,140
the other thing is you can have many

00:02:52,340 --> 00:02:57,580
interleavings of computation

00:02:54,140 --> 00:03:02,090
communication within the time step so a

00:02:57,580 --> 00:03:08,050
key problem of this sort of application

00:03:02,090 --> 00:03:12,710
is the following and it has to do with

00:03:08,050 --> 00:03:16,670
what happens within a note in each time

00:03:12,710 --> 00:03:19,760
step there is some there can be some

00:03:16,670 --> 00:03:21,709
load imbalance within node and that

00:03:19,760 --> 00:03:25,640
wouldn't know load balance is large

00:03:21,709 --> 00:03:29,420
enough to impact the overall application

00:03:25,640 --> 00:03:35,950
performance and so what I'm illustrating

00:03:29,420 --> 00:03:39,920
here is time as from right to left and

00:03:35,950 --> 00:03:44,150
core number from up to down and as

00:03:39,920 --> 00:03:48,500
you're going from right to left you see

00:03:44,150 --> 00:03:51,500
this these bars are time spent in

00:03:48,500 --> 00:03:58,040
computation you see this load imbalance

00:03:51,500 --> 00:04:01,430
within across course and I'll just make

00:03:58,040 --> 00:04:02,920
a point that these are nodes here when

00:04:01,430 --> 00:04:07,750
you

00:04:02,920 --> 00:04:12,400
group these cores into pieces and so how

00:04:07,750 --> 00:04:14,950
do you fix this well the simple way is

00:04:12,400 --> 00:04:18,970
to just redistribute work in each time

00:04:14,950 --> 00:04:20,950
step through some Oracle and that and

00:04:18,970 --> 00:04:24,930
that makes that allows for this

00:04:20,950 --> 00:04:28,620
distribution note that this here this

00:04:24,930 --> 00:04:34,800
this node here does not actually isn't

00:04:28,620 --> 00:04:38,169
upload balanced across these notes so

00:04:34,800 --> 00:04:39,700
this is just a point I want to make that

00:04:38,169 --> 00:04:41,890
we are not trying to solve this

00:04:39,700 --> 00:04:42,640
particular problem it's just the window

00:04:41,890 --> 00:04:46,630
that lowballs

00:04:42,640 --> 00:04:49,120
and there's actually also another type

00:04:46,630 --> 00:04:54,310
of load imbalance and that's this

00:04:49,120 --> 00:04:57,910
problem of noise amplification and what

00:04:54,310 --> 00:05:00,940
happens is that an every time step again

00:04:57,910 --> 00:05:03,760
this is the same sort of plot there's

00:05:00,940 --> 00:05:06,730
some noise event shown in the red and

00:05:03,760 --> 00:05:08,470
that delays some iteration that causes a

00:05:06,730 --> 00:05:10,150
load imbalance within a node and that

00:05:08,470 --> 00:05:15,880
actually if you have a bulk synchronous

00:05:10,150 --> 00:05:19,030
execution that causes a global delay so

00:05:15,880 --> 00:05:21,550
in each iteration on some node you're

00:05:19,030 --> 00:05:25,570
going to have if once you have this

00:05:21,550 --> 00:05:26,020
global delay you will suffer a big

00:05:25,570 --> 00:05:29,200
slowdown

00:05:26,020 --> 00:05:30,850
and so here also you can improve

00:05:29,200 --> 00:05:37,020
performance just by doing some

00:05:30,850 --> 00:05:37,020
redistribution within node and so

00:05:39,130 --> 00:05:47,690
so right here how do we do near-perfect

00:05:45,620 --> 00:05:50,260
worth distribution with a note that's

00:05:47,690 --> 00:05:54,050
the key question we want to answer and

00:05:50,260 --> 00:05:56,780
there's I'll just start with this simple

00:05:54,050 --> 00:05:59,090
diagram here that's just illustrating

00:05:56,780 --> 00:06:01,669
the computation in one time step and

00:05:59,090 --> 00:06:04,040
we're in this talk we're gonna focus on

00:06:01,669 --> 00:06:07,550
just the OpenMP computation region in

00:06:04,040 --> 00:06:11,000
the MPI plus OpenMP program and the

00:06:07,550 --> 00:06:14,389
first tactic is to just say just try the

00:06:11,000 --> 00:06:19,760
OpenMP dynamic schedule chunk size one

00:06:14,389 --> 00:06:22,250
so doing that will so I'll just show you

00:06:19,760 --> 00:06:27,010
what that looks like so that's openmp

00:06:22,250 --> 00:06:30,560
dynamic right there and that that is

00:06:27,010 --> 00:06:34,100
going to create a lot of overhead as

00:06:30,560 --> 00:06:37,580
soon as you have several large trip

00:06:34,100 --> 00:06:41,270
count and you have you're running on

00:06:37,580 --> 00:06:47,600
many a number of course so an idea to

00:06:41,270 --> 00:06:51,169
fix this is to have this hybrid load

00:06:47,600 --> 00:06:55,010
balancing system with a node that does

00:06:51,169 --> 00:06:59,389
the first some fraction of iterations

00:06:55,010 --> 00:07:01,940
statically and so this this is

00:06:59,389 --> 00:07:04,729
determined by some this fraction FD

00:07:01,940 --> 00:07:07,010
denoted here in this formula and then

00:07:04,729 --> 00:07:09,620
the remaining dynamically and what

00:07:07,010 --> 00:07:12,919
happens is that threads will contain

00:07:09,620 --> 00:07:13,760
will work on the static work and then as

00:07:12,919 --> 00:07:17,300
soon as they're done

00:07:13,760 --> 00:07:19,849
they don't wait and then continue on and

00:07:17,300 --> 00:07:25,550
do the dynamic work the idea is to tune

00:07:19,849 --> 00:07:31,970
that FD parameter for each loop and for

00:07:25,550 --> 00:07:36,289
each in fact for each MPI process which

00:07:31,970 --> 00:07:38,389
I'll show you in a second that such that

00:07:36,289 --> 00:07:42,149
the

00:07:38,389 --> 00:07:45,029
performance is the best that is that the

00:07:42,149 --> 00:07:48,080
load imbalance improves the reduces the

00:07:45,029 --> 00:07:51,779
threat idle time and the data locality

00:07:48,080 --> 00:07:57,089
the cost of data locality is minimized

00:07:51,779 --> 00:07:58,769
and so for the base the basic strategy

00:07:57,089 --> 00:08:03,899
we'll just assume we'll just think of

00:07:58,769 --> 00:08:05,669
one node right now and this is actually

00:08:03,899 --> 00:08:09,029
I'll just skip over this this is an

00:08:05,669 --> 00:08:11,879
enhanced loop scheduling strategy that

00:08:09,029 --> 00:08:15,479
allows for improving spatial locality

00:08:11,879 --> 00:08:17,429
were just redistribution redistributing

00:08:15,479 --> 00:08:24,139
the iterations in the loop iteration

00:08:17,429 --> 00:08:27,119
space to allow for fewer cache misses so

00:08:24,139 --> 00:08:29,189
with this basic static dynamic

00:08:27,119 --> 00:08:33,060
scheduling strategy duty time I'm not

00:08:29,189 --> 00:08:36,269
going to go through everything we found

00:08:33,060 --> 00:08:40,979
that for a communication of avoiding Lu

00:08:36,269 --> 00:08:50,399
code that that was deemed to be already

00:08:40,979 --> 00:08:52,769
faster in the as fast as the or much

00:08:50,399 --> 00:08:58,939
faster than the baseline Lu code we

00:08:52,769 --> 00:09:01,920
actually improved it by by 34% our

00:08:58,939 --> 00:09:04,850
improve our what we did was we had a

00:09:01,920 --> 00:09:08,310
mixed static dynamic scheduling strategy

00:09:04,850 --> 00:09:14,130
using 10% dynamic scheduling so the F D

00:09:08,310 --> 00:09:17,040
in my formula is 0.1 and we actually

00:09:14,130 --> 00:09:19,470
also changed this data layouts which is

00:09:17,040 --> 00:09:23,149
actually they'll just say that that that

00:09:19,470 --> 00:09:26,339
has to do the spatial locality and the

00:09:23,149 --> 00:09:29,040
what we found is significant

00:09:26,339 --> 00:09:33,540
improvements over the static CA Lu shown

00:09:29,040 --> 00:09:36,630
in blue furthermore we also beat the

00:09:33,540 --> 00:09:39,180
Intel MKL library using that use the

00:09:36,630 --> 00:09:42,449
similar numerical algorithm and the

00:09:39,180 --> 00:09:46,889
plasma runtime system

00:09:42,449 --> 00:09:49,300
implement their implementation which

00:09:46,889 --> 00:09:53,230
which had pretty much the same algorithm

00:09:49,300 --> 00:09:56,649
on on this on the left here you'll see

00:09:53,230 --> 00:10:01,529
that this is for these are histogram

00:09:56,649 --> 00:10:04,089
distributions of just running this CLU

00:10:01,529 --> 00:10:09,100
two-level block layout which was our

00:10:04,089 --> 00:10:11,829
fastest one we ran this many times we we

00:10:09,100 --> 00:10:14,709
see that the performance variation is

00:10:11,829 --> 00:10:17,490
very low when we use mixed static

00:10:14,709 --> 00:10:22,540
dynamic scheduling and that's good for

00:10:17,490 --> 00:10:29,259
scaling as especially as we go to a very

00:10:22,540 --> 00:10:36,100
very large number of nodes so I also did

00:10:29,259 --> 00:10:40,480
a study where we we have separate static

00:10:36,100 --> 00:10:43,029
fractions per MPI process so we actually

00:10:40,480 --> 00:10:45,940
created a runtime library to identify

00:10:43,029 --> 00:10:48,579
which what the best static fraction or

00:10:45,940 --> 00:10:50,709
dynamic fraction was and this is just

00:10:48,579 --> 00:10:55,269
kind of a soft the software architecture

00:10:50,709 --> 00:10:57,850
of that you can you can go into my

00:10:55,269 --> 00:11:00,910
papers and look at how we did this for

00:10:57,850 --> 00:11:09,810
more information these are some results

00:11:00,910 --> 00:11:12,160
with the with the adaptive MPI

00:11:09,810 --> 00:11:14,680
differentiated static fractions and you

00:11:12,160 --> 00:11:17,769
can see as we scale up we get a

00:11:14,680 --> 00:11:20,380
performance improvement over the dynamic

00:11:17,769 --> 00:11:25,569
scheduling and guided scheduling for an

00:11:20,380 --> 00:11:28,689
N body computation the we also this is

00:11:25,569 --> 00:11:32,889
actually some more recent work related

00:11:28,689 --> 00:11:36,040
to this the ideas we explored we

00:11:32,889 --> 00:11:38,500
actually found that through through a

00:11:36,040 --> 00:11:42,189
related technique except in task

00:11:38,500 --> 00:11:44,740
schedule the task loop direct using text

00:11:42,189 --> 00:11:46,810
loops we found that doing what we are

00:11:44,740 --> 00:11:50,949
doing through this locality aware

00:11:46,810 --> 00:11:53,880
scheduling we actually improve we reduce

00:11:50,949 --> 00:11:58,579
energy consumption on

00:11:53,880 --> 00:12:01,199
uh due to the less data movement and so

00:11:58,579 --> 00:12:06,870
I'll now I'll just take a step back

00:12:01,199 --> 00:12:10,829
again solve solve is a work in progress

00:12:06,870 --> 00:12:13,889
in terms of a software that should be

00:12:10,829 --> 00:12:16,589
able to be used by application

00:12:13,889 --> 00:12:19,800
programmers to know to get their hands

00:12:16,589 --> 00:12:22,259
on the latest research and development

00:12:19,800 --> 00:12:25,230
that's been going on this this all

00:12:22,259 --> 00:12:28,440
project so I've made a SPAC package for

00:12:25,230 --> 00:12:32,750
it you can get that you you are also

00:12:28,440 --> 00:12:35,730
able to obtain it through github and you

00:12:32,750 --> 00:12:38,089
can actually get some of my low over the

00:12:35,730 --> 00:12:41,399
loop scheduling strategies from there

00:12:38,089 --> 00:12:46,860
and there should be more improvements to

00:12:41,399 --> 00:12:50,040
it coming soon in the next year I'll one

00:12:46,860 --> 00:12:52,470
particular part that I've done for the

00:12:50,040 --> 00:12:55,560
open in the open MP spec is proposed

00:12:52,470 --> 00:12:58,189
this idea of a user-defined schedule so

00:12:55,560 --> 00:13:00,560
there's user-defined reductions recently

00:12:58,189 --> 00:13:03,509
user-defined mappers for GPUs

00:13:00,560 --> 00:13:07,139
user-defined schedules kind of follow in

00:13:03,509 --> 00:13:11,040
the same spirit then they they are

00:13:07,139 --> 00:13:13,920
trying to be this allowing users to

00:13:11,040 --> 00:13:16,050
define how they want the loop scheduling

00:13:13,920 --> 00:13:18,509
strategy to beep by intercepting the

00:13:16,050 --> 00:13:22,620
runtime and being able to say here's how

00:13:18,509 --> 00:13:25,740
you DQed on queue and whatnot so this is

00:13:22,620 --> 00:13:27,569
how this is how a user to find schedule

00:13:25,740 --> 00:13:29,970
would look you just declare a new

00:13:27,569 --> 00:13:32,160
schedule you attach it with some

00:13:29,970 --> 00:13:36,930
functions and then you use the schedule

00:13:32,160 --> 00:13:43,620
you can see more in ticket number 678 in

00:13:36,930 --> 00:13:49,189
the OpenMP track system and and we

00:13:43,620 --> 00:13:52,829
expect this to be probably in OpenMP 6.0

00:13:49,189 --> 00:13:56,220
I'll just say on rod so for performance

00:13:52,829 --> 00:13:58,210
portability we then built we actually

00:13:56,220 --> 00:14:00,010
built on top of

00:13:58,210 --> 00:14:01,930
the loop scheduling strategies that

00:14:00,010 --> 00:14:04,600
we've already developed and into

00:14:01,930 --> 00:14:07,810
particular user-defined schedules we

00:14:04,600 --> 00:14:10,180
hope to incorporate in the roger library

00:14:07,810 --> 00:14:17,550
so that key idea is to take this

00:14:10,180 --> 00:14:20,980
original code and just produce this raja

00:14:17,550 --> 00:14:22,840
raja layer that allows for the

00:14:20,980 --> 00:14:25,270
application programmer to just focus on

00:14:22,840 --> 00:14:28,300
the parallel li there there are science

00:14:25,270 --> 00:14:30,010
here and then this is the roger library

00:14:28,300 --> 00:14:34,330
implementation of the loop scheduling

00:14:30,010 --> 00:14:37,330
strategy so this we are out there I

00:14:34,330 --> 00:14:39,550
haven't github fork for for this version

00:14:37,330 --> 00:14:49,440
of Raja with the lightweight scheduling

00:14:39,550 --> 00:14:49,440
and you're welcome to try it out and

00:14:50,190 --> 00:14:57,490
okay so there's one more thing that I've

00:14:54,250 --> 00:14:59,980
done and that is to combine loop

00:14:57,490 --> 00:15:02,350
scheduling within node with across node

00:14:59,980 --> 00:15:05,440
load balancing this is some recent work

00:15:02,350 --> 00:15:09,970
and I've actually got some good results

00:15:05,440 --> 00:15:12,240
for it and what we do is just put inside

00:15:09,970 --> 00:15:15,100
the term plus plus runtime system this

00:15:12,240 --> 00:15:18,430
low overhead loop scheduling strategy

00:15:15,100 --> 00:15:22,420
and we adjust the loop scheduling

00:15:18,430 --> 00:15:24,820
strategy for the load of given the

00:15:22,420 --> 00:15:28,930
parameters of load balancing across node

00:15:24,820 --> 00:15:31,360
strategy and we do my Sirsa to have a

00:15:28,930 --> 00:15:32,830
load balancing strategy to be adapted

00:15:31,360 --> 00:15:35,650
for the loop scheduling strategy and

00:15:32,830 --> 00:15:38,940
this allows for a synergistic load

00:15:35,650 --> 00:15:42,970
balancing and loop scheduling technique

00:15:38,940 --> 00:15:45,850
you can check it out if you want from

00:15:42,970 --> 00:15:49,330
bit bucket like and these are some

00:15:45,850 --> 00:15:52,570
results for the particle and cell

00:15:49,330 --> 00:15:57,900
application and this was run on blue

00:15:52,570 --> 00:15:57,900
waters here's some related work

00:15:59,940 --> 00:16:06,210
here's a related work here's what we're

00:16:01,920 --> 00:16:09,210
doing and this is where in the salt

00:16:06,210 --> 00:16:12,930
project we've impacted I just have some

00:16:09,210 --> 00:16:16,320
points on the CPU and GPU there's some

00:16:12,930 --> 00:16:18,660
work being done for partitioning and

00:16:16,320 --> 00:16:22,110
current CPUs uther GPUs using loop

00:16:18,660 --> 00:16:24,780
scheduling and we're working on that on

00:16:22,110 --> 00:16:28,350
the next year and I'm also work with

00:16:24,780 --> 00:16:32,040
nurse at Berkeley to implement the solve

00:16:28,350 --> 00:16:34,820
are the smart software's of using this

00:16:32,040 --> 00:16:43,050
dynamic static scheduling strategy and

00:16:34,820 --> 00:16:45,290
so here's a summary and thank you for

00:16:43,050 --> 00:16:45,290

YouTube URL: https://www.youtube.com/watch?v=SSAIRyZz9GQ


