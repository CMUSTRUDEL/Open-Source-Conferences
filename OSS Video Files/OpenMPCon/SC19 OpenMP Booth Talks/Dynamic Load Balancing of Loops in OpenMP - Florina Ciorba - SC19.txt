Title: Dynamic Load Balancing of Loops in OpenMP - Florina Ciorba - SC19
Publication date: 2019-11-25
Playlist: SC19 OpenMP Booth Talks
Description: 
	SC19 November 19, 2019  Denver
Slides: https://www.openmp.org/wp-content/uploads/SC19-FlorinaCiorba-Dynamic.pdf
Captions: 
	00:00:00,030 --> 00:00:05,430
hello everyone and welcome to my talk

00:00:03,240 --> 00:00:06,960
about dynamic load balancing and openmp

00:00:05,430 --> 00:00:08,910
my name is Serena chairman with the

00:00:06,960 --> 00:00:10,200
University of Basel Switzerland and I

00:00:08,910 --> 00:00:15,360
would like to tell you what we have been

00:00:10,200 --> 00:00:16,650
doing to balance loops in OpenMP we need

00:00:15,360 --> 00:00:18,390
to balance loops because there is load

00:00:16,650 --> 00:00:20,779
imbalance in certain applications that

00:00:18,390 --> 00:00:24,480
use open MP for parallelization and

00:00:20,779 --> 00:00:26,340
scheduling is one way to solve the load

00:00:24,480 --> 00:00:28,320
imbalance problem and we have been using

00:00:26,340 --> 00:00:29,880
dynamic loop self scheduling which is a

00:00:28,320 --> 00:00:33,090
class of scheduling algorithms that I'll

00:00:29,880 --> 00:00:35,070
describe in a moment to do that in the

00:00:33,090 --> 00:00:36,800
new open MP runtime library

00:00:35,070 --> 00:00:40,020
implementation as well as in the LLVM

00:00:36,800 --> 00:00:43,410
runtime library implementation and also

00:00:40,020 --> 00:00:44,969
share a few takeaway messages I would

00:00:43,410 --> 00:00:46,649
like to first give acknowledgments to a

00:00:44,969 --> 00:00:48,180
lot of my collaborators this is mainly

00:00:46,649 --> 00:00:50,039
funded by the Swiss National Science

00:00:48,180 --> 00:00:51,660
Foundation's through a project in

00:00:50,039 --> 00:00:53,070
multilevel scheduling we have been

00:00:51,660 --> 00:00:55,610
working with my team at the University

00:00:53,070 --> 00:01:06,600
of Basel we have also been working oh

00:00:55,610 --> 00:01:07,799
excuse me just a second yeah everything

00:01:06,600 --> 00:01:09,119
we have been working also with

00:01:07,799 --> 00:01:12,840
collaborators at the University of

00:01:09,119 --> 00:01:15,869
Darmstadt Dresden Mississippi openmp ARP

00:01:12,840 --> 00:01:20,330
Brookhaven Argonne and also with ACP

00:01:15,869 --> 00:01:24,210
computing exascale computing project so

00:01:20,330 --> 00:01:26,460
load imbalance appears in computational

00:01:24,210 --> 00:01:29,030
intensive loops that are parallelized

00:01:26,460 --> 00:01:31,110
with open MP and these loops are

00:01:29,030 --> 00:01:34,320
representative of applications that are

00:01:31,110 --> 00:01:36,600
large data parallel and irregular in

00:01:34,320 --> 00:01:38,250
their implementation and many

00:01:36,600 --> 00:01:40,439
applications actually spend most of

00:01:38,250 --> 00:01:42,689
their time executing loops in science

00:01:40,439 --> 00:01:44,729
engineering and Industry and we also

00:01:42,689 --> 00:01:47,280
have complement complement from the

00:01:44,729 --> 00:01:49,229
hardware side that is also growing in

00:01:47,280 --> 00:01:53,100
complexity we have a highly

00:01:49,229 --> 00:01:55,619
heterogeneous architecture ecosystem

00:01:53,100 --> 00:01:57,869
these days which also leads to a large

00:01:55,619 --> 00:02:00,360
and massive parallelism that we need to

00:01:57,869 --> 00:02:04,110
exploit and weaken if we look at the

00:02:00,360 --> 00:02:06,060
trends about 18 years ago we had about

00:02:04,110 --> 00:02:08,729
one core in all the systems in the top

00:02:06,060 --> 00:02:12,569
500 list and that has grown to almost

00:02:08,729 --> 00:02:13,290
three digits in in the top 500 list of

00:02:12,569 --> 00:02:16,319
last year

00:02:13,290 --> 00:02:19,159
so the question is how does the increase

00:02:16,319 --> 00:02:22,500
software parallelism execute on large

00:02:19,159 --> 00:02:27,239
parallel and wildly widely distributed

00:02:22,500 --> 00:02:30,599
machines load imbalance is actually how

00:02:27,239 --> 00:02:32,310
they do is so they they execute very

00:02:30,599 --> 00:02:34,319
nicely for some parts of the application

00:02:32,310 --> 00:02:37,230
but when there is a computational

00:02:34,319 --> 00:02:39,870
intensive loop we can see here that

00:02:37,230 --> 00:02:42,150
there is load imbalance in the openmp

00:02:39,870 --> 00:02:44,939
level load imbalance in the MPI level

00:02:42,150 --> 00:02:48,510
and we are trying to solve exactly this

00:02:44,939 --> 00:02:50,579
problem so the focuses of this talk is

00:02:48,510 --> 00:02:52,620
concentrated on the addressing load

00:02:50,579 --> 00:02:54,359
imbalance in OpenMP but this the same

00:02:52,620 --> 00:02:58,920
methods can be applied at MPI level as

00:02:54,359 --> 00:03:00,930
well so I think I will maybe go a little

00:02:58,920 --> 00:03:04,290
bit faster over this slide about OpenMP

00:03:00,930 --> 00:03:05,940
loop scheduling we have work to be

00:03:04,290 --> 00:03:08,970
shared among the threads that are

00:03:05,940 --> 00:03:11,099
created is using openmp and we can use

00:03:08,970 --> 00:03:12,900
different scheduling options to to give

00:03:11,099 --> 00:03:14,489
work to those threads if we use a static

00:03:12,900 --> 00:03:17,790
scheduling option with a certain chunk

00:03:14,489 --> 00:03:20,849
size we may have one thread and another

00:03:17,790 --> 00:03:24,599
thread that executes with some offset in

00:03:20,849 --> 00:03:28,379
time however can we use other schedules

00:03:24,599 --> 00:03:31,530
that minimize that particular offset in

00:03:28,379 --> 00:03:33,959
time which is called load imbalance so

00:03:31,530 --> 00:03:36,660
there are some options already in the

00:03:33,959 --> 00:03:39,449
OpenMP that we can use to minimize load

00:03:36,660 --> 00:03:41,639
imbalance such as static dynamic guided

00:03:39,449 --> 00:03:43,260
and auto auto is actually not an

00:03:41,639 --> 00:03:46,829
implementation of a particular scheduler

00:03:43,260 --> 00:03:49,769
but the firstly the the choice of it to

00:03:46,829 --> 00:03:51,060
the runtime system what is important to

00:03:49,769 --> 00:03:53,549
know is that these methods have been

00:03:51,060 --> 00:03:55,410
proposed over the years and dynamic

00:03:53,549 --> 00:03:57,989
actually it's called self scheduling

00:03:55,410 --> 00:04:00,209
which has been propagated optimal

00:03:57,989 --> 00:04:02,099
version of lists of scheduling proposed

00:04:00,209 --> 00:04:06,750
by Richard Wrangham

00:04:02,099 --> 00:04:08,609
already in 1966 and guided is actually a

00:04:06,750 --> 00:04:11,729
method that has been proposed in already

00:04:08,609 --> 00:04:14,069
already in 1987 by Cooke and poured in

00:04:11,729 --> 00:04:15,239
from oculus and it has been one of the

00:04:14,069 --> 00:04:17,849
first self scheduling methods

00:04:15,239 --> 00:04:19,430
implemented in OpenMP in which came out

00:04:17,849 --> 00:04:23,070
in 1997

00:04:19,430 --> 00:04:24,840
so are these schedules good enough to

00:04:23,070 --> 00:04:27,120
exploit the parallelism that we have

00:04:24,840 --> 00:04:29,340
these days or beyond this year

00:04:27,120 --> 00:04:30,780
the schedule sufficient to cover all the

00:04:29,340 --> 00:04:33,090
characteristics of the systems and the

00:04:30,780 --> 00:04:34,979
applications are there better schedules

00:04:33,090 --> 00:04:36,720
not in OpenMP and i think you already

00:04:34,979 --> 00:04:38,490
can guess the answer that yes there are

00:04:36,720 --> 00:04:41,250
much more schedules that we should be

00:04:38,490 --> 00:04:42,750
able to to use in OpenMP to address load

00:04:41,250 --> 00:04:44,639
imbalance and I'll give an example that

00:04:42,750 --> 00:04:47,070
we recently published in a paper that

00:04:44,639 --> 00:04:49,889
will be it will come out early next year

00:04:47,070 --> 00:04:50,820
where for the same example that we have

00:04:49,889 --> 00:04:52,380
shown before that comes from

00:04:50,820 --> 00:04:54,780
astrophysics actually and this is just

00:04:52,380 --> 00:04:57,990
one iteration that is repeated over

00:04:54,780 --> 00:04:59,669
hundreds and thousands of times the load

00:04:57,990 --> 00:05:01,889
imbalance at the openmp level has been

00:04:59,669 --> 00:05:04,860
almost eliminated using one of the

00:05:01,889 --> 00:05:07,470
techniques that appeared in 1990 called

00:05:04,860 --> 00:05:09,060
factoring and we used against it the

00:05:07,470 --> 00:05:11,639
same self scheduling techniques at the

00:05:09,060 --> 00:05:14,610
MPI level to minimize the white space

00:05:11,639 --> 00:05:16,050
the load imbalance at the API level so

00:05:14,610 --> 00:05:18,840
yes the answer is that there are many

00:05:16,050 --> 00:05:20,910
other options I will maybe skip a little

00:05:18,840 --> 00:05:24,090
bit about this slide I think we all know

00:05:20,910 --> 00:05:26,639
what causes load imbalance computational

00:05:24,090 --> 00:05:28,080
intensive loops are irregular and that

00:05:26,639 --> 00:05:30,210
leads to variation in iteration

00:05:28,080 --> 00:05:31,590
execution times system in this

00:05:30,210 --> 00:05:34,050
variability is what I would like to

00:05:31,590 --> 00:05:35,849
focus this slide on that comes from the

00:05:34,050 --> 00:05:38,340
differences in hardware which leads to

00:05:35,849 --> 00:05:40,740
processing elements variety in the

00:05:38,340 --> 00:05:42,660
delivered computing speed non-uniform

00:05:40,740 --> 00:05:44,880
memory access operating system jitters

00:05:42,660 --> 00:05:47,039
and other resource sharing such as

00:05:44,880 --> 00:05:49,470
memory buses and network support in the

00:05:47,039 --> 00:05:51,270
distributed memory domain and of course

00:05:49,470 --> 00:05:53,490
there are other delays that we cannot

00:05:51,270 --> 00:05:55,380
avoid but what I would like to point out

00:05:53,490 --> 00:05:58,260
here is that the impact of system

00:05:55,380 --> 00:05:59,699
induced variability on load imbalance is

00:05:58,260 --> 00:06:03,120
often neglected by the scheduling

00:05:59,699 --> 00:06:04,470
algorithms in OpenMP right now but not

00:06:03,120 --> 00:06:08,370
neglected by the other available

00:06:04,470 --> 00:06:11,039
scheduling methods I mentioned some

00:06:08,370 --> 00:06:13,229
scheduling as being the central element

00:06:11,039 --> 00:06:16,770
of today's talk and all the methods that

00:06:13,229 --> 00:06:19,650
we are going to present it is a it's

00:06:16,770 --> 00:06:22,080
almost it's an approximation that is

00:06:19,650 --> 00:06:25,229
twice as worse as the most optimal a

00:06:22,080 --> 00:06:27,479
possible schedule using preemption for a

00:06:25,229 --> 00:06:30,030
set of what tasks executing on on a set

00:06:27,479 --> 00:06:32,550
of resources and it allow what the

00:06:30,030 --> 00:06:34,199
important benefit is that you don't need

00:06:32,550 --> 00:06:36,450
to worry about poor processor

00:06:34,199 --> 00:06:39,289
utilization so it's actually perfect for

00:06:36,450 --> 00:06:41,070
minimizing load imbalance because

00:06:39,289 --> 00:06:43,560
processes or threads

00:06:41,070 --> 00:06:45,090
acquire the next computational step or

00:06:43,560 --> 00:06:47,100
the next starts whenever they are ready

00:06:45,090 --> 00:06:48,510
that leads to perfect load balance and

00:06:47,100 --> 00:06:53,130
this is actually already implemented as

00:06:48,510 --> 00:06:54,180
dynamic one in in openmp so I told you

00:06:53,130 --> 00:06:55,410
that there are many more options

00:06:54,180 --> 00:06:58,920
available and this is just a selection

00:06:55,410 --> 00:07:02,670
this is not exhaustive they're all based

00:06:58,920 --> 00:07:06,360
on list scheduling starting with the

00:07:02,670 --> 00:07:09,930
1966 method by graha and going to self

00:07:06,360 --> 00:07:12,660
scheduling in 86 1997 guided was

00:07:09,930 --> 00:07:13,920
proposed and factoring is the method

00:07:12,660 --> 00:07:16,620
that I've shown in a previous slide that

00:07:13,920 --> 00:07:18,900
was used to optimize loading balance at

00:07:16,620 --> 00:07:21,330
the OpenMP level and then we have

00:07:18,900 --> 00:07:24,150
another method that also combines this

00:07:21,330 --> 00:07:26,100
with data locality using fractals that's

00:07:24,150 --> 00:07:28,050
why it's called frack tiling factoring

00:07:26,100 --> 00:07:30,450
and piling together and then we have

00:07:28,050 --> 00:07:33,030
other methods that are actually adapting

00:07:30,450 --> 00:07:35,460
the allocation of work the self

00:07:33,030 --> 00:07:36,900
scheduling of work at execution are

00:07:35,460 --> 00:07:39,840
called adaptive factoring so there's a

00:07:36,900 --> 00:07:43,500
lot that has not yet been included in

00:07:39,840 --> 00:07:45,060
the openmp runtimes in the standards and

00:07:43,500 --> 00:07:48,420
the choice of scheduling can actually

00:07:45,060 --> 00:07:49,770
help in different situations so this is

00:07:48,420 --> 00:07:51,480
what we are trying to explore but the

00:07:49,770 --> 00:07:52,680
scheduling algorithm is not useful if

00:07:51,480 --> 00:07:54,270
it's not implemented in the runtime

00:07:52,680 --> 00:07:55,980
library or in the library or in the

00:07:54,270 --> 00:07:58,500
compiler so there has been a lot of

00:07:55,980 --> 00:08:00,020
effort in implementing this in many

00:07:58,500 --> 00:08:05,070
compilers over the year starting with

00:08:00,020 --> 00:08:07,590
1987 and our most recent work is already

00:08:05,070 --> 00:08:09,780
in the last couple of years I would like

00:08:07,590 --> 00:08:11,430
to focus here only the attention to some

00:08:09,780 --> 00:08:14,490
to some methods that have been

00:08:11,430 --> 00:08:17,340
implemented in 1998 that are not

00:08:14,490 --> 00:08:21,090
currently active today we have started

00:08:17,340 --> 00:08:25,190
this work as an extension of a new

00:08:21,090 --> 00:08:29,070
runtime library implementation of OpenMP

00:08:25,190 --> 00:08:30,450
that was proposed by pinna and al we

00:08:29,070 --> 00:08:32,490
have extended it and we have added a few

00:08:30,450 --> 00:08:34,620
saw scheduling algorithms already in

00:08:32,490 --> 00:08:38,310
2017 and we have published different

00:08:34,620 --> 00:08:40,229
papers in 2018 and in 2018 we have a

00:08:38,310 --> 00:08:41,880
poster also which you can see later this

00:08:40,229 --> 00:08:47,580
evening in the session what you can

00:08:41,880 --> 00:08:50,280
learn more about that so I would like to

00:08:47,580 --> 00:08:53,490
tell you how we have done this so we

00:08:50,280 --> 00:08:54,840
have actually augmented the runtime we

00:08:53,490 --> 00:08:57,630
have our

00:08:54,840 --> 00:09:00,300
the challenge was to him to offer the

00:08:57,630 --> 00:09:01,830
user a way to choose among the old the

00:09:00,300 --> 00:09:03,270
other available options out there and

00:09:01,830 --> 00:09:04,529
for that we could not extend the

00:09:03,270 --> 00:09:07,380
standard because then we would have an

00:09:04,529 --> 00:09:10,770
endless list of of schedule clauses to

00:09:07,380 --> 00:09:12,450
explore so the idea was to use the

00:09:10,770 --> 00:09:14,130
runtime to extend the runtime so we

00:09:12,450 --> 00:09:16,410
don't modify the compiler and to defer

00:09:14,130 --> 00:09:19,380
the scheduling choice to execution time

00:09:16,410 --> 00:09:22,440
by setting the the environment variable

00:09:19,380 --> 00:09:24,150
to one of the newly added methods and in

00:09:22,440 --> 00:09:26,360
the code we only specified that the

00:09:24,150 --> 00:09:30,029
schedule will be defined at runtime and

00:09:26,360 --> 00:09:31,740
this is this is useful for the openmp

00:09:30,029 --> 00:09:36,180
runtime implementations used by Intel

00:09:31,740 --> 00:09:38,190
LLVM and new ok so we have some results

00:09:36,180 --> 00:09:40,440
already published a year ago at AI one

00:09:38,190 --> 00:09:42,029
in Barcelona in which we have added

00:09:40,440 --> 00:09:44,450
factoring - as a practical

00:09:42,029 --> 00:09:48,240
implementation of the factoring method

00:09:44,450 --> 00:09:50,100
trapezoid weighted factoring and random

00:09:48,240 --> 00:09:52,500
random is a method that we use only for

00:09:50,100 --> 00:09:55,860
baseline comparison what is important to

00:09:52,500 --> 00:09:58,500
know is that when we when we define new

00:09:55,860 --> 00:10:00,210
schedules that was the design strategies

00:09:58,500 --> 00:10:02,310
for the schedules that have been

00:10:00,210 --> 00:10:05,100
proposed here is that they want to

00:10:02,310 --> 00:10:08,640
minimize the scheduling overhead of

00:10:05,100 --> 00:10:10,260
allocating work at runtime and also

00:10:08,640 --> 00:10:13,080
minimize load imbalance so the ideal

00:10:10,260 --> 00:10:14,940
point would be here some skid sorry so

00:10:13,080 --> 00:10:17,190
scheduling is here where there is no

00:10:14,940 --> 00:10:19,080
load imbalance but there is overhead

00:10:17,190 --> 00:10:22,830
because you only give one single work

00:10:19,080 --> 00:10:24,990
item at a time static is actually on the

00:10:22,830 --> 00:10:26,520
other extreme where you have no

00:10:24,990 --> 00:10:28,380
scheduling overhead because you can pre

00:10:26,520 --> 00:10:30,690
compute the amount of work that can be

00:10:28,380 --> 00:10:34,140
taken at runtime by any available thread

00:10:30,690 --> 00:10:36,150
and loading balance however is not

00:10:34,140 --> 00:10:38,520
guaranteed so there's a sweet spot

00:10:36,150 --> 00:10:39,839
between this between these extremes and

00:10:38,520 --> 00:10:42,060
there is also a third dimension of

00:10:39,839 --> 00:10:43,890
locality right so we don't only care

00:10:42,060 --> 00:10:45,540
about load imbalance we don't only care

00:10:43,890 --> 00:10:47,670
about scheduling overhead we want to

00:10:45,540 --> 00:10:48,810
also minimize locality and there is one

00:10:47,670 --> 00:10:50,880
method that I already mentioned that

00:10:48,810 --> 00:10:53,520
does that the other ones don't take into

00:10:50,880 --> 00:10:55,980
account that future work for us to

00:10:53,520 --> 00:10:58,170
implement in the run time so we have

00:10:55,980 --> 00:10:59,339
been as I mentioned we use this through

00:10:58,170 --> 00:11:04,140
the runtime and through the openness

00:10:59,339 --> 00:11:05,280
rescheduling environment variable it is

00:11:04,140 --> 00:11:07,920
important to note that even though we've

00:11:05,280 --> 00:11:08,490
done two implementations this mechanism

00:11:07,920 --> 00:11:10,080
the scale

00:11:08,490 --> 00:11:12,839
mechanisms are not limited to a single

00:11:10,080 --> 00:11:15,899
runtime implementation so they can be

00:11:12,839 --> 00:11:16,410
used in any runtime library that

00:11:15,899 --> 00:11:19,380
implements

00:11:16,410 --> 00:11:21,779
OpenMP okay we have some experiments

00:11:19,380 --> 00:11:24,330
that we have performed on on a two

00:11:21,779 --> 00:11:26,700
socket machine we have said the the

00:11:24,330 --> 00:11:28,950
field pinning with opinion where we had

00:11:26,700 --> 00:11:30,750
some oversubscription of some nodes more

00:11:28,950 --> 00:11:33,330
of a subscription even more of a

00:11:30,750 --> 00:11:35,040
subscription and so forth so the

00:11:33,330 --> 00:11:37,080
question was does a schedule benefit a

00:11:35,040 --> 00:11:39,959
parallel loop and can it handle Hardware

00:11:37,080 --> 00:11:43,100
heterogeneity as mimicked by these

00:11:39,959 --> 00:11:46,110
oversubscription of a single socket so

00:11:43,100 --> 00:11:47,700
we for our experiments we use 20 threads

00:11:46,110 --> 00:11:49,620
we have seen we compared against the

00:11:47,700 --> 00:11:51,270
existing implementations in the standard

00:11:49,620 --> 00:11:54,450
and the newly added scheduling

00:11:51,270 --> 00:11:56,580
algorithms five pinnings these are the

00:11:54,450 --> 00:11:59,640
hardware descriptions and we also

00:11:56,580 --> 00:12:02,220
repeated every experiment 20 times - to

00:11:59,640 --> 00:12:04,410
take the average of that the median

00:12:02,220 --> 00:12:06,810
excuse me so we see for an adjoint

00:12:04,410 --> 00:12:09,029
convolution it is a computational kernel

00:12:06,810 --> 00:12:12,120
is not a full-fledged application which

00:12:09,029 --> 00:12:13,860
is actually triangular so it has more

00:12:12,120 --> 00:12:15,779
work at the beginning and less work at

00:12:13,860 --> 00:12:18,839
the end that's why it exhibits load

00:12:15,779 --> 00:12:22,529
imbalance when implemented using an open

00:12:18,839 --> 00:12:24,390
MP work-sharing loop for n to the power

00:12:22,529 --> 00:12:26,420
of 6 number of iterations and the

00:12:24,390 --> 00:12:29,070
variation between the execution of this

00:12:26,420 --> 00:12:32,329
every-every of those iterations the

00:12:29,070 --> 00:12:36,000
variation the the statistical dispersion

00:12:32,329 --> 00:12:38,220
is actually 57% so ideally if every time

00:12:36,000 --> 00:12:39,600
if every iteration would take the same

00:12:38,220 --> 00:12:41,430
amount of time the variation would be

00:12:39,600 --> 00:12:42,899
very small which tells you that this is

00:12:41,430 --> 00:12:46,020
highly variable therefore it could

00:12:42,899 --> 00:12:49,680
benefit from additional methods and we

00:12:46,020 --> 00:12:51,329
see here that static and weighted

00:12:49,680 --> 00:12:53,310
factoring or the least sensitive to

00:12:51,329 --> 00:12:55,470
pinnings here are the five pinnings for

00:12:53,310 --> 00:12:58,500
every method so basically they offer up

00:12:55,470 --> 00:12:59,700
almost comparable results no the these

00:12:58,500 --> 00:13:02,279
are the least and these are the most

00:12:59,700 --> 00:13:04,020
sensitive to pin exit excuse me and here

00:13:02,279 --> 00:13:06,390
we have the best performing method which

00:13:04,020 --> 00:13:08,100
is not one of the three methods that

00:13:06,390 --> 00:13:09,779
currently the the three methods are

00:13:08,100 --> 00:13:10,860
currently exist in the standard so that

00:13:09,779 --> 00:13:14,459
means that there is room for improvement

00:13:10,860 --> 00:13:16,230
and the least performing happened to be

00:13:14,459 --> 00:13:18,839
guided sub schedule for this particular

00:13:16,230 --> 00:13:20,579
case we have another example from the

00:13:18,839 --> 00:13:22,079
rodinia benchmarks it's a molecular

00:13:20,579 --> 00:13:23,759
dynamics

00:13:22,079 --> 00:13:26,130
which has much smaller number of

00:13:23,759 --> 00:13:28,019
iterations and just as high variability

00:13:26,130 --> 00:13:30,690
between the iteration execution times

00:13:28,019 --> 00:13:32,940
and we see also the most sensitive to

00:13:30,690 --> 00:13:35,160
paintings here due to some initial

00:13:32,940 --> 00:13:37,620
calibration to calculate the difference

00:13:35,160 --> 00:13:39,180
the the weights between the different

00:13:37,620 --> 00:13:41,370
hardware course because we have

00:13:39,180 --> 00:13:43,110
oversubscription here we have no

00:13:41,370 --> 00:13:44,759
restriction and for the last three

00:13:43,110 --> 00:13:47,630
paintings we have over subscriptions so

00:13:44,759 --> 00:13:49,800
we can see that they perform poorly

00:13:47,630 --> 00:13:52,500
however the best performing happened to

00:13:49,800 --> 00:13:56,279
be again factoring - which is very close

00:13:52,500 --> 00:13:59,009
to GS s and TSS and 2od the other method

00:13:56,279 --> 00:14:00,509
but for a no oversubscription and the

00:13:59,009 --> 00:14:04,440
least performant happened to be dynamic

00:14:00,509 --> 00:14:07,319
one or self scheduling so the idea here

00:14:04,440 --> 00:14:10,259
is that we have additional schedules

00:14:07,319 --> 00:14:12,870
that provide or exam provide benefit

00:14:10,259 --> 00:14:15,269
over existing schedules however when the

00:14:12,870 --> 00:14:18,930
application is quite uniform not

00:14:15,269 --> 00:14:20,699
irregular and not very large static is

00:14:18,930 --> 00:14:21,779
actually sufficient so here is not the

00:14:20,699 --> 00:14:23,639
method that tells you that you should

00:14:21,779 --> 00:14:25,560
just discard all the methods that are

00:14:23,639 --> 00:14:28,410
already present in the OpenMP standard

00:14:25,560 --> 00:14:30,240
but if you have a computational loop or

00:14:28,410 --> 00:14:32,160
several computational loops that are not

00:14:30,240 --> 00:14:33,779
showing the best performance but there

00:14:32,160 --> 00:14:35,610
is still some load imbalance there are

00:14:33,779 --> 00:14:39,689
other methods out there that one can use

00:14:35,610 --> 00:14:41,220
and they are mean the good news is that

00:14:39,689 --> 00:14:42,720
they are immediately usable so we have

00:14:41,220 --> 00:14:44,009
this library available online please

00:14:42,720 --> 00:14:45,839
tree for you to download it and play

00:14:44,009 --> 00:14:51,329
with it I'm not sure how am i doing on

00:14:45,839 --> 00:14:53,490
time I should maybe wrap up I will have

00:14:51,329 --> 00:14:56,009
more slides available online I will just

00:14:53,490 --> 00:14:58,980
try to summarize a little bit what we

00:14:56,009 --> 00:15:02,399
have been doing for ll LLVM for which we

00:14:58,980 --> 00:15:05,639
had to change just three three functions

00:15:02,399 --> 00:15:07,949
in the campi dispatch file we have added

00:15:05,639 --> 00:15:10,069
a few more functions a few more

00:15:07,949 --> 00:15:12,089
scheduling algorithms factoring

00:15:10,069 --> 00:15:14,250
trapezoid was actually already there

00:15:12,089 --> 00:15:16,470
implemented but is not conforming to the

00:15:14,250 --> 00:15:20,310
standard so we added it here so we

00:15:16,470 --> 00:15:22,230
expanded our LLVM implementation just

00:15:20,310 --> 00:15:24,990
with factoring we have interesting

00:15:22,230 --> 00:15:26,220
results that show here we have the

00:15:24,990 --> 00:15:28,170
details of the experiments which you can

00:15:26,220 --> 00:15:30,269
see online that if we so we wanted to

00:15:28,170 --> 00:15:31,800
analyze the overhead of a calling

00:15:30,269 --> 00:15:33,779
scheduling methods for the runtime

00:15:31,800 --> 00:15:35,730
versus calling them directly through the

00:15:33,779 --> 00:15:37,860
standard

00:15:35,730 --> 00:15:41,460
compliant implementation in the compiler

00:15:37,860 --> 00:15:44,100
and we see through the reference static

00:15:41,460 --> 00:15:47,640
guided and dynamic called it by the

00:15:44,100 --> 00:15:50,370
standard by the compiler static dynamic

00:15:47,640 --> 00:15:52,290
scheduling trapezoid and factoring only

00:15:50,370 --> 00:15:53,760
dynamic has a little bit of overhead

00:15:52,290 --> 00:15:55,110
which tells us that these are still

00:15:53,760 --> 00:15:56,430
useful if we call them through the

00:15:55,110 --> 00:15:57,570
random of course they are not ideal we

00:15:56,430 --> 00:16:00,900
could do much better and we're working

00:15:57,570 --> 00:16:02,550
on that and so there is some room to

00:16:00,900 --> 00:16:04,110
explore in between those two extremes I

00:16:02,550 --> 00:16:06,510
will just show you these two results and

00:16:04,110 --> 00:16:08,730
then I'll try to wrap up for more

00:16:06,510 --> 00:16:10,770
details please come see us at the poster

00:16:08,730 --> 00:16:12,630
for one case that we have also seen in

00:16:10,770 --> 00:16:14,190
the previous paper adjoint convolution

00:16:12,630 --> 00:16:16,590
which has a high variability and many

00:16:14,190 --> 00:16:19,070
iterations the static performed poorly

00:16:16,590 --> 00:16:22,080
and then I may perform the best and

00:16:19,070 --> 00:16:24,690
because then we have inherent load

00:16:22,080 --> 00:16:26,880
imbalance that dynamic actually is able

00:16:24,690 --> 00:16:30,000
to mitigate static isn't able to do that

00:16:26,880 --> 00:16:32,910
however we have a conversa performance

00:16:30,000 --> 00:16:34,500
for a dynamic and Static when we go to

00:16:32,910 --> 00:16:36,750
the molecular dynamics benchmarks we

00:16:34,500 --> 00:16:40,680
have seen before so I would like to skip

00:16:36,750 --> 00:16:43,590
to the takeaway messages here the last

00:16:40,680 --> 00:16:46,140
part of the talk was about was about the

00:16:43,590 --> 00:16:49,650
poster that you can see already at 5:00

00:16:46,140 --> 00:16:52,350
p.m. today we have shown that it is

00:16:49,650 --> 00:16:53,700
actually possible to do better that is

00:16:52,350 --> 00:16:55,200
currently available in the standard the

00:16:53,700 --> 00:16:56,700
standard was never meant to cover all

00:16:55,200 --> 00:16:59,640
possible cases so we're here to actually

00:16:56,700 --> 00:17:03,420
show that it we could complement the

00:16:59,640 --> 00:17:04,380
standard in this way and more scheduled

00:17:03,420 --> 00:17:06,690
are needed and we have two

00:17:04,380 --> 00:17:08,250
implementations already there a fact

00:17:06,690 --> 00:17:10,140
when you don't know so even if we offer

00:17:08,250 --> 00:17:12,120
you all of these choices in our we are

00:17:10,140 --> 00:17:14,760
going to release this library very soon

00:17:12,120 --> 00:17:16,500
in the couple of weeks even if you start

00:17:14,760 --> 00:17:18,570
using that library you won't know how to

00:17:16,500 --> 00:17:21,329
choose so as a rule of thumb

00:17:18,570 --> 00:17:23,070
please already use factoring to but feel

00:17:21,329 --> 00:17:24,810
free to explore other schedules as well

00:17:23,070 --> 00:17:27,000
that may be more useful for your

00:17:24,810 --> 00:17:30,360
application and your system and your

00:17:27,000 --> 00:17:33,360
scheduling loop and remaining questions

00:17:30,360 --> 00:17:37,770
for for us are how to incorporate more

00:17:33,360 --> 00:17:39,420
runtime information to actually give

00:17:37,770 --> 00:17:41,700
more information to the adaptive

00:17:39,420 --> 00:17:44,220
scheduling techniques to permit you to

00:17:41,700 --> 00:17:47,310
do to eliminate load imbalance even more

00:17:44,220 --> 00:17:48,870
and also to allow the users to develop

00:17:47,310 --> 00:17:51,720
their own scheduling techniques and we

00:17:48,870 --> 00:17:53,250
have some already existing efforts on

00:17:51,720 --> 00:17:55,830
that we have a publication that I won

00:17:53,250 --> 00:17:57,690
this year and if you want to know how

00:17:55,830 --> 00:18:00,270
this benefits real application not just

00:17:57,690 --> 00:18:01,410
micro kernels that have a single or very

00:18:00,270 --> 00:18:02,840
simple loop in there

00:18:01,410 --> 00:18:05,010
we have applied this to a computational

00:18:02,840 --> 00:18:07,110
application from astrophysics and we

00:18:05,010 --> 00:18:08,970
have seen that doing the dynamic

00:18:07,110 --> 00:18:10,620
load-balancing at the MPI and OpenMP

00:18:08,970 --> 00:18:13,590
level gave us an improvement over time

00:18:10,620 --> 00:18:16,080
step of up to 40 percent and overall

00:18:13,590 --> 00:18:17,070
over 3,000 times sets of 15 percent so

00:18:16,080 --> 00:18:18,809
there actually there's a lot of

00:18:17,070 --> 00:18:21,540
potential to use dynamic load-balancing

00:18:18,809 --> 00:18:22,890
at one time I think there's time maybe

00:18:21,540 --> 00:18:24,960
for one question if not I'm available

00:18:22,890 --> 00:18:35,870
around for further questions thank you

00:18:24,960 --> 00:18:35,870
for your attention take aways messages

00:18:36,559 --> 00:18:41,429
when you say dynamic are you using

00:18:39,470 --> 00:18:43,620
monotonic dynamic or non monotonic

00:18:41,429 --> 00:18:45,420
dynamic because at least in the LLVM

00:18:43,620 --> 00:18:48,570
runtime the overhead is very different

00:18:45,420 --> 00:18:50,250
yes we are using monotonic dynamic at

00:18:48,570 --> 00:18:53,220
this point but we are exploring exactly

00:18:50,250 --> 00:18:54,660
this challenge especially especially

00:18:53,220 --> 00:18:55,500
because a lot imbalance is important to

00:18:54,660 --> 00:18:59,010
be correct

00:18:55,500 --> 00:19:00,630
low overhead and also to maintain data

00:18:59,010 --> 00:19:04,530
locality so yes it's a very good point

00:19:00,630 --> 00:19:06,830
thank you for bringing that up thank you

00:19:04,530 --> 00:19:06,830

YouTube URL: https://www.youtube.com/watch?v=1EgrcnAYioI


