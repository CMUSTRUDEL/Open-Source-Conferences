Title: OpenMP clang and flang Development - Johannes Doerfert - SC19
Publication date: 2019-11-25
Playlist: SC19 OpenMP Booth Talks
Description: 
	20 November 2019 - SC19 - Denver
Slides:  https://www.openmp.org/wp-content/uploads/SC19-Johannes-clang-flang.pdf
Captions: 
	00:00:00,860 --> 00:00:03,840
whenever I'm ready uh-huh what's the

00:00:03,360 --> 00:00:08,719
time

00:00:03,840 --> 00:00:11,670
45 perfect okay so hi everyone welcome

00:00:08,719 --> 00:00:14,280
giving a talk about as you can see LLVM

00:00:11,670 --> 00:00:16,619
and OpenMP so we are we what is going on

00:00:14,280 --> 00:00:19,380
if you're interested in LLVM and OpenMP

00:00:16,619 --> 00:00:22,050
this might be a good thing i will

00:00:19,380 --> 00:00:24,390
briefly talk about clang clang and other

00:00:22,050 --> 00:00:26,189
things that are happening if you have

00:00:24,390 --> 00:00:29,340
any questions during it or feel free to

00:00:26,189 --> 00:00:30,570
ask so what I have actually is a lot of

00:00:29,340 --> 00:00:31,740
bullet points in the different

00:00:30,570 --> 00:00:34,440
categories of things that are happening

00:00:31,740 --> 00:00:35,880
but I want to answer your questions so

00:00:34,440 --> 00:00:37,950
if you have questions now during your

00:00:35,880 --> 00:00:39,290
talk asked him otherwise ask him

00:00:37,950 --> 00:00:43,230
afterwards that's fine as well

00:00:39,290 --> 00:00:45,960
okay let's do this first of all there is

00:00:43,230 --> 00:00:48,480
a new webpage new is generally speaking

00:00:45,960 --> 00:00:51,960
that shows you all the open and p50

00:00:48,480 --> 00:00:53,730
features that we are implementing if we

00:00:51,960 --> 00:00:56,399
are done if we are currently working on

00:00:53,730 --> 00:00:58,680
it or what's the statuses and if you

00:00:56,399 --> 00:00:59,840
want to take a look it roughly looks

00:00:58,680 --> 00:01:03,300
like this

00:00:59,840 --> 00:01:06,750
so we categorized them into various

00:01:03,300 --> 00:01:08,549
different categories on T empty tasking

00:01:06,750 --> 00:01:11,490
device extensions mostly device

00:01:08,549 --> 00:01:13,170
extensions a green is done red is

00:01:11,490 --> 00:01:15,270
usually unclaimed nobody is currently

00:01:13,170 --> 00:01:18,150
working on it as far as we know and

00:01:15,270 --> 00:01:20,549
yellow means people are working on it

00:01:18,150 --> 00:01:21,810
you get additional information in case

00:01:20,549 --> 00:01:23,430
you need it you want to look at the

00:01:21,810 --> 00:01:27,570
reviews you want to look at the patches

00:01:23,430 --> 00:01:30,659
you find most of the stuff in here ok so

00:01:27,570 --> 00:01:32,369
again that is this link but if you just

00:01:30,659 --> 00:01:37,650
google open and peace of Port Klang you

00:01:32,369 --> 00:01:39,630
will find this let's go forward so

00:01:37,650 --> 00:01:41,490
testing so one big thing that we're

00:01:39,630 --> 00:01:43,350
currently trying to enact is a testing

00:01:41,490 --> 00:01:45,030
infrastructure right now our testing you

00:01:43,350 --> 00:01:47,909
know LOV I'm open and P is really bad

00:01:45,030 --> 00:01:50,880
and at least community testing so we're

00:01:47,909 --> 00:01:52,829
half the hardware or basically ready to

00:01:50,880 --> 00:01:55,290
build build ports for offloading and

00:01:52,829 --> 00:01:58,649
we'll get to offloading in a second

00:01:55,290 --> 00:02:00,540
we will do community on community on

00:01:58,649 --> 00:02:01,770
build parts that actually run open and P

00:02:00,540 --> 00:02:03,390
that build everything that offload

00:02:01,770 --> 00:02:04,890
everything you do like first correctness

00:02:03,390 --> 00:02:08,789
test we get into performance testing

00:02:04,890 --> 00:02:10,649
later we will have ok what what else do

00:02:08,789 --> 00:02:12,270
we have we don't have even parallelism

00:02:10,649 --> 00:02:13,230
tests right now because the lob on test

00:02:12,270 --> 00:02:14,909
suite doesn't really serve

00:02:13,230 --> 00:02:17,310
or did use case that your tests are

00:02:14,909 --> 00:02:18,569
parallel it kind of like it's a little

00:02:17,310 --> 00:02:21,030
bit tricky it's just infrastructure

00:02:18,569 --> 00:02:22,769
changes that are going on we integrate

00:02:21,030 --> 00:02:25,200
devine V performance at the V and V

00:02:22,769 --> 00:02:28,040
verification and validation test suite

00:02:25,200 --> 00:02:31,920
into the aluminum test suite right now

00:02:28,040 --> 00:02:33,810
and we have the last point here is a

00:02:31,920 --> 00:02:36,690
host back-end so we have a device

00:02:33,810 --> 00:02:38,549
runtime library that is compiled for

00:02:36,690 --> 00:02:40,379
your device let's say it's written in

00:02:38,549 --> 00:02:43,470
CUDA and you compile it for your for

00:02:40,379 --> 00:02:45,900
your Nvidia hardware and now once you do

00:02:43,470 --> 00:02:48,360
that you lose a little bit of otherwise

00:02:45,900 --> 00:02:50,970
cool a capability studies for example

00:02:48,360 --> 00:02:53,129
sanitizers threat sanitizers it's like

00:02:50,970 --> 00:02:55,140
there's research sure but we have a lot

00:02:53,129 --> 00:02:57,120
of tooling that works of the host that

00:02:55,140 --> 00:02:59,040
we would like to reuse and one thing we

00:02:57,120 --> 00:03:00,750
are currently doing is we want to have a

00:02:59,040 --> 00:03:03,750
host back-end for the device front-end

00:03:00,750 --> 00:03:05,280
library which where we can check almost

00:03:03,750 --> 00:03:07,290
all of the device runtime library

00:03:05,280 --> 00:03:09,810
through sanitizer bills so we can run

00:03:07,290 --> 00:03:11,760
them as if we are going to the device

00:03:09,810 --> 00:03:13,560
but we're not like we're staying the

00:03:11,760 --> 00:03:19,489
host and then all the sanitizers work

00:03:13,560 --> 00:03:22,079
I am optimizations so this is this is

00:03:19,489 --> 00:03:24,000
always an interesting topic there's

00:03:22,079 --> 00:03:26,639
various various kinds of optimizations

00:03:24,000 --> 00:03:29,459
going on for OpenMP not only for OpenMP

00:03:26,639 --> 00:03:31,560
but especially for canopy they are the

00:03:29,459 --> 00:03:33,660
ones that are more sequential

00:03:31,560 --> 00:03:35,010
optimizations so standard optimizations

00:03:33,660 --> 00:03:36,810
you would like to see anyway like

00:03:35,010 --> 00:03:38,849
constant propagation into a parallel

00:03:36,810 --> 00:03:40,590
region right now you take any compiler

00:03:38,849 --> 00:03:42,299
you want at least any compiler I could

00:03:40,590 --> 00:03:45,180
find it will not propagate a constant

00:03:42,299 --> 00:03:47,609
into your parallel region if there is

00:03:45,180 --> 00:03:50,099
one please show it to me if you turn on

00:03:47,609 --> 00:03:52,290
this flag LLVM will do that and it will

00:03:50,099 --> 00:03:54,150
do more so all these like a lot of these

00:03:52,290 --> 00:03:56,430
scalar optimizations will just happen to

00:03:54,150 --> 00:03:58,709
work wants to turn this on it will be

00:03:56,430 --> 00:04:02,040
turned on automatically by default

00:03:58,709 --> 00:04:03,599
soonish as soon as I get like it is more

00:04:02,040 --> 00:04:05,099
or less a compile time issue so I have

00:04:03,599 --> 00:04:07,230
to work a little bit on compile time

00:04:05,099 --> 00:04:08,940
problems but like you pay like three

00:04:07,230 --> 00:04:10,709
percent or so so it's a little not like

00:04:08,940 --> 00:04:12,329
hurt you too much but you get actually

00:04:10,709 --> 00:04:14,430
all the good things you want and you

00:04:12,329 --> 00:04:16,109
will actually get more not only

00:04:14,430 --> 00:04:17,609
parallelism optimization but this will

00:04:16,109 --> 00:04:19,019
just be better in to procedural

00:04:17,609 --> 00:04:21,180
optimization that is what it will

00:04:19,019 --> 00:04:22,890
actually be okay

00:04:21,180 --> 00:04:24,539
then there's open and pia where Perley

00:04:22,890 --> 00:04:26,580
optimizations so things that actually

00:04:24,539 --> 00:04:28,979
kind of change the way parallelism is

00:04:26,580 --> 00:04:30,479
- cute it changed it things that are

00:04:28,979 --> 00:04:32,060
aware of to open appear on time calls

00:04:30,479 --> 00:04:34,889
what they mean what they do

00:04:32,060 --> 00:04:37,409
deduplicating run time calls expanding

00:04:34,889 --> 00:04:39,900
pearl regions to like mitigate dick to

00:04:37,409 --> 00:04:41,370
startup costs and merging parallel loops

00:04:39,900 --> 00:04:44,009
all of these things fall in that

00:04:41,370 --> 00:04:45,689
category the patches are under RIBA

00:04:44,009 --> 00:04:47,310
right now so you can take a look once

00:04:45,689 --> 00:04:49,039
they go in which should be in a week or

00:04:47,310 --> 00:04:51,539
two from now at least for these things

00:04:49,039 --> 00:04:53,099
you will be able to just like they will

00:04:51,539 --> 00:04:54,990
just run automatically like oh you're

00:04:53,099 --> 00:05:00,479
opening P code will just get that that's

00:04:54,990 --> 00:05:03,330
it target offloading we have right now

00:05:00,479 --> 00:05:05,159
in mainline LLVM support for three

00:05:03,330 --> 00:05:08,599
different offload targets so you can

00:05:05,159 --> 00:05:11,430
offload to your host here you're like

00:05:08,599 --> 00:05:13,110
hosted like accelerator multi-core which

00:05:11,430 --> 00:05:16,349
is roughly the same thing and you can

00:05:13,110 --> 00:05:18,210
offload to nvidia gpus we are in the

00:05:16,349 --> 00:05:21,210
process of restructuring the device

00:05:18,210 --> 00:05:22,800
runtime library such that it's easier to

00:05:21,210 --> 00:05:25,979
add more targets for example a host

00:05:22,800 --> 00:05:28,229
target and AMD is doing a lot of that

00:05:25,979 --> 00:05:30,240
heavy lifting and we should get there

00:05:28,229 --> 00:05:33,449
that we this year can offload to AMD

00:05:30,240 --> 00:05:35,190
with LLVM clang mainline there's already

00:05:33,449 --> 00:05:37,469
open source versions that can do that

00:05:35,190 --> 00:05:40,650
but merge everything in and offload to

00:05:37,469 --> 00:05:43,770
AMD we have support for math functions

00:05:40,650 --> 00:05:46,229
in your target regions like the actual

00:05:43,770 --> 00:05:49,770
and Vidya math like intrinsics and

00:05:46,229 --> 00:05:52,529
implementations will work also other

00:05:49,770 --> 00:05:53,879
kind of target specific code will work

00:05:52,529 --> 00:05:55,830
like you could basically write CUDA

00:05:53,879 --> 00:05:59,099
inside a target region that goes onto an

00:05:55,830 --> 00:06:03,150
Nvidia device that will roughly work in

00:05:59,099 --> 00:06:05,219
clang but there is a caveat here that is

00:06:03,150 --> 00:06:09,360
the way we enabled the math function

00:06:05,219 --> 00:06:10,800
support caused as a problem we regard

00:06:09,360 --> 00:06:12,900
like some math fractions will work and

00:06:10,800 --> 00:06:14,279
sometimes you run into really complex

00:06:12,900 --> 00:06:16,830
errors that you have looked manually

00:06:14,279 --> 00:06:18,569
declare symbols or not it's it's a

00:06:16,830 --> 00:06:20,250
little weird and it will be fixed as

00:06:18,569 --> 00:06:22,500
soon as we implement one of the tr-8

00:06:20,250 --> 00:06:24,779
features so we got it into tr-8 which

00:06:22,500 --> 00:06:26,699
will be 5.1 standard and one of those

00:06:24,779 --> 00:06:28,440
features we need to actually implement

00:06:26,699 --> 00:06:29,580
the open MP implementation for math

00:06:28,440 --> 00:06:32,130
function so

00:06:29,580 --> 00:06:34,530
I would go that way took us a little bit

00:06:32,130 --> 00:06:35,760
longer but that will happen static

00:06:34,530 --> 00:06:38,400
linking is a little bit problematic

00:06:35,760 --> 00:06:42,240
still we're working on that actively to

00:06:38,400 --> 00:06:44,520
do static linking Multi multi target FET

00:06:42,240 --> 00:06:48,570
binaries in all of these all of these

00:06:44,520 --> 00:06:52,470
fancy things okay okay

00:06:48,570 --> 00:06:54,530
so Fortran the fan favorite of favorite

00:06:52,470 --> 00:06:59,610
here right that is if the Fortran kraut

00:06:54,530 --> 00:07:02,550
so we'll have new flank currently still

00:06:59,610 --> 00:07:04,170
known as f-18 or at least the repository

00:07:02,550 --> 00:07:07,320
lives in this Court is a Sigma is known

00:07:04,170 --> 00:07:10,680
as named f-18 and that will become new

00:07:07,320 --> 00:07:14,460
flank or flank once we move which should

00:07:10,680 --> 00:07:16,800
happen in a month let's assume it

00:07:14,460 --> 00:07:20,250
happens in a month this year we move

00:07:16,800 --> 00:07:23,490
f-18 into the LLVM owner repository call

00:07:20,250 --> 00:07:24,810
it flank and then old flame legacy fling

00:07:23,490 --> 00:07:26,820
is all but dead

00:07:24,810 --> 00:07:28,590
it's already all but dead so you can use

00:07:26,820 --> 00:07:30,720
it to a float you can use it for openmp

00:07:28,590 --> 00:07:33,570
but there is little to no support

00:07:30,720 --> 00:07:35,070
anymore for work going forward like

00:07:33,570 --> 00:07:37,500
development basically has completely

00:07:35,070 --> 00:07:40,070
moved to Aventine and everyone involved

00:07:37,500 --> 00:07:42,300
is actually actively looking into f-18

00:07:40,070 --> 00:07:44,970
there's a little bit over simplified but

00:07:42,300 --> 00:07:47,310
roughly gives you the gist what we do is

00:07:44,970 --> 00:07:48,480
we have parsing support for OpenMP are

00:07:47,310 --> 00:07:51,390
basically done

00:07:48,480 --> 00:07:52,740
we have semantic analysis like the

00:07:51,390 --> 00:07:54,510
beginnings of semantic analysis for

00:07:52,740 --> 00:07:57,510
OpenMP but there's a lot of work to do

00:07:54,510 --> 00:07:59,460
in that in that area and what we what we

00:07:57,510 --> 00:08:01,380
decided to do when we started to do is

00:07:59,460 --> 00:08:03,720
we ripped out a cogeneration out of

00:08:01,380 --> 00:08:05,790
clang and put it in a different place

00:08:03,720 --> 00:08:08,460
such that we can reuse it the openmp

00:08:05,790 --> 00:08:10,680
cogeneration such that once we get to

00:08:08,460 --> 00:08:13,680
semantic analysis up and running we

00:08:10,680 --> 00:08:15,750
basically can get cogeneration actually

00:08:13,680 --> 00:08:17,790
working code way faster because we will

00:08:15,750 --> 00:08:21,030
we will reuse all the infrastructure

00:08:17,790 --> 00:08:23,040
that is there ok so we will have target

00:08:21,030 --> 00:08:25,920
offloading like I don't like only a

00:08:23,040 --> 00:08:30,960
short period after after we start to

00:08:25,920 --> 00:08:33,030
have semi fire how we do that with

00:08:30,960 --> 00:08:35,010
birthday or the ripping the cogeneration

00:08:33,030 --> 00:08:37,220
out and reusing it between different

00:08:35,010 --> 00:08:40,020
front ends it's the open and prr builder

00:08:37,220 --> 00:08:42,460
for the lack of a better name

00:08:40,020 --> 00:08:45,010
you will task it to build you ela VMI or

00:08:42,460 --> 00:08:48,160
for directive let's say I want LOV Maya

00:08:45,010 --> 00:08:50,620
for parallel or Perla for or task or a

00:08:48,160 --> 00:08:51,850
target and it does this for you so you

00:08:50,620 --> 00:08:53,470
don't need to care how that actually

00:08:51,850 --> 00:08:55,990
looks what run time calls are involved

00:08:53,470 --> 00:08:58,540
we can change them easily without you

00:08:55,990 --> 00:09:00,160
ever noticing and it can be used by

00:08:58,540 --> 00:09:02,530
other front ends as well so even if you

00:09:00,160 --> 00:09:04,750
just want to use the open MP runtime and

00:09:02,530 --> 00:09:07,540
for offloading purposes out of your

00:09:04,750 --> 00:09:09,190
language that is not C C++ or Fortran

00:09:07,540 --> 00:09:10,600
you could do that if you have an

00:09:09,190 --> 00:09:12,760
automatic parallelizing and you want to

00:09:10,600 --> 00:09:14,380
go for the open and P like go to the

00:09:12,760 --> 00:09:16,380
open if you run time you could do that

00:09:14,380 --> 00:09:19,690
so you now have like a very nice

00:09:16,380 --> 00:09:21,700
functionality and a nice API based on

00:09:19,690 --> 00:09:23,860
the directives of opening P inside the

00:09:21,700 --> 00:09:27,700
compiler that can be reused by different

00:09:23,860 --> 00:09:29,530
by different players here we have

00:09:27,700 --> 00:09:31,180
patches that are accepted and will be

00:09:29,530 --> 00:09:33,310
merged we have some patches that are

00:09:31,180 --> 00:09:34,570
under review and obviously there is now

00:09:33,310 --> 00:09:36,250
a lot of work to do because we have to

00:09:34,570 --> 00:09:41,080
rip out every single Co generate

00:09:36,250 --> 00:09:43,690
cogeneration part I mentioned this

00:09:41,080 --> 00:09:46,380
briefly earlier AMT is doing a redesign

00:09:43,690 --> 00:09:50,950
of the device runtime library mostly AMD

00:09:46,380 --> 00:09:53,320
what's happening is we want to have a

00:09:50,950 --> 00:09:55,360
common core of the logic of the device

00:09:53,320 --> 00:09:57,910
runtime library that is basically C++

00:09:55,360 --> 00:09:59,530
code roughly every and like you

00:09:57,910 --> 00:10:01,120
interpret it as CUDA if you want to but

00:09:59,530 --> 00:10:02,830
it's roughly C++ code and there's to

00:10:01,120 --> 00:10:04,660
target specific parts that live

00:10:02,830 --> 00:10:06,220
somewhere else if you if you add a new

00:10:04,660 --> 00:10:07,930
target you just like kind of fill out

00:10:06,220 --> 00:10:10,660
this these functions and you're you're

00:10:07,930 --> 00:10:12,820
up and running so it's it should allow

00:10:10,660 --> 00:10:16,090
us to get us AMD fast in afterwards

00:10:12,820 --> 00:10:18,130
other GPU vendors for sure and then

00:10:16,090 --> 00:10:20,500
other than GPUs we have to look and see

00:10:18,130 --> 00:10:21,970
what how to reuse between non GPU

00:10:20,500 --> 00:10:26,100
targets interview targets will look like

00:10:21,970 --> 00:10:28,630
mostly now is everything is kind of

00:10:26,100 --> 00:10:30,640
while we do this we will actually also

00:10:28,630 --> 00:10:32,640
change the API on that layer or at least

00:10:30,640 --> 00:10:34,780
layer it and add like more abstraction

00:10:32,640 --> 00:10:36,700
abstractions on it to get better

00:10:34,780 --> 00:10:38,230
optimizations there and help the

00:10:36,700 --> 00:10:46,090
optimizes to actually change your

00:10:38,230 --> 00:10:47,740
offloading code yeah that was there was

00:10:46,090 --> 00:10:50,350
the last of them so those are all the

00:10:47,740 --> 00:10:52,270
kind of different areas that are

00:10:50,350 --> 00:10:54,300
currently under active development if

00:10:52,270 --> 00:10:59,700
you have any questions on them

00:10:54,300 --> 00:11:02,580
sure you mentioned that you want to

00:10:59,700 --> 00:11:04,470
create a kind of device offload for the

00:11:02,580 --> 00:11:06,360
host to use the sanitizers and that

00:11:04,470 --> 00:11:09,140
stuff will that be a separate memory to

00:11:06,360 --> 00:11:12,300
space was running as a separate process

00:11:09,140 --> 00:11:14,130
or are you going to share memory because

00:11:12,300 --> 00:11:16,170
that way you I think

00:11:14,130 --> 00:11:22,650
lose a lot of the capabilities that you

00:11:16,170 --> 00:11:23,910
could get I can't I can't I can tell you

00:11:22,650 --> 00:11:25,710
for sure because we haven't started to

00:11:23,910 --> 00:11:27,690
do that yet so I know one person that

00:11:25,710 --> 00:11:32,520
looked into doing that after we had the

00:11:27,690 --> 00:11:34,470
idea but I'm I don't have details on how

00:11:32,520 --> 00:11:36,150
it will look like I would not have

00:11:34,470 --> 00:11:37,890
thought that we need to do to share

00:11:36,150 --> 00:11:39,390
elected to different memory spaces I

00:11:37,890 --> 00:11:41,040
would have thought it would be fine if

00:11:39,390 --> 00:11:43,590
just like you sanitize the whole

00:11:41,040 --> 00:11:45,330
application including the runtime like

00:11:43,590 --> 00:11:47,400
we do that at least for testing purposes

00:11:45,330 --> 00:11:49,230
like people would not necessarily do

00:11:47,400 --> 00:11:51,060
that but like for our stress test and we

00:11:49,230 --> 00:11:52,560
could ever build on see I built that

00:11:51,060 --> 00:11:54,570
does that where threat sanitizers are

00:11:52,560 --> 00:12:00,210
enabled and then we catch all these

00:11:54,570 --> 00:12:06,200
nasty bugs where we do stuff our other

00:12:00,210 --> 00:12:06,200

YouTube URL: https://www.youtube.com/watch?v=6yOa-hRi63M


