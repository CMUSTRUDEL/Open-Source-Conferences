Title: OpenMP in ARM Forge - Nick Forrington - SC19
Publication date: 2019-11-25
Playlist: SC19 OpenMP Booth Talks
Description: 
	SC19 - 20 November 2019 Denver
Captions: 
	00:00:03,170 --> 00:00:10,019
okay thank you all for coming

00:00:06,930 --> 00:00:12,809
my name is Nick Farrington I'm in the

00:00:10,019 --> 00:00:14,370
pro services team at arm I'm based at

00:00:12,809 --> 00:00:17,779
Oak Ridge National Lab we'll give you a

00:00:14,370 --> 00:00:24,090
very brief introduction to arm Forge our

00:00:17,779 --> 00:00:27,510
cross-platform development tools so just

00:00:24,090 --> 00:00:29,340
to put this into context arm provide the

00:00:27,510 --> 00:00:32,309
following for there arm architecture

00:00:29,340 --> 00:00:34,710
support so as part of this we have arm

00:00:32,309 --> 00:00:36,660
Forge cross-platform tools which I'll be

00:00:34,710 --> 00:00:38,670
talking about more but in addition to

00:00:36,660 --> 00:00:41,129
that on the ARM architecture we also

00:00:38,670 --> 00:00:43,469
have the the arm compiler for Linux and

00:00:41,129 --> 00:00:46,200
that's bundled with performance

00:00:43,469 --> 00:00:50,579
libraries doing accelerate things like

00:00:46,200 --> 00:00:50,940
la pack blast functions FFTs and things

00:00:50,579 --> 00:00:53,219
like that

00:00:50,940 --> 00:00:54,690
and so on the arm platform these are

00:00:53,219 --> 00:01:01,590
bundled together into what we call the

00:00:54,690 --> 00:01:03,690
arma linear studio but as I said today

00:01:01,590 --> 00:01:07,320
we're focusing solely on the cross

00:01:03,690 --> 00:01:09,330
platform tools so we have arm Forge this

00:01:07,320 --> 00:01:13,500
is the de facto standard on a lot of the

00:01:09,330 --> 00:01:15,479
large HPC sites so where I'm based at at

00:01:13,500 --> 00:01:17,939
Oakridge we have this on the summit

00:01:15,479 --> 00:01:19,970
machine it's very scalable this will

00:01:17,939 --> 00:01:23,119
scale up to the full size of the machine

00:01:19,970 --> 00:01:28,200
I let you profile and debug your

00:01:23,119 --> 00:01:31,229
applications in addition to being

00:01:28,200 --> 00:01:34,350
scalable in terms of the size and speed

00:01:31,229 --> 00:01:37,320
we leverage a tree based architecture so

00:01:34,350 --> 00:01:40,799
this allows us to execute quickly and

00:01:37,320 --> 00:01:43,740
also to aggregate data scale ibly as we

00:01:40,799 --> 00:01:46,710
as we move that up to present presented

00:01:43,740 --> 00:01:48,540
in the graphical user interface we

00:01:46,710 --> 00:01:51,240
support a number of different parallel

00:01:48,540 --> 00:01:53,100
programming paradigms so OpenMP

00:01:51,240 --> 00:01:56,570
obviously one of them we also do MPI

00:01:53,100 --> 00:01:59,250
CUDA various others as well and

00:01:56,570 --> 00:02:01,920
crucially we also support HPC workflows

00:01:59,250 --> 00:02:04,200
so we have a remote client that will

00:02:01,920 --> 00:02:06,360
help you connect to a remote system so

00:02:04,200 --> 00:02:09,280
you don't need to rely on x11 forwarding

00:02:06,360 --> 00:02:12,040
which can be very slow when your remote

00:02:09,280 --> 00:02:15,010
and we also support running inside batch

00:02:12,040 --> 00:02:16,990
systems and so this works both profiling

00:02:15,010 --> 00:02:23,140
as you might expect but also we have an

00:02:16,990 --> 00:02:25,330
offline mode for debugging as well so

00:02:23,140 --> 00:02:27,040
just a quick overview of what's new in

00:02:25,330 --> 00:02:31,170
the last couple of releases with forge

00:02:27,040 --> 00:02:33,370
so 19.1 is the one that's out right now

00:02:31,170 --> 00:02:35,800
20.0 will be out at the end of this week

00:02:33,370 --> 00:02:37,090
for the supercomputing release so a few

00:02:35,800 --> 00:02:39,010
of the features we've got there

00:02:37,090 --> 00:02:42,310
Python profiling was added recently to

00:02:39,010 --> 00:02:44,440
map we've added support for Lawrence

00:02:42,310 --> 00:02:46,540
Livermore caliper projects so we can add

00:02:44,440 --> 00:02:50,739
those regions to be displayed in map as

00:02:46,540 --> 00:02:53,280
well memory debugging features and DVT

00:02:50,739 --> 00:02:56,260
have been enhanced to cover NVRAM and

00:02:53,280 --> 00:02:59,110
the baked item for supercomputing this

00:02:56,260 --> 00:03:01,060
this show is the cooter on arm support

00:02:59,110 --> 00:03:02,410
so Nvidia just announced they're

00:03:01,060 --> 00:03:05,590
bringing their stack over to the arm

00:03:02,410 --> 00:03:09,340
platform and so our tools are now ready

00:03:05,590 --> 00:03:11,200
to support that the picture on the right

00:03:09,340 --> 00:03:13,840
there is an image of our configurable

00:03:11,200 --> 00:03:16,840
metrics feature which is new in map so

00:03:13,840 --> 00:03:20,049
you can choose individual Linux perf

00:03:16,840 --> 00:03:22,090
metrics to profile along with the rest

00:03:20,049 --> 00:03:26,430
of your application and we've also added

00:03:22,090 --> 00:03:26,430
an assembly view to DBT

00:03:27,550 --> 00:03:35,380
so I'll start out with a very quick

00:03:29,380 --> 00:03:36,940
overview of DVT a quick yeah a quick

00:03:35,380 --> 00:03:38,650
display of how you prepare your

00:03:36,940 --> 00:03:42,040
application essentially you compile with

00:03:38,650 --> 00:03:43,810
debug info disable optimizations to stop

00:03:42,040 --> 00:03:46,270
your application jumping around too much

00:03:43,810 --> 00:03:47,650
and we aim to make this as easy to

00:03:46,270 --> 00:03:49,840
launch as possible so a couple of

00:03:47,650 --> 00:03:52,150
example command lines there we can do

00:03:49,840 --> 00:03:54,070
DVT connect which will actually launch

00:03:52,150 --> 00:03:55,240
from inside a batch system and connect

00:03:54,070 --> 00:03:57,340
to an external GUI

00:03:55,240 --> 00:03:59,380
that you've already connected so that's

00:03:57,340 --> 00:04:01,210
our remote client and that will pop up a

00:03:59,380 --> 00:04:03,250
little a little box like you see in the

00:04:01,210 --> 00:04:05,110
top right there which tells you that a

00:04:03,250 --> 00:04:06,970
request is available you can click

00:04:05,110 --> 00:04:09,730
accept there and that will connect the

00:04:06,970 --> 00:04:11,860
batch system into your GUI and at the

00:04:09,730 --> 00:04:14,290
bottom here is an offline an offline

00:04:11,860 --> 00:04:16,390
view which is running near the full

00:04:14,290 --> 00:04:19,420
scale of Summit so that's about 25,000

00:04:16,390 --> 00:04:20,860
threats there this was 4096 nodes so

00:04:19,420 --> 00:04:22,300
this is something that obviously takes a

00:04:20,860 --> 00:04:24,610
while to go through the batch system and

00:04:22,300 --> 00:04:26,470
so it's nice to be able to do that kind

00:04:24,610 --> 00:04:27,940
of debugging non interactively rather

00:04:26,470 --> 00:04:30,040
than having to be sat in front of the

00:04:27,940 --> 00:04:35,890
the computer when when the batch system

00:04:30,040 --> 00:04:38,620
fulfills your job so his is essentially

00:04:35,890 --> 00:04:40,840
a screenshot of the DDT session once

00:04:38,620 --> 00:04:42,820
it's launched you can see up in the top

00:04:40,840 --> 00:04:44,650
left here the blue bar represents the

00:04:42,820 --> 00:04:48,340
current process group so in this case we

00:04:44,650 --> 00:04:51,490
have four processes just above that we

00:04:48,340 --> 00:04:53,920
can see what the current focus is so at

00:04:51,490 --> 00:04:56,140
the minute we have focus on group so

00:04:53,920 --> 00:04:58,420
most actions that you perform will apply

00:04:56,140 --> 00:05:00,370
to the whole process group and you can

00:04:58,420 --> 00:05:02,130
also switch that to focusing on an

00:05:00,370 --> 00:05:04,390
individual process so again only

00:05:02,130 --> 00:05:05,650
focusing on an individual process and

00:05:04,390 --> 00:05:07,240
you can also drill down to the thread

00:05:05,650 --> 00:05:10,870
level where you control one thread in

00:05:07,240 --> 00:05:13,120
isolation so as well as affecting things

00:05:10,870 --> 00:05:15,370
like step operations and adding

00:05:13,120 --> 00:05:17,080
breakpoints and things like that and we

00:05:15,370 --> 00:05:18,850
can also see this reflected in the

00:05:17,080 --> 00:05:22,570
parallel stack view which is in the

00:05:18,850 --> 00:05:24,130
bottom left here so as I mentioned the

00:05:22,570 --> 00:05:26,800
tree earlier there and the data

00:05:24,130 --> 00:05:28,300
aggregation so we when we collect snacks

00:05:26,800 --> 00:05:30,220
are all of the individual processes we

00:05:28,300 --> 00:05:32,290
merge these going up the tree and so in

00:05:30,220 --> 00:05:33,820
this case we can kind of see a tree like

00:05:32,290 --> 00:05:35,590
stack view where on the Left we have

00:05:33,820 --> 00:05:37,720
counts of individual processes and

00:05:35,590 --> 00:05:40,060
threads that

00:05:37,720 --> 00:05:41,830
at this particular line of code we can

00:05:40,060 --> 00:05:43,840
also see over on the right we have local

00:05:41,830 --> 00:05:46,630
variables so as well as displaying the

00:05:43,840 --> 00:05:49,480
values for the current thread we also

00:05:46,630 --> 00:05:51,390
have individual highlighting there so

00:05:49,480 --> 00:05:53,890
the green in this case represents a

00:05:51,390 --> 00:05:55,540
value is not the same across all

00:05:53,890 --> 00:05:57,700
processes so that's something that we

00:05:55,540 --> 00:05:59,140
just collect automatically to kind of

00:05:57,700 --> 00:06:01,570
point out to the user in case that's

00:05:59,140 --> 00:06:03,850
relevant for them you can also see these

00:06:01,570 --> 00:06:05,350
little little graphs or little graphics

00:06:03,850 --> 00:06:08,100
next to all the variables that's

00:06:05,350 --> 00:06:11,140
essentially a little graph of the values

00:06:08,100 --> 00:06:12,700
of all of the vary the value of the

00:06:11,140 --> 00:06:15,340
variable across all of the individual

00:06:12,700 --> 00:06:20,560
either processes or threads depending on

00:06:15,340 --> 00:06:21,970
how that's configured so if I step that

00:06:20,560 --> 00:06:23,800
on one this is essentially what the same

00:06:21,970 --> 00:06:25,570
view looks like if I focus on an

00:06:23,800 --> 00:06:27,850
individual process I can see all of my

00:06:25,570 --> 00:06:31,000
individual threads now in the top left

00:06:27,850 --> 00:06:32,590
and then also in stacks view we can now

00:06:31,000 --> 00:06:34,450
see that this is also filtered down to

00:06:32,590 --> 00:06:36,840
display only threads from the current

00:06:34,450 --> 00:06:36,840
process

00:06:40,550 --> 00:06:46,360
and then also focusing on threats as

00:06:43,310 --> 00:06:48,830
well so we also have an ability to

00:06:46,360 --> 00:06:50,930
compare values across individual

00:06:48,830 --> 00:06:52,940
processes or threads so in this case

00:06:50,930 --> 00:06:55,150
this is essentially a version of the

00:06:52,940 --> 00:06:57,620
last screenshot where I've stepped one

00:06:55,150 --> 00:06:59,810
one of the individual threads past a

00:06:57,620 --> 00:07:01,370
point where this W variable is

00:06:59,810 --> 00:07:05,330
initialized and so now we can see at a

00:07:01,370 --> 00:07:06,530
glance that thread 1 has a nonzero value

00:07:05,330 --> 00:07:09,970
for this whereas all the other threads

00:07:06,530 --> 00:07:09,970
still so have a zero value

00:07:13,719 --> 00:07:21,669
so I'm going to move on quickly to map

00:07:16,239 --> 00:07:24,219
now so maps maps a sample-based

00:07:21,669 --> 00:07:26,469
profiling so that enables us to keep the

00:07:24,219 --> 00:07:28,360
overhead low the sampling rate is

00:07:26,469 --> 00:07:29,229
adaptive as well so for particularly

00:07:28,360 --> 00:07:32,559
long-running jobs

00:07:29,229 --> 00:07:34,479
essentially the sampling rate will be

00:07:32,559 --> 00:07:37,329
the sampling interval will be increased

00:07:34,479 --> 00:07:38,769
so we collect we can like less data as

00:07:37,329 --> 00:07:41,110
the job goes on and we kind of

00:07:38,769 --> 00:07:42,309
consolidate this data as well so the

00:07:41,110 --> 00:07:43,899
idea is that your profile will be

00:07:42,309 --> 00:07:45,669
roughly the same size no matter how long

00:07:43,899 --> 00:07:47,889
your job is so you don't have to worry

00:07:45,669 --> 00:07:50,619
about things like exhausting the file

00:07:47,889 --> 00:07:54,219
system or you know excessive overhead as

00:07:50,619 --> 00:07:56,439
you have longer jobs we aim for this to

00:07:54,219 --> 00:07:59,559
be easy to set up as well so this is a

00:07:56,439 --> 00:08:01,479
case of adding - G - to your program

00:07:59,559 --> 00:08:03,249
before you profile there's no compiler

00:08:01,479 --> 00:08:05,979
wrappers or any kind of instrumentation

00:08:03,249 --> 00:08:07,479
or anything like that to do and there's

00:08:05,979 --> 00:08:11,199
a quick example there of how you might

00:08:07,479 --> 00:08:12,909
collect a profile there with ten open MP

00:08:11,199 --> 00:08:16,059
threats and integrating with your

00:08:12,909 --> 00:08:18,369
existing MPI launch and again using the

00:08:16,059 --> 00:08:21,639
the remote client that that we mentioned

00:08:18,369 --> 00:08:25,479
before you can display that within you

00:08:21,639 --> 00:08:27,969
know within your laptop so here's a

00:08:25,479 --> 00:08:29,319
quick look at what IMAP profile looks

00:08:27,969 --> 00:08:31,929
like you can see along the top where we

00:08:29,319 --> 00:08:34,479
have the application activity going left

00:08:31,929 --> 00:08:35,729
to right is time in your program and

00:08:34,479 --> 00:08:41,769
then vertically is the number of

00:08:35,729 --> 00:08:43,300
processing elements you have so so we

00:08:41,769 --> 00:08:45,220
can see the different colors represent

00:08:43,300 --> 00:08:47,529
different types of activities so these

00:08:45,220 --> 00:08:50,379
can be seen and this kind of key along

00:08:47,529 --> 00:08:52,059
the bottom here so in this case the

00:08:50,379 --> 00:08:59,079
average of all of these is we have about

00:08:52,059 --> 00:09:01,120
50% OpenMP we have around 17% MPI we

00:08:59,079 --> 00:09:04,480
have we're displaying file i/o there as

00:09:01,120 --> 00:09:06,550
well and potentially interesting for

00:09:04,480 --> 00:09:08,410
OpenMP as well as we display OpenMP

00:09:06,550 --> 00:09:10,540
overhead so that's essentially the

00:09:08,410 --> 00:09:12,610
amount of time where and threads are

00:09:10,540 --> 00:09:16,059
waiting for other threads to finish an

00:09:12,610 --> 00:09:17,290
open MP region so so this can this can

00:09:16,059 --> 00:09:18,879
potentially indicate some kind of

00:09:17,290 --> 00:09:23,110
workload in balance or something like

00:09:18,879 --> 00:09:25,329
that below that we can see metric graphs

00:09:23,110 --> 00:09:26,680
so you can actually toggle these out for

00:09:25,329 --> 00:09:28,870
different metrics at the minute

00:09:26,680 --> 00:09:31,120
showing cycles per instruction and how

00:09:28,870 --> 00:09:33,010
that varies across the job and also

00:09:31,120 --> 00:09:35,320
memory usage and so these a granade

00:09:33,010 --> 00:09:39,100
across all of your processing elements

00:09:35,320 --> 00:09:40,510
so this could be processes or threads we

00:09:39,100 --> 00:09:42,910
have the source code view in the middle

00:09:40,510 --> 00:09:44,920
here and you can see kind of in the

00:09:42,910 --> 00:09:47,620
left-hand side of the of the source view

00:09:44,920 --> 00:09:49,240
there's kind of a decomposed version of

00:09:47,620 --> 00:09:51,310
the activity timeline up there so this

00:09:49,240 --> 00:09:53,830
is the activity timeline as it applies

00:09:51,310 --> 00:09:55,959
just to this line of code and you can

00:09:53,830 --> 00:09:57,820
also do things like if you collapse a

00:09:55,959 --> 00:10:00,310
particular loop here then you will see

00:09:57,820 --> 00:10:02,399
that that graphic update apply to the

00:10:00,310 --> 00:10:05,680
whole loop so this can be useful and

00:10:02,399 --> 00:10:06,910
then the parallel stack view at the

00:10:05,680 --> 00:10:08,800
bottom here this shows kind of your

00:10:06,910 --> 00:10:10,570
profile where your applications spending

00:10:08,800 --> 00:10:12,640
all of its time in this case we've got

00:10:10,570 --> 00:10:14,830
most of most of the time spent in

00:10:12,640 --> 00:10:16,480
perform time step if we were to expand

00:10:14,830 --> 00:10:18,790
this year we'd be able to drill down and

00:10:16,480 --> 00:10:20,260
see a little bit more detail there we

00:10:18,790 --> 00:10:21,820
can also see in this particular example

00:10:20,260 --> 00:10:24,370
that we're spending about 20% at the

00:10:21,820 --> 00:10:26,470
time in in an output function and we can

00:10:24,370 --> 00:10:28,570
also see the decomposed activity there

00:10:26,470 --> 00:10:31,420
so we can see within output we've got a

00:10:28,570 --> 00:10:34,540
lot of MPI communication various little

00:10:31,420 --> 00:10:36,820
bits of i/o in there as well and so as a

00:10:34,540 --> 00:10:38,110
very kind of first step into looking at

00:10:36,820 --> 00:10:40,000
this profile you might want to wonder

00:10:38,110 --> 00:10:42,130
why why this particular application is

00:10:40,000 --> 00:10:45,640
spending about 20% of its time just just

00:10:42,130 --> 00:10:47,410
outputting data so yeah a good next step

00:10:45,640 --> 00:10:49,450
here would be to expand that down and

00:10:47,410 --> 00:10:51,839
dig into exactly what's going on within

00:10:49,450 --> 00:10:51,839
that function

00:10:54,720 --> 00:10:59,700
so here's just yeah kind of a zoomed in

00:10:57,360 --> 00:11:02,910
version of that you can see again these

00:10:59,700 --> 00:11:04,860
these activity timelines are all or all

00:11:02,910 --> 00:11:07,560
kind of decomposed here as well as

00:11:04,860 --> 00:11:09,390
viewing applications by snack for OpenMP

00:11:07,560 --> 00:11:12,450
as well we also identify individual

00:11:09,390 --> 00:11:15,570
OpenMP regions so you can expand in the

00:11:12,450 --> 00:11:17,130
same way by a by these regions again we

00:11:15,570 --> 00:11:18,710
have the activity here we can see inside

00:11:17,130 --> 00:11:21,570
the OpenMP regions we have a lot more

00:11:18,710 --> 00:11:24,720
green which represents compute rather

00:11:21,570 --> 00:11:28,350
than some of the MPI in the in the other

00:11:24,720 --> 00:11:30,240
views we can see the name of the OpenMP

00:11:28,350 --> 00:11:32,580
region here as well this is this is

00:11:30,240 --> 00:11:34,320
generated by the compiler so you know

00:11:32,580 --> 00:11:35,640
the name there can vary and we have a

00:11:34,320 --> 00:11:42,930
little kind of preview of what the

00:11:35,640 --> 00:11:45,720
source code looks like there as well so

00:11:42,930 --> 00:11:48,570
as we as we support openmp as well we

00:11:45,720 --> 00:11:50,580
support CUDA and so if you have a if you

00:11:48,570 --> 00:11:52,800
have an open MP offload compiler that

00:11:50,580 --> 00:11:55,710
generates CUDA kernels on NVIDIA

00:11:52,800 --> 00:11:58,200
hardware we can also display some GPU

00:11:55,710 --> 00:11:59,640
information there so you can see in the

00:11:58,200 --> 00:12:01,200
time line along the top now there's

00:11:59,640 --> 00:12:03,600
there's a lot more purple introduced

00:12:01,200 --> 00:12:04,950
which represents the time the CPU is

00:12:03,600 --> 00:12:08,640
waiting on the accelerator to do

00:12:04,950 --> 00:12:09,840
something so a lot of time in a lot of

00:12:08,640 --> 00:12:12,090
time in there kind of waiting for the

00:12:09,840 --> 00:12:15,210
accelerator again this filters down to

00:12:12,090 --> 00:12:17,400
the stacks view and an additional view

00:12:15,210 --> 00:12:18,570
we have four GPUs as well as the kernels

00:12:17,400 --> 00:12:18,930
view which we have in the bottom right

00:12:18,570 --> 00:12:21,300
there

00:12:18,930 --> 00:12:24,210
so similar to the openmp regions that we

00:12:21,300 --> 00:12:26,670
had before you can see compiler

00:12:24,210 --> 00:12:28,920
generated names there and on the left

00:12:26,670 --> 00:12:33,900
you can see time spent executing

00:12:28,920 --> 00:12:37,260
individual kernels and then quickly on

00:12:33,900 --> 00:12:40,050
to performance reports so performance

00:12:37,260 --> 00:12:41,730
reports you can create this directly as

00:12:40,050 --> 00:12:43,260
you would collect a map profile another

00:12:41,730 --> 00:12:45,030
interesting thing to do as well as you

00:12:43,260 --> 00:12:46,320
can take an existing map file and

00:12:45,030 --> 00:12:48,300
convert that over into performance

00:12:46,320 --> 00:12:50,190
reports well that aims to do is give you

00:12:48,300 --> 00:12:53,400
kind of a one-page report summary of

00:12:50,190 --> 00:12:55,530
your of your application and so you can

00:12:53,400 --> 00:12:57,390
see things like system load and GPU

00:12:55,530 --> 00:12:59,430
usage in here in this particular example

00:12:57,390 --> 00:13:03,540
this is a prompt report of the

00:12:59,430 --> 00:13:05,120
individual and the openmp run without

00:13:03,540 --> 00:13:06,960
GPUs that we were looking at before so

00:13:05,120 --> 00:13:08,590
where this is going to break it down

00:13:06,960 --> 00:13:11,590
telling us that we're spending this

00:13:08,590 --> 00:13:13,690
timon compute versus MPI and IO and then

00:13:11,590 --> 00:13:15,030
this is on the same report but if you

00:13:13,690 --> 00:13:17,080
were to scroll down you would see

00:13:15,030 --> 00:13:19,780
individual sections to have a little bit

00:13:17,080 --> 00:13:21,490
more information so from an open and P

00:13:19,780 --> 00:13:23,590
point of view of the the interesting

00:13:21,490 --> 00:13:25,870
sections here in the top left here we

00:13:23,590 --> 00:13:29,200
can see that 98% of the time is within

00:13:25,870 --> 00:13:31,660
some kind of open MP region we have

00:13:29,200 --> 00:13:34,350
different information on MPI IO things

00:13:31,660 --> 00:13:36,400
are that if we go into the open MP

00:13:34,350 --> 00:13:39,130
section as well we can see things like

00:13:36,400 --> 00:13:42,580
the breakdown of computation versus

00:13:39,130 --> 00:13:44,200
synchronization here so again this is

00:13:42,580 --> 00:13:46,900
the synchronization here this represents

00:13:44,200 --> 00:13:47,980
time where you know you have open MP

00:13:46,900 --> 00:13:49,930
threads that are essentially sitting

00:13:47,980 --> 00:13:51,880
idle waiting for for others to finish

00:13:49,930 --> 00:13:54,520
the regions and so a high number here

00:13:51,880 --> 00:13:55,960
will you know potentially indicate you

00:13:54,520 --> 00:13:58,870
might have some kind of workload in

00:13:55,960 --> 00:14:00,430
balance to to address and if you look at

00:13:58,870 --> 00:14:02,770
all the individual sections as well then

00:14:00,430 --> 00:14:03,850
that this includes kind of advice that

00:14:02,770 --> 00:14:07,800
you might want to follow to try and

00:14:03,850 --> 00:14:07,800
address some potential issues here so

00:14:08,910 --> 00:14:13,830
that's my very brief whirlwind tour of

00:14:11,830 --> 00:14:15,010
the different components of forge

00:14:13,830 --> 00:14:16,570
equiptment

00:14:15,010 --> 00:14:18,400
series at the booth if you want to find

00:14:16,570 --> 00:14:19,950
out more information if you go to the

00:14:18,400 --> 00:14:22,330
website there as well you can also grab

00:14:19,950 --> 00:14:24,190
grab like the remote clients grab an

00:14:22,330 --> 00:14:27,160
evaluation license to download something

00:14:24,190 --> 00:14:30,540
saw that so be happy to take any

00:14:27,160 --> 00:14:30,540

YouTube URL: https://www.youtube.com/watch?v=n28NnYD7C0Y


