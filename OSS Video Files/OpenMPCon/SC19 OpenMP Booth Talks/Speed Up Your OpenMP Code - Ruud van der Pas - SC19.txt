Title: Speed Up Your OpenMP Code - Ruud van der Pas - SC19
Publication date: 2019-11-25
Playlist: SC19 OpenMP Booth Talks
Description: 
	SC 19 - November 19, 2019 - Denver
Slides: https://www.openmp.org/wp-content/uploads/SC19-Ruud-SpeedUp.pdf
Captions: 
	00:00:00,120 --> 00:00:05,520
good afternoon welcome to this talk I'm

00:00:02,790 --> 00:00:10,050
glad you all showed up here to talk

00:00:05,520 --> 00:00:12,059
about easy ways to June open a pickle we

00:00:10,050 --> 00:00:13,650
all know if we spend enough time on

00:00:12,059 --> 00:00:15,450
something we can probably get some

00:00:13,650 --> 00:00:18,990
achievement here I'm going to look at

00:00:15,450 --> 00:00:20,939
what I call the locket one of my pet

00:00:18,990 --> 00:00:23,699
peeves is that people say OpenMP does

00:00:20,939 --> 00:00:25,560
not perform and my claim is you can get

00:00:23,699 --> 00:00:29,449
good performance out of pretty much any

00:00:25,560 --> 00:00:31,740
OpenMP program and your coat will scale

00:00:29,449 --> 00:00:34,920
but you have to do things in the right

00:00:31,740 --> 00:00:37,230
way and one of the things I recognize is

00:00:34,920 --> 00:00:38,879
not not everything has been documented

00:00:37,230 --> 00:00:41,129
very well so how could you know and

00:00:38,879 --> 00:00:43,200
that's why I made this talk to help

00:00:41,129 --> 00:00:46,469
clarify some of the performance

00:00:43,200 --> 00:00:49,350
mysteries that I see here is a very

00:00:46,469 --> 00:00:53,250
simple inequality the fact that a

00:00:49,350 --> 00:00:55,860
language is easy doesn't mean you can

00:00:53,250 --> 00:00:58,050
write stupid code when you write stupid

00:00:55,860 --> 00:00:59,430
code you'll probably get stupid

00:00:58,050 --> 00:01:01,680
performance maybe a little bit better

00:00:59,430 --> 00:01:03,359
than than that but not much because

00:01:01,680 --> 00:01:04,049
there's not much the compiler can do for

00:01:03,359 --> 00:01:05,880
you all right

00:01:04,049 --> 00:01:09,990
so that's what I'll go I'm going to talk

00:01:05,880 --> 00:01:13,380
about so definitely the ease of use of

00:01:09,990 --> 00:01:15,439
openmp is a mixed blessing it's quite

00:01:13,380 --> 00:01:18,360
easy to get your openmp up and running

00:01:15,439 --> 00:01:21,360
but then it won't scale maybe that's

00:01:18,360 --> 00:01:24,650
that's when things get hard so you have

00:01:21,360 --> 00:01:26,759
your prototype running very quickly

00:01:24,650 --> 00:01:28,619
implement your idea but maybe the

00:01:26,759 --> 00:01:32,100
performance is not as good as you

00:01:28,619 --> 00:01:34,979
expected it to be one of the things is

00:01:32,100 --> 00:01:36,720
what not everybody realizes is that some

00:01:34,979 --> 00:01:40,259
things are more expensive than others

00:01:36,720 --> 00:01:40,890
and you sort of have to know about that

00:01:40,259 --> 00:01:45,420
all right

00:01:40,890 --> 00:01:47,369
so and as I'll show a relatively small

00:01:45,420 --> 00:01:48,570
change can have quite a big impact and

00:01:47,369 --> 00:01:50,310
that's actually what you're looking for

00:01:48,570 --> 00:01:52,710
that's what I mean the low-hanging fruit

00:01:50,310 --> 00:01:55,170
you do get better performance with a

00:01:52,710 --> 00:01:59,280
small change oh yeah so that's again

00:01:55,170 --> 00:02:00,990
that's the focus of this talk so let's

00:01:59,280 --> 00:02:05,399
look at some of those things first of

00:02:00,990 --> 00:02:07,770
all never forget to tune your code for

00:02:05,399 --> 00:02:09,959
single thread performance very often

00:02:07,770 --> 00:02:11,700
that's ignored people think well I can

00:02:09,959 --> 00:02:13,860
skip it I'm interested in parallel

00:02:11,700 --> 00:02:16,500
computing but think about it

00:02:13,860 --> 00:02:19,080
okay what if your program doesn't run

00:02:16,500 --> 00:02:21,600
well on one core what do you think will

00:02:19,080 --> 00:02:24,510
happen on two or ten no 20 or under

00:02:21,600 --> 00:02:26,130
it'll get worse and there's there's a

00:02:24,510 --> 00:02:29,100
lot of theory behind that white it is

00:02:26,130 --> 00:02:31,770
but the bottom line is don't ignore

00:02:29,100 --> 00:02:33,990
single thread performance alright and

00:02:31,770 --> 00:02:36,840
another thing is don't be blinded by

00:02:33,990 --> 00:02:38,550
scalability it tends to be that if

00:02:36,840 --> 00:02:41,010
somebody only quotes scalability you

00:02:38,550 --> 00:02:44,870
have to be careful because slow code

00:02:41,010 --> 00:02:48,360
scale better in general so always ask

00:02:44,870 --> 00:02:50,220
for the time always ask well how long

00:02:48,360 --> 00:02:55,350
did this run take and I'll actually show

00:02:50,220 --> 00:02:58,500
you a little example of them I'm now

00:02:55,350 --> 00:02:59,970
going to go through a checklist and that

00:02:58,500 --> 00:03:02,700
may be obvious to you but I thought I'll

00:02:59,970 --> 00:03:04,290
just memorize it repeat it don't

00:03:02,700 --> 00:03:06,480
paralyze what doesn't matter

00:03:04,290 --> 00:03:08,130
I talked to too many users who just

00:03:06,480 --> 00:03:09,720
paralyzed every loop in their program

00:03:08,130 --> 00:03:12,870
that's not a good idea

00:03:09,720 --> 00:03:15,540
all right you need to use a profiling

00:03:12,870 --> 00:03:17,340
tool I don't care what you use

00:03:15,540 --> 00:03:20,160
there are several profiling tools out

00:03:17,340 --> 00:03:23,600
there they tell you where the time is

00:03:20,160 --> 00:03:27,330
spent and that's what you focus on

00:03:23,600 --> 00:03:29,700
another golden rule is although openmp

00:03:27,330 --> 00:03:32,280
is very easy with sharing data don't

00:03:29,700 --> 00:03:35,190
share data unless you have to be very

00:03:32,280 --> 00:03:37,950
careful only use private only you share

00:03:35,190 --> 00:03:41,030
data when you have to use private data

00:03:37,950 --> 00:03:44,040
as long as you can as much as you can

00:03:41,030 --> 00:03:46,950
another common thing I see often is

00:03:44,040 --> 00:03:50,070
multiple parallel force or parallel

00:03:46,950 --> 00:03:51,720
doing Fortran so what I say one is fine

00:03:50,070 --> 00:03:55,920
more is evil you know I'm going to show

00:03:51,720 --> 00:03:58,620
that with an example think big maximize

00:03:55,920 --> 00:04:00,420
the size of your parallel regions don't

00:03:58,620 --> 00:04:03,030
have all these tiny parallel regions

00:04:00,420 --> 00:04:05,910
because each each parallel region has

00:04:03,030 --> 00:04:08,430
overhead and that'll cost you

00:04:05,910 --> 00:04:10,200
performance seems simple but I see too

00:04:08,430 --> 00:04:13,890
many applications that violate that rule

00:04:10,200 --> 00:04:14,610
all right so here's an example of what I

00:04:13,890 --> 00:04:17,970
just said

00:04:14,610 --> 00:04:21,989
here I have one parallel for with a code

00:04:17,970 --> 00:04:24,900
block all right and I have all sequence

00:04:21,989 --> 00:04:27,450
of them and again I see that in too many

00:04:24,900 --> 00:04:27,750
applications well think about it this is

00:04:27,450 --> 00:04:30,720
a

00:04:27,750 --> 00:04:33,120
fully blown parallel region so you get

00:04:30,720 --> 00:04:34,890
all the overhead with that and there's a

00:04:33,120 --> 00:04:37,590
barrier at the end and barriers are

00:04:34,890 --> 00:04:39,870
expensive and they definitely impact

00:04:37,590 --> 00:04:42,600
your scalability so this is generally

00:04:39,870 --> 00:04:44,700
not a good solution but we don't we

00:04:42,600 --> 00:04:47,400
shouldn't to be doing that again the

00:04:44,700 --> 00:04:49,560
overhead is repeated and you can't use

00:04:47,400 --> 00:04:53,070
the opening P no weight cloths which i

00:04:49,560 --> 00:04:56,270
think is very useful instead what you do

00:04:53,070 --> 00:05:00,570
you set up one parallel region and

00:04:56,270 --> 00:05:04,140
within that just the own p4 it's exactly

00:05:00,570 --> 00:05:06,120
the same but faster and if relevant

00:05:04,140 --> 00:05:08,400
there's opportunities for the no wait

00:05:06,120 --> 00:05:09,960
cloths and certainly in no weight at the

00:05:08,400 --> 00:05:12,330
end because this one has an applied

00:05:09,960 --> 00:05:14,419
barrier already and you may wonder

00:05:12,330 --> 00:05:18,030
doesn't the compiler do that for you

00:05:14,419 --> 00:05:19,830
know that I know now technically a

00:05:18,030 --> 00:05:21,480
compiler could detect that and leave out

00:05:19,830 --> 00:05:22,050
the no way I don't think they go that

00:05:21,480 --> 00:05:24,630
far

00:05:22,050 --> 00:05:27,150
so do that yourself write it like this

00:05:24,630 --> 00:05:30,300
and you'll you'll immediately see better

00:05:27,150 --> 00:05:33,240
performance all right all right more

00:05:30,300 --> 00:05:35,430
basics again barriers are important you

00:05:33,240 --> 00:05:37,200
need them for correctness but use them

00:05:35,430 --> 00:05:40,680
with care don't sprinkle them all over

00:05:37,200 --> 00:05:42,720
your code just in case I've seen people

00:05:40,680 --> 00:05:45,479
looking you know sing sequential code

00:05:42,720 --> 00:05:48,479
with the barrier like no you don't need

00:05:45,479 --> 00:05:52,680
a same is true for locks and critical

00:05:48,479 --> 00:05:56,700
regions they are expensive ok you need

00:05:52,680 --> 00:05:58,790
them for correctness but be careful when

00:05:56,700 --> 00:06:01,410
to use them and how often to use them

00:05:58,790 --> 00:06:04,740
and really everything matters when you

00:06:01,410 --> 00:06:07,110
go for scalability Sam does law even the

00:06:04,740 --> 00:06:10,050
small things do matter so take that into

00:06:07,110 --> 00:06:13,140
account as well here's another example

00:06:10,050 --> 00:06:16,530
this is from a real code it's actually a

00:06:13,140 --> 00:06:18,660
benchmark code and I've sort of stripped

00:06:16,530 --> 00:06:21,240
it down a bit and what it is it's a

00:06:18,660 --> 00:06:24,990
single region and right after that a

00:06:21,240 --> 00:06:28,260
barrier I see some of you smile or even

00:06:24,990 --> 00:06:30,660
laugh yes that's really dumb code all

00:06:28,260 --> 00:06:33,300
right so we all we also know there's a

00:06:30,660 --> 00:06:35,490
barrier here so that barrier is

00:06:33,300 --> 00:06:37,650
redundant but it will still cost

00:06:35,490 --> 00:06:39,450
performance and admittedly it's fast

00:06:37,650 --> 00:06:41,879
because any waiting would have been done

00:06:39,450 --> 00:06:44,459
in this barrier the first one with

00:06:41,879 --> 00:06:47,550
again think about scalability it'll cost

00:06:44,459 --> 00:06:49,169
you cycles as you add threads that cost

00:06:47,550 --> 00:06:52,020
will go up as well the cost of the

00:06:49,169 --> 00:06:54,689
barrier will grow so bad idea very

00:06:52,020 --> 00:06:57,749
simple fix and this is really from a

00:06:54,689 --> 00:06:58,439
real-life benchmark I downloaded from a

00:06:57,749 --> 00:07:02,189
website

00:06:58,439 --> 00:07:03,899
I mean this is not made-up stuff so this

00:07:02,189 --> 00:07:05,459
is what I just said think about those

00:07:03,899 --> 00:07:07,740
those kind of opportunities it's

00:07:05,459 --> 00:07:09,389
absolutely low hang and you don't have

00:07:07,740 --> 00:07:13,169
to worry about correctness of your code

00:07:09,389 --> 00:07:15,029
that's that's guaranteed here's one more

00:07:13,169 --> 00:07:17,069
complex I'll spend a little bit more

00:07:15,029 --> 00:07:21,289
time on it again was from the same

00:07:17,069 --> 00:07:24,209
application an array value gets assigned

00:07:21,289 --> 00:07:27,259
that's that's called that index value

00:07:24,209 --> 00:07:30,449
end point then there's a parallel region

00:07:27,259 --> 00:07:35,639
inside that parallel region there's an

00:07:30,449 --> 00:07:38,309
own people okay and another one and some

00:07:35,639 --> 00:07:40,830
code now what's bad about this or

00:07:38,309 --> 00:07:44,249
potentially bad about this first of all

00:07:40,830 --> 00:07:46,740
two barriers both own people will end

00:07:44,249 --> 00:07:48,689
with a barrier I would think there's a

00:07:46,740 --> 00:07:50,789
no way to opportunity here for this one

00:07:48,689 --> 00:07:53,189
because this assignment is not not

00:07:50,789 --> 00:07:56,039
related but it's not there so the

00:07:53,189 --> 00:07:59,009
compiler will insert a barrier to get

00:07:56,039 --> 00:08:01,649
two barriers you have the cost of the

00:07:59,009 --> 00:08:05,189
infrastructure repeated twice though

00:08:01,649 --> 00:08:06,990
before goes through some logic so

00:08:05,189 --> 00:08:08,999
that'll cost you performance and the

00:08:06,990 --> 00:08:10,740
same for this one and each for loop

00:08:08,999 --> 00:08:14,159
always carries some overhead although

00:08:10,740 --> 00:08:17,159
minimal the worst thing on this example

00:08:14,159 --> 00:08:20,519
is that the value of endpoint

00:08:17,159 --> 00:08:22,409
what if endpoint is five you're going to

00:08:20,519 --> 00:08:24,389
paralyze the loop pipe long and then

00:08:22,409 --> 00:08:26,939
potentially this this value and it's is

00:08:24,389 --> 00:08:29,300
fairly high in general but this one

00:08:26,939 --> 00:08:33,419
could be really slow because endpoint is

00:08:29,300 --> 00:08:37,979
not big enough so this is not going to

00:08:33,419 --> 00:08:40,529
work very well the pics but is what I

00:08:37,979 --> 00:08:42,990
just said there are two barriers you get

00:08:40,529 --> 00:08:44,819
overhead and if the performance benefit

00:08:42,990 --> 00:08:47,009
depends on particular on endpoint and

00:08:44,819 --> 00:08:50,400
end but n is usually very large like

00:08:47,009 --> 00:08:53,970
these tens of thousands of element

00:08:50,400 --> 00:08:56,730
all right so when you see what they're

00:08:53,970 --> 00:09:01,650
trying to do is assign a value in that

00:08:56,730 --> 00:09:06,779
array then assign assigning the first

00:09:01,650 --> 00:09:08,490
part barrier second part barrier that

00:09:06,779 --> 00:09:11,550
does not look like a very smart

00:09:08,490 --> 00:09:15,480
implementation of just taking the whole

00:09:11,550 --> 00:09:18,060
array and assigning that value yeah

00:09:15,480 --> 00:09:19,410
that's I don't know how somebody can

00:09:18,060 --> 00:09:21,870
actually write code like that but it

00:09:19,410 --> 00:09:24,240
exists all right so the fix once you've

00:09:21,870 --> 00:09:26,910
seen this the pick is really easy you

00:09:24,240 --> 00:09:31,560
just assign the whole array to minus one

00:09:26,910 --> 00:09:33,690
and in a single with in no way you you

00:09:31,560 --> 00:09:35,310
fix that one value that was wrong but

00:09:33,690 --> 00:09:38,670
you know it was wrong you know where to

00:09:35,310 --> 00:09:40,980
fix it now this that the performance of

00:09:38,670 --> 00:09:43,020
this loop only depends on in I only have

00:09:40,980 --> 00:09:45,810
one barrier so all good things happen

00:09:43,020 --> 00:09:52,200
here again from an implementation point

00:09:45,810 --> 00:09:56,339
of view really simple to do so now let's

00:09:52,200 --> 00:10:00,660
look at a case study the application is

00:09:56,339 --> 00:10:03,000
the good-old graph 500 benchmark for a

00:10:00,660 --> 00:10:05,130
while there was a OpenMP version that's

00:10:03,000 --> 00:10:08,250
what to talk about the this base

00:10:05,130 --> 00:10:10,020
benchmark does the following it's a

00:10:08,250 --> 00:10:12,600
construction graph depending on your

00:10:10,020 --> 00:10:15,480
parameters it's an undirected graph of a

00:10:12,600 --> 00:10:18,450
specified size you specify the size then

00:10:15,480 --> 00:10:20,730
it will select the key and it will

00:10:18,450 --> 00:10:23,670
search for that key using a BFS search

00:10:20,730 --> 00:10:25,740
but then it will verify that the result

00:10:23,670 --> 00:10:29,010
is a tree and you do that with the next

00:10:25,740 --> 00:10:33,020
key and in total you do that was 64 and

00:10:29,010 --> 00:10:36,570
smart good that's that's the benchmark

00:10:33,020 --> 00:10:40,200
for the benchmark score put the list

00:10:36,570 --> 00:10:42,000
only the search time matters and the

00:10:40,200 --> 00:10:43,950
reason I selected this example is that's

00:10:42,000 --> 00:10:45,990
very typical in a real application you

00:10:43,950 --> 00:10:47,580
only want to follow one path you don't

00:10:45,990 --> 00:10:49,470
care about a lot of other things you

00:10:47,580 --> 00:10:51,300
want to optimize expecting so in this

00:10:49,470 --> 00:10:55,410
case we want to optimize the search time

00:10:51,300 --> 00:10:57,720
right so I have to describe how I ran

00:10:55,410 --> 00:11:02,730
this I the code takes a parameter called

00:10:57,720 --> 00:11:04,430
scale escaped at 224 that's a very small

00:11:02,730 --> 00:11:07,580
graph only nine gigabytes

00:11:04,430 --> 00:11:08,180
all right I ran that in our own Oracle

00:11:07,580 --> 00:11:11,510
cloud

00:11:08,180 --> 00:11:13,850
I used the sky Lake instance only eight

00:11:11,510 --> 00:11:16,490
cores and 16 threads so very small

00:11:13,850 --> 00:11:19,370
configuration but interesting enough as

00:11:16,490 --> 00:11:23,180
I hope to show to you I used our own

00:11:19,370 --> 00:11:25,190
Oracle Linux and the DCCC 8 compiler and

00:11:23,180 --> 00:11:26,810
I used our own performance tool to to

00:11:25,190 --> 00:11:28,880
make the profiles that I'm showing but

00:11:26,810 --> 00:11:31,640
again use whatever you whatever you

00:11:28,880 --> 00:11:34,970
prefer right here's what we call the

00:11:31,640 --> 00:11:38,529
time line the time is from the time is

00:11:34,970 --> 00:11:41,630
from left to right and each function

00:11:38,529 --> 00:11:44,300
here each snapshot here is the call

00:11:41,630 --> 00:11:46,850
stack of the code so we look at where

00:11:44,300 --> 00:11:48,529
you were in the program and normally

00:11:46,850 --> 00:11:51,589
each each function will get its own

00:11:48,529 --> 00:11:53,089
color but I grayed out everything I

00:11:51,589 --> 00:11:56,899
don't care about I only highlight the

00:11:53,089 --> 00:11:58,730
top the top-level functions so it gives

00:11:56,899 --> 00:11:59,930
me a feel for the dynamic behavior but

00:11:58,730 --> 00:12:03,620
underneath are these these other

00:11:59,930 --> 00:12:06,649
functions that are being called and this

00:12:03,620 --> 00:12:08,630
part is the graph generation this little

00:12:06,649 --> 00:12:10,850
kind of thing sticking out is a

00:12:08,630 --> 00:12:13,220
recursive sorting that's why it's the

00:12:10,850 --> 00:12:15,740
call call stack is quite deep all right

00:12:13,220 --> 00:12:19,370
and then then there's the search a

00:12:15,740 --> 00:12:22,850
verification place repeated 64 times in

00:12:19,370 --> 00:12:27,500
the next slides red is the search blue

00:12:22,850 --> 00:12:31,040
is the verification here's the initial

00:12:27,500 --> 00:12:33,110
performance and I'm showing the search

00:12:31,040 --> 00:12:34,760
time I don't care what the benchmark has

00:12:33,110 --> 00:12:37,040
a metric but I'd like to work with real

00:12:34,760 --> 00:12:40,220
time I mean this is real time how long

00:12:37,040 --> 00:12:40,670
the search takes the number of OpenMP

00:12:40,220 --> 00:12:43,339
threads

00:12:40,670 --> 00:12:46,550
remember I had eight cores two threads

00:12:43,339 --> 00:12:49,070
per core so I go all the way up to 16 16

00:12:46,550 --> 00:12:51,620
threads and the dotted line is the

00:12:49,070 --> 00:12:54,980
parallel speed-up scaled to the single

00:12:51,620 --> 00:12:57,680
thread performance right the good news

00:12:54,980 --> 00:12:59,870
is there is benefit from adding threads

00:12:57,680 --> 00:13:02,240
we do see a reduction in time but that's

00:12:59,870 --> 00:13:05,329
good and it can go all the way to 16

00:13:02,240 --> 00:13:07,730
hyper threads that's not a given but

00:13:05,329 --> 00:13:10,490
this this example I can use all the

00:13:07,730 --> 00:13:14,450
hybrids the bad thing is I only get

00:13:10,490 --> 00:13:17,540
three point 2x speed-up so that's not

00:13:14,450 --> 00:13:21,820
good ok that's very low for 16

00:13:17,540 --> 00:13:25,700
so when use again use the profiling tool

00:13:21,820 --> 00:13:29,780
and I found several opportunities to fix

00:13:25,700 --> 00:13:31,700
the code some of them just shown okay in

00:13:29,780 --> 00:13:33,200
a cleaner context but some of these

00:13:31,700 --> 00:13:37,220
things were actually it's code that I

00:13:33,200 --> 00:13:40,970
just talked about and all those small

00:13:37,220 --> 00:13:44,960
changes the improvement is rather

00:13:40,970 --> 00:13:47,990
dramatic what you see is the search time

00:13:44,960 --> 00:13:50,240
the dark blue is the modified code we

00:13:47,990 --> 00:13:51,890
see that the search time single thread

00:13:50,240 --> 00:13:54,200
is the same that's always a good sanity

00:13:51,890 --> 00:13:57,230
check make sure that you didn't ruin it

00:13:54,200 --> 00:13:59,960
in some way some unexpected way so this

00:13:57,230 --> 00:14:02,840
is the same actually on two threads the

00:13:59,960 --> 00:14:05,720
time is the same and that goes to what

00:14:02,840 --> 00:14:07,610
I've said before about scalability so

00:14:05,720 --> 00:14:10,430
2/3 you don't see a difference but then

00:14:07,610 --> 00:14:13,370
it starts taking off and ultimately you

00:14:10,430 --> 00:14:15,530
get pretty nice performance so here we

00:14:13,370 --> 00:14:18,110
see initially no benefit then is benefit

00:14:15,530 --> 00:14:20,360
here and ultimately the search time is

00:14:18,110 --> 00:14:23,090
two times faster really low-hanging

00:14:20,360 --> 00:14:25,190
fruit and and related to that the

00:14:23,090 --> 00:14:29,690
parallel speed-up goes up to like almost

00:14:25,190 --> 00:14:31,610
seven instead of 3.2 right are we done

00:14:29,690 --> 00:14:33,290
yet that's the hardest part in

00:14:31,610 --> 00:14:35,690
performance tuning you never know when

00:14:33,290 --> 00:14:39,590
you're finished so I decided to explore

00:14:35,690 --> 00:14:44,660
a little further and it's encouraging it

00:14:39,590 --> 00:14:47,450
gets you going not bad but let's look at

00:14:44,660 --> 00:14:50,090
the dynamic behavior of the threads all

00:14:47,450 --> 00:14:54,020
right again this time line now for one

00:14:50,090 --> 00:14:56,470
thread and two threads and at this level

00:14:54,020 --> 00:14:59,870
it looks fairly well but that's zoom in

00:14:56,470 --> 00:15:01,700
okay both are faster both the

00:14:59,870 --> 00:15:04,210
initialization and the search and

00:15:01,700 --> 00:15:08,660
verification benefit all good stuff I

00:15:04,210 --> 00:15:11,420
tell you zoom in now what you seem the

00:15:08,660 --> 00:15:14,600
master thread is fine but the second

00:15:11,420 --> 00:15:16,910
thread has gaps in the execution all

00:15:14,600 --> 00:15:19,190
right and when you zoom in some more you

00:15:16,910 --> 00:15:21,650
see that and actually when you look very

00:15:19,190 --> 00:15:24,170
closely you'll all see it's always in

00:15:21,650 --> 00:15:26,780
the red part it's always the search so

00:15:24,170 --> 00:15:31,070
for some reason the pair does work in

00:15:26,780 --> 00:15:33,410
the indium in the search phase okay

00:15:31,070 --> 00:15:35,810
sometimes problems go away as you

00:15:33,410 --> 00:15:37,820
increase the problem size or different

00:15:35,810 --> 00:15:40,130
thread found so always do that sanity

00:15:37,820 --> 00:15:43,430
check this is what I did for threads

00:15:40,130 --> 00:15:44,839
it's actually worse okay and you have to

00:15:43,430 --> 00:15:46,850
believe me little I have some more data

00:15:44,839 --> 00:15:49,519
on that but Portsmouth it gets worse as

00:15:46,850 --> 00:15:51,889
you add pets so I'd look into the source

00:15:49,519 --> 00:15:54,170
code the profiler was telling me I'm

00:15:51,889 --> 00:15:56,389
running spending a lot of time here and

00:15:54,170 --> 00:15:58,310
I don't this is not the right forum to

00:15:56,389 --> 00:16:00,980
go through source code in detail but

00:15:58,310 --> 00:16:04,160
I'll illustrate the highlights the

00:16:00,980 --> 00:16:06,470
highlights are this is a own before with

00:16:04,160 --> 00:16:07,880
a very regular structured parallel loop

00:16:06,470 --> 00:16:12,170
that's fine

00:16:07,880 --> 00:16:14,480
well this loop actually depends on the

00:16:12,170 --> 00:16:17,600
loop the loop counter kay the loop

00:16:14,480 --> 00:16:20,750
iteration variable so the work here is

00:16:17,600 --> 00:16:24,320
no longer regular it's not the same for

00:16:20,750 --> 00:16:26,839
different values of K of that then alarm

00:16:24,320 --> 00:16:29,149
alarm bell should go off to make that a

00:16:26,839 --> 00:16:31,820
little bit worse there's an if statement

00:16:29,149 --> 00:16:33,440
here so depending on whether that if

00:16:31,820 --> 00:16:36,769
it's true or not you'll do more or less

00:16:33,440 --> 00:16:41,690
work in other words this is a classical

00:16:36,769 --> 00:16:44,170
example of load imbalance alright or

00:16:41,690 --> 00:16:47,120
knowing that the fix is extremely easy

00:16:44,170 --> 00:16:49,160
so instead of using the default static

00:16:47,120 --> 00:16:53,389
scheduling now pretty much every

00:16:49,160 --> 00:16:55,550
compiler uses for a regular loop you can

00:16:53,389 --> 00:16:58,040
go to dynamic or guide it I'd like to

00:16:55,550 --> 00:17:01,519
use the runtime clause and with the

00:16:58,040 --> 00:17:04,220
runtime Clause I set at runtime in this

00:17:01,519 --> 00:17:07,850
case I set it to dynamic scaling with a

00:17:04,220 --> 00:17:09,319
chunk size of 25 the value of 25 it's

00:17:07,850 --> 00:17:11,299
trial and error you have to give it some

00:17:09,319 --> 00:17:14,319
tries find the right value it's hard to

00:17:11,299 --> 00:17:19,040
predict but that's what I did well and

00:17:14,319 --> 00:17:21,290
here's the benefit so the blue one this

00:17:19,040 --> 00:17:23,600
is the original code the bad one and

00:17:21,290 --> 00:17:27,169
actually you see here the modified

00:17:23,600 --> 00:17:29,419
version is slightly slower and the

00:17:27,169 --> 00:17:31,610
reason is dynamic is more expensive

00:17:29,419 --> 00:17:33,169
that's why compilers like static

00:17:31,610 --> 00:17:35,630
scheduling because it's so cheap to do

00:17:33,169 --> 00:17:38,929
it's very small I think it's in the

00:17:35,630 --> 00:17:41,630
order of 1% or so so very small but it's

00:17:38,929 --> 00:17:43,730
noticeable and after that it starts to

00:17:41,630 --> 00:17:44,960
take off all right so we see a little

00:17:43,730 --> 00:17:47,299
bit of slowdown

00:17:44,960 --> 00:17:50,029
now now there's about almost linear

00:17:47,299 --> 00:17:52,759
scaling for all eight cores in my system

00:17:50,029 --> 00:17:56,480
the second thread helps a little bit

00:17:52,759 --> 00:17:59,869
I mean why wait I get it so pretty good

00:17:56,480 --> 00:18:02,299
scanning overall and it gives me X

00:17:59,869 --> 00:18:04,970
performance improvement and I hope you

00:18:02,299 --> 00:18:07,700
all agree that was not a lot of most of

00:18:04,970 --> 00:18:09,830
the work was acting profiles and big

00:18:07,700 --> 00:18:13,220
going on but from an implementation

00:18:09,830 --> 00:18:17,179
point of view it's very small all right

00:18:13,220 --> 00:18:19,879
sanity check and indeed on this case on

00:18:17,179 --> 00:18:22,519
eight threads nicely balanced instead of

00:18:19,879 --> 00:18:23,090
all these gaps so it's doing the right

00:18:22,519 --> 00:18:27,919
thing

00:18:23,090 --> 00:18:30,499
conclusion again 2x very easy to get

00:18:27,919 --> 00:18:33,080
then the realization was this is an

00:18:30,499 --> 00:18:35,119
irregular workload using dynamic

00:18:33,080 --> 00:18:37,340
scheduling or you could try guided which

00:18:35,119 --> 00:18:39,139
I did as well dynamic was the best one

00:18:37,340 --> 00:18:42,710
for this gave me a total of 3x

00:18:39,139 --> 00:18:44,330
performance improvement and really you

00:18:42,710 --> 00:18:46,789
have to do this with the tool how else

00:18:44,330 --> 00:18:48,740
would I know this so again think about

00:18:46,789 --> 00:18:51,019
what tool you want to use and pick it

00:18:48,740 --> 00:18:54,110
but never forget to use it a profiling

00:18:51,019 --> 00:18:55,279
tool oh yeah said that many times I'm

00:18:54,110 --> 00:18:59,690
done thank you

00:18:55,279 --> 00:19:04,909
stay tuned as always thank you and any

00:18:59,690 --> 00:19:08,779
questions you're going to look back at

00:19:04,909 --> 00:19:10,990
your own code and like oh boy so all

00:19:08,779 --> 00:19:10,990

YouTube URL: https://www.youtube.com/watch?v=TnJEsm32iP0


