Title: Session-6: OpenMP Doacross Loops in Practice: A Mini-Application Case Study
Publication date: 2017-10-15
Playlist: OpenMPCon 2017 Developers Conference
Description: 
	Gabriele Jost and Haoqiang Jin
Slides at http://openmpcon.org/wp-content/uploads/openmpcon2017/Day1-Session3-Jost.pdf
Captions: 
	00:00:00,030 --> 00:00:06,299
um yeah my car my colleague Henry you

00:00:03,090 --> 00:00:11,099
and I we both work at NASA NASA Ames

00:00:06,299 --> 00:00:15,690
Research Center and we flip me for plate

00:00:11,099 --> 00:00:19,770
with our using the OpenMP 4.5 to across

00:00:15,690 --> 00:00:23,279
support for our well guess what Nass

00:00:19,770 --> 00:00:27,000
parallel benchmark that's what we do at

00:00:23,279 --> 00:00:29,060
not math parallel benchmarks so Henry

00:00:27,000 --> 00:00:32,340
has developed six different

00:00:29,060 --> 00:00:35,579
implementations of one of the benchmark

00:00:32,340 --> 00:00:38,010
kernels and so he's the mastermind

00:00:35,579 --> 00:00:42,600
behind all these from implementations

00:00:38,010 --> 00:00:47,520
and he is also our expert on openmp I

00:00:42,600 --> 00:00:49,730
myself do much more mundane tasks I work

00:00:47,520 --> 00:00:53,899
in the scientific consulting group a

00:00:49,730 --> 00:00:58,739
dealing but like mostly very mundane um

00:00:53,899 --> 00:01:02,090
music questions our users are very very

00:00:58,739 --> 00:01:06,479
conservative it gives only very very

00:01:02,090 --> 00:01:08,750
basic features of OpenMP so when I

00:01:06,479 --> 00:01:13,770
listen to the presentations this morning

00:01:08,750 --> 00:01:17,159
I I'm just in awe of all these new

00:01:13,770 --> 00:01:18,960
features that you guys are using and I

00:01:17,159 --> 00:01:23,880
certainly right now I feel like the

00:01:18,960 --> 00:01:28,619
caveman of openmp like cavemens approach

00:01:23,880 --> 00:01:30,810
to view of openmp the outline of the

00:01:28,619 --> 00:01:33,540
presentation is as follows oh yeah I

00:01:30,810 --> 00:01:36,659
should also add Henry will be Henry

00:01:33,540 --> 00:01:39,000
could not come right now but he will be

00:01:36,659 --> 00:01:41,310
available or next week at the

00:01:39,000 --> 00:01:43,409
face-to-face so for those of you who

00:01:41,310 --> 00:01:45,299
stay around for the face-to-face you'll

00:01:43,409 --> 00:01:48,000
have the opportunity to talk to him

00:01:45,299 --> 00:01:49,890
directly the outline of the talks as

00:01:48,000 --> 00:01:52,710
follows a give like a very brief

00:01:49,890 --> 00:01:56,869
background on the on the open and P do

00:01:52,710 --> 00:01:58,950
cause from concept I explain Henry's

00:01:56,869 --> 00:02:03,689
implementations of the Lu

00:01:58,950 --> 00:02:06,030
benchmark to you and then I'll talk a

00:02:03,689 --> 00:02:08,250
little bit about performance analysis

00:02:06,030 --> 00:02:12,959
which is select a small part that that

00:02:08,250 --> 00:02:16,170
I've done and then come up with like

00:02:12,959 --> 00:02:19,739
some preliminary summary and conclusions

00:02:16,170 --> 00:02:22,620
or I wrote here time permitting I'd also

00:02:19,739 --> 00:02:25,590
like to discuss a relatively new

00:02:22,620 --> 00:02:28,709
benchmark kernel the parallel research

00:02:25,590 --> 00:02:32,370
Cronus ins from point to point and it's

00:02:28,709 --> 00:02:35,280
very similar to the Lu OpenMP yet just

00:02:32,370 --> 00:02:39,569
different enough to have completely

00:02:35,280 --> 00:02:41,730
different conclusions but but I I don't

00:02:39,569 --> 00:02:45,299
think there's a fair chance that that

00:02:41,730 --> 00:02:48,810
I'll even get there also ok background I

00:02:45,299 --> 00:02:51,299
don't need to do much about distance you

00:02:48,810 --> 00:02:56,400
all help the background or you all

00:02:51,299 --> 00:02:59,970
probably know them that with OpenMP 4.0

00:02:56,400 --> 00:03:02,610
we have the ordered clause to the work

00:02:59,970 --> 00:03:05,489
share construct and then an ordered

00:03:02,610 --> 00:03:08,340
construct word that you can place within

00:03:05,489 --> 00:03:11,750
the body of such an ordered work shared

00:03:08,340 --> 00:03:16,200
glue and the vidis body you specify a

00:03:11,750 --> 00:03:18,989
code region victus contract you specify

00:03:16,200 --> 00:03:22,829
a code region in the loop body that will

00:03:18,989 --> 00:03:25,040
be then executed in lexical order which

00:03:22,829 --> 00:03:28,769
means in the in the ordered iterations

00:03:25,040 --> 00:03:30,810
in order of the iterations and so so

00:03:28,769 --> 00:03:34,470
basically in layman's term it will

00:03:30,810 --> 00:03:39,840
sequential eyes the the execution of

00:03:34,470 --> 00:03:41,780
this of the Swiss region and at MIT we

00:03:39,840 --> 00:03:44,940
have to admit the expressive

00:03:41,780 --> 00:03:47,640
expressiveness softest is not not very

00:03:44,940 --> 00:03:52,049
extensive why it's not very expressive

00:03:47,640 --> 00:03:55,350
you cannot specify any details about the

00:03:52,049 --> 00:04:00,600
dependence itself like such as distance

00:03:55,350 --> 00:04:02,910
vectors or you know other things so so

00:04:00,600 --> 00:04:07,080
relief to this

00:04:02,910 --> 00:04:09,660
came with OpenMP 4.4 by introducing the

00:04:07,080 --> 00:04:14,040
dependent clause for disordered

00:04:09,660 --> 00:04:17,870
construct and on the depend clause takes

00:04:14,040 --> 00:04:20,970
arguments sync and source and with these

00:04:17,870 --> 00:04:23,870
arguments you can specify you can

00:04:20,970 --> 00:04:27,510
basically fine-tune the dependents

00:04:23,870 --> 00:04:30,510
information and then they are cell yeah

00:04:27,510 --> 00:04:33,420
yep yep yep that's that's what you can

00:04:30,510 --> 00:04:35,970
do you can find rune or information

00:04:33,420 --> 00:04:39,750
about dependences and this whole thing

00:04:35,970 --> 00:04:43,230
is referred to just like whole combo of

00:04:39,750 --> 00:04:46,260
the ordered construct with the dependent

00:04:43,230 --> 00:04:51,720
clause and its argument that's referred

00:04:46,260 --> 00:04:54,300
to as to do cross concept the is a

00:04:51,720 --> 00:04:57,240
little code snippet here which for all

00:04:54,300 --> 00:05:00,210
of you who avidly study the open and

00:04:57,240 --> 00:05:02,850
piece examples document it will look

00:05:00,210 --> 00:05:06,960
familiar it's shamelessly stolen from

00:05:02,850 --> 00:05:10,440
there so on that data shows how this

00:05:06,960 --> 00:05:13,320
feature is being used so you place the

00:05:10,440 --> 00:05:15,780
ordered construct on the loop to wrong

00:05:13,320 --> 00:05:18,510
because there is a dependence in there

00:05:15,780 --> 00:05:22,080
to evaluate B you need the value of B of

00:05:18,510 --> 00:05:25,710
I minus 1 and then you basically go

00:05:22,080 --> 00:05:29,250
introduce or by using the the depend

00:05:25,710 --> 00:05:31,980
clause with the sync argument you

00:05:29,250 --> 00:05:33,840
specify a weight point you have to wait

00:05:31,980 --> 00:05:37,200
for the previous iteration to be

00:05:33,840 --> 00:05:40,230
finished and then here you signal to the

00:05:37,200 --> 00:05:42,900
other thread or other threads who may

00:05:40,230 --> 00:05:45,510
depend on this iteration that the works

00:05:42,900 --> 00:05:50,340
done the data is available can be

00:05:45,510 --> 00:05:54,060
consumed right so and why our situations

00:05:50,340 --> 00:05:58,710
were just is hopefully the robot hopes

00:05:54,060 --> 00:06:02,550
that is useful for hyperplane algorithms

00:05:58,710 --> 00:06:04,890
or pipeline threat algorithms examples

00:06:02,550 --> 00:06:05,820
for this is what have you need use that

00:06:04,890 --> 00:06:08,700
at NASA

00:06:05,820 --> 00:06:12,360
names like to see if decode overflow

00:06:08,700 --> 00:06:17,660
which has a silver like a success of

00:06:12,360 --> 00:06:20,820
scholarship das idle slow of time or dot

00:06:17,660 --> 00:06:26,310
line sweeper in one of the implicit

00:06:20,820 --> 00:06:28,710
times over on steps and yeah they have

00:06:26,310 --> 00:06:31,320
to they have to rearrange the order of

00:06:28,710 --> 00:06:34,680
force of iterations in strange and

00:06:31,320 --> 00:06:37,320
unusual ways to be able to extract a

00:06:34,680 --> 00:06:40,440
certain amount of parallelism or which

00:06:37,320 --> 00:06:42,800
is depicted either hyperplane or of a

00:06:40,440 --> 00:06:48,090
pipeline method and these little

00:06:42,800 --> 00:06:51,840
beautiful to little charts or sort of

00:06:48,090 --> 00:06:57,030
graphically displayed at um now there

00:06:51,840 --> 00:06:59,880
del um the ALU benchmark kernel that

00:06:57,030 --> 00:07:03,560
that we'll be discussing here that tries

00:06:59,880 --> 00:07:06,090
to now tries to it does capture the

00:07:03,560 --> 00:07:09,690
characteristics of this overflow code

00:07:06,090 --> 00:07:16,830
for just for just implicit x over step

00:07:09,690 --> 00:07:20,010
and so you see that yes it's it's a

00:07:16,830 --> 00:07:24,210
successive over relaxation method and I

00:07:20,010 --> 00:07:27,600
guess we don't have my own mouth and

00:07:24,210 --> 00:07:30,330
it's under methods effector eyes into

00:07:27,600 --> 00:07:33,750
lower and an upper solver step by both

00:07:30,330 --> 00:07:36,600
of them carried dependences in each of

00:07:33,750 --> 00:07:40,080
the spatial dimensions that it works so

00:07:36,600 --> 00:07:44,280
okay so there is no chance you could

00:07:40,080 --> 00:07:47,760
just easily or pick one dimension and

00:07:44,280 --> 00:07:52,590
back to I assert excuse me or paralyzed

00:07:47,760 --> 00:07:55,920
left it open and P so now but people

00:07:52,590 --> 00:07:59,820
have not given up to extract a certain

00:07:55,920 --> 00:08:03,180
amount of parallelism by using a thread

00:07:59,820 --> 00:08:03,730
pipelining method well if no text on

00:08:03,180 --> 00:08:07,960
this

00:08:03,730 --> 00:08:11,650
so it's animated it's animated so how do

00:08:07,960 --> 00:08:14,350
you set up a sweat pipeline you place a

00:08:11,650 --> 00:08:18,040
parallel construct on the outermost loop

00:08:14,350 --> 00:08:20,320
you will place the workshare on the next

00:08:18,040 --> 00:08:24,610
inner loop but then you need to

00:08:20,320 --> 00:08:27,580
synchronize all before the iterations

00:08:24,610 --> 00:08:29,980
before the execution of this inner loop

00:08:27,580 --> 00:08:32,380
you need to synchronize to the left and

00:08:29,980 --> 00:08:35,410
right that the left data is available

00:08:32,380 --> 00:08:38,229
and then also tell the others words when

00:08:35,410 --> 00:08:40,180
the right order the others words on the

00:08:38,229 --> 00:08:44,620
right side that now the data is ready

00:08:40,180 --> 00:08:48,670
for consumption and I've been we've both

00:08:44,620 --> 00:08:52,000
decided we do not want to show the code

00:08:48,670 --> 00:08:55,000
those orders before der before they will

00:08:52,000 --> 00:08:58,650
still open and p2 across support that

00:08:55,000 --> 00:09:01,390
was done manually by by explicitly

00:08:58,650 --> 00:09:04,960
programming such synchronization

00:09:01,390 --> 00:09:08,170
routines and today we lie on testing

00:09:04,960 --> 00:09:13,180
shared variables and they use the open

00:09:08,170 --> 00:09:17,020
and key flush on semantics in order to

00:09:13,180 --> 00:09:18,670
try to ensure memory consistency I will

00:09:17,020 --> 00:09:22,240
not show the code because that would

00:09:18,670 --> 00:09:29,740
derail the presentation right right from

00:09:22,240 --> 00:09:33,880
here because so I will only summarize it

00:09:29,740 --> 00:09:38,140
on that the implementing net is a time

00:09:33,880 --> 00:09:41,350
consuming of it's error-prone as we know

00:09:38,140 --> 00:09:44,290
from use of expertise because there had

00:09:41,350 --> 00:09:49,060
actually been a bug in there for many

00:09:44,290 --> 00:09:52,780
years that have that has now been fixed

00:09:49,060 --> 00:09:54,850
hopefully but it's very error-prone and

00:09:52,780 --> 00:09:57,970
also if you look at it it's like

00:09:54,850 --> 00:10:02,350
completely non-intuitive you could

00:09:57,970 --> 00:10:03,340
discuss that for for an hour until until

00:10:02,350 --> 00:10:05,950
we are all on the

00:10:03,340 --> 00:10:10,750
Paige so let me just just take my word

00:10:05,950 --> 00:10:13,350
for it that this is what it is but kinda

00:10:10,750 --> 00:10:18,120
long story short what you get the D

00:10:13,350 --> 00:10:21,100
synchronization is just like pipeline on

00:10:18,120 --> 00:10:27,730
the pipeline execution of the threads

00:10:21,100 --> 00:10:30,370
and yeah and not that it matters but I

00:10:27,730 --> 00:10:33,760
just wanted to show what we cannot do in

00:10:30,370 --> 00:10:36,430
open MP which is what I can do in MPI

00:10:33,760 --> 00:10:39,130
which is like a two dimensional

00:10:36,430 --> 00:10:43,000
distribution of the work and have the

00:10:39,130 --> 00:10:45,190
hyperplane sort of going and now and in

00:10:43,000 --> 00:10:48,220
two dimensions versus this here only

00:10:45,190 --> 00:10:51,490
goes in one dimension not that it

00:10:48,220 --> 00:10:53,860
matters but at least I don't know how to

00:10:51,490 --> 00:10:55,990
do it with openmp not sure if it would

00:10:53,860 --> 00:10:58,330
be possible using the collapse clause

00:10:55,990 --> 00:11:05,710
but I don't know how to distribute the

00:10:58,330 --> 00:11:08,380
work across the threads and okay now the

00:11:05,710 --> 00:11:11,560
same what I just explained to you the

00:11:08,380 --> 00:11:14,770
same can be done using the dual cross

00:11:11,560 --> 00:11:16,900
support that's now available and for the

00:11:14,770 --> 00:11:19,050
dual cross support and death steps shown

00:11:16,900 --> 00:11:24,400
here we see the two code snippets

00:11:19,050 --> 00:11:26,980
side-by-side so also on the left side

00:11:24,400 --> 00:11:30,070
that's the manual implementation and you

00:11:26,980 --> 00:11:33,040
see that it calls these routines is like

00:11:30,070 --> 00:11:35,320
happening when to retain some questions

00:11:33,040 --> 00:11:38,800
and cry that we do not want to show

00:11:35,320 --> 00:11:41,440
whereas with a dual core support you can

00:11:38,800 --> 00:11:44,200
now put your parallel on the outer loop

00:11:41,440 --> 00:11:46,660
just like with the manual version but

00:11:44,200 --> 00:11:49,410
then you can place this ordered

00:11:46,660 --> 00:11:52,870
construct with my mouth

00:11:49,410 --> 00:11:54,970
well nevermind you you see it you place

00:11:52,870 --> 00:11:58,029
the order to construct with an argument

00:11:54,970 --> 00:12:01,300
of 1 indicating that the loop nest

00:11:58,029 --> 00:12:04,510
stretches across one dimension you place

00:12:01,300 --> 00:12:07,930
this on a J loop and then within the

00:12:04,510 --> 00:12:10,029
loop body you use your depend claw you

00:12:07,930 --> 00:12:14,890
use your ordered with the dependent

00:12:10,029 --> 00:12:18,070
clause and to sink or the think argument

00:12:14,890 --> 00:12:22,360
specifying the weight point for J minus

00:12:18,070 --> 00:12:30,550
1 being available and and you place your

00:12:22,360 --> 00:12:34,980
source at the end of this loop body any

00:12:30,550 --> 00:12:34,980
question or not yes

00:12:36,440 --> 00:12:43,029
nice one excuse me

00:12:47,070 --> 00:12:57,570
ha you know I visited to that we get

00:12:54,300 --> 00:12:59,639
with it I actually do have to do have a

00:12:57,570 --> 00:13:03,240
flight on that I'm glad you asked the

00:12:59,639 --> 00:13:05,370
question so Oh actually I think I

00:13:03,240 --> 00:13:08,490
explained it a little bit right now

00:13:05,370 --> 00:13:12,149
so what Dad does pose was actually not

00:13:08,490 --> 00:13:15,720
coarser grain so you can think of that

00:13:12,149 --> 00:13:21,930
as synchronized as calling the routines

00:13:15,720 --> 00:13:26,149
and cleft okay because this will be this

00:13:21,930 --> 00:13:29,670
will be executed sequentially and then

00:13:26,149 --> 00:13:32,910
this will be executed in an ordered way

00:13:29,670 --> 00:13:35,639
until this dependence is satisfied and

00:13:32,910 --> 00:13:39,240
the same that's the same that does

00:13:35,639 --> 00:13:42,149
routine sync left us which I don't have

00:13:39,240 --> 00:13:44,730
the implementation here right now and I

00:13:42,149 --> 00:13:47,279
have a proof for this I have a proof for

00:13:44,730 --> 00:13:48,750
this because I mean 100% we don't really

00:13:47,279 --> 00:13:52,199
know what's going on here right a

00:13:48,750 --> 00:13:55,829
compiler does that now for us so so

00:13:52,199 --> 00:13:58,980
rather than using our hands have cobbled

00:13:55,829 --> 00:14:01,380
together implementation we now leave

00:13:58,980 --> 00:14:04,560
that took to to the compiler and we can

00:14:01,380 --> 00:14:08,910
you know then blame the compiler if it

00:14:04,560 --> 00:14:12,930
doesn't do the correct thing so wash our

00:14:08,910 --> 00:14:16,560
hands or dead I'm surprised another

00:14:12,930 --> 00:14:19,620
question doesn't come up which is yeah

00:14:16,560 --> 00:14:21,740
I'm actually surprised many things don't

00:14:19,620 --> 00:14:26,310
come up but one question I can actually

00:14:21,740 --> 00:14:28,949
um answer whereas I in the full picture

00:14:26,310 --> 00:14:31,529
are you hurt me blathering about a

00:14:28,949 --> 00:14:34,560
triply nested loop right with with

00:14:31,529 --> 00:14:37,649
dependences on each dimension while I is

00:14:34,560 --> 00:14:40,620
hidden in the routine so that's life

00:14:37,649 --> 00:14:41,230
outlined a little bit a nice fat body of

00:14:40,620 --> 00:14:44,829
the

00:14:41,230 --> 00:14:47,500
the swooping and I forgot to mention

00:14:44,829 --> 00:14:50,940
that the lower super step doesn't matter

00:14:47,500 --> 00:14:54,339
the opera's overstep the same thing yeah

00:14:50,940 --> 00:14:57,579
but the I loop here is hidden in these

00:14:54,339 --> 00:15:02,980
routines so we don't worry about the I

00:14:57,579 --> 00:15:05,709
loop here what's important is that the

00:15:02,980 --> 00:15:08,260
routine J ACOD

00:15:05,709 --> 00:15:12,670
so both of them has an I loop in there

00:15:08,260 --> 00:15:16,149
but the ji CLD routine has no dependence

00:15:12,670 --> 00:15:19,120
of so that caught they could be

00:15:16,149 --> 00:15:22,779
vectorized and the Intel compiler

00:15:19,120 --> 00:15:25,209
actually does that but it's I'm just

00:15:22,779 --> 00:15:27,550
saying that that is an optimization you

00:15:25,209 --> 00:15:31,300
know compiler optimization opportunity

00:15:27,550 --> 00:15:36,010
here or the Abby LTS the troublemaker

00:15:31,300 --> 00:15:38,170
so the ji CJ aprv doesn't do anything

00:15:36,010 --> 00:15:42,070
more than just calculating a

00:15:38,170 --> 00:15:46,810
one-dimensional Jacobian vector or a set

00:15:42,070 --> 00:15:49,690
of Jacobian and the routine BLTs wants

00:15:46,810 --> 00:15:52,510
to update a three dimensional residual

00:15:49,690 --> 00:15:57,550
vector and it uses this Jacobian

00:15:52,510 --> 00:16:00,880
district Obion matrices and it also uses

00:15:57,550 --> 00:16:05,440
with videos from two previous planes

00:16:00,880 --> 00:16:07,390
from J minus 1 and K minus 1 so that

00:16:05,440 --> 00:16:09,730
that's the guy who introduced us to

00:16:07,390 --> 00:16:11,920
dependences and it's also not

00:16:09,730 --> 00:16:15,149
vectorizable even go to the into the

00:16:11,920 --> 00:16:17,649
compiler vectorize or something somehow

00:16:15,149 --> 00:16:22,449
not notice matters I don't know it

00:16:17,649 --> 00:16:24,579
probably can yeah but like that but in

00:16:22,449 --> 00:16:26,279
generalized vectorization doesn't help

00:16:24,579 --> 00:16:30,610
here

00:16:26,279 --> 00:16:32,019
ok questions to the questions to the

00:16:30,610 --> 00:16:35,440
hyper excuse me

00:16:32,019 --> 00:16:38,040
so questions for for this method in

00:16:35,440 --> 00:16:41,100
general I think it's it's

00:16:38,040 --> 00:16:43,710
it's pretty clear also I'll come back to

00:16:41,100 --> 00:16:48,300
it so now let's move on to the

00:16:43,710 --> 00:16:51,810
hyperplane method the hyperplane method

00:16:48,300 --> 00:16:53,430
can recall for two-dimensional even

00:16:51,810 --> 00:16:55,530
though it's the one dimensional hyper

00:16:53,430 --> 00:17:01,980
plane that you saw the picture too in

00:16:55,530 --> 00:17:03,890
this in this previous chart but you will

00:17:01,980 --> 00:17:06,240
see so why does he call a

00:17:03,890 --> 00:17:08,910
two-dimensional or why I think he calls

00:17:06,240 --> 00:17:12,770
a two-dimensional so what is what is a

00:17:08,910 --> 00:17:18,620
hyper plane method what is a hyper plane

00:17:12,770 --> 00:17:21,930
you there in a green shirt no hybrid a

00:17:18,620 --> 00:17:24,570
hyper plane is defined but all the set

00:17:21,930 --> 00:17:26,940
of points were the indices J and K add

00:17:24,570 --> 00:17:29,640
up to or to L so that's the hyper plane

00:17:26,940 --> 00:17:32,670
L and the hyper plane method relies on

00:17:29,640 --> 00:17:35,430
the fact that all the points within a

00:17:32,670 --> 00:17:37,740
hyper plane they can actually be

00:17:35,430 --> 00:17:42,120
calculated independently of each other

00:17:37,740 --> 00:17:45,480
so you can you can paralyze the fruit so

00:17:42,120 --> 00:17:48,420
so what he did is so in order to do the

00:17:45,480 --> 00:17:52,530
hyper plane version you need to transfer

00:17:48,420 --> 00:17:56,790
the loop over JK into a loop over the L

00:17:52,530 --> 00:17:59,490
and I call that JK it's a loop over the

00:17:56,790 --> 00:18:02,400
hyper plane and then all the points

00:17:59,490 --> 00:18:05,700
within the hyper plane okay and then you

00:18:02,400 --> 00:18:08,100
get something that that looks like that

00:18:05,700 --> 00:18:12,960
that looks like the code snippet below

00:18:08,100 --> 00:18:15,570
and no manual synchronization is

00:18:12,960 --> 00:18:17,610
necessary here because as I said the

00:18:15,570 --> 00:18:21,600
points within the hyper plane can all be

00:18:17,610 --> 00:18:24,750
done in parallel however however not no

00:18:21,600 --> 00:18:27,630
explicit threat synchronization okay

00:18:24,750 --> 00:18:30,210
however all the hyper planes I have to

00:18:27,630 --> 00:18:32,820
be done sequentially step by step by

00:18:30,210 --> 00:18:36,030
step so therefore you know you have your

00:18:32,820 --> 00:18:40,560
implicit you have your implicit barrier

00:18:36,030 --> 00:18:42,090
synchronization um at the end of this of

00:18:40,560 --> 00:18:44,820
this JK loop

00:18:42,090 --> 00:18:47,400
I'm actually no I'm actually surprised

00:18:44,820 --> 00:18:50,610
with all your expert I'm surprised that

00:18:47,400 --> 00:18:52,590
no bus should go there but nobody was

00:18:50,610 --> 00:18:53,490
complaining for about the pipeline

00:18:52,590 --> 00:18:57,000
version

00:18:53,490 --> 00:19:00,030
did you see the no wait there was there

00:18:57,000 --> 00:19:03,810
you frodan over it and if you don't have

00:19:00,030 --> 00:19:06,530
to no wait there is a single hang now

00:19:03,810 --> 00:19:09,720
we're in the standard doesn't say

00:19:06,530 --> 00:19:12,900
standard experts we're in a standard as

00:19:09,720 --> 00:19:18,690
would say that the no wait of chill

00:19:12,900 --> 00:19:22,230
actually in fourth oh no wait I think I

00:19:18,690 --> 00:19:25,650
think it's ambiguous I think that the

00:19:22,230 --> 00:19:27,920
compiler does not can ignore - no no

00:19:25,650 --> 00:19:27,920
wait

00:19:28,220 --> 00:19:35,900
yeah it can I at least I don't see at

00:19:32,310 --> 00:19:40,500
least I don't see where it says it then

00:19:35,900 --> 00:19:45,600
shall not wait it could it could or

00:19:40,500 --> 00:19:48,480
choose to to wait and I've verified that

00:19:45,600 --> 00:19:50,640
if I take - no wait out to method for

00:19:48,480 --> 00:19:52,920
him so I don't know if this is

00:19:50,640 --> 00:19:55,500
intentional that would actually be one

00:19:52,920 --> 00:19:58,590
of the things I'm interested in is this

00:19:55,500 --> 00:20:01,170
intention that it can be ignored does

00:19:58,590 --> 00:20:03,900
that have any benefits I think it's very

00:20:01,170 --> 00:20:07,470
shopping for the user if you put - no

00:20:03,900 --> 00:20:11,150
wait there now and it wait what would be

00:20:07,470 --> 00:20:11,150
shocking for a benchmark

00:20:11,570 --> 00:20:16,450
[Music]

00:20:13,890 --> 00:20:26,830
the dependence can be told now that

00:20:16,450 --> 00:20:29,710
would be bad with her said yeah yeah

00:20:26,830 --> 00:20:33,310
then it sequentially it's okay but if

00:20:29,710 --> 00:20:35,050
you yeah if you just assume there are no

00:20:33,310 --> 00:20:47,890
dependents well you still have to order

00:20:35,050 --> 00:20:49,720
it but well it does not it does at the

00:20:47,890 --> 00:20:52,920
moment it doesn't do anything it can be

00:20:49,720 --> 00:20:52,920
completely ignored

00:20:57,920 --> 00:21:03,090
yeah unless but it doesn't right but

00:21:00,930 --> 00:21:06,330
it's the wrong logic right it doesn't

00:21:03,090 --> 00:21:09,630
mean if the if it's um if it is

00:21:06,330 --> 00:21:12,000
specified it has to be it doesn't mean

00:21:09,630 --> 00:21:25,290
it like the you know that like the

00:21:12,000 --> 00:21:27,240
inverse is so true yeah I mean one would

00:21:25,290 --> 00:21:30,060
understand it but is that really true

00:21:27,240 --> 00:21:34,380
that it just means that if to know wait

00:21:30,060 --> 00:21:37,140
is there you can not you care you can

00:21:34,380 --> 00:21:39,720
expect a barrier it doesn't tell you

00:21:37,140 --> 00:21:41,850
anything but okay I mean that's not to

00:21:39,720 --> 00:21:45,390
lead a subject of my talk it doesn't say

00:21:41,850 --> 00:21:52,770
is it stare what you can expect right

00:21:45,390 --> 00:21:56,610
or does it I would make to stand it less

00:21:52,770 --> 00:21:59,220
ambiguous but that's the truth me for

00:21:56,610 --> 00:22:02,580
anyhow here's an implicit barrier and

00:21:59,220 --> 00:22:07,260
and that's non-ambiguous you can expect

00:22:02,580 --> 00:22:10,950
that no no barrier so so those of what I

00:22:07,260 --> 00:22:13,400
would add a rule so the thing is here we

00:22:10,950 --> 00:22:16,500
had among with the indices quite

00:22:13,400 --> 00:22:19,620
significantly okay I mean it looks so

00:22:16,500 --> 00:22:23,220
easy but again you know transforming

00:22:19,620 --> 00:22:25,760
these indices there is some yeah now

00:22:23,220 --> 00:22:28,530
look how nice and easy now look at a

00:22:25,760 --> 00:22:31,170
nice and easy that can be implemented

00:22:28,530 --> 00:22:35,000
with the to across support all we need

00:22:31,170 --> 00:22:38,370
to do is that now we spend nesting or

00:22:35,000 --> 00:22:42,510
babies we span the dependences across

00:22:38,370 --> 00:22:46,620
two loops so we have we have like an

00:22:42,510 --> 00:22:50,070
audit with a little too and then we may

00:22:46,620 --> 00:22:54,810
be used to sing for K minus 1 and J

00:22:50,070 --> 00:22:57,460
minus 1 nice III think it's nice it

00:22:54,810 --> 00:23:00,100
cleaner

00:22:57,460 --> 00:23:04,290
and you know requires less manual

00:23:00,100 --> 00:23:07,630
banging you preserve the original

00:23:04,290 --> 00:23:11,550
structure Oscar loop no no we right

00:23:07,630 --> 00:23:15,880
that's what open and ps4 so that's good

00:23:11,550 --> 00:23:18,910
um so only specify dependences you don't

00:23:15,880 --> 00:23:23,100
really so so we call that we called it a

00:23:18,910 --> 00:23:26,950
two-dimensional or the hyperplane I

00:23:23,100 --> 00:23:29,980
think the name comes from because you

00:23:26,950 --> 00:23:33,160
have basically two industries involved

00:23:29,980 --> 00:23:35,860
and says in a manual version as well as

00:23:33,160 --> 00:23:39,100
in the dual cost version so certainly

00:23:35,860 --> 00:23:42,010
that that hyperplane goes through two

00:23:39,100 --> 00:23:43,540
dimensions with you know two indices are

00:23:42,010 --> 00:23:48,610
involved

00:23:43,540 --> 00:23:51,730
now does this of which we do across is

00:23:48,610 --> 00:23:53,980
that really hyperplane you know in the

00:23:51,730 --> 00:23:54,640
in the way that we've seen it in the

00:23:53,980 --> 00:23:57,190
picture

00:23:54,640 --> 00:24:00,040
we don't know I still don't know but I

00:23:57,190 --> 00:24:02,890
show you some perform so I show you some

00:24:00,040 --> 00:24:04,810
assumptions about this I mean apart for

00:24:02,890 --> 00:24:08,290
the manual implementation we know what's

00:24:04,810 --> 00:24:12,790
going on right we with reorder the

00:24:08,290 --> 00:24:14,650
indices and here here we only we only

00:24:12,790 --> 00:24:17,920
specify the dependences and on how to

00:24:14,650 --> 00:24:23,260
compile it and our deals with walking

00:24:17,920 --> 00:24:25,390
foodie serve to to do good space to get

00:24:23,260 --> 00:24:28,390
through the iteration space you don't

00:24:25,390 --> 00:24:30,390
know at least I don't know if it obvious

00:24:28,390 --> 00:24:33,429
I don't know

00:24:30,390 --> 00:24:33,429
[Music]

00:24:38,470 --> 00:25:00,740
the especailly a hyperplane I don't know

00:24:43,340 --> 00:25:04,220
I can't really envision is also to be

00:25:00,740 --> 00:25:06,410
haven't had a failure yet and I can tell

00:25:04,220 --> 00:25:08,840
you I find it multiple multiple times

00:25:06,410 --> 00:25:12,380
it's just not clear to me that this

00:25:08,840 --> 00:25:14,750
really well in a hyperplane a bit but I

00:25:12,380 --> 00:25:18,230
mean it definitely I shall some more

00:25:14,750 --> 00:25:20,809
about it later on okay oh oh oh an

00:25:18,230 --> 00:25:25,309
important difference here to notice and

00:25:20,809 --> 00:25:29,090
I come back over to this also is that

00:25:25,309 --> 00:25:32,240
that we are using the static one for the

00:25:29,090 --> 00:25:34,460
best load balancing for the best

00:25:32,240 --> 00:25:38,050
performance and I show you what happens

00:25:34,460 --> 00:25:41,030
if you use static bad things happen and

00:25:38,050 --> 00:25:43,460
now just when you thought we've heard

00:25:41,030 --> 00:25:47,240
all we want to about how to restructure

00:25:43,460 --> 00:25:50,360
Lu here's one more here's one more to

00:25:47,240 --> 00:25:52,640
sweidy hyperplane version once you start

00:25:50,360 --> 00:25:55,970
restructuring this thing you just can't

00:25:52,640 --> 00:26:00,230
stop so here is I can't talk about

00:25:55,970 --> 00:26:03,230
details so you can cause a useful you

00:26:00,230 --> 00:26:06,679
can just make a natural extension of

00:26:03,230 --> 00:26:10,460
this two-dimensional or implementation

00:26:06,679 --> 00:26:14,090
by by now getting all three indices into

00:26:10,460 --> 00:26:17,059
the equation okay but for this we have

00:26:14,090 --> 00:26:21,140
to be neat three indices we have to

00:26:17,059 --> 00:26:23,370
hoist us index I which was so useful for

00:26:21,140 --> 00:26:26,160
vectorization for the GAC

00:26:23,370 --> 00:26:29,160
LD watching we have to hoist that out of

00:26:26,160 --> 00:26:33,270
the loop so there is some some rewriting

00:26:29,160 --> 00:26:36,720
on we quiet and then and then again what

00:26:33,270 --> 00:26:40,290
he does is well but what I described

00:26:36,720 --> 00:26:45,330
here but I can't go into details so you

00:26:40,290 --> 00:26:48,930
saw you you you go to a so you lift acai

00:26:45,330 --> 00:26:51,660
out you pre compute the number in all of

00:26:48,930 --> 00:26:53,850
the hyperplanes we loop through the

00:26:51,660 --> 00:26:56,059
hyperplanes and look and the points

00:26:53,850 --> 00:27:01,230
within the hyperplane and you come

00:26:56,059 --> 00:27:04,650
convert this pair into indices L and n

00:27:01,230 --> 00:27:07,410
into indices I and J and then you get

00:27:04,650 --> 00:27:08,250
your case like this and just trust me

00:27:07,410 --> 00:27:13,440
this correct

00:27:08,250 --> 00:27:18,179
all right because and and this

00:27:13,440 --> 00:27:20,010
conversion is ugly very very ugly I just

00:27:18,179 --> 00:27:22,460
show you the code Snowbird here in the

00:27:20,010 --> 00:27:25,770
unlikely event I get to talk much about

00:27:22,460 --> 00:27:26,550
performance that actually was a bad

00:27:25,770 --> 00:27:30,000
thing

00:27:26,550 --> 00:27:31,800
to put this into the loop explicitly you

00:27:30,000 --> 00:27:33,840
wouldn't think and you think they'll

00:27:31,800 --> 00:27:35,880
feel a little bit of like integer

00:27:33,840 --> 00:27:40,850
arithmetic it's not going to work to

00:27:35,880 --> 00:27:45,809
performance but boy it does show you um

00:27:40,850 --> 00:27:51,330
and again with to across FCC you can now

00:27:45,809 --> 00:27:53,700
just expand it expand the dependences

00:27:51,330 --> 00:27:56,040
across all three dimensions the only

00:27:53,700 --> 00:27:59,940
thing you still need to do is host in X

00:27:56,040 --> 00:28:03,870
I out of these routines but now you can

00:27:59,940 --> 00:28:05,760
can do it it as again nice clean I like

00:28:03,870 --> 00:28:09,300
it I like it

00:28:05,760 --> 00:28:11,820
I I think I still have a couple of

00:28:09,300 --> 00:28:16,970
minutes I can show a couple of

00:28:11,820 --> 00:28:19,320
performance right let's not go into our

00:28:16,970 --> 00:28:23,919
evaluation environment I just want to

00:28:19,320 --> 00:28:31,039
say we used C on Bodwell and C on fine

00:28:23,919 --> 00:28:34,640
the teeth with these flags and nothing

00:28:31,039 --> 00:28:37,940
really interesting too and as used to as

00:28:34,640 --> 00:28:44,240
use a whole bunch of performance tools

00:28:37,940 --> 00:28:47,390
better to use my favorite sister a light

00:28:44,240 --> 00:28:50,450
way we have licensed software Opie scope

00:28:47,390 --> 00:28:53,480
for food which is really nice for desk

00:28:50,450 --> 00:28:56,179
open and PMP I very quickly and then

00:28:53,480 --> 00:28:58,700
para ver I really like going you'll

00:28:56,179 --> 00:29:01,570
probably some of you are familiar with

00:28:58,700 --> 00:29:04,250
power distributed by the Barcelona

00:29:01,570 --> 00:29:04,850
supercomputer Center and I like it very

00:29:04,250 --> 00:29:06,980
much

00:29:04,850 --> 00:29:10,100
or because you can generate nice

00:29:06,980 --> 00:29:13,100
timelines for it and just provide

00:29:10,100 --> 00:29:15,559
particular feel you deal with a large

00:29:13,100 --> 00:29:18,320
number of threads and things just nice

00:29:15,559 --> 00:29:20,720
to see these timelines or naming

00:29:18,320 --> 00:29:24,529
conventions which I've tried to follow

00:29:20,720 --> 00:29:26,450
and we we have to be helpful results and

00:29:24,529 --> 00:29:29,240
we have results for many many things but

00:29:26,450 --> 00:29:32,029
what we look at here is Class A which is

00:29:29,240 --> 00:29:39,140
truly small Class C which is just so a

00:29:32,029 --> 00:29:42,980
little bit bigger VB can do much more so

00:29:39,140 --> 00:29:45,710
okay so here is the Toyota performance

00:29:42,980 --> 00:29:51,470
whether in gigaflops for all of these

00:29:45,710 --> 00:29:56,630
six implementations in beautiful colors

00:29:51,470 --> 00:30:02,210
um and four for Class C for the broad

00:29:56,630 --> 00:30:06,830
well and for the C on I mean where for

00:30:02,210 --> 00:30:10,250
the board will and for the KNL and ok so

00:30:06,830 --> 00:30:13,940
and what we and that's collected with

00:30:10,250 --> 00:30:14,600
GCC and I come back to the interval

00:30:13,940 --> 00:30:17,179
compiler

00:30:14,600 --> 00:30:19,789
I have a slide comparing compilers

00:30:17,179 --> 00:30:23,419
because we have looked into that as well

00:30:19,789 --> 00:30:26,659
and and so then let me just show show

00:30:23,419 --> 00:30:30,250
GCC and that's actually soldered on a

00:30:26,659 --> 00:30:33,490
previous slide it's the seven point one

00:30:30,250 --> 00:30:35,980
GCC compiler because that

00:30:33,490 --> 00:30:38,980
port for Fortran for Fortran which

00:30:35,980 --> 00:30:43,870
stunned our codes are implemented and

00:30:38,980 --> 00:30:47,200
Fortran and and that will support the

00:30:43,870 --> 00:30:48,760
full dual crossing in Fortran and now

00:30:47,200 --> 00:30:50,860
look at and if you look at the

00:30:48,760 --> 00:30:52,600
performance but I mean you consider to

00:30:50,860 --> 00:30:56,350
you because the internal compiler is not

00:30:52,600 --> 00:30:59,920
next to it that we were very happy well

00:30:56,350 --> 00:31:03,100
particularly we um we we are happy about

00:30:59,920 --> 00:31:06,360
when we saw that the manual as well as

00:31:03,100 --> 00:31:13,450
the do act performance for all free

00:31:06,360 --> 00:31:16,660
implementations is very very close so

00:31:13,450 --> 00:31:19,690
you don't lose I mean your health where

00:31:16,660 --> 00:31:22,390
you have it's less effort to implement

00:31:19,690 --> 00:31:25,510
it with dual cost yet performance wise

00:31:22,390 --> 00:31:31,390
you are not taking any losses so far as

00:31:25,510 --> 00:31:33,580
we can see so that's some yeah they're

00:31:31,390 --> 00:31:36,570
Devils good and then actually for the

00:31:33,580 --> 00:31:39,880
hyperplane method the node is

00:31:36,570 --> 00:31:42,880
consistently consistently there the blue

00:31:39,880 --> 00:31:46,240
cross version slightly outperforms to

00:31:42,880 --> 00:31:49,480
manual implementation and we call that

00:31:46,240 --> 00:31:53,610
for hyperplane do parts we use the

00:31:49,480 --> 00:31:56,530
static one if you use the static one it

00:31:53,610 --> 00:32:00,580
outperforms it if you don't use the

00:31:56,530 --> 00:32:04,510
static one then that's bad now now I'm

00:32:00,580 --> 00:32:07,000
on it's not it was not really the goal

00:32:04,510 --> 00:32:09,580
of this investigation here to compare

00:32:07,000 --> 00:32:13,480
your different methods per se its

00:32:09,580 --> 00:32:17,050
morning or a comparison comparing duo

00:32:13,480 --> 00:32:20,140
cross versus manual but just a society

00:32:17,050 --> 00:32:23,559
note another is striking or one of the

00:32:20,140 --> 00:32:26,710
striking of observations we make here is

00:32:23,559 --> 00:32:30,940
that the three-dimensional performs very

00:32:26,710 --> 00:32:34,750
very poorly and I can tell you three or

00:32:30,940 --> 00:32:36,740
two reasons for it one or well actually

00:32:34,750 --> 00:32:40,150
so so Henry

00:32:36,740 --> 00:32:43,940
what one is the lack of vectorization

00:32:40,150 --> 00:32:45,890
but because we can't vector Isis J a CLG

00:32:43,940 --> 00:32:47,240
routine anymore because the index is

00:32:45,890 --> 00:32:51,650
hosted out

00:32:47,240 --> 00:32:55,100
but standard did the Intel compiler so

00:32:51,650 --> 00:32:58,309
so GCC actually doesn't make the rice

00:32:55,100 --> 00:33:02,059
any ourselves yes that it also doesn't

00:32:58,309 --> 00:33:04,370
vectorize the HP to order the pipeline's

00:33:02,059 --> 00:33:07,520
version just doesn't vector Isis the

00:33:04,370 --> 00:33:09,890
angel compiler does but as you'll see in

00:33:07,520 --> 00:33:13,730
a in a later chart it doesn't make all

00:33:09,890 --> 00:33:17,570
that much difference makes a little bit

00:33:13,730 --> 00:33:19,970
of difference but not that much and so

00:33:17,570 --> 00:33:22,370
that's that's maybe a minor reason the

00:33:19,970 --> 00:33:24,860
lack of vectorization but what what's

00:33:22,370 --> 00:33:27,590
really what was baffling was the dis

00:33:24,860 --> 00:33:31,730
little index calculations which is done

00:33:27,590 --> 00:33:33,290
on the fly in the inner loop in the HP

00:33:31,730 --> 00:33:37,130
free method you know where you just

00:33:33,290 --> 00:33:40,070
convert the indices boy that really drag

00:33:37,130 --> 00:33:42,410
to performance down and not because the

00:33:40,070 --> 00:33:44,890
integer arithmetic takes so long it's

00:33:42,410 --> 00:33:47,840
because it introduces a load imbalance

00:33:44,890 --> 00:33:49,940
the glue you you can go back I mean you

00:33:47,840 --> 00:33:52,040
can do this after presentation but if

00:33:49,940 --> 00:33:55,429
you go back and look at the loop harder

00:33:52,040 --> 00:33:57,640
stuffs calculated it actually depends so

00:33:55,429 --> 00:34:01,280
that that introduces a big workload

00:33:57,640 --> 00:34:04,220
imbalance between the fret and then you

00:34:01,280 --> 00:34:06,620
get dislike imbalance behavior i mean

00:34:04,220 --> 00:34:08,510
it's um yeah so so hanging i already

00:34:06,620 --> 00:34:11,270
pulled that out and he has new results

00:34:08,510 --> 00:34:13,940
but they were not ready in in end time

00:34:11,270 --> 00:34:16,850
so he already improved a lot but then

00:34:13,940 --> 00:34:19,190
there is another bad thing about 3d it's

00:34:16,850 --> 00:34:23,629
as you walk for the iteration space

00:34:19,190 --> 00:34:25,669
differently and you don't get deal that

00:34:23,629 --> 00:34:28,490
then then you have an issue with like

00:34:25,669 --> 00:34:31,490
cash well you now walk in three

00:34:28,490 --> 00:34:35,030
dimension so you basically have no cash

00:34:31,490 --> 00:34:37,730
we use none whatsoever and and I think

00:34:35,030 --> 00:34:39,679
that's another big bummer compared to

00:34:37,730 --> 00:34:43,240
the the other implementation but then

00:34:39,679 --> 00:34:45,060
that's not really my my focus but beyond

00:34:43,240 --> 00:34:47,310
those are bad

00:34:45,060 --> 00:34:51,420
right the manual as well as to do across

00:34:47,310 --> 00:34:53,790
from therefore I don't care as long as

00:34:51,420 --> 00:34:59,280
the due process good okay just like one

00:34:53,790 --> 00:35:01,560
click a few click unless there are some

00:34:59,280 --> 00:35:06,870
some other although I'm already over my

00:35:01,560 --> 00:35:09,570
time right also stand or just as one

00:35:06,870 --> 00:35:12,600
quick thing that for nice so so that's

00:35:09,570 --> 00:35:15,810
the dopey scope profile that I took of

00:35:12,600 --> 00:35:18,360
for the for the class see comparing the

00:35:15,810 --> 00:35:21,960
manual that's the pipelines version to

00:35:18,360 --> 00:35:25,020
the manuals on to the do cross pipelines

00:35:21,960 --> 00:35:27,240
versions or Pisco can mapped Hardware

00:35:25,020 --> 00:35:31,820
counters the collected Hardware counters

00:35:27,240 --> 00:35:34,110
on routine or basic block or or

00:35:31,820 --> 00:35:40,260
instruction level and I'm just showing

00:35:34,110 --> 00:35:42,630
here the the routine level and it also

00:35:40,260 --> 00:35:45,210
allows you to build partial sum so you

00:35:42,630 --> 00:35:48,510
can just click some of the routines and

00:35:45,210 --> 00:35:51,030
add them all up so I built it I built a

00:35:48,510 --> 00:35:54,930
partial sum here for the simplest

00:35:51,030 --> 00:35:57,570
Anderson quite routine okay and I get

00:35:54,930 --> 00:36:00,390
this and then I built the partial sum

00:35:57,570 --> 00:36:03,060
here for the dual cross weight and the

00:36:00,390 --> 00:36:05,820
two across post and I tell you what's

00:36:03,060 --> 00:36:07,680
also in this case I mean very similar

00:36:05,820 --> 00:36:09,540
I have cases where they're like

00:36:07,680 --> 00:36:11,940
completely identical I mean I've

00:36:09,540 --> 00:36:15,560
collected at many many times

00:36:11,940 --> 00:36:19,140
for many many different trials if it's

00:36:15,560 --> 00:36:23,550
same amount now basically the same

00:36:19,140 --> 00:36:27,810
amount I think that's nice so so it does

00:36:23,550 --> 00:36:30,570
the it does a very similar thing um and

00:36:27,810 --> 00:36:33,780
then I've also collected a pair of a

00:36:30,570 --> 00:36:37,170
timeline that shows the executions of

00:36:33,780 --> 00:36:39,540
the loop body lower and upper sober and

00:36:37,170 --> 00:36:42,330
I clearly you know it tries to trace

00:36:39,540 --> 00:36:45,290
every other iteration to see little gaps

00:36:42,330 --> 00:36:48,590
and clearly detectable pipeline

00:36:45,290 --> 00:36:52,640
here and and and I think I need to stop

00:36:48,590 --> 00:36:55,460
uh I think I maybe I just want to say

00:36:52,640 --> 00:36:59,450
that for the photo hyper dimensional

00:36:55,460 --> 00:37:04,390
hyper plane we see um I I again added up

00:36:59,450 --> 00:37:07,700
to justice synchronization stuff and um

00:37:04,390 --> 00:37:11,210
if you're if you look at how much time

00:37:07,700 --> 00:37:14,120
here is spent in the in the barrier rate

00:37:11,210 --> 00:37:16,190
it's six point six seven for the for the

00:37:14,120 --> 00:37:18,080
manual implementation because we have

00:37:16,190 --> 00:37:22,040
this barrier at the end of the loop

00:37:18,080 --> 00:37:27,260
right versus the partial sums over the

00:37:22,040 --> 00:37:30,620
do cross stuff plus the weight then we

00:37:27,260 --> 00:37:34,010
are doing better with a dual core stuff

00:37:30,620 --> 00:37:37,100
end up live dead at a time for the

00:37:34,010 --> 00:37:41,050
barrier is reduced and the dual across

00:37:37,100 --> 00:37:45,440
or post and weight doesn't add so much

00:37:41,050 --> 00:37:50,210
and and I'm afraid I have to stop it to

00:37:45,440 --> 00:37:53,990
you with like half of my slides fearful

00:37:50,210 --> 00:37:56,570
or maybe I just then we looked into

00:37:53,990 --> 00:38:00,770
scheduling and and this this slide just

00:37:56,570 --> 00:38:04,190
shows you know how disastrous it is if

00:38:00,770 --> 00:38:07,070
you don't specify the schedule one how

00:38:04,190 --> 00:38:11,150
disastrous it is for the performance on

00:38:07,070 --> 00:38:13,550
the HP three versions because GCC seems

00:38:11,150 --> 00:38:17,720
to be she seems to get completely

00:38:13,550 --> 00:38:20,780
confused is the studying if the if it's

00:38:17,720 --> 00:38:23,300
not a chunk size one and then and then

00:38:20,780 --> 00:38:28,120
and then as soon as it gets one pops up

00:38:23,300 --> 00:38:28,120
again and term and

00:38:28,180 --> 00:38:35,110
yeah that's really just and

00:38:32,320 --> 00:38:39,130
unfortunately we didn't have to chance

00:38:35,110 --> 00:38:41,020
to do a good a good Intel comparison

00:38:39,130 --> 00:38:44,560
because we were using compiled live

00:38:41,020 --> 00:38:47,950
version 17 and that fell over its

00:38:44,560 --> 00:38:51,490
sneakers and we to do across support and

00:38:47,950 --> 00:38:54,550
if we ported to bug and it says it's

00:38:51,490 --> 00:38:56,740
it's it's fix it we've been told it's

00:38:54,550 --> 00:38:57,610
fixed now but I didn't have to I just

00:38:56,740 --> 00:39:01,540
couldn't

00:38:57,610 --> 00:39:04,090
we want to test before I comes also and

00:39:01,540 --> 00:39:06,010
but but I mean what this slide shows is

00:39:04,090 --> 00:39:08,620
that Jesus is actually not that bad

00:39:06,010 --> 00:39:13,960
compared winter weather day they are

00:39:08,620 --> 00:39:16,480
pretty similar so so and I'm I suppose I

00:39:13,960 --> 00:39:19,740
can't wait to get to version 18 to

00:39:16,480 --> 00:39:24,190
investigate some other things and field

00:39:19,740 --> 00:39:31,830
so yeah sorry I have to I obviously

00:39:24,190 --> 00:39:35,890
didn't didn't didn't spend too much time

00:39:31,830 --> 00:39:38,580
either talking too much any any more

00:39:35,890 --> 00:39:38,580
questions

00:39:53,340 --> 00:40:01,250
that one

00:39:55,270 --> 00:40:04,700
yep that it takes a long time to happen

00:40:01,250 --> 00:40:08,450
okay here's here's a timeline here's the

00:40:04,700 --> 00:40:11,150
power over a timeline for it that's know

00:40:08,450 --> 00:40:14,420
for Class A on 8th frets okay but it

00:40:11,150 --> 00:40:19,430
basically shows what what what I think

00:40:14,420 --> 00:40:22,640
what's going on is that so this is what

00:40:19,430 --> 00:40:25,520
you get for static one it's it's the

00:40:22,640 --> 00:40:27,710
running state for each fret and in these

00:40:25,520 --> 00:40:29,720
little yellow flags that kind of

00:40:27,710 --> 00:40:32,270
indicate you know okay there here's a

00:40:29,720 --> 00:40:35,030
chunk then another chunks executable

00:40:32,270 --> 00:40:37,700
data like events of when these different

00:40:35,030 --> 00:40:40,970
bodies are executed and so for static

00:40:37,700 --> 00:40:43,430
one they're pretty nicely oh it's pretty

00:40:40,970 --> 00:40:46,090
nicely distributed they get to get the

00:40:43,430 --> 00:40:48,890
same amount of work oh well

00:40:46,090 --> 00:40:51,710
approximately the same while for for

00:40:48,890 --> 00:40:56,090
just if you just specify static then

00:40:51,710 --> 00:41:00,650
each of them gets one chunk but to me it

00:40:56,090 --> 00:41:05,619
looks like these chunks are not the same

00:41:00,650 --> 00:41:05,619
size yeah

00:41:07,520 --> 00:41:14,320
yeah so it's a screw that's the screw

00:41:12,560 --> 00:41:27,350
ending it

00:41:14,320 --> 00:41:31,220
Hey ah okay oh yeah I guess I wasn't

00:41:27,350 --> 00:41:54,890
really clear this would be yeah I wasn't

00:41:31,220 --> 00:41:56,830
saying if okay okay okay so but I mean

00:41:54,890 --> 00:41:59,510
they wouldn't that mean it's basically

00:41:56,830 --> 00:42:03,220
sequentially I mean one has to wait for

00:41:59,510 --> 00:42:03,220
next oh so you were right yeah

00:42:08,170 --> 00:42:14,569
because we just wait like this second

00:42:11,239 --> 00:42:16,809
chances all the way up saying how many

00:42:14,569 --> 00:42:16,809
good

00:42:18,900 --> 00:42:30,640
and it is but it even happens you know

00:42:28,450 --> 00:42:32,650
it was I've also experimenting with not

00:42:30,640 --> 00:42:35,890
just leave at the default you not have

00:42:32,650 --> 00:42:36,760
each one I also tried to and it's not

00:42:35,890 --> 00:42:38,980
much better

00:42:36,760 --> 00:42:42,730
I mean I haven't taken a profile I mean

00:42:38,980 --> 00:42:47,130
I I tried making in increasing thumb a

00:42:42,730 --> 00:42:47,130
little bit and and also you know yeah

00:42:57,480 --> 00:43:01,990
and of the words but I mean look look

00:43:00,310 --> 00:43:05,350
look if you look at this chart again

00:43:01,990 --> 00:43:09,400
here's like 128 frets so doctor the

00:43:05,350 --> 00:43:12,610
Class C benchmark was 162 by 162 so it's

00:43:09,400 --> 00:43:15,460
not that much bigger okay and then yet

00:43:12,610 --> 00:43:17,950
it's not that much bigger than one yeah

00:43:15,460 --> 00:43:21,720
even for for some of them it's even one

00:43:17,950 --> 00:43:26,110
and then look how this jumps up if I use

00:43:21,720 --> 00:43:28,420
162 threats on KNL but then I'm like oh

00:43:26,110 --> 00:43:30,370
back to normal again so it's just of

00:43:28,420 --> 00:43:33,520
chunk on so so I'm curious to see what

00:43:30,370 --> 00:43:39,990
the Intel compiler does I don't know if

00:43:33,520 --> 00:43:39,990
this will psycho GCC special or sorry

00:43:40,600 --> 00:43:49,810

YouTube URL: https://www.youtube.com/watch?v=7QkjUqjdyT4


