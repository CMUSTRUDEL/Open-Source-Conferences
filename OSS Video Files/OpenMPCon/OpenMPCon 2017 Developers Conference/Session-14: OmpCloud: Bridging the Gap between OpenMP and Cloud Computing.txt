Title: Session-14: OmpCloud: Bridging the Gap between OpenMP and Cloud Computing
Publication date: 2017-10-15
Playlist: OpenMPCon 2017 Developers Conference
Description: 
	HervÃ© Yviquel, Marcio Pereira and Guido Araujo
Slides at http://openmpcon.org/wp-content/uploads/openmpcon2017/Day2-Session4-Pereira.pdf
Captions: 
	00:00:00,000 --> 00:00:06,319
a lot of talk which is they're given by

00:00:03,140 --> 00:00:11,870
and it's about reaching the gap between

00:00:06,319 --> 00:00:11,870
locality and cloud computing thank you

00:00:12,410 --> 00:00:15,500
good afternoon

00:00:16,100 --> 00:00:23,400
well of course I'm not heavy I'm a

00:00:19,830 --> 00:00:27,060
Spadina have as the main collaborator in

00:00:23,400 --> 00:00:28,680
the work about humppa called bridging

00:00:27,060 --> 00:00:33,600
the gap between open P and cloud

00:00:28,680 --> 00:00:36,480
computing and I'm here to present it so

00:00:33,600 --> 00:00:41,100
anything stood I said is mine don't

00:00:36,480 --> 00:00:43,700
blame my colleagues ok a bit of

00:00:41,100 --> 00:00:47,820
background both me and have a

00:00:43,700 --> 00:00:49,800
postdoctoral research work at UNICAMP in

00:00:47,820 --> 00:00:50,760
Brazil under the supervision of the

00:00:49,800 --> 00:00:54,059
professor gido

00:00:50,760 --> 00:00:55,800
arousal and the main lines of our

00:00:54,059 --> 00:00:59,579
research are focused on compiled

00:00:55,800 --> 00:01:01,760
technologies for trade live speculation

00:00:59,579 --> 00:01:05,780
for loops loop tile and vectorization

00:01:01,760 --> 00:01:09,240
cloth paralyzation techniques and so on

00:01:05,780 --> 00:01:16,860
like parallel program modules iteration

00:01:09,240 --> 00:01:19,979
computers etc o my current working that

00:01:16,860 --> 00:01:22,320
are you presenting I want an open-source

00:01:19,979 --> 00:01:25,320
LLVM allowing the compiler framework

00:01:22,320 --> 00:01:26,369
that implements the recent release open

00:01:25,320 --> 00:01:29,909
Pearson Euratom

00:01:26,369 --> 00:01:32,460
program module our compiler

00:01:29,909 --> 00:01:36,200
automatically converts open via noted

00:01:32,460 --> 00:01:38,509
loops into open cell or spear care knows

00:01:36,200 --> 00:01:43,020
well provide a set of polyhedral

00:01:38,509 --> 00:01:44,930
techniques based on optimization like

00:01:43,020 --> 00:01:48,360
Thailand and vectorization

00:01:44,930 --> 00:01:51,000
this kernels results from the completion

00:01:48,360 --> 00:01:53,909
process can be executed on open cells

00:01:51,000 --> 00:01:57,390
frequent but the compatible acceleration

00:01:53,909 --> 00:02:01,549
of device and to the best of our

00:01:57,390 --> 00:02:04,259
knowledge this is the first

00:02:01,549 --> 00:02:07,170
implementation of open PS elevator model

00:02:04,259 --> 00:02:10,670
to provide a source to targets open C

00:02:07,170 --> 00:02:10,670
our conversion not source to source

00:02:10,940 --> 00:02:20,820
but let me start the target today top

00:02:15,840 --> 00:02:24,060
goon paralyzing loops is a well-know

00:02:20,820 --> 00:02:26,700
research problem that has been

00:02:24,060 --> 00:02:31,400
extensively student some of the approach

00:02:26,700 --> 00:02:34,670
to this problem use vectorization data

00:02:31,400 --> 00:02:38,070
arrangement and the loop transformation

00:02:34,670 --> 00:02:40,230
to improve program performance on the

00:02:38,070 --> 00:02:42,540
other hand the combination of large data

00:02:40,230 --> 00:02:45,680
center clusters and the MapReduce based

00:02:42,540 --> 00:02:48,710
techniques like those founding internet

00:02:45,680 --> 00:02:50,330
searching genes has opened up

00:02:48,710 --> 00:02:53,460
opportunities for cloud-based

00:02:50,330 --> 00:02:57,420
parallelization which could eventually

00:02:53,460 --> 00:02:59,070
be seen as new computing research we

00:02:57,420 --> 00:03:03,510
have Seminole cloud providers like

00:02:59,070 --> 00:03:06,150
Amazon Web Services Microsoft Azure as

00:03:03,510 --> 00:03:08,700
well large data center with massively

00:03:06,150 --> 00:03:17,520
parallel processing capabilities and the

00:03:08,700 --> 00:03:21,690
flexible usage so the cloud can be seen

00:03:17,520 --> 00:03:24,090
as a solution or maybe the ultimate

00:03:21,690 --> 00:03:30,060
solution for social media also useful

00:03:24,090 --> 00:03:34,590
for other domains like IOT but how to

00:03:30,060 --> 00:03:38,250
program the cloud this is an important

00:03:34,590 --> 00:03:42,180
question so we see in the left column

00:03:38,250 --> 00:03:46,170
the application domain and the the right

00:03:42,180 --> 00:03:50,610
column the model widely uses for small

00:03:46,170 --> 00:03:56,510
applications use Python or in your

00:03:50,610 --> 00:04:00,480
language plus the SDK provided for the

00:03:56,510 --> 00:04:03,780
cloud providers and easy to learn easy

00:04:00,480 --> 00:04:08,670
to use on the other hand big data use

00:04:03,780 --> 00:04:11,480
MapReduce or spark with high level of

00:04:08,670 --> 00:04:14,070
fault tolerance these are high level

00:04:11,480 --> 00:04:16,500
language and photo res and the high

00:04:14,070 --> 00:04:19,750
performs computer use a low-level

00:04:16,500 --> 00:04:24,160
program very efficient MPI

00:04:19,750 --> 00:04:30,440
but how about something in between this

00:04:24,160 --> 00:04:38,060
models on the other hand are you a

00:04:30,440 --> 00:04:39,620
program expect sorry waiting parallel

00:04:38,060 --> 00:04:42,669
program is not so natural and

00:04:39,620 --> 00:04:45,620
integrating cloud in your application

00:04:42,669 --> 00:04:47,450
may require to interface different

00:04:45,620 --> 00:04:53,600
program languages due to the nature of

00:04:47,450 --> 00:05:00,350
the hybrid secretion model so let make

00:04:53,600 --> 00:05:02,750
it simple as you know open PUA is a

00:05:00,350 --> 00:05:05,630
well-know API for developing parallel

00:05:02,750 --> 00:05:08,360
applications this is a directive based

00:05:05,630 --> 00:05:12,860
program made to be simple and no need to

00:05:08,360 --> 00:05:16,880
write the code but it's a so much a

00:05:12,860 --> 00:05:20,740
shared memory architecture so you just

00:05:16,880 --> 00:05:33,979
put a pragma in the code that you have

00:05:20,740 --> 00:05:39,169
to paralyze but from open p 4.0 and 4.5

00:05:33,979 --> 00:05:41,900
it is new open PS a varied model was

00:05:39,169 --> 00:05:45,169
designed to to programming accelerators

00:05:41,900 --> 00:05:46,820
but it it was designed keep in mind that

00:05:45,169 --> 00:05:48,979
the accelerators are connected to

00:05:46,820 --> 00:05:55,060
locally in your host target architecture

00:05:48,979 --> 00:05:58,370
module in this example the matrix

00:05:55,060 --> 00:06:03,830
multiplication we indicate the target

00:05:58,370 --> 00:06:07,360
device to disco this is acutely tiger

00:06:03,830 --> 00:06:11,180
device GPU and the D offloading the data

00:06:07,360 --> 00:06:19,270
sent to GPU a and B and they get the

00:06:11,180 --> 00:06:22,190
result in the matrix C so let's be brave

00:06:19,270 --> 00:06:24,190
to address this issue these work

00:06:22,190 --> 00:06:27,830
integrates open-pit directive

00:06:24,190 --> 00:06:29,690
cloud-based MapReduce park nodes and

00:06:27,830 --> 00:06:31,729
remote communication management into a

00:06:29,690 --> 00:06:33,710
single open P of loading

00:06:31,729 --> 00:06:36,219
device which can be seen by the

00:06:33,710 --> 00:06:43,430
programmers of available in this local

00:06:36,219 --> 00:06:46,400
computer this is only a modification for

00:06:43,430 --> 00:06:51,199
the programmer input point of view or

00:06:46,400 --> 00:06:56,809
program to achieve this problem just

00:06:51,199 --> 00:07:02,059
indicates this this new device so open

00:06:56,809 --> 00:07:04,999
p+ cloud is equal new or npcloud it's a

00:07:02,059 --> 00:07:08,300
new develop environment for cloud of

00:07:04,999 --> 00:07:13,300
loading that we call open McCloud it's

00:07:08,300 --> 00:07:16,789
open source it's available on the github

00:07:13,300 --> 00:07:20,240
is it's a relying on a custom 11 for a

00:07:16,789 --> 00:07:24,080
host to generate code for a host device

00:07:20,240 --> 00:07:31,759
right and on a patch patch is spark for

00:07:24,080 --> 00:07:35,419
target device from a point a program

00:07:31,759 --> 00:07:38,120
point of view just the program described

00:07:35,419 --> 00:07:41,509
the applications open P compile it with

00:07:38,120 --> 00:07:43,520
our custom ceiling instance Asia spark

00:07:41,509 --> 00:07:48,919
closed in your favorite cloud provide

00:07:43,520 --> 00:07:50,689
example Amazon Web service configure the

00:07:48,919 --> 00:07:53,029
oil if o'clock runtime with the

00:07:50,689 --> 00:07:58,249
credentials for assessing the cluster in

00:07:53,029 --> 00:08:02,779
the cloud and run the application in a

00:07:58,249 --> 00:08:05,209
graph model this is the the application

00:08:02,779 --> 00:08:07,849
so first the program configures the

00:08:05,209 --> 00:08:09,800
credentials of a spike to us the

00:08:07,849 --> 00:08:12,800
previous deployed on the cluster

00:08:09,800 --> 00:08:15,620
infrastructure then the program is is

00:08:12,800 --> 00:08:20,149
then started by the program in its local

00:08:15,620 --> 00:08:25,159
machine and iran's and to open piano

00:08:20,149 --> 00:08:27,649
tate code fragment is richard so a metal

00:08:25,159 --> 00:08:31,039
is then called to initialize the cloud

00:08:27,649 --> 00:08:34,909
advise note that the offloading is done

00:08:31,039 --> 00:08:36,860
dynamically so if the cloud is not

00:08:34,909 --> 00:08:38,070
available the computations performed

00:08:36,860 --> 00:08:43,110
locally

00:08:38,070 --> 00:08:45,240
okay then during times sends the input

00:08:43,110 --> 00:08:49,829
data required by the kernel as binary

00:08:45,240 --> 00:08:56,100
files to a cloud storage device after

00:08:49,829 --> 00:09:03,259
all the input data has transmitted send

00:08:56,100 --> 00:09:06,660
it to the the the storage the drive

00:09:03,259 --> 00:09:10,680
reads the input data from the cloud file

00:09:06,660 --> 00:09:14,100
compress it and broadcast to the work

00:09:10,680 --> 00:09:16,230
nodes to distribute the loop iteration

00:09:14,100 --> 00:09:22,500
across the spike word nodes which I

00:09:16,230 --> 00:09:24,750
charged to the computations next worker

00:09:22,500 --> 00:09:28,670
nodes run the mapping function that

00:09:24,750 --> 00:09:33,690
computes the loop body in parallel and

00:09:28,670 --> 00:09:36,300
the output of the loop is then

00:09:33,690 --> 00:09:40,380
compressed another collected through a

00:09:36,300 --> 00:09:44,940
reduce operation and stored in the cloud

00:09:40,380 --> 00:09:47,160
storage and finally the data strength

00:09:44,940 --> 00:09:49,889
transmitted back to the local code which

00:09:47,160 --> 00:09:52,190
then continues the execution on local

00:09:49,889 --> 00:09:52,190
machine

00:09:56,770 --> 00:10:08,210
so the model here we we have the fat by

00:10:04,130 --> 00:10:12,650
energy generated by LLVM which contains

00:10:08,210 --> 00:10:17,900
host own tag codes while the host code

00:10:12,650 --> 00:10:25,010
combined is the main function and the

00:10:17,900 --> 00:10:29,300
target codes are such code for CUDA code

00:10:25,010 --> 00:10:34,310
for example for GPU in the same in the

00:10:29,300 --> 00:10:39,950
same binary our solution requires an

00:10:34,310 --> 00:10:45,290
additional file to be generated the this

00:10:39,950 --> 00:10:49,040
code is describing the spark code that

00:10:45,290 --> 00:10:56,030
used in spec job and they compared to to

00:10:49,040 --> 00:11:00,050
jar binary did number to target a

00:10:56,030 --> 00:11:01,730
ganache of load and wrapper is

00:11:00,050 --> 00:11:04,340
responsible for detection of the

00:11:01,730 --> 00:11:07,250
available devices the creation of the

00:11:04,340 --> 00:11:10,130
device data environments the secure show

00:11:07,250 --> 00:11:14,270
of the right of load the function

00:11:10,130 --> 00:11:22,690
occurred to device type so you have also

00:11:14,270 --> 00:11:26,870
the cloud program the tag specific

00:11:22,690 --> 00:11:28,790
offload plugins performs the direct

00:11:26,870 --> 00:11:32,450
iteration with the device according to

00:11:28,790 --> 00:11:34,420
the architecture the architecture and

00:11:32,450 --> 00:11:38,720
provides serve switches initialization

00:11:34,420 --> 00:11:42,350
enters wish of input or output data in

00:11:38,720 --> 00:11:44,770
our in our case the cloud specific

00:11:42,350 --> 00:11:46,850
protein used to initialize the cluster

00:11:44,770 --> 00:11:51,610
transmitted offload data through the

00:11:46,850 --> 00:11:54,089
cloud and the submitted de spark jobs

00:11:51,610 --> 00:11:58,629
there

00:11:54,089 --> 00:12:02,410
Claude configurational file here this is

00:11:58,629 --> 00:12:06,009
the major difference between other

00:12:02,410 --> 00:12:10,420
solutions when you use a cloud to

00:12:06,009 --> 00:12:12,670
offload computing the compare the the

00:12:10,420 --> 00:12:15,790
the cloud the device cannot detect

00:12:12,670 --> 00:12:17,589
automatically like I said since they are

00:12:15,790 --> 00:12:21,399
not physically hosted at the local

00:12:17,589 --> 00:12:25,899
computer so the user has to provide

00:12:21,399 --> 00:12:30,879
another education information to the

00:12:25,899 --> 00:12:33,459
current application so the the plug-in

00:12:30,879 --> 00:12:36,490
reads at runtime the configuration file

00:12:33,459 --> 00:12:39,899
to properly set up the cloud device and

00:12:36,490 --> 00:12:42,790
to avoid to need to recompile the binary

00:12:39,899 --> 00:12:44,680
the log information the configuration

00:12:42,790 --> 00:12:47,170
file also contain the address of the

00:12:44,680 --> 00:12:54,399
spark driver as well the other of the

00:12:47,170 --> 00:12:56,230
clothes file storage so no need to

00:12:54,399 --> 00:12:58,240
recompile your application the code is

00:12:56,230 --> 00:13:02,620
part of our spark base load the device

00:12:58,240 --> 00:13:05,290
only change the configuration file this

00:13:02,620 --> 00:13:10,180
allow and use the portable load over the

00:13:05,290 --> 00:13:12,600
city Cloud Service because this is

00:13:10,180 --> 00:13:15,100
implemented as a modern infrastructure

00:13:12,600 --> 00:13:18,059
where the communication with the cloud

00:13:15,100 --> 00:13:21,730
to be customized for each existing cloud

00:13:18,059 --> 00:13:24,819
service by talking into the specifics

00:13:21,730 --> 00:13:28,389
first state for example storage service

00:13:24,819 --> 00:13:30,879
security mechanism etc for now our

00:13:28,389 --> 00:13:34,750
plug-in supports computation of laws for

00:13:30,879 --> 00:13:39,420
the Amazon Elastic Compute cloud ec2 we

00:13:34,750 --> 00:13:43,779
all support that of load for HDFS and

00:13:39,420 --> 00:13:45,939
Amazon simple storage service s3 this

00:13:43,779 --> 00:13:49,929
can be easily extend to support all the

00:13:45,939 --> 00:13:54,300
commissure Clause serves like Microsoft

00:13:49,929 --> 00:13:54,300
Azure cloud Google cloud etc

00:13:56,459 --> 00:14:03,699
the another top important top one

00:14:01,479 --> 00:14:06,219
central issue in distributed parallel

00:14:03,699 --> 00:14:08,829
execution models is to enable data

00:14:06,219 --> 00:14:11,429
partition mechanism that assign a

00:14:08,829 --> 00:14:14,769
specific data block to the worker nodes

00:14:11,429 --> 00:14:17,409
by doing this program consider benefit

00:14:14,769 --> 00:14:20,369
from locality does reducing the overhead

00:14:17,409 --> 00:14:24,099
of moving data around the

00:14:20,369 --> 00:14:26,559
interconnection networks automatically

00:14:24,099 --> 00:14:28,179
data partition is hard task which cannot

00:14:26,559 --> 00:14:31,719
typically be achieved solid by the

00:14:28,179 --> 00:14:33,399
compiler or runtime in most applications

00:14:31,719 --> 00:14:37,359
the programming knowledge is essential

00:14:33,399 --> 00:14:39,699
to enable an efficient data allocation

00:14:37,359 --> 00:14:42,489
unfortunate the open piece standard does

00:14:39,699 --> 00:14:45,999
not have directive specially designed

00:14:42,489 --> 00:14:51,599
for data partitioning with of waiting of

00:14:45,999 --> 00:14:51,599
loaded region so let it make it possible

00:14:51,629 --> 00:15:01,089
we extended the use of open p target

00:14:56,469 --> 00:15:03,399
data map directive so as to allow the

00:15:01,089 --> 00:15:06,959
programmer to express the Dasia data

00:15:03,399 --> 00:15:13,989
distribution to the cloud sparknotes no

00:15:06,959 --> 00:15:24,429
syntax modification was required since

00:15:13,989 --> 00:15:27,149
the how can I say this this is a

00:15:24,429 --> 00:15:31,059
construction inside the another

00:15:27,149 --> 00:15:35,769
pragma he is undefined behavior by the

00:15:31,059 --> 00:15:40,959
current on pimpies specification so you

00:15:35,769 --> 00:15:43,329
use that to indicate after the true from

00:15:40,959 --> 00:15:45,129
specify of the maple and map directives

00:15:43,329 --> 00:15:52,299
to the first element of the partitioned

00:15:45,129 --> 00:15:55,989
data block followed by by column and in

00:15:52,299 --> 00:15:58,269
the last elements the the first element

00:15:55,989 --> 00:16:01,809
and the backronym for the last element

00:15:58,269 --> 00:16:04,889
of the corresponding block in this

00:16:01,809 --> 00:16:08,549
example we are partition the matrix a

00:16:04,889 --> 00:16:12,119
to distribute a quote of the idiots to

00:16:08,549 --> 00:16:15,480
compare to the parts of matrix e not

00:16:12,119 --> 00:16:22,970
that the the babe meters are not

00:16:15,480 --> 00:16:26,759
positioned so if you look at this model

00:16:22,970 --> 00:16:29,369
first we read inputs a and B from the

00:16:26,759 --> 00:16:34,799
store at the cloud storage then

00:16:29,369 --> 00:16:36,689
broadcast and partition Abebe generated

00:16:34,799 --> 00:16:42,749
the set of all values taken by the loop

00:16:36,689 --> 00:16:47,359
index and the distribute a in the is

00:16:42,749 --> 00:16:53,600
lies a and under de the the index

00:16:47,359 --> 00:16:58,100
corresponding index map look body

00:16:53,600 --> 00:17:01,799
function to take value of the loop index

00:16:58,100 --> 00:17:06,510
then send back of a parts of see the

00:17:01,799 --> 00:17:09,480
computed reconstruct the final version

00:17:06,510 --> 00:17:16,439
of C and the right seat of the cloud

00:17:09,480 --> 00:17:21,559
storage is small still cool for this

00:17:16,439 --> 00:17:25,709
example here the really put four array

00:17:21,559 --> 00:17:28,260
generate distributed list using rdd's

00:17:25,709 --> 00:17:32,600
the Spiker runtime data structure called

00:17:28,260 --> 00:17:35,639
the resilient distributed date set

00:17:32,600 --> 00:17:39,289
patrician data and distribute loop

00:17:35,639 --> 00:17:42,620
iterations using j'ni lock body

00:17:39,289 --> 00:17:47,110
reconstructed output and write back the

00:17:42,620 --> 00:17:50,230
the result what the result back ok

00:17:47,110 --> 00:17:54,070
another important point is optimizing

00:17:50,230 --> 00:17:56,289
the granularity when the number of

00:17:54,070 --> 00:17:59,710
iterations much larger than the number

00:17:56,289 --> 00:18:02,519
of course and other hat is possible due

00:17:59,710 --> 00:18:06,360
to the great number of Gina Gina calls

00:18:02,519 --> 00:18:09,879
so our strategy is to apply tiny

00:18:06,360 --> 00:18:12,999
optimization into the loop with block

00:18:09,879 --> 00:18:20,619
size defined in in run time by the

00:18:12,999 --> 00:18:28,809
number of the the course so the this

00:18:20,619 --> 00:18:31,720
user partition is adjusted ok we did a

00:18:28,809 --> 00:18:35,710
lot of experiments we perform a set of

00:18:31,720 --> 00:18:38,379
experiments using simple laptop like

00:18:35,710 --> 00:18:45,580
this and the Amazon Web service data

00:18:38,379 --> 00:18:51,369
center here easy tool means Amazon a

00:18:45,580 --> 00:18:54,940
lashe computer club using a set of well

00:18:51,369 --> 00:18:59,889
no benchmarks like polly berry bar boy

00:18:54,940 --> 00:19:01,809
or Roedean etc here I will show you one

00:18:59,889 --> 00:19:09,460
example of the matrix multiplication

00:19:01,809 --> 00:19:13,059
this case stood using choo-choo matrix

00:19:09,460 --> 00:19:18,359
for one gigabyte of both floating-point

00:19:13,059 --> 00:19:20,559
I space matrix and a dense matrix so in

00:19:18,359 --> 00:19:24,029
comparing time the execution time for

00:19:20,559 --> 00:19:31,389
sequential for this matrix is a 3 point

00:19:24,029 --> 00:19:34,629
1/2 hours and in 256 cores we have three

00:19:31,389 --> 00:19:39,909
to eight ministry through sparse matrix

00:19:34,629 --> 00:19:42,369
eight minutes to venison matrix so we

00:19:39,909 --> 00:19:47,859
note that we have an increasing speed up

00:19:42,369 --> 00:19:52,960
it from 27 percent 27 times to six eight

00:19:47,859 --> 00:19:56,620
times on 256 cores

00:19:52,960 --> 00:20:02,740
another point a important point is the

00:19:56,620 --> 00:20:04,900
communication of the head is it's almost

00:20:02,740 --> 00:20:09,520
constant but of course the data time

00:20:04,900 --> 00:20:11,909
matter we observe that the space matter

00:20:09,520 --> 00:20:15,150
is the communication overhead this is

00:20:11,909 --> 00:20:17,559
less than dense matrix because the

00:20:15,150 --> 00:20:23,799
compression compression compression

00:20:17,559 --> 00:20:25,090
sorry but it almost constant in the Pend

00:20:23,799 --> 00:20:30,539
of the number of the course

00:20:25,090 --> 00:20:35,710
- it's expected the course that run the

00:20:30,539 --> 00:20:41,289
application of course we have limitation

00:20:35,710 --> 00:20:44,740
of this model the code regions of load

00:20:41,289 --> 00:20:46,390
to the to the cloud today we support

00:20:44,740 --> 00:20:49,450
president for with nested loops

00:20:46,390 --> 00:20:54,059
rejection Clause do not support a tank

00:20:49,450 --> 00:20:57,010
flush very critical or mastered and will

00:20:54,059 --> 00:20:58,870
plan to support blocks of sequential

00:20:57,010 --> 00:21:06,549
code a parallel for inside the

00:20:58,870 --> 00:21:11,490
sequential loop another thing cluster

00:21:06,549 --> 00:21:15,370
program sometimes is not adapted a

00:21:11,490 --> 00:21:18,880
floating to the closest not adapted but

00:21:15,370 --> 00:21:22,149
you will not need to rule only in a

00:21:18,880 --> 00:21:24,549
local computer because most are

00:21:22,149 --> 00:21:26,649
communications sometimes are expensive

00:21:24,549 --> 00:21:29,070
so you can rule the application direct

00:21:26,649 --> 00:21:32,289
phones back drive connect with essays

00:21:29,070 --> 00:21:35,470
SSH transfer application configure

00:21:32,289 --> 00:21:37,840
Olympic cloud runtime like say before

00:21:35,470 --> 00:21:40,059
and run it communication between the

00:21:37,840 --> 00:21:42,970
binary inspire handsomeness use the

00:21:40,059 --> 00:21:48,610
local file is rate to program a cluster

00:21:42,970 --> 00:21:52,460
from C C++ okay

00:21:48,610 --> 00:21:56,150
so my conclusion is simple parallel

00:21:52,460 --> 00:21:58,460
programming model like C C++ and open

00:21:56,150 --> 00:22:01,120
pejorative no need to rewrite rewrite

00:21:58,460 --> 00:22:01,120
your codes

00:22:07,030 --> 00:22:11,110
OPP addressed the problem of flawed

00:22:09,039 --> 00:22:13,419
computational cloud infrastructure so as

00:22:11,110 --> 00:22:16,600
to benefit from a quad unlimited

00:22:13,419 --> 00:22:18,610
parallel processing capabilities in

00:22:16,600 --> 00:22:21,070
order to ease the utilization of the

00:22:18,610 --> 00:22:22,690
cloud we design a runtime that offloaded

00:22:21,070 --> 00:22:25,480
maps and scheduled computation

00:22:22,690 --> 00:22:27,669
automatically our approach allows

00:22:25,480 --> 00:22:30,510
portables over commercial cloud and

00:22:27,669 --> 00:22:33,490
service and provide private clouds

00:22:30,510 --> 00:22:37,179
indeed by using a configuration file or

00:22:33,490 --> 00:22:40,030
our runtimes is able to easily switch

00:22:37,179 --> 00:22:43,419
from one cloud infrastructure to another

00:22:40,030 --> 00:22:45,039
without recompiling the binary the

00:22:43,419 --> 00:22:46,929
communication with the clouds to

00:22:45,039 --> 00:22:49,030
ourselves and the execution with the

00:22:46,929 --> 00:22:51,730
sparklers is handled automatically

00:22:49,030 --> 00:23:00,340
occurred to the given to the

00:22:51,730 --> 00:23:04,360
configuration the experiments

00:23:00,340 --> 00:23:10,120
demonstrated viability of the solution

00:23:04,360 --> 00:23:15,880
and promise performance and the the

00:23:10,120 --> 00:23:17,799
future works to to experiment machine

00:23:15,880 --> 00:23:22,650
layer and a face recognition and blend

00:23:17,799 --> 00:23:30,450
the rendering took plus I think this I

00:23:22,650 --> 00:23:30,450
have to talk so thank you questions

00:23:43,760 --> 00:23:46,810
I tried to

00:23:58,500 --> 00:24:01,750
[Music]

00:24:04,620 --> 00:24:11,730
yes I understand your question Python is

00:24:08,370 --> 00:24:14,909
easy to learn and to use with this

00:24:11,730 --> 00:24:18,090
infrastructure but I think this of

00:24:14,909 --> 00:24:21,419
course I talked about in the name of the

00:24:18,090 --> 00:24:26,159
heavy not behind but I think is this

00:24:21,419 --> 00:24:30,840
solution brings the c c++ developed for

00:24:26,159 --> 00:24:34,860
the the cloud because today programming

00:24:30,840 --> 00:24:41,309
with this language is quite difficult in

00:24:34,860 --> 00:24:47,880
this but i have no information to do for

00:24:41,309 --> 00:24:50,850
you if this is more efficient or no

00:24:47,880 --> 00:24:56,549
compare with the Python because at all

00:24:50,850 --> 00:25:00,419
is I think it's use the libraries prayer

00:24:56,549 --> 00:25:03,350
compilers and very optimizing the each

00:25:00,419 --> 00:25:06,779
clock no I thought it's only the

00:25:03,350 --> 00:25:09,770
interface interface I think I don't know

00:25:06,779 --> 00:25:09,770
I'm not sure about

00:25:26,650 --> 00:25:57,830
this color this color I apologize but I

00:25:48,070 --> 00:26:00,830
I don't know exactly yes this question I

00:25:57,830 --> 00:26:06,049
need to have here to I recommend you to

00:26:00,830 --> 00:26:09,710
to send a I'm a for have a okay because

00:26:06,049 --> 00:26:13,390
this is the their project and this

00:26:09,710 --> 00:26:16,390
question I I have no no answer to that

00:26:13,390 --> 00:26:16,390
sorry

00:26:22,470 --> 00:26:26,150

YouTube URL: https://www.youtube.com/watch?v=845ra2tRKjI


