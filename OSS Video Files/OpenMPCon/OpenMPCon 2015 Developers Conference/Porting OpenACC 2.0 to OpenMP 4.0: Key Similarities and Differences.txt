Title: Porting OpenACC 2.0 to OpenMP 4.0: Key Similarities and Differences
Publication date: 2015-12-13
Playlist: OpenMPCon 2015 Developers Conference
Description: 
	Oscar Hernandez, Oak Ridge National Laboratory
OpenMPCon 2015 - Aachen Germany - September 2015
Slides at http://openmpcon.org/wp-content/uploads/openmpcon2015-oscar-hernandez-portingacc.pdf

Abstract: The importance of computational accelerator technology for the future of high performance computing is widely acknowledged.  Programmability, performance portability and developer productivity for these systems is a topic of growing importance.In this paper we examine two emerging specifications offering the promise of performance portability for codes targeting accelerator-based computing systems: OpenMP 4.0 and OpenACC 2.0.We show how these two standards compare, both in similarities and differences.

We present code comparisons to show how each API is used to parallelize representative code fragments. Furthermore, we give guidelines for developers wishing to convert codes from OpenACC 2.0 to OpenMP 4.0.
Captions: 
	00:00:04,830 --> 00:00:11,709
hello first I want to introduce myself

00:00:07,709 --> 00:00:16,840
my name is oscar hernandez I work at oak

00:00:11,709 --> 00:00:19,300
ridge national lab and there I am in

00:00:16,840 --> 00:00:21,220
charge of the programming models for the

00:00:19,300 --> 00:00:26,970
next generation systems we will have

00:00:21,220 --> 00:00:30,789
their so as you can guess a is a very a

00:00:26,970 --> 00:00:32,349
challenging job because with the new

00:00:30,789 --> 00:00:35,289
trends of the new systems that we're

00:00:32,349 --> 00:00:38,409
getting and how the industry is evolving

00:00:35,289 --> 00:00:40,600
for exascale we're kind of like looking

00:00:38,409 --> 00:00:42,519
for what's the next programming model

00:00:40,600 --> 00:00:46,420
that we want to other a to start to use

00:00:42,519 --> 00:00:49,390
and basically a we're looking at new

00:00:46,420 --> 00:00:55,710
ideas a we are like we are very helpful

00:00:49,390 --> 00:01:02,499
in the support of open mp4 exascale and

00:00:55,710 --> 00:01:04,330
the more we see is the better the new

00:01:02,499 --> 00:01:07,240
feature that we see in open mp4 is

00:01:04,330 --> 00:01:11,350
starting to become very interesting to

00:01:07,240 --> 00:01:13,000
us and we see that opening p5 is going

00:01:11,350 --> 00:01:14,800
to be something that is going to be

00:01:13,000 --> 00:01:17,340
really really interested in that could

00:01:14,800 --> 00:01:22,060
be a programming model that we could use

00:01:17,340 --> 00:01:25,120
portable across different systems so for

00:01:22,060 --> 00:01:30,850
today talk a I'm going to focus a little

00:01:25,120 --> 00:01:34,690
bit on a our experience on a SLE rate of

00:01:30,850 --> 00:01:36,370
directives and especially in the

00:01:34,690 --> 00:01:41,410
technology that we have been using at

00:01:36,370 --> 00:01:43,600
oakridge with its open ACC and how r

00:01:41,410 --> 00:01:46,540
whatever plans for transitioning from

00:01:43,600 --> 00:01:50,320
opening CC to open mp4 and what will

00:01:46,540 --> 00:01:54,340
make us more comfortable to do that in

00:01:50,320 --> 00:01:56,590
the future in the near future and and

00:01:54,340 --> 00:01:59,800
then we do not give you some experience

00:01:56,590 --> 00:02:03,430
that we have about the directives I were

00:01:59,800 --> 00:02:06,250
using them and basically how to map from

00:02:03,430 --> 00:02:08,500
open acc to open mp4 and what features

00:02:06,250 --> 00:02:09,910
are very straightforward to do and what

00:02:08,500 --> 00:02:12,570
things are missing

00:02:09,910 --> 00:02:15,040
and what are the challenges that we see

00:02:12,570 --> 00:02:22,420
when we start to evaluate the directives

00:02:15,040 --> 00:02:24,160
um so I will go for my next slide em so

00:02:22,420 --> 00:02:26,500
this is kind of like the landscape of

00:02:24,160 --> 00:02:29,380
the supercomputers we're seeing and

00:02:26,500 --> 00:02:34,300
immense a number of parallelism and the

00:02:29,380 --> 00:02:38,140
node and as we move forward we're moving

00:02:34,300 --> 00:02:43,180
more to heterogeneity a for example we

00:02:38,140 --> 00:02:48,430
started with Titan and which is a a 27

00:02:43,180 --> 00:02:50,770
petaflop a theoretical a a performance

00:02:48,430 --> 00:02:53,770
and then we're moving to our next

00:02:50,770 --> 00:02:57,070
generation system with corral which is a

00:02:53,770 --> 00:02:59,380
consummate which is about five times to

00:02:57,070 --> 00:03:01,570
ten times faster than Titan we still

00:02:59,380 --> 00:03:05,680
looking at that originated in the system

00:03:01,570 --> 00:03:07,750
and this heterogeneity aspect that we're

00:03:05,680 --> 00:03:12,390
seeing here is probably going to stay

00:03:07,750 --> 00:03:15,490
for with us for some time so basically a

00:03:12,390 --> 00:03:18,160
what the challenges that you know we

00:03:15,490 --> 00:03:23,380
have five years of experience of working

00:03:18,160 --> 00:03:26,880
on Titan and we develop a technology

00:03:23,380 --> 00:03:29,350
stir for help our applications to port a

00:03:26,880 --> 00:03:31,990
to exploit a things in this new system

00:03:29,350 --> 00:03:35,530
but as we move to corral things are

00:03:31,990 --> 00:03:38,860
getting more the complexity to the user

00:03:35,530 --> 00:03:40,810
is becoming more challenging and as we

00:03:38,860 --> 00:03:43,150
start addressing things with directives

00:03:40,810 --> 00:03:46,090
or programming models this is something

00:03:43,150 --> 00:03:48,130
that we're looking forward to to see in

00:03:46,090 --> 00:03:50,980
terms of open and detective based

00:03:48,130 --> 00:03:53,440
programming in terms of OpenMP am to see

00:03:50,980 --> 00:03:57,070
we can help the user manage the

00:03:53,440 --> 00:04:01,140
complexity of programming systems em so

00:03:57,070 --> 00:04:04,239
as a result a we have put a lot of

00:04:01,140 --> 00:04:12,580
emphasis or a lot of resources in terms

00:04:04,239 --> 00:04:15,220
of em open a sec and open mp4 so why do

00:04:12,580 --> 00:04:17,680
we want to the challenges that we're

00:04:15,220 --> 00:04:19,630
seeing for example in in this program

00:04:17,680 --> 00:04:20,890
these next generation systems are you

00:04:19,630 --> 00:04:22,330
know these five challenges were

00:04:20,890 --> 00:04:24,440
parallelism at regina

00:04:22,330 --> 00:04:27,940
how we're going to deal with the memory

00:04:24,440 --> 00:04:30,350
hierarchies resilience and power however

00:04:27,940 --> 00:04:32,390
the immediate challenges that we see

00:04:30,350 --> 00:04:35,240
with the accelerator detectives is how

00:04:32,390 --> 00:04:38,300
to achieve portability so right now for

00:04:35,240 --> 00:04:40,760
example we have this system based ours

00:04:38,300 --> 00:04:43,610
based on GPUs and we have systems based

00:04:40,760 --> 00:04:45,830
on see on files at other labs and how

00:04:43,610 --> 00:04:47,690
can we write code poor performance

00:04:45,830 --> 00:04:49,670
portable across these two different

00:04:47,690 --> 00:04:52,190
systems and can the directives really

00:04:49,670 --> 00:04:55,220
help us and that's really really

00:04:52,190 --> 00:04:59,180
important for us in the portability

00:04:55,220 --> 00:05:00,980
aspect and a because that's going to

00:04:59,180 --> 00:05:03,770
help us to maintain the applications

00:05:00,980 --> 00:05:07,480
make the applications more easy to

00:05:03,770 --> 00:05:09,410
program a more maintainable a

00:05:07,480 --> 00:05:12,530
application scientists are going to

00:05:09,410 --> 00:05:15,320
become a happy to see that their cause

00:05:12,530 --> 00:05:17,060
are not with without many restructuring

00:05:15,320 --> 00:05:18,440
of their applications if they can still

00:05:17,060 --> 00:05:21,800
get cheap portability that would be

00:05:18,440 --> 00:05:24,320
great and then we have a lot of Industry

00:05:21,800 --> 00:05:28,730
and resources that we our goal is to see

00:05:24,320 --> 00:05:32,240
we can go in that direction currently we

00:05:28,730 --> 00:05:35,290
have a the programming model the most of

00:05:32,240 --> 00:05:39,380
our applications uses his NPI plus X but

00:05:35,290 --> 00:05:42,320
we are starting to see that a in these

00:05:39,380 --> 00:05:46,040
next generation systems were you know a

00:05:42,320 --> 00:05:48,830
a in some cases some of the nodes are

00:05:46,040 --> 00:05:52,010
getting more powerful and cost of moving

00:05:48,830 --> 00:05:53,690
data is becoming more expensive a we're

00:05:52,010 --> 00:05:55,490
starting to think that maybe in the

00:05:53,690 --> 00:05:58,130
future we're going to start seeing more

00:05:55,490 --> 00:06:03,040
of instead of asking NPI plus X is maybe

00:05:58,130 --> 00:06:06,820
opening p plus X where X can be a a

00:06:03,040 --> 00:06:09,950
big-ass model or communication as a

00:06:06,820 --> 00:06:15,940
communication library or a nexus Cal a

00:06:09,950 --> 00:06:19,460
runtime and this may help us to really a

00:06:15,940 --> 00:06:21,230
air if a parent we can help us to manage

00:06:19,460 --> 00:06:23,780
the complexity of the of the nose that

00:06:21,230 --> 00:06:25,810
will be very good but at the same time

00:06:23,780 --> 00:06:30,050
we have to think about the future and

00:06:25,810 --> 00:06:31,490
opening ping is to evolve to a soup to

00:06:30,050 --> 00:06:34,640
allow the a to exploit all the

00:06:31,490 --> 00:06:35,760
characteristics of the node and because

00:06:34,640 --> 00:06:37,080
of these we

00:06:35,760 --> 00:06:39,090
see that the exascale programming

00:06:37,080 --> 00:06:42,750
environments are certain tumor emerge

00:06:39,090 --> 00:06:45,960
and a lot of experiences will help us to

00:06:42,750 --> 00:06:49,170
drive a listing in the case of our

00:06:45,960 --> 00:06:52,530
system some it it will help us to define

00:06:49,170 --> 00:06:54,330
what we need for excess Cal and during

00:06:52,530 --> 00:06:58,350
this Corral timeframe where we're going

00:06:54,330 --> 00:07:00,180
to be a working towards opening p5 we

00:06:58,350 --> 00:07:02,010
have to think about those challenges and

00:07:00,180 --> 00:07:03,870
what things we need to address there so

00:07:02,010 --> 00:07:06,690
a so one of the things that we're

00:07:03,870 --> 00:07:09,240
starting to look in the applications is

00:07:06,690 --> 00:07:11,880
that hey we're trying to look at this

00:07:09,240 --> 00:07:15,090
aspect of portability and we need to

00:07:11,880 --> 00:07:16,710
find models that can help us to write

00:07:15,090 --> 00:07:18,720
applications that are architecture

00:07:16,710 --> 00:07:22,950
independent with very high level

00:07:18,720 --> 00:07:27,900
constructs a to represent data or were

00:07:22,950 --> 00:07:31,040
the compositions some people are working

00:07:27,900 --> 00:07:36,180
on in this area at the different labs a

00:07:31,040 --> 00:07:37,830
using dsl's and so on and then we need a

00:07:36,180 --> 00:07:40,580
person pull one aspect of the

00:07:37,830 --> 00:07:43,890
application that needs to be lower and

00:07:40,580 --> 00:07:47,280
into something that is a adaptable and

00:07:43,890 --> 00:07:50,100
portable a and this is something area of

00:07:47,280 --> 00:07:54,930
research that has been a explorer in

00:07:50,100 --> 00:07:57,120
terms of X escal run times that we have

00:07:54,930 --> 00:07:58,530
seen a about this is still in the

00:07:57,120 --> 00:08:00,660
research areas and there's a lot of

00:07:58,530 --> 00:08:03,150
lessons that we can learn and ideally

00:08:00,660 --> 00:08:05,460
what we want is to reduce this

00:08:03,150 --> 00:08:09,060
complexity of managing all these

00:08:05,460 --> 00:08:13,140
different resources in the nodes a so

00:08:09,060 --> 00:08:15,930
that him it can help a program make the

00:08:13,140 --> 00:08:18,600
application mode a easy to program but

00:08:15,930 --> 00:08:23,910
at the same time a being portable across

00:08:18,600 --> 00:08:25,140
architectures and then we have a a you

00:08:23,910 --> 00:08:26,820
know the area could be map the

00:08:25,140 --> 00:08:28,740
parallelism to the architecture and the

00:08:26,820 --> 00:08:32,700
square we use something like for example

00:08:28,740 --> 00:08:36,360
OpenMP a where we started to optimize

00:08:32,700 --> 00:08:38,580
more to her than architecture and one

00:08:36,360 --> 00:08:40,770
thing that we've seen is that opening

00:08:38,580 --> 00:08:42,150
peak is helping us to generate the code

00:08:40,770 --> 00:08:45,240
that we need for these different

00:08:42,150 --> 00:08:47,470
accelerators and see on files it has a

00:08:45,240 --> 00:08:49,720
capability to be in tune our

00:08:47,470 --> 00:08:52,630
but at the same time it has to become

00:08:49,720 --> 00:08:54,880
more smarter and maybe there is some

00:08:52,630 --> 00:08:56,680
lessons that we can learn from for

00:08:54,880 --> 00:09:01,360
example the research on excess called

00:08:56,680 --> 00:09:04,090
run times so that we can aim aim adapt

00:09:01,360 --> 00:09:07,870
these features in openmp for example

00:09:04,090 --> 00:09:11,770
Eric's talk that talk about all these m

00:09:07,870 --> 00:09:14,230
tasking and priorities and tasks all

00:09:11,770 --> 00:09:18,250
those things that make the wrong time

00:09:14,230 --> 00:09:21,970
scheduling more efficient that sort of

00:09:18,250 --> 00:09:23,800
things that we need and then a we when

00:09:21,970 --> 00:09:25,960
we want to see how you know what

00:09:23,800 --> 00:09:29,020
features we need an opening p to support

00:09:25,960 --> 00:09:30,820
to to go you know to support more

00:09:29,020 --> 00:09:33,190
high-level constructs for poor

00:09:30,820 --> 00:09:35,740
parallelism but at the same time keep

00:09:33,190 --> 00:09:38,080
opening p in a way that can be tunable

00:09:35,740 --> 00:09:42,340
to get the performance that we need him

00:09:38,080 --> 00:09:45,250
and the key thing here is can we make

00:09:42,340 --> 00:09:49,720
the application programmers life easier

00:09:45,250 --> 00:09:52,240
is it possible and if opening pekin

00:09:49,720 --> 00:09:57,640
offers that has he divorced for the

00:09:52,240 --> 00:10:01,330
future aim so we start to be directed

00:09:57,640 --> 00:10:07,120
based programming a directives with a

00:10:01,330 --> 00:10:12,640
key strategy for us it was started when

00:10:07,120 --> 00:10:15,040
we put the RFP for titan we wanted to

00:10:12,640 --> 00:10:20,110
find a programming model that was easy

00:10:15,040 --> 00:10:24,280
to hate to program GPUs a because of the

00:10:20,110 --> 00:10:27,190
time to deliver the Titan and we needed

00:10:24,280 --> 00:10:30,580
a direct a directive based programming

00:10:27,190 --> 00:10:32,980
model that work very fast and basically

00:10:30,580 --> 00:10:36,190
what's available to our users and that

00:10:32,980 --> 00:10:40,720
was the main origin of why we have open

00:10:36,190 --> 00:10:42,550
acc however a go into the future we want

00:10:40,720 --> 00:10:46,030
to move forward into something more

00:10:42,550 --> 00:10:49,120
standard like opening before a where we

00:10:46,030 --> 00:10:52,480
start seeing more support and compilers

00:10:49,120 --> 00:10:54,220
and isn't something that encourages so

00:10:52,480 --> 00:10:56,230
that we can move our existing

00:10:54,220 --> 00:10:57,440
applications within an open a cc to open

00:10:56,230 --> 00:11:02,120
mp4

00:10:57,440 --> 00:11:04,580
em we have a still a large community of

00:11:02,120 --> 00:11:08,480
users of open ecstasy users in the lab a

00:11:04,580 --> 00:11:13,820
and most of them are a there because

00:11:08,480 --> 00:11:17,360
compiler are eluted more a mature for

00:11:13,820 --> 00:11:22,130
for GPUs a poor supporting opening

00:11:17,360 --> 00:11:23,870
system GPUs and but the transition we

00:11:22,130 --> 00:11:25,700
starting to move it two to as

00:11:23,870 --> 00:11:30,470
applications people to move to open mp4

00:11:25,700 --> 00:11:33,200
and in that transition will happen as we

00:11:30,470 --> 00:11:37,460
get better compilers to support opening

00:11:33,200 --> 00:11:39,260
before GPUs and to do this we started to

00:11:37,460 --> 00:11:42,740
understand what does it takes to move

00:11:39,260 --> 00:11:44,420
open a cc to open it before and what are

00:11:42,740 --> 00:11:49,310
the technical challenges if there any

00:11:44,420 --> 00:11:51,770
and basically a how can we achieve a

00:11:49,310 --> 00:11:54,560
performance portability with opening p4

00:11:51,770 --> 00:12:02,750
and those are they the main things that

00:11:54,560 --> 00:12:04,940
that we would like to talk today and the

00:12:02,750 --> 00:12:07,460
main differences when we are starting to

00:12:04,940 --> 00:12:10,880
convert our applications with open sec

00:12:07,460 --> 00:12:16,280
to opening before is that a is this

00:12:10,880 --> 00:12:19,460
aspect of the the philosophy of the

00:12:16,280 --> 00:12:20,900
directives a one bin a descriptive

00:12:19,460 --> 00:12:25,250
versus the other one being prescriptive

00:12:20,900 --> 00:12:27,400
so there are certain choices a for some

00:12:25,250 --> 00:12:31,670
plain open acc certain detectives that

00:12:27,400 --> 00:12:33,290
can be that can the compiler chooses you

00:12:31,670 --> 00:12:36,860
know what's the best way to translate

00:12:33,290 --> 00:12:40,490
into the GPUs wherein opening before we

00:12:36,860 --> 00:12:43,700
may need to ask the user to make some of

00:12:40,490 --> 00:12:46,460
those choices aim to translate them

00:12:43,700 --> 00:12:50,089
efficiently to the architecture however

00:12:46,460 --> 00:12:52,460
we still need to understand you know

00:12:50,089 --> 00:12:55,820
what are those choices based on the

00:12:52,460 --> 00:12:58,760
implementations opening before and to

00:12:55,820 --> 00:13:01,760
see how we can map one to the other a

00:12:58,760 --> 00:13:05,020
programming model a many of the

00:13:01,760 --> 00:13:09,530
constructs have one-to-one mappings and

00:13:05,020 --> 00:13:13,010
we can think about something like open a

00:13:09,530 --> 00:13:15,980
cc is kind of like writing opening

00:13:13,010 --> 00:13:18,230
before in in terms of opening the disk a

00:13:15,980 --> 00:13:21,710
little bit like lowering open sse2

00:13:18,230 --> 00:13:24,170
openmp all low is so where you can do

00:13:21,710 --> 00:13:25,820
certain choices on how you're going to

00:13:24,170 --> 00:13:29,750
distribute the work across the different

00:13:25,820 --> 00:13:31,520
units in the in the GPU a some

00:13:29,750 --> 00:13:34,460
constructs are present in one

00:13:31,520 --> 00:13:36,800
programming model intending not in the

00:13:34,460 --> 00:13:39,410
other one but both both these two were

00:13:36,800 --> 00:13:42,920
something to to get very close to each

00:13:39,410 --> 00:13:45,560
other making it easy to transfer to move

00:13:42,920 --> 00:13:49,180
from one to the other one in at some

00:13:45,560 --> 00:13:51,530
point they're very subtle differences a

00:13:49,180 --> 00:13:54,230
basically it's mostly the freedom in the

00:13:51,530 --> 00:13:57,710
compiler on how to map the parallel

00:13:54,230 --> 00:13:59,990
listening to the architecture and in

00:13:57,710 --> 00:14:03,020
opening p for the user has more control

00:13:59,990 --> 00:14:06,470
over how to do this this is just a

00:14:03,020 --> 00:14:10,520
slight summarizing a what we are seeing

00:14:06,470 --> 00:14:13,370
in opening p 2 dot 0 vs opening before

00:14:10,520 --> 00:14:16,340
and we startin to see that most of the

00:14:13,370 --> 00:14:20,060
directive supporting in open a cc is

00:14:16,340 --> 00:14:22,850
also supported in opening p for a or our

00:14:20,060 --> 00:14:25,430
part of the opening p for dot one draft

00:14:22,850 --> 00:14:29,150
and that definitely will make things

00:14:25,430 --> 00:14:32,570
easier to move a still there are certain

00:14:29,150 --> 00:14:37,000
directives that r is still not supported

00:14:32,570 --> 00:14:41,960
in OpenMP a like the cache directive or

00:14:37,000 --> 00:14:44,150
the tile directive and these are things

00:14:41,960 --> 00:14:46,850
that maybe it's gonna it could be

00:14:44,150 --> 00:14:49,880
something useful for performance and

00:14:46,850 --> 00:14:53,060
perhaps a it will be something useful

00:14:49,880 --> 00:14:55,820
for opening v5m right now we're just

00:14:53,060 --> 00:14:58,790
kind of like relying on a smart

00:14:55,820 --> 00:15:01,730
compilers to optimize for the memory

00:14:58,790 --> 00:15:03,530
hierarchies and we hope that we will get

00:15:01,730 --> 00:15:08,019
good compiler implementations to do that

00:15:03,530 --> 00:15:17,970
so that we can get the performance

00:15:08,019 --> 00:15:21,730
in the challenge a mostly is a trying to

00:15:17,970 --> 00:15:24,910
to write portable code with this new set

00:15:21,730 --> 00:15:28,029
of directives and seeing how we can

00:15:24,910 --> 00:15:32,529
translate a different directives from

00:15:28,029 --> 00:15:34,540
opening CC to open it before so aim so

00:15:32,529 --> 00:15:38,499
we developed a sort of some guidelines

00:15:34,540 --> 00:15:40,089
and how to do that the process is not as

00:15:38,499 --> 00:15:41,980
complicated as we thought at the

00:15:40,089 --> 00:15:49,860
beginning and I just want to go through

00:15:41,980 --> 00:15:49,860
it one by one yes go ahead

00:15:58,259 --> 00:16:04,499
a so yeah so this is where when you I'm

00:16:03,359 --> 00:16:08,189
going to talk a little bit more about

00:16:04,499 --> 00:16:09,600
that eh but this is square a parallel

00:16:08,189 --> 00:16:12,509
loopy napanee CCS a little bit

00:16:09,600 --> 00:16:15,209
descriptive and leaves the programmer

00:16:12,509 --> 00:16:19,619
that the compiler make choice on how to

00:16:15,209 --> 00:16:26,359
map the loops basically on gangs vector

00:16:19,619 --> 00:16:26,359
or workers and in opening before they

00:16:29,529 --> 00:16:32,970
yes yes

00:16:49,060 --> 00:16:52,510
yes yes

00:16:54,829 --> 00:16:57,829
this

00:17:02,460 --> 00:17:10,870
yes yes so basically there is this a

00:17:05,890 --> 00:17:13,710
different choices so since we have now a

00:17:10,870 --> 00:17:16,390
better mapping between open a sec and

00:17:13,710 --> 00:17:19,540
openmp the question is when can we

00:17:16,390 --> 00:17:21,730
transition our applications and mostly

00:17:19,540 --> 00:17:23,800
the transitions is going to depend on

00:17:21,730 --> 00:17:26,340
the compiler implementation right now

00:17:23,800 --> 00:17:31,230
we're starting to get opening before

00:17:26,340 --> 00:17:34,030
compilers for GPUs and once we start

00:17:31,230 --> 00:17:36,880
experimenting a little bit more with the

00:17:34,030 --> 00:17:38,290
open mp4 compilers and getting the same

00:17:36,880 --> 00:17:39,670
performance that we're getting with open

00:17:38,290 --> 00:17:43,000
ACC then we would feel more comfortable

00:17:39,670 --> 00:17:47,430
in moving our applications to open it

00:17:43,000 --> 00:17:49,840
before a so we have since both

00:17:47,430 --> 00:17:53,940
specifications like opening p4 dot one

00:17:49,840 --> 00:17:57,640
and opening CC to dot five are kind of a

00:17:53,940 --> 00:18:00,730
wavelength or listing is they're very

00:17:57,640 --> 00:18:04,780
similar to each other we feel like we

00:18:00,730 --> 00:18:07,720
have from 2015 2017 to improve the

00:18:04,780 --> 00:18:10,150
openmp compilers for a seller raters and

00:18:07,720 --> 00:18:11,800
maybe at that point is a that's a good

00:18:10,150 --> 00:18:15,580
point for us to start transitioned

00:18:11,800 --> 00:18:18,370
applications to to open mp4 so what do

00:18:15,580 --> 00:18:23,170
we need to translate things from opening

00:18:18,370 --> 00:18:25,330
CC to openmp usually a the first thing

00:18:23,170 --> 00:18:27,400
that we need to do is to normalize the

00:18:25,330 --> 00:18:30,100
opening CC application so that we use

00:18:27,400 --> 00:18:34,840
directives leronis that are supported in

00:18:30,100 --> 00:18:37,660
opening before so for example we ask the

00:18:34,840 --> 00:18:46,150
users to change the acc colonel

00:18:37,660 --> 00:18:48,400
directive to acc a parallel so that a so

00:18:46,150 --> 00:18:51,660
that for sample that directive is it has

00:18:48,400 --> 00:18:54,700
a correspondence with in win OpenMP a

00:18:51,660 --> 00:18:57,130
the same thing

00:18:54,700 --> 00:18:58,660
and we asked them to put it in the form

00:18:57,130 --> 00:19:01,410
that is easy to compare from open

00:18:58,660 --> 00:19:04,150
ecstasy to opening two openmp we also

00:19:01,410 --> 00:19:07,990
asked first to start changing things

00:19:04,150 --> 00:19:11,370
that data directives and then those are

00:19:07,990 --> 00:19:14,110
a more like a one-to-one mapping between

00:19:11,370 --> 00:19:17,380
opening CC and opening before dot one

00:19:14,110 --> 00:19:21,100
then a move towards the parallel

00:19:17,380 --> 00:19:22,870
detectives and eventually go to the

00:19:21,100 --> 00:19:25,720
subroutines detectives and then convert

00:19:22,870 --> 00:19:30,070
the runtime api's so if we kind of like

00:19:25,720 --> 00:19:32,320
follow these sort of steps we see that

00:19:30,070 --> 00:19:36,250
it's easier to move a the coast from

00:19:32,320 --> 00:19:40,660
opening CC to open mp4 to be more

00:19:36,250 --> 00:19:43,810
precise in when we say about what are

00:19:40,660 --> 00:19:45,580
the existing constructs in opening CC

00:19:43,810 --> 00:19:48,700
which are not equivalent in opening p

00:19:45,580 --> 00:19:50,560
for this is a opening before dot 0

00:19:48,700 --> 00:19:53,710
because that's what the global Balor's

00:19:50,560 --> 00:19:56,590
that we have right now and all of some

00:19:53,710 --> 00:19:58,570
of these a will go away when we have

00:19:56,590 --> 00:20:05,560
open it before those one implementations

00:19:58,570 --> 00:20:11,050
so but currently we have a in opening p

00:20:05,560 --> 00:20:13,320
for a we have a with it that night we

00:20:11,050 --> 00:20:16,090
don't have a dynamic data regions and

00:20:13,320 --> 00:20:18,250
the Colonel's directive needs to be

00:20:16,090 --> 00:20:22,420
transformed we have to take them out a

00:20:18,250 --> 00:20:24,550
to convert it to a cc parallel and then

00:20:22,420 --> 00:20:27,490
there are other things that we see in

00:20:24,550 --> 00:20:30,640
opening p for dot one but we we know how

00:20:27,490 --> 00:20:33,190
it in in Portal 0 so if we start for

00:20:30,640 --> 00:20:36,100
example a changing some of these two

00:20:33,190 --> 00:20:41,350
supported futures in opening before then

00:20:36,100 --> 00:20:45,160
we will make make we will make easier

00:20:41,350 --> 00:20:47,800
the translation so once we do that we

00:20:45,160 --> 00:20:51,960
can translate the data regions where we

00:20:47,800 --> 00:20:55,630
translate a for example the data regions

00:20:51,960 --> 00:20:58,909
the data declare a

00:20:55,630 --> 00:21:04,279
directives and all the closest

00:20:58,909 --> 00:21:07,539
associated with it aim scalars a needs

00:21:04,279 --> 00:21:13,820
to be converted to first private as in

00:21:07,539 --> 00:21:18,799
open mp4 dot 0 is a map to and from aim

00:21:13,820 --> 00:21:21,500
and in some cases a when we use async in

00:21:18,799 --> 00:21:26,330
open a sec we may be able to use tasks

00:21:21,500 --> 00:21:29,870
to handle in at least they emulate the

00:21:26,330 --> 00:21:32,419
behavior of a a sink in open a cc or

00:21:29,870 --> 00:21:36,890
load in opening before there is still

00:21:32,419 --> 00:21:41,990
not a a good correspondence yet but

00:21:36,890 --> 00:21:44,990
there is a way to use a tasks to em to

00:21:41,990 --> 00:21:49,700
at least a exploit some a synchronicity

00:21:44,990 --> 00:21:55,070
there and then a and then replace the

00:21:49,700 --> 00:21:57,799
different a device numbers to the

00:21:55,070 --> 00:22:01,429
closest that you know that you specify

00:21:57,799 --> 00:22:06,799
from acc device number two device Norman

00:22:01,429 --> 00:22:10,100
in openmp a one thing to note is that

00:22:06,799 --> 00:22:13,309
here we're putting things in terms of P

00:22:10,100 --> 00:22:18,950
copy p copy in copy copy out and that's

00:22:13,309 --> 00:22:20,390
because in opening CC to dot 0 a does

00:22:18,950 --> 00:22:23,630
the correspondence that we have with

00:22:20,390 --> 00:22:27,559
opening p for boring opening p 2 dot

00:22:23,630 --> 00:22:30,230
opening CC 25 a the default behavior of

00:22:27,559 --> 00:22:32,510
copy will be p copies as so that will

00:22:30,230 --> 00:22:36,590
make it easier for translating the codes

00:22:32,510 --> 00:22:38,000
from opening CC to openmp then a the

00:22:36,590 --> 00:22:41,779
other step is just to translate the

00:22:38,000 --> 00:22:43,730
update directive a so the target update

00:22:41,779 --> 00:22:47,570
and then that's kind of like a

00:22:43,730 --> 00:22:49,880
straightforward and then we can also use

00:22:47,570 --> 00:22:52,909
a you know replace or so they are think

00:22:49,880 --> 00:22:54,580
with the tasks and that will be a more

00:22:52,909 --> 00:22:57,770
careful

00:22:54,580 --> 00:23:01,580
now this is the more challenging part so

00:22:57,770 --> 00:23:03,320
that part the first Sunday day for the

00:23:01,580 --> 00:23:07,040
second and the third step are very

00:23:03,320 --> 00:23:09,620
straightforward it's very easy to do now

00:23:07,040 --> 00:23:13,840
the challenging part is when we starting

00:23:09,620 --> 00:23:16,490
to translate some of the directives that

00:23:13,840 --> 00:23:20,180
describe the parallelism ins and also

00:23:16,490 --> 00:23:25,850
how to map it to the architecture so for

00:23:20,180 --> 00:23:29,930
example we have a cc loop gang or a CC

00:23:25,850 --> 00:23:32,000
loop worker a sec loop vector that

00:23:29,930 --> 00:23:35,600
probably can be translated to some of

00:23:32,000 --> 00:23:40,700
the directives we have it in openmp like

00:23:35,600 --> 00:23:45,920
basically a target teams a distribute or

00:23:40,700 --> 00:23:50,200
parallel for or SIMD in a phone in a in

00:23:45,920 --> 00:23:52,760
a similar form and the idea is that a a

00:23:50,200 --> 00:23:54,710
dis mapping because there is already a

00:23:52,760 --> 00:23:56,980
hint in terms of how you want to

00:23:54,710 --> 00:24:01,250
schedule the loops to the underline

00:23:56,980 --> 00:24:03,020
levels of parallelism a then it's there

00:24:01,250 --> 00:24:06,110
is a kind of like direct translation to

00:24:03,020 --> 00:24:09,410
opening before the most challenging part

00:24:06,110 --> 00:24:15,260
is the translation of something like a

00:24:09,410 --> 00:24:17,120
acc loop independent a where it is left

00:24:15,260 --> 00:24:19,940
to the compiler to pick what is the

00:24:17,120 --> 00:24:24,290
schedule that we need in this case it

00:24:19,940 --> 00:24:27,200
could be teams or parallel for or or

00:24:24,290 --> 00:24:29,630
SIMD or any permutation of this or any

00:24:27,200 --> 00:24:35,300
of these combined directives so there

00:24:29,630 --> 00:24:39,350
could be a team's distribute a parallel

00:24:35,300 --> 00:24:41,990
for SIMD or any of those directives and

00:24:39,350 --> 00:24:45,470
then that stay does a piece where the

00:24:41,990 --> 00:24:47,780
programmer has to make the choices a and

00:24:45,470 --> 00:24:51,080
this is also going to be the piece where

00:24:47,780 --> 00:24:54,440
a it will depend on the architecture

00:24:51,080 --> 00:24:56,060
that you may want to target but we're

00:24:54,440 --> 00:24:59,350
trying to understand how we can write

00:24:56,060 --> 00:25:02,150
OpenMP in a form that is also portable

00:24:59,350 --> 00:25:04,120
without sacrificing this decision made

00:25:02,150 --> 00:25:07,510
on by the compiler

00:25:04,120 --> 00:25:09,640
in open sec and then a we have other

00:25:07,510 --> 00:25:12,460
discloses where we can translate very

00:25:09,640 --> 00:25:14,440
easily the gang to this this schedule

00:25:12,460 --> 00:25:17,380
number of gangs the number of teams

00:25:14,440 --> 00:25:21,580
number workers to threat limit a vector

00:25:17,380 --> 00:25:24,370
left to save length and so on so this

00:25:21,580 --> 00:25:29,230
sort of translations it can be done a

00:25:24,370 --> 00:25:33,550
and then a body the hardest part is just

00:25:29,230 --> 00:25:38,650
how to translate the parallelism from a

00:25:33,550 --> 00:25:40,720
descriptive formed into a prescriptive

00:25:38,650 --> 00:25:42,220
form in openmp so they say there's going

00:25:40,720 --> 00:25:48,880
to be a lot of decisions that we will

00:25:42,220 --> 00:25:51,450
have to make and then we have a the ACC

00:25:48,880 --> 00:25:58,030
routine which can be translated to the

00:25:51,450 --> 00:26:01,300
declare target and in a season-opening

00:25:58,030 --> 00:26:04,300
CC a the routine you can specify the

00:26:01,300 --> 00:26:06,370
level of parallelism gun worker vectors

00:26:04,300 --> 00:26:09,100
sequential and we don't have that in

00:26:06,370 --> 00:26:12,100
openmp so we assume that there is no

00:26:09,100 --> 00:26:15,300
need to to deck the compiler which

00:26:12,100 --> 00:26:17,620
automatically generate the different a

00:26:15,300 --> 00:26:22,570
versions for these different levels of

00:26:17,620 --> 00:26:33,790
parallelism and and the challenge is

00:26:22,570 --> 00:26:37,450
mostly in making sure that that whatever

00:26:33,790 --> 00:26:39,670
you call them the function has there the

00:26:37,450 --> 00:26:42,250
right level of parallelism from where

00:26:39,670 --> 00:26:45,160
you are calling the function and we hope

00:26:42,250 --> 00:26:48,310
that the openmp will help us to to do

00:26:45,160 --> 00:26:51,090
this motor a easily to program in terms

00:26:48,310 --> 00:26:51,090
of GPUs

00:26:51,350 --> 00:26:57,980
so this is one of the first examples

00:26:53,820 --> 00:27:01,620
that we use so I translated basically a

00:26:57,980 --> 00:27:02,910
14 benchmarks from open a sec to opening

00:27:01,620 --> 00:27:06,570
before and I'm just going to go through

00:27:02,910 --> 00:27:09,809
some examples what things what we did

00:27:06,570 --> 00:27:13,590
first and what led us to some success

00:27:09,809 --> 00:27:16,350
what were the challenges we see a lot of

00:27:13,590 --> 00:27:18,540
application users in writing code like

00:27:16,350 --> 00:27:22,410
this where we have loop independent on

00:27:18,540 --> 00:27:24,330
different loop nest levels and at some

00:27:22,410 --> 00:27:25,770
point we have to come up with a decision

00:27:24,330 --> 00:27:29,490
on how to translate to opening before

00:27:25,770 --> 00:27:35,370
and they're like several versions that

00:27:29,490 --> 00:27:37,440
we can write a so some users when we ask

00:27:35,370 --> 00:27:41,309
for example several applications users

00:27:37,440 --> 00:27:43,500
to translate this piece of code for

00:27:41,309 --> 00:27:45,960
example some came with this version

00:27:43,500 --> 00:27:49,170
which is basically just adding a

00:27:45,960 --> 00:27:50,940
parallel for a target region and a

00:27:49,170 --> 00:27:55,530
parallel for in the outer loop and then

00:27:50,940 --> 00:27:57,660
an SIMD a in the inner loop but we

00:27:55,530 --> 00:27:59,790
figure out that that may not be portable

00:27:57,660 --> 00:28:04,530
arc across architectures it may work

00:27:59,790 --> 00:28:09,870
only for a certain a a architecture like

00:28:04,530 --> 00:28:11,340
the Xeon Phi and so so that was for

00:28:09,870 --> 00:28:17,120
example that's one way of doing it but

00:28:11,340 --> 00:28:21,950
might not be a efficient for GPUs and

00:28:17,120 --> 00:28:24,510
however a we can write a another user

00:28:21,950 --> 00:28:27,030
attempted to do this a transformation

00:28:24,510 --> 00:28:31,220
when they translated open a sec and then

00:28:27,030 --> 00:28:36,000
uses nested parallelism and in this case

00:28:31,220 --> 00:28:38,880
the code was were able to run a a body

00:28:36,000 --> 00:28:42,110
was probably not as efficient as before

00:28:38,880 --> 00:28:44,220
and this is some people thought that

00:28:42,110 --> 00:28:47,550
when they were going to write codes for

00:28:44,220 --> 00:28:50,070
the GPUs that because GPUs may not have

00:28:47,550 --> 00:28:52,470
very good support for SIMD directive

00:28:50,070 --> 00:28:55,050
that this was probably the best day the

00:28:52,470 --> 00:28:57,570
right way to write it but we figured out

00:28:55,050 --> 00:29:00,510
that probably was a isn't still not a

00:28:57,570 --> 00:29:02,279
portable opening p code because it might

00:29:00,510 --> 00:29:09,109
not work very efficient in the

00:29:02,279 --> 00:29:09,109
in the GPU and yes

00:29:12,669 --> 00:29:19,070
yes am

00:29:16,320 --> 00:29:19,070
yes

00:29:19,640 --> 00:29:27,480
yes yes yes so yeah so what happened was

00:29:24,720 --> 00:29:29,789
like when people we asked the people

00:29:27,480 --> 00:29:31,950
some of the programmers to translate

00:29:29,789 --> 00:29:35,070
this for cm5 that were just thinking

00:29:31,950 --> 00:29:37,919
about you know how to write it in xeon

00:29:35,070 --> 00:29:43,919
phi mind frame and this is what they

00:29:37,919 --> 00:29:46,260
came up and then a then we ask other

00:29:43,919 --> 00:29:48,720
people to think about GPUs and then they

00:29:46,260 --> 00:29:50,400
thought okay maybe because GPUs didn't

00:29:48,720 --> 00:29:51,900
they were not very clear what was the

00:29:50,400 --> 00:29:54,210
level of support for this I am d

00:29:51,900 --> 00:29:56,130
directive in the GPUs they were kind of

00:29:54,210 --> 00:29:58,590
like running it this way where you have

00:29:56,130 --> 00:30:00,419
like nested parallelism but we know that

00:29:58,590 --> 00:30:03,960
nessa parallelism is not implemented

00:30:00,419 --> 00:30:06,179
efficiently he doesn't get performance

00:30:03,960 --> 00:30:12,030
but this was just another form that

00:30:06,179 --> 00:30:18,929
people try to write and then a and then

00:30:12,030 --> 00:30:23,520
we have a this one we're basically a we

00:30:18,929 --> 00:30:26,970
could write for example this opening p

00:30:23,520 --> 00:30:29,419
version where we can start using the

00:30:26,970 --> 00:30:33,480
concept of teams distribute parallel for

00:30:29,419 --> 00:30:37,710
we're basically that's more performance

00:30:33,480 --> 00:30:41,280
portable for the GPUs a poor at the same

00:30:37,710 --> 00:30:46,169
time a user were specifying in the inner

00:30:41,280 --> 00:30:52,260
loop a dates the SIMD directive and what

00:30:46,169 --> 00:30:55,350
we realized was that a that writing that

00:30:52,260 --> 00:30:57,720
this pattern of writing OpenMP will make

00:30:55,350 --> 00:31:03,240
sense if the loops were not able to

00:30:57,720 --> 00:31:04,950
collapse I put some people in but

00:31:03,240 --> 00:31:07,530
basically soap if some people thought

00:31:04,950 --> 00:31:09,600
that this was like portable OpenMP but

00:31:07,530 --> 00:31:11,220
we still needed they're still need some

00:31:09,600 --> 00:31:13,530
work we don't in this version because

00:31:11,220 --> 00:31:15,840
some of these looks can be collapsed and

00:31:13,530 --> 00:31:20,280
we can put everything one combined

00:31:15,840 --> 00:31:24,430
directive in but that was another

00:31:20,280 --> 00:31:27,560
version that people came up and and

00:31:24,430 --> 00:31:30,140
unfortunately a this version the

00:31:27,560 --> 00:31:32,930
assumption is that we have wire the

00:31:30,140 --> 00:31:37,460
schedule in the inner loop as to be simv

00:31:32,930 --> 00:31:41,240
and the two outer loops are a team's

00:31:37,460 --> 00:31:44,900
distribute parallel for so it gives some

00:31:41,240 --> 00:31:50,690
flexibilities with a compiler but but

00:31:44,900 --> 00:31:55,280
not for the inner loop so for us a it

00:31:50,690 --> 00:31:58,300
was better for example if we to write at

00:31:55,280 --> 00:32:01,970
the most portable way was to really

00:31:58,300 --> 00:32:03,950
collapse all the loops in the in the

00:32:01,970 --> 00:32:07,490
loop nest and then write and use the

00:32:03,950 --> 00:32:10,420
combined directive a where we do oil p

00:32:07,490 --> 00:32:15,680
teams distribute parallel for SIMD and

00:32:10,420 --> 00:32:18,200
that will basically leave the compiler

00:32:15,680 --> 00:32:22,610
the best choice in selecting what's the

00:32:18,200 --> 00:32:24,500
best way to schedule things into the in

00:32:22,610 --> 00:32:29,270
the in this case the GPUs or the Xeon

00:32:24,500 --> 00:32:32,420
Phi however a one thing is that when we

00:32:29,270 --> 00:32:35,090
start using a directive like this and we

00:32:32,420 --> 00:32:39,980
look at the opening piece specification

00:32:35,090 --> 00:32:42,500
we notice that a if we program this we

00:32:39,980 --> 00:32:45,980
will leave the behavior to the compiler

00:32:42,500 --> 00:32:49,790
to be implementation defined a basically

00:32:45,980 --> 00:32:52,760
to select the number of teams or the

00:32:49,790 --> 00:32:59,570
thread limit or the safe length for

00:32:52,760 --> 00:33:03,590
example a and a and if we don't have a

00:32:59,570 --> 00:33:05,240
good implementation basically to select

00:33:03,590 --> 00:33:08,630
these features we will have to specify

00:33:05,240 --> 00:33:11,270
them in the directives so what are the

00:33:08,630 --> 00:33:14,210
challenges one of the lessons that we

00:33:11,270 --> 00:33:18,950
having to learn is that it is very

00:33:14,210 --> 00:33:21,290
important for a the compilers that use

00:33:18,950 --> 00:33:23,750
opening before a to the Target to target

00:33:21,290 --> 00:33:27,290
multiple

00:33:23,750 --> 00:33:30,550
a accelerators or different at Regina

00:33:27,290 --> 00:33:34,010
systems to be smart about selecting a

00:33:30,550 --> 00:33:37,010
list making an attempt to select how to

00:33:34,010 --> 00:33:39,860
map this for support this lupinus to the

00:33:37,010 --> 00:33:43,430
different architectures and that's kind

00:33:39,860 --> 00:33:47,540
of like that will kind of make life

00:33:43,430 --> 00:33:51,100
easier for open ACC users because then

00:33:47,540 --> 00:33:54,770
the compiler will help them to really

00:33:51,100 --> 00:33:59,230
write more portable codes so the

00:33:54,770 --> 00:34:03,880
challenge is here is to make sure that a

00:33:59,230 --> 00:34:07,730
we put opening pinned in a in a write a

00:34:03,880 --> 00:34:10,159
form to give as much flexibility to the

00:34:07,730 --> 00:34:13,550
openmp compiler to to the optimizations

00:34:10,159 --> 00:34:17,750
we are also not as specifying a number

00:34:13,550 --> 00:34:19,879
of threads or assuming that a the

00:34:17,750 --> 00:34:22,690
compiler will help us to identify what's

00:34:19,879 --> 00:34:22,690
best here

00:34:25,369 --> 00:34:31,500
so we did a other transformations with

00:34:29,190 --> 00:34:34,409
some other codes and it was a very

00:34:31,500 --> 00:34:38,990
straightforward translation between open

00:34:34,409 --> 00:34:41,940
ACC and open mp4 a some of the cases a

00:34:38,990 --> 00:34:44,129
we were translating for example ACC

00:34:41,940 --> 00:34:48,210
paddling loops into the combine

00:34:44,129 --> 00:34:49,919
directive here and went one thing that

00:34:48,210 --> 00:34:53,669
we notice is like yes the combined

00:34:49,919 --> 00:34:56,700
directed can be very long a maybe in the

00:34:53,669 --> 00:34:59,069
future we can make it shorter or figure

00:34:56,700 --> 00:35:01,619
out another name that we can give at

00:34:59,069 --> 00:35:04,380
least a combined directive will help a

00:35:01,619 --> 00:35:10,440
you know the programs would be more

00:35:04,380 --> 00:35:12,359
compact in the translation am so that

00:35:10,440 --> 00:35:17,240
was one of one of the one of the codes

00:35:12,359 --> 00:35:20,190
that we did em we did another one a

00:35:17,240 --> 00:35:21,930
where we have like similar patterns

00:35:20,190 --> 00:35:25,170
where we were able to translate them

00:35:21,930 --> 00:35:30,060
from one a directive set to the other

00:35:25,170 --> 00:35:32,700
mine and in and when we did this

00:35:30,060 --> 00:35:34,650
comparison we were able to get in some

00:35:32,700 --> 00:35:38,990
of experimental compilers that we have

00:35:34,650 --> 00:35:43,920
we will get to get similar performance a

00:35:38,990 --> 00:35:45,990
however m we still need to understand a

00:35:43,920 --> 00:35:47,670
little bit more a how the opening p

00:35:45,990 --> 00:35:51,240
compilers are going to be mapping

00:35:47,670 --> 00:35:52,650
release translating this a combined

00:35:51,240 --> 00:35:54,150
directives into the architecture and

00:35:52,650 --> 00:35:57,680
what's choices are they're going to make

00:35:54,150 --> 00:35:57,680
or what optimizations are going to make

00:35:58,550 --> 00:36:05,540
em so when we use this methodology we

00:36:02,130 --> 00:36:09,740
successfully ported several benchmarks a

00:36:05,540 --> 00:36:13,530
functionally the benchmarks are correct

00:36:09,740 --> 00:36:19,070
we found a that the main challenges was

00:36:13,530 --> 00:36:23,270
the performance portability mmm

00:36:19,070 --> 00:36:25,640
there is a a hope that a opening p can

00:36:23,270 --> 00:36:29,570
leave a lot of freedom to the compiler

00:36:25,640 --> 00:36:34,940
by using the combined directives without

00:36:29,570 --> 00:36:38,770
specifying the number of teams or threat

00:36:34,940 --> 00:36:42,140
limits or length of the vector and

00:36:38,770 --> 00:36:44,540
because we see that for example GPUs are

00:36:42,140 --> 00:36:47,240
going to be sensible to number of teams

00:36:44,540 --> 00:36:48,740
or number of threads and see on files

00:36:47,240 --> 00:36:53,170
architectures are going to be more

00:36:48,740 --> 00:36:56,810
sensible to the length of the SIMD and

00:36:53,170 --> 00:37:01,610
basically a we have to find the balance

00:36:56,810 --> 00:37:06,080
basically on how to write a code a in

00:37:01,610 --> 00:37:10,370
some cases a when we converted from a

00:37:06,080 --> 00:37:12,260
opening CC to open mp4 a for example for

00:37:10,370 --> 00:37:15,160
a different architecture going from a

00:37:12,260 --> 00:37:19,070
GPU to ac15 we needed to do some loop

00:37:15,160 --> 00:37:24,140
interchanges to exploit more SIMD in the

00:37:19,070 --> 00:37:26,900
Xeon Phi and and it would be nice to

00:37:24,140 --> 00:37:29,750
have a you know a mechanism where we can

00:37:26,900 --> 00:37:35,800
probably can trigger the sort of

00:37:29,750 --> 00:37:40,070
interchange so that we can or a way to

00:37:35,800 --> 00:37:42,760
as a way to to understand would it make

00:37:40,070 --> 00:37:45,590
sense to use SIMD in the loop nest a

00:37:42,760 --> 00:37:47,420
another thing that we came across was

00:37:45,590 --> 00:37:51,110
that it there is mainly there may be a

00:37:47,420 --> 00:37:53,780
need to write a macros so that you can

00:37:51,110 --> 00:37:54,890
tune in a different opening p options

00:37:53,780 --> 00:37:57,860
you may have four different

00:37:54,890 --> 00:38:03,470
architectures if the compiler doesn't do

00:37:57,860 --> 00:38:06,590
a good job and a and then one of the

00:38:03,470 --> 00:38:10,040
main macros that we hope to use is the

00:38:06,590 --> 00:38:14,210
collapse a whenever to play with

00:38:10,040 --> 00:38:16,250
different collapsing levels and and then

00:38:14,210 --> 00:38:17,870
for all the different schedules which

00:38:16,250 --> 00:38:23,790
are a

00:38:17,870 --> 00:38:29,220
the number of teams or a threat limit or

00:38:23,790 --> 00:38:35,210
distribute schedule or simd a length for

00:38:29,220 --> 00:38:35,210
example yes

00:38:45,930 --> 00:38:48,589
yes

00:38:51,990 --> 00:38:56,880
yes

00:38:54,330 --> 00:39:04,730
that's correct that's correct okay just

00:38:56,880 --> 00:39:04,730
as wrong but but yes

00:39:07,430 --> 00:39:14,290
yes that that's correct yeah so the

00:39:10,220 --> 00:39:17,180
implementations what happens is like a

00:39:14,290 --> 00:39:20,210
we are starting to understand the open

00:39:17,180 --> 00:39:22,430
mp4 implementations a as we started to

00:39:20,210 --> 00:39:29,660
see implementations for GPUs and see on

00:39:22,430 --> 00:39:31,190
face and a as so for example one of the

00:39:29,660 --> 00:39:34,550
first implementations may not be that

00:39:31,190 --> 00:39:36,670
smart and that because causes the

00:39:34,550 --> 00:39:38,770
problem may be may not generate a

00:39:36,670 --> 00:39:42,280
performance portable codes but as

00:39:38,770 --> 00:39:45,050
implementations improve maybe there is a

00:39:42,280 --> 00:39:47,359
you know if they catch chopped to the

00:39:45,050 --> 00:39:49,040
level of the same thing that the opening

00:39:47,359 --> 00:39:53,170
is he does at least early some base

00:39:49,040 --> 00:39:55,579
level that the user can use a before a

00:39:53,170 --> 00:39:59,150
tuning their coat with something more

00:39:55,579 --> 00:40:02,650
specific to the architecture but a yes

00:39:59,150 --> 00:40:02,650
so yeah

00:40:12,180 --> 00:40:15,109
yes

00:40:22,050 --> 00:40:24,710
right

00:40:27,580 --> 00:40:39,260
ok this is work for videos

00:40:36,970 --> 00:40:40,600
if you don't call less your loads you're

00:40:39,260 --> 00:40:44,160
dead

00:40:40,600 --> 00:40:44,160
still Cindy is still

00:40:45,320 --> 00:40:50,580
yes

00:40:47,580 --> 00:40:50,580
mm-hmm

00:40:50,920 --> 00:40:56,680
yes so this is just for example our

00:40:53,859 --> 00:40:58,510
initial a experiences but of course we

00:40:56,680 --> 00:41:01,270
have to understand more as as we

00:40:58,510 --> 00:41:04,480
experiment more in terms of mapping open

00:41:01,270 --> 00:41:07,150
before in two different architectures so

00:41:04,480 --> 00:41:10,349
in these benchmarks that I just talked

00:41:07,150 --> 00:41:12,430
about are a the spec SL benchmarks and

00:41:10,349 --> 00:41:15,730
we think we're going to be releasing

00:41:12,430 --> 00:41:17,890
them very soon however we're basically

00:41:15,730 --> 00:41:22,150
this is going to be the first test that

00:41:17,890 --> 00:41:25,900
we're going to have a to see how open if

00:41:22,150 --> 00:41:27,430
it can be written as portable as

00:41:25,900 --> 00:41:28,960
possible across architectures and

00:41:27,430 --> 00:41:31,119
there's gonna be a lot of feedback that

00:41:28,960 --> 00:41:34,950
we're going to get back to to the

00:41:31,119 --> 00:41:34,950
community to the open agency

00:41:36,720 --> 00:41:43,980
functionality yes yes yes yes

00:41:46,250 --> 00:41:51,770
that that's correct that's correct so

00:41:48,680 --> 00:41:53,570
the next step is to get the performance

00:41:51,770 --> 00:41:55,340
and the reason why we don't have

00:41:53,570 --> 00:41:57,920
performance numbers here is because

00:41:55,340 --> 00:42:00,380
across architectures at least in GPUs

00:41:57,920 --> 00:42:03,620
implementation are still not that mature

00:42:00,380 --> 00:42:07,220
yet so we get a functionality but not

00:42:03,620 --> 00:42:10,310
yet the performance and a of course we

00:42:07,220 --> 00:42:13,190
have a cfi implementations but in our

00:42:10,310 --> 00:42:17,810
case a we want to understand open a cc

00:42:13,190 --> 00:42:20,000
to see we only have open sec for GPUs to

00:42:17,810 --> 00:42:23,260
understand how those opening p looks for

00:42:20,000 --> 00:42:25,850
GPUs and and we will get more

00:42:23,260 --> 00:42:30,190
experiencing in the in that area as we

00:42:25,850 --> 00:42:30,190
get more on Pilar support

00:42:48,790 --> 00:42:51,870
I see

00:42:52,620 --> 00:42:58,740
okay yes yes so this is say another

00:42:56,770 --> 00:43:01,870
piece that we would be experimenting yes

00:42:58,740 --> 00:43:06,280
so another thing I went to mention is a

00:43:01,870 --> 00:43:10,990
open ACC has been around for three years

00:43:06,280 --> 00:43:12,580
or so and opening p4 and ported one or

00:43:10,990 --> 00:43:16,650
certain to emerged implementations for

00:43:12,580 --> 00:43:20,520
GPS so one question is what has been the

00:43:16,650 --> 00:43:22,930
road blocks of open ACC basically on how

00:43:20,520 --> 00:43:26,650
that we have experienced over the years

00:43:22,930 --> 00:43:28,570
that we need to put into opening p so

00:43:26,650 --> 00:43:31,840
that you don't suffer the same things

00:43:28,570 --> 00:43:34,870
that we have in open ACC and one of the

00:43:31,840 --> 00:43:37,210
main challenges for using open a CC on

00:43:34,870 --> 00:43:39,550
Titan was the idea that we don't have

00:43:37,210 --> 00:43:43,030
like that great support for deep copy in

00:43:39,550 --> 00:43:46,260
terms of directives and it's possible to

00:43:43,030 --> 00:43:49,750
do it using some of the wrong time api's

00:43:46,260 --> 00:43:52,930
but a that was one of the main

00:43:49,750 --> 00:43:55,900
challenges listen day in the on the

00:43:52,930 --> 00:43:58,030
Titan system because we have a set of

00:43:55,900 --> 00:44:02,110
data structures that the user wanted to

00:43:58,030 --> 00:44:07,300
move certain elements or some it to the

00:44:02,110 --> 00:44:08,980
GPU or basically a copy certain elements

00:44:07,300 --> 00:44:11,200
of the data structures and deeply nested

00:44:08,980 --> 00:44:13,780
data structures and that's where things

00:44:11,200 --> 00:44:20,350
have started to break down in terms of

00:44:13,780 --> 00:44:21,820
using open a cc in and without and those

00:44:20,350 --> 00:44:23,800
were for users that didn't want to

00:44:21,820 --> 00:44:27,330
restructure the data structure in their

00:44:23,800 --> 00:44:30,490
applications a so we were like we had a

00:44:27,330 --> 00:44:32,560
codes that were like very large in terms

00:44:30,490 --> 00:44:34,570
of code sizes that changing the data

00:44:32,560 --> 00:44:38,050
structure will mean changing the entire

00:44:34,570 --> 00:44:42,100
application and for those cases is the

00:44:38,050 --> 00:44:45,250
challenging was a to get a good and sort

00:44:42,100 --> 00:44:48,190
of a dip a copy support and I think that

00:44:45,250 --> 00:44:50,560
a OpenMP is already moving in there in

00:44:48,190 --> 00:44:54,760
that direction which is very important

00:44:50,560 --> 00:44:58,210
for using the directives and now that a

00:44:54,760 --> 00:44:59,890
we have more unified memory support

00:44:58,210 --> 00:45:01,430
maybe this is going to be needed only

00:44:59,890 --> 00:45:04,460
for performance

00:45:01,430 --> 00:45:06,619
eh but eh what is an important thing

00:45:04,460 --> 00:45:11,000
that we need to support in opening

00:45:06,619 --> 00:45:13,040
before or for that one or five and then

00:45:11,000 --> 00:45:16,420
the other thing that people are starting

00:45:13,040 --> 00:45:19,579
to eat to ask in terms of open a sec and

00:45:16,420 --> 00:45:22,210
opening p is like how are we going to be

00:45:19,579 --> 00:45:26,540
supporting different types of memories

00:45:22,210 --> 00:45:29,510
how are we going to deal with a digital

00:45:26,540 --> 00:45:32,050
unity of the memories are we going to be

00:45:29,510 --> 00:45:38,050
required to use vendor-specific a

00:45:32,050 --> 00:45:38,050
library calls or can we put something in

00:45:42,860 --> 00:45:45,580
yes

00:46:07,660 --> 00:46:10,660
yes

00:46:12,570 --> 00:46:15,320
mm-hmm

00:46:16,619 --> 00:46:25,880
yeah yes yes go ahead

00:46:23,089 --> 00:46:30,020
as you develop

00:46:25,880 --> 00:46:30,020
very interested in question

00:46:35,950 --> 00:46:44,110
degrees of their ass using the largest

00:46:40,240 --> 00:46:44,110
nice corner bases

00:46:49,640 --> 00:46:52,089
and also

00:47:10,530 --> 00:47:21,040
yeah well we so our main focus has been

00:47:17,890 --> 00:47:24,460
mostly on gpus and we have although we

00:47:21,040 --> 00:47:29,320
want to achieve portability for nice

00:47:24,460 --> 00:47:36,250
landing architecture and but we think

00:47:29,320 --> 00:47:38,860
that a in our case opening before that

00:47:36,250 --> 00:47:41,770
one will solve a lot of issues for us a

00:47:38,860 --> 00:47:44,950
list for the GPUs we will still need to

00:47:41,770 --> 00:47:48,700
understand a how we will be writing a

00:47:44,950 --> 00:47:50,710
portable code between GPUs and CM files

00:47:48,700 --> 00:47:52,660
using opening p there is the sale open

00:47:50,710 --> 00:47:54,460
question that we will depend a lot on

00:47:52,660 --> 00:47:58,560
the implementations of the compiler and

00:47:54,460 --> 00:47:58,560
also experimenting more on the model a

00:47:59,400 --> 00:48:02,550
just right

00:48:03,339 --> 00:48:10,640
yes yes but we need to bring the tree at

00:48:07,640 --> 00:48:12,710
the data the real data and then and this

00:48:10,640 --> 00:48:21,430
is something that we're getting we're

00:48:12,710 --> 00:48:21,430
going to be getting a person yes yeah

00:48:25,319 --> 00:48:28,009
yes

00:48:34,480 --> 00:48:36,510
Oh

00:48:38,240 --> 00:48:43,810
no yes all right oh yeah because it's

00:48:41,360 --> 00:48:43,810
already time

00:49:36,580 --> 00:49:39,300
hmm

00:49:47,770 --> 00:49:52,650
right right

00:50:08,960 --> 00:50:14,349
yes

00:50:10,789 --> 00:50:14,349
yes that

00:50:18,660 --> 00:50:27,540
yeah yeah so open and B is a model and

00:50:25,160 --> 00:50:30,930
you know there's a later model is just

00:50:27,540 --> 00:50:35,390
one form to write openmp but it should

00:50:30,930 --> 00:50:38,040
be portable across architectures and

00:50:35,390 --> 00:50:41,670
then the other thing is that we have

00:50:38,040 --> 00:50:43,800
other a lot of C++ applications and we

00:50:41,670 --> 00:50:47,010
have so much resistance of using openmp

00:50:43,800 --> 00:50:48,780
in those C++ applications because they

00:50:47,010 --> 00:50:50,220
tend not to like the directives because

00:50:48,780 --> 00:50:53,520
they have things like templates

00:50:50,220 --> 00:50:56,130
inheritance STL's maybe there is a

00:50:53,520 --> 00:51:00,360
another approach that we have to explore

00:50:56,130 --> 00:51:05,370
about how to go about open mp4 C++

00:51:00,360 --> 00:51:09,030
especially for accelerators and now a we

00:51:05,370 --> 00:51:10,710
have a better hope a4a tools a the other

00:51:09,030 --> 00:51:13,140
thing is just how to get measured

00:51:10,710 --> 00:51:15,540
performance in the application and now

00:51:13,140 --> 00:51:18,710
we have to say P I on both the standards

00:51:15,540 --> 00:51:22,110
or lease a technical report in opening

00:51:18,710 --> 00:51:25,440
p4000 one here at least a that works

00:51:22,110 --> 00:51:28,260
with opening before and we have one now

00:51:25,440 --> 00:51:30,720
in open acct to dot five so that will

00:51:28,260 --> 00:51:32,160
help us to really understand more the

00:51:30,720 --> 00:51:35,750
challenges of the performance

00:51:32,160 --> 00:51:35,750
portability across architectures

00:51:41,220 --> 00:51:47,750
yes yes yes yes c++ 11 yes yes

00:52:17,140 --> 00:52:20,140
one

00:52:28,440 --> 00:52:31,550
and in there

00:52:32,839 --> 00:52:35,019
say

00:52:35,109 --> 00:52:37,739
that's right

00:52:43,890 --> 00:52:51,240
because yes to answer your question no

00:52:47,580 --> 00:52:51,240
acceleration one way

00:52:55,070 --> 00:53:00,590
yes correct

00:53:04,200 --> 00:53:06,410
see

00:53:08,830 --> 00:53:19,270
I said if you want a direct translation

00:53:15,910 --> 00:53:19,270
right to pry

00:53:21,609 --> 00:53:27,009
right right

00:53:24,130 --> 00:53:30,009
cherry

00:53:27,009 --> 00:53:30,009
see

00:53:33,900 --> 00:53:36,900
going

00:53:37,480 --> 00:53:39,510
Oh

00:53:41,460 --> 00:53:46,109
and

00:53:42,609 --> 00:53:46,109
I say

00:53:46,430 --> 00:53:50,770
yes way

00:53:52,529 --> 00:54:06,099
right right right right yes I'm yeah we

00:54:03,430 --> 00:54:08,950
um we really ran out of time but just as

00:54:06,099 --> 00:54:11,200
a feedback open a cc is currently use

00:54:08,950 --> 00:54:14,160
more sleep or Fortran in our coils in

00:54:11,200 --> 00:54:16,960
our codes but I have very limited

00:54:14,160 --> 00:54:19,450
support for C++ ins we need to look for

00:54:16,960 --> 00:54:22,630
a solution for accelerators in terms of

00:54:19,450 --> 00:54:28,079
C++ m and very tested in the effort that

00:54:22,630 --> 00:54:31,329
you are doing and then this is just a

00:54:28,079 --> 00:54:34,749
summary just like these two specs are

00:54:31,329 --> 00:54:37,150
really similar to each other right now

00:54:34,749 --> 00:54:38,410
just move rose from open agency to open

00:54:37,150 --> 00:54:41,910
it before we just want to get the

00:54:38,410 --> 00:54:44,229
compilers give us the performance and

00:54:41,910 --> 00:54:46,599
help us to understand more how to write

00:54:44,229 --> 00:54:49,509
opening before portable codes and once

00:54:46,599 --> 00:54:54,400
we feel like we reach to that paint we

00:54:49,509 --> 00:55:00,640
will be a living a asking the people to

00:54:54,400 --> 00:55:02,170
move to open it before m and yeah and

00:55:00,640 --> 00:55:04,329
then there are other things that needs

00:55:02,170 --> 00:55:06,519
to be explored like multiple

00:55:04,329 --> 00:55:08,319
accelerators but these are other you

00:55:06,519 --> 00:55:11,680
know things that will come out along the

00:55:08,319 --> 00:55:15,180
way and then bring the questions just

00:55:11,680 --> 00:55:15,180
you probably already asked them

00:55:16,920 --> 00:55:18,980

YouTube URL: https://www.youtube.com/watch?v=CHMrcMUXuuY


