Title: Towards Using OpenMP in Embedded Systems
Publication date: 2015-12-13
Playlist: OpenMPCon 2015 Developers Conference
Description: 
	Eric Stotzer, Texas Instruments, Inc.
OpenMP Con 2015 - Aachen, Germany - September 2015
Slides at http://openmpcon.org/wp-content/uploads/openmpcon2015-eric-stotzer-embedded.pdf

Software for embedded systems is more complex than in the past, as more functions are implemented on the same device. This talk will provide an overview of the characteristics of embedded systems and discuss features that could be added to OpenMP to enable it to better serve as a programming model for these systems.  Embedded systems typically are constrained by among other things real-time deadlines, power-limitations and limited memory resources. Today OpenMP is not able to express these types of constraints.

Embedded systems applications can be broadly classified as event-driven or compute and data intensive. OpenMP is well suited to expressing the parallel execution that is demanded by compute and data intensive applications.  However, extensions are needed for event-driven applications, such as automotive embedded systems, where the behavior is characterized by a defined sequence of responses to a given incoming event from the environment.  While the actions performed may not be compute or data intensive, they tend to have strict real-time constraints.

The use of multicore technology has increased the design space and performance of Multiprocessor Systems-on-Chip (MPSoCs) that are targeted at embedded applications.  A natural extension is to adapt the device construct added in OpenMP 4.0 to support the mapping of different software tasks, or components, to various processor cores.
Captions: 
	00:00:04,840 --> 00:00:10,940
both complicated along with Jake fire

00:00:08,029 --> 00:00:13,940
co-chairing one of the most complicated

00:00:10,940 --> 00:00:15,799
did those issues Mayo committees out

00:00:13,940 --> 00:00:18,080
there was the accelerated comedian would

00:00:15,799 --> 00:00:20,480
always be talking continuously because

00:00:18,080 --> 00:00:24,109
it was so much to talk about and then we

00:00:20,480 --> 00:00:26,630
would end up sometimes leaving for lunch

00:00:24,109 --> 00:00:28,880
and now realizing Eric was still packing

00:00:26,630 --> 00:00:31,130
up his stuff and because of the language

00:00:28,880 --> 00:00:33,440
barrier often he would get left behind

00:00:31,130 --> 00:00:37,219
but somehow Eric was always able to find

00:00:33,440 --> 00:00:39,170
us despite our best attempt oh thank you

00:00:37,219 --> 00:00:41,600
very much Eric was staying with openmp

00:00:39,170 --> 00:00:42,559
and for delivering some of the some of

00:00:41,600 --> 00:00:44,210
the best work I've ever seen you

00:00:42,559 --> 00:00:47,390
absolutely one of the most patient

00:00:44,210 --> 00:00:49,309
person but he's not just being not just

00:00:47,390 --> 00:00:51,620
a patient guy he's technically brilliant

00:00:49,309 --> 00:00:54,230
in mind in my opinion here's a PhD from

00:00:51,620 --> 00:00:57,170
University Houston been with Texas

00:00:54,230 --> 00:00:59,960
initial in about 25 years mostly in

00:00:57,170 --> 00:01:02,059
compilers working through stuff so with

00:00:59,960 --> 00:01:04,160
that I want to thank you Eric coming up

00:01:02,059 --> 00:01:05,720
and talk to us about how openmp is use

00:01:04,160 --> 00:01:15,220
independent system thinking thanks

00:01:05,720 --> 00:01:19,540
Michael wow I hope I can live up to that

00:01:15,220 --> 00:01:22,009
okay so my talk today is entitled

00:01:19,540 --> 00:01:27,650
towards using OpenMP and embedded

00:01:22,009 --> 00:01:31,670
systems I hope to talk about maybe some

00:01:27,650 --> 00:01:34,610
different things than are discussed with

00:01:31,670 --> 00:01:38,060
this community where we tend to focus a

00:01:34,610 --> 00:01:43,700
lot on a smaller set of architectures

00:01:38,060 --> 00:01:46,520
and hpc and bring in the other part of

00:01:43,700 --> 00:01:50,170
computing the the world of embedded

00:01:46,520 --> 00:01:54,170
computing and see how we can make OpenMP

00:01:50,170 --> 00:01:58,250
be successful in that environment that

00:01:54,170 --> 00:02:03,470
community okay

00:01:58,250 --> 00:02:05,550
so just briefly what are the themes

00:02:03,470 --> 00:02:10,950
software for embedded systems is

00:02:05,550 --> 00:02:14,400
becoming more complex so the question is

00:02:10,950 --> 00:02:18,150
can we use OpenMP as a programming model

00:02:14,400 --> 00:02:19,230
to cope with this complexity well some

00:02:18,150 --> 00:02:20,880
of the problems some of the things that

00:02:19,230 --> 00:02:22,770
are unique about embedded systems as

00:02:20,880 --> 00:02:24,510
they they have constraints there's

00:02:22,770 --> 00:02:27,420
there's these things called real time

00:02:24,510 --> 00:02:29,459
deadlines and there's limited memory

00:02:27,420 --> 00:02:34,530
resources there's other constraints

00:02:29,459 --> 00:02:37,920
around power and size so can openmp

00:02:34,530 --> 00:02:41,940
adapt to these types of things you can

00:02:37,920 --> 00:02:45,600
classify roughly different types of

00:02:41,940 --> 00:02:47,989
embedded systems or an individual system

00:02:45,600 --> 00:02:50,400
may have different regions that have

00:02:47,989 --> 00:02:54,090
these different characteristics so

00:02:50,400 --> 00:02:56,400
you've got event driven systems where

00:02:54,090 --> 00:02:59,550
you're reacting to events coming from

00:02:56,400 --> 00:03:02,070
the real world and then you've got the

00:02:59,550 --> 00:03:04,080
more compute and data-intensive parts

00:03:02,070 --> 00:03:08,340
where you're doing some heavy duty

00:03:04,080 --> 00:03:11,280
processing so openmp as it exists today

00:03:08,340 --> 00:03:13,650
we could see how that could work for the

00:03:11,280 --> 00:03:17,430
compute and intent data-intensive parts

00:03:13,650 --> 00:03:20,040
the invent driven stuff is our part is

00:03:17,430 --> 00:03:22,650
maybe something where OpenMP could be

00:03:20,040 --> 00:03:24,330
extended so I want to talk about us it's

00:03:22,650 --> 00:03:27,080
there a way that we could extend the

00:03:24,330 --> 00:03:30,209
tasking model that's an open and P to

00:03:27,080 --> 00:03:31,830
support this event driven to extend it

00:03:30,209 --> 00:03:34,950
to be an event during program also i'll

00:03:31,830 --> 00:03:36,980
go through that another area i'll talk

00:03:34,950 --> 00:03:39,810
about is that you see a lot of

00:03:36,980 --> 00:03:42,690
integration in embedded systems into

00:03:39,810 --> 00:03:46,950
these multiprocessor system on chips I

00:03:42,690 --> 00:03:48,840
call mpsoc s all right so how can we

00:03:46,950 --> 00:03:51,930
adapt some of the things that are going

00:03:48,840 --> 00:03:54,000
into openmp to target these systems

00:03:51,930 --> 00:03:55,950
where you're seeing lots of parallelism

00:03:54,000 --> 00:03:57,860
with multiple processors of the same

00:03:55,950 --> 00:04:00,269
type but you're also seeing a lot of

00:03:57,860 --> 00:04:03,720
heterogeneous processors so you'll have

00:04:00,269 --> 00:04:06,420
different processing domains on the chip

00:04:03,720 --> 00:04:10,380
and so what I want to look at is can we

00:04:06,420 --> 00:04:11,560
can we adapt the openmp accelerator

00:04:10,380 --> 00:04:14,099
model too

00:04:11,560 --> 00:04:16,269
to become more of a generalized

00:04:14,099 --> 00:04:18,519
multiprocessor system on chip or a more

00:04:16,269 --> 00:04:23,080
generalized heterogeneous programming

00:04:18,519 --> 00:04:25,360
model so I'm like you know thinking a

00:04:23,080 --> 00:04:26,650
little outside the box here going a

00:04:25,360 --> 00:04:29,919
little crazy with some of the stuff

00:04:26,650 --> 00:04:30,880
trying to well I mean crazy if you can

00:04:29,919 --> 00:04:32,320
get crazy when you're talking about

00:04:30,880 --> 00:04:35,889
programming languages and things like

00:04:32,320 --> 00:04:38,050
that but you know so trying to think

00:04:35,889 --> 00:04:39,430
outside think a little differently so

00:04:38,050 --> 00:04:41,440
I'm sure some of your initial reaction

00:04:39,430 --> 00:04:46,889
will be no way we can't do that but

00:04:41,440 --> 00:04:49,870
that's good I just want to acknowledge

00:04:46,889 --> 00:04:53,979
some places that some of the the people

00:04:49,870 --> 00:04:57,160
I've worked with like barber Chapman I'm

00:04:53,979 --> 00:05:01,330
in Houston I'm worked with Barbara a lot

00:04:57,160 --> 00:05:03,880
and we many years ago worked on it

00:05:01,330 --> 00:05:06,040
adapting openmp for some of t oz

00:05:03,880 --> 00:05:08,919
processors and Roberts done a lot of

00:05:06,040 --> 00:05:11,050
work in her group with adapting openmp

00:05:08,919 --> 00:05:15,250
to the embedded world and making it run

00:05:11,050 --> 00:05:16,330
on top of a api called MMT p.m. copy

00:05:15,250 --> 00:05:19,539
that comes from the multi-core

00:05:16,330 --> 00:05:21,550
association it's similar to open CL a

00:05:19,539 --> 00:05:24,479
little bit maybe without the language

00:05:21,550 --> 00:05:29,289
and then these are just references on

00:05:24,479 --> 00:05:31,870
places where I went to get some

00:05:29,289 --> 00:05:33,490
information on just the key concepts of

00:05:31,870 --> 00:05:35,050
embedded processing there's many

00:05:33,490 --> 00:05:37,650
references out there like that like

00:05:35,050 --> 00:05:42,039
these but these I think are very good

00:05:37,650 --> 00:05:43,240
all right so here's I'm going to here's

00:05:42,039 --> 00:05:44,050
what's going to be the agenda for the

00:05:43,240 --> 00:05:46,660
talk i'm going to give you some

00:05:44,050 --> 00:05:49,030
background in embedded systems i'm going

00:05:46,660 --> 00:05:51,250
to talk about how we adapted OpenMP to

00:05:49,030 --> 00:05:54,729
work in an embedded system to work on

00:05:51,250 --> 00:05:57,460
one of our multi-core DSPs then I will

00:05:54,729 --> 00:05:59,590
talk about this event driven model and

00:05:57,460 --> 00:06:03,190
give you some background and how that

00:05:59,590 --> 00:06:06,669
works and then I will talk about this

00:06:03,190 --> 00:06:11,580
concept of an mps OSI model programming

00:06:06,669 --> 00:06:14,050
model and then I will conclude alright

00:06:11,580 --> 00:06:17,420
so let's talk about some of the

00:06:14,050 --> 00:06:20,880
characteristics of embedded systems

00:06:17,420 --> 00:06:23,850
well obviously embedded processing is

00:06:20,880 --> 00:06:27,480
all around you I this is just you know

00:06:23,850 --> 00:06:31,970
giving you some of some of the areas

00:06:27,480 --> 00:06:34,350
where it's it exists for example in your

00:06:31,970 --> 00:06:35,970
automobiles embedded processing in

00:06:34,350 --> 00:06:39,330
automobiles it's been in the news a lot

00:06:35,970 --> 00:06:43,140
lately for example there's things with

00:06:39,330 --> 00:06:45,150
but there's many places there's a kiosk

00:06:43,140 --> 00:06:46,500
spent a lot of time in wireless

00:06:45,150 --> 00:06:48,030
infrastructure so communication

00:06:46,500 --> 00:06:51,720
infrastructure the network that your

00:06:48,030 --> 00:06:53,940
cell phones run over those are bigger

00:06:51,720 --> 00:06:56,810
type things there's smaller things like

00:06:53,940 --> 00:07:01,410
medical devices for doing things like

00:06:56,810 --> 00:07:03,930
insulin blood testing and just a

00:07:01,410 --> 00:07:08,790
plethora of places where embedded

00:07:03,930 --> 00:07:10,980
processing is being used so HPC is is uh

00:07:08,790 --> 00:07:13,410
is a lot of revenue there's a lot of

00:07:10,980 --> 00:07:15,180
money and maybe in some parts of

00:07:13,410 --> 00:07:17,850
high-performance computing but in terms

00:07:15,180 --> 00:07:20,100
of I wish I had some sort of statistics

00:07:17,850 --> 00:07:22,830
to bolster this point but in terms of

00:07:20,100 --> 00:07:25,290
the number of processors that are being

00:07:22,830 --> 00:07:27,030
sold in the world by far more more

00:07:25,290 --> 00:07:29,340
embedded processors are being sold than

00:07:27,030 --> 00:07:31,200
general purpose and high performance

00:07:29,340 --> 00:07:33,600
computing precision so what does that

00:07:31,200 --> 00:07:34,920
mean for this community at least for the

00:07:33,600 --> 00:07:40,200
people in this community that are

00:07:34,920 --> 00:07:43,200
interested in seeing OpenMP grow it

00:07:40,200 --> 00:07:45,450
would be trying to get OpenMP to work in

00:07:43,200 --> 00:07:48,960
on more of the processors that are in

00:07:45,450 --> 00:07:50,460
the world so trying to target the I'm

00:07:48,960 --> 00:07:52,230
giving you some motivation and why it's

00:07:50,460 --> 00:07:54,960
interesting to try and make openmp work

00:07:52,230 --> 00:08:00,480
in embedded processors to get more users

00:07:54,960 --> 00:08:02,040
of OpenMP all right what is an embedded

00:08:00,480 --> 00:08:04,710
system well here's a couple definitions

00:08:02,040 --> 00:08:06,360
just two there's there's a lot of

00:08:04,710 --> 00:08:10,920
different ways to look at it but here's

00:08:06,360 --> 00:08:12,930
two I like it's not a computer whose not

00:08:10,920 --> 00:08:14,670
primarily doing information processing

00:08:12,930 --> 00:08:18,420
in the sense of running a spreadsheet or

00:08:14,670 --> 00:08:21,060
word or a database type thing not that

00:08:18,420 --> 00:08:22,890
type of information but it's a system

00:08:21,060 --> 00:08:25,860
that is interacting with physical

00:08:22,890 --> 00:08:27,870
processes you're reacting to events that

00:08:25,860 --> 00:08:29,969
are going on in the world that you've

00:08:27,870 --> 00:08:34,169
collected from some sort of

00:08:29,969 --> 00:08:36,180
sirs another definition is one that it's

00:08:34,169 --> 00:08:37,649
got a programmable computer but it's not

00:08:36,180 --> 00:08:40,229
a general-purpose computer it's not a

00:08:37,649 --> 00:08:41,849
desktop computer okay so it's

00:08:40,229 --> 00:08:45,720
programmable but it's not something like

00:08:41,849 --> 00:08:48,600
my laptop it's my engine controller in

00:08:45,720 --> 00:08:50,459
my car or something like that a lot of

00:08:48,600 --> 00:08:52,410
times embedded systems take advantage of

00:08:50,459 --> 00:08:54,089
the characteristics of the particular

00:08:52,410 --> 00:08:56,819
application they're going after and they

00:08:54,089 --> 00:08:58,709
optimize so they'll leave things out

00:08:56,819 --> 00:09:01,430
that aren't important for that

00:08:58,709 --> 00:09:03,240
particular application space so

00:09:01,430 --> 00:09:04,740
optimization that you don't need

00:09:03,240 --> 00:09:06,449
necessarily everything that's in a

00:09:04,740 --> 00:09:08,550
general-purpose computer for something

00:09:06,449 --> 00:09:10,050
that's embedded a big part of embedded

00:09:08,550 --> 00:09:12,870
systems is dealing with real time

00:09:10,050 --> 00:09:14,939
constraints okay so there's this concept

00:09:12,870 --> 00:09:17,220
of hard real-time where if you miss the

00:09:14,939 --> 00:09:19,379
deadline something catastrophic is going

00:09:17,220 --> 00:09:21,240
to happen so from friend of mine gave me

00:09:19,379 --> 00:09:23,930
a good example if you've got some sort

00:09:21,240 --> 00:09:26,399
of camera that's helping you monitor

00:09:23,930 --> 00:09:28,649
caps going on bottles as they're going

00:09:26,399 --> 00:09:30,689
by so you know imagine all these coke

00:09:28,649 --> 00:09:32,310
bottles or Pepsi bottles or beer bottles

00:09:30,689 --> 00:09:34,350
going by and you're having some

00:09:32,310 --> 00:09:36,059
automated system put the cap on them if

00:09:34,350 --> 00:09:37,889
you miss your deadline and suddenly get

00:09:36,059 --> 00:09:39,860
off on when that cap is going on you can

00:09:37,889 --> 00:09:43,709
imagine what that's going to do to your

00:09:39,860 --> 00:09:45,480
your automated system so that would be

00:09:43,709 --> 00:09:47,819
kind of loud me a catastrophic problem

00:09:45,480 --> 00:09:50,910
right there there's also soft this

00:09:47,819 --> 00:09:52,860
concept of soft real-time where okay

00:09:50,910 --> 00:09:54,569
maybe it's you know not a catastrophic

00:09:52,860 --> 00:09:56,430
event but you're going to degrade the

00:09:54,569 --> 00:09:58,259
system somehow the quality of service is

00:09:56,430 --> 00:10:01,079
going to go down if you don't make your

00:09:58,259 --> 00:10:02,970
deadline you have this concept of multi

00:10:01,079 --> 00:10:04,680
rate events occurring in other words

00:10:02,970 --> 00:10:06,750
they're not necessarily currently

00:10:04,680 --> 00:10:10,019
occurring at regular periods that could

00:10:06,750 --> 00:10:12,420
be multiple events occurring at random

00:10:10,019 --> 00:10:13,529
periods relative to each other so you

00:10:12,420 --> 00:10:16,800
have to deal with this multi rate

00:10:13,529 --> 00:10:18,689
concept and this can be different for

00:10:16,800 --> 00:10:21,120
people that are traditionally high

00:10:18,689 --> 00:10:23,790
performance oriented is it's not always

00:10:21,120 --> 00:10:27,209
about how fast you can go it's about

00:10:23,790 --> 00:10:29,399
meeting deadlines so even if you get

00:10:27,209 --> 00:10:31,980
something done really quick before the

00:10:29,399 --> 00:10:34,740
deadline has to be met that's not

00:10:31,980 --> 00:10:37,259
necessarily always the most important

00:10:34,740 --> 00:10:38,670
thing okay it could be that well if you

00:10:37,259 --> 00:10:40,350
slowed down you might not use as much

00:10:38,670 --> 00:10:42,149
energy and you can still meet your

00:10:40,350 --> 00:10:43,870
deadline or some other trade-off you can

00:10:42,149 --> 00:10:45,580
make so it's not all

00:10:43,870 --> 00:10:47,800
just about performance you have

00:10:45,580 --> 00:10:50,589
constraints like I mentioned before such

00:10:47,800 --> 00:10:52,420
as power temperature you might not be in

00:10:50,589 --> 00:10:55,870
a place where there's cooling available

00:10:52,420 --> 00:10:58,000
you have size constraints and you also

00:10:55,870 --> 00:10:59,620
have this interesting concept that your

00:10:58,000 --> 00:11:00,730
program is going to run forever okay

00:10:59,620 --> 00:11:02,529
you're going to you're going to put it

00:11:00,730 --> 00:11:04,390
in some system and it's going to be if

00:11:02,529 --> 00:11:05,730
you run out if you have some memory leak

00:11:04,390 --> 00:11:07,839
that's going to accumulate over time

00:11:05,730 --> 00:11:09,339
that's going to be a big problem because

00:11:07,839 --> 00:11:12,240
your program is supposed to be running

00:11:09,339 --> 00:11:17,620
forever well or at least until that

00:11:12,240 --> 00:11:19,570
system is no longer around so embedded

00:11:17,620 --> 00:11:22,860
systems are responding to inputs from

00:11:19,570 --> 00:11:25,000
the real world so you have some sort of

00:11:22,860 --> 00:11:27,670
sensors that are collecting information

00:11:25,000 --> 00:11:29,800
from the real world you have some those

00:11:27,670 --> 00:11:31,950
come in typically in some analog form

00:11:29,800 --> 00:11:34,750
then you have some mechanism some

00:11:31,950 --> 00:11:37,029
analog-to-digital converters that then

00:11:34,750 --> 00:11:39,400
convert it into a digitized form that

00:11:37,029 --> 00:11:41,529
your processor can deal with so there's

00:11:39,400 --> 00:11:43,540
this trade-off going from the analog

00:11:41,529 --> 00:11:45,970
world to the digital world you then have

00:11:43,540 --> 00:11:48,490
some sort of processor which then is

00:11:45,970 --> 00:11:51,700
going to work on that digital

00:11:48,490 --> 00:11:54,790
information come up with some result

00:11:51,700 --> 00:11:57,070
some response again take that and

00:11:54,790 --> 00:11:59,650
convert it back from a digital signal

00:11:57,070 --> 00:12:02,620
back to an analog signal and communicate

00:11:59,650 --> 00:12:05,080
that signal back out to some speaker or

00:12:02,620 --> 00:12:07,150
screen or whatever okay so it's this

00:12:05,080 --> 00:12:11,410
concept of interacting with the world

00:12:07,150 --> 00:12:13,750
and there's been really this growth in

00:12:11,410 --> 00:12:15,940
the development of sensor technologies

00:12:13,750 --> 00:12:18,209
so there are a lot of new sensors being

00:12:15,940 --> 00:12:21,100
created out there with a lot of

00:12:18,209 --> 00:12:26,709
precision so there's a lot of data that

00:12:21,100 --> 00:12:29,230
is there to be processed all right one

00:12:26,709 --> 00:12:31,360
thing that's very interesting about

00:12:29,230 --> 00:12:34,810
embedded systems is that the platforms

00:12:31,360 --> 00:12:36,610
are very diverse I'm from Texas

00:12:34,810 --> 00:12:40,209
Instruments obviously so I'm giving you

00:12:36,610 --> 00:12:42,670
the Texas Instruments collection of

00:12:40,209 --> 00:12:46,450
devices here but you can go to any of

00:12:42,670 --> 00:12:47,680
the other vendors that produce products

00:12:46,450 --> 00:12:49,270
for this area and you'll see very

00:12:47,680 --> 00:12:52,870
similar types of things it's a very

00:12:49,270 --> 00:12:54,700
diverse set of processors if I compare

00:12:52,870 --> 00:12:56,460
that to what we talked about in OpenMP

00:12:54,700 --> 00:12:58,770
the world of open a peewee it's

00:12:56,460 --> 00:13:00,870
like there's two or three processors we

00:12:58,770 --> 00:13:02,190
talked about in one or two accelerators

00:13:00,870 --> 00:13:06,560
and we spent a lot of time talking about

00:13:02,190 --> 00:13:08,880
that set of processors but then the

00:13:06,560 --> 00:13:11,610
chips and platforms are using embedded

00:13:08,880 --> 00:13:12,960
are very diverse so I've got very simple

00:13:11,610 --> 00:13:14,850
on the far left I know these are very

00:13:12,960 --> 00:13:18,750
small pictures but those are really just

00:13:14,850 --> 00:13:20,430
basic my microcontrollers where

00:13:18,750 --> 00:13:22,950
everything is contained on that chip the

00:13:20,430 --> 00:13:24,900
memory everything is self-contained then

00:13:22,950 --> 00:13:28,350
we have things where there's more

00:13:24,900 --> 00:13:29,910
real-time type process arms are control

00:13:28,350 --> 00:13:32,040
type processors or some DSP

00:13:29,910 --> 00:13:33,540
functionality built in and then people

00:13:32,040 --> 00:13:35,370
do things like way let's put two of

00:13:33,540 --> 00:13:37,320
those down not that all of a sudden

00:13:35,370 --> 00:13:39,540
looks interesting from a TI point of

00:13:37,320 --> 00:13:42,450
view there's versions they do where they

00:13:39,540 --> 00:13:44,670
they put Wi-Fi processors on there

00:13:42,450 --> 00:13:47,760
there's a version here that's got an arm

00:13:44,670 --> 00:13:49,650
and a and a controller on there so now

00:13:47,760 --> 00:13:51,630
we have this heterogeneous concept those

00:13:49,650 --> 00:13:52,940
are just these basic microcontrollers

00:13:51,630 --> 00:13:55,590
then we get into the more

00:13:52,940 --> 00:13:57,930
microprocessor-based where you have more

00:13:55,590 --> 00:14:00,600
complex systems may be running Linux and

00:13:57,930 --> 00:14:04,020
you've got arms with graphics processors

00:14:00,600 --> 00:14:05,790
and DSPs you have a lot of peripheral

00:14:04,020 --> 00:14:07,830
peripherals that are built into the chip

00:14:05,790 --> 00:14:10,850
for doing specific I oh so you can see

00:14:07,830 --> 00:14:17,340
that they get very sophisticated but

00:14:10,850 --> 00:14:18,690
they are very diverse okay so some of

00:14:17,340 --> 00:14:19,770
the things you need to worry about or

00:14:18,690 --> 00:14:22,410
think about when you're programming

00:14:19,770 --> 00:14:24,620
bedded systems is that concurrency is

00:14:22,410 --> 00:14:27,960
intrinsic in these systems you're always

00:14:24,620 --> 00:14:29,730
the real world is obviously made up of

00:14:27,960 --> 00:14:32,190
concurrent events going on and you're

00:14:29,730 --> 00:14:36,870
you have processes that are conceptually

00:14:32,190 --> 00:14:38,850
these concurrent things running that can

00:14:36,870 --> 00:14:40,920
run in parallel not necessarily running

00:14:38,850 --> 00:14:43,200
in parallel but you think about them in

00:14:40,920 --> 00:14:46,140
your programming as being tasks that are

00:14:43,200 --> 00:14:48,270
managing receiving inputs from a sensor

00:14:46,140 --> 00:14:50,550
and we aren't responding to that so the

00:14:48,270 --> 00:14:53,160
that thought process is very concurrent

00:14:50,550 --> 00:14:55,800
thought process it's not necessarily

00:14:53,160 --> 00:14:58,230
about exploiting parallelism it's just

00:14:55,800 --> 00:15:00,330
thinking about you can have parallelism

00:14:58,230 --> 00:15:02,310
in your system and have these tasks

00:15:00,330 --> 00:15:03,920
executing concurrently but you can also

00:15:02,310 --> 00:15:06,240
describe your system is just being

00:15:03,920 --> 00:15:08,280
concurrent tasks that are actually just

00:15:06,240 --> 00:15:09,480
running on one thread where you're

00:15:08,280 --> 00:15:11,550
switching with that one

00:15:09,480 --> 00:15:12,769
between those tasks so I'm just trying

00:15:11,550 --> 00:15:14,850
to make this distinction between

00:15:12,769 --> 00:15:16,740
concurrency and parallelism we and

00:15:14,850 --> 00:15:18,510
OpenMP talk a lot about parallelism

00:15:16,740 --> 00:15:20,070
creating threads are always going to be

00:15:18,510 --> 00:15:22,170
executing in parallel doing parallel

00:15:20,070 --> 00:15:24,720
work and embedded you're talking more

00:15:22,170 --> 00:15:28,440
about concurrent tasks that are managing

00:15:24,720 --> 00:15:31,980
things you spend a lot of time working

00:15:28,440 --> 00:15:33,779
on the interaction with your I oh the

00:15:31,980 --> 00:15:37,500
places that you're getting these sensors

00:15:33,779 --> 00:15:39,480
from again you have this concept of real

00:15:37,500 --> 00:15:41,160
time you're having to keep up with that

00:15:39,480 --> 00:15:42,899
I oh that you're getting from the

00:15:41,160 --> 00:15:45,269
external world if you miss some of it

00:15:42,899 --> 00:15:47,430
that could be a problem the programmer

00:15:45,269 --> 00:15:50,639
gets exposed to things like interrupts

00:15:47,430 --> 00:15:53,130
and timers and they get really exposed

00:15:50,639 --> 00:15:55,019
very often to them to the memory

00:15:53,130 --> 00:15:58,079
hierarchy the different parts of the

00:15:55,019 --> 00:16:00,209
memory system the RAM the rom the flash

00:15:58,079 --> 00:16:02,040
where am I going to put different parts

00:16:00,209 --> 00:16:03,899
of my program you spend a lot of time

00:16:02,040 --> 00:16:06,000
working with the more time working with

00:16:03,899 --> 00:16:07,199
the linker in embedded programming than

00:16:06,000 --> 00:16:09,300
you do in general-purpose programming

00:16:07,199 --> 00:16:11,430
because you're you have to get down to

00:16:09,300 --> 00:16:13,230
that next level of detail about placing

00:16:11,430 --> 00:16:18,180
specific parts of your program in these

00:16:13,230 --> 00:16:19,829
specific memory areas you traditionally

00:16:18,180 --> 00:16:22,380
do all your programming and see with

00:16:19,829 --> 00:16:25,529
some seven language is not a hundred

00:16:22,380 --> 00:16:27,389
percent that way but predominantly when

00:16:25,529 --> 00:16:29,160
you build one of these systems you you

00:16:27,389 --> 00:16:30,930
start you recompile everything from

00:16:29,160 --> 00:16:34,110
scratch for your given system you don't

00:16:30,930 --> 00:16:35,699
tend to use a libraries and systems and

00:16:34,110 --> 00:16:37,380
stitch them all together you recompile

00:16:35,699 --> 00:16:39,899
everything and put it all together at

00:16:37,380 --> 00:16:41,819
once and so what's nice about that is

00:16:39,899 --> 00:16:43,949
that you give the compiler a chance to

00:16:41,819 --> 00:16:47,699
specialize everything for that

00:16:43,949 --> 00:16:50,910
particular build you're not interacting

00:16:47,699 --> 00:16:52,079
with these with a full-blown operating

00:16:50,910 --> 00:16:55,230
system you have more of these

00:16:52,079 --> 00:16:59,850
lightweight micro kernels or real-time

00:16:55,230 --> 00:17:03,000
operating systems so this is the basic

00:16:59,850 --> 00:17:05,189
paradigm that you end up programming not

00:17:03,000 --> 00:17:08,339
all embedded systems are like this but

00:17:05,189 --> 00:17:11,309
this is represents a large set of them

00:17:08,339 --> 00:17:13,319
is that you have some sort of input like

00:17:11,309 --> 00:17:14,970
I've said multiple times now coming from

00:17:13,319 --> 00:17:20,669
these sensors so you have some sort of

00:17:14,970 --> 00:17:22,569
task process monitoring the sensor it's

00:17:20,669 --> 00:17:24,639
usually interrupt driven where

00:17:22,569 --> 00:17:26,709
the sensor indicates to you hey I've got

00:17:24,639 --> 00:17:31,389
enough data for you now to go collect

00:17:26,709 --> 00:17:33,820
and work on you then fire off from those

00:17:31,389 --> 00:17:36,630
interrupt service routine zor is ours a

00:17:33,820 --> 00:17:39,399
task to go actually process that data

00:17:36,630 --> 00:17:42,159
once it's done processing it it might

00:17:39,399 --> 00:17:43,899
then go fill up some other buffer that

00:17:42,159 --> 00:17:46,659
might generate and generate some other

00:17:43,899 --> 00:17:49,659
event to indicate okay it's time for

00:17:46,659 --> 00:17:52,480
some other external entity to go deal

00:17:49,659 --> 00:17:55,419
with this data I've just produced so in

00:17:52,480 --> 00:17:57,190
a very simple system this is pretty easy

00:17:55,419 --> 00:18:01,720
to manage but as soon as you start

00:17:57,190 --> 00:18:05,080
getting multiple input tasks multiple

00:18:01,720 --> 00:18:07,090
data processing tasks multiple tasks can

00:18:05,080 --> 00:18:09,039
get fairly complicated and that's when

00:18:07,090 --> 00:18:11,490
you start you rely on things like a

00:18:09,039 --> 00:18:17,250
real-time operating system to help

00:18:11,490 --> 00:18:21,909
manage this okay so I'm going to switch

00:18:17,250 --> 00:18:27,240
gears for a minute here and just talk

00:18:21,909 --> 00:18:29,320
about how we have adapted open mp4 and a

00:18:27,240 --> 00:18:31,149
processor that was traditionally

00:18:29,320 --> 00:18:33,370
targeted at embedded systems and just

00:18:31,149 --> 00:18:38,620
highlight how we dealt with some of

00:18:33,370 --> 00:18:40,179
these things so initially the area the

00:18:38,620 --> 00:18:42,429
areas of focus that this particular

00:18:40,179 --> 00:18:44,470
processor was targeted at or is target

00:18:42,429 --> 00:18:47,409
at is more of the high-performance end

00:18:44,470 --> 00:18:49,480
of the computing spectrum in embedded

00:18:47,409 --> 00:18:51,940
computing so like I gave you some

00:18:49,480 --> 00:18:53,649
examples before this would be the type

00:18:51,940 --> 00:18:56,200
of applications that require spend more

00:18:53,649 --> 00:18:58,450
time and that compute and data intensive

00:18:56,200 --> 00:19:02,909
part of the program so these would be

00:18:58,450 --> 00:19:05,049
things like imaging or analytics or

00:19:02,909 --> 00:19:07,090
something with smart cameras or in

00:19:05,049 --> 00:19:11,110
mission-critical systems radar systems

00:19:07,090 --> 00:19:14,460
or maybe the compute that's in the top

00:19:11,110 --> 00:19:16,149
in the cone of some of those drones

00:19:14,460 --> 00:19:18,909
things where you're doing more

00:19:16,149 --> 00:19:22,870
processing usually of signals or videos

00:19:18,909 --> 00:19:25,179
or imaging or video streams so TI had a

00:19:22,870 --> 00:19:28,960
single core DSP and just like everybody

00:19:25,179 --> 00:19:31,179
else in the semiconductor world they

00:19:28,960 --> 00:19:32,860
started integrating many of them onto a

00:19:31,179 --> 00:19:34,629
single chip because of all of the

00:19:32,860 --> 00:19:35,440
limitations of physics that we were all

00:19:34,629 --> 00:19:39,070
running into

00:19:35,440 --> 00:19:40,330
so it was like okay we had one core and

00:19:39,070 --> 00:19:41,529
now we're not going to make it any

00:19:40,330 --> 00:19:43,659
faster we're just going to start putting

00:19:41,529 --> 00:19:47,470
more cores down what are we supposed to

00:19:43,659 --> 00:19:48,669
do with all our customers who you know

00:19:47,470 --> 00:19:50,139
would before we would just give them a

00:19:48,669 --> 00:19:51,909
faster chip and they'd we compile their

00:19:50,139 --> 00:19:54,129
code and everything would be great well

00:19:51,909 --> 00:19:55,450
now that's not going to work now we're

00:19:54,129 --> 00:19:57,039
just giving them eight chips we didn't

00:19:55,450 --> 00:20:00,190
make any one of them go any faster what

00:19:57,039 --> 00:20:02,019
are we going to do and that's when we

00:20:00,190 --> 00:20:03,940
started looking around and trying to

00:20:02,019 --> 00:20:06,580
just like we've always done in embedded

00:20:03,940 --> 00:20:08,590
systems we try and adapt things just

00:20:06,580 --> 00:20:10,659
like we've adapted C code to work in a

00:20:08,590 --> 00:20:13,330
min system so we saw that openmp was

00:20:10,659 --> 00:20:16,809
there let's try and adapt OpenMP for

00:20:13,330 --> 00:20:17,889
these types of processors so here just

00:20:16,809 --> 00:20:19,659
to give you a quick overview here's

00:20:17,889 --> 00:20:20,980
these 8 d's piece there's those eight

00:20:19,659 --> 00:20:23,919
little blocks right there they each have

00:20:20,980 --> 00:20:25,360
their own little caches there's some odd

00:20:23,919 --> 00:20:28,179
chip shared memory that they can use

00:20:25,360 --> 00:20:30,639
that's it's not cache coherent between

00:20:28,179 --> 00:20:33,669
the individual cores and then they can

00:20:30,639 --> 00:20:38,379
go off chip to get at shared memory

00:20:33,669 --> 00:20:40,090
which is in external ddr so this is just

00:20:38,379 --> 00:20:41,950
echoing what i just said we're like well

00:20:40,090 --> 00:20:43,750
are what are our users going to do

00:20:41,950 --> 00:20:46,539
traditionally they'd have to go manually

00:20:43,750 --> 00:20:50,409
stitch all this stuff together they they

00:20:46,539 --> 00:20:52,960
could we see I had you know libraries

00:20:50,409 --> 00:20:54,549
that was very TI specific but that

00:20:52,960 --> 00:20:57,730
didn't seem very productive in the long

00:20:54,549 --> 00:20:59,740
term so that's that's why we started

00:20:57,730 --> 00:21:02,980
looking at OpenMP you know it's it was

00:20:59,740 --> 00:21:05,169
based on just this is a very simple

00:21:02,980 --> 00:21:06,610
approach it's portable it's easy and

00:21:05,169 --> 00:21:08,259
incremental they can start with their

00:21:06,610 --> 00:21:12,279
serial code and start adding parallelism

00:21:08,259 --> 00:21:13,720
to it all the benefits that I think many

00:21:12,279 --> 00:21:15,669
of you are familiar with but maybe

00:21:13,720 --> 00:21:18,759
people in the embedded world aren't you

00:21:15,669 --> 00:21:21,490
all know what openmp is about a fork

00:21:18,759 --> 00:21:24,940
join model there's basically two types

00:21:21,490 --> 00:21:27,279
of types of parallelism that are

00:21:24,940 --> 00:21:30,610
supported there's the data parallel your

00:21:27,279 --> 00:21:33,309
traditional parallel for and then you've

00:21:30,610 --> 00:21:36,429
got the task parallel which allows you

00:21:33,309 --> 00:21:39,009
to do more of the tasks constructs in

00:21:36,429 --> 00:21:42,850
parallel I'll talk about that more as

00:21:39,009 --> 00:21:45,340
part of my event driven system I just

00:21:42,850 --> 00:21:47,620
want to highlight the memory model so

00:21:45,340 --> 00:21:49,990
you've got this concept where

00:21:47,620 --> 00:21:52,420
each processor has their own cash they

00:21:49,990 --> 00:21:56,050
have their individual they have their

00:21:52,420 --> 00:21:58,120
access to a shared memory but really the

00:21:56,050 --> 00:21:59,920
threads the individual course do you

00:21:58,120 --> 00:22:01,630
know have that the threads running on

00:21:59,920 --> 00:22:03,430
the course don't have to be coherent

00:22:01,630 --> 00:22:05,890
with each other during a parallel region

00:22:03,430 --> 00:22:08,770
there's this concept of a temporary view

00:22:05,890 --> 00:22:10,630
and OpenMP that a thread is allowed to

00:22:08,770 --> 00:22:13,210
have when it's in a parallel region and

00:22:10,630 --> 00:22:17,230
that view doesn't have to be consistent

00:22:13,210 --> 00:22:19,750
until the end of the the join region so

00:22:17,230 --> 00:22:23,980
we looked at that and thought AHA that's

00:22:19,750 --> 00:22:25,510
a way to okay well you can just tell me

00:22:23,980 --> 00:22:28,960
why I'm incorrect at the end i'll

00:22:25,510 --> 00:22:33,340
appreciate that that's how we were able

00:22:28,960 --> 00:22:35,800
to make OpenMP work on our multi-core

00:22:33,340 --> 00:22:37,390
DSP that didn't have cache coherency so

00:22:35,800 --> 00:22:38,950
basically we just said all right we'll

00:22:37,390 --> 00:22:41,010
have eight threads eat one thread will

00:22:38,950 --> 00:22:44,590
run on each core we'll take our

00:22:41,010 --> 00:22:46,240
low-level runtime real-time operating

00:22:44,590 --> 00:22:48,040
system and we'll just use it to give us

00:22:46,240 --> 00:22:49,960
a thread on each core we could we got up

00:22:48,040 --> 00:22:52,000
more than one but we can also eliminate

00:22:49,960 --> 00:22:54,490
the real-time operating system and just

00:22:52,000 --> 00:22:57,130
run bare metal just running directly on

00:22:54,490 --> 00:22:58,420
the hardware we don't support nesting

00:22:57,130 --> 00:23:01,030
you just get one thread if you have a

00:22:58,420 --> 00:23:02,470
nested pearl region and so the way we

00:23:01,030 --> 00:23:04,870
dealt with not having a lack of

00:23:02,470 --> 00:23:06,910
coherency again was that we basically

00:23:04,870 --> 00:23:11,140
just we flush the cache at the beginning

00:23:06,910 --> 00:23:16,690
we flushed the cash at the end and it

00:23:11,140 --> 00:23:23,190
works so we were able to run OpenMP on

00:23:16,690 --> 00:23:26,080
this multi-core DSP so the thing that

00:23:23,190 --> 00:23:28,420
that I want you to if it's not already

00:23:26,080 --> 00:23:31,330
obvious is that ok OpenMP has a stack

00:23:28,420 --> 00:23:33,040
the users application is running and

00:23:31,330 --> 00:23:34,960
using the directives the library the

00:23:33,040 --> 00:23:36,460
environment variables but beneath their

00:23:34,960 --> 00:23:38,230
there's a run time but that's all

00:23:36,460 --> 00:23:40,600
sitting on and you could think of the

00:23:38,230 --> 00:23:43,120
lowest layer that run time is some sort

00:23:40,600 --> 00:23:45,250
of low-level I call it a parallel thread

00:23:43,120 --> 00:23:48,250
API to give you some time to P threads

00:23:45,250 --> 00:23:50,020
but some sort of low-level API that's

00:23:48,250 --> 00:23:51,970
giving you basic functionality like

00:23:50,020 --> 00:23:53,800
creating threads and some way to do

00:23:51,970 --> 00:23:56,110
locks and things like that so if you can

00:23:53,800 --> 00:23:58,240
just take that very low level and make

00:23:56,110 --> 00:23:59,929
that run on top of something other than

00:23:58,240 --> 00:24:02,299
like S&P linux or

00:23:59,929 --> 00:24:04,220
some higher level of us but you can make

00:24:02,299 --> 00:24:06,919
it run on an artists you can make it run

00:24:04,220 --> 00:24:08,990
on the multi-core association interfaces

00:24:06,919 --> 00:24:11,929
you can make it run like we've done even

00:24:08,990 --> 00:24:14,740
just bare metal so just showing you that

00:24:11,929 --> 00:24:18,999
that that OpenMP is portable to these

00:24:14,740 --> 00:24:21,379
more constrained type architectures

00:24:18,999 --> 00:24:23,210
alright so this is just summarizing what

00:24:21,379 --> 00:24:24,409
I just said but what I've just went

00:24:23,210 --> 00:24:26,240
through but just look at the highlights

00:24:24,409 --> 00:24:28,669
we shown you can do it in a bear mental

00:24:26,240 --> 00:24:29,869
way that you can that we are able to do

00:24:28,669 --> 00:24:32,509
it with shared memory but without

00:24:29,869 --> 00:24:34,730
precise hardware cache coherency it can

00:24:32,509 --> 00:24:36,619
that we wanted we feel like we've shown

00:24:34,730 --> 00:24:38,240
that in that it can be successful in

00:24:36,619 --> 00:24:40,730
embedded systems and just like other

00:24:38,240 --> 00:24:43,249
high-level concepts openmp can be

00:24:40,730 --> 00:24:46,070
adapted into it into the embedded world

00:24:43,249 --> 00:24:48,559
all right so it's what but what we have

00:24:46,070 --> 00:24:50,149
here is this really just still good for

00:24:48,559 --> 00:24:51,919
the compute intensive parts of an

00:24:50,149 --> 00:24:55,779
application all right I'm still just

00:24:51,919 --> 00:24:59,450
doing traditional openmp parallel for on

00:24:55,779 --> 00:25:02,090
on big data at least in the sense that

00:24:59,450 --> 00:25:03,320
it's on a chip big data but what about

00:25:02,090 --> 00:25:06,499
the other parts of the program what

00:25:03,320 --> 00:25:07,759
about this event driven world I've been

00:25:06,499 --> 00:25:09,529
talking about what about how do you deal

00:25:07,759 --> 00:25:13,549
with these these processors and things

00:25:09,529 --> 00:25:15,980
like that so typically the way this

00:25:13,549 --> 00:25:17,840
works in an embedded system is that you

00:25:15,980 --> 00:25:20,950
have some sort of event loop barring

00:25:17,840 --> 00:25:23,840
this is a very very simplified

00:25:20,950 --> 00:25:26,090
presentation of this idea but you've got

00:25:23,840 --> 00:25:28,549
an infinite loop you have some way of

00:25:26,090 --> 00:25:30,769
getting an event from the world you see

00:25:28,549 --> 00:25:32,869
with that event is and you invoke the

00:25:30,769 --> 00:25:37,100
individual handler for that event you

00:25:32,869 --> 00:25:38,330
know and again those events events are

00:25:37,100 --> 00:25:40,639
typically coming from things like

00:25:38,330 --> 00:25:42,799
sensors or other actors in your system

00:25:40,639 --> 00:25:44,149
and you have to think that you have to

00:25:42,799 --> 00:25:46,249
consider which would not be done by the

00:25:44,149 --> 00:25:47,990
sleep by the way is that you have to

00:25:46,249 --> 00:25:49,789
stay responsive while those events are

00:25:47,990 --> 00:25:51,499
being processed okay so you can't just

00:25:49,789 --> 00:25:53,360
say get an event and go focus on that

00:25:51,499 --> 00:25:55,820
one event ignore all other events that

00:25:53,360 --> 00:25:57,860
are happening you've got to be able to

00:25:55,820 --> 00:25:59,240
stay responsive it's similar there was

00:25:57,860 --> 00:26:01,759
there was someone that came and talked

00:25:59,240 --> 00:26:04,929
to us at one of our open in PE

00:26:01,759 --> 00:26:07,129
face-to-face meeting in Australia and

00:26:04,929 --> 00:26:09,080
they were they were looking at a similar

00:26:07,129 --> 00:26:11,029
type of problem but for trying to make

00:26:09,080 --> 00:26:13,159
open and P work in a GUI cut environment

00:26:11,029 --> 00:26:13,730
i gue you like with a GUI where you have

00:26:13,159 --> 00:26:15,530
someone

00:26:13,730 --> 00:26:17,090
you know interacting with the GUI and

00:26:15,530 --> 00:26:20,090
it's having things go off in the

00:26:17,090 --> 00:26:23,210
background so I refer you to their paper

00:26:20,090 --> 00:26:24,290
to go take a look at that their approach

00:26:23,210 --> 00:26:26,600
is a little different than what I'm

00:26:24,290 --> 00:26:29,870
talking about here but back to what I

00:26:26,600 --> 00:26:33,050
showed earlier is so if you remember I

00:26:29,870 --> 00:26:35,330
showed this earlier this paradigm of you

00:26:33,050 --> 00:26:38,390
have these these inputs coming in which

00:26:35,330 --> 00:26:39,950
are being driven or responded to you by

00:26:38,390 --> 00:26:42,170
some sort of interrupt service routine

00:26:39,950 --> 00:26:44,060
and then you process them and then you

00:26:42,170 --> 00:26:47,330
again send that send your results back

00:26:44,060 --> 00:26:49,460
out the way this is implemented on today

00:26:47,330 --> 00:26:50,840
on many systems is that stun on top of a

00:26:49,460 --> 00:26:52,610
real-time operating system which

00:26:50,840 --> 00:26:56,180
provides you with with these kind of

00:26:52,610 --> 00:26:59,200
basic functionalities for creating tasks

00:26:56,180 --> 00:27:01,880
for doing scheduling for doing past

00:26:59,200 --> 00:27:06,920
synchronization between these individual

00:27:01,880 --> 00:27:10,430
tasks that typically use a different

00:27:06,920 --> 00:27:12,410
kind of schedulers than something that

00:27:10,430 --> 00:27:15,110
we would be using in or that would be

00:27:12,410 --> 00:27:16,610
running underneath the threads that that

00:27:15,110 --> 00:27:19,490
might be implementing openmp would be

00:27:16,610 --> 00:27:21,530
using they have much more sophisticated

00:27:19,490 --> 00:27:23,410
scheduling algorithms to make sure that

00:27:21,530 --> 00:27:25,910
you can meet these real-time deadlines

00:27:23,410 --> 00:27:27,800
so some of the differences between a

00:27:25,910 --> 00:27:30,500
general-purpose operating system is

00:27:27,800 --> 00:27:35,420
there they're very you tailor them to

00:27:30,500 --> 00:27:37,640
very specific inferior given application

00:27:35,420 --> 00:27:40,700
you'll put things in leave things out

00:27:37,640 --> 00:27:43,760
there's much smaller they have much

00:27:40,700 --> 00:27:45,860
faster response times they have their

00:27:43,760 --> 00:27:48,110
limiting the type of file systems that

00:27:45,860 --> 00:27:49,970
can interact with you have dynamic

00:27:48,110 --> 00:27:51,650
memory in both cases typically although

00:27:49,970 --> 00:27:54,950
you could leave that out and the in the

00:27:51,650 --> 00:27:57,110
real-time OS if you want you don't think

00:27:54,950 --> 00:27:59,150
about like processes and peak threads so

00:27:57,110 --> 00:28:02,180
much talk about tasks and their

00:27:59,150 --> 00:28:06,260
observers routines and idle tasks it's

00:28:02,180 --> 00:28:07,790
not based on time slicing where if you

00:28:06,260 --> 00:28:09,470
are doing some sort of scheduling you

00:28:07,790 --> 00:28:11,000
know typically you have some sort of

00:28:09,470 --> 00:28:12,500
time slicing where you swap out one

00:28:11,000 --> 00:28:14,300
thread and bring in another it's more

00:28:12,500 --> 00:28:16,670
based on preemption where if a task is

00:28:14,300 --> 00:28:19,280
running or a thread is running and it's

00:28:16,670 --> 00:28:20,840
it's going to run until it releases and

00:28:19,280 --> 00:28:23,390
says okay it's okay for some other

00:28:20,840 --> 00:28:25,520
thread to run now so until it gives

00:28:23,390 --> 00:28:26,930
itself up by going into the scheduler

00:28:25,520 --> 00:28:30,950
it's going to

00:28:26,930 --> 00:28:32,840
you running typically again it's the

00:28:30,950 --> 00:28:35,180
diverse set of architectures that an

00:28:32,840 --> 00:28:37,040
artist has got to be adapted to and on a

00:28:35,180 --> 00:28:39,830
general-purpose OS it's more of those

00:28:37,040 --> 00:28:42,320
three processors that we tend to talk

00:28:39,830 --> 00:28:43,550
about in our community a lot I might be

00:28:42,320 --> 00:28:49,340
leaving the other one out of there if I

00:28:43,550 --> 00:28:50,870
am I'm sorry all right so again these

00:28:49,340 --> 00:28:52,820
events are triggered by interrupts and

00:28:50,870 --> 00:28:54,890
one way to think about you know setting

00:28:52,820 --> 00:28:58,130
up these types of systems is like the

00:28:54,890 --> 00:28:59,540
way I showed before or really what you

00:28:58,130 --> 00:29:01,040
do is you have these interrupt service

00:28:59,540 --> 00:29:03,110
routine czar kind of like more of these

00:29:01,040 --> 00:29:05,390
asynchronous types of tasks that are

00:29:03,110 --> 00:29:07,040
running you have some sort of wild loop

00:29:05,390 --> 00:29:08,090
that's running maybe you're collecting

00:29:07,040 --> 00:29:11,750
statistics or you're doing something

00:29:08,090 --> 00:29:14,570
that's not not a real time critical type

00:29:11,750 --> 00:29:16,490
of operation and when one of these is RS

00:29:14,570 --> 00:29:18,920
is triggered it says AHA I've got to go

00:29:16,490 --> 00:29:20,660
off in get this buffer that this sensor

00:29:18,920 --> 00:29:21,980
just told me it was full of data and I

00:29:20,660 --> 00:29:26,090
need to go process it and then maybe

00:29:21,980 --> 00:29:28,280
I'll do some I owe on it and then wait

00:29:26,090 --> 00:29:30,530
what you do is you think about

00:29:28,280 --> 00:29:32,270
transforming that into basically a bunch

00:29:30,530 --> 00:29:34,910
of tasks that are running where the

00:29:32,270 --> 00:29:36,830
scheduler then decides which task is

00:29:34,910 --> 00:29:38,780
running which of these tasks is that the

00:29:36,830 --> 00:29:41,030
highest priority needs to be running so

00:29:38,780 --> 00:29:43,100
you take what I've originally started

00:29:41,030 --> 00:29:46,280
with of that while loop think about it

00:29:43,100 --> 00:29:47,990
more as tasks put those tasks into an

00:29:46,280 --> 00:29:50,710
environment where they're running have

00:29:47,990 --> 00:29:53,000
some sort of priority among the tasks

00:29:50,710 --> 00:29:54,590
obviously the ones dealing with the

00:29:53,000 --> 00:29:57,140
interrupt service routine s need to be

00:29:54,590 --> 00:30:00,140
the highest priority but you end up with

00:29:57,140 --> 00:30:02,000
this concept of a bunch of tasks running

00:30:00,140 --> 00:30:03,560
in parallel in it where some of them are

00:30:02,000 --> 00:30:08,390
interacting with the real world some of

00:30:03,560 --> 00:30:12,740
them are doing data processing so just

00:30:08,390 --> 00:30:15,170
to talk about the different types of

00:30:12,740 --> 00:30:16,820
tasks so like I said before your idle

00:30:15,170 --> 00:30:18,020
task is maybe the thing that's just

00:30:16,820 --> 00:30:19,640
running in the background it can

00:30:18,020 --> 00:30:22,550
actually still be doing stuff but it's

00:30:19,640 --> 00:30:26,780
not it's more like maybe like collecting

00:30:22,550 --> 00:30:28,460
statistics or updating some sort of user

00:30:26,780 --> 00:30:31,010
interface type thing something that's

00:30:28,460 --> 00:30:33,410
not time-critical necessarily on a user

00:30:31,010 --> 00:30:34,820
interface maybe climb critical tasks are

00:30:33,410 --> 00:30:36,200
the things that are processing data

00:30:34,820 --> 00:30:37,520
that's come in there that sort of the

00:30:36,200 --> 00:30:38,590
middle priority and then your highest

00:30:37,520 --> 00:30:40,419
priority events or the

00:30:38,590 --> 00:30:43,210
you're interrupt service routine those

00:30:40,419 --> 00:30:45,429
tasks that need to go off and deal with

00:30:43,210 --> 00:30:46,990
some event that has just been hot that

00:30:45,429 --> 00:30:50,140
it's just occurred in the real world and

00:30:46,990 --> 00:30:52,059
needs to be dealt with immediately so

00:30:50,140 --> 00:30:54,520
the way these interrupt service routine

00:30:52,059 --> 00:30:57,520
work is you want them to be really fast

00:30:54,520 --> 00:30:59,020
at responding but then you don't want to

00:30:57,520 --> 00:31:00,400
spend a lot of time in your in a

00:30:59,020 --> 00:31:02,710
interrupt service routine because

00:31:00,400 --> 00:31:04,690
typically when you're dealing with

00:31:02,710 --> 00:31:06,220
something in an Arab service routine you

00:31:04,690 --> 00:31:07,960
sort of blocked all other interrupts

00:31:06,220 --> 00:31:09,250
from happening at that moment you're in

00:31:07,960 --> 00:31:10,929
you're in kind of what we might think of

00:31:09,250 --> 00:31:14,590
as this critical region so you want to

00:31:10,929 --> 00:31:19,179
quickly respond or capture whatever that

00:31:14,590 --> 00:31:21,039
event is somehow collect that into some

00:31:19,179 --> 00:31:23,049
sort of package of data and give it to a

00:31:21,039 --> 00:31:24,429
follow-up task and then get out of that

00:31:23,049 --> 00:31:26,980
interrupt service routine as quickly as

00:31:24,429 --> 00:31:29,169
possible so so that you're not you know

00:31:26,980 --> 00:31:31,419
locked out from dealing with another

00:31:29,169 --> 00:31:33,760
interrupt that might occur so is ours

00:31:31,419 --> 00:31:36,520
interrupts routines you quickly deal

00:31:33,760 --> 00:31:38,230
with the event package up the data for a

00:31:36,520 --> 00:31:42,850
follow-up task and then get out as

00:31:38,230 --> 00:31:44,860
quickly as you can so this is just kind

00:31:42,850 --> 00:31:47,440
of pictorial pictorial II showing you

00:31:44,860 --> 00:31:50,260
that concept the ISR tends to have its

00:31:47,440 --> 00:31:52,360
own stack the tends to share a system

00:31:50,260 --> 00:31:54,190
stack tends to be as quick as possible

00:31:52,360 --> 00:31:56,980
you don't get interrupted you run to

00:31:54,190 --> 00:32:00,070
completion the data that it then creates

00:31:56,980 --> 00:32:02,200
is sent to some sort of other task that

00:32:00,070 --> 00:32:04,600
might be blocked here I have it sitting

00:32:02,200 --> 00:32:06,399
at this semaphore and then it can go and

00:32:04,600 --> 00:32:07,450
start processing that type of data so

00:32:06,399 --> 00:32:09,460
I'm just kind of showing you the

00:32:07,450 --> 00:32:10,720
difference between what's going on in an

00:32:09,460 --> 00:32:13,630
interrupt service routine and then a

00:32:10,720 --> 00:32:15,669
task see how this concept of I'm stuck

00:32:13,630 --> 00:32:17,559
at this summer for waiting for somebody

00:32:15,669 --> 00:32:22,240
to tell me hey you got some data to your

00:32:17,559 --> 00:32:24,370
process so here's come to showing you

00:32:22,240 --> 00:32:26,169
what goes on with the scheduling there's

00:32:24,370 --> 00:32:28,929
nothing magic here just showing you this

00:32:26,169 --> 00:32:30,909
concept of the the idea of this priority

00:32:28,929 --> 00:32:33,399
the important thing I'm trying to show

00:32:30,909 --> 00:32:34,870
here is that processes or tasks and the

00:32:33,399 --> 00:32:37,029
same priority are scheduled in a

00:32:34,870 --> 00:32:39,640
first-in-first-out order so even though

00:32:37,029 --> 00:32:41,320
I've got two of those guys at priority

00:32:39,640 --> 00:32:43,390
one that are running even though I go

00:32:41,320 --> 00:32:44,559
off and handle in ISR and when I return

00:32:43,390 --> 00:32:46,929
from that interrupt I'm going to go back

00:32:44,559 --> 00:32:48,640
to the task I was working on because

00:32:46,929 --> 00:32:50,140
that was the one that was in the queue

00:32:48,640 --> 00:32:53,429
first all right that one at that

00:32:50,140 --> 00:32:53,429
priority level is going to finish

00:32:54,220 --> 00:33:02,780
alright so where I'm going is can we

00:32:57,590 --> 00:33:05,390
adapt this model to open MP and i just

00:33:02,780 --> 00:33:08,000
want to show this semaphore concept

00:33:05,390 --> 00:33:10,340
before I then discuss how we might adapt

00:33:08,000 --> 00:33:12,260
this to openmp we all know how some four

00:33:10,340 --> 00:33:15,380
works right I just want to show that

00:33:12,260 --> 00:33:17,270
there's this concept of time that that's

00:33:15,380 --> 00:33:19,790
in these some affords and real-time

00:33:17,270 --> 00:33:22,130
systems where I might want to say okay I

00:33:19,790 --> 00:33:24,260
want to wait for some data to show up

00:33:22,130 --> 00:33:26,030
but I don't want to be there I have a

00:33:24,260 --> 00:33:29,900
timeout I don't want to be stuck waiting

00:33:26,030 --> 00:33:32,090
forever so that's not really something

00:33:29,900 --> 00:33:35,270
that's in openmp we don't really talk we

00:33:32,090 --> 00:33:37,700
have we have I can do get w time to show

00:33:35,270 --> 00:33:39,410
me how much wall time has gone by but I

00:33:37,700 --> 00:33:41,840
don't have this idea of being able to

00:33:39,410 --> 00:33:43,490
say hey I want to wait and block for an

00:33:41,840 --> 00:33:46,850
event to occur but only for a limited

00:33:43,490 --> 00:33:48,800
amount of time all right but that is

00:33:46,850 --> 00:33:55,340
something that is important for embedded

00:33:48,800 --> 00:33:57,290
systems okay so I want to think about so

00:33:55,340 --> 00:33:59,930
at this point I want you to be where

00:33:57,290 --> 00:34:02,270
you're saying okay or what I'm trying to

00:33:59,930 --> 00:34:04,370
get you to is embedded systems have this

00:34:02,270 --> 00:34:05,630
event driven model they usually

00:34:04,370 --> 00:34:07,430
implement it on top of this real-time

00:34:05,630 --> 00:34:12,830
operating system that provides these

00:34:07,430 --> 00:34:15,530
these services and ap is that I've tried

00:34:12,830 --> 00:34:17,390
to give you a feel for but it's

00:34:15,530 --> 00:34:20,270
cumbersome to take an application and

00:34:17,390 --> 00:34:22,520
rewrite it to use an artist just like it

00:34:20,270 --> 00:34:25,030
would be cumbersome to rewrite your

00:34:22,520 --> 00:34:28,700
application to use P threads everywhere

00:34:25,030 --> 00:34:31,660
or to use any low-level API it's not

00:34:28,700 --> 00:34:33,860
very portable it's hard to try different

00:34:31,660 --> 00:34:35,720
experiments because you have to go you

00:34:33,860 --> 00:34:39,110
know mess with those different functions

00:34:35,720 --> 00:34:42,830
and so if you don't believe in higher

00:34:39,110 --> 00:34:44,540
level models then you know it's you have

00:34:42,830 --> 00:34:46,010
to ask yourself why am i into OpenMP you

00:34:44,540 --> 00:34:48,020
know that opening piece about getting

00:34:46,010 --> 00:34:50,419
away from these lower level models so

00:34:48,020 --> 00:34:53,270
can we can we provide a higher level

00:34:50,419 --> 00:34:56,920
model for this event driven system

00:34:53,270 --> 00:34:59,240
that's in embedded systems and so how I

00:34:56,920 --> 00:35:01,580
thought about it was well let's see

00:34:59,240 --> 00:35:03,270
we've got this concept of a task model

00:35:01,580 --> 00:35:06,390
and open in peak and that

00:35:03,270 --> 00:35:11,280
be adapted to these event driven systems

00:35:06,390 --> 00:35:13,380
so just quickly a quick review I'm sure

00:35:11,280 --> 00:35:17,460
this was covered in the tutorial

00:35:13,380 --> 00:35:19,410
yesterday so for those of you that were

00:35:17,460 --> 00:35:20,670
there this this be review or you can

00:35:19,410 --> 00:35:22,800
correct me about how I'm wrong also

00:35:20,670 --> 00:35:25,710
because you may better you may have had

00:35:22,800 --> 00:35:29,520
a more up-to-date review than I've had

00:35:25,710 --> 00:35:33,470
but so tasks were originally put in to

00:35:29,520 --> 00:35:36,090
open mp4 this irregular data

00:35:33,470 --> 00:35:38,910
competitions your your while loop is

00:35:36,090 --> 00:35:42,210
sort of the canonical example for white

00:35:38,910 --> 00:35:45,090
asking was put into OpenMP so you create

00:35:42,210 --> 00:35:47,940
a parallel region you then have one

00:35:45,090 --> 00:35:52,080
thread that out of your team of threads

00:35:47,940 --> 00:35:55,170
that then execute some code to create a

00:35:52,080 --> 00:35:57,870
bunch of tasks tasks are work they're

00:35:55,170 --> 00:36:01,500
not there they are work to be executed

00:35:57,870 --> 00:36:05,880
by a thread they don't threads are the

00:36:01,500 --> 00:36:08,220
workers tasks are the work so you're

00:36:05,880 --> 00:36:11,280
creating a bunch when you execute a task

00:36:08,220 --> 00:36:14,370
concept constructor you our packaging up

00:36:11,280 --> 00:36:16,140
some code and data conceptually putting

00:36:14,370 --> 00:36:19,140
it somewhere let's just say for a queue

00:36:16,140 --> 00:36:21,660
on a queue for now and then threads and

00:36:19,140 --> 00:36:23,790
your team are coming and picking off

00:36:21,660 --> 00:36:27,660
those tasks and going and executing them

00:36:23,790 --> 00:36:30,360
when all of your tasks are complete then

00:36:27,660 --> 00:36:32,160
all of the work in that parallel region

00:36:30,360 --> 00:36:35,130
is complete the parallel region can be

00:36:32,160 --> 00:36:37,140
finished so again in the basic example

00:36:35,130 --> 00:36:38,580
you have one thread that goes through

00:36:37,140 --> 00:36:41,070
the while loop crates up all that

00:36:38,580 --> 00:36:42,870
generates all the tasks the other

00:36:41,070 --> 00:36:45,120
threads and your team begin executing

00:36:42,870 --> 00:36:46,830
the tasks when that thread is done

00:36:45,120 --> 00:36:49,200
generating tasks it can then go

00:36:46,830 --> 00:36:54,150
participate in the execution of the

00:36:49,200 --> 00:37:00,090
tasks alright so again tox tasks or work

00:36:54,150 --> 00:37:02,520
threads are the workers so I was

00:37:00,090 --> 00:37:05,160
thinking like well is there some way

00:37:02,520 --> 00:37:07,770
that we could think about that in terms

00:37:05,160 --> 00:37:10,050
of this event driven model so can we

00:37:07,770 --> 00:37:12,690
take this tasking model can we adapt it

00:37:10,050 --> 00:37:15,660
to of gets this event driven model so I

00:37:12,690 --> 00:37:16,510
started playing around with it so all of

00:37:15,660 --> 00:37:18,280
this is

00:37:16,510 --> 00:37:21,010
I don't have an implementation of this

00:37:18,280 --> 00:37:23,260
this is to some degree a thought

00:37:21,010 --> 00:37:24,940
experiment a conjecture playing around

00:37:23,260 --> 00:37:27,220
playing with an idea putting this out

00:37:24,940 --> 00:37:30,070
there so I'm sure there's some details

00:37:27,220 --> 00:37:32,410
that would need to be worked through but

00:37:30,070 --> 00:37:34,630
generally you can see this where I'm

00:37:32,410 --> 00:37:37,600
coming from here this we created this

00:37:34,630 --> 00:37:39,640
concept of tasks can and event-driven

00:37:37,600 --> 00:37:42,280
system is about having these tasks

00:37:39,640 --> 00:37:45,010
running in parallel can we deserve a fit

00:37:42,280 --> 00:37:47,140
here so what I did was all right I'll

00:37:45,010 --> 00:37:49,270
have a new kind of task with a clause

00:37:47,140 --> 00:37:51,990
called in is are those are going to be

00:37:49,270 --> 00:37:54,490
tasks that are somehow marked as

00:37:51,990 --> 00:37:56,680
interrupt service routine tasks and

00:37:54,490 --> 00:37:58,720
maybe the number that I give you is

00:37:56,680 --> 00:38:00,610
which particular interrupt this task is

00:37:58,720 --> 00:38:03,720
tied to I know there could be some

00:38:00,610 --> 00:38:08,410
issues there with portability but and

00:38:03,720 --> 00:38:10,660
then if I want to have these other tasks

00:38:08,410 --> 00:38:13,120
in the background processing information

00:38:10,660 --> 00:38:18,550
I'll just fire them up so I have a

00:38:13,120 --> 00:38:20,380
pragma on Pete asked to create a task

00:38:18,550 --> 00:38:22,720
that I call process buffer it's just a

00:38:20,380 --> 00:38:23,950
general purpose okay take some input

00:38:22,720 --> 00:38:26,860
that you put in a buffer and go ahead

00:38:23,950 --> 00:38:30,550
and process it and then I'll fire up an

00:38:26,860 --> 00:38:33,520
idle task which is running at I'm doing

00:38:30,550 --> 00:38:37,720
my priorities where a 2 is actually one

00:38:33,520 --> 00:38:40,030
is they in this particular example one

00:38:37,720 --> 00:38:41,800
is a higher priority 2 is a lower

00:38:40,030 --> 00:38:42,850
priority I think I have a type over

00:38:41,800 --> 00:38:46,420
there because I think I do a different

00:38:42,850 --> 00:38:47,830
in a theater example and then i wasn't

00:38:46,420 --> 00:38:49,840
sure if i needed a task wait there

00:38:47,830 --> 00:38:51,130
because it well if the program ended i'm

00:38:49,840 --> 00:38:52,750
not sure if there's a barrier at the end

00:38:51,130 --> 00:38:55,120
of the program to make sure all my tasks

00:38:52,750 --> 00:38:56,440
finish before my program finishes so I

00:38:55,120 --> 00:38:59,440
mean I put a task wait there to make

00:38:56,440 --> 00:39:01,360
sure they would finish and then I tried

00:38:59,440 --> 00:39:04,060
to show you you know like what would be

00:39:01,360 --> 00:39:08,500
in the interrupt service routine task so

00:39:04,060 --> 00:39:09,940
basically there's a some some hardware

00:39:08,500 --> 00:39:12,580
events going to happen as signals going

00:39:09,940 --> 00:39:14,500
to go off hardware our hardware

00:39:12,580 --> 00:39:16,990
interrupt number one and this task will

00:39:14,500 --> 00:39:20,350
be invoked and what that interrupt old

00:39:16,990 --> 00:39:22,660
you is that there's a new character or

00:39:20,350 --> 00:39:24,520
float or integer that's shown up in a

00:39:22,660 --> 00:39:26,920
memory map location that's pointed to

00:39:24,520 --> 00:39:29,380
you by this X buff location register

00:39:26,920 --> 00:39:32,590
alright so I go read it

00:39:29,380 --> 00:39:33,760
and I keep filling up the buffer that

00:39:32,590 --> 00:39:35,500
way and when the buffer reaches a

00:39:33,760 --> 00:39:38,880
certain block size then I'm going to

00:39:35,500 --> 00:39:42,060
post the semaphore that will then

00:39:38,880 --> 00:39:45,070
indicate to the process buffer thread

00:39:42,060 --> 00:39:48,850
process buffer task pardon me that I

00:39:45,070 --> 00:39:50,440
thread can go execute that task because

00:39:48,850 --> 00:39:53,710
it has been sitting here in an infinite

00:39:50,440 --> 00:39:56,260
loop waiting for that semaphore to be

00:39:53,710 --> 00:39:59,500
posted it now knows that it has a full

00:39:56,260 --> 00:40:01,240
buffer it can go and then run a filter

00:39:59,500 --> 00:40:03,820
or whatever on that buffer all right so

00:40:01,240 --> 00:40:07,150
just a very simple example of how you

00:40:03,820 --> 00:40:10,660
can adapt at asking model to the

00:40:07,150 --> 00:40:12,340
event-driven how you can you could

00:40:10,660 --> 00:40:14,440
create an event-driven task model

00:40:12,340 --> 00:40:16,540
alright then I thought well that's

00:40:14,440 --> 00:40:19,410
really not the opening openmp way to do

00:40:16,540 --> 00:40:23,980
it maybe what we should really do is

00:40:19,410 --> 00:40:25,690
when you when you fill up the buffer

00:40:23,980 --> 00:40:27,730
when the interrupt service routine

00:40:25,690 --> 00:40:31,210
realized okay I finally collected block

00:40:27,730 --> 00:40:33,730
size enough work to go off and and

00:40:31,210 --> 00:40:35,710
invoke the filter routine I'll just

00:40:33,730 --> 00:40:38,950
invoke the task directly from there and

00:40:35,710 --> 00:40:41,140
put the the task construct directly on

00:40:38,950 --> 00:40:43,810
the call there i won't i won't create

00:40:41,140 --> 00:40:46,600
this persistent task that's running all

00:40:43,810 --> 00:40:49,480
the time I'll just invoke it when I I

00:40:46,600 --> 00:40:51,160
need it to be invoked and then here I

00:40:49,480 --> 00:40:52,570
just made my example a little more

00:40:51,160 --> 00:40:54,310
interesting and said okay I could then

00:40:52,570 --> 00:40:57,220
once inside this task I could use

00:40:54,310 --> 00:41:05,790
regular OpenMP to do some compute

00:40:57,220 --> 00:41:09,310
intensive work so in summary this is my

00:41:05,790 --> 00:41:10,630
idea like I said I haven't done an

00:41:09,310 --> 00:41:11,800
implementation I haven't really even

00:41:10,630 --> 00:41:13,900
thought through all the necessary

00:41:11,800 --> 00:41:16,900
details that go into this there's a lot

00:41:13,900 --> 00:41:19,300
of dark corners of tasking that you have

00:41:16,900 --> 00:41:21,700
to look out for that could maybe shoot

00:41:19,300 --> 00:41:24,070
this on the foot but I see something

00:41:21,700 --> 00:41:25,600
here because we want to improve the

00:41:24,070 --> 00:41:27,370
productivity of embedded programmers

00:41:25,600 --> 00:41:29,380
with these higher level models these

00:41:27,370 --> 00:41:32,100
embedded systems not are often are

00:41:29,380 --> 00:41:35,230
practically always somehow event-driven

00:41:32,100 --> 00:41:37,930
can we extend the open in petoskey model

00:41:35,230 --> 00:41:39,730
to implement this week I think we could

00:41:37,930 --> 00:41:41,680
there could be some issues we might need

00:41:39,730 --> 00:41:44,470
to come up with some new concepts

00:41:41,680 --> 00:41:47,710
ken Ken Ken can these is ours be these

00:41:44,470 --> 00:41:49,990
special types of tasks is the new task

00:41:47,710 --> 00:41:53,140
priority Clause that's coming in for dot

00:41:49,990 --> 00:41:54,880
one sufficient to implement these types

00:41:53,140 --> 00:41:59,830
of scheduling algorithms that might be

00:41:54,880 --> 00:42:02,470
required and if so would we may be neat

00:41:59,830 --> 00:42:04,930
if not would we maybe need to add some

00:42:02,470 --> 00:42:07,690
new type of task scheduling algorithms

00:42:04,930 --> 00:42:10,750
much like we have a schedule clause on

00:42:07,690 --> 00:42:13,390
the loop claw on the on the parallel

00:42:10,750 --> 00:42:16,870
loop construct you can imagine okay use

00:42:13,390 --> 00:42:20,620
this type of scheduling algorithms for

00:42:16,870 --> 00:42:21,910
tasks and then our persistent tasks that

00:42:20,620 --> 00:42:24,100
communicate using point-to-point

00:42:21,910 --> 00:42:27,340
communication that's what my first

00:42:24,100 --> 00:42:29,590
example was more efficient than

00:42:27,340 --> 00:42:31,870
launching new tasks each time an event

00:42:29,590 --> 00:42:33,880
occurs so I often hear this when people

00:42:31,870 --> 00:42:36,040
talk about tasking and openmp oh it's so

00:42:33,880 --> 00:42:38,170
cumbersome there's just overhead for

00:42:36,040 --> 00:42:40,060
using it and everything so maybe you

00:42:38,170 --> 00:42:43,450
could overcome some of that if you had a

00:42:40,060 --> 00:42:45,010
way of making tasks persistent and I

00:42:43,450 --> 00:42:47,170
think that if you wanted to make them

00:42:45,010 --> 00:42:48,700
work for this event driven model in an

00:42:47,170 --> 00:42:52,650
embedded system you need some sort of

00:42:48,700 --> 00:42:58,840
persistent type of task all right

00:42:52,650 --> 00:43:00,880
everyone's still with me here ok I'm

00:42:58,840 --> 00:43:02,560
going to transition now that's my ideas

00:43:00,880 --> 00:43:07,240
I'm trying to get open into you p

00:43:02,560 --> 00:43:08,590
working on an event-driven system i'm

00:43:07,240 --> 00:43:12,490
going to wrap up here we're just talking

00:43:08,590 --> 00:43:17,890
about this multiprocessor system on chip

00:43:12,490 --> 00:43:21,640
model so at TI again i'll go back to how

00:43:17,890 --> 00:43:24,040
we got involved in this is now we were

00:43:21,640 --> 00:43:27,430
taking processors we took this processor

00:43:24,040 --> 00:43:30,250
and we put 8ds peas on it and now we

00:43:27,430 --> 00:43:31,960
started integrating more cores on to

00:43:30,250 --> 00:43:34,270
that chip now we started pulling the

00:43:31,960 --> 00:43:35,920
host processors that were attached to

00:43:34,270 --> 00:43:37,600
that DSP onto the chip itself when we

00:43:35,920 --> 00:43:41,050
put arms on there so now we ended up

00:43:37,600 --> 00:43:45,640
with this heterogeneous processor where

00:43:41,050 --> 00:43:48,910
we had four arm a 15s and ate these DSPs

00:43:45,640 --> 00:43:51,370
on one chip that's how we became also

00:43:48,910 --> 00:43:52,530
very interested and involved in the work

00:43:51,370 --> 00:43:54,780
going on in

00:43:52,530 --> 00:43:56,460
openmp accelerator model because we

00:43:54,780 --> 00:44:00,750
wanted to take that model and use it to

00:43:56,460 --> 00:44:08,130
offload work from the arm processors on

00:44:00,750 --> 00:44:11,220
to the DSPs so if you're not familiar

00:44:08,130 --> 00:44:14,570
with the accelerator model it's

00:44:11,220 --> 00:44:17,700
basically based on a the target

00:44:14,570 --> 00:44:20,100
construct that indicates that the

00:44:17,700 --> 00:44:23,190
subsequent region of code is to be

00:44:20,100 --> 00:44:26,400
executed on a given device you have

00:44:23,190 --> 00:44:30,300
clauses to help you describe how the

00:44:26,400 --> 00:44:32,670
data is to be mapped or made synchronous

00:44:30,300 --> 00:44:34,920
between the host device and the

00:44:32,670 --> 00:44:37,320
accelerator devices or in our cases the

00:44:34,920 --> 00:44:40,050
DSPs and then again within that region

00:44:37,320 --> 00:44:42,720
you can have regular OpenMP so this for

00:44:40,050 --> 00:44:44,400
example takes some code map sit over

00:44:42,720 --> 00:44:49,920
there and then goes parallel once it's

00:44:44,400 --> 00:44:53,070
there so in the concept of mapping data

00:44:49,920 --> 00:44:55,500
from host memory to device memory we

00:44:53,070 --> 00:44:57,930
talked about allocating space for the

00:44:55,500 --> 00:44:59,610
variables that you're going to map a two

00:44:57,930 --> 00:45:04,410
means you're going to map a variable

00:44:59,610 --> 00:45:08,820
from the host to the device etc map does

00:45:04,410 --> 00:45:11,910
not necessarily mean copy okay map means

00:45:08,820 --> 00:45:13,590
make this variable available to this

00:45:11,910 --> 00:45:15,990
device it could be that you're executing

00:45:13,590 --> 00:45:18,870
in a system where the memory is shared

00:45:15,990 --> 00:45:21,360
between the host device and the house

00:45:18,870 --> 00:45:24,120
and the the accelerator device or the

00:45:21,360 --> 00:45:27,720
the other device okay so map does not

00:45:24,120 --> 00:45:30,110
necessarily mean copy and for us it it

00:45:27,720 --> 00:45:33,420
meant so now I'm just giving you some of

00:45:30,110 --> 00:45:35,330
the things we ran into when trying to

00:45:33,420 --> 00:45:39,180
implement OpenMP on this type of system

00:45:35,330 --> 00:45:42,270
was that sometimes map meant copy

00:45:39,180 --> 00:45:47,250
because the variable we were mapping was

00:45:42,270 --> 00:45:49,110
coming from a virtual memory region and

00:45:47,250 --> 00:45:51,750
that meant that the underlying physical

00:45:49,110 --> 00:45:54,930
memory was not contiguous and for better

00:45:51,750 --> 00:45:57,060
or for worse the accelerator on our ship

00:45:54,930 --> 00:45:59,880
looked at physical memory and so it

00:45:57,060 --> 00:46:02,080
required things to be contiguous so in

00:45:59,880 --> 00:46:04,060
the cases where the

00:46:02,080 --> 00:46:06,610
memory is coming from a virtual memory

00:46:04,060 --> 00:46:10,810
address we would make a copy of it but

00:46:06,610 --> 00:46:13,120
we also added some api's some special

00:46:10,810 --> 00:46:15,970
cons of Malik's where you could allocate

00:46:13,120 --> 00:46:18,640
memory out of a physical region and so

00:46:15,970 --> 00:46:20,350
in those cases they physically the

00:46:18,640 --> 00:46:22,270
memory allocated from physical

00:46:20,350 --> 00:46:24,190
contiguous memory didn't have to be

00:46:22,270 --> 00:46:27,040
copied so our runtime would detect this

00:46:24,190 --> 00:46:28,900
and in sometimes when mapping your

00:46:27,040 --> 00:46:33,850
variable would make a copy sometimes it

00:46:28,900 --> 00:46:35,560
would all right this is just giving you

00:46:33,850 --> 00:46:37,000
an idea of how that I'm just showing you

00:46:35,560 --> 00:46:39,190
with the code example and how that works

00:46:37,000 --> 00:46:41,320
so we that we added a special type of

00:46:39,190 --> 00:46:45,070
malik to say this is this is the kind of

00:46:41,320 --> 00:46:48,940
malik that you're using to to allocate

00:46:45,070 --> 00:46:51,040
from a contiguous location and then

00:46:48,940 --> 00:46:54,280
we're initializing it on the host device

00:46:51,040 --> 00:46:56,500
and then when we offload it the DSPs are

00:46:54,280 --> 00:46:57,520
able to use it and there's no copy going

00:46:56,500 --> 00:47:00,370
on in here it's just an address

00:46:57,520 --> 00:47:04,300
translation and then we free it at the

00:47:00,370 --> 00:47:08,770
end the other thing we added was a local

00:47:04,300 --> 00:47:11,110
type which meant that it's similar to

00:47:08,770 --> 00:47:13,960
private but it's not an its look and

00:47:11,110 --> 00:47:15,910
initialize variable we're just saying

00:47:13,960 --> 00:47:17,740
here's some local store we want this to

00:47:15,910 --> 00:47:20,890
be allocated locally in the scratchpad

00:47:17,740 --> 00:47:25,810
memory of each device alright it's kind

00:47:20,890 --> 00:47:28,240
of similar to the opencl local type

00:47:25,810 --> 00:47:32,800
modifier all right we expose that type

00:47:28,240 --> 00:47:34,600
of concept in B and added that to the

00:47:32,800 --> 00:47:36,430
map clause because we want to be able to

00:47:34,600 --> 00:47:40,210
take advantage of the scratchpad memory

00:47:36,430 --> 00:47:41,440
that's on the accelerators so just

00:47:40,210 --> 00:47:44,530
giving you a feel for some of the things

00:47:41,440 --> 00:47:49,120
that we had to do to adapt this to to

00:47:44,530 --> 00:47:53,140
our type of system alright so now I'm

00:47:49,120 --> 00:47:55,470
going to finish with just a area that

00:47:53,140 --> 00:47:59,700
we're spending a lot of effort on the TI

00:47:55,470 --> 00:48:03,100
it's a cool embedded application area

00:47:59,700 --> 00:48:05,500
this autonomous vehicles and advanced

00:48:03,100 --> 00:48:07,750
driver assistance systems where you have

00:48:05,500 --> 00:48:10,750
these sensors which are cameras radars

00:48:07,750 --> 00:48:12,710
light sensors ultrasonic thermo I are

00:48:10,750 --> 00:48:17,599
all these sensors are

00:48:12,710 --> 00:48:19,820
your car are giving you these these this

00:48:17,599 --> 00:48:21,380
data of the environment around you and

00:48:19,820 --> 00:48:22,849
people are developing these different

00:48:21,380 --> 00:48:25,700
types of perception processing

00:48:22,849 --> 00:48:27,980
algorithms for doing Lane detection stop

00:48:25,700 --> 00:48:30,320
sign recognition they're doing things

00:48:27,980 --> 00:48:31,940
where they stitch all the images and

00:48:30,320 --> 00:48:33,740
their cameras together and then give you

00:48:31,940 --> 00:48:36,710
a view of what your car looks like from

00:48:33,740 --> 00:48:39,140
the top okay lots of interesting things

00:48:36,710 --> 00:48:42,380
going on with this particular area and

00:48:39,140 --> 00:48:44,150
so tis come up with a processor for this

00:48:42,380 --> 00:48:46,430
area that get set what I was trying to

00:48:44,150 --> 00:48:50,510
talk about earlier about really

00:48:46,430 --> 00:48:52,880
heterogeneous processing I've got RMA 15

00:48:50,510 --> 00:48:55,369
s which is your general purpose I can

00:48:52,880 --> 00:48:57,800
run linux on it I've got an RMA for

00:48:55,369 --> 00:49:01,010
which is a more 16-bit microcontroller

00:48:57,800 --> 00:49:02,690
type processor I've got the same two DS

00:49:01,010 --> 00:49:04,910
piece that I showed you earlier which I

00:49:02,690 --> 00:49:07,010
had eight I've got this thing called e

00:49:04,910 --> 00:49:10,940
which our vision accelerators there's a

00:49:07,010 --> 00:49:13,000
GPU on there in this graphics engine so

00:49:10,940 --> 00:49:15,500
all these different heterogeneous

00:49:13,000 --> 00:49:18,470
processing elements I want to be able to

00:49:15,500 --> 00:49:21,170
use OpenMP to program this I want to

00:49:18,470 --> 00:49:22,940
adapt the openmp accelerator model and

00:49:21,170 --> 00:49:25,220
make it a heterogeneous programming

00:49:22,940 --> 00:49:27,950
model where I can think of my program as

00:49:25,220 --> 00:49:29,869
one entity that I'm working with and

00:49:27,950 --> 00:49:32,240
mapping different parts of it to these

00:49:29,869 --> 00:49:33,710
different processing elements they don't

00:49:32,240 --> 00:49:35,780
program these systems like that today

00:49:33,710 --> 00:49:37,670
each one gets programmed in its own

00:49:35,780 --> 00:49:41,570
little world and then they stitch them

00:49:37,670 --> 00:49:43,160
together and there's lots of performance

00:49:41,570 --> 00:49:44,330
that's left on the table because once

00:49:43,160 --> 00:49:45,609
you stick it all together and get it

00:49:44,330 --> 00:49:48,500
working you don't want to mess with it

00:49:45,609 --> 00:49:50,660
you know you know you you don't so it's

00:49:48,500 --> 00:49:52,400
hard to experiment it's hard to get the

00:49:50,660 --> 00:49:55,700
complete performance entitlement out of

00:49:52,400 --> 00:50:00,140
your system so if we could have this

00:49:55,700 --> 00:50:03,650
more holistic programming environment

00:50:00,140 --> 00:50:06,650
for these types of systems I think it

00:50:03,650 --> 00:50:09,140
would be a very good thing alright so

00:50:06,650 --> 00:50:11,359
this chip again is targeted at this is

00:50:09,140 --> 00:50:12,890
just giving you a more i sold this from

00:50:11,359 --> 00:50:14,839
a marketing guy but it was you know kind

00:50:12,890 --> 00:50:17,089
of cool showing you what you can do with

00:50:14,839 --> 00:50:18,500
some of these sensors the thing i think

00:50:17,089 --> 00:50:20,510
it's kind of interesting is they want to

00:50:18,500 --> 00:50:22,190
start getting rid of you know the

00:50:20,510 --> 00:50:25,609
mirrors on the side of your car are

00:50:22,190 --> 00:50:27,529
actually not good for

00:50:25,609 --> 00:50:29,690
you know gas mileage they're one of the

00:50:27,529 --> 00:50:31,519
bigger drags that you have but can we

00:50:29,690 --> 00:50:34,099
just rip those off and use the cameras

00:50:31,519 --> 00:50:37,130
and create create those mirrors for you

00:50:34,099 --> 00:50:41,180
digitally so the elimination of mirrors

00:50:37,130 --> 00:50:42,380
you know I'm sure you've heard of all

00:50:41,180 --> 00:50:45,730
the wonderful things that are going to

00:50:42,380 --> 00:50:47,630
be coming with automatic you know

00:50:45,730 --> 00:50:49,910
self-driving cars and things like that

00:50:47,630 --> 00:50:53,569
that's not quite going that far yet but

00:50:49,910 --> 00:50:55,339
it's getting there and so what I'm

00:50:53,569 --> 00:51:01,009
trying to show here is that what what

00:50:55,339 --> 00:51:03,170
what embedded developers in this case

00:51:01,009 --> 00:51:05,569
automobile manufacturers want is they

00:51:03,170 --> 00:51:09,319
want just sort of they want one platform

00:51:05,569 --> 00:51:10,759
that they can have one code base for

00:51:09,319 --> 00:51:13,069
that they use for their lower end

00:51:10,759 --> 00:51:15,650
systems and then they can just scale

00:51:13,069 --> 00:51:18,049
that for their hiring system so if we

00:51:15,650 --> 00:51:20,089
have this general purpose multiprocessor

00:51:18,049 --> 00:51:21,859
system bunch of programming model I want

00:51:20,089 --> 00:51:23,779
to be able to use that model to be able

00:51:21,859 --> 00:51:25,970
to you know turn things off or maybe I

00:51:23,779 --> 00:51:28,039
don't have that accelerator in the low

00:51:25,970 --> 00:51:30,739
end so I'll run that process on this

00:51:28,039 --> 00:51:33,200
this other processor you won't be able

00:51:30,739 --> 00:51:35,480
to get as good quality but you can still

00:51:33,200 --> 00:51:37,489
have something so I want the programming

00:51:35,480 --> 00:51:41,210
model to be able to scale across these

00:51:37,489 --> 00:51:47,019
different types of platforms so here's

00:51:41,210 --> 00:51:49,700
what I'm proposing can open and PB use

00:51:47,019 --> 00:51:51,259
ups are we can see how OpenMP can be

00:51:49,700 --> 00:51:52,819
used to exploit parallelism in the

00:51:51,259 --> 00:51:57,140
compute intensive parts of your

00:51:52,819 --> 00:51:59,749
algorithm and we can see how open if

00:51:57,140 --> 00:52:03,739
he's been used to offload code to from a

00:51:59,749 --> 00:52:06,519
host processor to an accelerator but can

00:52:03,739 --> 00:52:08,509
we use it as this for an event-driven

00:52:06,519 --> 00:52:11,119
multiprocessor system on chip this

00:52:08,509 --> 00:52:13,220
heterogeneous model where a device can

00:52:11,119 --> 00:52:14,930
launch code on any other device so I

00:52:13,220 --> 00:52:16,819
just came up with this example here I

00:52:14,930 --> 00:52:19,190
have my arm and force they're really

00:52:16,819 --> 00:52:22,430
specialized for reacting very quickly to

00:52:19,190 --> 00:52:23,660
real-time events there they're sitting

00:52:22,430 --> 00:52:25,190
there watching the real-time events

00:52:23,660 --> 00:52:26,960
they're running those interrupt service

00:52:25,190 --> 00:52:28,819
routine when these things happen they're

00:52:26,960 --> 00:52:31,249
dispatching processes to other cores in

00:52:28,819 --> 00:52:34,099
the system maybe to the other DSPs maybe

00:52:31,249 --> 00:52:35,420
to something to be armed a 15 the DSP

00:52:34,099 --> 00:52:37,069
might be running its own thing in the

00:52:35,420 --> 00:52:39,320
background it's going to collect

00:52:37,069 --> 00:52:41,090
specific events it's looking for

00:52:39,320 --> 00:52:43,280
and it's going to just process them

00:52:41,090 --> 00:52:45,170
locally the arm it's going to be running

00:52:43,280 --> 00:52:47,870
S&P linux and managing the user

00:52:45,170 --> 00:52:49,940
interface may be dispatching processes

00:52:47,870 --> 00:52:52,790
to the GPU to do some sort of graphics

00:52:49,940 --> 00:52:55,790
on the cool screens that that are coming

00:52:52,790 --> 00:52:58,070
in these cars all right so I want this

00:52:55,790 --> 00:53:00,350
combination of this event driven model

00:52:58,070 --> 00:53:02,750
and this this MPs OCD or this

00:53:00,350 --> 00:53:04,280
heterogeneous model so i tried to say

00:53:02,750 --> 00:53:06,200
like I tried to take what i showed

00:53:04,280 --> 00:53:08,810
earlier and sort of now adapted so I

00:53:06,200 --> 00:53:11,390
have a task that I launched over on the

00:53:08,810 --> 00:53:15,170
m4 that's the arm that specialized for

00:53:11,390 --> 00:53:17,870
doing real reacting very quickly to

00:53:15,170 --> 00:53:20,030
real-time events I've got another one

00:53:17,870 --> 00:53:23,090
that I put on the DSP I've got some

00:53:20,030 --> 00:53:25,040
other tasks one I call process driver

00:53:23,090 --> 00:53:26,990
fitness that's like some sensor that's

00:53:25,040 --> 00:53:28,640
watching the driver to see whether he's

00:53:26,990 --> 00:53:31,760
falling asleep or not some other

00:53:28,640 --> 00:53:33,440
sentence some other sensors are looking

00:53:31,760 --> 00:53:35,900
outside the car so I'm going to have a

00:53:33,440 --> 00:53:37,310
process vision frame sensor maybe both

00:53:35,900 --> 00:53:38,630
of those are running on the DSP at the

00:53:37,310 --> 00:53:41,810
same time but I haven't different

00:53:38,630 --> 00:53:43,430
priorities the process vision frame yet

00:53:41,810 --> 00:53:47,360
here I switched my priorities on you I

00:53:43,430 --> 00:53:49,370
apologize is a higher priority ok so

00:53:47,360 --> 00:53:54,410
here I show you maybe how this can work

00:53:49,370 --> 00:53:56,090
so the arm might before it posts and I'm

00:53:54,410 --> 00:53:58,280
just highlighting a problem here how do

00:53:56,090 --> 00:54:02,900
you manage the memory consistency

00:53:58,280 --> 00:54:04,160
between the the RM four and the DSP

00:54:02,900 --> 00:54:06,230
that's supposed to be reacting to this

00:54:04,160 --> 00:54:08,450
event is it do we need to explicitly

00:54:06,230 --> 00:54:11,750
update the memory using this update

00:54:08,450 --> 00:54:13,970
construct or does the semaphore do it

00:54:11,750 --> 00:54:15,290
for you automatically but this is where

00:54:13,970 --> 00:54:17,450
i'd like to get to i'd like to be able

00:54:15,290 --> 00:54:19,910
to go in annotate my code with these

00:54:17,450 --> 00:54:22,370
directives and you can see the power of

00:54:19,910 --> 00:54:24,590
how I could you know try different

00:54:22,370 --> 00:54:29,030
things put different pieces in different

00:54:24,590 --> 00:54:31,670
places and just be recompiling all right

00:54:29,030 --> 00:54:34,610
so this is my conclusions there's other

00:54:31,670 --> 00:54:36,590
topics there's power and energy

00:54:34,610 --> 00:54:38,060
consumption I believe there's a paper I

00:54:36,590 --> 00:54:40,250
didn't have time to type in the title

00:54:38,060 --> 00:54:41,300
that said I womp we should go look at

00:54:40,250 --> 00:54:43,430
that one and see what those guys are

00:54:41,300 --> 00:54:45,710
proposing there's all of the things with

00:54:43,430 --> 00:54:47,690
memory that I didn't get into there's

00:54:45,710 --> 00:54:49,670
the hierarchical memory systems that are

00:54:47,690 --> 00:54:50,810
in these MPs Oh Sees it's very similar

00:54:49,670 --> 00:54:51,079
to what people are dealing with known

00:54:50,810 --> 00:54:53,569
age

00:54:51,079 --> 00:54:55,880
bc how do I get things into my fast

00:54:53,569 --> 00:54:57,890
memory so I want some sort of double

00:54:55,880 --> 00:54:59,809
buffering or data streaming we didn't

00:54:57,890 --> 00:55:01,279
really talk about resiliency but like I

00:54:59,809 --> 00:55:03,140
said earlier these things have to run

00:55:01,279 --> 00:55:05,180
forever so we need something in the

00:55:03,140 --> 00:55:07,069
language cancellation construct is a

00:55:05,180 --> 00:55:09,289
good enough where something's going

00:55:07,069 --> 00:55:11,509
wrong I need to abort and restart or

00:55:09,289 --> 00:55:14,289
something and then finally

00:55:11,509 --> 00:55:16,609
specialization OpenMP is getting bigger

00:55:14,289 --> 00:55:18,650
and the embedded role I like this idea

00:55:16,609 --> 00:55:20,959
of being able to like just recompile

00:55:18,650 --> 00:55:22,459
everything only keep what i need and

00:55:20,959 --> 00:55:25,670
specialized for just the things i'm

00:55:22,459 --> 00:55:27,170
using so i might say okay here openmp

00:55:25,670 --> 00:55:29,239
compiler and runtime you know you've got

00:55:27,170 --> 00:55:34,579
this many threads specialized yourself

00:55:29,239 --> 00:55:35,869
for that all right sound collision open

00:55:34,579 --> 00:55:39,440
appease the industry standard for

00:55:35,869 --> 00:55:40,999
director based programming openmp can

00:55:39,440 --> 00:55:42,709
express the parallelism that's in these

00:55:40,999 --> 00:55:44,239
compute intensive parts of an embedded

00:55:42,709 --> 00:55:47,599
program we're doing that today with

00:55:44,239 --> 00:55:50,209
products from TI but very often embedded

00:55:47,599 --> 00:55:51,499
systems are event-driven and programmers

00:55:50,209 --> 00:55:55,309
have to write custom code to deal with

00:55:51,499 --> 00:55:57,650
this I want to extend OpenMP somehow the

00:55:55,309 --> 00:55:59,479
tasking model to support this event

00:55:57,650 --> 00:56:01,489
driven model maybe it needs to be some

00:55:59,479 --> 00:56:04,940
new concert a process model or something

00:56:01,489 --> 00:56:06,920
but you see where I'm coming from openmp

00:56:04,940 --> 00:56:08,719
Florida we added this accelerator house

00:56:06,920 --> 00:56:11,809
plus device model can we generalize that

00:56:08,719 --> 00:56:13,999
to be a heterogeneous multiprocessor

00:56:11,809 --> 00:56:16,729
system on chip model so that we could

00:56:13,999 --> 00:56:19,009
have what my vision here is that I want

00:56:16,729 --> 00:56:21,859
embedded programmers using OpenMP to

00:56:19,009 --> 00:56:25,989
implement these event driven systems for

00:56:21,859 --> 00:56:29,259
complex multiprocessor system on chips

00:56:25,989 --> 00:56:29,259
I'm done

00:56:35,550 --> 00:56:43,270
everyone if you have a question ok if

00:56:38,320 --> 00:56:44,710
you can tell me why I'm wrong no no

00:56:43,270 --> 00:57:02,410
that's fine it's good go ahead what's

00:56:44,710 --> 00:57:07,090
your question I think that openmp needs

00:57:02,410 --> 00:57:08,320
to expand into other places I guess

00:57:07,090 --> 00:57:09,700
because I'm coming from some of those

00:57:08,320 --> 00:57:12,670
other places so i guess i'm advocating

00:57:09,700 --> 00:57:15,870
that yes you should add these things no

00:57:12,670 --> 00:57:18,280
it shouldn't try and do everything but

00:57:15,870 --> 00:57:19,450
but i would say that there may be have

00:57:18,280 --> 00:57:22,120
been some things that have added to

00:57:19,450 --> 00:57:23,800
openmp that I would maybe think released

00:57:22,120 --> 00:57:25,990
from my perspective aren't as important

00:57:23,800 --> 00:57:31,150
as some of the things I'm proposing well

00:57:25,990 --> 00:57:34,230
I really do think I agree with you

00:57:31,150 --> 00:57:38,100
had a message passing call over the FBI

00:57:34,230 --> 00:57:38,100
we should add message passing

00:57:38,140 --> 00:57:51,890
okay I know you are I mean um like I

00:57:49,040 --> 00:57:55,580
said earlier this is obviously ideas I

00:57:51,890 --> 00:58:00,130
mean I see people at TI looking at

00:57:55,580 --> 00:58:03,410
opencl and openmp and trying to find

00:58:00,130 --> 00:58:04,820
general purpose portable models that

00:58:03,410 --> 00:58:06,470
were work for that chip I just showed

00:58:04,820 --> 00:58:08,060
you that mall and they're looking more

00:58:06,470 --> 00:58:09,380
at opencl I don't know why because

00:58:08,060 --> 00:58:10,790
there's a graphics processor on there

00:58:09,380 --> 00:58:12,080
because it doesn't do this event during

00:58:10,790 --> 00:58:14,560
stuff either so what are they supposed

00:58:12,080 --> 00:58:14,560
to do

00:58:27,880 --> 00:58:40,539
yes I sense a comment not a question

00:58:50,589 --> 00:58:57,239
and when you don't have this so called

00:58:54,339 --> 00:58:57,239
kursi current

00:59:00,390 --> 00:59:06,390
microsoft one since once a lot of motion

00:59:03,550 --> 00:59:06,390
Chris and click

00:59:10,550 --> 00:59:14,360
and then they wonder how to develop

00:59:12,290 --> 00:59:17,740
their own concurrency system of features

00:59:14,360 --> 00:59:17,740
the confusing

00:59:17,930 --> 00:59:23,099
I've actually very interested in seeing

00:59:20,849 --> 00:59:27,890
you so there was a lot couple years ago

00:59:23,099 --> 00:59:27,890
I want what they wanted to do

00:59:30,130 --> 00:59:34,309
if it's the thing I've talked about with

00:59:32,119 --> 00:59:36,589
gooey sit was it was more about the

00:59:34,309 --> 00:59:38,900
parallel region and what they would do

00:59:36,589 --> 00:59:41,690
is when they hit an event they sort of

00:59:38,900 --> 00:59:43,400
forked a new thread that would would go

00:59:41,690 --> 00:59:45,670
back to be a new master thread and the

00:59:43,400 --> 00:59:50,269
parallel region would go attack that

00:59:45,670 --> 00:59:52,759
given event yeah I keep looking at

00:59:50,269 --> 00:59:55,999
asking and thinking that you know this

00:59:52,759 --> 00:59:56,930
seems to conceptually fit but you need

00:59:55,999 --> 00:59:59,089
things to be a little bit more

00:59:56,930 --> 01:00:03,069
persistent in some of these tasks than

00:59:59,089 --> 01:00:03,069
the way they are right now rude

01:00:12,800 --> 01:00:14,890
you

01:00:17,380 --> 01:00:22,690
well actually that's one of the things

01:00:20,380 --> 01:00:24,460
in that last processor i showed you buy

01:00:22,690 --> 01:00:26,710
us putting those we're actually

01:00:24,460 --> 01:00:30,430
dedicating processors to the real time

01:00:26,710 --> 01:00:32,530
aspect of it those are members have

01:00:30,430 --> 01:00:35,200
really fast response times so they're

01:00:32,530 --> 01:00:36,880
sort of dealing with that you know oh

01:00:35,200 --> 01:00:39,760
you need to collect this event and do

01:00:36,880 --> 01:00:41,350
something with it so i guess in a way

01:00:39,760 --> 01:00:43,390
yeah we're spinning hardware for it but

01:00:41,350 --> 01:00:47,920
it's programmable hardware it's not like

01:00:43,390 --> 01:00:55,060
it's just this dedicated you know

01:00:47,920 --> 01:00:56,560
non-programmable piece of logic I mean

01:00:55,060 --> 01:00:58,480
my final comment would be that I don't

01:00:56,560 --> 01:01:01,720
just see event driven systems in the

01:00:58,480 --> 01:01:03,610
embedded world I see them in real time

01:01:01,720 --> 01:01:05,220
data processing things like that these

01:01:03,610 --> 01:01:07,810
people these guys that are doing the

01:01:05,220 --> 01:01:10,810
financial stuff they want to react

01:01:07,810 --> 01:01:13,840
really quickly to events so maybe

01:01:10,810 --> 01:01:17,890
there's a merger there of hpc and yeah

01:01:13,840 --> 01:01:20,140
where I get where I get stuck on like

01:01:17,890 --> 01:01:22,120
the dataflow version using depends and

01:01:20,140 --> 01:01:24,100
tasks and things like that is that at

01:01:22,120 --> 01:01:25,600
least the way the way embedded

01:01:24,100 --> 01:01:27,850
programmers think of it as they sort of

01:01:25,600 --> 01:01:29,470
spin everything up at once and they have

01:01:27,850 --> 01:01:32,440
these persistent tasks running in the

01:01:29,470 --> 01:01:35,740
background and I know there is data flow

01:01:32,440 --> 01:01:36,910
kind of going on there and i kind of got

01:01:35,740 --> 01:01:38,950
added a little bit with the way i

01:01:36,910 --> 01:01:41,410
respond it the second time where i

01:01:38,950 --> 01:01:44,080
invoke the task from within the inside

01:01:41,410 --> 01:01:45,550
the interrupt service routine but they

01:01:44,080 --> 01:01:47,080
just I don't know they don't think of it

01:01:45,550 --> 01:01:48,880
that way they think of it as more like I

01:01:47,080 --> 01:01:50,260
start up all these persistent tasks that

01:01:48,880 --> 01:01:52,360
are essentially running in concurrence

01:01:50,260 --> 01:01:54,370
in a concurrent way and then they get

01:01:52,360 --> 01:01:56,440
invoked based on certain when events

01:01:54,370 --> 01:01:58,690
happen so I don't know if it's

01:01:56,440 --> 01:02:02,100
Retraining them to think that way or you

01:01:58,690 --> 01:02:02,100

YouTube URL: https://www.youtube.com/watch?v=fSFjBmbWA0k


