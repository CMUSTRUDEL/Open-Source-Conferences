Title: Lock Yourself Out  -  Ruud van der Pas (Oracle)
Publication date: 2017-11-23
Playlist: SC17 OpenMP Booth Talks
Description: 
	SC17 OpenMP booth talks - November 2017, Denver CO.
PDF Slides at http://openmp.org/resources/openmp-presentations/sc17-booth-talks
Captions: 
	00:00:00,000 --> 00:00:07,290
all right I'm ready okay welcome good

00:00:04,560 --> 00:00:09,660
afternoon welcome to this talk I am

00:00:07,290 --> 00:00:11,580
going to talk about nasty things in

00:00:09,660 --> 00:00:15,570
parallel computing things you don't want

00:00:11,580 --> 00:00:17,640
to do but sometimes you have to my name

00:00:15,570 --> 00:00:20,400
is Ruth van de Paz I work at Oracle in

00:00:17,640 --> 00:00:22,380
the SPARC organization and typically

00:00:20,400 --> 00:00:24,960
looking at very large-scale problems

00:00:22,380 --> 00:00:27,930
both in terms of size of memory and

00:00:24,960 --> 00:00:30,359
threats and what I eventually go to show

00:00:27,930 --> 00:00:33,870
you is a real-world case that drove this

00:00:30,359 --> 00:00:37,469
entire talk and I think we're going to

00:00:33,870 --> 00:00:41,460
have an extra giveaway for the most

00:00:37,469 --> 00:00:43,350
engaged participants in this talk so I'm

00:00:41,460 --> 00:00:45,539
not talking about how many questions you

00:00:43,350 --> 00:00:47,730
ask because it's really as easy to ask

00:00:45,539 --> 00:00:50,010
many dumb questions it's about how

00:00:47,730 --> 00:00:52,590
engaged you are and that's highly

00:00:50,010 --> 00:00:54,210
subjective I'm afraid but in the end

00:00:52,590 --> 00:00:58,379
I'll need to make a decision who will

00:00:54,210 --> 00:01:00,629
who will get the extra prize oh yeah

00:00:58,379 --> 00:01:03,920
there's a little mini tutorial here I

00:01:00,629 --> 00:01:06,869
couldn't resist if you have a question

00:01:03,920 --> 00:01:09,630
we have very friendly booth staff here

00:01:06,869 --> 00:01:12,720
to help you out but if it's more

00:01:09,630 --> 00:01:14,939
specific to OpenMP we have on-site

00:01:12,720 --> 00:01:17,700
support as well there's always one of us

00:01:14,939 --> 00:01:21,900
around and here's your very friendly

00:01:17,700 --> 00:01:23,490
booth assistant to happily answer all

00:01:21,900 --> 00:01:27,600
the questions you may ever have about

00:01:23,490 --> 00:01:32,700
openmp alright let's get started with

00:01:27,600 --> 00:01:34,979
the meat of the talk what is a look the

00:01:32,700 --> 00:01:38,220
way I describe it a look is some sort of

00:01:34,979 --> 00:01:40,829
abstraction so I call it something and

00:01:38,220 --> 00:01:43,009
it's something that can be acquired by a

00:01:40,829 --> 00:01:47,040
thread

00:01:43,009 --> 00:01:49,229
the key is while a thread has that block

00:01:47,040 --> 00:01:51,240
nobody else can get it that's the that's

00:01:49,229 --> 00:01:53,909
the thing and actually how you implement

00:01:51,240 --> 00:01:57,210
it that's not my concern it's it's like

00:01:53,909 --> 00:01:59,369
I said it's like an abstraction so this

00:01:57,210 --> 00:02:01,560
allows a thread to do its work in

00:01:59,369 --> 00:02:03,299
private not disturbed by any of the

00:02:01,560 --> 00:02:06,000
other threads that's basically what it

00:02:03,299 --> 00:02:08,009
does and when you're done you're

00:02:06,000 --> 00:02:09,599
supposed to release the lock if you

00:02:08,009 --> 00:02:13,080
don't do that do that you have the

00:02:09,599 --> 00:02:13,950
famous deadlock everybody is waiting for

00:02:13,080 --> 00:02:15,840
you to release

00:02:13,950 --> 00:02:20,400
if you don't do that no progress will be

00:02:15,840 --> 00:02:23,069
made oh yeah so in that way you can do

00:02:20,400 --> 00:02:24,569
work on a protected region in your code

00:02:23,069 --> 00:02:26,790
where where you don't want to have

00:02:24,569 --> 00:02:29,370
multiple threads do that do that work at

00:02:26,790 --> 00:02:32,310
the same time all right here's a real

00:02:29,370 --> 00:02:33,630
world example everybody wants to steal

00:02:32,310 --> 00:02:37,380
from the cookie jar

00:02:33,630 --> 00:02:39,450
all right but while somebody is stealing

00:02:37,380 --> 00:02:41,670
a cookie trying to find the nicest one

00:02:39,450 --> 00:02:45,540
nobody else is allowed to open the jar

00:02:41,670 --> 00:02:50,069
and get a cookie so how would you do

00:02:45,540 --> 00:02:54,060
that well here's the code the code here

00:02:50,069 --> 00:02:56,160
will get some bookkeeping I have the

00:02:54,060 --> 00:02:58,890
OpenMP dates so it knows about the

00:02:56,160 --> 00:03:02,819
special data type and I have a variable

00:02:58,890 --> 00:03:05,040
called my clock that I hear declare to

00:03:02,819 --> 00:03:08,310
be of the locking type again how that's

00:03:05,040 --> 00:03:11,790
implemented it's not my concern then in

00:03:08,310 --> 00:03:13,650
my program I first have to initialize

00:03:11,790 --> 00:03:17,579
the lock that's a one-time thing done in

00:03:13,650 --> 00:03:20,549
the serial mode that declares the system

00:03:17,579 --> 00:03:22,350
to be a lock and actually sets up the

00:03:20,549 --> 00:03:24,480
data structures to handle the mechanics

00:03:22,350 --> 00:03:27,090
later on so that's a mandatory call if

00:03:24,480 --> 00:03:29,269
you don't have this any other behaviors

00:03:27,090 --> 00:03:31,859
unspecified so don't forget that and

00:03:29,269 --> 00:03:34,650
before I forget to say when you're done

00:03:31,859 --> 00:03:36,120
you have to destroy the look if you

00:03:34,650 --> 00:03:38,310
don't do that you'll probably get away

00:03:36,120 --> 00:03:41,160
with it but I would recommend to include

00:03:38,310 --> 00:03:43,799
it in your code all right then we have

00:03:41,160 --> 00:03:45,870
the parallel region and as you know all

00:03:43,799 --> 00:03:49,470
threads execute all the code in the

00:03:45,870 --> 00:03:52,639
parallel region so they all call a thing

00:03:49,470 --> 00:03:52,639
called the cookie jar

00:03:54,090 --> 00:03:57,430
so here's the source code of the cookie

00:03:56,890 --> 00:03:59,950
jar

00:03:57,430 --> 00:04:03,220
so one thread will get in and actually

00:03:59,950 --> 00:04:06,879
now it will set the look that jar is

00:04:03,220 --> 00:04:10,390
mine now and remembered nobody else can

00:04:06,879 --> 00:04:12,700
go in and try to do the same if you do

00:04:10,390 --> 00:04:16,120
you'll have to wait you're going to wait

00:04:12,700 --> 00:04:19,329
to acquire that what well you have the

00:04:16,120 --> 00:04:21,430
lock you grab your favorite cookie and

00:04:19,329 --> 00:04:23,830
you're supposed to release the lock that

00:04:21,430 --> 00:04:26,500
will give the next threat calling this

00:04:23,830 --> 00:04:26,949
function the same opportunity one after

00:04:26,500 --> 00:04:29,770
the other

00:04:26,949 --> 00:04:31,930
so that's by-and-large how a lock works

00:04:29,770 --> 00:04:34,720
by the way there are seats if you like

00:04:31,930 --> 00:04:37,690
to join there's going to be a lucky draw

00:04:34,720 --> 00:04:40,090
for a copy of our new book so if you

00:04:37,690 --> 00:04:44,590
leave your business card with us or join

00:04:40,090 --> 00:04:48,789
us you'll make a chance for that so why

00:04:44,590 --> 00:04:50,710
why bother about locks in open P it's

00:04:48,789 --> 00:04:53,430
typically implemented as a special

00:04:50,710 --> 00:04:57,070
variable where the special studies and

00:04:53,430 --> 00:04:59,260
it lives somewhere in memory you don't

00:04:57,070 --> 00:05:01,510
know where the lock is and I'll get back

00:04:59,260 --> 00:05:03,729
to that very soon the lock is available

00:05:01,510 --> 00:05:08,050
somewhere in your system in that shared

00:05:03,729 --> 00:05:09,849
memory and in order to check whether the

00:05:08,050 --> 00:05:13,389
lock is available it has to read the

00:05:09,849 --> 00:05:15,430
information now maybe you start seeing

00:05:13,389 --> 00:05:17,889
where I'm getting at a read could

00:05:15,430 --> 00:05:22,930
potentially be expensive in a large

00:05:17,889 --> 00:05:25,539
system because the data has to travel to

00:05:22,930 --> 00:05:27,070
that thread wherever it's executing so

00:05:25,539 --> 00:05:29,740
that single variable the cache line

00:05:27,070 --> 00:05:33,490
containing it will have to travel all

00:05:29,740 --> 00:05:35,800
the way to the to the thread and that

00:05:33,490 --> 00:05:37,889
could take some time for a lot of time

00:05:35,800 --> 00:05:40,150
and that will cost you performance

00:05:37,889 --> 00:05:43,630
another thing is with the lock you tend

00:05:40,150 --> 00:05:46,120
to serialize the execution one at a time

00:05:43,630 --> 00:05:47,410
and then each time you do that you have

00:05:46,120 --> 00:05:49,990
to wait for that variable to be

00:05:47,410 --> 00:05:52,930
available and if you're lucky the thread

00:05:49,990 --> 00:05:54,070
the next thread is executing nearby if

00:05:52,930 --> 00:05:56,260
you're not lucky that thread is

00:05:54,070 --> 00:05:59,199
somewhere else in your system and again

00:05:56,260 --> 00:06:02,380
you have to have the data so rocks tend

00:05:59,199 --> 00:06:02,830
to be expensive and that's what I just

00:06:02,380 --> 00:06:06,440
said

00:06:02,830 --> 00:06:09,150
it serializes execution

00:06:06,440 --> 00:06:11,780
as usual the bigger the system for the

00:06:09,150 --> 00:06:11,780
worse it gets

00:06:11,870 --> 00:06:17,160
but luckily you'll see it on a small

00:06:14,130 --> 00:06:19,440
system too so being aware even if you're

00:06:17,160 --> 00:06:21,960
developing on a small system today

00:06:19,440 --> 00:06:24,330
if you ever your manager gets enough

00:06:21,960 --> 00:06:25,950
money you'll get a bigger one if it

00:06:24,330 --> 00:06:30,690
doesn't hurt you today it will hurt you

00:06:25,950 --> 00:06:32,670
tomorrow so eventually a lock is going

00:06:30,690 --> 00:06:37,740
to destroy your scalability in many

00:06:32,670 --> 00:06:40,650
cases here's what I call the evil family

00:06:37,740 --> 00:06:44,070
member and that's an atomic operation

00:06:40,650 --> 00:06:46,140
and maybe a show of hands anybody here

00:06:44,070 --> 00:06:49,830
familiar knows what the atomic operation

00:06:46,140 --> 00:06:54,750
is in no all right I'm going to explain

00:06:49,830 --> 00:06:57,690
it it's some detail yeah so an atomic

00:06:54,750 --> 00:06:59,640
operation can be applied to any integer

00:06:57,690 --> 00:07:02,100
variables in some systems you can have a

00:06:59,640 --> 00:07:04,260
floating point variable but by and large

00:07:02,100 --> 00:07:07,080
you do that on an integer variable so

00:07:04,260 --> 00:07:09,980
here I have a variable my counter it's a

00:07:07,080 --> 00:07:13,140
global variable therefore shared

00:07:09,980 --> 00:07:17,220
initialized to zero there's a steamboat

00:07:13,140 --> 00:07:20,190
roll rolling in well so initialize to

00:07:17,220 --> 00:07:22,800
zero here's the parallel region and in

00:07:20,190 --> 00:07:27,240
this very simple example I used the

00:07:22,800 --> 00:07:30,480
atomic update to update this variable

00:07:27,240 --> 00:07:33,710
with one so each each time a thread will

00:07:30,480 --> 00:07:35,430
get in it will add one to that value

00:07:33,710 --> 00:07:37,140
essentially you're counting how many

00:07:35,430 --> 00:07:42,360
threads you have in your parallel reach

00:07:37,140 --> 00:07:44,160
that's what you do you know so behind

00:07:42,360 --> 00:07:48,030
the scenes a lot of things are happening

00:07:44,160 --> 00:07:50,760
here and the key the key of an atomic

00:07:48,030 --> 00:07:52,770
operation and this was introduced to

00:07:50,760 --> 00:07:56,250
think before the physicists found out

00:07:52,770 --> 00:07:58,290
there's more than an atom underneath the

00:07:56,250 --> 00:08:01,020
idea of an atomic operation is that

00:07:58,290 --> 00:08:04,740
nobody else can interfere while you do

00:08:01,020 --> 00:08:07,260
your atomic operation so you work on the

00:08:04,740 --> 00:08:09,990
atomic operation it's like a lock nobody

00:08:07,260 --> 00:08:14,750
else can get in and do the same so again

00:08:09,990 --> 00:08:14,750
you tend to serialize the computation

00:08:15,330 --> 00:08:21,900
and what I'm now going to show you and I

00:08:18,120 --> 00:08:23,849
bet you are probably the only one on

00:08:21,900 --> 00:08:26,580
this show floor showing you some

00:08:23,849 --> 00:08:28,199
assembly language in inner booths but

00:08:26,580 --> 00:08:30,479
that's what I'm going to do to show you

00:08:28,199 --> 00:08:33,209
how it really works under the hood

00:08:30,479 --> 00:08:35,940
alright so here's my function my atomic

00:08:33,209 --> 00:08:38,550
ad and what it does it takes a variable

00:08:35,940 --> 00:08:40,979
a and adds one to it in an atomic way

00:08:38,550 --> 00:08:43,349
let's say you want to write the source

00:08:40,979 --> 00:08:45,959
yourself which you shouldn't do because

00:08:43,349 --> 00:08:47,300
every function has atomic operations but

00:08:45,959 --> 00:08:49,890
let's say you want to do it at yourself

00:08:47,300 --> 00:08:53,459
alright and what I'm going to show you

00:08:49,890 --> 00:08:55,459
is non-existant assembly language and I

00:08:53,459 --> 00:08:59,790
couldn't resist to call it fake assembly

00:08:55,459 --> 00:09:04,529
so here's the code and I'll kind of

00:08:59,790 --> 00:09:07,350
slowly guide you through it I load the

00:09:04,529 --> 00:09:12,060
address the date at the address that's

00:09:07,350 --> 00:09:16,279
my my a into a register that's the first

00:09:12,060 --> 00:09:20,630
step then I have a loop in that loop I

00:09:16,279 --> 00:09:24,740
add one to that variable that's this one

00:09:20,630 --> 00:09:28,950
okay the thing is I want to know if that

00:09:24,740 --> 00:09:32,339
operation succeeded in an atomic way and

00:09:28,950 --> 00:09:35,370
for that about all systems I know have

00:09:32,339 --> 00:09:38,459
an instruction called cash compare and

00:09:35,370 --> 00:09:40,770
swap and how that works is best

00:09:38,459 --> 00:09:44,940
illustrated by the compare instruction

00:09:40,770 --> 00:09:47,730
next if if these two values are the same

00:09:44,940 --> 00:09:49,950
it means the swap has it has succeeded

00:09:47,730 --> 00:09:53,399
and have interchanged that I have

00:09:49,950 --> 00:09:55,050
updated the value it's not for the faint

00:09:53,399 --> 00:09:57,779
of heart this is probably not the right

00:09:55,050 --> 00:09:59,790
place to talk about these details but I

00:09:57,779 --> 00:10:03,149
wanted to show you how that works so you

00:09:59,790 --> 00:10:04,709
do the instruction the compare tells you

00:10:03,149 --> 00:10:06,149
whether it succeeded or not because

00:10:04,709 --> 00:10:09,120
maybe somebody else was doing it

00:10:06,149 --> 00:10:11,370
remember it's an atomic operation so if

00:10:09,120 --> 00:10:13,170
this thread can't do it that means

00:10:11,370 --> 00:10:15,149
somebody else was doing that operation

00:10:13,170 --> 00:10:17,670
so you have to wait and that's why

00:10:15,149 --> 00:10:18,240
there's a loop you're trying it you try

00:10:17,670 --> 00:10:21,709
again

00:10:18,240 --> 00:10:24,779
now the disclaimer is this is very naive

00:10:21,709 --> 00:10:26,730
usually that you don't try again

00:10:24,779 --> 00:10:28,350
immediately you have a timeout

00:10:26,730 --> 00:10:32,130
because otherwise you'll be hitting

00:10:28,350 --> 00:10:33,420
their cash line all the time the other

00:10:32,130 --> 00:10:36,810
reason I want to show you the assembly

00:10:33,420 --> 00:10:40,290
you see load instructions here you

00:10:36,810 --> 00:10:42,210
actually have to load that data and what

00:10:40,290 --> 00:10:44,250
I find to be the misconception is is

00:10:42,210 --> 00:10:45,090
that people think this instruction is

00:10:44,250 --> 00:10:47,640
expensive

00:10:45,090 --> 00:10:51,240
no it's loading the data that will cost

00:10:47,640 --> 00:10:56,340
you all right all right so why is it

00:10:51,240 --> 00:10:59,370
evil and even despite the instruction

00:10:56,340 --> 00:11:01,080
level support like as it sit the costs

00:10:59,370 --> 00:11:04,350
and most of the cost is in the data

00:11:01,080 --> 00:11:07,440
transfer and again as you scale up your

00:11:04,350 --> 00:11:11,430
machine and threads that becomes a worse

00:11:07,440 --> 00:11:13,290
and worse problem so eventually just

00:11:11,430 --> 00:11:17,040
like a lock an atomic operation will

00:11:13,290 --> 00:11:18,900
start dominating your scalability so I

00:11:17,040 --> 00:11:21,380
have a case study to demonstrate this

00:11:18,900 --> 00:11:24,120
this is from a real world application

00:11:21,380 --> 00:11:27,030
simplified but it's what I found in a

00:11:24,120 --> 00:11:30,120
real code and it's it's it drove me to

00:11:27,030 --> 00:11:32,940
actually give this talk so let me go

00:11:30,120 --> 00:11:36,810
through it fairly slowly there's an open

00:11:32,940 --> 00:11:40,460
MP parallel region that's some integer

00:11:36,810 --> 00:11:42,690
variable I but as a while 1 loop I

00:11:40,460 --> 00:11:45,410
always have some difficulty understand

00:11:42,690 --> 00:11:48,210
there while one means it will never end

00:11:45,410 --> 00:11:51,060
but eventually you'll see a break

00:11:48,210 --> 00:11:53,010
so you'll jump out of it ok I see some

00:11:51,060 --> 00:11:55,440
heads nodding so I'm probably the only

00:11:53,010 --> 00:11:57,660
one struggling with that concept but ok

00:11:55,440 --> 00:12:01,830
so it's an infinite loop where

00:11:57,660 --> 00:12:04,620
eventually you jump out so inside is an

00:12:01,830 --> 00:12:07,440
atomic updates inside the parallel

00:12:04,620 --> 00:12:10,680
region inside a while is an atomic

00:12:07,440 --> 00:12:14,450
update and it it does an increment and

00:12:10,680 --> 00:12:17,220
the capture says keep the old value

00:12:14,450 --> 00:12:19,530
because I need it so you do two things

00:12:17,220 --> 00:12:22,260
at the same time that's one of the more

00:12:19,530 --> 00:12:25,590
recent open MP constructs to keep the

00:12:22,260 --> 00:12:29,340
old value and update the new one so job

00:12:25,590 --> 00:12:32,700
counter is incremented if this I exceeds

00:12:29,340 --> 00:12:35,400
some threshold you're done and this is

00:12:32,700 --> 00:12:37,640
all private to that thread executing

00:12:35,400 --> 00:12:41,060
inside the parallel region

00:12:37,640 --> 00:12:44,500
yeah once you have your value of I and

00:12:41,060 --> 00:12:47,269
you didn't break out you do some work so

00:12:44,500 --> 00:12:49,070
I'm not in favor of asking questions to

00:12:47,269 --> 00:12:52,010
the audience especially not on the noisy

00:12:49,070 --> 00:12:54,260
show floor but why is this bad and I'll

00:12:52,010 --> 00:12:58,279
answer my own question why is this bad

00:12:54,260 --> 00:13:01,220
this one how often will this be executed

00:12:58,279 --> 00:13:04,070
many many times as much there's work for

00:13:01,220 --> 00:13:06,350
that thread this is like a work cubing

00:13:04,070 --> 00:13:08,839
system that's basically what it does it

00:13:06,350 --> 00:13:11,120
gets some work do it gets the next

00:13:08,839 --> 00:13:14,120
portion of work and that's in a very

00:13:11,120 --> 00:13:17,290
naive way implemented here so not only

00:13:14,120 --> 00:13:20,779
is the rock or the atomic I should say

00:13:17,290 --> 00:13:23,950
executed each for each thread it's a

00:13:20,779 --> 00:13:27,709
cute admitting any times for each set

00:13:23,950 --> 00:13:30,890
that's not a good idea I looked at this

00:13:27,709 --> 00:13:33,170
code and actually took me a little bit

00:13:30,890 --> 00:13:38,450
too long to realize gee this is just a

00:13:33,170 --> 00:13:41,600
look this is just a for loop all right

00:13:38,450 --> 00:13:44,360
it was done for load balancing in this

00:13:41,600 --> 00:13:47,420
way if if a thread needs more time it

00:13:44,360 --> 00:13:49,970
won't block the other threads but again

00:13:47,420 --> 00:13:54,459
bad for scalability and when you look at

00:13:49,970 --> 00:13:57,350
it long enough you can see it's a loop

00:13:54,459 --> 00:13:58,160
so here's what I came up with I can

00:13:57,350 --> 00:14:00,980
pre-compute

00:13:58,160 --> 00:14:02,779
how much work is being done so I have

00:14:00,980 --> 00:14:05,360
some bookkeeping how many threads do I

00:14:02,779 --> 00:14:07,279
have how much work is that to be done

00:14:05,360 --> 00:14:10,610
and how much work I might go to assign

00:14:07,279 --> 00:14:12,740
to each thread that's not difficult

00:14:10,610 --> 00:14:14,959
you're just a nasty bookkeeping but you

00:14:12,740 --> 00:14:17,240
get it right eventually and then you

00:14:14,959 --> 00:14:21,110
figure that out and when once you have

00:14:17,240 --> 00:14:23,570
that you start filling an array that for

00:14:21,110 --> 00:14:26,870
each thread will tell you how much work

00:14:23,570 --> 00:14:29,660
needs to be done so statically I pre

00:14:26,870 --> 00:14:32,750
compute how much work I'm going to give

00:14:29,660 --> 00:14:35,480
to each set so what I lose is my load

00:14:32,750 --> 00:14:37,880
balancing handling if there's a load

00:14:35,480 --> 00:14:40,130
imbalance and I'm sort of stuck and

00:14:37,880 --> 00:14:42,560
there is a load imbalance here the

00:14:40,130 --> 00:14:44,240
question is what will win the cost of

00:14:42,560 --> 00:14:47,899
giving up the nice load imbalance

00:14:44,240 --> 00:14:50,810
handling or getting rid of the lock well

00:14:47,899 --> 00:14:53,660
I know the answer and I'll show you

00:14:50,810 --> 00:14:58,310
all right so inside that parallel region

00:14:53,660 --> 00:15:01,910
I still have a look when I assign the

00:14:58,310 --> 00:15:04,700
work I still have to do a lock because a

00:15:01,910 --> 00:15:07,670
thread gets in and it will just grab

00:15:04,700 --> 00:15:11,090
from the cube remember I set up these

00:15:07,670 --> 00:15:12,590
arrays it's like a queue I have an index

00:15:11,090 --> 00:15:15,650
array that will give you the next

00:15:12,590 --> 00:15:18,230
portion of work and I don't care which

00:15:15,650 --> 00:15:21,170
thread does which port part of the work

00:15:18,230 --> 00:15:24,620
as long as it gets work to be done so

00:15:21,170 --> 00:15:27,620
this is a fairly dynamic assignment just

00:15:24,620 --> 00:15:30,590
pull your work from the queue I need to

00:15:27,620 --> 00:15:33,920
lock it because of this one I need to

00:15:30,590 --> 00:15:36,520
make sure that while this read is in

00:15:33,920 --> 00:15:40,700
progress in that work is not modified I

00:15:36,520 --> 00:15:42,410
hope that's clear to to you because

00:15:40,700 --> 00:15:44,720
that's the key part that's why I do the

00:15:42,410 --> 00:15:47,570
locking once I know what needs to be

00:15:44,720 --> 00:15:54,880
done I can set the lock and I can do my

00:15:47,570 --> 00:15:59,870
work okay and the work part is simply a

00:15:54,880 --> 00:16:02,750
for loop where start and end are

00:15:59,870 --> 00:16:05,030
controlled by the thread because that

00:16:02,750 --> 00:16:08,930
was the work had just picked up so I

00:16:05,030 --> 00:16:11,270
still have a lock but only the number of

00:16:08,930 --> 00:16:14,360
times called the number of times that I

00:16:11,270 --> 00:16:18,950
have threads no longer inside that wire

00:16:14,360 --> 00:16:21,980
loop that was the one killing me so it's

00:16:18,950 --> 00:16:23,990
not so good for load balancing but it's

00:16:21,980 --> 00:16:27,890
very much better for scalability and

00:16:23,990 --> 00:16:30,080
I'll show you them the results I ran

00:16:27,890 --> 00:16:33,080
that on a one of our servers a spark

00:16:30,080 --> 00:16:38,450
server running at 4 plus 0.1 key Goertz

00:16:33,080 --> 00:16:40,730
it has a total of 256 cores 256 2048

00:16:38,450 --> 00:16:43,850
threads in one system to one single

00:16:40,730 --> 00:16:47,870
system machine that 4 terabyte remember

00:16:43,850 --> 00:16:50,360
I didn't go that far I have two versions

00:16:47,870 --> 00:16:53,780
the dynamic that was with the while loop

00:16:50,360 --> 00:16:55,790
and all the atomic operations and the

00:16:53,780 --> 00:16:58,420
static that used that for loop that's

00:16:55,790 --> 00:17:02,140
the second version that I showed

00:16:58,420 --> 00:17:03,630
there's a result the result I show the

00:17:02,140 --> 00:17:07,949
seconds per iteration

00:17:03,630 --> 00:17:10,630
so like the speed so lower is better as

00:17:07,949 --> 00:17:13,329
a function of the number of threads that

00:17:10,630 --> 00:17:15,069
I'm using and I didn't use zero threads

00:17:13,329 --> 00:17:17,530
I used one that's a little glitch here

00:17:15,069 --> 00:17:21,250
this is one thread all the way to all

00:17:17,530 --> 00:17:24,339
the threads in the system the blue line

00:17:21,250 --> 00:17:26,980
is the good case that's aesthetic the

00:17:24,339 --> 00:17:30,220
red one is the dynamic version as you

00:17:26,980 --> 00:17:34,150
see for up to toon 256 ports and even

00:17:30,220 --> 00:17:36,640
beyond like 384 it's no performance

00:17:34,150 --> 00:17:39,790
difference this was on a hundred

00:17:36,640 --> 00:17:42,840
gigabyte size problem so that was sort

00:17:39,790 --> 00:17:45,640
of a smallish for this kind of machine

00:17:42,840 --> 00:17:48,429
and what you see is it starts taking

00:17:45,640 --> 00:17:50,530
this is bad news they get slower and

00:17:48,429 --> 00:17:54,070
slower that's what it says takes more

00:17:50,530 --> 00:17:56,919
time and when you do an honest

00:17:54,070 --> 00:17:58,150
comparison not here this is not a fair

00:17:56,919 --> 00:18:00,460
comparison when you look at the best

00:17:58,150 --> 00:18:02,260
score here and the best score here

00:18:00,460 --> 00:18:05,620
you'll see it's more than two times

00:18:02,260 --> 00:18:08,080
faster 2.3 times faster so it's a trick

00:18:05,620 --> 00:18:10,450
worth doing I want to see what happens

00:18:08,080 --> 00:18:14,770
on a larger problem size because then

00:18:10,450 --> 00:18:15,480
there's more work per thread pretty

00:18:14,770 --> 00:18:19,860
similar

00:18:15,480 --> 00:18:19,860
now yeah

00:18:22,200 --> 00:18:27,390
yes

00:18:24,320 --> 00:18:27,390
[Music]

00:18:29,799 --> 00:18:36,620
exactly the question is the question is

00:18:33,080 --> 00:18:39,649
is it exactly starts changing when you

00:18:36,620 --> 00:18:41,960
have used all the chords in the system

00:18:39,649 --> 00:18:44,059
so once you start over subscribing and

00:18:41,960 --> 00:18:46,399
yes definitely I haven't looked at that

00:18:44,059 --> 00:18:47,330
why that is but I don't think that's

00:18:46,399 --> 00:18:49,279
coincidence

00:18:47,330 --> 00:18:51,140
so there could be some cash annoying

00:18:49,279 --> 00:18:53,809
behavior because this is basically cash

00:18:51,140 --> 00:18:57,159
line behavior getting me yeah very good

00:18:53,809 --> 00:18:57,159
observation yes

00:19:00,480 --> 00:19:05,190
[Music]

00:19:02,560 --> 00:19:05,190
yeah

00:19:06,130 --> 00:19:13,600
yes yep that's the the the comment is

00:19:10,210 --> 00:19:15,970
it's probably the thread it's holding

00:19:13,600 --> 00:19:17,799
the lock it's holding the cash line and

00:19:15,970 --> 00:19:19,900
then it has to go out for the other

00:19:17,799 --> 00:19:23,140
thread to come in and then you start all

00:19:19,900 --> 00:19:25,150
over again so yeah so it's definitely I

00:19:23,140 --> 00:19:28,660
suspect it's something related to that

00:19:25,150 --> 00:19:32,110
yes so when we do the comparison here we

00:19:28,660 --> 00:19:34,690
see you lose it's not no longer 2.3

00:19:32,110 --> 00:19:36,940
because you got more work per thread so

00:19:34,690 --> 00:19:39,730
the cost is that what we're talking

00:19:36,940 --> 00:19:41,530
about half a terabyte size problem so

00:19:39,730 --> 00:19:42,640
you gotta have really large problems to

00:19:41,530 --> 00:19:47,140
make this go away

00:19:42,640 --> 00:19:50,320
probably petabyte or whatever so alright

00:19:47,140 --> 00:19:54,010
now here's the cliffhanger this is arias

00:19:50,320 --> 00:19:59,289
audience participation time anybody dare

00:19:54,010 --> 00:20:01,330
to suggest what would be a nice way to

00:19:59,289 --> 00:20:04,539
deal with the load balancing issue that

00:20:01,330 --> 00:20:07,809
I gave up I gave up the dealing of load

00:20:04,539 --> 00:20:12,909
balancing is there possibly a way to

00:20:07,809 --> 00:20:14,620
deal with it anybody dare to suggest now

00:20:12,909 --> 00:20:17,650
all right well that's why you need to

00:20:14,620 --> 00:20:22,049
buy the book because it's the new task

00:20:17,650 --> 00:20:24,460
loop construct in openmp the task loop

00:20:22,049 --> 00:20:27,789
actually is very nice I like it very

00:20:24,460 --> 00:20:31,299
much it's a loop but underneath it uses

00:20:27,789 --> 00:20:33,820
tasking and you can get more control

00:20:31,299 --> 00:20:36,580
about load balancing inside the loop

00:20:33,820 --> 00:20:40,260
with that you get some extra clauses to

00:20:36,580 --> 00:20:43,299
specify it's a very powerful construct

00:20:40,260 --> 00:20:45,429
unfortunately I did not have time to

00:20:43,299 --> 00:20:48,280
really try it

00:20:45,429 --> 00:20:51,000
maybe next year supercomputing 18 and

00:20:48,280 --> 00:20:54,010
that concludes my presentation

00:20:51,000 --> 00:20:57,730
to summarize the way I see locks in

00:20:54,010 --> 00:20:59,679
Atomics they're like gold coins you like

00:20:57,730 --> 00:21:03,820
to have them but you don't want to use

00:20:59,679 --> 00:21:06,190
them so that finishes it I remember if

00:21:03,820 --> 00:21:09,340
somebody tells you OpenMP does not scale

00:21:06,190 --> 00:21:13,179
you should say bad OpenMP does not scale

00:21:09,340 --> 00:21:16,860
and that finishes my talk and thank you

00:21:13,179 --> 00:21:22,399
very much any questions

00:21:16,860 --> 00:21:22,399

YouTube URL: https://www.youtube.com/watch?v=s542B6-ew3o


