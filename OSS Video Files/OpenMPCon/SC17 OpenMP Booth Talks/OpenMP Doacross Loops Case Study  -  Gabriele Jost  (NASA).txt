Title: OpenMP Doacross Loops Case Study  -  Gabriele Jost  (NASA)
Publication date: 2017-11-23
Playlist: SC17 OpenMP Booth Talks
Description: 
	SC17 OpenMP booth talks - November 2017, Denver CO.
PDF Slides at http://openmp.org/resources/openmp-presentations/sc17-booth-talks
Captions: 
	00:00:00,030 --> 00:00:06,750
I could good afternoon my name is

00:00:04,259 --> 00:00:08,820
cappella used I work in the scientific

00:00:06,750 --> 00:00:12,870
consulting group at NASA Ames Research

00:00:08,820 --> 00:00:15,660
Center and my colleague Henry in who is

00:00:12,870 --> 00:00:20,490
very active on OpenMP committee and

00:00:15,660 --> 00:00:24,689
myself the experiment but opened with

00:00:20,490 --> 00:00:27,990
the newly introduced open MP 4.5 duo

00:00:24,689 --> 00:00:32,399
cross support using our well-known

00:00:27,990 --> 00:00:38,160
NASCAR event mark area and that's what

00:00:32,399 --> 00:00:40,649
this talks all about and so the outline

00:00:38,160 --> 00:00:43,440
of the presentation will be as follows

00:00:40,649 --> 00:00:46,110
I'll give some background information on

00:00:43,440 --> 00:00:50,670
openmp dual costs because some people

00:00:46,110 --> 00:00:52,430
may not know what that is explained the

00:00:50,670 --> 00:00:55,530
different we have six different

00:00:52,430 --> 00:00:57,899
implementations after Lu benchmarks I'm

00:00:55,530 --> 00:01:03,300
sure you are all thrilled to hear about

00:00:57,899 --> 00:01:07,080
it and so we look at I will explain the

00:01:03,300 --> 00:01:09,840
different algorithms to you and focus on

00:01:07,080 --> 00:01:13,260
comparison of synchronization versus two

00:01:09,840 --> 00:01:16,080
across and to all the implementation

00:01:13,260 --> 00:01:18,869
work was done by my colleague Henry in

00:01:16,080 --> 00:01:20,490
new who can unfortunately not be here

00:01:18,869 --> 00:01:22,590
today that's why I'm giving the

00:01:20,490 --> 00:01:24,840
presentation I've done two performance

00:01:22,590 --> 00:01:27,090
analysis so I will show you some

00:01:24,840 --> 00:01:30,570
performance analysis results and then

00:01:27,090 --> 00:01:33,600
drawn summarize everything and come up

00:01:30,570 --> 00:01:39,090
with some conclusions hopefully so what

00:01:33,600 --> 00:01:41,340
what is openmp do or cross who has heard

00:01:39,090 --> 00:01:44,700
about the open and key to a cross

00:01:41,340 --> 00:01:47,970
support so velvety you've heard about it

00:01:44,700 --> 00:01:51,689
or not I'm going to explain it anyhow so

00:01:47,970 --> 00:01:55,560
since open mp4 we have the ordered

00:01:51,689 --> 00:01:58,439
clause for work share construct and an

00:01:55,560 --> 00:02:01,409
ordered construct and we dis with a

00:01:58,439 --> 00:02:04,320
combo of the two of them that enables

00:02:01,409 --> 00:02:07,920
you to enclose within a work shirt loop

00:02:04,320 --> 00:02:09,960
you can enclose a structure of a block

00:02:07,920 --> 00:02:13,530
of statements

00:02:09,960 --> 00:02:15,930
and make it web ID or as being ordered

00:02:13,530 --> 00:02:19,040
and that makes it that these statements

00:02:15,930 --> 00:02:22,620
will be executed sequentially so

00:02:19,040 --> 00:02:26,610
admittedly that's the expressiveness of

00:02:22,620 --> 00:02:29,640
this is not very great so you have like

00:02:26,610 --> 00:02:31,830
no possibilities to say anything about

00:02:29,640 --> 00:02:34,220
the nature of the dependence you know

00:02:31,830 --> 00:02:37,950
like the distance or anything and

00:02:34,220 --> 00:02:41,880
sometimes you may want that so relief

00:02:37,950 --> 00:02:45,660
comes with openmp 4.5 which actually

00:02:41,880 --> 00:02:48,510
introduced ordered append clause for the

00:02:45,660 --> 00:02:53,040
ordered construct and who depend clause

00:02:48,510 --> 00:02:56,340
takes arguments sync and source or which

00:02:53,040 --> 00:02:57,210
allow you I have a little code snippet

00:02:56,340 --> 00:02:59,970
here

00:02:57,210 --> 00:03:05,520
so the sync argument with the sync

00:02:59,970 --> 00:03:08,670
argument you can specify you can to tell

00:03:05,520 --> 00:03:11,280
the runtime that here there is a point

00:03:08,670 --> 00:03:14,310
where you have to wait for previous

00:03:11,280 --> 00:03:17,370
iteration to be finished so in this case

00:03:14,310 --> 00:03:21,810
it's just iteration I minus 1 so my tear

00:03:17,370 --> 00:03:25,580
directly pre the iteration pro well

00:03:21,810 --> 00:03:29,220
before and then the ordered source

00:03:25,580 --> 00:03:31,710
signals to completion of iteration I so

00:03:29,220 --> 00:03:34,110
now everybody else who are dependent on

00:03:31,710 --> 00:03:36,390
iteration I can go ahead and do their

00:03:34,110 --> 00:03:39,420
work why would you and and this whole

00:03:36,390 --> 00:03:41,280
combo out of the do across construct

00:03:39,420 --> 00:03:43,110
together with the sync and with a

00:03:41,280 --> 00:03:46,260
dependent clause and syncing source

00:03:43,110 --> 00:03:50,100
argument that's what's commonly referred

00:03:46,260 --> 00:03:53,400
to as blue cross concept so why would

00:03:50,100 --> 00:03:57,200
one want to have such an exotic thing

00:03:53,400 --> 00:04:00,510
said well that comes in handy for

00:03:57,200 --> 00:04:03,110
paralyzing algorithms that walk through

00:04:00,510 --> 00:04:06,420
the data in a hyperplane or pipeline

00:04:03,110 --> 00:04:10,260
fashion an example is two over for the

00:04:06,420 --> 00:04:14,640
overflow the computational computer AMEX

00:04:10,260 --> 00:04:17,190
code overflow which employs an Lu matrix

00:04:14,640 --> 00:04:21,930
decomposition with symmetric outsider

00:04:17,190 --> 00:04:25,499
line sweeping for an implicit portion of

00:04:21,930 --> 00:04:28,499
it's optional and and so does these

00:04:25,499 --> 00:04:31,979
these charts or these these pictures

00:04:28,499 --> 00:04:35,159
kind of nicely demonstrate here just in

00:04:31,979 --> 00:04:39,629
2d of how you walk through the data a

00:04:35,159 --> 00:04:42,629
hyperplane wise or pipelined wise order

00:04:39,629 --> 00:04:46,319
Lu Colonel captures the nature of this

00:04:42,629 --> 00:04:49,490
code of it it uses a successive over

00:04:46,319 --> 00:04:53,249
relaxation method to solve a bandit

00:04:49,490 --> 00:04:55,830
block diagonal matrix and here it's

00:04:53,249 --> 00:04:58,500
factorized into a lower and upper solver

00:04:55,830 --> 00:05:01,139
steps and both but both solver steps

00:04:58,500 --> 00:05:03,930
carry dependences in each of the spatial

00:05:01,139 --> 00:05:07,250
dimensions it's indicated here in this

00:05:03,930 --> 00:05:09,900
code snippet and obviously there is no

00:05:07,250 --> 00:05:12,779
straightforward way to just easily put

00:05:09,900 --> 00:05:16,080
an open and p directive and paralyze

00:05:12,779 --> 00:05:18,960
such just not parallel however if you

00:05:16,080 --> 00:05:22,139
put your brains and a lot of time and

00:05:18,960 --> 00:05:26,939
effort into it you can actually achieve

00:05:22,139 --> 00:05:30,300
a pipelined execution of the threads so

00:05:26,939 --> 00:05:33,719
for pipeline execution but you can do is

00:05:30,300 --> 00:05:39,479
you start all iterations of the K loop

00:05:33,719 --> 00:05:42,750
in parallel and then all at the same

00:05:39,479 --> 00:05:45,270
time then you place your work sure your

00:05:42,750 --> 00:05:47,819
work share on the next innermost loop

00:05:45,270 --> 00:05:51,300
which is the J in this case however

00:05:47,819 --> 00:05:53,819
before execution of the J loop you need

00:05:51,300 --> 00:05:56,430
to make sure you need to synchronize

00:05:53,819 --> 00:05:59,610
with your left neighbor whether the data

00:05:56,430 --> 00:06:02,159
is ready that you need it and then after

00:05:59,610 --> 00:06:08,009
you're done with your J loop you'll you

00:06:02,159 --> 00:06:11,399
indicate okay data available so now that

00:06:08,009 --> 00:06:13,439
looks so you can do this how can you do

00:06:11,399 --> 00:06:16,259
this now these would you that's here

00:06:13,439 --> 00:06:18,569
being done with routine sync left and

00:06:16,259 --> 00:06:21,479
soon quite and they're not just there

00:06:18,569 --> 00:06:25,680
okay you have to write them you have to

00:06:21,479 --> 00:06:30,899
implement them yourself and a boy that's

00:06:25,680 --> 00:06:33,570
like time consuming non-intuitive and as

00:06:30,899 --> 00:06:35,760
we all know throw error

00:06:33,570 --> 00:06:38,190
actually the benchmark itself had an

00:06:35,760 --> 00:06:40,470
error in it for years but it's fixed

00:06:38,190 --> 00:06:42,840
it's all working now I'm not going to

00:06:40,470 --> 00:06:45,390
show the code for the sink left and

00:06:42,840 --> 00:06:48,600
assume quite because we're two people

00:06:45,390 --> 00:06:51,690
who know OpenMP that will just trigger

00:06:48,600 --> 00:06:54,600
endless discussions I will only tell you

00:06:51,690 --> 00:06:58,430
that it relies on testing of shared

00:06:54,600 --> 00:07:01,320
variables and employs the OMP flash

00:06:58,430 --> 00:07:03,240
semantics that's all that's all not

00:07:01,320 --> 00:07:07,830
going to say anything more about it

00:07:03,240 --> 00:07:10,830
now now life has become easier look for

00:07:07,830 --> 00:07:15,300
T of it you do across support you can

00:07:10,830 --> 00:07:19,380
now just no more manual implementation

00:07:15,300 --> 00:07:22,290
necessary you use your your parallel and

00:07:19,380 --> 00:07:25,670
your work share as before except you

00:07:22,290 --> 00:07:30,120
introduced they ordered your introduced

00:07:25,670 --> 00:07:32,070
the ordered clause you will put the

00:07:30,120 --> 00:07:35,670
ordered clause on the work share and

00:07:32,070 --> 00:07:39,600
then you put your sink here and your

00:07:35,670 --> 00:07:44,460
source here and that's o see here it's

00:07:39,600 --> 00:07:46,980
nicely summarized what I just bled it so

00:07:44,460 --> 00:07:49,830
your instead of having a routine sink

00:07:46,980 --> 00:07:53,310
left that you call you know just specify

00:07:49,830 --> 00:07:56,610
this argument sink J minus one and then

00:07:53,310 --> 00:07:59,610
your signal instead of a sink right you

00:07:56,610 --> 00:08:03,390
just say depend source that's that and

00:07:59,610 --> 00:08:06,420
so so now no spent nothing error-prone

00:08:03,390 --> 00:08:09,150
from your side okay now it's all left to

00:08:06,420 --> 00:08:10,410
the compiler if there is an error it's

00:08:09,150 --> 00:08:12,420
not your fault

00:08:10,410 --> 00:08:17,640
but I mean hope for hopefully there is

00:08:12,420 --> 00:08:20,580
no error so nice nice and clean I like

00:08:17,640 --> 00:08:24,540
it well one might ask for is I well

00:08:20,580 --> 00:08:26,700
where do you think as I because we are

00:08:24,540 --> 00:08:30,500
talking about triply nested loops it's

00:08:26,700 --> 00:08:36,210
hidden in these fourteen cacld and and

00:08:30,500 --> 00:08:37,050
BLTs which somehow to micro is not

00:08:36,210 --> 00:08:46,860
really working

00:08:37,050 --> 00:08:52,110
so which yeah so and and plcs is to one

00:08:46,860 --> 00:08:54,870
carries the dependents and so that that

00:08:52,110 --> 00:08:57,990
was a pipelined version now there's also

00:08:54,870 --> 00:08:59,820
the possibility to in order to extract

00:08:57,990 --> 00:09:03,660
some parallelism to walk through the

00:08:59,820 --> 00:09:07,110
data along a hyperplane so it is in this

00:09:03,660 --> 00:09:10,800
approach you rely on the facts that all

00:09:07,110 --> 00:09:14,130
points within a hyperplane can be

00:09:10,800 --> 00:09:16,980
calculated in parallel so you exploit

00:09:14,130 --> 00:09:20,720
the parallelism across a hyperplane and

00:09:16,980 --> 00:09:23,610
you don't need any further threat

00:09:20,720 --> 00:09:26,820
synchronization here because you can do

00:09:23,610 --> 00:09:29,400
them all in parallel however in order to

00:09:26,820 --> 00:09:32,040
you you need to mung with the original

00:09:29,400 --> 00:09:35,250
code of the benchmark a little bit you

00:09:32,040 --> 00:09:39,780
have to do well in my view some sort of

00:09:35,250 --> 00:09:43,560
mind-bending in index calculation index

00:09:39,780 --> 00:09:47,880
calculation transforming the loop or JK

00:09:43,560 --> 00:09:51,270
into a loop over l and JK where L is the

00:09:47,880 --> 00:09:54,240
hyperplane are the hyperplanes and JK

00:09:51,270 --> 00:09:58,110
odd all the points within the L or

00:09:54,240 --> 00:10:00,060
within the hyperplane so no so you do it

00:09:58,110 --> 00:10:02,250
this way you walk through that and then

00:10:00,060 --> 00:10:04,440
you can do all of the hyperplane points

00:10:02,250 --> 00:10:06,930
in parallel and then you have to do it

00:10:04,440 --> 00:10:10,200
you have to have takes the implicit

00:10:06,930 --> 00:10:14,430
barrier synchronization at at the end of

00:10:10,200 --> 00:10:16,710
the work sharing loop all nice except

00:10:14,430 --> 00:10:20,490
yeah it's it's difficult it requires

00:10:16,710 --> 00:10:24,570
Manning but to code now again so here we

00:10:20,490 --> 00:10:29,220
employed a to do a cross support but now

00:10:24,570 --> 00:10:31,530
we are experiencing dependences in two

00:10:29,220 --> 00:10:34,920
dimensions so basically we are

00:10:31,530 --> 00:10:38,370
extracting parallelism in two dimensions

00:10:34,920 --> 00:10:41,340
by just using this two across and again

00:10:38,370 --> 00:10:43,680
looks so much nicer and cleaner only

00:10:41,340 --> 00:10:46,380
thing we leave the original structure of

00:10:43,680 --> 00:10:50,280
the code we just supply the ordered

00:10:46,380 --> 00:10:53,040
clause now with the argument - and we

00:10:50,280 --> 00:10:59,010
have - depends here and one source and

00:10:53,040 --> 00:11:02,680
Bob's your uncle that's all done nice

00:10:59,010 --> 00:11:06,100
so that's all you need to do but you

00:11:02,680 --> 00:11:07,560
know so you leave all this work schedule

00:11:06,100 --> 00:11:10,240
and the compiler generated

00:11:07,560 --> 00:11:13,030
synchronization and one time library

00:11:10,240 --> 00:11:17,410
it's all handled by them no worry about

00:11:13,030 --> 00:11:20,170
that which is good in one way except on

00:11:17,410 --> 00:11:22,540
the other hand you I am Not sure that

00:11:20,170 --> 00:11:24,670
really walks through the data in a hyper

00:11:22,540 --> 00:11:27,700
plane version as a matter fact you have

00:11:24,670 --> 00:11:32,160
very little little insights what's

00:11:27,700 --> 00:11:36,160
really going on okay and that's why we

00:11:32,160 --> 00:11:39,550
you may have noticed that here we use a

00:11:36,160 --> 00:11:42,940
static work schedule with chunk size one

00:11:39,550 --> 00:11:43,690
while video for a version we didn't have

00:11:42,940 --> 00:11:45,850
to do that

00:11:43,690 --> 00:11:48,310
why do we need chunk ninth if we need

00:11:45,850 --> 00:11:51,340
chunk size one well that led to the best

00:11:48,310 --> 00:11:53,520
load balancing and I'll come back to

00:11:51,340 --> 00:11:55,720
that later but you know since we odd

00:11:53,520 --> 00:11:57,850
understands so little about why it's

00:11:55,720 --> 00:12:00,160
what's going on the way we found out is

00:11:57,850 --> 00:12:03,820
by experimentation you know we just saw

00:12:00,160 --> 00:12:06,070
man the performance is bad you know why

00:12:03,820 --> 00:12:08,890
and then we experimented with the chunk

00:12:06,070 --> 00:12:12,670
size and lucky day look at it it's it's

00:12:08,890 --> 00:12:15,370
better so now for if you have not enough

00:12:12,670 --> 00:12:18,760
of this you can drive as a low-level

00:12:15,370 --> 00:12:22,750
further and now exploit the parallelism

00:12:18,760 --> 00:12:25,150
across all three dimensions I don't even

00:12:22,750 --> 00:12:28,780
want to show the manual implementation

00:12:25,150 --> 00:12:30,820
of it I mean if all for me to the index

00:12:28,780 --> 00:12:34,090
calculation was already mind pending

00:12:30,820 --> 00:12:40,480
before but just the other one only and

00:12:34,090 --> 00:12:42,940
we can do that so so anyhow this is how

00:12:40,480 --> 00:12:46,600
exploiting or parallelism in three

00:12:42,940 --> 00:12:49,210
dimensions I would look like with the

00:12:46,600 --> 00:12:52,510
two cross support again nice and clean

00:12:49,210 --> 00:12:55,150
all we have to do is now supply to order

00:12:52,510 --> 00:12:57,670
now specify an ordered suite and we have

00:12:55,150 --> 00:13:00,460
three sinks in all spatial dimension

00:12:57,670 --> 00:13:03,190
only little transformation with the

00:13:00,460 --> 00:13:06,280
source code that we had to do is pull

00:13:03,190 --> 00:13:09,100
the eye out of these routines which was

00:13:06,280 --> 00:13:12,160
hidden there before and it kind of trips

00:13:09,100 --> 00:13:15,640
over any vectorization by the way

00:13:12,160 --> 00:13:18,040
just as a side note so we had to pull

00:13:15,640 --> 00:13:20,680
the eye out which was not difficult even

00:13:18,040 --> 00:13:22,840
I could have done that but you know so

00:13:20,680 --> 00:13:27,430
it's it's not so easy to optimize for

00:13:22,840 --> 00:13:29,650
the compiler so now I show some

00:13:27,430 --> 00:13:32,640
performance results that just give some

00:13:29,650 --> 00:13:35,500
some information about our evaluation

00:13:32,640 --> 00:13:38,730
environment basically we are using a C

00:13:35,500 --> 00:13:41,920
on board well and to send okay an L note

00:13:38,730 --> 00:13:44,410
you know just because we wanted to see

00:13:41,920 --> 00:13:47,560
if an architecture as an impact on that

00:13:44,410 --> 00:13:50,290
at all different architectures we also

00:13:47,560 --> 00:13:54,070
compared to fine compilers to new and to

00:13:50,290 --> 00:13:58,810
Intel compiler and we used an internal

00:13:54,070 --> 00:14:02,940
profiling tool licensed for NASA for

00:13:58,810 --> 00:14:05,560
profiling and also de to power

00:14:02,940 --> 00:14:08,170
performance analysis tool which is

00:14:05,560 --> 00:14:12,460
developed at a barcelona supercomputer

00:14:08,170 --> 00:14:16,090
center and open source okay here is the

00:14:12,460 --> 00:14:18,960
data here is the data for all these us

00:14:16,090 --> 00:14:22,810
to performance for all six

00:14:18,960 --> 00:14:24,810
implementations for all six

00:14:22,810 --> 00:14:28,300
implementations I hope that the

00:14:24,810 --> 00:14:32,620
nomenclature is somewhat intuitive so

00:14:28,300 --> 00:14:36,720
it's like it's like pipe hyperplane two

00:14:32,620 --> 00:14:39,550
hyperplanes we and it is a manual and

00:14:36,720 --> 00:14:42,970
and a do cross implementation for each

00:14:39,550 --> 00:14:46,210
of them so and the most I will summarize

00:14:42,970 --> 00:14:48,520
you can stare the data and you know look

00:14:46,210 --> 00:14:50,740
at the colors and but you know to make

00:14:48,520 --> 00:14:54,160
it simpler for you I will just summarize

00:14:50,740 --> 00:14:56,920
the most important or drawn findings

00:14:54,160 --> 00:14:59,890
that you can conclude from that and the

00:14:56,920 --> 00:15:03,210
most important for us was for all for

00:14:59,890 --> 00:15:07,410
all three ways for all three different

00:15:03,210 --> 00:15:10,270
algorithms to do cross way and a manual

00:15:07,410 --> 00:15:13,780
implementation basically have like very

00:15:10,270 --> 00:15:16,990
similar timings which means for us you

00:15:13,780 --> 00:15:18,640
are you have to the ease of use with the

00:15:16,990 --> 00:15:22,120
two cross you are not sacrificing

00:15:18,640 --> 00:15:25,900
performance very nice we were so happy

00:15:22,120 --> 00:15:30,580
to see that or we can as a minor bye

00:15:25,900 --> 00:15:33,820
see insights that we gain from here also

00:15:30,580 --> 00:15:36,339
that the hyperplane to do cause

00:15:33,820 --> 00:15:39,190
hyperplane slightly better than Emanuel

00:15:36,339 --> 00:15:41,529
which is not too surprising and still

00:15:39,190 --> 00:15:43,990
scheduling somehow to front and then

00:15:41,529 --> 00:15:45,850
proof the architecture didn't really

00:15:43,990 --> 00:15:48,339
matter it's being observed the same

00:15:45,850 --> 00:15:52,180
behavior of vaudeville as well as on K

00:15:48,339 --> 00:15:54,670
and L and yeah in general you know we

00:15:52,180 --> 00:15:57,760
are not really into comparing these

00:15:54,670 --> 00:16:01,230
algorithms for us it's just important

00:15:57,760 --> 00:16:04,510
that manual or two across is the same

00:16:01,230 --> 00:16:07,960
I've there there's the long long papers

00:16:04,510 --> 00:16:10,630
written about why hyperplanes performs

00:16:07,960 --> 00:16:12,880
better and pipelined in most cases I

00:16:10,630 --> 00:16:15,550
should say that his timings were

00:16:12,880 --> 00:16:19,390
obtained for the Class C benchmark which

00:16:15,550 --> 00:16:21,670
has size 162 so good

00:16:19,390 --> 00:16:25,480
here's some performance data just to

00:16:21,670 --> 00:16:29,589
hammer it in even more we used our Pisco

00:16:25,480 --> 00:16:32,290
profiling tool and I showed a time here

00:16:29,589 --> 00:16:35,170
for the most time consuming sweat for

00:16:32,290 --> 00:16:38,320
the pipeline for the pipeline version

00:16:35,170 --> 00:16:41,050
and the tool allows me to build a

00:16:38,320 --> 00:16:44,320
vertical some and just add up certain

00:16:41,050 --> 00:16:48,010
routines in interest so I was interested

00:16:44,320 --> 00:16:50,800
in synchronization so I added up I added

00:16:48,010 --> 00:16:54,490
up to timings for the manual soon

00:16:50,800 --> 00:16:57,790
Clifton's and quite routines and and and

00:16:54,490 --> 00:17:01,089
a partial sums indicated here and then

00:16:57,790 --> 00:17:05,980
look at us you know I mean at times in

00:17:01,089 --> 00:17:08,679
in the new compiler one time for do

00:17:05,980 --> 00:17:11,829
across for for openmp do across weight

00:17:08,679 --> 00:17:16,059
and openmp to across post they are

00:17:11,829 --> 00:17:21,670
basically very very similar so so nice

00:17:16,059 --> 00:17:25,000
what was just nice to see we also took a

00:17:21,670 --> 00:17:28,660
pair of our profile like a timeline well

00:17:25,000 --> 00:17:31,510
but you know but you'll see here the the

00:17:28,660 --> 00:17:34,600
horizontal axis is the time the vertical

00:17:31,510 --> 00:17:37,600
axis is the thread ID or it's just for

00:17:34,600 --> 00:17:38,460
class a on a threads and what I want to

00:17:37,600 --> 00:17:41,610
show with

00:17:38,460 --> 00:17:45,540
but this picture is so we see the lowers

00:17:41,610 --> 00:17:48,960
over here BLTs beauteous here and what

00:17:45,540 --> 00:17:53,370
we clearly recognize or pipeline here

00:17:48,960 --> 00:17:56,610
okay so clearly recognizable so the same

00:17:53,370 --> 00:18:00,090
things going on or in either way except

00:17:56,610 --> 00:18:02,730
with two across it's easier so now then

00:18:00,090 --> 00:18:05,070
the other thing I've mentioned to work

00:18:02,730 --> 00:18:08,250
scheduling and that it was like

00:18:05,070 --> 00:18:11,640
essential for duo cross hyperplane to

00:18:08,250 --> 00:18:14,460
use a chunk size of one now

00:18:11,640 --> 00:18:17,640
so we've I want to show some some data

00:18:14,460 --> 00:18:20,820
for this here so this just shows the

00:18:17,640 --> 00:18:24,930
data on K and L because I can use more

00:18:20,820 --> 00:18:28,950
sweats they're done on K and L we look

00:18:24,930 --> 00:18:32,970
we compared static dynamic scheduling

00:18:28,950 --> 00:18:35,930
with chunk size one and just just a

00:18:32,970 --> 00:18:40,260
default which would be static with

00:18:35,930 --> 00:18:43,770
default chunk size and as you see the

00:18:40,260 --> 00:18:47,760
static with default chunk size which is

00:18:43,770 --> 00:18:51,300
chopped just chopping up the iteration

00:18:47,760 --> 00:18:55,890
space into about equal sizes for each

00:18:51,300 --> 00:18:59,310
thread very very poor very very poor

00:18:55,890 --> 00:19:03,900
compared to everybody else but but what

00:18:59,310 --> 00:19:06,630
you see is that 462 threads which I can

00:19:03,900 --> 00:19:08,540
use on the on the K and L you know hyper

00:19:06,630 --> 00:19:13,920
threading no no problem

00:19:08,540 --> 00:19:15,630
look how it jumps up now why is that for

00:19:13,920 --> 00:19:18,930
those of you who've seen the first

00:19:15,630 --> 00:19:26,370
slides and remember what the size of the

00:19:18,930 --> 00:19:31,640
class series 162 162 threads chunk size

00:19:26,370 --> 00:19:34,140
one I I haven't really thoroughly

00:19:31,640 --> 00:19:38,190
investigated it but it's an interesting

00:19:34,140 --> 00:19:41,220
coincidence is Matt so so it is my

00:19:38,190 --> 00:19:43,830
belief that for if anything that has a

00:19:41,220 --> 00:19:46,260
chunk size greater and one makes the

00:19:43,830 --> 00:19:50,340
glue compile they do something really

00:19:46,260 --> 00:19:51,260
weird you know it completely gets out of

00:19:50,340 --> 00:19:54,140
sync

00:19:51,260 --> 00:19:56,780
to speak I mean you see enormous time

00:19:54,140 --> 00:19:59,750
spent in synchronization as soon as it

00:19:56,780 --> 00:20:04,390
is it's just a little bit bigger than

00:19:59,750 --> 00:20:07,880
one one of them even just one of them so

00:20:04,390 --> 00:20:09,890
I'm not going to track down anything in

00:20:07,880 --> 00:20:13,220
in a clue compiler

00:20:09,890 --> 00:20:16,700
however you may ask the question well is

00:20:13,220 --> 00:20:19,400
this like AG new compiler bugger out

00:20:16,700 --> 00:20:21,970
efficiency or what and so we saw Toby

00:20:19,400 --> 00:20:24,800
compare different compilers we try to

00:20:21,970 --> 00:20:28,990
honestly we really tried

00:20:24,800 --> 00:20:33,200
so we also used the Intel compiler

00:20:28,990 --> 00:20:36,710
version 17 as well as version 18 and

00:20:33,200 --> 00:20:39,800
Allah it already trips over its sneakers

00:20:36,710 --> 00:20:47,590
for the for the for the pipeline

00:20:39,800 --> 00:20:50,090
execution the to do across pipeline and

00:20:47,590 --> 00:20:52,220
even worse for the for the two

00:20:50,090 --> 00:20:54,590
dimensional hyper plane I mean I'd I

00:20:52,220 --> 00:20:56,630
don't even know it didn't even like

00:20:54,590 --> 00:21:00,260
would it let it ride it just spends

00:20:56,630 --> 00:21:02,060
enormous time in synchronization and for

00:21:00,260 --> 00:21:04,460
the Class C we didn't on top of

00:21:02,060 --> 00:21:08,990
everything also got the occasional race

00:21:04,460 --> 00:21:11,990
condition so some not not right which is

00:21:08,990 --> 00:21:14,060
a pity because for other or for the idea

00:21:11,990 --> 00:21:16,940
for the manual implementations to

00:21:14,060 --> 00:21:19,280
performance was good performance is good

00:21:16,940 --> 00:21:21,860
for the intercom values of would Willie

00:21:19,280 --> 00:21:23,480
be nice we've reported about they're

00:21:21,860 --> 00:21:27,080
working on it so it will be very

00:21:23,480 --> 00:21:30,950
exciting to see what it does when a bugs

00:21:27,080 --> 00:21:34,070
fixed and but but what's also kind of

00:21:30,950 --> 00:21:36,890
pleasurable to see to see is that new

00:21:34,070 --> 00:21:39,350
compiler gets pretty much the same proof

00:21:36,890 --> 00:21:43,100
similar performance to Intel good

00:21:39,350 --> 00:21:46,580
nice nice nice so already summary and

00:21:43,100 --> 00:21:50,540
conclusion so in summary I can say or we

00:21:46,580 --> 00:21:53,240
think that open and P 4.5 adding this to

00:21:50,540 --> 00:21:57,170
cross support was a good thing at least

00:21:53,240 --> 00:21:59,950
in our observation it provides ease of

00:21:57,170 --> 00:22:03,830
use of programming while not sacrificing

00:21:59,950 --> 00:22:04,999
performance as I've mentioned before the

00:22:03,830 --> 00:22:08,139
drawbacks are

00:22:04,999 --> 00:22:11,359
is that debugging is kind of hard

00:22:08,139 --> 00:22:14,329
because yeah debugging is hard

00:22:11,359 --> 00:22:16,539
performance analysis is hard you know so

00:22:14,329 --> 00:22:19,069
it took some trial and error and

00:22:16,539 --> 00:22:22,939
experimentation to find out that we

00:22:19,069 --> 00:22:24,909
should use a chunk size one but I mean

00:22:22,939 --> 00:22:28,519
that Sun you know that's that's just

00:22:24,909 --> 00:22:31,129
that's just a matter of life the easier

00:22:28,519 --> 00:22:36,679
it gets the more is left to the compiler

00:22:31,129 --> 00:22:38,419
the more hidden from the user yeah the

00:22:36,679 --> 00:22:41,449
more difficult it gets

00:22:38,419 --> 00:22:45,799
to track it down by the user

00:22:41,449 --> 00:22:48,079
because yeah and and what eyes finest

00:22:45,799 --> 00:22:51,979
good news is that the new compiler

00:22:48,079 --> 00:22:55,789
provides such such good support for that

00:22:51,979 --> 00:23:03,109
yields acceptable results so that's

00:22:55,789 --> 00:23:08,709
that's that pom-pom thank you thank you

00:23:03,109 --> 00:23:08,709

YouTube URL: https://www.youtube.com/watch?v=sShkH9VVQh0


