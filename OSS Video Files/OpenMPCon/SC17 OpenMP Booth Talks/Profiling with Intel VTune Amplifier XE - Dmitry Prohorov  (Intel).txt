Title: Profiling with Intel VTune Amplifier XE - Dmitry Prohorov  (Intel)
Publication date: 2017-11-23
Playlist: SC17 OpenMP Booth Talks
Description: 
	SC 17 OpenMP booth talk - November 2017, Denver, CO.
Slides at http://www.openmp.org/resources/openmp-presentations/sc17-booth-talks
Captions: 
	00:00:02,120 --> 00:00:10,260
okay so my name is Misha procurve and

00:00:06,779 --> 00:00:13,049
I'm from vegan amplifier development

00:00:10,260 --> 00:00:17,820
team B tuna is a pretty famous profiler

00:00:13,049 --> 00:00:19,590
for performance analysis software

00:00:17,820 --> 00:00:22,380
application performance analysis and

00:00:19,590 --> 00:00:26,279
it's used by quite live in different

00:00:22,380 --> 00:00:29,250
application domains from HPC to embedded

00:00:26,279 --> 00:00:31,349
and my responsibility in the team to to

00:00:29,250 --> 00:00:42,410
make it relevant for HPC performance

00:00:31,349 --> 00:00:42,410
tuning and actually okay

00:00:43,110 --> 00:00:53,460
well yeah when we started this work we

00:00:51,059 --> 00:00:57,110
tried to think from from a user from

00:00:53,460 --> 00:01:00,809
application developer perspective so

00:00:57,110 --> 00:01:04,860
what can be what can they be interested

00:01:00,809 --> 00:01:07,110
in right and mostly like when they

00:01:04,860 --> 00:01:09,509
develop the application look introducing

00:01:07,110 --> 00:01:12,540
paralyzation they put pragmas and

00:01:09,509 --> 00:01:14,640
measure performance and very often it's

00:01:12,540 --> 00:01:19,800
not as expected right it's not linear

00:01:14,640 --> 00:01:21,600
now that stuff and mostly the questions

00:01:19,800 --> 00:01:24,800
are why my performance is not as

00:01:21,600 --> 00:01:27,330
expected of my parallel version right or

00:01:24,800 --> 00:01:30,090
if this is a key for a particular

00:01:27,330 --> 00:01:31,860
hardware and I'm moving my application

00:01:30,090 --> 00:01:33,240
today for example to a hardware with

00:01:31,860 --> 00:01:37,080
more number of course

00:01:33,240 --> 00:01:39,270
so why it's not scaling and you know

00:01:37,080 --> 00:01:41,280
that we tried you know to decompose

00:01:39,270 --> 00:01:46,130
these questions in terms of opening

00:01:41,280 --> 00:01:49,319
people so first it's important to know

00:01:46,130 --> 00:01:51,420
so what's the fraction of zero time when

00:01:49,319 --> 00:01:54,000
you paralyzed with openmp right because

00:01:51,420 --> 00:01:56,670
zero time will limit scalability of your

00:01:54,000 --> 00:02:00,750
application further and on particular

00:01:56,670 --> 00:02:02,759
system and further and what is the

00:02:00,750 --> 00:02:09,149
efficiency politicians of your peril

00:02:02,759 --> 00:02:10,890
part what so theoretical game can I have

00:02:09,149 --> 00:02:14,400
for example if you invest in a

00:02:10,890 --> 00:02:18,000
performance tuning of this parallel part

00:02:14,400 --> 00:02:20,550
of my work right and if I introduced

00:02:18,000 --> 00:02:22,890
like several lexical regions so what

00:02:20,550 --> 00:02:25,260
region is less efficient

00:02:22,890 --> 00:02:27,030
how much theoretical game I have for a

00:02:25,260 --> 00:02:29,819
particular region and what I can do with

00:02:27,030 --> 00:02:32,819
this so I have some clauses like for

00:02:29,819 --> 00:02:36,180
example scheduling I don't know with

00:02:32,819 --> 00:02:37,620
some granularity I might collapse my

00:02:36,180 --> 00:02:37,800
loops and all that stuff but what can I

00:02:37,620 --> 00:02:43,349
do

00:02:37,800 --> 00:02:46,200
and if profiler is not OpenMP aware so

00:02:43,349 --> 00:02:48,629
openmp unaware so usually you are passed

00:02:46,200 --> 00:02:51,060
luis this so this is how you see like

00:02:48,629 --> 00:02:54,210
hotspot analysis in region when it was

00:02:51,060 --> 00:02:56,580
opening p anywhere like you can see hot

00:02:54,210 --> 00:02:57,080
spots with all that stacks with all that

00:02:56,580 --> 00:03:00,350
open

00:02:57,080 --> 00:03:01,970
internals and you might not be able to

00:03:00,350 --> 00:03:05,750
recognize to answer to you to the

00:03:01,970 --> 00:03:08,740
questions we just articulated right so

00:03:05,750 --> 00:03:08,740
what we did envision

00:03:11,780 --> 00:03:17,590
so this is a typical summer review when

00:03:14,750 --> 00:03:21,590
you profile openmp application feature

00:03:17,590 --> 00:03:24,470
so you have clear articulation of cereal

00:03:21,590 --> 00:03:30,170
time fraction with percentage of elapsed

00:03:24,470 --> 00:03:33,970
time we have like parallel time and how

00:03:30,170 --> 00:03:33,970
much potential gain you can actually

00:03:37,000 --> 00:03:42,700
have in your peril like in your

00:03:40,370 --> 00:03:46,670
parallelization will opening people and

00:03:42,700 --> 00:03:49,430
the breakdown of this theoretical gain

00:03:46,670 --> 00:03:52,870
by opening p construct lexical construct

00:03:49,430 --> 00:03:54,920
that you introduced in your code so

00:03:52,870 --> 00:03:57,050
looking at this picture you can see

00:03:54,920 --> 00:03:59,600
pretty clear what's the fraction of

00:03:57,050 --> 00:04:01,340
serial code and if you can benefit from

00:03:59,600 --> 00:04:04,790
further tuning of your parallel part of

00:04:01,340 --> 00:04:06,830
the copy of your code probably else is

00:04:04,790 --> 00:04:08,540
the key here and here and you will need

00:04:06,830 --> 00:04:10,340
to look at for example architectural

00:04:08,540 --> 00:04:17,419
efficiency or something something else

00:04:10,340 --> 00:04:21,970
but not in in like opening positions ok

00:04:17,419 --> 00:04:24,530
let's look at the metrics actually so

00:04:21,970 --> 00:04:27,200
this is like a instance of a parallel

00:04:24,530 --> 00:04:29,720
region and here in green you might have

00:04:27,200 --> 00:04:32,479
efficient time the time that is actually

00:04:29,720 --> 00:04:35,780
spent in your application code doing

00:04:32,479 --> 00:04:37,280
useful work you can have imbalance so

00:04:35,780 --> 00:04:40,370
where for example worker threads can

00:04:37,280 --> 00:04:41,780
spin waiting for other threads on a

00:04:40,370 --> 00:04:44,570
barrier construct read but they do

00:04:41,780 --> 00:04:48,200
nothing so they just burn in CPU without

00:04:44,570 --> 00:04:49,520
any useful work you might have inside

00:04:48,200 --> 00:04:51,320
the parallel region instance you might

00:04:49,520 --> 00:04:54,530
have other inefficiencies like if you do

00:04:51,320 --> 00:04:57,470
locking you might have like spin lobster

00:04:54,530 --> 00:05:02,060
right again so not useful work you might

00:04:57,470 --> 00:05:04,610
have for example scheduling if you do

00:05:02,060 --> 00:05:07,370
some dynamic scheduling to eliminate

00:05:04,610 --> 00:05:10,760
opening p balance or then scheduling or

00:05:07,370 --> 00:05:12,350
also is not for free you might have for

00:05:10,760 --> 00:05:14,780
like if you have a lot of peril rich

00:05:12,350 --> 00:05:17,030
region small instances like microsecond

00:05:14,780 --> 00:05:19,280
instances you might have overhead for

00:05:17,030 --> 00:05:21,919
work for can write for each of each of

00:05:19,280 --> 00:05:23,440
them the instance might use atomic

00:05:21,919 --> 00:05:25,450
operations that are no so

00:05:23,440 --> 00:05:28,570
no they are lighter them like critical

00:05:25,450 --> 00:05:31,600
sections but they are not free and what

00:05:28,570 --> 00:05:33,130
we can do we can calculate this and then

00:05:31,600 --> 00:05:36,010
normalize in this by number of threads

00:05:33,130 --> 00:05:39,550
to show the gain in terms of elapsed

00:05:36,010 --> 00:05:43,720
time because because if you if we like

00:05:39,550 --> 00:05:44,710
show metrics in terms of CPU time it

00:05:43,720 --> 00:05:45,820
might be difficult you know to

00:05:44,710 --> 00:05:47,950
understand the performance in the

00:05:45,820 --> 00:05:49,720
elapsed time for example on many core

00:05:47,950 --> 00:05:53,080
systems when you might end up with more

00:05:49,720 --> 00:05:58,030
than one 200 threads you know what is

00:05:53,080 --> 00:06:00,220
like imbalance of like two seconds so if

00:05:58,030 --> 00:06:05,290
you eliminate this you might have like

00:06:00,220 --> 00:06:07,810
just zero point zero like two seconds of

00:06:05,290 --> 00:06:10,300
the benefit if you have just four cores

00:06:07,810 --> 00:06:12,070
you might have 0.5 seconds of benefit

00:06:10,300 --> 00:06:14,470
this is different right so it's

00:06:12,070 --> 00:06:17,440
important to to show the metrics in the

00:06:14,470 --> 00:06:20,770
elapsed time and so here if you're not

00:06:17,440 --> 00:06:23,290
normal as them so we can show the actual

00:06:20,770 --> 00:06:25,690
idea at the time of impact in efficient

00:06:23,290 --> 00:06:28,320
time in terms of elapsed time and

00:06:25,690 --> 00:06:32,169
classify it by different categories

00:06:28,320 --> 00:06:34,000
because Union strategy will depend on

00:06:32,169 --> 00:06:36,610
what particular inefficiency you have

00:06:34,000 --> 00:06:38,710
but for example you could have locks you

00:06:36,610 --> 00:06:40,690
you might want to eliminate locks with

00:06:38,710 --> 00:06:44,190
the reduction doing reduction right for

00:06:40,690 --> 00:06:48,870
example or you have scheduling you might

00:06:44,190 --> 00:06:53,919
you might play with chunking to make

00:06:48,870 --> 00:06:56,169
like iteration in iterations like more

00:06:53,919 --> 00:06:58,510
porous grain and eliminate scaled

00:06:56,169 --> 00:07:02,190
another head if you do a lot of work

00:06:58,510 --> 00:07:04,630
forking so probably you need to look at

00:07:02,190 --> 00:07:06,160
you know moving from like parallel

00:07:04,630 --> 00:07:08,980
regions to working work sharing

00:07:06,160 --> 00:07:11,530
constructs from open in parallel for to

00:07:08,980 --> 00:07:18,310
OMP parallel and inside or mp4

00:07:11,530 --> 00:07:21,630
constructs and and so on so in region we

00:07:18,310 --> 00:07:25,980
use tracing so currently we support

00:07:21,630 --> 00:07:31,180
sadistic know this methodology is

00:07:25,980 --> 00:07:32,770
supported by into OpenMP runtime we do

00:07:31,180 --> 00:07:35,650
some tracing but we do trace you know

00:07:32,770 --> 00:07:36,530
for global points forks joins barriers

00:07:35,650 --> 00:07:37,960
we

00:07:36,530 --> 00:07:39,920
try to eliminate per thread

00:07:37,960 --> 00:07:43,910
instrumentation because it might hurt

00:07:39,920 --> 00:07:45,950
performance overhead especially on many

00:07:43,910 --> 00:07:48,880
core systems where you can end up with

00:07:45,950 --> 00:07:54,250
more than 200 threads for example

00:07:48,880 --> 00:07:57,530
actually we're looking at OMP team

00:07:54,250 --> 00:08:00,500
interface that was just articulated in

00:07:57,530 --> 00:08:05,620
the previous talk and actually we are

00:08:00,500 --> 00:08:09,970
working with John Miller Nero Cooley

00:08:05,620 --> 00:08:14,240
actually two tributes to enhance it with

00:08:09,970 --> 00:08:15,740
some with some codecs to eliminate or

00:08:14,240 --> 00:08:18,800
threat portrait

00:08:15,740 --> 00:08:19,940
instrumentation to get important

00:08:18,800 --> 00:08:23,570
performance metrics like for example

00:08:19,940 --> 00:08:25,550
imbalance it's in the process and some

00:08:23,570 --> 00:08:27,980
statistics we are based on sampling

00:08:25,550 --> 00:08:30,470
technology because like for example to

00:08:27,980 --> 00:08:32,810
measure scheduled overhead you know if

00:08:30,470 --> 00:08:36,229
you want tray scheduler you will hurt it

00:08:32,810 --> 00:08:38,180
and the performance of and like for

00:08:36,229 --> 00:08:41,210
example the web stem of your application

00:08:38,180 --> 00:08:42,349
of the profiling might like will be

00:08:41,210 --> 00:08:46,430
increased in several times

00:08:42,349 --> 00:08:47,180
so we mix we mix our tracing over global

00:08:46,430 --> 00:08:49,070
points like

00:08:47,180 --> 00:08:51,970
fork and joints and barriers with

00:08:49,070 --> 00:08:51,970
sampling information

00:08:53,800 --> 00:09:03,189
okay envision we have from so called and

00:08:59,920 --> 00:09:05,259
the oldest types that are actually

00:09:03,189 --> 00:09:07,749
focused on particular performance

00:09:05,259 --> 00:09:10,089
aspects by focus on hot spots mostly for

00:09:07,749 --> 00:09:12,040
algorithmic analysis we have junior

00:09:10,089 --> 00:09:15,459
exploration for mock micro architectural

00:09:12,040 --> 00:09:17,769
issues we have memory analysis to see

00:09:15,459 --> 00:09:18,879
efficiency of memory accesses and we

00:09:17,769 --> 00:09:21,339
introduced age PC performance

00:09:18,879 --> 00:09:25,209
characterization analysis that you can

00:09:21,339 --> 00:09:29,079
choose from the GUI or you can use in

00:09:25,209 --> 00:09:31,360
command line and after you know running

00:09:29,079 --> 00:09:35,739
the application under this analysis you

00:09:31,360 --> 00:09:40,209
will have the you will have the summary

00:09:35,739 --> 00:09:41,860
summary page that with like CPU

00:09:40,209 --> 00:09:44,410
utilization section that mostly will

00:09:41,860 --> 00:09:46,059
show you the year the opening P analysis

00:09:44,410 --> 00:09:48,819
so here again so you'll see you will

00:09:46,059 --> 00:09:51,339
look at 0 time at parallel region time

00:09:48,819 --> 00:09:54,429
and the potential gain that you can have

00:09:51,339 --> 00:09:56,519
like invest into this tuning like for

00:09:54,429 --> 00:09:58,720
example here you have like 17.6 a

00:09:56,519 --> 00:10:01,029
percent of theoretical gain from elapsed

00:09:58,720 --> 00:10:03,939
time so if you think that it's worth to

00:10:01,029 --> 00:10:06,730
look at this and you can look at

00:10:03,939 --> 00:10:08,110
particular lexical constructs actually

00:10:06,730 --> 00:10:11,619
that you are introduced and read like

00:10:08,110 --> 00:10:15,610
parallel regions to see what concept is

00:10:11,619 --> 00:10:19,110
more inefficient to look at further and

00:10:15,610 --> 00:10:21,879
then in more detail to you like grid you

00:10:19,110 --> 00:10:23,829
so actually yeah if you press upon the

00:10:21,879 --> 00:10:27,790
parallel region in a summer you will go

00:10:23,829 --> 00:10:29,949
to grid you and here you can see like

00:10:27,790 --> 00:10:33,490
parallel regions and barrier constructs

00:10:29,949 --> 00:10:36,399
you can elapse expanding my barrier

00:10:33,490 --> 00:10:38,470
constructs and here you can see the

00:10:36,399 --> 00:10:40,389
rules that are like classified by

00:10:38,470 --> 00:10:43,779
particular inefficiencies like imbalance

00:10:40,389 --> 00:10:47,980
lock contention like work fork in

00:10:43,779 --> 00:10:51,819
scheduling Atomics and so on and here we

00:10:47,980 --> 00:10:54,269
have CPU time normalized by by number of

00:10:51,819 --> 00:10:57,989
threads so it's like in the elapsed time

00:10:54,269 --> 00:11:01,839
for example here you have like three

00:10:57,989 --> 00:11:05,350
like four four seconds over imbalance

00:11:01,839 --> 00:11:07,089
like in terms of elapsed time if the

00:11:05,350 --> 00:11:10,519
imbalance time is pretty

00:11:07,089 --> 00:11:11,839
big for this barrier contract so

00:11:10,519 --> 00:11:14,060
probably you need to look at dynamic

00:11:11,839 --> 00:11:16,040
scaling of course cautiously because it

00:11:14,060 --> 00:11:19,940
might be not so close friend Laurette

00:11:16,040 --> 00:11:24,370
that stated scheduling but in some cases

00:11:19,940 --> 00:11:27,440
it might work and for example here I

00:11:24,370 --> 00:11:29,060
used and yeah and you can look at some

00:11:27,440 --> 00:11:33,949
new Patra bution skier like static

00:11:29,060 --> 00:11:37,339
number like loop chunk and the loop

00:11:33,949 --> 00:11:38,660
iteration count and for example here I

00:11:37,339 --> 00:11:41,209
used bike dynamic scheduling

00:11:38,660 --> 00:11:44,389
straightforward was default chunk that

00:11:41,209 --> 00:11:47,440
is one and the next thing right after

00:11:44,389 --> 00:11:50,029
after up like next run I see that okay

00:11:47,440 --> 00:11:53,440
imbalance right now is vanished right

00:11:50,029 --> 00:11:56,690
it's good but skidded on your head is

00:11:53,440 --> 00:11:59,660
much is there worse right

00:11:56,690 --> 00:12:01,910
and actually it's not just kiddin

00:11:59,660 --> 00:12:03,889
overhead since a dynamic scheduling is

00:12:01,910 --> 00:12:06,740
less cash random the elapsed time will

00:12:03,889 --> 00:12:09,980
be even worse so then you need to play

00:12:06,740 --> 00:12:11,899
with chunking you can see the like hoop

00:12:09,980 --> 00:12:14,510
chunking is one like dynamic one so

00:12:11,899 --> 00:12:16,850
interplay with chunking to have course

00:12:14,510 --> 00:12:22,579
great more coarse grain work but to

00:12:16,850 --> 00:12:26,149
eliminate scaled another head and

00:12:22,579 --> 00:12:28,579
actually also recently where that

00:12:26,149 --> 00:12:31,010
ability you know to see serial hotspots

00:12:28,579 --> 00:12:32,779
so these are hotspots these are like

00:12:31,010 --> 00:12:35,389
functionality that is done outside of

00:12:32,779 --> 00:12:37,610
parallel regions sometimes you can not

00:12:35,389 --> 00:12:39,709
eliminate this but sometimes probably

00:12:37,610 --> 00:12:43,880
you can look at opportunities to

00:12:39,709 --> 00:12:46,550
paralyze more and here on the set on

00:12:43,880 --> 00:12:51,110
some review you can see like top serial

00:12:46,550 --> 00:12:53,540
functions right away and function slash

00:12:51,110 --> 00:12:55,339
loops and probably you will like for

00:12:53,540 --> 00:12:57,949
example here here I have like minifee

00:12:55,339 --> 00:12:59,649
application and I have a loop so

00:12:57,949 --> 00:13:02,300
probably this is this just a like a

00:12:59,649 --> 00:13:05,470
initialization phase but still this loop

00:13:02,300 --> 00:13:08,180
up like occupy this particular like

00:13:05,470 --> 00:13:10,100
amount of application time right and

00:13:08,180 --> 00:13:13,339
probably you need to you you you have

00:13:10,100 --> 00:13:16,339
ability to paralyze it also you can see

00:13:13,339 --> 00:13:18,199
more details in and grid view if you

00:13:16,339 --> 00:13:19,400
expand serial time and master thread so

00:13:18,199 --> 00:13:21,650
the work is done

00:13:19,400 --> 00:13:23,450
see the work is done in mustard red you

00:13:21,650 --> 00:13:25,520
can see like more like functions here

00:13:23,450 --> 00:13:29,210
not just top five but more and with some

00:13:25,520 --> 00:13:33,890
more matrix here and if you want for

00:13:29,210 --> 00:13:36,680
example to eliminate the warmup time you

00:13:33,890 --> 00:13:39,470
can in grid view we have also timeline

00:13:36,680 --> 00:13:44,330
you can just filter by a timeline region

00:13:39,470 --> 00:13:46,160
and see the this this matrix up or for

00:13:44,330 --> 00:13:52,610
example for the computational part of

00:13:46,160 --> 00:13:52,820
your application filter it by okay what

00:13:52,610 --> 00:13:57,110
else

00:13:52,820 --> 00:13:59,830
actually we also have a we call it

00:13:57,110 --> 00:14:03,040
scalable representation of a timeline

00:13:59,830 --> 00:14:06,470
for example here I have a picture with

00:14:03,040 --> 00:14:14,260
application that is run on Intel Xeon

00:14:06,470 --> 00:14:17,120
Phi machine node with like 288 Reds and

00:14:14,260 --> 00:14:19,550
the green the green part this is like

00:14:17,120 --> 00:14:22,190
useful work this is the work that is

00:14:19,550 --> 00:14:25,100
done in under it like in application and

00:14:22,190 --> 00:14:27,620
the black holes means that there was no

00:14:25,100 --> 00:14:32,060
actually useful over there it might be

00:14:27,620 --> 00:14:36,140
speeding in on barriers or partner for

00:14:32,060 --> 00:14:41,110
example dogs any and on the ruler you

00:14:36,140 --> 00:14:43,820
also will have her like the region marks

00:14:41,110 --> 00:14:46,520
that correspond to a particular instance

00:14:43,820 --> 00:14:48,920
of openmp construction construct so if

00:14:46,520 --> 00:14:53,600
you zoom in so you will see the this

00:14:48,920 --> 00:14:56,870
region marks and mostly this you is just

00:14:53,600 --> 00:15:01,010
do to have a birthday view or you can

00:14:56,870 --> 00:15:03,380
expand it zoom it to see like some

00:15:01,010 --> 00:15:06,050
patterns of your application behavior so

00:15:03,380 --> 00:15:09,350
for example if you if you have a sum

00:15:06,050 --> 00:15:10,880
like imbalance on a barrier so you will

00:15:09,350 --> 00:15:13,880
see at some point you will see like

00:15:10,880 --> 00:15:16,010
black black hole execution here and

00:15:13,880 --> 00:15:18,320
probe view you will recognize it

00:15:16,010 --> 00:15:21,290
recognize the patterns but this is just

00:15:18,320 --> 00:15:23,990
a I think complimentary review mostly

00:15:21,290 --> 00:15:26,170
since application can invoke Perl

00:15:23,990 --> 00:15:28,490
constructs millions of times right

00:15:26,170 --> 00:15:30,520
sometimes it's not very efficient to

00:15:28,490 --> 00:15:33,790
look at particular instance on time

00:15:30,520 --> 00:15:35,590
so rather probably you will mum you

00:15:33,790 --> 00:15:38,260
might want to look at aggregated metrics

00:15:35,590 --> 00:15:40,300
by a lexical construct right because if

00:15:38,260 --> 00:15:43,840
you put a lexical construct you can

00:15:40,300 --> 00:15:46,030
tweak my clauses like for the whole runs

00:15:43,840 --> 00:15:49,410
right for the whole run rather than you

00:15:46,030 --> 00:15:55,840
know children for particular instance

00:15:49,410 --> 00:15:59,140
okay and actually also we have ability

00:15:55,840 --> 00:16:01,750
if you like double-click on a particular

00:15:59,140 --> 00:16:04,240
region name in the grid then you can

00:16:01,750 --> 00:16:06,790
drill down to source you and then

00:16:04,240 --> 00:16:09,520
ditchin will show you the your payroll

00:16:06,790 --> 00:16:12,550
construct position and upon the pragma

00:16:09,520 --> 00:16:15,880
here and with some metrics that are like

00:16:12,550 --> 00:16:18,580
for example cpu time by by the source

00:16:15,880 --> 00:16:21,070
lines that were executed in this

00:16:18,580 --> 00:16:23,350
particular region this is just a I don't

00:16:21,070 --> 00:16:26,170
know quick navigation and actually if

00:16:23,350 --> 00:16:28,530
you double-click further some like

00:16:26,170 --> 00:16:33,340
editor will be invoked and you can even

00:16:28,530 --> 00:16:34,990
for example if an editor register it in

00:16:33,340 --> 00:16:37,120
on Linux system so it will be

00:16:34,990 --> 00:16:39,490
automatically picked up and you will

00:16:37,120 --> 00:16:41,950
have this source there you can change

00:16:39,490 --> 00:16:50,470
the source and recompile even just in

00:16:41,950 --> 00:16:52,870
the tool I mean in the to flow okay let

00:16:50,470 --> 00:16:54,930
me summarize and yeah

00:16:52,870 --> 00:16:58,720
before summarizing also let me say that

00:16:54,930 --> 00:17:01,120
actually we apply the same concept for

00:16:58,720 --> 00:17:04,839
hybrid applications in pay plus opening

00:17:01,120 --> 00:17:09,280
theme the metrics are the same but with

00:17:04,839 --> 00:17:12,520
him for imp I we can recognize also you

00:17:09,280 --> 00:17:15,400
know impair spilling through sampling

00:17:12,520 --> 00:17:17,830
and will show opening peon matrix for a

00:17:15,400 --> 00:17:21,150
rank they attack so it was on the

00:17:17,830 --> 00:17:25,660
critical path of open MP communication

00:17:21,150 --> 00:17:28,330
open oven sorry of impact of impact

00:17:25,660 --> 00:17:31,270
communication like the more likely less

00:17:28,330 --> 00:17:34,060
rank is spinning the more he eats on the

00:17:31,270 --> 00:17:36,430
critical path and so will show these

00:17:34,060 --> 00:17:39,280
metrics by by the paint by rank of

00:17:36,430 --> 00:17:41,950
choice that is not so you'll be able to

00:17:39,280 --> 00:17:44,140
assess pretty quickly opening p

00:17:41,950 --> 00:17:49,480
efficiency for your in purpose

00:17:44,140 --> 00:17:56,220
before hybrid application right so to

00:17:49,480 --> 00:17:58,960
summarize envision amplifier we have

00:17:56,220 --> 00:18:02,320
together with in Tehran time open appear

00:17:58,960 --> 00:18:05,800
on time we have ability to show opening

00:18:02,320 --> 00:18:08,830
P efficiency metrics like on the on on

00:18:05,800 --> 00:18:11,980
open MP language on and on the language

00:18:08,830 --> 00:18:14,970
of pragmas clauses like schedule right

00:18:11,980 --> 00:18:19,950
chunking and all that stuff they allow a

00:18:14,970 --> 00:18:22,960
user to understand what can be changed

00:18:19,950 --> 00:18:24,010
with the application to accept to make

00:18:22,960 --> 00:18:27,970
it more efficient in terms of

00:18:24,010 --> 00:18:31,620
polarization the analysis actually is

00:18:27,970 --> 00:18:36,090
well scalable on many core systems

00:18:31,620 --> 00:18:39,280
because we use not just tracing we have

00:18:36,090 --> 00:18:42,760
combination of tracing that we do by

00:18:39,280 --> 00:18:48,250
global points and sampling technology

00:18:42,760 --> 00:18:52,090
and even this two technologies combined

00:18:48,250 --> 00:18:54,220
allows us to to actually to to avoid a

00:18:52,090 --> 00:18:56,980
lot of other here that that's a

00:18:54,220 --> 00:18:58,570
collection my bring even on many core

00:18:56,980 --> 00:19:03,160
systems with where you can have

00:18:58,570 --> 00:19:06,190
potentially more than 200 threads as I

00:19:03,160 --> 00:19:09,100
said OpenMP analysis is impaired so it's

00:19:06,190 --> 00:19:13,440
used for impaired plus OpenMP

00:19:09,100 --> 00:19:15,880
applications the full feature set

00:19:13,440 --> 00:19:18,190
including for example zero time hotspots

00:19:15,880 --> 00:19:27,000
is available in the latest region

00:19:18,190 --> 00:19:29,530
amplifier XE thousand 18 and in there is

00:19:27,000 --> 00:19:33,310
available standalone and also as a part

00:19:29,530 --> 00:19:36,490
of peril studio XE 2018 but actually you

00:19:33,310 --> 00:19:41,170
can even try the older version but there

00:19:36,490 --> 00:19:46,540
may be miss some features and also I can

00:19:41,170 --> 00:19:49,300
say that right now we also ship a tool

00:19:46,540 --> 00:19:51,030
that is included in vigil that is called

00:19:49,300 --> 00:19:53,980
application performance snapshot that

00:19:51,030 --> 00:19:57,040
gives you a like high over you by the

00:19:53,980 --> 00:19:58,210
whole application by important aspects

00:19:57,040 --> 00:20:01,930
for HPC

00:19:58,210 --> 00:20:04,330
analysis in p8 I'm opening pin balance

00:20:01,930 --> 00:20:07,120
memory access efficiency and flop

00:20:04,330 --> 00:20:08,830
analysis some flop analysis and we used

00:20:07,120 --> 00:20:14,140
the same instrumentation from OpenMP

00:20:08,830 --> 00:20:16,830
there and the tool shows you oh like

00:20:14,140 --> 00:20:19,990
opening t0 time and opening pin balance

00:20:16,830 --> 00:20:23,200
so you can and application performance

00:20:19,990 --> 00:20:26,230
naps are included individual but it

00:20:23,200 --> 00:20:27,820
allows you very quickly perceive the

00:20:26,230 --> 00:20:30,250
important metrics by the whole run not

00:20:27,820 --> 00:20:32,530
not not waiting for the result

00:20:30,250 --> 00:20:36,720
processing that you might need for

00:20:32,530 --> 00:20:41,470
detailed information that region shows

00:20:36,720 --> 00:20:44,040
ok so thank you for listening and inhale

00:20:41,470 --> 00:20:44,040

YouTube URL: https://www.youtube.com/watch?v=Vl19kyt-cVI


