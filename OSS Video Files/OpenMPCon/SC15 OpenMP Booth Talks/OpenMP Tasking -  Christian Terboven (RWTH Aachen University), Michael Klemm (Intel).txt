Title: OpenMP Tasking -  Christian Terboven (RWTH Aachen University), Michael Klemm (Intel)
Publication date: 2015-11-30
Playlist: SC15 OpenMP Booth Talks
Description: 
	SC15 OpenMP Booth Talks
OpenMP Tasking â€“ Christian Terboven (RWTH Aachen University), Michael Klemm (Intel)    Slides: http://openmp.org/sc15/sc15-openmp-CT-MK-tasking.pdf
Captions: 
	00:00:00,000 --> 00:00:05,700
okay so welcome everybody I'm Kristin

00:00:03,330 --> 00:00:08,250
table from other Beauty HR University in

00:00:05,700 --> 00:00:11,550
Germany and with the openmp language

00:00:08,250 --> 00:00:14,280
committee since 2006 and today I'm going

00:00:11,550 --> 00:00:15,690
to talk about openmp tasking now wanted

00:00:14,280 --> 00:00:17,010
to do this talk together was Mike

00:00:15,690 --> 00:00:18,900
reclaim from Intel but he's not

00:00:17,010 --> 00:00:21,390
available but what we created together

00:00:18,900 --> 00:00:24,000
is a slide deck that would cover pretty

00:00:21,390 --> 00:00:25,650
much everything of OpenMP tasking to

00:00:24,000 --> 00:00:28,380
give you a pretty good overview

00:00:25,650 --> 00:00:31,080
including the new features in openmp 45

00:00:28,380 --> 00:00:32,880
so I want to start with a very nice and

00:00:31,080 --> 00:00:35,010
hopefully motivating example and we are

00:00:32,880 --> 00:00:37,140
serious computer scientists so what we

00:00:35,010 --> 00:00:39,510
deal with are important algorithms like

00:00:37,140 --> 00:00:41,730
solving sudoku seeeeee and then I will

00:00:39,510 --> 00:00:44,070
take a look at scheduling dependencies

00:00:41,730 --> 00:00:47,160
and some minor tasking clauses that are

00:00:44,070 --> 00:00:49,379
new and openmp and that intend to show

00:00:47,160 --> 00:00:53,489
you how powerful this feature actually

00:00:49,379 --> 00:00:56,129
is so let's take a look at su doku and

00:00:53,489 --> 00:00:58,680
I'm not trying to come with with a very

00:00:56,129 --> 00:01:01,410
efficient algorithm here I'm trying to

00:00:58,680 --> 00:01:03,750
paralyze and algorithm that's rather

00:01:01,410 --> 00:01:06,180
easy just to show you how to use the

00:01:03,750 --> 00:01:08,640
openmp tasking concept here so I'm

00:01:06,180 --> 00:01:11,010
assume you're aware with Sudoku puzzles

00:01:08,640 --> 00:01:13,170
and simple algorithm that finds all

00:01:11,010 --> 00:01:15,509
possible solutions but it's not

00:01:13,170 --> 00:01:17,520
deficient because it riveted many

00:01:15,509 --> 00:01:19,710
configuration is the following we have

00:01:17,520 --> 00:01:21,659
to start at an empty field in certain

00:01:19,710 --> 00:01:23,549
number checks you su doku if it's

00:01:21,659 --> 00:01:26,700
invalid delayed in a new number or

00:01:23,549 --> 00:01:28,530
delete the number insert a new number in

00:01:26,700 --> 00:01:30,240
the other case if it's valid we have to

00:01:28,530 --> 00:01:32,700
go to the next year if you do this and

00:01:30,240 --> 00:01:35,220
it's a recursive algorithm we will find

00:01:32,700 --> 00:01:36,720
all possible solutions as I said and if

00:01:35,220 --> 00:01:38,670
you take a look at this algorithm its

00:01:36,720 --> 00:01:41,130
kind of irregular so there's not a big

00:01:38,670 --> 00:01:42,869
loop that you could use any for work

00:01:41,130 --> 00:01:45,119
sharing construct with or if you think

00:01:42,869 --> 00:01:46,890
of the sections work sharing construct

00:01:45,119 --> 00:01:49,979
and openmp you really have a problem

00:01:46,890 --> 00:01:53,430
because it has a very deaths or very

00:01:49,979 --> 00:01:55,470
high recursive deaths so you would have

00:01:53,430 --> 00:01:58,290
to deal with a large number of threads

00:01:55,470 --> 00:02:00,360
are being created and this is where

00:01:58,290 --> 00:02:03,380
tasking comes into play so what are

00:02:00,360 --> 00:02:07,200
tasks are so small pieces of code that

00:02:03,380 --> 00:02:08,640
you define in your actual program so

00:02:07,200 --> 00:02:10,489
it's basically the structured block

00:02:08,640 --> 00:02:13,830
that's contained within the task

00:02:10,489 --> 00:02:15,780
construct and task also have some data

00:02:13,830 --> 00:02:17,280
ciated with it so we have the open p

00:02:15,780 --> 00:02:19,140
data scoping clauses that you're

00:02:17,280 --> 00:02:22,710
probably familiar with like shared

00:02:19,140 --> 00:02:24,540
private first private and of course a

00:02:22,710 --> 00:02:26,880
default clause and with it you can

00:02:24,540 --> 00:02:29,010
manage which data is contained inside

00:02:26,880 --> 00:02:31,890
the task and what does actually shared

00:02:29,010 --> 00:02:33,240
data that's available as a reference so

00:02:31,890 --> 00:02:35,280
all the times that you're going to

00:02:33,240 --> 00:02:37,590
express in your program are independent

00:02:35,280 --> 00:02:39,150
from all the other tasks and this kind

00:02:37,590 --> 00:02:41,280
of recursive definition of a task

00:02:39,150 --> 00:02:43,950
actually can teach you that these are

00:02:41,280 --> 00:02:47,070
very small scale or that's very fine

00:02:43,950 --> 00:02:48,150
great way of expressing parallel ISM so

00:02:47,070 --> 00:02:49,710
talents do not come with the

00:02:48,150 --> 00:02:51,450
restrictions of the work sharing

00:02:49,710 --> 00:02:53,640
constructs like that you can't allow

00:02:51,450 --> 00:02:56,010
that that you're not allowed to let them

00:02:53,640 --> 00:02:58,200
into each other instead tasks can be

00:02:56,010 --> 00:03:00,630
nested inside other tasks inside work

00:02:58,200 --> 00:03:03,330
sales constructs or just inside the

00:03:00,630 --> 00:03:05,580
parallel regions and actually as we will

00:03:03,330 --> 00:03:07,320
see in a second you will be able to

00:03:05,580 --> 00:03:09,810
express your parallel program in terms

00:03:07,320 --> 00:03:11,850
of millions and millions of tasks really

00:03:09,810 --> 00:03:14,490
millions and the openmp run time will

00:03:11,850 --> 00:03:16,350
take this large amount of tasks and map

00:03:14,490 --> 00:03:19,980
it to the team of threads that's

00:03:16,350 --> 00:03:22,430
available to perform the parallel work

00:03:19,980 --> 00:03:25,110
so whenever the open p runtime

00:03:22,430 --> 00:03:27,269
encounters a task or when the program

00:03:25,110 --> 00:03:29,040
flow and counters the task the runtime

00:03:27,269 --> 00:03:31,769
has two options you can either execute

00:03:29,040 --> 00:03:34,290
the task directly or it can put it onto

00:03:31,769 --> 00:03:36,239
a work you and all the threads that are

00:03:34,290 --> 00:03:37,800
waiting for whatever reason for example

00:03:36,239 --> 00:03:39,900
in the barrier or any other

00:03:37,800 --> 00:03:41,880
synchronizations construct they will

00:03:39,900 --> 00:03:44,330
monitor the work queue and pick up the

00:03:41,880 --> 00:03:47,040
task for execution and that's exactly

00:03:44,330 --> 00:03:48,930
where I said the runtime is a freedom to

00:03:47,040 --> 00:03:51,330
map these millions and millions of tasks

00:03:48,930 --> 00:03:52,890
to the team of threads and there's a lot

00:03:51,330 --> 00:03:54,840
of cleverness involved so if you have

00:03:52,890 --> 00:03:57,060
too many times from the work cube you

00:03:54,840 --> 00:03:59,370
might waste memory if you have too few

00:03:57,060 --> 00:04:02,610
times in the work you you were not

00:03:59,370 --> 00:04:05,670
guarantee you cannot guarantee that all

00:04:02,610 --> 00:04:10,220
the calls and threats will be kept busy

00:04:05,670 --> 00:04:12,269
so take a yeah we have also some sorry

00:04:10,220 --> 00:04:14,370
synchronization constructed play along

00:04:12,269 --> 00:04:16,200
with tasks so you might know the barrier

00:04:14,370 --> 00:04:18,390
as I said when threads waiting there

00:04:16,200 --> 00:04:20,700
they can pick up past that are ready for

00:04:18,390 --> 00:04:22,830
the execution and when the barrier has

00:04:20,700 --> 00:04:24,539
been past it's guaranteed that all

00:04:22,830 --> 00:04:27,420
threads have reached the barrier and

00:04:24,539 --> 00:04:30,240
that all tasks have been completed

00:04:27,420 --> 00:04:32,700
and only task-specific synchronization

00:04:30,240 --> 00:04:35,100
construct is a task wait it doesn't wait

00:04:32,700 --> 00:04:38,460
for oil task it only waits for direct

00:04:35,100 --> 00:04:40,680
child tasks of the threads or task that

00:04:38,460 --> 00:04:42,690
encounters the task wave so in the

00:04:40,680 --> 00:04:44,850
recursion level and I said we will only

00:04:42,690 --> 00:04:46,710
wait with the task wait construct for

00:04:44,850 --> 00:04:49,650
the direct child's child's of these

00:04:46,710 --> 00:04:52,100
direct child's will not be waited for in

00:04:49,650 --> 00:04:56,330
the task wait and this is why recursive

00:04:52,100 --> 00:04:58,980
parallelism in openmp tasking does work

00:04:56,330 --> 00:05:00,660
so now let's take a look at how we are

00:04:58,980 --> 00:05:03,510
going to parallel eyes the sudoku solver

00:05:00,660 --> 00:05:05,430
with openmp past the first construct in

00:05:03,510 --> 00:05:07,740
there we show a larger except of the

00:05:05,430 --> 00:05:09,960
code laid on the first contract here is

00:05:07,740 --> 00:05:11,730
a parallel and a single it sounds

00:05:09,960 --> 00:05:13,860
strange but that's exactly what I need I

00:05:11,730 --> 00:05:16,710
need a parallel construct in order to

00:05:13,860 --> 00:05:18,990
create a team of threat and then I need

00:05:16,710 --> 00:05:21,630
a single so that only one thread start

00:05:18,990 --> 00:05:23,580
the execution of my algorithm because if

00:05:21,630 --> 00:05:26,640
we don't look at over here we have to

00:05:23,580 --> 00:05:29,160
start start searching for one empty

00:05:26,640 --> 00:05:31,140
field and I want only one thread to

00:05:29,160 --> 00:05:33,120
start the execution of the algorithm and

00:05:31,140 --> 00:05:35,340
later on in the recursion steps we are

00:05:33,120 --> 00:05:36,950
going to express more and more task to

00:05:35,340 --> 00:05:39,510
finally come up with a parallel program

00:05:36,950 --> 00:05:41,310
so we run with this one thread through

00:05:39,510 --> 00:05:43,410
the algorithm the others jump around the

00:05:41,310 --> 00:05:45,600
signal wait at the implied barrier and

00:05:43,410 --> 00:05:48,390
things are available to execute any task

00:05:45,600 --> 00:05:51,960
that's inserted our edits to the web

00:05:48,390 --> 00:05:54,420
view so we finally will arrive at the

00:05:51,960 --> 00:05:55,980
step 4 in the algorithm and this is

00:05:54,420 --> 00:05:58,140
actually where we have the parallel ISM

00:05:55,980 --> 00:06:00,750
if the number doesn't fit so that mean

00:05:58,140 --> 00:06:02,550
if the Sudoku would be invalid we can

00:06:00,750 --> 00:06:04,950
express a parallel ISM that all the

00:06:02,550 --> 00:06:08,550
other possible numbers can be tried out

00:06:04,950 --> 00:06:11,370
in parallel and we create one task for

00:06:08,550 --> 00:06:12,930
every possible other number in that we

00:06:11,370 --> 00:06:15,510
have to create a copy of the pseudocode

00:06:12,930 --> 00:06:18,420
board because we are as I said going to

00:06:15,510 --> 00:06:20,280
revisit a few configurations when we're

00:06:18,420 --> 00:06:22,440
doing simple algorithm like that and

00:06:20,280 --> 00:06:26,730
finally at the very end we have to wait

00:06:22,440 --> 00:06:29,430
our for child x and this is how it looks

00:06:26,730 --> 00:06:31,110
like an actual OpenMP code if you are

00:06:29,430 --> 00:06:34,440
interested in the poodle sudoku solver

00:06:31,110 --> 00:06:36,630
just send me an email and reply with a

00:06:34,440 --> 00:06:38,790
code is actually not really long so

00:06:36,630 --> 00:06:40,320
here's a parallel singer and that only

00:06:38,790 --> 00:06:42,750
consists of the code

00:06:40,320 --> 00:06:44,550
of the 14 to start the recursive

00:06:42,750 --> 00:06:46,560
algorithms all the other threads as I

00:06:44,550 --> 00:06:48,630
said we'll jump around and wait at the

00:06:46,560 --> 00:06:50,340
end of the barrier before the parallel

00:06:48,630 --> 00:06:53,130
and we'll just work on the tan say that

00:06:50,340 --> 00:06:55,080
include into the task you the soft peril

00:06:53,130 --> 00:06:56,820
it is a recursive algorithm meant the

00:06:55,080 --> 00:06:59,280
sketch of the code shown on the next

00:06:56,820 --> 00:07:02,250
slide what you will also find in some

00:06:59,280 --> 00:07:03,990
openmp tasking benchmarks is something

00:07:02,250 --> 00:07:06,750
like the following pragma lumpy parallel

00:07:03,990 --> 00:07:09,990
sections let's syntactic sugar so

00:07:06,750 --> 00:07:11,790
sections that's a very static construct

00:07:09,990 --> 00:07:15,060
and all the sections that will follow

00:07:11,790 --> 00:07:17,160
here I executed by individual threads

00:07:15,060 --> 00:07:19,590
here in this very simple example we have

00:07:17,160 --> 00:07:21,060
only one thread and that means once read

00:07:19,590 --> 00:07:23,670
will start the execution will solve

00:07:21,060 --> 00:07:25,740
parallel the others will jump around and

00:07:23,670 --> 00:07:28,500
that's basically equivalent to the

00:07:25,740 --> 00:07:30,810
parallel singer but very single is not a

00:07:28,500 --> 00:07:33,600
construct or unlock constructor can be

00:07:30,810 --> 00:07:36,570
combined and let's see actual

00:07:33,600 --> 00:07:38,910
implementation then so for e equals 1 to

00:07:36,570 --> 00:07:41,340
the period side period sighs that's

00:07:38,910 --> 00:07:44,850
actually the number the possible numbers

00:07:41,340 --> 00:07:47,070
that we are going to evaluate and we do

00:07:44,850 --> 00:07:49,230
the pack multitask first private here

00:07:47,070 --> 00:07:52,530
because we want to capture the values of

00:07:49,230 --> 00:07:54,630
I x and y these are to put the positions

00:07:52,530 --> 00:07:57,390
in the field and the actual pointer to a

00:07:54,630 --> 00:07:58,920
field inside the tart the first private

00:07:57,390 --> 00:08:01,770
is really important in the context of

00:07:58,920 --> 00:08:04,080
task because the task here will be

00:08:01,770 --> 00:08:06,660
created and can be put onto the work you

00:08:04,080 --> 00:08:08,460
and it when it's later taken out from

00:08:06,660 --> 00:08:10,650
the work you and brought to execution on

00:08:08,460 --> 00:08:12,210
the thread the values of the surrounding

00:08:10,650 --> 00:08:14,550
variables might have been changed and

00:08:12,210 --> 00:08:17,310
the task of obviously needs access to

00:08:14,550 --> 00:08:19,740
all the values as you intended so first

00:08:17,310 --> 00:08:21,660
private will create new private

00:08:19,740 --> 00:08:24,510
variables of the given names inside the

00:08:21,660 --> 00:08:27,150
task but as was parallel first private

00:08:24,510 --> 00:08:30,570
means it will capture the value of these

00:08:27,150 --> 00:08:33,540
variables I XY and sudoku and copy them

00:08:30,570 --> 00:08:35,280
into the task and when the task finally

00:08:33,540 --> 00:08:38,070
will be picked up from the web so we can

00:08:35,280 --> 00:08:40,530
create a new Sudoku board with a copy

00:08:38,070 --> 00:08:43,710
constructor here a set the current

00:08:40,530 --> 00:08:47,760
number it's a position and continue with

00:08:43,710 --> 00:08:50,730
our our parallel search ok first private

00:08:47,760 --> 00:08:53,430
is for all private variables in the

00:08:50,730 --> 00:08:54,570
enclosing a construct of task the

00:08:53,430 --> 00:08:57,090
default

00:08:54,570 --> 00:08:59,430
so with the intent to make many programs

00:08:57,090 --> 00:09:01,410
safe and ensure that all the necessary

00:08:59,430 --> 00:09:05,610
leave it necessary values are copied

00:09:01,410 --> 00:09:07,830
inside the times I implemented that and

00:09:05,610 --> 00:09:10,140
that's the performance which I got so

00:09:07,830 --> 00:09:12,570
it's a two socket into a sandy bridge

00:09:10,140 --> 00:09:14,760
machine with eight physical cores per

00:09:12,570 --> 00:09:17,820
socket with hyper-threading and two

00:09:14,760 --> 00:09:19,440
circuits we come up to 32 logical cores

00:09:17,820 --> 00:09:24,360
and the total speed up this is this

00:09:19,440 --> 00:09:29,190
grayish line here maxes out at 3.6 is it

00:09:24,360 --> 00:09:30,720
good I was pretty disappointed but what

00:09:29,190 --> 00:09:33,270
we are encountering here is a very

00:09:30,720 --> 00:09:35,900
important performance problem later on

00:09:33,270 --> 00:09:39,630
that you will find in all tasks parallel

00:09:35,900 --> 00:09:41,970
programming models so we looked at this

00:09:39,630 --> 00:09:44,460
code with different tools on the left

00:09:41,970 --> 00:09:48,030
hand side you will find the output of

00:09:44,460 --> 00:09:49,560
the scale askah tool using scholars 4p

00:09:48,030 --> 00:09:51,330
based analysis on the right hand side

00:09:49,560 --> 00:09:53,970
you will find something from the to

00:09:51,330 --> 00:09:55,650
rename vampyre so scholastica gives us

00:09:53,970 --> 00:09:58,470
some statistics and what we're doing

00:09:55,650 --> 00:10:00,750
here is we execute in total 1.3 million

00:09:58,470 --> 00:10:04,620
times and if we divide that by the

00:10:00,750 --> 00:10:06,720
program run time of about 5.7 seconds in

00:10:04,620 --> 00:10:09,900
the serial case the average duration of

00:10:06,720 --> 00:10:11,940
every chance is only 4.4 microseconds

00:10:09,900 --> 00:10:13,470
and the problem here is of course that

00:10:11,940 --> 00:10:16,170
there's some overheads of creating the

00:10:13,470 --> 00:10:18,390
task putting it onto a work you taking

00:10:16,170 --> 00:10:20,580
it back for execution that some overhead

00:10:18,390 --> 00:10:22,920
and if the task is too small it doesn't

00:10:20,580 --> 00:10:25,470
pay off so with every small towns we're

00:10:22,920 --> 00:10:27,060
only adding overhead and you can see

00:10:25,470 --> 00:10:29,670
that in the recursion level at some

00:10:27,060 --> 00:10:32,280
point we still have pretty costly tasks

00:10:29,670 --> 00:10:34,380
that this recursion level 6 the average

00:10:32,280 --> 00:10:36,510
duration of the task is still point one

00:10:34,380 --> 00:10:39,060
six seven seconds where we go down

00:10:36,510 --> 00:10:41,520
deeper in the recursion tree we go down

00:10:39,060 --> 00:10:43,350
to two point two microseconds so the

00:10:41,520 --> 00:10:45,600
pattern to solve this problem is the

00:10:43,350 --> 00:10:48,030
so-called cut off at some point when we

00:10:45,600 --> 00:10:51,030
have created a sufficient amount of task

00:10:48,030 --> 00:10:52,770
we have to stop creating more tasks

00:10:51,030 --> 00:10:54,390
there's a clause for that in open he's

00:10:52,770 --> 00:10:58,680
the if clause which I will show on the

00:10:54,390 --> 00:11:00,840
next slide and if we do that so the if

00:10:58,680 --> 00:11:03,150
Clause will solve the problem here we

00:11:00,840 --> 00:11:04,980
come up with a speed up that's shown at

00:11:03,150 --> 00:11:07,140
the black line so we have for linear

00:11:04,980 --> 00:11:08,320
scalability was a number of physical

00:11:07,140 --> 00:11:10,750
course

00:11:08,320 --> 00:11:12,850
in the machine so when we have enough

00:11:10,750 --> 00:11:15,460
task we stop the creation of more task

00:11:12,850 --> 00:11:17,440
and let the threads continue the task so

00:11:15,460 --> 00:11:21,100
that we save the overhead and the good

00:11:17,440 --> 00:11:23,050
rule of thumb be stupid about s 10 times

00:11:21,100 --> 00:11:25,360
the number of tasks that you have as a

00:11:23,050 --> 00:11:27,820
number of threads of course in your

00:11:25,360 --> 00:11:30,550
machine so tasking can be made

00:11:27,820 --> 00:11:33,970
successful with this performs important

00:11:30,550 --> 00:11:36,640
performance problem better so the if

00:11:33,970 --> 00:11:38,680
Clause can be put onto a task it takes

00:11:36,640 --> 00:11:40,780
an expression and if the expression the

00:11:38,680 --> 00:11:43,030
village to false that will mean that the

00:11:40,780 --> 00:11:45,100
task is directly executed and we save

00:11:43,030 --> 00:11:47,680
the overhead of putting a task on to a

00:11:45,100 --> 00:11:50,800
work you and taking a log back later on

00:11:47,680 --> 00:11:55,270
so it's kind of sequential embedding

00:11:50,800 --> 00:11:57,940
into the enclosing task a few more words

00:11:55,270 --> 00:12:00,340
on scheduling and task dependencies so

00:11:57,940 --> 00:12:02,320
task once created will always be

00:12:00,340 --> 00:12:05,410
executed by the same thread which

00:12:02,320 --> 00:12:07,210
started the execution we differentiate

00:12:05,410 --> 00:12:08,590
between the creator and the executor

00:12:07,210 --> 00:12:10,810
that creator thread is the one that

00:12:08,590 --> 00:12:13,120
encounters the task constructing the

00:12:10,810 --> 00:12:14,890
actual code creates a work package puts

00:12:13,120 --> 00:12:16,870
it onto the work you and then the

00:12:14,890 --> 00:12:18,850
executor thread is the first one which

00:12:16,870 --> 00:12:20,980
picks up the task from the cube brings

00:12:18,850 --> 00:12:23,380
it to execution the executioner on the

00:12:20,980 --> 00:12:25,300
task might be interrupted at for example

00:12:23,380 --> 00:12:27,700
the encountering of an inner task

00:12:25,300 --> 00:12:30,340
construct or any other of these task

00:12:27,700 --> 00:12:33,820
scheduling points as we call them but

00:12:30,340 --> 00:12:35,740
instead in a standard case the great the

00:12:33,820 --> 00:12:37,960
executor thread will always come back

00:12:35,740 --> 00:12:40,330
and complete the task if you don't want

00:12:37,960 --> 00:12:42,490
it you can put the Untied cross and that

00:12:40,330 --> 00:12:44,920
means stands are not tight anymore so

00:12:42,490 --> 00:12:46,960
the task has one executors red and this

00:12:44,920 --> 00:12:48,760
is interrupted a different thread might

00:12:46,960 --> 00:12:50,830
come and pick it up so that would give

00:12:48,760 --> 00:12:53,940
the implementation more freedom to

00:12:50,830 --> 00:12:57,460
perform a better load balancing among

00:12:53,940 --> 00:12:59,050
the task and if you want to further

00:12:57,460 --> 00:13:02,350
improve the load balancing we have to

00:12:59,050 --> 00:13:04,450
task yield clause i would just jump to

00:13:02,350 --> 00:13:06,100
an example here so what we do is we have

00:13:04,450 --> 00:13:08,890
a function called something useful and

00:13:06,100 --> 00:13:11,050
something critical and we create a

00:13:08,890 --> 00:13:13,540
number of tasks in this simple example

00:13:11,050 --> 00:13:15,760
so we assume something useful perform

00:13:13,540 --> 00:13:17,740
some computation and then we want to

00:13:15,760 --> 00:13:20,200
store the result within something

00:13:17,740 --> 00:13:22,240
critical so we are going to modify from

00:13:20,200 --> 00:13:24,540
some shared space here

00:13:22,240 --> 00:13:29,500
and we are going to modify the shared

00:13:24,540 --> 00:13:31,990
data we have to guard it with local

00:13:29,500 --> 00:13:33,820
teams here and if multiple threads will

00:13:31,990 --> 00:13:35,290
do the same only one can acquire the

00:13:33,820 --> 00:13:38,470
lock I'm assuming you're familiar with

00:13:35,290 --> 00:13:40,540
locks in this case so what we can do is

00:13:38,470 --> 00:13:42,490
if we don't get the lock we will

00:13:40,540 --> 00:13:44,529
instruct the run time to put the corn

00:13:42,490 --> 00:13:46,750
task to sleep so that the runtime can

00:13:44,529 --> 00:13:49,899
take the sweat that was executing the

00:13:46,750 --> 00:13:51,640
task and put a different work on that

00:13:49,899 --> 00:13:54,220
particular thread for example a

00:13:51,640 --> 00:13:56,230
different task and later when the task

00:13:54,220 --> 00:13:58,480
is being picked up again it might have a

00:13:56,230 --> 00:14:00,070
better chance to acquire the lock so

00:13:58,480 --> 00:14:05,140
this may improve our the load-bearing

00:14:00,070 --> 00:14:07,240
singing opening we have more

00:14:05,140 --> 00:14:10,510
synchronization construct the task for a

00:14:07,240 --> 00:14:13,810
group construct for example the task

00:14:10,510 --> 00:14:16,120
group is again a structured block and it

00:14:13,810 --> 00:14:18,370
at the very end it contains a task

00:14:16,120 --> 00:14:21,070
barrier which waits for all the tasks

00:14:18,370 --> 00:14:22,959
that are created within this task group

00:14:21,070 --> 00:14:25,480
construct and we'll set it complements a

00:14:22,959 --> 00:14:27,640
barrier and the task wait to offer oil

00:14:25,480 --> 00:14:30,880
task all kinds of tasks related

00:14:27,640 --> 00:14:32,950
synchronization that are well known or

00:14:30,880 --> 00:14:36,130
used in the one described in the

00:14:32,950 --> 00:14:37,959
literature and in openmp we have plans

00:14:36,130 --> 00:14:40,329
dependencies at the future of opening

00:14:37,959 --> 00:14:42,640
before so is that you can express that

00:14:40,329 --> 00:14:46,240
the task is to wait for some other task

00:14:42,640 --> 00:14:48,040
to be executed first and we introduce

00:14:46,240 --> 00:14:50,410
the feature in a way that you can

00:14:48,040 --> 00:14:52,959
express the actual data flow we have two

00:14:50,410 --> 00:14:54,940
types of dependencies we have in and the

00:14:52,959 --> 00:14:59,740
in and our dependencies are equivalent

00:14:54,940 --> 00:15:01,240
so in means the generated task will be

00:14:59,740 --> 00:15:03,700
dependent on the previously generated

00:15:01,240 --> 00:15:06,399
sibling task that references the data

00:15:03,700 --> 00:15:09,550
value in the in or in outlaws and out

00:15:06,399 --> 00:15:11,410
will mean it waits for in out and in our

00:15:09,550 --> 00:15:13,390
doors and have an example here to

00:15:11,410 --> 00:15:16,870
illustrate that so we have again the

00:15:13,390 --> 00:15:19,300
parallel single pattern which creates a

00:15:16,870 --> 00:15:22,300
one thread that start the execution here

00:15:19,300 --> 00:15:24,760
it will loop over several iterations of

00:15:22,300 --> 00:15:27,610
this I loop here and it will create one

00:15:24,760 --> 00:15:29,740
task which I call t one that does some

00:15:27,610 --> 00:15:32,079
pre processing of the data there's an

00:15:29,740 --> 00:15:34,780
alt dependence into the variable X and

00:15:32,079 --> 00:15:36,910
then we have tasks t2 and

00:15:34,780 --> 00:15:39,700
three which are siblings of this task

00:15:36,910 --> 00:15:42,520
but they have in dependencies on the

00:15:39,700 --> 00:15:45,070
variable X and that means first t1 has

00:15:42,520 --> 00:15:49,210
to complete to be completed before the

00:15:45,070 --> 00:15:54,150
before t2 and t3 can be started but t2

00:15:49,210 --> 00:15:58,240
and t3 can then be executed in parallel

00:15:54,150 --> 00:16:00,460
okay and yeah that's what I just said

00:15:58,240 --> 00:16:02,410
and this can be actually used to express

00:16:00,460 --> 00:16:05,980
real dependencies as an example from

00:16:02,410 --> 00:16:07,630
linear i guar domain actually BSC

00:16:05,980 --> 00:16:09,910
implemented it and they explored this

00:16:07,630 --> 00:16:12,160
content with the UM barrel of

00:16:09,910 --> 00:16:13,720
programming paradigm and I think on the

00:16:12,160 --> 00:16:16,270
next slide there's approved jack

00:16:13,720 --> 00:16:18,190
dongarra cheered the openmp tasking

00:16:16,270 --> 00:16:20,260
construct so previously with a linear I

00:16:18,190 --> 00:16:22,420
gave our stuff they used the very own

00:16:20,260 --> 00:16:24,220
implementation of tasks and now they're

00:16:22,420 --> 00:16:26,410
considering open before and 45

00:16:24,220 --> 00:16:27,760
implementations to relieve them from the

00:16:26,410 --> 00:16:30,240
burden to do their own stuff they

00:16:27,760 --> 00:16:33,040
consider our future are stable enough

00:16:30,240 --> 00:16:34,990
before I close I want to briefly run

00:16:33,040 --> 00:16:38,110
through the new contract that we have in

00:16:34,990 --> 00:16:39,610
Oakland p45 the task group construct is

00:16:38,110 --> 00:16:42,270
very similar to the work sharing

00:16:39,610 --> 00:16:44,830
construct it parallelized us over the

00:16:42,270 --> 00:16:46,390
iterations of a loop but instead of

00:16:44,830 --> 00:16:49,180
distributing the work between the

00:16:46,390 --> 00:16:51,790
threads in the parallel team it creates

00:16:49,180 --> 00:16:53,860
tasks and that comes with all the

00:16:51,790 --> 00:16:56,920
adventures of tasks o-tar's can be

00:16:53,860 --> 00:16:58,570
listed they gives a runtime more freedom

00:16:56,920 --> 00:17:00,490
to do load balancing and stuff like that

00:16:58,570 --> 00:17:02,860
there are some closest with it but

00:17:00,490 --> 00:17:05,560
basically these most of the clauses are

00:17:02,860 --> 00:17:07,660
the one that you know from the forward

00:17:05,560 --> 00:17:13,420
chaining construct with respect to the

00:17:07,660 --> 00:17:15,760
data scoping two clauses are special

00:17:13,420 --> 00:17:17,860
special you can either specify the grain

00:17:15,760 --> 00:17:20,890
size the number of iterations to be

00:17:17,860 --> 00:17:23,230
grouped per task or the number of times

00:17:20,890 --> 00:17:26,200
that should be great at created by the

00:17:23,230 --> 00:17:28,060
construct so that's a new 45 feature we

00:17:26,200 --> 00:17:30,400
also introduced priorities and that's

00:17:28,060 --> 00:17:33,730
basically a hint to the runtime the two

00:17:30,400 --> 00:17:35,710
tasks which are ready and if two tasks

00:17:33,730 --> 00:17:37,600
are ready and their priorities the

00:17:35,710 --> 00:17:40,570
runtime will pick this red was a higher

00:17:37,600 --> 00:17:43,030
priority first it's meant as a hint it's

00:17:40,570 --> 00:17:45,340
not a feature that you can rely on to

00:17:43,030 --> 00:17:47,950
enforce a certain requirement but again

00:17:45,340 --> 00:17:50,860
if you have very complex dependencies

00:17:47,950 --> 00:17:52,630
an algorithm in which you can actually

00:17:50,860 --> 00:17:55,330
guide the run time to come up with a

00:17:52,630 --> 00:17:58,980
clever scheduling priorities can be used

00:17:55,330 --> 00:18:01,150
to express it and to achieve better

00:17:58,980 --> 00:18:04,690
performance if you don't specify it all

00:18:01,150 --> 00:18:10,360
tasks of the same priority which is a

00:18:04,690 --> 00:18:14,860
value 0 as we have it today and then in

00:18:10,360 --> 00:18:16,390
my Sudoku example I already set at some

00:18:14,860 --> 00:18:19,270
point we might have to stop the creation

00:18:16,390 --> 00:18:22,900
of more tasks we have finer and merge

00:18:19,270 --> 00:18:25,240
about final takes an integer sorry a

00:18:22,900 --> 00:18:27,700
boolean expression if it evaluates to

00:18:25,240 --> 00:18:29,590
true the run time will be notified that

00:18:27,700 --> 00:18:32,350
this is a final task which will not

00:18:29,590 --> 00:18:34,570
create any further task and this again

00:18:32,350 --> 00:18:37,030
allows the run time to perform certain

00:18:34,570 --> 00:18:39,280
performance improvement for example to

00:18:37,030 --> 00:18:41,320
merge the data environment of the final

00:18:39,280 --> 00:18:43,630
pass with the enclosing data and right

00:18:41,320 --> 00:18:45,790
environment but it's a dangerous feature

00:18:43,630 --> 00:18:48,910
so here you see a difference first

00:18:45,790 --> 00:18:51,220
private would copy in case it's a task

00:18:48,910 --> 00:18:53,650
the I available in to the task in which

00:18:51,220 --> 00:18:57,700
I hear is modified but it's the final

00:18:53,650 --> 00:19:02,140
expression evaluates to true that will

00:18:57,700 --> 00:19:04,330
not happen because I'm sorry the data

00:19:02,140 --> 00:19:05,950
reasons then will be merged just the

00:19:04,330 --> 00:19:07,810
other way around and then you would have

00:19:05,950 --> 00:19:09,550
a different value or when the data

00:19:07,810 --> 00:19:11,440
regions would not be merged so it's an

00:19:09,550 --> 00:19:13,840
expert feature which we can give you

00:19:11,440 --> 00:19:17,440
good performance if you know when and

00:19:13,840 --> 00:19:19,600
where to use it in recursive algorithms

00:19:17,440 --> 00:19:22,060
but be careful with it however to be

00:19:19,600 --> 00:19:25,840
honest currently no MP implementation as

00:19:22,060 --> 00:19:28,270
any implementation for that and finally

00:19:25,840 --> 00:19:31,840
we have mirja bowl which instruct the

00:19:28,270 --> 00:19:34,600
openmp compiler and then the runtime and

00:19:31,840 --> 00:19:37,140
give City implementation that the data

00:19:34,600 --> 00:19:41,250
environment can be merged with the outer

00:19:37,140 --> 00:19:44,200
enclosing task data environment and can

00:19:41,250 --> 00:19:46,450
that can lead to performs improvements

00:19:44,200 --> 00:19:50,050
particularly again which recursive

00:19:46,450 --> 00:19:51,400
algorithms I think think that's what

00:19:50,050 --> 00:19:53,560
I've prepared for today that was a

00:19:51,400 --> 00:19:56,800
really quick rundown about all task

00:19:53,560 --> 00:19:58,300
related stuff thank you for your

00:19:56,800 --> 00:20:03,360
attention I think I'm available for

00:19:58,300 --> 00:20:03,360
questions now if you have any think

00:20:04,160 --> 00:20:14,810
any questions no questions you have a

00:20:11,880 --> 00:20:14,810

YouTube URL: https://www.youtube.com/watch?v=2P0jXvBYuqs


