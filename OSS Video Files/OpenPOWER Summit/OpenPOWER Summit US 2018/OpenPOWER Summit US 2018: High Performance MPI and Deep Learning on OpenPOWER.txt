Title: OpenPOWER Summit US 2018: High Performance MPI and Deep Learning on OpenPOWER
Publication date: 2018-04-06
Playlist: OpenPOWER Summit US 2018
Description: 
	Dhabaleswar K (DK) Panda and Hari Subramoni of OSU discuss high-performance MPI and deep learning on OpenPOWER at the OpenPOWER Summit 2018. 

For more information please visit www.openpowerfoundation.org.
Captions: 
	00:00:00,000 --> 00:00:02,659
okay

00:00:17,970 --> 00:00:21,190
[Music]

00:05:02,349 --> 00:05:06,550
more into terms of the big data like the

00:05:04,509 --> 00:05:08,710
Hadoop and spark how you can actually

00:05:06,550 --> 00:05:11,469
run efficiently on the open power

00:05:08,710 --> 00:05:14,740
platform so that talk is at 2:15 in room

00:05:11,469 --> 00:05:16,779
307 so I'll start with this this is the

00:05:14,740 --> 00:05:19,449
project some of you might be already

00:05:16,779 --> 00:05:20,889
knowing this am happiest to project in

00:05:19,449 --> 00:05:24,309
my group who have been working in now

00:05:20,889 --> 00:05:27,129
for 16 years we were the very first ones

00:05:24,309 --> 00:05:30,249
when InfiniBand came into the picture we

00:05:27,129 --> 00:05:33,669
started the first open source MPI and it

00:05:30,249 --> 00:05:35,849
was available in the 2002 supercomputing

00:05:33,669 --> 00:05:38,020
and then since then we are continuously

00:05:35,849 --> 00:05:39,999
enhancing they said they software stack

00:05:38,020 --> 00:05:41,800
and there are different versions

00:05:39,999 --> 00:05:43,659
optimized versions here I'll talk a

00:05:41,800 --> 00:05:45,999
little bit about that later

00:05:43,659 --> 00:05:50,080
but now it is being used by more than

00:05:45,999 --> 00:05:52,719
2,800 organizations in 85 countries and

00:05:50,080 --> 00:05:54,669
just from our like websites you see we

00:05:52,719 --> 00:05:57,309
are almost like a quarter million

00:05:54,669 --> 00:05:59,319
sorry 0.45 million downloads just taking

00:05:57,309 --> 00:06:00,729
place from our side and not just the

00:05:59,319 --> 00:06:02,529
downloads if you take a look at all

00:06:00,729 --> 00:06:04,809
these machines even the number one

00:06:02,529 --> 00:06:06,939
system in China 100 particular machine

00:06:04,809 --> 00:06:08,979
is being driven by our stack you can

00:06:06,939 --> 00:06:12,490
also see the 9th ranked oak forest packs

00:06:08,979 --> 00:06:16,360
in Japan 12 attack 17 so a lot of these

00:06:12,490 --> 00:06:18,099
top 500 systems are being enabled by the

00:06:16,360 --> 00:06:20,080
software which we have developed in my

00:06:18,099 --> 00:06:22,300
group and this is a continuous project

00:06:20,080 --> 00:06:25,120
which has been going and we have been

00:06:22,300 --> 00:06:26,559
empowering this over a decade and the

00:06:25,120 --> 00:06:28,629
software stack not only is available

00:06:26,559 --> 00:06:32,009
from our side it is also available with

00:06:28,629 --> 00:06:35,469
integrated vendors from any other

00:06:32,009 --> 00:06:37,599
industry like if you take a red hat or

00:06:35,469 --> 00:06:40,509
sushi disk or even a open HPC you will

00:06:37,599 --> 00:06:43,149
see our a map is to stack being there so

00:06:40,509 --> 00:06:45,849
we have multiple versions here so there

00:06:43,149 --> 00:06:47,680
is a basic MPI version which is the map

00:06:45,849 --> 00:06:50,199
is 2 so then there is an MRAP

00:06:47,680 --> 00:06:52,029
a map is 2 X which has the advanced MPI

00:06:50,199 --> 00:06:54,189
features it also tries to provide with

00:06:52,029 --> 00:06:56,159
the figures hybrid mci figures kind of

00:06:54,189 --> 00:06:58,509
support and then there is a GPU

00:06:56,159 --> 00:06:59,559
optimized version for NVIDIA GPU so

00:06:58,509 --> 00:07:01,930
those are the three things I'll be

00:06:59,559 --> 00:07:04,629
mostly focusing today there are also

00:07:01,930 --> 00:07:06,909
some cloud versions energyaware worsens

00:07:04,629 --> 00:07:09,399
the my question which has been upgraded

00:07:06,909 --> 00:07:11,319
to K and L based we also have a lot of

00:07:09,399 --> 00:07:13,539
micro break for sweet the entire

00:07:11,319 --> 00:07:14,320
community uses issue micro benchmarks

00:07:13,539 --> 00:07:16,060
those

00:07:14,320 --> 00:07:18,790
the bench wants people use for

00:07:16,060 --> 00:07:20,470
evaluating different MPA libraries we

00:07:18,790 --> 00:07:23,830
also have an integrated network

00:07:20,470 --> 00:07:25,540
monitoring analysis tools so this is the

00:07:23,830 --> 00:07:27,070
kind of our release time download as you

00:07:25,540 --> 00:07:30,030
can see like over the years we are in a

00:07:27,070 --> 00:07:33,160
very steady rising curve kind of thing

00:07:30,030 --> 00:07:36,670
more and more systems are using our

00:07:33,160 --> 00:07:37,660
stack to get the best performance so

00:07:36,670 --> 00:07:41,140
this is the overall like the

00:07:37,660 --> 00:07:43,300
architecture of the software family so

00:07:41,140 --> 00:07:45,400
as I said not only it provides MPI but

00:07:43,300 --> 00:07:47,830
it also provides pas and hybrid MPI peer

00:07:45,400 --> 00:07:49,000
support we support all different kind of

00:07:47,830 --> 00:07:49,750
networking technologies not only

00:07:49,000 --> 00:07:52,120
InfiniBand

00:07:49,750 --> 00:07:54,970
which we were talk sharing more and more

00:07:52,120 --> 00:07:56,920
here also I were rocky also many paths

00:07:54,970 --> 00:07:59,560
and also for all the different platforms

00:07:56,920 --> 00:08:02,140
not only Intel Xeon of course the focus

00:07:59,560 --> 00:08:05,650
here is the open power Xeon Phi arm

00:08:02,140 --> 00:08:07,150
NVIDIA GPUs all the systems we try to

00:08:05,650 --> 00:08:09,810
take advantage of their features and

00:08:07,150 --> 00:08:12,160
then trying to take it through the stack

00:08:09,810 --> 00:08:15,610
to give you the best performance and

00:08:12,160 --> 00:08:17,290
scalability so so as the open power came

00:08:15,610 --> 00:08:18,790
into the picture I mean of course the

00:08:17,290 --> 00:08:20,920
community has been there with the x86

00:08:18,790 --> 00:08:22,990
for many years and then over the period

00:08:20,920 --> 00:08:25,390
of time we have been trying to provide

00:08:22,990 --> 00:08:28,690
more and more optimization for open

00:08:25,390 --> 00:08:31,810
power in our stack so in the basic MPI

00:08:28,690 --> 00:08:33,370
support almost like two years back we

00:08:31,810 --> 00:08:36,910
enabled the initial support and we

00:08:33,370 --> 00:08:38,320
continuously enhance it the pker support

00:08:36,910 --> 00:08:41,890
also has been there for almost two years

00:08:38,320 --> 00:08:43,720
now recently we have provided some very

00:08:41,890 --> 00:08:46,540
advanced collective support I will talk

00:08:43,720 --> 00:08:48,640
about that and also the NVIDIA GPU

00:08:46,540 --> 00:08:50,320
support and especially with Emily link

00:08:48,640 --> 00:08:52,360
that is the new thing which has come out

00:08:50,320 --> 00:08:54,370
with open power it can be linked like

00:08:52,360 --> 00:08:56,050
the choral kind of systems so we have

00:08:54,370 --> 00:08:58,600
done a lot of optimization for that so

00:08:56,050 --> 00:09:00,460
I'll also be talking about this so let

00:08:58,600 --> 00:09:01,690
me start with the basic MPI support and

00:09:00,460 --> 00:09:03,820
then gradually I will move to the other

00:09:01,690 --> 00:09:05,470
ones so this is where will I'll try to

00:09:03,820 --> 00:09:08,380
show a lot of performance numbers so

00:09:05,470 --> 00:09:10,420
just to illustrate you like how kind of

00:09:08,380 --> 00:09:12,550
performance you can get from the system

00:09:10,420 --> 00:09:14,710
so here I'll be comparing not only our a

00:09:12,550 --> 00:09:16,900
map is two but there are like two other

00:09:14,710 --> 00:09:18,160
stacks in the community someone who

00:09:16,900 --> 00:09:19,010
might be knowing it is the open MPI and

00:09:18,160 --> 00:09:21,920
the other one is

00:09:19,010 --> 00:09:24,470
IBM spectrum API that has been very much

00:09:21,920 --> 00:09:25,640
geared towards open power so what we are

00:09:24,470 --> 00:09:28,580
trying to show so this is like a

00:09:25,640 --> 00:09:31,580
internode within a node how efficiently

00:09:28,580 --> 00:09:33,800
you can do MPI communication and as you

00:09:31,580 --> 00:09:35,990
know like open power has a lot of course

00:09:33,800 --> 00:09:38,360
so here you can see that this is the

00:09:35,990 --> 00:09:41,060
like the green line here within like two

00:09:38,360 --> 00:09:43,310
cores in trance akut we can actually do

00:09:41,060 --> 00:09:44,510
MPI communication in 300 nanoseconds

00:09:43,310 --> 00:09:46,880
okay

00:09:44,510 --> 00:09:49,790
so that's what it tries to show and then

00:09:46,880 --> 00:09:51,440
this is like the interest socket small

00:09:49,790 --> 00:09:53,000
message latency this is the interest of

00:09:51,440 --> 00:09:55,250
that large message latency they are very

00:09:53,000 --> 00:09:58,610
similar interest rocket bandwidth again

00:09:55,250 --> 00:10:01,370
we are able to deliver equal or better

00:09:58,610 --> 00:10:04,130
than the other other stacks and here

00:10:01,370 --> 00:10:06,130
also very large my say this we are very

00:10:04,130 --> 00:10:09,740
comparable to the to the other ones

00:10:06,130 --> 00:10:11,740
these are the inter node that means from

00:10:09,740 --> 00:10:14,510
a node to node across like InfiniBand

00:10:11,740 --> 00:10:16,000
interconnect so here we lose out a

00:10:14,510 --> 00:10:19,400
little bit we have been continuously

00:10:16,000 --> 00:10:21,590
working on some better solutions here to

00:10:19,400 --> 00:10:23,960
to have comparable performance with the

00:10:21,590 --> 00:10:25,700
other two two stacks but for large

00:10:23,960 --> 00:10:27,440
message latency or bandwidth and

00:10:25,700 --> 00:10:29,450
bi-directional bandwidth you will see we

00:10:27,440 --> 00:10:32,740
are able to deliver equal or better than

00:10:29,450 --> 00:10:34,700
the window the other other two stacks

00:10:32,740 --> 00:10:37,220
now that is the one just only

00:10:34,700 --> 00:10:39,080
point-to-point but that it's not always

00:10:37,220 --> 00:10:41,600
sufficient because when jobs are running

00:10:39,080 --> 00:10:43,460
it is also many times like multiplayer

00:10:41,600 --> 00:10:44,690
communications matter so this is a multi

00:10:43,460 --> 00:10:46,400
player latency it is a part of the

00:10:44,690 --> 00:10:47,990
virtual micro benchmarks all these

00:10:46,400 --> 00:10:49,010
numbers you yourself should also be able

00:10:47,990 --> 00:10:50,930
to reproduce

00:10:49,010 --> 00:10:53,630
okay these are using the standard

00:10:50,930 --> 00:10:55,850
benchmarks so multi pair so that means

00:10:53,630 --> 00:10:57,200
from a since we have more number of

00:10:55,850 --> 00:10:59,420
cores here and more number of course

00:10:57,200 --> 00:11:00,920
here in a typical application multiple

00:10:59,420 --> 00:11:03,050
pair communication can happen at the

00:11:00,920 --> 00:11:05,660
same time okay so this is what is being

00:11:03,050 --> 00:11:07,730
measured like a multi player latency so

00:11:05,660 --> 00:11:09,830
here what we have done like this is a

00:11:07,730 --> 00:11:11,570
this is our old design we have a new

00:11:09,830 --> 00:11:14,390
design I will be talking these are the

00:11:11,570 --> 00:11:16,670
maps to XP mem solution which is coming

00:11:14,390 --> 00:11:19,010
so again here you can see like spectrum

00:11:16,670 --> 00:11:21,590
guy openmpi we are able to deliver for

00:11:19,010 --> 00:11:23,420
short messages within the node when

00:11:21,590 --> 00:11:25,430
multiple cores are talking like forty

00:11:23,420 --> 00:11:27,970
eight to forty five percent benefit here

00:11:25,430 --> 00:11:30,710
like a 40 to 30 percent 45 percent

00:11:27,970 --> 00:11:32,450
benefits kind of things we can give at

00:11:30,710 --> 00:11:35,329
the basic communication

00:11:32,450 --> 00:11:38,149
so that is with respect to latency also

00:11:35,329 --> 00:11:40,310
for a applications with large messages

00:11:38,149 --> 00:11:41,779
the bandwidth also matters or even the

00:11:40,310 --> 00:11:44,360
small messages how much concurrent

00:11:41,779 --> 00:11:46,910
communications we can have so though it

00:11:44,360 --> 00:11:48,529
is the higher is better so here you can

00:11:46,910 --> 00:11:52,040
see when compared to the spectrum MPI

00:11:48,529 --> 00:11:56,269
and openmpi were able to deliver 1.6 1.8

00:11:52,040 --> 00:11:59,089
X or even 1.5 X 1 point 2 X kind of

00:11:56,269 --> 00:12:01,760
benefits we are able to give with with

00:11:59,089 --> 00:12:03,769
our design now especially with now

00:12:01,760 --> 00:12:05,870
multiple cores coming if those of you

00:12:03,769 --> 00:12:07,760
are very familiar with MPI you will see

00:12:05,870 --> 00:12:09,860
that not only we have course we also

00:12:07,760 --> 00:12:11,329
have a lot of threads so when you are

00:12:09,860 --> 00:12:13,070
trying to run a job you need to make

00:12:11,329 --> 00:12:14,870
sure that you are actually allocating

00:12:13,070 --> 00:12:16,760
the the cores and threads properly to

00:12:14,870 --> 00:12:18,170
your processes otherwise you will see

00:12:16,760 --> 00:12:20,019
over subscription and you may not get

00:12:18,170 --> 00:12:22,070
the best performance so in fact

00:12:20,019 --> 00:12:24,139
continuously we have been working in our

00:12:22,070 --> 00:12:26,029
library also in the community people

00:12:24,139 --> 00:12:28,250
have been coming up with better better

00:12:26,029 --> 00:12:30,769
like a binding policies here we had a

00:12:28,250 --> 00:12:34,029
ban scatter recently we have introduced

00:12:30,769 --> 00:12:36,920
like a hybrid policy with a neumann old

00:12:34,029 --> 00:12:38,240
i'll not go into more details here but

00:12:36,920 --> 00:12:40,550
these are all there in the user guide

00:12:38,240 --> 00:12:44,000
but especially we have taken the power 8

00:12:40,550 --> 00:12:46,760
kind of architectures and introduced a

00:12:44,000 --> 00:12:49,399
model or a binding policy which is

00:12:46,760 --> 00:12:51,350
called spread ok so it will try to

00:12:49,399 --> 00:12:53,480
actually make sure that the the

00:12:51,350 --> 00:12:55,640
processes which are like the nearby

00:12:53,480 --> 00:12:59,120
processes are being applied to physical

00:12:55,640 --> 00:13:01,579
cores without over subscribing and so

00:12:59,120 --> 00:13:03,800
that you can get better performance and

00:13:01,579 --> 00:13:06,490
these this kind of new schemes not only

00:13:03,800 --> 00:13:10,180
gets used in power 8 but also can i'll

00:13:06,490 --> 00:13:12,709
hyper-threaded jian kind of things and

00:13:10,180 --> 00:13:14,390
those are like the by default of course

00:13:12,709 --> 00:13:15,500
if you really want to squeeze

00:13:14,390 --> 00:13:17,029
performance and if you know the

00:13:15,500 --> 00:13:20,209
communication patterns you can also do

00:13:17,029 --> 00:13:22,940
your explicit binding very advanced

00:13:20,209 --> 00:13:25,670
users do those kind of stuff you can

00:13:22,940 --> 00:13:27,410
explicitly say ok this this process goes

00:13:25,670 --> 00:13:29,269
to this core this core this core kind of

00:13:27,410 --> 00:13:32,569
things I will just leave it here and

00:13:29,269 --> 00:13:34,790
then actually our user guide tells you

00:13:32,569 --> 00:13:36,949
all the details about what needs to be

00:13:34,790 --> 00:13:38,389
done now those are the kind of the basic

00:13:36,949 --> 00:13:40,220
point of point now many of you now you

00:13:38,389 --> 00:13:42,199
might be knowing a lot of applications

00:13:40,220 --> 00:13:45,040
especially in MPI and scientific

00:13:42,199 --> 00:13:45,040
applications car

00:13:45,660 --> 00:13:49,900
the performance is determined by the

00:13:48,610 --> 00:13:51,400
performance of collectives

00:13:49,900 --> 00:13:54,460
okay the collectives are like broadcast

00:13:51,400 --> 00:13:56,710
reduce all reduce all to all these kind

00:13:54,460 --> 00:13:58,900
of operations take a lot of time and if

00:13:56,710 --> 00:14:00,460
you don't optimize those libraries then

00:13:58,900 --> 00:14:02,470
you will see your job is not running

00:14:00,460 --> 00:14:04,720
efficiently on a very large scale system

00:14:02,470 --> 00:14:06,310
so so in my group in this Robby's

00:14:04,720 --> 00:14:08,260
project as well as a lot of other

00:14:06,310 --> 00:14:10,780
projects people continuously have been

00:14:08,260 --> 00:14:13,450
optimizing a lot of these collectives so

00:14:10,780 --> 00:14:16,900
one of them is like a based on a kernel

00:14:13,450 --> 00:14:19,420
module this is called CMA these days

00:14:16,900 --> 00:14:21,190
actually the cm x cross memory attach

00:14:19,420 --> 00:14:23,470
that has been there in the in the

00:14:21,190 --> 00:14:26,320
default Linux kernel so you can utilize

00:14:23,470 --> 00:14:29,740
that other NK libraries use but we have

00:14:26,320 --> 00:14:32,050
also done gone one step ahead because if

00:14:29,740 --> 00:14:34,810
you just use the CMA by default you will

00:14:32,050 --> 00:14:36,820
see a lot of contention and the locks so

00:14:34,810 --> 00:14:38,440
we have come up with a new generation of

00:14:36,820 --> 00:14:40,180
algorithms which avoids this kind of

00:14:38,440 --> 00:14:41,850
filling contention and then that's what

00:14:40,180 --> 00:14:43,990
you will see here like this is a reduce

00:14:41,850 --> 00:14:47,080
operation this is an alt well operation

00:14:43,990 --> 00:14:49,240
this is for short messages up to four

00:14:47,080 --> 00:14:51,610
kilobytes and then up to four kilo and

00:14:49,240 --> 00:14:53,230
then eight kilobytes to one megabytes so

00:14:51,610 --> 00:14:56,050
again you can see across those MPI

00:14:53,230 --> 00:14:58,240
libraries we can deliver you like almost

00:14:56,050 --> 00:15:00,910
a factor of five point two or three

00:14:58,240 --> 00:15:03,550
point six X improvement and similarly

00:15:00,910 --> 00:15:05,890
all to all you see factor 3 point 3 or 1

00:15:03,550 --> 00:15:08,400
point 2 X improvement okay by by using

00:15:05,890 --> 00:15:11,680
the libraries which we have in our lock

00:15:08,400 --> 00:15:13,690
and here also similar like a gathered

00:15:11,680 --> 00:15:16,150
scattered those are also the other kind

00:15:13,690 --> 00:15:18,400
of collectives gets used by many

00:15:16,150 --> 00:15:20,290
applications like taking data from a lot

00:15:18,400 --> 00:15:23,650
of nodes that is gathered or or you are

00:15:20,290 --> 00:15:26,230
trying to do the scatter so then this is

00:15:23,650 --> 00:15:28,480
that is within the node I showed now you

00:15:26,230 --> 00:15:30,190
can actually scale so that these are the

00:15:28,480 --> 00:15:32,410
nodes which are the multi node numbers

00:15:30,190 --> 00:15:34,690
here we are trying to show so now you

00:15:32,410 --> 00:15:38,170
can see like even a this is a experiment

00:15:34,690 --> 00:15:40,930
so we only did with a 4 node like PPN 20

00:15:38,170 --> 00:15:43,360
so up to 80 processes running across 4

00:15:40,930 --> 00:15:45,010
nodes so here you will see like we can

00:15:43,360 --> 00:15:49,600
actually give you even a factor of 12

00:15:45,010 --> 00:15:52,740
benefits 1.9 one point x 8.5 x benefit

00:15:49,600 --> 00:15:56,170
even in the very small scale system

00:15:52,740 --> 00:15:58,990
similar kind of benefits we see also for

00:15:56,170 --> 00:16:01,209
gather and scatter so then there is a

00:15:58,990 --> 00:16:02,800
next generation solutions we are trying

00:16:01,209 --> 00:16:04,750
to provide and these kind of solutions

00:16:02,800 --> 00:16:07,029
are not publicly available in a lot of

00:16:04,750 --> 00:16:10,680
other libraries this is called an XP mmm

00:16:07,029 --> 00:16:14,610
best solution Cray MPI has this kind of

00:16:10,680 --> 00:16:16,839
solutions but not in any other public

00:16:14,610 --> 00:16:19,480
open source libraries so we have new

00:16:16,839 --> 00:16:21,850
designs coming up so it actually tries

00:16:19,480 --> 00:16:24,940
to do a kernel but also is almost like a

00:16:21,850 --> 00:16:26,589
zero copy kind kind of schemes so that

00:16:24,940 --> 00:16:28,959
you can optimize the the collectives

00:16:26,589 --> 00:16:30,250
much more efficiently and so this has

00:16:28,959 --> 00:16:33,040
not been released it will be released

00:16:30,250 --> 00:16:35,470
soon so this the black line is our new

00:16:33,040 --> 00:16:37,540
design which is coming up so again here

00:16:35,470 --> 00:16:41,290
you can see that this is a package to

00:16:37,540 --> 00:16:44,470
all reduce with 20 PPN 20 people and two

00:16:41,290 --> 00:16:46,630
nodes similar kind of stories we can see

00:16:44,470 --> 00:16:48,490
that we can give you a factor of

00:16:46,630 --> 00:16:50,709
benefits here even if you go like a

00:16:48,490 --> 00:16:52,810
three nodes four nodes the same story

00:16:50,709 --> 00:16:56,290
goes along so that means we are able to

00:16:52,810 --> 00:16:58,990
provide you a scalable kind of edge

00:16:56,290 --> 00:17:01,750
solution the same thing also for reduce

00:16:58,990 --> 00:17:04,179
here you will see that in fact sometimes

00:17:01,750 --> 00:17:09,130
even we go up to like a factor of like

00:17:04,179 --> 00:17:12,910
5.6 X improvement and then this is for

00:17:09,130 --> 00:17:14,799
like a up to 80 processes you can try to

00:17:12,910 --> 00:17:17,199
see like even for very large messages

00:17:14,799 --> 00:17:18,790
eight megabytes 16 megabytes and these

00:17:17,199 --> 00:17:20,669
are becoming more important I'll talk

00:17:18,790 --> 00:17:22,540
query shown because of the deep learning

00:17:20,669 --> 00:17:24,819
applications they use very large

00:17:22,540 --> 00:17:26,980
messages so we need to also optimize

00:17:24,819 --> 00:17:29,679
these this large message size and this

00:17:26,980 --> 00:17:31,510
is what we have been doing to to give

00:17:29,679 --> 00:17:33,010
you the very good performance so those

00:17:31,510 --> 00:17:34,299
are like the micro benchmarks but if you

00:17:33,010 --> 00:17:36,370
see then the question is okay what

00:17:34,299 --> 00:17:38,650
happens with applications so here is the

00:17:36,370 --> 00:17:40,870
mini Amr performance so this is like a

00:17:38,650 --> 00:17:42,700
the the new move experiments based

00:17:40,870 --> 00:17:45,040
collectives so now you can see at an

00:17:42,700 --> 00:17:46,360
application level okay we are able to

00:17:45,040 --> 00:17:49,030
give you benefits like when a ten

00:17:46,360 --> 00:17:51,870
process up to sixty process 40% benefit

00:17:49,030 --> 00:17:55,059
if you use this our library with these

00:17:51,870 --> 00:17:57,190
mechanisms so let me then quickly move

00:17:55,059 --> 00:17:58,990
forward so those are the basic MPI we

00:17:57,190 --> 00:18:02,350
also provide support as I said for the

00:17:58,990 --> 00:18:04,750
basic P gas P gas means here we can have

00:18:02,350 --> 00:18:07,600
like a this stack actually is very

00:18:04,750 --> 00:18:09,500
flexible it has been there since 2012 it

00:18:07,600 --> 00:18:11,720
provides complete flexibility you can

00:18:09,500 --> 00:18:13,490
the stack to have your application

00:18:11,720 --> 00:18:16,970
written with pure NPI or pure opens

00:18:13,490 --> 00:18:19,790
ma'am pure LPC you can mix and match MPI

00:18:16,970 --> 00:18:22,160
OpenMP open spam you can just play

00:18:19,790 --> 00:18:24,560
around with it any combinations to see

00:18:22,160 --> 00:18:26,690
that your application runs best on this

00:18:24,560 --> 00:18:28,670
platform so these are the very latest

00:18:26,690 --> 00:18:30,710
number this from the public version of

00:18:28,670 --> 00:18:32,480
the release these are the opens man

00:18:30,710 --> 00:18:34,280
which is another industry consortium

00:18:32,480 --> 00:18:36,500
where they are trying to provide the

00:18:34,280 --> 00:18:39,110
same standard so you can see spam get

00:18:36,500 --> 00:18:41,600
input with very low performance very low

00:18:39,110 --> 00:18:44,630
latency we can try to give you here like

00:18:41,600 --> 00:18:47,180
a in chronoed like a point zero one a

00:18:44,630 --> 00:18:49,960
point one microsecond kind of thing so

00:18:47,180 --> 00:18:52,820
so almost bare metal we can give you

00:18:49,960 --> 00:18:56,120
performance for these open spam light

00:18:52,820 --> 00:18:59,620
here it is UPC put and gate we also

00:18:56,120 --> 00:19:02,090
support UV C++ that also you can provide

00:18:59,620 --> 00:19:04,100
so then the broad thing is that how we

00:19:02,090 --> 00:19:07,220
can integrate this kind of things with

00:19:04,100 --> 00:19:09,080
GPUs okay now how many of you heard like

00:19:07,220 --> 00:19:11,300
you've done some GPU work like hey there

00:19:09,080 --> 00:19:14,270
is a common terminology these days

00:19:11,300 --> 00:19:17,290
called CUDA where MPI or CUDA where a

00:19:14,270 --> 00:19:19,730
runtime anyone of you familiar with that

00:19:17,290 --> 00:19:21,590
okay so in fact this is the term

00:19:19,730 --> 00:19:23,900
actually we will introduced in my group

00:19:21,590 --> 00:19:26,660
almost seven years back in our classic

00:19:23,900 --> 00:19:29,570
we are the IC 2010 paper so the question

00:19:26,660 --> 00:19:30,980
we asked that if anybody has done CUDA

00:19:29,570 --> 00:19:32,240
programming most of the time you know

00:19:30,980 --> 00:19:34,610
like let's say you have a system like

00:19:32,240 --> 00:19:36,890
this we have a GPU InfiniBand you

00:19:34,610 --> 00:19:39,830
typically do a CUDA copy to the host

00:19:36,890 --> 00:19:41,960
memory then do MPI and then after you do

00:19:39,830 --> 00:19:45,050
another CUDA copy so that means the end

00:19:41,960 --> 00:19:47,630
user needs to know about learn about

00:19:45,050 --> 00:19:50,090
CUDA so we indicated that okay you can

00:19:47,630 --> 00:19:51,650
do a very quick programming but it is

00:19:50,090 --> 00:19:53,570
not highly productive because the end

00:19:51,650 --> 00:19:55,010
engineers and scientists you need to

00:19:53,570 --> 00:19:57,320
learn about CUDA you need to know about

00:19:55,010 --> 00:19:58,970
what GPU performance all those things so

00:19:57,320 --> 00:20:01,460
we ask the question that can you do it

00:19:58,970 --> 00:20:03,920
in a very transparent manner so that

00:20:01,460 --> 00:20:05,390
means the end engineer or scientist if

00:20:03,920 --> 00:20:07,820
you know how to do a basic MCA

00:20:05,390 --> 00:20:09,020
programming from host that's all you

00:20:07,820 --> 00:20:10,370
need to do you don't need to learn

00:20:09,020 --> 00:20:12,830
anything else just like instead of

00:20:10,370 --> 00:20:15,110
saying imply send from host memory you

00:20:12,830 --> 00:20:18,679
say imply send from device via for or

00:20:15,110 --> 00:20:20,090
API received from device buffer and then

00:20:18,679 --> 00:20:22,130
you see the animation everything else

00:20:20,090 --> 00:20:24,140
and play library will take care

00:20:22,130 --> 00:20:26,240
okay so that will give you the best

00:20:24,140 --> 00:20:28,070
performance and productivity so that's

00:20:26,240 --> 00:20:30,620
what we have been working almost for

00:20:28,070 --> 00:20:32,500
last seven years continuously working

00:20:30,620 --> 00:20:35,000
like we do very close collaboration with

00:20:32,500 --> 00:20:37,250
mallanna asari Mellanox for infinite

00:20:35,000 --> 00:20:39,620
side of course in this angle with NVIDIA

00:20:37,250 --> 00:20:43,190
under funding we take the very latest

00:20:39,620 --> 00:20:45,230
and greatest from their architectures

00:20:43,190 --> 00:20:46,520
and then try to deliver the performance

00:20:45,230 --> 00:20:48,830
so now if you take a look at these

00:20:46,520 --> 00:20:50,750
numbers this is what like we have an

00:20:48,830 --> 00:20:52,789
optimizing map is two DDR library or a

00:20:50,750 --> 00:20:56,059
GPU direct cardema library look at this

00:20:52,789 --> 00:20:58,010
number one point eighty microsecond we

00:20:56,059 --> 00:21:01,580
can actually send data from one GPU

00:20:58,010 --> 00:21:04,460
going over network over switch adapter

00:21:01,580 --> 00:21:06,650
to the other GPU in 1.88 microsecond

00:21:04,460 --> 00:21:08,900
okay in fact I am very proud of my team

00:21:06,650 --> 00:21:12,260
who has done the design and also there

00:21:08,900 --> 00:21:13,789
is no other MPI stack in the world which

00:21:12,260 --> 00:21:16,190
can deliver you this kind of performance

00:21:13,789 --> 00:21:18,650
okay so these targets very widely used

00:21:16,190 --> 00:21:20,900
in all GPU platforms in here you can see

00:21:18,650 --> 00:21:22,760
like hoondi blue which is a molecular

00:21:20,900 --> 00:21:25,370
dynamics kind of applications it gives

00:21:22,760 --> 00:21:28,549
benefits by a factor of two kind of

00:21:25,370 --> 00:21:31,190
thing at an application and in fact next

00:21:28,549 --> 00:21:32,480
time you are in Europe in Switzerland or

00:21:31,190 --> 00:21:35,240
if you have been to Switzerland for the

00:21:32,480 --> 00:21:36,559
last five years we actually really

00:21:35,240 --> 00:21:38,809
helped them to have the real-time

00:21:36,559 --> 00:21:41,030
weather prediction in Switzerland if you

00:21:38,809 --> 00:21:43,429
open up your iPhone and see the weather

00:21:41,030 --> 00:21:44,570
we are actually delivering that using

00:21:43,429 --> 00:21:46,640
our stack so very three-way

00:21:44,570 --> 00:21:48,260
collaboration going on between us and

00:21:46,640 --> 00:21:50,710
Switzerland supercomputing Center and

00:21:48,260 --> 00:21:53,600
mature Swiss who were there organiser

00:21:50,710 --> 00:21:55,250
from the meteorology department so we

00:21:53,600 --> 00:21:58,909
three-way we do the collaboration to

00:21:55,250 --> 00:22:00,409
give you the best performance there so

00:21:58,909 --> 00:22:02,870
those are under like the numbers I

00:22:00,409 --> 00:22:04,730
showed on the x86 but now you must have

00:22:02,870 --> 00:22:07,070
seen like this open power is being now

00:22:04,730 --> 00:22:08,750
used in the very the two larger systems

00:22:07,070 --> 00:22:11,780
which are coming out the coral systems

00:22:08,750 --> 00:22:14,270
in the US Department of Energy these are

00:22:11,780 --> 00:22:16,090
the Sierra kind of things so these

00:22:14,270 --> 00:22:19,429
numbers are taken from similar kind of

00:22:16,090 --> 00:22:21,440
systems of course this is a power eight

00:22:19,429 --> 00:22:24,590
the power 9 which is just being deployed

00:22:21,440 --> 00:22:26,210
in the actual Sierra systems they don't

00:22:24,590 --> 00:22:28,549
have the GPU direct our DMA so that's

00:22:26,210 --> 00:22:30,679
why the latency is higher once the power

00:22:28,549 --> 00:22:32,299
nine will have G few direct our DMA you

00:22:30,679 --> 00:22:34,130
will see it's the performance what I

00:22:32,299 --> 00:22:35,419
showed earlier but if you see the

00:22:34,130 --> 00:22:35,990
bandwidth so this is where we've

00:22:35,419 --> 00:22:38,810
supported

00:22:35,990 --> 00:22:41,390
we link see the 33.9 gigabytes per

00:22:38,810 --> 00:22:43,430
second MPA level performance we can

00:22:41,390 --> 00:22:45,740
actually give from one GPU to the other

00:22:43,430 --> 00:22:48,260
GPU okay so we are able to exploit that

00:22:45,740 --> 00:22:51,710
kind of feature and then of course the

00:22:48,260 --> 00:22:54,260
internode these are the InfiniBand EDR

00:22:51,710 --> 00:22:57,410
so we are able to saturate that with the

00:22:54,260 --> 00:22:59,510
the 12.5 kilobytes per second so so this

00:22:57,410 --> 00:23:01,340
is a broad like a rapid project like as

00:22:59,510 --> 00:23:03,380
we have been working on these we

00:23:01,340 --> 00:23:05,600
actually not only provide some

00:23:03,380 --> 00:23:07,190
individual solution some of you are not

00:23:05,600 --> 00:23:09,170
familiar over the years now we have done

00:23:07,190 --> 00:23:11,780
a lot of best practices because this

00:23:09,170 --> 00:23:14,180
library gets widely used so if you are

00:23:11,780 --> 00:23:16,850
using one particular kind of an empty

00:23:14,180 --> 00:23:18,140
application and you want to to tune of

00:23:16,850 --> 00:23:20,570
course Impa library has so many

00:23:18,140 --> 00:23:22,940
parameters so we are actually this is a

00:23:20,570 --> 00:23:24,260
community effort I just want to share so

00:23:22,940 --> 00:23:26,750
you can actually take a look at these

00:23:24,260 --> 00:23:28,460
and then if you want to contribute your

00:23:26,750 --> 00:23:31,790
tuning and all those things we can also

00:23:28,460 --> 00:23:34,370
actually add it with your cut so now let

00:23:31,790 --> 00:23:36,170
me move try to finalize the the deep

00:23:34,370 --> 00:23:38,360
learning part as many of you know the

00:23:36,170 --> 00:23:40,280
deep loading has multiple roots the deep

00:23:38,360 --> 00:23:41,810
learning One Direction is going purely

00:23:40,280 --> 00:23:43,730
through MPI that's what I will try to

00:23:41,810 --> 00:23:45,980
focus here of course through Big Data

00:23:43,730 --> 00:23:47,450
also it is going on there is also tensor

00:23:45,980 --> 00:23:50,120
flow those are the things we'll talk in

00:23:47,450 --> 00:23:52,340
the in the other talk so broadly in the

00:23:50,120 --> 00:23:54,770
community this is the biggest challenge

00:23:52,340 --> 00:23:57,320
which is happening because the the deep

00:23:54,770 --> 00:23:58,370
learning frameworks are using very large

00:23:57,320 --> 00:23:59,690
message exchange

00:23:58,370 --> 00:24:01,400
so typically am player library has been

00:23:59,690 --> 00:24:03,050
optimized for short messages video

00:24:01,400 --> 00:24:04,880
messages so here you need to totally

00:24:03,050 --> 00:24:06,740
rethink how to optimize the large

00:24:04,880 --> 00:24:09,110
messages that's what I showed in the

00:24:06,740 --> 00:24:10,820
first part and then the question is how

00:24:09,110 --> 00:24:12,830
we can achieve scale up and scale out

00:24:10,820 --> 00:24:16,730
and then people have been working on all

00:24:12,830 --> 00:24:18,830
different kinds of solutions so for the

00:24:16,730 --> 00:24:21,230
most of the deep learning applications

00:24:18,830 --> 00:24:23,180
use reduce already use some of them

00:24:21,230 --> 00:24:25,100
because so that's what exactly what we

00:24:23,180 --> 00:24:27,110
have done in our GPU version of the

00:24:25,100 --> 00:24:29,810
library this is publicly available we

00:24:27,110 --> 00:24:31,820
have optimized all these collectives and

00:24:29,810 --> 00:24:33,530
continuously we optimized because now

00:24:31,820 --> 00:24:35,060
now you see the width and we link things

00:24:33,530 --> 00:24:37,340
are becoming different the cost model is

00:24:35,060 --> 00:24:39,140
changing or with a Voltas you may see

00:24:37,340 --> 00:24:41,690
some little bit of difference so we

00:24:39,140 --> 00:24:44,330
continuously take advantage of those and

00:24:41,690 --> 00:24:46,340
then optimize and then also here I am

00:24:44,330 --> 00:24:47,600
trying to show some comparison in the

00:24:46,340 --> 00:24:49,549
community might be on

00:24:47,600 --> 00:24:51,710
knowing saying Baidu as if I do already

00:24:49,549 --> 00:24:53,570
use so the question is and then nickel

00:24:51,710 --> 00:24:55,730
to a lot of these kind of libraries are

00:24:53,570 --> 00:24:57,049
coming up I actually want to show some

00:24:55,730 --> 00:24:59,510
numbers here so if you see this is

00:24:57,049 --> 00:25:01,309
comparison with Baidu and openmpi so now

00:24:59,510 --> 00:25:03,620
you can see that we can actually give

00:25:01,309 --> 00:25:05,179
you an even this is the by do this demap

00:25:03,620 --> 00:25:07,940
is too we can give you almost a factor

00:25:05,179 --> 00:25:09,530
of ten three point five or even a very

00:25:07,940 --> 00:25:12,080
large my says also twenty percent

00:25:09,530 --> 00:25:14,750
benefit okay so if you use our library

00:25:12,080 --> 00:25:16,490
and then do the already use same thing

00:25:14,750 --> 00:25:18,650
here also happens this is for sixteen

00:25:16,490 --> 00:25:21,559
GPUs similar kind of things you can see

00:25:18,650 --> 00:25:22,720
like a factor of 30 X for X kind of

00:25:21,559 --> 00:25:25,909
things better

00:25:22,720 --> 00:25:28,190
using our approach this is with nickel 2

00:25:25,909 --> 00:25:31,130
this is coming up I just want to clarify

00:25:28,190 --> 00:25:33,020
so the nickel 2 as such also doesn't run

00:25:31,130 --> 00:25:35,120
on open power so these are on x86

00:25:33,020 --> 00:25:37,159
platform there are some library

00:25:35,120 --> 00:25:39,590
dependencies and also once gets resolved

00:25:37,159 --> 00:25:42,860
we'll be able to now see the numbers on

00:25:39,590 --> 00:25:44,690
open power but under x86 if you see here

00:25:42,860 --> 00:25:46,669
we are able to even do compared to n

00:25:44,690 --> 00:25:49,130
equal to 4 small messages we get

00:25:46,669 --> 00:25:52,820
connects better here 4x better kind of

00:25:49,130 --> 00:25:54,559
things compared to that ok we also have

00:25:52,820 --> 00:25:56,240
a not only just optimize the entire

00:25:54,559 --> 00:25:58,760
layer we also do a lot of cool designing

00:25:56,240 --> 00:26:00,799
we have actually a version of cafe

00:25:58,760 --> 00:26:03,020
called wushu cafe you can actually

00:26:00,799 --> 00:26:04,909
download this was we released it almost

00:26:03,020 --> 00:26:08,809
two years back at that time we were able

00:26:04,909 --> 00:26:12,950
to have to scale up to 128 160 GPUs ok

00:26:08,809 --> 00:26:14,390
and and and this and currently we are

00:26:12,950 --> 00:26:16,700
actually trying to make it open power

00:26:14,390 --> 00:26:18,169
again there are a lot of dependencies in

00:26:16,700 --> 00:26:20,330
the morning we heard a lot of these

00:26:18,169 --> 00:26:22,120
tools need to be redesigned for open

00:26:20,330 --> 00:26:24,860
power then we should be able to directly

00:26:22,120 --> 00:26:27,799
run it on these so with this let me

00:26:24,860 --> 00:26:29,330
conclude here as we know like the next

00:26:27,799 --> 00:26:31,460
generation HPC systems need to be

00:26:29,330 --> 00:26:33,350
designed with a holistic view of the big

00:26:31,460 --> 00:26:35,380
data and also deep learning you cannot

00:26:33,350 --> 00:26:38,000
just look at the just the pure HPC and

00:26:35,380 --> 00:26:40,280
open power platform is de merging with

00:26:38,000 --> 00:26:42,169
many novel features so I presented some

00:26:40,280 --> 00:26:44,450
of the approaches and results here from

00:26:42,169 --> 00:26:46,370
our map is to and ideal projects and

00:26:44,450 --> 00:26:48,740
these solutions actually enable the

00:26:46,370 --> 00:26:51,020
hyper phones and scalable HPC and deep

00:26:48,740 --> 00:26:52,760
learning so as I said earlier from my

00:26:51,020 --> 00:26:55,429
group we have also done similar kind of

00:26:52,760 --> 00:26:58,250
things for Hadoop spark those are like

00:26:55,429 --> 00:26:59,930
the big data software stacks so myself

00:26:58,250 --> 00:27:03,710
and dr. Jia will do with sitting

00:26:59,930 --> 00:27:05,900
we'll talk in at 2:15 in the room 307

00:27:03,710 --> 00:27:08,780
with this let me just thank all our

00:27:05,900 --> 00:27:11,120
sponsors but more importantly these are

00:27:08,780 --> 00:27:12,800
all my heroes I just come and give a

00:27:11,120 --> 00:27:15,260
talk what you are actually hearing is

00:27:12,800 --> 00:27:17,480
this 17 years of work which we are

00:27:15,260 --> 00:27:20,480
continuously working in my group so and

00:27:17,480 --> 00:27:23,000
so all these people get the credit so

00:27:20,480 --> 00:27:25,070
with this let me stop here and if there

00:27:23,000 --> 00:27:31,060
are any quick questions I'll be happy to

00:27:25,070 --> 00:27:31,060
answer any quick questions

00:27:44,450 --> 00:27:49,260
it is not a single thing as I said like

00:27:47,130 --> 00:27:51,179
if you take an MPI library there are so

00:27:49,260 --> 00:27:53,130
many components okay

00:27:51,179 --> 00:27:55,140
so what we have been doing it's a again

00:27:53,130 --> 00:27:58,799
a holistic approach we try to make sure

00:27:55,140 --> 00:28:00,480
that each and every thing is optimized

00:27:58,799 --> 00:28:02,580
okay because when you give it to a

00:28:00,480 --> 00:28:04,710
public person that's what we like a lot

00:28:02,580 --> 00:28:06,960
of people all over the world use the our

00:28:04,710 --> 00:28:08,429
stack because every application has its

00:28:06,960 --> 00:28:10,799
own different communication computation

00:28:08,429 --> 00:28:16,650
factor so we want to make sure that all

00:28:10,799 --> 00:28:20,669
those applications get benefited very

00:28:16,650 --> 00:28:23,130
detailed yes yes so yes I mean we as I

00:28:20,669 --> 00:28:25,290
saw like sometimes I mean we we are

00:28:23,130 --> 00:28:27,630
showing like a number of like a 300

00:28:25,290 --> 00:28:30,510
nanoseconds you know so we operate at

00:28:27,630 --> 00:28:32,490
that level and continuously optimize and

00:28:30,510 --> 00:28:33,600
not just the basic performance in the

00:28:32,490 --> 00:28:36,690
scalability we have been in this

00:28:33,600 --> 00:28:39,480
community for 16 years as I said when I

00:28:36,690 --> 00:28:41,400
had the first software stack infiniment

00:28:39,480 --> 00:28:43,440
systems were not even running on two

00:28:41,400 --> 00:28:45,510
nodes four nodes and now it is running a

00:28:43,440 --> 00:28:46,980
hundred petaflop machines the number one

00:28:45,510 --> 00:28:48,870
so we have been in the community and

00:28:46,980 --> 00:28:54,470
enabling all these things over the last

00:28:48,870 --> 00:28:54,470
17 years yes

00:29:02,640 --> 00:29:08,760
I think single GPU might see some

00:29:06,570 --> 00:29:11,610
benefits but we always like focus on the

00:29:08,760 --> 00:29:13,380
distributed thing or you will not just

00:29:11,610 --> 00:29:15,990
you can say like a scaler if you have

00:29:13,380 --> 00:29:19,080
multiple GPUs within the node we provide

00:29:15,990 --> 00:29:20,820
very good support but if you just say

00:29:19,080 --> 00:29:23,070
have a single GPU then there is not any

00:29:20,820 --> 00:29:24,720
external communication is happening so

00:29:23,070 --> 00:29:29,940
whenever communication comes we are

00:29:24,720 --> 00:29:32,390
there to actually optimize any other

00:29:29,940 --> 00:29:32,390
questions

00:29:33,060 --> 00:29:36,230
[Music]

00:29:37,010 --> 00:29:42,470
yes yes it is in there my groups and I'm

00:29:40,460 --> 00:29:44,600
a part of the Ohio State so these are

00:29:42,470 --> 00:29:49,149
all the software's from my research

00:29:44,600 --> 00:29:49,149
group yes

00:29:52,330 --> 00:29:59,250
okay thank you then

00:29:54,340 --> 00:29:59,250

YouTube URL: https://www.youtube.com/watch?v=92tqB6NCbig


