Title: OpenPOWER Summit US 2018: GPU Accelerated Data Processing - Brytlyt
Publication date: 2018-04-03
Playlist: OpenPOWER Summit US 2018
Description: 
	Richard Heyns, Founder, Brytlyt, discusses GPU accelerated data processing and the speed of thought analytics at scale at OpenPOWER Summit 2018.

For more information, please visit: http://www.openpowerfoundation.org
Captions: 
	00:00:00,000 --> 00:00:05,310
mr. Richard Haines I'm the founder and

00:00:02,040 --> 00:00:07,680
CEO of bright light and what I'm going

00:00:05,310 --> 00:00:10,370
to be talking about today is our

00:00:07,680 --> 00:00:14,519
gpu-accelerated database and our

00:00:10,370 --> 00:00:17,750
visualization workbench let's take a

00:00:14,519 --> 00:00:21,869
users GPX L eration for analytics so

00:00:17,750 --> 00:00:26,939
just a show of hands who is familiar

00:00:21,869 --> 00:00:32,640
with GPUs good good good ok good stuff

00:00:26,939 --> 00:00:35,040
right so GPUs are being used for a

00:00:32,640 --> 00:00:38,399
number of years for non graphic

00:00:35,040 --> 00:00:41,730
workloads and what bright light does is

00:00:38,399 --> 00:00:45,180
use GPS for sequel workloads so

00:00:41,730 --> 00:00:47,399
relational databases the gpu-accelerated

00:00:45,180 --> 00:00:49,140
database is the next evolution in

00:00:47,399 --> 00:00:51,059
high-performance databases right in the

00:00:49,140 --> 00:00:54,539
beginning at punch cards and the most

00:00:51,059 --> 00:00:57,360
recent soar in-memory solutions and the

00:00:54,539 --> 00:01:00,840
GP accelerated solution is taking that

00:00:57,360 --> 00:01:03,660
to the next level two reasons why one is

00:01:00,840 --> 00:01:05,700
the fantastic competes that GPUs have

00:01:03,660 --> 00:01:08,220
available so that's that graphic peak

00:01:05,700 --> 00:01:13,290
flops the orange line is GPUs compared

00:01:08,220 --> 00:01:16,130
to a high-end CPU system at the time the

00:01:13,290 --> 00:01:19,770
blue line in that is Moore's law GPS are

00:01:16,130 --> 00:01:21,689
outstripping Moore's law in acceleration

00:01:19,770 --> 00:01:24,659
which is which is pretty impressive the

00:01:21,689 --> 00:01:26,670
other graphic there is memory bandwidth

00:01:24,659 --> 00:01:28,950
and that's really important for

00:01:26,670 --> 00:01:31,890
databases because it's actually how

00:01:28,950 --> 00:01:33,869
quickly you can get data on to the the

00:01:31,890 --> 00:01:35,880
cores and processed that really matters

00:01:33,869 --> 00:01:38,280
and we are seeing performance

00:01:35,880 --> 00:01:39,869
improvements of around about 300 X on a

00:01:38,280 --> 00:01:42,930
standard this base solution that you

00:01:39,869 --> 00:01:44,520
might get from Oracle or Microsoft 300 x

00:01:42,930 --> 00:01:46,350
is pretty significant it means that a

00:01:44,520 --> 00:01:49,259
query that might run in five hours can

00:01:46,350 --> 00:01:52,590
now run in under a minute why is that

00:01:49,259 --> 00:01:54,930
important well this guy over here finds

00:01:52,590 --> 00:01:58,079
it really really useful almost

00:01:54,930 --> 00:01:59,700
two-thirds of a data scientists time or

00:01:58,079 --> 00:02:02,159
an analysts time is spent actually

00:01:59,700 --> 00:02:05,009
working with the preparing data only

00:02:02,159 --> 00:02:06,799
three days a month is spent on the

00:02:05,009 --> 00:02:10,530
interesting stuff which is mining and

00:02:06,799 --> 00:02:11,550
refining algorithms almost 40% of

00:02:10,530 --> 00:02:15,660
analysts

00:02:11,550 --> 00:02:17,880
time it takes more than a week to

00:02:15,660 --> 00:02:19,050
generate a piece of insight so somebody

00:02:17,880 --> 00:02:21,840
comes in on a Monday morning with a

00:02:19,050 --> 00:02:23,910
bright idea and by the end of the week

00:02:21,840 --> 00:02:27,300
Friday afternoon they go home and they

00:02:23,910 --> 00:02:29,010
still haven't yet resolved that idea or

00:02:27,300 --> 00:02:32,670
dug down to the bottom of it and

00:02:29,010 --> 00:02:35,040
interestingly sequel is still the most

00:02:32,670 --> 00:02:38,370
common technology used in data science

00:02:35,040 --> 00:02:41,460
and data processing that was from a

00:02:38,370 --> 00:02:43,500
survey a recent survey the two other key

00:02:41,460 --> 00:02:46,550
points that came out of the survey keep

00:02:43,500 --> 00:02:51,020
pain points the first is the most

00:02:46,550 --> 00:02:53,190
biggest pain point is flexibility in how

00:02:51,020 --> 00:02:55,800
useful the tools are after data

00:02:53,190 --> 00:02:56,790
scientists and the second pain point

00:02:55,800 --> 00:02:59,550
second most important one was

00:02:56,790 --> 00:03:00,930
performance so one in three analysts

00:02:59,550 --> 00:03:03,060
were saying that they had to deal with

00:03:00,930 --> 00:03:06,030
slow running queries and it's very

00:03:03,060 --> 00:03:10,920
likely that these two pain points is the

00:03:06,030 --> 00:03:15,510
reason why it's taking so long to turn

00:03:10,920 --> 00:03:17,280
data into insight time to value right so

00:03:15,510 --> 00:03:19,320
what we're talking about will basically

00:03:17,280 --> 00:03:21,750
analyzing billions of rows of data in

00:03:19,320 --> 00:03:25,230
milliseconds and that's really important

00:03:21,750 --> 00:03:27,000
for two groups of users one our business

00:03:25,230 --> 00:03:29,550
business leaders and decision makers or

00:03:27,000 --> 00:03:33,030
using dashboards to give them up-to-date

00:03:29,550 --> 00:03:35,430
information in contextual awareness and

00:03:33,030 --> 00:03:36,959
situational awareness and also analysts

00:03:35,430 --> 00:03:41,459
and data scientists who day-in day-out

00:03:36,959 --> 00:03:43,290
are working with data and finding that

00:03:41,459 --> 00:03:46,830
that is just taking up a huge amount of

00:03:43,290 --> 00:03:50,130
their time so this requires a radical

00:03:46,830 --> 00:03:52,340
new think in the status quo and just to

00:03:50,130 --> 00:03:56,250
get a perspective on half fast

00:03:52,340 --> 00:03:59,040
ultra-fast is if you think of Usain Bolt

00:03:56,250 --> 00:04:01,680
world's fastest man in the starters'

00:03:59,040 --> 00:04:05,190
blocks and the starter's gun goes off it

00:04:01,680 --> 00:04:09,030
takes Usain Bolt about 155 milliseconds

00:04:05,190 --> 00:04:11,010
just to start moving and if he moved any

00:04:09,030 --> 00:04:13,680
sooner you would be disqualified because

00:04:11,010 --> 00:04:16,650
human perception is in the realm of 120

00:04:13,680 --> 00:04:18,180
milliseconds and in that time in 5

00:04:16,650 --> 00:04:21,130
milliseconds in fact for some of the

00:04:18,180 --> 00:04:26,110
workloads we've been able to process

00:04:21,130 --> 00:04:29,460
1.1 billion rows of data the great thing

00:04:26,110 --> 00:04:32,140
about GPUs is that they paralysed

00:04:29,460 --> 00:04:33,790
thousands and thousands of cause and

00:04:32,140 --> 00:04:35,860
that's where they get their fantastic

00:04:33,790 --> 00:04:39,100
complete characteristics from but it

00:04:35,860 --> 00:04:40,930
also is a real technology challenge that

00:04:39,100 --> 00:04:43,870
needs to be able to come there and

00:04:40,930 --> 00:04:45,310
bright light is the only vendor in the

00:04:43,870 --> 00:04:47,860
space to have patent-pending

00:04:45,310 --> 00:04:51,180
intellectual property to address these

00:04:47,860 --> 00:04:53,800
kinds of paralyzed herbal challenges

00:04:51,180 --> 00:04:56,770
we've done some benchmarking against

00:04:53,800 --> 00:04:58,930
other vendors in this space

00:04:56,770 --> 00:05:01,950
this is an independent benchmark run by

00:04:58,930 --> 00:05:05,320
a third-party same query same data sets

00:05:01,950 --> 00:05:07,360
those times are in milliseconds 1.1

00:05:05,320 --> 00:05:10,330
billion rows of theta ok fairly

00:05:07,360 --> 00:05:13,630
straightforward types of queries but we

00:05:10,330 --> 00:05:15,940
were using indexes on the GPS to really

00:05:13,630 --> 00:05:17,890
accelerate performance and this shows

00:05:15,940 --> 00:05:21,940
that we are between four and five times

00:05:17,890 --> 00:05:24,250
faster than other GPU vendors and

00:05:21,940 --> 00:05:25,870
bearing in mind that the GPU space is

00:05:24,250 --> 00:05:29,230
already exceptionally fast this is a

00:05:25,870 --> 00:05:30,670
fantastic accomplishment there it's not

00:05:29,230 --> 00:05:32,890
just indexing that allows us to run

00:05:30,670 --> 00:05:36,100
really fast these queries were run

00:05:32,890 --> 00:05:40,530
without indexing and still significantly

00:05:36,100 --> 00:05:42,730
faster than other vendors in this space

00:05:40,530 --> 00:05:46,150
just a little bit about indexing because

00:05:42,730 --> 00:05:49,180
it's all in memory and in GPU Ram our

00:05:46,150 --> 00:05:50,710
indexing is based on pointers and so

00:05:49,180 --> 00:05:53,410
whether you create an index on one

00:05:50,710 --> 00:05:55,630
column or if you create covering index

00:05:53,410 --> 00:05:58,060
on a number of columns the size of the

00:05:55,630 --> 00:06:00,790
index is actually the same and also a

00:05:58,060 --> 00:06:02,140
relatively small which is different to

00:06:00,790 --> 00:06:04,030
what you'd normally see in a disk based

00:06:02,140 --> 00:06:05,680
solution in a display solution you

00:06:04,030 --> 00:06:08,410
actually make an entire new copy of the

00:06:05,680 --> 00:06:13,240
data and rearrange it in a way that

00:06:08,410 --> 00:06:15,820
makes sense for accessing it one of the

00:06:13,240 --> 00:06:17,170
strengths within our IP the

00:06:15,820 --> 00:06:20,020
patent-pending IP that I talked about

00:06:17,170 --> 00:06:22,780
earlier is our ability to do joins fast

00:06:20,020 --> 00:06:24,190
joins on GPU so it joins is one of the

00:06:22,780 --> 00:06:25,870
things that is really difficult to do in

00:06:24,190 --> 00:06:27,780
parallel sorting is quite easy

00:06:25,870 --> 00:06:32,200
aggregating is quite easy grouping is

00:06:27,780 --> 00:06:33,880
perform of sort but joins when you're

00:06:32,200 --> 00:06:35,590
bringing different tables together

00:06:33,880 --> 00:06:39,460
is actually really difficult to do in

00:06:35,590 --> 00:06:42,640
parallel and quickly and so this is you

00:06:39,460 --> 00:06:44,500
know the TP CH dataset but just to give

00:06:42,640 --> 00:06:47,110
you an idea of tables and joins and so

00:06:44,500 --> 00:06:49,660
on so what does that leave you with well

00:06:47,110 --> 00:06:51,730
extreme performance that was the key

00:06:49,660 --> 00:06:54,070
element the key goal that we set

00:06:51,730 --> 00:06:56,860
ourselves when he started out but we

00:06:54,070 --> 00:06:58,780
actually set ourselves a constitution if

00:06:56,860 --> 00:07:00,610
you like three or four goals that we

00:06:58,780 --> 00:07:02,260
wanted to achieve with bright lights

00:07:00,610 --> 00:07:05,200
the first was real-time performance and

00:07:02,260 --> 00:07:07,600
we get that from the GPUs the second was

00:07:05,200 --> 00:07:09,280
to be able to easily integrate what

00:07:07,600 --> 00:07:12,160
we've got with existing investments and

00:07:09,280 --> 00:07:12,670
technology and infrastructure be easy to

00:07:12,160 --> 00:07:15,190
use

00:07:12,670 --> 00:07:17,650
and also be easy to extend and are those

00:07:15,190 --> 00:07:19,090
last three all come from the fact that

00:07:17,650 --> 00:07:22,750
we've actually integrated with post

00:07:19,090 --> 00:07:24,790
grades so we've taken our technology and

00:07:22,750 --> 00:07:26,290
rewritten large parts of the post player

00:07:24,790 --> 00:07:28,180
source code that the post grades

00:07:26,290 --> 00:07:30,220
database engine so from a user

00:07:28,180 --> 00:07:32,890
perspective what you're looking and

00:07:30,220 --> 00:07:34,570
working with this Postgres and all the

00:07:32,890 --> 00:07:35,710
tools and connectors and stuff that you

00:07:34,570 --> 00:07:37,510
get from post grades you'll get off the

00:07:35,710 --> 00:07:40,150
box with bright lights but the back end

00:07:37,510 --> 00:07:44,440
the engine actually runs on GPU so you

00:07:40,150 --> 00:07:47,470
know significantly faster if you drill

00:07:44,440 --> 00:07:51,150
down into what the user is actually

00:07:47,470 --> 00:07:53,350
going to be dealing with in the orange

00:07:51,150 --> 00:07:56,560
block you've got the bright light

00:07:53,350 --> 00:07:58,450
software running on GPUs and that's

00:07:56,560 --> 00:08:02,530
software then exposes sequel type

00:07:58,450 --> 00:08:04,120
operations via an API we've totally

00:08:02,530 --> 00:08:06,310
integrated that with Postgres so the

00:08:04,120 --> 00:08:07,990
first tool that users will use to

00:08:06,310 --> 00:08:10,060
interact with the system is post greece

00:08:07,990 --> 00:08:13,740
and all the standard post grades tools

00:08:10,060 --> 00:08:17,230
PG admin and all the visualization tools

00:08:13,740 --> 00:08:18,760
psql the command line if you like on the

00:08:17,230 --> 00:08:21,300
left hand side so on the right hand side

00:08:18,760 --> 00:08:23,680
you've got tableau power bi

00:08:21,300 --> 00:08:26,020
MicroStrategy they all have post PS

00:08:23,680 --> 00:08:27,820
connectors so they will work out the box

00:08:26,020 --> 00:08:30,040
with bright lights

00:08:27,820 --> 00:08:33,250
we've also however developed our own

00:08:30,040 --> 00:08:35,590
visualization tool called spotlight and

00:08:33,250 --> 00:08:37,510
this has a geospatial element in it I'll

00:08:35,590 --> 00:08:39,880
get on through the demo at the end of

00:08:37,510 --> 00:08:42,130
this presentation and show you what I

00:08:39,880 --> 00:08:43,630
mean but when it comes to geospatial

00:08:42,130 --> 00:08:46,820
data it's really useful to be able to

00:08:43,630 --> 00:08:49,190
visualize it on a map

00:08:46,820 --> 00:08:51,320
there's often millions if not billions

00:08:49,190 --> 00:08:53,180
of data points in the data set that you

00:08:51,320 --> 00:08:55,370
want to visualize and visualization

00:08:53,180 --> 00:08:57,500
tools today just aren't able to deal

00:08:55,370 --> 00:09:02,540
with that kind of a volume of data

00:08:57,500 --> 00:09:05,810
because those three all render the

00:09:02,540 --> 00:09:07,160
images locally on the clients and that

00:09:05,810 --> 00:09:09,110
means that if you want to render a

00:09:07,160 --> 00:09:12,110
billion data points they need to come

00:09:09,110 --> 00:09:15,260
across the network and end up on the

00:09:12,110 --> 00:09:18,020
clients what we've done is built a

00:09:15,260 --> 00:09:20,510
rendering engine on the database side on

00:09:18,020 --> 00:09:22,430
the GPUs so the GPUs are not only used

00:09:20,510 --> 00:09:25,010
for aggregating and running SQL

00:09:22,430 --> 00:09:27,050
workloads actually also used for

00:09:25,010 --> 00:09:29,930
generating the images that you would

00:09:27,050 --> 00:09:32,000
then overlay on a map and then finally

00:09:29,930 --> 00:09:35,060
there's torch and Jupiter so this is

00:09:32,000 --> 00:09:38,930
really interesting because when we are

00:09:35,060 --> 00:09:41,480
looking at our memory management module

00:09:38,930 --> 00:09:43,070
for bright light we realized that torch

00:09:41,480 --> 00:09:46,240
has got a very sophisticated memory

00:09:43,070 --> 00:09:49,060
management capability so we talked torch

00:09:46,240 --> 00:09:52,550
the memory management module there

00:09:49,060 --> 00:09:54,950
extended it enhanced it and used it as

00:09:52,550 --> 00:09:58,420
our own but what's really cool there is

00:09:54,950 --> 00:10:00,950
that from the computer perspective

00:09:58,420 --> 00:10:03,470
whether you looking at a column in a

00:10:00,950 --> 00:10:04,760
database in a table or tensor that is

00:10:03,470 --> 00:10:07,670
going to be consumed by a machine

00:10:04,760 --> 00:10:13,580
learning or AI workflow it looks exactly

00:10:07,670 --> 00:10:16,040
the same so you can use SQL to work with

00:10:13,580 --> 00:10:18,100
your data create the data load the

00:10:16,040 --> 00:10:21,050
columns in a table and with zero copy

00:10:18,100 --> 00:10:25,130
then that data can be consumed by a

00:10:21,050 --> 00:10:27,490
torch workload and we've also integrated

00:10:25,130 --> 00:10:30,170
Jupiter so what you then have is a a

00:10:27,490 --> 00:10:32,600
web-based front-end a workbench

00:10:30,170 --> 00:10:34,610
that you can run your visualizations you

00:10:32,600 --> 00:10:37,820
can run your SQL and you can run your

00:10:34,610 --> 00:10:40,250
torch and workloads as well at the

00:10:37,820 --> 00:10:42,350
bottom we've got all the mechanisms that

00:10:40,250 --> 00:10:44,450
you can bring you can use to get data

00:10:42,350 --> 00:10:47,060
into the platform it's all based on

00:10:44,450 --> 00:10:48,470
Postgres basically natively has a thing

00:10:47,060 --> 00:10:50,839
called the foreign data wrapper and

00:10:48,470 --> 00:10:52,550
basically what that means is you can

00:10:50,839 --> 00:10:55,700
connect to virtually any data source

00:10:52,550 --> 00:10:57,220
that you like it's open source so I

00:10:55,700 --> 00:10:59,230
think there's about

00:10:57,220 --> 00:11:00,790
sixty data connectors front data

00:10:59,230 --> 00:11:02,709
wrappers Postgres data wrappers at the

00:11:00,790 --> 00:11:05,350
moments available in the community you

00:11:02,709 --> 00:11:10,720
can connect to flat files you can

00:11:05,350 --> 00:11:12,790
connect to Microsoft sequel Excel CSV my

00:11:10,720 --> 00:11:16,449
sequel what analytics Oracle whatever it

00:11:12,790 --> 00:11:21,459
is very easily just by a single line of

00:11:16,449 --> 00:11:24,250
code suck data into the platform we are

00:11:21,459 --> 00:11:27,189
partnering with IBM and what that is

00:11:24,250 --> 00:11:29,709
doing is being bringing best and breed

00:11:27,189 --> 00:11:32,319
IBM power hardware with the next

00:11:29,709 --> 00:11:35,620
generation of GPU accelerate databases

00:11:32,319 --> 00:11:37,870
and analytics we're very excited about

00:11:35,620 --> 00:11:40,180
that partnership you've probably heard a

00:11:37,870 --> 00:11:43,209
lot of talk about envy link one of the

00:11:40,180 --> 00:11:46,449
key issues when using GPUs to accelerate

00:11:43,209 --> 00:11:49,420
theta is the bottleneck in getting theta

00:11:46,449 --> 00:11:51,189
on and off the GPUs an envy link has a

00:11:49,420 --> 00:11:53,620
very neat solution for that

00:11:51,189 --> 00:11:56,829
four to five times faster than

00:11:53,620 --> 00:12:00,189
comparable x86 type architectures which

00:11:56,829 --> 00:12:01,750
rely on the PCIe bus so just to go

00:12:00,189 --> 00:12:05,829
through that a bit more if you look at

00:12:01,750 --> 00:12:09,639
power eight architecture that is the

00:12:05,829 --> 00:12:14,550
envy link that connects the GPUs to the

00:12:09,639 --> 00:12:20,110
power eight CPU and gives you 80 gig

00:12:14,550 --> 00:12:24,160
bi-directional data uplink speeds that

00:12:20,110 --> 00:12:26,829
is half of a typical minsky server you

00:12:24,160 --> 00:12:29,350
actually have four GPUs in a server two

00:12:26,829 --> 00:12:34,629
sockets and there's a bridge between the

00:12:29,350 --> 00:12:37,470
two sockets so let's just talk a little

00:12:34,629 --> 00:12:39,790
bit about Postgres if you look at

00:12:37,470 --> 00:12:40,720
straightforward vanilla post grades this

00:12:39,790 --> 00:12:44,139
is what you'll get

00:12:40,720 --> 00:12:48,009
it's got a user client like PG admin or

00:12:44,139 --> 00:12:49,959
psql parser then takes the user query

00:12:48,009 --> 00:12:51,100
planner hands it over to the DB engine

00:12:49,959 --> 00:12:53,199
and there's a bit of disk storage in

00:12:51,100 --> 00:12:55,180
there I mentioned a little bit about the

00:12:53,199 --> 00:12:57,300
foreign data wrappers that's allows you

00:12:55,180 --> 00:13:00,730
to connect to third-party data sources

00:12:57,300 --> 00:13:03,250
and if bright line was just an extension

00:13:00,730 --> 00:13:05,889
then basically we would be using the

00:13:03,250 --> 00:13:08,230
foreign data wrapper for as a as a third

00:13:05,889 --> 00:13:11,480
party data source right but what we've

00:13:08,230 --> 00:13:14,600
actually done is integrated tightly

00:13:11,480 --> 00:13:16,330
the database engine so bright light is

00:13:14,600 --> 00:13:19,310
actually a fork of place grades we made

00:13:16,330 --> 00:13:21,560
very big changes read written large

00:13:19,310 --> 00:13:26,930
parts of the database engine to run on

00:13:21,560 --> 00:13:28,850
GPU and therefore the data is uploaded

00:13:26,930 --> 00:13:31,250
on to GPU and stays there and then you

00:13:28,850 --> 00:13:35,230
can run all your SQL workloads off that

00:13:31,250 --> 00:13:38,330
data once it's already on GPU we also

00:13:35,230 --> 00:13:41,600
have integrated with Maria dB

00:13:38,330 --> 00:13:45,530
last month we announced at the m18

00:13:41,600 --> 00:13:47,890
conference there is maria DB's annual

00:13:45,530 --> 00:13:52,610
event that we will be partnering with

00:13:47,890 --> 00:13:57,050
maria debe very interesting partnership

00:13:52,610 --> 00:14:00,530
there it gives us the the ability to get

00:13:57,050 --> 00:14:03,050
our technology into hands of millions

00:14:00,530 --> 00:14:06,320
and millions of users who can then

00:14:03,050 --> 00:14:09,860
really take advantage of it and if you

00:14:06,320 --> 00:14:13,370
look at maria DB it's one of the if not

00:14:09,860 --> 00:14:17,120
the fastest-growing databases on the

00:14:13,370 --> 00:14:20,450
market today so this is a graphic from

00:14:17,120 --> 00:14:24,530
BB engines and the bottom in yellow you

00:14:20,450 --> 00:14:26,660
can see the the accelerated adoption of

00:14:24,530 --> 00:14:28,490
Maria DB it doesn't mean that an element

00:14:26,660 --> 00:14:31,480
of our code is going to be open sourced

00:14:28,490 --> 00:14:37,550
and packaged up within the Maria DB

00:14:31,480 --> 00:14:39,170
environment I mentioned to you about the

00:14:37,550 --> 00:14:41,630
torch integration and how we are using

00:14:39,170 --> 00:14:44,060
the torch memory management module and

00:14:41,630 --> 00:14:47,260
that means that we have a product called

00:14:44,060 --> 00:14:50,450
bright mind which brings SQL and AI

00:14:47,260 --> 00:14:52,490
together with GPUs with zero copy and

00:14:50,450 --> 00:14:55,370
that is really really useful for

00:14:52,490 --> 00:14:57,530
analysts and data scientists because it

00:14:55,370 --> 00:15:00,230
means that they can use the SQL so you

00:14:57,530 --> 00:15:02,390
prepare the data which takes up most of

00:15:00,230 --> 00:15:04,970
their time and immediately begin running

00:15:02,390 --> 00:15:07,280
machine learning and AI type workloads

00:15:04,970 --> 00:15:09,470
on that data that they've prepared all

00:15:07,280 --> 00:15:11,710
happening on GPU

00:15:09,470 --> 00:15:14,210
so there's a little bit more going into

00:15:11,710 --> 00:15:17,810
but more depth of what that means you

00:15:14,210 --> 00:15:22,010
got your GPU Ram if you create an array

00:15:17,810 --> 00:15:25,220
in that piece of memory you can access

00:15:22,010 --> 00:15:27,800
that array directly via SQL do your data

00:15:25,220 --> 00:15:31,160
definition language data manipulation

00:15:27,800 --> 00:15:33,890
all by Postgres and then you can hand

00:15:31,160 --> 00:15:37,610
that over directly to torch and run your

00:15:33,890 --> 00:15:41,150
AI and mo operations via a torch 0 copy

00:15:37,610 --> 00:15:42,830
very efficient use of GPU hardware but

00:15:41,150 --> 00:15:44,810
also really efficient for data

00:15:42,830 --> 00:15:49,370
scientists in their workflow and the

00:15:44,810 --> 00:15:54,530
time that they are spending so spotlight

00:15:49,370 --> 00:15:57,920
is the front end the workbench that

00:15:54,530 --> 00:16:00,970
brings SQL and III together and allows

00:15:57,920 --> 00:16:04,580
you to run interactive analytics on

00:16:00,970 --> 00:16:09,830
billions of rows of data so I'm going to

00:16:04,580 --> 00:16:12,220
jump onto the demo now so this is the

00:16:09,830 --> 00:16:13,580
spotlight front end the workbench

00:16:12,220 --> 00:16:18,430
browser-based

00:16:13,580 --> 00:16:22,100
the data set is telco data basically

00:16:18,430 --> 00:16:24,260
user experience data it contains signal

00:16:22,100 --> 00:16:25,820
strength upload speed download speed a

00:16:24,260 --> 00:16:29,120
couple of latency couple of other

00:16:25,820 --> 00:16:31,610
metrics as well as date and time and

00:16:29,120 --> 00:16:33,260
then also location that's 160 million

00:16:31,610 --> 00:16:36,890
points that you can see on the screen

00:16:33,260 --> 00:16:41,990
there and I've wanted to navigate in

00:16:36,890 --> 00:16:47,480
there and have a look at the data sorry

00:16:41,990 --> 00:16:52,900
let me just refresh this Oh looks like

00:16:47,480 --> 00:16:52,900
we've got a Wi-Fi issue here

00:17:57,860 --> 00:18:05,970
well then back up and running

00:18:01,190 --> 00:18:07,760
okay so right let me just shift some

00:18:05,970 --> 00:18:10,760
data around and get this another

00:18:07,760 --> 00:18:10,760
graphics

00:18:49,530 --> 00:18:57,540
oh then sorry I thought up so mobile

00:18:55,760 --> 00:19:00,870
user experience data

00:18:57,540 --> 00:19:02,640
this is 160 million data points and I

00:19:00,870 --> 00:19:04,410
can Bob in there you can see the tiles

00:19:02,640 --> 00:19:07,470
being generated on the server in real

00:19:04,410 --> 00:19:10,130
time and you can also see the GPUs

00:19:07,470 --> 00:19:17,960
updating these graphics in real time

00:19:10,130 --> 00:19:22,200
this point map to location point map is

00:19:17,960 --> 00:19:25,320
showing the rendering engine running on

00:19:22,200 --> 00:19:30,000
GPU and generating the tiles for this

00:19:25,320 --> 00:19:34,220
for this visualization I can also pop in

00:19:30,000 --> 00:19:34,220
a sub selection within that map

00:19:40,530 --> 00:19:46,520
and drag that selection over and the

00:19:42,540 --> 00:19:46,520
everything will update in real time

00:19:53,059 --> 00:19:56,059
later

00:19:57,240 --> 00:20:04,590
cool so am I can the workbench is a

00:20:01,890 --> 00:20:07,950
range of visualizations that we can look

00:20:04,590 --> 00:20:11,460
at so there's a line chart I can choose

00:20:07,950 --> 00:20:13,790
my table and columns and so on be quite

00:20:11,460 --> 00:20:16,050
specific on what I want to be looking at

00:20:13,790 --> 00:20:18,360
I've got a number of charts that I can

00:20:16,050 --> 00:20:22,320
pick from table bar charts histograms

00:20:18,360 --> 00:20:23,670
point naps pivot table the split of

00:20:22,320 --> 00:20:26,040
tables quite interesting because I can

00:20:23,670 --> 00:20:31,430
actually drag and drop columns around

00:20:26,040 --> 00:20:31,430
yeah put that back

00:20:31,860 --> 00:20:38,370
so a very powerful visualization tool

00:20:34,770 --> 00:20:44,670
with a with a geospatial capability I

00:20:38,370 --> 00:20:47,360
can also jump in here and run SQL

00:20:44,670 --> 00:20:47,360
queries

00:20:56,680 --> 00:21:03,260
and then what's also pretty cool is I

00:21:00,470 --> 00:21:07,310
can directly connect to Jupiter from

00:21:03,260 --> 00:21:09,290
within the front end and I'm gonna give

00:21:07,310 --> 00:21:12,940
you a little demo of bright minds so

00:21:09,290 --> 00:21:18,800
what we have here is time series data

00:21:12,940 --> 00:21:22,550
from cuando financial ticker data load

00:21:18,800 --> 00:21:27,650
some this is all Lua load the modules I

00:21:22,550 --> 00:21:33,500
need get the data split into a training

00:21:27,650 --> 00:21:36,500
set and a validation set 80/20 going to

00:21:33,500 --> 00:21:40,210
be creating a window a moving window of

00:21:36,500 --> 00:21:42,920
20 days there's one data point per day

00:21:40,210 --> 00:21:45,650
train the data sets the trends so we

00:21:42,920 --> 00:21:47,210
train the neural network create a neural

00:21:45,650 --> 00:21:53,390
network it's three three layer net

00:21:47,210 --> 00:21:56,870
Network trainers and then use that

00:21:53,390 --> 00:22:00,320
trained network to make predictions on

00:21:56,870 --> 00:22:02,930
the twenty percent validation set now we

00:22:00,320 --> 00:22:05,000
didn't spend a lot of time creating a

00:22:02,930 --> 00:22:07,370
really accurate model this is really

00:22:05,000 --> 00:22:09,770
just to showcase the capabilities and

00:22:07,370 --> 00:22:13,730
how everything integrates together and

00:22:09,770 --> 00:22:16,010
also showcase the workbench but even so

00:22:13,730 --> 00:22:18,740
you can see that the model that we have

00:22:16,010 --> 00:22:20,180
created is pretty accurate so in blue

00:22:18,740 --> 00:22:23,240
you have the real data the 20%

00:22:20,180 --> 00:22:25,640
validation data sets and if we give the

00:22:23,240 --> 00:22:29,570
neural network 20 days of 21 days of

00:22:25,640 --> 00:22:32,690
data the neural network will then make a

00:22:29,570 --> 00:22:35,830
prediction on what the next day's data

00:22:32,690 --> 00:22:35,830
is going to be yes sir

00:22:41,960 --> 00:22:44,960
so

00:22:50,549 --> 00:22:58,450
so that particular demo ultimately we

00:22:56,710 --> 00:23:05,230
are running the notebook directly on

00:22:58,450 --> 00:23:06,669
data on the GPUs already thus there's a

00:23:05,230 --> 00:23:10,570
PG connect there that's right so this

00:23:06,669 --> 00:23:17,789
this is a slide that's right so this is

00:23:10,570 --> 00:23:20,379
a so this is a this is an old demo and

00:23:17,789 --> 00:23:22,749
what we have now is that that would not

00:23:20,379 --> 00:23:26,440
be there you would basically be running

00:23:22,749 --> 00:23:28,869
directly on the data that's on the GPUs

00:23:26,440 --> 00:23:31,679
that's in the database so you're

00:23:28,869 --> 00:23:34,960
absolutely right this model shows us

00:23:31,679 --> 00:23:39,840
creating a database and then fetching

00:23:34,960 --> 00:23:39,840
the data out of it but

00:23:43,100 --> 00:23:46,100
so

00:23:50,260 --> 00:23:53,260
correct

00:23:59,860 --> 00:24:05,679
No so what we've done is

00:24:10,810 --> 00:24:17,380
yes of our torch so specifically for

00:24:13,330 --> 00:24:19,420
torch if you're running if you're using

00:24:17,380 --> 00:24:24,760
torch to you do your machine learning

00:24:19,420 --> 00:24:26,410
you know correct correct so I think

00:24:24,760 --> 00:24:27,630
there's probably a torch module up here

00:24:26,410 --> 00:24:34,000
somewhere

00:24:27,630 --> 00:24:38,290
okay okay sorry yeah so specifically for

00:24:34,000 --> 00:24:43,750
torch you use sequel to prepare tables

00:24:38,290 --> 00:24:47,860
and columns and that column is exactly

00:24:43,750 --> 00:24:55,780
got it and that's pretty much the the

00:24:47,860 --> 00:24:57,990
presentation any any other questions yes

00:24:55,780 --> 00:24:57,990
sir

00:25:03,610 --> 00:25:14,460
so the IP is specifically around being

00:25:09,970 --> 00:25:19,990
able to do joins in parallel efficiently

00:25:14,460 --> 00:25:21,610
so joins can be done in all sorts of

00:25:19,990 --> 00:25:25,480
different ways you've got hash join

00:25:21,610 --> 00:25:29,380
merge join nested for loop index nested

00:25:25,480 --> 00:25:31,000
for loop house joins very fast but the

00:25:29,380 --> 00:25:32,650
predicate needs to be an equality and

00:25:31,000 --> 00:25:36,040
you need to create a hash table for one

00:25:32,650 --> 00:25:39,340
of the tables right it's also paralyze

00:25:36,040 --> 00:25:43,450
herbal nested for loop is paralyze

00:25:39,340 --> 00:25:45,130
herbal but grows exponentially with the

00:25:43,450 --> 00:25:49,870
size of the data set and quite often a

00:25:45,130 --> 00:25:54,340
lot of that work is unnecessary so you

00:25:49,870 --> 00:25:57,220
can do things like on GPU nested for

00:25:54,340 --> 00:25:59,710
loop but you get the data were clay

00:25:57,220 --> 00:26:00,940
becomes so big when you start looking at

00:25:59,710 --> 00:26:03,940
billions and billions of rows of data

00:26:00,940 --> 00:26:07,770
that it can take years literally to

00:26:03,940 --> 00:26:10,390
process the join so what the IP

00:26:07,770 --> 00:26:13,060
specifically targets is being able to

00:26:10,390 --> 00:26:16,290
run joins in parallel efficiently far

00:26:13,060 --> 00:26:19,870
more efficiently than nested for loop

00:26:16,290 --> 00:26:24,460
even more efficiently than hash join so

00:26:19,870 --> 00:26:27,010
our IP allows us to run joins process

00:26:24,460 --> 00:26:30,970
them more quickly than hash join and

00:26:27,010 --> 00:26:34,290
also gives us the scope to run on GPUs

00:26:30,970 --> 00:26:34,290
very effectively

00:26:38,610 --> 00:26:44,500
any other questions okay thanks very

00:26:43,050 --> 00:26:48,319
much for your time

00:26:44,500 --> 00:26:48,319

YouTube URL: https://www.youtube.com/watch?v=pcIoTN8DGk4


