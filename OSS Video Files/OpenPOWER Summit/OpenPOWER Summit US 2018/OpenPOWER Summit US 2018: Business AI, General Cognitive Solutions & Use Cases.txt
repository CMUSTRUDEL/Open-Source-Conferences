Title: OpenPOWER Summit US 2018: Business AI, General Cognitive Solutions & Use Cases
Publication date: 2018-04-03
Playlist: OpenPOWER Summit US 2018
Description: 
	OpenPOWER members from Fatbrain discuss their use of POWER technology at OpenPOWER Summit 2018.

Presenters:
- Rajarshi Das, CTO, Co-founder, Fatbrain
- Peter Ritz, Managing Director, Co-founder, Fatbrain

For more information, please visit: http://www.openpowerfoundation.org
Captions: 
	00:00:00,179 --> 00:00:05,819
my name is Peter Ritz and I am the CEO

00:00:03,510 --> 00:00:08,719
at FET brain and I am here with my

00:00:05,819 --> 00:00:12,269
colleague Rose Archie Das who is our

00:00:08,719 --> 00:00:14,549
chief technology officer and what we're

00:00:12,269 --> 00:00:16,529
going to talk about today is the

00:00:14,549 --> 00:00:17,789
cognitive solutions but cognitive

00:00:16,529 --> 00:00:20,880
solutions which are auditable

00:00:17,789 --> 00:00:25,519
explainable fair and causal and how all

00:00:20,880 --> 00:00:29,429
these come together in the use cases so

00:00:25,519 --> 00:00:31,399
at a very high level we'll talk a little

00:00:29,429 --> 00:00:35,040
bit about the context and a background

00:00:31,399 --> 00:00:38,430
the idea of what we call learn to vector

00:00:35,040 --> 00:00:40,379
embeddings and then order ability

00:00:38,430 --> 00:00:42,960
explain ability fairness causality and

00:00:40,379 --> 00:00:48,780
policy learning just kind of a tent

00:00:42,960 --> 00:00:50,190
alight everybody's appetite so just a

00:00:48,780 --> 00:00:54,030
little bit of introduction about our

00:00:50,190 --> 00:00:58,199
business we like working with with IBM

00:00:54,030 --> 00:01:01,469
and we think IBM's gear actually is

00:00:58,199 --> 00:01:04,199
perfectly set up for all the cognitive

00:01:01,469 --> 00:01:05,939
workloads not only from a perspective of

00:01:04,199 --> 00:01:09,720
delivering the latest and greatest in

00:01:05,939 --> 00:01:12,330
the GPU enabled technologies with power

00:01:09,720 --> 00:01:14,420
but also some of the latest technologies

00:01:12,330 --> 00:01:17,270
that are coming down the pike with Q so

00:01:14,420 --> 00:01:20,240
we'll use one example at least for how

00:01:17,270 --> 00:01:22,380
the concept that we have developed is

00:01:20,240 --> 00:01:27,090
generally applicable there as well

00:01:22,380 --> 00:01:29,369
just way of background the problem that

00:01:27,090 --> 00:01:31,079
we're solving is very exciting for us

00:01:29,369 --> 00:01:34,020
and it's a problem what we call the

00:01:31,079 --> 00:01:36,180
Millennial data geometry and the

00:01:34,020 --> 00:01:38,700
Millennial data geometry problem is

00:01:36,180 --> 00:01:42,840
really one that takes us into the world

00:01:38,700 --> 00:01:46,860
of unstructured data from the world that

00:01:42,840 --> 00:01:49,439
we knew much earlier on which is very

00:01:46,860 --> 00:01:50,759
difficult to manage in this three layer

00:01:49,439 --> 00:01:53,100
cake if you think about it it's a very

00:01:50,759 --> 00:01:55,409
high-end it's the data geometry that's

00:01:53,100 --> 00:01:57,390
changing with social and with mobile and

00:01:55,409 --> 00:01:58,560
with all the unstructured interactions

00:01:57,390 --> 00:02:02,700
that are coming down the pike

00:01:58,560 --> 00:02:05,640
a simple example is if you run a video

00:02:02,700 --> 00:02:08,369
an advertising video on YouTube the

00:02:05,640 --> 00:02:10,590
amount of data you get from one clip is

00:02:08,369 --> 00:02:13,050
gonna break any one of your old systems

00:02:10,590 --> 00:02:13,620
just to kind of be able to track it it's

00:02:13,050 --> 00:02:17,790
usually

00:02:13,620 --> 00:02:19,590
for 500 unit dimension array and that's

00:02:17,790 --> 00:02:21,569
just not what you're used to if you're

00:02:19,590 --> 00:02:25,620
running Oracle or s AP or anything else

00:02:21,569 --> 00:02:28,890
to to kind of do your earlier analytical

00:02:25,620 --> 00:02:31,410
workload on at the bottom layer you see

00:02:28,890 --> 00:02:32,760
the architecture is the application

00:02:31,410 --> 00:02:36,690
architectures and how they have changed

00:02:32,760 --> 00:02:39,450
and it goes from the you know the the

00:02:36,690 --> 00:02:42,090
early 60s artificial intelligence

00:02:39,450 --> 00:02:44,700
capable mainframes they could do

00:02:42,090 --> 00:02:46,470
handwriting to what you have today which

00:02:44,700 --> 00:02:48,720
is cognitive and GPU native kind of

00:02:46,470 --> 00:02:50,940
things and all of that with the journey

00:02:48,720 --> 00:02:53,130
of micro-services is is where we're

00:02:50,940 --> 00:02:54,630
coming to and the middle layer is

00:02:53,130 --> 00:02:56,130
probably the most important one and the

00:02:54,630 --> 00:02:58,920
middle layer really has to do with the

00:02:56,130 --> 00:03:00,599
fact that today's client expects hyper

00:02:58,920 --> 00:03:03,959
personal experience because they're used

00:03:00,599 --> 00:03:06,450
to it from their kind of consumer

00:03:03,959 --> 00:03:07,739
applications and it's very hard to do at

00:03:06,450 --> 00:03:11,220
scale if you have a hundred million

00:03:07,739 --> 00:03:13,920
customers or 30 million customers it's

00:03:11,220 --> 00:03:17,880
very difficult to do that on that kind

00:03:13,920 --> 00:03:19,530
of personal level so the the big value

00:03:17,880 --> 00:03:22,739
that we see in a big problem that we

00:03:19,530 --> 00:03:24,720
solve for is this idea of automated

00:03:22,739 --> 00:03:27,630
learning versus feature engineering that

00:03:24,720 --> 00:03:30,630
normally is presented and how do we take

00:03:27,630 --> 00:03:32,790
something that goes beyond classic

00:03:30,630 --> 00:03:35,010
analytics to cognitive analytics which

00:03:32,790 --> 00:03:36,780
is which is much more valuable and again

00:03:35,010 --> 00:03:39,870
to us the solution is very simple a

00:03:36,780 --> 00:03:42,150
cognitive cloud and a cognitive cloud in

00:03:39,870 --> 00:03:46,169
a box that comes to your data that

00:03:42,150 --> 00:03:48,630
enables this kind of an experience this

00:03:46,169 --> 00:03:52,319
is just a little bit of a high-level

00:03:48,630 --> 00:03:55,590
view of what the differences between

00:03:52,319 --> 00:04:00,630
predictive analytics or just analytics

00:03:55,590 --> 00:04:03,090
versus the you know business AI

00:04:00,630 --> 00:04:05,579
automation experiences like and the

00:04:03,090 --> 00:04:08,340
easiest example is you know 15 I'm old

00:04:05,579 --> 00:04:10,109
so 15 20 years ago if you're out and if

00:04:08,340 --> 00:04:13,109
you were driving from point A to point B

00:04:10,109 --> 00:04:15,419
yet to use a book to find your way there

00:04:13,109 --> 00:04:17,760
and you have to open up that book and

00:04:15,419 --> 00:04:20,430
you had to figure out where you where

00:04:17,760 --> 00:04:21,690
and how you kind of got there and and if

00:04:20,430 --> 00:04:25,500
you were kind enough and your wife

00:04:21,690 --> 00:04:27,060
allowed you ask for directions so the

00:04:25,500 --> 00:04:28,740
that world

00:04:27,060 --> 00:04:31,530
is very different than everything that

00:04:28,740 --> 00:04:34,590
we know today which is if you use any

00:04:31,530 --> 00:04:36,660
kind of navigation automation whether

00:04:34,590 --> 00:04:38,790
it's ways or Google Maps or anything

00:04:36,660 --> 00:04:41,460
else if you veer of course it's kind of

00:04:38,790 --> 00:04:43,889
telling you where you should go so this

00:04:41,460 --> 00:04:47,220
idea of assisted decision-making and

00:04:43,889 --> 00:04:49,380
business AI automation where outcomes

00:04:47,220 --> 00:04:50,850
they learn and can be aligned to from

00:04:49,380 --> 00:04:53,190
what you're doing today you know if

00:04:50,850 --> 00:04:54,960
you're if you're using large and

00:04:53,190 --> 00:04:56,100
managing large amount of data with

00:04:54,960 --> 00:04:56,850
Hadoop clusters and everything else

00:04:56,100 --> 00:04:58,770
that's great

00:04:56,850 --> 00:05:00,720
you've counted at all but have you

00:04:58,770 --> 00:05:02,340
learned from it that's the big issue and

00:05:00,720 --> 00:05:04,290
if you have ten thousand different

00:05:02,340 --> 00:05:06,180
things that you're counting which three

00:05:04,290 --> 00:05:07,500
really make a difference that's the

00:05:06,180 --> 00:05:09,510
whole that's the hard part that's that's

00:05:07,500 --> 00:05:11,790
the that's the problem so the things

00:05:09,510 --> 00:05:13,560
that we'll look at is we'll look at

00:05:11,790 --> 00:05:15,300
automated learning and we'll talk about

00:05:13,560 --> 00:05:17,630
something a special piece of technology

00:05:15,300 --> 00:05:20,190
we'll call to learn vector embeddings

00:05:17,630 --> 00:05:23,180
learning the policy for how to make the

00:05:20,190 --> 00:05:25,800
real time decision making being truly

00:05:23,180 --> 00:05:27,510
data agnostic and what I mean by that is

00:05:25,800 --> 00:05:30,810
you should be able to use linear

00:05:27,510 --> 00:05:34,020
regression on you know the comments that

00:05:30,810 --> 00:05:36,300
are coming in from customer interactions

00:05:34,020 --> 00:05:39,479
so there's one problem to use linear

00:05:36,300 --> 00:05:41,280
regression on speech it's not easy but

00:05:39,479 --> 00:05:43,260
with our technology you actually can

00:05:41,280 --> 00:05:45,210
it's the same thing with there are a lot

00:05:43,260 --> 00:05:46,530
of techniques in actually natural

00:05:45,210 --> 00:05:49,289
language processing that would be great

00:05:46,530 --> 00:05:51,780
to use on numbers but unless you have

00:05:49,289 --> 00:05:53,160
some sort of a vector in betty's

00:05:51,780 --> 00:05:55,260
technology it's very difficult to do

00:05:53,160 --> 00:05:57,330
that so we have a way of dealing with

00:05:55,260 --> 00:05:59,460
all disparate sources of data bringing

00:05:57,330 --> 00:05:59,700
it together and driving value out of

00:05:59,460 --> 00:06:02,100
that

00:05:59,700 --> 00:06:03,840
we're domain independent so what we

00:06:02,100 --> 00:06:06,600
learned and financial sector we can

00:06:03,840 --> 00:06:08,340
apply to a pharmacy you know Pharma we

00:06:06,600 --> 00:06:10,830
can apply to logistics and a bunch of

00:06:08,340 --> 00:06:12,300
other places and probably the most

00:06:10,830 --> 00:06:14,190
important thing if there's one thing you

00:06:12,300 --> 00:06:16,770
can learn about fed brain is that we're

00:06:14,190 --> 00:06:18,750
double explainable and quantifiable so

00:06:16,770 --> 00:06:20,970
if we help you make a decision we can

00:06:18,750 --> 00:06:26,970
tell you why we think that's a very very

00:06:20,970 --> 00:06:27,780
big deal this is a little bit of how the

00:06:26,970 --> 00:06:30,300
stuff works

00:06:27,780 --> 00:06:32,550
so there's three simple steps one step

00:06:30,300 --> 00:06:34,500
is simply connecting to the existing

00:06:32,550 --> 00:06:35,870
operational data stores and the

00:06:34,500 --> 00:06:39,599
operation that a source could be as

00:06:35,870 --> 00:06:40,479
varied as literally social media which

00:06:39,599 --> 00:06:42,479
is completely

00:06:40,479 --> 00:06:45,009
sure this is Twitter Facebook you know

00:06:42,479 --> 00:06:46,809
YouTube whatever all the way on the

00:06:45,009 --> 00:06:48,460
other side highly structured models

00:06:46,809 --> 00:06:50,349
which are regulated literally a model

00:06:48,460 --> 00:06:52,120
that you have running in the bank or

00:06:50,349 --> 00:06:54,309
model that's deciding whether to lend

00:06:52,120 --> 00:06:57,909
something or not lend on something and

00:06:54,309 --> 00:07:01,409
so on and all the course systems in

00:06:57,909 --> 00:07:03,520
between so this example just shows off a

00:07:01,409 --> 00:07:06,039
situation where we're doing something

00:07:03,520 --> 00:07:08,259
for anti money laundering but the setup

00:07:06,039 --> 00:07:10,169
is very very simple connect to all the

00:07:08,259 --> 00:07:12,610
data sources that are available and

00:07:10,169 --> 00:07:15,460
that's kind of their first step what we

00:07:12,610 --> 00:07:18,189
do want to would connect to them is we

00:07:15,460 --> 00:07:18,939
learn through this idea we call lve or

00:07:18,189 --> 00:07:22,509
you heard me

00:07:18,939 --> 00:07:25,330
you'll hear me say alive the the lve is

00:07:22,509 --> 00:07:29,110
this learned vector embeddings that

00:07:25,330 --> 00:07:31,120
understand and almost index the data so

00:07:29,110 --> 00:07:33,370
we don't create another you know from

00:07:31,120 --> 00:07:35,860
many data lakes the whole other data set

00:07:33,370 --> 00:07:38,559
we simply look at it as an index of

00:07:35,860 --> 00:07:40,749
learnings so if transactional data had

00:07:38,559 --> 00:07:43,029
smiles and frowns you can think of the

00:07:40,749 --> 00:07:46,479
whole thing as simply learning kind of

00:07:43,029 --> 00:07:47,979
the smiles and frowns of your

00:07:46,479 --> 00:07:50,319
transactions from that kind of a

00:07:47,979 --> 00:07:53,919
perspective so that's what vector

00:07:50,319 --> 00:07:57,370
embeddings is all about the second step

00:07:53,919 --> 00:08:01,149
is kind of the engine that is able now

00:07:57,370 --> 00:08:03,490
to learn and use kind of the inference

00:08:01,149 --> 00:08:05,919
in part of the a recommendation part or

00:08:03,490 --> 00:08:09,969
imputation part based on this learned

00:08:05,919 --> 00:08:12,339
model right and then the last part is

00:08:09,969 --> 00:08:14,529
just making decisions and again this is

00:08:12,339 --> 00:08:16,209
a system that can be deployed to process

00:08:14,529 --> 00:08:18,669
billions of transactions that can

00:08:16,209 --> 00:08:21,219
distill into hundreds or sometimes even

00:08:18,669 --> 00:08:24,370
less than reports and investigation so

00:08:21,219 --> 00:08:28,289
it can work at scale and learn very very

00:08:24,370 --> 00:08:31,120
quickly especially when it uses power

00:08:28,289 --> 00:08:34,389
this is what kind of the collaboration

00:08:31,120 --> 00:08:37,180
workflow looks like so it's a a piece of

00:08:34,389 --> 00:08:40,659
software that gets deployed on gear in

00:08:37,180 --> 00:08:42,849
place but the constituencies that it

00:08:40,659 --> 00:08:45,730
serves are engineering from a

00:08:42,849 --> 00:08:47,380
perspective of setting things up so you

00:08:45,730 --> 00:08:49,029
know connecting to data you would not

00:08:47,380 --> 00:08:51,339
ask an analyst to do but an engineer

00:08:49,029 --> 00:08:53,560
would do that but an analyst would set

00:08:51,339 --> 00:08:53,950
up the KPIs across which they would want

00:08:53,560 --> 00:08:56,140
to see

00:08:53,950 --> 00:08:58,600
sort of a business outcome and the same

00:08:56,140 --> 00:09:00,310
thing for a owner of a line of business

00:08:58,600 --> 00:09:01,810
right an owner of line of business would

00:09:00,310 --> 00:09:04,150
be the one who's going to thinking

00:09:01,810 --> 00:09:06,160
through those issues the folks who are

00:09:04,150 --> 00:09:07,690
vectorizing segmenting and analyzing

00:09:06,160 --> 00:09:10,780
from the from the previous slide would

00:09:07,690 --> 00:09:13,120
be analysts and data scientists all the

00:09:10,780 --> 00:09:14,920
sudden as I mentioned earlier data

00:09:13,120 --> 00:09:18,010
scientists can use the same linear

00:09:14,920 --> 00:09:22,090
regression on you know unstructured data

00:09:18,010 --> 00:09:23,560
that she or he is used to using on all

00:09:22,090 --> 00:09:26,110
the all the numbers that they like so

00:09:23,560 --> 00:09:29,170
much so although all these things become

00:09:26,110 --> 00:09:32,320
enabled very easily in in this set up

00:09:29,170 --> 00:09:34,210
one of the interesting wrinkles that we

00:09:32,320 --> 00:09:35,680
have with our technology not only can we

00:09:34,210 --> 00:09:39,840
look at unstructured data from a

00:09:35,680 --> 00:09:45,370
perspective of you know text and and

00:09:39,840 --> 00:09:46,990
voice and a video and numbers we can

00:09:45,370 --> 00:09:50,350
also look at actually at structures at

00:09:46,990 --> 00:09:52,150
graph data so who talked to whom or even

00:09:50,350 --> 00:09:54,040
source code or log files or any of those

00:09:52,150 --> 00:09:58,000
kind of things are all in a realm of

00:09:54,040 --> 00:10:00,040
really good substrate for us to drive

00:09:58,000 --> 00:10:03,040
decision-making and then last but not

00:10:00,040 --> 00:10:05,490
least if any of the decisions have to be

00:10:03,040 --> 00:10:08,770
audited or exposed to external

00:10:05,490 --> 00:10:10,570
regulatory bodies we enable that as well

00:10:08,770 --> 00:10:12,310
every every transaction and every

00:10:10,570 --> 00:10:14,680
decision that we make actually gets safe

00:10:12,310 --> 00:10:16,300
stored into a trusted source which could

00:10:14,680 --> 00:10:17,710
be extract blockchain that could be

00:10:16,300 --> 00:10:21,430
exposed to to that kind of a

00:10:17,710 --> 00:10:24,060
constituency this is a little bit of the

00:10:21,430 --> 00:10:41,980
architectural deployment set up for us

00:10:24,060 --> 00:10:43,690
so what you see in this quadrant here we

00:10:41,980 --> 00:10:48,250
simply enhance it through these two

00:10:43,690 --> 00:10:50,920
blocks the orange block and the the blue

00:10:48,250 --> 00:10:53,500
block one for kind of learning and the

00:10:50,920 --> 00:10:55,180
other one for inferencing each of these

00:10:53,500 --> 00:10:58,780
run is a kubernetes container and they

00:10:55,180 --> 00:11:01,390
can scale magically so to speak and

00:10:58,780 --> 00:11:04,060
because they're running on cubes they

00:11:01,390 --> 00:11:06,610
can be portable and deployed in hybrid

00:11:04,060 --> 00:11:07,270
infrastructures so we like an

00:11:06,610 --> 00:11:10,240
infrastructure

00:11:07,270 --> 00:11:12,910
example where it's GPU friendly on power

00:11:10,240 --> 00:11:16,210
but if a lot of transactional data runs

00:11:12,910 --> 00:11:17,620
on other architecture like IBM Z well

00:11:16,210 --> 00:11:19,150
that's great for us because we're able

00:11:17,620 --> 00:11:22,150
to do that in place and make it work

00:11:19,150 --> 00:11:24,400
really well so just a little bit of

00:11:22,150 --> 00:11:26,140
context for that if you're or if you're

00:11:24,400 --> 00:11:28,180
a multi cloud where we're friendly with

00:11:26,140 --> 00:11:30,220
that too so that's just a little bit of

00:11:28,180 --> 00:11:33,460
a set up there

00:11:30,220 --> 00:11:36,280
we're also fully API restful api driven

00:11:33,460 --> 00:11:39,640
so when this gets deployed in place it

00:11:36,280 --> 00:11:41,980
comes up and it never never leaves the

00:11:39,640 --> 00:11:44,230
pram so to speak in terms of its its

00:11:41,980 --> 00:11:48,100
capability its latency all they're

00:11:44,230 --> 00:11:50,080
really good networking innovation that's

00:11:48,100 --> 00:11:52,390
happened and a couple of folks that went

00:11:50,080 --> 00:11:53,560
before us whether it's from melon ax or

00:11:52,390 --> 00:11:55,600
some of the other folks we take

00:11:53,560 --> 00:11:58,270
advantage of all that to bridge this

00:11:55,600 --> 00:12:08,860
this kind of latency gap especially on

00:11:58,270 --> 00:12:11,190
pram so so one of the key ideas that we

00:12:08,860 --> 00:12:13,840
you know Peter mention about these

00:12:11,190 --> 00:12:17,530
learning these vectors the vector

00:12:13,840 --> 00:12:20,170
embeddings is that typically you know

00:12:17,530 --> 00:12:22,660
when you know when people are data

00:12:20,170 --> 00:12:25,210
scientists are looking for trying to

00:12:22,660 --> 00:12:28,210
find the customer with a particular

00:12:25,210 --> 00:12:30,040
behavior say the number of sales that

00:12:28,210 --> 00:12:32,380
they have done in the last two quarters

00:12:30,040 --> 00:12:34,750
so they're comparing numbers to numbers

00:12:32,380 --> 00:12:37,030
and so they can find for this customer

00:12:34,750 --> 00:12:39,720
these are the customers who are most

00:12:37,030 --> 00:12:42,430
like them but as Peter mentioned earlier

00:12:39,720 --> 00:12:44,470
imagine not we not only have numbers

00:12:42,430 --> 00:12:46,560
associated with each customer in the

00:12:44,470 --> 00:12:49,480
system of records but you also have

00:12:46,560 --> 00:12:51,640
additional data an additional system of

00:12:49,480 --> 00:12:54,340
records or data as to whom they have

00:12:51,640 --> 00:12:56,710
interacted with perhaps a graph we also

00:12:54,340 --> 00:12:59,080
have data with respect to each customer

00:12:56,710 --> 00:13:01,480
as to what they have said on the social

00:12:59,080 --> 00:13:03,220
media which is text and then the

00:13:01,480 --> 00:13:06,130
question becomes when you have all these

00:13:03,220 --> 00:13:08,890
disparate types of data how do you find

00:13:06,130 --> 00:13:13,020
out who is nearby to whom in the

00:13:08,890 --> 00:13:15,820
customer space so this this mechanism of

00:13:13,020 --> 00:13:18,490
figuring out these vectors numerical

00:13:15,820 --> 00:13:20,710
vectors gives us a common backplane to

00:13:18,490 --> 00:13:22,810
compute to quantify

00:13:20,710 --> 00:13:25,810
the distances or similarities between

00:13:22,810 --> 00:13:28,600
customers so if you have a customer that

00:13:25,810 --> 00:13:30,820
that is jet has just shown up you can

00:13:28,600 --> 00:13:32,890
see that for with respect to this

00:13:30,820 --> 00:13:35,410
customer who are the nearby best

00:13:32,890 --> 00:13:37,540
customers or perhaps you have a best

00:13:35,410 --> 00:13:39,910
customer and then I guess then you can

00:13:37,540 --> 00:13:41,890
quantify that who are the customers who

00:13:39,910 --> 00:13:44,320
are most like the best customers to whom

00:13:41,890 --> 00:13:47,529
perhaps you should cross sell upsell and

00:13:44,320 --> 00:13:50,920
provide I provide discounts so that's

00:13:47,529 --> 00:13:54,130
the key idea but you know so so this is

00:13:50,920 --> 00:13:56,500
the idea of in real time figuring out

00:13:54,130 --> 00:13:59,020
the digital twin and then driving these

00:13:56,500 --> 00:14:01,120
two learning not just in terms of

00:13:59,020 --> 00:14:05,350
actionable insights but really learning

00:14:01,120 --> 00:14:08,440
outcomes business outcomes so you know a

00:14:05,350 --> 00:14:11,980
few minutes ago in the other one of the

00:14:08,440 --> 00:14:14,649
other sessions on AI demystified one of

00:14:11,980 --> 00:14:16,540
the aspects that comes across is deep

00:14:14,649 --> 00:14:19,060
learning and machine learning and

00:14:16,540 --> 00:14:21,700
specially deep learning these models are

00:14:19,060 --> 00:14:24,279
so complex that he can they can latch on

00:14:21,700 --> 00:14:26,620
to nuanced correlations that are exist

00:14:24,279 --> 00:14:29,350
in the data so for example the example

00:14:26,620 --> 00:14:30,670
that was given was a deep learning

00:14:29,350 --> 00:14:34,240
system that is trying to identify

00:14:30,670 --> 00:14:35,920
between dogs and wolves it turned out it

00:14:34,240 --> 00:14:38,080
was doing a good job in and it in

00:14:35,920 --> 00:14:40,390
figuring out images of dogs and wolves

00:14:38,080 --> 00:14:42,670
but it turns out for the images of Holtz

00:14:40,390 --> 00:14:44,200
it had latched on to the idea that in

00:14:42,670 --> 00:14:46,240
most images of wolves there was snow in

00:14:44,200 --> 00:14:48,310
the background so it was not that they

00:14:46,240 --> 00:14:50,170
had figured out what a wolf is but it

00:14:48,310 --> 00:14:53,140
has latched onto another correlated

00:14:50,170 --> 00:14:55,779
attribute correlated a piece of data

00:14:53,140 --> 00:14:57,880
into in this case snow and so it is

00:14:55,779 --> 00:15:00,490
going to be very critical going forward

00:14:57,880 --> 00:15:03,190
in terms of explaining the results for

00:15:00,490 --> 00:15:05,400
each business decision that is made can

00:15:03,190 --> 00:15:07,839
you explain why that decision was made

00:15:05,400 --> 00:15:09,790
quantify you know in a quantified sense

00:15:07,839 --> 00:15:11,890
explain you know what are the factors

00:15:09,790 --> 00:15:13,510
that led to that particular decision you

00:15:11,890 --> 00:15:15,640
don't want to say that oh it was because

00:15:13,510 --> 00:15:16,560
of snow that this is a wolf that would

00:15:15,640 --> 00:15:21,310
be terrible

00:15:16,560 --> 00:15:23,800
so similarly you know business decisions

00:15:21,310 --> 00:15:25,980
you know in in some of our clients are

00:15:23,800 --> 00:15:29,079
working with fairness is a big big issue

00:15:25,980 --> 00:15:30,760
when you're approving loans you want to

00:15:29,079 --> 00:15:33,270
be you want to insure you want to

00:15:30,760 --> 00:15:34,550
guarantee that this approval process is

00:15:33,270 --> 00:15:37,850
not

00:15:34,550 --> 00:15:41,480
biased is not biased against sensitive

00:15:37,850 --> 00:15:42,680
attributes like race sex age zip code so

00:15:41,480 --> 00:15:44,510
you have to guarantee you have in

00:15:42,680 --> 00:15:47,360
enterprise environments you have to be

00:15:44,510 --> 00:15:49,550
able to guarantee that and then of all

00:15:47,360 --> 00:15:51,829
the models that you're using in in deep

00:15:49,550 --> 00:15:53,450
learning and in other systems you have a

00:15:51,829 --> 00:15:56,510
plethora of models they are

00:15:53,450 --> 00:15:59,450
interconnected and and so such but

00:15:56,510 --> 00:16:01,730
unless you have a mechanism through

00:15:59,450 --> 00:16:04,130
which you can authenticate you can you

00:16:01,730 --> 00:16:05,750
can verify an audit that this is the

00:16:04,130 --> 00:16:08,660
provenance of this model this is the

00:16:05,750 --> 00:16:10,730
provenance of this decision business

00:16:08,660 --> 00:16:12,980
decision that was suggested then it is

00:16:10,730 --> 00:16:15,860
likely to be you know vulnerable through

00:16:12,980 --> 00:16:17,600
attacks so if you have made a series of

00:16:15,860 --> 00:16:19,910
decisions then you can go back and say

00:16:17,600 --> 00:16:22,160
that this is this is the reason this is

00:16:19,910 --> 00:16:24,620
the chain of custody of this particular

00:16:22,160 --> 00:16:27,230
decision and these are the reasons for

00:16:24,620 --> 00:16:29,180
which a particular decision was made so

00:16:27,230 --> 00:16:31,480
so Peters going to go through some of

00:16:29,180 --> 00:16:35,260
the examples that touch upon all his

00:16:31,480 --> 00:16:38,149
attributes and and we'll go from there

00:16:35,260 --> 00:16:40,550
it's really simple maybe one of the

00:16:38,149 --> 00:16:45,140
things that's most common to many

00:16:40,550 --> 00:16:48,130
businesses is the boogieman of missing

00:16:45,140 --> 00:16:51,740
data if I have to make a decision and

00:16:48,130 --> 00:16:54,320
20% 30% sometimes 80% of my data is just

00:16:51,740 --> 00:16:56,000
not perfect for me to actually do the

00:16:54,320 --> 00:16:58,160
calculation or do something it happens

00:16:56,000 --> 00:16:59,959
all the time whether it's in banking and

00:16:58,160 --> 00:17:01,760
pharma and just a lot of lot of fields

00:16:59,959 --> 00:17:03,709
how do I deal with that how do I fill

00:17:01,760 --> 00:17:06,500
the gap and my choices are I'm gonna

00:17:03,709 --> 00:17:09,919
throw stuff out which then regulators

00:17:06,500 --> 00:17:12,110
find difficult or I'm gonna say wait a

00:17:09,919 --> 00:17:14,900
second I'm gonna use the last value of

00:17:12,110 --> 00:17:17,419
what I had before or I'm gonna find some

00:17:14,900 --> 00:17:19,339
other way to fix the problem so we have

00:17:17,419 --> 00:17:22,209
a principled way of fixing it that's

00:17:19,339 --> 00:17:26,780
explainable fair trusted and and so on

00:17:22,209 --> 00:17:29,240
and it as able to perform two to three

00:17:26,780 --> 00:17:31,820
times better than the manual system that

00:17:29,240 --> 00:17:33,800
people deploy so that's kind of a really

00:17:31,820 --> 00:17:36,770
interesting after effect of having this

00:17:33,800 --> 00:17:39,350
learned outcome system with live vector

00:17:36,770 --> 00:17:42,770
embeddings and the digital twin kind of

00:17:39,350 --> 00:17:45,770
capability where we're able to process

00:17:42,770 --> 00:17:48,200
as I mentioned before you know billions

00:17:45,770 --> 00:17:50,960
of transactions for anti-mining

00:17:48,200 --> 00:17:53,480
during a financial fraud in you know per

00:17:50,960 --> 00:17:56,299
day and then produce really impressive

00:17:53,480 --> 00:17:59,570
results in terms of very low false

00:17:56,299 --> 00:18:02,510
positive numbers we can really uplift

00:17:59,570 --> 00:18:04,190
and a cross sell upsell for folks like

00:18:02,510 --> 00:18:07,639
if I'm selling a mortgage and I'm gonna

00:18:04,190 --> 00:18:10,639
sell an auto loan how do I do that

00:18:07,639 --> 00:18:12,529
because just you know just 1% or 2% lift

00:18:10,639 --> 00:18:14,000
is gonna give me hundreds of millions of

00:18:12,529 --> 00:18:15,950
dollars normally even if I'm a small

00:18:14,000 --> 00:18:17,960
bank right so it's it's a very

00:18:15,950 --> 00:18:20,120
interesting ability to do that again

00:18:17,960 --> 00:18:22,880
based on these kind of things how do I

00:18:20,120 --> 00:18:25,340
Drive much quicker customer interaction

00:18:22,880 --> 00:18:27,380
from a perspective of you know

00:18:25,340 --> 00:18:29,929
everybody's been in a voicemail jail

00:18:27,380 --> 00:18:31,730
when you're you know you have to say 20

00:18:29,929 --> 00:18:33,769
things to get to the punchline and it's

00:18:31,730 --> 00:18:36,019
just it's just one sentence would do it

00:18:33,769 --> 00:18:37,340
if you really could do well we can do

00:18:36,019 --> 00:18:38,899
that and we can show you some of those

00:18:37,340 --> 00:18:41,269
kind of things and then last but not

00:18:38,899 --> 00:18:42,679
least for the pharma companies they

00:18:41,269 --> 00:18:44,809
can't get paid until they ship the

00:18:42,679 --> 00:18:46,610
medicine and keep you on it if you need

00:18:44,809 --> 00:18:49,370
that special that special medication

00:18:46,610 --> 00:18:52,340
well it takes so long to actually get

00:18:49,370 --> 00:18:53,750
that process through and as Rajesh you

00:18:52,340 --> 00:18:56,299
mentioned there's so many variables

00:18:53,750 --> 00:18:57,860
involved usually literally hundreds and

00:18:56,299 --> 00:18:59,600
sometimes thousands of variables

00:18:57,860 --> 00:19:01,789
involved it's very hard simply say oh

00:18:59,600 --> 00:19:03,889
yeah I know which three knobs to turn to

00:19:01,789 --> 00:19:05,750
get that down right so but we can help

00:19:03,889 --> 00:19:07,039
with that probably the most important

00:19:05,750 --> 00:19:09,110
thing I want to say today in addition to

00:19:07,039 --> 00:19:12,230
ordered ability is how fast we can

00:19:09,110 --> 00:19:14,029
deploy if somebody's got 10 ifs we can

00:19:12,230 --> 00:19:16,850
have them up and running on Z if

00:19:14,029 --> 00:19:18,350
somebody's got a power box with GPU we

00:19:16,850 --> 00:19:20,240
can have them up and running very very

00:19:18,350 --> 00:19:22,940
quickly I mean it's just said it's a

00:19:20,240 --> 00:19:25,039
very quick time to value from a

00:19:22,940 --> 00:19:26,779
perspective of getting engaged and we

00:19:25,039 --> 00:19:27,970
think that's that's a really a secret

00:19:26,779 --> 00:19:31,340
weapon at the end of the day because

00:19:27,970 --> 00:19:33,679
shifting data to any other place other

00:19:31,340 --> 00:19:36,019
than where it is already is gonna take

00:19:33,679 --> 00:19:38,779
you forget governance you know even if

00:19:36,019 --> 00:19:40,820
you bring in a Boeing it's gonna take

00:19:38,779 --> 00:19:42,139
you a very long time you know AWS has

00:19:40,820 --> 00:19:44,210
this wonderful thing that will bring out

00:19:42,139 --> 00:19:45,970
a big semi-truck on to the stage and say

00:19:44,210 --> 00:19:48,080
look what can backup your data

00:19:45,970 --> 00:19:49,909
that's all great if you're doing it in

00:19:48,080 --> 00:19:52,010
one shot you just won't be able to do it

00:19:49,909 --> 00:19:53,840
every second and that's usually how fast

00:19:52,010 --> 00:19:55,850
the transactions are generating so this

00:19:53,840 --> 00:19:58,429
just gives you a scale for why Amazon

00:19:55,850 --> 00:20:00,740
for itself has everything that it does

00:19:58,429 --> 00:20:01,970
behind this firewall so you know that's

00:20:00,740 --> 00:20:05,180
just that's just the way kind of

00:20:01,970 --> 00:20:07,280
world works right this is a little bit

00:20:05,180 --> 00:20:08,990
of the things that resorts you touched

00:20:07,280 --> 00:20:11,090
on in terms of auditable explainable

00:20:08,990 --> 00:20:13,910
fair and trustable decision-making if

00:20:11,090 --> 00:20:15,560
it's not quantifiable it cannot be

00:20:13,910 --> 00:20:17,420
established to a regulator it doesn't

00:20:15,560 --> 00:20:21,290
exist right so that's a very big deal

00:20:17,420 --> 00:20:23,690
for us and we think in terms of AI going

00:20:21,290 --> 00:20:25,040
forward if it doesn't have this the city

00:20:23,690 --> 00:20:27,350
of New York already promulgated a

00:20:25,040 --> 00:20:29,270
regulation that you cannot make business

00:20:27,350 --> 00:20:31,730
assisted decisions without ordered

00:20:29,270 --> 00:20:34,220
ability in place so and it's just a

00:20:31,730 --> 00:20:36,350
first you know with all the privacy

00:20:34,220 --> 00:20:37,760
regulations in Europe comment on strong

00:20:36,350 --> 00:20:41,720
we're sure that's gonna be the case

00:20:37,760 --> 00:20:43,640
everywhere else as well we talked about

00:20:41,720 --> 00:20:45,050
how fast we can start just a little bit

00:20:43,640 --> 00:20:47,330
of the use cases I'll give you a flavor

00:20:45,050 --> 00:20:50,150
of that so this is something we did for

00:20:47,330 --> 00:20:52,460
a bank one on data imputation and more

00:20:50,150 --> 00:20:53,930
specifically this was a data set so

00:20:52,460 --> 00:20:55,490
publicly available data set so I can

00:20:53,930 --> 00:20:57,530
show it to you not the stuff that we did

00:20:55,490 --> 00:21:00,110
for that for the bank on their own stuff

00:20:57,530 --> 00:21:02,210
but you know lots of different things

00:21:00,110 --> 00:21:05,450
that are in the Fannie Mae data

00:21:02,210 --> 00:21:06,890
this all happened to be 2008 data

00:21:05,450 --> 00:21:09,590
because it's exciting things that were

00:21:06,890 --> 00:21:11,210
happening that year for banks but you

00:21:09,590 --> 00:21:12,770
see they're different this is just the

00:21:11,210 --> 00:21:14,480
shape of data and on the left hand side

00:21:12,770 --> 00:21:16,580
and one of the things we're able to do

00:21:14,480 --> 00:21:19,910
is produce much better results even when

00:21:16,580 --> 00:21:22,970
we eliminate 25 50 or 75 percent of the

00:21:19,910 --> 00:21:25,310
data and we impute that back in and our

00:21:22,970 --> 00:21:26,990
curves which are kind of in blue if you

00:21:25,310 --> 00:21:29,630
notice I'm watching my coming much

00:21:26,990 --> 00:21:31,100
closer in line with a horizontal line

00:21:29,630 --> 00:21:33,650
than the red stuff that's kind of being

00:21:31,100 --> 00:21:36,100
derived manually using standard means so

00:21:33,650 --> 00:21:38,600
we're able to perform much better

00:21:36,100 --> 00:21:39,890
calculating and imputing the core values

00:21:38,600 --> 00:21:41,840
believe it or not these are missing from

00:21:39,890 --> 00:21:44,300
a lot of data for loans it's

00:21:41,840 --> 00:21:47,480
loan-to-value ratio and debt to income

00:21:44,300 --> 00:21:48,980
ratio the MLA use case is very

00:21:47,480 --> 00:21:51,680
interesting we're able to produce really

00:21:48,980 --> 00:21:54,110
great results again and just to give you

00:21:51,680 --> 00:21:55,730
a sense for what we were able to do and

00:21:54,110 --> 00:21:59,000
how they kind of the use cases worked

00:21:55,730 --> 00:22:01,430
was we're able to identify the you know

00:21:59,000 --> 00:22:04,670
to ingest all they know your customer

00:22:01,430 --> 00:22:06,530
data k kyc for anybody who doesn't know

00:22:04,670 --> 00:22:09,080
banking it's just know your customer

00:22:06,530 --> 00:22:10,730
these are all I call it kiss but all

00:22:09,080 --> 00:22:13,190
they're all they kind of funny acronyms

00:22:10,730 --> 00:22:15,740
that that the industry has developed but

00:22:13,190 --> 00:22:17,780
having the entity information the

00:22:15,740 --> 00:22:20,090
indications AP addresses transactions

00:22:17,780 --> 00:22:22,850
from wires etc and all the high-risk

00:22:20,090 --> 00:22:24,260
lists this is all unstructured stuff if

00:22:22,850 --> 00:22:26,600
you really think about it just a lot of

00:22:24,260 --> 00:22:28,550
texts and lists of things this is a

00:22:26,600 --> 00:22:31,370
structured data with some unstructured

00:22:28,550 --> 00:22:33,320
stuff but also most importantly a lot of

00:22:31,370 --> 00:22:34,960
the kind of graphs things who talked to

00:22:33,320 --> 00:22:38,750
whom when who did something with whom

00:22:34,960 --> 00:22:40,550
this is just IP address stuff again just

00:22:38,750 --> 00:22:43,130
to give you a sense for what some of the

00:22:40,550 --> 00:22:45,350
hyper scalars are doing Google is using

00:22:43,130 --> 00:22:48,140
the same vector Tec for its search

00:22:45,350 --> 00:22:51,980
engine today so search used to be rules

00:22:48,140 --> 00:22:53,420
based and you know I dress bass where

00:22:51,980 --> 00:22:56,059
the rules were specifically derived on

00:22:53,420 --> 00:22:58,340
that today it's all probabilistic and

00:22:56,059 --> 00:23:00,559
then we drive that two kind of behavior

00:22:58,340 --> 00:23:02,780
anomalies in in kind of chapter two

00:23:00,559 --> 00:23:05,120
where we're detect bad actors and are

00:23:02,780 --> 00:23:06,920
able to act on that and then of course

00:23:05,120 --> 00:23:09,950
alert the right authorities and producer

00:23:06,920 --> 00:23:12,590
reports this is the example that I used

00:23:09,950 --> 00:23:16,550
earlier which was the customer

00:23:12,590 --> 00:23:18,620
interaction distillation and they the

00:23:16,550 --> 00:23:21,110
real value there that we're able to do

00:23:18,620 --> 00:23:23,360
is imagine you put in a business outcome

00:23:21,110 --> 00:23:25,370
this is work for a collection call right

00:23:23,360 --> 00:23:27,380
so and the interesting part about the

00:23:25,370 --> 00:23:29,300
collection call is this is a person who

00:23:27,380 --> 00:23:31,760
is saying hey I'm calling in I'm calling

00:23:29,300 --> 00:23:34,010
the bank and I'm saying I lost my job

00:23:31,760 --> 00:23:36,380
but I got a new job and you know I'm

00:23:34,010 --> 00:23:39,200
gonna be able to pay you but I'm gonna

00:23:36,380 --> 00:23:41,690
be late well we're able to immediately

00:23:39,200 --> 00:23:44,120
understand the intent of that caller in

00:23:41,690 --> 00:23:46,250
two interactions versus twenty just like

00:23:44,120 --> 00:23:49,429
I mentioned before and quantify that so

00:23:46,250 --> 00:23:51,110
that this can be done to really improve

00:23:49,429 --> 00:23:53,600
and give ops AI

00:23:51,110 --> 00:23:55,370
as one of our colleagues were saying

00:23:53,600 --> 00:23:58,730
earlier it's it's it's a big deal to

00:23:55,370 --> 00:24:01,460
operationalize kind of you know to

00:23:58,730 --> 00:24:03,170
operationalize and really improve that

00:24:01,460 --> 00:24:04,970
the ops side of the house but this is

00:24:03,170 --> 00:24:07,070
kind of the ops AI example on the

00:24:04,970 --> 00:24:08,840
transactions we can also do sentiment on

00:24:07,070 --> 00:24:11,330
voice as the caller is calling in and

00:24:08,840 --> 00:24:19,700
identify if somebody's angry or happy or

00:24:11,330 --> 00:24:20,720
sad and kind of act accordingly so the

00:24:19,700 --> 00:24:23,600
interesting one of the interesting use

00:24:20,720 --> 00:24:25,580
cases we have is that when a situation

00:24:23,600 --> 00:24:27,320
is such that you can kind of influence

00:24:25,580 --> 00:24:28,800
somebody and you have their service

00:24:27,320 --> 00:24:30,390
records or other things we did

00:24:28,800 --> 00:24:32,730
this with a very large cable company for

00:24:30,390 --> 00:24:35,760
example nobody likes cable companies but

00:24:32,730 --> 00:24:37,320
that's yeah this is what it is but to be

00:24:35,760 --> 00:24:38,940
able to then influence the discussion

00:24:37,320 --> 00:24:42,180
and kind of nudge it in the right way so

00:24:38,940 --> 00:24:44,040
that customer becomes loyal for life it

00:24:42,180 --> 00:24:47,130
is is where the opportunity is when

00:24:44,040 --> 00:24:49,500
things are quantified this is a little

00:24:47,130 --> 00:24:52,230
bit of the example with the kind of

00:24:49,500 --> 00:24:54,350
transactions learning where normally you

00:24:52,230 --> 00:24:57,930
get this kind of a transaction and

00:24:54,350 --> 00:24:59,760
wouldn't be nice to get from this if you

00:24:57,930 --> 00:25:01,680
of the whole thing where on the left

00:24:59,760 --> 00:25:03,600
hand side this kind of you know the

00:25:01,680 --> 00:25:04,920
counting view or the classic analytical

00:25:03,600 --> 00:25:06,990
view can tell you the basket size

00:25:04,920 --> 00:25:08,490
frequency and all the things what we can

00:25:06,990 --> 00:25:11,070
tell you is what kind of customer is

00:25:08,490 --> 00:25:12,660
that and more importantly what should we

00:25:11,070 --> 00:25:15,570
do with that customer from a decision

00:25:12,660 --> 00:25:17,460
perspective to improve on you know where

00:25:15,570 --> 00:25:20,520
they need to be right that's kind of a

00:25:17,460 --> 00:25:22,170
little bit of a flavor of that last but

00:25:20,520 --> 00:25:23,880
not least we said that we can do that

00:25:22,170 --> 00:25:26,400
scale with all the global things with

00:25:23,880 --> 00:25:28,920
this something for a very large media

00:25:26,400 --> 00:25:32,100
company where we basically gave them a

00:25:28,920 --> 00:25:34,470
better way to view the world the Nielsen

00:25:32,100 --> 00:25:36,390
was able to give them in terms of where

00:25:34,470 --> 00:25:38,160
to place advertisements and how to drive

00:25:36,390 --> 00:25:40,620
their their value for the kind of

00:25:38,160 --> 00:25:43,620
audience they needed again processing

00:25:40,620 --> 00:25:45,480
all the social signals from a lot of

00:25:43,620 --> 00:25:49,590
social sources you know Twitter Facebook

00:25:45,480 --> 00:25:51,030
and and YouTube so that you can do these

00:25:49,590 --> 00:25:52,650
kind of things you can say hey I want to

00:25:51,030 --> 00:25:56,280
advertise on this particular show versus

00:25:52,650 --> 00:25:57,360
kind of the other one and so on I think

00:25:56,280 --> 00:25:58,650
that's the background I'm gonna stop

00:25:57,360 --> 00:26:01,050
here see if there's any questions

00:25:58,650 --> 00:26:03,230
there's more slides we can post and so

00:26:01,050 --> 00:26:03,230
on

00:26:08,880 --> 00:26:17,350
yes so the collection is sure so the

00:26:16,030 --> 00:26:19,030
collection is used case I'll come back

00:26:17,350 --> 00:26:24,460
to the real quick so the collections use

00:26:19,030 --> 00:26:27,070
case was the folks wanted to get very

00:26:24,460 --> 00:26:29,140
quickly to what the person was really

00:26:27,070 --> 00:26:30,580
wanted to do and in this case the

00:26:29,140 --> 00:26:33,880
business outcome they were able to

00:26:30,580 --> 00:26:36,250
specify here was how let's great a

00:26:33,880 --> 00:26:37,900
conversation right this were all live

00:26:36,250 --> 00:26:39,550
conversations that were going on so they

00:26:37,900 --> 00:26:42,780
should be done like live in real time

00:26:39,550 --> 00:26:45,580
right so you have somebody talking and

00:26:42,780 --> 00:26:48,490
this conversation is being graded and

00:26:45,580 --> 00:26:50,910
there's two people talking there is the

00:26:48,490 --> 00:26:53,410
customer and there is an agent right and

00:26:50,910 --> 00:26:55,450
this view on all the way in the right

00:26:53,410 --> 00:26:58,240
hand side agent has like another way of

00:26:55,450 --> 00:27:00,310
being augmented and and helping the

00:26:58,240 --> 00:27:02,740
customer in the conversation to get them

00:27:00,310 --> 00:27:06,310
to that outcome but instead of doing it

00:27:02,740 --> 00:27:07,990
from you know getting their name and all

00:27:06,310 --> 00:27:09,670
the other kind of information we can get

00:27:07,990 --> 00:27:12,370
to the to the punch lines very very

00:27:09,670 --> 00:27:14,590
quickly and grade this to hey this whole

00:27:12,370 --> 00:27:18,940
conversation is actually highly

00:27:14,590 --> 00:27:22,600
quantified to meet the objective of this

00:27:18,940 --> 00:27:24,790
person is likely to pay because we

00:27:22,600 --> 00:27:27,130
understood quickly that when they got a

00:27:24,790 --> 00:27:28,600
new job they're gonna pay

00:27:27,130 --> 00:27:31,180
because therefore if you were just

00:27:28,600 --> 00:27:33,490
looking for any kind of automation that

00:27:31,180 --> 00:27:35,260
was looking for kind of text or a word

00:27:33,490 --> 00:27:36,430
know the bag of words or anything else

00:27:35,260 --> 00:27:37,870
it's very difficult to do that because

00:27:36,430 --> 00:27:39,700
one of the things that's gonna be there

00:27:37,870 --> 00:27:42,250
and a signal is gonna be I lost my job

00:27:39,700 --> 00:27:44,290
which normally means I'm gonna be able

00:27:42,250 --> 00:27:46,540
to pay you we can understand very

00:27:44,290 --> 00:27:49,120
quickly all that as it's going on and

00:27:46,540 --> 00:27:50,500
then quantify it and that's because of

00:27:49,120 --> 00:27:54,280
the embedding that we discussed earlier

00:27:50,500 --> 00:27:56,680
so imagine the business could in in raw

00:27:54,280 --> 00:27:59,680
text say that it could be likely to pay

00:27:56,680 --> 00:28:02,110
or you know or likely to churn or likely

00:27:59,680 --> 00:28:04,420
to cross-sell or upsell so you the

00:28:02,110 --> 00:28:06,220
business would specify what is the

00:28:04,420 --> 00:28:09,400
outcome that they're looking for in raw

00:28:06,220 --> 00:28:11,680
text and effectively the conversation is

00:28:09,400 --> 00:28:14,650
now graded in real time with respect to

00:28:11,680 --> 00:28:16,450
that given desired business outcome so

00:28:14,650 --> 00:28:21,180
that the conversation could be nudged in

00:28:16,450 --> 00:28:21,180
the right way to get to the get to the

00:28:24,929 --> 00:28:30,450
other questions yes sir

00:28:33,940 --> 00:28:41,460
yes yes sure so so supposing you know

00:28:39,580 --> 00:28:44,200
supposing we are looking at a map and

00:28:41,460 --> 00:28:45,430
the map has you know latitude and

00:28:44,200 --> 00:28:48,730
longitude so those are the two

00:28:45,430 --> 00:28:51,430
coordinates for the city of New York so

00:28:48,730 --> 00:28:54,190
you can then specify give me the cities

00:28:51,430 --> 00:28:56,500
within a mile within a within a 50-mile

00:28:54,190 --> 00:28:58,510
radius because you know the coordinates

00:28:56,500 --> 00:29:00,490
of the nearby cities we can figure out

00:28:58,510 --> 00:29:04,510
who are the nearby cities with respect

00:29:00,490 --> 00:29:07,150
to New York okay so now imagine we have

00:29:04,510 --> 00:29:09,580
the same problem but instead of cities

00:29:07,150 --> 00:29:11,320
we have customers and for customers for

00:29:09,580 --> 00:29:13,840
each Associated customers we not only

00:29:11,320 --> 00:29:15,700
have numbers in which case it is easy to

00:29:13,840 --> 00:29:18,460
figure out who are the nearby customers

00:29:15,700 --> 00:29:20,950
but we also have who the customers spoke

00:29:18,460 --> 00:29:23,380
with what you know who are the other

00:29:20,950 --> 00:29:26,800
interactions what what items did they

00:29:23,380 --> 00:29:29,440
buy from who from which merchants what

00:29:26,800 --> 00:29:32,080
texts that they have published on social

00:29:29,440 --> 00:29:34,120
media or customer interactions so all of

00:29:32,080 --> 00:29:37,120
this all these records are going into

00:29:34,120 --> 00:29:39,670
this particular customer but because

00:29:37,120 --> 00:29:42,670
these are not numbers these are words

00:29:39,670 --> 00:29:44,860
these could be images text it is not

00:29:42,670 --> 00:29:46,660
possible to like on a map so you know

00:29:44,860 --> 00:29:49,240
give me latitude longitude I can figure

00:29:46,660 --> 00:29:52,750
out nearby this nearby cities I can't do

00:29:49,240 --> 00:29:56,140
that so this idea of learn vector

00:29:52,750 --> 00:29:59,140
embeddings transforms all of these

00:29:56,140 --> 00:30:01,660
disparate data into numbers into you

00:29:59,140 --> 00:30:03,820
know array number arrays and now if once

00:30:01,660 --> 00:30:06,640
everything is in numbers we have a

00:30:03,820 --> 00:30:08,230
common backplane and on this backplane

00:30:06,640 --> 00:30:12,220
we can find distances we can find

00:30:08,230 --> 00:30:15,040
similarities so a really easy example

00:30:12,220 --> 00:30:17,440
that we use in the language in in kind

00:30:15,040 --> 00:30:19,780
of vector space would be what's up there

00:30:17,440 --> 00:30:22,450
for natural language processing a vector

00:30:19,780 --> 00:30:25,090
space for human plus the vector space

00:30:22,450 --> 00:30:26,740
for a robot makes a prediction and says

00:30:25,090 --> 00:30:28,750
oh it's just like a vector space for

00:30:26,740 --> 00:30:30,040
cyborgs we're never told that concept

00:30:28,750 --> 00:30:31,780
we'll never did any of that stuff but it

00:30:30,040 --> 00:30:35,200
automatically gives you the answer and

00:30:31,780 --> 00:30:37,330
it's very similar to that idea in think

00:30:35,200 --> 00:30:40,710
of it in transaction space that's kind

00:30:37,330 --> 00:30:40,710
of the that's the aha

00:30:54,120 --> 00:30:59,200
it's like look you can think of as

00:30:56,470 --> 00:31:01,629
locality-sensitive hashing it's fine

00:30:59,200 --> 00:31:03,129
there is there are shortcuts literally

00:31:01,629 --> 00:31:05,830
so of all puns intended there are

00:31:03,129 --> 00:31:08,080
shortcuts that look at a lot of

00:31:05,830 --> 00:31:09,490
nonlinear stuff that deep learning does

00:31:08,080 --> 00:31:11,350
everything else throw hash like

00:31:09,490 --> 00:31:12,720
functions there's there's hashing all

00:31:11,350 --> 00:31:15,700
shortcuts for some of the

00:31:12,720 --> 00:31:18,580
implementations without using GPUs for

00:31:15,700 --> 00:31:25,299
this kind of stuff right VW's one for

00:31:18,580 --> 00:31:26,649
example that is the big deal you don't

00:31:25,299 --> 00:31:29,169
have to be sitting there saying oh

00:31:26,649 --> 00:31:30,970
here's a thousand pictures of cats here

00:31:29,169 --> 00:31:32,529
this out million pictures of cats here's

00:31:30,970 --> 00:31:33,580
a million pictures of dogs now you can

00:31:32,529 --> 00:31:36,129
tell the difference and then you get to

00:31:33,580 --> 00:31:37,629
the wolf problem right it will learn it

00:31:36,129 --> 00:31:39,639
from your data most want me to learn it

00:31:37,629 --> 00:31:41,830
from your transactional data right and

00:31:39,639 --> 00:31:44,259
and so for example the likely to pay

00:31:41,830 --> 00:31:46,840
that was a business that was the desired

00:31:44,259 --> 00:31:49,960
business outcome so I can do a keyword

00:31:46,840 --> 00:31:52,899
matching for you know the words likely

00:31:49,960 --> 00:31:55,539
to pay I'll find this some small subset

00:31:52,899 --> 00:32:00,399
but if I can find in the semantic space

00:31:55,539 --> 00:32:02,499
of ideas and phrases that are nearby in

00:32:00,399 --> 00:32:05,379
the semantic space then I have a much

00:32:02,499 --> 00:32:07,269
much richer corpus and I can make that

00:32:05,379 --> 00:32:09,820
connection and I if I can quantify that

00:32:07,269 --> 00:32:16,679
semantic distance we are you know we're

00:32:09,820 --> 00:32:16,679
good any other questions

00:32:17,100 --> 00:32:22,590
all right thank you very very much

00:32:19,590 --> 00:32:22,590

YouTube URL: https://www.youtube.com/watch?v=MYAN0wSyLBY


