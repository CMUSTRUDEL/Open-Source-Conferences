Title: OpenPOWER Summit US 2018: Hybrid Memory Platform
Publication date: 2018-04-03
Playlist: OpenPOWER Summit US 2018
Description: 
	OpenPOWER member from Rambus discusses their use of POWER technology at OpenPOWER Summit 2018.

Presenter: 
- Kenneth Wright, Sr. Director - Rambus Labs, Rambus

For more information, please visit: http://www.openpowerfoundation.org
Captions: 
	00:00:00,120 --> 00:00:05,609
my name is Kenneth right I'm senior

00:00:02,280 --> 00:00:09,960
director in Rambis labs the research arm

00:00:05,609 --> 00:00:12,120
of Rambis recently a new open power open

00:00:09,960 --> 00:00:14,580
Cappy member I'm here to talk to you

00:00:12,120 --> 00:00:17,039
today about hybrid a hybrid memory

00:00:14,580 --> 00:00:20,250
platform and research into emerging

00:00:17,039 --> 00:00:24,570
memories that we are developing for the

00:00:20,250 --> 00:00:28,199
open Cappy and power now in systems as

00:00:24,570 --> 00:00:29,490
an outline I'd like to start with giving

00:00:28,199 --> 00:00:32,070
you a bit of background or the

00:00:29,490 --> 00:00:34,890
opportunity that we see in memory

00:00:32,070 --> 00:00:36,239
subsystem design going forward then a

00:00:34,890 --> 00:00:38,399
little bit of the research that we've

00:00:36,239 --> 00:00:40,550
been carrying on in the hybrid memory

00:00:38,399 --> 00:00:42,930
arena for the last couple of years

00:00:40,550 --> 00:00:45,899
including some results of our simulation

00:00:42,930 --> 00:00:48,840
environment then I'd like to talk to you

00:00:45,899 --> 00:00:52,379
about our hardware platform that we are

00:00:48,840 --> 00:00:56,910
building and seeking collaboration own

00:00:52,379 --> 00:00:58,379
that is used to evaluate some of the

00:00:56,910 --> 00:01:00,510
management schemes that we've developed

00:00:58,379 --> 00:01:01,649
through simulation and then talk a

00:01:00,510 --> 00:01:05,309
little bit about the collaboration

00:01:01,649 --> 00:01:08,010
itself so we start with the opportunity

00:01:05,309 --> 00:01:12,810
and this is kind of the memories version

00:01:08,010 --> 00:01:14,520
of the Moore's Law graph I originally

00:01:12,810 --> 00:01:16,650
had pulled it from my slides but I saw

00:01:14,520 --> 00:01:20,610
that everyone was using it so I said ok

00:01:16,650 --> 00:01:23,400
I'll put it back in so this is showing

00:01:20,610 --> 00:01:26,340
the driving factor in memory which is

00:01:23,400 --> 00:01:31,170
really has capacity for a given

00:01:26,340 --> 00:01:33,240
investment how it has decreased over

00:01:31,170 --> 00:01:36,299
time basically it's saying bits in the

00:01:33,240 --> 00:01:39,360
future are always cost less than bits

00:01:36,299 --> 00:01:42,750
today and as we continue to see capacity

00:01:39,360 --> 00:01:45,780
increasing the demand for capacity

00:01:42,750 --> 00:01:48,210
increasing we also see the slowing of

00:01:45,780 --> 00:01:51,509
this curve especially around DRAM which

00:01:48,210 --> 00:01:54,720
is a primarily memory component in a

00:01:51,509 --> 00:01:57,630
memory subsystem nowadays and then we're

00:01:54,720 --> 00:02:00,420
starting to also see here a bit of NAND

00:01:57,630 --> 00:02:03,600
flash which is kind of the highest speed

00:02:00,420 --> 00:02:06,149
storage component so when I talk about

00:02:03,600 --> 00:02:09,660
memory I'm really talking about things

00:02:06,149 --> 00:02:11,849
that have load store access out to our

00:02:09,660 --> 00:02:13,710
out from the processor when I talk about

00:02:11,849 --> 00:02:16,740
storage I talk about something that's

00:02:13,710 --> 00:02:19,560
only page din or isn't directly accessed

00:02:16,740 --> 00:02:22,770
through a load store model and the cost

00:02:19,560 --> 00:02:25,950
gap between the two is continuing to

00:02:22,770 --> 00:02:28,110
grow that everyone knows but also both

00:02:25,950 --> 00:02:32,280
curves are bigoted are continuing to

00:02:28,110 --> 00:02:35,670
flatten and not accelerate the capacity

00:02:32,280 --> 00:02:39,300
growth like we're used to for the same

00:02:35,670 --> 00:02:41,250
investment so he's been talked about for

00:02:39,300 --> 00:02:43,410
a long time that emerging memories the

00:02:41,250 --> 00:02:46,890
new memories on the market will come in

00:02:43,410 --> 00:02:49,020
and help fill this gap but those have

00:02:46,890 --> 00:02:51,810
had to struggle they're still emerging

00:02:49,020 --> 00:02:53,670
into the memory subsystem although some

00:02:51,810 --> 00:02:57,540
of them have emerged into the storage

00:02:53,670 --> 00:02:59,310
subsystem so we see a lot of big

00:02:57,540 --> 00:03:03,600
opportunities in the memory subsystem

00:02:59,310 --> 00:03:05,970
and I think that this is you know shown

00:03:03,600 --> 00:03:07,950
by the amount of disruption it's

00:03:05,970 --> 00:03:10,380
presently going on in the modern memory

00:03:07,950 --> 00:03:13,320
subsystems this level of disruption

00:03:10,380 --> 00:03:16,440
hasn't been seen in decades we're seeing

00:03:13,320 --> 00:03:19,080
new attachment strategies new ways of

00:03:16,440 --> 00:03:22,140
attaching memory into the central

00:03:19,080 --> 00:03:25,200
processing unit right open Cappy jens

00:03:22,140 --> 00:03:26,670
ECC IX are all proposed as ways that in

00:03:25,200 --> 00:03:29,190
the future we'll be able to attach

00:03:26,670 --> 00:03:32,490
memory to our systems we're seeing

00:03:29,190 --> 00:03:37,970
extensions of the standard dr dim

00:03:32,490 --> 00:03:41,550
protocols and things like transactional

00:03:37,970 --> 00:03:43,470
aspects we are also seeing new module

00:03:41,550 --> 00:03:45,450
architectures people are beginning to

00:03:43,470 --> 00:03:49,790
talk about differential dim using

00:03:45,450 --> 00:03:52,920
differential signaling out to a dim or

00:03:49,790 --> 00:03:54,960
non-volatile dims like nvm in which has

00:03:52,920 --> 00:04:00,020
had some deployments already in hyper

00:03:54,960 --> 00:04:04,130
scale systems inv tempi a fundamentally

00:04:00,020 --> 00:04:08,310
similar technique where both DRAM and

00:04:04,130 --> 00:04:11,220
flash a technology that is very much

00:04:08,310 --> 00:04:14,190
emerged in the storage but has yet to

00:04:11,220 --> 00:04:17,970
emerge in memory are being combined onto

00:04:14,190 --> 00:04:19,380
one module and all the different memory

00:04:17,970 --> 00:04:21,989
types that we're seeing all the

00:04:19,380 --> 00:04:23,940
different ways of storing bits various

00:04:21,989 --> 00:04:26,700
types of resistive Ram or our Ram

00:04:23,940 --> 00:04:27,240
various types of magnetic Ram including

00:04:26,700 --> 00:04:30,150
spent

00:04:27,240 --> 00:04:33,050
work memory PCM memory and now we're

00:04:30,150 --> 00:04:37,319
seeing the emergence of ultra high speed

00:04:33,050 --> 00:04:40,050
ultra-low latency flash that looks like

00:04:37,319 --> 00:04:42,319
it would be a good candidate for the

00:04:40,050 --> 00:04:47,030
memory subsystem

00:04:42,319 --> 00:04:52,889
but none of these technologies have a

00:04:47,030 --> 00:04:54,750
directly sir plant DRAM you have DRAM

00:04:52,889 --> 00:04:59,000
which has incredibly low latency

00:04:54,750 --> 00:05:03,449
Hardware latency 30 nanoseconds or so

00:04:59,000 --> 00:05:06,509
almost infinite endurance bright energy

00:05:03,449 --> 00:05:10,110
because charge is being stored is very

00:05:06,509 --> 00:05:11,909
low it's very manufacturable although

00:05:10,110 --> 00:05:14,880
some people might argue with that now

00:05:11,909 --> 00:05:17,669
that we have super towers of capacitors

00:05:14,880 --> 00:05:19,370
and things like this but it is proven to

00:05:17,669 --> 00:05:22,199
be and continues to be very

00:05:19,370 --> 00:05:25,740
manufacturable and has quite good

00:05:22,199 --> 00:05:27,650
capacity none of the other technologies

00:05:25,740 --> 00:05:31,530
that are coming to the forefront

00:05:27,650 --> 00:05:34,680
completely replace this flash even

00:05:31,530 --> 00:05:36,479
high-speed flash is very manufacturable

00:05:34,680 --> 00:05:42,270
and it's been shown to scale quite well

00:05:36,479 --> 00:05:43,830
has better capacity than DRAM but its

00:05:42,270 --> 00:05:46,860
latency is not as good

00:05:43,830 --> 00:05:49,169
especially around writes its endurance

00:05:46,860 --> 00:05:53,460
has to be managed very carefully and

00:05:49,169 --> 00:05:56,340
it's right energy can be in a comparable

00:05:53,460 --> 00:05:59,280
level if you go across the chart you see

00:05:56,340 --> 00:06:01,740
that none of these memories will

00:05:59,280 --> 00:06:05,280
completely supplant DRAM and matter of

00:06:01,740 --> 00:06:09,240
fact it's my belief that a hybridization

00:06:05,280 --> 00:06:11,669
of DRAM and an emerging memory is where

00:06:09,240 --> 00:06:15,930
the future lies and this is something

00:06:11,669 --> 00:06:18,120
that we kind of rallied around a couple

00:06:15,930 --> 00:06:20,430
of years ago and said if this is the way

00:06:18,120 --> 00:06:22,620
that we will eventually be building

00:06:20,430 --> 00:06:25,110
memory subsystem someone needs to go out

00:06:22,620 --> 00:06:27,930
into the forefront and start trying

00:06:25,110 --> 00:06:31,490
these things try the hybridization and

00:06:27,930 --> 00:06:34,710
see what the right ratios are the right

00:06:31,490 --> 00:06:37,500
algorithms management schemes you know

00:06:34,710 --> 00:06:39,680
in memory in many ways we've had a

00:06:37,500 --> 00:06:42,770
hybrid memory subsystem forever

00:06:39,680 --> 00:06:46,340
the very first memory subsystem that I

00:06:42,770 --> 00:06:49,400
remember reading about was all SRAM it

00:06:46,340 --> 00:06:52,820
was a crazy loved SRAM so much he made

00:06:49,400 --> 00:06:54,979
his entire memory out of it right as for

00:06:52,820 --> 00:06:58,310
him is still in our memory subsystem it

00:06:54,979 --> 00:07:00,740
makes up our caches it DRAM never fully

00:06:58,310 --> 00:07:02,780
supplanted it and I believe that these

00:07:00,740 --> 00:07:05,090
emerging memory technologies will go

00:07:02,780 --> 00:07:07,520
that same way you'll never see them

00:07:05,090 --> 00:07:15,169
fully supplant DRAM that will be a

00:07:07,520 --> 00:07:17,600
hybridization in the stack so when we

00:07:15,169 --> 00:07:19,690
started this research we had a simple

00:07:17,600 --> 00:07:21,919
goal investigate memory subsystem

00:07:19,690 --> 00:07:25,940
architectures and attachment strategies

00:07:21,919 --> 00:07:28,789
of the future specifically multiple

00:07:25,940 --> 00:07:30,919
memory types in a memory subsystem not

00:07:28,789 --> 00:07:34,130
just DRAM but a memory subsystem

00:07:30,919 --> 00:07:37,669
consisting of DRAM with one of the

00:07:34,130 --> 00:07:39,080
emerging memory technologies also to

00:07:37,669 --> 00:07:41,389
investigate multiple different

00:07:39,080 --> 00:07:44,360
attachment scheme serially attached

00:07:41,389 --> 00:07:47,599
direct attached and other things but it

00:07:44,360 --> 00:07:51,110
was it very quickly became obvious that

00:07:47,599 --> 00:07:53,690
the management techniques were the thing

00:07:51,110 --> 00:07:57,229
that was either going to make or break

00:07:53,690 --> 00:07:59,599
this type of memory subsystem how do you

00:07:57,229 --> 00:08:01,849
manage the endurance how do you manage

00:07:59,599 --> 00:08:04,880
the latency how do you manage the band

00:08:01,849 --> 00:08:07,340
width of your emerging memory and how do

00:08:04,880 --> 00:08:11,659
you use your DRAM effectively to do that

00:08:07,340 --> 00:08:12,860
management so going forward we're

00:08:11,659 --> 00:08:15,710
wanting to create a collaborative

00:08:12,860 --> 00:08:19,039
ecosystem of academic and industry

00:08:15,710 --> 00:08:22,130
partners to develop a prototyping system

00:08:19,039 --> 00:08:27,010
where we can all experiment in these

00:08:22,130 --> 00:08:30,620
management areas and get very rapid and

00:08:27,010 --> 00:08:31,810
very collaborative designs to go forward

00:08:30,620 --> 00:08:33,969
okay

00:08:31,810 --> 00:08:36,620
but I'm getting a bit ahead of myself

00:08:33,969 --> 00:08:38,990
let me talk a little bit about the

00:08:36,620 --> 00:08:40,640
tracks of research that we've been

00:08:38,990 --> 00:08:44,300
performing in the way we see this

00:08:40,640 --> 00:08:46,640
evolving we see three primary tracks

00:08:44,300 --> 00:08:51,440
performance modeling or simulation

00:08:46,640 --> 00:08:52,850
Hardware prototyping and management both

00:08:51,440 --> 00:08:54,800
in software and hardware

00:08:52,850 --> 00:08:56,690
performance modeling we've been doing

00:08:54,800 --> 00:09:00,590
for approximately two years on a gym

00:08:56,690 --> 00:09:02,870
five base system and we've seen some

00:09:00,590 --> 00:09:05,630
very promising results but like any

00:09:02,870 --> 00:09:08,030
simulation it has some challenges first

00:09:05,630 --> 00:09:10,910
compared to actual hardware it's quite

00:09:08,030 --> 00:09:13,220
slow and it takes a long time to run any

00:09:10,910 --> 00:09:17,480
sizable benchmark and many benchmarks

00:09:13,220 --> 00:09:19,430
are just intractable in simulation so it

00:09:17,480 --> 00:09:22,250
also limits the number of scenarios we

00:09:19,430 --> 00:09:26,270
can run because of the speed and you

00:09:22,250 --> 00:09:29,120
know the shortness of our lifespan then

00:09:26,270 --> 00:09:31,300
we and then we also the most troubling

00:09:29,120 --> 00:09:33,980
for me is the simulation assumptions

00:09:31,300 --> 00:09:35,750
anytime you build a simulation engine

00:09:33,980 --> 00:09:38,690
there are certain assumptions that are

00:09:35,750 --> 00:09:40,670
sometimes not even in your forefront of

00:09:38,690 --> 00:09:43,430
your consciousness that you make when

00:09:40,670 --> 00:09:46,670
building it that may not be validated

00:09:43,430 --> 00:09:49,400
when you move to real Hardware so we're

00:09:46,670 --> 00:09:51,230
now ready to move into the next stage in

00:09:49,400 --> 00:09:53,480
the next track not that the first tract

00:09:51,230 --> 00:09:55,970
is going to stop but the next track is

00:09:53,480 --> 00:09:59,690
taking some of the management techniques

00:09:55,970 --> 00:10:01,520
that we've developed and implementing

00:09:59,690 --> 00:10:06,140
them in actual hardware so we can run

00:10:01,520 --> 00:10:08,750
full benchmarks own a custom board with

00:10:06,140 --> 00:10:11,720
real power 9 and open Caffey interfaces

00:10:08,750 --> 00:10:14,960
so that is the stage that we're moving

00:10:11,720 --> 00:10:17,630
into now we are also continuing our work

00:10:14,960 --> 00:10:18,280
on software and hardware management

00:10:17,630 --> 00:10:21,200
schemes

00:10:18,280 --> 00:10:24,290
I've been calling when a memory

00:10:21,200 --> 00:10:26,750
subsystem is managed by Hardware I've

00:10:24,290 --> 00:10:28,100
been calling it hybrid memory and many

00:10:26,750 --> 00:10:30,200
of the academics are starting to pick up

00:10:28,100 --> 00:10:32,390
on this when it's managed by software

00:10:30,200 --> 00:10:35,060
and it's exposed where data placement

00:10:32,390 --> 00:10:37,580
and data migration is done by software I

00:10:35,060 --> 00:10:40,640
call it heterogeneous so you'll hear me

00:10:37,580 --> 00:10:44,330
use those two terms in the presentation

00:10:40,640 --> 00:10:47,570
but in general something needs to manage

00:10:44,330 --> 00:10:51,410
data placement and data movement between

00:10:47,570 --> 00:10:52,820
the different memory types okay so I

00:10:51,410 --> 00:10:55,430
must show a little bit of our simulation

00:10:52,820 --> 00:10:57,170
results which I find very promising and

00:10:55,430 --> 00:10:59,360
it's one reason that we're so excited

00:10:57,170 --> 00:11:01,700
about moving forward it takes a few

00:10:59,360 --> 00:11:04,400
minutes to completely walk through this

00:11:01,700 --> 00:11:05,840
too so you get the gist of what the

00:11:04,400 --> 00:11:10,190
simulation is saying

00:11:05,840 --> 00:11:11,720
so we've done detailed simulations where

00:11:10,190 --> 00:11:14,590
we've looked at both read performance

00:11:11,720 --> 00:11:18,470
bandwidth and latency write performance

00:11:14,590 --> 00:11:20,140
endurance hybrid capacity ratios you'll

00:11:18,470 --> 00:11:22,610
see what I mean by that in a minute and

00:11:20,140 --> 00:11:26,510
different attributes of the emerging

00:11:22,610 --> 00:11:29,330
memory so let me tell you how to read

00:11:26,510 --> 00:11:31,250
the chart on the Left we have various

00:11:29,330 --> 00:11:33,730
workloads this is a small sample of the

00:11:31,250 --> 00:11:36,500
workloads we've run in simulation and we

00:11:33,730 --> 00:11:38,210
suppose a memory subsystem in this

00:11:36,500 --> 00:11:41,960
particular case we supposed a one

00:11:38,210 --> 00:11:45,140
terabyte memory subsystem and we said if

00:11:41,960 --> 00:11:47,210
we made that out of all DRAM and ran the

00:11:45,140 --> 00:11:50,480
workload we'll call that one as our

00:11:47,210 --> 00:11:54,440
reference point that is basically

00:11:50,480 --> 00:11:57,560
execution time but there may be many

00:11:54,440 --> 00:12:00,170
reasons why a terabyte memory subsystem

00:11:57,560 --> 00:12:04,100
of all DRAM may not be tractable either

00:12:00,170 --> 00:12:07,520
because of power space concerns cost

00:12:04,100 --> 00:12:10,880
many things so we also put suppose that

00:12:07,520 --> 00:12:14,089
you make the same memory subsystem as a

00:12:10,880 --> 00:12:16,670
terabyte out of an emerging memory this

00:12:14,089 --> 00:12:18,860
particular emerging memory we chose had

00:12:16,670 --> 00:12:23,030
a three microsecond read in a hundred

00:12:18,860 --> 00:12:24,980
microsecond write time so with no

00:12:23,030 --> 00:12:28,089
management at all just taking the

00:12:24,980 --> 00:12:31,370
benchmark and running it against the

00:12:28,089 --> 00:12:33,850
emerging memory only managing for

00:12:31,370 --> 00:12:36,320
endurance these are the numbers you get

00:12:33,850 --> 00:12:40,690
you can see that some of these are

00:12:36,320 --> 00:12:43,370
hundred X what a DRAM solution would be

00:12:40,690 --> 00:12:46,580
obviously this isn't something that

00:12:43,370 --> 00:12:50,170
makes a lot of sense to go forward right

00:12:46,580 --> 00:12:54,530
this greatly impact system performance

00:12:50,170 --> 00:12:56,630
now we take the same emerging memory but

00:12:54,530 --> 00:13:01,940
we make it we make the memory subsystem

00:12:56,630 --> 00:13:05,810
this time one-sixteenth DRAM and 15/16

00:13:01,940 --> 00:13:09,260
are merging memory we apply some

00:13:05,810 --> 00:13:11,900
management schemes both in software and

00:13:09,260 --> 00:13:13,970
hardware software giving hints about

00:13:11,900 --> 00:13:16,339
data placement and data movement to

00:13:13,970 --> 00:13:19,340
hardware and hardware doing the

00:13:16,339 --> 00:13:24,860
nanosecond level real-time

00:13:19,340 --> 00:13:28,940
of that policy and as you see we can get

00:13:24,860 --> 00:13:32,270
very close to an all DRAM solution which

00:13:28,940 --> 00:13:36,470
I find uniquely impressive we've taken

00:13:32,270 --> 00:13:39,820
something that is in the microsecond

00:13:36,470 --> 00:13:42,170
time scale with a very modest amount of

00:13:39,820 --> 00:13:44,990
something that's in the nanosecond time

00:13:42,170 --> 00:13:47,420
scale and gotten very close to the same

00:13:44,990 --> 00:13:51,770
performance this could have many

00:13:47,420 --> 00:13:56,630
benefits lower energy lower cost more

00:13:51,770 --> 00:13:58,910
density so many techniques were used to

00:13:56,630 --> 00:14:01,420
get to these numbers and the nice thing

00:13:58,910 --> 00:14:05,120
about simulation is we can kind of do an

00:14:01,420 --> 00:14:07,700
if-then kind of test one of the

00:14:05,120 --> 00:14:10,820
interesting things that we did was we

00:14:07,700 --> 00:14:13,100
recognized that writes stall behind

00:14:10,820 --> 00:14:16,089
reads could be a big problem so these

00:14:13,100 --> 00:14:18,200
results show us using what's called

00:14:16,089 --> 00:14:21,860
interruptible writes in the merging

00:14:18,200 --> 00:14:24,230
memory now we have some circuitry that

00:14:21,860 --> 00:14:25,820
we have supposed that could be built

00:14:24,230 --> 00:14:27,890
into many emerging memories that allow

00:14:25,820 --> 00:14:31,690
this but just from a performance

00:14:27,890 --> 00:14:34,460
simulation I'll show you how this

00:14:31,690 --> 00:14:38,330
if-then kind of experiments can be run

00:14:34,460 --> 00:14:40,339
so we say okay let's just take the data

00:14:38,330 --> 00:14:43,730
from previous you'll notice that is in

00:14:40,339 --> 00:14:46,610
the your far right hand column and the

00:14:43,730 --> 00:14:48,320
far right hand column is with the

00:14:46,610 --> 00:14:50,540
interruptive all rights same data that

00:14:48,320 --> 00:14:52,940
was on the previous chart now if we back

00:14:50,540 --> 00:14:56,390
out that one assumption and we say the

00:14:52,940 --> 00:14:58,550
writes in a particular emergency double

00:14:56,390 --> 00:15:00,350
once you start a write if a read comes

00:14:58,550 --> 00:15:02,589
in you have to finish the right before

00:15:00,350 --> 00:15:08,540
the read can be done and you can see

00:15:02,589 --> 00:15:12,260
that in many cases it's almost a 1x kind

00:15:08,540 --> 00:15:16,490
of edition so these types of attributes

00:15:12,260 --> 00:15:19,580
are very important and many of them

00:15:16,490 --> 00:15:22,180
swing things much larger than this so

00:15:19,580 --> 00:15:24,740
the simulation has led us toward

00:15:22,180 --> 00:15:28,280
management techniques on various

00:15:24,740 --> 00:15:31,580
different emerging memories that we now

00:15:28,280 --> 00:15:33,640
are beginning to be ready to implement

00:15:31,580 --> 00:15:37,910
in actual hardware

00:15:33,640 --> 00:15:40,700
so we are in the process of developing a

00:15:37,910 --> 00:15:43,130
modular and flexible hardware platform

00:15:40,700 --> 00:15:47,840
this is specifically for research in

00:15:43,130 --> 00:15:51,740
this area the idea is that you can mix

00:15:47,840 --> 00:15:56,000
and match any of the interface

00:15:51,740 --> 00:15:59,120
controllers and interfaces so you'd have

00:15:56,000 --> 00:16:02,420
an FPGA platform that implements the

00:15:59,120 --> 00:16:04,880
hardware management policies you would

00:16:02,420 --> 00:16:07,070
have an interface controller that talks

00:16:04,880 --> 00:16:09,140
to the processor that interface

00:16:07,070 --> 00:16:11,480
controller is completely modernized and

00:16:09,140 --> 00:16:15,200
the way the hardware management policy

00:16:11,480 --> 00:16:19,070
engine talks to it is in a generic way

00:16:15,200 --> 00:16:20,510
on the other side you have DRAM

00:16:19,070 --> 00:16:23,030
controllers and emerging memory

00:16:20,510 --> 00:16:24,800
controllers once again with abstracted

00:16:23,030 --> 00:16:27,530
interfaces so they can be switched out

00:16:24,800 --> 00:16:31,220
and then you would have the memory

00:16:27,530 --> 00:16:36,380
subsystem itself or the memory the

00:16:31,220 --> 00:16:39,020
hybrid memory now this is the goal but

00:16:36,380 --> 00:16:41,090
we'll have a first instance of it and in

00:16:39,020 --> 00:16:43,490
the first instance the initial platform

00:16:41,090 --> 00:16:45,370
we're developing we're going to take the

00:16:43,490 --> 00:16:49,300
IBM p9 server

00:16:45,370 --> 00:16:51,920
we're in joint development with IBM to

00:16:49,300 --> 00:16:54,050
create this research platform and we're

00:16:51,920 --> 00:16:57,830
hoping to be able to demo it by the end

00:16:54,050 --> 00:17:00,770
of the year will have memory interfaces

00:16:57,830 --> 00:17:02,630
that that will allow low latency access

00:17:00,770 --> 00:17:05,390
through open copy that was really the

00:17:02,630 --> 00:17:08,570
reason we were very excited to partner

00:17:05,390 --> 00:17:10,160
with IBM there is no nothing else out

00:17:08,570 --> 00:17:12,589
there that will allow this type of

00:17:10,160 --> 00:17:14,810
research to be done at latency

00:17:12,589 --> 00:17:17,930
timescales that makes sense for a memory

00:17:14,810 --> 00:17:22,730
subsystem and we're still looking for

00:17:17,930 --> 00:17:24,320
emerging memory collaborators we are in

00:17:22,730 --> 00:17:27,530
discussion with several of the large

00:17:24,320 --> 00:17:28,940
emerging memory producers and some of

00:17:27,530 --> 00:17:34,670
them are starting to work with us

00:17:28,940 --> 00:17:37,520
already so this is what our initial will

00:17:34,670 --> 00:17:39,530
look like it's just now going in to

00:17:37,520 --> 00:17:42,590
layout so I don't have a layout diagram

00:17:39,530 --> 00:17:45,050
but we're hoping to have it as I said by

00:17:42,590 --> 00:17:46,910
the end of the year we'll be using the

00:17:45,050 --> 00:17:49,040
low latency open copy which is

00:17:46,910 --> 00:17:50,870
the right of the diagram and possibly

00:17:49,040 --> 00:17:54,020
other interfaces that we're putting on

00:17:50,870 --> 00:17:58,370
the left side of the card it draws its

00:17:54,020 --> 00:18:02,120
power from PCIe and it will support many

00:17:58,370 --> 00:18:07,400
different memory types first it has ddr4

00:18:02,120 --> 00:18:12,380
dimm slots so standard ddr4 both DRAM

00:18:07,400 --> 00:18:16,100
nvm nvm - in that's a tongue twister and

00:18:12,380 --> 00:18:18,800
in VM - P support we will also be able

00:18:16,100 --> 00:18:22,160
to make custom dims out of various

00:18:18,800 --> 00:18:26,000
emerging memory types and even enhance

00:18:22,160 --> 00:18:28,250
flash custom dims it has one emerging

00:18:26,000 --> 00:18:32,030
memory slot itself which uses a standard

00:18:28,250 --> 00:18:34,700
M connector but is a little further away

00:18:32,030 --> 00:18:39,080
from the FPGA and will be used for lower

00:18:34,700 --> 00:18:42,770
bandwidth and lower lower at signal

00:18:39,080 --> 00:18:46,910
integrity intensive applications but

00:18:42,770 --> 00:18:52,010
with this platform you can have DRAM and

00:18:46,910 --> 00:18:53,690
flash DRAM and PCM DRAM and you know

00:18:52,010 --> 00:18:55,850
whatever you could even have two

00:18:53,690 --> 00:19:00,140
different emerging memories let's say

00:18:55,850 --> 00:19:03,110
sttm RAM and another emerging memory

00:19:00,140 --> 00:19:05,240
like high speed flash and start really

00:19:03,110 --> 00:19:15,470
seeing how the management policies work

00:19:05,240 --> 00:19:16,940
in full-blown benchmarks so so research

00:19:15,470 --> 00:19:22,160
opportunities and partners

00:19:16,940 --> 00:19:24,260
so the Rambis a10 Rambis we are working

00:19:22,160 --> 00:19:25,880
to provide this platform and we're

00:19:24,260 --> 00:19:28,760
looking for collaborators who want to

00:19:25,880 --> 00:19:31,220
work on this platform with us we're

00:19:28,760 --> 00:19:35,300
hoping to do benchmarking and develop

00:19:31,220 --> 00:19:38,240
various management policies where you

00:19:35,300 --> 00:19:41,300
know align ourselves with IBM as a

00:19:38,240 --> 00:19:43,370
processor leader who is interested in

00:19:41,300 --> 00:19:44,780
programming models resource sharing and

00:19:43,370 --> 00:19:47,120
partitioning and provisioning and

00:19:44,780 --> 00:19:48,950
interface comparisons so we'll be able

00:19:47,120 --> 00:19:51,410
to do various comparisons of different

00:19:48,950 --> 00:19:55,460
interfaces going out to the emerging

00:19:51,410 --> 00:19:58,610
memories we're engaging with memory

00:19:55,460 --> 00:20:00,620
leaders and hopes that they'll be able

00:19:58,610 --> 00:20:02,240
to use the platform for an

00:20:00,620 --> 00:20:05,480
alysus of the emerging memories that are

00:20:02,240 --> 00:20:07,790
coming out such as PCM and others demos

00:20:05,480 --> 00:20:10,550
this may be the one of the first places

00:20:07,790 --> 00:20:15,710
that you'll be able to take an nvm Envy

00:20:10,550 --> 00:20:20,990
dem - P and run real server workloads on

00:20:15,710 --> 00:20:23,030
it and do real application testing we're

00:20:20,990 --> 00:20:27,100
also part hoping a partner with system

00:20:23,030 --> 00:20:30,170
vendors who may one day want to take a

00:20:27,100 --> 00:20:34,809
version of this into actual production

00:20:30,170 --> 00:20:34,809
to produce the real next-generation

00:20:34,990 --> 00:20:44,210
emerging memory hybridization so we're

00:20:39,890 --> 00:20:46,940
interested in collaboration and please

00:20:44,210 --> 00:20:50,750
see me afterwards if you'd like to talk

00:20:46,940 --> 00:20:52,490
more about this so I've sped through

00:20:50,750 --> 00:20:54,830
that very quickly and didn't take any

00:20:52,490 --> 00:20:57,350
questions or any comments and I was

00:20:54,830 --> 00:20:59,059
hoping to have a few otherwise we're

00:20:57,350 --> 00:21:04,179
gonna all get to go to coffee a little

00:20:59,059 --> 00:21:04,179
early but we can take them now

00:21:24,210 --> 00:21:28,490
yes we it's quite impressive

00:21:35,000 --> 00:21:45,169
so so the DBM in this case we let me go

00:21:41,900 --> 00:21:46,760
back one more the DRAM in this case was

00:21:45,169 --> 00:21:49,309
a multi-channel was for channel

00:21:46,760 --> 00:21:51,770
simulation we have simulations of

00:21:49,309 --> 00:21:54,169
various and different structures it was

00:21:51,770 --> 00:22:02,480
four channels of DRAM running at 2400

00:21:54,169 --> 00:22:09,110
ddr4 standard 2400 latency numbers right

00:22:02,480 --> 00:22:10,669
out of jet expects order you know it

00:22:09,110 --> 00:22:12,409
depends on if you get a page hit or you

00:22:10,669 --> 00:22:14,539
get a Bank conflict or something like

00:22:12,409 --> 00:22:18,610
that but with a page hit 30 nanoseconds

00:22:14,539 --> 00:22:21,260
ish pin depend on the DRAM 80

00:22:18,610 --> 00:22:25,460
nanoseconds load to use to the processor

00:22:21,260 --> 00:22:28,549
something in that range and this is as

00:22:25,460 --> 00:22:31,039
you see the three microseconds was

00:22:28,549 --> 00:22:32,630
pinned to pen on the emerging memory it

00:22:31,039 --> 00:22:35,150
wasn't low to use but when you're

00:22:32,630 --> 00:22:40,669
talking three microseconds the extra

00:22:35,150 --> 00:22:42,940
cash levels is kind of in the noise yes

00:22:40,669 --> 00:22:42,940
please

00:23:00,740 --> 00:23:05,649
mm-hmm

00:23:03,429 --> 00:23:08,009
the management techniques here I would

00:23:05,649 --> 00:23:10,389
not necessarily classify as caching

00:23:08,009 --> 00:23:11,289
because there's definitely some other

00:23:10,389 --> 00:23:14,169
things going on

00:23:11,289 --> 00:23:16,509
because caches don't have this idea of

00:23:14,169 --> 00:23:19,299
endurance management they also don't

00:23:16,509 --> 00:23:21,580
have this idea of block management so

00:23:19,299 --> 00:23:24,869
it's a little bit beyond what you would

00:23:21,580 --> 00:23:29,309
learn in a standard caching algorithm

00:23:24,869 --> 00:23:33,099
it's kind of rotational we're leveling

00:23:29,309 --> 00:23:35,469
mixed with caching mix with prefetching

00:23:33,099 --> 00:23:37,960
and some very interesting synergies

00:23:35,469 --> 00:23:42,849
develop when you start actually studying

00:23:37,960 --> 00:23:45,099
it no but they are access pattern

00:23:42,849 --> 00:23:48,249
dependent and one of the things that we

00:23:45,099 --> 00:23:49,690
are doing research on is learning access

00:23:48,249 --> 00:23:52,659
patterns and that's what I was talking

00:23:49,690 --> 00:23:55,539
about where the software can give hints

00:23:52,659 --> 00:23:59,469
to the hardware to change data placement

00:23:55,539 --> 00:24:01,440
and data movement policy to depending on

00:23:59,469 --> 00:24:03,999
what the use patterns going to be and

00:24:01,440 --> 00:24:06,269
we're providing we're also working on a

00:24:03,999 --> 00:24:10,809
framework where that is learned

00:24:06,269 --> 00:24:13,869
automatically and it's just the the

00:24:10,809 --> 00:24:17,129
access and the allocation is analyzed

00:24:13,869 --> 00:24:19,239
and fed to the hardware a slightly

00:24:17,129 --> 00:24:21,759
beforehand so we know what your

00:24:19,239 --> 00:24:23,999
allocation patterns are and from that

00:24:21,759 --> 00:24:27,849
we're inferring your data use patterns

00:24:23,999 --> 00:24:34,899
via using some AI and feeding that down

00:24:27,849 --> 00:24:36,700
to the hardware didn't want to quite get

00:24:34,899 --> 00:24:38,769
into all that unless I got a question

00:24:36,700 --> 00:24:40,749
that's why I didn't put it in the slide

00:24:38,769 --> 00:24:45,129
deck and they made me promise I would

00:24:40,749 --> 00:24:47,139
not go overtime please any other

00:24:45,129 --> 00:24:51,339
questions I think we have the room until

00:24:47,139 --> 00:24:55,839
when 30 minutes

00:24:51,339 --> 00:25:01,310
another four or five minutes any other

00:24:55,839 --> 00:25:04,310
questions sure

00:25:01,310 --> 00:25:04,310
please

00:25:12,919 --> 00:25:20,220
so so we have varied it and we have a

00:25:18,269 --> 00:25:23,370
paper that we are submitting later in

00:25:20,220 --> 00:25:26,460
the year we have varied it from one to

00:25:23,370 --> 00:25:29,279
two which is kind of odd all the way to

00:25:26,460 --> 00:25:31,860
one to 64 and seeing different

00:25:29,279 --> 00:25:34,490
benchmarks and different workloads have

00:25:31,860 --> 00:25:37,710
different sensitivities to that ratio

00:25:34,490 --> 00:25:40,230
one to sixteen works on these benchmarks

00:25:37,710 --> 00:25:42,000
very well but even if you go to one to

00:25:40,230 --> 00:25:45,480
thirty two it's surprisingly how little

00:25:42,000 --> 00:25:48,090
you lose but you know I can't show all

00:25:45,480 --> 00:25:51,630
the results all at once but we'll have a

00:25:48,090 --> 00:25:53,909
paper we're hoping to have in Memphis

00:25:51,630 --> 00:25:58,620
that's later in the year that we'll have

00:25:53,909 --> 00:26:01,350
a lot more variation on the ratio the

00:25:58,620 --> 00:26:05,580
ratio is you know remarkably interesting

00:26:01,350 --> 00:26:08,360
what ratios work well so I'm sorry there

00:26:05,580 --> 00:26:08,360
was question over here also

00:26:16,730 --> 00:26:20,600
yeah there's a lot of partners that are

00:26:18,410 --> 00:26:22,280
going to end up helping us with this we

00:26:20,600 --> 00:26:24,710
just put out the press release this

00:26:22,280 --> 00:26:28,550
morning actually for our partnership

00:26:24,710 --> 00:26:31,010
with IBM so we're definitely looking for

00:26:28,550 --> 00:26:33,560
we're working with partners on the

00:26:31,010 --> 00:26:36,650
emerging memory side on the DRAM side

00:26:33,560 --> 00:26:38,540
and the FPGA side and we're getting all

00:26:36,650 --> 00:26:41,600
that where we can make various

00:26:38,540 --> 00:26:43,340
announcements about it but wasn't quite

00:26:41,600 --> 00:26:46,790
ready to do do all those announcements

00:26:43,340 --> 00:26:49,040
for today but yes this is a

00:26:46,790 --> 00:26:51,740
collaborative environment we're more

00:26:49,040 --> 00:26:54,650
interested in the algorithms things like

00:26:51,740 --> 00:26:57,770
the ratios how these hints can be passed

00:26:54,650 --> 00:27:00,740
between hardware and software that's you

00:26:57,770 --> 00:27:02,300
know our research in reality we're

00:27:00,740 --> 00:27:04,190
building the platform to kind of

00:27:02,300 --> 00:27:06,320
validate some of the things we're seeing

00:27:04,190 --> 00:27:07,670
in simulation but the platform I think

00:27:06,320 --> 00:27:11,510
will be super useful to a lot of

00:27:07,670 --> 00:27:12,890
different people like today it is

00:27:11,510 --> 00:27:17,630
speculated that there are several people

00:27:12,890 --> 00:27:20,990
who have in in vm - p modules that they

00:27:17,630 --> 00:27:24,740
could show even now but there's no

00:27:20,990 --> 00:27:26,060
system that uses in feed him - P yet so

00:27:24,740 --> 00:27:27,950
a system like this could be used for

00:27:26,060 --> 00:27:29,330
demonstrations and benchmarking and

00:27:27,950 --> 00:27:32,720
things like that and the fact that you

00:27:29,330 --> 00:27:36,080
have such a low latency access from from

00:27:32,720 --> 00:27:39,440
the processor and eventually a load

00:27:36,080 --> 00:27:42,350
store access not a DMA access a load

00:27:39,440 --> 00:27:44,810
from the process of targets the memory

00:27:42,350 --> 00:27:47,720
subsystem out on open copying comes back

00:27:44,810 --> 00:27:50,180
that's kind of the holy grail of getting

00:27:47,720 --> 00:27:53,410
this to work correctly and showing these

00:27:50,180 --> 00:27:53,410
kind of performance numbers

00:27:56,940 --> 00:28:04,300
let's see we have 30 seconds if anyone

00:27:59,950 --> 00:28:05,710
else has anything if not I'll be around

00:28:04,300 --> 00:28:07,300
afterwards and I'd be happy to talk to

00:28:05,710 --> 00:28:09,570
you thank you very much for your

00:28:07,300 --> 00:28:09,570

YouTube URL: https://www.youtube.com/watch?v=W_RQE2DA5ho


