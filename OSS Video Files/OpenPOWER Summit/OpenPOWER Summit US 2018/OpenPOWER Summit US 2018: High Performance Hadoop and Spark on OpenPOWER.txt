Title: OpenPOWER Summit US 2018: High Performance Hadoop and Spark on OpenPOWER
Publication date: 2018-04-03
Playlist: OpenPOWER Summit US 2018
Description: 
	OpenPOWER members from Ohio State University discuss their use of POWER technology at OpenPOWER Summit 2018.

Presenters include:
- Xiaoyi Lu, Ohio State University (OSU)
- Dhabaleswar K (DK) Panda, Ohio State University (OSU)

For more information, please visit: http://www.openpowerfoundation.org
Captions: 
	00:00:00,000 --> 00:00:05,640
everybody I am DK panda from while State

00:00:03,240 --> 00:00:10,070
University and my colleague dr. zhihui

00:00:05,640 --> 00:00:13,080
Liu so two of us will be presenting this

00:00:10,070 --> 00:00:15,900
so work here is focusing on hyper phones

00:00:13,080 --> 00:00:19,050
Hadoop and spark on the open power

00:00:15,900 --> 00:00:22,769
platform as most of you know we are in a

00:00:19,050 --> 00:00:26,010
very exciting phase of going between HPC

00:00:22,769 --> 00:00:27,720
and big data and deep learning one field

00:00:26,010 --> 00:00:29,910
is trying to push more pressure on the

00:00:27,720 --> 00:00:33,329
other field and we want to get the new

00:00:29,910 --> 00:00:34,860
results and it puts again feedback to

00:00:33,329 --> 00:00:38,160
the previous one so we are in a very

00:00:34,860 --> 00:00:39,480
exciting loop here and and at the same

00:00:38,160 --> 00:00:41,730
time we are trying to focus on

00:00:39,480 --> 00:00:43,860
convergence between these fields HPC and

00:00:41,730 --> 00:00:45,510
big data and deep learning and also

00:00:43,860 --> 00:00:48,149
there is an increasing need to run these

00:00:45,510 --> 00:00:49,530
applications on the cloud now when we

00:00:48,149 --> 00:00:51,360
are talking about big data so the

00:00:49,530 --> 00:00:53,100
question is okay what is the complexity

00:00:51,360 --> 00:00:55,260
of the big data I mean this is a very

00:00:53,100 --> 00:00:57,120
interesting chart which trying to show

00:00:55,260 --> 00:01:00,719
how much data is being generated every

00:00:57,120 --> 00:01:04,530
minute on the Internet okay it is a

00:01:00,719 --> 00:01:06,869
little bit of older data like in 2016

00:01:04,530 --> 00:01:09,689
but if you see like hey early part of

00:01:06,869 --> 00:01:12,180
2017 just just take it like any of the

00:01:09,689 --> 00:01:14,430
things like a YouTube there are almost 4

00:01:12,180 --> 00:01:16,710
million videos are being uploaded in

00:01:14,430 --> 00:01:19,080
every minute similarly if you see like a

00:01:16,710 --> 00:01:21,509
light say Twitter there are four hundred

00:01:19,080 --> 00:01:24,450
fifty six thousand tweets are being sent

00:01:21,509 --> 00:01:26,040
every minute so as the intensity is

00:01:24,450 --> 00:01:29,040
increasing continuously there is a lot

00:01:26,040 --> 00:01:31,560
of more and more demand to do the do the

00:01:29,040 --> 00:01:33,540
processing so how do we do this

00:01:31,560 --> 00:01:35,490
processing so if you take a look at the

00:01:33,540 --> 00:01:37,560
high level picture of the modern-day

00:01:35,490 --> 00:01:39,180
datacenter this is how you will see like

00:01:37,560 --> 00:01:41,070
when we connect to an Internet to a data

00:01:39,180 --> 00:01:42,780
center these are the like the front end

00:01:41,070 --> 00:01:44,430
here and these are the back end here so

00:01:42,780 --> 00:01:47,759
mostly we try to do the online

00:01:44,430 --> 00:01:50,700
processing like components like no SQL

00:01:47,759 --> 00:01:53,130
DB HBase or mem cache D this is what

00:01:50,700 --> 00:01:55,560
gets used in the front tier then in the

00:01:53,130 --> 00:01:58,020
back end here we try to do the offline

00:01:55,560 --> 00:01:59,490
processing which are like the HDFS

00:01:58,020 --> 00:02:03,149
MapReduce SPARC

00:01:59,490 --> 00:02:05,189
etc so the question is how do we design

00:02:03,149 --> 00:02:07,229
this kind of data centers and now

00:02:05,189 --> 00:02:09,209
especially if you see here is a lot of

00:02:07,229 --> 00:02:10,890
interesting technologies which are going

00:02:09,209 --> 00:02:12,959
on I mean we have the multi code many

00:02:10,890 --> 00:02:13,920
code especially the the open power is

00:02:12,959 --> 00:02:15,959
fitting into this many

00:02:13,920 --> 00:02:19,080
for architecture we have the InfiniBand

00:02:15,959 --> 00:02:23,040
interconnect and also the nvidia gpus

00:02:19,080 --> 00:02:24,870
and also there is a increasing things

00:02:23,040 --> 00:02:27,120
what we are seeing with respect to SSDs

00:02:24,870 --> 00:02:29,700
and vme SSDs so these are like the

00:02:27,120 --> 00:02:32,100
combining the infiniminer RDMA with SS

00:02:29,700 --> 00:02:34,080
these kind of capabilities and the mb

00:02:32,100 --> 00:02:36,540
ram so these are the newer components

00:02:34,080 --> 00:02:39,209
which are leading to to design these

00:02:36,540 --> 00:02:40,769
modern-day datacenters so these are with

00:02:39,209 --> 00:02:44,430
respect to the hardware but the question

00:02:40,769 --> 00:02:46,080
is ok how would the the software and now

00:02:44,430 --> 00:02:48,209
if you take a look at like the software

00:02:46,080 --> 00:02:50,040
we of course have to take the take the

00:02:48,209 --> 00:02:51,989
very best of the hardware and especially

00:02:50,040 --> 00:02:54,959
in the open power if you see like the

00:02:51,989 --> 00:02:57,750
the power 8 architectures it is not only

00:02:54,959 --> 00:03:01,019
like having large number of course but

00:02:57,750 --> 00:03:03,660
with respect to each code we also have 8

00:03:01,019 --> 00:03:05,489
SMT so that we can run actually the

00:03:03,660 --> 00:03:07,920
things in a very highly multi-threaded

00:03:05,489 --> 00:03:10,739
manner and even within a node we can

00:03:07,920 --> 00:03:12,269
have up to 160 threads so the question

00:03:10,739 --> 00:03:14,130
is if you are trying to design any

00:03:12,269 --> 00:03:16,350
software stack we need to make sure that

00:03:14,130 --> 00:03:18,780
we take advantage of all these these

00:03:16,350 --> 00:03:20,850
threats now this is the little bit of

00:03:18,780 --> 00:03:22,680
this chart but if you are working in the

00:03:20,850 --> 00:03:24,180
networking technology area so it might

00:03:22,680 --> 00:03:25,829
be more familiar to you

00:03:24,180 --> 00:03:29,579
this is something how many of you know

00:03:25,829 --> 00:03:32,310
like your open fabrics software stack ok

00:03:29,579 --> 00:03:34,320
so if not so this is where I just like

00:03:32,310 --> 00:03:36,120
you think of the Linux gets developed in

00:03:34,320 --> 00:03:38,519
the Linux community similarly a lot of

00:03:36,120 --> 00:03:41,040
network drivers are being designed in

00:03:38,519 --> 00:03:42,570
this open fabrics community so here

00:03:41,040 --> 00:03:44,940
especially if you see like on the left

00:03:42,570 --> 00:03:47,880
hand side the these are the traditional

00:03:44,940 --> 00:03:49,859
Ethernet so that means we have the new

00:03:47,880 --> 00:03:52,140
your application is written with sockets

00:03:49,859 --> 00:03:54,150
and it is typically written with a TCP

00:03:52,140 --> 00:03:55,680
IP over Ethernet driver Ethernet adapter

00:03:54,150 --> 00:03:58,079
Ethernet switch so this is the pure

00:03:55,680 --> 00:04:01,109
Ethernet with the infinite line you can

00:03:58,079 --> 00:04:03,060
also run the sockets based application

00:04:01,109 --> 00:04:05,100
it goes through an emulation mode called

00:04:03,060 --> 00:04:06,299
IP over ID that's how you run in the

00:04:05,100 --> 00:04:08,519
infinite and adapter the infinite and

00:04:06,299 --> 00:04:10,799
switch so you get the bandwidth but you

00:04:08,519 --> 00:04:11,940
may not get the latency and then of

00:04:10,799 --> 00:04:15,810
course there are different kinds of

00:04:11,940 --> 00:04:18,630
Ethernet adapters with different offload

00:04:15,810 --> 00:04:21,180
tcp/ip so they said like the tcp/ip

00:04:18,630 --> 00:04:23,729
offload but when InfiniBand came into

00:04:21,180 --> 00:04:25,470
the market this is what actually is

00:04:23,729 --> 00:04:27,240
designed on the right hand side is the

00:04:25,470 --> 00:04:29,340
native that means that

00:04:27,240 --> 00:04:30,720
we're the best performance you get the

00:04:29,340 --> 00:04:32,370
lowest latency highest bandwidth

00:04:30,720 --> 00:04:35,610
whenever whatever he will be talking in

00:04:32,370 --> 00:04:38,190
the in the slow so floor here like our

00:04:35,610 --> 00:04:40,050
DMA all those big benefits happen on the

00:04:38,190 --> 00:04:42,630
right hand side but there is a small

00:04:40,050 --> 00:04:46,080
catch that to achieve all these things

00:04:42,630 --> 00:04:47,460
direct sockets cannot give you that so

00:04:46,080 --> 00:04:49,919
that means that some layer of your

00:04:47,460 --> 00:04:52,050
software stack you need to modify the

00:04:49,919 --> 00:04:54,569
sockets to words the words is like a

00:04:52,050 --> 00:04:56,669
very low-level network interface in

00:04:54,569 --> 00:04:58,289
which you need to call then what has

00:04:56,669 --> 00:05:00,150
happened over the years a lot of

00:04:58,289 --> 00:05:02,669
software stacks are moving from the left

00:05:00,150 --> 00:05:05,729
hand side to the right hand side okay to

00:05:02,669 --> 00:05:07,470
give you those kind of benefits he

00:05:05,729 --> 00:05:09,300
doesn't happen over MPI it does happen

00:05:07,470 --> 00:05:10,949
for parallel file systems so the

00:05:09,300 --> 00:05:13,949
question is like be done over

00:05:10,949 --> 00:05:16,500
also over big data okay so this is where

00:05:13,949 --> 00:05:18,840
like in my group like in two hours back

00:05:16,500 --> 00:05:21,180
I gave another talk in the session with

00:05:18,840 --> 00:05:23,310
respect to MPI and P gas so this is what

00:05:21,180 --> 00:05:26,880
we have been working for almost last 17

00:05:23,310 --> 00:05:29,159
years our MPI stack is very widely used

00:05:26,880 --> 00:05:31,919
in including the number one in the world

00:05:29,159 --> 00:05:33,449
these days so while we are working in

00:05:31,919 --> 00:05:35,400
the employ project we also started

00:05:33,449 --> 00:05:38,009
looking this was like another five years

00:05:35,400 --> 00:05:39,570
old project not 17 year old project the

00:05:38,009 --> 00:05:41,699
imply 17 year old so we asked the

00:05:39,570 --> 00:05:44,310
question that asked the field is moving

00:05:41,699 --> 00:05:46,050
to the Big Data how those software

00:05:44,310 --> 00:05:48,630
stacks can be enhanced just like what we

00:05:46,050 --> 00:05:51,419
did for MPI can we take similar kind of

00:05:48,630 --> 00:05:53,340
knowledge and and enhance or accelerate

00:05:51,419 --> 00:05:56,039
these tags so you ask the question what

00:05:53,340 --> 00:05:58,800
are the major bottlenecks how HPC

00:05:56,039 --> 00:06:00,300
technologies can be used here can RDM

00:05:58,800 --> 00:06:02,789
enabled high-performance interconnects

00:06:00,300 --> 00:06:05,240
like InfiniBand or i work those kind of

00:06:02,789 --> 00:06:08,460
technologies can be used for Big Data

00:06:05,240 --> 00:06:09,960
Caribbean hyper for storage systems like

00:06:08,460 --> 00:06:12,539
I says these or even parallel file

00:06:09,960 --> 00:06:13,380
systems just like in an HPC cluster you

00:06:12,539 --> 00:06:15,900
know you have lost

00:06:13,380 --> 00:06:18,030
gpfs those kind of parallel file systems

00:06:15,900 --> 00:06:20,130
can directly be used and then if we can

00:06:18,030 --> 00:06:23,009
use those how much performance benefits

00:06:20,130 --> 00:06:24,870
can be achieved okay and and then how

00:06:23,009 --> 00:06:28,280
also we can introduce benchmarks to

00:06:24,870 --> 00:06:30,630
evaluate the performance so a broad Bowl

00:06:28,280 --> 00:06:32,310
was to bring this HPC big data

00:06:30,630 --> 00:06:35,729
processing and deep learning into a

00:06:32,310 --> 00:06:37,710
converging trajectory so that people can

00:06:35,729 --> 00:06:40,440
actually deploy all these software

00:06:37,710 --> 00:06:40,650
stacks in a very efficient manner

00:06:40,440 --> 00:06:42,030
so

00:06:40,650 --> 00:06:43,949
what do you mean by convergence so let

00:06:42,030 --> 00:06:45,960
me go into a little bit more details so

00:06:43,949 --> 00:06:47,250
our idea here is that on the same

00:06:45,960 --> 00:06:49,620
hardware let's say you have an open

00:06:47,250 --> 00:06:52,169
power flatform open power systems with

00:06:49,620 --> 00:06:54,960
infinite bandwidth GPUs on the same

00:06:52,169 --> 00:06:56,250
system you can run HPC you can run Big

00:06:54,960 --> 00:06:57,630
Data you can run deep learning

00:06:56,250 --> 00:07:00,060
you don't need like multiple versions

00:06:57,630 --> 00:07:01,740
okay so that's where I went trying to

00:07:00,060 --> 00:07:03,360
show through animation so let's say you

00:07:01,740 --> 00:07:06,330
have physical compute nodes you have

00:07:03,360 --> 00:07:07,860
resource managers like turk or slow your

00:07:06,330 --> 00:07:10,560
parallel file system like luster and

00:07:07,860 --> 00:07:12,630
GPFS can I run this kind of things

00:07:10,560 --> 00:07:14,699
concurrently on a very large-scale

00:07:12,630 --> 00:07:16,770
cluster might be some nodes are running

00:07:14,699 --> 00:07:19,050
MPI jobs some nodes are running Big Data

00:07:16,770 --> 00:07:21,330
Hadoop jobs some nodes can run spar job

00:07:19,050 --> 00:07:23,310
some runs can run deep learning and

00:07:21,330 --> 00:07:25,560
those of you are familiar with HPC

00:07:23,310 --> 00:07:28,289
stacked sometimes you just submit these

00:07:25,560 --> 00:07:30,900
as batch jobs so same thing you can also

00:07:28,289 --> 00:07:32,340
do now for Big Data and spar so all of

00:07:30,900 --> 00:07:34,349
these can't coexist so that is our

00:07:32,340 --> 00:07:36,750
region and in fact we have achieved this

00:07:34,349 --> 00:07:39,870
that's what we'll be we'll be talking

00:07:36,750 --> 00:07:42,780
here so in order to achieve that we came

00:07:39,870 --> 00:07:45,060
up with a software framework so so the

00:07:42,780 --> 00:07:46,770
software framework has like in the

00:07:45,060 --> 00:07:48,870
middle we took like these are all the

00:07:46,770 --> 00:07:50,610
Big Data middleware HDFS MapReduce all

00:07:48,870 --> 00:07:52,860
these things you will see they have been

00:07:50,610 --> 00:07:54,750
traditionally using sockets like we will

00:07:52,860 --> 00:07:57,060
download Apache spark or Apache loop

00:07:54,750 --> 00:07:58,979
below at the network layer when they

00:07:57,060 --> 00:08:01,500
talk to each other is sockets that is

00:07:58,979 --> 00:08:02,729
the lowest layer they can go and then of

00:08:01,500 --> 00:08:05,159
course we have all these different

00:08:02,729 --> 00:08:07,260
technologies I talked about computing

00:08:05,159 --> 00:08:10,460
networking and storage so we introduced

00:08:07,260 --> 00:08:13,860
our own communication and IO library

00:08:10,460 --> 00:08:16,949
modules here and first ask the question

00:08:13,860 --> 00:08:18,539
that can instead of sockets can we move

00:08:16,949 --> 00:08:19,919
to verse you remember in the previous

00:08:18,539 --> 00:08:22,199
slide I showed the words is the right

00:08:19,919 --> 00:08:24,150
hand side if we can rewrite some of the

00:08:22,199 --> 00:08:26,430
low-level functions we should be able to

00:08:24,150 --> 00:08:28,289
directly run with good for formats and

00:08:26,430 --> 00:08:30,150
that's what we have done and not only

00:08:28,289 --> 00:08:32,219
that once we have done that now we are

00:08:30,150 --> 00:08:34,740
actually modifying some of the upper

00:08:32,219 --> 00:08:36,990
level software stacks because these

00:08:34,740 --> 00:08:39,930
software stacks were written with slow

00:08:36,990 --> 00:08:42,719
network in mind sockets is very sockets

00:08:39,930 --> 00:08:44,940
tcp/ip those are very slow okay so now

00:08:42,719 --> 00:08:46,200
if we can enhance that then we can

00:08:44,940 --> 00:08:49,200
explore at the upper level architecture

00:08:46,200 --> 00:08:51,779
and then enhance them further and then

00:08:49,200 --> 00:08:53,040
put them together to get even bigger and

00:08:51,779 --> 00:08:53,850
bigger benefits and that's what we have

00:08:53,040 --> 00:08:54,840
done

00:08:53,850 --> 00:08:57,270
so this project is called

00:08:54,840 --> 00:08:58,680
high-performance big data or HIV deep

00:08:57,270 --> 00:09:00,630
some of you are not familiar you can

00:08:58,680 --> 00:09:04,560
just go to this website so we have

00:09:00,630 --> 00:09:06,060
actually enhanced version like I will

00:09:04,560 --> 00:09:08,790
call it a DMM but it has a lot of

00:09:06,060 --> 00:09:10,530
additional designs in addition to our

00:09:08,790 --> 00:09:13,020
DNA idea for Apache spark or even for

00:09:10,530 --> 00:09:15,150
Apache Hadoop to point-x HBase memcache

00:09:13,020 --> 00:09:17,370
D even heard of one point X which is

00:09:15,150 --> 00:09:19,140
being phased out so all these are

00:09:17,370 --> 00:09:21,570
available and this can run on infinite

00:09:19,140 --> 00:09:24,120
and rocky it can also run on Ethernet

00:09:21,570 --> 00:09:26,970
and these are publicly available you can

00:09:24,120 --> 00:09:28,860
just download and currently just go to

00:09:26,970 --> 00:09:31,890
this site we have around the user base

00:09:28,860 --> 00:09:33,930
from around 275 organizations from 34

00:09:31,890 --> 00:09:36,360
countries these are based on voluntary

00:09:33,930 --> 00:09:37,860
registration many people download they

00:09:36,360 --> 00:09:39,510
don't want to identify themselves that

00:09:37,860 --> 00:09:41,880
is ok with us but those who have

00:09:39,510 --> 00:09:44,850
identified themselves you will see they

00:09:41,880 --> 00:09:47,610
are listed there publicly and then we

00:09:44,850 --> 00:09:50,370
have more than 25,000 downloads for from

00:09:47,610 --> 00:09:52,710
from this kind of stacks and any

00:09:50,370 --> 00:09:55,500
addition to these tags we also have like

00:09:52,710 --> 00:09:57,360
a box and we'll talk about what

00:09:55,500 --> 00:09:59,820
little bit about that how exactly you

00:09:57,360 --> 00:10:01,380
can evaluate not just an application

00:09:59,820 --> 00:10:03,000
level but just a Stephan layer or

00:10:01,380 --> 00:10:04,770
MapReduce layer or HBase layer

00:10:03,000 --> 00:10:08,370
individual you should also be able to

00:10:04,770 --> 00:10:09,960
evaluate and then this is the kind of

00:10:08,370 --> 00:10:11,490
feel like a release time download as you

00:10:09,960 --> 00:10:15,030
can see over the years we started this

00:10:11,490 --> 00:10:16,500
the release around June 2013 and then in

00:10:15,030 --> 00:10:18,810
like four and a half years now we have

00:10:16,500 --> 00:10:23,220
been reaching continuously steadily

00:10:18,810 --> 00:10:25,290
rising and and and these were originally

00:10:23,220 --> 00:10:26,700
designed with x86 architecture and of

00:10:25,290 --> 00:10:28,530
course as the open power is architecture

00:10:26,700 --> 00:10:31,470
is coming we have tried to enable these

00:10:28,530 --> 00:10:32,520
in our public releases now support open

00:10:31,470 --> 00:10:34,770
power

00:10:32,520 --> 00:10:36,630
so here example like this is like a

00:10:34,770 --> 00:10:39,030
feature list I don't want to go into

00:10:36,630 --> 00:10:40,770
more details will talk will see some of

00:10:39,030 --> 00:10:43,260
the features and numbers a little bit

00:10:40,770 --> 00:10:45,630
later on so in fact now we and I will

00:10:43,260 --> 00:10:47,370
actually open power support here and the

00:10:45,630 --> 00:10:49,560
way we try to do it if you see this is

00:10:47,370 --> 00:10:51,990
based on like a fetch ahead of 2.8 which

00:10:49,560 --> 00:10:54,270
is the latest public stable release and

00:10:51,990 --> 00:10:56,250
the main thing is that this is compliant

00:10:54,270 --> 00:10:58,530
that means we don't change any API so

00:10:56,250 --> 00:11:00,540
many people think that well you you

00:10:58,530 --> 00:11:03,000
might have done some API changes to get

00:11:00,540 --> 00:11:06,360
the performance no we keep the same API

00:11:03,000 --> 00:11:07,300
so whatever runs publicly with a Pajero

00:11:06,360 --> 00:11:10,780
2.8

00:11:07,300 --> 00:11:13,180
Hortonworks or CDH it will exactly run

00:11:10,780 --> 00:11:15,280
on our system okay our stack there are

00:11:13,180 --> 00:11:17,620
no difference and in fact I forgot to

00:11:15,280 --> 00:11:20,230
mention one thing here we also have some

00:11:17,620 --> 00:11:22,450
plug-in designs you know in the Big Data

00:11:20,230 --> 00:11:24,460
work like sometimes people use the

00:11:22,450 --> 00:11:25,870
Haughton works stack or cloud or a stack

00:11:24,460 --> 00:11:29,050
we don't want you to throw those things

00:11:25,870 --> 00:11:30,640
out we have developed some plugins for

00:11:29,050 --> 00:11:32,710
those tags so you continue to use those

00:11:30,640 --> 00:11:34,360
tags but use our plugins so that the

00:11:32,710 --> 00:11:36,400
networking part is being accelerated

00:11:34,360 --> 00:11:38,740
okay so that is the kind of our

00:11:36,400 --> 00:11:42,490
architecture so this is the like the

00:11:38,740 --> 00:11:45,100
broad overall view software architecture

00:11:42,490 --> 00:11:47,620
you can see so we go into a little bit

00:11:45,100 --> 00:11:48,940
more details later on like Hadoop you

00:11:47,620 --> 00:11:51,100
know there are different components one

00:11:48,940 --> 00:11:52,720
is the HDFS component so we have some

00:11:51,100 --> 00:11:55,270
different versions here like we have a

00:11:52,720 --> 00:11:57,340
heterogeneous storage in memory mode you

00:11:55,270 --> 00:12:01,570
may lustre mode we have a burst buffer

00:11:57,340 --> 00:12:03,130
mode we have also RPC is a remote

00:12:01,570 --> 00:12:04,690
procedure call is a big component in the

00:12:03,130 --> 00:12:07,720
hadoop we have also made that our DMA

00:12:04,690 --> 00:12:10,030
and also the MapReduce we also have

00:12:07,720 --> 00:12:12,160
enhanced it with the our DMA and also

00:12:10,030 --> 00:12:14,290
enabled with the lustre and more

00:12:12,160 --> 00:12:16,210
importantly we have also interfaced with

00:12:14,290 --> 00:12:19,780
the job scheduler like slurm and people

00:12:16,210 --> 00:12:21,160
PBS so if your HPC environment is just

00:12:19,780 --> 00:12:23,860
like you submit and be a job the same

00:12:21,160 --> 00:12:25,690
thing you can submit Hadoop jobs okay so

00:12:23,860 --> 00:12:26,950
it is a very unified environment so

00:12:25,690 --> 00:12:29,410
that's where we are trying to achieve

00:12:26,950 --> 00:12:31,110
the the convergence similar kind of

00:12:29,410 --> 00:12:34,300
things we have done for the Apache spark

00:12:31,110 --> 00:12:36,910
so this is again it has a lot of

00:12:34,300 --> 00:12:38,890
advanced designs it has support for open

00:12:36,910 --> 00:12:42,070
power the public release is based on

00:12:38,890 --> 00:12:45,330
2.10 which is the very recent stable

00:12:42,070 --> 00:12:47,800
release and and we support that HBase

00:12:45,330 --> 00:12:50,230
similarly we have an optimized version

00:12:47,800 --> 00:12:52,210
the open power is being worked out it'll

00:12:50,230 --> 00:12:53,950
be available in future it's not yet

00:12:52,210 --> 00:12:56,440
released but it is on the x86 it has

00:12:53,950 --> 00:12:57,970
been there for for many years similarly

00:12:56,440 --> 00:13:00,100
there is another component called named

00:12:57,970 --> 00:13:02,620
Cassidy which is very widely used in the

00:13:00,100 --> 00:13:04,240
web 2.0 environment in the

00:13:02,620 --> 00:13:07,360
multi-threaded center that also we have

00:13:04,240 --> 00:13:10,750
merit REM enabled and there also we are

00:13:07,360 --> 00:13:12,370
working on the open power support so so

00:13:10,750 --> 00:13:13,990
in addition to all these tags we also

00:13:12,370 --> 00:13:15,310
have a lot of benchmarks for example you

00:13:13,990 --> 00:13:17,920
in the community if you just want to

00:13:15,310 --> 00:13:19,590
evaluate HDFS itself you will see there

00:13:17,920 --> 00:13:21,160
are not many tools or stacks

00:13:19,590 --> 00:13:24,490
available just to

00:13:21,160 --> 00:13:26,769
as the FS so to allow that we actually

00:13:24,490 --> 00:13:28,329
introduced a micro banks were set for

00:13:26,769 --> 00:13:30,120
Hadoop distributed file system it has

00:13:28,329 --> 00:13:32,920
sequential write latency latency

00:13:30,120 --> 00:13:35,620
different kinds of you can use it to

00:13:32,920 --> 00:13:38,829
benchmark products from different HDFS

00:13:35,620 --> 00:13:40,540
solution provider or within HDFS you can

00:13:38,829 --> 00:13:42,819
go inside and see where the bottlenecks

00:13:40,540 --> 00:13:44,769
lies so so this helps the developers and

00:13:42,819 --> 00:13:46,360
engineers to find out where the

00:13:44,769 --> 00:13:48,970
limitation of slides where things can be

00:13:46,360 --> 00:13:52,480
enhanced which you cannot just do by

00:13:48,970 --> 00:13:54,370
running an end application ok so that is

00:13:52,480 --> 00:13:55,569
our goal so same thing we have done for

00:13:54,370 --> 00:13:57,490
memcache DHBs

00:13:55,569 --> 00:14:00,250
SPARC etcetera this is also publicly

00:13:57,490 --> 00:14:01,870
available you can you can download so

00:14:00,250 --> 00:14:03,610
with this kind of environment so what we

00:14:01,870 --> 00:14:06,550
do is this is our region and this is

00:14:03,610 --> 00:14:07,959
what we have achieved if you see like on

00:14:06,550 --> 00:14:09,910
a given cluster let's say you have an

00:14:07,959 --> 00:14:12,160
HPC cluster or open power cluster and

00:14:09,910 --> 00:14:14,740
you can take our let's say the hybrid e

00:14:12,160 --> 00:14:16,629
stack it has again different mode you

00:14:14,740 --> 00:14:18,790
can based on your configuration like

00:14:16,629 --> 00:14:21,160
what kind of SSDs you have what kind of

00:14:18,790 --> 00:14:23,709
file system you have there since you

00:14:21,160 --> 00:14:26,529
select the appropriate mode compile it

00:14:23,709 --> 00:14:28,180
and then put it as a module and then let

00:14:26,529 --> 00:14:29,980
the users just use the module they don't

00:14:28,180 --> 00:14:32,410
have to worry about all the internals

00:14:29,980 --> 00:14:33,790
just like MPI library you just submit

00:14:32,410 --> 00:14:35,589
your job similarly people will just

00:14:33,790 --> 00:14:37,779
submit their application which will run

00:14:35,589 --> 00:14:40,540
against the Hadoop same thing we can do

00:14:37,779 --> 00:14:41,410
is also with with spark so in fact we

00:14:40,540 --> 00:14:43,660
have been working very collaboratively

00:14:41,410 --> 00:14:46,060
with a san diego supercomputing center

00:14:43,660 --> 00:14:49,089
they are one of our collaborators if

00:14:46,060 --> 00:14:50,500
those of you are familiar NSF the u.s.

00:14:49,089 --> 00:14:52,810
National Science Foundation has the

00:14:50,500 --> 00:14:55,480
exceed environment although super human

00:14:52,810 --> 00:14:58,209
being centers are connected so on SDS II

00:14:55,480 --> 00:15:00,069
comic we all actually have deployed like

00:14:58,209 --> 00:15:02,500
just like you see the RDA for what you

00:15:00,069 --> 00:15:04,990
had OOP in this this path or apache

00:15:02,500 --> 00:15:07,360
spark so you can just if you have an

00:15:04,990 --> 00:15:09,850
exceed account on HDAC you just directly

00:15:07,360 --> 00:15:11,920
use it there are no issues same thing we

00:15:09,850 --> 00:15:13,420
have also done for chameleon cloud that

00:15:11,920 --> 00:15:15,309
is a cloud infrastructure from again

00:15:13,420 --> 00:15:16,350
National Science Foundation we have

00:15:15,309 --> 00:15:18,490
actually

00:15:16,350 --> 00:15:21,129
made it available just like an appliance

00:15:18,490 --> 00:15:23,769
so so as an end user you just have your

00:15:21,129 --> 00:15:24,759
job you take your job and click on the

00:15:23,769 --> 00:15:26,649
appliance and then it will just

00:15:24,759 --> 00:15:28,569
everything else will be taken care under

00:15:26,649 --> 00:15:31,240
the hood Thanks

00:15:28,569 --> 00:15:33,639
so with this let me hand it over to my

00:15:31,240 --> 00:15:34,780
colleague here dr. J will Lou so he will

00:15:33,639 --> 00:15:37,480
go into a little bit more deep

00:15:34,780 --> 00:15:39,100
and then try to take a look at what kind

00:15:37,480 --> 00:15:42,340
of performance benefits you can achieve

00:15:39,100 --> 00:15:43,540
because these are the newer stacks if

00:15:42,340 --> 00:15:45,580
you don't get performance of any bids

00:15:43,540 --> 00:15:46,840
what is the motivation okay so that's

00:15:45,580 --> 00:15:49,210
what he will try to show and then you

00:15:46,840 --> 00:15:51,730
will see that it delivers very extremely

00:15:49,210 --> 00:15:52,780
high performance benefits and exactly on

00:15:51,730 --> 00:15:55,180
the same hardware

00:15:52,780 --> 00:15:57,850
InfiniBand hardware using the Apache

00:15:55,180 --> 00:15:59,170
version if you don't want to use that

00:15:57,850 --> 00:16:01,030
and use our words and you get

00:15:59,170 --> 00:16:04,810
significant performance boost that's

00:16:01,030 --> 00:16:06,820
what you will be taught good afternoon

00:16:04,810 --> 00:16:10,300
guys so my name is Jean you know I'm a

00:16:06,820 --> 00:16:12,610
research scientist in terminus group so

00:16:10,300 --> 00:16:14,800
the panel's give our view of what we

00:16:12,610 --> 00:16:16,840
have done in the last five years for our

00:16:14,800 --> 00:16:19,810
limit based designs for Hadoop spark

00:16:16,840 --> 00:16:22,360
HBase memory cache deep whatever so

00:16:19,810 --> 00:16:24,190
actually here am this problem I'm going

00:16:22,360 --> 00:16:26,670
to give a little bit more details of

00:16:24,190 --> 00:16:29,320
what we actually did in these packages

00:16:26,670 --> 00:16:31,330
so first of all let me let me introduce

00:16:29,320 --> 00:16:34,690
what we have done in the HDFS component

00:16:31,330 --> 00:16:36,760
as you have no I mean HDFS is the major

00:16:34,690 --> 00:16:39,490
component or major distributor for

00:16:36,760 --> 00:16:41,980
assistance for all kind of different big

00:16:39,490 --> 00:16:44,530
data analytics stacks for example no

00:16:41,980 --> 00:16:48,250
matter you Ramah produce jobs HBase jobs

00:16:44,530 --> 00:16:50,830
or like spark jobs whatever your you

00:16:48,250 --> 00:16:52,510
need HDFS as the underlying file system

00:16:50,830 --> 00:16:54,970
even these days when you run deep in

00:16:52,510 --> 00:16:56,860
earnings tax in order to integrate

00:16:54,970 --> 00:16:59,140
evenly into the big data analytics

00:16:56,860 --> 00:17:02,020
pipelines you still need to use data

00:16:59,140 --> 00:17:04,329
which actually stored in the HDFS layer

00:17:02,020 --> 00:17:06,760
so that's why HTF is the most important

00:17:04,329 --> 00:17:08,770
component you have to first know okay

00:17:06,760 --> 00:17:10,420
how to enhance it in your cluster if you

00:17:08,770 --> 00:17:12,459
have multi-core machines and the high

00:17:10,420 --> 00:17:14,319
performance networks so first of all

00:17:12,459 --> 00:17:16,390
this is the architecture of HDFS is your

00:17:14,319 --> 00:17:19,270
application based on my chief is clients

00:17:16,390 --> 00:17:21,010
or HDFS API so by default if you don't

00:17:19,270 --> 00:17:23,170
change anything you actually go through

00:17:21,010 --> 00:17:24,339
the left side pass basically your HDFS

00:17:23,170 --> 00:17:26,620
around on top of it you have a sake

00:17:24,339 --> 00:17:28,480
library and then that your sake library

00:17:26,620 --> 00:17:30,970
we go through these VIP protocols and

00:17:28,480 --> 00:17:34,840
then go strap either Ethernet networks

00:17:30,970 --> 00:17:37,660
or IP over IP protocols but actually we

00:17:34,840 --> 00:17:40,300
take this design into another direction

00:17:37,660 --> 00:17:43,750
we actually print the verbs lady verb

00:17:40,300 --> 00:17:44,679
space design into the HDFS under under

00:17:43,750 --> 00:17:46,360
HDTV APs

00:17:44,679 --> 00:17:48,380
okay like a terminal mentioned we don't

00:17:46,360 --> 00:17:51,080
change anything in HDFS API

00:17:48,380 --> 00:17:53,480
so everything will order the four

00:17:51,080 --> 00:17:56,210
communication paths will be bypassed if

00:17:53,480 --> 00:17:58,940
you enable our components okay we'll go

00:17:56,210 --> 00:18:01,220
through DNI redirect your right pass to

00:17:58,940 --> 00:18:03,230
the LC you design which running on top

00:18:01,220 --> 00:18:04,820
of lady verbs and then cost would

00:18:03,230 --> 00:18:06,290
already made protocols and in our

00:18:04,820 --> 00:18:07,250
already made engine we actually support

00:18:06,290 --> 00:18:09,860
post InfiniBand

00:18:07,250 --> 00:18:12,730
as well as rocky as well as the I work

00:18:09,860 --> 00:18:14,810
actually in today I talked a bit one

00:18:12,730 --> 00:18:16,570
person he mentioned about whether we

00:18:14,810 --> 00:18:18,740
support our work actually we support so

00:18:16,570 --> 00:18:22,550
depends on what kind of network you have

00:18:18,740 --> 00:18:24,190
you can enable this so not only that you

00:18:22,550 --> 00:18:26,360
know initiative is there's a very

00:18:24,190 --> 00:18:29,690
time-consuming phase called replication

00:18:26,360 --> 00:18:30,980
basically in order to in support the for

00:18:29,690 --> 00:18:34,340
tolerance you need to replicate your

00:18:30,980 --> 00:18:36,890
data in multiple nodes and in that phase

00:18:34,340 --> 00:18:38,930
exactly like a time like a communication

00:18:36,890 --> 00:18:41,360
intensive also as we as IO intensifies

00:18:38,930 --> 00:18:43,010
so it's already ma protocol you're able

00:18:41,360 --> 00:18:47,120
to scale it in improved performance of

00:18:43,010 --> 00:18:48,230
that okay so we have some papers in some

00:18:47,120 --> 00:18:49,910
different conference if you have

00:18:48,230 --> 00:18:52,940
interest is some kind of pointers you

00:18:49,910 --> 00:18:55,070
can take a look so this about

00:18:52,940 --> 00:18:56,870
complication part actually later on we

00:18:55,070 --> 00:18:58,820
see we see that another new

00:18:56,870 --> 00:19:02,420
opportunities coming up so for example

00:18:58,820 --> 00:19:03,740
in many HPC clusters is including for

00:19:02,420 --> 00:19:05,900
example urban power class so today in

00:19:03,740 --> 00:19:09,260
the keynote talks we we heard a lot of

00:19:05,900 --> 00:19:11,810
discussions about nvme SSDs right it was

00:19:09,260 --> 00:19:14,210
kind of new storage also available in

00:19:11,810 --> 00:19:16,490
these clusters now the question is if

00:19:14,210 --> 00:19:19,310
you look at the storage perspective in

00:19:16,490 --> 00:19:20,780
all this multi-core medical machines

00:19:19,310 --> 00:19:23,090
you'll get a lot of kind of different

00:19:20,780 --> 00:19:25,700
kind of storage medium for example you

00:19:23,090 --> 00:19:28,190
have run disk you have SSD sometimes OD

00:19:25,700 --> 00:19:30,950
PCIe SSD nvme SSD even a generation

00:19:28,190 --> 00:19:33,700
vanveen protocols and then of course you

00:19:30,950 --> 00:19:38,630
have HDD for example you have like 6 or

00:19:33,700 --> 00:19:40,160
32 32 HDD on each node probably and then

00:19:38,630 --> 00:19:42,740
another important thing you probably

00:19:40,160 --> 00:19:44,960
also have another dedicated amount point

00:19:42,740 --> 00:19:47,180
which backand by some parallel file

00:19:44,960 --> 00:19:49,940
systems like just like luster or GPFS

00:19:47,180 --> 00:19:52,610
now the question is how you actually can

00:19:49,940 --> 00:19:54,800
get all your HDFS and utilize all this

00:19:52,610 --> 00:19:57,440
kind of different storage medium in the

00:19:54,800 --> 00:19:59,870
most efficient manner so if you look at

00:19:57,440 --> 00:20:00,770
the HDFS inside right you definitely

00:19:59,870 --> 00:20:02,930
needs to handle

00:20:00,770 --> 00:20:05,300
three different things one is how you

00:20:02,930 --> 00:20:07,730
place your replica how you place your

00:20:05,300 --> 00:20:08,870
block in the edge ative Slayer what kind

00:20:07,730 --> 00:20:10,760
of lock should put in the high-speed

00:20:08,870 --> 00:20:12,830
story what kind of lock we should put in

00:20:10,760 --> 00:20:14,570
the low-speed storage this one thing

00:20:12,830 --> 00:20:16,100
second thing is replication mega

00:20:14,570 --> 00:20:18,350
mentioned because you need to provide

00:20:16,100 --> 00:20:20,750
for torrent support now the question is

00:20:18,350 --> 00:20:22,670
if if the round disk of course if power

00:20:20,750 --> 00:20:24,650
is gone then you lose your data if

00:20:22,670 --> 00:20:26,690
you're in Laster master has the right

00:20:24,650 --> 00:20:28,310
support typically so in that case you

00:20:26,690 --> 00:20:30,380
don't have to enable the multiple

00:20:28,310 --> 00:20:31,910
replication they Steve the lady right as

00:20:30,380 --> 00:20:33,380
soon as you have one replica in master

00:20:31,910 --> 00:20:36,020
you you probably can change the

00:20:33,380 --> 00:20:37,670
replication protocols so you can't work

00:20:36,020 --> 00:20:40,730
good trade-off between for tolerance and

00:20:37,670 --> 00:20:42,470
the performance and then eviction the

00:20:40,730 --> 00:20:45,170
promotion that's another exciting point

00:20:42,470 --> 00:20:47,090
of HTV because your applications think

00:20:45,170 --> 00:20:49,400
about keeping early or any other stacks

00:20:47,090 --> 00:20:51,940
you definitely have some hot data and

00:20:49,400 --> 00:20:53,930
some core data our question is how you

00:20:51,940 --> 00:20:57,470
efficiently move this data from

00:20:53,930 --> 00:20:59,420
different level of storage hierarchy

00:20:57,470 --> 00:21:01,550
right so that's another important things

00:20:59,420 --> 00:21:04,370
okay so with all this we propose a

00:21:01,550 --> 00:21:07,730
design called a creep hhhh basically

00:21:04,370 --> 00:21:11,180
means enhanced Eva's we memory achieved

00:21:07,730 --> 00:21:13,460
in years storage so with trip HP we have

00:21:11,180 --> 00:21:15,020
reaction of three modes why is the

00:21:13,460 --> 00:21:16,720
foremost basically we are trying to use

00:21:15,020 --> 00:21:19,430
all this storage in a balanced manner

00:21:16,720 --> 00:21:21,350
okay and the second mode occurred in

00:21:19,430 --> 00:21:22,610
memory mode so this stays because if you

00:21:21,350 --> 00:21:23,570
look at the community people trying to

00:21:22,610 --> 00:21:25,880
do in memory computing

00:21:23,570 --> 00:21:28,160
so there's another interesting work in

00:21:25,880 --> 00:21:30,920
the community called Tae Kyung or unless

00:21:28,160 --> 00:21:32,660
I oh I hope you heard of that they are

00:21:30,920 --> 00:21:34,850
so trying to bring the i/o purely in

00:21:32,660 --> 00:21:37,400
memory so that you I give you maximal

00:21:34,850 --> 00:21:38,900
performance but in the meantime I use

00:21:37,400 --> 00:21:39,980
different techniques to guarantee the

00:21:38,900 --> 00:21:42,380
for tolerance as well

00:21:39,980 --> 00:21:44,300
and then lastly integrate integrated

00:21:42,380 --> 00:21:47,000
like I mentioned how to utilize master

00:21:44,300 --> 00:21:48,710
or GPFS in your classroom so in the

00:21:47,000 --> 00:21:52,340
other way you probably can change the

00:21:48,710 --> 00:21:55,730
replication protocols as well so that's

00:21:52,340 --> 00:21:58,940
the hdfs part like and and and the third

00:21:55,730 --> 00:22:02,390
thing I want to mention is about the Map

00:21:58,940 --> 00:22:02,780
Reduce so Map Reduce is a different

00:22:02,390 --> 00:22:04,250
story

00:22:02,780 --> 00:22:06,020
when you want to use high purpose

00:22:04,250 --> 00:22:08,990
networks and high problem storage

00:22:06,020 --> 00:22:11,150
devices because in my produce the most

00:22:08,990 --> 00:22:13,460
rain consuming phase is called shuffle

00:22:11,150 --> 00:22:13,810
shuffle basically means your data needs

00:22:13,460 --> 00:22:17,230
to

00:22:13,810 --> 00:22:19,150
from map phase to reduce phase right

00:22:17,230 --> 00:22:21,310
think about if you do want here by the

00:22:19,150 --> 00:22:22,690
sword or terasort you actually needs to

00:22:21,310 --> 00:22:24,520
move from one here by the data over the

00:22:22,690 --> 00:22:26,410
networks from one side of an ounce to

00:22:24,520 --> 00:22:29,560
the other safeness that's a big amount

00:22:26,410 --> 00:22:31,510
of work has to be done efficiently so

00:22:29,560 --> 00:22:33,520
with our design similarly we don't again

00:22:31,510 --> 00:22:35,230
this is default architecture you can do

00:22:33,520 --> 00:22:36,970
the transfer over the Java soak in

00:22:35,230 --> 00:22:39,550
libraries either certain

00:22:36,970 --> 00:22:41,940
JT int for Hadoop that using jetty which

00:22:39,550 --> 00:22:44,620
go through HTTP protocol which is a very

00:22:41,940 --> 00:22:47,230
heavy heavy protocol from performance

00:22:44,620 --> 00:22:48,970
perspective and then with our approach

00:22:47,230 --> 00:22:52,300
we we don't change anything in the

00:22:48,970 --> 00:22:54,100
MapReduce API layer we just bypass your

00:22:52,300 --> 00:22:58,030
your default design we bring your

00:22:54,100 --> 00:22:59,980
traffic to the lady verbs based or limit

00:22:58,030 --> 00:23:02,470
protocols so that we can achieve the

00:22:59,980 --> 00:23:05,200
maximal Pandavas maximal solute food and

00:23:02,470 --> 00:23:07,660
the reduced latency for your data

00:23:05,200 --> 00:23:09,340
transfer not only that we also find that

00:23:07,660 --> 00:23:11,530
in order to improve or false further we

00:23:09,340 --> 00:23:14,140
need to efficient profession a caching

00:23:11,530 --> 00:23:17,110
of a math map output so that all already

00:23:14,140 --> 00:23:18,970
make operation comes it the data will be

00:23:17,110 --> 00:23:22,420
in the memory already so that's actually

00:23:18,970 --> 00:23:24,550
another something important and and also

00:23:22,420 --> 00:23:26,680
traffic origins in memory merge

00:23:24,550 --> 00:23:28,450
how to avoid disk i/o those kind of

00:23:26,680 --> 00:23:32,860
things we have proposed in the whole

00:23:28,450 --> 00:23:34,990
stack again we have pieces of paper we

00:23:32,860 --> 00:23:36,820
published in Isis 2014 if you have

00:23:34,990 --> 00:23:39,730
increased go over these paper you may

00:23:36,820 --> 00:23:41,350
get more details so now because we're

00:23:39,730 --> 00:23:42,490
talking about oven power write recently

00:23:41,350 --> 00:23:44,850
we did another job

00:23:42,490 --> 00:23:48,010
so we print all these snacks on top of

00:23:44,850 --> 00:23:50,230
open power machines now the question is

00:23:48,010 --> 00:23:53,350
what kind of new things before work and

00:23:50,230 --> 00:23:55,480
we designs accelerations we can do open

00:23:53,350 --> 00:23:58,690
power machines now of course if you look

00:23:55,480 --> 00:24:00,460
at this tag we don't want to change each

00:23:58,690 --> 00:24:02,170
of the components individually that's of

00:24:00,460 --> 00:24:04,960
heavy work right okay a foreign power

00:24:02,170 --> 00:24:06,130
should we do something in the HDFS or

00:24:04,960 --> 00:24:08,680
map you lose power gauge based

00:24:06,130 --> 00:24:12,880
differently no we want to bring some

00:24:08,680 --> 00:24:15,520
unique IDs like you define design so all

00:24:12,880 --> 00:24:17,910
these stands in the player can automatic

00:24:15,520 --> 00:24:21,700
in the benefit out of it so in the

00:24:17,910 --> 00:24:23,680
pattern based on our experiments what we

00:24:21,700 --> 00:24:25,060
see that the most important thing we

00:24:23,680 --> 00:24:26,299
need to enhance is actually in the early

00:24:25,060 --> 00:24:28,219
may complicate engine

00:24:26,299 --> 00:24:29,869
so there multiple things we released the

00:24:28,219 --> 00:24:32,779
hill this just highlight what we have

00:24:29,869 --> 00:24:34,549
done so first of all we want to we want

00:24:32,779 --> 00:24:37,580
to do efficient ultimate device

00:24:34,549 --> 00:24:39,289
selection and the detection so basically

00:24:37,580 --> 00:24:42,109
because you have so many calls or SMS

00:24:39,289 --> 00:24:43,399
rest and in the chip because all these

00:24:42,109 --> 00:24:45,200
systems are based on JVM right

00:24:43,399 --> 00:24:47,479
internally they have a lot of threads as

00:24:45,200 --> 00:24:52,279
well for example even one thing though

00:24:47,479 --> 00:24:52,940
RPC our PC client just for our PC

00:24:52,279 --> 00:24:54,619
component okay

00:24:52,940 --> 00:24:57,259
it has like a more than in oven or

00:24:54,619 --> 00:24:58,759
machine has more than 80 threads now in

00:24:57,259 --> 00:25:01,789
time you think about if if you have

00:24:58,759 --> 00:25:03,289
MapReduce and you have HDFS all the

00:25:01,789 --> 00:25:05,149
things together how many threads you

00:25:03,289 --> 00:25:07,039
have maybe saw some threads now the

00:25:05,149 --> 00:25:08,929
question is how you can efficiently make

00:25:07,039 --> 00:25:10,700
sure that as long as rest go through the

00:25:08,929 --> 00:25:12,889
already made protocols they are able to

00:25:10,700 --> 00:25:15,619
pick up the right or limit device and

00:25:12,889 --> 00:25:17,869
also use the best writing policies

00:25:15,619 --> 00:25:20,269
that's another thing very important

00:25:17,869 --> 00:25:22,279
basically in the HPC are actually

00:25:20,269 --> 00:25:24,649
binding or affinity setting it's very

00:25:22,279 --> 00:25:28,729
common but in the piggy durability still

00:25:24,649 --> 00:25:30,739
not being well explored especially in

00:25:28,729 --> 00:25:32,599
open param assistance so we propose

00:25:30,739 --> 00:25:34,969
different kind of binding policies so

00:25:32,599 --> 00:25:36,589
that user can specify okay whether you

00:25:34,969 --> 00:25:39,079
want to bind your comic and thread to

00:25:36,589 --> 00:25:42,799
the water and of course or SMT threads

00:25:39,079 --> 00:25:44,320
okay so in that way we are able to like

00:25:42,799 --> 00:25:47,779
a bind like give you the best

00:25:44,320 --> 00:25:51,769
complication performance so not only

00:25:47,779 --> 00:25:54,559
that actually so what we bring the like

00:25:51,769 --> 00:25:56,089
a user easy to use our stack we are

00:25:54,559 --> 00:25:57,769
automatically detect these kind of

00:25:56,089 --> 00:25:59,570
things and then we automatically binding

00:25:57,769 --> 00:26:02,229
the common thread with some to the

00:25:59,570 --> 00:26:05,239
course which closer to HCA those kind of

00:26:02,229 --> 00:26:06,139
policies are available and also another

00:26:05,239 --> 00:26:08,329
important thing is like a Power

00:26:06,139 --> 00:26:10,009
Architecture are well tuning is another

00:26:08,329 --> 00:26:12,099
something we observed so for example

00:26:10,009 --> 00:26:15,079
compared with the Intel Xeon

00:26:12,099 --> 00:26:17,329
architectures so some internal protocols

00:26:15,079 --> 00:26:18,559
may need to be tuned so we have some

00:26:17,329 --> 00:26:20,869
power architecture where tuned in

00:26:18,559 --> 00:26:24,919
component inside our library so that we

00:26:20,869 --> 00:26:27,769
are able to get better performance like

00:26:24,919 --> 00:26:29,809
even for the earth even for like poster

00:26:27,769 --> 00:26:32,089
saying our DMA design of impaired

00:26:29,809 --> 00:26:33,829
machines again like I said this desire

00:26:32,089 --> 00:26:35,239
key support opposed Hadoop and spark

00:26:33,829 --> 00:26:36,829
whatever we mentioned earlier in the

00:26:35,239 --> 00:26:38,989
future we're support HBase and memcache

00:26:36,829 --> 00:26:39,440
do as well now let's take a look at the

00:26:38,989 --> 00:26:41,990
perform

00:26:39,440 --> 00:26:44,480
what if I mentioned about already my

00:26:41,990 --> 00:26:47,780
best hadoop on manpower so this is the

00:26:44,480 --> 00:26:51,050
yellow lines I POV offer IB Easton EDR

00:26:47,780 --> 00:26:53,600
which 100 GB GPS GPS and then the red

00:26:51,050 --> 00:26:56,030
bar is our early may I be late if design

00:26:53,600 --> 00:26:57,800
so the left side is a three page default

00:26:56,030 --> 00:27:00,020
mode which basically use all kind of

00:26:57,800 --> 00:27:02,390
storage storage device and mentioned

00:27:00,020 --> 00:27:04,880
earlier in a palace manner and then HH n

00:27:02,390 --> 00:27:06,290
mode basically use just purely memory so

00:27:04,880 --> 00:27:10,670
you can imagine that you can get a

00:27:06,290 --> 00:27:12,830
higher slope like a slope okay

00:27:10,670 --> 00:27:14,810
so higher is better so as we can see

00:27:12,830 --> 00:27:18,880
that our limit is tanking improved like

00:27:14,810 --> 00:27:21,710
almost weeks for the for the throughput

00:27:18,880 --> 00:27:25,070
so basically if we use the same hardware

00:27:21,710 --> 00:27:26,630
you run before Apache version on the

00:27:25,070 --> 00:27:28,130
open parking and then you run our

00:27:26,630 --> 00:27:30,050
version on the open part machine

00:27:28,130 --> 00:27:32,210
you're able to get more 2x performance

00:27:30,050 --> 00:27:34,310
improvement for the throughput and

00:27:32,210 --> 00:27:35,960
that's similarly we run sold in the

00:27:34,310 --> 00:27:37,790
triple h mode before mode and the

00:27:35,960 --> 00:27:39,740
cribbage game mode similarly we see that

00:27:37,790 --> 00:27:41,480
for example for the default to beta mode

00:27:39,740 --> 00:27:44,180
we are able to reduce the security by

00:27:41,480 --> 00:27:46,400
40% in therefore the email mode we are

00:27:44,180 --> 00:27:49,730
able to reduce the execution time by 55%

00:27:46,400 --> 00:27:53,840
that's like almost half your execution

00:27:49,730 --> 00:27:55,490
time and a third example we showed here

00:27:53,840 --> 00:27:57,170
is like a terror salt which is a little

00:27:55,490 --> 00:27:59,570
bit different than salt the from the

00:27:57,170 --> 00:28:02,870
local perspective again we are able to

00:27:59,570 --> 00:28:05,810
reduce time almost the 20 percent or 15

00:28:02,870 --> 00:28:09,530
percent 12 to 15 percent depends on how

00:28:05,810 --> 00:28:12,080
large of data size you want to test so

00:28:09,530 --> 00:28:13,550
the next example it's about spark so

00:28:12,080 --> 00:28:15,830
spark is a little bit different than the

00:28:13,550 --> 00:28:18,290
Hadoop because spark is PI d 4 is in

00:28:15,830 --> 00:28:20,320
memory computing kind of concepts so

00:28:18,290 --> 00:28:23,000
they are trying to build some already

00:28:20,320 --> 00:28:25,370
objects and then utilize all kind of

00:28:23,000 --> 00:28:26,720
memory available in your machines so of

00:28:25,370 --> 00:28:28,820
course if if you have a large memory

00:28:26,720 --> 00:28:31,040
loss is definitely help for small kind

00:28:28,820 --> 00:28:33,470
of work clubs again by default SPARC is

00:28:31,040 --> 00:28:36,080
trying to use an 80 this does another

00:28:33,470 --> 00:28:38,180
very like a popular open source library

00:28:36,080 --> 00:28:40,160
in the Java community and an IO is the

00:28:38,180 --> 00:28:41,600
default Java socket library so that

00:28:40,160 --> 00:28:44,540
that's the default protocols available

00:28:41,600 --> 00:28:46,790
in the in the in the spark stack but we

00:28:44,540 --> 00:28:49,040
actually provide some plug-in in a spark

00:28:46,790 --> 00:28:51,350
architecture so that you don't all this

00:28:49,040 --> 00:28:52,250
kind of shuffle managers above layers

00:28:51,350 --> 00:28:54,260
are not

00:28:52,250 --> 00:28:56,750
anything we don't change anything over

00:28:54,260 --> 00:28:58,490
there so all kind of the for the shuffle

00:28:56,750 --> 00:29:02,570
mechanism like a sword has your constant

00:28:58,490 --> 00:29:04,820
sword is able to coexist or color to

00:29:02,570 --> 00:29:08,150
work with our proposed designs we give a

00:29:04,820 --> 00:29:11,360
lot of advanced features some pointers

00:29:08,150 --> 00:29:13,910
you can take it look papers so we run

00:29:11,360 --> 00:29:16,010
some kind of experiments on the power of

00:29:13,910 --> 00:29:18,410
marching as well so it is a guru by us

00:29:16,010 --> 00:29:20,780
or by we are we see that IP Opie

00:29:18,410 --> 00:29:24,310
performance on open peroxide is good

00:29:20,780 --> 00:29:26,870
so our automated is able to give like a

00:29:24,310 --> 00:29:28,580
11 percent or 18 percent performance

00:29:26,870 --> 00:29:30,890
improvement for 4 different workflows

00:29:28,580 --> 00:29:32,900
but actually when we go to the uh this

00:29:30,890 --> 00:29:35,900
with this this result actually went with

00:29:32,900 --> 00:29:38,300
nvme SSD so with um they made SSD we see

00:29:35,900 --> 00:29:40,430
that only may call if you have already

00:29:38,300 --> 00:29:42,440
made protocol you're able to get a much

00:29:40,430 --> 00:29:44,630
better performance improvement an extra

00:29:42,440 --> 00:29:46,790
5 percent or 25 percent depends on

00:29:44,630 --> 00:29:49,670
different number close is again same

00:29:46,790 --> 00:29:52,340
Hardware same hardware ok the yellow bar

00:29:49,670 --> 00:29:54,170
is the default Apache Hadoop or spark

00:29:52,340 --> 00:29:56,510
the right the right the red wines our

00:29:54,170 --> 00:29:57,890
solution so your application also saying

00:29:56,510 --> 00:30:00,290
there's no change in application no

00:29:57,890 --> 00:30:02,840
change in in the hardware just the

00:30:00,290 --> 00:30:04,730
middle level you just switch to our

00:30:02,840 --> 00:30:07,940
version we are you are able to read get

00:30:04,730 --> 00:30:10,160
better much better performance so again

00:30:07,940 --> 00:30:12,140
in our group like I mentioned we are we

00:30:10,160 --> 00:30:15,590
have been working on this area for more

00:30:12,140 --> 00:30:17,690
than six years so we are trying to do

00:30:15,590 --> 00:30:19,940
some other things or some for example we

00:30:17,690 --> 00:30:22,520
are trying to propose some new designs

00:30:19,940 --> 00:30:24,230
to enhance performance for p4 post big

00:30:22,520 --> 00:30:26,360
data and lattice and people early stacks

00:30:24,230 --> 00:30:27,970
we want to in the lean risk feature we

00:30:26,360 --> 00:30:30,290
want to make HBase on memory cache tea

00:30:27,970 --> 00:30:32,090
which can run on top of oven power

00:30:30,290 --> 00:30:33,980
efficiently available publicly available

00:30:32,090 --> 00:30:35,900
to everybody and then we also want to

00:30:33,980 --> 00:30:38,210
intensive a log in the cafe and and many

00:30:35,900 --> 00:30:39,980
others and the words of seeded GPGPU

00:30:38,210 --> 00:30:42,530
plus power plus infinite band this may

00:30:39,980 --> 00:30:43,640
be a very good combination for the for

00:30:42,530 --> 00:30:45,800
the future bigger than typical

00:30:43,640 --> 00:30:47,480
applications we are so trying to see

00:30:45,800 --> 00:30:49,880
whether other design opportunities

00:30:47,480 --> 00:30:52,460
available e we can do in for the power

00:30:49,880 --> 00:30:54,950
pie and then some other things like

00:30:52,460 --> 00:30:57,380
earlier talk before this one we heard

00:30:54,950 --> 00:31:00,020
something about like OpenStack or

00:30:57,380 --> 00:31:02,060
kubernetes on top of power so we are

00:31:00,020 --> 00:31:03,320
trying to see that with from performance

00:31:02,060 --> 00:31:05,059
perspective what kind of new

00:31:03,320 --> 00:31:08,000
opportunities we can

00:31:05,059 --> 00:31:09,260
we can like explore especially for

00:31:08,000 --> 00:31:12,200
bigger than the tip nor do more close

00:31:09,260 --> 00:31:14,030
with this let me conclude so we

00:31:12,200 --> 00:31:15,770
discussed the challenges of accelerating

00:31:14,030 --> 00:31:18,110
business tax with a specific authorities

00:31:15,770 --> 00:31:20,900
especially we present some case studies

00:31:18,110 --> 00:31:23,090
in HDFS MapReduce and and spark and then

00:31:20,900 --> 00:31:26,690
we say that open power with InfiniBand

00:31:23,090 --> 00:31:27,919
Parlophone it's kind of promising and we

00:31:26,690 --> 00:31:31,549
are able to get better performance

00:31:27,919 --> 00:31:32,900
through some like careful designs and

00:31:31,549 --> 00:31:35,600
that you need those kind of things and

00:31:32,900 --> 00:31:37,880
the order bizarres looks promising so

00:31:35,600 --> 00:31:39,200
hopefully we are able to enable the Big

00:31:37,880 --> 00:31:40,850
Data community in the people early

00:31:39,200 --> 00:31:43,340
committee trying to use open power plus

00:31:40,850 --> 00:31:45,620
InfiniBand festivities kind of emerging

00:31:43,340 --> 00:31:49,010
hardware so okay get good performance

00:31:45,620 --> 00:31:51,650
we actually along this direction post or

00:31:49,010 --> 00:31:53,630
abandoned we propose we actually

00:31:51,650 --> 00:31:55,850
organize a workshop called HP PDC I

00:31:53,630 --> 00:31:58,520
prefer make their computing we dislike

00:31:55,850 --> 00:32:01,220
force here already so if some of you

00:31:58,520 --> 00:32:03,830
like in the research area or even in the

00:32:01,220 --> 00:32:08,150
industry please feel free to join our

00:32:03,830 --> 00:32:10,360
conference or so in our community thanks

00:32:08,150 --> 00:32:10,360
a lot

00:32:19,520 --> 00:32:27,300
yes Oh Cassandra we actually didn't

00:32:23,240 --> 00:32:29,700
exactly modify their code but we have a

00:32:27,300 --> 00:32:31,080
similar one called memory cache D so

00:32:29,700 --> 00:32:33,420
both of them like a key value stores

00:32:31,080 --> 00:32:35,970
right so the only difference Cassandra

00:32:33,420 --> 00:32:38,070
is based on quorum based consistency

00:32:35,970 --> 00:32:41,340
model but memory cache is a little bit

00:32:38,070 --> 00:32:43,020
different but from from the application

00:32:41,340 --> 00:32:44,940
perspective both of them like key value

00:32:43,020 --> 00:32:49,020
stores or long sequel database see those

00:32:44,940 --> 00:32:51,150
kind of things so I think you just about

00:32:49,020 --> 00:32:53,610
whether to either or not I mean

00:32:51,150 --> 00:32:56,010
performance wise you could you could see

00:32:53,610 --> 00:33:01,310
similar kind of potential this is what I

00:32:56,010 --> 00:33:01,310
want to like give to you the comments

00:33:12,350 --> 00:33:26,489
actually yes yes yes yes this is a very

00:33:25,649 --> 00:33:29,039
good question

00:33:26,489 --> 00:33:31,440
okay so you know like I mentioned

00:33:29,039 --> 00:33:33,389
earlier the key for MapReduce during

00:33:31,440 --> 00:33:36,899
show they're using the HTTP protocol

00:33:33,389 --> 00:33:39,659
okay in with HTTP protocol you probably

00:33:36,899 --> 00:33:41,399
can enable HTTPS like it's securely

00:33:39,659 --> 00:33:44,429
support right that's a good point

00:33:41,399 --> 00:33:46,080
so because we bypassed that so we are we

00:33:44,429 --> 00:33:49,320
are kind of using our DMA based

00:33:46,080 --> 00:33:52,109
protocols so of course not HTTP okay but

00:33:49,320 --> 00:33:54,599
our DMA has its own security guarantee

00:33:52,109 --> 00:33:55,320
so for example all those data transfer

00:33:54,599 --> 00:33:57,779
they have a

00:33:55,320 --> 00:34:01,229
we didn't go to details they have some

00:33:57,779 --> 00:34:05,609
kook a concept of Corky as long as gate

00:34:01,229 --> 00:34:07,799
key you can do like access otherwise you

00:34:05,609 --> 00:34:09,599
cannot okay

00:34:07,799 --> 00:34:11,339
so there's there different kind of

00:34:09,599 --> 00:34:14,510
mechanisms to provide security support

00:34:11,339 --> 00:34:14,510
maybe toe loop and I can give some

00:34:29,369 --> 00:34:34,169
actually it's possible right for example

00:34:31,289 --> 00:34:36,750
for example let's say if you even you

00:34:34,169 --> 00:34:39,690
are using your run in your jobs you your

00:34:36,750 --> 00:34:41,369
your take given a key than me okay we

00:34:39,690 --> 00:34:43,169
have different keys so you cannot access

00:34:41,369 --> 00:34:46,529
my memory I can actually your memory

00:34:43,169 --> 00:34:48,389
because we we have different keys but

00:34:46,529 --> 00:34:52,429
but it's okay he's different than HTTP

00:34:48,389 --> 00:34:52,429
security that's that's that's too

00:35:01,640 --> 00:35:04,590

YouTube URL: https://www.youtube.com/watch?v=FuMBbFZfZD4


