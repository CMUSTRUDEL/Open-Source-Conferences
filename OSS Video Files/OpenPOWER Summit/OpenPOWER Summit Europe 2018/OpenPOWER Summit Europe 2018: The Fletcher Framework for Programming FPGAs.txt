Title: OpenPOWER Summit Europe 2018: The Fletcher Framework for Programming FPGAs
Publication date: 2019-02-07
Playlist: OpenPOWER Summit Europe 2018
Description: 
	Johan Peltenburg, Delft University, speaks at OpenPOWER Summit Europe 2018.

For more information, please visit: https://openpowerfoundation.org/summit-2018-10-eu/
Captions: 
	00:00:00,030 --> 00:00:08,580
okay hello everybody my name is Sean I'm

00:00:03,419 --> 00:00:10,620
from the TU delft and yeah so looking

00:00:08,580 --> 00:00:15,710
back at the analogy of somebody sitting

00:00:10,620 --> 00:00:20,449
on a rocket that was the C++ programmer

00:00:15,710 --> 00:00:22,439
it's actually a dangerous job and so

00:00:20,449 --> 00:00:24,510
we're trying to make that a little bit

00:00:22,439 --> 00:00:27,779
easier using the framework we call

00:00:24,510 --> 00:00:30,689
Fletcher which is based on Apache arrow

00:00:27,779 --> 00:00:35,760
and on a lot of the technologies that

00:00:30,689 --> 00:00:37,829
we've seen today so I'm not the only

00:00:35,760 --> 00:00:40,620
person doing this I also want to give

00:00:37,829 --> 00:00:42,719
thanks to my people helping me with the

00:00:40,620 --> 00:00:45,420
development there on the left and we

00:00:42,719 --> 00:00:48,059
also have a lot of support from from our

00:00:45,420 --> 00:00:49,940
supervisors at tu Delft and also from

00:00:48,059 --> 00:00:52,980
IBM and eiling's

00:00:49,940 --> 00:00:57,239
alright so what I want to talk about is

00:00:52,980 --> 00:01:00,090
we see very often we talk about each

00:00:57,239 --> 00:01:01,770
virginias hardware or when we say each

00:01:00,090 --> 00:01:05,460
Regine is computing we immediately think

00:01:01,770 --> 00:01:07,080
about GPUs or FPGA next to a CPU but

00:01:05,460 --> 00:01:14,580
actually in software there's also a lot

00:01:07,080 --> 00:01:23,610
of heterogeneity so um oh wait I gotta

00:01:14,580 --> 00:01:25,439
remove this there we go okay that was a

00:01:23,610 --> 00:01:28,380
little error that was still stuck there

00:01:25,439 --> 00:01:30,240
okay so we have a lot of different

00:01:28,380 --> 00:01:32,549
languages so we can have compiled

00:01:30,240 --> 00:01:35,369
languages like C++ and Fortran and rust

00:01:32,549 --> 00:01:37,020
we can have languages and run on virtual

00:01:35,369 --> 00:01:39,479
machines like the Java Virtual Machine

00:01:37,020 --> 00:01:42,420
like Java and Scala and we can have

00:01:39,479 --> 00:01:44,820
languages to run on interpreters like

00:01:42,420 --> 00:01:47,790
Python and R and all of these languages

00:01:44,820 --> 00:01:50,100
have some sort of way of especially the

00:01:47,790 --> 00:01:53,490
bottom two types they have some sort of

00:01:50,100 --> 00:01:54,899
way of increasing the performance so the

00:01:53,490 --> 00:01:56,729
virtual machine like languages have

00:01:54,899 --> 00:01:58,710
just-in-time compilers and these

00:01:56,729 --> 00:02:02,909
interpreters have a very strong

00:01:58,710 --> 00:02:05,880
integration with native libraries so

00:02:02,909 --> 00:02:08,429
that lent so there's there's a lot of

00:02:05,880 --> 00:02:12,629
heat Rajini software going on nowadays

00:02:08,429 --> 00:02:13,830
especially in big data systems so what

00:02:12,629 --> 00:02:15,810
do we see

00:02:13,830 --> 00:02:18,150
these big data systems are becoming

00:02:15,810 --> 00:02:20,070
increasingly a hijra genius so that's

00:02:18,150 --> 00:02:21,750
not only on the hardware level because

00:02:20,070 --> 00:02:24,090
we all know we're adding GPUs we're

00:02:21,750 --> 00:02:27,090
adding FPGAs to it but it's also on a

00:02:24,090 --> 00:02:29,790
software level so one example is if you

00:02:27,090 --> 00:02:32,160
look at a popular project called

00:02:29,790 --> 00:02:34,440
tensorflow and spark it's running a

00:02:32,160 --> 00:02:36,960
Python program that's the program you

00:02:34,440 --> 00:02:38,880
are writing as an application developer

00:02:36,960 --> 00:02:41,850
but it's actually using numpy in the

00:02:38,880 --> 00:02:45,870
background which is written in C or is

00:02:41,850 --> 00:02:48,750
using a C core and then it's running

00:02:45,870 --> 00:02:50,670
CUDA programs on a GPU and that's

00:02:48,750 --> 00:02:52,980
running on top of spark which is written

00:02:50,670 --> 00:02:56,190
in Scala and Java running on a java

00:02:52,980 --> 00:02:58,130
virtual machine on a CPU so that's a

00:02:56,190 --> 00:03:00,930
very heterogeneous

00:02:58,130 --> 00:03:02,820
system and this is already very widely

00:03:00,930 --> 00:03:06,240
used system and worked well but it also

00:03:02,820 --> 00:03:08,040
brings some challenges and also

00:03:06,240 --> 00:03:09,510
challenges that that you will see as

00:03:08,040 --> 00:03:14,610
FPGA developers when you try to

00:03:09,510 --> 00:03:18,060
integrate your FPGA accelerator with

00:03:14,610 --> 00:03:24,360
these systems so to sort of illustrate

00:03:18,060 --> 00:03:25,740
this let's look at at the data so one

00:03:24,360 --> 00:03:28,110
question that you have is an FPGA

00:03:25,740 --> 00:03:31,709
developer especially when you have

00:03:28,110 --> 00:03:33,540
something like capi yeah you can get an

00:03:31,709 --> 00:03:35,459
address right so where where was the

00:03:33,540 --> 00:03:37,620
data you have to give it an address your

00:03:35,459 --> 00:03:42,180
accelerator but that's not so trivial to

00:03:37,620 --> 00:03:44,970
answer in many of the cases for for

00:03:42,180 --> 00:03:47,150
different software runtimes so for C++

00:03:44,970 --> 00:03:49,470
for example as or for all of these

00:03:47,150 --> 00:03:51,300
languages let's let's look at a string

00:03:49,470 --> 00:03:55,170
so what does the string look like in

00:03:51,300 --> 00:03:58,470
memory so for C++ we have a little

00:03:55,170 --> 00:04:00,450
structure and we just this actual string

00:03:58,470 --> 00:04:02,010
resides in memory so we have the string

00:04:00,450 --> 00:04:04,440
size we have a little pointer to a

00:04:02,010 --> 00:04:06,810
character buffer but in the C++ standard

00:04:04,440 --> 00:04:08,340
template library for example that

00:04:06,810 --> 00:04:10,950
character buffer can be either an

00:04:08,340 --> 00:04:13,260
internal character array in that same

00:04:10,950 --> 00:04:15,840
memory space or continuous space as the

00:04:13,260 --> 00:04:19,739
rest of the fields or it can be some

00:04:15,840 --> 00:04:21,330
externally allocated character array so

00:04:19,739 --> 00:04:23,940
for Java looks different so there's an

00:04:21,330 --> 00:04:26,340
JVM object header because the Java

00:04:23,940 --> 00:04:27,639
Runtime requires all the objects you

00:04:26,340 --> 00:04:29,620
have this header so it

00:04:27,639 --> 00:04:33,520
knows how to do garbage collection for

00:04:29,620 --> 00:04:37,439
example or other stuff then Java

00:04:33,520 --> 00:04:40,960
stores strings in a with utf-8 16

00:04:37,439 --> 00:04:45,009
characters and as some additional fields

00:04:40,960 --> 00:04:48,310
to it 1 being a reference as they call

00:04:45,009 --> 00:04:49,419
it in the JVM 2 to that array and so

00:04:48,310 --> 00:04:54,099
there's also somewhere else in the

00:04:49,419 --> 00:04:56,710
memory so python has a variable length

00:04:54,099 --> 00:05:00,610
object header so that object itself is a

00:04:56,710 --> 00:05:03,250
variable length and then it has a hash

00:05:00,610 --> 00:05:05,770
for the string and some states for some

00:05:03,250 --> 00:05:08,080
some other mechanisms and then the

00:05:05,770 --> 00:05:10,719
characters follow so these are three

00:05:08,080 --> 00:05:12,699
different ways of actually representing

00:05:10,719 --> 00:05:17,080
the same type of data but there's an

00:05:12,699 --> 00:05:19,180
additional bunch of metadata added to

00:05:17,080 --> 00:05:22,900
that data that in general we don't

00:05:19,180 --> 00:05:24,729
really care about as programmers let

00:05:22,900 --> 00:05:26,740
alone as FPGA developers when we want to

00:05:24,729 --> 00:05:29,710
work on this string so on the right you

00:05:26,740 --> 00:05:31,240
see how I would like to as an FPGA

00:05:29,710 --> 00:05:33,460
developer how I would like to receive my

00:05:31,240 --> 00:05:36,099
string so I would like to I would like

00:05:33,460 --> 00:05:39,580
to receive that string as two streams so

00:05:36,099 --> 00:05:43,180
one stream is a length stream and the

00:05:39,580 --> 00:05:50,500
other stream is a character stream no ok

00:05:43,180 --> 00:05:53,110
we can talk later why not maybe so so

00:05:50,500 --> 00:05:55,689
this brings a lot of well sort of a

00:05:53,110 --> 00:05:57,069
challenge because we have to first first

00:05:55,689 --> 00:06:00,610
of all whenever we write an application

00:05:57,069 --> 00:06:02,409
in some language in that applications

00:06:00,610 --> 00:06:05,589
memory space that string doesn't look

00:06:02,409 --> 00:06:06,729
like I want to receive it on my FPGA so

00:06:05,589 --> 00:06:09,279
we have to do this thing that we call

00:06:06,729 --> 00:06:11,409
serialization this is not only a problem

00:06:09,279 --> 00:06:13,330
for F P J's but it's in general problem

00:06:11,409 --> 00:06:16,120
of course even if you want to send a

00:06:13,330 --> 00:06:17,500
bunch of objects over over the network

00:06:16,120 --> 00:06:20,050
or if you want to store them to disk

00:06:17,500 --> 00:06:22,719
right so what do you have to do when you

00:06:20,050 --> 00:06:26,680
when you serialize so you have to

00:06:22,719 --> 00:06:28,539
suppose you have a collection of objects

00:06:26,680 --> 00:06:32,560
in memory oh you guys don't see my mouse

00:06:28,539 --> 00:06:35,050
I have to move probably ok there we go

00:06:32,560 --> 00:06:39,219
so you have a collection of objects in

00:06:35,050 --> 00:06:41,529
in memory and then so these objects can

00:06:39,219 --> 00:06:44,289
consist of some pointers to other

00:06:41,529 --> 00:06:47,379
fields of the object and so you have to

00:06:44,289 --> 00:06:48,759
prefer if you suppose you want to send

00:06:47,379 --> 00:06:52,209
over all the fields you have to traverse

00:06:48,759 --> 00:06:54,279
all the other references so you pay a

00:06:52,209 --> 00:06:57,009
lot of memory latency in the worst case

00:06:54,279 --> 00:06:58,569
and then you have to copy all those

00:06:57,009 --> 00:07:02,589
fields into some intermediate format

00:06:58,569 --> 00:07:06,939
that everybody understands or both sides

00:07:02,589 --> 00:07:08,649
understand and well copies are pretty

00:07:06,939 --> 00:07:10,209
much a waste of bandwidth because

00:07:08,649 --> 00:07:13,989
they're not really doing anything

00:07:10,209 --> 00:07:18,159
functional and then at the end you have

00:07:13,989 --> 00:07:21,339
to reconstruct all these objects in the

00:07:18,159 --> 00:07:23,349
receiving processes memory again and

00:07:21,339 --> 00:07:25,659
that that can take a lot of allocations

00:07:23,349 --> 00:07:28,089
for example so there's there can be a

00:07:25,659 --> 00:07:30,189
lot of time spent on on this

00:07:28,089 --> 00:07:32,799
serialization and deserialization and

00:07:30,189 --> 00:07:34,629
the same goes of course for when we do

00:07:32,799 --> 00:07:36,459
stuff in accelerators when we start with

00:07:34,629 --> 00:07:38,679
Python objects and we want to do

00:07:36,459 --> 00:07:45,819
something in an FPGA accelerator well

00:07:38,679 --> 00:07:47,979
this can be pretty impactful so so the

00:07:45,819 --> 00:07:50,379
relative impact on accelerators is even

00:07:47,979 --> 00:07:54,489
is even bigger because it's not like

00:07:50,379 --> 00:07:56,259
okay we're processing it in and we're

00:07:54,489 --> 00:07:58,659
creating the data set in in Java for

00:07:56,259 --> 00:08:02,289
example and we're processing it on the

00:07:58,659 --> 00:08:07,239
CPU still in C++ or something maybe

00:08:02,289 --> 00:08:11,589
because of some reasons but in general

00:08:07,239 --> 00:08:14,049
what we see if we if we accelerate some

00:08:11,589 --> 00:08:16,509
computation on the CPU it goes down

00:08:14,049 --> 00:08:18,639
drastic and and we accelerated using a

00:08:16,509 --> 00:08:21,189
GPU or an FPGA it goes and drastically

00:08:18,639 --> 00:08:23,139
right but then suddenly this

00:08:21,189 --> 00:08:27,369
serialization cost is added that we

00:08:23,139 --> 00:08:28,839
don't that we don't want to pay so what

00:08:27,369 --> 00:08:30,279
we would like to do is we don't want to

00:08:28,839 --> 00:08:32,409
do any serialization we just want to do

00:08:30,279 --> 00:08:35,379
the copy and then do the computation and

00:08:32,409 --> 00:08:37,689
be done all right so it's relatively big

00:08:35,379 --> 00:08:43,059
problem and this is not an exaggerated

00:08:37,689 --> 00:08:45,129
graph ok so I pulled out of my hat but

00:08:43,059 --> 00:08:46,629
it's based on what we've seen in real

00:08:45,129 --> 00:08:51,520
applications something I will show later

00:08:46,629 --> 00:08:54,700
and in the slides all right so

00:08:51,520 --> 00:08:57,279
so how do we overcome this problem so we

00:08:54,700 --> 00:09:00,070
serialize and deserialize or a lot so

00:08:57,279 --> 00:09:00,790
that the question is can we do this in a

00:09:00,070 --> 00:09:03,610
smarter way

00:09:00,790 --> 00:09:06,310
so what if the data is in a standardized

00:09:03,610 --> 00:09:10,000
format in in such a format that every

00:09:06,310 --> 00:09:12,370
language runtime can use it and what if

00:09:10,000 --> 00:09:14,709
the data is as continuous as possible so

00:09:12,370 --> 00:09:21,450
we can move it quickly without having to

00:09:14,709 --> 00:09:25,089
traverse all the object graphs so so

00:09:21,450 --> 00:09:27,660
this this sort of solution is useful in

00:09:25,089 --> 00:09:30,370
many places and for many reasons and

00:09:27,660 --> 00:09:33,459
actually there's a top-level Apache

00:09:30,370 --> 00:09:38,560
project was initiated which is called

00:09:33,459 --> 00:09:39,640
Apache arrow and Apache arrow tries to

00:09:38,560 --> 00:09:44,550
deal with this problem with

00:09:39,640 --> 00:09:47,110
serialization so normally you have some

00:09:44,550 --> 00:09:49,839
some big data application that's running

00:09:47,110 --> 00:09:51,430
on top of SPARC on the JVM and every

00:09:49,839 --> 00:09:53,670
whenever you want to run a Python to

00:09:51,430 --> 00:09:56,350
launch you have to serialize deserialize

00:09:53,670 --> 00:09:59,620
whenever they store some stuff on off

00:09:56,350 --> 00:10:01,000
heap memory to prevent garbage

00:09:59,620 --> 00:10:03,670
collection in the JVM you have to

00:10:01,000 --> 00:10:04,990
serialize deserialize when it when you

00:10:03,670 --> 00:10:07,630
when you want to work with some native

00:10:04,990 --> 00:10:09,339
library etc all right also when you want

00:10:07,630 --> 00:10:11,380
to do with FPGA acceleration you have to

00:10:09,339 --> 00:10:14,399
realize deserializing and make

00:10:11,380 --> 00:10:17,500
potentially multiple copies of that data

00:10:14,399 --> 00:10:19,720
so what arrow does is it says well let's

00:10:17,500 --> 00:10:22,720
just create that data set in in a big

00:10:19,720 --> 00:10:26,740
share piece of memory and we do it in a

00:10:22,720 --> 00:10:28,329
format that that is standardized and

00:10:26,740 --> 00:10:31,660
then we provide libraries to all these

00:10:28,329 --> 00:10:33,970
different runtimes to interface with

00:10:31,660 --> 00:10:35,980
that data of course there can be a

00:10:33,970 --> 00:10:38,380
little bit of overhead added to it but

00:10:35,980 --> 00:10:42,490
hopefully because it's very true genius

00:10:38,380 --> 00:10:47,410
over context the benefits are bigger

00:10:42,490 --> 00:10:51,399
than the costs and so yeah they could so

00:10:47,410 --> 00:10:53,740
they call this a common data layer now

00:10:51,399 --> 00:10:55,839
they've been doing some choices there in

00:10:53,740 --> 00:10:57,430
that project so one of the things is

00:10:55,839 --> 00:11:00,360
that they want to make it harder

00:10:57,430 --> 00:11:03,940
friendly so they have a columnar format

00:11:00,360 --> 00:11:05,379
for tabular data I will be on the next

00:11:03,940 --> 00:11:07,929
slide I will show a little

00:11:05,379 --> 00:11:09,970
more what that means but that helps to

00:11:07,929 --> 00:11:14,999
for example iterate over data using

00:11:09,970 --> 00:11:14,999
assigned the instructions and helps with

00:11:15,720 --> 00:11:24,519
to reduce Kashmir misses etc alright so

00:11:20,999 --> 00:11:27,099
the thing we're we did was we added a

00:11:24,519 --> 00:11:30,339
little layer here next to the error

00:11:27,099 --> 00:11:34,799
libraries themselves that makes this

00:11:30,339 --> 00:11:34,799
this shared data set available for FPGA

00:11:35,009 --> 00:11:39,939
so that means that when we use Apache

00:11:37,539 --> 00:11:41,619
arrow to store our data set we don't

00:11:39,939 --> 00:11:44,199
have to pace your leadership overhead

00:11:41,619 --> 00:11:48,579
anymore at all when we consume this data

00:11:44,199 --> 00:11:51,459
using the FPGA so let's take a little

00:11:48,579 --> 00:11:54,489
look at a bit convoluted slide here but

00:11:51,459 --> 00:11:57,669
I will try to guide you through it and

00:11:54,489 --> 00:12:01,929
let's suppose we have this table here so

00:11:57,669 --> 00:12:03,549
it's offered mainly for tabular data we

00:12:01,929 --> 00:12:06,279
have this table here we have a column of

00:12:03,549 --> 00:12:09,069
some floating-point numbers maybe

00:12:06,279 --> 00:12:12,309
there's some nulls in there so there's

00:12:09,069 --> 00:12:15,189
no data for that entry in that column we

00:12:12,309 --> 00:12:18,729
have some strings and we have some some

00:12:15,189 --> 00:12:21,939
structures so the way in which arrow

00:12:18,729 --> 00:12:24,970
works is it doesn't put the meta data on

00:12:21,939 --> 00:12:29,829
on the object itself or on the row

00:12:24,970 --> 00:12:31,779
itself or whatever it just boosted meta

00:12:29,829 --> 00:12:34,869
data on top of the whole data structure

00:12:31,779 --> 00:12:37,470
and it will explain how the data what

00:12:34,869 --> 00:12:41,470
the data looks like what the data means

00:12:37,470 --> 00:12:44,350
anything they call schema so this schema

00:12:41,470 --> 00:12:47,589
has the schema for this table here has

00:12:44,350 --> 00:12:50,470
these three columns here and name this a

00:12:47,589 --> 00:12:52,779
B and C and then we have the types

00:12:50,470 --> 00:12:55,509
behind them right so a string is just a

00:12:52,779 --> 00:13:00,789
list of characters and so through this

00:12:55,509 --> 00:13:03,939
so the schema can be quite complex so it

00:13:00,789 --> 00:13:06,699
can have nested lists you can put

00:13:03,939 --> 00:13:09,099
structs in lists you can put floats in

00:13:06,699 --> 00:13:10,449
lists you can come up with all sorts of

00:13:09,099 --> 00:13:12,789
combinations here and they also have

00:13:10,449 --> 00:13:16,269
dictionaries and other stuff that that

00:13:12,789 --> 00:13:17,949
you can do with it but in the memory it

00:13:16,269 --> 00:13:19,240
tries to make everything as contiguous

00:13:17,949 --> 00:13:22,810
as possible

00:13:19,240 --> 00:13:25,800
so fixed-width types like these floats

00:13:22,810 --> 00:13:30,010
they are stored in any continuous c-like

00:13:25,800 --> 00:13:35,020
array which they call a buffer and then

00:13:30,010 --> 00:13:37,330
multiple buffers can can result in a

00:13:35,020 --> 00:13:39,970
combination of buffers can be can become

00:13:37,330 --> 00:13:41,680
an array what they call an array but

00:13:39,970 --> 00:13:45,459
actually it is a column here in this

00:13:41,680 --> 00:13:46,000
table they call what they call a record

00:13:45,459 --> 00:13:49,510
batch

00:13:46,000 --> 00:13:51,670
alright so because this column allows

00:13:49,510 --> 00:13:54,040
the data to be nala Bowl they also have

00:13:51,670 --> 00:13:58,270
a second buffer here for what they call

00:13:54,040 --> 00:13:59,740
a validity bit my buffer alright so but

00:13:58,270 --> 00:14:01,149
all the all these things that you can

00:13:59,740 --> 00:14:02,380
work on our contiguous and all these

00:14:01,149 --> 00:14:06,490
things that you can work on are

00:14:02,380 --> 00:14:09,130
contiguous so it's as contagious as

00:14:06,490 --> 00:14:12,000
possible so for the strings all the

00:14:09,130 --> 00:14:16,360
characters are in one big buffer and

00:14:12,000 --> 00:14:19,060
then you know there's a second buffer

00:14:16,360 --> 00:14:20,830
saying where each string starts so this

00:14:19,060 --> 00:14:25,959
is quite nice it's nicer than having

00:14:20,830 --> 00:14:27,640
lengths to have offsets or you can you

00:14:25,959 --> 00:14:29,950
can start in parallel processing these

00:14:27,640 --> 00:14:33,730
the strings that are in this character

00:14:29,950 --> 00:14:37,120
buffer so also for structures you just

00:14:33,730 --> 00:14:39,670
get to two buffers like that so true the

00:14:37,120 --> 00:14:42,610
schema you can discover where the data

00:14:39,670 --> 00:14:45,100
is in memory and what it looks like okay

00:14:42,610 --> 00:14:52,959
so so then now we can pass the address

00:14:45,100 --> 00:14:54,730
to do the accelerating alright so so we

00:14:52,959 --> 00:14:56,020
we thought that was very interesting

00:14:54,730 --> 00:14:58,899
because it would solve our serialization

00:14:56,020 --> 00:15:03,279
problem but at the same time it will it

00:14:58,899 --> 00:15:06,579
offers some some extra opportunities for

00:15:03,279 --> 00:15:08,230
FPGA accelerators so it's quite her so

00:15:06,579 --> 00:15:10,959
it's quite harder harder friendly as

00:15:08,230 --> 00:15:12,370
we've seen it's a standardized format so

00:15:10,959 --> 00:15:15,399
if you know the schema you know exactly

00:15:12,370 --> 00:15:17,709
where the data is it's continuous and

00:15:15,399 --> 00:15:20,410
columnar so we can iterate over columns

00:15:17,709 --> 00:15:24,220
in a streaming fashion that sounds good

00:15:20,410 --> 00:15:27,160
for FPGA so and we can use that to do

00:15:24,220 --> 00:15:29,230
maps reductions filters etc which is you

00:15:27,160 --> 00:15:32,699
were often operations that are often

00:15:29,230 --> 00:15:32,699
used in big data systems

00:15:32,830 --> 00:15:36,370
it's a parallel accessible format so and

00:15:34,720 --> 00:15:40,779
we can we can do both streaming and we

00:15:36,370 --> 00:15:44,110
can process stuff in parallel again for

00:15:40,779 --> 00:15:45,640
the same sort of reasons and so this

00:15:44,110 --> 00:15:46,990
made us believe that we could generate

00:15:45,640 --> 00:15:51,010
the easy to use hardware interfaces

00:15:46,990 --> 00:15:53,620
automatically for this based on the

00:15:51,010 --> 00:15:58,000
schema all right so normally when you

00:15:53,620 --> 00:16:01,600
develop for an FPGA and if you do in H

00:15:58,000 --> 00:16:04,600
ll HDL flow you you will be attached to

00:16:01,600 --> 00:16:06,579
this big white bus and you get a cache

00:16:04,600 --> 00:16:07,750
line right but somewhere in the cache

00:16:06,579 --> 00:16:10,329
line is actually the data that you want

00:16:07,750 --> 00:16:12,370
to work on in that instance so you have

00:16:10,329 --> 00:16:15,010
to do all the logic to reorder the data

00:16:12,370 --> 00:16:16,600
to combine these data structures like

00:16:15,010 --> 00:16:18,820
with the offsets and everything and so

00:16:16,600 --> 00:16:21,279
we thought well we can actually generate

00:16:18,820 --> 00:16:23,500
that and just deliver the exactly the

00:16:21,279 --> 00:16:25,779
exact streams that the people that the

00:16:23,500 --> 00:16:27,940
developers have expressed through the

00:16:25,779 --> 00:16:30,040
schema those things we can deliver

00:16:27,940 --> 00:16:33,459
immediately after generation after

00:16:30,040 --> 00:16:35,350
generating that structure for them and

00:16:33,459 --> 00:16:36,940
so that's what we did

00:16:35,350 --> 00:16:39,820
so this is the architecture of the

00:16:36,940 --> 00:16:41,260
framework we call it Fletcher so if

00:16:39,820 --> 00:16:43,899
let's just something with arrows and F

00:16:41,260 --> 00:16:46,240
was for FPGA that's why it's called like

00:16:43,899 --> 00:16:48,130
that all right so you start with an

00:16:46,240 --> 00:16:52,959
arrow schema you're on top left this is

00:16:48,130 --> 00:16:54,940
during compile time then you you you

00:16:52,959 --> 00:16:57,670
throw it into a thing we call the

00:16:54,940 --> 00:16:59,589
interface generation step you get a HDL

00:16:57,670 --> 00:17:04,030
template and then you can still do your

00:16:59,589 --> 00:17:06,280
accelerator design however you want then

00:17:04,030 --> 00:17:07,919
the interface sources and you and your

00:17:06,280 --> 00:17:10,179
your custom sources are they going to

00:17:07,919 --> 00:17:13,439
synthesis place on route and this

00:17:10,179 --> 00:17:15,760
becomes your your FPGA design right

00:17:13,439 --> 00:17:18,669
where the green thing is an interface

00:17:15,760 --> 00:17:21,040
between the host memory and actually the

00:17:18,669 --> 00:17:22,390
streams that are exactly the same data

00:17:21,040 --> 00:17:25,600
types as you've expressed through the

00:17:22,390 --> 00:17:28,919
schema to your hardware accelerated

00:17:25,600 --> 00:17:33,150
function as we call it in our framework

00:17:28,919 --> 00:17:33,150
now yep

00:17:35,900 --> 00:17:42,390
no dessert these are standalone tools

00:17:38,580 --> 00:17:43,260
yeah so I think I will get to that in

00:17:42,390 --> 00:17:48,480
the next slide

00:17:43,260 --> 00:17:51,750
yeah so so so this so during run time

00:17:48,480 --> 00:17:55,770
the only thing you have to do Orwell and

00:17:51,750 --> 00:17:57,780
any any programmer actually that that

00:17:55,770 --> 00:17:59,370
arrow well in any programming languages

00:17:57,780 --> 00:18:00,750
that is supported in the arrow project

00:17:59,370 --> 00:18:03,169
you can now build these data structures

00:18:00,750 --> 00:18:05,780
and you can feed them to the FPGA

00:18:03,169 --> 00:18:08,970
without this Surdas ation overhead

00:18:05,780 --> 00:18:11,669
alright so what that means for a

00:18:08,970 --> 00:18:13,169
specific language is hard to say we're

00:18:11,669 --> 00:18:15,240
investigating this a little bit more

00:18:13,169 --> 00:18:16,679
because to the using these libraries you

00:18:15,240 --> 00:18:19,169
might incur a little bit of overhead in

00:18:16,679 --> 00:18:21,660
different circumstances but in general

00:18:19,169 --> 00:18:23,700
we think especially for accelerated

00:18:21,660 --> 00:18:26,220
computing this helps a lot bringing you

00:18:23,700 --> 00:18:28,020
know bridging the gap between much

00:18:26,220 --> 00:18:31,710
higher level language than were used to

00:18:28,020 --> 00:18:33,090
so the poor guy on the rocket a C++ he's

00:18:31,710 --> 00:18:38,640
not the only guy who wants to step on

00:18:33,090 --> 00:18:41,040
the rocket right so we have a bunch of

00:18:38,640 --> 00:18:44,010
runtime libraries to support just

00:18:41,040 --> 00:18:46,230
throwing data datasets created in arrow

00:18:44,010 --> 00:18:47,880
at you know at the framework and and it

00:18:46,230 --> 00:18:50,370
will do that dispatching of addresses

00:18:47,880 --> 00:18:52,140
and stuff automatically for our

00:18:50,370 --> 00:18:57,059
interface to work properly with those

00:18:52,140 --> 00:18:58,830
buffers alright so yeah so let's get to

00:18:57,059 --> 00:19:02,429
the next slide where I'm I will explain

00:18:58,830 --> 00:19:06,570
what's your question so so the internals

00:19:02,429 --> 00:19:09,360
of this design everything is based on

00:19:06,570 --> 00:19:12,240
some streaming primitives that we did so

00:19:09,360 --> 00:19:14,400
we have all the slices register slices

00:19:12,240 --> 00:19:18,390
the splitters etc and so we created

00:19:14,400 --> 00:19:21,000
these to be vendor agnostic so

00:19:18,390 --> 00:19:22,679
everything is pure HDL all right so

00:19:21,000 --> 00:19:25,470
there is no need to integrate any of

00:19:22,679 --> 00:19:27,540
this with the width achill scripture or

00:19:25,470 --> 00:19:30,870
whatever so it actually works in your g

00:19:27,540 --> 00:19:34,650
HDL it works in questa same version

00:19:30,870 --> 00:19:36,900
action so other parts of the runtime

00:19:34,650 --> 00:19:42,900
engine work with the PS loc hopefully

00:19:36,900 --> 00:19:46,380
soon with the OC l we've also done some

00:19:42,900 --> 00:19:49,080
builds in quarter's just to try it

00:19:46,380 --> 00:19:53,220
so yeah so dad that is one advantage we

00:19:49,080 --> 00:19:55,020
think so more of the internal so using

00:19:53,220 --> 00:19:57,150
these streaming primitives which build

00:19:55,020 --> 00:19:59,100
up what we call the buffer reader so

00:19:57,150 --> 00:20:02,000
every Arab Africa's gets its own reader

00:19:59,100 --> 00:20:04,800
or writer because we can also do writing

00:20:02,000 --> 00:20:07,020
and then combining these buffers in a

00:20:04,800 --> 00:20:10,980
specific way that we can derive from the

00:20:07,020 --> 00:20:14,010
schema we can create what we call column

00:20:10,980 --> 00:20:16,650
writers or column readers to write or

00:20:14,010 --> 00:20:18,150
read a whole column in a table and from

00:20:16,650 --> 00:20:22,250
there you can do a whole table of course

00:20:18,150 --> 00:20:25,440
if you combine those so we generated the

00:20:22,250 --> 00:20:27,210
randomly we generated a lot of lots of

00:20:25,440 --> 00:20:28,980
schemas generated over a thousand

00:20:27,210 --> 00:20:34,830
schemas just to verify the functionality

00:20:28,980 --> 00:20:36,810
of these components and they work so

00:20:34,830 --> 00:20:38,310
somewhere in the internals so for

00:20:36,810 --> 00:20:40,620
example if you have fixed with data with

00:20:38,310 --> 00:20:43,890
a validity bitmap like we saw in the

00:20:40,620 --> 00:20:46,380
example table we get two of these buffer

00:20:43,890 --> 00:20:50,040
readers one for the validity bid map and

00:20:46,380 --> 00:20:52,500
one for the actual data and then we

00:20:50,040 --> 00:20:54,870
synchronize them and that those become

00:20:52,500 --> 00:20:56,730
two streams that go to the user so the

00:20:54,870 --> 00:20:59,730
user will see our this data is valid and

00:20:56,730 --> 00:21:01,410
you know it's so that's not the

00:20:59,730 --> 00:21:05,040
handshaking valid signal but the data

00:21:01,410 --> 00:21:07,290
validity signal and then they will get

00:21:05,040 --> 00:21:09,180
exactly this data type and they can also

00:21:07,290 --> 00:21:10,560
specify some more stuff like they want

00:21:09,180 --> 00:21:13,710
to have more elements per psycho or

00:21:10,560 --> 00:21:16,710
something so we can also do variable

00:21:13,710 --> 00:21:20,100
length data then we just instantiate the

00:21:16,710 --> 00:21:22,170
to buffer readers for example where the

00:21:20,100 --> 00:21:26,130
one that is going to read from the

00:21:22,170 --> 00:21:28,530
offsets is going to be get calculated

00:21:26,130 --> 00:21:30,590
into a length and then it will generate

00:21:28,530 --> 00:21:33,960
a command for the second buffer reader

00:21:30,590 --> 00:21:40,410
in this case we can read for example

00:21:33,960 --> 00:21:41,880
strings and we also have you know

00:21:40,410 --> 00:21:44,010
structure really easy to do we just have

00:21:41,880 --> 00:21:45,690
to synchronize the output of 2 to column

00:21:44,010 --> 00:21:47,550
readers because that's how they stored

00:21:45,690 --> 00:21:50,190
and so this might seem a little bit

00:21:47,550 --> 00:21:52,500
trivial but at the same time you have to

00:21:50,190 --> 00:21:55,890
remember that you know you can you can

00:21:52,500 --> 00:21:57,690
create lots of quite diverse schemas so

00:21:55,890 --> 00:22:00,019
very very deeply nested with lists or

00:21:57,690 --> 00:22:03,600
stuff and so all of this is

00:22:00,019 --> 00:22:06,149
automatically within the HDL itself so

00:22:03,600 --> 00:22:11,700
up until this part there's still no

00:22:06,149 --> 00:22:14,309
external tool being used the only thing

00:22:11,700 --> 00:22:16,799
that we yeah we have a problem but this

00:22:14,309 --> 00:22:21,559
is just a general problem with fidel

00:22:16,799 --> 00:22:21,559
that we cannot we cannot change ports

00:22:21,620 --> 00:22:27,120
dynamically on a component so in the end

00:22:24,990 --> 00:22:31,200
there is a little wrapper generator that

00:22:27,120 --> 00:22:33,600
that generates his template for you your

00:22:31,200 --> 00:22:36,000
your user core template your heart

00:22:33,600 --> 00:22:38,789
accelerated function template and sort

00:22:36,000 --> 00:22:40,409
of you know so all these streams this is

00:22:38,789 --> 00:22:42,360
now two streams but it also might be

00:22:40,409 --> 00:22:45,000
like a thousand streams if you go crazy

00:22:42,360 --> 00:22:47,340
and so these are all concatenated onto

00:22:45,000 --> 00:22:50,840
the same signals so to just dissect

00:22:47,340 --> 00:22:53,610
those we have a little wrapper generator

00:22:50,840 --> 00:22:57,929
alright so let's look at a use case

00:22:53,610 --> 00:23:02,519
because we we actually did the regular

00:22:57,929 --> 00:23:04,980
expression matching before so so what do

00:23:02,519 --> 00:23:06,659
we want to do so given a bunch of

00:23:04,980 --> 00:23:09,450
strings in a big collection of strings

00:23:06,659 --> 00:23:12,330
we want to match em different regular

00:23:09,450 --> 00:23:14,009
expressions and so we count the matches

00:23:12,330 --> 00:23:15,529
for each regular expression for example

00:23:14,009 --> 00:23:18,330
for looking for this regular expression

00:23:15,529 --> 00:23:21,600
and it's gonna match on a specific

00:23:18,330 --> 00:23:26,309
string here so you can imagine doing

00:23:21,600 --> 00:23:27,990
some analysis on how many times somebody

00:23:26,309 --> 00:23:31,980
tweets about a specific animal or

00:23:27,990 --> 00:23:34,860
something and so we did the design here

00:23:31,980 --> 00:23:39,120
so I think the most interesting one for

00:23:34,860 --> 00:23:41,700
this somebody's one on the right so we

00:23:39,120 --> 00:23:44,700
use the power eight capi this is about a

00:23:41,700 --> 00:23:45,090
year ago so we use power eight with

00:23:44,700 --> 00:23:48,389
Kathy

00:23:45,090 --> 00:23:51,419
so these components we we already seen a

00:23:48,389 --> 00:23:54,960
few times and then we've used snap so

00:23:51,419 --> 00:23:56,970
one of the major advantages for us using

00:23:54,960 --> 00:23:59,720
snap is that we get this that ax I

00:23:56,970 --> 00:24:05,549
interface which is very common in in

00:23:59,720 --> 00:24:07,289
FPGA design I think probably the most

00:24:05,549 --> 00:24:10,529
common boss nowadays if you want to

00:24:07,289 --> 00:24:12,990
connect IP and and so we have a little

00:24:10,529 --> 00:24:13,740
layer that we have our own internal

00:24:12,990 --> 00:24:16,740
buses

00:24:13,740 --> 00:24:19,920
them but that we have a you know some

00:24:16,740 --> 00:24:22,050
glue logic for EXI so that that helps us

00:24:19,920 --> 00:24:26,190
first of all to connect to snap and then

00:24:22,050 --> 00:24:28,230
secondly is you know for for other

00:24:26,190 --> 00:24:30,600
systems we have to copy over the arrow

00:24:28,230 --> 00:24:31,860
buffers to the onboard memory but

00:24:30,600 --> 00:24:35,309
because this is a fully streamable

00:24:31,860 --> 00:24:38,700
application we just do the requests on

00:24:35,309 --> 00:24:41,520
on the ax I bus in the snap case and we

00:24:38,700 --> 00:24:45,540
get straight from main memory we get the

00:24:41,520 --> 00:24:47,580
data that we want to work on and we use

00:24:45,540 --> 00:24:48,960
virtual addresses so that that is a big

00:24:47,580 --> 00:24:52,679
advantage we don't have to make a copy

00:24:48,960 --> 00:24:57,179
on the onboard memory so then this goes

00:24:52,679 --> 00:24:59,190
to our our custom interconnect there and

00:24:57,179 --> 00:25:01,320
then it goes into the column readers and

00:24:59,190 --> 00:25:03,240
you know each of the strings it goes

00:25:01,320 --> 00:25:05,460
through and goes into multiple regular

00:25:03,240 --> 00:25:10,140
expression matches in parallel and then

00:25:05,460 --> 00:25:13,740
we have in in the case of here we have

00:25:10,140 --> 00:25:17,010
eight of them eight of these units doing

00:25:13,740 --> 00:25:18,780
sixteen regular expressions each and so

00:25:17,010 --> 00:25:24,929
you can see that you know it's hard for

00:25:18,780 --> 00:25:26,370
a CPU to beat this so but but what one

00:25:24,929 --> 00:25:28,200
part was about the serialization right

00:25:26,370 --> 00:25:30,300
that would be killed before performance

00:25:28,200 --> 00:25:33,000
so I have some some measurements for

00:25:30,300 --> 00:25:36,840
that so we did it in two languages so we

00:25:33,000 --> 00:25:38,700
started with the both Java and C++ so

00:25:36,840 --> 00:25:40,320
first of all we measured just the

00:25:38,700 --> 00:25:42,179
performance this is on a powerade

00:25:40,320 --> 00:25:45,390
machine so we measured the performance

00:25:42,179 --> 00:25:50,520
to match these regular expressions on in

00:25:45,390 --> 00:25:51,809
Java and yeah and you know using all the

00:25:50,520 --> 00:25:55,080
hardware trades that were available to

00:25:51,809 --> 00:25:59,309
us I think one core didn't want to give

00:25:55,080 --> 00:26:01,710
us more so it's 152 we did it for C++

00:25:59,309 --> 00:26:04,170
and we can see well that's that's you

00:26:01,710 --> 00:26:07,410
know a bunch of seconds there it's a bit

00:26:04,170 --> 00:26:09,540
hard for me to read from here but it's

00:26:07,410 --> 00:26:12,750
it's more than what the FPGA would do of

00:26:09,540 --> 00:26:14,490
course so so this is what the FPGA did

00:26:12,750 --> 00:26:20,280
when the data was already sterilized in

00:26:14,490 --> 00:26:21,880
into that error format oops it was a

00:26:20,280 --> 00:26:26,530
little bit too fast

00:26:21,880 --> 00:26:28,780
so if we started to put the data not in

00:26:26,530 --> 00:26:31,990
the arrow format so we did it in its in

00:26:28,780 --> 00:26:32,530
Java zone way doing effector strings or

00:26:31,990 --> 00:26:34,419
something

00:26:32,530 --> 00:26:36,549
and these people plus the same we first

00:26:34,419 --> 00:26:38,559
had to do the serialization I said you

00:26:36,549 --> 00:26:40,000
can you can see well if you first have

00:26:38,559 --> 00:26:43,900
to do that serialization from those

00:26:40,000 --> 00:26:46,090
languages we don't even

00:26:43,900 --> 00:26:49,000
we're not even faster any more than what

00:26:46,090 --> 00:26:50,770
the CPU itself can do right so if we

00:26:49,000 --> 00:26:53,440
have to pay this overhead there's no

00:26:50,770 --> 00:26:54,940
point in accelerating that function

00:26:53,440 --> 00:26:58,390
anymore because the serialization is

00:26:54,940 --> 00:27:00,429
just gonna kill all the performance Wow

00:26:58,390 --> 00:27:02,500
here's some throughput numbers but we

00:27:00,429 --> 00:27:04,900
have a little time left so I will

00:27:02,500 --> 00:27:06,850
continue with hands-on examples so what

00:27:04,900 --> 00:27:09,880
do you have to do we have one well

00:27:06,850 --> 00:27:11,110
couple examples in our repository so one

00:27:09,880 --> 00:27:12,970
of them is just to do a simple sum

00:27:11,110 --> 00:27:16,840
suppose you want to add all the integers

00:27:12,970 --> 00:27:18,190
in a column so some weights or something

00:27:16,840 --> 00:27:20,260
and you just want to accumulate them and

00:27:18,190 --> 00:27:22,000
get some value so what do you do so the

00:27:20,260 --> 00:27:25,570
first step you do is you generate the

00:27:22,000 --> 00:27:27,400
schema well in our examples we use the

00:27:25,570 --> 00:27:29,500
C++ libraries for arrow because they're

00:27:27,400 --> 00:27:31,240
the most advanced at the moment but yeah

00:27:29,500 --> 00:27:35,169
you can also use any of the other

00:27:31,240 --> 00:27:38,230
languages as soon as they have all the

00:27:35,169 --> 00:27:40,659
functionalities that and that you'd like

00:27:38,230 --> 00:27:48,730
to do that for some language that's

00:27:40,659 --> 00:27:50,309
already there anyway so so you can add

00:27:48,730 --> 00:27:55,120
some metadata that is specific to our

00:27:50,309 --> 00:27:56,860
framework so some stuff like you know

00:27:55,120 --> 00:27:59,200
how many elements per cycle you want to

00:27:56,860 --> 00:28:01,030
get maybe some extra stuff in general

00:27:59,200 --> 00:28:02,799
like how many MMR your registers do you

00:28:01,030 --> 00:28:05,140
want to have to pass some configuration

00:28:02,799 --> 00:28:06,640
parameters and then you save that schema

00:28:05,140 --> 00:28:09,309
as a flat but for file but it could also

00:28:06,640 --> 00:28:12,039
sit on top of your data so then you

00:28:09,309 --> 00:28:17,110
throw it in that wrapper generator so

00:28:12,039 --> 00:28:19,299
that's just a little to hear mm-hmm and

00:28:17,110 --> 00:28:21,970
you say well that schema has to go and

00:28:19,299 --> 00:28:24,330
become an FPGA design where the streams

00:28:21,970 --> 00:28:27,669
that are available for me as a developer

00:28:24,330 --> 00:28:34,179
are exactly like that schema tells tells

00:28:27,669 --> 00:28:35,800
it to be so then yeah so we have two

00:28:34,179 --> 00:28:37,630
types of top-level that it can Jenna

00:28:35,800 --> 00:28:40,030
so one is for simulation so that's a

00:28:37,630 --> 00:28:42,520
pure HDL thing you can use it in any

00:28:40,030 --> 00:28:46,600
simulator but we also have one for X I

00:28:42,520 --> 00:28:48,280
because that's more practical thing it's

00:28:46,600 --> 00:28:51,970
compatible with baseline projects for

00:28:48,280 --> 00:28:54,160
captive snap and Amazon's system so then

00:28:51,970 --> 00:28:56,500
the third step is to implement the

00:28:54,160 --> 00:28:58,750
accelerator kernel so in this case you

00:28:56,500 --> 00:29:02,740
get two streams one stream is to send

00:28:58,750 --> 00:29:04,330
commands to the column reader to say

00:29:02,740 --> 00:29:07,960
well which range of data do I want to

00:29:04,330 --> 00:29:12,070
get and and the other stream is any

00:29:07,960 --> 00:29:14,200
actual data so this is fully fully all

00:29:12,070 --> 00:29:15,340
of these are streams right so even this

00:29:14,200 --> 00:29:22,120
command stream you can stream in

00:29:15,340 --> 00:29:23,710
multiple commands at a time so then at

00:29:22,120 --> 00:29:25,510
the end you have to do the finishing

00:29:23,710 --> 00:29:26,710
touches which are relatively normal so

00:29:25,510 --> 00:29:30,490
you have to simulate debug place and

00:29:26,710 --> 00:29:35,350
route and then at the end you you just

00:29:30,490 --> 00:29:37,180
have to wrap around our runtime into our

00:29:35,350 --> 00:29:39,160
runtime library so you can set some

00:29:37,180 --> 00:29:41,950
among you can easily set Emma my own

00:29:39,160 --> 00:29:45,400
read Emma my own and eventually you want

00:29:41,950 --> 00:29:49,240
to throw your your arrow record badge at

00:29:45,400 --> 00:29:56,880
the runtime and everything is executed

00:29:49,240 --> 00:30:00,730
automatically so we have some

00:29:56,880 --> 00:30:02,110
sorry so we have some future work so

00:30:00,730 --> 00:30:05,740
we're continuously developing this

00:30:02,110 --> 00:30:07,720
platform with our group so we want to

00:30:05,740 --> 00:30:10,330
have more applications for showcasing

00:30:07,720 --> 00:30:12,700
your verification and we actually want

00:30:10,330 --> 00:30:15,880
to do some more support some more of the

00:30:12,700 --> 00:30:18,490
arrow supported languages as well so one

00:30:15,880 --> 00:30:20,830
thing we're thinking about doing on soon

00:30:18,490 --> 00:30:22,600
is starting with H less integration for

00:30:20,830 --> 00:30:25,270
MapReduce and filter lambdas in some of

00:30:22,600 --> 00:30:29,080
those high-level languages and doing SQL

00:30:25,270 --> 00:30:31,510
integration on datasets like that all

00:30:29,080 --> 00:30:32,830
right so to summarize these accelerators

00:30:31,510 --> 00:30:34,450
they can be heavily burdened by

00:30:32,830 --> 00:30:36,850
serialization over it from from the

00:30:34,450 --> 00:30:38,860
heterogeneous systems so the Apache our

00:30:36,850 --> 00:30:41,530
format presents prevents sterilization

00:30:38,860 --> 00:30:43,780
overhead it allows hardware interface

00:30:41,530 --> 00:30:47,620
generation so this paves the way for

00:30:43,780 --> 00:30:49,240
more efficient FPGA acceleration in any

00:30:47,620 --> 00:30:52,260
of those supported language

00:30:49,240 --> 00:30:55,360
hmm so it's all open source it's Apache

00:30:52,260 --> 00:30:57,240
licensed so you can find it here also on

00:30:55,360 --> 00:30:59,740
the next slide a little bit smaller and

00:30:57,240 --> 00:31:01,630
then we also have some example

00:30:59,740 --> 00:31:04,030
applications being done by some members

00:31:01,630 --> 00:31:05,320
of the team so the regular expression

00:31:04,030 --> 00:31:07,710
matching examples they're also the

00:31:05,320 --> 00:31:10,390
simple sum of course you get started

00:31:07,710 --> 00:31:13,000
with capital now we did some tests we

00:31:10,390 --> 00:31:14,770
got 11 gigabytes of right bandwidth to a

00:31:13,000 --> 00:31:16,480
narrow data structure that's not

00:31:14,770 --> 00:31:21,940
something you're gonna easily find from

00:31:16,480 --> 00:31:23,470
a Java or Python application and we did

00:31:21,940 --> 00:31:26,260
some implementations for posit

00:31:23,470 --> 00:31:28,960
arithmetic so this is I think relates a

00:31:26,260 --> 00:31:32,070
little bit to the comments of Patterson

00:31:28,960 --> 00:31:34,270
and Hennessey that we saw this morning

00:31:32,070 --> 00:31:35,920
so thank you for the attention any

00:31:34,270 --> 00:31:41,130
questions

00:31:35,920 --> 00:31:41,130

YouTube URL: https://www.youtube.com/watch?v=M8fZm-MIuiU


