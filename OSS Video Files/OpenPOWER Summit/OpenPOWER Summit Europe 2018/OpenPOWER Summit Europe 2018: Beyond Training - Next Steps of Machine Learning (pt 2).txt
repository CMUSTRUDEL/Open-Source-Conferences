Title: OpenPOWER Summit Europe 2018: Beyond Training - Next Steps of Machine Learning (pt 2)
Publication date: 2019-02-07
Playlist: OpenPOWER Summit Europe 2018
Description: 
	Chris Parsons, IBM, speaks at OpenPOWER Summit Europe 2018.

For more information, please visit: https://openpowerfoundation.org/summit-2018-10-eu/
Captions: 
	00:00:00,130 --> 00:00:06,580
this is the second half of my talk and I

00:00:04,540 --> 00:00:08,490
want to talk about in fact I want to

00:00:06,580 --> 00:00:10,690
show you how easy it is to go from

00:00:08,490 --> 00:00:13,660
having an idea having that concept

00:00:10,690 --> 00:00:16,480
through to deploying an AI think a lot

00:00:13,660 --> 00:00:17,890
of the times when I see AI demos talks

00:00:16,480 --> 00:00:19,630
things like that people go hey look

00:00:17,890 --> 00:00:21,849
we've trained it and it's 90% accurate

00:00:19,630 --> 00:00:24,939
and then stop what I want to do with

00:00:21,849 --> 00:00:27,730
this talk is go beyond that so I'm gonna

00:00:24,939 --> 00:00:29,529
talk about why what IBM's motivations

00:00:27,730 --> 00:00:32,500
are what my motivations are behind this

00:00:29,529 --> 00:00:33,820
talk and you talk about IBM's

00:00:32,500 --> 00:00:37,300
tool change so we've built some really

00:00:33,820 --> 00:00:39,579
cool tools to enable this then I'm going

00:00:37,300 --> 00:00:41,530
to do a quick crash course on iOS

00:00:39,579 --> 00:00:42,910
development and go through some of the

00:00:41,530 --> 00:00:44,620
considerations you might want to think

00:00:42,910 --> 00:00:47,649
about when you're architecting this kind

00:00:44,620 --> 00:00:51,129
of solution before I begin anyone in the

00:00:47,649 --> 00:00:52,449
room and iOS developer okay a couple of

00:00:51,129 --> 00:00:54,250
people cool you're in for a smooth ride

00:00:52,449 --> 00:00:56,320
when I do the 101 it's literally one

00:00:54,250 --> 00:00:58,660
slide those of you those of you that are

00:00:56,320 --> 00:01:01,710
not do not worry I just want to put it

00:00:58,660 --> 00:01:05,740
up there to provide some context so why

00:01:01,710 --> 00:01:08,409
why this talk why deploying

00:01:05,740 --> 00:01:09,850
AI so I mentioned just now that I think

00:01:08,409 --> 00:01:11,409
a lot of the topics and other

00:01:09,850 --> 00:01:14,890
conversations talks I see on this

00:01:11,409 --> 00:01:16,900
subject go as far as demoing the

00:01:14,890 --> 00:01:20,079
training right hey hey look we trained

00:01:16,900 --> 00:01:22,479
an AI but nobody uses the training

00:01:20,079 --> 00:01:24,549
people use what you have trained so with

00:01:22,479 --> 00:01:27,579
this talk I want to go one stage beyond

00:01:24,549 --> 00:01:30,549
that and I think this actually indicates

00:01:27,579 --> 00:01:33,640
a slightly wider problem right and and

00:01:30,549 --> 00:01:36,939
that is around machine learning and deep

00:01:33,640 --> 00:01:39,159
learning AI in general and that is that

00:01:36,939 --> 00:01:42,850
is there's this skills gap or gulf

00:01:39,159 --> 00:01:44,710
between the data scientists and your

00:01:42,850 --> 00:01:46,240
subject matter experts right so your

00:01:44,710 --> 00:01:47,590
data scientists the person that that

00:01:46,240 --> 00:01:50,020
understands tensorflow

00:01:47,590 --> 00:01:53,439
gets all of these frameworks that's

00:01:50,020 --> 00:01:56,020
great but actually the person that that

00:01:53,439 --> 00:01:59,110
has that insight is your subject matter

00:01:56,020 --> 00:02:01,450
expert and no more is this the case for

00:01:59,110 --> 00:02:04,840
me or the the obvious kind of use case

00:02:01,450 --> 00:02:06,969
or example of this is medicine right the

00:02:04,840 --> 00:02:08,680
person I want training and teaching my

00:02:06,969 --> 00:02:12,100
system how to classify different types

00:02:08,680 --> 00:02:14,010
of cancer how to identify you know

00:02:12,100 --> 00:02:15,900
whether or not this is the healthy

00:02:14,010 --> 00:02:18,599
or unhealthy tissue right that that

00:02:15,900 --> 00:02:21,930
person is the clinician that has spent

00:02:18,599 --> 00:02:23,519
300 million years understanding that

00:02:21,930 --> 00:02:25,829
field right and has read every textbook

00:02:23,519 --> 00:02:27,900
that timeline is not right but has read

00:02:25,829 --> 00:02:30,060
every textbook on the subject that's the

00:02:27,900 --> 00:02:32,040
person I want giving that insight the

00:02:30,060 --> 00:02:35,310
problem is that person that persona

00:02:32,040 --> 00:02:36,599
probably doesn't have enough time to sit

00:02:35,310 --> 00:02:38,400
there and teach themselves tensorflow

00:02:36,599 --> 00:02:40,230
will sit there and teach themselves cafe

00:02:38,400 --> 00:02:42,599
so how do we enable them how do you

00:02:40,230 --> 00:02:45,420
enable the subject matter expert to be

00:02:42,599 --> 00:02:48,060
able to train and deploy these systems

00:02:45,420 --> 00:02:51,599
right I think that that to me is is one

00:02:48,060 --> 00:02:54,750
of the key things so with that I'm going

00:02:51,599 --> 00:02:57,599
to talk about tooling to do that job one

00:02:54,750 --> 00:02:59,700
of those tools is power AI vision now

00:02:57,599 --> 00:03:01,139
I'm going to show you this in a lot more

00:02:59,700 --> 00:03:04,200
detail and I'm going to show you it live

00:03:01,139 --> 00:03:06,480
in a minute power AR vision is a

00:03:04,200 --> 00:03:08,639
browser-based tool so it's a

00:03:06,480 --> 00:03:10,349
browser-based interface that takes you

00:03:08,639 --> 00:03:13,590
through that entire pipeline for

00:03:10,349 --> 00:03:16,200
building image and video classification

00:03:13,590 --> 00:03:18,359
detection models right so those kind of

00:03:16,200 --> 00:03:20,010
common image workloads that's what it

00:03:18,359 --> 00:03:23,400
walks you through yes please that'd be

00:03:20,010 --> 00:03:24,900
great thank you so so it talks you

00:03:23,400 --> 00:03:27,150
through that kind of pipeline right it

00:03:24,900 --> 00:03:29,489
goes through curating your data set how

00:03:27,150 --> 00:03:30,959
do you curate and accurately label your

00:03:29,489 --> 00:03:32,970
data set from start to finish

00:03:30,959 --> 00:03:35,340
right what tool do you use to do that it

00:03:32,970 --> 00:03:37,620
goes through training your model right

00:03:35,340 --> 00:03:39,510
actually selecting a network to train

00:03:37,620 --> 00:03:42,120
your model against all the way up to

00:03:39,510 --> 00:03:43,769
deploying that model right so actually

00:03:42,120 --> 00:03:45,419
deploying that model so that then users

00:03:43,769 --> 00:03:46,440
can get their hands on it by the way if

00:03:45,419 --> 00:03:48,599
you've ever gone through the process of

00:03:46,440 --> 00:03:51,120
trying to deploy a model for one of

00:03:48,599 --> 00:03:52,530
these workloads the fact that this tool

00:03:51,120 --> 00:03:55,109
can take care of that for you and I'll

00:03:52,530 --> 00:03:57,810
show it in a minute is really useful and

00:03:55,109 --> 00:03:59,819
it handles both video and image

00:03:57,810 --> 00:04:01,470
workloads so it really is about creating

00:03:59,819 --> 00:04:03,540
that pipeline to enable the subject

00:04:01,470 --> 00:04:05,190
matter expert right to take them through

00:04:03,540 --> 00:04:06,930
that journey of doing data science

00:04:05,190 --> 00:04:09,030
without bombarding them with all of the

00:04:06,930 --> 00:04:11,340
tensorflow documentation right without

00:04:09,030 --> 00:04:12,989
making them have to understand Bayesian

00:04:11,340 --> 00:04:15,030
inference and stuff like that let's just

00:04:12,989 --> 00:04:17,370
enable them to build a model for their

00:04:15,030 --> 00:04:20,070
specific domain so that's power AI

00:04:17,370 --> 00:04:23,159
vision and as I said it lets you deploy

00:04:20,070 --> 00:04:27,990
a model as a Web API which I want to

00:04:23,159 --> 00:04:29,520
talk a bit more about so this is xhr

00:04:27,990 --> 00:04:31,110
anyone in roof amilia with this chef's

00:04:29,520 --> 00:04:33,900
hands I don't familiar with EXO sure

00:04:31,110 --> 00:04:37,220
yeah a few be much my developers my iOS

00:04:33,900 --> 00:04:40,830
developer definitely right so xhr is XML

00:04:37,220 --> 00:04:42,449
HTTP requests for those of you that

00:04:40,830 --> 00:04:45,900
aren't familiar with it basically it is

00:04:42,449 --> 00:04:49,650
a web standard protocol for messaging

00:04:45,900 --> 00:04:51,270
essentially what we do is so in this

00:04:49,650 --> 00:04:53,760
example this doesn't quite fit with AI

00:04:51,270 --> 00:04:57,570
vision but most of us I think will have

00:04:53,760 --> 00:04:59,370
booked flights to come here today here

00:04:57,570 --> 00:05:01,770
is an example of xhr for flight so over

00:04:59,370 --> 00:05:03,600
here we have our client this is our web

00:05:01,770 --> 00:05:05,850
browser for the case of this demo it

00:05:03,600 --> 00:05:08,580
will be an iPhone app so we've got our

00:05:05,850 --> 00:05:11,940
web browser and we enter our from and to

00:05:08,580 --> 00:05:14,910
destination and we hit search right then

00:05:11,940 --> 00:05:17,010
what happens is we use xhr to package

00:05:14,910 --> 00:05:19,110
that up in a special box essentially

00:05:17,010 --> 00:05:21,750
that when it gets to our server over

00:05:19,110 --> 00:05:23,639
here where our vision might sit our

00:05:21,750 --> 00:05:24,900
server can unpackage that object and say

00:05:23,639 --> 00:05:26,940
okay yeah I've got the from and to

00:05:24,900 --> 00:05:29,370
destination it's in a particular format

00:05:26,940 --> 00:05:33,630
cool I can then send the response back

00:05:29,370 --> 00:05:38,580
of those flight times and dates so that

00:05:33,630 --> 00:05:40,800
is xhr now the AI vision API is xhr

00:05:38,580 --> 00:05:42,870
compliant which is really awesome it's a

00:05:40,800 --> 00:05:45,720
REST API it's really awesome because it

00:05:42,870 --> 00:05:47,610
means that anywhere where you can do xhr

00:05:45,720 --> 00:05:49,050
you can communicate with this API right

00:05:47,610 --> 00:05:51,210
which is why this talk would work just

00:05:49,050 --> 00:05:53,430
as well if I were building a web site or

00:05:51,210 --> 00:05:55,229
building an Android application or an

00:05:53,430 --> 00:05:58,080
iPhone application or frankly anything

00:05:55,229 --> 00:05:59,490
that can use this xhr protocol if you're

00:05:58,080 --> 00:06:01,470
writing in a programming language that

00:05:59,490 --> 00:06:05,220
doesn't use these kind of standard web

00:06:01,470 --> 00:06:07,320
protocols I'm sorry but they're fair

00:06:05,220 --> 00:06:09,539
they're fairly ubiquitous and it will

00:06:07,320 --> 00:06:12,449
allow you to integrate these models

00:06:09,539 --> 00:06:16,139
trained in our vision really quickly so

00:06:12,449 --> 00:06:17,430
that's xhr the second thing is Jason not

00:06:16,139 --> 00:06:20,789
the Jason at the back who's talking

00:06:17,430 --> 00:06:23,280
later different Jason this is JSON it is

00:06:20,789 --> 00:06:24,960
JavaScript object notation the response

00:06:23,280 --> 00:06:26,580
you get back from AI vision looks a lot

00:06:24,960 --> 00:06:28,500
like this because this is a copy/paste

00:06:26,580 --> 00:06:31,050
of the response you get back from AI

00:06:28,500 --> 00:06:34,320
vision what we've got here is this

00:06:31,050 --> 00:06:36,900
classified field here in it we have two

00:06:34,320 --> 00:06:39,360
things one the classification lares is a

00:06:36,900 --> 00:06:41,190
type of Segal I did a version of this

00:06:39,360 --> 00:06:42,960
talk in Norway and

00:06:41,190 --> 00:06:44,970
point when I was doing the demo

00:06:42,960 --> 00:06:46,770
somebody's hand went straight up and I

00:06:44,970 --> 00:06:49,140
was kind of naive and I said hi yes a

00:06:46,770 --> 00:06:51,480
question brilliant and the guy said that

00:06:49,140 --> 00:06:53,340
is not a lares it's a further floor of

00:06:51,480 --> 00:06:55,290
LA and some other type of bird so I

00:06:53,340 --> 00:06:57,120
learned my lesson so today we'll be

00:06:55,290 --> 00:07:00,000
using chocolate where I am a subject

00:06:57,120 --> 00:07:03,510
matter expert next of that what you get

00:07:00,000 --> 00:07:05,490
is the classification confidence so here

00:07:03,510 --> 00:07:07,440
this particular seagull or not seagull

00:07:05,490 --> 00:07:08,820
was in the training set which is why

00:07:07,440 --> 00:07:10,770
we've got a confidence of a hundred but

00:07:08,820 --> 00:07:12,510
basically it tells you how confident the

00:07:10,770 --> 00:07:16,290
model is that it belongs to that

00:07:12,510 --> 00:07:19,770
category then we get the image URL so it

00:07:16,290 --> 00:07:21,810
stores the image in this temp directory

00:07:19,770 --> 00:07:23,520
here once we've sent it and the final

00:07:21,810 --> 00:07:26,640
thing we get is the result the result of

00:07:23,520 --> 00:07:28,200
our query so you can handle errors

00:07:26,640 --> 00:07:30,570
things like that if you want to on the

00:07:28,200 --> 00:07:32,160
client side I didn't want to seem like

00:07:30,570 --> 00:07:34,020
more work than it was worth so that's

00:07:32,160 --> 00:07:38,490
the response you get back from the AI

00:07:34,020 --> 00:07:41,730
vision API iOS application development

00:07:38,490 --> 00:07:45,270
yeah this really is crash course this is

00:07:41,730 --> 00:07:46,620
a iPhone screenshot so three things you

00:07:45,270 --> 00:07:49,260
need to know for this talk to make sense

00:07:46,620 --> 00:07:51,810
the first thing is that iPhone

00:07:49,260 --> 00:07:53,940
applications or iOS applications can be

00:07:51,810 --> 00:07:55,530
written in a language called Swift Swift

00:07:53,940 --> 00:07:58,110
is open source actually but it

00:07:55,530 --> 00:07:59,610
originated inside Apple it's really

00:07:58,110 --> 00:08:01,620
really cool you can also write them in

00:07:59,610 --> 00:08:04,260
objective-c a variety of other languages

00:08:01,620 --> 00:08:06,630
but I don't like objective-c so I've

00:08:04,260 --> 00:08:09,600
chosen Swift the second thing is you get

00:08:06,630 --> 00:08:11,880
this thing called UI kit now UI kit

00:08:09,600 --> 00:08:13,919
brings with it all of the buttons and

00:08:11,880 --> 00:08:16,440
switches and things you might want for

00:08:13,919 --> 00:08:18,120
your standard user interface so here we

00:08:16,440 --> 00:08:20,250
can see we've got you know our list view

00:08:18,120 --> 00:08:22,740
here a couple of buttons down the bottom

00:08:20,250 --> 00:08:24,480
and our standard navigation controller

00:08:22,740 --> 00:08:26,760
that we're familiar with from pretty

00:08:24,480 --> 00:08:29,250
much every standard application they

00:08:26,760 --> 00:08:30,810
come in this UI kit thing so if I import

00:08:29,250 --> 00:08:33,510
UI kit I also get all these buttons

00:08:30,810 --> 00:08:37,169
pretty easy right the final thing is the

00:08:33,510 --> 00:08:41,310
iOS Network stack which is the network

00:08:37,169 --> 00:08:42,510
stack for iOS so snappily titled and

00:08:41,310 --> 00:08:46,620
we're going to use that to actually you

00:08:42,510 --> 00:08:48,510
form our xhr request and package our

00:08:46,620 --> 00:08:49,560
object up so essentially the

00:08:48,510 --> 00:08:51,120
architecture and i'll go into more

00:08:49,560 --> 00:08:54,120
detail when we start to look at the code

00:08:51,120 --> 00:08:55,410
in a minute but the architecture is we

00:08:54,120 --> 00:08:57,870
take an image from arc

00:08:55,410 --> 00:09:01,230
either choose image or from the camera

00:08:57,870 --> 00:09:03,270
and then we put it in our box fire it

00:09:01,230 --> 00:09:04,950
off to the server get that response back

00:09:03,270 --> 00:09:06,540
and then decide how to handle it right

00:09:04,950 --> 00:09:08,670
so if it's a detection workload like

00:09:06,540 --> 00:09:10,740
this we populate a list view if it's

00:09:08,670 --> 00:09:12,810
classification then we just write the

00:09:10,740 --> 00:09:14,520
response at the top of the page so that

00:09:12,810 --> 00:09:18,390
is everything you need to know to be an

00:09:14,520 --> 00:09:21,630
iOS app developer I promise so we have

00:09:18,390 --> 00:09:23,700
to do two things so this function we can

00:09:21,630 --> 00:09:25,740
dive deeper into it at the moment but we

00:09:23,700 --> 00:09:28,710
have two functions one I have called

00:09:25,740 --> 00:09:31,620
choose image from album lets you choose

00:09:28,710 --> 00:09:35,550
an image from the album the other choose

00:09:31,620 --> 00:09:38,280
image from camera yeah I see I told you

00:09:35,550 --> 00:09:39,630
it is easy so this will open up the

00:09:38,280 --> 00:09:41,760
camera view and let you take a picture

00:09:39,630 --> 00:09:43,170
and then send that to be classified you

00:09:41,760 --> 00:09:46,920
will notice the only difference between

00:09:43,170 --> 00:09:48,150
these two is the source type so here

00:09:46,920 --> 00:09:50,340
we're choosing for the photo library and

00:09:48,150 --> 00:09:53,010
here we're choosing from the camera so

00:09:50,340 --> 00:09:54,450
even that bit is the same and then we

00:09:53,010 --> 00:09:57,420
handle the response of that just by

00:09:54,450 --> 00:10:00,000
making our query to AI vision so so

00:09:57,420 --> 00:10:02,880
that's getting images the second is our

00:10:00,000 --> 00:10:05,610
network request so up here this is where

00:10:02,880 --> 00:10:06,990
your API URL could go by the way for

00:10:05,610 --> 00:10:09,660
those of you who are planning to go to

00:10:06,990 --> 00:10:12,780
the hackathon in a bit all of this code

00:10:09,660 --> 00:10:16,650
on github anyway so this is where the

00:10:12,780 --> 00:10:18,990
API URL for your instance could go then

00:10:16,650 --> 00:10:20,970
we set up our request so we set up some

00:10:18,990 --> 00:10:23,880
of the parameters for our request we

00:10:20,970 --> 00:10:25,560
create below our image object up and we

00:10:23,880 --> 00:10:29,790
get the data from that image so the

00:10:25,560 --> 00:10:33,090
actual image itself on the iPhone isn't

00:10:29,790 --> 00:10:36,360
the PNG right it isn't the JPEG so what

00:10:33,090 --> 00:10:39,570
I do there is I get the JPEG and then

00:10:36,360 --> 00:10:42,390
fire it off to the server down here

00:10:39,570 --> 00:10:44,810
somewhere so that's what we do so we get

00:10:42,390 --> 00:10:47,970
the image from the camera or from our

00:10:44,810 --> 00:10:49,920
album and then we make a simple web

00:10:47,970 --> 00:10:51,630
request a simple Network request over to

00:10:49,920 --> 00:10:56,310
the AI vision instance to get that

00:10:51,630 --> 00:10:58,980
result back simple right I'm going to

00:10:56,310 --> 00:11:00,570
prove it with the next 30 minutes by

00:10:58,980 --> 00:11:01,980
building a dataset in AI vision I'm

00:11:00,570 --> 00:11:03,120
going to cheat a bit there because you

00:11:01,980 --> 00:11:04,980
don't want to sit and watch me upload

00:11:03,120 --> 00:11:07,350
Cadbury's chocolates

00:11:04,980 --> 00:11:08,720
then we're going to train a model deploy

00:11:07,350 --> 00:11:11,720
that model there

00:11:08,720 --> 00:11:14,180
we're gonna not build we're gonna clone

00:11:11,720 --> 00:11:15,260
an iOS app connect it to the API and

00:11:14,180 --> 00:11:16,970
we're going to test the iPhone app

00:11:15,260 --> 00:11:20,870
there's a lares that one is Alerus by

00:11:16,970 --> 00:11:21,980
the way promise so we're gonna test the

00:11:20,870 --> 00:11:24,050
iPhone app and we're gonna do all that

00:11:21,980 --> 00:11:26,750
in about 30 minutes to prove it as

00:11:24,050 --> 00:11:30,440
possible to go from end to end with zero

00:11:26,750 --> 00:11:32,060
skill in in 30 minutes so that's the

00:11:30,440 --> 00:11:33,770
demo before I go into the demo there's a

00:11:32,060 --> 00:11:36,410
few considerations that I wanted to

00:11:33,770 --> 00:11:38,690
touch on about actually the architecture

00:11:36,410 --> 00:11:41,300
for these applications so I've spoken

00:11:38,690 --> 00:11:44,210
heavily about using the AI vision API

00:11:41,300 --> 00:11:46,250
right there are times when that's a

00:11:44,210 --> 00:11:49,340
really good idea and times when you

00:11:46,250 --> 00:11:51,650
don't want to do that it's a really good

00:11:49,340 --> 00:11:54,770
idea because this talk is about AI

00:11:51,650 --> 00:11:57,620
vision and the REST API it is also a

00:11:54,770 --> 00:11:59,630
good idea because it reduces the

00:11:57,620 --> 00:12:02,870
development overhead right it meant that

00:11:59,630 --> 00:12:05,810
I didn't have to integrate the model

00:12:02,870 --> 00:12:07,940
into my app so my app size is smaller so

00:12:05,810 --> 00:12:10,010
if I'm worried about size on a user's

00:12:07,940 --> 00:12:11,870
device then it's really interesting it's

00:12:10,010 --> 00:12:14,210
really useful to use that API because it

00:12:11,870 --> 00:12:17,330
means that you don't have a bloated app

00:12:14,210 --> 00:12:19,730
file size it's it's also useful because

00:12:17,330 --> 00:12:21,560
it means I can change the API and my

00:12:19,730 --> 00:12:23,750
users get that functionality without me

00:12:21,560 --> 00:12:25,190
pushing an app update to them right how

00:12:23,750 --> 00:12:27,290
annoying are those by the way you need

00:12:25,190 --> 00:12:28,280
to update this app bubble that pops up

00:12:27,290 --> 00:12:30,910
all the time unless you have an auto

00:12:28,280 --> 00:12:33,620
update on but those bubbles annoy me and

00:12:30,910 --> 00:12:35,350
the rest API would let you change your

00:12:33,620 --> 00:12:37,970
model so say one day we're recognizing

00:12:35,350 --> 00:12:39,740
eleris is the incorrect bird I could

00:12:37,970 --> 00:12:42,170
quickly change that without disrupting

00:12:39,740 --> 00:12:44,660
my users experience suddenly they get

00:12:42,170 --> 00:12:46,580
the new model right or maybe we add a

00:12:44,660 --> 00:12:48,050
new type of bird into the model they can

00:12:46,580 --> 00:12:50,180
get that without disrupting their

00:12:48,050 --> 00:12:55,550
service times when you would not want to

00:12:50,180 --> 00:12:57,980
use the API use cases where your users

00:12:55,550 --> 00:12:58,940
might not have a network connection all

00:12:57,980 --> 00:13:00,620
right because then doing a bunch of

00:12:58,940 --> 00:13:03,440
stuff over the network isn't very

00:13:00,620 --> 00:13:06,380
helpful say if they're down a mine or

00:13:03,440 --> 00:13:08,630
working underground or actually in the

00:13:06,380 --> 00:13:11,030
case of this bird detection example

00:13:08,630 --> 00:13:12,530
they're in a field looking at birds I

00:13:11,030 --> 00:13:13,910
don't know how they got them to pose

00:13:12,530 --> 00:13:15,200
quite like this but you're in a field

00:13:13,910 --> 00:13:17,060
looking at birds taking photos with your

00:13:15,200 --> 00:13:18,020
iPhone you don't know that you're gonna

00:13:17,060 --> 00:13:20,540
have a network connection

00:13:18,020 --> 00:13:22,010
so maybe the API isn't route to go down

00:13:20,540 --> 00:13:25,400
however for

00:13:22,010 --> 00:13:27,650
purpose of this talk it is also doing

00:13:25,400 --> 00:13:30,860
inference so classifying your image

00:13:27,650 --> 00:13:32,120
the inference phase on device is more

00:13:30,860 --> 00:13:34,130
computationally expensive than the

00:13:32,120 --> 00:13:36,050
network request for a lot of examples so

00:13:34,130 --> 00:13:38,630
if you care about your users battery at

00:13:36,050 --> 00:13:40,670
all right then

00:13:38,630 --> 00:13:42,500
actually maybe sending a lower

00:13:40,670 --> 00:13:46,070
resolution image out over the network is

00:13:42,500 --> 00:13:47,420
is better so up to you just a few of the

00:13:46,070 --> 00:13:49,340
design choices I made anyway as I

00:13:47,420 --> 00:13:51,050
promised um slightly less time now

00:13:49,340 --> 00:13:52,730
because I was talking but we're gonna do

00:13:51,050 --> 00:13:55,700
this demo build the dead-set train the

00:13:52,730 --> 00:13:57,470
model deploy it build the iPhone app and

00:13:55,700 --> 00:14:06,320
connect it to the API and then test it

00:13:57,470 --> 00:14:09,020
in about 30 minutes so let's go right so

00:14:06,320 --> 00:14:10,160
this is this is AI vision for those of

00:14:09,020 --> 00:14:13,550
you that have not seen it has anyone

00:14:10,160 --> 00:14:17,300
seen higher vision yeah okay cool the

00:14:13,550 --> 00:14:19,850
IBM is like me right so power AI vision

00:14:17,300 --> 00:14:21,170
basically as this I think this this is

00:14:19,850 --> 00:14:23,480
the the homepage for it kind of

00:14:21,170 --> 00:14:25,550
illustrates clearly what it does right

00:14:23,480 --> 00:14:27,920
so it's about creating your data set

00:14:25,550 --> 00:14:29,840
doing that data prep so augmenting the

00:14:27,920 --> 00:14:32,300
data if you need to adding noise if you

00:14:29,840 --> 00:14:35,870
need to and then training the model in

00:14:32,300 --> 00:14:37,940
in one kind of platform right and it's

00:14:35,870 --> 00:14:39,890
about enabling the subject matter expert

00:14:37,940 --> 00:14:43,340
so the first place where we need to

00:14:39,890 --> 00:14:45,890
start is with our data set there's a

00:14:43,340 --> 00:14:47,960
cover there's a few here you can see

00:14:45,890 --> 00:14:49,880
varying importance we've got chocolate

00:14:47,960 --> 00:14:51,320
here and we've also got a breast cancer

00:14:49,880 --> 00:14:52,610
demo as well I'm gonna stick with

00:14:51,320 --> 00:14:56,090
chocolate because I'm an expert in that

00:14:52,610 --> 00:14:59,180
so this is our data set what I've done

00:14:56,090 --> 00:15:01,130
beforehand to save you guys is I've

00:14:59,180 --> 00:15:03,980
uploaded photos of these chocolates now

00:15:01,130 --> 00:15:07,490
to upload a photo you can either drag

00:15:03,980 --> 00:15:08,870
the file here or import the files right

00:15:07,490 --> 00:15:10,670
if there's one thing we know about

00:15:08,870 --> 00:15:12,860
humanity at the moment it's that we're

00:15:10,670 --> 00:15:15,080
pretty good at uploading images to web

00:15:12,860 --> 00:15:16,640
browsers rightly or wrongly so I'm not

00:15:15,080 --> 00:15:19,130
going to demo that bit to you but trust

00:15:16,640 --> 00:15:22,460
me it's easy then once you've done that

00:15:19,130 --> 00:15:26,330
you can select the images that you want

00:15:22,460 --> 00:15:29,060
to to label and then select assigned

00:15:26,330 --> 00:15:31,550
category or label objects so let's say

00:15:29,060 --> 00:15:33,410
assign category and then I can pick the

00:15:31,550 --> 00:15:35,600
category of my Cadbury chocolate that

00:15:33,410 --> 00:15:37,370
that is so they are caramels

00:15:35,600 --> 00:15:39,710
so I could select caramel and then it

00:15:37,370 --> 00:15:42,470
would assign the label caramel to them

00:15:39,710 --> 00:15:44,270
right so you can see really quickly I

00:15:42,470 --> 00:15:46,550
don't need to know everything about

00:15:44,270 --> 00:15:49,370
tensorflow or Jupiter notebooks to

00:15:46,550 --> 00:15:50,840
classify my data set of whatever I want

00:15:49,370 --> 00:15:55,010
it to be I can be a subject matter

00:15:50,840 --> 00:15:57,860
expert and I can create this so so the

00:15:55,010 --> 00:15:59,960
other workload so this is this is this

00:15:57,860 --> 00:16:01,280
is our classification problem so there's

00:15:59,960 --> 00:16:03,830
two workloads that we're talking about

00:16:01,280 --> 00:16:05,960
here one is classification what type of

00:16:03,830 --> 00:16:07,970
chocolate this is the other is detection

00:16:05,960 --> 00:16:09,890
we're in the image is there this type of

00:16:07,970 --> 00:16:11,390
chocolate right so those are the two

00:16:09,890 --> 00:16:12,740
workloads so this one's really easy

00:16:11,390 --> 00:16:15,140
right because I just select them then I

00:16:12,740 --> 00:16:18,440
say assign category but what happens if

00:16:15,140 --> 00:16:21,050
I want to do detection well on this

00:16:18,440 --> 00:16:23,060
example I will show you how easy it is

00:16:21,050 --> 00:16:25,610
so let's select our cream egg hero and

00:16:23,060 --> 00:16:28,040
then label objects so what we've got

00:16:25,610 --> 00:16:29,960
here this is a photo around it so you

00:16:28,040 --> 00:16:32,090
can see this blue box this is the

00:16:29,960 --> 00:16:34,330
boundary where we have said there is a

00:16:32,090 --> 00:16:37,280
cream egg here oh so I can delete that

00:16:34,330 --> 00:16:37,850
and then I could say actually you know

00:16:37,280 --> 00:16:41,120
what it is

00:16:37,850 --> 00:16:43,070
a fudge hero and I can click and drag

00:16:41,120 --> 00:16:46,340
around it and let go and now it is

00:16:43,070 --> 00:16:48,350
labeled as oh fudge hero however that is

00:16:46,340 --> 00:16:50,990
bad data science because it is not fudge

00:16:48,350 --> 00:16:52,790
hero so I'm going to quickly undo that

00:16:50,990 --> 00:16:55,250
but you can see actually how quickly it

00:16:52,790 --> 00:16:57,920
is how quickly you can build your

00:16:55,250 --> 00:17:00,620
dataset right either for classification

00:16:57,920 --> 00:17:02,660
or detection it's simple it's a

00:17:00,620 --> 00:17:04,160
browser-based GUI and that means that

00:17:02,660 --> 00:17:05,900
you can get your subject matter expert

00:17:04,160 --> 00:17:08,060
to do the data science and then hand

00:17:05,900 --> 00:17:09,320
them the Train finished product to your

00:17:08,060 --> 00:17:12,110
development team and they can integrate

00:17:09,320 --> 00:17:13,970
it into your application right

00:17:12,110 --> 00:17:16,070
so once you've you've done that for your

00:17:13,970 --> 00:17:17,600
images you can select done editing now

00:17:16,070 --> 00:17:19,459
there are a whole bunch of other

00:17:17,600 --> 00:17:21,470
features that I am not covering because

00:17:19,459 --> 00:17:23,390
they're kind of out of scope for this

00:17:21,470 --> 00:17:26,750
talk but there is a demo booth

00:17:23,390 --> 00:17:28,430
downstairs that will be running in the

00:17:26,750 --> 00:17:30,740
breaks and after this where we can go

00:17:28,430 --> 00:17:32,780
through things like data augmentation so

00:17:30,740 --> 00:17:34,670
we can add noise to your data set so if

00:17:32,780 --> 00:17:36,860
you've got a small data set we can do

00:17:34,670 --> 00:17:38,900
data augmentation to reduce that kind of

00:17:36,860 --> 00:17:41,150
noise and any of those biases that might

00:17:38,900 --> 00:17:43,280
be introduced and we'll go through some

00:17:41,150 --> 00:17:46,010
of the more advanced features of this

00:17:43,280 --> 00:17:48,410
down there on a specific basis but that

00:17:46,010 --> 00:17:49,460
is labeling objects for the purpose of

00:17:48,410 --> 00:17:51,950
this talk

00:17:49,460 --> 00:17:54,530
now I have my labeled data set I'm gonna

00:17:51,950 --> 00:17:56,000
go back to this one because it's faster

00:17:54,530 --> 00:17:57,140
I have my labeled data set and now I

00:17:56,000 --> 00:17:59,360
think okay cool

00:17:57,140 --> 00:18:01,040
done that now I want to train an AI

00:17:59,360 --> 00:18:02,960
right to be able to classify my

00:18:01,040 --> 00:18:05,180
chocolate this is like groundbreaking

00:18:02,960 --> 00:18:07,880
work we're doing here right so I want to

00:18:05,180 --> 00:18:10,880
train this model to do it so I have this

00:18:07,880 --> 00:18:13,280
big blue button train model right and

00:18:10,880 --> 00:18:18,260
then it takes me to this page where I

00:18:13,280 --> 00:18:19,280
give it a name oh it's actually there we

00:18:18,260 --> 00:18:21,020
go

00:18:19,280 --> 00:18:23,270
and I can choose the type of training so

00:18:21,020 --> 00:18:25,400
I can choose classification or or

00:18:23,270 --> 00:18:27,020
detection this is a classification

00:18:25,400 --> 00:18:28,670
problem but this is really useful

00:18:27,020 --> 00:18:30,590
because it means you can use the same

00:18:28,670 --> 00:18:32,950
data set for both classification and

00:18:30,590 --> 00:18:36,140
detection problems you just choose here

00:18:32,950 --> 00:18:37,760
then you choose your base model there

00:18:36,140 --> 00:18:40,550
are a few of them what we do with the

00:18:37,760 --> 00:18:42,920
base model is make some assumptions

00:18:40,550 --> 00:18:45,380
about the underlying network right so we

00:18:42,920 --> 00:18:47,150
can make some assumptions about the best

00:18:45,380 --> 00:18:49,550
Network to train your model with if it

00:18:47,150 --> 00:18:51,410
falls into one of these categories so if

00:18:49,550 --> 00:18:53,210
you notice that you know things like

00:18:51,410 --> 00:18:58,880
flowers flowers all tend to look fairly

00:18:53,210 --> 00:19:00,560
similar not a botanist either so they

00:18:58,880 --> 00:19:01,850
all look relatively similar see so this

00:19:00,560 --> 00:19:03,260
will make some assertions about the

00:19:01,850 --> 00:19:06,320
underlying network to speed things up

00:19:03,260 --> 00:19:08,510
what those assertions are I'm sure we

00:19:06,320 --> 00:19:09,650
could tell you I'm not going to tell you

00:19:08,510 --> 00:19:11,330
in this talk because that would not be

00:19:09,650 --> 00:19:13,580
fun for me to sit here and read out the

00:19:11,330 --> 00:19:15,410
differences between them or you can pick

00:19:13,580 --> 00:19:18,140
general now I'm going to pick general

00:19:15,410 --> 00:19:20,530
because I don't want to make any

00:19:18,140 --> 00:19:24,050
assumptions about the network now I

00:19:20,530 --> 00:19:25,370
could click train here right and then it

00:19:24,050 --> 00:19:26,810
will start to train a model for

00:19:25,370 --> 00:19:29,330
classifying those different types of

00:19:26,810 --> 00:19:31,700
chocolate for me right that's great for

00:19:29,330 --> 00:19:33,350
my SME user my subject matter expert

00:19:31,700 --> 00:19:36,830
user that's brilliant right but actually

00:19:33,350 --> 00:19:38,600
I've got another another user right and

00:19:36,830 --> 00:19:40,070
that is my data scientist my person who

00:19:38,600 --> 00:19:42,200
actually knows what's going on and wants

00:19:40,070 --> 00:19:44,450
to modify some of the hyper parameters

00:19:42,200 --> 00:19:47,690
to do that I can select Advanced Options

00:19:44,450 --> 00:19:49,010
because I am an advanced user and I can

00:19:47,690 --> 00:19:50,870
go through and I can change some of

00:19:49,010 --> 00:19:55,910
these hyper parameters right so I've got

00:19:50,870 --> 00:19:58,040
the so this is the here we go so this is

00:19:55,910 --> 00:19:59,990
this is the so I've got things like the

00:19:58,040 --> 00:20:01,790
maximum number of iterations I've got

00:19:59,990 --> 00:20:03,490
how frequently it's the how frequently I

00:20:01,790 --> 00:20:06,580
run tests

00:20:03,490 --> 00:20:08,440
so against my test data set AI vision

00:20:06,580 --> 00:20:10,120
will automatically reserve some of your

00:20:08,440 --> 00:20:12,909
training data set to use for validation

00:20:10,120 --> 00:20:14,409
does that on its own which is great I

00:20:12,909 --> 00:20:15,820
can modify the learning rate my weight

00:20:14,409 --> 00:20:18,580
decay I can mess about with all of these

00:20:15,820 --> 00:20:20,890
high parameters to ultimately affect how

00:20:18,580 --> 00:20:23,919
my end network looks I can do all that

00:20:20,890 --> 00:20:25,450
here in the interest of time I'm gonna

00:20:23,919 --> 00:20:28,720
say that I want to go through the day

00:20:25,450 --> 00:20:31,510
150 times and I want to test every 10

00:20:28,720 --> 00:20:33,700
now this may not probably won't produce

00:20:31,510 --> 00:20:35,110
a very good Network but in the interest

00:20:33,700 --> 00:20:37,750
of time I just want to show you how how

00:20:35,110 --> 00:20:41,649
quick it is to do it so back out we go

00:20:37,750 --> 00:20:44,590
and I'm gonna click train so what's

00:20:41,649 --> 00:20:46,510
happening now is AI vision is going to

00:20:44,590 --> 00:20:50,649
go through the data set what this pause

00:20:46,510 --> 00:20:52,960
is is our vision is automatically

00:20:50,649 --> 00:20:55,179
resizing those images so they're all the

00:20:52,960 --> 00:20:57,100
same size they're all using the same

00:20:55,179 --> 00:20:58,330
color channel so it's doing the kind of

00:20:57,100 --> 00:21:00,279
things that a data scientist would

00:20:58,330 --> 00:21:01,960
probably be doing manually but the

00:21:00,279 --> 00:21:05,409
reason it's doing it is to balance the

00:21:01,960 --> 00:21:09,880
model it then produces then it says

00:21:05,409 --> 00:21:11,409
error because this is a live demo if it

00:21:09,880 --> 00:21:12,909
weren't a live demo wouldn't say error

00:21:11,409 --> 00:21:15,340
so there we go

00:21:12,909 --> 00:21:17,380
but what happens then trust me is it

00:21:15,340 --> 00:21:19,120
trains on do it that's the fail one

00:21:17,380 --> 00:21:22,059
let's go to one that works it trains and

00:21:19,120 --> 00:21:24,399
you will see something like this so what

00:21:22,059 --> 00:21:26,049
we've got here is our learning rate the

00:21:24,399 --> 00:21:28,149
number of iterations and then

00:21:26,049 --> 00:21:30,730
importantly the accuracy on the

00:21:28,149 --> 00:21:32,889
validation data set so the data it kept

00:21:30,730 --> 00:21:34,899
behind didn't train it you also see this

00:21:32,889 --> 00:21:36,460
graph so you can see it improving so if

00:21:34,899 --> 00:21:38,860
you've got a really steep gradient here

00:21:36,460 --> 00:21:40,480
when your model finishes training you

00:21:38,860 --> 00:21:42,549
probably want to either adjust your

00:21:40,480 --> 00:21:44,889
learning rate or actually look to run

00:21:42,549 --> 00:21:46,840
for more iterations right so this does

00:21:44,889 --> 00:21:48,880
actually show you some really useful

00:21:46,840 --> 00:21:52,240
data so so you've got all that there

00:21:48,880 --> 00:21:54,010
front and center so it's kind of helpful

00:21:52,240 --> 00:21:55,510
for those data scientist users but also

00:21:54,010 --> 00:22:00,820
shows you how accurate your model is

00:21:55,510 --> 00:22:02,080
anyway now we have trained and we framed

00:22:00,820 --> 00:22:03,700
our model we've created a dataset we've

00:22:02,080 --> 00:22:05,049
trained our model although we didn't

00:22:03,700 --> 00:22:08,019
quite because it failed for reasons I

00:22:05,049 --> 00:22:09,990
will debug after this the next step is

00:22:08,019 --> 00:22:13,659
to deploy I'm just actually going to

00:22:09,990 --> 00:22:16,659
delete that model so I can redeploy it

00:22:13,659 --> 00:22:18,159
right so I go back to my models page so

00:22:16,659 --> 00:22:20,259
these are all of the models that I have

00:22:18,159 --> 00:22:23,200
trained on AI visions you can see

00:22:20,259 --> 00:22:24,879
chocolate features heavily so to deploy

00:22:23,200 --> 00:22:27,399
it right now I'm thinking all right so

00:22:24,879 --> 00:22:29,109
I've done the data science I've trained

00:22:27,399 --> 00:22:30,279
my model and now I need to deploy it

00:22:29,109 --> 00:22:32,200
right I need to get it into the hands of

00:22:30,279 --> 00:22:34,629
my engineers so they can integrate it

00:22:32,200 --> 00:22:36,669
into that end application okay to do

00:22:34,629 --> 00:22:37,599
that I take this little box and then

00:22:36,669 --> 00:22:40,869
there's this button here which says

00:22:37,599 --> 00:22:42,999
deploy model I've got this choice here

00:22:40,869 --> 00:22:45,099
deploy and export if I wanted to export

00:22:42,999 --> 00:22:46,899
it and deploy it onto a different node

00:22:45,099 --> 00:22:48,159
something like that absolutely could do

00:22:46,899 --> 00:22:50,470
that but in this case I want to deploy

00:22:48,159 --> 00:22:52,059
it right where it is so I want to deploy

00:22:50,470 --> 00:22:55,499
that and I want to call it chocolate

00:22:52,059 --> 00:22:55,499
detection models so let's hit deploy

00:22:55,649 --> 00:22:58,809
okay

00:22:56,769 --> 00:23:02,859
so that's it so what's happening now is

00:22:58,809 --> 00:23:06,179
it is starting a REST API that will run

00:23:02,859 --> 00:23:08,019
on this box for classifying chocolates

00:23:06,179 --> 00:23:10,419
there we go it's ready I'm glad that

00:23:08,019 --> 00:23:12,369
worked right so so it's ready so I can

00:23:10,419 --> 00:23:15,929
select it here I can view its

00:23:12,369 --> 00:23:18,070
information I can I can test chocolates

00:23:15,929 --> 00:23:19,749
literally here so I can upload the

00:23:18,070 --> 00:23:33,039
chocolate and test it should we see that

00:23:19,749 --> 00:23:35,499
that might be fun right all right so I

00:23:33,039 --> 00:23:37,599
have here by the way the datasets are

00:23:35,499 --> 00:23:40,479
open source as well so if you want 700

00:23:37,599 --> 00:23:42,580
photos of Cadbury chocolates right so

00:23:40,479 --> 00:23:44,619
let's go into chocolate what we've got

00:23:42,580 --> 00:23:46,269
under here so these ones these test ones

00:23:44,619 --> 00:23:48,609
are ones that I have deliberately kept

00:23:46,269 --> 00:23:52,690
out of the data set so that I can do

00:23:48,609 --> 00:23:54,129
this with so let's screenshot that right

00:23:52,690 --> 00:23:56,049
and then let's go back to power AI

00:23:54,129 --> 00:23:57,999
vision go back to our deploy models and

00:23:56,049 --> 00:23:58,330
pick this image classification model

00:23:57,999 --> 00:24:00,309
right

00:23:58,330 --> 00:24:02,259
so here we go so it tells that the

00:24:00,309 --> 00:24:03,820
accuracy over here it's 97% accurate

00:24:02,259 --> 00:24:05,710
which is about to have to prove to us so

00:24:03,820 --> 00:24:07,330
I hope that's right it tells us when it

00:24:05,710 --> 00:24:08,710
was trained as well right so I can view

00:24:07,330 --> 00:24:10,599
whether or not this is the latest and

00:24:08,710 --> 00:24:11,950
greatest version of my model so maybe

00:24:10,599 --> 00:24:13,659
somebody came along with some more data

00:24:11,950 --> 00:24:16,119
and trained it after this and it's more

00:24:13,659 --> 00:24:18,009
accurate then I can make sure that I'm

00:24:16,119 --> 00:24:21,340
always on the latest and greatest stuff

00:24:18,009 --> 00:24:23,349
also shows me who created it so I can

00:24:21,340 --> 00:24:24,759
have multiple users so I know you know

00:24:23,349 --> 00:24:26,349
if I know that John is an absolute

00:24:24,759 --> 00:24:28,359
liability when it comes to training AI

00:24:26,349 --> 00:24:30,160
and it says that he deployed it I can

00:24:28,359 --> 00:24:32,710
ignore the API anyway

00:24:30,160 --> 00:24:36,370
so let's drag the the caramel over here

00:24:32,710 --> 00:24:38,560
and let it go and there we go

00:24:36,370 --> 00:24:41,170
calf it's a caramel so what we've got

00:24:38,560 --> 00:24:43,660
here so what we've got here it hurt me

00:24:41,170 --> 00:24:45,160
before now so over here this is the

00:24:43,660 --> 00:24:47,170
photo I uploaded hopefully everyone

00:24:45,160 --> 00:24:50,530
recognizes that we've got our accuracy

00:24:47,170 --> 00:24:51,850
up the top and this is the really

00:24:50,530 --> 00:24:52,960
interesting thing on this chart for me

00:24:51,850 --> 00:24:55,510
right and this is the really useful

00:24:52,960 --> 00:24:59,170
thing actually is this heat map is

00:24:55,510 --> 00:25:01,240
showing what weight activated right so

00:24:59,170 --> 00:25:04,870
what bits of the image made it's a

00:25:01,240 --> 00:25:07,090
caramel handy because this is the bit of

00:25:04,870 --> 00:25:10,330
the image that would make me say caramel

00:25:07,090 --> 00:25:15,550
right and and that's so helpful because

00:25:10,330 --> 00:25:18,430
I've been we had a maybe I I know of an

00:25:15,550 --> 00:25:20,890
organization that had built an AI to

00:25:18,430 --> 00:25:22,930
classify different types of sandwiches

00:25:20,890 --> 00:25:24,640
right so is this one a chicken sandwich

00:25:22,930 --> 00:25:26,170
or a bacon sandwich whatever it is it

00:25:24,640 --> 00:25:27,370
was classifying sandwiches and they

00:25:26,170 --> 00:25:30,310
built this model and they said you know

00:25:27,370 --> 00:25:31,810
what is 97% accurate classifying

00:25:30,310 --> 00:25:34,120
different types of sandwich and we said

00:25:31,810 --> 00:25:38,890
ok let's see let's run it through this

00:25:34,120 --> 00:25:41,140
and see what happened and it turned out

00:25:38,890 --> 00:25:43,210
so we ran it through and this image the

00:25:41,140 --> 00:25:45,070
background so what is here is white lit

00:25:43,210 --> 00:25:46,300
up like an absolute Christmas tree and a

00:25:45,070 --> 00:25:48,940
bit where the sandwich was was

00:25:46,300 --> 00:25:51,400
completely blue we thought okay not true

00:25:48,940 --> 00:25:53,020
you're classifying sandwiches let's look

00:25:51,400 --> 00:25:54,670
at the data so we went through their

00:25:53,020 --> 00:25:57,670
data set and it turns out that they had

00:25:54,670 --> 00:26:00,430
paid an intern presumably to take photos

00:25:57,670 --> 00:26:02,740
of these different sandwiches but the

00:26:00,430 --> 00:26:05,320
intern had gone out and taken each photo

00:26:02,740 --> 00:26:06,850
with a different background so all of my

00:26:05,320 --> 00:26:09,880
bacon sandwiches had a blue background

00:26:06,850 --> 00:26:12,070
and all of my chicken sandwiches had

00:26:09,880 --> 00:26:13,660
like a white background where they've

00:26:12,070 --> 00:26:15,190
used like different colored backdrops

00:26:13,660 --> 00:26:17,140
just around the office when they created

00:26:15,190 --> 00:26:19,000
this data set so they'd built a model

00:26:17,140 --> 00:26:21,040
that was really really good at telling

00:26:19,000 --> 00:26:23,140
you the background color in an image

00:26:21,040 --> 00:26:25,000
which isn't what they wanted it for at

00:26:23,140 --> 00:26:27,550
all so this is a really useful quick

00:26:25,000 --> 00:26:30,460
sanity check is my model looking for the

00:26:27,550 --> 00:26:35,620
thing I want it to see so particularly

00:26:30,460 --> 00:26:38,170
helpful right so this is this is it

00:26:35,620 --> 00:26:41,470
deployed now up here I have my API

00:26:38,170 --> 00:26:43,850
endpoint I could stand here and read to

00:26:41,470 --> 00:26:47,419
you the full API documentation

00:26:43,850 --> 00:26:49,970
I won't some nervous-looking faces to

00:26:47,419 --> 00:26:52,340
get the API URL to classify against this

00:26:49,970 --> 00:26:54,260
I literally just click copy right and it

00:26:52,340 --> 00:26:55,760
adds it to my clipboard and then I've

00:26:54,260 --> 00:26:57,740
got my API endpoint that I can integrate

00:26:55,760 --> 00:27:00,549
into any application I want right so

00:26:57,740 --> 00:27:02,480
let's jump over to the iPhone

00:27:00,549 --> 00:27:10,039
application development so this is my

00:27:02,480 --> 00:27:11,179
storyboard this is a beach ball that's a

00:27:10,039 --> 00:27:13,190
spinning there we go

00:27:11,179 --> 00:27:15,580
so this is my storyboard let me zoom out

00:27:13,190 --> 00:27:19,940
a bit you will see not massively

00:27:15,580 --> 00:27:22,159
complicated in that sorry there we go in

00:27:19,940 --> 00:27:23,990
that I only have a couple of scenes so

00:27:22,159 --> 00:27:25,039
I've got my main page which lets me

00:27:23,990 --> 00:27:27,020
choose whether or not I'm doing

00:27:25,039 --> 00:27:28,880
classification or detection or something

00:27:27,020 --> 00:27:31,659
like that and then I've got two screens

00:27:28,880 --> 00:27:35,030
both of which are pretty much identical

00:27:31,659 --> 00:27:37,789
the first one up here I've got an image

00:27:35,030 --> 00:27:40,130
view where I will draw the photo that I

00:27:37,789 --> 00:27:42,020
take from my camera or upload from my

00:27:40,130 --> 00:27:43,789
camera roll then I've got a label above

00:27:42,020 --> 00:27:45,740
and below it the label above it I will

00:27:43,789 --> 00:27:47,570
write the classification of the image I

00:27:45,740 --> 00:27:49,880
upload the label below it I will write

00:27:47,570 --> 00:27:51,049
the confidence and then I've got a

00:27:49,880 --> 00:27:56,090
couple of buttons at the bottom for

00:27:51,049 --> 00:27:59,720
choosing my image in the detection use

00:27:56,090 --> 00:28:01,880
case what I have is an image view and

00:27:59,720 --> 00:28:04,309
below a table where I will write the

00:28:01,880 --> 00:28:05,690
classification and the confidence and

00:28:04,309 --> 00:28:07,970
again the same two buttons that let me

00:28:05,690 --> 00:28:10,039
choose an image alright so super

00:28:07,970 --> 00:28:14,169
complicated user interface design I'm

00:28:10,039 --> 00:28:16,490
your man right so let's go into the code

00:28:14,169 --> 00:28:20,510
let's go for classification first right

00:28:16,490 --> 00:28:21,890
so say this one this is that your elet

00:28:20,510 --> 00:28:23,630
let me paste it in so let's take that

00:28:21,890 --> 00:28:24,679
out and paste it in a new one which

00:28:23,630 --> 00:28:26,990
happens to be exactly the same

00:28:24,679 --> 00:28:29,900
I was testing this earlier right and we

00:28:26,990 --> 00:28:31,610
can save that so this is our code so up

00:28:29,900 --> 00:28:41,720
here at the very top that is really

00:28:31,610 --> 00:28:46,309
small why did no one say is that better

00:28:41,720 --> 00:28:48,080
can I go bigger still how we doing we

00:28:46,309 --> 00:28:49,940
good right so up here I've got my

00:28:48,080 --> 00:28:52,070
different parameters so this is where I

00:28:49,940 --> 00:28:54,020
get the image view in those two labels

00:28:52,070 --> 00:28:56,590
just so I get them as properties and I

00:28:54,020 --> 00:28:58,720
can edit them later on

00:28:56,590 --> 00:29:02,260
here I've got this slightly bizarre line

00:28:58,720 --> 00:29:03,909
of code you'd think Apple would handle

00:29:02,260 --> 00:29:05,890
this automatically but this line of code

00:29:03,909 --> 00:29:08,320
will disable the camera button if my

00:29:05,890 --> 00:29:10,900
device doesn't have a camera thinking

00:29:08,320 --> 00:29:13,150
what Apple device or what iOS device

00:29:10,900 --> 00:29:15,840
doesn't have a camera the only one is

00:29:13,150 --> 00:29:17,919
the simulator that runs on a laptop

00:29:15,840 --> 00:29:19,059
there's literally the only device I can

00:29:17,919 --> 00:29:20,679
find that doesn't have one but that line

00:29:19,059 --> 00:29:23,890
of code will disable the camera button

00:29:20,679 --> 00:29:27,880
if there isn't a camera then what I do

00:29:23,890 --> 00:29:29,200
is I set the image ratio so when you

00:29:27,880 --> 00:29:30,820
take a photo it squeezes it into that

00:29:29,200 --> 00:29:33,159
box and doesn't fire my labels off the

00:29:30,820 --> 00:29:34,570
screen and I update my labels so that

00:29:33,159 --> 00:29:36,789
instead of the word label it says

00:29:34,570 --> 00:29:38,590
something more interesting then we've

00:29:36,789 --> 00:29:41,200
got the URL string which you just saw me

00:29:38,590 --> 00:29:43,840
paste in here we do our setup rabbil are

00:29:41,200 --> 00:29:45,460
all very exciting and then this is where

00:29:43,840 --> 00:29:48,250
we deal with our response so we get

00:29:45,460 --> 00:29:51,130
response back here and when it comes

00:29:48,250 --> 00:29:53,980
back to us I am delete that line when it

00:29:51,130 --> 00:29:55,750
comes back to us it is just a string so

00:29:53,980 --> 00:29:57,370
what i'm doing here is converting that

00:29:55,750 --> 00:29:58,690
string into a json object so i can

00:29:57,370 --> 00:30:00,970
manipulate it and get the parameters i

00:29:58,690 --> 00:30:02,799
want out of it so here where i've

00:30:00,970 --> 00:30:04,770
handily commented retrieve values for

00:30:02,799 --> 00:30:07,840
api what i'm doing is getting the

00:30:04,770 --> 00:30:10,059
classification label so what label it

00:30:07,840 --> 00:30:12,309
thinks it belongs to and then also the

00:30:10,059 --> 00:30:14,740
confidence right how confident how

00:30:12,309 --> 00:30:16,710
confident is it that it's that thing and

00:30:14,740 --> 00:30:19,390
then convert them back to a string

00:30:16,710 --> 00:30:21,159
access the main thread and then update

00:30:19,390 --> 00:30:23,980
those two labels the reason i need to

00:30:21,159 --> 00:30:26,230
access the main thread there is iOS

00:30:23,980 --> 00:30:28,149
applications only let you update the UI

00:30:26,230 --> 00:30:30,399
on the main thread so I need to jump

00:30:28,149 --> 00:30:32,590
back over to there so the network task

00:30:30,399 --> 00:30:33,909
will happen asynchronously good that's

00:30:32,590 --> 00:30:35,799
what you want and then they'll come back

00:30:33,909 --> 00:30:37,690
to the main thread and update my UI even

00:30:35,799 --> 00:30:41,679
in the middle of that right that's

00:30:37,690 --> 00:30:43,299
boring Network stuff right so that is in

00:30:41,679 --> 00:30:46,500
theory all the code you need to make

00:30:43,299 --> 00:30:49,240
this work here we are this is my

00:30:46,500 --> 00:30:50,350
simulator running over here what I'm

00:30:49,240 --> 00:30:53,740
going to do is I'm going to choose image

00:30:50,350 --> 00:30:57,690
classification I know she's image

00:30:53,740 --> 00:31:00,850
classification and then choose image and

00:30:57,690 --> 00:31:03,580
then in here you will see conveniently

00:31:00,850 --> 00:31:06,070
my camera roll I have some various

00:31:03,580 --> 00:31:09,190
photos of chocolate I'm going to pick

00:31:06,070 --> 00:31:10,269
one and way thank God that worked so

00:31:09,190 --> 00:31:12,629
it's

00:31:10,269 --> 00:31:14,649
come back and told me that it is a fudge

00:31:12,629 --> 00:31:16,179
drawn the little fudge in the middle and

00:31:14,649 --> 00:31:18,549
it's told me it's confidence right and

00:31:16,179 --> 00:31:19,719
it's doing that on a server that is

00:31:18,549 --> 00:31:21,820
running in our London office

00:31:19,719 --> 00:31:24,909
so it sends the image over the network

00:31:21,820 --> 00:31:26,709
to London gets a result back and and

00:31:24,909 --> 00:31:27,969
renders it on the screen I know this is

00:31:26,709 --> 00:31:29,950
really simple stuff right we're not

00:31:27,969 --> 00:31:31,899
doing anything we're not doing anything

00:31:29,950 --> 00:31:33,849
that will change the world here but it's

00:31:31,899 --> 00:31:36,399
literally that quick to integrate a

00:31:33,849 --> 00:31:38,739
custom image classification model into

00:31:36,399 --> 00:31:41,080
an end-user application right and think

00:31:38,739 --> 00:31:42,279
of the implications of that I know this

00:31:41,080 --> 00:31:43,659
might seem like a slightly trivial

00:31:42,279 --> 00:31:46,179
example but I could apply it to

00:31:43,659 --> 00:31:48,219
absolutely anything right what if I'm

00:31:46,179 --> 00:31:50,289
building an application for the visually

00:31:48,219 --> 00:31:51,669
impaired who really want to know what

00:31:50,289 --> 00:31:54,609
type of chocolate they're looking at and

00:31:51,669 --> 00:31:57,129
using this simple app it will you know

00:31:54,609 --> 00:31:58,419
let them take a photo of that chocolate

00:31:57,129 --> 00:32:00,369
and it will speak the name of the

00:31:58,419 --> 00:32:02,739
chocolate to them using speech to text

00:32:00,369 --> 00:32:04,509
or something like that and so actually

00:32:02,739 --> 00:32:05,709
the impact is kind of profound and you

00:32:04,509 --> 00:32:06,999
can just apply it to whatever you want

00:32:05,709 --> 00:32:08,979
all I'm trying to do is show you how

00:32:06,999 --> 00:32:10,379
quickly you can go from okay I've had a

00:32:08,979 --> 00:32:12,639
really great idea that might use AI

00:32:10,379 --> 00:32:13,929
using some really cool tooling and then

00:32:12,639 --> 00:32:21,539
deploy it and integrate it into an

00:32:13,929 --> 00:32:24,539
end-user application so yes go ahead yes

00:32:21,539 --> 00:32:24,539
yeah

00:32:36,100 --> 00:32:40,990
yeah really good question so the

00:32:38,170 --> 00:32:43,690
question for the recording the question

00:32:40,990 --> 00:32:46,500
from the recording was how many images

00:32:43,690 --> 00:32:50,020
is a typical customer deployment and and

00:32:46,500 --> 00:32:54,040
yeah yeah exactly and and the standard

00:32:50,020 --> 00:32:55,750
tech industry response is it depends it

00:32:54,040 --> 00:32:58,870
depends on it depends on a number of

00:32:55,750 --> 00:33:01,420
different factors one how diverse is

00:32:58,870 --> 00:33:03,430
your sample so here we're choosing

00:33:01,420 --> 00:33:04,900
chocolates which are actually actually

00:33:03,430 --> 00:33:05,620
all relatively similar right we're

00:33:04,900 --> 00:33:07,510
looking at things that are the same

00:33:05,620 --> 00:33:09,730
roughly size and shape maybe the color

00:33:07,510 --> 00:33:12,130
changes but it's fairly simple so for

00:33:09,730 --> 00:33:14,760
this data set there's something like 200

00:33:12,130 --> 00:33:17,650
images so it's not a colossal data set

00:33:14,760 --> 00:33:18,850
if your problem is more complicated and

00:33:17,650 --> 00:33:22,810
things are more similar then you're

00:33:18,850 --> 00:33:24,670
going to want more data naturally the or

00:33:22,810 --> 00:33:26,050
there's a there's a really handy chart

00:33:24,670 --> 00:33:28,210
which actually the folks from end video

00:33:26,050 --> 00:33:30,610
that put together where they've got the

00:33:28,210 --> 00:33:33,250
the number of images and the proposed

00:33:30,610 --> 00:33:36,250
level of accuracy and they say something

00:33:33,250 --> 00:33:37,660
like thousands will be so thousands of

00:33:36,250 --> 00:33:40,780
images for a typical enterprise use case

00:33:37,660 --> 00:33:43,990
will be usable and then by the time you

00:33:40,780 --> 00:33:45,730
get to millions of images you're beating

00:33:43,990 --> 00:33:47,230
human accuracy that's the kind of

00:33:45,730 --> 00:33:48,820
general rule of thumb so we're talking

00:33:47,230 --> 00:33:50,200
the order of thousands which isn't which

00:33:48,820 --> 00:33:52,000
isn't so massive actually when you look

00:33:50,200 --> 00:33:53,560
at enterprise data on the question of

00:33:52,000 --> 00:33:55,510
sitting there in labeling thousands of

00:33:53,560 --> 00:33:56,650
images you're right I don't want to do

00:33:55,510 --> 00:33:58,510
that either that's why we get the

00:33:56,650 --> 00:34:02,230
subject matter expert slash intern to do

00:33:58,510 --> 00:34:05,200
it know there is a there is a there is a

00:34:02,230 --> 00:34:07,450
tool in here which I can show you

00:34:05,200 --> 00:34:10,120
downstairs that will auto label your

00:34:07,450 --> 00:34:11,830
data set so you take a few photos of a

00:34:10,120 --> 00:34:13,690
caramel train a model on a few photos of

00:34:11,830 --> 00:34:15,280
a caramel and then you can fire this off

00:34:13,690 --> 00:34:17,020
so it labels the rest of your data set

00:34:15,280 --> 00:34:17,980
which is really really powerful so it

00:34:17,020 --> 00:34:19,480
means you don't have to sit there and

00:34:17,980 --> 00:34:21,520
tag every image you can tag like a

00:34:19,480 --> 00:34:22,840
sample and then say okay now you tagged

00:34:21,520 --> 00:34:24,370
the rest of them and I will tell you if

00:34:22,840 --> 00:34:27,970
you're right or wrong which can

00:34:24,370 --> 00:34:29,560
expediate that pipeline right so I'm

00:34:27,970 --> 00:34:31,180
gonna be really brave here and I've not

00:34:29,560 --> 00:34:33,280
tested this so let's see if it works I'm

00:34:31,180 --> 00:34:35,650
going to literally copy this from the

00:34:33,280 --> 00:34:39,250
chocolate detection model come over here

00:34:35,650 --> 00:34:41,350
to my detection view controller and it's

00:34:39,250 --> 00:34:43,360
already highlighted it was begging me to

00:34:41,350 --> 00:34:49,450
try this right I'm going to paste that

00:34:43,360 --> 00:34:51,399
in there and then we're gonna redeploy

00:34:49,450 --> 00:34:53,440
about five minute five minutes left I

00:34:51,399 --> 00:34:56,049
think I've got more than five minutes

00:34:53,440 --> 00:34:57,520
I've got 20 minutes left I mean you're

00:34:56,049 --> 00:35:00,549
down early well be good for questions

00:34:57,520 --> 00:35:01,480
right so object detection so let's go

00:35:00,549 --> 00:35:04,829
for this let's try it and see what

00:35:01,480 --> 00:35:04,829
happens so I'm going to choose an image

00:35:05,130 --> 00:35:13,119
and let's pick one with lots of

00:35:08,589 --> 00:35:14,440
chocolates in it hey right so I mean no

00:35:13,119 --> 00:35:16,119
applause fine don't worry about it right

00:35:14,440 --> 00:35:18,339
so there's lots times 20 minutes you can

00:35:16,119 --> 00:35:20,470
clap me at some point right so what

00:35:18,339 --> 00:35:22,180
we've got here is it's gone through

00:35:20,470 --> 00:35:25,299
exactly that same process we all we have

00:35:22,180 --> 00:35:27,520
done is send the image to that other API

00:35:25,299 --> 00:35:30,480
that you saw me paste in one second ago

00:35:27,520 --> 00:35:34,089
and the API said all right cool I see

00:35:30,480 --> 00:35:35,890
cream egg I see caramel heroes and this

00:35:34,089 --> 00:35:37,809
is my confidence right then all I've

00:35:35,890 --> 00:35:39,700
done is taken those parameters in the

00:35:37,809 --> 00:35:42,819
JSON response and use it to populate a

00:35:39,700 --> 00:35:45,010
table and then just to kind of show off

00:35:42,819 --> 00:35:47,440
a bit I've also done some drawing and

00:35:45,010 --> 00:35:49,000
drawn the green boxes around the object

00:35:47,440 --> 00:35:50,799
let's dive into the code it's not

00:35:49,000 --> 00:35:53,140
massively complicated so all this stuff

00:35:50,799 --> 00:35:55,599
is the same right literally I copy

00:35:53,140 --> 00:35:57,460
pasted it but so this is the bit where

00:35:55,599 --> 00:35:58,980
we set up the request the only thing

00:35:57,460 --> 00:36:01,210
that's changed is the endpoint right

00:35:58,980 --> 00:36:03,700
then the bit that is slightly different

00:36:01,210 --> 00:36:06,069
is where I handle the response where I

00:36:03,700 --> 00:36:09,220
handle the output I get back out the

00:36:06,069 --> 00:36:12,130
other side so I've got this array here

00:36:09,220 --> 00:36:15,160
my objects detected array which starts

00:36:12,130 --> 00:36:16,630
as empty and that's why that table is

00:36:15,160 --> 00:36:20,079
empty at the beginning right I've got no

00:36:16,630 --> 00:36:22,119
no objects in that in that table then

00:36:20,079 --> 00:36:23,910
what I do is I convert my response to

00:36:22,119 --> 00:36:27,730
Jason as as possible

00:36:23,910 --> 00:36:29,650
as before from the string I hat by the

00:36:27,730 --> 00:36:32,349
way if I don't get any classifications

00:36:29,650 --> 00:36:35,440
back I don't crash he's all this says

00:36:32,349 --> 00:36:37,869
right so down down here what I'm going

00:36:35,440 --> 00:36:39,670
to do is retrieve the values from that

00:36:37,869 --> 00:36:43,000
API so the API basically comes back with

00:36:39,670 --> 00:36:44,319
this long JSON array that says okay this

00:36:43,000 --> 00:36:45,819
is this is the classification this is

00:36:44,319 --> 00:36:49,900
the confidence and then conveniently

00:36:45,819 --> 00:36:52,180
this is the X Max and X min for all of

00:36:49,900 --> 00:36:54,640
the images right so so here we've got

00:36:52,180 --> 00:36:57,040
the the coordinates basically for those

00:36:54,640 --> 00:36:58,450
green boxes I've drawn right and that's

00:36:57,040 --> 00:37:00,099
cool too because if I wanted to make it

00:36:58,450 --> 00:37:01,569
more complicated what I could do is have

00:37:00,099 --> 00:37:03,310
it so that I could then click on those

00:37:01,569 --> 00:37:06,550
and maybe it would give me a description

00:37:03,310 --> 00:37:08,070
of the thing it had seen or in this case

00:37:06,550 --> 00:37:12,360
I could draw a big green box around it

00:37:08,070 --> 00:37:16,120
so I've got I've got another class here

00:37:12,360 --> 00:37:17,950
which basically says it create is called

00:37:16,120 --> 00:37:19,240
object detection classification because

00:37:17,950 --> 00:37:21,400
I'm really good with titles and

00:37:19,240 --> 00:37:23,080
basically all it does is it holds those

00:37:21,400 --> 00:37:24,670
different parameters so I can get them

00:37:23,080 --> 00:37:27,010
back in a second when I need to fill my

00:37:24,670 --> 00:37:28,270
table so what I've got is the label I'm

00:37:27,010 --> 00:37:30,790
storing the label

00:37:28,270 --> 00:37:33,420
I'm also storing the confidence and I'm

00:37:30,790 --> 00:37:35,800
formatting it into that percentage here

00:37:33,420 --> 00:37:37,570
I'm doing it here because I didn't want

00:37:35,800 --> 00:37:38,800
to do it on the UI thread I wanted it to

00:37:37,570 --> 00:37:41,080
happen as the data came back because

00:37:38,800 --> 00:37:44,610
it's actually really quick just to move

00:37:41,080 --> 00:37:50,290
that float across then I'm storing my

00:37:44,610 --> 00:37:51,460
the the X min the Y max the Y min all of

00:37:50,290 --> 00:37:55,810
those different values in this object

00:37:51,460 --> 00:37:58,930
then I'm adding that object to my up

00:37:55,810 --> 00:38:01,090
here my empty objects detected array and

00:37:58,930 --> 00:38:02,470
then I'm moving on all right so I'm

00:38:01,090 --> 00:38:04,300
iterating through that whole JSON

00:38:02,470 --> 00:38:07,000
response for every classification I've

00:38:04,300 --> 00:38:07,840
got I'm creating an object that is one

00:38:07,000 --> 00:38:10,360
of those object detection

00:38:07,840 --> 00:38:12,910
classifications and then I'm putting it

00:38:10,360 --> 00:38:16,750
in this objects detected array right

00:38:12,910 --> 00:38:18,250
once it's there what I do is I've got C

00:38:16,750 --> 00:38:21,400
I'll go back to my please can I have the

00:38:18,250 --> 00:38:25,840
main thread please what I do then is I

00:38:21,400 --> 00:38:30,580
update the table view data right so the

00:38:25,840 --> 00:38:33,040
the table view basically understands its

00:38:30,580 --> 00:38:34,450
datatype understands what data it can be

00:38:33,040 --> 00:38:36,040
passed and will do all of that heavy

00:38:34,450 --> 00:38:37,780
lifting for you right so I just say this

00:38:36,040 --> 00:38:39,430
is a table view this is your data and

00:38:37,780 --> 00:38:41,080
then when I want to I say right now

00:38:39,430 --> 00:38:42,910
reload your data because I've updated it

00:38:41,080 --> 00:38:45,100
right so you can do that as frequently

00:38:42,910 --> 00:38:46,960
as you want in this case I'm just doing

00:38:45,100 --> 00:38:49,000
it once all of the classifications have

00:38:46,960 --> 00:38:51,250
come in but if you wanted them to render

00:38:49,000 --> 00:38:54,010
one at a time I don't know what that use

00:38:51,250 --> 00:38:56,340
case is but you could do that right and

00:38:54,010 --> 00:39:00,220
then the the guess the final step here

00:38:56,340 --> 00:39:02,920
is I draw on my image so I get my so I

00:39:00,220 --> 00:39:05,710
get my image view and then I call this

00:39:02,920 --> 00:39:08,080
function draw detection rectangle on

00:39:05,710 --> 00:39:11,020
image which draws the detection

00:39:08,080 --> 00:39:14,680
rectangle on the image and persist and

00:39:11,020 --> 00:39:16,380
passes it the images from from that from

00:39:14,680 --> 00:39:19,170
that array right

00:39:16,380 --> 00:39:21,749
so this is what happens basically I get

00:39:19,170 --> 00:39:24,569
the X&Y coordinates and set the the

00:39:21,749 --> 00:39:27,450
height and width of my box and the start

00:39:24,569 --> 00:39:30,269
coordinate and then say okay get my

00:39:27,450 --> 00:39:33,569
current rendering context and draw the

00:39:30,269 --> 00:39:36,390
image with this draw function alright so

00:39:33,569 --> 00:39:38,519
it draws it here with these text

00:39:36,390 --> 00:39:40,739
attributes the other thing I do which

00:39:38,519 --> 00:39:42,660
you will see is I get the so the text

00:39:40,739 --> 00:39:44,190
attribute is I get the label and put the

00:39:42,660 --> 00:39:46,109
label in the top corner so if we go back

00:39:44,190 --> 00:39:48,509
to this I've also drawn the label on

00:39:46,109 --> 00:39:50,069
each box otherwise you just end up with

00:39:48,509 --> 00:39:51,809
a bunch of green boxes around things and

00:39:50,069 --> 00:39:53,999
you don't know what it thought it was so

00:39:51,809 --> 00:39:56,309
so I also get the label back and draw it

00:39:53,999 --> 00:39:58,200
in the top corner and then I return that

00:39:56,309 --> 00:40:00,989
as a new image and render it back on the

00:39:58,200 --> 00:40:04,049
screen so that is literally all that all

00:40:00,989 --> 00:40:06,420
that goes on it's really simple code

00:40:04,049 --> 00:40:08,009
it's not it's not really complicated and

00:40:06,420 --> 00:40:09,390
that's kind of the point of this talk

00:40:08,009 --> 00:40:12,029
right is that it's really really simple

00:40:09,390 --> 00:40:13,650
to go from that idea that core concept

00:40:12,029 --> 00:40:14,940
through to deploying it and integrating

00:40:13,650 --> 00:40:16,970
it into an app that people can have in

00:40:14,940 --> 00:40:20,069
their hands for classifying chocolate

00:40:16,970 --> 00:40:21,749
this app is in the App Store for

00:40:20,069 --> 00:40:23,849
classifying chocolate so if you're

00:40:21,749 --> 00:40:26,369
thinking to yourself I really wish I

00:40:23,849 --> 00:40:28,469
knew what Cadbury hero that was you can

00:40:26,369 --> 00:40:30,839
search for chocolate AI on both the iOS

00:40:28,469 --> 00:40:33,390
and Android App Store and get yourself a

00:40:30,839 --> 00:40:35,160
copy of it and actually because there

00:40:33,390 --> 00:40:37,979
was a Friday where I didn't have much on

00:40:35,160 --> 00:40:39,420
in the office I also did beer so if you

00:40:37,979 --> 00:40:41,789
want an AI that will classify your

00:40:39,420 --> 00:40:43,799
different types of beer please go ahead

00:40:41,789 --> 00:40:46,229
and download beer AI and it will just

00:40:43,799 --> 00:40:48,239
use exactly this REST API to classify

00:40:46,229 --> 00:40:49,920
your different beers and disclaimer on

00:40:48,239 --> 00:40:51,299
that by the way because I mentioned that

00:40:49,920 --> 00:40:52,619
a couple of other conferences and

00:40:51,299 --> 00:40:54,719
guaranteed every drink this evening

00:40:52,619 --> 00:40:57,440
someone will come up to me and say this

00:40:54,719 --> 00:41:00,630
beer isn't in the app I know I'm sorry

00:40:57,440 --> 00:41:03,900
there is like the beers I had in the off

00:41:00,630 --> 00:41:05,999
in the offer its the beers that the

00:41:03,900 --> 00:41:08,579
local Tesco's or Sainsbury's or other

00:41:05,999 --> 00:41:09,420
supermarket sold near the office on a

00:41:08,579 --> 00:41:10,799
Friday afternoon

00:41:09,420 --> 00:41:12,509
that's the beers that are in there so

00:41:10,799 --> 00:41:14,339
there might not be any of the Amsterdam

00:41:12,509 --> 00:41:16,890
favorites although Heineken is in there

00:41:14,339 --> 00:41:18,839
so feel free to download beer a ID and

00:41:16,890 --> 00:41:20,099
give it give it a try later on if it

00:41:18,839 --> 00:41:22,109
doesn't work please don't come and tell

00:41:20,099 --> 00:41:24,239
me unless you are carrying a beer for me

00:41:22,109 --> 00:41:27,329
and then please come and tell me that it

00:41:24,239 --> 00:41:29,369
didn't work right so that's kind of the

00:41:27,329 --> 00:41:29,850
demo end to end just before I finish as

00:41:29,369 --> 00:41:31,710
we've got

00:41:29,850 --> 00:41:33,990
plenty of time I'm gonna choose another

00:41:31,710 --> 00:41:35,160
image this one with noise in the

00:41:33,990 --> 00:41:39,900
background and see what happens

00:41:35,160 --> 00:41:41,310
oh I'm so so that that works so what

00:41:39,900 --> 00:41:43,200
we've done exactly the same thing it's

00:41:41,310 --> 00:41:45,270
gone through and it's classified the the

00:41:43,200 --> 00:41:47,130
images one of the things that's really

00:41:45,270 --> 00:41:49,050
interesting on this depends on how

00:41:47,130 --> 00:41:52,050
knowledgeable you guys are about Cadbury

00:41:49,050 --> 00:41:54,210
chocolate is that the whisper and the

00:41:52,050 --> 00:41:57,270
Dairy Milk are both really really

00:41:54,210 --> 00:41:59,660
similar they're both purple with the

00:41:57,270 --> 00:42:01,590
only difference being that one says

00:41:59,660 --> 00:42:04,650
their milk on it and the other says

00:42:01,590 --> 00:42:07,020
whisper the AI actually does get those

00:42:04,650 --> 00:42:07,950
confused really often it mixes the two

00:42:07,020 --> 00:42:09,690
of them up because they're really

00:42:07,950 --> 00:42:12,000
similar the others brightly colored

00:42:09,690 --> 00:42:13,050
packaging really distinct it's really

00:42:12,000 --> 00:42:14,160
easy for so where we come back to the

00:42:13,050 --> 00:42:16,110
question that I had earlier on about how

00:42:14,160 --> 00:42:18,210
many images you need and what was it

00:42:16,110 --> 00:42:20,160
depends it does and it depends on the

00:42:18,210 --> 00:42:21,930
class and how similar the class is and

00:42:20,160 --> 00:42:24,810
and actually the problem you're trying

00:42:21,930 --> 00:42:27,780
to solve for so so there's kind of lots

00:42:24,810 --> 00:42:29,520
of lots of nuances but but actually this

00:42:27,780 --> 00:42:32,550
tool the AI vision tool makes it really

00:42:29,520 --> 00:42:35,000
easy to kind of pick those up so I will

00:42:32,550 --> 00:42:37,170
finish with this the code all on github

00:42:35,000 --> 00:42:40,170
github.com forward slash crisp pass

00:42:37,170 --> 00:42:43,260
instead for vision underscore iOS you

00:42:40,170 --> 00:42:45,390
get all the code and not much of a

00:42:43,260 --> 00:42:46,860
readme but you get all the code to go

00:42:45,390 --> 00:42:48,210
and get access to this and do what you

00:42:46,860 --> 00:42:49,790
want with it right do something really

00:42:48,210 --> 00:42:53,610
really cool with it that is not

00:42:49,790 --> 00:42:55,770
detecting Cadbury chocolates right so

00:42:53,610 --> 00:42:57,600
that's it the only thing I will put up

00:42:55,770 --> 00:42:58,970
is just this slide because I bothered to

00:42:57,600 --> 00:43:03,210
build it so you're all going to see it

00:42:58,970 --> 00:43:04,950
just the the thank-you slide and and

00:43:03,210 --> 00:43:05,910
just to finish with you know you guys

00:43:04,950 --> 00:43:07,770
have been great thank you so much for

00:43:05,910 --> 00:43:08,850
coming along there's a few links on here

00:43:07,770 --> 00:43:12,390
if you want to get access to the code

00:43:08,850 --> 00:43:13,530
samples like that any of that and you

00:43:12,390 --> 00:43:15,480
know if you're wondering where to go

00:43:13,530 --> 00:43:17,970
next there's a hackathon a few rooms

00:43:15,480 --> 00:43:20,010
down go there do this do better than I

00:43:17,970 --> 00:43:22,820
did with Cadbury's chocolate but yeah I

00:43:20,010 --> 00:43:22,820
think you're right for listening

00:43:23,740 --> 00:43:25,800

YouTube URL: https://www.youtube.com/watch?v=UG9z-NCdKKQ


