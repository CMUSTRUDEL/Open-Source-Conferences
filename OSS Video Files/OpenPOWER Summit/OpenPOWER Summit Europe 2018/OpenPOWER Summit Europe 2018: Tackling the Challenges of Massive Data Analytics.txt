Title: OpenPOWER Summit Europe 2018: Tackling the Challenges of Massive Data Analytics
Publication date: 2018-11-14
Playlist: OpenPOWER Summit Europe 2018
Description: 
	David Leichner, CMO and Ayelet Heyman, VP Product, SQream, speak at OpenPOWER Foundation's OpenPOWER Summit Europe 2018.

For more information, please visit: https://openpowerfoundation.org/summit-2018-10-eu/
Captions: 
	00:00:00,500 --> 00:00:05,569
my name is David lysine I'm the CMO at

00:00:03,170 --> 00:00:09,230
scream and with me today as I yell it

00:00:05,569 --> 00:00:11,210
Haman who's our product VP of product so

00:00:09,230 --> 00:00:14,150
you have in the room a couple of very

00:00:11,210 --> 00:00:16,010
interesting people from scream quick

00:00:14,150 --> 00:00:18,079
question for you how many people in the

00:00:16,010 --> 00:00:23,989
room have more than 50 terabytes of data

00:00:18,079 --> 00:00:26,599
in their organization okay okay so you

00:00:23,989 --> 00:00:28,699
should meet with Hannon Cohen who's

00:00:26,599 --> 00:00:31,159
sitting in the back row there he's

00:00:28,699 --> 00:00:33,440
actually our the person responsible for

00:00:31,159 --> 00:00:34,880
business in Europe so we would like to

00:00:33,440 --> 00:00:38,000
have a conversation with you once you've

00:00:34,880 --> 00:00:40,970
seen this amazing product great so I'm

00:00:38,000 --> 00:00:43,490
gonna start off with basically just

00:00:40,970 --> 00:00:45,380
going through setting the stage you

00:00:43,490 --> 00:00:47,420
could say for the the technical part of

00:00:45,380 --> 00:00:49,280
this presentation by talking about the

00:00:47,420 --> 00:00:52,070
the challenges that that companies are

00:00:49,280 --> 00:00:54,380
facing with massive data analytics so

00:00:52,070 --> 00:00:57,920
I'm going to jump right in this slide

00:00:54,380 --> 00:01:01,100
basically shows you that CPU based

00:00:57,920 --> 00:01:03,290
technology x86 technology has stayed

00:01:01,100 --> 00:01:06,260
relatively stagnant over the years and

00:01:03,290 --> 00:01:08,030
we can see that GPU technology as we

00:01:06,260 --> 00:01:11,180
know and as nvidia has made a lot of

00:01:08,030 --> 00:01:14,900
noise about has obviously grown

00:01:11,180 --> 00:01:17,000
substantially the the technology the

00:01:14,900 --> 00:01:17,690
capabilities performance capabilities

00:01:17,000 --> 00:01:20,479
and so on

00:01:17,690 --> 00:01:22,790
now what you're seeing here is data

00:01:20,479 --> 00:01:24,920
that's grown and as we know there are

00:01:22,790 --> 00:01:27,229
different analyst companies that are

00:01:24,920 --> 00:01:29,030
talking about the fact that 90% of the

00:01:27,229 --> 00:01:31,820
world's data was created in the last two

00:01:29,030 --> 00:01:34,340
years every month were going up by X

00:01:31,820 --> 00:01:36,710
amount of you know data in the world

00:01:34,340 --> 00:01:39,020
terabytes petabytes up to you know

00:01:36,710 --> 00:01:40,220
trillions of whatever that we're going

00:01:39,020 --> 00:01:42,140
to have in the world in the next two to

00:01:40,220 --> 00:01:45,920
three years so organizations are facing

00:01:42,140 --> 00:01:48,229
major major hassles in both storing the

00:01:45,920 --> 00:01:50,510
data and getting information off of the

00:01:48,229 --> 00:01:52,159
data and one of the reasons is because

00:01:50,510 --> 00:01:54,860
the data warehouses that they're using

00:01:52,159 --> 00:01:57,080
were not built to handle this kind of

00:01:54,860 --> 00:01:59,270
data you know back in when I started out

00:01:57,080 --> 00:02:01,010
30 years ago we were talking about you

00:01:59,270 --> 00:02:02,930
know megabytes of data then we went to

00:02:01,010 --> 00:02:04,700
gigabytes of data well today we have

00:02:02,930 --> 00:02:07,640
companies that we're talking to who are

00:02:04,700 --> 00:02:09,560
trying to tackle how to analyze the data

00:02:07,640 --> 00:02:13,370
coming off of hundreds of petabytes of

00:02:09,560 --> 00:02:14,330
data so the visionaries that scream when

00:02:13,370 --> 00:02:17,360
we started out

00:02:14,330 --> 00:02:19,910
they were looking at how to handle let's

00:02:17,360 --> 00:02:21,020
say hundreds of terabytes looking into

00:02:19,910 --> 00:02:22,310
the future and understanding that

00:02:21,020 --> 00:02:24,290
there's going to be this tremendous

00:02:22,310 --> 00:02:25,940
growth and part of the growth and the

00:02:24,290 --> 00:02:28,670
reason for the growth is as I mentioned

00:02:25,940 --> 00:02:30,790
the x86 systems are not advancing the

00:02:28,670 --> 00:02:33,830
same way that we're seeing for example

00:02:30,790 --> 00:02:36,140
GPUs advancing so if you look at a

00:02:33,830 --> 00:02:38,360
typical query this was actually one of

00:02:36,140 --> 00:02:42,800
our customers they were getting data off

00:02:38,360 --> 00:02:44,720
of micro antennas and it was taking them

00:02:42,800 --> 00:02:46,130
30 minutes to transfer that data into

00:02:44,720 --> 00:02:49,340
the data like it was then taking them

00:02:46,130 --> 00:02:51,200
three to five hours to to ingest the

00:02:49,340 --> 00:02:53,330
data to create the cubes to aggregate

00:02:51,200 --> 00:02:55,880
that data basically the data preparation

00:02:53,330 --> 00:02:58,400
level taking three to five hours and

00:02:55,880 --> 00:02:59,810
then going from the legacy MPP it was

00:02:58,400 --> 00:03:01,580
taking them another couple of hours to

00:02:59,810 --> 00:03:04,790
get the query out so we're talking about

00:03:01,580 --> 00:03:07,790
up to nine ten hours to get one query

00:03:04,790 --> 00:03:10,550
done coming off of those micro cells

00:03:07,790 --> 00:03:13,010
okay so this is the challenge is that

00:03:10,550 --> 00:03:14,959
these SQL queries are taking way too

00:03:13,010 --> 00:03:16,250
long and business intelligence is

00:03:14,959 --> 00:03:19,430
limited by the amount of data that

00:03:16,250 --> 00:03:22,970
you're actually able to to query and to

00:03:19,430 --> 00:03:25,640
analyze so estimates are that 90% of

00:03:22,970 --> 00:03:27,820
business intelligence is being lost in

00:03:25,640 --> 00:03:31,220
organizations and when I talk to

00:03:27,820 --> 00:03:33,019
companies at events or at business

00:03:31,220 --> 00:03:36,019
meetings so what they're telling me is

00:03:33,019 --> 00:03:37,489
that they're analyzing 10 to 15% of

00:03:36,019 --> 00:03:38,840
their data they don't even know how much

00:03:37,489 --> 00:03:40,910
data they have and if we're talking to

00:03:38,840 --> 00:03:42,560
the data scientists they say talk to the

00:03:40,910 --> 00:03:44,660
database person the database person says

00:03:42,560 --> 00:03:47,150
yeah we have hundreds of terabytes of

00:03:44,660 --> 00:03:49,040
data we can only offer up to five

00:03:47,150 --> 00:03:52,220
terabytes of data to the data scientists

00:03:49,040 --> 00:03:53,720
in order to do the analysis work and so

00:03:52,220 --> 00:03:55,610
at the end of the day the reports that

00:03:53,720 --> 00:03:58,730
are going up to the to the c-level to

00:03:55,610 --> 00:04:00,709
the board it could only have you know 10

00:03:58,730 --> 00:04:02,480
15 percent of the data actually analyzed

00:04:00,709 --> 00:04:03,769
they might not even know that they might

00:04:02,480 --> 00:04:05,540
be getting their report saying well this

00:04:03,769 --> 00:04:06,650
is great information but then they come

00:04:05,540 --> 00:04:09,019
back and they check they say well why am

00:04:06,650 --> 00:04:11,090
I only getting historical information of

00:04:09,019 --> 00:04:13,130
a week why can't I get a year why can't

00:04:11,090 --> 00:04:15,280
I get two years so these are the types

00:04:13,130 --> 00:04:17,540
of challenges that were we're tackling

00:04:15,280 --> 00:04:19,760
so basically you could say this is our

00:04:17,540 --> 00:04:22,400
elevator pitch before I hand over to I

00:04:19,760 --> 00:04:24,080
yell it we can analyze twenty times more

00:04:22,400 --> 00:04:25,850
data we can do it a hundred times faster

00:04:24,080 --> 00:04:26,870
at ten percent of cost and this has been

00:04:25,850 --> 00:04:29,840
proven in

00:04:26,870 --> 00:04:32,450
use cases that will talk if we have time

00:04:29,840 --> 00:04:35,120
we'll talk about it later on today just

00:04:32,450 --> 00:04:36,889
one more slide showing what we are

00:04:35,120 --> 00:04:39,800
before we hand over and I will go

00:04:36,889 --> 00:04:43,430
through how we did it so we are a data

00:04:39,800 --> 00:04:44,930
warehouse powered by GPUs massively

00:04:43,430 --> 00:04:47,570
scalable so we can handle everything

00:04:44,930 --> 00:04:50,060
from a terabyte of data up to petabytes

00:04:47,570 --> 00:04:51,740
of data we are an SQL database really

00:04:50,060 --> 00:04:54,230
important we realize that most of the

00:04:51,740 --> 00:04:56,060
data that's being where the struggle is

00:04:54,230 --> 00:04:57,880
in order to analyze that data is coming

00:04:56,060 --> 00:05:01,070
off of corporate data enterprise data

00:04:57,880 --> 00:05:03,350
which today different estimates have it

00:05:01,070 --> 00:05:04,880
at 75 80 percent of that data is SQL

00:05:03,350 --> 00:05:07,970
base so it was really important for us

00:05:04,880 --> 00:05:12,290
to stay - to have a this data warehouse

00:05:07,970 --> 00:05:14,290
B standard SQL extensible for machine

00:05:12,290 --> 00:05:16,880
learning and artificial intelligence

00:05:14,290 --> 00:05:19,700
very minimal footprint and we'll talk

00:05:16,880 --> 00:05:22,520
about that later on and a very very

00:05:19,700 --> 00:05:24,979
rapid ingest of data so one of our goals

00:05:22,520 --> 00:05:26,960
was to go from the point of bringing

00:05:24,979 --> 00:05:29,780
data into the system - point of getting

00:05:26,960 --> 00:05:32,240
it out so time to query time of query

00:05:29,780 --> 00:05:38,000
would be extremely extremely fast and

00:05:32,240 --> 00:05:41,210
just yesterday we announced that we are

00:05:38,000 --> 00:05:44,150
now available for power 9 so it was very

00:05:41,210 --> 00:05:46,160
much in line with this event so we made

00:05:44,150 --> 00:05:49,880
this announcement yesterday that the

00:05:46,160 --> 00:05:53,030
data warehouse scream dB we boast query

00:05:49,880 --> 00:05:55,700
performance of up to 150 percent and I

00:05:53,030 --> 00:05:58,070
yell at will drill down into that and

00:05:55,700 --> 00:05:59,930
you can see here a quote from one of

00:05:58,070 --> 00:06:02,030
your colleagues for the IBM errs in the

00:05:59,930 --> 00:06:05,210
room this came from somewhat Koopa who

00:06:02,030 --> 00:06:08,300
was the VP of HPC and he wrote basically

00:06:05,210 --> 00:06:10,280
that the combination of scream and IBM

00:06:08,300 --> 00:06:12,979
power 9 platform takes this concept to

00:06:10,280 --> 00:06:14,419
another level of performance so with

00:06:12,979 --> 00:06:16,430
that I'd like to hand over to our yell

00:06:14,419 --> 00:06:17,930
at who's going to go through and get

00:06:16,430 --> 00:06:22,060
more into the technical details

00:06:17,930 --> 00:06:30,590
thank you David I feel like a rockstar

00:06:22,060 --> 00:06:33,530
talking about GPUs okay so as weird as

00:06:30,590 --> 00:06:36,430
it may sound you hear me well we

00:06:33,530 --> 00:06:39,470
developed data base from scratch and

00:06:36,430 --> 00:06:42,290
this is not something that is very

00:06:39,470 --> 00:06:46,250
the co2 business personnel wants to go

00:06:42,290 --> 00:06:48,550
fast to the market why we did that we

00:06:46,250 --> 00:06:52,310
did that in order to fulfill our mission

00:06:48,550 --> 00:06:56,150
to provide high performance data

00:06:52,310 --> 00:06:58,760
analytics at scale is David said we are

00:06:56,150 --> 00:07:03,080
not in the business of one Tara - Tara

00:06:58,760 --> 00:07:12,110
five terrors we are in the 500 Tara and

00:07:03,080 --> 00:07:14,660
going north the way to do that was to

00:07:12,110 --> 00:07:18,760
combine our advanced technology together

00:07:14,660 --> 00:07:21,650
with the parallel processing of the GPU

00:07:18,760 --> 00:07:25,480
the main three operation we need to

00:07:21,650 --> 00:07:28,280
manage was loading data to the GPU

00:07:25,480 --> 00:07:32,590
executing the data and then extract it

00:07:28,280 --> 00:07:36,530
back and video technology enabled us to

00:07:32,590 --> 00:07:39,620
do this very efficiently in a high

00:07:36,530 --> 00:07:42,410
performance manner what we did we used

00:07:39,620 --> 00:07:45,560
the pin memory to transfer the data to

00:07:42,410 --> 00:07:50,050
the GPU having the a synchronous copies

00:07:45,560 --> 00:07:52,630
of the data together from and to CPU GPU

00:07:50,050 --> 00:07:58,580
together with an video streaming

00:07:52,630 --> 00:08:02,710
programming model we got into concurrent

00:07:58,580 --> 00:08:05,990
CUDA operations and this took they

00:08:02,710 --> 00:08:12,680
enabled us to utilize the GPU into a

00:08:05,990 --> 00:08:15,620
maximum however we were we were still

00:08:12,680 --> 00:08:21,620
bounded by the PCI which introduced the

00:08:15,620 --> 00:08:25,180
typical IO bat earnings so IBM called it

00:08:21,620 --> 00:08:29,270
and willing we call it the missing link

00:08:25,180 --> 00:08:31,610
what Envy link enabled us is to take the

00:08:29,270 --> 00:08:34,820
concurrent CUDA operation into a new

00:08:31,610 --> 00:08:38,450
scale by enjoying the full bandwidth of

00:08:34,820 --> 00:08:43,700
the anvil Inc and then reducing the i/o

00:08:38,450 --> 00:08:46,400
bottlenecks to a minimum now it's just

00:08:43,700 --> 00:08:49,250
it's not just the course or the envy

00:08:46,400 --> 00:08:54,730
links we are looking at it as a whole

00:08:49,250 --> 00:09:05,690
system there will echo system the

00:08:54,730 --> 00:09:07,160
for high-performance computing okay this

00:09:05,690 --> 00:09:11,000
is the interesting part let's take a

00:09:07,160 --> 00:09:14,779
look at the results we did a benchmark

00:09:11,000 --> 00:09:18,649
with the TP CH we are comparing the IBM

00:09:14,779 --> 00:09:21,290
power nine to the Dell PowerEdge as we

00:09:18,649 --> 00:09:26,450
can see loading time on the power nine

00:09:21,290 --> 00:09:29,630
is nearly twice as fast from the x86 so

00:09:26,450 --> 00:09:33,220
I think everybody can understand why we

00:09:29,630 --> 00:09:37,940
are going on a partnership with IBM

00:09:33,220 --> 00:09:42,500
query time also depends on the query and

00:09:37,940 --> 00:09:44,860
later on we'll see why but we got again

00:09:42,500 --> 00:09:48,860
and this is again comparing to the Dell

00:09:44,860 --> 00:09:53,690
PowerEdge we got between 100 and 50

00:09:48,860 --> 00:09:58,310
percent you know 370 percent faster of

00:09:53,690 --> 00:10:03,260
the query execution and this the query

00:09:58,310 --> 00:10:07,820
time is mainly enabled due to the anvil

00:10:03,260 --> 00:10:11,540
Inc bandwidth in order to apply the

00:10:07,820 --> 00:10:16,660
complex join operation group by and so

00:10:11,540 --> 00:10:16,660
on so how we do it

00:10:20,200 --> 00:10:26,660
few words about the process chain in

00:10:23,630 --> 00:10:30,980
screen we have the raw data we are

00:10:26,660 --> 00:10:33,470
columnar based database we are doing

00:10:30,980 --> 00:10:36,949
chunking will in a minute will go into

00:10:33,470 --> 00:10:38,240
each block in details we are doing

00:10:36,949 --> 00:10:41,779
chunking of the data

00:10:38,240 --> 00:10:45,740
chunking with new term that we are using

00:10:41,779 --> 00:10:52,970
which split the data and then gather the

00:10:45,740 --> 00:10:55,990
data back in an optimized manner so we

00:10:52,970 --> 00:10:59,240
could process it fast

00:10:55,990 --> 00:11:01,699
another nice patent we have is the

00:10:59,240 --> 00:11:05,510
automatic adaptive compression since we

00:11:01,699 --> 00:11:07,520
are columnar database we are able to to

00:11:05,510 --> 00:11:10,730
optimize the compress

00:11:07,520 --> 00:11:12,980
to the data and we are automatic

00:11:10,730 --> 00:11:16,580
choosing the right compression that

00:11:12,980 --> 00:11:20,440
enables fast query time based on the

00:11:16,580 --> 00:11:23,990
data then we are doing the data skipping

00:11:20,440 --> 00:11:28,540
the metadata tagging allow us actually

00:11:23,990 --> 00:11:33,050
the data skipping this is let's say a

00:11:28,540 --> 00:11:36,770
replacement for the indexing that most

00:11:33,050 --> 00:11:38,990
traditional database are having so we

00:11:36,770 --> 00:11:40,940
don't need to do the indexing we don't

00:11:38,990 --> 00:11:44,000
need to know in advance what the query

00:11:40,940 --> 00:11:46,790
we are going to read now that we have

00:11:44,000 --> 00:11:48,860
these small chunks that are only the

00:11:46,790 --> 00:11:52,280
relevant chunks that we would like to

00:11:48,860 --> 00:11:58,400
query we are pushing them into the GPU

00:11:52,280 --> 00:12:03,620
to apply the parallel processing so

00:11:58,400 --> 00:12:06,860
coronary that culinary database we have

00:12:03,620 --> 00:12:11,720
row based which is Postgres and all the

00:12:06,860 --> 00:12:14,630
rest columnar is good for analytics for

00:12:11,720 --> 00:12:18,250
aggregation it allows good compression

00:12:14,630 --> 00:12:20,600
of the data actually it allows more

00:12:18,250 --> 00:12:26,870
efficient compressive compression of the

00:12:20,600 --> 00:12:32,450
data the chunking operation this is done

00:12:26,870 --> 00:12:35,750
behind the scenes so we are partitioning

00:12:32,450 --> 00:12:39,020
the data into multiple dimension both on

00:12:35,750 --> 00:12:42,560
the size of the bulk of the data as well

00:12:39,020 --> 00:12:45,950
as the content of the data all of this

00:12:42,560 --> 00:12:48,680
is being done behind the scene during in

00:12:45,950 --> 00:12:53,270
this time now remember guys we don't

00:12:48,680 --> 00:12:55,520
have any indexing on the data so now we

00:12:53,270 --> 00:12:58,550
are tagging the data while we are

00:12:55,520 --> 00:13:01,250
loading it for each chunk we know

00:12:58,550 --> 00:13:05,690
distribution of the data we know all

00:13:01,250 --> 00:13:08,990
kind of metadata statistics which enable

00:13:05,690 --> 00:13:12,530
us to filter the data and get I call it

00:13:08,990 --> 00:13:15,640
just in time only the data we need at

00:13:12,530 --> 00:13:15,640
the moment we need it

00:13:18,750 --> 00:13:26,589
and this is the smart metadata access

00:13:24,180 --> 00:13:28,720
meaning for your question

00:13:26,589 --> 00:13:30,970
if we were doing full scan we will

00:13:28,720 --> 00:13:34,360
always need to go down to the disk and

00:13:30,970 --> 00:13:37,630
bring all the data again however we are

00:13:34,360 --> 00:13:41,250
not doing that and this is the Inga's

00:13:37,630 --> 00:13:45,730
time allows us to do that

00:13:41,250 --> 00:13:49,660
let's take example for these combination

00:13:45,730 --> 00:13:53,500
of the power nine Bienville ink and the

00:13:49,660 --> 00:13:59,940
nvidia gpus and white an able scrim to

00:13:53,500 --> 00:14:03,190
perform in such a manner so think about

00:13:59,940 --> 00:14:05,950
splitting the data versa gathering the

00:14:03,190 --> 00:14:10,149
data it's also connected to the question

00:14:05,950 --> 00:14:14,560
you asked the internal architecture of

00:14:10,149 --> 00:14:17,440
screen allows us to gather the data

00:14:14,560 --> 00:14:19,930
rather than split it if you think about

00:14:17,440 --> 00:14:23,110
splitting the data and passing through

00:14:19,930 --> 00:14:26,589
the PCI or the anvil Inc in our case

00:14:23,110 --> 00:14:30,760
chunk by chunk this is splitting the

00:14:26,589 --> 00:14:33,940
data if you think about moving a lot of

00:14:30,760 --> 00:14:38,130
chunks in parallel gathering them all

00:14:33,940 --> 00:14:42,130
into the GPU on only then performing the

00:14:38,130 --> 00:14:44,829
operation this is what allow us to to do

00:14:42,130 --> 00:14:47,290
the group by and join on the large data

00:14:44,829 --> 00:14:50,050
set this is why we are not bounded to

00:14:47,290 --> 00:14:52,180
the RAM so we are getting the most out

00:14:50,050 --> 00:14:55,029
of the Jairam since we are collecting

00:14:52,180 --> 00:14:57,850
the data we are loading it until we get

00:14:55,029 --> 00:15:00,040
into the maximum of the Jairam we are

00:14:57,850 --> 00:15:03,010
gathering all the information needed

00:15:00,040 --> 00:15:07,089
based on all the optimization we done on

00:15:03,010 --> 00:15:09,490
big chunks and of course in respect to

00:15:07,089 --> 00:15:11,860
the distribution of the data and all the

00:15:09,490 --> 00:15:14,529
metadata we collected and now we can

00:15:11,860 --> 00:15:21,550
control the movement of these chunks on

00:15:14,529 --> 00:15:23,470
the anvil Inc so basically this is what

00:15:21,550 --> 00:15:26,279
allows us this is why we did the

00:15:23,470 --> 00:15:29,110
partnership both with power 9 and video

00:15:26,279 --> 00:15:30,550
so I think one of one of the other

00:15:29,110 --> 00:15:31,810
things that we're doing here is we're

00:15:30,550 --> 00:15:33,399
optimizing between

00:15:31,810 --> 00:15:35,410
operations that need to be done on the

00:15:33,399 --> 00:15:38,170
CPU and on the GPU so we have an

00:15:35,410 --> 00:15:39,970
automatic mechanism as well that decides

00:15:38,170 --> 00:15:41,829
whether or not a particular operation

00:15:39,970 --> 00:15:43,959
should be done on the CPU or on the GPU

00:15:41,829 --> 00:15:45,939
as we know not everything should be done

00:15:43,959 --> 00:15:47,949
on the GPU because it's heavily geared

00:15:45,939 --> 00:15:49,959
to its parallel processing and some of

00:15:47,949 --> 00:15:52,180
the operations that we want to do will

00:15:49,959 --> 00:15:54,370
actually work better on the CPU so

00:15:52,180 --> 00:15:56,350
that's built in as well and all of the

00:15:54,370 --> 00:15:59,610
you know as I mentioned before all of

00:15:56,350 --> 00:16:02,259
the traditional column safeties of

00:15:59,610 --> 00:16:03,819
database and data warehouse that we've

00:16:02,259 --> 00:16:06,249
learned over the years this is something

00:16:03,819 --> 00:16:07,600
that we've got built into the product we

00:16:06,249 --> 00:16:09,910
have a couple of minutes left so I'd

00:16:07,600 --> 00:16:12,100
like to give you a couple of examples of

00:16:09,910 --> 00:16:15,610
customers that we've worked with now

00:16:12,100 --> 00:16:17,470
these case studies are not on the power

00:16:15,610 --> 00:16:18,699
nine okay they're not on the power nine

00:16:17,470 --> 00:16:20,589
simply because we announced the

00:16:18,699 --> 00:16:23,709
availability of the power nine yesterday

00:16:20,589 --> 00:16:25,180
okay but and as I yeah that showed you

00:16:23,709 --> 00:16:28,449
the testing that we've done the ingest

00:16:25,180 --> 00:16:30,189
is much quicker and the time to query is

00:16:28,449 --> 00:16:33,519
much quicker using the power nine based

00:16:30,189 --> 00:16:36,910
on the testing that we did with x86 with

00:16:33,519 --> 00:16:42,579
similar GPU configuration so this is a

00:16:36,910 --> 00:16:44,920
company actually in in Thailand one of

00:16:42,579 --> 00:16:48,490
the largest cell operators in Thailand

00:16:44,920 --> 00:16:53,009
okay so they were running greenplum they

00:16:48,490 --> 00:16:57,610
had they had 40 nodes five full racks

00:16:53,009 --> 00:16:59,319
they had ingest time of 200 seconds that

00:16:57,610 --> 00:17:02,170
we brought down to 18 seconds

00:16:59,319 --> 00:17:05,380
they had reporting time of what is it

00:17:02,170 --> 00:17:08,409
six six hours it looks like we brought

00:17:05,380 --> 00:17:10,630
that down to 46 seconds they had

00:17:08,409 --> 00:17:11,740
ownership cost of over 10 million

00:17:10,630 --> 00:17:13,600
dollars and we were able to bring that

00:17:11,740 --> 00:17:16,329
down to half a million dollars so this

00:17:13,600 --> 00:17:18,909
is an actual up and running use case you

00:17:16,329 --> 00:17:21,309
know I know we we don't like giving

00:17:18,909 --> 00:17:22,839
stories so we basically you know get

00:17:21,309 --> 00:17:26,110
permission from our customers and and

00:17:22,839 --> 00:17:28,360
this was one of them another customer

00:17:26,110 --> 00:17:30,809
actually in the West Coast in the United

00:17:28,360 --> 00:17:32,950
States one of the largest ad Tech's so

00:17:30,809 --> 00:17:34,419
there's a very interesting one because

00:17:32,950 --> 00:17:36,820
it's something that we're running into a

00:17:34,419 --> 00:17:41,169
lot so you can see they were doing 85

00:17:36,820 --> 00:17:42,640
terabytes a day of data and what they

00:17:41,169 --> 00:17:44,679
were looking to do was to be able to

00:17:42,640 --> 00:17:44,880
construct their histograms better so

00:17:44,679 --> 00:17:47,210
that

00:17:44,880 --> 00:17:49,830
they can get more ad revenue coming out

00:17:47,210 --> 00:17:52,590
you can see here that they have Hadoop

00:17:49,830 --> 00:17:55,050
as the primarily well it's become there

00:17:52,590 --> 00:17:57,600
in main data lake they were taking out

00:17:55,050 --> 00:18:00,630
data from there into HBase Phoenix and

00:17:57,600 --> 00:18:03,270
the queries were taking five hours so we

00:18:00,630 --> 00:18:04,590
replaced that with two and Vidia Tesla

00:18:03,270 --> 00:18:07,290
GPUs we replace their current

00:18:04,590 --> 00:18:10,380
installation we did the data ingest into

00:18:07,290 --> 00:18:13,320
scream and they were able to reduce the

00:18:10,380 --> 00:18:14,640
query time to five minutes now this is a

00:18:13,320 --> 00:18:15,930
great example a dupe because we're

00:18:14,640 --> 00:18:20,340
working more and more with companies

00:18:15,930 --> 00:18:23,270
that they started out with very small

00:18:20,340 --> 00:18:25,200
installations of dupe and as this

00:18:23,270 --> 00:18:27,300
exponentially growing data has come into

00:18:25,200 --> 00:18:28,770
the organization they're they're the

00:18:27,300 --> 00:18:30,180
nodes the amount of nodes that they have

00:18:28,770 --> 00:18:32,910
that they have to support of Hadoop has

00:18:30,180 --> 00:18:34,050
grown to the point that you know one of

00:18:32,910 --> 00:18:37,470
the companies we're dealing with right

00:18:34,050 --> 00:18:38,790
now has about 250 notes of Hadoop and

00:18:37,470 --> 00:18:41,160
they're really drowning and they're

00:18:38,790 --> 00:18:43,140
struggling how to how to support that

00:18:41,160 --> 00:18:44,640
and from what I was talking to a couple

00:18:43,140 --> 00:18:46,440
of the IBM who's here they told me that

00:18:44,640 --> 00:18:49,640
it's very similar in enterprises here in

00:18:46,440 --> 00:18:53,760
Europe that there's a similar situation

00:18:49,640 --> 00:18:55,290
so this was 86 terabytes a day now they

00:18:53,760 --> 00:18:57,390
wanted to expand the amount of data that

00:18:55,290 --> 00:18:59,370
they were querying that they were

00:18:57,390 --> 00:19:01,110
analyzing because that would help them

00:18:59,370 --> 00:19:02,600
to build better histograms so they

00:19:01,110 --> 00:19:06,180
actually went up to three hundred and

00:19:02,600 --> 00:19:08,100
sixty terabytes a day that they're now

00:19:06,180 --> 00:19:09,600
ingesting and the only difference was

00:19:08,100 --> 00:19:13,470
that that we increase the amount of

00:19:09,600 --> 00:19:14,550
Nvidia Tesla's from two to eight but

00:19:13,470 --> 00:19:15,750
they're still getting the same five

00:19:14,550 --> 00:19:17,240
minute response time and this is

00:19:15,750 --> 00:19:19,950
something that wasn't even feasible

00:19:17,240 --> 00:19:22,560
previously with the system that they had

00:19:19,950 --> 00:19:24,470
in place so there's no question you know

00:19:22,560 --> 00:19:27,600
like that we call it the Trinity of

00:19:24,470 --> 00:19:29,820
power 9 together with the NVIDIA GPUs

00:19:27,600 --> 00:19:31,940
together was scream that we're able to

00:19:29,820 --> 00:19:34,740
really tackle these challenges of

00:19:31,940 --> 00:19:36,900
extreme amounts of data extreme amounts

00:19:34,740 --> 00:19:39,840
of growing data and the amount of time

00:19:36,900 --> 00:19:42,330
it takes to query that data so I welcome

00:19:39,840 --> 00:19:43,740
you all to you know to speak to us after

00:19:42,330 --> 00:19:45,150
the session

00:19:43,740 --> 00:19:48,120
yeah just finish this and I'll take

00:19:45,150 --> 00:19:49,920
questions so just you know from who we

00:19:48,120 --> 00:19:53,400
are point of view we were founded back

00:19:49,920 --> 00:19:55,350
in 2010 we've gone through actually a

00:19:53,400 --> 00:19:56,910
few years of R&D to get this product to

00:19:55,350 --> 00:19:58,560
the point where it is today that you can

00:19:56,910 --> 00:19:59,670
see that you know the results being

00:19:58,560 --> 00:20:01,920
given

00:19:59,670 --> 00:20:04,800
the companies that we showed here are

00:20:01,920 --> 00:20:06,240
making significant business decisions

00:20:04,800 --> 00:20:07,770
and changes to how they're doing

00:20:06,240 --> 00:20:09,630
business based on the data and the

00:20:07,770 --> 00:20:11,370
additional data that they can have so

00:20:09,630 --> 00:20:14,190
it's really driving business change and

00:20:11,370 --> 00:20:17,070
which is you know obviously an important

00:20:14,190 --> 00:20:19,830
part of what we're doing so we've got 60

00:20:17,070 --> 00:20:22,230
plus employees we've got ten patents we

00:20:19,830 --> 00:20:25,710
signed a very strategic partnership with

00:20:22,230 --> 00:20:27,270
Alibaba cloud back in in May actually in

00:20:25,710 --> 00:20:29,010
in February and then again in May and

00:20:27,270 --> 00:20:32,220
May in February we announced that Ali

00:20:29,010 --> 00:20:37,470
Baba will be actually selling scream on

00:20:32,220 --> 00:20:39,510
their cloud in China so the it's similar

00:20:37,470 --> 00:20:42,480
situation that you have between Amazon

00:20:39,510 --> 00:20:44,400
and redshift but they don't own us but

00:20:42,480 --> 00:20:45,810
then they invested in us in May so

00:20:44,400 --> 00:20:48,720
actually they're one of our big

00:20:45,810 --> 00:20:50,190
investors as well so we've got um you

00:20:48,720 --> 00:20:52,080
know one of the fastest growing cloud

00:20:50,190 --> 00:20:54,780
providers as our you can call it our

00:20:52,080 --> 00:20:56,190
backing we have our headquarters in the

00:20:54,780 --> 00:20:58,620
number seven World Trade Center in New

00:20:56,190 --> 00:21:00,210
York and we just moved into a nice

00:20:58,620 --> 00:21:02,340
facility overlooking the Mediterranean

00:21:00,210 --> 00:21:07,020
in tel-aviv and anybody who comes as

00:21:02,340 --> 00:21:09,510
welcome to a 360-degree view of the

00:21:07,020 --> 00:21:12,630
country and I think you've been actually

00:21:09,510 --> 00:21:14,910
and you can vouch for that so we welcome

00:21:12,630 --> 00:21:16,570
you know welcome to see you thank you

00:21:14,910 --> 00:21:20,859
very much

00:21:16,570 --> 00:21:20,859

YouTube URL: https://www.youtube.com/watch?v=H5uHvfUZ7C8


