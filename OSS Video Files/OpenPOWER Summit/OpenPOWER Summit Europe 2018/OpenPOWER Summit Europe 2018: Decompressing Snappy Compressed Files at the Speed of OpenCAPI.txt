Title: OpenPOWER Summit Europe 2018: Decompressing Snappy Compressed Files at the Speed of OpenCAPI
Publication date: 2019-02-07
Playlist: OpenPOWER Summit Europe 2018
Description: 
	Jian Fang, TU Delft, speaks at OpenPOWER Summit Europe 2018.

For more information, please visit: https://openpowerfoundation.org/summit-2018-10-eu/
Captions: 
	00:00:00,869 --> 00:00:09,600
so I might give a introduction for

00:00:04,680 --> 00:00:13,740
myself I'm Jen from cue doubt I am a PhD

00:00:09,600 --> 00:00:17,280
student and working on the database s

00:00:13,740 --> 00:00:21,539
aeration using FPGAs and today I'm going

00:00:17,280 --> 00:00:26,630
to show you an application of the open

00:00:21,539 --> 00:00:31,129
copy which is the database s aeration so

00:00:26,630 --> 00:00:35,160
let me start from our current projects

00:00:31,129 --> 00:00:37,710
we are going to make a heterogeneous

00:00:35,160 --> 00:00:42,149
database that can you may use of the

00:00:37,710 --> 00:00:46,440
FPGA so let's assume we have many

00:00:42,149 --> 00:00:51,570
applications running on top of the CPU

00:00:46,440 --> 00:00:55,050
which would be the power knife and when

00:00:51,570 --> 00:00:59,760
you have some queries you need to map

00:00:55,050 --> 00:01:02,969
the SQL down and then we go to the

00:00:59,760 --> 00:01:06,170
storage to fetch the data and we would

00:01:02,969 --> 00:01:10,799
like to store the data in an mm VMI's

00:01:06,170 --> 00:01:14,700
storage device and go to the an FPGA

00:01:10,799 --> 00:01:19,859
that performed the become compressed

00:01:14,700 --> 00:01:25,409
filtering and also we have this Fletcher

00:01:19,859 --> 00:01:30,149
framework which is from your hump Alban

00:01:25,409 --> 00:01:34,759
Berg and this one can help you to write

00:01:30,149 --> 00:01:43,380
the table in Apache arrow format and

00:01:34,759 --> 00:01:46,020
from the data processing side we add

00:01:43,380 --> 00:01:49,109
another FPGA to do the data processing

00:01:46,020 --> 00:01:52,859
or you can also merge these two a

00:01:49,109 --> 00:01:57,329
feature into one and we also use the

00:01:52,859 --> 00:02:01,999
fracture fracture framework and but for

00:01:57,329 --> 00:02:05,789
this part we use the read to read the

00:02:01,999 --> 00:02:13,500
tables from the share memory and we

00:02:05,789 --> 00:02:14,310
performs the actions in the in the FPGA

00:02:13,500 --> 00:02:18,780
we

00:02:14,310 --> 00:02:23,160
do some sort John skylight etc and risk

00:02:18,780 --> 00:02:30,360
this arrow table you can also upload

00:02:23,160 --> 00:02:33,870
your of loader tasks into the GPU and

00:02:30,360 --> 00:02:38,370
this one we also take advantage of the

00:02:33,870 --> 00:02:41,810
arrow table to help you to avoid the

00:02:38,370 --> 00:02:46,200
serialization and this year this year

00:02:41,810 --> 00:02:49,830
realization and we are going to make a

00:02:46,200 --> 00:02:53,940
scalable heterogeneous as a radiated

00:02:49,830 --> 00:03:00,620
database and we haven't given name about

00:02:53,940 --> 00:03:05,150
this project maybe we just go eight so

00:03:00,620 --> 00:03:10,230
today our presentation will focus on the

00:03:05,150 --> 00:03:15,930
compress a future part which is funny

00:03:10,230 --> 00:03:19,790
here and the motivation is in nowadays

00:03:15,930 --> 00:03:22,799
in the big data processing data

00:03:19,790 --> 00:03:28,109
analytics applications there are many

00:03:22,799 --> 00:03:32,180
many data intensive tasks such as swords

00:03:28,109 --> 00:03:37,049
George partitioning filtering

00:03:32,180 --> 00:03:42,030
aggregation histogram may be data

00:03:37,049 --> 00:03:45,959
reformat and a very common feature from

00:03:42,030 --> 00:03:48,930
these among these tasks is they have a

00:03:45,959 --> 00:03:52,340
lot of data movement you need to move

00:03:48,930 --> 00:03:56,579
the data from the storage to the CPU

00:03:52,340 --> 00:04:01,049
from the CPU to the network or from the

00:03:56,579 --> 00:04:04,230
network back to the memory so if the

00:04:01,049 --> 00:04:07,829
data amount is really large these will

00:04:04,230 --> 00:04:12,959
become a bottleneck especially when your

00:04:07,829 --> 00:04:15,420
data comes from the storage and you have

00:04:12,959 --> 00:04:19,859
to face the fact that even though you

00:04:15,420 --> 00:04:22,380
can put your database in the memory you

00:04:19,859 --> 00:04:26,750
can now avoid the first step which is

00:04:22,380 --> 00:04:26,750
fetching the data from the storage

00:04:26,760 --> 00:04:39,630
so - to solve this problem we have

00:04:35,630 --> 00:04:43,590
explored some solutions one of them is

00:04:39,630 --> 00:04:46,530
to use the compressed filtering so the

00:04:43,590 --> 00:04:48,960
same architecture in between the storage

00:04:46,530 --> 00:04:51,770
and the host we put an FPGA and

00:04:48,960 --> 00:04:55,740
performed the compressed filter and

00:04:51,770 --> 00:04:59,430
instead of storing the original data in

00:04:55,740 --> 00:05:03,600
the storage we are now storing the

00:04:59,430 --> 00:05:08,090
compress the data so the data among will

00:05:03,600 --> 00:05:11,550
be much less than the original one so

00:05:08,090 --> 00:05:17,730
now when your CPU need to fetch it a

00:05:11,550 --> 00:05:20,660
bunch of data you

00:05:17,730 --> 00:05:23,610
you only need to move a small amount

00:05:20,660 --> 00:05:26,400
compressed data and do the compaction

00:05:23,610 --> 00:05:31,980
inside the FPGA and then to the

00:05:26,400 --> 00:05:37,680
filtering and and then forward this

00:05:31,980 --> 00:05:42,240
filtered data to the host and this this

00:05:37,680 --> 00:05:49,760
idea has been proved by net Azad a

00:05:42,240 --> 00:05:52,050
couple of years ago and there are more

00:05:49,760 --> 00:05:55,680
compassion and the contraction algorithm

00:05:52,050 --> 00:06:00,210
have been improvement in the FPGA

00:05:55,680 --> 00:06:04,500
already so these days I has been asked

00:06:00,210 --> 00:06:08,040
some questions well why are you still

00:06:04,500 --> 00:06:12,630
doing something others has been finished

00:06:08,040 --> 00:06:16,350
a couple of years ago so similarly

00:06:12,630 --> 00:06:18,750
christian or and simple answer is we are

00:06:16,350 --> 00:06:24,450
doing something else or missing here we

00:06:18,750 --> 00:06:28,950
do the snappy detection and snappy is a

00:06:24,450 --> 00:06:32,670
new the compression algorithm you widely

00:06:28,950 --> 00:06:36,740
use in the potato systems and it's the

00:06:32,670 --> 00:06:36,740
post package or a seed

00:06:38,639 --> 00:06:46,409
that that that's why we still need the

00:06:41,699 --> 00:06:50,639
compression but another critical

00:06:46,409 --> 00:06:55,020
question is so now we have the open KP

00:06:50,639 --> 00:06:58,349
as much it has much larger boundaries

00:06:55,020 --> 00:07:02,759
why you still need to compress your data

00:06:58,349 --> 00:07:07,949
why not just forward original data so I

00:07:02,759 --> 00:07:12,900
would say you can still save the storage

00:07:07,949 --> 00:07:15,060
space if you have two times compression

00:07:12,900 --> 00:07:18,689
ratio then you can save half of the

00:07:15,060 --> 00:07:24,930
space and you can store twice as much

00:07:18,689 --> 00:07:26,520
data as you can right and more a further

00:07:24,930 --> 00:07:31,680
answer will sorry

00:07:26,520 --> 00:07:36,930
a further answer will be actually 25 gig

00:07:31,680 --> 00:07:42,509
speech is not enough so people are or um

00:07:36,930 --> 00:07:45,150
I always credit when you have KP one you

00:07:42,509 --> 00:07:47,909
said a gig is just not enough

00:07:45,150 --> 00:07:52,469
we won more than we have capital so we

00:07:47,909 --> 00:07:55,289
we have 16 gig now and then we say we

00:07:52,469 --> 00:07:59,610
are not in that's not enough so we have

00:07:55,289 --> 00:08:04,430
open capi now that's 25 gig

00:07:59,610 --> 00:08:10,069
I actually I want to steal a slice from

00:08:04,430 --> 00:08:14,789
my own but I haven't bought any any well

00:08:10,069 --> 00:08:21,979
it shows the power of empower Rome at

00:08:14,789 --> 00:08:25,770
and in 2020 plus they will have open

00:08:21,979 --> 00:08:31,370
power time plus KP 5 or something and

00:08:25,770 --> 00:08:36,930
provide you a 50 get so actually we are

00:08:31,370 --> 00:08:43,800
we always asking more boundaries so in

00:08:36,930 --> 00:08:46,470
our architecture we can give you let's

00:08:43,800 --> 00:08:50,670
say we can amplify these boundaries so

00:08:46,470 --> 00:08:53,520
if your compression ratio can reach 2

00:08:50,670 --> 00:08:56,880
and you can decompressed

00:08:53,520 --> 00:09:00,180
data as fast as you can then you can get

00:08:56,880 --> 00:09:04,560
twice as much of spanner ease so in open

00:09:00,180 --> 00:09:11,580
cap it you actually you can have 50 gig

00:09:04,560 --> 00:09:15,660
and when then you don't need to wait as

00:09:11,580 --> 00:09:20,250
three years later to until IBM published

00:09:15,660 --> 00:09:23,640
the 50 gig and when IBM have this 50

00:09:20,250 --> 00:09:27,750
kick available you can have 100 gig

00:09:23,640 --> 00:09:35,430
that means you are always as a one

00:09:27,750 --> 00:09:39,810
generation ahead of the world so what is

00:09:35,430 --> 00:09:44,490
snappy snappy is compression algorithm

00:09:39,810 --> 00:09:49,470
open sourced by Google more than ten

00:09:44,490 --> 00:09:56,550
years ago and it's lz77 based by level

00:09:49,470 --> 00:09:59,700
and its loss list it's widely used in

00:09:56,550 --> 00:10:04,200
many big data systems platforms and

00:09:59,700 --> 00:10:08,310
support packet and was it and it has

00:10:04,200 --> 00:10:15,710
lower compression ratio but the thus be

00:10:08,310 --> 00:10:20,850
is fast and this number from the snappy

00:10:15,710 --> 00:10:24,900
official website they give 500 megabyte

00:10:20,850 --> 00:10:30,990
per seconds the compactions throughput

00:10:24,900 --> 00:10:37,380
from one code and that's not enough

00:10:30,990 --> 00:10:42,089
because we have 25 gig so our goal is to

00:10:37,380 --> 00:10:49,710
have open kappa speed the compression

00:10:42,089 --> 00:10:53,810
ratio inside fpga so the following

00:10:49,710 --> 00:10:59,220
slides we will be some details about the

00:10:53,810 --> 00:11:00,900
snappy complexion and snappy the

00:10:59,220 --> 00:11:03,270
compaction compression and the

00:11:00,900 --> 00:11:06,300
compression algorithm is actually a very

00:11:03,270 --> 00:11:08,760
simple algorithm it just

00:11:06,300 --> 00:11:12,800
the repeated sequential from the

00:11:08,760 --> 00:11:17,190
previous one so for example we have this

00:11:12,800 --> 00:11:24,780
sequence ABCD EFG H and then we file and

00:11:17,190 --> 00:11:29,360
repeat ABCD so now we use this tuple a

00:11:24,780 --> 00:11:34,320
for to to replace this then we can

00:11:29,360 --> 00:11:38,330
stream the data amount so for those is

00:11:34,320 --> 00:11:42,810
not in the we can now file a repeated

00:11:38,330 --> 00:11:49,290
sequence we just keep its original data

00:11:42,810 --> 00:11:54,170
so we call this the literal token so the

00:11:49,290 --> 00:12:05,370
the compaction process is like this so

00:11:54,170 --> 00:12:08,070
the daughter doc means some previews the

00:12:05,370 --> 00:12:12,390
previous screen show is here and when

00:12:08,070 --> 00:12:15,740
you read a B C D F a gh and you cannot

00:12:12,390 --> 00:12:20,250
find any match before so you create a

00:12:15,740 --> 00:12:23,600
little token and then you keep keep on

00:12:20,250 --> 00:12:28,460
fighting a match so you found another

00:12:23,600 --> 00:12:32,430
ABCD then your file match here and

00:12:28,460 --> 00:12:34,880
that's a copy token so we we are now

00:12:32,430 --> 00:12:38,190
using this little token

00:12:34,880 --> 00:12:45,630
copy token to replace the original data

00:12:38,190 --> 00:12:49,950
and the connection is reverse process so

00:12:45,630 --> 00:12:54,480
now the data you read is token by token

00:12:49,950 --> 00:12:57,960
and photos literal token when you when

00:12:54,480 --> 00:13:03,300
you read it you you only need to read

00:12:57,960 --> 00:13:08,670
the original data and for for those copy

00:13:03,300 --> 00:13:13,050
tokens you go back with this index files

00:13:08,670 --> 00:13:18,900
sorry a step before and for length of

00:13:13,050 --> 00:13:20,279
410 copy this into added into the end so

00:13:18,900 --> 00:13:23,399
by this process

00:13:20,279 --> 00:13:29,639
you can be compassed all the the whole

00:13:23,399 --> 00:13:33,029
streams so there are some details about

00:13:29,639 --> 00:13:39,740
the snappy conversion and the commercial

00:13:33,029 --> 00:13:43,680
algorithm and as we see there are some

00:13:39,740 --> 00:13:48,269
something miss here which is the history

00:13:43,680 --> 00:13:53,040
so you always need to fight back to the

00:13:48,269 --> 00:13:59,449
history to find repeat sequence so the

00:13:53,040 --> 00:14:02,389
the setting of the snappy is 64k by and

00:13:59,449 --> 00:14:09,360
if I don't know whether you are familiar

00:14:02,389 --> 00:14:12,209
with lz77 that's a slight window the

00:14:09,360 --> 00:14:15,839
history is a slight window but in snappy

00:14:12,209 --> 00:14:19,620
here it's a fist window so when you

00:14:15,839 --> 00:14:22,999
finish with the construction of the

00:14:19,620 --> 00:14:26,189
history that means you finishes this

00:14:22,999 --> 00:14:33,360
block of data the connection then you

00:14:26,189 --> 00:14:36,750
start a new 64k blocks so the token the

00:14:33,360 --> 00:14:40,709
token there are two tokens copies and

00:14:36,750 --> 00:14:44,699
literals the the data both now is see

00:14:40,709 --> 00:14:48,750
the sixteen for by and we also did some

00:14:44,699 --> 00:14:51,930
calculation on the size of the token the

00:14:48,750 --> 00:14:57,379
token size will be varies some tokens to

00:14:51,930 --> 00:15:01,199
buy some stree by sums for buys so and

00:14:57,379 --> 00:15:04,679
for the little rows if we count the the

00:15:01,199 --> 00:15:07,889
size of the original data then the size

00:15:04,679 --> 00:15:11,399
of the Tagum will be much larger so the

00:15:07,889 --> 00:15:17,189
average here is a little bit less than

00:15:11,399 --> 00:15:21,709
for from a couple of benchmark and the

00:15:17,189 --> 00:15:21,709
data is very highly depend sorry

00:15:22,519 --> 00:15:35,420
dependent that means the token one token

00:15:27,689 --> 00:15:35,420
need to read the data that from the last

00:15:36,230 --> 00:15:49,519
so in FPGA design we we want to store

00:15:46,740 --> 00:15:51,259
the history in the B Ram Babu Ram is

00:15:49,519 --> 00:15:55,410
block-by-block

00:15:51,259 --> 00:15:59,790
so you cannot use small granularity the

00:15:55,410 --> 00:16:04,199
the the smallest one is for 4k 4k by so

00:15:59,790 --> 00:16:10,170
we need 16 of those to construct a

00:16:04,199 --> 00:16:15,769
history buffer so during this design we

00:16:10,170 --> 00:16:18,629
faced many challenges and this for other

00:16:15,769 --> 00:16:21,509
let's say the most important one so

00:16:18,629 --> 00:16:24,360
first of all you need to deal with a

00:16:21,509 --> 00:16:27,000
different type of token for literal

00:16:24,360 --> 00:16:30,389
token you only need to write your data

00:16:27,000 --> 00:16:32,579
in the history but for those copy token

00:16:30,389 --> 00:16:36,569
you need to read from the history first

00:16:32,579 --> 00:16:39,089
and then write back and for the the

00:16:36,569 --> 00:16:42,809
other one is you need to do with this

00:16:39,089 --> 00:16:47,759
very size of the token so for little

00:16:42,809 --> 00:16:52,350
root tokens they have three three types

00:16:47,759 --> 00:16:56,490
of constructions these represent

00:16:52,350 --> 00:16:59,689
different size of the little road for

00:16:56,490 --> 00:17:02,699
small one you only need a two by four

00:16:59,689 --> 00:17:04,890
large one you need a medium one you need

00:17:02,699 --> 00:17:08,939
three by some larger one you need four

00:17:04,890 --> 00:17:12,689
bytes and for copy is similar and when

00:17:08,939 --> 00:17:17,000
you need to copy the data from the near

00:17:12,689 --> 00:17:20,400
part then you you you have small offset

00:17:17,000 --> 00:17:22,829
that I mean the index and if you need to

00:17:20,400 --> 00:17:26,850
copy data from very fast

00:17:22,829 --> 00:17:33,450
sorry very far then you need to you need

00:17:26,850 --> 00:17:40,049
long bar to indicate in this so this is

00:17:33,450 --> 00:17:43,230
the size of the token and when you have

00:17:40,049 --> 00:17:46,440
very size of the token that means you

00:17:43,230 --> 00:17:47,670
it's hard for you to recognize which one

00:17:46,440 --> 00:17:50,960
is the token you can

00:17:47,670 --> 00:17:54,690
now said I cut it - bye - bye - bye and

00:17:50,960 --> 00:17:58,770
do a translation in a in the same cycle

00:17:54,690 --> 00:18:00,990
it's impossible because it's varies you

00:17:58,770 --> 00:18:05,940
you don't know where the next token stop

00:18:00,990 --> 00:18:07,490
before you recognize the first token and

00:18:05,940 --> 00:18:11,940
[Applause]

00:18:07,490 --> 00:18:15,180
but in FPGA we can do this in parallel

00:18:11,940 --> 00:18:19,080
so we just it is pros all the

00:18:15,180 --> 00:18:23,730
possibility so for example if we grab an

00:18:19,080 --> 00:18:29,250
a by ly it's possible that every token

00:18:23,730 --> 00:18:33,230
stuff wrong everybody so we just assume

00:18:29,250 --> 00:18:41,090
that all device are a start of the token

00:18:33,230 --> 00:18:45,570
so at the end when we have the first by

00:18:41,090 --> 00:18:52,620
the first boundary decide we can note

00:18:45,570 --> 00:18:57,780
which is our correct choice so by this

00:18:52,620 --> 00:19:04,800
matter we can let's say recognize the

00:18:57,780 --> 00:19:12,210
token boundary in every every cycle we

00:19:04,800 --> 00:19:16,640
can recognize a whole whole life and the

00:19:12,210 --> 00:19:20,250
most important one is how to parallel

00:19:16,640 --> 00:19:27,620
parallel lies this token translation and

00:19:20,250 --> 00:19:33,360
how yeah so if you want to translate

00:19:27,620 --> 00:19:36,750
token into the data itself you need a

00:19:33,360 --> 00:19:38,760
read from the history and right back to

00:19:36,750 --> 00:19:44,160
the history or you don't need a read

00:19:38,760 --> 00:19:46,740
just right so if you want to execute a

00:19:44,160 --> 00:19:50,670
multiple token in a same time then you

00:19:46,740 --> 00:19:55,080
need to solve this dependency so let's

00:19:50,670 --> 00:19:58,590
say token 1 & 2 in issue in the same

00:19:55,080 --> 00:20:02,130
cycle and token 3 M 4 issue the next

00:19:58,590 --> 00:20:08,640
cycle so what we need to do is is

00:20:02,130 --> 00:20:13,650
this re and right dependency so for we

00:20:08,640 --> 00:20:16,350
and read there is no dependency because

00:20:13,650 --> 00:20:21,950
you don't need to change detail and for

00:20:16,350 --> 00:20:25,140
right we felt that it never has

00:20:21,950 --> 00:20:28,799
dependents if it costs you almost sorry

00:20:25,140 --> 00:20:31,679
you always add changed the token

00:20:28,799 --> 00:20:36,720
translation I mean the data at the end

00:20:31,679 --> 00:20:40,770
of the history so you never write a same

00:20:36,720 --> 00:20:43,830
bye-bye to to token and for those write

00:20:40,770 --> 00:20:48,929
and read you can just for forward to in

00:20:43,830 --> 00:20:52,350
forwarding it seems that there is no

00:20:48,929 --> 00:20:54,299
dependency here but in everyday these

00:20:52,350 --> 00:20:57,900
things are difference because the

00:20:54,299 --> 00:21:02,070
history is still in the BRM and the BM

00:20:57,900 --> 00:21:07,710
only offer you one report and one report

00:21:02,070 --> 00:21:12,390
so when you need to write when 2 tokens

00:21:07,710 --> 00:21:17,400
right same blocks then you have the

00:21:12,390 --> 00:21:23,520
address conflict for this write and

00:21:17,400 --> 00:21:26,250
write it the first write may hit the

00:21:23,520 --> 00:21:30,740
second write in the same block for this

00:21:26,250 --> 00:21:37,130
we can use the right combination or

00:21:30,740 --> 00:21:42,390
combination right and before this one

00:21:37,130 --> 00:21:46,169
when you when you need to write

00:21:42,390 --> 00:21:50,450
different life in the same theorem block

00:21:46,169 --> 00:21:56,159
you cannot finish it in one cycle right

00:21:50,450 --> 00:22:00,570
so for this one you have to stop these

00:21:56,159 --> 00:22:02,669
two tokens maybe let the first one to

00:22:00,570 --> 00:22:08,429
the right and then let the second one to

00:22:02,669 --> 00:22:13,530
the right and a the re-entry now becomes

00:22:08,429 --> 00:22:16,710
a problem because

00:22:13,530 --> 00:22:18,299
the rear and only you when you read the

00:22:16,710 --> 00:22:19,110
data from the history you don't know

00:22:18,299 --> 00:22:24,750
where it is

00:22:19,110 --> 00:22:29,039
so we did some statistic that most of

00:22:24,750 --> 00:22:32,730
the address and token will get a

00:22:29,039 --> 00:22:35,760
conflict on the address from the read so

00:22:32,730 --> 00:22:39,360
for this one you I would say you have to

00:22:35,760 --> 00:22:44,909
stop one token translation until the

00:22:39,360 --> 00:22:50,360
first voice down so we have talked about

00:22:44,909 --> 00:22:54,419
putting to history but that's not very

00:22:50,360 --> 00:22:57,330
scalable because if you want to have

00:22:54,419 --> 00:23:04,789
more token translate in a same cycle

00:22:57,330 --> 00:23:08,789
then you need more history duplicate so

00:23:04,789 --> 00:23:12,750
it seems that there is no solution

00:23:08,789 --> 00:23:15,690
and if you want to key at least the open

00:23:12,750 --> 00:23:19,520
copy boundaries then we do some

00:23:15,690 --> 00:23:27,000
calculation already so you need 13

00:23:19,520 --> 00:23:31,700
instance two and the frequency to reach

00:23:27,000 --> 00:23:35,990
250 megahertz to to consume the whole

00:23:31,700 --> 00:23:37,620
open copy boundaries and this is

00:23:35,990 --> 00:23:41,880
impossible

00:23:37,620 --> 00:23:50,940
if we try in the latest epic a that

00:23:41,880 --> 00:23:55,200
kayuu 37 p it's it's impossible so we

00:23:50,940 --> 00:24:02,789
try to find another solution and our

00:23:55,200 --> 00:24:06,419
idea is very simple so we have the first

00:24:02,789 --> 00:24:10,679
one is the real complete so we can see

00:24:06,419 --> 00:24:13,679
that the conflict only occurs in the

00:24:10,679 --> 00:24:18,179
middle two blocks not the first one and

00:24:13,679 --> 00:24:21,150
the second one and also this right it

00:24:18,179 --> 00:24:24,419
only occurs in one beer and block not

00:24:21,150 --> 00:24:29,120
the rest so why not just let the rest to

00:24:24,419 --> 00:24:29,120
themselves and just block this

00:24:29,480 --> 00:24:42,509
so so now we have finer granularity one

00:24:37,200 --> 00:24:54,570
to do this translation so we propose

00:24:42,509 --> 00:24:58,259
this architecture so the three key ten

00:24:54,570 --> 00:25:01,440
technique from our architecture is first

00:24:58,259 --> 00:25:04,889
we need to do a two-level puzzles so

00:25:01,440 --> 00:25:07,710
first of all we need to recognize the

00:25:04,889 --> 00:25:11,940
token boundary and token information

00:25:07,710 --> 00:25:17,509
from the the from a couple of pies let's

00:25:11,940 --> 00:25:23,999
say 16 bytes then we need to chanced

00:25:17,509 --> 00:25:25,369
translate these token into beer M into P

00:25:23,999 --> 00:25:28,950
RM command

00:25:25,369 --> 00:25:31,700
so for example if you have a token

00:25:28,950 --> 00:25:36,259
writing these three beer and brats you

00:25:31,700 --> 00:25:39,809
you are getting three beer and commands

00:25:36,259 --> 00:25:45,029
so the second one is to parallelized

00:25:39,809 --> 00:25:51,989
beer and operations so we specified 16

00:25:45,029 --> 00:25:57,600
of these p.m. set and also we put the 16

00:25:51,989 --> 00:26:03,239
independent control objects around this

00:25:57,600 --> 00:26:06,809
p.m. and we have relaxed execution model

00:26:03,239 --> 00:26:12,529
so I will explain these two in us in the

00:26:06,809 --> 00:26:16,249
same slide so for for the literal

00:26:12,529 --> 00:26:19,470
literal token you you actually get a

00:26:16,249 --> 00:26:24,840
recommend and for those copy token you

00:26:19,470 --> 00:26:31,350
have a read and a write so the right

00:26:24,840 --> 00:26:34,470
always successful but for those read it

00:26:31,350 --> 00:26:40,289
it's possible that the data is not there

00:26:34,470 --> 00:26:41,020
yet so for those not ready want we just

00:26:40,289 --> 00:26:45,130
let it

00:26:41,020 --> 00:26:50,520
ooh back we don't we don't start them we

00:26:45,130 --> 00:26:54,910
don't block just use a recycle file and

00:26:50,520 --> 00:27:01,410
put it in a queue and wait for the next

00:26:54,910 --> 00:27:04,690
round execution we we have some

00:27:01,410 --> 00:27:09,610
implementation results based on the ko

00:27:04,690 --> 00:27:13,230
15 P so the most resource consumed is

00:27:09,610 --> 00:27:18,060
the locked it tastes almost 9 percent of

00:27:13,230 --> 00:27:22,680
in one affiliate and we do some

00:27:18,060 --> 00:27:26,890
benchmark we compare the official

00:27:22,680 --> 00:27:29,800
benchmark from the snappy we get a sorry

00:27:26,890 --> 00:27:33,330
a 5 gigabyte per second in a single

00:27:29,800 --> 00:27:41,920
instance compared with a single called

00:27:33,330 --> 00:27:50,620
i7 which is 500 megabytes so it seems

00:27:41,920 --> 00:27:54,460
that we get a 10 SB up so yeah our

00:27:50,620 --> 00:27:58,360
project will be open source and the the

00:27:54,460 --> 00:28:02,170
link here is the the the project for

00:27:58,360 --> 00:28:05,050
this past filtering and for the whole

00:28:02,170 --> 00:28:11,190
project and the other component we we

00:28:05,050 --> 00:28:15,040
will put the link inside this link and

00:28:11,190 --> 00:28:17,770
we it for those who is interesting in

00:28:15,040 --> 00:28:21,400
our projects you can read our paper and

00:28:17,770 --> 00:28:23,320
if you still have questions long

00:28:21,400 --> 00:28:25,470
discussion you can send me email thank

00:28:23,320 --> 00:28:25,470
you

00:28:27,470 --> 00:28:29,530

YouTube URL: https://www.youtube.com/watch?v=8kjTUpHkP6U


