Title: OpenPOWER Summit Europe 2018: Hardware for HBM-Centric Computing
Publication date: 2019-02-07
Playlist: OpenPOWER Summit Europe 2018
Description: 
	Andrew McCormick, Alpha Data, speaks at OpenPOWER Summit Europe 2018.

For more information, please visit: https://openpowerfoundation.org/summit-2018-10-eu/
Captions: 
	00:00:01,030 --> 00:00:07,000
and I'm going to talk technical director

00:00:03,939 --> 00:00:10,660
Alfred it er a I guess there my talk is

00:00:07,000 --> 00:00:12,340
going to be focused on a I guess the HBM

00:00:10,660 --> 00:00:15,400
parts that you've heard about an awful

00:00:12,340 --> 00:00:18,190
lot in the the last talk and I'm also

00:00:15,400 --> 00:00:21,460
going to touch on open Cappy and I'm

00:00:18,190 --> 00:00:24,750
going to talk about it so some of the

00:00:21,460 --> 00:00:29,019
hardware we've been working on a

00:00:24,750 --> 00:00:31,269
primarily and a for the open cap we say

00:00:29,019 --> 00:00:34,239
the things but also based on these HBM

00:00:31,269 --> 00:00:37,899
chips I'm going to talk about initially

00:00:34,239 --> 00:00:43,899
about some applications that have used

00:00:37,899 --> 00:00:45,579
these these parts and then a I'll going

00:00:43,899 --> 00:00:46,989
through some sort of architecture of

00:00:45,579 --> 00:00:50,860
some shell structures that can fit in

00:00:46,989 --> 00:00:52,329
the FPGA to what Ruthie's a and then

00:00:50,860 --> 00:00:54,280
I'll go ahead and present some of

00:00:52,329 --> 00:00:56,559
information but some of the hardware

00:00:54,280 --> 00:01:02,340
we've Brett with brought to market based

00:00:56,559 --> 00:01:05,320
on HBM products so quick overview and

00:01:02,340 --> 00:01:08,400
for section I will just briefly recap or

00:01:05,320 --> 00:01:10,750
in the HBM architecture previous talk

00:01:08,400 --> 00:01:12,880
probably told you far more details and

00:01:10,750 --> 00:01:14,680
I've got things going to so I'll just

00:01:12,880 --> 00:01:16,869
briefly touching that and again also

00:01:14,680 --> 00:01:19,420
briefly touch on some of the reasons why

00:01:16,869 --> 00:01:21,939
FP the acceleration gives you

00:01:19,420 --> 00:01:23,650
performance increases over other

00:01:21,939 --> 00:01:25,450
architectures despite the fact that

00:01:23,650 --> 00:01:30,159
possibly other architectures may have

00:01:25,450 --> 00:01:31,450
hardened a arithmetic or operational

00:01:30,159 --> 00:01:36,220
units that are potentially higher

00:01:31,450 --> 00:01:38,380
performance than fpg implementations are

00:01:36,220 --> 00:01:40,450
then going talk about four or five

00:01:38,380 --> 00:01:44,110
different applications that we've looked

00:01:40,450 --> 00:01:46,899
at certainly at a simulation level and

00:01:44,110 --> 00:01:52,689
are a implementing a provider level or

00:01:46,899 --> 00:01:54,850
in a targeting the HBM architecture yeah

00:01:52,689 --> 00:01:56,799
I'll then look at some sort of in ship

00:01:54,850 --> 00:01:59,079
architecture of some shell designs for

00:01:56,799 --> 00:02:00,310
let me fit these different architectures

00:01:59,079 --> 00:02:03,939
and then I'll talk about some of the

00:02:00,310 --> 00:02:06,700
boards that we're we've brought to

00:02:03,939 --> 00:02:10,239
market specific specifically ones in the

00:02:06,700 --> 00:02:11,090
data center I'm Dave Kathy Hawken Cappy

00:02:10,239 --> 00:02:14,239
area

00:02:11,090 --> 00:02:16,130
so I guess the only thing I really want

00:02:14,239 --> 00:02:18,140
to say about the HBM architecture that

00:02:16,130 --> 00:02:22,069
hasn't already been covered or has been

00:02:18,140 --> 00:02:23,330
covered probably well so far the key

00:02:22,069 --> 00:02:26,239
point really is the fact that you have

00:02:23,330 --> 00:02:28,550
got this massively wade into a bandwidth

00:02:26,239 --> 00:02:32,420
interface but you have to access that I

00:02:28,550 --> 00:02:34,310
has 32 independent ports and these are

00:02:32,420 --> 00:02:35,180
these are fortunately quite well spread

00:02:34,310 --> 00:02:38,000
across there

00:02:35,180 --> 00:02:40,370
one of the HBM thighs yeah so you've got

00:02:38,000 --> 00:02:43,700
all this routing congestion issues and

00:02:40,370 --> 00:02:45,200
using these a and each of these ports

00:02:43,700 --> 00:02:47,299
does already through the switching IP

00:02:45,200 --> 00:02:49,730
although you taxes already gigabytes off

00:02:47,299 --> 00:02:54,370
there the one chip memory and that

00:02:49,730 --> 00:02:59,110
allows you great potential and

00:02:54,370 --> 00:02:59,110
paralyzing your architectures yeah I

00:03:01,360 --> 00:03:10,160
guess quickly run through why fpg is

00:03:07,069 --> 00:03:12,470
give you improvements in performance per

00:03:10,160 --> 00:03:13,670
watt and performance per gate and a lot

00:03:12,470 --> 00:03:15,320
of the improvements improve just

00:03:13,670 --> 00:03:17,390
efficiency of your implementation these

00:03:15,320 --> 00:03:19,730
can be dataflow pipeline processing

00:03:17,390 --> 00:03:23,120
you're feeding data directly between

00:03:19,730 --> 00:03:25,190
your a operational units your arithmetic

00:03:23,120 --> 00:03:28,640
units you've not storing them in any

00:03:25,190 --> 00:03:30,290
intermediary cashing you are you don't

00:03:28,640 --> 00:03:32,750
need to implement an instruction set so

00:03:30,290 --> 00:03:35,600
you can save all the extra power cost

00:03:32,750 --> 00:03:37,489
and memory access cost of running an

00:03:35,600 --> 00:03:40,489
instruction unit you can reduce your

00:03:37,489 --> 00:03:41,660
estimate arithmetic complexity don't a

00:03:40,489 --> 00:03:44,930
level it's actually needed for your

00:03:41,660 --> 00:03:46,630
algorithm and you can actually a very

00:03:44,930 --> 00:03:48,590
high detailed control of your

00:03:46,630 --> 00:03:51,530
application specific memory management

00:03:48,590 --> 00:03:53,180
today you can schedule your memory

00:03:51,530 --> 00:03:54,859
region rates to actually match what your

00:03:53,180 --> 00:03:56,170
application needs and also access the

00:03:54,859 --> 00:03:57,380
hardware in the most efficient manner

00:03:56,170 --> 00:04:00,260
Hey

00:03:57,380 --> 00:04:02,290
with all these implementation efficiency

00:04:00,260 --> 00:04:04,639
improvements that allows you to paralyze

00:04:02,290 --> 00:04:06,019
massively across your chip and that

00:04:04,639 --> 00:04:09,230
gives you your performance increase

00:04:06,019 --> 00:04:12,350
overall over all this acceleration

00:04:09,230 --> 00:04:15,260
within the chip a you're still going to

00:04:12,350 --> 00:04:17,870
hit and I hope bandwidth boundary

00:04:15,260 --> 00:04:21,320
because your external chip has not

00:04:17,870 --> 00:04:23,419
increased in bandwidth a for a number of

00:04:21,320 --> 00:04:24,770
years however HBM is one either for

00:04:23,419 --> 00:04:28,069
you're going to get an order of Magnus

00:04:24,770 --> 00:04:31,220
improvement in this area so this is one

00:04:28,069 --> 00:04:33,169
thing we're looking forward to and so

00:04:31,220 --> 00:04:35,210
move they want to some of the machine

00:04:33,169 --> 00:04:37,610
min applications that people are

00:04:35,210 --> 00:04:40,940
targeting FB G's with and probably in

00:04:37,610 --> 00:04:43,060
2018 probably couldn't have our FPGA

00:04:40,940 --> 00:04:46,460
talk without mentioning machine learning

00:04:43,060 --> 00:04:48,710
artificial intelligence yeah these can

00:04:46,460 --> 00:04:52,699
be most energy-efficient if you can keep

00:04:48,710 --> 00:04:54,500
the your neural network weeks within the

00:04:52,699 --> 00:04:58,449
chip and your one chip cache you're on

00:04:54,500 --> 00:05:00,620
it and share ultra Rama bought Ram and

00:04:58,449 --> 00:05:03,080
move it as soon as you move these data

00:05:00,620 --> 00:05:04,430
around that's obviously whether some of

00:05:03,080 --> 00:05:06,940
these can be fairly large and that can

00:05:04,430 --> 00:05:09,169
be a quite high energy cost yeah

00:05:06,940 --> 00:05:11,569
unfortunetly people come up with are too

00:05:09,169 --> 00:05:13,729
big for to fit on any chip I think all

00:05:11,569 --> 00:05:15,530
the best example think vgg network is

00:05:13,729 --> 00:05:16,969
that the largest one and if so your

00:05:15,530 --> 00:05:19,610
options have to go to multi chip which

00:05:16,969 --> 00:05:22,460
may be an option if you fare if your

00:05:19,610 --> 00:05:24,050
Amazon or your Microsoft and but it can

00:05:22,460 --> 00:05:27,800
be a very expensive option or you can

00:05:24,050 --> 00:05:29,180
use external deer arm if the memory

00:05:27,800 --> 00:05:30,979
bandwidth for getting your weights on

00:05:29,180 --> 00:05:33,770
and off the chip is pretty high but you

00:05:30,979 --> 00:05:36,080
can make this efficient by using batch

00:05:33,770 --> 00:05:40,580
process you know and we just you know

00:05:36,080 --> 00:05:43,250
the number of fare and process a large

00:05:40,580 --> 00:05:48,460
number of images or elements or infinite

00:05:43,250 --> 00:05:51,680
assets a as a batch splitting up their

00:05:48,460 --> 00:05:53,569
network processing however this this

00:05:51,680 --> 00:05:55,130
type of solution which is quite good if

00:05:53,569 --> 00:05:57,380
you've got a single FPGA an external D

00:05:55,130 --> 00:05:59,599
Ram is memory is going to be memory

00:05:57,380 --> 00:06:01,759
bound unless you can use large batch

00:05:59,599 --> 00:06:04,099
sizes and you may want not want to use

00:06:01,759 --> 00:06:07,490
large both sizes because larger the bus

00:06:04,099 --> 00:06:08,930
that he's a washer latency so again each

00:06:07,490 --> 00:06:11,960
BM should give you your order of

00:06:08,930 --> 00:06:14,229
magnitude a performance boost over your

00:06:11,960 --> 00:06:19,039
standard yeah

00:06:14,229 --> 00:06:21,199
your standard a given beast accelerator

00:06:19,039 --> 00:06:22,880
some other applications we've been

00:06:21,199 --> 00:06:25,940
looking at we're looking at search

00:06:22,880 --> 00:06:28,849
that's a fairly trivial probably

00:06:25,940 --> 00:06:31,729
parallelizable and memory boned type of

00:06:28,849 --> 00:06:35,210
applications if you just give you great

00:06:31,729 --> 00:06:36,860
potential to scan the same distance in

00:06:35,210 --> 00:06:37,820
say at multiple teams for lots of

00:06:36,860 --> 00:06:39,440
different

00:06:37,820 --> 00:06:41,810
such queries just streaming the data in

00:06:39,440 --> 00:06:43,660
as fast as possible as obviously memory

00:06:41,810 --> 00:06:47,330
bound and all this kind of bear from HBM

00:06:43,660 --> 00:06:49,730
we've looked at sort and you can

00:06:47,330 --> 00:06:51,040
implement in FPGA czar order in parallel

00:06:49,730 --> 00:06:55,540
in the house or you can basically just

00:06:51,040 --> 00:06:58,970
stream the the data straight through a

00:06:55,540 --> 00:07:03,170
different sorting FIFO and almost FFT

00:06:58,970 --> 00:07:06,530
like a comparison split in marriage

00:07:03,170 --> 00:07:08,570
taper algorithm this will help your

00:07:06,530 --> 00:07:10,790
memory limit using over 60 megabytes

00:07:08,570 --> 00:07:12,100
using ultra around the block Ram but if

00:07:10,790 --> 00:07:15,130
you've got all these multiple

00:07:12,100 --> 00:07:20,450
HBM ports you can then actually set up

00:07:15,130 --> 00:07:23,720
higher order marriages using going to

00:07:20,450 --> 00:07:24,920
and from each BM in a stream

00:07:23,720 --> 00:07:27,920
sequential mine are that will

00:07:24,920 --> 00:07:29,150
efficiently access the HBM another thing

00:07:27,920 --> 00:07:32,480
we've looked at in terms of big data

00:07:29,150 --> 00:07:35,450
they this analytics is keeping his

00:07:32,480 --> 00:07:37,580
clustering again this works well with a

00:07:35,450 --> 00:07:39,770
fixpoint implementation because your

00:07:37,580 --> 00:07:42,050
datasets have to be normalized to more

00:07:39,770 --> 00:07:45,440
or less the same same scale and don't

00:07:42,050 --> 00:07:47,150
benefit from any numerical distributions

00:07:45,440 --> 00:07:48,800
and again the ceniza easily

00:07:47,150 --> 00:07:51,620
parallelizable most people want to run

00:07:48,800 --> 00:07:55,100
this multiple times with different

00:07:51,620 --> 00:07:56,780
starting values a and they will not

00:07:55,100 --> 00:07:58,100
necessarily marry bone this this will

00:07:56,780 --> 00:08:00,830
become Mary boned if you want to run

00:07:58,100 --> 00:08:04,340
lots in parallel or you have very large

00:08:00,830 --> 00:08:08,300
data sizes hey we have looked at a

00:08:04,340 --> 00:08:09,890
couple of other applications I've been

00:08:08,300 --> 00:08:12,980
set up I wonder the question earlier but

00:08:09,890 --> 00:08:14,750
we have looked this 3d FFT s and you

00:08:12,980 --> 00:08:16,790
know see you look at these big effigies

00:08:14,750 --> 00:08:19,190
Ultron's going to be good for a corner

00:08:16,790 --> 00:08:21,400
turning memory probably up to 128 cubes

00:08:19,190 --> 00:08:22,900
of double precision or bigger or smaller

00:08:21,400 --> 00:08:25,910
Hey

00:08:22,900 --> 00:08:28,460
HBM can be used for chronic turning of

00:08:25,910 --> 00:08:31,040
all not directly I think you need to use

00:08:28,460 --> 00:08:33,380
of ultra ramus over and in between cache

00:08:31,040 --> 00:08:35,780
you would paralyze your reads across

00:08:33,380 --> 00:08:37,520
multiple channels yeah but this would

00:08:35,780 --> 00:08:43,969
give you a corner turning they're very

00:08:37,520 --> 00:08:45,680
up to here 50s cubes and she just think

00:08:43,969 --> 00:08:48,050
occupies about 4 gigs each so you've

00:08:45,680 --> 00:08:50,690
just already got enough memory to this

00:08:48,050 --> 00:08:51,500
whopper and again we've looked at matrix

00:08:50,690 --> 00:08:53,210
multiply

00:08:51,500 --> 00:08:55,250
or not specifically mainly bones pretty

00:08:53,210 --> 00:08:57,530
much when you don't memory multiply

00:08:55,250 --> 00:08:59,210
operation usually follow up with some

00:08:57,530 --> 00:09:02,450
sort of memory being operationally an ad

00:08:59,210 --> 00:09:04,430
if you are self dealing with a larger

00:09:02,450 --> 00:09:07,070
size of memory it matrix and trying to

00:09:04,430 --> 00:09:08,450
combine them or I guess a lot of other

00:09:07,070 --> 00:09:13,370
high performance computing applications

00:09:08,450 --> 00:09:16,820
tinting I did four multiplications and

00:09:13,370 --> 00:09:19,790
then scalar multiplies or square roots

00:09:16,820 --> 00:09:22,250
or other maybe bone for linear

00:09:19,790 --> 00:09:25,930
operations a so there's a potential to

00:09:22,250 --> 00:09:25,930
use its being the multiple port a

00:09:26,350 --> 00:09:33,440
options of each BM to manipulate this

00:09:30,350 --> 00:09:37,160
data and higher bandwidth we in para and

00:09:33,440 --> 00:09:39,230
the parallel or in as part of the same

00:09:37,160 --> 00:09:47,420
algorithm and same ideas as a matrix

00:09:39,230 --> 00:09:49,340
multiply okay so onto a sort of the HBM

00:09:47,420 --> 00:09:50,540
Excel is to tape shells and this this

00:09:49,340 --> 00:09:52,850
first example is probably very similar

00:09:50,540 --> 00:09:55,730
to what was presented on a stock is it's

00:09:52,850 --> 00:09:58,970
kind of the standard OpenCL tape shell

00:09:55,730 --> 00:10:02,030
where you chef's data from the host

00:09:58,970 --> 00:10:04,220
memory into there the working memory on

00:10:02,030 --> 00:10:06,200
your accelerator card and then process

00:10:04,220 --> 00:10:09,470
it from there and this is going to be

00:10:06,200 --> 00:10:11,420
quite effective for if you're working

00:10:09,470 --> 00:10:13,339
data sets between 50 Meg's and hit gigs

00:10:11,420 --> 00:10:15,110
if it's 50 megabytes you may as well put

00:10:13,339 --> 00:10:18,830
it in the alter army probably don't want

00:10:15,110 --> 00:10:20,780
to move it into even HBM use a faster

00:10:18,830 --> 00:10:22,430
memory if it's gray still a bigger

00:10:20,780 --> 00:10:28,820
you aren't going to hit the PCIe it's

00:10:22,430 --> 00:10:30,710
going to be a bottleneck so the solution

00:10:28,820 --> 00:10:33,380
will work for quite a lot of a lot of

00:10:30,710 --> 00:10:36,410
use cases but there are ways we can go

00:10:33,380 --> 00:10:39,140
officer mentioned PCIe bottlenecks and I

00:10:36,410 --> 00:10:40,700
suppose Myron spoke earlier about how

00:10:39,140 --> 00:10:43,820
people are working around the PCIe

00:10:40,700 --> 00:10:47,720
bottleneck and open cathy is certainly a

00:10:43,820 --> 00:10:50,540
solution that allows you to jump you and

00:10:47,720 --> 00:10:53,390
this not only giving you a big jump in

00:10:50,540 --> 00:10:57,800
bandwidth but also lowering the latency

00:10:53,390 --> 00:10:59,780
and giving all the advantages of a cache

00:10:57,800 --> 00:11:01,730
coherence so this this type of solution

00:10:59,780 --> 00:11:03,710
with all used to extend your your

00:11:01,730 --> 00:11:07,190
working memory from

00:11:03,710 --> 00:11:10,460
just eat gigabytes HBM to also use with

00:11:07,190 --> 00:11:12,790
a slightly lower performance say your

00:11:10,460 --> 00:11:16,100
host memory as part of your accelerator

00:11:12,790 --> 00:11:18,440
action memory and this would the

00:11:16,100 --> 00:11:20,089
differences between standard ddr4 on the

00:11:18,440 --> 00:11:23,300
board and the clear most memory over

00:11:20,089 --> 00:11:25,730
using open Kathy there's still within

00:11:23,300 --> 00:11:27,920
the same order of magnitude so possible

00:11:25,730 --> 00:11:30,890
in this case you may not want to use on

00:11:27,920 --> 00:11:35,420
board run when you may have 120 here a

00:11:30,890 --> 00:11:37,580
512 gig of a host memory which can also

00:11:35,420 --> 00:11:42,830
be shared coherent way with it and the

00:11:37,580 --> 00:11:46,279
CPUs and and when we're looking at HBC

00:11:42,830 --> 00:11:48,680
type applications multi-tiered systems

00:11:46,279 --> 00:11:52,600
what we're thinking is that what you

00:11:48,680 --> 00:11:56,330
wants high level of connectivity from a

00:11:52,600 --> 00:11:59,770
you reach BM to other equivalent

00:11:56,330 --> 00:11:59,770
accelerator notes and cheering

00:11:59,950 --> 00:12:06,440
sharing the data directly between the

00:12:02,500 --> 00:12:08,870
these nodes and so you know the high

00:12:06,440 --> 00:12:11,510
performance GT is that we haven't so

00:12:08,870 --> 00:12:14,120
having state refugees allow you to share

00:12:11,510 --> 00:12:16,970
let's say you could have many links a

00:12:14,120 --> 00:12:19,760
between nodes you know extending your

00:12:16,970 --> 00:12:22,700
workings say it so horizontally across

00:12:19,760 --> 00:12:26,380
the different FP G's rather than just

00:12:22,700 --> 00:12:30,100
extending it through the host memory and

00:12:26,380 --> 00:12:32,089
actually come up with a fairly similar a

00:12:30,100 --> 00:12:34,339
architecture for networking which I

00:12:32,089 --> 00:12:37,250
guess it's maybe possibly related to

00:12:34,339 --> 00:12:39,529
endlich's question as well and here you

00:12:37,250 --> 00:12:42,680
could have your hundred Gigabit Ethernet

00:12:39,529 --> 00:12:45,260
all feeding into and HBM working memory

00:12:42,680 --> 00:12:47,329
her must been matched by and opk open

00:12:45,260 --> 00:12:49,430
Kathy transferred to the host memory and

00:12:47,329 --> 00:12:51,140
well the status is sitting in you HBM

00:12:49,430 --> 00:12:54,130
working memory you could have a lot of

00:12:51,140 --> 00:12:57,110
intelligent tape network analytics

00:12:54,130 --> 00:12:59,779
applications a performing threat

00:12:57,110 --> 00:13:02,899
detection another it's networking up

00:12:59,779 --> 00:13:05,740
algorithms accessing that memory and you

00:13:02,899 --> 00:13:08,699
know deciding to throw away packets or

00:13:05,740 --> 00:13:11,470
discarding

00:13:08,699 --> 00:13:14,800
so finally I went to the the co-state

00:13:11,470 --> 00:13:17,079
plug and Alfred ADA I've been working

00:13:14,800 --> 00:13:19,029
with the VA 37 piece to bring her her

00:13:17,079 --> 00:13:20,410
own board to market market and we've

00:13:19,029 --> 00:13:24,670
looked at these different areas and

00:13:20,410 --> 00:13:27,160
identified what we should have we've

00:13:24,670 --> 00:13:28,720
targeted this sort of the the full

00:13:27,160 --> 00:13:30,819
height 3/4 length fair

00:13:28,720 --> 00:13:33,939
double with the PCIe foreign factor that

00:13:30,819 --> 00:13:36,100
GPUs typically have and people asked

00:13:33,939 --> 00:13:39,519
what pair of just earlier and we've spec

00:13:36,100 --> 00:13:41,199
this up to be able to take in cool 225

00:13:39,519 --> 00:13:45,149
watts possibly most users will never

00:13:41,199 --> 00:13:48,579
drive a chip up up to that level and

00:13:45,149 --> 00:13:54,040
again the kiai or features of versus we

00:13:48,579 --> 00:13:56,769
have 40 SFP 20 it a 100 gigabit ethernet

00:13:54,040 --> 00:14:00,639
capable interfaces to the front we have

00:13:56,769 --> 00:14:04,839
a PCIe gen3 or Gen 4 may 16 on the edge

00:14:00,639 --> 00:14:08,350
gen for us would be bifurcated as to Gen

00:14:04,839 --> 00:14:11,829
4 by eights and we have to open capi

00:14:08,350 --> 00:14:15,309
cable a connectors to the rear of the

00:14:11,829 --> 00:14:17,170
board and we also eat on board 20 K over

00:14:15,309 --> 00:14:19,569
per second keyhole Firefly connectors

00:14:17,170 --> 00:14:20,980
and these fire fire connectors are quite

00:14:19,569 --> 00:14:22,829
interesting because they give you a

00:14:20,980 --> 00:14:26,379
number of expansion options you could

00:14:22,829 --> 00:14:28,509
connect them between two cards equally

00:14:26,379 --> 00:14:28,930
if you were wanting to transfer data

00:14:28,509 --> 00:14:34,559
between

00:14:28,930 --> 00:14:38,980
HBM chips you could also connect

00:14:34,559 --> 00:14:42,550
director C in NCIC storage such as a you

00:14:38,980 --> 00:14:45,459
could run in nvm UPC over the Firefly

00:14:42,550 --> 00:14:47,529
and the example shown in this slide is

00:14:45,459 --> 00:14:50,199
our expansion card that we've come up

00:14:47,529 --> 00:14:52,540
with which is our I think will slot PCIe

00:14:50,199 --> 00:14:55,420
card which allows you to connect a an

00:14:52,540 --> 00:15:03,040
additional if were QFP connectors like

00:14:55,420 --> 00:15:05,740
using extra PCIe slot and we do have

00:15:03,040 --> 00:15:08,620
another a number of other boards which

00:15:05,740 --> 00:15:11,259
are not HP n and he bought de the one

00:15:08,620 --> 00:15:13,600
Ellis rated here is their villa sleepy

00:15:11,259 --> 00:15:16,120
which has been a important in the open

00:15:13,600 --> 00:15:18,519
Cappy bringing up a miscount does affect

00:15:16,120 --> 00:15:18,939
away an open Cappy fpg that card with

00:15:18,519 --> 00:15:22,240
the

00:15:18,939 --> 00:15:24,249
the ve CP never take soldier skill

00:15:22,240 --> 00:15:28,869
the vase on it and it's kept of open

00:15:24,249 --> 00:15:34,990
copy and copy two double-a operation has

00:15:28,869 --> 00:15:36,550
Dukey sfb 28 a Frank connections which

00:15:34,990 --> 00:15:39,220
are capable of each key for 100 Gigabit

00:15:36,550 --> 00:15:41,319
Ethernet and the sport has a head one

00:15:39,220 --> 00:15:42,910
more ddr4 and as they open Cappy

00:15:41,319 --> 00:15:45,490
interface at the back anything I was

00:15:42,910 --> 00:15:48,689
quite good match between the two 500 gig

00:15:45,490 --> 00:15:52,920
ye Ethernet the front and the 25 gigabit

00:15:48,689 --> 00:15:55,660
per second capability of open Cathy and

00:15:52,920 --> 00:15:59,040
also like to mention a couple of our

00:15:55,660 --> 00:16:05,769
older boards which are peppery and capi

00:15:59,040 --> 00:16:07,720
when the orchid or the q3 in the key

00:16:05,769 --> 00:16:10,720
five boards these are based on silent

00:16:07,720 --> 00:16:12,490
social skill key or sixteen key 105 and

00:16:10,720 --> 00:16:14,589
these are both the Cathy snap enable did

00:16:12,490 --> 00:16:18,850
you hear more about a Cathy snap with

00:16:14,589 --> 00:16:20,529
her and so these are capable of

00:16:18,850 --> 00:16:23,519
networking as well and their talk

00:16:20,529 --> 00:16:26,019
tomorrow or in Kathy snap and networking

00:16:23,519 --> 00:16:28,019
and these counters are capable of 1004

00:16:26,019 --> 00:16:31,540
2g so I'm not great into the hundred

00:16:28,019 --> 00:16:34,829
genome but they're post by good

00:16:31,540 --> 00:16:39,069
entry-level solution to get into

00:16:34,829 --> 00:16:42,069
Catholic happy development yeah and then

00:16:39,069 --> 00:16:43,959
just le announcement of a board for

00:16:42,069 --> 00:16:47,619
bringing a fairly soon at supercomputing

00:16:43,959 --> 00:16:52,389
a the EMP saline HDS is are a

00:16:47,619 --> 00:16:55,629
low-profile version of the HBM car that

00:16:52,389 --> 00:16:57,999
has the video 33 P device and as an open

00:16:55,629 --> 00:17:00,579
Kappa connection at the rear so this kid

00:16:57,999 --> 00:17:05,529
will be a a deployer will open Kathy net

00:17:00,579 --> 00:17:08,230
card as the key SFPD connections all

00:17:05,529 --> 00:17:13,240
English 200 Gigabit Ethernet connections

00:17:08,230 --> 00:17:15,370
at the front and really just to

00:17:13,240 --> 00:17:16,480
summarize I think I've seen from the

00:17:15,370 --> 00:17:18,220
previous talk and everything else that

00:17:16,480 --> 00:17:20,350
HB n is offering a magnitude improvement

00:17:18,220 --> 00:17:24,579
in memory bandwidth for FPGA

00:17:20,350 --> 00:17:26,049
applications that issue and you can see

00:17:24,579 --> 00:17:31,179
that there's a potentially good fit

00:17:26,049 --> 00:17:32,740
between each p.m. and open Kathy and we

00:17:31,179 --> 00:17:34,470
have boards available for both of these

00:17:32,740 --> 00:17:37,919
technologies

00:17:34,470 --> 00:17:39,929
so I'll just go into first thing for

00:17:37,919 --> 00:17:41,830
questions it's great if not theirs we're

00:17:39,929 --> 00:17:48,970
at the booth

00:17:41,830 --> 00:17:48,970

YouTube URL: https://www.youtube.com/watch?v=J01N-WJEyco


