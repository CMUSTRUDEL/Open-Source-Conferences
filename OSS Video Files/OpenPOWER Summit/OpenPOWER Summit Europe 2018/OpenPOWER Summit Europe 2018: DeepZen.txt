Title: OpenPOWER Summit Europe 2018: DeepZen
Publication date: 2019-02-07
Playlist: OpenPOWER Summit Europe 2018
Description: 
	Kerem Sozugecer, CTO, DeepZen, speaks at OpenPOWER Summit Europe 2018.

For more information, please visit: https://openpowerfoundation.org/summit-2018-10-eu/
Captions: 
	00:00:00,290 --> 00:00:04,890
all right I'm gonna be talking about

00:00:02,100 --> 00:00:07,290
something slightly different a lot of

00:00:04,890 --> 00:00:11,040
vision stuff so we're gonna be talking

00:00:07,290 --> 00:00:15,269
about voice and human voice and audio we

00:00:11,040 --> 00:00:17,940
are a startup we're called deep Zen ever

00:00:15,269 --> 00:00:19,500
started we started about a year ago I

00:00:17,940 --> 00:00:21,869
want to give you some background

00:00:19,500 --> 00:00:23,550
information and on what we're doing who

00:00:21,869 --> 00:00:27,720
we are and why we're doing what we're

00:00:23,550 --> 00:00:29,849
doing so we are still fairly new we

00:00:27,720 --> 00:00:33,030
officially launched at the beginning of

00:00:29,849 --> 00:00:35,190
the year we are 10 people now mostly

00:00:33,030 --> 00:00:40,200
PhDs in natural language processing and

00:00:35,190 --> 00:00:41,940
and text-to-speech and yeah we got we've

00:00:40,200 --> 00:00:43,680
been working closely with IBM since the

00:00:41,940 --> 00:00:46,770
beginning so we've been lucky to have to

00:00:43,680 --> 00:00:49,379
have their support and just quick here's

00:00:46,770 --> 00:00:53,100
a quick preview of who we are so the two

00:00:49,379 --> 00:00:56,309
co-founders me and Alan at the top left

00:00:53,100 --> 00:00:58,770
and we have an international advisory

00:00:56,309 --> 00:01:01,829
board we have PhDs from all over the

00:00:58,770 --> 00:01:04,019
globe actually it's kind of we are a

00:01:01,829 --> 00:01:07,229
team of ten but we're all remote almost

00:01:04,019 --> 00:01:08,369
in like five countries so that's that

00:01:07,229 --> 00:01:10,710
that works out pretty well

00:01:08,369 --> 00:01:17,220
it just gives that gives a lot more

00:01:10,710 --> 00:01:21,750
different opinions and input okay so why

00:01:17,220 --> 00:01:24,330
we started deep sandeep Sun we while we

00:01:21,750 --> 00:01:26,610
were doing research middle of like

00:01:24,330 --> 00:01:30,119
summer last year we were trying to

00:01:26,610 --> 00:01:32,220
figure out come up with something in the

00:01:30,119 --> 00:01:34,619
air ai space that's gonna I just dropped

00:01:32,220 --> 00:01:37,259
the industry so we looked at the audio

00:01:34,619 --> 00:01:39,060
book industry and audio book industry I

00:01:37,259 --> 00:01:42,750
don't know about how many of you listen

00:01:39,060 --> 00:01:44,549
to audiobooks or ever listened to one ok

00:01:42,750 --> 00:01:47,579
so I think it's gonna become more and

00:01:44,549 --> 00:01:49,770
more popular essential audio book

00:01:47,579 --> 00:01:53,399
industry is a is a is an upcoming

00:01:49,770 --> 00:01:56,579
industry it's increasing about 30% a

00:01:53,399 --> 00:01:58,110
year after year and we looked at how the

00:01:56,579 --> 00:01:59,969
audio book industries today works it's

00:01:58,110 --> 00:02:02,729
it's basically works with the humans

00:01:59,969 --> 00:02:07,259
humans going to studios do a lot of

00:02:02,729 --> 00:02:08,849
recording and essentially the average

00:02:07,259 --> 00:02:10,679
time to build an audiobook from scratch

00:02:08,849 --> 00:02:13,080
is about six to eight weeks and starts

00:02:10,679 --> 00:02:13,690
from 4,000 it's average is four thousand

00:02:13,080 --> 00:02:17,350
to five

00:02:13,690 --> 00:02:19,270
dollars for ten-hour audio book so it's

00:02:17,350 --> 00:02:21,130
a complex process it's you have to find

00:02:19,270 --> 00:02:23,670
a narrator you have to find your studio

00:02:21,130 --> 00:02:27,160
there's a lot of editing in mold and

00:02:23,670 --> 00:02:29,050
then the a lot of times the narrator

00:02:27,160 --> 00:02:32,260
needs to go back to the studio and redo

00:02:29,050 --> 00:02:34,390
a lot of the recordings and you have to

00:02:32,260 --> 00:02:36,700
find the right voice actor for the right

00:02:34,390 --> 00:02:38,440
book so and that's not easy because you

00:02:36,700 --> 00:02:39,490
start sometimes you don't like it and

00:02:38,440 --> 00:02:42,490
you need to change it again

00:02:39,490 --> 00:02:46,720
and it's a time-consuming costly process

00:02:42,490 --> 00:02:48,940
and so the opportunity was out there

00:02:46,720 --> 00:02:53,170
there are 2 million books printed every

00:02:48,940 --> 00:02:55,120
year only 40,000 are are turned into

00:02:53,170 --> 00:02:59,490
audio books mainly because of this

00:02:55,120 --> 00:03:02,500
time-consuming and expensive process and

00:02:59,490 --> 00:03:04,450
so and but and when you go through all

00:03:02,500 --> 00:03:07,690
this process only get is one version of

00:03:04,450 --> 00:03:10,240
the book one language one accent female

00:03:07,690 --> 00:03:11,290
or male and if you want anything more

00:03:10,240 --> 00:03:13,150
than that you need to go through this

00:03:11,290 --> 00:03:15,160
whole process is basically do you double

00:03:13,150 --> 00:03:16,780
and triple the cost so there was a big

00:03:15,160 --> 00:03:20,020
opportunity there and we thought why

00:03:16,780 --> 00:03:22,570
can't we do this why can't we do this

00:03:20,020 --> 00:03:26,050
with without artificial intelligence so

00:03:22,570 --> 00:03:27,700
just some of the summary so it's a six

00:03:26,050 --> 00:03:30,220
billion dollar industry audio book

00:03:27,700 --> 00:03:34,540
growing 30% but still it's less than 5%

00:03:30,220 --> 00:03:40,780
of the print market and 30% growth is is

00:03:34,540 --> 00:03:43,000
a lot about 75% of Americans in 2017

00:03:40,780 --> 00:03:44,980
read or listened to at least one audio

00:03:43,000 --> 00:03:50,140
book so the opportunity was was clearly

00:03:44,980 --> 00:03:52,230
out there we also identified other

00:03:50,140 --> 00:03:54,640
industries which I'm going to talk later

00:03:52,230 --> 00:03:56,440
we're talking to video gaming companies

00:03:54,640 --> 00:03:58,330
as well and advertising companies for

00:03:56,440 --> 00:04:01,709
any voice-over stuff but our main focus

00:03:58,330 --> 00:04:04,780
has always been in the audio books so

00:04:01,709 --> 00:04:07,390
after we decided you want to go this way

00:04:04,780 --> 00:04:10,810
we tried to figure out how to do this

00:04:07,390 --> 00:04:12,280
because it's it's the problem is when

00:04:10,810 --> 00:04:15,820
you look at when you when you go or a

00:04:12,280 --> 00:04:18,840
double yes and and IBM and and you know

00:04:15,820 --> 00:04:25,289
a lot of TTS companies already do TTS so

00:04:18,840 --> 00:04:27,520
TTS has existed for years human quality

00:04:25,289 --> 00:04:30,370
voice meaning in distinguished

00:04:27,520 --> 00:04:32,710
human quality voice is fairly new it's

00:04:30,370 --> 00:04:34,690
it became possible with deep neural

00:04:32,710 --> 00:04:37,090
networks in the past two-three years so

00:04:34,690 --> 00:04:39,550
you can actually go out and find api's

00:04:37,090 --> 00:04:42,009
that synthesize human voice that is

00:04:39,550 --> 00:04:45,789
indistinguishable but when you do this

00:04:42,009 --> 00:04:47,650
it's usually a sentence or two so for a

00:04:45,789 --> 00:04:49,389
sentence or two it sounds great

00:04:47,650 --> 00:04:53,349
but when you try to synthesize a whole

00:04:49,389 --> 00:04:55,900
book an article a paragraph or basically

00:04:53,349 --> 00:04:58,449
a larger context whatever system you use

00:04:55,900 --> 00:05:00,610
today it becomes monotonous and boring

00:04:58,449 --> 00:05:02,800
because there is no emotions and

00:05:00,610 --> 00:05:05,020
expressivity involved in the synthesis

00:05:02,800 --> 00:05:06,580
process and that's because without

00:05:05,020 --> 00:05:09,069
understanding what the text is saying

00:05:06,580 --> 00:05:11,139
it's not possible to synthesize what the

00:05:09,069 --> 00:05:13,389
emotions and expressivity so in order

00:05:11,139 --> 00:05:16,240
for that to happen there was a whole big

00:05:13,389 --> 00:05:18,539
layer that was always lacking in any

00:05:16,240 --> 00:05:20,650
text to speech

00:05:18,539 --> 00:05:22,389
products out there and that's natural

00:05:20,650 --> 00:05:24,639
language processing so in order to make

00:05:22,389 --> 00:05:26,800
this happen we first need to put

00:05:24,639 --> 00:05:32,259
together a natural prog natural language

00:05:26,800 --> 00:05:35,620
processing a project and first analyze

00:05:32,259 --> 00:05:37,330
the text parse the data understand the

00:05:35,620 --> 00:05:40,210
text as much as we can so I mean when I

00:05:37,330 --> 00:05:41,740
say understand the text I am NOT saying

00:05:40,210 --> 00:05:44,529
that we can understand the whole book

00:05:41,740 --> 00:05:47,110
that's that's not possible yet it's just

00:05:44,529 --> 00:05:49,599
it's it's a big problem to solve but

00:05:47,110 --> 00:05:52,360
we've tried to find something in between

00:05:49,599 --> 00:05:55,300
so we tried to find do it at a paragraph

00:05:52,360 --> 00:05:57,759
level or even a chapter level and

00:05:55,300 --> 00:06:00,099
basically it start from there so you

00:05:57,759 --> 00:06:03,190
first understand it and then you tag it

00:06:00,099 --> 00:06:07,090
with emotions you basically decide we

00:06:03,190 --> 00:06:10,360
identified nine emotions for our start

00:06:07,090 --> 00:06:13,000
in the start the project our goals to to

00:06:10,360 --> 00:06:15,759
go up to 23 different emotions in the

00:06:13,000 --> 00:06:18,219
past in the next year and you basically

00:06:15,759 --> 00:06:20,110
you identify you go santa's paragraph by

00:06:18,219 --> 00:06:22,630
paragraph and you tag it with emotions

00:06:20,110 --> 00:06:25,210
and this when you tag with emotions it's

00:06:22,630 --> 00:06:28,960
not like you don't tag it with one

00:06:25,210 --> 00:06:30,639
emotion it's really a distribution of

00:06:28,960 --> 00:06:32,889
the of the nine emotions that's you

00:06:30,639 --> 00:06:34,360
basically give a very granular score for

00:06:32,889 --> 00:06:37,419
every sentence or every paragraph

00:06:34,360 --> 00:06:39,539
depending on the context and then you

00:06:37,419 --> 00:06:41,290
output that and you have this enriched

00:06:39,539 --> 00:06:43,960
labeled and tagged

00:06:41,290 --> 00:06:47,320
texts now that now you can Center

00:06:43,960 --> 00:06:47,710
text-to-speech and that's that's how it

00:06:47,320 --> 00:06:51,010
works

00:06:47,710 --> 00:06:53,500
now the second problem that we that we

00:06:51,010 --> 00:06:56,140
need the soul was also we need to solve

00:06:53,500 --> 00:06:58,120
two things one is replicate what's

00:06:56,140 --> 00:07:02,350
already out there which is human-like

00:06:58,120 --> 00:07:03,670
speech and but more importantly we

00:07:02,350 --> 00:07:05,470
needed to figure out how to synthesize

00:07:03,670 --> 00:07:07,710
emotional speech we need to synthesize

00:07:05,470 --> 00:07:10,330
the voice that can go up and down and

00:07:07,710 --> 00:07:13,540
there's continued to between sentences

00:07:10,330 --> 00:07:14,440
then that it's essentially it's in you

00:07:13,540 --> 00:07:18,430
know our goal is to make it

00:07:14,440 --> 00:07:20,680
indistinguishable for an audio book so

00:07:18,430 --> 00:07:23,260
in order for that to happen and there's

00:07:20,680 --> 00:07:25,030
a bunch of other steps that we did I'm

00:07:23,260 --> 00:07:28,720
gonna go into detail a little bit but so

00:07:25,030 --> 00:07:29,980
we have the NLP we tagged it we'd send

00:07:28,720 --> 00:07:33,070
it to Texas speech and we have a

00:07:29,980 --> 00:07:34,450
finalized audio and we always have

00:07:33,070 --> 00:07:37,300
incremental emotional training what I

00:07:34,450 --> 00:07:40,890
mean with that is we keep adding finding

00:07:37,300 --> 00:07:46,570
and creating our own emotional data set

00:07:40,890 --> 00:07:48,490
in order to train both both our TTS and

00:07:46,570 --> 00:07:50,920
natural language processing and the

00:07:48,490 --> 00:07:52,810
essentially this is voice so if you

00:07:50,920 --> 00:07:56,230
think about the industries in these

00:07:52,810 --> 00:07:57,940
industries that this applies to are like

00:07:56,230 --> 00:08:00,130
a lot all over the place

00:07:57,940 --> 00:08:02,680
we start with audio books we're looking

00:08:00,130 --> 00:08:04,960
at their voiceovers as well and the

00:08:02,680 --> 00:08:07,120
voiceovers meaning any company that

00:08:04,960 --> 00:08:09,940
needs to do any voice over for like a

00:08:07,120 --> 00:08:12,010
demo video that you soon on the YouTube

00:08:09,940 --> 00:08:14,410
like an introduction video that's two

00:08:12,010 --> 00:08:16,330
minutes log or any advertising it

00:08:14,410 --> 00:08:18,550
applies to this because for all of these

00:08:16,330 --> 00:08:21,280
it's always a human going to studio and

00:08:18,550 --> 00:08:23,260
doing recordings same for gay voiceovers

00:08:21,280 --> 00:08:24,730
gaming companies have to go through the

00:08:23,260 --> 00:08:27,100
exact same process we spoke to a couple

00:08:24,730 --> 00:08:29,080
large gaming companies and and it was a

00:08:27,100 --> 00:08:30,880
big it you know happened to be a big

00:08:29,080 --> 00:08:32,440
problem for them as well and voice

00:08:30,880 --> 00:08:35,919
assistance is obviously it's a little

00:08:32,440 --> 00:08:37,660
bit different in this sense that the

00:08:35,919 --> 00:08:39,190
implementation of the voice assistant

00:08:37,660 --> 00:08:42,280
requires a little bit more processing

00:08:39,190 --> 00:08:44,830
power a little bit meaning you need to

00:08:42,280 --> 00:08:47,970
do some real-time a voice synthesis but

00:08:44,830 --> 00:08:53,650
the applications are are basically

00:08:47,970 --> 00:08:55,090
endless here so if you go to do a little

00:08:53,650 --> 00:08:56,860
bit more technical detail this

00:08:55,090 --> 00:08:59,170
so the natural language processing is

00:08:56,860 --> 00:09:01,360
what we have today is MIDI these are the

00:08:59,170 --> 00:09:03,670
stuff that we try and then we ended up

00:09:01,360 --> 00:09:06,870
finding that where things were lacking

00:09:03,670 --> 00:09:09,000
so the we started with a text-based

00:09:06,870 --> 00:09:11,140
natural language processing which is the

00:09:09,000 --> 00:09:14,320
which is the simplest one which is the

00:09:11,140 --> 00:09:16,540
most obvious one but again it works for

00:09:14,320 --> 00:09:20,710
a sentence or two but when you actually

00:09:16,540 --> 00:09:24,010
try to do this for a large context there

00:09:20,710 --> 00:09:26,170
are so many vague sentences and we're

00:09:24,010 --> 00:09:30,820
doing with English right now that is

00:09:26,170 --> 00:09:32,260
impossible to understand without by just

00:09:30,820 --> 00:09:33,970
looking at the text you know how the

00:09:32,260 --> 00:09:36,400
emotional state of it so we run into

00:09:33,970 --> 00:09:40,990
these sentences fairly often so that's

00:09:36,400 --> 00:09:42,670
why we are improving on a natural

00:09:40,990 --> 00:09:44,500
language processing where we're turning

00:09:42,670 --> 00:09:47,890
into a multimodal sentiment analysis

00:09:44,500 --> 00:09:51,130
where we not only feed text but we also

00:09:47,890 --> 00:09:54,700
we basically try to find recordings or

00:09:51,130 --> 00:09:58,390
we create our own again that is a video

00:09:54,700 --> 00:10:01,000
that is basically extract the text from

00:09:58,390 --> 00:10:03,550
that video feed it as text we extract

00:10:01,000 --> 00:10:05,890
the facial gestures from that video if

00:10:03,550 --> 00:10:08,320
it's a person that's speaking throughout

00:10:05,890 --> 00:10:09,820
the video and then we and then the third

00:10:08,320 --> 00:10:11,080
thing is with the voice analysis so when

00:10:09,820 --> 00:10:14,020
you actually put all these three

00:10:11,080 --> 00:10:15,940
together then you are able to do better

00:10:14,020 --> 00:10:18,130
emotion extraction we're still working

00:10:15,940 --> 00:10:19,990
through this not there yet it's not an

00:10:18,130 --> 00:10:24,460
easy problem to solve but there are

00:10:19,990 --> 00:10:26,950
approaches that approaches out there at

00:10:24,460 --> 00:10:28,900
a fairly recent so we're trying over

00:10:26,950 --> 00:10:30,820
pushing through that but for now what we

00:10:28,900 --> 00:10:34,000
our system is completely text-based and

00:10:30,820 --> 00:10:35,770
we've also integrated with other api's

00:10:34,000 --> 00:10:38,560
and and we're for example we're

00:10:35,770 --> 00:10:40,839
integrated with Watson's natural

00:10:38,560 --> 00:10:42,760
language processing emotional emotion

00:10:40,839 --> 00:10:45,100
and alysus so we're able to switch

00:10:42,760 --> 00:10:46,930
between different NLP systems in real

00:10:45,100 --> 00:10:51,430
time during synthesis so to do a

00:10:46,930 --> 00:10:53,380
comparison so it it helped us make our

00:10:51,430 --> 00:10:55,270
NLP better and then basically test it

00:10:53,380 --> 00:11:00,670
against the systems that are already out

00:10:55,270 --> 00:11:02,320
there on the text of speech part so NLP

00:11:00,670 --> 00:11:04,150
and Texas speech for us are completely

00:11:02,320 --> 00:11:05,800
two different systems we thought of

00:11:04,150 --> 00:11:08,320
putting them together but it just didn't

00:11:05,800 --> 00:11:08,649
make sense it did not make sense to put

00:11:08,320 --> 00:11:11,170
it into

00:11:08,649 --> 00:11:13,480
one big codebase so we added a

00:11:11,170 --> 00:11:17,110
controller in between because these guys

00:11:13,480 --> 00:11:20,319
these things only speak through the

00:11:17,110 --> 00:11:21,970
controller so they when NLP does but

00:11:20,319 --> 00:11:23,709
it's done it sends it to the controller

00:11:21,970 --> 00:11:26,110
and then controller decides to send it

00:11:23,709 --> 00:11:28,540
to to take to text-to-speech for speech

00:11:26,110 --> 00:11:30,850
synthesis so our speech synthesis system

00:11:28,540 --> 00:11:34,319
again that's that was another large

00:11:30,850 --> 00:11:36,600
problem is there there are two types of

00:11:34,319 --> 00:11:39,369
synthesis synthesis system

00:11:36,600 --> 00:11:41,829
well one of them is that the older ones

00:11:39,369 --> 00:11:43,660
these are all still neural networks this

00:11:41,829 --> 00:11:46,300
is not we're not doing any concatenation

00:11:43,660 --> 00:11:48,129
type of old technology but these are all

00:11:46,300 --> 00:11:50,079
the latest technologies one is the

00:11:48,129 --> 00:11:52,990
linguistic based system that we

00:11:50,079 --> 00:11:54,459
developed and the other one is entrant

00:11:52,990 --> 00:11:56,499
synthesis system so the difference

00:11:54,459 --> 00:12:04,420
between them is linguistic based systems

00:11:56,499 --> 00:12:07,059
have have draw blanks I'll come back to

00:12:04,420 --> 00:12:11,110
that antwuan system is these are the

00:12:07,059 --> 00:12:13,870
newer systems such as a wave net socket

00:12:11,110 --> 00:12:17,259
Ron a Google socket Ron where it learns

00:12:13,870 --> 00:12:18,759
directly from voice and it learns how to

00:12:17,259 --> 00:12:20,170
pronounce directly from more so it

00:12:18,759 --> 00:12:22,149
doesn't need to look at anything else

00:12:20,170 --> 00:12:23,559
the problem with these systems are

00:12:22,149 --> 00:12:25,449
they're very very good they're they're

00:12:23,559 --> 00:12:27,699
easy to train the problem with that is

00:12:25,449 --> 00:12:29,980
when you try to synthesize a book just

00:12:27,699 --> 00:12:31,809
learning from voice requires thousands

00:12:29,980 --> 00:12:33,309
of hours of training data so you act so

00:12:31,809 --> 00:12:35,649
the system actually learn to pronounce

00:12:33,309 --> 00:12:39,939
every word because you need to you need

00:12:35,649 --> 00:12:42,009
to teach it the linguistic base system

00:12:39,939 --> 00:12:43,779
is yeah I remember the word now is you

00:12:42,009 --> 00:12:48,040
there's actually predefined a phonetic

00:12:43,779 --> 00:12:50,319
library that you can purchase for every

00:12:48,040 --> 00:12:51,730
language different accents so the good

00:12:50,319 --> 00:12:54,279
thing about these phonetic libraries is

00:12:51,730 --> 00:12:56,470
is when you actually see the text to

00:12:54,279 --> 00:12:58,959
synthesize it actually already knows how

00:12:56,470 --> 00:13:00,850
to pronounce four different accents so

00:12:58,959 --> 00:13:04,240
that makes life a lot of ease a lot

00:13:00,850 --> 00:13:07,179
easier so so the the the end-to-end

00:13:04,240 --> 00:13:11,679
system like I said the problem with that

00:13:07,179 --> 00:13:13,329
when you try to build a book it creates

00:13:11,679 --> 00:13:16,240
a lot of problems so what we decided to

00:13:13,329 --> 00:13:21,600
do was we tried to build a hybrid system

00:13:16,240 --> 00:13:24,300
so we essentially I need to

00:13:21,600 --> 00:13:37,130
can you one second it's supposed to go -

00:13:24,300 --> 00:13:37,130
do not disturb yeah exactly

00:13:38,840 --> 00:13:46,320
alright so yeah we decided put it

00:13:43,260 --> 00:13:48,870
together and and go kind of with an

00:13:46,320 --> 00:13:50,700
hybrid approach where we utilize you

00:13:48,870 --> 00:13:53,100
know the new technologies directly

00:13:50,700 --> 00:13:55,140
learning from noise but to be safe we

00:13:53,100 --> 00:13:56,700
use a linguist linguistic based system

00:13:55,140 --> 00:13:58,200
to make sure that we can actually

00:13:56,700 --> 00:14:00,510
pronounce everything everything's

00:13:58,200 --> 00:14:02,940
pronounced well so another thing that we

00:14:00,510 --> 00:14:05,970
did on top of this so this is the base

00:14:02,940 --> 00:14:09,300
voice system we built our base voice

00:14:05,970 --> 00:14:11,930
system where you can train with about 20

00:14:09,300 --> 00:14:15,960
hours of data a single speaker data

00:14:11,930 --> 00:14:17,340
which actually we had an agreement were

00:14:15,960 --> 00:14:19,680
there ever the worst over are this we

00:14:17,340 --> 00:14:23,460
put her in a studio and then had her

00:14:19,680 --> 00:14:25,350
read books for 24 hours so so this is

00:14:23,460 --> 00:14:28,230
that's that's how we had to start so

00:14:25,350 --> 00:14:31,560
with that data we built a base force and

00:14:28,230 --> 00:14:33,480
base felishj meaning a voice with her a

00:14:31,560 --> 00:14:36,270
completely her expressivity so nothing

00:14:33,480 --> 00:14:37,770
if she's very expressive in in the

00:14:36,270 --> 00:14:39,690
training data then the voice becomes

00:14:37,770 --> 00:14:41,130
base force becomes expressive if she is

00:14:39,690 --> 00:14:43,260
just not expressive with you so it

00:14:41,130 --> 00:14:48,930
basically mimics what's your this speaks

00:14:43,260 --> 00:14:52,260
so the reason we approach is we cannot

00:14:48,930 --> 00:14:53,510
record an or purchase so many different

00:14:52,260 --> 00:14:55,350
data sets that have different

00:14:53,510 --> 00:14:57,690
expressivity levels it's just not

00:14:55,350 --> 00:15:00,450
feasible you cannot keep recording and

00:14:57,690 --> 00:15:03,780
recording and then try to imitate the

00:15:00,450 --> 00:15:06,270
the emotional emotional speech so we had

00:15:03,780 --> 00:15:08,910
to come up with another approach and

00:15:06,270 --> 00:15:12,570
what we did is a style importing so in

00:15:08,910 --> 00:15:14,670
this case we actually have a multi

00:15:12,570 --> 00:15:17,280
speaker say we created a multi speaker

00:15:14,670 --> 00:15:19,320
set that has expressivity from very

00:15:17,280 --> 00:15:20,820
little expressive to to very expressive

00:15:19,320 --> 00:15:22,140
I mean when I say expressive I don't

00:15:20,820 --> 00:15:24,360
know if you listen to like a children's

00:15:22,140 --> 00:15:26,250
audiobooks they're super expressive the

00:15:24,360 --> 00:15:27,960
voice of the idea the voice-over act

00:15:26,250 --> 00:15:29,760
which changes frequently goes up and

00:15:27,960 --> 00:15:31,410
down this cry sounds and everything so

00:15:29,760 --> 00:15:33,330
and then you need to find the right

00:15:31,410 --> 00:15:34,380
balance between this this multi speaker

00:15:33,330 --> 00:15:39,210
set

00:15:34,380 --> 00:15:43,230
- essentially extract different emotions

00:15:39,210 --> 00:15:45,510
and extract different emotions cluster

00:15:43,230 --> 00:15:47,820
them together and then come up with the

00:15:45,510 --> 00:15:51,600
you will get and tag your expressivity

00:15:47,820 --> 00:15:54,810
cells emotions such as happy angry sad

00:15:51,600 --> 00:15:56,580
all of these and then we are able to

00:15:54,810 --> 00:15:58,440
extract these and tokenize this so we

00:15:56,580 --> 00:16:00,870
can take these tokens and embed it on

00:15:58,440 --> 00:16:05,070
top of the the base force so by doing

00:16:00,870 --> 00:16:07,860
that a base force that the 24 hour hour

00:16:05,070 --> 00:16:10,020
was that that we did who never actually

00:16:07,860 --> 00:16:12,210
spoke in an emotional state or an

00:16:10,020 --> 00:16:14,910
expressive state can actually start

00:16:12,210 --> 00:16:17,280
speaking in that state directly by

00:16:14,910 --> 00:16:20,280
emotions extracted from a completely

00:16:17,280 --> 00:16:22,320
different force so that was the that was

00:16:20,280 --> 00:16:23,820
the approach that we did that was the

00:16:22,320 --> 00:16:25,980
only way of doing it but that was the

00:16:23,820 --> 00:16:27,420
only feasible way of doing it so that's

00:16:25,980 --> 00:16:29,250
what we've been working on so that's why

00:16:27,420 --> 00:16:31,170
we have a single and multi speaker model

00:16:29,250 --> 00:16:33,390
single for creating a base post

00:16:31,170 --> 00:16:39,360
multi-speaker model for for emotion

00:16:33,390 --> 00:16:41,580
extraction and okay so while we're doing

00:16:39,360 --> 00:16:43,680
this so let's say one of the things the

00:16:41,580 --> 00:16:45,510
reason I'm presenting here is is is is

00:16:43,680 --> 00:16:47,520
that we've been working with IBM system

00:16:45,510 --> 00:16:48,240
beginning we actually happen to go to

00:16:47,520 --> 00:16:51,660
the first meetup

00:16:48,240 --> 00:16:55,710
your first meetup in January in London

00:16:51,660 --> 00:16:57,030
and you know we talked to we might

00:16:55,710 --> 00:16:59,400
actually my I wasn't there but my

00:16:57,030 --> 00:17:01,680
partner spoke to Chris and we started

00:16:59,400 --> 00:17:06,300
with power AI we actually rented a

00:17:01,680 --> 00:17:09,660
pariah box in in March of this year so

00:17:06,300 --> 00:17:11,220
we have a lot of cloud credits that were

00:17:09,660 --> 00:17:13,350
using with our credits from ADA will yes

00:17:11,220 --> 00:17:17,130
Google almost half a million dollars

00:17:13,350 --> 00:17:18,780
worth of credits but we actually liked

00:17:17,130 --> 00:17:21,600
it and we're only paying for this power

00:17:18,780 --> 00:17:23,130
a box that we have every month and

00:17:21,600 --> 00:17:24,630
because we're happy to do it mainly

00:17:23,130 --> 00:17:26,310
because it's it's very it's

00:17:24,630 --> 00:17:27,750
significantly different than what's out

00:17:26,310 --> 00:17:30,750
there what you can get on a double yes

00:17:27,750 --> 00:17:32,580
so there are so many advantages of it if

00:17:30,750 --> 00:17:35,100
you need to unit agree you can go read

00:17:32,580 --> 00:17:37,380
articles above about it but these are

00:17:35,100 --> 00:17:38,910
the three things that are have been very

00:17:37,380 --> 00:17:42,960
helpful to us and it's going to be

00:17:38,910 --> 00:17:44,520
helpful to us one is the NV link we have

00:17:42,960 --> 00:17:48,179
to train with a lot of data I mean

00:17:44,520 --> 00:17:50,490
originally they are training so single

00:17:48,179 --> 00:17:52,100
speaker said transient about used to

00:17:50,490 --> 00:17:54,779
train about three to four days

00:17:52,100 --> 00:17:57,480
multi-speaker said would train in almost

00:17:54,779 --> 00:18:01,740
seven to eight days so by switching to

00:17:57,480 --> 00:18:04,049
Amy Amy link we it reduced by 50%

00:18:01,740 --> 00:18:05,700
and I've read about different

00:18:04,049 --> 00:18:07,350
implementations I think that it can even

00:18:05,700 --> 00:18:10,110
go faster for different implementations

00:18:07,350 --> 00:18:13,470
but at least for our case it seems to

00:18:10,110 --> 00:18:16,080
make trainings twice as fast so that

00:18:13,470 --> 00:18:17,940
saves a lot of time especially you know

00:18:16,080 --> 00:18:21,450
we're a startup we're burning a lot of

00:18:17,940 --> 00:18:24,019
cash and like three four days for every

00:18:21,450 --> 00:18:27,210
training is it is a big amount to say so

00:18:24,019 --> 00:18:30,929
that has been helpful to us from from

00:18:27,210 --> 00:18:32,759
day one large model support is is an

00:18:30,929 --> 00:18:35,090
actually later thing we found out thanks

00:18:32,759 --> 00:18:38,759
to Chris again I called you about that

00:18:35,090 --> 00:18:42,960
we so most of our models actually fit in

00:18:38,759 --> 00:18:44,580
a single GPUs GPU and that's I think for

00:18:42,960 --> 00:18:47,159
production that's how it should work

00:18:44,580 --> 00:18:48,570
anyway but because we're trying to

00:18:47,159 --> 00:18:51,990
innovate because we're trying to do

00:18:48,570 --> 00:18:54,690
different things we try adding a lot of

00:18:51,990 --> 00:18:58,350
parameters to do to the model you know

00:18:54,690 --> 00:19:01,799
grow the models sometimes sometimes the

00:18:58,350 --> 00:19:03,869
past 100 gigabytes then an nvidia gpus

00:19:01,799 --> 00:19:06,379
16 gigabytes the new ones have 32 gigs

00:19:03,869 --> 00:19:09,869
which is not easy to get access but

00:19:06,379 --> 00:19:11,369
essentially you are limited with if you

00:19:09,869 --> 00:19:13,200
want to have a simple solution you're

00:19:11,369 --> 00:19:15,869
limited with 16 gigabytes to fit your

00:19:13,200 --> 00:19:17,249
model so large model support helped us

00:19:15,869 --> 00:19:19,470
there at least to to test different

00:19:17,249 --> 00:19:22,830
things where we can actually load

00:19:19,470 --> 00:19:25,409
everything in the memory of the of the

00:19:22,830 --> 00:19:27,419
box and then I send it basically takes

00:19:25,409 --> 00:19:29,789
chunks off of the model and then puts

00:19:27,419 --> 00:19:31,919
them into into GPUs and then does its

00:19:29,789 --> 00:19:34,379
training that way so because of the NB

00:19:31,919 --> 00:19:36,389
link and plus large model support this

00:19:34,379 --> 00:19:38,999
works seamlessly and it's it's really

00:19:36,389 --> 00:19:43,320
fast as if it's it's communicating

00:19:38,999 --> 00:19:45,869
between the two to nvd gps and the third

00:19:43,320 --> 00:19:48,570
one is linear scalability so we're not

00:19:45,869 --> 00:19:49,980
using it yet we're still pre-production

00:19:48,570 --> 00:19:53,610
we're trying to go production end of

00:19:49,980 --> 00:19:55,619
this month by creating our first few

00:19:53,610 --> 00:19:58,490
audio audio books and then publishing

00:19:55,619 --> 00:20:00,509
them so linear scalability is

00:19:58,490 --> 00:20:01,830
essentially our process is completely

00:20:00,509 --> 00:20:04,440
GPU dependence

00:20:01,830 --> 00:20:07,620
right now if you got a they will your

00:20:04,440 --> 00:20:09,690
school you can get for GPS or hgp setups

00:20:07,620 --> 00:20:12,480
that are very expensive by the way and

00:20:09,690 --> 00:20:14,190
then if you need to scale more than that

00:20:12,480 --> 00:20:15,780
you need to get three four five six

00:20:14,190 --> 00:20:18,750
different systems and it becomes super

00:20:15,780 --> 00:20:21,690
expensive so with linear scalability

00:20:18,750 --> 00:20:23,340
with power AI we have one box right now

00:20:21,690 --> 00:20:26,340
a server but we're actually talking to

00:20:23,340 --> 00:20:28,170
to get another one and then in the next

00:20:26,340 --> 00:20:31,290
month so the way they work I guess you

00:20:28,170 --> 00:20:33,540
can you guys can clarify it if I'm wrong

00:20:31,290 --> 00:20:35,790
but you can put two servers next to each

00:20:33,540 --> 00:20:38,160
other and connect them via do via a

00:20:35,790 --> 00:20:42,810
special link I guess and then you can

00:20:38,160 --> 00:20:44,550
scale it up up to 256 GPUs that run as

00:20:42,810 --> 00:20:48,060
one system so this is great for a

00:20:44,550 --> 00:20:50,730
production level scalability so that's

00:20:48,060 --> 00:20:58,670
that's basically our choice when we go

00:20:50,730 --> 00:21:06,660
production all right so all right a

00:20:58,670 --> 00:21:10,500
little bit more a little more on the

00:21:06,660 --> 00:21:14,190
business side so we are not trying to

00:21:10,500 --> 00:21:16,410
stay as a technology company only we

00:21:14,190 --> 00:21:19,050
from day one we actually wanted to have

00:21:16,410 --> 00:21:21,510
a tech company that feeds our actual

00:21:19,050 --> 00:21:24,060
business of creating audio books so with

00:21:21,510 --> 00:21:27,600
the numbers that I've already told you

00:21:24,060 --> 00:21:29,760
sixty six to eight weeks we are able to

00:21:27,600 --> 00:21:32,010
build an audio book a 10-hour audio book

00:21:29,760 --> 00:21:33,330
under two hours right now so compared to

00:21:32,010 --> 00:21:38,490
six to eight weeks that's that's a big

00:21:33,330 --> 00:21:40,650
improvement we're trying to we're gonna

00:21:38,490 --> 00:21:42,500
try and increase the quality we're still

00:21:40,650 --> 00:21:44,820
probably a few weeks away from doing it

00:21:42,500 --> 00:21:47,340
which is gonna slow down the process a

00:21:44,820 --> 00:21:49,380
little but with parallel processing and

00:21:47,340 --> 00:21:51,360
different metal methodologies we're able

00:21:49,380 --> 00:21:55,020
to synthesize a speech about ten times

00:21:51,360 --> 00:21:56,880
the speed of real-time so if you don't

00:21:55,020 --> 00:21:58,320
know what it means is if a speech is ten

00:21:56,880 --> 00:22:01,890
seconds long we're able to synthesize

00:21:58,320 --> 00:22:03,450
that speech in one second so that with

00:22:01,890 --> 00:22:06,840
that a 10 hour audio book we can

00:22:03,450 --> 00:22:10,440
actually synthesize in one hour so by

00:22:06,840 --> 00:22:13,050
doing that we have the capability and

00:22:10,440 --> 00:22:15,410
the capacity to build as many audiobooks

00:22:13,050 --> 00:22:18,200
as we want as much as this

00:22:15,410 --> 00:22:21,950
for audiobooks in a day compared to what

00:22:18,200 --> 00:22:23,510
audible has today is about 450,000 total

00:22:21,950 --> 00:22:26,750
in the they built in the past eight nine

00:22:23,510 --> 00:22:29,920
years and then there's the second one

00:22:26,750 --> 00:22:31,880
after that is they have about 250,000 so

00:22:29,920 --> 00:22:33,920
essentially we're building a capacity to

00:22:31,880 --> 00:22:35,570
do that Oh obviously it's not gonna be

00:22:33,920 --> 00:22:36,830
that easy because the first ones we're

00:22:35,570 --> 00:22:39,940
always gonna need to Quality Assurance

00:22:36,830 --> 00:22:41,990
because they're gonna be times that that

00:22:39,940 --> 00:22:44,950
you know sometimes some of the

00:22:41,990 --> 00:22:47,750
pronunciations are not not done well you

00:22:44,950 --> 00:22:50,120
know so many things that need to be q8

00:22:47,750 --> 00:22:51,860
at the beginning so one our synthesis

00:22:50,120 --> 00:22:53,720
time but it's probably gonna add seven

00:22:51,860 --> 00:22:55,850
eight hours of quality assurance time on

00:22:53,720 --> 00:22:57,350
top of it at least at the beginning but

00:22:55,850 --> 00:23:00,890
our our goal is if we can actually

00:22:57,350 --> 00:23:02,930
perfect this algorithm that the model we

00:23:00,890 --> 00:23:07,130
can do it without quality assurance in

00:23:02,930 --> 00:23:09,170
in in an hour so so that creates

00:23:07,130 --> 00:23:12,380
obviously another business model for us

00:23:09,170 --> 00:23:16,610
is is is is we would like to we are

00:23:12,380 --> 00:23:19,280
actually launching our own on audio book

00:23:16,610 --> 00:23:20,860
store called audio elle.com or hopefully

00:23:19,280 --> 00:23:23,690
be launching it by the end of this month

00:23:20,860 --> 00:23:25,790
we already talking to publishers we're

00:23:23,690 --> 00:23:28,760
talking to agents we're talking to

00:23:25,790 --> 00:23:30,230
narrators for narrator so voiceover I

00:23:28,760 --> 00:23:32,360
want to make dissapoint so we're not

00:23:30,230 --> 00:23:34,100
trying to replace any voice-over artist

00:23:32,360 --> 00:23:35,810
voice that's not what we're doing we're

00:23:34,100 --> 00:23:38,630
actually lie sing we're talking to them

00:23:35,810 --> 00:23:42,170
and licensing their voice you know one

00:23:38,630 --> 00:23:43,700
by one so that we can they can actually

00:23:42,170 --> 00:23:44,960
make money off of like it with their

00:23:43,700 --> 00:23:47,990
revenue sharing model they can actually

00:23:44,960 --> 00:23:50,480
make money without ever having to record

00:23:47,990 --> 00:23:52,070
it so that's that's one of the things

00:23:50,480 --> 00:23:53,870
that we're we're careful about because a

00:23:52,070 --> 00:23:55,520
lot of times we'll get feedback from a

00:23:53,870 --> 00:23:57,350
voice-over artist out there that we're

00:23:55,520 --> 00:24:00,680
killing their jobs but that's not what

00:23:57,350 --> 00:24:02,840
we're trying to do so as I want to

00:24:00,680 --> 00:24:04,730
emphasize on that because you know they

00:24:02,840 --> 00:24:08,720
say AI is gonna kill everything so we're

00:24:04,730 --> 00:24:11,710
trying not to and so we're working with

00:24:08,720 --> 00:24:13,610
publishers literary agents writers and

00:24:11,710 --> 00:24:16,970
what we're gonna do is we're going to

00:24:13,610 --> 00:24:19,430
start with we don't wanna start directly

00:24:16,970 --> 00:24:21,050
with only a synthesis synthetic voice

00:24:19,430 --> 00:24:24,080
content we actually wanted to mix and

00:24:21,050 --> 00:24:26,630
match so we are working with a with a

00:24:24,080 --> 00:24:27,920
company to license their existing audio

00:24:26,630 --> 00:24:28,780
books we're going to launch with that

00:24:27,920 --> 00:24:31,210
and then

00:24:28,780 --> 00:24:33,160
Julie start adding our own content our

00:24:31,210 --> 00:24:35,020
focus is going to be slightly different

00:24:33,160 --> 00:24:39,040
we don't want to be a direct oral

00:24:35,020 --> 00:24:41,110
competitor but we want to have some

00:24:39,040 --> 00:24:42,400
human recorded and synthetic but we

00:24:41,110 --> 00:24:45,850
actually want to work more with

00:24:42,400 --> 00:24:48,970
independent authors so a lot of existing

00:24:45,850 --> 00:24:50,410
authors that you know they already have

00:24:48,970 --> 00:24:52,390
the means to be able to create their

00:24:50,410 --> 00:24:55,930
only audiobooks so four to five thousand

00:24:52,390 --> 00:24:57,790
dollars is not cheap but it's not a it's

00:24:55,930 --> 00:24:59,830
not an enormous amount so but a lot of

00:24:57,790 --> 00:25:04,180
independent authors and there's so many

00:24:59,830 --> 00:25:07,270
of them on sites like Wattpad com that

00:25:04,180 --> 00:25:09,310
are very popular in social media but

00:25:07,270 --> 00:25:11,500
nobody ever knows of them and all of

00:25:09,310 --> 00:25:13,720
them so we would like to actually work

00:25:11,500 --> 00:25:15,550
with them and then give them the ability

00:25:13,720 --> 00:25:16,660
to create their audiobooks with fraction

00:25:15,550 --> 00:25:19,360
of the cost and we were talking about

00:25:16,660 --> 00:25:20,470
well we can actually in some in some

00:25:19,360 --> 00:25:22,060
sense we actually want to give it a very

00:25:20,470 --> 00:25:25,900
complete for free and then do a

00:25:22,060 --> 00:25:28,090
different licensing agreement so so we

00:25:25,900 --> 00:25:30,520
have that you know technology view we

00:25:28,090 --> 00:25:32,550
have the business view and we would like

00:25:30,520 --> 00:25:34,840
to and when the technology is out there

00:25:32,550 --> 00:25:38,710
we would like to capitalize on it as

00:25:34,840 --> 00:25:41,380
fast as we can so all this that we're

00:25:38,710 --> 00:25:43,930
doing essentially what it does is you

00:25:41,380 --> 00:25:45,990
know it's speed and cost we can do in

00:25:43,930 --> 00:25:49,360
hours rather than six to eight weeks a

00:25:45,990 --> 00:25:51,220
fraction of the cost and we have and the

00:25:49,360 --> 00:25:53,740
other thing is when I said one hour

00:25:51,220 --> 00:25:56,740
that's for one voice one so if you add

00:25:53,740 --> 00:25:58,240
if you want to do multiple voices it's

00:25:56,740 --> 00:26:00,520
another hour if you want to do multiple

00:25:58,240 --> 00:26:03,700
accent it's another you can add another

00:26:00,520 --> 00:26:04,990
hour on top of it what we can do we will

00:26:03,700 --> 00:26:07,240
have the capability of building

00:26:04,990 --> 00:26:09,640
interactive more interactive audio books

00:26:07,240 --> 00:26:11,440
where actually every character has a

00:26:09,640 --> 00:26:13,480
different force so we would like to give

00:26:11,440 --> 00:26:16,030
that ability so as it's like you're

00:26:13,480 --> 00:26:17,680
listening to a theater on the radio so

00:26:16,030 --> 00:26:19,390
that's that that can open up new doors

00:26:17,680 --> 00:26:22,720
and we're gonna go a little bit further

00:26:19,390 --> 00:26:24,340
beyond that is not necessarily wouldn't

00:26:22,720 --> 00:26:26,290
the AI just go but while they're

00:26:24,340 --> 00:26:27,730
listening to an audiobook if it's on

00:26:26,290 --> 00:26:30,970
your mobile form you would like to give

00:26:27,730 --> 00:26:33,340
you visual and feedbacks or written

00:26:30,970 --> 00:26:34,810
feedbacks on the screen about I don't

00:26:33,340 --> 00:26:37,930
know if T if the the book is about

00:26:34,810 --> 00:26:39,760
somewhere in Geneva and you're gonna

00:26:37,930 --> 00:26:42,130
need to visualize it so we would like to

00:26:39,760 --> 00:26:42,550
be able to do that in real time while

00:26:42,130 --> 00:26:44,800
they're action

00:26:42,550 --> 00:26:46,840
listen listening to it so there's a lot

00:26:44,800 --> 00:26:49,090
of things that just because we're saving

00:26:46,840 --> 00:26:50,710
a lot of cost and money you know it's

00:26:49,090 --> 00:26:52,930
going to give us the ability to add a

00:26:50,710 --> 00:26:57,900
lot more other functionalities that do

00:26:52,930 --> 00:27:02,010
not exist out there today one slide is

00:26:57,900 --> 00:27:05,010
about yeah so did I talked about

00:27:02,010 --> 00:27:08,470
audiobooks a lot and quickly other

00:27:05,010 --> 00:27:09,580
applications are the voice over apps it

00:27:08,470 --> 00:27:12,310
were talking to a lot of marketing

00:27:09,580 --> 00:27:15,160
companies and and they loved the idea to

00:27:12,310 --> 00:27:18,280
be able to create a voiceover for their

00:27:15,160 --> 00:27:20,470
two-minute video in less than 10 minutes

00:27:18,280 --> 00:27:23,290
by picking the voice they want and

00:27:20,470 --> 00:27:24,550
modifying during synthesis time we're

00:27:23,290 --> 00:27:26,350
talking the gaming companies we're

00:27:24,550 --> 00:27:29,410
actually writing plug-ins for unity and

00:27:26,350 --> 00:27:31,390
Unreal Engine so a game developer can

00:27:29,410 --> 00:27:33,550
while developing the game they can

00:27:31,390 --> 00:27:35,260
actually put the script in the code

00:27:33,550 --> 00:27:36,850
synthesize it and directly have it

00:27:35,260 --> 00:27:38,740
embedded in the indie game itself

00:27:36,850 --> 00:27:41,800
without having to ever exit their

00:27:38,740 --> 00:27:43,480
development environment and you know

00:27:41,800 --> 00:27:48,970
there are a lot of applications as you

00:27:43,480 --> 00:27:51,190
can imagine so quick roadmap is so we we

00:27:48,970 --> 00:27:52,990
finished end to end an LP two TTS

00:27:51,190 --> 00:27:54,880
integration human-like acoustic quality

00:27:52,990 --> 00:27:57,910
I'm gonna play you samples in a minute

00:27:54,880 --> 00:28:00,880
emotional an expressive speech we are

00:27:57,910 --> 00:28:04,330
able to control it from NLP as well so

00:28:00,880 --> 00:28:05,830
our NLP decides you should send it tell

00:28:04,330 --> 00:28:08,650
the TTS you should synthesize it this

00:28:05,830 --> 00:28:10,330
way but as the owner of the of the

00:28:08,650 --> 00:28:12,220
article if you don't like it that way

00:28:10,330 --> 00:28:14,260
we're gonna give them the ability to

00:28:12,220 --> 00:28:16,420
change make modifications and the

00:28:14,260 --> 00:28:19,180
emotion index and then resent the size

00:28:16,420 --> 00:28:22,330
until they actually like it we're

00:28:19,180 --> 00:28:24,940
launching our marketplace this quarter

00:28:22,330 --> 00:28:26,350
and we're working on speech synthesis on

00:28:24,940 --> 00:28:29,530
mobile devices which is going to be

00:28:26,350 --> 00:28:33,130
become critical because this is a very

00:28:29,530 --> 00:28:36,310
computing power intensive and for and

00:28:33,130 --> 00:28:38,470
for an application on mobile devices we

00:28:36,310 --> 00:28:39,610
cannot keep synthesizing on the server

00:28:38,470 --> 00:28:41,260
especially when you're talking about

00:28:39,610 --> 00:28:43,210
hundreds of thousand millions of devices

00:28:41,260 --> 00:28:45,250
so we're working on a solution to be

00:28:43,210 --> 00:28:49,690
able to synthesize directly on the on

00:28:45,250 --> 00:28:50,860
the mobile CPU at the and then next year

00:28:49,690 --> 00:28:52,720
we're gonna be adding new language

00:28:50,860 --> 00:28:55,700
supports currently we're on in English

00:28:52,720 --> 00:28:57,169
and again we're

00:28:55,700 --> 00:28:58,700
before consumed on the real time speech

00:28:57,169 --> 00:29:01,580
synthesis for real-time applications

00:28:58,700 --> 00:29:03,559
right now our focus is a bad synthesis

00:29:01,580 --> 00:29:04,370
because that's what is needed for

00:29:03,559 --> 00:29:06,230
audiobooks

00:29:04,370 --> 00:29:08,929
you don't need real-time synthesis and

00:29:06,230 --> 00:29:10,580
the next year what we were working on so

00:29:08,929 --> 00:29:14,419
how I mentioned the single speaker model

00:29:10,580 --> 00:29:16,789
we're creating a base voice from 20 24

00:29:14,419 --> 00:29:21,200
hours of boys we're actually trying to

00:29:16,789 --> 00:29:22,850
reduce it down to 5 minutes and that's

00:29:21,200 --> 00:29:25,309
where the voice cloning and adaptation

00:29:22,850 --> 00:29:27,080
is gonna come in handy so if you can

00:29:25,309 --> 00:29:28,909
have applications where you can record

00:29:27,080 --> 00:29:31,399
your voice for 5 minutes on your mobile

00:29:28,909 --> 00:29:33,380
phone and you'll be able to you'll be

00:29:31,399 --> 00:29:35,240
able to duplicate that voice right now

00:29:33,380 --> 00:29:37,700
this need right now the technology is

00:29:35,240 --> 00:29:39,620
not it's we've done it we've done it

00:29:37,700 --> 00:29:41,149
with 20 minutes you can actually hear

00:29:39,620 --> 00:29:42,710
the person's voice that it's definitely

00:29:41,149 --> 00:29:45,230
heard but the quality of the voice is

00:29:42,710 --> 00:29:47,000
not that great so it's it's you know

00:29:45,230 --> 00:29:48,679
there are different reasons for that one

00:29:47,000 --> 00:29:50,480
of them is the size of the multi CPU

00:29:48,679 --> 00:29:52,669
need a lot of data to be able to clone

00:29:50,480 --> 00:29:56,659
from so that's gonna take care take some

00:29:52,669 --> 00:30:00,230
time to put together and couple sample

00:29:56,659 --> 00:30:02,510
voices that just gonna play a couple

00:30:00,230 --> 00:30:08,330
sentences we synthesized randomly from

00:30:02,510 --> 00:30:09,940
books traditions in art schools provided

00:30:08,330 --> 00:30:13,279
an atmosphere of experimentation

00:30:09,940 --> 00:30:14,899
personal creativity and hip culture that

00:30:13,279 --> 00:30:17,240
were totally lacking in the formal

00:30:14,899 --> 00:30:19,760
Conservatoire atmospheres and for music

00:30:17,240 --> 00:30:22,130
schools in all these respects the art

00:30:19,760 --> 00:30:26,990
colleges provide an unexpected breeding

00:30:22,130 --> 00:30:30,649
ground for rock culture the pedagogics

00:30:26,990 --> 00:30:32,779
tradition as a replacement the Byrne

00:30:30,649 --> 00:30:35,210
bought in some oddball named Ringo Starr

00:30:32,779 --> 00:30:37,940
blingo was older and had a big funny

00:30:35,210 --> 00:30:40,010
nose we go a boy to get the same re

00:30:37,940 --> 00:30:41,840
haircut as John Paul and George and

00:30:40,010 --> 00:30:44,870
insisted on writing songs about

00:30:41,840 --> 00:30:46,450
octopuses and submarines there's a bunch

00:30:44,870 --> 00:30:50,299
of other samples but essentially this is

00:30:46,450 --> 00:30:52,909
completely synthetic voice so hopefully

00:30:50,299 --> 00:30:57,200
it'll get even better soon enough and

00:30:52,909 --> 00:30:58,820
that's it I did yeah 41 minutes well

00:30:57,200 --> 00:31:01,120
actually you know not if like half an

00:30:58,820 --> 00:31:01,120

YouTube URL: https://www.youtube.com/watch?v=kaNKxfTjpzQ


