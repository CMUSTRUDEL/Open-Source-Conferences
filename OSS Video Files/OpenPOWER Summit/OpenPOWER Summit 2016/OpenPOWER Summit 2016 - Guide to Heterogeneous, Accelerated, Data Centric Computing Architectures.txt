Title: OpenPOWER Summit 2016 - Guide to Heterogeneous, Accelerated, Data Centric Computing Architectures
Publication date: 2016-04-29
Playlist: OpenPOWER Summit 2016
Description: 
	Presented by Allan Cantle of Nallatech
Captions: 
	00:00:01,159 --> 00:00:06,450
okay hi everybody my name is Alan can

00:00:04,740 --> 00:00:09,540
tell and I'm president and founder of

00:00:06,450 --> 00:00:12,450
nanotech we specialize in data-centric

00:00:09,540 --> 00:00:17,010
Computing's were specifically using fpga

00:00:12,450 --> 00:00:19,430
technology and today basically I want to

00:00:17,010 --> 00:00:21,990
talk about it's really a one on one died

00:00:19,430 --> 00:00:23,369
this may seem a little bit orders to

00:00:21,990 --> 00:00:25,500
some people but heterogeneous are

00:00:23,369 --> 00:00:30,420
accelerated data-centric computing we've

00:00:25,500 --> 00:00:32,940
been talking about that all day but I

00:00:30,420 --> 00:00:35,880
sort of feel that there's a lot of

00:00:32,940 --> 00:00:37,800
acronyms going on we hear many of these

00:00:35,880 --> 00:00:39,570
acronyms and I'm sure all of us

00:00:37,800 --> 00:00:42,540
understand some of them to greater or

00:00:39,570 --> 00:00:44,430
lesser degree but um what do they all

00:00:42,540 --> 00:00:46,260
mean in what context and what was what's

00:00:44,430 --> 00:00:49,680
really going on here so I want to really

00:00:46,260 --> 00:00:51,329
give a story of where we've been in the

00:00:49,680 --> 00:00:55,170
world of computing and where we're going

00:00:51,329 --> 00:00:57,690
and i think really if you look at the

00:00:55,170 --> 00:00:59,699
computers of today they still pretty

00:00:57,690 --> 00:01:02,489
pretty much look like they did 10 years

00:00:59,699 --> 00:01:05,220
ago but we're all talking data centric

00:01:02,489 --> 00:01:07,590
and I think open powers taking us to a

00:01:05,220 --> 00:01:09,030
real much more data centric world and

00:01:07,590 --> 00:01:13,049
and that's what i would like to

00:01:09,030 --> 00:01:15,240
articulate today so right back in in the

00:01:13,049 --> 00:01:17,220
history fruit processor centric

00:01:15,240 --> 00:01:21,360
evolution we've lived in a process known

00:01:17,220 --> 00:01:22,860
centric world for well over 30 years and

00:01:21,360 --> 00:01:25,470
it's a there's really been a laser focus

00:01:22,860 --> 00:01:27,330
on increasing ops and flops and and

00:01:25,470 --> 00:01:29,220
that's been the main the main driver and

00:01:27,330 --> 00:01:33,950
the data is really played second-class

00:01:29,220 --> 00:01:36,299
citizen but way back in 1977 john backus

00:01:33,950 --> 00:01:39,450
coined the von Neumann bottleneck of

00:01:36,299 --> 00:01:41,009
getting data to and from the cpu I won't

00:01:39,450 --> 00:01:42,689
read that paragraph out there but if

00:01:41,009 --> 00:01:45,750
you'd look at it later it's very

00:01:42,689 --> 00:01:49,170
applicable to today uncannily actually

00:01:45,750 --> 00:01:51,299
when i read it so intel way back in

00:01:49,170 --> 00:01:54,360
nineteen eighty-five introd in with

00:01:51,299 --> 00:01:56,219
their free 86 introduced external cache

00:01:54,360 --> 00:01:59,520
memory for the first time on the x86

00:01:56,219 --> 00:02:02,310
architecture and really ever so ever

00:01:59,520 --> 00:02:03,540
since there and as the clock speed of

00:02:02,310 --> 00:02:06,090
the processors been getting longer

00:02:03,540 --> 00:02:07,710
faster and faster the relative distance

00:02:06,090 --> 00:02:10,020
of the data have been getting further

00:02:07,710 --> 00:02:11,790
and further away exacerbating the

00:02:10,020 --> 00:02:13,600
problem but sure we've had a fix for

00:02:11,790 --> 00:02:16,660
that year after year after you

00:02:13,600 --> 00:02:19,540
they're increasing levels of cash exotic

00:02:16,660 --> 00:02:22,960
local disk disk ashes operating system

00:02:19,540 --> 00:02:24,880
tricks and virtualization overhead is

00:02:22,960 --> 00:02:27,340
been coming around making multiple

00:02:24,880 --> 00:02:29,860
copies of this memory so this is all

00:02:27,340 --> 00:02:33,820
well and good but really 30 years of

00:02:29,860 --> 00:02:35,980
this same solution is fighting this von

00:02:33,820 --> 00:02:38,890
Neumann bottleneck is really become a

00:02:35,980 --> 00:02:42,820
crutch that we entirely rely on is an

00:02:38,890 --> 00:02:45,190
industry today and we can't break this

00:02:42,820 --> 00:02:48,610
correct this crutch without breaking the

00:02:45,190 --> 00:02:54,190
entire system so it's not something we

00:02:48,610 --> 00:02:56,980
can throw away so just take a look at it

00:02:54,190 --> 00:02:58,540
in another sense this is a an abstract

00:02:56,980 --> 00:03:00,550
view of the CPU at the heart of the

00:02:58,540 --> 00:03:02,680
world with all of its layers of memory

00:03:00,550 --> 00:03:04,090
around it in the far right-hand side

00:03:02,680 --> 00:03:06,760
you've got your Nash you're big you're

00:03:04,090 --> 00:03:08,730
big storage engine and if we take a look

00:03:06,760 --> 00:03:11,890
at the look at the path of our data

00:03:08,730 --> 00:03:14,140
typically today comes through the neck

00:03:11,890 --> 00:03:16,450
for the PC are interfacing gets copied

00:03:14,140 --> 00:03:18,520
into the multiple levels of cache gets

00:03:16,450 --> 00:03:22,750
copied back out to memory and and and it

00:03:18,520 --> 00:03:25,900
may be into this storage what happened

00:03:22,750 --> 00:03:27,820
there ok so just taking a look at our

00:03:25,900 --> 00:03:30,210
repeat myself here just take a look at a

00:03:27,820 --> 00:03:33,580
millisecond in the life of your data

00:03:30,210 --> 00:03:37,270
starting out in your in your network

00:03:33,580 --> 00:03:39,460
attached storage basically it travels in

00:03:37,270 --> 00:03:41,110
for the Nick for the PCI interface gets

00:03:39,460 --> 00:03:45,490
copied into the multiple levels of cash

00:03:41,110 --> 00:03:47,530
in actually your memory and and and

00:03:45,490 --> 00:03:50,710
potentially additional discs caches etc

00:03:47,530 --> 00:03:53,080
or local local disks so there's many

00:03:50,710 --> 00:03:57,580
there's much copying going on here all

00:03:53,080 --> 00:03:59,830
in the name of coherency and really in

00:03:57,580 --> 00:04:01,480
reality the CPU is really efficient when

00:03:59,830 --> 00:04:04,570
it's working out of level one cache you

00:04:01,480 --> 00:04:07,210
can't beat it but it's very distant from

00:04:04,570 --> 00:04:08,530
from from its primary data store that's

00:04:07,210 --> 00:04:16,480
the bottom line of where we've ended up

00:04:08,530 --> 00:04:18,460
to out today so just going back to this

00:04:16,480 --> 00:04:20,739
slide the processor centric legacy we

00:04:18,460 --> 00:04:22,060
live in so we've got memory copying in

00:04:20,739 --> 00:04:23,740
data movement he's going all the time

00:04:22,060 --> 00:04:27,070
and that's really where the most power

00:04:23,740 --> 00:04:29,140
gets burnt in a system again

00:04:27,070 --> 00:04:32,170
rating CPU and level one cache is very

00:04:29,140 --> 00:04:34,510
low power and non-volatile data is

00:04:32,170 --> 00:04:36,910
actually 0 power so all of the power in

00:04:34,510 --> 00:04:40,090
our computing systems is is spent in

00:04:36,910 --> 00:04:42,310
moving this data to and from that the

00:04:40,090 --> 00:04:47,280
processor and this is this is a

00:04:42,310 --> 00:04:50,830
well-understood problem so really back

00:04:47,280 --> 00:04:52,660
maybe 10 years ago or more Google were

00:04:50,830 --> 00:04:54,190
probably the first to really take a look

00:04:52,660 --> 00:04:55,600
at data centric computing because they

00:04:54,190 --> 00:04:58,180
have a big data problem or the sleeve of

00:04:55,600 --> 00:05:00,280
the internet etc in the search and they

00:04:58,180 --> 00:05:04,330
put the focus on this but they played

00:05:00,280 --> 00:05:05,770
with the system level components in turn

00:05:04,330 --> 00:05:07,180
in terms of trying to make the process

00:05:05,770 --> 00:05:09,490
or a bit closer to the data they

00:05:07,180 --> 00:05:10,810
restructured you know we all we all know

00:05:09,490 --> 00:05:13,450
what they've done with Matt with

00:05:10,810 --> 00:05:15,730
MapReduce over the years now and that's

00:05:13,450 --> 00:05:17,560
that was that the beginnings of trying

00:05:15,730 --> 00:05:20,320
to make this the CPU centric

00:05:17,560 --> 00:05:23,560
architectures more more more friendly to

00:05:20,320 --> 00:05:26,290
data centric applications additionally

00:05:23,560 --> 00:05:27,850
what happened was was some of these

00:05:26,290 --> 00:05:31,870
buzzwords and acronyms you here read

00:05:27,850 --> 00:05:34,060
many times over our DM ad pdk I warp all

00:05:31,870 --> 00:05:38,320
of these techniques are ways of trying

00:05:34,060 --> 00:05:40,600
to circumvent their circumvention

00:05:38,320 --> 00:05:42,430
strategies over a lot of this copying

00:05:40,600 --> 00:05:44,770
trying to improve performance and

00:05:42,430 --> 00:05:48,130
minimize power or any unnecessary

00:05:44,770 --> 00:05:51,850
copying as also was talked about by by

00:05:48,130 --> 00:05:53,320
John earlier so really essentially today

00:05:51,850 --> 00:05:56,830
we're living as we're still living in

00:05:53,320 --> 00:05:59,050
the process of centric world there is it

00:05:56,830 --> 00:06:01,080
is being adapted for for data centric

00:05:59,050 --> 00:06:03,880
applications without completely breaking

00:06:01,080 --> 00:06:05,380
the traditional programming model for a

00:06:03,880 --> 00:06:06,700
good reason you know if we want me we

00:06:05,380 --> 00:06:10,960
can't really break the existing

00:06:06,700 --> 00:06:12,550
programming model so what about the

00:06:10,960 --> 00:06:13,990
accelerator side of it so that that was

00:06:12,550 --> 00:06:16,420
mainly in a data movement on the

00:06:13,990 --> 00:06:20,140
accelerator side we all know now that

00:06:16,420 --> 00:06:22,510
the GPU is is it is it is a king of

00:06:20,140 --> 00:06:24,700
acceleration and the FPGA is now now

00:06:22,510 --> 00:06:27,280
getting a lot better a lot more adoption

00:06:24,700 --> 00:06:29,110
as you've probably seen today GPU is a

00:06:27,280 --> 00:06:31,510
really traditional flop Alfred

00:06:29,110 --> 00:06:34,270
amplification historically and F pjs are

00:06:31,510 --> 00:06:36,730
the archetypal data-centric d prime line

00:06:34,270 --> 00:06:38,800
computing is where they really come into

00:06:36,730 --> 00:06:40,810
their own but really at the end of the

00:06:38,800 --> 00:06:43,030
days were increased in ops and flops

00:06:40,810 --> 00:06:44,530
and or keeping the data more local to

00:06:43,030 --> 00:06:48,130
the CPU these these subtly different

00:06:44,530 --> 00:06:50,889
architectures so but if we look at that

00:06:48,130 --> 00:06:53,470
our path of data again from a CPUs

00:06:50,889 --> 00:06:55,810
memory you took the traditional path is

00:06:53,470 --> 00:06:57,970
it what it would actually get copied to

00:06:55,810 --> 00:07:01,389
and fro the memory before it got passed

00:06:57,970 --> 00:07:02,950
to the accelerator or if I or if and one

00:07:01,389 --> 00:07:04,990
accelerator wanted to talk to the other

00:07:02,950 --> 00:07:07,720
accelerator it would have to go through

00:07:04,990 --> 00:07:09,910
the system memory twice and before

00:07:07,720 --> 00:07:11,980
getting to the accelerator so when in

00:07:09,910 --> 00:07:14,889
reality peer-to-peer has been supported

00:07:11,980 --> 00:07:16,870
in pci forever it never really got

00:07:14,889 --> 00:07:20,950
utilizing a PT in the cpu centric

00:07:16,870 --> 00:07:23,740
architecture but today you can have the

00:07:20,950 --> 00:07:26,889
peer-to-peer and and video of coin that

00:07:23,740 --> 00:07:29,950
GPU directed moving moving data directly

00:07:26,889 --> 00:07:31,630
between accelerators so really we're

00:07:29,950 --> 00:07:35,320
beginning to become more like peer

00:07:31,630 --> 00:07:38,050
processors and really really the the

00:07:35,320 --> 00:07:40,150
lines are becoming blurred between these

00:07:38,050 --> 00:07:43,300
different devices fpga routing

00:07:40,150 --> 00:07:45,760
processors GPUs are adding adding or

00:07:43,300 --> 00:07:49,210
they're becoming more processor like in

00:07:45,760 --> 00:07:51,430
their in their cores processors main

00:07:49,210 --> 00:07:57,370
CPUs are adding adding GPU capability

00:07:51,430 --> 00:07:59,740
and in reality even more so today as

00:07:57,370 --> 00:08:01,750
processors are pulling F pjs on board

00:07:59,740 --> 00:08:04,240
GPUs are introducing more streaming like

00:08:01,750 --> 00:08:06,340
functionality copy in the F pjs and even

00:08:04,240 --> 00:08:08,050
fpgas from darlings for instance their

00:08:06,340 --> 00:08:10,450
next generation will have some GPU

00:08:08,050 --> 00:08:11,979
content in it so the lungs are certainly

00:08:10,450 --> 00:08:14,530
blurring and these are becoming peer

00:08:11,979 --> 00:08:18,250
processors more than more than hosts and

00:08:14,530 --> 00:08:20,889
accelerator and really this is this was

00:08:18,250 --> 00:08:22,979
understood back in 1998 by our friends

00:08:20,889 --> 00:08:24,900
at DARPA and they coined the phrase

00:08:22,979 --> 00:08:26,770
polymorphic processor there was a

00:08:24,900 --> 00:08:29,919
processor that was good at all these

00:08:26,770 --> 00:08:32,080
different abstract data types and it

00:08:29,919 --> 00:08:34,089
looks like we're on a were really on a

00:08:32,080 --> 00:08:37,930
journey of invention towards this

00:08:34,089 --> 00:08:39,820
polymorphic processor that so open power

00:08:37,930 --> 00:08:41,919
you know what's it all about its data

00:08:39,820 --> 00:08:43,630
centric it really that the open power of

00:08:41,919 --> 00:08:46,420
foundation is taking data centric to the

00:08:43,630 --> 00:08:48,130
next level through collaboration IBM

00:08:46,420 --> 00:08:51,100
opened a Power Architecture at the chip

00:08:48,130 --> 00:08:52,790
level so there there are navy they're

00:08:51,100 --> 00:08:54,770
enabling really collab

00:08:52,790 --> 00:08:57,260
to offer a collaboration around

00:08:54,770 --> 00:08:58,870
polymorphic processor innovation is what

00:08:57,260 --> 00:09:01,280
we're well we're actually seeing there

00:08:58,870 --> 00:09:03,500
and the open power architecture has been

00:09:01,280 --> 00:09:05,180
opened up at the system level enabling

00:09:03,500 --> 00:09:07,310
data-centric system architecture

00:09:05,180 --> 00:09:09,590
innovation and really changing the game

00:09:07,310 --> 00:09:12,230
on how processors accelerators memory

00:09:09,590 --> 00:09:15,350
storage and networking interact with

00:09:12,230 --> 00:09:16,880
each other and certainly for nanotech

00:09:15,350 --> 00:09:20,180
I'm shorts and colleagues out in the

00:09:16,880 --> 00:09:21,980
audience they're allowing data centric

00:09:20,180 --> 00:09:23,180
computing experts like now I set we've

00:09:21,980 --> 00:09:25,760
been doing this for over 20 years

00:09:23,180 --> 00:09:28,130
data-centric computing to have a voice

00:09:25,760 --> 00:09:31,100
and actually be heard and I'm contribute

00:09:28,130 --> 00:09:34,400
to this this this community so a little

00:09:31,100 --> 00:09:37,490
bit about nanotech we focus on fpga

00:09:34,400 --> 00:09:40,820
accelerators we were the first Cappy

00:09:37,490 --> 00:09:43,940
Cappy enabled accelerator back that last

00:09:40,820 --> 00:09:45,680
year a couple of years ago with a

00:09:43,940 --> 00:09:47,330
network attacks the acceleration it was

00:09:45,680 --> 00:09:49,400
good for compression encryption

00:09:47,330 --> 00:09:51,830
financial services as you heard some

00:09:49,400 --> 00:09:55,340
some presentations today and intrusion

00:09:51,830 --> 00:09:57,200
detection etc and we have compute

00:09:55,340 --> 00:10:00,350
acceleration at the other end in this

00:09:57,200 --> 00:10:02,630
this is a GPU form factor occurred with

00:10:00,350 --> 00:10:04,280
dual FPGA xinhai memory bandwidth good

00:10:02,630 --> 00:10:06,410
for all in gas migration algorithms

00:10:04,280 --> 00:10:08,480
machine learning video encoding and

00:10:06,410 --> 00:10:10,130
bioinformatics there's a couple of

00:10:08,480 --> 00:10:12,050
examples and today I'd like to announce

00:10:10,130 --> 00:10:14,180
as you seen the Mersenne on the show

00:10:12,050 --> 00:10:16,760
floor already we've now into we've now

00:10:14,180 --> 00:10:20,080
completed the set of inline acceleration

00:10:16,760 --> 00:10:23,000
so to speak with our storage accelerator

00:10:20,080 --> 00:10:25,250
which is Cappy enabled in collaboration

00:10:23,000 --> 00:10:29,090
with IBM which is a single lars i'll

00:10:25,250 --> 00:10:32,540
accept pga with two terabytes of nvme

00:10:29,090 --> 00:10:34,280
flash attached to that fpga this is a

00:10:32,540 --> 00:10:36,520
this is great for in-memory database

00:10:34,280 --> 00:10:38,690
applications in line compression and

00:10:36,520 --> 00:10:40,880
installing the algorithm acceleration

00:10:38,690 --> 00:10:45,320
lost at lots of different acceleration

00:10:40,880 --> 00:10:49,310
ideas to come additionally not in europe

00:10:45,320 --> 00:10:52,340
nanotech is a the EU deve government is

00:10:49,310 --> 00:10:55,780
funded some exascale research programs

00:10:52,340 --> 00:10:59,240
and data centric computing programs and

00:10:55,780 --> 00:11:01,460
nanotech is the key partner in that in

00:10:59,240 --> 00:11:04,490
that in that consortium with IBM and

00:11:01,460 --> 00:11:05,070
hewlett-packard enterprise and are we we

00:11:04,490 --> 00:11:09,260
have a

00:11:05,070 --> 00:11:11,610
a Cappy flash card sorry big Cappy

00:11:09,260 --> 00:11:14,790
network-attached card for actually

00:11:11,610 --> 00:11:16,980
bringing Kathy to non tu non kappa to

00:11:14,790 --> 00:11:19,230
turn on power architectures so this is

00:11:16,980 --> 00:11:23,340
an IBM power8 box being coupled to a

00:11:19,230 --> 00:11:24,780
moonshot a box from from from HP with

00:11:23,340 --> 00:11:27,030
with our capping the accelerator

00:11:24,780 --> 00:11:28,230
technology and we're exploring some

00:11:27,030 --> 00:11:32,630
different algorithms with that

00:11:28,230 --> 00:11:32,630
consortium over the next couple of years

00:11:34,820 --> 00:11:39,000
so I just like to leave you with a

00:11:37,830 --> 00:11:41,010
little bit of a data-centric

00:11:39,000 --> 00:11:44,250
architecture prediction and maybe you

00:11:41,010 --> 00:11:46,500
guys can help us make this happen do is

00:11:44,250 --> 00:11:49,580
big big target number is less than 20

00:11:46,500 --> 00:11:52,770
megawatts for a nexus scale computer and

00:11:49,580 --> 00:11:55,410
and and you know we're working our way

00:11:52,770 --> 00:11:57,600
towards that but there's a there may be

00:11:55,410 --> 00:11:59,370
a long way to go but I think this is a

00:11:57,600 --> 00:12:00,750
destination that we're all working to

00:11:59,370 --> 00:12:03,060
when you look at this from a data

00:12:00,750 --> 00:12:04,650
centric perspective we've got our

00:12:03,060 --> 00:12:06,210
polymorphic processor we've managed to

00:12:04,650 --> 00:12:08,550
innovate our way to this new processor

00:12:06,210 --> 00:12:10,740
but we have free flavors we have the

00:12:08,550 --> 00:12:13,410
polymer a relatively small processor

00:12:10,740 --> 00:12:15,120
this storage attached medium-sized

00:12:13,410 --> 00:12:17,160
processor that's dear am attached and

00:12:15,120 --> 00:12:20,580
and oh just a rule compute processor

00:12:17,160 --> 00:12:22,230
maybe with no no no direct memory except

00:12:20,580 --> 00:12:25,560
for maybe level one cache buried in it

00:12:22,230 --> 00:12:27,210
and that will have a control plane this

00:12:25,560 --> 00:12:28,740
very traditional to our networks today

00:12:27,210 --> 00:12:30,390
but it that's going to be class is

00:12:28,740 --> 00:12:32,400
really a low bandwidth fabric switched

00:12:30,390 --> 00:12:34,560
managed and it's going to be managed

00:12:32,400 --> 00:12:37,560
coherency raveling d for everything

00:12:34,560 --> 00:12:39,420
coherent control plane and that will be

00:12:37,560 --> 00:12:41,910
a classic switched electrical network

00:12:39,420 --> 00:12:44,640
that we know today fabric switched but

00:12:41,910 --> 00:12:47,070
we'll have a data plane zero power and

00:12:44,640 --> 00:12:48,930
very high bandwidth and it's optically

00:12:47,070 --> 00:12:51,240
enabled to get to the zero power it's

00:12:48,930 --> 00:12:53,520
absolutely noncoherent so we don't have

00:12:51,240 --> 00:12:55,350
all this this copying going on but it's

00:12:53,520 --> 00:12:57,800
for a streaming data playing from moving

00:12:55,350 --> 00:13:00,570
data between these different nodes and

00:12:57,800 --> 00:13:02,400
and you basically compute in a

00:13:00,570 --> 00:13:04,260
distributed fashion where the data is

00:13:02,400 --> 00:13:06,540
when you think you've got an you've got

00:13:04,260 --> 00:13:08,730
an exabyte of data you don't want to

00:13:06,540 --> 00:13:10,650
move that anywhere you'd rather have an

00:13:08,730 --> 00:13:13,830
idol processor that maybe gets used once

00:13:10,650 --> 00:13:16,020
a year then moving terabytes of data

00:13:13,830 --> 00:13:18,450
I'll leave you with one little fault

00:13:16,020 --> 00:13:18,870
there if you look at the processor image

00:13:18,450 --> 00:13:21,720
to make

00:13:18,870 --> 00:13:24,650
processor on an FPGA an FPGA needs a 20

00:13:21,720 --> 00:13:27,570
megabyte or 30 megabyte bitstream

00:13:24,650 --> 00:13:29,550
wouldn't you rather move 30 megabytes of

00:13:27,570 --> 00:13:32,700
data a rank than two terabytes of data

00:13:29,550 --> 00:13:34,290
around so we need to start moving the

00:13:32,700 --> 00:13:37,170
process or the closer to the data and

00:13:34,290 --> 00:13:39,000
this is one idea anybody that you know

00:13:37,170 --> 00:13:40,350
any funders out there that can help make

00:13:39,000 --> 00:13:42,300
this happen but open power as a

00:13:40,350 --> 00:13:44,279
community we're all working together and

00:13:42,300 --> 00:13:48,890
I think this is a altima destination

00:13:44,279 --> 00:13:48,890

YouTube URL: https://www.youtube.com/watch?v=fE6a-dwXZ0M


