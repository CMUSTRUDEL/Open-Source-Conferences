Title: OpenPOWER Summit 2016 - CUDA Fortran Programming with the IBM XL Fortran Compiler
Publication date: 2016-04-29
Playlist: OpenPOWER Summit 2016
Description: 
	Presented by Rafik Zurob of IBM
Captions: 
	00:00:00,000 --> 00:00:08,040
hi my name is Rafiq syrup I work on the

00:00:02,480 --> 00:00:11,250
excel co-axial fortran compiler t let's

00:00:08,040 --> 00:00:12,840
go closer okay so I was saying that I

00:00:11,250 --> 00:00:16,470
work on at the xcel Fortran compiler

00:00:12,840 --> 00:00:20,490
team today we announced the availability

00:00:16,470 --> 00:00:24,119
of our Excel Fortran compiler in June

00:00:20,490 --> 00:00:28,019
and that compiler will provide good a

00:00:24,119 --> 00:00:30,119
Fortran support for the first time so in

00:00:28,019 --> 00:00:33,030
this talk I'd like to introduce some of

00:00:30,119 --> 00:00:36,410
the cadet fortran features that I think

00:00:33,030 --> 00:00:40,350
make good a Fortran and easy to program

00:00:36,410 --> 00:00:42,719
language for cuda and i'd like to

00:00:40,350 --> 00:00:45,510
introduce some of the excel fortran

00:00:42,719 --> 00:00:51,840
features that we've added this release

00:00:45,510 --> 00:00:53,610
for cuda so good a fortran is a set of

00:00:51,840 --> 00:00:55,949
extensions to the fortran programming

00:00:53,610 --> 00:00:59,309
language they allow you to access the

00:00:55,949 --> 00:01:03,210
GPU it could have fortran was created by

00:00:59,309 --> 00:01:05,850
the portland group in 2009-2010 it

00:01:03,210 --> 00:01:09,350
provides seamless integration of the

00:01:05,850 --> 00:01:13,020
CUDA language into the fortran language

00:01:09,350 --> 00:01:14,460
you basically basically extended the

00:01:13,020 --> 00:01:17,970
declarations and the statements and

00:01:14,460 --> 00:01:22,939
fortran so that you don't have to call

00:01:17,970 --> 00:01:25,049
the equity api explicitly as much it's

00:01:22,939 --> 00:01:27,570
functionally equivalent to quit at sea

00:01:25,049 --> 00:01:33,210
so anything you can do in courtesy you

00:01:27,570 --> 00:01:35,460
likely can do include a fortran so if

00:01:33,210 --> 00:01:37,650
you look at the example here you will

00:01:35,460 --> 00:01:40,979
recognize a lot of the memory types that

00:01:37,650 --> 00:01:43,430
are available on NVIDIA GPUs quitte

00:01:40,979 --> 00:01:46,729
fortran provides attributes and

00:01:43,430 --> 00:01:50,280
procedure prefixes to allow you to

00:01:46,729 --> 00:01:55,730
declare variables and functions of those

00:01:50,280 --> 00:01:59,230
types the next

00:01:55,730 --> 00:02:02,750
okay okay I think there's a problem here

00:01:59,230 --> 00:02:06,020
okay so if you look at this slide we

00:02:02,750 --> 00:02:08,750
have a CUDA c program where we're

00:02:06,020 --> 00:02:11,000
allocating an array in global space in

00:02:08,750 --> 00:02:13,820
global memory another array in manage

00:02:11,000 --> 00:02:17,180
memory and included see you need to know

00:02:13,820 --> 00:02:19,400
what API function to do to use so could

00:02:17,180 --> 00:02:21,140
a Malik versus critic Malik managed and

00:02:19,400 --> 00:02:22,940
when you're done with it you have to

00:02:21,140 --> 00:02:25,820
call quit a free to free the memory if

00:02:22,940 --> 00:02:28,490
you look at the quid a fortran sniped at

00:02:25,820 --> 00:02:31,070
the bottom just using the attribute

00:02:28,490 --> 00:02:34,340
attribute is enough the excel compiler

00:02:31,070 --> 00:02:38,470
will call the appropriate malloc

00:02:34,340 --> 00:02:41,900
function and when the procedure scope is

00:02:38,470 --> 00:02:43,100
when you're exiting the procedure it

00:02:41,900 --> 00:02:50,660
will call it with a free for you

00:02:43,100 --> 00:02:53,690
automatically as well similarly if you

00:02:50,660 --> 00:02:55,460
have allocation the allocation pointer

00:02:53,690 --> 00:02:58,490
assignment all these are done via

00:02:55,460 --> 00:03:05,720
standard for trans syntax so you do not

00:02:58,490 --> 00:03:09,080
have to do any API calls for these data

00:03:05,720 --> 00:03:11,230
transfer is done via assignment so if

00:03:09,080 --> 00:03:15,530
you look at the top quitte c program

00:03:11,230 --> 00:03:20,330
trying to assign one to every array

00:03:15,530 --> 00:03:23,060
element i'm trying to then copy from the

00:03:20,330 --> 00:03:25,690
device array to the host array and then

00:03:23,060 --> 00:03:29,959
i'm trying to add one to the host

00:03:25,690 --> 00:03:32,780
variable it's not very obvious from the

00:03:29,959 --> 00:03:34,670
code you have to read the code carefully

00:03:32,780 --> 00:03:37,730
and you have to know what each API

00:03:34,670 --> 00:03:39,920
function does include a Fortran all you

00:03:37,730 --> 00:03:43,070
need to do is just say that it is device

00:03:39,920 --> 00:03:46,090
and it's the compilers job after that to

00:03:43,070 --> 00:03:49,670
figure out the best API call to use and

00:03:46,090 --> 00:03:52,010
to break up the assignment into its

00:03:49,670 --> 00:03:55,760
components for copying from the host

00:03:52,010 --> 00:03:57,620
device and then incrementing by one by

00:03:55,760 --> 00:04:01,370
the way there is a typo in this slide so

00:03:57,620 --> 00:04:04,000
if you spot it let me know and we can

00:04:01,370 --> 00:04:04,000
talk at a booth

00:04:04,580 --> 00:04:08,130
good and Fortran also allows you to do

00:04:06,660 --> 00:04:10,760
asynchronous data transfer it's

00:04:08,130 --> 00:04:15,330
available via assignment as well as API

00:04:10,760 --> 00:04:17,700
so in this example we f4 is a module

00:04:15,330 --> 00:04:22,340
that provides you with access to the

00:04:17,700 --> 00:04:25,350
CUDA runtime API the pinned attribute

00:04:22,340 --> 00:04:28,170
just as you'd expect is something that

00:04:25,350 --> 00:04:32,700
would give you access to page loc memory

00:04:28,170 --> 00:04:35,400
and then you probably recognize the

00:04:32,700 --> 00:04:38,850
names could a stream create that is a

00:04:35,400 --> 00:04:42,120
CUDA rent I'm API call to create a new

00:04:38,850 --> 00:04:44,580
stream on the device and then credit for

00:04:42,120 --> 00:04:48,060
Trent has quit aforesaid default stream

00:04:44,580 --> 00:04:50,550
and that changes the default stream if

00:04:48,060 --> 00:04:52,860
stream 0 now you can use any stream you

00:04:50,550 --> 00:04:55,200
want and it has the side effect of

00:04:52,860 --> 00:04:59,040
basically making your assignments after

00:04:55,200 --> 00:05:01,920
that and Colonel calls asynchronous so

00:04:59,040 --> 00:05:03,960
the two assignment statements there are

00:05:01,920 --> 00:05:05,970
asynchronous because we're using pin

00:05:03,960 --> 00:05:12,360
memory if you are not using pin memory

00:05:05,970 --> 00:05:16,070
then they will be synchronous so cuda

00:05:12,360 --> 00:05:20,010
see provides a lot of libraries for

00:05:16,070 --> 00:05:23,490
blasts Fourier transforms sparse algebra

00:05:20,010 --> 00:05:24,840
random cuda Fortran provides for trend

00:05:23,490 --> 00:05:27,660
modules that provide binds the

00:05:24,840 --> 00:05:31,130
interfaces for all these and Excel for

00:05:27,660 --> 00:05:31,130
train provides all of these as well

00:05:32,000 --> 00:05:37,980
speaking of XL for an xl-4 Tran is a

00:05:35,700 --> 00:05:41,340
full-featured Fortran compiler that's

00:05:37,980 --> 00:05:43,980
been targeting power since 1990 we were

00:05:41,340 --> 00:05:48,210
one of the first compilers to provide

00:05:43,980 --> 00:05:51,590
complete fortran 2003 support and we

00:05:48,210 --> 00:05:54,810
also provide most of fortran 2008 and

00:05:51,590 --> 00:05:57,270
almost all of fortunate of TS to 911 3

00:05:54,810 --> 00:06:01,080
which is the C interoperability TS which

00:05:57,270 --> 00:06:02,669
is going to be part of 4 10 2015 the

00:06:01,080 --> 00:06:05,490
compiler team works closely with the

00:06:02,669 --> 00:06:08,630
power hardware team so we take maximum

00:06:05,490 --> 00:06:12,000
advantage of the IBM power processors

00:06:08,630 --> 00:06:14,370
and we are sometimes even involved in

00:06:12,000 --> 00:06:16,520
the design in terms of giving feedback

00:06:14,370 --> 00:06:21,029
to the hardware team

00:06:16,520 --> 00:06:25,139
so as you expect we have a very good

00:06:21,029 --> 00:06:28,110
optimizer for power and this optimizer

00:06:25,139 --> 00:06:30,689
is available on all IBM platforms so

00:06:28,110 --> 00:06:37,800
it's available on power for ax bar for

00:06:30,689 --> 00:06:39,629
linux and even 40 s ok so if we look at

00:06:37,800 --> 00:06:42,240
this table here and I'm just going to

00:06:39,629 --> 00:06:44,909
start with the top left if you have

00:06:42,240 --> 00:06:48,300
fortran source it goes through the XL

00:06:44,909 --> 00:06:51,779
fortran front-end XL fortran front and

00:06:48,300 --> 00:06:54,110
produces w code which is the excel

00:06:51,779 --> 00:06:57,229
compiler intermediate representation

00:06:54,110 --> 00:06:59,849
that goes into the high level optimizer

00:06:57,229 --> 00:07:04,379
that does dataflow optimizations loop

00:06:59,849 --> 00:07:08,939
optimizations can also do in lining that

00:07:04,379 --> 00:07:11,639
produces w code again and if you're

00:07:08,939 --> 00:07:14,009
doing host programming or just normal

00:07:11,639 --> 00:07:17,400
cpu programming that would have gone to

00:07:14,009 --> 00:07:19,499
the low level optimizer which I would

00:07:17,400 --> 00:07:21,419
have done some low-level optimizations

00:07:19,499 --> 00:07:23,430
like registre and then register

00:07:21,419 --> 00:07:28,469
allocation and then just generated that

00:07:23,430 --> 00:07:29,759
your dot 0 for you in the device case we

00:07:28,469 --> 00:07:32,370
have this component called the

00:07:29,759 --> 00:07:36,509
partitioner and it's partitioning the

00:07:32,370 --> 00:07:38,210
code at the ir level so some codec

00:07:36,509 --> 00:07:42,839
umpires like for example Quilici

00:07:38,210 --> 00:07:45,229
partitions at the source level our our

00:07:42,839 --> 00:07:47,999
compiler partitions at the ir level and

00:07:45,229 --> 00:07:50,249
as you can see here the flow for the

00:07:47,999 --> 00:07:52,800
host code which is the blue stuff is

00:07:50,249 --> 00:07:54,719
exactly the same with and without queda

00:07:52,800 --> 00:07:57,300
fortran which means that you are

00:07:54,719 --> 00:07:59,370
maintaining all the optimizations that

00:07:57,300 --> 00:08:02,430
you'd have gotten for your cpu code

00:07:59,370 --> 00:08:06,029
you're not losing any of those for the

00:08:02,430 --> 00:08:09,539
device code our high-level optimizer

00:08:06,029 --> 00:08:11,449
would run on the device code so there's

00:08:09,539 --> 00:08:14,370
the potential for improvements there

00:08:11,449 --> 00:08:18,389
after that we run the device code

00:08:14,370 --> 00:08:20,969
through w code to l of m lv m ir

00:08:18,389 --> 00:08:24,719
translator and from that point forward

00:08:20,969 --> 00:08:29,399
you get NV NV v mir that goes through

00:08:24,719 --> 00:08:30,160
the cuda toolkit and is optimized by lib

00:08:29,399 --> 00:08:32,979
nvm

00:08:30,160 --> 00:08:34,660
and PTX assembler so in this way

00:08:32,979 --> 00:08:35,979
basically you're getting two sets of

00:08:34,660 --> 00:08:37,780
optimizations you're getting the

00:08:35,979 --> 00:08:39,940
optimizations from the cuda toolkit out

00:08:37,780 --> 00:08:41,919
of the box but you're also getting the

00:08:39,940 --> 00:08:49,810
optimizations from our high level of

00:08:41,919 --> 00:08:52,300
optimizer so CUDA Fortran hands Excel

00:08:49,810 --> 00:08:55,150
fortran has some enhancements for

00:08:52,300 --> 00:08:58,420
usability if you've programmed it

00:08:55,150 --> 00:09:00,730
couldn't see you probably have had to

00:08:58,420 --> 00:09:03,370
write a macro around every API call you

00:09:00,730 --> 00:09:05,410
made like for example check cuda or

00:09:03,370 --> 00:09:07,780
something like that but basically check

00:09:05,410 --> 00:09:10,270
their turn of the api call if it's not

00:09:07,780 --> 00:09:14,140
good at success then you call could i

00:09:10,270 --> 00:09:16,120
get air string and you print an error we

00:09:14,140 --> 00:09:19,570
have a compiler option that does this

00:09:16,120 --> 00:09:22,450
automatically fit for you for every API

00:09:19,570 --> 00:09:26,200
call if you want or for comparison area

00:09:22,450 --> 00:09:28,840
API calls the default is to only check

00:09:26,200 --> 00:09:31,500
the comparator API calls so that could

00:09:28,840 --> 00:09:37,300
be Colonel calls or assignment or

00:09:31,500 --> 00:09:39,100
allocate and if you want you could make

00:09:37,300 --> 00:09:41,920
it check everything or you could even

00:09:39,100 --> 00:09:44,830
make a check user-defined functions so

00:09:41,920 --> 00:09:46,630
we have an attribute that you can place

00:09:44,830 --> 00:09:48,280
on user-defined functions to tell the

00:09:46,630 --> 00:09:52,420
compiler you wanted to check the return

00:09:48,280 --> 00:09:56,050
for you we do not clear the CUDA error

00:09:52,420 --> 00:09:57,730
state so we check the return of the API

00:09:56,050 --> 00:10:00,550
but if you have your own code that

00:09:57,730 --> 00:10:02,740
checks their turn we're not because

00:10:00,550 --> 00:10:06,250
we're not clearing the air state your

00:10:02,740 --> 00:10:08,140
code will not be affected and we also

00:10:06,250 --> 00:10:10,720
provide the ability to either stop the

00:10:08,140 --> 00:10:13,030
program if an error is detected or to

00:10:10,720 --> 00:10:15,790
continue in case you have your own error

00:10:13,030 --> 00:10:18,790
checking so our default is to continue

00:10:15,790 --> 00:10:23,050
but by via environment variable you can

00:10:18,790 --> 00:10:26,080
make it stop so here's an example I have

00:10:23,050 --> 00:10:29,050
code that calls a colonel and the number

00:10:26,080 --> 00:10:30,940
of threads is just input from the

00:10:29,050 --> 00:10:34,540
command line and the current could I

00:10:30,940 --> 00:10:38,260
gpus you cannot have more than than 1024

00:10:34,540 --> 00:10:42,400
threads in a block so in this program I

00:10:38,260 --> 00:10:43,519
try putting 2048 and when I run the

00:10:42,400 --> 00:10:46,829
program

00:10:43,519 --> 00:10:50,160
just compile it with XL cuff the name of

00:10:46,829 --> 00:10:52,199
the program no options it will give you

00:10:50,160 --> 00:10:54,539
the file name where the error occurred

00:10:52,199 --> 00:10:56,910
the line number and it will tell you the

00:10:54,539 --> 00:10:58,829
API call that failed so in this case is

00:10:56,910 --> 00:11:00,599
good a launch colonel it will give you

00:10:58,829 --> 00:11:04,109
the error code from the API call and

00:11:00,599 --> 00:11:07,139
will also give you the air string as

00:11:04,109 --> 00:11:08,729
returned by the tukwila toolkit and in

00:11:07,139 --> 00:11:10,709
this case it's going to continue after

00:11:08,729 --> 00:11:12,929
giving you this warning but if you set

00:11:10,709 --> 00:11:15,089
an environment variable it will air

00:11:12,929 --> 00:11:23,069
recovery equals no it will stop the

00:11:15,089 --> 00:11:25,619
program for you open mp4 and OpenMP 4.5

00:11:23,069 --> 00:11:29,429
are device-independent GPU programming

00:11:25,619 --> 00:11:32,720
models if you view quit a Fortran as

00:11:29,429 --> 00:11:36,389
higher level than could see in terms of

00:11:32,720 --> 00:11:40,169
how you program in it openmp is even

00:11:36,389 --> 00:11:46,619
higher level than CUDA Fortran it

00:11:40,169 --> 00:11:49,859
abstracts more of the device access ap

00:11:46,619 --> 00:11:52,759
is and it shifts the burden of

00:11:49,859 --> 00:11:55,529
explaining the hardware to the compiler

00:11:52,759 --> 00:11:58,229
this has the advantage of increasing

00:11:55,529 --> 00:12:00,089
program practice productivity but you

00:11:58,229 --> 00:12:04,769
have to have a very good optimizing

00:12:00,089 --> 00:12:09,679
compiler so let's look at an example I

00:12:04,769 --> 00:12:15,089
have 4096 x 4096 matrix multiplication

00:12:09,679 --> 00:12:17,339
in any OpenMP compiler this will you'd

00:12:15,089 --> 00:12:20,429
write a loop that like a nested loop

00:12:17,339 --> 00:12:22,799
that will multiply the matrices and I

00:12:20,429 --> 00:12:25,739
think every OpenMP compiler is going to

00:12:22,799 --> 00:12:29,639
use tiling to distribute the

00:12:25,739 --> 00:12:32,249
multiplication between threads however

00:12:29,639 --> 00:12:35,239
not every OpenMP compiler would use

00:12:32,249 --> 00:12:38,850
shared memory because shared memory is

00:12:35,239 --> 00:12:40,979
more of a hardware thing in the NVIDIA

00:12:38,850 --> 00:12:45,419
GPU might not be available in general

00:12:40,979 --> 00:12:47,819
and if your programming could a Fortran

00:12:45,419 --> 00:12:50,309
as a user you have the ability to write

00:12:47,819 --> 00:12:54,600
that yourself using a shared memory but

00:12:50,309 --> 00:12:55,799
programming in OpenMP basically you're

00:12:54,600 --> 00:12:57,190
at the mercy of the compiler the

00:12:55,799 --> 00:13:00,610
compiler does not use shared

00:12:57,190 --> 00:13:03,010
Murray you will not get it and so if you

00:13:00,610 --> 00:13:05,740
look here on the left this is just these

00:13:03,010 --> 00:13:09,100
are numbers with tiled but not shared

00:13:05,740 --> 00:13:10,990
and this is just with a research OpenMP

00:13:09,100 --> 00:13:14,640
compiler that does not do shared

00:13:10,990 --> 00:13:18,220
optimizations and you can see that it's

00:13:14,640 --> 00:13:21,940
very much slower than courtesy and cuda

00:13:18,220 --> 00:13:24,280
fortran when we turn on tiled and shared

00:13:21,940 --> 00:13:26,590
memory you can see also that we can gain

00:13:24,280 --> 00:13:30,730
quite a bit of performance compared to

00:13:26,590 --> 00:13:32,500
just tiled so I think that's an

00:13:30,730 --> 00:13:36,100
advantage at least in the short term for

00:13:32,500 --> 00:13:39,310
good a Fortran because you can optimize

00:13:36,100 --> 00:13:41,110
your code right away and I think over

00:13:39,310 --> 00:13:43,240
time though like open and pecan powders

00:13:41,110 --> 00:13:45,100
are adding optimizations and you should

00:13:43,240 --> 00:13:48,280
be able to get the same amount of

00:13:45,100 --> 00:13:53,470
optimizations you might be asking like

00:13:48,280 --> 00:13:56,320
why is this lower several reasons one of

00:13:53,470 --> 00:13:58,210
them is high level optimizer did some

00:13:56,320 --> 00:14:02,130
optimization but that doesn't cover the

00:13:58,210 --> 00:14:04,360
whole thing another one I suspect is

00:14:02,130 --> 00:14:07,150
called major versus row major might be

00:14:04,360 --> 00:14:13,990
giving better coalescing but I'm still

00:14:07,150 --> 00:14:16,210
checking on that so just to sum up quick

00:14:13,990 --> 00:14:18,970
for trans gives a high level GPU

00:14:16,210 --> 00:14:21,550
programming model it's functional

00:14:18,970 --> 00:14:25,060
equivalent to cuda see you can take full

00:14:21,550 --> 00:14:27,460
advantage of the NVIDIA GPUs and it's

00:14:25,060 --> 00:14:30,130
available in our compiler and of course

00:14:27,460 --> 00:14:33,370
p guys compiler it will be available in

00:14:30,130 --> 00:14:35,320
our compiler starting in june and if you

00:14:33,370 --> 00:14:37,450
have any questions please feel free to

00:14:35,320 --> 00:14:40,170
visit our booth it's right at the corner

00:14:37,450 --> 00:14:40,170

YouTube URL: https://www.youtube.com/watch?v=z6IoEPOKh3I


