Title: Hit-reco: ProtoDUNE Raw Data Denoising with DL models - Marco Rossi, CERN
Publication date: 2020-09-21
Playlist: OpenPOWER Summit NA 2020
Description: 
	Hit-reco: ProtoDUNE Raw Data Denoising with DL models - Marco Rossi, CERN

Speakers: Marco Rossi

We present Hit-reco model for denoising and region of interest selection on raw simulation data from ProtoDUNE experiment. ProtoDUNE detector is hosted by CERN and it aims to test and calibrate technologies for DUNE, a forthcoming experiment in neutrino physics. Hit-reco leverages deep learning algorithms to make a first step in the reconstruction workchain, that consists in converting digital detector signals into physical high level quantities. We benchmark the artificial intelligence based approach against traditional algorithms implemented by the DUNE collaboration. We investigate the capability of graph convolutional neural networks, while exploiting the IBM Minsky multi-GPU setup to accelerate training and inference processes.
Captions: 
	00:00:00,080 --> 00:00:04,319
so welcome everybody this is uh marco

00:00:03,199 --> 00:00:07,639
rossi

00:00:04,319 --> 00:00:11,200
and that's my presentation it reiko

00:00:07,639 --> 00:00:14,240
producing with deep learning models

00:00:11,200 --> 00:00:16,080
let me first present you dune

00:00:14,240 --> 00:00:18,080
which stands for deep underground

00:00:16,080 --> 00:00:21,439
neutrino experiment

00:00:18,080 --> 00:00:24,560
the dune experiment is uh uh

00:00:21,439 --> 00:00:27,519
based in the u.s and its main goal

00:00:24,560 --> 00:00:28,960
is to have a deeper understanding of

00:00:27,519 --> 00:00:32,719
neutrino physics

00:00:28,960 --> 00:00:35,680
in particular we have two facilities

00:00:32,719 --> 00:00:36,719
one is at fermilab in chicago where the

00:00:35,680 --> 00:00:40,640
most intense

00:00:36,719 --> 00:00:44,960
proto um neutrino beam is produced

00:00:40,640 --> 00:00:48,640
and this neutrinos travels all the way

00:00:44,960 --> 00:00:51,120
until they reach a fire detector

00:00:48,640 --> 00:00:53,520
underground in the same for the

00:00:51,120 --> 00:00:56,719
underground research facility

00:00:53,520 --> 00:01:00,160
in south dakota at

00:00:56,719 --> 00:01:01,359
cern in geneva we have a protogen which

00:01:00,160 --> 00:01:05,040
is a prototype of

00:01:01,359 --> 00:01:08,479
the human spark detector in scale 120

00:01:05,040 --> 00:01:11,200
where it its main goal is

00:01:08,479 --> 00:01:12,000
is to test and validate demons

00:01:11,200 --> 00:01:15,280
technologies

00:01:12,000 --> 00:01:17,439
for the forthcoming experiment in the us

00:01:15,280 --> 00:01:19,600
in the picture here you see the the

00:01:17,439 --> 00:01:22,960
detectors box

00:01:19,600 --> 00:01:24,960
this detector is called lrtpc is uh

00:01:22,960 --> 00:01:26,880
which stands for liquid argon time

00:01:24,960 --> 00:01:29,600
projection chamber

00:01:26,880 --> 00:01:31,040
this is a big box filled with liquid

00:01:29,600 --> 00:01:35,200
argon

00:01:31,040 --> 00:01:37,680
and it works as following a particle

00:01:35,200 --> 00:01:38,880
uh as you can see here a particle like a

00:01:37,680 --> 00:01:41,680
neutrino

00:01:38,880 --> 00:01:43,360
inca comes within the detector and

00:01:41,680 --> 00:01:47,200
scutters with the

00:01:43,360 --> 00:01:50,399
nucleus of argon that are inside

00:01:47,200 --> 00:01:53,119
and since a electric

00:01:50,399 --> 00:01:54,560
uh electromagnetic field is established

00:01:53,119 --> 00:01:57,920
inside the detector

00:01:54,560 --> 00:01:59,119
the produced particles after the

00:01:57,920 --> 00:02:01,840
interaction

00:01:59,119 --> 00:02:03,520
are drifted rightwards in the case of

00:02:01,840 --> 00:02:06,560
negative charge the

00:02:03,520 --> 00:02:09,759
particles like electrons these electrons

00:02:06,560 --> 00:02:13,680
are collected by these planes

00:02:09,759 --> 00:02:17,120
that are a set of wires there

00:02:13,680 --> 00:02:18,319
are called anode planes and these settle

00:02:17,120 --> 00:02:21,200
wires collect the

00:02:18,319 --> 00:02:22,400
induced current by these drifting

00:02:21,200 --> 00:02:25,520
electrons

00:02:22,400 --> 00:02:28,560
we have then these uh two kinds of uh

00:02:25,520 --> 00:02:30,319
raw data that are data coming out from

00:02:28,560 --> 00:02:32,400
the detector

00:02:30,319 --> 00:02:34,840
we have a one-dimensional view that is

00:02:32,400 --> 00:02:36,000
uh the current induced by these

00:02:34,840 --> 00:02:39,760
electrons

00:02:36,000 --> 00:02:42,959
on a single wire and

00:02:39,760 --> 00:02:43,920
calculated by the detector at different

00:02:42,959 --> 00:02:46,400
time steps

00:02:43,920 --> 00:02:47,440
so we have a one-dimensional array on

00:02:46,400 --> 00:02:50,319
the other hand

00:02:47,440 --> 00:02:51,360
we could have a two-dimensional view of

00:02:50,319 --> 00:02:54,480
this

00:02:51,360 --> 00:02:58,400
raw data that is the whole

00:02:54,480 --> 00:03:01,760
number of wires inside of each plane

00:02:58,400 --> 00:03:02,319
against the time on the other axis so we

00:03:01,760 --> 00:03:06,000
prefer

00:03:02,319 --> 00:03:08,159
using in our models the raw data in the

00:03:06,000 --> 00:03:10,159
two-dimensional view but sometimes

00:03:08,159 --> 00:03:11,760
it's useful also to to see what's

00:03:10,159 --> 00:03:12,480
happening in the one-dimensional one

00:03:11,760 --> 00:03:15,440
here

00:03:12,480 --> 00:03:15,680
on the x-axis we have the time as i said

00:03:15,440 --> 00:03:17,760
and

00:03:15,680 --> 00:03:20,239
on the y-axis we have the number of the

00:03:17,760 --> 00:03:23,440
wire in the one-dimensional view we

00:03:20,239 --> 00:03:26,799
select a single stripe horizontal stripe

00:03:23,440 --> 00:03:26,799
of this data

00:03:27,599 --> 00:03:31,840
the traditional workflow of of line data

00:03:30,959 --> 00:03:35,760
processing

00:03:31,840 --> 00:03:38,879
works in this image like these steps

00:03:35,760 --> 00:03:42,000
we have initially we have a simulation

00:03:38,879 --> 00:03:45,200
or detector that simulates

00:03:42,000 --> 00:03:46,959
or measure the incoming particles and

00:03:45,200 --> 00:03:50,080
produce this raw data that

00:03:46,959 --> 00:03:50,080
i just explained

00:03:50,480 --> 00:03:54,799
before and after that we have the

00:03:53,599 --> 00:03:58,239
reconstruction

00:03:54,799 --> 00:03:59,439
step that is a kind of a feature

00:03:58,239 --> 00:04:02,879
extraction

00:03:59,439 --> 00:04:05,360
we have we have

00:04:02,879 --> 00:04:05,920
split this reconstruction in different

00:04:05,360 --> 00:04:09,040
steps

00:04:05,920 --> 00:04:09,599
the denoising and it finding which means

00:04:09,040 --> 00:04:13,360
that

00:04:09,599 --> 00:04:16,799
we have to see if each pixel

00:04:13,360 --> 00:04:18,320
contains or not contains signal inside

00:04:16,799 --> 00:04:22,000
it

00:04:18,320 --> 00:04:24,560
and we and the fi well the final uh

00:04:22,000 --> 00:04:25,440
parts of this reconstruction step is uh

00:04:24,560 --> 00:04:28,240
given by

00:04:25,440 --> 00:04:29,520
particle identification and event

00:04:28,240 --> 00:04:32,639
labeling

00:04:29,520 --> 00:04:33,040
these reconstruction pro products are

00:04:32,639 --> 00:04:35,520
then

00:04:33,040 --> 00:04:36,960
gathered together in uh to form a

00:04:35,520 --> 00:04:40,080
theoretical model

00:04:36,960 --> 00:04:42,479
in inside an analysis step this is

00:04:40,080 --> 00:04:44,479
made to have a final insight of the

00:04:42,479 --> 00:04:47,600
physics of the neutrinos

00:04:44,479 --> 00:04:49,520
my the goal of my research is

00:04:47,600 --> 00:04:50,720
to replace the reconstruction

00:04:49,520 --> 00:04:53,919
traditional

00:04:50,720 --> 00:04:56,400
algorithms with deep learning model and

00:04:53,919 --> 00:04:57,840
in this uh presentation i'm going to

00:04:56,400 --> 00:05:01,360
focus just on

00:04:57,840 --> 00:05:03,360
the first two parts here

00:05:01,360 --> 00:05:04,720
the denoising and the region of inter

00:05:03,360 --> 00:05:08,479
selection that is the

00:05:04,720 --> 00:05:11,680
equivalent of it finding

00:05:08,479 --> 00:05:14,880
again let me present uh

00:05:11,680 --> 00:05:17,759
the kind of data we have to deal with

00:05:14,880 --> 00:05:18,639
we have uh these kind of features that

00:05:17,759 --> 00:05:22,000
is

00:05:18,639 --> 00:05:23,039
we have a noisy noisy waveforms

00:05:22,000 --> 00:05:25,360
as you can see here in the

00:05:23,039 --> 00:05:28,479
one-dimensional view and

00:05:25,360 --> 00:05:31,680
also you can see from this picture that

00:05:28,479 --> 00:05:32,320
the images have sparse signals inside

00:05:31,680 --> 00:05:34,800
them

00:05:32,320 --> 00:05:35,720
and also they are really big they are

00:05:34,800 --> 00:05:40,639
the

00:05:35,720 --> 00:05:43,039
960 per 6000 pixels each so

00:05:40,639 --> 00:05:44,080
really big images in order to deal with

00:05:43,039 --> 00:05:47,360
these two

00:05:44,080 --> 00:05:50,720
features that could uh constitute

00:05:47,360 --> 00:05:53,600
difficulty in the models we

00:05:50,720 --> 00:05:55,120
uh we employ graph conversion neural

00:05:53,600 --> 00:05:57,280
networks

00:05:55,120 --> 00:05:58,800
in order to deal with sparsity and with

00:05:57,280 --> 00:06:01,919
the size of the

00:05:58,800 --> 00:06:03,919
images we used to use a

00:06:01,919 --> 00:06:05,919
data parallel approach meaning that we

00:06:03,919 --> 00:06:06,800
are cropping the images and feed the

00:06:05,919 --> 00:06:10,639
crops

00:06:06,800 --> 00:06:11,199
to our models here i've spoken about

00:06:10,639 --> 00:06:15,120
crops

00:06:11,199 --> 00:06:16,080
here we have a sample of noisy images on

00:06:15,120 --> 00:06:19,280
the left

00:06:16,080 --> 00:06:22,479
and the corresponding target images

00:06:19,280 --> 00:06:25,199
the or well the the labels on the right

00:06:22,479 --> 00:06:25,840
in a two-dimensional view in this slide

00:06:25,199 --> 00:06:27,440
instead

00:06:25,840 --> 00:06:29,600
we have a one-dimensional view as you

00:06:27,440 --> 00:06:33,440
can see the target waveform is

00:06:29,600 --> 00:06:36,800
cleaner than the noisy one of course

00:06:33,440 --> 00:06:40,479
that is used as an input we

00:06:36,800 --> 00:06:43,120
built a data set uh containing a 10

00:06:40,479 --> 00:06:45,840
simulated events

00:06:43,120 --> 00:06:46,560
each of these of these events have six

00:06:45,840 --> 00:06:50,000
planes

00:06:46,560 --> 00:06:53,199
where the data are collected

00:06:50,000 --> 00:06:55,599
that simulates the detector planes and

00:06:53,199 --> 00:06:58,240
all of these 10 events are split into

00:06:55,599 --> 00:06:59,599
train test and validation set as in this

00:06:58,240 --> 00:07:02,960
pie chart

00:06:59,599 --> 00:07:07,280
shown here the raw data size in memory

00:07:02,960 --> 00:07:10,880
is uh takes seven gigabytes

00:07:07,280 --> 00:07:11,919
for both inputs and labels and as i said

00:07:10,880 --> 00:07:14,720
previously planes

00:07:11,919 --> 00:07:15,680
in the train set are cropped to fit in

00:07:14,720 --> 00:07:19,599
memory

00:07:15,680 --> 00:07:23,440
and to be fed to our models

00:07:19,599 --> 00:07:27,280
so we randomly sampled two 24 000 crops

00:07:23,440 --> 00:07:29,120
32 by 32 while test and validation set

00:07:27,280 --> 00:07:32,160
to contain six planes each

00:07:29,120 --> 00:07:34,400
which are one event for tests and one

00:07:32,160 --> 00:07:37,680
event for validation

00:07:34,400 --> 00:07:43,039
set each planes is 960

00:07:37,680 --> 00:07:43,039
times 6 000 pixels each

00:07:43,120 --> 00:07:47,360
let me present now the proposed model we

00:07:46,080 --> 00:07:49,440
are going to use

00:07:47,360 --> 00:07:51,520
uh this is the graph convolutional

00:07:49,440 --> 00:07:56,319
neural network layer

00:07:51,520 --> 00:08:00,240
given by this paper referenced here

00:07:56,319 --> 00:08:03,680
the graph convolutional layer is a

00:08:00,240 --> 00:08:07,199
is a is an average of two operations

00:08:03,680 --> 00:08:09,840
the convolutional of a three by three

00:08:07,199 --> 00:08:11,120
filter that takes care of the

00:08:09,840 --> 00:08:14,800
relationship between

00:08:11,120 --> 00:08:18,800
the pixel in question and the

00:08:14,800 --> 00:08:22,000
correlation with the local pixels

00:08:18,800 --> 00:08:25,440
while the non-local aggregator builds

00:08:22,000 --> 00:08:28,240
inside a graph a k-9 graph with k

00:08:25,440 --> 00:08:30,800
equal to eight and exploits a long

00:08:28,240 --> 00:08:33,279
distance correlation between pixels

00:08:30,800 --> 00:08:34,320
in particular we have that for a red

00:08:33,279 --> 00:08:37,120
pixel

00:08:34,320 --> 00:08:38,719
is receptive field is is comprised of

00:08:37,120 --> 00:08:42,080
the

00:08:38,719 --> 00:08:44,399
the closest eight closest pixels

00:08:42,080 --> 00:08:46,959
in feature space where the distance in

00:08:44,399 --> 00:08:50,480
future space is computed as an euclidean

00:08:46,959 --> 00:08:51,200
distance difficulty the caveat to have

00:08:50,480 --> 00:08:54,399
in mind

00:08:51,200 --> 00:08:57,680
when we employ this kind of

00:08:54,399 --> 00:09:00,480
layer is is complexity namely

00:08:57,680 --> 00:09:01,279
the complexity is of order and square

00:09:00,480 --> 00:09:03,600
where n

00:09:01,279 --> 00:09:04,320
is the number of pixels inside the

00:09:03,600 --> 00:09:07,760
images

00:09:04,320 --> 00:09:10,959
so if we choose to have square crops

00:09:07,760 --> 00:09:14,880
the complexity is quadratic

00:09:10,959 --> 00:09:18,160
against the sides of the edge of the

00:09:14,880 --> 00:09:22,160
crop our

00:09:18,160 --> 00:09:25,920
interest in in models

00:09:22,160 --> 00:09:29,360
is to fold it first we want to perform

00:09:25,920 --> 00:09:31,120
an roi namely a regional of interest

00:09:29,360 --> 00:09:34,240
finding

00:09:31,120 --> 00:09:36,480
selection which answers

00:09:34,240 --> 00:09:38,240
the question does the pixel contain a

00:09:36,480 --> 00:09:40,959
chart deposition

00:09:38,240 --> 00:09:42,480
secondly i'll show that we will also

00:09:40,959 --> 00:09:46,480
employ our models for

00:09:42,480 --> 00:09:49,760
a denoising task but as for this

00:09:46,480 --> 00:09:52,880
roi the output of the model

00:09:49,760 --> 00:09:55,680
is one when there's actual

00:09:52,880 --> 00:09:56,880
charge so there's signal inside the peak

00:09:55,680 --> 00:10:00,000
inside a pixel

00:09:56,880 --> 00:10:03,440
and zero when the signal

00:10:00,000 --> 00:10:05,839
there is not present in the

00:10:03,440 --> 00:10:06,640
in these plots you can see the output of

00:10:05,839 --> 00:10:10,640
a trained

00:10:06,640 --> 00:10:12,560
roi block and the target

00:10:10,640 --> 00:10:13,680
the target for the target for the color

00:10:12,560 --> 00:10:17,120
coding

00:10:13,680 --> 00:10:20,560
yellow means one so signal inside and

00:10:17,120 --> 00:10:24,079
violet means no signal the output

00:10:20,560 --> 00:10:27,200
is given by a soft max layer so

00:10:24,079 --> 00:10:31,120
we have to cut

00:10:27,200 --> 00:10:33,440
with a threshold this this kind of

00:10:31,120 --> 00:10:34,800
output in order to have the final output

00:10:33,440 --> 00:10:38,800
that i show you

00:10:34,800 --> 00:10:41,600
after the technical features of this

00:10:38,800 --> 00:10:41,600
array block

00:10:42,079 --> 00:10:46,320
well this right block takes as inputs

00:10:44,560 --> 00:10:50,880
the noisy crops

00:10:46,320 --> 00:10:53,920
and outputs the heat like like this one

00:10:50,880 --> 00:10:57,240
it's comprised of several stacked

00:10:53,920 --> 00:10:58,560
layer first we have several convolution

00:10:57,240 --> 00:11:02,000
7x7

00:10:58,560 --> 00:11:05,519
with filters of these sides and and then

00:11:02,000 --> 00:11:07,600
some graph convolutional i'm i'd like to

00:11:05,519 --> 00:11:09,040
anticipate here that we are going to use

00:11:07,600 --> 00:11:13,360
the two kind of

00:11:09,040 --> 00:11:15,920
uh models one kind is the this actual uh

00:11:13,360 --> 00:11:16,720
graph convolutional neural network and

00:11:15,920 --> 00:11:19,760
the other one

00:11:16,720 --> 00:11:21,440
is a convolutional neural network i call

00:11:19,760 --> 00:11:24,800
convolutional neural network

00:11:21,440 --> 00:11:26,959
the same architecture but with the

00:11:24,800 --> 00:11:28,240
layers like this one so the graph

00:11:26,959 --> 00:11:31,680
convolutional ones

00:11:28,240 --> 00:11:32,560
replaced by usual convolutions this is

00:11:31,680 --> 00:11:35,040
to have

00:11:32,560 --> 00:11:36,240
some benchmarks some comparison between

00:11:35,040 --> 00:11:39,920
the the outputs

00:11:36,240 --> 00:11:43,760
and the performances the dimension

00:11:39,920 --> 00:11:46,880
of the array block is of 10 to the fifth

00:11:43,760 --> 00:11:48,720
trainable parameters and we train this

00:11:46,880 --> 00:11:51,040
uh

00:11:48,720 --> 00:11:52,160
this net with the binary cross center

00:11:51,040 --> 00:11:55,680
because functions

00:11:52,160 --> 00:11:56,480
and the atom optimizer as i anticipated

00:11:55,680 --> 00:12:00,160
before

00:11:56,480 --> 00:12:02,959
this is a part of a two-fold uh

00:12:00,160 --> 00:12:04,240
aim the second the second task we want

00:12:02,959 --> 00:12:07,680
to perform is the

00:12:04,240 --> 00:12:12,079
denoising the noising is taken

00:12:07,680 --> 00:12:14,560
is carried out by this bigger network

00:12:12,079 --> 00:12:15,839
as as before it takes as inputs the

00:12:14,560 --> 00:12:19,839
noisy crops

00:12:15,839 --> 00:12:22,560
and outputs are denoised crop

00:12:19,839 --> 00:12:23,200
as you can see here we have a early

00:12:22,560 --> 00:12:26,320
stage

00:12:23,200 --> 00:12:27,440
of processing that is uh comprised of a

00:12:26,320 --> 00:12:31,040
preprocessing

00:12:27,440 --> 00:12:34,079
of some pre-processing blocks and an roi

00:12:31,040 --> 00:12:37,120
so a full trained roi presented before

00:12:34,079 --> 00:12:37,519
which output is concatenated with the

00:12:37,120 --> 00:12:40,880
other

00:12:37,519 --> 00:12:44,560
and then passed by uh some

00:12:40,880 --> 00:12:46,880
filters again i i'm going to speak

00:12:44,560 --> 00:12:47,680
of uh gcnn with this kind of

00:12:46,880 --> 00:12:51,360
architecture

00:12:47,680 --> 00:12:54,079
and cnns with when denoising

00:12:51,360 --> 00:12:54,880
where layers the green layers are

00:12:54,079 --> 00:12:58,800
replaced by

00:12:54,880 --> 00:13:02,160
convolutional yellow ones in this plot

00:12:58,800 --> 00:13:06,639
you can see uh an example of

00:13:02,160 --> 00:13:07,440
output of a trained model the noisy

00:13:06,639 --> 00:13:10,560
model

00:13:07,440 --> 00:13:12,079
and it's a correspondent target so a

00:13:10,560 --> 00:13:14,480
visually they are quite

00:13:12,079 --> 00:13:17,120
indistinguishable

00:13:14,480 --> 00:13:19,760
as technical feature again data inputs

00:13:17,120 --> 00:13:21,360
are crops 32 by 32 and

00:13:19,760 --> 00:13:23,519
as you can see by the number of

00:13:21,360 --> 00:13:26,079
trainable parameters this model is 10

00:13:23,519 --> 00:13:29,839
times bigger than the one before

00:13:26,079 --> 00:13:32,480
and is 10 to the 6 parameters

00:13:29,839 --> 00:13:33,360
we train the models with a custom loss

00:13:32,480 --> 00:13:36,480
function

00:13:33,360 --> 00:13:39,040
that is comprised of this sum

00:13:36,480 --> 00:13:40,240
of one minus structural similarity thus

00:13:39,040 --> 00:13:41,920
mean square error

00:13:40,240 --> 00:13:43,279
means where error is defined in the

00:13:41,920 --> 00:13:48,079
usual way

00:13:43,279 --> 00:13:51,760
while structural similarity is a custom

00:13:48,079 --> 00:13:55,839
perceptual loss that that means that

00:13:51,760 --> 00:13:55,839
gives higher scores for

00:13:56,399 --> 00:14:02,800
indistinguishable uh crops so the more

00:14:00,079 --> 00:14:03,360
the crops are similar in the perceptual

00:14:02,800 --> 00:14:06,720
way

00:14:03,360 --> 00:14:09,600
the more uh the structural similarity uh

00:14:06,720 --> 00:14:10,639
value computed by this formula here is

00:14:09,600 --> 00:14:12,639
high

00:14:10,639 --> 00:14:15,360
the the structural similarity in

00:14:12,639 --> 00:14:20,320
particular is bounded between minus one

00:14:15,360 --> 00:14:24,079
and one then taking one minus ssmi

00:14:20,320 --> 00:14:27,440
gives you a positive defined number

00:14:24,079 --> 00:14:29,760
and where zero is the perfect score

00:14:27,440 --> 00:14:30,560
as we would like to have foremost

00:14:29,760 --> 00:14:33,839
functions

00:14:30,560 --> 00:14:35,519
again we train with the optimizer our

00:14:33,839 --> 00:14:39,440
working environment

00:14:35,519 --> 00:14:42,839
is uh given by an ibm power 8

00:14:39,440 --> 00:14:46,160
cpu and we used

00:14:42,839 --> 00:14:49,360
four uh nvidia tesla p100

00:14:46,160 --> 00:14:53,600
16 gigabytes each gpus we

00:14:49,360 --> 00:14:56,560
coded everything in in pytarch

00:14:53,600 --> 00:14:57,440
and now let me present some training

00:14:56,560 --> 00:14:59,680
scores

00:14:57,440 --> 00:15:02,000
starting from the matrix here you have

00:14:59,680 --> 00:15:02,800
two plots the one the one on the left is

00:15:02,000 --> 00:15:06,560
for

00:15:02,800 --> 00:15:08,079
uh the uh training loss the binary cross

00:15:06,560 --> 00:15:09,440
entropy for the region of interest

00:15:08,079 --> 00:15:13,040
selection

00:15:09,440 --> 00:15:16,240
and as you can see the cnn

00:15:13,040 --> 00:15:19,680
uh the cnn behavior is motor

00:15:16,240 --> 00:15:22,560
while uh on the other hand we have

00:15:19,680 --> 00:15:24,160
on the right plot the validation

00:15:22,560 --> 00:15:27,279
matrices

00:15:24,160 --> 00:15:30,240
while but uh as you can see here

00:15:27,279 --> 00:15:31,120
the best score in on validation set is

00:15:30,240 --> 00:15:35,279
given by this

00:15:31,120 --> 00:15:37,680
gcnn on epoch 15. the timings

00:15:35,279 --> 00:15:38,800
for uh training the region of interest

00:15:37,680 --> 00:15:41,040
selection

00:15:38,800 --> 00:15:42,079
are given by these plots we have the

00:15:41,040 --> 00:15:44,560
absolute timing

00:15:42,079 --> 00:15:46,639
and the ratio for training either for

00:15:44,560 --> 00:15:49,199
graph convolutional neural net against

00:15:46,639 --> 00:15:52,839
uh convolutional neural network the

00:15:49,199 --> 00:15:54,800
ratio between the two is uh

00:15:52,839 --> 00:15:57,839
2.5 so

00:15:54,800 --> 00:16:01,360
cnn is 2.5 faster than dcnn

00:15:57,839 --> 00:16:05,360
but this can be expected because

00:16:01,360 --> 00:16:08,240
cnn is optimized by torch

00:16:05,360 --> 00:16:09,759
programmers and while gcna is just a

00:16:08,240 --> 00:16:13,839
custom layer

00:16:09,759 --> 00:16:17,920
on validation we have a factor of seven

00:16:13,839 --> 00:16:21,120
of uh speed up for the cnn

00:16:17,920 --> 00:16:24,399
in uh what about the denoising

00:16:21,120 --> 00:16:27,279
training so we train before

00:16:24,399 --> 00:16:28,079
the ri block then use a pre-trained

00:16:27,279 --> 00:16:31,440
array block

00:16:28,079 --> 00:16:34,880
to be uh to load to be loaded

00:16:31,440 --> 00:16:37,680
loaded into the denoising block and then

00:16:34,880 --> 00:16:38,959
training everything together with the

00:16:37,680 --> 00:16:41,440
custom

00:16:38,959 --> 00:16:42,160
with the custom loss function as you can

00:16:41,440 --> 00:16:45,759
see here

00:16:42,160 --> 00:16:49,440
the gcnn and cnn are

00:16:45,759 --> 00:16:52,399
quite well behaved on training

00:16:49,440 --> 00:16:53,040
and but the gcnn validation lost is

00:16:52,399 --> 00:16:56,560
almost

00:16:53,040 --> 00:16:57,120
always below the cnn ones we present

00:16:56,560 --> 00:17:00,880
here

00:16:57,120 --> 00:17:03,920
several metrics uh for uh

00:17:00,880 --> 00:17:05,679
validation on the validation set just

00:17:03,920 --> 00:17:08,000
have a focus on the ps

00:17:05,679 --> 00:17:08,880
and r which is the peak signal to noise

00:17:08,000 --> 00:17:11,839
ratio

00:17:08,880 --> 00:17:13,439
it's kind of a logarithmic scale for the

00:17:11,839 --> 00:17:16,480
mean square error

00:17:13,439 --> 00:17:17,679
and higher scores here are better so as

00:17:16,480 --> 00:17:20,799
you can see here

00:17:17,679 --> 00:17:23,919
the blue line is almost always above

00:17:20,799 --> 00:17:27,199
the yellow the orange one

00:17:23,919 --> 00:17:30,640
as uh again for the timings

00:17:27,199 --> 00:17:33,360
of the denoising uh we have a four

00:17:30,640 --> 00:17:34,320
a factor of four for the gcnn to be

00:17:33,360 --> 00:17:36,880
slower

00:17:34,320 --> 00:17:38,720
than the cnn on training and a factor of

00:17:36,880 --> 00:17:42,160
5.6

00:17:38,720 --> 00:17:45,520
on validation so this is comparable to

00:17:42,160 --> 00:17:46,480
the previous results now we decided to

00:17:45,520 --> 00:17:49,200
benchmark

00:17:46,480 --> 00:17:49,919
the regency of interest selection

00:17:49,200 --> 00:17:54,000
training

00:17:49,919 --> 00:17:54,799
trained on our data set against a basic

00:17:54,000 --> 00:17:57,200
uh

00:17:54,799 --> 00:17:58,080
kenny filter this kenny filter is a

00:17:57,200 --> 00:18:01,520
basic

00:17:58,080 --> 00:18:03,760
edge detection tool which is uh

00:18:01,520 --> 00:18:05,440
which is known in computer vision and

00:18:03,760 --> 00:18:08,240
answered the question does the pixel

00:18:05,440 --> 00:18:11,360
belong to an edge or not

00:18:08,240 --> 00:18:12,720
it's uh comprised of a convolution and a

00:18:11,360 --> 00:18:16,320
thresholding method

00:18:12,720 --> 00:18:19,039
to label the pixels just to

00:18:16,320 --> 00:18:20,000
just uh just to mention uh we have been

00:18:19,039 --> 00:18:23,120
tested

00:18:20,000 --> 00:18:26,480
six planes then an order of

00:18:23,120 --> 00:18:30,080
34 millions of pixels

00:18:26,480 --> 00:18:32,480
but these pixels are really unbalanced

00:18:30,080 --> 00:18:33,520
meaning that the ratio between each and

00:18:32,480 --> 00:18:36,559
no needs

00:18:33,520 --> 00:18:38,880
is 1.9 percent so we choose

00:18:36,559 --> 00:18:40,160
uh figure of merit like the sensitivity

00:18:38,880 --> 00:18:44,320
because we wanted

00:18:40,160 --> 00:18:47,280
to uh wash out the whole um

00:18:44,320 --> 00:18:48,640
the all the empty space in the in the in

00:18:47,280 --> 00:18:51,600
the images

00:18:48,640 --> 00:18:53,039
the plot shows here the final evaluation

00:18:51,600 --> 00:18:56,960
for the sensitivity

00:18:53,039 --> 00:18:59,679
uh for each of the three

00:18:56,960 --> 00:19:00,720
algorithms the kenny one is not suited i

00:18:59,679 --> 00:19:03,760
would say that this is not

00:19:00,720 --> 00:19:07,520
is not suited for this purpose to

00:19:03,760 --> 00:19:10,559
process our data set but

00:19:07,520 --> 00:19:13,919
we achieve a best peak signal

00:19:10,559 --> 00:19:18,400
peak sensitivity of 0.85 in

00:19:13,919 --> 00:19:20,880
with the cnn network

00:19:18,400 --> 00:19:22,000
here we present this course histogram

00:19:20,880 --> 00:19:25,440
the green lines

00:19:22,000 --> 00:19:28,799
are histograms for uh

00:19:25,440 --> 00:19:31,360
pixel with without any heat insight so

00:19:28,799 --> 00:19:32,000
in principle this best classifier would

00:19:31,360 --> 00:19:35,679
have

00:19:32,000 --> 00:19:38,960
classified these pixels as zeros

00:19:35,679 --> 00:19:42,960
while the red curves are

00:19:38,960 --> 00:19:46,799
its uh pixels so pixels that

00:19:42,960 --> 00:19:50,400
would have been uh attached a score

00:19:46,799 --> 00:19:54,000
of one the uh

00:19:50,400 --> 00:19:57,520
the solid line is uh regards the cnn

00:19:54,000 --> 00:20:00,960
was the dust one the gcnn

00:19:57,520 --> 00:20:03,600
as you can see the gcnn is

00:20:00,960 --> 00:20:04,320
is more separated is less separated

00:20:03,600 --> 00:20:07,760
sorry

00:20:04,320 --> 00:20:11,039
than the cnn ones so as

00:20:07,760 --> 00:20:11,919
in the right as the right plot uh points

00:20:11,039 --> 00:20:15,120
out

00:20:11,919 --> 00:20:16,960
the cnn achieve a better performance uh

00:20:15,120 --> 00:20:18,400
also in receiving operating

00:20:16,960 --> 00:20:20,559
characteristic curve

00:20:18,400 --> 00:20:21,679
with the rendered curve parameter that

00:20:20,559 --> 00:20:27,200
is higher

00:20:21,679 --> 00:20:27,200
for the cnn of 0.996

00:20:27,679 --> 00:20:33,360
here we we present the uh

00:20:31,280 --> 00:20:36,320
results for the region of interest in

00:20:33,360 --> 00:20:38,480
the form of the two-dimensional plane

00:20:36,320 --> 00:20:39,360
we have the target in the first in the

00:20:38,480 --> 00:20:42,000
first plane

00:20:39,360 --> 00:20:43,840
while the second and third is the cnn

00:20:42,000 --> 00:20:47,360
and gcnn

00:20:43,840 --> 00:20:50,559
we see that neural networks perform good

00:20:47,360 --> 00:20:54,240
in the region of interest selection

00:20:50,559 --> 00:20:55,200
but isolated the pixels are difficult to

00:20:54,240 --> 00:20:58,320
be matched

00:20:55,200 --> 00:21:01,600
by these algorithms

00:20:58,320 --> 00:21:02,000
while they are targeting the clustered

00:21:01,600 --> 00:21:05,600
ones

00:21:02,000 --> 00:21:09,360
the cluster pixels so tracks like these

00:21:05,600 --> 00:21:12,080
in a really good way on the other hand

00:21:09,360 --> 00:21:14,559
kenny is performs poorly on this data

00:21:12,080 --> 00:21:18,320
set and focuses just on these cluster

00:21:14,559 --> 00:21:20,960
tracks but this performance is not

00:21:18,320 --> 00:21:22,080
high enough to compete with the with the

00:21:20,960 --> 00:21:24,960
the other

00:21:22,080 --> 00:21:24,960
neural networks

00:21:25,280 --> 00:21:30,080
as for the denoising benchmark we

00:21:27,440 --> 00:21:33,919
benchmark the noise organizing model

00:21:30,080 --> 00:21:35,520
so the full gig model against veneer

00:21:33,919 --> 00:21:38,159
filter algorithms these

00:21:35,520 --> 00:21:40,320
are just naive convolution with the

00:21:38,159 --> 00:21:42,400
gaussian filters

00:21:40,320 --> 00:21:43,600
we employ three different kind of

00:21:42,400 --> 00:21:46,559
filters uh

00:21:43,600 --> 00:21:48,480
one two three by three one five by five

00:21:46,559 --> 00:21:51,760
and one seven by seven

00:21:48,480 --> 00:21:54,080
we collected here the uh scores

00:21:51,760 --> 00:21:55,440
in terms of uh big signal tonight's

00:21:54,080 --> 00:21:58,640
ratio on the left

00:21:55,440 --> 00:21:59,600
and structural similarity values on the

00:21:58,640 --> 00:22:02,960
right

00:21:59,600 --> 00:22:06,159
on the the test data set and

00:22:02,960 --> 00:22:09,600
we see that the the gcnn

00:22:06,159 --> 00:22:12,960
achieved the best performances

00:22:09,600 --> 00:22:14,600
with the fixed peak signal to rise ratio

00:22:12,960 --> 00:22:17,600
of

00:22:14,600 --> 00:22:17,600
70.7.5

00:22:18,000 --> 00:22:22,080
now i'd like to present here

00:22:22,159 --> 00:22:25,200
a result for the denoising and to show

00:22:24,799 --> 00:22:28,559
here

00:22:25,200 --> 00:22:29,760
what's going on better i plot here the

00:22:28,559 --> 00:22:33,919
waveforms

00:22:29,760 --> 00:22:36,880
in a um one-dimensional view

00:22:33,919 --> 00:22:38,159
so on the x-axis we have the time time

00:22:36,880 --> 00:22:41,039
ticks

00:22:38,159 --> 00:22:43,120
and on the y-axis we have the adc values

00:22:41,039 --> 00:22:46,400
namely the the current values

00:22:43,120 --> 00:22:47,120
induced by the electrons you can see

00:22:46,400 --> 00:22:50,480
that

00:22:47,120 --> 00:22:53,120
on the top plot we have a wire with some

00:22:50,480 --> 00:22:53,679
it's inside so a wire that contains

00:22:53,120 --> 00:22:57,280
actual

00:22:53,679 --> 00:22:58,559
signal and this is uh given by the

00:22:57,280 --> 00:23:01,120
spikes here

00:22:58,559 --> 00:23:01,679
while on the lower plot we have a wire

00:23:01,120 --> 00:23:06,320
without

00:23:01,679 --> 00:23:09,520
any signal so um on the upper part

00:23:06,320 --> 00:23:13,520
you see you you can see the high uh

00:23:09,520 --> 00:23:18,320
end of this peak is uh is given

00:23:13,520 --> 00:23:22,880
by this gray line and it represents the

00:23:18,320 --> 00:23:25,919
target uh while the cnn and gcnn are

00:23:22,880 --> 00:23:29,120
respectively the orange and the

00:23:25,919 --> 00:23:33,120
violet curves they uh

00:23:29,120 --> 00:23:36,080
reconstruct uh perfectly the position

00:23:33,120 --> 00:23:36,880
so the position mean left or right and

00:23:36,080 --> 00:23:40,159
the shape

00:23:36,880 --> 00:23:43,520
of the peaks but struggles a bit

00:23:40,159 --> 00:23:48,000
they struggle a bit about the height

00:23:43,520 --> 00:23:50,159
of this peak on however

00:23:48,000 --> 00:23:51,120
the winner filters so the benchmark we

00:23:50,159 --> 00:23:53,840
made them

00:23:51,120 --> 00:23:54,559
are not able uh to reconstruct the

00:23:53,840 --> 00:23:58,720
position

00:23:54,559 --> 00:24:01,760
of the of the target spikes

00:23:58,720 --> 00:24:03,919
and show displaced peaks

00:24:01,760 --> 00:24:05,919
as you can see here in these greens by

00:24:03,919 --> 00:24:08,559
these greens lines

00:24:05,919 --> 00:24:09,440
on the other hand in the lower plot the

00:24:08,559 --> 00:24:12,640
target

00:24:09,440 --> 00:24:15,600
is hidden behind these these lines and

00:24:12,640 --> 00:24:17,039
since this uh this is a wire without any

00:24:15,600 --> 00:24:18,640
signal inside

00:24:17,039 --> 00:24:21,039
this could the target would be a

00:24:18,640 --> 00:24:23,919
constant function at zero

00:24:21,039 --> 00:24:25,600
and you can see that just the the best

00:24:23,919 --> 00:24:28,799
the best performing

00:24:25,600 --> 00:24:31,039
algorithm is the winner ones because the

00:24:28,799 --> 00:24:32,799
this binaries are closest to zero while

00:24:31,039 --> 00:24:37,120
the neural networks

00:24:32,799 --> 00:24:39,520
are slightly biased uh from below

00:24:37,120 --> 00:24:41,200
and maybe this is due to the fact that

00:24:39,520 --> 00:24:43,760
uh

00:24:41,200 --> 00:24:44,320
neural network are somehow reminiscent

00:24:43,760 --> 00:24:47,919
of

00:24:44,320 --> 00:24:51,600
the noisy inputs so they struggle to

00:24:47,919 --> 00:24:54,640
remove the noise from the empty space

00:24:51,600 --> 00:24:56,559
in summary we presented the denoising a

00:24:54,640 --> 00:24:58,240
region of interest selection models for

00:24:56,559 --> 00:25:01,039
proto-dune

00:24:58,240 --> 00:25:02,320
we employed simulation data so monte

00:25:01,039 --> 00:25:05,440
carlo data

00:25:02,320 --> 00:25:07,520
and we benchmarked our cnn and graph

00:25:05,440 --> 00:25:10,960
neural network models against basic

00:25:07,520 --> 00:25:14,880
algorithms the kenyan the vr filters

00:25:10,960 --> 00:25:15,600
and we decided in light of in light of

00:25:14,880 --> 00:25:18,480
the results

00:25:15,600 --> 00:25:20,720
we decided the best model is the cnn

00:25:18,480 --> 00:25:24,480
region of interest selection

00:25:20,720 --> 00:25:26,000
and a graph convolutional neural network

00:25:24,480 --> 00:25:29,679
denoiser

00:25:26,000 --> 00:25:32,000
for future work we uh commit to

00:25:29,679 --> 00:25:33,200
make a hyper parameter tuning to improve

00:25:32,000 --> 00:25:35,600
performances

00:25:33,200 --> 00:25:36,320
uh for the models thank you very much

00:25:35,600 --> 00:25:38,799
for uh

00:25:36,320 --> 00:25:42,720
attending this talk and let me know if

00:25:38,799 --> 00:25:42,720

YouTube URL: https://www.youtube.com/watch?v=YUpXzpMngY8


