Title: IBM open sources PowerAI as Open Cognitive Environment! - Jason Furmanek, IBM & Chris Sullivan
Publication date: 2020-09-21
Playlist: OpenPOWER Summit NA 2020
Description: 
	IBM open sources PowerAI as Open Cognitive Environment! - Jason Furmanek, IBM & Chris Sullivan, Oregon State University

Speakers: Chris Sullivan, Jason Furmanek

This talk is an introduction to a new open source project called Open Cognitive Environment (Open-CE).
Open-CE is a mid-stream integration community project that aims to foster collaboration between communities, vendors, user/enterprises, and academic institutions. Open-CE is designed to minimize the time to value and increase the consumability and inclusivity of important foundational AI and deep learning frameworks, libraries and tools, including TensorFlow and PyTorch, by providing a pre-integrated, multi-architectural set of recipes, build scripts, predefined Continuous Integration pipeline code and cutting edge models for building a complete environment of packages for AI development and/or production capacities.

Open-CE is based on the code from IBM's PowerAI project, which was launched to market as IBM Watson Machine Learning Community Edition. Therefore, Open-CE supports OpenPOWER (ppc64le) out of the box with options for GPU acceleration enablement throughout.
 
OpenCE provides even greater flexibility to users by embracing open source and removing barriers for users to build integrated packages and environments from source targeting platforms, environments and applications that users care about most. Build what you want, how you want it. We also hope to gain more members, users, builders and hosters for the project.
Captions: 
	00:00:00,640 --> 00:00:03,679
um okay i want to get started because

00:00:02,000 --> 00:00:05,759
we've got a lot to talk about

00:00:03,679 --> 00:00:07,200
a lot a lot of ex uh i'm excited to talk

00:00:05,759 --> 00:00:10,719
about this topic so

00:00:07,200 --> 00:00:12,480
um trying to maximize the time here um

00:00:10,719 --> 00:00:14,160
so we're gonna be talking about uh

00:00:12,480 --> 00:00:16,640
opence the open cognitive

00:00:14,160 --> 00:00:17,199
environment um it's a brand new open

00:00:16,640 --> 00:00:19,520
source

00:00:17,199 --> 00:00:20,400
contribution um kind of originated at

00:00:19,520 --> 00:00:22,160
ibm

00:00:20,400 --> 00:00:23,760
um so we talked about that and then

00:00:22,160 --> 00:00:25,359
talking about uh

00:00:23,760 --> 00:00:27,199
i'm talking to chris sullivan who's here

00:00:25,359 --> 00:00:28,480
with us as well he's from oregon state

00:00:27,199 --> 00:00:30,560
university

00:00:28,480 --> 00:00:32,399
about uh his involvement in the project

00:00:30,560 --> 00:00:36,079
and you know maybe we'll we'll

00:00:32,399 --> 00:00:37,760
get your involvement as well so um

00:00:36,079 --> 00:00:39,600
so we're gonna talk a lot about what

00:00:37,760 --> 00:00:40,960
opence is but i want to talk a little

00:00:39,600 --> 00:00:43,280
bit about the history as well

00:00:40,960 --> 00:00:44,960
um because we you know see where we came

00:00:43,280 --> 00:00:46,239
from so we can find out where we are and

00:00:44,960 --> 00:00:48,559
where we're going to go

00:00:46,239 --> 00:00:50,160
so if you're on the keynote this morning

00:00:48,559 --> 00:00:52,160
mindy uh

00:00:50,160 --> 00:00:53,440
the president of open powers was

00:00:52,160 --> 00:00:57,120
mentioning about

00:00:53,440 --> 00:00:59,199
uh you know power ai being um

00:00:57,120 --> 00:01:00,640
open source which is true right but you

00:00:59,199 --> 00:01:01,920
know there's you know ibm

00:01:00,640 --> 00:01:03,680
uses a lot of different terms so let's

00:01:01,920 --> 00:01:07,040
just kind of make sure we all understand

00:01:03,680 --> 00:01:08,640
that the history here um so back in 2016

00:01:07,040 --> 00:01:10,320
you know ibm was looking at uh

00:01:08,640 --> 00:01:12,479
bringing gpus to the power platform for

00:01:10,320 --> 00:01:14,960
the first time and working with nvidia

00:01:12,479 --> 00:01:16,799
and um there it was a lot of research

00:01:14,960 --> 00:01:17,280
going on and about workloads and things

00:01:16,799 --> 00:01:19,600
and

00:01:17,280 --> 00:01:21,119
you know the power ai project came into

00:01:19,600 --> 00:01:23,840
being at that point where

00:01:21,119 --> 00:01:25,200
um uh you know google had just open

00:01:23,840 --> 00:01:26,799
source tensorflow

00:01:25,200 --> 00:01:28,080
and cafe was out there for the first

00:01:26,799 --> 00:01:28,960
time these these deep learning

00:01:28,080 --> 00:01:31,840
frameworks which

00:01:28,960 --> 00:01:32,799
you know were perfect fit for gpus and

00:01:31,840 --> 00:01:34,640
seemed to perfect

00:01:32,799 --> 00:01:36,880
fit for the power platform as well just

00:01:34,640 --> 00:01:39,200
all the data centric aspects to them

00:01:36,880 --> 00:01:40,079
so um so that's at that point where the

00:01:39,200 --> 00:01:41,840
power i was

00:01:40,079 --> 00:01:43,600
was basically building these these

00:01:41,840 --> 00:01:44,560
packages for the platform making them

00:01:43,600 --> 00:01:47,040
available and then

00:01:44,560 --> 00:01:48,720
and investigating it um turns out they

00:01:47,040 --> 00:01:50,960
ran really well there

00:01:48,720 --> 00:01:54,640
so we wanted to offer those you know to

00:01:50,960 --> 00:01:56,079
customers in a supportable way um

00:01:54,640 --> 00:01:57,360
so that's kind of what power ai was it

00:01:56,079 --> 00:01:58,479
was it was like okay let's build these

00:01:57,360 --> 00:02:00,640
package packages

00:01:58,479 --> 00:02:02,159
make them available optimize them for

00:02:00,640 --> 00:02:05,200
the platform as best we could

00:02:02,159 --> 00:02:06,840
um and bring them to market and and you

00:02:05,200 --> 00:02:09,920
know a couple other

00:02:06,840 --> 00:02:11,520
uh products sprang out from that we had

00:02:09,920 --> 00:02:13,040
the the vision empowering enterprise

00:02:11,520 --> 00:02:15,520
that were all built on top of this kind

00:02:13,040 --> 00:02:19,120
of core power a set of set of frameworks

00:02:15,520 --> 00:02:19,680
um you know when we uh dropped that to

00:02:19,120 --> 00:02:22,319
market

00:02:19,680 --> 00:02:24,239
we you know we started to come you know

00:02:22,319 --> 00:02:26,480
how do we support these things how do we

00:02:24,239 --> 00:02:27,840
you know the upstream moves so fast and

00:02:26,480 --> 00:02:29,760
then um

00:02:27,840 --> 00:02:31,280
how do we support these and you know

00:02:29,760 --> 00:02:32,959
support our businesses that want us

00:02:31,280 --> 00:02:34,480
that cert wants certain versions of

00:02:32,959 --> 00:02:36,239
frameworks for for

00:02:34,480 --> 00:02:37,760
you know six to eight eight months or

00:02:36,239 --> 00:02:40,319
longer right we're in upstream

00:02:37,760 --> 00:02:41,280
having a a new version every six weeks

00:02:40,319 --> 00:02:44,400
so

00:02:41,280 --> 00:02:46,959
um so that became our new problem in

00:02:44,400 --> 00:02:48,319
more than just um you know porting these

00:02:46,959 --> 00:02:49,760
things because we did the porting we

00:02:48,319 --> 00:02:50,800
upstream most of it these are open

00:02:49,760 --> 00:02:52,160
projects they're all

00:02:50,800 --> 00:02:54,000
a lot of the the changes that we need to

00:02:52,160 --> 00:02:56,800
do were have been accepted

00:02:54,000 --> 00:02:57,280
um so you know what what what the

00:02:56,800 --> 00:03:00,400
project

00:02:57,280 --> 00:03:03,280
turned into uh was kind of like this

00:03:00,400 --> 00:03:03,840
this you know continually built ci

00:03:03,280 --> 00:03:05,599
project

00:03:03,840 --> 00:03:07,200
really um and it's kind of kind of an

00:03:05,599 --> 00:03:10,800
issue problem and this is kind of what

00:03:07,200 --> 00:03:12,640
we're open sourcing today so um the the

00:03:10,800 --> 00:03:14,159
you know so we actually have a new the

00:03:12,640 --> 00:03:15,840
the name for it was watson machine

00:03:14,159 --> 00:03:18,640
learning community edition was like the

00:03:15,840 --> 00:03:19,360
the latest name of it the power guy uh

00:03:18,640 --> 00:03:21,280
name what was

00:03:19,360 --> 00:03:23,120
is not being used like as a formal

00:03:21,280 --> 00:03:25,760
product name anymore but

00:03:23,120 --> 00:03:27,519
um but so now we're moving into this

00:03:25,760 --> 00:03:30,640
open ce environment

00:03:27,519 --> 00:03:32,879
uh open cognitive uh environment

00:03:30,640 --> 00:03:34,480
is what we're calling it so the the idea

00:03:32,879 --> 00:03:36,879
here is to take some of the

00:03:34,480 --> 00:03:38,159
what we learned on supporting fast

00:03:36,879 --> 00:03:41,200
moving open source

00:03:38,159 --> 00:03:45,120
ai projects and and

00:03:41,200 --> 00:03:48,720
you know bringing them to an enterprise

00:03:45,120 --> 00:03:51,040
and research you know level support so

00:03:48,720 --> 00:03:52,480
um so so you're so more rejected this is

00:03:51,040 --> 00:03:54,480
what like we we do aim

00:03:52,480 --> 00:03:56,560
at living at this mid midstream kind of

00:03:54,480 --> 00:03:58,640
level in openstream community i'll i'll

00:03:56,560 --> 00:04:00,080
um i'll illustrate this a little bit

00:03:58,640 --> 00:04:03,120
better on the next chart

00:04:00,080 --> 00:04:03,439
uh you know midstream is is an area that

00:04:03,120 --> 00:04:05,760
where

00:04:03,439 --> 00:04:08,080
red hat plays a lot in where you know

00:04:05,760 --> 00:04:10,560
the integration happens

00:04:08,080 --> 00:04:11,519
um in the open and then you that your

00:04:10,560 --> 00:04:14,480
downstream

00:04:11,519 --> 00:04:15,920
um is your product level and that's your

00:04:14,480 --> 00:04:17,680
support and your security fixes and your

00:04:15,920 --> 00:04:19,840
updates and whatnot right so

00:04:17,680 --> 00:04:21,359
um so having this you know there's a lot

00:04:19,840 --> 00:04:24,720
of collaboration that can help

00:04:21,359 --> 00:04:26,720
help uh the integration level so um so

00:04:24,720 --> 00:04:28,960
focusing on the midstream is is

00:04:26,720 --> 00:04:31,520
really kind of what we do in a lot of

00:04:28,960 --> 00:04:35,120
this in this this power environment so

00:04:31,520 --> 00:04:38,800
um so um can i can i mention

00:04:35,120 --> 00:04:41,120
the um the one piece which is that this

00:04:38,800 --> 00:04:43,680
power ai really provided these optimized

00:04:41,120 --> 00:04:45,680
pipelines to the end user in a way that

00:04:43,680 --> 00:04:48,240
enabled them to focus in on their work

00:04:45,680 --> 00:04:51,199
and lower their activation energy

00:04:48,240 --> 00:04:52,000
and that ibm really did listen to the

00:04:51,199 --> 00:04:53,440
community

00:04:52,000 --> 00:04:54,960
while we were doing this and that's the

00:04:53,440 --> 00:04:56,080
evolution history you see on the

00:04:54,960 --> 00:04:58,800
right-hand side

00:04:56,080 --> 00:05:00,240
but yeah thanks for mentioning that

00:04:58,800 --> 00:05:02,080
that's one of the the other

00:05:00,240 --> 00:05:03,280
foundations of what we did in the

00:05:02,080 --> 00:05:06,400
project was

00:05:03,280 --> 00:05:07,520
um you know these these frameworks are

00:05:06,400 --> 00:05:10,800
heavily

00:05:07,520 --> 00:05:11,840
um you know influenced by the hardware

00:05:10,800 --> 00:05:13,759
they run on there's the

00:05:11,840 --> 00:05:14,960
gpu enabled we want the the most

00:05:13,759 --> 00:05:18,560
optimized

00:05:14,960 --> 00:05:20,880
uh hardware builds you know possible

00:05:18,560 --> 00:05:22,880
and all that all that's very hard to do

00:05:20,880 --> 00:05:24,479
like you know it's like we want the

00:05:22,880 --> 00:05:25,680
running on x86 we want the best

00:05:24,479 --> 00:05:27,039
optimized version of that for the

00:05:25,680 --> 00:05:29,039
hardware we run on

00:05:27,039 --> 00:05:30,960
the same thing on power and we want it

00:05:29,039 --> 00:05:34,560
easily consumable and easily usable

00:05:30,960 --> 00:05:36,720
right um so uh that you know that's

00:05:34,560 --> 00:05:37,600
one of the foundations of of the project

00:05:36,720 --> 00:05:39,120
as well

00:05:37,600 --> 00:05:40,800
um we don't want people to have to worry

00:05:39,120 --> 00:05:43,919
about that right so and then

00:05:40,800 --> 00:05:45,520
we'll talk uh a little bit more about

00:05:43,919 --> 00:05:47,759
um why we do this way instead of just

00:05:45,520 --> 00:05:48,160
relying on on pip and stuff and upstream

00:05:47,759 --> 00:05:52,080
as well

00:05:48,160 --> 00:05:54,720
so um what it comes down to

00:05:52,080 --> 00:05:56,319
though is providing this this flexible

00:05:54,720 --> 00:05:57,840
source to image kind of solution i want

00:05:56,319 --> 00:06:01,520
to be my source image

00:05:57,840 --> 00:06:04,639
is um you know taking the power

00:06:01,520 --> 00:06:08,479
of uh the binaries uh

00:06:04,639 --> 00:06:10,880
back right so in in order to give you

00:06:08,479 --> 00:06:11,840
the power of control of what you're

00:06:10,880 --> 00:06:13,840
actually running

00:06:11,840 --> 00:06:15,360
as far as optimization as far as fixes

00:06:13,840 --> 00:06:20,160
as far as um

00:06:15,360 --> 00:06:21,600
uh updates and whatnot so um

00:06:20,160 --> 00:06:23,520
let me show a little bit more what we

00:06:21,600 --> 00:06:25,440
mean by midstream here we have uh

00:06:23,520 --> 00:06:26,880
if we're looking at like a tensorflow or

00:06:25,440 --> 00:06:28,880
pi torch um

00:06:26,880 --> 00:06:30,720
obviously we've got the the upstream

00:06:28,880 --> 00:06:32,639
open source projects that are you know

00:06:30,720 --> 00:06:33,840
mostly run by uh google and test flow

00:06:32,639 --> 00:06:35,440
but there are there are open

00:06:33,840 --> 00:06:36,880
contributions as well

00:06:35,440 --> 00:06:38,960
especially when it comes to hardware

00:06:36,880 --> 00:06:41,680
right we we um

00:06:38,960 --> 00:06:42,880
uh on the power seam we put a lot of the

00:06:41,680 --> 00:06:44,479
updates needed

00:06:42,880 --> 00:06:47,680
uh to get these frameworks to work in

00:06:44,479 --> 00:06:50,240
the upstream little box there

00:06:47,680 --> 00:06:51,280
but uh what we found when we were doing

00:06:50,240 --> 00:06:53,599
a lot of these

00:06:51,280 --> 00:06:55,440
doing this initial enablement is the

00:06:53,599 --> 00:06:58,880
these ai frameworks are

00:06:55,440 --> 00:07:01,759
have widely complex dependency chains

00:06:58,880 --> 00:07:02,080
so tensorflow itself i think has 87 open

00:07:01,759 --> 00:07:05,520
source

00:07:02,080 --> 00:07:07,280
projects that it relies on so um

00:07:05,520 --> 00:07:08,720
you know so you know building that once

00:07:07,280 --> 00:07:09,520
and shipping it out the door okay you

00:07:08,720 --> 00:07:12,639
can do that

00:07:09,520 --> 00:07:16,000
what about keeping three versions of it

00:07:12,639 --> 00:07:18,479
in support both with security fixes and

00:07:16,000 --> 00:07:19,440
you know um you know just functional

00:07:18,479 --> 00:07:21,440
fixes

00:07:19,440 --> 00:07:23,599
um it becomes a difficult problem

00:07:21,440 --> 00:07:25,599
especially with all the the dependencies

00:07:23,599 --> 00:07:27,280
that that it relies on and then add

00:07:25,599 --> 00:07:30,400
pytorch to the mix which is also widely

00:07:27,280 --> 00:07:32,960
complex how do you how do you have those

00:07:30,400 --> 00:07:34,639
uh enviro all these dependencies work in

00:07:32,960 --> 00:07:36,000
the same environment together

00:07:34,639 --> 00:07:38,479
and that's what we wanted to do with

00:07:36,000 --> 00:07:40,720
power we wanted like ease of use just

00:07:38,479 --> 00:07:43,120
hit go and you get all of the ai

00:07:40,720 --> 00:07:44,560
frameworks into a single environment

00:07:43,120 --> 00:07:45,840
where does that integration happen so

00:07:44,560 --> 00:07:46,879
that integration happens in the

00:07:45,840 --> 00:07:49,360
midstream and

00:07:46,879 --> 00:07:50,879
um and it does make sense to kind of

00:07:49,360 --> 00:07:54,319
move this to an open

00:07:50,879 --> 00:07:56,400
uh model where um

00:07:54,319 --> 00:07:57,599
all the different people that have needs

00:07:56,400 --> 00:07:59,919
on this type of thing can

00:07:57,599 --> 00:08:00,800
can uh have input on it like which

00:07:59,919 --> 00:08:03,360
version of

00:08:00,800 --> 00:08:04,400
uh tensorflow do we want and then which

00:08:03,360 --> 00:08:06,639
which ecosix

00:08:04,400 --> 00:08:08,080
ecosystem packages around it do we want

00:08:06,639 --> 00:08:09,360
to include an environment that we can

00:08:08,080 --> 00:08:11,520
pre-integrate

00:08:09,360 --> 00:08:12,720
and then click a button and build build

00:08:11,520 --> 00:08:13,840
the environment and put it into

00:08:12,720 --> 00:08:16,400
production

00:08:13,840 --> 00:08:18,160
um so that's you know that that's kind

00:08:16,400 --> 00:08:21,440
of the the model here that we're

00:08:18,160 --> 00:08:23,280
we're moving towards and um in this

00:08:21,440 --> 00:08:24,720
what else we mean by the this source to

00:08:23,280 --> 00:08:27,919
image kind of model right

00:08:24,720 --> 00:08:29,840
is which which with the advent of

00:08:27,919 --> 00:08:32,080
you know or the popularity of hybrid

00:08:29,840 --> 00:08:35,760
clouds when people have maybe have

00:08:32,080 --> 00:08:37,760
a large openshift cluster on site now um

00:08:35,760 --> 00:08:39,039
you know we want a target to be able to

00:08:37,760 --> 00:08:40,080
you know leverage some of these

00:08:39,039 --> 00:08:41,919
resources

00:08:40,080 --> 00:08:44,000
both you know in a hybrid cloud or out

00:08:41,919 --> 00:08:45,680
in a research institution like

00:08:44,000 --> 00:08:48,560
oregon state you know just click a

00:08:45,680 --> 00:08:50,959
button and get your pre-integrated set

00:08:48,560 --> 00:08:52,839
of packages in a you know coherent

00:08:50,959 --> 00:08:56,320
cognitive environment

00:08:52,839 --> 00:08:59,200
um so another uh key

00:08:56,320 --> 00:09:00,080
uh piece of this is the hermetic builds

00:08:59,200 --> 00:09:01,760
um we

00:09:00,080 --> 00:09:03,120
you know we want to be able to have this

00:09:01,760 --> 00:09:05,760
build the same way

00:09:03,120 --> 00:09:06,640
no matter your environment um you know

00:09:05,760 --> 00:09:09,440
so that's

00:09:06,640 --> 00:09:10,160
that's a big piece of it and um today we

00:09:09,440 --> 00:09:11,920
leverage

00:09:10,160 --> 00:09:14,240
conda kinda is really really good at

00:09:11,920 --> 00:09:16,240
that uh there's a couple of reasons you

00:09:14,240 --> 00:09:17,279
can't uh i'll i'll get to you in just a

00:09:16,240 --> 00:09:20,320
second

00:09:17,279 --> 00:09:23,440
um and then uh so you know

00:09:20,320 --> 00:09:26,000
but the end result is a standard

00:09:23,440 --> 00:09:27,040
standardized uh set of content and

00:09:26,000 --> 00:09:30,000
versions

00:09:27,040 --> 00:09:31,680
uh for the community you know to to use

00:09:30,000 --> 00:09:33,760
and and to kind of standardize on like

00:09:31,680 --> 00:09:37,040
all the stuff moves so fast

00:09:33,760 --> 00:09:39,360
um you know if you need something like

00:09:37,040 --> 00:09:40,800
uh hugging face transformers which is a

00:09:39,360 --> 00:09:44,000
very advanced

00:09:40,800 --> 00:09:46,800
uh set of models for uh

00:09:44,000 --> 00:09:48,320
natural language right and and you know

00:09:46,800 --> 00:09:49,440
but you also need a certain version of

00:09:48,320 --> 00:09:52,320
tensorflow which

00:09:49,440 --> 00:09:53,600
versions do i pick right so and and what

00:09:52,320 --> 00:09:53,839
about all the other dependencies that

00:09:53,600 --> 00:09:56,320
are

00:09:53,839 --> 00:09:57,920
involved with that now that integration

00:09:56,320 --> 00:09:58,320
can happen right here in the mid stream

00:09:57,920 --> 00:10:01,360
you

00:09:58,320 --> 00:10:03,440
get involved in this project and

00:10:01,360 --> 00:10:05,200
um you know we can get that integration

00:10:03,440 --> 00:10:06,959
out of the way and and we can

00:10:05,200 --> 00:10:08,959
get to get down to business and actually

00:10:06,959 --> 00:10:12,240
doing the research right so

00:10:08,959 --> 00:10:15,600
um that's that's part of the the

00:10:12,240 --> 00:10:18,640
the other tenant of this project

00:10:15,600 --> 00:10:19,680
um so i mentioned uh conda i i think you

00:10:18,640 --> 00:10:22,959
know

00:10:19,680 --> 00:10:24,720
there's uh a couple charts here on on

00:10:22,959 --> 00:10:26,480
you know why we're while we're doing

00:10:24,720 --> 00:10:28,800
some of the technologies that we picked

00:10:26,480 --> 00:10:29,760
what you know we did pick conda in in

00:10:28,800 --> 00:10:33,440
power ai

00:10:29,760 --> 00:10:34,880
um it's it's uh our multi-architecture

00:10:33,440 --> 00:10:36,800
by default but

00:10:34,880 --> 00:10:38,079
um it's kind of the only way that the

00:10:36,800 --> 00:10:40,480
only reason

00:10:38,079 --> 00:10:42,560
one of the other reasons is you know if

00:10:40,480 --> 00:10:44,160
relying strictly on wheel files and in

00:10:42,560 --> 00:10:46,480
the python community

00:10:44,160 --> 00:10:47,680
um has a lot of that a lot of bounce a

00:10:46,480 --> 00:10:51,200
lot of limitations

00:10:47,680 --> 00:10:52,880
to the whole uh environment of wheel

00:10:51,200 --> 00:10:54,640
files and pi pi

00:10:52,880 --> 00:10:56,480
um you know that they're they're getting

00:10:54,640 --> 00:10:58,480
better and part of

00:10:56,480 --> 00:11:00,480
in part of why they're getting better is

00:10:58,480 --> 00:11:03,760
there's communities like tensorflow that

00:11:00,480 --> 00:11:06,240
are outstripping the the capabilities of

00:11:03,760 --> 00:11:07,839
pip and pi by and are pushing the

00:11:06,240 --> 00:11:10,000
community forward be able to

00:11:07,839 --> 00:11:11,360
to include things like basic metadata

00:11:10,000 --> 00:11:14,480
for for cuda

00:11:11,360 --> 00:11:15,200
or um you know even like what kind of

00:11:14,480 --> 00:11:18,079
basic

00:11:15,200 --> 00:11:20,079
uh uh foundational uh libraries that you

00:11:18,079 --> 00:11:23,760
rely on so it's compatible

00:11:20,079 --> 00:11:24,160
um but with conda it's it's already kind

00:11:23,760 --> 00:11:25,920
of all

00:11:24,160 --> 00:11:27,360
baked into this you know baked into the

00:11:25,920 --> 00:11:29,279
tool set there's a

00:11:27,360 --> 00:11:31,680
there's a separate tool chain kind of

00:11:29,279 --> 00:11:35,040
uses it's it's hermetic by default

00:11:31,680 --> 00:11:38,720
um and you know it's it's easy to

00:11:35,040 --> 00:11:39,519
uh uh too easy to use and then there's

00:11:38,720 --> 00:11:42,959
also

00:11:39,519 --> 00:11:45,120
a real solve solver um dependency solver

00:11:42,959 --> 00:11:48,640
that's built in where pip does not

00:11:45,120 --> 00:11:50,320
um so it's

00:11:48,640 --> 00:11:51,680
another chart here just kind of uh

00:11:50,320 --> 00:11:54,880
underlying the fact that

00:11:51,680 --> 00:11:56,639
on kind of being the initial first

00:11:54,880 --> 00:11:57,680
direction for us which which isn't to

00:11:56,639 --> 00:11:59,920
say that

00:11:57,680 --> 00:12:00,800
it's not possible to do will file uh

00:11:59,920 --> 00:12:03,600
builds

00:12:00,800 --> 00:12:04,959
uh with opence we can certainly add that

00:12:03,600 --> 00:12:06,320
especially if there's people in the

00:12:04,959 --> 00:12:08,480
community that wanted it

00:12:06,320 --> 00:12:10,000
it'd be great we'd love to love to work

00:12:08,480 --> 00:12:12,480
on it um it's just that

00:12:10,000 --> 00:12:13,680
condos they're just so much so much

00:12:12,480 --> 00:12:15,120
further ahead

00:12:13,680 --> 00:12:17,040
in the community as far as as far as

00:12:15,120 --> 00:12:19,279
that goes so um

00:12:17,040 --> 00:12:20,480
yeah so things like the mini linux uh

00:12:19,279 --> 00:12:23,360
standards and

00:12:20,480 --> 00:12:24,639
pip m and um some of the new things that

00:12:23,360 --> 00:12:27,279
are coming in the in

00:12:24,639 --> 00:12:28,880
in the python community environments um

00:12:27,279 --> 00:12:31,600
are all good things to track and

00:12:28,880 --> 00:12:33,519
we will be looking at that as well um

00:12:31,600 --> 00:12:34,639
red hat has a project called uh those

00:12:33,519 --> 00:12:38,240
station

00:12:34,639 --> 00:12:39,360
that that is also uh a sourced image

00:12:38,240 --> 00:12:42,399
kind of builder

00:12:39,360 --> 00:12:45,200
uh focused around um

00:12:42,399 --> 00:12:46,560
pi pi and you know wheel files and you

00:12:45,200 --> 00:12:47,440
know that's something to watch as well

00:12:46,560 --> 00:12:48,800
in this environment

00:12:47,440 --> 00:12:51,279
we'd love to integrate with that at some

00:12:48,800 --> 00:12:52,720
point um

00:12:51,279 --> 00:12:54,800
okay so that's you know that's why we do

00:12:52,720 --> 00:12:57,680
kinda uh

00:12:54,800 --> 00:12:59,040
the benefits of an open approach i think

00:12:57,680 --> 00:13:00,480
are pretty obvious we're all an open

00:12:59,040 --> 00:13:03,680
power here right so

00:13:00,480 --> 00:13:05,440
we came here to to learn about um open

00:13:03,680 --> 00:13:06,480
things how do we how we work together

00:13:05,440 --> 00:13:09,279
how do we

00:13:06,480 --> 00:13:10,720
um collaborate right the fact of the

00:13:09,279 --> 00:13:12,560
matter is open communities

00:13:10,720 --> 00:13:14,320
can move faster they they really can so

00:13:12,560 --> 00:13:17,760
the um

00:13:14,320 --> 00:13:19,040
the speed at which these upstream

00:13:17,760 --> 00:13:22,399
communities

00:13:19,040 --> 00:13:25,920
move at is is impressive right they they

00:13:22,399 --> 00:13:26,560
um we need focus from all over to be

00:13:25,920 --> 00:13:29,920
able to

00:13:26,560 --> 00:13:30,639
uh uh you know keep up with that right

00:13:29,920 --> 00:13:33,279
and

00:13:30,639 --> 00:13:35,200
um so that's definitely an open

00:13:33,279 --> 00:13:38,880
community moves faster kind of story

00:13:35,200 --> 00:13:41,199
that the um you know the content as well

00:13:38,880 --> 00:13:42,320
right is is good to farm out in an open

00:13:41,199 --> 00:13:45,600
way right if

00:13:42,320 --> 00:13:49,040
we have a a singular focus on

00:13:45,600 --> 00:13:50,639
the things that ibm wants uh for example

00:13:49,040 --> 00:13:51,920
with power i was like we knew we wanted

00:13:50,639 --> 00:13:54,560
with it we use this stuff

00:13:51,920 --> 00:13:55,920
internally as well um that's great we

00:13:54,560 --> 00:13:57,519
can get it in but what about

00:13:55,920 --> 00:14:00,079
you know the six other things that are

00:13:57,519 --> 00:14:02,079
needed by a customer over here and a

00:14:00,079 --> 00:14:03,839
research environment up here um

00:14:02,079 --> 00:14:05,120
if this was a open collaborative

00:14:03,839 --> 00:14:06,160
environment like we're trying to do with

00:14:05,120 --> 00:14:08,079
opence then

00:14:06,160 --> 00:14:09,760
then you know that that could just be

00:14:08,079 --> 00:14:11,279
added uh you can get added to the

00:14:09,760 --> 00:14:12,000
community or you take it out and you add

00:14:11,279 --> 00:14:14,639
it yourself

00:14:12,000 --> 00:14:15,360
as you build it right um so you know

00:14:14,639 --> 00:14:17,199
just the

00:14:15,360 --> 00:14:18,560
the general community set direction

00:14:17,199 --> 00:14:20,320
especially in the midstream where we're

00:14:18,560 --> 00:14:22,240
trying to do this collaboration work

00:14:20,320 --> 00:14:23,839
uh makes a whole lot of sense and it

00:14:22,240 --> 00:14:26,560
makes uh even makes

00:14:23,839 --> 00:14:27,279
enterprise support downstream easier

00:14:26,560 --> 00:14:30,000
right

00:14:27,279 --> 00:14:31,680
um the most expensive part of a life

00:14:30,000 --> 00:14:33,519
cycle

00:14:31,680 --> 00:14:34,800
of a software life cycle is that

00:14:33,519 --> 00:14:36,880
downstream you know

00:14:34,800 --> 00:14:39,199
support where you're interacting with

00:14:36,880 --> 00:14:40,800
customers and fixing their problems and

00:14:39,199 --> 00:14:42,839
you know have boots on the ground kind

00:14:40,800 --> 00:14:46,399
of thing if something goes wrong

00:14:42,839 --> 00:14:48,000
um you know so you you need it to be

00:14:46,399 --> 00:14:49,920
as good as possible and you need it to

00:14:48,000 --> 00:14:52,320
be as fast as possible you need it

00:14:49,920 --> 00:14:53,120
uh to solve everybody's problems right

00:14:52,320 --> 00:14:56,399
so

00:14:53,120 --> 00:14:58,959
um so yeah so you know

00:14:56,399 --> 00:14:59,600
just general usage freedom right get the

00:14:58,959 --> 00:15:01,920
you know you

00:14:59,600 --> 00:15:03,440
you want the function that that you want

00:15:01,920 --> 00:15:05,519
with the fixes that you want when you

00:15:03,440 --> 00:15:08,639
want it how you want it right so

00:15:05,519 --> 00:15:11,600
um and that kind of you know goes to

00:15:08,639 --> 00:15:11,600
the um

00:15:11,680 --> 00:15:18,639
uh back to the point of uh

00:15:15,600 --> 00:15:19,839
why conda or why why we do this at all

00:15:18,639 --> 00:15:23,600
actually right it's

00:15:19,839 --> 00:15:25,279
it's um part of the the

00:15:23,600 --> 00:15:28,480
in part of the reason is control right

00:15:25,279 --> 00:15:31,680
so if if we if we rely on

00:15:28,480 --> 00:15:32,000
uh packages from pip which are pretty

00:15:31,680 --> 00:15:34,399
great

00:15:32,000 --> 00:15:35,600
by the way google puts stuff out there

00:15:34,399 --> 00:15:36,480
really quickly for tensorflow for

00:15:35,600 --> 00:15:39,759
example

00:15:36,480 --> 00:15:41,839
um but at the same time they patch

00:15:39,759 --> 00:15:43,360
security patch it when they want to they

00:15:41,839 --> 00:15:44,000
support certain versions that they want

00:15:43,360 --> 00:15:46,720
to

00:15:44,000 --> 00:15:47,600
uh and they they build towards hardware

00:15:46,720 --> 00:15:49,279
that they use

00:15:47,600 --> 00:15:50,639
right so they you know tensorflow

00:15:49,279 --> 00:15:53,120
actually supports a lot

00:15:50,639 --> 00:15:55,040
newer version of the intel you know

00:15:53,120 --> 00:15:57,680
vector instructions for example

00:15:55,040 --> 00:15:59,600
um with power there's a little bit less

00:15:57,680 --> 00:16:00,320
variety so we can kind of control a

00:15:59,600 --> 00:16:02,720
little bit more

00:16:00,320 --> 00:16:04,560
uh when we build there although there is

00:16:02,720 --> 00:16:05,519
no pit packages for power too that's the

00:16:04,560 --> 00:16:08,480
other problem

00:16:05,519 --> 00:16:10,560
um but a lot of people build tensorflow

00:16:08,480 --> 00:16:12,000
themselves even on x86 because they want

00:16:10,560 --> 00:16:13,040
to take advantage of their hardware

00:16:12,000 --> 00:16:15,120
right so

00:16:13,040 --> 00:16:17,199
um that's the other thing to keep take

00:16:15,120 --> 00:16:20,800
advantage of the hardware that you have

00:16:17,199 --> 00:16:23,600
um but but you know but also

00:16:20,800 --> 00:16:24,720
be within a community and a project that

00:16:23,600 --> 00:16:27,279
will make it work

00:16:24,720 --> 00:16:28,639
right um and you know if you build

00:16:27,279 --> 00:16:30,079
yourself you're on your own as far as

00:16:28,639 --> 00:16:31,440
tensorflow is concerned

00:16:30,079 --> 00:16:33,279
uh we don't want you to be on your own

00:16:31,440 --> 00:16:34,639
we want to we want it to be a

00:16:33,279 --> 00:16:36,320
collaborative community where we can

00:16:34,639 --> 00:16:37,680
build all this together have it work

00:16:36,320 --> 00:16:40,160
and have it work the way you want to

00:16:37,680 --> 00:16:41,279
work give me about 10 minutes left

00:16:40,160 --> 00:16:43,519
before questions

00:16:41,279 --> 00:16:44,880
okay perfect like let me do just the

00:16:43,519 --> 00:16:46,079
content here and we'll kick it over to

00:16:44,880 --> 00:16:48,880
your charts chris

00:16:46,079 --> 00:16:49,680
so um that you know the stuff that we'll

00:16:48,880 --> 00:16:51,360
include

00:16:49,680 --> 00:16:53,519
is you know obviously that since flown

00:16:51,360 --> 00:16:57,279
pie charge ecosystems i think the

00:16:53,519 --> 00:16:58,800
each release of uh open ce will have

00:16:57,279 --> 00:16:59,360
like a new version of each one of those

00:16:58,800 --> 00:17:01,519
and then

00:16:59,360 --> 00:17:03,040
whatever else we kind of come happens to

00:17:01,519 --> 00:17:04,000
be there at the time as far as

00:17:03,040 --> 00:17:05,760
versioning

00:17:04,000 --> 00:17:07,120
um we also include xg boost and then

00:17:05,760 --> 00:17:08,480
things like um

00:17:07,120 --> 00:17:09,760
spacey and then what i mentioned

00:17:08,480 --> 00:17:11,280
transformers from hugging face we're

00:17:09,760 --> 00:17:14,160
gonna include that as well

00:17:11,280 --> 00:17:15,600
um we'll have a set of docker files

00:17:14,160 --> 00:17:17,520
that'll spit out from this in addition

00:17:15,600 --> 00:17:20,720
to the conda packages

00:17:17,520 --> 00:17:23,520
and then we also have a a

00:17:20,720 --> 00:17:24,959
you know a complete set of ci and

00:17:23,520 --> 00:17:28,319
pipeline targets

00:17:24,959 --> 00:17:28,960
for um for building this stuff right so

00:17:28,319 --> 00:17:31,679
we'll have

00:17:28,960 --> 00:17:32,240
a complete local build setup and then

00:17:31,679 --> 00:17:36,720
we're also

00:17:32,240 --> 00:17:38,960
working on a argo uh kubernetes native

00:17:36,720 --> 00:17:40,320
uh ci environment where you will it'll

00:17:38,960 --> 00:17:43,039
take a

00:17:40,320 --> 00:17:45,120
dependency graph output from you know

00:17:43,039 --> 00:17:46,880
the basic scripts and then it'll feed

00:17:45,120 --> 00:17:48,640
into a kubernetes argo

00:17:46,880 --> 00:17:51,120
setup and and build everything in

00:17:48,640 --> 00:17:51,919
parallel so this uh which kind of really

00:17:51,120 --> 00:17:54,559
brings this

00:17:51,919 --> 00:17:55,520
source to image uh project kind of alive

00:17:54,559 --> 00:17:57,280
right you can

00:17:55,520 --> 00:17:59,840
um these stuff takes a lot of time to

00:17:57,280 --> 00:18:00,080
build but if you have the power of a you

00:17:59,840 --> 00:18:02,559
know

00:18:00,080 --> 00:18:04,320
multi-node kubernetes cluster that you

00:18:02,559 --> 00:18:06,080
can you know constantly keep it high

00:18:04,320 --> 00:18:06,559
utilization by building the stuff as you

00:18:06,080 --> 00:18:09,039
need it

00:18:06,559 --> 00:18:10,960
um so there you go that's another piece

00:18:09,039 --> 00:18:13,120
of the value there

00:18:10,960 --> 00:18:14,640
um and that's just kind of underlying

00:18:13,120 --> 00:18:17,760
the uh

00:18:14,640 --> 00:18:19,840
the cips here so uh

00:18:17,760 --> 00:18:21,679
multi-platform is the goal uh we we have

00:18:19,840 --> 00:18:25,360
a power heritage

00:18:21,679 --> 00:18:25,760
um you know but a big piece of the value

00:18:25,360 --> 00:18:27,919
here

00:18:25,760 --> 00:18:31,360
is you know support for the hardware

00:18:27,919 --> 00:18:32,880
that you want right so and you need

00:18:31,360 --> 00:18:34,480
okay so chris let's hop over to you we

00:18:32,880 --> 00:18:36,960
can uh

00:18:34,480 --> 00:18:38,640
introduce how oregon state university is

00:18:36,960 --> 00:18:41,200
going to be involved

00:18:38,640 --> 00:18:42,320
great so um i know there's something in

00:18:41,200 --> 00:18:43,039
the chat there you have 10 minutes

00:18:42,320 --> 00:18:46,400
remaining

00:18:43,039 --> 00:18:48,960
all right so um oregon state university

00:18:46,400 --> 00:18:51,440
um is one of these downstream groups

00:18:48,960 --> 00:18:54,960
that was leveraging the power ai system

00:18:51,440 --> 00:18:55,919
and um i want to give a one second about

00:18:54,960 --> 00:18:57,840
the background

00:18:55,919 --> 00:18:58,960
on why we do this uh oregon state

00:18:57,840 --> 00:19:00,880
university has

00:18:58,960 --> 00:19:02,000
uh first and foremost what we call the

00:19:00,880 --> 00:19:04,400
open source lab

00:19:02,000 --> 00:19:06,000
and this group is out there helping open

00:19:04,400 --> 00:19:08,480
source software

00:19:06,000 --> 00:19:09,440
um become more accessible uh get people

00:19:08,480 --> 00:19:12,480
involved in them

00:19:09,440 --> 00:19:14,799
and provide access and so we're already

00:19:12,480 --> 00:19:16,559
doing that for about 160 projects lance

00:19:14,799 --> 00:19:19,039
albertson gets credit for that

00:19:16,559 --> 00:19:20,160
he uh he helps manage that through uh

00:19:19,039 --> 00:19:21,919
through the campus

00:19:20,160 --> 00:19:24,160
and through the campus school of

00:19:21,919 --> 00:19:26,240
electrical engineering um

00:19:24,160 --> 00:19:28,240
and things like the apache software

00:19:26,240 --> 00:19:29,679
foundation drupal all kinds of stuff

00:19:28,240 --> 00:19:30,400
will be hosted out of oregon state

00:19:29,679 --> 00:19:33,840
university

00:19:30,400 --> 00:19:35,679
and uh we have a large openstack cluster

00:19:33,840 --> 00:19:37,280
that osu managed with game things and

00:19:35,679 --> 00:19:39,360
all the tools ready to go

00:19:37,280 --> 00:19:40,559
for users and continuous development to

00:19:39,360 --> 00:19:42,000
occur

00:19:40,559 --> 00:19:43,440
uh the group that i'm part of is called

00:19:42,000 --> 00:19:44,160
the center for genome research and bio

00:19:43,440 --> 00:19:45,600
computing

00:19:44,160 --> 00:19:46,880
and we're really one of those research

00:19:45,600 --> 00:19:48,799
groups that take advantage of this

00:19:46,880 --> 00:19:49,840
technology and leverages for research

00:19:48,799 --> 00:19:52,000
purposes

00:19:49,840 --> 00:19:53,760
and uh one of our main focus is to take

00:19:52,000 --> 00:19:55,440
technologies and integrate them in a way

00:19:53,760 --> 00:19:57,919
that reduces the impact

00:19:55,440 --> 00:19:59,200
to our researchers and power ai really

00:19:57,919 --> 00:20:02,000
did that for us

00:19:59,200 --> 00:20:03,760
and we work with a large group of users

00:20:02,000 --> 00:20:04,880
across almost every single department on

00:20:03,760 --> 00:20:07,200
our campus

00:20:04,880 --> 00:20:08,240
and one of the things that we bring to

00:20:07,200 --> 00:20:09,760
the table

00:20:08,240 --> 00:20:11,600
is the ability to interact with these

00:20:09,760 --> 00:20:14,000
gpu technologies we've been

00:20:11,600 --> 00:20:14,880
compiling software stacks for many many

00:20:14,000 --> 00:20:18,480
years

00:20:14,880 --> 00:20:18,960
and we've been able to show the value of

00:20:18,480 --> 00:20:21,840
the

00:20:18,960 --> 00:20:25,039
multi-architecture infrastructures jason

00:20:21,840 --> 00:20:25,039
can you switch the slides for me

00:20:25,360 --> 00:20:30,320
thank you so really when we looked at

00:20:28,000 --> 00:20:33,039
this opportunity we saw that there was

00:20:30,320 --> 00:20:34,000
uh already a pathway in place and we

00:20:33,039 --> 00:20:36,240
wanted to help

00:20:34,000 --> 00:20:38,000
uh take over a piece of that pathway and

00:20:36,240 --> 00:20:40,640
kind of stick ourselves in the middle

00:20:38,000 --> 00:20:42,480
uh there were the upstream releases um

00:20:40,640 --> 00:20:44,320
we kind of called it that time the well

00:20:42,480 --> 00:20:46,080
well west uncoordinated

00:20:44,320 --> 00:20:48,080
and really that's where things should be

00:20:46,080 --> 00:20:50,400
for a lot of developers testing and

00:20:48,080 --> 00:20:51,120
making things kind of change and come to

00:20:50,400 --> 00:20:53,520
life

00:20:51,120 --> 00:20:54,240
and then ultimately there's this you

00:20:53,520 --> 00:20:55,840
know

00:20:54,240 --> 00:20:57,360
midstream in the mid streams where we're

00:20:55,840 --> 00:20:58,480
going to kind of put things back

00:20:57,360 --> 00:21:01,679
together and and

00:20:58,480 --> 00:21:02,480
try and create these releases of this

00:21:01,679 --> 00:21:05,200
upstream

00:21:02,480 --> 00:21:07,120
uh technologies and we're really looking

00:21:05,200 --> 00:21:09,360
at how we can put those releases in a

00:21:07,120 --> 00:21:11,360
way for the community to be involved

00:21:09,360 --> 00:21:12,880
and actually work with us to to actually

00:21:11,360 --> 00:21:15,600
get those out

00:21:12,880 --> 00:21:16,320
we'll be looking at how we can release

00:21:15,600 --> 00:21:19,600
these

00:21:16,320 --> 00:21:21,120
um under initially a single tensorflow

00:21:19,600 --> 00:21:22,799
and pie torch release

00:21:21,120 --> 00:21:24,799
i think that's an important aspect of

00:21:22,799 --> 00:21:26,960
this that way we can focus in on

00:21:24,799 --> 00:21:28,400
the functions and the capabilities of

00:21:26,960 --> 00:21:29,679
those functions and making sure that

00:21:28,400 --> 00:21:31,520
we're doing things

00:21:29,679 --> 00:21:34,080
cleanly and that we're we're getting all

00:21:31,520 --> 00:21:36,240
the optimizations that we're looking for

00:21:34,080 --> 00:21:37,360
um in the end we're going to be

00:21:36,240 --> 00:21:39,360
including as

00:21:37,360 --> 00:21:40,799
jason said pipelines and all kinds of

00:21:39,360 --> 00:21:43,120
other things

00:21:40,799 --> 00:21:44,960
but we're also going to start looking

00:21:43,120 --> 00:21:45,760
initially at a single version of cuda i

00:21:44,960 --> 00:21:47,679
think that

00:21:45,760 --> 00:21:49,360
the community involvement will help us

00:21:47,679 --> 00:21:52,720
broaden and create

00:21:49,360 --> 00:21:54,480
a vast different other areas around that

00:21:52,720 --> 00:21:56,720
maybe more versions of cuda

00:21:54,480 --> 00:21:58,480
but the oregon state university

00:21:56,720 --> 00:21:59,520
capabilities we'll first look at one

00:21:58,480 --> 00:22:00,799
version of cuda

00:21:59,520 --> 00:22:03,200
and we're going to try and focus in on

00:22:00,799 --> 00:22:05,280
that as those stable releases of those

00:22:03,200 --> 00:22:06,480
other technologies cafe tensorflow pi

00:22:05,280 --> 00:22:07,520
torch come out

00:22:06,480 --> 00:22:09,760
can you go ahead and change the slide

00:22:07,520 --> 00:22:12,080
for me jason

00:22:09,760 --> 00:22:13,760
so we are going to make an official

00:22:12,080 --> 00:22:15,440
statement that jason helped me create

00:22:13,760 --> 00:22:17,520
which is that we are announcing the

00:22:15,440 --> 00:22:18,720
intent to build and offer community

00:22:17,520 --> 00:22:20,720
binaries

00:22:18,720 --> 00:22:22,799
related to each one of those tagged

00:22:20,720 --> 00:22:24,840
releases of opence

00:22:22,799 --> 00:22:26,000
and that's in an effort to grow

00:22:24,840 --> 00:22:27,679
participation

00:22:26,000 --> 00:22:28,960
and we really are looking for groups to

00:22:27,679 --> 00:22:30,240
get involved with us and we're going to

00:22:28,960 --> 00:22:31,360
create a pathway for them to get

00:22:30,240 --> 00:22:33,120
involved with us

00:22:31,360 --> 00:22:34,559
uh it's important for us to make sure

00:22:33,120 --> 00:22:37,120
that those binaries

00:22:34,559 --> 00:22:38,640
are in that con the space and our

00:22:37,120 --> 00:22:41,039
maintain that

00:22:38,640 --> 00:22:42,240
multi-architecture or heterogeneous

00:22:41,039 --> 00:22:45,600
architecture set

00:22:42,240 --> 00:22:46,880
which is x86 and right now power pcle

00:22:45,600 --> 00:22:48,400
which is really what

00:22:46,880 --> 00:22:51,919
we see a lot of the high performance

00:22:48,400 --> 00:22:51,919
computing being focused in around

00:22:52,000 --> 00:22:55,360
we hope that people are going to be

00:22:53,360 --> 00:22:57,440
helping us contribute

00:22:55,360 --> 00:23:00,000
we also hope that groups like ibm will

00:22:57,440 --> 00:23:02,159
be able to take the midstream and create

00:23:00,000 --> 00:23:04,320
a downstream solution still for their

00:23:02,159 --> 00:23:05,840
needs and other groups potentially be

00:23:04,320 --> 00:23:08,480
able to do that as well maybe

00:23:05,840 --> 00:23:11,280
cloud services being able to put this

00:23:08,480 --> 00:23:12,799
into this context allows us to move

00:23:11,280 --> 00:23:14,000
at our own pace and i think that's what

00:23:12,799 --> 00:23:14,880
i was trying to say at the beginning was

00:23:14,000 --> 00:23:17,440
that

00:23:14,880 --> 00:23:19,280
ibm was listening to us and that's what

00:23:17,440 --> 00:23:20,159
you saw over the years were the changes

00:23:19,280 --> 00:23:22,320
and this i think

00:23:20,159 --> 00:23:23,440
is our next logical step with this

00:23:22,320 --> 00:23:24,960
technology is to

00:23:23,440 --> 00:23:26,720
kind of bring it to the community and

00:23:24,960 --> 00:23:29,919
let the community take control

00:23:26,720 --> 00:23:31,919
and drive its future pathway what we

00:23:29,919 --> 00:23:34,240
wanted to do at the end here jason was

00:23:31,919 --> 00:23:36,000
go ahead and show some of the examples

00:23:34,240 --> 00:23:38,080
and here's some of the usage examples

00:23:36,000 --> 00:23:39,520
that we have build an individual

00:23:38,080 --> 00:23:42,799
feedstock and this is where we're going

00:23:39,520 --> 00:23:44,720
to have um you know these capabilities

00:23:42,799 --> 00:23:46,080
to basically build out these

00:23:44,720 --> 00:23:47,520
environments very quickly and very

00:23:46,080 --> 00:23:48,720
easily and get the community involved

00:23:47,520 --> 00:23:51,840
and get people

00:23:48,720 --> 00:23:52,799
able to help us get this work done jason

00:23:51,840 --> 00:23:56,960
did you want to help

00:23:52,799 --> 00:23:56,960
uh conclude this for us

00:23:57,200 --> 00:24:02,559
yes um right and that the the kind of

00:24:00,799 --> 00:24:04,400
the interesting

00:24:02,559 --> 00:24:06,559
aspect on this chart is the the

00:24:04,400 --> 00:24:09,120
flexibility here right if you wanted to

00:24:06,559 --> 00:24:10,480
to to just rebuild a piece of the

00:24:09,120 --> 00:24:12,080
environment for example

00:24:10,480 --> 00:24:13,760
uh you can build a visual individual

00:24:12,080 --> 00:24:15,039
feed stocks which is the kind of

00:24:13,760 --> 00:24:17,440
terminology

00:24:15,039 --> 00:24:19,120
um versus building an entire testable

00:24:17,440 --> 00:24:20,080
environment what that is is not only

00:24:19,120 --> 00:24:21,520
tensorflow but like

00:24:20,080 --> 00:24:23,279
its dependencies that are that are

00:24:21,520 --> 00:24:24,720
needed uh you know

00:24:23,279 --> 00:24:27,360
that are you know either pulls in

00:24:24,720 --> 00:24:28,480
through um uh various channels you can

00:24:27,360 --> 00:24:32,000
see here where

00:24:28,480 --> 00:24:32,880
we're sourcing uh the actual wmlce

00:24:32,000 --> 00:24:35,600
channel that that's

00:24:32,880 --> 00:24:36,080
for cuda at the moment um you know but

00:24:35,600 --> 00:24:37,360
that'll

00:24:36,080 --> 00:24:38,480
build up the entire environment and all

00:24:37,360 --> 00:24:39,679
the dependencies you don't even have to

00:24:38,480 --> 00:24:42,400
think of what it is it's already

00:24:39,679 --> 00:24:44,240
pre-integrated preset um and then you

00:24:42,400 --> 00:24:45,440
know build all of opence releases the

00:24:44,240 --> 00:24:46,880
one in the bottom world not only build

00:24:45,440 --> 00:24:48,240
the tensorflow environment but the pi

00:24:46,880 --> 00:24:50,720
torch environment and the extra use

00:24:48,240 --> 00:24:51,120
environment and its dependencies based

00:24:50,720 --> 00:24:53,440
on the

00:24:51,120 --> 00:24:54,960
the dependency trees that were created

00:24:53,440 --> 00:25:00,080
during the

00:24:54,960 --> 00:25:02,159
analysis step so we have one question uh

00:25:00,080 --> 00:25:02,559
the question is when can we expect the

00:25:02,159 --> 00:25:06,400
first

00:25:02,559 --> 00:25:08,559
open ce with cuda 11 support release

00:25:06,400 --> 00:25:09,440
so yeah i think good question so we're

00:25:08,559 --> 00:25:12,320
initially

00:25:09,440 --> 00:25:12,720
still targeting 10.2 especially because

00:25:12,320 --> 00:25:14,640
the

00:25:12,720 --> 00:25:16,640
the scripts that we had internally were

00:25:14,640 --> 00:25:20,640
10.2 we wanted to have

00:25:16,640 --> 00:25:21,039
uh it uh you know an external version of

00:25:20,640 --> 00:25:23,200
that

00:25:21,039 --> 00:25:24,559
that and upstream hasn't moved to cuda

00:25:23,200 --> 00:25:26,960
11 just yet

00:25:24,559 --> 00:25:28,000
um and in a tag release so tensorflow

00:25:26,960 --> 00:25:29,760
just you know i think

00:25:28,000 --> 00:25:31,840
last month they they had a whole bunch

00:25:29,760 --> 00:25:32,880
of commits that were in for kuda 11

00:25:31,840 --> 00:25:35,200
finally

00:25:32,880 --> 00:25:37,200
um so we'll be able to benefit from that

00:25:35,200 --> 00:25:38,640
uh we'll we'll kind of just follow i

00:25:37,200 --> 00:25:42,000
mean this is an open thing we'll

00:25:38,640 --> 00:25:43,440
we'll follow where upstream is uh if the

00:25:42,000 --> 00:25:43,840
support is there and you know we can

00:25:43,440 --> 00:25:45,600
always

00:25:43,840 --> 00:25:47,279
help help help in the upstream this is

00:25:45,600 --> 00:25:47,919
primarily a midstream kind of project

00:25:47,279 --> 00:25:50,320
right

00:25:47,919 --> 00:25:51,919
um so we'll we'll follow where upstream

00:25:50,320 --> 00:25:53,440
is on that and looks like they are there

00:25:51,919 --> 00:25:55,600
for coup 11 so

00:25:53,440 --> 00:25:57,200
um our initial release will be it could

00:25:55,600 --> 00:25:57,760
attend to but probably some time by the

00:25:57,200 --> 00:25:59,679
end of the year

00:25:57,760 --> 00:26:01,120
we'll we'll have wretched it up to kuda

00:25:59,679 --> 00:26:03,360
00:26:01,120 --> 00:26:04,559
support in there as well you know and as

00:26:03,360 --> 00:26:06,799
chris mentioned maybe we'll

00:26:04,559 --> 00:26:08,240
you know at that point add an added

00:26:06,799 --> 00:26:09,919
another switch here where it can kind of

00:26:08,240 --> 00:26:11,360
build for multiple cued environments if

00:26:09,919 --> 00:26:12,240
you still needed to attend that too for

00:26:11,360 --> 00:26:14,720
example

00:26:12,240 --> 00:26:16,159
um you know people people don't always

00:26:14,720 --> 00:26:18,159
move up to the cuda

00:26:16,159 --> 00:26:21,679
latest cuda that better is available so

00:26:18,159 --> 00:26:21,679
it'd be nice to have both right

00:26:22,000 --> 00:26:26,320
hopefully that answers our question um

00:26:24,559 --> 00:26:28,240
if there are any other questions we can

00:26:26,320 --> 00:26:31,120
take some of those for you right now

00:26:28,240 --> 00:26:31,600
um we have just a couple minutes left

00:26:31,120 --> 00:26:34,320
yeah

00:26:31,600 --> 00:26:35,520
and while we wait for some i switched to

00:26:34,320 --> 00:26:38,480
the the last here

00:26:35,520 --> 00:26:39,440
the page here we've got our github link

00:26:38,480 --> 00:26:41,520
um

00:26:39,440 --> 00:26:43,360
head out and take a look give us a star

00:26:41,520 --> 00:26:45,679
uh if you want get you know

00:26:43,360 --> 00:26:47,279
watch where we're going with it we you

00:26:45,679 --> 00:26:48,880
know that we have code out there now

00:26:47,279 --> 00:26:51,039
we're still we don't have the ci

00:26:48,880 --> 00:26:52,640
code the argo code out there just yet

00:26:51,039 --> 00:26:53,520
but we do have all the local scripts you

00:26:52,640 --> 00:26:56,000
should be able to

00:26:53,520 --> 00:26:57,760
to to build up an entire tensorflow

00:26:56,000 --> 00:26:59,120
environment or entire open c environment

00:26:57,760 --> 00:27:02,960
of the box if you'd like

00:26:59,120 --> 00:27:04,559
um we're still you know working out some

00:27:02,960 --> 00:27:06,240
of the kinks with the open version of

00:27:04,559 --> 00:27:08,799
stuff but

00:27:06,240 --> 00:27:09,600
love to have your feedback on it and

00:27:08,799 --> 00:27:11,760
your involvement

00:27:09,600 --> 00:27:13,600
right um you know as we mentioned i

00:27:11,760 --> 00:27:17,679
think it this will this will be as good

00:27:13,600 --> 00:27:17,679
as we can make it as a community

00:27:19,279 --> 00:27:22,880
i don't see any other questions right

00:27:21,360 --> 00:27:26,320
now and

00:27:22,880 --> 00:27:30,159
uh we're just about out of time

00:27:26,320 --> 00:27:30,159
uh we've got another minute or so i

00:27:32,840 --> 00:27:37,200
think

00:27:34,880 --> 00:27:38,799
so anything else you want to finish with

00:27:37,200 --> 00:27:40,480
jason i think that

00:27:38,799 --> 00:27:43,200
we're excited about you helping us

00:27:40,480 --> 00:27:45,279
transition into the space and

00:27:43,200 --> 00:27:46,880
we'll probably be picking up that 10.2

00:27:45,279 --> 00:27:49,760
release to begin with but

00:27:46,880 --> 00:27:50,399
we'll be working with you on that 11. so

00:27:49,760 --> 00:27:52,080
yes

00:27:50,399 --> 00:27:54,159
yeah yeah i think that that that'll be

00:27:52,080 --> 00:27:57,120
an interesting uh step there

00:27:54,159 --> 00:27:59,200
is you know moving this from you know

00:27:57,120 --> 00:28:02,480
primarily ibm or is working on it

00:27:59,200 --> 00:28:05,520
ibm is working in the open to you know

00:28:02,480 --> 00:28:07,919
a community working on it right um

00:28:05,520 --> 00:28:08,559
you know and we'll you know evolve it as

00:28:07,919 --> 00:28:10,000
we go

00:28:08,559 --> 00:28:12,159
um i think those should there's

00:28:10,000 --> 00:28:14,080
interesting direction here on taking the

00:28:12,159 --> 00:28:17,200
the dependency graphs that we've

00:28:14,080 --> 00:28:18,720
uh you know have have built in the early

00:28:17,200 --> 00:28:20,399
code and what else can we do with that

00:28:18,720 --> 00:28:22,320
as far as integration goes

00:28:20,399 --> 00:28:23,840
um you know we've got we've got a lot of

00:28:22,320 --> 00:28:24,960
ideas we want to develop those out in

00:28:23,840 --> 00:28:28,640
the community and

00:28:24,960 --> 00:28:31,760
um you know really make this a valuable

00:28:28,640 --> 00:28:33,200
um one more quick question how

00:28:31,760 --> 00:28:36,320
additional packages

00:28:33,200 --> 00:28:37,600
can be included in opence how the

00:28:36,320 --> 00:28:41,039
process will be done

00:28:37,600 --> 00:28:44,799
for example opence 4.x

00:28:41,039 --> 00:28:47,360
um that was a good example yeah so we uh

00:28:44,799 --> 00:28:49,520
if if you wanted to add a new feedstock

00:28:47,360 --> 00:28:52,240
um well for for one we have

00:28:49,520 --> 00:28:53,600
uh we're working on the cla out there

00:28:52,240 --> 00:28:55,760
now we've got i get a lower

00:28:53,600 --> 00:28:56,880
lawyer stamp on that and some approval

00:28:55,760 --> 00:28:58,159
so right now

00:28:56,880 --> 00:29:00,080
we'll just have to you have to open an

00:28:58,159 --> 00:29:01,039
issue and want to do it but soon we'll

00:29:00,080 --> 00:29:03,200
have that worked out and

00:29:01,039 --> 00:29:04,960
we'll have community involvement on that

00:29:03,200 --> 00:29:08,320
um and you'll be able to just

00:29:04,960 --> 00:29:09,679
add a pr to it um and

00:29:08,320 --> 00:29:12,000
you know eventually we'll have a little

00:29:09,679 --> 00:29:15,200
bit more checks and and linters

00:29:12,000 --> 00:29:16,480
and and um that kind of thing that that

00:29:15,200 --> 00:29:19,039
should be able to

00:29:16,480 --> 00:29:20,399
um uh you know check it out and make

00:29:19,039 --> 00:29:21,760
sure it's a good feed stock

00:29:20,399 --> 00:29:23,679
we're not we're not aiming this to be

00:29:21,760 --> 00:29:25,840
another kind of forge though um

00:29:23,679 --> 00:29:27,760
keep in mind we you know it will have to

00:29:25,840 --> 00:29:28,480
be you know an open seas a good example

00:29:27,760 --> 00:29:30,159
to have an

00:29:28,480 --> 00:29:31,919
environment it's a lot of a lot of

00:29:30,159 --> 00:29:32,480
integration points and a lot of

00:29:31,919 --> 00:29:35,840
integration

00:29:32,480 --> 00:29:37,279
pain come with open cvs right so um so

00:29:35,840 --> 00:29:38,000
that that probably a good one to have in

00:29:37,279 --> 00:29:40,000
there but

00:29:38,000 --> 00:29:41,520
um but we won't just have anything in

00:29:40,000 --> 00:29:42,960
there right so that will kind of come

00:29:41,520 --> 00:29:45,600
down to a certain approval

00:29:42,960 --> 00:29:46,559
um from the team or from the community

00:29:45,600 --> 00:29:49,919
in general

00:29:46,559 --> 00:29:51,440
uh about what what we want in in opence

00:29:49,919 --> 00:29:53,520
you know what would people need in their

00:29:51,440 --> 00:29:55,360
cognitive environments right

00:29:53,520 --> 00:29:57,039
there can always be downstream scripts

00:29:55,360 --> 00:29:58,640
to help people exactly and you can

00:29:57,039 --> 00:29:59,520
always fork it and mat it yourself right

00:29:58,640 --> 00:30:01,039
if we if we

00:29:59,520 --> 00:30:02,559
determine that you know we don't want to

00:30:01,039 --> 00:30:04,480
take that one on

00:30:02,559 --> 00:30:06,240
as a group i think we're about out of

00:30:04,480 --> 00:30:09,840
time um

00:30:06,240 --> 00:30:09,840
so i don't see any more questions

00:30:11,440 --> 00:30:16,960
okay all right thanks guys thanks chris

00:30:15,120 --> 00:30:18,960
uh thanks everybody for joining uh this

00:30:16,960 --> 00:30:20,240
was uh this was great but we're excited

00:30:18,960 --> 00:30:23,840
to talk about this today and hopefully

00:30:20,240 --> 00:30:23,840

YouTube URL: https://www.youtube.com/watch?v=Skc4MrvfyMA


