Title: Pod scaling ad infinitum!! - Krishna Harsha Voora& Mithun HR, IBM India Pvt. Ltd.
Publication date: 2020-09-21
Playlist: OpenPOWER Summit NA 2020
Description: 
	Pod scaling ad infinitum!! - Krishna Harsha Voora& Mithun HR, IBM India Pvt. Ltd.

Speakers: Krishna Harsha Voora, Mithun HR

In this talk, we will look at the importance of Kubernetes Quality of Service, itâ€™s journey & evolution. QoS is a Kubernetes concept that is leveraged by the Kubernetes scheduler to make scheduling decisions about pods onto nodes. How will this benefit you? We were compelled after seeing significant improvement by merely switching between different QoS Classes & eventually exploiting POWER Architecture thus application performance boosted when compared to other architectures, so what changes now? A "DevOps" scenario with a workload similar to a MEAN stack (Mongo, Express, Angular, and Node) / PostgreSQL was selected to purposefully demonstrate the POWER Architecture value proposition when compared with other architectures.
Captions: 
	00:00:00,240 --> 00:00:04,480
hi all uh greetings uh thank you for uh

00:00:03,600 --> 00:00:07,839
joining this

00:00:04,480 --> 00:00:10,559
session where uh we intend to talk about

00:00:07,839 --> 00:00:12,799
part scaling uh

00:00:10,559 --> 00:00:14,920
abilities on power systems and then

00:00:12,799 --> 00:00:17,840
hence we termed it as spot scaling ad

00:00:14,920 --> 00:00:19,920
infinitum

00:00:17,840 --> 00:00:21,920
i'll briefly introduce myself my name is

00:00:19,920 --> 00:00:22,480
krishna shabura i work as a software

00:00:21,920 --> 00:00:25,039
developer

00:00:22,480 --> 00:00:27,439
in cognitive systems of ibm india

00:00:25,039 --> 00:00:31,039
software development labs

00:00:27,439 --> 00:00:32,640
in this particular role i help clients

00:00:31,039 --> 00:00:35,520
specifically independent software

00:00:32,640 --> 00:00:38,079
vendors and business partners

00:00:35,520 --> 00:00:40,559
in their journey to cloud and in their

00:00:38,079 --> 00:00:44,559
digital transformation

00:00:40,559 --> 00:00:46,719
i play various roles wherein i help with

00:00:44,559 --> 00:00:49,200
porting of the required software stack

00:00:46,719 --> 00:00:52,000
onto ibm power systems

00:00:49,200 --> 00:00:54,399
and then help with their validation and

00:00:52,000 --> 00:00:58,000
benchmarking exercises

00:00:54,399 --> 00:01:00,640
i also focus on performance

00:00:58,000 --> 00:01:04,640
engineering aspects of isv applications

00:01:00,640 --> 00:01:04,640
on red hat open shift container platform

00:01:04,799 --> 00:01:09,280
with that said i would like mithin

00:01:07,439 --> 00:01:12,640
michali to introduce himself

00:01:09,280 --> 00:01:15,759
nathan over to you thanks richard

00:01:12,640 --> 00:01:19,439
um i work with dasha in the same team

00:01:15,759 --> 00:01:22,799
so we so i work as a software developer

00:01:19,439 --> 00:01:23,840
and uh it is kind of a same role i also

00:01:22,799 --> 00:01:27,200
work as a

00:01:23,840 --> 00:01:29,119
on different roles i also work as a

00:01:27,200 --> 00:01:31,280
technical consultant

00:01:29,119 --> 00:01:33,680
enabling isps port their packages onto

00:01:31,280 --> 00:01:36,479
ibm power architecture

00:01:33,680 --> 00:01:37,680
and also some of the performance work

00:01:36,479 --> 00:01:40,560
related

00:01:37,680 --> 00:01:42,240
to power platform and also some of the

00:01:40,560 --> 00:01:45,119
modernization stories

00:01:42,240 --> 00:01:48,079
around openshift container platform and

00:01:45,119 --> 00:01:48,079
in their cloud journey

00:01:48,240 --> 00:01:52,399
so with that i'll hand it over back to

00:01:52,840 --> 00:01:55,840
hershey

00:01:56,079 --> 00:02:00,799
let's take a glimpse at today's agenda

00:01:58,560 --> 00:02:02,640
we'll briefly touch base on ibm standard

00:02:00,799 --> 00:02:03,200
heads partnership this has nothing to do

00:02:02,640 --> 00:02:05,280
with the

00:02:03,200 --> 00:02:07,759
acquisition but how they have co-existed

00:02:05,280 --> 00:02:10,000
in the open source ecosystem

00:02:07,759 --> 00:02:11,200
spend some time on overview of red hat

00:02:10,000 --> 00:02:13,840
open shift

00:02:11,200 --> 00:02:14,959
uh container platform and what are the

00:02:13,840 --> 00:02:18,080
uh

00:02:14,959 --> 00:02:21,120
best use cases that suits for

00:02:18,080 --> 00:02:24,720
uh openshift container platform

00:02:21,120 --> 00:02:26,400
i'll also give an introduction towards

00:02:24,720 --> 00:02:28,400
the power line

00:02:26,400 --> 00:02:30,959
model of service that can be leveraged

00:02:28,400 --> 00:02:32,879
for different workloads

00:02:30,959 --> 00:02:34,840
will spend considerable amount of time

00:02:32,879 --> 00:02:37,840
on objective of the

00:02:34,840 --> 00:02:39,519
particular proof point study and how the

00:02:37,840 --> 00:02:42,000
workload is structured

00:02:39,519 --> 00:02:42,800
and if time permits again if time

00:02:42,000 --> 00:02:45,519
permits

00:02:42,800 --> 00:02:46,879
will spend some time on a canned demo

00:02:45,519 --> 00:02:51,840
which is

00:02:46,879 --> 00:02:51,840
available in youtube

00:02:52,959 --> 00:02:59,120
ibm entertained has coexisted in

00:02:56,640 --> 00:03:00,400
open source ecosystem for more than 20

00:02:59,120 --> 00:03:03,040
years

00:03:00,400 --> 00:03:04,400
and they have done a marvelous job and

00:03:03,040 --> 00:03:06,239
they have come up with

00:03:04,400 --> 00:03:08,879
beautiful product portfolios which

00:03:06,239 --> 00:03:10,879
complement with each other as well

00:03:08,879 --> 00:03:12,239
speaking specifically from ibm power

00:03:10,879 --> 00:03:14,239
systems

00:03:12,239 --> 00:03:16,640
red hat enterprise linux has been

00:03:14,239 --> 00:03:19,680
available on ibm power systems for

00:03:16,640 --> 00:03:20,640
quite a long time that's it we also have

00:03:19,680 --> 00:03:22,800
had

00:03:20,640 --> 00:03:24,959
red hats open stack available on ibm

00:03:22,800 --> 00:03:28,480
power systems we also have now

00:03:24,959 --> 00:03:33,840
uh red hats openshift container platform

00:03:28,480 --> 00:03:33,840
available on ibm power systems

00:03:34,239 --> 00:03:40,560
i'll spend some time on

00:03:37,280 --> 00:03:43,200
the cloud workloads if you take into

00:03:40,560 --> 00:03:47,120
consideration

00:03:43,200 --> 00:03:49,760
the operating systems in the cloud world

00:03:47,120 --> 00:03:50,879
more than are near about 50 percentage

00:03:49,760 --> 00:03:52,959
of them are linux

00:03:50,879 --> 00:03:53,920
operating system and attack is

00:03:52,959 --> 00:03:56,640
indisputably

00:03:53,920 --> 00:04:00,000
the number one service provider and the

00:03:56,640 --> 00:04:02,080
next operating system distributor

00:04:00,000 --> 00:04:03,200
that's it there is always an imminent

00:04:02,080 --> 00:04:06,000
threat

00:04:03,200 --> 00:04:07,040
to an enterprise workload that runs on a

00:04:06,000 --> 00:04:10,560
multi-cloud

00:04:07,040 --> 00:04:13,439
kind of scenario wherein

00:04:10,560 --> 00:04:14,640
resume your application makes use of a

00:04:13,439 --> 00:04:17,440
module

00:04:14,640 --> 00:04:18,320
and then the vendor pulls backs its

00:04:17,440 --> 00:04:20,320
support

00:04:18,320 --> 00:04:22,320
how do we go about from there this is a

00:04:20,320 --> 00:04:23,440
really typical scenario it may or may

00:04:22,320 --> 00:04:26,639
not happen

00:04:23,440 --> 00:04:28,560
but in order to cater to

00:04:26,639 --> 00:04:30,880
this solution and many other solution

00:04:28,560 --> 00:04:33,360
ibm and red hat have

00:04:30,880 --> 00:04:34,240
developed end-to-end solutions that

00:04:33,360 --> 00:04:37,840
addresses

00:04:34,240 --> 00:04:41,040
are helps unify public and private cloud

00:04:37,840 --> 00:04:44,479
investment and also mitigate vendor lock

00:04:41,040 --> 00:04:44,479
in specific kind of an issues

00:04:46,800 --> 00:04:51,759
there are limitless applications with

00:04:49,759 --> 00:04:53,440
red hat openshift

00:04:51,759 --> 00:04:55,520
if only one understands its true

00:04:53,440 --> 00:04:57,840
capabilities and features that it brings

00:04:55,520 --> 00:05:00,320
onto the table

00:04:57,840 --> 00:05:02,000
boiling down to three major pillars

00:05:00,320 --> 00:05:05,520
which we think

00:05:02,000 --> 00:05:05,520
plays crucial role in this

00:05:05,600 --> 00:05:11,039
era are our application and

00:05:08,560 --> 00:05:13,759
infrastructure modernization story

00:05:11,039 --> 00:05:14,880
as an analogy think of an existing

00:05:13,759 --> 00:05:17,520
application

00:05:14,880 --> 00:05:18,240
which makes use of legacy software and

00:05:17,520 --> 00:05:22,880
you want to

00:05:18,240 --> 00:05:25,840
cloudify or jump onto the train of

00:05:22,880 --> 00:05:25,840
modernization story

00:05:25,919 --> 00:05:32,960
redhats openshift provides you

00:05:29,520 --> 00:05:34,160
bundle of information or our application

00:05:32,960 --> 00:05:37,280
capabilities

00:05:34,160 --> 00:05:39,520
that when leveraged can help modernize

00:05:37,280 --> 00:05:42,000
your existing application

00:05:39,520 --> 00:05:44,560
and men and months will leverage their

00:05:42,000 --> 00:05:47,840
existing utilities or tools

00:05:44,560 --> 00:05:48,560
we can convert our applications existing

00:05:47,840 --> 00:05:51,039
legacy

00:05:48,560 --> 00:05:52,560
applications into microservice based

00:05:51,039 --> 00:05:54,560
applications

00:05:52,560 --> 00:05:55,600
when we switch to microservice based

00:05:54,560 --> 00:05:57,520
application your

00:05:55,600 --> 00:05:59,280
application availability or your

00:05:57,520 --> 00:06:02,560
application down time

00:05:59,280 --> 00:06:04,960
goes to near about zero you know

00:06:02,560 --> 00:06:07,039
because it provides us the capability to

00:06:04,960 --> 00:06:10,960
do parallel upgrades

00:06:07,039 --> 00:06:13,120
and panel rollouts speaking about

00:06:10,960 --> 00:06:15,039
building data centric application cloud

00:06:13,120 --> 00:06:18,960
applications

00:06:15,039 --> 00:06:20,880
with data bursting at an exponential

00:06:18,960 --> 00:06:23,520
rate

00:06:20,880 --> 00:06:24,240
the cloud internal organization have to

00:06:23,520 --> 00:06:26,479
think

00:06:24,240 --> 00:06:27,520
about the way they handle this

00:06:26,479 --> 00:06:30,479
information or

00:06:27,520 --> 00:06:32,160
how they handle the data that is at

00:06:30,479 --> 00:06:36,240
their disposal

00:06:32,160 --> 00:06:39,680
new future clouds will also not only

00:06:36,240 --> 00:06:43,840
handle the data but also will capture

00:06:39,680 --> 00:06:43,840
process and analyze say logs

00:06:43,919 --> 00:06:49,199
keeping this in in mind we should have

00:06:46,800 --> 00:06:49,680
an approach in such a way that we should

00:06:49,199 --> 00:06:52,800
bring

00:06:49,680 --> 00:06:54,319
the compute capabilities to the data as

00:06:52,800 --> 00:06:56,080
as opposed to the traditional approach

00:06:54,319 --> 00:06:59,360
of bringing

00:06:56,080 --> 00:06:59,840
data to the compute capabilities so this

00:06:59,360 --> 00:07:02,880
is

00:06:59,840 --> 00:07:05,520
typically possible by a hybrid

00:07:02,880 --> 00:07:09,280
multi-cloud kind of a structure which

00:07:05,520 --> 00:07:09,280
redhat openshift already provides us

00:07:09,360 --> 00:07:13,280
there's a lot of traction around

00:07:11,520 --> 00:07:16,479
artificial intelligence specifically

00:07:13,280 --> 00:07:18,960
machine learning and deep learning

00:07:16,479 --> 00:07:20,800
redhead openshift provides us a plugin

00:07:18,960 --> 00:07:23,440
which allows

00:07:20,800 --> 00:07:24,160
the model to run directly on gpu boxes

00:07:23,440 --> 00:07:27,919
and on

00:07:24,160 --> 00:07:31,039
your gpu gpus directly

00:07:27,919 --> 00:07:34,560
and then we have a tailor-made server

00:07:31,039 --> 00:07:35,440
specifically designed to run your ai

00:07:34,560 --> 00:07:38,960
models

00:07:35,440 --> 00:07:39,840
much faster that is ac922 i'll spend

00:07:38,960 --> 00:07:45,840
some time

00:07:39,840 --> 00:07:45,840
in a next slide

00:07:46,000 --> 00:07:53,039
this is the power 9

00:07:49,199 --> 00:07:54,560
a couple of power 9 architecture based

00:07:53,039 --> 00:07:56,560
server models

00:07:54,560 --> 00:07:58,000
if we categorize the entire slide into

00:07:56,560 --> 00:07:59,520
two vertical halves

00:07:58,000 --> 00:08:02,720
on the left hand side of the screen we

00:07:59,520 --> 00:08:06,080
can see lc 922 box

00:08:02,720 --> 00:08:07,840
its architecture is and and

00:08:06,080 --> 00:08:09,599
the peripheral components are aligned in

00:08:07,840 --> 00:08:12,479
such a way that

00:08:09,599 --> 00:08:13,680
it helps process big data workload kind

00:08:12,479 --> 00:08:16,479
of

00:08:13,680 --> 00:08:17,039
uh workloads that's pretty good and then

00:08:16,479 --> 00:08:20,479
we have

00:08:17,039 --> 00:08:23,759
ac 922 yeah

00:08:20,479 --> 00:08:26,080
ac922 is a lego building block of

00:08:23,759 --> 00:08:26,960
one of the supercomputers available in

00:08:26,080 --> 00:08:30,639
the world

00:08:26,960 --> 00:08:33,680
that is summit and coil

00:08:30,639 --> 00:08:36,320
ac 922's planar surface is aligned in

00:08:33,680 --> 00:08:38,479
such a way that it allows you to pump

00:08:36,320 --> 00:08:41,519
enormous amount of data from your cpus

00:08:38,479 --> 00:08:43,519
to gpus pretty instantly

00:08:41,519 --> 00:08:44,720
which allows us to spend considerable

00:08:43,519 --> 00:08:48,240
amount of time

00:08:44,720 --> 00:08:48,240
in trading and testing your models

00:08:49,519 --> 00:08:53,440
moving on to the mid section of this

00:08:51,920 --> 00:08:56,640
particular slide

00:08:53,440 --> 00:09:00,720
we have taylormates of servers

00:08:56,640 --> 00:09:03,920
particularly for sap hana h922

00:09:00,720 --> 00:09:05,519
and h924 because

00:09:03,920 --> 00:09:07,760
they have a huge memory footprint

00:09:05,519 --> 00:09:09,200
requirement and this two particular

00:09:07,760 --> 00:09:13,120
server models

00:09:09,200 --> 00:09:17,920
caters for the particular need similarly

00:09:13,120 --> 00:09:20,560
we have uh s922 s914 and s924

00:09:17,920 --> 00:09:23,040
which are scalable systems in in with

00:09:20,560 --> 00:09:26,080
power bm as a hypervisor

00:09:23,040 --> 00:09:27,120
which primarily addresses osdb kind of

00:09:26,080 --> 00:09:30,000
uh

00:09:27,120 --> 00:09:30,800
uh workloads that is posterior sql

00:09:30,000 --> 00:09:34,320
mongodb

00:09:30,800 --> 00:09:34,720
and others moving on to the last segment

00:09:34,320 --> 00:09:37,920
of

00:09:34,720 --> 00:09:39,360
this particular slide we have power

00:09:37,920 --> 00:09:43,360
enterprise systems

00:09:39,360 --> 00:09:46,399
where which is particularly targeted for

00:09:43,360 --> 00:09:50,320
enterprise kind of softwares for example

00:09:46,399 --> 00:09:52,720
db2 and our oracle and

00:09:50,320 --> 00:09:55,279
the beautiful thing is you can install

00:09:52,720 --> 00:09:57,440
an ad open shift across all of this

00:09:55,279 --> 00:10:05,360
server models that are available in

00:09:57,440 --> 00:10:07,360
front of you right now

00:10:05,360 --> 00:10:10,079
for this particular proof point study we

00:10:07,360 --> 00:10:12,240
have picked up a data intensive workload

00:10:10,079 --> 00:10:14,000
which was very intentional because we

00:10:12,240 --> 00:10:16,640
wanted to stress

00:10:14,000 --> 00:10:18,880
the cpus or the physical cores available

00:10:16,640 --> 00:10:21,360
both on power system as well as

00:10:18,880 --> 00:10:22,240
skylake system which is our competitive

00:10:21,360 --> 00:10:25,040
architecture

00:10:22,240 --> 00:10:25,040
pin in question

00:10:26,720 --> 00:10:33,760
in order to match the data intensive

00:10:31,040 --> 00:10:35,440
nature of the workload we have defined

00:10:33,760 --> 00:10:39,760
the objective of the workload

00:10:35,440 --> 00:10:41,920
as following right the main

00:10:39,760 --> 00:10:43,200
aspect of this particular objective was

00:10:41,920 --> 00:10:47,360
to derive a

00:10:43,200 --> 00:10:49,680
price performance at a perk or advantage

00:10:47,360 --> 00:10:51,920
level

00:10:49,680 --> 00:10:51,920
sorry

00:10:52,720 --> 00:10:55,920
so in order to do that we have

00:10:54,000 --> 00:10:57,839
identified a workload which which was

00:10:55,920 --> 00:11:01,279
coming from geospatial workload from

00:10:57,839 --> 00:11:05,839
mongodb's website

00:11:01,279 --> 00:11:07,680
which was loosely based on main stack

00:11:05,839 --> 00:11:09,360
for audience who do not know what means

00:11:07,680 --> 00:11:13,680
tackies

00:11:09,360 --> 00:11:17,360
we are it is this is based on mongodb

00:11:13,680 --> 00:11:19,680
express js angularjs and node.js

00:11:17,360 --> 00:11:20,399
and then uh the nature of the workload

00:11:19,680 --> 00:11:23,600
was such

00:11:20,399 --> 00:11:26,320
that we could tamper it accordingly

00:11:23,600 --> 00:11:27,920
to make its cpu intensive workload we

00:11:26,320 --> 00:11:28,959
have also defined service level

00:11:27,920 --> 00:11:32,000
agreements

00:11:28,959 --> 00:11:35,040
in order to define the metrics

00:11:32,000 --> 00:11:38,079
which were acting as some rules in order

00:11:35,040 --> 00:11:41,200
to evaluate a workload

00:11:38,079 --> 00:11:43,920
you know there were two in particular

00:11:41,200 --> 00:11:46,640
interest one of them was if you trigger

00:11:43,920 --> 00:11:48,399
an api res if you trigger an api call

00:11:46,640 --> 00:11:50,560
the response time should always be less

00:11:48,399 --> 00:11:53,519
than 999 milliseconds

00:11:50,560 --> 00:11:54,800
less than or equal to 999 milliseconds

00:11:53,519 --> 00:11:58,160
if we

00:11:54,800 --> 00:12:00,959
do not get any response if any of the

00:11:58,160 --> 00:12:03,519
api responses takes more than

00:12:00,959 --> 00:12:05,760
one second or above we categorize it as

00:12:03,519 --> 00:12:11,360
our news

00:12:05,760 --> 00:12:14,720
what if if we have

00:12:11,360 --> 00:12:16,079
more than many more such engineers api

00:12:14,720 --> 00:12:18,240
responses

00:12:16,079 --> 00:12:20,720
right what we have defined was we could

00:12:18,240 --> 00:12:24,639
tolerate near about one percentage

00:12:20,720 --> 00:12:26,399
of total apa calls made to be added news

00:12:24,639 --> 00:12:28,160
anything more than one percentage of

00:12:26,399 --> 00:12:30,320
total apa calls which are

00:12:28,160 --> 00:12:31,440
erroneous with categories of particular

00:12:30,320 --> 00:12:35,279
workload

00:12:31,440 --> 00:12:37,040
are run as unfit

00:12:35,279 --> 00:12:38,880
for example if you have 100 such

00:12:37,040 --> 00:12:42,320
transactions and if we

00:12:38,880 --> 00:12:44,959
notice even one of the api calls are

00:12:42,320 --> 00:12:49,360
taking more than 999 milliseconds

00:12:44,959 --> 00:12:52,480
we just disqualify that particular run

00:12:49,360 --> 00:12:55,839
and then what we were also trying to do

00:12:52,480 --> 00:12:58,639
at simultaneously were trying to

00:12:55,839 --> 00:12:59,279
pack as many containers as possible per

00:12:58,639 --> 00:13:02,320
host

00:12:59,279 --> 00:13:02,880
are on a per container basis you can

00:13:02,320 --> 00:13:05,680
imagine

00:13:02,880 --> 00:13:06,320
container as an isolated environment

00:13:05,680 --> 00:13:09,839
where

00:13:06,320 --> 00:13:11,760
your developer is working without any

00:13:09,839 --> 00:13:13,519
performance degradations

00:13:11,760 --> 00:13:15,600
so how many search developers can you

00:13:13,519 --> 00:13:18,240
accommodate

00:13:15,600 --> 00:13:18,880
through independent containers what's

00:13:18,240 --> 00:13:21,120
the

00:13:18,880 --> 00:13:22,160
concept behind uh packing the many

00:13:21,120 --> 00:13:26,079
containers as

00:13:22,160 --> 00:13:28,000
as on-house per as as possible right

00:13:26,079 --> 00:13:30,079
based on this particular slas and the

00:13:28,000 --> 00:13:32,320
metric systems that we have derived

00:13:30,079 --> 00:13:34,000
we worked our way through the price and

00:13:32,320 --> 00:13:38,720
the performance ratio

00:13:34,000 --> 00:13:38,720
are added at a per core basis

00:13:39,760 --> 00:13:46,240
this is really a busy chart however

00:13:43,040 --> 00:13:47,360
and i'll try to keep it as minimalistic

00:13:46,240 --> 00:13:50,079
as possible

00:13:47,360 --> 00:13:52,480
that said the mongodb geospatial dataset

00:13:50,079 --> 00:13:55,440
that we have picked up from

00:13:52,480 --> 00:13:56,079
mongodb website contained a lot of

00:13:55,440 --> 00:13:59,360
collections

00:13:56,079 --> 00:14:00,399
within it we were primarily interested

00:13:59,360 --> 00:14:03,040
in two collections

00:14:00,399 --> 00:14:04,480
which is neighborhoods and restaurants

00:14:03,040 --> 00:14:06,000
primarily

00:14:04,480 --> 00:14:08,720
in order to access this particular

00:14:06,000 --> 00:14:12,079
collection data we have

00:14:08,720 --> 00:14:14,839
built in specifically api calls

00:14:12,079 --> 00:14:16,160
which were tailor-made to hit this

00:14:14,839 --> 00:14:19,279
particular

00:14:16,160 --> 00:14:21,120
mongodb datasets you know

00:14:19,279 --> 00:14:23,040
you can imagine that you have picked up

00:14:21,120 --> 00:14:25,360
a fold and you are trying to

00:14:23,040 --> 00:14:26,639
query which is a nearest restaurant in

00:14:25,360 --> 00:14:30,000
your neighborhood

00:14:26,639 --> 00:14:33,120
are which is the nearest neighborhoods

00:14:30,000 --> 00:14:35,600
next to your home so what we have

00:14:33,120 --> 00:14:38,720
defined was

00:14:35,600 --> 00:14:41,519
if if a user picks up his phone

00:14:38,720 --> 00:14:42,320
and performs a transaction it translates

00:14:41,519 --> 00:14:45,839
to

00:14:42,320 --> 00:14:48,880
five internal apa calls which which

00:14:45,839 --> 00:14:50,079
basically are get my nearest ten

00:14:48,880 --> 00:14:52,959
neighborhoods

00:14:50,079 --> 00:14:53,519
are get my immediate neighborhood and

00:14:52,959 --> 00:14:55,920
then

00:14:53,519 --> 00:14:57,120
get the restaurants based in a donut

00:14:55,920 --> 00:15:00,560
kind of a ship

00:14:57,120 --> 00:15:01,680
you know which was feeding via latitude

00:15:00,560 --> 00:15:04,880
and longitude

00:15:01,680 --> 00:15:07,440
geospatial ranges and then restaurants

00:15:04,880 --> 00:15:10,800
in one particular range

00:15:07,440 --> 00:15:13,600
in order to simulate the virtual users

00:15:10,800 --> 00:15:15,600
what we have done is we have leveraged

00:15:13,600 --> 00:15:17,519
the emitter automation tool

00:15:15,600 --> 00:15:19,920
that triggered or submitted the virtual

00:15:17,519 --> 00:15:21,519
users for example if

00:15:19,920 --> 00:15:23,519
four users triggered 10 such

00:15:21,519 --> 00:15:26,320
transactions or 10 sec

00:15:23,519 --> 00:15:28,560
10 such requests it translates to 200

00:15:26,320 --> 00:15:32,000
transactions

00:15:28,560 --> 00:15:33,839
we categorized short and long runs

00:15:32,000 --> 00:15:36,399
short terms for near about less than 10

00:15:33,839 --> 00:15:37,759
minutes and long runs for near about 30

00:15:36,399 --> 00:15:39,440
minutes

00:15:37,759 --> 00:15:42,480
long runs were crucially important to

00:15:39,440 --> 00:15:45,839
understand which component

00:15:42,480 --> 00:15:48,880
of the system was

00:15:45,839 --> 00:15:50,320
uh acting up good or getting stressed or

00:15:48,880 --> 00:15:51,839
was it getting stressed

00:15:50,320 --> 00:15:53,120
so during this long runs we were

00:15:51,839 --> 00:15:54,079
collecting the performance data to

00:15:53,120 --> 00:15:56,959
analyze and

00:15:54,079 --> 00:15:56,959
tune accordingly

00:16:01,360 --> 00:16:04,880
the software stack in question when we

00:16:03,440 --> 00:16:07,120
have performed

00:16:04,880 --> 00:16:09,519
this particular proof point study and

00:16:07,120 --> 00:16:11,759
point in time

00:16:09,519 --> 00:16:13,360
it is as follows we have made use of

00:16:11,759 --> 00:16:15,360
version 3.11

00:16:13,360 --> 00:16:16,720
of openshift container platform across

00:16:15,360 --> 00:16:20,160
both power 9

00:16:16,720 --> 00:16:21,040
and skylake system the choice of

00:16:20,160 --> 00:16:24,720
hypervisor

00:16:21,040 --> 00:16:27,120
on power9 was power vm and then

00:16:24,720 --> 00:16:29,920
the industry standard hypervisor kvm on

00:16:27,120 --> 00:16:29,920
skylake system

00:16:32,000 --> 00:16:38,320
we are trying to recreate

00:16:35,120 --> 00:16:40,880
the same workload on 4.

00:16:38,320 --> 00:16:44,240
5 version of openshift on power as well

00:16:40,880 --> 00:16:46,959
as x86 systems as well

00:16:44,240 --> 00:16:49,440
the operating system that compatible was

00:16:46,959 --> 00:16:51,839
rhl 7.6 across both power 9 and

00:16:49,440 --> 00:16:52,800
x86 and the kernel with which it was

00:16:51,839 --> 00:16:56,880
coming was

00:16:52,800 --> 00:17:01,360
3.10 the container which was bundling

00:16:56,880 --> 00:17:04,480
both node.js and mongodb binaries was

00:17:01,360 --> 00:17:07,120
on top of centos

00:17:04,480 --> 00:17:08,160
as and then the kernel was almost the

00:17:07,120 --> 00:17:11,360
same because

00:17:08,160 --> 00:17:12,400
it basically shares the host kernel

00:17:11,360 --> 00:17:15,600
libraries or

00:17:12,400 --> 00:17:17,600
host kernel itself

00:17:15,600 --> 00:17:18,959
and the mongodb enterprise version was

00:17:17,600 --> 00:17:21,600
4.0.2

00:17:18,959 --> 00:17:24,400
it was consistent across power 9 as well

00:17:21,600 --> 00:17:24,400
as 686

00:17:24,799 --> 00:17:30,079
at that particular point in time node.js

00:17:26,559 --> 00:17:30,079
version was 8.14

00:17:31,520 --> 00:17:38,960
so this is a typical topology diagram

00:17:35,600 --> 00:17:42,000
that we have considered and deployed

00:17:38,960 --> 00:17:45,280
uh you know in order to evaluate uh both

00:17:42,000 --> 00:17:47,679
power nine as well as calix system

00:17:45,280 --> 00:17:49,360
so taking a look over here we have two

00:17:47,679 --> 00:17:51,440
pure clusters

00:17:49,360 --> 00:17:53,440
that that's power only clustered over

00:17:51,440 --> 00:17:55,679
here and intel only cluster on on the

00:17:53,440 --> 00:17:58,080
right side of the screen

00:17:55,679 --> 00:17:59,200
the traffic to both the clusters were

00:17:58,080 --> 00:18:02,480
coming from

00:17:59,200 --> 00:18:04,400
same rack switch and then the traffic

00:18:02,480 --> 00:18:05,360
was generated using the same workload

00:18:04,400 --> 00:18:11,039
generator

00:18:05,360 --> 00:18:11,039
which is sa212 lc powered box then

00:18:11,440 --> 00:18:15,360
the power vm resources were equally

00:18:13,360 --> 00:18:16,080
distributed across logical partition one

00:18:15,360 --> 00:18:18,480
and two

00:18:16,080 --> 00:18:19,520
that is 128 gb of ram and then physical

00:18:18,480 --> 00:18:23,120
cores

00:18:19,520 --> 00:18:27,120
whereas on interestingly we have

00:18:23,120 --> 00:18:32,320
given 18 physical cores to vm1 and vm2

00:18:27,120 --> 00:18:35,280
and then ram was 128 gb

00:18:32,320 --> 00:18:35,280
served accordingly

00:18:35,360 --> 00:18:38,799
let's take a look at the data flow

00:18:39,039 --> 00:18:45,360
we have in order to target

00:18:42,640 --> 00:18:46,960
the services exposed are the application

00:18:45,360 --> 00:18:49,360
services exposed

00:18:46,960 --> 00:18:50,160
we have something called socp route

00:18:49,360 --> 00:18:53,440
which

00:18:50,160 --> 00:18:55,760
allows us to access application services

00:18:53,440 --> 00:18:59,360
outside the cluster

00:18:55,760 --> 00:19:00,640
ocp route you can think of it as a

00:18:59,360 --> 00:19:02,799
unique url

00:19:00,640 --> 00:19:04,720
yeah you can think of it as a url which

00:19:02,799 --> 00:19:06,799
is unique to both

00:19:04,720 --> 00:19:08,880
uh power only cluster and intel only

00:19:06,799 --> 00:19:11,919
cluster

00:19:08,880 --> 00:19:13,039
right so the rectangular blocks that you

00:19:11,919 --> 00:19:16,160
are seeing over here

00:19:13,039 --> 00:19:18,160
on the screen there they are physical

00:19:16,160 --> 00:19:19,360
representations

00:19:18,160 --> 00:19:21,679
uh they are diagrammatical

00:19:19,360 --> 00:19:24,400
representation of the containers

00:19:21,679 --> 00:19:27,039
you know they are hosting uh at the

00:19:24,400 --> 00:19:30,400
outset node.js and mongodb services

00:19:27,039 --> 00:19:32,880
similarly over here so whenever

00:19:30,400 --> 00:19:34,240
we trigger a workload we feed in the

00:19:32,880 --> 00:19:36,080
unique url

00:19:34,240 --> 00:19:39,840
and the data wall and the data flow was

00:19:36,080 --> 00:19:39,840
getting targeted accordingly

00:19:41,120 --> 00:19:47,600
yeah so with this all what does it mean

00:19:44,400 --> 00:19:49,919
when it comes to price performance ratio

00:19:47,600 --> 00:19:51,440
right so what we have taken into

00:19:49,919 --> 00:19:55,280
consideration

00:19:51,440 --> 00:19:58,400
is a ibm powered l922 box

00:19:55,280 --> 00:20:02,400
and then the intel's skylake box

00:19:58,400 --> 00:20:05,440
which is 6148 they were almost the same

00:20:02,400 --> 00:20:08,880
they almost have both same uh

00:20:05,440 --> 00:20:11,360
ram that is uh

00:20:08,880 --> 00:20:12,320
256 gb which has been shared across two

00:20:11,360 --> 00:20:15,039
vms

00:20:12,320 --> 00:20:16,960
and then at the outset we were having 18

00:20:15,039 --> 00:20:20,480
physical cores per vm

00:20:16,960 --> 00:20:23,600
and 10 physical cost per

00:20:20,480 --> 00:20:27,600
uh l par over here you know uh

00:20:23,600 --> 00:20:30,880
if we do the math what it means is

00:20:27,600 --> 00:20:34,159
we could a com we were

00:20:30,880 --> 00:20:36,799
we could showcase 3.2 x greater than

00:20:34,159 --> 00:20:37,840
greater container density per core as in

00:20:36,799 --> 00:20:41,600
comparison to

00:20:37,840 --> 00:20:44,159
nn with nearly 2.5

00:20:41,600 --> 00:20:44,640
better price performance ratio you know

00:20:44,159 --> 00:20:48,080
if it

00:20:44,640 --> 00:20:49,760
if it means on a container level how

00:20:48,080 --> 00:20:52,159
costly were there

00:20:49,760 --> 00:20:54,159
you know uh assuming all of the map

00:20:52,159 --> 00:20:56,720
that's that's written over here

00:20:54,159 --> 00:20:57,760
you know it's 666 dollars per container

00:20:56,720 --> 00:21:01,440
in a way

00:20:57,760 --> 00:21:04,880
and then this is nearly 1750.

00:21:01,440 --> 00:21:08,559
on intel we have done

00:21:04,880 --> 00:21:11,120
a similar use case study on 1922 or the

00:21:08,559 --> 00:21:15,840
mihawk systems

00:21:11,120 --> 00:21:19,120
along with the schedic systems again

00:21:15,840 --> 00:21:22,240
we have seen was we we could

00:21:19,120 --> 00:21:23,520
still maintain the lead off to exploit a

00:21:22,240 --> 00:21:26,559
container density deal

00:21:23,520 --> 00:21:27,679
on a system on a system on a per core

00:21:26,559 --> 00:21:29,440
basis

00:21:27,679 --> 00:21:31,440
and then the price performance was near

00:21:29,440 --> 00:21:34,720
about 2.35

00:21:31,440 --> 00:21:38,480
better than intel system but we have

00:21:34,720 --> 00:21:41,760
leveraged something called as qos

00:21:38,480 --> 00:21:41,760
which is quality of service

00:21:41,840 --> 00:21:46,799
basing on that we could drive

00:21:45,039 --> 00:21:48,159
more transactions per second as in

00:21:46,799 --> 00:21:52,000
comparison to

00:21:48,159 --> 00:21:54,799
uh default qos which is

00:21:52,000 --> 00:21:58,480
uh you know i think i think that that's

00:21:54,799 --> 00:22:01,520
boostable if i'm not wrong

00:21:58,480 --> 00:22:01,520
oh that's best of it

00:22:02,320 --> 00:22:07,679
so we have three different quality of

00:22:06,400 --> 00:22:11,600
services classes

00:22:07,679 --> 00:22:13,280
rtuse which is available at our disposal

00:22:11,600 --> 00:22:14,720
and then this are something as a

00:22:13,280 --> 00:22:17,120
fundamental topic that comes for

00:22:14,720 --> 00:22:20,400
kubernetes and has been

00:22:17,120 --> 00:22:23,600
consumed onto openshift as well

00:22:20,400 --> 00:22:24,320
so you can think of a container and then

00:22:23,600 --> 00:22:27,039
how

00:22:24,320 --> 00:22:28,640
the resources can be defined to the

00:22:27,039 --> 00:22:30,240
particular container

00:22:28,640 --> 00:22:31,840
the resources that can be defined and

00:22:30,240 --> 00:22:35,440
controlled are basically

00:22:31,840 --> 00:22:38,960
are majorly are cpu and ram

00:22:35,440 --> 00:22:41,039
and then if you feed both set

00:22:38,960 --> 00:22:42,000
the upper limit and the lower limit as

00:22:41,039 --> 00:22:44,159
equal

00:22:42,000 --> 00:22:45,600
that's called as guaranteed quality of

00:22:44,159 --> 00:22:49,200
service

00:22:45,600 --> 00:22:52,240
if we if

00:22:49,200 --> 00:22:54,799
uh if we only set

00:22:52,240 --> 00:22:56,559
the request and optionally uh leave the

00:22:54,799 --> 00:22:58,240
limits field

00:22:56,559 --> 00:23:01,919
you can think of request as the upper

00:22:58,240 --> 00:23:01,919
limit and limits as the lower limit

00:23:02,080 --> 00:23:06,880
you know if you set only the upper limit

00:23:04,159 --> 00:23:08,559
and level about the lower limit

00:23:06,880 --> 00:23:10,559
we get something called as personable

00:23:08,559 --> 00:23:12,159
quality of service if we do not define

00:23:10,559 --> 00:23:14,000
any

00:23:12,159 --> 00:23:16,240
that that's that gets by default

00:23:14,000 --> 00:23:18,799
classified as best of foods

00:23:16,240 --> 00:23:20,720
so when we did that particular test and

00:23:18,799 --> 00:23:22,960
switching back to the previous slide

00:23:20,720 --> 00:23:25,280
what happened was we could drive more

00:23:22,960 --> 00:23:28,320
transactions per second

00:23:25,280 --> 00:23:30,480
but keeping in view the the agenda of

00:23:28,320 --> 00:23:33,679
this particular use case study was to

00:23:30,480 --> 00:23:37,360
pack as many as containers as possible

00:23:33,679 --> 00:23:38,159
in this particular result what we have

00:23:37,360 --> 00:23:43,360
also

00:23:38,159 --> 00:23:43,360
did was driven a great deal of dps

00:23:47,360 --> 00:23:54,480
i think we are short on time

00:23:50,799 --> 00:23:57,919
for the youtube uh video mython is

00:23:54,480 --> 00:23:58,320
right we have for five more minutes i

00:23:57,919 --> 00:24:01,600
think

00:23:58,320 --> 00:24:05,440
we can go to uh q a

00:24:01,600 --> 00:24:08,559
all right uh yeah i think i think i'll

00:24:05,440 --> 00:24:08,559
i'll just take a pause

00:24:09,120 --> 00:24:12,159
if in case you have any questions we

00:24:11,600 --> 00:24:14,880
have

00:24:12,159 --> 00:24:15,360
one question uh we have two questions

00:24:14,880 --> 00:24:19,240
actually

00:24:15,360 --> 00:24:21,039
one uh is there a plan to credit to

00:24:19,240 --> 00:24:23,919
openshift454.5

00:24:21,039 --> 00:24:26,480
uh from frederick uh to see if it makes

00:24:23,919 --> 00:24:26,480
any difference

00:24:26,880 --> 00:24:35,600
actually yeah yeah so so i think i think

00:24:31,039 --> 00:24:38,640
openshift 4.5 is is is

00:24:35,600 --> 00:24:39,520
in fact open openshift 4.x is really

00:24:38,640 --> 00:24:41,120
different in

00:24:39,520 --> 00:24:42,960
the architecture the way it brings onto

00:24:41,120 --> 00:24:47,039
the table as in comparison to

00:24:42,960 --> 00:24:50,400
openshift version that said

00:24:47,039 --> 00:24:53,360
we do say we do assume

00:24:50,400 --> 00:24:56,080
that there will be some performance

00:24:53,360 --> 00:24:58,880
benefit if you run it on power systems

00:24:56,080 --> 00:25:00,480
but but it will be too early to make

00:24:58,880 --> 00:25:02,480
that statement

00:25:00,480 --> 00:25:04,720
uh we would want to do some tests which

00:25:02,480 --> 00:25:07,360
are right now under progress and then

00:25:04,720 --> 00:25:08,480
then we'll see how it comes along now i

00:25:07,360 --> 00:25:10,400
think i think it will

00:25:08,480 --> 00:25:11,919
if it will definitely make no difference

00:25:10,400 --> 00:25:14,480
but

00:25:11,919 --> 00:25:17,279
we need to understand how or what's your

00:25:14,480 --> 00:25:17,279
driving factor

00:25:20,320 --> 00:25:25,679
i'm not sure we have we have one more

00:25:23,279 --> 00:25:28,000
question from vpn

00:25:25,679 --> 00:25:28,880
in performance comparison can you

00:25:28,000 --> 00:25:32,159
explain if

00:25:28,880 --> 00:25:34,720
a skydeck 20 core is enabled with smt

00:25:32,159 --> 00:25:37,360
is first part of the question second

00:25:34,720 --> 00:25:41,039
part is if ic922 is enabled with

00:25:37,360 --> 00:25:43,679
smt4 and third parties

00:25:41,039 --> 00:25:44,400
the 10 g internet interconnect is per

00:25:43,679 --> 00:25:48,320
pneuma

00:25:44,400 --> 00:25:51,679
or 1 into 10 g on numa

00:25:48,320 --> 00:25:56,640
and weapon has asked if you can share

00:25:51,679 --> 00:25:59,520
some insight on kvm running on skylake

00:25:56,640 --> 00:26:00,400
treason uh there are only four threads

00:25:59,520 --> 00:26:02,320
which are mentioned

00:26:00,400 --> 00:26:03,520
uh 40 threads which are mentioned in the

00:26:02,320 --> 00:26:06,960
slide

00:26:03,520 --> 00:26:10,559
that's correct so um i'll just

00:26:06,960 --> 00:26:14,559
switch back to the particular

00:26:10,559 --> 00:26:16,080
um you know comparison so so let me

00:26:14,559 --> 00:26:19,120
answer your question

00:26:16,080 --> 00:26:22,960
that is a skylake

00:26:19,120 --> 00:26:25,200
20 cores is enabled with smt

00:26:22,960 --> 00:26:26,720
smt is is a concept associated with

00:26:25,200 --> 00:26:29,039
power systems only

00:26:26,720 --> 00:26:30,559
uh the equivalent terminology for that

00:26:29,039 --> 00:26:33,600
will be hyper-v

00:26:30,559 --> 00:26:35,200
and then yes it was enabled and on the

00:26:33,600 --> 00:26:38,400
intel systems

00:26:35,200 --> 00:26:41,679
and uh and then that's how we could

00:26:38,400 --> 00:26:45,279
drive 40 virtual threads

00:26:41,679 --> 00:26:45,279
you know and then um

00:26:45,919 --> 00:26:51,760
and then if i seen it saying yes ic922

00:26:49,679 --> 00:26:54,320
was enabled with only smt4

00:26:51,760 --> 00:26:54,320
that's correct

00:26:54,799 --> 00:27:00,960
uh the 10g the 10 gig

00:26:57,919 --> 00:27:02,880
interconnect is per numa or one into i

00:27:00,960 --> 00:27:06,080
think i need to get back to you on

00:27:02,880 --> 00:27:08,400
question c within i think i think uh

00:27:06,080 --> 00:27:10,000
i'll reach out to you i'll try to get

00:27:08,400 --> 00:27:12,159
the details and find out you and then

00:27:10,000 --> 00:27:16,000
get back to you on this can you share

00:27:12,159 --> 00:27:19,279
inside to kvm running on skylake

00:27:16,000 --> 00:27:22,399
um i do not quite follow this question

00:27:19,279 --> 00:27:24,960
can you elaborate

00:27:22,399 --> 00:27:24,960
more on this

00:27:28,799 --> 00:27:35,840
okay so all of the codes are associated

00:27:30,640 --> 00:27:35,840
to kvm yeah

00:27:45,120 --> 00:27:49,840
right so moving on the second question

00:27:48,080 --> 00:27:53,679
which chipping has just posted

00:27:49,840 --> 00:27:53,679
right that is um

00:27:55,760 --> 00:27:59,919
okay uh so we have 20 physical cores if

00:27:58,799 --> 00:28:04,159
we enable

00:27:59,919 --> 00:28:06,799
hyper-v then we will get 40 cpus

00:28:04,159 --> 00:28:08,320
or you know that's how it will be 40

00:28:06,799 --> 00:28:17,840
hardware threads you can

00:28:08,320 --> 00:28:17,840
you can think of it in that way

00:28:18,320 --> 00:28:21,760
exactly we have done the cpu pinning of

00:28:20,640 --> 00:28:25,200
the questions as well

00:28:21,760 --> 00:28:28,840
you know yeah yeah we've been

00:28:25,200 --> 00:28:32,720
i have uh uh uh unlocked uh

00:28:28,840 --> 00:28:34,799
yeah so i was just

00:28:32,720 --> 00:28:35,760
a couple of things which was not clear

00:28:34,799 --> 00:28:38,880
to me was

00:28:35,760 --> 00:28:41,679
like the skylake uh six one four eight

00:28:38,880 --> 00:28:43,520
zeon that you mentioned right each is

00:28:41,679 --> 00:28:45,760
having 20 goes

00:28:43,520 --> 00:28:47,200
and since there are two pneuma there

00:28:45,760 --> 00:28:49,120
would be 40 cores

00:28:47,200 --> 00:28:50,880
and if hyper threatening or smt is

00:28:49,120 --> 00:28:54,799
enabled wouldn't that make it

00:28:50,880 --> 00:28:54,799
80 threads available to it

00:28:55,760 --> 00:28:59,360
that's a very good point i was talking

00:28:57,440 --> 00:29:02,799
at the socket level

00:28:59,360 --> 00:29:03,679
oh okay yeah okay so this is our two

00:29:02,799 --> 00:29:06,880
socket box

00:29:03,679 --> 00:29:10,720
so each socket having 20 cores

00:29:06,880 --> 00:29:14,399
yes in total we have 40 physical cores

00:29:10,720 --> 00:29:17,120
and exactly yes this is uh we have

00:29:14,399 --> 00:29:17,760
80 physical 80 hardware threads that we

00:29:17,120 --> 00:29:20,960
can leverage

00:29:17,760 --> 00:29:23,279
yes absolutely and when i think about

00:29:20,960 --> 00:29:27,120
power ic 922

00:29:23,279 --> 00:29:28,240
it has 20 plus 20 with smt4 enabled

00:29:27,120 --> 00:29:31,760
makes it

00:29:28,240 --> 00:29:35,120
440 into four 160 threads uh

00:29:31,760 --> 00:29:38,480
that was my understanding and uh you

00:29:35,120 --> 00:29:41,679
have used core zero if i am not wrong

00:29:38,480 --> 00:29:42,320
to run the linux uh on the host that is

00:29:41,679 --> 00:29:45,360
why

00:29:42,320 --> 00:29:48,000
one one thread per one container

00:29:45,360 --> 00:29:49,120
so that is why you have 159 on power pc

00:29:48,000 --> 00:29:52,880
and 79

00:29:49,120 --> 00:29:56,000
on xeon that is what i am assuming

00:29:52,880 --> 00:29:59,039
is that the right understanding

00:29:56,000 --> 00:30:02,480
um that's uh one way of

00:29:59,039 --> 00:30:04,559
doing the math yes but but uh

00:30:02,480 --> 00:30:05,679
to answer your question pretty short and

00:30:04,559 --> 00:30:09,760
clean right

00:30:05,679 --> 00:30:12,240
so we could the one

00:30:09,760 --> 00:30:13,039
thread that's exactly true one container

00:30:12,240 --> 00:30:15,279
per thread

00:30:13,039 --> 00:30:16,080
and the one thing that we have to leave

00:30:15,279 --> 00:30:19,279
out

00:30:16,080 --> 00:30:21,279
was because we had to

00:30:19,279 --> 00:30:22,480
ensure openshift container platform was

00:30:21,279 --> 00:30:25,679
also running

00:30:22,480 --> 00:30:29,200
absolutely i agree i agree yeah yeah so

00:30:25,679 --> 00:30:31,279
so so uh basically it was uh you know

00:30:29,200 --> 00:30:33,440
openshift container platform as well as

00:30:31,279 --> 00:30:34,480
kvm and operating system running on one

00:30:33,440 --> 00:30:37,039
thread

00:30:34,480 --> 00:30:39,279
absolutely so in skylake the kvm and

00:30:37,039 --> 00:30:40,080
openshift runs on let's say that core

00:30:39,279 --> 00:30:43,679
zero

00:30:40,080 --> 00:30:45,679
perfect but in ibm with ic92 i thought

00:30:43,679 --> 00:30:49,919
it was a hardware kvm

00:30:45,679 --> 00:30:50,799
so the open shift only need to be run on

00:30:49,919 --> 00:30:53,440
core 0

00:30:50,799 --> 00:30:54,399
with some management activity from os is

00:30:53,440 --> 00:30:56,240
what i was

00:30:54,399 --> 00:30:57,440
trying to understand so you do have

00:30:56,240 --> 00:31:00,320
power savings

00:30:57,440 --> 00:31:02,000
and you do have the core impact savings

00:31:00,320 --> 00:31:02,720
with that that is what i was trying to

00:31:02,000 --> 00:31:05,440
compare

00:31:02,720 --> 00:31:06,720
but thank you i think i got a picture

00:31:05,440 --> 00:31:10,559
thank you very much

00:31:06,720 --> 00:31:12,640
yeah thank you yeah and then guys if in

00:31:10,559 --> 00:31:15,120
case you have any more questions

00:31:12,640 --> 00:31:18,000
please feel free to post them on our

00:31:15,120 --> 00:31:18,000

YouTube URL: https://www.youtube.com/watch?v=aLPSCia4N3s


