Title: OpenCAPI BoF - A Memory Centric Fabric for a Data Centric World
Publication date: 2020-09-21
Playlist: OpenPOWER Summit NA 2020
Description: 
	OpenCAPI BoF - A Memory Centric Fabric for a Data Centric World - Allan J. Cantle, Nallasway Inc.; Marcy Byers & Alexandre Castellane IBM; Craig Petrie, BittWare & Oskar Mencer, Maxeler

Speakers: Alexandre Castellane, Allan J. Cantle, Craig Petrie, Marcy Byers, Oskar Mencer
Concluding the OpenCAPI track there will be two additional lightning talks followed by the described BoF moderated by Allan Cantle.

FPGA Accelerators including Hybrid Memory Subsystems - BittWare - Craig Petrie

Applications that can benefit from OMI enabled FPGA Acceleration - Maxeler  - Oskar Mencer

As the computing industry shifts towards a Disaggregated, Heterogeneous, Data Centric World, we've seen a myriad of Fabric Technologies being proposed and developed in what has commonly been referred to as Fabric Wars. This BoF reviews the key attributes of OpenCAPI, which is the only Fabric in production that's focused on lowest latency and high bandwidth direct connections with Memory, Accelerators & other Systems. The primary aim of the BoF is to both educate and to debate the merits & shortcomings of OpenCAPI when compared to alternate fabrics that typically have a broader scope. Is OpenCAPI a bus standard for the HPC world where only the highest performance will suffice and can such an open technology significantly help in democratizing the High Performance Computing Community once and for all?
Captions: 
	00:00:01,360 --> 00:00:06,319
uh hi everyone welcome to the um

00:00:04,240 --> 00:00:08,160
open cappy birds of a fat birds of a

00:00:06,319 --> 00:00:12,160
favorite panel session

00:00:08,160 --> 00:00:13,759
uh so hopefully you've you've all seen

00:00:12,160 --> 00:00:15,759
a good few of the presentations my

00:00:13,759 --> 00:00:19,279
keynote this morning and the open copy

00:00:15,759 --> 00:00:22,560
track to a um um

00:00:19,279 --> 00:00:25,039
we're the the the panel session here is

00:00:22,560 --> 00:00:26,080
is we're really just discussing uh open

00:00:25,039 --> 00:00:29,119
cappy

00:00:26,080 --> 00:00:30,720
it's it's applicability um to

00:00:29,119 --> 00:00:32,160
to the high performance computing world

00:00:30,720 --> 00:00:33,280
the data centric fabric for high

00:00:32,160 --> 00:00:35,760
performance computing

00:00:33,280 --> 00:00:37,760
alongside with the omi the open capping

00:00:35,760 --> 00:00:40,399
memory interface as well that

00:00:37,760 --> 00:00:40,879
that we was talking about in the keynote

00:00:40,399 --> 00:00:42,480
i'm

00:00:40,879 --> 00:00:46,000
happy to take any questions on all

00:00:42,480 --> 00:00:48,879
subjects uh contentious or positive

00:00:46,000 --> 00:00:49,840
or everything um so looking forward to a

00:00:48,879 --> 00:00:53,520
lively debate

00:00:49,840 --> 00:00:55,840
um so so feel free to to to to

00:00:53,520 --> 00:00:57,520
put questions in the q a and you can

00:00:55,840 --> 00:00:58,000
start putting questions in right from

00:00:57,520 --> 00:01:00,800
now if

00:00:58,000 --> 00:01:01,840
you like uh we're going to start with a

00:01:00,800 --> 00:01:04,080
couple more

00:01:01,840 --> 00:01:05,199
short lightning talks from craig petery

00:01:04,080 --> 00:01:08,400
at bittware

00:01:05,199 --> 00:01:10,159
and oscar menser at max eller but before

00:01:08,400 --> 00:01:11,119
we jump into that i'd like to just give

00:01:10,159 --> 00:01:13,360
everybody

00:01:11,119 --> 00:01:14,960
a chance to introduce ourselves who are

00:01:13,360 --> 00:01:17,600
on the panel

00:01:14,960 --> 00:01:21,040
so we have oscar menser would you like

00:01:17,600 --> 00:01:21,040
to give us a brief introduction

00:01:23,119 --> 00:01:29,280
sure oscar menswear i'm here uh

00:01:26,799 --> 00:01:31,680
um a new member at the open cafe

00:01:29,280 --> 00:01:33,759
consortium very exciting uh

00:01:31,680 --> 00:01:35,360
to to see all these new developments so

00:01:33,759 --> 00:01:36,320
i've been uh running maxellar

00:01:35,360 --> 00:01:39,600
technologies

00:01:36,320 --> 00:01:40,000
for uh 17 years now so it's um it's been

00:01:39,600 --> 00:01:43,680
a long

00:01:40,000 --> 00:01:48,159
time um and before that

00:01:43,680 --> 00:01:51,600
was uh at stanford and bell labs

00:01:48,159 --> 00:01:53,600
thank you greg

00:01:51,600 --> 00:01:54,880
hi everyone my name is craig petrie i'm

00:01:53,600 --> 00:01:57,200
vp of marketing

00:01:54,880 --> 00:01:58,640
at bitsware which is part of the molex

00:01:57,200 --> 00:02:00,799
group of companies

00:01:58,640 --> 00:02:01,759
uh i'm based in the uk i've been with

00:02:00,799 --> 00:02:05,200
organization

00:02:01,759 --> 00:02:08,239
uh 18 years now um started as an

00:02:05,200 --> 00:02:08,560
fpga programmer from university and i've

00:02:08,239 --> 00:02:11,920
been

00:02:08,560 --> 00:02:13,200
programming fpgas for are involved in

00:02:11,920 --> 00:02:16,319
fpga computing for

00:02:13,200 --> 00:02:19,040
23 years now and been involved in the

00:02:16,319 --> 00:02:20,160
opencapi open power initiative with alan

00:02:19,040 --> 00:02:23,360
for the last

00:02:20,160 --> 00:02:26,959
six or seven years thank you great

00:02:23,360 --> 00:02:28,879
marcy you know your turn sure so as alan

00:02:26,959 --> 00:02:29,840
said i'm marcy i'm a senior engineer

00:02:28,879 --> 00:02:31,360
with ibm

00:02:29,840 --> 00:02:33,360
i've been involved in both the power 9

00:02:31,360 --> 00:02:35,440
and power 10 platforms

00:02:33,360 --> 00:02:37,280
from the perspective of a core designer

00:02:35,440 --> 00:02:38,959
most recently i'm really focused on

00:02:37,280 --> 00:02:40,959
energy efficiency so looking at ways

00:02:38,959 --> 00:02:43,360
that we're reducing that through design

00:02:40,959 --> 00:02:44,239
in the core in order to get that

00:02:43,360 --> 00:02:45,840
advantage that you've kind of heard

00:02:44,239 --> 00:02:47,920
about throughout the day on our

00:02:45,840 --> 00:02:49,440
energy reduction from the power 10 from

00:02:47,920 --> 00:02:50,720
the power 9 processor into the power 10

00:02:49,440 --> 00:02:52,480
processor

00:02:50,720 --> 00:02:53,840
um but in terms of this panel i'm really

00:02:52,480 --> 00:02:56,160
going to be covering things on

00:02:53,840 --> 00:02:58,400
amuse's flow as well as memory inception

00:02:56,160 --> 00:03:02,239
in the power 10.

00:02:58,400 --> 00:03:02,239
thank you marcy alexander

00:03:02,959 --> 00:03:06,560
hi everybody thank you very much for

00:03:04,480 --> 00:03:07,920
your attendance my name is alexander

00:03:06,560 --> 00:03:11,040
castellano i'm working

00:03:07,920 --> 00:03:11,920
with ibm for a few years on supporting

00:03:11,040 --> 00:03:14,720
and

00:03:11,920 --> 00:03:18,000
helping people to develop copy and open

00:03:14,720 --> 00:03:20,959
and copy um

00:03:18,000 --> 00:03:21,760
situations i used to be a radio engineer

00:03:20,959 --> 00:03:24,239
so i've been

00:03:21,760 --> 00:03:25,840
working for a long time in analog design

00:03:24,239 --> 00:03:28,239
analogue world

00:03:25,840 --> 00:03:30,640
radioactivity and for a few years now

00:03:28,239 --> 00:03:34,400
i'm working with ibm very happy to

00:03:30,640 --> 00:03:37,920
help you design your new um opencapi

00:03:34,400 --> 00:03:40,480
systems thank you alexander

00:03:37,920 --> 00:03:41,280
okay so that's us the panelists we have

00:03:40,480 --> 00:03:43,760
um

00:03:41,280 --> 00:03:44,560
i just did again uh please feel free to

00:03:43,760 --> 00:03:47,680
enter uh

00:03:44,560 --> 00:03:48,319
questions in the q a uh we'll try to uh

00:03:47,680 --> 00:03:50,080
get them

00:03:48,319 --> 00:03:51,920
answered but written answered and then

00:03:50,080 --> 00:03:53,680
i'll i will bring i will bring them in

00:03:51,920 --> 00:03:56,400
for the panel discussion

00:03:53,680 --> 00:03:57,200
see if we can get a a a a nice debate

00:03:56,400 --> 00:04:00,319
going

00:03:57,200 --> 00:04:01,040
uh around the various areas so but

00:04:00,319 --> 00:04:03,599
firstly

00:04:01,040 --> 00:04:04,879
uh let's i'll hand over to craig who

00:04:03,599 --> 00:04:08,640
will give a

00:04:04,879 --> 00:04:12,239
a brief presentation on um on bitwear's

00:04:08,640 --> 00:04:14,239
acceleration cards thanks dylan

00:04:12,239 --> 00:04:15,360
um okay i'm showing screen now hopefully

00:04:14,239 --> 00:04:17,680
everyone can see that

00:04:15,360 --> 00:04:18,479
okay i think this uh presentation will

00:04:17,680 --> 00:04:21,040
be about

00:04:18,479 --> 00:04:22,320
five or just over five minutes in total

00:04:21,040 --> 00:04:24,639
so i'll try and

00:04:22,320 --> 00:04:25,759
pack as much in as i can there um i'd

00:04:24,639 --> 00:04:27,600
like to start by

00:04:25,759 --> 00:04:29,280
thanking alan and organizers for

00:04:27,600 --> 00:04:30,320
providing a better with the opportunity

00:04:29,280 --> 00:04:33,120
to present

00:04:30,320 --> 00:04:33,520
uh today uh open power and open cappy

00:04:33,120 --> 00:04:36,240
are

00:04:33,520 --> 00:04:38,080
exciting initiatives that we're um very

00:04:36,240 --> 00:04:40,240
pleased to be involved with and uh

00:04:38,080 --> 00:04:42,400
like alan hope for lots of lively debate

00:04:40,240 --> 00:04:45,280
debate on the subject

00:04:42,400 --> 00:04:46,400
so i'll be providing a quick overview of

00:04:45,280 --> 00:04:49,199
an opencapi

00:04:46,400 --> 00:04:49,919
enabled fpga accelerator products which

00:04:49,199 --> 00:04:53,280
we developed

00:04:49,919 --> 00:04:55,280
in conjunction with ibm

00:04:53,280 --> 00:04:56,639
um for those of you who are unfamiliar

00:04:55,280 --> 00:04:58,240
with bitswear we're actually an

00:04:56,639 --> 00:05:01,039
amalgamation of

00:04:58,240 --> 00:05:01,759
legacy now tech and legacy bitsware two

00:05:01,039 --> 00:05:03,759
of the leading

00:05:01,759 --> 00:05:05,680
uh suppliers of fpga accelerator

00:05:03,759 --> 00:05:07,840
products in the market

00:05:05,680 --> 00:05:09,840
we were both acquired by molex and

00:05:07,840 --> 00:05:10,320
rebranded bits where the molex company

00:05:09,840 --> 00:05:12,000
about

00:05:10,320 --> 00:05:14,720
two years ago roughly and now that's it

00:05:12,000 --> 00:05:17,600
being acquired more like five years ago

00:05:14,720 --> 00:05:18,400
between has a rich fpga heritage dating

00:05:17,600 --> 00:05:21,600
back

00:05:18,400 --> 00:05:24,960
30 years to the very birth of fpgas

00:05:21,600 --> 00:05:27,360
we address four main application areas

00:05:24,960 --> 00:05:29,280
but for today's presentation i'll focus

00:05:27,360 --> 00:05:33,120
on how we're using opencapi

00:05:29,280 --> 00:05:36,000
for computational storage use cases

00:05:33,120 --> 00:05:36,479
as part of molex between has tremendous

00:05:36,000 --> 00:05:39,120
reach

00:05:36,479 --> 00:05:40,560
in the marketplace and we're happy to be

00:05:39,120 --> 00:05:42,400
helping to spread

00:05:40,560 --> 00:05:45,600
the word on the benefits and the

00:05:42,400 --> 00:05:49,120
potential of open power and open cappy

00:05:45,600 --> 00:05:50,639
um between as part of legacy now tech

00:05:49,120 --> 00:05:52,639
we were involved in the very first

00:05:50,639 --> 00:05:56,720
incarnation of cappy

00:05:52,639 --> 00:06:00,639
way back in 2014 the card you see here

00:05:56,720 --> 00:06:03,759
is a 250 soc card which is very new

00:06:00,639 --> 00:06:05,440
this is a versatile product which allows

00:06:03,759 --> 00:06:07,360
customers to experiment

00:06:05,440 --> 00:06:09,280
with solutions which address the

00:06:07,360 --> 00:06:12,000
accelerator and the coherence

00:06:09,280 --> 00:06:13,600
network controller use cases that we see

00:06:12,000 --> 00:06:16,639
with opencapi

00:06:13,600 --> 00:06:19,600
it uses oculin connectors to support

00:06:16,639 --> 00:06:21,120
up to two open cappia links to the

00:06:19,600 --> 00:06:22,400
power9 horse processor

00:06:21,120 --> 00:06:25,280
[Music]

00:06:22,400 --> 00:06:26,400
focusing specifically on advanced memory

00:06:25,280 --> 00:06:29,039
and coherent

00:06:26,400 --> 00:06:29,919
storage controller use cases there are

00:06:29,039 --> 00:06:32,960
some clear

00:06:29,919 --> 00:06:34,319
market trends that we should highlight

00:06:32,960 --> 00:06:36,880
which play into the strength and

00:06:34,319 --> 00:06:39,440
potential of open cappy

00:06:36,880 --> 00:06:39,919
storage class memory is clearly here to

00:06:39,440 --> 00:06:42,240
stay

00:06:39,919 --> 00:06:43,600
with many applications taking advantage

00:06:42,240 --> 00:06:46,000
of persistent

00:06:43,600 --> 00:06:46,639
memory capability this is fueling

00:06:46,000 --> 00:06:48,639
advanced

00:06:46,639 --> 00:06:50,720
research and now what we're seeing is

00:06:48,639 --> 00:06:54,160
the deployment of production systems

00:06:50,720 --> 00:06:56,800
based on opencapa 3.0

00:06:54,160 --> 00:06:58,880
um it bits where we successfully

00:06:56,800 --> 00:07:01,680
collaborated with ibm

00:06:58,880 --> 00:07:02,400
on a new class of fpga accelerator which

00:07:01,680 --> 00:07:04,560
supports

00:07:02,400 --> 00:07:05,520
an open cap enabled hybrid memory

00:07:04,560 --> 00:07:09,599
subsystem

00:07:05,520 --> 00:07:11,199
or hms there are many pcie cards

00:07:09,599 --> 00:07:12,639
on the markets which feature

00:07:11,199 --> 00:07:15,280
acceleration technology

00:07:12,639 --> 00:07:17,599
with mixed memory supports however

00:07:15,280 --> 00:07:19,280
building on open cappy provides many

00:07:17,599 --> 00:07:21,120
clear advantages

00:07:19,280 --> 00:07:22,960
specifically the low latency high

00:07:21,120 --> 00:07:23,759
bandwidth connection to persistent

00:07:22,960 --> 00:07:26,080
memory

00:07:23,759 --> 00:07:27,840
for applications which benefits from

00:07:26,080 --> 00:07:30,000
large memory footprints

00:07:27,840 --> 00:07:31,360
example applications there include

00:07:30,000 --> 00:07:35,120
database acceleration

00:07:31,360 --> 00:07:36,319
of which there are many kinds opencap

00:07:35,120 --> 00:07:38,400
removes traditional

00:07:36,319 --> 00:07:40,720
storage software and hardware

00:07:38,400 --> 00:07:41,520
bottlenecks along with faster restart

00:07:40,720 --> 00:07:44,080
times

00:07:41,520 --> 00:07:44,720
often with no or minimal changes to the

00:07:44,080 --> 00:07:47,919
application

00:07:44,720 --> 00:07:50,800
code and the fruits of our labor

00:07:47,919 --> 00:07:52,000
with ibm is shown in a picture here um

00:07:50,800 --> 00:07:54,319
this is a photograph

00:07:52,000 --> 00:07:55,120
of the product we developed which is the

00:07:54,319 --> 00:07:58,319
00:07:55,120 --> 00:08:01,039
hms hms being hybrid memory subsystem

00:07:58,319 --> 00:08:02,720
um the card specifications are fairly

00:08:01,039 --> 00:08:05,199
straightforward

00:08:02,720 --> 00:08:06,479
it's a full height half length single

00:08:05,199 --> 00:08:08,319
width pcie card

00:08:06,479 --> 00:08:09,599
which you can see here is a passively

00:08:08,319 --> 00:08:11,280
killed um

00:08:09,599 --> 00:08:13,039
things get very interesting with the

00:08:11,280 --> 00:08:15,680
memory um architecture

00:08:13,039 --> 00:08:16,400
so in total we've got um four types of

00:08:15,680 --> 00:08:19,440
memory

00:08:16,400 --> 00:08:21,360
onboard card um the main

00:08:19,440 --> 00:08:23,599
i'm going to star of the show is the

00:08:21,360 --> 00:08:26,720
samsung xenon's memory

00:08:23,599 --> 00:08:28,319
you can see that here along the top we

00:08:26,720 --> 00:08:32,640
also have samsung

00:08:28,319 --> 00:08:35,360
ddr4 sdram uh we also have sram

00:08:32,640 --> 00:08:37,360
inside the xylex fpga which you can't

00:08:35,360 --> 00:08:39,599
see there but is underneath the um

00:08:37,360 --> 00:08:41,039
the heatsink on the bottom and finally

00:08:39,599 --> 00:08:44,800
we have everspin

00:08:41,039 --> 00:08:47,680
mram as well now each card can support

00:08:44,800 --> 00:08:49,519
up to three terabytes of xenand memory

00:08:47,680 --> 00:08:51,839
which can be virtualized

00:08:49,519 --> 00:08:52,839
importantly we are able to hit the

00:08:51,839 --> 00:08:56,640
target price

00:08:52,839 --> 00:08:58,480
between traditional ssds and dram

00:08:56,640 --> 00:09:01,839
making this product a very compelling

00:08:58,480 --> 00:09:03,920
platform for sequential workloads

00:09:01,839 --> 00:09:05,120
at the moment we're doing testing and

00:09:03,920 --> 00:09:07,279
work with ibm

00:09:05,120 --> 00:09:08,560
and we're on track to meet an average

00:09:07,279 --> 00:09:11,279
read the latency

00:09:08,560 --> 00:09:12,240
of one microsecond at the bandwidth of

00:09:11,279 --> 00:09:14,720
00:09:12,240 --> 00:09:16,959
gigabytes per second and this of course

00:09:14,720 --> 00:09:20,720
is possible because of the opencapi

00:09:16,959 --> 00:09:24,000
3.0 high speed serial interface

00:09:20,720 --> 00:09:26,800
the 250 hms is mechanically

00:09:24,000 --> 00:09:28,000
quite sophisticated it's a very complex

00:09:26,800 --> 00:09:30,160
car mechanically

00:09:28,000 --> 00:09:31,440
um and that's because it uses a very

00:09:30,160 --> 00:09:33,760
novel and modular

00:09:31,440 --> 00:09:35,040
m.2 approach to house the xenons

00:09:33,760 --> 00:09:36,720
memories

00:09:35,040 --> 00:09:38,880
the xenon memories is where the large

00:09:36,720 --> 00:09:40,720
application data sets will be stored

00:09:38,880 --> 00:09:42,240
in these four banks you see here on the

00:09:40,720 --> 00:09:45,600
left hand side

00:09:42,240 --> 00:09:47,040
the ddr4 sdram is soldered onto the main

00:09:45,600 --> 00:09:50,080
pcb

00:09:47,040 --> 00:09:52,880
acting as a local card dram cache for

00:09:50,080 --> 00:09:53,839
the applications and the sram inside the

00:09:52,880 --> 00:09:57,040
fpga

00:09:53,839 --> 00:09:59,760
and also acts another card level cache

00:09:57,040 --> 00:10:00,560
finally the mram is there to guarantee

00:09:59,760 --> 00:10:04,240
persistence

00:10:00,560 --> 00:10:06,640
during unexpected power losses

00:10:04,240 --> 00:10:08,640
in the image you can see here uh this

00:10:06,640 --> 00:10:11,760
shows a server which i think is the

00:10:08,640 --> 00:10:13,200
s 924 server uh with them two of the

00:10:11,760 --> 00:10:15,040
cards populated

00:10:13,200 --> 00:10:16,320
i think the server can take up to four

00:10:15,040 --> 00:10:18,959
cards and

00:10:16,320 --> 00:10:20,160
of course there's an open cappy enabled

00:10:18,959 --> 00:10:22,959
platform here

00:10:20,160 --> 00:10:25,360
so we have up to 25 gigabytes per second

00:10:22,959 --> 00:10:27,360
uh with opencapi 3.0

00:10:25,360 --> 00:10:29,040
uh which you can clearly see here on the

00:10:27,360 --> 00:10:29,839
right hand side of the card connecting

00:10:29,040 --> 00:10:33,200
into the

00:10:29,839 --> 00:10:33,920
motherboard um as you can see in this

00:10:33,200 --> 00:10:36,240
diagram

00:10:33,920 --> 00:10:37,839
uh the hierarchy of the memory on the

00:10:36,240 --> 00:10:40,800
250 hms card

00:10:37,839 --> 00:10:42,399
works well for sequential workloads

00:10:40,800 --> 00:10:45,360
that's what it's geared up for

00:10:42,399 --> 00:10:48,000
this is where we're pre-fetching from

00:10:45,360 --> 00:10:50,240
the zenand memory to the dram cache

00:10:48,000 --> 00:10:51,839
then we're quickly accessing that across

00:10:50,240 --> 00:10:54,560
the open capi link

00:10:51,839 --> 00:10:55,279
to the power line processor initial host

00:10:54,560 --> 00:10:56,800
access

00:10:55,279 --> 00:10:58,959
um to the zenens is about five

00:10:56,800 --> 00:11:01,120
microseconds however

00:10:58,959 --> 00:11:02,240
this will then level out towards one

00:11:01,120 --> 00:11:06,240
microseconds

00:11:02,240 --> 00:11:08,959
once these accesses are falling

00:11:06,240 --> 00:11:10,800
um for more information on the 250 hms

00:11:08,959 --> 00:11:12,560
products then please get in touch with

00:11:10,800 --> 00:11:15,120
bitwear

00:11:12,560 --> 00:11:16,560
ibm is very much uh a driver of this um

00:11:15,120 --> 00:11:20,000
product in this development

00:11:16,560 --> 00:11:21,600
and uh i'm expecting ibm to show to

00:11:20,000 --> 00:11:23,920
share more details and application

00:11:21,600 --> 00:11:24,959
benchmarks and solutions using this

00:11:23,920 --> 00:11:27,600
powerful platform

00:11:24,959 --> 00:11:28,079
later this year and early next year so

00:11:27,600 --> 00:11:31,200
thank you

00:11:28,079 --> 00:11:33,120
for um the kind of power presentation

00:11:31,200 --> 00:11:34,800
there i can have a short form five to

00:11:33,120 --> 00:11:37,360
seven minute presentation

00:11:34,800 --> 00:11:37,839
um thank you for your attention and alan

00:11:37,360 --> 00:11:39,440
said

00:11:37,839 --> 00:11:41,519
very happy to try and answer any

00:11:39,440 --> 00:11:42,079
questions which you have if i can answer

00:11:41,519 --> 00:11:43,760
them

00:11:42,079 --> 00:11:45,680
live then i'll be sure to give you an

00:11:43,760 --> 00:11:47,120
answer as a follow-up thank you

00:11:45,680 --> 00:11:50,160
[Music]

00:11:47,120 --> 00:11:53,600
thanks craig if you can uh release your

00:11:50,160 --> 00:11:56,959
presentation and uh oscar can jump in

00:11:53,600 --> 00:12:00,399
there you go thank you all right

00:11:56,959 --> 00:12:03,279
can you give me a second here sharing

00:12:00,399 --> 00:12:03,279
the screen

00:12:04,160 --> 00:12:06,480
now

00:12:07,680 --> 00:12:11,839
yum yum

00:12:12,160 --> 00:12:20,880
okay does that work

00:12:17,600 --> 00:12:24,639
all right well

00:12:20,880 --> 00:12:27,680
um thank you everybody for

00:12:24,639 --> 00:12:31,600
uh for joining our panel here this is

00:12:27,680 --> 00:12:34,639
uh a great opportunity to bridge across

00:12:31,600 --> 00:12:36,560
uh the different aspects of uh of the

00:12:34,639 --> 00:12:39,680
opencapi ecosystem

00:12:36,560 --> 00:12:41,600
um we clearly need cards we need memory

00:12:39,680 --> 00:12:45,200
we need processors

00:12:41,600 --> 00:12:49,360
um but we also need applications and

00:12:45,200 --> 00:12:51,279
and so this is where maxellar comes in

00:12:49,360 --> 00:12:53,279
here at maxellar we've been developing

00:12:51,279 --> 00:12:58,079
applications for

00:12:53,279 --> 00:13:01,760
fpgas um for the last 17 years

00:12:58,079 --> 00:13:05,680
uh it all started with a dream

00:13:01,760 --> 00:13:07,519
at stanford where i thought well

00:13:05,680 --> 00:13:09,519
it looks like the transistors are going

00:13:07,519 --> 00:13:10,480
to shrink the wires are going to stay

00:13:09,519 --> 00:13:13,279
large

00:13:10,480 --> 00:13:15,760
so maybe we should focus on moving data

00:13:13,279 --> 00:13:18,480
or data movement optimization

00:13:15,760 --> 00:13:20,000
um as opposed to optimizing operations

00:13:18,480 --> 00:13:23,040
and optimizing arithmetic

00:13:20,000 --> 00:13:26,320
units inside of microprocessors

00:13:23,040 --> 00:13:27,040
um and so that that kind of drove my my

00:13:26,320 --> 00:13:29,279
whole

00:13:27,040 --> 00:13:31,279
development of a data-centric

00:13:29,279 --> 00:13:35,839
high-performance computing

00:13:31,279 --> 00:13:35,839
activity um

00:13:36,480 --> 00:13:41,760
starting in 2006 we deployed our first

00:13:39,760 --> 00:13:44,079
high performance computing application

00:13:41,760 --> 00:13:44,959
on fpgas this is now a very long time

00:13:44,079 --> 00:13:47,120
ago

00:13:44,959 --> 00:13:48,079
uh nobody could have imagined that one

00:13:47,120 --> 00:13:51,920
can run

00:13:48,079 --> 00:13:54,560
3d seismic imaging on on fpgas

00:13:51,920 --> 00:13:57,279
uh to manage circuits of that size to

00:13:54,560 --> 00:14:01,279
manage many different fpga cards

00:13:57,279 --> 00:14:05,120
in one rack uh we focused early on

00:14:01,279 --> 00:14:07,839
on deployment on deployment across

00:14:05,120 --> 00:14:10,480
iraq on deployment in production on

00:14:07,839 --> 00:14:14,240
numerical stability

00:14:10,480 --> 00:14:16,079
on convergence and

00:14:14,240 --> 00:14:17,839
all the other little problems that would

00:14:16,079 --> 00:14:20,800
arise when

00:14:17,839 --> 00:14:22,480
when we hit the fpgas one of the key

00:14:20,800 --> 00:14:25,440
problems that we had throughout

00:14:22,480 --> 00:14:27,279
all of this time is communication with

00:14:25,440 --> 00:14:28,399
memories and communication with the

00:14:27,279 --> 00:14:31,360
processor

00:14:28,399 --> 00:14:33,680
that was always too slow and so we've

00:14:31,360 --> 00:14:36,480
developed a latency

00:14:33,680 --> 00:14:38,000
and bandwidth to some extent tolerant

00:14:36,480 --> 00:14:40,880
architecture

00:14:38,000 --> 00:14:42,399
that would allow us to mitigate some of

00:14:40,880 --> 00:14:45,199
the

00:14:42,399 --> 00:14:45,920
log that that we had a backlog that we

00:14:45,199 --> 00:14:49,040
had

00:14:45,920 --> 00:14:49,920
compared to the competition um i don't

00:14:49,040 --> 00:14:51,600
know if it's

00:14:49,920 --> 00:14:53,519
if it's allowed to to mention the

00:14:51,600 --> 00:14:56,639
competition in this uh

00:14:53,519 --> 00:14:57,360
in this power but uh they uh they make

00:14:56,639 --> 00:14:59,760
these

00:14:57,360 --> 00:15:00,880
these cards with lots of little

00:14:59,760 --> 00:15:03,920
processors

00:15:00,880 --> 00:15:06,880
on them and uh they

00:15:03,920 --> 00:15:08,880
have their own memory they developed um

00:15:06,880 --> 00:15:10,399
and their own connection to that memory

00:15:08,880 --> 00:15:12,720
and that gave them a benefit over the

00:15:10,399 --> 00:15:14,639
last 10 to 15 years

00:15:12,720 --> 00:15:17,440
that was really very hard to compete

00:15:14,639 --> 00:15:19,760
with and so we had to build systems on

00:15:17,440 --> 00:15:22,480
the rack level and the box level too

00:15:19,760 --> 00:15:23,760
to have a chance against that today with

00:15:22,480 --> 00:15:25,760
open happy with

00:15:23,760 --> 00:15:28,240
with faster memories with faster

00:15:25,760 --> 00:15:31,360
connection to the processor

00:15:28,240 --> 00:15:33,600
we have a much easier time and all of

00:15:31,360 --> 00:15:36,800
these different activities

00:15:33,600 --> 00:15:40,399
not just for 3d imaging but also

00:15:36,800 --> 00:15:44,480
high performance computing in finance

00:15:40,399 --> 00:15:47,759
and in physics experiments

00:15:44,480 --> 00:15:49,759
in uh in many other domains will be able

00:15:47,759 --> 00:15:52,399
to benefit from this

00:15:49,759 --> 00:15:53,360
so it's really exciting to have an open

00:15:52,399 --> 00:15:56,560
cappy cable

00:15:53,360 --> 00:15:59,279
and open cappy memory um

00:15:56,560 --> 00:16:01,279
i wanted to put forward the the most

00:15:59,279 --> 00:16:04,560
exciting application that we have

00:16:01,279 --> 00:16:07,040
this is uh a quantum chromodynamics

00:16:04,560 --> 00:16:08,320
simulation which we managed to put onto

00:16:07,040 --> 00:16:11,600
an fpga

00:16:08,320 --> 00:16:14,000
in in many years of of effort

00:16:11,600 --> 00:16:15,360
and collaboration of course funded by

00:16:14,000 --> 00:16:20,079
the european union

00:16:15,360 --> 00:16:23,360
uh deployed in in germany in europe

00:16:20,079 --> 00:16:26,399
and putting the whole numerics and

00:16:23,360 --> 00:16:30,240
uh and acceleration

00:16:26,399 --> 00:16:34,560
and system versus card versus box

00:16:30,240 --> 00:16:36,720
uh trade-offs all into into one solution

00:16:34,560 --> 00:16:39,040
the one thing that we're limited on here

00:16:36,720 --> 00:16:41,279
is problem size

00:16:39,040 --> 00:16:43,120
so we can deal with a certain size of

00:16:41,279 --> 00:16:44,959
problem but that is not exciting enough

00:16:43,120 --> 00:16:46,079
for the physicists and that's where open

00:16:44,959 --> 00:16:48,000
copy comes in

00:16:46,079 --> 00:16:49,519
this is what it really will enable us to

00:16:48,000 --> 00:16:51,120
do instead of doing quantum

00:16:49,519 --> 00:16:54,240
chromodynamics on a small

00:16:51,120 --> 00:16:56,639
system on just a few particles

00:16:54,240 --> 00:16:58,880
we'll be able to do much larger particle

00:16:56,639 --> 00:17:02,240
systems because we can connect

00:16:58,880 --> 00:17:05,039
the different cards with a cable that is

00:17:02,240 --> 00:17:08,079
as fast as we're connecting to memory

00:17:05,039 --> 00:17:11,360
with a connection to the processor

00:17:08,079 --> 00:17:12,640
um as well as using uh power processors

00:17:11,360 --> 00:17:15,760
which of course will boost

00:17:12,640 --> 00:17:19,360
our our cpu site significantly

00:17:15,760 --> 00:17:22,720
so we are expecting a very significant

00:17:19,360 --> 00:17:25,839
benefit for many applications um

00:17:22,720 --> 00:17:27,280
i wanted to show two particular ones

00:17:25,839 --> 00:17:29,919
so one of them is the quantum

00:17:27,280 --> 00:17:32,400
chromodynamics that we've seen

00:17:29,919 --> 00:17:33,600
on the other slide here we are

00:17:32,400 --> 00:17:37,280
simulating

00:17:33,600 --> 00:17:40,559
particles in particular quarks and and

00:17:37,280 --> 00:17:41,679
the particles that that they uh create

00:17:40,559 --> 00:17:45,120
when they

00:17:41,679 --> 00:17:47,280
go together and that really drives

00:17:45,120 --> 00:17:49,600
our fundamental understanding of the

00:17:47,280 --> 00:17:53,280
universe it's a very fundamental

00:17:49,600 --> 00:17:54,960
application and also uh slightly on the

00:17:53,280 --> 00:17:56,720
complicated side if you

00:17:54,960 --> 00:17:58,320
if you think about the data structures

00:17:56,720 --> 00:18:01,120
we have to deal with here

00:17:58,320 --> 00:18:02,480
uh we're looking at five dimensional

00:18:01,120 --> 00:18:05,039
cubes

00:18:02,480 --> 00:18:06,080
that is really nasty once you put that

00:18:05,039 --> 00:18:08,000
onto a dram

00:18:06,080 --> 00:18:09,919
and you want to rotate it and you want

00:18:08,000 --> 00:18:11,200
to move it and you want to slice it in

00:18:09,919 --> 00:18:14,400
different ways

00:18:11,200 --> 00:18:16,720
uh you want to do uh various

00:18:14,400 --> 00:18:18,400
operators on on these kind of data

00:18:16,720 --> 00:18:20,320
structures

00:18:18,400 --> 00:18:22,640
and so it's all about the memory it's

00:18:20,320 --> 00:18:25,360
about the size of the memory system

00:18:22,640 --> 00:18:26,160
and the flexibility to configure it in

00:18:25,360 --> 00:18:27,679
the way

00:18:26,160 --> 00:18:30,240
that is most suitable for the

00:18:27,679 --> 00:18:31,840
application it's all nice and good to

00:18:30,240 --> 00:18:33,039
build large supercomputers with a

00:18:31,840 --> 00:18:35,520
hypercube

00:18:33,039 --> 00:18:37,200
but if you look at the actual

00:18:35,520 --> 00:18:39,200
application and you look at what it

00:18:37,200 --> 00:18:42,480
needs to be able to structure the

00:18:39,200 --> 00:18:44,640
interconnect of of your machine

00:18:42,480 --> 00:18:45,679
to what your application needs brings a

00:18:44,640 --> 00:18:49,200
huge amount

00:18:45,679 --> 00:18:52,400
of benefit being able to connect

00:18:49,200 --> 00:18:54,880
fpgas across iraq um

00:18:52,400 --> 00:18:56,080
brings tremendous benefit we've tried

00:18:54,880 --> 00:18:59,039
many things in the past

00:18:56,080 --> 00:19:00,320
we've built pci express networks uh

00:18:59,039 --> 00:19:03,840
we've built our own

00:19:00,320 --> 00:19:07,039
uh proprietary cables and and connectors

00:19:03,840 --> 00:19:10,720
to go from fpga to fpga

00:19:07,039 --> 00:19:14,320
all of these attempts are ultimately

00:19:10,720 --> 00:19:18,160
limited by volume that that

00:19:14,320 --> 00:19:18,559
hpc offers and uh by momentum that one

00:19:18,160 --> 00:19:21,200
can

00:19:18,559 --> 00:19:25,600
one can drive in one application so

00:19:21,200 --> 00:19:29,360
having an open source and

00:19:25,600 --> 00:19:30,080
and welcoming ecosystem that has many

00:19:29,360 --> 00:19:32,880
partners

00:19:30,080 --> 00:19:35,200
bringing their own expertise together of

00:19:32,880 --> 00:19:36,480
course we can't compete with a molex on

00:19:35,200 --> 00:19:39,760
connectors

00:19:36,480 --> 00:19:42,320
or cables and we cannot compete on on

00:19:39,760 --> 00:19:43,200
building microprocessors uh with you

00:19:42,320 --> 00:19:44,880
know

00:19:43,200 --> 00:19:46,640
probably the world's best team to do

00:19:44,880 --> 00:19:49,280
that at ibm

00:19:46,640 --> 00:19:50,840
um so being able to put all of these

00:19:49,280 --> 00:19:52,320
things together into the same

00:19:50,840 --> 00:19:54,720
environment is

00:19:52,320 --> 00:19:56,720
uh is really what what i believe is

00:19:54,720 --> 00:20:00,559
going to give us a chance for the next

00:19:56,720 --> 00:20:02,880
10x of performance

00:20:00,559 --> 00:20:03,600
for any kind of really data intensive

00:20:02,880 --> 00:20:05,679
application

00:20:03,600 --> 00:20:08,240
3d imaging for example is not just in

00:20:05,679 --> 00:20:11,600
oil and gas but also in medicine

00:20:08,240 --> 00:20:12,640
um in manufacturing in many other places

00:20:11,600 --> 00:20:14,320
where we need to look

00:20:12,640 --> 00:20:15,760
into three-dimensional structures

00:20:14,320 --> 00:20:18,640
understand what's going on

00:20:15,760 --> 00:20:19,280
inside of it and that's where we need

00:20:18,640 --> 00:20:22,559
this

00:20:19,280 --> 00:20:24,159
this super super high end computing so

00:20:22,559 --> 00:20:27,679
so here is the the baby that

00:20:24,159 --> 00:20:31,120
that we are trying to uh

00:20:27,679 --> 00:20:34,799
uh talk about here um we're trying to

00:20:31,120 --> 00:20:38,080
pitch the idea of a super high-end

00:20:34,799 --> 00:20:38,559
fpga card connected via pci express open

00:20:38,080 --> 00:20:42,080
cappy

00:20:38,559 --> 00:20:45,120
ethernet um many different connectors

00:20:42,080 --> 00:20:47,360
maxing out on d dimms putting as much

00:20:45,120 --> 00:20:51,039
memory as possible onto the cards

00:20:47,360 --> 00:20:54,000
building racks out of these with

00:20:51,039 --> 00:20:56,240
of course uh power processors on the

00:20:54,000 --> 00:20:59,679
other side i believe soon you'll have

00:20:56,240 --> 00:21:00,240
a power 10 to uh to use as an option

00:20:59,679 --> 00:21:02,159
here

00:21:00,240 --> 00:21:03,440
and so with power 10 on the one side

00:21:02,159 --> 00:21:06,880
open cappy

00:21:03,440 --> 00:21:10,320
and a really powerful ultra high-end

00:21:06,880 --> 00:21:12,080
fpga solution many of these applications

00:21:10,320 --> 00:21:15,919
in high performance computing

00:21:12,080 --> 00:21:18,159
that are really mission critical for

00:21:15,919 --> 00:21:19,440
keeping the world around and in a better

00:21:18,159 --> 00:21:22,559
shape

00:21:19,440 --> 00:21:24,080
would be really benefit from this um

00:21:22,559 --> 00:21:26,000
i didn't put it on the slide because

00:21:24,080 --> 00:21:28,400
this was kind of a last minute thing

00:21:26,000 --> 00:21:29,679
but the latest discussions we've had in

00:21:28,400 --> 00:21:31,840
california

00:21:29,679 --> 00:21:34,080
are about predicting fires predicting

00:21:31,840 --> 00:21:36,720
the spread of fires predicting the

00:21:34,080 --> 00:21:37,520
the risk of different areas of being hit

00:21:36,720 --> 00:21:40,880
by fires

00:21:37,520 --> 00:21:42,720
uh as as they go around uh so there's

00:21:40,880 --> 00:21:45,120
plenty of applications for

00:21:42,720 --> 00:21:46,159
ultra high-end computing that are really

00:21:45,120 --> 00:21:48,799
important

00:21:46,159 --> 00:21:50,880
i'm looking forward to any questions at

00:21:48,799 --> 00:21:54,159
the panel

00:21:50,880 --> 00:21:55,039
back to you ellen okay thank you very

00:21:54,159 --> 00:21:58,480
much oscar

00:21:55,039 --> 00:22:00,720
that's great all right everybody

00:21:58,480 --> 00:22:02,400
so um that's that's uh the two

00:22:00,720 --> 00:22:04,720
presentations that we've had to add to

00:22:02,400 --> 00:22:06,159
the track that you've hopefully all seen

00:22:04,720 --> 00:22:08,720
and my keynote at the beginning of the

00:22:06,159 --> 00:22:10,559
day uh please feel free to

00:22:08,720 --> 00:22:12,000
to put all your all your questions into

00:22:10,559 --> 00:22:15,280
the q a panel

00:22:12,000 --> 00:22:15,919
as i said earlier and um and i'll i'll

00:22:15,280 --> 00:22:17,520
go through

00:22:15,919 --> 00:22:19,200
through the questions and read them out

00:22:17,520 --> 00:22:22,080
to the panel and we can uh

00:22:19,200 --> 00:22:22,960
maybe get some discussion going on this

00:22:22,080 --> 00:22:26,159
um

00:22:22,960 --> 00:22:29,679
so um the the first

00:22:26,159 --> 00:22:32,960
question is uh from bruno mesnet

00:22:29,679 --> 00:22:35,200
what's next on power 10 for all fpga

00:22:32,960 --> 00:22:38,320
accelerators question marks

00:22:35,200 --> 00:22:39,440
will open cappy be supported on like on

00:22:38,320 --> 00:22:43,760
power9

00:22:39,440 --> 00:22:47,039
or just for storage class memory um

00:22:43,760 --> 00:22:49,280
i i i well actually maybe marcy or

00:22:47,039 --> 00:22:50,480
or or alexander would you with marcy

00:22:49,280 --> 00:22:53,120
would you like to give this one a ghost

00:22:50,480 --> 00:22:54,799
and you're the power 10 expert here

00:22:53,120 --> 00:22:56,720
sure i mean i could start and we can

00:22:54,799 --> 00:22:58,159
have others jump in um

00:22:56,720 --> 00:23:00,000
you know so open cappy right it

00:22:58,159 --> 00:23:03,200
continues to evolve onto power 10

00:23:00,000 --> 00:23:05,039
there's you know open cappy um 40150

00:23:03,200 --> 00:23:06,880
features that have been added

00:23:05,039 --> 00:23:08,880
things like memory inception are also in

00:23:06,880 --> 00:23:11,200
play there so we're definitely seeing

00:23:08,880 --> 00:23:12,240
that that space continues to evolve

00:23:11,200 --> 00:23:14,240
i think your question is probably a

00:23:12,240 --> 00:23:14,480
little bit more around system offerings

00:23:14,240 --> 00:23:16,159
and

00:23:14,480 --> 00:23:18,640
that's kind of a little outside of my

00:23:16,159 --> 00:23:20,320
expertise um

00:23:18,640 --> 00:23:21,840
i would assume it would follow a similar

00:23:20,320 --> 00:23:23,600
structure to power nine though where

00:23:21,840 --> 00:23:26,480
open cap is not going to be available

00:23:23,600 --> 00:23:26,880
in your first ga um and then would come

00:23:26,480 --> 00:23:28,799
on

00:23:26,880 --> 00:23:30,159
later in the ibm solutions it'd be it's

00:23:28,799 --> 00:23:32,000
interesting to see what will evolve in

00:23:30,159 --> 00:23:33,840
the open power space

00:23:32,000 --> 00:23:36,080
right in the system level my

00:23:33,840 --> 00:23:39,679
understanding is that there will be

00:23:36,080 --> 00:23:41,200
happy ports available but in terms of

00:23:39,679 --> 00:23:44,159
full enablement

00:23:41,200 --> 00:23:46,720
uh alexander do you know any any more

00:23:44,159 --> 00:23:46,720
details

00:23:47,840 --> 00:23:51,840
oh you're on me alexander

00:23:53,279 --> 00:23:57,440
i was saying no i i couldn't comment on

00:23:55,520 --> 00:24:00,480
that maybe brian could uh

00:23:57,440 --> 00:24:01,520
bring some uh ryan would you like to

00:24:00,480 --> 00:24:05,679
jump in

00:24:01,520 --> 00:24:08,799
your guest i'm sure can you hear me okay

00:24:05,679 --> 00:24:09,840
yeah yes we do okay well thank you for

00:24:08,799 --> 00:24:13,120
the question bruno

00:24:09,840 --> 00:24:16,159
that's a good leader um

00:24:13,120 --> 00:24:18,400
so for power 10 you know from what i'm

00:24:16,159 --> 00:24:21,520
kind of seeing

00:24:18,400 --> 00:24:24,720
scm is an interesting

00:24:21,520 --> 00:24:27,039
segment to go after just because from

00:24:24,720 --> 00:24:30,240
what i'm observing

00:24:27,039 --> 00:24:34,080
that appears to be the one part of

00:24:30,240 --> 00:24:35,440
acceleration that multiple

00:24:34,080 --> 00:24:37,679
what's called consortiums are

00:24:35,440 --> 00:24:40,400
gravitating to let's call it that

00:24:37,679 --> 00:24:42,720
it's one of the lowest hanging fruits

00:24:40,400 --> 00:24:45,360
that are out there

00:24:42,720 --> 00:24:46,240
you'll see cxl for instance i think

00:24:45,360 --> 00:24:48,799
their

00:24:46,240 --> 00:24:49,760
their first adopters will be folks that

00:24:48,799 --> 00:24:52,400
are gravitating

00:24:49,760 --> 00:24:53,200
gravitating towards scm we've got that

00:24:52,400 --> 00:24:56,320
today even

00:24:53,200 --> 00:24:58,240
on power nine with open cap em1

00:24:56,320 --> 00:24:59,360
and some of the presentations that were

00:24:58,240 --> 00:25:02,640
done this morning

00:24:59,360 --> 00:25:04,640
like what um christian was kind of

00:25:02,640 --> 00:25:06,720
showing with thymesis

00:25:04,640 --> 00:25:09,200
um and other folks right we've had some

00:25:06,720 --> 00:25:12,159
other engagements doing opencapi m1 so

00:25:09,200 --> 00:25:14,240
in my mind power 10 is going to uh you

00:25:12,159 --> 00:25:17,279
know scm will be a a

00:25:14,240 --> 00:25:17,679
definitely a a bogey where people are

00:25:17,279 --> 00:25:20,000
going to

00:25:17,679 --> 00:25:21,679
want to keep on doing accelerated

00:25:20,000 --> 00:25:23,600
development on

00:25:21,679 --> 00:25:25,039
um we'll also have what's called a

00:25:23,600 --> 00:25:26,960
forward migration path so the

00:25:25,039 --> 00:25:29,039
accelerators that we're developing

00:25:26,960 --> 00:25:30,159
on power 9 will forward migrate into

00:25:29,039 --> 00:25:32,000
power 10

00:25:30,159 --> 00:25:33,520
because that's basically an open cappy

00:25:32,000 --> 00:25:37,840
3.0 c1

00:25:33,520 --> 00:25:37,840
and m1 type environment

00:25:38,159 --> 00:25:45,279
we will also support the the opencapi

00:25:41,679 --> 00:25:48,480
4.0 constructs as well so atc

00:25:45,279 --> 00:25:52,720
and eac which allows you to do

00:25:48,480 --> 00:25:55,600
dma store ordering as well as

00:25:52,720 --> 00:25:56,640
like an effective address cache will be

00:25:55,600 --> 00:25:58,320
supported but

00:25:56,640 --> 00:26:00,080
you know we're not cli we're not seeing

00:25:58,320 --> 00:26:01,360
a lot of people talking about

00:26:00,080 --> 00:26:03,360
they really like the shared memory

00:26:01,360 --> 00:26:05,840
constructs let's call it that

00:26:03,360 --> 00:26:08,480
but the caching abilities i have not

00:26:05,840 --> 00:26:11,600
seen a lot of folks gravitating to that

00:26:08,480 --> 00:26:12,159
in open capping or anywhere else so to

00:26:11,600 --> 00:26:14,159
me

00:26:12,159 --> 00:26:15,840
those are nice features to have i think

00:26:14,159 --> 00:26:18,480
you need to have those

00:26:15,840 --> 00:26:18,880
as you move forward out in time but i

00:26:18,480 --> 00:26:21,279
think

00:26:18,880 --> 00:26:22,159
most of the folks are going to do kind

00:26:21,279 --> 00:26:26,320
of the strictly

00:26:22,159 --> 00:26:28,240
c1 m1 stuff um like we're doing today

00:26:26,320 --> 00:26:29,120
um so i think that's going to continue

00:26:28,240 --> 00:26:30,480
on in the future

00:26:29,120 --> 00:26:33,600
[Music]

00:26:30,480 --> 00:26:35,840
um we're still going to be good

00:26:33,600 --> 00:26:37,200
right now i was just going to say so um

00:26:35,840 --> 00:26:38,880
obviously the bit where a car is quite

00:26:37,200 --> 00:26:40,080
an interesting one it's a hybrid memory

00:26:38,880 --> 00:26:43,279
one with the

00:26:40,080 --> 00:26:45,840
low latency nand from samsung and yeah

00:26:43,279 --> 00:26:46,640
and lending the dram yeah that today

00:26:45,840 --> 00:26:49,200
obviously

00:26:46,640 --> 00:26:51,679
i i presume that that that's still the

00:26:49,200 --> 00:26:54,240
uh c1 interface for having an m1

00:26:51,679 --> 00:26:55,679
but potentially that's that's m1 that is

00:26:54,240 --> 00:26:58,799
m1 okay yeah hms

00:26:55,679 --> 00:27:00,400
m1 and potentially that um well one

00:26:58,799 --> 00:27:01,520
thing i would like to add on the power

00:27:00,400 --> 00:27:04,400
10 is

00:27:01,520 --> 00:27:05,200
is the power 10 really introduces the

00:27:04,400 --> 00:27:08,320
omi

00:27:05,200 --> 00:27:10,320
fully correct which is which is really

00:27:08,320 --> 00:27:11,600
this is in my mind that the big game

00:27:10,320 --> 00:27:14,320
change changer

00:27:11,600 --> 00:27:17,360
and omi is effectively a subset of the

00:27:14,320 --> 00:27:17,360
open cappy um

00:27:18,080 --> 00:27:23,600
protocols i guess and but 4.01 power 10

00:27:21,440 --> 00:27:24,480
is bringing those two back under the one

00:27:23,600 --> 00:27:27,520
open cappy

00:27:24,480 --> 00:27:28,159
roof right correct right yeah so if you

00:27:27,520 --> 00:27:29,840
look at the

00:27:28,159 --> 00:27:31,440
from an architecture perspective open

00:27:29,840 --> 00:27:34,159
cap i'm sorry power just

00:27:31,440 --> 00:27:34,960
power 10 supports 4.0 right which is

00:27:34,159 --> 00:27:36,960
inclusive of

00:27:34,960 --> 00:27:39,919
not only the 4.0 constructs but like you

00:27:36,960 --> 00:27:42,000
said 3.1 which is basically the omi

00:27:39,919 --> 00:27:43,919
and then you'll have microchips memory

00:27:42,000 --> 00:27:45,919
buffer implementation

00:27:43,919 --> 00:27:47,360
around power 10 right i mean that's one

00:27:45,919 --> 00:27:50,240
fundamental shift

00:27:47,360 --> 00:27:52,799
going from power 9 to power 10 is doing

00:27:50,240 --> 00:27:54,960
memory buffer redrive chips right with 5

00:27:52,799 --> 00:27:58,000
nanosecond type latency

00:27:54,960 --> 00:27:59,360
adders over just traditional direct

00:27:58,000 --> 00:28:01,600
connect drams

00:27:59,360 --> 00:28:03,200
but it'll also include the the ability

00:28:01,600 --> 00:28:05,279
to continue to support the 3.0

00:28:03,200 --> 00:28:08,240
accelerators that are being done today

00:28:05,279 --> 00:28:09,919
so so so from from my perspective the

00:28:08,240 --> 00:28:11,760
excitement there and it was in the power

00:28:09,919 --> 00:28:13,520
10 presentation at hop chips which is

00:28:11,760 --> 00:28:15,760
also given today i think

00:28:13,520 --> 00:28:17,520
um was obviously we're bringing the bit

00:28:15,760 --> 00:28:19,039
where card the storage class memory and

00:28:17,520 --> 00:28:21,039
and the 250 soc

00:28:19,039 --> 00:28:23,440
is is media devices we're bringing that

00:28:21,039 --> 00:28:26,240
in through the open capy 3.0

00:28:23,440 --> 00:28:26,799
uh interface today yeah clearly it could

00:28:26,240 --> 00:28:29,760
well be

00:28:26,799 --> 00:28:30,080
extremely applicable on the omi channel

00:28:29,760 --> 00:28:32,960
we

00:28:30,080 --> 00:28:34,559
we we can suddenly start to bring in um

00:28:32,960 --> 00:28:35,279
this storage class memory type so

00:28:34,559 --> 00:28:38,240
suddenly

00:28:35,279 --> 00:28:39,440
an omi d dim based on the microchip and

00:28:38,240 --> 00:28:42,640
ddr4

00:28:39,440 --> 00:28:44,399
can go up to about 128 gigabytes but

00:28:42,640 --> 00:28:46,320
uh we know we already see that the bit

00:28:44,399 --> 00:28:49,279
where card is three terabytes

00:28:46,320 --> 00:28:50,960
so suddenly you can bring like 48 or 96

00:28:49,279 --> 00:28:53,600
terabytes into it into one

00:28:50,960 --> 00:28:55,039
on power 10 with with that approach i

00:28:53,600 --> 00:28:56,399
guess we would need to upgrade the

00:28:55,039 --> 00:28:59,520
interface to be fully

00:28:56,399 --> 00:29:00,720
omi or football 4.0 compliant uh to

00:28:59,520 --> 00:29:02,720
bring that in

00:29:00,720 --> 00:29:06,000
but the other significant thing today

00:29:02,720 --> 00:29:08,480
with the with the omid dims

00:29:06,000 --> 00:29:10,640
is that they they we we've already got

00:29:08,480 --> 00:29:12,640
the rtl the imi billions were actually

00:29:10,640 --> 00:29:14,880
brought up on xilinx fpga so we've

00:29:12,640 --> 00:29:16,640
already got the host rtl it's in github

00:29:14,880 --> 00:29:19,360
it's ready for anybody to use

00:29:16,640 --> 00:29:21,679
and so you can actually if you know on a

00:29:19,360 --> 00:29:24,240
large xilinx fpga

00:29:21,679 --> 00:29:24,720
with 128 transceivers let's say you

00:29:24,240 --> 00:29:27,200
reserve

00:29:24,720 --> 00:29:29,200
16 for your host connection or your open

00:29:27,200 --> 00:29:30,559
cappy connection pci or whichever way

00:29:29,200 --> 00:29:35,360
you want to use

00:29:30,559 --> 00:29:38,480
um you you can bring in 14 omiddiums

00:29:35,360 --> 00:29:41,679
which gives you 800 gigabytes per second

00:29:38,480 --> 00:29:43,200
of peak bandwidth which is twice the hbm

00:29:41,679 --> 00:29:46,399
bandwidth on a

00:29:43,200 --> 00:29:49,679
on a zoning's fpga and

00:29:46,399 --> 00:29:50,799
it can go to 48 terabytes not 16 or 8

00:29:49,679 --> 00:29:54,320
gigabytes

00:29:50,799 --> 00:29:57,520
so i i think this combination of

00:29:54,320 --> 00:29:59,919
of depth with the bandwidth of hbm

00:29:57,520 --> 00:30:01,360
is really what makes that piece of the

00:29:59,919 --> 00:30:02,720
of it compelling

00:30:01,360 --> 00:30:06,240
and so we've been bringing it in through

00:30:02,720 --> 00:30:08,320
open cappy we're on a journey here

00:30:06,240 --> 00:30:09,360
and and and and that's the that's a good

00:30:08,320 --> 00:30:11,679
thing we're on a journey

00:30:09,360 --> 00:30:12,640
we've established open cappy we brought

00:30:11,679 --> 00:30:15,120
the omi

00:30:12,640 --> 00:30:16,799
it's all about latency latency latency

00:30:15,120 --> 00:30:19,039
number one is the latency which has

00:30:16,799 --> 00:30:20,880
always been the focus of cappy and so i

00:30:19,039 --> 00:30:22,080
think that that that's the interest in

00:30:20,880 --> 00:30:25,039
dynamic and i think power

00:30:22,080 --> 00:30:27,440
10 really does turn that on uh

00:30:25,039 --> 00:30:29,600
significantly as well

00:30:27,440 --> 00:30:32,080
morrissey you mentioned memory inception

00:30:29,600 --> 00:30:32,960
so if you guys have only followed this

00:30:32,080 --> 00:30:34,640
track

00:30:32,960 --> 00:30:36,000
you're probably wondering what morris is

00:30:34,640 --> 00:30:37,279
talking about so

00:30:36,000 --> 00:30:38,799
you heard hopefully you heard the

00:30:37,279 --> 00:30:41,279
firemeses flow apart you know

00:30:38,799 --> 00:30:44,399
disaggregating and borrowing memory

00:30:41,279 --> 00:30:46,159
um um maybe marcy you maybe you can give

00:30:44,399 --> 00:30:48,399
a few more words on

00:30:46,159 --> 00:30:50,080
on on memory inception versus versus

00:30:48,399 --> 00:30:52,159
fimesis what's going on there sure

00:30:50,080 --> 00:30:54,080
absolutely so thymesis flow is really a

00:30:52,159 --> 00:30:55,679
prototype right on the power nine

00:30:54,080 --> 00:30:57,360
that christian presented in the last

00:30:55,679 --> 00:30:59,360
session in this track

00:30:57,360 --> 00:31:01,440
and in at the same time right we've been

00:30:59,360 --> 00:31:02,559
developing power 10 in house

00:31:01,440 --> 00:31:03,919
and there what we're doing is we're

00:31:02,559 --> 00:31:05,360
really focused you know kind of the same

00:31:03,919 --> 00:31:06,799
the same thought process you've got low

00:31:05,360 --> 00:31:08,480
latency high bandwidth

00:31:06,799 --> 00:31:10,320
we're sucking a lot of the pieces into

00:31:08,480 --> 00:31:12,399
the processor on the dye themselves

00:31:10,320 --> 00:31:14,159
pulling a few tricks there so basically

00:31:12,399 --> 00:31:15,360
you're eliminating the two fpgas and the

00:31:14,159 --> 00:31:17,039
ethernet connection

00:31:15,360 --> 00:31:19,519
and you're cabling a processor to a

00:31:17,039 --> 00:31:21,360
processor where you're able to

00:31:19,519 --> 00:31:23,440
still steal that memory over from you

00:31:21,360 --> 00:31:25,200
know server b to over to server a

00:31:23,440 --> 00:31:27,600
hop into a window so there's still no

00:31:25,200 --> 00:31:30,159
application or os type

00:31:27,600 --> 00:31:32,000
requirements and you're able to use load

00:31:30,159 --> 00:31:33,200
source semantics to access it so that

00:31:32,000 --> 00:31:34,640
part stays the same

00:31:33,200 --> 00:31:36,720
but you're really getting you know

00:31:34,640 --> 00:31:38,640
orders of magnitude less latency

00:31:36,720 --> 00:31:40,799
higher bandwidth and you know we're

00:31:38,640 --> 00:31:42,480
thinking um

00:31:40,799 --> 00:31:44,960
you're in the range of you know 50 to

00:31:42,480 --> 00:31:46,480
100 nanoseconds of latency hit on a

00:31:44,960 --> 00:31:48,720
short cable reach there

00:31:46,480 --> 00:31:50,080
versus you know traditional rdma type

00:31:48,720 --> 00:31:53,200
methods to kind of get

00:31:50,080 --> 00:31:55,360
across notes so so

00:31:53,200 --> 00:31:57,279
we've got it with fimesis flow we've got

00:31:55,360 --> 00:31:57,760
it with memory inception which also

00:31:57,279 --> 00:32:00,640
works

00:31:57,760 --> 00:32:01,039
my understanding is over open capital iv

00:32:00,640 --> 00:32:03,039
um

00:32:01,039 --> 00:32:04,080
so it's not just reserved for the smp

00:32:03,039 --> 00:32:07,120
bus

00:32:04,080 --> 00:32:08,640
um so uh we have you know if you were

00:32:07,120 --> 00:32:10,320
building your own processor

00:32:08,640 --> 00:32:11,919
and and you wanted to to leverage

00:32:10,320 --> 00:32:13,519
opencapi in omi

00:32:11,919 --> 00:32:15,600
you you could potentially get this

00:32:13,519 --> 00:32:18,080
memory inception piece of it as well

00:32:15,600 --> 00:32:19,440
um that's all to do with open power and

00:32:18,080 --> 00:32:22,000
license in terms of so

00:32:19,440 --> 00:32:24,080
i'm open capping i don't know how much

00:32:22,000 --> 00:32:25,760
that will cost you for licensing um but

00:32:24,080 --> 00:32:28,720
on the basis power is fully open i'm

00:32:25,760 --> 00:32:30,159
hoping it is licensable um but we've got

00:32:28,720 --> 00:32:32,159
pharmesis flow which

00:32:30,159 --> 00:32:33,760
obviously works with the fpga is doing

00:32:32,159 --> 00:32:35,760
roughly the same thing

00:32:33,760 --> 00:32:37,519
and you can potentially add acceleration

00:32:35,760 --> 00:32:38,960
so you can add either just a memory node

00:32:37,519 --> 00:32:42,080
or a compute node

00:32:38,960 --> 00:32:43,039
where the processor can still see and

00:32:42,080 --> 00:32:45,120
access

00:32:43,039 --> 00:32:46,880
and borrow the memory of the accelerator

00:32:45,120 --> 00:32:48,640
as well so you're you begin to share

00:32:46,880 --> 00:32:49,120
memory much more effectively here which

00:32:48,640 --> 00:32:50,799
is

00:32:49,120 --> 00:32:52,320
which is really quite exciting so we

00:32:50,799 --> 00:32:55,279
really are looking at

00:32:52,320 --> 00:32:56,880
you know the memory is the center of the

00:32:55,279 --> 00:32:57,840
universe here this is a data centric

00:32:56,880 --> 00:32:59,919
system

00:32:57,840 --> 00:33:01,760
we're we've broken free of the cpu

00:32:59,919 --> 00:33:02,720
centric uh hybrid approaches i was

00:33:01,760 --> 00:33:05,360
saying in my

00:33:02,720 --> 00:33:05,919
in my in my keynote you know where we're

00:33:05,360 --> 00:33:08,159
we're really

00:33:05,919 --> 00:33:09,200
really focusing on on that data centric

00:33:08,159 --> 00:33:11,679
approach which is

00:33:09,200 --> 00:33:13,039
i think is an exciting piece of it

00:33:11,679 --> 00:33:13,440
there's another question out there for

00:33:13,039 --> 00:33:15,279
you

00:33:13,440 --> 00:33:17,120
alan that i think you should read from

00:33:15,279 --> 00:33:19,279
paul uh yeah the second part

00:33:17,120 --> 00:33:21,440
i understand that there will be no bare

00:33:19,279 --> 00:33:22,000
metal no no no no not from paul from

00:33:21,440 --> 00:33:25,760
paul

00:33:22,000 --> 00:33:28,640
oh right okay looking in the open

00:33:25,760 --> 00:33:31,279
yeah a lot of very interesting

00:33:28,640 --> 00:33:33,120
applications in research presented today

00:33:31,279 --> 00:33:35,279
a common theme is that open caption

00:33:33,120 --> 00:33:38,320
power allowed them to solve

00:33:35,279 --> 00:33:41,919
problems they could not solve before aka

00:33:38,320 --> 00:33:42,559
psi and phymesis how do your respective

00:33:41,919 --> 00:33:45,600
companies

00:33:42,559 --> 00:33:49,360
help open power slash open cappy

00:33:45,600 --> 00:33:52,480
grow the ecosystem so good question

00:33:49,360 --> 00:33:55,760
anybody like to take on that one oh i'm

00:33:52,480 --> 00:33:56,480
i'm happy to to start um that's all

00:33:55,760 --> 00:33:59,440
right alan

00:33:56,480 --> 00:34:01,840
yeah absolutely far away yeah so um

00:33:59,440 --> 00:34:03,760
since since this is mentioning uh

00:34:01,840 --> 00:34:06,720
the research problems and applications

00:34:03,760 --> 00:34:09,119
that are hard to solve um

00:34:06,720 --> 00:34:10,000
i think open cap is a game changer in

00:34:09,119 --> 00:34:12,079
terms of

00:34:10,000 --> 00:34:13,599
what it allows people on the software

00:34:12,079 --> 00:34:15,440
side to do

00:34:13,599 --> 00:34:17,679
and the types of problems that we'll be

00:34:15,440 --> 00:34:21,119
able to solve with it

00:34:17,679 --> 00:34:24,000
um from a how do we

00:34:21,119 --> 00:34:25,200
deliver that uh there are three

00:34:24,000 --> 00:34:27,599
components to this

00:34:25,200 --> 00:34:29,599
one is of course uh software that that

00:34:27,599 --> 00:34:32,320
could be available we can

00:34:29,599 --> 00:34:34,079
make available uh software in the open

00:34:32,320 --> 00:34:37,599
source realm of high performance

00:34:34,079 --> 00:34:40,240
computing or proprietary software

00:34:37,599 --> 00:34:41,919
um that can be made available at

00:34:40,240 --> 00:34:44,560
maxellar we've been

00:34:41,919 --> 00:34:45,599
porting high performance computing

00:34:44,560 --> 00:34:48,639
applications

00:34:45,599 --> 00:34:50,480
over two fpgas as a service

00:34:48,639 --> 00:34:52,320
and so we're offering that anybody who

00:34:50,480 --> 00:34:53,359
has a problem some application that they

00:34:52,320 --> 00:34:55,839
cannot run

00:34:53,359 --> 00:34:57,200
a problem that they cannot solve a

00:34:55,839 --> 00:35:00,160
problem that

00:34:57,200 --> 00:35:01,760
has no solution today they're very happy

00:35:00,160 --> 00:35:02,000
to take on the challenge and move that

00:35:01,760 --> 00:35:04,800
over

00:35:02,000 --> 00:35:05,520
to fpgas and show how to do that as

00:35:04,800 --> 00:35:08,160
we've done

00:35:05,520 --> 00:35:08,800
for jp morgan during the credit crisis

00:35:08,160 --> 00:35:10,800
where

00:35:08,800 --> 00:35:13,119
with all of the computers they were they

00:35:10,800 --> 00:35:16,000
were buying from from major vendors

00:35:13,119 --> 00:35:18,160
they could not calculate their risk and

00:35:16,000 --> 00:35:19,520
and so we build a specialized fpga

00:35:18,160 --> 00:35:22,560
machine for them

00:35:19,520 --> 00:35:25,280
to be doing that um

00:35:22,560 --> 00:35:27,040
that that's then uh helped them through

00:35:25,280 --> 00:35:28,640
through that credit crisis

00:35:27,040 --> 00:35:30,560
we did a similar thing for quantum

00:35:28,640 --> 00:35:33,440
chromodynamics where people are looking

00:35:30,560 --> 00:35:35,680
at larger and larger systems

00:35:33,440 --> 00:35:36,560
so it's all about the transformation and

00:35:35,680 --> 00:35:38,560
process

00:35:36,560 --> 00:35:40,400
and on the one side that can be a

00:35:38,560 --> 00:35:42,400
service on the other side

00:35:40,400 --> 00:35:43,440
there's an opportunity to build software

00:35:42,400 --> 00:35:45,119
libraries

00:35:43,440 --> 00:35:46,560
and so we have we have a large stack of

00:35:45,119 --> 00:35:49,359
components uh

00:35:46,560 --> 00:35:52,240
once we get our hands onto an actual uh

00:35:49,359 --> 00:35:55,440
open cappy system with an fpga on it

00:35:52,240 --> 00:35:58,560
um we'll be able to to create

00:35:55,440 --> 00:35:59,359
a layer of libraries that will allow

00:35:58,560 --> 00:36:03,200
anyone

00:35:59,359 --> 00:36:06,480
to take advantage of open cappy

00:36:03,200 --> 00:36:08,480
power on the hpc level on a floating

00:36:06,480 --> 00:36:10,960
point level on the numerix level

00:36:08,480 --> 00:36:13,119
on a multi-dimensional data set level so

00:36:10,960 --> 00:36:15,440
there's a software layer needed

00:36:13,119 --> 00:36:16,560
and and that's where uh maxellar is is

00:36:15,440 --> 00:36:19,040
focusing

00:36:16,560 --> 00:36:21,200
and uh of course somebody would have to

00:36:19,040 --> 00:36:24,320
build the cards and the hardware

00:36:21,200 --> 00:36:26,720
and and that's where we're looking to uh

00:36:24,320 --> 00:36:27,680
um companies like beatware and then

00:36:26,720 --> 00:36:31,280
molex and

00:36:27,680 --> 00:36:33,200
ibm to to provide uh their leadership on

00:36:31,280 --> 00:36:36,079
that front

00:36:33,200 --> 00:36:36,480
yeah an oscar that's um a good segue for

00:36:36,079 --> 00:36:39,040
me

00:36:36,480 --> 00:36:40,880
um so i think that the bets where in the

00:36:39,040 --> 00:36:43,280
molex value proposition is fairly

00:36:40,880 --> 00:36:45,040
straightforward but his oscar says in

00:36:43,280 --> 00:36:47,520
order to

00:36:45,040 --> 00:36:49,280
help people be very productive and

00:36:47,520 --> 00:36:52,720
successful at the application

00:36:49,280 --> 00:36:54,079
layer the hardware and the firmware

00:36:52,720 --> 00:36:56,720
and all that needs to be in place

00:36:54,079 --> 00:36:59,680
underneath to to make that happen

00:36:56,720 --> 00:37:00,480
and you know for many people open cappy

00:36:59,680 --> 00:37:02,720
and the other

00:37:00,480 --> 00:37:03,520
interconnects are all very new so

00:37:02,720 --> 00:37:06,480
they've probably

00:37:03,520 --> 00:37:08,320
heard of them read about them but they

00:37:06,480 --> 00:37:11,440
may not have had a chance to actually

00:37:08,320 --> 00:37:14,640
um experiment and benchmark with them

00:37:11,440 --> 00:37:16,640
so for us the way that i feel better

00:37:14,640 --> 00:37:18,000
helps contribute um to the growth of the

00:37:16,640 --> 00:37:21,119
ecosystem

00:37:18,000 --> 00:37:22,160
is we we're all about enablement at the

00:37:21,119 --> 00:37:25,599
hardware level

00:37:22,160 --> 00:37:27,760
so as marcy said before

00:37:25,599 --> 00:37:28,800
some of the functionality uh which is

00:37:27,760 --> 00:37:31,599
which is temporary

00:37:28,800 --> 00:37:32,240
within the fpga outside the cpu is then

00:37:31,599 --> 00:37:34,720
sucked into

00:37:32,240 --> 00:37:37,280
the power processor um there needs to be

00:37:34,720 --> 00:37:40,400
peripherals into the acceleration cards

00:37:37,280 --> 00:37:42,400
uh which attach into the system and you

00:37:40,400 --> 00:37:44,400
know these cards are

00:37:42,400 --> 00:37:46,400
pretty advanced we're really on the

00:37:44,400 --> 00:37:47,440
cutting edge of signal integrity and

00:37:46,400 --> 00:37:50,480
density

00:37:47,440 --> 00:37:52,240
um but we're also trying to make these

00:37:50,480 --> 00:37:56,079
hardware platforms available

00:37:52,240 --> 00:37:58,880
um at an enterprise class quality level

00:37:56,079 --> 00:38:00,720
where customers can confidently

00:37:58,880 --> 00:38:01,760
prototype and benchmark and then

00:38:00,720 --> 00:38:04,160
transition

00:38:01,760 --> 00:38:05,280
into deployment if they wish to deploy

00:38:04,160 --> 00:38:07,119
the combination of

00:38:05,280 --> 00:38:08,880
the processor and the card as a

00:38:07,119 --> 00:38:11,200
combination um

00:38:08,880 --> 00:38:12,160
so i think for us we're very much on the

00:38:11,200 --> 00:38:14,480
leading edge

00:38:12,160 --> 00:38:15,599
of these exciting changes and helping to

00:38:14,480 --> 00:38:18,640
enable the market

00:38:15,599 --> 00:38:20,160
and that's the way that that we feel

00:38:18,640 --> 00:38:23,440
that we can contribute

00:38:20,160 --> 00:38:25,040
um we also um uh we spoke about you know

00:38:23,440 --> 00:38:28,160
low hanging fruits

00:38:25,040 --> 00:38:29,760
out there um one thing which um

00:38:28,160 --> 00:38:31,440
which is just a rule in the world is

00:38:29,760 --> 00:38:32,880
that um you know

00:38:31,440 --> 00:38:34,960
different customers want different

00:38:32,880 --> 00:38:37,200
things right um

00:38:34,960 --> 00:38:38,400
the especially when it comes to fpga

00:38:37,200 --> 00:38:41,200
acceleration

00:38:38,400 --> 00:38:42,400
um often the the memory architecture the

00:38:41,200 --> 00:38:45,599
type of fpga

00:38:42,400 --> 00:38:46,560
the interconnect um those those can be

00:38:45,599 --> 00:38:48,640
customized

00:38:46,560 --> 00:38:50,320
at the hardware level and so one of the

00:38:48,640 --> 00:38:52,240
things we also do is um

00:38:50,320 --> 00:38:54,079
provide variants of our products which

00:38:52,240 --> 00:38:56,720
allow the acceleration part

00:38:54,079 --> 00:38:57,599
of the platform to be optimized for the

00:38:56,720 --> 00:39:00,800
specific

00:38:57,599 --> 00:39:03,839
application and that again uh enables

00:39:00,800 --> 00:39:05,760
new applications to be developed which

00:39:03,839 --> 00:39:07,200
you know uh not many people may have

00:39:05,760 --> 00:39:09,520
thought of until the use case

00:39:07,200 --> 00:39:10,320
emerged so that's how we feel we can

00:39:09,520 --> 00:39:11,599
contribute

00:39:10,320 --> 00:39:13,520
going forward and we've been able to

00:39:11,599 --> 00:39:14,800
help some of that over the last five or

00:39:13,520 --> 00:39:18,240
six years

00:39:14,800 --> 00:39:18,560
thanks frank alexander is um what's next

00:39:18,240 --> 00:39:21,599
for

00:39:18,560 --> 00:39:25,040
um ocxl are we are you gonna bring omi

00:39:21,599 --> 00:39:28,560
support and uh and bring finesses into

00:39:25,040 --> 00:39:31,040
directly into uh into the likes of ocxl

00:39:28,560 --> 00:39:32,400
or are there other advances in ocxl like

00:39:31,040 --> 00:39:35,760
supporting vitus

00:39:32,400 --> 00:39:38,320
for instance your english is too good

00:39:35,760 --> 00:39:39,119
i missed some of your keywords um well i

00:39:38,320 --> 00:39:41,920
i guess

00:39:39,119 --> 00:39:43,839
uh what's next for ocxl in terms of

00:39:41,920 --> 00:39:47,200
support on power 10

00:39:43,839 --> 00:39:48,720
bringing in maybe omi into fpga into the

00:39:47,200 --> 00:39:51,760
fpga

00:39:48,720 --> 00:39:54,320
into the ocxl framework um rather than

00:39:51,760 --> 00:39:56,960
just regular ddr4 dimms

00:39:54,320 --> 00:39:58,079
uh is there any or or support you you

00:39:56,960 --> 00:40:00,720
support hls

00:39:58,079 --> 00:40:02,000
tool flows in and obviously directly hlr

00:40:00,720 --> 00:40:03,680
hdl today

00:40:02,000 --> 00:40:05,839
i mean for me personally it'd be lovely

00:40:03,680 --> 00:40:06,560
to see max the max j component from max

00:40:05,839 --> 00:40:10,319
seller

00:40:06,560 --> 00:40:13,200
be uh compatible with your oc xl and

00:40:10,319 --> 00:40:13,520
um and and and but what about vitus you

00:40:13,200 --> 00:40:15,440
know

00:40:13,520 --> 00:40:17,920
xylinks have been doing a big push on

00:40:15,440 --> 00:40:18,800
vitus will will that simply drop in with

00:40:17,920 --> 00:40:20,720
ocxl

00:40:18,800 --> 00:40:23,359
uh what can what what can uh people

00:40:20,720 --> 00:40:25,520
expect from that

00:40:23,359 --> 00:40:27,599
well it really depends on the on the

00:40:25,520 --> 00:40:31,119
capacity we have to

00:40:27,599 --> 00:40:34,480
invest in uh developers

00:40:31,119 --> 00:40:37,040
because this system is um is a

00:40:34,480 --> 00:40:38,880
living system so everybody is welcome to

00:40:37,040 --> 00:40:41,280
to contribute of course

00:40:38,880 --> 00:40:42,960
and it will depend on the on the

00:40:41,280 --> 00:40:45,280
questions we will have on the

00:40:42,960 --> 00:40:46,960
interest that we will have and i'm

00:40:45,280 --> 00:40:49,520
pretty sure that

00:40:46,960 --> 00:40:50,839
a company will be willing to invest in

00:40:49,520 --> 00:40:54,240
any area

00:40:50,839 --> 00:40:57,599
where the the the

00:40:54,240 --> 00:41:00,160
the maturity of the uh

00:40:57,599 --> 00:41:01,200
what we call that proof of concept will

00:41:00,160 --> 00:41:04,880
be um

00:41:01,200 --> 00:41:06,880
anna will be great enough to justify

00:41:04,880 --> 00:41:09,359
that we invest in this uh in these

00:41:06,880 --> 00:41:09,359
developments

00:41:10,400 --> 00:41:13,599
ocxl is all all of it software and rtl

00:41:13,280 --> 00:41:15,760
is

00:41:13,599 --> 00:41:17,839
is uh open source on git github is that

00:41:15,760 --> 00:41:20,800
correct

00:41:17,839 --> 00:41:21,520
again your question is is ocxl uh the

00:41:20,800 --> 00:41:24,240
rtl

00:41:21,520 --> 00:41:25,839
and the software all open source and on

00:41:24,240 --> 00:41:27,040
github

00:41:25,839 --> 00:41:30,400
yeah the part of actually actually

00:41:27,040 --> 00:41:33,680
completely opened it's basically

00:41:30,400 --> 00:41:37,359
architectured around the dialings

00:41:33,680 --> 00:41:40,480
vivado tool so it's pretty uh easy to

00:41:37,359 --> 00:41:40,880
go inside and adjust or modify so people

00:41:40,480 --> 00:41:42,720
could

00:41:40,880 --> 00:41:44,560
could modify and contribute themselves

00:41:42,720 --> 00:41:45,440
as well as sure and they are more than

00:41:44,560 --> 00:41:48,319
welcome to do it

00:41:45,440 --> 00:41:49,920
this is the goal of this framework is

00:41:48,319 --> 00:41:52,880
that people can

00:41:49,920 --> 00:41:54,960
go inside the scripts and they can

00:41:52,880 --> 00:41:58,000
propose any modification

00:41:54,960 --> 00:41:58,720
we are used to work with branches so for

00:41:58,000 --> 00:42:01,760
example

00:41:58,720 --> 00:42:05,280
psi has a nicely um

00:42:01,760 --> 00:42:08,319
offered the the way to use udp packets

00:42:05,280 --> 00:42:08,800
we did not work tightly on that and all

00:42:08,319 --> 00:42:11,760
the

00:42:08,800 --> 00:42:12,960
all the ethernet udp connection has been

00:42:11,760 --> 00:42:15,760
uh contributed by

00:42:12,960 --> 00:42:17,280
psi uh in the github so this is an

00:42:15,760 --> 00:42:20,160
example good example that

00:42:17,280 --> 00:42:22,000
shows that everybody can make this tool

00:42:20,160 --> 00:42:24,160
much better than it is today

00:42:22,000 --> 00:42:25,040
and uh i think it's very nice to have a

00:42:24,160 --> 00:42:27,359
company that is

00:42:25,040 --> 00:42:29,440
hosting the the responsibility of

00:42:27,359 --> 00:42:32,400
checking that everything is um

00:42:29,440 --> 00:42:33,520
is a fair and it's uh under control so

00:42:32,400 --> 00:42:36,480
there is a

00:42:33,520 --> 00:42:37,200
tracking of any branch but it's very

00:42:36,480 --> 00:42:39,680
open and

00:42:37,200 --> 00:42:41,440
contributional well are welcome for sure

00:42:39,680 --> 00:42:45,839
okay thanks oscar i think you were going

00:42:41,440 --> 00:42:45,839
to jump in there

00:42:46,000 --> 00:42:53,599
yeah no i was uh i was just curious

00:42:50,000 --> 00:42:58,079
more about the the oc excel

00:42:53,599 --> 00:43:01,920
direction and uh maybe um

00:42:58,079 --> 00:43:05,200
how it connects to to opencap the omi

00:43:01,920 --> 00:43:08,000
and uh and the hls that

00:43:05,200 --> 00:43:09,839
uh that we're driving of course on on

00:43:08,000 --> 00:43:10,560
our side how one could combine that so

00:43:09,839 --> 00:43:12,319
maybe

00:43:10,560 --> 00:43:14,319
maybe a few more words on that would be

00:43:12,319 --> 00:43:14,720
great ellen you you kicked off something

00:43:14,319 --> 00:43:18,079
there

00:43:14,720 --> 00:43:21,119
so would be great alexander

00:43:18,079 --> 00:43:23,359
more about that yeah alexander gave a

00:43:21,119 --> 00:43:24,960
good answer there but yeah i i i

00:43:23,359 --> 00:43:26,280
certainly support the idea it'll be

00:43:24,960 --> 00:43:29,599
wonderful to bring

00:43:26,280 --> 00:43:32,960
omiddims into the ocxl framework

00:43:29,599 --> 00:43:34,800
um uh i i think uh one of the points in

00:43:32,960 --> 00:43:37,680
fact there's a question that came up on

00:43:34,800 --> 00:43:39,200
on the omid is in terms of people that

00:43:37,680 --> 00:43:40,000
have already got applications on the

00:43:39,200 --> 00:43:42,240
fpgas

00:43:40,000 --> 00:43:43,440
it was asking uh you know if they've

00:43:42,240 --> 00:43:46,560
already got an application

00:43:43,440 --> 00:43:48,480
with ddr4 dimms attached

00:43:46,560 --> 00:43:51,119
and they could come across a card which

00:43:48,480 --> 00:43:52,960
has ome dims and more enemy bandwidth

00:43:51,119 --> 00:43:54,400
could they drop their application easily

00:43:52,960 --> 00:43:57,359
into the card

00:43:54,400 --> 00:43:58,160
and into the new card and how much work

00:43:57,359 --> 00:44:01,680
would it be

00:43:58,160 --> 00:44:02,960
so obviously if if um if if ocxl had

00:44:01,680 --> 00:44:03,920
that then that would be an interesting

00:44:02,960 --> 00:44:06,240
one but

00:44:03,920 --> 00:44:08,160
one thing that i've uh been talking

00:44:06,240 --> 00:44:10,960
about with my responsibility as the

00:44:08,160 --> 00:44:13,119
open capital technical director is is

00:44:10,960 --> 00:44:17,200
they they already have ac interfaces

00:44:13,119 --> 00:44:19,599
on the omi uh host for the fpga the rtl

00:44:17,200 --> 00:44:23,200
but it's not directly compatible ddr4 so

00:44:19,599 --> 00:44:25,599
it'd be nice to get a shim that

00:44:23,200 --> 00:44:27,920
somebody with a uh an application could

00:44:25,599 --> 00:44:30,319
literally drop it in with the ohmi

00:44:27,920 --> 00:44:31,599
uh shim to a ddr4 interface and then

00:44:30,319 --> 00:44:33,520
just recompile and

00:44:31,599 --> 00:44:35,119
and away you go i think that's a that

00:44:33,520 --> 00:44:37,680
would be i mean

00:44:35,119 --> 00:44:39,920
that's certainly something that that we

00:44:37,680 --> 00:44:41,839
could do here at maxellar our interfaces

00:44:39,920 --> 00:44:44,960
are all axi compliant

00:44:41,839 --> 00:44:46,319
um as well as uh ddr we have a ddr

00:44:44,960 --> 00:44:49,280
memory controller

00:44:46,319 --> 00:44:50,560
that could very easily be modified to

00:44:49,280 --> 00:44:53,599
provide that

00:44:50,560 --> 00:44:55,040
achievement that that connection there's

00:44:53,599 --> 00:44:56,640
little effort for us

00:44:55,040 --> 00:44:58,319
and i would make it easy for everybody

00:44:56,640 --> 00:44:59,200
that's already got working applications

00:44:58,319 --> 00:45:02,400
to play with a

00:44:59,200 --> 00:45:04,560
a card with new mi channels i've got a

00:45:02,400 --> 00:45:05,760
few questions rolling in here so let me

00:45:04,560 --> 00:45:08,720
just read them

00:45:05,760 --> 00:45:10,960
um polar coats asked oscar mentioned

00:45:08,720 --> 00:45:12,000
access to hardware as a potential

00:45:10,960 --> 00:45:14,240
roadblock

00:45:12,000 --> 00:45:17,200
and craig mentioned the complexity

00:45:14,240 --> 00:45:19,920
equals cost in brackets of the hardware

00:45:17,200 --> 00:45:21,440
how do we solve both of these divergent

00:45:19,920 --> 00:45:24,640
problems

00:45:21,440 --> 00:45:24,640
i guess that's oscar and craig

00:45:28,160 --> 00:45:32,160
on the access to hardware uh what i

00:45:30,240 --> 00:45:35,599
meant is that we don't have

00:45:32,160 --> 00:45:38,880
a card with a large fpga

00:45:35,599 --> 00:45:39,520
omi channels and and 10d dimms connected

00:45:38,880 --> 00:45:41,520
to it

00:45:39,520 --> 00:45:44,079
we could have it the technology would

00:45:41,520 --> 00:45:46,880
support an amazing solution here

00:45:44,079 --> 00:45:49,040
but uh we don't have it right now so so

00:45:46,880 --> 00:45:52,079
i think it's a race against the clock to

00:45:49,040 --> 00:45:55,200
to start uh entering the field and

00:45:52,079 --> 00:45:58,000
delivering systems with this technology

00:45:55,200 --> 00:45:58,400
to get the card like this up and running

00:45:58,000 --> 00:46:01,839
and

00:45:58,400 --> 00:46:02,480
uh evan and i we've been uh uh back and

00:46:01,839 --> 00:46:05,200
forth

00:46:02,480 --> 00:46:06,960
on uh the design of such a card and how

00:46:05,200 --> 00:46:09,920
quickly we could make one

00:46:06,960 --> 00:46:10,560
so so i think uh this is well underway

00:46:09,920 --> 00:46:13,040
uh

00:46:10,560 --> 00:46:14,960
but uh the sooner the better on on

00:46:13,040 --> 00:46:17,440
getting an omi memory card

00:46:14,960 --> 00:46:19,280
i think that's uh that would be my my

00:46:17,440 --> 00:46:21,920
answer to this

00:46:19,280 --> 00:46:23,680
um i guess an easy way would be for the

00:46:21,920 --> 00:46:25,359
chip suppliers to load their prices that

00:46:23,680 --> 00:46:28,400
would be an easy way to

00:46:25,359 --> 00:46:29,599
create and bigger hardware but and in

00:46:28,400 --> 00:46:32,800
the absence of that

00:46:29,599 --> 00:46:33,920
um i think to be honest the one of the

00:46:32,800 --> 00:46:37,839
things i'd like to see is a

00:46:33,920 --> 00:46:40,800
tipping point in the market whereby um

00:46:37,839 --> 00:46:43,119
as a hardware you know supplier it's

00:46:40,800 --> 00:46:44,160
it's expensive for us to invest in new

00:46:43,119 --> 00:46:46,640
technologies

00:46:44,160 --> 00:46:47,440
if there's a possibility that they won't

00:46:46,640 --> 00:46:48,960
take off

00:46:47,440 --> 00:46:51,440
and there's going to be remain a very

00:46:48,960 --> 00:46:53,839
small user base for that technology

00:46:51,440 --> 00:46:55,680
because there's less customers that we

00:46:53,839 --> 00:46:58,880
can advertise the investment

00:46:55,680 --> 00:47:00,160
cost for that product across um

00:46:58,880 --> 00:47:02,079
so one of the things i think would be

00:47:00,160 --> 00:47:05,280
great is if um you know

00:47:02,079 --> 00:47:07,520
coping cappy really um hits its stride

00:47:05,280 --> 00:47:08,480
uh solves a number of important use

00:47:07,520 --> 00:47:11,359
cases in the market

00:47:08,480 --> 00:47:12,240
and in the market and user base grows

00:47:11,359 --> 00:47:15,520
then

00:47:12,240 --> 00:47:18,720
companies like betsware we can invest

00:47:15,520 --> 00:47:21,040
in new hardware capabilities um uh

00:47:18,720 --> 00:47:22,480
more confidently uh knowing that we're

00:47:21,040 --> 00:47:23,040
going to get more of a return across a

00:47:22,480 --> 00:47:25,520
larger

00:47:23,040 --> 00:47:26,240
customer base and so that's a win-win

00:47:25,520 --> 00:47:28,319
for everybody

00:47:26,240 --> 00:47:29,920
we can advertise our costs we can get

00:47:28,319 --> 00:47:30,880
economies of scale as we build more

00:47:29,920 --> 00:47:32,880
hardware

00:47:30,880 --> 00:47:34,000
and those savings can be passed on to

00:47:32,880 --> 00:47:37,040
customers as well

00:47:34,000 --> 00:47:38,240
uh toward the unit price and of the

00:47:37,040 --> 00:47:41,359
hardware they're buying

00:47:38,240 --> 00:47:41,680
so i think success beats success and i

00:47:41,359 --> 00:47:44,960
think

00:47:41,680 --> 00:47:47,040
um if opencapi can continue to

00:47:44,960 --> 00:47:48,559
demonstrate the benefits then the

00:47:47,040 --> 00:47:50,880
traction will happen

00:47:48,559 --> 00:47:51,680
and the the cost reduction will take

00:47:50,880 --> 00:47:53,839
place as

00:47:51,680 --> 00:47:55,280
an actual function of the market

00:47:53,839 --> 00:47:58,640
economics so

00:47:55,280 --> 00:48:00,960
that that's how it should play out um

00:47:58,640 --> 00:48:02,480
but i think is you know people involved

00:48:00,960 --> 00:48:04,319
in open capital we're all willing to

00:48:02,480 --> 00:48:06,720
invest a degree

00:48:04,319 --> 00:48:07,599
just to overcome that initial inertia

00:48:06,720 --> 00:48:10,319
and uh

00:48:07,599 --> 00:48:11,920
help people see the benefits so i think

00:48:10,319 --> 00:48:14,480
it'll take time but i think um

00:48:11,920 --> 00:48:16,960
that success is certainly one path to

00:48:14,480 --> 00:48:18,960
reducing costs for everybody

00:48:16,960 --> 00:48:21,040
thanks craig bryan did you want to jump

00:48:18,960 --> 00:48:21,920
in i see and give a live contribution on

00:48:21,040 --> 00:48:24,880
this one

00:48:21,920 --> 00:48:24,880
or do you think it's covered

00:48:25,280 --> 00:48:29,040
well i think that was okay that was good

00:48:27,200 --> 00:48:30,319
i mean i think um i answered a couple of

00:48:29,040 --> 00:48:32,160
them

00:48:30,319 --> 00:48:33,599
publicly already but then paul has

00:48:32,160 --> 00:48:36,880
another one

00:48:33,599 --> 00:48:40,640
yeah um oh so second one i'll jump

00:48:36,880 --> 00:48:41,760
oh the first one you you did you just

00:48:40,640 --> 00:48:44,720
did the first one he

00:48:41,760 --> 00:48:46,400
but this is the next one yeah yeah um if

00:48:44,720 --> 00:48:48,000
you can click done on that first one the

00:48:46,400 --> 00:48:51,599
next one is any option for

00:48:48,000 --> 00:48:53,839
partnerships between cloud providers

00:48:51,599 --> 00:48:55,760
uh and hardware providers to provide

00:48:53,839 --> 00:48:58,079
inexpensive cloud access

00:48:55,760 --> 00:48:59,760
cloud access to potential developers

00:48:58,079 --> 00:49:02,400
this amortizes the cost

00:48:59,760 --> 00:49:02,960
that the cost across multiple users and

00:49:02,400 --> 00:49:05,280
multiple

00:49:02,960 --> 00:49:06,880
providers i think i've put that one

00:49:05,280 --> 00:49:09,920
straight in my lap but i'll let every

00:49:06,880 --> 00:49:11,280
skip in here first

00:49:09,920 --> 00:49:13,200
i think that was targeted towards you

00:49:11,280 --> 00:49:15,119
ellen

00:49:13,200 --> 00:49:16,559
no but go on anyone else want to make a

00:49:15,119 --> 00:49:18,720
comment on that

00:49:16,559 --> 00:49:21,839
um so working with cloud providers in

00:49:18,720 --> 00:49:24,880
the likes craig or anyone else

00:49:21,839 --> 00:49:29,680
um yeah i think we're we're always open

00:49:24,880 --> 00:49:31,680
to that and i think uh i can on demand

00:49:29,680 --> 00:49:33,200
that type of model is what customers

00:49:31,680 --> 00:49:34,960
expect these days they don't always

00:49:33,200 --> 00:49:35,920
expect to have to invest in on-premise

00:49:34,960 --> 00:49:38,480
hardware

00:49:35,920 --> 00:49:39,200
um unless there's good reason to do so

00:49:38,480 --> 00:49:41,200
so

00:49:39,200 --> 00:49:42,800
making the technology available like you

00:49:41,200 --> 00:49:44,000
have in cloud services which are

00:49:42,800 --> 00:49:46,960
becoming more sophisticated

00:49:44,000 --> 00:49:48,480
is definitely the way to go um so yeah

00:49:46,960 --> 00:49:49,920
absolutely an advocate for that and i

00:49:48,480 --> 00:49:50,640
think that goes back to what i said

00:49:49,920 --> 00:49:53,359
about

00:49:50,640 --> 00:49:55,040
trying to reach success here so that

00:49:53,359 --> 00:49:56,640
there's a larger ecosystem and more

00:49:55,040 --> 00:49:57,440
opportunities for all the players in the

00:49:56,640 --> 00:49:59,839
market

00:49:57,440 --> 00:50:00,880
so we're certainly um proponents of that

00:49:59,839 --> 00:50:04,160
i certainly

00:50:00,880 --> 00:50:06,319
agree with that the the the the the big

00:50:04,160 --> 00:50:07,280
issue that or one of the challenges

00:50:06,319 --> 00:50:11,359
we've seen is

00:50:07,280 --> 00:50:14,640
um uh uh is is

00:50:11,359 --> 00:50:15,839
um there's it's always uh we've got all

00:50:14,640 --> 00:50:18,319
these different open

00:50:15,839 --> 00:50:20,240
bodies and everybody's doing their own

00:50:18,319 --> 00:50:22,160
open thing but open hardware is open

00:50:20,240 --> 00:50:24,480
hardware once it's open

00:50:22,160 --> 00:50:25,440
do we need separate ones is my opinion

00:50:24,480 --> 00:50:28,079
and so

00:50:25,440 --> 00:50:28,559
one of one of the ones that has really

00:50:28,079 --> 00:50:31,040
uh

00:50:28,559 --> 00:50:33,359
really got some traction is ocp the open

00:50:31,040 --> 00:50:35,839
compute project and there's a lot of

00:50:33,359 --> 00:50:36,559
um odms are involved building real

00:50:35,839 --> 00:50:38,160
hardware

00:50:36,559 --> 00:50:40,319
scaling up for the for the cloud

00:50:38,160 --> 00:50:43,440
providers and the hyperscalers

00:50:40,319 --> 00:50:45,760
and um they're they're donating you know

00:50:43,440 --> 00:50:48,960
all of the hardware from the bmc

00:50:45,760 --> 00:50:51,040
to accelerator modules to infrastructure

00:50:48,960 --> 00:50:52,960
chassis for these accelerators

00:50:51,040 --> 00:50:54,880
all of these pieces are coming to play

00:50:52,960 --> 00:50:58,240
coming into play here

00:50:54,880 --> 00:51:00,079
and um but but typically what's going on

00:50:58,240 --> 00:51:02,079
right now in the ocp world is

00:51:00,079 --> 00:51:04,160
everything's pci connected

00:51:02,079 --> 00:51:05,280
and but we need to move towards these

00:51:04,160 --> 00:51:08,559
these um

00:51:05,280 --> 00:51:10,240
uh coherently connected buses these more

00:51:08,559 --> 00:51:12,000
memory centric buses that we

00:51:10,240 --> 00:51:13,599
they were seeing and so therefore

00:51:12,000 --> 00:51:16,000
they've got some idiosyncrasies they

00:51:13,599 --> 00:51:18,319
can't work for a pci switch

00:51:16,000 --> 00:51:20,079
so so effectively we we could do with

00:51:18,319 --> 00:51:20,400
some optimization so i think we could

00:51:20,079 --> 00:51:22,319
both

00:51:20,400 --> 00:51:23,680
leverage all the excellent work that's

00:51:22,319 --> 00:51:26,160
going on in ocp

00:51:23,680 --> 00:51:27,760
and not reinvent the wheel ourselves and

00:51:26,160 --> 00:51:31,359
just do some incremental

00:51:27,760 --> 00:51:33,520
adders to that now that is very

00:51:31,359 --> 00:51:36,559
likely very more tailored towards the

00:51:33,520 --> 00:51:36,559
cloud providers and

00:51:38,160 --> 00:51:42,000
some other pure aspects that you may

00:51:40,000 --> 00:51:44,480
want from a platform

00:51:42,000 --> 00:51:45,680
like sheer performance per per cubic per

00:51:44,480 --> 00:51:48,800
cubic inch

00:51:45,680 --> 00:51:50,800
but um but that may actually get us

00:51:48,800 --> 00:51:52,319
nicely to if we if we could get some

00:51:50,800 --> 00:51:54,319
hyperscaler adoption

00:51:52,319 --> 00:51:55,920
that can give us some scale that can get

00:51:54,319 --> 00:51:58,640
the cost down as you say

00:51:55,920 --> 00:52:00,640
there craig and allowed us allow us to

00:51:58,640 --> 00:52:04,000
to be successful so i think

00:52:00,640 --> 00:52:06,720
um i'm certainly trying

00:52:04,000 --> 00:52:09,599
to to build more bridges between open

00:52:06,720 --> 00:52:11,280
cappy and ocp and open power and ocp

00:52:09,599 --> 00:52:13,359
so that we can really get some more

00:52:11,280 --> 00:52:14,319
momentum in all the really truly open

00:52:13,359 --> 00:52:16,480
stuff

00:52:14,319 --> 00:52:20,160
uh and and and i think i think that's a

00:52:16,480 --> 00:52:23,280
key a key way to go forward

00:52:20,160 --> 00:52:23,839
maybe could i just ask a question as

00:52:23,280 --> 00:52:26,800
well

00:52:23,839 --> 00:52:27,599
absolutely i was wondering how much

00:52:26,800 --> 00:52:31,839
support

00:52:27,599 --> 00:52:34,880
and an interaction opencapi has

00:52:31,839 --> 00:52:37,920
from ibm cloud the the kind of

00:52:34,880 --> 00:52:40,960
primary driver of of ibm in

00:52:37,920 --> 00:52:44,800
in the future um is there any

00:52:40,960 --> 00:52:47,520
anything that that can be said about

00:52:44,800 --> 00:52:50,319
open cap availability in the cloud power

00:52:47,520 --> 00:52:52,160
10 availability in the cloud

00:52:50,319 --> 00:52:54,160
and support for all of these standard

00:52:52,160 --> 00:52:55,440
and interconnections because if that was

00:52:54,160 --> 00:52:57,680
just available

00:52:55,440 --> 00:52:59,839
on there that would clearly be a game

00:52:57,680 --> 00:53:01,599
changer for

00:52:59,839 --> 00:53:03,440
alexander i think you maybe have to

00:53:01,599 --> 00:53:06,400
answer that with the

00:53:03,440 --> 00:53:07,359
the ocxl you can dial into machines and

00:53:06,400 --> 00:53:09,839
there's some

00:53:07,359 --> 00:53:11,680
are you familiar with um what's

00:53:09,839 --> 00:53:13,920
available there or

00:53:11,680 --> 00:53:15,040
i would suspect brian would be more

00:53:13,920 --> 00:53:18,800
inclined to

00:53:15,040 --> 00:53:21,920
address this question would you brian um

00:53:18,800 --> 00:53:25,040
sure so and that's a good point uh

00:53:21,920 --> 00:53:28,880
oscar and one of the things that

00:53:25,040 --> 00:53:31,119
um like james and mendy

00:53:28,880 --> 00:53:33,119
and toshon are talking about and i think

00:53:31,119 --> 00:53:37,119
they actually have a talk

00:53:33,119 --> 00:53:39,119
um at 2 5 about power your cloud so

00:53:37,119 --> 00:53:40,240
i think toshon might broach some of this

00:53:39,119 --> 00:53:43,599
stuff

00:53:40,240 --> 00:53:45,599
um as well but you know

00:53:43,599 --> 00:53:47,839
open power definitely has a let's call

00:53:45,599 --> 00:53:49,760
it a vested interest

00:53:47,839 --> 00:53:51,680
and making the accelerability

00:53:49,760 --> 00:53:55,280
accessibility of

00:53:51,680 --> 00:53:56,480
power machines you know let's call it a

00:53:55,280 --> 00:53:58,640
lower barrier

00:53:56,480 --> 00:54:02,079
right and in my mind that's inclusive of

00:53:58,640 --> 00:54:05,200
the ac 922s and the ic922s

00:54:02,079 --> 00:54:08,640
and having fpga cards

00:54:05,200 --> 00:54:11,119
be part of hosting those platforms

00:54:08,640 --> 00:54:12,960
um you know the underpinning with that

00:54:11,119 --> 00:54:16,000
would be ocxl

00:54:12,960 --> 00:54:17,920
right as the fpga programming frameworks

00:54:16,000 --> 00:54:21,359
and so i i can't really you know

00:54:17,920 --> 00:54:24,800
disclose anything publicly but i know

00:54:21,359 --> 00:54:25,280
the the overarching mission of open

00:54:24,800 --> 00:54:28,640
power

00:54:25,280 --> 00:54:31,920
is to get a development cloud

00:54:28,640 --> 00:54:35,119
put in play so you know kind of stay

00:54:31,920 --> 00:54:37,040
tuned um with respect to that but we're

00:54:35,119 --> 00:54:40,160
kind of on the same page as you ask her

00:54:37,040 --> 00:54:41,920
is of what of where it needs to go

00:54:40,160 --> 00:54:44,000
because the accessibility needs to be

00:54:41,920 --> 00:54:48,160
there

00:54:44,000 --> 00:54:51,280
that make sense yeah yeah that's great

00:54:48,160 --> 00:54:53,520
okay now unmuted

00:54:51,280 --> 00:54:54,960
the the the one other thing just to

00:54:53,520 --> 00:54:56,880
mention just came to mind

00:54:54,960 --> 00:54:58,880
on on the imi and accessibility of

00:54:56,880 --> 00:55:01,920
hardware with fpgas

00:54:58,880 --> 00:55:04,720
so there there is um

00:55:01,920 --> 00:55:06,480
an fpga platform internally codenamed

00:55:04,720 --> 00:55:09,040
firing ice

00:55:06,480 --> 00:55:11,440
that is um there basically is a host

00:55:09,040 --> 00:55:12,240
platform with up to four imid dimms on

00:55:11,440 --> 00:55:15,599
it

00:55:12,240 --> 00:55:16,880
and there's even a d dim with an fpga on

00:55:15,599 --> 00:55:18,960
so you could build your own memory

00:55:16,880 --> 00:55:20,720
buffers if you were if you're interested

00:55:18,960 --> 00:55:22,880
in doing that um

00:55:20,720 --> 00:55:24,000
so it's it's it's both a testing

00:55:22,880 --> 00:55:25,760
platform uh

00:55:24,000 --> 00:55:27,680
you know uh but it but it's a very

00:55:25,760 --> 00:55:29,200
useful bring up platform so

00:55:27,680 --> 00:55:30,960
if anybody well let me let me say it

00:55:29,200 --> 00:55:34,400
differently alan so

00:55:30,960 --> 00:55:36,640
and you're right partially so

00:55:34,400 --> 00:55:37,520
there are open source contributions out

00:55:36,640 --> 00:55:39,720
there

00:55:37,520 --> 00:55:41,280
right then you'll see it underneath

00:55:39,720 --> 00:55:44,400
github.comcappy there's a

00:55:41,280 --> 00:55:45,680
let's call it a fire and a nice open

00:55:44,400 --> 00:55:47,599
source

00:55:45,680 --> 00:55:49,040
rtl implementations that were used for

00:55:47,599 --> 00:55:51,599
different purposes

00:55:49,040 --> 00:55:52,559
for testing the memory buffer there are

00:55:51,599 --> 00:55:57,280
also

00:55:52,559 --> 00:56:01,040
fpga platforms called apollo and gemini

00:55:57,280 --> 00:56:04,160
right that are related to fire and ice

00:56:01,040 --> 00:56:05,839
so if you talk to um so if you attended

00:56:04,160 --> 00:56:09,359
like let's call it the memory work

00:56:05,839 --> 00:56:12,000
group within the open power um

00:56:09,359 --> 00:56:13,760
uh foundation right and you talked to

00:56:12,000 --> 00:56:16,960
kevin micklevane or

00:56:13,760 --> 00:56:18,000
um you know uh or pierre luke right we

00:56:16,960 --> 00:56:20,720
do have

00:56:18,000 --> 00:56:21,520
fpga platforms that we've used that

00:56:20,720 --> 00:56:23,839
they've also

00:56:21,520 --> 00:56:24,720
i think i don't know if they license

00:56:23,839 --> 00:56:26,559
them out or

00:56:24,720 --> 00:56:28,960
what how they actually do that overall

00:56:26,559 --> 00:56:31,200
relationship called apollo and gemini

00:56:28,960 --> 00:56:33,200
for folks to take those fire and ice

00:56:31,200 --> 00:56:34,079
implementations on those two particular

00:56:33,200 --> 00:56:36,640
platforms

00:56:34,079 --> 00:56:38,240
right right yeah no i i do well he has i

00:56:36,640 --> 00:56:39,760
understand kevin's built a few more in

00:56:38,240 --> 00:56:40,400
terms of sharing and he has right he's

00:56:39,760 --> 00:56:43,760
building

00:56:40,400 --> 00:56:45,119
more to have on hand for relationships

00:56:43,760 --> 00:56:47,599
that kind of let's call it take that

00:56:45,119 --> 00:56:50,160
next step

00:56:47,599 --> 00:56:51,680
right all right so that's that's all i

00:56:50,160 --> 00:56:53,599
want to correct you is yeah

00:56:51,680 --> 00:56:54,960
it's apollo and gemini yeah yeah

00:56:53,599 --> 00:56:56,079
effectively what i wanted to say if

00:56:54,960 --> 00:56:58,079
people were really

00:56:56,079 --> 00:57:00,079
interested in getting started with the

00:56:58,079 --> 00:57:01,680
id dimms on the fpgas and

00:57:00,079 --> 00:57:03,520
they're not ground zero of making their

00:57:01,680 --> 00:57:03,839
own board they can start playing with ip

00:57:03,520 --> 00:57:08,160
and

00:57:03,839 --> 00:57:11,520
looking at them exactly exactly exactly

00:57:08,160 --> 00:57:16,319
right yeah but we lost craig

00:57:11,520 --> 00:57:19,760
um um these keys back i guess

00:57:16,319 --> 00:57:21,440
um okay uh we're running close to the

00:57:19,760 --> 00:57:21,760
wire on time i believe i think we've got

00:57:21,440 --> 00:57:28,480
till

00:57:21,760 --> 00:57:28,480
1220 annie is that correct believe so

00:57:28,640 --> 00:57:35,839
um so i i i'm not sure if

00:57:32,160 --> 00:57:38,319
there's one more question in here uh

00:57:35,839 --> 00:57:39,760
oh he sent me the schedule yeah i i

00:57:38,319 --> 00:57:40,160
think the other thing i kind of want to

00:57:39,760 --> 00:57:42,880
mention

00:57:40,160 --> 00:57:44,480
too alan is it's just and it's been kind

00:57:42,880 --> 00:57:46,559
of

00:57:44,480 --> 00:57:47,680
reinforced i guess in multiple different

00:57:46,559 --> 00:57:50,960
talks about

00:57:47,680 --> 00:57:52,799
just the overall you know spirit of what

00:57:50,960 --> 00:57:54,079
we're trying to do with open cappy and

00:57:52,799 --> 00:57:56,640
working within the open source

00:57:54,079 --> 00:57:58,160
communities right we really recommend

00:57:56,640 --> 00:58:00,400
and encourage folks to

00:57:58,160 --> 00:58:01,520
to download the implementations take a

00:58:00,400 --> 00:58:04,559
look at them provide

00:58:01,520 --> 00:58:07,520
feedback i'm getting you know

00:58:04,559 --> 00:58:08,160
more and more of that as we progress

00:58:07,520 --> 00:58:10,480
over time

00:58:08,160 --> 00:58:11,599
but i encourage folks to take a look at

00:58:10,480 --> 00:58:14,079
them

00:58:11,599 --> 00:58:15,680
you know uh invest some time

00:58:14,079 --> 00:58:16,559
understanding them and if you find some

00:58:15,680 --> 00:58:18,240
things that

00:58:16,559 --> 00:58:19,760
don't work quite right or if you have

00:58:18,240 --> 00:58:21,359
questions on them or actually want to

00:58:19,760 --> 00:58:22,960
contribute back with

00:58:21,359 --> 00:58:24,640
you know some simple modifications to

00:58:22,960 --> 00:58:26,960
make them better

00:58:24,640 --> 00:58:28,799
um i i'm all for that i mean because

00:58:26,960 --> 00:58:30,319
that's that's primarily what we're

00:58:28,799 --> 00:58:31,440
trying to do with all these open source

00:58:30,319 --> 00:58:33,520
contributions is

00:58:31,440 --> 00:58:36,319
we don't want them to be necessarily ibm

00:58:33,520 --> 00:58:38,160
led the whole time we did that initially

00:58:36,319 --> 00:58:41,440
but we want the broader base community

00:58:38,160 --> 00:58:44,000
to be an active and vibrant community

00:58:41,440 --> 00:58:45,520
um and and for all of us to be able to

00:58:44,000 --> 00:58:46,640
collaborate together

00:58:45,520 --> 00:58:48,880
and so we you know the more

00:58:46,640 --> 00:58:50,480
contributions that we can get um and

00:58:48,880 --> 00:58:51,920
i'll put all you know and create the

00:58:50,480 --> 00:58:54,079
repositories

00:58:51,920 --> 00:58:55,440
um out there for them i think that only

00:58:54,079 --> 00:58:57,760
helps all of us

00:58:55,440 --> 00:58:59,839
yeah um one other thing that's just come

00:58:57,760 --> 00:59:02,720
in here thank you for the link pool

00:58:59,839 --> 00:59:03,359
uh at 3 30 um i'm not sure what track

00:59:02,720 --> 00:59:06,640
it's on

00:59:03,359 --> 00:59:08,720
um but dan jones from skytap

00:59:06,640 --> 00:59:10,640
will be uh talking about you can run

00:59:08,720 --> 00:59:12,160
power on microsoft azure

00:59:10,640 --> 00:59:13,839
so i'm not sure if that will include any

00:59:12,160 --> 00:59:14,960
open cappy accelerators but that's

00:59:13,839 --> 00:59:18,000
that's an interesting

00:59:14,960 --> 00:59:20,799
one i wasn't aware of um we do

00:59:18,000 --> 00:59:22,319
apparently we do have till 1225 so maybe

00:59:20,799 --> 00:59:25,839
i'll just throw

00:59:22,319 --> 00:59:26,190
one more question in there

00:59:25,839 --> 00:59:29,249
um

00:59:26,190 --> 00:59:29,249
[Music]

00:59:30,839 --> 00:59:33,839
okay

00:59:39,599 --> 00:59:47,839
support open uh

00:59:51,760 --> 00:59:56,160
there's one here um what is the power

00:59:55,359 --> 00:59:58,799
consumption

00:59:56,160 --> 01:00:00,640
comparison of eight rmi channels

00:59:58,799 --> 01:00:05,200
compared to a single

01:00:00,640 --> 01:00:08,400
on package hbm channel um

01:00:05,200 --> 01:00:10,720
just on hbm comparisons uh

01:00:08,400 --> 01:00:12,880
obviously on chip with short channels is

01:00:10,720 --> 01:00:15,359
is is really pretty low power obviously

01:00:12,880 --> 01:00:16,160
so reaching out to eight mi channels

01:00:15,359 --> 01:00:18,000
would be uh

01:00:16,160 --> 01:00:19,440
would be a higher a higher power

01:00:18,000 --> 01:00:21,680
requirement i'm sure

01:00:19,440 --> 01:00:24,160
but in terms of power density you you do

01:00:21,680 --> 01:00:26,160
have a power problem with all of these

01:00:24,160 --> 01:00:28,079
all of these uh memories and and very

01:00:26,160 --> 01:00:29,599
high power processors all on the one

01:00:28,079 --> 01:00:31,760
package so actually

01:00:29,599 --> 01:00:33,680
being able to break out at the same or

01:00:31,760 --> 01:00:36,559
higher bandwidth

01:00:33,680 --> 01:00:38,000
in hbm and being able to go to far

01:00:36,559 --> 01:00:41,280
greater depths than

01:00:38,000 --> 01:00:43,359
16 to 32 gigabytes for their bags uh

01:00:41,280 --> 01:00:44,400
really becomes very compelling and the

01:00:43,359 --> 01:00:46,799
cost

01:00:44,400 --> 01:00:48,880
of the silicons you know the the silicon

01:00:46,799 --> 01:00:50,720
substrates these these hbm enabled

01:00:48,880 --> 01:00:54,720
devices are not cheap

01:00:50,720 --> 01:00:56,799
um uh in comparison so so i think um

01:00:54,720 --> 01:00:58,400
i i i think there's there's a lot of

01:00:56,799 --> 01:01:01,920
opportunity there in fact

01:00:58,400 --> 01:01:03,920
my big vote needs a lot of money

01:01:01,920 --> 01:01:05,839
but i really don't understand you know

01:01:03,920 --> 01:01:06,799
if you look at an hbm interface it's

01:01:05,839 --> 01:01:08,559
actually got eight

01:01:06,799 --> 01:01:10,559
ports on it so it looks very much like

01:01:08,559 --> 01:01:13,119
eight imi channels

01:01:10,559 --> 01:01:13,839
um so you can have full compatibility

01:01:13,119 --> 01:01:17,520
from

01:01:13,839 --> 01:01:19,440
on chip hbm all the way to

01:01:17,520 --> 01:01:21,119
to storage class memory remotely

01:01:19,440 --> 01:01:22,720
connected through the through the memory

01:01:21,119 --> 01:01:25,359
fabric

01:01:22,720 --> 01:01:27,359
so i would love to see the chip the hbm

01:01:25,359 --> 01:01:30,480
logic layer interface

01:01:27,359 --> 01:01:34,240
get rid of that very high pin count

01:01:30,480 --> 01:01:36,480
um uh interface on the substrate

01:01:34,240 --> 01:01:38,960
get it get get eight oma channels on

01:01:36,480 --> 01:01:39,440
there instead and then we can connect

01:01:38,960 --> 01:01:41,200
them with an

01:01:39,440 --> 01:01:43,119
organic substrate so the cost of the

01:01:41,200 --> 01:01:45,599
package parts comes rapidly

01:01:43,119 --> 01:01:47,200
ramping down so if there's a vote for me

01:01:45,599 --> 01:01:50,000
to go out there as samsung

01:01:47,200 --> 01:01:50,400
tear that logic layer out and put in put

01:01:50,000 --> 01:01:53,359
in an

01:01:50,400 --> 01:01:54,720
omi logic layer or ibm get it done pay

01:01:53,359 --> 01:01:57,680
for it to be done and then

01:01:54,720 --> 01:01:59,119
we could go omi on on package all the

01:01:57,680 --> 01:02:01,119
way to omi

01:01:59,119 --> 01:02:03,200
uh remotely connected and that i think

01:02:01,119 --> 01:02:07,039
that would be the icing on the cake

01:02:03,200 --> 01:02:09,440
um if there any other comments on

01:02:07,039 --> 01:02:10,960
from a viewer of hbm from from anyone

01:02:09,440 --> 01:02:12,480
else in the panels

01:02:10,960 --> 01:02:14,640
i mean it's great from its bandwidth

01:02:12,480 --> 01:02:16,880
perspective but

01:02:14,640 --> 01:02:18,240
i i think in in the high performance

01:02:16,880 --> 01:02:19,760
computing world maybe oscar maybe you

01:02:18,240 --> 01:02:22,480
can answer this is

01:02:19,760 --> 01:02:23,839
is how many problems when you go memory

01:02:22,480 --> 01:02:27,200
band

01:02:23,839 --> 01:02:29,200
how many problems are okay with 16

01:02:27,200 --> 01:02:31,280
gigabytes of memory or how many problems

01:02:29,200 --> 01:02:32,799
really need to go much deeper or what is

01:02:31,280 --> 01:02:34,960
the ratio

01:02:32,799 --> 01:02:37,200
would it be better to have a tiny

01:02:34,960 --> 01:02:40,000
processor with only a few flops

01:02:37,200 --> 01:02:40,400
but massive memory bandwidth uh or you

01:02:40,000 --> 01:02:42,480
know

01:02:40,400 --> 01:02:43,680
you know are we wasting flops in the

01:02:42,480 --> 01:02:45,920
devices so

01:02:43,680 --> 01:02:48,000
what is that balance going on is there a

01:02:45,920 --> 01:02:49,039
need for this in the in the hpc world or

01:02:48,000 --> 01:02:52,319
not

01:02:49,039 --> 01:02:54,079
so so that's a great question i i really

01:02:52,319 --> 01:02:57,359
like this question because

01:02:54,079 --> 01:02:58,880
we were at the core of that uh when we

01:02:57,359 --> 01:03:02,799
were working with the oil and gas

01:02:58,880 --> 01:03:03,520
industry um as well as now looking at

01:03:02,799 --> 01:03:06,880
climate

01:03:03,520 --> 01:03:10,000
and other simulations um

01:03:06,880 --> 01:03:12,880
the accuracy of any prediction depends

01:03:10,000 --> 01:03:15,680
on the discretization of space

01:03:12,880 --> 01:03:16,319
time and value and i've been trying to

01:03:15,680 --> 01:03:19,280
drive

01:03:16,319 --> 01:03:20,960
that uh into physics as well where

01:03:19,280 --> 01:03:21,920
originally physics of course only

01:03:20,960 --> 01:03:25,039
consider

01:03:21,920 --> 01:03:27,760
space and time and they assume infinite

01:03:25,039 --> 01:03:28,799
precision um and then they hit the

01:03:27,760 --> 01:03:30,640
computer

01:03:28,799 --> 01:03:31,839
and once they hit the computer they say

01:03:30,640 --> 01:03:34,559
well wait a minute

01:03:31,839 --> 01:03:35,760
there is no infinite precision so what

01:03:34,559 --> 01:03:38,160
do we do with that

01:03:35,760 --> 01:03:39,920
and then the initial answer of course uh

01:03:38,160 --> 01:03:42,880
for for a few decades was

01:03:39,920 --> 01:03:45,039
uh let's just use floating point uh ieee

01:03:42,880 --> 01:03:47,760
standard and not worry about it

01:03:45,039 --> 01:03:49,039
and we can see today that that is not

01:03:47,760 --> 01:03:53,280
possible anymore

01:03:49,039 --> 01:03:56,319
so when you see uh google making a tpu

01:03:53,280 --> 01:03:59,280
um some of my colleagues

01:03:56,319 --> 01:04:00,640
from bell labs actually uh over there

01:03:59,280 --> 01:04:04,079
driving that

01:04:00,640 --> 01:04:06,640
um you don't see floating point anymore

01:04:04,079 --> 01:04:09,119
uh you see very customized number of

01:04:06,640 --> 01:04:11,920
representations which is discretization

01:04:09,119 --> 01:04:13,680
of value and then you add to that

01:04:11,920 --> 01:04:17,280
discretization of space

01:04:13,680 --> 01:04:19,680
where you have 3d 4d 5d spaces depending

01:04:17,280 --> 01:04:23,119
on how crazy you go with the physics

01:04:19,680 --> 01:04:24,720
you add time to all of this now suddenly

01:04:23,119 --> 01:04:25,440
there is more and more data to be

01:04:24,720 --> 01:04:27,119
considered

01:04:25,440 --> 01:04:29,280
and you want to make predictions into

01:04:27,119 --> 01:04:30,559
the future you want to say is there

01:04:29,280 --> 01:04:34,079
global warming is it

01:04:30,559 --> 01:04:37,359
going up is it going down the more

01:04:34,079 --> 01:04:38,480
memory you have on a node the more

01:04:37,359 --> 01:04:41,599
bandwidth you have

01:04:38,480 --> 01:04:44,720
to that memory the more accurate

01:04:41,599 --> 01:04:47,760
predictions you can make the more

01:04:44,720 --> 01:04:51,119
accurate simulations you can run

01:04:47,760 --> 01:04:53,119
globally across the whole planet and so

01:04:51,119 --> 01:04:54,559
it makes the difference from being able

01:04:53,119 --> 01:04:57,760
to simulate

01:04:54,559 --> 01:04:58,480
weather in california versus to simulate

01:04:57,760 --> 01:05:01,599
climate

01:04:58,480 --> 01:05:02,880
across the whole planet including the

01:05:01,599 --> 01:05:05,599
oceans

01:05:02,880 --> 01:05:06,720
including the air including what goes

01:05:05,599 --> 01:05:10,160
around

01:05:06,720 --> 01:05:12,720
so absolutely but can it happen quickly

01:05:10,160 --> 01:05:14,559
well that's the question because

01:05:12,720 --> 01:05:16,480
scientists have to understand the

01:05:14,559 --> 01:05:18,160
capabilities of such new hardware so

01:05:16,480 --> 01:05:20,640
they first have to build it

01:05:18,160 --> 01:05:22,000
then they have to change the models yeah

01:05:20,640 --> 01:05:24,799
then they have to learn

01:05:22,000 --> 01:05:25,760
how to do business with these newer

01:05:24,799 --> 01:05:28,799
models

01:05:25,760 --> 01:05:30,880
and so the first step is on us to build

01:05:28,799 --> 01:05:34,160
these capabilities maxellar was

01:05:30,880 --> 01:05:38,079
first to be able to run 3 000

01:05:34,160 --> 01:05:40,640
cubed seismic imaging on the whole rack

01:05:38,079 --> 01:05:44,160
of machines in production

01:05:40,640 --> 01:05:47,359
the only way we were able to do that was

01:05:44,160 --> 01:05:50,480
through fpgas and some crazy hardware

01:05:47,359 --> 01:05:54,000
that we were building at the time that

01:05:50,480 --> 01:05:55,599
in turn enabled a whole other set of

01:05:54,000 --> 01:05:57,440
geophysics developments

01:05:55,599 --> 01:05:59,119
in terms of how they built their physics

01:05:57,440 --> 01:06:01,920
their models and and

01:05:59,119 --> 01:06:03,520
and how they do things in in general we

01:06:01,920 --> 01:06:06,000
then got overtaken by

01:06:03,520 --> 01:06:07,200
by mainstream off-the-shelf hardware

01:06:06,000 --> 01:06:07,920
which of course is always more

01:06:07,200 --> 01:06:11,359
attractive

01:06:07,920 --> 01:06:14,480
especially if it comes at zero cost but

01:06:11,359 --> 01:06:15,280
um at the same time the first step has

01:06:14,480 --> 01:06:18,400
to be

01:06:15,280 --> 01:06:20,160
showing that the capability is there

01:06:18,400 --> 01:06:21,760
then people will find the use for it

01:06:20,160 --> 01:06:23,920
absolutely yeah

01:06:21,760 --> 01:06:24,799
okay thanks oscar on that we've overrun

01:06:23,920 --> 01:06:27,200
a little there but

01:06:24,799 --> 01:06:28,720
thank you very much all panelists much

01:06:27,200 --> 01:06:30,160
appreciated in the audience for your

01:06:28,720 --> 01:06:32,799
participation

01:06:30,160 --> 01:06:34,319
uh much appreciated have a good rest of

01:06:32,799 --> 01:06:37,760
the conference

01:06:34,319 --> 01:06:37,760

YouTube URL: https://www.youtube.com/watch?v=q4KLYjBQXq4


