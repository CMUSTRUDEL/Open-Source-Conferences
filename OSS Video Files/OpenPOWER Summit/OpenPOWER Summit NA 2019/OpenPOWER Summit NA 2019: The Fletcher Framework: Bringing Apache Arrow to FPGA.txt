Title: OpenPOWER Summit NA 2019: The Fletcher Framework: Bringing Apache Arrow to FPGA
Publication date: 2019-08-20
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Johan Peltenburg, Delft University of Technology

Modern big data systems are highly heterogeneous. Components are implemented in a wide variety of programming languages and frameworks. Due to implementation differences, interfaces between components are burdened by serialization overhead. The Apache Arrow project helps to overcome this burden through a language-agnostic columnar in-memory format for big data applications. The open-source Fletcher framework is an implementation of Arrow for FPGA accelerators. Fletcher allows developers to communicate in the Arrow format through specialized, high-performance and easy-to-use hardware interfaces. Serialization overhead is prevented, and integration with over 11 high-level languages is made possible and efficient. The OpenPOWER CAPI SNAP framework is a supported platforms of Fletcher. We will go over the benefits of Apache Arrow and Fletcher and show a hands-on example.
Captions: 
	00:00:00,030 --> 00:00:06,890
thanks a lot so thank you everybody for

00:00:03,030 --> 00:00:10,130
attending thanks to new Shin for a nice

00:00:06,890 --> 00:00:13,440
tiny introduction towards this talk so

00:00:10,130 --> 00:00:14,849
I'm I'm Jung peltor from Delft

00:00:13,440 --> 00:00:16,260
University of Technology I'm gonna talk

00:00:14,849 --> 00:00:19,350
about our framework that we call

00:00:16,260 --> 00:00:21,119
Fletcher because it's built on Apache

00:00:19,350 --> 00:00:24,029
arrow and then we had to come up with a

00:00:21,119 --> 00:00:27,390
name that had something to do with

00:00:24,029 --> 00:00:29,699
arrows and FPGAs so the f is for FPGA in

00:00:27,390 --> 00:00:31,080
the lecture part I don't know what

00:00:29,699 --> 00:00:32,189
so that sure it has something to do with

00:00:31,080 --> 00:00:37,290
error so that's why it's called like

00:00:32,189 --> 00:00:39,660
that so we have that out of the way so

00:00:37,290 --> 00:00:41,370
let's first give thanks to all the

00:00:39,660 --> 00:00:44,489
people Peter mentioned a few already

00:00:41,370 --> 00:00:46,500
here in our development team and we have

00:00:44,489 --> 00:00:48,629
also some PhD students and master

00:00:46,500 --> 00:00:50,940
students assisting me with a lot of

00:00:48,629 --> 00:00:52,949
interesting stuff and we also get some

00:00:50,940 --> 00:00:55,230
nice support from our advisors of course

00:00:52,949 --> 00:00:58,320
including Peter and then also from

00:00:55,230 --> 00:01:01,859
Xilinx and the fit octave is European

00:00:58,320 --> 00:01:03,719
project and also from IBM and an alpha

00:01:01,859 --> 00:01:06,000
data for some nice accelerator cards

00:01:03,719 --> 00:01:09,720
that we test our stuff on so thanks to

00:01:06,000 --> 00:01:12,659
those although all those folks so the

00:01:09,720 --> 00:01:14,159
outline for my talk is first gonna talk

00:01:12,659 --> 00:01:16,710
a little bit about the heterogeneity

00:01:14,159 --> 00:01:19,080
challenge in big data systems and we'll

00:01:16,710 --> 00:01:21,299
slowly get to Apache arrow itself

00:01:19,080 --> 00:01:22,830
I'll give this very brief introduction

00:01:21,299 --> 00:01:25,920
on it because it's a pretty massive

00:01:22,830 --> 00:01:28,560
project by now and I'll talk about how

00:01:25,920 --> 00:01:31,409
our framework brings that to the FPGA

00:01:28,560 --> 00:01:33,990
accelerators I'll show you a little mini

00:01:31,409 --> 00:01:36,390
tutorial that we that all of you could

00:01:33,990 --> 00:01:38,369
do in your laptops almost for most of

00:01:36,390 --> 00:01:40,860
the steps until you need some FPGA of

00:01:38,369 --> 00:01:43,110
course and I'll talk a little bit about

00:01:40,860 --> 00:01:46,880
some future work and ongoing stuff that

00:01:43,110 --> 00:01:50,250
in our lab based on this framework

00:01:46,880 --> 00:01:52,399
all right so contemporary big data

00:01:50,250 --> 00:01:55,049
systems are very very heterogeneous

00:01:52,399 --> 00:01:57,060
so not only in terms of hardware are

00:01:55,049 --> 00:01:59,119
they becoming more heterogeneous but all

00:01:57,060 --> 00:02:02,490
the software components are also very

00:01:59,119 --> 00:02:05,549
heterogeneous so I just a little example

00:02:02,490 --> 00:02:08,369
of one big data framework is tensorflow

00:02:05,549 --> 00:02:10,500
and spark you run a Python program users

00:02:08,369 --> 00:02:13,050
numpy thats Python bindings on a C core

00:02:10,500 --> 00:02:13,720
it has interface with tensorflow

00:02:13,050 --> 00:02:16,420
that's programmed

00:02:13,720 --> 00:02:19,750
CUDA runs on a GPU and that runs on top

00:02:16,420 --> 00:02:21,820
of spark which is a Scala Java framework

00:02:19,750 --> 00:02:23,680
mainly that runs on a Java Virtual

00:02:21,820 --> 00:02:27,790
Machine and then that obstructs your CP

00:02:23,680 --> 00:02:31,600
on CPU and IO right so that's a that's a

00:02:27,790 --> 00:02:33,670
pretty many layered many layers in that

00:02:31,600 --> 00:02:37,510
stack there and it's not untypical for

00:02:33,670 --> 00:02:40,960
big data accelerator big data analytics

00:02:37,510 --> 00:02:44,920
systems to have such a very varied stack

00:02:40,960 --> 00:02:47,020
of components and so some of the

00:02:44,920 --> 00:02:48,910
technologies that people use especially

00:02:47,020 --> 00:02:51,190
very high level language runtimes are

00:02:48,910 --> 00:02:54,220
not necessary necessarily designed to

00:02:51,190 --> 00:02:57,430
process terabytes of data and so me as

00:02:54,220 --> 00:03:00,459
an FPGA accelerator guy right if I look

00:02:57,430 --> 00:03:03,040
at those those stacks and I'm trying to

00:03:00,459 --> 00:03:05,890
find out where's my data and all of this

00:03:03,040 --> 00:03:08,350
right it's like a pretty hard question

00:03:05,890 --> 00:03:10,450
and and the second question that you

00:03:08,350 --> 00:03:13,300
could ask is what does the data look

00:03:10,450 --> 00:03:14,830
like is it is it usable to me at all

00:03:13,300 --> 00:03:16,959
when it enters my FPGA

00:03:14,830 --> 00:03:19,000
can I start processing on it already or

00:03:16,959 --> 00:03:21,730
do I have to do some other stuff and

00:03:19,000 --> 00:03:23,739
turns out these questions are you know

00:03:21,730 --> 00:03:26,080
they go pretty deep so by the time you

00:03:23,739 --> 00:03:28,269
get to the core like with this onion on

00:03:26,080 --> 00:03:33,280
the right you might be crying a little

00:03:28,269 --> 00:03:37,360
bit itself so so just to give an example

00:03:33,280 --> 00:03:39,340
I have a few memory layouts of a string

00:03:37,360 --> 00:03:41,769
object in different language runtimes on

00:03:39,340 --> 00:03:43,989
the left so I have it for a few popular

00:03:41,769 --> 00:03:46,269
ones but we could come up with others

00:03:43,989 --> 00:03:48,910
and they would all look different right

00:03:46,269 --> 00:03:49,900
so for C++ we have the size of the

00:03:48,910 --> 00:03:52,600
string and Anna pointer to character

00:03:49,900 --> 00:03:54,880
buffer but sometimes uses an internal

00:03:52,600 --> 00:03:57,070
character array if the string is not too

00:03:54,880 --> 00:03:58,480
large and you know in Java it looks

00:03:57,070 --> 00:04:00,640
different again I will not go into

00:03:58,480 --> 00:04:03,070
details too much even the encoding is

00:04:00,640 --> 00:04:07,150
different of the characters right and

00:04:03,070 --> 00:04:08,890
then in Python it's again different so

00:04:07,150 --> 00:04:10,989
for me isn't it fiji accelerator guy

00:04:08,890 --> 00:04:12,549
when I look at this it's like you know

00:04:10,989 --> 00:04:14,230
it's not very usable to me because even

00:04:12,549 --> 00:04:17,260
if I would load this sort of data

00:04:14,230 --> 00:04:19,900
structure straight into the FPGA I see a

00:04:17,260 --> 00:04:23,380
lot of fields that actually are not very

00:04:19,900 --> 00:04:25,210
usable to me what why did what would I

00:04:23,380 --> 00:04:27,669
have to do with a JVM object is to use

00:04:25,210 --> 00:04:29,289
those data to me so that's already

00:04:27,669 --> 00:04:31,180
a little bit of overhead there that you

00:04:29,289 --> 00:04:33,340
know when I load that data into the FPGA

00:04:31,180 --> 00:04:36,280
I lose a lot of bandwidth because of

00:04:33,340 --> 00:04:38,319
that and also it's it's not really

00:04:36,280 --> 00:04:41,050
enough in a format that that helps me a

00:04:38,319 --> 00:04:42,849
lot because I have all these a I have to

00:04:41,050 --> 00:04:44,460
traverse these pointers and I have to

00:04:42,849 --> 00:04:47,289
pay memory later seen that sort of stuff

00:04:44,460 --> 00:04:49,509
right for an FPGA guy I mean I would

00:04:47,289 --> 00:04:50,800
like to have a stream with the lengths

00:04:49,509 --> 00:04:52,569
of the strings and another stream with

00:04:50,800 --> 00:04:54,849
the character of the strings for me as a

00:04:52,569 --> 00:04:58,599
PJ guy that wants to create some sort of

00:04:54,849 --> 00:05:01,779
data flow design that would be much more

00:04:58,599 --> 00:05:04,930
convenient right so it's not so easy to

00:05:01,779 --> 00:05:07,029
you know once you create your FPGA

00:05:04,930 --> 00:05:09,370
design to integrate it with all these

00:05:07,029 --> 00:05:11,590
different language runtimes and so that

00:05:09,370 --> 00:05:13,750
makes matters very complicated if you

00:05:11,590 --> 00:05:16,000
want to accelerate stuff in a big data

00:05:13,750 --> 00:05:18,810
environment because people use these

00:05:16,000 --> 00:05:22,150
very high level language runtimes

00:05:18,810 --> 00:05:24,370
alright so so what you have to do is you

00:05:22,150 --> 00:05:26,319
have to take that all these little

00:05:24,370 --> 00:05:28,449
pieces of memory you have some

00:05:26,319 --> 00:05:31,000
collection X in the memory of some

00:05:28,449 --> 00:05:33,009
process a for example and there's a lot

00:05:31,000 --> 00:05:35,979
of pointers to traverse once you get to

00:05:33,009 --> 00:05:37,719
the data and you know when you want to

00:05:35,979 --> 00:05:39,610
transport that data to another process

00:05:37,719 --> 00:05:41,589
may be seen FPGA component maybe it's

00:05:39,610 --> 00:05:43,270
another software process or something

00:05:41,589 --> 00:05:47,050
typically what people have to do with

00:05:43,270 --> 00:05:48,789
oracle serialization so we gather all

00:05:47,050 --> 00:05:52,779
the information we want we should be

00:05:48,789 --> 00:05:55,479
stored in some sort of intermediate

00:05:52,779 --> 00:05:57,250
format maybe or already in the in the

00:05:55,479 --> 00:06:00,729
desired format that's also possible of

00:05:57,250 --> 00:06:02,439
course we put that in an IPC message or

00:06:00,729 --> 00:06:04,659
in some shared memory and then we

00:06:02,439 --> 00:06:07,210
deserialize it back into the language

00:06:04,659 --> 00:06:10,270
runtime that is the destination of the

00:06:07,210 --> 00:06:12,810
data or maybe we do serialize it into

00:06:10,270 --> 00:06:16,330
you know something that the FPGA can use

00:06:12,810 --> 00:06:18,069
but this is pretty costly right because

00:06:16,330 --> 00:06:19,539
we have to iterate over all the objects

00:06:18,069 --> 00:06:22,060
but remember we have a lot of objects

00:06:19,539 --> 00:06:24,339
because the data is very large we have

00:06:22,060 --> 00:06:26,199
to traverse all these objects object

00:06:24,339 --> 00:06:28,330
graphs so depending a little bit on the

00:06:26,199 --> 00:06:30,819
choice is made by wherever the data is

00:06:28,330 --> 00:06:33,849
coming from we can have we have to have

00:06:30,819 --> 00:06:35,889
a lot of traversals or maybe less

00:06:33,849 --> 00:06:38,440
reversals but we have to pay memory

00:06:35,889 --> 00:06:40,820
latency all the time right and we have

00:06:38,440 --> 00:06:43,820
to make a lot of copies

00:06:40,820 --> 00:06:45,740
so we lose bandwidth and sometimes we

00:06:43,820 --> 00:06:48,350
also have to reconstruct the objects

00:06:45,740 --> 00:06:51,470
like I said so it's quite costly and

00:06:48,350 --> 00:06:55,610
it's a relatively big problem many

00:06:51,470 --> 00:06:59,180
people are working on you know getting

00:06:55,610 --> 00:07:02,480
rid of all this overhead so on

00:06:59,180 --> 00:07:06,830
accelerators it's this can be just gonna

00:07:02,480 --> 00:07:08,600
have a very high impact actually so you

00:07:06,830 --> 00:07:11,180
know if you have some original software

00:07:08,600 --> 00:07:12,380
process running on your CPU you know and

00:07:11,180 --> 00:07:14,180
you're like okay it's a little bit slow

00:07:12,380 --> 00:07:17,150
let's accelerate it with whatever maybe

00:07:14,180 --> 00:07:20,390
gpgpu or FPGA and very often you'll see

00:07:17,150 --> 00:07:22,400
okay I have to I'm gonna create a nice

00:07:20,390 --> 00:07:25,340
accelerator it's kind of run very very

00:07:22,400 --> 00:07:29,510
very fast so the accelerator compute

00:07:25,340 --> 00:07:30,980
time is decreased a lot but then you

00:07:29,510 --> 00:07:33,430
still have to do the serialization right

00:07:30,980 --> 00:07:35,630
so that's a completely non-functional

00:07:33,430 --> 00:07:38,240
component of the total run time of your

00:07:35,630 --> 00:07:40,430
accelerated solution and so it can be

00:07:38,240 --> 00:07:42,190
very very substantial so this is not

00:07:40,430 --> 00:07:44,300
just copying the data over it's also

00:07:42,190 --> 00:07:46,970
reordering it and putting it in the

00:07:44,300 --> 00:07:48,590
right place so what you would like even

00:07:46,970 --> 00:07:50,600
if you had to copy to your accelerator

00:07:48,590 --> 00:07:52,610
you just like to have just that copy and

00:07:50,600 --> 00:07:54,440
then do the computation and copy the

00:07:52,610 --> 00:07:56,180
result back you don't really want to

00:07:54,440 --> 00:07:58,340
reach off all the bytes in different

00:07:56,180 --> 00:08:02,240
positions and traverse all the pointers

00:07:58,340 --> 00:08:06,020
and that sort of stuff so in 2016 I

00:08:02,240 --> 00:08:07,880
think we did a 2017 we did some

00:08:06,020 --> 00:08:12,230
preliminary measurements on one of the

00:08:07,880 --> 00:08:14,630
language runtimes a very popular runtime

00:08:12,230 --> 00:08:16,370
framework is the open JDK in big data

00:08:14,630 --> 00:08:19,250
world because Java runs on it and Scala

00:08:16,370 --> 00:08:23,930
and stuff I think we we measured on

00:08:19,250 --> 00:08:26,330
Powerade first specific for all sorts of

00:08:23,930 --> 00:08:28,490
object graphs actually like how fast can

00:08:26,330 --> 00:08:29,840
we sterilize that and why we look at the

00:08:28,490 --> 00:08:33,349
performance of that it's actually quite

00:08:29,840 --> 00:08:35,990
you know quite low so we could all only

00:08:33,349 --> 00:08:38,750
do it like in a safe way so the top two

00:08:35,990 --> 00:08:41,240
ones are basically cheating and no

00:08:38,750 --> 00:08:45,020
saying software developer would ever use

00:08:41,240 --> 00:08:46,490
them because they are very unsafe so if

00:08:45,020 --> 00:08:48,060
you do it in a safer way we couldn't

00:08:46,490 --> 00:08:50,580
really get above

00:08:48,060 --> 00:08:52,680
and close to a gigabyte per second even

00:08:50,580 --> 00:08:55,080
if we you know increase the number of

00:08:52,680 --> 00:08:56,580
stretch a lot so that's that's not the

00:08:55,080 --> 00:08:58,080
kind of bandwidth that you have for your

00:08:56,580 --> 00:08:59,580
accelerator itself right because now

00:08:58,080 --> 00:09:01,710
we're getting open copy for example

00:08:59,580 --> 00:09:03,990
we're gonna have 25 gigabytes per second

00:09:01,710 --> 00:09:06,000
but yeah even though that bandwidth is

00:09:03,990 --> 00:09:08,010
very high if we still have to do all the

00:09:06,000 --> 00:09:09,510
serialization it's just kind of it's

00:09:08,010 --> 00:09:13,410
we're not going to be able to leverage

00:09:09,510 --> 00:09:16,710
all of that bandwidth so not only us but

00:09:13,410 --> 00:09:18,060
our weight okay so I'm just gonna show

00:09:16,710 --> 00:09:19,920
you like what happens if you don't have

00:09:18,060 --> 00:09:21,780
to do that serialization we did a little

00:09:19,920 --> 00:09:23,790
experiment that's also a sneak preview

00:09:21,780 --> 00:09:26,700
because we actually use Fletcher to

00:09:23,790 --> 00:09:29,160
implement all this eventually so we did

00:09:26,700 --> 00:09:33,570
a regular expression matching we have a

00:09:29,160 --> 00:09:36,120
whole bunch of strings we we used about

00:09:33,570 --> 00:09:37,800
a gigabytes of strings like this and

00:09:36,120 --> 00:09:39,390
then we have a regular expression and

00:09:37,800 --> 00:09:41,850
then we want to match the strings to

00:09:39,390 --> 00:09:43,800
that expression and FPGAs turn out to be

00:09:41,850 --> 00:09:44,340
pretty good at that or hardware in

00:09:43,800 --> 00:09:45,870
general

00:09:44,340 --> 00:09:48,090
alright so it's something that we can

00:09:45,870 --> 00:09:49,730
accelerate very well but yeah I mean we

00:09:48,090 --> 00:09:51,960
just saw what the strings looked like in

00:09:49,730 --> 00:09:56,340
in a software run time and that's not

00:09:51,960 --> 00:09:59,670
very very convenient for us so we so so

00:09:56,340 --> 00:10:01,530
we're gonna see what happened right we

00:09:59,670 --> 00:10:03,660
did the regular session matching on the

00:10:01,530 --> 00:10:05,700
gigabyte of treat like strings so

00:10:03,660 --> 00:10:07,740
they're gonna be I know what's the max

00:10:05,700 --> 00:10:11,070
characters it's like 240 now all right

00:10:07,740 --> 00:10:13,680
something like that and so the bottom

00:10:11,070 --> 00:10:16,230
graph is actually on on on the power

00:10:13,680 --> 00:10:17,760
nine system and we use the Capetian have

00:10:16,230 --> 00:10:21,540
to do that

00:10:17,760 --> 00:10:23,880
and so if so here you can see the

00:10:21,540 --> 00:10:26,550
runtime components right so this is the

00:10:23,880 --> 00:10:28,230
CPU compute so sometimes we do so we do

00:10:26,550 --> 00:10:30,750
it in three languages we didn't software

00:10:28,230 --> 00:10:32,700
only what all the tests enabled because

00:10:30,750 --> 00:10:34,860
he takes about in C++ as the fastest

00:10:32,700 --> 00:10:36,180
takes about three seconds and then for

00:10:34,860 --> 00:10:38,940
Python and Java they're really slow so

00:10:36,180 --> 00:10:41,010
Java is a little it's kind of faster

00:10:38,940 --> 00:10:44,730
compared to pythons still so that was

00:10:41,010 --> 00:10:47,160
like seven or something and then Python

00:10:44,730 --> 00:10:49,230
was about ten seconds and then when we

00:10:47,160 --> 00:10:51,240
did that this is an FPGA just compute

00:10:49,230 --> 00:10:53,780
parts so not the data transfer part of

00:10:51,240 --> 00:10:56,990
civilization we can do it in like

00:10:53,780 --> 00:10:59,930
few a few milliseconds right a bunch of

00:10:56,990 --> 00:11:01,340
milliseconds so that's really fast we

00:10:59,930 --> 00:11:03,860
have a nice accelerator the

00:11:01,340 --> 00:11:05,960
computational performance is really good

00:11:03,860 --> 00:11:09,110
but now we have to get those strings

00:11:05,960 --> 00:11:10,970
from a C++ runtime environment or a

00:11:09,110 --> 00:11:14,150
Python runtime of our java runtime

00:11:10,970 --> 00:11:14,480
environment into the FPGA so we just saw

00:11:14,150 --> 00:11:16,100
okay

00:11:14,480 --> 00:11:18,410
the format is not very usable we want to

00:11:16,100 --> 00:11:21,680
turn it into streams so we have to share

00:11:18,410 --> 00:11:24,230
lies it right and now you can see the

00:11:21,680 --> 00:11:25,640
serialization component here and here it

00:11:24,230 --> 00:11:27,860
still makes sense to do it you know

00:11:25,640 --> 00:11:29,630
because in total the runtime is gonna be

00:11:27,860 --> 00:11:32,330
less even though we have to share lines

00:11:29,630 --> 00:11:34,310
but in some cases the serialization over

00:11:32,330 --> 00:11:36,380
it is so large that it doesn't even make

00:11:34,310 --> 00:11:38,840
sense anymore to use it accelerator just

00:11:36,380 --> 00:11:41,420
because the data format is you know it

00:11:38,840 --> 00:11:43,370
takes too much time to to reorder it and

00:11:41,420 --> 00:11:49,310
to serialize things into something

00:11:43,370 --> 00:11:51,380
usable all right so what can we do okay

00:11:49,310 --> 00:11:53,750
so we have to overcome this realization

00:11:51,380 --> 00:11:56,660
bottleneck for the reasons I just showed

00:11:53,750 --> 00:11:58,790
in the example right so the in memory

00:11:56,660 --> 00:12:00,620
formats it's very hard to tell people to

00:11:58,790 --> 00:12:02,900
change them right because they're

00:12:00,620 --> 00:12:03,950
determined by a lot of factors so they

00:12:02,900 --> 00:12:05,839
can be determined by the programming

00:12:03,950 --> 00:12:07,670
language themselves and especially the

00:12:05,839 --> 00:12:09,440
standard libraries in the runtime system

00:12:07,670 --> 00:12:12,140
design choices dictate that they're

00:12:09,440 --> 00:12:13,730
gonna look like this and very often the

00:12:12,140 --> 00:12:15,020
programmers themselves don't even have

00:12:13,730 --> 00:12:17,240
to think about them anymore and it's

00:12:15,020 --> 00:12:19,490
very high highly abstracted languages

00:12:17,240 --> 00:12:21,620
but also the algorithms can of course

00:12:19,490 --> 00:12:22,760
dictate what what the data looks like in

00:12:21,620 --> 00:12:24,589
memory and and the programmers

00:12:22,760 --> 00:12:27,920
themselves they could do something about

00:12:24,589 --> 00:12:30,830
it if they wanted to so we see that

00:12:27,920 --> 00:12:32,990
there's increased heat originate in big

00:12:30,830 --> 00:12:34,700
data systems right we have to do more

00:12:32,990 --> 00:12:37,100
interprocess communication so we have

00:12:34,700 --> 00:12:40,190
more civilization overhead so a lot of

00:12:37,100 --> 00:12:42,230
very smart and experienced folks thought

00:12:40,190 --> 00:12:44,780
about that and they said well what is it

00:12:42,230 --> 00:12:47,390
what if this data is in a standardized

00:12:44,780 --> 00:12:49,160
format so we're not gonna let the

00:12:47,390 --> 00:12:50,450
language runtimes dictate anymore what

00:12:49,160 --> 00:12:51,770
the data looks like in memory we're

00:12:50,450 --> 00:12:53,300
gonna decide that for ourselves right

00:12:51,770 --> 00:12:55,220
and we're gonna standardize that and

00:12:53,300 --> 00:12:57,350
every language that we in every language

00:12:55,220 --> 00:12:59,450
that we use we just expose access to

00:12:57,350 --> 00:13:01,870
that data to some library rather than

00:12:59,450 --> 00:13:04,040
using the language constructs themselves

00:13:01,870 --> 00:13:06,260
or the language library constructs

00:13:04,040 --> 00:13:07,600
themself and then we're going to try to

00:13:06,260 --> 00:13:09,970
make that as continuous as

00:13:07,600 --> 00:13:12,010
so whenever we transfer it even if if we

00:13:09,970 --> 00:13:14,950
have to transfer it we can do it using

00:13:12,010 --> 00:13:19,000
large births we prevent a lot of pointer

00:13:14,950 --> 00:13:20,710
chasing and misalignment issues so those

00:13:19,000 --> 00:13:23,230
folks come up with Apache arrow which is

00:13:20,710 --> 00:13:26,440
a great project so normally you'd have

00:13:23,230 --> 00:13:29,140
like your your big data system here with

00:13:26,440 --> 00:13:30,940
lots of components so for example you

00:13:29,140 --> 00:13:33,370
you'd have a Python tool or something

00:13:30,940 --> 00:13:35,410
you want you want to make that work with

00:13:33,370 --> 00:13:37,540
some a pet something like expect a spark

00:13:35,410 --> 00:13:39,040
and you have to do all this civilization

00:13:37,540 --> 00:13:41,290
in this realization back into the Python

00:13:39,040 --> 00:13:42,790
tool and make copies right so they

00:13:41,290 --> 00:13:46,450
thought okay it would be much nicer to

00:13:42,790 --> 00:13:48,940
have this shared memory we specify the

00:13:46,450 --> 00:13:51,820
format of the data in memory and we can

00:13:48,940 --> 00:13:54,220
just share the data set across different

00:13:51,820 --> 00:13:56,440
processes through the libraries and so

00:13:54,220 --> 00:13:58,480
the Python tool and Apache and for

00:13:56,440 --> 00:14:00,550
example an Apache spark application all

00:13:58,480 --> 00:14:02,050
of them could consume that data in the

00:14:00,550 --> 00:14:04,900
same format without moving the data at

00:14:02,050 --> 00:14:06,550
all or making any copies so of course

00:14:04,900 --> 00:14:10,690
that's a great idea they call this zero

00:14:06,550 --> 00:14:13,360
copy zero copy inter process

00:14:10,690 --> 00:14:15,340
communication and so they've chosen that

00:14:13,360 --> 00:14:17,950
to be a columnar format because it's

00:14:15,340 --> 00:14:20,230
very hard to find me in many cases that

00:14:17,950 --> 00:14:21,580
helps a lot it's better for some

00:14:20,230 --> 00:14:23,950
algorithms it's rich for others

00:14:21,580 --> 00:14:25,810
sometimes you benefit more from a robust

00:14:23,950 --> 00:14:27,940
format but this is the choice that they

00:14:25,810 --> 00:14:30,760
made and we thought that's a very good

00:14:27,940 --> 00:14:33,730
idea so our idea was to you know add a

00:14:30,760 --> 00:14:37,000
little thing which is not little anymore

00:14:33,730 --> 00:14:41,500
now that would you know give that

00:14:37,000 --> 00:14:44,170
benefit also to FPGA accelerators so

00:14:41,500 --> 00:14:46,300
this this project is more like under the

00:14:44,170 --> 00:14:48,280
hood of a lot of other projects so a lot

00:14:46,300 --> 00:14:50,740
of big data analytics framers like spark

00:14:48,280 --> 00:14:52,120
and ask for campaign as they all they're

00:14:50,740 --> 00:14:55,900
all starting to see integration the

00:14:52,120 --> 00:14:57,940
Apache arrow a lot nowadays so once all

00:14:55,900 --> 00:15:01,120
those projects have you know shifted to

00:14:57,940 --> 00:15:04,180
use this methods you know any FPGA

00:15:01,120 --> 00:15:07,500
accelerator could also unlock good

00:15:04,180 --> 00:15:10,180
access to do that platform immediately

00:15:07,500 --> 00:15:11,500
so what does it look like the error form

00:15:10,180 --> 00:15:15,430
and I'm just going to show a very simple

00:15:11,500 --> 00:15:18,700
one so there's a bunch of terminology

00:15:15,430 --> 00:15:21,040
that they use in error right so we want

00:15:18,700 --> 00:15:24,160
to store tabular data sets so here's a

00:15:21,040 --> 00:15:25,600
little table and the types of the data

00:15:24,160 --> 00:15:28,510
in the table are described through a

00:15:25,600 --> 00:15:30,400
schema and here's an example of schema

00:15:28,510 --> 00:15:32,440
so we just say okay in column a we have

00:15:30,400 --> 00:15:33,760
floats and Colombia we have something

00:15:32,440 --> 00:15:36,760
like a list of characters which is

00:15:33,760 --> 00:15:38,470
basically a string right you can have

00:15:36,760 --> 00:15:40,120
structs but you can have many other more

00:15:38,470 --> 00:15:42,190
advanced types like dictionaries and

00:15:40,120 --> 00:15:46,120
sparse and dense unions and I'm not

00:15:42,190 --> 00:15:48,310
going to go into that now and then you

00:15:46,120 --> 00:15:51,580
know so this data said once it's there

00:15:48,310 --> 00:15:54,370
in memory it's called a according to the

00:15:51,580 --> 00:15:56,650
schema it's called a record batch right

00:15:54,370 --> 00:16:00,220
so the record badge and physically has a

00:15:56,650 --> 00:16:03,220
bunch of arrays and arrays are again a

00:16:00,220 --> 00:16:05,050
combination of arrow buffers that holds

00:16:03,220 --> 00:16:06,690
all sorts of you know data and the

00:16:05,050 --> 00:16:12,460
combination of the buffers is gonna

00:16:06,690 --> 00:16:15,220
cause the record batch to you know to

00:16:12,460 --> 00:16:18,760
contain the the types that you ID that

00:16:15,220 --> 00:16:20,770
you define through the schema ID so here

00:16:18,760 --> 00:16:23,410
for example for this column of

00:16:20,770 --> 00:16:25,690
floating-point values we have two

00:16:23,410 --> 00:16:27,880
buffers why because okay you can also

00:16:25,690 --> 00:16:29,320
have something like inaudible and you

00:16:27,880 --> 00:16:32,470
can have no values in that sort of stuff

00:16:29,320 --> 00:16:35,140
so all of that all of those things are

00:16:32,470 --> 00:16:36,640
in the format and the string string

00:16:35,140 --> 00:16:38,770
looks different so it has an offset

00:16:36,640 --> 00:16:40,360
buffer for every string it points

00:16:38,770 --> 00:16:42,790
somewhere in a values buffer where the

00:16:40,360 --> 00:16:44,350
string write a string starts and so this

00:16:42,790 --> 00:16:47,470
is highly contagious if you would

00:16:44,350 --> 00:16:48,760
compare that to something like a C++

00:16:47,470 --> 00:16:51,870
string or a byte and string or something

00:16:48,760 --> 00:16:55,379
that's good that is more spread out or

00:16:51,870 --> 00:16:56,999
and throughout memory okay so so all

00:16:55,379 --> 00:16:58,470
these things we have to also you know

00:16:56,999 --> 00:17:01,259
when we want to take this to fu J we

00:16:58,470 --> 00:17:06,390
also have to support all these all these

00:17:01,259 --> 00:17:10,260
different things right so it turns out

00:17:06,390 --> 00:17:13,020
is very harder friendly well turns out

00:17:10,260 --> 00:17:15,600
you know because it's been designed like

00:17:13,020 --> 00:17:17,069
that of course it's clearly specified in

00:17:15,600 --> 00:17:19,829
memory format we cannot say this about

00:17:17,069 --> 00:17:22,039
many of the data formats that we can

00:17:19,829 --> 00:17:23,819
find in language runtimes for example

00:17:22,039 --> 00:17:25,650
the in Java

00:17:23,819 --> 00:17:28,319
there's no specification on how the data

00:17:25,650 --> 00:17:30,030
must look like in memory they'd only

00:17:28,319 --> 00:17:34,500
only specifies what sort of information

00:17:30,030 --> 00:17:35,730
should be there partially so that that's

00:17:34,500 --> 00:17:36,990
a big advantage so if you know the

00:17:35,730 --> 00:17:38,370
schema you know exactly where the data

00:17:36,990 --> 00:17:40,890
is so we can do all the pointer

00:17:38,370 --> 00:17:43,620
arithmetic find it it's highly

00:17:40,890 --> 00:17:46,049
continuous in culinary so whenever we we

00:17:43,620 --> 00:17:47,730
want to use it in the FPGA because it's

00:17:46,049 --> 00:17:50,580
so contagious we can easily stream it in

00:17:47,730 --> 00:17:52,919
right it's very useful format reductions

00:17:50,580 --> 00:17:56,669
and filters it's also parallel

00:17:52,919 --> 00:17:58,770
accessible so juices for example the

00:17:56,669 --> 00:18:00,240
offsets rather than lengths for the to

00:17:58,770 --> 00:18:03,090
figure out where strings are like we

00:18:00,240 --> 00:18:04,620
just saw and so our question was can we

00:18:03,090 --> 00:18:06,210
generate easy to use and high troop with

00:18:04,620 --> 00:18:08,880
hardware interfaces for this format

00:18:06,210 --> 00:18:12,210
automatically and of course the answer

00:18:08,880 --> 00:18:14,700
was yes right that's why we're here and

00:18:12,210 --> 00:18:16,890
so so what you usually see is an

00:18:14,700 --> 00:18:19,409
accelerator developer on FPGA usually

00:18:16,890 --> 00:18:20,909
you interface with a memory directly to

00:18:19,409 --> 00:18:22,679
a byte address and you get a bus word

00:18:20,909 --> 00:18:26,570
right and this is this is very wide

00:18:22,679 --> 00:18:30,330
nowadays 512 bits and for example snap

00:18:26,570 --> 00:18:32,669
open cap open power snap right and then

00:18:30,330 --> 00:18:34,049
you do you have to do a lot of work to

00:18:32,669 --> 00:18:36,179
make this really fast and do the thing

00:18:34,049 --> 00:18:37,320
you want right so that's a lot of work

00:18:36,179 --> 00:18:40,350
and then you can get to the

00:18:37,320 --> 00:18:42,390
computational part so I idea if with

00:18:40,350 --> 00:18:45,659
flexure was that let's just generate the

00:18:42,390 --> 00:18:47,340
interface create the streams that we at

00:18:45,659 --> 00:18:49,080
the beginning of the talk saw that we

00:18:47,340 --> 00:18:51,510
would like to get if we talk about a

00:18:49,080 --> 00:18:53,010
string or something and rather than

00:18:51,510 --> 00:18:55,169
giving byte address we just want to give

00:18:53,010 --> 00:18:56,640
table indices to the interface because

00:18:55,169 --> 00:18:58,860
then we don't have to do the pointer

00:18:56,640 --> 00:19:01,770
arithmetic ourselves and then we get the

00:18:58,860 --> 00:19:05,440
we get the streams of data back so this

00:19:01,770 --> 00:19:06,910
for us means you know that's easy to use

00:19:05,440 --> 00:19:10,750
because it's much easier than working

00:19:06,910 --> 00:19:13,510
with bytes now we actually whoops now we

00:19:10,750 --> 00:19:15,660
actually get the types of streams that

00:19:13,510 --> 00:19:18,250
we'd like to see based on the schema and

00:19:15,660 --> 00:19:20,950
the field the types of the fields in the

00:19:18,250 --> 00:19:22,660
schema and we we also wanted to make it

00:19:20,950 --> 00:19:25,210
high throughput so we wanted to make

00:19:22,660 --> 00:19:26,800
sure that you know we do get that 25

00:19:25,210 --> 00:19:29,830
gigabytes per second or something now

00:19:26,800 --> 00:19:32,650
and so we shouldn't really be limited by

00:19:29,830 --> 00:19:34,420
you know if we if we get a stream of

00:19:32,650 --> 00:19:36,640
characters if you would deliver you one

00:19:34,420 --> 00:19:39,250
character per cycle that would not be

00:19:36,640 --> 00:19:40,960
very high throughput so all the streams

00:19:39,250 --> 00:19:42,910
that you get from Fletcher well almost

00:19:40,960 --> 00:19:45,400
all of them you can also have multiple

00:19:42,910 --> 00:19:47,830
elements per cycle in those streams so

00:19:45,400 --> 00:19:51,310
it's quite involved to create this of

00:19:47,830 --> 00:19:52,750
course and so eventually we came up with

00:19:51,310 --> 00:19:56,350
the whole Fletcher architecture like

00:19:52,750 --> 00:19:58,540
this so what you do is a what you do as

00:19:56,350 --> 00:20:00,670
a developer during compilation time the

00:19:58,540 --> 00:20:02,530
top of this figure if you start with the

00:20:00,670 --> 00:20:05,290
air schema you throw this in a thing

00:20:02,530 --> 00:20:08,080
that I was playing later which is our

00:20:05,290 --> 00:20:11,620
interface generation tool then you get

00:20:08,080 --> 00:20:15,010
an HDL template or work is being done on

00:20:11,620 --> 00:20:16,720
HLS templates and you get interface

00:20:15,010 --> 00:20:18,130
sources so the schema is going to

00:20:16,720 --> 00:20:21,160
dictate to you okay what's the interface

00:20:18,130 --> 00:20:22,570
with my career accelerator kernel now

00:20:21,160 --> 00:20:24,130
you still have to implement that we

00:20:22,570 --> 00:20:26,080
don't do that for you you can use

00:20:24,130 --> 00:20:28,090
whatever tools you want whatever

00:20:26,080 --> 00:20:31,510
techniques you were used to as long as

00:20:28,090 --> 00:20:33,070
you adhere to the interface and then you

00:20:31,510 --> 00:20:35,910
synthesize place and route of course and

00:20:33,070 --> 00:20:38,290
then you get your FPGA design with the

00:20:35,910 --> 00:20:41,140
hardware accelerated function there or

00:20:38,290 --> 00:20:43,180
your hardware colonel so during one time

00:20:41,140 --> 00:20:45,640
all you have to do is you have to use

00:20:43,180 --> 00:20:47,980
the Apache our libraries the first time

00:20:45,640 --> 00:20:50,080
as soon as you load this the data from

00:20:47,980 --> 00:20:52,000
whatever source may be disk or over the

00:20:50,080 --> 00:20:53,230
network you through the Apache I rely

00:20:52,000 --> 00:20:56,350
which is stored in a memory in that

00:20:53,230 --> 00:20:59,950
format so now it's a narrow table here

00:20:56,350 --> 00:21:02,740
and then you know we've fully automate

00:20:59,950 --> 00:21:05,020
transfer of that that Aero table to the

00:21:02,740 --> 00:21:07,120
FPGA and and all you have to do is give

00:21:05,020 --> 00:21:10,360
a table index and the data streams roll

00:21:07,120 --> 00:21:14,980
out alright and they roll out fast now

00:21:10,360 --> 00:21:17,520
if you if you don't use Cappy but you

00:21:14,980 --> 00:21:19,679
don't have some sort of shared

00:21:17,520 --> 00:21:22,950
memory system then you still have to

00:21:19,679 --> 00:21:25,950
copy this this table on board to the

00:21:22,950 --> 00:21:29,580
accelerator card all right but if you

00:21:25,950 --> 00:21:32,480
use cap you can directly you know pull

00:21:29,580 --> 00:21:35,160
it into the accelerator kernel

00:21:32,480 --> 00:21:38,100
now our advance on libraries take care

00:21:35,160 --> 00:21:41,070
of that all right so this is the general

00:21:38,100 --> 00:21:43,470
overview that the framework and so I'm

00:21:41,070 --> 00:21:48,360
just gonna go really fast I I know how

00:21:43,470 --> 00:21:51,360
are we in time pretty good okay okay so

00:21:48,360 --> 00:21:53,460
not as fast then let's fast I'm gonna go

00:21:51,360 --> 00:21:55,500
over all the other components in the in

00:21:53,460 --> 00:21:55,950
the framework so we build it up from the

00:21:55,500 --> 00:21:58,620
ground

00:21:55,950 --> 00:22:02,220
we don't use any vendor IP so we have to

00:21:58,620 --> 00:22:04,170
do a lot of work it should it should be

00:22:02,220 --> 00:22:07,650
able to run on any FPGA platform

00:22:04,170 --> 00:22:10,770
basically so we basically all

00:22:07,650 --> 00:22:13,290
architecture on a pretty extensive

00:22:10,770 --> 00:22:15,270
library with stream primitives and then

00:22:13,290 --> 00:22:17,100
we use all those primitive components to

00:22:15,270 --> 00:22:20,429
build up what we call buffer readers and

00:22:17,100 --> 00:22:22,020
writers to read from the arrow buffers

00:22:20,429 --> 00:22:24,480
and work to write to the arrow buffers

00:22:22,020 --> 00:22:26,580
so combining those buffers we just saw

00:22:24,480 --> 00:22:28,830
and is in the record batch by combining

00:22:26,580 --> 00:22:30,210
buffers you turn them into arrow arrays

00:22:28,830 --> 00:22:32,580
all right so they're nazi-like

00:22:30,210 --> 00:22:35,850
areas they can be you can hold much more

00:22:32,580 --> 00:22:37,200
complex data types so the combination of

00:22:35,850 --> 00:22:40,320
both readers and writers turns into a

00:22:37,200 --> 00:22:43,290
narrow array reader and writer and that

00:22:40,320 --> 00:22:45,270
it's generated to true pure HDL up to

00:22:43,290 --> 00:22:48,210
this point and then it became a little

00:22:45,270 --> 00:22:50,280
bit more complex so to support full

00:22:48,210 --> 00:22:52,830
tables like the record matches and arrow

00:22:50,280 --> 00:22:54,510
writes and we have to combine we have to

00:22:52,830 --> 00:22:56,179
combine these readers and writers and we

00:22:54,510 --> 00:23:00,140
have to make some special tools for that

00:22:56,179 --> 00:23:03,720
because the HDL is just too limited for

00:23:00,140 --> 00:23:05,790
for that and then finally you have some

00:23:03,720 --> 00:23:07,710
sort of what we call a mental it's just

00:23:05,790 --> 00:23:09,480
a wrapper around everything that also

00:23:07,710 --> 00:23:11,190
instantiates the full bus infrastructure

00:23:09,480 --> 00:23:14,610
that's also generated based on the

00:23:11,190 --> 00:23:22,440
schema all right so we started with

00:23:14,610 --> 00:23:24,000
streaming primitives now sorry FPGA

00:23:22,440 --> 00:23:25,700
acceleration is already a bit bit of a

00:23:24,000 --> 00:23:28,230
niche of course in big data analytics

00:23:25,700 --> 00:23:30,450
we're certainly new guys of course and

00:23:28,230 --> 00:23:31,240
so we thought it would be you know most

00:23:30,450 --> 00:23:32,350
attractive for

00:23:31,240 --> 00:23:35,679
people to start breaking with a

00:23:32,350 --> 00:23:37,840
framework that we build if it's fully

00:23:35,679 --> 00:23:40,570
free and open-source so we try to do as

00:23:37,840 --> 00:23:42,790
much of the things that we do with

00:23:40,570 --> 00:23:46,900
open-source tools including simulation

00:23:42,790 --> 00:23:48,490
and so we don't use any IP because

00:23:46,900 --> 00:23:51,190
there's a lot of IP that can do these

00:23:48,490 --> 00:23:52,720
kinds of things but of course it's that

00:23:51,190 --> 00:23:58,420
that's a that's a very steep

00:23:52,720 --> 00:24:01,059
you know entry curve for people might so

00:23:58,420 --> 00:24:02,650
these you can use these in any FPGA

00:24:01,059 --> 00:24:05,980
design not only in our design right so

00:24:02,650 --> 00:24:07,630
we publish this library as well I'm not

00:24:05,980 --> 00:24:12,190
gonna go over all the components but

00:24:07,630 --> 00:24:13,929
they can do a lot of advanced stuff with

00:24:12,190 --> 00:24:15,820
with the streams to make sure that we

00:24:13,929 --> 00:24:17,290
can maximize the throughput that it can

00:24:15,820 --> 00:24:21,070
get multiple elements per cycle and

00:24:17,290 --> 00:24:22,530
stuff like that so we we use all these

00:24:21,070 --> 00:24:25,570
components and then we combine them into

00:24:22,530 --> 00:24:28,059
this these buffer readers right so this

00:24:25,570 --> 00:24:30,970
is a buffer reader for a values buffer

00:24:28,059 --> 00:24:32,470
so for example I see like array it does

00:24:30,970 --> 00:24:34,720
all the pointer arithmetic for you to

00:24:32,470 --> 00:24:37,809
figure out where is the data and to

00:24:34,720 --> 00:24:40,360
align it properly and it reshapes the

00:24:37,809 --> 00:24:42,309
stream into you know multiple elements

00:24:40,360 --> 00:24:45,880
per cycle streams according to your

00:24:42,309 --> 00:24:48,010
configuration and eventually you get a

00:24:45,880 --> 00:24:50,830
stream out of this but this might not be

00:24:48,010 --> 00:24:52,840
a usable stream for you because it's

00:24:50,830 --> 00:24:56,140
just it just reads a narrow buffer and

00:24:52,840 --> 00:25:00,400
that's not like let's say that might not

00:24:56,140 --> 00:25:02,580
be the data the same format of the data

00:25:00,400 --> 00:25:04,690
as you would expect from from the schema

00:25:02,580 --> 00:25:07,240
so sometimes we have to combine them

00:25:04,690 --> 00:25:09,190
right for example if this if a buffer

00:25:07,240 --> 00:25:11,350
you would have to read the offsets of

00:25:09,190 --> 00:25:14,140
strings we want to give you length right

00:25:11,350 --> 00:25:15,520
so so for an offset buffer we have a

00:25:14,140 --> 00:25:17,290
slightly different buffer reader and

00:25:15,520 --> 00:25:18,790
then the output is lengths but it also

00:25:17,290 --> 00:25:20,470
generates a command for the values

00:25:18,790 --> 00:25:23,080
buffer because we saw that the offsets

00:25:20,470 --> 00:25:24,309
point to wherever point to somewhere in

00:25:23,080 --> 00:25:25,900
the values buffer where the string

00:25:24,309 --> 00:25:28,000
starts and it has to start reading from

00:25:25,900 --> 00:25:31,210
there so sometimes they're combined a

00:25:28,000 --> 00:25:33,520
little bit we also have the four writers

00:25:31,210 --> 00:25:35,380
but in the end you know combining all

00:25:33,520 --> 00:25:37,300
the components and having a few

00:25:35,380 --> 00:25:43,050
different configurations we were able to

00:25:37,300 --> 00:25:45,310
support reading arrow buffers all right

00:25:43,050 --> 00:25:49,380
so then on to the next

00:25:45,310 --> 00:25:53,190
Eero artifacts which is the Aries right

00:25:49,380 --> 00:25:56,440
so by combining all these buffer readers

00:25:53,190 --> 00:25:59,350
I'm not going to show the writers in the

00:25:56,440 --> 00:26:01,210
sake of 4/6 time but by combining all

00:25:59,350 --> 00:26:03,520
the buffer readers we can support all

00:26:01,210 --> 00:26:06,010
the different arrow types right we can

00:26:03,520 --> 00:26:09,400
support strings by combining an offsets

00:26:06,010 --> 00:26:12,430
in a various buffer like we just saw we

00:26:09,400 --> 00:26:14,500
can we can support nullable floats for

00:26:12,430 --> 00:26:16,600
example by combining a buffer ear to

00:26:14,500 --> 00:26:19,240
read the values in a buffer for the

00:26:16,600 --> 00:26:23,530
other buffer that says if if a value is

00:26:19,240 --> 00:26:26,890
valid or not and then we can do structs

00:26:23,530 --> 00:26:29,170
and we could do more but I'm not gonna

00:26:26,890 --> 00:26:30,730
show those right so combining all the

00:26:29,170 --> 00:26:33,550
buffer readers to insert into every

00:26:30,730 --> 00:26:37,390
readers and so now we can support arrow

00:26:33,550 --> 00:26:40,840
arrays right so we passed the

00:26:37,390 --> 00:26:43,390
configuration of this architecture as a

00:26:40,840 --> 00:26:46,690
string in HDL and that does seek us in

00:26:43,390 --> 00:26:49,660
limits of synthesis tools we noticed so

00:26:46,690 --> 00:26:51,760
up to this level of abstraction yeah you

00:26:49,660 --> 00:26:53,080
get some recursive components and that's

00:26:51,760 --> 00:26:55,480
sort of stuff and then you know

00:26:53,080 --> 00:26:58,240
sometimes to say okay sorry

00:26:55,480 --> 00:27:00,550
now I'm gonna crash or they can say

00:26:58,240 --> 00:27:03,190
sorry but it's too recursive for me or

00:27:00,550 --> 00:27:06,310
something that depth is too it's too

00:27:03,190 --> 00:27:08,050
deep for example so up to this point of

00:27:06,310 --> 00:27:09,790
abstraction we decided okay we need

00:27:08,050 --> 00:27:10,950
something else which I'm gonna show you

00:27:09,790 --> 00:27:13,780
later

00:27:10,950 --> 00:27:15,460
so we want to test a lot of

00:27:13,780 --> 00:27:18,400
configuration strings of course because

00:27:15,460 --> 00:27:20,350
we can have a lot of crazy Aero fuel

00:27:18,400 --> 00:27:22,810
types for example you could have a list

00:27:20,350 --> 00:27:26,020
of structure of a list and an integer

00:27:22,810 --> 00:27:27,400
and then inside that blue inner list you

00:27:26,020 --> 00:27:30,010
could have a structure of an integer and

00:27:27,400 --> 00:27:31,780
a string or something so so the craziest

00:27:30,010 --> 00:27:33,520
data types you could come up with of

00:27:31,780 --> 00:27:35,800
course there's an infinite amount you

00:27:33,520 --> 00:27:38,430
could generate so we decided to you know

00:27:35,800 --> 00:27:42,970
test over 10,000 field types are just

00:27:38,430 --> 00:27:44,920
generating random field types decreasing

00:27:42,970 --> 00:27:47,260
with decreasing laxity on every level

00:27:44,920 --> 00:27:50,059
and so it turns out that it's a pretty

00:27:47,260 --> 00:27:52,879
good test to you know

00:27:50,059 --> 00:27:55,429
test all your components so we could

00:27:52,879 --> 00:27:58,580
verify and then we were sure okay now we

00:27:55,429 --> 00:28:02,799
really support the arrow average with

00:27:58,580 --> 00:28:04,789
not all the types yet but most of them

00:28:02,799 --> 00:28:06,109
so then like I said it was really

00:28:04,789 --> 00:28:08,029
challenging to get everything to

00:28:06,109 --> 00:28:09,950
synthesize and actually you know what

00:28:08,029 --> 00:28:12,499
you also want is you want syntactic

00:28:09,950 --> 00:28:15,229
syntactically pleasing interfaces for

00:28:12,499 --> 00:28:19,909
your kernel and there's not a nice way

00:28:15,229 --> 00:28:21,830
to rename ports in HDL itself like where

00:28:19,909 --> 00:28:24,589
you could say oh I'm just gonna rename

00:28:21,830 --> 00:28:26,269
my port using some HDL itself alright so

00:28:24,589 --> 00:28:30,979
we had to come up with something better

00:28:26,269 --> 00:28:34,099
and for that because we want a group

00:28:30,979 --> 00:28:38,109
array readers and writers in to record

00:28:34,099 --> 00:28:40,369
batch readers and writers right we wanna

00:28:38,109 --> 00:28:43,969
have the stream names to correspond to

00:28:40,369 --> 00:28:47,690
schema fields synthesized by geo was to

00:28:43,969 --> 00:28:49,099
live in it like I said and also we

00:28:47,690 --> 00:28:50,929
wanted to generate the current templates

00:28:49,099 --> 00:28:53,119
of course we wanted to include some

00:28:50,929 --> 00:28:55,609
simulation and platform integration so

00:28:53,119 --> 00:28:58,009
in the end we created a tool called

00:28:55,609 --> 00:29:03,589
Fletch and this is the command line to

00:28:58,009 --> 00:29:05,330
show later alright so after we created

00:29:03,589 --> 00:29:07,969
this tool it's just unpublished work

00:29:05,330 --> 00:29:10,219
maybe at some point we will put

00:29:07,969 --> 00:29:11,899
something out there but it's all open

00:29:10,219 --> 00:29:14,299
source you can check it out right now we

00:29:11,899 --> 00:29:17,089
should also support record batches okay

00:29:14,299 --> 00:29:23,299
so great we're done right we support all

00:29:17,089 --> 00:29:24,919
of arrow in FPGA now alright so there's

00:29:23,299 --> 00:29:26,299
another component of course because

00:29:24,919 --> 00:29:28,669
during runtime you also want to have

00:29:26,299 --> 00:29:29,690
that easy integration for programmers

00:29:28,669 --> 00:29:32,719
for software programmer

00:29:29,690 --> 00:29:34,339
so there's a pretty big stack that you

00:29:32,719 --> 00:29:36,619
know it starts with a Python application

00:29:34,339 --> 00:29:38,389
and that can interface with a flasher

00:29:36,619 --> 00:29:42,109
Python runtime so for c plus we have a

00:29:38,389 --> 00:29:43,549
c++ runtime and if we support more

00:29:42,109 --> 00:29:45,409
languages of course for whatever

00:29:43,549 --> 00:29:49,119
language we could have runtime for that

00:29:45,409 --> 00:29:52,099
language and that gives you some control

00:29:49,119 --> 00:29:55,759
that allows you to do some control flow

00:29:52,099 --> 00:29:59,450
with the fpga and to exit the control

00:29:55,759 --> 00:30:02,229
pad path to the FPGA that all comes

00:29:59,450 --> 00:30:05,139
together in a C API and

00:30:02,229 --> 00:30:07,029
you know and and then you get platform

00:30:05,139 --> 00:30:11,080
support on the hardware side so we

00:30:07,029 --> 00:30:13,599
support AWS ec2 f1 it's a bit older the

00:30:11,080 --> 00:30:15,159
support for that but we are current

00:30:13,599 --> 00:30:17,440
version does support the latest version

00:30:15,159 --> 00:30:21,909
of snap so that's more interesting for

00:30:17,440 --> 00:30:24,159
people that are using open power and you

00:30:21,909 --> 00:30:28,479
know you could add your own platform to

00:30:24,159 --> 00:30:30,999
Fletcher just shoot us a pull request so

00:30:28,479 --> 00:30:33,099
you know then there's a lot of platform

00:30:30,999 --> 00:30:35,909
specific stuff but in the end you know

00:30:33,099 --> 00:30:39,129
if you have an ax eye for a light

00:30:35,909 --> 00:30:41,799
interface for to set some registers and

00:30:39,129 --> 00:30:43,719
if you have an ax eye for full interface

00:30:41,799 --> 00:30:46,239
for the memory axes then we can connect

00:30:43,719 --> 00:30:48,249
to your platform I so the nice thing

00:30:46,239 --> 00:30:50,169
about this is that you know if you're

00:30:48,249 --> 00:30:52,179
lucky you can create one accelerator and

00:30:50,169 --> 00:30:53,679
then connect it to any of these

00:30:52,179 --> 00:30:55,570
languages right so that's a big

00:30:53,679 --> 00:30:58,539
advantage because we're using an arrow

00:30:55,570 --> 00:31:00,159
as a standardized format and arrow has

00:30:58,539 --> 00:31:05,769
support for way more language than we

00:31:00,159 --> 00:31:07,989
support already all right so just to

00:31:05,769 --> 00:31:12,789
show you how easy it is now might get

00:31:07,989 --> 00:31:15,639
easier later just a little mini tutorial

00:31:12,789 --> 00:31:17,679
like our hello world example it's a

00:31:15,639 --> 00:31:19,239
relatively trivial example just sums a

00:31:17,679 --> 00:31:21,279
column of integers so here we have some

00:31:19,239 --> 00:31:23,679
integers we have a really easy record

00:31:21,279 --> 00:31:25,389
bash there's only one array there's just

00:31:23,679 --> 00:31:28,359
some integers here and then we just want

00:31:25,389 --> 00:31:30,369
to sum it and get this result out yeah

00:31:28,359 --> 00:31:32,409
of course this is not a real you know a

00:31:30,369 --> 00:31:34,179
good example for a big data application

00:31:32,409 --> 00:31:36,909
where you would have way more complex

00:31:34,179 --> 00:31:39,339
types and more arrays and way more

00:31:36,909 --> 00:31:41,200
record batches at the same time inputs

00:31:39,339 --> 00:31:43,989
and outputs but we just want to show you

00:31:41,200 --> 00:31:45,519
like the tool chain right so not not

00:31:43,989 --> 00:31:47,190
necessarily something that's very useful

00:31:45,519 --> 00:31:49,599
but just to get to know the tool chain

00:31:47,190 --> 00:31:52,570
so this tutorial should available and

00:31:49,599 --> 00:31:55,570
get up you can just go to our github

00:31:52,570 --> 00:31:57,849
page and see exactly the same stuff that

00:31:55,570 --> 00:31:59,529
I'm going to tell you now and it works

00:31:57,849 --> 00:32:02,049
on your laptop up to step four or

00:31:59,529 --> 00:32:04,089
something so the first step is we have

00:32:02,049 --> 00:32:06,410
to create an arrow schema and you can do

00:32:04,089 --> 00:32:08,510
that in many ways

00:32:06,410 --> 00:32:10,910
this is an example how you can do it in

00:32:08,510 --> 00:32:12,890
Python because that's just the shortest

00:32:10,910 --> 00:32:15,860
thing we support right now which is

00:32:12,890 --> 00:32:19,700
import by arrow that's the Python arrow

00:32:15,860 --> 00:32:21,350
library we have to define a fuel for our

00:32:19,700 --> 00:32:23,360
scheme alright so we just saw that

00:32:21,350 --> 00:32:26,930
there's a number array so we call that

00:32:23,360 --> 00:32:28,730
number and then it's an in 64 type we

00:32:26,930 --> 00:32:31,520
don't make it nullable so all the values

00:32:28,730 --> 00:32:33,680
are always valid all right and then we

00:32:31,520 --> 00:32:36,620
throw that in that field we throw that

00:32:33,680 --> 00:32:38,960
into a new schema that we just call

00:32:36,620 --> 00:32:41,450
schema and then we have to add some

00:32:38,960 --> 00:32:44,420
specific metadata for Fletcher to make

00:32:41,450 --> 00:32:46,520
this - for it to be able to generate

00:32:44,420 --> 00:32:47,960
hardware from the schema so because

00:32:46,520 --> 00:32:49,760
schemas don't have names or something in

00:32:47,960 --> 00:32:52,160
arrow and we're gonna generate hardware

00:32:49,760 --> 00:32:53,630
interfaces that need names right so we

00:32:52,160 --> 00:32:55,010
have to add a name and we also have to

00:32:53,630 --> 00:32:58,730
tell Fletcher if it has to read or

00:32:55,010 --> 00:33:01,280
rights to a record batch that you create

00:32:58,730 --> 00:33:02,720
from the schema so you add the metadata

00:33:01,280 --> 00:33:05,330
and you're done you just have to save it

00:33:02,720 --> 00:33:09,860
to to a file and this is how it works

00:33:05,330 --> 00:33:11,930
for Python right pretty pretty short now

00:33:09,860 --> 00:33:15,080
what you can do optionally for

00:33:11,930 --> 00:33:17,420
simulation you could also put data in a

00:33:15,080 --> 00:33:20,300
record batch based on the schema so here

00:33:17,420 --> 00:33:23,930
the values that I showed on for step 1

00:33:20,300 --> 00:33:26,360
are here 1 - 3 etc alright so we create

00:33:23,930 --> 00:33:28,790
a little PI arrow array with these

00:33:26,360 --> 00:33:29,240
values then we put that in a record

00:33:28,790 --> 00:33:31,700
batch

00:33:29,240 --> 00:33:33,830
according to the schema so my error is

00:33:31,700 --> 00:33:36,470
going to check if the if that data

00:33:33,830 --> 00:33:37,910
actually fits with the schema and then

00:33:36,470 --> 00:33:40,490
we're just gonna create a record bad

00:33:37,910 --> 00:33:42,110
shot of that with two lines of Python we

00:33:40,490 --> 00:33:43,190
just write that to a file and the nice

00:33:42,110 --> 00:33:45,620
thing is this lecture can take this

00:33:43,190 --> 00:33:48,500
record batch and it can generate a

00:33:45,620 --> 00:33:50,990
simulation model for you and it will you

00:33:48,500 --> 00:33:53,570
know if everything works directly on the

00:33:50,990 --> 00:33:55,130
output stream of you're going to your

00:33:53,570 --> 00:33:57,140
kernel you will see this this data

00:33:55,130 --> 00:34:00,170
appear so it's really nice because then

00:33:57,140 --> 00:34:05,270
you can do some functional testing in

00:34:00,170 --> 00:34:08,110
in simulation now we use this tool

00:34:05,270 --> 00:34:10,850
flexion right so it has some parameters

00:34:08,110 --> 00:34:11,919
looks a bit boring of course so it's

00:34:10,850 --> 00:34:14,030
just a cool name

00:34:11,919 --> 00:34:17,510
the record match input file that we just

00:34:14,030 --> 00:34:21,440
created an output file that's the memory

00:34:17,510 --> 00:34:23,540
model for our simulator you can put do

00:34:21,440 --> 00:34:26,480
the design you can set the design output

00:34:23,540 --> 00:34:29,360
languages so we currently support VHDL I

00:34:26,480 --> 00:34:33,470
know I mean I know I'm in u.s. so sorry

00:34:29,360 --> 00:34:34,700
for that but that should be if you you

00:34:33,470 --> 00:34:37,130
know feel free to add a very log

00:34:34,700 --> 00:34:39,890
back-end but we also have this dots

00:34:37,130 --> 00:34:41,570
back-end that generates a graphical view

00:34:39,890 --> 00:34:43,010
of the whole design for you so that's

00:34:41,570 --> 00:34:47,390
kind of nice for documentation purposes

00:34:43,010 --> 00:34:48,740
and we also give this flag to say okay

00:34:47,390 --> 00:34:51,290
we want to have a simulation top-level

00:34:48,740 --> 00:34:53,590
right so this is the kind of this is

00:34:51,290 --> 00:34:56,570
actually this design for the tutorial

00:34:53,590 --> 00:34:58,130
that you get a dot graph like I said so

00:34:56,570 --> 00:35:00,200
that's just a visual representation of

00:34:58,130 --> 00:35:02,540
all the streams in the design so it's

00:35:00,200 --> 00:35:04,040
kind of nice you know I can do much we

00:35:02,540 --> 00:35:05,780
can do much larger designs then we look

00:35:04,040 --> 00:35:08,360
like this I don't know how clear that is

00:35:05,780 --> 00:35:10,540
anymore but there's some options there

00:35:08,360 --> 00:35:13,400
to make it simpler look simpler or more

00:35:10,540 --> 00:35:16,160
complicated or to hide some some

00:35:13,400 --> 00:35:18,080
complicated stuff alright so after we've

00:35:16,160 --> 00:35:19,880
done then we get we got all this this

00:35:18,080 --> 00:35:22,760
feech the out code right we're not going

00:35:19,880 --> 00:35:27,050
to go and look at that we don't want to

00:35:22,760 --> 00:35:28,400
cry so and then you implement the kernel

00:35:27,050 --> 00:35:30,470
so you start from the template you get

00:35:28,400 --> 00:35:32,690
in this case if each DL template right

00:35:30,470 --> 00:35:36,560
and you can use your favorite tools you

00:35:32,690 --> 00:35:38,630
can use custom a GL or F avada HLS we

00:35:36,560 --> 00:35:40,550
will have integration in progress or any

00:35:38,630 --> 00:35:42,980
anything else as long as you adhere to

00:35:40,550 --> 00:35:46,540
the specification of how to use our

00:35:42,980 --> 00:35:50,450
streams which is like axis X I streams

00:35:46,540 --> 00:35:51,920
now and then you have some so these are

00:35:50,450 --> 00:35:54,440
the interface that you've seen on your

00:35:51,920 --> 00:35:56,390
kernel in a xif for light for mm IO

00:35:54,440 --> 00:35:59,510
registers because you always want to set

00:35:56,390 --> 00:36:01,520
some constants or whatever and control

00:35:59,510 --> 00:36:03,740
your kernel and then you get a command

00:36:01,520 --> 00:36:05,570
stream to towards the generated

00:36:03,740 --> 00:36:07,400
interface the Flex your build for you so

00:36:05,570 --> 00:36:09,310
you can issue a command like I want to

00:36:07,400 --> 00:36:11,360
get all the strings from this range or I

00:36:09,310 --> 00:36:12,510
want to get in this case all the

00:36:11,360 --> 00:36:14,640
integers and the record

00:36:12,510 --> 00:36:18,060
or something and then you get the data

00:36:14,640 --> 00:36:19,859
stream back and then you can simulate

00:36:18,060 --> 00:36:22,020
the design so we have we built a little

00:36:19,859 --> 00:36:24,750
tool because you know we have a guy that

00:36:22,020 --> 00:36:29,640
is very good at building very nice tools

00:36:24,750 --> 00:36:32,790
I saw with one line of well one

00:36:29,640 --> 00:36:34,859
recommend line command we can actually

00:36:32,790 --> 00:36:36,930
start simulating already right so the

00:36:34,859 --> 00:36:39,270
most most of the work is in implementing

00:36:36,930 --> 00:36:43,220
the kernels still but at least now we

00:36:39,270 --> 00:36:46,830
have an interface that's very usable so

00:36:43,220 --> 00:36:48,660
we just give the path to the hardware

00:36:46,830 --> 00:36:52,310
libraries and we say we want to use G

00:36:48,660 --> 00:36:54,330
HDL this is a free and open source

00:36:52,310 --> 00:36:56,670
simulator so you don't even need any

00:36:54,330 --> 00:37:00,650
vendor tools up to this point it doesn't

00:36:56,670 --> 00:37:02,640
really have you can get waveforms but it

00:37:00,650 --> 00:37:04,650
it's not integrated with this tool

00:37:02,640 --> 00:37:06,240
itself but you could also do like quests

00:37:04,650 --> 00:37:09,600
the same or fishing or something and

00:37:06,240 --> 00:37:12,060
then you would get this visual

00:37:09,600 --> 00:37:16,500
representation of your waveforms for GCL

00:37:12,060 --> 00:37:18,420
you just get this output alright so then

00:37:16,500 --> 00:37:19,590
you say well what do you want to

00:37:18,420 --> 00:37:21,240
assimilate right so this is the

00:37:19,590 --> 00:37:23,490
simulation top level that flashin

00:37:21,240 --> 00:37:26,460
generated automatically for you that

00:37:23,490 --> 00:37:27,990
that took you less than a second so then

00:37:26,460 --> 00:37:30,780
you can run the simulation and you can

00:37:27,990 --> 00:37:33,810
see here in the waveform it's more

00:37:30,780 --> 00:37:35,369
interesting I think than this part so in

00:37:33,810 --> 00:37:36,690
the waveform for quest the same for

00:37:35,369 --> 00:37:38,520
example you can you can actually see

00:37:36,690 --> 00:37:40,890
that you know I called my record bad

00:37:38,520 --> 00:37:45,000
example badge I called my area number

00:37:40,890 --> 00:37:46,680
right so I can see the same identifiers

00:37:45,000 --> 00:37:49,200
that I used in my error schema here in

00:37:46,680 --> 00:37:51,060
the hardware and I actually see that

00:37:49,200 --> 00:37:51,630
data that I put in the record badge in

00:37:51,060 --> 00:37:53,369
Python

00:37:51,630 --> 00:37:56,580
I see that appearing here in simulation

00:37:53,369 --> 00:37:59,010
and so you know this has summed up in

00:37:56,580 --> 00:38:03,180
this kernel onion the the answer is

00:37:59,010 --> 00:38:06,359
minus six so that works pretty well so

00:38:03,180 --> 00:38:08,010
up to up to this point so step five you

00:38:06,359 --> 00:38:12,960
can do everything or laptop without any

00:38:08,010 --> 00:38:16,410
vendor tools so then you if you really

00:38:12,960 --> 00:38:18,090
want to run it on a platform and I can

00:38:16,410 --> 00:38:20,550
recommend Kappa snap because writing

00:38:18,090 --> 00:38:23,609
host side software you know the hardware

00:38:20,550 --> 00:38:25,440
software code design is really nice on

00:38:23,609 --> 00:38:26,500
snap right you can write the same

00:38:25,440 --> 00:38:29,480
software you

00:38:26,500 --> 00:38:33,410
for your simulation as as you write for

00:38:29,480 --> 00:38:35,780
your actual hardware runtime so this is

00:38:33,410 --> 00:38:38,170
an example of what you have to do on the

00:38:35,780 --> 00:38:41,180
software side right so you import our

00:38:38,170 --> 00:38:43,160
invitin again you can import PI fletcher

00:38:41,180 --> 00:38:45,320
which is our python library for this

00:38:43,160 --> 00:38:47,540
project you don't have to do a lot of

00:38:45,320 --> 00:38:50,500
things this might already for python

00:38:47,540 --> 00:38:52,820
programmers be relatively low-level

00:38:50,500 --> 00:38:54,430
but you could extract that a little bit

00:38:52,820 --> 00:38:57,859
more you just have to create a

00:38:54,430 --> 00:38:59,990
initialized platform in our case that's

00:38:57,859 --> 00:39:01,730
going to be snap right and then you

00:38:59,990 --> 00:39:04,220
create a context for your record batch

00:39:01,730 --> 00:39:06,589
to live in in the in memory of the that

00:39:04,220 --> 00:39:08,660
is accessible to the FPGA you enable the

00:39:06,589 --> 00:39:10,760
context and that means that from that

00:39:08,660 --> 00:39:12,020
point onwards the record batch is all

00:39:10,760 --> 00:39:15,230
your data is going to be available to

00:39:12,020 --> 00:39:17,480
your FPGA kernel and then you can

00:39:15,230 --> 00:39:18,980
control the kernel by creating a kernel

00:39:17,480 --> 00:39:20,570
on top of that context and you just

00:39:18,980 --> 00:39:23,420
start it and you wait for it to finish

00:39:20,570 --> 00:39:25,070
and if you're lucky of course the answer

00:39:23,420 --> 00:39:29,930
for this example minus six you can roll

00:39:25,070 --> 00:39:32,089
out and then eventually you can you can

00:39:29,930 --> 00:39:35,390
target the platform right so we have

00:39:32,089 --> 00:39:39,170
support for open power Capetian app and

00:39:35,390 --> 00:39:40,730
for this platform you know this context

00:39:39,170 --> 00:39:42,500
enable that we just saw on the previous

00:39:40,730 --> 00:39:44,810
slide let me show it to you one more

00:39:42,500 --> 00:39:46,339
time this is when actually normally

00:39:44,810 --> 00:39:47,599
there's gonna be some data transferring

00:39:46,339 --> 00:39:49,520
so we're gonna transfer all the arrow

00:39:47,599 --> 00:39:52,310
buffers to the onboard memory of the

00:39:49,520 --> 00:39:54,530
FPGA accelerator card but actually for

00:39:52,310 --> 00:39:56,660
snap of course because it's using capi

00:39:54,530 --> 00:40:01,970
we don't have to do anything we just

00:39:56,660 --> 00:40:03,890
pass a few addresses and then the FPGA

00:40:01,970 --> 00:40:07,220
can access the buffers on those as

00:40:03,890 --> 00:40:08,810
addresses and you know and like I said

00:40:07,220 --> 00:40:11,599
there's excellent harvest off

00:40:08,810 --> 00:40:13,640
co-simulation I too can get pretty high

00:40:11,599 --> 00:40:16,430
throughput for capi 2.0 we get for

00:40:13,640 --> 00:40:17,900
example 11-game this figure is wrong so

00:40:16,430 --> 00:40:20,720
it has to be ten gigabytes per second

00:40:17,900 --> 00:40:22,910
for an example where we did reading

00:40:20,720 --> 00:40:24,500
strings for example that's pretty high

00:40:22,910 --> 00:40:27,760
to put also for writing strings we could

00:40:24,500 --> 00:40:30,020
get like 10 gigabytes per second

00:40:27,760 --> 00:40:33,290
well we already had this working for

00:40:30,020 --> 00:40:35,540
capi 1.0 so a very nice thing that we

00:40:33,290 --> 00:40:37,369
saw was when we switch to copy 2.0 that

00:40:35,540 --> 00:40:39,770
was pretty seamless we didn't have to do

00:40:37,369 --> 00:40:44,390
anything just tell

00:40:39,770 --> 00:40:45,560
snap that we wanted to use copy 2.0 so

00:40:44,390 --> 00:40:50,680
we hope this will be the same for open

00:40:45,560 --> 00:40:53,270
copy gotta look at the snap thing here

00:40:50,680 --> 00:40:54,619
and actually this hello world example

00:40:53,270 --> 00:40:56,900
that I just show you

00:40:54,619 --> 00:40:58,970
you can run it on Nimbus so if you want

00:40:56,900 --> 00:41:01,339
to do this please come talk to me after

00:40:58,970 --> 00:41:03,349
the talk then we can maybe you know talk

00:41:01,339 --> 00:41:06,710
about how we how we can collaborate on

00:41:03,349 --> 00:41:11,420
that yeah we also support this platform

00:41:06,710 --> 00:41:13,550
but it's the support is a bit old so

00:41:11,420 --> 00:41:15,410
there's a lot of spin-off projects in

00:41:13,550 --> 00:41:19,849
our group based on this framework you

00:41:15,410 --> 00:41:21,109
have a bunch of future work coming up so

00:41:19,849 --> 00:41:23,359
I just want to talk about the spin-off

00:41:21,109 --> 00:41:24,740
projects so it's a continued development

00:41:23,359 --> 00:41:26,839
effort in your group especially Mattias

00:41:24,740 --> 00:41:30,349
who's sitting over there is working hard

00:41:26,839 --> 00:41:32,180
on that and we have a few master

00:41:30,349 --> 00:41:34,910
students or large vitamins he worked on

00:41:32,180 --> 00:41:36,710
dynamic arab buffers in hardware so

00:41:34,910 --> 00:41:38,750
especially for the right path so if

00:41:36,710 --> 00:41:40,670
you're writing data into a narrow data

00:41:38,750 --> 00:41:43,670
structure in memory you sometimes you

00:41:40,670 --> 00:41:45,740
want to have dynamic buffers right you

00:41:43,670 --> 00:41:46,790
want to be able to resize them as you go

00:41:45,740 --> 00:41:49,099
because you don't know what their

00:41:46,790 --> 00:41:50,510
eventual size is gonna be for example if

00:41:49,099 --> 00:41:53,540
you have some filter operation or

00:41:50,510 --> 00:41:55,730
something something that Aaron is going

00:41:53,540 --> 00:41:57,859
to talk about later today you don't know

00:41:55,730 --> 00:41:59,089
what the actual buffer size has to be

00:41:57,859 --> 00:42:00,710
later and so you need some sort of

00:41:59,089 --> 00:42:03,140
support for that in hardware so large

00:42:00,710 --> 00:42:06,140
worked on that I'll show you on the next

00:42:03,140 --> 00:42:07,460
slide we have another Lars who worked on

00:42:06,140 --> 00:42:10,250
parquet to arrow decoder and

00:42:07,460 --> 00:42:14,210
decompressor so we're gonna get some

00:42:10,250 --> 00:42:15,859
data may be from a foul that flows

00:42:14,210 --> 00:42:17,240
through the FPGA it doesn't even hit in

00:42:15,859 --> 00:42:19,970
memory and then you're actually

00:42:17,240 --> 00:42:22,220
decompressing that file and decoding

00:42:19,970 --> 00:42:25,520
that file into an arrow in memory data

00:42:22,220 --> 00:42:27,050
structure on the fly you might even want

00:42:25,520 --> 00:42:28,970
to combine that with filtering but I

00:42:27,050 --> 00:42:33,020
think everyone will say some more things

00:42:28,970 --> 00:42:34,460
about that later all right so yeah we

00:42:33,020 --> 00:42:37,520
can do all sorts of interesting things

00:42:34,460 --> 00:42:39,290
with the framework that we build so we

00:42:37,520 --> 00:42:41,089
want to do runtime profiling of the data

00:42:39,290 --> 00:42:41,900
streams and then we want actually want

00:42:41,089 --> 00:42:45,010
to do

00:42:41,900 --> 00:42:47,330
we want to automatically improve the

00:42:45,010 --> 00:42:49,760
generated interface you know while we

00:42:47,330 --> 00:42:52,040
were running it sure your your cluster

00:42:49,760 --> 00:42:53,420
with FPGA is running and it's gonna get

00:42:52,040 --> 00:42:58,880
better you don't even have to do

00:42:53,420 --> 00:43:00,770
anything so this is an image of what la

00:42:58,880 --> 00:43:03,560
vie de mons is doing on dynamic Aero

00:43:00,770 --> 00:43:07,640
buffers in hardware so he's really

00:43:03,560 --> 00:43:10,220
working on you know this is what it

00:43:07,640 --> 00:43:13,390
looks like for copy she had the host R

00:43:10,220 --> 00:43:15,710
and P cell interconnect and then your

00:43:13,390 --> 00:43:18,560
your Arab readers and writers here's

00:43:15,710 --> 00:43:22,070
called column reader writer and so he's

00:43:18,560 --> 00:43:24,350
gonna add a virtual virtualization and

00:43:22,070 --> 00:43:25,430
memory virtual layer to that three

00:43:24,350 --> 00:43:27,560
moments okay good

00:43:25,430 --> 00:43:30,230
so more interesting work this is the

00:43:27,560 --> 00:43:33,680
work I was talking about so Parkay is an

00:43:30,230 --> 00:43:36,500
in-memory sorry in a disk format for for

00:43:33,680 --> 00:43:38,810
big data and so large this kind of work

00:43:36,500 --> 00:43:40,430
on decoding that he built a whole nice

00:43:38,810 --> 00:43:42,470
hardware structure I think his master

00:43:40,430 --> 00:43:44,990
teachers will pop up in our university

00:43:42,470 --> 00:43:47,050
repository very soon and so you could

00:43:44,990 --> 00:43:51,320
read all about that

00:43:47,050 --> 00:43:52,880
so summary big data systems are getting

00:43:51,320 --> 00:43:55,700
increasingly hit Regine's

00:43:52,880 --> 00:43:58,730
so many different tools many different

00:43:55,700 --> 00:44:01,490
technologies and we need some solutions

00:43:58,730 --> 00:44:04,160
for that right to to make the inter

00:44:01,490 --> 00:44:06,680
process communication less contain less

00:44:04,160 --> 00:44:08,660
overhead so the folks at the patch ero

00:44:06,680 --> 00:44:11,260
have have done a great job to do that

00:44:08,660 --> 00:44:14,570
right one in memory formats for any

00:44:11,260 --> 00:44:16,600
component and then we do inter process

00:44:14,570 --> 00:44:19,100
communication through shared memory

00:44:16,600 --> 00:44:22,010
now if lecture enables you to use that

00:44:19,100 --> 00:44:23,570
standardized format and generate you

00:44:22,010 --> 00:44:26,150
know hydro boots easy to use hardware

00:44:23,570 --> 00:44:28,070
interfaces for FPGA and then that paves

00:44:26,150 --> 00:44:30,200
the way for more efficient FPGA

00:44:28,070 --> 00:44:32,510
accelerator integration with any of the

00:44:30,200 --> 00:44:35,690
supported software languages so this is

00:44:32,510 --> 00:44:37,850
the link to the to the repository but if

00:44:35,690 --> 00:44:39,680
you just type flat your FPGA or

00:44:37,850 --> 00:44:42,200
something in Google you you'll also find

00:44:39,680 --> 00:44:43,640
it and here are the references and some

00:44:42,200 --> 00:44:46,130
example projects and exist in

00:44:43,640 --> 00:44:48,800
applications that we did with this

00:44:46,130 --> 00:44:51,160
framework so thank you very much for

00:44:48,800 --> 00:44:51,160
your attention

00:44:51,430 --> 00:44:56,330
[Applause]

00:45:07,250 --> 00:45:12,049
so the question is if if I've seen any

00:45:10,029 --> 00:45:14,990
limitations to the size of the data set

00:45:12,049 --> 00:45:15,950
coming so actually if the the size of

00:45:14,990 --> 00:45:18,500
the data set is small

00:45:15,950 --> 00:45:20,690
yeah then we see some limitations

00:45:18,500 --> 00:45:22,940
because yeah delay that there is still

00:45:20,690 --> 00:45:24,319
some latency in doing everything and we

00:45:22,940 --> 00:45:25,760
haven't really optimized for latency

00:45:24,319 --> 00:45:27,680
right something like that so if you have

00:45:25,760 --> 00:45:29,960
many small record budget or something

00:45:27,680 --> 00:45:31,520
that wouldn't work too well but in

00:45:29,960 --> 00:45:41,000
general the bigger the data sets the

00:45:31,520 --> 00:45:44,690
better yeah yeah that's also a thing

00:45:41,000 --> 00:45:46,430
right so yeah so an advantage of capi is

00:45:44,690 --> 00:45:48,589
you know we don't have to make a copy at

00:45:46,430 --> 00:45:50,029
all right we don't have to and we also

00:45:48,589 --> 00:45:51,859
don't have to be used in memory so that

00:45:50,029 --> 00:45:54,319
would that could be a solution for other

00:45:51,859 --> 00:45:56,150
platforms but you know some people don't

00:45:54,319 --> 00:45:56,580
like that for a specific reasons of

00:45:56,150 --> 00:45:59,710
course

00:45:56,580 --> 00:45:59,710
[Music]

00:46:12,900 --> 00:46:17,700
okay so so the question is if there's

00:46:15,339 --> 00:46:20,739
any optimization for sparse data right

00:46:17,700 --> 00:46:22,329
so this is not something that we have to

00:46:20,739 --> 00:46:25,329
take care of this is already taken care

00:46:22,329 --> 00:46:28,559
of I think in the Apache arrow in memory

00:46:25,329 --> 00:46:32,019
format itself right because it has these

00:46:28,559 --> 00:46:33,910
nolo any field type is inaudible and so

00:46:32,019 --> 00:46:37,180
it doesn't take up any storage space if

00:46:33,910 --> 00:46:39,519
the if there's missing data in right

00:46:37,180 --> 00:46:42,309
it only takes up one bit of storage

00:46:39,519 --> 00:46:44,259
space in a fluidity buffer so I don't

00:46:42,309 --> 00:46:50,309
know if that answers your question or if

00:46:44,259 --> 00:46:50,309
you sorry okay yeah sure okay

00:46:59,620 --> 00:47:01,860

YouTube URL: https://www.youtube.com/watch?v=qkaQQu1bHcI


