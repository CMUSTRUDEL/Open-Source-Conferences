Title: OpenPOWER Summit NA 2019: Pack-em or Stack-em: Advantages of Running OpenShift on Power
Publication date: 2019-08-20
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Krishna Harsha Voora, IBM

In this session, you will hear about the (container density, pod scaling) tests we performed with  OpenShift Container Platform (OCP) and compared different architectures. You will ascertain the effectiveness of using POWER Systems with OpenShift Container Platform which can host most containers or pods without performance degradation compared to other platforms.  A  “DevOps” scenario with a workload similar to a  MEAN  stack (Mongo,  Express, Angular,  and  Node) is selected.  The workload was purposeful to further demonstrate the price-performance advantage of using OpenShift with POWER Platform.
Captions: 
	00:00:00,030 --> 00:00:07,830
right hi everyone good morning thanks

00:00:04,200 --> 00:00:09,179
for making it to the session you know

00:00:07,830 --> 00:00:11,429
probably looking at the title you would

00:00:09,179 --> 00:00:13,650
think that this is kind of Xing slang to

00:00:11,429 --> 00:00:15,450
it but you know don't presume by I'm

00:00:13,650 --> 00:00:18,420
from Texas let me take this opportunity

00:00:15,450 --> 00:00:21,240
to introduce myself my name is krishna

00:00:18,420 --> 00:00:23,810
raja vira I work as a software developer

00:00:21,240 --> 00:00:27,740
in IBM software India development labs

00:00:23,810 --> 00:00:29,490
in this role I primarily help ISPs or

00:00:27,740 --> 00:00:33,360
independent software vendors and

00:00:29,490 --> 00:00:36,480
business partners and move them to the

00:00:33,360 --> 00:00:38,700
next one particle system by doing

00:00:36,480 --> 00:00:41,190
validation and benchmarking exercises

00:00:38,700 --> 00:00:43,260
and I also evangelize blockchain as a

00:00:41,190 --> 00:00:45,600
technology at various forums meetups and

00:00:43,260 --> 00:00:46,860
conferences my colleague meet in her

00:00:45,600 --> 00:00:49,020
chair who couldn't make it here to the

00:00:46,860 --> 00:00:51,570
summit is is a technical enablement

00:00:49,020 --> 00:00:53,910
specialist or a consultant he also works

00:00:51,570 --> 00:00:59,370
on enabling ISPs and business partners

00:00:53,910 --> 00:01:01,410
onto our Linux on power ecosystem taking

00:00:59,370 --> 00:01:03,180
a quick look at and then at the glimpse

00:01:01,410 --> 00:01:05,339
at how we are gonna spend the next 30 to

00:01:03,180 --> 00:01:07,350
40 minutes I will be touch basing on few

00:01:05,339 --> 00:01:10,020
of the focus areas that I will be

00:01:07,350 --> 00:01:11,580
talking to today one of them is IBM and

00:01:10,020 --> 00:01:14,130
redyed partnership this has nothing to

00:01:11,580 --> 00:01:15,960
do with the acquisition or merger that

00:01:14,130 --> 00:01:18,180
have happened I'm just gonna touch base

00:01:15,960 --> 00:01:20,130
on how in the open source world how

00:01:18,180 --> 00:01:22,500
beautiful things either meant that had

00:01:20,130 --> 00:01:25,650
have done together to benefit ten

00:01:22,500 --> 00:01:26,909
customers I'll touch base on the

00:01:25,650 --> 00:01:29,130
overview of open shift

00:01:26,909 --> 00:01:31,310
which is a Red Hat's product and then

00:01:29,130 --> 00:01:33,479
different use cases or

00:01:31,310 --> 00:01:35,520
workloads that could be targeted to run

00:01:33,479 --> 00:01:36,869
on open shift and then probably I will

00:01:35,520 --> 00:01:39,720
give you a brief introduction on power

00:01:36,869 --> 00:01:41,640
line processor family and I'll spend

00:01:39,720 --> 00:01:43,710
considerable amount of time on the

00:01:41,640 --> 00:01:45,180
objective and the workload that we have

00:01:43,710 --> 00:01:47,369
picked up for this particular

00:01:45,180 --> 00:01:50,549
performance case study and if time

00:01:47,369 --> 00:01:52,590
permits we are gonna show you a can demo

00:01:50,549 --> 00:01:56,009
where and I'll be spinning up one

00:01:52,590 --> 00:01:58,049
application on top of open shipped and

00:01:56,009 --> 00:02:05,100
try to simulate some workload on top of

00:01:58,049 --> 00:02:07,680
it IBM Android hat have coexisted in the

00:02:05,100 --> 00:02:09,840
open source for for near about 20 years

00:02:07,680 --> 00:02:12,060
and they have done a marvelous job so

00:02:09,840 --> 00:02:13,140
you know and then they have a pretty

00:02:12,060 --> 00:02:16,650
huge product

00:02:13,140 --> 00:02:18,690
folios as a part of their charter IBM

00:02:16,650 --> 00:02:21,510
power systems in particular has worked

00:02:18,690 --> 00:02:23,819
with Red Hat to bring most of its

00:02:21,510 --> 00:02:25,050
current capabilities or product

00:02:23,819 --> 00:02:27,209
portfolios onto power

00:02:25,050 --> 00:02:29,520
speaking about Red Hat Enterprise Linux

00:02:27,209 --> 00:02:32,580
which is which has been running on top

00:02:29,520 --> 00:02:35,850
of power system from a long time and

00:02:32,580 --> 00:02:37,890
then three others like we have had right

00:02:35,850 --> 00:02:43,260
at OpenStack we have had relied

00:02:37,890 --> 00:02:50,160
openshift which are now part of IBM part

00:02:43,260 --> 00:02:53,130
platform as well I would like to take

00:02:50,160 --> 00:02:56,580
some time and talk about the cloud

00:02:53,130 --> 00:02:58,830
workloads over here we know that half of

00:02:56,580 --> 00:03:01,140
the work goes which run on cloud today

00:02:58,830 --> 00:03:03,959
work on top of Linux operating system

00:03:01,140 --> 00:03:06,810
and red hacked is indisputably the

00:03:03,959 --> 00:03:10,410
number one cloud distributor in terms of

00:03:06,810 --> 00:03:13,380
and and also Linux distributed and

00:03:10,410 --> 00:03:16,230
support provider over here there is an

00:03:13,380 --> 00:03:17,870
imminent threat when an Enterprise Linux

00:03:16,230 --> 00:03:20,700
running an enterprise application

00:03:17,870 --> 00:03:23,489
running on top of multiple clouds run

00:03:20,700 --> 00:03:28,470
into you know vendor lock-in kind of an

00:03:23,489 --> 00:03:30,810
issue IBM and Red Hat have worked with

00:03:28,470 --> 00:03:33,510
end-to-end solutions which helps unify

00:03:30,810 --> 00:03:36,329
your public and private cloud

00:03:33,510 --> 00:03:39,090
investments and then but that that makes

00:03:36,329 --> 00:03:40,920
use of your application and services

00:03:39,090 --> 00:03:43,860
built around open source frameworks and

00:03:40,920 --> 00:03:47,370
then which helps eliminate the vendor

00:03:43,860 --> 00:03:48,570
lock-in as we speak the reason I say we

00:03:47,370 --> 00:03:49,950
can eliminate the vendor lock-in is

00:03:48,570 --> 00:03:52,170
let's assume you have an application

00:03:49,950 --> 00:03:53,579
running along with a software bundle

00:03:52,170 --> 00:03:55,079
which has not been signed and you are

00:03:53,579 --> 00:03:57,810
running it on top of a production and

00:03:55,079 --> 00:04:00,150
all of the sudden they pull their

00:03:57,810 --> 00:04:02,760
support back what do we do next we have

00:04:00,150 --> 00:04:05,370
an application running in production to

00:04:02,760 --> 00:04:07,950
eliminate that IBM and you know in fact

00:04:05,370 --> 00:04:10,859
Renaud openshift has a catalog in which

00:04:07,950 --> 00:04:13,920
they have huge suit of software's being

00:04:10,859 --> 00:04:17,070
signed and securely published to a

00:04:13,920 --> 00:04:18,780
in-house repository kind of a thing

00:04:17,070 --> 00:04:20,479
which could be plugged which could be

00:04:18,780 --> 00:04:22,109
pulled in on to your openshift

00:04:20,479 --> 00:04:25,640
instantaneously and you can run on top

00:04:22,109 --> 00:04:25,640
of your power systems to

00:04:26,300 --> 00:04:32,190
there are limitless applications one

00:04:29,520 --> 00:04:33,900
could only realize with one one

00:04:32,190 --> 00:04:37,470
understands the capabilities of

00:04:33,900 --> 00:04:39,479
OpenStack or our openshift as such the

00:04:37,470 --> 00:04:41,580
you know boiling down there are three

00:04:39,479 --> 00:04:44,400
focus areas that I'm going to touch base

00:04:41,580 --> 00:04:47,910
on and they fit too and they are free to

00:04:44,400 --> 00:04:49,650
run OpenShift on power as such one of

00:04:47,910 --> 00:04:52,139
them is application modernization story

00:04:49,650 --> 00:04:54,210
let me give you a brief analogy and how

00:04:52,139 --> 00:04:59,009
application modernization story can work

00:04:54,210 --> 00:05:01,740
over here we an enterprise company

00:04:59,009 --> 00:05:03,120
running your application depending on

00:05:01,740 --> 00:05:05,520
your legacy software and then you

00:05:03,120 --> 00:05:07,169
realize you want to shift to the micro

00:05:05,520 --> 00:05:08,729
services based approach and you don't

00:05:07,169 --> 00:05:11,639
know where to start and how to start it

00:05:08,729 --> 00:05:15,330
you could probably leverage opens shift

00:05:11,639 --> 00:05:17,220
as as it is because it has a whole suit

00:05:15,330 --> 00:05:20,639
of offerings within it you just have to

00:05:17,220 --> 00:05:21,900
you know download them and and then get

00:05:20,639 --> 00:05:24,389
started with your application develop

00:05:21,900 --> 00:05:27,990
sign as such with micro services based

00:05:24,389 --> 00:05:30,889
approach whenever you try upgrading one

00:05:27,990 --> 00:05:34,710
of the components you are not entirely

00:05:30,889 --> 00:05:38,580
compromising on on the availability of

00:05:34,710 --> 00:05:40,710
your application as it is and also you

00:05:38,580 --> 00:05:42,900
know this helps in in terms of

00:05:40,710 --> 00:05:45,060
application modernization story and then

00:05:42,900 --> 00:05:48,000
when it comes to building new data

00:05:45,060 --> 00:05:52,349
centric cloud kind of an application the

00:05:48,000 --> 00:05:54,419
data at which it is bursting in terms of

00:05:52,349 --> 00:05:57,930
exponential growth we need to rethink

00:05:54,419 --> 00:06:00,090
the way the cloud internal organizations

00:05:57,930 --> 00:06:04,650
works you know because the future clouds

00:06:00,090 --> 00:06:06,180
will will need to have will be capturing

00:06:04,650 --> 00:06:08,940
processing and analyzing the logs in

00:06:06,180 --> 00:06:12,120
particular right so we need to bring the

00:06:08,940 --> 00:06:13,469
compute to the data in turn as as

00:06:12,120 --> 00:06:16,110
opposed to the traditional approach of

00:06:13,469 --> 00:06:17,669
bringing the data to the compute so

00:06:16,110 --> 00:06:19,889
they're very and we need to have

00:06:17,669 --> 00:06:22,860
multiple cloud kind of a multi cloud

00:06:19,889 --> 00:06:25,050
kind of a scenario and then openshift

00:06:22,860 --> 00:06:27,000
provides a cloud like experience which

00:06:25,050 --> 00:06:28,770
could be leveraged easily and then

00:06:27,000 --> 00:06:31,770
seamlessly and deploy your applications

00:06:28,770 --> 00:06:33,449
on top of it we have had a lot of

00:06:31,770 --> 00:06:35,250
traction around machine learning and

00:06:33,449 --> 00:06:36,449
deep learning how could you get

00:06:35,250 --> 00:06:38,699
benefited with

00:06:36,449 --> 00:06:41,069
openshift it provides you an inbuilt

00:06:38,699 --> 00:06:43,909
plugin that could be leveraged and then

00:06:41,069 --> 00:06:47,279
you can run your model on top of your

00:06:43,909 --> 00:06:49,229
your GPUs directly from my be empower

00:06:47,279 --> 00:06:52,469
nine process of family we have an

00:06:49,229 --> 00:06:55,860
offering called AC 922 which is built

00:06:52,469 --> 00:06:57,749
for AI kind of a workload it has its

00:06:55,860 --> 00:07:00,360
planar surface aligned in such a way

00:06:57,749 --> 00:07:03,539
that you can pump in your data from CPU

00:07:00,360 --> 00:07:05,879
to GPU instantly making use of and it

00:07:03,539 --> 00:07:07,259
pretty bulky Li in fact making use of PC

00:07:05,879 --> 00:07:09,060
agent for kind of purposes

00:07:07,259 --> 00:07:13,319
I'll talk a little deep into it a little

00:07:09,060 --> 00:07:15,930
later so this is the power and family I

00:07:13,319 --> 00:07:18,539
was talking about earlier if you

00:07:15,930 --> 00:07:22,139
categorize this slide into two halves

00:07:18,539 --> 00:07:24,360
the vertical house one of them is LC 922

00:07:22,139 --> 00:07:27,629
kind of a box and all of these are based

00:07:24,360 --> 00:07:30,270
on power line family so the LC 922 box

00:07:27,629 --> 00:07:31,860
is mainly based on big data kind of a

00:07:30,270 --> 00:07:34,020
works or you could target your Big Data

00:07:31,860 --> 00:07:36,539
kind of workload on this box and then we

00:07:34,020 --> 00:07:39,360
have had the AC 922 which is a level

00:07:36,539 --> 00:07:42,419
building block of your one of the

00:07:39,360 --> 00:07:46,169
supercomputers as of last year 2018

00:07:42,419 --> 00:07:47,729
which is summit and coral this is this

00:07:46,169 --> 00:07:51,210
as I was mentioning the planar surface

00:07:47,729 --> 00:07:54,149
it and in such a way that you can pump

00:07:51,210 --> 00:07:58,129
in a lot of data from your CPU to your

00:07:54,149 --> 00:08:00,810
GPUs and then it comes with pretty good

00:07:58,129 --> 00:08:02,580
you know support from the software

00:08:00,810 --> 00:08:04,589
aspect of it we have LMS which means

00:08:02,580 --> 00:08:07,139
large model processing you could process

00:08:04,589 --> 00:08:09,930
your high-resolution pictures on top of

00:08:07,139 --> 00:08:12,839
your GPUs directly without overshooting

00:08:09,930 --> 00:08:14,729
its memory capabilities and then moving

00:08:12,839 --> 00:08:17,370
or the right side of the slide we have

00:08:14,729 --> 00:08:20,459
had IBM db2 and Oracle which are

00:08:17,370 --> 00:08:22,800
Enterprise kind of workloads that could

00:08:20,459 --> 00:08:25,469
be easily run on your nine fifty nine

00:08:22,800 --> 00:08:27,209
and eighty kind of boxes and then moving

00:08:25,469 --> 00:08:31,319
on to the middle segment of the slide

00:08:27,209 --> 00:08:33,060
which is SAP HANA kind of a workload

00:08:31,319 --> 00:08:35,969
could be targeted on this because we

00:08:33,060 --> 00:08:37,829
have had a huge footprint requirement

00:08:35,969 --> 00:08:39,659
when we need to run SAP HANA kind of a

00:08:37,829 --> 00:08:42,719
thing on top of it

00:08:39,659 --> 00:08:44,839
IBM power 9 processor family has a huge

00:08:42,719 --> 00:08:47,699
footprint and then we have released

00:08:44,839 --> 00:08:49,649
specifically a tailor-made kind of a

00:08:47,699 --> 00:08:53,519
server which is as 922

00:08:49,649 --> 00:08:59,790
- 949 s 924 which is which caters to the

00:08:53,519 --> 00:09:02,189
needs of a shapee kind of MU code so now

00:08:59,790 --> 00:09:03,899
that we know what kind of workloads

00:09:02,189 --> 00:09:08,179
should be targeted for OpenShift

00:09:03,899 --> 00:09:10,679
mean we need to know what kind of

00:09:08,179 --> 00:09:13,980
infrastructure also should be targeted

00:09:10,679 --> 00:09:16,410
when it comes down to running openshift

00:09:13,980 --> 00:09:18,449
on top of power in order to get much of

00:09:16,410 --> 00:09:20,730
a benefit to our end consumers our

00:09:18,449 --> 00:09:21,749
customers there are different modes when

00:09:20,730 --> 00:09:24,300
I say modes there are different

00:09:21,749 --> 00:09:26,119
hypervisors available in market that

00:09:24,300 --> 00:09:30,269
could be leveraged in order to run your

00:09:26,119 --> 00:09:31,730
systems one of them is the KVM approach

00:09:30,269 --> 00:09:35,970
which is industry standard

00:09:31,730 --> 00:09:38,970
virtualization hypervisors are kind of a

00:09:35,970 --> 00:09:41,670
software you can run LC 9:22 which is

00:09:38,970 --> 00:09:43,050
our big data kind of a workload on top

00:09:41,670 --> 00:09:46,740
of it you can run it either in bare

00:09:43,050 --> 00:09:48,720
metal and our hypervisor or in a

00:09:46,740 --> 00:09:52,999
virtualized hypervisor - kind of thing

00:09:48,720 --> 00:09:55,800
we have had 8922 where you can run your

00:09:52,999 --> 00:09:57,959
AI kind of a worker in bare metal mode

00:09:55,800 --> 00:10:00,990
and then we have the traditional power

00:09:57,959 --> 00:10:03,629
VM partitioning hypervisor which is used

00:10:00,990 --> 00:10:07,679
for major targeting your enterprise kind

00:10:03,629 --> 00:10:09,720
of workloads so the whole premise of

00:10:07,679 --> 00:10:13,379
this slide is to understand you could

00:10:09,720 --> 00:10:15,990
run openshift on any kind of mode let it

00:10:13,379 --> 00:10:21,420
be k vm let it be power k vm our power

00:10:15,990 --> 00:10:25,290
vm so i would like to spend considerable

00:10:21,420 --> 00:10:28,230
amount of time on the choice of worker

00:10:25,290 --> 00:10:30,959
that we have taken for this particular

00:10:28,230 --> 00:10:32,939
performance case study the workload is

00:10:30,959 --> 00:10:35,339
very data-intensive the reason we picked

00:10:32,939 --> 00:10:39,299
up this kind of workload was to you know

00:10:35,339 --> 00:10:41,309
put a lot of pressure on top of you put

00:10:39,299 --> 00:10:43,769
a lot of performance worked on top of

00:10:41,309 --> 00:10:45,749
your CPUs and see how power 9 processor

00:10:43,769 --> 00:10:50,670
stands out as compared to the skylight

00:10:45,749 --> 00:10:52,649
in this particular performance study the

00:10:50,670 --> 00:10:54,809
objective when we were doing this

00:10:52,649 --> 00:10:58,079
performance case study was to derive a

00:10:54,809 --> 00:11:01,350
price performance advantage that we

00:10:58,079 --> 00:11:03,510
could have as a leverage on when we run

00:11:01,350 --> 00:11:06,360
it on power 9 as compared to skylight

00:11:03,510 --> 00:11:08,640
kind of system and then in order to come

00:11:06,360 --> 00:11:11,340
unto that particular conclusion we have

00:11:08,640 --> 00:11:13,530
identified a workload which was coming

00:11:11,340 --> 00:11:16,460
from DB s website and is a

00:11:13,530 --> 00:11:19,860
geospatial kind of a dataset and then

00:11:16,460 --> 00:11:23,220
which was a CPU intensive workload I'll

00:11:19,860 --> 00:11:24,900
come down to the basics and and why it

00:11:23,220 --> 00:11:27,450
is a CPU intensive kind of a workload

00:11:24,900 --> 00:11:29,370
and it was loosely based on the mean

00:11:27,450 --> 00:11:32,100
stack means that if you're not aware is

00:11:29,370 --> 00:11:34,140
based on MongoDB Enterprise GS angularjs

00:11:32,100 --> 00:11:36,660
and no GS we will just make use of

00:11:34,140 --> 00:11:38,640
MongoDB Enterprise binaries angularjs

00:11:36,660 --> 00:11:40,500
and note years over here and then we

00:11:38,640 --> 00:11:42,270
defined the service level agreements in

00:11:40,500 --> 00:11:45,240
order to evaluate the metrics associated

00:11:42,270 --> 00:11:47,460
for this performance case study one of

00:11:45,240 --> 00:11:49,380
the SLA was to make sure the transaction

00:11:47,460 --> 00:11:51,480
response time was always less than 999

00:11:49,380 --> 00:11:54,800
milliseconds if you have hundred

00:11:51,480 --> 00:11:57,060
transactions and if any if any of those

00:11:54,800 --> 00:11:58,800
transaction responses were less or

00:11:57,060 --> 00:12:00,870
greater than 999 milliseconds they were

00:11:58,800 --> 00:12:03,030
qualified as error news and we didn't

00:12:00,870 --> 00:12:06,390
categorize it in order to evaluate if

00:12:03,030 --> 00:12:08,910
the workload was going good or not and

00:12:06,390 --> 00:12:12,450
then also we had another metric system

00:12:08,910 --> 00:12:16,590
where and we said hey if 1% of the whole

00:12:12,450 --> 00:12:19,230
workload is greater than has a response

00:12:16,590 --> 00:12:21,180
time more than 999 milliseconds we just

00:12:19,230 --> 00:12:23,610
discarded that workload it was something

00:12:21,180 --> 00:12:25,200
this were our in-house metric system

00:12:23,610 --> 00:12:27,960
that we developed in order to evaluate

00:12:25,200 --> 00:12:30,960
the price performance number as such and

00:12:27,960 --> 00:12:33,090
then the whole intent was to pack as

00:12:30,960 --> 00:12:36,720
many containers as possible on a host

00:12:33,090 --> 00:12:38,400
basis as an analogy can think if you

00:12:36,720 --> 00:12:41,640
have multiple developers who need an

00:12:38,400 --> 00:12:43,560
isolated environments and then how many

00:12:41,640 --> 00:12:46,950
such developers can you accommodate onto

00:12:43,560 --> 00:12:48,870
one system with containerization kind of

00:12:46,950 --> 00:12:52,290
a technology you could do that same

00:12:48,870 --> 00:12:52,800
thing and if you can Mac map it down to

00:12:52,290 --> 00:12:55,350
here

00:12:52,800 --> 00:12:58,080
the intent of packing as many containers

00:12:55,350 --> 00:13:00,570
as possible was to see if you can give

00:12:58,080 --> 00:13:03,450
an isolated development environment to

00:13:00,570 --> 00:13:06,000
respective developers or testers hashes

00:13:03,450 --> 00:13:09,510
and then we worked our way through the

00:13:06,000 --> 00:13:11,430
performance per core basis and we have

00:13:09,510 --> 00:13:14,790
the numbers I'll probably showcase you

00:13:11,430 --> 00:13:17,600
on how the TPS and how the cost per core

00:13:14,790 --> 00:13:17,600
not good for us

00:13:20,470 --> 00:13:25,270
yeah this is a busy chart but but I'll

00:13:22,750 --> 00:13:29,440
I'll try summarizing it into easier

00:13:25,270 --> 00:13:31,149
analogy one of if you pick up your

00:13:29,440 --> 00:13:33,250
mobile phones and start searching for

00:13:31,149 --> 00:13:35,080
your restaurants in a particular

00:13:33,250 --> 00:13:37,540
neighborhood on your neighborhood

00:13:35,080 --> 00:13:39,100
what would you probably need these two

00:13:37,540 --> 00:13:40,750
datasets one of them is neighborhood

00:13:39,100 --> 00:13:43,180
data set and restaurant data said this

00:13:40,750 --> 00:13:46,060
was all coming from geospatial data set

00:13:43,180 --> 00:13:51,310
part of your MongoDB sample tutorial as

00:13:46,060 --> 00:13:53,920
it is and and then we have multiple

00:13:51,310 --> 00:13:56,230
users been doing the search operation

00:13:53,920 --> 00:14:01,149
and it was been similar to making use of

00:13:56,230 --> 00:14:03,730
jmeter kind of service wherein whenever

00:14:01,149 --> 00:14:05,920
a user picks up sis mobile and says hey

00:14:03,730 --> 00:14:09,160
give me some results back it translates

00:14:05,920 --> 00:14:13,029
it to five different transactions as you

00:14:09,160 --> 00:14:16,240
can see so if you have four users doing

00:14:13,029 --> 00:14:18,160
100 hundred such loop transactions it

00:14:16,240 --> 00:14:20,890
narrows down to 2,000 kind of a

00:14:18,160 --> 00:14:23,050
transactions over here in a net net on

00:14:20,890 --> 00:14:25,300
an average a short turn was somewhere

00:14:23,050 --> 00:14:26,860
coming around eight to ten minutes long

00:14:25,300 --> 00:14:28,870
and then the longer ins which was the

00:14:26,860 --> 00:14:34,630
benchmarking runs came somewhere around

00:14:28,870 --> 00:14:36,700
30 minutes long in this particular

00:14:34,630 --> 00:14:38,230
exercise are at the performance case

00:14:36,700 --> 00:14:41,170
area that we have taken up the software

00:14:38,230 --> 00:14:44,800
stack which we considered for evaluation

00:14:41,170 --> 00:14:47,079
of this particular performance run was

00:14:44,800 --> 00:14:49,959
in in this manner the hypervisor used on

00:14:47,079 --> 00:14:52,600
a power line processor family was power

00:14:49,959 --> 00:14:54,730
VM that's our in-house partitioning tool

00:14:52,600 --> 00:14:57,270
in house partitioning hypervisor and the

00:14:54,730 --> 00:14:59,709
industry standard KVM on an x86 machine

00:14:57,270 --> 00:15:01,300
the open shift container platform was

00:14:59,709 --> 00:15:05,050
around 3.11

00:15:01,300 --> 00:15:08,890
and it was remaining same and then for

00:15:05,050 --> 00:15:10,510
you to run 3.11 we need to have rho 7.6

00:15:08,890 --> 00:15:13,329
which is the latest and the greatest

00:15:10,510 --> 00:15:16,360
as often as of today as of yesterday I

00:15:13,329 --> 00:15:18,339
think 7.7 got released and it also got

00:15:16,360 --> 00:15:22,480
released and in the kernel that was

00:15:18,339 --> 00:15:24,670
coming in from 7.6 was 3.10

00:15:22,480 --> 00:15:27,940
which was fairly the same across v9

00:15:24,670 --> 00:15:29,920
processor and x86 processor they the

00:15:27,940 --> 00:15:33,250
intent of sticking with Centaurs

00:15:29,920 --> 00:15:35,730
as a container base OS was we were

00:15:33,250 --> 00:15:38,050
making use of enterprise DB MongoDB

00:15:35,730 --> 00:15:40,300
version 4.2 which was coming in handy

00:15:38,050 --> 00:15:43,420
and tends to picked it up accordingly in

00:15:40,300 --> 00:15:45,490
the node.js which was the front-end

00:15:43,420 --> 00:15:49,300
based and it was serving as a rest

00:15:45,490 --> 00:15:51,850
server was version a dot 14 this is a

00:15:49,300 --> 00:15:57,279
fairly Apple to Apple comparison as you

00:15:51,850 --> 00:15:59,079
can see the systems under test are the

00:15:57,279 --> 00:16:02,230
architecture that we resorted to was

00:15:59,079 --> 00:16:05,440
like this you can see the blue box and

00:16:02,230 --> 00:16:10,420
we can see the yellow box in the slide

00:16:05,440 --> 00:16:12,339
so OpenShift does not yet support the

00:16:10,420 --> 00:16:13,930
heterogeneous coexistence it doesn't

00:16:12,339 --> 00:16:15,389
mean that we haven't tested we have

00:16:13,930 --> 00:16:17,800
tested and we got the similar numbers

00:16:15,389 --> 00:16:23,110
but but the reason we resorted to

00:16:17,800 --> 00:16:24,399
different pure clusters was to make sure

00:16:23,110 --> 00:16:26,769
when we come up with the performance

00:16:24,399 --> 00:16:29,620
numbers it remained fairly the same and

00:16:26,769 --> 00:16:32,260
then hence we resulted to give two

00:16:29,620 --> 00:16:35,110
different pure power clusters and pure

00:16:32,260 --> 00:16:37,449
intellect last year we have had the same

00:16:35,110 --> 00:16:39,490
load generator which is based on power 8

00:16:37,449 --> 00:16:41,470
processor family I said to to LC box

00:16:39,490 --> 00:16:43,810
which was generating the load and was

00:16:41,470 --> 00:16:46,959
going to the switch which was the top of

00:16:43,810 --> 00:16:49,839
the racks which GA to 460 and it was

00:16:46,959 --> 00:16:52,540
redirecting the it was redirecting the

00:16:49,839 --> 00:16:56,920
flow to the respective clusters based on

00:16:52,540 --> 00:16:58,779
the URL that gets formed then it comes

00:16:56,920 --> 00:17:02,380
to the openshift OCP router kind of on

00:16:58,779 --> 00:17:04,959
the can ISM and you can see we have a

00:17:02,380 --> 00:17:07,329
power VM based hypervisor it was running

00:17:04,959 --> 00:17:09,459
on top of an L line 22 box and this was

00:17:07,329 --> 00:17:11,740
a partitioning software and on top of

00:17:09,459 --> 00:17:14,350
which we have hosted L power 2 L pass

00:17:11,740 --> 00:17:16,030
which is a standard terminology which

00:17:14,350 --> 00:17:18,370
were acting up as compute node 1 and

00:17:16,030 --> 00:17:20,410
compute node 2 then coming to the yellow

00:17:18,370 --> 00:17:23,679
box which is our Intel only box we have

00:17:20,410 --> 00:17:28,750
had the k vm as a hypervisor and we see

00:17:23,679 --> 00:17:31,740
vm 1 & 2 running as the running the

00:17:28,750 --> 00:17:35,260
operating system and were hosting the

00:17:31,740 --> 00:17:36,850
node.js and DB containers and they

00:17:35,260 --> 00:17:41,020
were acting as the compute nodes in this

00:17:36,850 --> 00:17:44,220
cluster this is more of the data flow

00:17:41,020 --> 00:17:47,230
that we have in the consideration

00:17:44,220 --> 00:17:49,000
so again if we divide the slide into two

00:17:47,230 --> 00:17:53,740
vertical halves on the left side of the

00:17:49,000 --> 00:17:57,010
slide on my left hand off the side we

00:17:53,740 --> 00:17:59,050
can see the pure power only cluster the

00:17:57,010 --> 00:18:00,280
load is getting generated or the

00:17:59,050 --> 00:18:02,680
simulation of the users I've been

00:18:00,280 --> 00:18:04,870
getting generated for the jmeter box it

00:18:02,680 --> 00:18:06,070
gets routed through OCP route kind of a

00:18:04,870 --> 00:18:08,590
mechanism which is our ingress

00:18:06,070 --> 00:18:11,020
controller and then it distributes the

00:18:08,590 --> 00:18:13,240
load to your alphas hosting your

00:18:11,020 --> 00:18:15,520
containers the small rectangle of black

00:18:13,240 --> 00:18:17,320
boxes that you see here are nothing but

00:18:15,520 --> 00:18:19,180
the container representation of how they

00:18:17,320 --> 00:18:22,840
are running it gets evenly distributed

00:18:19,180 --> 00:18:25,270
across aren't both systems and because

00:18:22,840 --> 00:18:28,570
we have a unique URL we are able to

00:18:25,270 --> 00:18:33,100
target which particular soft which

00:18:28,570 --> 00:18:33,730
particular host does the generator is

00:18:33,100 --> 00:18:36,670
going to hit

00:18:33,730 --> 00:18:38,800
he's been expressed over here and then

00:18:36,670 --> 00:18:41,860
we go to the next half of the slide

00:18:38,800 --> 00:18:44,080
wherein we have had the Intel only

00:18:41,860 --> 00:18:45,520
cluster which is a skylight cluster in

00:18:44,080 --> 00:18:48,760
the compulsion that we have taken and

00:18:45,520 --> 00:18:50,380
then again we have the OSI peer our kind

00:18:48,760 --> 00:18:53,890
of a mechanism which is our ingress

00:18:50,380 --> 00:18:56,470
controller and it helps redirect the

00:18:53,890 --> 00:18:58,900
flow based on the URL that gets exposed

00:18:56,470 --> 00:19:01,350
and this on top of your OCP router and

00:18:58,900 --> 00:19:04,450
it redirects it to the respective

00:19:01,350 --> 00:19:09,190
MongoDB and node.js based containers in

00:19:04,450 --> 00:19:14,140
in this equation when we narrowed it to

00:19:09,190 --> 00:19:16,050
how the MongoDB container was looking at

00:19:14,140 --> 00:19:19,990
when it comes to the performance

00:19:16,050 --> 00:19:25,090
comparison as you can see the intel xeon

00:19:19,990 --> 00:19:27,280
SP base six one five zero box was

00:19:25,090 --> 00:19:30,130
premature in terms of the number of

00:19:27,280 --> 00:19:32,020
containers being hosted on top of it we

00:19:30,130 --> 00:19:34,330
see there were 98 containers that were

00:19:32,020 --> 00:19:36,910
hosted on top of it which means you know

00:19:34,330 --> 00:19:39,720
that was across at 36 cold box

00:19:36,910 --> 00:19:43,750
it was evenly distributed across two VMs

00:19:39,720 --> 00:19:45,970
so if you take the number of TPS we are

00:19:43,750 --> 00:19:50,320
coming down somewhere around to 2200 or

00:19:45,970 --> 00:19:53,200
2300 when we do a per core comparison

00:19:50,320 --> 00:19:56,020
which is how many containers can the

00:19:53,200 --> 00:19:57,460
Intel skylake Box can accommodate we can

00:19:56,020 --> 00:19:59,860
see this somewhere around 2

00:19:57,460 --> 00:20:02,350
point seven containers per quart when it

00:19:59,860 --> 00:20:03,820
comes to power server power line base

00:20:02,350 --> 00:20:06,000
server we can see it is somewhere around

00:20:03,820 --> 00:20:08,830
eight point seven containers per quart

00:20:06,000 --> 00:20:11,679
with when it translate a net-net

00:20:08,830 --> 00:20:16,240
we see three point to get a container

00:20:11,679 --> 00:20:18,429
capability per core such you would

00:20:16,240 --> 00:20:21,240
probably think water container is just a

00:20:18,429 --> 00:20:23,919
container can be thought of as a

00:20:21,240 --> 00:20:25,990
lightweight operating system which helps

00:20:23,919 --> 00:20:27,850
you pack all of your binaries and

00:20:25,990 --> 00:20:29,440
libraries onto it then the moment you

00:20:27,850 --> 00:20:31,480
spin up those containers you have the

00:20:29,440 --> 00:20:34,360
application runtime available and could

00:20:31,480 --> 00:20:36,850
be leveraged for your application

00:20:34,360 --> 00:20:39,100
development as such so this is a

00:20:36,850 --> 00:20:41,260
configurable compute unit how can you

00:20:39,100 --> 00:20:43,539
configure it so we have fuel label

00:20:41,260 --> 00:20:46,029
identifiers are you know a few

00:20:43,539 --> 00:20:50,169
identifies by which you can configure

00:20:46,029 --> 00:20:52,720
this this compute units one of them is

00:20:50,169 --> 00:20:55,570
labels if you have the label mentioning

00:20:52,720 --> 00:20:57,730
it as whenever I spin up a container it

00:20:55,570 --> 00:20:59,380
should go and sit on top of a c920 to

00:20:57,730 --> 00:21:01,809
kind of box you can label it accordingly

00:20:59,380 --> 00:21:04,659
and then when it comes to install to the

00:21:01,809 --> 00:21:06,130
CPU memory and the storage units you can

00:21:04,659 --> 00:21:08,529
also configure and tell hey you cannot

00:21:06,130 --> 00:21:10,690
get more than two CPUs of virtual CPUs

00:21:08,529 --> 00:21:14,429
to this box and then similar same goes

00:21:10,690 --> 00:21:14,429
to your i/o and your storage as well

00:21:15,000 --> 00:21:22,029
speaking of data intensive workload that

00:21:17,740 --> 00:21:24,640
we have had as an objective the another

00:21:22,029 --> 00:21:27,100
CPU intensive kind of or data intensive

00:21:24,640 --> 00:21:31,059
kind of workload that one could target

00:21:27,100 --> 00:21:33,760
is your AI models I would not dwell much

00:21:31,059 --> 00:21:36,720
into this slide but with desi 922 kind

00:21:33,760 --> 00:21:39,820
of a workload as as as a server out of

00:21:36,720 --> 00:21:41,340
choice you could do large moral support

00:21:39,820 --> 00:21:43,690
as an analogy you can think of

00:21:41,340 --> 00:21:46,330
processing your high resolution images

00:21:43,690 --> 00:21:48,340
on top of your GPUs it will always go

00:21:46,330 --> 00:21:50,679
into art of memory kind of an exception

00:21:48,340 --> 00:21:56,940
kind of the thing with cafes libraries

00:21:50,679 --> 00:21:59,020
we could offload the relevant pieces of

00:21:56,940 --> 00:22:01,539
relevant pieces of processing on to your

00:21:59,020 --> 00:22:02,890
CPUs so you don't overshoot your memory

00:22:01,539 --> 00:22:05,380
and you can come back and leverage the

00:22:02,890 --> 00:22:07,360
same data accordingly with PC agent for

00:22:05,380 --> 00:22:08,919
kind of a thing you could pump in the

00:22:07,360 --> 00:22:10,690
data back at much faster rate as

00:22:08,919 --> 00:22:13,539
compared to any other PCIe

00:22:10,690 --> 00:22:15,909
three kind of model supports we have

00:22:13,539 --> 00:22:18,460
distributed deep learning within the

00:22:15,909 --> 00:22:22,090
understanding is the convergence are the

00:22:18,460 --> 00:22:24,609
rate at which you learn or the model

00:22:22,090 --> 00:22:27,129
learns is done at a much faster level

00:22:24,609 --> 00:22:29,739
and then we have the industry standard

00:22:27,129 --> 00:22:31,629
and willing 2.0 in place so this for few

00:22:29,739 --> 00:22:34,239
in-house testing that we have done and

00:22:31,629 --> 00:22:36,369
we realize that cafe was doing near

00:22:34,239 --> 00:22:39,429
about four times much better as compared

00:22:36,369 --> 00:22:44,349
to its as compared to the Intel GPA

00:22:39,429 --> 00:22:46,779
boxes in the in picture as a net net if

00:22:44,349 --> 00:22:53,259
I put this up in a visual representation

00:22:46,779 --> 00:22:55,779
on how and how in today's power cloud

00:22:53,259 --> 00:22:57,759
model what we can do better over here is

00:22:55,779 --> 00:22:58,899
is when it comes to the MongoDB as a

00:22:57,759 --> 00:23:02,399
performance case study that we have

00:22:58,899 --> 00:23:05,080
taken we realized that we are doing 3.2

00:23:02,399 --> 00:23:06,820
container density on a cloud kind of an

00:23:05,080 --> 00:23:08,470
environment and then when it comes to

00:23:06,820 --> 00:23:12,129
the price performance ratio we are doing

00:23:08,470 --> 00:23:14,470
2 point X kind of a thing and in with AI

00:23:12,129 --> 00:23:16,840
modeling kind of in picking in picture

00:23:14,470 --> 00:23:22,239
we are doing 4 X much better as compared

00:23:16,840 --> 00:23:23,590
to Intel Xeon 300 GPUs and then the

00:23:22,239 --> 00:23:25,539
in-house testing that we have done was

00:23:23,590 --> 00:23:27,369
it cafe and the large model support and

00:23:25,539 --> 00:23:29,049
we have done the iterations near about

00:23:27,369 --> 00:23:31,749
thousand times and then we concluded

00:23:29,049 --> 00:23:34,570
that a workload which was taking 3.1

00:23:31,749 --> 00:23:38,979
hours on Intel was fairly doing in 49

00:23:34,570 --> 00:23:41,320
minutes on a nap our server power is

00:23:38,979 --> 00:23:43,629
already a part of open hardware kind of

00:23:41,320 --> 00:23:49,029
an ecosystem with red heightened picture

00:23:43,629 --> 00:23:51,759
we are also have provided the software

00:23:49,029 --> 00:23:54,479
and implement option and then with which

00:23:51,759 --> 00:23:56,859
we give the openness in the choice of

00:23:54,479 --> 00:23:59,259
what kind of software can run on what

00:23:56,859 --> 00:24:03,789
kind of hardware is left to the ICS or

00:23:59,259 --> 00:24:07,779
the business partners a summary I would

00:24:03,789 --> 00:24:12,009
like to give you some few takeaways over

00:24:07,779 --> 00:24:13,899
here the performance on a core basis as

00:24:12,009 --> 00:24:15,729
we have compared is very high the reason

00:24:13,899 --> 00:24:17,950
it is pretty high is we have a huge

00:24:15,729 --> 00:24:21,820
footprint when we visualize the same on

00:24:17,950 --> 00:24:24,670
planar surface of your hardware the our

00:24:21,820 --> 00:24:27,820
memory is residing immediately next year

00:24:24,670 --> 00:24:30,520
which means the response time which

00:24:27,820 --> 00:24:32,860
considerably take if taken comes back in

00:24:30,520 --> 00:24:34,210
you know pretty less time and hence we

00:24:32,860 --> 00:24:36,580
are getting a higher throughput and then

00:24:34,210 --> 00:24:39,070
when it when it boils down to how many

00:24:36,580 --> 00:24:42,100
dollars could be invested on a container

00:24:39,070 --> 00:24:44,920
basis it already speaks to us and it has

00:24:42,100 --> 00:24:47,560
a two point six much better bandwidth or

00:24:44,920 --> 00:24:52,600
twenty core power only box as compared

00:24:47,560 --> 00:24:55,590
to Intel only box I have a demo can demo

00:24:52,600 --> 00:24:55,590
which I would like to give

00:25:15,309 --> 00:25:21,559
so this is a 3.11 open-open shift

00:25:19,099 --> 00:25:23,690
cluster running on top of power server I

00:25:21,559 --> 00:25:26,659
logged in as a default user system admin

00:25:23,690 --> 00:25:29,029
and in this cluster I have had one

00:25:26,659 --> 00:25:31,399
management node and to compute nodes one

00:25:29,029 --> 00:25:32,960
of them is scheduling is disabled and we

00:25:31,399 --> 00:25:34,940
were doing few internal testings and we

00:25:32,960 --> 00:25:39,139
want to do and see if you can attain the

00:25:34,940 --> 00:25:40,879
same number of container capacity on

00:25:39,139 --> 00:25:43,639
same system and hence we disabled this

00:25:40,879 --> 00:25:48,259
this is a PP 64 le box little Indian

00:25:43,639 --> 00:25:50,359
version of power processor this is as I

00:25:48,259 --> 00:25:55,330
mentioned in my architecture previously

00:25:50,359 --> 00:25:55,330
this is a power lead based master node

00:25:56,139 --> 00:26:01,009
we have we can create as many products

00:25:59,539 --> 00:26:03,649
as we can when it comes to the

00:26:01,009 --> 00:26:06,259
kubernetes terminology which means name

00:26:03,649 --> 00:26:08,330
spacing convention so we see there is

00:26:06,259 --> 00:26:10,940
something called as mitten month this is

00:26:08,330 --> 00:26:12,679
the project that we have taken and we

00:26:10,940 --> 00:26:14,599
have then this is the way we can isolate

00:26:12,679 --> 00:26:17,089
our projects we can have multiple such

00:26:14,599 --> 00:26:23,989
process existing on the same open chip

00:26:17,089 --> 00:26:25,789
cluster this is a fairly new project and

00:26:23,989 --> 00:26:28,519
we see nothing is been running on top of

00:26:25,789 --> 00:26:30,349
them as of now if we're making use of

00:26:28,519 --> 00:26:33,169
the helm approach to see the ease with

00:26:30,349 --> 00:26:36,309
which we can shift and translate towards

00:26:33,169 --> 00:26:43,879
open shift from any kubernetes kind of

00:26:36,309 --> 00:26:46,249
platform as of now there are no parts or

00:26:43,879 --> 00:26:51,289
containers running in this point and I

00:26:46,249 --> 00:26:56,389
have deployed an instance with reference

00:26:51,289 --> 00:26:59,570
as Saoirse and then we can see how the

00:26:56,389 --> 00:27:02,029
parts are coming up so it takes

00:26:59,570 --> 00:27:03,499
instantly to reply or pull the

00:27:02,029 --> 00:27:06,080
respective docker images from the

00:27:03,499 --> 00:27:08,570
registry of the openshift end and see

00:27:06,080 --> 00:27:11,330
how it comes up you can see there is a

00:27:08,570 --> 00:27:13,759
route which has been created this is our

00:27:11,330 --> 00:27:15,619
external router so this can be used for

00:27:13,759 --> 00:27:18,259
our external accesses if you have any

00:27:15,619 --> 00:27:19,999
API is being coming up we can see if it

00:27:18,259 --> 00:27:21,370
comes up or not it's going to take a

00:27:19,999 --> 00:27:26,070
little while

00:27:21,370 --> 00:27:26,070
should be doing some updates over here

00:27:40,400 --> 00:27:46,720
so I can do describe these parts and see

00:27:43,580 --> 00:27:52,640
how it is coming and where it is getting

00:27:46,720 --> 00:27:54,590
deployed at if you can see at the node

00:27:52,640 --> 00:27:56,480
name it says it got deployed on to 133

00:27:54,590 --> 00:28:02,690
hosts which is only host in this point

00:27:56,480 --> 00:28:05,360
which is available and then I'll

00:28:02,690 --> 00:28:11,450
probably try reloading it it comes back

00:28:05,360 --> 00:28:14,030
again I will probably try logging into

00:28:11,450 --> 00:28:19,340
one of the nodes to see if it goit

00:28:14,030 --> 00:28:21,410
should yield properly onto it there are

00:28:19,340 --> 00:28:23,870
multiple such parts over there in place

00:28:21,410 --> 00:28:25,309
and all of them translates it to

00:28:23,870 --> 00:28:27,610
different projects that you have on the

00:28:25,309 --> 00:28:27,610
system

00:28:34,350 --> 00:28:40,200
so as I was mentioning earlier when it

00:28:36,179 --> 00:28:42,450
came down to we have 256 GB of memory

00:28:40,200 --> 00:28:44,399
being shared across two VMs and was

00:28:42,450 --> 00:28:53,070
running in SMT eighth mode and this

00:28:44,399 --> 00:28:55,980
particular box had 128 GB with it this

00:28:53,070 --> 00:28:59,159
is our jmeter box and it is running in

00:28:55,980 --> 00:29:03,450
poverty mode it was fairly used for

00:28:59,159 --> 00:29:05,159
generating the workload over here you

00:29:03,450 --> 00:29:08,870
can see the transaction response time is

00:29:05,159 --> 00:29:12,179
somewhere around 90 99 milliseconds and

00:29:08,870 --> 00:29:13,289
the URL that we have used is unique and

00:29:12,179 --> 00:29:15,539
this is how we were trying to target

00:29:13,289 --> 00:29:22,470
each and every particular openshift

00:29:15,539 --> 00:29:26,669
cluster I'd probably not dwell much into

00:29:22,470 --> 00:29:31,740
this on how it is going and how it is

00:29:26,669 --> 00:29:33,570
being translated over here but that was

00:29:31,740 --> 00:29:36,230
it guys thank you if you had any

00:29:33,570 --> 00:29:39,230
questions please let me know

00:29:36,230 --> 00:29:39,230
sure

00:29:46,239 --> 00:29:54,669
no particular reason okay my question

00:29:51,039 --> 00:30:00,759
was why did you use virtual machines to

00:29:54,669 --> 00:30:02,979
deploy the containers so we had so when

00:30:00,759 --> 00:30:04,989
we're doing a comparison study we also

00:30:02,979 --> 00:30:06,580
had done a single node testing as you

00:30:04,989 --> 00:30:08,619
have mentioned the numbers came

00:30:06,580 --> 00:30:10,539
exponentially away better as compared to

00:30:08,619 --> 00:30:12,729
skylake and we wanted to test it on a

00:30:10,539 --> 00:30:16,179
virtualized container environment

00:30:12,729 --> 00:30:17,559
because if you host on a cloud not

00:30:16,179 --> 00:30:19,539
everyone will try to resort to a

00:30:17,559 --> 00:30:20,979
bare-metal approach over there they were

00:30:19,539 --> 00:30:22,659
trying to replicate the cloud scenario

00:30:20,979 --> 00:30:23,919
not everyone will try to resort to a

00:30:22,659 --> 00:30:25,539
bare-metal kind of an approach over

00:30:23,919 --> 00:30:27,549
there and hence we wanted to do a

00:30:25,539 --> 00:30:29,229
virtual machine over there because when

00:30:27,549 --> 00:30:30,639
it comes down to flower terminologies it

00:30:29,229 --> 00:30:32,769
is a virtual machine as compared to bare

00:30:30,639 --> 00:30:34,929
metal we tested it over there and it

00:30:32,769 --> 00:30:37,029
came fairly good in terms of the

00:30:34,929 --> 00:30:39,809
performance comparison we have also done

00:30:37,029 --> 00:30:43,149
a bare-metal kind of an approach to and

00:30:39,809 --> 00:30:45,759
if I'm not wrong we would able to scale

00:30:43,149 --> 00:30:49,029
somewhere around to 240 containers on

00:30:45,759 --> 00:30:50,859
one single machine and it was just on a

00:30:49,029 --> 00:30:52,269
permanent server and if it came down to

00:30:50,859 --> 00:30:54,549
a skylight it was somewhere around

00:30:52,269 --> 00:30:56,499
hundred so we are still in the

00:30:54,549 --> 00:30:58,239
preliminary testing phase over in the

00:30:56,499 --> 00:30:59,830
bare metal mode but the numbers are

00:30:58,239 --> 00:31:05,919
looking pretty favorable in terms of

00:30:59,830 --> 00:31:10,659
power processor one more question please

00:31:05,919 --> 00:31:13,179
if I container is running on a system

00:31:10,659 --> 00:31:17,379
with GPUs okay and can it use a GPU

00:31:13,179 --> 00:31:19,479
resources so what exactly is running

00:31:17,379 --> 00:31:22,269
inside your container is it the data

00:31:19,479 --> 00:31:24,700
that is it is hosting or is it and then

00:31:22,269 --> 00:31:26,049
to answer in an S in a simpler way yes

00:31:24,700 --> 00:31:27,609
you can allocate a device to your

00:31:26,049 --> 00:31:29,109
container when you can allocate

00:31:27,609 --> 00:31:32,019
otherwise you can always look at a GPU

00:31:29,109 --> 00:31:34,659
to your content also so the other way of

00:31:32,019 --> 00:31:36,429
thinking is you could containerize your

00:31:34,659 --> 00:31:38,259
machine learning and deep learning model

00:31:36,429 --> 00:31:41,080
also because it has it will have a lot

00:31:38,259 --> 00:31:43,149
of software libraries dependencies and

00:31:41,080 --> 00:31:47,440
you cannot spin it up again and again so

00:31:43,149 --> 00:31:49,889
you could do that also yes sure thank

00:31:47,440 --> 00:31:49,889
you

00:31:50,640 --> 00:31:53,850

YouTube URL: https://www.youtube.com/watch?v=4fJkiUR1JQo


