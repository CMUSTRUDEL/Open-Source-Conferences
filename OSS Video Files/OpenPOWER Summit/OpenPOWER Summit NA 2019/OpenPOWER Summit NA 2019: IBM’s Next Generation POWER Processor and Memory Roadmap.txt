Title: OpenPOWER Summit NA 2019: IBMâ€™s Next Generation POWER Processor and Memory Roadmap
Publication date: 2019-08-28
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Madeline Vega & Brian Allison, IBM
Captions: 
	00:00:00,030 --> 00:00:06,180
okay so it's 1:45 let's get started on

00:00:03,959 --> 00:00:08,160
this next session we're gonna be talking

00:00:06,180 --> 00:00:10,440
about IBM's next-generation power

00:00:08,160 --> 00:00:14,280
processor roadmap as well it's it's

00:00:10,440 --> 00:00:16,260
memory roadmap my name is Brian Allison

00:00:14,280 --> 00:00:17,940
and along with Madeline Vega

00:00:16,260 --> 00:00:21,270
we're gonna do kind of like a Coe

00:00:17,940 --> 00:00:23,490
presentation my background is I'm a

00:00:21,270 --> 00:00:27,090
logic designer based out of the IBM

00:00:23,490 --> 00:00:32,099
Rochester development site in Minnesota

00:00:27,090 --> 00:00:34,290
I've been doing power or doing chip

00:00:32,099 --> 00:00:37,950
generation or chip development for about

00:00:34,290 --> 00:00:40,110
25 years now most specifically I've been

00:00:37,950 --> 00:00:42,480
working on Cappy and open Cappy over the

00:00:40,110 --> 00:00:43,879
last five or six years so I've been

00:00:42,480 --> 00:00:46,200
spending a significant amount of my time

00:00:43,879 --> 00:00:48,450
working with partners and doing

00:00:46,200 --> 00:00:51,360
acceleration development whether it be

00:00:48,450 --> 00:00:57,149
open Cappy and be linked you know those

00:00:51,360 --> 00:00:59,309
kind of constructs hi my name is

00:00:57,149 --> 00:01:01,850
Madeline Vega I'm the chief engineer for

00:00:59,309 --> 00:01:04,080
the next generation of power systems

00:01:01,850 --> 00:01:06,000
I've also been working in the last

00:01:04,080 --> 00:01:07,770
couple of years on the new emerging

00:01:06,000 --> 00:01:10,200
memory said we want to get into power

00:01:07,770 --> 00:01:12,090
and then we'll talk about the OMI and

00:01:10,200 --> 00:01:16,500
open copy and connecting memory through

00:01:12,090 --> 00:01:18,509
that so I always like to Kattegat a

00:01:16,500 --> 00:01:19,830
little feel for my audience here so how

00:01:18,509 --> 00:01:24,450
many of you folks are alike in this

00:01:19,830 --> 00:01:27,479
scale-out type of environment how many

00:01:24,450 --> 00:01:31,020
are in the scale-up environment how many

00:01:27,479 --> 00:01:34,829
are in the cognitive environment how

00:01:31,020 --> 00:01:36,979
many are new to power ok so I'm seeing a

00:01:34,829 --> 00:01:40,380
smattering of hands all over the place

00:01:36,979 --> 00:01:42,509
ok so the focus of today's talk is to

00:01:40,380 --> 00:01:44,070
really talk about the next generation of

00:01:42,509 --> 00:01:47,310
the power processor we call it a IO

00:01:44,070 --> 00:01:49,860
which is advanced i/o today you know

00:01:47,310 --> 00:01:51,090
we've got two types of machines that are

00:01:49,860 --> 00:01:52,770
out there we've got a scale out

00:01:51,090 --> 00:01:55,200
environment as well as a scale up

00:01:52,770 --> 00:01:57,630
environment scale up is kind of like the

00:01:55,200 --> 00:02:00,630
enterprise type clusters so if you're

00:01:57,630 --> 00:02:02,759
doing IBM I or ax where you're doing you

00:02:00,630 --> 00:02:05,130
know for socket and larger that's a

00:02:02,759 --> 00:02:06,390
scale up environment on the scale out

00:02:05,130 --> 00:02:07,530
environments right that's where you're

00:02:06,390 --> 00:02:10,140
gonna get into your Linux type

00:02:07,530 --> 00:02:13,980
environments I also consider a lot of

00:02:10,140 --> 00:02:15,870
the AI cognitive systems like the AC 9

00:02:13,980 --> 00:02:18,379
22 is part of the scale-out environment

00:02:15,870 --> 00:02:20,670
as well what you're gonna see here is

00:02:18,379 --> 00:02:24,599
there's going to be a fundamental shift

00:02:20,670 --> 00:02:27,180
in in my mind and strategy of where IBM

00:02:24,599 --> 00:02:31,049
is going as far as what our systems look

00:02:27,180 --> 00:02:32,819
like out in the industry today it's kind

00:02:31,049 --> 00:02:35,010
of my opinion you know cores are

00:02:32,819 --> 00:02:37,980
becoming more of a commodity it's very

00:02:35,010 --> 00:02:41,370
much very difficult to differentiate

00:02:37,980 --> 00:02:43,079
yourself just go on core to core now

00:02:41,370 --> 00:02:45,049
obviously you've got to have a strong

00:02:43,079 --> 00:02:47,640
core you've got to have strong threads

00:02:45,049 --> 00:02:50,160
but based on you know a lot of these

00:02:47,640 --> 00:02:52,849
emerging workloads you've got to be able

00:02:50,160 --> 00:02:55,260
to support heterogeneity right and

00:02:52,849 --> 00:02:57,060
accelerators are become becoming more

00:02:55,260 --> 00:02:59,400
and more prevalent right so the

00:02:57,060 --> 00:03:00,750
overarching theme I think from all the

00:02:59,400 --> 00:03:03,299
talks that you've heard from this

00:03:00,750 --> 00:03:06,989
morning right there's a lot of open

00:03:03,299 --> 00:03:11,609
initiatives based on acceleration right

00:03:06,989 --> 00:03:13,049
and so we're we're obviously doing chip

00:03:11,609 --> 00:03:16,650
and system development

00:03:13,049 --> 00:03:18,120
around these accelerators today you know

00:03:16,650 --> 00:03:20,010
on the scale out environment it's very

00:03:18,120 --> 00:03:23,790
traditional you know you've got direct

00:03:20,010 --> 00:03:26,430
memory attached right that's one

00:03:23,790 --> 00:03:28,049
approach to to building out your let's

00:03:26,430 --> 00:03:30,209
call it your memory infrastructure and

00:03:28,049 --> 00:03:32,069
then on our scale-up type of

00:03:30,209 --> 00:03:34,049
environments right we've got my buffered

00:03:32,069 --> 00:03:35,489
memory now Madeline's going to talk

00:03:34,049 --> 00:03:37,079
about a little bit about you know what

00:03:35,489 --> 00:03:39,630
we're doing with our memory subsystems

00:03:37,079 --> 00:03:41,880
that we're doing in in the advanced i/o

00:03:39,630 --> 00:03:44,190
area but what you're gonna see is

00:03:41,880 --> 00:03:46,019
there's a lot of different emerging

00:03:44,190 --> 00:03:47,760
storage class memories that are going to

00:03:46,019 --> 00:03:49,709
become more and more prevalent as we go

00:03:47,760 --> 00:03:52,230
over time and you actually have to be

00:03:49,709 --> 00:03:53,760
able to address those environments now

00:03:52,230 --> 00:03:55,650
you can't really do those types of

00:03:53,760 --> 00:03:57,120
things just doing direct DDR memory

00:03:55,650 --> 00:03:59,849
right you have to have an environment

00:03:57,120 --> 00:04:01,560
where you're able to scale right to

00:03:59,849 --> 00:04:05,340
actually have a large memory footprint

00:04:01,560 --> 00:04:07,769
have a large bandwidth type environment

00:04:05,340 --> 00:04:10,109
and then to address these emerging you

00:04:07,769 --> 00:04:12,870
know storage class memories so what

00:04:10,109 --> 00:04:14,609
you're gonna see today is you know on

00:04:12,870 --> 00:04:17,849
the scale out environment you know we've

00:04:14,609 --> 00:04:19,829
got eight direct connect DDR ports we

00:04:17,849 --> 00:04:22,409
can get up to 150 gigabytes per second

00:04:19,829 --> 00:04:25,590
of sustained memory bandwidth

00:04:22,409 --> 00:04:25,890
we've got PCIe gen 4 there's 48 lanes of

00:04:25,590 --> 00:04:27,960
it

00:04:25,890 --> 00:04:30,479
we're the first ones in the industry to

00:04:27,960 --> 00:04:33,780
basically have that adoption for Gen 4

00:04:30,479 --> 00:04:36,870
others are following you no suit over

00:04:33,780 --> 00:04:38,610
time we've got advanced i/o you know

00:04:36,870 --> 00:04:42,150
we've got twenty five gigabit signaling

00:04:38,610 --> 00:04:43,830
for open cap e as well as env link so

00:04:42,150 --> 00:04:45,960
there's some differentiation that we're

00:04:43,830 --> 00:04:49,050
doing with acceleration with the NVIDIA

00:04:45,960 --> 00:04:52,740
GPUs as well as what we can do for open

00:04:49,050 --> 00:04:54,810
capi and then you'll see that you know

00:04:52,740 --> 00:04:57,150
with both our scale out and our scale up

00:04:54,810 --> 00:04:59,789
type environments today now as we're

00:04:57,150 --> 00:05:00,990
moving forward into the 2020 type you

00:04:59,789 --> 00:05:04,320
know time frame we're still going to be

00:05:00,990 --> 00:05:06,780
on a 14 nanometer node from Global

00:05:04,320 --> 00:05:08,400
Foundries we've got a whole new memory

00:05:06,780 --> 00:05:11,630
subsystem that Madeline is going to talk

00:05:08,400 --> 00:05:14,070
about we still have PCI Express Gen 4

00:05:11,630 --> 00:05:17,310
we're still going to run all of our NV

00:05:14,070 --> 00:05:19,680
link and our open cap e accelerators at

00:05:17,310 --> 00:05:22,590
25 gigabit but then we're going to go to

00:05:19,680 --> 00:05:24,449
open cap e for dado so you heard some of

00:05:22,590 --> 00:05:25,530
the discussions this morning about some

00:05:24,449 --> 00:05:28,080
of the initiatives that we're doing

00:05:25,530 --> 00:05:30,930
we're opening up some of our reference

00:05:28,080 --> 00:05:32,520
designs around open cap e 3.0 and but

00:05:30,930 --> 00:05:34,110
we're going to open up those

00:05:32,520 --> 00:05:36,630
environments today but then we're going

00:05:34,110 --> 00:05:39,840
to migrate to open cap before dot o when

00:05:36,630 --> 00:05:42,599
we get into the p9 advanced io chip

00:05:39,840 --> 00:05:45,630
development and then in 2021 we're gonna

00:05:42,599 --> 00:05:48,240
have our power 10 processor I think most

00:05:45,630 --> 00:05:50,039
people are aware that we're using a

00:05:48,240 --> 00:05:52,190
different foundry partner for power 10

00:05:50,039 --> 00:05:54,060
we're gonna go to Samsung 7 nanometre

00:05:52,190 --> 00:05:56,460
along with that you're going to have a

00:05:54,060 --> 00:05:59,060
new our new microarchitecture you're

00:05:56,460 --> 00:06:01,650
gonna have additional memory bandwidth

00:05:59,060 --> 00:06:04,229
we're gonna go along with PCI Express

00:06:01,650 --> 00:06:05,580
Gen 5 and then for our advanced

00:06:04,229 --> 00:06:08,159
signaling rates we're going to start to

00:06:05,580 --> 00:06:11,039
go to 32 and 50 gigabit so what you'll

00:06:08,159 --> 00:06:13,620
see along with that you'll see the next

00:06:11,039 --> 00:06:16,460
generation NVIDIA GPUs and then you'll

00:06:13,620 --> 00:06:18,479
see those next generation GPUs also with

00:06:16,460 --> 00:06:20,430
you know the system that we're coming

00:06:18,479 --> 00:06:22,979
out in 2020 so there's a new revision in

00:06:20,430 --> 00:06:30,020
2020 of NVIDIA GPUs and then there's

00:06:22,979 --> 00:06:30,020
another one in 2021 any questions so far

00:06:31,159 --> 00:06:35,789
so power 9 so I just wanted to kind of

00:06:33,930 --> 00:06:38,130
re emphasize you know this is one of the

00:06:35,789 --> 00:06:38,990
premier acceleration platforms that are

00:06:38,130 --> 00:06:41,770
out there

00:06:38,990 --> 00:06:45,729
you know we've got a number of different

00:06:41,770 --> 00:06:47,870
interconnects that are meant to address

00:06:45,729 --> 00:06:50,630
acceleration technologies whether it's

00:06:47,870 --> 00:06:53,050
PCI Express whether it's the 25 gig

00:06:50,630 --> 00:06:55,849
common link which by the way is the same

00:06:53,050 --> 00:06:58,759
five signaling that we use for envy link

00:06:55,849 --> 00:07:01,669
as we do for open capi we've got some on

00:06:58,759 --> 00:07:05,479
chip acceleration as far as gzip engines

00:07:01,669 --> 00:07:08,389
a compression engine some shah's those

00:07:05,479 --> 00:07:09,949
are available today as far as up

00:07:08,389 --> 00:07:13,280
streaming the code we've actually got a

00:07:09,949 --> 00:07:14,539
relationship with a synchrotron over in

00:07:13,280 --> 00:07:16,490
Europe where we've been doing some

00:07:14,539 --> 00:07:18,560
metrics of looking at our on chip

00:07:16,490 --> 00:07:21,320
acceleration we're seeing some really

00:07:18,560 --> 00:07:23,750
compelling results with that it's my

00:07:21,320 --> 00:07:26,599
expectation that those engines will be

00:07:23,750 --> 00:07:28,340
available sometime later this year for

00:07:26,599 --> 00:07:29,330
other partners to take advantage of but

00:07:28,340 --> 00:07:31,909
we're seeing some really impressive

00:07:29,330 --> 00:07:36,860
results we've got the second generation

00:07:31,909 --> 00:07:38,810
of capi 2.0 which is basically our

00:07:36,860 --> 00:07:42,560
second revision of when we did

00:07:38,810 --> 00:07:44,210
acceleration on PCI Express we've got n

00:07:42,560 --> 00:07:47,060
V link like I talked about we've got

00:07:44,210 --> 00:07:49,520
open cap e 3.0 as well and then all my

00:07:47,060 --> 00:07:54,710
which which is our open memory interface

00:07:49,520 --> 00:07:56,900
which Madeline will talk about now most

00:07:54,710 --> 00:07:58,699
people are aware of this right the

00:07:56,900 --> 00:08:02,240
systems that we built today with the AC

00:07:58,699 --> 00:08:04,550
922 of they're powering the 2 largest

00:08:02,240 --> 00:08:07,729
most powerful supercomputers in the

00:08:04,550 --> 00:08:10,219
world right and summit in Sierra at Los

00:08:07,729 --> 00:08:14,240
Alamos and Oak Ridge right it's all

00:08:10,219 --> 00:08:16,639
powered by you know Mellanox Nix and

00:08:14,240 --> 00:08:20,229
NVIDIA GPUs right that's something that

00:08:16,639 --> 00:08:20,229
we stand behind that we're very proud of

00:08:20,530 --> 00:08:25,190
now this is kind of an eye chart but

00:08:23,090 --> 00:08:26,750
I'll kind of go over some of the main

00:08:25,190 --> 00:08:28,969
differentiators and things to pay

00:08:26,750 --> 00:08:31,430
attention to so this is what we call our

00:08:28,969 --> 00:08:33,020
advanced i/o chip right which is going

00:08:31,430 --> 00:08:35,120
to be our next generation platform

00:08:33,020 --> 00:08:38,899
sometimes you'll hear it called Swift

00:08:35,120 --> 00:08:42,529
it's basically our AC 922 follow-on for

00:08:38,899 --> 00:08:46,360
the cognitive space it's got again 24

00:08:42,529 --> 00:08:49,040
SMT cores it's got 120 Meg of l3 cache

00:08:46,360 --> 00:08:51,620
it's got still the same twenty five

00:08:49,040 --> 00:08:52,850
gigabit low energy differential

00:08:51,620 --> 00:08:55,880
signaling for

00:08:52,850 --> 00:08:59,779
everything that we do for OMI for open

00:08:55,880 --> 00:09:03,740
capi for envy link has the capabilities

00:08:59,779 --> 00:09:05,870
to go from for socket 216 socket as far

00:09:03,740 --> 00:09:09,740
as being able to address the enterprise

00:09:05,870 --> 00:09:13,250
space it's got you know PCI Express Gen

00:09:09,740 --> 00:09:14,480
4 still have 48 lanes of that so what

00:09:13,250 --> 00:09:17,389
you're going to see is is that there's

00:09:14,480 --> 00:09:18,470
just a bundle of interconnect for

00:09:17,389 --> 00:09:21,170
acceleration

00:09:18,470 --> 00:09:23,120
you know interconnect now one of the

00:09:21,170 --> 00:09:25,310
other things that we've addressed like I

00:09:23,120 --> 00:09:27,050
said is open Cappy for doubt oh and I've

00:09:25,310 --> 00:09:28,430
got a slide later in the deck to talk

00:09:27,050 --> 00:09:30,829
about what some of the features are with

00:09:28,430 --> 00:09:33,470
for tato but what you're gonna see is is

00:09:30,829 --> 00:09:34,910
that this guy is very much meant to

00:09:33,470 --> 00:09:37,009
address all these acceleration

00:09:34,910 --> 00:09:38,630
technologies now one of the things that

00:09:37,009 --> 00:09:40,339
we kind of point to on the bottom is

00:09:38,630 --> 00:09:43,449
these technologies don't do a lot of

00:09:40,339 --> 00:09:46,130
good unless you have a superhighway of

00:09:43,449 --> 00:09:48,740
on-chip bandwidth so there's 2 terabytes

00:09:46,130 --> 00:09:51,139
of raw signaling bandwidth shared by all

00:09:48,740 --> 00:09:53,000
these different attach mechanisms to

00:09:51,139 --> 00:09:56,209
basically handle all of the you know

00:09:53,000 --> 00:09:58,670
incoming and outgoing traffic for NB Lee

00:09:56,209 --> 00:10:00,730
for open copy for all my things of that

00:09:58,670 --> 00:10:00,730
nature

00:10:01,930 --> 00:10:06,350
so this chart is really meant to just

00:10:04,430 --> 00:10:08,600
kind of show us a pictorial diagram of

00:10:06,350 --> 00:10:10,339
what you could build as far as what

00:10:08,600 --> 00:10:13,250
we're looking at for this advanced I all

00:10:10,339 --> 00:10:15,889
right we've got open capi interconnect

00:10:13,250 --> 00:10:17,540
we've got PCI Express Gen 4 we've got

00:10:15,889 --> 00:10:19,160
all of my memory which Madeline like I

00:10:17,540 --> 00:10:20,899
said it's going to talk about and then

00:10:19,160 --> 00:10:23,360
the ability to have let's say twenty

00:10:20,899 --> 00:10:27,529
four lanes of NVIDIA GPU interconnect

00:10:23,360 --> 00:10:29,029
you know running at 25 gigabit so you're

00:10:27,529 --> 00:10:31,310
gonna have just you know a ton of

00:10:29,029 --> 00:10:32,779
bandwidth you know going back and forth

00:10:31,310 --> 00:10:35,889
between the processor and then the

00:10:32,779 --> 00:10:38,060
nvidia gpus and then you know a balanced

00:10:35,889 --> 00:10:39,970
memory construct as well because that's

00:10:38,060 --> 00:10:46,279
also running at a twenty five point six

00:10:39,970 --> 00:10:47,449
giga transfer signaling rate as well so

00:10:46,279 --> 00:10:50,060
let's talk a little bit about our open

00:10:47,449 --> 00:10:51,439
capi design goals one of the things that

00:10:50,060 --> 00:10:53,269
was talked about this morning was

00:10:51,439 --> 00:10:56,089
opening up some of our reference designs

00:10:53,269 --> 00:10:58,220
for the open memory interface right for

00:10:56,089 --> 00:11:01,939
the host side as well as the endpoint

00:10:58,220 --> 00:11:03,980
side as well as doing an endpoint open

00:11:01,939 --> 00:11:06,290
copy reference design for the device

00:11:03,980 --> 00:11:08,209
side so you know

00:11:06,290 --> 00:11:11,870
you've seen a lot of let's call it

00:11:08,209 --> 00:11:13,880
industry buzz around cxl from Intel you

00:11:11,870 --> 00:11:15,709
know open Cappy has been out there for

00:11:13,880 --> 00:11:18,199
you know a couple of years now we have

00:11:15,709 --> 00:11:20,990
all of those similar constructs and even

00:11:18,199 --> 00:11:24,800
more so today we have the ability to

00:11:20,990 --> 00:11:27,410
address coherent caching accelerators to

00:11:24,800 --> 00:11:29,259
support network controllers to support

00:11:27,410 --> 00:11:32,449
differentiated memories whether it be

00:11:29,259 --> 00:11:35,360
you know re Ram em RAM you know what

00:11:32,449 --> 00:11:37,550
have you it's you know able to sustain

00:11:35,360 --> 00:11:39,920
you know very high bandwidth very low

00:11:37,550 --> 00:11:41,540
latency so it can handle all these

00:11:39,920 --> 00:11:43,880
different constructs of all these new

00:11:41,540 --> 00:11:45,470
emerging storage class things we also

00:11:43,880 --> 00:11:48,199
can look at things like storage

00:11:45,470 --> 00:11:50,750
controllers now the design today is an

00:11:48,199 --> 00:11:52,970
asymmetric design which is pretty

00:11:50,750 --> 00:11:55,220
predominant in the industry that's what

00:11:52,970 --> 00:11:59,120
cxl is doing and that's what others are

00:11:55,220 --> 00:12:01,339
doing as well it it embodies the ISA of

00:11:59,120 --> 00:12:03,199
the host architecture we want to make

00:12:01,339 --> 00:12:06,829
sure that the accelerator development is

00:12:03,199 --> 00:12:08,930
very easy for those guys in that type of

00:12:06,829 --> 00:12:10,610
environment so we need to hide the

00:12:08,930 --> 00:12:12,620
differences between the coherence and

00:12:10,610 --> 00:12:14,389
memory models address translations and

00:12:12,620 --> 00:12:16,430
all those types of things we want to put

00:12:14,389 --> 00:12:17,990
all the complexity and the host and not

00:12:16,430 --> 00:12:19,760
in the accelerator and that's what

00:12:17,990 --> 00:12:22,639
you're gonna see as part of this

00:12:19,760 --> 00:12:24,889
environment now it obviously takes many

00:12:22,639 --> 00:12:27,079
years to design a host CPU you know

00:12:24,889 --> 00:12:28,760
let's say three or four years we want to

00:12:27,079 --> 00:12:30,380
keep it on you know a very shorter

00:12:28,760 --> 00:12:32,870
development cycle for folks that are

00:12:30,380 --> 00:12:35,389
doing accelerator development typically

00:12:32,870 --> 00:12:37,880
less than a year so we're trying to

00:12:35,389 --> 00:12:40,339
build an ecosystem that allows for folks

00:12:37,880 --> 00:12:42,440
to do accelerator development on open

00:12:40,339 --> 00:12:44,149
capi and one of the things that there

00:12:42,440 --> 00:12:46,040
was an earlier presentation from Lou

00:12:44,149 --> 00:12:48,199
young from our China research lab where

00:12:46,040 --> 00:12:49,970
she talked about OSI XL which is a

00:12:48,199 --> 00:12:51,589
higher level programming framework for

00:12:49,970 --> 00:12:53,209
folks that want to do FPGA development

00:12:51,589 --> 00:12:54,740
those are one of the things that we're

00:12:53,209 --> 00:12:57,470
trying to do to address that type of

00:12:54,740 --> 00:12:59,120
environment the other thing that we're

00:12:57,470 --> 00:13:00,670
trying to do is a that is that we're

00:12:59,120 --> 00:13:03,980
doing is that the timing corners

00:13:00,670 --> 00:13:05,600
obviously and in an ASIC and FPGA you're

00:13:03,980 --> 00:13:07,250
not gonna want to run at 2 gigahertz

00:13:05,600 --> 00:13:09,620
you're gonna want to run at 400

00:13:07,250 --> 00:13:11,240
megahertz or slower right so we want to

00:13:09,620 --> 00:13:12,949
run at these lower frequencies so when

00:13:11,240 --> 00:13:15,949
you're doing your timing optimization

00:13:12,949 --> 00:13:17,209
it's much easier to do it at those types

00:13:15,949 --> 00:13:18,949
of frequencies than trying to do

00:13:17,209 --> 00:13:20,180
something at a gigahertz or greater so

00:13:18,949 --> 00:13:22,370
we're trying to we're

00:13:20,180 --> 00:13:26,480
were basically making that a lower

00:13:22,370 --> 00:13:28,100
barrier to entry trust is another thing

00:13:26,480 --> 00:13:29,839
that's very important as far as all the

00:13:28,100 --> 00:13:31,430
accelerators go one of the things that

00:13:29,839 --> 00:13:33,220
we do is we make sure that all the

00:13:31,430 --> 00:13:36,200
translation gets done in the host

00:13:33,220 --> 00:13:38,300
everything is a virtual address space so

00:13:36,200 --> 00:13:39,860
there's never a physical address running

00:13:38,300 --> 00:13:42,140
around that somebody can basically tap

00:13:39,860 --> 00:13:44,750
on the wire and do some nefarious types

00:13:42,140 --> 00:13:46,640
of things so we basically are building

00:13:44,750 --> 00:13:48,230
trust into the architecture itself where

00:13:46,640 --> 00:13:50,690
everything is run running in the virtual

00:13:48,230 --> 00:13:52,339
address domain and then obviously cache

00:13:50,690 --> 00:13:54,410
coherence we want to make sure that all

00:13:52,339 --> 00:13:57,200
of our accelerators whether it be an NB

00:13:54,410 --> 00:13:59,600
link or an open cat pee or what-have-you

00:13:57,200 --> 00:14:01,310
can participate in our caching structure

00:13:59,600 --> 00:14:02,000
whether it be in the l2 or l3 or

00:14:01,310 --> 00:14:04,550
what-have-you

00:14:02,000 --> 00:14:06,560
we want to make sure that it it you know

00:14:04,550 --> 00:14:09,380
participates in our cache coherence and

00:14:06,560 --> 00:14:11,480
so we can't count it on the accelerator

00:14:09,380 --> 00:14:16,490
to do that so we make sure all that gets

00:14:11,480 --> 00:14:19,459
done in the host so one of my last

00:14:16,490 --> 00:14:22,640
slides this is kind of just IBM's

00:14:19,459 --> 00:14:25,820
history of roadmaps around acceleration

00:14:22,640 --> 00:14:28,459
right we started this game around 2014

00:14:25,820 --> 00:14:30,800
empowering with Capuano right it was

00:14:28,459 --> 00:14:33,200
very limited in the sense that we only

00:14:30,800 --> 00:14:33,650
supported a single cache line in 128

00:14:33,200 --> 00:14:36,230
bytes

00:14:33,650 --> 00:14:38,930
it was tunneled over PCI Express gen3

00:14:36,230 --> 00:14:42,080
and we didn't you know support a lot of

00:14:38,930 --> 00:14:44,930
things like native DMA or Atomics or

00:14:42,080 --> 00:14:45,920
you know host memory attached agents and

00:14:44,930 --> 00:14:48,350
things like that so it's pretty

00:14:45,920 --> 00:14:51,560
rudimentary at that point in time it's

00:14:48,350 --> 00:14:53,990
taken us relatively around four or five

00:14:51,560 --> 00:14:56,720
years to really get it right right with

00:14:53,990 --> 00:14:58,370
capita dot o and cap III dot o you know

00:14:56,720 --> 00:15:01,430
we're able to basically sustain

00:14:58,370 --> 00:15:03,950
bandwidth on open cap III at around 22

00:15:01,430 --> 00:15:07,520
gigabytes per second right out of a 25

00:15:03,950 --> 00:15:09,440
gigabyte possibility and even on cap e

00:15:07,520 --> 00:15:11,930
to dot o where you've got PCI Express

00:15:09,440 --> 00:15:13,550
Gen 4 where it's sixteen gigabit we were

00:15:11,930 --> 00:15:16,190
able to get a little bit north of like

00:15:13,550 --> 00:15:18,649
let's say 13 gigabytes sustained when we

00:15:16,190 --> 00:15:20,450
run that accelerator we've got all these

00:15:18,649 --> 00:15:22,820
additional features and functions that

00:15:20,450 --> 00:15:25,370
we've been enabling over time the

00:15:22,820 --> 00:15:27,950
ability to do native DMAs to host memory

00:15:25,370 --> 00:15:30,560
to do Atomics from the accelerator to

00:15:27,950 --> 00:15:32,209
host memory the ability to wake up a

00:15:30,560 --> 00:15:33,980
host thread instead of doing interrupts

00:15:32,209 --> 00:15:36,620
as your hand off mechanism

00:15:33,980 --> 00:15:40,790
and then the ability to do like let's

00:15:36,620 --> 00:15:43,100
say memory attached off of an endpoint

00:15:40,790 --> 00:15:44,840
device so if you've got some source

00:15:43,100 --> 00:15:47,120
storage class memory you want to run it

00:15:44,840 --> 00:15:49,880
off of your accelerator whether it be

00:15:47,120 --> 00:15:52,100
just traditional DDR or whether it's re

00:15:49,880 --> 00:15:54,350
Ram or something like that you can start

00:15:52,100 --> 00:15:56,360
to do hybrid memory solutions once you

00:15:54,350 --> 00:15:59,510
start to get into open cap III dot o and

00:15:56,360 --> 00:16:02,120
beyond now what you're going to see is

00:15:59,510 --> 00:16:03,470
you know with open Kappa for dot L a

00:16:02,120 --> 00:16:05,720
couple of the different capabilities

00:16:03,470 --> 00:16:08,480
that are in that that power nine

00:16:05,720 --> 00:16:11,390
advanced i/o chip is we support the

00:16:08,480 --> 00:16:14,120
ability to do posted operations just

00:16:11,390 --> 00:16:16,250
like PCI Express does and then we're

00:16:14,120 --> 00:16:17,510
also able to do like low latency short

00:16:16,250 --> 00:16:20,060
messages from the host to the

00:16:17,510 --> 00:16:21,920
accelerator historically speaking it's

00:16:20,060 --> 00:16:24,140
all been MMI O's whether it's for bite

00:16:21,920 --> 00:16:26,270
or a fight we're gonna actually going to

00:16:24,140 --> 00:16:28,610
be able to push messages of the 128 byte

00:16:26,270 --> 00:16:30,470
variety down to the accelerator there's

00:16:28,610 --> 00:16:33,050
a lot of applications and solutions that

00:16:30,470 --> 00:16:35,060
kind of demand that and then the ability

00:16:33,050 --> 00:16:37,730
to actually have an accelerator cache

00:16:35,060 --> 00:16:40,310
underneath the processors caches right

00:16:37,730 --> 00:16:43,280
that's all now capable in open capi 4.0

00:16:40,310 --> 00:16:46,790
in that new chip that's coming up now

00:16:43,280 --> 00:16:49,610
with open kappa 5.0 which is coming in

00:16:46,790 --> 00:16:52,220
our power 10 processor family right

00:16:49,610 --> 00:16:54,470
that's coming out in a 2021 kind of

00:16:52,220 --> 00:16:57,950
timeframe this is where we get into some

00:16:54,470 --> 00:16:59,990
of these more let's call it in advanced

00:16:57,950 --> 00:17:03,260
interconnects and as far as being able

00:16:59,990 --> 00:17:04,520
to run at 32 gigabit or 50 gigabit like

00:17:03,260 --> 00:17:06,950
I mentioned earlier that's going to have

00:17:04,520 --> 00:17:09,430
a new NVIDIA GPU associated with that

00:17:06,950 --> 00:17:11,930
and then it's going to be able to do

00:17:09,430 --> 00:17:14,210
let's call it interoperability what

00:17:11,930 --> 00:17:15,830
we're trying to do is with open kappa

00:17:14,210 --> 00:17:17,990
5.0 we're trying to make it such that

00:17:15,830 --> 00:17:20,750
somebody that develops an accelerator on

00:17:17,990 --> 00:17:23,060
PCI Express Gen 5 can interact with the

00:17:20,750 --> 00:17:24,230
host processor is open capi so you

00:17:23,060 --> 00:17:28,040
actually don't have to have a separate

00:17:24,230 --> 00:17:32,270
Phi 4 app open Kappa 5.0 relative to

00:17:28,040 --> 00:17:33,800
what we did historically speaking and

00:17:32,270 --> 00:17:36,430
I'll just leave it at that and Madeline

00:17:33,800 --> 00:17:36,430
will take over here

00:17:38,900 --> 00:17:46,410
hey everybody so even yesterday when we

00:17:44,640 --> 00:17:47,880
had the keynotes from you know state

00:17:46,410 --> 00:17:51,240
fields talk about what we're doing for

00:17:47,880 --> 00:17:53,070
our systems our memory strategies is

00:17:51,240 --> 00:17:55,650
changing you know in the power nine

00:17:53,070 --> 00:17:57,840
family we have the power 9 with a scale

00:17:55,650 --> 00:18:01,830
up with a scale out in the scale up we

00:17:57,840 --> 00:18:04,380
use the buffered memory and then in the

00:18:01,830 --> 00:18:06,780
scale out we have the direct-attached on

00:18:04,380 --> 00:18:09,260
our next unit on our next revision of

00:18:06,780 --> 00:18:12,240
the power 9 system with the power 9

00:18:09,260 --> 00:18:13,740
advanced i/o we're moving that to what

00:18:12,240 --> 00:18:18,510
we're calling the open capping memory

00:18:13,740 --> 00:18:21,059
interface and it's going to have all

00:18:18,510 --> 00:18:23,760
these you know all these qualities that

00:18:21,059 --> 00:18:26,669
that Brian mentioned before and we're

00:18:23,760 --> 00:18:28,799
moving that way because we need to have

00:18:26,669 --> 00:18:30,360
for the next generation of memories we

00:18:28,799 --> 00:18:32,280
will need to have extreme bandwidth

00:18:30,360 --> 00:18:34,200
we're looking for something that is

00:18:32,280 --> 00:18:36,750
going to be common and that we can use

00:18:34,200 --> 00:18:38,429
to to connect different type of memory

00:18:36,750 --> 00:18:40,380
technologies we'll talk about a little

00:18:38,429 --> 00:18:41,520
bit about storage glass memories but

00:18:40,380 --> 00:18:44,159
that's something that it's new and

00:18:41,520 --> 00:18:46,590
emerging and we want to be ready in our

00:18:44,159 --> 00:18:49,049
processor to support any of these types

00:18:46,590 --> 00:18:55,289
of technologies in the in the most

00:18:49,049 --> 00:18:57,960
efficient way we will also make this a

00:18:55,289 --> 00:19:00,270
common design that we will keep the rest

00:18:57,960 --> 00:19:03,480
features that we currently have on our

00:19:00,270 --> 00:19:04,770
enterprise systems we will also make

00:19:03,480 --> 00:19:08,370
sure that we can have a lot of capacity

00:19:04,770 --> 00:19:12,240
and bandwidth on it and it will also

00:19:08,370 --> 00:19:14,250
support the as I mentioned different

00:19:12,240 --> 00:19:20,309
technologies for for memory including

00:19:14,250 --> 00:19:22,530
storage glass memories this is how we're

00:19:20,309 --> 00:19:26,190
moving from in our systems we have the

00:19:22,530 --> 00:19:29,280
what we call IBM Center dims it has a

00:19:26,190 --> 00:19:33,480
buffer that has an L for cash it has

00:19:29,280 --> 00:19:36,360
extra rest and this one however is only

00:19:33,480 --> 00:19:38,220
used in our systems and then we had on

00:19:36,360 --> 00:19:40,409
the scale out we had the jeddak

00:19:38,220 --> 00:19:43,559
standardized industry standard themes

00:19:40,409 --> 00:19:45,780
and as we move forward we're going to

00:19:43,559 --> 00:19:48,390
the technology agnostic we're changing

00:19:45,780 --> 00:19:50,730
that the foreign factor but we're making

00:19:48,390 --> 00:19:52,330
it we're going to direct to a standard I

00:19:50,730 --> 00:19:57,219
said

00:19:52,330 --> 00:19:58,599
it will be low-cost it will have the

00:19:57,219 --> 00:20:00,429
enterprise reliability that is needed

00:19:58,599 --> 00:20:02,499
the latency even though we're putting a

00:20:00,429 --> 00:20:05,559
buffer in there's a lot of innovation

00:20:02,499 --> 00:20:07,239
and there's a buffer that microchip they

00:20:05,559 --> 00:20:09,429
will talk about later in another session

00:20:07,239 --> 00:20:11,830
they've done a lot of innovation to make

00:20:09,429 --> 00:20:15,129
sure that the latency doesn't go much

00:20:11,830 --> 00:20:18,219
higher than the direct attached memory

00:20:15,129 --> 00:20:20,739
and because we are connecting through

00:20:18,219 --> 00:20:23,739
the through the high-speed serial bosses

00:20:20,739 --> 00:20:25,659
at twenty five point six gig this is

00:20:23,739 --> 00:20:27,519
going to have a lot of high bandwidth

00:20:25,659 --> 00:20:32,499
with all the ports that we have on our

00:20:27,519 --> 00:20:35,649
processor the p9k i/o we're going to

00:20:32,499 --> 00:20:42,399
have 16 of these ports 16 of these by 8

00:20:35,649 --> 00:20:45,129
ports at 25 gig so why are we continue

00:20:42,399 --> 00:20:47,379
our message is that Oh am i is there the

00:20:45,129 --> 00:20:49,119
right thing to go for per memory and

00:20:47,379 --> 00:20:51,219
it's because it's going to be low

00:20:49,119 --> 00:20:53,769
latency high bandwidth and it's going to

00:20:51,219 --> 00:20:57,609
be technology agnostic we don't have to

00:20:53,769 --> 00:21:00,190
wait on another processor development to

00:20:57,609 --> 00:21:02,169
introduce new new new memory

00:21:00,190 --> 00:21:03,849
technologies we don't have to have a

00:21:02,169 --> 00:21:06,039
specific memory controller inside the

00:21:03,849 --> 00:21:08,139
chip we put that in a buffer under them

00:21:06,039 --> 00:21:11,289
and then we can support any of the

00:21:08,139 --> 00:21:13,509
transitions like when we go from ddr4 to

00:21:11,289 --> 00:21:16,330
3 r5 whenever it makes sense

00:21:13,509 --> 00:21:17,529
whenever the cost goes better for ddr 5

00:21:16,330 --> 00:21:18,849
we will be happy

00:21:17,529 --> 00:21:21,070
we'll have already have systems that are

00:21:18,849 --> 00:21:23,379
ready for it

00:21:21,070 --> 00:21:26,619
you will also allow for the new

00:21:23,379 --> 00:21:28,899
technologies and emerging an emergency

00:21:26,619 --> 00:21:30,519
merging memories like stack theorem low

00:21:28,899 --> 00:21:33,879
latency deer and things like that

00:21:30,519 --> 00:21:37,659
I also and it was mentioned before via

00:21:33,879 --> 00:21:41,559
session for the technology sort of the

00:21:37,659 --> 00:21:43,989
future we need to we need to be able to

00:21:41,559 --> 00:21:45,700
do that extra bandwidth and with having

00:21:43,989 --> 00:21:48,669
all these parallel eyes and all these

00:21:45,700 --> 00:21:50,679
pins the processor you will put it you

00:21:48,669 --> 00:21:52,509
will be using a lot of real estate to be

00:21:50,679 --> 00:21:55,869
able to put all these into the processor

00:21:52,509 --> 00:22:01,690
with omi for serializing that and that

00:21:55,869 --> 00:22:04,300
way we get we're able to - you know I

00:22:01,690 --> 00:22:06,640
love word I'm sorry

00:22:04,300 --> 00:22:09,070
so we were able to save those paint

00:22:06,640 --> 00:22:12,310
those paints from the from the processor

00:22:09,070 --> 00:22:18,340
to get them to a better use of your

00:22:12,310 --> 00:22:20,830
silicon and the big point is is through

00:22:18,340 --> 00:22:22,810
standardized through the open copy which

00:22:20,830 --> 00:22:26,410
we have you know it's open we're

00:22:22,810 --> 00:22:28,270
standardizing all these DIMMs did them

00:22:26,410 --> 00:22:31,330
differential dims we're standardizing

00:22:28,270 --> 00:22:33,790
them through genetic and other CPU

00:22:31,330 --> 00:22:35,530
architectures can use OMI an open cut

00:22:33,790 --> 00:22:40,510
copy this is not something only for

00:22:35,530 --> 00:22:43,030
power and of course we want to make sure

00:22:40,510 --> 00:22:45,370
that we establish this as a technology

00:22:43,030 --> 00:22:51,970
that other manufacturers will use to

00:22:45,370 --> 00:22:53,880
lower the cost foreign as mentioned the

00:22:51,970 --> 00:22:57,160
signaling rate is twenty five point six

00:22:53,880 --> 00:22:59,740
versus a DDR at thirty two mega thirty

00:22:57,160 --> 00:23:01,120
two hundred megahertz so right just raw

00:22:59,740 --> 00:23:06,640
bandwidth we get at four times

00:23:01,120 --> 00:23:08,770
improvement we are only having you know

00:23:06,640 --> 00:23:11,440
between five or two ten nanoseconds that

00:23:08,770 --> 00:23:13,570
we're adding into the latency so we want

00:23:11,440 --> 00:23:17,890
to make sure these performs just as any

00:23:13,570 --> 00:23:20,830
other industry standard memory and the

00:23:17,890 --> 00:23:22,950
microchip SMC is going to be that first

00:23:20,830 --> 00:23:27,190
buffer that we will use on our systems

00:23:22,950 --> 00:23:30,160
we are we develop we work with them to

00:23:27,190 --> 00:23:32,320
develop it but it is their design and it

00:23:30,160 --> 00:23:34,780
can be acquired through you know working

00:23:32,320 --> 00:23:37,450
with them that there's different chip

00:23:34,780 --> 00:23:45,670
vendor dimdim vendors that are working

00:23:37,450 --> 00:23:47,560
with them to build these new items so

00:23:45,670 --> 00:23:49,360
here's you know from a processor

00:23:47,560 --> 00:23:52,150
perspective we have our high-speed

00:23:49,360 --> 00:23:55,270
signalling transmitted it goes through

00:23:52,150 --> 00:23:57,430
the dam they do the different functions

00:23:55,270 --> 00:24:01,080
like laying these cue fast activate and

00:23:57,430 --> 00:24:04,390
then it gets to the theorem and back and

00:24:01,080 --> 00:24:09,580
we're making it you know this microchip

00:24:04,390 --> 00:24:11,650
SMC 1000 it has the innovation to keep

00:24:09,580 --> 00:24:13,840
that latency to the minimum we don't

00:24:11,650 --> 00:24:17,090
want to affect performance but we want

00:24:13,840 --> 00:24:19,009
to keep all the other benefits of omi

00:24:17,090 --> 00:24:22,129
the good thing also is like once they've

00:24:19,009 --> 00:24:25,309
done this type of buffer we can reuse

00:24:22,129 --> 00:24:27,519
that type of that side and then the

00:24:25,309 --> 00:24:29,659
other you know media controller

00:24:27,519 --> 00:24:31,460
controlling the media it's something

00:24:29,659 --> 00:24:33,379
that you know you can add in to

00:24:31,460 --> 00:24:39,529
different type of buffers to support

00:24:33,379 --> 00:24:41,419
other technologies and as I mentioned

00:24:39,529 --> 00:24:46,360
before this is the way we're going for

00:24:41,419 --> 00:24:50,840
power 9 advanced i/o we are we have the

00:24:46,360 --> 00:24:54,350
the CPU we have open copy which we also

00:24:50,840 --> 00:24:55,970
have in p9 and we have our OMI slots we

00:24:54,350 --> 00:24:59,480
will be able to put different memory

00:24:55,970 --> 00:25:01,970
technologies in both type of interfaces

00:24:59,480 --> 00:25:03,649
the ones that go through the OMI it's

00:25:01,970 --> 00:25:06,019
something that is more optimized for

00:25:03,649 --> 00:25:08,990
memory and then the ones are going to

00:25:06,019 --> 00:25:10,490
open copy it is an open in a boss that

00:25:08,990 --> 00:25:11,869
is also used for accelerators and

00:25:10,490 --> 00:25:15,320
accelerators it will have a little bit

00:25:11,869 --> 00:25:16,549
of extra latency but we're believed some

00:25:15,320 --> 00:25:19,450
of the technologies that we put out

00:25:16,549 --> 00:25:22,039
there will still be very useful and

00:25:19,450 --> 00:25:23,809
performance and cost efficient for some

00:25:22,039 --> 00:25:29,690
workloads and I'll talk about that in

00:25:23,809 --> 00:25:32,269
the you know coming slides another point

00:25:29,690 --> 00:25:36,110
I wanted to make here is that even for

00:25:32,269 --> 00:25:38,330
p9 which is what it's out there today in

00:25:36,110 --> 00:25:41,869
the market we're going to be able to put

00:25:38,330 --> 00:25:44,419
some hybrid memory subsystem like memory

00:25:41,869 --> 00:25:46,999
that is combined with storage back to

00:25:44,419 --> 00:25:50,149
making a low cost for specific

00:25:46,999 --> 00:25:51,889
applications that can can get the work

00:25:50,149 --> 00:25:56,029
done with a little bit of extra

00:25:51,889 --> 00:25:58,490
performance degradation so we will be

00:25:56,029 --> 00:26:00,619
able to on pin an existing p9 will be

00:25:58,490 --> 00:26:04,100
able to us use this hybrid memory

00:26:00,619 --> 00:26:07,460
subsystem on the open cubby ports as we

00:26:04,100 --> 00:26:11,480
move to p9 prime which is a p9i IO and

00:26:07,460 --> 00:26:15,580
p10 we will be able to also put all

00:26:11,480 --> 00:26:15,580
these memories into the omi channels

00:26:18,380 --> 00:26:22,220
another thing that Brian mentioned once

00:26:20,809 --> 00:26:25,220
they know few times is like storage

00:26:22,220 --> 00:26:27,440
class memory so what is that it's all

00:26:25,220 --> 00:26:29,179
these new emerging technologies that

00:26:27,440 --> 00:26:31,880
have properties like memory and

00:26:29,179 --> 00:26:34,280
properties like storage the main thing

00:26:31,880 --> 00:26:38,150
is it it's a byte addressable like

00:26:34,280 --> 00:26:40,419
memory it is fast not as fast as real

00:26:38,150 --> 00:26:44,799
memory but it's much faster than storage

00:26:40,419 --> 00:26:48,140
and also the key is that it's persistent

00:26:44,799 --> 00:26:51,770
so as we have many many were close now

00:26:48,140 --> 00:26:54,530
like in-memory databases you want to be

00:26:51,770 --> 00:26:57,470
able to have your data there and not

00:26:54,530 --> 00:26:59,780
have to go all the way to your disk to

00:26:57,470 --> 00:27:03,730
find to get it back if the database has

00:26:59,780 --> 00:27:06,650
to be restarted so the persistence

00:27:03,730 --> 00:27:10,309
qualities of storage class memory are

00:27:06,650 --> 00:27:17,030
great for the use case of quick quick

00:27:10,309 --> 00:27:19,909
restart of in-memory databases and we we

00:27:17,030 --> 00:27:22,309
see that as one of the use cases we are

00:27:19,909 --> 00:27:25,190
going to show you that hybrid memory

00:27:22,309 --> 00:27:27,799
subsystem to address this another key

00:27:25,190 --> 00:27:29,720
that we see is not just about quick

00:27:27,799 --> 00:27:32,450
restart of applications that have your

00:27:29,720 --> 00:27:35,679
data in memory it's also about cost

00:27:32,450 --> 00:27:39,169
performance if we look at the whole

00:27:35,679 --> 00:27:42,320
spread spectrum of technologies you have

00:27:39,169 --> 00:27:44,210
your DRAM in the you know it's volatile

00:27:42,320 --> 00:27:46,640
it's very fast it's the best that you

00:27:44,210 --> 00:27:49,730
can get for performance and then you got

00:27:46,640 --> 00:27:52,640
your none that is used today for storage

00:27:49,730 --> 00:27:56,780
it is persistent but then that's very

00:27:52,640 --> 00:28:00,440
high latency and and it's not fast

00:27:56,780 --> 00:28:02,200
enough for just to be memory but it is

00:28:00,440 --> 00:28:04,880
persistent and it's very very low cost

00:28:02,200 --> 00:28:07,970
there's new technologies out there today

00:28:04,880 --> 00:28:14,870
that are called alonein low latency NAND

00:28:07,970 --> 00:28:17,900
and it gets a big improvement in the

00:28:14,870 --> 00:28:20,990
latency that it has instead of hundreds

00:28:17,900 --> 00:28:23,750
you know thousands of microseconds you

00:28:20,990 --> 00:28:25,280
can get at less than 10 microseconds and

00:28:23,750 --> 00:28:30,559
when you're in the low latency Nantz

00:28:25,280 --> 00:28:32,390
area so you have all this range and we

00:28:30,559 --> 00:28:35,809
need a way of how do we use

00:28:32,390 --> 00:28:40,010
all that range for us memory to be able

00:28:35,809 --> 00:28:41,929
to tie it to the best performance cost

00:28:40,010 --> 00:28:48,410
performance applicant in your

00:28:41,929 --> 00:28:53,980
applications so with that we have been

00:28:48,410 --> 00:28:57,200
working on this hybrid memory subsystem

00:28:53,980 --> 00:28:58,760
we you know our design here is and with

00:28:57,200 --> 00:29:02,120
it this will be available with p9

00:28:58,760 --> 00:29:06,650
systems and it will be through the open

00:29:02,120 --> 00:29:09,860
copy slots the main thing is let's use

00:29:06,650 --> 00:29:13,429
this low latency NAND technology that is

00:29:09,860 --> 00:29:17,000
available today it is still too slow to

00:29:13,429 --> 00:29:17,660
be just uses memory as but with open

00:29:17,000 --> 00:29:21,290
copy

00:29:17,660 --> 00:29:24,679
we do have a mode that supports memory

00:29:21,290 --> 00:29:28,700
semantics load store memory semantics so

00:29:24,679 --> 00:29:31,880
we will put big capacity of low latency

00:29:28,700 --> 00:29:36,440
nan in that card and we will have enough

00:29:31,880 --> 00:29:37,910
of the DRAM as cache we have an FPGA

00:29:36,440 --> 00:29:40,370
we're working on the memory controller

00:29:37,910 --> 00:29:44,299
right now it's an FPGA and we're doing

00:29:40,370 --> 00:29:46,460
all the media everything you have to do

00:29:44,299 --> 00:29:48,590
for the media cuz it still flash so it

00:29:46,460 --> 00:29:51,860
doesn't have the endurance SDRAM so it

00:29:48,590 --> 00:29:55,130
does a lot of media management but we

00:29:51,860 --> 00:29:57,890
will also have there the controller to

00:29:55,130 --> 00:29:59,929
be able to cash and prefetch and other

00:29:57,890 --> 00:30:02,299
the data into your DRAM so the

00:29:59,929 --> 00:30:06,169
application doesn't see that it's very

00:30:02,299 --> 00:30:08,059
far away your data and the typical the

00:30:06,169 --> 00:30:11,690
primary application we're going after is

00:30:08,059 --> 00:30:13,910
the in-memory databases when you know

00:30:11,690 --> 00:30:16,130
that it's like for all that type of

00:30:13,910 --> 00:30:18,919
workloads when you're doing analytics

00:30:16,130 --> 00:30:20,960
and then you know where you're going so

00:30:18,919 --> 00:30:22,549
if it's not if you know where you're

00:30:20,960 --> 00:30:25,100
going and what you need to get next

00:30:22,549 --> 00:30:29,150
we're going to be able to hide the extra

00:30:25,100 --> 00:30:31,990
latency of the low latency nan and this

00:30:29,150 --> 00:30:35,750
card we've been working on it as a

00:30:31,990 --> 00:30:40,070
partnership to get the media but also

00:30:35,750 --> 00:30:43,550
for my adapter development and design

00:30:40,070 --> 00:30:46,299
bit where has built there on the card

00:30:43,550 --> 00:30:49,340
here it has the

00:30:46,299 --> 00:30:53,020
it is a form factor of PCI so it would

00:30:49,340 --> 00:30:54,799
go into your existing systems it has a

00:30:53,020 --> 00:30:59,170
form factor

00:30:54,799 --> 00:31:03,260
kind of like my m2 sticks it's not m2

00:30:59,170 --> 00:31:05,090
that we use but for a map from a

00:31:03,260 --> 00:31:09,350
physical perspective it just looks like

00:31:05,090 --> 00:31:12,679
an m2 then we have four of them here

00:31:09,350 --> 00:31:16,910
those are the ones that have the low

00:31:12,679 --> 00:31:23,270
latency nine components then that is

00:31:16,910 --> 00:31:25,790
connected to your FPGA and open copy you

00:31:23,270 --> 00:31:27,799
get your power from your PCI slots on

00:31:25,790 --> 00:31:30,890
the system but then you get the data

00:31:27,799 --> 00:31:32,360
talks through open copy we're working

00:31:30,890 --> 00:31:34,070
right now this is you know prototype

00:31:32,360 --> 00:31:36,110
that we have we're working in the lab

00:31:34,070 --> 00:31:40,220
with them making sure everything works

00:31:36,110 --> 00:31:41,510
and also get all the everything worked

00:31:40,220 --> 00:31:43,960
in the memory controller to get the

00:31:41,510 --> 00:31:46,700
performance that we need for these and

00:31:43,960 --> 00:31:48,710
what we believe is that these will have

00:31:46,700 --> 00:31:51,500
a cost point that would be attractive

00:31:48,710 --> 00:31:53,390
for those workloads and we also believe

00:31:51,500 --> 00:31:56,360
that in the future it's going to be a

00:31:53,390 --> 00:31:58,190
lot of different tiers of cost

00:31:56,360 --> 00:32:00,230
performance depending on your

00:31:58,190 --> 00:32:02,720
application you might want to use these

00:32:00,230 --> 00:32:05,570
depending on other applications instead

00:32:02,720 --> 00:32:08,030
we will go through omi either 2d ram

00:32:05,570 --> 00:32:10,640
through that with a microchip buffer or

00:32:08,030 --> 00:32:13,040
we will go to something in between you

00:32:10,640 --> 00:32:16,610
know it just depends the right point for

00:32:13,040 --> 00:32:19,250
the workload what is the what is okay to

00:32:16,610 --> 00:32:21,020
it when is it okay to go slower to

00:32:19,250 --> 00:32:23,690
slower media when do you really need to

00:32:21,020 --> 00:32:25,549
be fast and with omi it will be very

00:32:23,690 --> 00:32:29,750
flexible because we can connect anything

00:32:25,549 --> 00:32:35,419
to our power 9 advanced i/o and 12 power

00:32:29,750 --> 00:32:37,010
10 processors if you have questions

00:32:35,419 --> 00:32:41,750
about it you know so we have the card

00:32:37,010 --> 00:32:46,220
within the bit where booth and then just

00:32:41,750 --> 00:32:49,610
to summarize you know the talk today was

00:32:46,220 --> 00:32:50,960
about our roadmap with power 9 then you

00:32:49,610 --> 00:32:53,240
know the final thing the final

00:32:50,960 --> 00:32:55,250
additional we're having in the family is

00:32:53,240 --> 00:32:59,630
at power 9a i/o

00:32:55,250 --> 00:33:01,310
and as Brian mentioned you know

00:32:59,630 --> 00:33:04,760
it's not a lot we're not making any

00:33:01,310 --> 00:33:07,430
changes in the core of the processor but

00:33:04,760 --> 00:33:08,720
everything around in the IO is where

00:33:07,430 --> 00:33:12,050
we're putting all the innovation in this

00:33:08,720 --> 00:33:13,280
one because it's all about you know we

00:33:12,050 --> 00:33:16,250
might not get all the differentiation in

00:33:13,280 --> 00:33:18,200
core strength right now and in the

00:33:16,250 --> 00:33:20,750
future you know the next technology will

00:33:18,200 --> 00:33:23,840
get that but for right now we're making

00:33:20,750 --> 00:33:26,690
sure that also all the the bandwidth

00:33:23,840 --> 00:33:28,640
that you get works well from the

00:33:26,690 --> 00:33:30,650
different you know just not to get into

00:33:28,640 --> 00:33:33,680
the memory get into your i/o getting the

00:33:30,650 --> 00:33:34,910
data where you need it to do all the to

00:33:33,680 --> 00:33:37,550
the world you know get the best

00:33:34,910 --> 00:33:59,150
performance possible if there are

00:33:37,550 --> 00:34:01,400
questions yes so will you will now that

00:33:59,150 --> 00:34:05,090
we're moving into the Oh am i you will

00:34:01,400 --> 00:34:07,610
still need to have a buffer or some

00:34:05,090 --> 00:34:09,889
controller in between so we will get

00:34:07,610 --> 00:34:11,659
from the power 9 you will get different

00:34:09,889 --> 00:34:14,450
processor you will have your OMI

00:34:11,659 --> 00:34:17,389
interface from memory the Oh Emma yeah

00:34:14,450 --> 00:34:20,419
Oh am i but you will need something to

00:34:17,389 --> 00:34:21,950
talk to your to your sims and it could

00:34:20,419 --> 00:34:24,290
be industry standard and so you'd have

00:34:21,950 --> 00:34:29,919
to you have to put that into the planer

00:34:24,290 --> 00:34:29,919
that is a supported configuration

00:34:39,659 --> 00:34:44,800
yeah so that you know the systems will

00:34:43,149 --> 00:34:46,750
go out next year so there's right now

00:34:44,800 --> 00:34:49,960
work with the different vendors on what

00:34:46,750 --> 00:34:51,609
it is and the main thing is on the the

00:34:49,960 --> 00:34:54,460
buffer we wanted to make sure that it's

00:34:51,609 --> 00:34:57,069
going to be competitive pricing

00:34:54,460 --> 00:35:11,380
I cannot say like you know tell exactly

00:34:57,069 --> 00:35:12,819
what it will be yeah yes Zeron yes he

00:35:11,380 --> 00:35:15,450
was asking which type of low-latency

00:35:12,819 --> 00:35:15,450
non-producing

00:35:19,510 --> 00:35:25,660
okay any questions for me or for Brian

00:35:23,790 --> 00:35:29,369
okay we appreciate it

00:35:25,660 --> 00:35:29,369

YouTube URL: https://www.youtube.com/watch?v=e6r-MVyr2nQ


