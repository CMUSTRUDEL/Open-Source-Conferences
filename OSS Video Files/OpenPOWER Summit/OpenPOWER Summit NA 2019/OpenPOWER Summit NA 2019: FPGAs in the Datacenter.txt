Title: OpenPOWER Summit NA 2019: FPGAs in the Datacenter
Publication date: 2019-08-20
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Steve Hebert, Nimbix
Captions: 
	00:00:00,030 --> 00:00:06,830
thank you very much Peter and it's great

00:00:02,190 --> 00:00:09,719
to be here last talked before cocktails

00:00:06,830 --> 00:00:12,150
so just a little bit of background you

00:00:09,719 --> 00:00:14,519
know we you know I the talk is FPGAs in

00:00:12,150 --> 00:00:15,719
the data center and at hyperscale and i

00:00:14,519 --> 00:00:17,369
was thinking about this and it's

00:00:15,719 --> 00:00:18,810
interesting because we said we talked

00:00:17,369 --> 00:00:20,310
about FPGAs in the data center and

00:00:18,810 --> 00:00:22,740
actually they've been in the data center

00:00:20,310 --> 00:00:24,930
a long time you know Wireless you know

00:00:22,740 --> 00:00:28,519
wired communications wireline networking

00:00:24,930 --> 00:00:30,900
all you know large homes to massive

00:00:28,519 --> 00:00:33,329
quantities of FPGAs that have shipped

00:00:30,900 --> 00:00:35,579
over the last couple of decades or all

00:00:33,329 --> 00:00:36,809
in data centers so I think we we

00:00:35,579 --> 00:00:37,890
actually are really talking about when

00:00:36,809 --> 00:00:39,960
we talk about the data center we're

00:00:37,890 --> 00:00:42,809
talking about computing in the new ways

00:00:39,960 --> 00:00:44,789
that FPGAs are being applied and I

00:00:42,809 --> 00:00:46,500
wanted to talk a little bit about you

00:00:44,789 --> 00:00:50,539
know the whole concept of hyper scale

00:00:46,500 --> 00:00:53,190
and why this is important you know to me

00:00:50,539 --> 00:00:58,859
you know at NIMH bik's as Nimbus has

00:00:53,190 --> 00:01:01,649
been all about the driving the vision

00:00:58,859 --> 00:01:04,949
for reconfigurable computing at hyper

00:01:01,649 --> 00:01:07,799
scale the notion of FPGAs purpose-built

00:01:04,949 --> 00:01:10,049
you know for specific workloads so that

00:01:07,799 --> 00:01:11,640
we can process information faster with

00:01:10,049 --> 00:01:14,189
the new types of workloads that we're

00:01:11,640 --> 00:01:15,840
seeing across the globe you know AI

00:01:14,189 --> 00:01:18,030
being obviously one of those and we'll

00:01:15,840 --> 00:01:20,009
talk about that in a second since in

00:01:18,030 --> 00:01:23,100
since our inception you know really back

00:01:20,009 --> 00:01:25,920
in 2010 this has been a you know an area

00:01:23,100 --> 00:01:28,320
that we've been really trying to pioneer

00:01:25,920 --> 00:01:30,869
and in the you know spirit of the open

00:01:28,320 --> 00:01:33,229
power you know ecosystem obviously a lot

00:01:30,869 --> 00:01:36,689
of the work that's being done in open

00:01:33,229 --> 00:01:39,150
open power with Cappy Cappy Snap we've

00:01:36,689 --> 00:01:41,070
been involved with but also just you

00:01:39,150 --> 00:01:46,890
know FPGAs in general so we'll talk a

00:01:41,070 --> 00:01:50,130
little bit about that okay so you know

00:01:46,890 --> 00:01:52,649
you guys are real quick how many folks

00:01:50,130 --> 00:01:54,390
are hardware centric consider cells

00:01:52,649 --> 00:01:57,860
Hardware people okay

00:01:54,390 --> 00:02:00,689
quite a bit any software software okay

00:01:57,860 --> 00:02:04,040
so this is we're gonna take we're going

00:02:00,689 --> 00:02:10,070
to go up the stack but the idea here is

00:02:04,040 --> 00:02:13,200
I'm actually a hardware guy myself and

00:02:10,070 --> 00:02:16,530
love hardware and part of the challenge

00:02:13,200 --> 00:02:18,300
of getting to large quantities large

00:02:16,530 --> 00:02:21,360
volumes of any kind of hardware is

00:02:18,300 --> 00:02:23,730
finding the applications that will

00:02:21,360 --> 00:02:27,930
consume that hardware at scale and it

00:02:23,730 --> 00:02:29,420
seems like my adapter is not happy here

00:02:27,930 --> 00:02:33,200
[Music]

00:02:29,420 --> 00:02:33,200
let me try it differently

00:02:36,629 --> 00:02:48,120
I think it's just the connector all

00:02:46,260 --> 00:02:51,269
right let's see if we can get lucky here

00:02:48,120 --> 00:02:52,260
okay so if you guys remember for those

00:02:51,269 --> 00:02:53,819
of you that have been around the

00:02:52,260 --> 00:02:56,340
hardware for a while in the 80s and 90s

00:02:53,819 --> 00:02:58,590
you know it was a lot of logic you know

00:02:56,340 --> 00:03:01,349
we talked about you know I used to sell

00:02:58,590 --> 00:03:03,510
actually for Texas Instruments the just

00:03:01,349 --> 00:03:05,579
standard logic right discrete logic

00:03:03,510 --> 00:03:07,409
components and we'd have boards full of

00:03:05,579 --> 00:03:09,389
discrete logic components and the

00:03:07,409 --> 00:03:11,040
competitive devices were FPGAs that

00:03:09,389 --> 00:03:13,319
could suck all that up into a single

00:03:11,040 --> 00:03:14,549
chip so you did that for integration it

00:03:13,319 --> 00:03:16,739
was important obviously in

00:03:14,549 --> 00:03:19,260
communications industrial and embedded

00:03:16,739 --> 00:03:20,730
applications and over the years we've

00:03:19,260 --> 00:03:22,530
seen the technology advanced

00:03:20,730 --> 00:03:24,510
dramatically you know with surtees in

00:03:22,530 --> 00:03:26,879
the FPGA you've got you know massive

00:03:24,510 --> 00:03:28,919
numbers of gates and logic you're

00:03:26,879 --> 00:03:31,379
putting entire systems on these chips

00:03:28,919 --> 00:03:34,189
processors in these chips and you know

00:03:31,379 --> 00:03:37,829
but you tended to think of these as

00:03:34,189 --> 00:03:40,019
devices that ultimately ran and

00:03:37,829 --> 00:03:42,599
typically very customized applications

00:03:40,019 --> 00:03:44,970
and in low-volume so we think about what

00:03:42,599 --> 00:03:47,489
are the things that start to unlock the

00:03:44,970 --> 00:03:50,430
potential of FPGAs you know as we

00:03:47,489 --> 00:03:51,959
continue to advance in our technology so

00:03:50,430 --> 00:03:53,970
again it's kind of taking this concept

00:03:51,959 --> 00:03:56,220
of looking at FPGAs historically you

00:03:53,970 --> 00:03:58,680
know you think about ASIC emulation the

00:03:56,220 --> 00:04:00,359
applications that I mentioned you know

00:03:58,680 --> 00:04:03,030
areas that you guys are all very

00:04:00,359 --> 00:04:05,639
familiar with and one of the challenges

00:04:03,030 --> 00:04:08,220
in the data center is how do you put

00:04:05,639 --> 00:04:11,729
these you know multi-thousand dollar

00:04:08,220 --> 00:04:14,069
devices in servers where you're

00:04:11,729 --> 00:04:16,680
constantly pushing component costs down

00:04:14,069 --> 00:04:17,789
to you know very inexpensive things so

00:04:16,680 --> 00:04:20,489
that you can scale out those those

00:04:17,789 --> 00:04:22,680
volumes and and so those seem like

00:04:20,489 --> 00:04:24,330
they're in congruent but part of what's

00:04:22,680 --> 00:04:27,990
really interesting about the time we're

00:04:24,330 --> 00:04:30,539
in right now with pushing through

00:04:27,990 --> 00:04:32,580
especially around open power and open

00:04:30,539 --> 00:04:35,370
copy and mechanisms and frameworks that

00:04:32,580 --> 00:04:36,690
help democratize access is driving the

00:04:35,370 --> 00:04:38,490
numbers of applications that can

00:04:36,690 --> 00:04:40,229
actually consume this hardware to

00:04:38,490 --> 00:04:45,469
quote-unquote commoditize it to some

00:04:40,229 --> 00:04:47,849
extent so let's look at hyper scale

00:04:45,469 --> 00:04:49,620
deployment and cloud evolution and

00:04:47,849 --> 00:04:50,130
actually if we think back to the

00:04:49,620 --> 00:04:52,200
beginning of

00:04:50,130 --> 00:04:56,640
you know Amazon which is really the sort

00:04:52,200 --> 00:04:58,430
of the parent of cloud computing it was

00:04:56,640 --> 00:05:02,250
really ushered in with open source

00:04:58,430 --> 00:05:04,560
virtualization technology and quasi left

00:05:02,250 --> 00:05:06,690
over computing from e-commerce right

00:05:04,560 --> 00:05:10,620
that was now being repurposed and sold

00:05:06,690 --> 00:05:12,690
as computing cycles initially targeted

00:05:10,620 --> 00:05:14,910
in a very developer centric way right

00:05:12,690 --> 00:05:18,120
lightweight applications web services

00:05:14,910 --> 00:05:19,710
things like that and this was breaking

00:05:18,120 --> 00:05:21,270
the notion of enterprise computing where

00:05:19,710 --> 00:05:23,460
you're standing up you know very

00:05:21,270 --> 00:05:25,650
feature-rich machines and the hyper

00:05:23,460 --> 00:05:28,350
scalars you know Amazon in particular

00:05:25,650 --> 00:05:30,570
Google Microsoft were stripping

00:05:28,350 --> 00:05:33,840
everything out and focused on again

00:05:30,570 --> 00:05:35,760
commoditized volume but what we've seen

00:05:33,840 --> 00:05:38,880
in the last several years and NIMH bik's

00:05:35,760 --> 00:05:41,190
has really been sort of you know really

00:05:38,880 --> 00:05:44,370
pushing the envelope on the type of

00:05:41,190 --> 00:05:47,130
class of infrastructure that it you know

00:05:44,370 --> 00:05:48,870
that we host in our cloud but you're

00:05:47,130 --> 00:05:51,420
staying that from all the major

00:05:48,870 --> 00:05:53,880
providers around the globe and that is

00:05:51,420 --> 00:05:55,320
evolving because the demands of the type

00:05:53,880 --> 00:05:58,260
of work that they're putting on are

00:05:55,320 --> 00:05:59,910
changing the their focus not just on the

00:05:58,260 --> 00:06:02,130
developers of lightweight applications

00:05:59,910 --> 00:06:04,380
but they're recognizing that what

00:06:02,130 --> 00:06:06,840
enterprises and people need to compute

00:06:04,380 --> 00:06:08,780
are different classes of workloads that

00:06:06,840 --> 00:06:10,640
have very sort of sophisticated

00:06:08,780 --> 00:06:13,590
requirements from the infrastructure

00:06:10,640 --> 00:06:15,710
itself and then you've seen the

00:06:13,590 --> 00:06:19,650
evolution to heterogeneous computing

00:06:15,710 --> 00:06:21,090
with GPUs and FPGAs so for those of you

00:06:19,650 --> 00:06:23,250
that have followed what's happened over

00:06:21,090 --> 00:06:25,110
the last ten years let's say with GPUs

00:06:23,250 --> 00:06:26,850
it's been pretty fascinating to watch

00:06:25,110 --> 00:06:29,940
and I expect the actual same thing to

00:06:26,850 --> 00:06:31,740
happen with with FPGAs and that is you

00:06:29,940 --> 00:06:36,990
know you take this graphics technology

00:06:31,740 --> 00:06:39,870
and you find a few applications where

00:06:36,990 --> 00:06:41,880
they used sort of the the actual

00:06:39,870 --> 00:06:45,720
architectural advantages of a GPU for

00:06:41,880 --> 00:06:48,030
vector processing to speed up HPC

00:06:45,720 --> 00:06:50,040
applications as one example or real time

00:06:48,030 --> 00:06:52,530
ray tracing very specific applications

00:06:50,040 --> 00:06:55,020
and it didn't take long before the

00:06:52,530 --> 00:06:56,790
number of use cases and graduate

00:06:55,020 --> 00:07:00,390
programs graduate students writing code

00:06:56,790 --> 00:07:03,100
in CUDA to target this hardware and

00:07:00,390 --> 00:07:05,050
NVIDIA did a nice job of you know caps

00:07:03,100 --> 00:07:07,060
during this in building cards for the

00:07:05,050 --> 00:07:09,280
data center and now you're seeing that

00:07:07,060 --> 00:07:10,720
go and I remember in 2010 I was at the

00:07:09,280 --> 00:07:14,500
supercomputing conference in New Orleans

00:07:10,720 --> 00:07:17,020
and it was almost heresy to talk about

00:07:14,500 --> 00:07:20,500
putting things other than lots and lots

00:07:17,020 --> 00:07:22,570
of CPUs in a big cluster and now you

00:07:20,500 --> 00:07:24,820
can't find a supercomputer that doesn't

00:07:22,570 --> 00:07:28,270
have a GPU in it or a cloud on the

00:07:24,820 --> 00:07:31,030
planet that doesn't have GPUs as a large

00:07:28,270 --> 00:07:33,820
scale deployment and we're just at the

00:07:31,030 --> 00:07:37,990
beginnings of this same trend with with

00:07:33,820 --> 00:07:39,130
FPGAs and the reason why we're at the

00:07:37,990 --> 00:07:41,410
beginning and we're seeing this trend

00:07:39,130 --> 00:07:44,230
now is that there's a need for both

00:07:41,410 --> 00:07:48,280
performance from a lot more people and

00:07:44,230 --> 00:07:50,860
and agility from these people so it's

00:07:48,280 --> 00:07:53,760
not just in the realm of academics and

00:07:50,860 --> 00:07:57,400
research it's in the realm of day-to-day

00:07:53,760 --> 00:08:00,040
enterprise computing that needs this

00:07:57,400 --> 00:08:01,480
type of processing power and that is you

00:08:00,040 --> 00:08:03,940
know goes from deep learning and AI to

00:08:01,480 --> 00:08:08,290
large-scale computation so traditional

00:08:03,940 --> 00:08:11,350
HPC and in HPC algorithms that can you

00:08:08,290 --> 00:08:12,640
know be accelerated in these new types

00:08:11,350 --> 00:08:14,920
of architectures in these new

00:08:12,640 --> 00:08:18,730
technologies and then we're also seeing

00:08:14,920 --> 00:08:21,070
this convergence around again hyper

00:08:18,730 --> 00:08:23,320
scale right the need for the agility to

00:08:21,070 --> 00:08:25,210
where as one company you don't have to

00:08:23,320 --> 00:08:27,760
build these monolithic systems you can

00:08:25,210 --> 00:08:29,740
actually leverage computing power of

00:08:27,760 --> 00:08:31,810
other providers in the space and

00:08:29,740 --> 00:08:38,490
leveraging on unique capabilities and

00:08:31,810 --> 00:08:40,360
architectures from those providers so

00:08:38,490 --> 00:08:41,860
one of the things that I find

00:08:40,360 --> 00:08:43,270
interesting is that you've got these

00:08:41,860 --> 00:08:46,360
kind of mega trends happening in the

00:08:43,270 --> 00:08:49,180
background you've got demands from the

00:08:46,360 --> 00:08:50,530
market and when it comes to FPGAs

00:08:49,180 --> 00:08:52,570
there's been a challenge and we've been

00:08:50,530 --> 00:08:55,840
working on this now for literally I

00:08:52,570 --> 00:08:57,880
think nine years right our first FPGAs

00:08:55,840 --> 00:08:59,500
and our cloud were actually supported

00:08:57,880 --> 00:09:03,010
with if you guys remember if you've been

00:08:59,500 --> 00:09:05,020
around at the conve computer hybrid core

00:09:03,010 --> 00:09:07,090
systems that had Xilinx FPGA x' in them

00:09:05,020 --> 00:09:10,180
as a co processing engine it was a

00:09:07,090 --> 00:09:12,970
pretty monolithic design on a standard

00:09:10,180 --> 00:09:14,770
1u server but very specific you know

00:09:12,970 --> 00:09:16,450
customized architecture and they were

00:09:14,770 --> 00:09:17,890
you know hard

00:09:16,450 --> 00:09:20,260
program and that's something that's been

00:09:17,890 --> 00:09:22,660
a challenge with FPGAs and when you look

00:09:20,260 --> 00:09:24,430
at you know the the methodologies and we

00:09:22,660 --> 00:09:26,020
saw some of this with you know and some

00:09:24,430 --> 00:09:28,810
of the great advances in the work with

00:09:26,020 --> 00:09:31,990
frameworks like copy snap moving to open

00:09:28,810 --> 00:09:35,200
copy which are helping democratize the

00:09:31,990 --> 00:09:37,360
ability to get code into these hardware

00:09:35,200 --> 00:09:40,360
systems but you take it going back to

00:09:37,360 --> 00:09:42,160
RTL to actually that being able to

00:09:40,360 --> 00:09:43,960
synthesize from IP blocks that are

00:09:42,160 --> 00:09:46,480
already off-the-shelf which is helping

00:09:43,960 --> 00:09:49,180
you know shrink design cycles - all the

00:09:46,480 --> 00:09:51,510
way to high level languages and the

00:09:49,180 --> 00:09:53,890
ability to use tools to actually take

00:09:51,510 --> 00:09:56,320
existing code and actually target that

00:09:53,890 --> 00:09:58,740
to the devices so we're seeing a

00:09:56,320 --> 00:10:00,910
movement from these monolithic

00:09:58,740 --> 00:10:03,700
self-contained tools environments where

00:10:00,910 --> 00:10:05,980
an FPGA developer is in a lab on a

00:10:03,700 --> 00:10:08,920
machine with a board and a set of

00:10:05,980 --> 00:10:11,320
expensive tools - we're starting to see

00:10:08,920 --> 00:10:13,930
that open up into more collaborative

00:10:11,320 --> 00:10:16,540
cloud-based environments we're seeing

00:10:13,930 --> 00:10:18,850
you know historically you know long

00:10:16,540 --> 00:10:20,680
design cycles you know how get

00:10:18,850 --> 00:10:23,170
compressed we're needing to get to

00:10:20,680 --> 00:10:25,210
market faster with these these new types

00:10:23,170 --> 00:10:28,840
of codes and being able to iterate break

00:10:25,210 --> 00:10:31,450
things and you know because we're

00:10:28,840 --> 00:10:34,000
shifting the way developers do it it's

00:10:31,450 --> 00:10:35,760
not as big of a crime if they do break

00:10:34,000 --> 00:10:38,260
things right because they didn't spend

00:10:35,760 --> 00:10:40,360
$20,000 on boards and tools and so forth

00:10:38,260 --> 00:10:43,570
to try to get their their software

00:10:40,360 --> 00:10:45,400
working testing on local hardware and

00:10:43,570 --> 00:10:47,200
then also being able to expand that

00:10:45,400 --> 00:10:50,590
outside of the local environment and

00:10:47,200 --> 00:10:53,350
then moving from customized hardware to

00:10:50,590 --> 00:10:55,090
more open in standardized hardware and

00:10:53,350 --> 00:10:57,850
this is everything that you're seeing

00:10:55,090 --> 00:11:01,150
here you know at the open power summit

00:10:57,850 --> 00:11:02,830
as well as cards like zhiling Salvio

00:11:01,150 --> 00:11:07,720
which has created you know their first

00:11:02,830 --> 00:11:10,540
their own branded form factor and create

00:11:07,720 --> 00:11:13,030
some standardization for the market to

00:11:10,540 --> 00:11:16,570
actually target versus again a lot of

00:11:13,030 --> 00:11:19,240
highly differentiated systems that again

00:11:16,570 --> 00:11:21,990
just prevent sort of the scaling process

00:11:19,240 --> 00:11:21,990
from happening

00:11:22,970 --> 00:11:28,790
so the next challenge of course is when

00:11:26,420 --> 00:11:30,770
you compared to traditional FPGA

00:11:28,790 --> 00:11:32,510
software development the demands that

00:11:30,770 --> 00:11:34,070
are going on in the rest of the market

00:11:32,510 --> 00:11:37,040
around software and applications that

00:11:34,070 --> 00:11:39,770
are being consumed by large

00:11:37,040 --> 00:11:43,190
organizations and they're needing these

00:11:39,770 --> 00:11:46,130
applications to be runnable on Prem on

00:11:43,190 --> 00:11:49,670
their existing clusters on their cloud

00:11:46,130 --> 00:11:52,130
partners infrastructure and over the

00:11:49,670 --> 00:11:55,070
last decade we've seen lots and lots of

00:11:52,130 --> 00:11:56,780
software companies build software that's

00:11:55,070 --> 00:11:58,970
distributed in traditional ways we've

00:11:56,780 --> 00:12:01,010
seen them build scaffolding to actually

00:11:58,970 --> 00:12:02,930
deploy it in an automated way on a cloud

00:12:01,010 --> 00:12:05,510
provider of their choice but it tended

00:12:02,930 --> 00:12:07,840
to be glued into either an Amazon or a

00:12:05,510 --> 00:12:12,320
Google or a Microsoft for example and

00:12:07,840 --> 00:12:14,620
increasingly organizations are wanting

00:12:12,320 --> 00:12:19,280
that software to be deployable anywhere

00:12:14,620 --> 00:12:20,630
and part of what the technology that's

00:12:19,280 --> 00:12:22,820
enabling that to happen is the

00:12:20,630 --> 00:12:24,110
proliferation of containers and what I'm

00:12:22,820 --> 00:12:26,450
going to do is transition a little bit

00:12:24,110 --> 00:12:29,300
about you know kind of this look at

00:12:26,450 --> 00:12:31,280
getting FPGAs to scale in the data

00:12:29,300 --> 00:12:33,560
center and then also some of the ways

00:12:31,280 --> 00:12:35,870
that Nimbus is working to help enable

00:12:33,560 --> 00:12:38,210
that democratize access and speed up

00:12:35,870 --> 00:12:39,920
time to accelerate both software

00:12:38,210 --> 00:12:42,860
development as well as deployment of

00:12:39,920 --> 00:12:44,810
hardware and part of again the way that

00:12:42,860 --> 00:12:46,850
this ecosystem is evolving is the use of

00:12:44,810 --> 00:12:48,650
containers and what we're finding and

00:12:46,850 --> 00:12:52,340
certainly Nimbus has been supporting for

00:12:48,650 --> 00:12:55,010
for several years is the use of this

00:12:52,340 --> 00:12:57,710
type of technology to create FPGA

00:12:55,010 --> 00:13:00,020
accelerated software package it so that

00:12:57,710 --> 00:13:03,110
it's deployable anywhere and runnable on

00:13:00,020 --> 00:13:05,810
the bare metal FPGA hardware and the

00:13:03,110 --> 00:13:07,580
benefits to this or a couple fold one is

00:13:05,810 --> 00:13:10,040
that you're generally using FPGA is

00:13:07,580 --> 00:13:11,089
because you want performance and the

00:13:10,040 --> 00:13:13,820
other thing is when you're trying to

00:13:11,089 --> 00:13:16,910
scale out the hardware you don't

00:13:13,820 --> 00:13:19,670
necessarily want to be limited or

00:13:16,910 --> 00:13:21,650
constrained by the hypervisor that's

00:13:19,670 --> 00:13:23,720
running you know underneath or have to

00:13:21,650 --> 00:13:25,040
pass through the hardware and do a lot

00:13:23,720 --> 00:13:27,170
of kind of unique things in the

00:13:25,040 --> 00:13:29,150
infrastructure layer to actually pass

00:13:27,170 --> 00:13:30,800
through that that hardware and actually

00:13:29,150 --> 00:13:32,810
a good case in point of that is when you

00:13:30,800 --> 00:13:34,970
know Amazon's you know release of the f1

00:13:32,810 --> 00:13:36,649
which has been fantastic for the market

00:13:34,970 --> 00:13:39,019
I think Alibaba has

00:13:36,649 --> 00:13:41,240
jiae's as a service offering as well but

00:13:39,019 --> 00:13:43,100
ultimately what customers want to do is

00:13:41,240 --> 00:13:46,699
be able to consume the software

00:13:43,100 --> 00:13:49,189
applications at scale and so containers

00:13:46,699 --> 00:13:50,839
has become a mechanism by which many

00:13:49,189 --> 00:13:53,420
software companies are now packaging

00:13:50,839 --> 00:13:56,540
their code and deploying them you know

00:13:53,420 --> 00:13:58,790
across environments and it enables

00:13:56,540 --> 00:14:00,499
applications to work both in a

00:13:58,790 --> 00:14:05,089
virtualized environment as well as a

00:14:00,499 --> 00:14:06,769
bare-metal environment so let's look at

00:14:05,089 --> 00:14:09,619
kind of the flow of that from an

00:14:06,769 --> 00:14:13,009
application ecosystem standpoint in the

00:14:09,619 --> 00:14:15,259
container world you see from kind of

00:14:13,009 --> 00:14:17,300
left-to-right formats registries

00:14:15,259 --> 00:14:19,399
platforms and runtimes and so in formats

00:14:17,300 --> 00:14:22,279
obviously the most prolific is docker in

00:14:19,399 --> 00:14:26,059
the HPC community singularity has become

00:14:22,279 --> 00:14:28,069
you know popular as well from a registry

00:14:26,059 --> 00:14:29,809
standpoint docker hub you know you have

00:14:28,069 --> 00:14:32,149
Google there's you know Nvidia has a

00:14:29,809 --> 00:14:34,160
container registry I'll talk to you in a

00:14:32,149 --> 00:14:36,860
minute about hyper hub and then

00:14:34,160 --> 00:14:39,050
platforms obviously our container native

00:14:36,860 --> 00:14:40,220
platforms like kubernetes maysa and

00:14:39,050 --> 00:14:42,529
we're seeing obviously kubernetes

00:14:40,220 --> 00:14:46,399
proliferate immensely especially in the

00:14:42,529 --> 00:14:47,959
deep learning side of things Jarvis the

00:14:46,399 --> 00:14:48,769
the platform that actually powers the

00:14:47,959 --> 00:14:50,660
Nimbus cloud

00:14:48,769 --> 00:14:53,089
is a container native platform that's

00:14:50,660 --> 00:14:56,709
been focused on accelerated computing an

00:14:53,089 --> 00:14:59,389
HPC so you know very tightly coupled

00:14:56,709 --> 00:15:02,720
workloads and workflows as well as

00:14:59,389 --> 00:15:05,749
obviously FPGA and GPU GPU powered

00:15:02,720 --> 00:15:07,910
workflows and then runtimes obviously

00:15:05,749 --> 00:15:10,790
having the actual container runtime to

00:15:07,910 --> 00:15:13,279
actually execute the applications so if

00:15:10,790 --> 00:15:14,779
you're an ISV a software developer

00:15:13,279 --> 00:15:16,309
you're concerned with building

00:15:14,779 --> 00:15:19,189
distributing and monetizing the

00:15:16,309 --> 00:15:20,870
applications in your choosing your

00:15:19,189 --> 00:15:23,540
delivery mechanisms well part of getting

00:15:20,870 --> 00:15:25,100
to hyper scale is is being able to have

00:15:23,540 --> 00:15:27,470
those applications be consumable

00:15:25,100 --> 00:15:30,309
anywhere and so containerization is a

00:15:27,470 --> 00:15:33,709
very important technology enabler to

00:15:30,309 --> 00:15:36,319
helping speed up the time to deployment

00:15:33,709 --> 00:15:37,759
of new infrastructure and then the

00:15:36,319 --> 00:15:42,139
software that can actually consume that

00:15:37,759 --> 00:15:44,360
infrastructure so what Nimbus announced

00:15:42,139 --> 00:15:47,089
actually last week is part of our effort

00:15:44,360 --> 00:15:49,620
to support the ecosystem of acceleration

00:15:47,089 --> 00:15:53,100
is what we call hyper

00:15:49,620 --> 00:15:56,850
and this is essentially a branded

00:15:53,100 --> 00:15:59,850
application marketplace that is open

00:15:56,850 --> 00:16:01,980
that we've been you know curating over

00:15:59,850 --> 00:16:04,759
many years but we're now actually going

00:16:01,980 --> 00:16:07,589
to be opening it up and offering it for

00:16:04,759 --> 00:16:09,629
developers is v's enterprises to be able

00:16:07,589 --> 00:16:12,170
to park their applications to be able to

00:16:09,629 --> 00:16:16,019
deploy them on any infrastructure and

00:16:12,170 --> 00:16:17,999
when you use you know this is for

00:16:16,019 --> 00:16:20,220
essentially the distribute distribution

00:16:17,999 --> 00:16:22,110
deployment and running of the workflows

00:16:20,220 --> 00:16:24,149
on any application so it's important

00:16:22,110 --> 00:16:25,649
it's not just a container registry right

00:16:24,149 --> 00:16:28,009
container registries will contain all

00:16:25,649 --> 00:16:31,439
the bits of the application but it also

00:16:28,009 --> 00:16:33,149
includes the elements that describe the

00:16:31,439 --> 00:16:35,009
runtime environment so you're actually

00:16:33,149 --> 00:16:36,809
executing the application when you

00:16:35,009 --> 00:16:38,699
launch it when you click on an app card

00:16:36,809 --> 00:16:40,139
you're not just pulling a container

00:16:38,699 --> 00:16:42,990
you're actually launching the work on

00:16:40,139 --> 00:16:45,209
the infrastructure this includes native

00:16:42,990 --> 00:16:48,209
accelerator support for both GPU and

00:16:45,209 --> 00:16:50,309
FPGA based infrastructure

00:16:48,209 --> 00:16:51,569
it's obviously purpose-built for more

00:16:50,309 --> 00:16:54,120
traditional high performance

00:16:51,569 --> 00:16:55,769
applications but obviously for

00:16:54,120 --> 00:16:57,569
accelerated infrastructure is one of the

00:16:55,769 --> 00:17:00,360
key attributes of it and then

00:16:57,569 --> 00:17:02,519
importantly it supports through Jarvis

00:17:00,360 --> 00:17:05,429
XE which is the software sort of

00:17:02,519 --> 00:17:07,350
operating system that powers our cloud

00:17:05,429 --> 00:17:10,199
but is now also something that we're we

00:17:07,350 --> 00:17:12,209
are selling to enterprises to run their

00:17:10,199 --> 00:17:14,130
on-prem infrastructures is the

00:17:12,209 --> 00:17:16,470
synchronization of this marketplace so

00:17:14,130 --> 00:17:19,319
when it comes to FPGA accelerated

00:17:16,470 --> 00:17:22,350
applications the ability to propagate

00:17:19,319 --> 00:17:24,089
those to more than one cloud - or to any

00:17:22,350 --> 00:17:29,610
infrastructure including your own data

00:17:24,089 --> 00:17:31,020
center is really important so - when you

00:17:29,610 --> 00:17:33,870
combine sort of the hyper hub with the

00:17:31,020 --> 00:17:36,390
Jarvis XE ecosystem you know which today

00:17:33,870 --> 00:17:40,309
is over a thousand applications and

00:17:36,390 --> 00:17:43,140
workflows across both the HPC and

00:17:40,309 --> 00:17:45,659
accelerated ecosystem it's a platform

00:17:43,140 --> 00:17:48,450
for containerized continuous integration

00:17:45,659 --> 00:17:51,809
and development so the idea for our capi

00:17:48,450 --> 00:17:54,690
snap work for example is that you know

00:17:51,809 --> 00:17:57,929
Alex and and in France can can develop

00:17:54,690 --> 00:17:59,940
his application and copy snap publish it

00:17:57,929 --> 00:18:01,409
and that application can can run on the

00:17:59,940 --> 00:18:03,000
Nimbus cloud but it can also then

00:18:01,409 --> 00:18:04,710
through hyper hub

00:18:03,000 --> 00:18:06,690
and Jarvis XE propagate to any other

00:18:04,710 --> 00:18:11,880
capi snap enabled or powered

00:18:06,690 --> 00:18:13,380
infrastructure so what our goal here

00:18:11,880 --> 00:18:15,960
going up the stack from a hardware

00:18:13,380 --> 00:18:18,870
standpoint is is to actually put work on

00:18:15,960 --> 00:18:22,620
the infrastructure so part of why we

00:18:18,870 --> 00:18:24,510
build you know incredible hardware is so

00:18:22,620 --> 00:18:27,060
that we can actually put it to work and

00:18:24,510 --> 00:18:30,690
we what we want to do is democratize

00:18:27,060 --> 00:18:33,060
access by reducing complexity so the

00:18:30,690 --> 00:18:35,130
idea for us is to create more software

00:18:33,060 --> 00:18:38,850
oriented software as a service oriented

00:18:35,130 --> 00:18:40,770
and platform level access for developers

00:18:38,850 --> 00:18:42,780
so we want to be able to onboard these

00:18:40,770 --> 00:18:45,990
new accelerated applications going back

00:18:42,780 --> 00:18:47,640
to for example the CUDA and GPU CUDA was

00:18:45,990 --> 00:18:49,650
different because most people had CUDA

00:18:47,640 --> 00:18:51,840
on their laptops because they had a GPU

00:18:49,650 --> 00:18:54,240
and they're in their graphics card and

00:18:51,840 --> 00:18:56,970
they're in their PC or their laptop in

00:18:54,240 --> 00:18:58,830
the case of FPGAs it's a little

00:18:56,970 --> 00:19:01,070
different and so while you may be able

00:18:58,830 --> 00:19:03,930
to do some some basic tool development

00:19:01,070 --> 00:19:07,460
in this environment you can actually go

00:19:03,930 --> 00:19:10,470
in to end all the way to infrastructure

00:19:07,460 --> 00:19:12,570
and in from an actual software

00:19:10,470 --> 00:19:14,430
application developer it provides a

00:19:12,570 --> 00:19:17,310
pathway to distributing their their

00:19:14,430 --> 00:19:20,610
applications and software globally and

00:19:17,310 --> 00:19:23,330
and also monetize that IP so if you are

00:19:20,610 --> 00:19:27,000
developing the you know a new

00:19:23,330 --> 00:19:30,330
acceleration open copy or capi snap

00:19:27,000 --> 00:19:33,200
enabled application you can actually

00:19:30,330 --> 00:19:37,110
propagate this throughout multiple

00:19:33,200 --> 00:19:38,730
infrastructures in a very easy way you

00:19:37,110 --> 00:19:40,620
can build once and adapt it to run on

00:19:38,730 --> 00:19:42,000
any cloud infrastructure that supports

00:19:40,620 --> 00:19:45,150
the actual hardware that your

00:19:42,000 --> 00:19:49,200
application targets and in finally

00:19:45,150 --> 00:19:51,180
importantly for FPGAs we have digital

00:19:49,200 --> 00:19:53,640
rights management technology built-in

00:19:51,180 --> 00:19:56,310
which supports bitstream protection

00:19:53,640 --> 00:19:58,440
which is important actual additional

00:19:56,310 --> 00:20:01,320
element in the case of fpga accelerated

00:19:58,440 --> 00:20:03,690
workloads and this works for will be

00:20:01,320 --> 00:20:06,150
supported both for kind of the

00:20:03,690 --> 00:20:08,730
traditional pcie-based you know

00:20:06,150 --> 00:20:13,860
acceleration as well as the capi snap

00:20:08,730 --> 00:20:15,300
and open copy support in onboarding

00:20:13,860 --> 00:20:16,470
applications we've tried to make very

00:20:15,300 --> 00:20:20,010
easy

00:20:16,470 --> 00:20:22,350
and whether you use containers are using

00:20:20,010 --> 00:20:24,780
containers or deployed that way now it

00:20:22,350 --> 00:20:27,330
can be done through compilation of get

00:20:24,780 --> 00:20:29,040
source and directly depositing that into

00:20:27,330 --> 00:20:30,090
a container or simply pulling in

00:20:29,040 --> 00:20:32,580
containers that you may have already

00:20:30,090 --> 00:20:34,560
created as well as some documentation

00:20:32,580 --> 00:20:36,390
around creating the metadata that you

00:20:34,560 --> 00:20:38,970
might use to describe the actual runtime

00:20:36,390 --> 00:20:40,590
environment for the end consumers of

00:20:38,970 --> 00:20:42,990
those applications and then I've

00:20:40,590 --> 00:20:44,940
included a couple of links for the work

00:20:42,990 --> 00:20:47,310
we're doing with xylene Salvio

00:20:44,940 --> 00:20:50,340
accelerators as well as with IBM on the

00:20:47,310 --> 00:20:52,530
Cappy snap so with that thank you very

00:20:50,340 --> 00:20:54,000
much for your time and I'll take happy

00:20:52,530 --> 00:21:01,079
to take any questions if you have any

00:20:54,000 --> 00:21:01,079
[Applause]

00:21:07,679 --> 00:21:44,799
you ready for cocktail yes yeah so the

00:21:42,010 --> 00:21:46,780
the we don't have a specific different

00:21:44,799 --> 00:21:48,309
licensing model of Jarvis XE for

00:21:46,780 --> 00:21:50,710
universities other than our traditional

00:21:48,309 --> 00:21:52,540
University discounts but I think it's

00:21:50,710 --> 00:21:56,559
you know an area where we are actively

00:21:52,540 --> 00:21:58,179
pursuing technology collaborations so

00:21:56,559 --> 00:22:00,549
where there's interesting ongoing work

00:21:58,179 --> 00:22:02,470
that's sort of you know pushing the you

00:22:00,549 --> 00:22:05,490
know pushing the envelope on new

00:22:02,470 --> 00:22:08,890
infrastructure technology we are

00:22:05,490 --> 00:22:11,950
motivated to invest to support that and

00:22:08,890 --> 00:22:15,160
can make that you know make that

00:22:11,950 --> 00:22:16,600
software available in those cases and we

00:22:15,160 --> 00:22:19,570
would just take that on a case-by-case

00:22:16,600 --> 00:22:22,900
basis and we do actually have a forum

00:22:19,570 --> 00:22:28,510
where we do allow researchers and

00:22:22,900 --> 00:22:31,720
academia to submit proposals and then we

00:22:28,510 --> 00:22:33,490
come back and and and you know do

00:22:31,720 --> 00:22:37,559
everything from discounted stuff to free

00:22:33,490 --> 00:22:37,559
and sponsored type work as well

00:22:40,260 --> 00:22:45,790
yes yes so we have the Nimbus cloud

00:22:43,330 --> 00:22:48,490
supports workloads globally out of data

00:22:45,790 --> 00:22:51,010
centers in North America hyper hub and

00:22:48,490 --> 00:22:54,220
Jarvis XE is available globally for

00:22:51,010 --> 00:22:56,910
deployment in any data center or any

00:22:54,220 --> 00:22:56,910
cloud provider

00:23:03,220 --> 00:23:17,180
mhmmm ya know we'd be happy to happy to

00:23:08,450 --> 00:23:18,410
chat yeah yeah and by the way that ya

00:23:17,180 --> 00:23:21,350
and that's an important thing that I

00:23:18,410 --> 00:23:23,930
didn't if you know I I guess I mentioned

00:23:21,350 --> 00:23:28,450
it a couple of times but the PARP our

00:23:23,930 --> 00:23:32,060
platform and part of what we're about is

00:23:28,450 --> 00:23:34,880
heterogeneity of you know that goes for

00:23:32,060 --> 00:23:38,090
CPU it goes for accelerator we're not

00:23:34,880 --> 00:23:41,030
biased towards you know x86 or GPU and

00:23:38,090 --> 00:23:42,830
what it's about is about targeting the

00:23:41,030 --> 00:23:46,490
workload to the right infrastructure and

00:23:42,830 --> 00:23:48,920
allowing the platform to place that work

00:23:46,490 --> 00:23:51,830
on the most well suited infrastructure

00:23:48,920 --> 00:23:55,160
so in power by the way the Jarvis axion

00:23:51,830 --> 00:23:56,810
hyper up supports power nine power you

00:23:55,160 --> 00:23:59,780
know power eight the prior generation

00:23:56,810 --> 00:24:01,790
you know as well and then you know we'll

00:23:59,780 --> 00:24:04,760
continue to be innovating with in

00:24:01,790 --> 00:24:13,540
partnership with IBM on all the sort of

00:24:04,760 --> 00:24:13,540
futures as well right thank you guys

00:24:14,430 --> 00:24:16,949

YouTube URL: https://www.youtube.com/watch?v=_7vq1sY_K_s


