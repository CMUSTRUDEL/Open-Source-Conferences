Title: OpenPOWER Summit NA 2019: Enabling SQL to FPGA Using HLS for Filtering Stream Data Transformations
Publication date: 2019-08-20
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Erwin de Haan, Delft University of Technology

This talk discusses automating the transpiling of SQL to High-Level Synthesis C++ to generate hardware for filtering and data stream transformations using CAPI on POWER systems. This work uses the Fletcher framework to automate the handling of data movement between memory and the FPGA. The use of HLS technologies can greatly reduce the development time of FPGAs compared to manual FPGA development workflows. 

Deploying FPGAs in fast changing data processing pipelines, can be very complicated or limit the use of the FPGA hardware. This work investigates if HLS is good enough for these kinds of applications to meaningfully reduce total development time while still maintaining performance. Additionally, the use of the Fletcher framework further reduces required developer time.
Captions: 
	00:00:00,410 --> 00:00:05,520
this good afternoon so I'm Aaron and I'm

00:00:03,570 --> 00:00:08,690
from the accelerated Big Data Systems

00:00:05,520 --> 00:00:10,860
Group at tu Delft in Netherlands and

00:00:08,690 --> 00:00:15,210
today I want to talk to you about

00:00:10,860 --> 00:00:18,439
enabling SQL to fpga using HLS for

00:00:15,210 --> 00:00:22,170
filtering and stream transformations and

00:00:18,439 --> 00:00:25,350
so FPGA is a free to be on the rise in

00:00:22,170 --> 00:00:27,570
HPC and big data lately in there they're

00:00:25,350 --> 00:00:30,179
very good at doing complex parallel

00:00:27,570 --> 00:00:34,200
problems due to their nature there they

00:00:30,179 --> 00:00:36,870
can have very deep pipelines for data

00:00:34,200 --> 00:00:39,379
flows and processing I'm a most of the

00:00:36,870 --> 00:00:42,629
issues stem from from data movement and

00:00:39,379 --> 00:00:45,180
so the goal of the group is is to

00:00:42,629 --> 00:00:48,660
provide high throughput low cost Big

00:00:45,180 --> 00:00:50,789
Data solutions and so a little bit of an

00:00:48,660 --> 00:00:52,559
overview of what I want to talk to you

00:00:50,789 --> 00:00:54,690
about today so I want to give a little

00:00:52,559 --> 00:00:59,219
bit of context on why I did what I did

00:00:54,690 --> 00:01:02,969
and then I wanna give a very brief sort

00:00:59,219 --> 00:01:05,610
of point to what Fletcher and Aero are

00:01:02,969 --> 00:01:07,350
and what they do and a couple of usage

00:01:05,610 --> 00:01:09,510
scenarios and after that I want to talk

00:01:07,350 --> 00:01:11,720
more about sort of the architecture

00:01:09,510 --> 00:01:14,520
implementation and how we tested these

00:01:11,720 --> 00:01:19,310
and we'll end with a little bit of an

00:01:14,520 --> 00:01:21,830
outlook so for the context so the main

00:01:19,310 --> 00:01:25,170
thing here is that I want to generate

00:01:21,830 --> 00:01:30,030
essentially a filter so in the group we

00:01:25,170 --> 00:01:33,180
have someone logically oh he worked on a

00:01:30,030 --> 00:01:37,560
parquet file reader for FPGA and then a

00:01:33,180 --> 00:01:39,900
decompressor to decompress the data from

00:01:37,560 --> 00:01:42,750
that park a file and so the things

00:01:39,900 --> 00:01:44,729
before it touches memory or even the CPU

00:01:42,750 --> 00:01:48,060
it would be great to be able to apply

00:01:44,729 --> 00:01:51,420
some some very small transformations and

00:01:48,060 --> 00:01:54,450
filters and so the idea of this project

00:01:51,420 --> 00:01:58,969
is to automate as much as possible of

00:01:54,450 --> 00:02:02,430
that filter generation so traditional

00:01:58,969 --> 00:02:03,930
FPGA development or closed or they're

00:02:02,430 --> 00:02:06,509
they're complicated

00:02:03,930 --> 00:02:08,940
hardware designs you need to write you

00:02:06,509 --> 00:02:10,560
know HDL obviously this gives you high

00:02:08,940 --> 00:02:12,730
performance and complete control over

00:02:10,560 --> 00:02:14,890
whatever your filter or kernel

00:02:12,730 --> 00:02:17,739
going to do but the fact that it's

00:02:14,890 --> 00:02:19,120
complicated means it's expensive and so

00:02:17,739 --> 00:02:22,450
on the other side you have the high

00:02:19,120 --> 00:02:23,650
level synthesis which you've moderate

00:02:22,450 --> 00:02:26,830
performance and depending on what you

00:02:23,650 --> 00:02:28,780
can do you can absolutely reach the same

00:02:26,830 --> 00:02:32,230
speeds as some of the hto

00:02:28,780 --> 00:02:34,390
implementations yes so that it's easier

00:02:32,230 --> 00:02:36,250
to do so it might actually save you time

00:02:34,390 --> 00:02:41,440
and money if you know if it can reach

00:02:36,250 --> 00:02:44,620
sufficient throughput and so earlier

00:02:41,440 --> 00:02:49,000
today yon who's over there gave a talk

00:02:44,620 --> 00:02:52,720
on on the flexure framework which one of

00:02:49,000 --> 00:02:55,450
its aims is to to always saturate system

00:02:52,720 --> 00:02:57,870
bandwidth while reading and writing to

00:02:55,450 --> 00:03:01,780
arrow buffers so that's the standardized

00:02:57,870 --> 00:03:03,940
sunrise memory layout and it's obviously

00:03:01,780 --> 00:03:07,959
great for interoperability and data

00:03:03,940 --> 00:03:10,859
sharing so a really quick overview of

00:03:07,959 --> 00:03:13,750
what what the arrow in memory format is

00:03:10,859 --> 00:03:15,910
so a traditional memory buffer will have

00:03:13,750 --> 00:03:20,079
for example in in C they will just

00:03:15,910 --> 00:03:22,180
structs will be you know together all of

00:03:20,079 --> 00:03:24,190
them and then for arrow what it does is

00:03:22,180 --> 00:03:27,400
it will split them up into separate

00:03:24,190 --> 00:03:29,889
buffers for each and every column

00:03:27,400 --> 00:03:33,549
essentially in in the record batch which

00:03:29,889 --> 00:03:36,459
is like a table essentially for arrow

00:03:33,549 --> 00:03:38,620
which has a certain specification which

00:03:36,459 --> 00:03:41,440
is a schema and it says okay this field

00:03:38,620 --> 00:03:46,150
is an integer it's this large and so on

00:03:41,440 --> 00:03:49,269
and so the idea was to make a compiler

00:03:46,150 --> 00:03:51,549
that takes an SQL query and a schema and

00:03:49,269 --> 00:03:54,359
the schema is essentially like the SQL

00:03:51,549 --> 00:03:57,819
table definition in this case and

00:03:54,359 --> 00:04:03,450
generate hardware that will execute that

00:03:57,819 --> 00:04:06,510
query in in a streaming fashion from

00:04:03,450 --> 00:04:10,150
from the the fletcher streams that are

00:04:06,510 --> 00:04:13,269
specified by the schema so it's written

00:04:10,150 --> 00:04:15,930
in Python and so it builds on top of

00:04:13,269 --> 00:04:20,590
Fletcher it builds on top of HLS tools

00:04:15,930 --> 00:04:24,340
and and what it tries to solve is sort

00:04:20,590 --> 00:04:25,639
of you have on the left here you there's

00:04:24,340 --> 00:04:28,039
a couple of kernel

00:04:25,639 --> 00:04:30,229
or other sources that generate streams

00:04:28,039 --> 00:04:32,569
of Fletcher combatable

00:04:30,229 --> 00:04:35,870
later Fletcher compatible streams with a

00:04:32,569 --> 00:04:37,870
lot of data and if you have a small

00:04:35,870 --> 00:04:40,780
filter action you might want to do

00:04:37,870 --> 00:04:43,639
before you pass it on to the next

00:04:40,780 --> 00:04:46,939
fletcher compatible colonel and you want

00:04:43,639 --> 00:04:48,919
to do this automatically so if you want

00:04:46,939 --> 00:04:50,509
to generate dynamic filters right now

00:04:48,919 --> 00:04:54,110
the easiest way to do it is to just have

00:04:50,509 --> 00:04:56,330
the CPU do the actual filtering and so

00:04:54,110 --> 00:05:00,710
you get a full round-trip essentially to

00:04:56,330 --> 00:05:03,199
the cpu for the data and more ideal is

00:05:00,710 --> 00:05:05,810
to automatically generate that middle

00:05:03,199 --> 00:05:09,740
core right now you can obviously do this

00:05:05,810 --> 00:05:12,979
you can just write the HDL yourself you

00:05:09,740 --> 00:05:15,529
can write this hls yourself and then you

00:05:12,979 --> 00:05:17,560
have your fixed filter but if your

00:05:15,529 --> 00:05:21,020
filter changes this means you need to

00:05:17,560 --> 00:05:23,150
redo your design essentially and so the

00:05:21,020 --> 00:05:27,199
goal of this project was to fully

00:05:23,150 --> 00:05:28,849
automate that whole internal filter so

00:05:27,199 --> 00:05:30,860
if you have two kernels one on the left

00:05:28,849 --> 00:05:33,440
one on the right that are larger

00:05:30,860 --> 00:05:35,659
fixed-function kernels but in between

00:05:33,440 --> 00:05:37,159
there's a little transformation that you

00:05:35,659 --> 00:05:39,949
might need to do and that might change

00:05:37,159 --> 00:05:42,169
for example there's a date filter or

00:05:39,949 --> 00:05:46,039
some other thing that might change

00:05:42,169 --> 00:05:48,699
through time then it would be very nice

00:05:46,039 --> 00:05:51,229
if we could automatically generate and

00:05:48,699 --> 00:05:54,199
this obviously means that the bulk of

00:05:51,229 --> 00:05:57,289
the data now bypasses memory and so you

00:05:54,199 --> 00:05:58,909
don't have any round-trip time you don't

00:05:57,289 --> 00:06:02,659
need to push it over the host interface

00:05:58,909 --> 00:06:05,810
towards the the CPU for example for

00:06:02,659 --> 00:06:08,930
processing and then here's a little bit

00:06:05,810 --> 00:06:11,120
of a detail so the for this core what

00:06:08,930 --> 00:06:13,849
will happen is that the input and the

00:06:11,120 --> 00:06:15,620
output streams left and right they're

00:06:13,849 --> 00:06:18,199
essentially it's only dependent on the

00:06:15,620 --> 00:06:23,839
schemas you deliver so they can be 1

00:06:18,199 --> 00:06:26,060
they can be 5 10 and so on so that's you

00:06:23,839 --> 00:06:29,719
can do essentially as many as you like

00:06:26,060 --> 00:06:32,810
and your hardware allows so for the

00:06:29,719 --> 00:06:35,209
implementation part here is Fletcher

00:06:32,810 --> 00:06:38,990
firfer data movement this is obviously

00:06:35,209 --> 00:06:41,990
it means especially when using capi

00:06:38,990 --> 00:06:43,759
and and and for example the snap

00:06:41,990 --> 00:06:47,780
framework you don't actually have to

00:06:43,759 --> 00:06:50,030
copy the the data over to the FPGA or

00:06:47,780 --> 00:06:52,520
vice versa because fpj can directly

00:06:50,030 --> 00:06:54,620
access your hosts memory over the copy

00:06:52,520 --> 00:06:56,300
interface and Fletcher makes it even

00:06:54,620 --> 00:06:58,699
easier because this means that anything

00:06:56,300 --> 00:07:01,009
on the host or other accelerators can

00:06:58,699 --> 00:07:04,520
also write to that same buffer if you

00:07:01,009 --> 00:07:07,460
want so this this greatly simplifies the

00:07:04,520 --> 00:07:10,970
design of this sort of automated system

00:07:07,460 --> 00:07:13,580
then for the parsing from tenth of this

00:07:10,970 --> 00:07:16,550
compiler so didn't make much sense to

00:07:13,580 --> 00:07:18,740
write our own so we use the Mozilla SQL

00:07:16,550 --> 00:07:22,370
parser and then for the final code

00:07:18,740 --> 00:07:26,449
generation so there's a project and what

00:07:22,370 --> 00:07:28,220
it does it takes any input and it can

00:07:26,449 --> 00:07:30,919
transpile it to any open this works for

00:07:28,220 --> 00:07:34,400
Fortran and C++ and Python and it uses

00:07:30,919 --> 00:07:35,830
Python is teased internally so we use

00:07:34,400 --> 00:07:39,830
the unpassed

00:07:35,830 --> 00:07:42,979
a Python is tea that you can generate

00:07:39,830 --> 00:07:46,639
and it makes c++ and then you can feed

00:07:42,979 --> 00:07:48,710
that c++ into a tool like v Auto HLS and

00:07:46,639 --> 00:07:50,870
this can create your kernel and you can

00:07:48,710 --> 00:07:55,219
run your normal FPGA tools to get it

00:07:50,870 --> 00:07:58,759
where it needs to go on an FPGA and so

00:07:55,219 --> 00:08:04,070
internally the tool also produces a

00:07:58,759 --> 00:08:07,729
Python 3 ast and so this is an

00:08:04,070 --> 00:08:11,840
architecture overview of of the compiler

00:08:07,729 --> 00:08:14,810
so it has a front-end which generates a

00:08:11,840 --> 00:08:16,400
customized T it passes it off to the

00:08:14,810 --> 00:08:19,159
middleware where it goes through a

00:08:16,400 --> 00:08:22,159
couple of very standard compiler

00:08:19,159 --> 00:08:25,009
transforms it does some simple constant

00:08:22,159 --> 00:08:28,219
propagation it does some de sugaring and

00:08:25,009 --> 00:08:32,510
some normalizing of of the parse ast and

00:08:28,219 --> 00:08:35,089
then finally there's some more Fletcher

00:08:32,510 --> 00:08:38,690
and output specific transformations this

00:08:35,089 --> 00:08:40,339
generates the final Python HT pass it to

00:08:38,690 --> 00:08:44,060
the back end and then the back end

00:08:40,339 --> 00:08:46,480
generates the the readable HLS C++ code

00:08:44,060 --> 00:08:49,269
essentially which can then

00:08:46,480 --> 00:08:53,130
go on and you can compile it into HDL

00:08:49,269 --> 00:08:55,660
and this is build on top of several

00:08:53,130 --> 00:08:57,760
little little things here at the bottom

00:08:55,660 --> 00:08:59,740
that the dependencies and such and I

00:08:57,760 --> 00:09:02,589
want to just go through a couple of

00:08:59,740 --> 00:09:05,639
these just to highlight certain parts so

00:09:02,589 --> 00:09:08,589
I want to start with with the front end

00:09:05,639 --> 00:09:10,779
so originally the front end the output

00:09:08,589 --> 00:09:15,100
essentially what you see here on the

00:09:10,779 --> 00:09:18,010
right it's essentially a JSON type

00:09:15,100 --> 00:09:19,930
format now for doing transformations on

00:09:18,010 --> 00:09:22,600
this and for writing a compiler based on

00:09:19,930 --> 00:09:24,820
this it's not very useful

00:09:22,600 --> 00:09:27,160
it makes transformations much harder

00:09:24,820 --> 00:09:29,320
than there needed to be a thankfully

00:09:27,160 --> 00:09:31,360
it's fully open source parser and it's

00:09:29,320 --> 00:09:34,449
based on PI parsing which makes it

00:09:31,360 --> 00:09:36,730
relatively easy to extend so after a bit

00:09:34,449 --> 00:09:39,610
of work it can actually output full

00:09:36,730 --> 00:09:41,410
abstract syntax trees so all the little

00:09:39,610 --> 00:09:43,690
parts near the top for the query they

00:09:41,410 --> 00:09:48,850
map to the different parts as colored on

00:09:43,690 --> 00:09:52,000
the right here and these are classes

00:09:48,850 --> 00:09:54,220
that are based on the Python ast class

00:09:52,000 --> 00:09:57,279
this means all the tools that work on

00:09:54,220 --> 00:09:59,320
Python is teased for walking the ast and

00:09:57,279 --> 00:10:02,620
transforming it and replacing different

00:09:59,320 --> 00:10:07,540
parts work on this as well so this makes

00:10:02,620 --> 00:10:11,230
it very easy to extend it's very it's

00:10:07,540 --> 00:10:13,029
very accessible for any other person to

00:10:11,230 --> 00:10:15,940
add their own transformations and to

00:10:13,029 --> 00:10:19,089
make bigger and better kernels

00:10:15,940 --> 00:10:21,130
automatically generated so then there's

00:10:19,089 --> 00:10:23,920
the transformations in the middle and as

00:10:21,130 --> 00:10:26,050
I said these are very much a very

00:10:23,920 --> 00:10:27,699
standard so for example some of the

00:10:26,050 --> 00:10:30,130
easier ones if there's not a where

00:10:27,699 --> 00:10:32,079
clause we do sugar that to a where

00:10:30,130 --> 00:10:34,390
Clause is always true because in

00:10:32,079 --> 00:10:36,730
hardware you will always need some value

00:10:34,390 --> 00:10:39,209
right and same thing with some of the

00:10:36,730 --> 00:10:42,699
constant propagation on the bottom ones

00:10:39,209 --> 00:10:44,920
certain ones you can just remove and I

00:10:42,699 --> 00:10:48,209
just makes your final code that you

00:10:44,920 --> 00:10:48,209
generate much easier to read

00:10:48,350 --> 00:10:53,450
and then a look at the back end which is

00:10:51,590 --> 00:10:58,730
what takes that Python ast and it

00:10:53,450 --> 00:11:00,620
generates your actual HLS C++ so it's

00:10:58,730 --> 00:11:02,980
Nate we see or intend to transpire and

00:11:00,620 --> 00:11:06,710
it does all these languages sort of

00:11:02,980 --> 00:11:10,220
mostly any-to-any although there's

00:11:06,710 --> 00:11:12,800
obviously some caveats with that but so

00:11:10,220 --> 00:11:15,680
it uses byte intensities to do basically

00:11:12,800 --> 00:11:19,660
cross compiling from one to the other

00:11:15,680 --> 00:11:22,370
and this project only really uses the

00:11:19,660 --> 00:11:25,160
c++ unbar so from this project because

00:11:22,370 --> 00:11:28,820
obviously the source of this compiler is

00:11:25,160 --> 00:11:31,340
SQL and it was not supported so we just

00:11:28,820 --> 00:11:35,590
we hook in halfway through this and then

00:11:31,340 --> 00:11:38,360
just let it generate the actual c++ and

00:11:35,590 --> 00:11:40,700
so the integration with Fletcher this is

00:11:38,360 --> 00:11:43,490
essentially is a part of the Fletcher

00:11:40,700 --> 00:11:46,940
project for free Vado hls integration in

00:11:43,490 --> 00:11:49,600
this case and so what it does it

00:11:46,940 --> 00:11:53,860
represents most of the arrow types as

00:11:49,600 --> 00:11:56,690
normal sea types so these are just

00:11:53,860 --> 00:11:58,070
structures and you can use these in C

00:11:56,690 --> 00:12:00,620
like you would use most of your

00:11:58,070 --> 00:12:02,420
primitives and C because most of the

00:12:00,620 --> 00:12:04,340
operators are fully overloaded so it

00:12:02,420 --> 00:12:06,470
will handle all the auxiliary signals

00:12:04,340 --> 00:12:09,920
that Fletch your needs for their support

00:12:06,470 --> 00:12:13,550
streams you can just do a plus B and it

00:12:09,920 --> 00:12:15,440
will handle all the extra flags that

00:12:13,550 --> 00:12:17,360
need to be passed along to your results

00:12:15,440 --> 00:12:20,570
so you don't have to manually you know

00:12:17,360 --> 00:12:23,960
handle the data handle this signal

00:12:20,570 --> 00:12:26,270
handle that signal and so on so then

00:12:23,960 --> 00:12:29,720
obviously we need to test this needs to

00:12:26,270 --> 00:12:32,330
have some target to verify against so I

00:12:29,720 --> 00:12:34,160
used my sequel or but I could have

00:12:32,330 --> 00:12:38,060
picked any other SQL implementations

00:12:34,160 --> 00:12:40,670
just for logical correctness checking so

00:12:38,060 --> 00:12:42,350
first test it all in software and then

00:12:40,670 --> 00:12:47,600
we moved on to hardware and we've

00:12:42,350 --> 00:12:51,800
finished with actual in cloud hardware

00:12:47,600 --> 00:12:54,080
testing and so there's different stages

00:12:51,800 --> 00:12:57,620
to testing and they all need to output

00:12:54,080 --> 00:13:00,020
the exact same so it's obviously the

00:12:57,620 --> 00:13:05,290
easiest one is to just run

00:13:00,020 --> 00:13:07,459
the SQL query on a known SQL server and

00:13:05,290 --> 00:13:10,190
then just store the output so you

00:13:07,459 --> 00:13:12,560
compare it to your other things then for

00:13:10,190 --> 00:13:16,580
ease of development just run the actual

00:13:12,560 --> 00:13:19,010
HLS code like it's normal C so run it

00:13:16,580 --> 00:13:22,190
through GCC and run the code this

00:13:19,010 --> 00:13:25,190
obviously is it's very easy to check if

00:13:22,190 --> 00:13:27,440
this is correct and this is also one of

00:13:25,190 --> 00:13:29,779
the advantages of using H less is that

00:13:27,440 --> 00:13:31,630
you're testing your first functional

00:13:29,779 --> 00:13:34,790
testing is actually very straightforward

00:13:31,630 --> 00:13:39,410
because it's just you know a bunch of

00:13:34,790 --> 00:13:41,899
C++ code then you can actually run it to

00:13:39,410 --> 00:13:44,510
evaluate LS or your other hls tool of

00:13:41,899 --> 00:13:46,399
choice and it has very nice go

00:13:44,510 --> 00:13:48,950
simulation features so it runs the

00:13:46,399 --> 00:13:51,620
actual kernel and hardware and your test

00:13:48,950 --> 00:13:55,010
bench can still be the same as

00:13:51,620 --> 00:13:57,380
essentially your your code for your C++

00:13:55,010 --> 00:14:00,320
testing because it can still be in in

00:13:57,380 --> 00:14:02,540
C++ so this is just a software and

00:14:00,320 --> 00:14:04,600
hardware code simulation and then when

00:14:02,540 --> 00:14:08,290
all that works you can use the snap

00:14:04,600 --> 00:14:15,829
framework from open power to actually

00:14:08,290 --> 00:14:17,870
run it on FPGAs and the compiler

00:14:15,829 --> 00:14:20,180
generates the projects for you it

00:14:17,870 --> 00:14:23,980
generates most of the other helper files

00:14:20,180 --> 00:14:26,720
so when you run the command it outputs

00:14:23,980 --> 00:14:30,380
your project for you and you just hit

00:14:26,720 --> 00:14:32,329
you know make image and it will create

00:14:30,380 --> 00:14:35,360
the image for you and you can just run

00:14:32,329 --> 00:14:38,390
it on the FPGA and so we see one of the

00:14:35,360 --> 00:14:42,079
use cases could be to run this in a

00:14:38,390 --> 00:14:46,730
just-in-time fashion in certain but big

00:14:42,079 --> 00:14:50,089
data frameworks for example and so the

00:14:46,730 --> 00:14:54,800
hardware tests were run on Linux on one

00:14:50,089 --> 00:15:00,170
of their power nodes with the 250 SF BJ

00:14:54,800 --> 00:15:03,860
cards this is a context part and so I

00:15:00,170 --> 00:15:05,750
have some actual throughput numbers so

00:15:03,860 --> 00:15:10,800
these are potential throughput numbers

00:15:05,750 --> 00:15:14,190
running on the highest F max that

00:15:10,800 --> 00:15:17,340
in this case Avada would let the part

00:15:14,190 --> 00:15:20,120
front so this is per instance and these

00:15:17,340 --> 00:15:22,500
instances are fairly small and this is

00:15:20,120 --> 00:15:25,140
so you can have multiple so you could

00:15:22,500 --> 00:15:28,380
easily saturate your system bandwidth

00:15:25,140 --> 00:15:32,070
and these are all using only primitives

00:15:28,380 --> 00:15:34,650
so the problem gets becomes when you

00:15:32,070 --> 00:15:36,570
read in strings right now the

00:15:34,650 --> 00:15:38,670
implementation is a little bit naive so

00:15:36,570 --> 00:15:41,100
it reads in strings one byte at a time

00:15:38,670 --> 00:15:43,710
as you can see obviously the bandwidth

00:15:41,100 --> 00:15:45,930
is not that staggering still these are

00:15:43,710 --> 00:15:48,300
very small so you can probably put

00:15:45,930 --> 00:15:53,100
hundreds of these on an FPGA or more

00:15:48,300 --> 00:15:55,260
with room to spare so these are the ones

00:15:53,100 --> 00:15:57,870
from simulation the numbers and then the

00:15:55,260 --> 00:15:59,300
actual hardware runs it's supposed to be

00:15:57,870 --> 00:16:02,610
a thousand in the hardware room was

00:15:59,300 --> 00:16:05,400
about 950 so these numbers they they

00:16:02,610 --> 00:16:10,230
match reality and this is over just one

00:16:05,400 --> 00:16:11,910
simple 32-bit integer loading so that's

00:16:10,230 --> 00:16:13,920
about 30 megabytes per second per bus

00:16:11,910 --> 00:16:16,680
bit and because it's an FPGA this scales

00:16:13,920 --> 00:16:18,510
very well by you know just making your

00:16:16,680 --> 00:16:20,400
bus wide are having more columns the

00:16:18,510 --> 00:16:23,670
more columns you have the higher your

00:16:20,400 --> 00:16:27,810
throughput gets and otherwise you'll

00:16:23,670 --> 00:16:30,030
have to paralyze them per record batch

00:16:27,810 --> 00:16:32,430
so you can obviously just run multiple

00:16:30,030 --> 00:16:33,990
instances and each give them a little

00:16:32,430 --> 00:16:36,150
bit of data to filter and they will just

00:16:33,990 --> 00:16:40,140
filter push it out to whatever is

00:16:36,150 --> 00:16:43,440
afterwards and so on and so here's some

00:16:40,140 --> 00:16:47,040
of the the post implementation results

00:16:43,440 --> 00:16:51,510
of if you would run them on limbic

00:16:47,040 --> 00:16:55,110
system right column right now those FPGA

00:16:51,510 --> 00:16:57,090
is run at 250 megahertz and so this is

00:16:55,110 --> 00:17:00,420
per instance what you would get out of

00:16:57,090 --> 00:17:03,300
most of these and then here's the

00:17:00,420 --> 00:17:07,050
resource usage so as you can see all of

00:17:03,300 --> 00:17:09,510
these are very very small all of these

00:17:07,050 --> 00:17:12,510
numbers on this target part are less

00:17:09,510 --> 00:17:14,100
than half a percent of the FPGA this is

00:17:12,510 --> 00:17:16,410
without the actual interconnect this is

00:17:14,100 --> 00:17:19,440
just just to filter core this just to

00:17:16,410 --> 00:17:23,439
give you an idea of how small these

00:17:19,440 --> 00:17:25,539
kernels are especially the bee RAM usage

00:17:23,439 --> 00:17:29,710
affected by how large you can have your

00:17:25,539 --> 00:17:31,210
strings because it can do some some for

00:17:29,710 --> 00:17:33,549
example string concatenation it will

00:17:31,210 --> 00:17:36,129
need a little bit of B Rams obviously if

00:17:33,549 --> 00:17:39,639
you scale up your string size these go

00:17:36,129 --> 00:17:41,940
up but this is for about 255 character

00:17:39,639 --> 00:17:45,159
strings just fairly usable in a lot of

00:17:41,940 --> 00:17:48,519
applications that have smaller strings

00:17:45,159 --> 00:17:51,309
for example and then as I said before on

00:17:48,519 --> 00:17:54,850
the target part for this if you ignore

00:17:51,309 --> 00:17:57,879
your interconnect costs hundreds of

00:17:54,850 --> 00:18:00,070
these fit on a single FPGA so your total

00:17:57,879 --> 00:18:02,379
bandwidth can be more than enough to

00:18:00,070 --> 00:18:10,059
saturate your your capi one or two

00:18:02,379 --> 00:18:11,799
interface for some of these and so so

00:18:10,059 --> 00:18:14,080
there is definitely a lot of potential

00:18:11,799 --> 00:18:16,539
still here to make these faster

00:18:14,080 --> 00:18:19,179
especially the ones that use strings is

00:18:16,539 --> 00:18:20,769
very naive right now so if one would

00:18:19,179 --> 00:18:23,200
spend a little bit of time there's

00:18:20,769 --> 00:18:26,529
there's a ton of potential to get maybe

00:18:23,200 --> 00:18:28,419
a 10x or a hundred X depending on how

00:18:26,529 --> 00:18:31,149
much effort you want to spend there's

00:18:28,419 --> 00:18:33,850
some multiple elements per cycle

00:18:31,149 --> 00:18:37,809
functionality in Fletcher the framework

00:18:33,850 --> 00:18:40,090
itself and there's already some some

00:18:37,809 --> 00:18:41,799
work done to get HLS to integrate

00:18:40,090 --> 00:18:43,240
properly with using multiple elements

00:18:41,799 --> 00:18:46,059
per cycle and presenting these to the

00:18:43,240 --> 00:18:48,220
user as essentially just little fixed

00:18:46,059 --> 00:18:50,289
size arrays and obviously the code

00:18:48,220 --> 00:18:52,840
generation for this could take make use

00:18:50,289 --> 00:18:54,460
of those same types and if you go to two

00:18:52,840 --> 00:18:56,860
elements per cycle because of the

00:18:54,460 --> 00:19:00,009
linearity of sort of how that load in

00:18:56,860 --> 00:19:01,870
and write out works you know you get a

00:19:00,009 --> 00:19:04,870
latency that's half and then you go to

00:19:01,870 --> 00:19:08,649
four and it's a fourth and so on and so

00:19:04,870 --> 00:19:13,149
if you go to a very wide data bus you

00:19:08,649 --> 00:19:16,000
can easily gain 10 X or even more on

00:19:13,149 --> 00:19:21,009
just simple stringing reading and read

00:19:16,000 --> 00:19:24,820
out and then every advance in HLS so if

00:19:21,009 --> 00:19:26,200
if a full data flow gets enabled and for

00:19:24,820 --> 00:19:28,179
example if you evaluate Celeste's

00:19:26,200 --> 00:19:31,869
obviously it gets you nicer pipelining

00:19:28,179 --> 00:19:34,389
because right now the kernels due to how

00:19:31,869 --> 00:19:35,640
far HLS generates them they can't really

00:19:34,389 --> 00:19:39,360
be pipelined

00:19:35,640 --> 00:19:41,010
so they have to wait essentially until

00:19:39,360 --> 00:19:43,200
they're whole all the matching is done

00:19:41,010 --> 00:19:45,929
before they know if they can pass it to

00:19:43,200 --> 00:19:47,730
the output so they do their matching on

00:19:45,929 --> 00:19:50,040
our input variables and then they know

00:19:47,730 --> 00:19:52,740
like okay this record matches the where

00:19:50,040 --> 00:19:56,130
clause right at the output but if you

00:19:52,740 --> 00:19:58,410
can have more of a data flow sort of

00:19:56,130 --> 00:20:00,750
approach to haulage it's less Tool Works

00:19:58,410 --> 00:20:04,170
it can already start matching next one

00:20:00,750 --> 00:20:05,760
while it's riding out sort of the

00:20:04,170 --> 00:20:10,559
previous one this obviously gets you

00:20:05,760 --> 00:20:13,799
free performance by just having your HL

00:20:10,559 --> 00:20:15,870
s to become better over time and because

00:20:13,799 --> 00:20:18,840
it is written sort of that intermediate

00:20:15,870 --> 00:20:22,169
is just C++ that just means it's very

00:20:18,840 --> 00:20:24,900
portable as well and so then the end

00:20:22,169 --> 00:20:27,210
goal I think for me personally is what I

00:20:24,900 --> 00:20:29,610
would like to see from a chalasis to

00:20:27,210 --> 00:20:32,280
start using H lesson as an Orchestrator

00:20:29,610 --> 00:20:36,000
more so now it's you put it's less

00:20:32,280 --> 00:20:39,410
kernels into HDL but obviously it will

00:20:36,000 --> 00:20:42,059
very nice if you could use HLS to even

00:20:39,410 --> 00:20:44,940
easier essentially to instantiate maybe

00:20:42,059 --> 00:20:48,600
hundreds of these sort of semi

00:20:44,940 --> 00:20:52,169
automatically from HLS this would lower

00:20:48,600 --> 00:20:55,380
that bar to use FPGA accelerators in in

00:20:52,169 --> 00:20:59,520
big data for example even more which I

00:20:55,380 --> 00:21:05,040
think is is important just for to get

00:20:59,520 --> 00:21:08,010
sort of FPGA is used more and then in

00:21:05,040 --> 00:21:11,340
the far future hopefully HDL gets

00:21:08,010 --> 00:21:15,000
relegated to what assembly today is for

00:21:11,340 --> 00:21:16,620
software so you'll end up writing most

00:21:15,000 --> 00:21:19,140
of your stuff in some higher level and

00:21:16,620 --> 00:21:22,520
then you write your performance critical

00:21:19,140 --> 00:21:22,520
code in a shell

00:21:22,730 --> 00:21:26,499
and thank you very much for your time

00:21:35,740 --> 00:21:38,829
[Music]

00:21:38,860 --> 00:21:45,330
to translate - yes

00:21:46,700 --> 00:21:56,660
[Music]

00:21:53,640 --> 00:21:56,660
yes correct

00:21:58,240 --> 00:22:01,680
and is it down there any

00:22:04,010 --> 00:22:07,760
the whole

00:22:07,890 --> 00:22:18,050
yes correct so it's what they want

00:22:14,960 --> 00:22:21,240
[Music]

00:22:18,050 --> 00:22:25,050
No so it's not necessarily like a

00:22:21,240 --> 00:22:27,420
databases where sequel was just chosen

00:22:25,050 --> 00:22:30,929
as sort of the representation of the

00:22:27,420 --> 00:22:33,360
filters because most people are familiar

00:22:30,929 --> 00:22:37,500
with it so it's very easy and accessible

00:22:33,360 --> 00:22:40,679
sort of way to just write a filter as a

00:22:37,500 --> 00:22:42,840
sequel query that's sort of intuitive it

00:22:40,679 --> 00:22:46,410
could be you could Emma Kenny front end

00:22:42,840 --> 00:22:53,940
for this any filter the specification

00:22:46,410 --> 00:22:58,830
could work yes it is the the bottom link

00:22:53,940 --> 00:23:02,510
is it's Apache 2.0 so the code is fully

00:22:58,830 --> 00:23:02,510
open it's the the bottom one here

00:23:02,670 --> 00:23:05,809

YouTube URL: https://www.youtube.com/watch?v=X0Q8cnqr_V8


