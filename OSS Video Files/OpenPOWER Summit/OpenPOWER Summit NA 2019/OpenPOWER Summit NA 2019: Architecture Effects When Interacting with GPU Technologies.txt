Title: OpenPOWER Summit NA 2019: Architecture Effects When Interacting with GPU Technologies
Publication date: 2019-08-28
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Christopher M. Sullivan, Oregon State University 

Oregon State Universityâ€™s Center for Genome Research and Biocomputing (CGRB) works closely with its users to determine the best computing platform for computational research. In the past several years we have seen many differences associated with architecture and GPU interactions. As we continued our testing we found tremendous benefits from using the OpenPOWER platform with Power9 processors and NVIDIA GPU. In an effort to truly determine the best platform for different types of GPU processing we created a set of test. We will be showing all the current data comparing some of the most bleeding-edge platforms and a demo of the machines racing each other. Our goal is to provide users with the ability to bring online the best platform for the work they are planning with GPU technology.
Captions: 
	00:00:00,030 --> 00:00:05,490
all right thank you thank you for coming

00:00:04,020 --> 00:00:07,830
I appreciate it today we're going to

00:00:05,490 --> 00:00:11,309
talk about some of the architecture

00:00:07,830 --> 00:00:13,710
effects that we see when utilizing GPUs

00:00:11,309 --> 00:00:16,379
and different architectures I think this

00:00:13,710 --> 00:00:18,930
is super important because people buy

00:00:16,379 --> 00:00:23,609
GPUs and have no idea what the impact

00:00:18,930 --> 00:00:25,260
will be when they plug them in I like to

00:00:23,609 --> 00:00:26,580
give a little background first about the

00:00:25,260 --> 00:00:29,519
Center for Genome Research and bio

00:00:26,580 --> 00:00:31,320
computing we work right now with 26

00:00:29,519 --> 00:00:32,880
departments across the entire university

00:00:31,320 --> 00:00:35,700
and a whole bunch of groups outside of

00:00:32,880 --> 00:00:39,210
our university we usually complete about

00:00:35,700 --> 00:00:41,670
20,000 jobs a day we have about 5,000

00:00:39,210 --> 00:00:43,920
and 6,000 processors going at all times

00:00:41,670 --> 00:00:47,789
we're holding about five petabytes of

00:00:43,920 --> 00:00:49,530
research data and we have quite a few

00:00:47,789 --> 00:00:51,449
machines with greater than one terabyte

00:00:49,530 --> 00:00:54,120
of memory to allow us to change the

00:00:51,449 --> 00:00:56,250
scope of work we can do we we did start

00:00:54,120 --> 00:00:57,660
buying a lot of the power8 Minsky boxes

00:00:56,250 --> 00:01:00,870
with the GPUs in them and we started

00:00:57,660 --> 00:01:02,969
then after those got migrated to the AC

00:01:00,870 --> 00:01:04,500
922 started buying those and that's what

00:01:02,969 --> 00:01:07,799
we're here to talk about a little bit

00:01:04,500 --> 00:01:10,799
today why we buy them the purpose behind

00:01:07,799 --> 00:01:12,270
them and how we use them right now that

00:01:10,799 --> 00:01:14,580
in the last five years has been about

00:01:12,270 --> 00:01:17,369
500 scientific publications associated

00:01:14,580 --> 00:01:19,250
to our work so we try to be as impactful

00:01:17,369 --> 00:01:23,610
as possible

00:01:19,250 --> 00:01:25,460
see GRB has a model where we maintain a

00:01:23,610 --> 00:01:27,840
lot of the software tools for our group

00:01:25,460 --> 00:01:29,790
there are currently over about four

00:01:27,840 --> 00:01:33,900
actually closer to 5,000 accessible

00:01:29,790 --> 00:01:35,700
programs and and tools we spend some

00:01:33,900 --> 00:01:38,310
time porting them to the power side and

00:01:35,700 --> 00:01:39,990
I'll talk about that a little bit the cg

00:01:38,310 --> 00:01:41,250
army donates this time to compile these

00:01:39,990 --> 00:01:42,630
tools it really enables the

00:01:41,250 --> 00:01:45,060
infrastructure and allows people to get

00:01:42,630 --> 00:01:47,460
working we also have computational staff

00:01:45,060 --> 00:01:49,710
that people can hire our way based on

00:01:47,460 --> 00:01:52,110
FTE or our and they can help them

00:01:49,710 --> 00:01:54,210
interact with the infrastructure and

00:01:52,110 --> 00:01:56,240
interact with technology helping them

00:01:54,210 --> 00:01:58,740
get that extra computational work done

00:01:56,240 --> 00:02:00,390
we build new tools as well that's what

00:01:58,740 --> 00:02:02,520
we're going to talk about today is that

00:02:00,390 --> 00:02:04,170
build the tools that we've built and how

00:02:02,520 --> 00:02:07,890
they interact with that architecture

00:02:04,170 --> 00:02:09,420
tools are novel and heading in the

00:02:07,890 --> 00:02:11,319
direction of currently deep learning and

00:02:09,420 --> 00:02:13,150
mission learning

00:02:11,319 --> 00:02:16,390
we started a collaboration with IBM

00:02:13,150 --> 00:02:19,540
where as we started to go to the PowerPC

00:02:16,390 --> 00:02:22,180
64 le platform we noticed that there was

00:02:19,540 --> 00:02:23,790
a lack of binaries over in that space

00:02:22,180 --> 00:02:26,409
and what we really wanted to do was

00:02:23,790 --> 00:02:28,390
bring the binaries over and bring the

00:02:26,409 --> 00:02:31,510
compiling methods over and so I paid an

00:02:28,390 --> 00:02:33,549
undergraduate to go ahead and do that

00:02:31,510 --> 00:02:35,769
process for us he actually worked with

00:02:33,549 --> 00:02:38,319
IBM as an intern and he put a ton of

00:02:35,769 --> 00:02:40,930
build scripts up over 2000 programs up

00:02:38,319 --> 00:02:42,129
on github people can just pull down

00:02:40,930 --> 00:02:43,569
these build scripts around them and they

00:02:42,129 --> 00:02:44,950
actually bring the binaries down bring

00:02:43,569 --> 00:02:47,920
them up and make them work it's kind of

00:02:44,950 --> 00:02:50,489
nice really lowers the energy for people

00:02:47,920 --> 00:02:53,200
to interact with that stuff

00:02:50,489 --> 00:02:56,650
we also do a lot of work with Lance

00:02:53,200 --> 00:02:58,269
who's here and Thank You Lance in the

00:02:56,650 --> 00:02:59,889
open source lab and that collaboration

00:02:58,269 --> 00:03:01,299
is really important to us because it

00:02:59,889 --> 00:03:02,769
allows us to interact with many of the

00:03:01,299 --> 00:03:06,790
companies that we're trying to work with

00:03:02,769 --> 00:03:10,569
and present some of the work out to the

00:03:06,790 --> 00:03:12,489
world in that context the OSU OSL has

00:03:10,569 --> 00:03:17,290
been up for a long time how long Lance

00:03:12,489 --> 00:03:19,299
where we took 20 years 15 okay and we

00:03:17,290 --> 00:03:22,690
are providing through the CGR be with

00:03:19,299 --> 00:03:25,150
Lance access to the GPU machines on the

00:03:22,690 --> 00:03:27,669
AC 9 22s for free so people can check

00:03:25,150 --> 00:03:30,340
out at AC 9 22s with us and they can get

00:03:27,669 --> 00:03:32,500
onto the AC 9 22s with the P 100 over T

00:03:30,340 --> 00:03:34,540
100 in this case and we do it for free

00:03:32,500 --> 00:03:35,919
we're gonna get people on there and we

00:03:34,540 --> 00:03:37,540
don't care who you are we're not gonna

00:03:35,919 --> 00:03:38,979
try and take anything from you and we'll

00:03:37,540 --> 00:03:41,260
give you bare metal we'll give you

00:03:38,979 --> 00:03:43,030
whatever access you need and that allows

00:03:41,260 --> 00:03:44,680
people to port this software interact

00:03:43,030 --> 00:03:47,709
with the technology and look at it in a

00:03:44,680 --> 00:03:50,739
in a unthreatened way it was what we

00:03:47,709 --> 00:03:52,780
like to think okay today we're going to

00:03:50,739 --> 00:03:54,819
look at and focus on four different

00:03:52,780 --> 00:03:56,379
algorithms we've written inside the

00:03:54,819 --> 00:03:59,919
Center for Genome Research and bio

00:03:56,379 --> 00:04:03,280
computing and these are really more of

00:03:59,919 --> 00:04:04,780
the deep learning AI space and we're

00:04:03,280 --> 00:04:06,729
focused in on these because this talk is

00:04:04,780 --> 00:04:09,549
about how GPUs and architectures work

00:04:06,729 --> 00:04:11,979
together now we're going to go through

00:04:09,549 --> 00:04:13,209
each one of these first individually

00:04:11,979 --> 00:04:14,709
we're going to talk about each one of

00:04:13,209 --> 00:04:16,509
the algorithms a little bit then we're

00:04:14,709 --> 00:04:20,289
going to actually watch them race each

00:04:16,509 --> 00:04:21,030
other after we've discussed them on GPUs

00:04:20,289 --> 00:04:22,380
in

00:04:21,030 --> 00:04:25,530
we're gonna watch some videos and see

00:04:22,380 --> 00:04:27,450
what really effect of different types of

00:04:25,530 --> 00:04:28,950
processing on different architecture and

00:04:27,450 --> 00:04:30,960
how those occur each one of these does a

00:04:28,950 --> 00:04:33,060
different type of processing I think

00:04:30,960 --> 00:04:35,580
that's what's important the avian one is

00:04:33,060 --> 00:04:39,180
the first and we're gonna go through in

00:04:35,580 --> 00:04:40,650
just one second we we saw these

00:04:39,180 --> 00:04:43,950
algorithms and we started building them

00:04:40,650 --> 00:04:46,320
originally on the x86 side and we or

00:04:43,950 --> 00:04:48,030
some of them and when we started to

00:04:46,320 --> 00:04:49,770
bring them over to the IBM side we

00:04:48,030 --> 00:04:51,360
noticed the tremendous speed up and so

00:04:49,770 --> 00:04:54,030
we started this collaboration with IBM

00:04:51,360 --> 00:04:57,120
to really start investigating that on

00:04:54,030 --> 00:04:59,970
the GP GPUs power in power 9 for example

00:04:57,120 --> 00:05:01,560
some of them cut their time in half and

00:04:59,970 --> 00:05:03,180
that was really important to us because

00:05:01,560 --> 00:05:04,800
it changed the scope of work that we

00:05:03,180 --> 00:05:08,190
could do and helped us remove bias by

00:05:04,800 --> 00:05:10,020
increasing more data and so we put up

00:05:08,190 --> 00:05:14,070
some of these blogs like the spotted owl

00:05:10,020 --> 00:05:15,210
one and the oceans of data one which is

00:05:14,070 --> 00:05:15,720
about the plankton which you'll see in

00:05:15,210 --> 00:05:17,430
just a minute

00:05:15,720 --> 00:05:19,350
and we kind of give people the

00:05:17,430 --> 00:05:21,840
impression that you know the different

00:05:19,350 --> 00:05:23,700
architecture does affect things so let's

00:05:21,840 --> 00:05:25,830
start talking about these the first one

00:05:23,700 --> 00:05:27,290
here is where we're actually working

00:05:25,830 --> 00:05:31,850
with the Forest Service to monitor

00:05:27,290 --> 00:05:34,650
northern spotted owl in the Northwest

00:05:31,850 --> 00:05:37,280
area and we're actually just putting

00:05:34,650 --> 00:05:39,930
recorders in the forest and we are

00:05:37,280 --> 00:05:41,820
generating copious amounts of sound data

00:05:39,930 --> 00:05:43,350
and we just record the forest and then

00:05:41,820 --> 00:05:47,039
we ultimately want to process through

00:05:43,350 --> 00:05:50,789
that we want to track the spotted owl

00:05:47,039 --> 00:05:52,800
populations and the migration pathways

00:05:50,789 --> 00:05:54,390
and even potentially get to where we can

00:05:52,800 --> 00:05:56,400
identify individual species or

00:05:54,390 --> 00:05:59,220
individual owls and watch them move

00:05:56,400 --> 00:06:00,210
through the forest so as we started to

00:05:59,220 --> 00:06:03,960
do this I did this with one

00:06:00,210 --> 00:06:05,789
undergraduate broth right here and you

00:06:03,960 --> 00:06:08,760
know we we had a lot of stuff coming out

00:06:05,789 --> 00:06:09,390
so we had 150 sites of data it was 250

00:06:08,760 --> 00:06:13,460
tera

00:06:09,390 --> 00:06:16,470
every month and a half to two months and

00:06:13,460 --> 00:06:18,600
we needed to create a CNN from scratch

00:06:16,470 --> 00:06:21,930
that would basically be able to mine all

00:06:18,600 --> 00:06:24,030
of the owl data out of there and so we

00:06:21,930 --> 00:06:25,979
went ahead and did that we created the

00:06:24,030 --> 00:06:28,370
CNN and it's I've been accepted in a

00:06:25,979 --> 00:06:31,070
paper this past Sunday

00:06:28,370 --> 00:06:33,680
so that'll be coming out but we started

00:06:31,070 --> 00:06:38,180
to race them first we noticed that we

00:06:33,680 --> 00:06:40,100
had K ATS on the original x86 machines

00:06:38,180 --> 00:06:43,639
they were donated by Nvidia for this

00:06:40,100 --> 00:06:45,500
project and when we moved on to the IBM

00:06:43,639 --> 00:06:46,820
power boxes we had P 100 we noticed this

00:06:45,500 --> 00:06:49,130
tremendous difference and we thought

00:06:46,820 --> 00:06:51,590
well is it the P 100 and it really

00:06:49,130 --> 00:06:53,240
wasn't it wasn't the P 100 because

00:06:51,590 --> 00:06:55,460
ultimately we bought P 100 and race to

00:06:53,240 --> 00:06:58,100
them they they didn't integrate they

00:06:55,460 --> 00:07:00,950
didn't act the same way on the x86 and

00:06:58,100 --> 00:07:02,810
so we found that the copy bus of the env

00:07:00,950 --> 00:07:05,300
link created a pathway of moving data

00:07:02,810 --> 00:07:07,010
that was so much greater than what we

00:07:05,300 --> 00:07:10,340
were seeing on the x86 side that it

00:07:07,010 --> 00:07:14,169
really intrigued us and as we kept

00:07:10,340 --> 00:07:16,700
moving forward we thought let's start to

00:07:14,169 --> 00:07:19,669
leverage this copy and these

00:07:16,700 --> 00:07:20,780
interactions in other ways and so we

00:07:19,669 --> 00:07:22,580
started to build more two algorithms

00:07:20,780 --> 00:07:24,889
around this and one of them we called

00:07:22,580 --> 00:07:26,810
was Casa so that's the next one we're

00:07:24,889 --> 00:07:29,900
going to talk about in Casa is a tool

00:07:26,810 --> 00:07:31,880
that we created on CUDA that actually

00:07:29,900 --> 00:07:33,650
does genome sequence alignment so this

00:07:31,880 --> 00:07:35,270
is done pretty heavily out there right

00:07:33,650 --> 00:07:37,820
now in the world of bioinformatics and

00:07:35,270 --> 00:07:40,970
bio computing and we recognize that a

00:07:37,820 --> 00:07:43,820
lot of groups were burning CPU time just

00:07:40,970 --> 00:07:45,050
pounding sequence alignment through and

00:07:43,820 --> 00:07:46,639
we thought well it might be a better way

00:07:45,050 --> 00:07:47,930
to do this if we really could push data

00:07:46,639 --> 00:07:50,180
through the boss and it looked like this

00:07:47,930 --> 00:07:52,520
copy and feeling could do it and so we

00:07:50,180 --> 00:07:54,710
built this thing called CUDA or I'm

00:07:52,520 --> 00:07:58,820
sorry Casas in Casas yeah I wish we

00:07:54,710 --> 00:08:02,450
built CUDA that was funny we built Casas

00:07:58,820 --> 00:08:05,539
and casa allowed us to really interact

00:08:02,450 --> 00:08:06,919
with the GPU in an interesting way again

00:08:05,539 --> 00:08:08,360
I have an undergraduate who helped me do

00:08:06,919 --> 00:08:10,760
this Ryan kitchen

00:08:08,360 --> 00:08:13,070
he's now such moved on and getting paid

00:08:10,760 --> 00:08:15,680
a lot more money than me but as you can

00:08:13,070 --> 00:08:18,770
see here's our P 100 these are p1

00:08:15,680 --> 00:08:20,510
hundredths and this is you know us

00:08:18,770 --> 00:08:22,310
running costs of vs. our standard

00:08:20,510 --> 00:08:25,490
algorithms some people out there might

00:08:22,310 --> 00:08:30,190
know bwa it's a very famous algorithm

00:08:25,490 --> 00:08:35,240
it's burrows-wheeler we put the bwa and

00:08:30,190 --> 00:08:36,890
bowtie algorithms alignment pieces into

00:08:35,240 --> 00:08:38,409
casa so that way you could run those

00:08:36,890 --> 00:08:41,769
those those

00:08:38,409 --> 00:08:43,959
pieces and get similar output or exactly

00:08:41,769 --> 00:08:46,060
the same output you can see what 16

00:08:43,959 --> 00:08:48,519
cores are throughput on the CPU is

00:08:46,060 --> 00:08:51,639
pretty low but as we moved on to the P

00:08:48,519 --> 00:08:54,670
100 it really increased and we noticed

00:08:51,639 --> 00:08:58,149
that you get to the 3x increase by

00:08:54,670 --> 00:08:59,560
running the P 100 on the IBM platform so

00:08:58,149 --> 00:09:01,480
in this case it was actually on Minsky

00:08:59,560 --> 00:09:02,470
this is when we were on the Minsky's and

00:09:01,480 --> 00:09:04,810
we were starting to move on these

00:09:02,470 --> 00:09:06,550
Minsky's and we realized wow we can

00:09:04,810 --> 00:09:09,579
pound data through the Minsky's and

00:09:06,550 --> 00:09:12,639
especially on those GPUs it was stunning

00:09:09,579 --> 00:09:14,790
instead of doing 45 minutes for a small

00:09:12,639 --> 00:09:17,769
file we were done in two minutes and

00:09:14,790 --> 00:09:21,160
that really changed people's opinion of

00:09:17,769 --> 00:09:22,959
using this technology we had to verify

00:09:21,160 --> 00:09:24,579
that our accuracy was good and so we

00:09:22,959 --> 00:09:26,319
actually you know looked through and we

00:09:24,579 --> 00:09:29,410
actually were able to become more

00:09:26,319 --> 00:09:31,959
accurate than them our hit rate is

00:09:29,410 --> 00:09:34,600
amazing but you can see our accuracy

00:09:31,959 --> 00:09:36,339
lies above the bowtie accuracy which is

00:09:34,600 --> 00:09:38,379
important because bowtie bees become

00:09:36,339 --> 00:09:41,310
somewhat of the de-facto standard out

00:09:38,379 --> 00:09:44,560
there in the bio computing world and

00:09:41,310 --> 00:09:47,800
that really really gave us confidence in

00:09:44,560 --> 00:09:50,290
utilizing this technology so let's move

00:09:47,800 --> 00:09:52,600
on to the the third one this is

00:09:50,290 --> 00:09:54,880
predicting ocean health where we

00:09:52,600 --> 00:09:57,579
actually drag video cameras behind an

00:09:54,880 --> 00:09:59,980
NSF ship and we take the video and we

00:09:57,579 --> 00:10:02,459
classify plankton and so we can identify

00:09:59,980 --> 00:10:04,509
a hundred and sixty-seven different

00:10:02,459 --> 00:10:10,589
types of plankton right now at this

00:10:04,509 --> 00:10:10,589
point in time and we built the CNN with

00:10:11,009 --> 00:10:20,350
it was one of the keeping mice mined

00:10:15,550 --> 00:10:22,569
here one of the competitions out there I

00:10:20,350 --> 00:10:23,829
can't remember the competition group

00:10:22,569 --> 00:10:26,139
that was doing it but it was one of the

00:10:23,829 --> 00:10:27,730
data science bowls competitions and then

00:10:26,139 --> 00:10:29,250
we've taken the algorithm and changed it

00:10:27,730 --> 00:10:31,449
to make it more accurate

00:10:29,250 --> 00:10:33,490
ultimately this one generates about

00:10:31,449 --> 00:10:36,699
right now a hundred terabytes of data a

00:10:33,490 --> 00:10:38,620
week at the ocean and we have to process

00:10:36,699 --> 00:10:40,750
through that video data very rapidly

00:10:38,620 --> 00:10:43,120
because ultimately it will create

00:10:40,750 --> 00:10:45,069
tremendous amounts of downstream data

00:10:43,120 --> 00:10:46,509
every time there's a plankton has to cut

00:10:45,069 --> 00:10:47,759
it out in terms of image if I go through

00:10:46,509 --> 00:10:51,520
plankton rich water I could have

00:10:47,759 --> 00:10:53,920
billions of images to classify

00:10:51,520 --> 00:10:56,740
it is an alarming process so you have a

00:10:53,920 --> 00:10:59,140
finite amount of input data but then it

00:10:56,740 --> 00:11:01,779
turns into a tremendous amount of

00:10:59,140 --> 00:11:03,130
downstream data our objectives are

00:11:01,779 --> 00:11:04,570
really to change the scope of work that

00:11:03,130 --> 00:11:06,339
we could do increase the number of

00:11:04,570 --> 00:11:08,950
species increase our accuracy and reduce

00:11:06,339 --> 00:11:10,899
training time and the training time one

00:11:08,950 --> 00:11:12,100
is the big one it was taking us about a

00:11:10,899 --> 00:11:15,399
month to Train

00:11:12,100 --> 00:11:17,709
on the x86 on the PCIe and we've reduced

00:11:15,399 --> 00:11:19,420
that down to about seven days so that

00:11:17,709 --> 00:11:22,149
was a huge step for us because now we

00:11:19,420 --> 00:11:25,510
can fit into the limits on some of the

00:11:22,149 --> 00:11:27,220
cloud services for time allocation we

00:11:25,510 --> 00:11:29,260
can only run for seven days on exceed

00:11:27,220 --> 00:11:30,910
and we had to fit into a seven day

00:11:29,260 --> 00:11:33,880
process and now we could actually train

00:11:30,910 --> 00:11:35,709
up on seed if we could get these guys to

00:11:33,880 --> 00:11:37,660
buy a real hardware you know some ac9

00:11:35,709 --> 00:11:39,790
22s and so we've been to talk with them

00:11:37,660 --> 00:11:42,310
about that again and undergraduate named

00:11:39,790 --> 00:11:44,140
Mikaela worked on this project and

00:11:42,310 --> 00:11:46,930
she'll be working on some of the other

00:11:44,140 --> 00:11:48,520
projects you'll see coming down this is

00:11:46,930 --> 00:11:50,740
the famous image that's out there that

00:11:48,520 --> 00:11:53,110
we put out dragged the camera behind the

00:11:50,740 --> 00:11:56,370
boat the plankton feeds everything and

00:11:53,110 --> 00:11:59,050
so it really is about ocean health and

00:11:56,370 --> 00:12:03,190
we actually were able to scale this one

00:11:59,050 --> 00:12:05,079
up going on the AC 922 allowed us to

00:12:03,190 --> 00:12:07,570
rewrite the grant show people what we

00:12:05,079 --> 00:12:10,000
could do with it and we got funding for

00:12:07,570 --> 00:12:13,029
four countries and now we'll be doing it

00:12:10,000 --> 00:12:15,610
with Brazil France Japan and the United

00:12:13,029 --> 00:12:21,180
States so this is gonna be massively

00:12:15,610 --> 00:12:23,230
scaling up let's see

00:12:21,180 --> 00:12:24,850
really it's important that we realized

00:12:23,230 --> 00:12:26,860
that there's two steps to this one along

00:12:24,850 --> 00:12:29,980
with the avian one that was segmentation

00:12:26,860 --> 00:12:31,750
and classification and this one actually

00:12:29,980 --> 00:12:33,870
leans pretty heavily on the segmentation

00:12:31,750 --> 00:12:37,089
side and we realized that the AC 922

00:12:33,870 --> 00:12:39,790
came with two parts there was a lot of

00:12:37,089 --> 00:12:41,649
processing capability on one side and

00:12:39,790 --> 00:12:42,940
there was a lot of GPU capability on the

00:12:41,649 --> 00:12:45,190
other side and you could leverage them

00:12:42,940 --> 00:12:47,620
at the exact same time and so we are

00:12:45,190 --> 00:12:50,380
actually using the AC 29 22 like it's

00:12:47,620 --> 00:12:52,180
cluster in a box you can segment on one

00:12:50,380 --> 00:12:54,140
side while it's classifying on the other

00:12:52,180 --> 00:12:55,970
and you've got full go

00:12:54,140 --> 00:12:58,160
is really impressive the limit actually

00:12:55,970 --> 00:12:59,930
became the network and so we had to

00:12:58,160 --> 00:13:01,310
start putting 1,400 gig on the machines

00:12:59,930 --> 00:13:02,600
to actually keep them hopped up and keep

00:13:01,310 --> 00:13:04,850
them going okay

00:13:02,600 --> 00:13:07,220
the fourth algorithm we're going to talk

00:13:04,850 --> 00:13:09,710
about a little bit is a newer one where

00:13:07,220 --> 00:13:12,590
we've actually created a process where

00:13:09,710 --> 00:13:15,170
we can identify different grass seed

00:13:12,590 --> 00:13:18,230
species and separate them and this one

00:13:15,170 --> 00:13:21,620
is utilizing tensorflow do things like

00:13:18,230 --> 00:13:23,750
this we have an engineer and a CS

00:13:21,620 --> 00:13:26,510
student helping us our goal is to get to

00:13:23,750 --> 00:13:30,110
about 14 seeds per second and make sure

00:13:26,510 --> 00:13:32,090
that we have 100% pure one type of seed

00:13:30,110 --> 00:13:33,530
in the in the bag if you've ever looked

00:13:32,090 --> 00:13:35,840
at grass seed they'll only go up to

00:13:33,530 --> 00:13:37,190
about 99 percent pure and that's because

00:13:35,840 --> 00:13:38,630
there's no possible way for them to

00:13:37,190 --> 00:13:41,120
actually separate out the grass seeds

00:13:38,630 --> 00:13:42,920
effectively unless it's done by hand and

00:13:41,120 --> 00:13:44,570
so there are people at Oregon State

00:13:42,920 --> 00:13:46,490
because we are the grass seed capital of

00:13:44,570 --> 00:13:48,170
the world there are people at Oregon

00:13:46,490 --> 00:13:50,030
State who literally sit with microscopes

00:13:48,170 --> 00:13:52,190
separating grass seed and they get paid

00:13:50,030 --> 00:13:54,050
all day to do that and it's an alarming

00:13:52,190 --> 00:13:56,540
process but grass seed is super small

00:13:54,050 --> 00:13:58,730
it's super hard to deal with and it's

00:13:56,540 --> 00:14:01,400
super hard to see and so that's one of

00:13:58,730 --> 00:14:05,240
the goals that we had in this one so

00:14:01,400 --> 00:14:07,250
here's the scanner and you can see these

00:14:05,240 --> 00:14:10,640
seeds are actually in macro lenses so

00:14:07,250 --> 00:14:12,290
they're actually been blown out but our

00:14:10,640 --> 00:14:14,630
goal is to be able to say that's a good

00:14:12,290 --> 00:14:16,430
seed and that's a bad seed and this came

00:14:14,630 --> 00:14:19,040
from a lot of training data so although

00:14:16,430 --> 00:14:22,010
we're running this on a desktop with a

00:14:19,040 --> 00:14:24,610
desktop GPU we actually had to do all

00:14:22,010 --> 00:14:27,980
the training data on the AC 9:22 and so

00:14:24,610 --> 00:14:29,810
without training over on the AC 9:22 we

00:14:27,980 --> 00:14:31,190
were gonna take exorbitant amounts of

00:14:29,810 --> 00:14:33,590
time and you got to realize i'm paying

00:14:31,190 --> 00:14:35,150
people to do this i'm gonna pay somebody

00:14:33,590 --> 00:14:36,590
to sit there and watch the training go

00:14:35,150 --> 00:14:38,270
and that's not going to be good and

00:14:36,590 --> 00:14:39,530
they're waiting for that to finish to

00:14:38,270 --> 00:14:41,060
see what the next steps going to be or

00:14:39,530 --> 00:14:44,900
help with the effect you know the effect

00:14:41,060 --> 00:14:46,460
was so in the end if we could massively

00:14:44,900 --> 00:14:48,170
reduce that train it keeps people

00:14:46,460 --> 00:14:52,130
focused keeps them on task and keeps

00:14:48,170 --> 00:14:55,550
them going so this led us to a project

00:14:52,130 --> 00:14:57,320
that I worked with Tech Data a little

00:14:55,550 --> 00:15:00,200
bit because I had to get some extra

00:14:57,320 --> 00:15:01,870
hardware in and we really wanted to

00:15:00,200 --> 00:15:04,839
create a demo site around

00:15:01,870 --> 00:15:07,900
concept of seeing how the speed-up and

00:15:04,839 --> 00:15:10,510
the change occurred with the same GPU

00:15:07,900 --> 00:15:12,460
across different architectures and so we

00:15:10,510 --> 00:15:15,310
started this with an undergraduate named

00:15:12,460 --> 00:15:17,380
Azam and Mikayla is now taking this over

00:15:15,310 --> 00:15:19,420
as she's migrated off the plankton

00:15:17,380 --> 00:15:21,400
algorithm and so they created a website

00:15:19,420 --> 00:15:22,480
that shows these differences between

00:15:21,400 --> 00:15:25,540
GPUs and that's what we're really

00:15:22,480 --> 00:15:27,100
focused in on today each machine and

00:15:25,540 --> 00:15:29,920
these examples will be running

00:15:27,100 --> 00:15:31,270
side-by-side and we can choose the

00:15:29,920 --> 00:15:34,210
machines that we want

00:15:31,270 --> 00:15:37,270
along with choosing the number of GPUs

00:15:34,210 --> 00:15:39,520
and things like that it really was

00:15:37,270 --> 00:15:42,250
focused initially on the PCIe versus the

00:15:39,520 --> 00:15:44,440
envy link because at the time that was

00:15:42,250 --> 00:15:47,620
only envy link was only available on the

00:15:44,440 --> 00:15:50,260
IBM side and as we move forward we

00:15:47,620 --> 00:15:53,290
realized that the dgx and dgx 2s were

00:15:50,260 --> 00:15:56,650
bringing in a new flavor of envy or envy

00:15:53,290 --> 00:15:58,029
link on the PCI or the x86 side when

00:15:56,650 --> 00:15:59,170
that was occurring we really want to

00:15:58,029 --> 00:16:00,820
make sure we have those two and so we

00:15:59,170 --> 00:16:04,330
included into some new data about the DG

00:16:00,820 --> 00:16:06,100
X 2 and we've raced those as well ok we

00:16:04,330 --> 00:16:07,959
did talk with Dowell and a whole bunch

00:16:06,100 --> 00:16:10,600
of the computing groups who sell a lot

00:16:07,959 --> 00:16:13,420
of the x86 advanced high-performance

00:16:10,600 --> 00:16:15,730
computing HPC and they did communicate

00:16:13,420 --> 00:16:19,050
up until the beginning of this month

00:16:15,730 --> 00:16:22,150
that people are still buying pcie-based

00:16:19,050 --> 00:16:24,790
x86 boxes and it has to do with the

00:16:22,150 --> 00:16:27,160
price it just simply is the price and

00:16:24,790 --> 00:16:29,470
people are definitely scared of the dgx

00:16:27,160 --> 00:16:31,870
because of its price and so we've

00:16:29,470 --> 00:16:34,540
recognized that the AC 922 sits in the

00:16:31,870 --> 00:16:36,400
middle is a really good price point to

00:16:34,540 --> 00:16:38,380
actually be able to embark on moving

00:16:36,400 --> 00:16:42,339
data on the GPU without having to ensue

00:16:38,380 --> 00:16:44,080
that cost of the DG X so let's go

00:16:42,339 --> 00:16:46,060
through here and let's look at this demo

00:16:44,080 --> 00:16:47,709
so the demo that we're going to start

00:16:46,060 --> 00:16:51,220
with is willing to us focused on that

00:16:47,709 --> 00:16:52,770
PCIe and it still is because Dell who

00:16:51,220 --> 00:16:55,029
also helped us with this a little bit

00:16:52,770 --> 00:16:57,790
really want people to understand the

00:16:55,029 --> 00:16:58,930
difference of putting GPUs on different

00:16:57,790 --> 00:17:00,970
things and they want people to stop

00:16:58,930 --> 00:17:02,740
putting desktop GPUs on the servers that

00:17:00,970 --> 00:17:04,569
was one of their goals because they saw

00:17:02,740 --> 00:17:06,370
a lot of people putting desktop GPUs on

00:17:04,569 --> 00:17:07,199
to their servers breaking EULA's and all

00:17:06,370 --> 00:17:10,810
kinds of stuff

00:17:07,199 --> 00:17:12,370
we were running 10 80s to race those in

00:17:10,810 --> 00:17:13,839
this demo we dropped that out of the

00:17:12,370 --> 00:17:16,449
demo because it was just such

00:17:13,839 --> 00:17:19,659
bad heart it took so long to run this

00:17:16,449 --> 00:17:22,209
enough compared to these GPU GPUs I mean

00:17:19,659 --> 00:17:25,449
we're talking like you know 10x the time

00:17:22,209 --> 00:17:27,579
sometimes so we dropped it it was going

00:17:25,449 --> 00:17:29,470
to take too long a show on the demo but

00:17:27,579 --> 00:17:32,850
really these are the two pieces of

00:17:29,470 --> 00:17:37,299
hardware we focused in on the IBM AC 922

00:17:32,850 --> 00:17:39,970
has four V 100's in it 32 gig and then

00:17:37,299 --> 00:17:42,940
we have an Intel Xeon it actually has 5

00:17:39,970 --> 00:17:44,559
V 100's in it it was actually able to

00:17:42,940 --> 00:17:46,600
hold five of them and so they're very

00:17:44,559 --> 00:17:48,999
similar and they were actually very

00:17:46,600 --> 00:17:50,559
similar in price will even out there

00:17:48,999 --> 00:17:51,999
within about five to six thousand

00:17:50,559 --> 00:17:54,429
dollars of each other in terms of cost

00:17:51,999 --> 00:17:56,649
to me and that's because the GPUs are

00:17:54,429 --> 00:17:57,970
actually the main cost they were very

00:17:56,649 --> 00:18:00,129
expensive when we were putting these up

00:17:57,970 --> 00:18:03,970
there are probably 30 thousand dollars

00:18:00,129 --> 00:18:07,360
apiece maybe and so we tried to

00:18:03,970 --> 00:18:10,210
configure machines exactly the same in

00:18:07,360 --> 00:18:12,490
this case the AC 922 is a 2.2 gigahertz

00:18:10,210 --> 00:18:15,220
we bought a 2.2 gigahertz down below on

00:18:12,490 --> 00:18:17,860
the Xeon side the Xeon required us to

00:18:15,220 --> 00:18:19,570
back the processor down and that was

00:18:17,860 --> 00:18:21,639
because we wanted to hook up so many

00:18:19,570 --> 00:18:23,169
GPUs and there was only so much power

00:18:21,639 --> 00:18:26,259
going into the box that they actually

00:18:23,169 --> 00:18:27,549
reduced the processor the dgx does not

00:18:26,259 --> 00:18:31,179
do that but the amount of power going

00:18:27,549 --> 00:18:32,799
the dgx is alarming so this is a

00:18:31,179 --> 00:18:35,200
consequence that we see and we want

00:18:32,799 --> 00:18:37,419
people to understand that consequence so

00:18:35,200 --> 00:18:40,299
as we go forward we're gonna sit here

00:18:37,419 --> 00:18:43,659
and we're gonna run a video where we are

00:18:40,299 --> 00:18:45,369
gonna run the avian algorithm okay now I

00:18:43,659 --> 00:18:48,220
sped the videos up to reduce the time

00:18:45,369 --> 00:18:49,840
for this presentation but this avian

00:18:48,220 --> 00:18:51,730
algorithm is really about moving data on

00:18:49,840 --> 00:18:53,080
the bus and so it's going to try and

00:18:51,730 --> 00:18:54,340
move the data across the bus and we're

00:18:53,080 --> 00:18:57,850
going to see the reaction of that

00:18:54,340 --> 00:19:01,179
hopefully there we go so it's a little

00:18:57,850 --> 00:19:03,129
bit hard to see but as you go you can

00:19:01,179 --> 00:19:05,529
see the left sides already started and

00:19:03,129 --> 00:19:07,960
the right sides trying to get going and

00:19:05,529 --> 00:19:09,249
the really that was a really important

00:19:07,960 --> 00:19:12,820
piece right there is that as we get

00:19:09,249 --> 00:19:14,049
going the the the AC 922 immediately

00:19:12,820 --> 00:19:15,820
starts interacting with the bus

00:19:14,049 --> 00:19:19,210
immediately starts loading the data and

00:19:15,820 --> 00:19:20,919
start your processing and so that right

00:19:19,210 --> 00:19:23,559
there made us realize that there was an

00:19:20,919 --> 00:19:25,629
interaction problem just talking to the

00:19:23,559 --> 00:19:27,869
GPU to begin with but then when you got

00:19:25,629 --> 00:19:31,690
on the GPU sending data through the bus

00:19:27,869 --> 00:19:36,460
became prohibitive and so as we went

00:19:31,690 --> 00:19:39,070
through on this one we get a 2 X - 3 X

00:19:36,460 --> 00:19:41,590
speed up just by plugins the exact same

00:19:39,070 --> 00:19:43,600
code guys we did no change to the code

00:19:41,590 --> 00:19:45,789
here we just dropped the code on the AC

00:19:43,600 --> 00:19:50,259
922 and watch the girl was 3x faster and

00:19:45,789 --> 00:19:51,669
it was like yay no programming no effort

00:19:50,259 --> 00:19:54,399
all we had to do was have the right

00:19:51,669 --> 00:19:56,590
version of tensorflow and with powering

00:19:54,399 --> 00:19:59,230
I okay well Watson machine learning

00:19:56,590 --> 00:20:02,049
whatever we want to call it today power

00:19:59,230 --> 00:20:05,529
AI it was super easy for us I want you

00:20:02,049 --> 00:20:07,659
guys to also appreciate that the values

00:20:05,529 --> 00:20:10,240
on the plots are very consistent on the

00:20:07,659 --> 00:20:14,230
env link and on the AC 922 and go up and

00:20:10,240 --> 00:20:15,940
down it's very noisy on the PCIe and the

00:20:14,230 --> 00:20:18,909
x86 and that's just the way it's always

00:20:15,940 --> 00:20:21,250
been and we we recognize this so when

00:20:18,909 --> 00:20:24,789
they finished you were at least two x

00:20:21,250 --> 00:20:32,369
from the I think I just lost power

00:20:24,789 --> 00:20:32,369
hold on sorry about that

00:20:33,370 --> 00:20:40,360
so the the speed is there power up here

00:20:40,600 --> 00:20:49,880
maybe I didn't see it real so the speed

00:20:47,840 --> 00:20:54,140
of moving data across the bus is really

00:20:49,880 --> 00:20:57,230
what we were focused in on and that

00:20:54,140 --> 00:21:00,040
became ever so crucial because we were

00:20:57,230 --> 00:21:09,309
working with 250 Tara worth of data

00:21:00,040 --> 00:21:11,419
every couple months baby and and the

00:21:09,309 --> 00:21:13,850
Forest Service really want to scale this

00:21:11,419 --> 00:21:16,970
algorithm up pretty heavily and as we

00:21:13,850 --> 00:21:18,770
want to scale it up they want to put we

00:21:16,970 --> 00:21:23,000
were working currently with 1500

00:21:18,770 --> 00:21:25,970
recorders in the forest they want to

00:21:23,000 --> 00:21:28,450
scale it up to a lot much much greater

00:21:25,970 --> 00:21:31,700
than that and they wanted to ultimately

00:21:28,450 --> 00:21:33,530
potentially even go into real-time so

00:21:31,700 --> 00:21:37,460
we're looking at how we're going to be

00:21:33,530 --> 00:21:40,940
able to start interacting with the data

00:21:37,460 --> 00:21:48,590
in a much greater capacity and do it in

00:21:40,940 --> 00:21:51,370
a way where we okay here we go should we

00:21:48,590 --> 00:21:51,370
get this back up

00:21:54,040 --> 00:22:02,110
it just unplugged itself again it was up

00:22:00,000 --> 00:22:04,830
this soon as I touched the video it

00:22:02,110 --> 00:22:04,830
unplugged itself

00:22:06,120 --> 00:22:11,900
technical difficulties

00:22:08,770 --> 00:22:11,900
[Music]

00:22:24,480 --> 00:22:32,830
got a strong wall time and the same

00:22:29,230 --> 00:22:34,980
thing occurs on the plankton side so as

00:22:32,830 --> 00:22:36,910
we segment again on the owl the

00:22:34,980 --> 00:22:39,390
segmentations based upon how many owls

00:22:36,910 --> 00:22:42,640
made a sound in the forest now right now

00:22:39,390 --> 00:22:45,420
we started with owls we are sitting at

00:22:42,640 --> 00:22:49,450
11 species of owls and we're moving to

00:22:45,420 --> 00:22:53,260
more than that we also are now picking

00:22:49,450 --> 00:22:54,660
up squirrels and various other species

00:22:53,260 --> 00:22:58,780
in the forest

00:22:54,660 --> 00:23:00,910
so as we scale every single time we find

00:22:58,780 --> 00:23:03,190
a new species we're going to have to

00:23:00,910 --> 00:23:04,930
capture that piece of information and

00:23:03,190 --> 00:23:07,750
classify it the same thing as the

00:23:04,930 --> 00:23:11,590
plankton in so many cases where

00:23:07,750 --> 00:23:13,300
everything that we do is not based upon

00:23:11,590 --> 00:23:15,040
the raw data that comes out and I say

00:23:13,300 --> 00:23:17,500
based upon the segmentation of the raw

00:23:15,040 --> 00:23:20,280
data all right let's see if we can't do

00:23:17,500 --> 00:23:20,280
this again here

00:23:23,090 --> 00:23:30,890
it's opening hopefully

00:23:28,080 --> 00:23:30,890
all right

00:23:32,720 --> 00:23:35,590
moving on

00:23:42,230 --> 00:23:49,860
all right so there was the avian and

00:23:47,070 --> 00:23:53,309
those are the exact same GPUs and we saw

00:23:49,860 --> 00:23:58,710
four minutes versus seven minutes as we

00:23:53,309 --> 00:24:01,110
go forward and we did the DG x the DG ax

00:23:58,710 --> 00:24:03,809
was actually running MV amis and not

00:24:01,110 --> 00:24:07,260
SSDs and so we configured nvm YZ on our

00:24:03,809 --> 00:24:09,630
AC 922 as well and this one came in as

00:24:07,260 --> 00:24:12,980
the AC 922 thousand in three minutes and

00:24:09,630 --> 00:24:16,830
14 seconds now so it does drop and the

00:24:12,980 --> 00:24:20,850
DG x2 got down to where we were with the

00:24:16,830 --> 00:24:23,580
SSDs on the AC 922 so the envy link

00:24:20,850 --> 00:24:25,830
works on the DG x2 but it's not the same

00:24:23,580 --> 00:24:27,270
and working across that bus is just not

00:24:25,830 --> 00:24:30,049
the same in terms of moving data that's

00:24:27,270 --> 00:24:33,690
getting closer but it's not the same

00:24:30,049 --> 00:24:36,149
even when that DG x2 had a 10 VMI's in a

00:24:33,690 --> 00:24:40,289
raid 0 and we had 2m VMI's in a raid 0

00:24:36,149 --> 00:24:42,870
they were still not there so as we move

00:24:40,289 --> 00:24:44,340
on here's the plankton algorithm this is

00:24:42,870 --> 00:24:47,880
the one where remind me plankton out of

00:24:44,340 --> 00:24:49,620
the ocean and if we let this one run

00:24:47,880 --> 00:24:51,990
this one's a little different it's

00:24:49,620 --> 00:24:53,370
transactional so we go on and off and if

00:24:51,990 --> 00:24:55,429
you watch the left-hand side you can

00:24:53,370 --> 00:24:58,230
just watch the transactions going

00:24:55,429 --> 00:25:01,529
whereas the right-hand side is not and

00:24:58,230 --> 00:25:04,140
that cost of getting on and off the GPU

00:25:01,529 --> 00:25:07,020
at the beginning is really really

00:25:04,140 --> 00:25:09,299
hurting us here ok the jobs are small

00:25:07,020 --> 00:25:10,620
they can fit on the GPU no problem and

00:25:09,299 --> 00:25:13,740
when they get out there they just sit on

00:25:10,620 --> 00:25:18,450
the GPU but the process of getting on

00:25:13,740 --> 00:25:21,750
and off constantly is really taxing the

00:25:18,450 --> 00:25:24,510
data processing pipeline and this one we

00:25:21,750 --> 00:25:26,970
get a much greater of return and it's

00:25:24,510 --> 00:25:30,059
simply because of that on/off effect and

00:25:26,970 --> 00:25:33,870
so the plankton algorithm really really

00:25:30,059 --> 00:25:35,760
loved the AC 922 down to where NSF was

00:25:33,870 --> 00:25:39,179
looking at putting this product onto the

00:25:35,760 --> 00:25:41,399
ship because we realized that it went so

00:25:39,179 --> 00:25:44,159
fast that we would actually be able to

00:25:41,399 --> 00:25:47,280
process the data before the ship got

00:25:44,159 --> 00:25:49,649
back to dock in the five days that it

00:25:47,280 --> 00:25:50,400
was traveling and we thought wow that is

00:25:49,649 --> 00:25:52,920
really an

00:25:50,400 --> 00:25:54,030
and MSF is right now in the process of

00:25:52,920 --> 00:25:58,320
thinking about putting this onto the

00:25:54,030 --> 00:26:00,150
ship so as we went forward those were

00:25:58,320 --> 00:26:03,210
your times three minutes versus eight

00:26:00,150 --> 00:26:06,270
minutes and the segmentation side is

00:26:03,210 --> 00:26:09,320
even faster so we got a bout of two acts

00:26:06,270 --> 00:26:12,300
on the segmentation side leading us to

00:26:09,320 --> 00:26:14,220
between a 5 and 8 X speed-up depending

00:26:12,300 --> 00:26:15,330
upon the areas that we go through and

00:26:14,220 --> 00:26:17,309
things like that and that's based upon

00:26:15,330 --> 00:26:18,750
how many things we segmented on one side

00:26:17,309 --> 00:26:20,400
and how many things we classify on the

00:26:18,750 --> 00:26:22,350
other the more things we have to

00:26:20,400 --> 00:26:24,420
classify the better return every single

00:26:22,350 --> 00:26:26,040
time and that's the cost of going on and

00:26:24,420 --> 00:26:27,450
off so we try and get companies to

00:26:26,040 --> 00:26:30,990
realize if you're using GPUs for

00:26:27,450 --> 00:26:32,610
transactional data whoo you better be on

00:26:30,990 --> 00:26:34,140
NAC 9:22 or otherwise you're just

00:26:32,610 --> 00:26:35,460
throwing your money in the trash because

00:26:34,140 --> 00:26:36,960
you could have been doing so many more

00:26:35,460 --> 00:26:39,570
transactions generating so much more

00:26:36,960 --> 00:26:41,910
money on the same piece of hardware on

00:26:39,570 --> 00:26:45,120
the same power footprint doing nothing

00:26:41,910 --> 00:26:48,150
different okay same code on all these

00:26:45,120 --> 00:26:52,140
guys so here's our cost algorithm now

00:26:48,150 --> 00:26:54,780
this demo I really wanted to show what

00:26:52,140 --> 00:26:56,700
the effect was if the if the data went

00:26:54,780 --> 00:26:58,710
directly off of the GPU did not really

00:26:56,700 --> 00:27:01,020
interact on the bus at all so we created

00:26:58,710 --> 00:27:02,130
a very very small data set to a line on

00:27:01,020 --> 00:27:04,800
this one because we had in better

00:27:02,130 --> 00:27:06,210
control and we did this one so that you

00:27:04,800 --> 00:27:08,730
could see that the GPUs were really

00:27:06,210 --> 00:27:14,340
matched and so as we go and we do this

00:27:08,730 --> 00:27:17,250
demo both of them load the data the PCI

00:27:14,340 --> 00:27:18,809
side is still a little bit noisier but

00:27:17,250 --> 00:27:19,830
this shouldn't have any data really

00:27:18,809 --> 00:27:21,960
going through there's really down there

00:27:19,830 --> 00:27:24,030
at zero and they go through at the same

00:27:21,960 --> 00:27:25,860
speed so the GPUs are exactly the same

00:27:24,030 --> 00:27:27,210
and they show that they're exactly the

00:27:25,860 --> 00:27:29,670
same if you can go out then you can do a

00:27:27,210 --> 00:27:32,670
simulation on them you don't need an AC

00:27:29,670 --> 00:27:35,610
9:22 you go back to your x86 box you're

00:27:32,670 --> 00:27:37,710
fine but you have to make sure that your

00:27:35,610 --> 00:27:39,450
work completely sits on the GPU never

00:27:37,710 --> 00:27:43,350
leaves the GPU and never has to interact

00:27:39,450 --> 00:27:45,330
with memory CPU or any i/o if that's the

00:27:43,350 --> 00:27:47,490
case than sure you're fine buying a GPU

00:27:45,330 --> 00:27:51,600
the PCI bus or something along those

00:27:47,490 --> 00:27:53,850
lines of slapping it in so these were

00:27:51,600 --> 00:27:56,100
your times there are exactly the same

00:27:53,850 --> 00:27:58,520
almost every single time they're you

00:27:56,100 --> 00:27:59,630
know a little bit noisy on the PCIe side

00:27:58,520 --> 00:28:01,520
because we had to get on the bus

00:27:59,630 --> 00:28:05,150
initially but they're effectively the

00:28:01,520 --> 00:28:07,880
same statistically okay as we went

00:28:05,150 --> 00:28:13,760
forward I want to show everybody the

00:28:07,880 --> 00:28:17,240
times on the dgx the dgx - it gets a lot

00:28:13,760 --> 00:28:18,650
closer to the AC 920 - but it's cost

00:28:17,240 --> 00:28:20,330
became prohibitive I mean you're looking

00:28:18,650 --> 00:28:22,550
at four hundred thousand dollars for one

00:28:20,330 --> 00:28:24,530
of these things and we buy ac-9 I could

00:28:22,550 --> 00:28:29,030
buy for AC 922 s for a lot less of that

00:28:24,530 --> 00:28:30,560
and so cost for performance is not there

00:28:29,030 --> 00:28:34,640
the other thing that we figured out that

00:28:30,560 --> 00:28:36,590
is the DG acts is so large that if you

00:28:34,640 --> 00:28:37,790
try and get bare metal on it you're

00:28:36,590 --> 00:28:40,040
gonna have a lot of people interacting

00:28:37,790 --> 00:28:42,950
with each other and kind of banging

00:28:40,040 --> 00:28:44,870
against each other whereas the AC 922

00:28:42,950 --> 00:28:47,150
really allowed us to put bare metal to a

00:28:44,870 --> 00:28:48,890
single group and allow them to interact

00:28:47,150 --> 00:28:50,660
on that bare metal by themselves and not

00:28:48,890 --> 00:28:52,040
have to try and leverage the piece of

00:28:50,660 --> 00:28:54,830
equipment it cost multiple groups in

00:28:52,040 --> 00:28:56,090
that case and created a single context

00:28:54,830 --> 00:28:58,280
where I could almost containerize they

00:28:56,090 --> 00:28:59,720
the machines so they were cheaper more

00:28:58,280 --> 00:29:02,600
accessible and more useable to my

00:28:59,720 --> 00:29:04,070
researchers they were also faster the

00:29:02,600 --> 00:29:07,340
last one is if you look over there at

00:29:04,070 --> 00:29:09,290
casa uh-huh casa does a better job with

00:29:07,340 --> 00:29:11,240
taking advantage of the NV link that one

00:29:09,290 --> 00:29:14,900
minute and 14 is the exact same time

00:29:11,240 --> 00:29:16,250
basically that we got on the PCIe bus so

00:29:14,900 --> 00:29:20,450
the end and this was where we actually

00:29:16,250 --> 00:29:24,590
use two GPUs on this and the NV link

00:29:20,450 --> 00:29:27,680
interacts differently okay on the on the

00:29:24,590 --> 00:29:30,920
power side than it does on the dgx and

00:29:27,680 --> 00:29:32,330
so you really didn't see any kind of

00:29:30,920 --> 00:29:35,240
considerable difference because the

00:29:32,330 --> 00:29:38,750
things sat heavily on one GPU anyway on

00:29:35,240 --> 00:29:40,580
the x86 on the dgx but it did drop on

00:29:38,750 --> 00:29:42,410
the power side so we really saw the NV

00:29:40,580 --> 00:29:45,710
link actually work properly on the power

00:29:42,410 --> 00:29:47,090
side and that was important so we

00:29:45,710 --> 00:29:48,230
thought let's put some real numbers

00:29:47,090 --> 00:29:50,180
behind the whole machine

00:29:48,230 --> 00:29:52,190
let's see what's really going on here

00:29:50,180 --> 00:29:54,200
because we saw real speed-up on the CPU

00:29:52,190 --> 00:29:57,440
side and we saw massive speed-up on the

00:29:54,200 --> 00:30:00,290
GPU side and so as we went through we

00:29:57,440 --> 00:30:04,430
started putting numbers to stuff we had

00:30:00,290 --> 00:30:07,850
epic 7600 ones we had Zeon's and we had

00:30:04,430 --> 00:30:09,650
power nines and you know we just started

00:30:07,850 --> 00:30:12,890
racing and having some fun we thought

00:30:09,650 --> 00:30:14,930
take a 3400 mega you know megahertz Z on

00:30:12,890 --> 00:30:16,130
this it was super fast than people loved

00:30:14,930 --> 00:30:18,680
it and they always talked about how much

00:30:16,130 --> 00:30:19,970
they love this machine and I raced it

00:30:18,680 --> 00:30:21,650
against the power nine and I raced

00:30:19,970 --> 00:30:23,060
against the epic 76 that one which is

00:30:21,650 --> 00:30:25,100
another machine that all my people were

00:30:23,060 --> 00:30:26,900
saying all you love this machine and I

00:30:25,100 --> 00:30:28,880
thought okay let's racing so when you

00:30:26,900 --> 00:30:30,800
just did the Fibonacci you could see

00:30:28,880 --> 00:30:31,820
that the power 91 and we were like yeah

00:30:30,800 --> 00:30:33,890
that's what we're seeing we're

00:30:31,820 --> 00:30:35,660
definitely seeing that but we definitely

00:30:33,890 --> 00:30:37,610
saw a different effect was as you thread

00:30:35,660 --> 00:30:41,420
it up by the power time it got a lot

00:30:37,610 --> 00:30:44,660
better okay and so the epic was was

00:30:41,420 --> 00:30:47,210
continually beating the Intel as you

00:30:44,660 --> 00:30:51,590
kept threading up but the power

00:30:47,210 --> 00:30:53,960
destroyed it okay it was amazing to

00:30:51,590 --> 00:30:56,660
watch the power go and my users

00:30:53,960 --> 00:30:58,910
immediately were like wow and started

00:30:56,660 --> 00:31:00,500
buying power boxes and that's one of the

00:30:58,910 --> 00:31:02,150
things that was selling it was the the

00:31:00,500 --> 00:31:05,300
fact that with no code change

00:31:02,150 --> 00:31:07,030
we got a 2x return I mean it was

00:31:05,300 --> 00:31:09,710
basically the same price for the machine

00:31:07,030 --> 00:31:11,450
so that's phenomenal and this is a

00:31:09,710 --> 00:31:13,340
machine without GPUs or this is the

00:31:11,450 --> 00:31:14,870
machine with GPUs we get the same CPUs

00:31:13,340 --> 00:31:17,000
on either side and you can choose to buy

00:31:14,870 --> 00:31:18,800
one with or without so my users could

00:31:17,000 --> 00:31:20,830
buy machines with just CPUs they don't

00:31:18,800 --> 00:31:23,360
need GPS or they can buy it with both

00:31:20,830 --> 00:31:25,940
but then we said ah let's go and do the

00:31:23,360 --> 00:31:28,460
GPUs and let's go do the memory the the

00:31:25,940 --> 00:31:30,190
CPU and the bus unless benchmark these

00:31:28,460 --> 00:31:33,320
this is awesome

00:31:30,190 --> 00:31:35,030
so when you did a benchmarking we I

00:31:33,320 --> 00:31:36,740
tried to identify the total number of

00:31:35,030 --> 00:31:42,260
events that we could do within the same

00:31:36,740 --> 00:31:45,410
amount of time the AC 922 did almost

00:31:42,260 --> 00:31:47,480
three acts faster than the CPU you would

00:31:45,410 --> 00:31:49,430
get on any other box that we'd buy a

00:31:47,480 --> 00:31:51,770
bunch of GPUs on so that machine that

00:31:49,430 --> 00:31:54,140
you saw earlier where we were they were

00:31:51,770 --> 00:31:55,880
both matched to point to s that's this

00:31:54,140 --> 00:31:59,420
box and that's what we were racing here

00:31:55,880 --> 00:32:02,060
and you get a 3x performance increase on

00:31:59,420 --> 00:32:05,960
the CPU side and that's using the exact

00:32:02,060 --> 00:32:08,900
same number of threads now the Intel box

00:32:05,960 --> 00:32:13,850
on this case only comes with I think it

00:32:08,900 --> 00:32:16,250
was 96 threads whereas the power 9 gives

00:32:13,850 --> 00:32:18,350
us a hundred and sixty threads so not

00:32:16,250 --> 00:32:21,350
only did each thread go massive 3x

00:32:18,350 --> 00:32:23,280
faster but I got almost 2x of them and

00:32:21,350 --> 00:32:25,380
that's where you're getting that for

00:32:23,280 --> 00:32:27,120
five X increase on the CPU side if

00:32:25,380 --> 00:32:30,270
you're really going at it it is

00:32:27,120 --> 00:32:32,910
impressive to see as we go down you can

00:32:30,270 --> 00:32:34,770
see that the DG acts and this D G X was

00:32:32,910 --> 00:32:38,730
a two point seven Platinum it's

00:32:34,770 --> 00:32:42,570
brand-new okay it's still three X behind

00:32:38,730 --> 00:32:45,060
on the CPU okay it's just funny to watch

00:32:42,570 --> 00:32:47,070
when you watch the power side finish and

00:32:45,060 --> 00:32:48,780
you're like wow and then you watch the

00:32:47,070 --> 00:32:50,640
dgx still going you're like bummer

00:32:48,780 --> 00:32:55,020
because he spent so much money on this

00:32:50,640 --> 00:32:57,660
thing when we got down to the memory we

00:32:55,020 --> 00:32:59,730
recognized that there was the Intel was

00:32:57,660 --> 00:33:02,970
winning on the memory this was because

00:32:59,730 --> 00:33:06,060
the benchmark we were running was SSE

00:33:02,970 --> 00:33:08,010
and SSE to three enabled and it was able

00:33:06,060 --> 00:33:09,630
to see and take advantage of some memory

00:33:08,010 --> 00:33:11,520
libraries on the Intel side that we do

00:33:09,630 --> 00:33:14,310
not have on the other side and so the

00:33:11,520 --> 00:33:16,080
code itself was focused in on that that

00:33:14,310 --> 00:33:18,600
those memory libraries and so that

00:33:16,080 --> 00:33:19,980
created a slight bias and we were

00:33:18,600 --> 00:33:21,870
looking for benchmarks that don't have

00:33:19,980 --> 00:33:24,060
that but it's hard because we collapsed

00:33:21,870 --> 00:33:25,740
into that x86 world so badly and

00:33:24,060 --> 00:33:27,180
everybody who wants to show benchmarks

00:33:25,740 --> 00:33:30,150
wants to show the best that that thing

00:33:27,180 --> 00:33:33,330
can possibly do and so those libraries

00:33:30,150 --> 00:33:34,680
were interacting but the AC 922 wasn't

00:33:33,330 --> 00:33:36,930
that far behind and we're not heavily

00:33:34,680 --> 00:33:39,630
using memory on these GPU jobs and so

00:33:36,930 --> 00:33:41,970
that's an important feature as we kept

00:33:39,630 --> 00:33:43,890
going down the i/o was the important

00:33:41,970 --> 00:33:46,170
piece to us how are we moving data

00:33:43,890 --> 00:33:47,520
across that bus and how that bus affect

00:33:46,170 --> 00:33:50,250
that and that's what this was about

00:33:47,520 --> 00:33:53,100
so we have two boxes here green and

00:33:50,250 --> 00:33:58,320
orange the green represents the SSDs

00:33:53,100 --> 00:34:00,600
against the PCIe based Intel box and you

00:33:58,320 --> 00:34:02,970
can see that we're basically 3x the i/o

00:34:00,600 --> 00:34:05,640
on that and so that's where we were

00:34:02,970 --> 00:34:08,460
seeing that the change was the 3x of the

00:34:05,640 --> 00:34:09,480
i/o across the bus was massive to us I

00:34:08,460 --> 00:34:11,490
mean when you're talking about 100

00:34:09,480 --> 00:34:14,730
terror a week coming from the ocean I

00:34:11,490 --> 00:34:17,970
got pushed that data across the GPU 3x

00:34:14,730 --> 00:34:22,140
is important as we went down to the ECU

00:34:17,970 --> 00:34:24,480
922 you can see that the nvme is on the

00:34:22,140 --> 00:34:27,500
east 922 are still faster that's the

00:34:24,480 --> 00:34:29,280
copy the copy bus is SuperDuper and

00:34:27,500 --> 00:34:31,860
ultimately we're still getting better

00:34:29,280 --> 00:34:33,570
performance so the the dgx does start to

00:34:31,860 --> 00:34:33,850
catch back up and put us into the sub

00:34:33,570 --> 00:34:35,680
number

00:34:33,850 --> 00:34:37,990
that are closer to what we see on that

00:34:35,680 --> 00:34:39,790
SSD side again but they still aren't

00:34:37,990 --> 00:34:41,080
matching what we can do on the AC 920

00:34:39,790 --> 00:34:43,570
now I would love to be able to expand

00:34:41,080 --> 00:34:46,090
out the nvme capabilities on the AC 922

00:34:43,570 --> 00:34:48,460
that's where the dgx is is winning is

00:34:46,090 --> 00:34:50,980
we're getting more space so we have like

00:34:48,460 --> 00:34:52,240
20-30 tear of nvme versus a smaller

00:34:50,980 --> 00:34:54,910
amount of space and so I think that

00:34:52,240 --> 00:34:55,870
that's your limit on the AC 922 in my

00:34:54,910 --> 00:34:57,760
opinion and that's the thing that's

00:34:55,870 --> 00:35:00,130
upsetting me is that I want to put a

00:34:57,760 --> 00:35:01,840
crapload of nvme on there so that way I

00:35:00,130 --> 00:35:03,220
can use it a scratch based on that local

00:35:01,840 --> 00:35:06,340
box and go like a bat out of hell

00:35:03,220 --> 00:35:07,690
but I'm limited on slots and I'm limited

00:35:06,340 --> 00:35:09,220
because I want to put a hundred gig card

00:35:07,690 --> 00:35:12,220
in there to keep it topped up I've got

00:35:09,220 --> 00:35:13,690
to do some other things and so you know

00:35:12,220 --> 00:35:15,280
we're communicating that but that seems

00:35:13,690 --> 00:35:19,000
to me to be the only limit right now on

00:35:15,280 --> 00:35:20,680
my AC 922 we can we can go to six GPUs

00:35:19,000 --> 00:35:23,350
if I really want to on it but I have to

00:35:20,680 --> 00:35:25,360
liquid cool that's still not a limit to

00:35:23,350 --> 00:35:29,020
me it's a bummer but it's al it's not a

00:35:25,360 --> 00:35:31,270
limit so I feel like the lack of the

00:35:29,020 --> 00:35:33,190
expandability on the nvme is the only

00:35:31,270 --> 00:35:35,560
limit I've found on the AC 922 other

00:35:33,190 --> 00:35:40,450
than that it's it it goes so fast it

00:35:35,560 --> 00:35:43,630
almost wants to take flight okay so you

00:35:40,450 --> 00:35:45,700
know when we were using you know these

00:35:43,630 --> 00:35:48,030
machines we recognize that compiling the

00:35:45,700 --> 00:35:50,140
software was ever so crucial and

00:35:48,030 --> 00:35:52,030
compiling the software to work properly

00:35:50,140 --> 00:35:53,440
on the power nine had to be done

00:35:52,030 --> 00:35:54,970
properly otherwise you didn't see the

00:35:53,440 --> 00:35:56,320
acceleration so we watched a lot of

00:35:54,970 --> 00:35:58,210
people pulling down many kind of

00:35:56,320 --> 00:35:59,260
packages from anaconda which is that an

00:35:58,210 --> 00:36:01,390
old version of tensorflow

00:35:59,260 --> 00:36:03,850
running an old version of CUDA and was

00:36:01,390 --> 00:36:06,400
compiled on the power eight box and you

00:36:03,850 --> 00:36:07,810
didn't get the same return a value that

00:36:06,400 --> 00:36:09,730
you would have gotten if you had sat

00:36:07,810 --> 00:36:11,830
there hand compiled Bazelon hand

00:36:09,730 --> 00:36:13,360
compiled tensorflow and python and all

00:36:11,830 --> 00:36:15,130
these things on the box itself where it

00:36:13,360 --> 00:36:15,610
was recognizing the accelerator and how

00:36:15,130 --> 00:36:19,810
it worked

00:36:15,610 --> 00:36:22,390
and so as we went forward we recognized

00:36:19,810 --> 00:36:26,770
that the a power AI lots of machine

00:36:22,390 --> 00:36:29,200
learning is the tool to overcome this

00:36:26,770 --> 00:36:31,840
problem for us so it actually was able

00:36:29,200 --> 00:36:35,190
to be compiled based upon the

00:36:31,840 --> 00:36:39,310
acceleration created a very very low

00:36:35,190 --> 00:36:41,920
energy for my users to install it and it

00:36:39,310 --> 00:36:44,440
works on both the x86 and the power side

00:36:41,920 --> 00:36:46,220
the same so we can pick out the version

00:36:44,440 --> 00:36:48,080
of tensorflow I want on both side

00:36:46,220 --> 00:36:49,460
it's optimized on both sides I don't

00:36:48,080 --> 00:36:51,920
have to worry about this and I get all

00:36:49,460 --> 00:36:56,420
my speed with no energy and no effort

00:36:51,920 --> 00:36:57,650
and this has been brilliant and so most

00:36:56,420 --> 00:36:59,450
of those algorithms that were running

00:36:57,650 --> 00:37:01,100
tensorflow and those things were running

00:36:59,450 --> 00:37:04,070
lots of machine learning on the back end

00:37:01,100 --> 00:37:05,540
so that way we got the acceleration we

00:37:04,070 --> 00:37:06,710
did have to hand compile some of the

00:37:05,540 --> 00:37:11,330
stuff to make sure that it was getting

00:37:06,710 --> 00:37:12,470
the same speed on the x86 side because

00:37:11,330 --> 00:37:14,540
we want to make sure we weren't getting

00:37:12,470 --> 00:37:16,130
any any bias over there but we got the

00:37:14,540 --> 00:37:19,550
same speed whether I hand compiled on

00:37:16,130 --> 00:37:20,990
the DG x or the PCIe or I used watts of

00:37:19,550 --> 00:37:22,340
machine learning so they clearly went

00:37:20,990 --> 00:37:23,630
through and they spent their time making

00:37:22,340 --> 00:37:26,420
sure it was optimized and getting

00:37:23,630 --> 00:37:27,530
everything done we have a lot of people

00:37:26,420 --> 00:37:29,570
involved in this stuff I have a lot of

00:37:27,530 --> 00:37:30,920
undergrads yes yes these are undergrads

00:37:29,570 --> 00:37:31,970
you wrote these code with us one

00:37:30,920 --> 00:37:34,340
undergrad did each one of those

00:37:31,970 --> 00:37:37,400
algorithms with me we have really

00:37:34,340 --> 00:37:39,980
impressive undergraduates and they go

00:37:37,400 --> 00:37:41,869
out and they get great jobs but you know

00:37:39,980 --> 00:37:43,100
we challenge them we push them really

00:37:41,869 --> 00:37:44,270
hard you know you want to be my

00:37:43,100 --> 00:37:47,810
undergraduate you're gonna have to work

00:37:44,270 --> 00:37:50,600
really super hard I appreciate you guys

00:37:47,810 --> 00:37:51,950
listening that was the gist of it I hope

00:37:50,600 --> 00:37:53,540
you guys understand that there really is

00:37:51,950 --> 00:37:55,190
an architecture dependence depending

00:37:53,540 --> 00:37:59,770
upon where you put your GPU it's not the

00:37:55,190 --> 00:37:59,770
GPU it is the architecture thank you

00:38:14,940 --> 00:38:19,219
coming in the grass on the bottom I

00:38:17,890 --> 00:38:22,890
remember

00:38:19,219 --> 00:38:33,809
let's goodnight okay is it for the cost

00:38:22,890 --> 00:38:38,249
of one this one reading the video when

00:38:33,809 --> 00:38:44,430
you see this video oh you're talking

00:38:38,249 --> 00:38:47,069
about these okay so these are the dial

00:38:44,430 --> 00:38:49,680
is the GPU load okay

00:38:47,069 --> 00:38:53,190
the top one is the GPU memory and the

00:38:49,680 --> 00:38:55,579
bottom plot is the GPU i/o so that's the

00:38:53,190 --> 00:38:55,579
i/o bus

00:39:06,119 --> 00:39:11,740
that is correct that is exactly correct

00:39:09,339 --> 00:39:13,510
that's why we did this is that we got

00:39:11,740 --> 00:39:15,970
people to visually see what was really

00:39:13,510 --> 00:39:17,740
happening and where you're losing it's

00:39:15,970 --> 00:39:19,540
because of the i/o it has nothing to do

00:39:17,740 --> 00:39:21,040
with the GPU it's only i/o and every

00:39:19,540 --> 00:39:22,359
time it has to dip because every single

00:39:21,040 --> 00:39:24,940
time he has to go and interact and

00:39:22,359 --> 00:39:27,069
that's that transactional problem that's

00:39:24,940 --> 00:39:31,559
what that gets expanded so heavily in

00:39:27,069 --> 00:39:31,559
the transactional State so yeah

00:39:42,740 --> 00:39:54,180
but when you were making a banner

00:39:47,780 --> 00:39:55,560
revenue versus so we were on the big GX

00:39:54,180 --> 00:39:58,320
in bare-metal first of all for all those

00:39:55,560 --> 00:39:59,700
tests so I had 16 GPUs accessible to me

00:39:58,320 --> 00:40:01,050
we just limited the number of GPUs for

00:39:59,700 --> 00:40:03,480
the job so that way it was bare metal on

00:40:01,050 --> 00:40:06,270
both of them we do know for a fact

00:40:03,480 --> 00:40:08,640
Charlie and I both know that if you put

00:40:06,270 --> 00:40:11,640
anything into a docker or into a verse

00:40:08,640 --> 00:40:17,730
libvirt you are going to reduce down its

00:40:11,640 --> 00:40:19,950
throughput and so we've shown that so

00:40:17,730 --> 00:40:22,230
like if you take that Casas that came in

00:40:19,950 --> 00:40:23,880
on the AC 920 was perfect it's a minute

00:40:22,230 --> 00:40:25,470
and 14 seconds every single time it's so

00:40:23,880 --> 00:40:31,230
consistent it'll go up to about a minute

00:40:25,470 --> 00:40:32,760
and 25 min and 30 yeah I mean and and

00:40:31,230 --> 00:40:34,200
then when you do env link you don't get

00:40:32,760 --> 00:40:36,840
back the env link when you do it because

00:40:34,200 --> 00:40:38,580
it's confusing which GPU it's on the

00:40:36,840 --> 00:40:41,760
boss and all this kind of stuff and so

00:40:38,580 --> 00:40:43,680
there's a delay in there and so you know

00:40:41,760 --> 00:40:45,720
we can light up multiple GPUs but the

00:40:43,680 --> 00:40:47,610
problem becomes worse and so you tend a

00:40:45,720 --> 00:40:49,890
worse return and so if you really want

00:40:47,610 --> 00:40:51,180
to do env link across two GPUs you

00:40:49,890 --> 00:40:52,830
really want to do it on bare metal as

00:40:51,180 --> 00:40:55,220
what we've seen yeah

00:40:52,830 --> 00:40:57,870
because then you don't have any of these

00:40:55,220 --> 00:40:59,910
maybe that was Nvidia docker by the way

00:40:57,870 --> 00:41:01,320
that was the Nvidia docker yeah you

00:40:59,910 --> 00:41:05,270
don't have any of those downstream

00:41:01,320 --> 00:41:05,270
problems yep that's very true

00:41:17,880 --> 00:41:24,310
what sunshine so when we hand compiled

00:41:21,700 --> 00:41:26,920
everything we were originally doing that

00:41:24,310 --> 00:41:29,110
and then Watson machine learning came

00:41:26,920 --> 00:41:31,600
out basically the exact same so we

00:41:29,110 --> 00:41:34,450
bailed on hand compiling at that point

00:41:31,600 --> 00:41:36,130
cuz it was a pain in the ass and I mean

00:41:34,450 --> 00:41:38,620
it was like you know root canal or

00:41:36,130 --> 00:41:44,200
compiled tensor flow like tether go for

00:41:38,620 --> 00:41:46,060
the root canal so in the end we got the

00:41:44,200 --> 00:41:48,130
basically the exact same time with it

00:41:46,060 --> 00:41:50,320
was powering the island we started and

00:41:48,130 --> 00:41:52,600
we moved over to power yeah our problem

00:41:50,320 --> 00:41:54,460
was versioning we were coming from an

00:41:52,600 --> 00:41:56,710
older version of tensor flow at the time

00:41:54,460 --> 00:41:58,300
and Kiera's and so we just had to do a

00:41:56,710 --> 00:42:00,850
little bit of coding to make sure that

00:41:58,300 --> 00:42:02,920
we met the new tensor flow and that's it

00:42:00,850 --> 00:42:06,690
but yeah we were getting the performance

00:42:02,920 --> 00:42:06,690
so there was no question

00:42:16,119 --> 00:42:21,549
no it's mostly companies yep

00:42:19,150 --> 00:42:23,589
the students I put them over I have an

00:42:21,549 --> 00:42:25,269
entire teaching environment and the

00:42:23,589 --> 00:42:28,029
entire deep learning clubs with me and

00:42:25,269 --> 00:42:29,950
we give them separate equipment so they

00:42:28,029 --> 00:42:32,739
don't interact on that side we don't

00:42:29,950 --> 00:42:33,970
want them to interact with the machines

00:42:32,739 --> 00:42:35,829
that we're trying to present to the

00:42:33,970 --> 00:42:37,809
world to allow other groups to come in

00:42:35,829 --> 00:42:40,390
we were really focused on scientific

00:42:37,809 --> 00:42:42,220
binaries groups who are working with us

00:42:40,390 --> 00:42:44,049
and trying to change the way that

00:42:42,220 --> 00:42:47,410
they're doing computing so we were we

00:42:44,049 --> 00:42:49,749
helped Julia port their code over onto

00:42:47,410 --> 00:42:51,849
the power they still do it in a

00:42:49,749 --> 00:42:53,739
continuous environment what we do is we

00:42:51,849 --> 00:42:55,150
start them on my side and we a lot of

00:42:53,739 --> 00:42:56,980
times we potentially migrate them to

00:42:55,150 --> 00:42:58,180
Lance's site so Lance has the continuous

00:42:56,980 --> 00:43:00,489
and development environment

00:42:58,180 --> 00:43:02,829
he runs the full jenkins and so we let

00:43:00,489 --> 00:43:05,049
them make a decision they get the full

00:43:02,829 --> 00:43:06,519
gamut of opportunity they can pick

00:43:05,049 --> 00:43:08,799
whatever they want they get bare metal

00:43:06,519 --> 00:43:11,349
VMs have root access whatever they want

00:43:08,799 --> 00:43:12,880
they get to choose and then we back off

00:43:11,349 --> 00:43:14,769
and it's a lot of times companies who

00:43:12,880 --> 00:43:16,539
are trying to do video processing things

00:43:14,769 --> 00:43:18,759
like this and they're investigating this

00:43:16,539 --> 00:43:21,190
architecture I'm talking right now with

00:43:18,759 --> 00:43:24,039
David and myriad about testing this on

00:43:21,190 --> 00:43:25,839
that exact same thing and so we are

00:43:24,039 --> 00:43:27,609
really focused in on how companies can

00:43:25,839 --> 00:43:29,410
do it because companies allow us to get

00:43:27,609 --> 00:43:30,999
that code get that hardware and change

00:43:29,410 --> 00:43:32,380
the way we're doing science it really

00:43:30,999 --> 00:43:34,690
does change the scope and remove bias

00:43:32,380 --> 00:43:36,940
the students would give them access to

00:43:34,690 --> 00:43:37,900
the backend so we have our own machines

00:43:36,940 --> 00:43:39,849
that are owned by Oregon State

00:43:37,900 --> 00:43:41,529
University that we've paid for they get

00:43:39,849 --> 00:43:42,940
those machines yep

00:43:41,529 --> 00:43:45,059
with the relationship for those other

00:43:42,940 --> 00:43:50,920
machines is based upon IBM and stuff

00:43:45,059 --> 00:43:54,299
okay anyone else I really appreciate you

00:43:50,920 --> 00:43:54,299
guys coming thank you

00:43:55,140 --> 00:43:57,330

YouTube URL: https://www.youtube.com/watch?v=pkDxW75pAiM


