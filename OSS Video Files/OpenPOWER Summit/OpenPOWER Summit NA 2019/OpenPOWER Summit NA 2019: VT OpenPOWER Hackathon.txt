Title: OpenPOWER Summit NA 2019: VT OpenPOWER Hackathon
Publication date: 2019-08-20
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Robert Settlage, Virginia Tech

In Spring of 2019, Virginia Tech hosted an OpenPOWER Hackathon with the aim of showing users how the PowerAI ecosystem can accelerate AI/DL frameworks with little to no modifications.  Many of the students that signed up for the Hackathon were new to Linux and HPC.  As a limited duration Hackathon with a goal of using the PowerAI toolset, it was important to get new users into the Power system quickly.  Here we will discuss the Open OnDemand platform that allows for creating custom GUIs and portals of entry into HPC systems.  We will show how this system allowed users to focus more on the Hackathon topic and give summaries of the winning projects and acceleration results achieved.
Captions: 
	00:00:00,030 --> 00:00:03,899
okay so this is probably the only

00:00:01,589 --> 00:00:06,150
non-technical talk at this conference as

00:00:03,899 --> 00:00:08,340
far as I can tell and really what we're

00:00:06,150 --> 00:00:10,110
talking about is enabling new users so

00:00:08,340 --> 00:00:13,679
for those of you in the audience that

00:00:10,110 --> 00:00:15,420
are at an educational facility or have

00:00:13,679 --> 00:00:16,770
data scientists that you want to enable

00:00:15,420 --> 00:00:19,439
in a different way this is kind of your

00:00:16,770 --> 00:00:22,980
talk what we're going to talk about

00:00:19,439 --> 00:00:25,199
today is a hackathon that we did in the

00:00:22,980 --> 00:00:26,580
spring we're going to talk through some

00:00:25,199 --> 00:00:28,199
of the format things that we did that

00:00:26,580 --> 00:00:31,980
that were a little bit different and

00:00:28,199 --> 00:00:33,180
then in in in that context I'm going to

00:00:31,980 --> 00:00:33,930
introduce something called open

00:00:33,180 --> 00:00:35,730
on-demand

00:00:33,930 --> 00:00:40,410
to you guys which is really the the

00:00:35,730 --> 00:00:43,469
enabler here so this is the event it's a

00:00:40,410 --> 00:00:47,129
little bit that's my fault but you know

00:00:43,469 --> 00:00:48,899
I guess the the we'll talk about all the

00:00:47,129 --> 00:00:50,129
details here in a few minutes but this

00:00:48,899 --> 00:00:52,829
is something that we ran this last

00:00:50,129 --> 00:00:57,059
spring we had about 52 people register

00:00:52,829 --> 00:01:00,180
and we'll talk about the format and and

00:00:57,059 --> 00:01:01,620
what we did later so this is really I'm

00:01:00,180 --> 00:01:04,379
going to talk kind of fast since we're

00:01:01,620 --> 00:01:05,880
already 10 minutes late but anyhow so

00:01:04,379 --> 00:01:08,340
what what I'm going to do is introduce

00:01:05,880 --> 00:01:11,030
our cat VT for those of you that don't

00:01:08,340 --> 00:01:13,830
know us talk about the the hackathon

00:01:11,030 --> 00:01:15,930
talk a bit about the barriers to HPC is

00:01:13,830 --> 00:01:19,320
I see it introduced something called up

00:01:15,930 --> 00:01:21,720
and on demand which is the enabler that

00:01:19,320 --> 00:01:25,640
I was talking about and then we'll talk

00:01:21,720 --> 00:01:31,650
about some of the the hackathon projects

00:01:25,640 --> 00:01:34,979
so who are Virginia Tech basically we're

00:01:31,650 --> 00:01:38,369
a unit within MIT that is responsible

00:01:34,979 --> 00:01:41,280
for making sure that users at at or

00:01:38,369 --> 00:01:44,220
people at Virginia Tech have access to

00:01:41,280 --> 00:01:48,479
compute appropriate for the size and

00:01:44,220 --> 00:01:50,780
scale of their projects just a little

00:01:48,479 --> 00:01:50,780
bit about

00:01:50,790 --> 00:01:56,830
Blue is engineering were largely an

00:01:54,070 --> 00:01:58,570
engineering University yellow is college

00:01:56,830 --> 00:02:01,030
of science and then we've got sort of

00:01:58,570 --> 00:02:05,490
everybody else and so that that's that's

00:02:01,030 --> 00:02:08,259
what we'll talk about a little bit later

00:02:05,490 --> 00:02:10,210
in terms of what do we have at Virginia

00:02:08,259 --> 00:02:13,750
Tech we have about a thousand total

00:02:10,210 --> 00:02:15,580
nodes of compute most of them are x86

00:02:13,750 --> 00:02:17,220
this is probably the case just about

00:02:15,580 --> 00:02:19,960
everywhere but we have these fourteen

00:02:17,220 --> 00:02:22,090
power8 nodes that have quite a bit of

00:02:19,960 --> 00:02:24,370
power to them and that's really the

00:02:22,090 --> 00:02:29,230
topic of this hackathon is how we use

00:02:24,370 --> 00:02:33,940
that I'm one of scientists within arc

00:02:29,230 --> 00:02:37,350
and my job is really to enable people at

00:02:33,940 --> 00:02:40,240
Tech to use our are our systems

00:02:37,350 --> 00:02:41,950
sometimes that means just showing people

00:02:40,240 --> 00:02:44,500
where to login sometimes that means

00:02:41,950 --> 00:02:47,260
helping people find software sometimes

00:02:44,500 --> 00:02:48,850
that means educating and so hackathons

00:02:47,260 --> 00:02:53,410
kind of fall into that education

00:02:48,850 --> 00:02:56,890
component as I see it so here's the

00:02:53,410 --> 00:03:01,120
event again basically what we did is we

00:02:56,890 --> 00:03:03,820
had a two-week hackathon so we met once

00:03:01,120 --> 00:03:05,799
on a Friday and Cleese came out and gave

00:03:03,820 --> 00:03:07,570
a nice presentation and then we met

00:03:05,799 --> 00:03:10,330
again in two weeks where basically

00:03:07,570 --> 00:03:12,480
people presented their their solutions

00:03:10,330 --> 00:03:16,209
and we'll talk about the solutions later

00:03:12,480 --> 00:03:18,070
the goal was really to accelerate a

00:03:16,209 --> 00:03:21,160
model that was it it was pretty simple

00:03:18,070 --> 00:03:23,769
take something that is on an x86 machine

00:03:21,160 --> 00:03:27,130
for instance and then put it on to power

00:03:23,769 --> 00:03:29,560
and see how how much faster power is and

00:03:27,130 --> 00:03:32,140
so that was really the goal so we made

00:03:29,560 --> 00:03:33,510
it pretty pretty simple because we

00:03:32,140 --> 00:03:37,409
wanted to really

00:03:33,510 --> 00:03:39,120
people to the power ecosystem and many

00:03:37,409 --> 00:03:42,330
of the people weren't very familiar with

00:03:39,120 --> 00:03:46,129
it so that that's that's the goal so

00:03:42,330 --> 00:03:49,590
primary goal of industry optimizing

00:03:46,129 --> 00:03:51,690
training time can impact time the

00:03:49,590 --> 00:03:53,730
results that's kind of obvious and the

00:03:51,690 --> 00:03:55,680
second is sort of what you'd expect from

00:03:53,730 --> 00:03:58,349
a hackathon so bring together students

00:03:55,680 --> 00:04:00,269
from different disciplines and just kind

00:03:58,349 --> 00:04:03,620
of mix them and see what they do so that

00:04:00,269 --> 00:04:03,620
that's kind of the fun part for me

00:04:10,849 --> 00:04:15,750
liberals in this case we're really five

00:04:14,129 --> 00:04:17,579
to ten minute presentations I think they

00:04:15,750 --> 00:04:21,199
all ended up being 15 to 20 but that's

00:04:17,579 --> 00:04:24,720
okay some codes so we have some Python

00:04:21,199 --> 00:04:26,130
duper notebooks and then ultimately what

00:04:24,720 --> 00:04:28,949
we're asking people to do was put

00:04:26,130 --> 00:04:32,160
together white papers that IBM could use

00:04:28,949 --> 00:04:34,169
for or open power I guess could use to

00:04:32,160 --> 00:04:40,440
advertise what can be done with their

00:04:34,169 --> 00:04:44,610
system importantly at Virginia Tech were

00:04:40,440 --> 00:04:47,190
a pretty spread out University so we use

00:04:44,610 --> 00:04:49,289
slack for communication which was pretty

00:04:47,190 --> 00:04:53,599
cool so two things that were cool about

00:04:49,289 --> 00:04:53,599
this one we were able to get the IBM

00:04:53,810 --> 00:04:59,419
developers I guess onto slack so they

00:04:57,060 --> 00:05:01,560
were able to actively answer questions

00:04:59,419 --> 00:05:04,289
the computational scientists were all

00:05:01,560 --> 00:05:07,860
involved but then we also had students

00:05:04,289 --> 00:05:10,740
from different locations within Virginia

00:05:07,860 --> 00:05:13,610
Tech so we're spread out all over the

00:05:10,740 --> 00:05:16,400
state of Virginia and so we had people

00:05:13,610 --> 00:05:21,050
at least an hour away that were

00:05:16,400 --> 00:05:27,510
participating in teams that were I guess

00:05:21,050 --> 00:05:31,560
distributed so that was pretty cool we

00:05:27,510 --> 00:05:33,360
have to evaluate the submissions here's

00:05:31,560 --> 00:05:36,360
the criteria it doesn't really matter

00:05:33,360 --> 00:05:39,780
but really you know what we're trying to

00:05:36,360 --> 00:05:43,080
focus on was how do people use the power

00:05:39,780 --> 00:05:44,020
system and what's the potential impact

00:05:43,080 --> 00:05:47,800
or benefit

00:05:44,020 --> 00:05:49,480
of what they've done creativity was kind

00:05:47,800 --> 00:05:53,250
of the fun part for me to see what kind

00:05:49,480 --> 00:05:56,110
of diverse solutions people put together

00:05:53,250 --> 00:05:58,630
and you know just kind of continuing

00:05:56,110 --> 00:06:00,460
down this we had about 52 people as I

00:05:58,630 --> 00:06:03,370
mentioned we had people from all over

00:06:00,460 --> 00:06:05,590
campus so biology statistics computer

00:06:03,370 --> 00:06:08,440
science engineering medicine even plant

00:06:05,590 --> 00:06:14,020
pathology so we had a very diverse set

00:06:08,440 --> 00:06:15,640
of people joining us many of the people

00:06:14,020 --> 00:06:18,690
when we hold them said that they're

00:06:15,640 --> 00:06:22,660
familiar with a IRB on deep learning

00:06:18,690 --> 00:06:25,360
nobody really said experts okay so what

00:06:22,660 --> 00:06:26,890
that means is that as host to the

00:06:25,360 --> 00:06:30,550
hackathon we have to do something to

00:06:26,890 --> 00:06:34,780
sort of bring these people up and and

00:06:30,550 --> 00:06:39,040
allow them to be creative and be you

00:06:34,780 --> 00:06:45,250
know good participants almost none of

00:06:39,040 --> 00:06:47,080
them had HPC experience okay so thinking

00:06:45,250 --> 00:06:48,970
back to the goal of this hackathon it's

00:06:47,080 --> 00:06:51,340
it's deep learning it's its power AI

00:06:48,970 --> 00:06:55,690
it's that type of stuff it's not teach

00:06:51,340 --> 00:07:01,240
people HPC and so for the couple of

00:06:55,690 --> 00:07:03,250
people here that teach classes you'll

00:07:01,240 --> 00:07:04,720
know that getting people on HPC and

00:07:03,250 --> 00:07:06,280
understanding how to submit jobs and

00:07:04,720 --> 00:07:09,850
that type of stuff can be a pretty

00:07:06,280 --> 00:07:12,520
arduous task okay so for instance many

00:07:09,850 --> 00:07:15,400
of the people in biology or plant

00:07:12,520 --> 00:07:17,770
pathology might not live at the command

00:07:15,400 --> 00:07:21,090
line they're in the lab right so we need

00:07:17,770 --> 00:07:24,100
to figure out how to enable them to

00:07:21,090 --> 00:07:31,590
participate without spending all of our

00:07:24,100 --> 00:07:31,590
time teaching them Linux and HPC so

00:07:32,480 --> 00:07:37,220
you know hardware is really not our

00:07:33,650 --> 00:07:38,240
issue it's really accessing use and in

00:07:37,220 --> 00:07:41,050
my opinion these are largely

00:07:38,240 --> 00:07:43,100
self-imposed so thinking about the blue

00:07:41,050 --> 00:07:45,140
part of the curve over there those are

00:07:43,100 --> 00:07:46,910
engineers there they're good to go you

00:07:45,140 --> 00:07:50,840
know most of them have already been

00:07:46,910 --> 00:07:52,790
taught SSH and command-line access and

00:07:50,840 --> 00:07:54,170
Linux and that type of stuff we're

00:07:52,790 --> 00:07:57,650
really speaking to the other half that

00:07:54,170 --> 00:07:59,510
are more focusing on how do they perform

00:07:57,650 --> 00:08:02,810
experience what are they doing in the

00:07:59,510 --> 00:08:04,340
lab and that type of stuff so barriers

00:08:02,810 --> 00:08:07,190
you know how do you get into the system

00:08:04,340 --> 00:08:09,890
traditionally it's a safer software how

00:08:07,190 --> 00:08:12,440
do you install software you know there's

00:08:09,890 --> 00:08:14,510
no root access so software installs are

00:08:12,440 --> 00:08:17,570
often hard people aren't familiar with

00:08:14,510 --> 00:08:21,950
modules which is how we handle our our

00:08:17,570 --> 00:08:25,310
software on dark systems the data is not

00:08:21,950 --> 00:08:29,320
in our systems to start with so you know

00:08:25,310 --> 00:08:31,910
we have to teach people FTP SCP etc

00:08:29,320 --> 00:08:34,010
script writing is not a native tongue

00:08:31,910 --> 00:08:35,690
for many people so you know something

00:08:34,010 --> 00:08:37,610
needs to be done there and then job

00:08:35,690 --> 00:08:39,580
scheduling people aren't familiar in

00:08:37,610 --> 00:08:41,870
some of these disciplines with

00:08:39,580 --> 00:08:47,210
scheduling jobs you know you press run

00:08:41,870 --> 00:08:49,700
and it just kind of goes so this is

00:08:47,210 --> 00:08:53,360
where open on demand comes in so open on

00:08:49,700 --> 00:08:58,550
demand is really a system for accessing

00:08:53,360 --> 00:09:00,470
HPC through web-based GUI so what's cool

00:08:58,550 --> 00:09:01,880
is what we're doing is we're exposing

00:09:00,470 --> 00:09:04,670
our systems through tools that people

00:09:01,880 --> 00:09:08,540
already know so it's a plugin free web

00:09:04,670 --> 00:09:11,390
experience like meaning that you just

00:09:08,540 --> 00:09:13,820
open a web browser and it works we're

00:09:11,390 --> 00:09:16,580
gonna provide file management

00:09:13,820 --> 00:09:18,650
a way to get into the command line

00:09:16,580 --> 00:09:23,120
that's a little easier than installing

00:09:18,650 --> 00:09:27,560
putty or you know Moab or whatever a

00:09:23,120 --> 00:09:30,610
wave to look at jobs and then some

00:09:27,560 --> 00:09:35,920
graphical environments for people to

00:09:30,610 --> 00:09:41,710
sort of look at what they're doing so

00:09:35,920 --> 00:09:41,710
out of the box what do you get basically

00:09:42,640 --> 00:09:48,110
some sort landing page that you can

00:09:44,780 --> 00:09:50,210
customize to the site's liking so I'm

00:09:48,110 --> 00:09:54,530
showing you the Ohio super computer

00:09:50,210 --> 00:09:55,130
centers landing page ours looks

00:09:54,530 --> 00:09:56,840
different

00:09:55,130 --> 00:09:58,550
there's the files app there's a job

00:09:56,840 --> 00:10:02,300
composer app and there's a jump job

00:09:58,550 --> 00:10:04,010
monitor those are the basic things going

00:10:02,300 --> 00:10:06,740
through them sort of one at a time just

00:10:04,010 --> 00:10:09,220
real quick files app basically looks

00:10:06,740 --> 00:10:14,060
like what you'd expect from a web-based

00:10:09,220 --> 00:10:17,510
files manager so what's cool here is

00:10:14,060 --> 00:10:21,860
that basically we don't have to SC at

00:10:17,510 --> 00:10:26,420
least sort of medium is files so we can

00:10:21,860 --> 00:10:31,270
just drag and drop we're beyond SCP were

00:10:26,420 --> 00:10:31,270
beyond FTP for many people this is great

00:10:32,050 --> 00:10:37,940
incidentally the last thing there is

00:10:35,270 --> 00:10:39,710
pretty important you know there's

00:10:37,940 --> 00:10:43,940
there's a lot of people that'll write

00:10:39,710 --> 00:10:46,760
down in their scripts RM minus RF and

00:10:43,940 --> 00:10:49,580
maybe there's a star in there true

00:10:46,760 --> 00:10:52,580
stories one of our bigger users just did

00:10:49,580 --> 00:10:54,640
that and lost 50 terabytes of data right

00:10:52,580 --> 00:10:57,890
before we're migrating to a new storage

00:10:54,640 --> 00:10:58,970
system so that's not all that from my

00:10:57,890 --> 00:11:01,300
perspective but

00:10:58,970 --> 00:11:04,149
[Music]

00:11:01,300 --> 00:11:07,050
you know I mean this this this is a big

00:11:04,149 --> 00:11:09,580
deal so for many people command-line

00:11:07,050 --> 00:11:11,769
manipulation of files is completely new

00:11:09,580 --> 00:11:14,019
okay and so having some way for people

00:11:11,769 --> 00:11:20,140
to play with files in a more familiar

00:11:14,019 --> 00:11:22,360
way is is important a pretty common

00:11:20,140 --> 00:11:24,970
workflow for many people is going to be

00:11:22,360 --> 00:11:27,430
to start a job well first you have to

00:11:24,970 --> 00:11:29,380
write a script then you submit a job

00:11:27,430 --> 00:11:32,740
then you see that it's running and then

00:11:29,380 --> 00:11:34,750
you get the results back we can we can

00:11:32,740 --> 00:11:36,640
put a GUI around that that's what we've

00:11:34,750 --> 00:11:38,589
done here this is the job composer app

00:11:36,640 --> 00:11:43,329
we're not going to focus on that today

00:11:38,589 --> 00:11:45,040
but this this is a pretty cool tool this

00:11:43,329 --> 00:11:48,610
is the thing that I want to bring people

00:11:45,040 --> 00:11:52,420
to so we can extend that the interface

00:11:48,610 --> 00:11:56,740
so we can write what are called apps

00:11:52,420 --> 00:11:58,240
that are custom around various things

00:11:56,740 --> 00:12:01,510
that you might want to do so for

00:11:58,240 --> 00:12:05,829
instance Jupiter notebooks which is what

00:12:01,510 --> 00:12:08,620
we're going to use in the hackathon we

00:12:05,829 --> 00:12:10,690
one of the the way to get a jupiter

00:12:08,620 --> 00:12:14,500
notebook on our systems is submit a job

00:12:10,690 --> 00:12:16,990
create some sort of SSH tunnel open up

00:12:14,500 --> 00:12:19,270
Jupiter notebook and you know hit it on

00:12:16,990 --> 00:12:22,360
your browser for someone that's not

00:12:19,270 --> 00:12:25,810
familiar with HPC setting up tunnels and

00:12:22,360 --> 00:12:27,970
that type of stuff is like you know so

00:12:25,810 --> 00:12:29,890
we need some better way to do that same

00:12:27,970 --> 00:12:34,660
goes for MATLAB traditionally we don't

00:12:29,890 --> 00:12:37,810
have GUI type systems on our on our

00:12:34,660 --> 00:12:40,990
compute nodes for for security reasons

00:12:37,810 --> 00:12:45,699
but we can abstract some of the starting

00:12:40,990 --> 00:12:50,370
of some of these these gooeys and allow

00:12:45,699 --> 00:12:50,370
some of these various apps to run

00:12:52,350 --> 00:12:57,990
so it is pretty easy to facilitate or to

00:12:55,550 --> 00:13:00,389
to extend and write these apps the

00:12:57,990 --> 00:13:05,759
documentation is really really well

00:13:00,389 --> 00:13:08,249
built out and developing APS's is pretty

00:13:05,759 --> 00:13:10,740
fast and easy so here's here's a list of

00:13:08,249 --> 00:13:12,990
apps that I put together and about a day

00:13:10,740 --> 00:13:19,980
I guess there's some ice templates

00:13:12,990 --> 00:13:23,670
online so you know coming back to where

00:13:19,980 --> 00:13:25,860
we're going here so one of the things

00:13:23,670 --> 00:13:28,920
that my group is responsible for is

00:13:25,860 --> 00:13:32,249
going out and teaching like intro to HPC

00:13:28,920 --> 00:13:35,399
okay oftentimes we'll do that in a

00:13:32,249 --> 00:13:39,019
classroom setting and we'll go into you

00:13:35,399 --> 00:13:42,119
know a group of 30 to 50 students and

00:13:39,019 --> 00:13:44,970
we'll spend probably 40 minutes trying

00:13:42,119 --> 00:13:46,259
to get people to install putty or you

00:13:44,970 --> 00:13:49,379
know whatever you know they're

00:13:46,259 --> 00:13:55,019
platform-specific shell client is and

00:13:49,379 --> 00:13:57,389
then get ssh into into the clusters what

00:13:55,019 --> 00:13:59,999
we're doing here with open on-demand is

00:13:57,389 --> 00:14:01,920
we're authenticating people into the

00:13:59,999 --> 00:14:04,589
browser so that's kind of done we know

00:14:01,920 --> 00:14:07,079
who they are and then they simply click

00:14:04,589 --> 00:14:11,160
on a little button that opens up the

00:14:07,079 --> 00:14:13,139
show so we've taken what did take you

00:14:11,160 --> 00:14:16,619
know 40 minutes for a class to less than

00:14:13,139 --> 00:14:17,730
15 minutes or so so in other words we

00:14:16,619 --> 00:14:20,220
have more time to actually talk about

00:14:17,730 --> 00:14:25,459
compute versus just get into the damn

00:14:20,220 --> 00:14:25,459
system so pretty radical idea

00:14:25,649 --> 00:14:33,600
for us what we want it wanted to do was

00:14:29,620 --> 00:14:37,540
really get them into not necessarily the

00:14:33,600 --> 00:14:40,560
Michele app but rather into some

00:14:37,540 --> 00:14:45,010
environments more specific to the IBM

00:14:40,560 --> 00:14:47,410
ecosystems to the power AI tools side so

00:14:45,010 --> 00:14:49,390
we had about 50 participants we had

00:14:47,410 --> 00:14:51,459
about 2 weeks so we could have spent a

00:14:49,390 --> 00:14:55,079
lot of time you know teaching HPC and

00:14:51,459 --> 00:14:57,670
stuff instead what we wanted to do was

00:14:55,079 --> 00:15:03,760
use open on-demand is really the portal

00:14:57,670 --> 00:15:11,920
to get into the system so what we did is

00:15:03,760 --> 00:15:15,640
we created a by default loaded the power

00:15:11,920 --> 00:15:18,670
AI toolset so users click on a little

00:15:15,640 --> 00:15:20,769
button loads the Jupiter notebook pops

00:15:18,670 --> 00:15:23,350
up in their browser and it has the

00:15:20,769 --> 00:15:27,269
environment all set up so in basically

00:15:23,350 --> 00:15:32,260
one click users are into power AI a

00:15:27,269 --> 00:15:36,220
power a icon environment tensorflow is

00:15:32,260 --> 00:15:37,690
kind of the same way so you know I'd say

00:15:36,220 --> 00:15:40,649
for probably three months when we got

00:15:37,690 --> 00:15:44,290
the power AI system up and running

00:15:40,649 --> 00:15:48,520
people would often come into our offices

00:15:44,290 --> 00:15:49,660
and and and you know kind of spend a

00:15:48,520 --> 00:15:53,279
bunch of time trying to figure out how

00:15:49,660 --> 00:15:56,529
to get tensor the tensor board working

00:15:53,279 --> 00:15:59,050
so what we've done here is it's now just

00:15:56,529 --> 00:16:01,450
an app all you do is you specify the

00:15:59,050 --> 00:16:04,089
directory where your tensor flow logs

00:16:01,450 --> 00:16:06,970
are and you you know start the app and

00:16:04,089 --> 00:16:10,079
it pops up the the tensor board so

00:16:06,970 --> 00:16:10,079
pretty pretty nice

00:16:13,959 --> 00:16:21,800
so any time you give users or students I

00:16:19,160 --> 00:16:24,500
guess a chance to be creative they'll

00:16:21,800 --> 00:16:26,600
take it the first thing that we did is

00:16:24,500 --> 00:16:29,779
we said well create yourself some teams

00:16:26,600 --> 00:16:31,220
and give yourself a team name and so you

00:16:29,779 --> 00:16:35,480
can see some of the fun ones that came

00:16:31,220 --> 00:16:37,579
up here I was I was expecting ganna

00:16:35,480 --> 00:16:40,100
stand to be here one of the ones that he

00:16:37,579 --> 00:16:43,339
really liked is the Chennai Super Kings

00:16:40,100 --> 00:16:46,459
I guess it's some sort of cricket team

00:16:43,339 --> 00:16:50,410
and need to hear something but anyhow um

00:16:46,459 --> 00:16:53,899
kind of fun so to the hackathon we had

00:16:50,410 --> 00:16:56,149
basically three finalists teams and I

00:16:53,899 --> 00:16:58,810
wanted to just show you quickly the

00:16:56,149 --> 00:17:01,490
solutions that they they came up with

00:16:58,810 --> 00:17:05,150
these solutions were very diverse in

00:17:01,490 --> 00:17:08,569
terms of topics so we went from game

00:17:05,150 --> 00:17:12,530
iocked game AI to cell type

00:17:08,569 --> 00:17:15,679
classification and then Gans for

00:17:12,530 --> 00:17:19,370
creating datasets in CFD and so when we

00:17:15,679 --> 00:17:21,559
go through those here in C so the first

00:17:19,370 --> 00:17:25,189
team like a Gauss turns out that one of

00:17:21,559 --> 00:17:29,330
the two members is in our School of

00:17:25,189 --> 00:17:32,660
Medicine and he works in a in an NMR or

00:17:29,330 --> 00:17:34,760
mr MRI lab and so that's where the name

00:17:32,660 --> 00:17:38,390
comes from I guess but anyhow they were

00:17:34,760 --> 00:17:41,299
interested they were brand new to deep

00:17:38,390 --> 00:17:42,710
learning okay so for whatever reason

00:17:41,299 --> 00:17:45,530
they were really interested in

00:17:42,710 --> 00:17:48,020
reinforcement learning their particular

00:17:45,530 --> 00:17:50,929
app was pong you know not not that

00:17:48,020 --> 00:17:54,740
difficult but Elon in this particular

00:17:50,929 --> 00:17:58,640
case was was interested more in terms of

00:17:54,740 --> 00:18:01,160
what he could do in image processing and

00:17:58,640 --> 00:18:03,230
varan was more interested in terms of

00:18:01,160 --> 00:18:06,549
what he could do with reinforcement

00:18:03,230 --> 00:18:09,169
learning and for robot manipulation

00:18:06,549 --> 00:18:10,790
diverse things but they they kind of

00:18:09,169 --> 00:18:12,380
came together around this project here

00:18:10,790 --> 00:18:14,419
so what they're gonna do is they're

00:18:12,380 --> 00:18:17,190
going to take this actor critic

00:18:14,419 --> 00:18:18,960
algorithm that's traditionally CPU

00:18:17,190 --> 00:18:21,210
they're gonna port it to where they're

00:18:18,960 --> 00:18:27,059
they're just showing acceleration on a

00:18:21,210 --> 00:18:30,299
GPU version of that so what does power

00:18:27,059 --> 00:18:32,789
AI get them so the scale is a little bit

00:18:30,299 --> 00:18:40,229
blurry but in the in the in the first

00:18:32,789 --> 00:18:48,229
case we're getting to it's pretty

00:18:40,229 --> 00:18:51,090
dramatic improvement the second team is

00:18:48,229 --> 00:18:54,149
they came out of the by biological

00:18:51,090 --> 00:18:57,539
sciences and they were interested in

00:18:54,149 --> 00:19:01,129
something completely different so their

00:18:57,539 --> 00:19:04,559
application is around DNA sequencing

00:19:01,129 --> 00:19:07,229
specifically in tumors is what we're

00:19:04,559 --> 00:19:11,029
their interest was and what they're

00:19:07,229 --> 00:19:11,029
wanting to do is translate show that

00:19:18,320 --> 00:19:24,840
you're sequencing single cells you can

00:19:21,989 --> 00:19:29,879
use the DNA profiles or RNA profiles in

00:19:24,840 --> 00:19:33,509
this case to determine which cell type

00:19:29,879 --> 00:19:36,149
that is so for instance if you if you

00:19:33,509 --> 00:19:37,440
get a tissue biopsy there's probably

00:19:36,149 --> 00:19:39,359
going to be some normal cells in there

00:19:37,440 --> 00:19:43,019
there's gonna be some cancerous cells in

00:19:39,359 --> 00:19:45,509
there can you use the RNA profile

00:19:43,019 --> 00:19:47,519
signature to determine which of those

00:19:45,509 --> 00:19:51,840
two it is first before you do any other

00:19:47,519 --> 00:19:54,720
analysis so there they're using a pretty

00:19:51,840 --> 00:19:57,479
complex algorithm this is called the

00:19:54,720 --> 00:20:00,119
Siamese neural network or basically

00:19:57,479 --> 00:20:03,059
they're taking two samples through the

00:20:00,119 --> 00:20:05,549
network at the same time and through

00:20:03,059 --> 00:20:11,549
some mechanisms I'm not sure I really

00:20:05,549 --> 00:20:13,679
understand they kind of mix the mix the

00:20:11,549 --> 00:20:15,869
the the results from the networks and

00:20:13,679 --> 00:20:18,570
then come out with sort of a mixed

00:20:15,869 --> 00:20:19,070
signal at the end and so they run them

00:20:18,570 --> 00:20:21,830
through

00:20:19,070 --> 00:20:23,179
so from the person suitcases I'm showing

00:20:21,830 --> 00:20:25,519
positive pairs or they're showing

00:20:23,179 --> 00:20:27,610
positive in the second case it's and

00:20:25,519 --> 00:20:30,230
they get in pairs so in other words the

00:20:27,610 --> 00:20:35,860
cell types are the same or they're

00:20:30,230 --> 00:20:40,039
different in their case they had a

00:20:35,860 --> 00:20:45,019
problem in that their data was so large

00:20:40,039 --> 00:20:46,759
they could not run even even a

00:20:45,019 --> 00:20:50,149
significant portion of their data

00:20:46,759 --> 00:20:53,899
through a chi pu at the at one time so

00:20:50,149 --> 00:20:57,139
what they were really looking at is how

00:20:53,899 --> 00:20:58,940
can they speed this up do using some

00:20:57,139 --> 00:21:01,399
sort of distributed learning okay so

00:20:58,940 --> 00:21:03,169
they they want to take their data spread

00:21:01,399 --> 00:21:06,980
it over multiple GPUs and push it

00:21:03,169 --> 00:21:12,200
through faster and then look at the

00:21:06,980 --> 00:21:24,529
accuracy their results were basically

00:21:12,200 --> 00:21:27,789
what you would expect it's in the farc

00:21:24,529 --> 00:21:30,409
set of histograms it's a constant

00:21:27,789 --> 00:21:33,950
accuracy when they change to a different

00:21:30,409 --> 00:21:38,809
network so the siamese our network you

00:21:33,950 --> 00:21:41,000
can see that they sort of what they

00:21:38,809 --> 00:21:42,919
would use traditionally interestingly

00:21:41,000 --> 00:21:45,889
enough as they scaled two more GPUs

00:21:42,919 --> 00:21:48,409
accuracy went down I don't think they

00:21:45,889 --> 00:21:50,120
understand what that is and then these

00:21:48,409 --> 00:21:54,110
curves here are really sort of training

00:21:50,120 --> 00:21:58,460
time as they scale to multiple nodes and

00:21:54,110 --> 00:22:00,049
GPUs and so as you would hope the

00:21:58,460 --> 00:22:03,440
training time goes down as you scale

00:22:00,049 --> 00:22:08,210
across more and more nodes and GPUs it's

00:22:03,440 --> 00:22:10,990
not linear and you know I think they got

00:22:08,210 --> 00:22:10,990
what they hoped for

00:22:11,879 --> 00:22:20,830
so the last application is Ganz for CFD

00:22:17,470 --> 00:22:33,669
so what these these guys are out of our

00:22:20,830 --> 00:22:36,940
engineering department across the way as

00:22:33,669 --> 00:22:40,090
you might imagine getting these datasets

00:22:36,940 --> 00:22:43,419
is pretty expensive and so if there's a

00:22:40,090 --> 00:22:48,070
way for them to generate datasets that

00:22:43,419 --> 00:22:53,950
would be advantageous if they could you

00:22:48,070 --> 00:22:55,240
know use that to augment data so I'm not

00:22:53,950 --> 00:22:56,740
going to go through this but you know

00:22:55,240 --> 00:22:58,360
basically they've got a loss function at

00:22:56,740 --> 00:23:00,399
the bottom that's really what what you

00:22:58,360 --> 00:23:02,980
what you need to do some sort of deep

00:23:00,399 --> 00:23:05,200
learning algorithm is you've got a loss

00:23:02,980 --> 00:23:08,200
to measure how good you did so you can

00:23:05,200 --> 00:23:09,759
do some updates what they're doing is

00:23:08,200 --> 00:23:15,690
their programming in the physics right

00:23:09,759 --> 00:23:15,690
so if you've you've got some data or

00:23:21,090 --> 00:23:29,549
sort of a generator and a discriminator

00:23:23,679 --> 00:23:31,690
and they're gonna maximize the

00:23:29,549 --> 00:23:34,210
discriminators power but they're gonna

00:23:31,690 --> 00:23:41,049
minimize the generators loss as

00:23:34,210 --> 00:23:43,119
effectively the way it goes so all the

00:23:41,049 --> 00:23:46,360
stuff is being is in a white paper that

00:23:43,119 --> 00:23:47,769
will I guess post so you know I don't

00:23:46,360 --> 00:23:51,220
need to go through this but you know

00:23:47,769 --> 00:23:54,960
here's another sort of way to think

00:23:51,220 --> 00:23:56,889
about this they've got the physical

00:23:54,960 --> 00:23:59,350
equations here and they've got

00:23:56,889 --> 00:24:03,929
constraints and they can set that up and

00:23:59,350 --> 00:24:03,929
use this in this generative fashion

00:24:06,360 --> 00:24:12,750
sort of early on what what they were

00:24:09,480 --> 00:24:16,350
showing us is how well they're generated

00:24:12,750 --> 00:24:24,000
data looks compared to what their actual

00:24:16,350 --> 00:24:27,480
data looks like so what they're showing

00:24:24,000 --> 00:24:29,490
is that the generated data starts to

00:24:27,480 --> 00:24:34,200
look more and more like actual data and

00:24:29,490 --> 00:24:35,519
that's what you would hope in our

00:24:34,200 --> 00:24:38,070
particular case they had a lot of

00:24:35,519 --> 00:24:42,840
parameters that they were interested in

00:24:38,070 --> 00:24:44,519
exploring so you know I don't need to go

00:24:42,840 --> 00:24:46,200
through it all here but you know they

00:24:44,519 --> 00:24:48,860
have a pretty complex system that

00:24:46,200 --> 00:24:51,679
they're they're they're playing with

00:24:48,860 --> 00:24:54,830
they have a lot of considerations

00:24:51,679 --> 00:25:00,559
probably the biggest here for them was

00:24:54,830 --> 00:25:04,200
scalability which pretty quickly gets to

00:25:00,559 --> 00:25:05,519
they've got multiple neural network so I

00:25:04,200 --> 00:25:14,929
mean at the same time and they need to

00:25:05,519 --> 00:25:17,789
talk across ultimately nodes measures of

00:25:14,929 --> 00:25:20,039
convergence and their little note here

00:25:17,789 --> 00:25:23,490
is that their divergence is their

00:25:20,039 --> 00:25:27,240
convergence metric but what they're

00:25:23,490 --> 00:25:30,720
really looking for is the gans are

00:25:27,240 --> 00:25:34,200
inherently difficult to get to train and

00:25:30,720 --> 00:25:36,480
converge and so you know how long does

00:25:34,200 --> 00:25:41,940
it take and how many nodes and GPUs can

00:25:36,480 --> 00:25:44,309
they use to get to trained networks at

00:25:41,940 --> 00:25:48,000
the end of the day we get to here which

00:25:44,309 --> 00:25:49,740
is basically using the power AI system

00:25:48,000 --> 00:25:53,309
or the power aid systems with power AI

00:25:49,740 --> 00:25:54,990
to to get their models to converge and

00:25:53,309 --> 00:25:58,309
looking at the training times for the

00:25:54,990 --> 00:26:01,320
different numbers of GPUs they have this

00:25:58,309 --> 00:26:05,190
the red and the blue bars are really

00:26:01,320 --> 00:26:09,750
using GPUs on the same node versus intra

00:26:05,190 --> 00:26:13,990
node and controlling or I guess shifting

00:26:09,750 --> 00:26:17,289
who the controlling GPU is there's

00:26:13,990 --> 00:26:20,799
on the project so really just to

00:26:17,289 --> 00:26:23,080
summarize you know we we we put together

00:26:20,799 --> 00:26:25,120
this hackathon it's its target was

00:26:23,080 --> 00:26:29,740
really people that were new to our

00:26:25,120 --> 00:26:32,470
system we had a really different way

00:26:29,740 --> 00:26:36,070
that to do this in that we spread this

00:26:32,470 --> 00:26:37,330
out over time okay so this wasn't a you

00:26:36,070 --> 00:26:40,630
know 24 or 48 hour

00:26:37,330 --> 00:26:43,899
sprint it was really get intimate with

00:26:40,630 --> 00:26:45,990
the system over a couple of weeks we use

00:26:43,899 --> 00:26:49,270
some communication tools to really help

00:26:45,990 --> 00:26:52,870
both us support them and then to

00:26:49,270 --> 00:26:56,799
communicate we used open on demand

00:26:52,870 --> 00:26:59,830
really to level the playing fields to

00:26:56,799 --> 00:27:02,830
make it a little bit easier for new

00:26:59,830 --> 00:27:06,390
users to use our systems so they got up

00:27:02,830 --> 00:27:09,640
to speed faster and then ultimately our

00:27:06,390 --> 00:27:12,070
our our topic was bring your own model

00:27:09,640 --> 00:27:15,309
and just show that it accelerates which

00:27:12,070 --> 00:27:18,039
I think allowed for more different types

00:27:15,309 --> 00:27:22,440
of models across many different fields

00:27:18,039 --> 00:27:26,399
which was really cool and that's it

00:27:22,440 --> 00:27:26,399
thoughts or questions yeah

00:27:34,210 --> 00:27:48,890
yeah which shell and what was the

00:27:37,220 --> 00:27:51,290
technology forgetting you know it is not

00:27:48,890 --> 00:27:54,140
a Java applet and I I don't know which

00:27:51,290 --> 00:27:59,120
shell that they use but I can get the

00:27:54,140 --> 00:28:05,980
answer to you yeah sorry is it yeah do

00:27:59,120 --> 00:28:05,980
you guys do you guys use upon yeah I

00:28:08,470 --> 00:28:13,970
don't we've had this going for well I

00:28:12,830 --> 00:28:17,350
guess since the beginning of the year

00:28:13,970 --> 00:28:17,350
and we have not seen that as an issue

00:28:25,930 --> 00:28:33,590
yeah we are to factor and we didn't have

00:28:31,760 --> 00:28:40,230
any issues with that

00:28:33,590 --> 00:28:51,510
we're on version one for we are

00:28:40,230 --> 00:28:51,510
hmm I'm not sure it's IB

00:29:01,820 --> 00:29:04,660
No

00:29:05,660 --> 00:29:10,890
yeah and their their data set size was

00:29:08,850 --> 00:29:25,080
so you're thinking specifically the bio

00:29:10,890 --> 00:29:47,460
app CFD they were using MPI and this was

00:29:25,080 --> 00:29:49,140
the power version of MPI yeah no I mean

00:29:47,460 --> 00:29:52,050
we should probably have them redo this

00:29:49,140 --> 00:29:55,050
because I guess it's been about a month

00:29:52,050 --> 00:29:57,720
or so ago one of our computational

00:29:55,050 --> 00:30:00,000
scientists put a lot of effort into MPI

00:29:57,720 --> 00:30:02,700
and specifically getting MV pitch

00:30:00,000 --> 00:30:05,210
compiled right on our systems this might

00:30:02,700 --> 00:30:05,210
be changed

00:30:09,200 --> 00:30:17,100
this was this was openmpi is probably

00:30:14,490 --> 00:30:19,250
three but I'd have to you know as the

00:30:17,100 --> 00:30:24,570
version that comes that ships with the

00:30:19,250 --> 00:30:30,179
this was power AI 1.6 so you know that

00:30:24,570 --> 00:30:32,809
comes with an MPI you know this was

00:30:30,179 --> 00:30:32,809
community edition

00:30:37,810 --> 00:30:41,580
okay thank you very much

00:30:42,270 --> 00:30:46,650

YouTube URL: https://www.youtube.com/watch?v=sqMkMkB_uDU


