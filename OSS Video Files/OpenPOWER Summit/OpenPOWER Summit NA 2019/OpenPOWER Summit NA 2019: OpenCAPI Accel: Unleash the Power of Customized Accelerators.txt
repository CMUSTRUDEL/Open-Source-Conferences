Title: OpenPOWER Summit NA 2019: OpenCAPI Accel: Unleash the Power of Customized Accelerators
Publication date: 2019-08-20
Playlist: OpenPOWER Summit NA 2019
Description: 
	Presented by Yong Lu, IBM

OpenCAPI Acceleration Framework, abbreviated as OC-Accel, is a platform to enable programmers and computer engineers to quickly create FPGA-based accelerations. The acceleration action's software part and hardware part share the server host memory data through OpenCAPI interface. With it, people can quickly design an accelerator and benefit from the bandwidth, latency, coherency and programmability advantages of OpenCAPI.
Captions: 
	00:00:00,030 --> 00:00:06,540
hi everyone I'm very glad he stand here

00:00:03,659 --> 00:00:11,759
and presents the open KP acceleration

00:00:06,540 --> 00:00:14,070
framework to you okay so actually I

00:00:11,759 --> 00:00:18,150
believe a lot of people here had already

00:00:14,070 --> 00:00:23,100
heard KP snap which was the acceleration

00:00:18,150 --> 00:00:25,109
framework for KP 1.0 and 2.0 and it

00:00:23,100 --> 00:00:28,699
provides a quite conveniently

00:00:25,109 --> 00:00:32,279
environment through parts algorithms and

00:00:28,699 --> 00:00:35,550
computation to FPGA and today I'm going

00:00:32,279 --> 00:00:41,190
to take open KP acceleration work here

00:00:35,550 --> 00:00:44,910
and introduce the details about it okay

00:00:41,190 --> 00:00:49,530
so today my contents including the basic

00:00:44,910 --> 00:00:53,789
fpga acceleration paradigms the contents

00:00:49,530 --> 00:00:56,370
the components and workflow and our

00:00:53,789 --> 00:00:58,739
testing result how about the framework

00:00:56,370 --> 00:01:01,410
bandwidth and latency you will be

00:00:58,739 --> 00:01:04,739
interested in that and the last one is

00:01:01,410 --> 00:01:08,729
some examples to fully utilize open

00:01:04,739 --> 00:01:14,670
heavy acceleration framework so first

00:01:08,729 --> 00:01:18,210
because you know 4/9 has emphasized his

00:01:14,670 --> 00:01:22,380
eye or capability to connect all the

00:01:18,210 --> 00:01:26,130
computing components of FPGA and GPU so

00:01:22,380 --> 00:01:30,780
today the open happy is really a hot

00:01:26,130 --> 00:01:37,650
topic and the VR sees that it makes the

00:01:30,780 --> 00:01:42,390
FPGA or ASIC accelerator to be placed to

00:01:37,650 --> 00:01:45,990
the parallel place like CPU cores so you

00:01:42,390 --> 00:01:50,970
can call that FPGA accelerator as

00:01:45,990 --> 00:01:53,340
another hit her generous processor and I

00:01:50,970 --> 00:01:56,159
want to mention one point is that in

00:01:53,340 --> 00:01:59,969
last presentation Dmitry had introduced

00:01:56,159 --> 00:02:04,290
the c1 mode and annual mode and here I

00:01:59,969 --> 00:02:06,960
will say that the open KP acceleration

00:02:04,290 --> 00:02:10,379
framework actually focused on c1 mode

00:02:06,960 --> 00:02:13,380
that means of the transactions are

00:02:10,379 --> 00:02:18,060
initiated from the accelerator

00:02:13,380 --> 00:02:21,540
so the FPGA side is the master it will

00:02:18,060 --> 00:02:26,130
send the transaction commands IVs

00:02:21,540 --> 00:02:28,610
virtual address and this this command

00:02:26,130 --> 00:02:31,950
server goes through open Cappy links and

00:02:28,610 --> 00:02:36,050
arrived at unsaved coherent inter

00:02:31,950 --> 00:02:38,550
connection sometimes we call that nest

00:02:36,050 --> 00:02:42,600
okay and after the virtual address

00:02:38,550 --> 00:02:46,320
arrived so the power processor will look

00:02:42,600 --> 00:02:50,150
after the data in its cache subsystem

00:02:46,320 --> 00:02:52,890
and so this is the coherent access and

00:02:50,150 --> 00:02:55,560
sometimes finally it has go through the

00:02:52,890 --> 00:02:56,280
external local memory so that's the

00:02:55,560 --> 00:03:01,020
whole story

00:02:56,280 --> 00:03:08,700
of open KP snack open Kevin stack for

00:03:01,020 --> 00:03:12,270
our acceleration framework okay so today

00:03:08,700 --> 00:03:16,590
I want to mention that for acceleration

00:03:12,270 --> 00:03:19,320
we should focus from two aspects the

00:03:16,590 --> 00:03:24,660
first one is to offload the CPU

00:03:19,320 --> 00:03:29,670
computation so traditional we execute

00:03:24,660 --> 00:03:32,520
all the functions with CPU based

00:03:29,670 --> 00:03:37,200
software and we when we move the

00:03:32,520 --> 00:03:41,040
computation to FPGA card actually we are

00:03:37,200 --> 00:03:43,110
utilized the capability of FPGA

00:03:41,040 --> 00:03:46,890
resources that includes the

00:03:43,110 --> 00:03:50,190
combinational logic and also the

00:03:46,890 --> 00:03:52,950
memories and all kinds of things you

00:03:50,190 --> 00:03:55,890
should pay attention to the instruction

00:03:52,950 --> 00:04:00,350
complexity that means in one cycle you

00:03:55,890 --> 00:04:04,140
can do a particular job with some

00:04:00,350 --> 00:04:07,800
complicated steps so not like CPU

00:04:04,140 --> 00:04:11,100
instruction actually FPGA uses the gates

00:04:07,800 --> 00:04:15,270
and circuits to for fear function and

00:04:11,100 --> 00:04:18,959
another important thing is to utilize

00:04:15,270 --> 00:04:21,830
the parallely parallelism that means you

00:04:18,959 --> 00:04:25,020
must you keep multiple engines and

00:04:21,830 --> 00:04:27,270
finally tune the pipeline between the

00:04:25,020 --> 00:04:30,629
data dependency so in

00:04:27,270 --> 00:04:34,319
that case you can get the computation

00:04:30,629 --> 00:04:37,560
get accelerated on a VGA card so this is

00:04:34,319 --> 00:04:41,069
the first paradigm and the second one is

00:04:37,560 --> 00:04:47,580
to explore FPGA is I all capabilities

00:04:41,069 --> 00:04:51,900
that means we can move data ingress and

00:04:47,580 --> 00:04:56,220
out rest so we today a physic cars can

00:04:51,900 --> 00:05:00,030
be designed based on customer requests

00:04:56,220 --> 00:05:03,620
and you can design any external

00:05:00,030 --> 00:05:08,280
interfaces as you want so for example

00:05:03,620 --> 00:05:12,780
you can have the interface this is an

00:05:08,280 --> 00:05:16,409
DME connection to i/o sorry to the

00:05:12,780 --> 00:05:21,150
hard-disk or the storage and the Bulow's

00:05:16,409 --> 00:05:24,930
picture is the connection to Ethernet so

00:05:21,150 --> 00:05:27,690
for different ivj cards you can have the

00:05:24,930 --> 00:05:30,930
different connections that means if your

00:05:27,690 --> 00:05:33,719
source data is located in hard disk or

00:05:30,930 --> 00:05:37,009
in memory you don't need to use

00:05:33,719 --> 00:05:40,770
additional hard disk driver or

00:05:37,009 --> 00:05:44,370
additional user net hard to move data to

00:05:40,770 --> 00:05:45,930
host first you can directly use the FPGA

00:05:44,370 --> 00:05:49,370
to catch the data and doing a

00:05:45,930 --> 00:05:55,919
computation and standard the results and

00:05:49,370 --> 00:06:00,360
exchange the data with host CPU all

00:05:55,919 --> 00:06:03,169
right so let's look closer into the open

00:06:00,360 --> 00:06:08,130
heavy acceleration framework

00:06:03,169 --> 00:06:12,860
so first is okay it's abbreviation is OC

00:06:08,130 --> 00:06:16,919
x there so from the left side it is the

00:06:12,860 --> 00:06:20,099
software running on hosted server it had

00:06:16,919 --> 00:06:23,610
so people can write software programs as

00:06:20,099 --> 00:06:28,590
they want and actually a lot of people

00:06:23,610 --> 00:06:33,870
have done a lot of work to to explode to

00:06:28,590 --> 00:06:37,830
opera like levers and we have oh snap

00:06:33,870 --> 00:06:40,770
library and this is a user user space

00:06:37,830 --> 00:06:45,660
library and it talks to live OC excel

00:06:40,770 --> 00:06:48,780
and later lower it is oceaxe it is a

00:06:45,660 --> 00:06:51,979
kernel module and it has already been

00:06:48,780 --> 00:06:53,130
included in most of linux dispute

00:06:51,979 --> 00:06:59,360
distributions

00:06:53,130 --> 00:07:04,169
today on the right side it is Hardware

00:06:59,360 --> 00:07:08,940
FPGA part so we have a open Cathy - AXI

00:07:04,169 --> 00:07:12,660
bridge which will converts the open kpp

00:07:08,940 --> 00:07:18,210
our exit ERX to two interfaces the first

00:07:12,660 --> 00:07:21,050
one is a xi4 light in this case the the

00:07:18,210 --> 00:07:24,930
hardware action which is the logic part

00:07:21,050 --> 00:07:30,960
owned by the developers or by the users

00:07:24,930 --> 00:07:33,780
this is this part is a slave and and the

00:07:30,960 --> 00:07:36,990
next to the main data part is this here

00:07:33,780 --> 00:07:41,669
it is an active memory mapped interface

00:07:36,990 --> 00:07:44,460
and here the hardware action is a master

00:07:41,669 --> 00:07:48,539
and it uses virtual address to access

00:07:44,460 --> 00:07:53,310
host a memory and you can also expand

00:07:48,539 --> 00:07:58,830
your connections to this FPGA cards

00:07:53,310 --> 00:08:01,860
external iOS for example we have DDR

00:07:58,830 --> 00:08:04,320
memory controller we can also have nvme

00:08:01,860 --> 00:08:05,969
controller here and we have Ethernet

00:08:04,320 --> 00:08:10,460
controller here

00:08:05,969 --> 00:08:14,580
so as you wish and you can expand it

00:08:10,460 --> 00:08:18,690
alright so the next thing is about the

00:08:14,580 --> 00:08:22,020
open KP bought Support Package so if you

00:08:18,690 --> 00:08:25,169
have a new card you want to design a

00:08:22,020 --> 00:08:28,169
specific card and you want to claim that

00:08:25,169 --> 00:08:32,700
your card is supported in open KP

00:08:28,169 --> 00:08:35,490
acceleration framework you can you can

00:08:32,700 --> 00:08:39,630
bring the details into the support

00:08:35,490 --> 00:08:41,729
support package so today it's already

00:08:39,630 --> 00:08:44,670
supposed effort eight or nine is three

00:08:41,729 --> 00:08:47,550
card and quickly in our pipeline we are

00:08:44,670 --> 00:08:49,470
going to support the Arthur tater nine

00:08:47,550 --> 00:08:54,270
age seven and

00:08:49,470 --> 00:08:56,600
beet vera and 250 SOC and so on you just

00:08:54,270 --> 00:09:00,120
need to provide the constraint fires

00:08:56,600 --> 00:09:03,570
some particular very log fires for your

00:09:00,120 --> 00:09:10,400
top design and also some specific ideas

00:09:03,570 --> 00:09:13,920
that you are going to use alright so

00:09:10,400 --> 00:09:17,130
this is the main workflow for all the

00:09:13,920 --> 00:09:19,490
heavy acceleration framework so it is

00:09:17,130 --> 00:09:25,110
more like an integrated development

00:09:19,490 --> 00:09:29,190
environment ide okay so we have we have

00:09:25,110 --> 00:09:32,820
optimized social steps to be integrated

00:09:29,190 --> 00:09:36,480
in one pass on script it is cards to

00:09:32,820 --> 00:09:39,030
network flow so after preparing the

00:09:36,480 --> 00:09:41,940
environment you have two options to

00:09:39,030 --> 00:09:46,470
write to the hardware part so either

00:09:41,940 --> 00:09:51,210
oh sorry so you have to write the

00:09:46,470 --> 00:09:54,870
application running on CPU you also have

00:09:51,210 --> 00:09:57,630
to design your acceleration on hardware

00:09:54,870 --> 00:09:59,520
you have two options here one is to

00:09:57,630 --> 00:10:05,460
write the Verilog design and the other

00:09:59,520 --> 00:10:07,410
is to use hrs C++ so after the after

00:10:05,460 --> 00:10:10,820
posts the software parts and the

00:10:07,410 --> 00:10:13,950
hardware part are ready we came to some

00:10:10,820 --> 00:10:18,500
co-stimulation this is an important step

00:10:13,950 --> 00:10:24,180
to guarantee that your your work can

00:10:18,500 --> 00:10:28,800
work really before you go to test is

00:10:24,180 --> 00:10:30,660
unreal hardware so basically if you have

00:10:28,800 --> 00:10:31,800
passed the code simulation you have

00:10:30,660 --> 00:10:37,500
solved

00:10:31,800 --> 00:10:42,120
95% of correctness or I should say

00:10:37,500 --> 00:10:45,510
functional logic so the next thing is to

00:10:42,120 --> 00:10:50,160
build RPG image and in this step you

00:10:45,510 --> 00:10:54,500
need to take care of the the timing the

00:10:50,160 --> 00:10:58,920
place and route so after a PG image is

00:10:54,500 --> 00:11:04,579
is ready you can deploy the application

00:10:58,920 --> 00:11:08,220
side and the image 2 / 9 server

00:11:04,579 --> 00:11:11,730
okay so here I will spend several

00:11:08,220 --> 00:11:14,730
minutes to describe the options for for

00:11:11,730 --> 00:11:22,069
the hardware development so if you are a

00:11:14,730 --> 00:11:25,740
very large developer we have in improved

00:11:22,069 --> 00:11:30,569
XE memory memory mapped master interface

00:11:25,740 --> 00:11:33,959
so compared to the original snap 4k p1

00:11:30,569 --> 00:11:39,449
dot o and a2 dot o it supports new

00:11:33,959 --> 00:11:42,079
features ok and it's it even as a

00:11:39,449 --> 00:11:45,779
protocol interface monitor on this pot

00:11:42,079 --> 00:11:50,449
so that means that means it can check

00:11:45,779 --> 00:11:56,579
your AXI transactions track if they are

00:11:50,449 --> 00:12:01,290
comply complying with the protocol so

00:11:56,579 --> 00:12:04,939
let's see the the AXI features here

00:12:01,290 --> 00:12:08,879
so first the address they are the same

00:12:04,939 --> 00:12:14,269
64 bits effective address and for the

00:12:08,879 --> 00:12:19,139
data the oceaxe era has increased from 5

00:12:14,269 --> 00:12:21,600
512 bits to 1,024 ok

00:12:19,139 --> 00:12:28,709
and for the past size that means the

00:12:21,600 --> 00:12:31,589
data path sighs so when 1024 means 128

00:12:28,709 --> 00:12:35,009
bytes we support all kinds of narrow

00:12:31,589 --> 00:12:38,550
sized transfers I think that may benefit

00:12:35,009 --> 00:12:42,839
for the apart narrow or something ok so

00:12:38,550 --> 00:12:45,990
we support all kinds from one bytes but

00:12:42,839 --> 00:12:49,009
previously it's not only supposed 64

00:12:45,990 --> 00:12:53,069
bytes that is the full size of database

00:12:49,009 --> 00:12:55,829
ok and the persons we didn't change that

00:12:53,069 --> 00:13:00,300
it is the same and for the person mode

00:12:55,829 --> 00:13:04,620
we also added a fixed type ok so we also

00:13:00,300 --> 00:13:09,990
support writes tube we also support of 5

00:13:04,620 --> 00:13:14,670
v piece of ax e IDs that means 32 IDs so

00:13:09,990 --> 00:13:16,380
so that means if you have 32 engines you

00:13:14,670 --> 00:13:20,460
don't need to change anything

00:13:16,380 --> 00:13:24,630
and you can get multiple engines working

00:13:20,460 --> 00:13:28,410
and each one use a different ID we also

00:13:24,630 --> 00:13:32,870
we also support multiple processes to

00:13:28,410 --> 00:13:36,720
access the the FPGA hardware so we

00:13:32,870 --> 00:13:40,980
currently we support five and a twerp

00:13:36,720 --> 00:13:43,230
has IDs that means process process

00:13:40,980 --> 00:13:51,000
context that's the number of process

00:13:43,230 --> 00:13:55,460
contest alright so if you are c++ hrs

00:13:51,000 --> 00:14:00,930
developer so things quite easy to start

00:13:55,460 --> 00:14:04,130
so in this this page you just pay

00:14:00,930 --> 00:14:10,370
attention to this function this is the

00:14:04,130 --> 00:14:14,130
entrance it has one two three four four

00:14:10,370 --> 00:14:18,120
arguments and the first one TMG mmm

00:14:14,130 --> 00:14:22,290
the out g mmm it's simply mapped to this

00:14:18,120 --> 00:14:25,620
master interface okay so you actually

00:14:22,290 --> 00:14:29,070
they just look like two theta arrays you

00:14:25,620 --> 00:14:34,260
can use your 64 bits virtual address to

00:14:29,070 --> 00:14:37,770
in taxes are raised okay and this DD DD

00:14:34,260 --> 00:14:44,420
art mam method to this part

00:14:37,770 --> 00:14:44,420
it's can talk to the memory and hard and

00:14:44,900 --> 00:14:51,810
so action register it is it's a slave

00:14:48,450 --> 00:14:55,800
pod it can catch the the control

00:14:51,810 --> 00:14:59,400
information and the status information

00:14:55,800 --> 00:15:05,250
and the talk test rule the I'm Emma I oh

00:14:59,400 --> 00:15:09,330
yeah yeah okay so yeah these pictures

00:15:05,250 --> 00:15:11,960
shows OCSE so how do we run a similar

00:15:09,330 --> 00:15:17,220
software and hardware co-simulation

00:15:11,960 --> 00:15:19,860
actually we will start at least three

00:15:17,220 --> 00:15:23,520
processes and our development

00:15:19,860 --> 00:15:28,110
environment so the first one is to start

00:15:23,520 --> 00:15:29,850
the simulator currently we support the

00:15:28,110 --> 00:15:32,790
cadence simulator

00:15:29,850 --> 00:15:38,490
and also the building lovato simulator

00:15:32,790 --> 00:15:41,940
and OCS the you look look at it it looks

00:15:38,490 --> 00:15:46,290
like a bridge actually on the software

00:15:41,940 --> 00:15:50,760
side it'll provides OCSE version of Lib

00:15:46,290 --> 00:15:53,490
OC excel and talk to software and on the

00:15:50,760 --> 00:15:57,000
right side it provides a very long AF

00:15:53,490 --> 00:16:02,100
you driver to directly track drive the

00:15:57,000 --> 00:16:07,500
TRX to AF you interface so for this as

00:16:02,100 --> 00:16:10,560
the second process of sorry as the

00:16:07,500 --> 00:16:14,040
second process it is OCLC and the third

00:16:10,560 --> 00:16:17,610
process is your application you can run

00:16:14,040 --> 00:16:21,720
your application anytime just like

00:16:17,610 --> 00:16:25,620
running on real power 9 hardware and you

00:16:21,720 --> 00:16:28,950
you can track the simulation result and

00:16:25,620 --> 00:16:36,840
and it makes sure that the results are

00:16:28,950 --> 00:16:39,870
correct okay so we also make gather of

00:16:36,840 --> 00:16:43,440
the documentation and the support

00:16:39,870 --> 00:16:47,490
message a website a static Maps website

00:16:43,440 --> 00:16:52,140
it has it has the user guide part and

00:16:47,490 --> 00:16:54,150
also some examples and also some if you

00:16:52,140 --> 00:16:56,340
want to learn more about this

00:16:54,150 --> 00:17:01,380
acceleration framework you can go to

00:16:56,340 --> 00:17:05,579
this deep dive tab alright so here is

00:17:01,380 --> 00:17:09,449
the bandwidth result of today's oceaxe

00:17:05,579 --> 00:17:13,770
there so you will see if you move data

00:17:09,449 --> 00:17:17,310
from hosted to FPGA that means F here is

00:17:13,770 --> 00:17:20,040
better ok the bandwidth is about twenty

00:17:17,310 --> 00:17:23,970
one point six gigabytes per second and

00:17:20,040 --> 00:17:27,360
if you move data from apt to host that

00:17:23,970 --> 00:17:34,880
means IPG writes something and the

00:17:27,360 --> 00:17:38,640
pelvis is similar and if you if I PGA

00:17:34,880 --> 00:17:41,610
sends read and write requests at the

00:17:38,640 --> 00:17:43,260
same time this is the duplex case we can

00:17:41,610 --> 00:17:49,770
get posts at our

00:17:43,260 --> 00:17:54,600
out 18 18 gigabytes per second so next

00:17:49,770 --> 00:17:59,520
is the latency so we measure latency in

00:17:54,600 --> 00:18:03,570
this way here on the master part it will

00:17:59,520 --> 00:18:07,860
send a taxi commands so we measure when

00:18:03,570 --> 00:18:10,320
we send the AXI address and the actually

00:18:07,860 --> 00:18:14,340
address actually their goals its parts

00:18:10,320 --> 00:18:17,880
and to get cata date her for breed okay

00:18:14,340 --> 00:18:21,600
yeah and come back and this is the read

00:18:17,880 --> 00:18:25,530
data so from standard read address to

00:18:21,600 --> 00:18:30,420
get read the data this so the average

00:18:25,530 --> 00:18:32,940
leave in need of 495 nanoseconds and for

00:18:30,420 --> 00:18:38,250
the right for the writes it is a little

00:18:32,940 --> 00:18:40,560
shorter at about 450 by the way this

00:18:38,250 --> 00:18:44,510
latency number can be even shorter

00:18:40,560 --> 00:18:49,460
because currently our snap car runs at

00:18:44,510 --> 00:18:54,390
200 megahertz and it can if we can

00:18:49,460 --> 00:18:57,900
enhance that to 300 or even 400 the

00:18:54,390 --> 00:19:05,670
latency number can be around 400 nano

00:18:57,900 --> 00:19:09,390
seconds okay so so in the following page

00:19:05,670 --> 00:19:12,810
I will try to introduce some examples

00:19:09,390 --> 00:19:16,650
especially for the developers what we

00:19:12,810 --> 00:19:19,860
can consider to fully utilize this open

00:19:16,650 --> 00:19:24,150
heavy acceleration framework so the main

00:19:19,860 --> 00:19:27,060
idea comes from actually that from heavy

00:19:24,150 --> 00:19:30,480
one turtle it has the idea of shared

00:19:27,060 --> 00:19:37,320
memory so that means the software thread

00:19:30,480 --> 00:19:40,350
can can set some work elements and it

00:19:37,320 --> 00:19:44,130
can execute the software tasks and

00:19:40,350 --> 00:19:48,690
attract status and access any address at

00:19:44,130 --> 00:19:51,240
any time and IV T's side it gets the

00:19:48,690 --> 00:19:53,920
work elements and to hardware

00:19:51,240 --> 00:19:57,250
computation and it can

00:19:53,920 --> 00:20:01,270
address at any time within the same

00:19:57,250 --> 00:20:02,530
contest okay so they are talking in the

00:20:01,270 --> 00:20:08,340
same contest

00:20:02,530 --> 00:20:12,160
process contest so the first idea is

00:20:08,340 --> 00:20:15,670
this open happy acceleration framework

00:20:12,160 --> 00:20:19,810
actually you can try to accelerate more

00:20:15,670 --> 00:20:22,930
and the smaller functions basically you

00:20:19,810 --> 00:20:26,440
know we can do profiling this is a part

00:20:22,930 --> 00:20:27,790
of the diagram we did a profiling for H

00:20:26,440 --> 00:20:32,070
dot 264

00:20:27,790 --> 00:20:35,470
video encoder it is very big diagram and

00:20:32,070 --> 00:20:38,410
we can pick up and we can look at the

00:20:35,470 --> 00:20:43,480
numbers and find out the hottest spot

00:20:38,410 --> 00:20:46,030
functions and you can identify the the

00:20:43,480 --> 00:20:50,560
input arguments and the output arguments

00:20:46,030 --> 00:20:54,840
and use the acceleration framework to do

00:20:50,560 --> 00:20:58,210
some so it doesn't have to be a very big

00:20:54,840 --> 00:21:03,880
function even some smaller functions it

00:20:58,210 --> 00:21:07,300
can get accelerated the second idea is

00:21:03,880 --> 00:21:10,150
about scattered memory access actually

00:21:07,300 --> 00:21:15,220
we have already seen a lot of benefits

00:21:10,150 --> 00:21:20,680
from this side this idea so for for a

00:21:15,220 --> 00:21:23,920
traditional pcie-based apt acceleration

00:21:20,680 --> 00:21:27,340
you need to have device driver and you'd

00:21:23,920 --> 00:21:30,940
better to gather all the data you need

00:21:27,340 --> 00:21:35,310
by software and through a data block and

00:21:30,940 --> 00:21:38,200
then you are supposed DMA to to make a

00:21:35,310 --> 00:21:41,200
transaction of a big amount of data to

00:21:38,200 --> 00:21:45,040
APG that is the most efficient way in

00:21:41,200 --> 00:21:49,570
this in this scenario but this caviar

00:21:45,040 --> 00:21:53,020
open copy we can just send the address

00:21:49,570 --> 00:21:55,390
or the least handle pointer which it

00:21:53,020 --> 00:21:59,320
doesn't need a pointer so equity and

00:21:55,390 --> 00:22:03,700
equity can read can read the scattered

00:21:59,320 --> 00:22:07,300
memory directly this address so you know

00:22:03,700 --> 00:22:09,850
today a lot of software

00:22:07,300 --> 00:22:16,360
actually they have very completed data

00:22:09,850 --> 00:22:19,600
structures like lists or graphs so the

00:22:16,360 --> 00:22:22,720
traditional the DMF a actually is not

00:22:19,600 --> 00:22:25,800
very good as that but Kathy and open

00:22:22,720 --> 00:22:25,800
have he can make that happen

00:22:26,580 --> 00:22:34,690
so the third idea is asking software and

00:22:31,210 --> 00:22:36,280
hardware to working together so in the

00:22:34,690 --> 00:22:40,600
light left diagram

00:22:36,280 --> 00:22:44,470
so in this case a pj just doing some

00:22:40,600 --> 00:22:46,360
offloading so because we don't have a

00:22:44,470 --> 00:22:50,890
device driver running in the background

00:22:46,360 --> 00:22:52,630
so in this case the utilization of cpu

00:22:50,890 --> 00:22:56,920
is very very low

00:22:52,630 --> 00:23:01,270
it is usually a one or two percent of

00:22:56,920 --> 00:23:04,510
CPU time so if you at that time it can

00:23:01,270 --> 00:23:07,050
be used to two other tasks or you can

00:23:04,510 --> 00:23:11,890
carefully design the software and

00:23:07,050 --> 00:23:16,300
hardware cooperation so as with them to

00:23:11,890 --> 00:23:19,120
running in pipeline so and you know

00:23:16,300 --> 00:23:22,300
because our overhead is shorter so you

00:23:19,120 --> 00:23:28,360
you don't lose a lot of things during

00:23:22,300 --> 00:23:32,410
the interconnection the interaction okay

00:23:28,360 --> 00:23:37,420
and the first example is about moving

00:23:32,410 --> 00:23:38,080
later between GPU and fvg will everyone

00:23:37,420 --> 00:23:43,660
knows that

00:23:38,080 --> 00:23:46,890
Poorna also has only link and actually

00:23:43,660 --> 00:23:52,030
today we are using GPU to do a lot of

00:23:46,890 --> 00:23:55,150
fancy computation but in some cases the

00:23:52,030 --> 00:23:58,180
GPU also needs some pre-processing and

00:23:55,150 --> 00:24:00,520
post-processing for that for the for

00:23:58,180 --> 00:24:05,230
example for the video of for the images

00:24:00,520 --> 00:24:07,750
and in this case a PDA can work with key

00:24:05,230 --> 00:24:10,860
field together and the best thing is

00:24:07,750 --> 00:24:13,990
that they can share the unified memory

00:24:10,860 --> 00:24:16,480
IPTA use open heavy interface and if you

00:24:13,990 --> 00:24:18,820
use a milling interface it is very

00:24:16,480 --> 00:24:20,050
convenient and we already have an

00:24:18,820 --> 00:24:27,580
example run

00:24:20,050 --> 00:24:31,210
this way so the the fifth example is

00:24:27,580 --> 00:24:36,690
about the Ethernet acceleration

00:24:31,210 --> 00:24:40,450
you know because today we have a matched

00:24:36,690 --> 00:24:45,370
bandwidth so for the Ethernet if you use

00:24:40,450 --> 00:24:48,280
to 1 gigabit PPS is a NAT IP it is

00:24:45,370 --> 00:24:59,770
exactly identical to the oven happy

00:24:48,280 --> 00:25:03,550
bandwidth alright so what's more next

00:24:59,770 --> 00:25:04,930
season we are also developed working on

00:25:03,550 --> 00:25:09,130
load EMA

00:25:04,930 --> 00:25:10,830
so this one is trying to help you parts

00:25:09,130 --> 00:25:14,650
that you can see steam pcie-based

00:25:10,830 --> 00:25:17,260
accelerator to open happy so each of

00:25:14,650 --> 00:25:20,830
their provides the exactly same

00:25:17,260 --> 00:25:24,370
interface like styling surround time and

00:25:20,830 --> 00:25:28,750
the sidings XD ma so actually it has a

00:25:24,370 --> 00:25:32,980
job manager here and it very in in

00:25:28,750 --> 00:25:37,300
Hobart interpret the job descriptors and

00:25:32,980 --> 00:25:40,720
move data for you so it'll provides to

00:25:37,300 --> 00:25:44,620
actually light interfaces and several

00:25:40,720 --> 00:25:48,960
channels of AXI data ports and it can

00:25:44,620 --> 00:25:48,960
either be memory mapped or stream like

00:25:49,560 --> 00:26:00,670
ok so that is all for my today's

00:25:54,610 --> 00:26:03,550
presentation and you should try to fully

00:26:00,670 --> 00:26:06,990
utilize this open Cathy acceleration

00:26:03,550 --> 00:26:11,040
work these the global memory sharing and

00:26:06,990 --> 00:26:14,350
open and easy development developing and

00:26:11,040 --> 00:26:18,270
the good throughput because today

00:26:14,350 --> 00:26:20,680
actually today it is the the biggest

00:26:18,270 --> 00:26:26,750
throughput around the world in the world

00:26:20,680 --> 00:26:29,880
and the latency okay so yeah

00:26:26,750 --> 00:26:29,880
[Applause]

00:26:33,840 --> 00:27:17,890
and your questions mm-hmm yeah yes so if

00:27:14,710 --> 00:27:23,290
I understand your question correctly it

00:27:17,890 --> 00:27:31,059
it means oh I didn't prepare that chart

00:27:23,290 --> 00:27:32,740
but you know hrs can synthesize AXI for

00:27:31,059 --> 00:27:36,520
interfaces okay

00:27:32,740 --> 00:27:39,610
so you give it a directive and tell him

00:27:36,520 --> 00:27:43,150
that this part I want to exceed four

00:27:39,610 --> 00:27:44,440
part so it it can synthesize that for

00:27:43,150 --> 00:27:48,309
you automatically

00:27:44,440 --> 00:27:52,090
yeah and it'll provide a memory array

00:27:48,309 --> 00:27:57,549
model so if you want to catheter you

00:27:52,090 --> 00:28:00,040
just say array in tax I give you the in

00:27:57,549 --> 00:28:03,790
tax and I catch the data if I want to

00:28:00,040 --> 00:28:07,020
store data I just say memory in tax and

00:28:03,790 --> 00:28:07,020
you can start the data

00:28:13,580 --> 00:28:34,860
yes yeah exactly you know we we didn't

00:28:31,350 --> 00:28:37,560
change that because for the kepi one

00:28:34,860 --> 00:28:41,370
auto and a2 dot how it is it is like

00:28:37,560 --> 00:28:46,470
that because we want to keep the old

00:28:41,370 --> 00:28:49,170
actions developing snap still can work

00:28:46,470 --> 00:28:52,860
our open cavity acceleration also we

00:28:49,170 --> 00:28:53,610
didn't change that actually we have some

00:28:52,860 --> 00:28:58,350
backup

00:28:53,610 --> 00:29:05,400
I want to show you that is okay but it

00:28:58,350 --> 00:29:08,730
is true it does have theta this mismatch

00:29:05,400 --> 00:29:11,460
you know the original one is five and

00:29:08,730 --> 00:29:15,060
twelve so video automatically insert

00:29:11,460 --> 00:29:18,420
exit abyss converter to do the job so

00:29:15,060 --> 00:29:22,050
you can if you have some old snap

00:29:18,420 --> 00:29:25,370
accelerators you can move to the new one

00:29:22,050 --> 00:29:25,370
without any efforts

00:29:27,780 --> 00:29:36,320
hey okay

00:29:57,690 --> 00:30:07,240
actually today they use the data logs

00:30:01,030 --> 00:30:13,860
and actually oh so you are talking about

00:30:07,240 --> 00:30:24,669
amo we we haven't implemented a you know

00:30:13,860 --> 00:30:27,460
atomic right so actually we have red

00:30:24,669 --> 00:30:30,570
flag and a right flag it it acts like a

00:30:27,460 --> 00:30:30,570
status exchange

00:31:10,350 --> 00:31:31,050
[Music]

00:31:13,010 --> 00:31:33,720
okay okay so if you want to catch the

00:31:31,050 --> 00:31:37,050
personal latency you should guarantee

00:31:33,720 --> 00:31:41,550
that the data is in the cache you buy in

00:31:37,050 --> 00:31:44,850
initialized allocated memory otherwise

00:31:41,550 --> 00:31:47,400
yeah it takes a longer time but that's

00:31:44,850 --> 00:31:50,660
not caused by the oven cavity caused by

00:31:47,400 --> 00:31:50,660
the cache system here

00:32:04,220 --> 00:32:07,220
Hey

00:32:11,090 --> 00:32:16,770
sorry

00:32:13,429 --> 00:32:20,040
well actually we are an energy in some

00:32:16,770 --> 00:32:23,090
legal review process and I believe it

00:32:20,040 --> 00:32:23,090
will be organ soon

00:32:41,840 --> 00:32:44,160

YouTube URL: https://www.youtube.com/watch?v=AkzNsinaEs0


