Title: OpenPOWER Summit NA 2019: Day 1 Keynote: Brian Pan, H3 Platform Inc.
Publication date: 2019-08-20
Playlist: OpenPOWER Summit NA 2019
Description: 
	
Captions: 
	00:00:00,060 --> 00:00:05,339
my topic is smarter hydrogenous

00:00:02,220 --> 00:00:08,880
Computing's I will explain how we used

00:00:05,339 --> 00:00:11,190
compose of GPU solutions to increase the

00:00:08,880 --> 00:00:16,859
GPU iteration way and also gather your

00:00:11,190 --> 00:00:20,220
software code higher productivity this

00:00:16,859 --> 00:00:23,550
is a AI or HP she wore all you have a

00:00:20,220 --> 00:00:26,880
user create different jobs then submit

00:00:23,550 --> 00:00:30,000
the jobs to be wrong as soon as the GPU

00:00:26,880 --> 00:00:33,750
are available then you have a bunch of

00:00:30,000 --> 00:00:36,600
the GPU server for Bay 6 pay emails in

00:00:33,750 --> 00:00:39,030
your data centers this is a very typical

00:00:36,600 --> 00:00:42,660
sub hype oh geez

00:00:39,030 --> 00:00:44,879
computing scenario what kind of

00:00:42,660 --> 00:00:48,059
challenges you will have in the

00:00:44,879 --> 00:00:52,980
heterogeneous computing environment in

00:00:48,059 --> 00:00:55,699
how well you need a interconnect to with

00:00:52,980 --> 00:00:59,670
the higher bandwidth and low latency a

00:00:55,699 --> 00:01:02,100
suitable protocol to manage your system

00:00:59,670 --> 00:01:04,500
memory and the device memory and then of

00:01:02,100 --> 00:01:07,409
course you also need to do your resource

00:01:04,500 --> 00:01:09,479
optimization for all your jobs in

00:01:07,409 --> 00:01:10,890
software sighs you have also straight

00:01:09,479 --> 00:01:13,590
different challenges the first challenge

00:01:10,890 --> 00:01:18,630
will be how to get your code more

00:01:13,590 --> 00:01:23,549
positivity then how to scale your call

00:01:18,630 --> 00:01:28,229
as GPU increased then run your code in

00:01:23,549 --> 00:01:32,659
different hydrogenous environments also

00:01:28,229 --> 00:01:36,630
routing is the composable GPU solutions

00:01:32,659 --> 00:01:39,590
the GPU in tribute appreciation for

00:01:36,630 --> 00:01:42,509
chases artists segregate from a server

00:01:39,590 --> 00:01:45,560
the GPU can be dynamically okay to any

00:01:42,509 --> 00:01:49,920
connected server without shutting down

00:01:45,560 --> 00:01:53,490
the server or GPU chases it mean that

00:01:49,920 --> 00:01:57,450
you can create two GPUs server 4gb

00:01:53,490 --> 00:02:02,189
server a GPU server over 32 GB server

00:01:57,450 --> 00:02:06,090
unlined please be noted all these GPU

00:02:02,189 --> 00:02:09,030
are committed in PCH and for carnations

00:02:06,090 --> 00:02:13,319
so latency and the bandwidth is much

00:02:09,030 --> 00:02:17,379
better than any networking protocol

00:02:13,319 --> 00:02:20,830
the server we use is a witch from power

00:02:17,379 --> 00:02:23,410
9 open power server with lots of great

00:02:20,830 --> 00:02:26,920
features you've got a 32 thin memory

00:02:23,410 --> 00:02:31,540
peach hmm for IO and also open cable

00:02:26,920 --> 00:02:38,099
treated ero the GPU chesses is the pitch

00:02:31,540 --> 00:02:38,099
a gem for bass with a 16 GPU slot in it

00:02:38,610 --> 00:02:44,349
so let's see what kind of challenger has

00:02:41,200 --> 00:02:47,500
been addressed in our solutions for the

00:02:44,349 --> 00:02:49,150
first and - we use a pitch high chamber

00:02:47,500 --> 00:02:53,650
to address interconnected memory

00:02:49,150 --> 00:02:56,530
management PJ jumbo has Cerrito gigabyte

00:02:53,650 --> 00:03:00,510
bandwidth and as some micro latency and

00:02:56,530 --> 00:03:04,629
the p2p could be wrong on pam-4 protocol

00:03:00,510 --> 00:03:09,400
so the first two challenges is addressed

00:03:04,629 --> 00:03:11,560
by the PGM for our composable GPU

00:03:09,400 --> 00:03:14,170
solutions could dynamically allocated

00:03:11,560 --> 00:03:18,519
GPU to any connected house to increase

00:03:14,170 --> 00:03:21,700
the GPU mutation rate besides that you

00:03:18,519 --> 00:03:24,040
can get GPU duration informations memory

00:03:21,700 --> 00:03:28,959
generation informations and a Penguin's

00:03:24,040 --> 00:03:31,359
information from our chases so you can

00:03:28,959 --> 00:03:37,299
get a you a call higher productivity by

00:03:31,359 --> 00:03:39,340
using these three informations yeah in

00:03:37,299 --> 00:03:42,459
summary what we have provided is that

00:03:39,340 --> 00:03:46,959
our solutions can dynamic or okay the

00:03:42,459 --> 00:03:50,769
GPU to provide a how a flexibility

00:03:46,959 --> 00:03:56,200
it's a PCIe channel based GP only

00:03:50,769 --> 00:03:58,239
provisioning capability and that the GP

00:03:56,200 --> 00:04:02,230
regenerated memory retention rate and a

00:03:58,239 --> 00:04:06,760
bandwidth could be used to see whether

00:04:02,230 --> 00:04:10,599
the GPU or storage has been fully

00:04:06,760 --> 00:04:11,349
utilized by the so vehicle of course you

00:04:10,599 --> 00:04:15,190
can dynamic

00:04:11,349 --> 00:04:20,620
ADA your GPU to see your cocaine scale

00:04:15,190 --> 00:04:22,810
or not withdraw better

00:04:20,620 --> 00:04:25,419
UT Asia and the flexibility not auto

00:04:22,810 --> 00:04:26,740
cost of ownership of the composable

00:04:25,419 --> 00:04:31,960
solutions

00:04:26,740 --> 00:04:35,979
we'll be better than GPU server so we

00:04:31,960 --> 00:04:39,039
have the demo on the boots sv welcome to

00:04:35,979 --> 00:04:41,680
check it and we have another printed

00:04:39,039 --> 00:04:45,550
presentation tomorrow morning 11:00

00:04:41,680 --> 00:04:49,660
Sergey to expend more how we do it by

00:04:45,550 --> 00:04:51,390
the GPU composable solutions thank you

00:04:49,660 --> 00:04:57,790
very much

00:04:51,390 --> 00:04:57,790

YouTube URL: https://www.youtube.com/watch?v=usQFNJ41lJ0


