Title: OpenPOWER Summit Europe 2016 - Swift Object Store Deployment on OpenPOWER
Publication date: 2016-11-17
Playlist: OpenPOWER Summit Europe 2016
Description: 
	
Captions: 
	00:00:15,070 --> 00:00:24,439
so good afternoon hopefully some of us

00:00:19,610 --> 00:00:27,289
are awake after after this rough morning

00:00:24,439 --> 00:00:30,470
I know that if I sit down giving that

00:00:27,289 --> 00:00:32,150
I'm from New York after one minute of

00:00:30,470 --> 00:00:35,540
sitting down I felt do fall asleep

00:00:32,150 --> 00:00:38,470
trying to catch up for the time I don't

00:00:35,540 --> 00:00:41,090
have that in at night but in any case

00:00:38,470 --> 00:00:45,920
this was a great introduction to our

00:00:41,090 --> 00:00:49,580
topic because Eddie was covering a swift

00:00:45,920 --> 00:00:52,100
on open power which is the proof of

00:00:49,580 --> 00:00:57,710
concept we have done to measure how to

00:00:52,100 --> 00:01:02,299
operate or how to raise them the impact

00:00:57,710 --> 00:01:06,710
of open open power or Swift running on

00:01:02,299 --> 00:01:10,220
open power and so I'm Jacob casspi I'm a

00:01:06,710 --> 00:01:15,500
principal architect and AT&T responsible

00:01:10,220 --> 00:01:17,270
for our cloud architecture Tom Matthews

00:01:15,500 --> 00:01:20,270
who is a distinguished engineer with

00:01:17,270 --> 00:01:22,460
power system at IBM and Chris Christian

00:01:20,270 --> 00:01:25,550
rice who's the VP of high skype a

00:01:22,460 --> 00:01:28,150
skeleton canonical which we all did this

00:01:25,550 --> 00:01:28,150
together

00:01:30,270 --> 00:01:35,909
so we actually delivered this

00:01:33,570 --> 00:01:40,759
presentation at across the street that

00:01:35,909 --> 00:01:43,920
at the openstack of Summit so some of

00:01:40,759 --> 00:01:46,289
this especially this slide we may not be

00:01:43,920 --> 00:01:48,630
applicable because obviously hopefully

00:01:46,289 --> 00:01:52,110
everybody here knows what the open power

00:01:48,630 --> 00:01:55,319
is but the what we wanted to emphasize

00:01:52,110 --> 00:01:59,909
is why we actually looked at open power

00:01:55,319 --> 00:02:03,349
for swift given that so if isn't not the

00:01:59,909 --> 00:02:06,929
most cpu intensive or memory intensive

00:02:03,349 --> 00:02:13,620
application yet still we feel that it

00:02:06,929 --> 00:02:17,489
benefited from having open power as the

00:02:13,620 --> 00:02:20,160
base architecture for it in for a more

00:02:17,489 --> 00:02:22,319
efficient use of the CPU so Tom if you

00:02:20,160 --> 00:02:26,220
can elaborate a little bit about that

00:02:22,319 --> 00:02:27,500
right sure so is the chart says right i

00:02:26,220 --> 00:02:30,540
mean is is that there's some

00:02:27,500 --> 00:02:32,549
characteristics that that open power has

00:02:30,540 --> 00:02:35,760
that are really critical for this

00:02:32,549 --> 00:02:37,709
particular workload right it's got a lot

00:02:35,760 --> 00:02:40,769
of threads it's got more cash it's got

00:02:37,709 --> 00:02:43,889
more bandwidth and you know through this

00:02:40,769 --> 00:02:45,600
POC and the and some of the performance

00:02:43,889 --> 00:02:47,670
work that we've done we still have some

00:02:45,600 --> 00:02:51,900
performance work to work through but you

00:02:47,670 --> 00:02:53,220
know we see you know comparatively you

00:02:51,900 --> 00:02:55,500
know fairly significant performance

00:02:53,220 --> 00:02:58,889
differences right in this environment

00:02:55,500 --> 00:03:01,889
with this workload running on top of

00:02:58,889 --> 00:03:03,840
open power right i mean one of them you

00:03:01,889 --> 00:03:05,489
know I at least in my opinion one of the

00:03:03,840 --> 00:03:08,519
strengths of open power writer who was

00:03:05,489 --> 00:03:10,680
built as a you know the workloads I ran

00:03:08,519 --> 00:03:14,069
on and so forth and did moving forward

00:03:10,680 --> 00:03:18,630
it was built as as a you know as a data

00:03:14,069 --> 00:03:21,660
machine and and those characteristics

00:03:18,630 --> 00:03:24,239
you know that brought about brought were

00:03:21,660 --> 00:03:27,090
brought forward from that really have a

00:03:24,239 --> 00:03:29,790
significant impact on performance in

00:03:27,090 --> 00:03:31,739
here right because this is you know open

00:03:29,790 --> 00:03:34,019
source it's just about cost and

00:03:31,739 --> 00:03:36,239
performance so so we've seen some very

00:03:34,019 --> 00:03:38,220
good results out of this the other thing

00:03:36,239 --> 00:03:40,680
there's been discussion about about the

00:03:38,220 --> 00:03:41,940
accelerators this that's something that

00:03:40,680 --> 00:03:46,530
we'll be applying to this

00:03:41,940 --> 00:03:51,210
as well so okay could you like to talk

00:03:46,530 --> 00:03:52,650
about um what is Swift and and what

00:03:51,210 --> 00:03:54,480
we're looking to get out of this sure

00:03:52,650 --> 00:03:56,340
should you take it so as introduced me

00:03:54,480 --> 00:03:57,600
up a VP for hyperscale I'm a canonical

00:03:56,340 --> 00:04:00,120
veteran in fact I've been a canonical

00:03:57,600 --> 00:04:02,370
for 11 years and from the very beginning

00:04:00,120 --> 00:04:04,190
we've invested in sort of looking at

00:04:02,370 --> 00:04:06,330
ecosystems and making sure that there is

00:04:04,190 --> 00:04:09,870
opportunity for multiple vendors to come

00:04:06,330 --> 00:04:11,820
in and to provide important components

00:04:09,870 --> 00:04:13,740
and when you look at the infrastructure

00:04:11,820 --> 00:04:15,390
layer we've always understood that it's

00:04:13,740 --> 00:04:17,549
very important to have multiple

00:04:15,390 --> 00:04:19,049
architectures and so I'm gonna talk here

00:04:17,549 --> 00:04:20,700
about Swift and at the end around our

00:04:19,049 --> 00:04:23,280
tooling but just to understand our view

00:04:20,700 --> 00:04:25,500
is that's the tool to provide in the

00:04:23,280 --> 00:04:27,330
operating system we provide is the same

00:04:25,500 --> 00:04:29,340
no matter where you're running it if

00:04:27,330 --> 00:04:32,490
it's in private cloud or public cloud if

00:04:29,340 --> 00:04:34,110
it's on x86 power or other architectures

00:04:32,490 --> 00:04:36,390
that you've got the same experience the

00:04:34,110 --> 00:04:38,580
same tooling and the application and the

00:04:36,390 --> 00:04:40,710
operational team as much as possible can

00:04:38,580 --> 00:04:42,810
navigate regardless of where they are so

00:04:40,710 --> 00:04:45,360
invested in canonical in general is

00:04:42,810 --> 00:04:47,520
making easy access to software into

00:04:45,360 --> 00:04:49,410
high-value operations Swift is one of

00:04:47,520 --> 00:04:51,240
the tools I'm also responsible for the

00:04:49,410 --> 00:04:52,410
storage be you at canonical so Swift is

00:04:51,240 --> 00:04:54,180
one of the products that we've looked at

00:04:52,410 --> 00:04:55,980
for years and said this is a great

00:04:54,180 --> 00:04:59,370
alternative for people that are at the

00:04:55,980 --> 00:05:02,790
moment stuck inside expensive arrays or

00:04:59,370 --> 00:05:06,210
expensive NASA's for recording what is

00:05:02,790 --> 00:05:08,250
typically low I ops high volume data

00:05:06,210 --> 00:05:10,050
that everybody has plenty of and lots of

00:05:08,250 --> 00:05:12,180
people throw away so Swift is a great

00:05:10,050 --> 00:05:14,190
answer for that because it is pure

00:05:12,180 --> 00:05:16,740
software it can run on any hardware in

00:05:14,190 --> 00:05:18,720
fact across the cluster you can have any

00:05:16,740 --> 00:05:20,700
configuration hardware and Swift

00:05:18,720 --> 00:05:22,320
understands what the sizes of this

00:05:20,700 --> 00:05:24,120
machine's and how many drives they have

00:05:22,320 --> 00:05:26,220
and how much storage capacity and knows

00:05:24,120 --> 00:05:27,900
how to balance it out so if there's a

00:05:26,220 --> 00:05:29,910
two tier architecture it as a proxy on

00:05:27,900 --> 00:05:31,860
the top and object storage nodes at the

00:05:29,910 --> 00:05:33,540
bottom the proxy is essentially there to

00:05:31,860 --> 00:05:36,140
handle API requests which are the sort

00:05:33,540 --> 00:05:39,270
store an object and giving back an ID or

00:05:36,140 --> 00:05:41,130
retrieve an object based on that ID the

00:05:39,270 --> 00:05:43,230
proxy and Swift is essentially what

00:05:41,130 --> 00:05:44,669
handles all the northbound communication

00:05:43,230 --> 00:05:45,930
everybody's requesting data we're

00:05:44,669 --> 00:05:48,330
putting data into the object stores

00:05:45,930 --> 00:05:50,729
talking to it and the proxy itself sends

00:05:48,330 --> 00:05:53,400
streams information in fact streams the

00:05:50,729 --> 00:05:55,409
data back into one or more object

00:05:53,400 --> 00:05:57,239
storage demons which sit in the back

00:05:55,409 --> 00:05:58,589
so the object storage demons run on the

00:05:57,239 --> 00:06:01,229
servers that actually have the disks

00:05:58,589 --> 00:06:02,550
where it did it gets stored in this

00:06:01,229 --> 00:06:03,749
example here we don't have it on the

00:06:02,550 --> 00:06:05,789
slide but we're going to be looking at

00:06:03,749 --> 00:06:07,169
specifically arrays your coding which is

00:06:05,789 --> 00:06:09,360
a strategy in which you don't have to

00:06:07,169 --> 00:06:11,610
replicate all the data in fact you can

00:06:09,360 --> 00:06:14,669
use something which is analogous to raid

00:06:11,610 --> 00:06:16,259
inside a single machine rate 5 and raid

00:06:14,669 --> 00:06:18,869
6 in particular where you're calculating

00:06:16,259 --> 00:06:20,489
parity and so in Swift what you do is

00:06:18,869 --> 00:06:22,139
when you get an object that comes in and

00:06:20,489 --> 00:06:23,969
you're doing erasure coding that object

00:06:22,139 --> 00:06:26,249
gets cut up into chunks we calculate

00:06:23,969 --> 00:06:27,809
parody blocks and those are stored in

00:06:26,249 --> 00:06:29,459
the underlying object storage targets

00:06:27,809 --> 00:06:31,800
the high level net benefit is that

00:06:29,459 --> 00:06:33,239
instead of requiring three times the

00:06:31,800 --> 00:06:35,039
copies which is sort of industry

00:06:33,239 --> 00:06:38,279
standard for scale-out storage you may

00:06:35,039 --> 00:06:40,649
require 2x or 1.8 X or less so it's

00:06:38,279 --> 00:06:42,439
really a significant savings in terms of

00:06:40,649 --> 00:06:44,969
dis capacity required and this is why

00:06:42,439 --> 00:06:48,239
the investigations been done here

00:06:44,969 --> 00:06:50,339
looking at power as a vehicle for

00:06:48,239 --> 00:06:52,110
providing erasure coded back object

00:06:50,339 --> 00:06:54,149
storage is so important it's because we

00:06:52,110 --> 00:06:56,069
really want to see economies of scale

00:06:54,149 --> 00:06:59,119
and driving down costs in each of the

00:06:56,069 --> 00:07:02,729
individual components there great thanks

00:06:59,119 --> 00:07:04,979
so this was a test environment time

00:07:02,729 --> 00:07:06,209
would you mind describing so this test

00:07:04,979 --> 00:07:09,419
environment there were actually three

00:07:06,209 --> 00:07:11,909
Swift clusters here as part of the work

00:07:09,419 --> 00:07:14,819
that we're doing there were three Swift

00:07:11,909 --> 00:07:20,729
clusters here actually of the same type

00:07:14,819 --> 00:07:22,559
each one of them had six power servers

00:07:20,729 --> 00:07:24,659
and open power servers in them as a

00:07:22,559 --> 00:07:27,419
matter of fact the same ones that I saw

00:07:24,659 --> 00:07:30,629
in the Connecticut pitch a few minutes

00:07:27,419 --> 00:07:35,309
back in addition to that there were we

00:07:30,629 --> 00:07:38,129
used super six supermicro group drawers

00:07:35,309 --> 00:07:42,599
in the environment fair amount of

00:07:38,129 --> 00:07:44,999
storage here and also a dedicated proxy

00:07:42,599 --> 00:07:47,249
server in the environment and 10 gig

00:07:44,999 --> 00:07:49,919
networks for data and one gig for

00:07:47,249 --> 00:07:54,019
management in the environment and in the

00:07:49,919 --> 00:07:58,079
software was a boon to software

00:07:54,019 --> 00:08:01,740
obviously obviously you know Swift and

00:07:58,079 --> 00:08:06,530
open stock right coming out of open

00:08:01,740 --> 00:08:06,530
coming out of the committee

00:08:10,080 --> 00:08:19,439
so we have we've had two goals when we

00:08:17,189 --> 00:08:22,680
started this proof-of-concept the first

00:08:19,439 --> 00:08:25,889
is strict functionality meaning the

00:08:22,680 --> 00:08:28,409
Swift work on open tower in the same way

00:08:25,889 --> 00:08:30,569
that works of x86 meaning from a

00:08:28,409 --> 00:08:33,149
functionality perspective are we losing

00:08:30,569 --> 00:08:36,149
anything does it take a lot more effort

00:08:33,149 --> 00:08:39,740
to deploy it as are we did we get any

00:08:36,149 --> 00:08:42,839
gotchas while we did the installation

00:08:39,740 --> 00:08:46,079
and the response to that is pretty much

00:08:42,839 --> 00:08:51,060
it went as well as we expected to have

00:08:46,079 --> 00:08:53,970
done if we have gone to any new x86

00:08:51,060 --> 00:08:57,089
environment so from a sort of deployment

00:08:53,970 --> 00:09:00,480
perspective we we found very little

00:08:57,089 --> 00:09:04,709
differences on whether we went to an

00:09:00,480 --> 00:09:07,260
open power processors versus x86

00:09:04,709 --> 00:09:11,579
processor which is very important for us

00:09:07,260 --> 00:09:15,600
at ATT because we we're very concerned

00:09:11,579 --> 00:09:18,120
with large-scale operations and making

00:09:15,600 --> 00:09:20,760
sure that operation teams have unified

00:09:18,120 --> 00:09:22,500
tool and unified deployment that we

00:09:20,760 --> 00:09:26,070
don't have to differentiate between one

00:09:22,500 --> 00:09:30,890
cpu versus the other which would have

00:09:26,070 --> 00:09:34,589
caused a barrier to entry within AT&T

00:09:30,890 --> 00:09:37,140
the other thing that we were testing is

00:09:34,589 --> 00:09:40,860
of course performance being how well

00:09:37,140 --> 00:09:43,560
does the does the cluster perform and

00:09:40,860 --> 00:09:47,670
what kind of fishin seadoo are we seeing

00:09:43,560 --> 00:09:49,500
versus x86 of course we don't have we

00:09:47,670 --> 00:09:52,730
did not have a benchmark we did

00:09:49,500 --> 00:09:56,040
one-to-one comparison between x86 but

00:09:52,730 --> 00:09:58,350
there's no mention we we're testing

00:09:56,040 --> 00:10:01,050
erasure coding in this case it's to

00:09:58,350 --> 00:10:07,070
parrot data and to parity which allowed

00:10:01,050 --> 00:10:11,459
us to do a 1 to 1.5 data replication so

00:10:07,070 --> 00:10:13,410
imagine that's you know it was more or

00:10:11,459 --> 00:10:15,269
less half the amount of hardware that we

00:10:13,410 --> 00:10:20,010
would have needed if we have done it

00:10:15,269 --> 00:10:22,339
again with standard 3x replication which

00:10:20,010 --> 00:10:26,990
is normal with OpenStack

00:10:22,339 --> 00:10:31,540
with OpenStack Swift as you can imagine

00:10:26,990 --> 00:10:34,220
AT&T has huge amount of data and every

00:10:31,540 --> 00:10:37,420
every ounce we can squeeze out of the

00:10:34,220 --> 00:10:41,290
hardware and every ounce because we can

00:10:37,420 --> 00:10:44,779
make more efficient in terms of storage

00:10:41,290 --> 00:10:47,120
translate to huge savings over the scale

00:10:44,779 --> 00:10:50,120
of data that that we that we store and

00:10:47,120 --> 00:10:52,970
that's one of the major reasons that we

00:10:50,120 --> 00:10:56,779
looked at open power because if we can

00:10:52,970 --> 00:11:02,749
do the same workload with let's say less

00:10:56,779 --> 00:11:05,209
cpus less power less space in when you

00:11:02,749 --> 00:11:09,079
do look at exabytes worth of storage

00:11:05,209 --> 00:11:11,569
that translate to a fairly significant

00:11:09,079 --> 00:11:16,730
amount of of reduction in capital

00:11:11,569 --> 00:11:21,559
investment so some of the test results

00:11:16,730 --> 00:11:30,649
basically we've done various various

00:11:21,559 --> 00:11:33,350
loads anything from 909 900 2000 object

00:11:30,649 --> 00:11:36,980
as the high load and varying the amount

00:11:33,350 --> 00:11:39,110
of work of workers on this on the

00:11:36,980 --> 00:11:44,149
servers and as you can see from the

00:11:39,110 --> 00:11:47,149
graph we barely touched fifty percent

00:11:44,149 --> 00:11:49,129
utilization on those servers now of

00:11:47,149 --> 00:11:51,889
course we went with with the servers

00:11:49,129 --> 00:11:54,759
that we are had in the lab we we didn't

00:11:51,889 --> 00:11:57,740
do much optimization but as you can see

00:11:54,759 --> 00:12:01,399
we definitely over provision the servers

00:11:57,740 --> 00:12:03,559
so even if we cut the CPUs by half we

00:12:01,399 --> 00:12:06,259
could have still managed to do the same

00:12:03,559 --> 00:12:10,249
one of workload that these servers

00:12:06,259 --> 00:12:12,769
produced and the other thing that we

00:12:10,249 --> 00:12:16,309
measure it is the failure rate looking

00:12:12,769 --> 00:12:19,610
at 64k objects to 512k objects given

00:12:16,309 --> 00:12:22,819
that we we have variety of workloads on

00:12:19,610 --> 00:12:24,589
these you can see the from a front of

00:12:22,819 --> 00:12:26,420
success ratio rate meaning how many

00:12:24,589 --> 00:12:29,829
times that did we have to go back and

00:12:26,420 --> 00:12:33,470
retrieve the same data there was almost

00:12:29,829 --> 00:12:35,180
no no significance discernible

00:12:33,470 --> 00:12:39,620
difference between

00:12:35,180 --> 00:12:44,390
when we loaded with 32 workers or 1,100

00:12:39,620 --> 00:12:48,170
workers and pretty much we've concluded

00:12:44,390 --> 00:12:50,660
that at least with our environment we

00:12:48,170 --> 00:12:54,560
could not generate enough load to stress

00:12:50,660 --> 00:12:59,240
the environment and and and overload

00:12:54,560 --> 00:13:01,660
this the servers now the other thing

00:12:59,240 --> 00:13:04,610
that this is very portable is repeatable

00:13:01,660 --> 00:13:07,100
import is very repeatable solution and

00:13:04,610 --> 00:13:09,920
repeatable deployment of course when you

00:13:07,100 --> 00:13:12,530
do again exabytes worth of data storage

00:13:09,920 --> 00:13:14,780
you must have really good tools you must

00:13:12,530 --> 00:13:17,150
have automated deployment so that's

00:13:14,780 --> 00:13:20,680
where some of the tools from Canonical's

00:13:17,150 --> 00:13:23,090
make make a difference yeah and in fact

00:13:20,680 --> 00:13:25,520
object storage in particular is a great

00:13:23,090 --> 00:13:27,650
example for open power coming in easily

00:13:25,520 --> 00:13:29,330
into m to any data center everyone needs

00:13:27,650 --> 00:13:33,890
an object store curl people are putting

00:13:29,330 --> 00:13:36,230
data into s3 in buckets paying thirty

00:13:33,890 --> 00:13:38,570
dollars per gig per month sorry Patera

00:13:36,230 --> 00:13:40,310
byte per month and so if you look at

00:13:38,570 --> 00:13:42,230
that there's obviously an opportunity to

00:13:40,310 --> 00:13:44,180
come in power can come in without

00:13:42,230 --> 00:13:45,500
changing any of the operational tooling

00:13:44,180 --> 00:13:48,980
because we're using exactly the same

00:13:45,500 --> 00:13:50,540
operating system and tools on top here

00:13:48,980 --> 00:13:52,580
as in anything else that they would

00:13:50,540 --> 00:13:55,070
already be using their benchmarks are

00:13:52,580 --> 00:13:56,660
hard so we normally tell people they

00:13:55,070 --> 00:13:58,880
have to reproduce ago and we've work

00:13:56,660 --> 00:14:01,340
together with AT&T and IBM to make the

00:13:58,880 --> 00:14:02,990
entire set here uh producible who

00:14:01,340 --> 00:14:05,240
provide automation tooling with Mars and

00:14:02,990 --> 00:14:07,040
juju which again ours what are what we

00:14:05,240 --> 00:14:09,800
use at every single OpenStack and

00:14:07,040 --> 00:14:11,540
storage customer that we have and so the

00:14:09,800 --> 00:14:14,240
code in there is good which understands

00:14:11,540 --> 00:14:16,430
how to handle quirks and networking

00:14:14,240 --> 00:14:19,010
peculiarities across every customer that

00:14:16,430 --> 00:14:20,840
we've ever worked with we invite you to

00:14:19,010 --> 00:14:22,130
come and talk to us more about what it

00:14:20,840 --> 00:14:23,780
is that we did to get the

00:14:22,130 --> 00:14:25,550
reproducibility scripts on your own and

00:14:23,780 --> 00:14:26,960
to understand how power and Swift

00:14:25,550 --> 00:14:30,010
together can make a difference thanks

00:14:26,960 --> 00:14:33,190
very much thank you and

00:14:30,010 --> 00:14:36,460
I really like to thank I BM and the

00:14:33,190 --> 00:14:38,650
Austin lab team for helping us set up

00:14:36,460 --> 00:14:41,650
this environment I know they had to work

00:14:38,650 --> 00:14:44,020
and crunch time to give us these results

00:14:41,650 --> 00:14:46,870
too so we can present in this in this

00:14:44,020 --> 00:14:51,190
form and of course my team especially

00:14:46,870 --> 00:14:53,140
Cindy bill of its on my team for working

00:14:51,190 --> 00:14:55,770
nights and getting this result in time

00:14:53,140 --> 00:14:55,770
thank you

00:15:14,450 --> 00:15:16,510

YouTube URL: https://www.youtube.com/watch?v=-6ZOClN4LIw


