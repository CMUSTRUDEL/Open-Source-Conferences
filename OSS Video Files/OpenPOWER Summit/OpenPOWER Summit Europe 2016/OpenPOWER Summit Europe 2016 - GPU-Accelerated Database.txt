Title: OpenPOWER Summit Europe 2016 - GPU-Accelerated Database
Publication date: 2016-11-17
Playlist: OpenPOWER Summit Europe 2016
Description: 
	Convergence of Business Analytics and AI
Captions: 
	00:00:16,150 --> 00:00:20,840
good afternoon everyone I'm not sure if

00:00:18,290 --> 00:00:22,849
I can compete with the video but I'm

00:00:20,840 --> 00:00:27,039
chelle Sutton I manage kinetica in

00:00:22,849 --> 00:00:29,539
Europe just try get these slides up cool

00:00:27,039 --> 00:00:32,449
so I'm going to introduce you to the

00:00:29,539 --> 00:00:35,840
fastest distributing in-memory database

00:00:32,449 --> 00:00:37,850
accelerated by GPUs and ultimately take

00:00:35,840 --> 00:00:43,150
you through why we believe there is a

00:00:37,850 --> 00:00:43,150
massive convergence between bi and AI so

00:00:46,870 --> 00:00:52,100
cool so first of all I want to take you

00:00:50,150 --> 00:00:56,030
through the evolution of data processing

00:00:52,100 --> 00:00:58,159
so in the 90s and early 2000s you very

00:00:56,030 --> 00:01:00,080
much had the relational data warehouse

00:00:58,159 --> 00:01:02,629
so you had your Oracle's your Terra

00:01:00,080 --> 00:01:04,129
daters these were basically

00:01:02,629 --> 00:01:05,990
high-performance machines where

00:01:04,129 --> 00:01:09,200
customers or enterprise customers

00:01:05,990 --> 00:01:11,540
invested a huge amounts of money on

00:01:09,200 --> 00:01:13,580
consultants to build data warehouses

00:01:11,540 --> 00:01:15,320
within their organization and they were

00:01:13,580 --> 00:01:17,240
probably analyzing about three percent

00:01:15,320 --> 00:01:21,290
of their data and that was very much

00:01:17,240 --> 00:01:23,810
focused on structured data and in the

00:01:21,290 --> 00:01:25,640
early 2000s the web property companies

00:01:23,810 --> 00:01:27,980
so your Yahoo's your google is your

00:01:25,640 --> 00:01:29,840
Facebook's they got slightly annoyed

00:01:27,980 --> 00:01:33,010
writing a huge check to Oracle every

00:01:29,840 --> 00:01:36,110
week when they needed to increase their

00:01:33,010 --> 00:01:39,530
data processing capacity so they

00:01:36,110 --> 00:01:41,330
developed a platform called Hadoop very

00:01:39,530 --> 00:01:43,400
much designed and developed to for

00:01:41,330 --> 00:01:46,930
managing huge amounts of distributed

00:01:43,400 --> 00:01:49,760
storage across multiple machines I

00:01:46,930 --> 00:01:51,260
actually work for cloudera so I was one

00:01:49,760 --> 00:01:53,930
of their will their first resource in

00:01:51,260 --> 00:01:56,979
Europe and I implemented big data

00:01:53,930 --> 00:02:00,920
solutions across Europe at Cloudera a

00:01:56,979 --> 00:02:02,659
fantastic platform for storing data but

00:02:00,920 --> 00:02:04,790
it was a very much design for batch

00:02:02,659 --> 00:02:07,610
processing and it wasn't designed for

00:02:04,790 --> 00:02:11,750
your real time user cases that you're

00:02:07,610 --> 00:02:13,790
seeing today in business what happened

00:02:11,750 --> 00:02:15,920
was in memory became cheaper and a lot

00:02:13,790 --> 00:02:19,370
of people then decided to invest in in

00:02:15,920 --> 00:02:21,090
memory solutions such as hannah mem

00:02:19,370 --> 00:02:23,220
sequel

00:02:21,090 --> 00:02:24,840
and no sequel solutions these are

00:02:23,220 --> 00:02:28,230
fantastic solutions but again they

00:02:24,840 --> 00:02:30,239
struggle to ingest data in real time and

00:02:28,230 --> 00:02:31,980
serve up that data when those could not

00:02:30,239 --> 00:02:34,319
cardinality all those data sets became

00:02:31,980 --> 00:02:37,290
huge it was very difficult for them to

00:02:34,319 --> 00:02:40,440
manage that and hit any SLA s and the

00:02:37,290 --> 00:02:43,379
reason for that is the CPU became the

00:02:40,440 --> 00:02:47,400
bottleneck so at scale processing now

00:02:43,379 --> 00:02:50,099
became the bottleneck cut to the chase

00:02:47,400 --> 00:02:54,209
to now we believe GPU acceleration is

00:02:50,099 --> 00:03:00,420
the future of data processing the reason

00:02:54,209 --> 00:03:02,849
for this is GPUs are designed around

00:03:00,420 --> 00:03:05,099
thousands of small cause and so they

00:03:02,849 --> 00:03:08,849
very much can process data in parallel

00:03:05,099 --> 00:03:12,870
so a GPU these days has 4,000 to 5,000

00:03:08,849 --> 00:03:16,319
cause a CPU has about 32 or maximum 64

00:03:12,870 --> 00:03:19,379
cores per device and basically a GPU

00:03:16,319 --> 00:03:21,540
processes data in parallel so they can

00:03:19,379 --> 00:03:24,599
action all these actions so they can

00:03:21,540 --> 00:03:26,310
process and scan an entire data set and

00:03:24,599 --> 00:03:29,459
do brute force compute across an entire

00:03:26,310 --> 00:03:32,549
data set by the way we're not the only

00:03:29,459 --> 00:03:34,200
one saying this if you look now we work

00:03:32,549 --> 00:03:39,030
very closely with NVIDIA who obviously

00:03:34,200 --> 00:03:43,500
created the GPU and you have everyone

00:03:39,030 --> 00:03:46,769
from google cloud AWS ozzard they are

00:03:43,500 --> 00:03:49,139
all releasing their GPU environments or

00:03:46,769 --> 00:03:51,810
upgrading their and they are they are

00:03:49,139 --> 00:03:54,450
absolutely hugely investing in GPUs at

00:03:51,810 --> 00:03:56,880
this present moment to really offer GPU

00:03:54,450 --> 00:03:58,650
as a service so it's not just us and

00:03:56,880 --> 00:04:00,450
actually you can even look at in videos

00:03:58,650 --> 00:04:03,540
share prices well it's tripled this year

00:04:00,450 --> 00:04:05,340
so GPUs definitely are the future we

00:04:03,540 --> 00:04:09,569
believe in data warehousing and data

00:04:05,340 --> 00:04:12,780
processing so who are Kinetico and why

00:04:09,569 --> 00:04:14,959
am I in front of you sorry just go one

00:04:12,780 --> 00:04:14,959
more

00:04:17,040 --> 00:04:23,100
so hurry kinetica so kinetically

00:04:19,920 --> 00:04:27,000
actually was founded in 2009 we have

00:04:23,100 --> 00:04:28,770
founded in the US army so at that time

00:04:27,000 --> 00:04:30,290
the NSA which has probably got one of

00:04:28,770 --> 00:04:33,680
the largest databases in the world

00:04:30,290 --> 00:04:36,720
really needed to create a platform to

00:04:33,680 --> 00:04:40,530
identify people of interest or terrorist

00:04:36,720 --> 00:04:42,870
threats in North America at this time

00:04:40,530 --> 00:04:46,440
around 2009 they already had thousands

00:04:42,870 --> 00:04:48,840
of days of Hadoop no sequel platforms

00:04:46,440 --> 00:04:51,180
and huge investments in Oracle as well

00:04:48,840 --> 00:04:53,790
the challenge they had was it was taking

00:04:51,180 --> 00:04:56,430
them at best they could serve up data in

00:04:53,790 --> 00:04:58,770
a 90-minute window these guys needed to

00:04:56,430 --> 00:05:01,560
ingest billions of rows of data per

00:04:58,770 --> 00:05:05,100
minute or per hour and serve that data

00:05:01,560 --> 00:05:07,050
up as in next to real time so they

00:05:05,100 --> 00:05:09,870
challenged their internal organizations

00:05:07,050 --> 00:05:14,730
come up with a better platform and our

00:05:09,870 --> 00:05:16,680
founder Nima who's our CTO he had some

00:05:14,730 --> 00:05:19,650
experiences of gpus in the finserv

00:05:16,680 --> 00:05:21,780
industry so he built a GPU accelerated

00:05:19,650 --> 00:05:24,390
database from the ground up and this

00:05:21,780 --> 00:05:27,240
went into production in 2012 within the

00:05:24,390 --> 00:05:31,020
US Army we also have a patent for it as

00:05:27,240 --> 00:05:33,300
well so it went into production in the

00:05:31,020 --> 00:05:35,190
US Army to identify and serve out that

00:05:33,300 --> 00:05:38,010
data so they can understand terrorist

00:05:35,190 --> 00:05:39,870
threats in real time but also we won the

00:05:38,010 --> 00:05:44,850
high performance computing award for

00:05:39,870 --> 00:05:47,190
this deployment in 2014 we were called

00:05:44,850 --> 00:05:50,160
GPU dB at the time we actually changed

00:05:47,190 --> 00:05:52,110
the name very recently too kinetica the

00:05:50,160 --> 00:05:54,030
reason being is most people started

00:05:52,110 --> 00:05:56,670
calling us QP do which doesn't really

00:05:54,030 --> 00:06:00,590
bode well so we decided we had to give

00:05:56,670 --> 00:06:04,410
ourselves a better name but we actually

00:06:00,590 --> 00:06:05,880
we became commercially available in 2014

00:06:04,410 --> 00:06:08,580
but we actually had no sales or

00:06:05,880 --> 00:06:10,560
operations team at all this is where

00:06:08,580 --> 00:06:13,200
companies approaching us because they

00:06:10,560 --> 00:06:15,420
were looking for solutions to better

00:06:13,200 --> 00:06:17,880
understand their real-time analytics

00:06:15,420 --> 00:06:21,510
requirements and one of those customers

00:06:17,880 --> 00:06:23,280
was the US Postal Service's so US Postal

00:06:21,510 --> 00:06:25,530
Service is probably the biggest

00:06:23,280 --> 00:06:28,190
logistics company in the world they

00:06:25,530 --> 00:06:31,010
deliver nor post the

00:06:28,190 --> 00:06:33,050
and DHL and UPS deliver in a year they

00:06:31,010 --> 00:06:35,720
deliver in a day so these guys seriously

00:06:33,050 --> 00:06:38,210
have a lot of posts to deliver them they

00:06:35,720 --> 00:06:41,330
have around 250,000 vehicles on the road

00:06:38,210 --> 00:06:44,960
in North America and they basically use

00:06:41,330 --> 00:06:47,450
kinetica to track in real time the

00:06:44,960 --> 00:06:50,270
location of their vehicles so they can

00:06:47,450 --> 00:06:52,370
re-route their vehicles in real time due

00:06:50,270 --> 00:06:54,080
to speaks and demand and due to weather

00:06:52,370 --> 00:06:56,660
and traffic constraints they believe

00:06:54,080 --> 00:06:59,300
they save themselves around seven

00:06:56,660 --> 00:07:01,760
billion gallons of fuel a year by using

00:06:59,300 --> 00:07:04,670
kinetica they it's actually used by

00:07:01,760 --> 00:07:06,200
about 20,000 people inside the US Postal

00:07:04,670 --> 00:07:08,300
Service as well so it's kind of

00:07:06,200 --> 00:07:11,990
absolutely enterprise-ready as a

00:07:08,300 --> 00:07:14,000
platform but not only that is they can

00:07:11,990 --> 00:07:16,280
now actually almost danced the minute

00:07:14,000 --> 00:07:18,050
track where people's post is so it's

00:07:16,280 --> 00:07:20,510
transformational for these guys they can

00:07:18,050 --> 00:07:22,190
actually now if their tools allowed them

00:07:20,510 --> 00:07:24,830
to they can pretty much communicate to

00:07:22,190 --> 00:07:25,910
their customers next to real time when

00:07:24,830 --> 00:07:27,620
they're going to get delivered their

00:07:25,910 --> 00:07:30,050
post so it's transformational for their

00:07:27,620 --> 00:07:32,180
business we had other customers

00:07:30,050 --> 00:07:36,590
approaches as well we have a particle

00:07:32,180 --> 00:07:38,300
dire net who do cyber security and look

00:07:36,590 --> 00:07:39,580
for anomaly detection xand they work

00:07:38,300 --> 00:07:41,960
with a lot of the financial services

00:07:39,580 --> 00:07:44,600
companies using our platform in their

00:07:41,960 --> 00:07:46,880
business we also have the largest

00:07:44,600 --> 00:07:49,340
utility company in the US Pacific Gas

00:07:46,880 --> 00:07:51,200
and Electric again who use us to really

00:07:49,340 --> 00:07:55,240
understand peaks and troughs and demand

00:07:51,200 --> 00:07:59,180
for their electricity supplies you know

00:07:55,240 --> 00:08:00,440
so I'm conscious of time so some of the

00:07:59,180 --> 00:08:02,120
use cases were seeing so we're working

00:08:00,440 --> 00:08:04,280
across multiple verticals at this

00:08:02,120 --> 00:08:08,270
present moment so we're working with the

00:08:04,280 --> 00:08:11,780
largest retailer in the world they

00:08:08,270 --> 00:08:15,169
actually purchased over 60 devices

00:08:11,780 --> 00:08:17,450
minsky devices to use kinetica or and

00:08:15,169 --> 00:08:20,270
very recently just to show you the scale

00:08:17,450 --> 00:08:22,130
of and what they needed to do was they

00:08:20,270 --> 00:08:23,600
really need to understand their pls

00:08:22,130 --> 00:08:25,669
informations their point of sale

00:08:23,600 --> 00:08:28,010
information and their inventory

00:08:25,669 --> 00:08:30,410
information and track in real time out

00:08:28,010 --> 00:08:31,940
of stock situations so for this

00:08:30,410 --> 00:08:34,310
particular retailer it costs and

00:08:31,940 --> 00:08:35,870
billions of dollars a year in out of

00:08:34,310 --> 00:08:38,089
stock situations because they could

00:08:35,870 --> 00:08:39,779
never in real time understand their

00:08:38,089 --> 00:08:41,009
inventory demand and making

00:08:39,779 --> 00:08:45,089
or the inventory was in the right place

00:08:41,009 --> 00:08:47,129
so they very much use connecticut now to

00:08:45,089 --> 00:08:49,079
really match their inventory and their

00:08:47,129 --> 00:08:51,060
sales information this was the first

00:08:49,079 --> 00:08:53,040
time they could achieve that they have

00:08:51,060 --> 00:08:54,689
multiple other user cases they're using

00:08:53,040 --> 00:08:56,370
with us now which is really about

00:08:54,689 --> 00:08:58,379
understanding their customer and giving

00:08:56,370 --> 00:09:02,699
the best customer service but we're

00:08:58,379 --> 00:09:04,680
seeing huge amount of momentum in retail

00:09:02,699 --> 00:09:07,199
we're also seeing a lot of momentum in

00:09:04,680 --> 00:09:11,579
financial services the reason being is

00:09:07,199 --> 00:09:13,410
actually in in the risk space low

00:09:11,579 --> 00:09:15,149
latency is a critical requirement but

00:09:13,410 --> 00:09:18,449
they've actually already invested a lot

00:09:15,149 --> 00:09:19,949
in GPUs within the risk space in

00:09:18,449 --> 00:09:22,439
financial services so it's just a

00:09:19,949 --> 00:09:24,660
natural extension for these guys we're

00:09:22,439 --> 00:09:26,279
also working in the the last speaker we

00:09:24,660 --> 00:09:27,660
actually are working in that space for

00:09:26,279 --> 00:09:29,699
with another book customers in the US

00:09:27,660 --> 00:09:32,040
now so love to talk to you after hits

00:09:29,699 --> 00:09:35,399
butter yeah in the genome modeling space

00:09:32,040 --> 00:09:37,290
we're accelerating that process and

00:09:35,399 --> 00:09:39,660
we're also working with quite a lot of

00:09:37,290 --> 00:09:41,519
car companies as well so in the the

00:09:39,660 --> 00:09:43,699
connected car or the connected connected

00:09:41,519 --> 00:09:46,589
city well where they need to streaming

00:09:43,699 --> 00:09:49,290
huge amounts of data and serve that data

00:09:46,589 --> 00:09:55,790
up in real time then it's a very strong

00:09:49,290 --> 00:09:55,790
platform can I got this working now so

00:09:56,149 --> 00:10:02,550
so just performance benchmark so because

00:09:59,250 --> 00:10:05,689
as I said we have 4,000 5,000 calls per

00:10:02,550 --> 00:10:07,860
GPU the performance we can gain is is

00:10:05,689 --> 00:10:11,370
magnitude higher over any other

00:10:07,860 --> 00:10:13,290
in-memory database so as you can see

00:10:11,370 --> 00:10:15,649
here so we're kind of from the hundred

00:10:13,290 --> 00:10:18,059
percent performance improvement to the

00:10:15,649 --> 00:10:19,589
502 almost a thousand percent point

00:10:18,059 --> 00:10:21,959
performance improvement you will see

00:10:19,589 --> 00:10:26,699
over your more traditional in-memory

00:10:21,959 --> 00:10:28,649
database platforms can just go cool so

00:10:26,699 --> 00:10:30,420
one of the one of the retailer i

00:10:28,649 --> 00:10:34,889
mentioned actually benchmarked us

00:10:30,420 --> 00:10:37,290
against ICP hannah which was their

00:10:34,889 --> 00:10:39,449
incumbent solution and they obviously

00:10:37,290 --> 00:10:42,120
did their most complex queries on our

00:10:39,449 --> 00:10:44,670
platform and you can see here we're for

00:10:42,120 --> 00:10:46,860
a great boy join summer or select some

00:10:44,670 --> 00:10:48,600
of the time and prompt performance

00:10:46,860 --> 00:10:50,760
improvements they gained with kinetica

00:10:48,600 --> 00:10:54,060
and

00:10:50,760 --> 00:10:57,540
i would add so we were benchmarked with

00:10:54,060 --> 00:11:00,900
far less kit than SCP Hannah was ohm we

00:10:57,540 --> 00:11:03,420
could ingest 1.2 billion rows of data in

00:11:00,900 --> 00:11:06,600
a minute it took them over it took them

00:11:03,420 --> 00:11:09,990
and over an hour to do 1 billion rows on

00:11:06,600 --> 00:11:12,360
SCP Hannah and we had a far less server

00:11:09,990 --> 00:11:14,190
estate or capacity so it's not just

00:11:12,360 --> 00:11:15,990
performance games it's also you're

00:11:14,190 --> 00:11:19,110
absolutely reducing your hardware

00:11:15,990 --> 00:11:20,940
footprint as well so one thing that's

00:11:19,110 --> 00:11:24,930
interesting is we scale linearly across

00:11:20,940 --> 00:11:27,110
so we can we can scale predictably so we

00:11:24,930 --> 00:11:32,460
can scale to tens to hundreds of

00:11:27,110 --> 00:11:33,870
terabytes conscious of time so but as I

00:11:32,460 --> 00:11:36,990
said we reduce the footprint

00:11:33,870 --> 00:11:38,610
substantially as well so in the US Army

00:11:36,990 --> 00:11:41,060
I think we reduce the footprint of their

00:11:38,610 --> 00:11:44,490
hardware environment by over 40 times

00:11:41,060 --> 00:11:46,500
and the US Postal Service it was around

00:11:44,490 --> 00:11:49,020
over 10 fold that they reduced their

00:11:46,500 --> 00:11:50,880
hardware footprint so not only do we get

00:11:49,020 --> 00:11:52,530
performance gains we get rejection and

00:11:50,880 --> 00:11:55,290
footprint and reduction in power

00:11:52,530 --> 00:11:58,170
reduction in calling so this huge gains

00:11:55,290 --> 00:12:00,360
to be had there what I forgot to mention

00:11:58,170 --> 00:12:03,450
as well just quickly if I went back to

00:12:00,360 --> 00:12:06,390
here was we actually benchmark this with

00:12:03,450 --> 00:12:08,700
envy link as well when it came out at

00:12:06,390 --> 00:12:10,860
the end and we actually got a 3 to 10 X

00:12:08,700 --> 00:12:13,290
performance improvement in this customer

00:12:10,860 --> 00:12:15,390
by taking advantage of the MV link

00:12:13,290 --> 00:12:17,670
capacity or power and that is the reason

00:12:15,390 --> 00:12:20,010
why we're so focused on partnering with

00:12:17,670 --> 00:12:26,040
power today that is just we think it's a

00:12:20,010 --> 00:12:27,840
huge huge huge win for kinetica so the

00:12:26,040 --> 00:12:30,260
interesting thing about is we can we

00:12:27,840 --> 00:12:32,790
plug into your existing architecture so

00:12:30,260 --> 00:12:35,640
but you don't need to do any tuning or

00:12:32,790 --> 00:12:39,210
indexing or that you would need to do

00:12:35,640 --> 00:12:42,270
with a traditional CPU platform so we

00:12:39,210 --> 00:12:44,390
also have built NLP I so we built list

00:12:42,270 --> 00:12:47,360
seen under the bonnet in our platform

00:12:44,390 --> 00:12:49,440
and we plug into the more traditional

00:12:47,360 --> 00:12:51,950
business intelligence black plication

00:12:49,440 --> 00:12:54,360
we're working with tableau at the moment

00:12:51,950 --> 00:12:55,530
they kind of did make me laugh when I

00:12:54,360 --> 00:12:57,300
met them the other day because they used

00:12:55,530 --> 00:12:59,070
to be called tab slow and so they quite

00:12:57,300 --> 00:13:00,570
liked the fact that we have a database

00:12:59,070 --> 00:13:02,190
that can give them the speed they

00:13:00,570 --> 00:13:03,900
require but we're also working with a

00:13:02,190 --> 00:13:04,860
lot of the open source frameworks as

00:13:03,900 --> 00:13:07,529
well

00:13:04,860 --> 00:13:10,750
and we actually have a very powerful

00:13:07,529 --> 00:13:12,550
geospatial you i purely because of our

00:13:10,750 --> 00:13:14,650
GPU heritage we're very strong at

00:13:12,550 --> 00:13:18,220
rendering data both geospatially and

00:13:14,650 --> 00:13:21,760
temporarily so where do we fit in so if

00:13:18,220 --> 00:13:26,070
we fitted in as a in-memory layer so

00:13:21,760 --> 00:13:26,070
we're really good at streaming analytics

00:13:26,370 --> 00:13:33,100
so we very much fit into a most

00:13:31,360 --> 00:13:37,120
customers reference architecture with

00:13:33,100 --> 00:13:39,310
sequel 92 compliant but we work with the

00:13:37,120 --> 00:13:42,339
data lake so we really really try and

00:13:39,310 --> 00:13:44,500
gain or drive value out of the data lake

00:13:42,339 --> 00:13:48,490
already in play so the kinetic

00:13:44,500 --> 00:13:51,220
architecture very much takes advantage

00:13:48,490 --> 00:13:54,520
of the open source integration

00:13:51,220 --> 00:13:57,940
frameworks whether they're Kafka spark

00:13:54,520 --> 00:13:59,260
knife i we take advantage of those and

00:13:57,940 --> 00:14:01,089
we also use the other the more

00:13:59,260 --> 00:14:03,190
traditional integration platforms as

00:14:01,089 --> 00:14:05,470
well we have standard odbc and jdbc

00:14:03,190 --> 00:14:09,520
connectors but we have a restful

00:14:05,470 --> 00:14:11,920
endpoint as well and finally you just

00:14:09,520 --> 00:14:13,630
conscious one thing we're seeing now is

00:14:11,920 --> 00:14:17,589
a lot of customers have already

00:14:13,630 --> 00:14:20,110
investing in using gpus and they are

00:14:17,589 --> 00:14:24,490
using tools like tensorflow cafe torch

00:14:20,110 --> 00:14:27,010
as their solutions for AI what they are

00:14:24,490 --> 00:14:29,740
actually seeing is because we also take

00:14:27,010 --> 00:14:32,200
advantage of the CUDA libraries we can

00:14:29,740 --> 00:14:35,350
actually define UDS with our platform so

00:14:32,200 --> 00:14:38,440
when a process is being run on kinetica

00:14:35,350 --> 00:14:41,920
they can absolutely kick off the process

00:14:38,440 --> 00:14:45,310
go and call that CUDA library and run

00:14:41,920 --> 00:14:47,860
that UDF and bring that result back in

00:14:45,310 --> 00:14:50,410
near real time or real time which is

00:14:47,860 --> 00:14:52,510
transformational they don't have to move

00:14:50,410 --> 00:14:54,490
the data so we we believe there is a

00:14:52,510 --> 00:14:58,600
massive convergence now with the more

00:14:54,490 --> 00:15:01,750
and more bi being automated by AI work

00:14:58,600 --> 00:15:03,190
lace but also this is this is this is

00:15:01,750 --> 00:15:06,100
where we believe that there is a massive

00:15:03,190 --> 00:15:08,279
convergence in bi nai thank you for your

00:15:06,100 --> 00:15:08,279
time

00:15:24,560 --> 00:15:26,620

YouTube URL: https://www.youtube.com/watch?v=9rggKM1_aCA


