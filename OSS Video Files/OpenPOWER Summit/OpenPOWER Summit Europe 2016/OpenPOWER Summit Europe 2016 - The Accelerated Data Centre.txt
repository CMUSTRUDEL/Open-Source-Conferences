Title: OpenPOWER Summit Europe 2016 - The Accelerated Data Centre
Publication date: 2016-11-17
Playlist: OpenPOWER Summit Europe 2016
Description: 
	
Captions: 
	00:00:11,830 --> 00:00:17,430
now

00:00:14,389 --> 00:00:19,800
so my name is Tim lanphear and I managed

00:00:17,430 --> 00:00:21,990
in videos European solution architecture

00:00:19,800 --> 00:00:25,169
group so we are a team an engineering

00:00:21,990 --> 00:00:29,029
team technical team that supports all of

00:00:25,169 --> 00:00:31,969
our invidious enterprise solutions I

00:00:29,029 --> 00:00:34,050
want to talk about two things today

00:00:31,969 --> 00:00:38,340
first of all I want to talk about what

00:00:34,050 --> 00:00:40,890
is the most recent and key and hot

00:00:38,340 --> 00:00:43,020
activity in the area of GPU computing

00:00:40,890 --> 00:00:45,360
where we're seeing the biggest business

00:00:43,020 --> 00:00:46,980
opportunities for GPU computing and that

00:00:45,360 --> 00:00:50,100
is in the area of artificial

00:00:46,980 --> 00:00:52,379
intelligence and deep learning and then

00:00:50,100 --> 00:00:56,219
after that I want to talk about how the

00:00:52,379 --> 00:00:58,559
open you can take advantage of that GPUs

00:00:56,219 --> 00:01:01,050
for deep learning within the context of

00:00:58,559 --> 00:01:02,999
the open Power Architecture an open

00:01:01,050 --> 00:01:04,800
power framework so I think previous

00:01:02,999 --> 00:01:06,600
speakers have mentioned they're open

00:01:04,800 --> 00:01:09,060
power credentials if I got it right

00:01:06,600 --> 00:01:11,130
Danny I think that Nvidia was a founder

00:01:09,060 --> 00:01:12,540
member of the of open power so we've

00:01:11,130 --> 00:01:14,610
been it in it right from the beginning

00:01:12,540 --> 00:01:18,560
working together close very closely with

00:01:14,610 --> 00:01:20,550
IBM so the way i'll talk about

00:01:18,560 --> 00:01:22,410
artificial intelligence and deep

00:01:20,550 --> 00:01:25,050
learning is not is actually by not

00:01:22,410 --> 00:01:26,340
talking but by showing a video i'm sure

00:01:25,050 --> 00:01:27,960
by the end of the afternoon you've heard

00:01:26,340 --> 00:01:29,730
enough people talking you've had enough

00:01:27,960 --> 00:01:32,220
slides and it'd be more attending to see

00:01:29,730 --> 00:01:34,650
a video this is a video that was shown

00:01:32,220 --> 00:01:37,130
as part of the keynote presentation of

00:01:34,650 --> 00:01:39,630
our recent GPU technology conference in

00:01:37,130 --> 00:01:43,890
California so I hope this is going to

00:01:39,630 --> 00:01:50,000
work it all begins from a single origin

00:01:43,890 --> 00:01:50,000
a unique point in space and time

00:01:53,520 --> 00:02:01,460
this is the spark of innovation that

00:01:56,700 --> 00:02:01,460
fuels your most amazing breakthroughs

00:02:05,760 --> 00:02:12,030
it's a passion for discovery that

00:02:08,460 --> 00:02:17,940
unveiled the genesis of all that exists

00:02:12,030 --> 00:02:21,180
in the universe today the power of a I

00:02:17,940 --> 00:02:23,880
helps computers achieve super human

00:02:21,180 --> 00:02:26,730
capabilities in image recognition and

00:02:23,880 --> 00:02:30,720
lets scientists save our most precious

00:02:26,730 --> 00:02:34,520
resources by analyzing in one month what

00:02:30,720 --> 00:02:36,680
used to take ten years

00:02:34,520 --> 00:02:39,829
she's a funny note

00:02:36,680 --> 00:02:43,269
everyday devices translate even the most

00:02:39,829 --> 00:02:47,269
complex languages from voice into text

00:02:43,269 --> 00:02:49,569
and images into words maybe here is now

00:02:47,269 --> 00:02:53,150
present helping the visually impaired

00:02:49,569 --> 00:02:56,599
recognize an old friend or letting a

00:02:53,150 --> 00:02:59,409
blind woman read to her child for the

00:02:56,599 --> 00:02:59,409
first to me

00:03:02,349 --> 00:03:09,290
autonomous vehicles give us the freedom

00:03:05,090 --> 00:03:11,930
to reimagine our city streets and travel

00:03:09,290 --> 00:03:16,270
where there are no streets at all to

00:03:11,930 --> 00:03:16,270
help the loss find their way home

00:03:17,850 --> 00:03:24,660
we see robots keeps themselves to

00:03:21,360 --> 00:03:28,860
perform simple test

00:03:24,660 --> 00:03:31,460
we even watch in awe as they take their

00:03:28,860 --> 00:03:31,460
first steps

00:03:32,560 --> 00:03:40,989
and today a 2500 year old game meets its

00:03:37,540 --> 00:03:43,620
match as a computer competes with one of

00:03:40,989 --> 00:03:47,640
the greatest human champions of all time

00:03:43,620 --> 00:03:47,640
and wins

00:03:47,890 --> 00:03:54,780
this is the collective imagination

00:03:51,750 --> 00:03:59,730
fueled by forward-looking technologies

00:03:54,780 --> 00:04:03,920
and the beginning of your most amazing

00:03:59,730 --> 00:04:03,920
discoveries yet to come

00:04:13,600 --> 00:04:18,859
now you might know Nvidia or is probably

00:04:16,970 --> 00:04:21,769
best known as a company that produces

00:04:18,859 --> 00:04:25,130
graphics cards that go into pcs so you

00:04:21,769 --> 00:04:27,140
can play your video games but the

00:04:25,130 --> 00:04:30,320
company does reinvent it from time to

00:04:27,140 --> 00:04:33,500
time first of all it became went into

00:04:30,320 --> 00:04:36,560
enterprise graphics about a decade ago

00:04:33,500 --> 00:04:39,380
it started the idea of using a graphics

00:04:36,560 --> 00:04:41,540
processor for numerical computation and

00:04:39,380 --> 00:04:44,750
that was when I joined the company and

00:04:41,540 --> 00:04:49,010
then most recently it's now positioning

00:04:44,750 --> 00:04:52,070
itself as the artificial intelligence

00:04:49,010 --> 00:04:53,990
computing company so all of the effort

00:04:52,070 --> 00:04:55,820
of large amounts of effort in silent

00:04:53,990 --> 00:04:57,650
video is being placed upon deep learning

00:04:55,820 --> 00:05:01,160
machine intelligence artificial

00:04:57,650 --> 00:05:04,280
intelligence now I've heard the CEO of

00:05:01,160 --> 00:05:06,770
our company Jensen Hong say nvidia is

00:05:04,280 --> 00:05:12,350
going all in on artificial intelligence

00:05:06,770 --> 00:05:15,080
and when our CEO says something you can

00:05:12,350 --> 00:05:17,300
be absolutely sure that the 10,000

00:05:15,080 --> 00:05:19,400
employees of the company will follow

00:05:17,300 --> 00:05:22,430
that and the reason is that if you don't

00:05:19,400 --> 00:05:26,000
do what he says he is an extremely scary

00:05:22,430 --> 00:05:28,010
guy and you will very quickly has start

00:05:26,000 --> 00:05:30,200
doing what he wants you to do and so as

00:05:28,010 --> 00:05:32,210
a consequence of this strategic decision

00:05:30,200 --> 00:05:34,669
from the top of the company invidious

00:05:32,210 --> 00:05:36,830
has investing heavily throughout the

00:05:34,669 --> 00:05:39,320
company in deep learning and artificial

00:05:36,830 --> 00:05:42,530
intelligence and the reason for this is

00:05:39,320 --> 00:05:45,110
we found that the GPU is the ideal

00:05:42,530 --> 00:05:47,000
computing platform for doing the sorts

00:05:45,110 --> 00:05:50,930
of computational work that's required

00:05:47,000 --> 00:05:53,180
for this task of teaching the world of

00:05:50,930 --> 00:05:55,910
teaching the computer to interact with

00:05:53,180 --> 00:05:59,479
the world in a way in the same sort of

00:05:55,910 --> 00:06:01,340
way as human beings do so these are some

00:05:59,479 --> 00:06:06,080
of a couple of the two or three of the

00:06:01,340 --> 00:06:08,870
key moments within the development of

00:06:06,080 --> 00:06:10,340
the GPU for a car as a computational

00:06:08,870 --> 00:06:12,080
device not just for doing computer

00:06:10,340 --> 00:06:14,990
graphics but but as a device for

00:06:12,080 --> 00:06:17,330
general-purpose computation and several

00:06:14,990 --> 00:06:19,789
times we have now appeared on the front

00:06:17,330 --> 00:06:23,670
cover of nature magazine which is surely

00:06:19,789 --> 00:06:27,430
the the leading source of

00:06:23,670 --> 00:06:29,830
the leading scientific magazine within

00:06:27,430 --> 00:06:32,650
the world and so what we've got here on

00:06:29,830 --> 00:06:36,010
the far left-hand side we have an

00:06:32,650 --> 00:06:38,800
analysis of a key bacterium that was

00:06:36,010 --> 00:06:41,740
related to these the HIV virus so

00:06:38,800 --> 00:06:44,410
analysis of how the model of how the HIV

00:06:41,740 --> 00:06:46,810
virus is working and then we have two

00:06:44,410 --> 00:06:48,970
others which are related to this theme

00:06:46,810 --> 00:06:50,770
of artificial intelligence and in

00:06:48,970 --> 00:06:55,270
particular the one on the left hand side

00:06:50,770 --> 00:06:58,690
is reporting the case where the computer

00:06:55,270 --> 00:07:03,430
has finally be able to master the game

00:06:58,690 --> 00:07:05,500
of Go IBM a decade or maybe it was even

00:07:03,430 --> 00:07:08,680
longer ago managed to master the chess

00:07:05,500 --> 00:07:10,120
game with their my cotton of the name is

00:07:08,680 --> 00:07:12,040
this number there deep blue thank you

00:07:10,120 --> 00:07:13,360
very much I'm sure there a number of IBM

00:07:12,040 --> 00:07:15,490
people in the room who can remind me

00:07:13,360 --> 00:07:17,530
about the deep blue system mastered the

00:07:15,490 --> 00:07:20,860
game of chess it took a little longer

00:07:17,530 --> 00:07:22,540
but now we have also computers that can

00:07:20,860 --> 00:07:24,070
master the game of go because the

00:07:22,540 --> 00:07:25,870
experts work and actually consider the

00:07:24,070 --> 00:07:30,070
go isn't actually a much harder game to

00:07:25,870 --> 00:07:35,280
manage than the than the idea of playing

00:07:30,070 --> 00:07:40,030
chess how does a GPU acceleration work

00:07:35,280 --> 00:07:42,250
so this the GPU is a coprocessor so much

00:07:40,030 --> 00:07:45,490
of your code will continue to execute on

00:07:42,250 --> 00:07:48,280
the CPU as before and this of course it

00:07:45,490 --> 00:07:51,700
can be a se any sort of CPU but of

00:07:48,280 --> 00:07:53,340
course including IBM power CPUs and what

00:07:51,700 --> 00:07:55,750
we have in the architecture is a

00:07:53,340 --> 00:07:58,390
combination of devices a combination of

00:07:55,750 --> 00:08:01,000
processors where we take advantage of

00:07:58,390 --> 00:08:03,700
the strengths of the different of the

00:08:01,000 --> 00:08:07,180
processes within the system so we have

00:08:03,700 --> 00:08:10,300
the CPU it's characterized by a modest

00:08:07,180 --> 00:08:12,700
number of relatively powerful course and

00:08:10,300 --> 00:08:14,860
so it's good when you have relative of

00:08:12,700 --> 00:08:17,560
pieces of code that have relatively less

00:08:14,860 --> 00:08:19,810
parallelism within them whereas the GPU

00:08:17,560 --> 00:08:22,420
on the left on the left hand side of the

00:08:19,810 --> 00:08:25,300
screen has a very large number of

00:08:22,420 --> 00:08:27,700
lightweight course and is relevant when

00:08:25,300 --> 00:08:30,940
you have a high degree of parallelism

00:08:27,700 --> 00:08:32,979
within your code and so by distributing

00:08:30,940 --> 00:08:35,200
your codes your application between the

00:08:32,979 --> 00:08:37,060
two classes of processors you can get

00:08:35,200 --> 00:08:38,919
the best of both worlds and have the

00:08:37,060 --> 00:08:41,349
two classes of professors working

00:08:38,919 --> 00:08:43,570
together on the more parallel and the

00:08:41,349 --> 00:08:45,490
less parallel parts of application so as

00:08:43,570 --> 00:08:51,370
to get over all the the best possible

00:08:45,490 --> 00:08:53,680
throughput but it's not sufficient just

00:08:51,370 --> 00:08:55,870
to perform video to produce a piece of

00:08:53,680 --> 00:08:57,580
hardware and hand it over to the users

00:08:55,870 --> 00:08:59,770
and say here you are please get on with

00:08:57,580 --> 00:09:01,390
it write some applications because

00:08:59,770 --> 00:09:03,670
actually a piece of hardware sitting on

00:09:01,390 --> 00:09:06,940
its own is only a small part of the

00:09:03,670 --> 00:09:10,990
story what you need is the as well as

00:09:06,940 --> 00:09:12,700
the good processors and the good the

00:09:10,990 --> 00:09:14,890
processors GPU processes are

00:09:12,700 --> 00:09:17,110
characterized by two things one is a

00:09:14,890 --> 00:09:19,480
very high floating-point performance and

00:09:17,110 --> 00:09:22,720
the other is the very high memory

00:09:19,480 --> 00:09:25,330
bandwidth but of course you also need to

00:09:22,720 --> 00:09:28,390
go along with that all of the tools that

00:09:25,330 --> 00:09:30,820
the developers need and so you might

00:09:28,390 --> 00:09:33,279
believe or imagine that Nvidia is a

00:09:30,820 --> 00:09:34,720
hardware company but in fact the

00:09:33,279 --> 00:09:37,240
majority of believe it is the majority

00:09:34,720 --> 00:09:38,920
of our of our employees are working on

00:09:37,240 --> 00:09:42,210
software because we have to develop

00:09:38,920 --> 00:09:44,890
compilers libraries debugging tools

00:09:42,210 --> 00:09:47,050
profiling tools and so on so there's a

00:09:44,890 --> 00:09:50,050
vast amount of software work is going on

00:09:47,050 --> 00:09:52,270
inside Nvidia making sure that the

00:09:50,050 --> 00:09:56,350
developments of have all the tools that

00:09:52,270 --> 00:09:58,570
they need but as well as all of the

00:09:56,350 --> 00:10:01,089
tools we also have within our company a

00:09:58,570 --> 00:10:04,240
number of domain experts so we have

00:10:01,089 --> 00:10:05,950
people who know about CFD we have people

00:10:04,240 --> 00:10:08,610
who know about quantum chemistry we have

00:10:05,950 --> 00:10:12,670
people who know about quantum mechanics

00:10:08,610 --> 00:10:17,950
molecular dynamics CID modeling and so

00:10:12,670 --> 00:10:19,839
we can work together with both users and

00:10:17,950 --> 00:10:21,970
the developers of new platforms to

00:10:19,839 --> 00:10:25,209
ensure that they have a platform that

00:10:21,970 --> 00:10:27,850
suits the requirements of the GPU and is

00:10:25,209 --> 00:10:29,470
the most performance system and then

00:10:27,850 --> 00:10:32,650
finally of course we want people to have

00:10:29,470 --> 00:10:35,589
access to the platforms and IBM

00:10:32,650 --> 00:10:37,600
SoftLayer cloud system does indeed offer

00:10:35,589 --> 00:10:40,260
GPUs to users today and there are many

00:10:37,600 --> 00:10:40,260
others as well

00:10:40,410 --> 00:10:45,400
so the latest products coming from video

00:10:43,270 --> 00:10:47,680
which works and i'll show you how you

00:10:45,400 --> 00:10:50,350
can deploy this GPU within the context

00:10:47,680 --> 00:10:56,070
of power processors very shortly is the

00:10:50,350 --> 00:10:59,260
tesla p100 so this is a new architecture

00:10:56,070 --> 00:11:01,210
IBM was very deeply involved with the

00:10:59,260 --> 00:11:03,190
bring up of this system and the design

00:11:01,210 --> 00:11:06,010
of the system because one of the key

00:11:03,190 --> 00:11:09,010
characteristics of the tesla p100 is

00:11:06,010 --> 00:11:11,500
this second box which is envy link which

00:11:09,010 --> 00:11:13,750
is a high-speed bus that allows you both

00:11:11,500 --> 00:11:18,210
to transfer data from one GPU to another

00:11:13,750 --> 00:11:20,590
but also between the GPU and the cpu and

00:11:18,210 --> 00:11:22,510
IBM is the company that had the

00:11:20,590 --> 00:11:26,170
foresight to know to know that it's very

00:11:22,510 --> 00:11:29,050
important to have an i have a high-speed

00:11:26,170 --> 00:11:30,670
interface between CPW and GPU so you can

00:11:29,050 --> 00:11:33,400
move data quickly between the two

00:11:30,670 --> 00:11:36,160
processes within the system and so IBM

00:11:33,400 --> 00:11:38,380
engineers were at our site on the day

00:11:36,160 --> 00:11:42,550
that we got the very first samples back

00:11:38,380 --> 00:11:43,870
from the chip chip foundry and just a

00:11:42,550 --> 00:11:45,910
few days later I think they went away

00:11:43,870 --> 00:11:47,890
with a few samples of their own so they

00:11:45,910 --> 00:11:51,880
can then start seeing how well the

00:11:47,890 --> 00:11:56,590
Pascal GPUs would integrate with within

00:11:51,880 --> 00:11:58,090
the IBM power platform what else we got

00:11:56,590 --> 00:12:00,400
we got a couple of things here we've got

00:11:58,090 --> 00:12:02,650
a high very high bandwidth memory system

00:12:00,400 --> 00:12:04,660
so gddr5 memory is pretty much running

00:12:02,650 --> 00:12:07,150
out of steam but luckily the next

00:12:04,660 --> 00:12:09,670
generation of stacked memories coming

00:12:07,150 --> 00:12:12,610
along to replace that and then finally

00:12:09,670 --> 00:12:15,400
we have some extra aids to help the

00:12:12,610 --> 00:12:20,620
developer port their applications to the

00:12:15,400 --> 00:12:23,530
GPU platform so the GPU the pascal p100

00:12:20,620 --> 00:12:26,560
is available within the Minsky servers

00:12:23,530 --> 00:12:31,300
you can have up to four GPUs within this

00:12:26,560 --> 00:12:34,240
platform as I said IBM is the had the

00:12:31,300 --> 00:12:36,580
good for sites the good engineering

00:12:34,240 --> 00:12:39,480
understanding that into tight coupling

00:12:36,580 --> 00:12:42,220
between the GPU and CPU was important

00:12:39,480 --> 00:12:45,610
this platform is this Minsky platform is

00:12:42,220 --> 00:12:47,920
now available for for sale and would be

00:12:45,610 --> 00:12:49,780
a good way for people to get hold of

00:12:47,920 --> 00:12:51,160
GPUs and start using them and I know

00:12:49,780 --> 00:12:52,370
that there are a number of people within

00:12:51,160 --> 00:12:55,010
the open

00:12:52,370 --> 00:12:57,529
community who was already starting to

00:12:55,010 --> 00:12:59,480
have had I see one here from STFC I

00:12:57,529 --> 00:13:02,360
think already have some systems here

00:12:59,480 --> 00:13:04,640
available so that concludes my

00:13:02,360 --> 00:13:06,820
presentation so thank you for for your

00:13:04,640 --> 00:13:06,820
time

00:13:22,860 --> 00:13:24,920

YouTube URL: https://www.youtube.com/watch?v=K3NqvQG27Pk


