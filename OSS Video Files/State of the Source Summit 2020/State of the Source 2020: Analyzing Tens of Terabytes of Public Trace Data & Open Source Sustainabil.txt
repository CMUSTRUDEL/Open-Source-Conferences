Title: State of the Source 2020: Analyzing Tens of Terabytes of Public Trace Data & Open Source Sustainabil
Publication date: 2020-09-17
Playlist: State of the Source Summit 2020
Description: 
	What can analyzing tens of terabytes of public trace data tell us about open source sustainability?
Bogdan Vasilescu and Christian Kaestner

Open-source communities face significant sustainability challenges, from attracting and retaining a diverse set of contributors, to fundraising. Through interviews, surveys, and analysis of billions of commits and other public traces, we studied the organization, functioning, and overall health of open-source communities. Among others, we found that donations are not promising for the vast majority of maintainers and that team demographic diversity correlates with higher productivity.

Session Slides:Â https://cmustrudel.github.io//slides/state-of-the-source.pdf

Thank you to our Video Recordings Sponsor eng@salesforce!
Full Program: https://eventyay.com/e/8fa7fd14/schedule
Captions: 
	00:00:04,080 --> 00:00:08,160
all right welcome hi this is Bogdan this is Christian

00:00:08,160 --> 00:00:10,800
we want to talk a little bit about our research on

00:00:10,800 --> 00:00:14,960
open source sustainability and how we use a large amount of trace data to find

00:00:14,960 --> 00:00:17,920
interesting things let's do it so we want to talk about open source

00:00:17,920 --> 00:00:20,560
sustainability i don't think we really need to under

00:00:20,560 --> 00:00:23,760
introduce the challenges right we all know this is hard

00:00:23,760 --> 00:00:27,920
but i think there's also the insight that there's a huge amount of trace data

00:00:27,920 --> 00:00:31,599
in there that we can study and where we can find lots of interesting things that

00:00:31,599 --> 00:00:34,239
makes us learn more about problems and possible

00:00:34,239 --> 00:00:38,559
solutions what we want to do in this talk is talk a little bit about

00:00:38,559 --> 00:00:41,840
how we're using large amounts many terabytes of trace

00:00:41,840 --> 00:00:45,760
data to study open source and some of the findings that we have found

00:00:45,760 --> 00:00:50,879
we've done this for years now a bit of a disclaimer we are both academics we

00:00:50,879 --> 00:00:54,480
teach at carnegie mellon um this is a picture from carnegie mellon

00:00:54,480 --> 00:00:58,079
these are our ivory towers although these days i think this is more

00:00:58,079 --> 00:01:01,520
what our research looks like and this is these are our ivory towers

00:01:01,520 --> 00:01:06,320
but the important part here i think is we're here at this conference because we

00:01:06,320 --> 00:01:09,920
want to share some of the results and we more importantly we want to learn from

00:01:09,920 --> 00:01:12,640
you right we want to engage with the community

00:01:12,640 --> 00:01:16,240
study some of the problems bring some of the results into the community

00:01:16,240 --> 00:01:20,159
about our incorrect assumptions or about some problems some other problems that

00:01:20,159 --> 00:01:24,080
you're facing that we haven't considered and so on

00:01:24,240 --> 00:01:27,520
so open source has changed over the last couple of years

00:01:27,520 --> 00:01:31,680
uh decades right it used to be kind of this hippie thing maybe in the 90s or

00:01:31,680 --> 00:01:35,439
even 80s uh rich white guys with a lot of spare

00:01:35,439 --> 00:01:39,360
time would hack on some software (and long hair!)

00:01:39,360 --> 00:01:42,479
and things have changed first of all open source has become

00:01:42,479 --> 00:01:46,720
way more popular right it's so much open source out there and it's so broadly

00:01:46,720 --> 00:01:49,439
used there's nobody questioning this anymore

00:01:49,439 --> 00:01:52,799
but there's also rise of social coding platforms like

00:01:52,799 --> 00:01:56,320
github has really popularized this everybody has a github profile these

00:01:56,320 --> 00:02:00,159
days right it's ucb according to some you can learn

00:02:00,159 --> 00:02:03,119
a lot of the about the project so if you're thinking

00:02:03,119 --> 00:02:07,040
about adopting one of these projects you can learn so much with just a glance

00:02:07,040 --> 00:02:10,319
on the project page how many contributors how active is it

00:02:10,319 --> 00:02:13,760
right how recently who's working on this what else are they doing

00:02:13,760 --> 00:02:17,360
and people studies have shown people use this actually to make decisions

00:02:17,360 --> 00:02:22,080
right it's it's very different uh there's a lot of information available i

00:02:22,080 --> 00:02:24,239
heard you can't get an interview unless you have a

00:02:24,239 --> 00:02:28,800
github profile in some places unfortunately

00:02:28,800 --> 00:02:35,519
it's also really complicated lots of um not complicated but lots of dependencies

00:02:35,519 --> 00:02:40,000
right so no project is an island anymore every project depends on nearly every

00:02:40,000 --> 00:02:45,440
project depends on many others and on any other contributors there

00:02:45,440 --> 00:02:48,640
this is most visible when it breaks down right so

00:02:48,640 --> 00:02:52,080
the heartbleed case is very common where um

00:02:52,080 --> 00:02:56,080
this project that was universally used by so many other projects

00:02:56,080 --> 00:03:00,319
maybe three half-time maintainers had a bug and it affected everybody

00:03:00,319 --> 00:03:05,120
right the um left pet issue is equally well known right so this is

00:03:05,120 --> 00:03:09,840
actually visible when it's breaking but there's lots of challenges we're

00:03:09,840 --> 00:03:13,519
depending so much on software that's maintained by others

00:03:13,519 --> 00:03:18,000
right layers and layers and then it also the nature of the game changes we have

00:03:18,000 --> 00:03:22,400
lots of volunteers working together with professional developers paid

00:03:22,400 --> 00:03:25,159
developers right we see an increasing commercialization and

00:03:25,159 --> 00:03:29,519
professionalization even in the opens in the volunteer

00:03:29,519 --> 00:03:32,400
communities we see more process more governance

00:03:32,400 --> 00:03:37,120
and then we see lots of companies big companies small companies startups that

00:03:37,120 --> 00:03:41,120
make money with open source that donate that donate their code as open source

00:03:41,120 --> 00:03:44,239
that have their own software release it for

00:03:44,239 --> 00:03:47,360
others to use right and what happens is that

00:03:47,360 --> 00:03:51,200
volunteers and paid developers work together

00:03:51,200 --> 00:03:55,920
sometimes better sometimes this is causing conflicts

00:03:55,920 --> 00:03:58,159
um

00:03:59,040 --> 00:04:05,599
and actually these projects there's this notion of um catastrophic success of an

00:04:05,599 --> 00:04:10,400
open source project um where the project that you start as a

00:04:10,400 --> 00:04:13,280
volunteer suddenly becomes so popular that everybody

00:04:13,280 --> 00:04:16,799
depends on it right and it's suddenly used in critical places where

00:04:16,799 --> 00:04:21,359
you didn't depend on this uh where you didn't expect it in extreme

00:04:21,359 --> 00:04:26,639
cases here maybe apache struts which was blamed publicly by equifax when equifax

00:04:26,639 --> 00:04:31,680
got hacked three years ago right so this big company never donated

00:04:31,680 --> 00:04:35,520
to open source that didn't contribute to this project was using this in all parts

00:04:35,520 --> 00:04:39,600
of their system publicly in the news blame this open

00:04:39,600 --> 00:04:43,280
source project for the attack it's actually interesting

00:04:43,280 --> 00:04:46,479
you should go and read the congressional report that actually tells

00:04:46,479 --> 00:04:51,199
a much more nuanced story yes there was a vulnerability but there were so many

00:04:51,199 --> 00:04:55,120
issues in how equifax internally internal process

00:04:55,120 --> 00:05:00,080
and structure and things like this um it's a fascinating reading yeah yeah

00:05:00,080 --> 00:05:03,680
um and this brings me to this point that

00:05:03,680 --> 00:05:06,560
the equifax cases may be a little bit extreme but

00:05:06,560 --> 00:05:11,840
think about the poor maintainers in those are consultants who are doing this

00:05:11,840 --> 00:05:15,759
as part of their work right but being blamed being in the national news

00:05:15,759 --> 00:05:19,919
for this we hear stories over and over again how people complain

00:05:19,919 --> 00:05:22,240
about their workload about being burned out

00:05:22,240 --> 00:05:26,320
about toxicity in the interactions that they have with the community

00:05:26,320 --> 00:05:31,280
it's it's really turning off some contributors

00:05:31,280 --> 00:05:35,440
and there's really questions here how can we make this a welcoming and

00:05:35,440 --> 00:05:40,639
sustainable community so there are lots of questions here lots of

00:05:40,639 --> 00:05:43,440
challenges what are best practices that we can

00:05:43,440 --> 00:05:47,919
recommend what works what doesn't work what really helps for sustainability

00:05:47,919 --> 00:05:52,080
right things are changing all the time we need to change our practices but

00:05:52,080 --> 00:05:54,639
don't people have lots of opinions about these

00:05:54,639 --> 00:06:00,240
yeah um and often good uh opinions right from experience from their projects from

00:06:00,240 --> 00:06:04,160
other projects that they know but a lot of this is anecdotal evidence

00:06:04,160 --> 00:06:08,319
right we saw this in a lot of studies when we talked to developers

00:06:08,319 --> 00:06:11,360
they know very well they have opinions why they're doing this

00:06:11,360 --> 00:06:14,479
and they can point to other projects where this has been successful

00:06:14,479 --> 00:06:18,880
but they rarely ever have a really good overview of all the design decisions

00:06:18,880 --> 00:06:22,400
and they rarely ever have evidence behind what they're doing

00:06:22,400 --> 00:06:25,680
and i think this is where science can actually help

00:06:25,680 --> 00:06:29,680
exactly we can go beyond just anecdotal evidence

00:06:29,680 --> 00:06:32,880
this is actually a great research opportunity here and that's what we've

00:06:32,880 --> 00:06:38,400
been trying to do for the last few years uh on this um and the fact that

00:06:38,400 --> 00:06:42,000
the practices have been more than standardized since that have uh

00:06:42,000 --> 00:06:45,360
existed uh most people are using git now for their version control they're

00:06:45,360 --> 00:06:47,759
contributing through this pull request model

00:06:47,759 --> 00:06:51,919
everybody has these profile pages rich with information

00:06:51,919 --> 00:06:54,880
all of this is sort of more or less standardized in uniform by now this

00:06:54,880 --> 00:06:57,840
makes it a lot easier for people like us for researchers

00:06:57,840 --> 00:07:03,520
to mine and analyze this kind of data and there's lots of it okay i don't know

00:07:03,520 --> 00:07:09,120
if you know this but there's uh 50 million people 50 million people

00:07:09,120 --> 00:07:12,800
that's twice the size of romania 50 million people

00:07:12,800 --> 00:07:16,000
on github over 100 billion repositories as of last year

00:07:16,000 --> 00:07:19,120
and many of them are active not all of them but a large number

00:07:19,120 --> 00:07:23,039
many are active that's right um some colleagues at the university of

00:07:23,039 --> 00:07:27,520
tennessee try to quantify how much disk space all of these public git

00:07:27,520 --> 00:07:32,160
repositories on the internet take and they came to a petabyte or two of

00:07:32,160 --> 00:07:34,800
storage uh more than a year ago so it's probably

00:07:34,800 --> 00:07:37,759
much much bigger by now just for comparison this is already

00:07:37,759 --> 00:07:41,599
bigger than wikipedia and you know the thing is this is a

00:07:41,599 --> 00:07:44,240
really great opportunity for research right

00:07:44,240 --> 00:07:49,440
having access to this big rich data set because you can go from you know

00:07:49,440 --> 00:07:52,639
anecdotes and small scale studies that people may have done

00:07:52,639 --> 00:07:55,520
you could go from these to something much much bigger something that's much

00:07:55,520 --> 00:07:58,800
more likely to generalize to a large population like here

00:07:58,800 --> 00:08:03,120
um for example right you could do a census of all the donation platforms

00:08:03,120 --> 00:08:06,879
across all of github and we've done this and you know we found that paypal is

00:08:06,879 --> 00:08:10,479
maybe the most popular and patreon and others are are used as well

00:08:10,479 --> 00:08:12,240
i'm going to talk about this a bit more yeah

00:08:12,240 --> 00:08:15,520
we're going to come back to this another really cool thing

00:08:15,520 --> 00:08:19,440
is that all of this data is timestamp it's longitudinal okay so you know think

00:08:19,440 --> 00:08:22,319
of comments and issues and what have your emails whatever

00:08:22,319 --> 00:08:25,599
messages communications all of this is timestamp

00:08:25,599 --> 00:08:29,759
so you can reconstruct the the timeline of

00:08:29,759 --> 00:08:33,039
all of these events and you could reason about

00:08:33,039 --> 00:08:36,560
changes to files for example or reason about people

00:08:36,560 --> 00:08:41,599
joining or leaving projects based on based on these traces and these

00:08:41,599 --> 00:08:45,680
timestamps of events to give you another example okay the way

00:08:45,680 --> 00:08:49,680
we found these um these donation platforms is by

00:08:49,680 --> 00:08:53,440
tracking the history of changes to people's readme files in the

00:08:53,440 --> 00:08:57,920
repositories because that tells us exactly because

00:08:57,920 --> 00:09:01,600
they mentioned their donation platforms in

00:09:01,600 --> 00:09:04,880
their github readmes we could tell exactly when they started

00:09:04,880 --> 00:09:08,320
using any particular platform because there's a commit that's introduced that

00:09:08,320 --> 00:09:12,240
link in there and even which maintainers introduced it and even which maintainer

00:09:12,240 --> 00:09:15,200
introduced this and this way we can begin to understand

00:09:15,200 --> 00:09:18,080
these trends over time we can begin to reason about how

00:09:18,080 --> 00:09:22,080
some things are uh have changed and which things are popular and so on and

00:09:22,080 --> 00:09:27,120
that is really useful but so this is all great and you can you

00:09:27,120 --> 00:09:29,360
know describe and begin to understand the

00:09:29,360 --> 00:09:32,640
ecosystem this way but what if you want to actually do something about

00:09:32,640 --> 00:09:36,080
sustainability what if you want to i don't know design a new intervention

00:09:36,080 --> 00:09:39,680
to make open source more sustainable that's what you should learn christian i

00:09:39,680 --> 00:09:42,640
keep saying this christian keeps saying that everybody

00:09:42,640 --> 00:09:46,320
needs to learn how to juggle and i tend to disagree and you know to

00:09:46,320 --> 00:09:49,760
resolve this dispute between us like what can you do you can you can run this

00:09:49,760 --> 00:09:52,399
as a medical trial as an experiment so you

00:09:52,399 --> 00:09:57,600
for example would randomly assign uh maintainers to either juggle or not

00:09:57,600 --> 00:10:01,440
and you could see you know you could measure them before

00:10:01,440 --> 00:10:04,640
and after and you could see if there's any effect

00:10:04,640 --> 00:10:08,640
in the group that learn how to juggle if their projects are more sustainable if

00:10:08,640 --> 00:10:10,880
they're happier and less likely to burn out

00:10:10,880 --> 00:10:18,240
okay except you know we can't really do this because while juggling is really

00:10:18,240 --> 00:10:20,640
boring

00:10:21,040 --> 00:10:26,959
and because it's not always practical to run experiments in in this way but we

00:10:26,959 --> 00:10:31,839
could do something that tries to get us close to this as

00:10:31,839 --> 00:10:35,600
possible we could um think of these different things that

00:10:35,600 --> 00:10:39,360
people may have think of these possible interventions as

00:10:39,360 --> 00:10:43,519
natural interventions chances are that somebody somewhere and

00:10:43,519 --> 00:10:47,680
this giant ecosystem has tried this before

00:10:47,680 --> 00:10:50,959
and in fact chances are there's sufficiently many of them and you could

00:10:50,959 --> 00:10:55,040
actually using statistics right instead of random assignment we can't really do

00:10:55,040 --> 00:10:58,240
random assignment by using statistics we can begin to

00:10:58,240 --> 00:11:01,519
separate the effects of say juggling right whatever

00:11:01,519 --> 00:11:03,760
favorite intervention you have from these other

00:11:03,760 --> 00:11:06,800
things that are correlated this is where the analogy breaks down

00:11:06,800 --> 00:11:09,839
because it's hard to detect who's struggling but

00:11:09,839 --> 00:11:15,279
things like tool adoption donations there are lots of interventions in study

00:11:15,279 --> 00:11:18,640
so this is all great but there's no free lunch

00:11:18,640 --> 00:11:23,680
um we could spend literally a whole day talking about all the ways in which you

00:11:23,680 --> 00:11:26,800
could misinterpret or this data or all the ways in which is

00:11:26,800 --> 00:11:32,720
noisy just to give you one example say you're looking at this contribution

00:11:32,720 --> 00:11:36,480
graph of uh of a maintainer would this tell

00:11:36,480 --> 00:11:40,079
you that this is a very sustainable project almost six thousand

00:11:40,079 --> 00:11:44,480
contributions last year but there's no single day in which they

00:11:44,480 --> 00:11:46,720
took a break they've been active the whole year

00:11:46,720 --> 00:11:49,920
it seems pretty exhausting but turns out this is actually

00:11:49,920 --> 00:11:56,959
not a not a human it's it's a bug shopping so the point here is that there

00:11:56,959 --> 00:12:00,320
are so many of these gotchas um that if you just

00:12:00,320 --> 00:12:05,760
sort of um blindly uh mine and analyze this data

00:12:05,760 --> 00:12:09,600
chances are you would arrive at the wrong

00:12:09,600 --> 00:12:12,240
conclusions just because of all this immense noise

00:12:12,240 --> 00:12:15,440
and you know we've spent years cleaning and so on understanding these and we're

00:12:15,440 --> 00:12:18,480
still uh and you find some results in any

00:12:18,480 --> 00:12:21,600
noise you find right so that's the thing okay

00:12:21,600 --> 00:12:24,720
so with data sets this big you always find

00:12:24,720 --> 00:12:27,839
some results somewhere there's always a correlation somewhere you always detect

00:12:27,839 --> 00:12:31,200
something so how do you actually know if it's if

00:12:31,200 --> 00:12:34,240
it's real or not right for example the data could

00:12:34,240 --> 00:12:38,079
show you that this particular person dropped out at

00:12:38,079 --> 00:12:40,320
some point because the number of commits they were making

00:12:40,320 --> 00:12:45,440
uh just dropped significantly how do you actually know what happened

00:12:45,440 --> 00:12:48,959
so the only way to do this you can't just by looking at this data the only

00:12:48,959 --> 00:12:53,519
way to do this is to go beyond and to look at for example decades of

00:12:53,519 --> 00:12:57,519
literature in the social sciences people have studied turnover and other things

00:12:57,519 --> 00:13:00,480
group dynamics and team composition and all these things

00:13:00,480 --> 00:13:05,279
actually ask them or you could just ask them yeah why not

00:13:05,279 --> 00:13:09,040
okay so that's about it in terms of methods

00:13:09,040 --> 00:13:13,120
let's actually look at some concrete examples of research findings from these

00:13:13,120 --> 00:13:14,880
different studies that we've done over the years

00:13:14,880 --> 00:13:18,880
and we've done quite a few of these um we won't have time to cover all of these

00:13:18,880 --> 00:13:22,160
and so many other researchers have done other studies

00:13:22,160 --> 00:13:25,519
but we we're just picking a few examples here right

00:13:25,519 --> 00:13:28,880
things that we think are interesting to share and we want to start

00:13:28,880 --> 00:13:32,720
with donations all right let's start with the first thing um

00:13:32,720 --> 00:13:36,720
we already mentioned donations right um there's lots of discussions of open

00:13:36,720 --> 00:13:39,120
source and money and it's kind of controversial

00:13:39,120 --> 00:13:42,160
um this is actually interesting this is not your equivalent

00:13:42,160 --> 00:13:45,519
lemonade stand the guide to all the different or many different

00:13:45,519 --> 00:13:49,199
approaches to fund open source and there's so many different approaches

00:13:49,199 --> 00:13:53,600
including consulting and donations and crowdfunding and

00:13:53,600 --> 00:13:57,440
selling books and just being part of a larger company

00:13:57,440 --> 00:14:02,880
but we wanted to look at we wanted to look at donations right so

00:14:02,880 --> 00:14:06,000
um this is still controversial what works what doesn't work

00:14:06,000 --> 00:14:10,240
uh donations are getting extremely popular github itself has integrated a

00:14:10,240 --> 00:14:12,240
feature where you can ask for donations from

00:14:12,240 --> 00:14:17,839
github itself right but whether it really works what's the

00:14:17,839 --> 00:14:21,120
effectiveness that's kind of still controversial and

00:14:21,120 --> 00:14:25,199
we also won't have a final solution here but you see lots of anecdotes right

00:14:25,199 --> 00:14:28,639
people who are really happy about receiving donations and

00:14:28,639 --> 00:14:32,560
funding this people are really critical about this

00:14:32,560 --> 00:14:35,920
people are frustrated about not sustaining their work even though

00:14:35,920 --> 00:14:39,600
they want um there's prior work on this showing that

00:14:39,600 --> 00:14:43,519
even popular projects often only get very small amounts of donations when

00:14:43,519 --> 00:14:47,279
we're asking often beyond below the u.s poverty line for example

00:14:47,279 --> 00:14:51,279
so you couldn't fund your lifestyle of this and it's certainly below

00:14:51,279 --> 00:14:55,199
typically industry standards right there's a question of whether you

00:14:55,199 --> 00:14:58,079
should fund your lifestyle through open source it's maybe

00:14:58,079 --> 00:15:02,240
a separate question but if you wanted to could you right so

00:15:02,240 --> 00:15:05,600
there are lots of things to explore here just a couple of things that we looked

00:15:05,600 --> 00:15:09,279
in in our study um like how prevalent are

00:15:09,279 --> 00:15:13,120
donations who's receiving donations what is the money used for

00:15:13,120 --> 00:15:17,120
are they effective right and the study is actually more complicated we looked

00:15:17,120 --> 00:15:21,680
at many different data sources like all the data from github a huge amount

00:15:21,680 --> 00:15:25,760
of readme project metrics we also looked at lots

00:15:25,760 --> 00:15:29,519
of donation pages kind of read through a lot of things also the research methods

00:15:29,519 --> 00:15:32,639
are different but let me just show you some results as

00:15:32,639 --> 00:15:37,440
shown earlier we used mainly readme pages to quantify how

00:15:37,440 --> 00:15:43,600
often do people ask for the donations right we find as brockman has shown

00:15:43,600 --> 00:15:46,639
earlier that donations are common there are platforms that are

00:15:46,639 --> 00:15:51,920
common but it's also as we know already um not a lot of projects that

00:15:51,920 --> 00:15:55,120
ask for donations get large amounts of donations right

00:15:55,120 --> 00:15:59,040
actually a good chunk of projects where we can observe those

00:15:59,040 --> 00:16:02,959
with patreon or open collected actually don't receive any motivation

00:16:02,959 --> 00:16:06,839
just think about this if you as a maintainer ask for donation and nobody's

00:16:06,839 --> 00:16:10,240
responding there's much more analysis that we can

00:16:10,240 --> 00:16:13,040
do we've for example looked at who's asking for

00:16:13,040 --> 00:16:17,759
a donation and who's receiving donations in a paper you see a lot of kind of

00:16:17,759 --> 00:16:20,959
statistics here i'm not going to go into the details it looks

00:16:20,959 --> 00:16:25,279
a lot like this but i would just want to show you some of the results

00:16:25,279 --> 00:16:28,959
for example the projects that are asking for donations compared to all the other

00:16:28,959 --> 00:16:33,279
ones that are not asking right the majority is not asking the projects that

00:16:33,279 --> 00:16:36,079
are asking for donations tend to be more active and

00:16:36,079 --> 00:16:39,759
more popular so they already have a platform when they're asking

00:16:39,759 --> 00:16:43,839
but they also tend to be somewhat smaller in personal accounts rather than

00:16:43,839 --> 00:16:47,519
organizational accounts indicating that the very large and

00:16:47,519 --> 00:16:51,120
popular projects they probably don't fund themselves that much through

00:16:51,120 --> 00:16:54,560
donations or they already have organizations that provide some other

00:16:54,560 --> 00:16:58,720
form of support right so there's a certain issue but if

00:16:58,720 --> 00:17:05,280
we try to understand which projects actually get more donations than others

00:17:05,280 --> 00:17:10,079
of the ones that are getting any the signals become really thin um it's

00:17:10,079 --> 00:17:12,799
not that we see very clear trends the only

00:17:12,799 --> 00:17:17,520
trend that remains is kind of popularity projects that have more stars projects

00:17:17,520 --> 00:17:20,160
that have more downloads those tend to be the ones

00:17:20,160 --> 00:17:24,240
that are more successful in gaining donations but otherwise there are no

00:17:24,240 --> 00:17:27,280
really large trends so i think there's a lot of

00:17:27,280 --> 00:17:33,440
opportunities to study more to identify good fundraising strategies for example

00:17:33,440 --> 00:17:39,440
beyond just a platform trends we also looked a little bit into what do

00:17:39,440 --> 00:17:43,440
people expect to get from donations this is by reading the descriptions actually

00:17:43,440 --> 00:17:46,000
a lot of people don't say anything but among the people

00:17:46,000 --> 00:17:49,919
who say something they often talk about engineering they talk about community

00:17:49,919 --> 00:17:54,320
supporting their community supporting project expenses like server costs or

00:17:54,320 --> 00:17:58,000
even just personal expenses like i need to pay back my student loans

00:17:58,000 --> 00:18:02,080
right rather than saying i want to invest in a certain feature

00:18:02,080 --> 00:18:07,039
um in a couple of platforms especially open collective we can observe how the

00:18:07,039 --> 00:18:10,559
money is spent and this is also interesting the number of interesting

00:18:10,559 --> 00:18:14,480
insights so a lot of projects get way more donations than they are

00:18:14,480 --> 00:18:18,960
spending right not not a lot but um actually a lot of

00:18:18,960 --> 00:18:23,200
projects are savers especially if they get small amount of

00:18:23,200 --> 00:18:26,880
donations they seem to amount kind of accumulate this for rainy days maybe

00:18:26,880 --> 00:18:31,200
and the expenses that they're using on

00:18:31,200 --> 00:18:34,240
is largely engineering especially projects that get quite a bit of

00:18:34,240 --> 00:18:37,120
donations of poverty line level they actually pay

00:18:37,120 --> 00:18:41,679
mostly for engineering projects in smaller settings to find

00:18:41,679 --> 00:18:46,320
services but again we have some initial

00:18:46,320 --> 00:18:49,200
observations right we can control for a lot of

00:18:49,200 --> 00:18:52,400
data here we are pretty confident that certain trends

00:18:52,400 --> 00:18:55,440
persist across all the work and a lot of things don't

00:18:55,440 --> 00:18:59,760
persist but there's also a huge amount of room for more and especially bringing

00:18:59,760 --> 00:19:03,520
in theory right you talked about this before there's a huge amount of

00:19:03,520 --> 00:19:06,960
knowledge about fundraising in philanthropy

00:19:06,960 --> 00:19:09,520
i was going to ask is there anything that people could do to be more

00:19:09,520 --> 00:19:13,760
effective so so looking in the literature there

00:19:13,760 --> 00:19:17,679
are a couple of things right so the reputation matters for

00:19:17,679 --> 00:19:20,960
charities and so this is what we see here right so

00:19:20,960 --> 00:19:24,880
more popular projects more active projects they tend to

00:19:24,880 --> 00:19:29,440
attract more donations this is probably a reputation mechanism but the

00:19:29,440 --> 00:19:32,640
literature also talks about awareness for needs

00:19:32,640 --> 00:19:36,240
and this is something that we don't see people doing a lot of kind of really

00:19:36,240 --> 00:19:40,880
explaining why they do need no donations what they needed for right so

00:19:40,880 --> 00:19:45,200
some projects explain this but the vast majority does not and the efficiency of

00:19:45,200 --> 00:19:47,840
using funds is also something that has been studied

00:19:47,840 --> 00:19:52,559
a lot in traditional uh philanthropy like effective altruism

00:19:52,559 --> 00:19:56,160
things like this right so this is something that has we

00:19:56,160 --> 00:19:59,679
haven't seen much attention to actually explaining uh

00:19:59,679 --> 00:20:03,840
beyond kind of a patriarch open collective kind of data

00:20:03,840 --> 00:20:07,360
what money was used for what was it successful

00:20:07,360 --> 00:20:13,120
you mean giving a report back to the donors so some projects do this but i

00:20:13,120 --> 00:20:16,559
think it's not as common as we might expect in other

00:20:16,559 --> 00:20:19,840
areas and there's also a dark side to donations which is pretty well

00:20:19,840 --> 00:20:22,240
understood if for example if you give people a

00:20:22,240 --> 00:20:26,240
little bit of money they turn from self-motivated volunteers

00:20:26,240 --> 00:20:29,120
into underpaid employees right and this can actually be

00:20:29,120 --> 00:20:34,640
demotivated that's how i feel my day job right so let me move on to a different

00:20:34,640 --> 00:20:38,640
topic a key to us being able to study

00:20:38,640 --> 00:20:41,760
the how people use these donation platforms

00:20:41,760 --> 00:20:46,080
was the fact that they were mentioning them in their readme files

00:20:46,080 --> 00:20:49,440
and often it was through these these badges that you see they're embedded in

00:20:49,440 --> 00:20:51,919
in this bb file that we were able to detect

00:20:51,919 --> 00:20:55,840
which services people are using now this is actually really interesting if you

00:20:55,840 --> 00:21:00,400
think about it a little bit because uh transparency and so the all

00:21:00,400 --> 00:21:04,720
these social features are already so fundamentally part of the

00:21:04,720 --> 00:21:07,520
platform they're a defining characteristic of the platform and the

00:21:07,520 --> 00:21:10,880
environment by themselves but this goes beyond this is

00:21:10,880 --> 00:21:13,200
more than just what the platform

00:21:13,200 --> 00:21:16,080
directly provides this is stuff that people

00:21:16,080 --> 00:21:20,159
deliberately customize and add to their own projects and they'll

00:21:20,159 --> 00:21:24,080
add to their readme files okay so you know you can see all kinds of these

00:21:24,080 --> 00:21:27,600
different badges uh there's a whole variety of them that

00:21:27,600 --> 00:21:31,200
people adopt and embed in the readme files and

00:21:31,200 --> 00:21:33,840
presumably they're trying to signal something to

00:21:33,840 --> 00:21:37,679
to their audience and their users yeah i mean i can see high test coverage here

00:21:37,679 --> 00:21:40,480
right they use continuous integration these

00:21:40,480 --> 00:21:43,280
tend to be good signs for a project right right right so

00:21:43,280 --> 00:21:47,120
we actually wanted to study this more rigorously to see

00:21:47,120 --> 00:21:52,480
what if any facts doing this has on these communities and these

00:21:52,480 --> 00:21:56,240
projects so um let's go back to the beginning

00:21:56,240 --> 00:21:59,760
when we're talking about these these time series and the longitudinal

00:21:59,760 --> 00:22:04,000
nature of the data okay so here let's say we're interested

00:22:04,000 --> 00:22:09,679
in studying um what the effect of adopting or displaying this dependency

00:22:09,679 --> 00:22:13,760
management badge is okay the fact that all of this data

00:22:13,760 --> 00:22:16,559
is versioned allows us to reason about this over time

00:22:16,559 --> 00:22:20,240
so what i'm showing you here is i'm showing you how fresh people's

00:22:20,240 --> 00:22:23,679
dependencies are in a particular project on average the

00:22:23,679 --> 00:22:26,480
lower is better here the lower the fresher okay

00:22:26,480 --> 00:22:29,840
and i'm showing this over a period of time

00:22:29,840 --> 00:22:34,000
before and after they started managing their dependencies and

00:22:34,000 --> 00:22:37,679
displaying these badges in their readings okay and you can see in this

00:22:37,679 --> 00:22:41,919
one project that i'm showing here how after they started doing this their

00:22:41,919 --> 00:22:44,559
dependencies got all of a sudden much much fresher

00:22:44,559 --> 00:22:50,720
okay so here's the the cool thing if you take all of the projects that

00:22:50,720 --> 00:22:55,039
adopted the same badge it doesn't matter when that happened

00:22:55,039 --> 00:22:58,799
okay but because you have this intervention that they were all exposed

00:22:58,799 --> 00:23:02,960
to think of this badge as an intervention right you can then align

00:23:02,960 --> 00:23:05,760
all of these different time series and sort of look at these

00:23:05,760 --> 00:23:10,080
strands in aggregate over the entire sampler population this is how you get

00:23:10,080 --> 00:23:13,679
from anecdotes to entire trends that's right so you could have these

00:23:13,679 --> 00:23:16,720
entire distributions of these values of these dependency

00:23:16,720 --> 00:23:20,480
freshness metrics computed over large samples as thousands and thousands of

00:23:20,480 --> 00:23:23,520
projects represented here and you could see whether there's any

00:23:23,520 --> 00:23:27,679
common trends across all of them but it's actually it goes beyond just

00:23:27,679 --> 00:23:32,400
visualizing the data we can actually um model this more

00:23:32,400 --> 00:23:35,760
precisely using statistics and we could actually

00:23:35,760 --> 00:23:39,679
quantify and we can measure you know if there's any change in the

00:23:39,679 --> 00:23:43,120
slopes of these time series before and after the intervention if there's any

00:23:43,120 --> 00:23:46,640
change in the level like was there any big jump around the time when they did

00:23:46,640 --> 00:23:50,159
this did the trend afterwards change compared to the one before etcetera lots

00:23:50,159 --> 00:23:53,039
of things like this that we could we could quantify and measure very

00:23:53,039 --> 00:23:56,640
precisely and you can control for other effects like the popularity of the

00:23:56,640 --> 00:24:00,400
project may have just skyrocketed at the time and that maybe that was the effect

00:24:00,400 --> 00:24:04,720
that's the beauty right so if you're doing this carefully you could you could

00:24:04,720 --> 00:24:09,279
separate the effects of this particular thing as as much as possible from other

00:24:09,279 --> 00:24:12,400
things that might be correlated like popularity like you said

00:24:12,400 --> 00:24:16,799
so we've done this and again i uh i won't go into all these details here but

00:24:16,799 --> 00:24:19,679
let me just show you some of the conclusions from from our analysis and

00:24:19,679 --> 00:24:22,320
you can find more details in our papers about these

00:24:22,320 --> 00:24:26,000
if we're looking at say dependency management and these dependency manager

00:24:26,000 --> 00:24:30,480
badges okay you can see that after people start

00:24:30,480 --> 00:24:33,679
doing this across this large sample thousands and

00:24:33,679 --> 00:24:36,880
thousands of projects you can see this consistent effect right

00:24:36,880 --> 00:24:41,760
their dependencies are consistently more up-to-date when they do this it's a

00:24:41,760 --> 00:24:45,039
really good practice probably also more secure because they

00:24:45,039 --> 00:24:49,760
keep you know fixing these uh vulnerabilities presumably

00:24:49,760 --> 00:24:53,120
an interesting thing there if you look at how this

00:24:53,120 --> 00:24:57,520
evolves over a longer period of time there's nine months being shown here

00:24:57,520 --> 00:25:01,440
actually you could see it's starting to trail off so it seems like

00:25:01,440 --> 00:25:05,360
after some time people stop paying as much attention to this as they were

00:25:05,360 --> 00:25:07,120
doing in the beginning so it's really interesting to

00:25:07,120 --> 00:25:10,880
just think about how you could make this even more sustainable and

00:25:10,880 --> 00:25:14,720
enforce this in a longer period let me give you another example that's really

00:25:14,720 --> 00:25:17,440
fascinating maintainers complain often about their

00:25:17,440 --> 00:25:21,279
contributors maybe not submitting uh tests together with their pr's okay

00:25:21,279 --> 00:25:27,120
so how can you incentivize people to do this in a

00:25:27,120 --> 00:25:30,320
as non-invasive uh a way as possible how to do this

00:25:30,320 --> 00:25:34,240
okay take a look at this chart the first half

00:25:34,240 --> 00:25:37,520
before they started displaying these badges

00:25:37,520 --> 00:25:41,840
hardly anyone was ever submitting tests together with their

00:25:41,840 --> 00:25:46,240
the second part here but in the second part look how many more people

00:25:46,240 --> 00:25:49,360
started doing this and consistently afterwards

00:25:49,360 --> 00:25:53,840
and this is what i mean well this is a success right

00:25:53,840 --> 00:25:58,000
yeah because it was such a small thing to change right you just

00:25:58,000 --> 00:26:01,679
you just signal that you care about testing and you care about

00:26:01,679 --> 00:26:05,919
quality let me step back for a minute and talk a little bit about theory

00:26:05,919 --> 00:26:09,200
signaling theory is something that's not specific to

00:26:09,200 --> 00:26:12,480
badges it's something that people have looked at for a long time in other

00:26:12,480 --> 00:26:15,840
another disciplines like economics and biology and the theory

00:26:15,840 --> 00:26:21,039
explains how some type of signals are more reliable more trustworthy than

00:26:21,039 --> 00:26:23,919
others to give you an example take the peacock

00:26:23,919 --> 00:26:29,200
and the peacock's fluffy colorful feathers when the bird has those

00:26:29,200 --> 00:26:34,640
feathers up on display it's becomes more prone to being hunted

00:26:34,640 --> 00:26:40,320
by predators it becomes slower and so on but the fact that you see a bird that

00:26:40,320 --> 00:26:44,080
has survived despite this hardship despite this handicap

00:26:44,080 --> 00:26:47,279
right that means that bird has a lot more energy and

00:26:47,279 --> 00:26:53,120
probably a much better mate so in the same way here if you distinguish between

00:26:53,120 --> 00:26:56,159
the badges that have some kind of underlying analysis that's

00:26:56,159 --> 00:27:00,000
you know compute the the bill status or some test coverage metric or something

00:27:00,000 --> 00:27:02,880
some kind of analysis that's harder to fake

00:27:02,880 --> 00:27:08,559
from those that simply link to somewhere but much easier to fake you would expect

00:27:08,559 --> 00:27:12,640
to see stronger effects for these assessment signals they're called

00:27:12,640 --> 00:27:15,679
the ones that have underlying analysis and we're seeing this consistently in

00:27:15,679 --> 00:27:18,960
our data as well so this means that for example

00:27:18,960 --> 00:27:24,640
whatever you can choose uh what a flavor of a badge over another right

00:27:24,640 --> 00:27:27,840
take the slack uh the two slack badges one just points

00:27:27,840 --> 00:27:31,200
to a channel that people can join the other one in addition also tells you

00:27:31,200 --> 00:27:34,399
how many people are active at any point in time and so it keeps updating this

00:27:34,399 --> 00:27:37,120
information right that one's harder to fake it's

00:27:37,120 --> 00:27:40,880
more expensive but it's also more trustworthy because it's more expensive

00:27:40,880 --> 00:27:44,080
and it's harder to do and you can use this for design right so

00:27:44,080 --> 00:27:48,159
if you go back to donations it might actually be much smarter to

00:27:48,159 --> 00:27:52,480
actually show that you have a need for donations by some analysis

00:27:52,480 --> 00:27:56,399
right rather than just claiming donations requested that's exactly the

00:27:56,399 --> 00:28:00,240
idea right but you could use this for design and you could design them in this

00:28:00,240 --> 00:28:03,760
particular way to make the most effective

00:28:03,760 --> 00:28:08,159
another takeaway from this is you probably don't want to add too many

00:28:08,159 --> 00:28:11,679
so if we've looked at the correlation between how many

00:28:11,679 --> 00:28:15,279
downloads these packages get and how many badges they were showing and we're

00:28:15,279 --> 00:28:18,559
controlling for other things that might vary alongside

00:28:18,559 --> 00:28:20,640
this and what we're seeing consistently in

00:28:20,640 --> 00:28:25,039
our models again is this very strong non-linear effect there right so there

00:28:25,039 --> 00:28:28,559
seems to be some sweet spot that seems to be around five or so batteries in our

00:28:28,559 --> 00:28:31,919
models but the point is that if you have too

00:28:31,919 --> 00:28:35,200
many it becomes counterproductive it doesn't

00:28:35,200 --> 00:28:38,080
look as serious anymore and it's not attractive you want to signal the

00:28:38,080 --> 00:28:41,200
important things you want to signal the important things

00:28:41,200 --> 00:28:44,240
um and finally as you're talking about design

00:28:44,240 --> 00:28:48,240
there's lots of these things that are these qualities that people

00:28:48,240 --> 00:28:51,679
care about when they look at open source projects that contributors care about

00:28:51,679 --> 00:28:56,159
when they look at open source projects that are not currently as visible as

00:28:56,159 --> 00:29:00,080
they could be to give you one example um the tone of

00:29:00,080 --> 00:29:03,039
the community is something in our interviews with

00:29:03,039 --> 00:29:06,000
potential contributors something that comes up time and again

00:29:06,000 --> 00:29:09,600
as being important when people decide whether or not to join a project to

00:29:09,600 --> 00:29:12,880
contribute to a project if they find the community welcoming and

00:29:12,880 --> 00:29:15,440
friendly right and you know these days there's

00:29:15,440 --> 00:29:19,440
all kinds of nlp techniques that that could look at this with some

00:29:19,440 --> 00:29:22,480
accuracy perhaps but the point is um this is not

00:29:22,480 --> 00:29:24,640
something that's easily visible somebody will

00:29:24,640 --> 00:29:28,640
have to read through these discussions to to make this inference well it could

00:29:28,640 --> 00:29:31,279
perhaps be made more visible through something like

00:29:31,279 --> 00:29:34,320
like a match um and there's others too like

00:29:34,320 --> 00:29:38,559
if you need help if you want to attract new contributors

00:29:38,559 --> 00:29:43,200
well signal that explicitly they know that you're welcoming pr you're

00:29:43,200 --> 00:29:48,159
asking for help you're uh you have 20 issues open that requires somebody to to

00:29:48,159 --> 00:29:51,520
work on and so on right so you could make these things more visible just make

00:29:51,520 --> 00:29:55,919
it easier for people to find it you know there's also a dark side to all

00:29:55,919 --> 00:29:59,919
of this transparency it's not all fun and games

00:29:59,919 --> 00:30:05,039
so you kind of always watched right everything is public that you're doing

00:30:05,039 --> 00:30:08,080
yeah and the fact that you have these profile pages

00:30:08,080 --> 00:30:13,120
that show your photo and your name and all kinds of information about you

00:30:13,120 --> 00:30:19,279
make you much more prone to whatever biases implicit or explicit others might

00:30:19,279 --> 00:30:23,440
have so um to give you an example we ran a

00:30:23,440 --> 00:30:28,559
survey a few years ago and we asked people uh how much they're

00:30:28,559 --> 00:30:31,679
aware of some of these personal attributes

00:30:31,679 --> 00:30:36,799
some of these demographic attributes of each other despite these things mind

00:30:36,799 --> 00:30:39,440
you not being explicitly recorded right this

00:30:39,440 --> 00:30:43,039
is not even information that's that's part of your profile page

00:30:43,039 --> 00:30:46,399
right um speaking of gender here in particular

00:30:46,399 --> 00:30:52,080
there's no fields to enter your gender and your github page or similar right

00:30:52,080 --> 00:30:58,880
and still right despite this people infer this very commonly

00:30:58,880 --> 00:31:02,399
in fact in our survey data much more commonly than they

00:31:02,399 --> 00:31:05,679
infer other qualities or other attributes like

00:31:05,679 --> 00:31:10,000
from things like your name or your profile photo and so on

00:31:10,000 --> 00:31:14,880
and you know some of the respondents to our survey also mentioned

00:31:14,880 --> 00:31:18,720
negative experience since presumably because of this

00:31:18,720 --> 00:31:22,080
right so somebody mentioned explicitly that they changed

00:31:22,080 --> 00:31:27,279
their identity on the platform to appear so that people would assume they

00:31:27,279 --> 00:31:31,760
were a different gender okay just because they're probably i

00:31:31,760 --> 00:31:36,080
don't know harassed or or bothered by others on the platform

00:31:36,080 --> 00:31:39,279
because of this and now for talking about

00:31:39,279 --> 00:31:43,600
sexist behavior in particular this is actually not new to open source has been

00:31:43,600 --> 00:31:49,200
documented for a long time it's a well-known study that

00:31:49,200 --> 00:31:52,559
finds that sexist behavior in open source is as

00:31:52,559 --> 00:31:56,559
common as it is extreme and this is a quote from that particular paper

00:31:56,559 --> 00:31:59,760
and there's others too there's a study that looked at how

00:31:59,760 --> 00:32:05,360
having your personal information be a part of your

00:32:05,360 --> 00:32:10,720
profile makes you more prone to biases in your pull requests biases

00:32:10,720 --> 00:32:16,000
against you in your pull requests and so on um and you know probably by

00:32:16,000 --> 00:32:21,760
now it wouldn't surprise you to to learn that the

00:32:21,760 --> 00:32:25,039
gender diversity in open source in particular is

00:32:25,039 --> 00:32:30,559
much lower than in most other places in tech in the tech

00:32:30,559 --> 00:32:33,600
industry this is really really concerning and

00:32:33,600 --> 00:32:38,159
disappointing your companies like

00:32:38,159 --> 00:32:42,000
the big companies have higher gender representation and this and this data is

00:32:42,000 --> 00:32:45,919
already a few years old but platforms uh like github and stack

00:32:45,919 --> 00:32:50,880
overflow and open source more more broadly very low okay um

00:32:50,880 --> 00:32:56,000
and this is really at odds with people's expectations if you ask people

00:32:56,000 --> 00:33:00,799
what is open source culture like i think the most common answer you would get is

00:33:00,799 --> 00:33:04,159
that it's really a meritocracy that nothing matters but the quality of your

00:33:04,159 --> 00:33:08,399
code right codes sees no color or gender it's how

00:33:08,399 --> 00:33:12,720
well you can how much you can contribute uh that matters nothing else is this i

00:33:12,720 --> 00:33:18,240
think the mainstream perception and this is just not true so um

00:33:18,240 --> 00:33:20,880
lots of these anecdotes i think the mainstream one is that it's a

00:33:20,880 --> 00:33:24,880
meritocracy but also opposing views some people really

00:33:24,880 --> 00:33:28,640
embrace diversity and and they think it's a positive and they're trying to

00:33:28,640 --> 00:33:33,360
encourage this others uh have had negative experiences because

00:33:33,360 --> 00:33:38,000
of diversity and they may be discouraged by this so

00:33:38,000 --> 00:33:41,920
lots of anecdotes again like we've seen throughout what about the evidence

00:33:41,920 --> 00:33:44,240
right what is the evidence is there any data

00:33:44,240 --> 00:33:49,120
to uh inform this question either way is it that more

00:33:49,120 --> 00:33:53,600
diverse teams tend to be more effective more diverse communities tend to be more

00:33:53,600 --> 00:33:56,080
effective or is it the other way around that it doesn't matter or

00:33:56,080 --> 00:34:02,720
if anything uh even harmful and we do find we do find evidence in

00:34:02,720 --> 00:34:05,760
the data that diversity helps and let me show you

00:34:05,760 --> 00:34:09,280
how we got to this so if you think of this again as a

00:34:09,280 --> 00:34:12,240
natural experiment

00:34:12,320 --> 00:34:18,480
you can mine lots of data from a large set of projects collaborative

00:34:18,480 --> 00:34:22,399
projects with different people collaborating and you

00:34:22,399 --> 00:34:26,000
can compare their outputs okay this is the

00:34:26,000 --> 00:34:29,679
way we're operationalizing success or effectiveness here you're

00:34:29,679 --> 00:34:34,480
comparing their outputs you want to see if there's any difference in how much

00:34:34,480 --> 00:34:39,520
people produce per unit time and their output per unit time between

00:34:39,520 --> 00:34:42,560
the two conditions between teams that are more diverse and teams that are less

00:34:42,560 --> 00:34:48,159
diverse and here we're looking at two dimensions

00:34:48,159 --> 00:34:51,119
of diversity we're looking at diversity in terms of gender

00:34:51,119 --> 00:34:55,119
and i want to note here that because of the

00:34:55,119 --> 00:35:00,640
um name based inference that we're making for for people's

00:35:00,640 --> 00:35:04,000
gender you have to do because there is no fear right there is no field

00:35:04,000 --> 00:35:06,480
yeah so because there is no field we have to infer

00:35:06,480 --> 00:35:09,599
gender in order to study this from people's names

00:35:09,599 --> 00:35:15,440
and we can only do this for uh technology right now for name name-based

00:35:15,440 --> 00:35:20,079
inference only allows binary inferences with some hackers so i apologize to

00:35:20,079 --> 00:35:23,440
people that don't identify as binary just don't have tools

00:35:23,440 --> 00:35:28,240
to study this okay the other dimension is experience or

00:35:28,240 --> 00:35:30,560
tenure right you could think of teams where it's a

00:35:30,560 --> 00:35:33,760
whole bunch of senior people or a whole bunch of junior people are

00:35:33,760 --> 00:35:37,440
mixed between the two kinds of engineers and developers okay

00:35:37,440 --> 00:35:40,480
which one is more effective so we're looking at

00:35:40,480 --> 00:35:47,119
how many commits these different teams make per unit time

00:35:47,119 --> 00:35:50,640
okay that's the measure of how much stuff do they get done how much

00:35:50,640 --> 00:35:54,560
code they write per unit time okay and you're probably going to

00:35:54,560 --> 00:35:57,839
complain like you're probably going to complain that this is overly simplistic

00:35:57,839 --> 00:36:01,200
right so because you know all kinds of other things

00:36:01,200 --> 00:36:06,079
matter and correlate with how quickly people get stuff done right maybe they

00:36:06,079 --> 00:36:10,000
have more developers maybe the project is more popular and more

00:36:10,000 --> 00:36:13,040
active maybe on the contrary maybe the

00:36:13,040 --> 00:36:17,440
project's old and um slow down development and whatnot

00:36:17,440 --> 00:36:20,960
right all of these things um that you can

00:36:20,960 --> 00:36:25,520
complain are correlating with with how effective and

00:36:25,520 --> 00:36:28,720
productive they are are actually things we can measure

00:36:28,720 --> 00:36:32,720
though we can measure in the data and again coming back to this point i mean

00:36:32,720 --> 00:36:36,079
earlier you could try to separate the effect of one from the effects of the

00:36:36,079 --> 00:36:39,200
others so what do we find okay we find

00:36:39,200 --> 00:36:43,680
consistent evidence in the data across very large samples

00:36:43,680 --> 00:36:49,280
that those teams that are more balanced more diverse in terms of gender okay so

00:36:49,280 --> 00:36:53,200
this means not any in this case binary gender

00:36:53,200 --> 00:36:58,480
dominating right just the balance of the two and similarly in terms of

00:36:58,480 --> 00:37:02,320
experience balance of junior and senior people

00:37:02,320 --> 00:37:06,320
those are the teams that are most effective even with controlling for all

00:37:06,320 --> 00:37:08,400
the obvious things even with controlling for the obvious

00:37:08,400 --> 00:37:11,280
teams and the obvious things behave as you'd expect so you know larger teams

00:37:11,280 --> 00:37:15,040
and so on are are more effective just like you'd

00:37:15,040 --> 00:37:18,079
expect but even when controlling for all these other things

00:37:18,079 --> 00:37:24,000
you still see some effect there for these diversity variables and it's small

00:37:24,000 --> 00:37:28,000
it's small in the data um but it's there and it fits the theory

00:37:28,000 --> 00:37:31,119
and it fits the theory so let me tell you about one more study

00:37:31,119 --> 00:37:35,680
we looked at dropout and retention and let's start from the observation in

00:37:35,680 --> 00:37:42,000
the data that women are more likely to drop out

00:37:42,000 --> 00:37:46,800
after any time spent in open source than men are on average and again this

00:37:46,800 --> 00:37:49,440
is the same caveats about binary gender as before

00:37:49,440 --> 00:37:52,960
the effect is particularly strong early in the project that's right

00:37:52,960 --> 00:37:56,000
so here you see the probability of survival uh

00:37:56,000 --> 00:38:00,079
it's called just remaining active active and contributing to open source

00:38:00,079 --> 00:38:03,359
over time and how that varies between the two genders

00:38:03,359 --> 00:38:10,320
and there's actually really interesting theory again in the social sciences that

00:38:10,320 --> 00:38:14,880
explains how the very connections that people

00:38:14,880 --> 00:38:20,800
make over time and that very nature of the projects and so on that

00:38:20,800 --> 00:38:25,200
they work on the teams they uh they join over time

00:38:25,200 --> 00:38:32,000
how those uh connections in this network how those explain this effect

00:38:32,000 --> 00:38:35,520
it's really interesting so let me let me tell you about this so there's two kinds

00:38:35,520 --> 00:38:37,520
of social capitals here there's two kinds

00:38:37,520 --> 00:38:42,480
of this one is about uh bonding this is about uh so having

00:38:42,480 --> 00:38:46,079
cohesive teams and so being part of these

00:38:46,079 --> 00:38:53,119
tightly connected groups and how this provides people with willingness to to

00:38:53,119 --> 00:38:55,599
continue and just some sense of belonging you

00:38:55,599 --> 00:38:57,760
feel like you're part of something a close

00:38:57,760 --> 00:39:00,960
network connection between all these people and you can see how that would be

00:39:00,960 --> 00:39:05,280
beneficial the counterpart to this is about

00:39:05,280 --> 00:39:09,040
learning about new opportunities or bridging or getting out of your

00:39:09,040 --> 00:39:13,200
of your bubble your echo chamber your cluster learning about new things

00:39:13,200 --> 00:39:17,119
and branching out over time and this doesn't happen

00:39:17,119 --> 00:39:21,040
through these tightly connected groups right because people there

00:39:21,040 --> 00:39:24,880
probably know and have access to roughly the same information it's through these

00:39:24,880 --> 00:39:28,800
weak ties that you learn about new opportunities differently

00:39:28,800 --> 00:39:35,280
okay so both of these mechanisms would explain why some open source

00:39:35,280 --> 00:39:40,480
contributors are uh more active or they're active longer term rather

00:39:40,480 --> 00:39:45,040
than others that's right uh yes well we'll see

00:39:45,040 --> 00:39:48,480
cinema but here's the catch though when you have

00:39:48,480 --> 00:39:52,560
such an imbalanced environment like we do in terms of gender in open source

00:39:52,560 --> 00:39:59,200
right some of these metric mechanisms might not be as beneficial as you would

00:39:59,200 --> 00:40:02,240
hope in particular you know being part of

00:40:02,240 --> 00:40:06,400
these or being a minority rather in these very tightly connected very

00:40:06,400 --> 00:40:13,119
cohesive groups um exposes you to higher risk of of bias

00:40:13,119 --> 00:40:16,560
and potential discrimination just because echo chambers are more

00:40:16,560 --> 00:40:20,000
likely to form among the majority group and these tightly

00:40:20,000 --> 00:40:23,599
connected teams and projects think of politics we've seen this all

00:40:23,599 --> 00:40:27,599
the time with bipartisanship and participate in politics

00:40:27,599 --> 00:40:34,160
okay so this would actually um suggest that a way to fix this right

00:40:34,160 --> 00:40:37,599
if that's the case if that's true if there's any evidence for this even in

00:40:37,599 --> 00:40:40,880
our data a way to fix this would potentially be

00:40:40,880 --> 00:40:46,000
to break out of these clusters okay by just exposing yourself

00:40:46,000 --> 00:40:50,640
or joining projects where you're more

00:40:50,640 --> 00:40:54,640
likely to encounter new people or new ideas or new

00:40:54,640 --> 00:40:57,680
technologies or whatever but there'll be a way to break out of

00:40:57,680 --> 00:41:01,599
these bubbles of these echo chambers but the question is does it does it

00:41:01,599 --> 00:41:05,200
happen is there any evidence for this in open source again we can study this

00:41:05,200 --> 00:41:09,200
with data and we've done this we have a big sample of about 60 000 people and

00:41:09,200 --> 00:41:11,760
again similar modeling as before and with all the

00:41:11,760 --> 00:41:14,480
um the controls and so on the steps we're cleaning and filtering now we

00:41:14,480 --> 00:41:18,960
talked about earlier and we're seeing um evidence for

00:41:18,960 --> 00:41:22,160
for all of these so first off we're seeing here

00:41:22,160 --> 00:41:25,920
um this is a plot that shows how higher or

00:41:25,920 --> 00:41:30,480
lower lower cohesion in these projects between the different contributors so

00:41:30,480 --> 00:41:32,800
the bonding capital the bonding capital yes

00:41:32,800 --> 00:41:38,640
how this correlates with a higher probability of survival or

00:41:38,640 --> 00:41:41,839
long-term contribution okay so it's better for

00:41:41,839 --> 00:41:46,480
everyone on average people that are part of these more cohesive projects

00:41:46,480 --> 00:41:51,119
in communities they stay engaged longer okay everyone

00:41:51,119 --> 00:41:56,160
benefits from this and interestingly we're seeing this gender interaction

00:41:56,160 --> 00:41:59,440
effect that we're hypothesizing so what i'm showing you here is a little

00:41:59,440 --> 00:42:01,359
bit complicated so bear with me for a second

00:42:01,359 --> 00:42:04,720
what i'm showing you here is the difference in

00:42:04,720 --> 00:42:12,560
um engagement or survival probability between people that were part of

00:42:12,560 --> 00:42:16,720
teams that are more diverse project communities that are more diverse

00:42:16,720 --> 00:42:20,000
in terms of this information that they have access to we're looking at the

00:42:20,000 --> 00:42:23,440
programming languages that people have had experience with before as a proxy

00:42:23,440 --> 00:42:26,880
for this and what you're seeing across the board

00:42:26,880 --> 00:42:31,119
here for both genders is that everybody again benefits from

00:42:31,119 --> 00:42:33,200
this right so like you would expect this is

00:42:33,200 --> 00:42:35,440
the bridging kind of social capital you learn

00:42:35,440 --> 00:42:38,880
new things and everybody benefits from listening

00:42:38,880 --> 00:42:42,839
exactly the people that have had more of this they tend to stick around

00:42:42,839 --> 00:42:49,280
longer when you again control for other things okay but the interesting part is

00:42:49,280 --> 00:42:56,400
that uh women benefit from this more and especially after about a year or so

00:42:56,400 --> 00:43:01,119
of contributing to open source i think that's when uh having access to

00:43:01,119 --> 00:43:04,720
these new opportunities to continue your engagement that's when it's most

00:43:04,720 --> 00:43:07,920
critical okay so this suggests right that we

00:43:07,920 --> 00:43:14,720
could be investing more deliberately into um mentorship programs for example

00:43:14,720 --> 00:43:18,240
and design them deliberately exactly that's the that's the catch right so

00:43:18,240 --> 00:43:22,800
it's not just about having mentors but it's about having the

00:43:22,800 --> 00:43:26,400
right mentors that are the right opportunities the right connections

00:43:26,400 --> 00:43:29,839
exactly that will expose you to these new ideas and these new opportunities

00:43:29,839 --> 00:43:33,280
and these new projects again we can learn from theory to design

00:43:33,280 --> 00:43:37,119
interventions to design our communities that's what we're finding here yeah that

00:43:37,119 --> 00:43:42,240
was a lot right um let's summarize so we talked about

00:43:42,240 --> 00:43:45,839
sustainability uh we talked about all the challenges that come

00:43:45,839 --> 00:43:49,040
there right um all the high workload the stress

00:43:49,040 --> 00:43:52,079
uh the attention that comes but we also have

00:43:52,079 --> 00:43:55,599
i mean we have only scratched the first office but we have shown you a couple of

00:43:55,599 --> 00:43:58,720
different things we have shown the limitations of

00:43:58,720 --> 00:44:01,920
donations as a sustainable funding source

00:44:01,920 --> 00:44:05,119
whether good whether that how we can maybe use

00:44:05,119 --> 00:44:10,240
theory to improve others badges as a transparent signaling mechanism which is

00:44:10,240 --> 00:44:13,359
useful for designing lots of interventions right

00:44:13,359 --> 00:44:18,400
it's so easy right the dark side to transparency where you always observe

00:44:18,400 --> 00:44:20,960
them your work is observed but also your

00:44:20,960 --> 00:44:24,880
personal characteristics and what may affect how you work

00:44:24,880 --> 00:44:32,000
but also how social capital theory suggests really specific paths how you

00:44:32,000 --> 00:44:35,760
can improve community design and retention just as

00:44:35,760 --> 00:44:37,680
one example there are others right and

00:44:37,680 --> 00:44:41,680
there's so much more right but equally importantly this talk we'd also

00:44:41,680 --> 00:44:44,640
try to give an overview of how we can go beyond

00:44:44,640 --> 00:44:48,079
anecdotes right so we've shown you much with

00:44:48,079 --> 00:44:52,640
different research designs almost always we looked at terabytes of data right

00:44:52,640 --> 00:44:57,280
thousands of projects long histories uh we had to control for a lot of things

00:44:57,280 --> 00:45:02,240
that sometimes fancy statistics involved but in general the trend is always going

00:45:02,240 --> 00:45:06,640
from kind of anecdotes what we find what people are talking about looking

00:45:06,640 --> 00:45:10,720
for trends and then coming up hopefully with evidence and theory based

00:45:10,720 --> 00:45:14,240
recommendations and the goal here is for the entire

00:45:14,240 --> 00:45:19,040
community to go beyond just widen your horizon essentially right so

00:45:19,040 --> 00:45:21,839
don't just copy what you see other projects are doing

00:45:21,839 --> 00:45:25,359
don't just go off anecdotal evidence right actually

00:45:25,359 --> 00:45:31,839
look at evidence look at the science and hopefully the more we understand we can

00:45:31,839 --> 00:45:35,920
actually intentionally design our tools and communities

00:45:35,920 --> 00:45:40,240
and design interventions and pick from a menu of possible things

00:45:40,240 --> 00:45:44,400
for the community and the specific goals that we have in mind the right approach

00:45:44,400 --> 00:45:48,480
to go here the ones that we we expect are going to be most effective yeah

00:45:48,480 --> 00:45:51,839
so there's much more research here here's just a couple more things that we

00:45:51,839 --> 00:45:55,920
have worked on um there's much more out there we

00:45:55,920 --> 00:45:59,920
recommend to google scholar is a good source

00:45:59,920 --> 00:46:02,960
search for a couple of keywords here there's lots of

00:46:02,960 --> 00:46:06,720
research in this community researchers always appreciate

00:46:06,720 --> 00:46:10,319
uh when practitioners talk about our papers because

00:46:10,319 --> 00:46:15,760
contact us right and before i close i just want to

00:46:15,760 --> 00:46:19,760
acknowledge this is always collaborative work with so many others

00:46:19,760 --> 00:46:23,440
especially especially especially i should highlight all the students that

00:46:23,440 --> 00:46:27,119
we've worked on who do all the main grunt of the work right the

00:46:27,119 --> 00:46:31,119
real heroes here um and finally i think we need to go

00:46:31,119 --> 00:46:33,839
back to the point we are always starting from

00:46:33,839 --> 00:46:37,760
what's the community talking about right so what are the sustainability

00:46:37,760 --> 00:46:41,359
challenges how is open source changing and we're here to listen as

00:46:41,359 --> 00:46:45,680
well so we also want to know um what are the sustainability

00:46:45,680 --> 00:46:49,359
challenges what are anecdotal evidence that we should

00:46:49,359 --> 00:46:53,119
support refute what are things that need to be studied

00:46:53,119 --> 00:46:56,640
um where we might have the data and that's

00:46:56,640 --> 00:47:00,000
all there is first try recording now get out of my

00:47:00,000 --> 00:47:04,160
bedroom first recording first try recording first try

00:47:04,160 --> 00:47:07,040
recording i guess in the meantime we can pick up

00:47:07,040 --> 00:47:11,920
the discussion from the chat right about non-coding contributors

00:47:11,920 --> 00:47:15,599
which i think is super interesting and especially how this

00:47:15,599 --> 00:47:21,920
relates to visibility of the work maybe funding of the work how it relates

00:47:21,920 --> 00:47:26,559
to paid contributors unpaid work

00:47:26,720 --> 00:47:29,760
there's some work in this area but i think a lot of more

00:47:29,760 --> 00:47:32,640
things to be done

00:47:33,359 --> 00:47:36,400
so here's a question christian from somebody in the chat

00:47:36,400 --> 00:47:39,920
josh is asking if you think that language around volunteering and

00:47:39,920 --> 00:47:42,720
donating puts off contributors who aren't already

00:47:42,720 --> 00:47:45,760
financially secure

00:47:46,480 --> 00:47:50,559
i don't know um i think this is interesting there's a huge amount of

00:47:50,559 --> 00:47:54,960
literature on volunteering more broadly right

00:47:54,960 --> 00:48:00,800
philanthropy and this attracts a certain kind of

00:48:00,800 --> 00:48:06,640
people um not everybody i don't know

00:48:06,640 --> 00:48:10,079
i think this would be an interesting thing to to study

00:48:10,079 --> 00:48:15,440
in um there's a lot of studies on motivation

00:48:15,440 --> 00:48:19,200
of open source contributors right um from

00:48:19,200 --> 00:48:23,440
this scratch your own itch to um see this seeing this as a career path

00:48:23,440 --> 00:48:28,800
intrinsic and extrinsic motivation and i think some of them don't interact

00:48:28,800 --> 00:48:35,119
well with donations right kind of being

00:48:35,119 --> 00:48:40,319
begging for money

00:48:40,319 --> 00:48:45,839
you might be better off at least taking the money completely out of it and

00:48:45,839 --> 00:48:49,839
completely seeing this as volunteering i don't know

00:48:49,839 --> 00:48:54,160
do you have a thought no not about this specifically but i do

00:48:54,160 --> 00:49:00,640
we have seen that the language people use in their

00:49:00,720 --> 00:49:04,400
front page read me files or things like this the stuff that people see

00:49:04,400 --> 00:49:08,319
the first time they they come across a project that that makes a difference

00:49:08,319 --> 00:49:12,960
that's sort of it the perception that readers or viewers

00:49:12,960 --> 00:49:18,640
of these things um form is influenced by the kind of

00:49:18,640 --> 00:49:23,920
language and how welcoming it appears in the interviews we've done

00:49:23,920 --> 00:49:28,079
we've even seen that people go through i don't know like issue

00:49:28,079 --> 00:49:31,839
discussions and things like that and they try to get a sense of how

00:49:31,839 --> 00:49:37,359
welcoming the maintainers are and so if it's worth their time to try to

00:49:37,359 --> 00:49:44,640
engage or things like that i wouldn't be surprised if if this also

00:49:44,640 --> 00:49:47,839
makes a difference because other kinds of language we do see that

00:49:47,839 --> 00:49:52,240
that make a difference i'm not entirely sure what the alternative is to

00:49:52,240 --> 00:49:54,960
volunteering

00:49:55,359 --> 00:49:59,520
i mean through language around volunteering if you want people to

00:49:59,520 --> 00:50:04,880
kind of volunteer their time right so you can probably phrase it a little bit

00:50:04,880 --> 00:50:10,000
differently but i don't know bounties

00:50:10,160 --> 00:50:13,280
and then you're bringing it money right and bounties are

00:50:13,280 --> 00:50:16,400
gamification but not really a serious income

00:50:16,400 --> 00:50:19,599
um most of the time i haven't seen anything

00:50:19,599 --> 00:50:22,720
um on

00:50:22,720 --> 00:50:28,640
incubators actually there has i think um one of my colleagues has looked at

00:50:28,640 --> 00:50:32,800
the apache incubator specifically um i'll see if i can dig up

00:50:32,800 --> 00:50:36,640
some published research on this um like i

00:50:36,640 --> 00:50:40,000
could think of at least one study that looked at this i don't know the details

00:50:40,000 --> 00:50:43,280
um off the top of my head i need to check but let me do that and get back to

00:50:43,280 --> 00:50:46,800
you on the on the notes here yeah i don't i

00:50:46,800 --> 00:50:51,120

YouTube URL: https://www.youtube.com/watch?v=y4cpIaN3tFc


