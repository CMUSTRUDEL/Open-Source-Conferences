Title: Power a Better Future (sponsored by MemSQL) - Drew Paroski (MemSQL)
Publication date: 2018-09-12
Playlist: Strata Data Conference 2018 - New York, NY
Description: 
	Today’s successful businesses utilize data better than their competitors; however, data sprawl and inefficient data infrastructure restrict what’s possible. Blending the best of the past with the software innovations of today will solve future data challenges. Drew Paroski shares how to develop modern database applications without sacrificing cost savings, data familiarity, and flexibility.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,230 --> 00:00:05,250
hello and thank you my name is trooper

00:00:03,480 --> 00:00:07,680
Oskie and I'm vice president of

00:00:05,250 --> 00:00:09,960
engineering at mem sequel today I'd like

00:00:07,680 --> 00:00:13,469
to talk with you about how MEMS sequel

00:00:09,960 --> 00:00:16,640
sees the future of the data landscape

00:00:13,469 --> 00:00:18,480
changing over the next few decades

00:00:16,640 --> 00:00:21,689
there's a quote from Albert Einstein

00:00:18,480 --> 00:00:23,840
that I love the definition of genius is

00:00:21,689 --> 00:00:26,640
taking the complex and making it simple

00:00:23,840 --> 00:00:28,500
this quote is particularly applicable to

00:00:26,640 --> 00:00:32,850
technology and how people interact with

00:00:28,500 --> 00:00:34,469
it and are empowered by it I'd like to

00:00:32,850 --> 00:00:36,920
start with an example that's familiar to

00:00:34,469 --> 00:00:40,500
almost everyone's day-to-day experience

00:00:36,920 --> 00:00:43,590
smartphones where once we had we needed

00:00:40,500 --> 00:00:47,100
separate devices for different functions

00:00:43,590 --> 00:00:50,730
a calculator a camera an alarm clock and

00:00:47,100 --> 00:00:54,360
so on we now have all of that technology

00:00:50,730 --> 00:00:56,699
combined in a single device cell phones

00:00:54,360 --> 00:00:59,760
smartphones are an excellent example of

00:00:56,699 --> 00:01:01,620
technology convergence for most use

00:00:59,760 --> 00:01:03,329
cases people want their experience with

00:01:01,620 --> 00:01:06,930
technology to be as simple and

00:01:03,329 --> 00:01:09,090
streamlined as possible and we see

00:01:06,930 --> 00:01:12,930
examples of convergence across different

00:01:09,090 --> 00:01:15,630
areas of Technology ranging from cars to

00:01:12,930 --> 00:01:19,350
Smart TVs it's a hyper-converged

00:01:15,630 --> 00:01:21,330
infrastructure and as other areas of

00:01:19,350 --> 00:01:23,810
technology have evolved to deliver a

00:01:21,330 --> 00:01:27,630
simpler and more streamlined experience

00:01:23,810 --> 00:01:31,979
the data technology space must evolve as

00:01:27,630 --> 00:01:33,900
well you've probably read statistics

00:01:31,979 --> 00:01:36,689
about how much data is being created

00:01:33,900 --> 00:01:38,759
every day every hour it's a lot and it's

00:01:36,689 --> 00:01:41,460
coming from all kinds of sources ranging

00:01:38,759 --> 00:01:43,649
from phones to watches to shoes things

00:01:41,460 --> 00:01:47,070
you might not expect like basketballs

00:01:43,649 --> 00:01:49,799
and water bottles according to an

00:01:47,070 --> 00:01:51,899
Accenture study 79 percent of enterprise

00:01:49,799 --> 00:01:53,939
executives agree that companies that do

00:01:51,899 --> 00:01:55,770
not embrace big data will lose their

00:01:53,939 --> 00:01:58,950
competitive position and could face

00:01:55,770 --> 00:02:01,140
extinction driving insights from your

00:01:58,950 --> 00:02:03,780
data is a competitive advantage that can

00:02:01,140 --> 00:02:05,490
no longer be ignored but many companies

00:02:03,780 --> 00:02:08,069
are finding it difficult to make the

00:02:05,490 --> 00:02:10,200
most of their data because traditional

00:02:08,069 --> 00:02:12,340
data technology wasn't built with such

00:02:10,200 --> 00:02:15,440
huge scale in mind

00:02:12,340 --> 00:02:18,049
the current data technology landscape is

00:02:15,440 --> 00:02:21,349
a jungle it's a huge universe of

00:02:18,049 --> 00:02:24,019
different components and systems ranging

00:02:21,349 --> 00:02:26,540
from legacy offerings to caches to no

00:02:24,019 --> 00:02:30,110
sequel solutions to all the tools needed

00:02:26,540 --> 00:02:32,840
to manage and monitor everything you've

00:02:30,110 --> 00:02:33,920
probably seen complex data architecture

00:02:32,840 --> 00:02:35,900
slides like these

00:02:33,920 --> 00:02:38,060
maybe you're dealing with a similarly

00:02:35,900 --> 00:02:41,299
complex data infrastructure at your

00:02:38,060 --> 00:02:44,239
company today the demands on data

00:02:41,299 --> 00:02:47,390
infrastructure continue to increase over

00:02:44,239 --> 00:02:49,849
time demands ranging from dealing with

00:02:47,390 --> 00:02:54,680
larger datasets delivering faster time

00:02:49,849 --> 00:02:58,549
to insights to handling more concurrency

00:02:54,680 --> 00:02:59,959
and being able to handle a wider range

00:02:58,549 --> 00:03:03,890
of different transactional and

00:02:59,959 --> 00:03:06,200
analytical workloads many companies have

00:03:03,890 --> 00:03:07,879
addressed this problem by adding new

00:03:06,200 --> 00:03:09,890
specialized components to their data

00:03:07,879 --> 00:03:13,879
infrastructure the problem with that

00:03:09,890 --> 00:03:15,980
approach is that each new component you

00:03:13,879 --> 00:03:18,620
add to your system makes it harder to

00:03:15,980 --> 00:03:22,970
manage more expensive and requires

00:03:18,620 --> 00:03:25,700
experts and this complexity only gets

00:03:22,970 --> 00:03:27,430
worse as the demands on your data

00:03:25,700 --> 00:03:32,859
infrastructure continue to increase

00:03:27,430 --> 00:03:36,700
there's a better way we all know that

00:03:32,859 --> 00:03:40,069
traditional data technology started with

00:03:36,700 --> 00:03:42,819
sequel based databases that were

00:03:40,069 --> 00:03:45,160
excelled at handling a wide range of

00:03:42,819 --> 00:03:48,379
workloads that fit on a single machine

00:03:45,160 --> 00:03:51,379
when that stopped working the no sequel

00:03:48,379 --> 00:03:53,750
wave brought us a multitude of

00:03:51,379 --> 00:03:55,910
specialized components to tackle the

00:03:53,750 --> 00:03:59,840
rising demands on data infrastructure

00:03:55,910 --> 00:04:02,660
but with it came complexity and this

00:03:59,840 --> 00:04:04,419
complexity led to new problems for data

00:04:02,660 --> 00:04:07,220
infrastructure teams to deal with

00:04:04,419 --> 00:04:09,349
ranging from data siloing to more data

00:04:07,220 --> 00:04:12,230
movement leading to slower time to

00:04:09,349 --> 00:04:14,299
insight to needing more staff to manage

00:04:12,230 --> 00:04:19,450
and keep everything just the core

00:04:14,299 --> 00:04:22,310
functionality up and running REM sequel

00:04:19,450 --> 00:04:25,190
sees the next step in the evolution of

00:04:22,310 --> 00:04:25,980
data technology as convergence the

00:04:25,190 --> 00:04:29,190
answer is

00:04:25,980 --> 00:04:32,790
database that does more analysts have

00:04:29,190 --> 00:04:34,770
different terms for this I prefer the

00:04:32,790 --> 00:04:39,330
term new sequel as it represents a

00:04:34,770 --> 00:04:43,890
return to the power and the familiarity

00:04:39,330 --> 00:04:46,080
of sequel while still solving the

00:04:43,890 --> 00:04:51,390
challenges that no sequel originally set

00:04:46,080 --> 00:04:53,730
out to address the ideal modern database

00:04:51,390 --> 00:04:56,520
is sequel base it's distributed and

00:04:53,730 --> 00:04:59,790
horizontally scalable memory optimize is

00:04:56,520 --> 00:05:02,280
durable and runs anywhere in other words

00:04:59,790 --> 00:05:03,890
it's a database without limits by

00:05:02,280 --> 00:05:05,850
delivering more value with your database

00:05:03,890 --> 00:05:07,440
you can simplify your data

00:05:05,850 --> 00:05:10,800
infrastructure and transform your

00:05:07,440 --> 00:05:13,200
business now I'd like to invite octave

00:05:10,800 --> 00:05:24,020
Dean on stage to talk about how fanatics

00:05:13,200 --> 00:05:26,310
did just that thanks drew

00:05:24,020 --> 00:05:28,560
good morning everyone my name is asif

00:05:26,310 --> 00:05:30,180
dean i'm a principal engineer at

00:05:28,560 --> 00:05:32,700
fanatics and the data science and

00:05:30,180 --> 00:05:34,740
engineering org today i'm going to give

00:05:32,700 --> 00:05:37,140
you a brief overview of our technology

00:05:34,740 --> 00:05:39,510
architecture and how we solve some

00:05:37,140 --> 00:05:43,170
complex data integration and analytics

00:05:39,510 --> 00:05:45,600
problems using them sequel so fanatics

00:05:43,170 --> 00:05:50,360
is a global leader and the license for

00:05:45,600 --> 00:05:53,790
merchandise industry we operate over 200

00:05:50,360 --> 00:05:56,580
offline and online partner stores

00:05:53,790 --> 00:05:59,550
including all ecommerce business for

00:05:56,580 --> 00:06:03,060
major sports leagues in the u.s. major

00:05:59,550 --> 00:06:10,890
media brands and over 200 collegiate and

00:06:03,060 --> 00:06:14,190
professional team sites sports is a very

00:06:10,890 --> 00:06:16,380
fast and ever-changing landscape about

00:06:14,190 --> 00:06:19,350
three years ago we decided to completely

00:06:16,380 --> 00:06:20,760
revamp our technology architecture so

00:06:19,350 --> 00:06:23,220
that we could better serve our very

00:06:20,760 --> 00:06:26,880
passionate fans with their ever-growing

00:06:23,220 --> 00:06:29,880
real-time expectations so we moved from

00:06:26,880 --> 00:06:32,850
siloed and monolithic applications to a

00:06:29,880 --> 00:06:35,460
completely event-driven architecture at

00:06:32,850 --> 00:06:37,080
the core of this architecture is a Kafka

00:06:35,460 --> 00:06:39,840
based event messaging platform that we

00:06:37,080 --> 00:06:43,590
call fan flow so all front-end

00:06:39,840 --> 00:06:46,230
back-end applications log critical

00:06:43,590 --> 00:06:48,330
business and application events using

00:06:46,230 --> 00:06:51,630
tightly governed schemas directly into

00:06:48,330 --> 00:06:53,840
fan flow these events include the user

00:06:51,630 --> 00:06:56,340
behavior interactions on the site

00:06:53,840 --> 00:06:58,410
type-ahead results search

00:06:56,340 --> 00:07:00,900
recommendations product recommendations

00:06:58,410 --> 00:07:04,650
all the state changes within an order

00:07:00,900 --> 00:07:07,740
life cycle such as additions to cart

00:07:04,650 --> 00:07:13,350
checkout through fulfillment and

00:07:07,740 --> 00:07:15,410
delivery and so forth this allows our

00:07:13,350 --> 00:07:17,160
different business units and teams to

00:07:15,410 --> 00:07:21,200
communicate with each other more

00:07:17,160 --> 00:07:23,610
effectively and provide a more robust

00:07:21,200 --> 00:07:25,530
experience to our users provide more

00:07:23,610 --> 00:07:28,820
innovative and readily available

00:07:25,530 --> 00:07:32,310
products across all our retail channels

00:07:28,820 --> 00:07:36,210
it also allows us to ingest these events

00:07:32,310 --> 00:07:38,510
in real time and derive insights from

00:07:36,210 --> 00:07:40,680
them which allows us to build

00:07:38,510 --> 00:07:45,539
intelligent feedback loops back to the

00:07:40,680 --> 00:07:48,690
servicing applications so our first

00:07:45,539 --> 00:07:50,430
attempt at processing and sort of

00:07:48,690 --> 00:07:55,590
distributing this data and serving it

00:07:50,430 --> 00:07:57,740
out to users was to adopt a couple of

00:07:55,590 --> 00:08:03,560
different open source technologies and

00:07:57,740 --> 00:08:05,850
cloud-based storage so we used flank and

00:08:03,560 --> 00:08:08,910
Redis for state management for our

00:08:05,850 --> 00:08:12,150
real-time computation of business KPIs

00:08:08,910 --> 00:08:13,919
and time-series metrics we wrote a lot

00:08:12,150 --> 00:08:16,979
of spark applications for deeper

00:08:13,919 --> 00:08:19,889
analytics such as customer subscriber

00:08:16,979 --> 00:08:21,620
order attribution actor behavior models

00:08:19,889 --> 00:08:25,470
and such

00:08:21,620 --> 00:08:28,320
we used elastic search multiple clusters

00:08:25,470 --> 00:08:30,950
for elastic search for our primary

00:08:28,320 --> 00:08:34,620
persistence layer and query engine and

00:08:30,950 --> 00:08:36,839
used Cabana for data discovery and

00:08:34,620 --> 00:08:39,570
limited dashboarding so we had a bit of

00:08:36,839 --> 00:08:42,029
a split between our audiences where our

00:08:39,570 --> 00:08:45,330
executives and managers would use Cabana

00:08:42,029 --> 00:08:47,700
for query purposes and sort of data

00:08:45,330 --> 00:08:48,779
discovery but our data scientists and

00:08:47,700 --> 00:08:52,259
our data engineers would

00:08:48,779 --> 00:08:56,999
use hive and Zeppelin to do deeper

00:08:52,259 --> 00:08:58,290
analysis of these events there were a

00:08:56,999 --> 00:09:01,439
couple of challenges with this approach

00:08:58,290 --> 00:09:05,100
one we had very complex workflows that

00:09:01,439 --> 00:09:06,930
were difficult to manage on the

00:09:05,100 --> 00:09:08,699
elasticsearch side you know high

00:09:06,930 --> 00:09:10,620
throughput during peak traffic events

00:09:08,699 --> 00:09:12,660
was also difficult to manage we have

00:09:10,620 --> 00:09:14,430
constantly evolving schemas as our

00:09:12,660 --> 00:09:17,309
business needs evolve as their customers

00:09:14,430 --> 00:09:18,839
evolve and changing schemas was also

00:09:17,309 --> 00:09:21,600
very difficult to manage in elastic

00:09:18,839 --> 00:09:22,949
search indexes so we had a bit of a

00:09:21,600 --> 00:09:26,850
split brain we had separate query

00:09:22,949 --> 00:09:28,740
platforms for different audiences we

00:09:26,850 --> 00:09:31,319
found that a lot of our time was going

00:09:28,740 --> 00:09:33,029
into just maintenance of these

00:09:31,319 --> 00:09:37,050
applications keeping them up and running

00:09:33,029 --> 00:09:40,319
meeting our SaaS and such so we decided

00:09:37,050 --> 00:09:43,079
to adopt mem sequel the adoption of mem

00:09:40,319 --> 00:09:46,170
sequel led to a much simpler technology

00:09:43,079 --> 00:09:49,589
stock for us and fewer technologies in

00:09:46,170 --> 00:09:51,959
the mix so mem sequel serves as our

00:09:49,589 --> 00:09:54,809
primary persistence and query engine so

00:09:51,959 --> 00:09:57,059
it replaces elastic search in Cabana we

00:09:54,809 --> 00:10:00,750
converted all our spark and flank jobs

00:09:57,059 --> 00:10:03,329
to sequel based processing which allowed

00:10:00,750 --> 00:10:05,399
us to have much quicker development life

00:10:03,329 --> 00:10:09,420
cycles and more predictive service level

00:10:05,399 --> 00:10:12,480
agreements previously with elastic

00:10:09,420 --> 00:10:14,399
search and and flank and spark flink at

00:10:12,480 --> 00:10:15,870
least we had very difficult time doing

00:10:14,399 --> 00:10:17,189
data integration across under other

00:10:15,870 --> 00:10:19,439
enterprise sources we actually didn't

00:10:17,189 --> 00:10:20,939
have that capability with mem sequel in

00:10:19,439 --> 00:10:22,920
the mix we actually gained our

00:10:20,939 --> 00:10:24,779
capability we ingest all our other

00:10:22,920 --> 00:10:25,139
enterprise sources into mem sequel as

00:10:24,779 --> 00:10:27,899
well

00:10:25,139 --> 00:10:29,279
and we're able to do complex data

00:10:27,899 --> 00:10:30,959
integrations to provide a very

00:10:29,279 --> 00:10:35,759
comprehensive view of the current state

00:10:30,959 --> 00:10:39,000
of our business in addition to all of

00:10:35,759 --> 00:10:41,399
this we found out as we were able to

00:10:39,000 --> 00:10:43,800
move the our entire target audience

00:10:41,399 --> 00:10:46,290
which is executives managers data

00:10:43,800 --> 00:10:48,720
scientists data engineers to a single a

00:10:46,290 --> 00:10:50,220
sequel based platform which has lower

00:10:48,720 --> 00:10:54,209
barrier to entry and everyone knows

00:10:50,220 --> 00:10:56,490
sequel and so we saved a significant

00:10:54,209 --> 00:10:58,139
amount of time in setting up different

00:10:56,490 --> 00:11:01,319
kinds of platforms for different

00:10:58,139 --> 00:11:02,150
purposes you know even though they're

00:11:01,319 --> 00:11:04,280
all trying

00:11:02,150 --> 00:11:06,560
to serve you know analytics into our in

00:11:04,280 --> 00:11:09,290
our organization we spent a lot more

00:11:06,560 --> 00:11:10,760
time now deriving deeper insights and

00:11:09,290 --> 00:11:12,760
developing new capabilities such as

00:11:10,760 --> 00:11:15,050
self-service analytics platforms

00:11:12,760 --> 00:11:16,850
dashboarding and so forth

00:11:15,050 --> 00:11:19,160
we also were able to power a lot more

00:11:16,850 --> 00:11:21,560
analytics use cases such as order

00:11:19,160 --> 00:11:22,880
visibility which power several customer

00:11:21,560 --> 00:11:28,220
service applications within our

00:11:22,880 --> 00:11:30,310
organization so in a nutshell we spend a

00:11:28,220 --> 00:11:33,110
lot more time and resources now on

00:11:30,310 --> 00:11:35,660
providing intelligence from the data

00:11:33,110 --> 00:11:40,700
deeper insights rather than keeping our

00:11:35,660 --> 00:11:42,350
platforms up and running quick note

00:11:40,700 --> 00:11:43,730
fanatics is always hiring technologists

00:11:42,350 --> 00:11:45,650
across the board you can find us on

00:11:43,730 --> 00:11:49,010
fanatic Singh Kham or a little reach out

00:11:45,650 --> 00:11:50,990
to us on LinkedIn thank you very much

00:11:49,010 --> 00:11:59,390
and I'm gonna turn it back over to Drew

00:11:50,990 --> 00:12:01,130
now thanks octave phonetics is a great

00:11:59,390 --> 00:12:03,320
example of how you can simplify your

00:12:01,130 --> 00:12:07,820
data infrastructure you just need a

00:12:03,320 --> 00:12:10,190
better database you can come stop by our

00:12:07,820 --> 00:12:11,660
booth number 9:15 to talk with me or

00:12:10,190 --> 00:12:13,370
another member of the team about how you

00:12:11,660 --> 00:12:16,030
can simplify your data infrastructure

00:12:13,370 --> 00:12:16,030
thank you

00:12:22,390 --> 00:12:24,450

YouTube URL: https://www.youtube.com/watch?v=FJLgsG5hAzc


