Title: Lessons Learned from Tens of Thousands of Kaggle Notebooks
Publication date: 2017-11-08
Playlist: JupyterCon
Description: 
	Megan Risdal (Kaggle), Wendy Chih-wen Kan (Kaggle)

Kaggle Kernels, an in-browser code execution environment that includes a version of Jupyter Notebooks, has allowed Kaggle to flourish in new ways. Drawing on a diverse repository of user-created notebooks paired with competitions and public datasets, Megan Risdal and Wendy Chih-wen Kan explain how Kernels has impacted machine learning trends, collaborative data science, and learning.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,560 --> 00:00:07,349
so I'm Megan rizz doll I'm a community

00:00:04,680 --> 00:00:10,200
advocate and I manage our data sets

00:00:07,349 --> 00:00:11,969
platform at Kaggle and this is Wendy and

00:00:10,200 --> 00:00:15,539
I'm Wendy and we're all data scientist

00:00:11,969 --> 00:00:17,130
at the competition platform yeah and

00:00:15,539 --> 00:00:19,230
we're gonna be talking about cattle

00:00:17,130 --> 00:00:20,760
kernels so you may have heard the word

00:00:19,230 --> 00:00:24,750
kernel before but you may not be

00:00:20,760 --> 00:00:27,450
familiar with what it means on Cagle so

00:00:24,750 --> 00:00:29,550
we'll be going deep into that and

00:00:27,450 --> 00:00:32,369
sharing with you what we've learned from

00:00:29,550 --> 00:00:35,850
our community and how they use notebooks

00:00:32,369 --> 00:00:40,320
on cattle so those are twitter handles

00:00:35,850 --> 00:00:42,809
if you want to follow or at us alright

00:00:40,320 --> 00:00:45,659
so just to give you an outline of what

00:00:42,809 --> 00:00:47,550
we'll be talking over give a little bit

00:00:45,659 --> 00:00:50,190
of background on cattle for anybody

00:00:47,550 --> 00:00:51,390
who's not familiar with cattle or

00:00:50,190 --> 00:00:55,649
doesn't know about all the different

00:00:51,390 --> 00:00:58,859
components of our platform then the

00:00:55,649 --> 00:01:00,960
focus of our talk is kernels so telling

00:00:58,859 --> 00:01:03,210
you what are kernels and what are their

00:01:00,960 --> 00:01:05,070
features and how our communities is them

00:01:03,210 --> 00:01:06,990
in the third section on community stats

00:01:05,070 --> 00:01:08,310
so we have a lot of notebooks we have a

00:01:06,990 --> 00:01:11,310
lot of content that our community has

00:01:08,310 --> 00:01:13,829
created so we have a lot of interesting

00:01:11,310 --> 00:01:16,829
things to share and then finally we'll

00:01:13,829 --> 00:01:19,439
do we'll look at how our community like

00:01:16,829 --> 00:01:22,920
some actual examples of collaborative

00:01:19,439 --> 00:01:25,500
data science using kernels on cattle so

00:01:22,920 --> 00:01:27,570
first the intro to cattle I still do

00:01:25,500 --> 00:01:30,869
have to ask if everybody who's heard of

00:01:27,570 --> 00:01:32,460
cattle could you raise your hands okay

00:01:30,869 --> 00:01:33,359
cool that's that's encouraging but don't

00:01:32,460 --> 00:01:34,530
feel bad if you haven't heard of us

00:01:33,359 --> 00:01:36,479
that's alright

00:01:34,530 --> 00:01:38,100
and then who is competed in a

00:01:36,479 --> 00:01:42,079
competition or made a submission to a

00:01:38,100 --> 00:01:44,340
competition okay cool and then who has

00:01:42,079 --> 00:01:47,280
who's actually heard of kernels before

00:01:44,340 --> 00:01:48,270
and is familiar with kernels okay it's

00:01:47,280 --> 00:01:50,880
still a really good number of people

00:01:48,270 --> 00:01:52,500
cool and then finally who's seeing our

00:01:50,880 --> 00:01:56,869
data sets platform or downloaded a

00:01:52,500 --> 00:02:00,210
dataset from it awesome very cool

00:01:56,869 --> 00:02:02,670
all right so sorry for the buzzword but

00:02:00,210 --> 00:02:06,479
the cattle is known as the home of data

00:02:02,670 --> 00:02:09,270
science so really we see it as a place

00:02:06,479 --> 00:02:11,790
where people can come to learn data

00:02:09,270 --> 00:02:13,230
science compete in competitive machine

00:02:11,790 --> 00:02:16,170
learning competitions

00:02:13,230 --> 00:02:18,690
and you know we give them really

00:02:16,170 --> 00:02:20,550
interesting problems to work on but it's

00:02:18,690 --> 00:02:22,860
also a place to have fun and just

00:02:20,550 --> 00:02:25,310
interact with other data scientists from

00:02:22,860 --> 00:02:27,450
all over the world from really beginner

00:02:25,310 --> 00:02:31,560
to experts that are topping the

00:02:27,450 --> 00:02:33,450
leaderboards so you probably first heard

00:02:31,560 --> 00:02:36,720
of us as a competitive machine learning

00:02:33,450 --> 00:02:38,010
platform we're hosts come just to share

00:02:36,720 --> 00:02:41,190
their supervised machine learning

00:02:38,010 --> 00:02:43,800
problems with our community we published

00:02:41,190 --> 00:02:46,070
data sets or they build they share their

00:02:43,800 --> 00:02:49,590
data with our community posed a problem

00:02:46,070 --> 00:02:52,410
they typically historically download the

00:02:49,590 --> 00:02:54,120
data create a submission file submit it

00:02:52,410 --> 00:02:56,310
and get a placement on the leaderboard

00:02:54,120 --> 00:02:58,200
and then the winners end up you know

00:02:56,310 --> 00:03:02,430
getting cash prizes

00:02:58,200 --> 00:03:03,690
we also host recruiting competitions so

00:03:02,430 --> 00:03:05,400
that's really been Kyle's bread and

00:03:03,690 --> 00:03:10,400
butter for the past seven and a half

00:03:05,400 --> 00:03:13,350
years and it's actually because of

00:03:10,400 --> 00:03:14,820
competitions that we've built up the

00:03:13,350 --> 00:03:17,220
world's largest community of data

00:03:14,820 --> 00:03:20,430
scientists by d2 scientists I really

00:03:17,220 --> 00:03:23,549
mean anybody who works with data - you

00:03:20,430 --> 00:03:25,260
know usually you know a lot of machine

00:03:23,549 --> 00:03:28,980
learning of course but it's really

00:03:25,260 --> 00:03:31,910
anybody who works with data so we have a

00:03:28,980 --> 00:03:35,030
now we have a global user base of over

00:03:31,910 --> 00:03:37,380
1.1 million people registered users

00:03:35,030 --> 00:03:38,760
there they come from all over the world

00:03:37,380 --> 00:03:40,290
we have a lot of users in the United

00:03:38,760 --> 00:03:45,000
States of course but we also have many

00:03:40,290 --> 00:03:47,010
users in India China Russia so it's a

00:03:45,000 --> 00:03:49,350
really truly diverse community coming

00:03:47,010 --> 00:03:52,230
together to work on interesting problems

00:03:49,350 --> 00:03:55,560
and it's this community that has allowed

00:03:52,230 --> 00:03:57,510
us to or enable this to really enable

00:03:55,560 --> 00:03:59,910
our community to do more with data then

00:03:57,510 --> 00:04:02,640
just get their name on a leaderboard and

00:03:59,910 --> 00:04:05,670
compete so it's becoming much more

00:04:02,640 --> 00:04:08,370
collaborative first with our datasets

00:04:05,670 --> 00:04:11,519
platform that we launched a year ago

00:04:08,370 --> 00:04:15,600
anybody can you can find datasets we

00:04:11,519 --> 00:04:17,220
have a catalog over 2000 datasets or and

00:04:15,600 --> 00:04:20,220
discuss those datasets in our community

00:04:17,220 --> 00:04:21,810
analyze them and discuss them and then

00:04:20,220 --> 00:04:24,240
kernels which is the focus of the talk

00:04:21,810 --> 00:04:27,030
today which we launched about two years

00:04:24,240 --> 00:04:30,960
two years ago enables people to write

00:04:27,030 --> 00:04:31,710
Python or our flat file scripts or sorry

00:04:30,960 --> 00:04:36,060
I'm just

00:04:31,710 --> 00:04:38,790
scripts or hosted by Jupiter notebooks

00:04:36,060 --> 00:04:40,980
which everybody is familiar with you

00:04:38,790 --> 00:04:45,380
very notebooks so that's really the

00:04:40,980 --> 00:04:49,169
focus for the talk today so kernels so

00:04:45,380 --> 00:04:51,210
what are cattle kernels we really see

00:04:49,169 --> 00:04:54,300
this is where the name comes from we

00:04:51,210 --> 00:04:56,550
really see a cattle kernel as all of the

00:04:54,300 --> 00:04:58,260
ingredients required to grow your work

00:04:56,550 --> 00:05:00,480
as a data scientist to make it something

00:04:58,260 --> 00:05:02,550
bigger than you know just working on

00:05:00,480 --> 00:05:06,300
your laptop alone

00:05:02,550 --> 00:05:08,760
so it combines these four things

00:05:06,300 --> 00:05:12,300
environment datasets community and

00:05:08,760 --> 00:05:14,760
infrastructure and I'm gonna try to use

00:05:12,300 --> 00:05:16,620
like an analogy here to see a seed you

00:05:14,760 --> 00:05:19,410
know comes with an environments got

00:05:16,620 --> 00:05:22,770
prepackaged nutrients that allow a seed

00:05:19,410 --> 00:05:26,580
to become an oak tree and kind of the

00:05:22,770 --> 00:05:30,630
same way with cattle kernels we provide

00:05:26,580 --> 00:05:33,260
an environment which is a docker it's

00:05:30,630 --> 00:05:37,350
it's all in a docker container we have

00:05:33,260 --> 00:05:38,970
pre-loaded libraries that a data science

00:05:37,350 --> 00:05:43,800
would typically data scientists would

00:05:38,970 --> 00:05:45,810
typically use or docker file is open on

00:05:43,800 --> 00:05:47,460
github so anybody can submit pull

00:05:45,810 --> 00:05:48,180
requests so it's really kind of

00:05:47,460 --> 00:05:53,340
crowd-sourced

00:05:48,180 --> 00:05:55,729
to be something that enables people to

00:05:53,340 --> 00:05:58,500
share the same reproducible environment

00:05:55,729 --> 00:06:00,770
and then datasets we see is kind of like

00:05:58,500 --> 00:06:04,860
the soil it's sort of like the external

00:06:00,770 --> 00:06:08,070
nutrients that feed feed the seed feed

00:06:04,860 --> 00:06:10,200
the kernel so when you create a kernel

00:06:08,070 --> 00:06:13,320
on Kaggle you have access to this

00:06:10,200 --> 00:06:14,820
catalog of I mentioned over 2000 public

00:06:13,320 --> 00:06:19,560
datasets as well as the datasets

00:06:14,820 --> 00:06:22,260
associated with competitions so there's

00:06:19,560 --> 00:06:25,860
no download required it's all in the

00:06:22,260 --> 00:06:28,020
cloud and then finally our next is

00:06:25,860 --> 00:06:29,460
community and I won't try to stretch the

00:06:28,020 --> 00:06:31,229
analogy further here because I think

00:06:29,460 --> 00:06:34,950
community is actually really quite

00:06:31,229 --> 00:06:36,680
unique so when you're sharing or when

00:06:34,950 --> 00:06:38,960
you're creating a kernel on kaggle

00:06:36,680 --> 00:06:40,880
you're doing so in

00:06:38,960 --> 00:06:43,430
huge community so you share your code

00:06:40,880 --> 00:06:45,979
you get feedback on your code you can

00:06:43,430 --> 00:06:49,099
iterate on it all of the code is public

00:06:45,979 --> 00:06:51,110
so if you're a new user who's never used

00:06:49,099 --> 00:06:52,910
a certain package before you can go find

00:06:51,110 --> 00:06:55,009
examples for it I like to call it codes

00:06:52,910 --> 00:07:00,560
Bo it's code inspiration it's right

00:06:55,009 --> 00:07:02,419
there and and also I need any kernel

00:07:00,560 --> 00:07:05,360
that you create anybody else can take it

00:07:02,419 --> 00:07:07,789
and fork it so that means that they can

00:07:05,360 --> 00:07:10,970
just make a copy of it and an extend

00:07:07,789 --> 00:07:13,220
extend that work and that also is its

00:07:10,970 --> 00:07:16,550
own sort of like collaborative community

00:07:13,220 --> 00:07:20,169
there and then finally is infrastructure

00:07:16,550 --> 00:07:23,479
so all of this is code that we execute

00:07:20,169 --> 00:07:26,240
and so we're extending that these

00:07:23,479 --> 00:07:28,130
compute resources to our global our

00:07:26,240 --> 00:07:29,240
global community enabling them to do

00:07:28,130 --> 00:07:30,979
things that they would be able to do

00:07:29,240 --> 00:07:33,740
with just their laptop locally

00:07:30,979 --> 00:07:36,470
especially a lot of users from other

00:07:33,740 --> 00:07:38,240
parts of the world and Wendy's going to

00:07:36,470 --> 00:07:41,449
talk a little bit about more details of

00:07:38,240 --> 00:07:43,849
our infrastructure in a little bit so

00:07:41,449 --> 00:07:45,199
yeah that's cavil kernels it's that you

00:07:43,849 --> 00:07:47,150
know conceptually it's like all of these

00:07:45,199 --> 00:07:48,740
things all wrapped up together which is

00:07:47,150 --> 00:07:53,630
why we picked somewhat confusing name

00:07:48,740 --> 00:07:56,180
for it but it's meaningful so to add a

00:07:53,630 --> 00:07:58,550
little more something a limb or concrete

00:07:56,180 --> 00:08:01,849
this is what the kernels page looks like

00:07:58,550 --> 00:08:05,659
on Kaggle it's I think we're over like

00:08:01,849 --> 00:08:07,880
160 thousand public kernels and every

00:08:05,659 --> 00:08:09,440
piece of data on Kaggle has a list of

00:08:07,880 --> 00:08:11,780
kernels attached to it this is the

00:08:09,440 --> 00:08:15,710
global listing so it's all kernels made

00:08:11,780 --> 00:08:18,620
public on Kaggle so and then creating a

00:08:15,710 --> 00:08:21,050
kernel is really as easy as clicking a

00:08:18,620 --> 00:08:24,259
new kernel button it's been spends up

00:08:21,050 --> 00:08:27,770
this environment and you can you select

00:08:24,259 --> 00:08:29,719
either a script or a notebook so a lot

00:08:27,770 --> 00:08:34,070
of users use scripts because it's just

00:08:29,719 --> 00:08:36,050
one file that executes and to start and

00:08:34,070 --> 00:08:38,270
it's ideal for fitting models and making

00:08:36,050 --> 00:08:41,479
competition submissions and then

00:08:38,270 --> 00:08:43,909
notebooks as we know a really ideal for

00:08:41,479 --> 00:08:45,680
more exploratory data analysis where you

00:08:43,909 --> 00:08:50,320
want to enter in a leave narrative with

00:08:45,680 --> 00:08:53,550
markdown and encode and share

00:08:50,320 --> 00:08:56,920
data visualizations maybe share a story

00:08:53,550 --> 00:09:00,009
so I'm you know if I was walking through

00:08:56,920 --> 00:09:01,300
here I would I would click notebook and

00:09:00,009 --> 00:09:02,860
this is what I would see next this is

00:09:01,300 --> 00:09:06,040
our notebook editor built on top of

00:09:02,860 --> 00:09:08,709
Jupiter and you get the option to add

00:09:06,040 --> 00:09:09,699
any data sources you can add more than

00:09:08,709 --> 00:09:13,540
one you can mix and match it

00:09:09,699 --> 00:09:15,579
automatically is be part of your

00:09:13,540 --> 00:09:17,699
environment so you can search datasets

00:09:15,579 --> 00:09:22,449
from our public data platform and

00:09:17,699 --> 00:09:24,730
competitions so this is the notebook

00:09:22,449 --> 00:09:27,610
editor after I've added the Bitcoin

00:09:24,730 --> 00:09:29,610
historical prices data set that one of

00:09:27,610 --> 00:09:33,940
our users publish that's really popular

00:09:29,610 --> 00:09:36,699
so a few things to point out here is you

00:09:33,940 --> 00:09:38,470
can see my cursor so there's input files

00:09:36,699 --> 00:09:40,149
if I click to expand that I can see a

00:09:38,470 --> 00:09:40,660
file preview of the data set that I'm

00:09:40,149 --> 00:09:44,230
working with

00:09:40,660 --> 00:09:47,380
so really able to see the the different

00:09:44,230 --> 00:09:49,029
columns and their descriptions and it

00:09:47,380 --> 00:09:53,220
can also add additional data sources if

00:09:49,029 --> 00:09:55,899
I decide to later on in my analysis we

00:09:53,220 --> 00:09:59,079
enable users to write their code in

00:09:55,899 --> 00:10:04,029
either Python or our I am also an AR

00:09:59,079 --> 00:10:06,790
user and but you Python here all of your

00:10:04,029 --> 00:10:08,410
code is private by default so this is

00:10:06,790 --> 00:10:09,550
actually a pretty new feature for us in

00:10:08,410 --> 00:10:11,319
the last few months and we've noticed

00:10:09,550 --> 00:10:13,420
that since enabling private kernels

00:10:11,319 --> 00:10:15,160
people iterate a lot more on their code

00:10:13,420 --> 00:10:16,480
because you can you know perfect

00:10:15,160 --> 00:10:18,160
something polished something before

00:10:16,480 --> 00:10:21,399
really is seeing it public for for

00:10:18,160 --> 00:10:23,980
feedback from the community and then

00:10:21,399 --> 00:10:28,180
yeah it's a simple you know sharing your

00:10:23,980 --> 00:10:30,550
code is is you just hit publish and so

00:10:28,180 --> 00:10:31,870
it's that it's really that easy

00:10:30,550 --> 00:10:33,730
so Wendy's going to talk a little bit

00:10:31,870 --> 00:10:37,610
more about the details of the Keio

00:10:33,730 --> 00:10:42,530
kernels infrastructure thanks Meg

00:10:37,610 --> 00:10:45,120
so cago kernels infrastructure is is

00:10:42,530 --> 00:10:46,860
conceptual conceptually it's very simple

00:10:45,120 --> 00:10:48,780
of course there's a lot of details this

00:10:46,860 --> 00:10:51,960
is a very high-level overview of the

00:10:48,780 --> 00:10:54,060
Catalan kernels infrastructure we furbot

00:10:51,960 --> 00:10:55,920
provide free computed for our users so

00:10:54,060 --> 00:11:00,600
of course we don't want people to abuse

00:10:55,920 --> 00:11:02,490
it so we have some compute limits so

00:11:00,600 --> 00:11:04,800
it's one hour of them actually this is

00:11:02,490 --> 00:11:08,310
unofficial like we quietly increased it

00:11:04,800 --> 00:11:11,190
maybe in the last few days every kernel

00:11:08,310 --> 00:11:14,400
has one hour of run time limit 16 gigs

00:11:11,190 --> 00:11:17,160
of memory for GPU cores and one gigs of

00:11:14,400 --> 00:11:18,780
output storage your data is not included

00:11:17,160 --> 00:11:21,540
in this output storage so data could be

00:11:18,780 --> 00:11:24,990
very big the input data that's living on

00:11:21,540 --> 00:11:27,690
cattle so we basically the top box

00:11:24,990 --> 00:11:30,060
basically is stuff is it's a browser so

00:11:27,690 --> 00:11:31,800
we want people to just you only have to

00:11:30,060 --> 00:11:33,480
have a browser you open the browser and

00:11:31,800 --> 00:11:35,100
you can start coding and all the data

00:11:33,480 --> 00:11:36,720
lives on the cloud your code looks on

00:11:35,100 --> 00:11:38,850
the cloud and you push it and it's just

00:11:36,720 --> 00:11:39,960
running on crap cloud so to make that

00:11:38,850 --> 00:11:42,690
possible

00:11:39,960 --> 00:11:45,210
everything is interacted through the

00:11:42,690 --> 00:11:48,660
what cago wept here which is a blue box

00:11:45,210 --> 00:11:51,300
in the middle and the data is that all

00:11:48,660 --> 00:11:53,790
of the data not just the execution data

00:11:51,300 --> 00:11:58,970
but also all the metadata of your kernel

00:11:53,790 --> 00:12:01,500
is saved in the sequel server as a

00:11:58,970 --> 00:12:04,410
relational database and then that your

00:12:01,500 --> 00:12:06,360
code or the data files and all these

00:12:04,410 --> 00:12:10,170
like larger file that needs to be

00:12:06,360 --> 00:12:12,720
executed when with the code are stored

00:12:10,170 --> 00:12:15,210
in blob storage so it's like a file

00:12:12,720 --> 00:12:17,370
storage the other thing is more for

00:12:15,210 --> 00:12:19,080
messaging and control of the worker

00:12:17,370 --> 00:12:21,810
that's in the backend so that's done

00:12:19,080 --> 00:12:25,280
with a pub sub we use Redis now but

00:12:21,810 --> 00:12:30,600
we're moving towards something else on

00:12:25,280 --> 00:12:32,370
the other side so the bottom box is kind

00:12:30,600 --> 00:12:36,600
of like the heart of the execution of

00:12:32,370 --> 00:12:39,510
the kernels so the kernels as Meg Stata

00:12:36,600 --> 00:12:41,970
there are two types - two main types one

00:12:39,510 --> 00:12:44,580
is more like the flat file so either

00:12:41,970 --> 00:12:48,080
like the it's kind of like the text file

00:12:44,580 --> 00:12:49,830
of Python or our julia code so that's

00:12:48,080 --> 00:12:54,090
executed from

00:12:49,830 --> 00:12:56,520
these are all conceptually capsulated in

00:12:54,090 --> 00:12:58,530
docker containers so those are a

00:12:56,520 --> 00:13:02,250
community manage so there the docker

00:12:58,530 --> 00:13:04,610
files are all on on github that you can

00:13:02,250 --> 00:13:06,540
commit and put put up or requests for

00:13:04,610 --> 00:13:08,730
packages that you want to use it but

00:13:06,540 --> 00:13:10,650
most of the stuff that usually I see

00:13:08,730 --> 00:13:14,880
mostly stuff that I need are already in

00:13:10,650 --> 00:13:16,740
there poor for the Jupiter notebooks

00:13:14,880 --> 00:13:19,560
it's a little different so you when you

00:13:16,740 --> 00:13:22,020
so it's not just like grabbing a text

00:13:19,560 --> 00:13:24,300
file and then execute against it so for

00:13:22,020 --> 00:13:27,330
kernels you have a session and then we

00:13:24,300 --> 00:13:29,640
interact we let people interact between

00:13:27,330 --> 00:13:33,300
the browser and the session through this

00:13:29,640 --> 00:13:34,440
cloud so that's basically our very

00:13:33,300 --> 00:13:39,450
high-level overview of the

00:13:34,440 --> 00:13:41,130
infrastructure so about some community

00:13:39,450 --> 00:13:43,500
stats we wanted to share it's very

00:13:41,130 --> 00:13:47,580
interesting because two years ago about

00:13:43,500 --> 00:13:49,890
April 2015 we started to launch kaggle

00:13:47,580 --> 00:13:52,350
kernels and at the time we didn't have

00:13:49,890 --> 00:13:55,020
all these data sets and kernels it's

00:13:52,350 --> 00:13:57,240
really a competition site and we

00:13:55,020 --> 00:13:58,800
launched this and we feel it agreed

00:13:57,240 --> 00:14:02,220
everybody would love it and we actually

00:13:58,800 --> 00:14:04,710
received a pretty big backlash from our

00:14:02,220 --> 00:14:06,540
community because nobody likes to work

00:14:04,710 --> 00:14:08,790
really hard on the competition where in

00:14:06,540 --> 00:14:11,220
the end somebody published a really high

00:14:08,790 --> 00:14:12,690
performing script and and I well and

00:14:11,220 --> 00:14:14,100
that everybody is like jumping on that

00:14:12,690 --> 00:14:16,860
and then you know you lose the

00:14:14,100 --> 00:14:18,810
competition so the community actually

00:14:16,860 --> 00:14:22,230
gave us a really hard time we fought for

00:14:18,810 --> 00:14:24,090
that it's kind of funny looking back two

00:14:22,230 --> 00:14:25,320
years after and we realized a lot of

00:14:24,090 --> 00:14:27,840
people have changed our mind towards

00:14:25,320 --> 00:14:29,580
this because they realize like okay we

00:14:27,840 --> 00:14:31,680
still all hate the high performing

00:14:29,580 --> 00:14:33,210
scripts published at the end of the

00:14:31,680 --> 00:14:36,330
company like towards the end of the

00:14:33,210 --> 00:14:39,600
competition like two days before but all

00:14:36,330 --> 00:14:41,160
of them agree that I was like I changed

00:14:39,600 --> 00:14:43,350
my mind I really learned so much from

00:14:41,160 --> 00:14:45,270
looking at other people's kernels and

00:14:43,350 --> 00:14:48,350
looking at other people's scripts and

00:14:45,270 --> 00:14:52,230
just be able being able to like search

00:14:48,350 --> 00:14:55,020
on like methods that I wanted to use on

00:14:52,230 --> 00:14:57,090
like regression or like you know how to

00:14:55,020 --> 00:14:59,850
deal with this categorical variable is

00:14:57,090 --> 00:15:01,650
very valuable and this is the usage

00:14:59,850 --> 00:15:06,029
graph you know

00:15:01,650 --> 00:15:09,630
over 150,000 public kernels and 62,000

00:15:06,029 --> 00:15:11,460
authors and you can see that I was

00:15:09,630 --> 00:15:14,160
flattered before and the rule I took off

00:15:11,460 --> 00:15:18,660
there a few very significant events are

00:15:14,160 --> 00:15:20,910
in our history we initially only started

00:15:18,660 --> 00:15:24,510
with the scripts to flat file and then

00:15:20,910 --> 00:15:26,580
we ourselves are no Jupiter notebook

00:15:24,510 --> 00:15:28,680
users we realized that our community

00:15:26,580 --> 00:15:32,190
would love to use that so we launched

00:15:28,680 --> 00:15:35,700
stupider notebook on cago kernels like

00:15:32,190 --> 00:15:37,290
maybe six months after that usage was

00:15:35,700 --> 00:15:39,779
still low but we definitely saw the

00:15:37,290 --> 00:15:43,170
kernels starting the the Jupiter

00:15:39,779 --> 00:15:45,830
notebooks started to take off one very

00:15:43,170 --> 00:15:48,510
important thing that happened there was

00:15:45,830 --> 00:15:51,060
about a year after we launched it we

00:15:48,510 --> 00:15:52,890
launched Kaggle datasets and that really

00:15:51,060 --> 00:15:54,420
caused a kind of like an explosive

00:15:52,890 --> 00:15:57,300
growth from the number of kernels

00:15:54,420 --> 00:15:59,820
because people are realizing like you

00:15:57,300 --> 00:16:01,680
know like you could just go and explore

00:15:59,820 --> 00:16:03,540
a public data set on kaggle and then

00:16:01,680 --> 00:16:05,400
start to work on it you don't have to

00:16:03,540 --> 00:16:07,110
download anything and then your results

00:16:05,400 --> 00:16:08,970
are already published and then people

00:16:07,110 --> 00:16:11,910
can jump on and comment so it's really

00:16:08,970 --> 00:16:16,080
fun so that caused a big usage a year

00:16:11,910 --> 00:16:18,480
and a half after original launch we felt

00:16:16,080 --> 00:16:21,870
that the cago kernels was mature enough

00:16:18,480 --> 00:16:22,950
that we ran a competition that was very

00:16:21,870 --> 00:16:25,650
different from all the other

00:16:22,950 --> 00:16:28,230
competitions from before this is a

00:16:25,650 --> 00:16:31,260
kernels only competition so instead of

00:16:28,230 --> 00:16:32,910
submitting your predictions as CSV files

00:16:31,260 --> 00:16:35,820
to cattle and they get a score you

00:16:32,910 --> 00:16:38,100
submit your code through cattle kernels

00:16:35,820 --> 00:16:41,040
and then you make sure that it's

00:16:38,100 --> 00:16:44,610
executable and to work and then we can

00:16:41,040 --> 00:16:46,650
run it to get new predictions if we have

00:16:44,610 --> 00:16:49,620
new data coming in it was very very very

00:16:46,650 --> 00:16:51,420
beneficial for time series data to

00:16:49,620 --> 00:16:54,360
ensure that you have new data come in

00:16:51,420 --> 00:16:57,089
and people are no not overfitting that

00:16:54,360 --> 00:16:59,160
design was very for me I was very

00:16:57,089 --> 00:17:00,800
revolutionary because we weren't able to

00:16:59,160 --> 00:17:03,839
design a competition like that before

00:17:00,800 --> 00:17:07,530
without the help of cattle kernels so

00:17:03,839 --> 00:17:09,449
yeah we definitely experienced different

00:17:07,530 --> 00:17:12,120
events and time and overall we're

00:17:09,449 --> 00:17:14,300
steadily or sometimes exponentially

00:17:12,120 --> 00:17:14,300
growing

00:17:14,699 --> 00:17:21,370
we had a little debate our versus Python

00:17:18,699 --> 00:17:22,029
every time it goes into a very strong

00:17:21,370 --> 00:17:24,779
debate

00:17:22,029 --> 00:17:29,350
I try to be language agnostic but

00:17:24,779 --> 00:17:31,380
leaning more towards Python you see we

00:17:29,350 --> 00:17:35,890
have this Meg made this beautiful graph

00:17:31,380 --> 00:17:37,710
over time of cago kernels language our

00:17:35,890 --> 00:17:41,440
versus Python we have a little other

00:17:37,710 --> 00:17:44,620
being Julia they kind of have

00:17:41,440 --> 00:17:47,049
disappeared Python it's definitely

00:17:44,620 --> 00:17:49,000
getting more and more usage and I don't

00:17:47,049 --> 00:17:49,750
have a great explanation for this my

00:17:49,000 --> 00:17:52,000
mind

00:17:49,750 --> 00:17:54,460
my guess is maybe deep learning is

00:17:52,000 --> 00:17:56,350
taking a lot of attention and people are

00:17:54,460 --> 00:17:58,240
trying new things on deep learning and

00:17:56,350 --> 00:18:00,399
most of the code that I see in deep

00:17:58,240 --> 00:18:03,130
learning art in Python but I don't know

00:18:00,399 --> 00:18:06,460
you can make your own make your own

00:18:03,130 --> 00:18:09,850
interpretation the other thing we want

00:18:06,460 --> 00:18:11,529
to look at is so we have it's very

00:18:09,850 --> 00:18:13,389
interesting right because like I used

00:18:11,529 --> 00:18:15,340
rubes in notebook all the time I wanna

00:18:13,389 --> 00:18:17,740
know what other people are using or

00:18:15,340 --> 00:18:21,429
people are using flat files executing

00:18:17,740 --> 00:18:23,200
Python and what did they use it for so

00:18:21,429 --> 00:18:26,799
we happen to have these you know

00:18:23,200 --> 00:18:30,279
hundreds of thousands of kernels that we

00:18:26,799 --> 00:18:35,320
can analyze so so this is a graph of

00:18:30,279 --> 00:18:37,990
over time the popularity of know the the

00:18:35,320 --> 00:18:41,470
number of notebooks versus scripts so

00:18:37,990 --> 00:18:45,820
you see that it was very it was very

00:18:41,470 --> 00:18:48,279
flat before the the scripts which are

00:18:45,820 --> 00:18:50,350
the flat files were about similar or the

00:18:48,279 --> 00:18:51,970
notebooks actually have less usage but

00:18:50,350 --> 00:18:54,250
after a certain time

00:18:51,970 --> 00:18:56,649
Jupiter notebook just took off and it

00:18:54,250 --> 00:19:00,549
doesn't seem like it'll change the blue

00:18:56,649 --> 00:19:03,340
line is art markdown which is basically

00:19:00,549 --> 00:19:05,529
just our flat file but it's interesting

00:19:03,340 --> 00:19:07,690
to look at so we also have this notion

00:19:05,529 --> 00:19:10,090
of voting so you can look at somebody's

00:19:07,690 --> 00:19:11,500
work you can see the code you could vote

00:19:10,090 --> 00:19:16,809
if you like it and you can't download

00:19:11,500 --> 00:19:18,279
you can vote so we realize that a lot of

00:19:16,809 --> 00:19:20,590
times I really like to our markdown

00:19:18,279 --> 00:19:23,799
kernels and we realize that that's the

00:19:20,590 --> 00:19:26,110
it's a lower volume on cago but they're

00:19:23,799 --> 00:19:27,659
generally very high quality so they're

00:19:26,110 --> 00:19:30,909
very well voted

00:19:27,659 --> 00:19:33,960
so we also could look at what are people

00:19:30,909 --> 00:19:38,679
using on Kaggle so we looked at the top

00:19:33,960 --> 00:19:41,589
thousand most voted cube notebooks in

00:19:38,679 --> 00:19:44,919
each of the hour versus Python languages

00:19:41,589 --> 00:19:46,929
and in did it work cloud and saw that it

00:19:44,919 --> 00:19:48,339
was not too surprising that scikit-learn

00:19:46,929 --> 00:19:52,809
was right there

00:19:48,339 --> 00:19:54,849
pandas was right there matplotlib

00:19:52,809 --> 00:19:56,710
because that we're looking at the

00:19:54,849 --> 00:19:58,359
notebooks I'm sure for the flat files

00:19:56,710 --> 00:19:59,309
nobody not a lot of people would use

00:19:58,359 --> 00:20:03,759
matplotlib

00:19:59,309 --> 00:20:05,139
see bora is also there it's coggle so

00:20:03,759 --> 00:20:07,499
there's a lot of machine learning stuff

00:20:05,139 --> 00:20:12,129
going out with scikit-learn with Kerris

00:20:07,499 --> 00:20:13,929
with metrics and different kinds of

00:20:12,129 --> 00:20:17,200
models I'm a little bit surprised that

00:20:13,929 --> 00:20:18,820
XG boost was not on it but I feel like

00:20:17,200 --> 00:20:22,809
maybe we're looking at the notebooks

00:20:18,820 --> 00:20:25,539
maybe they're more into files for on the

00:20:22,809 --> 00:20:29,649
other hand for our packages not very

00:20:25,539 --> 00:20:32,259
surprising that ggplot2 and the whole

00:20:29,649 --> 00:20:34,359
tidy verse is big up there I actually

00:20:32,259 --> 00:20:36,609
had to reduce the font size for this

00:20:34,359 --> 00:20:41,669
graph because if I don't then ggplot2 is

00:20:36,609 --> 00:20:44,349
like half of the graph so of course

00:20:41,669 --> 00:20:48,029
carat is there people are doing a lot of

00:20:44,349 --> 00:20:51,729
classification and regression on Kaggle

00:20:48,029 --> 00:20:53,619
so other than analyzing code we also

00:20:51,729 --> 00:20:54,960
want to look at how people interact with

00:20:53,619 --> 00:20:57,339
each other because we have all these

00:20:54,960 --> 00:20:58,599
people interacting with other people's

00:20:57,339 --> 00:21:01,509
code so we wanted to see what people

00:20:58,599 --> 00:21:06,849
like and what what can you do to get

00:21:01,509 --> 00:21:09,879
more likes we have this follower graph

00:21:06,849 --> 00:21:12,099
so we launched this feature maybe a few

00:21:09,879 --> 00:21:13,899
months ago and then started to get a lot

00:21:12,099 --> 00:21:17,320
of attention so you could if you like an

00:21:13,899 --> 00:21:18,700
author you can follow them and initially

00:21:17,320 --> 00:21:19,989
the graph looked like this and it

00:21:18,700 --> 00:21:21,639
started to progress and then we get

00:21:19,989 --> 00:21:26,169
getting more and more following more and

00:21:21,639 --> 00:21:28,239
more following basically a user can

00:21:26,169 --> 00:21:30,809
interact with somebody else's kernel in

00:21:28,239 --> 00:21:32,889
various ways and various degrees of

00:21:30,809 --> 00:21:35,259
involvement I guess you could view it

00:21:32,889 --> 00:21:37,269
you keep you could see us so on the

00:21:35,259 --> 00:21:39,250
right I have a screenshot from one of

00:21:37,269 --> 00:21:41,530
the pretty good

00:21:39,250 --> 00:21:45,970
from one of the competition's called

00:21:41,530 --> 00:21:48,370
Wikipedia traffic forecasts and you can

00:21:45,970 --> 00:21:52,720
view it you could vote it so that number

00:21:48,370 --> 00:21:54,400
137 is number of votes I'm there it's

00:21:52,720 --> 00:21:58,090
earning a medal because it's like it's

00:21:54,400 --> 00:21:59,680
gotten a pretty good amount of votes you

00:21:58,090 --> 00:22:02,380
could if you like it you can follow the

00:21:59,680 --> 00:22:04,600
author you could comment so I copied one

00:22:02,380 --> 00:22:06,400
of the comments on the left side so

00:22:04,600 --> 00:22:10,060
somebody made a comment of like oh great

00:22:06,400 --> 00:22:11,770
work but didn't you see this there's

00:22:10,060 --> 00:22:13,660
this issue and the author very quickly

00:22:11,770 --> 00:22:15,400
replied thank you for correcting me I

00:22:13,660 --> 00:22:18,520
fixed it so you could comment on those

00:22:15,400 --> 00:22:21,040
you could also fork so Forks script on

00:22:18,520 --> 00:22:23,140
the right side is where you could make a

00:22:21,040 --> 00:22:24,490
copy of this kernel and then you can

00:22:23,140 --> 00:22:27,070
just build on top of it so you don't

00:22:24,490 --> 00:22:29,320
have to copy and paste everything it's

00:22:27,070 --> 00:22:31,300
funny because the previous talk Hillary

00:22:29,320 --> 00:22:34,570
was talking about version control and

00:22:31,300 --> 00:22:37,120
all these fork thing when we first

00:22:34,570 --> 00:22:38,770
introduced cago kernels to the community

00:22:37,120 --> 00:22:41,680
of all these data sciences even some of

00:22:38,770 --> 00:22:43,600
the very high-profile CAG lers very

00:22:41,680 --> 00:22:45,220
talented data scientists they don't do

00:22:43,600 --> 00:22:48,070
version control they're not familiar

00:22:45,220 --> 00:22:50,530
with fourth at all they were confused

00:22:48,070 --> 00:22:54,370
while that concept was very popular and

00:22:50,530 --> 00:22:57,580
github for software engineers so so

00:22:54,370 --> 00:22:59,440
these are very interesting ways that

00:22:57,580 --> 00:23:02,980
people could interact with cattle

00:22:59,440 --> 00:23:05,080
kernels we also looked at interesting

00:23:02,980 --> 00:23:08,920
things like how many votes are you gonna

00:23:05,080 --> 00:23:11,650
get like the number of votes versus the

00:23:08,920 --> 00:23:13,540
user account age and to our surprise we

00:23:11,650 --> 00:23:15,940
thought you know maybe if you're on a go

00:23:13,540 --> 00:23:18,460
for a long time you'll write better

00:23:15,940 --> 00:23:20,920
content that gets a lot of votes and to

00:23:18,460 --> 00:23:24,520
our surprise a lot of the very new

00:23:20,920 --> 00:23:26,710
accounts create very well liked content

00:23:24,520 --> 00:23:27,850
very well liked kernels and we're

00:23:26,710 --> 00:23:29,590
actually really happy to see that

00:23:27,850 --> 00:23:31,090
because that's a that's the whole point

00:23:29,590 --> 00:23:33,490
we want people to open the browser and

00:23:31,090 --> 00:23:35,770
there's no learning curve at all you

00:23:33,490 --> 00:23:37,330
just start coding and you don't have to

00:23:35,770 --> 00:23:39,520
like learn all these five different

00:23:37,330 --> 00:23:42,070
tools to start using and sharing your

00:23:39,520 --> 00:23:45,460
stuff look up get get to have commands

00:23:42,070 --> 00:23:48,160
all the time you just click run and it's

00:23:45,460 --> 00:23:51,940
like there so we like that

00:23:48,160 --> 00:23:58,750
it also helps I guess

00:23:51,940 --> 00:24:01,420
if I guess if you have the number so we

00:23:58,750 --> 00:24:03,670
also saw that if you because we have

00:24:01,420 --> 00:24:05,650
version control so every time you hit

00:24:03,670 --> 00:24:07,540
run we save a new version so you can

00:24:05,650 --> 00:24:11,020
always go back so we also saw that

00:24:07,540 --> 00:24:12,640
people are better at publishing

00:24:11,020 --> 00:24:15,430
something first and then go back and an

00:24:12,640 --> 00:24:17,320
iterate or publishing something get some

00:24:15,430 --> 00:24:19,630
feedback and then go in a different

00:24:17,320 --> 00:24:22,900
direction or something so we definitely

00:24:19,630 --> 00:24:27,820
see that the number of versions is

00:24:22,900 --> 00:24:30,700
related to the number of votes and the

00:24:27,820 --> 00:24:33,310
other thing is we we don't know what's

00:24:30,700 --> 00:24:35,950
the cause of what but if you have a lot

00:24:33,310 --> 00:24:37,690
of votes if you have a lot of followers

00:24:35,950 --> 00:24:39,070
and you have a lot of votes so it could

00:24:37,690 --> 00:24:40,900
be that you because you have a lot of

00:24:39,070 --> 00:24:42,340
followers you have a lot of oats or you

00:24:40,900 --> 00:24:46,150
can because you have a lot of votes you

00:24:42,340 --> 00:24:47,880
have a lot of followers so yeah so those

00:24:46,150 --> 00:24:51,540
are our interesting findings from

00:24:47,880 --> 00:24:56,110
exploring on our on all of our kernels

00:24:51,540 --> 00:24:58,140
our marketing team is doing this cackle

00:24:56,110 --> 00:25:00,790
machine learning data science survey

00:24:58,140 --> 00:25:02,550
which we're very excited about we want

00:25:00,790 --> 00:25:04,870
to do like a Stack Overflow style

00:25:02,550 --> 00:25:07,030
understanding our community with tools

00:25:04,870 --> 00:25:10,240
people use and stuff like that so please

00:25:07,030 --> 00:25:14,050
if you if you're interested in joining

00:25:10,240 --> 00:25:16,120
these research and please help help us

00:25:14,050 --> 00:25:19,120
out by for me filling out those surveys

00:25:16,120 --> 00:25:21,160
will also after we're done with that it

00:25:19,120 --> 00:25:23,560
will also publish these results of

00:25:21,160 --> 00:25:26,620
course on cattle cattle datasets so

00:25:23,560 --> 00:25:31,210
people can analyze them I'm gonna give

00:25:26,620 --> 00:25:32,710
back to Mick yeah so if you want to

00:25:31,210 --> 00:25:34,330
learn more about our community and how

00:25:32,710 --> 00:25:36,940
data scientists and people who work with

00:25:34,330 --> 00:25:38,350
data work you can yeah check out the

00:25:36,940 --> 00:25:41,650
results of that survey when we publish

00:25:38,350 --> 00:25:44,980
it on cattle datasets so to kind of wrap

00:25:41,650 --> 00:25:49,150
up I wanted to kind of highlight some

00:25:44,980 --> 00:25:51,130
actual examples of our users doing

00:25:49,150 --> 00:25:55,320
collaborative data science with kernels

00:25:51,130 --> 00:25:58,510
on Kaggle is just kind of a case study

00:25:55,320 --> 00:26:01,390
so the first example is this playground

00:25:58,510 --> 00:26:02,860
competition that we launched a month ago

00:26:01,390 --> 00:26:04,960
or so

00:26:02,860 --> 00:26:07,570
playground competitions on Kegel aren't

00:26:04,960 --> 00:26:10,330
for cash prizes normally they use public

00:26:07,570 --> 00:26:11,799
data typically so you can cheat but it's

00:26:10,330 --> 00:26:15,370
just for fun it's a way to learn and

00:26:11,799 --> 00:26:17,320
just interact with a new group of data

00:26:15,370 --> 00:26:20,230
data scientists and other competitors on

00:26:17,320 --> 00:26:21,970
the platform so this competition was a

00:26:20,230 --> 00:26:25,000
little bit different because we

00:26:21,970 --> 00:26:28,330
incentivize sharing code and data with

00:26:25,000 --> 00:26:30,100
cash prizes and the challenge is to

00:26:28,330 --> 00:26:34,120
predict New York City Taxi trip

00:26:30,100 --> 00:26:35,770
durations but really the core of this

00:26:34,120 --> 00:26:37,270
competition is not really a competition

00:26:35,770 --> 00:26:37,900
it's about sharing code and learning

00:26:37,270 --> 00:26:40,900
from each other

00:26:37,900 --> 00:26:43,990
so we had a bunch of prizes for 13

00:26:40,900 --> 00:26:45,850
popular helpful kernels so there's we're

00:26:43,990 --> 00:26:47,549
awarding bi-weekly prizes it's actually

00:26:45,850 --> 00:26:50,710
still ongoing if you want to participate

00:26:47,549 --> 00:26:54,640
and then also we're awarding prizes it

00:26:50,710 --> 00:26:57,010
looks like I guess in 22 days for like

00:26:54,640 --> 00:26:58,600
tutorial kernels interactive data

00:26:57,010 --> 00:27:01,929
visualization kernels and things like

00:26:58,600 --> 00:27:04,030
that and then also twelve thousand

00:27:01,929 --> 00:27:07,210
dollars in prizes for top three

00:27:04,030 --> 00:27:09,070
supplementary data sources shared so

00:27:07,210 --> 00:27:11,530
kind of what happen when we kick this

00:27:09,070 --> 00:27:13,720
off it's still ongoing as I said this is

00:27:11,530 --> 00:27:15,309
one of the very first I think this is

00:27:13,720 --> 00:27:16,570
the second first or second kernel that

00:27:15,309 --> 00:27:18,910
we awarded a prize to in this

00:27:16,570 --> 00:27:23,110
competition by a competitions

00:27:18,910 --> 00:27:28,510
Grandmaster Beluga so and his kernel is

00:27:23,110 --> 00:27:30,910
a start to finish from EDA exploratory

00:27:28,510 --> 00:27:33,820
data analysis of the dataset through

00:27:30,910 --> 00:27:35,890
some data processing and then some

00:27:33,820 --> 00:27:37,809
feature engineering so you can see he's

00:27:35,890 --> 00:27:41,320
defining some different clusters of

00:27:37,809 --> 00:27:43,540
Manhattan here and then he also shows

00:27:41,320 --> 00:27:46,090
you how to make to fit a model using

00:27:43,540 --> 00:27:48,010
extra boost incredibly incredibly

00:27:46,090 --> 00:27:50,169
popular in our community and make a

00:27:48,010 --> 00:27:51,549
submission to the competition so if

00:27:50,169 --> 00:27:52,990
you're a new user like you're going to

00:27:51,549 --> 00:27:54,820
you're going to look at the kernels page

00:27:52,990 --> 00:27:56,410
of this competition and see that

00:27:54,820 --> 00:27:58,660
somebody has already put together this

00:27:56,410 --> 00:28:00,220
beautiful analysis helped you understand

00:27:58,660 --> 00:28:01,750
the data helped you understand how to

00:28:00,220 --> 00:28:03,340
create a submission and this is

00:28:01,750 --> 00:28:05,950
something that you can you can build off

00:28:03,340 --> 00:28:08,320
of and work on by forking it and

00:28:05,950 --> 00:28:09,580
potentially create something even better

00:28:08,320 --> 00:28:11,050
and because he's a competition's

00:28:09,580 --> 00:28:12,870
grandmaster he's very competitive and

00:28:11,050 --> 00:28:16,330
he'll try to beat you again

00:28:12,870 --> 00:28:17,530
so really it's it's really actually kind

00:28:16,330 --> 00:28:21,130
of beautiful to see this kind of stuff

00:28:17,530 --> 00:28:23,380
openly shared in our community and it's

00:28:21,130 --> 00:28:26,080
quickly become the most popular

00:28:23,380 --> 00:28:27,760
competition in terms of kernels so far

00:28:26,080 --> 00:28:30,400
so there's a lot of code we should check

00:28:27,760 --> 00:28:32,679
it out and then kind of the second

00:28:30,400 --> 00:28:34,960
example of incentivizing collaborative

00:28:32,679 --> 00:28:37,630
data science in our community is we

00:28:34,960 --> 00:28:42,970
kicked off this award series every week

00:28:37,630 --> 00:28:45,309
we're awarding $500 to basically just

00:28:42,970 --> 00:28:48,850
excellent kernel created on our data

00:28:45,309 --> 00:28:50,380
sets platform so if you share a really

00:28:48,850 --> 00:28:52,350
helpful tutorial that helps other get

00:28:50,380 --> 00:28:58,030
others get started with some new tool or

00:28:52,350 --> 00:29:02,200
library or even a unique data set you

00:28:58,030 --> 00:29:03,549
can win $500 and our weekly award will

00:29:02,200 --> 00:29:06,010
probably be announcing this week's award

00:29:03,549 --> 00:29:07,780
tomorrow and then also we're doing a ten

00:29:06,010 --> 00:29:09,910
thousand dollars for data sets Awards

00:29:07,780 --> 00:29:11,590
that's if you share a data set on Kangol

00:29:09,910 --> 00:29:14,320
and august still be automatically

00:29:11,590 --> 00:29:18,370
considered for some of this this money

00:29:14,320 --> 00:29:21,850
so this is I think the person who won

00:29:18,370 --> 00:29:25,780
the kernel award last week did this

00:29:21,850 --> 00:29:28,600
gorgeous exploratory data analysis on

00:29:25,780 --> 00:29:31,270
this data set of ten years of political

00:29:28,600 --> 00:29:32,650
political conflict in Africa this is a

00:29:31,270 --> 00:29:35,230
data set that was published by one of

00:29:32,650 --> 00:29:37,630
our users who probably cares a lot about

00:29:35,230 --> 00:29:40,020
this issue and it was actually a

00:29:37,630 --> 00:29:44,280
completely brand-new user who decided to

00:29:40,020 --> 00:29:48,760
explore this data really extensively and

00:29:44,280 --> 00:29:50,500
this is an arm markdown kernel has

00:29:48,760 --> 00:29:53,890
really nice code folding so you can see

00:29:50,500 --> 00:29:55,900
the the code underlying the analysis it

00:29:53,890 --> 00:29:59,590
shares some beautiful ggplot but then

00:29:55,900 --> 00:30:02,020
also does some exploratory data analysis

00:29:59,590 --> 00:30:04,210
using an interactive mapping library

00:30:02,020 --> 00:30:06,190
leaflet which I've never used before so

00:30:04,210 --> 00:30:10,299
I was able to kind of check out the code

00:30:06,190 --> 00:30:11,740
and I could I could fork this maybe and

00:30:10,299 --> 00:30:12,850
play around with it

00:30:11,740 --> 00:30:14,980
so those are just some really cool

00:30:12,850 --> 00:30:17,230
examples and you know we have this

00:30:14,980 --> 00:30:21,940
catalog of 100 and almost 160,000

00:30:17,230 --> 00:30:22,850
kernels so it's only growing so to wrap

00:30:21,940 --> 00:30:26,240
up

00:30:22,850 --> 00:30:27,770
what have we learned from you know

00:30:26,240 --> 00:30:29,570
putting together this talk really taking

00:30:27,770 --> 00:30:32,960
a look at what what our users are

00:30:29,570 --> 00:30:35,180
creating we've definitely learned that

00:30:32,960 --> 00:30:37,120
Kaggle kernels is has been a great place

00:30:35,180 --> 00:30:40,790
for our users to showcase their work

00:30:37,120 --> 00:30:42,260
learn new things and collaborate to make

00:30:40,790 --> 00:30:43,810
it easy for people to get started we

00:30:42,260 --> 00:30:46,520
make it easy for people to find examples

00:30:43,810 --> 00:30:50,060
and find inspiration and find people who

00:30:46,520 --> 00:30:53,870
are experts that they can communicate

00:30:50,060 --> 00:30:57,860
with all in one place and then you know

00:30:53,870 --> 00:31:01,460
with our large community of 100 and 100

00:30:57,860 --> 00:31:04,340
million data scientists registered users

00:31:01,460 --> 00:31:06,020
we can learn valuable industry trends

00:31:04,340 --> 00:31:07,910
both by looking at we know what

00:31:06,020 --> 00:31:10,340
libraries people are using what

00:31:07,910 --> 00:31:12,410
languages and things like that and then

00:31:10,340 --> 00:31:13,670
also with the the machine learning and

00:31:12,410 --> 00:31:16,430
data science survey that would be

00:31:13,670 --> 00:31:18,370
publishing and then finally probably

00:31:16,430 --> 00:31:21,110
most importantly is if you give people

00:31:18,370 --> 00:31:24,050
good data if you enable people to share

00:31:21,110 --> 00:31:27,290
data and ideas and interesting problems

00:31:24,050 --> 00:31:29,480
and also you know we're very glad and

00:31:27,290 --> 00:31:31,100
happy to be extending the compute

00:31:29,480 --> 00:31:34,190
resources that we can to our community

00:31:31,100 --> 00:31:35,330
we see a lot of great content and you

00:31:34,190 --> 00:31:38,480
know our mission is to help the world

00:31:35,330 --> 00:31:42,650
learn from data so it's amazing to see

00:31:38,480 --> 00:31:44,600
that in action with kernels so if you

00:31:42,650 --> 00:31:49,660
have questions if you want to publish a

00:31:44,600 --> 00:31:49,660
dataset you can reach out to us here

00:31:55,250 --> 00:32:28,100
I think we want to enable people to do

00:32:25,340 --> 00:32:30,170
both so I think it's more rare to have

00:32:28,100 --> 00:32:32,390
the ability to do that in the cloud and

00:32:30,170 --> 00:32:33,590
have those resources free to you users

00:32:32,390 --> 00:32:35,750
are still absolutely free to download

00:32:33,590 --> 00:32:37,910
the datasets and you know we make our

00:32:35,750 --> 00:32:42,260
docker file people can pull our docker

00:32:37,910 --> 00:32:44,480
docker file as well and you they could

00:32:42,260 --> 00:32:49,630
recreate cattle locally if they if they

00:32:44,480 --> 00:32:49,630
so wish so yeah

00:33:10,970 --> 00:33:18,570
availability ah you mean like are they

00:33:16,710 --> 00:33:27,960
going to live on cattle forever or more

00:33:18,570 --> 00:33:29,760
like can you execute them yeah so we

00:33:27,960 --> 00:33:32,220
don't have any plans to make them

00:33:29,760 --> 00:33:34,050
unavailable at any point they are all

00:33:32,220 --> 00:33:39,810
public Colonels are released at Apache

00:33:34,050 --> 00:33:42,420
2.0 license as yeah we don't have any

00:33:39,810 --> 00:33:44,490
reason or plans to not make them not

00:33:42,420 --> 00:33:48,080
available or like take them and then use

00:33:44,490 --> 00:33:48,080
them install them or something

00:33:55,929 --> 00:34:02,470
ah yeah that's a good point about

00:33:59,440 --> 00:34:04,299
dependency and stuff that could be a

00:34:02,470 --> 00:34:07,119
problem we don't have any plans to

00:34:04,299 --> 00:34:09,429
backward support like you know all

00:34:07,119 --> 00:34:11,050
packages or deprecated methods and stuff

00:34:09,429 --> 00:34:14,649
like that we we think we're a platform

00:34:11,050 --> 00:34:16,750
that the the code user probably should

00:34:14,649 --> 00:34:18,490
be responsible for that or like somebody

00:34:16,750 --> 00:34:23,010
should fork the code and then make it

00:34:18,490 --> 00:34:23,010
more applicable or like try to edit it

00:34:35,940 --> 00:34:42,240
I can share it in which we can share it

00:34:39,659 --> 00:34:45,950
on one Google Doc very soon yeah yeah

00:34:42,240 --> 00:34:45,950
but I'm glad you like it

00:34:48,679 --> 00:34:58,560
ah well yeah yeah we actually do have a

00:34:55,649 --> 00:34:59,550
medical data set it's very out of date

00:34:58,560 --> 00:35:01,140
right now

00:34:59,550 --> 00:35:04,349
it's like literally on my to-do list

00:35:01,140 --> 00:35:05,700
next week to update her or in the next

00:35:04,349 --> 00:35:08,730
couple of weeks I won't make it too hard

00:35:05,700 --> 00:35:10,440
of a promise but to update you know some

00:35:08,730 --> 00:35:11,880
data that we can share about these

00:35:10,440 --> 00:35:12,990
things all right you can actually

00:35:11,880 --> 00:35:15,030
analyze it we'll be able to reproduce

00:35:12,990 --> 00:35:17,579
some of these things as well we're

00:35:15,030 --> 00:35:19,470
actually really excited to eventually we

00:35:17,579 --> 00:35:21,750
probably have like database as a data

00:35:19,470 --> 00:35:23,880
source for cattle right now it's all

00:35:21,750 --> 00:35:27,030
from like CSV files and data files like

00:35:23,880 --> 00:35:29,130
that so therefore we can't use kavik

00:35:27,030 --> 00:35:31,200
URLs for doing this analysis because a

00:35:29,130 --> 00:35:33,750
lot of that is not on cattle and there's

00:35:31,200 --> 00:35:35,460
like port the data over to our local

00:35:33,750 --> 00:35:37,619
computers and do analysis that way and

00:35:35,460 --> 00:35:39,690
then we can't share between us so we're

00:35:37,619 --> 00:35:42,869
like ah duh this is what cago kernel

00:35:39,690 --> 00:35:44,819
exists and yeah we can't we can't use it

00:35:42,869 --> 00:35:48,260
yet but hopefully that'll be soon and we

00:35:44,819 --> 00:35:48,260
can connect it to our database

00:35:54,710 --> 00:35:57,179

YouTube URL: https://www.youtube.com/watch?v=ENPBTl0uNOE


