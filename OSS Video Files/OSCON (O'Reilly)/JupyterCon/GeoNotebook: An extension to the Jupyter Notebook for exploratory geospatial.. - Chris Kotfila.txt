Title: GeoNotebook: An extension to the Jupyter Notebook for exploratory geospatial.. - Chris Kotfila
Publication date: 2017-09-22
Playlist: JupyterCon
Description: 
	Chris Kotfila offers an overview of the GeoNotebook extension to the Jupyter Notebook, which provides interactive visualization and analysis of geospatial data. Unlike other geospatial extensions to the Jupyter Notebook, GeoNotebook includes a fully integrated tile server providing easy visualization of vector and raster data formats.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,599 --> 00:00:06,279
good afternoon it's a pleasure to be

00:00:03,489 --> 00:00:08,980
here my name is Chris capella I'm an

00:00:06,279 --> 00:00:11,710
open-source software engineer at kitware

00:00:08,980 --> 00:00:13,570
incorporated today I'm gonna be talking

00:00:11,710 --> 00:00:15,450
about your notebook an extension of the

00:00:13,570 --> 00:00:18,550
joopa notebook for exploratory

00:00:15,450 --> 00:00:21,130
geospatial analysis so I'm just going to

00:00:18,550 --> 00:00:22,329
do a quick introduction give a little

00:00:21,130 --> 00:00:25,630
bit of background information on

00:00:22,329 --> 00:00:27,399
geospatial data types I'm going to do a

00:00:25,630 --> 00:00:30,430
demonstration of the extension in action

00:00:27,399 --> 00:00:32,439
live demo and then I'm going to talk

00:00:30,430 --> 00:00:34,420
about some of the technical objectives

00:00:32,439 --> 00:00:36,610
underlying technologies and some of the

00:00:34,420 --> 00:00:38,680
current limitations of the extension as

00:00:36,610 --> 00:00:42,820
it exists right now so let's go ahead

00:00:38,680 --> 00:00:46,110
and get started so what is geo notebook

00:00:42,820 --> 00:00:48,160
you know geo notebook is a Python and

00:00:46,110 --> 00:00:50,410
JavaScript extension to the Jupiter

00:00:48,160 --> 00:00:52,350
notebook there's really two salient

00:00:50,410 --> 00:00:55,120
features that it adds to the notebook

00:00:52,350 --> 00:00:57,370
experience the first is an interactive

00:00:55,120 --> 00:00:59,680
map that communicates with the notebooks

00:00:57,370 --> 00:01:02,230
Python execution environment

00:00:59,680 --> 00:01:04,720
and the second is an integrated tile

00:01:02,230 --> 00:01:07,030
server for rendering geospatial data

00:01:04,720 --> 00:01:10,450
onto the map and so the ultimate goal is

00:01:07,030 --> 00:01:13,300
to support interactive exploration and

00:01:10,450 --> 00:01:20,680
subsetting of geospatial data with a

00:01:13,300 --> 00:01:22,270
special focus on raster data so

00:01:20,680 --> 00:01:24,130
geospatial information Falls broadly

00:01:22,270 --> 00:01:26,830
into two different categories vector

00:01:24,130 --> 00:01:30,040
data and raster data vector data is made

00:01:26,830 --> 00:01:33,100
up of points lines polygons Multi

00:01:30,040 --> 00:01:36,610
polygons some examples of record vector

00:01:33,100 --> 00:01:39,040
data are like County boundaries or road

00:01:36,610 --> 00:01:40,119
networks building footprints anything

00:01:39,040 --> 00:01:42,369
that you can sort of describe with

00:01:40,119 --> 00:01:44,409
shapes the classic vector data format is

00:01:42,369 --> 00:01:46,540
the ESRI shape file but you may be more

00:01:44,409 --> 00:01:49,180
familiar with geo JSON which is more

00:01:46,540 --> 00:01:52,060
common in open-source communities so

00:01:49,180 --> 00:01:54,189
raster data on the other hand is a grid

00:01:52,060 --> 00:01:57,430
of data values over a particular

00:01:54,189 --> 00:01:58,840
geographic extent usually not always in

00:01:57,430 --> 00:02:01,720
our context it will always be over a

00:01:58,840 --> 00:02:03,759
geographic extent it's often easiest to

00:02:01,720 --> 00:02:06,220
think about the data as sort of a two

00:02:03,759 --> 00:02:08,080
dimensional array though this can sort

00:02:06,220 --> 00:02:10,209
of be misleading because the grid isn't

00:02:08,080 --> 00:02:12,150
always uniform and so certain cells the

00:02:10,209 --> 00:02:14,060
value for a particular cell isn't always

00:02:12,150 --> 00:02:15,410
covering the same extent

00:02:14,060 --> 00:02:17,660
and it's the value for every other cell

00:02:15,410 --> 00:02:19,250
and that can really bite you if you're

00:02:17,660 --> 00:02:22,700
doing certain kinds of analyses and

00:02:19,250 --> 00:02:24,410
don't take that into account so some

00:02:22,700 --> 00:02:26,959
examples of raster data are like digital

00:02:24,410 --> 00:02:29,750
elevation models satellite data so

00:02:26,959 --> 00:02:32,540
motifs or Landsat data which includes

00:02:29,750 --> 00:02:33,980
like RGB values so you get a nice pretty

00:02:32,540 --> 00:02:37,250
picture but also a bunch of other

00:02:33,980 --> 00:02:39,950
spectral values for information across a

00:02:37,250 --> 00:02:42,470
broad range of different categories as

00:02:39,950 --> 00:02:44,150
well as climate models and projections

00:02:42,470 --> 00:02:45,890
for climate models which is actually

00:02:44,150 --> 00:02:49,459
what sort of spawned a lot of the work

00:02:45,890 --> 00:02:52,220
that ended up creating Geo notebook so

00:02:49,459 --> 00:02:54,040
common formats are geo Tiff's geo Tiff's

00:02:52,220 --> 00:02:57,799
are really great for rendering stuff

00:02:54,040 --> 00:02:59,299
usually uncompressed there are a number

00:02:57,799 --> 00:03:00,019
of other kinds of data types though that

00:02:59,299 --> 00:03:02,989
do raster data

00:03:00,019 --> 00:03:05,380
many of them are hdf derivatives so like

00:03:02,989 --> 00:03:08,209
netcdf which is sort of a compressed

00:03:05,380 --> 00:03:10,670
multi-dimensional array that comes out

00:03:08,209 --> 00:03:12,709
of the HTF group and from my car and a

00:03:10,670 --> 00:03:14,780
bunch of other places so restaurant

00:03:12,709 --> 00:03:17,000
vector are both very different kinds of

00:03:14,780 --> 00:03:20,030
data but one attribute that they share

00:03:17,000 --> 00:03:21,769
is size especially at useful resolutions

00:03:20,030 --> 00:03:23,420
so it's quite easy to have a couple

00:03:21,769 --> 00:03:26,239
hundred Meg's worth of vector data or a

00:03:23,420 --> 00:03:27,650
couple hundred gigs worth of raster data

00:03:26,239 --> 00:03:29,239
when you're doing meaningful analysis

00:03:27,650 --> 00:03:31,069
and so well that's not really sort of

00:03:29,239 --> 00:03:34,130
outside the scope of processing on a

00:03:31,069 --> 00:03:35,720
laptop or a consumer desktop it will

00:03:34,130 --> 00:03:38,060
definitely crash your browser if you try

00:03:35,720 --> 00:03:39,410
and render all of it at the same time so

00:03:38,060 --> 00:03:41,049
if you want to visualize that data what

00:03:39,410 --> 00:03:44,060
you really need is some way to sort of

00:03:41,049 --> 00:03:46,130
systematically reduce the resolution of

00:03:44,060 --> 00:03:48,560
the data when you're looking at the

00:03:46,130 --> 00:03:50,630
whole data set and so that's sort of

00:03:48,560 --> 00:03:53,590
where a tile server comes in a tile

00:03:50,630 --> 00:03:58,069
server serves tiles out of a conceptual

00:03:53,590 --> 00:04:00,709
pyramid of a pyramid of tiles where the

00:03:58,069 --> 00:04:02,540
highest resolution tiles are down at the

00:04:00,709 --> 00:04:05,000
bottom and then you have increasingly

00:04:02,540 --> 00:04:06,470
coarser resolution tiles all the way up

00:04:05,000 --> 00:04:08,989
to the top and so while they represent

00:04:06,470 --> 00:04:10,549
the same geographic extent right the top

00:04:08,989 --> 00:04:12,290
tile up here represents the same

00:04:10,549 --> 00:04:14,450
geographic extent is all the tiles down

00:04:12,290 --> 00:04:18,079
here the top tile up here has a much

00:04:14,450 --> 00:04:20,510
coarser resolution and so you can you

00:04:18,079 --> 00:04:21,709
can you can see large trends in that

00:04:20,510 --> 00:04:24,110
data without having to necessarily

00:04:21,709 --> 00:04:27,040
render all of that data at the same time

00:04:24,110 --> 00:04:29,290
and crash your browser and so

00:04:27,040 --> 00:04:30,910
by zooming sort of up and down the

00:04:29,290 --> 00:04:33,520
pyramid your browser is only ever

00:04:30,910 --> 00:04:35,800
looking at a portion of the pyramid at

00:04:33,520 --> 00:04:38,080
any given time and so you never really

00:04:35,800 --> 00:04:39,910
need to keep a large amount of data in

00:04:38,080 --> 00:04:42,970
the browser when you're visualizing it

00:04:39,910 --> 00:04:45,490
so tile generation like this can be done

00:04:42,970 --> 00:04:48,100
as a pre-processing step or dynamically

00:04:45,490 --> 00:04:49,680
at the time of the tile request and

00:04:48,100 --> 00:04:51,730
there's a trade-off there between

00:04:49,680 --> 00:04:53,230
storage so if you do pre-processing

00:04:51,730 --> 00:04:55,360
you're probably gonna double your data

00:04:53,230 --> 00:04:57,820
size on demand tile generation on the

00:04:55,360 --> 00:04:59,440
other hand will affect response latency

00:04:57,820 --> 00:05:01,240
and so you can use caching mechanisms to

00:04:59,440 --> 00:05:04,050
kind of tune where you want to live on

00:05:01,240 --> 00:05:07,900
that storage to response latency

00:05:04,050 --> 00:05:09,190
spectrum so the tile server just

00:05:07,900 --> 00:05:11,290
provides tiles at well-defined end

00:05:09,190 --> 00:05:13,270
points usually with X y and

00:05:11,290 --> 00:05:14,560
z-coordinates inside of the pyramid and

00:05:13,270 --> 00:05:16,330
so there's like an API endpoint where

00:05:14,560 --> 00:05:18,700
you can say give me the tile at X Y Z

00:05:16,330 --> 00:05:22,330
and it'll return a tile for a particular

00:05:18,700 --> 00:05:24,550
type of data so to get that interactive

00:05:22,330 --> 00:05:26,470
map experience though that everyone

00:05:24,550 --> 00:05:29,170
knows and loves from their GPS is or

00:05:26,470 --> 00:05:30,820
from uber or for whatever you need to

00:05:29,170 --> 00:05:33,670
have a JavaScript library that actually

00:05:30,820 --> 00:05:35,860
provides pan and zoom capabilities which

00:05:33,670 --> 00:05:38,370
essentially requests and renders those

00:05:35,860 --> 00:05:41,290
tiles at the appropriate resolution

00:05:38,370 --> 00:05:43,690
within the viewport of that particular

00:05:41,290 --> 00:05:46,090
map and so these are the two features

00:05:43,690 --> 00:05:48,130
that geo notebook tries to provide for

00:05:46,090 --> 00:05:50,860
the notebook computing environment one

00:05:48,130 --> 00:05:53,020
is a tile server for serving these tiles

00:05:50,860 --> 00:05:56,050
including dynamically generated tiles

00:05:53,020 --> 00:05:58,720
and the other is an interactive map for

00:05:56,050 --> 00:06:00,180
viewing those tiles and so with that I

00:05:58,720 --> 00:06:07,230
will go straight to a demonstration

00:06:00,180 --> 00:06:07,230
hopefully see if I can pull this

00:06:13,940 --> 00:06:18,890
so probably the first thing that you

00:06:15,980 --> 00:06:21,560
will notice is that there is a rather

00:06:18,890 --> 00:06:24,470
large interactive map on the right-hand

00:06:21,560 --> 00:06:26,480
side of the notebook you have all of the

00:06:24,470 --> 00:06:28,310
traditional cells marked down all the

00:06:26,480 --> 00:06:29,600
kind of standard functionality that you

00:06:28,310 --> 00:06:32,780
expect from the notebook here on the

00:06:29,600 --> 00:06:36,230
left-hand side and we can resize this as

00:06:32,780 --> 00:06:38,210
needed and so one of the things that you

00:06:36,230 --> 00:06:40,550
may not notice right away is that we're

00:06:38,210 --> 00:06:42,200
actually using a custom kernel here so

00:06:40,550 --> 00:06:44,330
this is a geo notebook kernel which is

00:06:42,200 --> 00:06:46,340
actually just a simple derivative of the

00:06:44,330 --> 00:06:49,910
Python kernel in this case Python 2 that

00:06:46,340 --> 00:06:51,710
you could also use Python 3 and what we

00:06:49,910 --> 00:06:54,410
do with that kernel is we actually

00:06:51,710 --> 00:06:56,630
inject a custom variable into the

00:06:54,410 --> 00:06:58,490
namespace so when the kernel starts up

00:06:56,630 --> 00:07:00,860
we get this M object even though we

00:06:58,490 --> 00:07:02,990
haven't actually imported anything and

00:07:00,860 --> 00:07:06,470
that M object matters because we have an

00:07:02,990 --> 00:07:08,870
API set on it that actually communicates

00:07:06,470 --> 00:07:11,420
from the Python execution environment

00:07:08,870 --> 00:07:14,870
down to the map and so when I execute

00:07:11,420 --> 00:07:20,150
this function you should see that the

00:07:14,870 --> 00:07:21,730
map actually changes location yeah there

00:07:20,150 --> 00:07:26,120
we go

00:07:21,730 --> 00:07:28,280
so just to just to be clear here I think

00:07:26,120 --> 00:07:30,890
it's important to sort of understand the

00:07:28,280 --> 00:07:32,660
bones here when we call m dot set Center

00:07:30,890 --> 00:07:34,790
in that cell what we're doing is we're

00:07:32,660 --> 00:07:39,020
actually taking a string with M period

00:07:34,790 --> 00:07:40,250
SC t underscore that represents Python

00:07:39,020 --> 00:07:42,260
code and we're actually sending it

00:07:40,250 --> 00:07:44,600
across the tornado web server to the

00:07:42,260 --> 00:07:47,180
kernel so this is across a WebSocket and

00:07:44,600 --> 00:07:49,669
0 mq connection that string is being

00:07:47,180 --> 00:07:51,830
evaluated as Python in that kernel and

00:07:49,669 --> 00:07:54,110
what that Python does is it actually

00:07:51,830 --> 00:07:57,740
sends a message back to the interactive

00:07:54,110 --> 00:07:59,540
map over this comm channel and then that

00:07:57,740 --> 00:08:02,720
inner that message in the interactive

00:07:59,540 --> 00:08:04,070
map is interpreted so it's a remote

00:08:02,720 --> 00:08:05,660
procedure call message so it calls a

00:08:04,070 --> 00:08:10,460
procedure inside that map and it

00:08:05,660 --> 00:08:12,650
actually changes the state of the map so

00:08:10,460 --> 00:08:15,320
that's great for sending things from the

00:08:12,650 --> 00:08:16,910
kernel down to the map and I'm skipping

00:08:15,320 --> 00:08:18,650
ahead one of the things that is cool

00:08:16,910 --> 00:08:20,150
about this is that because it's just a

00:08:18,650 --> 00:08:22,430
function you can use it with the

00:08:20,150 --> 00:08:23,600
traditional widget infrastructure and so

00:08:22,430 --> 00:08:25,350
while this may not be a particularly

00:08:23,600 --> 00:08:26,970
compelling widget

00:08:25,350 --> 00:08:29,250
it sort of demonstrates the ability to

00:08:26,970 --> 00:08:32,910
use widgets in order to affect Mapp

00:08:29,250 --> 00:08:34,289
State on the front end so that sort of

00:08:32,910 --> 00:08:37,560
demonstrates some of the things that we

00:08:34,289 --> 00:08:39,450
can do when we go kernel to map but we

00:08:37,560 --> 00:08:41,400
can also go map to kernel so we've added

00:08:39,450 --> 00:08:44,970
a couple of buttons up here that allow

00:08:41,400 --> 00:08:47,040
you to do things like create polygons so

00:08:44,970 --> 00:08:49,980
we've been calling these annotations so

00:08:47,040 --> 00:08:52,950
you can drop points and rectangles and

00:08:49,980 --> 00:08:56,460
those annotations become available back

00:08:52,950 --> 00:08:59,370
inside of the kernel environment and so

00:08:56,460 --> 00:09:00,870
you can see here that this object that

00:08:59,370 --> 00:09:02,520
we've drawn in the map is now available

00:09:00,870 --> 00:09:04,800
back inside of the execution environment

00:09:02,520 --> 00:09:07,980
and this is just a shapely object and so

00:09:04,800 --> 00:09:09,390
that shapely object has a bunch of API

00:09:07,980 --> 00:09:12,120
associated with it so you can actually

00:09:09,390 --> 00:09:15,060
look at what the vertexes are you can

00:09:12,120 --> 00:09:17,610
calculate the center of mass on that and

00:09:15,060 --> 00:09:21,230
even do some projection magic to

00:09:17,610 --> 00:09:23,340
determine what the total amount of

00:09:21,230 --> 00:09:26,940
square meters is for that particular

00:09:23,340 --> 00:09:28,740
polygon so that's sort of demonstrating

00:09:26,940 --> 00:09:32,250
kernel to map and map the kernel

00:09:28,740 --> 00:09:34,640
communication what what we really want

00:09:32,250 --> 00:09:37,200
to do though is we want to be able to

00:09:34,640 --> 00:09:38,370
was sort of a special class of signals

00:09:37,200 --> 00:09:40,110
that we want to be able to send from the

00:09:38,370 --> 00:09:43,050
kernel to the map and that class of

00:09:40,110 --> 00:09:45,210
signals is a signal that says to the map

00:09:43,050 --> 00:09:47,220
hey I want you to start requesting tiles

00:09:45,210 --> 00:09:49,830
and start rendering those tiles on the

00:09:47,220 --> 00:09:51,090
map and so to demonstrate that I'm just

00:09:49,830 --> 00:09:53,880
going to run a couple of cells here

00:09:51,090 --> 00:09:56,580
quickly that are just setting up some

00:09:53,880 --> 00:09:58,890
data a little legend and we can do that

00:09:56,580 --> 00:10:01,830
by using this MDOT add layer function

00:09:58,890 --> 00:10:04,110
and when I call em dot add layer what

00:10:01,830 --> 00:10:07,470
I've done is I've actually added the

00:10:04,110 --> 00:10:09,810
National Land cover dataset to this map

00:10:07,470 --> 00:10:12,870
as a layer so the National Land cover

00:10:09,810 --> 00:10:16,560
dataset is a 30 meter resolution data

00:10:12,870 --> 00:10:18,450
set and so we can zoom way in let's find

00:10:16,560 --> 00:10:20,070
somewhere interesting to look at so we

00:10:18,450 --> 00:10:22,110
can zoom way in actually all the way

00:10:20,070 --> 00:10:25,050
down to the pixel level each one of

00:10:22,110 --> 00:10:27,840
these pixels represents a 30 meter by 30

00:10:25,050 --> 00:10:29,520
meter square that's been classified by

00:10:27,840 --> 00:10:32,520
using some machine learning algorithm

00:10:29,520 --> 00:10:33,930
that I'm not familiar with and so again

00:10:32,520 --> 00:10:35,730
what we've done what we've done here is

00:10:33,930 --> 00:10:37,180
the geo Notebook kernel has actually

00:10:35,730 --> 00:10:39,010
sent a signal down to the interact

00:10:37,180 --> 00:10:42,460
map and the interactive map has started

00:10:39,010 --> 00:10:44,620
requesting tiles from the tile server so

00:10:42,460 --> 00:10:47,530
the National Land cover dataset is not a

00:10:44,620 --> 00:10:49,840
tribulus size data set you can see here

00:10:47,530 --> 00:10:52,840
that we've got the actual legend here so

00:10:49,840 --> 00:10:54,880
blues tend to be water and snow and

00:10:52,840 --> 00:10:58,560
Red's tend to be developed greens or

00:10:54,880 --> 00:11:00,910
forests and then browns and yellows our

00:10:58,560 --> 00:11:04,000
pasture and cultivated areas within the

00:11:00,910 --> 00:11:06,130
United States so as I was saying this is

00:11:04,000 --> 00:11:09,730
not a trivially sized dataset we've

00:11:06,130 --> 00:11:12,070
actually got this total on disk is a 25

00:11:09,730 --> 00:11:14,380
gigabyte file that we're reading out of

00:11:12,070 --> 00:11:17,020
and this actually includes pre-generated

00:11:14,380 --> 00:11:19,330
tiles just because it makes the

00:11:17,020 --> 00:11:21,070
performance a little bit better but we

00:11:19,330 --> 00:11:25,630
can also do dynamic rendering of those

00:11:21,070 --> 00:11:26,890
tiles at request time and so just a

00:11:25,630 --> 00:11:29,260
little bit more in terms of

00:11:26,890 --> 00:11:32,380
demonstration we can look at this shape

00:11:29,260 --> 00:11:37,090
file here and we can pull a shapefile of

00:11:32,380 --> 00:11:39,430
New York City neighborhoods and we can

00:11:37,090 --> 00:11:41,320
actually subset data out we can actually

00:11:39,430 --> 00:11:44,650
use that polygon information to subset

00:11:41,320 --> 00:11:47,800
data out of the underlying data set and

00:11:44,650 --> 00:11:51,010
so again we have that polygon here this

00:11:47,800 --> 00:11:53,320
is Midtown Midtown south where we're

00:11:51,010 --> 00:11:55,960
actually all currently located this guy

00:11:53,320 --> 00:11:59,260
right here and we can actually pull that

00:11:55,960 --> 00:12:01,660
data as a numpy master array by using

00:11:59,260 --> 00:12:04,780
that polygon information with a little

00:12:01,660 --> 00:12:05,920
API sugar here and so what you're

00:12:04,780 --> 00:12:07,240
actually seeing here is a mass array

00:12:05,920 --> 00:12:08,710
because it's actually a two-dimensional

00:12:07,240 --> 00:12:10,900
array that's the bounding box of this

00:12:08,710 --> 00:12:12,580
particular polygon and then you're just

00:12:10,900 --> 00:12:16,150
missing data from areas where the

00:12:12,580 --> 00:12:17,560
polygon doesn't actually cover and so we

00:12:16,150 --> 00:12:19,390
can take that data though and do

00:12:17,560 --> 00:12:21,580
something simple like look at what the

00:12:19,390 --> 00:12:24,840
counts are so here in midtown Manhattan

00:12:21,580 --> 00:12:27,820
you've got a rather high amount of

00:12:24,840 --> 00:12:29,410
developed high intensity land cover and

00:12:27,820 --> 00:12:32,110
then actually all of your land cover is

00:12:29,410 --> 00:12:33,910
some form of developed land cover

00:12:32,110 --> 00:12:36,070
whether it's high medium low or open

00:12:33,910 --> 00:12:38,860
space I don't know if you've walked

00:12:36,070 --> 00:12:42,970
around outside at all no forests in

00:12:38,860 --> 00:12:44,200
in midtown Manhattan so you might think

00:12:42,970 --> 00:12:48,459
that midtown Manhattan actually has a

00:12:44,200 --> 00:12:49,990
pretty high intensity development but we

00:12:48,459 --> 00:12:51,730
can also group by all of these different

00:12:49,990 --> 00:12:53,800
we can sort of subset by each one of

00:12:51,730 --> 00:12:55,120
these neighborhoods group by each one of

00:12:53,800 --> 00:12:57,209
them and actually look at the proportion

00:12:55,120 --> 00:12:58,930
of high intensity development to all

00:12:57,209 --> 00:13:00,370
development in that particular

00:12:58,930 --> 00:13:03,430
neighborhood and so actually Soho

00:13:00,370 --> 00:13:04,930
Tribeca is the highest midtown Manhattan

00:13:03,430 --> 00:13:08,380
actually doesn't comes in somewhere

00:13:04,930 --> 00:13:09,820
right in the middle here so let me keep

00:13:08,380 --> 00:13:11,380
going down I want to display I want to

00:13:09,820 --> 00:13:13,300
do one more demo that sort of speaks to

00:13:11,380 --> 00:13:15,250
sort of the moat some of the motivation

00:13:13,300 --> 00:13:18,339
behind why we've actually created this

00:13:15,250 --> 00:13:19,720
extension to begin with and so I'm just

00:13:18,339 --> 00:13:22,740
going to render a little bit of

00:13:19,720 --> 00:13:26,529
web-enabled Landsat data onto the map

00:13:22,740 --> 00:13:29,350
and that web-enabled Landsat data so

00:13:26,529 --> 00:13:32,110
this actually represents NDVI which is a

00:13:29,350 --> 00:13:34,779
measure of vegetation index so it's how

00:13:32,110 --> 00:13:36,670
green a particular area is I've rendered

00:13:34,779 --> 00:13:41,230
it with the most beautiful of color maps

00:13:36,670 --> 00:13:42,730
the jet color map from matplotlib but if

00:13:41,230 --> 00:13:44,440
you found the jet color map to be a

00:13:42,730 --> 00:13:45,550
little bit too aggressive then you can

00:13:44,440 --> 00:13:48,850
actually restyle it with other

00:13:45,550 --> 00:13:50,560
matplotlib color maps even custom color

00:13:48,850 --> 00:13:52,120
maps that may actually represent what

00:13:50,560 --> 00:13:54,130
your data is supposed to be and so this

00:13:52,120 --> 00:13:55,660
is an area appearing like Glacier

00:13:54,130 --> 00:13:57,940
Mountain National Park you can actually

00:13:55,660 --> 00:14:00,160
see where the ice is where the barren

00:13:57,940 --> 00:14:01,510
Rock is and where the forest starts so

00:14:00,160 --> 00:14:04,089
this is not land cover data this is

00:14:01,510 --> 00:14:08,050
actually individual pixels representing

00:14:04,089 --> 00:14:09,160
NDVI for a particular area and so you

00:14:08,050 --> 00:14:10,420
know one of the questions that you might

00:14:09,160 --> 00:14:16,329
ask is like what can we do with this

00:14:10,420 --> 00:14:18,339
data and so we can actually select rent

00:14:16,329 --> 00:14:23,470
arbitrarily select regions of this data

00:14:18,339 --> 00:14:24,699
and then we can subset that data sort of

00:14:23,470 --> 00:14:27,970
as we've already demonstrated we get

00:14:24,699 --> 00:14:29,829
back this master Ray and we can even

00:14:27,970 --> 00:14:31,600
just do like a sanity check to make sure

00:14:29,829 --> 00:14:32,920
that in fact that is the right data so

00:14:31,600 --> 00:14:34,300
you can see here that projections are a

00:14:32,920 --> 00:14:36,100
little bit different this is just in raw

00:14:34,300 --> 00:14:37,329
latitude and longitude this is web

00:14:36,100 --> 00:14:39,010
Mercator and so they're a little bit

00:14:37,329 --> 00:14:41,529
different but the data is actually the

00:14:39,010 --> 00:14:44,769
same data underneath so I am NOT a

00:14:41,529 --> 00:14:46,660
computer vision person but I can copy

00:14:44,769 --> 00:14:50,170
code shamelessly off of the site get

00:14:46,660 --> 00:14:51,339
image website and so I'm not going to

00:14:50,170 --> 00:14:52,100
explain any of this code here but

00:14:51,339 --> 00:14:53,779
essentially if you

00:14:52,100 --> 00:14:56,120
interested there's some great tutorials

00:14:53,779 --> 00:14:56,870
on how to do segmentation analysis using

00:14:56,120 --> 00:14:58,190
site kidding

00:14:56,870 --> 00:14:59,630
and so what I've done is I've just

00:14:58,190 --> 00:15:01,910
created a function here called print

00:14:59,630 --> 00:15:05,449
print segments and what that does is it

00:15:01,910 --> 00:15:09,019
allows me to actually use that data to

00:15:05,449 --> 00:15:11,060
identify the particular segments the

00:15:09,019 --> 00:15:12,920
particular fields in this area that I've

00:15:11,060 --> 00:15:14,509
selected and the reason why that's

00:15:12,920 --> 00:15:16,990
important so I mean you could do that

00:15:14,509 --> 00:15:19,190
anyways with whatever data that you want

00:15:16,990 --> 00:15:20,329
what's nice about this is that you can

00:15:19,190 --> 00:15:22,509
then go ahead and select a different

00:15:20,329 --> 00:15:25,579
region call that function on that region

00:15:22,509 --> 00:15:26,779
and then you get another example and so

00:15:25,579 --> 00:15:28,550
you can see actually in this example

00:15:26,779 --> 00:15:30,199
that the segmentation analysis is sort

00:15:28,550 --> 00:15:31,550
of failed it's found a polygon that

00:15:30,199 --> 00:15:34,220
actually doesn't belong it should be a

00:15:31,550 --> 00:15:36,560
hole not a new polygon and so the

00:15:34,220 --> 00:15:39,649
ability to sort of treat your function

00:15:36,560 --> 00:15:42,889
as a particular way of moving from data

00:15:39,649 --> 00:15:44,300
to some piece of information and then to

00:15:42,889 --> 00:15:45,709
test that function out on a number of

00:15:44,300 --> 00:15:47,720
different pieces of data sort of

00:15:45,709 --> 00:15:49,579
interactively was sort of the goal here

00:15:47,720 --> 00:15:51,829
because ultimately what you want to do

00:15:49,579 --> 00:15:53,899
is be able to refine this print segments

00:15:51,829 --> 00:15:55,940
or whatever function you're developing

00:15:53,899 --> 00:15:58,759
into something that can then be batched

00:15:55,940 --> 00:16:00,649
out across large-scale data systems or

00:15:58,759 --> 00:16:01,970
if you've got a large-scale data system

00:16:00,649 --> 00:16:05,600
that sort of already integrated into

00:16:01,970 --> 00:16:10,100
your notebook it allows you to to use

00:16:05,600 --> 00:16:15,910
that instead so that is the end of that

00:16:10,100 --> 00:16:15,910
let me see if I can pull this out here

00:16:18,720 --> 00:16:22,790
through the look

00:16:33,420 --> 00:16:37,860
sorry about this so that's the

00:16:35,730 --> 00:16:39,870
demonstration so I just wanna talk a

00:16:37,860 --> 00:16:42,960
little bit about some of the technical

00:16:39,870 --> 00:16:45,630
objectives of Geo notebook the first

00:16:42,960 --> 00:16:48,030
really critical component for us is to

00:16:45,630 --> 00:16:49,740
not enforce any assumptions about the

00:16:48,030 --> 00:16:52,350
relationship between data access and

00:16:49,740 --> 00:16:53,940
data visualization so in this case data

00:16:52,350 --> 00:16:55,890
access is you know how do we bring data

00:16:53,940 --> 00:16:59,100
into the notebook into those cells to

00:16:55,890 --> 00:17:00,300
actually work with that data and data

00:16:59,100 --> 00:17:02,520
visualization is you know how do you

00:17:00,300 --> 00:17:04,530
actually style data and render it to the

00:17:02,520 --> 00:17:06,740
map with tiles and one of the advantages

00:17:04,530 --> 00:17:09,120
here is that by separating those two

00:17:06,740 --> 00:17:10,920
really strongly we ensure that data

00:17:09,120 --> 00:17:12,450
access is always at native resolution

00:17:10,920 --> 00:17:13,650
which is a really critical component for

00:17:12,450 --> 00:17:16,290
people who are working in the geospatial

00:17:13,650 --> 00:17:20,100
context they don't want their if they

00:17:16,290 --> 00:17:21,600
select a region and and they want to do

00:17:20,100 --> 00:17:23,220
run an analysis on that region

00:17:21,600 --> 00:17:26,040
they don't want that analysis to be run

00:17:23,220 --> 00:17:28,710
on down sample data they want to see it

00:17:26,040 --> 00:17:31,290
run on the native resolution of that

00:17:28,710 --> 00:17:32,700
data one of the other things that we're

00:17:31,290 --> 00:17:34,530
trying to do is provide sensible

00:17:32,700 --> 00:17:37,250
defaults we're trying to target sort of

00:17:34,530 --> 00:17:39,930
the traditional Jupiter user which I'm

00:17:37,250 --> 00:17:41,010
arbitrarily to finding as you know

00:17:39,930 --> 00:17:44,490
somebody who's working with small to

00:17:41,010 --> 00:17:46,170
medium data on a laptop or on a server

00:17:44,490 --> 00:17:48,330
that's running Jupiter hub but doesn't

00:17:46,170 --> 00:17:51,660
necessarily have the sort of moxie to

00:17:48,330 --> 00:17:54,810
get a full AWS cluster running behind

00:17:51,660 --> 00:17:56,460
them with that said we don't want to

00:17:54,810 --> 00:17:58,320
limit ourselves and so we want to

00:17:56,460 --> 00:18:00,600
support adding new methods for data

00:17:58,320 --> 00:18:02,490
access and data visualization and to do

00:18:00,600 --> 00:18:05,340
that we've actually started using Python

00:18:02,490 --> 00:18:07,170
entry points which are one of the most

00:18:05,340 --> 00:18:09,000
widely underappreciated features of

00:18:07,170 --> 00:18:11,370
Python and have set up tools in my

00:18:09,000 --> 00:18:15,150
opinion and so what this basically

00:18:11,370 --> 00:18:17,010
allows us to do is to have third-party

00:18:15,150 --> 00:18:19,230
developers create external packages

00:18:17,010 --> 00:18:21,360
which when installed allowed geo

00:18:19,230 --> 00:18:23,760
notebook to discover from those

00:18:21,360 --> 00:18:25,980
third-party packages automatically what

00:18:23,760 --> 00:18:27,360
visualization and data access methods

00:18:25,980 --> 00:18:29,910
are available and we actually had a

00:18:27,360 --> 00:18:32,150
really great success story here a couple

00:18:29,910 --> 00:18:34,400
of weeks ago a couple of months ago a

00:18:32,150 --> 00:18:37,230
open source company called azavea

00:18:34,400 --> 00:18:39,180
actually contacted us to do a quick

00:18:37,230 --> 00:18:41,850
collaboration for foss4g which was in

00:18:39,180 --> 00:18:43,420
Boston last last week and they actually

00:18:41,850 --> 00:18:46,630
run a

00:18:43,420 --> 00:18:49,000
spark based raster processing and tiling

00:18:46,630 --> 00:18:50,170
engine called geo trellis and with a

00:18:49,000 --> 00:18:51,460
little bit of work they were able to put

00:18:50,170 --> 00:18:54,010
together some stuff that they then ran a

00:18:51,460 --> 00:18:56,350
demonstration workshop on using the Geo

00:18:54,010 --> 00:18:58,630
notebook and they essentially allowed

00:18:56,350 --> 00:19:00,550
that data access and data visualization

00:18:58,630 --> 00:19:03,310
to be done with a 10 or 12 node cluster

00:19:00,550 --> 00:19:05,320
out on AWS and so same experience but

00:19:03,310 --> 00:19:10,510
much larger data volumes that you could

00:19:05,320 --> 00:19:12,070
both visualize and process and so you

00:19:10,510 --> 00:19:13,060
know if you our goal here sort of you

00:19:12,070 --> 00:19:16,090
know the takeaways and you know if you

00:19:13,060 --> 00:19:18,790
have a bunch of raster data and we're a

00:19:16,090 --> 00:19:20,020
bunch of vector data and you want to you

00:19:18,790 --> 00:19:22,210
have your own custom tile server a

00:19:20,020 --> 00:19:23,470
processing engine you know we want to be

00:19:22,210 --> 00:19:25,900
able to make it easy for you to bring

00:19:23,470 --> 00:19:27,880
that engine into the notebook so that

00:19:25,900 --> 00:19:33,520
your users can start playing around with

00:19:27,880 --> 00:19:35,350
it so with that said the sort of default

00:19:33,520 --> 00:19:36,760
technical stack that we use for

00:19:35,350 --> 00:19:37,900
visualization is a little complicated

00:19:36,760 --> 00:19:41,380
and I wanted to just get into it a

00:19:37,900 --> 00:19:43,570
little bit you know we use G doll which

00:19:41,380 --> 00:19:46,330
is or good ol depending on your

00:19:43,570 --> 00:19:48,970
preference which is a C++ library for

00:19:46,330 --> 00:19:51,700
i/o we also do a fair amount of custom

00:19:48,970 --> 00:19:53,650
VRT generation on the back end which

00:19:51,700 --> 00:19:55,390
handles certain warping operations and

00:19:53,650 --> 00:19:57,070
provides styling hints to math Nick if

00:19:55,390 --> 00:19:59,230
you don't know what that means then good

00:19:57,070 --> 00:20:02,710
for you if you do know what that means

00:19:59,230 --> 00:20:04,930
that I'm sorry but one of the things

00:20:02,710 --> 00:20:06,550
that this one of the things that's nice

00:20:04,930 --> 00:20:08,290
about that is that you know we can

00:20:06,550 --> 00:20:11,260
essentially render anything that G doll

00:20:08,290 --> 00:20:14,650
can read which is a pretty wide array of

00:20:11,260 --> 00:20:16,480
geospatial data formats so we use math

00:20:14,650 --> 00:20:18,280
Nick which is another C++ library for

00:20:16,480 --> 00:20:20,500
styling data and for also doing

00:20:18,280 --> 00:20:24,550
orchestration of down sampling so

00:20:20,500 --> 00:20:27,040
getting that rendering lower resolution

00:20:24,550 --> 00:20:29,530
data we use key tile which is a fork of

00:20:27,040 --> 00:20:31,420
tile stash for actually serving tiles we

00:20:29,530 --> 00:20:34,270
wrap that up inside of jupiter's route

00:20:31,420 --> 00:20:37,060
handlers obviously he was trooping her

00:20:34,270 --> 00:20:38,560
notebook and to make the whole thing

00:20:37,060 --> 00:20:41,290
come together this includes a

00:20:38,560 --> 00:20:44,020
server-side plugin a client-side plugin

00:20:41,290 --> 00:20:45,610
custom Python derived kernel as well as

00:20:44,020 --> 00:20:46,990
this Jupiter comm channel for

00:20:45,610 --> 00:20:50,380
interaction between the kernel and the

00:20:46,990 --> 00:20:52,120
map using custom JSON RPC messages and

00:20:50,380 --> 00:20:53,620
then finally for the actual JavaScript

00:20:52,120 --> 00:20:57,350
library that we use for map rendering we

00:20:53,620 --> 00:20:58,700
use goj s or alternatively open layers

00:20:57,350 --> 00:21:00,440
for interactive presentation of the map

00:20:58,700 --> 00:21:03,049
we tried to actually abstract away from

00:21:00,440 --> 00:21:04,580
the map idea a little bit we have some

00:21:03,049 --> 00:21:05,929
people who are interested other people

00:21:04,580 --> 00:21:08,750
at kitware who are interested in looking

00:21:05,929 --> 00:21:11,179
at histopathology for this kind of thing

00:21:08,750 --> 00:21:13,070
and so they have large blood slides

00:21:11,179 --> 00:21:14,990
slides of blood that they want to be

00:21:13,070 --> 00:21:18,080
able to zoom in and out of and perform

00:21:14,990 --> 00:21:19,460
these kinds of analyses on so

00:21:18,080 --> 00:21:22,940
graphically this is sort of what that

00:21:19,460 --> 00:21:28,820
looks like I'm just gonna grab my

00:21:22,940 --> 00:21:31,130
pointer here so this line here sort of

00:21:28,820 --> 00:21:32,780
divides the client and server you know

00:21:31,130 --> 00:21:34,700
everything on this side down here is

00:21:32,780 --> 00:21:38,980
client and server that's unfortunate

00:21:34,700 --> 00:21:42,740
that it does that so that you can't see

00:21:38,980 --> 00:21:44,390
so you know the notebook cells here the

00:21:42,740 --> 00:21:46,610
tornado and the juniper kernel that's

00:21:44,390 --> 00:21:50,870
sort of the traditional execution path

00:21:46,610 --> 00:21:54,679
for for the notebook we add an

00:21:50,870 --> 00:21:55,970
interactive map obviously and then on

00:21:54,679 --> 00:21:58,940
the right here you can also see that

00:21:55,970 --> 00:22:01,039
server extension that implements the

00:21:58,940 --> 00:22:03,169
actual tile server so when you add a

00:22:01,039 --> 00:22:06,470
layer to the map the kernel does two

00:22:03,169 --> 00:22:08,539
things first the kernel posts metadata

00:22:06,470 --> 00:22:10,429
to the server extension which just sort

00:22:08,539 --> 00:22:12,200
of gives it an opportunity to set up

00:22:10,429 --> 00:22:15,500
anything that it needs to initialize

00:22:12,200 --> 00:22:18,620
that server extension before request

00:22:15,500 --> 00:22:19,940
start coming in to render tiles assuming

00:22:18,620 --> 00:22:22,100
that that's successful then in the

00:22:19,940 --> 00:22:24,590
second stage the notebook sends a

00:22:22,100 --> 00:22:26,900
message through the comm channel to the

00:22:24,590 --> 00:22:28,429
to the interactive map which begins

00:22:26,900 --> 00:22:31,309
requesting tiles from that server

00:22:28,429 --> 00:22:32,419
extension and then on the flip side you

00:22:31,309 --> 00:22:35,419
know when we actually place an

00:22:32,419 --> 00:22:39,260
annotation either programmatically or or

00:22:35,419 --> 00:22:41,120
through the interface that information

00:22:39,260 --> 00:22:43,549
is being sent via remote procedure calls

00:22:41,120 --> 00:22:46,250
up to the kernel where it's used to

00:22:43,549 --> 00:22:52,309
actually pull windows out of the data

00:22:46,250 --> 00:22:55,429
and subset of soju notebook is by no

00:22:52,309 --> 00:22:56,510
means a complete piece of software there

00:22:55,429 --> 00:22:58,580
are some important limitations that

00:22:56,510 --> 00:23:01,789
currently exist so first we have a

00:22:58,580 --> 00:23:03,289
pretty complex deployment you know that

00:23:01,789 --> 00:23:05,450
leverages some pretty new features in G

00:23:03,289 --> 00:23:07,549
Dahl and map NIC and so system package

00:23:05,450 --> 00:23:08,540
is probably going to be out of date for

00:23:07,549 --> 00:23:09,250
a little while you won't be able to

00:23:08,540 --> 00:23:12,130
apt-get and

00:23:09,250 --> 00:23:13,540
ethnic and get into enough version to

00:23:12,130 --> 00:23:15,610
sort of mitigate this issue we have a

00:23:13,540 --> 00:23:17,350
docker image available and if you're

00:23:15,610 --> 00:23:19,660
comfortable with docker I recommend you

00:23:17,350 --> 00:23:22,030
use that if you're not comfortable with

00:23:19,660 --> 00:23:24,370
docker then you probably need to start

00:23:22,030 --> 00:23:26,470
getting more comfortable with GCC

00:23:24,370 --> 00:23:28,990
because you'll have to compile a bunch

00:23:26,470 --> 00:23:30,730
of stuff to make it work currently don't

00:23:28,990 --> 00:23:33,220
have a very good solution for rerender

00:23:30,730 --> 00:23:35,380
in memory transformations of data which

00:23:33,220 --> 00:23:36,490
sounds a little bit complicated but it's

00:23:35,380 --> 00:23:37,810
actually probably the first thing that

00:23:36,490 --> 00:23:40,240
you're going to want to do once you

00:23:37,810 --> 00:23:41,710
actually subset that data so if you've

00:23:40,240 --> 00:23:44,650
subsetted data and brought it into the

00:23:41,710 --> 00:23:45,910
kernel then then you're going to do some

00:23:44,650 --> 00:23:47,560
transformation on that data and you'd

00:23:45,910 --> 00:23:49,000
probably like to be able to rerender

00:23:47,560 --> 00:23:50,410
restyle and re-render that

00:23:49,000 --> 00:23:51,940
transformation back out to the map

00:23:50,410 --> 00:23:53,590
unfortunately the only way to do that

00:23:51,940 --> 00:23:55,510
right now is to actually save that out

00:23:53,590 --> 00:23:57,940
to file and that has a lot to do with

00:23:55,510 --> 00:24:00,940
the fact that the data is in the geo

00:23:57,940 --> 00:24:03,100
notebook kernel and the processes that

00:24:00,940 --> 00:24:04,780
are actually doing the rendering are in

00:24:03,100 --> 00:24:08,350
the server extension and there isn't a

00:24:04,780 --> 00:24:10,870
good sort of way of doing shared memory

00:24:08,350 --> 00:24:12,190
between those processes and so

00:24:10,870 --> 00:24:14,410
communicating back and forth between

00:24:12,190 --> 00:24:16,920
them is also going to be problematic I'm

00:24:14,410 --> 00:24:19,810
getting a little ahead of myself there

00:24:16,920 --> 00:24:21,550
finally there's some of the interactive

00:24:19,810 --> 00:24:24,760
elements of geo notebook especially

00:24:21,550 --> 00:24:25,870
annotations and viewports break some of

00:24:24,760 --> 00:24:28,270
the implicit promises about

00:24:25,870 --> 00:24:30,220
reproducibility of a particular notebook

00:24:28,270 --> 00:24:32,830
so if you let somebody just select an

00:24:30,220 --> 00:24:34,030
arbitrary region of raster data set then

00:24:32,830 --> 00:24:35,830
you can't really guarantee that running

00:24:34,030 --> 00:24:38,950
the notebook from top to bottom it's

00:24:35,830 --> 00:24:40,840
going to produce the same results plus

00:24:38,950 --> 00:24:42,490
an integrated tile server you know means

00:24:40,840 --> 00:24:44,260
that if you have a notebook server

00:24:42,490 --> 00:24:46,540
running to render tiles from that data

00:24:44,260 --> 00:24:49,090
set a static version of the notebook

00:24:46,540 --> 00:24:50,440
won't include the map which is why as a

00:24:49,090 --> 00:24:52,030
stopgap we've included sort of a

00:24:50,440 --> 00:24:53,890
screenshot functionality which I

00:24:52,030 --> 00:24:55,090
literally put a note in there that said

00:24:53,890 --> 00:24:56,710
don't forget to show the screenshot

00:24:55,090 --> 00:24:58,570
functionality and then I forgot to show

00:24:56,710 --> 00:25:01,840
it so I apologize I'm going to go back

00:24:58,570 --> 00:25:03,250
maybe once we've got questions so we've

00:25:01,840 --> 00:25:05,050
been talking about some ways to sort of

00:25:03,250 --> 00:25:08,470
mitigate some of these reproducibility

00:25:05,050 --> 00:25:10,060
issues but the problem isn't probably

00:25:08,470 --> 00:25:12,310
going to be something that we can solve

00:25:10,060 --> 00:25:13,420
from a purely technical perspective and

00:25:12,310 --> 00:25:16,210
actually I think it's an interesting

00:25:13,420 --> 00:25:17,440
open problem you know a lot of the stuff

00:25:16,210 --> 00:25:19,360
that I've been seeing from Jupiter lab

00:25:17,440 --> 00:25:21,200
is so awesome but you've got a bunch of

00:25:19,360 --> 00:25:23,900
different things that are sort of now

00:25:21,200 --> 00:25:26,210
interacting with and writing to this

00:25:23,900 --> 00:25:27,920
underlying data format and so sort of

00:25:26,210 --> 00:25:30,110
how do you make sure that if you're not

00:25:27,920 --> 00:25:31,880
operating in just a top-down execution

00:25:30,110 --> 00:25:33,860
where it's sell sell sell that you're

00:25:31,880 --> 00:25:34,730
actually going to get the same that

00:25:33,860 --> 00:25:39,530
you're actually gonna get the same

00:25:34,730 --> 00:25:40,940
results so before I wrap up you know I

00:25:39,530 --> 00:25:42,350
just wanted to talk a little bit about

00:25:40,940 --> 00:25:45,920
the context in which geo notebook was

00:25:42,350 --> 00:25:48,470
developed so this is not the product of

00:25:45,920 --> 00:25:49,760
a lone hacker but actually the effort of

00:25:48,470 --> 00:25:51,290
a couple of different devs

00:25:49,760 --> 00:25:53,330
two or three different devs over the

00:25:51,290 --> 00:25:54,680
course of about nine months and so the

00:25:53,330 --> 00:25:56,900
work was done as a part of NASA's Earth

00:25:54,680 --> 00:25:59,630
Science and Technology offices aced or

00:25:56,900 --> 00:26:02,240
advanced information systems technology

00:25:59,630 --> 00:26:03,740
grant and that's a bit of a mouthful we

00:26:02,240 --> 00:26:07,640
worked closely with NASA earth exchange

00:26:03,740 --> 00:26:08,900
at NASA Ames who curated and managed who

00:26:07,640 --> 00:26:12,440
actually did curate and manage some of

00:26:08,900 --> 00:26:14,840
the most complete and valuable data sets

00:26:12,440 --> 00:26:16,340
related to worldwide climate change and

00:26:14,840 --> 00:26:19,340
so the thrust of the proposal was to

00:26:16,340 --> 00:26:22,150
really demonstrate public cloud tools

00:26:19,340 --> 00:26:24,710
for extending raster data analysis

00:26:22,150 --> 00:26:27,200
capabilities so putting stuff out on AWS

00:26:24,710 --> 00:26:30,500
that allows for using notebooks and web

00:26:27,200 --> 00:26:32,210
mapping and NASA like many data stewards

00:26:30,500 --> 00:26:34,490
sort of has this problem right now where

00:26:32,210 --> 00:26:36,980
data size is rapidly outpacing

00:26:34,490 --> 00:26:39,380
researchers ability to download and

00:26:36,980 --> 00:26:40,430
analyze that data and so this is

00:26:39,380 --> 00:26:42,020
starting to actually impact some of

00:26:40,430 --> 00:26:44,020
their core mission which is to provide

00:26:42,020 --> 00:26:47,180
access to the data that your text that

00:26:44,020 --> 00:26:48,710
your tax dollars pay for so increasingly

00:26:47,180 --> 00:26:50,660
the solution that people are turning to

00:26:48,710 --> 00:26:53,150
is Leo delivering an analysis

00:26:50,660 --> 00:26:56,240
environment into the cloud in a way or

00:26:53,150 --> 00:26:58,130
into the cloud in a way that gets that

00:26:56,240 --> 00:26:59,390
analysis environment closer to the data

00:26:58,130 --> 00:27:01,970
and NASA has a bunch of different

00:26:59,390 --> 00:27:04,010
products know also both internal and

00:27:01,970 --> 00:27:05,780
external for sort of doing this kind of

00:27:04,010 --> 00:27:07,370
it but then the general idea is how do

00:27:05,780 --> 00:27:09,050
we get an analysis environment closer

00:27:07,370 --> 00:27:10,820
the data rather than having to ask

00:27:09,050 --> 00:27:12,980
people to bring data down into their

00:27:10,820 --> 00:27:14,990
individual institutions so Jupiter

00:27:12,980 --> 00:27:16,670
notebook and Jupiter hub in particular

00:27:14,990 --> 00:27:18,830
is really well placed to sort of be that

00:27:16,670 --> 00:27:20,570
analysis environment not only from a

00:27:18,830 --> 00:27:22,970
technical perspective but also from a

00:27:20,570 --> 00:27:24,980
mindshare perspective you know we've had

00:27:22,970 --> 00:27:26,650
a lot of really positive reactions from

00:27:24,980 --> 00:27:29,300
people in the geospatial community

00:27:26,650 --> 00:27:30,470
Jupiter notebook is a language that

00:27:29,300 --> 00:27:32,140
people really want to be able to

00:27:30,470 --> 00:27:34,730
and they want to be able to work with

00:27:32,140 --> 00:27:37,850
professionally in their day to day jobs

00:27:34,730 --> 00:27:39,950
and so sort of all of this is to say all

00:27:37,850 --> 00:27:41,659
that context is to say that geo notebook

00:27:39,950 --> 00:27:43,970
was originally developed as a

00:27:41,659 --> 00:27:45,530
demonstration of what is possible when

00:27:43,970 --> 00:27:47,720
you mash up web mapping with Jupiter

00:27:45,530 --> 00:27:49,100
notebook unfortunately what this means

00:27:47,720 --> 00:27:51,409
is that it comes with some of the

00:27:49,100 --> 00:27:54,470
shortcuts and technical debt that's

00:27:51,409 --> 00:27:56,150
indicative of demo code in many ways it

00:27:54,470 --> 00:27:58,340
sort of evolved well beyond those

00:27:56,150 --> 00:27:59,990
initial demonstrations towards what I

00:27:58,340 --> 00:28:01,730
would probably consider a sort of a

00:27:59,990 --> 00:28:03,710
Minimum Viable Product but it's still

00:28:01,730 --> 00:28:06,559
very early days for us in terms of the

00:28:03,710 --> 00:28:07,760
development that we're doing so part of

00:28:06,559 --> 00:28:09,679
what I'm here to do today is to sort of

00:28:07,760 --> 00:28:11,840
raise awareness about the project and

00:28:09,679 --> 00:28:13,850
potentially attract interested users and

00:28:11,840 --> 00:28:15,110
contributors so I don't know how many

00:28:13,850 --> 00:28:16,730
people in this room are familiar with

00:28:15,110 --> 00:28:18,440
Eric Raymond's essays the cathedral and

00:28:16,730 --> 00:28:21,080
the bazaar they're sort of canonical

00:28:18,440 --> 00:28:23,510
works in open source software community

00:28:21,080 --> 00:28:25,340
development and in his essays Raymond

00:28:23,510 --> 00:28:27,230
describes this concept of a plausible

00:28:25,340 --> 00:28:29,600
promise so when it comes to building

00:28:27,230 --> 00:28:30,830
open-source communities Raymond says you

00:28:29,600 --> 00:28:33,200
know your program doesn't have to work

00:28:30,830 --> 00:28:35,750
particularly well I can be crude buggy

00:28:33,200 --> 00:28:37,309
incomplete and poorly documented but

00:28:35,750 --> 00:28:39,860
what it must not fail to do is to run

00:28:37,309 --> 00:28:41,059
and to convince potential co developers

00:28:39,860 --> 00:28:42,470
that it can be evolved into something

00:28:41,059 --> 00:28:44,330
really neat in the foreseeable future

00:28:42,470 --> 00:28:46,700
and so I hope I've been able to make

00:28:44,330 --> 00:28:47,630
that promise to you guys today and if

00:28:46,700 --> 00:28:50,690
you're interested in getting involved

00:28:47,630 --> 00:28:52,190
please let me know I have a bunch of

00:28:50,690 --> 00:28:54,320
people to thank contributing projects in

00:28:52,190 --> 00:28:55,640
particular without these projects none

00:28:54,320 --> 00:28:57,200
of this work would be possible I mean

00:28:55,640 --> 00:28:58,909
thousands hundreds of thousands of

00:28:57,200 --> 00:29:01,250
man-hours involved here many of these

00:28:58,909 --> 00:29:03,530
projects are actually unfunded and

00:29:01,250 --> 00:29:04,970
without the dedicated work of the people

00:29:03,530 --> 00:29:07,159
behind those projects this would not be

00:29:04,970 --> 00:29:10,280
possible also a number of contributing

00:29:07,159 --> 00:29:11,720
humans so John Beasley and Dirk Ozturk

00:29:10,280 --> 00:29:13,280
in particular they are the geospatial

00:29:11,720 --> 00:29:15,559
experts that I work with they're both

00:29:13,280 --> 00:29:15,770
very smart significantly smarter than I

00:29:15,559 --> 00:29:18,200
am

00:29:15,770 --> 00:29:22,010
Mike little a Peter votive uh Andrew

00:29:18,200 --> 00:29:24,230
Michaels at NASA helped us an enormous

00:29:22,010 --> 00:29:25,460
amount in terms of use cases Mike little

00:29:24,230 --> 00:29:27,919
in particular as a program manager

00:29:25,460 --> 00:29:29,330
actually funded this work which is

00:29:27,919 --> 00:29:31,510
critical so this is all open source

00:29:29,330 --> 00:29:34,280
apache2 but somebody had to pay for it

00:29:31,510 --> 00:29:36,590
so that's pretty much all I've got so

00:29:34,280 --> 00:29:38,149
I'll take questions just you know we're

00:29:36,590 --> 00:29:41,299
out on github

00:29:38,149 --> 00:29:43,639
we're based on the east coast and so you

00:29:41,299 --> 00:29:45,739
know we're in get er 9:00 to 5:00

00:29:43,639 --> 00:29:47,029
usually Monday through Friday if anybody

00:29:45,739 --> 00:29:49,159
has any direct questions they want to

00:29:47,029 --> 00:29:52,159
ask read the docs and then also have a

00:29:49,159 --> 00:29:54,859
little docker incantation on the bottom

00:29:52,159 --> 00:29:56,539
here that if you have docker installed

00:29:54,859 --> 00:29:58,909
and running you should be able to get up

00:29:56,539 --> 00:30:00,439
and running with the notebook and so

00:29:58,909 --> 00:30:02,359
that is pretty much it

00:30:00,439 --> 00:30:17,229
and if you guys have questions I'll be

00:30:02,359 --> 00:30:17,229
happy to take them yes really awesome

00:30:23,109 --> 00:30:31,849
yeah so you can't actually um and the

00:30:27,079 --> 00:30:34,059
way that you do that is nope that's not

00:30:31,849 --> 00:30:34,059
right

00:30:36,150 --> 00:30:40,320
sorry I'm like totally

00:30:40,940 --> 00:30:50,440
let's see if we can there we go yeah so

00:30:47,030 --> 00:30:50,440
we do that up here

00:30:52,780 --> 00:30:56,530
sorry trying to find it

00:31:02,440 --> 00:31:11,270
let's go ahead and first of all let's

00:31:06,800 --> 00:31:13,640
blow away well let me just show you

00:31:11,270 --> 00:31:18,740
where the coat is and then all can worry

00:31:13,640 --> 00:31:21,220
about trying to get it to run yes you

00:31:18,740 --> 00:31:23,600
can you can actually add annotations by

00:31:21,220 --> 00:31:26,360
reading in like a shape file or polygon

00:31:23,600 --> 00:31:29,480
data geo JSON data and then you can use

00:31:26,360 --> 00:31:31,700
this m dot add annotation function and

00:31:29,480 --> 00:31:33,830
so you can specify a polygon and then

00:31:31,700 --> 00:31:36,590
the actual coordinates for that polygon

00:31:33,830 --> 00:31:44,300
as well as any metadata properties that

00:31:36,590 --> 00:31:48,080
you want to assign to it yes well yes

00:31:44,300 --> 00:31:50,180
yes so so yes you can use an existing

00:31:48,080 --> 00:31:52,010
geoserver there's actually in the source

00:31:50,180 --> 00:31:53,750
code repository we actually started with

00:31:52,010 --> 00:31:55,580
geoserver before I went to map Nick and

00:31:53,750 --> 00:31:57,140
G Dahl we found that there were some

00:31:55,580 --> 00:32:00,080
performance issues and some other

00:31:57,140 --> 00:32:02,260
complexities with getting styling to

00:32:00,080 --> 00:32:05,450
work particularly in this environment

00:32:02,260 --> 00:32:07,790
and so plus it's a it's a burden for

00:32:05,450 --> 00:32:09,710
people to have to set up a Geo server on

00:32:07,790 --> 00:32:10,760
their own if your goal is to support

00:32:09,710 --> 00:32:13,070
somebody who's just going to be running

00:32:10,760 --> 00:32:15,710
on their laptop and so there's actually

00:32:13,070 --> 00:32:18,230
some code in there that's specifically

00:32:15,710 --> 00:32:26,900
designed to use a custom visualization

00:32:18,230 --> 00:32:29,600
server for geo server and so so there's

00:32:26,900 --> 00:32:31,490
this there's this piece of thing here

00:32:29,600 --> 00:32:34,280
called a vis server that actually

00:32:31,490 --> 00:32:36,740
coordinates a bunch of the communication

00:32:34,280 --> 00:32:38,660
between the kernel and the server and

00:32:36,740 --> 00:32:40,610
there's one of those that specifically

00:32:38,660 --> 00:32:42,490
exists for geo Notebook the reason why I

00:32:40,610 --> 00:32:44,990
was a little hesitant earlier is because

00:32:42,490 --> 00:32:46,430
the last time anybody sort of used it

00:32:44,990 --> 00:32:48,860
was maybe three or four months ago and

00:32:46,430 --> 00:32:50,510
so you know we're we're in a we're in a

00:32:48,860 --> 00:32:52,850
fast-changing environment here where

00:32:50,510 --> 00:32:54,110
we're not necessarily supporting API

00:32:52,850 --> 00:32:56,390
stability and so there might be some

00:32:54,110 --> 00:32:58,490
issues associated with that on the flip

00:32:56,390 --> 00:33:00,500
side we are using K tile which is

00:32:58,490 --> 00:33:01,520
actually just tiles - there's a renderer

00:33:00,500 --> 00:33:04,280
and so if all you really want to do is

00:33:01,520 --> 00:33:08,360
render tiles then we can actually proxy

00:33:04,280 --> 00:33:10,820
through to a web map service like geo

00:33:08,360 --> 00:33:11,510
server or something else is that does

00:33:10,820 --> 00:33:13,760
that answer your question

00:33:11,510 --> 00:33:16,570
great I'm happy to talk in more detail

00:33:13,760 --> 00:33:16,570
about that with you

00:33:18,550 --> 00:33:50,450
well yeah so this export tool what do

00:33:23,690 --> 00:33:53,960
you expect some web man that the answer

00:33:50,450 --> 00:33:59,480
to your questions no and the reason is

00:33:53,960 --> 00:34:00,440
you know there's a lot of with the web

00:33:59,480 --> 00:34:01,970
map you need to be able to have

00:34:00,440 --> 00:34:03,740
something that's actually serving tiles

00:34:01,970 --> 00:34:07,100
behind it and actually reading that data

00:34:03,740 --> 00:34:08,630
and currently that's that's what's been

00:34:07,100 --> 00:34:12,020
extended on the Jupiter notebook sign

00:34:08,630 --> 00:34:13,850
and so I mean no there isn't an easy way

00:34:12,020 --> 00:34:16,760
there isn't an easy way to do that but

00:34:13,850 --> 00:34:17,990
code that you you know what no there

00:34:16,760 --> 00:34:20,600
isn't but I'd be happy to talk to you

00:34:17,990 --> 00:34:22,520
too about like sort of why it's why

00:34:20,600 --> 00:34:26,470
that's complicated transitioning into

00:34:22,520 --> 00:34:26,470
something like this yeah

00:34:35,119 --> 00:34:39,050
yeah well so yeah sure sorry let me

00:34:37,760 --> 00:34:42,050
repeat the question so the question is

00:34:39,050 --> 00:34:46,070
why don't we just go direct directly

00:34:42,050 --> 00:34:49,550
through the tornado server for this comm

00:34:46,070 --> 00:34:50,750
channel communication and I apologize

00:34:49,550 --> 00:34:53,389
this is actually a little bit misleading

00:34:50,750 --> 00:34:56,060
the the comm channel actually does go

00:34:53,389 --> 00:34:57,230
directly through the tornado web server

00:34:56,060 --> 00:34:58,640
right and so it actually is

00:34:57,230 --> 00:35:00,980
communicating from the notebook cell

00:34:58,640 --> 00:35:03,020
across the WebSocket the web the tornado

00:35:00,980 --> 00:35:04,940
server is proxying that through 2 0 mq

00:35:03,020 --> 00:35:07,550
but Jupiter actually provides a really

00:35:04,940 --> 00:35:08,990
nice abstraction on top of that so you

00:35:07,550 --> 00:35:13,010
don't actually have to know or care

00:35:08,990 --> 00:35:14,510
about any of that probably and that

00:35:13,010 --> 00:35:16,010
abstraction is the comm Channel yeah

00:35:14,510 --> 00:35:18,590
actually if you look at the messaging

00:35:16,010 --> 00:35:20,030
documentation for Jupiter towards the

00:35:18,590 --> 00:35:22,190
bottom there's a thing called custom

00:35:20,030 --> 00:35:24,770
comm channels and that's sort of how we

00:35:22,190 --> 00:35:26,119
started the stuff that we ended up

00:35:24,770 --> 00:35:27,619
implementing is a lot more complicated

00:35:26,119 --> 00:35:28,250
than that we built a lot of things on

00:35:27,619 --> 00:35:30,260
top of it

00:35:28,250 --> 00:35:33,320
but like that's the kernel of how to get

00:35:30,260 --> 00:35:38,320
started with getting a notebook and and

00:35:33,320 --> 00:35:38,320
the kernel to talk to each other yep

00:35:40,320 --> 00:35:46,380
oh my god I love Jupiter live it's so

00:35:42,090 --> 00:35:47,820
awesome yes so I would love to support

00:35:46,380 --> 00:35:50,550
this in Jupiter lab and I think actually

00:35:47,820 --> 00:35:51,990
it makes a lot of sense to support it in

00:35:50,550 --> 00:35:54,020
Jupiter lab we actually looked at

00:35:51,990 --> 00:35:57,270
Jupiter lab when we started doing this

00:35:54,020 --> 00:35:58,530
at that time there was no documentation

00:35:57,270 --> 00:36:01,230
I don't even know if they were an alpha

00:35:58,530 --> 00:36:02,400
yet so it was like it was too early we

00:36:01,230 --> 00:36:04,710
needed something that was a little bit

00:36:02,400 --> 00:36:07,020
more stable and I think we're they're

00:36:04,710 --> 00:36:08,700
approaching a point now where we would

00:36:07,020 --> 00:36:10,650
want to make that transition the issue

00:36:08,700 --> 00:36:15,030
really exists at the intersection of

00:36:10,650 --> 00:36:17,240
three dimensions one is time how much

00:36:15,030 --> 00:36:19,830
time that would take how much

00:36:17,240 --> 00:36:25,550
documentation exists for Jupiter Jupiter

00:36:19,830 --> 00:36:28,020
lab currently and then how much how much

00:36:25,550 --> 00:36:29,700
stability there is in the API and so

00:36:28,020 --> 00:36:31,200
with enough time we could overcome the

00:36:29,700 --> 00:36:33,570
other two issues with more of the other

00:36:31,200 --> 00:36:34,770
two we could take less time and so it's

00:36:33,570 --> 00:36:36,810
just a matter of sort of figuring out

00:36:34,770 --> 00:36:39,680
where the funding and other sorts of

00:36:36,810 --> 00:36:39,680
stuff will come from to that

00:36:52,900 --> 00:36:57,859
yeah that's correct so yeah so this guy

00:36:56,150 --> 00:36:59,600
which is sort of like the default I mean

00:36:57,859 --> 00:37:01,070
it kind of looks the same so this the

00:36:59,600 --> 00:37:02,450
default sort of like out-of-the-box

00:37:01,070 --> 00:37:04,400
functionality

00:37:02,450 --> 00:37:06,050
yeah the expectation is that you're sort

00:37:04,400 --> 00:37:07,430
of working with data that's locally but

00:37:06,050 --> 00:37:20,119
there's nothing that enforces that

00:37:07,430 --> 00:37:22,210
requirement yes so so actually not the

00:37:20,119 --> 00:37:27,170
demo that I showed so there's actually a

00:37:22,210 --> 00:37:28,640
couple of example notebooks and when you

00:37:27,170 --> 00:37:32,119
spin this up there will be an example

00:37:28,640 --> 00:37:33,890
one two three and four and this demo is

00:37:32,119 --> 00:37:35,540
actually just sort of a mash-up of those

00:37:33,890 --> 00:37:37,580
four notebooks and those should be

00:37:35,540 --> 00:37:39,410
available and they should work and if

00:37:37,580 --> 00:37:49,250
you try it and they don't please let me

00:37:39,410 --> 00:37:51,590
know yep yeah everything altogether the

00:37:49,250 --> 00:37:53,330
only thing that you'll need to do is to

00:37:51,590 --> 00:38:01,460
sort of get it up and running with

00:37:53,330 --> 00:38:04,010
docker is you'll want to you'll want to

00:38:01,460 --> 00:38:06,080
include something here that does port

00:38:04,010 --> 00:38:10,340
mapping on your hosts so you have direct

00:38:06,080 --> 00:38:13,460
access and then if you check out the

00:38:10,340 --> 00:38:15,200
notebook then you should if you so if

00:38:13,460 --> 00:38:16,970
you like have a repository and you may

00:38:15,200 --> 00:38:18,740
want to do a path to wherever your

00:38:16,970 --> 00:38:20,300
notebooks are gonna be but but if you're

00:38:18,740 --> 00:38:21,560
not if you're just running this then you

00:38:20,300 --> 00:38:25,190
actually don't play need to mount that

00:38:21,560 --> 00:38:26,330
and then we have the inside the example

00:38:25,190 --> 00:38:27,800
notebooks that are cells that will

00:38:26,330 --> 00:38:30,109
actually download data that you can work

00:38:27,800 --> 00:38:32,690
with and so they're intended to be sort

00:38:30,109 --> 00:38:36,859
of top to bottom very little upkeep to

00:38:32,690 --> 00:38:38,690
get started but at the same time like if

00:38:36,859 --> 00:38:39,770
there are issues if things that we've

00:38:38,690 --> 00:38:42,310
introduced recently have caused problems

00:38:39,770 --> 00:38:48,880
and we'd love to know about that

00:38:42,310 --> 00:38:49,930
other questions awesome thank you guys

00:38:48,880 --> 00:38:52,320
so much for coming out I really

00:38:49,930 --> 00:38:52,320

YouTube URL: https://www.youtube.com/watch?v=s82yE1gOuks


