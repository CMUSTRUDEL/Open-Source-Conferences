Title: Jupyter at Netflix - Kyle Kelley  (Netflix)
Publication date: 2017-11-08
Playlist: JupyterCon
Description: 
	So, Netflix's data scientists and engineers. . .do they know things? Join Kyle Kelley to find out. Kyle explores how Netflix uses Jupyter and explains how you can learn from Netflix's experience to enable analysts at your organization.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,550 --> 00:00:07,069
I'm Kyle I'm a Jupiter developer and

00:00:04,850 --> 00:00:09,580
then in the past on Jupiter I used to

00:00:07,069 --> 00:00:12,970
work on like security systems

00:00:09,580 --> 00:00:16,430
orchestration but now I work more on

00:00:12,970 --> 00:00:18,019
protocols and formats in front-end Evan

00:00:16,430 --> 00:00:21,679
kind of just things that work across the

00:00:18,019 --> 00:00:23,570
ecosystem and then within interact so I

00:00:21,679 --> 00:00:26,359
work on this other front-end that that's

00:00:23,570 --> 00:00:27,759
for the desktop and then a variety of

00:00:26,359 --> 00:00:33,170
different experiences and that's

00:00:27,759 --> 00:00:35,420
basically 99.999% front-end work and I

00:00:33,170 --> 00:00:37,879
was a mathematician and I just write

00:00:35,420 --> 00:00:44,600
JavaScript and I run the notebook

00:00:37,879 --> 00:00:50,690
platform in Netflix so I was a that was

00:00:44,600 --> 00:00:53,300
a good run from the elevator right so so

00:00:50,690 --> 00:00:55,969
I I fell in love with Jupiter and before

00:00:53,300 --> 00:00:57,589
Jupiter because of the experience that I

00:00:55,969 --> 00:00:59,499
got out of you know working with a

00:00:57,589 --> 00:01:02,570
repple and then working with a notebook

00:00:59,499 --> 00:01:05,690
and I really want more people to like

00:01:02,570 --> 00:01:07,520
experience that joy from from both you

00:01:05,690 --> 00:01:08,750
know working with with a computer but

00:01:07,520 --> 00:01:09,920
then working with you know their own

00:01:08,750 --> 00:01:14,960
data and just kind of having this

00:01:09,920 --> 00:01:16,610
overall dance with all of it and so

00:01:14,960 --> 00:01:19,550
before I was at Netflix I worked at

00:01:16,610 --> 00:01:21,380
Rackspace and largely speaking my work

00:01:19,550 --> 00:01:23,450
on Jupiter was just for fun I was a

00:01:21,380 --> 00:01:26,600
volunteer contributor I mean I'm still a

00:01:23,450 --> 00:01:28,910
volunteer contributor but it was just

00:01:26,600 --> 00:01:31,580
like there was no there was no purpose

00:01:28,910 --> 00:01:35,330
in mind and that there weren't like

00:01:31,580 --> 00:01:36,770
nobody was had other than issues like I

00:01:35,330 --> 00:01:38,120
didn't I didn't have any analysts that I

00:01:36,770 --> 00:01:40,700
was supporting I didn't have anybody

00:01:38,120 --> 00:01:42,080
that was that was really driving why I

00:01:40,700 --> 00:01:43,820
would go for certain kinds of decisions

00:01:42,080 --> 00:01:48,860
and so admittedly it was a bit of a

00:01:43,820 --> 00:01:50,840
vacuum and I guess on some level was

00:01:48,860 --> 00:01:54,770
isolating once I realized that I had

00:01:50,840 --> 00:01:56,780
kind of not seen what was going on but I

00:01:54,770 --> 00:02:00,500
was fortunate to come to Netflix because

00:01:56,780 --> 00:02:01,820
it gave me a lot greater context I was

00:02:00,500 --> 00:02:04,160
amazing to see what some of the real

00:02:01,820 --> 00:02:05,840
pain points were like things before like

00:02:04,160 --> 00:02:07,910
I could only kind of perceive what they

00:02:05,840 --> 00:02:09,410
were from issues a lot of its like if

00:02:07,910 --> 00:02:11,120
you fix something like much further up

00:02:09,410 --> 00:02:13,400
from what people are describing like

00:02:11,120 --> 00:02:14,060
you'll completely like closed loop on

00:02:13,400 --> 00:02:16,700
what the real issue

00:02:14,060 --> 00:02:20,090
was and so now I'm just I'm really happy

00:02:16,700 --> 00:02:21,739
to work on just just anything that

00:02:20,090 --> 00:02:25,250
that's gonna be able to support analysts

00:02:21,739 --> 00:02:27,170
of different backgrounds and so

00:02:25,250 --> 00:02:29,300
effectively the way that I think about

00:02:27,170 --> 00:02:32,060
it like for me is that Netflix is kind

00:02:29,300 --> 00:02:33,470
of my laboratory to to evaluate how

00:02:32,060 --> 00:02:34,940
analysts and data scientists and

00:02:33,470 --> 00:02:37,069
engineers are working with stuff and

00:02:34,940 --> 00:02:38,540
make the tools better and then I'm

00:02:37,069 --> 00:02:40,819
really happy that that ends up going

00:02:38,540 --> 00:02:41,900
back into the open source and I get to

00:02:40,819 --> 00:02:50,090
continue the work that I was doing

00:02:41,900 --> 00:02:51,920
before I said right and part of that is

00:02:50,090 --> 00:02:54,019
also finding out you know that humans

00:02:51,920 --> 00:02:55,640
they always just do exactly what you

00:02:54,019 --> 00:02:58,160
tell them and they go straight for

00:02:55,640 --> 00:03:02,900
intended behavior there's there's

00:02:58,160 --> 00:03:04,489
nothing crazy that ever happens and I

00:03:02,900 --> 00:03:06,019
think some of the big highlights and

00:03:04,489 --> 00:03:09,709
it's like oh these are these are areas

00:03:06,019 --> 00:03:11,420
we need to go after as Jupiter is that

00:03:09,709 --> 00:03:13,010
the notebook server gets treated like a

00:03:11,420 --> 00:03:14,390
cheap web server dashboard and

00:03:13,010 --> 00:03:17,030
especially if you have the permissions

00:03:14,390 --> 00:03:18,410
wide open then and people will try to do

00:03:17,030 --> 00:03:20,060
it on purpose to leave the permissions

00:03:18,410 --> 00:03:22,310
open give them this good way to iterate

00:03:20,060 --> 00:03:24,980
they'll create like template notebooks

00:03:22,310 --> 00:03:28,640
they have a curry within them and

00:03:24,980 --> 00:03:30,709
they'll they like basically they'll just

00:03:28,640 --> 00:03:32,750
hand someone this prefab like pi spark

00:03:30,709 --> 00:03:34,880
setup and job that'll do this stuff

00:03:32,750 --> 00:03:36,200
where an analyst probably no sequel but

00:03:34,880 --> 00:03:38,329
they may not know how to do the rest of

00:03:36,200 --> 00:03:40,100
the work in Python but it gives them a

00:03:38,329 --> 00:03:41,329
way to do exploration that's fairly

00:03:40,100 --> 00:03:42,859
light

00:03:41,329 --> 00:03:44,060
I mean I'm describing like you're all

00:03:42,859 --> 00:03:44,959
here at Jupiter con so I'm like

00:03:44,060 --> 00:03:48,400
describing things are like well

00:03:44,959 --> 00:03:50,480
obviously uber can do all those things

00:03:48,400 --> 00:03:51,859
but then they you know they end up

00:03:50,480 --> 00:03:54,709
tripping on each other's toes without

00:03:51,859 --> 00:03:56,120
standard practices and then another big

00:03:54,709 --> 00:03:57,739
thing I mean like this is kind of

00:03:56,120 --> 00:03:59,389
obvious to me before is that you know

00:03:57,739 --> 00:04:02,739
people want to they want to disseminate

00:03:59,389 --> 00:04:02,739
they want to share with each other oh

00:04:05,530 --> 00:04:09,340
I'm gonna get some water real quick

00:04:20,440 --> 00:04:29,110
I mean so for the data platform itself

00:04:26,440 --> 00:04:31,210
like generally what we want to do is is

00:04:29,110 --> 00:04:32,740
one of this nice smooth experience for

00:04:31,210 --> 00:04:34,810
for running code generally on the

00:04:32,740 --> 00:04:36,870
platform whether that's in our they were

00:04:34,810 --> 00:04:39,630
working in Python or with just Prestel

00:04:36,870 --> 00:04:43,060
presto queries or their hive queries

00:04:39,630 --> 00:04:45,010
right now it spans exploration of data

00:04:43,060 --> 00:04:46,990
to machine learning to like running

00:04:45,010 --> 00:04:48,970
production jobs but it's not really

00:04:46,990 --> 00:04:50,920
fully cohesive and people are still

00:04:48,970 --> 00:04:54,010
they're gonna go back to tableau for for

00:04:50,920 --> 00:04:56,020
exploration and reporting without

00:04:54,010 --> 00:04:58,810
without going to to Netflix I wouldn't

00:04:56,020 --> 00:05:01,150
have realized how good tableau is and I

00:04:58,810 --> 00:05:05,380
didn't want to admit that like a few

00:05:01,150 --> 00:05:08,560
days in I was like oh this is good I see

00:05:05,380 --> 00:05:10,360
why people like this okay and well I

00:05:08,560 --> 00:05:13,480
don't think I don't think Jupiter is

00:05:10,360 --> 00:05:15,490
gonna like take over that like area I

00:05:13,480 --> 00:05:17,440
think someone should you know keep keep

00:05:15,490 --> 00:05:19,450
investing towards the visualization and

00:05:17,440 --> 00:05:22,060
get you know tableau like stuff out and

00:05:19,450 --> 00:05:24,190
open-source sometimes a machine learning

00:05:22,060 --> 00:05:25,150
it gets done in our and then we ship it

00:05:24,190 --> 00:05:28,780
and docker and then we call that

00:05:25,150 --> 00:05:30,730
production and then there you go

00:05:28,780 --> 00:05:32,230
then production ETL is around and hiver

00:05:30,730 --> 00:05:36,070
pig and it's you know kind of all over

00:05:32,230 --> 00:05:37,660
the place and so you know we don't have

00:05:36,070 --> 00:05:39,400
a single environment to solve all these

00:05:37,660 --> 00:05:41,740
problems and so we want to invest in the

00:05:39,400 --> 00:05:43,930
tools that the kind of span this right

00:05:41,740 --> 00:05:45,750
and I mean not surprisingly I'm gonna

00:05:43,930 --> 00:05:47,830
tell you that hey it's the notebook

00:05:45,750 --> 00:05:49,960
right and so we can explore data

00:05:47,830 --> 00:05:53,470
interact with the platform and then run

00:05:49,960 --> 00:05:54,850
jobs in really simple ways and some of

00:05:53,470 --> 00:05:57,400
the some of the main problems that

00:05:54,850 --> 00:06:00,700
people want to handle are reproducible

00:05:57,400 --> 00:06:02,320
research collaboration and sharing and

00:06:00,700 --> 00:06:04,540
then just generally like improving the

00:06:02,320 --> 00:06:06,130
runtimes for jobs that weren't easy to

00:06:04,540 --> 00:06:08,440
production Eliza before on the spark

00:06:06,130 --> 00:06:09,910
cluster on the Hadoop cluster or they're

00:06:08,440 --> 00:06:14,770
just too small to make sense to put

00:06:09,910 --> 00:06:16,780
there right and and generally it's about

00:06:14,770 --> 00:06:18,940
you know reducing the friction making it

00:06:16,780 --> 00:06:20,620
a lot easier like you know if anything

00:06:18,940 --> 00:06:22,240
like our goal should be to make sure

00:06:20,620 --> 00:06:25,300
that people are spending lots of money

00:06:22,240 --> 00:06:28,840
on jobs and they're just wasting all the

00:06:25,300 --> 00:06:30,400
resources they can but like you know

00:06:28,840 --> 00:06:32,500
it's really just like give people access

00:06:30,400 --> 00:06:34,270
to the point that anybody that comes in

00:06:32,500 --> 00:06:35,890
to Netflix like

00:06:34,270 --> 00:06:37,510
even if they're if they're an analyst or

00:06:35,890 --> 00:06:38,560
they were in some certain other area

00:06:37,510 --> 00:06:40,270
they should be able to make a curry

00:06:38,560 --> 00:06:42,520
immediately like they should be able to

00:06:40,270 --> 00:06:45,040
come in and find a report a memo and

00:06:42,520 --> 00:06:46,570
then have the the backing data to it and

00:06:45,040 --> 00:06:50,280
run it themselves and see what's there

00:06:46,570 --> 00:06:52,240
even if they're they're not a programmer

00:06:50,280 --> 00:06:53,890
right and so the the vision statement

00:06:52,240 --> 00:06:56,320
that I put together for the notebook

00:06:53,890 --> 00:06:58,030
environment is that you should that we

00:06:56,320 --> 00:06:59,590
that we provide a notebook environment

00:06:58,030 --> 00:07:02,170
to experiment with data interactively

00:06:59,590 --> 00:07:06,190
and collaborate with colleagues quickly

00:07:02,170 --> 00:07:07,720
and effectively so I'm gonna get get

00:07:06,190 --> 00:07:09,940
down to earth just a little bit

00:07:07,720 --> 00:07:13,360
no fun facts so all these slides these

00:07:09,940 --> 00:07:20,320
are from story bots which is my favorite

00:07:13,360 --> 00:07:22,120
kid show right and so to the data

00:07:20,320 --> 00:07:25,030
platform itself

00:07:22,120 --> 00:07:27,520
the main ways that we do it are with a

00:07:25,030 --> 00:07:28,840
Python library called kragle I know I

00:07:27,520 --> 00:07:31,450
didn't mention in here but there's also

00:07:28,840 --> 00:07:33,370
geni but that'll be another slide SPARC

00:07:31,450 --> 00:07:34,960
is another primary access point it's

00:07:33,370 --> 00:07:38,230
some like twenty to forty percent of all

00:07:34,960 --> 00:07:40,090
jobs and then layers and layers of

00:07:38,230 --> 00:07:41,620
sovereigns who create this big data

00:07:40,090 --> 00:07:43,690
image which I guess I should call the

00:07:41,620 --> 00:07:45,910
big big data image since it has like all

00:07:43,690 --> 00:07:50,950
the libraries and it's the same image

00:07:45,910 --> 00:07:55,900
used for jobs and then genie is is is

00:07:50,950 --> 00:07:58,780
effectively the kind of orchestration

00:07:55,900 --> 00:08:00,430
engine for for running a lot of jobs

00:07:58,780 --> 00:08:02,620
I probably shouldn't caught to somebody

00:08:00,430 --> 00:08:04,930
else's but stitch fix were a really good

00:08:02,620 --> 00:08:06,340
article on how they use genie so I

00:08:04,930 --> 00:08:07,630
definitely recommend going and looking

00:08:06,340 --> 00:08:12,190
that up and they put it out just a

00:08:07,630 --> 00:08:13,480
couple weeks ago and then for kernels we

00:08:12,190 --> 00:08:15,790
provide a whole bunch of kernels that

00:08:13,480 --> 00:08:18,150
are available for for bash and Python

00:08:15,790 --> 00:08:20,230
with different versions of Pi spark

00:08:18,150 --> 00:08:24,220
because some people need to transition

00:08:20,230 --> 00:08:25,450
from one six two two o or in some cases

00:08:24,220 --> 00:08:27,850
they're actually going to read you know

00:08:25,450 --> 00:08:30,520
they want to reach spark to one or spark

00:08:27,850 --> 00:08:33,820
to two and we could give access to all

00:08:30,520 --> 00:08:35,350
those and and at least for Scala and

00:08:33,820 --> 00:08:37,240
there will be a talk about this tomorrow

00:08:35,350 --> 00:08:38,440
that that I hope people go to that are

00:08:37,240 --> 00:08:40,840
interested in making the skull

00:08:38,440 --> 00:08:43,450
experience better as Alex archambault is

00:08:40,840 --> 00:08:45,070
going to talk about the Scala kernels

00:08:43,450 --> 00:08:47,080
and kind of the landscape around them

00:08:45,070 --> 00:08:48,580
but we currently contribute to Apache

00:08:47,080 --> 00:08:51,640
Tory

00:08:48,580 --> 00:08:53,080
it has its warts but we we run it with

00:08:51,640 --> 00:08:54,760
their own patches internally we keep

00:08:53,080 --> 00:08:55,840
trying to fix up what we can and we're

00:08:54,760 --> 00:09:00,340
hoping more people will get involved

00:08:55,840 --> 00:09:03,700
there and on top of that at least for

00:09:00,340 --> 00:09:06,040
Scala it doesn't have a matplotlib so so

00:09:03,700 --> 00:09:08,170
some folks at Netflix created Vegas with

00:09:06,040 --> 00:09:10,900
which outputs Vega so if you've worked

00:09:08,170 --> 00:09:13,480
with altair right it's outputting the

00:09:10,900 --> 00:09:16,990
same JSON that JSON Vega and big alight

00:09:13,480 --> 00:09:18,370
spec but but you can stop it's not

00:09:16,990 --> 00:09:19,960
showing it well here but I mean you can

00:09:18,370 --> 00:09:22,870
effectively work with spark data frames

00:09:19,960 --> 00:09:27,270
or other kinds of objects and visualize

00:09:22,870 --> 00:09:27,270
them directly inside the notebooks so

00:09:28,320 --> 00:09:32,740
the main ways that we provided or we

00:09:31,300 --> 00:09:34,690
have this kind of fixed shared

00:09:32,740 --> 00:09:37,510
allocation kind like a multi-tenant host

00:09:34,690 --> 00:09:40,510
that's over provisioned but has SSH

00:09:37,510 --> 00:09:42,340
access and is always on and then these

00:09:40,510 --> 00:09:44,890
notebooks that you can spawn on demand

00:09:42,340 --> 00:09:48,520
and request request a number of GPUs

00:09:44,890 --> 00:09:49,030
that you want like how much CPU and

00:09:48,520 --> 00:09:51,370
memory

00:09:49,030 --> 00:09:53,710
you're gonna need and then it has a TTL

00:09:51,370 --> 00:09:55,150
and we just go ahead and kill it off and

00:09:53,710 --> 00:09:57,430
so if you've worked with temp in beer

00:09:55,150 --> 00:09:59,380
you've worked with Jupiter hub it's the

00:09:57,430 --> 00:10:00,580
it's the same kind of concept it's some

00:09:59,380 --> 00:10:02,860
of the same kind of it's some of the

00:10:00,580 --> 00:10:05,200
same code but then both of these

00:10:02,860 --> 00:10:07,660
environments live on top of EFS and it's

00:10:05,200 --> 00:10:11,589
Amazon EFS the elastic filesystem so

00:10:07,660 --> 00:10:14,230
it's just NFS and that's been phenomenal

00:10:11,589 --> 00:10:17,140
because we used to actually put the

00:10:14,230 --> 00:10:18,520
notebooks directly to s3 but we found

00:10:17,140 --> 00:10:21,430
people have been much happier just

00:10:18,520 --> 00:10:26,110
having a file system that they know

00:10:21,430 --> 00:10:27,640
where to work with it and so like I was

00:10:26,110 --> 00:10:29,380
saying before about this big data image

00:10:27,640 --> 00:10:32,580
it's actually just the same docker image

00:10:29,380 --> 00:10:34,690
and so when I talk about a TTL

00:10:32,580 --> 00:10:36,580
effectively we're upgrading people all

00:10:34,690 --> 00:10:38,050
the time like over the weekend their

00:10:36,580 --> 00:10:40,210
notebook server's gonna get killed off

00:10:38,050 --> 00:10:42,280
and they'll end up getting a new one

00:10:40,210 --> 00:10:44,080
brought up back on Monday so they'll get

00:10:42,280 --> 00:10:45,670
a bunch of updates and you probably

00:10:44,080 --> 00:10:48,700
think to yourself oh my gosh they

00:10:45,670 --> 00:10:50,050
changed versions on them every week and

00:10:48,700 --> 00:10:52,480
so people can create their own virtual

00:10:50,050 --> 00:10:54,820
environments or Khanda environments if

00:10:52,480 --> 00:10:57,100
they want to but but generally speaking

00:10:54,820 --> 00:10:58,440
like we want to keep people upgraded we

00:10:57,100 --> 00:11:02,149
want to keep all the security patches

00:10:58,440 --> 00:11:04,069
like moving forward

00:11:02,149 --> 00:11:05,720
yeah like I was saying before ones

00:11:04,069 --> 00:11:07,699
basically kind of like a single-user

00:11:05,720 --> 00:11:09,470
notebook yeah it actually lives on a

00:11:07,699 --> 00:11:14,149
sub-domain and then another one that's

00:11:09,470 --> 00:11:16,790
effectively Jupiter hub like I'm gonna

00:11:14,149 --> 00:11:19,730
skip that right now is about the big

00:11:16,790 --> 00:11:21,919
data image and an important thing to do

00:11:19,730 --> 00:11:23,809
at least for these I mean like we treat

00:11:21,919 --> 00:11:25,699
this like it's a support role and so

00:11:23,809 --> 00:11:28,040
people will come in on slack or post to

00:11:25,699 --> 00:11:30,410
internal Google Groups to post to

00:11:28,040 --> 00:11:33,049
mailing lists or to a private github

00:11:30,410 --> 00:11:35,629
repo to kind of post about things a

00:11:33,049 --> 00:11:37,339
large amount of it is just people asking

00:11:35,629 --> 00:11:39,589
for features in the Jupiter notebook and

00:11:37,339 --> 00:11:41,720
then you know we just have to like move

00:11:39,589 --> 00:11:44,269
that feedback as far into open source as

00:11:41,720 --> 00:11:46,429
we can but a lot of times it's also our

00:11:44,269 --> 00:11:48,259
own platform and it's sometimes hard for

00:11:46,429 --> 00:11:50,329
users to tell the difference between is

00:11:48,259 --> 00:11:52,339
it a spark problem a scala problem an

00:11:50,329 --> 00:11:54,350
output problem and you have to like help

00:11:52,339 --> 00:11:58,399
them navigate that and hope to fix kind

00:11:54,350 --> 00:11:59,629
of everything for the greater good so if

00:11:58,399 --> 00:12:01,639
you want to hear more about the data

00:11:59,629 --> 00:12:03,799
platform in particular at flicks I

00:12:01,639 --> 00:12:07,610
recommend to talks Curt Brown gave a

00:12:03,799 --> 00:12:09,559
talk at strata just this year not too

00:12:07,610 --> 00:12:12,199
long ago both the slides were linked in

00:12:09,559 --> 00:12:14,600
here at all I'll tweet out all of these

00:12:12,199 --> 00:12:17,029
slides and then Michelle offered put a

00:12:14,600 --> 00:12:20,480
talk on scaling data quality I'm she's

00:12:17,029 --> 00:12:21,769
much much closer to the the analysts so

00:12:20,480 --> 00:12:25,610
she'll have a different perspective if

00:12:21,769 --> 00:12:27,290
you want to see that and so when I

00:12:25,610 --> 00:12:29,389
talked about having all the notebooks on

00:12:27,290 --> 00:12:31,639
ef-s one big benefit that we have is

00:12:29,389 --> 00:12:33,379
that we can we can mount a different

00:12:31,639 --> 00:12:35,179
server that has the ef-s and then just

00:12:33,379 --> 00:12:37,429
go ahead and render them all and so we

00:12:35,179 --> 00:12:39,860
do this with commuter and commuter is

00:12:37,429 --> 00:12:41,269
effectively just like MB viewer but it's

00:12:39,860 --> 00:12:43,279
it's going to be more tailored to

00:12:41,269 --> 00:12:45,709
publishing as well as being able to

00:12:43,279 --> 00:12:47,329
actually execute code on it uses the

00:12:45,709 --> 00:12:49,489
same react components that are in the

00:12:47,329 --> 00:12:51,110
interact desktop app and we're just

00:12:49,489 --> 00:12:56,869
we're just going to keep pumping stuff

00:12:51,110 --> 00:12:58,669
out through there and so and then

00:12:56,869 --> 00:13:00,739
another project that we're working on

00:12:58,669 --> 00:13:02,929
and this is within the the enter act org

00:13:00,739 --> 00:13:06,379
so if you go to github.com slash anorak

00:13:02,929 --> 00:13:08,389
slash paper mill and get to this which

00:13:06,379 --> 00:13:11,739
is effectively being able to execute

00:13:08,389 --> 00:13:11,739
parametrized notebooks

00:13:14,070 --> 00:13:17,829
and so that this is for people that

00:13:16,360 --> 00:13:19,720
basically want to go for a notebook to

00:13:17,829 --> 00:13:22,779
notebook they want to run some amount of

00:13:19,720 --> 00:13:28,180
parameters inside of it I'm actually

00:13:22,779 --> 00:13:30,190
gonna skip straight to this so you you

00:13:28,180 --> 00:13:32,320
tag a cell with a label say oh hey this

00:13:30,190 --> 00:13:33,730
is my parameter cell and the API before

00:13:32,320 --> 00:13:36,220
this may change that's why I put that

00:13:33,730 --> 00:13:37,779
data tag on there but effectively you

00:13:36,220 --> 00:13:39,730
you write code in the first block that

00:13:37,779 --> 00:13:42,790
you want to have be able to be swapped

00:13:39,730 --> 00:13:45,250
out and then when you run it so here it

00:13:42,790 --> 00:13:48,910
takes a local notebook right out to s3

00:13:45,250 --> 00:13:51,070
and then set these parameters and if you

00:13:48,910 --> 00:13:53,560
if you iterate across the parameters you

00:13:51,070 --> 00:13:55,240
just run papermill multiple times you'd

00:13:53,560 --> 00:13:56,769
run them with those separate parameters

00:13:55,240 --> 00:13:58,269
but you're you're giving an individual

00:13:56,769 --> 00:14:01,110
notebook with the outputs and everything

00:13:58,269 --> 00:14:04,600
in line so this is this is how we run

00:14:01,110 --> 00:14:06,730
notebooks as jobs but none of the

00:14:04,600 --> 00:14:10,389
scheduling just literally how we run the

00:14:06,730 --> 00:14:13,389
notebook and then of course you can also

00:14:10,389 --> 00:14:15,570
do it from the Python API directly this

00:14:13,389 --> 00:14:17,589
shows and a flex paper mill but the

00:14:15,570 --> 00:14:25,029
public paper mill you can just pip

00:14:17,589 --> 00:14:26,470
install paper mill right and so so once

00:14:25,029 --> 00:14:28,660
you do this and you actually ran like I

00:14:26,470 --> 00:14:30,970
just you you ran a parallel job across

00:14:28,660 --> 00:14:32,740
the notebooks you can you could record

00:14:30,970 --> 00:14:34,569
in each individual cell a particular

00:14:32,740 --> 00:14:36,430
parameter you cared about right you can

00:14:34,569 --> 00:14:38,230
you could put an R MSE value in here

00:14:36,430 --> 00:14:41,769
right as you guys you're gonna do some

00:14:38,230 --> 00:14:43,690
grid search and and then on the side you

00:14:41,769 --> 00:14:45,010
can actually access that that recorded

00:14:43,690 --> 00:14:46,959
value so if you had a whole bunch of

00:14:45,010 --> 00:14:48,730
notebooks you wanted to read from you

00:14:46,959 --> 00:14:51,490
could check to see how each of them

00:14:48,730 --> 00:14:52,870
performed and then dive into them and at

00:14:51,490 --> 00:14:54,220
least for a Commuter that's really easy

00:14:52,870 --> 00:14:58,779
because you're just clicking through me

00:14:54,220 --> 00:15:00,610
to the created notebooks and it lets you

00:14:58,779 --> 00:15:01,870
pull out pull out other outputs from the

00:15:00,610 --> 00:15:03,610
notebooks individually and so it gives

00:15:01,870 --> 00:15:09,010
you this way to analyze your notebooks

00:15:03,610 --> 00:15:10,630
as if they're data themselves and it's

00:15:09,010 --> 00:15:13,240
not just for Python there's actually our

00:15:10,630 --> 00:15:15,970
bindings and you can change that the

00:15:13,240 --> 00:15:17,889
same parameters too so you still get

00:15:15,970 --> 00:15:20,199
parameters notebooks I want it to be a

00:15:17,889 --> 00:15:22,480
bigger feature within Jupiter as if that

00:15:20,199 --> 00:15:24,130
was a real thing for us to be able to

00:15:22,480 --> 00:15:25,470
set parameters kind of at the start of a

00:15:24,130 --> 00:15:27,970
notebook

00:15:25,470 --> 00:15:28,780
we're don't know exactly what to do for

00:15:27,970 --> 00:15:30,430
that yet

00:15:28,780 --> 00:15:32,830
this seems like the easiest experience

00:15:30,430 --> 00:15:34,870
right now to just have the tags and then

00:15:32,830 --> 00:15:40,180
let people set it set particular values

00:15:34,870 --> 00:15:41,680
that get overridden yeah and so like I

00:15:40,180 --> 00:15:43,120
was saying about looking at across a

00:15:41,680 --> 00:15:45,280
bunch of different jobs so if you look

00:15:43,120 --> 00:15:48,130
at this one there's there's several

00:15:45,280 --> 00:15:50,260
different file names and then you can

00:15:48,130 --> 00:15:52,150
see which which names and values those

00:15:50,260 --> 00:15:54,550
had and you just give a data frame of

00:15:52,150 --> 00:15:57,790
notebooks to look at and see how those

00:15:54,550 --> 00:15:59,470
did write you were you were in the the

00:15:57,790 --> 00:16:00,880
the thing here is that instead of

00:15:59,470 --> 00:16:02,290
running a scripts and they're just

00:16:00,880 --> 00:16:04,510
getting some sort of standard output

00:16:02,290 --> 00:16:05,860
later on you've got a full notebook that

00:16:04,510 --> 00:16:08,470
has all the stuff you would normally

00:16:05,860 --> 00:16:10,060
have in there including the images any

00:16:08,470 --> 00:16:11,650
other data frames made thing else and

00:16:10,060 --> 00:16:15,040
then you can actually analyze that

00:16:11,650 --> 00:16:16,420
instead of having to read each one and

00:16:15,040 --> 00:16:18,400
so this is an example of how we're

00:16:16,420 --> 00:16:20,500
submitting jobs so here's here's a

00:16:18,400 --> 00:16:22,630
collection of parameters and then we

00:16:20,500 --> 00:16:24,280
then we're going ahead and creating a

00:16:22,630 --> 00:16:27,820
job that's going to run across each of

00:16:24,280 --> 00:16:29,830
these this is this is that that API so

00:16:27,820 --> 00:16:31,420
like we have an internal layer to be

00:16:29,830 --> 00:16:34,060
able to just run a job really easily and

00:16:31,420 --> 00:16:37,530
Netflix you set up what your job name is

00:16:34,060 --> 00:16:44,680
and then then you run this right through

00:16:37,530 --> 00:16:47,980
right yeah it's so so one of my

00:16:44,680 --> 00:16:49,570
colleagues Eric Massey who's not here he

00:16:47,980 --> 00:16:51,970
wants to focus also on being able to

00:16:49,570 --> 00:16:53,800
write write and read data frames to and

00:16:51,970 --> 00:16:56,550
from tables and like make that really

00:16:53,800 --> 00:16:58,990
easy and kind of part of paper mill and

00:16:56,550 --> 00:17:00,610
we're exploring that a little bit and

00:16:58,990 --> 00:17:01,990
exploring how we might do it with with

00:17:00,610 --> 00:17:04,089
arrow and actually have it as a side

00:17:01,990 --> 00:17:05,949
artifact but not in the notebook so it'd

00:17:04,089 --> 00:17:08,589
be a reference within there but then

00:17:05,949 --> 00:17:12,820
we'd be able to display it with within

00:17:08,589 --> 00:17:14,260
our own ends and then one thing that you

00:17:12,820 --> 00:17:16,630
know isn't in the Jupiter notebook right

00:17:14,260 --> 00:17:18,040
now which is the cell execution time so

00:17:16,630 --> 00:17:21,339
we're going to explore it as metadata

00:17:18,040 --> 00:17:22,420
for now but at least at least make it so

00:17:21,339 --> 00:17:24,790
I don't know if you've worked with like

00:17:22,420 --> 00:17:26,589
data Brooks's UI but in databar qi they

00:17:24,790 --> 00:17:28,750
show you what the what the timestamp is

00:17:26,589 --> 00:17:30,190
for the the cell runs and so here we

00:17:28,750 --> 00:17:32,470
want to just go ahead and make that a

00:17:30,190 --> 00:17:35,130
part of the notebook it's never a part

00:17:32,470 --> 00:17:38,080
of the jupiter notebook format by like

00:17:35,130 --> 00:17:38,650
by default like we have the information

00:17:38,080 --> 00:17:39,610
for it but it

00:17:38,650 --> 00:17:41,230
not put in there because we've been

00:17:39,610 --> 00:17:43,120
worried about what that looks for

00:17:41,230 --> 00:17:44,200
diffing but for use cases like these

00:17:43,120 --> 00:17:46,180
where you really just want the

00:17:44,200 --> 00:17:51,310
information like we're gonna stick it in

00:17:46,180 --> 00:17:53,080
to make it separate metadata and so so

00:17:51,310 --> 00:17:58,270
these are those resources for paper mill

00:17:53,080 --> 00:18:02,010
themselves yeah

00:17:58,270 --> 00:18:02,010
Oh was that are you me go back

00:18:12,980 --> 00:18:18,040
go I could leave it there then and I

00:18:15,110 --> 00:18:18,040
have some questions

00:18:39,930 --> 00:18:47,460
so the question was how do you so with

00:18:43,140 --> 00:18:48,540
with papermill how do you know how do

00:18:47,460 --> 00:18:50,690
you know which notebook you're going to

00:18:48,540 --> 00:18:50,690
run

00:18:55,920 --> 00:19:03,480
yes so okay so the the user knows

00:19:01,680 --> 00:19:05,100
because when you're creating a notebook

00:19:03,480 --> 00:19:07,350
that you're going to run through paper

00:19:05,100 --> 00:19:09,360
mill it's not it's not a service it's

00:19:07,350 --> 00:19:10,620
literally just a command-line tool so

00:19:09,360 --> 00:19:12,240
you would have saved you saved the

00:19:10,620 --> 00:19:13,440
notebook with whatever name you want and

00:19:12,240 --> 00:19:14,700
then you're gonna run it through paper

00:19:13,440 --> 00:19:23,280
money it works just like and be

00:19:14,700 --> 00:19:27,300
converted but with less arguments you

00:19:23,280 --> 00:19:44,250
can you can ask anything I Swift soda is

00:19:27,300 --> 00:19:46,980
fine yeah so that the question was for

00:19:44,250 --> 00:19:48,690
for enterprise usage of EFS and with

00:19:46,980 --> 00:19:52,100
people doing version control how do you

00:19:48,690 --> 00:19:55,260
manage it on on this network file system

00:19:52,100 --> 00:19:57,630
so we also have a slash data amount that

00:19:55,260 --> 00:19:59,730
is an e BS volume that stays persistent

00:19:57,630 --> 00:20:04,050
for that whichever one there they're

00:19:59,730 --> 00:20:05,640
loading off of and they'll hit file like

00:20:04,050 --> 00:20:07,350
that it'll be obvious to them that their

00:20:05,640 --> 00:20:08,790
files aren't loading as fast and we

00:20:07,350 --> 00:20:11,130
recommend that they work with stuff

00:20:08,790 --> 00:20:20,120
inside of slash data instead of on their

00:20:11,130 --> 00:20:20,120
EFS that's no

00:20:28,260 --> 00:20:33,780
No we give them we give them backups

00:20:31,010 --> 00:20:36,780
what I'd like to do and actually I wish

00:20:33,780 --> 00:20:38,220
I would had I meant to put that in was

00:20:36,780 --> 00:20:41,280
basically kind of the interaction

00:20:38,220 --> 00:20:42,900
between paper mill and commuter so

00:20:41,280 --> 00:20:44,070
commuter we're kind of we're planning

00:20:42,900 --> 00:20:46,020
out a publishing API

00:20:44,070 --> 00:20:48,450
that'll effectively give them version

00:20:46,020 --> 00:20:50,910
control it'll probably just be on s3

00:20:48,450 --> 00:20:52,380
though and it'll be a linear history

00:20:50,910 --> 00:20:54,150
because I don't want it I don't want to

00:20:52,380 --> 00:20:55,290
force anyone to have to do rebase is I

00:20:54,150 --> 00:20:57,210
want them to just be able to have

00:20:55,290 --> 00:21:00,900
versions that can go through and kind of

00:20:57,210 --> 00:21:03,210
like work from but as far as version

00:21:00,900 --> 00:21:05,910
controlling a notebook it's just gets

00:21:03,210 --> 00:21:07,440
really messy especially if you're not if

00:21:05,910 --> 00:21:09,570
they don't have hands on so we prefer

00:21:07,440 --> 00:21:12,390
that people figure that out on their own

00:21:09,570 --> 00:21:14,880
for what they want to do I've had at

00:21:12,390 --> 00:21:16,170
least one person burn themselves I mean

00:21:14,880 --> 00:21:17,400
there's there's been more but I mean

00:21:16,170 --> 00:21:21,830
recently there was someone that burnt

00:21:17,400 --> 00:21:23,940
themselves and I was able to pull their

00:21:21,830 --> 00:21:26,250
the notebook that they accidentally

00:21:23,940 --> 00:21:28,470
wrote over from the checkpoints and if I

00:21:26,250 --> 00:21:33,500
had to or we make regular backups of the

00:21:28,470 --> 00:21:33,500
ef-s volume but yeah

00:21:38,600 --> 00:21:42,590
I've done definitely

00:22:06,040 --> 00:22:14,660
there so the question is so the question

00:22:12,350 --> 00:22:16,250
is how how did how do people production

00:22:14,660 --> 00:22:19,160
alized their code and what are they

00:22:16,250 --> 00:22:21,890
doing for that and when I said yes it

00:22:19,160 --> 00:22:26,150
was it is it is kind of a gray area and

00:22:21,890 --> 00:22:27,920
that some people are like there there

00:22:26,150 --> 00:22:29,390
are jobs that you know just just regular

00:22:27,920 --> 00:22:32,990
submitted jobs that go through you see

00:22:29,390 --> 00:22:35,030
four and then some people are literally

00:22:32,990 --> 00:22:37,160
running them on docker we have a we have

00:22:35,030 --> 00:22:40,580
an entire set up just for for running

00:22:37,160 --> 00:22:42,110
batch jobs and people will build from

00:22:40,580 --> 00:22:42,980
the the big data image and then that's

00:22:42,110 --> 00:22:45,710
where they're actually running their

00:22:42,980 --> 00:22:47,750
jobs on and then people that are running

00:22:45,710 --> 00:22:51,400
full servers I mean they would do the

00:22:47,750 --> 00:22:51,400
same thing but with but with docker

00:22:57,010 --> 00:23:05,950
oh so we do link outs to commuter and

00:23:04,270 --> 00:23:08,290
the other step we do if we have several

00:23:05,950 --> 00:23:10,900
MB extensions that are all internal but

00:23:08,290 --> 00:23:13,780
it's more like they're internal only

00:23:10,900 --> 00:23:17,500
because they understand like where our

00:23:13,780 --> 00:23:19,240
data is located and other things but

00:23:17,500 --> 00:23:20,740
most stuff we're actually we pull in a

00:23:19,240 --> 00:23:22,960
bunch of extensions that are public -

00:23:20,740 --> 00:23:28,290
including the hiding of cells hiding of

00:23:22,960 --> 00:23:31,290
hiding of inputs hiding of outputs yeah

00:23:28,290 --> 00:23:31,290
question

00:23:37,530 --> 00:23:39,980
or

00:23:40,910 --> 00:23:48,870
so the it has the kinds of trade-offs if

00:23:46,830 --> 00:23:51,240
you're dealing with like free hosting

00:23:48,870 --> 00:23:52,890
where you're on Heroku versus where

00:23:51,240 --> 00:23:54,870
you're running where you have like a

00:23:52,890 --> 00:23:57,420
beef your machine but still like a

00:23:54,870 --> 00:23:59,520
managed platform for you I use both and

00:23:57,420 --> 00:24:01,560
a lot of users use both like it's faster

00:23:59,520 --> 00:24:04,590
to get to the shared the shared instance

00:24:01,560 --> 00:24:06,510
one I mean but like with with that ease

00:24:04,590 --> 00:24:09,000
of access it's also the the one with the

00:24:06,510 --> 00:24:10,860
least amount of resources and when

00:24:09,000 --> 00:24:12,900
people need more they just go spin up

00:24:10,860 --> 00:24:14,400
the one that I mean it's literally

00:24:12,900 --> 00:24:16,170
clicking a button I mean like they don't

00:24:14,400 --> 00:24:17,250
have to go through they just go to to go

00:24:16,170 --> 00:24:20,370
to a report all and they say oh yeah

00:24:17,250 --> 00:24:23,330
start my notebook server and so all

00:24:20,370 --> 00:24:23,330
that's integrated for them

00:24:33,309 --> 00:24:45,580
started repeat that one again have you

00:24:39,730 --> 00:24:47,679
managed projects oh so people posted

00:24:45,580 --> 00:24:48,820
note so their code goes to stash right

00:24:47,679 --> 00:24:51,370
it's up to them whether they're working

00:24:48,820 --> 00:24:55,480
on get arbor stash or if they have some

00:24:51,370 --> 00:24:57,700
other process but generally like the DFS

00:24:55,480 --> 00:24:59,230
volume is there for them we we manage it

00:24:57,700 --> 00:25:03,039
and monitor it but for the most part

00:24:59,230 --> 00:25:04,270
it's like their own sandbox sorry that

00:25:03,039 --> 00:25:07,330
the question itself is like how do

00:25:04,270 --> 00:25:10,260
people manage projects but it's it's

00:25:07,330 --> 00:25:10,260
kind of Wild West

00:25:25,930 --> 00:25:30,290
so people but so the question is is

00:25:28,820 --> 00:25:34,960
paper mills something you just use

00:25:30,290 --> 00:25:34,960
yourself or it's the way you put it was

00:25:49,750 --> 00:25:54,680
I guess I haven't even thought through

00:25:52,340 --> 00:25:56,960
that part but I mean generally paper

00:25:54,680 --> 00:26:01,100
mill is it's it's just a client so it

00:25:56,960 --> 00:26:03,170
literally runs runs a notebook outputs a

00:26:01,100 --> 00:26:04,850
notebook so how people want it I like it

00:26:03,170 --> 00:26:07,310
because it just pulls from a file

00:26:04,850 --> 00:26:09,560
whether it's a local file or on s3 and

00:26:07,310 --> 00:26:11,840
then writes out to another file whether

00:26:09,560 --> 00:26:16,990
it's local or s3 and it could do it in

00:26:11,840 --> 00:26:16,990
place so it's it's open-ended

00:26:32,549 --> 00:26:38,539
yeah so it so the question is like what

00:26:35,339 --> 00:26:43,830
why are we using EFS and not just EBS

00:26:38,539 --> 00:26:45,389
but is that fair the question we were we

00:26:43,830 --> 00:26:51,869
were some time ago just using EBS and

00:26:45,389 --> 00:26:53,129
then backing up their files to s3 the FS

00:26:51,869 --> 00:26:55,379
has actually been really easy to work

00:26:53,129 --> 00:26:56,909
with I think I was a naysayer on EFS

00:26:55,379 --> 00:26:59,759
like maybe a year and a half or two

00:26:56,909 --> 00:27:01,169
years ago but I'm pretty happy with it

00:26:59,759 --> 00:27:03,989
now

00:27:01,169 --> 00:27:05,549
and big date so they do have the the

00:27:03,989 --> 00:27:08,009
separate machines problem is the main

00:27:05,549 --> 00:27:16,709
one that this solves because there's

00:27:08,009 --> 00:27:19,440
actually a third tier right and and so

00:27:16,709 --> 00:27:21,089
they run jobs too and the jobs too can

00:27:19,440 --> 00:27:23,099
mount EFS and so if you want to have

00:27:21,089 --> 00:27:25,169
access to those files I mean I thought

00:27:23,099 --> 00:27:27,059
everybody would be fully cloudy and

00:27:25,169 --> 00:27:29,009
they'd pull everything up off of s3 and

00:27:27,059 --> 00:27:31,559
stage it locally to slash data but the

00:27:29,009 --> 00:27:34,669
reality is people make messy things and

00:27:31,559 --> 00:27:34,669
they want to use them right there

00:27:45,870 --> 00:27:58,190
we're using a s3 sink now what else

00:28:00,110 --> 00:28:02,170
Oh

00:28:27,600 --> 00:28:30,900
so the question was and have I seen

00:28:29,760 --> 00:28:36,080
people doing things that really

00:28:30,900 --> 00:28:36,080
surprised me within the notebooks I

00:28:36,620 --> 00:28:42,720
never every time somebody creates

00:28:39,240 --> 00:28:45,300
something custom with widgets it's in

00:28:42,720 --> 00:28:48,600
and generally like anything built in the

00:28:45,300 --> 00:28:50,130
notebook it's like it finally clicked

00:28:48,600 --> 00:28:53,670
for me that if you have a running

00:28:50,130 --> 00:28:56,610
notebook server people basically get to

00:28:53,670 --> 00:28:58,320
treat it like a web server where they

00:28:56,610 --> 00:29:00,450
don't have to manage any operations

00:28:58,320 --> 00:29:02,100
because we're managing it for them and

00:29:00,450 --> 00:29:03,570
so they get this platform as a service

00:29:02,100 --> 00:29:04,770
that's effectively the notebook they

00:29:03,570 --> 00:29:06,390
really only have to know how to work in

00:29:04,770 --> 00:29:09,090
the notebook but now they have this

00:29:06,390 --> 00:29:12,510
beautiful thing that can run dynamic

00:29:09,090 --> 00:29:14,190
custom code and then they share the the

00:29:12,510 --> 00:29:16,830
URLs for those and people just run them

00:29:14,190 --> 00:29:19,470
and I was like oh okay I guess that I

00:29:16,830 --> 00:29:20,370
mean that is a selling point and it

00:29:19,470 --> 00:29:22,710
means you know they don't have to hire

00:29:20,370 --> 00:29:25,230
some team where they go get to front-end

00:29:22,710 --> 00:29:27,030
engineers and you know a bunch of Ops

00:29:25,230 --> 00:29:28,530
people just to manage like this one

00:29:27,030 --> 00:29:30,840
thing for a query that's probably going

00:29:28,530 --> 00:29:33,180
to change later and then you know they

00:29:30,840 --> 00:29:35,730
like deprecated that and so now there's

00:29:33,180 --> 00:29:37,380
this like this quick on-ramp to to run

00:29:35,730 --> 00:29:42,170
stuff and then treat that like it's its

00:29:37,380 --> 00:29:42,170
own its own little setup

00:29:47,330 --> 00:29:57,830
I'm gonna give it in a percentage it's

00:29:51,570 --> 00:29:57,830
like 30% of people are Netflix

00:30:01,040 --> 00:30:10,370
that number could be way wrong now 30%

00:30:08,090 --> 00:30:13,370
of employees I would be it would be

00:30:10,370 --> 00:30:30,250
great if Netflix users it was 30% of

00:30:13,370 --> 00:30:33,050
those a pretty much every single

00:30:30,250 --> 00:30:38,900
business area whether it's marketing or

00:30:33,050 --> 00:30:41,630
security or or content or messaging is

00:30:38,900 --> 00:30:44,300
has data scientists on it like Netflix

00:30:41,630 --> 00:30:47,330
is data all the way through I infer from

00:30:44,300 --> 00:30:50,090
it's very beginning to now and I

00:30:47,330 --> 00:30:52,160
remember when I was a mathematician

00:30:50,090 --> 00:30:54,010
thinking of Netflix with high honors

00:30:52,160 --> 00:30:58,010
because of the the Netflix

00:30:54,010 --> 00:31:00,800
million-dollar challenge and and that

00:30:58,010 --> 00:31:02,180
that culture hasn't hasn't stopped I'm

00:31:00,800 --> 00:31:05,330
not gonna give any specifics but at the

00:31:02,180 --> 00:31:07,910
very least like literally every orgasm I

00:31:05,330 --> 00:31:09,770
data and there are plenty of like

00:31:07,910 --> 00:31:12,160
everyone sharing and trying to figure

00:31:09,770 --> 00:31:12,160
things out

00:31:16,770 --> 00:31:23,460
all right I hung up my badge and said

00:31:19,770 --> 00:31:24,960
I'm done the question was if I if since

00:31:23,460 --> 00:31:31,070
I was a mathematician if they like

00:31:24,960 --> 00:31:31,070
stripped me of it yeah yeah I don't know

00:31:35,660 --> 00:31:40,320
how do we manage entitlements and

00:31:38,370 --> 00:31:42,120
sharing of notebooks all the notebooks

00:31:40,320 --> 00:31:46,410
are public and accessible to everyone

00:31:42,120 --> 00:31:48,000
who is logged in at Netflix Netflix

00:31:46,410 --> 00:31:50,130
generally has a culture of wanting to

00:31:48,000 --> 00:31:53,040
share information with others like

00:31:50,130 --> 00:31:55,530
within the company so what we have an

00:31:53,040 --> 00:31:59,090
audit trail generally speaking one

00:31:55,530 --> 00:31:59,090
everybody to to be able to work together

00:32:05,220 --> 00:32:09,820
yet so in inside the contained so the

00:32:08,380 --> 00:32:14,350
question was what does the user run as

00:32:09,820 --> 00:32:34,300
inside of the inside of a container and

00:32:14,350 --> 00:32:35,800
they were on his route yeah we hope that

00:32:34,300 --> 00:32:42,160
people aren't doing that so how do you

00:32:35,800 --> 00:32:47,860
manage secrets within the notebook oh oh

00:32:42,160 --> 00:32:51,880
oh no so so so sensitive data is is not

00:32:47,860 --> 00:32:54,100
over there or at least so we we are

00:32:51,880 --> 00:32:55,810
watching what what's going on

00:32:54,100 --> 00:32:57,940
with data and like who's accessing it

00:32:55,810 --> 00:32:58,960
and whatnot and then we'll we'll clean

00:32:57,940 --> 00:33:00,060
up stuff

00:32:58,960 --> 00:33:02,050
[Music]

00:33:00,060 --> 00:33:03,610
generally it's frowned upon to have

00:33:02,050 --> 00:33:05,440
secrets people are gonna leak them no

00:33:03,610 --> 00:33:07,750
matter what

00:33:05,440 --> 00:33:10,480
like developers will leak things all the

00:33:07,750 --> 00:33:13,680
time just in general not just data

00:33:10,480 --> 00:33:16,510
scientists everyone does it

00:33:13,680 --> 00:33:17,770
I'm using and this is like general stuff

00:33:16,510 --> 00:33:19,630
enough for Netflix I usually tell people

00:33:17,770 --> 00:33:22,000
to use environment variables but with

00:33:19,630 --> 00:33:24,010
the notebook but the other the other

00:33:22,000 --> 00:33:26,380
reality is that you might have so like

00:33:24,010 --> 00:33:28,480
we actually have an internal store that

00:33:26,380 --> 00:33:30,040
you can get access to stuff most of the

00:33:28,480 --> 00:33:31,720
time you don't need secrets because we

00:33:30,040 --> 00:33:33,880
give the each of the containers as an

00:33:31,720 --> 00:33:36,120
iamb role which has access to the data

00:33:33,880 --> 00:33:38,230
that they need and so they shouldn't be

00:33:36,120 --> 00:33:45,280
explicitly using secrets so they'll end

00:33:38,230 --> 00:33:46,960
up in code yes yeah

00:33:45,280 --> 00:33:48,580
and so when I say it runs this route of

00:33:46,960 --> 00:33:50,080
course it's not really it's that user

00:33:48,580 --> 00:33:54,270
but they have route but within the

00:33:50,080 --> 00:33:57,270
container yeah that's it

00:33:54,270 --> 00:33:57,270
cool

00:33:59,150 --> 00:34:19,260
please come to the Sprint's on Saturday

00:34:01,530 --> 00:34:22,070
we can work on anything in Jupiter in

00:34:19,260 --> 00:34:22,070
the building from

00:34:24,870 --> 00:34:29,120

YouTube URL: https://www.youtube.com/watch?v=X77lvsv6h98


