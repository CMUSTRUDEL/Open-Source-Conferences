Title: Data Science Platforms: Your Key to Actionable Analytics - William Merchan (DataScience.com)
Publication date: 2017-11-08
Playlist: JupyterCon
Description: 
	Explores the key components of a data science platform and explains how they are enabling organizations to realize the potential of their data science teams.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,630 --> 00:00:05,980
today what we're gonna cover is really

00:00:04,840 --> 00:00:09,879
what we've seen in working with

00:00:05,980 --> 00:00:13,629
different organizations both public and

00:00:09,879 --> 00:00:16,150
private in what are some best practices

00:00:13,629 --> 00:00:19,029
and organizing teams and things that

00:00:16,150 --> 00:00:22,090
they're doing to get an edge and grow

00:00:19,029 --> 00:00:23,710
their teams and improve the performance

00:00:22,090 --> 00:00:25,210
of what they're doing related to data

00:00:23,710 --> 00:00:29,470
science so that's really what we'll

00:00:25,210 --> 00:00:32,439
cover today my background I've been in

00:00:29,470 --> 00:00:35,079
the analytics and big data space for a

00:00:32,439 --> 00:00:37,300
while so I keep following the 10 10 plus

00:00:35,079 --> 00:00:41,379
year category but maybe not as a data

00:00:37,300 --> 00:00:44,890
scientist my early experience is working

00:00:41,379 --> 00:00:48,430
with data science were you know working

00:00:44,890 --> 00:00:52,059
in R and working with a team at Yahoo

00:00:48,430 --> 00:00:53,859
that built out Hadoop so that was a fun

00:00:52,059 --> 00:00:58,930
experience to see that from the ground

00:00:53,859 --> 00:01:01,480
floor and finding use cases for data

00:00:58,930 --> 00:01:04,239
sets and building models with data that

00:01:01,480 --> 00:01:06,909
weren't possible before until hadoop was

00:01:04,239 --> 00:01:09,130
invented so it was really really cool to

00:01:06,909 --> 00:01:12,479
be a part of that fast forwarding to

00:01:09,130 --> 00:01:17,130
where we are today so data science comm

00:01:12,479 --> 00:01:19,479
the the company was focused on building

00:01:17,130 --> 00:01:21,850
data science models and doing data

00:01:19,479 --> 00:01:25,060
science work for companies that we

00:01:21,850 --> 00:01:26,619
partnered with the goal of doing that

00:01:25,060 --> 00:01:30,520
for us was we really wanted to

00:01:26,619 --> 00:01:32,649
understand what was happening in the

00:01:30,520 --> 00:01:36,070
sector how people were building models

00:01:32,649 --> 00:01:39,100
what were some of the pain points we had

00:01:36,070 --> 00:01:42,399
built the team we grew from a team of

00:01:39,100 --> 00:01:45,460
zero to a team of 50 very quickly and

00:01:42,399 --> 00:01:47,170
these are all hands-on data scientists

00:01:45,460 --> 00:01:49,719
that were building models delivering

00:01:47,170 --> 00:01:52,950
outputs for customers and as we were

00:01:49,719 --> 00:01:56,380
going through that scaling process our

00:01:52,950 --> 00:01:58,509
engineering and product teams said hey

00:01:56,380 --> 00:02:02,170
we've got to fix this because things

00:01:58,509 --> 00:02:05,520
aren't working well people are redoing

00:02:02,170 --> 00:02:08,170
work that's already been created they're

00:02:05,520 --> 00:02:10,180
conflicting their code check-ins they're

00:02:08,170 --> 00:02:11,950
delivering outputs that sometimes aren't

00:02:10,180 --> 00:02:15,430
scaling the way that we expect them to

00:02:11,950 --> 00:02:18,340
scale so we took a step back and said

00:02:15,430 --> 00:02:19,689
how can we fix this we kind of canvassed

00:02:18,340 --> 00:02:21,819
what was out there in the landscape

00:02:19,689 --> 00:02:23,409
looked at all the existing tools looked

00:02:21,819 --> 00:02:27,519
at what was there in the open source

00:02:23,409 --> 00:02:30,730
world and nothing really was a fit for

00:02:27,519 --> 00:02:34,090
what we needed so our our teams the data

00:02:30,730 --> 00:02:36,370
scientists they had very specific needs

00:02:34,090 --> 00:02:40,060
that they were looking for they wanted a

00:02:36,370 --> 00:02:41,500
sort of open source to be built in the

00:02:40,060 --> 00:02:44,769
system from the ground up they didn't

00:02:41,500 --> 00:02:48,069
want to work with a closed-off system or

00:02:44,769 --> 00:02:50,590
something proprietary they had their

00:02:48,069 --> 00:02:52,720
preferred ways of doing work and they

00:02:50,590 --> 00:02:56,079
didn't want to have to completely swap

00:02:52,720 --> 00:02:57,900
everything out for something new so what

00:02:56,079 --> 00:03:01,090
we did is we we built our own platform

00:02:57,900 --> 00:03:03,040
we built it to support that team of data

00:03:01,090 --> 00:03:04,000
scientists working hand-in-hand with

00:03:03,040 --> 00:03:05,799
them our engineering

00:03:04,000 --> 00:03:08,739
engineers partnered closely with them

00:03:05,799 --> 00:03:10,719
and then we brought it to market so we

00:03:08,739 --> 00:03:14,500
we launched the platform about a year

00:03:10,719 --> 00:03:17,139
ago and we've been bringing to market

00:03:14,500 --> 00:03:19,479
and getting feedback from organizations

00:03:17,139 --> 00:03:20,949
that are now using it and what we'll

00:03:19,479 --> 00:03:23,290
cover is some of that feedback and what

00:03:20,949 --> 00:03:25,269
we've been seeing in terms of how teams

00:03:23,290 --> 00:03:30,099
are organizing the work and the things

00:03:25,269 --> 00:03:31,810
that they're doing to get success and I

00:03:30,099 --> 00:03:35,680
think one of the the things that we've

00:03:31,810 --> 00:03:37,689
seen is you know the way that companies

00:03:35,680 --> 00:03:40,329
and organizations are doing data science

00:03:37,689 --> 00:03:43,479
work has really changed a lot and you

00:03:40,329 --> 00:03:48,269
know you've looked back five years ago

00:03:43,479 --> 00:03:51,579
ten years ago data science was typically

00:03:48,269 --> 00:03:54,609
R&D function that was kind of off to the

00:03:51,579 --> 00:03:57,069
side doing analysis producing an output

00:03:54,609 --> 00:03:58,930
based on you know inbound requests from

00:03:57,069 --> 00:04:01,750
various stakeholders in the organization

00:03:58,930 --> 00:04:04,449
and I think now what we're seeing is

00:04:01,750 --> 00:04:06,699
that the the role of the data scientists

00:04:04,449 --> 00:04:09,459
has evolved pretty dramatically and it's

00:04:06,699 --> 00:04:12,340
you know continuing to evolve into being

00:04:09,459 --> 00:04:14,919
a very close partner with whoever the

00:04:12,340 --> 00:04:16,780
consumers are of the output so whether

00:04:14,919 --> 00:04:19,810
that be product or one of the business

00:04:16,780 --> 00:04:24,789
units and I think with that there's this

00:04:19,810 --> 00:04:27,389
need to bring data science work into the

00:04:24,789 --> 00:04:29,230
kind of conversation with these teams

00:04:27,389 --> 00:04:32,320
expose it to them

00:04:29,230 --> 00:04:34,690
than what's happening and give clarity

00:04:32,320 --> 00:04:36,490
into you know where where are we in the

00:04:34,690 --> 00:04:38,140
development process and share that with

00:04:36,490 --> 00:04:41,920
the various stakeholders that might be

00:04:38,140 --> 00:04:46,330
working in the organization and it's

00:04:41,920 --> 00:04:48,040
it's not a function that doesn't exist

00:04:46,330 --> 00:04:49,900
anymore in every industry so I think

00:04:48,040 --> 00:04:50,260
what we're seeing is that across the

00:04:49,900 --> 00:04:53,440
board

00:04:50,260 --> 00:04:56,050
deena companies large and small data

00:04:53,440 --> 00:04:58,360
science is playing a role and you know

00:04:56,050 --> 00:05:00,700
it may go by a different name depending

00:04:58,360 --> 00:05:04,090
on industry so you may be an actuary you

00:05:00,700 --> 00:05:06,370
may be a machine learning engineer at a

00:05:04,090 --> 00:05:09,280
company but in the end what you're doing

00:05:06,370 --> 00:05:11,880
is you're building a a model to support

00:05:09,280 --> 00:05:14,770
a use case for a customer facing

00:05:11,880 --> 00:05:17,040
application or interaction and we're

00:05:14,770 --> 00:05:21,250
seeing this happen in every industry so

00:05:17,040 --> 00:05:22,960
we're seeing it in government entities

00:05:21,250 --> 00:05:25,870
we're seeing it in startups we're seeing

00:05:22,960 --> 00:05:28,120
it in traditional industries that you

00:05:25,870 --> 00:05:32,260
know are looking for ways to automate

00:05:28,120 --> 00:05:34,510
tasks that may be historically were done

00:05:32,260 --> 00:05:36,520
through manual intervention or you know

00:05:34,510 --> 00:05:40,480
custom coding that might have been

00:05:36,520 --> 00:05:44,860
developed and this idea that you know

00:05:40,480 --> 00:05:46,000
data science is central this is really I

00:05:44,860 --> 00:05:48,730
think kourt's sort of where we're at

00:05:46,000 --> 00:05:52,870
today which is if you think about any

00:05:48,730 --> 00:05:55,390
function in an organization data science

00:05:52,870 --> 00:05:59,650
is no longer off to the side it's really

00:05:55,390 --> 00:06:01,150
helping them perform better and it's you

00:05:59,650 --> 00:06:03,280
know depending on the industry and what

00:06:01,150 --> 00:06:05,320
group you're supporting it's doing it in

00:06:03,280 --> 00:06:08,530
different ways in some cases it might be

00:06:05,320 --> 00:06:11,320
you know the core output of that team is

00:06:08,530 --> 00:06:13,480
now directly influenced by data science

00:06:11,320 --> 00:06:15,940
so you think of you know security and

00:06:13,480 --> 00:06:18,040
fraud detection use cases I mean that's

00:06:15,940 --> 00:06:19,900
a large part what the security team does

00:06:18,040 --> 00:06:22,330
it's like hey let's find where there's

00:06:19,900 --> 00:06:24,430
issues on the marketing side it's okay

00:06:22,330 --> 00:06:27,220
who are most valuable customers and how

00:06:24,430 --> 00:06:29,440
do we interact with them and that

00:06:27,220 --> 00:06:31,780
doesn't happen today without data

00:06:29,440 --> 00:06:36,600
science teams being directly involved in

00:06:31,780 --> 00:06:36,600
the development of how that's executed

00:06:36,780 --> 00:06:41,290
there are issues that I think it's not

00:06:39,160 --> 00:06:42,950
it's not solved yet you know there's the

00:06:41,290 --> 00:06:44,900
industry and the role

00:06:42,950 --> 00:06:47,870
and how people are applying data science

00:06:44,900 --> 00:06:50,780
is still evolving we've worked closely

00:06:47,870 --> 00:06:53,000
with Forrester to understand you know

00:06:50,780 --> 00:06:55,790
how our organizations using data science

00:06:53,000 --> 00:06:58,130
how are they measuring value out of it

00:06:55,790 --> 00:07:00,200
and you know I think probably not not

00:06:58,130 --> 00:07:03,950
surprising for anyone in this room that

00:07:00,200 --> 00:07:06,560
pretty much every company thinks data

00:07:03,950 --> 00:07:11,300
science is a valuable discipline to

00:07:06,560 --> 00:07:13,600
develop but there's this gap 22% can

00:07:11,300 --> 00:07:18,200
directly tie their data science work to

00:07:13,600 --> 00:07:19,940
business value and this gap is really I

00:07:18,200 --> 00:07:21,710
think what a lot of us in the room are

00:07:19,940 --> 00:07:26,000
here to solve well you know one way or

00:07:21,710 --> 00:07:29,390
the other right so I think closing that

00:07:26,000 --> 00:07:31,790
gap is gonna benefit everybody so you

00:07:29,390 --> 00:07:34,520
know how do we make sure that the work

00:07:31,790 --> 00:07:37,640
that a data science team is directly

00:07:34,520 --> 00:07:39,200
translated to business value you know

00:07:37,640 --> 00:07:41,930
all the stakeholders understand how to

00:07:39,200 --> 00:07:43,670
measure it everyone's aligned on what

00:07:41,930 --> 00:07:47,260
the expectations are for the work that's

00:07:43,670 --> 00:07:47,260
being produced by the data science team

00:07:49,600 --> 00:07:54,800
that's a that's a very good question

00:07:51,970 --> 00:07:59,060
yeah so the question was why does that

00:07:54,800 --> 00:08:01,100
gap exist I think this is actually one

00:07:59,060 --> 00:08:03,410
of the main reasons why this gap exists

00:08:01,100 --> 00:08:04,880
it's not the only reason but if you

00:08:03,410 --> 00:08:08,870
think about you know what does it really

00:08:04,880 --> 00:08:11,900
take to do a proper data science

00:08:08,870 --> 00:08:15,020
workflow and a modern organization and

00:08:11,900 --> 00:08:16,790
you know these are typically larger

00:08:15,020 --> 00:08:19,700
organizations that can afford to build

00:08:16,790 --> 00:08:22,400
out a data science team there are a lot

00:08:19,700 --> 00:08:24,200
of stakeholders so you have people on

00:08:22,400 --> 00:08:26,570
the business side that are asking

00:08:24,200 --> 00:08:28,280
questions and defining you know what is

00:08:26,570 --> 00:08:30,890
the problem that we're working on how

00:08:28,280 --> 00:08:32,930
are we going to solve issues in the

00:08:30,890 --> 00:08:36,140
business on the cost or profitability or

00:08:32,930 --> 00:08:37,660
customer service side you have the data

00:08:36,140 --> 00:08:40,610
scientists the person that's actually

00:08:37,660 --> 00:08:42,910
building the model and is responsible

00:08:40,610 --> 00:08:46,280
for developing the code that goes into

00:08:42,910 --> 00:08:48,380
the production system you have data

00:08:46,280 --> 00:08:50,990
engineers so these are the folks that

00:08:48,380 --> 00:08:53,360
are typically getting the data ready for

00:08:50,990 --> 00:08:55,400
the data scientist making sure that you

00:08:53,360 --> 00:08:56,660
know systems are in place to capture the

00:08:55,400 --> 00:08:59,030
data that

00:08:56,660 --> 00:09:01,150
going to be used down the road by a V

00:08:59,030 --> 00:09:03,710
data scientists and then you have

00:09:01,150 --> 00:09:05,510
systems engineers and that you know list

00:09:03,710 --> 00:09:08,000
could go on but you know these are folks

00:09:05,510 --> 00:09:10,460
that are making sure that the

00:09:08,000 --> 00:09:12,380
infrastructure is working properly the

00:09:10,460 --> 00:09:14,330
production systems are performing as

00:09:12,380 --> 00:09:17,270
expected

00:09:14,330 --> 00:09:19,430
if you zoom out from that you have these

00:09:17,270 --> 00:09:22,640
human interactions which you know in

00:09:19,430 --> 00:09:24,830
some cases create roadblocks like well

00:09:22,640 --> 00:09:26,510
you know did the definition of what the

00:09:24,830 --> 00:09:28,580
business stakeholder is trying to solve

00:09:26,510 --> 00:09:32,110
get translated properly to the data

00:09:28,580 --> 00:09:35,090
scientists when the data engineer

00:09:32,110 --> 00:09:38,330
envisioned their data platform or their

00:09:35,090 --> 00:09:40,490
data Lake how did they understand the

00:09:38,330 --> 00:09:41,960
use case of the data scientist and they

00:09:40,490 --> 00:09:44,630
did they build something that actually

00:09:41,960 --> 00:09:48,440
fits with what a data scientist needs to

00:09:44,630 --> 00:09:52,160
actually build the models the tools that

00:09:48,440 --> 00:09:53,390
data scientists use you know many of us

00:09:52,160 --> 00:09:57,380
in the room are very familiar with

00:09:53,390 --> 00:10:00,110
probably all of these a lot of them are

00:09:57,380 --> 00:10:02,360
not oriented to a group setting and

00:10:00,110 --> 00:10:03,880
they're typically not oriented to an

00:10:02,360 --> 00:10:06,890
enterprise setting where you might have

00:10:03,880 --> 00:10:09,890
you know security restrictions or data

00:10:06,890 --> 00:10:11,840
restrictions and what we're finding is

00:10:09,890 --> 00:10:14,060
that there's these you know

00:10:11,840 --> 00:10:16,220
opportunities to improve how you're

00:10:14,060 --> 00:10:18,020
interfacing with data how you're

00:10:16,220 --> 00:10:20,780
defining the environments that these

00:10:18,020 --> 00:10:22,610
data scientists are working in when the

00:10:20,780 --> 00:10:24,440
model is actually done and it's it's

00:10:22,610 --> 00:10:26,900
sort of signed off on how do you

00:10:24,440 --> 00:10:29,300
actually take that model and move it to

00:10:26,900 --> 00:10:31,790
the next step into the production system

00:10:29,300 --> 00:10:34,460
how do you deploy it how do you do that

00:10:31,790 --> 00:10:36,650
in a repeatable way how do you track

00:10:34,460 --> 00:10:39,470
those results how do you understand the

00:10:36,650 --> 00:10:41,840
history of that model who developed it

00:10:39,470 --> 00:10:43,520
what data went into it what version are

00:10:41,840 --> 00:10:46,640
we on which ones performing better than

00:10:43,520 --> 00:10:48,620
the other and all of this needs to be

00:10:46,640 --> 00:10:51,320
collaborative right this you know this

00:10:48,620 --> 00:10:53,750
idea that you can build it in the dark

00:10:51,320 --> 00:10:55,520
and show up with a model or you know

00:10:53,750 --> 00:10:59,270
click a button and you're gonna produce

00:10:55,520 --> 00:11:01,790
a model I think is flawed in many ways I

00:10:59,270 --> 00:11:03,730
think the the organizations that we've

00:11:01,790 --> 00:11:07,520
talked to and that we've worked with

00:11:03,730 --> 00:11:09,470
there needs to be a transparency in the

00:11:07,520 --> 00:11:10,470
model development process there needs to

00:11:09,470 --> 00:11:14,040
be

00:11:10,470 --> 00:11:16,199
open you know frank discussion on how

00:11:14,040 --> 00:11:18,269
did we get to the answer and what are

00:11:16,199 --> 00:11:19,860
the implications of the answer when the

00:11:18,269 --> 00:11:21,420
model is being built so everyone's on

00:11:19,860 --> 00:11:24,149
the same page when the model is

00:11:21,420 --> 00:11:25,889
performing and it's in production to

00:11:24,149 --> 00:11:28,139
understand why it's performing one way

00:11:25,889 --> 00:11:30,869
or the other so I think that's one of

00:11:28,139 --> 00:11:32,639
the the areas of opportunity in terms of

00:11:30,869 --> 00:11:36,509
closing the gap is how do you streamline

00:11:32,639 --> 00:11:38,639
that process what we're seeing is that

00:11:36,509 --> 00:11:43,499
you know there's no no slowing in the

00:11:38,639 --> 00:11:45,239
the drive and growth of open source it's

00:11:43,499 --> 00:11:48,449
across the board it's you know it's

00:11:45,239 --> 00:11:51,509
Python it's our and I think that this

00:11:48,449 --> 00:11:53,910
pace of innovation continues to increase

00:11:51,509 --> 00:11:56,519
you think about you know the the

00:11:53,910 --> 00:11:59,879
contributions of companies like Google

00:11:56,519 --> 00:12:03,209
and others that have you know brought in

00:11:59,879 --> 00:12:05,040
some of these you know core packages to

00:12:03,209 --> 00:12:06,720
the community and it's really driving

00:12:05,040 --> 00:12:09,509
and speeding up that pace of innovation

00:12:06,720 --> 00:12:11,369
and I think the really interesting thing

00:12:09,509 --> 00:12:12,869
that that's happening now and it's you

00:12:11,369 --> 00:12:16,049
know it's been happening for a while is

00:12:12,869 --> 00:12:18,029
this collaboration so you have you know

00:12:16,049 --> 00:12:20,519
public sector private sector companies

00:12:18,029 --> 00:12:23,879
coming together I'm sure you know a lot

00:12:20,519 --> 00:12:26,369
of the folks saw the posters last night

00:12:23,879 --> 00:12:28,049
on some of these great innovations that

00:12:26,369 --> 00:12:30,660
are you know happening in this

00:12:28,049 --> 00:12:32,220
combination so you know we've been

00:12:30,660 --> 00:12:35,730
working with the National Science

00:12:32,220 --> 00:12:37,769
Foundation and understanding traffic

00:12:35,730 --> 00:12:40,170
fatalities and you know data around that

00:12:37,769 --> 00:12:43,079
and I think it's it's an opportunity to

00:12:40,170 --> 00:12:46,679
bring together groups for sort of a

00:12:43,079 --> 00:12:48,929
common good common goal and out of that

00:12:46,679 --> 00:12:50,970
comes innovation sort of new techniques

00:12:48,929 --> 00:12:52,949
that can down the road be applied to

00:12:50,970 --> 00:12:56,220
industry but also they can be applied in

00:12:52,949 --> 00:12:58,110
the public sector to improve everybody's

00:12:56,220 --> 00:13:01,139
lives so I think it's definitely an

00:12:58,110 --> 00:13:02,399
exciting time in the category and it's

00:13:01,139 --> 00:13:06,839
great to see the pace of innovation

00:13:02,399 --> 00:13:09,379
that's happening the the rise of Python

00:13:06,839 --> 00:13:13,799
is I'm sure many of you are aware is

00:13:09,379 --> 00:13:15,989
continuing if you look at you know what

00:13:13,799 --> 00:13:17,790
languages were were people using and

00:13:15,989 --> 00:13:19,379
what tools were they using just a few

00:13:17,790 --> 00:13:22,410
years ago

00:13:19,379 --> 00:13:26,819
- wasn't really on the radar

00:13:22,410 --> 00:13:30,629
and if you look at today it is a major

00:13:26,819 --> 00:13:32,100
force in the category so what we're

00:13:30,629 --> 00:13:34,259
seeing is that you know it's happening

00:13:32,100 --> 00:13:35,759
everywhere it's happening in university

00:13:34,259 --> 00:13:38,339
we were just chatting earlier it's

00:13:35,759 --> 00:13:40,379
happening in second and third grade in

00:13:38,339 --> 00:13:42,329
many cases where you know kids are

00:13:40,379 --> 00:13:45,149
learning Python and how to code at a

00:13:42,329 --> 00:13:47,970
very young age and I think that will

00:13:45,149 --> 00:13:51,600
just continue it's really exciting to

00:13:47,970 --> 00:13:55,680
see and you know I think in the end the

00:13:51,600 --> 00:13:58,050
the solution to how do you how do you

00:13:55,680 --> 00:13:59,639
get more value out of data science and

00:13:58,050 --> 00:14:03,029
how do you really apply these analytics

00:13:59,639 --> 00:14:06,149
to to get success it isn't just about

00:14:03,029 --> 00:14:09,689
more tools it's not about you know just

00:14:06,149 --> 00:14:11,370
finding the right Python package to

00:14:09,689 --> 00:14:16,079
solve some particular thing I think

00:14:11,370 --> 00:14:19,050
there's more more to it to that and you

00:14:16,079 --> 00:14:23,279
know we've seen data science platforms

00:14:19,050 --> 00:14:24,810
as being one way of doing that if you

00:14:23,279 --> 00:14:27,000
think of the definition of what a data

00:14:24,810 --> 00:14:30,750
science platform is it's not just tools

00:14:27,000 --> 00:14:34,110
it's really giving this entire lifecycle

00:14:30,750 --> 00:14:37,470
a place for the work to be done in a way

00:14:34,110 --> 00:14:39,269
that's open it's transparent it's

00:14:37,470 --> 00:14:43,199
collaborative and it handles that

00:14:39,269 --> 00:14:45,930
end-to-end process from data integration

00:14:43,199 --> 00:14:49,050
all the way through to model deployment

00:14:45,930 --> 00:14:50,639
and you know depending on what you're

00:14:49,050 --> 00:14:53,670
building for your organization

00:14:50,639 --> 00:14:56,430
the output of the model may actually

00:14:53,670 --> 00:14:59,370
just be feeding a dashboard for some and

00:14:56,430 --> 00:15:01,439
consumer if you think about some of the

00:14:59,370 --> 00:15:02,250
more sophisticated use cases it might be

00:15:01,439 --> 00:15:05,490
you know

00:15:02,250 --> 00:15:09,389
scoring data in real time on massive

00:15:05,490 --> 00:15:11,519
scale you know there's there's really a

00:15:09,389 --> 00:15:16,350
similar process that can be followed for

00:15:11,519 --> 00:15:17,880
either any of those use cases and what

00:15:16,350 --> 00:15:21,360
what can you do with it you know there's

00:15:17,880 --> 00:15:24,329
so much discussion and hype around some

00:15:21,360 --> 00:15:26,189
of these topics you know bless you deep

00:15:24,329 --> 00:15:27,889
learning artificial intelligence machine

00:15:26,189 --> 00:15:31,860
learning you know how do you actually

00:15:27,889 --> 00:15:33,899
start using those at an organization and

00:15:31,860 --> 00:15:35,900
you know I think when people start

00:15:33,899 --> 00:15:38,690
investigating these areas there's

00:15:35,900 --> 00:15:40,520
sort of prepackaged vertical

00:15:38,690 --> 00:15:42,260
applications that are doing things with

00:15:40,520 --> 00:15:45,680
each one of these technologies that are

00:15:42,260 --> 00:15:49,160
certainly there off the shelf as teams

00:15:45,680 --> 00:15:51,470
evolve and their data science

00:15:49,160 --> 00:15:54,200
sophistication grows what they're

00:15:51,470 --> 00:15:56,240
typically looking at is how do we take

00:15:54,200 --> 00:15:58,490
some of those capabilities and build

00:15:56,240 --> 00:16:02,150
them in-house and grow a team to support

00:15:58,490 --> 00:16:03,770
these use cases and you know that's when

00:16:02,150 --> 00:16:06,200
you start running into some of these

00:16:03,770 --> 00:16:09,460
roadblocks so you know how do you get a

00:16:06,200 --> 00:16:13,100
a particular package to work

00:16:09,460 --> 00:16:15,650
consistently across the team how do you

00:16:13,100 --> 00:16:17,720
get a machine learning library to scale

00:16:15,650 --> 00:16:20,780
in the way that your team needs it to

00:16:17,720 --> 00:16:22,780
across a given data set and then how do

00:16:20,780 --> 00:16:26,500
you run the analysis in a way that's

00:16:22,780 --> 00:16:32,030
repeatable for the team and that's where

00:16:26,500 --> 00:16:34,640
a platform comes in and that that

00:16:32,030 --> 00:16:38,240
scaling so you if you if you grow from

00:16:34,640 --> 00:16:41,690
three or four data scientists to 50 or a

00:16:38,240 --> 00:16:46,550
couple hundred or thousands that's when

00:16:41,690 --> 00:16:49,580
you start to think about scale and scale

00:16:46,550 --> 00:16:51,920
is not as not just hey we have a large

00:16:49,580 --> 00:16:57,250
team now I think I think scale is really

00:16:51,920 --> 00:16:59,980
about how influential is data science in

00:16:57,250 --> 00:17:02,300
everything that your company does and

00:16:59,980 --> 00:17:04,339
it's a it's a you know it's kind of a

00:17:02,300 --> 00:17:07,310
different mindset you know this is the

00:17:04,339 --> 00:17:09,050
the mindset that you'll see if you look

00:17:07,310 --> 00:17:10,610
at what Google and Facebook and Amazon

00:17:09,050 --> 00:17:12,530
are doing but they're you know they're

00:17:10,610 --> 00:17:14,839
they're not alone right I think last

00:17:12,530 --> 00:17:17,030
night Bloomberg was sharing some of the

00:17:14,839 --> 00:17:22,360
good work that they're doing and it's

00:17:17,030 --> 00:17:26,030
having this DNA and this application of

00:17:22,360 --> 00:17:29,740
data science outputs and models that are

00:17:26,030 --> 00:17:33,560
developed to intersect and interact with

00:17:29,740 --> 00:17:35,240
all of the customer touch points all of

00:17:33,560 --> 00:17:40,010
the you know in some cases machine touch

00:17:35,240 --> 00:17:42,350
points and having it be a core part of

00:17:40,010 --> 00:17:44,690
the company's DNA so I think that's

00:17:42,350 --> 00:17:47,270
really what scale means to me it's okay

00:17:44,690 --> 00:17:49,280
you know the team is actually getting

00:17:47,270 --> 00:17:51,470
results and those results are being

00:17:49,280 --> 00:17:56,270
put in two systems that are influencing

00:17:51,470 --> 00:17:59,360
the business and when we we talk to

00:17:56,270 --> 00:18:02,330
teams some of these very high-performing

00:17:59,360 --> 00:18:05,780
teams some of the things that they're

00:18:02,330 --> 00:18:09,340
doing when it comes to scale so you know

00:18:05,780 --> 00:18:11,960
nobody loves doing planning but I think

00:18:09,340 --> 00:18:14,890
planning is one of those key steps and

00:18:11,960 --> 00:18:19,220
if you think about the planning process

00:18:14,890 --> 00:18:23,360
this isn't just sort of spitballing R&D

00:18:19,220 --> 00:18:27,080
ideas and moving forward on those the

00:18:23,360 --> 00:18:28,520
the process for planning brings in all

00:18:27,080 --> 00:18:31,550
those stakeholders that we saw on that

00:18:28,520 --> 00:18:33,920
that earlier slide so you know defining

00:18:31,550 --> 00:18:37,460
success of a data science project with a

00:18:33,920 --> 00:18:40,670
business stakeholder developing the data

00:18:37,460 --> 00:18:42,320
strategy for the company in combination

00:18:40,670 --> 00:18:43,790
with the data engineers and the

00:18:42,320 --> 00:18:46,820
stakeholders that are involved there and

00:18:43,790 --> 00:18:49,220
then laying out what are the goals of

00:18:46,820 --> 00:18:51,140
these various projects and and

00:18:49,220 --> 00:18:54,920
development that the data science team

00:18:51,140 --> 00:18:57,260
is doing and then tying that back to a

00:18:54,920 --> 00:19:00,530
measurement framework so what what is

00:18:57,260 --> 00:19:02,900
the success criteria of a data science

00:19:00,530 --> 00:19:06,410
project is it revenue is it cost savings

00:19:02,900 --> 00:19:09,260
is it model accuracy is it you know the

00:19:06,410 --> 00:19:11,870
speed of a model once it's in production

00:19:09,260 --> 00:19:14,930
if everyone's aligned on those things

00:19:11,870 --> 00:19:16,610
upfront there's no missed expectations

00:19:14,930 --> 00:19:18,350
you know there's not going to be this

00:19:16,610 --> 00:19:21,020
misalignment when you get to the output

00:19:18,350 --> 00:19:22,970
and everyone says wait a second this

00:19:21,020 --> 00:19:24,980
isn't driving revenue in the way that we

00:19:22,970 --> 00:19:28,310
thought it would be so everyone's on the

00:19:24,980 --> 00:19:29,960
same page on how you do that so the the

00:19:28,310 --> 00:19:31,580
different areas to think about are you

00:19:29,960 --> 00:19:33,740
know what are the tools and processes

00:19:31,580 --> 00:19:36,380
that the teams are putting in place to

00:19:33,740 --> 00:19:38,450
actually do the data science work

00:19:36,380 --> 00:19:40,970
what is the infrastructure and

00:19:38,450 --> 00:19:42,770
environment that the team needs to

00:19:40,970 --> 00:19:45,740
actually do the development that's

00:19:42,770 --> 00:19:48,370
required for the organization and then

00:19:45,740 --> 00:19:50,840
how does this go into production so

00:19:48,370 --> 00:19:52,460
developing the best data science model

00:19:50,840 --> 00:19:53,900
in the world and you know building

00:19:52,460 --> 00:19:56,960
something that's highly accurate and

00:19:53,900 --> 00:20:01,190
highly performant but if it doesn't get

00:19:56,960 --> 00:20:03,849
used kind of doesn't matter so I think

00:20:01,190 --> 00:20:05,529
that's that's one of the areas that

00:20:03,849 --> 00:20:09,700
we see these teams nearing as closing

00:20:05,529 --> 00:20:13,210
that gap so the tool landscape and and

00:20:09,700 --> 00:20:16,149
what's out there there are many many

00:20:13,210 --> 00:20:18,639
different options and it you know it can

00:20:16,149 --> 00:20:21,190
be overwhelming especially for someone

00:20:18,639 --> 00:20:23,649
that's new to the category you know what

00:20:21,190 --> 00:20:26,349
what is the best tool out there for a

00:20:23,649 --> 00:20:29,769
particular problem I think the the good

00:20:26,349 --> 00:20:31,359
news is there are communities behind all

00:20:29,769 --> 00:20:33,039
of these much like theirs with the

00:20:31,359 --> 00:20:37,119
Jupiter community that are happy to

00:20:33,039 --> 00:20:40,239
share ideas and best practices if you

00:20:37,119 --> 00:20:42,849
dive into any one of these areas there's

00:20:40,239 --> 00:20:46,989
probably you know 50 or a hundred ways

00:20:42,849 --> 00:20:48,879
of solving a particular problem one of

00:20:46,989 --> 00:20:51,849
the things that these teams are doing

00:20:48,879 --> 00:20:55,570
that we're seeing is you know trying

00:20:51,849 --> 00:20:58,719
trying not to have to reinvent every

00:20:55,570 --> 00:21:01,419
time so you know a lot of time and a lot

00:20:58,719 --> 00:21:03,339
of focus that companies is going into

00:21:01,419 --> 00:21:04,749
you know how do we actually solve this

00:21:03,339 --> 00:21:08,379
what is the best way to build a

00:21:04,749 --> 00:21:11,259
particular model once it's built what

00:21:08,379 --> 00:21:14,200
language should it go into and

00:21:11,259 --> 00:21:16,779
unfortunately in many cases that process

00:21:14,200 --> 00:21:19,089
happens over and over and over again

00:21:16,779 --> 00:21:20,559
because you know the the starting point

00:21:19,089 --> 00:21:23,769
is always the same okay we need to

00:21:20,559 --> 00:21:26,799
investigate how do we solve this so I

00:21:23,769 --> 00:21:27,820
think a really good best practice there

00:21:26,799 --> 00:21:29,769
is you know how do you document

00:21:27,820 --> 00:21:31,869
everything that you're doing in your

00:21:29,769 --> 00:21:33,549
investigation process and how do you

00:21:31,869 --> 00:21:36,039
expose that to the rest of the

00:21:33,549 --> 00:21:38,349
organization so that when it comes time

00:21:36,039 --> 00:21:40,469
to develop that next model or do that

00:21:38,349 --> 00:21:43,419
next area of exploratory research

00:21:40,469 --> 00:21:45,339
there's an accelerated starting point so

00:21:43,419 --> 00:21:48,070
people can see the work that's been done

00:21:45,339 --> 00:21:52,690
in the past and move quicker to the

00:21:48,070 --> 00:21:54,849
answer the the process this is something

00:21:52,690 --> 00:21:56,440
that's going to vary widely depending on

00:21:54,849 --> 00:21:59,799
the organization that you're working in

00:21:56,440 --> 00:22:02,229
the size of the team the expectations in

00:21:59,799 --> 00:22:04,570
terms of outputs and what the team is

00:22:02,229 --> 00:22:07,779
producing but these are kind of the

00:22:04,570 --> 00:22:09,369
general outlines of what some of these

00:22:07,779 --> 00:22:12,329
teams are doing that move into a larger

00:22:09,369 --> 00:22:15,890
scale is you know how do you experiment

00:22:12,329 --> 00:22:19,490
rapidly and also

00:22:15,890 --> 00:22:25,070
do it in a way that that experimentation

00:22:19,490 --> 00:22:26,360
becomes a output the the the higher

00:22:25,070 --> 00:22:29,180
performing teams and the ways that

00:22:26,360 --> 00:22:31,460
they're doing this is you know they'll

00:22:29,180 --> 00:22:33,530
they'll build out a center of excellence

00:22:31,460 --> 00:22:37,640
they'll build out a data science hub or

00:22:33,530 --> 00:22:40,130
some team that is really tackling some

00:22:37,640 --> 00:22:41,420
of the big questions around you know

00:22:40,130 --> 00:22:43,070
maybe it's one of those earlier topics

00:22:41,420 --> 00:22:44,570
like deep learning so like you know

00:22:43,070 --> 00:22:47,690
let's build out a team that's focused

00:22:44,570 --> 00:22:51,650
just on that and their responsibilities

00:22:47,690 --> 00:22:55,430
to research experiment produce outputs

00:22:51,650 --> 00:22:58,130
and what those outputs look like can be

00:22:55,430 --> 00:22:59,900
something where it's documenting you

00:22:58,130 --> 00:23:02,210
know what are the best practices for

00:22:59,900 --> 00:23:03,770
applying deep learning for a particular

00:23:02,210 --> 00:23:05,750
use case what did they find

00:23:03,770 --> 00:23:08,300
you know canvassing all of the resources

00:23:05,750 --> 00:23:10,670
that are out there giving guidance

00:23:08,300 --> 00:23:12,500
giving code samples to the team so they

00:23:10,670 --> 00:23:16,700
can get started quickly the next time

00:23:12,500 --> 00:23:20,450
someone's looking into using that the

00:23:16,700 --> 00:23:22,520
the idea of reproducibility so that

00:23:20,450 --> 00:23:24,530
there there's always nuance to how a

00:23:22,520 --> 00:23:29,240
particular models developed how the data

00:23:24,530 --> 00:23:32,960
structured the the common link for many

00:23:29,240 --> 00:23:35,270
of those might be you know doing

00:23:32,960 --> 00:23:38,510
exploratory analysis doing feature

00:23:35,270 --> 00:23:41,720
engineering doing model experimentation

00:23:38,510 --> 00:23:45,110
model selection moving the model into

00:23:41,720 --> 00:23:47,810
production and I think the the ability

00:23:45,110 --> 00:23:50,360
to share that work across teams to share

00:23:47,810 --> 00:23:52,400
it in a consistent way is something that

00:23:50,360 --> 00:23:54,320
we've seen you know as teams grow that

00:23:52,400 --> 00:23:56,840
has a lot of downstream benefits on

00:23:54,320 --> 00:24:00,680
closing the gap and being able to move

00:23:56,840 --> 00:24:03,590
to production faster the the sharing

00:24:00,680 --> 00:24:06,070
across teams so you know the the way

00:24:03,590 --> 00:24:09,860
that data science teams are organized

00:24:06,070 --> 00:24:12,020
across organizations there's many times

00:24:09,860 --> 00:24:14,030
a partnership that gets created so the

00:24:12,020 --> 00:24:16,160
data science team will be embedded

00:24:14,030 --> 00:24:19,400
within finance or they'll be embedded

00:24:16,160 --> 00:24:21,620
within marketing and I think there's

00:24:19,400 --> 00:24:24,500
always this risk where you know as that

00:24:21,620 --> 00:24:27,250
happens as teams dispersed within the

00:24:24,500 --> 00:24:29,299
organization that they no longer

00:24:27,250 --> 00:24:32,779
communicate with each other

00:24:29,299 --> 00:24:35,509
and having that ability to share ideas

00:24:32,779 --> 00:24:38,360
to you know say hey like you guys built

00:24:35,509 --> 00:24:40,129
a forecasting model for finance would

00:24:38,360 --> 00:24:42,110
that work as we're trying to you know

00:24:40,129 --> 00:24:46,220
forecast the number of users that are

00:24:42,110 --> 00:24:49,039
coming to our website and having that

00:24:46,220 --> 00:24:50,899
open dialogue between teams and sharing

00:24:49,039 --> 00:24:54,049
what they're working on is very helpful

00:24:50,899 --> 00:24:56,590
to point them in the right direction and

00:24:54,049 --> 00:24:59,690
and you know avoid that situation where

00:24:56,590 --> 00:25:02,989
you might have teams reproducing work

00:24:59,690 --> 00:25:07,369
that's already been created the next

00:25:02,989 --> 00:25:09,679
piece is the infrastructure side and you

00:25:07,369 --> 00:25:13,580
know I think one of the trends that

00:25:09,679 --> 00:25:15,700
we've seen is there there's a lot of

00:25:13,580 --> 00:25:18,830
experimentation happening still with

00:25:15,700 --> 00:25:22,369
cloud computing and using the public

00:25:18,830 --> 00:25:25,999
cloud providers to handle workloads for

00:25:22,369 --> 00:25:28,070
these organizations I think the the

00:25:25,999 --> 00:25:30,470
challenge often comes in you know if you

00:25:28,070 --> 00:25:31,700
you talk about a larger team and a large

00:25:30,470 --> 00:25:33,980
organization and it's how do you

00:25:31,700 --> 00:25:36,019
actually get access to those resources

00:25:33,980 --> 00:25:39,859
you can't you know you could but it's

00:25:36,019 --> 00:25:42,259
probably not not in the organization's

00:25:39,859 --> 00:25:43,730
ideal situation where you just like we'd

00:25:42,259 --> 00:25:46,220
put in your credit card and set up an

00:25:43,730 --> 00:25:48,559
account that's just not how it works so

00:25:46,220 --> 00:25:50,919
there's typically a conversation with

00:25:48,559 --> 00:25:53,090
the systems team with the IT team about

00:25:50,919 --> 00:25:55,909
provisioning resources about getting

00:25:53,090 --> 00:25:58,519
access to what's needed to scale a model

00:25:55,909 --> 00:26:00,769
as it's being developed and I think that

00:25:58,519 --> 00:26:03,289
that's a really important step in the

00:26:00,769 --> 00:26:05,419
process because that that will need to

00:26:03,289 --> 00:26:09,200
happen over and over again you know it's

00:26:05,419 --> 00:26:12,590
like almost a daily daily need so

00:26:09,200 --> 00:26:14,899
understanding what is the time

00:26:12,590 --> 00:26:18,080
requirement or how quickly can you get

00:26:14,899 --> 00:26:20,210
the resources that you need to the data

00:26:18,080 --> 00:26:22,720
scientists in the moment that they need

00:26:20,210 --> 00:26:25,730
it instead of having this cycle where a

00:26:22,720 --> 00:26:27,529
request comes in and then you have a you

00:26:25,730 --> 00:26:30,799
know a big time lag where they might

00:26:27,529 --> 00:26:32,570
need to go you know spin up the new

00:26:30,799 --> 00:26:34,100
accounts or spin out the new resource

00:26:32,570 --> 00:26:37,399
and then come back a week later

00:26:34,100 --> 00:26:39,590
oK we've got it so you know what you end

00:26:37,399 --> 00:26:41,539
up with is a data science team that's

00:26:39,590 --> 00:26:42,200
waiting a lot instead of actually doing

00:26:41,539 --> 00:26:45,560
the work that

00:26:42,200 --> 00:26:49,550
like to do the the standardization of

00:26:45,560 --> 00:26:53,260
environments so this would be an example

00:26:49,550 --> 00:26:56,570
where you have best practices

00:26:53,260 --> 00:26:59,630
established across the organization so

00:26:56,570 --> 00:27:01,370
as as teams do this development what

00:26:59,630 --> 00:27:04,430
they can do is they can say hey here is

00:27:01,370 --> 00:27:07,370
our our standard package for solving a

00:27:04,430 --> 00:27:09,950
certain use case and expose that to the

00:27:07,370 --> 00:27:13,490
team and that gets reused instead of

00:27:09,950 --> 00:27:16,160
having to reinvent it every time the

00:27:13,490 --> 00:27:16,880
access control the the kind of bytes

00:27:16,160 --> 00:27:20,030
nature

00:27:16,880 --> 00:27:21,800
the data that data scientists are

00:27:20,030 --> 00:27:23,630
typically working with is usually the

00:27:21,800 --> 00:27:27,710
most sensitive data in the organization

00:27:23,630 --> 00:27:30,790
so having an understanding of what users

00:27:27,710 --> 00:27:33,530
can have access to what data upfront and

00:27:30,790 --> 00:27:35,750
having a conversation with the you know

00:27:33,530 --> 00:27:38,120
security and privacy policy teams on

00:27:35,750 --> 00:27:41,000
what are the rules of engagement in

00:27:38,120 --> 00:27:44,210
terms of sharing data between projects

00:27:41,000 --> 00:27:46,820
between teams and making sure that that

00:27:44,210 --> 00:27:49,340
set up from the beginning is extremely

00:27:46,820 --> 00:27:51,740
helpful we've seen in some situations

00:27:49,340 --> 00:27:54,050
where you know that this policy

00:27:51,740 --> 00:27:56,510
violation can result in people no longer

00:27:54,050 --> 00:28:00,380
having jobs there are companies ending

00:27:56,510 --> 00:28:03,080
up in trouble the idea of moving to

00:28:00,380 --> 00:28:05,450
production so you know how do we get

00:28:03,080 --> 00:28:08,840
data science work that's that's been

00:28:05,450 --> 00:28:11,860
developed out of the background and into

00:28:08,840 --> 00:28:15,530
the foreground how do we move it into a

00:28:11,860 --> 00:28:18,320
system that is going to be used to

00:28:15,530 --> 00:28:21,050
engage with our customers and this

00:28:18,320 --> 00:28:23,840
really is where this change has happened

00:28:21,050 --> 00:28:26,270
where this is no longer just producing

00:28:23,840 --> 00:28:30,890
an insight it's producing what the

00:28:26,270 --> 00:28:35,240
company does and in this process there's

00:28:30,890 --> 00:28:38,330
often tasks that happened over and over

00:28:35,240 --> 00:28:40,580
again so you know an example being once

00:28:38,330 --> 00:28:43,160
your model is complete you need to check

00:28:40,580 --> 00:28:46,280
in that code to github as an example how

00:28:43,160 --> 00:28:47,540
do you make that process automated so

00:28:46,280 --> 00:28:49,550
someone doesn't have to write a script

00:28:47,540 --> 00:28:51,430
every time and you know they're probably

00:28:49,550 --> 00:28:54,800
creating their own script every time

00:28:51,430 --> 00:28:58,130
once the the model moves into a

00:28:54,800 --> 00:29:00,350
a production system having an eye

00:28:58,130 --> 00:29:03,110
towards how to closing the loop on that

00:29:00,350 --> 00:29:06,290
model how is it performing is it living

00:29:03,110 --> 00:29:08,330
up to expectations is the model giving

00:29:06,290 --> 00:29:10,730
us answers that everybody believes in

00:29:08,330 --> 00:29:12,710
and are the results matching what the

00:29:10,730 --> 00:29:15,580
the goals were when you initially set

00:29:12,710 --> 00:29:19,550
out to build that model with the team

00:29:15,580 --> 00:29:23,240
and then constant improvement so you

00:29:19,550 --> 00:29:24,770
know that there's often teams you know

00:29:23,240 --> 00:29:27,110
there's always this desire to keep

00:29:24,770 --> 00:29:31,160
building and build something new

00:29:27,110 --> 00:29:33,050
I think certainly you know one of the

00:29:31,160 --> 00:29:34,820
best practices would be you know once

00:29:33,050 --> 00:29:36,400
the model is complete you don't just

00:29:34,820 --> 00:29:39,380
move to the next project you kind of

00:29:36,400 --> 00:29:41,360
monitor how its performing iterate on

00:29:39,380 --> 00:29:44,770
the model test multiple versions of it

00:29:41,360 --> 00:29:47,750
and then improve it over time because

00:29:44,770 --> 00:29:49,700
the the data is going to change the the

00:29:47,750 --> 00:29:51,260
profile of users are going to change

00:29:49,700 --> 00:29:57,440
over time and you're going to need to

00:29:51,260 --> 00:30:00,320
update it over time as well this this

00:29:57,440 --> 00:30:02,600
idea of exposing all the work if you

00:30:00,320 --> 00:30:04,790
think about the the various stakeholders

00:30:02,600 --> 00:30:06,860
you know especially people that might be

00:30:04,790 --> 00:30:09,740
the you know business unit leaders or

00:30:06,860 --> 00:30:12,560
leaders of organizations within the

00:30:09,740 --> 00:30:14,330
company the the exposure of what's

00:30:12,560 --> 00:30:17,330
happening in data science has has

00:30:14,330 --> 00:30:19,490
typically been fairly limited other than

00:30:17,330 --> 00:30:20,960
you know they may get a quarterly update

00:30:19,490 --> 00:30:26,060
or some update as a projects being

00:30:20,960 --> 00:30:28,580
developed so this is what we've done to

00:30:26,060 --> 00:30:31,820
bring all of this together so you could

00:30:28,580 --> 00:30:33,940
see the different areas aligned pretty

00:30:31,820 --> 00:30:38,110
well with what we talked about there so

00:30:33,940 --> 00:30:41,170
having a variety of tools that have been

00:30:38,110 --> 00:30:44,570
tested and configured for the teams

00:30:41,170 --> 00:30:47,000
those tools being the standards so you

00:30:44,570 --> 00:30:51,580
know having tools that are open source

00:30:47,000 --> 00:30:51,580
friendly that that work consistently

00:30:52,120 --> 00:30:58,160
having the outputs be structured in a

00:30:55,550 --> 00:31:00,380
way that's intuitive for the team so you

00:30:58,160 --> 00:31:01,760
know those outputs being the api's they

00:31:00,380 --> 00:31:06,140
could be dashboards they could be apps

00:31:01,760 --> 00:31:07,500
they could be reports but delivering

00:31:06,140 --> 00:31:10,520
them in a way that

00:31:07,500 --> 00:31:14,340
is simple to use and understand for

00:31:10,520 --> 00:31:18,300
anyone on the team the infrastructure

00:31:14,340 --> 00:31:21,810
side so you know I think docker has been

00:31:18,300 --> 00:31:24,810
a steep change in the industry where the

00:31:21,810 --> 00:31:28,290
idea of having flexible compute

00:31:24,810 --> 00:31:32,340
resources anywhere is now a reality so

00:31:28,290 --> 00:31:34,920
you know using using the systems that

00:31:32,340 --> 00:31:39,690
are in place for security for user

00:31:34,920 --> 00:31:43,790
identity system logging and connecting

00:31:39,690 --> 00:31:48,120
it to both public cloud and internal

00:31:43,790 --> 00:31:50,550
infrastructure environments the tool

00:31:48,120 --> 00:31:53,970
alone isn't enough typically so if you

00:31:50,550 --> 00:31:56,100
think about the data science team there

00:31:53,970 --> 00:31:57,030
there's certainly you know the roadmap

00:31:56,100 --> 00:31:58,950
development

00:31:57,030 --> 00:32:01,770
there's the guidance on what are the

00:31:58,950 --> 00:32:03,600
priorities for the data science team so

00:32:01,770 --> 00:32:06,240
when we're working with customers we

00:32:03,600 --> 00:32:08,490
assign a team to support them on that

00:32:06,240 --> 00:32:11,160
development and understanding like how

00:32:08,490 --> 00:32:13,230
do we get everyone organized how do we

00:32:11,160 --> 00:32:15,600
align the team on the priorities and how

00:32:13,230 --> 00:32:18,150
do we measure success that can also be

00:32:15,600 --> 00:32:20,040
done internally so this idea of like

00:32:18,150 --> 00:32:22,590
setting up a center of excellence or a

00:32:20,040 --> 00:32:26,580
team that's a data science hub can also

00:32:22,590 --> 00:32:28,230
establish those for your team and then

00:32:26,580 --> 00:32:31,200
what what can you actually do with it

00:32:28,230 --> 00:32:34,800
you know once you have these models

00:32:31,200 --> 00:32:36,840
produced and you have outputs this list

00:32:34,800 --> 00:32:38,870
is just an example there's you know

00:32:36,840 --> 00:32:41,670
probably hundreds of these that can be

00:32:38,870 --> 00:32:44,490
talked about that you can see it's a mix

00:32:41,670 --> 00:32:46,970
so in some cases the actual end product

00:32:44,490 --> 00:32:49,320
that a data science team is producing is

00:32:46,970 --> 00:32:51,690
influencing a data pipeline it's doing

00:32:49,320 --> 00:32:54,300
some you know ongoing transformation

00:32:51,690 --> 00:32:56,820
work of data it could also be a

00:32:54,300 --> 00:32:58,920
full-featured application you know this

00:32:56,820 --> 00:33:00,810
is something that when people click a

00:32:58,920 --> 00:33:03,690
button or when they arrive to a mobile

00:33:00,810 --> 00:33:06,060
app it's going to decide what gets

00:33:03,690 --> 00:33:07,530
served to them so there there's you know

00:33:06,060 --> 00:33:12,000
various outputs that the teams are

00:33:07,530 --> 00:33:13,230
producing I think an important step to

00:33:12,000 --> 00:33:15,480
think about is you know how do you

00:33:13,230 --> 00:33:17,429
actually move into that leadership

00:33:15,480 --> 00:33:19,640
position how do you scale data science

00:33:17,429 --> 00:33:23,210
and these are two areas

00:33:19,640 --> 00:33:24,890
that we've seen teams do to help get

00:33:23,210 --> 00:33:26,810
them there and you know they may seem

00:33:24,890 --> 00:33:28,250
intuitive but there's you know clearly a

00:33:26,810 --> 00:33:31,280
difference here between these

00:33:28,250 --> 00:33:33,320
organizations developing that roadmap

00:33:31,280 --> 00:33:37,220
having a clear plan for your data

00:33:33,320 --> 00:33:39,790
science team both functionally and then

00:33:37,220 --> 00:33:43,580
also in the center of excellence

00:33:39,790 --> 00:33:45,140
defining the use cases defining how

00:33:43,580 --> 00:33:51,950
those use cases are going to be measured

00:33:45,140 --> 00:33:55,820
going forward and then across teams

00:33:51,950 --> 00:33:58,010
these are also areas that are sort of

00:33:55,820 --> 00:34:01,370
the keys to scaling that team scaling

00:33:58,010 --> 00:34:03,170
success integrating the data science

00:34:01,370 --> 00:34:05,230
team embedding them within the

00:34:03,170 --> 00:34:07,940
organization that they're working with

00:34:05,230 --> 00:34:11,090
making sure data scientists are actually

00:34:07,940 --> 00:34:13,310
doing data science work this one can be

00:34:11,090 --> 00:34:15,679
challenging sometimes you know the did

00:34:13,310 --> 00:34:18,169
the data engineer set up the platform

00:34:15,679 --> 00:34:20,570
the data platform and the data pipeline

00:34:18,169 --> 00:34:22,970
in a way that can be used or is there a

00:34:20,570 --> 00:34:24,919
bunch of manual intervention custom

00:34:22,970 --> 00:34:28,880
coding to get it in a place where you

00:34:24,919 --> 00:34:30,950
can actually work with it and in the end

00:34:28,880 --> 00:34:33,050
this is really what matters right so

00:34:30,950 --> 00:34:35,120
it's great to be a leader it's great to

00:34:33,050 --> 00:34:37,280
have a high performing team but how does

00:34:35,120 --> 00:34:39,919
that tie to business results for these

00:34:37,280 --> 00:34:43,370
organizations and we've seen you know

00:34:39,919 --> 00:34:46,490
clearly teams that are applying these

00:34:43,370 --> 00:34:49,520
best practices using data science across

00:34:46,490 --> 00:34:54,010
the organization are growing faster from

00:34:49,520 --> 00:34:57,700
a revenue and profitability perspective

00:34:54,010 --> 00:35:00,680
so with that just to wrap up on summary

00:34:57,700 --> 00:35:03,260
recommendations so unifying into a

00:35:00,680 --> 00:35:05,420
single platform clearly has some

00:35:03,260 --> 00:35:06,980
benefits it helps organize the work it

00:35:05,420 --> 00:35:09,800
helps get everyone on the same page in

00:35:06,980 --> 00:35:12,380
terms of what's being developed making

00:35:09,800 --> 00:35:15,170
the process itself open and transparent

00:35:12,380 --> 00:35:17,480
so I think you know keeping everybody

00:35:15,170 --> 00:35:19,820
posted on the development process the

00:35:17,480 --> 00:35:24,200
status of projects what's left to

00:35:19,820 --> 00:35:26,510
complete them making sure that what the

00:35:24,200 --> 00:35:29,750
knowledge base that is created within a

00:35:26,510 --> 00:35:31,340
data science organization stays when

00:35:29,750 --> 00:35:32,530
somebody leaves the company so how do

00:35:31,340 --> 00:35:34,150
you

00:35:32,530 --> 00:35:36,760
deserve that knowledgebase how do you

00:35:34,150 --> 00:35:39,310
make sure that the the code and the

00:35:36,760 --> 00:35:41,950
models have been developed can be reused

00:35:39,310 --> 00:35:46,630
going forward and then you know this

00:35:41,950 --> 00:35:50,410
isn't a point offering that you know can

00:35:46,630 --> 00:35:54,580
just be kind of managed by a IT buyer

00:35:50,410 --> 00:35:56,200
because the roles in the the workloads

00:35:54,580 --> 00:35:58,450
that the data science teams are working

00:35:56,200 --> 00:36:03,700
now are very influential in sort of the

00:35:58,450 --> 00:36:06,190
core business now and you know this

00:36:03,700 --> 00:36:08,830
can't be treated as like a reporting

00:36:06,190 --> 00:36:12,490
dashboard because the way that it's

00:36:08,830 --> 00:36:15,400
being used is directly impacting the

00:36:12,490 --> 00:36:18,310
company's core offerings so it is

00:36:15,400 --> 00:36:19,990
strategic it does make a lot of changes

00:36:18,310 --> 00:36:23,340
when you you kind of move into this

00:36:19,990 --> 00:36:27,290
direction but it also has high impact

00:36:23,340 --> 00:36:32,550
all right thank you

00:36:27,290 --> 00:36:32,550
[Applause]

00:36:39,539 --> 00:36:43,900
yeah I'm not sure if they posted or if

00:36:42,579 --> 00:36:46,890
you give me your card I could send it to

00:36:43,900 --> 00:36:46,890
you yeah

00:36:56,390 --> 00:37:01,460
so I would say the the most surprising

00:36:59,119 --> 00:37:04,039
thing for me was the lack of cloud

00:37:01,460 --> 00:37:05,239
adoption to be honest that that was I'd

00:37:04,039 --> 00:37:06,680
say that one of the most surprising

00:37:05,239 --> 00:37:09,609
things because I you know my my

00:37:06,680 --> 00:37:13,670
background is in cloud computing and

00:37:09,609 --> 00:37:14,869
embracing that and I think I understand

00:37:13,670 --> 00:37:16,789
why it's happening in a lot of these

00:37:14,869 --> 00:37:19,190
organizations where there's sort of a

00:37:16,789 --> 00:37:22,670
resistance to move sensitive data and

00:37:19,190 --> 00:37:24,410
you know but but that was really

00:37:22,670 --> 00:37:28,579
surprising to me it's like the the lack

00:37:24,410 --> 00:37:30,349
of cloud computing adoption within data

00:37:28,579 --> 00:37:37,119
science teams it's still very very

00:37:30,349 --> 00:37:37,119
limited today did you have a question

00:37:40,390 --> 00:37:45,339
yeah right

00:37:49,340 --> 00:37:54,740
right right yeah it's a good question

00:37:51,710 --> 00:37:56,450
yep so the question was on our pricing

00:37:54,740 --> 00:37:58,490
model and you know if you have a hybrid

00:37:56,450 --> 00:38:00,980
customer that's using cloud and an

00:37:58,490 --> 00:38:03,290
on-premises infrastructure how we

00:38:00,980 --> 00:38:06,500
support them so when we work with

00:38:03,290 --> 00:38:08,150
customers we don't actually move their

00:38:06,500 --> 00:38:10,310
systems or we're not creating a native

00:38:08,150 --> 00:38:11,600
data Lake the way that we typically work

00:38:10,310 --> 00:38:14,450
with them is we're deploying our

00:38:11,600 --> 00:38:17,150
platform within their environment so

00:38:14,450 --> 00:38:20,210
their choice of infrastructure or cloud

00:38:17,150 --> 00:38:21,910
compute its really done within their

00:38:20,210 --> 00:38:24,380
accounts we're not hosting it for them

00:38:21,910 --> 00:38:25,970
and then our pricing model is pretty

00:38:24,380 --> 00:38:28,190
simple it's basically you know how many

00:38:25,970 --> 00:38:38,930
data scientists are there and you know

00:38:28,190 --> 00:38:40,610
that's how we price our product thank

00:38:38,930 --> 00:38:43,860
you

00:38:40,610 --> 00:38:43,860

YouTube URL: https://www.youtube.com/watch?v=2iuUF0m6xyU


