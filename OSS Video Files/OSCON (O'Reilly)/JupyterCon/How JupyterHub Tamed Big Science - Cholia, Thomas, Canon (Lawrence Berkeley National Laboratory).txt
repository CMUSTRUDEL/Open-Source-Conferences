Title: How JupyterHub Tamed Big Science - Cholia, Thomas, Canon (Lawrence Berkeley National Laboratory)
Publication date: 2017-11-08
Playlist: JupyterCon
Description: 
	Shreyas Cholia (Lawrence Berkeley National Laboratory), Rollin Thomas (Lawrence Berkeley National Laboratory), Shane Canon (Lawrence Berkeley National Laboratory) share their experience leveraging JupyterHub to enable notebook services for data-intensive supercomputing on the Cray XC40 Cori system at the National Energy Research Scientific Computing Center (NERSC).

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,520 --> 00:00:07,250
I'm sure is this is Rolla and up here my

00:00:04,670 --> 00:00:11,180
colleague and we're gonna be talking

00:00:07,250 --> 00:00:14,770
about how we've used Jupiter hub and

00:00:11,180 --> 00:00:17,630
Jupiter notebooks to get a handle on

00:00:14,770 --> 00:00:20,690
some of the cool science problems we've

00:00:17,630 --> 00:00:24,020
been solving at nurse so to start

00:00:20,690 --> 00:00:26,810
actually I like to this is really who we

00:00:24,020 --> 00:00:30,170
are so this is the view from our Center

00:00:26,810 --> 00:00:32,360
at nurse so we're right by right on top

00:00:30,170 --> 00:00:37,340
of the hills in Berkeley overlooking the

00:00:32,360 --> 00:00:40,399
San Francisco Bay and who we are where

00:00:37,340 --> 00:00:41,750
were the office of science production

00:00:40,399 --> 00:00:45,050
high-performance computing and data

00:00:41,750 --> 00:00:48,380
facility and the office of science is

00:00:45,050 --> 00:00:51,829
the largest funder of basic research in

00:00:48,380 --> 00:00:54,440
the Department of Energy and really the

00:00:51,829 --> 00:00:57,890
largest federal funder of science

00:00:54,440 --> 00:00:59,510
research in general and and we have we

00:00:57,890 --> 00:01:03,079
cover a whole bunch of different areas

00:00:59,510 --> 00:01:05,000
so bioenergy advanced computing material

00:01:03,079 --> 00:01:08,450
science high energy physics nuclear

00:01:05,000 --> 00:01:10,819
science fusion so we have projects from

00:01:08,450 --> 00:01:14,119
all of these different spaces that run

00:01:10,819 --> 00:01:16,579
at our supercomputing Center and where

00:01:14,119 --> 00:01:21,319
they run is the system called Cori so

00:01:16,579 --> 00:01:24,999
this is our so Cori is our big

00:01:21,319 --> 00:01:27,979
supercomputer and it's a combination of

00:01:24,999 --> 00:01:30,099
what we call a data partition and a

00:01:27,979 --> 00:01:32,869
compute partition so it's got Intel

00:01:30,099 --> 00:01:36,020
Haswell nodes that that are focused more

00:01:32,869 --> 00:01:40,700
on our data users and it's got an HPC

00:01:36,020 --> 00:01:42,889
partition that has more cores per node

00:01:40,700 --> 00:01:46,700
we've got a bunch of special features

00:01:42,889 --> 00:01:50,149
that we hope will enhance data driven

00:01:46,700 --> 00:01:52,009
computing so things like NVRAM burst

00:01:50,149 --> 00:01:57,139
buffer which is basically a big flash

00:01:52,009 --> 00:01:59,119
memory filesystem that people can read

00:01:57,139 --> 00:02:03,049
and write data from very quickly we've

00:01:59,119 --> 00:02:04,969
got our batch queues optimized to do a

00:02:03,049 --> 00:02:07,700
lot of real-time computing a lot of

00:02:04,969 --> 00:02:09,770
shared computing we've got containerized

00:02:07,700 --> 00:02:11,000
HPC and within the form of this thing

00:02:09,770 --> 00:02:15,170
called shifter which is basically

00:02:11,000 --> 00:02:16,550
bringing docker to supercomputing

00:02:15,170 --> 00:02:19,069
so yeah so we're trying to do a lot of

00:02:16,550 --> 00:02:21,200
fun stuff in supercomputing space which

00:02:19,069 --> 00:02:22,850
tends to be you know in some ways still

00:02:21,200 --> 00:02:24,770
very different from the cloud and that

00:02:22,850 --> 00:02:28,030
it's all big iron you've got these big

00:02:24,770 --> 00:02:30,530
clusters with very specialized hardware

00:02:28,030 --> 00:02:32,540
but but we're seeing more and more you

00:02:30,530 --> 00:02:34,880
know as kind of people are doing

00:02:32,540 --> 00:02:37,490
exploratory work in data that we kind of

00:02:34,880 --> 00:02:40,190
need a slightly different paradigm for

00:02:37,490 --> 00:02:44,500
how to actually start thinking about use

00:02:40,190 --> 00:02:49,160
of these supercomputers all right so all

00:02:44,500 --> 00:02:53,090
right so so what is so now taking a step

00:02:49,160 --> 00:02:54,470
back right so what is data science and

00:02:53,090 --> 00:02:59,150
and so this is the thing that we grabbed

00:02:54,470 --> 00:03:01,070
from Wikipedia so it must be true but

00:02:59,150 --> 00:03:03,500
but but the idea is that you've got this

00:03:01,070 --> 00:03:05,030
ground truth the reality of what's going

00:03:03,500 --> 00:03:07,340
on in the world you collect that data

00:03:05,030 --> 00:03:09,380
you process the data and then maybe you

00:03:07,340 --> 00:03:11,780
clean it and then you go into this

00:03:09,380 --> 00:03:13,040
exploratory data analysis phase and and

00:03:11,780 --> 00:03:14,810
that's really where something like

00:03:13,040 --> 00:03:17,090
Jupiter would come and come into the

00:03:14,810 --> 00:03:18,320
picture but and then you kind of circle

00:03:17,090 --> 00:03:20,480
through that loop a little bit and

00:03:18,320 --> 00:03:22,100
eventually you communicate and visualize

00:03:20,480 --> 00:03:25,160
your results make decisions based on

00:03:22,100 --> 00:03:26,840
those results and then possibly create

00:03:25,160 --> 00:03:31,040
more data products which feed to the

00:03:26,840 --> 00:03:35,510
ground truth in practice what that often

00:03:31,040 --> 00:03:37,700
means though is that you've got here

00:03:35,510 --> 00:03:39,290
here's sort of the real world side of

00:03:37,700 --> 00:03:41,420
that right you've got some manageable

00:03:39,290 --> 00:03:43,820
chunk of data you then copy it to your

00:03:41,420 --> 00:03:46,310
laptop or workstation you write a bunch

00:03:43,820 --> 00:03:48,739
of code you need to make sure everything

00:03:46,310 --> 00:03:49,610
is reproducible there's plots there's

00:03:48,739 --> 00:03:53,660
equations

00:03:49,610 --> 00:03:55,790
there's iteration so in in the sort of

00:03:53,660 --> 00:03:57,470
old-school war world you kind of had to

00:03:55,790 --> 00:03:59,750
have scripts for everything you had lots

00:03:57,470 --> 00:04:04,519
of different tools and you had to

00:03:59,750 --> 00:04:07,459
somehow bring this all together now so

00:04:04,519 --> 00:04:10,250
Jupiter kind of changes the the equation

00:04:07,459 --> 00:04:11,660
a little bit and what that does is it

00:04:10,250 --> 00:04:14,060
kind of gives you this one this sort of

00:04:11,660 --> 00:04:19,489
unified place where you can now run all

00:04:14,060 --> 00:04:21,729
these narratives you can encode your

00:04:19,489 --> 00:04:24,110
work you can add code add comments

00:04:21,729 --> 00:04:25,669
iterate I mean you guys are all familiar

00:04:24,110 --> 00:04:27,500
with Jupiter so I don't need to be

00:04:25,669 --> 00:04:28,949
preaching to the choir here but you get

00:04:27,500 --> 00:04:31,689
the idea

00:04:28,949 --> 00:04:33,669
now supercomputing is still kind of

00:04:31,689 --> 00:04:36,729
stuck in this sort of old-school mode

00:04:33,669 --> 00:04:38,680
where you know there's so scientific

00:04:36,729 --> 00:04:41,529
insight is often dependent on having

00:04:38,680 --> 00:04:43,870
iterative exploration you look at a

00:04:41,529 --> 00:04:45,610
bunch of data you you analyze it and

00:04:43,870 --> 00:04:47,589
then you come to some interesting idea

00:04:45,610 --> 00:04:50,469
you want to test your hypothesis and you

00:04:47,589 --> 00:04:52,029
want to do this in a very tight loop but

00:04:50,469 --> 00:04:54,339
type performance computing tends to be

00:04:52,029 --> 00:04:57,699
very much of a you know command line

00:04:54,339 --> 00:04:59,650
batch driven enterprise and you know we

00:04:57,699 --> 00:05:01,449
don't quite see terminals like those but

00:04:59,650 --> 00:05:05,979
but it's pretty close you've got people

00:05:01,449 --> 00:05:08,229
you know logging in through their SSH

00:05:05,979 --> 00:05:11,289
terminals at clients and and compiling

00:05:08,229 --> 00:05:13,710
their codes and doing a lot of things

00:05:11,289 --> 00:05:17,289
that that are not what I would consider

00:05:13,710 --> 00:05:19,599
conducive to this iterative discovery

00:05:17,289 --> 00:05:23,310
loop so really the question is you know

00:05:19,599 --> 00:05:23,310
how does Jupiter bridge this gap and

00:05:25,589 --> 00:05:32,710
really and how does how does Jupiter fit

00:05:29,710 --> 00:05:34,839
into the context of running at a

00:05:32,710 --> 00:05:36,159
supercomputing Center so the difference

00:05:34,839 --> 00:05:39,550
between sort of small you know smaller

00:05:36,159 --> 00:05:41,169
scale data analysis versus something at

00:05:39,550 --> 00:05:42,699
a supercomputing centers we've got these

00:05:41,169 --> 00:05:46,349
fairly deep questions that people want

00:05:42,699 --> 00:05:48,759
to ask there's data being collected from

00:05:46,349 --> 00:05:50,620
fairly large instruments so things like

00:05:48,759 --> 00:05:54,039
the Large Hadron Collider or big

00:05:50,620 --> 00:05:55,360
telescopes big simulations that are

00:05:54,039 --> 00:05:57,520
running are actually generating data

00:05:55,360 --> 00:05:59,529
that needs to be analyzed so you've got

00:05:57,520 --> 00:06:00,580
you know massive massive amounts of data

00:05:59,529 --> 00:06:03,759
that are coming into these

00:06:00,580 --> 00:06:05,529
supercomputers but then you want to be

00:06:03,759 --> 00:06:07,029
able to do some sort of insightful

00:06:05,529 --> 00:06:09,669
real-time analysis you want to do

00:06:07,029 --> 00:06:12,909
exploratory analysis you want to be able

00:06:09,669 --> 00:06:14,529
to do make some decisions based on you

00:06:12,909 --> 00:06:17,560
know what data you care about what data

00:06:14,529 --> 00:06:20,339
will will basically continue to live on

00:06:17,560 --> 00:06:23,289
the system what data gets thrown away so

00:06:20,339 --> 00:06:25,209
so it's it's it's all sort of stuff that

00:06:23,289 --> 00:06:27,009
needs to happen onboard the

00:06:25,209 --> 00:06:31,479
supercomputer you can't really farm that

00:06:27,009 --> 00:06:35,979
out and and here's kind of the big

00:06:31,479 --> 00:06:37,539
picture of what we're trying to do so

00:06:35,979 --> 00:06:39,879
you've got all of these resources

00:06:37,539 --> 00:06:41,769
sitting on our supercomputers and users

00:06:39,879 --> 00:06:42,330
want to be able to submit jobs monitor

00:06:41,769 --> 00:06:44,280
jobs

00:06:42,330 --> 00:06:45,900
interact with those jobs you've got our

00:06:44,280 --> 00:06:49,319
file systems that people want to be able

00:06:45,900 --> 00:06:51,599
to to access there's software modules

00:06:49,319 --> 00:06:53,129
underneath that there's databases so all

00:06:51,599 --> 00:06:57,090
of these things kind of need to come

00:06:53,129 --> 00:06:59,789
together Python has played a pretty

00:06:57,090 --> 00:07:05,400
important role in this space so we've

00:06:59,789 --> 00:07:07,409
got most of our users a very large

00:07:05,400 --> 00:07:09,389
number of our users are actually using

00:07:07,409 --> 00:07:11,370
Python as the engine to kind of script

00:07:09,389 --> 00:07:14,250
everything together to bring all these

00:07:11,370 --> 00:07:20,310
different pieces of their scientific

00:07:14,250 --> 00:07:22,800
pipeline under one umbrella all right so

00:07:20,310 --> 00:07:25,500
the motivation for now coming for all of

00:07:22,800 --> 00:07:26,849
all of this is so we started seeing all

00:07:25,500 --> 00:07:28,770
of this and then our users basically

00:07:26,849 --> 00:07:31,379
like okay this is cool and they ended up

00:07:28,770 --> 00:07:34,190
start running their own notebook servers

00:07:31,379 --> 00:07:37,190
on the supercomputing login nodes and

00:07:34,190 --> 00:07:40,409
basically just started using that

00:07:37,190 --> 00:07:42,509
without our knowledge which is fine but

00:07:40,409 --> 00:07:44,069
it started to make our security folks a

00:07:42,509 --> 00:07:46,110
little bit nervous because the idea of

00:07:44,069 --> 00:07:49,020
just sort of running something that's

00:07:46,110 --> 00:07:52,560
exposed to the public on an open port

00:07:49,020 --> 00:07:53,819
was not great and people we started

00:07:52,560 --> 00:07:55,379
getting questions about you know

00:07:53,819 --> 00:07:57,150
different kinds of kernels how do we

00:07:55,379 --> 00:08:00,419
manage those so it was not an ideal

00:07:57,150 --> 00:08:03,509
situation but then Jupiter hub came

00:08:00,419 --> 00:08:06,000
along and ended up solving a lot of

00:08:03,509 --> 00:08:07,500
these problems so Jupiter hub is

00:08:06,000 --> 00:08:09,810
basically a centralized service to

00:08:07,500 --> 00:08:12,150
deploy these notebooks so and we can now

00:08:09,810 --> 00:08:14,520
do this in an authenticated manner we

00:08:12,150 --> 00:08:16,349
can package up specific kernels so we

00:08:14,520 --> 00:08:18,120
can give users a standard environment

00:08:16,349 --> 00:08:21,150
and then we can access all of these

00:08:18,120 --> 00:08:23,129
resources that I talked about in the

00:08:21,150 --> 00:08:25,830
file systems the batch system the

00:08:23,129 --> 00:08:30,629
database is the environment all under

00:08:25,830 --> 00:08:33,990
you know the this common environment so

00:08:30,629 --> 00:08:35,310
in case folks are not familiar with

00:08:33,990 --> 00:08:38,159
Jupiter hub it's basically this

00:08:35,310 --> 00:08:40,829
multi-user environment that allows

00:08:38,159 --> 00:08:43,649
people to create their own notebooks

00:08:40,829 --> 00:08:45,660
under a common framework so it manages

00:08:43,649 --> 00:08:47,250
things like user authentication it

00:08:45,660 --> 00:08:49,290
manages the notebook spawning and

00:08:47,250 --> 00:08:50,850
deployment and it manages things like

00:08:49,290 --> 00:08:52,890
web proxying so you come into this

00:08:50,850 --> 00:08:56,360
single interface and it proxies things

00:08:52,890 --> 00:08:56,360
between that server and the back-end

00:08:57,060 --> 00:09:01,500
so yeah towards this end so we so we

00:08:59,640 --> 00:09:04,260
kind of felt like okay we need to set up

00:09:01,500 --> 00:09:05,520
this Jupiter hub service so the first

00:09:04,260 --> 00:09:07,110
thing is you know we got to give the

00:09:05,520 --> 00:09:12,300
people what they want so we give them

00:09:07,110 --> 00:09:15,420
their data so we started with this this

00:09:12,300 --> 00:09:18,090
single node what we call an edge service

00:09:15,420 --> 00:09:20,880
node to to deploy this so this was

00:09:18,090 --> 00:09:22,890
basically a node that where users came

00:09:20,880 --> 00:09:25,380
in to this docker container that ran

00:09:22,890 --> 00:09:28,320
Jupiter hub and everything just kind of

00:09:25,380 --> 00:09:32,040
ran locally so people were able to bring

00:09:28,320 --> 00:09:34,740
up Jupiter notebooks on this node we

00:09:32,040 --> 00:09:37,350
mounted the big file systems at our

00:09:34,740 --> 00:09:39,900
Center onto this system so people now

00:09:37,350 --> 00:09:42,150
had access to the file system so it was

00:09:39,900 --> 00:09:43,530
not quite onboard the supercomputer but

00:09:42,150 --> 00:09:45,120
it shared a file system so you could

00:09:43,530 --> 00:09:47,040
start to do a lot of interesting things

00:09:45,120 --> 00:09:48,540
with the data that you were generating

00:09:47,040 --> 00:09:51,780
from your simulations or preparing the

00:09:48,540 --> 00:09:53,280
data and this became popular very

00:09:51,780 --> 00:09:55,770
quickly so we ended up with over a

00:09:53,280 --> 00:10:00,390
hundred users in the manner of just I

00:09:55,770 --> 00:10:03,030
think a few months and and we were

00:10:00,390 --> 00:10:04,920
missing a few key components but this

00:10:03,030 --> 00:10:07,890
was definitely a really good place to

00:10:04,920 --> 00:10:09,900
start well we didn't have though was

00:10:07,890 --> 00:10:11,070
access to the actual batch jobs that

00:10:09,900 --> 00:10:13,710
were running we and we didn't have

00:10:11,070 --> 00:10:15,480
access to the core file systems things

00:10:13,710 --> 00:10:17,400
like the lustre file system or the burst

00:10:15,480 --> 00:10:19,770
buffer file system that you would want

00:10:17,400 --> 00:10:21,630
with your jobs we didn't have access to

00:10:19,770 --> 00:10:25,680
the same Python environment the jobs

00:10:21,630 --> 00:10:27,240
running it so it was not quite ideal so

00:10:25,680 --> 00:10:29,300
this is kind of where we move move

00:10:27,240 --> 00:10:32,760
towards this that this new architecture

00:10:29,300 --> 00:10:37,740
which integrates our compute system with

00:10:32,760 --> 00:10:39,270
our file systems and allows us users to

00:10:37,740 --> 00:10:42,050
still log in to nurse but now they have

00:10:39,270 --> 00:10:46,200
access to the bigquery supercomputer

00:10:42,050 --> 00:10:47,670
through Jupiter notebooks so people

00:10:46,200 --> 00:10:51,480
still love people now login to the

00:10:47,670 --> 00:10:53,700
Jupiter hub server we use this thing

00:10:51,480 --> 00:10:56,430
called an SSH spawner which lets you go

00:10:53,700 --> 00:11:00,420
off and spin up a notebook on a Cori

00:10:56,430 --> 00:11:02,190
node directly and now it has access to

00:11:00,420 --> 00:11:03,960
not just the global file system but the

00:11:02,190 --> 00:11:06,240
Cori specific file system as well and

00:11:03,960 --> 00:11:08,760
we've got some hooks to be able to

00:11:06,240 --> 00:11:14,850
access the batch queue

00:11:08,760 --> 00:11:17,520
in there so this was actually you know

00:11:14,850 --> 00:11:19,410
big plus forward and then we're seeing

00:11:17,520 --> 00:11:21,060
more and more projects basically just

00:11:19,410 --> 00:11:24,570
you know once they start using this it's

00:11:21,060 --> 00:11:26,460
really hard for them to go back so the

00:11:24,570 --> 00:11:28,950
the pieces that we added to make all of

00:11:26,460 --> 00:11:31,920
this stuff happen so we added a custom

00:11:28,950 --> 00:11:33,630
Authenticator to Jupiter hub and that

00:11:31,920 --> 00:11:35,070
let people log in with their nurse

00:11:33,630 --> 00:11:36,690
credentials their usernames and

00:11:35,070 --> 00:11:39,600
passwords and got them a little token

00:11:36,690 --> 00:11:41,490
that could then be used by the other

00:11:39,600 --> 00:11:44,970
piece of it which was the SSH spawner

00:11:41,490 --> 00:11:49,320
which would go off and which will spin

00:11:44,970 --> 00:11:54,300
up notebooks on the other side using

00:11:49,320 --> 00:11:56,310
this token and we added some additional

00:11:54,300 --> 00:11:57,690
sort of what we called slurm magics to

00:11:56,310 --> 00:12:01,260
be able to talk to our batch queue

00:11:57,690 --> 00:12:03,600
system so a little bit about the GSI

00:12:01,260 --> 00:12:06,270
Authenticator it allows users to log in

00:12:03,600 --> 00:12:09,120
with their username and password it goes

00:12:06,270 --> 00:12:12,000
off and gets an x.509 certificate for

00:12:09,120 --> 00:12:16,790
that user and then uses that x.509

00:12:12,000 --> 00:12:19,620
certificate to talk to the corey note

00:12:16,790 --> 00:12:22,590
this also means the jupiter hub can now

00:12:19,620 --> 00:12:24,960
run as a standalone service doesn't need

00:12:22,590 --> 00:12:27,150
root access to do anything so you just

00:12:24,960 --> 00:12:32,160
get these certificates and log the user

00:12:27,150 --> 00:12:34,070
indirectly the other piece that we wrote

00:12:32,160 --> 00:12:38,010
this was actually inspired somewhat by

00:12:34,070 --> 00:12:39,720
Andres ANCA from San Diego so he had

00:12:38,010 --> 00:12:42,540
something called the remote spawner and

00:12:39,720 --> 00:12:45,270
then we expanded on that and modified it

00:12:42,540 --> 00:12:47,580
to do a little bit more so we wrote this

00:12:45,270 --> 00:12:50,220
thing called the SSH spawner which uses

00:12:47,580 --> 00:12:53,640
you can use SSH you can use GSI as SH

00:12:50,220 --> 00:12:56,940
you can use different kinds of tokens to

00:12:53,640 --> 00:12:58,680
basically log in to the backend it

00:12:56,940 --> 00:13:01,260
basically starts up a notebook server

00:12:58,680 --> 00:13:03,570
process and then goes away and it'll

00:13:01,260 --> 00:13:06,120
just use the the keys to communicate

00:13:03,570 --> 00:13:09,060
with things over an SSH connection as

00:13:06,120 --> 00:13:11,610
needed and it keep does things like it

00:13:09,060 --> 00:13:15,440
keeps track of the remote process ID to

00:13:11,610 --> 00:13:15,440
pull and shutdown notebooks

00:13:16,739 --> 00:13:22,379
and then we also added this piece called

00:13:18,720 --> 00:13:24,239
the slur MAGIX which would let you talk

00:13:22,379 --> 00:13:26,249
to the batch system on the back end so

00:13:24,239 --> 00:13:28,949
you can use this to submit job so you

00:13:26,249 --> 00:13:31,589
craft your jobs as this batch script

00:13:28,949 --> 00:13:33,929
which yes old-school super computing and

00:13:31,589 --> 00:13:36,839
then you can query you can query the

00:13:33,929 --> 00:13:38,670
queue you can cancel your job so you can

00:13:36,839 --> 00:13:43,470
interface with something like slurm or

00:13:38,670 --> 00:13:45,149
PBS using this type of thing one of the

00:13:43,470 --> 00:13:47,549
other things that our users wanted was

00:13:45,149 --> 00:13:51,629
this ability to have custom kernels so a

00:13:47,549 --> 00:13:53,279
lot of what we tend to see soap you know

00:13:51,629 --> 00:13:55,079
we it was really nice to be able to have

00:13:53,279 --> 00:13:58,829
these common environments and everyone

00:13:55,079 --> 00:14:01,350
could run in something that we knew how

00:13:58,829 --> 00:14:03,720
to support so we had anaconda and people

00:14:01,350 --> 00:14:04,769
just ran that but then of course people

00:14:03,720 --> 00:14:06,499
wanted to be able to add their own

00:14:04,769 --> 00:14:09,389
packages at their own libraries and

00:14:06,499 --> 00:14:10,920
supporting that across a very large

00:14:09,389 --> 00:14:13,319
number of users starts to get a little

00:14:10,920 --> 00:14:16,949
tricky so we gave people these recipes

00:14:13,319 --> 00:14:19,139
for how to basically customize their

00:14:16,949 --> 00:14:21,869
kernels to be able to do what they

00:14:19,139 --> 00:14:25,740
wanted so so we kind of use the kernel

00:14:21,869 --> 00:14:27,029
spec and then show people how to here's

00:14:25,740 --> 00:14:29,579
what you want to add to your library

00:14:27,029 --> 00:14:32,879
path here's you know you you still want

00:14:29,579 --> 00:14:35,069
to use the same condo package but then

00:14:32,879 --> 00:14:36,990
you want to add other packages to your

00:14:35,069 --> 00:14:40,499
kernel spec and then you can run with

00:14:36,990 --> 00:14:42,629
your own packages so before I go further

00:14:40,499 --> 00:14:44,610
I want to thank men for a lot of help

00:14:42,629 --> 00:14:47,869
with throughout all this so I think

00:14:44,610 --> 00:14:52,350
couldn't have done it without you

00:14:47,869 --> 00:14:55,110
alright so now we're up for the more

00:14:52,350 --> 00:14:56,730
dangerous part of this talk Rollins

00:14:55,110 --> 00:15:03,149
gonna do a couple of live demos and kind

00:14:56,730 --> 00:15:08,189
of show us how with the live demos with

00:15:03,149 --> 00:15:09,990
Shreyas this idea just before I get

00:15:08,189 --> 00:15:11,549
started I just wanted to see like are

00:15:09,990 --> 00:15:14,399
there people here who have actually used

00:15:11,549 --> 00:15:17,189
like supercomputers at like a HPC

00:15:14,399 --> 00:15:19,139
computing system like a crisis tum' so

00:15:17,189 --> 00:15:23,879
you're familiar with batch queue systems

00:15:19,139 --> 00:15:25,720
like PBS torque Moab or slurm slurm ok

00:15:23,879 --> 00:15:29,870
cool slims cool man

00:15:25,720 --> 00:15:34,990
as okay it's a batch it's not cool

00:15:29,870 --> 00:15:36,980
so live demos if if this goes bad then

00:15:34,990 --> 00:15:45,040
we'll just have to figure out how to

00:15:36,980 --> 00:15:45,040
fill at the time here so I got it thanks

00:15:47,410 --> 00:15:57,620
okay so I'm going to show you a couple

00:15:50,840 --> 00:16:00,910
of notebooks first one's going to be

00:15:57,620 --> 00:16:03,170
from an actual experiment that uses

00:16:00,910 --> 00:16:05,630
basically runs their calibration

00:16:03,170 --> 00:16:08,750
procedure through Jupiter notebooks this

00:16:05,630 --> 00:16:10,600
is Lux the liquid underground xenon

00:16:08,750 --> 00:16:13,640
detector they're looking for direct

00:16:10,600 --> 00:16:15,980
interaction of dark matter particles

00:16:13,640 --> 00:16:17,630
with stuff on earth and the way they do

00:16:15,980 --> 00:16:19,910
this experiment is they have like the

00:16:17,630 --> 00:16:22,490
biggest tank of liquid xenon on the

00:16:19,910 --> 00:16:24,710
planet it's 400 kilograms liquid xenon

00:16:22,490 --> 00:16:26,810
and the dark matter particles go through

00:16:24,710 --> 00:16:28,280
and they interact with the xenon that's

00:16:26,810 --> 00:16:30,140
in there and they admit a little bit of

00:16:28,280 --> 00:16:31,790
light and then electric field pulls

00:16:30,140 --> 00:16:33,860
electrons that are liberated up to the

00:16:31,790 --> 00:16:36,020
top of the detector the drift time tells

00:16:33,860 --> 00:16:37,820
you the z-coordinate and then through

00:16:36,020 --> 00:16:39,380
some modeling with these photomultiplier

00:16:37,820 --> 00:16:40,970
tubes you can figure out where the

00:16:39,380 --> 00:16:43,670
original pulse came from so you get XY

00:16:40,970 --> 00:16:45,410
and z and the way that they they

00:16:43,670 --> 00:16:47,540
calibrate this detector is that they put

00:16:45,410 --> 00:16:49,700
a radioactive source into it like

00:16:47,540 --> 00:16:51,860
Krypton and then they just wait for

00:16:49,700 --> 00:16:53,900
those decays to happen and then they

00:16:51,860 --> 00:16:55,010
they measure the pulse widths and they

00:16:53,900 --> 00:17:00,140
correct the widths of these pulses

00:16:55,010 --> 00:17:01,580
basically - to calibrate the day the

00:17:00,140 --> 00:17:04,490
detector it's a flat fielding exercise

00:17:01,580 --> 00:17:06,830
so this is a real notebook that they

00:17:04,490 --> 00:17:08,950
that they gave us I think it's it's

00:17:06,830 --> 00:17:11,450
pretty old now so there might be some

00:17:08,950 --> 00:17:14,000
annoying old warnings but we're actually

00:17:11,450 --> 00:17:18,050
interacting with data that's living on

00:17:14,000 --> 00:17:18,350
the nurse global file system at nurse

00:17:18,050 --> 00:17:20,780
k--

00:17:18,350 --> 00:17:22,730
and so of course the entire experiment

00:17:20,780 --> 00:17:24,590
if you've ever worked on an experiment

00:17:22,730 --> 00:17:25,940
like this i mean you know you do an

00:17:24,590 --> 00:17:27,350
analysis and you tell your adviser

00:17:25,940 --> 00:17:29,210
here's what i did and of course it's

00:17:27,350 --> 00:17:30,800
like they figure out that you did

00:17:29,210 --> 00:17:32,360
something wrong and here you can

00:17:30,800 --> 00:17:34,100
actually show them everything that

00:17:32,360 --> 00:17:35,120
you've done wrong and they can say you

00:17:34,100 --> 00:17:38,220
know you should really pick a different

00:17:35,120 --> 00:17:40,000
threshold or something like that so

00:17:38,220 --> 00:17:41,740
everybody in the experiment basically

00:17:40,000 --> 00:17:43,509
can see so this is kind of what the

00:17:41,740 --> 00:17:50,139
pulse rates look like or pulse what's

00:17:43,509 --> 00:17:52,960
look like we expect radioactive decay to

00:17:50,139 --> 00:18:03,210
look a particular way that's what this

00:17:52,960 --> 00:18:03,210
plot is here some filtering

00:18:13,390 --> 00:18:19,140
or Wireless please stop watching movies

00:18:17,140 --> 00:18:21,490
if that's what you're doing out there

00:18:19,140 --> 00:18:23,470
this is the correction factor basically

00:18:21,490 --> 00:18:26,200
the flat fielding thing and if you do

00:18:23,470 --> 00:18:29,160
this right what it should look like at

00:18:26,200 --> 00:18:32,890
the end of the day is completely flat

00:18:29,160 --> 00:18:34,570
why can't I scroll there you go okay so

00:18:32,890 --> 00:18:38,790
it's all been corrected for the pulse

00:18:34,570 --> 00:18:42,070
widths and the second example is kind of

00:18:38,790 --> 00:18:43,929
gonna show off basically that we are

00:18:42,070 --> 00:18:46,720
running this notebook actually on a

00:18:43,929 --> 00:18:51,280
login note on the supercomputer so it's

00:18:46,720 --> 00:18:53,350
got 32 Haswell CPUs and about 500

00:18:51,280 --> 00:18:55,809
gigabytes of virtual of memory of total

00:18:53,350 --> 00:18:59,530
memory there we can see the scratch file

00:18:55,809 --> 00:19:02,770
system you can see I probably need to

00:18:59,530 --> 00:19:06,790
clean some stuff up there before they

00:19:02,770 --> 00:19:07,929
purge me one of the things that you

00:19:06,790 --> 00:19:09,160
couldn't get from the original

00:19:07,929 --> 00:19:10,630
implementation which was running in a

00:19:09,160 --> 00:19:13,299
docker containers it's not the exact

00:19:10,630 --> 00:19:15,340
same Python environment and so this

00:19:13,299 --> 00:19:18,549
leads all kinds of problems when users

00:19:15,340 --> 00:19:20,890
want to you know migrate their workflow

00:19:18,549 --> 00:19:22,510
from Cori to the Jupiter notebook or

00:19:20,890 --> 00:19:24,370
back and forth and so actually having

00:19:22,510 --> 00:19:29,190
just a single environment that they can

00:19:24,370 --> 00:19:29,190
use on on the system that's a big plus

00:19:29,640 --> 00:19:37,750
so batch queues are fun to submit your

00:19:34,360 --> 00:19:39,640
jobs to and then wait maybe a couple of

00:19:37,750 --> 00:19:42,160
days to see when your job is gonna run

00:19:39,640 --> 00:19:44,380
so here's some examples of slurm magic

00:19:42,160 --> 00:19:46,150
so you can see all the jobs that are

00:19:44,380 --> 00:19:52,120
kind of waiting in the queue or running

00:19:46,150 --> 00:19:54,700
or configuring nodes to run and oh it

00:19:52,120 --> 00:19:56,710
actually picks up my particular way of

00:19:54,700 --> 00:19:59,820
liking to format the output of the SQ

00:19:56,710 --> 00:20:02,470
command which shows me all of these jobs

00:19:59,820 --> 00:20:06,580
the output is actually in a panda's data

00:20:02,470 --> 00:20:08,710
frame so if you're waiting for your job

00:20:06,580 --> 00:20:11,080
to run and you want to do did something

00:20:08,710 --> 00:20:13,059
and you want to do some data science on

00:20:11,080 --> 00:20:14,530
everybody else's jobs like figure out

00:20:13,059 --> 00:20:18,370
how long it's going to take for your job

00:20:14,530 --> 00:20:22,480
to run you can do that you can actually

00:20:18,370 --> 00:20:25,450
submit jobs from cells that's a simple

00:20:22,480 --> 00:20:28,299
job that just prints out hostname

00:20:25,450 --> 00:20:33,010
and I'd be surprised if I actually get

00:20:28,299 --> 00:20:34,330
to get this job actually done or not

00:20:33,010 --> 00:20:35,950
it's probably not going to run in the

00:20:34,330 --> 00:20:37,779
amount of time that I'm gonna have here

00:20:35,950 --> 00:20:41,620
so I can't show you the output but it's

00:20:37,779 --> 00:20:45,279
gonna print out a hostname for for a

00:20:41,620 --> 00:20:48,070
compute node basically alright so you

00:20:45,279 --> 00:20:50,169
can submit jobs this is on a specialized

00:20:48,070 --> 00:20:51,880
login node that was set aside for

00:20:50,169 --> 00:20:54,909
running Jupiter when we bought the

00:20:51,880 --> 00:20:57,580
machine right so what are we going to do

00:20:54,909 --> 00:20:58,929
in the future so Travis mentioned the

00:20:57,580 --> 00:21:02,260
first incarnation had about a hundred

00:20:58,929 --> 00:21:03,820
users and that rapidly you know they

00:21:02,260 --> 00:21:06,010
were rapidly stepping on each other and

00:21:03,820 --> 00:21:08,409
so we needed to expand the service we

00:21:06,010 --> 00:21:10,539
added the Cori login node version of our

00:21:08,409 --> 00:21:12,340
Jupiter hub installation and the next

00:21:10,539 --> 00:21:14,169
step is going to be getting users

00:21:12,340 --> 00:21:17,289
actually running Jupiter notebooks on

00:21:14,169 --> 00:21:20,260
the compute nodes on the christum and so

00:21:17,289 --> 00:21:22,059
how are we going to do this this another

00:21:20,260 --> 00:21:24,760
picture of our system there's 10,000

00:21:22,059 --> 00:21:26,679
nodes in all those cabinets and I should

00:21:24,760 --> 00:21:29,409
mention we're number six on top 500

00:21:26,679 --> 00:21:30,789
right now the way that this is going to

00:21:29,409 --> 00:21:33,130
work is that we're going to enable

00:21:30,789 --> 00:21:35,470
access to the system through a few

00:21:33,130 --> 00:21:38,889
specialized queues and interactive queue

00:21:35,470 --> 00:21:41,590
which is going to in is which is enabled

00:21:38,889 --> 00:21:43,960
by a rack of nodes that's just set aside

00:21:41,590 --> 00:21:46,029
for interactive workflow so you can

00:21:43,960 --> 00:21:48,580
submit a job and you get a basically

00:21:46,029 --> 00:21:51,010
within a couple of minutes you get you

00:21:48,580 --> 00:21:53,789
get a node or up to 20 nodes for four

00:21:51,010 --> 00:21:56,289
hours so you can actually do interactive

00:21:53,789 --> 00:21:58,450
exploration of data on a computer note

00:21:56,289 --> 00:22:01,630
or on a small mini cluster running

00:21:58,450 --> 00:22:03,880
inside of of the system so that becomes

00:22:01,630 --> 00:22:06,250
feasible so that the the green box at

00:22:03,880 --> 00:22:08,049
the top is what we've got now it's one

00:22:06,250 --> 00:22:09,549
of these you know login nodes which is

00:22:08,049 --> 00:22:11,409
kind of on the outside of the network of

00:22:09,549 --> 00:22:13,630
the system but it's still attached to

00:22:11,409 --> 00:22:16,360
the system the gold boxes are a couple

00:22:13,630 --> 00:22:19,090
of Representative kind of configurations

00:22:16,360 --> 00:22:20,679
for what we are working on right now and

00:22:19,090 --> 00:22:22,600
so this would be like just migrating

00:22:20,679 --> 00:22:24,159
your your your workflow from the quarry

00:22:22,600 --> 00:22:25,360
login node out to a single quarry

00:22:24,159 --> 00:22:28,380
compute node where you're running a

00:22:25,360 --> 00:22:30,970
notebook and some kernel processes or a

00:22:28,380 --> 00:22:33,159
single quarry compute node running a

00:22:30,970 --> 00:22:35,590
notebook server and a whole bunch of

00:22:33,159 --> 00:22:36,789
other quarry compute nodes maybe 100

00:22:35,590 --> 00:22:37,600
nodes or something like that they're

00:22:36,789 --> 00:22:40,990
running a bunch of

00:22:37,600 --> 00:22:44,039
no processes so we're thinking about the

00:22:40,990 --> 00:22:46,600
end we're thinking about these kinds of

00:22:44,039 --> 00:22:50,919
configurations running desk jobs or

00:22:46,600 --> 00:22:55,840
spark powered by Jupiter we've done both

00:22:50,919 --> 00:22:57,880
of those haven't had users really really

00:22:55,840 --> 00:22:59,679
take off with them yet but we know

00:22:57,880 --> 00:23:01,809
they're coming oh there's a whole bunch

00:22:59,679 --> 00:23:04,030
of arrows on this that's why I don't

00:23:01,809 --> 00:23:08,530
have a demo is because all the arrows

00:23:04,030 --> 00:23:09,610
make a demo really far too risky and so

00:23:08,530 --> 00:23:12,130
what we're gonna do is we're gonna

00:23:09,610 --> 00:23:13,510
leverage Software Defined Networking so

00:23:12,130 --> 00:23:15,789
that once the user is authenticated

00:23:13,510 --> 00:23:17,770
through our gsi Authenticator or

00:23:15,789 --> 00:23:19,960
whatever Authenticator we actually end

00:23:17,770 --> 00:23:22,240
up using the head node of the job

00:23:19,960 --> 00:23:25,150
allocation will advertise an IP an

00:23:22,240 --> 00:23:26,549
external IP address back to the user and

00:23:25,150 --> 00:23:30,730
they'll just be able to connect directly

00:23:26,549 --> 00:23:35,500
that's a pretty new capability for us on

00:23:30,730 --> 00:23:37,179
these crazy systems another modality I

00:23:35,500 --> 00:23:40,750
guess is basically you could have a

00:23:37,179 --> 00:23:42,640
long-running notebook process running on

00:23:40,750 --> 00:23:44,650
that service node on that log Jupiter

00:23:42,640 --> 00:23:46,510
node and then submit jobs and then

00:23:44,650 --> 00:23:48,520
connect to your jobs your kernels or

00:23:46,510 --> 00:23:50,080
your cluster that are is running out on

00:23:48,520 --> 00:23:52,390
the on the compute nodes and manage

00:23:50,080 --> 00:23:54,280
workflows through through a notebook

00:23:52,390 --> 00:23:57,580
interface and so we actually have a

00:23:54,280 --> 00:23:59,530
project there's a LD Rd project led by

00:23:57,580 --> 00:24:02,020
shreya sand matt henderson matt had a

00:23:59,530 --> 00:24:06,909
very nice poster yesterday about this

00:24:02,020 --> 00:24:08,440
project kali so and Oliver who's who's

00:24:06,909 --> 00:24:10,929
over in the corner okay

00:24:08,440 --> 00:24:13,750
so this is about real-time monitoring of

00:24:10,929 --> 00:24:15,429
HPC jobs and output widgets dashboards

00:24:13,750 --> 00:24:18,789
for a job output management it's a lot

00:24:15,429 --> 00:24:20,590
nicer maybe been SQ but really putting

00:24:18,789 --> 00:24:22,510
together workflows a lot of these

00:24:20,590 --> 00:24:24,730
experimental data analysis workflows are

00:24:22,510 --> 00:24:26,770
things that have a lot of parallelism

00:24:24,730 --> 00:24:28,809
and then like almost no parallelism and

00:24:26,770 --> 00:24:30,549
then lots of parallelism and then some

00:24:28,809 --> 00:24:33,039
human and the loop kind of stuff and so

00:24:30,549 --> 00:24:36,159
putting that together in a through

00:24:33,039 --> 00:24:39,159
Jupiter's what this project is about so

00:24:36,159 --> 00:24:41,190
our hope is that within the next couple

00:24:39,159 --> 00:24:43,030
of months we'll will have the ultimate

00:24:41,190 --> 00:24:45,909
configuration of Jupiter at nurse

00:24:43,030 --> 00:24:47,679
running like I mentioned Software

00:24:45,909 --> 00:24:50,559
Defined Networking is going to have a

00:24:47,679 --> 00:24:51,420
very big role here advertising notebook

00:24:50,559 --> 00:24:54,120
server

00:24:51,420 --> 00:24:56,340
P addresses back to users different ways

00:24:54,120 --> 00:24:58,020
of running notebooks and kernels

00:24:56,340 --> 00:25:00,330
different kind of combinations your

00:24:58,020 --> 00:25:02,040
whole job your whole workflow being in

00:25:00,330 --> 00:25:06,180
the compute nodes or may be split across

00:25:02,040 --> 00:25:09,660
compute nodes and login nodes leveraging

00:25:06,180 --> 00:25:11,400
interactive cues one of the things that

00:25:09,660 --> 00:25:14,820
Shreyas mentioned is that we have a

00:25:11,400 --> 00:25:19,110
containerized or we have containers in

00:25:14,820 --> 00:25:21,420
HPC now based on docker a system that we

00:25:19,110 --> 00:25:23,880
developed called shifter we're going to

00:25:21,420 --> 00:25:26,430
be exposing the ability to run docker

00:25:23,880 --> 00:25:28,650
containers with your entire Python

00:25:26,430 --> 00:25:30,420
environment if you want in those and

00:25:28,650 --> 00:25:32,040
you'll just spin throw those out to the

00:25:30,420 --> 00:25:34,500
compute nodes and be able to connect up

00:25:32,040 --> 00:25:37,530
to those and really actually on a crazy

00:25:34,500 --> 00:25:39,480
system because of the way the file

00:25:37,530 --> 00:25:41,100
system is configured this is really the

00:25:39,480 --> 00:25:44,460
only way that we're gonna be able to to

00:25:41,100 --> 00:25:46,650
scale up large scale especially Python

00:25:44,460 --> 00:25:47,970
applications there a number of other

00:25:46,650 --> 00:25:50,640
possibilities that we're looking into

00:25:47,970 --> 00:25:52,650
running the notebook or schedulers like

00:25:50,640 --> 00:25:55,020
desk schedulers on one partition of the

00:25:52,650 --> 00:25:57,570
system and having jobs that span both

00:25:55,020 --> 00:25:59,160
the data friendly partition and then the

00:25:57,570 --> 00:26:03,090
many-core partitioned is this nice

00:25:59,160 --> 00:26:05,580
landing partition in addition to the

00:26:03,090 --> 00:26:07,680
customizations to the spawner and the

00:26:05,580 --> 00:26:10,650
Authenticator classes that Tres

00:26:07,680 --> 00:26:13,290
mentioned we're adding additional stuff

00:26:10,650 --> 00:26:14,790
that kind of customizes Jupiter to the

00:26:13,290 --> 00:26:17,070
nurse-in

00:26:14,790 --> 00:26:19,440
ecosystem and this is all based off of

00:26:17,070 --> 00:26:20,550
rap spawner and badger spawner but

00:26:19,440 --> 00:26:22,050
basically we'll be able to expose

00:26:20,550 --> 00:26:25,220
resources like do you want the burst

00:26:22,050 --> 00:26:27,510
buffer that that layer of fast NVRAM

00:26:25,220 --> 00:26:29,760
included in your job do you want to run

00:26:27,510 --> 00:26:32,040
your job on a quarry node a compute node

00:26:29,760 --> 00:26:34,380
on an edge service node maybe on a

00:26:32,040 --> 00:26:37,320
different supercomputer in the system or

00:26:34,380 --> 00:26:39,240
at the center and also we want to

00:26:37,320 --> 00:26:40,620
customize the user experience so that

00:26:39,240 --> 00:26:44,160
you know you don't have to remember all

00:26:40,620 --> 00:26:46,410
of your say allocation repos and type in

00:26:44,160 --> 00:26:48,990
each one of them it should know what

00:26:46,410 --> 00:26:51,240
what repos you can actually charge to or

00:26:48,990 --> 00:26:53,280
maybe allow users to sort of set up job

00:26:51,240 --> 00:26:57,240
templates of their own and select which

00:26:53,280 --> 00:26:59,640
one they're going to run so none of this

00:26:57,240 --> 00:27:02,700
would have been possible without a lot

00:26:59,640 --> 00:27:04,740
of help from other people msi attack and

00:27:02,700 --> 00:27:05,380
SD SD have have given us a lot of the

00:27:04,740 --> 00:27:07,540
pieces or

00:27:05,380 --> 00:27:09,280
showing us the way to how to how to

00:27:07,540 --> 00:27:12,160
customize different aspects of the

00:27:09,280 --> 00:27:14,290
Jupiter ecosystem so that we can you

00:27:12,160 --> 00:27:16,420
know we can adapt it to our environment

00:27:14,290 --> 00:27:18,760
of course the jupiter dev team has been

00:27:16,420 --> 00:27:22,030
exceedingly helpful and answering

00:27:18,760 --> 00:27:24,070
questions so this slide is just about

00:27:22,030 --> 00:27:26,830
letting you know that you know we're

00:27:24,070 --> 00:27:28,810
we're providing Jupiter to users maybe

00:27:26,830 --> 00:27:30,190
in a different context from a lot of the

00:27:28,810 --> 00:27:31,810
other kinds of things that we see at

00:27:30,190 --> 00:27:37,180
this conference so this is you know big

00:27:31,810 --> 00:27:38,920
science and Jupiter is extremely popular

00:27:37,180 --> 00:27:40,750
there we don't have a hundred thousand

00:27:38,920 --> 00:27:43,300
users at nurse but we have seven

00:27:40,750 --> 00:27:45,100
thousand users and almost every one of

00:27:43,300 --> 00:27:46,720
them uses Python in some way and a

00:27:45,100 --> 00:27:50,070
substantial fraction of them are

00:27:46,720 --> 00:27:52,960
expecting to be able to use Jupiter

00:27:50,070 --> 00:27:55,180
we're working on ways to figure out how

00:27:52,960 --> 00:27:57,700
to scale up jobs using Jupiter to handle

00:27:55,180 --> 00:28:00,280
the large data sets multi hundred

00:27:57,700 --> 00:28:01,810
terabyte petabyte data sets that that

00:28:00,280 --> 00:28:04,900
are going to be resident at at Newark in

00:28:01,810 --> 00:28:07,510
the next few years and then especially

00:28:04,900 --> 00:28:09,010
for the Jupiter Khan audience

00:28:07,510 --> 00:28:10,840
we thought we'd outline a couple

00:28:09,010 --> 00:28:13,170
high-level takeaways which was most of

00:28:10,840 --> 00:28:15,000
what we've done has really just been

00:28:13,170 --> 00:28:18,550
customizing or extending existing

00:28:15,000 --> 00:28:20,980
interfaces and the nurse ecosystem for

00:28:18,550 --> 00:28:23,170
the nurse ecosystem and so we really

00:28:20,980 --> 00:28:24,670
appreciate the thought and hard work

00:28:23,170 --> 00:28:26,500
that went into designing these

00:28:24,670 --> 00:28:29,500
interfaces and figuring out what the

00:28:26,500 --> 00:28:31,870
right abstractions are because you know

00:28:29,500 --> 00:28:34,930
when we don't have to hack somebody

00:28:31,870 --> 00:28:37,600
else's code just implement what we need

00:28:34,930 --> 00:28:39,250
it's it's really a lot nicer and a lot

00:28:37,600 --> 00:28:41,560
easier for us to maintain and explain to

00:28:39,250 --> 00:28:44,200
our security people and our management

00:28:41,560 --> 00:28:46,420
what we're doing actually external to

00:28:44,200 --> 00:28:48,550
that we have had to add some I would

00:28:46,420 --> 00:28:51,160
just say hacks I guess to make things

00:28:48,550 --> 00:28:53,560
work helper scripts on the on the on the

00:28:51,160 --> 00:28:55,420
compute system we also have to kind of

00:28:53,560 --> 00:28:57,610
negotiate or work with the networking

00:28:55,420 --> 00:28:58,930
team to change configuration so that we

00:28:57,610 --> 00:29:01,060
can actually connect different parts of

00:28:58,930 --> 00:29:02,530
the supercomputer that initially weren't

00:29:01,060 --> 00:29:05,650
you know designed to talk to each other

00:29:02,530 --> 00:29:07,870
maybe out-of-the-box right and then we

00:29:05,650 --> 00:29:11,170
actually are leveraging an API for a

00:29:07,870 --> 00:29:14,380
supercomputing Center called neut which

00:29:11,170 --> 00:29:16,810
was designed and written by Shreyas here

00:29:14,380 --> 00:29:19,210
so that's that's going to be essential I

00:29:16,810 --> 00:29:22,480
think and of course what do our use

00:29:19,210 --> 00:29:25,090
say this is like the top comment that

00:29:22,480 --> 00:29:27,850
they don't ever want to SSH in anymore

00:29:25,090 --> 00:29:29,559
and in fact we envision that there's

00:29:27,850 --> 00:29:31,600
going to be a very large class of users

00:29:29,559 --> 00:29:34,059
in the future who probably never SSH

00:29:31,600 --> 00:29:35,440
into a command line on Corey or any of

00:29:34,059 --> 00:29:38,669
our systems and just interact through

00:29:35,440 --> 00:29:52,059
Jupiter okay

00:29:38,669 --> 00:29:54,580
so that's it Thanks we have ten minutes

00:29:52,059 --> 00:29:56,260
for your questions and Shreyas from hall

00:29:54,580 --> 00:30:08,440
and if you can repeat the questions for

00:29:56,260 --> 00:30:18,610
the audio I think that'll help the lux

00:30:08,440 --> 00:30:21,580
data set oh it isn't oh yeah I don't

00:30:18,610 --> 00:30:22,840
know I don't think that this is a really

00:30:21,580 --> 00:30:25,029
huge data set I think we're talking

00:30:22,840 --> 00:30:26,250
about much less than a maybe a few

00:30:25,029 --> 00:30:29,250
hundred gigabytes worth of data

00:30:26,250 --> 00:30:29,250
basically

00:30:58,090 --> 00:31:04,450
sure sure yeah so the question was about

00:31:02,020 --> 00:31:06,250
the the root colonel that that Reyes

00:31:04,450 --> 00:31:08,200
showed

00:31:06,250 --> 00:31:09,700
yeah we can we can talk about that and

00:31:08,200 --> 00:31:11,950
actually if if you have questions about

00:31:09,700 --> 00:31:13,779
what we did to set it up to set that up

00:31:11,950 --> 00:31:16,179
it was it was pretty easy it was really

00:31:13,779 --> 00:31:32,640
not much more than defining that that

00:31:16,179 --> 00:31:46,110
one Colonel spec file after we had okay

00:31:32,640 --> 00:31:48,070
all right sure yeah how do we submit

00:31:46,110 --> 00:31:50,250
spark jobs

00:31:48,070 --> 00:31:53,429
[Music]

00:31:50,250 --> 00:31:53,429
with what

00:31:56,099 --> 00:32:02,469
yeah so what I'll say about spark and

00:32:00,369 --> 00:32:06,219
analytic software on a crisis tone is

00:32:02,469 --> 00:32:10,149
that you know the supercomputing vendors

00:32:06,219 --> 00:32:12,099
realize that there is a need for tools

00:32:10,149 --> 00:32:14,979
like this on their systems and so there

00:32:12,099 --> 00:32:17,109
but working out with them exactly how

00:32:14,979 --> 00:32:19,539
you do this in their environment it's

00:32:17,109 --> 00:32:21,759
it's kind of a partnership and so that

00:32:19,539 --> 00:32:24,729
means that we develop a lot of tools

00:32:21,759 --> 00:32:26,199
ourselves that because maybe off the

00:32:24,729 --> 00:32:28,509
commercial off-the-shelf solutions like

00:32:26,199 --> 00:32:31,149
maybe what you're talking about are just

00:32:28,509 --> 00:32:33,369
not built for are not engineered with

00:32:31,149 --> 00:32:34,869
the Cray system in mind and so we do

00:32:33,369 --> 00:32:36,729
have to do quite a bit of customization

00:32:34,869 --> 00:32:40,359
we actually use I think we leverage

00:32:36,729 --> 00:32:43,149
docker quite a bit actually to to manage

00:32:40,359 --> 00:32:44,529
large scale SPARC jobs the actual

00:32:43,149 --> 00:32:46,539
submission we basically would just at

00:32:44,529 --> 00:32:50,499
the job the head node that sort of

00:32:46,539 --> 00:32:52,149
shares the same note is as the jupiter

00:32:50,499 --> 00:33:01,889
login node and then you can communicate

00:32:52,149 --> 00:33:03,909
with that yeah exactly yep yep yeah so

00:33:01,889 --> 00:33:05,559
yeah you have to basically be able to

00:33:03,909 --> 00:33:07,419
talk to the SPARC head node directly so

00:33:05,559 --> 00:33:10,719
yeah sorry now we submitted all this one

00:33:07,419 --> 00:33:12,249
job and usually SPARC jobs are just

00:33:10,719 --> 00:33:14,319
submitted as regular jobs and they're

00:33:12,249 --> 00:33:15,609
not attached to Jupiter quite yet to

00:33:14,319 --> 00:33:18,549
make that work we have to do something

00:33:15,609 --> 00:33:19,959
like be able to you know finish the the

00:33:18,549 --> 00:33:22,659
Software Defined Networking piece so

00:33:19,959 --> 00:33:24,429
that we can actually run that in the

00:33:22,659 --> 00:33:26,940
same cluster basically as the spark

00:33:24,429 --> 00:33:29,169
cluster that's running or we have to

00:33:26,940 --> 00:33:31,089
kind of reverse the way that the network

00:33:29,169 --> 00:33:33,999
is working so that we can expose the

00:33:31,089 --> 00:33:35,709
login node onto the same network as all

00:33:33,999 --> 00:33:39,789
of the compute nodes and interact that

00:33:35,709 --> 00:33:44,849
way and so both both we have plans to to

00:33:39,789 --> 00:33:44,849
set up both of those kinds of workflows

00:33:59,240 --> 00:34:03,809
know so that the Jupiter hub servers

00:34:01,799 --> 00:34:06,600
actually just on a separate node

00:34:03,809 --> 00:34:08,990
entirely because the the hub server that

00:34:06,600 --> 00:34:11,250
would under the new sort of in or the

00:34:08,990 --> 00:34:14,490
yeah so the hub server is basically a

00:34:11,250 --> 00:34:16,770
separate service and its uses the SSH

00:34:14,490 --> 00:34:21,810
spawner to go off and spawn notebooks on

00:34:16,770 --> 00:34:23,550
this big giant login node with and what

00:34:21,810 --> 00:34:25,470
we're moving towards this idea of being

00:34:23,550 --> 00:34:27,149
able to use that to spawn notebooks not

00:34:25,470 --> 00:34:29,540
just on the login nodes but also on the

00:34:27,149 --> 00:34:29,540
compute nodes

00:34:45,040 --> 00:34:49,869
have you recently figured out a way

00:34:47,300 --> 00:34:49,869
around

00:34:55,960 --> 00:35:00,849
so yeah so the the the question was

00:34:58,660 --> 00:35:02,380
about the environment right having two

00:35:00,849 --> 00:35:04,720
environments one in the docker container

00:35:02,380 --> 00:35:06,190
which was separate from the actual

00:35:04,720 --> 00:35:10,150
Python environment that's running on

00:35:06,190 --> 00:35:12,160
Cori and the the second iteration of our

00:35:10,150 --> 00:35:13,869
architecture solves that problem by just

00:35:12,160 --> 00:35:15,700
having the hub piece be in the docker

00:35:13,869 --> 00:35:19,059
container and then spawn the notebook

00:35:15,700 --> 00:35:21,640
the notebook server actually on the

00:35:19,059 --> 00:35:23,470
commanda on the compute system and so

00:35:21,640 --> 00:35:26,200
then you know they just pick up whatever

00:35:23,470 --> 00:35:28,300
anaconda Python we we're running on on

00:35:26,200 --> 00:35:31,180
Cori that's you know that's backing that

00:35:28,300 --> 00:35:32,589
and so that's the same exact Python they

00:35:31,180 --> 00:35:35,800
would get from a module load when they

00:35:32,589 --> 00:35:38,710
log in via SSH so the idea is you just

00:35:35,800 --> 00:35:50,020
decouple the hub from the act the rest

00:35:38,710 --> 00:35:51,579
of the service that's why we have to

00:35:50,020 --> 00:35:53,050
that's why we have to get this

00:35:51,579 --> 00:35:54,579
software-defined networking business

00:35:53,050 --> 00:35:58,809
going because there's about a hundred

00:35:54,579 --> 00:36:00,640
users hundred unique users just today

00:35:58,809 --> 00:36:02,680
there are 50 notebook servers running

00:36:00,640 --> 00:36:04,900
today on that one login node and if

00:36:02,680 --> 00:36:06,819
you've ever used the system like this

00:36:04,900 --> 00:36:08,349
you know that you know the system

00:36:06,819 --> 00:36:11,349
administrator will come along and bash

00:36:08,349 --> 00:36:13,000
you if you if you do computing stuff on

00:36:11,349 --> 00:36:14,920
the login code right but we've got it

00:36:13,000 --> 00:36:17,380
this is a special login node where we

00:36:14,920 --> 00:36:19,210
let them do that kind of stuff but even

00:36:17,380 --> 00:36:20,440
today they're stomping on each other

00:36:19,210 --> 00:36:24,460
yeah I mean it's a big note it's got

00:36:20,440 --> 00:36:26,049
like what's 768 gigs of ram and lots of

00:36:24,460 --> 00:36:27,460
CPUs but at some point you run up

00:36:26,049 --> 00:36:30,490
against a commit and really they're not

00:36:27,460 --> 00:36:32,530
all computing all at the same time we

00:36:30,490 --> 00:36:34,510
don't have resource limits in place yet

00:36:32,530 --> 00:36:36,700
but I think we're getting there and I

00:36:34,510 --> 00:36:38,049
think that imposition of resource limits

00:36:36,700 --> 00:36:39,430
is going to be something that's going to

00:36:38,049 --> 00:36:42,190
drive the users to say look give me

00:36:39,430 --> 00:36:44,470
another option and so that's why the you

00:36:42,190 --> 00:36:46,150
know running Jupiter jobs on the compute

00:36:44,470 --> 00:36:48,099
nodes is something we really need to get

00:36:46,150 --> 00:36:50,400
going here in the next couple of months

00:36:48,099 --> 00:36:50,400
I think

00:36:53,940 --> 00:36:57,580
yeah I mean so we were gonna that that's

00:36:56,170 --> 00:36:59,980
where you have to put you limits and

00:36:57,580 --> 00:37:01,480
make sure that people don't have it's

00:36:59,980 --> 00:37:03,490
kind of the same problem as any other

00:37:01,480 --> 00:37:06,130
login node that you have with with users

00:37:03,490 --> 00:37:07,810
right so the question was well what can

00:37:06,130 --> 00:37:23,440
users essentially take down the service

00:37:07,810 --> 00:37:25,360
I think with last question yeah yeah so

00:37:23,440 --> 00:37:26,980
I don't think it impacts the hub part of

00:37:25,360 --> 00:37:30,010
it because you still want people to come

00:37:26,980 --> 00:37:31,450
in through that one common interface so

00:37:30,010 --> 00:37:34,540
really what it'll do is it'll allow us

00:37:31,450 --> 00:37:36,850
to create a virtual tunnel between the

00:37:34,540 --> 00:37:39,970
hub and the backend nodes because right

00:37:36,850 --> 00:37:42,280
now you can't go both ways you can only

00:37:39,970 --> 00:37:43,330
pull from a login node so yeah the

00:37:42,280 --> 00:37:46,420
question was whether Software Defined

00:37:43,330 --> 00:37:47,980
Networking will allow us to remove the

00:37:46,420 --> 00:37:50,050
hub as a proxy and maybe we can look

00:37:47,980 --> 00:37:51,550
into that but our plans right now are to

00:37:50,050 --> 00:37:53,350
still have people funnel through the hub

00:37:51,550 --> 00:37:58,000
because it gives us a single point of

00:37:53,350 --> 00:38:00,600
control there is that right I mean I

00:37:58,000 --> 00:38:02,920
think that's about right that's yeah

00:38:00,600 --> 00:38:07,630
thank you

00:38:02,920 --> 00:38:07,630

YouTube URL: https://www.youtube.com/watch?v=m3LFm22Om60


