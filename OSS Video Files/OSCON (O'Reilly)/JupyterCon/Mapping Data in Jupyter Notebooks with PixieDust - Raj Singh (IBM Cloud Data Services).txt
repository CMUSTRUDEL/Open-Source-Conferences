Title: Mapping Data in Jupyter Notebooks with PixieDust - Raj Singh (IBM Cloud Data Services)
Publication date: 2017-11-08
Playlist: JupyterCon
Description: 
	Raj Singh offers an overview of PixieDust, a Jupyter Notebook extension that provides an easy way to make interactive maps from DataFrames for visual exploratory data analysis. Raj explains how he built mapping into PixieDust, putting data from Apache Spark-based analytics on maps using Mapbox GL.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,530 --> 00:00:06,689
hi I'm Raj Singh I'm a developer

00:00:04,140 --> 00:00:09,839
advocate with IBM cloud and Watson

00:00:06,689 --> 00:00:11,700
platform so my job as a developer

00:00:09,839 --> 00:00:16,289
advocate is to help make people like you

00:00:11,700 --> 00:00:17,760
more productive on the IBM cloud but I

00:00:16,289 --> 00:00:19,650
haven't been doing this that long I've

00:00:17,760 --> 00:00:22,740
mainly been a geospatial professional

00:00:19,650 --> 00:00:24,750
for 20 years and so bringing what I'm

00:00:22,740 --> 00:00:27,390
going to show you today mapping to the

00:00:24,750 --> 00:00:29,250
data science platform means a lot to me

00:00:27,390 --> 00:00:31,290
I'm very excited about bringing some of

00:00:29,250 --> 00:00:34,460
this stuff that's been sort of locked in

00:00:31,290 --> 00:00:35,609
the world of GIS and geospatial

00:00:34,460 --> 00:00:40,339
analytics

00:00:35,609 --> 00:00:47,159
to the larger mainstream analytics world

00:00:40,339 --> 00:00:51,239
so you know I spend a lot of time

00:00:47,159 --> 00:00:53,280
actually at MIT in the 90s doing before

00:00:51,239 --> 00:00:54,539
it was called data science spent a lot

00:00:53,280 --> 00:00:56,969
of time in grad school working with

00:00:54,539 --> 00:00:59,909
census data which at the time was really

00:00:56,969 --> 00:01:01,620
large data we had to wait till like

00:00:59,909 --> 00:01:04,710
midnight when the when the US government

00:01:01,620 --> 00:01:06,719
server FTP servers weren't too busy and

00:01:04,710 --> 00:01:09,030
download big census data files and then

00:01:06,719 --> 00:01:11,460
put them somewhere and use them and and

00:01:09,030 --> 00:01:15,180
do some analytics on them and then make

00:01:11,460 --> 00:01:16,829
maps by hand and then luckily the census

00:01:15,180 --> 00:01:20,759
data only changes every 10 years so it

00:01:16,829 --> 00:01:23,520
wasn't a big deal but you know that kind

00:01:20,759 --> 00:01:27,180
of gave me the first flavor of how

00:01:23,520 --> 00:01:29,219
monotonous and redundant and a lot of

00:01:27,180 --> 00:01:32,280
our work is until we get to the real

00:01:29,219 --> 00:01:34,799
payoff which is actually studying some

00:01:32,280 --> 00:01:37,560
topic doing some analysis tackling some

00:01:34,799 --> 00:01:41,280
real problem so it's really exciting to

00:01:37,560 --> 00:01:42,840
see at this conference and add a lot of

00:01:41,280 --> 00:01:45,390
you know I said pie data a few weeks ago

00:01:42,840 --> 00:01:47,009
and this is the logical progression into

00:01:45,390 --> 00:01:50,159
more specialization Jupiter but

00:01:47,009 --> 00:01:55,409
everybody's moving to awesome analytics

00:01:50,159 --> 00:01:57,630
on the on cloud platforms so my talk is

00:01:55,409 --> 00:02:00,119
about Jupiter which everybody here

00:01:57,630 --> 00:02:02,070
obviously knows well pixie-dust

00:02:00,119 --> 00:02:04,530
my colleague David tyub gave a

00:02:02,070 --> 00:02:06,359
presentation on a lot of the non spatial

00:02:04,530 --> 00:02:08,959
visualization pieces of it this morning

00:02:06,359 --> 00:02:15,140
and I hope you saw us at the booth and

00:02:08,959 --> 00:02:15,140
my thing is on maps so

00:02:15,400 --> 00:02:21,170
gonna start here so I love this quote

00:02:19,489 --> 00:02:25,069
this is stuck with me for a couple years

00:02:21,170 --> 00:02:27,709
and this is about over 10 years old now

00:02:25,069 --> 00:02:31,910
but I love this good programmers are

00:02:27,709 --> 00:02:34,190
lazy and dumb because a lot of the

00:02:31,910 --> 00:02:36,080
motivation of programming came out of

00:02:34,190 --> 00:02:41,299
not wanting to repeatedly write the same

00:02:36,080 --> 00:02:42,410
code over and over again and first of

00:02:41,299 --> 00:02:45,200
all we don't want to do that because

00:02:42,410 --> 00:02:46,910
we're lazy but second of all we don't

00:02:45,200 --> 00:02:50,950
want to write monotonous repetitive code

00:02:46,910 --> 00:02:53,420
because it introduces errors and finally

00:02:50,950 --> 00:02:54,650
if people are working on libraries

00:02:53,420 --> 00:02:56,750
libraries have been around for decades

00:02:54,650 --> 00:03:00,250
right people work on libraries together

00:02:56,750 --> 00:03:02,810
and continually improve those libraries

00:03:00,250 --> 00:03:05,060
everything speeds up everybody you know

00:03:02,810 --> 00:03:06,860
nobody writes on UNIX nobody writes

00:03:05,060 --> 00:03:08,780
sockets and threading anymore you just

00:03:06,860 --> 00:03:10,970
grab a library and it works really well

00:03:08,780 --> 00:03:12,170
better than you could write yourself so

00:03:10,970 --> 00:03:14,299
that's part of the motivation behind

00:03:12,170 --> 00:03:17,000
pixie-dust there's nothing magical here

00:03:14,299 --> 00:03:19,250
it's the automation of code that you

00:03:17,000 --> 00:03:21,829
could have written by hand but now is

00:03:19,250 --> 00:03:31,840
packaged up in a library which everybody

00:03:21,829 --> 00:03:33,920
can contribute to and improve so

00:03:31,840 --> 00:03:35,389
actually before I go on to this I want

00:03:33,920 --> 00:03:37,900
to ask a few questions who in the

00:03:35,389 --> 00:03:43,940
audience would consider themselves

00:03:37,900 --> 00:03:47,959
statistician few who considers themself

00:03:43,940 --> 00:03:50,599
a data scientists uh-huh

00:03:47,959 --> 00:03:53,959
good because people aren't lying how

00:03:50,599 --> 00:03:55,459
many people understand really feel like

00:03:53,959 --> 00:03:58,310
they understand what a data scientists

00:03:55,459 --> 00:04:00,519
job is and I'm keeping my hand down for

00:03:58,310 --> 00:04:00,519
a reason

00:04:01,480 --> 00:04:07,720
so how many people are this probably few

00:04:04,819 --> 00:04:13,880
how many people are web developers here

00:04:07,720 --> 00:04:15,290
okay so what are the rest of you and how

00:04:13,880 --> 00:04:19,669
many finally how many people have done a

00:04:15,290 --> 00:04:20,840
lot of mapping in their job okay so some

00:04:19,669 --> 00:04:23,300
people didn't raise their hands at all

00:04:20,840 --> 00:04:25,340
but and what final question when I give

00:04:23,300 --> 00:04:26,630
this presentation is who feels like they

00:04:25,340 --> 00:04:27,530
have to do a little bit of all this

00:04:26,630 --> 00:04:32,660
stuff in their job

00:04:27,530 --> 00:04:34,760
to be successful yes and so more of a

00:04:32,660 --> 00:04:39,370
reason why we need to use libraries

00:04:34,760 --> 00:04:42,500
right and not spend a lot of time

00:04:39,370 --> 00:04:44,180
repeating not only monotonous code but

00:04:42,500 --> 00:04:46,220
this stuff is hard to keep in your head

00:04:44,180 --> 00:04:48,230
if you're anything like me I probably

00:04:46,220 --> 00:04:51,230
spend more than half my time looking up

00:04:48,230 --> 00:04:53,540
the little details of a command like I

00:04:51,230 --> 00:04:56,600
know basically the command I want to use

00:04:53,540 --> 00:04:59,510
but I don't know all all the details of

00:04:56,600 --> 00:05:05,120
the parameters to get to get the same

00:04:59,510 --> 00:05:07,640
thing I got last week and that occurs

00:05:05,120 --> 00:05:09,770
through all kinds of different facets of

00:05:07,640 --> 00:05:12,040
what we have to do like the sexy stuff

00:05:09,770 --> 00:05:15,350
that our bosses want us to talk about or

00:05:12,040 --> 00:05:18,110
produces of visualization you spark and

00:05:15,350 --> 00:05:20,240
build the analyses and notebooks and

00:05:18,110 --> 00:05:22,040
throw some machine learning in there but

00:05:20,240 --> 00:05:25,160
to be able to do all that stuff we have

00:05:22,040 --> 00:05:27,200
to know all this you know in linear

00:05:25,160 --> 00:05:31,040
regression is really a statisticians

00:05:27,200 --> 00:05:33,320
expertise analysis of errors and alice

00:05:31,040 --> 00:05:35,000
is a variation data cleansing you know

00:05:33,320 --> 00:05:37,760
you have some data engineering jobs in

00:05:35,000 --> 00:05:39,800
here you've got a lot of the data

00:05:37,760 --> 00:05:42,039
science stuff at the top and you have a

00:05:39,800 --> 00:05:45,740
lot of database administrator

00:05:42,039 --> 00:05:47,240
administrators stuff in here and you

00:05:45,740 --> 00:05:50,060
know it all kind of has to come together

00:05:47,240 --> 00:05:53,560
in this thing we call data science so

00:05:50,060 --> 00:05:55,850
which kind of sucks for us so and then

00:05:53,560 --> 00:05:57,380
what we're able to get out of this in

00:05:55,850 --> 00:06:00,169
the end isn't that great

00:05:57,380 --> 00:06:05,150
you know if you're if you're building a

00:06:00,169 --> 00:06:06,979
matplotlib chart this is like 11:00 you

00:06:05,150 --> 00:06:09,860
know it's not too bad maybe about 10

00:06:06,979 --> 00:06:12,229
lines of code I never remember what the

00:06:09,860 --> 00:06:14,510
exact X&Y label code is so I'll spend

00:06:12,229 --> 00:06:16,610
some time looking that out finally get

00:06:14,510 --> 00:06:18,080
it out and at the end of it you know

00:06:16,610 --> 00:06:19,789
find some old notebook you did that has

00:06:18,080 --> 00:06:20,990
the code and after you spend half an

00:06:19,789 --> 00:06:22,970
hour finding that then you put this

00:06:20,990 --> 00:06:28,340
together and then that's not that great

00:06:22,970 --> 00:06:32,090
a chart is it kind of ugly and in

00:06:28,340 --> 00:06:33,650
mapping it's even worse so to make this

00:06:32,090 --> 00:06:37,039
thing which looks like something out of

00:06:33,650 --> 00:06:39,530
like Miss pac-man you have to write 20

00:06:37,039 --> 00:06:40,620
30 lines of code and matplotlib does

00:06:39,530 --> 00:06:44,010
have

00:06:40,620 --> 00:06:45,780
rapping library available but it doesn't

00:06:44,010 --> 00:06:48,060
do much of a great job what we really

00:06:45,780 --> 00:06:50,520
want lose something Google Maps kind of

00:06:48,060 --> 00:06:53,850
sets the bar on this is a map box map

00:06:50,520 --> 00:06:55,979
which is a partner of ours but that is a

00:06:53,850 --> 00:06:59,190
lot more what you want you can zoom into

00:06:55,979 --> 00:07:01,290
that and you get more you know more

00:06:59,190 --> 00:07:03,360
place names surfacing as you zoom in you

00:07:01,290 --> 00:07:05,760
get more detail on the underlying

00:07:03,360 --> 00:07:08,729
contextual geography and still see your

00:07:05,760 --> 00:07:14,000
data that's really what you want so and

00:07:08,729 --> 00:07:16,169
that's what pixie-dust will give you so

00:07:14,000 --> 00:07:19,620
basically if you haven't seen the demo

00:07:16,169 --> 00:07:23,220
in the booth yet you get yourself a data

00:07:19,620 --> 00:07:28,020
frame in Python or PI spark data frame

00:07:23,220 --> 00:07:29,669
Scout spark data frame and you just call

00:07:28,020 --> 00:07:33,600
the display command which is a pixie

00:07:29,669 --> 00:07:36,360
dust command which pops up a dialog box

00:07:33,600 --> 00:07:37,620
actually it pops up a menu and you

00:07:36,360 --> 00:07:40,020
choose from whether you want a bar chart

00:07:37,620 --> 00:07:43,199
line chart all these things if you pick

00:07:40,020 --> 00:07:46,380
Matt you have to pick what your latitude

00:07:43,199 --> 00:07:47,760
longitude columns are the numeric

00:07:46,380 --> 00:07:49,740
variable you want to map and that's all

00:07:47,760 --> 00:07:53,430
you have to do and then it generates a

00:07:49,740 --> 00:07:57,570
lot of Python to translate your data

00:07:53,430 --> 00:08:00,270
frame into geographic JSON object then a

00:07:57,570 --> 00:08:01,919
lot of JavaScript to create the the

00:08:00,270 --> 00:08:04,950
right shadings and colorings of your

00:08:01,919 --> 00:08:07,910
data and legends and puts it on in about

00:08:04,950 --> 00:08:10,050
two seconds puts it all in your notebook

00:08:07,910 --> 00:08:12,750
and I'll just throw this in that and

00:08:10,050 --> 00:08:18,240
that's really what makes some what we

00:08:12,750 --> 00:08:20,970
try to do in comparison to our cloud our

00:08:18,240 --> 00:08:22,380
cloud out competitors Azure and AWS we

00:08:20,970 --> 00:08:25,020
try to make the state as simple and

00:08:22,380 --> 00:08:27,960
accessible to more than just the deep

00:08:25,020 --> 00:08:31,020
hardcore programmer this is my this is

00:08:27,960 --> 00:08:33,630
my boss Derek and he's been telling me

00:08:31,020 --> 00:08:37,169
this for three years so I'm gonna

00:08:33,630 --> 00:08:39,539
quickly before I go into the mapping

00:08:37,169 --> 00:08:42,659
demo it's gonna be about 20 minutes of

00:08:39,539 --> 00:08:44,700
demos so sit through some quick little

00:08:42,659 --> 00:08:46,650
overview overview of all the things

00:08:44,700 --> 00:08:49,709
pixie-dust does so I'm focusing on

00:08:46,650 --> 00:08:51,750
visualizations but we also have package

00:08:49,709 --> 00:08:54,250
management cloud integration Scala

00:08:51,750 --> 00:08:56,800
bridge extensibility and embedded

00:08:54,250 --> 00:08:58,810
apps in here it's a first package

00:08:56,800 --> 00:09:01,690
manager' if you've done a lot of jupiter

00:08:58,810 --> 00:09:04,170
work you need to use your own custom jar

00:09:01,690 --> 00:09:06,550
file but I'd taken out these pans

00:09:04,170 --> 00:09:09,010
Transition need to use their own custom

00:09:06,550 --> 00:09:10,780
jar file you have to shutdown install

00:09:09,010 --> 00:09:13,180
the jar file change your configuration

00:09:10,780 --> 00:09:14,980
file and then restart again if you know

00:09:13,180 --> 00:09:17,440
how to do that in the first place

00:09:14,980 --> 00:09:19,510
pixie-dust allows you to just run a

00:09:17,440 --> 00:09:23,560
command pixie-dust install package and

00:09:19,510 --> 00:09:24,790
grab the jar and without restarting or

00:09:23,560 --> 00:09:26,380
anything you may have to restart your

00:09:24,790 --> 00:09:28,900
kernel from the menu but at least you

00:09:26,380 --> 00:09:31,270
don't have to leave your jupiter

00:09:28,900 --> 00:09:34,690
notebook environment to just start start

00:09:31,270 --> 00:09:37,320
going visualizations other than mapping

00:09:34,690 --> 00:09:41,830
we have bar chart line chart scatterplot

00:09:37,320 --> 00:09:46,420
pie chart and histogram cloud

00:09:41,830 --> 00:09:47,770
integration sometimes it's hard or

00:09:46,420 --> 00:09:49,240
sometimes you have to look up too many

00:09:47,770 --> 00:09:54,370
commands to be able to actually download

00:09:49,240 --> 00:09:55,990
data and downloading data is probably

00:09:54,370 --> 00:09:59,080
something people know pretty well but

00:09:55,990 --> 00:10:01,030
instead of downloading data getting it

00:09:59,080 --> 00:10:03,220
off into a database getting your results

00:10:01,030 --> 00:10:07,150
into it into a database is something

00:10:03,220 --> 00:10:09,280
very esoteric and very hand coded so you

00:10:07,150 --> 00:10:10,540
know we're we're a commercial

00:10:09,280 --> 00:10:12,190
organisation although pixie dust is

00:10:10,540 --> 00:10:15,880
open-source we focus on building

00:10:12,190 --> 00:10:18,210
adapters to stash your data into our

00:10:15,880 --> 00:10:20,860
databases of choice so right now we have

00:10:18,210 --> 00:10:24,640
clouding and object storage which is

00:10:20,860 --> 00:10:29,080
IBM's sort of competitor to s3

00:10:24,640 --> 00:10:34,030
and then text download format CSV XML

00:10:29,080 --> 00:10:37,150
JSON plain text HTML markdown and we

00:10:34,030 --> 00:10:38,890
would love pull requests in community

00:10:37,150 --> 00:10:41,470
contributions to extend that list of

00:10:38,890 --> 00:10:46,300
database stashing to a lot more

00:10:41,470 --> 00:10:49,240
platforms Scala bridge some people I

00:10:46,300 --> 00:10:51,700
know know Scala so I have I've never

00:10:49,240 --> 00:10:55,930
used this but for people who do use

00:10:51,700 --> 00:10:58,000
Scala and one big problem with scholars

00:10:55,930 --> 00:11:00,160
that it has a lot of benefits but it has

00:10:58,000 --> 00:11:01,990
horrible visualization libraries you can

00:11:00,160 --> 00:11:04,990
share this allows you to share variables

00:11:01,990 --> 00:11:08,080
with Scala so you can send Scala

00:11:04,990 --> 00:11:11,740
a variable perhaps a data frame do some

00:11:08,080 --> 00:11:14,170
work on it in Scala get it back into the

00:11:11,740 --> 00:11:16,570
Python environment and then use all the

00:11:14,170 --> 00:11:18,610
Python visuals including Pixy dust all

00:11:16,570 --> 00:11:23,250
the Python based visualization library

00:11:18,610 --> 00:11:23,250
libraries like map pod live and etc

00:11:23,700 --> 00:11:28,750
extensibility well I won't talk a lot

00:11:27,220 --> 00:11:30,550
about this you can if you're a really

00:11:28,750 --> 00:11:33,490
good programmer you can extend all the

00:11:30,550 --> 00:11:35,920
visualizations but we also after doing

00:11:33,490 --> 00:11:39,480
that I created a lighter-weight

00:11:35,920 --> 00:11:42,010
way to extend pixie dust which is

00:11:39,480 --> 00:11:45,900
basically using Jinja to templating

00:11:42,010 --> 00:11:48,370
writing a little HTML and CSS to build

00:11:45,900 --> 00:11:50,500
basically dashboards like you might do

00:11:48,370 --> 00:11:51,970
in tableau but tableau is you get what

00:11:50,500 --> 00:11:56,200
they give you here you can do whatever

00:11:51,970 --> 00:12:03,220
you want and david Tayyab can talk a lot

00:11:56,200 --> 00:12:06,730
about extending pixie dust with HTML so

00:12:03,220 --> 00:12:09,060
let's talk about mapping and get out of

00:12:06,730 --> 00:12:09,060
PowerPoint

00:12:21,840 --> 00:12:32,560
okay so I'm going to go back to the

00:12:23,680 --> 00:12:35,050
beginning this is IBM's data science

00:12:32,560 --> 00:12:36,880
experience with of which which does a

00:12:35,050 --> 00:12:41,500
few things but the flagship part of it

00:12:36,880 --> 00:12:45,580
right now is is Jupiter notebooks on the

00:12:41,500 --> 00:12:49,900
cloud with spark built in so you can

00:12:45,580 --> 00:12:51,160
have a project library and share your

00:12:49,900 --> 00:12:54,880
Jupiter based projects with

00:12:51,160 --> 00:12:58,080
collaborators I'm gonna go into this

00:12:54,880 --> 00:13:06,910
folder I have and I'm gonna find my

00:12:58,080 --> 00:13:09,730
mapping overview and fire up this

00:13:06,910 --> 00:13:13,300
notebook so pixie dust is an open source

00:13:09,730 --> 00:13:15,580
library publicly available on pi PI and

00:13:13,300 --> 00:13:17,290
github and it will run in your

00:13:15,580 --> 00:13:20,140
standalone Jupiter notebooks but it will

00:13:17,290 --> 00:13:27,270
also run on our cloud hosted version of

00:13:20,140 --> 00:13:27,270
Jupiter so I'm just going to go through

00:13:29,880 --> 00:13:34,200
so in a multi collaborator setting

00:13:32,350 --> 00:13:36,520
sometimes it can be locked so you don't

00:13:34,200 --> 00:13:39,280
step on somebody else's edit so I have

00:13:36,520 --> 00:13:40,570
to go into edit mode here and I'm

00:13:39,280 --> 00:13:42,880
basically just gonna start running a

00:13:40,570 --> 00:13:48,250
notebook to show you how quick this and

00:13:42,880 --> 00:13:50,470
how code-free this works so right now

00:13:48,250 --> 00:13:53,440
what we're doing what's taking so long

00:13:50,470 --> 00:13:55,620
is it's firing up you know this is a

00:13:53,440 --> 00:13:58,390
multi-user cloud environment so it's

00:13:55,620 --> 00:13:59,980
provisioning you the jupiter kernel

00:13:58,390 --> 00:14:01,240
provisioning you actually starting up

00:13:59,980 --> 00:14:05,680
your spark instance you've already

00:14:01,240 --> 00:14:07,750
provisioned it and getting going here

00:14:05,680 --> 00:14:10,140
this looks like slow in and out more

00:14:07,750 --> 00:14:10,140
than anything

00:14:21,470 --> 00:14:26,840
I have a local version of this if I need

00:14:23,510 --> 00:14:32,630
to go to it switchover local version for

00:14:26,840 --> 00:14:37,190
now which is proof that it's exactly the

00:14:32,630 --> 00:14:40,660
same code I guess let me restart the

00:14:37,190 --> 00:14:40,660
kernel so you know this is for real

00:14:46,060 --> 00:14:50,930
so I commented out my pip install

00:14:48,140 --> 00:14:55,130
because I don't need that more than once

00:14:50,930 --> 00:14:58,840
so we just import three basic things

00:14:55,130 --> 00:14:58,840
pandas numpy and pixie dust

00:14:59,140 --> 00:15:04,720
David's released a new version since I

00:15:01,430 --> 00:15:13,580
built this and I don't want to use it

00:15:04,720 --> 00:15:16,700
sorry so all I'm gonna do here is I do a

00:15:13,580 --> 00:15:19,490
lot of work with open data too so I'm

00:15:16,700 --> 00:15:21,350
gonna pull in a open data set from the

00:15:19,490 --> 00:15:24,440
city of Boston this is all the property

00:15:21,350 --> 00:15:26,390
for property appraisal data from 2016

00:15:24,440 --> 00:15:31,640
it's about a hundred thousand parcels in

00:15:26,390 --> 00:15:33,740
Boston so not a huge data set and all I

00:15:31,640 --> 00:15:35,240
won about ten of the different columns I

00:15:33,740 --> 00:15:37,640
need the latitude longitude because I

00:15:35,240 --> 00:15:41,350
want to map this stuff and I grab the

00:15:37,640 --> 00:15:45,860
land use property type owner occupancy

00:15:41,350 --> 00:15:50,060
things like that then I just do some

00:15:45,860 --> 00:15:52,280
quick little things like make sure I'm

00:15:50,060 --> 00:15:53,780
not going to use the I'm not going to

00:15:52,280 --> 00:15:56,620
use the rows where latitude or longitude

00:15:53,780 --> 00:15:56,620
is no

00:15:59,379 --> 00:16:03,939
and then I'm gonna call this prop

00:16:01,269 --> 00:16:07,839
display command the pixie dust display

00:16:03,939 --> 00:16:09,999
command on a sample of 30 rows from the

00:16:07,839 --> 00:16:18,459
properties just to make sure the data

00:16:09,999 --> 00:16:20,619
looks good so I'm really having problem

00:16:18,459 --> 00:16:23,109
with the internet here because it

00:16:20,619 --> 00:16:25,439
stopped at this request to grab the data

00:16:23,109 --> 00:16:25,439
Oh

00:17:02,480 --> 00:17:10,549
cross fingers all right we are in

00:17:08,280 --> 00:17:10,549
business

00:17:16,189 --> 00:17:22,860
so pixie-dust if you are just looking at

00:17:19,289 --> 00:17:26,039
a table view of your data if you ever

00:17:22,860 --> 00:17:27,569
use this you know Python print is not

00:17:26,039 --> 00:17:30,230
the nicest way to see your data

00:17:27,569 --> 00:17:33,360
pixie-dust quickly gives you the schema

00:17:30,230 --> 00:17:33,990
in a drop-down not too much formatting

00:17:33,360 --> 00:17:36,539
of it yet

00:17:33,990 --> 00:17:41,030
you can see the data types for all your

00:17:36,539 --> 00:17:43,350
columns and I asked for a sample of 30

00:17:41,030 --> 00:17:48,330
so I just see that here in a nice

00:17:43,350 --> 00:17:53,789
scrollable table that's not too exciting

00:17:48,330 --> 00:17:55,260
because we're not doing mapping yet so

00:17:53,789 --> 00:17:57,480
once more get rid of some bad data I'm

00:17:55,260 --> 00:17:58,890
just gonna grab properties where the

00:17:57,480 --> 00:18:01,049
living area is greater than 0

00:17:58,890 --> 00:18:04,799
I don't want little tiny slivers a date

00:18:01,049 --> 00:18:09,899
or bad badly coded data and then we'll

00:18:04,799 --> 00:18:19,159
run that display command again at this

00:18:09,899 --> 00:18:22,530
time we've chosen we've chosen the Matt

00:18:19,159 --> 00:18:29,760
command and you'll see those hundred

00:18:22,530 --> 00:18:33,450
thousand points pop in in real time so

00:18:29,760 --> 00:18:35,159
what I did here before the demo was I

00:18:33,450 --> 00:18:37,080
pre filled these things a latitude and

00:18:35,159 --> 00:18:38,850
longitude are my keys and living areas

00:18:37,080 --> 00:18:40,740
the value I want to look at so this is

00:18:38,850 --> 00:18:46,169
showing me the living area of properties

00:18:40,740 --> 00:18:47,760
in Boston by square footage so purple

00:18:46,169 --> 00:18:52,500
you can see they're higher values orange

00:18:47,760 --> 00:18:55,740
or lower values and just visually you

00:18:52,500 --> 00:18:58,500
can see a lot of you can see start to

00:18:55,740 --> 00:19:00,899
see a lot of patterns which is really

00:18:58,500 --> 00:19:02,940
important and you know when you're first

00:19:00,899 --> 00:19:04,770
working on any kind of data science

00:19:02,940 --> 00:19:07,559
project what you're doing is really a

00:19:04,770 --> 00:19:09,120
lot of exploratory data analysis trying

00:19:07,559 --> 00:19:11,429
to figure out what's going on with your

00:19:09,120 --> 00:19:13,860
data before you start to move to a stage

00:19:11,429 --> 00:19:15,360
where you produce your final your final

00:19:13,860 --> 00:19:18,630
presentations and

00:19:15,360 --> 00:19:20,130
and visualizations so and that's exactly

00:19:18,630 --> 00:19:22,470
the time where you don't want to be

00:19:20,130 --> 00:19:25,080
bogged down in code documentation

00:19:22,470 --> 00:19:27,600
looking up commands because that is

00:19:25,080 --> 00:19:29,910
context switching and taking yourself

00:19:27,600 --> 00:19:32,670
away from actually trying to solve your

00:19:29,910 --> 00:19:34,980
problem so you know most developer

00:19:32,670 --> 00:19:37,260
productivity is lost in context

00:19:34,980 --> 00:19:38,580
switching and so if you fire up a web

00:19:37,260 --> 00:19:41,190
browser to go look up pandas

00:19:38,580 --> 00:19:44,100
documentation then maybe oh I'm in a web

00:19:41,190 --> 00:19:45,510
browser and open up the Amazon and do a

00:19:44,100 --> 00:19:47,910
little shopping I forgot to do or

00:19:45,510 --> 00:19:50,700
something like that there are a lot of a

00:19:47,910 --> 00:19:54,960
lot of productivity losses in context

00:19:50,700 --> 00:19:56,730
switching so I can stay here maybe

00:19:54,960 --> 00:19:59,430
orange two purples and showing me the

00:19:56,730 --> 00:20:01,950
right thing I'll switch my color ramp to

00:19:59,430 --> 00:20:07,530
light to dark red that makes more sense

00:20:01,950 --> 00:20:09,510
for a continuous value so we'll see we

00:20:07,530 --> 00:20:11,850
can speed we're just looking at living

00:20:09,510 --> 00:20:14,640
area we see down here oh those are low

00:20:11,850 --> 00:20:16,610
square footage areas that makes sense

00:20:14,640 --> 00:20:20,160
because I know Boston these are more

00:20:16,610 --> 00:20:22,050
spread out single-family homes as you

00:20:20,160 --> 00:20:26,040
get towards the core of the city up here

00:20:22,050 --> 00:20:29,310
these are more high-rises but still I'm

00:20:26,040 --> 00:20:32,790
a little surprised because you know

00:20:29,310 --> 00:20:34,380
we're going up to over a what's this 1.9

00:20:32,790 --> 00:20:37,320
million square feet that doesn't sound

00:20:34,380 --> 00:20:40,710
like residential so I had my mind I was

00:20:37,320 --> 00:20:42,690
gonna look at residential oh but so that

00:20:40,710 --> 00:20:47,460
must mean these were probably office

00:20:42,690 --> 00:20:50,280
buildings right so let's take a let's

00:20:47,460 --> 00:20:54,510
take a look at the day let's bar chart

00:20:50,280 --> 00:20:58,140
the data by land-use type so you have to

00:20:54,510 --> 00:21:01,140
go look at the city of Boston's land use

00:20:58,140 --> 00:21:04,020
coding chart excuse me to know what

00:21:01,140 --> 00:21:07,800
these mean but I R 1 R 2 R 3 in our far

00:21:04,020 --> 00:21:12,690
four are the residential codes are one

00:21:07,800 --> 00:21:14,970
is single-family R 4 is 4 for family and

00:21:12,690 --> 00:21:16,830
above but we have all these other which

00:21:14,970 --> 00:21:20,970
are actually the highest values for

00:21:16,830 --> 00:21:24,120
square footage is tax exempt C is

00:21:20,970 --> 00:21:25,740
commercial and we have our C residential

00:21:24,120 --> 00:21:27,960
commercial mix so all those are really

00:21:25,740 --> 00:21:28,710
not helping me with my look at

00:21:27,960 --> 00:21:32,520
residential

00:21:28,710 --> 00:21:34,919
we're footage so then we can quickly and

00:21:32,520 --> 00:21:39,330
I made that once again I'll show you the

00:21:34,919 --> 00:21:43,679
options I made that with absolutely no

00:21:39,330 --> 00:21:47,549
code just that okay my key value here is

00:21:43,679 --> 00:21:50,909
land use and I want to aggregate living

00:21:47,549 --> 00:21:54,630
area take the average living area for

00:21:50,909 --> 00:21:58,620
each row and group it up by land use

00:21:54,630 --> 00:22:00,510
code oh and here this is important so

00:21:58,620 --> 00:22:03,480
pixie-dust works on a sample of your

00:22:00,510 --> 00:22:06,270
data so I'm gonna use 10,000 values here

00:22:03,480 --> 00:22:08,340
and once more this is really helpful for

00:22:06,270 --> 00:22:11,539
the exploratory data analysis stage as

00:22:08,340 --> 00:22:14,429
you move towards you know actually

00:22:11,539 --> 00:22:17,130
producing your results you'll want to

00:22:14,429 --> 00:22:20,490
use the full data set or more and more

00:22:17,130 --> 00:22:21,840
of it but this gives me and I this tells

00:22:20,490 --> 00:22:23,100
me what I need to know here which is I

00:22:21,840 --> 00:22:24,630
have to get rid of all these land-use

00:22:23,100 --> 00:22:28,169
codes which are not relevant to what I'm

00:22:24,630 --> 00:22:30,059
doing and I can look a little deeper

00:22:28,169 --> 00:22:31,880
into that show me just the living coat

00:22:30,059 --> 00:22:34,500
the land use codes which have

00:22:31,880 --> 00:22:39,659
square-footage values greater than 3000

00:22:34,500 --> 00:22:41,340
square-feet so some are one some sorry

00:22:39,659 --> 00:22:45,450
single-family residential czar bigger

00:22:41,340 --> 00:22:47,130
than that but mostly these are all these

00:22:45,450 --> 00:22:53,100
other codes so i'm on the right track

00:22:47,130 --> 00:22:54,899
here i we need r1 through our four so

00:22:53,100 --> 00:22:59,100
res living I'll make a new data frame

00:22:54,899 --> 00:23:08,700
just give me r1 r2 r3 and r4 and if we

00:22:59,100 --> 00:23:11,870
mop those now now we get something

00:23:08,700 --> 00:23:11,870
that's beginning to look a little better

00:23:12,380 --> 00:23:19,649
OOP so this once again is downtown

00:23:16,440 --> 00:23:22,049
Boston back Bay Fenway Park is right

00:23:19,649 --> 00:23:23,970
there so we still have the purple the

00:23:22,049 --> 00:23:27,559
highest values here which are probably

00:23:23,970 --> 00:23:31,850
those multifamily apartment buildings

00:23:27,559 --> 00:23:34,320
you zoom out chief sorry not values

00:23:31,850 --> 00:23:36,630
Chelsea area out by the airport down

00:23:34,320 --> 00:23:39,389
here in the more single-family

00:23:36,630 --> 00:23:40,540
residential areas lower which makes

00:23:39,389 --> 00:23:49,460
sense

00:23:40,540 --> 00:23:54,200
and so finally we go down here and we

00:23:49,460 --> 00:23:56,000
get values per square foot so I I divide

00:23:54,200 --> 00:23:59,630
the total square footage of each

00:23:56,000 --> 00:24:03,260
property by the by the total housing

00:23:59,630 --> 00:24:05,870
value and we get a map which really

00:24:03,260 --> 00:24:07,880
makes sense as somebody who's looking at

00:24:05,870 --> 00:24:10,580
residential property values in Boston so

00:24:07,880 --> 00:24:13,850
per square foot the highest values are

00:24:10,580 --> 00:24:17,200
here in purple downtown the most the

00:24:13,850 --> 00:24:19,670
nicest residential areas will go to

00:24:17,200 --> 00:24:21,110
Beacon Hill over here this is all

00:24:19,670 --> 00:24:22,910
residential this is where John Kerry

00:24:21,110 --> 00:24:23,330
lives if you remember when he ran for

00:24:22,910 --> 00:24:25,220
president

00:24:23,330 --> 00:24:31,190
I don't know if New Yorkers remember

00:24:25,220 --> 00:24:32,870
John Kerry so much and then we'll come

00:24:31,190 --> 00:24:35,120
down here here's some of the more you

00:24:32,870 --> 00:24:37,820
know the public housing projects area in

00:24:35,120 --> 00:24:41,780
some of the poor areas and then values

00:24:37,820 --> 00:24:44,540
go up down here where we have some of

00:24:41,780 --> 00:24:45,740
the nicer you know it's still an urban

00:24:44,540 --> 00:24:47,570
area but these are seeing a lot of

00:24:45,740 --> 00:24:50,090
single-family homes and double-deckers

00:24:47,570 --> 00:24:54,050
over here with better neighborhoods

00:24:50,090 --> 00:24:55,910
better schools and then you move over

00:24:54,050 --> 00:24:59,440
here over by the airport and once more

00:24:55,910 --> 00:25:01,820
you get down to the lower lower values

00:24:59,440 --> 00:25:03,680
airports cause lower housing value so

00:25:01,820 --> 00:25:06,590
that's you know I put this whole thing

00:25:03,680 --> 00:25:10,100
together in a two or three hours because

00:25:06,590 --> 00:25:11,630
I didn't have to write any code and now

00:25:10,100 --> 00:25:13,100
I'm gonna get into a couple little more

00:25:11,630 --> 00:25:20,500
advanced things and then talk about how

00:25:13,100 --> 00:25:23,960
everything works so that was basically

00:25:20,500 --> 00:25:26,510
point mapping you can I had a latitude

00:25:23,960 --> 00:25:29,360
and a longitude field in my data so I

00:25:26,510 --> 00:25:31,700
could map points on ax I could put

00:25:29,360 --> 00:25:34,430
points on a map we also support lines

00:25:31,700 --> 00:25:36,530
and polygons and you a lot of people a

00:25:34,430 --> 00:25:39,950
lot of people who are in the natural

00:25:36,530 --> 00:25:42,170
resources space or military don't ever

00:25:39,950 --> 00:25:43,460
understand why you'd need to map lines

00:25:42,170 --> 00:25:45,310
or polygons because usually you're

00:25:43,460 --> 00:25:49,460
mapping customers or something like that

00:25:45,310 --> 00:25:51,920
but in this case this is actually health

00:25:49,460 --> 00:25:53,690
data and a lot of the sample health data

00:25:51,920 --> 00:25:55,700
you get we do a lot of work in health

00:25:53,690 --> 00:25:58,820
Watson hell a lot of the sample health

00:25:55,700 --> 00:26:01,340
data you get is aggregated to the three

00:25:58,820 --> 00:26:04,759
digit zip code level to maintain privacy

00:26:01,340 --> 00:26:06,320
for those for those people so we had to

00:26:04,759 --> 00:26:10,039
come up with a three digit zip code map

00:26:06,320 --> 00:26:14,330
so took took the five digit zip codes

00:26:10,039 --> 00:26:16,460
from the government dissolved the

00:26:14,330 --> 00:26:18,590
polygons down to the three digit level

00:26:16,460 --> 00:26:21,080
which was a exercise in and of itself

00:26:18,590 --> 00:26:23,750
but once we had that data set we could

00:26:21,080 --> 00:26:29,120
build it into pixie dust and then we

00:26:23,750 --> 00:26:32,450
took a we took some data from one of our

00:26:29,120 --> 00:26:35,240
health studies and we didn't have we

00:26:32,450 --> 00:26:37,629
didn't have any GM geometric data for it

00:26:35,240 --> 00:26:40,429
but we had this three digit zip code and

00:26:37,629 --> 00:26:41,899
then we were able to map it I'm not

00:26:40,429 --> 00:26:43,519
using that data here because we're not

00:26:41,899 --> 00:26:45,740
allowed to share it publicly but I just

00:26:43,519 --> 00:26:49,700
have population value for that three to

00:26:45,740 --> 00:26:52,340
the zip code boy we can map that so what

00:26:49,700 --> 00:26:56,299
this function does here is take my data

00:26:52,340 --> 00:26:58,909
frame that has a zip code in it join it

00:26:56,299 --> 00:27:01,190
to the geometry file that we have

00:26:58,909 --> 00:27:06,110
publicly available and then we have

00:27:01,190 --> 00:27:08,570
these these um polygon objects which are

00:27:06,110 --> 00:27:12,889
in a format standard format called geo

00:27:08,570 --> 00:27:16,250
JSON and that allows us to map this in

00:27:12,889 --> 00:27:19,429
pixie dust so we have the same map we

00:27:16,250 --> 00:27:21,169
have great interactivity and hover over

00:27:19,429 --> 00:27:26,029
and see the populations whatever value

00:27:21,169 --> 00:27:28,330
our mapping pops up there and you'll see

00:27:26,029 --> 00:27:31,250
here their holes in the data because

00:27:28,330 --> 00:27:32,899
once again I'm only displaying a

00:27:31,250 --> 00:27:35,169
thousand rows let's trying to display

00:27:32,899 --> 00:27:35,169
more

00:27:38,530 --> 00:27:43,030
there we go so now you see the whole

00:27:40,210 --> 00:27:45,030
country that was my mistake but see how

00:27:43,030 --> 00:27:49,150
fast that was just a second

00:27:45,030 --> 00:27:53,020
to fix the problem with my Dave so

00:27:49,150 --> 00:27:55,480
that's nice and once again if you're

00:27:53,020 --> 00:27:57,030
printing you want to print you want to

00:27:55,480 --> 00:27:58,990
go black and white or you have

00:27:57,030 --> 00:28:03,820
accessibility issue you can go black and

00:27:58,990 --> 00:28:05,260
white and you've done no and you know

00:28:03,820 --> 00:28:07,960
you probably don't know how to do this

00:28:05,260 --> 00:28:11,020
because your job isn't mapping so you've

00:28:07,960 --> 00:28:13,380
been able to take advantage of you might

00:28:11,020 --> 00:28:15,820
need an hour to train on that instead of

00:28:13,380 --> 00:28:17,590
weeks that it would take to understand

00:28:15,820 --> 00:28:21,640
all the JavaScript that's grabbing this

00:28:17,590 --> 00:28:26,050
I should mention that I'm gonna go up to

00:28:21,640 --> 00:28:29,260
this map because it's easier to show so

00:28:26,050 --> 00:28:31,000
this is okay thanks this is a very

00:28:29,260 --> 00:28:34,750
interactive map and it takes a lot of

00:28:31,000 --> 00:28:37,300
JavaScript to make this happen and also

00:28:34,750 --> 00:28:40,300
as i zoom in you see these names come in

00:28:37,300 --> 00:28:41,710
this is this is also a lot of

00:28:40,300 --> 00:28:44,410
functionality we take for granted we

00:28:41,710 --> 00:28:46,810
expect this to be there but it takes a

00:28:44,410 --> 00:28:48,280
lot of takes a lot of processing power

00:28:46,810 --> 00:28:50,830
for Google to be shipping out those

00:28:48,280 --> 00:28:55,120
tiles all the time and your your street

00:28:50,830 --> 00:28:57,940
map and all that stuff and puts you to

00:28:55,120 --> 00:28:59,950
another kind of map Luis Natalie just so

00:28:57,940 --> 00:29:01,180
you can see so we partnered we didn't

00:28:59,950 --> 00:29:02,590
build this all ourselves we partnered

00:29:01,180 --> 00:29:05,440
with a great company called map box

00:29:02,590 --> 00:29:08,530
which does this for a living

00:29:05,440 --> 00:29:09,880
provides these base maps see a zoom in

00:29:08,530 --> 00:29:15,400
you get more detail I can go right down

00:29:09,880 --> 00:29:17,950
to a building and go over to my data so

00:29:15,400 --> 00:29:20,950
if I go over to an area with my data in

00:29:17,950 --> 00:29:24,220
it oh I just have the opacity set very

00:29:20,950 --> 00:29:25,660
light so once i zoom down this far it's

00:29:24,220 --> 00:29:33,850
hard to see my point so I'll bump the

00:29:25,660 --> 00:29:36,090
opacity opacity up I wish nobody would

00:29:33,850 --> 00:29:36,090
say that

00:29:36,710 --> 00:29:44,580
good question we haven't figured out a

00:29:41,429 --> 00:29:48,510
good way to we haven't focused on that

00:29:44,580 --> 00:29:50,850
little nice usability tweak I think it's

00:29:48,510 --> 00:29:52,380
possible but so if you really so we're

00:29:50,850 --> 00:29:54,150
looking at a housing study here if you

00:29:52,380 --> 00:29:56,070
want really doing a residential study

00:29:54,150 --> 00:29:57,660
you switch to the satellite imagery and

00:29:56,070 --> 00:30:00,270
you zoom in and you get a better idea of

00:29:57,660 --> 00:30:02,820
what those places really look like on

00:30:00,270 --> 00:30:04,830
the ground but that takes a lot of work

00:30:02,820 --> 00:30:07,140
like doing this yourself would not just

00:30:04,830 --> 00:30:10,020
take a lot of JavaScript programming but

00:30:07,140 --> 00:30:11,880
it's nice to have a company behind that

00:30:10,020 --> 00:30:13,890
base mapping piece which does it well

00:30:11,880 --> 00:30:17,340
though that you know as their primary

00:30:13,890 --> 00:30:20,280
business goal I'm gonna switch back to

00:30:17,340 --> 00:30:24,960
dark because data often looks better on

00:30:20,280 --> 00:30:27,240
a simpler map yeah and you still get all

00:30:24,960 --> 00:30:29,070
that wonderful context of knowing where

00:30:27,240 --> 00:30:32,730
a place is when you're looking at

00:30:29,070 --> 00:30:39,780
geographic data and I'm going to switch

00:30:32,730 --> 00:30:42,960
over I'm gonna try to go back to DSX so

00:30:39,780 --> 00:30:46,340
I can show you that our platform really

00:30:42,960 --> 00:30:46,340
works now that we have Internet

00:30:55,029 --> 00:30:59,870
and I'm gonna show you one more thing

00:30:57,080 --> 00:31:04,190
which is so you may have missed this but

00:30:59,870 --> 00:31:06,139
I said pixie dust is all handles data in

00:31:04,190 --> 00:31:10,460
memory so that's why we're just taking a

00:31:06,139 --> 00:31:17,380
sample of the data now there's a problem

00:31:10,460 --> 00:31:17,380
if I get off fullscreen

00:31:28,640 --> 00:31:34,409
now one problem is if your data doesn't

00:31:31,950 --> 00:31:36,450
fit in memory what do you do and that's

00:31:34,409 --> 00:31:42,470
a big big problem with Geographic data

00:31:36,450 --> 00:31:44,909
because okay that's the wrong way

00:31:42,470 --> 00:31:48,150
buying publication they're banning that

00:31:44,909 --> 00:31:50,179
so one thing people who don't understand

00:31:48,150 --> 00:31:52,260
Geographic data take for granted is that

00:31:50,179 --> 00:31:54,720
something like the zip code boundaries

00:31:52,260 --> 00:31:56,280
can be huge a shoreline boundary can be

00:31:54,720 --> 00:31:58,860
millions and millions of points to get

00:31:56,280 --> 00:32:00,690
the detail you want zip codes that's a

00:31:58,860 --> 00:32:02,370
natural thing so that's not as important

00:32:00,690 --> 00:32:04,650
to a business analysis but a zip code

00:32:02,370 --> 00:32:08,220
boundary can be thousands of points to

00:32:04,650 --> 00:32:10,020
describe it properly and that's not even

00:32:08,220 --> 00:32:11,580
that's just the geometry of it that's

00:32:10,020 --> 00:32:13,049
not talking about your data so if you

00:32:11,580 --> 00:32:15,450
have to bring that into memory all the

00:32:13,049 --> 00:32:17,669
time and you have to map thousands and

00:32:15,450 --> 00:32:20,100
thousands of zip codes that's a problem

00:32:17,669 --> 00:32:22,409
or if you have to map millions of you

00:32:20,100 --> 00:32:23,789
know data points so this is a study

00:32:22,409 --> 00:32:26,039
which I'm not going to talk about too

00:32:23,789 --> 00:32:31,679
much they have a blog on it which is

00:32:26,039 --> 00:32:33,840
there but this map box has a way to take

00:32:31,679 --> 00:32:35,850
a data set that's too large to that you

00:32:33,840 --> 00:32:38,070
don't want to fit in memory send it to

00:32:35,850 --> 00:32:41,309
their server they tile the whole thing

00:32:38,070 --> 00:32:45,390
up tile is a format is what is a quick

00:32:41,309 --> 00:32:49,049
term we call for building different

00:32:45,390 --> 00:32:52,080
levels of detail of the data set so that

00:32:49,049 --> 00:32:55,490
as you move around in your map you only

00:32:52,080 --> 00:32:58,590
send the data to the user that they need

00:32:55,490 --> 00:33:00,900
so I just did an analysis we don't see

00:32:58,590 --> 00:33:02,669
it here but I did an analysis of which

00:33:00,900 --> 00:33:05,580
areas in the country are most urban

00:33:02,669 --> 00:33:07,890
based on zip codes and there's about

00:33:05,580 --> 00:33:10,679
there's thousands of zip codes in the

00:33:07,890 --> 00:33:15,059
country and if I had all that zip code

00:33:10,679 --> 00:33:18,240
data in the browser plus all my you know

00:33:15,059 --> 00:33:20,820
numeric data it would blow up but this

00:33:18,240 --> 00:33:22,620
way using map boxes tying scheme and

00:33:20,820 --> 00:33:24,600
calling on it from within pixie-dust

00:33:22,620 --> 00:33:25,710
I can see the whole cut I can zoom

00:33:24,600 --> 00:33:29,370
around the country in a matter of

00:33:25,710 --> 00:33:33,270
milliseconds so you'll see the country

00:33:29,370 --> 00:33:34,679
in general is a pretty rural place but

00:33:33,270 --> 00:33:38,159
as you zoom in you'll get more detail

00:33:34,679 --> 00:33:39,880
and map box as i zoom if i zoom in fast

00:33:38,159 --> 00:33:46,490
enough you'll see tiles here

00:33:39,880 --> 00:33:48,049
let me try to see they're so good you

00:33:46,490 --> 00:33:50,720
can't even see the tile sometimes you'll

00:33:48,049 --> 00:33:53,120
see a square which is blank because the

00:33:50,720 --> 00:33:56,690
tile of data hasn't loaded in yet but

00:33:53,120 --> 00:33:58,370
Mac bucks for every this picture is

00:33:56,690 --> 00:34:00,230
probably about 20 tiles it'll bring in

00:33:58,370 --> 00:34:03,440
every tile of data asynchronously so

00:34:00,230 --> 00:34:05,960
user has no slowdown and then take every

00:34:03,440 --> 00:34:08,270
tile of data and apply your styling

00:34:05,960 --> 00:34:10,700
rules to it so what I'm doing here in

00:34:08,270 --> 00:34:14,470
JavaScript is saying okay I have like

00:34:10,700 --> 00:34:17,240
10,000 zip codes as you bring in data

00:34:14,470 --> 00:34:19,030
find me the zip code like I have data

00:34:17,240 --> 00:34:21,889
for this zip code find me that zip code

00:34:19,030 --> 00:34:24,649
apply this color to it look up this

00:34:21,889 --> 00:34:26,899
color and apply it and show it on the

00:34:24,649 --> 00:34:29,179
map and all that's happening fast enough

00:34:26,899 --> 00:34:30,619
so that if you did an analysis of the

00:34:29,179 --> 00:34:34,399
whole country let's say you're looking

00:34:30,619 --> 00:34:36,889
at you know shoppers per square per

00:34:34,399 --> 00:34:40,190
square foot around shopping malls you

00:34:36,889 --> 00:34:43,750
could provide a map which is seamlessly

00:34:40,190 --> 00:34:47,060
zoomable and doesn't slow down at all

00:34:43,750 --> 00:34:50,500
okay so those are some demos glad I can

00:34:47,060 --> 00:34:50,500
show the data science experience works

00:34:53,109 --> 00:35:03,080
I'm just gonna wrap up a couple minutes

00:34:56,030 --> 00:35:05,510
so just to summarize what is going on on

00:35:03,080 --> 00:35:09,410
the technology side pixie dust is a

00:35:05,510 --> 00:35:11,990
Python library which which basically

00:35:09,410 --> 00:35:15,440
packages up a lot of redundant boring

00:35:11,990 --> 00:35:17,270
monotonous Python code gives it to you

00:35:15,440 --> 00:35:20,750
in a menu system nice widget based menu

00:35:17,270 --> 00:35:22,700
system in the mapping we convert spark

00:35:20,750 --> 00:35:25,580
or Python data spark or pandas

00:35:22,700 --> 00:35:27,589
dataframes to geo JSON format which our

00:35:25,580 --> 00:35:31,070
partner company map box which provides

00:35:27,589 --> 00:35:34,130
that JavaScript mapping library can can

00:35:31,070 --> 00:35:37,280
put on a mat we do some more Python to

00:35:34,130 --> 00:35:40,010
cut the data set into quantiles and then

00:35:37,280 --> 00:35:43,970
we put that we put those pond tiles into

00:35:40,010 --> 00:35:48,109
another javascript file for styling map

00:35:43,970 --> 00:35:50,270
styling and that's basically all we do

00:35:48,109 --> 00:35:52,740
and then we take the JavaScript we

00:35:50,270 --> 00:35:57,180
created and put it into a

00:35:52,740 --> 00:35:59,070
- template which is which is quite what

00:35:57,180 --> 00:36:03,540
pixie-dust decided to use for creating

00:35:59,070 --> 00:36:07,619
interactive graphics on the in Jupiter

00:36:03,540 --> 00:36:09,200
which is basically a web application so

00:36:07,619 --> 00:36:11,760
we do this if you look through the

00:36:09,200 --> 00:36:14,150
pixie-dust code you'll find all these

00:36:11,760 --> 00:36:16,440
pieces and these in these directories

00:36:14,150 --> 00:36:21,450
and then we render in the case of

00:36:16,440 --> 00:36:23,430
mapping we render it in iframe and then

00:36:21,450 --> 00:36:27,510
we call the map box API for getting

00:36:23,430 --> 00:36:29,970
those basis street maps so in the future

00:36:27,510 --> 00:36:32,220
are gonna add some more cartographic

00:36:29,970 --> 00:36:34,260
options you saw me play around with some

00:36:32,220 --> 00:36:39,230
of the styling some of the color ramps

00:36:34,260 --> 00:36:41,550
the opacity of points and polygons there

00:36:39,230 --> 00:36:43,650
where we have some work right now going

00:36:41,550 --> 00:36:45,930
on to add temporal visualization which

00:36:43,650 --> 00:36:48,360
is gonna be awesome because a lot of

00:36:45,930 --> 00:36:50,100
things aren't just on the earth but they

00:36:48,360 --> 00:36:53,280
also move around the earth like clouds

00:36:50,100 --> 00:36:56,490
and weather and military features of

00:36:53,280 --> 00:36:57,780
interest MapBox

00:36:56,490 --> 00:36:59,460
liked what we did so much they're

00:36:57,780 --> 00:37:02,940
building an official library for Jupiter

00:36:59,460 --> 00:37:04,530
and we're gonna use that in pixie dust

00:37:02,940 --> 00:37:06,750
and you'll be able to use it on your own

00:37:04,530 --> 00:37:08,670
as a Python developer and then we're

00:37:06,750 --> 00:37:13,850
gonna integrate more mapping providers

00:37:08,670 --> 00:37:16,950
as Ricardo some other things and so

00:37:13,850 --> 00:37:18,240
pixie dust on github here open-source

00:37:16,950 --> 00:37:21,540
you can try it on data science

00:37:18,240 --> 00:37:25,580
experience and use it and join us in

00:37:21,540 --> 00:37:25,580
community of developers thanks

00:37:30,220 --> 00:37:35,440
thank you we have time for maybe one

00:37:32,780 --> 00:37:35,440
quick question

00:37:36,190 --> 00:37:42,800
it looks like the local install of pixie

00:37:39,020 --> 00:37:47,800
dust requires spark 1.6 this is a little

00:37:42,800 --> 00:37:47,800
bit old it doesn't anymore quick answer

00:38:00,910 --> 00:38:04,850
yes if you're if you don't want to

00:38:03,410 --> 00:38:10,760
develop on the code you can pip install

00:38:04,850 --> 00:38:12,710
pixie dust and go okay so that's the end

00:38:10,760 --> 00:38:15,770
of today's sessions in this room there's

00:38:12,710 --> 00:38:16,190
one more talk in several of the other

00:38:15,770 --> 00:38:19,790
rooms

00:38:16,190 --> 00:38:22,980
so let's thank the speaker again okay

00:38:19,790 --> 00:38:22,980

YouTube URL: https://www.youtube.com/watch?v=rEo3klBpOV0


