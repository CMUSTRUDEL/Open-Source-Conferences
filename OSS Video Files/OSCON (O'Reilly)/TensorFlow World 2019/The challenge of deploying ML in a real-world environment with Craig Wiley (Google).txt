Title: The challenge of deploying ML in a real-world environment with Craig Wiley (Google)
Publication date: 2019-11-12
Playlist: TensorFlow World 2019
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:04,560
Roger McGough is here with Craig Wiley

00:00:01,740 --> 00:00:06,870
who's director of product for the Google

00:00:04,560 --> 00:00:09,440
Cloud a I platform welcome Craig thank

00:00:06,870 --> 00:00:10,860
you very much so Google cloud platform

00:00:09,440 --> 00:00:13,200
what is it

00:00:10,860 --> 00:00:16,770
so Clara hat platform is basically a set

00:00:13,200 --> 00:00:18,420
of services and tools that allows you

00:00:16,770 --> 00:00:20,220
know you customers and users to build

00:00:18,420 --> 00:00:22,430
their own machine learning on Google

00:00:20,220 --> 00:00:25,470
cloud what we're really excited about

00:00:22,430 --> 00:00:27,840
today is is the launch of tensorflow

00:00:25,470 --> 00:00:30,119
Enterprise as a part of that great a

00:00:27,840 --> 00:00:31,619
little like what sure yeah tensorflow

00:00:30,119 --> 00:00:33,390
Enterprise really came about with us

00:00:31,619 --> 00:00:34,590
working with customers and finding some

00:00:33,390 --> 00:00:37,320
challenges that they were having

00:00:34,590 --> 00:00:40,230
deploying machine learning in a real

00:00:37,320 --> 00:00:41,790
world environment and so today we've

00:00:40,230 --> 00:00:44,489
released tensorflow enterprise which

00:00:41,790 --> 00:00:47,820
basically gives three core things the

00:00:44,489 --> 00:00:50,250
first is it extends the support window

00:00:47,820 --> 00:00:52,710
for older versions of tensorflow from

00:00:50,250 --> 00:00:55,050
one year to three years and this really

00:00:52,710 --> 00:00:57,270
gives those enterprises the confidence

00:00:55,050 --> 00:00:59,250
to know that they can deploy and still

00:00:57,270 --> 00:01:01,469
have things like security patches and

00:00:59,250 --> 00:01:03,239
and the necessary pieces for them to

00:01:01,469 --> 00:01:05,850
feel confident about using this software

00:01:03,239 --> 00:01:07,409
the the second thing is it's it's a

00:01:05,850 --> 00:01:10,080
highly optimized version of tensorflow

00:01:07,409 --> 00:01:11,909
for google cloud that provides kind of

00:01:10,080 --> 00:01:14,790
state-of-the-art speed reliability

00:01:11,909 --> 00:01:16,350
durability so that customers know that

00:01:14,790 --> 00:01:18,150
they're using the best tensorflow when

00:01:16,350 --> 00:01:20,400
they're using it on google cloud and

00:01:18,150 --> 00:01:22,110
then finally it's integrated into all of

00:01:20,400 --> 00:01:24,509
our managed services so whether you're

00:01:22,110 --> 00:01:26,220
using our kubernetes engine and comes

00:01:24,509 --> 00:01:28,110
our flow there potentially with coop

00:01:26,220 --> 00:01:30,900
flow or whether you're using it in our

00:01:28,110 --> 00:01:32,490
managed AI platform you'll get all of

00:01:30,900 --> 00:01:38,579
the benefits of tensorflow Enterprise

00:01:32,490 --> 00:01:40,860
kind of right out of the box the the

00:01:38,579 --> 00:01:42,420
platform certainly does so you know for

00:01:40,860 --> 00:01:44,970
example with tensorflow Enterprise one

00:01:42,420 --> 00:01:47,250
of the optimizations we made was that

00:01:44,970 --> 00:01:50,369
bigquery which is Google's kind of hyper

00:01:47,250 --> 00:01:52,619
scale data warehouse now has three times

00:01:50,369 --> 00:01:54,990
faster read speed when using tensor flow

00:01:52,619 --> 00:01:56,549
so really allowing you to take full

00:01:54,990 --> 00:01:58,680
advantage of the speed of bigquery

00:01:56,549 --> 00:02:00,540
when using tensor flow which is super

00:01:58,680 --> 00:02:03,030
exciting for us and our customers know

00:02:00,540 --> 00:02:05,070
that what kind of problems are expecting

00:02:03,030 --> 00:02:06,420
to solve with tens of years yeah you

00:02:05,070 --> 00:02:07,770
know I mean you know one of the

00:02:06,420 --> 00:02:10,179
customers who we worked hard and

00:02:07,770 --> 00:02:13,269
developing this with was unity gaming

00:02:10,179 --> 00:02:16,719
and you know unity is installed on over

00:02:13,269 --> 00:02:19,390
three billion devices worldwide and you

00:02:16,719 --> 00:02:22,709
know their monetization platform uses

00:02:19,390 --> 00:02:25,810
cloud AI and cloud platform and

00:02:22,709 --> 00:02:28,299
tensorflow to kind of you know quickly

00:02:25,810 --> 00:02:29,859
and easily test out different models and

00:02:28,299 --> 00:02:32,260
then once they found a winner scale

00:02:29,859 --> 00:02:33,670
those models out you know across across

00:02:32,260 --> 00:02:37,569
their platform

00:02:33,670 --> 00:02:39,280
you know similarly cruise automotive you

00:02:37,569 --> 00:02:41,439
know working on kind of what I think is

00:02:39,280 --> 00:02:44,919
probably one of the generation defining

00:02:41,439 --> 00:02:46,989
problems and in autonomous vehicles you

00:02:44,919 --> 00:02:48,879
know we've worked with them to reduce

00:02:46,989 --> 00:02:51,250
their training times from four days down

00:02:48,879 --> 00:02:54,489
to one day with this technology as well

00:02:51,250 --> 00:02:56,139
great so and in terms of the fit and

00:02:54,489 --> 00:02:58,239
current infrastructure including from

00:02:56,139 --> 00:03:00,790
the developer into production how does

00:02:58,239 --> 00:03:02,709
that work yeah you know I mean really it

00:03:00,790 --> 00:03:04,810
it's up to the developer and the

00:03:02,709 --> 00:03:06,159
customer whether at what abstraction

00:03:04,810 --> 00:03:08,500
layer they want to work at you know I

00:03:06,159 --> 00:03:11,230
think the the most straightforward one

00:03:08,500 --> 00:03:13,840
would be one where they potentially use

00:03:11,230 --> 00:03:16,090
our notebook service and then roll right

00:03:13,840 --> 00:03:17,769
into our training system where all they

00:03:16,090 --> 00:03:20,409
have to do is kind of submit their you

00:03:17,769 --> 00:03:22,120
know 15 lines of Karass and you know

00:03:20,409 --> 00:03:25,989
they're off to the races training across

00:03:22,120 --> 00:03:27,909
as many CPUs or GPUs as they want right

00:03:25,989 --> 00:03:31,299
and so you know they can easily kind of

00:03:27,909 --> 00:03:32,739
pile on you know ten GPUs if that's what

00:03:31,299 --> 00:03:35,049
it makes sense for them to do from a

00:03:32,739 --> 00:03:37,150
scale perspective mm-hmm I'm curious

00:03:35,049 --> 00:03:38,560
from the customers that you have what

00:03:37,150 --> 00:03:40,540
kind of feedback have you gotten in

00:03:38,560 --> 00:03:43,359
terms of just kind of an abstract sense

00:03:40,540 --> 00:03:45,729
what not just what problems are solving

00:03:43,359 --> 00:03:49,930
but but how the problems are having with

00:03:45,729 --> 00:03:51,790
integrating AI into their regular yeah I

00:03:49,930 --> 00:03:54,519
mean you know certainly I can remember

00:03:51,790 --> 00:03:56,680
as when I was managing a data science

00:03:54,519 --> 00:03:58,209
team years ago you know and turning to

00:03:56,680 --> 00:04:00,040
one of the economy Trish ins on the team

00:03:58,209 --> 00:04:01,269
and saying hey why don't you go you know

00:04:00,040 --> 00:04:03,159
install tensorflow and get it working

00:04:01,269 --> 00:04:04,900
and test some things out and he kind of

00:04:03,159 --> 00:04:06,040
came back to me a half a day later and

00:04:04,900 --> 00:04:07,870
said I'm still having a hard time

00:04:06,040 --> 00:04:10,239
getting all the drivers solved and all

00:04:07,870 --> 00:04:12,069
of this and you know what we aim to do

00:04:10,239 --> 00:04:14,019
is make it so that none of that is a

00:04:12,069 --> 00:04:16,030
concern all you have to do is worry

00:04:14,019 --> 00:04:17,919
about describing your model in whatever

00:04:16,030 --> 00:04:20,469
language it makes sense to you to do

00:04:17,919 --> 00:04:22,330
that using whatever framework makes

00:04:20,469 --> 00:04:23,660
sense having said that I think with

00:04:22,330 --> 00:04:25,100
tensor flow and with tensor

00:04:23,660 --> 00:04:26,960
enterprise we're really excited about

00:04:25,100 --> 00:04:28,070
this being Google cloud being the best

00:04:26,960 --> 00:04:31,310
place to run tensorflow

00:04:28,070 --> 00:04:34,250
mm-hmm and what do you see people using

00:04:31,310 --> 00:04:36,290
mostly everything yeah I mean you know

00:04:34,250 --> 00:04:38,210
certainly we we still we see a

00:04:36,290 --> 00:04:42,620
tremendous amount of tons of flow usage

00:04:38,210 --> 00:04:45,290
you know we also all say the I think the

00:04:42,620 --> 00:04:46,790
world underestimates the value of kind

00:04:45,290 --> 00:04:48,710
of more traditional machine learning

00:04:46,790 --> 00:04:51,020
right and you know whether it's XG boost

00:04:48,710 --> 00:04:53,390
or linear models you know for in many

00:04:51,020 --> 00:04:55,370
many times those models solve things you

00:04:53,390 --> 00:04:56,570
know with similar efficacy and a whole

00:04:55,370 --> 00:05:01,760
lot easier more easily

00:04:56,570 --> 00:05:05,180
I think Occam's razor something

00:05:01,760 --> 00:05:07,100
absolutely absolutely now it's I think

00:05:05,180 --> 00:05:08,600
you know both the innovations and deep

00:05:07,100 --> 00:05:10,700
learning as well as kind of a more

00:05:08,600 --> 00:05:12,860
traditional machine learning are but you

00:05:10,700 --> 00:05:15,590
know we're seeing strong deployments of

00:05:12,860 --> 00:05:18,590
kind of both directions on that path

00:05:15,590 --> 00:05:21,770
yeah and my guess is that people will

00:05:18,590 --> 00:05:22,910
get used to what works best that I think

00:05:21,770 --> 00:05:24,770
right now it's still a bit of an art

00:05:22,910 --> 00:05:27,890
that that's right and you know I think

00:05:24,770 --> 00:05:30,380
the the piece for me is that as we watch

00:05:27,890 --> 00:05:32,720
them do this at you know as cloud gets

00:05:30,380 --> 00:05:35,390
to a place where it can get faster and

00:05:32,720 --> 00:05:37,370
scale even more powerfully I think what

00:05:35,390 --> 00:05:39,380
the the big transition I see is around

00:05:37,370 --> 00:05:42,650
hyper parameter optimization and you

00:05:39,380 --> 00:05:44,660
know the art of you know kind of these

00:05:42,650 --> 00:05:46,910
hyper parameters that you know some of

00:05:44,660 --> 00:05:49,730
us and some folks out there understand

00:05:46,910 --> 00:05:52,250
at some level you know instead passing

00:05:49,730 --> 00:05:55,100
that to a computer to take care of is

00:05:52,250 --> 00:05:57,169
really accelerating you know learning

00:05:55,100 --> 00:05:59,900
and and network architecture as well

00:05:57,169 --> 00:06:02,780
right you know both of those two are

00:05:59,900 --> 00:06:05,000
really accelerating learning in new and

00:06:02,780 --> 00:06:08,419
exciting ways yeah we actually think of

00:06:05,000 --> 00:06:09,980
ml for ML yeah and really for so many

00:06:08,419 --> 00:06:12,560
other things it's actually one of the

00:06:09,980 --> 00:06:14,240
big trends we'll see sure oh yeah no

00:06:12,560 --> 00:06:15,440
it's it's certainly with the auto ml

00:06:14,240 --> 00:06:17,360
products we've gotten out there and

00:06:15,440 --> 00:06:19,840
market it that's an area where customers

00:06:17,360 --> 00:06:22,040
have shown a lot of excitement mm-hmm

00:06:19,840 --> 00:06:23,600
including I know that there's some

00:06:22,040 --> 00:06:27,410
things out there to help people

00:06:23,600 --> 00:06:29,840
like ml to help regular code yeah yeah

00:06:27,410 --> 00:06:32,180
it's a it's an area I mean I think all

00:06:29,840 --> 00:06:33,979
of this language generation whether it's

00:06:32,180 --> 00:06:35,240
we think of it as English but you know

00:06:33,979 --> 00:06:37,040
there's no reason why some of these

00:06:35,240 --> 00:06:39,740
language generation models can't be

00:06:37,040 --> 00:06:42,050
turned to computer science as well great

00:06:39,740 --> 00:06:43,850
so this all sounds pretty exciting where

00:06:42,050 --> 00:06:46,790
do you go if you want to try it out yeah

00:06:43,850 --> 00:06:47,210
so I you know if you go to you know

00:06:46,790 --> 00:06:51,020
Jesus

00:06:47,210 --> 00:06:52,669
Chico slash cloud slash tensorflow you

00:06:51,020 --> 00:06:54,500
can check out kind of what our new

00:06:52,669 --> 00:06:56,600
offering with tensorflow Enterprise and

00:06:54,500 --> 00:06:58,460
get started there the great thing about

00:06:56,600 --> 00:07:00,650
tensorflow enterprises it's not a

00:06:58,460 --> 00:07:02,900
special SKU that you have to pay extra

00:07:00,650 --> 00:07:05,330
for every Google cloud customer gets it

00:07:02,900 --> 00:07:07,430
included when they use Google cloud to

00:07:05,330 --> 00:07:08,780
do their machine learning great well

00:07:07,430 --> 00:07:10,840
thanks a lot for your time today thank

00:07:08,780 --> 00:07:10,840

YouTube URL: https://www.youtube.com/watch?v=k1b9Zj3NKXw


