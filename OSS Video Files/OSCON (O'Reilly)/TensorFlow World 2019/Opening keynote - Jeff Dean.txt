Title: Opening keynote - Jeff Dean
Publication date: 2019-10-30
Playlist: TensorFlow World 2019
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:02,230 --> 00:00:06,160
I'm really excited to be here I think it

00:00:04,359 --> 00:00:08,980
was almost four years ago to the day

00:00:06,160 --> 00:00:10,719
that we were about 20 people sitting in

00:00:08,980 --> 00:00:13,059
a small conference room and one of the

00:00:10,719 --> 00:00:14,320
Google buildings we've woken up early

00:00:13,059 --> 00:00:16,630
because we wanted a kind of time this

00:00:14,320 --> 00:00:18,400
for an early East Coast launch where we

00:00:16,630 --> 00:00:21,010
were turning on the tent of flow org

00:00:18,400 --> 00:00:22,330
website and releasing the first version

00:00:21,010 --> 00:00:25,480
of tensorflow as an open source product

00:00:22,330 --> 00:00:27,820
at project and I'm really really excited

00:00:25,480 --> 00:00:29,920
to see what it's become it's just

00:00:27,820 --> 00:00:31,420
remarkable to see the growth and all the

00:00:29,920 --> 00:00:33,790
different kinds of ways in which people

00:00:31,420 --> 00:00:36,360
have used this system for all kinds of

00:00:33,790 --> 00:00:38,680
interesting things around the world so

00:00:36,360 --> 00:00:40,809
one thing that's interesting is the

00:00:38,680 --> 00:00:43,210
growth in the use of tensor flow also

00:00:40,809 --> 00:00:44,769
kind of mirrors the growth in interest

00:00:43,210 --> 00:00:47,409
in machine learning and machine learning

00:00:44,769 --> 00:00:49,119
research generally around the world so

00:00:47,409 --> 00:00:51,369
this is a graph showing the number of

00:00:49,119 --> 00:00:54,129
machine learning archived papers that

00:00:51,369 --> 00:00:55,690
have been posted over the last sort of

00:00:54,129 --> 00:00:58,320
10 years or so and you can see it's

00:00:55,690 --> 00:01:01,659
growing quite quite rapidly much more

00:00:58,320 --> 00:01:04,710
quickly than you might expect and but

00:01:01,659 --> 00:01:07,150
that lower red line is kind of the nice

00:01:04,710 --> 00:01:09,130
doubling every couple of years growth

00:01:07,150 --> 00:01:13,150
rate exponential growth rate we got used

00:01:09,130 --> 00:01:14,470
to in computing power for due to Moore's

00:01:13,150 --> 00:01:16,570
law for so many years

00:01:14,470 --> 00:01:17,620
that's now kind of slowed down but you

00:01:16,570 --> 00:01:19,360
can see that the machine learning

00:01:17,620 --> 00:01:21,760
research community is generating

00:01:19,360 --> 00:01:24,190
research ideas at faster than that right

00:01:21,760 --> 00:01:25,870
which is pretty remarkable we've

00:01:24,190 --> 00:01:29,200
replaced computational growth with

00:01:25,870 --> 00:01:31,000
growth of ideas and we'll see those both

00:01:29,200 --> 00:01:32,620
together will be important and really

00:01:31,000 --> 00:01:34,870
the excitement about machine learning is

00:01:32,620 --> 00:01:38,620
because we can now do things we couldn't

00:01:34,870 --> 00:01:39,280
do before right as little as five or six

00:01:38,620 --> 00:01:41,260
years ago

00:01:39,280 --> 00:01:44,560
computers really couldn't see that well

00:01:41,260 --> 00:01:46,990
and starting in about you know 2012 2013

00:01:44,560 --> 00:01:49,050
we started to have people use deep

00:01:46,990 --> 00:01:51,040
neural networks to try to tackle

00:01:49,050 --> 00:01:53,020
computer vision problems image

00:01:51,040 --> 00:01:55,479
classification object detection and

00:01:53,020 --> 00:01:57,580
things like that and so now using deep

00:01:55,479 --> 00:01:59,409
learning and deep neural networks you

00:01:57,580 --> 00:02:02,530
can feed in the raw pixels of an image

00:01:59,409 --> 00:02:05,049
and fairly reliably get a prediction of

00:02:02,530 --> 00:02:06,729
what kind of object is in that image you

00:02:05,049 --> 00:02:08,649
know feeding the pixels they're red

00:02:06,729 --> 00:02:11,020
green and blue values in a bunch of

00:02:08,649 --> 00:02:14,080
different coordinates and you get out

00:02:11,020 --> 00:02:15,730
the prediction Leopard this works for

00:02:14,080 --> 00:02:19,300
speed too so while you can feed in

00:02:15,730 --> 00:02:21,280
audio waveforms and by training on lots

00:02:19,300 --> 00:02:22,810
of audio waveforms and transcripts of

00:02:21,280 --> 00:02:24,220
what's being said in those waveforms we

00:02:22,810 --> 00:02:26,680
can actually take a completely new

00:02:24,220 --> 00:02:28,269
recording and tell you what is being

00:02:26,680 --> 00:02:32,319
said I made a transcript well Jerome

00:02:28,269 --> 00:02:34,780
Italia you can even combine these ideas

00:02:32,319 --> 00:02:36,220
and have models that take in pixels and

00:02:34,780 --> 00:02:38,799
instead of just predicting

00:02:36,220 --> 00:02:40,299
classification classifications of water

00:02:38,799 --> 00:02:42,730
is in the object can actually write a

00:02:40,299 --> 00:02:44,560
short sentence a short caption that a

00:02:42,730 --> 00:02:46,420
human might write about about the image

00:02:44,560 --> 00:02:48,340
you know a cheetah lying on top of a car

00:02:46,420 --> 00:02:53,470
that's one of my vacation photos which

00:02:48,340 --> 00:02:56,640
was kind of cool and so just to show the

00:02:53,470 --> 00:02:59,170
progress in computer vision in 2011

00:02:56,640 --> 00:03:01,870
Stanford hosts an image net contest

00:02:59,170 --> 00:03:03,940
every year to see how well compute

00:03:01,870 --> 00:03:05,709
computer vision systems can predict one

00:03:03,940 --> 00:03:07,629
of a thousand categories in a full-color

00:03:05,709 --> 00:03:10,120
image and you get about a million images

00:03:07,629 --> 00:03:12,220
to train on and then you get you know a

00:03:10,120 --> 00:03:13,390
bunch of test images you've your model

00:03:12,220 --> 00:03:15,910
has never seen before and you make it

00:03:13,390 --> 00:03:17,379
need to make a prediction in 2011 the

00:03:15,910 --> 00:03:19,900
winning entrant got twenty six percent

00:03:17,379 --> 00:03:21,069
error right so you can kind of make out

00:03:19,900 --> 00:03:24,310
what that is but it's pretty hard to

00:03:21,069 --> 00:03:27,099
tell we know from a human experiment

00:03:24,310 --> 00:03:28,389
that human error of a well-trained human

00:03:27,099 --> 00:03:30,310
someone who's practiced at this

00:03:28,389 --> 00:03:32,440
particular task and really understands

00:03:30,310 --> 00:03:34,859
the thousand categories gets about five

00:03:32,440 --> 00:03:38,019
percent error this is not a trivial task

00:03:34,859 --> 00:03:40,030
and in 2016 the winning entrant got

00:03:38,019 --> 00:03:41,919
three percent error so just look at that

00:03:40,030 --> 00:03:44,410
tremendous progress in the ability of

00:03:41,919 --> 00:03:46,750
computers to resolve and understand

00:03:44,410 --> 00:03:48,669
computer imagery and and and have

00:03:46,750 --> 00:03:51,280
computer vision that actually works

00:03:48,669 --> 00:03:53,230
this is remarkably important in the

00:03:51,280 --> 00:03:55,269
world because now we have systems that

00:03:53,230 --> 00:03:56,769
can perceive the world around this and

00:03:55,269 --> 00:03:59,319
can we can do all kinds of really

00:03:56,769 --> 00:04:00,459
interesting things that we've seen

00:03:59,319 --> 00:04:02,410
similar progress in speech recognition

00:04:00,459 --> 00:04:06,220
and language translation and things like

00:04:02,410 --> 00:04:08,470
that so for the rest of the talk I'd

00:04:06,220 --> 00:04:12,430
like to kind of structure it around this

00:04:08,470 --> 00:04:14,769
nice list of 14 challenges that the US

00:04:12,430 --> 00:04:16,840
National Academy engineering put out and

00:04:14,769 --> 00:04:18,130
felt like these were important things

00:04:16,840 --> 00:04:20,169
for the science and engineering

00:04:18,130 --> 00:04:23,169
communities to work on for the next

00:04:20,169 --> 00:04:25,419
hundred years they they put this out in

00:04:23,169 --> 00:04:28,060
2008 and came up with this list of 14

00:04:25,419 --> 00:04:29,590
things after some deliberation and I

00:04:28,060 --> 00:04:31,510
think you'll agree that these are

00:04:29,590 --> 00:04:33,100
sort of pretty pretty good large

00:04:31,510 --> 00:04:34,900
challenging problems that if we actually

00:04:33,100 --> 00:04:37,900
make progress on them till we'll

00:04:34,900 --> 00:04:39,430
actually have you know you know a lot of

00:04:37,900 --> 00:04:40,720
progress in the world we'll be healthier

00:04:39,430 --> 00:04:42,310
we'll be able to learn things better

00:04:40,720 --> 00:04:44,470
we'll be able to develop better

00:04:42,310 --> 00:04:47,380
medicines you know we'll have all kinds

00:04:44,470 --> 00:04:49,330
of interesting energy solutions so I'm

00:04:47,380 --> 00:04:50,920
going to talk about a few of these and

00:04:49,330 --> 00:04:52,570
the first one I'll talk about is

00:04:50,920 --> 00:04:57,930
restoring and improving urban

00:04:52,570 --> 00:05:01,300
infrastructure so we're on the cusp of

00:04:57,930 --> 00:05:03,550
the sort of widespread commercialization

00:05:01,300 --> 00:05:05,650
of a really interesting new technology

00:05:03,550 --> 00:05:07,750
that's going to really change how we

00:05:05,650 --> 00:05:11,890
think about transportation and that is

00:05:07,750 --> 00:05:13,240
autonomous vehicles and you know this is

00:05:11,890 --> 00:05:15,580
a problem that has been worked on for

00:05:13,240 --> 00:05:17,320
quite a while but it's now starting to

00:05:15,580 --> 00:05:19,630
look like it's actually completely

00:05:17,320 --> 00:05:21,670
possible and commercially viable to

00:05:19,630 --> 00:05:23,530
produce these things and a lot of the

00:05:21,670 --> 00:05:25,210
reason is that we now have computer

00:05:23,530 --> 00:05:27,700
computer vision and machine learning

00:05:25,210 --> 00:05:29,770
techniques that can take in sort of raw

00:05:27,700 --> 00:05:31,510
forms of data that the sensors on these

00:05:29,770 --> 00:05:33,040
cars collect you know so they have like

00:05:31,510 --> 00:05:35,260
the spinning light R's on the top that

00:05:33,040 --> 00:05:36,490
give them 3d point cloud data they have

00:05:35,260 --> 00:05:39,940
cameras and lots of different directions

00:05:36,490 --> 00:05:41,980
they have radar in you know the front

00:05:39,940 --> 00:05:44,050
bumper and the rear bumper and they can

00:05:41,980 --> 00:05:46,270
really take all this raw information in

00:05:44,050 --> 00:05:48,100
and with a deep neural network fuse it

00:05:46,270 --> 00:05:49,930
all together to build a high level

00:05:48,100 --> 00:05:53,050
understanding of what is going on around

00:05:49,930 --> 00:05:55,330
the car or is it like at another car

00:05:53,050 --> 00:05:56,860
door my side there's a pedestrian up

00:05:55,330 --> 00:05:58,120
here to the left there's a light post

00:05:56,860 --> 00:06:00,880
over there I don't really need to worry

00:05:58,120 --> 00:06:02,680
about that moving and really help to

00:06:00,880 --> 00:06:04,540
understand the environment in which

00:06:02,680 --> 00:06:06,700
they're operating and then what actions

00:06:04,540 --> 00:06:09,220
can they take in the world that are both

00:06:06,700 --> 00:06:12,430
legal safe obey all the traffic laws and

00:06:09,220 --> 00:06:16,120
get them from A to B and this is not

00:06:12,430 --> 00:06:17,740
some distant far-off dream alphabets way

00:06:16,120 --> 00:06:19,600
mo subsidiaries actually been running

00:06:17,740 --> 00:06:21,010
tests in Phoenix Arizona normally when

00:06:19,600 --> 00:06:23,050
they run tests they have a safety driver

00:06:21,010 --> 00:06:24,520
on the front seat ready to take over if

00:06:23,050 --> 00:06:26,680
the car does something kind of

00:06:24,520 --> 00:06:28,270
unexpected but for the last year or so

00:06:26,680 --> 00:06:31,960
they've been running tests in Phoenix

00:06:28,270 --> 00:06:33,730
with real passengers in the back seat

00:06:31,960 --> 00:06:36,730
and no safety drivers in the front seat

00:06:33,730 --> 00:06:38,860
running around suburban Phoenix so

00:06:36,730 --> 00:06:40,330
suburban Phoenix is a slightly easier

00:06:38,860 --> 00:06:43,040
training ground than say downtown

00:06:40,330 --> 00:06:44,960
Manhattan or San Francisco but

00:06:43,040 --> 00:06:46,910
it's still something that is like not

00:06:44,960 --> 00:06:48,950
really far off it's something that's

00:06:46,910 --> 00:06:51,230
actually happening and this is really

00:06:48,950 --> 00:06:54,020
possible because of things like machine

00:06:51,230 --> 00:06:57,290
learning and the use of tensorflow in in

00:06:54,020 --> 00:06:59,150
these systems another one that I'm

00:06:57,290 --> 00:07:01,430
really really excited about is advanced

00:06:59,150 --> 00:07:03,830
health informatics this is a really

00:07:01,430 --> 00:07:05,360
broad area and I think there's lots and

00:07:03,830 --> 00:07:07,640
lots of ways that machine learning and

00:07:05,360 --> 00:07:09,320
the use of healthcare data can be used

00:07:07,640 --> 00:07:12,140
to make better healthcare decisions for

00:07:09,320 --> 00:07:14,510
people so I'll talk about one of them

00:07:12,140 --> 00:07:17,180
and really I think the potential here is

00:07:14,510 --> 00:07:20,300
that we can use machine learning to

00:07:17,180 --> 00:07:22,520
bring the wisdom of experts through a

00:07:20,300 --> 00:07:26,270
machine learning model anywhere in the

00:07:22,520 --> 00:07:28,760
world and that's really a huge huge

00:07:26,270 --> 00:07:30,770
opportunity so let's look at this

00:07:28,760 --> 00:07:32,090
through one problem we've been working

00:07:30,770 --> 00:07:34,700
on for a while which is diabetic

00:07:32,090 --> 00:07:36,830
retinopathy so diabetic retinopathy is

00:07:34,700 --> 00:07:41,330
the fastest growing cause of preventable

00:07:36,830 --> 00:07:43,610
blindness in the world and screening

00:07:41,330 --> 00:07:46,010
every year if you're at risk for this

00:07:43,610 --> 00:07:48,530
and if you're if you have diabetes or

00:07:46,010 --> 00:07:50,360
early sort of symptoms that make it

00:07:48,530 --> 00:07:52,250
likely you might develop diabetes you

00:07:50,360 --> 00:07:54,350
should really get screened every year so

00:07:52,250 --> 00:07:56,020
there's 400 million people around the

00:07:54,350 --> 00:07:58,280
world that should be screened every year

00:07:56,020 --> 00:07:59,980
but the screening is really specialized

00:07:58,280 --> 00:08:02,720
doctors can't do it you really need a

00:07:59,980 --> 00:08:05,000
ophthalmologist level of training in

00:08:02,720 --> 00:08:06,650
order to do this effectively and the

00:08:05,000 --> 00:08:08,720
impact of this shortage is significant

00:08:06,650 --> 00:08:10,190
so in India for example there's a

00:08:08,720 --> 00:08:12,200
shortage of a hundred and twenty seven

00:08:10,190 --> 00:08:15,290
thousand eye doctors to do this sort of

00:08:12,200 --> 00:08:18,020
screening and as a result 45 percent of

00:08:15,290 --> 00:08:19,490
patients who are diagnosed to this

00:08:18,020 --> 00:08:21,020
disease actually have suffered either

00:08:19,490 --> 00:08:22,880
full or partial vision loss before

00:08:21,020 --> 00:08:25,160
they're actually diagnosed and then

00:08:22,880 --> 00:08:26,900
treated and this is completely tragic

00:08:25,160 --> 00:08:28,640
because this disease if you catch it in

00:08:26,900 --> 00:08:31,310
time is completely treatable there's a

00:08:28,640 --> 00:08:33,590
very simple 99% effective treatment that

00:08:31,310 --> 00:08:37,180
we just need to make sure that the right

00:08:33,590 --> 00:08:41,330
people get treated at the right time so

00:08:37,180 --> 00:08:43,220
what can you do so it turns out diabetic

00:08:41,330 --> 00:08:45,140
retinopathy screening is also a computer

00:08:43,220 --> 00:08:47,540
vision problem and the progress we've

00:08:45,140 --> 00:08:49,760
made on general computer vision problems

00:08:47,540 --> 00:08:51,590
where you want to take a take a picture

00:08:49,760 --> 00:08:54,350
and tell if that's a leopard or an

00:08:51,590 --> 00:08:56,360
aircraft or a car actually also works

00:08:54,350 --> 00:08:57,230
for diabetic retinopathy so you can take

00:08:56,360 --> 00:08:59,690
a retinal image

00:08:57,230 --> 00:09:00,980
is what the screaming camera sort of the

00:08:59,690 --> 00:09:03,770
raw data that comes off the screening

00:09:00,980 --> 00:09:05,900
camera and try to feed that into a model

00:09:03,770 --> 00:09:07,730
that predicts one two three four or five

00:09:05,900 --> 00:09:09,320
that's how these things are graded you

00:09:07,730 --> 00:09:11,630
know one being no diabetic retinopathy

00:09:09,320 --> 00:09:14,540
five being proliferative and the other

00:09:11,630 --> 00:09:17,270
numbers being in between so turns out

00:09:14,540 --> 00:09:19,400
you can get a collection of data of

00:09:17,270 --> 00:09:22,940
retinal images and have ophthalmologists

00:09:19,400 --> 00:09:24,650
label them turns out if you ask two

00:09:22,940 --> 00:09:26,810
ophthalmologists to label the same image

00:09:24,650 --> 00:09:28,820
they agree with each other sixty percent

00:09:26,810 --> 00:09:31,580
of the time on the number one two three

00:09:28,820 --> 00:09:33,170
four or five but perhaps slightly

00:09:31,580 --> 00:09:35,120
scarier if you ask the same

00:09:33,170 --> 00:09:37,070
ophthalmologist degrade the same image a

00:09:35,120 --> 00:09:38,510
few hours apart they agree with

00:09:37,070 --> 00:09:42,560
themselves sixty five percent of the

00:09:38,510 --> 00:09:44,690
time but you can fix this by actually

00:09:42,560 --> 00:09:46,400
getting each image labeled by a lot of

00:09:44,690 --> 00:09:48,410
ophthalmologists so you get it labeled

00:09:46,400 --> 00:09:49,880
by seven ophthalmologists if five of

00:09:48,410 --> 00:09:50,990
them say at the - and two of them say

00:09:49,880 --> 00:09:52,940
it's a three it's probably more like a

00:09:50,990 --> 00:09:54,440
tooth and a three eventually you have a

00:09:52,940 --> 00:09:56,180
nice high quality it is that you can

00:09:54,440 --> 00:09:59,030
train on like many machine learning

00:09:56,180 --> 00:10:01,700
problems high quality data is the right

00:09:59,030 --> 00:10:04,010
raw ingredient but then you can apply

00:10:01,700 --> 00:10:06,170
basically an off-the-shelf computer

00:10:04,010 --> 00:10:10,160
vision model trained on this data set

00:10:06,170 --> 00:10:12,530
and now you can get a model that is on

00:10:10,160 --> 00:10:13,850
par or perhaps slightly better than the

00:10:12,530 --> 00:10:18,200
average board-certified ophthalmologist

00:10:13,850 --> 00:10:20,060
Sameer s which is pretty amazing it

00:10:18,200 --> 00:10:20,600
turns out you can actually do better

00:10:20,060 --> 00:10:23,330
than that

00:10:20,600 --> 00:10:25,040
and if you get the data labeled by

00:10:23,330 --> 00:10:28,280
retinal specialists people who have more

00:10:25,040 --> 00:10:30,110
training in retinal disease and have and

00:10:28,280 --> 00:10:31,730
changed the protocol by which you label

00:10:30,110 --> 00:10:34,010
things you get three retinal specialists

00:10:31,730 --> 00:10:36,050
to look at an image discuss it amongst

00:10:34,010 --> 00:10:39,650
themselves and come up with a what's

00:10:36,050 --> 00:10:43,580
called a I sort of coordinated

00:10:39,650 --> 00:10:45,410
assessment and one one number then you

00:10:43,580 --> 00:10:46,940
can train a model and now be on par with

00:10:45,410 --> 00:10:49,180
retinal specialist which is kind of the

00:10:46,940 --> 00:10:51,890
gold standard of care in this area and

00:10:49,180 --> 00:10:57,590
that's something you can now take and

00:10:51,890 --> 00:10:59,000
distribute widely around the world so

00:10:57,590 --> 00:11:01,910
one issue with with particularly with

00:10:59,000 --> 00:11:03,500
healthcare kinds of problems is you want

00:11:01,910 --> 00:11:05,300
explainable models you want to be able

00:11:03,500 --> 00:11:09,050
to explain to a clinician you know why

00:11:05,300 --> 00:11:10,990
is this person why do we think this

00:11:09,050 --> 00:11:12,790
person has moderate diabetic retinopathy

00:11:10,990 --> 00:11:14,860
so you can take a retinal image like

00:11:12,790 --> 00:11:18,210
this and one of the things that really

00:11:14,860 --> 00:11:21,820
helps is if you can show in the models

00:11:18,210 --> 00:11:23,980
assessment why this is a 2 and not a 3

00:11:21,820 --> 00:11:25,630
and by highlighting parts of the input

00:11:23,980 --> 00:11:27,730
data you can actually make this more

00:11:25,630 --> 00:11:29,470
understandable for clinicians and enable

00:11:27,730 --> 00:11:31,510
them to sort of really sort of get

00:11:29,470 --> 00:11:33,250
behind the assessment that the model is

00:11:31,510 --> 00:11:35,410
making and we've seen this in other

00:11:33,250 --> 00:11:36,760
areas as well it's been a lot of work

00:11:35,410 --> 00:11:38,920
unexplained ability so I think the

00:11:36,760 --> 00:11:40,860
notion that deep neural networks are

00:11:38,920 --> 00:11:43,090
sort of complete black boxes it's a bit

00:11:40,860 --> 00:11:44,320
overdone there's actually a bunch of

00:11:43,090 --> 00:11:45,130
good techniques that are being developed

00:11:44,320 --> 00:11:49,090
and more all the time

00:11:45,130 --> 00:11:50,620
that will improve this so a bunch of

00:11:49,090 --> 00:11:53,560
advances depend on being able to

00:11:50,620 --> 00:11:55,120
understand text so and we've had a lot

00:11:53,560 --> 00:11:59,230
of really good improvements in the last

00:11:55,120 --> 00:12:02,140
few years on language understanding so

00:11:59,230 --> 00:12:04,660
this is a bit of a story of research and

00:12:02,140 --> 00:12:06,910
how research builds on other research so

00:12:04,660 --> 00:12:09,280
in 2017 a collection of Google

00:12:06,910 --> 00:12:11,080
researchers and interns came up with a

00:12:09,280 --> 00:12:13,870
new kind of model for text called the

00:12:11,080 --> 00:12:15,340
transformer model so unlike recurrent

00:12:13,870 --> 00:12:18,280
models where you have kind of a

00:12:15,340 --> 00:12:20,890
sequential process where you absorb one

00:12:18,280 --> 00:12:22,960
word or one token at a time and update

00:12:20,890 --> 00:12:24,970
some internal stage and then go on to

00:12:22,960 --> 00:12:27,220
the next token the transformer model

00:12:24,970 --> 00:12:29,740
enables you to process a whole bunch of

00:12:27,220 --> 00:12:31,390
text all at once in parallel making it

00:12:29,740 --> 00:12:34,270
much more computationally efficient and

00:12:31,390 --> 00:12:36,160
then to use attention on previous text

00:12:34,270 --> 00:12:37,960
to really focus on if I'm trying to

00:12:36,160 --> 00:12:39,850
predict what the next word is you know

00:12:37,960 --> 00:12:41,830
what are other parts of the context to

00:12:39,850 --> 00:12:45,040
the left that are relevant to predicting

00:12:41,830 --> 00:12:46,840
that so that paper was was quite

00:12:45,040 --> 00:12:48,970
successful and showed really good

00:12:46,840 --> 00:12:51,520
results on language translation tasks

00:12:48,970 --> 00:12:52,900
with a lot less compute so the blue

00:12:51,520 --> 00:12:54,280
score there and the first two columns

00:12:52,900 --> 00:12:57,970
for English to German and English to

00:12:54,280 --> 00:13:00,340
French higher is better and then the the

00:12:57,970 --> 00:13:01,630
compute cost of these models shows that

00:13:00,340 --> 00:13:04,300
this is getting sort of state-of-the-art

00:13:01,630 --> 00:13:08,290
results at that time with 10 to 100 X

00:13:04,300 --> 00:13:10,660
less compute than other approaches then

00:13:08,290 --> 00:13:12,910
in 2018 another team of Google

00:13:10,660 --> 00:13:14,470
researchers built on the idea of

00:13:12,910 --> 00:13:16,720
transformers so everything you see there

00:13:14,470 --> 00:13:18,550
in a blue oval is a transformer module

00:13:16,720 --> 00:13:21,040
and they came up with this approach is

00:13:18,550 --> 00:13:23,410
called bi-directional encoder encoding

00:13:21,040 --> 00:13:25,660
representations from transformers or

00:13:23,410 --> 00:13:29,860
Burtt we it's a little bit shorter and

00:13:25,660 --> 00:13:31,480
more catchy so Burt has this really nice

00:13:29,860 --> 00:13:33,940
property that in addition to using

00:13:31,480 --> 00:13:38,139
context to the left it uses context all

00:13:33,940 --> 00:13:39,970
around the language the the sort of the

00:13:38,139 --> 00:13:42,250
surrounding text in order to make

00:13:39,970 --> 00:13:45,339
predictions about text and the way it

00:13:42,250 --> 00:13:47,259
works is you start with a self

00:13:45,339 --> 00:13:49,120
supervisor objective so the one really

00:13:47,259 --> 00:13:50,589
nice thing about this is there's lots

00:13:49,120 --> 00:13:53,139
and lots of text in the world so if you

00:13:50,589 --> 00:13:55,000
can figure out a way to use that text to

00:13:53,139 --> 00:13:56,920
train a model to be able to understand

00:13:55,000 --> 00:13:59,680
text better that would be great so we're

00:13:56,920 --> 00:14:01,360
gonna take this text and in the bird

00:13:59,680 --> 00:14:03,730
training objective to make it self

00:14:01,360 --> 00:14:06,040
supervised we're gonna drop about 15

00:14:03,730 --> 00:14:07,899
percent of the words and this is

00:14:06,040 --> 00:14:09,490
actually pretty hard but the model is

00:14:07,899 --> 00:14:11,680
then gonna try to fill in the blanks

00:14:09,490 --> 00:14:12,939
essentially try to predict what are the

00:14:11,680 --> 00:14:15,100
missing words that were dropped and

00:14:12,939 --> 00:14:18,490
because we actually have the original

00:14:15,100 --> 00:14:19,930
words we now know you know if the model

00:14:18,490 --> 00:14:21,939
is correct and it's guesses about what

00:14:19,930 --> 00:14:23,410
goes in the box and by processing

00:14:21,939 --> 00:14:24,310
trillions of words or texts like this

00:14:23,410 --> 00:14:26,800
you actually get a very good

00:14:24,310 --> 00:14:28,870
understanding of contextual cues in

00:14:26,800 --> 00:14:32,110
language and how to actually fill in the

00:14:28,870 --> 00:14:33,519
blanks in a really intelligent way and

00:14:32,110 --> 00:14:35,860
so that's essentially the training

00:14:33,519 --> 00:14:38,620
objective for bird you take text you

00:14:35,860 --> 00:14:44,230
drop 15 percent of it and then you try

00:14:38,620 --> 00:14:45,699
to predict those missing words and one

00:14:44,230 --> 00:14:48,399
key thing that works really well is

00:14:45,699 --> 00:14:50,560
that's step one you can pre train a

00:14:48,399 --> 00:14:52,630
model on lots and lots of text using

00:14:50,560 --> 00:14:55,449
this fill in the blanks self supervisor

00:14:52,630 --> 00:14:57,430
objective function and then step two you

00:14:55,449 --> 00:14:58,540
can then take a language task you really

00:14:57,430 --> 00:15:00,939
care about like maybe you want to

00:14:58,540 --> 00:15:02,740
predict is this a you know a five star

00:15:00,939 --> 00:15:04,509
review or a one star review for some

00:15:02,740 --> 00:15:06,579
hotel but you don't have very much

00:15:04,509 --> 00:15:08,410
labeled text for that for that actual

00:15:06,579 --> 00:15:12,130
task you might have 10,000 reviews and

00:15:08,410 --> 00:15:13,630
know the star count of each review but

00:15:12,130 --> 00:15:15,910
you can then fine-tune the model

00:15:13,630 --> 00:15:17,620
starting with the model trained in step

00:15:15,910 --> 00:15:20,889
one on trillions of words of text and

00:15:17,620 --> 00:15:22,540
now use your paltry 10,000 examples for

00:15:20,889 --> 00:15:24,279
the text task you really care about and

00:15:22,540 --> 00:15:26,769
that works extremely well

00:15:24,279 --> 00:15:28,750
so in particular Bert gave

00:15:26,769 --> 00:15:30,579
state-of-the-art results across a broad

00:15:28,750 --> 00:15:34,000
range of different text understanding

00:15:30,579 --> 00:15:36,970
benchmarks in this glue benchmark suite

00:15:34,000 --> 00:15:37,480
which was pretty cool and people have

00:15:36,970 --> 00:15:39,850
been using

00:15:37,480 --> 00:15:42,279
now in this way to improve all kinds of

00:15:39,850 --> 00:15:47,620
different things all across the language

00:15:42,279 --> 00:15:49,750
understanding in an LP space so one of

00:15:47,620 --> 00:15:51,130
the grand challenges was engineer the

00:15:49,750 --> 00:15:53,470
tools of scientific discovery and I

00:15:51,130 --> 00:15:54,639
think it's pretty clear machine learning

00:15:53,470 --> 00:15:56,290
is actually going to be an important

00:15:54,639 --> 00:15:57,820
component of making advances in a lot of

00:15:56,290 --> 00:15:59,949
these other Grand Challenge areas things

00:15:57,820 --> 00:16:02,769
like autonomous vehicles or other kinds

00:15:59,949 --> 00:16:06,190
of things and it's been really

00:16:02,769 --> 00:16:08,350
satisfying to see what we'd hoped would

00:16:06,190 --> 00:16:10,779
happen when we release tensorflow as an

00:16:08,350 --> 00:16:13,870
open source project has actually kind of

00:16:10,779 --> 00:16:15,820
come to come to pass as we were hoping

00:16:13,870 --> 00:16:17,019
in that lots of people would sort of

00:16:15,820 --> 00:16:18,730
pick up tensorflow

00:16:17,019 --> 00:16:20,709
use it for all kinds of things people

00:16:18,730 --> 00:16:22,810
would improve the core system they would

00:16:20,709 --> 00:16:25,120
use it for tasks we would never imagine

00:16:22,810 --> 00:16:26,440
and that's been quite satisfying so

00:16:25,120 --> 00:16:29,260
people have done all kinds of things

00:16:26,440 --> 00:16:31,329
some of these are our uses intra inside

00:16:29,260 --> 00:16:33,190
of Google some are outside inside

00:16:31,329 --> 00:16:35,230
academic institutions some are you know

00:16:33,190 --> 00:16:37,740
scientists working on conserving whales

00:16:35,230 --> 00:16:39,910
or understanding like ancient scripts

00:16:37,740 --> 00:16:42,970
many kinds of things which is pretty

00:16:39,910 --> 00:16:47,709
neat the breadth of breadth of uses is

00:16:42,970 --> 00:16:51,100
really amazing this these are the 20

00:16:47,709 --> 00:16:52,660
winners of the google.org a I impact

00:16:51,100 --> 00:16:54,699
challenge where people could submit

00:16:52,660 --> 00:16:57,459
proposal for how they might use machine

00:16:54,699 --> 00:16:59,139
learning and AI to really tackle a local

00:16:57,459 --> 00:17:01,839
challenge they saw in their communities

00:16:59,139 --> 00:17:04,079
and they have all kinds of things keep

00:17:01,839 --> 00:17:06,520
ranging from like trying to predict

00:17:04,079 --> 00:17:09,850
better ambulance dispatching to

00:17:06,520 --> 00:17:12,490
identifying sort of illegal logging

00:17:09,850 --> 00:17:16,150
using speech recognition or audio

00:17:12,490 --> 00:17:17,829
processing pretty neat and many of them

00:17:16,150 --> 00:17:19,600
are using tensorflow so one of the

00:17:17,829 --> 00:17:22,900
things we're pretty excited about is

00:17:19,600 --> 00:17:24,490
auto ml which is this idea of automating

00:17:22,900 --> 00:17:27,850
some of the process by which machine

00:17:24,490 --> 00:17:29,710
learning experts sit down and sort of

00:17:27,850 --> 00:17:32,350
make decisions to solve machine learning

00:17:29,710 --> 00:17:34,120
problems so currently you have a machine

00:17:32,350 --> 00:17:35,740
learning expert sit down they take data

00:17:34,120 --> 00:17:37,179
they have computation they run a bunch

00:17:35,740 --> 00:17:38,919
of experiments they kind of stir it all

00:17:37,179 --> 00:17:40,570
together and eventually you get a

00:17:38,919 --> 00:17:43,090
solution to a problem you actually care

00:17:40,570 --> 00:17:44,919
about one of the things we'd like to be

00:17:43,090 --> 00:17:47,200
able to do though is see if we could

00:17:44,919 --> 00:17:48,669
eliminate a lot of a need for the human

00:17:47,200 --> 00:17:50,590
machine learning expert to run these

00:17:48,669 --> 00:17:51,280
experiments and instead automate the

00:17:50,590 --> 00:17:53,080
experimental

00:17:51,280 --> 00:17:56,320
process by which a machine learning

00:17:53,080 --> 00:17:59,440
expert comes by a high-quality solution

00:17:56,320 --> 00:18:00,910
for a problem you care about so one of

00:17:59,440 --> 00:18:02,440
the you know lots and lots of

00:18:00,910 --> 00:18:04,330
organizations around the world have

00:18:02,440 --> 00:18:05,860
machine learning problems but many many

00:18:04,330 --> 00:18:07,810
of them don't even realize they have a

00:18:05,860 --> 00:18:09,400
machine learning problem let alone have

00:18:07,810 --> 00:18:12,940
people in their organization that can

00:18:09,400 --> 00:18:14,740
tackle the problem so one of the

00:18:12,940 --> 00:18:16,510
earliest pieces of work our researchers

00:18:14,740 --> 00:18:18,010
did in the space was something called

00:18:16,510 --> 00:18:20,740
neural architecture search so when you

00:18:18,010 --> 00:18:22,900
sit down and design a neural network to

00:18:20,740 --> 00:18:25,630
tackle a particular task you make a lot

00:18:22,900 --> 00:18:27,100
of decisions about you know shapes of

00:18:25,630 --> 00:18:29,020
this and that and like should it be used

00:18:27,100 --> 00:18:31,600
three by three filters in layer 17 or

00:18:29,020 --> 00:18:34,150
5x5 all kinds of things like this it

00:18:31,600 --> 00:18:37,270
turns out you can automate this process

00:18:34,150 --> 00:18:39,130
by having a model generating model and

00:18:37,270 --> 00:18:41,920
train the model generating model based

00:18:39,130 --> 00:18:43,450
on feedback about how well the models

00:18:41,920 --> 00:18:45,520
that it generates work on the problem

00:18:43,450 --> 00:18:47,230
you care so the way this will work we're

00:18:45,520 --> 00:18:48,400
gonna generate a bunch of models those

00:18:47,230 --> 00:18:50,860
are just descriptions of different

00:18:48,400 --> 00:18:52,840
neural network architectures we're gonna

00:18:50,860 --> 00:18:54,400
train each of those for a few hours and

00:18:52,840 --> 00:18:56,680
then we're going to see how well they

00:18:54,400 --> 00:18:58,600
work and then use the accuracy of those

00:18:56,680 --> 00:19:00,760
models as a reinforcement learning

00:18:58,600 --> 00:19:02,710
signal for the model generating model to

00:19:00,760 --> 00:19:05,050
steer it away from models that didn't

00:19:02,710 --> 00:19:06,820
work very well and towards models that

00:19:05,050 --> 00:19:10,480
worked better and we're gonna repeat

00:19:06,820 --> 00:19:12,580
many many times and over time we're

00:19:10,480 --> 00:19:14,770
gonna get better and better by steering

00:19:12,580 --> 00:19:18,070
the search to the parts of the space of

00:19:14,770 --> 00:19:19,210
models that worked well and so it comes

00:19:18,070 --> 00:19:20,680
up with models that look a little

00:19:19,210 --> 00:19:22,060
strange admittedly

00:19:20,680 --> 00:19:24,910
you know human probably would not sit

00:19:22,060 --> 00:19:26,830
down and wire up a sort of machine

00:19:24,910 --> 00:19:30,070
learning computer vision model exactly

00:19:26,830 --> 00:19:32,380
that way but they're pretty effective so

00:19:30,070 --> 00:19:36,670
if you look at this graph this shows

00:19:32,380 --> 00:19:38,500
kind of the best machine human machine

00:19:36,670 --> 00:19:40,330
learning experts computer vision experts

00:19:38,500 --> 00:19:43,060
machine learning researchers in the

00:19:40,330 --> 00:19:45,040
world producing a whole bunch of

00:19:43,060 --> 00:19:46,990
different kinds of models of in the last

00:19:45,040 --> 00:19:51,190
four or five years things like ResNet 50

00:19:46,990 --> 00:19:53,920
dense net 201 inception ResNet all kinds

00:19:51,190 --> 00:19:57,220
of things that black dotted line is kind

00:19:53,920 --> 00:20:00,520
of the frontier of human machine

00:19:57,220 --> 00:20:02,650
learning expert model quality on the

00:20:00,520 --> 00:20:04,960
y-axis and computational cost on the

00:20:02,650 --> 00:20:07,210
x-axis so what you see is as you

00:20:04,960 --> 00:20:07,990
the x-axis you tend to get more accuracy

00:20:07,210 --> 00:20:11,170
because you're applying more

00:20:07,990 --> 00:20:14,680
computational cost but what you see is

00:20:11,170 --> 00:20:16,420
the blue dotted line is Auto ml based

00:20:14,680 --> 00:20:18,580
solutions systems where we've done this

00:20:16,420 --> 00:20:20,140
automated experimentation instead of pre

00:20:18,580 --> 00:20:22,210
designing any particular architecture

00:20:20,140 --> 00:20:23,950
and you see that it's better both at the

00:20:22,210 --> 00:20:26,050
high end where you care about most

00:20:23,950 --> 00:20:27,250
accurate model you can get regardless of

00:20:26,050 --> 00:20:29,590
computational cost but it's also

00:20:27,250 --> 00:20:30,970
accurate at the low end where you care

00:20:29,590 --> 00:20:32,050
about a really lightweight model that

00:20:30,970 --> 00:20:34,240
might run in a phone or something like

00:20:32,050 --> 00:20:35,680
that and in 2019

00:20:34,240 --> 00:20:39,490
we've actually been able to improve that

00:20:35,680 --> 00:20:41,620
significantly this is a set of models

00:20:39,490 --> 00:20:43,180
called efficient net and has a very kind

00:20:41,620 --> 00:20:44,740
of a slider about you can trade-off

00:20:43,180 --> 00:20:47,410
computational cost and accuracy but

00:20:44,740 --> 00:20:50,050
they're all way better than human sort

00:20:47,410 --> 00:20:52,540
of guided experimentation on the black

00:20:50,050 --> 00:20:53,860
that black dotted line there and this is

00:20:52,540 --> 00:20:56,320
true for image recognition for

00:20:53,860 --> 00:20:58,330
classification it's true for object

00:20:56,320 --> 00:21:01,780
detection so the red line there is auto

00:20:58,330 --> 00:21:04,150
ml the other things are not it's true

00:21:01,780 --> 00:21:06,190
for language translations so the black

00:21:04,150 --> 00:21:08,590
line there is various kinds of

00:21:06,190 --> 00:21:10,900
transformers the red line is we've gave

00:21:08,590 --> 00:21:12,400
the basic components of transformers to

00:21:10,900 --> 00:21:13,990
an auto ml system and allowed it to

00:21:12,400 --> 00:21:18,100
fiddle with it and come up with

00:21:13,990 --> 00:21:20,080
something better it's true for computer

00:21:18,100 --> 00:21:21,340
vision models used in autonomous

00:21:20,080 --> 00:21:22,990
vehicles so this is a collaboration

00:21:21,340 --> 00:21:24,160
between way moe and google research we

00:21:22,990 --> 00:21:26,560
were able to come up with models that

00:21:24,160 --> 00:21:28,990
are you know significantly lower latency

00:21:26,560 --> 00:21:31,180
for the same quality or we could trade

00:21:28,990 --> 00:21:35,950
it off and get significantly lower error

00:21:31,180 --> 00:21:37,510
rate at the same latency it actually

00:21:35,950 --> 00:21:39,850
works for tabular data so if you have

00:21:37,510 --> 00:21:41,740
lots of like customer records and you

00:21:39,850 --> 00:21:43,330
want to predict which customers or you

00:21:41,740 --> 00:21:45,130
know gonna be spending a thousand

00:21:43,330 --> 00:21:47,800
dollars with your your business next

00:21:45,130 --> 00:21:49,060
month you know you can use auto ml to

00:21:47,800 --> 00:21:52,810
come up with a high quality model for

00:21:49,060 --> 00:21:54,940
that kind of problem okay so what do we

00:21:52,810 --> 00:21:57,190
want I think we want the following

00:21:54,940 --> 00:21:59,560
properties in that computer on a machine

00:21:57,190 --> 00:22:02,020
learning model so one is we tend to

00:21:59,560 --> 00:22:03,610
Train separate models for each different

00:22:02,020 --> 00:22:05,950
problem we care about I think this is a

00:22:03,610 --> 00:22:07,570
bit misguided like really we want one

00:22:05,950 --> 00:22:09,790
model that does a lot of things so that

00:22:07,570 --> 00:22:12,310
it can build on the knowledge in how it

00:22:09,790 --> 00:22:13,960
does thousands or millions of different

00:22:12,310 --> 00:22:15,970
things so that when the million and

00:22:13,960 --> 00:22:18,670
first thing comes along it can actually

00:22:15,970 --> 00:22:21,040
use its expertise from all the other

00:22:18,670 --> 00:22:23,260
knows how to do to know how to get into

00:22:21,040 --> 00:22:25,120
a good state for the new problem with

00:22:23,260 --> 00:22:27,820
relatively little data and relatively

00:22:25,120 --> 00:22:29,590
little computational cost so these are

00:22:27,820 --> 00:22:31,060
some nice properties I have kind of a

00:22:29,590 --> 00:22:33,400
cartoon diagram of something I think

00:22:31,060 --> 00:22:35,500
might make sense so imagine we have a

00:22:33,400 --> 00:22:37,210
model like this where it's very sparsely

00:22:35,500 --> 00:22:39,220
activated so different pieces of the

00:22:37,210 --> 00:22:40,570
model you know I'll have different kinds

00:22:39,220 --> 00:22:42,970
of expertise and they're called upon

00:22:40,570 --> 00:22:45,160
when it makes sense but they're mostly

00:22:42,970 --> 00:22:48,910
idle so it's relatively computational

00:22:45,160 --> 00:22:52,570
even power efficient but it can do many

00:22:48,910 --> 00:22:53,830
things and now each component here is

00:22:52,570 --> 00:22:56,260
some piece of a machine learning model

00:22:53,830 --> 00:22:58,060
with different kinds of state parameters

00:22:56,260 --> 00:23:03,070
in the model and different operations

00:22:58,060 --> 00:23:04,990
and a new task comes along now you can

00:23:03,070 --> 00:23:07,270
imagine something like neural

00:23:04,990 --> 00:23:08,830
architecture search becoming squint at

00:23:07,270 --> 00:23:10,630
it just right and now turn it into a

00:23:08,830 --> 00:23:12,880
neural pathway search we're gonna look

00:23:10,630 --> 00:23:15,040
for components that are really good for

00:23:12,880 --> 00:23:16,720
this new task we care about and maybe we

00:23:15,040 --> 00:23:18,700
will search and find that this path

00:23:16,720 --> 00:23:20,110
through the model actually gets us into

00:23:18,700 --> 00:23:22,030
a pretty good state for this new task

00:23:20,110 --> 00:23:23,740
because maybe it goes through components

00:23:22,030 --> 00:23:26,860
that are trained on related tasks

00:23:23,740 --> 00:23:28,630
already and now maybe we want that model

00:23:26,860 --> 00:23:31,950
to be more accurate for the purple tasks

00:23:28,630 --> 00:23:34,450
so we can add a bit more you know

00:23:31,950 --> 00:23:36,850
computational capacity add a new

00:23:34,450 --> 00:23:38,920
component start to use that component

00:23:36,850 --> 00:23:41,920
for this new task continue training it

00:23:38,920 --> 00:23:44,550
and now that new component can also be

00:23:41,920 --> 00:23:47,050
used for solving other related tasks and

00:23:44,550 --> 00:23:48,640
each component itself might be running

00:23:47,050 --> 00:23:50,980
some sort of interesting architectural

00:23:48,640 --> 00:23:52,840
search inside it so I think something

00:23:50,980 --> 00:23:55,780
like that is the direction we should be

00:23:52,840 --> 00:23:57,040
exploring as a community it's not what

00:23:55,780 --> 00:23:59,740
we're doing today but I think it could

00:23:57,040 --> 00:24:01,600
be a pretty interesting direction okay

00:23:59,740 --> 00:24:03,850
and finally I'd like to touch on

00:24:01,600 --> 00:24:05,560
thoughtful use of AI in societies we've

00:24:03,850 --> 00:24:08,140
seen more and more uses of machine

00:24:05,560 --> 00:24:10,000
learning in our products and around the

00:24:08,140 --> 00:24:12,610
world it's really really important to be

00:24:10,000 --> 00:24:14,050
thinking carefully about how we want to

00:24:12,610 --> 00:24:16,510
apply these technologies you know they

00:24:14,050 --> 00:24:18,790
can like any technology these systems

00:24:16,510 --> 00:24:20,470
can be used for amazing things or things

00:24:18,790 --> 00:24:22,930
we might find a little sort of

00:24:20,470 --> 00:24:24,730
detrimental in various ways and so we've

00:24:22,930 --> 00:24:26,980
come up with a set of principles by

00:24:24,730 --> 00:24:29,170
which we think about applying sort of

00:24:26,980 --> 00:24:31,000
machine learning and AI to our products

00:24:29,170 --> 00:24:32,140
and we've made these public about a year

00:24:31,000 --> 00:24:36,190
and a half ago

00:24:32,140 --> 00:24:38,170
a way of sort of sharing our thought

00:24:36,190 --> 00:24:39,730
process with the rest of the world and I

00:24:38,170 --> 00:24:41,050
pretty particularly like these I'll

00:24:39,730 --> 00:24:43,810
point out many of these are sort of

00:24:41,050 --> 00:24:45,700
areas of research that are not fully

00:24:43,810 --> 00:24:47,440
understood yet but we aim to apply the

00:24:45,700 --> 00:24:49,900
best in the state-of-the-art methods for

00:24:47,440 --> 00:24:52,270
example for reducing bias in machine

00:24:49,900 --> 00:24:53,620
learning models but also continue to do

00:24:52,270 --> 00:24:55,750
research and advance the state of the

00:24:53,620 --> 00:24:57,670
Artemis areas and so this is just kind

00:24:55,750 --> 00:24:59,320
of a taste of different kinds of work

00:24:57,670 --> 00:25:01,090
we're doing in this area how do we do

00:24:59,320 --> 00:25:02,950
machine learning with more privacy using

00:25:01,090 --> 00:25:04,630
things like federated learning how do we

00:25:02,950 --> 00:25:06,790
make models more interpretive also the

00:25:04,630 --> 00:25:08,700
clinician can understand the predictions

00:25:06,790 --> 00:25:11,830
is making on on diabetic retinopathy

00:25:08,700 --> 00:25:14,890
sort of examples how do we make machine

00:25:11,830 --> 00:25:17,650
learning more fair okay and with that I

00:25:14,890 --> 00:25:18,730
hope I've convinced you that deep neural

00:25:17,650 --> 00:25:20,680
Nets and machine learning

00:25:18,730 --> 00:25:23,020
you're already here so maybe you're

00:25:20,680 --> 00:25:25,030
already convinced to this but are

00:25:23,020 --> 00:25:26,530
helping make sort of significant

00:25:25,030 --> 00:25:27,970
advances and a lot of hard computer

00:25:26,530 --> 00:25:29,410
science problems computer vision speech

00:25:27,970 --> 00:25:32,230
recognition language understanding

00:25:29,410 --> 00:25:34,360
general use of machine learning is going

00:25:32,230 --> 00:25:36,580
to push the world forward so thank you

00:25:34,360 --> 00:25:38,910
very much and I appreciate you all being

00:25:36,580 --> 00:25:38,910

YouTube URL: https://www.youtube.com/watch?v=ZHoNF28Nj98


