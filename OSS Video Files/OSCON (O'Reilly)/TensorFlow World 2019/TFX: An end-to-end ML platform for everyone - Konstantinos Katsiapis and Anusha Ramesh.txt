Title: TFX: An end-to-end ML platform for everyone - Konstantinos Katsiapis and Anusha Ramesh
Publication date: 2019-11-01
Playlist: TensorFlow World 2019
Description: 
	TensorFlow Extended (TFX) has evolved as the ML platform solution within Alphabet over the past decade, and Alphabet is now evangelizing TFX for the rest of the world. Konstantinos Katsiapis and Anusha Ramesh discuss what it means to be an “ML platform” and share Alphabet’s insights and approach that laid the foundation for TFX to reach its current popularity within Alphabet—and which the company hopes to amplify beyond Alphabet.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,620 --> 00:00:05,240
hello everyone good morning I'm gaskets

00:00:03,530 --> 00:00:07,730
herpes and I'm a principal engineer in

00:00:05,240 --> 00:00:09,350
the effects hi everyone I'm Anushka I'm

00:00:07,730 --> 00:00:11,420
a product manager in tf-x

00:00:09,350 --> 00:00:13,100
today we'll talk to you about our

00:00:11,420 --> 00:00:14,990
end-to-end ml platform test flow

00:00:13,100 --> 00:00:18,650
extended otherwise known as the effects

00:00:14,990 --> 00:00:20,599
on behalf of the tf-x team so the

00:00:18,650 --> 00:00:22,550
discipline of software engineering has

00:00:20,599 --> 00:00:25,279
evolved over the last five plus decades

00:00:22,550 --> 00:00:27,050
to a good level of maturity if you think

00:00:25,279 --> 00:00:29,509
about it this is both a blessing and a

00:00:27,050 --> 00:00:30,949
necessity because our lives usually

00:00:29,509 --> 00:00:33,290
depend on it

00:00:30,949 --> 00:00:35,300
at the same time the popularity of ml

00:00:33,290 --> 00:00:37,580
has been increasing rapidly over the

00:00:35,300 --> 00:00:40,160
last two-plus decades and over the last

00:00:37,580 --> 00:00:42,020
decade or so it's been used very much

00:00:40,160 --> 00:00:44,510
very actively both in experimentation

00:00:42,020 --> 00:00:47,360
and production settings it is no longer

00:00:44,510 --> 00:00:51,020
uncommon for ml to power widely used

00:00:47,360 --> 00:00:52,880
applications that we use every day so

00:00:51,020 --> 00:00:55,610
much like was the case for software

00:00:52,880 --> 00:00:57,920
engineering they the wide use of ml

00:00:55,610 --> 00:01:00,200
technology necessitates the evolution of

00:00:57,920 --> 00:01:03,740
the discipline from ml coding to amel

00:01:00,200 --> 00:01:05,390
engineering as most of you know to do ml

00:01:03,740 --> 00:01:08,509
introduction you need a lot more than

00:01:05,390 --> 00:01:10,399
just a trainer for example the trainer

00:01:08,509 --> 00:01:12,170
code in an annual production system is

00:01:10,399 --> 00:01:13,909
usually five to ten percent of the

00:01:12,170 --> 00:01:15,350
majority of the entirety of the code and

00:01:13,909 --> 00:01:17,329
similarly the amount of time that

00:01:15,350 --> 00:01:19,310
engineers spend on the trainer is often

00:01:17,329 --> 00:01:20,899
do art by the amount of time and in your

00:01:19,310 --> 00:01:22,969
spending preparing the data ensuring

00:01:20,899 --> 00:01:26,689
it's of good quality and sharing it

00:01:22,969 --> 00:01:28,579
unbiased etc at the same time research

00:01:26,689 --> 00:01:30,829
eventually makes its way into production

00:01:28,579 --> 00:01:34,100
and ideally one wouldn't need to change

00:01:30,829 --> 00:01:36,710
stocks in order to evolve an idea and

00:01:34,100 --> 00:01:39,380
put it into a product so I think what is

00:01:36,710 --> 00:01:41,450
needed here is flexibility and

00:01:39,380 --> 00:01:43,249
robustness and a consistent system that

00:01:41,450 --> 00:01:45,979
allows you to apply in ml in a product

00:01:43,249 --> 00:01:49,249
and remember that the ml code itself is

00:01:45,979 --> 00:01:51,590
a tiny piece of the entire puzzle now

00:01:49,249 --> 00:01:53,600
here is a concrete example of the

00:01:51,590 --> 00:01:55,639
difference between ml coding and ml

00:01:53,600 --> 00:01:57,469
engineering as you can see in this use

00:01:55,639 --> 00:02:00,079
case it took about three weeks to build

00:01:57,469 --> 00:02:01,189
a model it's about a year it's still not

00:02:00,079 --> 00:02:04,069
deployed in production

00:02:01,189 --> 00:02:06,469
similarly stories used to be common at

00:02:04,069 --> 00:02:09,470
Google as well but we made things

00:02:06,469 --> 00:02:13,480
noticeably easier over the past decade

00:02:09,470 --> 00:02:16,209
by building ml platforms like T FX

00:02:13,480 --> 00:02:18,280
now emerald platforms in Google is not a

00:02:16,209 --> 00:02:20,290
new thing we've been building Google

00:02:18,280 --> 00:02:22,930
scale machine learning platforms for

00:02:20,290 --> 00:02:25,480
quite a while now Subin existed as a

00:02:22,930 --> 00:02:28,900
precursor to tf-x it started about 12

00:02:25,480 --> 00:02:30,910
years ago a lot of the design code and

00:02:28,900 --> 00:02:33,819
best practices that we gain through

00:02:30,910 --> 00:02:35,050
Sibyl have been incorporated into the

00:02:33,819 --> 00:02:38,050
design of tf-x

00:02:35,050 --> 00:02:39,430
now while tf-x shares several core

00:02:38,050 --> 00:02:41,769
principles with Sybil

00:02:39,430 --> 00:02:44,709
it also arguments it under several

00:02:41,769 --> 00:02:47,530
important dimensions this made T FX to

00:02:44,709 --> 00:02:49,660
be the most widely used n to n ml

00:02:47,530 --> 00:02:54,760
platform at alphabet while being

00:02:49,660 --> 00:02:56,799
available on premises and on GCP the

00:02:54,760 --> 00:02:59,890
vision of T FX is to provide an

00:02:56,799 --> 00:03:02,440
end-to-end ml platform for everyone by

00:02:59,890 --> 00:03:05,319
providing this ml platform our goal is

00:03:02,440 --> 00:03:08,110
to ensure that we can proliferate the

00:03:05,319 --> 00:03:11,110
use of ml Engineering thus improving ml

00:03:08,110 --> 00:03:13,390
powered applications but let's discuss

00:03:11,110 --> 00:03:15,640
on what it means to be an ml platform

00:03:13,390 --> 00:03:18,600
and what are the various parts that are

00:03:15,640 --> 00:03:20,709
required to help us realize this vision

00:03:18,600 --> 00:03:22,630
so today we're gonna tell you a little

00:03:20,709 --> 00:03:25,090
bit more about how we enabled global

00:03:22,630 --> 00:03:26,980
scale ml engineering at Google from best

00:03:25,090 --> 00:03:29,500
practices and libraries all the way to a

00:03:26,980 --> 00:03:32,709
full-fledged end-to-end ml platform so

00:03:29,500 --> 00:03:35,470
let's start from the beginning machine

00:03:32,709 --> 00:03:38,230
learning is hard doing it well is harder

00:03:35,470 --> 00:03:39,760
and applying diggity in production and

00:03:38,230 --> 00:03:42,910
powering applications is actually even

00:03:39,760 --> 00:03:45,130
harder we want to help others avoid the

00:03:42,910 --> 00:03:47,019
many many pitfalls that we haven't had

00:03:45,130 --> 00:03:50,170
it in the past and to that end we

00:03:47,019 --> 00:03:52,450
actually publish papers blog posts and

00:03:50,170 --> 00:03:57,340
other material that capture a lot of our

00:03:52,450 --> 00:03:58,750
learnings and our best practices so here

00:03:57,340 --> 00:04:00,940
are but a few examples of our

00:03:58,750 --> 00:04:02,319
publications the capture collective

00:04:00,940 --> 00:04:04,510
lessons learned more than a decade of

00:04:02,319 --> 00:04:06,250
apply the mallet kugel and several of

00:04:04,510 --> 00:04:09,609
them like the rules of machine learning

00:04:06,250 --> 00:04:11,319
are quite comprehensive we won't have

00:04:09,609 --> 00:04:12,819
time to go into them today as part of

00:04:11,319 --> 00:04:15,780
this talk obviously but we encourage you

00:04:12,819 --> 00:04:15,780
to take a look when you get a chance

00:04:15,870 --> 00:04:20,410
while best practices are great

00:04:18,180 --> 00:04:22,720
communication of best practices alone

00:04:20,410 --> 00:04:24,640
would not be sufficient this does not

00:04:22,720 --> 00:04:27,130
scale because it does not get applied in

00:04:24,640 --> 00:04:28,990
code so we want to capture

00:04:27,130 --> 00:04:31,750
our learnings and best practices in code

00:04:28,990 --> 00:04:33,910
we want to enable our users to reuse

00:04:31,750 --> 00:04:36,070
these best practices and at the same

00:04:33,910 --> 00:04:39,490
time give them the ability to pick and

00:04:36,070 --> 00:04:42,850
choose to that extent we offer standard

00:04:39,490 --> 00:04:45,310
and data parallel libraries now here are

00:04:42,850 --> 00:04:47,350
a few examples of libraries that we

00:04:45,310 --> 00:04:49,750
offer for different phases of machine

00:04:47,350 --> 00:04:52,570
learning to our developers as you can

00:04:49,750 --> 00:04:55,030
see we offer libraries for almost every

00:04:52,570 --> 00:04:56,620
step of your ml workflow starting from

00:04:55,030 --> 00:04:59,140
data validation to feature

00:04:56,620 --> 00:05:01,540
transformations to analyzing the quality

00:04:59,140 --> 00:05:04,690
of a model all the way still serving

00:05:01,540 --> 00:05:06,370
that in production we also make transfer

00:05:04,690 --> 00:05:09,670
learning easy by providing tensorflow

00:05:06,370 --> 00:05:12,400
hub ml metadata is a library for

00:05:09,670 --> 00:05:15,400
recording and retrieving metadata for ML

00:05:12,400 --> 00:05:17,290
workflows now the best part about these

00:05:15,400 --> 00:05:20,260
libraries is that they are highly

00:05:17,290 --> 00:05:24,190
modular which makes it easy to plug into

00:05:20,260 --> 00:05:25,990
your existing ml infrastructure we have

00:05:24,190 --> 00:05:28,060
found that libraries are not enough

00:05:25,990 --> 00:05:30,880
within alphabet and we expect the same

00:05:28,060 --> 00:05:32,980
elsewhere not all users need or want the

00:05:30,880 --> 00:05:34,660
full flexibility some of them might

00:05:32,980 --> 00:05:37,510
actually be confused by it and many

00:05:34,660 --> 00:05:39,490
users prefer out-of-the-box solutions so

00:05:37,510 --> 00:05:40,990
what we do is manage a release of our

00:05:39,490 --> 00:05:43,090
libraries we ensure they're nicely

00:05:40,990 --> 00:05:45,160
packaged and optimized but importantly

00:05:43,090 --> 00:05:46,660
we also offer higher-level api's and

00:05:45,160 --> 00:05:48,910
those come frequently in the form of

00:05:46,660 --> 00:05:52,540
binaries or components or a container

00:05:48,910 --> 00:05:55,360
sorry libraries and binaries provide a

00:05:52,540 --> 00:05:58,270
lot of flexibility to our users but this

00:05:55,360 --> 00:05:59,950
is not sufficient for ml workflows ml

00:05:58,270 --> 00:06:02,260
workflow is typically involves

00:05:59,950 --> 00:06:04,990
inspecting and man you plating several

00:06:02,260 --> 00:06:06,700
types of artifacts so we provide

00:06:04,990 --> 00:06:09,190
components which interact with

00:06:06,700 --> 00:06:12,190
well-defined and strongly typed artifact

00:06:09,190 --> 00:06:13,960
api's the components also understand the

00:06:12,190 --> 00:06:15,700
context and environment in which they

00:06:13,960 --> 00:06:16,630
operate in and can be interconnected

00:06:15,700 --> 00:06:19,630
with one another

00:06:16,630 --> 00:06:23,800
we also provide UI components for

00:06:19,630 --> 00:06:25,510
visualization of the said artifacts that

00:06:23,800 --> 00:06:27,880
brings us to a new functionality we are

00:06:25,510 --> 00:06:30,250
launching intensive flow world you can

00:06:27,880 --> 00:06:32,410
run any tf-x component in a notebook as

00:06:30,250 --> 00:06:34,780
you can see here you can run tf-x

00:06:32,410 --> 00:06:36,880
components cell by cell this example

00:06:34,780 --> 00:06:39,430
showcases a couple of components

00:06:36,880 --> 00:06:41,500
the first one is example Jen

00:06:39,430 --> 00:06:43,510
example Jen ingest data into a tf-x

00:06:41,500 --> 00:06:46,120
pipeline and this is typically the first

00:06:43,510 --> 00:06:48,460
component that you use the second one is

00:06:46,120 --> 00:06:50,500
statistics Jen which computes statistics

00:06:48,460 --> 00:06:52,540
for visualization and example validation

00:06:50,500 --> 00:06:54,790
so when you run a component like

00:06:52,540 --> 00:06:56,410
statistics Jen in notebook you can

00:06:54,790 --> 00:06:58,870
visualize something like this which

00:06:56,410 --> 00:07:01,660
showcases stats on your data and it

00:06:58,870 --> 00:07:03,880
helps you detect anomalies the benefit

00:07:01,660 --> 00:07:07,150
of running tf-x components in a notebook

00:07:03,880 --> 00:07:09,130
is twofold first it makes it easy for

00:07:07,150 --> 00:07:10,780
users to on would on to tf-x

00:07:09,130 --> 00:07:12,820
it helps you understand the various

00:07:10,780 --> 00:07:15,070
components of tf-x and how you connect

00:07:12,820 --> 00:07:17,110
them and order in which you can go it

00:07:15,070 --> 00:07:19,180
also helps with debugging the various

00:07:17,110 --> 00:07:23,860
steps of your ml workflow as you go

00:07:19,180 --> 00:07:25,450
through the notebook or experience we've

00:07:23,860 --> 00:07:28,240
learned that components aren't actually

00:07:25,450 --> 00:07:30,190
sufficient for production ml manually

00:07:28,240 --> 00:07:31,860
orchestrating components can become

00:07:30,190 --> 00:07:33,970
cumbersome and importantly error-prone

00:07:31,860 --> 00:07:35,620
and they're also understanding the

00:07:33,970 --> 00:07:37,300
lineage of all the artifacts that are

00:07:35,620 --> 00:07:38,710
produced by those components produced

00:07:37,300 --> 00:07:41,170
are consumed by those components is

00:07:38,710 --> 00:07:42,880
often fundamental both from a debugging

00:07:41,170 --> 00:07:45,310
perspective and but many times from a

00:07:42,880 --> 00:07:47,800
compliance perspective as well as such

00:07:45,310 --> 00:07:49,780
we offer ways of creating task driven

00:07:47,800 --> 00:07:52,030
pipelines of components we allow it to

00:07:49,780 --> 00:07:54,250
stitch to get components together in a

00:07:52,030 --> 00:07:56,590
test-driven fashion but we have also

00:07:54,250 --> 00:07:58,600
found that data scale and advanced use

00:07:56,590 --> 00:08:00,640
cases also necessitate this platform

00:07:58,600 --> 00:08:02,740
this pipeline to actually be reactive to

00:08:00,640 --> 00:08:04,690
the environment right so we found that

00:08:02,740 --> 00:08:07,960
over time we need more something like

00:08:04,690 --> 00:08:09,220
data-driven components now the

00:08:07,960 --> 00:08:10,930
interesting part here is that the

00:08:09,220 --> 00:08:12,370
components we offer are the same

00:08:10,930 --> 00:08:14,740
components that can operate both new

00:08:12,370 --> 00:08:16,060
task the task driven mode and in a

00:08:14,740 --> 00:08:18,520
dratted driven mode thereby enabling

00:08:16,060 --> 00:08:20,410
more flexibility and the most important

00:08:18,520 --> 00:08:22,330
part is that the art the artifact

00:08:20,410 --> 00:08:23,770
lineage is tracked throughout this ml

00:08:22,330 --> 00:08:26,200
pipeline whether it's task or

00:08:23,770 --> 00:08:28,380
data-driven which helps experimentation

00:08:26,200 --> 00:08:31,270
debugging and compliance

00:08:28,380 --> 00:08:33,070
so here's putting it all together here

00:08:31,270 --> 00:08:36,010
is kind of a canonical production end to

00:08:33,070 --> 00:08:37,720
end I multiply pipeline it starts with

00:08:36,010 --> 00:08:39,340
the example generation statistic

00:08:37,720 --> 00:08:39,940
generations which ensure the data is of

00:08:39,340 --> 00:08:42,430
good quality

00:08:39,940 --> 00:08:45,010
proceeds with transformations to augment

00:08:42,430 --> 00:08:47,560
the data in ways that make it easier to

00:08:45,010 --> 00:08:49,360
fit the model training the model after

00:08:47,560 --> 00:08:51,430
we train the model we ensure that is of

00:08:49,360 --> 00:08:53,260
good quality and only after we're sure

00:08:51,430 --> 00:08:54,760
it's it meets the quality bar that

00:08:53,260 --> 00:08:56,800
we're comfortable with do we actually

00:08:54,760 --> 00:08:58,540
push to one of the serving systems of

00:08:56,800 --> 00:09:00,490
choice whether that's a server or a

00:08:58,540 --> 00:09:01,140
mobile application tier flight via

00:09:00,490 --> 00:09:03,580
flight

00:09:01,140 --> 00:09:05,620
note that the pipeline topology here is

00:09:03,580 --> 00:09:06,880
fully customizable right so you can

00:09:05,620 --> 00:09:09,120
actually move things around as you

00:09:06,880 --> 00:09:10,900
please and importantly if one of the

00:09:09,120 --> 00:09:12,880
out-of-the-box components we offer

00:09:10,900 --> 00:09:14,530
doesn't work for you you can create a

00:09:12,880 --> 00:09:16,570
custom component with custom business

00:09:14,530 --> 00:09:22,300
logic and all of this is under a single

00:09:16,570 --> 00:09:23,860
ml pipeline now what does it need

00:09:22,300 --> 00:09:26,770
what does it mean to be an end-to-end ml

00:09:23,860 --> 00:09:29,020
platform right so I think there's some

00:09:26,770 --> 00:09:30,490
key properties to it and one is seamless

00:09:29,020 --> 00:09:32,020
integration right we want to make sure

00:09:30,490 --> 00:09:33,790
that all the components within those

00:09:32,020 --> 00:09:35,410
pipeline actually within the pipeline

00:09:33,790 --> 00:09:37,510
actually similarly interoperate with

00:09:35,410 --> 00:09:39,430
each other and we have actually found

00:09:37,510 --> 00:09:41,560
that we think Google the value added for

00:09:39,430 --> 00:09:43,450
our users gets larger as they move

00:09:41,560 --> 00:09:45,130
higher up the stack you know as I move

00:09:43,450 --> 00:09:46,480
higher from libraries going further up

00:09:45,130 --> 00:09:48,910
to components and further up into

00:09:46,480 --> 00:09:52,120
library ed into the pipeline itself this

00:09:48,910 --> 00:09:53,980
is because operating at a higher level

00:09:52,120 --> 00:09:56,910
of the abstraction allows us to give

00:09:53,980 --> 00:09:58,930
better robustness and support ability

00:09:56,910 --> 00:10:00,670
another important aspect of animal

00:09:58,930 --> 00:10:03,310
platform is its interoperability with

00:10:00,670 --> 00:10:04,990
the environment it operates in so each

00:10:03,310 --> 00:10:06,670
of those platforms might be employed in

00:10:04,990 --> 00:10:08,740
different environments you know some on

00:10:06,670 --> 00:10:10,300
premises how much ICP etcetera and we

00:10:08,740 --> 00:10:13,030
need to make sure that we interact with

00:10:10,300 --> 00:10:15,370
the ecosystem that you operate in so the

00:10:13,030 --> 00:10:16,630
effects actually works with other parts

00:10:15,370 --> 00:10:18,280
of the fundamental parts of the memory

00:10:16,630 --> 00:10:21,940
ecosystem like cool flow pipelines

00:10:18,280 --> 00:10:25,840
Apache beam Apache spark fling air flow

00:10:21,940 --> 00:10:26,980
etc this interoperability also gives us

00:10:25,840 --> 00:10:28,930
something else that's very important

00:10:26,980 --> 00:10:30,640
here the flexibility right so we allow

00:10:28,930 --> 00:10:32,830
customization of components and

00:10:30,640 --> 00:10:35,710
extension points within the ml platform

00:10:32,830 --> 00:10:37,150
that allows you to if something doesn't

00:10:35,710 --> 00:10:38,830
work out of the box for you it allows

00:10:37,150 --> 00:10:41,080
you to customize it to your business

00:10:38,830 --> 00:10:42,940
needs the effects is by no means a

00:10:41,080 --> 00:10:45,430
perfect platform but we strive to

00:10:42,940 --> 00:10:48,490
collect feedback and improve it so let's

00:10:45,430 --> 00:10:50,680
give it to us internally

00:10:48,490 --> 00:10:53,110
tf-x platform powers several alphabet

00:10:50,680 --> 00:10:55,330
companies within Google it powers

00:10:53,110 --> 00:10:58,000
several of our most important products

00:10:55,330 --> 00:11:00,730
that you're probably familiar with also

00:10:58,000 --> 00:11:03,910
tf-x powers by integrates with cloud AI

00:11:00,730 --> 00:11:06,470
platform ml engine and dataflow products

00:11:03,910 --> 00:11:10,130
and thus helping you realize your ml

00:11:06,470 --> 00:11:12,560
Robus Leon GCB tf-x also powers several

00:11:10,130 --> 00:11:14,600
of cloud auto ml solutions that automate

00:11:12,560 --> 00:11:19,430
and simplify ml for you so check them

00:11:14,600 --> 00:11:21,440
out to the external world T FX is

00:11:19,430 --> 00:11:23,870
available as an end-to-end solution our

00:11:21,440 --> 00:11:26,180
friends at Twitter who spoke at the

00:11:23,870 --> 00:11:27,770
keynote yesterday talked about we have

00:11:26,180 --> 00:11:30,200
already published like a fascinating

00:11:27,770 --> 00:11:32,290
blog post on how they are ranking tweets

00:11:30,200 --> 00:11:34,430
on their home time line using tensorflow

00:11:32,290 --> 00:11:37,100
they are using tensor flow model

00:11:34,430 --> 00:11:40,010
analysis and tensorflow hub for sharing

00:11:37,100 --> 00:11:41,930
word embeddings they evaluated several

00:11:40,010 --> 00:11:43,730
other technologies and frameworks and

00:11:41,930 --> 00:11:45,050
decided to go ahead with tensor flow

00:11:43,730 --> 00:11:48,140
ecosystem for their production

00:11:45,050 --> 00:11:50,240
requirements similar to Twitter we also

00:11:48,140 --> 00:11:53,150
have several other partners who are

00:11:50,240 --> 00:11:55,910
using T FX I hope you will join us right

00:11:53,150 --> 00:11:58,100
after this talk to hear from Spotify on

00:11:55,910 --> 00:12:03,230
how they are using T FX for their

00:11:58,100 --> 00:12:05,510
production workflow needs we also have

00:12:03,230 --> 00:12:07,820
another detail talk later today called T

00:12:05,510 --> 00:12:10,520
FX production ml pipelines with tensor

00:12:07,820 --> 00:12:12,740
flow so we have two great talks one by

00:12:10,520 --> 00:12:14,480
Spotify the other one detailed talk on T

00:12:12,740 --> 00:12:17,240
FX if you're interested in learning more

00:12:14,480 --> 00:12:19,730
check these two talks visit our webpage

00:12:17,240 --> 00:12:22,920
tensorflow dot org slash T effects to

00:12:19,730 --> 00:12:26,890
get started thank you

00:12:22,920 --> 00:12:26,890

YouTube URL: https://www.youtube.com/watch?v=JHLhLa5LRZ4


