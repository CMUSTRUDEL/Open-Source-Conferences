Title: TensorFlow Hub: The platform to share and discover pretrained models for TensorFlow - Mike Liang
Publication date: 2019-11-01
Playlist: TensorFlow World 2019
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:02,139 --> 00:00:07,450
good morning everyone my name is Mike

00:00:05,140 --> 00:00:09,700
I'm one of the product managers on the

00:00:07,450 --> 00:00:12,730
tensorflow team and today I'd like to

00:00:09,700 --> 00:00:15,549
share with you something about intensive

00:00:12,730 --> 00:00:17,260
L hub so we've seen some amazing

00:00:15,549 --> 00:00:19,330
breakthroughs on what machine learning

00:00:17,260 --> 00:00:21,100
can do over the past few years and

00:00:19,330 --> 00:00:23,320
throughout this conference you've heard

00:00:21,100 --> 00:00:25,930
a lot about the services and tools that

00:00:23,320 --> 00:00:28,990
have been built on top of them machines

00:00:25,930 --> 00:00:31,390
are becoming capable of doing mere devam

00:00:28,990 --> 00:00:33,430
myriad of amazing things from vision to

00:00:31,390 --> 00:00:35,740
speech to natural language processing

00:00:33,430 --> 00:00:37,780
and with tensorflow

00:00:35,740 --> 00:00:41,020
machine learning experts and data

00:00:37,780 --> 00:00:42,610
scientists are able to combine data and

00:00:41,020 --> 00:00:44,680
algorithms and computational power

00:00:42,610 --> 00:00:46,090
together to train machine learning

00:00:44,680 --> 00:00:49,300
models that are very proficient at a

00:00:46,090 --> 00:00:52,390
variety of tasks but if your focus was

00:00:49,300 --> 00:00:53,320
to solve business problems or build new

00:00:52,390 --> 00:00:55,570
applications

00:00:53,320 --> 00:00:57,790
how can you quickly use machine learning

00:00:55,570 --> 00:01:01,030
in your solutions well this is where

00:00:57,790 --> 00:01:04,299
tents will hub comes in tents will hub

00:01:01,030 --> 00:01:06,430
is a repository of pre-trained ready to

00:01:04,299 --> 00:01:08,950
use models to help you solve novel

00:01:06,430 --> 00:01:11,140
business problems he has a comprehensive

00:01:08,950 --> 00:01:13,360
collection of models from across the

00:01:11,140 --> 00:01:15,520
tensile ecosystem and you can find sea

00:01:13,360 --> 00:01:17,860
of the art research models here

00:01:15,520 --> 00:01:21,549
intensive will hub many of the models

00:01:17,860 --> 00:01:23,619
here are also can be composed into new

00:01:21,549 --> 00:01:26,440
models and retrained using transfer

00:01:23,619 --> 00:01:27,970
learning and a while and recently we've

00:01:26,440 --> 00:01:30,280
added a lot of new models that you can

00:01:27,970 --> 00:01:32,830
deploy straight to production from cloud

00:01:30,280 --> 00:01:35,020
to the edge through tents for light or

00:01:32,830 --> 00:01:37,860
tensile ojs and we're getting many

00:01:35,020 --> 00:01:40,630
contributions from the community as well

00:01:37,860 --> 00:01:42,340
tensorflow hubs rich repository models

00:01:40,630 --> 00:01:45,369
covers a wide range of machine learning

00:01:42,340 --> 00:01:48,159
problems for example in image related

00:01:45,369 --> 00:01:50,400
tasks we have a variety of models for

00:01:48,159 --> 00:01:54,189
object detection image classification

00:01:50,400 --> 00:01:56,170
automatic image augmentation and some

00:01:54,189 --> 00:01:59,470
new things like image generation for

00:01:56,170 --> 00:02:01,299
sale transfers in text really tasks we

00:01:59,470 --> 00:02:03,630
have some of the state-of-the-art models

00:02:01,299 --> 00:02:05,560
out there like Burton and Albert and

00:02:03,630 --> 00:02:07,450
Universal sentence encoders and you've

00:02:05,560 --> 00:02:10,720
heard about some of the things that

00:02:07,450 --> 00:02:14,080
machines can deal with with Bert just

00:02:10,720 --> 00:02:15,340
yesterday these encoders can support a

00:02:14,080 --> 00:02:16,030
wide range of natural language

00:02:15,340 --> 00:02:18,520
understanding

00:02:16,030 --> 00:02:21,490
such as question and answering text

00:02:18,520 --> 00:02:23,200
classification or sentiment analysis and

00:02:21,490 --> 00:02:24,940
there are also video related models too

00:02:23,200 --> 00:02:25,690
so if you want to do gesture

00:02:24,940 --> 00:02:28,360
recognitions

00:02:25,690 --> 00:02:32,350
you can use some of the models there or

00:02:28,360 --> 00:02:34,720
even video generation and we've recently

00:02:32,350 --> 00:02:36,220
actually just completely upgraded our

00:02:34,720 --> 00:02:38,319
front-end interface so that it's a lot

00:02:36,220 --> 00:02:41,560
easier to use so many of these models

00:02:38,319 --> 00:02:45,580
can be easily found or searched going to

00:02:41,560 --> 00:02:48,160
tens for hub we've invested a lot of

00:02:45,580 --> 00:02:51,160
energy in making these models intensive

00:02:48,160 --> 00:02:53,019
l hub easily reusable or composable

00:02:51,160 --> 00:02:54,730
ingÃ©nue models where you can actually

00:02:53,019 --> 00:02:56,739
bring your own data and through transfer

00:02:54,730 --> 00:02:59,500
learning improve the power of those

00:02:56,739 --> 00:03:01,030
models with one line of code you can

00:02:59,500 --> 00:03:03,640
bring these models right into tenth

00:03:01,030 --> 00:03:06,069
floor - and using the high level chaos

00:03:03,640 --> 00:03:09,459
api's or the low level API you can

00:03:06,069 --> 00:03:11,410
actually go and retrain these models and

00:03:09,459 --> 00:03:13,269
all these models can also be deployed

00:03:11,410 --> 00:03:14,110
straight into machine learning pipelines

00:03:13,269 --> 00:03:16,890
like tf-x

00:03:14,110 --> 00:03:19,900
as you've heard about earlier today

00:03:16,890 --> 00:03:22,360
recently we've added support for models

00:03:19,900 --> 00:03:24,220
that are ready to deploy these pre

00:03:22,360 --> 00:03:25,780
trained models have been prepared for a

00:03:24,220 --> 00:03:29,530
wide range of environments across the

00:03:25,780 --> 00:03:32,950
tencel ecosystem so if you want to work

00:03:29,530 --> 00:03:35,410
in a web or a node-based environment you

00:03:32,950 --> 00:03:36,970
can deploy them into tens for Jas or if

00:03:35,410 --> 00:03:39,670
you are working with mobile and bed

00:03:36,970 --> 00:03:42,030
devices you can deploy employ some of

00:03:39,670 --> 00:03:45,160
these models through tenths of a light

00:03:42,030 --> 00:03:47,769
in Tesla hub you can also discover

00:03:45,160 --> 00:03:49,420
reiji's models for coral edge a TPU

00:03:47,769 --> 00:03:51,940
devices and we recently started adding

00:03:49,420 --> 00:03:55,239
these these devices combined tensile

00:03:51,940 --> 00:03:57,190
light models with some very efficient

00:03:55,239 --> 00:03:58,900
accelerators that allows companies to

00:03:57,190 --> 00:04:01,090
create products that can run inference

00:03:58,900 --> 00:04:04,930
right on the edge and you can learn more

00:04:01,090 --> 00:04:07,030
about that or coral yeah so here's an

00:04:04,930 --> 00:04:10,060
example of how you can use tensile Hub

00:04:07,030 --> 00:04:12,370
to do fast artistic style transfer that

00:04:10,060 --> 00:04:15,340
can work on an arbitrary painting style

00:04:12,370 --> 00:04:17,890
or generative models so let's say you

00:04:15,340 --> 00:04:20,950
had an image of a beautiful yellow

00:04:17,890 --> 00:04:24,580
Labrador and you wanted to see what that

00:04:20,950 --> 00:04:27,159
style would look like in Kandinsky well

00:04:24,580 --> 00:04:29,200
with one line of code you can load a one

00:04:27,159 --> 00:04:29,770
of these pre train star transfer models

00:04:29,200 --> 00:04:33,490
from the

00:04:29,770 --> 00:04:35,199
Genta team at Google and then you can

00:04:33,490 --> 00:04:37,150
just apply it to your content and style

00:04:35,199 --> 00:04:39,849
image and you can get a new in satellite

00:04:37,150 --> 00:04:41,680
image and you can learn more about some

00:04:39,849 --> 00:04:45,069
simple tutorials like that in this link

00:04:41,680 --> 00:04:48,610
below well let's say you wanted to Train

00:04:45,069 --> 00:04:50,979
and you trance a text classifier such as

00:04:48,610 --> 00:04:53,500
predicting whether a movie review had is

00:04:50,979 --> 00:04:55,599
positive or negative rating well

00:04:53,500 --> 00:04:58,659
training a text embedding layer may take

00:04:55,599 --> 00:05:00,810
a lot of time and data you're going to

00:04:58,659 --> 00:05:03,580
make that work well but with tencel hub

00:05:00,810 --> 00:05:05,560
you can pull a number of pre trained

00:05:03,580 --> 00:05:08,409
text models with just one line of code

00:05:05,560 --> 00:05:10,990
and then you can incorporate it into

00:05:08,409 --> 00:05:12,849
tense flow too and using standard api is

00:05:10,990 --> 00:05:17,080
like arrows you can retrain it on your

00:05:12,849 --> 00:05:19,449
new data set just like that we've also

00:05:17,080 --> 00:05:21,789
integrated an interactive model

00:05:19,449 --> 00:05:24,159
visualizer in beta for some of the

00:05:21,789 --> 00:05:26,199
models and this allows you to

00:05:24,159 --> 00:05:29,409
immediately preview what the model would

00:05:26,199 --> 00:05:33,370
do and run that that model within the

00:05:29,409 --> 00:05:36,460
webpage or on a mobile app like a

00:05:33,370 --> 00:05:38,110
playground app for example here is a

00:05:36,460 --> 00:05:40,870
model from the Danish mycological

00:05:38,110 --> 00:05:43,500
Society for identifying a wide range of

00:05:40,870 --> 00:05:46,599
fungi as far as ice fun by Atlas project

00:05:43,500 --> 00:05:48,789
you can directly drag an image onto the

00:05:46,599 --> 00:05:51,310
site and the model will run in real time

00:05:48,789 --> 00:05:53,949
and show you the results such as what

00:05:51,310 --> 00:05:55,330
mushrooms were in that image and then

00:05:53,949 --> 00:05:56,190
you can click on it to go and get more

00:05:55,330 --> 00:05:58,479
information

00:05:56,190 --> 00:06:01,300
many of the tents of all hung models

00:05:58,479 --> 00:06:05,199
also have collab links so you can play

00:06:01,300 --> 00:06:06,909
with these models in right in with the

00:06:05,199 --> 00:06:08,500
code right inside the browser and

00:06:06,909 --> 00:06:11,979
powered by the Google infrastructure

00:06:08,500 --> 00:06:15,190
with collab in fact the Google machine

00:06:11,979 --> 00:06:17,409
learning fairness a team also has built

00:06:15,190 --> 00:06:19,479
some collab notebooks that can pull text

00:06:17,409 --> 00:06:23,500
embeddings and other embeddings straight

00:06:19,479 --> 00:06:26,560
into to their platform so you can assess

00:06:23,500 --> 00:06:29,020
whether there are potential biases for a

00:06:26,560 --> 00:06:30,400
standard set of tasks and you can

00:06:29,020 --> 00:06:34,419
combine a mobility we want to learn more

00:06:30,400 --> 00:06:36,219
about that pencil hub is also powered by

00:06:34,419 --> 00:06:39,130
the community when we launch tense well

00:06:36,219 --> 00:06:40,570
hub last year we were sharing some of

00:06:39,130 --> 00:06:43,600
the state of the art models from deep

00:06:40,570 --> 00:06:45,460
mine in Google but now a wide range

00:06:43,600 --> 00:06:48,700
publishers are beginning to share their

00:06:45,460 --> 00:06:51,360
models from a diverse set of areas such

00:06:48,700 --> 00:06:54,460
as Microsoft AI for Earth the met or

00:06:51,360 --> 00:06:56,110
Nvidia and these models can be used for

00:06:54,460 --> 00:06:58,360
many different tasks such as from

00:06:56,110 --> 00:07:00,490
studying wildlife populations through

00:06:58,360 --> 00:07:03,190
these camera traps or for automatic

00:07:00,490 --> 00:07:06,130
visual defect detection in industries

00:07:03,190 --> 00:07:08,350
and crowdsource by Google is also

00:07:06,130 --> 00:07:10,630
generating a wide range of data through

00:07:08,350 --> 00:07:13,390
the open images extended datasets and

00:07:10,630 --> 00:07:16,120
with that we can get an even richer set

00:07:13,390 --> 00:07:20,260
of ready to use models across many

00:07:16,120 --> 00:07:22,510
different specific datasets so with

00:07:20,260 --> 00:07:24,490
hundreds of a models that are pre

00:07:22,510 --> 00:07:27,250
trained and ready to use you can use

00:07:24,490 --> 00:07:28,600
tencel hub to immediately begin using

00:07:27,250 --> 00:07:32,650
machine learning to solve some business

00:07:28,600 --> 00:07:35,560
problems so I hope that you can come by

00:07:32,650 --> 00:07:37,210
our demo booth or go to the TF hub death

00:07:35,560 --> 00:07:38,720
and I'll see you there

00:07:37,210 --> 00:07:42,720
thank you

00:07:38,720 --> 00:07:42,720

YouTube URL: https://www.youtube.com/watch?v=okxhGoqUCKA


