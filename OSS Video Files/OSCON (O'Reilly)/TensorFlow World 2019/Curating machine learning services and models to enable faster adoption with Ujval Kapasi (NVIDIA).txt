Title: Curating machine learning services and models to enable faster adoption with Ujval Kapasi (NVIDIA)
Publication date: 2019-11-12
Playlist: TensorFlow World 2019
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,000 --> 00:00:05,310
hi Roger here with goofball capaci who's

00:00:02,639 --> 00:00:08,069
VP of deep learning at Nvidia welcome

00:00:05,310 --> 00:00:10,679
thank you and you know we were talking

00:00:08,069 --> 00:00:14,400
before the started about kubernetes as

00:00:10,679 --> 00:00:16,980
something that's pretty engaging what do

00:00:14,400 --> 00:00:19,320
you think is going on in that space one

00:00:16,980 --> 00:00:21,960
thing that we found is you know in the

00:00:19,320 --> 00:00:24,779
world of kubernetes you know for certain

00:00:21,960 --> 00:00:26,699
application stacks you know they have

00:00:24,779 --> 00:00:27,930
these things he's like with with queue

00:00:26,699 --> 00:00:30,210
flow and helm charts you can put

00:00:27,930 --> 00:00:33,239
together you can string together a bunch

00:00:30,210 --> 00:00:35,040
of services and put into help chart and

00:00:33,239 --> 00:00:37,680
then you can just basically deploy it

00:00:35,040 --> 00:00:38,760
almost automatically and that was one of

00:00:37,680 --> 00:00:40,559
the things that actually I talked about

00:00:38,760 --> 00:00:41,850
was we're starting to make these help

00:00:40,559 --> 00:00:43,079
charts available with developing and

00:00:41,850 --> 00:00:45,059
make them available so people can get

00:00:43,079 --> 00:00:48,059
started with that if they want mm-hmm

00:00:45,059 --> 00:00:53,420
but also just getting your model into a

00:00:48,059 --> 00:00:55,649
service is something that is you know

00:00:53,420 --> 00:00:57,180
not like like you said something

00:00:55,649 --> 00:00:59,280
something you just stumble into you have

00:00:57,180 --> 00:01:02,190
to if to understand what are all the

00:00:59,280 --> 00:01:03,480
different options you know what will

00:01:02,190 --> 00:01:04,920
work in our production deployment

00:01:03,480 --> 00:01:06,180
environment what do you have to be

00:01:04,920 --> 00:01:08,310
intentional you have to be intentional

00:01:06,180 --> 00:01:10,260
yeah and there's depending on what you

00:01:08,310 --> 00:01:12,689
used for training you may have to take

00:01:10,260 --> 00:01:15,060
different paths one of the projects my

00:01:12,689 --> 00:01:19,140
team is working on actually is a server

00:01:15,060 --> 00:01:20,159
for serving predictions and I think one

00:01:19,140 --> 00:01:23,820
of the unique things about it is that

00:01:20,159 --> 00:01:26,189
it's agnostic to framework or hardware

00:01:23,820 --> 00:01:26,880
works on CPUs or GPUs your model could

00:01:26,189 --> 00:01:29,549
be tensorflow

00:01:26,880 --> 00:01:33,180
or an onyx or PI torch and we're seeing

00:01:29,549 --> 00:01:36,570
strong interest in that because people

00:01:33,180 --> 00:01:39,540
haven't made their decisions and so but

00:01:36,570 --> 00:01:41,340
once you go into deployment it's hard to

00:01:39,540 --> 00:01:44,340
change things right that's like a much

00:01:41,340 --> 00:01:45,930
more stringent environment than what you

00:01:44,340 --> 00:01:47,490
might do on your mind and your research

00:01:45,930 --> 00:01:48,869
environment and so we're seeing a lot of

00:01:47,490 --> 00:01:53,159
interest in that because it gives them

00:01:48,869 --> 00:01:55,710
the flexibility to an organization they

00:01:53,159 --> 00:01:56,720
may have a variety of different sources

00:01:55,710 --> 00:01:58,700
of

00:01:56,720 --> 00:02:00,080
models that they want to serve so this

00:01:58,700 --> 00:02:01,700
is interesting so you're saying that as

00:02:00,080 --> 00:02:05,260
people are trying to get into a more

00:02:01,700 --> 00:02:07,280
production phase of working things out

00:02:05,260 --> 00:02:08,960
that you're providing the kind of tools

00:02:07,280 --> 00:02:11,570
that make that easier maybe going a

00:02:08,960 --> 00:02:14,840
little detail on yeah yeah actually you

00:02:11,570 --> 00:02:18,110
know so there's entire workflow starting

00:02:14,840 --> 00:02:20,960
at pure research to deployment and

00:02:18,110 --> 00:02:24,140
production and you know one thing we

00:02:20,960 --> 00:02:25,490
realized is that different organizations

00:02:24,140 --> 00:02:27,650
or different people in organizations may

00:02:25,490 --> 00:02:29,360
want to start at different points but it

00:02:27,650 --> 00:02:31,510
doesn't make sense for them to try to

00:02:29,360 --> 00:02:34,180
recreate everything from Ground Zero and

00:02:31,510 --> 00:02:36,950
we love that there's such a vibrant

00:02:34,180 --> 00:02:38,870
open-source community for people to you

00:02:36,950 --> 00:02:42,860
know build on top of each other and lots

00:02:38,870 --> 00:02:44,750
of ideas sprouting everywhere but one

00:02:42,860 --> 00:02:46,880
thing we've tried to do is and I think

00:02:44,750 --> 00:02:49,070
where Nvidia can contribute into this is

00:02:46,880 --> 00:02:53,720
we try to keep an eye on okay well what

00:02:49,070 --> 00:02:57,800
is our some sort of areas where people

00:02:53,720 --> 00:02:59,690
are spending more time on more models

00:02:57,800 --> 00:03:01,580
are getting more popular types of

00:02:59,690 --> 00:03:03,770
applications that are starting to get

00:03:01,580 --> 00:03:08,840
more interesting and then what we do is

00:03:03,770 --> 00:03:11,660
we try to contribute by then curating

00:03:08,840 --> 00:03:14,209
code for a particular use case or model

00:03:11,660 --> 00:03:16,100
and making it available for every step

00:03:14,209 --> 00:03:17,330
of the workflow so you might consider

00:03:16,100 --> 00:03:19,820
for instance we have an optimized

00:03:17,330 --> 00:03:21,170
tensorflow container that you can use to

00:03:19,820 --> 00:03:23,000
just get started and do something from

00:03:21,170 --> 00:03:24,530
scratch but if you're interested in

00:03:23,000 --> 00:03:27,650
natural language processing and you want

00:03:24,530 --> 00:03:29,000
to use burn we have a script that you

00:03:27,650 --> 00:03:32,090
can use to start training for it with

00:03:29,000 --> 00:03:33,410
your own data but maybe you want Bert

00:03:32,090 --> 00:03:34,820
pre trained with the data that we

00:03:33,410 --> 00:03:37,820
already trained it with which is pretty

00:03:34,820 --> 00:03:39,920
general Wiki Wikipedia etc then you can

00:03:37,820 --> 00:03:42,410
take our pre trained model and then find

00:03:39,920 --> 00:03:45,230
start with that and fine-tune it for the

00:03:42,410 --> 00:03:46,160
particular task you care about well we

00:03:45,230 --> 00:03:48,080
may have already changed it for the

00:03:46,160 --> 00:03:50,870
particular task you care about and you

00:03:48,080 --> 00:03:52,519
may just want to start with that and we

00:03:50,870 --> 00:03:53,870
have like an optimized plan for

00:03:52,519 --> 00:03:55,690
deployment you can just take that into

00:03:53,870 --> 00:03:57,430
point in a service

00:03:55,690 --> 00:04:00,220
you might actually be deploying it in a

00:03:57,430 --> 00:04:02,920
service as part of a larger application

00:04:00,220 --> 00:04:05,050
some kind of conversational AI thing and

00:04:02,920 --> 00:04:06,310
we may have a pipeline already full

00:04:05,050 --> 00:04:07,450
pipeline built for that you can just

00:04:06,310 --> 00:04:11,020
download the help chart and deploy that

00:04:07,450 --> 00:04:14,380
so at each of these steps I think we can

00:04:11,020 --> 00:04:16,239
engage with people that are coming at it

00:04:14,380 --> 00:04:17,320
and they want to figure out where do

00:04:16,239 --> 00:04:20,890
they're gonna add their differentiation

00:04:17,320 --> 00:04:24,010
and our goal is to kind of curate in the

00:04:20,890 --> 00:04:25,930
sense of like testing and documenting

00:04:24,010 --> 00:04:27,790
maintaining the software it for each of

00:04:25,930 --> 00:04:29,470
these so we don't do everything but we

00:04:27,790 --> 00:04:30,790
pick the the key ones we think that can

00:04:29,470 --> 00:04:32,890
help enable the most people to get

00:04:30,790 --> 00:04:34,390
started quickly and of course everything

00:04:32,890 --> 00:04:37,000
we put out is like well optimized for

00:04:34,390 --> 00:04:39,220
GPUs yeah and it sounds like almost like

00:04:37,000 --> 00:04:40,630
a buffet approach in a way and that you

00:04:39,220 --> 00:04:42,400
can pick the things that might work for

00:04:40,630 --> 00:04:44,020
you or the general things that you would

00:04:42,400 --> 00:04:46,840
because that kind of an accurate

00:04:44,020 --> 00:04:47,140
description yeah yeah of what you're

00:04:46,840 --> 00:04:49,180
doing

00:04:47,140 --> 00:04:52,900
yeah and it's a salt like open sourced

00:04:49,180 --> 00:04:55,420
or is this yeah how are you providing

00:04:52,900 --> 00:04:57,730
these different containers and so forth

00:04:55,420 --> 00:05:00,580
yeah so it's it's all open sourced the

00:04:57,730 --> 00:05:02,560
containers you know all the changes any

00:05:00,580 --> 00:05:03,730
changes that we make is the source codes

00:05:02,560 --> 00:05:05,230
and the containers as well but it's also

00:05:03,730 --> 00:05:09,550
built so you don't have to compile it

00:05:05,230 --> 00:05:11,860
all the training scripts and that

00:05:09,550 --> 00:05:14,350
stuff's also on github as well as TF hub

00:05:11,860 --> 00:05:15,730
which was launched today we were we were

00:05:14,350 --> 00:05:17,020
one of the first to get on there because

00:05:15,730 --> 00:05:18,640
we just want to have the stuff available

00:05:17,020 --> 00:05:21,910
where developers are mm-hmm

00:05:18,640 --> 00:05:24,430
but ng C Nvidia comm we have it all

00:05:21,910 --> 00:05:26,530
there just in kind of a way that we

00:05:24,430 --> 00:05:29,169
think is organized to help people coming

00:05:26,530 --> 00:05:30,880
in at it from different mm-hmm any point

00:05:29,169 --> 00:05:33,610
of the workflow that they're they're

00:05:30,880 --> 00:05:35,500
starting from and the source code for

00:05:33,610 --> 00:05:37,060
all this stuff is up there mmm but we

00:05:35,500 --> 00:05:38,980
also have pre-built things so you can

00:05:37,060 --> 00:05:40,120
get started quicker sure where do you

00:05:38,980 --> 00:05:41,890
think people have in the most trouble

00:05:40,120 --> 00:05:43,360
and then like where are you focusing

00:05:41,890 --> 00:05:45,310
your efforts yeah

00:05:43,360 --> 00:05:48,190
and that workflow that's a great

00:05:45,310 --> 00:05:49,720
question you know someone was giving a

00:05:48,190 --> 00:05:51,430
talk here I don't remember which talk it

00:05:49,720 --> 00:05:54,190
was but they had a slide up that I

00:05:51,430 --> 00:05:56,890
thought kind of captured the essence of

00:05:54,190 --> 00:05:57,840
the problem which is most models never

00:05:56,890 --> 00:06:00,370
see the light of day

00:05:57,840 --> 00:06:02,740
most deep machine learning models that's

00:06:00,370 --> 00:06:05,980
right because it's really hard to get

00:06:02,740 --> 00:06:07,830
from something that was

00:06:05,980 --> 00:06:11,260
arrived at through research

00:06:07,830 --> 00:06:13,090
experimentation trial and error built on

00:06:11,260 --> 00:06:16,690
top of some other people's code then you

00:06:13,090 --> 00:06:18,910
have something that works well getting

00:06:16,690 --> 00:06:21,070
from that to actually something you can

00:06:18,910 --> 00:06:25,260
deploy in a production harden

00:06:21,070 --> 00:06:28,720
environment that can scale is a gap and

00:06:25,260 --> 00:06:30,190
part of a gap is just understanding what

00:06:28,720 --> 00:06:34,420
tools are available to get you there

00:06:30,190 --> 00:06:37,330
part of it is understanding you know

00:06:34,420 --> 00:06:40,870
what the requirements of the production

00:06:37,330 --> 00:06:42,460
environment are and that that is a big

00:06:40,870 --> 00:06:44,740
gap we see we're trying to develop some

00:06:42,460 --> 00:06:47,310
tools to help it make it so that if you

00:06:44,740 --> 00:06:50,290
have a model you've trained you can then

00:06:47,310 --> 00:06:52,600
put it up as a service without python

00:06:50,290 --> 00:06:54,580
code you're using the c++ interface of

00:06:52,600 --> 00:06:55,810
tensorflow for instance without any work

00:06:54,580 --> 00:06:57,160
on your end

00:06:55,810 --> 00:06:58,510
but i think there's a lot of work to be

00:06:57,160 --> 00:07:01,300
done there and it's something we're

00:06:58,510 --> 00:07:02,530
continually trying to you know work on

00:07:01,300 --> 00:07:05,400
it's great it's creating a lot of work

00:07:02,530 --> 00:07:08,110
for us so that's fun thank you busy yeah

00:07:05,400 --> 00:07:10,060
so in this world where you're giving

00:07:08,110 --> 00:07:11,470
stuff out where most people grabbing

00:07:10,060 --> 00:07:13,690
stuff like what kind of things do you

00:07:11,470 --> 00:07:17,110
see getting the most uptake yeah good

00:07:13,690 --> 00:07:21,250
question certainly the whole space of

00:07:17,110 --> 00:07:23,230
conversational AI is budding the machine

00:07:21,250 --> 00:07:25,720
learning deep learning models what they

00:07:23,230 --> 00:07:28,330
can do today is drastically different

00:07:25,720 --> 00:07:29,410
from just like a year or two ago and now

00:07:28,330 --> 00:07:32,440
people are just being able to digest

00:07:29,410 --> 00:07:35,920
that and build products with it and you

00:07:32,440 --> 00:07:38,350
know it's not coincidental that these

00:07:35,920 --> 00:07:40,870
models require like a large amount of

00:07:38,350 --> 00:07:43,510
compute and you know that's where GPUs

00:07:40,870 --> 00:07:47,800
shine right and so when people go to

00:07:43,510 --> 00:07:50,110
deploy these into products or services

00:07:47,800 --> 00:07:52,510
they're gonna need the power compute

00:07:50,110 --> 00:07:54,310
power of a GPU to be able to serve

00:07:52,510 --> 00:07:55,600
predictions with something like a Bert

00:07:54,310 --> 00:07:59,110
model for instance which Jeff Dean

00:07:55,600 --> 00:08:01,210
talked about mmm-hmm so that's kind of

00:07:59,110 --> 00:08:03,250
one you know

00:08:01,210 --> 00:08:04,540
trend we're seeing sure how about in

00:08:03,250 --> 00:08:09,250
terms of verticals where do you see

00:08:04,540 --> 00:08:11,950
people adopting we see a lot of activity

00:08:09,250 --> 00:08:14,110
in healthcare I think partially because

00:08:11,950 --> 00:08:19,480
that's an area that you know NVIDIA is

00:08:14,110 --> 00:08:22,450
also engaged in healthcare is a field

00:08:19,480 --> 00:08:23,920
that I think is sort of unique Nvidia

00:08:22,450 --> 00:08:27,510
has some unique things to offer there

00:08:23,920 --> 00:08:32,200
because there's a lot of computer vision

00:08:27,510 --> 00:08:34,870
required in that space but also there's

00:08:32,200 --> 00:08:36,310
a lot of variety in the kinds of

00:08:34,870 --> 00:08:38,200
applications people need to run it's not

00:08:36,310 --> 00:08:40,630
just one thing and since GPUs are

00:08:38,200 --> 00:08:42,820
programmable that is as helping there so

00:08:40,630 --> 00:08:49,690
healthcare is is one vertical we see a

00:08:42,820 --> 00:08:52,570
lot of action in and I guess the another

00:08:49,690 --> 00:08:55,600
vertical would be obviously autonomous

00:08:52,570 --> 00:09:00,930
vehicles of all sorts robots and cars

00:08:55,600 --> 00:09:03,540
etc vacuum cleaners yeah yeah so I

00:09:00,930 --> 00:09:06,370
missed curious what was your background

00:09:03,540 --> 00:09:07,480
in terms of informing what you're doing

00:09:06,370 --> 00:09:08,770
with this because it sounds like you

00:09:07,480 --> 00:09:12,180
guys are taking a pretty multifaceted

00:09:08,770 --> 00:09:15,760
approach to getting people up to speed

00:09:12,180 --> 00:09:19,660
how did you get to being able to provide

00:09:15,760 --> 00:09:22,750
that oh I think so you know when I first

00:09:19,660 --> 00:09:24,910
got said Vidya I started to work on the

00:09:22,750 --> 00:09:26,590
CUDA team and this was about ten years

00:09:24,910 --> 00:09:29,680
ago so we're just starting out and our

00:09:26,590 --> 00:09:33,810
goal was to provide a platform for

00:09:29,680 --> 00:09:37,000
scientists who were looking for a way to

00:09:33,810 --> 00:09:38,620
be able to do more with simulation so

00:09:37,000 --> 00:09:40,930
they had the ability to do lab work and

00:09:38,620 --> 00:09:42,640
they had theory and they wanted to

00:09:40,930 --> 00:09:44,470
augment it with simulation with the

00:09:42,640 --> 00:09:46,270
right simulation they could test out

00:09:44,470 --> 00:09:48,820
their theories with less lab work and

00:09:46,270 --> 00:09:52,540
only go do you know going to the wet lab

00:09:48,820 --> 00:09:55,000
when they have more sort of pruned set

00:09:52,540 --> 00:09:57,940
of ideas and be more fruitful with their

00:09:55,000 --> 00:09:59,380
research and this was you know a mission

00:09:57,940 --> 00:10:02,230
I could really get behind and so I

00:09:59,380 --> 00:10:04,780
joined the team and what we learned

00:10:02,230 --> 00:10:07,450
through there was that a you know

00:10:04,780 --> 00:10:11,350
compute there's an insatiable demand for

00:10:07,450 --> 00:10:12,630
compute there but it not everyone is a

00:10:11,350 --> 00:10:15,259
computer scientist

00:10:12,630 --> 00:10:17,850
and so we had to keep developing

00:10:15,259 --> 00:10:19,949
libraries primarily at other high level

00:10:17,850 --> 00:10:22,319
abstractions so people can get the

00:10:19,949 --> 00:10:24,600
benefits of the computer in GP without

00:10:22,319 --> 00:10:25,589
having to write code themselves and for

00:10:24,600 --> 00:10:27,060
the cases where they didn't need to

00:10:25,589 --> 00:10:30,029
write it they could do that with CUDA

00:10:27,060 --> 00:10:32,190
and so my focus was building those

00:10:30,029 --> 00:10:34,079
libraries one of the spaces we started

00:10:32,190 --> 00:10:35,279
looking at was deep learning and machine

00:10:34,079 --> 00:10:37,319
learning and then quickly deep learning

00:10:35,279 --> 00:10:39,509
and so that's how my team started

00:10:37,319 --> 00:10:41,579
working on deep learning and we were

00:10:39,509 --> 00:10:43,889
kind of informed by the HPC background

00:10:41,579 --> 00:10:45,240
which I think you know was one of the

00:10:43,889 --> 00:10:50,100
points I was making him my talk today

00:10:45,240 --> 00:10:51,839
was as you get beyond you know training

00:10:50,100 --> 00:10:53,190
on a single GPU and if you want to train

00:10:51,839 --> 00:10:55,199
things like Bert which we just talked

00:10:53,190 --> 00:10:55,529
about as being one of the hot things

00:10:55,199 --> 00:10:57,899
right now

00:10:55,529 --> 00:11:00,829
or even larger models you have to start

00:10:57,899 --> 00:11:03,509
training on basically supercomputers and

00:11:00,829 --> 00:11:05,220
you cannot do that effectively without

00:11:03,509 --> 00:11:07,800
designing the hardware and software

00:11:05,220 --> 00:11:11,069
together and precisely tuning everything

00:11:07,800 --> 00:11:13,139
and coming from an HPC background we

00:11:11,069 --> 00:11:16,199
bring that systems expertise to this

00:11:13,139 --> 00:11:19,860
problem and that's been really enjoyable

00:11:16,199 --> 00:11:21,899
and I think productive have an impact

00:11:19,860 --> 00:11:24,720
that makes a lot of sense in that you're

00:11:21,899 --> 00:11:26,670
moving people into production that that

00:11:24,720 --> 00:11:29,899
background would help yeah so great well

00:11:26,670 --> 00:11:29,899

YouTube URL: https://www.youtube.com/watch?v=FTSO__S8G48


