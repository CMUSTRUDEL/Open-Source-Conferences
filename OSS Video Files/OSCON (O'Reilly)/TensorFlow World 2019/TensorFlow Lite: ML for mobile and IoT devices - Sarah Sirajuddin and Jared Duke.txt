Title: TensorFlow Lite: ML for mobile and IoT devices - Sarah Sirajuddin and Jared Duke
Publication date: 2019-11-01
Playlist: TensorFlow World 2019
Description: 
	TensorFlow Lite makes it really easy to execute machine learning on mobile phones and microcontrollers. Jared Duke and Sarah Sirajuddin explore on-device ML and the latest updates to TensorFlow Lite, including model conversion, optimization, hardware acceleration, and a ready-to-use model gallery. They also showcase demos and production use cases for TensorFlow Lite on phones and microcontrollers.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:02,170 --> 00:00:06,710
so welcome everyone

00:00:04,070 --> 00:00:08,719
I'm Sara I am the engineering lead for

00:00:06,710 --> 00:00:10,820
tensorflow light and I'm really happy to

00:00:08,719 --> 00:00:13,400
be here talking to you about on device

00:00:10,820 --> 00:00:15,019
machine learning I'm Jarrod tech lead on

00:00:13,400 --> 00:00:16,670
tents for light and I'm reasonably

00:00:15,019 --> 00:00:20,570
excited to share with you our progress

00:00:16,670 --> 00:00:23,630
and all the latest updates so first of

00:00:20,570 --> 00:00:25,580
all what is tensorflow light so

00:00:23,630 --> 00:00:27,619
tensorflow light is our production-ready

00:00:25,580 --> 00:00:29,929
framework for deploying machine learning

00:00:27,619 --> 00:00:31,999
on mobile and embedded devices it is

00:00:29,929 --> 00:00:35,570
cross-platform so it can be used for

00:00:31,999 --> 00:00:37,399
deployment on Android iOS Linux based

00:00:35,570 --> 00:00:41,420
systems as well as several other

00:00:37,399 --> 00:00:43,579
platforms so let's talk about the need

00:00:41,420 --> 00:00:45,760
for tons of low light and why we built a

00:00:43,579 --> 00:00:49,010
non device machine learning solution

00:00:45,760 --> 00:00:50,809
simply put there is now a huge demand

00:00:49,010 --> 00:00:54,079
for doing machine learning on the edge

00:00:50,809 --> 00:00:56,030
and it is driven by a need for building

00:00:54,079 --> 00:00:59,300
user experiences which require low

00:00:56,030 --> 00:01:01,219
latency further factors are poor network

00:00:59,300 --> 00:01:03,949
connectivity and the need for user

00:01:01,219 --> 00:01:05,810
privacy preserving features all of these

00:01:03,949 --> 00:01:07,490
are easier done when you're doing

00:01:05,810 --> 00:01:09,619
machine learning directly on the device

00:01:07,490 --> 00:01:13,909
and that's why we release tensorflow

00:01:09,619 --> 00:01:16,430
Lite late in 2017 and this shows our

00:01:13,909 --> 00:01:18,110
journey since then we've made a ton of

00:01:16,430 --> 00:01:20,619
improvements across the board in terms

00:01:18,110 --> 00:01:23,390
of the ops that we support performance

00:01:20,619 --> 00:01:25,700
usability tools which allow you to

00:01:23,390 --> 00:01:27,950
optimize your models the number of

00:01:25,700 --> 00:01:29,509
languages we support in our API as well

00:01:27,950 --> 00:01:33,619
as the number of platforms tensorflow

00:01:29,509 --> 00:01:35,450
light runs on tensorflow line is now on

00:01:33,619 --> 00:01:38,479
deployed on more than three billion

00:01:35,450 --> 00:01:41,299
devices globally many of Google's own

00:01:38,479 --> 00:01:45,680
largest apps are using it as our apps

00:01:41,299 --> 00:01:47,360
from several other external companies so

00:01:45,680 --> 00:01:50,649
this is a sampling of apps which use

00:01:47,360 --> 00:01:53,780
tensorflow like google photos g board

00:01:50,649 --> 00:01:58,759
youtube assistant as well as leading

00:01:53,780 --> 00:02:00,409
companies like hike uber and more so

00:01:58,759 --> 00:02:03,170
what is sense of the light being used

00:02:00,409 --> 00:02:05,329
for so we find that our developers use

00:02:03,170 --> 00:02:07,610
it for popular use cases around text

00:02:05,329 --> 00:02:10,370
image and speech but we are also seeing

00:02:07,610 --> 00:02:12,890
lots of emerging in new use cases come

00:02:10,370 --> 00:02:14,630
up in the areas of audio and content

00:02:12,890 --> 00:02:16,100
generation

00:02:14,630 --> 00:02:18,020
so this was a quick introduction about

00:02:16,100 --> 00:02:19,850
tensorflow light in the rest of this

00:02:18,020 --> 00:02:21,500
talk we are going to be focusing on

00:02:19,850 --> 00:02:23,690
sharing our latest updates and the

00:02:21,500 --> 00:02:25,700
highlights for more details please check

00:02:23,690 --> 00:02:29,750
out the tensorflow light talk later in

00:02:25,700 --> 00:02:31,520
the day so today I'm really excited to

00:02:29,750 --> 00:02:33,620
announce a suite of tools which will

00:02:31,520 --> 00:02:36,740
make it really easy for developers to

00:02:33,620 --> 00:02:38,930
get started with tensorflow light first

00:02:36,740 --> 00:02:41,720
up we are introducing a new support

00:02:38,930 --> 00:02:44,060
library this makes it really easy to

00:02:41,720 --> 00:02:45,830
pre-process and transform your data to

00:02:44,060 --> 00:02:49,190
make it ready for inferencing with a

00:02:45,830 --> 00:02:51,740
machine learning model so let's look at

00:02:49,190 --> 00:02:54,140
an example these are the steps that a

00:02:51,740 --> 00:02:56,330
developer typically goes through to use

00:02:54,140 --> 00:02:57,890
a model in their app once they have

00:02:56,330 --> 00:03:01,490
converted it to the tensorflow light

00:02:57,890 --> 00:03:03,950
model format and let's say they're doing

00:03:01,490 --> 00:03:06,050
image classification so then they will

00:03:03,950 --> 00:03:08,780
likely need to write code which looks

00:03:06,050 --> 00:03:11,450
something like this as you can see it is

00:03:08,780 --> 00:03:15,230
a lot of code for loading transforming

00:03:11,450 --> 00:03:17,510
and using the data with the new support

00:03:15,230 --> 00:03:20,000
library the previous wall of code that I

00:03:17,510 --> 00:03:22,580
showed can be reduced significantly to

00:03:20,000 --> 00:03:25,010
this just a single line of code is

00:03:22,580 --> 00:03:28,330
needed for each of loading transforming

00:03:25,010 --> 00:03:31,010
and using the resultant classifications

00:03:28,330 --> 00:03:34,070
next up we are introducing model

00:03:31,010 --> 00:03:36,620
metadata now model authors can provide a

00:03:34,070 --> 00:03:38,720
metadata spec when they are creating and

00:03:36,620 --> 00:03:40,520
converting models and this makes it

00:03:38,720 --> 00:03:42,320
easier for users of the model to

00:03:40,520 --> 00:03:45,410
understand what the model does and to

00:03:42,320 --> 00:03:48,140
use it in production let's look at an

00:03:45,410 --> 00:03:50,060
example again the metadata descriptor

00:03:48,140 --> 00:03:52,820
here provides additional information

00:03:50,060 --> 00:03:54,860
about what the model does the expected

00:03:52,820 --> 00:03:58,970
format of the inputs and what is the

00:03:54,860 --> 00:04:02,090
meaning of the outputs third we've made

00:03:58,970 --> 00:04:04,670
our model repository much richer we've

00:04:02,090 --> 00:04:07,040
added several new models across several

00:04:04,670 --> 00:04:08,510
different domains all of them are pre

00:04:07,040 --> 00:04:10,400
converted into the tensorflow light

00:04:08,510 --> 00:04:14,360
model format so you can download them

00:04:10,400 --> 00:04:17,150
and use them right away having a

00:04:14,360 --> 00:04:19,220
repository of ready-to-use models is a

00:04:17,150 --> 00:04:22,160
great for getting started and trying

00:04:19,220 --> 00:04:23,960
them out however most of our developers

00:04:22,160 --> 00:04:26,900
will need to customize these models in

00:04:23,960 --> 00:04:28,430
some way which is why we are releasing a

00:04:26,900 --> 00:04:31,490
set of API switch you

00:04:28,430 --> 00:04:33,979
News 2 use your own data to retrain

00:04:31,490 --> 00:04:39,669
these models and then use them in your

00:04:33,979 --> 00:04:42,289
app we've heard from our developers that

00:04:39,669 --> 00:04:44,539
we need to provide better and more

00:04:42,289 --> 00:04:46,490
tutorials and examples so we are

00:04:44,539 --> 00:04:49,070
releasing today several full examples

00:04:46,490 --> 00:04:51,830
with show code not only how to use a

00:04:49,070 --> 00:04:54,350
model but to how you would write an

00:04:51,830 --> 00:04:55,660
end-to-end app and these examples have

00:04:54,350 --> 00:04:59,180
been written for several platforms

00:04:55,660 --> 00:05:03,470
Android iOS raspberry Pi and even edge

00:04:59,180 --> 00:05:05,000
TPU and lastly I'm super happy to

00:05:03,470 --> 00:05:07,250
announce that we have just launched a

00:05:05,000 --> 00:05:11,150
brand new course on how to use sense of

00:05:07,250 --> 00:05:13,639
low light on Udacity all of these are

00:05:11,150 --> 00:05:16,490
live right now please check them out and

00:05:13,639 --> 00:05:17,870
give us feedback and this brings me to

00:05:16,490 --> 00:05:20,840
another announcement that I'm very

00:05:17,870 --> 00:05:23,090
excited about so we have worked with the

00:05:20,840 --> 00:05:25,070
researchers at Google brain to bring

00:05:23,090 --> 00:05:28,789
mobile birth to developers through

00:05:25,070 --> 00:05:30,830
tensorflow life bert is a method of

00:05:28,789 --> 00:05:33,380
pre-training language representations

00:05:30,830 --> 00:05:35,419
which gets really fantastic results on a

00:05:33,380 --> 00:05:38,659
wide variety of natural language

00:05:35,419 --> 00:05:41,060
processing tasks Google itself uses

00:05:38,659 --> 00:05:43,490
board extensively to understand natural

00:05:41,060 --> 00:05:45,500
text on the web but it is having a

00:05:43,490 --> 00:05:48,800
transformational impact broadly across

00:05:45,500 --> 00:05:51,199
the industry so the model that we are

00:05:48,800 --> 00:05:53,990
releasing is up to four point four times

00:05:51,199 --> 00:05:56,389
faster then standard board while being

00:05:53,990 --> 00:05:59,990
four times smaller with no loss in

00:05:56,389 --> 00:06:02,599
accuracy the model is less than hundred

00:05:59,990 --> 00:06:05,539
megabytes in size so it's usable even on

00:06:02,599 --> 00:06:07,970
lower end phones it's available on our

00:06:05,539 --> 00:06:10,070
site ready for use right now we're

00:06:07,970 --> 00:06:12,620
really excited about the new use cases

00:06:10,070 --> 00:06:14,539
this model will unlock and to show you

00:06:12,620 --> 00:06:17,479
all how cool this technology really is

00:06:14,539 --> 00:06:19,490
we have a demo coming up of mobile Bert

00:06:17,479 --> 00:06:23,419
running live on a phone I'll invite

00:06:19,490 --> 00:06:25,009
Jared to show you thanks Sarah so as

00:06:23,419 --> 00:06:27,139
we've heard Bert can be used for a

00:06:25,009 --> 00:06:28,789
number of language related tasks but

00:06:27,139 --> 00:06:31,280
today I want to demonstrate it for

00:06:28,789 --> 00:06:33,169
question answering that is given some

00:06:31,280 --> 00:06:35,509
body of text and a question about its

00:06:33,169 --> 00:06:37,610
content Bert can find the answer to the

00:06:35,509 --> 00:06:40,490
question in the text so let's take it

00:06:37,610 --> 00:06:42,289
for a spin we have an app here which has

00:06:40,490 --> 00:06:44,240
a number of pre-selected Wikipedia

00:06:42,289 --> 00:06:46,449
it's and again the model was not trained

00:06:44,240 --> 00:06:50,270
on any of the text in these snippets so

00:06:46,449 --> 00:06:52,729
now I'm a space geek so let's stick in

00:06:50,270 --> 00:06:54,879
the Apollo program all right let's start

00:06:52,729 --> 00:06:57,589
with an easy question

00:06:54,879 --> 00:07:03,499
what did Kennedy want to achieve with

00:06:57,589 --> 00:07:05,300
the Apollo program landing a man on the

00:07:03,499 --> 00:07:08,360
moon and returning him safely to the

00:07:05,300 --> 00:07:12,319
earth okay but everybody knows that

00:07:08,360 --> 00:07:17,050
let's try a harder one which program

00:07:12,319 --> 00:07:17,050
came after mercury but before Apollo

00:07:18,999 --> 00:07:28,490
project Gemini not bad hmm all right

00:07:24,499 --> 00:07:41,749
Bert you think you're so smart where are

00:07:28,490 --> 00:07:42,759
all the aliens there it is mystery

00:07:41,749 --> 00:07:45,080
solved

00:07:42,759 --> 00:07:46,819
now all jokes aside you may not have

00:07:45,080 --> 00:07:48,769
noticed that this phone is running in

00:07:46,819 --> 00:07:50,809
airplane mode there's no connection to

00:07:48,769 --> 00:07:52,819
the server so everything from speech

00:07:50,809 --> 00:07:54,649
recognition to the burp model to

00:07:52,819 --> 00:07:58,509
text-to-speech was all running on device

00:07:54,649 --> 00:07:58,509
using ml pretty neat

00:08:03,130 --> 00:08:06,560
so now I'd like to talk about some

00:08:05,180 --> 00:08:08,390
improvements and investments we've been

00:08:06,560 --> 00:08:10,280
making in a tensor flow light ecosystem

00:08:08,390 --> 00:08:12,770
focused on improving your model

00:08:10,280 --> 00:08:15,290
deployment let's start with performance

00:08:12,770 --> 00:08:17,240
a key goal of tensor fill light is to

00:08:15,290 --> 00:08:20,540
make your models run as fast as possible

00:08:17,240 --> 00:08:22,340
across mobile and edge CPUs GPUs DSPs

00:08:20,540 --> 00:08:24,110
and NT use and we've made many

00:08:22,340 --> 00:08:26,510
investments across all of these fronts

00:08:24,110 --> 00:08:28,550
we've made significant CPU improvements

00:08:26,510 --> 00:08:31,070
we've added open CL support to improve

00:08:28,550 --> 00:08:33,080
GPU acceleration and we've updated our

00:08:31,070 --> 00:08:35,510
support for all of Android Q and an API

00:08:33,080 --> 00:08:37,160
ops and features our previously

00:08:35,510 --> 00:08:39,740
announced Qualcomm DSP delegate

00:08:37,160 --> 00:08:41,270
targeting mid and low hair devices will

00:08:39,740 --> 00:08:43,460
be available for use in the coming weeks

00:08:41,270 --> 00:08:45,320
and we've also made some improvements in

00:08:43,460 --> 00:08:47,210
our performance and benchmark tooling to

00:08:45,320 --> 00:08:49,310
better assist both model and app

00:08:47,210 --> 00:08:53,420
developers and identifying the optimal

00:08:49,310 --> 00:08:54,350
deployment configuration now to

00:08:53,420 --> 00:08:55,880
highlight some of these improvements

00:08:54,350 --> 00:08:58,130
let's take a look at our performance

00:08:55,880 --> 00:09:00,190
just six months ago at Google i/o using

00:08:58,130 --> 00:09:02,630
mobile net for classification inference

00:09:00,190 --> 00:09:04,730
and compare that with the performance of

00:09:02,630 --> 00:09:06,950
today this represents a massive

00:09:04,730 --> 00:09:08,630
reduction in latency and you can expect

00:09:06,950 --> 00:09:11,390
this across a wide range of models and

00:09:08,630 --> 00:09:12,680
devices both low end and high end just

00:09:11,390 --> 00:09:14,300
pull the latest version of tensor the

00:09:12,680 --> 00:09:18,020
light into your app and you can see

00:09:14,300 --> 00:09:18,950
these improvements today so digging a

00:09:18,020 --> 00:09:21,260
little bit more into these numbers

00:09:18,950 --> 00:09:23,120
floating-point CPU execution is our

00:09:21,260 --> 00:09:26,390
default path and it represents a solid

00:09:23,120 --> 00:09:28,070
baseline enabling quantization now

00:09:26,390 --> 00:09:31,400
easier with post-training quantization

00:09:28,070 --> 00:09:34,010
provides three times faster inference an

00:09:31,400 --> 00:09:36,200
enabling GPU execution provides yet more

00:09:34,010 --> 00:09:39,680
of a speed-up six times faster than our

00:09:36,200 --> 00:09:41,660
CPU baseline and finally for absolute

00:09:39,680 --> 00:09:44,240
peak performance we have the pixel for

00:09:41,660 --> 00:09:46,940
neural core accessible via the and an

00:09:44,240 --> 00:09:48,500
API tensor for life delegate this kind

00:09:46,940 --> 00:09:50,270
of expression specialized accelerator

00:09:48,500 --> 00:09:52,370
available in more and more of the latest

00:09:50,270 --> 00:09:53,930
devices amongst capabilities and use

00:09:52,370 --> 00:09:58,100
cases that just a short time ago were

00:09:53,930 --> 00:10:00,800
thought impossible on mobile devices but

00:09:58,100 --> 00:10:02,360
we haven't stopped there seamless and

00:10:00,800 --> 00:10:04,430
more robust model conversion has been a

00:10:02,360 --> 00:10:06,110
major priority for the team and we'd

00:10:04,430 --> 00:10:08,000
like to give an update on a completely

00:10:06,110 --> 00:10:10,340
new tensorflow light model conversion

00:10:08,000 --> 00:10:11,690
pipeline this new converter was built

00:10:10,340 --> 00:10:13,430
from the ground up to provide more

00:10:11,690 --> 00:10:16,000
intuitive error messages when conversion

00:10:13,430 --> 00:10:17,710
fails at support for control flow

00:10:16,000 --> 00:10:20,620
and for more advanced models like bird

00:10:17,710 --> 00:10:22,420
deep spoofy to mask our CNN and more

00:10:20,620 --> 00:10:24,880
we're excited to announce that the new

00:10:22,420 --> 00:10:28,420
convertor is available in beta and will

00:10:24,880 --> 00:10:29,800
be available more generally soon we also

00:10:28,420 --> 00:10:31,900
want to make it easy for any app

00:10:29,800 --> 00:10:33,190
developer to use tents for the light and

00:10:31,900 --> 00:10:34,920
to that end we've released a number of

00:10:33,190 --> 00:10:38,230
new first-class language bindings

00:10:34,920 --> 00:10:40,690
including Swift Objective C C sharp for

00:10:38,230 --> 00:10:43,150
unity and more this complements our

00:10:40,690 --> 00:10:45,490
existing set of bindings in C++ Java and

00:10:43,150 --> 00:10:47,170
Python and thanks to community efforts

00:10:45,490 --> 00:10:50,260
we've seen the creation of additional

00:10:47,170 --> 00:10:51,880
bindings in rust go and even dart as an

00:10:50,260 --> 00:10:53,410
open source project we welcome and

00:10:51,880 --> 00:10:56,950
encourage these kinds of contributions

00:10:53,410 --> 00:10:59,080
our model optimization toolkit remains

00:10:56,950 --> 00:11:00,880
the one-stop-shop for compressing and

00:10:59,080 --> 00:11:02,830
optimized your model there will be a

00:11:00,880 --> 00:11:06,730
talk later today with more details check

00:11:02,830 --> 00:11:08,110
out that talk so we've come a long way

00:11:06,730 --> 00:11:10,870
but we have many planned improvements

00:11:08,110 --> 00:11:12,760
our roadmap includes expanding a set of

00:11:10,870 --> 00:11:14,380
supported models further improvements in

00:11:12,760 --> 00:11:16,300
performance as well as someone were

00:11:14,380 --> 00:11:18,790
envious advanced features like on device

00:11:16,300 --> 00:11:20,589
personalization and training please

00:11:18,790 --> 00:11:22,420
check out our roadmap on tensorflow org

00:11:20,589 --> 00:11:24,070
and give us feedback again we're an open

00:11:22,420 --> 00:11:25,660
source project and we want to remain

00:11:24,070 --> 00:11:29,350
transparent about our priorities and

00:11:25,660 --> 00:11:31,030
where we're headed so I want to talk now

00:11:29,350 --> 00:11:32,830
about our efforts in enabling ml not

00:11:31,030 --> 00:11:34,660
just on billions of phones but on the

00:11:32,830 --> 00:11:36,910
hundreds of billions of embedded devices

00:11:34,660 --> 00:11:39,310
and microcontrollers that exist and are

00:11:36,910 --> 00:11:40,810
used in production globally tensorflow

00:11:39,310 --> 00:11:43,150
light for microcontrollers is that

00:11:40,810 --> 00:11:45,070
effort it uses the same model format the

00:11:43,150 --> 00:11:47,460
same conversion pipeline and largely the

00:11:45,070 --> 00:11:50,260
same kernel library as tensorflow light

00:11:47,460 --> 00:11:52,060
so what are these microcontrollers these

00:11:50,260 --> 00:11:54,580
are the small low-power all-in-one

00:11:52,060 --> 00:11:56,410
computer computers that power everyday

00:11:54,580 --> 00:12:00,040
device is all around us from microwaves

00:11:56,410 --> 00:12:01,660
smoke detectors to sensors and toys it

00:12:00,040 --> 00:12:03,490
can cost as little as 10 cents each and

00:12:01,660 --> 00:12:06,640
with tensorflow it's possible to use

00:12:03,490 --> 00:12:08,290
them for machine learning arm an

00:12:06,640 --> 00:12:10,210
industry leader in the embedded market

00:12:08,290 --> 00:12:12,970
has adopted tensorflow as their official

00:12:10,210 --> 00:12:14,980
solution for AI on arm microcontrollers

00:12:12,970 --> 00:12:16,600
and together we've made optimizations

00:12:14,980 --> 00:12:19,960
that significantly improve performance

00:12:16,600 --> 00:12:21,820
on this embedded arm hardware we've also

00:12:19,960 --> 00:12:23,560
partnered partnered with Arduino and

00:12:21,820 --> 00:12:25,330
just launched the official Arduino

00:12:23,560 --> 00:12:26,770
tensorflow library this makes it

00:12:25,330 --> 00:12:28,870
possible for you to get started doing

00:12:26,770 --> 00:12:30,960
speech detection on Arduino Hardware in

00:12:28,870 --> 00:12:33,340
just under 5 minutes

00:12:30,960 --> 00:12:34,870
and now we'd like to demonstrate tents

00:12:33,340 --> 00:12:37,750
for lights microcontrollers running in

00:12:34,870 --> 00:12:39,910
production today if a motor breaks down

00:12:37,750 --> 00:12:41,800
it can cause expensive downtime and

00:12:39,910 --> 00:12:44,110
maintenance costs but using tensorflow

00:12:41,800 --> 00:12:45,850
it's possible to simply and affordably

00:12:44,110 --> 00:12:49,450
detect these problems before failure

00:12:45,850 --> 00:12:52,120
dramatically reducing these costs mark

00:12:49,450 --> 00:12:53,680
Stubbs co-founder of shoreline IOT will

00:12:52,120 --> 00:12:54,310
now give us a demo of how they're using

00:12:53,680 --> 00:12:58,360
tensorflow

00:12:54,310 --> 00:12:59,860
to address this problem they've

00:12:58,360 --> 00:13:02,380
developed a sensor that can be attached

00:12:59,860 --> 00:13:04,780
to a motor just like a sticker it uses a

00:13:02,380 --> 00:13:07,180
low-power always-on tensorflow model to

00:13:04,780 --> 00:13:08,890
detect motor anomalies and with this

00:13:07,180 --> 00:13:11,110
model their device can run for up to

00:13:08,890 --> 00:13:13,930
five years on a single small battery

00:13:11,110 --> 00:13:18,220
using just 45 micro amps with its cortex

00:13:13,930 --> 00:13:20,050
ambach cortex m4 CPU so here we have a

00:13:18,220 --> 00:13:22,630
motor that will simulate an anomaly as

00:13:20,050 --> 00:13:24,640
the RPMs increase you'll start to

00:13:22,630 --> 00:13:26,710
vibrate and shake and the tensorflow

00:13:24,640 --> 00:13:30,130
model should detect this as a fault and

00:13:26,710 --> 00:13:36,340
indicate so with a red LED all right

00:13:30,130 --> 00:13:38,920
mark let's start the motor okay so here

00:13:36,340 --> 00:13:40,510
we have a normal state and you can see

00:13:38,920 --> 00:13:41,980
this it's being detected with the green

00:13:40,510 --> 00:13:45,850
LED everything's fine

00:13:41,980 --> 00:13:47,890
let's crank it up okay it's starting to

00:13:45,850 --> 00:13:48,700
vibrate it's oscillating I'm getting a

00:13:47,890 --> 00:13:50,890
little nervous

00:13:48,700 --> 00:13:52,600
and frankly a little sweaty red light

00:13:50,890 --> 00:13:53,920
boom okay

00:13:52,600 --> 00:13:55,960
the tents flow model detected the

00:13:53,920 --> 00:13:57,160
anomaly we could shut it down Halloween

00:13:55,960 --> 00:14:00,180
disaster averted

00:13:57,160 --> 00:14:00,180
thank you Mark

00:14:03,050 --> 00:14:07,140
that's all we have folks please try out

00:14:05,550 --> 00:14:09,300
tensorflow light if you haven't already

00:14:07,140 --> 00:14:10,920
and once again we are very thankful for

00:14:09,300 --> 00:14:12,899
the contributions that we get from our

00:14:10,920 --> 00:14:14,940
community we also have a longer talk

00:14:12,899 --> 00:14:18,410
later today we have a demo booth please

00:14:14,940 --> 00:14:18,410

YouTube URL: https://www.youtube.com/watch?v=zjDGAiLqGk8


