Title: MLIR: Accelerating AI - Chris Lattner and Tatiana Shpeisman
Publication date: 2019-11-01
Playlist: TensorFlow World 2019
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:02,460 --> 00:00:09,030
hi I'm Tatiana and I'm going to talk

00:00:05,850 --> 00:00:11,400
today about am a liar before we talk

00:00:09,030 --> 00:00:14,880
about the Millea let's start from the

00:00:11,400 --> 00:00:17,609
basics we are here because artificial

00:00:14,880 --> 00:00:20,060
intelligence is experience a tremendous

00:00:17,609 --> 00:00:23,039
growth all the three components

00:00:20,060 --> 00:00:27,619
algorithms data compute have come

00:00:23,039 --> 00:00:30,180
together to change the world compute is

00:00:27,619 --> 00:00:31,980
really really important because that's

00:00:30,180 --> 00:00:34,410
what enables machine learning

00:00:31,980 --> 00:00:37,200
researchers to build better algorithms

00:00:34,410 --> 00:00:39,720
to build new models and this you can see

00:00:37,200 --> 00:00:42,329
the models are becoming much much more

00:00:39,720 --> 00:00:44,489
complex to train a model today we need

00:00:42,329 --> 00:00:46,980
several orders of magnitude compute

00:00:44,489 --> 00:00:50,850
capabilities then we needed several here

00:00:46,980 --> 00:00:52,860
as a go and how do we build hardware

00:00:50,850 --> 00:00:55,410
which makes that possible

00:00:52,860 --> 00:00:58,469
for those of you who were stand guard

00:00:55,410 --> 00:01:01,110
we're at details more lore is and then

00:00:58,469 --> 00:01:04,949
this is also the knock end of the nerd

00:01:01,110 --> 00:01:06,780
scaling we can its anymore simply to say

00:01:04,949 --> 00:01:09,630
the next CPU is gonna run at high

00:01:06,780 --> 00:01:11,400
frequency and because of that that will

00:01:09,630 --> 00:01:14,190
power a machine learning what is

00:01:11,400 --> 00:01:17,130
happening in the industry is the

00:01:14,190 --> 00:01:19,680
explosion of custom hardware and there

00:01:17,130 --> 00:01:21,659
is a lot of innovation which is driving

00:01:19,680 --> 00:01:25,080
this compute which makes artificial

00:01:21,659 --> 00:01:27,869
intelligence possible so if we look at

00:01:25,080 --> 00:01:30,960
what is happenin you look in your pocket

00:01:27,869 --> 00:01:34,320
you probably have cell phone inside that

00:01:30,960 --> 00:01:36,869
cell phone most likely there is a little

00:01:34,320 --> 00:01:40,320
chip which makes artificial intelligence

00:01:36,869 --> 00:01:43,680
possible and it's not just one chip

00:01:40,320 --> 00:01:46,710
right there is CPU there is GPU there is

00:01:43,680 --> 00:01:49,170
DSP there is neural processing unit all

00:01:46,710 --> 00:01:51,990
of that is sitting inside a little phone

00:01:49,170 --> 00:01:55,710
and seamlessly working together to make

00:01:51,990 --> 00:01:58,649
great user experience possible in the

00:01:55,710 --> 00:02:01,549
data center we see the explosion of

00:01:58,649 --> 00:02:05,280
specialized hardware also

00:02:01,549 --> 00:02:09,060
Habana specialized accelerations and

00:02:05,280 --> 00:02:13,290
CPUs and GPUs many different chips

00:02:09,060 --> 00:02:16,170
we have CPUs all of this is powering the

00:02:13,290 --> 00:02:20,550
tremendous growth of specialized compute

00:02:16,170 --> 00:02:22,200
in data centers and once you have more

00:02:20,550 --> 00:02:25,380
specialized accelerators that brings

00:02:22,200 --> 00:02:28,260
more complexity and as we all know

00:02:25,380 --> 00:02:30,900
Hardware doesn't work by itself it is

00:02:28,260 --> 00:02:33,090
powered by software and so there is also

00:02:30,900 --> 00:02:35,880
a tremendous growth in software

00:02:33,090 --> 00:02:37,170
ecosystems for machine learning in

00:02:35,880 --> 00:02:38,819
addition to tensorflow

00:02:37,170 --> 00:02:40,860
there are many other different

00:02:38,819 --> 00:02:45,840
frameworks which are trying to solve

00:02:40,860 --> 00:02:48,269
this problem and actually we got a

00:02:45,840 --> 00:02:52,080
problem with the explosive growth of

00:02:48,269 --> 00:02:53,970
hardware and software so the big problem

00:02:52,080 --> 00:02:55,830
here is that none of the scales too much

00:02:53,970 --> 00:02:57,569
Hardware too much complexity too much

00:02:55,830 --> 00:02:59,610
software too many different systems that

00:02:57,569 --> 00:03:01,230
are not working together and what's the

00:02:59,610 --> 00:03:03,030
fundamental problem the fundamental

00:03:01,230 --> 00:03:04,680
problem is that we as a technology

00:03:03,030 --> 00:03:07,200
industry across the board are

00:03:04,680 --> 00:03:08,880
reinventing the same kinds of tools the

00:03:07,200 --> 00:03:11,489
same kinds of technologies and we're not

00:03:08,880 --> 00:03:12,840
working together and this is why you see

00:03:11,489 --> 00:03:14,700
the consequences of this

00:03:12,840 --> 00:03:16,200
you see systems that don't interoperate

00:03:14,700 --> 00:03:17,430
because they're built by different

00:03:16,200 --> 00:03:20,190
people and different teams to solve

00:03:17,430 --> 00:03:21,720
different problems no vendor X is

00:03:20,190 --> 00:03:23,549
working on their chip which makes

00:03:21,720 --> 00:03:24,540
perfect sense and doesn't really

00:03:23,549 --> 00:03:26,310
integrate with all the different

00:03:24,540 --> 00:03:28,079
software and likewise for the software

00:03:26,310 --> 00:03:30,600
people that can't know or work with all

00:03:28,079 --> 00:03:31,980
the hardware people this is why you see

00:03:30,600 --> 00:03:33,060
things like you bring up your model you

00:03:31,980 --> 00:03:34,410
try to get to work on a new piece of

00:03:33,060 --> 00:03:36,810
hardware it doesn't work right the first

00:03:34,410 --> 00:03:38,700
time you see this in the cracks that

00:03:36,810 --> 00:03:40,620
form between these systems and that

00:03:38,700 --> 00:03:42,480
manifests as usability problems or

00:03:40,620 --> 00:03:45,269
performance problems or debug ability

00:03:42,480 --> 00:03:47,359
problems and as a user this is not

00:03:45,269 --> 00:03:50,910
something you should have to deal with

00:03:47,359 --> 00:03:54,120
so what do we want what we'd really love

00:03:50,910 --> 00:03:56,010
to do is take this big problem which has

00:03:54,120 --> 00:03:58,109
many different pieces and make it

00:03:56,010 --> 00:04:00,630
simpler by getting people to work

00:03:58,109 --> 00:04:02,700
together and so we've thought a lot

00:04:00,630 --> 00:04:04,410
about this and the way we think we think

00:04:02,700 --> 00:04:06,060
that we can move the world forward is

00:04:04,410 --> 00:04:08,400
not by saying that there is one right

00:04:06,060 --> 00:04:10,260
way to do things I don't think that

00:04:08,400 --> 00:04:12,420
works in a field that's as growing as

00:04:10,260 --> 00:04:14,130
explosively as machine learning instead

00:04:12,420 --> 00:04:16,500
what we think the right way to get to do

00:04:14,130 --> 00:04:19,739
this is is to introduce building blocks

00:04:16,500 --> 00:04:21,510
and instead of standardizing these are

00:04:19,739 --> 00:04:23,970
experienced or standardizing the one

00:04:21,510 --> 00:04:25,500
right way to do machine learning we

00:04:23,970 --> 00:04:27,330
think that we as a technology industry

00:04:25,500 --> 00:04:28,550
can standardize some of the underlying

00:04:27,330 --> 00:04:31,400
building block

00:04:28,550 --> 00:04:32,960
that go into these tools that can go

00:04:31,400 --> 00:04:34,819
into the compiler for a specific chip

00:04:32,960 --> 00:04:36,530
that can go into a translator that it

00:04:34,819 --> 00:04:39,349
works between one system or the other

00:04:36,530 --> 00:04:41,000
and if we build building blocks we know

00:04:39,349 --> 00:04:43,009
and we can think about what we want from

00:04:41,000 --> 00:04:46,039
them we want of course the best-in-class

00:04:43,009 --> 00:04:47,419
graph technology that's that's a given

00:04:46,039 --> 00:04:49,729
we want the best compiler technology

00:04:47,419 --> 00:04:51,770
compilers are really important we want

00:04:49,729 --> 00:04:54,770
to solve not just training but also

00:04:51,770 --> 00:04:57,139
inference mobile and servers in

00:04:54,770 --> 00:04:58,970
including all permutations so training

00:04:57,139 --> 00:05:02,000
on the edge super important growing

00:04:58,970 --> 00:05:03,740
growing growing in popularity we don't

00:05:02,000 --> 00:05:06,949
want this to be a new kind of technology

00:05:03,740 --> 00:05:10,039
Island solution we want this to be part

00:05:06,949 --> 00:05:12,919
of a continuous ecosystem that spans the

00:05:10,039 --> 00:05:15,800
whole problem and so this is what my are

00:05:12,919 --> 00:05:17,870
is all about and wires a new system that

00:05:15,800 --> 00:05:20,330
we wait Google have been building but we

00:05:17,870 --> 00:05:22,729
are bringing to the industry to help

00:05:20,330 --> 00:05:25,819
solve some of these common problems that

00:05:22,729 --> 00:05:27,050
that manifest in different ways and so

00:05:25,819 --> 00:05:29,419
one of the things that we're really

00:05:27,050 --> 00:05:32,449
excited about is the N layer is not just

00:05:29,419 --> 00:05:34,729
a Google technology we are collaborating

00:05:32,449 --> 00:05:36,259
extensively with hardware makers across

00:05:34,729 --> 00:05:38,030
the industry and we're seeing a lot of

00:05:36,259 --> 00:05:39,830
excitement and a lot of adoption by

00:05:38,030 --> 00:05:42,620
people that are building the world's

00:05:39,830 --> 00:05:45,380
biggest and most popular hardware across

00:05:42,620 --> 00:05:48,280
across the world but what is MLR

00:05:45,380 --> 00:05:50,960
well so MLR is a compiler infrastructure

00:05:48,280 --> 00:05:52,639
and if you're not familiar with

00:05:50,960 --> 00:05:54,199
compilers what it's really saying is

00:05:52,639 --> 00:05:56,300
it's saying that it is providing that

00:05:54,199 --> 00:05:58,639
bottom level technology low-level

00:05:56,300 --> 00:06:01,099
technology that underpins building

00:05:58,639 --> 00:06:03,289
individual tools and individual systems

00:06:01,099 --> 00:06:05,330
that then get used to help with graphs

00:06:03,289 --> 00:06:08,539
and help with chips and things like that

00:06:05,330 --> 00:06:10,370
and so how does this work well what and

00:06:08,539 --> 00:06:12,710
why provides if you look at it in

00:06:10,370 --> 00:06:15,830
contrast to other systems is that it is

00:06:12,710 --> 00:06:17,990
not again a one size fits none kind of a

00:06:15,830 --> 00:06:20,599
solution it's trying to be technology

00:06:17,990 --> 00:06:23,240
technology the powers these systems and

00:06:20,599 --> 00:06:25,009
so like we said before it of course

00:06:23,240 --> 00:06:28,009
contains the state-of-the-art compiler

00:06:25,009 --> 00:06:29,630
technology we have both within Google we

00:06:28,009 --> 00:06:31,039
have dozens of years of compiler

00:06:29,630 --> 00:06:32,240
experience within the team but we

00:06:31,039 --> 00:06:34,250
probably have hundreds of years of

00:06:32,240 --> 00:06:35,539
compiler experience across the industry

00:06:34,250 --> 00:06:37,699
all collaborating together on this

00:06:35,539 --> 00:06:39,500
common platform it is designed to be

00:06:37,699 --> 00:06:41,270
modular and extensible because

00:06:39,500 --> 00:06:42,230
requirements continue to change in our

00:06:41,270 --> 00:06:44,090
field

00:06:42,230 --> 00:06:45,620
it's not designed to tell you the right

00:06:44,090 --> 00:06:47,540
way to do things as a system integrator

00:06:45,620 --> 00:06:50,720
it's designed to provide tools so that

00:06:47,540 --> 00:06:52,160
you can solve your problems now if you

00:06:50,720 --> 00:06:53,750
dive into the compiler there's a whole

00:06:52,160 --> 00:06:56,480
bunch of different pieces and so there

00:06:53,750 --> 00:06:58,820
are things like you know low-level graph

00:06:56,480 --> 00:07:00,290
transformation systems there are things

00:06:58,820 --> 00:07:01,640
for code generation so that if you're

00:07:00,290 --> 00:07:03,860
building a chip you can handle like

00:07:01,640 --> 00:07:05,810
picking the right colonel but the point

00:07:03,860 --> 00:07:07,820
of this is the MLR does not force you to

00:07:05,810 --> 00:07:09,440
use one common pipeline it turns out

00:07:07,820 --> 00:07:11,180
that while compilers for code generation

00:07:09,440 --> 00:07:13,340
are really great so are handwritten

00:07:11,180 --> 00:07:14,630
kernels if you have handwritten kernels

00:07:13,340 --> 00:07:16,040
they're tuned and optimized for your

00:07:14,630 --> 00:07:17,690
application of course they should saw it

00:07:16,040 --> 00:07:19,580
into the same framework it should work

00:07:17,690 --> 00:07:21,770
with existing runtimes and we'd really

00:07:19,580 --> 00:07:23,930
see MLR as providing useful value that

00:07:21,770 --> 00:07:25,820
then can be used to solve problems it is

00:07:23,930 --> 00:07:28,850
not trying to force everything into one

00:07:25,820 --> 00:07:30,380
box so you may be wondering though free

00:07:28,850 --> 00:07:32,630
if you're not a compiler person or a

00:07:30,380 --> 00:07:34,430
system integrator or a chip person what

00:07:32,630 --> 00:07:37,360
does this mean to you and so let's talk

00:07:34,430 --> 00:07:41,930
about what it means for tensorflow

00:07:37,360 --> 00:07:43,930
so what it means photons of flow is it

00:07:41,930 --> 00:07:47,630
allows us to build a better system

00:07:43,930 --> 00:07:49,940
because integrate and tenza flow with

00:07:47,630 --> 00:07:53,120
the myriad of specialized hardware is

00:07:49,940 --> 00:07:55,970
really a hard problem and with Emily are

00:07:53,120 --> 00:07:58,520
we can build a unified infrastructure

00:07:55,970 --> 00:07:59,300
layer which will make it much simpler

00:07:58,520 --> 00:08:02,510
for tensorflow

00:07:59,300 --> 00:08:06,530
to seamlessly work with any hardware

00:08:02,510 --> 00:08:09,800
chip which comes out for you as a Python

00:08:06,530 --> 00:08:13,040
developer it simply means better

00:08:09,800 --> 00:08:15,140
developed developer experiences a lot of

00:08:13,040 --> 00:08:19,040
things that today might be not working

00:08:15,140 --> 00:08:22,280
as smoothly as we would like them to can

00:08:19,040 --> 00:08:25,100
be it is a result by am a liar and so

00:08:22,280 --> 00:08:28,400
this is just one example you write a

00:08:25,100 --> 00:08:30,410
model you try to run it through the tens

00:08:28,400 --> 00:08:32,840
of float in the flow light converter you

00:08:30,410 --> 00:08:35,240
get an error you have no clue what it is

00:08:32,840 --> 00:08:38,180
and now we see issues and get hop and

00:08:35,240 --> 00:08:40,160
try to help you with Amala are you will

00:08:38,180 --> 00:08:43,340
get an error message that says this is

00:08:40,160 --> 00:08:45,980
the line of Python code which caused the

00:08:43,340 --> 00:08:49,570
problem you can look at it and fix the

00:08:45,980 --> 00:08:52,910
problem yourself and just to summarize

00:08:49,570 --> 00:08:55,730
the reason we are build an ml ir is

00:08:52,910 --> 00:08:57,829
because we want to move faster

00:08:55,730 --> 00:09:01,760
we want the industry to move faster with

00:08:57,829 --> 00:09:02,990
us and one of the keys to make industry

00:09:01,760 --> 00:09:06,880
work well together

00:09:02,990 --> 00:09:10,010
is neutral governance and that's why we

00:09:06,880 --> 00:09:13,430
submitted a male are as a project to

00:09:10,010 --> 00:09:16,850
LLVM and now it is part of all of the

00:09:13,430 --> 00:09:19,730
Amika system the code is moving soon and

00:09:16,850 --> 00:09:22,250
this is very important because alluvium

00:09:19,730 --> 00:09:23,660
has a 20 year history of neutral

00:09:22,250 --> 00:09:25,399
governance and building the

00:09:23,660 --> 00:09:30,110
infrastructure which is used by

00:09:25,399 --> 00:09:31,220
everybody in the world and this is just

00:09:30,110 --> 00:09:33,949
the beginning

00:09:31,220 --> 00:09:36,410
please stay tuned we are building a

00:09:33,949 --> 00:09:39,920
global community around the Millea are

00:09:36,410 --> 00:09:43,839
and once we are done ml will be better

00:09:39,920 --> 00:09:45,860
for everybody and we will see much

00:09:43,839 --> 00:09:54,790
faster advance of artificial

00:09:45,860 --> 00:09:54,790

YouTube URL: https://www.youtube.com/watch?v=QYV0Se167hM


