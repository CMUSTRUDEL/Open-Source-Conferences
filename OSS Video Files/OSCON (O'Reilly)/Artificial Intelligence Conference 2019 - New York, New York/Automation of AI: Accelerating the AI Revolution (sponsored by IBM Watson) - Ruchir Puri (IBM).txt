Title: Automation of AI: Accelerating the AI Revolution (sponsored by IBM Watson) - Ruchir Puri (IBM)
Publication date: 2019-04-18
Playlist: Artificial Intelligence Conference 2019 - New York, New York
Description: 
	View more keynotes and sessions from AI NY 2019:
https://oreilly.com/go/ainy19

Ruchir Puri discusses the next revolution in automating AI, which strives to deploy AI to automate the task of building, deploying, and managing AI tasks, accelerating enterprises' journey to AI.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,179 --> 00:00:06,870
I really wanted to actually really hit

00:00:03,480 --> 00:00:09,809
the next generation of what is coming

00:00:06,870 --> 00:00:13,320
down the I pipe line we have actually

00:00:09,809 --> 00:00:16,320
seen really massive adoption as well as

00:00:13,320 --> 00:00:18,300
we move forward but more importantly on

00:00:16,320 --> 00:00:19,949
the horizon we are seeing an anomaly and

00:00:18,300 --> 00:00:21,689
I'm gonna talk about that anomaly I'm

00:00:19,949 --> 00:00:23,699
gonna talk about how we are addressing

00:00:21,689 --> 00:00:26,640
it and what is there in the future

00:00:23,699 --> 00:00:29,279
for AI so let's really talk about you

00:00:26,640 --> 00:00:31,439
know what does it incorporate to be

00:00:29,279 --> 00:00:33,420
really a data scientist what skills does

00:00:31,439 --> 00:00:36,270
it take and I think this this Venn

00:00:33,420 --> 00:00:37,890
diagram depicts it perfectly if you

00:00:36,270 --> 00:00:39,600
really look at machine learning it's at

00:00:37,890 --> 00:00:42,000
the intersection of computer science and

00:00:39,600 --> 00:00:44,670
coding and and mathematics and

00:00:42,000 --> 00:00:46,739
statistics if you look at application

00:00:44,670 --> 00:00:48,780
software it is at the intersection of

00:00:46,739 --> 00:00:51,000
computer science and coding and domain

00:00:48,780 --> 00:00:53,070
knowledge and if you really look at

00:00:51,000 --> 00:00:55,350
research it's at the intersection of

00:00:53,070 --> 00:00:57,870
mathematics and statistics and domain

00:00:55,350 --> 00:00:59,850
knowledge in itself and data science is

00:00:57,870 --> 00:01:01,500
a perfect combination of all of these

00:00:59,850 --> 00:01:03,750
three which is machine learning

00:01:01,500 --> 00:01:06,600
application software and traditional

00:01:03,750 --> 00:01:09,150
research now really short of scaling the

00:01:06,600 --> 00:01:12,299
training of individuals in all of these

00:01:09,150 --> 00:01:15,150
three dimensions good data sight science

00:01:12,299 --> 00:01:18,509
skills are very hard to scale in fact

00:01:15,150 --> 00:01:20,340
many of you know good data science

00:01:18,509 --> 00:01:22,950
skills cost upwards of half a million

00:01:20,340 --> 00:01:26,189
dollars in many of the geographies where

00:01:22,950 --> 00:01:28,829
the demand is very high the only viable

00:01:26,189 --> 00:01:31,259
solution is to replace one or more of

00:01:28,829 --> 00:01:33,390
these quadrants with automation anytime

00:01:31,259 --> 00:01:35,009
such anomalies happen where there's a

00:01:33,390 --> 00:01:36,960
large queue between demand and supply

00:01:35,009 --> 00:01:39,420
there is actually a large space for

00:01:36,960 --> 00:01:42,630
automation and in fact I'm here to argue

00:01:39,420 --> 00:01:45,479
and show you that AI itself can be

00:01:42,630 --> 00:01:47,579
automated by multiple ways and I will

00:01:45,479 --> 00:01:49,560
demonstrate to you what capabilities we

00:01:47,579 --> 00:01:51,960
are building at IBM and what the future

00:01:49,560 --> 00:01:54,990
will look like and the future is there

00:01:51,960 --> 00:01:56,700
today so automating true domain

00:01:54,990 --> 00:01:58,920
knowledge is the one which is the

00:01:56,700 --> 00:02:01,439
hardest to acclimate so I'm gonna leave

00:01:58,920 --> 00:02:03,930
that as a fundamental platform that

00:02:01,439 --> 00:02:05,909
really people should focus on the domain

00:02:03,930 --> 00:02:08,129
knowledge which is the hardest one to

00:02:05,909 --> 00:02:10,200
automate algorithms can be automated

00:02:08,129 --> 00:02:12,150
techniques can be automated but domain

00:02:10,200 --> 00:02:13,240
knowledge is the one which is we as

00:02:12,150 --> 00:02:15,520
humans really

00:02:13,240 --> 00:02:18,100
bring to the table and an automation can

00:02:15,520 --> 00:02:20,800
be built above it industry domain is

00:02:18,100 --> 00:02:23,410
where eventual realization of the AI

00:02:20,800 --> 00:02:25,360
value really happens so we'll really

00:02:23,410 --> 00:02:28,810
focus on that one from point of your

00:02:25,360 --> 00:02:32,470
value-add now this is really the demand

00:02:28,810 --> 00:02:34,930
curve as you can see in 2018 machine

00:02:32,470 --> 00:02:38,770
learning saw roughly 12x

00:02:34,930 --> 00:02:40,150
actly increase in the demand obviously

00:02:38,770 --> 00:02:43,540
machine learning engineers in the

00:02:40,150 --> 00:02:47,170
LinkedIn jobs report in 2017 saw around

00:02:43,540 --> 00:02:49,990
10x increase and AI skills are quickly

00:02:47,170 --> 00:02:52,960
spreading beyond just the tech industry

00:02:49,990 --> 00:02:58,000
to every industry that you see every CEO

00:02:52,960 --> 00:02:59,940
and CIO has AI in their spare G this is

00:02:58,000 --> 00:03:03,370
really the supply side of the dynamics

00:02:59,940 --> 00:03:05,620
on the x-axis is the hardness to fill on

00:03:03,370 --> 00:03:07,270
the y-axis is the projected growth and

00:03:05,620 --> 00:03:10,300
if you are in the upper right hand side

00:03:07,270 --> 00:03:11,830
of this quadrant you have a problem the

00:03:10,300 --> 00:03:13,960
problem is actually called the supply

00:03:11,830 --> 00:03:16,180
side of the problem so we saw the demand

00:03:13,960 --> 00:03:19,300
side we saw the supply side and there is

00:03:16,180 --> 00:03:21,550
a large gap between the two there's

00:03:19,300 --> 00:03:23,290
another gap building up as well which is

00:03:21,550 --> 00:03:25,930
really AI workflows are becoming

00:03:23,290 --> 00:03:28,660
increasing increasingly bigger and lot

00:03:25,930 --> 00:03:30,640
more complicated so from down to

00:03:28,660 --> 00:03:32,860
gathering to data cleaning to feature

00:03:30,640 --> 00:03:35,380
engineering which is really complicated

00:03:32,860 --> 00:03:37,780
and I would say almost magic from a data

00:03:35,380 --> 00:03:40,330
science point of view model selection to

00:03:37,780 --> 00:03:42,210
parameter optimization to to rename and

00:03:40,330 --> 00:03:45,340
sample building to model validation

00:03:42,210 --> 00:03:48,100
model deployment and on and on and that

00:03:45,340 --> 00:03:49,840
circle keeps on going and the time spent

00:03:48,100 --> 00:03:52,900
on many of these steps is really

00:03:49,840 --> 00:03:55,870
increasing as well so what do we need to

00:03:52,900 --> 00:03:58,000
do we really need to combine the upper

00:03:55,870 --> 00:03:59,620
two circles which is around computer

00:03:58,000 --> 00:04:01,150
science and coding machine learning

00:03:59,620 --> 00:04:02,950
mathematics and statistics

00:04:01,150 --> 00:04:05,470
application software traditional

00:04:02,950 --> 00:04:08,470
research into one which I'll describe it

00:04:05,470 --> 00:04:09,970
as automation of AI or Auto AI itself so

00:04:08,470 --> 00:04:13,150
automated machine learning and data

00:04:09,970 --> 00:04:15,340
engineering really and being fed by the

00:04:13,150 --> 00:04:17,320
domain knowledge that data scientists

00:04:15,340 --> 00:04:19,480
and and SMEs really bring to the table

00:04:17,320 --> 00:04:21,880
and that really is what the future is

00:04:19,480 --> 00:04:23,290
going to look like so there are three

00:04:21,880 --> 00:04:25,120
main things which I'm going to

00:04:23,290 --> 00:04:26,889
demonstrate to you hopefully that will

00:04:25,120 --> 00:04:30,400
convince you that the future is a

00:04:26,889 --> 00:04:33,310
we there today number one it's

00:04:30,400 --> 00:04:36,250
automation is actually automating the AI

00:04:33,310 --> 00:04:39,069
we can leverage AI itself to automate a

00:04:36,250 --> 00:04:41,259
re so number one is AI designing a I

00:04:39,069 --> 00:04:44,500
we're gonna take a look at example there

00:04:41,259 --> 00:04:45,789
number two yeah I opted amaizing AI and

00:04:44,500 --> 00:04:48,669
number three

00:04:45,789 --> 00:04:50,080
ai correcting AI so those are the three

00:04:48,669 --> 00:04:52,509
main things we're gonna take a look at

00:04:50,080 --> 00:04:55,000
today and see where we really what the

00:04:52,509 --> 00:04:58,180
future looks like so first one ai

00:04:55,000 --> 00:04:59,710
designing a I highly skilled researchers

00:04:58,180 --> 00:05:01,629
data scientists are needed to really

00:04:59,710 --> 00:05:05,139
handcraft the latest and the greatest of

00:05:01,629 --> 00:05:08,080
AI handcraft and complex neural networks

00:05:05,139 --> 00:05:10,029
is a time-consuming task error-prone and

00:05:08,080 --> 00:05:12,340
does not scale with time and resources

00:05:10,029 --> 00:05:15,099
we all know this these barrier to

00:05:12,340 --> 00:05:17,110
entries are very high neural networks

00:05:15,099 --> 00:05:19,330
also continue to grow in size and

00:05:17,110 --> 00:05:21,490
complexity as shown in the left hand

00:05:19,330 --> 00:05:22,960
side of the of the diagram here and on

00:05:21,490 --> 00:05:25,750
the right hand side as well and that

00:05:22,960 --> 00:05:28,270
evolution is continuing on a very fast

00:05:25,750 --> 00:05:29,830
basis as it is evident from literally

00:05:28,270 --> 00:05:31,690
tens and thousands of papers published

00:05:29,830 --> 00:05:34,599
in conferences that you are well aware

00:05:31,690 --> 00:05:36,099
of so what what have we done we have

00:05:34,599 --> 00:05:38,800
actually released a capability that's

00:05:36,099 --> 00:05:40,599
available online for you to try it's

00:05:38,800 --> 00:05:43,479
called new nets which is part of Watson

00:05:40,599 --> 00:05:45,250
open scale it's a new AI engine for new

00:05:43,479 --> 00:05:48,310
network design that automatically

00:05:45,250 --> 00:05:51,969
synthesizes new neural network models or

00:05:48,310 --> 00:05:53,830
evolves and improves existing ones how

00:05:51,969 --> 00:05:55,569
does it really work it automatically

00:05:53,830 --> 00:05:58,150
generates the optimal neural network for

00:05:55,569 --> 00:06:00,969
a given training data without any coding

00:05:58,150 --> 00:06:02,860
required so I'll emphasize again it is

00:06:00,969 --> 00:06:04,089
not about we have like hundred neural

00:06:02,860 --> 00:06:05,979
networks and we go and take your

00:06:04,089 --> 00:06:08,199
training data and map it to one of them

00:06:05,979 --> 00:06:12,069
we really design the neural networks

00:06:08,199 --> 00:06:14,050
from scratch built customized to them to

00:06:12,069 --> 00:06:16,020
that data that you provide us and I'm

00:06:14,050 --> 00:06:18,219
going to show you a demo of it as well

00:06:16,020 --> 00:06:20,560
so that what kind of results are we

00:06:18,219 --> 00:06:23,550
getting on the extreme right hand side

00:06:20,560 --> 00:06:26,020
column I'm showing best hand-tuned

00:06:23,550 --> 00:06:28,719
neural networks designed for certain

00:06:26,020 --> 00:06:31,029
well-known benchmarks M nest is what

00:06:28,719 --> 00:06:32,229
I'll call a a pipe cleaner but there are

00:06:31,029 --> 00:06:34,089
others that get increasingly more

00:06:32,229 --> 00:06:36,550
complicated and we have several

00:06:34,089 --> 00:06:40,149
optimizers available as part of this

00:06:36,550 --> 00:06:40,630
this engine some of them actually match

00:06:40,149 --> 00:06:42,220
well to

00:06:40,630 --> 00:06:44,980
certain datasets and others match well

00:06:42,220 --> 00:06:47,250
to other datasets and as you can see we

00:06:44,980 --> 00:06:50,830
are actually in many cases either

00:06:47,250 --> 00:06:52,720
increasing either exceeding the accuracy

00:06:50,830 --> 00:06:54,640
of hand-designed networks or really

00:06:52,720 --> 00:06:56,680
meeting it so we are pretty much in the

00:06:54,640 --> 00:06:59,710
ballpark with respect to human design

00:06:56,680 --> 00:07:02,830
networks most importantly we can do this

00:06:59,710 --> 00:07:04,300
literally in over write runs as opposed

00:07:02,830 --> 00:07:06,370
to months it might take from data

00:07:04,300 --> 00:07:09,790
scientists point of view and we can do

00:07:06,370 --> 00:07:12,130
this in in roughly 1 GPU one to two GPUs

00:07:09,790 --> 00:07:13,930
as opposed to thousands of GPUs that

00:07:12,130 --> 00:07:15,730
might have been used before actually so

00:07:13,930 --> 00:07:17,770
this is not about exhaustive search it's

00:07:15,730 --> 00:07:19,120
really about being smarter so I'm going

00:07:17,770 --> 00:07:22,240
to show you a demo that you got to look

00:07:19,120 --> 00:07:23,920
and what you will see is so what you

00:07:22,240 --> 00:07:25,360
really are seeing is a compressed

00:07:23,920 --> 00:07:27,280
version of a run because this was the

00:07:25,360 --> 00:07:29,320
overnight run it's really a vehicle

00:07:27,280 --> 00:07:31,180
repair estimator neural network model

00:07:29,320 --> 00:07:33,400
being built you see that accuracy

00:07:31,180 --> 00:07:35,590
increasing on the left hand side this

00:07:33,400 --> 00:07:37,600
what you see in the network being design

00:07:35,590 --> 00:07:39,910
it's actually really going through

00:07:37,600 --> 00:07:41,980
thousands of data points so use the one

00:07:39,910 --> 00:07:45,130
that you see right at the at the bottom

00:07:41,980 --> 00:07:47,470
upper lower right hand side is many many

00:07:45,130 --> 00:07:49,540
designs that the that the optimizer or

00:07:47,470 --> 00:07:51,430
the engine called new nets is choosing

00:07:49,540 --> 00:07:53,920
and really giving trying to give you the

00:07:51,430 --> 00:07:55,630
optimal design possible all within an

00:07:53,920 --> 00:07:58,240
overnight run what you really do is

00:07:55,630 --> 00:08:00,580
upload your data and really let the let

00:07:58,240 --> 00:08:03,310
the tool do the task and finally you end

00:08:00,580 --> 00:08:06,100
up with roughly an accuracy of 93% or

00:08:03,310 --> 00:08:07,900
slightly upward of 93% and this is again

00:08:06,100 --> 00:08:09,940
it's almost like look ma no hands

00:08:07,900 --> 00:08:12,640
actually so that's really the level that

00:08:09,940 --> 00:08:14,860
we are driving that automation to and it

00:08:12,640 --> 00:08:17,290
can start from an existing design or it

00:08:14,860 --> 00:08:19,690
can really start from a from a totally

00:08:17,290 --> 00:08:23,050
scratch new design as well second one I

00:08:19,690 --> 00:08:26,320
would say is really AI optimizing AI one

00:08:23,050 --> 00:08:28,300
of the key parts of of data science is

00:08:26,320 --> 00:08:29,830
really feature engineering as many of

00:08:28,300 --> 00:08:31,870
the experts in the field have said as

00:08:29,830 --> 00:08:35,110
well it's really one of the voodoo magic

00:08:31,870 --> 00:08:36,789
parts of AI what we really have done is

00:08:35,110 --> 00:08:38,860
so you really start from original data

00:08:36,789 --> 00:08:40,870
the data scientist sits in the middle

00:08:38,860 --> 00:08:42,310
you really look at you know what has the

00:08:40,870 --> 00:08:45,490
functions through which I can combine

00:08:42,310 --> 00:08:48,580
many of the features in my data you

00:08:45,490 --> 00:08:50,890
really go through transform that data in

00:08:48,580 --> 00:08:53,080
many ways you actually look at model

00:08:50,890 --> 00:08:53,900
building and validation you feed it back

00:08:53,080 --> 00:08:55,940
and you can't

00:08:53,900 --> 00:08:57,410
new that loop until you really get the

00:08:55,940 --> 00:09:00,560
right set of features and it's a very

00:08:57,410 --> 00:09:02,780
painful and laborious process what it

00:09:00,560 --> 00:09:05,570
really involves is the experience which

00:09:02,780 --> 00:09:07,610
is expertise coding and really trial and

00:09:05,570 --> 00:09:09,860
error and you just iterate through this

00:09:07,610 --> 00:09:11,930
so how can machines perform all of these

00:09:09,860 --> 00:09:14,120
automatically what we really have done

00:09:11,930 --> 00:09:17,150
is pattern learning reinforcement

00:09:14,120 --> 00:09:18,890
learning based methods exploration which

00:09:17,150 --> 00:09:21,140
is hierarchical exploration driven by

00:09:18,890 --> 00:09:23,330
performance numbers and finally fusion

00:09:21,140 --> 00:09:25,370
of useful combinations through

00:09:23,330 --> 00:09:27,710
intelligent enumeration and feature

00:09:25,370 --> 00:09:29,780
selection all automatically and the

00:09:27,710 --> 00:09:31,400
results are that you can start with the

00:09:29,780 --> 00:09:33,980
model the best of the model you have

00:09:31,400 --> 00:09:36,110
roughly in this case I'm showing 89% and

00:09:33,980 --> 00:09:38,840
you can improve that accuracy to 92%

00:09:36,110 --> 00:09:40,790
again we are automating that task of

00:09:38,840 --> 00:09:43,070
really trial and error which is very

00:09:40,790 --> 00:09:44,570
hard to do and the last one is really

00:09:43,070 --> 00:09:47,870
around this is really interesting which

00:09:44,570 --> 00:09:50,690
is AI correcting AI so the best example

00:09:47,870 --> 00:09:52,790
I can give is if I have if I'm hard of C

00:09:50,690 --> 00:09:55,310
sort of seeing far so I don't have a

00:09:52,790 --> 00:09:57,800
20/20 vision there are two ways I can

00:09:55,310 --> 00:10:00,050
correct myself I can go through laser

00:09:57,800 --> 00:10:02,060
eye surgery or the second option is I

00:10:00,050 --> 00:10:04,010
can get glasses actually now laser eye

00:10:02,060 --> 00:10:06,980
surgery is like you know rebuilding the

00:10:04,010 --> 00:10:09,110
model itself so if I was a machine

00:10:06,980 --> 00:10:10,730
learning model laser eye surgery on me

00:10:09,110 --> 00:10:13,730
will be like rebuilding the model and

00:10:10,730 --> 00:10:16,010
glasses for me will be correcting AI

00:10:13,730 --> 00:10:17,900
itself through something that sits on

00:10:16,010 --> 00:10:19,730
top of it we have actually released a

00:10:17,900 --> 00:10:22,160
capability in Watson open scale again

00:10:19,730 --> 00:10:25,520
which manages and operates your AI and

00:10:22,160 --> 00:10:27,830
corrects it all automatically so it's

00:10:25,520 --> 00:10:30,620
really a eye correcting AI in real-time

00:10:27,830 --> 00:10:32,900
without compromising model and accuracy

00:10:30,620 --> 00:10:34,310
I actually have attached references to

00:10:32,900 --> 00:10:36,080
all the papers that have been written

00:10:34,310 --> 00:10:38,000
that are there on archive and published

00:10:36,080 --> 00:10:39,740
in conferences as well I'm giving a

00:10:38,000 --> 00:10:41,720
detailed talk actually later on today

00:10:39,740 --> 00:10:45,100
please join me and I can give you a lot

00:10:41,720 --> 00:10:45,100
more details so thank you very much

00:10:51,510 --> 00:10:53,570

YouTube URL: https://www.youtube.com/watch?v=BwPEmDM1uTA


