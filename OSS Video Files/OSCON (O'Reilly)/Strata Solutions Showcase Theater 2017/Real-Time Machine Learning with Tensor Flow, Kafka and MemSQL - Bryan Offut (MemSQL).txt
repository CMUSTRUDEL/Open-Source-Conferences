Title: Real-Time Machine Learning with Tensor Flow, Kafka and MemSQL - Bryan Offut (MemSQL)
Publication date: 2017-10-17
Playlist: Strata Solutions Showcase Theater 2017
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	                              hey everyone my name is Brian Offit I'm                               a product manager with mem sequel and                               I'm here to talk about real time machine                               learning with kafka mem sequel and                               tensorflow                               so start off with a rough agenda start                               off with some background kind of what                               we're gonna talk about today provide                               some problem context what's the data set                                what are we trying to solve then we're                                gonna go from zero to your real time                                machine learning in less than three                                minutes so right now I have nothing                                installed on my laptop we're gonna go                                through the full installation get                                everything set up and by the end we'll                                be doing some machine learning and be                                able to do some analysis on data I will                                leave some time at the end key takeaways                                and questions I won't have terribly too                                much time for questions but I'll be                                hanging around the booth afterwards so                                what is this presentation about right                                we've kind of all been here all day at                                least I have we've heard all the words                                Big Data speed data analytics kind of                                all the buzzwords so what is this                                presentation about it's partially about                                those things so the first question is                                how can I train and classify data in                                real time can I do this without taking                                years to set up my environment learning                                a ton about machine learning learning a                                ton about all these different systems                                how can I make this easy and quick and                                can I train and classify at the same                                time right so lots of times you have                                your machine learning algorithm you do a                                bunch of training you host it somewhere                                and then when you run classification                                through it it's kind of stale you know                                what if I want to add I have new                                training data that's coming in and I                                want my algorithm to be updated with                                that new training data and classified                                using the most up-to-date version of the                                weights whatever it might be but really                                this presentations have a little bit                                more than that it's about the big                                questions right you know can I use                                statistics to answer one of the life's                                biggest and most inherently undefiable                                questions you know one of the things                                that makes us inherently human which is                                love so this may come as a surprise to                                many of you but I am single and like any                                reasonable single millennial with a math                                background I was curious if I could use                                statistics to solve this problem so I                                went online and I was able to find a                                real data set of speed-dating results so                                there was a professor at Columbia and it                                wanted to do a sociological study on                                basically what people said they wanted                                into potential partner versus what they                                actually wanted so we had a bunch of                                people go through speed dates and more                                people as matches or not and beforehand                                they're asked to date hundred points and                                they're asked to assign these hundred                                points to six categories sincerity                                attractiveness fun shared interests                                ambition and intelligence and they were                                also asked to rank a variety of                                interests on a                                scale from one to ten this is stuff like                                yoga is one of them movies music all of                                these sorts of things                                someone's anok's can we use this data                                the answers to these questions and                                people that actually matched in real                                life these are real people to                                empirically determine one a romantic                                type identify potential dating matches                                as they come in in real time we'll see                                that in a second and answer the question                                like how well do the machines know me                                right so I presumably have a pretty                                understanding of my dating history and                                what I'm generally attracted to so I was                                very curious how close would this                                actually be to to reality so do this I                                use four technologies Kafka mmm sequel                                pipelines tensorflow                                and docker so pretty standard stuff                                pretty commonly use technologies nothing                                super crazy here so a quick overview of                                the architecture we have training data                                so there's CSV we have classification                                 data also in a CSV that gets sucked into                                 Kafka via to Kafka topics we then use                                 mem sequel pipelines to extract the data                                 from Kafka run it through pipelines                                 transforms which are going to run our                                 tensor flow code for training and                                 classification then it's going to put it                                 into the database and then we can do                                 some analyzing of the data in the                                 application afterward so just to give a                                 quick overview of what the data actually                                 looks like to make this picture a little                                 clearer person want a answers a bunch of                                 questions person B answers a bunch of                                 questions they meet up they talk for                                 four minutes and at the end they say is                                 it a match if they both say yes then                                 it's a                                                                 the classification it's going to be                                 person a plus myself there's a wonderful                                 picture of me that I took outside about                                 two hours ago and will determine is it                                 actually a match cool let's take a look                                 and see what this actually looks like in                                 action so the first thing we're gonna do                                 is start our MEMC cool docker image so                                 pretty straightforward just go ahead and                                 run that and then we're gonna do the                                 exact same thing for Kafka again just                                 docker run we have a Kafka docker image                                 here                                 Oh interesting                                 let's on the fullscreen this and go over                                 here cool yeah so it's these I just did                                 this line and this line and so over here                                 in the terminal window we have docker n                                 mem sequel running then we have to make                                 our topics so there's a bunch of code                                 here most of it just copying over                                 configuration files there's nothing too                                 crazy what's actually interesting down                                 here is we're making our two Kafka                                 topics and then turning it on so we go                                 right here and we can run that and then                                 we have some Python we have to install                                 the men sequel the transform of the men                                 sequel Python pipeline is written in                                 Python so just some libraries we have to                                 install again nothing too crazy just                                 scripting this to make it a little                                 faster and then once all of that is set                                 up we did interesting stuff so we're                                 gonna make a database called                                 speed-dating matches we're gonna create                                 two tables training and the actual                                 results and then we're going to make our                                 pipelines so immense equal pipe bombs                                 are gonna stream the data from Kafka as                                 you can see where my mouse is this is                                 actually pretty straightforward I'll                                 make it a little bit bigger for everyone                                 you say create pipeline you give it a                                 name you say you want to load from Kafka                                 you give the IP address and you give the                                 topic name and you specify a transform                                 file so if we're training we're gonna                                 use a training Python file and for the                                 running we're going to use a run model                                 Python file and then these are actually                                 the arguments to those transforms so                                 we're gonna give it a an algorithm we                                 want to use which in this case is linear                                 classifier and a directory we want it to                                 save it to so the classification                                 algorithm is going to read from that                                 directory to use that model and the                                 training is going to save results to                                 that directory so that the                                 classification can pull from it                                 cool so let's go ahead and run this real                                 quick still installing some of the                                 Python I should fine                                 oh and we see that mem sequel has an                                 issue so something is actually really                                 interesting about the mem sequel docker                                 image is it will also spin up mem sequel                                 ops so if we go to localhost                                           clear we can cook very clearly see oh                                 look one of our nose didn't run so we                                 can go over to our bash screen sequel                                 bash and we can go MC boil ops restart                                 there we go we restart all notes and so                                 this should solve our problem it's gonna                                 stop the cluster and start it back up                                 and we can actually see what's going on                                 over here in Memphis equal opps which is                                 really nice so sometimes you'll see                                 issues and it's really cool to go in                                 here and you can see oh cool that node                                 wasn't running I should probably just                                 restart things and it'll pick itself                                 back up so we're starting up and we see                                 they're now both running and we can go                                 over here and copy paste the exact same                                 thing and we've made our table we've                                 created our pipeline and if we run show                                 pipelines we can see that the training                                 is now running cool so what is actually                                 going on in this training transform that                                 I've been talking about how complicated                                 is the code the good news is that it's                                 actually very straightforward there's                                 four files the first one is this model                                 options file this is a really simple                                 convenience function tensorflow has                                 these things called estimators which are                                 really awesome it's like a very high                                 level API for running you have pretty                                 basic machine learning algorithms and                                 this is just so that you can use this                                 method to pick one of those things so if                                 we go back to when we made our pipeline                                 we put linear classifier as our argument                                 you could go and alter the transform and                                 easily put in one of these and and                                 restart your pipeline you're good to go                                 the other ones a model variables file so                                 this is just a reading from a CSV one of                                 the column names and then setting up our                                 tensor flow features so machine learning                                 feature vector got to do all that we                                 have two types categorical which is                                 going to be anything that isn't a                                 continuous number it's like a color                                 would be categorical and tensorflow does                                 an awesome job of actually mapping those                                 things too sparse vectors for you which                                 is really convenient you don't have to                                 know how many different categories you                                 have and then continuous so this is                                 stuff like age etc we put these into a                                 list because that's what tensorflow                                 actually wants to pass into the method                                 and this is my answer to the questions                                 so so if we go over here                                 and we select star from speed training                                 I got a typo here cool we can see that                                 the training the initial training is                                 done just has some information here                                 accuracy accuracy baseline average loss                                 all that kind of stuff so now that we've                                 done that let's go ahead and start our                                 speed dating results pipeline cool so                                 now we show pipe lines and they're                                 actually both running at the same time                                 so if new classification data comes in                                 it's going to run the same thing when                                 new training results come in it'll do                                 that so what does the actual training                                 code look like so the training and run                                 code are actually very similar it's                                 going to take in cook take in the input                                 stream the extractor passes that                                 transformed this stuff as a byte encoded                                 CSV so this is just boilerplate for any                                 Kafka transform it you're gonna use an                                 input function it's really                                 straightforward oh yeah and then                                 basically all we do is read the CSV into                                 a data frame choose our model using the                                 arguments we passed in and then trade it                                 and then we'll output some evaluation                                 information which we saw just a second                                 ago and run model is actually the exact                                 same thing same boilerplate code here                                 same deal reading in the CSV doing some                                 stuff to combine my answers with other                                 people's answers choosing the model and                                 then instead of training we're gonna                                 predict so if we go over here and we                                 select star from speed dating from                                 dating                                 cool we see that and we can actually go                                 through and do this we have some results                                 right so these are people that                                 presumably match with me or did not                                 match with me in this case so I'm                                 running a long one time so I'm not going                                 to do too much of the going through                                 queries but to spoil the surprise it's                                 very very good at predicting fairly                                 correctly people that I would probably                                 actually be attracted to in her life                                 which I found very interesting so quick                                 takeaways so I can wrap this up here key                                 takeaways here are yeah tensorflow makes                                 a pretty easy - simple machine learning                                 right at the beginning here I had                                 nothing installed and by the end we had                                 everything running I was actually able                                 to do some machine learning and output                                 some results pipelines in tensorflow                                 makes doing this in real time actually                                 pretty easy if we went through and did a                                 query again you could see stuff was                                 actually coming in in real time and love                                 is np-complete so while this is pretty                                 good you know there's a lot more factors                                 at play here rather than shared                                 interests so just want to call that out                                 so thank you everybody thank you very                                 much
YouTube URL: https://www.youtube.com/watch?v=k4mFyxG08-I


