Title: Stream Analytics on GCP - Kir Titievsky (Google Cloud)
Publication date: 2017-10-17
Playlist: Strata Solutions Showcase Theater 2017
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	                              my name is Kiera I work in Google cloud                               platform I'm a product manager most of                               my time is spent on cloud pub/sub which                               is a stream ingestion service and I                               think about streaming analytics in                               general so today's today's talk is about                               a story of her single companies sort of                               journey from self managed stream                               analytics and in general data analytics                                tools to sort of a fully managed stack                                this is a picture of the team this is a                                data data engineering team at a company                                called Travel Loco as you can see                                they're smiling so this is a giveaway                                the story ends well they're happy this                                is the after picture so of course that                                of course the story is really about sort                                of what the problem was that they faced                                and sort of how how they fixed it so                                let's let's let's dive into that it's                                gonna be a short talk ten minutes the                                first of all travel loca it's a travel a                                travel technology firm right so think                                kayak Expedia so forth they're based in                                Indonesia and they've been expanding                                very rapidly they're now in six                                countries the company is fairly large so                                we're talking about a thousand employees                                                                                                     produce these apps that let you book                                flights and hotels so it's an e-commerce                                business of course when you're an                                e-commerce business like this especially                                a competitive one                                like like travel technology data                                analytics is absolutely core to your                                competitiveness it's not just about                                connecting vendors together you have to                                do the right things you have to present                                the right things you have to optimize                                all the time so when you are data when                                you're managing a data analytics staff                                stack you are enabling use cases that                                absolutely core to the business so they                                were talking about basic business                                intelligence right how much money we're                                making and we're making money to kind of                                user-facing high-volume feature like                                features like personalization and fraud                                adds up to m'as a ssin cross-selling                                all sorts of things this is what the                                data analytics tacit travel ouka looked                                like before the team was smiling the way                                they were in the first picture                                so they they ship Android and iOS apps                                and they were running two parallel                                systems both of them were fed through an                                Apache Kafka cluster an app would                                generate an event it would go to a Kafka                                cluster they operate at night on AWS and                                from there it was split into two paths                                one of them was real time                                the other one was batch you can also you                                can read some more about there they have                                a public blog about this you can get                                some of the details but some features to                                highlight here so they're the real time                                things there were two kinds there was                                the operational database which was                                they were winding it themselves and then                                there was a real-time data warehouse                                right what is currently happening which                                sort of fed a bi analytics tool they ran                                in Domo now the bad news case were was                                primarily for historical analyses right                                this is not real-time data warehousing                                so he had Goblin net was reading from                                from Kafka and then that went into a                                data Lake an object storage and then it                                either was map reduced over through                                sequel on cue ball or the the BI tools                                were fed through through redshift so                                that was the that was that the stack and                                it worked they were they were doing                                billions of events a day so a fairly                                successful business of course it came at                                a cost                                first of all Kafka is absolutely central                                that's your persistence layer unless a                                piece of data makes it to Kafka nothing                                works                                so there was somebody had to be on call                                all the time all right that's a con cost                                secondly you're scaling the whole thing                                right it's gonna keep it bids it's                                distributed its company's growing fast                                so throughput issues happened different                                different parts particularly with                                redshift and then finally scaling is                                 difficult because there's so many                                 different components of this of this                                 diagram that themselves are there                                 binaries running on multiple machines                                 multiple cores right talking about mem                                 sequel talking about those connectors                                 that are themselves custom custom Java                                 binaries that are taking data from Kafka                                 putting that into mem sequel right so                                 all of this needs to be administered and                                 run and all of this needs to be                                 constantly scaled                                 and so this is of course cost of doing                                 business right this is what you do this                                 is what engineers have jobs except that                                 at some point the cost became big enough                                 that people started getting paged at                                 night on weekends and then somebody gets                                 paged in their honeymoon and then                                 they're like okay we're done right let's                                 let's it's time for a rewrite and so                                 they set out for a rewrite with with                                 this goal they wanted to turn that thing                                 where they were scaling everything                                 themselves into a fully managed managed                                 stock that freed engineers to spend time                                 with friends and family on weekends at                                 nights and then when they came to work                                 so they could focus on on writing                                 solving business problems not running                                 infrastructure and sort of the core                                 requirements were low into and latency                                 high availability end-to-end right not                                 just individual systems and out of                                 scaling everything the solution looked                                 like this Android and iOS app stayed the                                 same the output stayed the same except                                 now the initial events were went to                                 cloud pub/sub on Google on Google cloud                                 platform which is a stream ingestion                                 service in a pub subsystem in general                                 think of it as a mix of Kinesis and SQS                                 if you're not familiar with Google cloud                                 platform then all the processing all                                 ingestion ztl transformation was done in                                 our stream processing framework called                                 dataflow that converged real-time                                 streams of data as well as some legacy                                 data that that was in object storage and                                 Google and then we split the output into                                 two first of all there was the real-time                                 database for operations that was                                 migrated to AWS dynamodb so it's now a                                 managed managed service so that that                                 sort of achieved that goal and all the                                 warehousing loads went to Google Cloud                                 bigquery again the outputs are still the                                 same right so your business users don't                                 really don't really see the difference                                 so a few things to highlight about this                                 solution first of all all the components                                 all the new components right right there                                 in the middle they're all managed                                 certainly to Google bits and so is                                 DynamoDB so now you don't really have to                                 have people operating these things                                 second thing to notice is that it's a                                 cross cloud solution                                 right even though they went all in to                                 manage services they were happily                                 operating a mix thirdly what you're not                                 seeing is two different warehouses right                                 remember we they used to have a real                                 time warehouse and they used to have the                                 historical warehouse they used to have a                                 cue ball thing for the data analysts to                                 run map producers over historical data                                 they had another tool for in redshift                                 for bi dashboards that's all gone                                 there's just one data warehouse that's                                 bigquery it solves all it all the all                                 the use cases so this is these are kind                                 of the core different the the core sort                                 of core features of the new solution I                                 think to tell you a bit more about                                 dataflow right which is the processing                                 system what it replaced there's a lot of                                 stuff I didn't actually show you on the                                 initial diagram all right something had                                 to consume from Kafka something had to                                 transform data push it somewhere else                                 data flow does all of that what's also                                 interesting is that you're not                                 transforming data in multiple                                 environments you're not thinking about                                 ETL and goblin and in spark versus                                 custom binaries that know how to pull                                 from from Kafka and right into mem                                 sequel it's all done the same with the                                 same Apache beam SDK that's executed and                                 ran for you on a managed service so                                 that's a beautiful thing and that's kind                                 of that's the that's really the second                                 bit first bit I've already referred to                                 or at the analytics the analytics stream                                 all went into bigquery                                 nice nice thing about bigquery is that                                 it's it does do real-time so you can you                                 can insert something at a very high rate                                 just as you would essentially insert                                 something into a Kafka Kafka log except                                 it's available for analytics within                                 within a second or so secondly it's it's                                 scales well enough in fact that was its                                 original kind of promise for those giant                                 historical queries right so now your                                 analysts can go and run run queries                                 except across the entirety of logs as                                 well as the bi dashboards that needed                                 the latest information they are all in                                 the same system what's also interesting                                 is this developer happiness line on the                                 last thing so                                 what was what was cool about this is                                 despite the fact that this is all                                 designed for managed services there the                                 the the team was able to write hermetic                                 tests that all run locally right which                                 is kind of its it speaks to the kind of                                 tooling that's available so the real                                 success story though is this is that it                                 took two engineers to migrate                                        cases in                                                              from proof-of-concept to a full-scale                                 pilot the entirety of the data going                                 through the system right there was and                                 there was no nobody on ops which is to                                 two people right the end-to-end pipeline                                 latency for all use cases right there's                                 no longer batch and so forth seconds                                 right as soon as the data hits pub/sub                                 two seconds later it's queryable and                                 bigquery weather for the bi dashboards                                 or not they've achieved their no ops                                 scalability so hundreds of gigabytes a                                 day and bigquery is an interesting bit                                 in that because it's it's although it's                                 a managed warehouse because it supports                                 your standard sequel all of those                                 thousands of dashboards that their                                 business users were used to just worked                                 right it was an easy migration so that's                                 sort of a success story about stream                                 analytics on GCP and I think it                                 highlights kind of four four attributes                                 is that we're open right managed doesn't                                 mean you're closed and it is no ops and                                 it is scalable and ultimately it does                                 solve the problem I'll be happy to                                 answer any question afterwards we have a                                 booth set up there our first our first                                 attendee gets one of these but I'll tell                                 you a secret                                 you can get a Google cardboard for your                                 VR experience at our booth as well just                                 stop by thank you very much
YouTube URL: https://www.youtube.com/watch?v=zWObqWqRHDg


