Title: Deep Learning Solutions Powered by Intel and BigDL - Radhika Rangarajan (Intel)
Publication date: 2017-10-17
Playlist: Strata Solutions Showcase Theater 2017
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	                              my name is Radhika Rangarajan I'm with                               Intel Big Data technologies and I will                               be talking to you about deep learning                               solutions powered by Intel and big deal                               so what is big deal with the Electra                               stands for deep learning for big data                               it's basically a distributed deep                               learning library for Apache spark big                               deal is implemented as a standalone                                library on SPARC                                now we actually worked on this for about                                a year and we act open-source dead                                towards end of                                                          out there for about nine months and                                we've seen tremendous support from the                                community from customers and from the                                cloud service providers if you're                                familiar with a spark stack you know                                that there's a spark core which is a                                core data processing engine on top of                                which there are libraries for sequel                                processing our stream processing machine                                learning graph analytics and so on we                                build big deal to reside alongside with                                these other libraries right on top of                                SPARC code and works really well with                                SPARC machine learning and data frames                                with big deal users can build your deep                                learning applications as standard SPARC                                programs which can then run on their                                existing spark or Hadoop clusters so                                very often we get asked the question                                what can I do with big deal that I                                cannot do with other deep learning                                frameworks or why does it have why does                                why do we need another deep learning                                framework well the reality is that if                                you look at the Hadoop SPARC stack there                                is a key gap in terms of not having an                                organically built deep learning library                                that takes advantage of the massive                                scale of the Hadoop and spark ecosystem                                so to address that gap we actually                                introduced big deal from a future                                perspective anything that you can build                                with traditional deep learning                                frameworks like cafe torch or tensorflow                                you can build with big deal so it has                                feature parity with all popular deal                                frameworks the fact that big deal                                actually runs on Intel Xeon on your                                existing SPARC and Hadoop infrastructure                                you can take advantage of your existing                                investments now for IT and                                infrastructure money                                that means lower TCO and improved                                ease-of-use because now you're working                                with a software stack that you're                                already familiar with big deal actually                                is built on Intel for Intel Xeon                                processors which means it takes                                advantage of Intel's map kernel                                acceleration library so you get high                                performance from the single node                                acceleration from Intel's mkl now when                                you're talking about SPARC architecture                                it becomes less interesting when we are                                defining single node performance big                                deal actually takes advantage of this                                sufficient scale out architecture of                                SPARC and scales to tens to hundreds of                                Xeon processors let's look at what's                                inside big deal                                now beyond the basic layers that you can                                have there's like a hundred plus layers                                in big deal                                that you can use to build any kind of                                models but beyond that the fact that big                                deal is actually built for SPARC it's                                built in Scala so you have both Scala                                API support and we recently introduced                                Python API support as well it integrates                                really well with SPARC machine learning                                and SPARC streaming and there's some                                excellent use cases and code snippets                                available on the github on how to                                actually leverage big deal to work with                                these other SPARC components with our                                version point two that came out in                                second quarter of this year we actually                                provided Jupiter notebook integration                                for big deal now the interesting part                                about deep learning is the time you                                spend training your model and actually                                ensuring your model converges this would                                actually be a very much of interest to                                all the data scientists because we now                                have tens aboard integration with big                                deal so you can actually do                                 visualization of your entire training                                 cycle and last but not least and this is                                 the one of the most appealing features                                 of big deal interoperability with other                                 traditional deep learning frameworks you                                 can actually load cafe torch or tenza                                 flow models inside big league big deal                                 and continue to fine-tune them now                                 wherever you want to use something like                                 this it would be an inferencing as well                                 as in transfer learning with a version                                 of big deal that's coming out in October                                 we are going to be able to provide some                                 amount of functional API support for                                 working with some of the popular deep                                 learning frameworks as well as Kerris                                 support                                 so what is a community cloud and                                 customer adoption for big-deal mean I                                 mentioned earlier that we open sourced                                 in in December of                                                   rock-solid community support when I                                 actually open source this we had about a                                 handful of contributors to this project                                 from Intel we are training at about                                    contributors at this point all of them                                 externally so that tells you how strong                                 our project is and how can it can                                 sustain on its own as a community driven                                 initiative but let's look at all the                                 cloud and partners support now we know                                 that all popular CSPs have their version                                 of managed SPARC services big dl is                                 available on all your favorite cloud                                 platforms from Azure hdinsight to Azure                                 D SVM to Amazon Web Services to Kingsoft                                 cloud which has recently included VL as                                 part of their managed MapReduce service                                 and data breaks all the csps have                                 technical tutorials and blogs available                                 on how to onboard big deal on their                                 platform great as a very valued partner                                 for Intel and a super computer company                                 when you talk about scaling on SPARC                                 Cray knows how to scale to hundreds of                                 nodes and Cray is actually integrated                                 big deal with in their Eureka XE                                 platform and shipped it out just a                                 couple months ago to all their HPC users                                 both Lite pent and cloud r are also                                 valued partners and they have actually                                 put out the big deal based technical                                 blogs and tutorials now with cloud arras                                 data science workbench you can easily                                 bring in big deal into that environment                                 and continue to work with your familiar                                 CDH environment we are also working with                                 cloud on a tighter integration of big                                 deal to simplify the experience of                                 working with big deal inside the data                                 science workbench we just announced this                                 morning or actually blu-ray announced                                 this morning that they would be actually                                 integrating big deal with your fall                                 release of epic well whose production                                 rising with big deal and that's the more                                 interesting part from what I can                                 actually tell you from between from                                 finance vertical all the way to                                 healthcare                                 we have several proof points all of whom                                 have actually built end-to-end use cases                                 productionize solutions with big deal                                 now in the past rocks we've talked a lot                                 about the fraud detection use case that                                 UnionPay actually                                 implemented I want to shine the                                 spotlight on the other three use cases                                 very briefly on the healthcare vertical                                 we partnered with the Center for Digital                                 health and innovation at UCSF and they                                 have actually implemented a use case for                                 automatic knee damage detection and                                 classification using                                                    big deal                                 but the next couple of slides I'll go a                                 little bit in detail about the use cases                                 that JD dot-com actually built as well                                 as with Giga spaces so what are JD                                 actually well now if you don't know JD                                 is one of the top online retailers in                                 China and to put it in context they have                                 hundreds of millions of merchandise                                 pictures that they like to actually                                 analyze and do some feature extraction                                 at a large scale feature extraction                                 image feature extraction is a very                                 complicated problem because you first                                 need to identify whether the object of                                 interest is available in that overall                                 picture and then you have to extract the                                 features of the image so it's actually a                                 two-stage process you have object                                 detection and then you have feature                                 extraction so what we did was we used                                 the single shot multi box detector model                                 for object detection and we use the deep                                 bit model for feature extraction and all                                 of this was done with big deal before JD                                 actually leveraged big deal for building                                 this inference pipeline they were using                                 cafe models on GPU clusters and with the                                 performance and throughput that they                                 were getting out of this big deal based                                 model they have now decided to move to                                 the Intel Xeon processor family so the                                 pipeline is very simple you have                                 hundreds of millions of image in your                                 distributed data set you actually read                                 them as spark rdd's you pre process                                 these images and then you actually use                                 big deal to load the SSD model and you                                 do object detection on that once you                                 have identified the object that's of                                 interest you isolate that object based                                 on its coordinates and you crop the                                 image and then you resize the image and                                 you batch it again just a little note                                 pre-processing and use the deep bit                                 model to extract the features out of                                 this target object and you put it back                                 in HDFS there will be a white paper                                 alongside with this use case that you                                 can read about later                                 now here's another interesting use case                                 customer service call center experience                                 how do you actually simplify that                                 experience with big deal                                 giggles faces in memory computing inside                                 each platform has now integrated big                                 deal to automatically transcribe your                                 customer service request analyze the                                 text and route it very efficiently in                                 less than hundred milliseconds to their                                 respective specialist tech specialist                                 who can actually quickly respond to your                                 call so those are just couple of                                 examples we just launched big deal on                                 AWS marketplace so I would highly                                 encourage everyone to go and try big                                 deal from ami from the marketplace and                                 you can actually get free compute                                 credits if you want to try that                                 so do get started with big deal here are                                 a few resources that are available you                                 can apply for free compute credits for                                 big deal for trying this on our                                 marketplace and join the conversation on                                 our user group but I want to leave you                                 with one more thought in addition to big                                 deal Intel is heavily invested in                                 optimizing all other AI frameworks and                                 we have a wealth of information                                 available on the Internet wanna Academy                                 from trains to tools to community so                                 thank you for joining this talk on big                                 deal and hope you get to join the                                 conversation with us in our user groups
YouTube URL: https://www.youtube.com/watch?v=1sUijNIi9zk


