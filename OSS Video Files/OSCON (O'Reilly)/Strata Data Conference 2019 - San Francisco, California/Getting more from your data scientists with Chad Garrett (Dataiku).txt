Title: Getting more from your data scientists with Chad Garrett (Dataiku)
Publication date: 2019-04-02
Playlist: Strata Data Conference 2019 - San Francisco, California
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,560 --> 00:00:05,220
hi my name is Paco Nathan and I'm here

00:00:03,300 --> 00:00:07,440
with the Reilly media were at strata

00:00:05,220 --> 00:00:08,970
data conference in San Francisco and

00:00:07,440 --> 00:00:11,490
today it's pleasure to be joined with

00:00:08,970 --> 00:00:13,049
chad garret chief revenue officer data

00:00:11,490 --> 00:00:15,240
iku thanks for having me

00:00:13,049 --> 00:00:18,660
wonderful thinking Chad welcome to

00:00:15,240 --> 00:00:21,510
strata pleasure uh you know one question

00:00:18,660 --> 00:00:23,550
I have for you we do a lot of surveys

00:00:21,510 --> 00:00:26,130
that are Reilly and one of the things

00:00:23,550 --> 00:00:29,580
that's always identified is just talent

00:00:26,130 --> 00:00:31,560
crunch talent gap finding and retaining

00:00:29,580 --> 00:00:33,090
data scientists it's it's one of the

00:00:31,560 --> 00:00:36,450
major challenges one of the big hurdles

00:00:33,090 --> 00:00:37,950
water companies face and especially is

00:00:36,450 --> 00:00:40,170
they try to become more data-driven

00:00:37,950 --> 00:00:43,290
there's there's more demand for people

00:00:40,170 --> 00:00:47,789
these skills but it's even harder what

00:00:43,290 --> 00:00:50,010
can enterprises do to deploy more

00:00:47,789 --> 00:00:52,649
machine learning and AI without

00:00:50,010 --> 00:00:55,170
necessarily hiring up armies of these

00:00:52,649 --> 00:00:57,360
people that's a great question I you

00:00:55,170 --> 00:00:59,370
know Harvard Business Review did an

00:00:57,360 --> 00:01:01,949
article recently where they they said

00:00:59,370 --> 00:01:04,379
the data scientists was the sexiest job

00:01:01,949 --> 00:01:06,210
of the 21st century it was a good

00:01:04,379 --> 00:01:08,400
article but if you look at what's behind

00:01:06,210 --> 00:01:10,740
that article it's it's the fact that

00:01:08,400 --> 00:01:12,479
there is a shortage it's a very high

00:01:10,740 --> 00:01:14,909
paid job but not every company can

00:01:12,479 --> 00:01:16,560
afford to hire four and we're here in

00:01:14,909 --> 00:01:19,320
Silicon Valley and we don't need to name

00:01:16,560 --> 00:01:20,939
names but there's a lot of shiny bright

00:01:19,320 --> 00:01:22,830
companies that everyone wants to work

00:01:20,939 --> 00:01:25,220
for so it's easy for them to attract the

00:01:22,830 --> 00:01:27,509
talent but if you're the other companies

00:01:25,220 --> 00:01:29,490
either you have it you don't have your

00:01:27,509 --> 00:01:32,040
first data scientist or you need to

00:01:29,490 --> 00:01:34,020
build a bigger team it's it's hard so I

00:01:32,040 --> 00:01:36,000
think one thing that companies can do is

00:01:34,020 --> 00:01:38,340
try to find a partner or a platform

00:01:36,000 --> 00:01:40,590
where they can get more bang for their

00:01:38,340 --> 00:01:43,259
buck or more scale out of the data

00:01:40,590 --> 00:01:45,659
scientists that do have you know when

00:01:43,259 --> 00:01:48,930
you think about data I COO one of our

00:01:45,659 --> 00:01:52,320
big values are value adds the market is

00:01:48,930 --> 00:01:55,680
we can we can get more out of those data

00:01:52,320 --> 00:01:57,990
scientists by bridging the gap with the

00:01:55,680 --> 00:02:00,149
business meaning you can have business

00:01:57,990 --> 00:02:02,880
users doing what they want and love to

00:02:00,149 --> 00:02:03,990
do building flows and processes when

00:02:02,880 --> 00:02:06,090
they don't necessarily have the skills

00:02:03,990 --> 00:02:08,520
to do what the data scientist does and

00:02:06,090 --> 00:02:10,649
we can never actually leverage that data

00:02:08,520 --> 00:02:13,330
scientist more it's almost like a one

00:02:10,649 --> 00:02:15,770
plus one equals three scenario

00:02:13,330 --> 00:02:18,140
excellent Nixon because I can imagine if

00:02:15,770 --> 00:02:19,700
they're having to cross-train learning

00:02:18,140 --> 00:02:21,680
each other's tool sets that right

00:02:19,700 --> 00:02:23,420
there's gonna be friction right yeah and

00:02:21,680 --> 00:02:25,760
you think about personas and ite and

00:02:23,420 --> 00:02:28,580
personas in business and how people want

00:02:25,760 --> 00:02:31,130
to interact with data or want to

00:02:28,580 --> 00:02:32,510
actually build solutions for you know

00:02:31,130 --> 00:02:34,970
who they are and the skill sets they

00:02:32,510 --> 00:02:36,890
have you know if you're a data scientist

00:02:34,970 --> 00:02:38,090
you're coding I mean you're brilliant

00:02:36,890 --> 00:02:39,830
that's what you were trained to do and

00:02:38,090 --> 00:02:41,000
that's what you're good at but you know

00:02:39,830 --> 00:02:43,310
business analysts on the other end of

00:02:41,000 --> 00:02:44,990
the spectrum for them to learn are or

00:02:43,310 --> 00:02:47,600
Python or all these you know open source

00:02:44,990 --> 00:02:49,730
type scenarios is kind of a is a leap

00:02:47,600 --> 00:02:51,770
right so I think again I think that's

00:02:49,730 --> 00:02:53,900
where we can do some amazing things as

00:02:51,770 --> 00:02:55,790
we bridge that gap and right now there's

00:02:53,900 --> 00:02:58,550
not a lot of solutions out here no in

00:02:55,790 --> 00:03:00,050
the market yeah that that that bridge

00:02:58,550 --> 00:03:01,520
the gap not only from a communication

00:03:00,050 --> 00:03:03,890
standpoint because people talk

00:03:01,520 --> 00:03:05,810
differently but also that skills gap so

00:03:03,890 --> 00:03:08,210
I think we've got a unique edge today in

00:03:05,810 --> 00:03:10,280
the market Oh fantastic I mean that that

00:03:08,210 --> 00:03:12,500
kind of cultural problem especially in

00:03:10,280 --> 00:03:14,150
well-established companies that seems to

00:03:12,500 --> 00:03:16,040
be one of the the real big challenges

00:03:14,150 --> 00:03:17,870
it's not just getting the people with

00:03:16,040 --> 00:03:21,470
the skills but it's it's that culture

00:03:17,870 --> 00:03:24,260
how do you go across it is it is I would

00:03:21,470 --> 00:03:26,480
agree you know looking at your term

00:03:24,260 --> 00:03:29,990
long-term outlook what what you see as

00:03:26,480 --> 00:03:32,150
far as the the future roadmap on the

00:03:29,990 --> 00:03:34,100
regulatory side of AI that seem to be a

00:03:32,150 --> 00:03:36,110
very hot topic it is a hot topic in

00:03:34,100 --> 00:03:37,760
regulation is a hot topic almost

00:03:36,110 --> 00:03:42,140
everywhere you go and a lot of different

00:03:37,760 --> 00:03:44,630
ways but AI is in the crosshairs of

00:03:42,140 --> 00:03:47,810
regulation yeah right and it should be

00:03:44,630 --> 00:03:49,370
for obvious reasons I don't know a few

00:03:47,810 --> 00:03:51,230
things that come to mind that signal the

00:03:49,370 --> 00:03:54,800
coming of regulation there's a simple

00:03:51,230 --> 00:03:58,280
one data privacy Day of 2019 you know

00:03:54,800 --> 00:04:01,130
came and went in January the the

00:03:58,280 --> 00:04:03,920
European Council recently started

00:04:01,130 --> 00:04:06,950
amending its convention to include a lot

00:04:03,920 --> 00:04:08,330
more data privacy that's a clear signal

00:04:06,950 --> 00:04:10,610
that's going to happen in Europe

00:04:08,330 --> 00:04:12,800
specifically and you know closer to home

00:04:10,610 --> 00:04:15,770
the president in the United States just

00:04:12,800 --> 00:04:18,880
signed I believe was an executive order

00:04:15,770 --> 00:04:20,770
to create the American a

00:04:18,880 --> 00:04:22,360
rusha t'v right so you look at those

00:04:20,770 --> 00:04:26,290
things and you say wow things are coming

00:04:22,360 --> 00:04:28,420
now if I'm a company building AI I don't

00:04:26,290 --> 00:04:30,850
want fully automated what we would is

00:04:28,420 --> 00:04:33,070
call kind of blackbox AI where you throw

00:04:30,850 --> 00:04:35,410
things in and and it's all automated and

00:04:33,070 --> 00:04:36,850
out comes the output I mean that's where

00:04:35,410 --> 00:04:39,460
a lot of the bad press is coming today

00:04:36,850 --> 00:04:41,080
right so I think a data IQ we've taken a

00:04:39,460 --> 00:04:44,680
step back and we have what we call human

00:04:41,080 --> 00:04:47,200
centric AI and human centric AI says you

00:04:44,680 --> 00:04:50,790
know I kind of there's two tenets of it

00:04:47,200 --> 00:04:53,620
first is transparency and the second is

00:04:50,790 --> 00:04:55,780
interpretability so it's the ability to

00:04:53,620 --> 00:04:58,420
interact as a human build these things

00:04:55,780 --> 00:05:00,970
right not just taking the machines word

00:04:58,420 --> 00:05:03,460
for it it's the ability to refine them

00:05:00,970 --> 00:05:05,860
over time and the ability from a

00:05:03,460 --> 00:05:08,470
governance perspective to go look at it

00:05:05,860 --> 00:05:10,420
see what went wrong I see what's going

00:05:08,470 --> 00:05:13,630
right and if there is all of a sudden a

00:05:10,420 --> 00:05:15,040
new government scenario to deal with you

00:05:13,630 --> 00:05:17,080
can get in there and do what you need to

00:05:15,040 --> 00:05:20,680
do so again and I think the point is

00:05:17,080 --> 00:05:22,000
automated fully automated AI is really

00:05:20,680 --> 00:05:23,830
the bright and shiny thing in a lot of

00:05:22,000 --> 00:05:26,740
places today but you really have to

00:05:23,830 --> 00:05:27,790
think what it's early days for AI what's

00:05:26,740 --> 00:05:30,130
coming in the next two or three years

00:05:27,790 --> 00:05:32,140
technology wise and regulation wise so

00:05:30,130 --> 00:05:34,440
that's it's a really good point and I

00:05:32,140 --> 00:05:36,190
think anyone who's looking to build AI

00:05:34,440 --> 00:05:38,620
really needs to take that in

00:05:36,190 --> 00:05:39,940
consideration the the shiny object is

00:05:38,620 --> 00:05:42,250
out there and there's this promise of

00:05:39,940 --> 00:05:44,890
auto ml etc or however you want to call

00:05:42,250 --> 00:05:46,780
it but exactly is the regulations are

00:05:44,890 --> 00:05:48,310
coming you have no idea where that's

00:05:46,780 --> 00:05:49,600
gonna land that's right how many times

00:05:48,310 --> 00:05:51,370
it will change that's right

00:05:49,600 --> 00:05:53,620
and we just have had that flexibility to

00:05:51,370 --> 00:05:54,160
be able to respond as as companies yeah

00:05:53,620 --> 00:05:56,200
agreed

00:05:54,160 --> 00:05:58,500
so and I think just thinking two steps

00:05:56,200 --> 00:06:01,660
ahead as a company is investing in AI

00:05:58,500 --> 00:06:03,460
it's not only about the cost it's not

00:06:01,660 --> 00:06:05,650
only about the impact to the customer

00:06:03,460 --> 00:06:08,290
but it's it's from a strategic

00:06:05,650 --> 00:06:10,480
perspective how do you put a platform in

00:06:08,290 --> 00:06:12,580
place again I think that allows you to

00:06:10,480 --> 00:06:15,340
have that human centric you know AI that

00:06:12,580 --> 00:06:18,220
responsible that non terminator kind of

00:06:15,340 --> 00:06:19,810
AI as you see in the press to get you

00:06:18,220 --> 00:06:21,880
through that journey and to come out on

00:06:19,810 --> 00:06:24,160
the other end able to be flexible and to

00:06:21,880 --> 00:06:27,130
change those things as needed so I think

00:06:24,160 --> 00:06:29,200
fully auto ml is is great as a feature

00:06:27,130 --> 00:06:30,040
of a product but not the whole strategy

00:06:29,200 --> 00:06:32,050
of the

00:06:30,040 --> 00:06:34,240
well a lot of the news cycle about AI is

00:06:32,050 --> 00:06:35,560
looking at the risks yeah but you know

00:06:34,240 --> 00:06:36,880
you're talking earlier about that

00:06:35,560 --> 00:06:38,320
bridging that gap between the

00:06:36,880 --> 00:06:40,210
technologists and the people who

00:06:38,320 --> 00:06:42,610
understand the domain who really making

00:06:40,210 --> 00:06:44,260
the key business decision right we're

00:06:42,610 --> 00:06:46,210
hearing more and more that there's

00:06:44,260 --> 00:06:49,360
upside on this as well I mean you might

00:06:46,210 --> 00:06:50,710
talk about the risks involved with data

00:06:49,360 --> 00:06:52,690
privacy and why we have compliance and

00:06:50,710 --> 00:06:54,190
all that but when you start to do it

00:06:52,690 --> 00:06:55,600
right you can identify business

00:06:54,190 --> 00:06:57,550
opportunities as well

00:06:55,600 --> 00:06:59,350
I can imagine there's synergy up these

00:06:57,550 --> 00:07:02,550
two things working together absolutely I

00:06:59,350 --> 00:07:07,930
I couldn't agree more you know I think

00:07:02,550 --> 00:07:09,760
when you think about where AI is going

00:07:07,930 --> 00:07:13,270
and where the biggest opportunities are

00:07:09,760 --> 00:07:15,280
it's easy I think as a consumer to see

00:07:13,270 --> 00:07:16,360
things like Alexa and self-driving cars

00:07:15,280 --> 00:07:18,430
that are coming those are the bright

00:07:16,360 --> 00:07:19,920
shiny objects they'll start impact in

00:07:18,430 --> 00:07:23,320
our life let's let's face it

00:07:19,920 --> 00:07:25,270
but the real needle mover in this whole

00:07:23,320 --> 00:07:27,130
picture is really what's trapped in the

00:07:25,270 --> 00:07:28,470
enterprise interesting so you think

00:07:27,130 --> 00:07:31,420
about things that we've tried to

00:07:28,470 --> 00:07:34,690
automate over the years basic human

00:07:31,420 --> 00:07:36,580
workflow we've been doing that for I

00:07:34,690 --> 00:07:39,100
mean for the 20 years I've been in

00:07:36,580 --> 00:07:40,960
Silicon Valley working we've been doing

00:07:39,100 --> 00:07:44,560
things like BPM and all sorts of things

00:07:40,960 --> 00:07:46,840
to automate but I think there's that

00:07:44,560 --> 00:07:49,300
next level of automation to handle a

00:07:46,840 --> 00:07:51,070
very menial tasks or tasks that purely

00:07:49,300 --> 00:07:53,350
can be completely automated things like

00:07:51,070 --> 00:07:54,550
dealing with customer satisfaction and

00:07:53,350 --> 00:07:57,580
things like that so I think we'll see a

00:07:54,550 --> 00:07:59,050
big revolution and that type of industry

00:07:57,580 --> 00:08:01,480
and the enterprise in the next five

00:07:59,050 --> 00:08:02,890
years if not sooner does that start to

00:08:01,480 --> 00:08:05,790
tie together some of the business units

00:08:02,890 --> 00:08:07,520
that might be siloed like supply chain

00:08:05,790 --> 00:08:09,470
ERP

00:08:07,520 --> 00:08:11,180
maintenance schedule customer support

00:08:09,470 --> 00:08:13,310
yeah they need to talk with each other

00:08:11,180 --> 00:08:14,780
in formal ways they do they do and I

00:08:13,310 --> 00:08:16,729
think companies in the last seven years

00:08:14,780 --> 00:08:18,590
had done a fantastic jobs with their

00:08:16,729 --> 00:08:20,960
analytics teams if you look at the

00:08:18,590 --> 00:08:22,520
beginning of analytics it was really you

00:08:20,960 --> 00:08:22,970
know the use cases were fairly simple

00:08:22,520 --> 00:08:24,409
yeah

00:08:22,970 --> 00:08:26,810
and you look at where they were just you

00:08:24,409 --> 00:08:28,729
know five four years ago you know

00:08:26,810 --> 00:08:30,259
predictive maintenance on oil wells was

00:08:28,729 --> 00:08:32,779
a huge thing then the amount of money

00:08:30,259 --> 00:08:34,969
that these companies can save by looking

00:08:32,779 --> 00:08:36,380
at the temperature and the friction and

00:08:34,969 --> 00:08:38,779
all sorts of different metrics that

00:08:36,380 --> 00:08:41,810
alone don't mean something but together

00:08:38,779 --> 00:08:44,060
are meaningful so companies got there

00:08:41,810 --> 00:08:46,610
but there's that next level use cases I

00:08:44,060 --> 00:08:47,930
think that you you really hit on is we

00:08:46,610 --> 00:08:50,959
kind of don't know what we don't know

00:08:47,930 --> 00:08:53,240
yet and and at the beginning of the

00:08:50,959 --> 00:08:54,890
analytics journey we didn't know how to

00:08:53,240 --> 00:08:57,260
build those use cases because we weren't

00:08:54,890 --> 00:08:59,450
sophisticated enough and the use cases

00:08:57,260 --> 00:09:02,209
became more sophisticated as we went eh

00:08:59,450 --> 00:09:03,890
I will follow the same path there was a

00:09:02,209 --> 00:09:05,870
presentation today talking about on a

00:09:03,890 --> 00:09:07,880
scale of AI how companies are deploying

00:09:05,870 --> 00:09:10,100
applications today I believe it was zero

00:09:07,880 --> 00:09:13,520
to ten most companies are in that zero

00:09:10,100 --> 00:09:15,980
to two phase their simple use cases I'd

00:09:13,520 --> 00:09:17,720
submit to you that next year at this

00:09:15,980 --> 00:09:20,000
event there'll be quite a few more in

00:09:17,720 --> 00:09:22,910
the three to four range right so it will

00:09:20,000 --> 00:09:24,589
evolve I think the beauty of the market

00:09:22,910 --> 00:09:28,070
today and I think the opportunity that

00:09:24,589 --> 00:09:31,010
my company has is the the journey is

00:09:28,070 --> 00:09:33,220
early people don't know what's to come

00:09:31,010 --> 00:09:35,810
regulation sure but let's talk about

00:09:33,220 --> 00:09:38,270
insulating those customers from

00:09:35,810 --> 00:09:40,220
technologies that are in vogue now that

00:09:38,270 --> 00:09:42,260
maybe go out of vogue yeah let's say

00:09:40,220 --> 00:09:43,670
Hadoop is very even very hot let's say

00:09:42,260 --> 00:09:45,589
three years from now and all that's and

00:09:43,670 --> 00:09:47,630
Hadoop is gonna go away so don't don't

00:09:45,589 --> 00:09:49,490
quote me there but I'm just saying in a

00:09:47,630 --> 00:09:51,410
company it might not be the strategic

00:09:49,490 --> 00:09:54,230
direction anymore wouldn't it be great

00:09:51,410 --> 00:09:55,700
to have a platform that allows you to

00:09:54,230 --> 00:09:58,490
decouple Hadoop if that were the case

00:09:55,700 --> 00:10:00,860
and plug in the new hot thing while

00:09:58,490 --> 00:10:04,070
keeping all those applications and all

00:10:00,860 --> 00:10:05,930
that logic that you built intact and

00:10:04,070 --> 00:10:08,860
still shock it like being a shock

00:10:05,930 --> 00:10:10,850
absorber for the future so so I think

00:10:08,860 --> 00:10:12,980
you bring up a good point

00:10:10,850 --> 00:10:14,480
it's early days we don't know it comes

00:10:12,980 --> 00:10:15,770
and I think you need to partner with a

00:10:14,480 --> 00:10:17,630
vendor that can get you there I mean I

00:10:15,770 --> 00:10:18,980
know we can but there's not a lot of

00:10:17,630 --> 00:10:20,899
vendors that have that horsepower right

00:10:18,980 --> 00:10:23,660
now there's that last mile

00:10:20,899 --> 00:10:25,149
smile alright what we're looking at

00:10:23,660 --> 00:10:28,160
projections were talking about this

00:10:25,149 --> 00:10:29,389
where do you see a i driving value for

00:10:28,160 --> 00:10:31,369
the next five years can you characterize

00:10:29,389 --> 00:10:35,119
that I kind of touched on a little bit

00:10:31,369 --> 00:10:36,860
but yeah we did yeah I I do think again

00:10:35,119 --> 00:10:38,899
I think it's trapped in the enterprise

00:10:36,860 --> 00:10:40,579
the consumer things great they'll take

00:10:38,899 --> 00:10:42,139
care of themselves or be fun innovation

00:10:40,579 --> 00:10:45,110
there and I think we all enjoy it I know

00:10:42,139 --> 00:10:46,790
our kids will and our grandkids but as

00:10:45,110 --> 00:10:49,279
far as the enterprise I mean there's big

00:10:46,790 --> 00:10:51,319
big value there we discussed automating

00:10:49,279 --> 00:10:53,709
very simple tasks but you know there's

00:10:51,319 --> 00:10:56,240
there's industries like health care

00:10:53,709 --> 00:10:57,499
there is all sorts of wearables and you

00:10:56,240 --> 00:10:58,999
know in the future there'll be things

00:10:57,499 --> 00:11:00,499
that actually you know will be put in

00:10:58,999 --> 00:11:04,249
our body to monitor our health

00:11:00,499 --> 00:11:06,410
those AI machine learning systems can

00:11:04,249 --> 00:11:08,509
take seemingly independent events

00:11:06,410 --> 00:11:10,369
surrounding a person where they are

00:11:08,509 --> 00:11:12,470
what's happening and they can correlate

00:11:10,369 --> 00:11:14,600
in real-time something that we didn't

00:11:12,470 --> 00:11:16,369
intend or maybe it may be the drug

00:11:14,600 --> 00:11:18,800
reaction or maybe something that needs

00:11:16,369 --> 00:11:20,869
to happen sooner than expected so I

00:11:18,800 --> 00:11:23,329
think analytics on its own can't follow

00:11:20,869 --> 00:11:24,800
a person around in their environment I

00:11:23,329 --> 00:11:26,329
think there are AI machine learning

00:11:24,800 --> 00:11:28,610
benefits that are coming in healthcare

00:11:26,329 --> 00:11:31,459
industry there'll be gain not only game

00:11:28,610 --> 00:11:32,959
changers but but lifesavers and I think

00:11:31,459 --> 00:11:34,970
this is the fuel to the fire that's

00:11:32,959 --> 00:11:36,470
going to get us there so it's really

00:11:34,970 --> 00:11:38,360
kind of a one plus one again equals

00:11:36,470 --> 00:11:39,740
three it's it's it's the needle mover

00:11:38,360 --> 00:11:42,410
for the enterprise and we just don't

00:11:39,740 --> 00:11:44,689
know yet but but it's it's pretty

00:11:42,410 --> 00:11:47,740
exciting times wonderful thank very much

00:11:44,689 --> 00:11:47,740
Chad as a pleasure

00:11:54,170 --> 00:11:56,230

YouTube URL: https://www.youtube.com/watch?v=Z1_CXPP2XWA


