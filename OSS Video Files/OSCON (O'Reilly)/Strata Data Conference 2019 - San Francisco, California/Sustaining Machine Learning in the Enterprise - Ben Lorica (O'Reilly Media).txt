Title: Sustaining Machine Learning in the Enterprise - Ben Lorica (O'Reilly Media)
Publication date: 2019-05-02
Playlist: Strata Data Conference 2019 - San Francisco, California
Description: 
	To view more keynotes and other talks from Strata SF 2019, visit:
http://oreilly.com/go/stratasf19

Drawing insights from recent surveys, Ben Lorica analyzes important trends in machine learning.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,060 --> 00:00:03,689
I wanted to take a few minutes to

00:00:01,829 --> 00:00:06,029
highlight the results of some recent

00:00:03,689 --> 00:00:08,370
surveys we conducted and along the way

00:00:06,029 --> 00:00:09,990
describes some recent trends in data and

00:00:08,370 --> 00:00:12,450
machine learning within companies and

00:00:09,990 --> 00:00:14,190
also give you guys a sneak peak of the

00:00:12,450 --> 00:00:17,460
program over the next few days

00:00:14,190 --> 00:00:21,060
so first last July we released a survey

00:00:17,460 --> 00:00:23,730
we drew over 11,000 respondents and at

00:00:21,060 --> 00:00:25,710
that time many of our respondents

00:00:23,730 --> 00:00:30,240
already indicated that they had machine

00:00:25,710 --> 00:00:32,579
learning models in production so with

00:00:30,240 --> 00:00:35,910
all the hype around AI it's very

00:00:32,579 --> 00:00:38,750
tempting to jump into use cases and data

00:00:35,910 --> 00:00:41,489
types that you may not be familiar with

00:00:38,750 --> 00:00:44,370
but the reality is hoarding to our

00:00:41,489 --> 00:00:46,170
surveys and the surveys of others the

00:00:44,370 --> 00:00:49,559
companies have successfully adopted

00:00:46,170 --> 00:00:54,510
machine learning do so by building on an

00:00:49,559 --> 00:00:56,399
existing analytic products like a bi and

00:00:54,510 --> 00:00:59,129
this means in practice that you take

00:00:56,399 --> 00:01:02,579
your existing system in layer machine

00:00:59,129 --> 00:01:04,409
learning on top of it so take for

00:01:02,579 --> 00:01:06,180
example deep learning which is a huge

00:01:04,409 --> 00:01:09,210
topic in this conference over the next

00:01:06,180 --> 00:01:11,659
two days many companies are using deep

00:01:09,210 --> 00:01:14,760
learning in a few ways including one

00:01:11,659 --> 00:01:17,729
replacing or augmenting existing machine

00:01:14,760 --> 00:01:19,560
learning systems so we've had tutorials

00:01:17,729 --> 00:01:22,740
from franceska lasari

00:01:19,560 --> 00:01:24,930
of Microsoft of how to use deep learning

00:01:22,740 --> 00:01:27,210
for example to augment your time series

00:01:24,930 --> 00:01:29,009
forecasting tools we also have tutorials

00:01:27,210 --> 00:01:32,100
about deep learning for recommender

00:01:29,009 --> 00:01:34,560
systems and you can also of course use

00:01:32,100 --> 00:01:36,299
deep learning to improve your existing

00:01:34,560 --> 00:01:41,820
machine learning product by augmenting

00:01:36,299 --> 00:01:44,670
new data types like images and video so

00:01:41,820 --> 00:01:47,329
machine learning will not only start

00:01:44,670 --> 00:01:50,130
appearing in more products and systems

00:01:47,329 --> 00:01:52,409
in many ways it will also change the way

00:01:50,130 --> 00:01:54,720
we write applications and software the

00:01:52,409 --> 00:01:57,479
important thing to note is that we are

00:01:54,720 --> 00:01:59,689
still in a highly empirical era for

00:01:57,479 --> 00:02:02,490
machine learning so there's not a lot of

00:01:59,689 --> 00:02:06,570
theoretical understanding for when and

00:02:02,490 --> 00:02:08,520
why it works in particular there's still

00:02:06,570 --> 00:02:11,489
the need for three important ingredients

00:02:08,520 --> 00:02:12,660
which is big data big compute and big

00:02:11,489 --> 00:02:13,620
models because the deep learning

00:02:12,660 --> 00:02:17,549
architectures are

00:02:13,620 --> 00:02:19,409
getting bigger and bigger so building a

00:02:17,549 --> 00:02:21,629
strong machine learning practice

00:02:19,409 --> 00:02:23,750
requires foundational technologies and

00:02:21,629 --> 00:02:27,060
that's basically the theme of this talk

00:02:23,750 --> 00:02:29,819
and data is gonna be key in getting data

00:02:27,060 --> 00:02:31,409
flowing cleaned and in usable form is

00:02:29,819 --> 00:02:34,019
going to be key to sustaining machine

00:02:31,409 --> 00:02:35,940
learning in your company so with an eye

00:02:34,019 --> 00:02:38,040
towards the importance of machine

00:02:35,940 --> 00:02:40,440
learning we recently completed another

00:02:38,040 --> 00:02:42,930
survey this one drew over 3,200

00:02:40,440 --> 00:02:45,540
respondents and we had two high-level

00:02:42,930 --> 00:02:49,109
goals the first is what are you folks

00:02:45,540 --> 00:02:51,959
using so what libraries what platforms

00:02:49,109 --> 00:02:53,459
what frameworks and what are you

00:02:51,959 --> 00:02:55,200
building so are you building the

00:02:53,459 --> 00:02:57,629
foundational tools in order to guarantee

00:02:55,200 --> 00:03:00,900
success in your machine learning

00:02:57,629 --> 00:03:03,019
practice so one of the first questions

00:03:00,900 --> 00:03:06,900
we asked was what are you building and

00:03:03,019 --> 00:03:08,940
not surprisingly data integration was on

00:03:06,900 --> 00:03:11,010
the top of the list so in my mind

00:03:08,940 --> 00:03:12,780
actually more people should be paying

00:03:11,010 --> 00:03:14,280
attention to this because everything

00:03:12,780 --> 00:03:17,609
begins with collecting and aggregating

00:03:14,280 --> 00:03:20,910
data and in in in today's world of

00:03:17,609 --> 00:03:22,829
course that means high volume at high

00:03:20,910 --> 00:03:26,549
velocity and from many many different

00:03:22,829 --> 00:03:28,139
sources so we have many many tops at

00:03:26,549 --> 00:03:30,599
this conference over the next two days

00:03:28,139 --> 00:03:32,819
from leading practitioners and companies

00:03:30,599 --> 00:03:35,819
on data integration and data pipelines

00:03:32,819 --> 00:03:37,650
so once you have your data collected an

00:03:35,819 --> 00:03:40,319
important part is to get it ready for

00:03:37,650 --> 00:03:43,319
machine learning today that means in

00:03:40,319 --> 00:03:45,120
practice involving domain experts right

00:03:43,319 --> 00:03:48,060
so in order to clean data you have to

00:03:45,120 --> 00:03:50,730
have some context so usually that means

00:03:48,060 --> 00:03:53,310
having a user interface where a domain

00:03:50,730 --> 00:03:55,829
expert can train the machine learning

00:03:53,310 --> 00:03:58,769
model that can do the data prep and data

00:03:55,829 --> 00:04:00,959
cleaning at scale and actually I want to

00:03:58,769 --> 00:04:04,230
give a shout out to speaking of user

00:04:00,959 --> 00:04:06,209
interfaces there's a very interesting

00:04:04,230 --> 00:04:09,389
project in the expo hall

00:04:06,209 --> 00:04:11,010
it's from MIT it's called North Star so

00:04:09,389 --> 00:04:13,680
if you get a chance stop by their booth

00:04:11,010 --> 00:04:16,169
but there's also going to be many talks

00:04:13,680 --> 00:04:19,949
about data prep as well as sponsors at

00:04:16,169 --> 00:04:22,200
the expo hall at this conference so once

00:04:19,949 --> 00:04:25,080
you have your data in place you need to

00:04:22,200 --> 00:04:27,570
know what data you have and who can use

00:04:25,080 --> 00:04:30,620
it as you can see about a third of our

00:04:27,570 --> 00:04:32,880
respondents are working on data catalogs

00:04:30,620 --> 00:04:34,980
and some companies are actually

00:04:32,880 --> 00:04:37,830
beginning to build their own solutions

00:04:34,980 --> 00:04:41,400
so for example we work as an open source

00:04:37,830 --> 00:04:44,100
project called marques uber announced an

00:04:41,400 --> 00:04:47,150
internal data governance and data

00:04:44,100 --> 00:04:50,070
catalog solution called data books and

00:04:47,150 --> 00:04:51,810
Paco Nathan will be giving an executive

00:04:50,070 --> 00:04:54,420
briefing on data governance and data

00:04:51,810 --> 00:04:57,690
catalogs later this afternoon at this

00:04:54,420 --> 00:04:59,850
conference so in the past we got by with

00:04:57,690 --> 00:05:03,240
a cavalier attitude towards our data

00:04:59,850 --> 00:05:06,270
sources that is beginning to end right

00:05:03,240 --> 00:05:08,010
so with the discussions about ethics we

00:05:06,270 --> 00:05:10,200
need to know about data lineage and

00:05:08,010 --> 00:05:12,990
provenance which really comes down to

00:05:10,200 --> 00:05:15,450
where does your data come from how was

00:05:12,990 --> 00:05:18,150
it gathered how was it modified along

00:05:15,450 --> 00:05:20,790
the way and who touched it last so the

00:05:18,150 --> 00:05:23,130
need to reproduce an audit your machine

00:05:20,790 --> 00:05:25,770
learning pipelines is increasingly

00:05:23,130 --> 00:05:28,200
becoming a legal and security issue so

00:05:25,770 --> 00:05:30,540
there are gonna be a few talks at this

00:05:28,200 --> 00:05:32,760
conference on how companies have built

00:05:30,540 --> 00:05:34,830
internal data lineage systems vision

00:05:32,760 --> 00:05:38,250
actually is quite a challenging task

00:05:34,830 --> 00:05:39,840
because you can imagine an environment

00:05:38,250 --> 00:05:42,930
where you have many many different data

00:05:39,840 --> 00:05:46,320
frameworks and data systems so it's hard

00:05:42,930 --> 00:05:49,080
to actually incorporate logging precise

00:05:46,320 --> 00:05:50,850
logging into each of these systems so I

00:05:49,080 --> 00:05:52,800
want to give a shout out to a couple of

00:05:50,850 --> 00:05:54,570
talks one from Intuit and one from

00:05:52,800 --> 00:05:57,150
Netflix they'll talk about how they

00:05:54,570 --> 00:06:00,750
built their internal data lineage system

00:05:57,150 --> 00:06:03,570
and of course we have a sponsor in the

00:06:00,750 --> 00:06:08,580
expo hall pachyderm who's who also has

00:06:03,570 --> 00:06:10,890
an interesting data lineage solution so

00:06:08,580 --> 00:06:12,750
as the number of data scientists and

00:06:10,890 --> 00:06:14,670
machine learning experts grow within

00:06:12,750 --> 00:06:17,340
your organization you have to

00:06:14,670 --> 00:06:19,040
standardized libraries models and

00:06:17,340 --> 00:06:23,100
features right so you have to

00:06:19,040 --> 00:06:26,700
incorporate collaboration and maybe you

00:06:23,100 --> 00:06:28,290
begin to introduce automation so one of

00:06:26,700 --> 00:06:30,270
the big topics of this conference is

00:06:28,290 --> 00:06:33,000
data science platforms so there will be

00:06:30,270 --> 00:06:34,530
numerous companies explaining what kind

00:06:33,000 --> 00:06:36,330
of data platform they have what

00:06:34,530 --> 00:06:39,330
libraries they support what trade-offs

00:06:36,330 --> 00:06:41,100
and design choices they made but we also

00:06:39,330 --> 00:06:44,040
have many

00:06:41,100 --> 00:06:47,070
in the expo hall who have interesting

00:06:44,040 --> 00:06:49,230
Auto ml solutions which is one aspect of

00:06:47,070 --> 00:06:54,450
data science platforms including

00:06:49,230 --> 00:06:56,730
determined AI so in the same survey we

00:06:54,450 --> 00:06:59,070
found a vast majority of companies

00:06:56,730 --> 00:07:01,830
already have a portion of their data

00:06:59,070 --> 00:07:03,570
infrastructure in the cloud and

00:07:01,830 --> 00:07:07,230
interestingly the people who use a

00:07:03,570 --> 00:07:10,470
public cloud many of them I would say is

00:07:07,230 --> 00:07:12,930
about 60% or more actually use multiple

00:07:10,470 --> 00:07:16,470
cloud providers right so they're not

00:07:12,930 --> 00:07:19,290
locked into a single cloud vendor and

00:07:16,470 --> 00:07:20,970
also a lot of people we found over 1/3

00:07:19,290 --> 00:07:24,300
are already beginning to use serverless

00:07:20,970 --> 00:07:26,640
technologies and there are many reasons

00:07:24,300 --> 00:07:30,360
for doing that from a data perspective

00:07:26,640 --> 00:07:32,100
so for example for data pipelines among

00:07:30,360 --> 00:07:33,300
other things and inference for machine

00:07:32,100 --> 00:07:34,830
learning

00:07:33,300 --> 00:07:38,420
there will be an interesting talk

00:07:34,830 --> 00:07:42,090
tomorrow morning by Eric Jonas who will

00:07:38,420 --> 00:07:43,860
give an overview of a recent UC Berkeley

00:07:42,090 --> 00:07:46,200
paper where they lay out their view on

00:07:43,860 --> 00:07:49,920
the current state in the future of

00:07:46,200 --> 00:07:52,140
serverless Technologies so our thesis is

00:07:49,920 --> 00:07:55,410
the use of machine learning will grow

00:07:52,140 --> 00:07:57,480
even more in the next few years so for

00:07:55,410 --> 00:07:59,760
one thing 5g is beginning to be rolled

00:07:57,480 --> 00:08:02,160
out and that means machine to machine

00:07:59,760 --> 00:08:05,640
applications many of which will

00:08:02,160 --> 00:08:08,790
incorporate machine learning and there's

00:08:05,640 --> 00:08:11,940
also going to be a new generation of

00:08:08,790 --> 00:08:13,920
specialized hardware particularly for

00:08:11,940 --> 00:08:16,560
deep learning both for inference and

00:08:13,920 --> 00:08:18,600
training both at the edge and at the

00:08:16,560 --> 00:08:20,610
data center so in particular the

00:08:18,600 --> 00:08:23,060
generation of deep learning hardware

00:08:20,610 --> 00:08:26,610
that will come out probably around q3 q4

00:08:23,060 --> 00:08:29,700
will really greatly accelerate training

00:08:26,610 --> 00:08:32,669
so we're talking I you know I'm not

00:08:29,700 --> 00:08:34,770
supposed to say this but 40 X speed-up

00:08:32,669 --> 00:08:36,780
in training so you can imagine a

00:08:34,770 --> 00:08:38,669
training test that took you 40 hours

00:08:36,780 --> 00:08:41,969
will now take you 1 hour right so that

00:08:38,669 --> 00:08:44,160
means in practice that data scientists

00:08:41,969 --> 00:08:46,980
can now run many more experiments and

00:08:44,160 --> 00:08:49,860
remember we're still in a very empirical

00:08:46,980 --> 00:08:51,930
era for machine learning so here are a

00:08:49,860 --> 00:08:54,660
couple of other indicators that machine

00:08:51,930 --> 00:08:57,450
learning will grow within companies

00:08:54,660 --> 00:09:00,090
so several years ago one of the hottest

00:08:57,450 --> 00:09:02,670
jobs in the industry was data scientists

00:09:00,090 --> 00:09:05,850
and that's still a very attractive job

00:09:02,670 --> 00:09:07,740
although I I have to say the term data

00:09:05,850 --> 00:09:09,300
scientist has kind of become muddled a

00:09:07,740 --> 00:09:12,690
little bit so I was talking to someone

00:09:09,300 --> 00:09:14,220
the other day where he said so this is a

00:09:12,690 --> 00:09:16,020
tech company in Silicon Valley where

00:09:14,220 --> 00:09:18,210
their business analyst so these are the

00:09:16,020 --> 00:09:19,740
people who run sequel queries have the

00:09:18,210 --> 00:09:23,160
title of data scientists right so

00:09:19,740 --> 00:09:26,310
there's been a lot of kind of confusion

00:09:23,160 --> 00:09:29,070
about who to haul data scientists so a

00:09:26,310 --> 00:09:31,830
few years ago we started to notice a new

00:09:29,070 --> 00:09:33,660
title emerging particularly in the San

00:09:31,830 --> 00:09:37,410
Francisco Bay Area but that has since

00:09:33,660 --> 00:09:39,780
grown out of this area and that was a

00:09:37,410 --> 00:09:41,610
machine learning engineer and this is a

00:09:39,780 --> 00:09:44,630
role that sits somewhere between data

00:09:41,610 --> 00:09:47,340
science and engineering and operations

00:09:44,630 --> 00:09:50,190
they tend to be higher paid than data

00:09:47,340 --> 00:09:51,720
scientists and they're usually tasked

00:09:50,190 --> 00:09:53,730
with really bringing things to

00:09:51,720 --> 00:09:56,070
production and as you can see there's a

00:09:53,730 --> 00:09:57,900
certain amount of rebranding among data

00:09:56,070 --> 00:10:01,250
scientists right so data scientists who

00:09:57,900 --> 00:10:04,500
two years ago refer to themselves as

00:10:01,250 --> 00:10:07,950
data scientists now want to be referred

00:10:04,500 --> 00:10:10,950
to as machine learning engineers so

00:10:07,950 --> 00:10:14,040
another sign is the emergence of new

00:10:10,950 --> 00:10:16,320
tools so here's one tool ml flow it's

00:10:14,040 --> 00:10:18,720
only ten months old as you can see

00:10:16,320 --> 00:10:20,880
there's a lot of traction with this tool

00:10:18,720 --> 00:10:22,980
so among other things that this tool has

00:10:20,880 --> 00:10:25,890
three components but one of the most

00:10:22,980 --> 00:10:28,350
widely used components is one that

00:10:25,890 --> 00:10:31,470
allows data scientists to track

00:10:28,350 --> 00:10:33,810
experiments and manage experiments so ml

00:10:31,470 --> 00:10:35,880
flow is useful for people with small

00:10:33,810 --> 00:10:38,790
teams or even individual data scientists

00:10:35,880 --> 00:10:40,380
can benefit from using it but also large

00:10:38,790 --> 00:10:42,720
teams of data scientists so there are

00:10:40,380 --> 00:10:45,630
cases where companies with thousands of

00:10:42,720 --> 00:10:49,560
models in production are using data ml

00:10:45,630 --> 00:10:51,930
flow so projects like ml flow will make

00:10:49,560 --> 00:10:54,840
machine learning development much easier

00:10:51,930 --> 00:10:56,820
to manage but it's much more than ml

00:10:54,840 --> 00:10:59,550
flow so there are other startups so one

00:10:56,820 --> 00:11:03,900
of them is here comet ml and Verta

00:10:59,550 --> 00:11:07,140
AI but as we are learning there are many

00:11:03,900 --> 00:11:08,579
important considerations that arise when

00:11:07,140 --> 00:11:10,679
it comes to machine learning so

00:11:08,579 --> 00:11:13,410
I started to give talks around the

00:11:10,679 --> 00:11:15,389
notion of managing risk and thankfully

00:11:13,410 --> 00:11:18,389
the research community has stepped up to

00:11:15,389 --> 00:11:20,610
the plate so many of the foundational

00:11:18,389 --> 00:11:23,129
technologies I covered earlier right so

00:11:20,610 --> 00:11:25,290
data lineage data governance data

00:11:23,129 --> 00:11:27,989
integration they all matter when it

00:11:25,290 --> 00:11:31,290
comes to auditing your applications for

00:11:27,989 --> 00:11:34,799
fairness security and privacy so we have

00:11:31,290 --> 00:11:36,989
a lot of talks about how to do machine

00:11:34,799 --> 00:11:39,269
learning in a privacy-preserving way it

00:11:36,989 --> 00:11:40,829
will have will even have a 40 minute

00:11:39,269 --> 00:11:43,319
session on machine learning on the

00:11:40,829 --> 00:11:45,389
encrypted data right after keynotes so

00:11:43,319 --> 00:11:48,420
one session I'd like to highlight when

00:11:45,389 --> 00:11:50,459
it comes to fairness is Sharad Gowell of

00:11:48,420 --> 00:11:53,399
Stanford will speak this afternoon at

00:11:50,459 --> 00:11:55,829
2:40 they have a recent paper serve a

00:11:53,399 --> 00:11:59,899
paper on fairness and machine learning

00:11:55,829 --> 00:11:59,899
which you will want to see

00:12:05,910 --> 00:12:07,970

YouTube URL: https://www.youtube.com/watch?v=dufU2D0S5wM


