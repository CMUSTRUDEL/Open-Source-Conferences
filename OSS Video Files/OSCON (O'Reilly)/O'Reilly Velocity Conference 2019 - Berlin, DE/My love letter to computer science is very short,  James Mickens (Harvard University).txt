Title: My love letter to computer science is very short,  James Mickens (Harvard University)
Publication date: 2019-11-07
Playlist: O'Reilly Velocity Conference 2019 - Berlin, DE
Description: 
	My love letter to computer science is very short and I also forgot to mail it
James Mickens (Harvard University)

James Mickens is an associate professor of computer science at Harvard University. His research focuses on the performance, security, and robustness of large-scale distributed web services. James earned a BS degree in computer science from the Georgia Institute of Technology and a PhD in computer science from the University of Michigan. Previously, he spent six years as a researcher at Microsoft. He currently does not have a Wikipedia article, mainly because Wikipedia servers do not accept 17 GB text files entitled “Let Me Sing The Song Of James Mickens (This Song Was Uploaded From An I.P. Address Owned By James Mickens).”

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,299 --> 00:00:05,939
do you ever feel like Twitter has a

00:00:03,210 --> 00:00:08,099
Content moderation problem I feel like

00:00:05,939 --> 00:00:09,809
that sometimes and it's not just Twitter

00:00:08,099 --> 00:00:11,849
it's Facebook and all the other

00:00:09,809 --> 00:00:13,469
technology companies that don't want to

00:00:11,849 --> 00:00:15,749
be responsible for the content on their

00:00:13,469 --> 00:00:17,910
platforms this is why I find it darkly

00:00:15,749 --> 00:00:20,130
hilarious to hear these companies talk

00:00:17,910 --> 00:00:22,289
about the challenges of content

00:00:20,130 --> 00:00:24,150
moderation these executives get up and

00:00:22,289 --> 00:00:26,580
they say stuff like you know once we're

00:00:24,150 --> 00:00:36,750
taking this content down the question is

00:00:26,580 --> 00:00:39,060
where do you draw the line there's a lot

00:00:36,750 --> 00:00:41,850
we need to address globally we have to

00:00:39,060 --> 00:00:51,180
prioritize our resources according to

00:00:41,850 --> 00:00:56,120
impact we want the progress that comes

00:00:51,180 --> 00:00:56,120
from free expression but not the tension

00:01:00,140 --> 00:01:05,250
right it's just like a very sad play

00:01:03,750 --> 00:01:07,679
constantly when you hear these people

00:01:05,250 --> 00:01:10,590
talk about content moderation now to be

00:01:07,679 --> 00:01:14,399
fair content moderation does pose some

00:01:10,590 --> 00:01:16,079
difficult ethical challenges okay but so

00:01:14,399 --> 00:01:18,210
does the collection of user data for

00:01:16,079 --> 00:01:19,859
targeted advertising and here's how

00:01:18,210 --> 00:01:22,609
companies have responded to those

00:01:19,859 --> 00:01:25,439
ethical dilemmas take all the user data

00:01:22,609 --> 00:01:26,460
follow the user everywhere oh my god

00:01:25,439 --> 00:01:28,530
what is happening there jump out of a

00:01:26,460 --> 00:01:30,509
building go get that data feed it to

00:01:28,530 --> 00:01:32,369
machine learning that is made of machine

00:01:30,509 --> 00:01:34,319
learning we shall be guided by no

00:01:32,369 --> 00:01:38,369
ethical framework besides the ancient

00:01:34,319 --> 00:01:39,329
wisdom of the snake King I don't feel so

00:01:38,369 --> 00:01:42,299
good mr. stark

00:01:39,329 --> 00:01:45,630
I don't feel so good so so what have we

00:01:42,299 --> 00:01:47,969
seen it's almost as if ethical

00:01:45,630 --> 00:01:49,950
considerations become less important

00:01:47,969 --> 00:01:53,639
when considering them would hurt revenue

00:01:49,950 --> 00:01:56,880
now listen I get it capitalism has some

00:01:53,639 --> 00:01:59,459
nice aspects markets are nice these

00:01:56,880 --> 00:02:01,469
statements are mostly true and yet I

00:01:59,459 --> 00:02:04,139
think that we can do better we must do

00:02:01,469 --> 00:02:06,389
better a big problem I think is that

00:02:04,139 --> 00:02:08,970
many software developers suffer from a

00:02:06,389 --> 00:02:11,850
lack of moral imagination an inability

00:02:08,970 --> 00:02:13,920
to understand the hopes and the fears of

00:02:11,850 --> 00:02:16,770
people who aren't in the tech industry

00:02:13,920 --> 00:02:18,780
so hate speech seems less problematic to

00:02:16,770 --> 00:02:20,280
developers because I think the groups

00:02:18,780 --> 00:02:22,380
that suffer from hate speech are

00:02:20,280 --> 00:02:24,959
typically underrepresented in the tech

00:02:22,380 --> 00:02:27,390
industry so it's easy for developers to

00:02:24,959 --> 00:02:30,209
say things like oh well hate speech is a

00:02:27,390 --> 00:02:33,090
minor problem because that danger seems

00:02:30,209 --> 00:02:35,910
so remote and so abstract however I

00:02:33,090 --> 00:02:37,890
guarantee you that if on Monday a new

00:02:35,910 --> 00:02:40,170
hate group called deaf to full stack

00:02:37,890 --> 00:02:41,820
developers released a grainy video that

00:02:40,170 --> 00:02:44,370
depicted corporate shuttles being set on

00:02:41,820 --> 00:02:46,380
fire in free food cafeterias being

00:02:44,370 --> 00:02:48,180
smashed to pieces if all this happened

00:02:46,380 --> 00:02:50,760
on a Monday then tech companies won't

00:02:48,180 --> 00:02:53,730
embrace content moderation on a Tuesday

00:02:50,760 --> 00:02:56,880
okay not the following Tuesday the very

00:02:53,730 --> 00:02:58,860
next day that Tuesday right because then

00:02:56,880 --> 00:03:01,080
the hate speech would seem real these

00:02:58,860 --> 00:03:04,290
savage revolutionaries they're

00:03:01,080 --> 00:03:08,180
disparaging the avocado order this hate

00:03:04,290 --> 00:03:08,180

YouTube URL: https://www.youtube.com/watch?v=GnBfGCUORK8


