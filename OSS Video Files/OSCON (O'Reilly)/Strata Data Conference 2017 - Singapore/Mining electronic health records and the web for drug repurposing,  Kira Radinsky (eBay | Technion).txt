Title: Mining electronic health records and the web for drug repurposing,  Kira Radinsky (eBay | Technion)
Publication date: 2017-12-07
Playlist: Strata Data Conference 2017 - Singapore
Description: 
	Check out all the Strata Data Conference keynotes, sessions, and tutorials here:
https://www.safaribooksonline.com/library/view/strata-data-conference/9781491985373/

Researchers decide on exploratory targets for drug repurposing—the process of applying known drugs in new ways to treat diseases—based on trends in research and observations on small numbers of cases, leading to potentially costly biases of focus and neglect. Kira Radinsky offers an overview of a system that jointly mines 10 years of nationwide medical records of more than 1.5 million people and extracts medical knowledge from Wikipedia to help reduce spurious correlations and provide guidance about drug repurposing. The resulting system seeks to identify potential biological processes to justify potential influences between medications and target diseases via links on a graph constructed from Wikipedia data. Kira shares results of the system on two studies on drug repurposing for hypertension and diabetes. In both cases, the algorithm identified drug families that were previously unknown, and clinical opinion by experts in the field and clinical trials on those drug families suggest that these drugs show promise.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:03,790 --> 00:00:10,059
the idea of applying large data finds on

00:00:07,480 --> 00:00:12,040
large query logs in order to predict

00:00:10,059 --> 00:00:14,470
events in the medical space it's also

00:00:12,040 --> 00:00:16,630
been applied in Google one of the first

00:00:14,470 --> 00:00:20,140
things that are trying to do is predict

00:00:16,630 --> 00:00:22,210
the flu do ristic was very simple if

00:00:20,140 --> 00:00:24,190
you're searching for the word flu you

00:00:22,210 --> 00:00:26,770
probably have flu and they showed that

00:00:24,190 --> 00:00:29,440
they were able to predict flu a drugs in

00:00:26,770 --> 00:00:31,000
the United States two weeks before the

00:00:29,440 --> 00:00:34,480
central of Disease Control could

00:00:31,000 --> 00:00:38,350
actually identify until one day the

00:00:34,480 --> 00:00:40,059
heuristic stopped working something

00:00:38,350 --> 00:00:45,280
happened that when you search for the

00:00:40,059 --> 00:00:47,319
word flu you stop having the flu and the

00:00:45,280 --> 00:00:50,139
exact event that happened was the swine

00:00:47,319 --> 00:00:51,879
flu people were searching for swine flu

00:00:50,139 --> 00:00:54,159
not because they had swine flu but only

00:00:51,879 --> 00:00:57,339
because they cared about the news and

00:00:54,159 --> 00:00:58,959
this is exactly the problem in many of

00:00:57,339 --> 00:01:00,819
the things we're doing data science and

00:00:58,959 --> 00:01:03,219
medicine and in all the other fields as

00:01:00,819 --> 00:01:06,430
well when identified correlations and

00:01:03,219 --> 00:01:08,260
not causation but in order to know what

00:01:06,430 --> 00:01:10,060
clinical trials to apply this stand

00:01:08,260 --> 00:01:12,760
causality in this space you need to go

00:01:10,060 --> 00:01:14,620
deeper and this is where I went to a

00:01:12,760 --> 00:01:17,590
deeper project trying to identify

00:01:14,620 --> 00:01:21,370
everything we know as humanity about

00:01:17,590 --> 00:01:23,800
causality for this I started taking data

00:01:21,370 --> 00:01:26,320
450 years of news articles billions of

00:01:23,800 --> 00:01:28,150
tweets and millions of web searches and

00:01:26,320 --> 00:01:29,730
I built an algorithm that actually reads

00:01:28,150 --> 00:01:33,520
all this information to identify

00:01:29,730 --> 00:01:35,650
causality so it wasn't the following way

00:01:33,520 --> 00:01:38,020
it would receive articles from the news

00:01:35,650 --> 00:01:39,760
for example here US Army bombs the

00:01:38,020 --> 00:01:42,760
weapon warehouse in Kabul with missiles

00:01:39,760 --> 00:01:45,100
it would apply deep natural-language on

00:01:42,760 --> 00:01:48,040
top of it to identify the actor the

00:01:45,100 --> 00:01:49,900
action the location and the instrument

00:01:48,040 --> 00:01:53,080
for example and then it would look for

00:01:49,900 --> 00:01:56,740
patterns that people actually wrote this

00:01:53,080 --> 00:01:58,990
causes that that happens after in this

00:01:56,740 --> 00:02:03,370
case this was identified to cause five

00:01:58,990 --> 00:02:05,220
of gun troops I created a graph of 300

00:02:03,370 --> 00:02:07,960
million mils and billions of edges

00:02:05,220 --> 00:02:09,970
having the entire human knowledge about

00:02:07,960 --> 00:02:11,889
causality which started growing more and

00:02:09,970 --> 00:02:13,599
more until we got more and more data

00:02:11,889 --> 00:02:16,049
sources even to the beginning of the

00:02:13,599 --> 00:02:16,049
century

00:02:22,050 --> 00:02:24,110

YouTube URL: https://www.youtube.com/watch?v=KTxB41qK2XE


