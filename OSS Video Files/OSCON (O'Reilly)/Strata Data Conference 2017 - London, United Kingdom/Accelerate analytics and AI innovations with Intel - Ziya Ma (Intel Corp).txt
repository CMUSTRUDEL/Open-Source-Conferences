Title: Accelerate analytics and AI innovations with Intel - Ziya Ma (Intel Corp)
Publication date: 2017-05-25
Playlist: Strata Data Conference 2017 - London, United Kingdom
Description: 
	We are in an era of big data, analytics, and artificial intelligence. Intelâ€™s vision is to provide the easiest, most secure, and most performant environment for its data customers and partners, from software to silicon. With AI becoming the next big wave in computing, many customers are adding AI workloads to their big data environment.

Ziya Ma outlines the challenges for applying machine learning and deep learning at scale and shares solutions that Intel has enabled for customers and partners, highlighting the BigDL Apache Spark project that Intel has recently open-sourced. BigDL is a unified analytics platform that can directly run on top of existing Spark or Hadoop clusters, giving customers a consistent and integrated experience for the entire learning process. Along the way, Ziya explains how Intel optimized solutions to help cloud businesses, financial services, manufacturing, and other companies to gain more insights and drive business differentiation and points to future trends and work in the space.

This keynote is sponsored by Intel.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:00,320 --> 00:00:06,529
good morning it's a great pleasure to be

00:00:03,350 --> 00:00:09,320
here in London you know earlier this

00:00:06,529 --> 00:00:12,590
year our CEO Brian krzanich

00:00:09,320 --> 00:00:16,460
has told the industry that Intel is a

00:00:12,590 --> 00:00:20,390
data company the girls in our data

00:00:16,460 --> 00:00:23,740
center and other businesses is driven by

00:00:20,390 --> 00:00:27,050
our industry's data transformation

00:00:23,740 --> 00:00:29,630
especially the need to gather a massive

00:00:27,050 --> 00:00:32,829
amount of data from people their

00:00:29,630 --> 00:00:36,170
computers and many connected devices and

00:00:32,829 --> 00:00:38,899
converts the data into powerful insights

00:00:36,170 --> 00:00:41,809
and intelligence for much improved

00:00:38,899 --> 00:00:45,859
decision-making and enhanced life

00:00:41,809 --> 00:00:50,299
experience throughout this data journey

00:00:45,859 --> 00:00:53,059
our commitment is always to enable the

00:00:50,299 --> 00:00:56,589
best experience for data and analytics

00:00:53,059 --> 00:00:59,949
for our customers at the hardware level

00:00:56,589 --> 00:01:03,440
we have been driving Silicon innovation

00:00:59,949 --> 00:01:07,040
delivering faster processors low latency

00:01:03,440 --> 00:01:09,640
fabrics and high-speed storage at the

00:01:07,040 --> 00:01:12,650
data platform level we have been

00:01:09,640 --> 00:01:14,780
optimizing Hadoop and a spark on Intel

00:01:12,650 --> 00:01:18,050
hardware for much improve the

00:01:14,780 --> 00:01:20,420
performance and security at the

00:01:18,050 --> 00:01:23,030
analytics level we have been

00:01:20,420 --> 00:01:27,280
accelerating Hadoop and spark based

00:01:23,030 --> 00:01:30,760
analytics deployment on Intel platform

00:01:27,280 --> 00:01:32,890
implementing large-scale distributed

00:01:30,760 --> 00:01:35,750
machine learning and deep learning

00:01:32,890 --> 00:01:40,730
deriving business value for our

00:01:35,750 --> 00:01:43,760
customers but really what is that best

00:01:40,730 --> 00:01:47,600
experience we're enabling for some

00:01:43,760 --> 00:01:50,480
customers it means high performance for

00:01:47,600 --> 00:01:54,800
instance by leveraging Intel math kernal

00:01:50,480 --> 00:01:56,780
library our customers enjoyed full x

00:01:54,800 --> 00:02:00,020
performance for SPARC machine learning

00:01:56,780 --> 00:02:02,810
workloads this optimization software has

00:02:00,020 --> 00:02:05,180
been merged to Apache upstream it's also

00:02:02,810 --> 00:02:09,259
available in the very recent cloud era

00:02:05,180 --> 00:02:12,950
release through HBase all hit read

00:02:09,259 --> 00:02:13,500
optimization we achieved five point six

00:02:12,950 --> 00:02:16,380
times

00:02:13,500 --> 00:02:20,100
performance and our customers like

00:02:16,380 --> 00:02:23,070
Alibaba were able to benefit Ali uses

00:02:20,100 --> 00:02:25,440
HBase as the data store for its

00:02:23,070 --> 00:02:28,920
real-time machine learning system

00:02:25,440 --> 00:02:32,670
it's HBase cluster has more than 1,500

00:02:28,920 --> 00:02:35,520
anodes and 200,000 regions with this

00:02:32,670 --> 00:02:38,220
optimization Annie had much more

00:02:35,520 --> 00:02:42,090
predictable latency and improved its

00:02:38,220 --> 00:02:46,980
throughput by 30% during singles day

00:02:42,090 --> 00:02:51,180
last year with Intel storage

00:02:46,980 --> 00:02:54,060
acceleration library HDFS a racial

00:02:51,180 --> 00:02:57,780
coding computing showed 19 times

00:02:54,060 --> 00:03:01,739
performance and 50% call saving for

00:02:57,780 --> 00:03:03,989
storage this software code also has been

00:03:01,739 --> 00:03:08,520
merged into Apache upstream it will be

00:03:03,989 --> 00:03:11,880
available in Hadoop 3.0 release for some

00:03:08,520 --> 00:03:15,360
customers best experience means strong

00:03:11,880 --> 00:03:19,250
security by using Intel security

00:03:15,360 --> 00:03:22,320
instruction set like AES and I our

00:03:19,250 --> 00:03:25,049
customers implemented much stronger

00:03:22,320 --> 00:03:31,590
encryption for SPARC shuffle and a spark

00:03:25,049 --> 00:03:35,670
RPC as well as achieving 28% and to end

00:03:31,590 --> 00:03:40,590
performance gain for some other

00:03:35,670 --> 00:03:44,190
customers best experience means best

00:03:40,590 --> 00:03:46,739
scalability we have helped online

00:03:44,190 --> 00:03:49,070
retailer to improve its analytics

00:03:46,739 --> 00:03:52,470
application and achieve the ten times

00:03:49,070 --> 00:03:56,220
scalability for its work to back machine

00:03:52,470 --> 00:03:58,500
learning and this online retailer is now

00:03:56,220 --> 00:04:01,130
able to analyze its customers shopping

00:03:58,500 --> 00:04:03,769
behavior and much more granular level

00:04:01,130 --> 00:04:06,630
recommend more relevant products and

00:04:03,769 --> 00:04:11,269
increase the likelihood of selling more

00:04:06,630 --> 00:04:15,870
goods we have supported Internet company

00:04:11,269 --> 00:04:19,169
to improve its analytics and achieve 70

00:04:15,870 --> 00:04:21,660
times scalability for its LD a machine

00:04:19,169 --> 00:04:24,720
learning for topic modeling and this

00:04:21,660 --> 00:04:27,270
customer is now able to analyze and

00:04:24,720 --> 00:04:30,449
train with 150

00:04:27,270 --> 00:04:33,210
million documents versus previously two

00:04:30,449 --> 00:04:36,780
million and handle one million topics

00:04:33,210 --> 00:04:41,400
and half a million vocabulary classified

00:04:36,780 --> 00:04:44,240
documents more accurately and quickly so

00:04:41,400 --> 00:04:47,220
we talked about enabling best

00:04:44,240 --> 00:04:50,430
performance scalability and a security

00:04:47,220 --> 00:04:54,240
is that all about the best experience

00:04:50,430 --> 00:04:56,819
were enabling in recent years some of

00:04:54,240 --> 00:04:58,620
our customers went beyond the

00:04:56,819 --> 00:05:00,569
traditional machine learning and started

00:04:58,620 --> 00:05:03,120
adding deep learning to their analytics

00:05:00,569 --> 00:05:06,720
they encountered several common

00:05:03,120 --> 00:05:10,380
challenges first working with

00:05:06,720 --> 00:05:13,680
distributed data customers source data

00:05:10,380 --> 00:05:15,900
is distributed lis stored and resides in

00:05:13,680 --> 00:05:20,430
distributed data platforms like Hadoop

00:05:15,900 --> 00:05:23,280
and a spark and this customers have

00:05:20,430 --> 00:05:26,669
already build and to ant analytics

00:05:23,280 --> 00:05:30,330
pipeline on top of that and they wanted

00:05:26,669 --> 00:05:32,789
leverage the existing cluster and just

00:05:30,330 --> 00:05:36,000
add deep learning to the existing

00:05:32,789 --> 00:05:40,409
pipeline and the second challenge is

00:05:36,000 --> 00:05:43,440
deep learning at a scale when scaling

00:05:40,409 --> 00:05:46,289
out deep learning on a cluster customers

00:05:43,440 --> 00:05:50,430
want to see choose data parallelism and

00:05:46,289 --> 00:05:53,130
model training parallelism and some of

00:05:50,430 --> 00:05:55,500
them try to integrate existing deep

00:05:53,130 --> 00:05:59,069
learning frameworks like cafe and a

00:05:55,500 --> 00:06:01,349
newer one with the spark hoping to

00:05:59,069 --> 00:06:03,900
leverage sparse data parallelism

00:06:01,349 --> 00:06:06,590
the challenge with this approach is that

00:06:03,900 --> 00:06:09,930
the existing deep learning frameworks

00:06:06,590 --> 00:06:12,240
were not designed for scale out all from

00:06:09,930 --> 00:06:15,870
working with spark newer integration

00:06:12,240 --> 00:06:19,139
with spark it's very superficial they're

00:06:15,870 --> 00:06:22,139
simply using spark as a dispatcher there

00:06:19,139 --> 00:06:25,440
is no data or model level integration of

00:06:22,139 --> 00:06:28,529
parallelism the third challenge is cost

00:06:25,440 --> 00:06:30,810
of ownership customers want to leverage

00:06:28,529 --> 00:06:33,300
their existing infrastructure for deep

00:06:30,810 --> 00:06:36,289
learning rather than building a brand

00:06:33,300 --> 00:06:39,440
new and expensive a cluster and

00:06:36,289 --> 00:06:41,400
performance is another consideration

00:06:39,440 --> 00:06:46,139
customers for instance want

00:06:41,400 --> 00:06:49,889
reduce their training cycle so to give

00:06:46,139 --> 00:06:52,320
customers the best experience we must

00:06:49,889 --> 00:06:55,400
address this new needs and this is

00:06:52,320 --> 00:06:58,650
exactly why we open source the big deal

00:06:55,400 --> 00:07:01,080
big deal is a distributed deep learning

00:06:58,650 --> 00:07:03,930
framework organically build on Apache

00:07:01,080 --> 00:07:07,259
spark it offers several significant

00:07:03,930 --> 00:07:09,570
benefits first it has feature parity

00:07:07,259 --> 00:07:13,530
with existing deep learning frameworks

00:07:09,570 --> 00:07:15,600
like a cafe torch and a newer ones and a

00:07:13,530 --> 00:07:19,860
second it works very well with

00:07:15,600 --> 00:07:22,110
distributed data big deal drives Hadoop

00:07:19,860 --> 00:07:26,130
and spark as the unified analytics

00:07:22,110 --> 00:07:28,260
platform giving customers the consistent

00:07:26,130 --> 00:07:32,100
and integrated pipeline for analytics

00:07:28,260 --> 00:07:34,470
from data ingest to data storage data

00:07:32,100 --> 00:07:38,060
processing traditional machine learning

00:07:34,470 --> 00:07:40,919
and deep learning and model serving and

00:07:38,060 --> 00:07:44,220
it scales out deep learning very

00:07:40,919 --> 00:07:48,720
efficiently big deal is organically

00:07:44,220 --> 00:07:51,650
build on Apache spark it's designed for

00:07:48,720 --> 00:07:54,780
data parallelism and model parallelism

00:07:51,650 --> 00:07:57,720
enabling efficient scale out fault

00:07:54,780 --> 00:08:01,530
tolerance elastic and dynamic resource

00:07:57,720 --> 00:08:04,080
management by keeping deep learning on

00:08:01,530 --> 00:08:07,650
the same cluster with the existing

00:08:04,080 --> 00:08:10,860
analytics pipeline customers avoid the

00:08:07,650 --> 00:08:13,370
need of building a new and separate

00:08:10,860 --> 00:08:16,560
cluster for deep learning as well as

00:08:13,370 --> 00:08:18,900
eliminates the need of moving large

00:08:16,560 --> 00:08:21,510
amount of data and models between two

00:08:18,900 --> 00:08:25,949
different hardware clusters reduce the

00:08:21,510 --> 00:08:28,740
total cost of ownership big deal offers

00:08:25,949 --> 00:08:31,680
high performance on Xeon clusters by

00:08:28,740 --> 00:08:36,599
using Intel optimized math kernal

00:08:31,680 --> 00:08:38,760
library ever since open source 2 at the

00:08:36,599 --> 00:08:42,320
beginning of the year we have seen

00:08:38,760 --> 00:08:45,080
speedy adoption from the industry

00:08:42,320 --> 00:08:48,709
top-tier cloud service providers like

00:08:45,080 --> 00:08:52,200
Amazon Microsoft and Alibaba

00:08:48,709 --> 00:08:54,670
have published tutorials on using big DL

00:08:52,200 --> 00:08:59,650
in their cloud offering for district

00:08:54,670 --> 00:09:01,990
deep-learning caldera included big deals

00:08:59,650 --> 00:09:05,830
in its data science workbench launched

00:09:01,990 --> 00:09:09,850
last month data breaks included big deal

00:09:05,830 --> 00:09:12,960
in data breaks platform customers from

00:09:09,850 --> 00:09:15,460
manufacturing and financial services

00:09:12,960 --> 00:09:17,650
production eyes and to any deep learning

00:09:15,460 --> 00:09:20,230
pipeline using spark and a big deal

00:09:17,650 --> 00:09:22,330
showing significant performance showing

00:09:20,230 --> 00:09:24,160
significant improvement for fraud

00:09:22,330 --> 00:09:27,070
detection and a manufacturing defect

00:09:24,160 --> 00:09:29,470
reduction we're also collaborating with

00:09:27,070 --> 00:09:34,780
customers from telco Enterprise

00:09:29,470 --> 00:09:37,870
government and healthcare not just a

00:09:34,780 --> 00:09:40,540
Hadoop spark and big deal we have a full

00:09:37,870 --> 00:09:46,360
stack of products for building AI

00:09:40,540 --> 00:09:49,180
solutions in our industry Intel is the

00:09:46,360 --> 00:09:53,700
one that can provide comprehensive

00:09:49,180 --> 00:09:55,570
technology portfolio from Ziya Xeon Phi

00:09:53,700 --> 00:09:58,360
FPGA to nirvana

00:09:55,570 --> 00:10:01,750
from computer to storage and a network

00:09:58,360 --> 00:10:03,760
at lower software level we improve

00:10:01,750 --> 00:10:07,330
performance for primitive functions

00:10:03,760 --> 00:10:11,020
through mkl and Dell at the framework

00:10:07,330 --> 00:10:15,510
level we optimize the most popular deep

00:10:11,020 --> 00:10:19,360
learning frameworks on our hardware and

00:10:15,510 --> 00:10:23,260
such as cafe nyan tensorflow and others

00:10:19,360 --> 00:10:26,740
at the application level we offer SDKs

00:10:23,260 --> 00:10:28,450
for developers to focus on real value

00:10:26,740 --> 00:10:32,940
added deep learning training and

00:10:28,450 --> 00:10:32,940
deployment with great productivity

00:10:34,680 --> 00:10:41,500
we're excited with what we can do for

00:10:37,660 --> 00:10:43,330
our customers in AI and analytics Intel

00:10:41,500 --> 00:10:46,030
has proven to be a leader and is

00:10:43,330 --> 00:10:49,360
uniquely positioned for democratizing

00:10:46,030 --> 00:10:51,040
technologies for AI and analytics we

00:10:49,360 --> 00:10:52,930
know the future because we're building

00:10:51,040 --> 00:10:56,170
it let's work together and build

00:10:52,930 --> 00:10:57,760
together so please visit our demo booths

00:10:56,170 --> 00:11:00,130
or join our technical sessions

00:10:57,760 --> 00:11:02,770
additional information is available at

00:11:00,130 --> 00:11:04,250
the URLs on this page with that thank

00:11:02,770 --> 00:11:06,310
you

00:11:04,250 --> 00:11:06,310

YouTube URL: https://www.youtube.com/watch?v=AXt_49hzvgY


