Title: The science of visual interactions - Miriam Redi (Bell Labs Cambridge, UK)
Publication date: 2017-05-24
Playlist: Strata Data Conference 2017 - London, United Kingdom
Description: 
	Miriam Redi explores the invisible side of visual data, investigating how machine learning can detect subjective properties of images and videos, such as beauty, creativity, sentiment, style, and more curious characteristics. Miriam shows how these detectors can be applied in the context of web media search, advertising, and social media and analyzes the precious contribution of computer vision in understanding how people and cultures perceive visual properties, underlining the importance of feature interpretability for this task.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:01,270 --> 00:00:05,109
let me just give you a couple of

00:00:02,950 --> 00:00:08,770
examples of what we can do with these

00:00:05,109 --> 00:00:10,330
subjects in machine vision techniques so

00:00:08,770 --> 00:00:13,300
click computational aesthetics for

00:00:10,330 --> 00:00:14,740
example this is one of the most popular

00:00:13,300 --> 00:00:17,680
branches of subjecting machine vision

00:00:14,740 --> 00:00:20,140
and it's about designing systems that

00:00:17,680 --> 00:00:23,009
given an image can automatically score

00:00:20,140 --> 00:00:25,180
it in terms of its beauty or

00:00:23,009 --> 00:00:28,980
photographic quality aesthetic appeal

00:00:25,180 --> 00:00:31,390
and in general this is done by

00:00:28,980 --> 00:00:33,820
operationalizing photographic theories

00:00:31,390 --> 00:00:36,100
into visual features into a computer

00:00:33,820 --> 00:00:37,899
vision framework so let me give you an

00:00:36,100 --> 00:00:40,929
example through a work we did in the

00:00:37,899 --> 00:00:42,969
Indies in this context and actually this

00:00:40,929 --> 00:00:46,420
is a computational aesthetic algorithm

00:00:42,969 --> 00:00:48,640
specific for a for a narrow image domain

00:00:46,420 --> 00:00:52,989
which is the domain of portraits so

00:00:48,640 --> 00:00:54,550
images with faces only so we design this

00:00:52,989 --> 00:00:56,920
computational portrait aesthetic

00:00:54,550 --> 00:01:00,399
framework able to score images of faces

00:00:56,920 --> 00:01:02,289
in terms of beauty note that we actually

00:01:00,399 --> 00:01:04,989
don't care whether the person depicted

00:01:02,289 --> 00:01:07,149
is beautiful or not you just want to

00:01:04,989 --> 00:01:09,159
know whether the image composition is

00:01:07,149 --> 00:01:12,159
beautiful knowing that there is a person

00:01:09,159 --> 00:01:14,710
in it and the reason why we actually

00:01:12,159 --> 00:01:17,229
need a specific framework for faces is

00:01:14,710 --> 00:01:21,520
that because we know from several series

00:01:17,229 --> 00:01:24,700
of faces occupy a specific place in our

00:01:21,520 --> 00:01:26,770
affective sphere we perceive faces in a

00:01:24,700 --> 00:01:29,020
completely different way compared to

00:01:26,770 --> 00:01:31,420
other objects and actually photographers

00:01:29,020 --> 00:01:34,180
when shooting pictures of people should

00:01:31,420 --> 00:01:37,329
follow specific portrait photography

00:01:34,180 --> 00:01:40,689
rules which convey the subject humanity

00:01:37,329 --> 00:01:43,229
and so what we did is that we took a

00:01:40,689 --> 00:01:46,450
large data set of images annotated with

00:01:43,229 --> 00:01:49,600
Beauty degrees by humans and then we

00:01:46,450 --> 00:01:52,600
design and compute features inspired by

00:01:49,600 --> 00:01:55,180
poetry photography this means that we

00:01:52,600 --> 00:01:57,789
not each of the rules that photographer

00:01:55,180 --> 00:02:00,460
follows to shoot good portraits into the

00:01:57,789 --> 00:02:04,060
visual features into a number able to

00:02:00,460 --> 00:02:06,490
describe an aspect of the image and then

00:02:04,060 --> 00:02:08,259
we give all these features that are

00:02:06,490 --> 00:02:10,720
built on top of deep learning frameworks

00:02:08,259 --> 00:02:12,370
to a machine learning algorithm which

00:02:10,720 --> 00:02:14,530
will be able to distinguishing between

00:02:12,370 --> 00:02:17,440
good and bad portraits

00:02:14,530 --> 00:02:19,870
and not only this algorithm works well

00:02:17,440 --> 00:02:22,690
for this task but also because we

00:02:19,870 --> 00:02:24,490
carefully designed our features to be

00:02:22,690 --> 00:02:27,070
interpretable and to directly map

00:02:24,490 --> 00:02:29,170
portrait photography rules we can also

00:02:27,070 --> 00:02:30,370
understand what makes a portrait

00:02:29,170 --> 00:02:33,250
beautiful from an algorithmic

00:02:30,370 --> 00:02:36,010
perspective so for example things like

00:02:33,250 --> 00:02:38,590
the sharpness of the face landmarks eyes

00:02:36,010 --> 00:02:40,990
and nose are positively indicators

00:02:38,590 --> 00:02:43,030
positive indicators off of portrait

00:02:40,990 --> 00:02:45,820
beauty then there are group of features

00:02:43,030 --> 00:02:47,680
is a positive indicator of portrait

00:02:45,820 --> 00:02:49,750
beauty and there is a third group of

00:02:47,680 --> 00:02:51,970
features which actually we can literally

00:02:49,750 --> 00:02:53,950
put in the trash because they are not

00:02:51,970 --> 00:02:55,989
predictive at all for portrait beauty

00:02:53,950 --> 00:02:59,020
but actually those are demographic

00:02:55,989 --> 00:03:01,690
features so this tells us that no matter

00:02:59,020 --> 00:03:04,420
the age the race or the gender of the

00:03:01,690 --> 00:03:07,120
person depicted if the photographer does

00:03:04,420 --> 00:03:09,430
a good artistic job then the resulting

00:03:07,120 --> 00:03:12,570
fortune will be beautiful which i think

00:03:09,430 --> 00:03:12,570

YouTube URL: https://www.youtube.com/watch?v=l4aL8r8fCjw


