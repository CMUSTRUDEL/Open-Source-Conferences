Title: Machine learning challenges at LinkedIn: Spark, TensorFlow, and beyond, Zhe Zhang (LinkedIn)
Publication date: 2019-10-17
Playlist: O'Reilly Artificial Intelligence Conference 2019 - London, UK
Description: 
	From people you may know (PYMK) to economic graph research, machine learning is the oxygen that powers how LinkedIn serves its 630M+ members.
Zhe Zhang provides you with an architectural overview of LinkedIn’s typical machine learning pipelines complemented with key types of ML use cases. He explores the changes and challenges brought in by the emergence of deep learning techniques, including hardware (GPU, networking), data, tooling, and language (Python and C++ versus Java and Scala). You’ll be introduced to the ongoing work of establishing a unified ML infrastructure based on Spark and TensorFlow, which offers high performance and efficiency together with ease of use.


Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,730 --> 00:00:05,380
and now I'd like to give an overview of

00:00:03,520 --> 00:00:08,290
the typical machine learning development

00:00:05,380 --> 00:00:11,770
process at Lincoln the first stage is

00:00:08,290 --> 00:00:14,049
idea the machine learning engineer will

00:00:11,770 --> 00:00:14,889
have an idea of how to how to improve

00:00:14,049 --> 00:00:17,289
the product

00:00:14,889 --> 00:00:20,589
this is typically tied to the business

00:00:17,289 --> 00:00:22,960
logic of the product for example and

00:00:20,589 --> 00:00:25,240
engineer might be having a Nydia of

00:00:22,960 --> 00:00:28,060
using a deep learning model to extract

00:00:25,240 --> 00:00:29,769
useful information from a job post to

00:00:28,060 --> 00:00:32,380
improve the accuracy of job

00:00:29,769 --> 00:00:34,960
documentation and then the next stage is

00:00:32,380 --> 00:00:37,000
research for any given idea

00:00:34,960 --> 00:00:40,359
there must be existing solutions in the

00:00:37,000 --> 00:00:42,100
community so in this case the engineer

00:00:40,359 --> 00:00:44,260
would do research and find out the

00:00:42,100 --> 00:00:45,879
machining a measure that can be used to

00:00:44,260 --> 00:00:49,030
do this type of natural language

00:00:45,879 --> 00:00:51,850
processing for example bird and the next

00:00:49,030 --> 00:00:53,559
stage is opportunity analysis the

00:00:51,850 --> 00:00:57,989
engineer needs to do a preliminary

00:00:53,559 --> 00:01:01,480
analysis to see the scope of applicable

00:00:57,989 --> 00:01:03,280
area for this method if this particular

00:01:01,480 --> 00:01:06,940
method can only be applied for example

00:01:03,280 --> 00:01:09,940
to a small portion of job posting then

00:01:06,940 --> 00:01:11,260
the opportunity is limited if the

00:01:09,940 --> 00:01:13,870
opportunity is verified

00:01:11,260 --> 00:01:16,600
we entered the expensive phase of a fly

00:01:13,870 --> 00:01:18,040
experiment for alpha experiment the

00:01:16,600 --> 00:01:21,000
machine learning engineer need to

00:01:18,040 --> 00:01:23,590
provide an implementation of different

00:01:21,000 --> 00:01:25,060
different methods for example the

00:01:23,590 --> 00:01:27,220
machine learning engineer need to build

00:01:25,060 --> 00:01:29,710
a data pipeline to generate the features

00:01:27,220 --> 00:01:31,090
the labels and need to provide an

00:01:29,710 --> 00:01:33,580
implementation for the machine learning

00:01:31,090 --> 00:01:37,510
model and algorithms the model is a

00:01:33,580 --> 00:01:39,070
format and the algorithm specifies how

00:01:37,510 --> 00:01:43,270
to update the parameters of the model

00:01:39,070 --> 00:01:44,920
over input data and then the machine

00:01:43,270 --> 00:01:46,450
learning training need to be repeated

00:01:44,920 --> 00:01:48,010
many many times with different

00:01:46,450 --> 00:01:50,800
configurations including hyper

00:01:48,010 --> 00:01:53,530
parameters and this process is highly

00:01:50,800 --> 00:01:56,440
iterative and then we have the offline

00:01:53,530 --> 00:02:00,640
evaluation based to evaluate the model

00:01:56,440 --> 00:02:03,580
based on past a past a few days or few

00:02:00,640 --> 00:02:05,980
weeks of offline data if the offline

00:02:03,580 --> 00:02:08,619
evaluation turns out to improve metrics

00:02:05,980 --> 00:02:10,929
then we can go to the online deployment

00:02:08,619 --> 00:02:13,510
process of production Eliza did the

00:02:10,929 --> 00:02:14,010
model verify the model deploy model and

00:02:13,510 --> 00:02:16,739
to

00:02:14,010 --> 00:02:19,950
maybe test grungey gradually ramp up to

00:02:16,739 --> 00:02:22,230
majority member experience if it turns

00:02:19,950 --> 00:02:24,659
out to improve online metrics then we

00:02:22,230 --> 00:02:27,230
call it success otherwise we turn to the

00:02:24,659 --> 00:02:27,230
beginning

00:02:33,210 --> 00:02:35,270

YouTube URL: https://www.youtube.com/watch?v=U2rsGcu-s_4


