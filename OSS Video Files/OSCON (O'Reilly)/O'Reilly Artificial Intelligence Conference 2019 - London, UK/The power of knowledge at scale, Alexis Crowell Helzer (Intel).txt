Title: The power of knowledge at scale, Alexis Crowell Helzer (Intel)
Publication date: 2019-10-16
Playlist: O'Reilly Artificial Intelligence Conference 2019 - London, UK
Description: 
	The industrial revolution scaled output and productivity to new heights. The Internet revolution did the same for access to information. Now, the AI revolution is poised to scale both machine and human knowledge. To generate that knowledge, companies must think differently about AI and how to deploy it. Alexis will cover the three “Be’s”, and how to approach AI systematically to truly harness knowledge at scale.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,740 --> 00:00:06,090
I call them three bees right it's a

00:00:03,840 --> 00:00:09,110
super simple right three bees first just

00:00:06,090 --> 00:00:12,840
be thoughtful and what I mean by that is

00:00:09,110 --> 00:00:15,240
we really do need to think through the

00:00:12,840 --> 00:00:17,670
smallest and maybe the easiest lowest

00:00:15,240 --> 00:00:19,410
hanging fruit to tackle right if you're

00:00:17,670 --> 00:00:21,270
teaching your child how to ride a bike

00:00:19,410 --> 00:00:22,680
you're not gonna throw them on a bike

00:00:21,270 --> 00:00:25,110
shove them down a hill and hope that

00:00:22,680 --> 00:00:27,000
they succeed that doesn't make any sense

00:00:25,110 --> 00:00:28,770
you're gonna take him into your garden

00:00:27,000 --> 00:00:31,349
you're gonna take him into your driveway

00:00:28,770 --> 00:00:33,630
put a helmet on them in my case my kids

00:00:31,349 --> 00:00:36,719
got knee pads and elbow pads too just in

00:00:33,630 --> 00:00:38,309
case I and we're gonna teach them we're

00:00:36,719 --> 00:00:41,820
gonna stay with them we're gonna follow

00:00:38,309 --> 00:00:44,850
them through their learning process a is

00:00:41,820 --> 00:00:47,670
no different choose a data problem and

00:00:44,850 --> 00:00:50,280
then stick with it right do something

00:00:47,670 --> 00:00:53,309
that's small enough to be meaningful but

00:00:50,280 --> 00:00:55,800
not large enough that it actually causes

00:00:53,309 --> 00:00:58,230
indecision there's an interesting

00:00:55,800 --> 00:01:01,530
balance there right so small enough to

00:00:58,230 --> 00:01:06,840
be meaningful but not so big that you

00:01:01,530 --> 00:01:08,460
can't go forward the second thing so be

00:01:06,840 --> 00:01:12,810
thoughtful is to start the second thing

00:01:08,460 --> 00:01:14,939
is to be secure in an IT we all know

00:01:12,810 --> 00:01:18,810
this security is more important today

00:01:14,939 --> 00:01:21,299
than it ever has been in an AI I can't

00:01:18,810 --> 00:01:25,049
stress the importance of building this

00:01:21,299 --> 00:01:26,219
into your process at the beginning so as

00:01:25,049 --> 00:01:27,619
you're thinking through what data

00:01:26,219 --> 00:01:29,490
challenge you even want to go after

00:01:27,619 --> 00:01:32,759
security needs to be at the forefront

00:01:29,490 --> 00:01:35,340
and there's multiple levels right it's

00:01:32,759 --> 00:01:37,649
not just securing your hardware although

00:01:35,340 --> 00:01:40,200
that's incredibly important in AI you

00:01:37,649 --> 00:01:42,659
have to secure your data and you have to

00:01:40,200 --> 00:01:45,479
secure your model and what I mean by

00:01:42,659 --> 00:01:46,979
that is how do you ensure as you're

00:01:45,479 --> 00:01:49,409
going through your data collection phase

00:01:46,979 --> 00:01:51,210
that it's the data that you need want

00:01:49,409 --> 00:01:53,549
and is appropriate for what you're

00:01:51,210 --> 00:01:56,700
building and that no one can insert

00:01:53,549 --> 00:01:59,520
false positives or false training data

00:01:56,700 --> 00:02:02,189
that could skew your output but then on

00:01:59,520 --> 00:02:04,590
the model side once you've built that

00:02:02,189 --> 00:02:06,450
model how are you ensuring no one's

00:02:04,590 --> 00:02:09,450
tampering with it they're not changing

00:02:06,450 --> 00:02:11,520
your weights they're not changing how

00:02:09,450 --> 00:02:14,569
that model behaves with a certain input

00:02:11,520 --> 00:02:16,950
and skewing your output

00:02:14,569 --> 00:02:20,310
security has never been more important

00:02:16,950 --> 00:02:24,410
in technology and in AI it's at the

00:02:20,310 --> 00:02:28,680
utmost of importance so be thoughtful be

00:02:24,410 --> 00:02:30,000
secure and be transparent and I'm gonna

00:02:28,680 --> 00:02:34,470
cheat a little bit because there's a few

00:02:30,000 --> 00:02:38,040
levels to transparency but transparency

00:02:34,470 --> 00:02:40,470
is about your data to begin with so

00:02:38,040 --> 00:02:43,260
there's a ton of conversations around

00:02:40,470 --> 00:02:45,450
ethics right now and they're all very

00:02:43,260 --> 00:02:47,519
valid you know the world is incredibly

00:02:45,450 --> 00:02:49,769
nuanced it's gonna be the same within

00:02:47,519 --> 00:02:52,890
this space but what I mean by

00:02:49,769 --> 00:02:55,650
transparency of your data is by knowing

00:02:52,890 --> 00:02:57,750
what's really going into your models and

00:02:55,650 --> 00:03:00,090
it's interesting we recently

00:02:57,750 --> 00:03:02,340
participated in a study that looked at a

00:03:00,090 --> 00:03:05,280
number hundreds of customers that have

00:03:02,340 --> 00:03:09,810
implemented AI at some level some POC

00:03:05,280 --> 00:03:13,650
simple deployments and we asked how many

00:03:09,810 --> 00:03:18,209
of you have trained your AI practitioner

00:03:13,650 --> 00:03:20,549
on ethics there were a good a good

00:03:18,209 --> 00:03:22,920
majority of them that responded yes but

00:03:20,549 --> 00:03:26,549
then we correlated that with now how

00:03:22,920 --> 00:03:30,810
many of you actually had a successful

00:03:26,549 --> 00:03:32,280
implementation and as you can see 92% of

00:03:30,810 --> 00:03:34,560
the companies that were successful in

00:03:32,280 --> 00:03:37,489
their implementations had trained their

00:03:34,560 --> 00:03:37,489

YouTube URL: https://www.youtube.com/watch?v=GCte945Mqqk


