Title: Evolve AI - Naveen Rao (Intel)
Publication date: 2017-06-30
Playlist: O'Reilly Artificial Intelligence Conference 2017 - New York, New York
Description: 
	Naveen Rao explains how Intel Nervana is evolving the AI stack from silicon all the way to the cloud so that true AI transformation can happen across every experience and every vertical.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:04,160 --> 00:00:09,170
morning everyone I hope everyone's a

00:00:07,519 --> 00:00:10,820
little bit awake I'm from the west coast

00:00:09,170 --> 00:00:13,130
so it's a little bit early for us a copy

00:00:10,820 --> 00:00:16,340
ran out earlier - so is this a bad

00:00:13,130 --> 00:00:17,300
combination of things anyway so I'm

00:00:16,340 --> 00:00:19,369
going to talk to you a little bit about

00:00:17,300 --> 00:00:20,930
some of the some of the some exciting

00:00:19,369 --> 00:00:23,570
things that are happening at Intel

00:00:20,930 --> 00:00:26,689
nirvana this is the the new AI brand

00:00:23,570 --> 00:00:28,460
that we're launching from himself so

00:00:26,689 --> 00:00:30,349
it's really an exciting time to be in

00:00:28,460 --> 00:00:32,360
the industry I mean things that we were

00:00:30,349 --> 00:00:34,670
we thought were next to impossible five

00:00:32,360 --> 00:00:36,080
or six years ago are now actually quite

00:00:34,670 --> 00:00:38,149
easy in fact we're taking it for granted

00:00:36,080 --> 00:00:39,730
how easy we can build an image

00:00:38,149 --> 00:00:42,739
classifier that beats human performance

00:00:39,730 --> 00:00:44,809
I mean think about that from computer

00:00:42,739 --> 00:00:47,450
science class that you took 10 years ago

00:00:44,809 --> 00:00:49,730
that was just not a possible task so I

00:00:47,450 --> 00:00:51,320
think I just I hope everyone can

00:00:49,730 --> 00:00:53,030
appreciate kind of what what kind of

00:00:51,320 --> 00:00:55,010
transformations happen in the last few

00:00:53,030 --> 00:00:56,690
years and so we start seeing use cases

00:00:55,010 --> 00:00:58,640
in industry some of the things we're

00:00:56,690 --> 00:01:00,920
scrolling through here they're becoming

00:00:58,640 --> 00:01:02,629
commonplace and you know it's been said

00:01:00,920 --> 00:01:05,449
that technology when it's when it's

00:01:02,629 --> 00:01:07,130
really fully developed kind of you know

00:01:05,449 --> 00:01:08,869
used into the background and I think

00:01:07,130 --> 00:01:15,319
we're seeing seeing that right now with

00:01:08,869 --> 00:01:18,080
AI so it's like a little bit about what

00:01:15,319 --> 00:01:19,640
powered this this revolution I think

00:01:18,080 --> 00:01:21,890
there are three main things that I see

00:01:19,640 --> 00:01:23,750
Moore's law is actually one of them they

00:01:21,890 --> 00:01:25,220
capability to iterate build these

00:01:23,750 --> 00:01:28,009
gradient descent algorithms that

00:01:25,220 --> 00:01:30,470
actually find these useful solutions in

00:01:28,009 --> 00:01:33,470
these very large parameter spaces is

00:01:30,470 --> 00:01:35,690
something that is underappreciated we

00:01:33,470 --> 00:01:36,819
really didn't have that capability 10-15

00:01:35,690 --> 00:01:39,259
years ago

00:01:36,819 --> 00:01:41,300
silicon got to a point where we actually

00:01:39,259 --> 00:01:43,429
could stuff enough transistors onto a

00:01:41,300 --> 00:01:45,349
chip and build something that's fast

00:01:43,429 --> 00:01:49,819
enough and can do enough compute cycles

00:01:45,349 --> 00:01:52,640
on a large data set the next piece of

00:01:49,819 --> 00:01:55,069
that is data itself so I think the last

00:01:52,640 --> 00:01:56,840
15 years probably you could say we spent

00:01:55,069 --> 00:01:58,729
a lot of money on data storage

00:01:56,840 --> 00:02:00,800
every Enterprise company out there has

00:01:58,729 --> 00:02:03,140
you know huge storage arrays cloud

00:02:00,800 --> 00:02:06,170
computing became prevalent storing data

00:02:03,140 --> 00:02:07,910
became cheap and that enabled us in

00:02:06,170 --> 00:02:09,619
conjunction with compute to start

00:02:07,910 --> 00:02:10,940
building these kinds of models and I

00:02:09,619 --> 00:02:12,680
think this is how we're really going to

00:02:10,940 --> 00:02:15,410
start approaching intelligence is the

00:02:12,680 --> 00:02:17,560
data plus a compute another very

00:02:15,410 --> 00:02:19,120
important piece of it is also the demand

00:02:17,560 --> 00:02:20,560
as I mentioned you know we're talking

00:02:19,120 --> 00:02:22,360
about all these products now we kind of

00:02:20,560 --> 00:02:23,709
take it for granted we want our we want

00:02:22,360 --> 00:02:25,209
our products to recognize their voice in

00:02:23,709 --> 00:02:27,310
fact we actually now kind of wanted

00:02:25,209 --> 00:02:29,020
products to get better at at things as

00:02:27,310 --> 00:02:31,330
we use them right that's actually not so

00:02:29,020 --> 00:02:32,800
easy I want my phone to understand me

00:02:31,330 --> 00:02:34,600
better than understand every one of you

00:02:32,800 --> 00:02:37,239
is that really that easy to do not

00:02:34,600 --> 00:02:38,530
really we're working on it and I think

00:02:37,239 --> 00:02:39,850
these techniques are maturing to the

00:02:38,530 --> 00:02:41,830
point where we can actually start

00:02:39,850 --> 00:02:43,120
satisfying that demand but the reason

00:02:41,830 --> 00:02:44,500
everyone is here today is because this

00:02:43,120 --> 00:02:50,550
is exciting and everyone wants to see

00:02:44,500 --> 00:02:52,569
these kind of things construing so this

00:02:50,550 --> 00:02:55,030
one of the big motivators for me and

00:02:52,569 --> 00:02:57,190
this has actually been that I in this

00:02:55,030 --> 00:02:58,630
field of AI is that you know we look at

00:02:57,190 --> 00:03:01,450
a brain so on the left there we have

00:02:58,630 --> 00:03:03,510
some cool-looking neurons right and your

00:03:01,450 --> 00:03:05,950
brain used about 20 watts of energy

00:03:03,510 --> 00:03:08,110
that's not a lot all right so just to

00:03:05,950 --> 00:03:10,510
kind of calibrate people your CPU and

00:03:08,110 --> 00:03:12,489
your laptop is using you know 20 to 40

00:03:10,510 --> 00:03:14,680
watts of energy presumably your brain is

00:03:12,489 --> 00:03:16,180
doing more computation then your then

00:03:14,680 --> 00:03:20,769
your laptop is maybe that's not true for

00:03:16,180 --> 00:03:22,650
everyone but probably not for me without

00:03:20,769 --> 00:03:25,690
coffee this morning

00:03:22,650 --> 00:03:27,160
but I think that's that's just that very

00:03:25,690 --> 00:03:28,480
simple fact it's been a huge motivator

00:03:27,160 --> 00:03:28,750
for me in this field like how can we do

00:03:28,480 --> 00:03:31,090
better

00:03:28,750 --> 00:03:33,190
clearly synthetic computation can get

00:03:31,090 --> 00:03:34,799
better and we have a long way to go we

00:03:33,190 --> 00:03:41,470
have an existence proof in our heads

00:03:34,799 --> 00:03:43,630
today that we can do this better so what

00:03:41,470 --> 00:03:44,980
is intelligence really so it's really

00:03:43,630 --> 00:03:46,959
the ability to take in information

00:03:44,980 --> 00:03:49,299
through our senses so it brains due

00:03:46,959 --> 00:03:52,870
process it find some useful structure in

00:03:49,299 --> 00:03:55,030
it and drive a useful output in the

00:03:52,870 --> 00:03:56,230
context of an animal humans or any other

00:03:55,030 --> 00:03:59,109
animal it's really about survival

00:03:56,230 --> 00:04:01,019
finding food you know these kinds of

00:03:59,109 --> 00:04:05,170
things surviving through the world

00:04:01,019 --> 00:04:06,819
evading predators but in industry we're

00:04:05,170 --> 00:04:09,579
looking for ways to improve businesses

00:04:06,819 --> 00:04:13,060
and I think the same sense process Act

00:04:09,579 --> 00:04:14,350
actually exists there as well and so the

00:04:13,060 --> 00:04:16,750
tools we're building are going to make

00:04:14,350 --> 00:04:19,000
that easy and accessible for the rest of

00:04:16,750 --> 00:04:20,530
industry not just in the realm of you

00:04:19,000 --> 00:04:22,709
know the biggest high-tech players out

00:04:20,530 --> 00:04:22,709
there

00:04:31,650 --> 00:04:37,090
so until Nirvana we think of this as a

00:04:35,169 --> 00:04:38,830
holistic picture we call it speeding up

00:04:37,090 --> 00:04:40,210
the innovation cycle and what I mean by

00:04:38,830 --> 00:04:42,729
that is really taking this whole loop

00:04:40,210 --> 00:04:46,120
where we we bring data and call that the

00:04:42,729 --> 00:04:47,620
sensing part we process it that's the

00:04:46,120 --> 00:04:49,539
deep learning and the AI card that we're

00:04:47,620 --> 00:04:51,639
all excited about is the action piece

00:04:49,539 --> 00:04:53,979
right we need to deploy these solutions

00:04:51,639 --> 00:04:56,110
in some useful fashion whether it be a

00:04:53,979 --> 00:04:57,490
data center where we're lunging through

00:04:56,110 --> 00:04:59,860
a bunch of data we're putting out a

00:04:57,490 --> 00:05:01,509
phone to enable a new experience or

00:04:59,860 --> 00:05:04,270
we're driving a new website experience

00:05:01,509 --> 00:05:06,159
so it's a very similar similar thing

00:05:04,270 --> 00:05:08,199
that we see in nature and we're seeing

00:05:06,159 --> 00:05:10,750
that happen now here and I think what's

00:05:08,199 --> 00:05:12,849
going to drive this forward is obviously

00:05:10,750 --> 00:05:14,440
the tip of the spear research is always

00:05:12,849 --> 00:05:15,880
extremely important what we've actually

00:05:14,440 --> 00:05:18,190
hit a critical mass now that I think we

00:05:15,880 --> 00:05:20,050
we understand enough about some of the

00:05:18,190 --> 00:05:21,940
computational primitives that actually

00:05:20,050 --> 00:05:23,800
allow us to solve these kind of problems

00:05:21,940 --> 00:05:26,259
in the real world so now it's really

00:05:23,800 --> 00:05:28,750
about tools making it easy and

00:05:26,259 --> 00:05:31,030
accessible bringing the cost of things

00:05:28,750 --> 00:05:33,250
down right now it's still very difficult

00:05:31,030 --> 00:05:35,409
to scale AI solutions I mean some

00:05:33,250 --> 00:05:37,659
companies out there are very good at it

00:05:35,409 --> 00:05:39,250
because they have bespoke experts

00:05:37,659 --> 00:05:42,479
working on these things we really want

00:05:39,250 --> 00:05:42,479
to make this easier for people to use

00:05:44,069 --> 00:05:49,419
so one thing also is competition in this

00:05:47,289 --> 00:05:52,840
space is actually a very important thing

00:05:49,419 --> 00:05:54,969
we need different suppliers building

00:05:52,840 --> 00:05:56,680
solutions and and competing against each

00:05:54,969 --> 00:05:59,139
other to drive the field forward I'm a

00:05:56,680 --> 00:06:00,639
big believer in that and so important

00:05:59,139 --> 00:06:03,039
metrics for what we're building are

00:06:00,639 --> 00:06:04,690
actually a very important thing you know

00:06:03,039 --> 00:06:07,539
we've talked about swaps you know

00:06:04,690 --> 00:06:09,219
floating point opts for second as a big

00:06:07,539 --> 00:06:10,750
metric out there you know that's

00:06:09,219 --> 00:06:15,639
something that I actually find a little

00:06:10,750 --> 00:06:17,529
bit lacking because it's not a really

00:06:15,639 --> 00:06:20,409
good metric of real-world performance

00:06:17,529 --> 00:06:22,360
the consequence that has is that you

00:06:20,409 --> 00:06:24,460
tend to see people optimizing for

00:06:22,360 --> 00:06:26,680
metrics that people that that drive

00:06:24,460 --> 00:06:28,419
buying decisions so we actually put

00:06:26,680 --> 00:06:30,009
forward two new metrics that I'll talk

00:06:28,419 --> 00:06:32,229
about in just a moment the three major

00:06:30,009 --> 00:06:34,089
components are memory bandwidth this is

00:06:32,229 --> 00:06:36,070
basically how much data you can shove

00:06:34,089 --> 00:06:38,490
into and get out as memory it's close to

00:06:36,070 --> 00:06:38,490
a chip

00:06:38,920 --> 00:06:44,420
precision this is basically how many

00:06:41,690 --> 00:06:46,460
bits we represent each of our operations

00:06:44,420 --> 00:06:48,350
with neural networks are actually very

00:06:46,460 --> 00:06:53,180
good and tolerant to the kind of noise

00:06:48,350 --> 00:06:55,310
that low precision adds to their to the

00:06:53,180 --> 00:06:56,780
training regime so unlike other types of

00:06:55,310 --> 00:06:57,920
computation scientific and scientific

00:06:56,780 --> 00:07:00,350
computing for instance where we need

00:06:57,920 --> 00:07:02,570
very high fidelity to a you know a real

00:07:00,350 --> 00:07:03,920
number in neural networks we can

00:07:02,570 --> 00:07:04,970
actually get away with lower bit

00:07:03,920 --> 00:07:09,410
Precision's and actually get some

00:07:04,970 --> 00:07:11,210
advantages from doing that and the last

00:07:09,410 --> 00:07:13,160
piece of utilize hops so what I mean by

00:07:11,210 --> 00:07:15,050
that is how many of these operations per

00:07:13,160 --> 00:07:16,460
second in this precision through this

00:07:15,050 --> 00:07:19,580
memory bandwidth can you realistically

00:07:16,460 --> 00:07:21,320
do and so we've related together with

00:07:19,580 --> 00:07:23,750
something that we coined called

00:07:21,320 --> 00:07:26,330
computational capacity and so basically

00:07:23,750 --> 00:07:30,380
we're taking the precision which is B

00:07:26,330 --> 00:07:32,330
memory bandwidth as M times the utilize

00:07:30,380 --> 00:07:33,650
ops and so this is kind of a metric that

00:07:32,330 --> 00:07:35,330
I think is actually pretty useful for

00:07:33,650 --> 00:07:37,310
comparing various hardware platforms out

00:07:35,330 --> 00:07:38,960
there if people start optimizing around

00:07:37,310 --> 00:07:41,030
something like this for their for their

00:07:38,960 --> 00:07:43,910
hardware stack we actually have I think

00:07:41,030 --> 00:07:46,419
more relevant solutions and in the

00:07:43,910 --> 00:07:46,419
industry today

00:07:47,290 --> 00:07:52,040
so beyond Hardware the next piece of

00:07:50,150 --> 00:07:54,500
software as I mentioned tool is super

00:07:52,040 --> 00:07:56,210
important here this is something that

00:07:54,500 --> 00:07:58,460
again we we're very excited about

00:07:56,210 --> 00:08:01,820
because we actually just released a few

00:07:58,460 --> 00:08:04,550
big tools today one of them is Intel

00:08:01,820 --> 00:08:06,410
nirvana graph so what this is it's a

00:08:04,550 --> 00:08:08,720
it's a built it's a it's a layer that

00:08:06,410 --> 00:08:10,669
abstract hardware to some extent it's a

00:08:08,720 --> 00:08:12,620
graph execution layer and you can find

00:08:10,669 --> 00:08:16,610
more information on this and at Intel

00:08:12,620 --> 00:08:18,470
Nirvana comm it's something that enabled

00:08:16,610 --> 00:08:23,180
us to support many different hardware

00:08:18,470 --> 00:08:25,430
platforms with an abstraction of basic

00:08:23,180 --> 00:08:26,900
primitives from various deep learning

00:08:25,430 --> 00:08:29,330
framework so the idea that we can

00:08:26,900 --> 00:08:31,940
support tensorflow or neon which is our

00:08:29,330 --> 00:08:34,070
framework on multiple hardware platforms

00:08:31,940 --> 00:08:35,990
without having to optimize for each one

00:08:34,070 --> 00:08:37,880
of those frameworks over and over again

00:08:35,990 --> 00:08:39,380
this is super important important again

00:08:37,880 --> 00:08:42,620
for the industry because we're

00:08:39,380 --> 00:08:43,909
supporting our own hardware until CPUs

00:08:42,620 --> 00:08:47,480
as well as a new stuff we have coming

00:08:43,909 --> 00:08:50,320
out as well as competitors GPUs FPGAs

00:08:47,480 --> 00:08:50,320
things like that

00:08:52,449 --> 00:08:57,470
and so it's part of this our framework

00:08:56,000 --> 00:08:59,959
we call it our reference standard for

00:08:57,470 --> 00:09:02,589
framework it's called neon we have to

00:08:59,959 --> 00:09:06,260
just release 2.0 today which will be

00:09:02,589 --> 00:09:07,670
supporting intel architecture CPUs and a

00:09:06,260 --> 00:09:10,040
highly optimized fashion on top of em

00:09:07,670 --> 00:09:12,980
kale so please go check it out on github

00:09:10,040 --> 00:09:15,949
feel free to start it

00:09:12,980 --> 00:09:17,269
I put my shameless plug in there but

00:09:15,949 --> 00:09:18,470
yeah we're very excited about getting

00:09:17,269 --> 00:09:21,740
these things out into the world because

00:09:18,470 --> 00:09:23,839
as as we are able to add new models and

00:09:21,740 --> 00:09:25,370
and build the community around it we can

00:09:23,839 --> 00:09:27,740
really make it easier and accessible

00:09:25,370 --> 00:09:29,000
across this entire stack you'll start

00:09:27,740 --> 00:09:34,760
seeing more more announcements from us

00:09:29,000 --> 00:09:36,949
in the next few months so we're seeing

00:09:34,760 --> 00:09:39,019
this cycle happening already actually

00:09:36,949 --> 00:09:41,240
it's actually something we started at

00:09:39,019 --> 00:09:43,010
Nirvana the startup that I co-founded

00:09:41,240 --> 00:09:44,329
and we're continuing now as part of

00:09:43,010 --> 00:09:48,589
Intel we're actually seeing these

00:09:44,329 --> 00:09:50,360
verticals start to take up AI in a big

00:09:48,589 --> 00:09:52,790
way and I think it's because it really

00:09:50,360 --> 00:09:57,130
adds directly to the bottom line and you

00:09:52,790 --> 00:09:57,130
know a few examples of that are here

00:09:57,579 --> 00:10:01,190
these are just a couple of companies

00:09:59,480 --> 00:10:03,440
that we've worked with there are many

00:10:01,190 --> 00:10:05,260
more as a enterprise supplier we can't

00:10:03,440 --> 00:10:07,220
really talk about all of them but I

00:10:05,260 --> 00:10:09,319
think what you're seeing here is a broad

00:10:07,220 --> 00:10:11,569
array of use cases it's not just tech

00:10:09,319 --> 00:10:14,089
it's not just finance it's oil and gas

00:10:11,569 --> 00:10:16,579
it's insurance it's lots of different

00:10:14,089 --> 00:10:17,899
things so this is how the world is going

00:10:16,579 --> 00:10:19,010
to evolve this is how the world of

00:10:17,899 --> 00:10:20,420
computation is going to go up and I

00:10:19,010 --> 00:10:22,370
think this is super exciting from my

00:10:20,420 --> 00:10:23,750
perspective a computer architected

00:10:22,370 --> 00:10:25,940
neuroscientist to see these things

00:10:23,750 --> 00:10:28,100
happening in my lifetime so with that

00:10:25,940 --> 00:10:29,080
thank you for your time and enjoy the

00:10:28,100 --> 00:10:29,180
rest of the

00:10:29,080 --> 00:10:32,350
[Applause]

00:10:29,180 --> 00:10:32,350

YouTube URL: https://www.youtube.com/watch?v=0oCXsCQMTYA


