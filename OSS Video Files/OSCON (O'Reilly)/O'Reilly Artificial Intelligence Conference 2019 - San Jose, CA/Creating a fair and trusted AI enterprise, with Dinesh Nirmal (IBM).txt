Title: Creating a fair and trusted AI enterprise, with Dinesh Nirmal (IBM)
Publication date: 2019-09-17
Playlist: O'Reilly Artificial Intelligence Conference 2019 - San Jose, CA
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,119 --> 00:00:07,270
hi Roger McGough us here at O'Reilly AI

00:00:04,020 --> 00:00:10,090
2019 conference in San Jose and I'm here

00:00:07,270 --> 00:00:12,490
with Denise normal he's a VP of data and

00:00:10,090 --> 00:00:13,000
AI development at IBM welcome Thank You

00:00:12,490 --> 00:00:16,150
Roger

00:00:13,000 --> 00:00:18,910
and he is a big area it's complex

00:00:16,150 --> 00:00:19,870
there's a lot going on what's the first

00:00:18,910 --> 00:00:22,300
bit of advice you would give someone

00:00:19,870 --> 00:00:25,510
who's thinking about the space right

00:00:22,300 --> 00:00:27,190
I think the first bit of advice I would

00:00:25,510 --> 00:00:30,100
give if you are especially an enterprise

00:00:27,190 --> 00:00:33,190
identify a use case I mean what are you

00:00:30,100 --> 00:00:35,920
trying to do and does it really need a I

00:00:33,190 --> 00:00:37,600
that's the first thing I would do the

00:00:35,920 --> 00:00:38,920
second piece is that you know Roger I

00:00:37,600 --> 00:00:40,600
really don't think there's a shortage of

00:00:38,920 --> 00:00:41,980
data there's plenty of data but there's

00:00:40,600 --> 00:00:43,900
social data behavioral data

00:00:41,980 --> 00:00:46,690
transactional data I don't think there's

00:00:43,900 --> 00:00:49,180
a shortage of data but getting clean

00:00:46,690 --> 00:00:51,160
data to make sure that you know because

00:00:49,180 --> 00:00:53,530
the training data set becomes such a

00:00:51,160 --> 00:00:56,739
critical piece of how the model is going

00:00:53,530 --> 00:00:58,840
to behave and how accurate it is so the

00:00:56,739 --> 00:01:01,989
advice I would give is like identify a

00:00:58,840 --> 00:01:03,970
use case and make sure a is critical or

00:01:01,989 --> 00:01:06,880
air is necessary for that use case

00:01:03,970 --> 00:01:08,650
sometimes you could use rules engine to

00:01:06,880 --> 00:01:10,090
build you know what you want to or

00:01:08,650 --> 00:01:13,060
accomplish what you want or it could be

00:01:10,090 --> 00:01:14,620
even a bi use case in some cases right

00:01:13,060 --> 00:01:16,659
so you don't need to go to the AI

00:01:14,620 --> 00:01:19,030
element of building you know multiple

00:01:16,659 --> 00:01:20,020
neuronal nets and all those things let's

00:01:19,030 --> 00:01:21,670
just keep it simple

00:01:20,020 --> 00:01:24,610
and the second is data I mean make sure

00:01:21,670 --> 00:01:27,580
that you have that right set of data not

00:01:24,610 --> 00:01:30,520
a lot of data so that's a good segue

00:01:27,580 --> 00:01:31,690
into you know how how do you help

00:01:30,520 --> 00:01:34,440
organizations grapple with the

00:01:31,690 --> 00:01:37,030
complexities of AI is the right choice

00:01:34,440 --> 00:01:39,220
with the pipeline with the data prep and

00:01:37,030 --> 00:01:40,990
deploying which is gonna take more time

00:01:39,220 --> 00:01:44,770
than the model probably oh yeah yeah I

00:01:40,990 --> 00:01:48,400
think so when I look at AI I call it the

00:01:44,770 --> 00:01:50,470
three DS there is obviously the middle

00:01:48,400 --> 00:01:53,140
DS the development of the model the

00:01:50,470 --> 00:01:55,780
first one is the data right and the last

00:01:53,140 --> 00:01:58,030
one is the deployment I think most

00:01:55,780 --> 00:02:01,509
enterprises get tripped over the first

00:01:58,030 --> 00:02:04,180
and that last D which is you know how do

00:02:01,509 --> 00:02:06,610
I discover the data how do I profile the

00:02:04,180 --> 00:02:08,169
data how do I classify the data the

00:02:06,610 --> 00:02:10,179
quality of the data the provenance of

00:02:08,169 --> 00:02:12,190
the data the whole data governance

00:02:10,179 --> 00:02:14,319
in the last of the deployment because

00:02:12,190 --> 00:02:16,330
it's not just about building the model

00:02:14,319 --> 00:02:19,420
how do you deploy it into your existing

00:02:16,330 --> 00:02:22,330
infrastructure that's 30 40 50 years you

00:02:19,420 --> 00:02:24,190
know old and then productionize it right

00:02:22,330 --> 00:02:27,280
the development of the model itself is

00:02:24,190 --> 00:02:28,989
getting more and more commoditized in a

00:02:27,280 --> 00:02:31,569
way that you know you have a lot of you

00:02:28,989 --> 00:02:33,400
feed the data it turns out a bunch of

00:02:31,569 --> 00:02:35,560
models based on the algorithms that's

00:02:33,400 --> 00:02:38,110
getting more and more automated but the

00:02:35,560 --> 00:02:40,870
last 2 DS are critical so to answer your

00:02:38,110 --> 00:02:43,930
question I would say where I start is

00:02:40,870 --> 00:02:47,050
that you know do we have a clean data

00:02:43,930 --> 00:02:49,570
set to start with how is the data

00:02:47,050 --> 00:02:52,150
quality that's where I start with

00:02:49,570 --> 00:02:54,730
because data becomes so critical because

00:02:52,150 --> 00:02:59,200
that training data said past data is

00:02:54,730 --> 00:03:01,959
what will really elevate the quality of

00:02:59,200 --> 00:03:03,790
the model so we got to make sure we get

00:03:01,959 --> 00:03:06,100
the data right so that's where I usually

00:03:03,790 --> 00:03:08,530
start with customers is that let's look

00:03:06,100 --> 00:03:10,660
and you know the first identify the use

00:03:08,530 --> 00:03:14,019
case then let's look at the data and

00:03:10,660 --> 00:03:17,560
make sure that we can get the right data

00:03:14,019 --> 00:03:19,000
for you to train the model so during

00:03:17,560 --> 00:03:21,549
this discussion it's clear that you've

00:03:19,000 --> 00:03:24,010
got some empirical experience with all

00:03:21,549 --> 00:03:28,540
this how do you do internally what are

00:03:24,010 --> 00:03:30,940
you using AI for and right so so I don't

00:03:28,540 --> 00:03:34,120
a large development organization and you

00:03:30,940 --> 00:03:35,709
know we obviously in IBM we use AI in HR

00:03:34,120 --> 00:03:38,440
for example hoping it's you know

00:03:35,709 --> 00:03:41,910
compensation we use a I've written

00:03:38,440 --> 00:03:44,890
customer service we use AI written

00:03:41,910 --> 00:03:48,640
hiring right so AI is being used widely

00:03:44,890 --> 00:03:53,230
but for me personally I will give you a

00:03:48,640 --> 00:03:55,329
really good example where you know we

00:03:53,230 --> 00:03:58,540
have 3,000 plus developers and obviously

00:03:55,329 --> 00:04:00,700
a lot of customers enterprise customers

00:03:58,540 --> 00:04:03,640
were you know when a problem happens

00:04:00,700 --> 00:04:05,530
it's always severity one regardless of

00:04:03,640 --> 00:04:07,299
it is they want to get it fixed because

00:04:05,530 --> 00:04:10,329
for them it doesn't matter whether we

00:04:07,299 --> 00:04:11,920
have thousand plus p.m. ours they're PMR

00:04:10,329 --> 00:04:13,900
or their problem ticket becomes the most

00:04:11,920 --> 00:04:16,870
critical and developers you know

00:04:13,900 --> 00:04:19,780
obviously get so many problems a day

00:04:16,870 --> 00:04:21,880
they cannot go after everyone because

00:04:19,780 --> 00:04:22,820
everyone every problem is coming in a

00:04:21,880 --> 00:04:27,070
cell one

00:04:22,820 --> 00:04:30,500
so we used a I within within our

00:04:27,070 --> 00:04:33,170
mechanism to say how do we really find

00:04:30,500 --> 00:04:35,390
out if this problem is critical

00:04:33,170 --> 00:04:37,400
will it get escalated so we used a bunch

00:04:35,390 --> 00:04:39,560
of features based on how many days it

00:04:37,400 --> 00:04:42,980
has been open which component of the

00:04:39,560 --> 00:04:44,420
code is it hitting the history and trend

00:04:42,980 --> 00:04:46,970
of the customer so we used bunch of

00:04:44,420 --> 00:04:50,330
features to predict yes this problem is

00:04:46,970 --> 00:04:52,280
one routed to this developer and Roger

00:04:50,330 --> 00:04:55,520
believe it or not we had like 40%

00:04:52,280 --> 00:04:57,620
improvement in our NPS because we were

00:04:55,520 --> 00:04:59,360
able to really channel our problems to

00:04:57,620 --> 00:05:02,720
the right person who could get it fixed

00:04:59,360 --> 00:05:05,270
and then we also used AI once they're

00:05:02,720 --> 00:05:07,100
coded effects to say we don't need to

00:05:05,270 --> 00:05:09,590
run or all thousand regression test

00:05:07,100 --> 00:05:12,320
cases this code only changed this

00:05:09,590 --> 00:05:14,150
particular piece of the software let's

00:05:12,320 --> 00:05:16,340
just run regression for that particular

00:05:14,150 --> 00:05:19,700
piece of the code so it efficiently

00:05:16,340 --> 00:05:21,920
elevated hearts to improve our NPS and

00:05:19,700 --> 00:05:23,540
the customer side so when you ask I mean

00:05:21,920 --> 00:05:25,550
there's so many places where you can a I

00:05:23,540 --> 00:05:27,530
but that's where you have to look at the

00:05:25,550 --> 00:05:30,110
use case and say how do we make sure

00:05:27,530 --> 00:05:32,150
that this particular use case will help

00:05:30,110 --> 00:05:35,000
us improve the customer experience and

00:05:32,150 --> 00:05:38,330
also you know developers becomes much

00:05:35,000 --> 00:05:40,160
more efficient I'm curious because I

00:05:38,330 --> 00:05:42,530
have an interest in text analysis did

00:05:40,160 --> 00:05:45,380
you're looking at trouble tickets didn't

00:05:42,530 --> 00:05:47,660
include any texts no he did not I mean

00:05:45,380 --> 00:05:51,170
you know so what we did was that so a

00:05:47,660 --> 00:05:52,850
lot of the data comes from so after the

00:05:51,170 --> 00:05:55,130
problem is fixed obviously we look at

00:05:52,850 --> 00:05:57,620
the NPS Medallia comes in you know we

00:05:55,130 --> 00:05:59,810
look at the text Watson has some speech

00:05:57,620 --> 00:06:01,940
detection you know text-to-speech

00:05:59,810 --> 00:06:03,320
so we started converting it doing

00:06:01,940 --> 00:06:05,120
sentimental announce all those things

00:06:03,320 --> 00:06:07,130
but prior to that we didn't have to use

00:06:05,120 --> 00:06:08,450
text analytics it was purely based on

00:06:07,130 --> 00:06:11,630
some of the features that we created

00:06:08,450 --> 00:06:14,510
based on customer input based on you

00:06:11,630 --> 00:06:17,000
know the the number of days that PMR has

00:06:14,510 --> 00:06:19,310
been opened which part of the code it

00:06:17,000 --> 00:06:22,130
hit I mean for example in the database

00:06:19,310 --> 00:06:24,320
side if it's hitting buffer pool or if

00:06:22,130 --> 00:06:26,390
it's hitting data manager side obviously

00:06:24,320 --> 00:06:28,790
the criticality is tend to be higher

00:06:26,390 --> 00:06:31,040
rather than et filling log manager which

00:06:28,790 --> 00:06:34,040
is less severe so we kind of you know

00:06:31,040 --> 00:06:35,020
categorized it pattern analysis all

00:06:34,040 --> 00:06:38,169
those things so

00:06:35,020 --> 00:06:39,849
we'll be focused on great so a theme of

00:06:38,169 --> 00:06:42,099
this conference I would say and just

00:06:39,849 --> 00:06:44,830
that doesn't a layperson just read the

00:06:42,099 --> 00:06:47,289
paper knows that trust fairness right

00:06:44,830 --> 00:06:49,270
bias are all really a big part of the AI

00:06:47,289 --> 00:06:52,300
story and in some ways might be the

00:06:49,270 --> 00:06:53,770
Achilles heel of what we're what we're

00:06:52,300 --> 00:06:55,240
able to do in fact I think some of these

00:06:53,770 --> 00:06:58,419
things are becoming an imperative not

00:06:55,240 --> 00:07:00,520
just a nice to have so IBM seems to be

00:06:58,419 --> 00:07:01,690
clearly working on some of these things

00:07:00,520 --> 00:07:04,120
maybe we can describe some of those

00:07:01,690 --> 00:07:05,580
efforts right definitely so I think once

00:07:04,120 --> 00:07:08,259
you build a model right I think

00:07:05,580 --> 00:07:10,449
everybody thinks the job is done once

00:07:08,259 --> 00:07:12,940
you get a level of accuracy but then

00:07:10,449 --> 00:07:15,729
comes the real work for example you know

00:07:12,940 --> 00:07:17,949
is the model explainable once you deny

00:07:15,729 --> 00:07:21,639
alone can you explain to the regulator

00:07:17,949 --> 00:07:23,740
that why that loan was denied is the

00:07:21,639 --> 00:07:26,229
model fair I mean is it biased I mean is

00:07:23,740 --> 00:07:29,110
it not giving to particular genders race

00:07:26,229 --> 00:07:31,120
age group so you have to make sure of

00:07:29,110 --> 00:07:33,759
that accuracy you know is the model

00:07:31,120 --> 00:07:35,560
drifting has the data changed and then

00:07:33,759 --> 00:07:37,599
you know the last but not least I talk

00:07:35,560 --> 00:07:40,210
about open I mean to me I honestly

00:07:37,599 --> 00:07:43,030
believe Roger this cannot be a paradigm

00:07:40,210 --> 00:07:44,650
where a couple of vendors or enterprises

00:07:43,030 --> 00:07:46,569
have secret sauce or a bunch of

00:07:44,650 --> 00:07:48,159
algorithms that they hold close to their

00:07:46,569 --> 00:07:50,289
chest this has to be done in the open

00:07:48,159 --> 00:07:52,599
this has to be a moment because I

00:07:50,289 --> 00:07:54,940
strongly believe that a is the biggest

00:07:52,599 --> 00:07:57,219
undertaking we have in our lifetime and

00:07:54,940 --> 00:07:59,409
in many generations to come and unless

00:07:57,219 --> 00:08:03,099
these models are trained to be fair

00:07:59,409 --> 00:08:05,169
ethical and accurate and explainable I

00:08:03,099 --> 00:08:07,360
think we'll have much more problems down

00:08:05,169 --> 00:08:09,310
the road so I be mistaking you know huge

00:08:07,360 --> 00:08:11,110
steps I mean we contributed immensely

00:08:09,310 --> 00:08:13,330
back into the community we are working

00:08:11,110 --> 00:08:16,990
very closely with the community to make

00:08:13,330 --> 00:08:19,150
sure that you know how do we make a bias

00:08:16,990 --> 00:08:20,740
detection system how do we make sure

00:08:19,150 --> 00:08:22,599
it's fair how do we make sure it's

00:08:20,740 --> 00:08:24,310
explainable all those things we have a

00:08:22,599 --> 00:08:26,169
software called Watson open scale that's

00:08:24,310 --> 00:08:28,090
available which is built on open source

00:08:26,169 --> 00:08:30,639
which we have contributed back into open

00:08:28,090 --> 00:08:32,680
source but to me that's probably the

00:08:30,639 --> 00:08:34,990
most important piece is that it's a

00:08:32,680 --> 00:08:37,180
movement and it has to come from the

00:08:34,990 --> 00:08:37,719
community not from a vendor not from a

00:08:37,180 --> 00:08:40,329
end

00:08:37,719 --> 00:08:43,870
not from a single source it has to come

00:08:40,329 --> 00:08:45,610
from a lot of people mm-hmm so I've I've

00:08:43,870 --> 00:08:49,209
heard IBM say that you can't have AI

00:08:45,610 --> 00:08:50,860
without IA information architecture

00:08:49,209 --> 00:08:55,870
maybe you can quickly explain that right

00:08:50,860 --> 00:08:57,939
so that that goes from the 3ds I talked

00:08:55,870 --> 00:09:00,730
about you know being able to take the

00:08:57,939 --> 00:09:03,399
data or discover the data right I mean

00:09:00,730 --> 00:09:05,680
world where is your data being able to

00:09:03,399 --> 00:09:09,009
profile the data being able to classify

00:09:05,680 --> 00:09:11,079
the data being able to you know cleanse

00:09:09,009 --> 00:09:13,360
the data I mean there's a whole data

00:09:11,079 --> 00:09:15,850
process but then you also need

00:09:13,360 --> 00:09:19,449
governance around the data I mean how do

00:09:15,850 --> 00:09:22,810
we get the data to the data scientist in

00:09:19,449 --> 00:09:24,639
a much more faster fashion I mean today

00:09:22,810 --> 00:09:26,800
they say that it takes six to eight

00:09:24,639 --> 00:09:28,720
weeks to get any data to the data

00:09:26,800 --> 00:09:30,519
scientist how can you enable

00:09:28,720 --> 00:09:32,290
self-service analogy so ia or

00:09:30,519 --> 00:09:35,050
information architecture not only

00:09:32,290 --> 00:09:37,480
enables that but it puts the governance

00:09:35,050 --> 00:09:40,689
layer on top of it not just the data but

00:09:37,480 --> 00:09:43,180
the whole life cycle of AI taking it

00:09:40,689 --> 00:09:45,459
from the data being able to develop the

00:09:43,180 --> 00:09:47,889
model being able to deploy the model so

00:09:45,459 --> 00:09:50,559
that lifecycle becomes the information

00:09:47,889 --> 00:09:54,339
architecture so AI cannot be done

00:09:50,559 --> 00:09:57,939
without ia partly because you know you

00:09:54,339 --> 00:10:00,639
want to make sure the the flow of data

00:09:57,939 --> 00:10:02,769
and the models to the deployment of the

00:10:00,639 --> 00:10:04,600
model is under some level of governance

00:10:02,769 --> 00:10:06,639
and and the for enterprises it becomes

00:10:04,600 --> 00:10:09,490
huge because there's whole kind of

00:10:06,639 --> 00:10:10,600
regulatory you know implications to it

00:10:09,490 --> 00:10:13,509
I'll give you an example I've been

00:10:10,600 --> 00:10:16,029
working with a large bank in Europe

00:10:13,509 --> 00:10:19,269
where you know they said right now they

00:10:16,029 --> 00:10:21,269
have models built on SAS to take those

00:10:19,269 --> 00:10:23,529
models and even convert the Python

00:10:21,269 --> 00:10:25,389
conversion is not a problem but to get

00:10:23,529 --> 00:10:28,720
that modern regulatory approved

00:10:25,389 --> 00:10:30,550
he's 18 to 24 months that's one model so

00:10:28,720 --> 00:10:32,230
that's such a real-world challenge that

00:10:30,550 --> 00:10:34,389
these customers are facing it's not like

00:10:32,230 --> 00:10:36,819
you know I'm a data scientist I got some

00:10:34,389 --> 00:10:38,889
data I coded a model I deployed it done

00:10:36,819 --> 00:10:41,139
that's not the case right so we have to

00:10:38,889 --> 00:10:42,579
have AI for the real world right right I

00:10:41,139 --> 00:10:45,189
mean you know and that's what we have to

00:10:42,579 --> 00:10:47,410
and it's really interesting that how

00:10:45,189 --> 00:10:49,600
prevalent it becomes this morning there

00:10:47,410 --> 00:10:52,080
was a news by Airbus were

00:10:49,600 --> 00:10:54,760
they call it the connected airplane

00:10:52,080 --> 00:10:56,410
where you know they can even tell you

00:10:54,760 --> 00:10:58,300
when you get up from your seed they can

00:10:56,410 --> 00:11:01,330
even tell how many times you use the

00:10:58,300 --> 00:11:01,810
lavatory or how crowded it is all those

00:11:01,330 --> 00:11:04,360
things

00:11:01,810 --> 00:11:05,770
but the data you know data more and more

00:11:04,360 --> 00:11:08,320
data comes I'm sure they're going to be

00:11:05,770 --> 00:11:09,670
able to predict you know in future what

00:11:08,320 --> 00:11:11,410
why take two Airbus is also you know

00:11:09,670 --> 00:11:12,910
first year to make sure that laboratory

00:11:11,410 --> 00:11:14,680
works before you know you can send

00:11:12,910 --> 00:11:17,380
people there but you know they're using

00:11:14,680 --> 00:11:20,170
all this data to predict the future so

00:11:17,380 --> 00:11:22,120
AI is becoming in in our everyday life

00:11:20,170 --> 00:11:25,120
and you can all be successful in

00:11:22,120 --> 00:11:28,710
enterprise without RA mm-hmm great well

00:11:25,120 --> 00:11:28,710
thanks a lot for your time thank you

00:11:34,499 --> 00:11:36,559

YouTube URL: https://www.youtube.com/watch?v=HqnsiwfXczc


