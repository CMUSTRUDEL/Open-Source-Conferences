Title: Scaling the future of Machine Learning in enterprises, with Kurt Muehmel (Dataiku)
Publication date: 2019-09-17
Playlist: O'Reilly Artificial Intelligence Conference 2019 - San Jose, CA
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,439 --> 00:00:05,850
hi Roger McGough is here VP of radar

00:00:03,389 --> 00:00:09,059
O'Reilly and I'm at the AI conference

00:00:05,850 --> 00:00:09,870
2019 in San Jose and I'm here with Kurt

00:00:09,059 --> 00:00:13,079
Nemo

00:00:09,870 --> 00:00:14,549
he's the chief customer officer at data

00:00:13,079 --> 00:00:15,839
I COO welcome Kurt

00:00:14,549 --> 00:00:17,670
thanks very much Roger that's her to be

00:00:15,839 --> 00:00:19,620
here and you had mentioned that when you

00:00:17,670 --> 00:00:23,070
talk to in your talk that enterprises

00:00:19,620 --> 00:00:25,680
may be managing millions of deployed ml

00:00:23,070 --> 00:00:27,480
models in the future like sounds kind of

00:00:25,680 --> 00:00:29,700
unreasonable but is that reasonable and

00:00:27,480 --> 00:00:32,099
kind of a time scale you think this is

00:00:29,700 --> 00:00:34,140
gonna happen sure sure I think what

00:00:32,099 --> 00:00:36,030
we're you know the answer is the short

00:00:34,140 --> 00:00:38,699
answer is yes it is reasonable the

00:00:36,030 --> 00:00:40,920
question is when the question is both

00:00:38,699 --> 00:00:43,050
win and how because we see this you know

00:00:40,920 --> 00:00:45,359
great acceleration over the past already

00:00:43,050 --> 00:00:47,399
12 years 15 years when we've been doing

00:00:45,359 --> 00:00:50,699
now let's call it modern data science

00:00:47,399 --> 00:00:52,409
and so we can anticipate that that that

00:00:50,699 --> 00:00:54,120
trend is going to continue and and

00:00:52,409 --> 00:00:57,210
accelerate and so what we've seen

00:00:54,120 --> 00:00:59,550
already is a lot of advances made in

00:00:57,210 --> 00:01:01,019
terms of automating the development and

00:00:59,550 --> 00:01:02,729
the management of model it's not that's

00:01:01,019 --> 00:01:04,469
a subtly different thing than auto

00:01:02,729 --> 00:01:06,360
machine learning auto ml do we often

00:01:04,469 --> 00:01:09,030
hear a lot about because it's not just

00:01:06,360 --> 00:01:10,710
about you know automating the generation

00:01:09,030 --> 00:01:13,020
of new features or hyper

00:01:10,710 --> 00:01:15,149
parameterization or a lot of these other

00:01:13,020 --> 00:01:17,450
techniques which are valuable it's much

00:01:15,149 --> 00:01:20,939
more about templating processes

00:01:17,450 --> 00:01:22,770
automating the QA the QC the Quality

00:01:20,939 --> 00:01:25,320
Assurance and control process of

00:01:22,770 --> 00:01:27,930
validating these models monitoring them

00:01:25,320 --> 00:01:30,509
when they're in production and given the

00:01:27,930 --> 00:01:31,649
means to do that which which is

00:01:30,509 --> 00:01:34,740
something that you know of course we're

00:01:31,649 --> 00:01:36,149
working very very closely on is of

00:01:34,740 --> 00:01:37,859
course the necessity and the value that

00:01:36,149 --> 00:01:40,170
comes from that because we can imagine

00:01:37,859 --> 00:01:41,759
the the potential where you know you

00:01:40,170 --> 00:01:43,920
have so many different you know if your

00:01:41,759 --> 00:01:46,259
manufacturer might be assets and

00:01:43,920 --> 00:01:48,810
factories around the world augmenting

00:01:46,259 --> 00:01:50,969
those with with the potential of machine

00:01:48,810 --> 00:01:53,640
learning for the very first time that's

00:01:50,969 --> 00:01:55,040
incredibly powerful in you know that the

00:01:53,640 --> 00:01:57,200
gains are not not me

00:01:55,040 --> 00:01:58,640
and you know making a model 2% more

00:01:57,200 --> 00:02:00,290
perfect than another model it's about

00:01:58,640 --> 00:02:02,030
actually just getting the first model

00:02:00,290 --> 00:02:03,470
out there doing it for the first time

00:02:02,030 --> 00:02:05,930
and then being able to repeat that

00:02:03,470 --> 00:02:08,750
process at scale so yeah we do think

00:02:05,930 --> 00:02:10,310
that's reasonable on the time frame you

00:02:08,750 --> 00:02:12,470
know maybe the the median comes and

00:02:10,310 --> 00:02:15,380
company is is getting to that scale five

00:02:12,470 --> 00:02:16,550
eight ten years from now but the real

00:02:15,380 --> 00:02:18,170
challenge is to be at the head of that

00:02:16,550 --> 00:02:20,540
pack because the the gains for those

00:02:18,170 --> 00:02:22,940
leaders are really gonna be remarkable

00:02:20,540 --> 00:02:24,620
mm-hmm so in to hearing about that one

00:02:22,940 --> 00:02:26,000
of the things I know about models is

00:02:24,620 --> 00:02:27,620
that sometimes they don't live that long

00:02:26,000 --> 00:02:30,590
sure is that part of the equation

00:02:27,620 --> 00:02:31,640
absolutely yeah because if you have you

00:02:30,590 --> 00:02:33,590
know if you have millions of models so

00:02:31,640 --> 00:02:36,470
you need to maintain you know it's it's

00:02:33,590 --> 00:02:38,209
one bad practice you know it's just bad

00:02:36,470 --> 00:02:39,800
business practice to leave them out of a

00:02:38,209 --> 00:02:41,270
model out there in the wild it's

00:02:39,800 --> 00:02:42,890
performance is going to degrade over

00:02:41,270 --> 00:02:44,870
time and then depending on the

00:02:42,890 --> 00:02:47,239
application it may also start having

00:02:44,870 --> 00:02:49,790
negative impacts either on your business

00:02:47,239 --> 00:02:51,739
or on the people that it's affecting and

00:02:49,790 --> 00:02:53,690
there we get into kind of the ethical

00:02:51,739 --> 00:02:56,420
concerns around this as well and so

00:02:53,690 --> 00:02:58,550
being able to monitor model performance

00:02:56,420 --> 00:03:01,010
over time and at scale when we're

00:02:58,550 --> 00:03:03,530
talking about millions or even tens of

00:03:01,010 --> 00:03:05,780
millions of of models being deployed out

00:03:03,530 --> 00:03:07,610
there that becomes essential or really

00:03:05,780 --> 00:03:09,920
it's a you know it's a necessary

00:03:07,610 --> 00:03:12,769
condition to do things responsibly both

00:03:09,920 --> 00:03:16,489
as as a business and let's say as a as a

00:03:12,769 --> 00:03:18,799
citizen mm-hmm right so some people talk

00:03:16,489 --> 00:03:20,090
about AI certainly a lot of hype around

00:03:18,799 --> 00:03:23,000
and that's kind of technology for

00:03:20,090 --> 00:03:24,230
technology's sake where do you see the

00:03:23,000 --> 00:03:27,350
value in it you've brought a little bit

00:03:24,230 --> 00:03:29,570
kind of first model as being a big

00:03:27,350 --> 00:03:32,510
change for certain applications sure

00:03:29,570 --> 00:03:34,400
absolutely and there is a risk of doing

00:03:32,510 --> 00:03:36,080
technology for technology's sake and I

00:03:34,400 --> 00:03:38,299
think the companies who are thinking

00:03:36,080 --> 00:03:40,700
about these processes need to be very

00:03:38,299 --> 00:03:42,140
conscious of that understand what

00:03:40,700 --> 00:03:43,459
they're attempting to accomplish is it

00:03:42,140 --> 00:03:46,610
just to be able to tell the board that

00:03:43,459 --> 00:03:48,290
hey we've done it is it just a you know

00:03:46,610 --> 00:03:50,600
a competition to see how many models

00:03:48,290 --> 00:03:53,239
they can do that's not ultimately going

00:03:50,600 --> 00:03:54,800
to be that valuable and so really being

00:03:53,239 --> 00:03:57,410
able to take the

00:03:54,800 --> 00:03:59,600
potential that we all know that machine

00:03:57,410 --> 00:04:02,360
learning has for even some of the most

00:03:59,600 --> 00:04:04,280
mundane business processes and not not

00:04:02,360 --> 00:04:06,950
only the high-flying ones but really the

00:04:04,280 --> 00:04:11,240
day-to-day that's where we see a huge

00:04:06,950 --> 00:04:13,010
game and a potentially massive ROI for

00:04:11,240 --> 00:04:15,380
these companies because once again once

00:04:13,010 --> 00:04:17,870
you build the capability to develop

00:04:15,380 --> 00:04:19,580
machine learning models and scale to

00:04:17,870 --> 00:04:22,700
maintain machine learning models at

00:04:19,580 --> 00:04:24,710
scale deploy them at scale then really

00:04:22,700 --> 00:04:26,780
you have the ability to transform your

00:04:24,710 --> 00:04:29,690
business pretty much across the board

00:04:26,780 --> 00:04:33,020
and that's that's potentially very very

00:04:29,690 --> 00:04:35,630
important for for customers in the in

00:04:33,020 --> 00:04:38,210
the coming years decades as we go

00:04:35,630 --> 00:04:40,040
forward so in thinking about these kind

00:04:38,210 --> 00:04:43,670
of enterprise folks trying to get ahead

00:04:40,040 --> 00:04:44,930
of the game and and do this stuff what

00:04:43,670 --> 00:04:47,720
do they need to take in our account so

00:04:44,930 --> 00:04:49,850
that they can scale to me yeah those

00:04:47,720 --> 00:04:52,940
needs I would say that there's three

00:04:49,850 --> 00:04:56,360
main dimensions the first dimension is

00:04:52,940 --> 00:04:58,160
the human dimension scale it's not just

00:04:56,360 --> 00:05:00,080
about technology it's you know

00:04:58,160 --> 00:05:02,120
technology is an enabler technology is

00:05:00,080 --> 00:05:03,740
an accelerator but ultimately it's the

00:05:02,120 --> 00:05:06,440
the people who are going to be doing

00:05:03,740 --> 00:05:08,300
this and we're looking forward to to a

00:05:06,440 --> 00:05:09,800
future where there's you know maybe tens

00:05:08,300 --> 00:05:12,080
of thousands of people within a single

00:05:09,800 --> 00:05:13,040
company to imagine a company where 50

00:05:12,080 --> 00:05:15,530
thousand a hundred thousand employees

00:05:13,040 --> 00:05:18,410
might be you know a significant portion

00:05:15,530 --> 00:05:20,210
of that company which is involved in the

00:05:18,410 --> 00:05:23,030
data science process now are they all

00:05:20,210 --> 00:05:24,470
data scientists frankly the terminology

00:05:23,030 --> 00:05:26,770
it's not the most interesting question

00:05:24,470 --> 00:05:28,460
right it's you know a title or not

00:05:26,770 --> 00:05:30,530
what's important is that they are

00:05:28,460 --> 00:05:33,050
contributing participating in that

00:05:30,530 --> 00:05:35,360
process and so the first element is that

00:05:33,050 --> 00:05:37,550
is bringing enough people in to be able

00:05:35,360 --> 00:05:40,010
to scale that process the second is

00:05:37,550 --> 00:05:42,200
necessarily the the technology and being

00:05:40,010 --> 00:05:45,020
able to operationalize what you have

00:05:42,200 --> 00:05:47,000
because scale you know if it's just

00:05:45,020 --> 00:05:50,250
prototypes if it's just you know

00:05:47,000 --> 00:05:52,200
laboratory work that's not valuable

00:05:50,250 --> 00:05:53,670
I shouldn't say that's not failure well

00:05:52,200 --> 00:05:55,140
there's useful insights that are going

00:05:53,670 --> 00:05:57,210
to come from that exactly it's a

00:05:55,140 --> 00:05:58,680
learning experience which is which is

00:05:57,210 --> 00:06:00,510
valuable but it's not the scale that

00:05:58,680 --> 00:06:01,770
we're talking about here transforming

00:06:00,510 --> 00:06:03,510
the business comes from actually

00:06:01,770 --> 00:06:05,880
operationalizing these and deploying

00:06:03,510 --> 00:06:07,530
them and then the third point is doing

00:06:05,880 --> 00:06:09,870
it responsibly doing responsible AI

00:06:07,530 --> 00:06:12,150
because if you're scaling out your

00:06:09,870 --> 00:06:13,980
practice well hopefully it has an impact

00:06:12,150 --> 00:06:15,480
on the world right hopefully at least it

00:06:13,980 --> 00:06:17,640
has an impact on your bottom line and

00:06:15,480 --> 00:06:19,110
hopefully there's a there's some ROI the

00:06:17,640 --> 00:06:22,230
flip side of that coin is that that

00:06:19,110 --> 00:06:23,970
impact can be positive neutral or maybe

00:06:22,230 --> 00:06:24,780
negative and of course you know if

00:06:23,970 --> 00:06:26,670
you're doing good things for the world

00:06:24,780 --> 00:06:27,720
and making money fantastic if you're

00:06:26,670 --> 00:06:29,460
making a bunch of money and you know

00:06:27,720 --> 00:06:31,770
you're not harming anyone totally fine

00:06:29,460 --> 00:06:33,450
yeah no one's gonna tell you to stop but

00:06:31,770 --> 00:06:35,370
if you're harming people you know if

00:06:33,450 --> 00:06:36,750
there's unintentional bias ease things

00:06:35,370 --> 00:06:38,400
like that getting built into your models

00:06:36,750 --> 00:06:40,830
you need to be really cautious and so to

00:06:38,400 --> 00:06:43,050
do things responsibly that requires good

00:06:40,830 --> 00:06:45,480
governance procedures that could never

00:06:43,050 --> 00:06:47,990
requires good good monitoring procedures

00:06:45,480 --> 00:06:50,820
and that ultimately requires good

00:06:47,990 --> 00:06:52,650
organizational structure to ensure that

00:06:50,820 --> 00:06:54,540
things are not be happening off the

00:06:52,650 --> 00:06:56,520
books and a you know in a corner

00:06:54,540 --> 00:06:58,560
somewhere but that really everybody is

00:06:56,520 --> 00:07:00,419
aware of what's going on relevant people

00:06:58,560 --> 00:07:03,180
are participating in this process to

00:07:00,419 --> 00:07:05,610
ensure that what we're doing isn't not

00:07:03,180 --> 00:07:07,350
causing harm right admirably for

00:07:05,610 --> 00:07:09,810
bringing up people almost always as the

00:07:07,350 --> 00:07:11,190
first item this stuff so clearly with

00:07:09,810 --> 00:07:13,440
these things happening what will be the

00:07:11,190 --> 00:07:15,030
effect on employees I think expect at

00:07:13,440 --> 00:07:16,680
absolutely I think it's a very important

00:07:15,030 --> 00:07:18,870
question people are rightly concerned

00:07:16,680 --> 00:07:21,479
that you know the this increase in

00:07:18,870 --> 00:07:25,020
automation this increase in machine

00:07:21,479 --> 00:07:27,240
intelligence is going to you know reduce

00:07:25,020 --> 00:07:29,400
the need for humans to participate in

00:07:27,240 --> 00:07:30,990
the labor force which which

00:07:29,400 --> 00:07:33,990
understandably is frightening this stuff

00:07:30,990 --> 00:07:36,270
is on people's livelihoods and I think

00:07:33,990 --> 00:07:38,400
that we need to to remember back that a

00:07:36,270 --> 00:07:39,930
couple hundred years ago it was

00:07:38,400 --> 00:07:41,820
something like 90 or 95% of the

00:07:39,930 --> 00:07:44,280
population was involved in agriculture

00:07:41,820 --> 00:07:45,900
right today it's to four percent

00:07:44,280 --> 00:07:47,400
something like this we don't have 90

00:07:45,900 --> 00:07:49,169
percent unemployment people have gone on

00:07:47,400 --> 00:07:50,460
to do more productive things now the

00:07:49,169 --> 00:07:51,690
difference in a very important

00:07:50,460 --> 00:07:54,630
difference is the speed of that change

00:07:51,690 --> 00:07:56,460
that industrial transition was overjet

00:07:54,630 --> 00:07:58,110
multiple generations a grandson was able

00:07:56,460 --> 00:08:01,229
to say or a grandfather was able to say

00:07:58,110 --> 00:08:02,400
to his grandson you know listen the the

00:08:01,229 --> 00:08:03,870
farms not where it's at moved to the

00:08:02,400 --> 00:08:06,720
city and there was time to take that

00:08:03,870 --> 00:08:08,070
into account and so now we need to you

00:08:06,720 --> 00:08:10,460
know these changes are happening even

00:08:08,070 --> 00:08:13,500
more quickly and I think that employers

00:08:10,460 --> 00:08:15,360
who in that case of data ku customers

00:08:13,500 --> 00:08:17,039
need to be anticipating how they can

00:08:15,360 --> 00:08:18,630
involve more people in these processes

00:08:17,039 --> 00:08:21,810
where we can automate the most mundane

00:08:18,630 --> 00:08:23,280
aspects of the work so that the

00:08:21,810 --> 00:08:25,410
intelligence and you know the the

00:08:23,280 --> 00:08:26,910
incredible value that these these

00:08:25,410 --> 00:08:28,710
employees have even if they're not

00:08:26,910 --> 00:08:30,240
trained data scientists they know about

00:08:28,710 --> 00:08:32,039
the business and they have something to

00:08:30,240 --> 00:08:33,690
contribute as well and I think that

00:08:32,039 --> 00:08:36,570
that's important to remember that even

00:08:33,690 --> 00:08:37,979
as we go through this next you know you

00:08:36,570 --> 00:08:41,219
know third industrial fourth Industrial

00:08:37,979 --> 00:08:42,719
Revolution that we are really engaging

00:08:41,219 --> 00:08:45,060
with the the people who have something

00:08:42,719 --> 00:08:46,830
valuable to bring to that process so it

00:08:45,060 --> 00:08:48,480
sounds like you're in some ways

00:08:46,830 --> 00:08:50,310
advocating leave it advocating for the

00:08:48,480 --> 00:08:54,720
right word but you're saying you expect

00:08:50,310 --> 00:08:55,950
a augment not replace very much in the

00:08:54,720 --> 00:08:58,440
way that we phrased that is often around

00:08:55,950 --> 00:09:01,290
inclusion that we're including the right

00:08:58,440 --> 00:09:04,080
people at the right time that's you know

00:09:01,290 --> 00:09:06,810
even if you're not a PhD former

00:09:04,080 --> 00:09:08,670
astrophysicist data scientist who don't

00:09:06,810 --> 00:09:09,660
get me wrong are extremely valuable and

00:09:08,670 --> 00:09:11,880
if you have them on your team you're

00:09:09,660 --> 00:09:13,740
lucky but even if you don't have that

00:09:11,880 --> 00:09:16,200
level of skill that you have something

00:09:13,740 --> 00:09:18,120
to bring to the table given all of your

00:09:16,200 --> 00:09:19,500
years of experience given the different

00:09:18,120 --> 00:09:23,070
or outside perspective that you can

00:09:19,500 --> 00:09:24,480
bring into that process so painting is

00:09:23,070 --> 00:09:26,880
kind of a picture of how to get forward

00:09:24,480 --> 00:09:30,660
how did one get started so I think that

00:09:26,880 --> 00:09:32,910
it's really important to choose both of

00:09:30,660 --> 00:09:35,130
the right allies to work with and that

00:09:32,910 --> 00:09:36,870
you know that can be external either

00:09:35,130 --> 00:09:38,820
consultants you know technology vendors

00:09:36,870 --> 00:09:41,430
whatever that is but also for a company

00:09:38,820 --> 00:09:43,589
internally to work with the right folks

00:09:41,430 --> 00:09:45,660
who are going to be able to be strong

00:09:43,589 --> 00:09:47,339
advocates for the process as well one of

00:09:45,660 --> 00:09:50,040
the key topics that we often come up

00:09:47,339 --> 00:09:52,760
against in you know in working on these

00:09:50,040 --> 00:09:55,080
transformations is acceptance and Trust

00:09:52,760 --> 00:09:57,089
so imagine you know a new data science

00:09:55,080 --> 00:10:00,450
practice coming with a new way of doing

00:09:57,089 --> 00:10:01,770
something that's a pricing model for an

00:10:00,450 --> 00:10:02,790
insurance company there's a

00:10:01,770 --> 00:10:04,770
long-established team that's been

00:10:02,790 --> 00:10:07,020
working on that for years understandably

00:10:04,770 --> 00:10:10,500
there could be resistance and that's why

00:10:07,020 --> 00:10:13,170
finding an ally who is open to to this

00:10:10,500 --> 00:10:14,240
progress but doing the process and

00:10:13,170 --> 00:10:15,860
developing the model

00:10:14,240 --> 00:10:19,040
going through that development process

00:10:15,860 --> 00:10:20,510
in a measured and transparent way is

00:10:19,040 --> 00:10:23,270
extremely important to then gain the

00:10:20,510 --> 00:10:26,089
trust in the acceptance of of that team

00:10:23,270 --> 00:10:28,430
and so by building those allies with the

00:10:26,089 --> 00:10:30,170
initial successes that's that's a great

00:10:28,430 --> 00:10:32,690
way to get started so that you have a

00:10:30,170 --> 00:10:34,010
strong foundation then for scaling that

00:10:32,690 --> 00:10:35,959
makes a lot of sense and from what I

00:10:34,010 --> 00:10:38,000
know about these things is probably the

00:10:35,959 --> 00:10:40,970
tendency for people that the data people

00:10:38,000 --> 00:10:43,190
to be very uh not insular but maybe not

00:10:40,970 --> 00:10:46,310
reach out as much as they should to get

00:10:43,190 --> 00:10:47,839
the motivation why indeed it's it's

00:10:46,310 --> 00:10:50,209
something that we've seen quite quite

00:10:47,839 --> 00:10:52,279
frequently frequently now historically

00:10:50,209 --> 00:10:54,380
there's been a bit of a bit of a

00:10:52,279 --> 00:10:55,940
language barrier I'm using that

00:10:54,380 --> 00:10:57,709
metaphorically but the truth is that you

00:10:55,940 --> 00:11:00,140
know somebody is writing in Python and

00:10:57,709 --> 00:11:01,010
the other person is you know modeling in

00:11:00,140 --> 00:11:02,600
Excel

00:11:01,010 --> 00:11:04,640
those are fundamentally different

00:11:02,600 --> 00:11:06,200
languages to bring together and that's

00:11:04,640 --> 00:11:08,180
where did I COO hopes to break down some

00:11:06,200 --> 00:11:09,860
of those barriers not put people off

00:11:08,180 --> 00:11:12,140
into different segments or into

00:11:09,860 --> 00:11:14,630
different categories based on skill sets

00:11:12,140 --> 00:11:16,820
or educational background or whatever it

00:11:14,630 --> 00:11:18,860
may be because we recognize that you

00:11:16,820 --> 00:11:21,740
know people and who you are and what you

00:11:18,860 --> 00:11:23,120
bring is not so binary you know people

00:11:21,740 --> 00:11:25,190
don't fit into these neat little buckets

00:11:23,120 --> 00:11:26,900
it's a you know when we look at a

00:11:25,190 --> 00:11:29,150
population it's a gradient of skills

00:11:26,900 --> 00:11:30,290
it's a spectrum everyone with different

00:11:29,150 --> 00:11:31,820
things to contribute and that's why

00:11:30,290 --> 00:11:34,010
bringing everyone into a common platform

00:11:31,820 --> 00:11:35,600
can really be so valuable very

00:11:34,010 --> 00:11:36,020
interesting so thanks for your time

00:11:35,600 --> 00:11:38,980
today

00:11:36,020 --> 00:11:38,980
thanks Roger I appreciate it

00:11:45,089 --> 00:11:47,149

YouTube URL: https://www.youtube.com/watch?v=nENypD44DJw


