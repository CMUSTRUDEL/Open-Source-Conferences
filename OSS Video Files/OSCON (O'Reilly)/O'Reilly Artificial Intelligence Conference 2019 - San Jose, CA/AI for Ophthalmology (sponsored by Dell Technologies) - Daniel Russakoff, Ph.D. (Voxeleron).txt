Title: AI for Ophthalmology (sponsored by Dell Technologies) - Daniel Russakoff, Ph.D. (Voxeleron)
Publication date: 2019-09-12
Playlist: O'Reilly Artificial Intelligence Conference 2019 - San Jose, CA
Description: 
	Today, the emphasis in AI is on replicating human performance. Examples abound: ImageNet, self-driving cars, etc. It’s the same in medicine. At Voxeleron, we’re working on what’s next; i.e. AI algorithms that do things that humans can’t. One example of this is prediction of age-related macular degeneration (AMD) progression, critical to successful treatment of this leading cause of vision loss.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,060 --> 00:00:04,140
good morning thanks for coming as he

00:00:02,730 --> 00:00:08,429
mentioned my name is Daniel Russakoff

00:00:04,140 --> 00:00:10,469
I'm the co-founder of XLR on we're based

00:00:08,429 --> 00:00:12,120
here in the Bay Area and we sit at the

00:00:10,469 --> 00:00:14,400
intersection of computer vision machine

00:00:12,120 --> 00:00:16,260
learning and ophthalmic imaging our goal

00:00:14,400 --> 00:00:19,039
is to combine these disciplines to build

00:00:16,260 --> 00:00:21,930
tools to help physicians improve lives

00:00:19,039 --> 00:00:23,939
in general the emphasis in AI has been

00:00:21,930 --> 00:00:27,390
on replicating human performance whether

00:00:23,939 --> 00:00:30,769
it's imagenet self-driving cars or my

00:00:27,390 --> 00:00:34,980
personal favorite hot dog not a hot dog

00:00:30,769 --> 00:00:37,079
but now these are these are all tasks

00:00:34,980 --> 00:00:39,420
human the humans are already good at and

00:00:37,079 --> 00:00:41,040
traditionally machines haven't been but

00:00:39,420 --> 00:00:43,379
deep learning with convolutional neural

00:00:41,040 --> 00:00:45,300
nets has changed all that and we're in a

00:00:43,379 --> 00:00:47,820
very exciting time now where AI is

00:00:45,300 --> 00:00:49,200
nearly everywhere healthcare is no

00:00:47,820 --> 00:00:51,300
exception and in particular in

00:00:49,200 --> 00:00:54,260
ophthalmology we've seen the first-ever

00:00:51,300 --> 00:00:58,079
FDA approved autonomous AI system

00:00:54,260 --> 00:00:59,489
released by idx last year now idx is

00:00:58,079 --> 00:01:01,920
still basically doing something

00:00:59,489 --> 00:01:03,719
physicians are already good at at fox

00:01:01,920 --> 00:01:05,640
Celeron the question we're asking is

00:01:03,719 --> 00:01:08,939
what can we do with these images that

00:01:05,640 --> 00:01:10,500
physicians can't to tackle this problem

00:01:08,939 --> 00:01:12,360
it helps to understand a little bit more

00:01:10,500 --> 00:01:15,210
about what's going on under the hood in

00:01:12,360 --> 00:01:17,729
general the narrative with cnn's

00:01:15,210 --> 00:01:19,470
has been that they take low level

00:01:17,729 --> 00:01:21,119
features and built them up to high level

00:01:19,470 --> 00:01:24,060
structures so on the Left they

00:01:21,119 --> 00:01:26,759
characterize it as edges two parts two

00:01:24,060 --> 00:01:29,369
objects and on the right it's textures

00:01:26,759 --> 00:01:30,750
two features two faces so there's truth

00:01:29,369 --> 00:01:33,479
to this but it's a little bit misleading

00:01:30,750 --> 00:01:35,159
because what these CNN's are doing is

00:01:33,479 --> 00:01:36,960
not perceiving structure and shape the

00:01:35,159 --> 00:01:39,090
way we are they're really responding to

00:01:36,960 --> 00:01:41,250
textures now here's a paper

00:01:39,090 --> 00:01:43,560
demonstrating CNN's inherent bias to

00:01:41,250 --> 00:01:45,420
texture on the left or to images where

00:01:43,560 --> 00:01:47,040
we agree with the CNN on the right

00:01:45,420 --> 00:01:49,920
though we see an image that clearly has

00:01:47,040 --> 00:01:51,570
cat shaped and cat structure but it's

00:01:49,920 --> 00:01:54,299
misclassified because it's made from

00:01:51,570 --> 00:01:56,009
elephant texture here are two more

00:01:54,299 --> 00:01:58,799
examples of scenes showing seeing how

00:01:56,009 --> 00:02:01,140
sensitive CNN's are to texture in both

00:01:58,799 --> 00:02:03,060
cases just inserting very subtle

00:02:01,140 --> 00:02:06,000
textures to the image causes otherwise

00:02:03,060 --> 00:02:08,369
strong classifiers to fail in one case

00:02:06,000 --> 00:02:09,599
the banana becomes a toaster and in the

00:02:08,369 --> 00:02:13,110
other case the stop signs missed

00:02:09,599 --> 00:02:13,690
entirely CNN's are so good at texture

00:02:13,110 --> 00:02:15,730
they're actually

00:02:13,690 --> 00:02:17,590
better than us so here are the left we

00:02:15,730 --> 00:02:19,510
see images where we agree with the CNN

00:02:17,590 --> 00:02:21,670
on the right though are images where the

00:02:19,510 --> 00:02:23,920
structure has been convinced scrambled

00:02:21,670 --> 00:02:26,110
and the structure is completely gone but

00:02:23,920 --> 00:02:27,760
the texture remains and impressively the

00:02:26,110 --> 00:02:30,370
scene is actually do a great job with

00:02:27,760 --> 00:02:31,950
these two so let's take advantage of

00:02:30,370 --> 00:02:34,180
this let's apply this to problems

00:02:31,950 --> 00:02:36,550
involving subtle textures that humans

00:02:34,180 --> 00:02:38,050
have a hard time recognizing and that

00:02:36,550 --> 00:02:40,510
brings us to the main point

00:02:38,050 --> 00:02:42,760
ai and ophthalmology so first a little

00:02:40,510 --> 00:02:45,400
bit of background age-related macular

00:02:42,760 --> 00:02:47,080
degeneration or AMD is the leading cause

00:02:45,400 --> 00:02:48,550
of vision loss for Americans over the

00:02:47,080 --> 00:02:50,530
age of 50

00:02:48,550 --> 00:02:53,610
currently I thought my ophthalmologists

00:02:50,530 --> 00:02:57,280
use optical coherence tomography or OCD

00:02:53,610 --> 00:02:59,980
Oct 2 generators of the retina to

00:02:57,280 --> 00:03:02,140
diagnose and monitor this disease it has

00:02:59,980 --> 00:03:04,990
two main stages there's an early dry

00:03:02,140 --> 00:03:07,450
stage and an advanced wet stage where

00:03:04,990 --> 00:03:09,670
the vision loss occurs currently though

00:03:07,450 --> 00:03:11,890
we have no way of knowing which patients

00:03:09,670 --> 00:03:14,800
will go from the dry stage to convert to

00:03:11,890 --> 00:03:16,600
the wet stage and which won't our best

00:03:14,800 --> 00:03:19,810
guess is there are subtle textures in

00:03:16,600 --> 00:03:21,340
these images that we that we can't see

00:03:19,810 --> 00:03:23,560
that will indicate which patients will

00:03:21,340 --> 00:03:25,090
convert this is exactly the kind of

00:03:23,560 --> 00:03:28,480
problem that CNN's are great at and

00:03:25,090 --> 00:03:30,430
humans aren't as so we designed a

00:03:28,480 --> 00:03:32,770
retrospective study where we followed a

00:03:30,430 --> 00:03:34,900
set cohort of patients over two years a

00:03:32,770 --> 00:03:37,780
code or patients with dry MD over two

00:03:34,900 --> 00:03:39,280
years some converted some didn't we

00:03:37,780 --> 00:03:40,750
trained a classifier in the baseline

00:03:39,280 --> 00:03:42,310
images to see if we could determine

00:03:40,750 --> 00:03:44,980
which ones would convert and which ones

00:03:42,310 --> 00:03:47,170
wouldn't we added a proprietary

00:03:44,980 --> 00:03:49,150
normalization step to focus the

00:03:47,170 --> 00:03:51,250
classifier specifically on the region of

00:03:49,150 --> 00:03:53,200
interest and we did our training with

00:03:51,250 --> 00:03:55,900
our Dell Precision workstation and three

00:03:53,200 --> 00:03:58,090
Nvidia GV 100s this gave us the speed

00:03:55,900 --> 00:03:59,980
and flexibility to try thousands of

00:03:58,090 --> 00:04:03,310
different model architectures until we

00:03:59,980 --> 00:04:04,840
arrived at the best one and the results

00:04:03,310 --> 00:04:07,930
were pretty striking we had a strong

00:04:04,840 --> 00:04:09,640
predictive power for AMD compression AMD

00:04:07,930 --> 00:04:12,790
progression and this is a great example

00:04:09,640 --> 00:04:15,700
of a problem that doctors simply can't

00:04:12,790 --> 00:04:17,739
do now and maybe more importantly when

00:04:15,700 --> 00:04:19,630
we asked the classifier where was

00:04:17,739 --> 00:04:21,549
looking to make its decision it

00:04:19,630 --> 00:04:23,080
indicated this region just below the

00:04:21,549 --> 00:04:25,180
retina called the choroid which

00:04:23,080 --> 00:04:27,220
dovetails very nicely with a growing

00:04:25,180 --> 00:04:27,570
body of literature suggesting that there

00:04:27,220 --> 00:04:29,520
are

00:04:27,570 --> 00:04:33,000
need subclinical indications of disease

00:04:29,520 --> 00:04:34,620
in exactly this region in the future

00:04:33,000 --> 00:04:35,850
we're planning on validating this or

00:04:34,620 --> 00:04:37,410
we're currently working on validating

00:04:35,850 --> 00:04:38,820
this on a larger data set and we're

00:04:37,410 --> 00:04:41,970
working on a number of other projects

00:04:38,820 --> 00:04:44,210
involved in ophthalmology thanks for

00:04:41,970 --> 00:04:44,210
your time

00:04:50,740 --> 00:04:52,800

YouTube URL: https://www.youtube.com/watch?v=R7VRyKn2ji4


