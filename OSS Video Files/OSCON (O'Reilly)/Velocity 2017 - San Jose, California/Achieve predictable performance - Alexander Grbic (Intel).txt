Title: Achieve predictable performance - Alexander Grbic (Intel)
Publication date: 2017-06-21
Playlist: Velocity 2017 - San Jose, California
Description: 
	Alex Grbic explains how a single FPGA can deliver significant acceleration for multiple workloads. This new approach of integrating data analytics frameworks and existing databases enables enterprise customers to run unmodified applications without requiring any FPGA expertise and can be used with unstructured, NoSQL, and traditional relational databases, such as Swarm64.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:03,420 --> 00:00:09,090
well good morning everyone I'd like to

00:00:07,230 --> 00:00:12,260
cover a little bit about how you can

00:00:09,090 --> 00:00:16,139
accelerate your data analytics workloads

00:00:12,260 --> 00:00:17,939
using Intel FPGAs what's possible and

00:00:16,139 --> 00:00:21,749
how really you can take advantage of

00:00:17,939 --> 00:00:24,240
this technology it all really starts

00:00:21,749 --> 00:00:27,539
with the investment that Intel is made

00:00:24,240 --> 00:00:30,140
in big data analytics frameworks these

00:00:27,539 --> 00:00:33,420
are frameworks built on open standard

00:00:30,140 --> 00:00:36,239
building blocks as well as the API

00:00:33,420 --> 00:00:39,809
libraries that exist that we've

00:00:36,239 --> 00:00:41,730
optimized for Xeon processors within

00:00:39,809 --> 00:00:45,590
this framework and within this set of

00:00:41,730 --> 00:00:48,420
api's we've now integrated FPGAs a

00:00:45,590 --> 00:00:51,750
technology that really is emerging and

00:00:48,420 --> 00:00:53,760
becoming widespread in servers because

00:00:51,750 --> 00:00:56,429
we've integrated it within the existing

00:00:53,760 --> 00:00:58,890
frameworks and implemented some of the

00:00:56,429 --> 00:01:01,050
key functions in these libraries your

00:00:58,890 --> 00:01:02,129
applications don't need to change the

00:01:01,050 --> 00:01:04,170
workloads don't need to change

00:01:02,129 --> 00:01:05,820
themselves and I'll talk you through a

00:01:04,170 --> 00:01:10,320
few of the areas that we've been able to

00:01:05,820 --> 00:01:14,189
accelerate in key data store approaches

00:01:10,320 --> 00:01:18,570
of unstructured no SQL and relational

00:01:14,189 --> 00:01:20,610
databases so what is an FPGA and how is

00:01:18,570 --> 00:01:22,590
it accelerating the application so

00:01:20,610 --> 00:01:25,049
really you can think of an FPGA as a

00:01:22,590 --> 00:01:27,360
multi-function hardware accelerator that

00:01:25,049 --> 00:01:30,570
sits somewhere between the processor and

00:01:27,360 --> 00:01:32,700
your data now that data can get to the

00:01:30,570 --> 00:01:35,100
processor through a variety of means one

00:01:32,700 --> 00:01:37,020
is it can come from local storage right

00:01:35,100 --> 00:01:38,820
on that node it can also come from

00:01:37,020 --> 00:01:41,040
across the network if that data is

00:01:38,820 --> 00:01:43,530
stored somewhere else and we can support

00:01:41,040 --> 00:01:46,380
real-time streaming as well that can

00:01:43,530 --> 00:01:48,930
come from a variety of sources the key

00:01:46,380 --> 00:01:50,789
here really is that the FPGA support has

00:01:48,930 --> 00:01:53,130
been integrated into the Intel

00:01:50,789 --> 00:01:56,270
frameworks and ap is so you can run your

00:01:53,130 --> 00:02:00,119
applications unmodified that is a huge

00:01:56,270 --> 00:02:01,500
benefit in addition to those because

00:02:00,119 --> 00:02:03,750
you're using those same frameworks

00:02:01,500 --> 00:02:06,030
regardless of where your workload lands

00:02:03,750 --> 00:02:08,490
in the system the application will run

00:02:06,030 --> 00:02:10,740
so if there's an FPGA present it will

00:02:08,490 --> 00:02:12,090
take advantage of the FPGA and if there

00:02:10,740 --> 00:02:15,120
isn't one it will continue to execute

00:02:12,090 --> 00:02:16,830
that application on the processor so the

00:02:15,120 --> 00:02:18,930
FPGA delivers significant

00:02:16,830 --> 00:02:21,210
performance through a variety of modes

00:02:18,930 --> 00:02:22,770
there too I want to call out here one is

00:02:21,210 --> 00:02:24,540
what we call look beside acceleration

00:02:22,770 --> 00:02:26,460
and this is through intervention of the

00:02:24,540 --> 00:02:28,890
processor where the processor will move

00:02:26,460 --> 00:02:30,690
some data into the FPGA the FPGA will

00:02:28,890 --> 00:02:32,810
perform some type of computation on it

00:02:30,690 --> 00:02:35,340
and then send it back to the processor

00:02:32,810 --> 00:02:36,780
that's the look the side approach the

00:02:35,340 --> 00:02:38,970
second one is what we call inline

00:02:36,780 --> 00:02:40,560
acceleration so while that data is

00:02:38,970 --> 00:02:42,570
coming either from the network from

00:02:40,560 --> 00:02:44,220
local data access or for streaming you

00:02:42,570 --> 00:02:47,130
can process that data on the fly in the

00:02:44,220 --> 00:02:49,530
FPGA without the processor intervening

00:02:47,130 --> 00:02:51,690
this is powerful so you can do functions

00:02:49,530 --> 00:02:53,130
such as compression filtering encryption

00:02:51,690 --> 00:02:55,080
as well as some of the traditional

00:02:53,130 --> 00:02:59,790
things that PGA's have been good at such

00:02:55,080 --> 00:03:01,980
as fast look ups and and in hat a few

00:02:59,790 --> 00:03:03,990
examples that we have through our

00:03:01,980 --> 00:03:07,560
partner ecosystem as well as some of the

00:03:03,990 --> 00:03:09,480
examples that intel has built so if we

00:03:07,560 --> 00:03:12,120
take a look at the unstructured approach

00:03:09,480 --> 00:03:14,070
here for Hadoop we've been able to

00:03:12,120 --> 00:03:16,410
accelerate the aggregation or shuffle

00:03:14,070 --> 00:03:17,850
phase and we do this primarily through

00:03:16,410 --> 00:03:21,840
implementing a high performance

00:03:17,850 --> 00:03:23,880
compression algorithm in the FPGA we can

00:03:21,840 --> 00:03:25,680
do this for SPARC as well and I've shown

00:03:23,880 --> 00:03:28,200
three additional examples here so

00:03:25,680 --> 00:03:30,150
partner of ours called bitstream has

00:03:28,200 --> 00:03:34,230
been able to accelerate the ingress the

00:03:30,150 --> 00:03:37,770
in data processing to SPARC by about 3x

00:03:34,230 --> 00:03:40,380
by taking advantage of the FPGA if your

00:03:37,770 --> 00:03:42,989
work load requires machine learning we

00:03:40,380 --> 00:03:46,200
have support for that as well so Intel

00:03:42,989 --> 00:03:48,510
has contributed the big DL library which

00:03:46,200 --> 00:03:50,610
is implemented on top of Intel's math

00:03:48,510 --> 00:03:53,400
kernal library support where we have

00:03:50,610 --> 00:03:54,989
hardware acceleration in the FPGA built

00:03:53,400 --> 00:03:58,410
into that and some of the more

00:03:54,989 --> 00:04:01,950
traditional M Lib ml libs as well for

00:03:58,410 --> 00:04:04,230
unsupervised machine learning in the

00:04:01,950 --> 00:04:06,090
area of no SQL we have a partner called

00:04:04,230 --> 00:04:08,610
out the logic that is implemented

00:04:06,090 --> 00:04:10,530
networking and data access in the FPGA

00:04:08,610 --> 00:04:14,160
so you harden parts of the network stack

00:04:10,530 --> 00:04:16,709
as well as the lookups to key values in

00:04:14,160 --> 00:04:19,380
memory again over a 3x performance

00:04:16,709 --> 00:04:21,390
improvement in that processing and then

00:04:19,380 --> 00:04:24,750
for traditional SQL in relational

00:04:21,390 --> 00:04:28,200
databases our partner swarm 64 has been

00:04:24,750 --> 00:04:30,670
able to implement algorithms that that

00:04:28,200 --> 00:04:32,950
can support up to a million queer

00:04:30,670 --> 00:04:37,600
or updates per second for real-time

00:04:32,950 --> 00:04:40,030
Postgres SQL processing that's about a

00:04:37,600 --> 00:04:43,060
5x improvement over a non accelerated

00:04:40,030 --> 00:04:44,890
version so some initial impressive

00:04:43,060 --> 00:04:46,930
results ones that we can demonstrate to

00:04:44,890 --> 00:04:49,020
you talk to you more integrate into your

00:04:46,930 --> 00:04:52,470
systems we'd be happy to do that

00:04:49,020 --> 00:04:55,240
so really to summarize on top of that

00:04:52,470 --> 00:04:57,370
standards-based set of frameworks that

00:04:55,240 --> 00:04:59,530
Intel provides an API is for libraries

00:04:57,370 --> 00:05:02,730
that those workloads use we've now

00:04:59,530 --> 00:05:05,920
implemented FPGA support for them and

00:05:02,730 --> 00:05:08,200
that FPGA even one per server can

00:05:05,920 --> 00:05:10,030
provide significant acceleration for a

00:05:08,200 --> 00:05:11,830
variety of different workloads because

00:05:10,030 --> 00:05:14,590
that FPGA can be configured to support

00:05:11,830 --> 00:05:16,120
different harden functions and we enable

00:05:14,590 --> 00:05:18,040
this support through really are broad

00:05:16,120 --> 00:05:21,070
and developing set of data analytic

00:05:18,040 --> 00:05:22,420
solutions and partners out there so I'd

00:05:21,070 --> 00:05:24,790
love to talk to you more about it and

00:05:22,420 --> 00:05:29,059
hope to see you later today thank you

00:05:24,790 --> 00:05:29,059
[Applause]

00:05:34,070 --> 00:05:36,130

YouTube URL: https://www.youtube.com/watch?v=62VnMnCZUhY


