Title: Integrating FPGA's with API's for ease of use with Michael Strickland (Intel)
Publication date: 2017-06-27
Playlist: Velocity 2017 - San Jose, California
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:00,000 --> 00:00:04,650
hi this is Mike Hendrickson from fluent

00:00:01,979 --> 00:00:06,089
in velocity in San Jose I'm here with

00:00:04,650 --> 00:00:07,259
Mike Strickland from Intel Mike how you

00:00:06,089 --> 00:00:09,599
doing I'm good thank you

00:00:07,259 --> 00:00:11,280
so one of the things we heard and we've

00:00:09,599 --> 00:00:15,059
heard it for 10 years is about

00:00:11,280 --> 00:00:18,449
operations and DevOps and performance

00:00:15,059 --> 00:00:20,490
mm-hmm how is intel's fpga program going

00:00:18,449 --> 00:00:22,890
to help people with getting better

00:00:20,490 --> 00:00:24,090
performance yeah so so as you said one

00:00:22,890 --> 00:00:26,010
of the themes here at this show is

00:00:24,090 --> 00:00:28,650
performance and flexibility and being

00:00:26,010 --> 00:00:30,840
able to move quickly and the IT data

00:00:28,650 --> 00:00:32,850
center environment is moving quickly the

00:00:30,840 --> 00:00:34,969
good news is FPGAs are programmable so

00:00:32,850 --> 00:00:37,230
they're inherently flexible and

00:00:34,969 --> 00:00:38,879
adaptable however the challenge in the

00:00:37,230 --> 00:00:41,460
past have been these of use for these

00:00:38,879 --> 00:00:42,950
FPGAs well they're widely deployed it

00:00:41,460 --> 00:00:45,600
requires people with specialized

00:00:42,950 --> 00:00:47,670
programming knowledge and for the

00:00:45,600 --> 00:00:49,230
average enterprise data center it then

00:00:47,670 --> 00:00:51,989
will be complicated for them to use

00:00:49,230 --> 00:00:54,629
these FPGAs so Intel is taking the

00:00:51,989 --> 00:00:58,109
approach now of integrating these FPGAs

00:00:54,629 --> 00:00:59,640
underneath frameworks and api's so that

00:00:58,109 --> 00:01:02,010
they're easier to use for the enterprise

00:00:59,640 --> 00:01:03,750
well how does how does a framework in an

00:01:02,010 --> 00:01:06,360
API make it easier for a developer to

00:01:03,750 --> 00:01:07,860
use your FPGAs I mean is there some

00:01:06,360 --> 00:01:10,650
magic are you hiding some of the

00:01:07,860 --> 00:01:12,390
complexity what's going on there let me

00:01:10,650 --> 00:01:15,360
go through an example so for instance

00:01:12,390 --> 00:01:17,610
intel has been talking about proof of

00:01:15,360 --> 00:01:20,159
concept we're developing to accelerate

00:01:17,610 --> 00:01:22,380
the shuffle phase of Hadoop or sparkly

00:01:20,159 --> 00:01:24,030
aggregate the results by using better

00:01:22,380 --> 00:01:27,450
compression with the FPGA

00:01:24,030 --> 00:01:29,759
and so Intel is always developing

00:01:27,450 --> 00:01:31,619
frameworks and api's they're tuned for

00:01:29,759 --> 00:01:33,720
performance for Xeon instruction sets

00:01:31,619 --> 00:01:36,509
and so there's a spark framework that's

00:01:33,720 --> 00:01:38,130
out there we can now integrate the FPGA

00:01:36,509 --> 00:01:40,200
underneath what would normally be a

00:01:38,130 --> 00:01:42,720
compression call to some software and

00:01:40,200 --> 00:01:44,579
hide the FPGA underneath it so the

00:01:42,720 --> 00:01:46,710
software is unmodified makes the same

00:01:44,579 --> 00:01:49,649
compression call instead it goes to the

00:01:46,710 --> 00:01:52,290
FPGA and one of the advantages now is at

00:01:49,649 --> 00:01:54,060
runtime you can either run on a Xeon

00:01:52,290 --> 00:01:56,969
processor or where you can run on the

00:01:54,060 --> 00:01:59,009
FPGA so you have that flexibility and as

00:01:56,969 --> 00:02:02,820
well you have now from Intel and

00:01:59,009 --> 00:02:06,200
accelerator and Xeon processor with n n

00:02:02,820 --> 00:02:09,899
virtualization and security and then

00:02:06,200 --> 00:02:11,760
lastly I would just say that you know as

00:02:09,899 --> 00:02:13,140
well it's an integrated solution form

00:02:11,760 --> 00:02:15,930
orchestration so we're

00:02:13,140 --> 00:02:18,780
openstack compliant so is is this going

00:02:15,930 --> 00:02:21,330
to make life easier or more complex for

00:02:18,780 --> 00:02:24,390
a data center I mean our FPGAs are

00:02:21,330 --> 00:02:27,390
intended to make things more performant

00:02:24,390 --> 00:02:29,400
faster are they going to be scalable and

00:02:27,390 --> 00:02:31,620
resilient as well I mean is that going

00:02:29,400 --> 00:02:33,060
to make the data center people's life

00:02:31,620 --> 00:02:34,800
better sure

00:02:33,060 --> 00:02:36,900
so one well-known example right now is

00:02:34,800 --> 00:02:38,670
Microsoft and Microsoft shared a lot of

00:02:36,900 --> 00:02:40,650
information about how they use an Intel

00:02:38,670 --> 00:02:43,430
FPGAs so they've talked about

00:02:40,650 --> 00:02:47,610
accelerating machine learning networking

00:02:43,430 --> 00:02:49,140
different types of traffic however not

00:02:47,610 --> 00:02:51,360
everyone has the expertise that

00:02:49,140 --> 00:02:54,120
Microsoft has in terms of operating

00:02:51,360 --> 00:02:57,480
software and even even FPGA knowledge

00:02:54,120 --> 00:02:59,940
and so what we're delivering now is an

00:02:57,480 --> 00:03:00,510
approach that so completely hides the

00:02:59,940 --> 00:03:03,269
FPGA

00:03:00,510 --> 00:03:05,220
that your analytics program doesn't have

00:03:03,269 --> 00:03:07,260
to be changed at all so whether you're

00:03:05,220 --> 00:03:09,840
running a Hadoop job or traditional

00:03:07,260 --> 00:03:11,670
sequel relational job there's no change

00:03:09,840 --> 00:03:14,250
to that so from the point of view of the

00:03:11,670 --> 00:03:16,830
programmer they have no idea that an

00:03:14,250 --> 00:03:18,630
FPGA is there except for things running

00:03:16,830 --> 00:03:22,500
faster of course so if you're making

00:03:18,630 --> 00:03:25,290
FPGA acceleration more attainable or

00:03:22,500 --> 00:03:27,480
your data center is you're making life

00:03:25,290 --> 00:03:30,209
quicker and we're going to go start to

00:03:27,480 --> 00:03:33,060
crunch more data is that I mean it the

00:03:30,209 --> 00:03:34,980
the panacea here is that when your

00:03:33,060 --> 00:03:37,860
machine learning is going to be

00:03:34,980 --> 00:03:40,170
crunching big amounts of data is this

00:03:37,860 --> 00:03:43,140
FPGA approach going to make things much

00:03:40,170 --> 00:03:45,180
better yes absolutely and so it's a very

00:03:43,140 --> 00:03:47,160
competitive environment in cloud hosting

00:03:45,180 --> 00:03:49,290
and of course enterprise data centers

00:03:47,160 --> 00:03:51,540
have to be a little bit more efficient

00:03:49,290 --> 00:03:53,700
as well to keep up with that and so to

00:03:51,540 --> 00:03:56,459
give you some examples we have what one

00:03:53,700 --> 00:03:58,500
partner our swarm 64 that can take a

00:03:56,459 --> 00:04:00,720
traditional relational database and

00:03:58,500 --> 00:04:03,570
accelerated over five times for

00:04:00,720 --> 00:04:05,579
real-time data analytics and so the FPGA

00:04:03,570 --> 00:04:08,340
there is doing some compression into

00:04:05,579 --> 00:04:09,870
Xeon memory to fit more data or they're

00:04:08,340 --> 00:04:12,209
compressing the storage you get more

00:04:09,870 --> 00:04:14,820
bandwidth in your read off to storage or

00:04:12,209 --> 00:04:17,160
they're maintaining index lookups that

00:04:14,820 --> 00:04:19,350
are more efficient so now we're the same

00:04:17,160 --> 00:04:21,750
server you plug in an Intel branded PCI

00:04:19,350 --> 00:04:23,910
Express card and things run five times

00:04:21,750 --> 00:04:25,700
faster to be able to do for instance a

00:04:23,910 --> 00:04:28,430
million updates and queer

00:04:25,700 --> 00:04:30,020
per second there are other examples as

00:04:28,430 --> 00:04:33,050
well we have another partner who does

00:04:30,020 --> 00:04:35,480
key value store a no sequel example and

00:04:33,050 --> 00:04:37,340
the FPGA completely offloads the

00:04:35,480 --> 00:04:40,550
networking so request comes in through

00:04:37,340 --> 00:04:43,190
an Ethernet interface the FPGA decodes

00:04:40,550 --> 00:04:45,500
the packet does a quick look up because

00:04:43,190 --> 00:04:47,180
FPGA is good at hashing and returns a

00:04:45,500 --> 00:04:49,130
value three times faster than a

00:04:47,180 --> 00:04:52,580
traditional server and this is going to

00:04:49,130 --> 00:04:55,280
make life easier or more complex it I

00:04:52,580 --> 00:04:58,220
mean is it going to be simple to design

00:04:55,280 --> 00:05:00,680
for deploying your large data sets or

00:04:58,220 --> 00:05:03,470
making sense of large data sets on an

00:05:00,680 --> 00:05:05,150
FPGA are you guys making that way

00:05:03,470 --> 00:05:07,220
through your api's and your frameworks

00:05:05,150 --> 00:05:10,100
mm-hmm more attainable for the average

00:05:07,220 --> 00:05:12,080
developer or yeah so it's one of the

00:05:10,100 --> 00:05:15,740
beauties of fitting into these existing

00:05:12,080 --> 00:05:18,170
API is no software needs to change so to

00:05:15,740 --> 00:05:20,030
give you go back to examples form 64

00:05:18,170 --> 00:05:21,250
there's no change your application

00:05:20,030 --> 00:05:23,900
software or the database schema

00:05:21,250 --> 00:05:26,570
everything stays the way it was before

00:05:23,900 --> 00:05:28,220
better much faster so I think it'll

00:05:26,570 --> 00:05:29,810
actually make things easier because if

00:05:28,220 --> 00:05:31,880
you have predictable latency and lower

00:05:29,810 --> 00:05:34,490
response times it always makes for a

00:05:31,880 --> 00:05:37,580
better end-user environment and where do

00:05:34,490 --> 00:05:41,330
you see developers deploying this most

00:05:37,580 --> 00:05:44,420
is it for edge applications or is it for

00:05:41,330 --> 00:05:47,450
large data sets in a large enterprise

00:05:44,420 --> 00:05:50,360
crunching you know customer records or

00:05:47,450 --> 00:05:52,940
where do you see this most useful yeah

00:05:50,360 --> 00:05:55,430
so today at the show we're focusing

00:05:52,940 --> 00:05:58,010
mostly on a traditional data center so

00:05:55,430 --> 00:06:01,220
these servers that are running sequel or

00:05:58,010 --> 00:06:03,040
Hadoop or no sequel key value store or

00:06:01,220 --> 00:06:05,770
even traditional relational databases

00:06:03,040 --> 00:06:07,970
but you talked a bit about the edge and

00:06:05,770 --> 00:06:10,550
it's not the focus of what I'm talking

00:06:07,970 --> 00:06:12,050
about today but certainly FPGA is a good

00:06:10,550 --> 00:06:14,240
on the edge of residence on video

00:06:12,050 --> 00:06:16,190
analytics doing some pre filtering and

00:06:14,240 --> 00:06:18,890
identification of what the cameras are

00:06:16,190 --> 00:06:21,770
signing in so that's maybe another

00:06:18,890 --> 00:06:23,390
interview with you to talk about the

00:06:21,770 --> 00:06:24,800
Internet of Things and ways in which

00:06:23,390 --> 00:06:26,420
FPGA is going to accelerate those

00:06:24,800 --> 00:06:29,720
workloads as well excellent

00:06:26,420 --> 00:06:31,880
so Mike if you were to fast forward 12

00:06:29,720 --> 00:06:36,090
months from now where would you like to

00:06:31,880 --> 00:06:39,330
see if PGA's and Intel in the market

00:06:36,090 --> 00:06:41,580
is it more deployment more use api's

00:06:39,330 --> 00:06:43,949
richer what would you like to see

00:06:41,580 --> 00:06:45,330
happening in the next 12 months so 12

00:06:43,949 --> 00:06:48,199
months from now I'd like to come back to

00:06:45,330 --> 00:06:51,330
this show and be able to talk about

00:06:48,199 --> 00:06:53,100
end-user deployments we have some

00:06:51,330 --> 00:06:56,250
partners running some of the traditional

00:06:53,100 --> 00:06:57,960
benchmarks like TPC DS and I think we'll

00:06:56,250 --> 00:07:00,150
see some pretty impressive results and

00:06:57,960 --> 00:07:03,150
so I hope they come back a year from now

00:07:00,150 --> 00:07:05,850
and have end-user examples some really

00:07:03,150 --> 00:07:07,560
nice benchmarks and some case studies

00:07:05,850 --> 00:07:09,180
that are very compelling excellent we

00:07:07,560 --> 00:07:11,300
look forward to that pleasure - thank

00:07:09,180 --> 00:07:11,300
you

00:07:17,100 --> 00:07:19,160

YouTube URL: https://www.youtube.com/watch?v=YsKhsZ2AZsA


