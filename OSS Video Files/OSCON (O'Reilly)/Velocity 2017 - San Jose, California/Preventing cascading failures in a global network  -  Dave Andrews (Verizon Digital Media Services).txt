Title: Preventing cascading failures in a global network  -  Dave Andrews (Verizon Digital Media Services)
Publication date: 2017-06-23
Playlist: Velocity 2017 - San Jose, California
Description: 
	Cascading failures are every team's worst nightmare. Without the right monitoring, alerting, and containment in place, the failure of a system's key part can quickly result in the entire system failing. Dave Andrews shares strategies for addressing cascading failures at various scales, on a single system, within a given data center and in a globally distributed environment.


Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:01,340 --> 00:00:05,490
first of all it's great to be back at

00:00:03,300 --> 00:00:07,350
velocity and I'm super excited to join

00:00:05,490 --> 00:00:10,349
the kind of velocity family especially

00:00:07,350 --> 00:00:11,580
on the 10th anniversary today so what I

00:00:10,349 --> 00:00:15,240
want to have a chat about this morning

00:00:11,580 --> 00:00:16,620
was cascading failure at scales just

00:00:15,240 --> 00:00:18,450
going to jump right in oh really quick

00:00:16,620 --> 00:00:21,690
edge car city an architect at Verizon

00:00:18,450 --> 00:00:23,730
digital media services so yeah jumping

00:00:21,690 --> 00:00:27,000
right in so what I mean what do I mean

00:00:23,730 --> 00:00:29,390
when I say scales at the upper end this

00:00:27,000 --> 00:00:32,219
is the edge car CDN as it exists today

00:00:29,390 --> 00:00:34,980
at least as it existed last week when I

00:00:32,219 --> 00:00:37,200
made this slide we're growing reason

00:00:34,980 --> 00:00:39,000
rather quickly I think two years ago our

00:00:37,200 --> 00:00:41,430
total network capacity was between two

00:00:39,000 --> 00:00:44,700
to three terabytes per second so yeah

00:00:41,430 --> 00:00:46,290
growing rather quickly at the analogy I

00:00:44,700 --> 00:00:47,700
draw I kind of feel like a 16 year old

00:00:46,290 --> 00:00:49,950
who's just been handed the keys to a

00:00:47,700 --> 00:00:51,630
Lamborghini and it's straddling that

00:00:49,950 --> 00:00:55,620
line between super excited with this

00:00:51,630 --> 00:00:58,350
amazing toy and absolutely terrified so

00:00:55,620 --> 00:01:00,000
yeah we do a reasonable chunk of the

00:00:58,350 --> 00:01:01,559
global Internet traffic we support some

00:01:00,000 --> 00:01:03,930
of the biggest logos on the web so we

00:01:01,559 --> 00:01:07,049
have a reasonably vested interest in

00:01:03,930 --> 00:01:09,479
resiliency at scale the smaller scale

00:01:07,049 --> 00:01:09,960
we'll get into but first just to kick it

00:01:09,479 --> 00:01:13,289
off

00:01:09,960 --> 00:01:15,329
what is the cascading failure well um

00:01:13,289 --> 00:01:17,850
one way to think about it is a cascading

00:01:15,329 --> 00:01:19,499
failure is when the failure of one

00:01:17,850 --> 00:01:21,329
component in your system can cause a

00:01:19,499 --> 00:01:23,130
ripple on effect and take down the

00:01:21,329 --> 00:01:25,380
entire system like dominoes falling or

00:01:23,130 --> 00:01:31,229
these really oddly arranged matches

00:01:25,380 --> 00:01:32,880
Catching Fire so how do we go about kind

00:01:31,229 --> 00:01:34,529
of preventing or working around this

00:01:32,880 --> 00:01:37,020
problem what strategies do we use to

00:01:34,529 --> 00:01:38,909
make sure that this never happens first

00:01:37,020 --> 00:01:41,369
one load testing we basically try to

00:01:38,909 --> 00:01:43,219
understand the capacity of all the

00:01:41,369 --> 00:01:47,429
individual components in our system

00:01:43,219 --> 00:01:49,200
monitoring and alerting we try to have

00:01:47,429 --> 00:01:50,939
visibility into what production is

00:01:49,200 --> 00:01:53,490
actually doing as it relates to those

00:01:50,939 --> 00:01:55,079
theoretical like maximums and get

00:01:53,490 --> 00:01:57,779
alerting when it's getting close

00:01:55,079 --> 00:02:01,109
traffic shaping or load balancing allows

00:01:57,779 --> 00:02:02,849
us to kind of distribute the load evenly

00:02:01,109 --> 00:02:04,349
so there's no hotspots within our

00:02:02,849 --> 00:02:05,939
network and we're getting the maximum

00:02:04,349 --> 00:02:08,160
maximum throughput for the hardware that

00:02:05,939 --> 00:02:09,509
we have and the one that doesn't get a

00:02:08,160 --> 00:02:11,610
lot of love which is the one that I'm

00:02:09,509 --> 00:02:13,980
going to talk about today is containment

00:02:11,610 --> 00:02:17,129
the idea of containment is you've done

00:02:13,980 --> 00:02:19,200
the first three great something is still

00:02:17,129 --> 00:02:20,610
failed a bogus and snuck in there's a

00:02:19,200 --> 00:02:23,250
massive surge in traffic that wasn't

00:02:20,610 --> 00:02:24,959
expected something happens and some and

00:02:23,250 --> 00:02:27,299
something is going to fail how do you

00:02:24,959 --> 00:02:29,670
limit the blast radius and provide the

00:02:27,299 --> 00:02:33,090
best quality service possible in that in

00:02:29,670 --> 00:02:37,349
that scenario so starting at the smaller

00:02:33,090 --> 00:02:39,150
scale containment on a single system we

00:02:37,349 --> 00:02:40,950
can imagine you know image an edge node

00:02:39,150 --> 00:02:42,989
in our network has a variety of

00:02:40,950 --> 00:02:45,060
processes we have the main process which

00:02:42,989 --> 00:02:47,430
is the Sailfish web server delivering

00:02:45,060 --> 00:02:49,260
HTTP requests and then a bunch of

00:02:47,430 --> 00:02:49,980
secondary and tertiary processes running

00:02:49,260 --> 00:02:52,379
on the box

00:02:49,980 --> 00:02:56,670
everything from purging log ingestion

00:02:52,379 --> 00:02:58,799
monitoring etc what we don't want is a

00:02:56,670 --> 00:03:00,689
bug in one of those tertiary systems to

00:02:58,799 --> 00:03:02,219
impact the performance of the main the

00:03:00,689 --> 00:03:04,950
main function of the box so we use

00:03:02,219 --> 00:03:06,299
control groups to wall off the secondary

00:03:04,950 --> 00:03:08,310
components so that even if something

00:03:06,299 --> 00:03:11,040
sneaks in they can't run away with the

00:03:08,310 --> 00:03:14,099
entire system stepping up a level

00:03:11,040 --> 00:03:15,989
containment within a pup if we assume

00:03:14,099 --> 00:03:18,150
that we've done perfect load balancing

00:03:15,989 --> 00:03:19,799
perfect traffic shaping every box within

00:03:18,150 --> 00:03:22,500
the pup is getting an equal share of the

00:03:19,799 --> 00:03:24,840
traffic how do we deal with the scenario

00:03:22,500 --> 00:03:26,430
where something is going to fail so

00:03:24,840 --> 00:03:27,870
let's say a pup can do a million

00:03:26,430 --> 00:03:30,739
requests per second and we're currently

00:03:27,870 --> 00:03:33,359
getting 1.1 million requests per second

00:03:30,739 --> 00:03:35,969
in that option we can try to serve

00:03:33,359 --> 00:03:37,829
everything and degrade everything or we

00:03:35,969 --> 00:03:41,930
can rate limit and decide to upfront

00:03:37,829 --> 00:03:44,159
basically return a 503 or 429 or reject

00:03:41,930 --> 00:03:46,079
that additional load that we know that

00:03:44,159 --> 00:03:48,450
we can't handle so basically fail

00:03:46,079 --> 00:03:49,379
quickly let people retry and that's

00:03:48,450 --> 00:03:51,780
worth noting that we've never actually

00:03:49,379 --> 00:03:54,840
had to do this but this is what we would

00:03:51,780 --> 00:03:55,409
do in that sort of event and stepping up

00:03:54,840 --> 00:03:59,909
again

00:03:55,409 --> 00:04:01,530
containment globally what we do here is

00:03:59,909 --> 00:04:03,780
we basically carve up the world in two

00:04:01,530 --> 00:04:05,730
separate regions and then we use DNS to

00:04:03,780 --> 00:04:08,609
select regions of pubs to deliver

00:04:05,730 --> 00:04:10,680
traffic so what that means essentially

00:04:08,609 --> 00:04:13,650
is that someone in Australia where I'm

00:04:10,680 --> 00:04:15,329
from will only ever get requested what

00:04:13,650 --> 00:04:18,540
so their traffic will only ever get

00:04:15,329 --> 00:04:21,240
served out of the asia-pacific region so

00:04:18,540 --> 00:04:22,890
if we extrapolate from that if all of

00:04:21,240 --> 00:04:24,000
APEC is on fire for some particular

00:04:22,890 --> 00:04:26,370
reason

00:04:24,000 --> 00:04:28,680
users and clients in north america and

00:04:26,370 --> 00:04:29,850
europe will be not impacted at all which

00:04:28,680 --> 00:04:31,250
is nice so we're basically drawing a

00:04:29,850 --> 00:04:33,930
border around different regions

00:04:31,250 --> 00:04:37,130
geographically and containing say

00:04:33,930 --> 00:04:39,990
stereos that way so just to summarize

00:04:37,130 --> 00:04:42,900
there's four strategies variety of

00:04:39,990 --> 00:04:44,460
scales we layer each strategy so I relay

00:04:42,900 --> 00:04:47,730
each of those strategies at each scale

00:04:44,460 --> 00:04:49,290
and kind of the whole mess combined is

00:04:47,730 --> 00:04:50,970
what we used to try to ensure we have

00:04:49,290 --> 00:04:54,030
some resiliency against cascading

00:04:50,970 --> 00:04:55,260
failures and if you're masochistic and

00:04:54,030 --> 00:04:57,090
want to hear me talk about this for more

00:04:55,260 --> 00:04:59,070
than five minutes feel free to stop by

00:04:57,090 --> 00:05:01,160
our booth on the expo floor or hit me up

00:04:59,070 --> 00:05:05,059
on Twitter thank you

00:05:01,160 --> 00:05:05,059

YouTube URL: https://www.youtube.com/watch?v=x58YJQtnRZE


