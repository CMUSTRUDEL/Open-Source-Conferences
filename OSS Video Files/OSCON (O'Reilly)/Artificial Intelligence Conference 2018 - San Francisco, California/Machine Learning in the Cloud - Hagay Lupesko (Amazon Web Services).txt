Title: Machine Learning in the Cloud - Hagay Lupesko (Amazon Web Services)
Publication date: 2018-09-07
Playlist: Artificial Intelligence Conference 2018 - San Francisco, California
Description: 
	AWS puts machine learning in reach of every developer and data scientist. Hagay Lupesko explores key trends in machine learning, the importance of designing models for scale, and the impact that machine learning innovation has had on startups and enterprises alike.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,060 --> 00:00:05,279
we've learned that our customers vary in

00:00:03,570 --> 00:00:08,160
their level of expression earning

00:00:05,279 --> 00:00:10,380
expertise funding requirements and time

00:00:08,160 --> 00:00:12,870
to market and this really boils down to

00:00:10,380 --> 00:00:14,700
us embracing machine learning of every

00:00:12,870 --> 00:00:19,260
size and shape so we can give our

00:00:14,700 --> 00:00:21,240
customers choice and it's a WS we

00:00:19,260 --> 00:00:23,010
address this need via a layered approach

00:00:21,240 --> 00:00:24,750
to solving AI problems and we've

00:00:23,010 --> 00:00:27,000
designed our machine learning service

00:00:24,750 --> 00:00:30,150
stack accordingly and let's go over that

00:00:27,000 --> 00:00:32,130
so at the lower level of the stack we

00:00:30,150 --> 00:00:33,840
offer the frameworks which are all

00:00:32,130 --> 00:00:35,700
available is open source solution and

00:00:33,840 --> 00:00:38,160
also available as pre-configured

00:00:35,700 --> 00:00:40,050
pre-optimized installed packages that

00:00:38,160 --> 00:00:42,030
are ready to go on AWS deep learning

00:00:40,050 --> 00:00:45,719
army the Amazon machine instance that

00:00:42,030 --> 00:00:49,200
runs on ec2 there is a segment of our

00:00:45,719 --> 00:00:50,989
customer base of customers with really

00:00:49,200 --> 00:00:53,129
high machine learning expertise

00:00:50,989 --> 00:00:55,440
scientists researchers and alike who

00:00:53,129 --> 00:00:57,360
want tight control over the environment

00:00:55,440 --> 00:00:59,879
and are comfortable tweaking machine

00:00:57,360 --> 00:01:01,500
learning at a very low level our

00:00:59,879 --> 00:01:01,859
ephemeral Kaufering includes framework

00:01:01,500 --> 00:01:04,019
like

00:01:01,859 --> 00:01:06,720
MX net with its performance and

00:01:04,019 --> 00:01:07,680
scalability care us with it ease of use

00:01:06,720 --> 00:01:11,340
tensorflow

00:01:07,680 --> 00:01:12,930
which is very popular framework pi torch

00:01:11,340 --> 00:01:15,990
with this game which is gaining lots of

00:01:12,930 --> 00:01:18,360
momentum across which research scientist

00:01:15,990 --> 00:01:20,759
and also onyx which is the framework the

00:01:18,360 --> 00:01:22,560
framework that enables developers and

00:01:20,759 --> 00:01:26,700
scientists to port their models across

00:01:22,560 --> 00:01:29,610
frameworks and for us at AWS we want to

00:01:26,700 --> 00:01:32,310
make sure that at that level customers

00:01:29,610 --> 00:01:34,680
get a choice the best and most popular

00:01:32,310 --> 00:01:36,420
tools are all represented and customer

00:01:34,680 --> 00:01:41,610
can pick and choose the tool that works

00:01:36,420 --> 00:01:43,290
best for them we go one layer above the

00:01:41,610 --> 00:01:45,990
frameworks layer we have the platform

00:01:43,290 --> 00:01:48,540
layer and on the platform layer we have

00:01:45,990 --> 00:01:51,689
D plans which is the world's first deep

00:01:48,540 --> 00:01:53,430
learning enabled video camera built for

00:01:51,689 --> 00:01:56,070
developers to be used by developers

00:01:53,430 --> 00:01:57,479
which it enables developers to deploy

00:01:56,070 --> 00:02:00,390
models writing the difference for

00:01:57,479 --> 00:02:03,210
prototyping experimentation and the sage

00:02:00,390 --> 00:02:05,340
maker sage maker is Amazon machine

00:02:03,210 --> 00:02:07,229
learning platform for end-to-end model

00:02:05,340 --> 00:02:08,640
lifecycle development and is one of the

00:02:07,229 --> 00:02:10,770
most exciting new machine learning

00:02:08,640 --> 00:02:11,350
services we launched at last reinvent

00:02:10,770 --> 00:02:14,440
and I want

00:02:11,350 --> 00:02:16,210
to take a closer look there we sage

00:02:14,440 --> 00:02:18,430
maker developers and scientist have the

00:02:16,210 --> 00:02:20,200
power and flexibility to experiment

00:02:18,430 --> 00:02:22,960
collaborate and ship models while

00:02:20,200 --> 00:02:24,760
letting the platform itself handled all

00:02:22,960 --> 00:02:26,290
the undifferentiated heavy lifting for

00:02:24,760 --> 00:02:30,130
them which eventually speeds up

00:02:26,290 --> 00:02:32,140
development we say Jamaica you build and

00:02:30,130 --> 00:02:33,790
train your model and you can do it on

00:02:32,140 --> 00:02:36,550
one of the leading frameworks like MX

00:02:33,790 --> 00:02:39,220
net Apache MX net tensor flow or PI

00:02:36,550 --> 00:02:41,800
torch or chain air or you can bring your

00:02:39,220 --> 00:02:44,130
own algorithm through a container or you

00:02:41,800 --> 00:02:46,660
can use our pre-built pre optimized

00:02:44,130 --> 00:02:49,240
algorithm that are available on the sage

00:02:46,660 --> 00:02:51,010
maker platform after you've built and

00:02:49,240 --> 00:02:53,260
trained your model you can optimize it

00:02:51,010 --> 00:02:55,030
and we offer optimization tools that are

00:02:53,260 --> 00:02:56,560
built into Sage maker advanced

00:02:55,030 --> 00:02:58,660
techniques like hyper parameter

00:02:56,560 --> 00:03:00,520
optimizations is available within sage

00:02:58,660 --> 00:03:02,440
maker and lastly once your model is

00:03:00,520 --> 00:03:04,690
ready to be shipped it takes only one

00:03:02,440 --> 00:03:06,550
API call one click of a button to

00:03:04,690 --> 00:03:09,850
actually take your model and deploy it

00:03:06,550 --> 00:03:12,760
to become an endpoint that your clients

00:03:09,850 --> 00:03:14,560
or other web services can call and on

00:03:12,760 --> 00:03:15,970
Sage Maker can also easily a be test as

00:03:14,560 --> 00:03:17,980
you deploy your models and you want to

00:03:15,970 --> 00:03:19,930
make sure the work is expected or you

00:03:17,980 --> 00:03:21,880
want to compare their performance all

00:03:19,930 --> 00:03:24,700
done for you all the undifferentiated

00:03:21,880 --> 00:03:27,640
heavy lifting is handled for you so as a

00:03:24,700 --> 00:03:31,060
customer you can actually focus on what

00:03:27,640 --> 00:03:33,940
matters which is your business logic ok

00:03:31,060 --> 00:03:36,040
so when we go one layer higher there is

00:03:33,940 --> 00:03:38,080
the top of the stack we have the machine

00:03:36,040 --> 00:03:39,940
learning application services and these

00:03:38,080 --> 00:03:41,830
are cognitive services that will

00:03:39,940 --> 00:03:44,800
encapsulate state-of-the-art models

00:03:41,830 --> 00:03:49,810
across various domains but the expose it

00:03:44,800 --> 00:03:51,880
is a easy to call Web API that our

00:03:49,810 --> 00:03:55,000
service and that scale for the customer

00:03:51,880 --> 00:03:56,560
needs so we offer API for computer

00:03:55,000 --> 00:03:59,650
vision via Amazon recognition

00:03:56,560 --> 00:04:01,510
translation the Amazon translate natural

00:03:59,650 --> 00:04:04,600
language understanding we are comprehend

00:04:01,510 --> 00:04:06,580
chat BOTS via Lex text-to-speech we are

00:04:04,600 --> 00:04:08,290
poorly and there's others that I haven't

00:04:06,580 --> 00:04:10,960
mentioned and more interesting services

00:04:08,290 --> 00:04:13,990
are coming but the key point here is we

00:04:10,960 --> 00:04:15,790
cater for that tier of developers who do

00:04:13,990 --> 00:04:17,710
not want to build or not able to build

00:04:15,790 --> 00:04:19,210
that level of expertise in deep learning

00:04:17,710 --> 00:04:21,729
but we enable them to use

00:04:19,210 --> 00:04:24,630
state-of-the-art cutting-edge models by

00:04:21,729 --> 00:04:24,630
just calling an API

00:04:30,800 --> 00:04:32,860

YouTube URL: https://www.youtube.com/watch?v=W1QaB-CHEGM


