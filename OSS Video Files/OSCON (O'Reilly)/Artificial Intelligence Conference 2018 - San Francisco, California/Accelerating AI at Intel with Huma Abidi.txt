Title: Accelerating AI at Intel with Huma Abidi
Publication date: 2018-09-21
Playlist: Artificial Intelligence Conference 2018 - San Francisco, California
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:04,920
hi I'm Roger goalless we're here at the

00:00:02,190 --> 00:00:06,810
AI conference in San Francisco in 2018

00:00:04,920 --> 00:00:08,760
and I'm here with Huma a Bedi

00:00:06,810 --> 00:00:11,190
who is the director of machine learning

00:00:08,760 --> 00:00:13,769
and deep learning software at Intel I

00:00:11,190 --> 00:00:15,990
know the Intel has made a big push in

00:00:13,769 --> 00:00:17,850
this area and it's Epicure is like you

00:00:15,990 --> 00:00:20,550
know who you are in terms of working on

00:00:17,850 --> 00:00:24,779
this and what you work on okay I didn't

00:00:20,550 --> 00:00:27,930
tell ya you got to be here so my focus

00:00:24,779 --> 00:00:30,179
is getting software to get best

00:00:27,930 --> 00:00:32,940
performance out of the hardware and I

00:00:30,179 --> 00:00:34,710
manage software optimization team and

00:00:32,940 --> 00:00:37,590
they artificial intelligence product

00:00:34,710 --> 00:00:39,719
group at Intel and we have a very

00:00:37,590 --> 00:00:42,210
extensive portfolio for both hardware

00:00:39,719 --> 00:00:45,539
and software so on the hardware side

00:00:42,210 --> 00:00:48,450
from data center to edge to device we

00:00:45,539 --> 00:00:51,570
have general-purpose CPUs we also have

00:00:48,450 --> 00:00:54,000
FPGAs we have accelerator neural network

00:00:51,570 --> 00:00:56,370
processor so all that is there but

00:00:54,000 --> 00:00:58,530
without the software you won't get the

00:00:56,370 --> 00:01:00,300
maximum out of it especially for AI

00:00:58,530 --> 00:01:03,090
workloads which are very computer

00:01:00,300 --> 00:01:06,330
intensive so the focus that my team has

00:01:03,090 --> 00:01:08,310
is to optimize this and to make sure

00:01:06,330 --> 00:01:12,150
that the performance that our customers

00:01:08,310 --> 00:01:14,400
get is is the best that you can so we

00:01:12,150 --> 00:01:16,229
leveraged for example these all the open

00:01:14,400 --> 00:01:16,979
source frameworks that out there so

00:01:16,229 --> 00:01:20,880
tensorflow

00:01:16,979 --> 00:01:23,130
pie chart MX that all of those we work

00:01:20,880 --> 00:01:25,740
closely with them and we make sure that

00:01:23,130 --> 00:01:28,890
they are highly optimized specifically

00:01:25,740 --> 00:01:31,350
for Xeon and or all other in that

00:01:28,890 --> 00:01:34,530
hardware so that's the focus that I have

00:01:31,350 --> 00:01:36,000
okay so a real software focus to make

00:01:34,530 --> 00:01:38,729
sure that you're getting the performance

00:01:36,000 --> 00:01:41,759
that you want yes exactly exactly

00:01:38,729 --> 00:01:44,040
and it sounds like you're looking at

00:01:41,759 --> 00:01:46,590
both sides do you make changes to the

00:01:44,040 --> 00:01:48,090
hardware as well - absolutely so yeah so

00:01:46,590 --> 00:01:50,610
how our hardware's gained new

00:01:48,090 --> 00:01:54,030
instructions so for example in the

00:01:50,610 --> 00:01:57,270
upcoming next-generation Xeon processor

00:01:54,030 --> 00:02:00,750
we we are introducing DL boost V and n I

00:01:57,270 --> 00:02:03,479
and and to match with that we are having

00:02:00,750 --> 00:02:05,460
adding our own software optimization so

00:02:03,479 --> 00:02:08,489
together generation over generation we

00:02:05,460 --> 00:02:11,039
will get another 11 exposed so it's a

00:02:08,489 --> 00:02:13,590
combination of both hardware and

00:02:11,039 --> 00:02:16,019
software mm-hmm great

00:02:13,590 --> 00:02:17,190
and can you give an example of customers

00:02:16,019 --> 00:02:18,959
that you're working with where you're

00:02:17,190 --> 00:02:21,989
fighting both the hardware and the

00:02:18,959 --> 00:02:25,170
software so one such example is Novartis

00:02:21,989 --> 00:02:27,450
the pharmaceutical company and they had

00:02:25,170 --> 00:02:31,170
an interesting problem where they had to

00:02:27,450 --> 00:02:33,660
analyze very large images like 26 X

00:02:31,170 --> 00:02:36,569
large and the datasets that we are used

00:02:33,660 --> 00:02:38,610
to and so forth at our Zeon scalable

00:02:36,569 --> 00:02:40,650
processor was was indeed the best

00:02:38,610 --> 00:02:44,670
solution because of its large memory

00:02:40,650 --> 00:02:46,769
capacity and so taking advantage of our

00:02:44,670 --> 00:02:47,549
highly optimized Intel optimized

00:02:46,769 --> 00:02:50,430
tensorflow

00:02:47,549 --> 00:02:52,620
and scaling it up to eight node we were

00:02:50,430 --> 00:02:55,769
able to reduce the training time from

00:02:52,620 --> 00:02:58,500
hours to just minutes and so so there

00:02:55,769 --> 00:03:01,349
are many examples in in healthcare or

00:02:58,500 --> 00:03:03,090
education government retail we are

00:03:01,349 --> 00:03:05,549
working very closely with our partners

00:03:03,090 --> 00:03:07,590
and the best thing that Intel has to

00:03:05,549 --> 00:03:10,230
offer is that depending on whether it's

00:03:07,590 --> 00:03:12,329
the customer wants performance or if

00:03:10,230 --> 00:03:14,579
latency is more important or power but

00:03:12,329 --> 00:03:16,890
is more important so depending on what

00:03:14,579 --> 00:03:18,690
they need we have the right hardware and

00:03:16,890 --> 00:03:22,590
the software solution for that mm-hmm

00:03:18,690 --> 00:03:24,690
okay hearing the way you're doing this

00:03:22,590 --> 00:03:27,209
are you open sourcing so starting from

00:03:24,690 --> 00:03:29,519
the very basic Intel's math kernal

00:03:27,209 --> 00:03:32,760
library for deep neural network that is

00:03:29,519 --> 00:03:34,940
open source then we have something what

00:03:32,760 --> 00:03:38,010
we call n graph which serves as a

00:03:34,940 --> 00:03:41,250
abstraction layer or a glue between the

00:03:38,010 --> 00:03:42,299
open source frameworks and the various

00:03:41,250 --> 00:03:44,220
different architects

00:03:42,299 --> 00:03:46,470
architectures that it supports in

00:03:44,220 --> 00:03:49,019
addition to that we also have an AI lab

00:03:46,470 --> 00:03:51,810
which is which has many products such as

00:03:49,019 --> 00:03:53,760
reinforcement learning coach natural

00:03:51,810 --> 00:03:55,620
language processor architect and many

00:03:53,760 --> 00:03:57,599
other such things that we are

00:03:55,620 --> 00:03:59,549
continuously open sourcing for people

00:03:57,599 --> 00:04:01,739
well that sounds great thanks a lot for

00:03:59,549 --> 00:04:04,130
participating with us glad to be here

00:04:01,739 --> 00:04:04,130
thank you

00:04:10,640 --> 00:04:12,700

YouTube URL: https://www.youtube.com/watch?v=xi3Ku6rHIaY


