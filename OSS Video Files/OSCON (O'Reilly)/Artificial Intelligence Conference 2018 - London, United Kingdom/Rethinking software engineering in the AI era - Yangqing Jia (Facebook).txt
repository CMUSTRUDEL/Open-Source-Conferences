Title: Rethinking software engineering in the AI era - Yangqing Jia (Facebook)
Publication date: 2018-10-10
Playlist: Artificial Intelligence Conference 2018 - London, United Kingdom
Description: 
	With the breakthrough of AI and deep learning technologies, conventional software engineering practices have been evolving significantly to pair with the advances of large-scale data, computation, and algorithmic evolution. Yangqing Jia shares a series of examples to illustrate the uniqueness of AI software and its connections to conventional computer science wisdom. Yangqing then discusses future software engineering principles for AI compute.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,230 --> 00:00:06,080
the beauty of computer vision is that we

00:00:03,850 --> 00:00:07,790
humans taken for granted was like what

00:00:06,080 --> 00:00:09,650
as a car it's so easy to recognize that

00:00:07,790 --> 00:00:11,300
there's no problem but it's really

00:00:09,650 --> 00:00:14,000
difficult for computers to actually do

00:00:11,300 --> 00:00:15,469
so because how do you classify a car

00:00:14,000 --> 00:00:18,740
there's wheels and things what is real

00:00:15,469 --> 00:00:20,090
is round stuff but what is round so one

00:00:18,740 --> 00:00:21,859
of the fundamental problem of computer

00:00:20,090 --> 00:00:24,920
vision is to recognize objects in this

00:00:21,859 --> 00:00:26,779
way and now in a conventional software

00:00:24,920 --> 00:00:29,599
engineering world the way we try to

00:00:26,779 --> 00:00:31,939
solve those from is to design rules or

00:00:29,599 --> 00:00:34,789
hard-coded quote-unquote features to

00:00:31,939 --> 00:00:36,589
address those prongs and before the deep

00:00:34,789 --> 00:00:38,839
learning days one really widely adopted

00:00:36,589 --> 00:00:41,780
approaches called histogram or gradients

00:00:38,839 --> 00:00:43,489
what it does is basically it finds edges

00:00:41,780 --> 00:00:44,089
of different directions destruction in

00:00:43,489 --> 00:00:45,799
that direction

00:00:44,089 --> 00:00:49,459
and try to collect the statistics

00:00:45,799 --> 00:00:51,499
locally - as a way to describe what kind

00:00:49,459 --> 00:00:53,420
of things are going on in this image so

00:00:51,499 --> 00:00:56,719
this is one example when you look at a

00:00:53,420 --> 00:00:58,850
car through this his room kind of

00:00:56,719 --> 00:01:00,859
feature if you look really carefully you

00:00:58,850 --> 00:01:02,329
can kind of see that there are different

00:01:00,859 --> 00:01:05,089
you know like a car is kind of stuff

00:01:02,329 --> 00:01:07,250
round kind of stuff over there it's not

00:01:05,089 --> 00:01:09,740
really great but it's kind of the way

00:01:07,250 --> 00:01:11,210
that we can use rules or hard coded

00:01:09,740 --> 00:01:15,020
features to represent all those images

00:01:11,210 --> 00:01:17,780
this is another view of a broader image

00:01:15,020 --> 00:01:20,149
as we can see it's an OK feature because

00:01:17,780 --> 00:01:22,039
you can kind of recognize there are you

00:01:20,149 --> 00:01:23,890
know like buildings trees rows and stuff

00:01:22,039 --> 00:01:26,750
like that in it but it's not too much

00:01:23,890 --> 00:01:28,399
well if we want to use this to infer

00:01:26,750 --> 00:01:31,039
really complex information out of these

00:01:28,399 --> 00:01:32,990
images it's really difficult right and

00:01:31,039 --> 00:01:36,350
then the question is we're actually

00:01:32,990 --> 00:01:38,990
limited by logic to design features and

00:01:36,350 --> 00:01:40,609
the create features in that way now a

00:01:38,990 --> 00:01:42,229
few years ago a grad student called

00:01:40,609 --> 00:01:43,399
actor Jeff Sookie said no we can't we

00:01:42,229 --> 00:01:45,530
don't need to do this we can actually

00:01:43,399 --> 00:01:47,719
basically write building blocks in a

00:01:45,530 --> 00:01:49,609
very abstract way or we call nowadays

00:01:47,719 --> 00:01:51,829
called convolutional neural nets to

00:01:49,609 --> 00:01:54,079
basically design what kind of sense we

00:01:51,829 --> 00:01:56,240
want to be there and then we use a

00:01:54,079 --> 00:01:58,460
massive animal data to infer what

00:01:56,240 --> 00:02:00,710
exactly they would do and basically went

00:01:58,460 --> 00:02:03,679
from the right and logic to right models

00:02:00,710 --> 00:02:05,179
in their field it worked really well and

00:02:03,679 --> 00:02:08,209
surprisingly it also has a pretty

00:02:05,179 --> 00:02:10,129
interesting biological backend of it so

00:02:08,209 --> 00:02:12,260
in our visual cortex we actually see

00:02:10,129 --> 00:02:13,319
that our brain is doing layered

00:02:12,260 --> 00:02:15,180
inference with new

00:02:13,319 --> 00:02:17,010
feeding information from layer to the

00:02:15,180 --> 00:02:18,780
next one - next one - next one and

00:02:17,010 --> 00:02:22,170
extracting more and more complex

00:02:18,780 --> 00:02:24,599
information out of that that gave us a

00:02:22,170 --> 00:02:26,879
really good win on the accuracy so over

00:02:24,599 --> 00:02:29,280
the last few years before deep line is

00:02:26,879 --> 00:02:31,560
started we saw a plateau in effect of

00:02:29,280 --> 00:02:33,620
the hard-coded features of logic so we

00:02:31,560 --> 00:02:35,700
were basically not able to get to good

00:02:33,620 --> 00:02:38,129
classification results there's a

00:02:35,700 --> 00:02:41,909
benchmark in example called imagenet

00:02:38,129 --> 00:02:43,349
that tries to recognize and objects out

00:02:41,909 --> 00:02:45,989
of a thousand categories and were able

00:02:43,349 --> 00:02:48,299
to basically get about 26% out of five

00:02:45,989 --> 00:02:50,790
guesses before we used apply new

00:02:48,299 --> 00:02:52,680
features and Aleks net in 2012 a reading

00:02:50,790 --> 00:02:54,299
made a breakthrough and had a really big

00:02:52,680 --> 00:02:57,269
jump in the accuracy that got everyone

00:02:54,299 --> 00:02:59,250
really excited about this field so

00:02:57,269 --> 00:03:01,859
essentially what we are seeing in AI is

00:02:59,250 --> 00:03:04,349
that we're starting to replace logic

00:03:01,859 --> 00:03:07,379
that we hard code and we write in our

00:03:04,349 --> 00:03:09,389
software programs - thinking more about

00:03:07,379 --> 00:03:12,239
adaptive models that can basically

00:03:09,389 --> 00:03:13,829
derive a general rule for us to do

00:03:12,239 --> 00:03:16,230
compeition and then use this massive

00:03:13,829 --> 00:03:20,000
amount of data and compute to get the

00:03:16,230 --> 00:03:20,000

YouTube URL: https://www.youtube.com/watch?v=fUMYh1lkNPE


