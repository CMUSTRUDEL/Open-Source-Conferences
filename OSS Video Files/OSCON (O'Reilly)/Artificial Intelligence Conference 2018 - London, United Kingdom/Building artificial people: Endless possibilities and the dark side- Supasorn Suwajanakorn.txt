Title: Building artificial people: Endless possibilities and the dark side- Supasorn Suwajanakorn
Publication date: 2018-10-11
Playlist: Artificial Intelligence Conference 2018 - London, United Kingdom
Description: 
	Supasorn Suwajanakorn (VISTEC (Vidyasirimedhi Institute of Science and Technology))

Supasorn Suwajanakorn is a computer vision researcher who recently developed a technique that can synthesize a speech video of President Obama by learning from existing video footage. His earlier work includes a novel method to reconstruct a 3D face model of anyone just from their photos, which was awarded the Madrona Prize and the Innovation of the Year in 2016, as well as a software that predicts an age-progressed photo of a missing child. Previously, he was a research resident at Google Brain. Supasorn holds a PhD in computer science from the University of Washington.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:04,920
now I'm going to show you what we can do

00:00:02,370 --> 00:00:08,610
today and all the latest work since 2017

00:00:04,920 --> 00:00:10,170
and how does AI play a role here by

00:00:08,610 --> 00:00:12,420
training a recurrent neural neural

00:00:10,170 --> 00:00:14,580
network on 14 hours of President Obama

00:00:12,420 --> 00:00:17,369
video we can synthesize the new lip sync

00:00:14,580 --> 00:00:21,420
videos given on the Obama video sorry

00:00:17,369 --> 00:00:24,439
given on the Obama audio the results are

00:00:21,420 --> 00:00:28,380
clear America's businesses have created

00:00:24,439 --> 00:00:30,900
14.5 million new jobs over 75 straight

00:00:28,380 --> 00:00:33,230
months we've seen the first sustained

00:00:30,900 --> 00:00:35,730
manufacturing growth since the 90s so

00:00:33,230 --> 00:00:37,440
know that only the mouth part is being

00:00:35,730 --> 00:00:39,510
synthesized here the rest of the face in

00:00:37,440 --> 00:00:41,730
the background comes from source videos

00:00:39,510 --> 00:00:43,230
which we don't have control over this

00:00:41,730 --> 00:00:44,850
also has application in the movie

00:00:43,230 --> 00:00:46,829
dubbing where we want to modify the

00:00:44,850 --> 00:00:49,350
actors mouth to speak a foreign language

00:00:46,829 --> 00:00:50,850
with the correct lip-sync so moving

00:00:49,350 --> 00:00:52,860
forward how can you allow arbitrary

00:00:50,850 --> 00:00:56,010
expressions in head motion not the one

00:00:52,860 --> 00:00:58,289
borrowed from source videos in a project

00:00:56,010 --> 00:01:00,300
called deep video portrayed by Hakeem at

00:00:58,289 --> 00:01:02,460
all they allow you to drive another

00:01:00,300 --> 00:01:06,330
person using a source video sequence on

00:01:02,460 --> 00:01:08,580
the left and what you need here is just

00:01:06,330 --> 00:01:10,590
a single video of the target person on

00:01:08,580 --> 00:01:13,020
the right and they show how you can

00:01:10,590 --> 00:01:15,570
drive the facial motion the head motion

00:01:13,020 --> 00:01:20,790
of the target person using the the

00:01:15,570 --> 00:01:22,740
source sequence on the left another

00:01:20,790 --> 00:01:24,900
recent technique that can be used for

00:01:22,740 --> 00:01:26,850
facial reenactment is called recycle

00:01:24,900 --> 00:01:29,280
cans or recycle generative adversarii

00:01:26,850 --> 00:01:31,590
networks that's how it all shows how you

00:01:29,280 --> 00:01:36,600
can transfer the motion in one video to

00:01:31,590 --> 00:01:40,770
another so the real video is on the left

00:01:36,600 --> 00:01:43,979
and it's used to drive a video of

00:01:40,770 --> 00:01:45,600
Stephen Colbert on the right in contrast

00:01:43,979 --> 00:01:47,369
to the previous work I just show this

00:01:45,600 --> 00:01:49,380
one is more generic and can be applied

00:01:47,369 --> 00:01:51,180
to any video including you know a

00:01:49,380 --> 00:01:56,299
blooming video of one flower map to

00:01:51,180 --> 00:01:56,299
another and this is done automatically

00:01:57,110 --> 00:02:02,250
so artificial humans aren't really

00:02:00,060 --> 00:02:04,079
limited to you know capturing real

00:02:02,250 --> 00:02:06,899
humans and turning them into avatars

00:02:04,079 --> 00:02:09,119
using AI care us at all from Nvidia show

00:02:06,899 --> 00:02:11,220
how machines can imagine new faces from

00:02:09,119 --> 00:02:13,410
scratch after we show them lots of

00:02:11,220 --> 00:02:13,920
celebrities photos and these two photos

00:02:13,410 --> 00:02:17,550
are what it

00:02:13,920 --> 00:02:19,349
rheems up he also show results for

00:02:17,550 --> 00:02:23,819
interpolating between different phases

00:02:19,349 --> 00:02:25,470
all of which are synthetic this is the

00:02:23,819 --> 00:02:27,090
word called progressive growing of Gans

00:02:25,470 --> 00:02:29,750
for improved quality stability and

00:02:27,090 --> 00:02:29,750
variation

00:02:42,720 --> 00:02:46,440
so another recent technique that can

00:02:44,460 --> 00:02:49,170
generate realistic face photo is by

00:02:46,440 --> 00:02:50,820
Kingma at all from opening i'm and

00:02:49,170 --> 00:02:52,800
what's interesting about this is that

00:02:50,820 --> 00:02:54,810
the model actually automatically

00:02:52,800 --> 00:02:57,450
discovers important attributes like hair

00:02:54,810 --> 00:03:00,060
color how much you smile beard or age

00:02:57,450 --> 00:03:02,400
and allows you to change that attribute

00:03:00,060 --> 00:03:04,410
given any image so here's the center of

00:03:02,400 --> 00:03:06,750
image is it's a real photo and you can

00:03:04,410 --> 00:03:10,020
change for example manipulate the hair

00:03:06,750 --> 00:03:10,680
color or making her look younger or

00:03:10,020 --> 00:03:13,170
older

00:03:10,680 --> 00:03:15,300
again this semantic attributes are

00:03:13,170 --> 00:03:18,260
discovered matically as a byproduct of

00:03:15,300 --> 00:03:18,260

YouTube URL: https://www.youtube.com/watch?v=E_oH0xS5e94


