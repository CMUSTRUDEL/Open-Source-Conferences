Title: Trust and transparency of AI for the enterprise (sponsored by IBM Watson) -Ruchir Puri (IBM)
Publication date: 2018-10-10
Playlist: Artificial Intelligence Conference 2018 - London, United Kingdom
Description: 
	Ruchir Puri is CTO and Chief Architect, IBM Watson, and an IBM Fellow, who has held various technical, research and engineering leadership roles across IBMâ€™s AI and Research businesses. Dr. Puri is a Fellow of the IEEE, and has been an ACM Distinguished Speaker, an IEEE Distinguished Lecturer, and was awarded 2014 Asian American Engineer of the Year. Ruchir has been an adjunct professor at Columbia University, NY, and a visiting scientist at Stanford University, CA. He was honored with John Von-Neumann Chair at Institute of Discrete Mathematics at Bonn University, Germany. Dr. Puri is an inventor of over 50 United States patents and has authored over 100 scientific publications on software, hardware automation methods and optimization algorithms.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,179 --> 00:00:04,979
thank you for joining me today I

00:00:02,759 --> 00:00:06,930
appreciate your time I'm gonna talk

00:00:04,979 --> 00:00:09,630
really about something that's I think

00:00:06,930 --> 00:00:12,870
important to all of us humans which is

00:00:09,630 --> 00:00:15,120
really about trust and transparency and

00:00:12,870 --> 00:00:17,160
I think one thing that's fundamental to

00:00:15,120 --> 00:00:20,040
the relationships that we have with each

00:00:17,160 --> 00:00:22,580
other is actually a fundamental notion

00:00:20,040 --> 00:00:25,080
of trust and transparency and we believe

00:00:22,580 --> 00:00:28,560
machines shouldn't be any different in

00:00:25,080 --> 00:00:29,660
fact all the narrative about AI one

00:00:28,560 --> 00:00:33,179
thing that is becoming increasingly

00:00:29,660 --> 00:00:37,579
important not just humans trusting

00:00:33,179 --> 00:00:40,620
machines but also governments as they

00:00:37,579 --> 00:00:42,989
realize the importance of AI more and

00:00:40,620 --> 00:00:45,570
more so regulations might be getting in

00:00:42,989 --> 00:00:48,030
place we are at a place where no at the

00:00:45,570 --> 00:00:51,089
advent of GDP are as well it is becoming

00:00:48,030 --> 00:00:53,550
important for us to really raise the

00:00:51,089 --> 00:00:56,190
level of awareness and put capabilities

00:00:53,550 --> 00:00:58,769
out there technical capabilities that

00:00:56,190 --> 00:01:00,839
allow people not just data scientists

00:00:58,769 --> 00:01:04,370
actually business people to really go

00:01:00,839 --> 00:01:06,840
and trust and trust the machines and

00:01:04,370 --> 00:01:09,090
realize that the decisions they are

00:01:06,840 --> 00:01:10,050
making are transparent as well so I'm

00:01:09,090 --> 00:01:12,420
going to take you through a small

00:01:10,050 --> 00:01:14,370
journey on what capabilities we have

00:01:12,420 --> 00:01:17,550
released and the level at which they

00:01:14,370 --> 00:01:19,590
exist and later in the in the morning

00:01:17,550 --> 00:01:22,320
today I'm going to give a 40 minute talk

00:01:19,590 --> 00:01:25,830
again in a deep technical dive on how

00:01:22,320 --> 00:01:28,160
they really work so most importantly

00:01:25,830 --> 00:01:30,780
let's look at where we are today know

00:01:28,160 --> 00:01:32,880
somewhere around 94% of companies

00:01:30,780 --> 00:01:35,160
believe that AI is really key to their

00:01:32,880 --> 00:01:37,640
success now that's not surprising given

00:01:35,160 --> 00:01:40,950
all the narrative around us however only

00:01:37,640 --> 00:01:43,800
35% of the people really or businesses

00:01:40,950 --> 00:01:46,380
realize that they really can trust the

00:01:43,800 --> 00:01:48,060
machinery that they have they can really

00:01:46,380 --> 00:01:52,140
put a trust in the decisions that are

00:01:48,060 --> 00:01:53,910
being made and interestingly 60% of of

00:01:52,140 --> 00:01:55,770
the companies really believe or the

00:01:53,910 --> 00:01:58,380
business people really believe they

00:01:55,770 --> 00:02:00,600
really can trust the decisions to be

00:01:58,380 --> 00:02:03,810
fair as well this really leads to the

00:02:00,600 --> 00:02:06,360
the bias issues that might exist in

00:02:03,810 --> 00:02:09,030
technology and overall just from the

00:02:06,360 --> 00:02:11,219
point of view of practical adoption we

00:02:09,030 --> 00:02:13,319
are really seeing only one in 20

00:02:11,219 --> 00:02:13,890
companies are really realizing the

00:02:13,319 --> 00:02:17,220
benefits of

00:02:13,890 --> 00:02:19,440
why right now there by Italy leads us to

00:02:17,220 --> 00:02:22,560
a dichotomy I think everybody has

00:02:19,440 --> 00:02:24,390
tremendous hope for AI but where we

00:02:22,560 --> 00:02:26,610
exist today there is a difference

00:02:24,390 --> 00:02:29,370
between hope and what we are delivering

00:02:26,610 --> 00:02:32,370
right now and really we release the

00:02:29,370 --> 00:02:35,910
capability actually of trust and

00:02:32,370 --> 00:02:38,940
transparency in the IBM cloud that

00:02:35,910 --> 00:02:40,650
allows you to really take your AI it

00:02:38,940 --> 00:02:42,360
doesn't have to run in the IBM cloud it

00:02:40,650 --> 00:02:44,670
can be running wherever you are actually

00:02:42,360 --> 00:02:46,350
you can be running in AWS it can be

00:02:44,670 --> 00:02:49,770
running in in Google or it can be

00:02:46,350 --> 00:02:52,230
running in in Microsoft we allow your AI

00:02:49,770 --> 00:02:54,600
to be wrapped around and to really

00:02:52,230 --> 00:02:56,760
deliver trust and transparency to that

00:02:54,600 --> 00:03:01,769
particular AI you are getting benefit

00:02:56,760 --> 00:03:03,690
from so most importantly I think as I

00:03:01,769 --> 00:03:05,519
said there are three fundamental tenants

00:03:03,690 --> 00:03:09,150
to the capabilities that we delivered

00:03:05,519 --> 00:03:12,330
number one it's really about detecting

00:03:09,150 --> 00:03:15,060
the bias now interestingly as most of us

00:03:12,330 --> 00:03:16,920
are aware there are actually no when

00:03:15,060 --> 00:03:18,810
models are really built when AI models

00:03:16,920 --> 00:03:21,090
are really built they actually data

00:03:18,810 --> 00:03:23,370
scientists really do a lot of work in

00:03:21,090 --> 00:03:26,220
making sure the models and the data that

00:03:23,370 --> 00:03:28,350
goes into them may be free of the skewed

00:03:26,220 --> 00:03:30,690
nature of the data that might get in let

00:03:28,350 --> 00:03:33,269
me give you a quick example for example

00:03:30,690 --> 00:03:35,940
if I was building a model for mortgage

00:03:33,269 --> 00:03:39,030
approvals and if I take the data for

00:03:35,940 --> 00:03:41,370
last 50 years as an example what might

00:03:39,030 --> 00:03:44,010
happen is that if the data point I'm

00:03:41,370 --> 00:03:46,620
looking for is Maude get is over 1

00:03:44,010 --> 00:03:48,959
million dollars now it will not be a

00:03:46,620 --> 00:03:51,420
surprised a lot of people that the data

00:03:48,959 --> 00:03:54,360
might be skewed in the favor of approval

00:03:51,420 --> 00:03:56,430
for males than females because not that

00:03:54,360 --> 00:03:58,799
many females were applying at that point

00:03:56,430 --> 00:04:00,390
in time for mortgages that were over 1

00:03:58,799 --> 00:04:02,579
million 1 million dollars that doesn't

00:04:00,390 --> 00:04:05,040
mean to say the bias was intentional in

00:04:02,579 --> 00:04:07,170
any way that just happens to be the case

00:04:05,040 --> 00:04:09,060
that the data I'm collecting is skewed

00:04:07,170 --> 00:04:10,890
in certain way that doesn't mean to say

00:04:09,060 --> 00:04:11,280
it needs to continue that way in the

00:04:10,890 --> 00:04:14,970
future

00:04:11,280 --> 00:04:16,709
so most importantly bias gets in at the

00:04:14,970 --> 00:04:19,680
time the models are built and

00:04:16,709 --> 00:04:22,080
interestingly when the models are really

00:04:19,680 --> 00:04:24,870
built the training data is only a

00:04:22,080 --> 00:04:27,270
representation of reality now we all

00:04:24,870 --> 00:04:27,810
must admit that's not a reality in

00:04:27,270 --> 00:04:30,270
itself

00:04:27,810 --> 00:04:33,180
no representation is a reality in itself

00:04:30,270 --> 00:04:37,080
and what this capability really salsas

00:04:33,180 --> 00:04:38,910
it actually detects bias at runtime when

00:04:37,080 --> 00:04:41,639
these models are actually running it

00:04:38,910 --> 00:04:43,710
detects bias at runtime which is really

00:04:41,639 --> 00:04:45,750
when the transactions are taking place

00:04:43,710 --> 00:04:48,210
it just doesn't detect bias at runtime

00:04:45,750 --> 00:04:50,160
it also gives you guidance how to

00:04:48,210 --> 00:04:52,350
actually mitigate that bias as well

00:04:50,160 --> 00:04:54,150
while the transactions are taking place

00:04:52,350 --> 00:04:54,919
and the feedback is being collected as

00:04:54,150 --> 00:04:57,720
well

00:04:54,919 --> 00:05:00,630
the second tenant of this capability is

00:04:57,720 --> 00:05:04,530
really about explained ability now as we

00:05:00,630 --> 00:05:08,130
all know the more critical decisions AI

00:05:04,530 --> 00:05:10,620
takes more important it is for AI to

00:05:08,130 --> 00:05:13,169
explain those decisions as well again

00:05:10,620 --> 00:05:17,010
example of claims approval or mortgage

00:05:13,169 --> 00:05:20,250
approval or credit rating as well it is

00:05:17,010 --> 00:05:23,610
many times exactly not just a nice to

00:05:20,250 --> 00:05:26,639
have with with the regulations like Jade

00:05:23,610 --> 00:05:28,979
GT PR it is becoming critical for us to

00:05:26,639 --> 00:05:31,020
have explained ability as part of AI and

00:05:28,979 --> 00:05:32,729
in fact they've been lot of research

00:05:31,020 --> 00:05:34,979
going on in this area and the

00:05:32,729 --> 00:05:38,160
capabilities that we release released

00:05:34,979 --> 00:05:41,130
actually last month allow us to raise

00:05:38,160 --> 00:05:43,680
the level of of technical capability

00:05:41,130 --> 00:05:45,450
delivered to businesses not just to data

00:05:43,680 --> 00:05:47,220
scientist not just to give select me

00:05:45,450 --> 00:05:49,289
it's really the capabilities that are

00:05:47,220 --> 00:05:51,150
released to business people so that

00:05:49,289 --> 00:05:53,580
while the transactions are taking place

00:05:51,150 --> 00:05:56,490
they just can type a transaction number

00:05:53,580 --> 00:05:58,530
and it can tell them why was that loan

00:05:56,490 --> 00:06:00,810
denied for example was it the credit

00:05:58,530 --> 00:06:02,430
rating of that particular person was it

00:06:00,810 --> 00:06:05,639
the address they lived in was their

00:06:02,430 --> 00:06:07,530
income bad or other factors that went

00:06:05,639 --> 00:06:10,770
into it and we'll look through some very

00:06:07,530 --> 00:06:12,510
simple examples as well and the third

00:06:10,770 --> 00:06:14,940
tenant of this capability is really

00:06:12,510 --> 00:06:16,080
about traceability now traceability is

00:06:14,940 --> 00:06:18,990
really all about

00:06:16,080 --> 00:06:22,470
again regulations as well regulations

00:06:18,990 --> 00:06:25,560
like GDP are that as the decisions are

00:06:22,470 --> 00:06:27,840
being done I would like to know what

00:06:25,560 --> 00:06:28,590
data was used actually to make those

00:06:27,840 --> 00:06:31,380
decisions

00:06:28,590 --> 00:06:33,570
what model actually was used to make

00:06:31,380 --> 00:06:35,760
that decision as well how old was the

00:06:33,570 --> 00:06:38,220
model who built the model who touched it

00:06:35,760 --> 00:06:40,590
last all of that lineage of that model

00:06:38,220 --> 00:06:41,669
all the lineage of that decision as the

00:06:40,590 --> 00:06:44,249
decision was being

00:06:41,669 --> 00:06:46,860
needed to be traced back in many

00:06:44,249 --> 00:06:49,110
situations and it allows this capability

00:06:46,860 --> 00:06:51,629
allows us to acne trace those decisions

00:06:49,110 --> 00:06:54,330
in a very simple business centric way

00:06:51,629 --> 00:06:56,430
again most important I think we do this

00:06:54,330 --> 00:06:58,979
at run time we also do it in a very

00:06:56,430 --> 00:07:00,659
simple to use business centric way as

00:06:58,979 --> 00:07:02,930
well so let's look at some of these

00:07:00,659 --> 00:07:05,460
capabilities this is actually the first

00:07:02,930 --> 00:07:07,879
dashboard that you see when you really

00:07:05,460 --> 00:07:11,069
log into that capability there

00:07:07,879 --> 00:07:13,469
the capability gives you the health and

00:07:11,069 --> 00:07:16,050
the performance of the models that are

00:07:13,469 --> 00:07:18,419
being deployed in a very simple easy to

00:07:16,050 --> 00:07:19,889
see way and as you can see eight models

00:07:18,419 --> 00:07:21,900
are deployed in this particular

00:07:19,889 --> 00:07:24,210
situation in your enterprise you know

00:07:21,900 --> 00:07:25,879
there are accuracy alerts for three of

00:07:24,210 --> 00:07:29,129
the models by that I really mean

00:07:25,879 --> 00:07:31,259
businesses can set set thresholds with

00:07:29,129 --> 00:07:33,419
respect to I would like to know is the

00:07:31,259 --> 00:07:36,330
accuracy of the model drops below a

00:07:33,419 --> 00:07:38,789
certain threshold again this accuracy is

00:07:36,330 --> 00:07:40,949
the accuracy at run time which is most

00:07:38,789 --> 00:07:43,740
important as opposed to that can is here

00:07:40,949 --> 00:07:45,419
the model that was built at the time the

00:07:43,740 --> 00:07:47,189
data scientist really built the model

00:07:45,419 --> 00:07:50,669
which is a representation of that

00:07:47,189 --> 00:07:52,439
reality not a reality in itself and and

00:07:50,669 --> 00:07:55,469
interestingly we allow you to actually

00:07:52,439 --> 00:07:58,139
set something called fairness attributes

00:07:55,469 --> 00:08:01,169
for example various attributes can be on

00:07:58,139 --> 00:08:03,719
societal dimensions gender race color

00:08:01,169 --> 00:08:06,300
and so on but they may also be on on

00:08:03,719 --> 00:08:07,919
societal dimensions as well for example

00:08:06,300 --> 00:08:10,050
I would like to actually not be biased

00:08:07,919 --> 00:08:12,300
against certain zip codes as an example

00:08:10,050 --> 00:08:14,279
or could be other notions that the

00:08:12,300 --> 00:08:17,250
businesses might have which may not be

00:08:14,279 --> 00:08:20,460
exactly societal as well so we give you

00:08:17,250 --> 00:08:23,009
actually a simple flag of if we find out

00:08:20,460 --> 00:08:25,649
there is bias creeping into a particular

00:08:23,009 --> 00:08:28,199
model as these decisions are being done

00:08:25,649 --> 00:08:30,569
we actually give raise a red flag as you

00:08:28,199 --> 00:08:32,789
can see on some of the models here let's

00:08:30,569 --> 00:08:35,430
dive into a very simple flag right there

00:08:32,789 --> 00:08:36,930
on claims approval so we are gonna

00:08:35,430 --> 00:08:38,669
double pick on the model for claim

00:08:36,930 --> 00:08:41,370
approval and you're gonna come to this

00:08:38,669 --> 00:08:45,320
screen now that screen actually gives

00:08:41,370 --> 00:08:48,600
you a runtime basis of a notion of bias

00:08:45,320 --> 00:08:51,449
for a particular model for a particular

00:08:48,600 --> 00:08:53,279
attribute that the AI operations person

00:08:51,449 --> 00:08:55,420
will set up for example in this

00:08:53,279 --> 00:08:57,430
particular case I'm looking at the mall

00:08:55,420 --> 00:08:59,730
and three attributes I'm monitoring for

00:08:57,430 --> 00:09:02,680
that model which is on car value

00:08:59,730 --> 00:09:05,290
policyholders age and policy age as well

00:09:02,680 --> 00:09:08,050
and interestingly for that model I'm

00:09:05,290 --> 00:09:10,690
observing a bias creeping in for the

00:09:08,050 --> 00:09:12,910
policy age so I'm discriminating against

00:09:10,690 --> 00:09:15,310
policy holders who have not been my

00:09:12,910 --> 00:09:17,380
customers for very long time so what I

00:09:15,310 --> 00:09:19,990
do is I just double-click on the view

00:09:17,380 --> 00:09:23,079
details right there and you go to this

00:09:19,990 --> 00:09:25,839
screen that actually tells you that you

00:09:23,079 --> 00:09:27,880
know that gives you a a further deep

00:09:25,839 --> 00:09:30,850
dive into that attribute and gives you

00:09:27,880 --> 00:09:33,610
the range of the age of the of the

00:09:30,850 --> 00:09:36,339
policy holders and here I observe that

00:09:33,610 --> 00:09:40,180
I'm actually being biased against the

00:09:36,339 --> 00:09:42,040
age group 18 to 23 and it gives me the

00:09:40,180 --> 00:09:44,079
first question I'll have whenever

00:09:42,040 --> 00:09:46,389
somebody tells me hey your decisions are

00:09:44,079 --> 00:09:48,820
biased my first question will be you

00:09:46,389 --> 00:09:50,860
know can you tell me my exposure what I

00:09:48,820 --> 00:09:53,079
really do at that point is I actually

00:09:50,860 --> 00:09:55,180
click on that that red bar right there

00:09:53,079 --> 00:09:57,459
on the left hand side it actually tells

00:09:55,180 --> 00:10:00,220
me all the transactions that went

00:09:57,459 --> 00:10:03,100
through in that exposed region right

00:10:00,220 --> 00:10:04,209
there which is and there comes a screen

00:10:03,100 --> 00:10:06,370
which actually gives me all the

00:10:04,209 --> 00:10:08,980
transactions I can double click on any

00:10:06,370 --> 00:10:11,050
particular transaction and that takes me

00:10:08,980 --> 00:10:13,300
to this final screen which is really

00:10:11,050 --> 00:10:16,269
about explained ability it can tell me

00:10:13,300 --> 00:10:18,579
why that decision was taken for example

00:10:16,269 --> 00:10:20,680
in this particular case that transaction

00:10:18,579 --> 00:10:24,070
was actually denied with the confidence

00:10:20,680 --> 00:10:26,140
of 90% and the the factors that

00:10:24,070 --> 00:10:28,630
contributed to denial of that particular

00:10:26,140 --> 00:10:31,329
transaction policyholders age which was

00:10:28,630 --> 00:10:34,390
most important to it the brand of the

00:10:31,329 --> 00:10:36,459
car in this insurance claims scenario

00:10:34,390 --> 00:10:39,279
was most important and the factors that

00:10:36,459 --> 00:10:42,040
would have actually led to approval of

00:10:39,279 --> 00:10:44,380
that particular transaction as well went

00:10:42,040 --> 00:10:46,930
into that too so in a very easy to

00:10:44,380 --> 00:10:49,990
understand way it raises the level of

00:10:46,930 --> 00:10:51,970
abstraction of this capability to not

00:10:49,990 --> 00:10:54,490
tear a scientist to really business

00:10:51,970 --> 00:10:56,949
people and this capability is really all

00:10:54,490 --> 00:10:59,050
about making sure businesses can get

00:10:56,949 --> 00:11:01,920
trust and transparency into the AI

00:10:59,050 --> 00:11:04,660
processes that they're deploying I

00:11:01,920 --> 00:11:06,250
appreciate it to come back to to the top

00:11:04,660 --> 00:11:08,079
we are giving at at 11 o clock

00:11:06,250 --> 00:11:09,789
Hilary Koerner and myself are really

00:11:08,079 --> 00:11:12,289
taking through

00:11:09,789 --> 00:11:14,089
you through the the details of the

00:11:12,289 --> 00:11:15,799
process and really giving you a deep

00:11:14,089 --> 00:11:17,720
dive into the demo and these

00:11:15,799 --> 00:11:20,209
capabilities are available in IBM cloud

00:11:17,720 --> 00:11:21,919
for any anyone to try and we are very

00:11:20,209 --> 00:11:24,199
proud of it and this will really raise

00:11:21,919 --> 00:11:26,329
the level of abstraction of the

00:11:24,199 --> 00:11:28,189
capabilities to a point where really

00:11:26,329 --> 00:11:30,589
businesses can go and try it out as

00:11:28,189 --> 00:11:32,749
opposed to AI models being residing in

00:11:30,589 --> 00:11:34,130
the closets of the data scientist thank

00:11:32,749 --> 00:11:39,539
you very much appreciate your time

00:11:34,130 --> 00:11:39,539

YouTube URL: https://www.youtube.com/watch?v=zEIv97GoDtc


