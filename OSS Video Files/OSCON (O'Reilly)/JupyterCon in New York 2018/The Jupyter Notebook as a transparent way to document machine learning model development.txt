Title: The Jupyter Notebook as a transparent way to document machine learning model development
Publication date: 2018-09-21
Playlist: JupyterCon in New York 2018
Description: 
	The Jupyter Notebook as a transparent way to document machine learning model development: A case study from a US defense agency
Catherine Ordun (Booz Allen Hamilton)

Machine learning is new to many US government agencies. They need to transparently document each step of a model, from data preparation to final model prediction. One US defense agency has used the Jupyter Notebook to document its steps and show results in the model building process for a series of recurrent neural network (RNNs) algorithms. The project was so successful that the team has recommended the Jupyter Notebook to be a key component in model documentation for all government scientists.

Catherine Ordun walks you through a notebook built to test the feasibility of developing multivariate time series models to predict cases of pertussis collected weekly over a 10-year time period. These models were built in Keras with a TensorFlow backend and built in Jupyter in order to transparently show the progress of training and testing for a US defense agency technical approach. The notebook chronicles the teamâ€™s data science workflow, from data acquisition and preprocessing to neural network building to evaluation and final model selection.

The project used EpiArchive, publicly available weekly time series data from Los Alamos National Laboratory. The team used the Python requests library to call an API response from the EpiArchive database and convert the disease data for a dozen different infectious diseases into a pandas DataFrame. They also used time series weekly NOAA temperature data and precipitation data as multivariate features and converted and normalized the data. For neural network building, the team built a basic ARIMA time series model to predict weekly pertussis cases achieving a mean absolute error of 6.633, in order to establish a baseline. They then built initial LSTM and GRU models, visualizing the training and validation loss in matplotlib and using the Keras callback function to visualize on TensorBoard (outside of the Jupyter Notebook). As the team experimented with adjusting different hyperparameters and layers for the LSTM and GRU (i.e., adding dropout and changing the activation functions, optimizers, and learning rate), they arrived at a set of final models in the notebook. After several more iterations of hyperparameter tuning, they selected a nonstateful LSTM as the final model of one input layer, one layer with 10 units, and two fully connected layers. This model applied a 20% dropout layer, activation was tanh (hyperbolic tangent), and run on 100 epochs with a batch size of 20. The final model achieved a mean absolute error of 0.0896.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,199 --> 00:00:06,090
so hi everyone my name is Catherine and

00:00:03,600 --> 00:00:08,639
Orden I'm a senior data scientist at

00:00:06,090 --> 00:00:10,559
Booz Allen Hamilton for those of you who

00:00:08,639 --> 00:00:13,920
do not know of Booz Allen Hamilton is

00:00:10,559 --> 00:00:15,330
what it is not as a law firm because

00:00:13,920 --> 00:00:17,580
people are often like oh there's like

00:00:15,330 --> 00:00:19,500
must have three partners so it's not a

00:00:17,580 --> 00:00:22,170
law firm we're actually a large

00:00:19,500 --> 00:00:24,720
consulting firm based out in Tyson's

00:00:22,170 --> 00:00:28,650
Corner which is in McLean Virginia it's

00:00:24,720 --> 00:00:31,019
only about 20 minutes from DC we provide

00:00:28,650 --> 00:00:34,019
a lot of consulting services all across

00:00:31,019 --> 00:00:35,639
the world for mainland governments so we

00:00:34,019 --> 00:00:37,769
even have some international presence

00:00:35,639 --> 00:00:40,799
out in Saudi Arabia for example we do

00:00:37,769 --> 00:00:44,309
cybersecurity consulting for the kingdom

00:00:40,799 --> 00:00:46,229
we do a lot probably 97 percent of our

00:00:44,309 --> 00:00:50,459
work in the federal government for the

00:00:46,229 --> 00:00:52,319
for the country and the types of work

00:00:50,459 --> 00:00:53,850
that I personally lead as both the

00:00:52,319 --> 00:00:56,010
senior data scientist as well as a

00:00:53,850 --> 00:00:57,839
senior manager within Booz Allen are

00:00:56,010 --> 00:00:59,999
developing machine learning prototypes

00:00:57,839 --> 00:01:01,739
for the defense sector and also the

00:00:59,999 --> 00:01:04,949
health sector so that gives me a really

00:01:01,739 --> 00:01:07,109
great opportunity to both code a great

00:01:04,949 --> 00:01:09,930
deal which is a great passion of mine

00:01:07,109 --> 00:01:12,450
and then also to work with a lot of very

00:01:09,930 --> 00:01:13,920
smart people who are coming out of

00:01:12,450 --> 00:01:16,259
undergraduate and graduate programs

00:01:13,920 --> 00:01:19,409
hailing from multiple backgrounds a

00:01:16,259 --> 00:01:20,729
little bit about me I actually have a

00:01:19,409 --> 00:01:25,399
background in public health and biology

00:01:20,729 --> 00:01:27,689
and I started at the CDC as an injury

00:01:25,399 --> 00:01:31,770
epidemiologist many many many moons ago

00:01:27,689 --> 00:01:34,560
and from there I really wanted to work

00:01:31,770 --> 00:01:37,020
in public sector that was my natural

00:01:34,560 --> 00:01:39,240
desire so my entire life I've been

00:01:37,020 --> 00:01:41,369
working for the government so after CDC

00:01:39,240 --> 00:01:43,200
I worked in some bio defense projects

00:01:41,369 --> 00:01:44,670
over at DARPA after dark I worked in the

00:01:43,200 --> 00:01:46,380
intelligence community and then

00:01:44,670 --> 00:01:48,420
naturally I started working at Booz

00:01:46,380 --> 00:01:50,999
Allen so I've been on the firm for about

00:01:48,420 --> 00:01:53,520
seven years and what I'm going to talk

00:01:50,999 --> 00:01:55,350
about today is using Jupiter notebooks

00:01:53,520 --> 00:01:57,600
as a tool for being more transparent

00:01:55,350 --> 00:01:59,639
about how we build machine learning

00:01:57,600 --> 00:02:01,170
models for the government and I'm going

00:01:59,639 --> 00:02:03,630
to walk you through a case study that

00:02:01,170 --> 00:02:05,999
deals with disease modeling for a u.s.

00:02:03,630 --> 00:02:08,310
defense health agency now in the

00:02:05,999 --> 00:02:10,920
abstract for this session is probably

00:02:08,310 --> 00:02:11,770
very technical as I want to let you know

00:02:10,920 --> 00:02:13,240
that since this

00:02:11,770 --> 00:02:15,160
is the business summit you may not

00:02:13,240 --> 00:02:18,160
realize everything in concourse a is a

00:02:15,160 --> 00:02:20,470
business summit that my goal is to not

00:02:18,160 --> 00:02:22,030
necessarily show you how to build a

00:02:20,470 --> 00:02:24,220
recurrent neural network for disease

00:02:22,030 --> 00:02:26,920
modeling but I want to show you the so

00:02:24,220 --> 00:02:29,410
what the reasons for why showing this

00:02:26,920 --> 00:02:32,070
code in a notebook is important and

00:02:29,410 --> 00:02:34,420
valuable in terms of being transparent

00:02:32,070 --> 00:02:36,460
the talk is going to be in two different

00:02:34,420 --> 00:02:38,230
parts so the first part we're going to

00:02:36,460 --> 00:02:39,400
go through a presentation I think that's

00:02:38,230 --> 00:02:41,800
going to appeal to the business

00:02:39,400 --> 00:02:44,080
leadership in the room again emphasizing

00:02:41,800 --> 00:02:45,820
the story of transparency and so what

00:02:44,080 --> 00:02:47,560
and then the other half I'm going to

00:02:45,820 --> 00:02:49,660
walk you through a notebook it's going

00:02:47,560 --> 00:02:51,310
to go through one particular example and

00:02:49,660 --> 00:02:54,010
I'm going to show you what I have

00:02:51,310 --> 00:02:56,620
embedded as transparency value-adds

00:02:54,010 --> 00:02:58,510
that's my consulting speak meaning it's

00:02:56,620 --> 00:03:00,760
the so what who cares about why this

00:02:58,510 --> 00:03:01,800
code is even helpful at all let's go

00:03:00,760 --> 00:03:06,340
ahead and begin

00:03:01,800 --> 00:03:08,380
there's my handy clicker all right so in

00:03:06,340 --> 00:03:10,150
terms of the US government the

00:03:08,380 --> 00:03:12,150
Department of Defense really leads the

00:03:10,150 --> 00:03:14,590
way when it comes to machine learning

00:03:12,150 --> 00:03:17,110
lately they've done a lot of work called

00:03:14,590 --> 00:03:18,610
algorithmic warfare project maven that

00:03:17,110 --> 00:03:21,340
deals a lot with computer vision on

00:03:18,610 --> 00:03:22,900
images and full motion video but we'll

00:03:21,340 --> 00:03:25,480
see just through some of these articles

00:03:22,900 --> 00:03:28,480
that really ever since beginning of the

00:03:25,480 --> 00:03:30,430
2000s advanced analytics using machine

00:03:28,480 --> 00:03:33,160
learning statistical models and machine

00:03:30,430 --> 00:03:35,920
learning have really coalesced at the

00:03:33,160 --> 00:03:39,130
DoD NASA as well as the intelligence

00:03:35,920 --> 00:03:40,780
community now although the DoD really

00:03:39,130 --> 00:03:43,510
leads the way when it comes to

00:03:40,780 --> 00:03:45,790
innovation with machine learning not

00:03:43,510 --> 00:03:49,120
every single government agency is on

00:03:45,790 --> 00:03:51,630
board so there are even offices within

00:03:49,120 --> 00:03:54,250
the DoD we're doing data science is new

00:03:51,630 --> 00:03:57,070
doing machine learning is also very

00:03:54,250 --> 00:03:58,630
brand new so the organization as a whole

00:03:57,070 --> 00:04:01,060
is really starting to dip their toe in

00:03:58,630 --> 00:04:03,880
the water and anything that we can do to

00:04:01,060 --> 00:04:06,190
help them better understand both from an

00:04:03,880 --> 00:04:08,320
area of transparency as well as client

00:04:06,190 --> 00:04:10,690
education is incredibly helpful

00:04:08,320 --> 00:04:13,180
now other parts of the government aren't

00:04:10,690 --> 00:04:16,750
really sold on machine learning and AI

00:04:13,180 --> 00:04:19,030
this particular article cites a survey

00:04:16,750 --> 00:04:21,010
of a hundred different c-level

00:04:19,030 --> 00:04:23,600
executives ninety within the government

00:04:21,010 --> 00:04:25,970
and really only a quarter of them think

00:04:23,600 --> 00:04:28,730
machine learning and AI is important to

00:04:25,970 --> 00:04:31,550
their agency's mission I think 25% is

00:04:28,730 --> 00:04:33,140
actually pretty good and so you know why

00:04:31,550 --> 00:04:35,720
is this happening well there are

00:04:33,140 --> 00:04:37,370
multiple factors related to the

00:04:35,720 --> 00:04:39,380
government writ large about why these

00:04:37,370 --> 00:04:42,410
leaders are not adapting machine

00:04:39,380 --> 00:04:43,820
learning at a rapid pace undoubtedly I

00:04:42,410 --> 00:04:45,830
would say that one of them is that

00:04:43,820 --> 00:04:47,870
machine learning is hard machine

00:04:45,830 --> 00:04:50,150
learning suffers from a paradox I'd like

00:04:47,870 --> 00:04:52,760
to say where our previous speaker had

00:04:50,150 --> 00:04:54,650
noted it's very easy to run machine

00:04:52,760 --> 00:04:56,600
learning code you get three lines of

00:04:54,650 --> 00:04:59,810
code you're doing machine learning it's

00:04:56,600 --> 00:05:02,210
another kind of beast all together to be

00:04:59,810 --> 00:05:05,330
able to explain why you chose that model

00:05:02,210 --> 00:05:07,160
how the algorithm algorithm works how

00:05:05,330 --> 00:05:08,990
you can interpret the model and then do

00:05:07,160 --> 00:05:13,130
it again a hundred different times and

00:05:08,990 --> 00:05:14,870
so the whole idea of being able to be a

00:05:13,130 --> 00:05:16,250
little bit more transparent we build

00:05:14,870 --> 00:05:19,610
these models for the government is

00:05:16,250 --> 00:05:22,040
absolutely paramount these really speak

00:05:19,610 --> 00:05:25,030
to several questions I myself have had

00:05:22,040 --> 00:05:27,800
to answer in my 15 years in government

00:05:25,030 --> 00:05:31,540
from the Treasury to the intelligence

00:05:27,800 --> 00:05:34,430
community to the FDA the VA the army

00:05:31,540 --> 00:05:36,620
multiple government leaders scientists

00:05:34,430 --> 00:05:38,570
have asked me these questions and a lot

00:05:36,620 --> 00:05:39,890
of it comes from probably things that

00:05:38,570 --> 00:05:42,380
you might be experiencing in your

00:05:39,890 --> 00:05:44,930
industry which is there is a big talent

00:05:42,380 --> 00:05:46,940
gap we've got a lot of very very smart

00:05:44,930 --> 00:05:49,190
people who are graduating right now and

00:05:46,940 --> 00:05:50,870
I really believe then the next decade

00:05:49,190 --> 00:05:54,320
will kind of be able to bridge this gap

00:05:50,870 --> 00:05:57,500
but as we can all see in government and

00:05:54,320 --> 00:05:59,630
industry is much more attractive salary

00:05:57,500 --> 00:06:01,340
wise to go to industry than it is to

00:05:59,630 --> 00:06:03,320
government so we don't really have the

00:06:01,340 --> 00:06:05,180
ability to marry up this talent bridge

00:06:03,320 --> 00:06:07,190
that's one of my questions basically

00:06:05,180 --> 00:06:10,040
points to what are we going to do when

00:06:07,190 --> 00:06:12,530
all the consultants leave this points to

00:06:10,040 --> 00:06:14,300
a much larger theme that's been

00:06:12,530 --> 00:06:16,150
permeating within the machine learning

00:06:14,300 --> 00:06:19,550
world right now which is all about

00:06:16,150 --> 00:06:21,590
replicability and transparency this is a

00:06:19,550 --> 00:06:24,500
Twitter thread from about a week ago

00:06:21,590 --> 00:06:26,450
with some luminaries and AI and they are

00:06:24,500 --> 00:06:29,420
lamenting about how being able to

00:06:26,450 --> 00:06:31,760
duplicate and reproduce academic

00:06:29,420 --> 00:06:33,530
research is hard so they look for the

00:06:31,760 --> 00:06:35,150
code and it's just hard to replicate

00:06:33,530 --> 00:06:36,770
these methods especially when it comes

00:06:35,150 --> 00:06:40,220
to something as calm

00:06:36,770 --> 00:06:42,289
as deep learning but our thesis is that

00:06:40,220 --> 00:06:45,020
while it's also important and covered in

00:06:42,289 --> 00:06:47,509
academic research is just as important

00:06:45,020 --> 00:06:50,919
to a government particularly when that

00:06:47,509 --> 00:06:54,020
organization is just getting started

00:06:50,919 --> 00:06:56,780
so the value proposition for using a

00:06:54,020 --> 00:06:58,789
jupiter notebook is very very high when

00:06:56,780 --> 00:07:01,819
it comes to transparently documenting

00:06:58,789 --> 00:07:04,009
how we build these models now before I

00:07:01,819 --> 00:07:05,120
ever knew what a jupiter notebook was I

00:07:04,009 --> 00:07:08,030
think when it was called ipython

00:07:05,120 --> 00:07:10,340
notebook about two years ago I was doing

00:07:08,030 --> 00:07:12,919
the uncool thing and I was coding

00:07:10,340 --> 00:07:15,139
everything in my IDE of choice which is

00:07:12,919 --> 00:07:18,139
spider which is not as cool as PyCharm

00:07:15,139 --> 00:07:20,000
and I was just writing functions and

00:07:18,139 --> 00:07:22,190
writing a maned up high and running it

00:07:20,000 --> 00:07:24,020
and I would explain to my fellow data

00:07:22,190 --> 00:07:26,720
scientists hey this little bit is how I

00:07:24,020 --> 00:07:29,150
built the model eyes would glaze over so

00:07:26,720 --> 00:07:31,909
it's hard to explain how your code works

00:07:29,150 --> 00:07:34,430
to your fellow data scientist how are

00:07:31,909 --> 00:07:36,740
you possibly going to explain it to a

00:07:34,430 --> 00:07:38,300
government project manager or to a

00:07:36,740 --> 00:07:41,419
scientist who wants to be able to run

00:07:38,300 --> 00:07:43,699
your code so the very base minimal specs

00:07:41,419 --> 00:07:46,340
just the better readability of your code

00:07:43,699 --> 00:07:49,130
and a Jupiter notebook makes machine

00:07:46,340 --> 00:07:50,710
learning very helpful not only that but

00:07:49,130 --> 00:07:54,020
there are many opportunities for

00:07:50,710 --> 00:07:55,550
explanation in a jupiter notebook what

00:07:54,020 --> 00:07:57,289
i'm going to show you and my notebook is

00:07:55,550 --> 00:08:00,529
it comes down to using a lot of pictures

00:07:57,289 --> 00:08:02,960
and diagrams so putting out diagrams for

00:08:00,529 --> 00:08:05,000
how you are shaping your data a diagram

00:08:02,960 --> 00:08:07,370
for your models architecture obviously

00:08:05,000 --> 00:08:10,279
being able to visualize some of these

00:08:07,370 --> 00:08:12,110
methods like your loss plots as well as

00:08:10,279 --> 00:08:14,360
having little brackets where you can

00:08:12,110 --> 00:08:17,509
talk about the research your references

00:08:14,360 --> 00:08:20,240
etc so the basis of being able to read

00:08:17,509 --> 00:08:22,190
your code and to explain it and hand it

00:08:20,240 --> 00:08:24,590
over to someone and walk them through as

00:08:22,190 --> 00:08:26,719
a fundamental value proposition of the

00:08:24,590 --> 00:08:29,930
Jupiter notebook so we're going to go

00:08:26,719 --> 00:08:31,610
ahead and dive into our use case for so

00:08:29,930 --> 00:08:34,039
for the prototype that we built for this

00:08:31,610 --> 00:08:36,770
defense health agency they wanted to

00:08:34,039 --> 00:08:39,229
better forecast future cases of

00:08:36,770 --> 00:08:41,599
pertussis which is whooping cough and

00:08:39,229 --> 00:08:43,810
we've been working on not whooping cough

00:08:41,599 --> 00:08:47,690
problem but the overall problem since

00:08:43,810 --> 00:08:48,769
December now what we wanted to do was

00:08:47,690 --> 00:08:50,809
investigate a pretty

00:08:48,769 --> 00:08:52,819
Keillor type of machine learning model

00:08:50,809 --> 00:08:55,670
or what you might popularly hear is a

00:08:52,819 --> 00:08:59,239
neural network called a recurrent neural

00:08:55,670 --> 00:09:01,189
network or an R and now our nuns are

00:08:59,239 --> 00:09:03,559
very good at being able to pick up

00:09:01,189 --> 00:09:06,139
patterns of historic sequences of

00:09:03,559 --> 00:09:08,720
chronological data and be able to

00:09:06,139 --> 00:09:11,089
predict the next sequence in the future

00:09:08,720 --> 00:09:12,439
of that chronological data they

00:09:11,089 --> 00:09:14,569
naturally lend themselves well to

00:09:12,439 --> 00:09:16,459
problems like natural language

00:09:14,569 --> 00:09:18,799
processing we're looking at what is the

00:09:16,459 --> 00:09:20,929
next word in the sentence because all

00:09:18,799 --> 00:09:23,600
the other words before it have context

00:09:20,929 --> 00:09:26,119
and meaning also for this problem very

00:09:23,600 --> 00:09:28,970
good fit for potentially investigating

00:09:26,119 --> 00:09:30,499
excuse for timeseriesforecasting because

00:09:28,970 --> 00:09:32,600
all the patterns and time have a

00:09:30,499 --> 00:09:35,629
historic pattern we want to use it for

00:09:32,600 --> 00:09:37,639
forecasting in the future now recurrent

00:09:35,629 --> 00:09:39,709
neural networks have a specific type of

00:09:37,639 --> 00:09:43,790
model that we're very interested in

00:09:39,709 --> 00:09:47,600
using called an LS TM or a long term

00:09:43,790 --> 00:09:50,809
memory unit RNN you have to learn a lot

00:09:47,600 --> 00:09:52,670
of acronyms in this space LS teams are

00:09:50,809 --> 00:09:54,889
not new they're you know not something

00:09:52,670 --> 00:09:57,170
that was just invented a day ago they

00:09:54,889 --> 00:09:59,889
were developed and 90s from hawk writer

00:09:57,170 --> 00:10:03,319
a lot of these methods are based on

00:09:59,889 --> 00:10:06,649
sound statistical methods using a lot of

00:10:03,319 --> 00:10:08,689
calculus but because we have high GPU

00:10:06,649 --> 00:10:11,089
compute today we've got a lot of data

00:10:08,689 --> 00:10:14,089
there's a lot of research and makes it a

00:10:11,089 --> 00:10:16,730
fruitful time to do deep learning now

00:10:14,089 --> 00:10:19,610
the plot on the left is by an author and

00:10:16,730 --> 00:10:22,519
group called way at L and what they did

00:10:19,610 --> 00:10:25,850
is they predicted stock market prices on

00:10:22,519 --> 00:10:29,420
multiple stock indices using multiple

00:10:25,850 --> 00:10:32,350
types of LS teams so doing a univariate

00:10:29,420 --> 00:10:35,689
forecast for only predicting stock price

00:10:32,350 --> 00:10:38,649
we wanted to know do you think that we

00:10:35,689 --> 00:10:41,230
could take an LS TM and apply it for

00:10:38,649 --> 00:10:43,699
multivariate time series forecasting

00:10:41,230 --> 00:10:46,160
meaning that in the public health sphere

00:10:43,699 --> 00:10:48,199
there are many many environmental

00:10:46,160 --> 00:10:51,069
factors that influence the outcome of

00:10:48,199 --> 00:10:54,589
disease that could be climate

00:10:51,069 --> 00:10:57,319
environmental demographics other disease

00:10:54,589 --> 00:10:59,209
factors and being able to do time series

00:10:57,319 --> 00:10:59,810
forecasting in and of itself is

00:10:59,209 --> 00:11:02,149
incredible

00:10:59,810 --> 00:11:03,949
challenging and hard and I'll say that

00:11:02,149 --> 00:11:06,079
we have not solved this challenge it's

00:11:03,949 --> 00:11:07,490
very hard if we could all solve time

00:11:06,079 --> 00:11:09,410
series I think we'd all be millionaires

00:11:07,490 --> 00:11:12,199
because we could predict the stocks per

00:11:09,410 --> 00:11:14,959
you know tomorrow the next week so our

00:11:12,199 --> 00:11:19,149
goal was to build a multivariate time

00:11:14,959 --> 00:11:21,769
series forecasting model using an LS TM

00:11:19,149 --> 00:11:23,959
now in the notebook that I'm going to

00:11:21,769 --> 00:11:25,790
show you I'm going to show you some of

00:11:23,959 --> 00:11:27,709
the code of how we built this mod I'm

00:11:25,790 --> 00:11:29,720
going to show you one example that's not

00:11:27,709 --> 00:11:31,879
anything to write home about that's

00:11:29,720 --> 00:11:34,040
pretty ordinary and I think in a lot of

00:11:31,879 --> 00:11:36,439
the excellent tutorials this week you've

00:11:34,040 --> 00:11:38,600
seen how people build models however

00:11:36,439 --> 00:11:40,819
when you pull them all together and we

00:11:38,600 --> 00:11:43,879
bridge together the functionality of how

00:11:40,819 --> 00:11:46,189
do we process and transform the data how

00:11:43,879 --> 00:11:47,899
did we evaluate the model how can we

00:11:46,189 --> 00:11:50,689
plot the predictions how can we

00:11:47,899 --> 00:11:52,249
visualize the training loss how can we

00:11:50,689 --> 00:11:54,499
look at the weights or compute the

00:11:52,249 --> 00:11:56,660
gradients together all of these

00:11:54,499 --> 00:11:59,029
different components make it a lot more

00:11:56,660 --> 00:12:02,930
transparent about how we are building

00:11:59,029 --> 00:12:10,009
these models for the government so let

00:12:02,930 --> 00:12:12,050
me go ahead and switch over here and I'm

00:12:10,009 --> 00:12:15,910
hoping that we'll have some time for

00:12:12,050 --> 00:12:15,910
questions here as well at the end

00:12:24,010 --> 00:12:30,100
all right now the first thing that I

00:12:27,040 --> 00:12:33,310
want to orient you to is this I really

00:12:30,100 --> 00:12:35,740
like NB extensions which is a Jupiter

00:12:33,310 --> 00:12:37,900
package or I don't this a package but

00:12:35,740 --> 00:12:39,940
it's a plugin and that's why I've got a

00:12:37,900 --> 00:12:42,790
table of contents when you're a building

00:12:39,940 --> 00:12:44,170
a lot of models it's very hard to keep

00:12:42,790 --> 00:12:45,940
track of what you're doing if you don't

00:12:44,170 --> 00:12:48,640
have a table of contents so here's your

00:12:45,940 --> 00:12:50,260
first step towards readability what I'm

00:12:48,640 --> 00:12:53,500
going to do because some of this code is

00:12:50,260 --> 00:12:55,870
technical I created a very very simple

00:12:53,500 --> 00:12:57,640
example at the end of this notebook I

00:12:55,870 --> 00:13:00,280
will show you a final notebook with

00:12:57,640 --> 00:13:01,900
seven similar examples but because it

00:13:00,280 --> 00:13:03,790
makes no sense to go through seven

00:13:01,900 --> 00:13:06,160
different examples this one is very

00:13:03,790 --> 00:13:09,370
representative of what we've done what I

00:13:06,160 --> 00:13:11,800
want you to see in this notebook is get

00:13:09,370 --> 00:13:14,230
a sense of why this code that I'm

00:13:11,800 --> 00:13:17,470
showing you is helpful when being

00:13:14,230 --> 00:13:20,620
transparent about building a model now

00:13:17,470 --> 00:13:23,290
another part of this is that this is not

00:13:20,620 --> 00:13:25,540
just a trend this is not something I

00:13:23,290 --> 00:13:27,940
just think is cool and I just want for

00:13:25,540 --> 00:13:29,920
everyone to Booz Allen to use as a

00:13:27,940 --> 00:13:32,830
senior data scientist also a senior

00:13:29,920 --> 00:13:35,290
associate I write and respond to a lot

00:13:32,830 --> 00:13:37,390
of government proposals meaning that I

00:13:35,290 --> 00:13:39,160
am writing a technical approach that

00:13:37,390 --> 00:13:41,230
tells the government here's how we would

00:13:39,160 --> 00:13:42,970
execute this work in machine learning

00:13:41,230 --> 00:13:45,460
and deep learning if you gave us that

00:13:42,970 --> 00:13:47,410
opportunity and as a part of writing

00:13:45,460 --> 00:13:49,540
into that time table and schedule of

00:13:47,410 --> 00:13:51,190
deliverables I write in to have a

00:13:49,540 --> 00:13:52,690
Jupiter notebook as a part of the

00:13:51,190 --> 00:13:54,610
deliverable at every single sprint

00:13:52,690 --> 00:13:56,500
review so this is something that I'm

00:13:54,610 --> 00:13:58,780
very committed to that I really think is

00:13:56,500 --> 00:14:00,460
gaining great great adoption across Booz

00:13:58,780 --> 00:14:02,710
Allen and especially for our clients

00:14:00,460 --> 00:14:04,480
that are doing a lot of this work all

00:14:02,710 --> 00:14:05,980
right let me make sure that we can see

00:14:04,480 --> 00:14:10,120
this let me just blow this up a little

00:14:05,980 --> 00:14:12,280
bit all right

00:14:10,120 --> 00:14:14,740
so we're going to talk about two ways of

00:14:12,280 --> 00:14:16,450
doing time series modeling now there are

00:14:14,740 --> 00:14:18,880
a lot of great references out there for

00:14:16,450 --> 00:14:20,890
time series so while this presentation

00:14:18,880 --> 00:14:23,080
is not about time series I've embedded a

00:14:20,890 --> 00:14:24,760
couple of references at the end of this

00:14:23,080 --> 00:14:26,860
session I have this on my github account

00:14:24,760 --> 00:14:28,450
so you can have this notebook and I'll

00:14:26,860 --> 00:14:30,040
also show you how to have it on Google

00:14:28,450 --> 00:14:31,960
collaboratory which I've put up as well

00:14:30,040 --> 00:14:33,340
so you'll keep get to keep all of this

00:14:31,960 --> 00:14:35,370
don't feel like you have to scribble

00:14:33,340 --> 00:14:37,110
down notes furiously

00:14:35,370 --> 00:14:39,990
the first way to do time series we can

00:14:37,110 --> 00:14:42,390
model the so cast ik process that means

00:14:39,990 --> 00:14:45,480
decomposing the seasonality the noise

00:14:42,390 --> 00:14:48,510
the trend and implementing a model like

00:14:45,480 --> 00:14:50,160
ARIMA we're gonna do that another way is

00:14:48,510 --> 00:14:52,620
to use a supervised machine learning

00:14:50,160 --> 00:14:55,050
approach which means we've got all this

00:14:52,620 --> 00:14:57,480
historic data we've got a target what's

00:14:55,050 --> 00:14:59,610
our target pertussis cases that's the

00:14:57,480 --> 00:15:01,560
thing that we want to predict so let's

00:14:59,610 --> 00:15:03,480
use this example to explore both of

00:15:01,560 --> 00:15:06,150
these different methods we're going to

00:15:03,480 --> 00:15:08,810
use data that is from the National

00:15:06,150 --> 00:15:12,780
Oceanic administer the spherical

00:15:08,810 --> 00:15:14,370
acronyms or NOAA for a climate data and

00:15:12,780 --> 00:15:16,260
we're also going to use data from our

00:15:14,370 --> 00:15:19,020
partner at Booz Allen both Alamos

00:15:16,260 --> 00:15:22,860
National Labs called epi Archive you can

00:15:19,020 --> 00:15:25,800
go online to epi Archive dot nut I think

00:15:22,860 --> 00:15:28,410
and we access the API that they gave us

00:15:25,800 --> 00:15:31,140
but they have time series disease case

00:15:28,410 --> 00:15:34,530
counts from multiple DS diseases all

00:15:31,140 --> 00:15:37,640
around the world 544 time steps every

00:15:34,530 --> 00:15:41,970
single time step is one week around June

00:15:37,640 --> 00:15:42,630
2007 to September 2017 roughly a 10-year

00:15:41,970 --> 00:15:46,190
period

00:15:42,630 --> 00:15:49,500
our goal forecast weekly pertussis cases

00:15:46,190 --> 00:15:51,030
all right so here we go to one I'd like

00:15:49,500 --> 00:15:53,880
to tee everything up for this is a

00:15:51,030 --> 00:15:56,040
diagram that I use with my teams to

00:15:53,880 --> 00:15:57,720
explain how we build some of these

00:15:56,040 --> 00:15:59,130
machine learning models especially

00:15:57,720 --> 00:16:01,710
because I'm in the business of building

00:15:59,130 --> 00:16:04,080
prototypes and what this is telling me

00:16:01,710 --> 00:16:05,850
is that we have a problem definition

00:16:04,080 --> 00:16:09,750
which is the first most important thing

00:16:05,850 --> 00:16:11,760
what is foolish to do is from a model

00:16:09,750 --> 00:16:13,710
building transparency perspective is

00:16:11,760 --> 00:16:16,230
just hey let's just build an LS TM let's

00:16:13,710 --> 00:16:17,730
just do it that's foolish what we really

00:16:16,230 --> 00:16:20,100
need to do is define the problem

00:16:17,730 --> 00:16:22,410
carefully and methodically after that we

00:16:20,100 --> 00:16:25,440
get some data we build some data models

00:16:22,410 --> 00:16:28,200
now now we're ready to do cool stuff we

00:16:25,440 --> 00:16:31,230
build the initial models evaluate them

00:16:28,200 --> 00:16:33,120
we interpret them we inspect them the

00:16:31,230 --> 00:16:35,610
whole process by the way as some of our

00:16:33,120 --> 00:16:37,200
speakers made a point in our keynote we

00:16:35,610 --> 00:16:39,630
are not data scientists we don't just do

00:16:37,200 --> 00:16:42,510
this by ourselves we are not unicorns we

00:16:39,630 --> 00:16:44,640
work with data engineers with smees with

00:16:42,510 --> 00:16:48,060
scientists and with managers the entire

00:16:44,640 --> 00:16:49,089
process again another reason why Jupiter

00:16:48,060 --> 00:16:51,789
notebook makes that

00:16:49,089 --> 00:16:53,949
parent finally ready for beta deployment

00:16:51,789 --> 00:16:55,569
now with these feedback loops and tail

00:16:53,949 --> 00:16:57,999
I'll tell you why this is even important

00:16:55,569 --> 00:16:59,799
to this notebook is that sometimes

00:16:57,999 --> 00:17:01,899
things can go real haywire and they can

00:16:59,799 --> 00:17:04,029
go wrong the first feedback loop that

00:17:01,899 --> 00:17:05,769
I've experienced is I've interpreted the

00:17:04,029 --> 00:17:08,829
model incorrectly or I just haven't

00:17:05,769 --> 00:17:10,120
interpreted it correctly at all another

00:17:08,829 --> 00:17:12,490
problem for mistakes

00:17:10,120 --> 00:17:14,319
may be the data models were incorrect we

00:17:12,490 --> 00:17:16,539
don't have the right data the data is

00:17:14,319 --> 00:17:18,459
biased we don't have enough data we

00:17:16,539 --> 00:17:21,879
really mucked up how we transformed it

00:17:18,459 --> 00:17:24,579
go back to data models many cases

00:17:21,879 --> 00:17:27,249
sometimes the problem defined was not

00:17:24,579 --> 00:17:29,409
careful it's the wrong use case we

00:17:27,249 --> 00:17:30,639
shouldn't be used machine learning maybe

00:17:29,409 --> 00:17:32,799
there's something else that's more

00:17:30,639 --> 00:17:35,619
fundamental go all the way to the back

00:17:32,799 --> 00:17:38,289
and do problem definition now when I

00:17:35,619 --> 00:17:40,119
showed you my slide of like my my wonky

00:17:38,289 --> 00:17:41,499
code that I showed you in sublime which

00:17:40,119 --> 00:17:44,169
is not fair

00:17:41,499 --> 00:17:46,720
and how I did everything in spider you

00:17:44,169 --> 00:17:49,899
can't really do this and visualize these

00:17:46,720 --> 00:17:51,399
these different steps very nicely at

00:17:49,899 --> 00:17:53,799
least in a Jupiter notebook this

00:17:51,399 --> 00:17:55,720
provides me a road map a voyage journey

00:17:53,799 --> 00:17:58,090
for how I can chronicle each one of

00:17:55,720 --> 00:18:00,159
these steps alright so we're going to

00:17:58,090 --> 00:18:03,249
load in the data here again we've got 10

00:18:00,159 --> 00:18:04,720
years of weekly data and let's just kind

00:18:03,249 --> 00:18:07,269
of take a look at what this data looks

00:18:04,720 --> 00:18:09,340
like so here's our pertussis data at the

00:18:07,269 --> 00:18:11,590
top we see a little bit of a spike

00:18:09,340 --> 00:18:14,590
around here but it's kind of random

00:18:11,590 --> 00:18:16,480
we've got our influenza data with a lot

00:18:14,590 --> 00:18:19,059
of data points towards the last years

00:18:16,480 --> 00:18:20,740
we've got our precipitation from NOAA

00:18:19,059 --> 00:18:24,159
and then we've got out of sorry

00:18:20,740 --> 00:18:25,539
Salmonella precipitation high and low

00:18:24,159 --> 00:18:28,629
temperature which of course are very

00:18:25,539 --> 00:18:30,519
very seasonal now here's what we first

00:18:28,629 --> 00:18:33,519
need to do here's my here's my

00:18:30,519 --> 00:18:36,309
consulting speak transparency value add

00:18:33,519 --> 00:18:38,740
this is the so what alright so with our

00:18:36,309 --> 00:18:40,450
baseline model what we try to do is

00:18:38,740 --> 00:18:42,879
start with something that we already

00:18:40,450 --> 00:18:45,940
know start small so that we can leapfrog

00:18:42,879 --> 00:18:47,590
into something larger in my personal

00:18:45,940 --> 00:18:49,869
humble opinion I do think it's foolish

00:18:47,590 --> 00:18:52,240
to immediately start on a novel problem

00:18:49,869 --> 00:18:54,279
dealing with neural networks or machine

00:18:52,240 --> 00:18:56,200
learning I think that for a new

00:18:54,279 --> 00:18:57,879
organization such as a government

00:18:56,200 --> 00:18:58,690
organization where they've never done

00:18:57,879 --> 00:19:00,389
machine learning

00:18:58,690 --> 00:19:03,460
it's important to use a tried-and-true

00:19:00,389 --> 00:19:05,979
process or at least a process of the

00:19:03,460 --> 00:19:08,289
organization has been using already way

00:19:05,979 --> 00:19:09,759
before you ever got there and so I call

00:19:08,289 --> 00:19:12,249
this kind of a form of technical

00:19:09,759 --> 00:19:15,039
stakeholder engagement you want to honor

00:19:12,249 --> 00:19:17,440
the existing analysts and scientists and

00:19:15,039 --> 00:19:19,419
database administrators that used to be

00:19:17,440 --> 00:19:20,679
there and use their prevailing method

00:19:19,419 --> 00:19:23,019
just as a check

00:19:20,679 --> 00:19:24,849
maybe it's linear regression maybe it's

00:19:23,019 --> 00:19:27,070
doing counts and frequencies and pivot

00:19:24,849 --> 00:19:29,229
tables an Excel spreadsheet or it might

00:19:27,070 --> 00:19:31,840
be a tried-and-true method that is well

00:19:29,229 --> 00:19:33,549
documented in statistics so for exists

00:19:31,840 --> 00:19:35,440
example we're going to use an ARIMA

00:19:33,549 --> 00:19:37,899
model which is an auto regressive

00:19:35,440 --> 00:19:39,820
integrated moving average for those of

00:19:37,899 --> 00:19:41,889
you who are not familiar with ARIMA

00:19:39,820 --> 00:19:44,440
ARIMA is basically a linear regression

00:19:41,889 --> 00:19:46,809
model that's correlating future values

00:19:44,440 --> 00:19:49,479
with past values dealing with lags and

00:19:46,809 --> 00:19:51,759
moving averages there are some nice

00:19:49,479 --> 00:19:53,379
functionality built this is a I

00:19:51,759 --> 00:19:54,669
shouldn't say this and on Jupiter

00:19:53,379 --> 00:19:57,309
conference but an hour

00:19:54,669 --> 00:19:59,769
god forbid so there are some nice some

00:19:57,309 --> 00:20:02,739
auto rima packages and are and then also

00:19:59,769 --> 00:20:05,049
you can use them in Python now in order

00:20:02,739 --> 00:20:07,479
to build this model we have to define a

00:20:05,049 --> 00:20:10,539
couple of parameters first P for the

00:20:07,479 --> 00:20:12,369
number of our outer regressive factors D

00:20:10,539 --> 00:20:14,769
for whether we want a difference in

00:20:12,369 --> 00:20:16,749
meaning we want to get this time series

00:20:14,769 --> 00:20:19,479
data and remove it of seasonality and

00:20:16,749 --> 00:20:23,019
trend and Q the number of lagged

00:20:19,479 --> 00:20:25,509
forecast errors so as a part of our

00:20:23,019 --> 00:20:27,340
exploratory analysis I'll perform a

00:20:25,509 --> 00:20:30,729
dickey-fuller test and that will tell me

00:20:27,340 --> 00:20:32,830
if forecasting only for pertussis we've

00:20:30,729 --> 00:20:34,539
got a stationary data set it tells me

00:20:32,830 --> 00:20:37,599
it's stationary so I'm not going to log

00:20:34,539 --> 00:20:39,999
transform or difference it we also have

00:20:37,599 --> 00:20:42,190
our plots here for autocorrelation and

00:20:39,999 --> 00:20:44,349
partial autocorrelation and that tells

00:20:42,190 --> 00:20:46,989
me right here that I've got about to

00:20:44,349 --> 00:20:49,509
auto regressive terms maybe all the way

00:20:46,989 --> 00:20:51,460
out to five it's outside of my 95

00:20:49,509 --> 00:20:53,950
percent confidence interval so we'll

00:20:51,460 --> 00:20:56,409
just go ahead and choose five and so now

00:20:53,950 --> 00:20:58,479
we've got our parameters under Reema

00:20:56,409 --> 00:21:01,359
using the stats models package of five

00:20:58,479 --> 00:21:03,279
zero and one so here I have the general

00:21:01,359 --> 00:21:05,619
ARIMA forecasting equation and this

00:21:03,279 --> 00:21:08,739
provides another transparency value add

00:21:05,619 --> 00:21:11,140
why is it important to document formulas

00:21:08,739 --> 00:21:13,090
in a notebook well

00:21:11,140 --> 00:21:15,040
there is always a classical fight that I

00:21:13,090 --> 00:21:17,680
have seen even in Booz Allen between

00:21:15,040 --> 00:21:19,480
mathematicians and data scientists and a

00:21:17,680 --> 00:21:21,460
lot of data and mathematicians think

00:21:19,480 --> 00:21:23,500
that data scientists are the this

00:21:21,460 --> 00:21:25,870
mystical thing that just came about and

00:21:23,500 --> 00:21:28,810
was cool and hot and hip and so it's

00:21:25,870 --> 00:21:30,640
important to be able to talk about the

00:21:28,810 --> 00:21:32,590
statistics and the mathematics for how

00:21:30,640 --> 00:21:34,390
you're building these models why it's

00:21:32,590 --> 00:21:35,860
important to the government is this in

00:21:34,390 --> 00:21:37,630
the government all talking about that

00:21:35,860 --> 00:21:39,580
talent gap there are a lot of

00:21:37,630 --> 00:21:40,660
mathematicians and government have you

00:21:39,580 --> 00:21:42,730
ever been to NASA

00:21:40,660 --> 00:21:45,490
everyone's a mathematician or NSA

00:21:42,730 --> 00:21:47,940
everyone's a mathematician so by being

00:21:45,490 --> 00:21:51,490
able to use something like for example

00:21:47,940 --> 00:21:53,110
latex which is an inherent part of a

00:21:51,490 --> 00:21:55,630
Jupiter notebook you can use mathjax

00:21:53,110 --> 00:21:58,390
which is the the library I guess the

00:21:55,630 --> 00:22:00,580
wrapper you can use latex and you can

00:21:58,390 --> 00:22:02,280
write out all of your equations that

00:22:00,580 --> 00:22:05,440
breaks things down and kind of

00:22:02,280 --> 00:22:06,880
encourages this communication between an

00:22:05,440 --> 00:22:09,510
organization that may have a lot of

00:22:06,880 --> 00:22:11,920
scientists but not a lot of programmers

00:22:09,510 --> 00:22:14,140
so we're going to go ahead and build our

00:22:11,920 --> 00:22:17,380
ARIMA model with that five zero one

00:22:14,140 --> 00:22:20,020
parameters the first 417 time steps

00:22:17,380 --> 00:22:22,000
we're going to train the last 417 we're

00:22:20,020 --> 00:22:26,710
going to test and we get a total mean

00:22:22,000 --> 00:22:29,410
absolute error of 6.6 3 now granted this

00:22:26,710 --> 00:22:32,380
is only univariate it's only for a

00:22:29,410 --> 00:22:36,210
pertussis timeseriesforecasting could we

00:22:32,380 --> 00:22:38,860
explore a way to use an LS TM to build a

00:22:36,210 --> 00:22:41,380
multivariate forecasting and how would

00:22:38,860 --> 00:22:43,000
that differ from this mean absolute

00:22:41,380 --> 00:22:46,060
error so we're going to begin that

00:22:43,000 --> 00:22:48,250
voyage right now but before I finish

00:22:46,060 --> 00:22:51,550
this it's important to also exhaust

00:22:48,250 --> 00:22:53,920
every possibility for your Areva model

00:22:51,550 --> 00:22:56,020
when you're building that baseline model

00:22:53,920 --> 00:22:58,630
don't just ditch it because your first

00:22:56,020 --> 00:23:00,610
model had a low accuracy keep going at

00:22:58,630 --> 00:23:02,050
it try the best that you can as you

00:23:00,610 --> 00:23:04,810
would have the attention on your machine

00:23:02,050 --> 00:23:08,020
learning model to make this non machine

00:23:04,810 --> 00:23:10,420
learning model as good as possible so as

00:23:08,020 --> 00:23:13,720
I was saying about our they've got an R

00:23:10,420 --> 00:23:16,300
Otto ARIMA library and there's a great

00:23:13,720 --> 00:23:19,030
package called pyramid which is the

00:23:16,300 --> 00:23:21,670
essentially our Zotto rima library

00:23:19,030 --> 00:23:22,700
within python and so right here we're

00:23:21,670 --> 00:23:25,549
basically

00:23:22,700 --> 00:23:28,970
to grid search the entire space of these

00:23:25,549 --> 00:23:30,590
PDQ parameters to find the best AIC

00:23:28,970 --> 00:23:32,749
which is essentially a measure of a

00:23:30,590 --> 00:23:35,450
goodness of fit and so what we found

00:23:32,749 --> 00:23:37,820
here is that our a ICS that tells us

00:23:35,450 --> 00:23:41,269
that actually instead of five zero one

00:23:37,820 --> 00:23:43,309
two zero one was the best that we could

00:23:41,269 --> 00:23:46,399
do with our time series of pertussis

00:23:43,309 --> 00:23:48,679
data alright so we've gone ahead we've

00:23:46,399 --> 00:23:49,970
investigated our baseline model and

00:23:48,679 --> 00:23:52,929
we're going to start with our data

00:23:49,970 --> 00:23:56,029
processing here is the next value add

00:23:52,929 --> 00:23:58,730
takeaway this is where you can really

00:23:56,029 --> 00:24:01,190
really mess up our previous speaker

00:23:58,730 --> 00:24:03,080
talks about how 80 to 90 percent of

00:24:01,190 --> 00:24:05,749
building a model is dealing with the

00:24:03,080 --> 00:24:08,600
data I myself have been guilty many

00:24:05,749 --> 00:24:10,820
times doing the wrong imputation taking

00:24:08,600 --> 00:24:12,619
the wrong amount of data in neural

00:24:10,820 --> 00:24:15,080
networks you're constantly dealing with

00:24:12,619 --> 00:24:17,239
numb PI's or you're reshaping things and

00:24:15,080 --> 00:24:20,389
in multiple dimensions you can screw up

00:24:17,239 --> 00:24:21,980
immensely in this step so a part of the

00:24:20,389 --> 00:24:24,230
jupiter notebook value add for the

00:24:21,980 --> 00:24:26,450
government is to start chronicling what

00:24:24,230 --> 00:24:28,609
you're doing to the data i guarantee you

00:24:26,450 --> 00:24:30,499
that if you step into any organization

00:24:28,609 --> 00:24:31,970
that you've not worked with before they

00:24:30,499 --> 00:24:33,980
will know one thing better than you will

00:24:31,970 --> 00:24:35,570
ever know which is the data they will

00:24:33,980 --> 00:24:37,369
know their data better than you will

00:24:35,570 --> 00:24:39,379
know in the next year two years what

00:24:37,369 --> 00:24:41,450
have you so is another part of that

00:24:39,379 --> 00:24:43,789
technical stakeholder engagement honor

00:24:41,450 --> 00:24:46,009
their understanding of the data and be

00:24:43,789 --> 00:24:48,379
transparent and how you treat it all

00:24:46,009 --> 00:24:50,450
right so this metamorphosis and the data

00:24:48,379 --> 00:24:54,409
processing let's first start with how we

00:24:50,450 --> 00:24:56,239
are going to X standard Isis data again

00:24:54,409 --> 00:24:59,029
am using link tuck I'm laying that out

00:24:56,239 --> 00:25:03,289
zero mean and unit variance for all of

00:24:59,029 --> 00:25:05,480
our 444 time steps we want to talk about

00:25:03,289 --> 00:25:07,399
in this particular step if we're

00:25:05,480 --> 00:25:09,559
normalizing it such are we going to

00:25:07,399 --> 00:25:11,840
scale it from zero to one sometimes

00:25:09,559 --> 00:25:15,619
these things do have an impact now I

00:25:11,840 --> 00:25:18,970
have gotten that CSV file of that 544

00:25:15,619 --> 00:25:22,609
time steps for six different features

00:25:18,970 --> 00:25:24,489
pertussis influenza Salmonella which are

00:25:22,609 --> 00:25:26,869
weekly case counts by the way

00:25:24,489 --> 00:25:29,119
precipitation low temperature and high

00:25:26,869 --> 00:25:31,789
temperature and I put them into a two

00:25:29,119 --> 00:25:35,430
dimensional matrix here so our first

00:25:31,789 --> 00:25:36,990
five values have our five independent

00:25:35,430 --> 00:25:39,390
variables that we're going to use as our

00:25:36,990 --> 00:25:41,630
multivariate forecast and then we have

00:25:39,390 --> 00:25:46,430
our target value which is all of our

00:25:41,630 --> 00:25:48,840
normalized pertussis forecast targets

00:25:46,430 --> 00:25:52,050
all right now we're going to transform

00:25:48,840 --> 00:25:55,230
this data and so this model is only good

00:25:52,050 --> 00:25:56,940
for a one-week forward forecast for the

00:25:55,230 --> 00:25:58,710
simplicity of the notebook I thought

00:25:56,940 --> 00:26:00,090
that would be the most helpful here so

00:25:58,710 --> 00:26:03,420
all we're doing is we're shifting our

00:26:00,090 --> 00:26:06,810
pertussis cases for the next week and so

00:26:03,420 --> 00:26:09,720
now we're left with a new matrix of 543

00:26:06,810 --> 00:26:11,610
by 6 all right we're tart we're starting

00:26:09,720 --> 00:26:13,740
to talk about matrices so let's get into

00:26:11,610 --> 00:26:16,350
this reshaping the data the Train test

00:26:13,740 --> 00:26:19,320
split here's our transparency value add

00:26:16,350 --> 00:26:21,410
when you're dealing with deep learning

00:26:19,320 --> 00:26:24,450
you are constantly dealing with

00:26:21,410 --> 00:26:26,040
reshaping data from a business

00:26:24,450 --> 00:26:27,750
perspective especially in an

00:26:26,040 --> 00:26:30,210
organization new to machine learning

00:26:27,750 --> 00:26:32,850
they're probably gonna give you a CSV it

00:26:30,210 --> 00:26:35,130
might be highly dimensional like a

00:26:32,850 --> 00:26:37,410
thousand fields or a thousand different

00:26:35,130 --> 00:26:40,560
columns but they're used to working with

00:26:37,410 --> 00:26:41,790
just a tabular set of data what the

00:26:40,560 --> 00:26:44,520
government organizations are interested

00:26:41,790 --> 00:26:46,200
is they don't want just a result and

00:26:44,520 --> 00:26:47,910
walk away they want to understand again

00:26:46,200 --> 00:26:49,020
what did you do to their data because

00:26:47,910 --> 00:26:51,870
they want to be able to train their

00:26:49,020 --> 00:26:53,850
workforce - this is at least for me the

00:26:51,870 --> 00:26:56,490
part when I began learning about neural

00:26:53,850 --> 00:26:58,290
networks the most mind-boggling I've had

00:26:56,490 --> 00:27:00,060
I have notebooks and notebooks and mole

00:26:58,290 --> 00:27:03,030
skins and mole scans of just drawings

00:27:00,060 --> 00:27:06,000
and whiteboards of how we assemble this

00:27:03,030 --> 00:27:08,970
data this is from an excerpt from

00:27:06,000 --> 00:27:10,440
medium.com from hacker noon and all it's

00:27:08,970 --> 00:27:12,960
telling you are different ways for you

00:27:10,440 --> 00:27:15,120
to think about the shape of data we've

00:27:12,960 --> 00:27:17,280
got a 1d tensor or vector is just a

00:27:15,120 --> 00:27:18,690
whole vector of data that's one you can

00:27:17,280 --> 00:27:21,510
think of it in rows and columns won't

00:27:18,690 --> 00:27:23,790
call them long we have a 2d tensor which

00:27:21,510 --> 00:27:25,410
is tabular data let's think of this in

00:27:23,790 --> 00:27:27,870
terms of rows and columns

00:27:25,410 --> 00:27:30,000
now we're getting that 2d tensor and

00:27:27,870 --> 00:27:32,850
then we are adding additional features

00:27:30,000 --> 00:27:36,570
now I've got a cube cubes can be stacked

00:27:32,850 --> 00:27:38,400
4d 5d so we deal with 4d and 5d we're

00:27:36,570 --> 00:27:40,530
dealing with computer vision models and

00:27:38,400 --> 00:27:43,440
deal with images and full motion video

00:27:40,530 --> 00:27:45,750
for the purposes of our x is forecast

00:27:43,440 --> 00:27:49,950
for an RNN we're just gonna deal with a

00:27:45,750 --> 00:27:53,310
three dimensional space again what I've

00:27:49,950 --> 00:27:55,440
done here which I'm a big fan of doing

00:27:53,310 --> 00:27:58,470
is drawing I draw a lot of pictures I

00:27:55,440 --> 00:28:01,110
find that if I can't draw a diagram and

00:27:58,470 --> 00:28:03,150
tell you how I reach a pata or what the

00:28:01,110 --> 00:28:05,310
model architecture is I actually don't

00:28:03,150 --> 00:28:07,590
know what I'm doing and so this is also

00:28:05,310 --> 00:28:09,660
for the data scientists in the room who

00:28:07,590 --> 00:28:12,090
are working with other data scientists I

00:28:09,660 --> 00:28:14,160
have a recommendation ask your data

00:28:12,090 --> 00:28:16,020
scientist all right you want to build

00:28:14,160 --> 00:28:18,300
this model this convolutional neural

00:28:16,020 --> 00:28:20,130
network can you draw the architecture

00:28:18,300 --> 00:28:22,380
for the convolutional layers the pooling

00:28:20,130 --> 00:28:24,180
features a drop out can you draw that

00:28:22,380 --> 00:28:26,790
all for me because now we're talking the

00:28:24,180 --> 00:28:28,740
same type of understanding so this is

00:28:26,790 --> 00:28:29,940
one first set of drawings and you're

00:28:28,740 --> 00:28:32,550
gonna see all headed drawings in a

00:28:29,940 --> 00:28:36,330
minute what thing here is that I've got

00:28:32,550 --> 00:28:39,780
a training set of data a validation set

00:28:36,330 --> 00:28:41,940
of data and a test set of data my

00:28:39,780 --> 00:28:44,250
training set for the simplicity of this

00:28:41,940 --> 00:28:48,570
model is one by one eighty one by five

00:28:44,250 --> 00:28:51,420
that means one very very long sample of

00:28:48,570 --> 00:28:55,350
a hundred eighty one time steps for

00:28:51,420 --> 00:28:57,480
influenza Salmonella precipitation low

00:28:55,350 --> 00:29:00,330
and high temperature one long long

00:28:57,480 --> 00:29:02,310
sample first three and a half years my

00:29:00,330 --> 00:29:04,560
validation set is the next three and a

00:29:02,310 --> 00:29:08,070
half years and then my test set is a

00:29:04,560 --> 00:29:10,530
next three and a half years and what we

00:29:08,070 --> 00:29:14,730
have here are essentially 181 time steps

00:29:10,530 --> 00:29:16,710
in this vector I've done this for each

00:29:14,730 --> 00:29:18,900
one of the three sets as I've just

00:29:16,710 --> 00:29:21,150
narrated to you here or a training set

00:29:18,900 --> 00:29:22,860
or validation in our tests this is a

00:29:21,150 --> 00:29:26,280
very simple example that we're gonna be

00:29:22,860 --> 00:29:28,290
walking through all right we are finally

00:29:26,280 --> 00:29:30,810
ready to build the model so let's do

00:29:28,290 --> 00:29:33,860
this alright the transparency value add

00:29:30,810 --> 00:29:36,450
neural networks are hard to understand

00:29:33,860 --> 00:29:37,830
I'm sure that there's a lot of people

00:29:36,450 --> 00:29:40,320
here who have done some deep learning

00:29:37,830 --> 00:29:42,000
maybe it's very easy to understand but

00:29:40,320 --> 00:29:43,980
for me it's hard to understand you have

00:29:42,000 --> 00:29:45,720
to make a leap from understanding the

00:29:43,980 --> 00:29:47,550
fundamentals of machine learning and

00:29:45,720 --> 00:29:50,190
then apply it into a different type of

00:29:47,550 --> 00:29:52,410
mindset with neural networks so as I

00:29:50,190 --> 00:29:54,990
mentioned earlier by drawing out the

00:29:52,410 --> 00:29:56,970
architecture of this model and not only

00:29:54,990 --> 00:29:58,680
helps the government understand what

00:29:56,970 --> 00:30:00,220
type of prototype we're trying to build

00:29:58,680 --> 00:30:02,200
but also tests

00:30:00,220 --> 00:30:04,000
your knowledge and understanding as well

00:30:02,200 --> 00:30:07,030
so let's go over this at a very high

00:30:04,000 --> 00:30:09,610
level on the equal sign you'll see that

00:30:07,030 --> 00:30:11,470
there is a diagram to the left of it and

00:30:09,610 --> 00:30:11,980
then you'll see a diagram to the right

00:30:11,470 --> 00:30:14,230
of it

00:30:11,980 --> 00:30:15,909
this is a classic depiction of how one

00:30:14,230 --> 00:30:19,390
would talk about a recurrent neural

00:30:15,909 --> 00:30:21,370
network on the right hand side you've

00:30:19,390 --> 00:30:24,250
got all of your X inputs right that's

00:30:21,370 --> 00:30:27,280
the 181 long time step for our training

00:30:24,250 --> 00:30:30,460
set that goes into one hidden layer we

00:30:27,280 --> 00:30:32,530
have one layer of LST M units you might

00:30:30,460 --> 00:30:34,539
call a unit a neuron some of you might

00:30:32,530 --> 00:30:37,299
have heard that term one hidden layer

00:30:34,539 --> 00:30:40,210
and my model is going to show you 128

00:30:37,299 --> 00:30:42,220
neurons or LST M units and then we're

00:30:40,210 --> 00:30:45,549
outputting our target which is our

00:30:42,220 --> 00:30:47,620
pertussis forecast on the left side of

00:30:45,549 --> 00:30:50,500
our equation is this model what we call

00:30:47,620 --> 00:30:54,130
unrolled and what this is telling you is

00:30:50,500 --> 00:30:56,890
that at each one of the 181 time steps

00:30:54,130 --> 00:30:59,679
we're going to feed it into our layer of

00:30:56,890 --> 00:31:02,169
all the LST M units and we're gonna say

00:30:59,679 --> 00:31:04,480
hey because I built this in a curious PI

00:31:02,169 --> 00:31:06,220
torch is also great framework in our

00:31:04,480 --> 00:31:08,470
Kuras model in say hey Harris

00:31:06,220 --> 00:31:10,960
give me a prediction at every single

00:31:08,470 --> 00:31:13,090
time step that's why there's a wrapper

00:31:10,960 --> 00:31:16,270
that says time distributed that's just

00:31:13,090 --> 00:31:18,309
an artifact of programming these LST M's

00:31:16,270 --> 00:31:20,260
at every single time sequence and Kuras

00:31:18,309 --> 00:31:23,140
this is what some of you may have seen

00:31:20,260 --> 00:31:25,870
as a many-to-many sequence you can also

00:31:23,140 --> 00:31:28,299
do a many-to-many sequence and other use

00:31:25,870 --> 00:31:30,600
cases like machine language translation

00:31:28,299 --> 00:31:33,610
going from English to French

00:31:30,600 --> 00:31:35,799
here's another transparency value-add

00:31:33,610 --> 00:31:38,320
now as you can tell we're ratcheting up

00:31:35,799 --> 00:31:41,559
a number of diagrams and opportunities

00:31:38,320 --> 00:31:43,559
for explanation every single neural

00:31:41,559 --> 00:31:45,640
network has all sorts of complexities

00:31:43,559 --> 00:31:47,500
when you start researching the

00:31:45,640 --> 00:31:50,280
literature you'll find that one

00:31:47,500 --> 00:31:53,289
researcher has made a better way of

00:31:50,280 --> 00:31:55,210
doing a bunch of convolutional layers or

00:31:53,289 --> 00:31:58,120
fully connected layers to a previous

00:31:55,210 --> 00:32:00,070
researchers convolutional network etc

00:31:58,120 --> 00:32:02,500
etc so there's a lot of research but

00:32:00,070 --> 00:32:03,880
different architectures what's important

00:32:02,500 --> 00:32:06,190
and why I'm showing you this is because

00:32:03,880 --> 00:32:08,590
this is where a lot of government

00:32:06,190 --> 00:32:10,500
organizations get kind of stuck they

00:32:08,590 --> 00:32:12,669
understood how you transform their data

00:32:10,500 --> 00:32:13,840
the understood kind of what you're going

00:32:12,669 --> 00:32:17,080
to be doing with

00:32:13,840 --> 00:32:19,330
model what is happening inside the model

00:32:17,080 --> 00:32:21,789
and this is where the whole notion of a

00:32:19,330 --> 00:32:23,380
model being black box comes into play so

00:32:21,789 --> 00:32:25,840
I'm not gonna go over this in great

00:32:23,380 --> 00:32:28,659
depth this is my own picture of my own

00:32:25,840 --> 00:32:31,299
rendering of Chris ollas blog for anyone

00:32:28,659 --> 00:32:34,870
who is interested in learning about rnns

00:32:31,299 --> 00:32:36,909
you have to check out but this is my own

00:32:34,870 --> 00:32:39,880
type of picture and all I'm telling you

00:32:36,909 --> 00:32:41,980
here is that an El STM is a special type

00:32:39,880 --> 00:32:45,010
of recurrent neural network there are

00:32:41,980 --> 00:32:47,470
many regulatory mathematical operations

00:32:45,010 --> 00:32:51,039
that allow information to be inputted

00:32:47,470 --> 00:32:53,289
written to saved and outputted in a

00:32:51,039 --> 00:32:55,419
regulated format using multiple

00:32:53,289 --> 00:32:59,740
different types of essentially linear

00:32:55,419 --> 00:33:01,539
algebra this is what prevents this type

00:32:59,740 --> 00:33:04,000
of network from having a problem called

00:33:01,539 --> 00:33:05,890
vanishing or exploding gradient or

00:33:04,000 --> 00:33:08,140
basically this is a type of model that

00:33:05,890 --> 00:33:11,830
will help it remember past historical

00:33:08,140 --> 00:33:13,809
sequences of data all right we're gonna

00:33:11,830 --> 00:33:16,330
go ahead and define our loss metric here

00:33:13,809 --> 00:33:19,240
this is the mean absolute error and

00:33:16,330 --> 00:33:20,860
again as I was saying laytaka is an

00:33:19,240 --> 00:33:24,159
awesome tool let's go ahead and use

00:33:20,860 --> 00:33:25,990
latex and write out our formula it's

00:33:24,159 --> 00:33:28,029
also important here that if there is a

00:33:25,990 --> 00:33:30,490
statistician or a mathematician on your

00:33:28,029 --> 00:33:32,380
team consult them to not leave them out

00:33:30,490 --> 00:33:33,940
of the fold there are many types of

00:33:32,380 --> 00:33:36,880
metrics that you could use we could have

00:33:33,940 --> 00:33:38,890
used a mean squared error probably not R

00:33:36,880 --> 00:33:41,559
squared but we used a mean absolute here

00:33:38,890 --> 00:33:43,720
look at the other types of research and

00:33:41,559 --> 00:33:45,309
publications and what they're using this

00:33:43,720 --> 00:33:47,289
is very important because this is gonna

00:33:45,309 --> 00:33:49,570
define our loss and how well our model

00:33:47,289 --> 00:33:51,700
performs here we go we're gonna build

00:33:49,570 --> 00:33:53,950
our model and what I showed you in my

00:33:51,700 --> 00:33:56,830
diagram was one hidden layer actually

00:33:53,950 --> 00:34:00,039
two hidden layers so we've got two

00:33:56,830 --> 00:34:02,590
hidden layers 128 neurons and every

00:34:00,039 --> 00:34:04,390
single layer one time distributed a

00:34:02,590 --> 00:34:07,750
dense layer saying give me one

00:34:04,390 --> 00:34:10,540
prediction at every single one of my 181

00:34:07,750 --> 00:34:13,619
time steps we've trained it for 200

00:34:10,540 --> 00:34:16,240
epochs and now we have our loss plot

00:34:13,619 --> 00:34:18,970
okay here's a transparency value-add

00:34:16,240 --> 00:34:20,800
when it comes to a loss plot now as

00:34:18,970 --> 00:34:22,960
you'll see here I've only plotted you

00:34:20,800 --> 00:34:24,639
the loss of the training data that's

00:34:22,960 --> 00:34:26,339
because I only have one sample for the

00:34:24,639 --> 00:34:28,950
brevity of this exercise like

00:34:26,339 --> 00:34:30,329
really split one but anything else to

00:34:28,950 --> 00:34:34,349
give you a split of a training

00:34:30,329 --> 00:34:36,690
validation set however giving you the

00:34:34,349 --> 00:34:38,460
overview of a training loss is not

00:34:36,690 --> 00:34:40,409
helpful we really need to know the

00:34:38,460 --> 00:34:42,629
validation loss because that gives you

00:34:40,409 --> 00:34:45,109
the best estimate of how generalizable

00:34:42,629 --> 00:34:48,089
your models going to be on unseen data

00:34:45,109 --> 00:34:49,979
so in a future model I'm going to show

00:34:48,089 --> 00:34:52,319
you in a couple of minutes the second

00:34:49,979 --> 00:34:56,039
data processing approach we'll be able

00:34:52,319 --> 00:34:58,319
to split 20% 30% our training and

00:34:56,039 --> 00:35:00,569
validation data and what makes it really

00:34:58,319 --> 00:35:03,630
helpful is that Kerris has callback

00:35:00,569 --> 00:35:06,660
functions many libraries do where you

00:35:03,630 --> 00:35:08,519
can be able to output your training and

00:35:06,660 --> 00:35:10,680
your loss curve and tensor board for

00:35:08,519 --> 00:35:12,960
example so here we have an on tensor

00:35:10,680 --> 00:35:15,299
board these are about seven or six

00:35:12,960 --> 00:35:17,969
different models that we ran and now you

00:35:15,299 --> 00:35:20,940
can see that at the top is our training

00:35:17,969 --> 00:35:22,829
loss but the bottom is our validation

00:35:20,940 --> 00:35:24,690
loss and you can see how all these

00:35:22,829 --> 00:35:27,630
different models stack up to each other

00:35:24,690 --> 00:35:29,940
when using the mean absolute error now

00:35:27,630 --> 00:35:32,099
this is helpful because being able to

00:35:29,940 --> 00:35:34,950
understand how well your model is

00:35:32,099 --> 00:35:36,989
performing one peak into it is

00:35:34,950 --> 00:35:40,289
understanding your training and your

00:35:36,989 --> 00:35:41,969
validation loss plots all right let's

00:35:40,289 --> 00:35:44,279
keep moving forward let's check out how

00:35:41,969 --> 00:35:46,589
well this model did our mean absolute

00:35:44,279 --> 00:35:49,170
error for the validation set zero point

00:35:46,589 --> 00:35:51,420
nine seven and then our mean absolute

00:35:49,170 --> 00:35:53,670
error for the prediction set is one

00:35:51,420 --> 00:35:56,969
point five two hey guys this doesn't

00:35:53,670 --> 00:35:59,219
look very good so our orange are all of

00:35:56,969 --> 00:36:02,249
our actual time series values and then

00:35:59,219 --> 00:36:03,599
our blue is our prediction now I could

00:36:02,249 --> 00:36:05,130
have sugar-coated it and shown you

00:36:03,599 --> 00:36:07,519
something great and we would have like a

00:36:05,130 --> 00:36:10,200
super low loss and you know magic magic

00:36:07,519 --> 00:36:10,650
but it's important to show people in a

00:36:10,200 --> 00:36:13,289
notebook

00:36:10,650 --> 00:36:16,109
especially to a government that there's

00:36:13,289 --> 00:36:17,880
a lot of room for iteration like I said

00:36:16,109 --> 00:36:20,849
we've been working on this since around

00:36:17,880 --> 00:36:22,559
December and I personally must have

00:36:20,849 --> 00:36:25,349
built like a hundred different models a

00:36:22,559 --> 00:36:28,140
lot of it is based on a lot of trial and

00:36:25,349 --> 00:36:29,969
error some of it as an art reading a lot

00:36:28,140 --> 00:36:32,309
of literature but not everything is

00:36:29,969 --> 00:36:34,349
peaches so what this tells me here is

00:36:32,309 --> 00:36:37,170
that this model has been pretty good at

00:36:34,349 --> 00:36:38,460
predicting the overall trend but it has

00:36:37,170 --> 00:36:41,730
a long long way

00:36:38,460 --> 00:36:44,670
to go all right next up get the model

00:36:41,730 --> 00:36:46,980
configurations why is this important

00:36:44,670 --> 00:36:48,540
well you just heard me say that I

00:36:46,980 --> 00:36:51,450
probably worked on like a hundred

00:36:48,540 --> 00:36:53,550
different models I have been very guilty

00:36:51,450 --> 00:36:55,619
of repeating the same model again

00:36:53,550 --> 00:36:58,080
because I didn't write down on a piece

00:36:55,619 --> 00:36:59,849
of paper all the hyper parameters I

00:36:58,080 --> 00:37:01,530
didn't write down how many epics I ran

00:36:59,849 --> 00:37:04,500
and I ended up running the same model

00:37:01,530 --> 00:37:06,240
again now for one model like this you

00:37:04,500 --> 00:37:08,040
can write it on a piece of paper what

00:37:06,240 --> 00:37:10,320
was your activation function what was

00:37:08,040 --> 00:37:12,839
your train to split all these different

00:37:10,320 --> 00:37:15,420
knobs and levers that you've turned but

00:37:12,839 --> 00:37:18,089
once you start building a lot of models

00:37:15,420 --> 00:37:20,760
you need to be able to inventory them in

00:37:18,089 --> 00:37:23,010
a way that is organized and make sense

00:37:20,760 --> 00:37:25,020
I'm going to show you in the final

00:37:23,010 --> 00:37:27,599
master notebook how this really helps

00:37:25,020 --> 00:37:29,849
when you do multiple models so here

00:37:27,599 --> 00:37:32,099
we're able to output all the parameters

00:37:29,849 --> 00:37:34,410
for each one of the three layers so

00:37:32,099 --> 00:37:36,869
we've got our first layer tells us our

00:37:34,410 --> 00:37:38,520
activation function was at an age we've

00:37:36,869 --> 00:37:40,980
got all these different configurations

00:37:38,520 --> 00:37:43,200
our second layer we've got all these

00:37:40,980 --> 00:37:46,050
configurations and our third layer which

00:37:43,200 --> 00:37:47,400
is our duds is our time distributed for

00:37:46,050 --> 00:37:48,869
those of you in the audience who are

00:37:47,400 --> 00:37:50,910
looking at this and it looks like

00:37:48,869 --> 00:37:52,890
complete gibberish the reason why this

00:37:50,910 --> 00:37:55,680
is important is because these are the

00:37:52,890 --> 00:37:57,960
hyper parameters these are the knobs and

00:37:55,680 --> 00:38:00,000
the switches that you can turn to be

00:37:57,960 --> 00:38:02,310
able to make your model become more and

00:38:00,000 --> 00:38:04,710
more accurate a lot of machine learning

00:38:02,310 --> 00:38:06,960
data scientists they'll first start with

00:38:04,710 --> 00:38:09,210
a learning rate the experiment with

00:38:06,960 --> 00:38:11,130
different optimization functions and it

00:38:09,210 --> 00:38:13,140
becomes this big kind of Chinese menu

00:38:11,130 --> 00:38:14,910
for figuring out what are the best

00:38:13,140 --> 00:38:18,260
combinations to give me the best type of

00:38:14,910 --> 00:38:21,300
model this is very important from a

00:38:18,260 --> 00:38:23,099
documentation perspective if you forget

00:38:21,300 --> 00:38:25,220
your configurations

00:38:23,099 --> 00:38:28,109
how can you reproduce this ever again

00:38:25,220 --> 00:38:29,880
all right now it's time to do something

00:38:28,109 --> 00:38:32,040
that I am personally starting to do a

00:38:29,880 --> 00:38:34,650
lot of which is computing the gradients

00:38:32,040 --> 00:38:37,170
so in a neural network there is a

00:38:34,650 --> 00:38:39,540
backward pass I'm not going to go into

00:38:37,170 --> 00:38:41,339
great detail about it but when you are

00:38:39,540 --> 00:38:43,589
computing your loss function you're

00:38:41,339 --> 00:38:46,650
going through a forward pass like in

00:38:43,589 --> 00:38:48,390
linear regression for example but that's

00:38:46,650 --> 00:38:49,590
not the end of the story you have to do

00:38:48,390 --> 00:38:51,060
a backward pass

00:38:49,590 --> 00:38:53,280
what that means is that we're doing a

00:38:51,060 --> 00:38:55,440
back propagation method that will

00:38:53,280 --> 00:38:56,940
compute the gradients gradient just

00:38:55,440 --> 00:38:59,280
means a derivative it's a rate of change

00:38:56,940 --> 00:39:01,620
for multiple multiple teach multiple

00:38:59,280 --> 00:39:03,750
variables but then after that we

00:39:01,620 --> 00:39:05,640
optimize those gradients and that makes

00:39:03,750 --> 00:39:07,920
the model learn and what ends up

00:39:05,640 --> 00:39:10,470
happening is that all the weight across

00:39:07,920 --> 00:39:12,840
the entire network or adjust it a little

00:39:10,470 --> 00:39:15,600
bit up a little bit down so that we're

00:39:12,840 --> 00:39:18,120
minimizing the mean absolute error that

00:39:15,600 --> 00:39:20,580
loss function at the very end now there

00:39:18,120 --> 00:39:23,220
is a trick and compute ingredients where

00:39:20,580 --> 00:39:25,170
you can compute the gradients of the

00:39:23,220 --> 00:39:28,230
inputs of the output vector with respect

00:39:25,170 --> 00:39:31,050
to the inputs all that is telling you is

00:39:28,230 --> 00:39:33,000
a form of sensitivity analysis I want to

00:39:31,050 --> 00:39:35,640
be able to do something kind of like you

00:39:33,000 --> 00:39:38,040
might see in a random forest has anyone

00:39:35,640 --> 00:39:39,630
ever used around the forest model and so

00:39:38,040 --> 00:39:42,210
when scikit-learn they make it super

00:39:39,630 --> 00:39:43,800
easy feature importances i can see all

00:39:42,210 --> 00:39:46,350
my features which ones are more

00:39:43,800 --> 00:39:48,690
predictive business leaders love to see

00:39:46,350 --> 00:39:50,760
that you can do derivations of it and

00:39:48,690 --> 00:39:52,650
permute and destroy an entire column

00:39:50,760 --> 00:39:54,750
rerun a model again do it hundreds of

00:39:52,650 --> 00:39:56,880
times take the average and now you can

00:39:54,750 --> 00:39:58,980
get that feature importance how can we

00:39:56,880 --> 00:40:01,200
do something similarly to a recurrent

00:39:58,980 --> 00:40:03,420
neural network this is one way of doing

00:40:01,200 --> 00:40:06,270
it so what this is telling me is that

00:40:03,420 --> 00:40:09,030
the prediction my pertussis forecast is

00:40:06,270 --> 00:40:11,760
most sensitive to which one of my five

00:40:09,030 --> 00:40:15,300
independent variables that influenza is

00:40:11,760 --> 00:40:17,610
it salmonella is it precipitation low or

00:40:15,300 --> 00:40:19,290
high temperature now again it's

00:40:17,610 --> 00:40:22,520
important when you're doing something

00:40:19,290 --> 00:40:25,440
like this for a new organization please

00:40:22,520 --> 00:40:27,570
please use weigh tuck please document

00:40:25,440 --> 00:40:30,330
your references and talk about what it

00:40:27,570 --> 00:40:32,400
is that you're doing just for the folks

00:40:30,330 --> 00:40:35,580
in the audience who don't do a lot of

00:40:32,400 --> 00:40:37,380
calculus that a derivative is just the

00:40:35,580 --> 00:40:40,200
rate of change with regard to one

00:40:37,380 --> 00:40:42,030
variable and a derivative derivative is

00:40:40,200 --> 00:40:44,880
just a fancy way of saying it's a

00:40:42,030 --> 00:40:46,470
matrices a matrix of multiple values of

00:40:44,880 --> 00:40:48,600
partial derivatives it's a derivative

00:40:46,470 --> 00:40:50,340
with respect to multiple values we have

00:40:48,600 --> 00:40:53,220
multiple values five independent

00:40:50,340 --> 00:40:56,370
variables all right this is the same

00:40:53,220 --> 00:40:58,770
depiction of the previous diagram where

00:40:56,370 --> 00:41:00,420
we unrolled it but we've got our inputs

00:40:58,770 --> 00:41:03,270
we've got two hidden layer

00:41:00,420 --> 00:41:05,880
of 128 units and this is our output we

00:41:03,270 --> 00:41:09,810
want to calculate the gradient of the

00:41:05,880 --> 00:41:11,910
outputs with respect to our inputs this

00:41:09,810 --> 00:41:13,680
is similar to something that maybe

00:41:11,910 --> 00:41:16,830
you've seen before out in the literature

00:41:13,680 --> 00:41:19,470
and this one example from another medium

00:41:16,830 --> 00:41:21,870
blogpost he wants to know for my text

00:41:19,470 --> 00:41:24,060
classification score which one of my

00:41:21,870 --> 00:41:26,310
words are most sensitive to that score

00:41:24,060 --> 00:41:28,170
and he found that Coke is the most

00:41:26,310 --> 00:41:30,630
sensitive but he's using the same type

00:41:28,170 --> 00:41:32,700
of analysis computing the gradients of

00:41:30,630 --> 00:41:35,160
the output with respect to the input

00:41:32,700 --> 00:41:36,960
this is also similar to something you

00:41:35,160 --> 00:41:39,690
might see in computer vision which is

00:41:36,960 --> 00:41:41,910
they use saliency maps the idea of being

00:41:39,690 --> 00:41:43,890
able to compute which one of the pixel

00:41:41,910 --> 00:41:47,880
features and this image is most

00:41:43,890 --> 00:41:49,830
sensitive to my prediction so when we go

00:41:47,880 --> 00:41:51,270
ahead and we do this we're gonna get our

00:41:49,830 --> 00:41:54,210
gradient these are all the partial

00:41:51,270 --> 00:41:56,430
derivatives for our training set and we

00:41:54,210 --> 00:41:58,950
can just get the mean or the average of

00:41:56,430 --> 00:42:01,260
all the absolute values of the gradients

00:41:58,950 --> 00:42:02,820
for each one of our five features and

00:42:01,260 --> 00:42:06,000
we'll see that only for this training

00:42:02,820 --> 00:42:08,310
set Salmonella seems to have the largest

00:42:06,000 --> 00:42:10,170
gradient it is the most the prediction

00:42:08,310 --> 00:42:12,660
is the most sensitive to changes in

00:42:10,170 --> 00:42:15,660
Salmonella then let's say compared to

00:42:12,660 --> 00:42:19,500
high temperature and we plot this out

00:42:15,660 --> 00:42:22,560
another value add for jupiter notebook

00:42:19,500 --> 00:42:25,320
we're able to see only for our training

00:42:22,560 --> 00:42:27,690
set that we get a plot and this shows a

00:42:25,320 --> 00:42:29,430
plot of how all the gradients their

00:42:27,690 --> 00:42:31,710
absolute value of the gradients have

00:42:29,430 --> 00:42:34,500
changed over time with respect to the

00:42:31,710 --> 00:42:37,250
predictions and what we see here is that

00:42:34,500 --> 00:42:39,960
we see a blue curve and an orange curve

00:42:37,250 --> 00:42:41,790
pretty much the largest gradients here

00:42:39,960 --> 00:42:44,250
and that makes sense because our

00:42:41,790 --> 00:42:46,860
previous mean average showed us that the

00:42:44,250 --> 00:42:48,720
strength of the gradient the magnitude

00:42:46,860 --> 00:42:50,490
of the gradient the predictions are the

00:42:48,720 --> 00:42:53,070
most sensitive to Salmonella and

00:42:50,490 --> 00:42:54,750
influenza now this provides more of an

00:42:53,070 --> 00:42:59,280
intuition this is not an absolute

00:42:54,750 --> 00:43:01,110
science if I added an entire 544 time

00:42:59,280 --> 00:43:04,380
steps instead of just my training step

00:43:01,110 --> 00:43:07,080
of 181 this would change so this is

00:43:04,380 --> 00:43:09,420
something that is our attempt at being

00:43:07,080 --> 00:43:11,589
able to understand the inner workings of

00:43:09,420 --> 00:43:13,359
a black box especially with neural net

00:43:11,589 --> 00:43:15,809
and I think it's very important for

00:43:13,359 --> 00:43:19,569
interpretability to begin this process

00:43:15,809 --> 00:43:23,170
alright now I showed you the model where

00:43:19,569 --> 00:43:25,689
we used 180 one time steps one single

00:43:23,170 --> 00:43:27,729
sequence and we use time distributed and

00:43:25,689 --> 00:43:30,640
we said give me a prediction at every

00:43:27,729 --> 00:43:32,170
single time step we got a bad loss

00:43:30,640 --> 00:43:34,930
function it was not a good prediction

00:43:32,170 --> 00:43:37,299
this is another opportunity in a jupiter

00:43:34,930 --> 00:43:39,640
notebook to start exploring maybe a

00:43:37,299 --> 00:43:43,869
different type of approach instead of

00:43:39,640 --> 00:43:45,729
having one long sample of 181 can we

00:43:43,869 --> 00:43:48,009
show in this jupiter notebook how maybe

00:43:45,729 --> 00:43:50,469
we could have multiple samples but

00:43:48,009 --> 00:43:52,150
overlapping sequences and this is kind

00:43:50,469 --> 00:43:54,400
of natural to a supervised machine

00:43:52,150 --> 00:43:56,109
learning approach so here what we've

00:43:54,400 --> 00:43:59,859
done was we provided overlapping

00:43:56,109 --> 00:44:02,680
sequences we now have building our model

00:43:59,859 --> 00:44:04,660
we have our loss plot so we've now seen

00:44:02,680 --> 00:44:07,509
that our training and our validation

00:44:04,660 --> 00:44:09,009
loss have converged quite well and now

00:44:07,509 --> 00:44:11,920
we're able to output our score

00:44:09,009 --> 00:44:14,529
predictions so for the ballot the test

00:44:11,920 --> 00:44:16,449
set our score is zero point eight nine

00:44:14,529 --> 00:44:17,979
seven and then you'll be able to see

00:44:16,449 --> 00:44:20,619
here with this new data processing

00:44:17,979 --> 00:44:22,959
approach it's a little bit closer to our

00:44:20,619 --> 00:44:25,089
predicted values but we still have a

00:44:22,959 --> 00:44:27,489
very very long way to go because we can

00:44:25,089 --> 00:44:29,049
still see a big difference here now at

00:44:27,489 --> 00:44:31,599
the end of this notebook we'll be able

00:44:29,049 --> 00:44:33,519
to use those configurations let me just

00:44:31,599 --> 00:44:35,679
expand this a little because it's a

00:44:33,519 --> 00:44:36,849
little bit hard to see remember when I

00:44:35,679 --> 00:44:39,819
was talking about the model

00:44:36,849 --> 00:44:42,069
configurations we're now able to get

00:44:39,819 --> 00:44:44,469
kind of an overview of the different

00:44:42,069 --> 00:44:47,319
models that we built and then their mean

00:44:44,469 --> 00:44:49,079
absolute errors and we can customize

00:44:47,319 --> 00:44:51,939
this output so we've got other

00:44:49,079 --> 00:44:54,130
configurations to show but in our final

00:44:51,939 --> 00:44:56,439
master notebook this is really helpful

00:44:54,130 --> 00:44:58,900
because as we build more and more models

00:44:56,439 --> 00:45:00,910
just give it a little minute we'll find

00:44:58,900 --> 00:45:02,709
that this is a good way to keep up with

00:45:00,910 --> 00:45:04,539
all of the models that we build and

00:45:02,709 --> 00:45:06,160
we've trucked that mean absolute error

00:45:04,539 --> 00:45:09,519
we want to build the model has the

00:45:06,160 --> 00:45:11,229
lowest loss function and this reminds me

00:45:09,519 --> 00:45:13,390
a lot for anyone who's done work on

00:45:11,229 --> 00:45:15,459
Kaggle and just participated in Cavill

00:45:13,390 --> 00:45:17,559
competitions going up the leaderboard

00:45:15,459 --> 00:45:19,619
and building a leaderboard of your own

00:45:17,559 --> 00:45:22,420
of different models that you've built

00:45:19,619 --> 00:45:23,630
one of the things I really want to do

00:45:22,420 --> 00:45:25,640
with our team

00:45:23,630 --> 00:45:28,340
as you can tell a lot of this is just

00:45:25,640 --> 00:45:30,470
hard coded just for me preparing this

00:45:28,340 --> 00:45:33,200
but what I'd really like to do is build

00:45:30,470 --> 00:45:35,360
a toolkit in Jupiter that everyone can

00:45:33,200 --> 00:45:37,730
use put it up on github that will have

00:45:35,360 --> 00:45:39,530
like a running leaderboard pandas output

00:45:37,730 --> 00:45:41,300
so that everyone who's building a

00:45:39,530 --> 00:45:42,890
notebook can do a running leaderboard

00:45:41,300 --> 00:45:45,320
and you can just summarize all of your

00:45:42,890 --> 00:45:47,510
models at the very end a baseline I

00:45:45,320 --> 00:45:50,300
think that would be super helpful to

00:45:47,510 --> 00:45:51,770
have all right so let me just show you a

00:45:50,300 --> 00:45:54,350
couple of things about a couple of

00:45:51,770 --> 00:45:56,780
little more minutes here this whole

00:45:54,350 --> 00:45:57,920
notebook is available here up on github

00:45:56,780 --> 00:46:01,280
on my account

00:45:57,920 --> 00:46:04,310
so it's neutral which is my name spell

00:46:01,280 --> 00:46:06,080
my last name is felt backwards orden and

00:46:04,310 --> 00:46:08,360
as Jupiter forecast here all the

00:46:06,080 --> 00:46:11,990
dependencies that will you will need and

00:46:08,360 --> 00:46:14,990
then here's the data spot and here's the

00:46:11,990 --> 00:46:16,580
notebook up here so this is going to be

00:46:14,990 --> 00:46:19,070
something if you have any questions

00:46:16,580 --> 00:46:21,710
about it you know do not hesitate to

00:46:19,070 --> 00:46:25,160
give me a call and I'll help you think

00:46:21,710 --> 00:46:27,770
through it also I have this notebook

00:46:25,160 --> 00:46:30,650
well you could actually do this too up

00:46:27,770 --> 00:46:33,500
on Google collaboratory so Google

00:46:30,650 --> 00:46:36,020
collaboratory is something that opens up

00:46:33,500 --> 00:46:38,030
like started doing a lot of especially

00:46:36,020 --> 00:46:40,040
when it comes to tutorials and teaching

00:46:38,030 --> 00:46:41,840
each other and the reason why is this

00:46:40,040 --> 00:46:43,310
maybe some of you have been asking

00:46:41,840 --> 00:46:46,670
Katherine you built a neural network

00:46:43,310 --> 00:46:49,850
where is a GPU and so a Booz Allen we

00:46:46,670 --> 00:46:52,190
have a partnership with Nvidia and a lot

00:46:49,850 --> 00:46:53,990
of our data scientists are like Nvidia

00:46:52,190 --> 00:46:56,540
deep learning instructors I'm one of

00:46:53,990 --> 00:46:58,550
them and because of this partnership we

00:46:56,540 --> 00:47:00,950
have our own Nvidia cluster we've got

00:46:58,550 --> 00:47:03,410
three different clusters and so I always

00:47:00,950 --> 00:47:07,010
tunnel into an Nvidia cluster it's got

00:47:03,410 --> 00:47:09,380
four Titan cards but for this model when

00:47:07,010 --> 00:47:12,320
you download it off of github you don't

00:47:09,380 --> 00:47:13,130
need to run it on a GPU it's only 544

00:47:12,320 --> 00:47:15,410
timesteps

00:47:13,130 --> 00:47:18,350
it's only six different features are all

00:47:15,410 --> 00:47:21,410
numerical I have a MacBook Pro it's got

00:47:18,350 --> 00:47:23,150
six core CPUs I just run it takes less

00:47:21,410 --> 00:47:26,600
than a minute when you're dealing with

00:47:23,150 --> 00:47:28,370
large processes obviously you need a GPU

00:47:26,600 --> 00:47:31,010
that's why a Google collaboratory

00:47:28,370 --> 00:47:33,020
notebook is really cool for 12 hours you

00:47:31,010 --> 00:47:36,560
can run it on their GPU which i think is

00:47:33,020 --> 00:47:38,960
equivalent to a p2x large and aw

00:47:36,560 --> 00:47:41,960
which is equivalents like 1 I guess one

00:47:38,960 --> 00:47:43,070
like geforce card I think don't quote me

00:47:41,960 --> 00:47:46,610
on that

00:47:43,070 --> 00:47:47,480
but when you run it in your to Google

00:47:46,610 --> 00:47:50,840
collaboratory

00:47:47,480 --> 00:47:54,380
you can run this model and it'll run you

00:47:50,840 --> 00:47:56,480
know really fast or just as fast

00:47:54,380 --> 00:48:00,290
once it starts running here let's do

00:47:56,480 --> 00:48:01,970
this because Google collaboratory all

00:48:00,290 --> 00:48:04,700
your neural networks can be built on

00:48:01,970 --> 00:48:06,500
their GPU 12 hours free so I would

00:48:04,700 --> 00:48:09,050
highly recommend that you get your

00:48:06,500 --> 00:48:11,270
notebook and you build it into Google

00:48:09,050 --> 00:48:13,670
collaboratory we use it a lot of booze

00:48:11,270 --> 00:48:16,310
on for our tutorials and I think that's

00:48:13,670 --> 00:48:18,170
really neat so let me go ahead and close

00:48:16,310 --> 00:48:22,490
this out here and I'm going to go back

00:48:18,170 --> 00:48:25,370
to our slides really quickly so what I

00:48:22,490 --> 00:48:28,490
walked you through was the value

00:48:25,370 --> 00:48:29,690
proposition of Y being transparent with

00:48:28,490 --> 00:48:31,370
machine learning model for the

00:48:29,690 --> 00:48:34,130
government is helpful I hope that came

00:48:31,370 --> 00:48:36,950
out clear I also walked you through just

00:48:34,130 --> 00:48:39,920
by itself showing you the one model code

00:48:36,950 --> 00:48:41,990
is ordinary but if we show you all the

00:48:39,920 --> 00:48:44,420
different features for multiple multiple

00:48:41,990 --> 00:48:46,760
models that provides one step towards

00:48:44,420 --> 00:48:47,840
being transparent I also walked you

00:48:46,760 --> 00:48:49,820
through the notebook and now you have

00:48:47,840 --> 00:48:51,350
access to it on github I highly

00:48:49,820 --> 00:48:54,680
recommend that you run it in Google

00:48:51,350 --> 00:48:57,380
collaboratory I would recommend as kind

00:48:54,680 --> 00:49:00,170
of a final call to action is practice

00:48:57,380 --> 00:49:01,790
considering some of these transparency

00:49:00,170 --> 00:49:04,250
steps is everything that we talked about

00:49:01,790 --> 00:49:06,640
today the baseline model the data

00:49:04,250 --> 00:49:08,650
processing building the model the model

00:49:06,640 --> 00:49:11,260
configurations computing the gradient

00:49:08,650 --> 00:49:13,520
something I didn't show you because it's

00:49:11,260 --> 00:49:15,020
sometimes not really worth it is the

00:49:13,520 --> 00:49:17,000
different weights so you can actually

00:49:15,020 --> 00:49:19,790
output the weights for every single

00:49:17,000 --> 00:49:21,620
neuron for every single gate of Alice TM

00:49:19,790 --> 00:49:23,840
but for this talk I think that would get

00:49:21,620 --> 00:49:25,610
too much in the weeds that might be

00:49:23,840 --> 00:49:28,520
helpful but computing the gradients is

00:49:25,610 --> 00:49:30,590
more helpful and then also to summarize

00:49:28,520 --> 00:49:31,610
your models in the end I recommend

00:49:30,590 --> 00:49:34,640
considering some of these

00:49:31,610 --> 00:49:35,900
recommendations your clients may not be

00:49:34,640 --> 00:49:38,150
in the government but they may be

00:49:35,900 --> 00:49:39,800
organizations or stakeholders who are

00:49:38,150 --> 00:49:42,230
also starting to learn about machine

00:49:39,800 --> 00:49:44,600
learning and I would emphasize be easy

00:49:42,230 --> 00:49:48,210
on them try to make it as easy to

00:49:44,600 --> 00:49:50,849
swallow as possible and hold their hands

00:49:48,210 --> 00:49:52,829
and educate them because they are trying

00:49:50,849 --> 00:49:55,559
to use your models to do something very

00:49:52,829 --> 00:49:58,290
important for their organization so with

00:49:55,559 --> 00:50:00,210
that again do not hesitate to email me

00:49:58,290 --> 00:50:03,410
I'm more than happy to answer questions

00:50:00,210 --> 00:50:06,089
now or in the hallway and you can also

00:50:03,410 --> 00:50:09,420
follow me on Twitter as well sometimes I

00:50:06,089 --> 00:50:11,460
repeat and retweet interesting machine

00:50:09,420 --> 00:50:47,849
learning articles so thank you very much

00:50:11,460 --> 00:50:50,190
for your time everyone yes sir yeah I

00:50:47,849 --> 00:50:52,859
mean I myself have read a lot of stack

00:50:50,190 --> 00:50:55,950
overflow and cross validated posts about

00:50:52,859 --> 00:50:58,500
this very topic we're even well I let

00:50:55,950 --> 00:51:00,990
let's just forget Python two are within

00:50:58,500 --> 00:51:02,970
stats models sometimes I get an error

00:51:00,990 --> 00:51:06,059
it's called maximum likelihood

00:51:02,970 --> 00:51:08,069
estimation convergence error uh-huh and

00:51:06,059 --> 00:51:10,650
I'm like why am I getting this error and

00:51:08,069 --> 00:51:12,599
sometimes it's because people have not

00:51:10,650 --> 00:51:14,220
updated the recent package of stats

00:51:12,599 --> 00:51:16,140
models sometimes they've changed

00:51:14,220 --> 00:51:18,240
documentation on the back end so the

00:51:16,140 --> 00:51:19,730
actual ARIMA forecasts or the sera max

00:51:18,240 --> 00:51:23,430
forecasts is not working appropriately

00:51:19,730 --> 00:51:25,380
so I mean that's one root cause about

00:51:23,430 --> 00:51:27,599
why it might be happening some of it

00:51:25,380 --> 00:51:30,660
comes down to inspecting the source code

00:51:27,599 --> 00:51:32,730
so yes obviously it's important because

00:51:30,660 --> 00:51:34,650
in our teams not everyone is I mean I'm

00:51:32,730 --> 00:51:36,980
not I don't tell people you have to do

00:51:34,650 --> 00:51:39,329
this in Python you got to do this in R

00:51:36,980 --> 00:51:41,010
whatever language they're familiar with

00:51:39,329 --> 00:51:41,849
and they can do good work is what

00:51:41,010 --> 00:51:44,790
they're going to use

00:51:41,849 --> 00:51:46,920
but regardless R has an advantage and

00:51:44,790 --> 00:51:49,190
that it's very statistic as a lot of

00:51:46,920 --> 00:51:51,450
statistical models mathematicians use it

00:51:49,190 --> 00:51:53,160
epidemiologists use it and sometimes

00:51:51,450 --> 00:51:55,170
it's not a one-to-one mapping if you're

00:51:53,160 --> 00:51:57,630
going to build an auditor ARIMA

00:51:55,170 --> 00:51:58,710
and our it's not the same output it's

00:51:57,630 --> 00:52:01,470
like a little bit off from what you

00:51:58,710 --> 00:52:04,559
might see in stats models so kind of the

00:52:01,470 --> 00:52:07,200
solution there is to look at the source

00:52:04,559 --> 00:52:08,359
code and maybe do this which is the

00:52:07,200 --> 00:52:11,520
reason I put all those mathematical

00:52:08,359 --> 00:52:13,920
formulas and leeteuk is because although

00:52:11,520 --> 00:52:16,559
scikit-learn is incredibly well

00:52:13,920 --> 00:52:19,200
documented although every single NLP

00:52:16,559 --> 00:52:22,530
package is built on the back of n LT k

00:52:19,200 --> 00:52:24,630
if you are able to reproduce your model

00:52:22,530 --> 00:52:26,460
with your own mathematical formula I

00:52:24,630 --> 00:52:28,410
would I would suggest that you try it

00:52:26,460 --> 00:52:30,210
for those folks who are building neural

00:52:28,410 --> 00:52:33,030
networks don't just immediately go into

00:52:30,210 --> 00:52:35,220
Karis try to follow tutorials that use

00:52:33,030 --> 00:52:38,040
numpy and do it from bare-bones from

00:52:35,220 --> 00:52:40,109
scratch so I don't see like an immediate

00:52:38,040 --> 00:52:42,809
way to solve this writ large

00:52:40,109 --> 00:52:44,640
I think it's a class-by-class problem

00:52:42,809 --> 00:52:46,950
that requires investigating the source

00:52:44,640 --> 00:52:49,020
code but actually just having like the

00:52:46,950 --> 00:52:51,119
having the guts to try to build it

00:52:49,020 --> 00:52:59,390
yourself mathematically if that's

00:52:51,119 --> 00:52:59,390
something that's possible yeah yes sir

00:53:25,219 --> 00:53:30,499
well I mean I think that I'm going to

00:53:27,949 --> 00:53:33,439
answer this in this way which is one of

00:53:30,499 --> 00:53:36,589
the features that we used was Salmonella

00:53:33,439 --> 00:53:38,689
now for a lot of the folks in public

00:53:36,589 --> 00:53:40,880
health you might think what is that

00:53:38,689 --> 00:53:43,640
there is no relationship really between

00:53:40,880 --> 00:53:46,670
Salmonella and pertussis Salmonella is

00:53:43,640 --> 00:53:49,640
bacterial processes also bacterial

00:53:46,670 --> 00:53:53,109
influences viral so a part of this

00:53:49,640 --> 00:53:55,069
causal analysis I think first goes to

00:53:53,109 --> 00:53:57,829
consulting with a subject matter expert

00:53:55,069 --> 00:53:59,119
and determining whether the feature that

00:53:57,829 --> 00:54:01,849
you're going to be using in your

00:53:59,119 --> 00:54:03,739
analysis has any logical relevance at

00:54:01,849 --> 00:54:05,839
all that's number one

00:54:03,739 --> 00:54:08,089
because I could get diapers and beer and

00:54:05,839 --> 00:54:10,160
I could maybe correlate that with

00:54:08,089 --> 00:54:11,839
pertussis and I'll say oh well diapers

00:54:10,160 --> 00:54:15,289
and pertussis have something in common

00:54:11,839 --> 00:54:17,779
for the causal analysis no we didn't

00:54:15,289 --> 00:54:19,849
look at that for this time series we

00:54:17,779 --> 00:54:22,369
were really focusing on being able to do

00:54:19,849 --> 00:54:25,430
a prediction however I think that that

00:54:22,369 --> 00:54:27,259
would be a next step I've got a couple

00:54:25,430 --> 00:54:30,439
of ideas about maybe how that would work

00:54:27,259 --> 00:54:33,319
but I think this is such a hard space in

00:54:30,439 --> 00:54:34,969
terms of disease I mean it's a very hard

00:54:33,319 --> 00:54:39,400
space in terms of disease it's hard to

00:54:34,969 --> 00:54:41,539
say if the influenza cases are causing

00:54:39,400 --> 00:54:44,209
pertussis we can say there are

00:54:41,539 --> 00:54:46,729
correlations but causation in itself is

00:54:44,209 --> 00:54:49,160
kind of hard to define but I'm more than

00:54:46,729 --> 00:54:53,589
happy to have some ideas from you later

00:54:49,160 --> 00:54:53,589
on thank you

00:54:56,539 --> 00:55:00,050
all right well thank you very much and

00:54:58,519 --> 00:55:05,119
if you have any questions let me know

00:55:00,050 --> 00:55:05,119

YouTube URL: https://www.youtube.com/watch?v=vdghnZUr0bI


