Title: Reproducible science with the Renku platform- Sandra Savchenko-de Jong (Swiss Data Science Center)
Publication date: 2018-10-02
Playlist: JupyterCon in New York 2018
Description: 
	Sandra Savchenko-de Jong offers an overview of Renku, a highly scalable and secure open software platform developed by the Swiss Data Science Centre (a collaboration between ETH Zurich and EFPL) that is designed to make (data) science reproducible, foster collaboration between scientists, and share resources in a federated environment. The name was borrowed from the renku, a traditional form of Japanese collaborative poetry. Like its namesake, the platform encourages interdisciplinary cooperation (or competition) between scientists.

Renku shows up as a shell around users’ Jupyter notebooks. Under the hood, the platform is governed by a loosely coupled federated model that allows organizations to share compute and storage resources while keeping complete control over said resources. Renku is developed in alignment with the FAIR principles—to make data findable, accessible, interoperable, and reusable.

Reusability is enabled by Renku’s knowledge graph. All actions performed on the data and code, whether code execution and access to the storage to read or write new results, are authorized and registered automatically by the Renku middleware into the knowledge graph. The knowledge graph is immutable and contains information about the version of data, code (or notebooks), and the relationships between the two, such as which execution of a notebook generated a version of a dataset and what dataset was used in input. The resulting knowledge graph can be used for governance, intellectual properties attribution, auditing, and data science on data science. The latter would enable new type of services, such as improved search algorithms for data science research and recommender systems to suggest algorithms or datasets to data scientists based on their research activities.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,920 --> 00:00:07,450
hello everyone and welcome to my talk

00:00:04,600 --> 00:00:10,360
about Renko my name is saundra Savchenko

00:00:07,450 --> 00:00:13,059
do and i'm with swiss data science

00:00:10,360 --> 00:00:14,710
center so first i want to talk a little

00:00:13,059 --> 00:00:16,980
bit about issues that many of you may

00:00:14,710 --> 00:00:19,480
have seen working in data science for

00:00:16,980 --> 00:00:21,669
example you have a very beautiful plot

00:00:19,480 --> 00:00:25,480
but you don't actually know how it was

00:00:21,669 --> 00:00:27,460
created where the data came from or you

00:00:25,480 --> 00:00:29,079
or your colleagues have written paper in

00:00:27,460 --> 00:00:38,590
nature and there's some new data

00:00:29,079 --> 00:00:40,750
available okay so for example you have

00:00:38,590 --> 00:00:42,670
you or your colleagues have written a

00:00:40,750 --> 00:00:44,500
paper in nature and you certainly come

00:00:42,670 --> 00:00:46,540
upon some new data and you wonder I

00:00:44,500 --> 00:00:48,550
wonder what that means for my last test

00:00:46,540 --> 00:00:50,170
results and what happens to us

00:00:48,550 --> 00:00:52,720
especially if we work on companies is

00:00:50,170 --> 00:00:54,880
that the person before us had created

00:00:52,720 --> 00:00:56,650
some great models some great results and

00:00:54,880 --> 00:00:58,570
you actually you're not entirely sure

00:00:56,650 --> 00:01:01,810
how they did it so you kind of have to

00:00:58,570 --> 00:01:03,880
reverse engineer this information and if

00:01:01,810 --> 00:01:06,490
you work for example with confidential

00:01:03,880 --> 00:01:08,319
data what might happen is that you want

00:01:06,490 --> 00:01:10,060
to run an algorithm on someone else's

00:01:08,319 --> 00:01:15,189
data and how can you do that in a safe

00:01:10,060 --> 00:01:17,259
way M or completely different problem

00:01:15,189 --> 00:01:19,679
you have a data set and you want to

00:01:17,259 --> 00:01:22,119
train a model on it which might be a bit

00:01:19,679 --> 00:01:24,280
compute-intensive and you wonder well I

00:01:22,119 --> 00:01:25,840
probably thought not the first person to

00:01:24,280 --> 00:01:28,509
think of this I wonder if someone else

00:01:25,840 --> 00:01:30,310
had already done it and Leslie

00:01:28,509 --> 00:01:32,289
especially for scientists this is a

00:01:30,310 --> 00:01:34,090
problem you create a beautiful algorithm

00:01:32,289 --> 00:01:38,020
you have a really nice data set that you

00:01:34,090 --> 00:01:40,270
have put all your time into to make

00:01:38,020 --> 00:01:42,310
nicely available and then people are

00:01:40,270 --> 00:01:44,590
probably using it but you don't really

00:01:42,310 --> 00:01:48,579
know it and first of all they're not

00:01:44,590 --> 00:01:50,079
citing you obviously I'm not the first

00:01:48,579 --> 00:01:52,770
person to address these issues there are

00:01:50,079 --> 00:01:55,209
many solutions nowadays which exists to

00:01:52,770 --> 00:01:57,639
solve at least part of these questions

00:01:55,209 --> 00:02:00,249
people nowadays use gates often for

00:01:57,639 --> 00:02:01,659
version control and collaboration to

00:02:00,249 --> 00:02:04,689
collaborate on papers you can use

00:02:01,659 --> 00:02:07,090
overleaf Google Drive Evernote and to

00:02:04,689 --> 00:02:09,729
have this viewable environment people

00:02:07,090 --> 00:02:11,530
use docker containers even completely

00:02:09,729 --> 00:02:15,750
rerun about pipelines exist using for

00:02:11,530 --> 00:02:17,890
example yuvigi cwl and there's also

00:02:15,750 --> 00:02:19,300
many other things which I learned about

00:02:17,890 --> 00:02:22,900
in this conference which I didn't put on

00:02:19,300 --> 00:02:25,870
my slides like like binder like binder

00:02:22,900 --> 00:02:27,210
and like but but but we heard this

00:02:25,870 --> 00:02:31,360
morning about Pangaea

00:02:27,210 --> 00:02:33,130
so what Roku does is combined it

00:02:31,360 --> 00:02:34,480
combines existing technologies such as

00:02:33,130 --> 00:02:36,370
some of the ones that I've listed here

00:02:34,480 --> 00:02:38,530
and new technologies to provide a

00:02:36,370 --> 00:02:43,510
one-stop shop for complete data science

00:02:38,530 --> 00:02:45,130
process so as I said I'm from Swiss day

00:02:43,510 --> 00:02:46,750
design center I guess most of you are

00:02:45,130 --> 00:02:49,150
not from Switzerland so you might not

00:02:46,750 --> 00:02:50,500
have heard about us so I will first talk

00:02:49,150 --> 00:02:52,870
a little bit about what the Swiss data

00:02:50,500 --> 00:02:56,880
science center is after that I will talk

00:02:52,870 --> 00:02:56,880
to you about the platform itself and

00:02:57,690 --> 00:03:01,210
sorry I have it's a bit difficult to be

00:02:59,830 --> 00:03:04,240
talking in the microphone and also

00:03:01,210 --> 00:03:09,400
looking on my slides and after that I

00:03:04,240 --> 00:03:11,050
will just conclude the whole talk so the

00:03:09,400 --> 00:03:12,490
Swiss data Science Center is a national

00:03:11,050 --> 00:03:14,140
project in Switzerland it's a

00:03:12,490 --> 00:03:15,970
collaboration between the two biggest

00:03:14,140 --> 00:03:18,670
technical universities in Switzerland

00:03:15,970 --> 00:03:20,020
the EPFL in Lausanne and some of you

00:03:18,670 --> 00:03:24,040
might know that because that's rascal I

00:03:20,020 --> 00:03:26,890
was developed and ETH century and so we

00:03:24,040 --> 00:03:28,780
as you see is like a start-up within the

00:03:26,890 --> 00:03:31,420
University so we are government

00:03:28,780 --> 00:03:33,730
employees but we're not a lab in the

00:03:31,420 --> 00:03:37,750
sense that we do not have PhD students

00:03:33,730 --> 00:03:42,400
and we are also not driven by profit so

00:03:37,750 --> 00:03:44,080
we have a the ideas that we can sustain

00:03:42,400 --> 00:03:46,570
ourselves so to say but right now we're

00:03:44,080 --> 00:03:50,020
working from some government grants the

00:03:46,570 --> 00:03:51,730
as you see started in 2017 I myself have

00:03:50,020 --> 00:03:54,130
been part of it for about one year now

00:03:51,730 --> 00:03:55,030
and currently there are 25 people

00:03:54,130 --> 00:03:57,310
working there

00:03:55,030 --> 00:03:59,500
we have several software engineers we

00:03:57,310 --> 00:04:02,350
have data scientists and there are some

00:03:59,500 --> 00:04:05,050
people that are doing other stuff like

00:04:02,350 --> 00:04:07,989
management and administration so the

00:04:05,050 --> 00:04:10,780
mission of SES is basically to promote

00:04:07,989 --> 00:04:12,910
open data science and especially in

00:04:10,780 --> 00:04:16,570
Switzerland data science started to come

00:04:12,910 --> 00:04:18,600
up but it's not really very well adopted

00:04:16,570 --> 00:04:21,400
everywhere and part of our mission is to

00:04:18,600 --> 00:04:23,650
help with this adoption and we do that

00:04:21,400 --> 00:04:26,470
by being involved in projects both from

00:04:23,650 --> 00:04:28,570
the ETH domain and academic projects and

00:04:26,470 --> 00:04:32,440
in industrial projects and that

00:04:28,570 --> 00:04:33,820
also beyond Switzerland and the second

00:04:32,440 --> 00:04:36,310
part of that is that we are developing

00:04:33,820 --> 00:04:41,050
the platform rankle and that is what my

00:04:36,310 --> 00:04:43,870
talk is about and as you see kind of

00:04:41,050 --> 00:04:46,000
places itself in the middle so on the

00:04:43,870 --> 00:04:47,020
one hand you have the basic research and

00:04:46,000 --> 00:04:49,750
data science so that's really

00:04:47,020 --> 00:04:53,320
development of code of machine learning

00:04:49,750 --> 00:04:57,490
techniques of you know work on data

00:04:53,320 --> 00:04:59,560
privacy and security and on the other

00:04:57,490 --> 00:05:02,010
hand you have the domain expertise so

00:04:59,560 --> 00:05:04,720
people in companies they might have very

00:05:02,010 --> 00:05:06,190
extensive knowledge of manufacturing

00:05:04,720 --> 00:05:08,530
process and people that work in

00:05:06,190 --> 00:05:12,520
environmental sciences they they know

00:05:08,530 --> 00:05:16,930
exactly how the processes work in their

00:05:12,520 --> 00:05:18,370
in their domain and then in between that

00:05:16,930 --> 00:05:20,170
there is the Applied Research or the

00:05:18,370 --> 00:05:21,790
application of these machine learning

00:05:20,170 --> 00:05:23,860
techniques of these statistical methods

00:05:21,790 --> 00:05:28,360
on this domain science and that is where

00:05:23,860 --> 00:05:32,890
as CSC places itself so we are trying to

00:05:28,360 --> 00:05:34,870
interface between and as I said our

00:05:32,890 --> 00:05:36,760
mission is really to help with the

00:05:34,870 --> 00:05:38,620
adoption of data science and machine

00:05:36,760 --> 00:05:40,720
learning techniques in academic

00:05:38,620 --> 00:05:44,020
community and the industrial sector so

00:05:40,720 --> 00:05:45,550
we do so the academic community what we

00:05:44,020 --> 00:05:48,430
do is that we have a call for projects

00:05:45,550 --> 00:05:50,020
occasionally and then a lab can apply to

00:05:48,430 --> 00:05:51,790
work with us because we really want to

00:05:50,020 --> 00:05:53,410
have a collaboration we don't just want

00:05:51,790 --> 00:05:55,180
to have send the data scientist out for

00:05:53,410 --> 00:05:56,980
three months solve the problem and

00:05:55,180 --> 00:06:03,970
that's that we really want to have a

00:05:56,980 --> 00:06:05,290
sort of sustained collaboration so let's

00:06:03,970 --> 00:06:05,730
talk about records probably what you're

00:06:05,290 --> 00:06:08,050
here for

00:06:05,730 --> 00:06:09,670
first of all talk to you a bit about how

00:06:08,050 --> 00:06:11,470
we envision the renkel because it is a

00:06:09,670 --> 00:06:14,230
platform in progress it's a platform in

00:06:11,470 --> 00:06:18,310
development it's not it's not completely

00:06:14,230 --> 00:06:19,750
done yet I'll be honest and I will talk

00:06:18,310 --> 00:06:22,000
a little bit about the technical details

00:06:19,750 --> 00:06:23,410
and because I'm not brave enough to do a

00:06:22,000 --> 00:06:24,910
demo I will show you how you can

00:06:23,410 --> 00:06:28,900
interact with the platform I'm not going

00:06:24,910 --> 00:06:31,210
to like do the demo and then I will tell

00:06:28,900 --> 00:06:35,410
you what's the next pieces which will be

00:06:31,210 --> 00:06:37,930
coming so Renko is actually not a Swiss

00:06:35,410 --> 00:06:41,650
word surprised it's a Japanese word and

00:06:37,930 --> 00:06:42,220
it is a form of of poetry so what

00:06:41,650 --> 00:06:44,500
happens

00:06:42,220 --> 00:06:46,720
if in this idea of collaborative poetry

00:06:44,500 --> 00:06:48,850
is that each poet writes a stanza or

00:06:46,720 --> 00:06:50,500
coup in this case and which are all

00:06:48,850 --> 00:06:54,280
combined together to create a beautiful

00:06:50,500 --> 00:06:55,870
poem and that's kind of how we see data

00:06:54,280 --> 00:06:58,630
science is this really collaborative

00:06:55,870 --> 00:07:04,540
effort to create a beautiful result

00:06:58,630 --> 00:07:08,410
basically so these are fine the five

00:07:04,540 --> 00:07:11,500
main like pillars so to say off of the

00:07:08,410 --> 00:07:13,150
Ranko platform so first off is that we

00:07:11,500 --> 00:07:15,940
want to create the means to make data

00:07:13,150 --> 00:07:17,620
science reproducible and I think that is

00:07:15,940 --> 00:07:19,650
something that we have heard of several

00:07:17,620 --> 00:07:22,150
in several talks already the fact that

00:07:19,650 --> 00:07:25,180
this is something that is often still

00:07:22,150 --> 00:07:27,910
missing in in many data science projects

00:07:25,180 --> 00:07:31,990
and what is also important is that we

00:07:27,910 --> 00:07:37,060
will be able to share and reuse results

00:07:31,990 --> 00:07:38,770
quote algorithms for for late for later

00:07:37,060 --> 00:07:42,040
use in different projects or for maybe

00:07:38,770 --> 00:07:44,320
rerunning your analysis and we really

00:07:42,040 --> 00:07:46,330
want to create an environment which is

00:07:44,320 --> 00:07:49,210
where it's easy to collaborate with

00:07:46,330 --> 00:07:50,710
others and then not just people of your

00:07:49,210 --> 00:07:53,010
own group of your own discipline but

00:07:50,710 --> 00:07:59,620
really have this multidisciplinary

00:07:53,010 --> 00:08:01,479
environment we want to be we want people

00:07:59,620 --> 00:08:04,900
to be able to search for data of the

00:08:01,479 --> 00:08:06,490
search for methods as well and lastly we

00:08:04,900 --> 00:08:07,930
are working on having a federated

00:08:06,490 --> 00:08:10,750
environment so that means that there is

00:08:07,930 --> 00:08:13,479
like several institutions which each

00:08:10,750 --> 00:08:15,520
have their own version of Ranko and they

00:08:13,479 --> 00:08:17,770
will have the freedom to say for example

00:08:15,520 --> 00:08:19,450
I don't want to have my complete

00:08:17,770 --> 00:08:21,010
computer available for everyone or I

00:08:19,450 --> 00:08:23,320
don't want my data to be available for

00:08:21,010 --> 00:08:25,300
everyone they can still have control and

00:08:23,320 --> 00:08:26,680
for many universities this is important

00:08:25,300 --> 00:08:27,820
but also for example for hospitals

00:08:26,680 --> 00:08:33,400
because they don't want to have

00:08:27,820 --> 00:08:36,490
everything freely available thank God so

00:08:33,400 --> 00:08:38,500
this is done basically by capturing the

00:08:36,490 --> 00:08:41,409
lineage and with the lineage I mean how

00:08:38,500 --> 00:08:43,680
a result was achieved so the lineage

00:08:41,409 --> 00:08:46,240
over data set is how it was produced and

00:08:43,680 --> 00:08:49,420
by capturing this when a moment that

00:08:46,240 --> 00:08:51,400
someone starts to use rank ooh we check

00:08:49,420 --> 00:08:54,040
we keep track of how they would achieve

00:08:51,400 --> 00:08:55,550
their results we record this and then

00:08:54,040 --> 00:08:57,830
exploit this later

00:08:55,550 --> 00:09:01,750
this is how we want to enable on these

00:08:57,830 --> 00:09:01,750
features that I just had shown you

00:09:05,649 --> 00:09:11,120
especially in science nowadays there is

00:09:08,149 --> 00:09:14,420
a lot of data available and this data is

00:09:11,120 --> 00:09:16,269
often not easy to combine with each

00:09:14,420 --> 00:09:18,440
other I mean even in the same field in

00:09:16,269 --> 00:09:19,640
astrophysics that probably like for

00:09:18,440 --> 00:09:21,320
example to talk that was given yesterday

00:09:19,640 --> 00:09:25,130
they were talking a little bit about

00:09:21,320 --> 00:09:26,450
this multi messenger approach to events

00:09:25,130 --> 00:09:28,399
for example and what happens is that you

00:09:26,450 --> 00:09:31,420
have data which is in different forms

00:09:28,399 --> 00:09:34,310
the fare principles were developed about

00:09:31,420 --> 00:09:36,890
about four years ago and with the idea

00:09:34,310 --> 00:09:40,459
of how can we describe data and situate

00:09:36,890 --> 00:09:43,820
it you can easily reuse them find them

00:09:40,459 --> 00:09:46,100
access them and combine them with each

00:09:43,820 --> 00:09:48,380
other so fare stands for findable

00:09:46,100 --> 00:09:51,890
accessible interoperable and reusable

00:09:48,380 --> 00:09:54,440
and I mean it kind of speaks for itself

00:09:51,890 --> 00:09:59,180
and the data which is stored in ranked

00:09:54,440 --> 00:10:07,220
who will be able to build a build up how

00:09:59,180 --> 00:10:09,200
do you say that it will be sorry we will

00:10:07,220 --> 00:10:11,180
enable the fare principles basically

00:10:09,200 --> 00:10:13,760
because the data which is saved in renko

00:10:11,180 --> 00:10:18,620
everything is tracked everything has

00:10:13,760 --> 00:10:21,350
been labeled with a proper metadata we

00:10:18,620 --> 00:10:23,120
will we actually provide api's for easy

00:10:21,350 --> 00:10:25,100
access of the data and of the code and

00:10:23,120 --> 00:10:27,110
the data is in a standard form so it's

00:10:25,100 --> 00:10:28,940
easily to rewrite both by machines and

00:10:27,110 --> 00:10:30,980
by people and because we have this

00:10:28,940 --> 00:10:33,200
lineage it's also possible for the data

00:10:30,980 --> 00:10:34,640
to be very easily reused and include

00:10:33,200 --> 00:10:40,370
this much more than that but it also

00:10:34,640 --> 00:10:44,480
complies to the fare principles so let's

00:10:40,370 --> 00:10:46,399
say you are a data scientist and you you

00:10:44,480 --> 00:10:48,350
get to work right so you start with the

00:10:46,399 --> 00:10:50,480
raw data you will often have to do some

00:10:48,350 --> 00:10:52,910
pre-processing for this and this will

00:10:50,480 --> 00:10:54,140
give you some process data and to get

00:10:52,910 --> 00:10:58,100
your result you might need some other

00:10:54,140 --> 00:10:59,480
data and all this is recorded in a

00:10:58,100 --> 00:11:02,529
knowledge graph and a knowledge graph is

00:10:59,480 --> 00:11:04,520
basically the database where all the

00:11:02,529 --> 00:11:06,350
everything is stored would happen to in

00:11:04,520 --> 00:11:08,149
Renko so that's a data that's a metadata

00:11:06,350 --> 00:11:08,939
that's the code everything is stored in

00:11:08,149 --> 00:11:11,639
a knowledge graph

00:11:08,939 --> 00:11:15,239
and because we record these steps they

00:11:11,639 --> 00:11:17,009
can be reused and be repeated we have a

00:11:15,239 --> 00:11:18,629
built-in version control we use git for

00:11:17,009 --> 00:11:21,809
this I'll talk about that later a bit

00:11:18,629 --> 00:11:23,699
more and we also enable the people that

00:11:21,809 --> 00:11:25,019
use Renko to very easily access the

00:11:23,699 --> 00:11:29,699
linear so that you can visually see

00:11:25,019 --> 00:11:32,939
where your data comes from and because

00:11:29,699 --> 00:11:36,929
we stored questions you can be masculine

00:11:32,939 --> 00:11:39,119
sir because we started the metadata and

00:11:36,929 --> 00:11:40,799
the algorithms afterwards it's also

00:11:39,119 --> 00:11:42,600
possible to search for them so you can

00:11:40,799 --> 00:11:46,109
search not just for the data for example

00:11:42,600 --> 00:11:47,789
I want to know if someone uses a Titanic

00:11:46,109 --> 00:11:49,709
data like to talk about a very favorite

00:11:47,789 --> 00:11:52,919
data set but we also want to enable

00:11:49,709 --> 00:11:55,679
people to search for algorithms patterns

00:11:52,919 --> 00:11:57,389
within relationships so for example did

00:11:55,679 --> 00:11:59,819
someone use this data set for this

00:11:57,389 --> 00:12:04,889
purpose this kind of stuff which would

00:11:59,819 --> 00:12:06,899
be very useful to have access to and as

00:12:04,889 --> 00:12:08,819
I said so we have the little from the

00:12:06,899 --> 00:12:10,769
beginning you have your data set you

00:12:08,819 --> 00:12:12,509
analyzed it and then you see for example

00:12:10,769 --> 00:12:13,919
you search around and you think oh you

00:12:12,509 --> 00:12:16,619
know what I wonder how this would

00:12:13,919 --> 00:12:18,689
interact with this other data set which

00:12:16,619 --> 00:12:21,149
I found and it's very easy then to

00:12:18,689 --> 00:12:23,220
combine these things together but still

00:12:21,149 --> 00:12:28,859
preserve the lineage so you still know

00:12:23,220 --> 00:12:30,869
where it came from and that is really

00:12:28,859 --> 00:12:33,869
how we see the data science process

00:12:30,869 --> 00:12:38,309
working so this is the big theory around

00:12:33,869 --> 00:12:40,319
it now I want to talk a bit about the

00:12:38,309 --> 00:12:44,519
system aspect so how we have built the

00:12:40,319 --> 00:12:47,819
platform and we use some modular

00:12:44,519 --> 00:12:50,609
architecture so we want the components

00:12:47,819 --> 00:12:52,379
to be reused and we also wanted to be

00:12:50,609 --> 00:12:54,799
able for people to extend and build

00:12:52,379 --> 00:12:57,029
their own modules on the platform

00:12:54,799 --> 00:12:59,339
everything is open source of course and

00:12:57,029 --> 00:13:02,309
we use a lot of proven standards and

00:12:59,339 --> 00:13:04,799
technologies for example jupyter right

00:13:02,309 --> 00:13:07,439
now we have the platform is written in

00:13:04,799 --> 00:13:10,199
Java scripts for the front-end Scala and

00:13:07,439 --> 00:13:13,379
Python but we are we are basically

00:13:10,199 --> 00:13:16,470
language agnostic for us it's more like

00:13:13,379 --> 00:13:19,199
if someone wants to develop a piece of a

00:13:16,470 --> 00:13:20,759
module for our platform you can do that

00:13:19,199 --> 00:13:22,290
and go if you want it's just that right

00:13:20,759 --> 00:13:23,190
now we chose these languages

00:13:22,290 --> 00:13:27,540
because there's some ones that we were

00:13:23,190 --> 00:13:28,949
most comfortable with so as I said we

00:13:27,540 --> 00:13:32,730
use a lot of technologies that already

00:13:28,949 --> 00:13:34,380
existed to just get lap jupyter actually

00:13:32,730 --> 00:13:36,570
do fighter via now we are now switching

00:13:34,380 --> 00:13:38,940
to Jupiter lab but just didn't update

00:13:36,570 --> 00:13:41,880
the slide yet we also use two fighter

00:13:38,940 --> 00:13:45,839
hub we do our deployments with

00:13:41,880 --> 00:13:48,810
kubernetes and helm and we use the CDW

00:13:45,839 --> 00:13:54,839
common workflow language to track the

00:13:48,810 --> 00:13:57,259
the pipeline so this is a really

00:13:54,839 --> 00:14:00,750
high-level overview of the architecture

00:13:57,259 --> 00:14:02,699
we have the user facing parts which is

00:14:00,750 --> 00:14:04,829
the web UI and the CLI the command-line

00:14:02,699 --> 00:14:06,829
interface and that is something that I

00:14:04,829 --> 00:14:09,690
will demonstrate a little bit later

00:14:06,829 --> 00:14:11,519
these both talk to a gateway or a proxy

00:14:09,690 --> 00:14:14,899
because that's way we can very easily

00:14:11,519 --> 00:14:18,149
enforce authentication and authorization

00:14:14,899 --> 00:14:19,470
the way there's much more back-end

00:14:18,149 --> 00:14:20,250
services than this these are just the

00:14:19,470 --> 00:14:22,529
ones that I thought were most

00:14:20,250 --> 00:14:24,480
interesting to show we have a notebook

00:14:22,529 --> 00:14:28,170
surface we have to fight or how best I

00:14:24,480 --> 00:14:29,220
said and we have the kg which is the

00:14:28,170 --> 00:14:31,500
knowledge scrap so that's where

00:14:29,220 --> 00:14:34,290
everything is stored so the gateway the

00:14:31,500 --> 00:14:36,480
key cloak at lab everything produces

00:14:34,290 --> 00:14:41,430
events and these events are then piped

00:14:36,480 --> 00:14:43,560
to the knowledge graph and so for

00:14:41,430 --> 00:14:45,569
example if someone adds data with the

00:14:43,560 --> 00:14:48,480
metadata this information is sent

00:14:45,569 --> 00:14:50,399
through the the events queue and is

00:14:48,480 --> 00:14:52,649
recorded and afterwards other surfaces

00:14:50,399 --> 00:14:55,500
can then query again the knowledge graph

00:14:52,649 --> 00:14:57,360
to say for example do I have this data

00:14:55,500 --> 00:14:59,490
and the way we build the knowledge graph

00:14:57,360 --> 00:15:02,040
is that it's very easy to to clearly in

00:14:59,490 --> 00:15:04,260
a very fast way the graph itself is

00:15:02,040 --> 00:15:07,470
immutable so once it's there it's there

00:15:04,260 --> 00:15:09,930
and it contains both information on the

00:15:07,470 --> 00:15:12,990
data and metadata and also the other

00:15:09,930 --> 00:15:19,259
services can query it for for whatever

00:15:12,990 --> 00:15:24,120
reason that they want so now we go to

00:15:19,259 --> 00:15:25,620
the kind of interactive part so as I

00:15:24,120 --> 00:15:27,149
said there's two ways to interact with a

00:15:25,620 --> 00:15:29,670
platform you can either use the

00:15:27,149 --> 00:15:33,750
web-based front-end the UI and the CLI

00:15:29,670 --> 00:15:36,269
well let's start with the UI because it

00:15:33,750 --> 00:15:37,350
makes for better images and I do think

00:15:36,269 --> 00:15:39,120
that it's the thing that people will

00:15:37,350 --> 00:15:40,470
mostly use because this is really this

00:15:39,120 --> 00:15:42,959
the online component where people can

00:15:40,470 --> 00:15:44,670
really share and collaborate the CLI is

00:15:42,959 --> 00:15:45,899
something that's on your own machine so

00:15:44,670 --> 00:15:48,779
that is not a part where you would

00:15:45,899 --> 00:15:49,889
easily you can easily do with someone

00:15:48,779 --> 00:15:54,870
else unless they're physically next to

00:15:49,889 --> 00:15:57,059
you and we have jupyter integrated in

00:15:54,870 --> 00:15:59,459
like almost every part of the UI because

00:15:57,059 --> 00:16:04,459
we want people to be able to use their

00:15:59,459 --> 00:16:07,860
notebooks at any moment basically so

00:16:04,459 --> 00:16:10,740
okay so let's start you have logged in

00:16:07,860 --> 00:16:13,790
to rank ooh and you do have to log in

00:16:10,740 --> 00:16:16,949
and you want to create a new project

00:16:13,790 --> 00:16:18,689
very simple you can go to your list of

00:16:16,949 --> 00:16:20,160
projects and then you see all the

00:16:18,689 --> 00:16:23,339
projects which are publicly available

00:16:20,160 --> 00:16:26,309
for you right now we support just the

00:16:23,339 --> 00:16:30,000
gate lab public private projects but we

00:16:26,309 --> 00:16:32,699
do want to have more you know how would

00:16:30,000 --> 00:16:34,470
you say that delicate way of dealing

00:16:32,699 --> 00:16:36,240
with this later but for now we just have

00:16:34,470 --> 00:16:38,699
the public your project decided public

00:16:36,240 --> 00:16:40,199
or private that's it so I see a list of

00:16:38,699 --> 00:16:43,559
project that's my my colleagues made

00:16:40,199 --> 00:16:45,180
there's also one of myself and you can

00:16:43,559 --> 00:16:46,529
make a new project very easily you give

00:16:45,180 --> 00:16:49,949
it a title and a description this is

00:16:46,529 --> 00:16:52,019
also just how you make it in get lab and

00:16:49,949 --> 00:16:54,809
then you set the visibility either to

00:16:52,019 --> 00:16:59,279
public or private and then you have a

00:16:54,809 --> 00:17:01,019
new project and as you can see your

00:16:59,279 --> 00:17:03,409
project standard comes with some initial

00:17:01,019 --> 00:17:06,390
files so these are the gate files and

00:17:03,409 --> 00:17:08,339
metadata files there is also a docker

00:17:06,390 --> 00:17:10,890
file and a requirements file and these

00:17:08,339 --> 00:17:12,270
two files are used to make a custom

00:17:10,890 --> 00:17:14,010
notebook image and that is the little

00:17:12,270 --> 00:17:15,750
block you can see there because the

00:17:14,010 --> 00:17:18,809
moment you start you create your project

00:17:15,750 --> 00:17:20,699
a notebooks image is being built for you

00:17:18,809 --> 00:17:22,230
so that takes a little bit of time but

00:17:20,699 --> 00:17:27,209
then you have your very own custom

00:17:22,230 --> 00:17:31,110
notebook image and so let's say you have

00:17:27,209 --> 00:17:33,929
done already some some works or you have

00:17:31,110 --> 00:17:36,809
some files so you can see we divide

00:17:33,929 --> 00:17:38,580
the files which are there in data in

00:17:36,809 --> 00:17:40,590
notebooks and in workflow so for my

00:17:38,580 --> 00:17:42,299
notebooks I have some notebooks here and

00:17:40,590 --> 00:17:44,009
I'm sure that this is something other

00:17:42,299 --> 00:17:48,480
people may or may not have had as well

00:17:44,009 --> 00:17:50,340
but when I the time before jupyter lab

00:17:48,480 --> 00:17:52,919
so what would happen sometimes is that

00:17:50,340 --> 00:17:54,929
you have you make like ten notebooks and

00:17:52,919 --> 00:17:57,450
you're not very smart like me so you

00:17:54,929 --> 00:17:59,220
just give them very not too great names

00:17:57,450 --> 00:18:01,619
and then you have to open all your

00:17:59,220 --> 00:18:04,679
notebooks to find out what was the one

00:18:01,619 --> 00:18:07,289
you were searching for so what we build

00:18:04,679 --> 00:18:08,820
in is that if you look in your notebooks

00:18:07,289 --> 00:18:10,950
folder you just have a very quick

00:18:08,820 --> 00:18:13,499
preview of your actual notebook so you

00:18:10,950 --> 00:18:16,559
can't just be like I think I called this

00:18:13,499 --> 00:18:18,450
start analysis 1 to 5 or was it start

00:18:16,559 --> 00:18:20,159
analysis 1 to 6 I can just quickly

00:18:18,450 --> 00:18:22,799
compare and then if you have at least

00:18:20,159 --> 00:18:24,960
the thought to write the first cell

00:18:22,799 --> 00:18:26,700
properly then you know exactly which

00:18:24,960 --> 00:18:28,950
notebook you want to use and then you

00:18:26,700 --> 00:18:34,830
can launch the notebook from there and

00:18:28,950 --> 00:18:37,440
then you can use it so let's say you did

00:18:34,830 --> 00:18:38,789
some analysis in your notebook and you

00:18:37,440 --> 00:18:42,029
are like you're done for the day you're

00:18:38,789 --> 00:18:44,309
like ok time to go home what you do is

00:18:42,029 --> 00:18:46,860
that because we use the gate lab as a

00:18:44,309 --> 00:18:48,869
back-end back-end you can commit and

00:18:46,860 --> 00:18:51,179
push your changes after saving your

00:18:48,869 --> 00:18:54,720
notebook then you go back to the renkel

00:18:51,179 --> 00:18:56,789
UI and you see this sign which says do

00:18:54,720 --> 00:19:00,570
you want to create a change so right now

00:18:56,789 --> 00:19:03,179
we only support one branch in basically

00:19:00,570 --> 00:19:04,830
mean get left of course support many

00:19:03,179 --> 00:19:07,769
branches but for now we just have this

00:19:04,830 --> 00:19:09,240
idea of you have one branch and every

00:19:07,769 --> 00:19:10,919
change you make that's pushed to this

00:19:09,240 --> 00:19:12,419
master branch and as many of you know

00:19:10,919 --> 00:19:14,549
it's a good practice to make sure that

00:19:12,419 --> 00:19:16,110
people don't push directly to the master

00:19:14,549 --> 00:19:18,450
branch but they make a much request and

00:19:16,110 --> 00:19:20,220
that is basically what happens here so

00:19:18,450 --> 00:19:23,249
you when you commit your code it's put

00:19:20,220 --> 00:19:25,710
on a separate branch and then this

00:19:23,249 --> 00:19:31,259
prompts you to say like you want to make

00:19:25,710 --> 00:19:32,970
a change here you can see preview and

00:19:31,259 --> 00:19:34,590
you can see the diff so the differences

00:19:32,970 --> 00:19:37,679
between your notebooks and it's it's a

00:19:34,590 --> 00:19:40,110
very visual over overview well in this

00:19:37,679 --> 00:19:41,970
case that I was very lucky because I am

00:19:40,110 --> 00:19:43,619
i don't have merge conflict so I can

00:19:41,970 --> 00:19:45,020
merge it directly that's your useful

00:19:43,619 --> 00:19:47,450
what happens if you

00:19:45,020 --> 00:19:49,370
do have merged conflicts right now we

00:19:47,450 --> 00:19:52,280
still need you to go to get lab to solve

00:19:49,370 --> 00:19:53,950
your merge conflicts but in this case it

00:19:52,280 --> 00:19:59,660
was okay so you can just merge and

00:19:53,950 --> 00:20:03,320
everything's okay as I said before we

00:19:59,660 --> 00:20:07,520
are so the idea of the the collaborative

00:20:03,320 --> 00:20:11,090
poem is that you use coos to to create

00:20:07,520 --> 00:20:13,670
your stanzas and we have these also in

00:20:11,090 --> 00:20:15,440
our project in our in the records the

00:20:13,670 --> 00:20:17,990
COO is like an extension of a gitlab

00:20:15,440 --> 00:20:21,110
issue so it's more than just something

00:20:17,990 --> 00:20:26,750
you would use to say hey for the book

00:20:21,110 --> 00:20:28,580
don't do that here for example one of my

00:20:26,750 --> 00:20:30,440
project I have a list of coos and

00:20:28,580 --> 00:20:31,910
they're like from me and another

00:20:30,440 --> 00:20:33,890
colleague that I bet you it into making

00:20:31,910 --> 00:20:36,200
a cool my project for the purpose of

00:20:33,890 --> 00:20:39,470
this presentation and you can ask

00:20:36,200 --> 00:20:42,290
questions and you can reply and what you

00:20:39,470 --> 00:20:44,600
can also do is that you can open and

00:20:42,290 --> 00:20:47,540
refer to notebooks from a COO itself so

00:20:44,600 --> 00:20:49,730
for example I have a question and I can

00:20:47,540 --> 00:20:55,640
directly copy paste my notebook in there

00:20:49,730 --> 00:20:57,500
and then launch it from there as well as

00:20:55,640 --> 00:20:59,990
I mentioned before we also have a small

00:20:57,500 --> 00:21:02,780
notebook surface and this links to

00:20:59,990 --> 00:21:05,270
potala to fighter hub with gitlab and

00:21:02,780 --> 00:21:08,030
what what happens is that every time you

00:21:05,270 --> 00:21:13,340
push to your project an image is being

00:21:08,030 --> 00:21:14,780
made built made from the docker file and

00:21:13,340 --> 00:21:17,420
the requirements file the project so

00:21:14,780 --> 00:21:20,420
every time you update it you have a new

00:21:17,420 --> 00:21:22,460
image and you can directly launch a

00:21:20,420 --> 00:21:25,610
jupyter server based on your project and

00:21:22,460 --> 00:21:27,260
your commit hash and you can basically

00:21:25,610 --> 00:21:30,080
retrieve the state of your project at

00:21:27,260 --> 00:21:32,900
any moment so you can just go back like

00:21:30,080 --> 00:21:35,810
three days and be like okay at this

00:21:32,900 --> 00:21:37,700
point it still works I launch it from

00:21:35,810 --> 00:21:39,980
there and then I can hopefully see the

00:21:37,700 --> 00:21:41,840
differences and then very easily okay

00:21:39,980 --> 00:21:43,220
oh yeah oh I forgot that import yeah

00:21:41,840 --> 00:21:49,190
that doesn't that's probably the problem

00:21:43,220 --> 00:21:51,040
why now the CLI so that's the offline

00:21:49,190 --> 00:21:54,110
component it actually also works online

00:21:51,040 --> 00:21:55,790
but this is the the benefit is it can be

00:21:54,110 --> 00:21:57,170
run without the full platform so do

00:21:55,790 --> 00:21:58,400
something do something you can install

00:21:57,170 --> 00:22:01,190
on your

00:21:58,400 --> 00:22:05,170
because it is it's on the pi PI registry

00:22:01,190 --> 00:22:08,780
and the CLI has had a slightly different

00:22:05,170 --> 00:22:10,220
evolution than the UI so this is for now

00:22:08,780 --> 00:22:13,100
you can only run the reproducible

00:22:10,220 --> 00:22:14,780
workflows on the CLI but they work

00:22:13,100 --> 00:22:17,750
together so you have a project in your

00:22:14,780 --> 00:22:23,360
CLI you can also push it to the UI okay

00:22:17,750 --> 00:22:27,350
the CLI has a very straightforward how

00:22:23,360 --> 00:22:29,240
do you say that it syntax there is much

00:22:27,350 --> 00:22:31,640
more to the CLI than just this because I

00:22:29,240 --> 00:22:34,280
mean I couldn't like write everything of

00:22:31,640 --> 00:22:36,170
it but so assuming you want to have a

00:22:34,280 --> 00:22:38,150
project you can very easily create a

00:22:36,170 --> 00:22:40,100
dataset and you call it my data because

00:22:38,150 --> 00:22:41,170
you're not very original you add a file

00:22:40,100 --> 00:22:44,210
to it

00:22:41,170 --> 00:22:47,059
and you can run an analysis on this

00:22:44,210 --> 00:22:49,670
Rinku run analysis on your data set and

00:22:47,059 --> 00:22:51,890
then you pipe that to an output and what

00:22:49,670 --> 00:22:54,200
you can do then is view the lineage of

00:22:51,890 --> 00:22:57,920
your output so you can see where it came

00:22:54,200 --> 00:22:59,780
from some other features which I didn't

00:22:57,920 --> 00:23:01,970
show here is that you can the moment you

00:22:59,780 --> 00:23:04,309
actually change your data set it

00:23:01,970 --> 00:23:09,380
automatically reruns your analysis

00:23:04,309 --> 00:23:11,540
creating a new output but here I just

00:23:09,380 --> 00:23:13,970
want to show like the very kind of basic

00:23:11,540 --> 00:23:17,660
steps so for example I have a dataset

00:23:13,970 --> 00:23:18,980
which is the Fermi threelac and I do an

00:23:17,660 --> 00:23:20,420
analysis which is I can do a grep

00:23:18,980 --> 00:23:22,880
command it's very basic

00:23:20,420 --> 00:23:26,390
I grab for a word which i think is going

00:23:22,880 --> 00:23:28,340
to be in there and it's f FS RQ and I

00:23:26,390 --> 00:23:30,500
pipe that to an output and I do the same

00:23:28,340 --> 00:23:34,760
thing for another word that I think

00:23:30,500 --> 00:23:37,480
that's probably in there and then

00:23:34,760 --> 00:23:40,940
afterwards I check for both of these the

00:23:37,480 --> 00:23:43,160
lineage so in this case for the for it's

00:23:40,940 --> 00:23:44,990
very simple it's the word there's this

00:23:43,160 --> 00:23:47,240
workflow which is automatically created

00:23:44,990 --> 00:23:50,690
and storing this dot Rinku slash

00:23:47,240 --> 00:23:52,070
workflow folder it has a very long hash

00:23:50,690 --> 00:23:54,140
and then it's called corrupt because

00:23:52,070 --> 00:23:56,030
they did a grab comments and it's a cwl

00:23:54,140 --> 00:23:59,330
fell so this is this common workflow

00:23:56,030 --> 00:24:03,410
language and then it shows that it came

00:23:59,330 --> 00:24:06,950
from this Fermi threelac now what you

00:24:03,410 --> 00:24:09,650
can do is use these outputs as input for

00:24:06,950 --> 00:24:12,440
a new pipeline so I now run an analysis

00:24:09,650 --> 00:24:14,150
which is called which is basically

00:24:12,440 --> 00:24:19,420
word count on both of the files that I

00:24:14,150 --> 00:24:22,460
made and I piped that to a new file and

00:24:19,420 --> 00:24:24,860
now you can see a bit better this IDE of

00:24:22,460 --> 00:24:27,350
the lineage so on top there is the word

00:24:24,860 --> 00:24:30,080
count file this is the new result the

00:24:27,350 --> 00:24:32,980
workflow which created that and I'm two

00:24:30,080 --> 00:24:35,150
times the workflows which created the

00:24:32,980 --> 00:24:37,520
intermediate files on going all the way

00:24:35,150 --> 00:24:42,020
back to the beginning this is not like

00:24:37,520 --> 00:24:43,580
super clear but push your project to the

00:24:42,020 --> 00:24:45,500
UI and then you get this much more

00:24:43,580 --> 00:24:46,970
clearer over you it's inverted by the

00:24:45,500 --> 00:24:49,100
way so now we start on the top with a

00:24:46,970 --> 00:24:51,770
data set you have the two workflow is

00:24:49,100 --> 00:24:54,440
creating the intermediate files there's

00:24:51,770 --> 00:24:56,240
a workflow which combines them and then

00:24:54,440 --> 00:24:57,950
you get this output I mean obviously if

00:24:56,240 --> 00:25:00,170
you have a lot of analysis this is going

00:24:57,950 --> 00:25:02,120
to become much larger than that but for

00:25:00,170 --> 00:25:05,180
the purposes of demonstrating it

00:25:02,120 --> 00:25:14,240
I used kind of a much more quicker

00:25:05,180 --> 00:25:18,380
easier analysis so that was already kind

00:25:14,240 --> 00:25:20,540
of but what we want what we have so

00:25:18,380 --> 00:25:23,710
there's still some diff in between so

00:25:20,540 --> 00:25:27,080
what's the next step for the SGC

00:25:23,710 --> 00:25:31,010
as I mentioned we now use the the get

00:25:27,080 --> 00:25:33,830
left public private projects for our for

00:25:31,010 --> 00:25:37,070
our security what we want to do is to

00:25:33,830 --> 00:25:39,340
create a bit more of a fine maced way of

00:25:37,070 --> 00:25:42,980
securing projects using access based

00:25:39,340 --> 00:25:45,050
attribute based access control and this

00:25:42,980 --> 00:25:48,350
is something that would allow for much

00:25:45,050 --> 00:25:50,570
more much more control for users so that

00:25:48,350 --> 00:25:52,430
they can say I want to have this part of

00:25:50,570 --> 00:25:55,070
my data which can be exposed in this

00:25:52,430 --> 00:25:56,480
part not for example we are working on

00:25:55,070 --> 00:25:57,950
the federated motifs is something that

00:25:56,480 --> 00:26:00,020
we don't have yet but there is a demand

00:25:57,950 --> 00:26:03,530
for it because we work with several

00:26:00,020 --> 00:26:05,300
institutions which would meet this as I

00:26:03,530 --> 00:26:07,610
mentioned the workflow execution right

00:26:05,300 --> 00:26:09,620
now we only have in the offline analysis

00:26:07,610 --> 00:26:10,670
this is going to be in the cloud and

00:26:09,620 --> 00:26:13,790
that's something that should be done

00:26:10,670 --> 00:26:16,460
pretty soon for the lineage we want to

00:26:13,790 --> 00:26:18,230
create better a better college II and

00:26:16,460 --> 00:26:20,810
metadata standards because right now we

00:26:18,230 --> 00:26:22,790
used our own but we want to see if we

00:26:20,810 --> 00:26:24,380
can standardize this and the graph

00:26:22,790 --> 00:26:26,570
search from

00:26:24,380 --> 00:26:28,010
charity is not exposed has been

00:26:26,570 --> 00:26:31,220
implemented but it's not exposed right

00:26:28,010 --> 00:26:34,040
now with some of our academic partners

00:26:31,220 --> 00:26:37,040
we are working on some plugins one of

00:26:34,040 --> 00:26:39,620
them being for recommender systems so

00:26:37,040 --> 00:26:41,770
what happens if I have a data set and I

00:26:39,620 --> 00:26:44,750
wonder what other people did with it or

00:26:41,770 --> 00:26:46,370
or and we work on data and code

00:26:44,750 --> 00:26:48,950
discovery as well and there are several

00:26:46,370 --> 00:26:50,480
other plugins that we we are working on

00:26:48,950 --> 00:26:56,420
and we hope other people will also

00:26:50,480 --> 00:27:00,440
contribute to so yeah these issues from

00:26:56,420 --> 00:27:02,600
the beginning in its complete form

00:27:00,440 --> 00:27:05,120
wrinkle should be able to basically

00:27:02,600 --> 00:27:06,230
resolve most of them because well you

00:27:05,120 --> 00:27:08,570
definitely know what a data for your

00:27:06,230 --> 00:27:11,090
player plot came from because it is all

00:27:08,570 --> 00:27:14,840
trapped in the lineage you can rerun

00:27:11,090 --> 00:27:17,120
your analysis with the new data and the

00:27:14,840 --> 00:27:18,320
reproducibility also allows you to see

00:27:17,120 --> 00:27:19,970
how someone else created the same

00:27:18,320 --> 00:27:21,530
results I mean this is all assuming that

00:27:19,970 --> 00:27:22,910
they were smart enough to use a tanker

00:27:21,530 --> 00:27:26,390
right I mean if they didn't and you

00:27:22,910 --> 00:27:28,490
still don't know anything with the

00:27:26,390 --> 00:27:29,990
federated mode when we have implemented

00:27:28,490 --> 00:27:32,600
that it should you should be able to

00:27:29,990 --> 00:27:35,750
have data in one place code in another

00:27:32,600 --> 00:27:39,910
place and combine them when the search

00:27:35,750 --> 00:27:39,910
function enabled you can search for

00:27:39,970 --> 00:27:45,050
relations like did someone ever train

00:27:42,530 --> 00:27:47,720
this model on this data or did this

00:27:45,050 --> 00:27:49,610
person use that data set and lastly

00:27:47,720 --> 00:27:51,830
because of the linear trees should also

00:27:49,610 --> 00:27:53,330
be able to see from the data that you

00:27:51,830 --> 00:27:57,050
created from the code that you created

00:27:53,330 --> 00:27:58,940
who has been using that so if you want

00:27:57,050 --> 00:28:01,250
to know more we have to read the docs

00:27:58,940 --> 00:28:02,630
you can look upon our code and judge us

00:28:01,250 --> 00:28:06,110
if you feel so inclined you could also

00:28:02,630 --> 00:28:07,430
notice the data science CH is our

00:28:06,110 --> 00:28:11,720
official page we talked a little bit

00:28:07,430 --> 00:28:15,050
about the platform and more a more

00:28:11,720 --> 00:28:18,140
fluent way probably and we have first

00:28:15,050 --> 00:28:19,970
steps if you are wanting to use franku

00:28:18,140 --> 00:28:22,370
and you can because we have a rank rule

00:28:19,970 --> 00:28:23,900
lab life you can go there make an

00:28:22,370 --> 00:28:27,860
account and you can start trying out

00:28:23,900 --> 00:28:29,900
rangu it is still we're still actively

00:28:27,860 --> 00:28:32,429
developing it so there might be points

00:28:29,900 --> 00:28:34,960
where things

00:28:32,429 --> 00:28:37,540
might not work but we were hoping that

00:28:34,960 --> 00:28:38,950
people can try it and maybe they can you

00:28:37,540 --> 00:28:40,420
know make an issue on our gate and say

00:28:38,950 --> 00:28:41,710
like hey I tried this and it broke

00:28:40,420 --> 00:28:44,170
completely send help

00:28:41,710 --> 00:28:46,950
and we are very yeah we hope that people

00:28:44,170 --> 00:28:58,270
want to use our platform and enjoy it

00:28:46,950 --> 00:29:00,929
thank you oh my so think I effect some

00:28:58,270 --> 00:29:00,929
time for questions

00:29:12,450 --> 00:29:15,700
[Music]

00:29:33,330 --> 00:29:39,130
yeah so right now we ask people to

00:29:37,450 --> 00:29:40,570
kindly clear their outputs before

00:29:39,130 --> 00:29:42,309
committing it because else you will

00:29:40,570 --> 00:29:44,040
definitely run into a merge conflicts

00:29:42,309 --> 00:29:46,720
yeah because the moment that you run it

00:29:44,040 --> 00:29:48,840
if you run it twice one cell then you

00:29:46,720 --> 00:29:51,610
all had these different things in front

00:29:48,840 --> 00:29:53,470
yeah right now we just ask people to

00:29:51,610 --> 00:29:56,020
just clear all the outputs before

00:29:53,470 --> 00:29:58,480
committing it I'm not sure if there are

00:29:56,020 --> 00:29:59,890
really ways to properly address that but

00:29:58,480 --> 00:30:02,700
that is definitely something we want to

00:29:59,890 --> 00:30:02,700
take into account

00:30:24,320 --> 00:30:28,919
I'm a freshman in the beginning

00:30:26,970 --> 00:30:31,799
imagining are you yeah that's the guy

00:30:28,919 --> 00:30:33,869
that invented asia paper yeah over there

00:30:31,799 --> 00:30:38,909
now is there to Raghu and I use back

00:30:33,869 --> 00:30:40,340
would you publish my next it would be a

00:30:38,909 --> 00:30:42,809
great honor

00:30:40,340 --> 00:30:46,830
well we want to work towards that right

00:30:42,809 --> 00:30:50,309
now we Sony ie but we have what we have

00:30:46,830 --> 00:30:52,739
is that if you have a dataset and

00:30:50,309 --> 00:30:54,269
workflow producing a result when you

00:30:52,739 --> 00:30:56,309
substitute your data set for another

00:30:54,269 --> 00:30:59,999
data set you can rerun the exact same

00:30:56,309 --> 00:31:03,059
workflow and get a new results we don't

00:30:59,999 --> 00:31:05,190
have automatic publishing yet but we do

00:31:03,059 --> 00:32:11,580
want to be able to help people with

00:31:05,190 --> 00:32:15,989
creating papers in also yeah we now the

00:32:11,580 --> 00:32:21,570
what I showed us to two pi to 2 pi lab

00:32:15,989 --> 00:32:23,159
so I I told my colleagues I'm going to

00:32:21,570 --> 00:32:25,549
give a presentation don't change

00:32:23,159 --> 00:32:25,549
anything

00:32:26,160 --> 00:32:47,790
it's a communications because we're in

00:32:28,320 --> 00:32:51,210
two different everything tracked because

00:32:47,790 --> 00:32:54,810
but not so that would that would be done

00:32:51,210 --> 00:32:56,310
in the in the metadata but I mean

00:32:54,810 --> 00:32:58,860
obviously what I show here is like this

00:32:56,310 --> 00:33:00,630
it's very this high-level overview and

00:32:58,860 --> 00:33:04,110
also what do you want to expose to

00:33:00,630 --> 00:33:07,140
people using it but yeah we track

00:33:04,110 --> 00:33:09,810
everything at all the versions I'm not

00:33:07,140 --> 00:33:36,360
sure if we will be able to expose

00:33:09,810 --> 00:33:37,770
everything yes the storage service is

00:33:36,360 --> 00:33:42,990
something that a colleague of mine has

00:33:37,770 --> 00:33:44,910
written and we we do have different

00:33:42,990 --> 00:33:46,950
backends that people can use like for

00:33:44,910 --> 00:33:48,510
right now we mostly use get lab but we

00:33:46,950 --> 00:33:52,440
also allow people to use for example

00:33:48,510 --> 00:33:56,810
over for their storage but we have kind

00:33:52,440 --> 00:33:56,810
of base it around the ID of the git LFS

00:34:29,230 --> 00:35:36,220
so it's also which is what you do

00:35:34,070 --> 00:35:39,470
because that's how we do this thing with

00:35:36,220 --> 00:35:43,630
with a notebook server that you can get

00:35:39,470 --> 00:35:43,630
your project back at any stage because

00:35:47,350 --> 00:35:53,890
if you would have your copper file and

00:35:50,630 --> 00:35:56,510
you want to use different leader I'm

00:35:53,890 --> 00:35:58,550
sure that there's a way to do digest

00:35:56,510 --> 00:36:01,090
it's not really news case if you

00:35:58,550 --> 00:36:01,090
considered

00:36:07,510 --> 00:36:15,010
but thanks and something that you should

00:36:08,770 --> 00:36:19,150
be doing um please okay well thank you

00:36:15,010 --> 00:36:21,730
so much and yeah I hope that you would

00:36:19,150 --> 00:36:24,810
if you want to give a look if you try to

00:36:21,730 --> 00:36:24,810
talk that form

00:36:27,630 --> 00:36:31,079

YouTube URL: https://www.youtube.com/watch?v=5kFhAAnv2D0


