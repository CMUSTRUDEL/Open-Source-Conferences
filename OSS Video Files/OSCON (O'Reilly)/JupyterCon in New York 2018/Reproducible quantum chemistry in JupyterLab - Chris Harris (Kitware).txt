Title: Reproducible quantum chemistry in JupyterLab - Chris Harris (Kitware)
Publication date: 2018-10-09
Playlist: JupyterCon in New York 2018
Description: 
	In silico prediction of chemical properties has seen vast improvements in both veracity and volume of data but is currently hamstrung by a lack of transparent, reproducible workflows coupled with environments for visualization and analysis. Chris Harris offers an overview of a platform that uses Jupyter notebooks to enable an end-to-end workflow from simulation setup to visualizing the results.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,219 --> 00:00:05,359
my name is Chris Harris and I'm here to

00:00:03,560 --> 00:00:09,410
talk to you about reproducible quantum

00:00:05,359 --> 00:00:11,450
chemistry in Jupiter lab so we're going

00:00:09,410 --> 00:00:13,429
to start off with a overview of what I'm

00:00:11,450 --> 00:00:15,139
going to cover in the presentation so

00:00:13,429 --> 00:00:16,910
we'll start with the scientific use case

00:00:15,139 --> 00:00:19,400
to provide the motivation for the work

00:00:16,910 --> 00:00:21,800
that we're doing here well then describe

00:00:19,400 --> 00:00:24,619
why we chose Jupiter lab as one of the

00:00:21,800 --> 00:00:27,410
core components of our platform to

00:00:24,619 --> 00:00:29,509
enable the scientific use case then our

00:00:27,410 --> 00:00:32,540
outline our overall approach in terms of

00:00:29,509 --> 00:00:35,960
design and implementation well then have

00:00:32,540 --> 00:00:37,309
a brief demo to provide some context so

00:00:35,960 --> 00:00:39,289
that we can then talk about the

00:00:37,309 --> 00:00:40,640
architectural components to support the

00:00:39,289 --> 00:00:43,340
underlying workflows that we're

00:00:40,640 --> 00:00:44,960
developing and then we'll discuss some

00:00:43,340 --> 00:00:46,430
deployments that we've done particularly

00:00:44,960 --> 00:00:48,829
a deployment at a national lab

00:00:46,430 --> 00:00:52,160
supercomputing center and then this is

00:00:48,829 --> 00:00:53,719
an ongoing project so we'll then by way

00:00:52,160 --> 00:00:55,250
of a conclusion we'll talk about some of

00:00:53,719 --> 00:00:59,210
the future work that we're going to do

00:00:55,250 --> 00:01:00,199
in the next couple of years so before I

00:00:59,210 --> 00:01:02,210
dive into the scientific

00:01:00,199 --> 00:01:04,460
esk so just briefly want to mention the

00:01:02,210 --> 00:01:05,930
project in the team so this work is

00:01:04,460 --> 00:01:08,720
supported by the Department of Energy

00:01:05,930 --> 00:01:10,940
through their SBIR program we completed

00:01:08,720 --> 00:01:12,560
a phase one last year so much of the

00:01:10,940 --> 00:01:16,790
work that we present here is from that

00:01:12,560 --> 00:01:18,440
phase one and we've we are just ramping

00:01:16,790 --> 00:01:22,580
up on a Phase two and so we have another

00:01:18,440 --> 00:01:24,950
two years of work left so the team the

00:01:22,580 --> 00:01:27,170
project is led by kitware and we have

00:01:24,950 --> 00:01:28,580
two collaborating institutions Berkeley

00:01:27,170 --> 00:01:30,770
National Lab and the University of

00:01:28,580 --> 00:01:33,440
Buffalo and they're providing much of

00:01:30,770 --> 00:01:36,110
the domain expertise in terms of quantum

00:01:33,440 --> 00:01:37,730
chemistry and machine learning and I'll

00:01:36,110 --> 00:01:40,820
also briefly want to mention the open

00:01:37,730 --> 00:01:43,940
chemistry project which is aim is to

00:01:40,820 --> 00:01:46,490
produce a set of open tooling to support

00:01:43,940 --> 00:01:50,680
the computational chemistry community

00:01:46,490 --> 00:01:50,680
and that's what this project is part of

00:01:51,880 --> 00:01:58,280
so quantum chemistry uses quantum

00:01:56,390 --> 00:02:00,560
mechanics to characterize chemical

00:01:58,280 --> 00:02:01,970
systems and then that involves the

00:02:00,560 --> 00:02:04,850
Schrodinger equation that describes

00:02:01,970 --> 00:02:07,850
physical systems that exhibit quantum

00:02:04,850 --> 00:02:10,490
effects now the equation can't be solved

00:02:07,850 --> 00:02:13,670
using analytical means for real-world

00:02:10,490 --> 00:02:14,660
systems so computational chemistry uses

00:02:13,670 --> 00:02:16,970
a set of approximate

00:02:14,660 --> 00:02:19,780
and numerical methods in order to

00:02:16,970 --> 00:02:22,670
simulate a chemical system in software

00:02:19,780 --> 00:02:23,870
now these techniques are computationally

00:02:22,670 --> 00:02:25,820
intensive so they require

00:02:23,870 --> 00:02:27,980
high-performance computing resources or

00:02:25,820 --> 00:02:29,960
HPC in order to be able to simulate

00:02:27,980 --> 00:02:33,170
large systems in a reasonable amount of

00:02:29,960 --> 00:02:35,030
time and so these techniques have seen

00:02:33,170 --> 00:02:37,010
vast improvements in both the veracity

00:02:35,030 --> 00:02:39,440
and volume of data that these techniques

00:02:37,010 --> 00:02:41,390
can produce but progress has been

00:02:39,440 --> 00:02:43,040
hampered by a lack of transparent

00:02:41,390 --> 00:02:45,590
reproducible workflows that use these

00:02:43,040 --> 00:02:47,420
computational codes and so there are a

00:02:45,590 --> 00:02:49,940
couple of issues the data management

00:02:47,420 --> 00:02:51,830
tends to be very ad hoc in terms of

00:02:49,940 --> 00:02:53,930
there being a lack of structured data

00:02:51,830 --> 00:02:55,790
management the appropriate metadata

00:02:53,930 --> 00:02:57,380
tends not to be stored with the outputs

00:02:55,790 --> 00:02:59,000
of these computational results so a lot

00:02:57,380 --> 00:03:01,040
of the value is lost because there's no

00:02:59,000 --> 00:03:03,650
context you don't know the versions of

00:03:01,040 --> 00:03:06,410
the particular quantum quantum code that

00:03:03,650 --> 00:03:08,270
you're using and the various input and

00:03:06,410 --> 00:03:09,950
parameters can be lost so what you'll

00:03:08,270 --> 00:03:12,650
find is data tends to be written to the

00:03:09,950 --> 00:03:14,030
file system of HPC system and then

00:03:12,650 --> 00:03:15,380
essentially it's lost because people

00:03:14,030 --> 00:03:18,950
simply don't know the contexts and they

00:03:15,380 --> 00:03:20,900
can't reuse it the computational codes

00:03:18,950 --> 00:03:22,700
themselves have associated complexity

00:03:20,900 --> 00:03:24,560
there's very little standardization in

00:03:22,700 --> 00:03:26,690
terms of the input and output formats

00:03:24,560 --> 00:03:28,850
and then there's the intricacies of the

00:03:26,690 --> 00:03:30,980
HPC systems themselves they have their

00:03:28,850 --> 00:03:32,720
own set of command line tools that you

00:03:30,980 --> 00:03:34,370
need to master in order to interact with

00:03:32,720 --> 00:03:37,160
them and they have their own scripting

00:03:34,370 --> 00:03:38,690
dialogues and even when you've actually

00:03:37,160 --> 00:03:40,160
produced some results using these

00:03:38,690 --> 00:03:42,220
quantum codes there's still a lack of

00:03:40,160 --> 00:03:44,270
integrated environments for

00:03:42,220 --> 00:03:47,209
visualization and analysis of the

00:03:44,270 --> 00:03:48,920
results so there's a real need for a

00:03:47,209 --> 00:03:51,320
platform that will enable end-to-end

00:03:48,920 --> 00:03:53,360
workflows right from simulation set up

00:03:51,320 --> 00:03:55,220
right through to analysis and

00:03:53,360 --> 00:03:57,770
visualization of the results and that's

00:03:55,220 --> 00:04:01,250
really the kind of key scientific use

00:03:57,770 --> 00:04:04,370
case that we're trying to support so I

00:04:01,250 --> 00:04:06,200
hope a platform which provide it enabled

00:04:04,370 --> 00:04:08,030
these workflows would kind of produce

00:04:06,200 --> 00:04:10,220
the cycle of knowledge discovery where

00:04:08,030 --> 00:04:11,930
scientists can share the results of

00:04:10,220 --> 00:04:13,730
their simulations they can search for

00:04:11,930 --> 00:04:16,310
existing simulations that are only been

00:04:13,730 --> 00:04:17,900
done they can the simulations were

00:04:16,310 --> 00:04:19,520
preserved with the provenance and the

00:04:17,900 --> 00:04:21,620
analytic steps that they've performed

00:04:19,520 --> 00:04:25,250
and so I hope to enable this like like

00:04:21,620 --> 00:04:26,810
nice cycle of knowledge discovery so why

00:04:25,250 --> 00:04:28,430
do we choose Jupiter as one of their key

00:04:26,810 --> 00:04:30,530
components to support our work

00:04:28,430 --> 00:04:31,669
flows well the notebook environment

00:04:30,530 --> 00:04:34,130
obviously provides the kind of

00:04:31,669 --> 00:04:37,009
interactive analysis that we needed to

00:04:34,130 --> 00:04:38,570
provide to support these workflows the

00:04:37,009 --> 00:04:39,590
notebook environment with its linear

00:04:38,570 --> 00:04:41,210
structure of cells

00:04:39,590 --> 00:04:43,220
obviously lends itself to codifying

00:04:41,210 --> 00:04:45,680
workflows and then much of the

00:04:43,220 --> 00:04:48,050
provenance is stored within the notebook

00:04:45,680 --> 00:04:49,280
files themselves which is an important

00:04:48,050 --> 00:04:51,680
thing to be able to reproduce these

00:04:49,280 --> 00:04:53,419
workflows it's also a familiar

00:04:51,680 --> 00:04:54,880
environment in the computational

00:04:53,419 --> 00:04:57,350
chemistry domain

00:04:54,880 --> 00:04:58,820
notebooks are clearly becoming the de

00:04:57,350 --> 00:05:01,520
facto standard for this sort of analysis

00:04:58,820 --> 00:05:03,139
and the language itself is also widely

00:05:01,520 --> 00:05:05,000
used within computational chemistry

00:05:03,139 --> 00:05:06,440
there's a whole set of libraries and

00:05:05,000 --> 00:05:08,539
packages that we would be able to

00:05:06,440 --> 00:05:11,599
leverage if we use Python as the key

00:05:08,539 --> 00:05:13,789
language to encode these workflows we

00:05:11,599 --> 00:05:15,110
understood that in order to produce this

00:05:13,789 --> 00:05:17,840
sort of platform to enable these

00:05:15,110 --> 00:05:20,570
workflows we need to extend the platform

00:05:17,840 --> 00:05:22,820
for the specific needs of our workflows

00:05:20,570 --> 00:05:24,080
and Jupiter in particular Jupiter layer

00:05:22,820 --> 00:05:26,060
which is the core technology we are

00:05:24,080 --> 00:05:28,400
using as a simple extension mechanism

00:05:26,060 --> 00:05:30,620
that allows us to develop these complex

00:05:28,400 --> 00:05:32,810
domain-specific visualizations that can

00:05:30,620 --> 00:05:34,820
then be viewed within the workflow

00:05:32,810 --> 00:05:36,860
environment and then of course it has a

00:05:34,820 --> 00:05:38,300
vibrant ecosystem and compute e that we

00:05:36,860 --> 00:05:41,240
really wanted to be part of and we

00:05:38,300 --> 00:05:44,360
wanted to build on the great work that

00:05:41,240 --> 00:05:45,919
other people have done and so we're

00:05:44,360 --> 00:05:48,340
really putting Jupiter and the open

00:05:45,919 --> 00:05:50,419
chemistry project at the core of this

00:05:48,340 --> 00:05:54,289
cycle of knowledge discovery that we

00:05:50,419 --> 00:05:55,639
want to be enabled in able to label so

00:05:54,289 --> 00:05:57,440
our overall approach was very

00:05:55,639 --> 00:05:59,750
data-centric the data is the most

00:05:57,440 --> 00:06:01,280
important part of this platform we

00:05:59,750 --> 00:06:03,530
wanted to make the data more available

00:06:01,280 --> 00:06:06,139
and not just to the those that initiated

00:06:03,530 --> 00:06:08,479
their quantum calculations but also to

00:06:06,139 --> 00:06:10,750
other users and so we wanted to

00:06:08,479 --> 00:06:13,789
basically derive more value from this

00:06:10,750 --> 00:06:16,099
valuable data essentially so we store

00:06:13,789 --> 00:06:18,470
started with a small but powerful data

00:06:16,099 --> 00:06:20,870
model and encapsulated in a data server

00:06:18,470 --> 00:06:23,840
and then we can serve that data through

00:06:20,870 --> 00:06:26,599
a language agnostic set of restful api

00:06:23,840 --> 00:06:29,030
and that opened us up to a wide variety

00:06:26,599 --> 00:06:31,490
of different environments from notebooks

00:06:29,030 --> 00:06:33,409
web applications command-line tools and

00:06:31,490 --> 00:06:35,060
desktop applications and it provides a

00:06:33,409 --> 00:06:36,710
nice third-party integration point

00:06:35,060 --> 00:06:38,770
people can write to these restful api

00:06:36,710 --> 00:06:40,700
eyes and then of course we're using

00:06:38,770 --> 00:06:42,920
Jupiter environment to do

00:06:40,700 --> 00:06:45,800
actual analysis the interactive analysis

00:06:42,920 --> 00:06:47,900
but we needed a mechanism to encode the

00:06:45,800 --> 00:06:51,080
actual steps that the scientists were

00:06:47,900 --> 00:06:53,750
performing and so with our collaborators

00:06:51,080 --> 00:06:55,880
we developed a domain-specific high -

00:06:53,750 --> 00:06:57,440
API high-level API there was really

00:06:55,880 --> 00:06:59,120
tailored to the sort of tasks that they

00:06:57,440 --> 00:07:00,860
were doing and that would be the

00:06:59,120 --> 00:07:02,960
language that would be used or the API

00:07:00,860 --> 00:07:05,810
that would be used to essentially codify

00:07:02,960 --> 00:07:08,420
the workflows and then we had a web

00:07:05,810 --> 00:07:10,160
application that provide much the nuts

00:07:08,420 --> 00:07:12,650
and bolts of like notebook management

00:07:10,160 --> 00:07:14,510
people could search notebooks it was the

00:07:12,650 --> 00:07:15,860
launching point for notebooks and then

00:07:14,510 --> 00:07:18,050
it provide access control and

00:07:15,860 --> 00:07:20,120
authentication and it also provides a

00:07:18,050 --> 00:07:21,200
nice mechanism to interact with the data

00:07:20,120 --> 00:07:23,240
when you're not in a notebook

00:07:21,200 --> 00:07:24,950
environment for example if you're in a

00:07:23,240 --> 00:07:27,740
limited form factor device such as a

00:07:24,950 --> 00:07:29,090
mobile phone then a notebook isn't a

00:07:27,740 --> 00:07:32,300
great environment in order to actually

00:07:29,090 --> 00:07:34,190
visualize or look at the data and so now

00:07:32,300 --> 00:07:36,950
we're going to switch to a brief demo by

00:07:34,190 --> 00:07:38,900
way of a screencast the main reason I'm

00:07:36,950 --> 00:07:41,500
doing a screencast for the live demo is

00:07:38,900 --> 00:07:43,730
that these computational jobs take

00:07:41,500 --> 00:07:45,800
several minutes to run even for like

00:07:43,730 --> 00:07:47,030
very small systems and so I wanted to be

00:07:45,800 --> 00:07:48,710
able to show the entire workflow

00:07:47,030 --> 00:07:50,600
including the actual computation itself

00:07:48,710 --> 00:07:54,590
so I've actually unedited the video so

00:07:50,600 --> 00:07:56,540
it speeds up time so we'll start by

00:07:54,590 --> 00:07:59,630
logging into the system and when you

00:07:56,540 --> 00:08:00,920
land within the system you essentially

00:07:59,630 --> 00:08:02,240
in your home directory and you have a

00:08:00,920 --> 00:08:04,640
list of the notebooks that you're

00:08:02,240 --> 00:08:07,340
actually working on and then we can

00:08:04,640 --> 00:08:08,780
select a particular notebook the one

00:08:07,340 --> 00:08:11,870
that we've preferred for this demo and

00:08:08,780 --> 00:08:13,490
then you'll be launched into the Jupiter

00:08:11,870 --> 00:08:17,180
lab environment which most of you should

00:08:13,490 --> 00:08:18,770
be familiar with and so the first thing

00:08:17,180 --> 00:08:19,910
we do within this notebook is we're

00:08:18,770 --> 00:08:22,640
going to actually import our high-level

00:08:19,910 --> 00:08:25,160
API and this is the starting point for

00:08:22,640 --> 00:08:26,660
essentially our investigation and then

00:08:25,160 --> 00:08:28,730
we're going to search for a particular

00:08:26,660 --> 00:08:31,640
structure in this case we're searching

00:08:28,730 --> 00:08:33,650
for aspirin and what the system does is

00:08:31,640 --> 00:08:35,990
it checks to see whether it already has

00:08:33,650 --> 00:08:37,910
that molecule in the data store if it

00:08:35,990 --> 00:08:39,650
does then it simply returns it but then

00:08:37,910 --> 00:08:41,840
we also have integration with some web

00:08:39,650 --> 00:08:44,930
services that can access online

00:08:41,840 --> 00:08:46,310
databases of particular structures and

00:08:44,930 --> 00:08:48,920
then what we can do is we can call

00:08:46,310 --> 00:08:50,660
structured show and it will show a rent

00:08:48,920 --> 00:08:51,980
3d rendering of the actual structure

00:08:50,660 --> 00:08:54,350
within the notebook environment self

00:08:51,980 --> 00:08:55,880
this is rendered with WebGL with a

00:08:54,350 --> 00:08:57,530
which go to be tkj s which is a

00:08:55,880 --> 00:08:59,780
open-source package that kit has also

00:08:57,530 --> 00:09:01,100
involved in and you can I interact with

00:08:59,780 --> 00:09:03,890
the molecule and adjust some of the

00:09:01,100 --> 00:09:04,970
visualization parameters and now what

00:09:03,890 --> 00:09:07,040
we're going to do is we're going to

00:09:04,970 --> 00:09:10,190
search for another molecule we're going

00:09:07,040 --> 00:09:12,230
to search for ethanol and we're actually

00:09:10,190 --> 00:09:13,640
going to use rather than the common name

00:09:12,230 --> 00:09:15,650
we're going to use something called an

00:09:13,640 --> 00:09:18,020
inch iki which is a commonly used

00:09:15,650 --> 00:09:20,240
chemical identifier and we sort support

00:09:18,020 --> 00:09:22,280
many mechanisms for searching for these

00:09:20,240 --> 00:09:24,440
particular structures and then once

00:09:22,280 --> 00:09:25,340
we've actually found the structure we're

00:09:24,440 --> 00:09:28,070
actually going to set up some

00:09:25,340 --> 00:09:30,830
calculation parameters and we're going

00:09:28,070 --> 00:09:33,080
to perform a geometry optimization on

00:09:30,830 --> 00:09:34,670
this particular structure and so what

00:09:33,080 --> 00:09:36,620
this will do again it's going to check

00:09:34,670 --> 00:09:38,060
do we have an optimization using these

00:09:36,620 --> 00:09:40,070
particular parameters which is

00:09:38,060 --> 00:09:41,840
essentially controlling how we're going

00:09:40,070 --> 00:09:46,040
to solve that trading equation that you

00:09:41,840 --> 00:09:47,540
saw in the in the use case and if it

00:09:46,040 --> 00:09:49,730
does then it's just going to return the

00:09:47,540 --> 00:09:51,260
optimized result that someone else has

00:09:49,730 --> 00:09:54,490
really run if it doesn't then it's going

00:09:51,260 --> 00:09:57,140
to trigger a job on a HPC system and

00:09:54,490 --> 00:09:58,820
rather than when we actually call to

00:09:57,140 --> 00:10:00,830
show the structure rather than showing

00:09:58,820 --> 00:10:03,230
the actual 3d visualization it's

00:10:00,830 --> 00:10:04,880
actually gonna throw it show a pending

00:10:03,230 --> 00:10:06,830
calculations we do it which you see here

00:10:04,880 --> 00:10:08,450
which shows the state of the job and

00:10:06,830 --> 00:10:10,220
this is where I've actually compressed

00:10:08,450 --> 00:10:12,170
time and this is actually running on an

00:10:10,220 --> 00:10:14,180
HPC system and you can monitor the

00:10:12,170 --> 00:10:16,670
status of it within the notebook itself

00:10:14,180 --> 00:10:18,110
and so it's now uploading ingesting the

00:10:16,670 --> 00:10:21,080
data into our system and it's now

00:10:18,110 --> 00:10:22,370
complete and so once the calculation is

00:10:21,080 --> 00:10:25,070
complete what we could do is we could

00:10:22,370 --> 00:10:26,960
just switch out to the 3d visualization

00:10:25,070 --> 00:10:28,490
of the actual structure but we kind of

00:10:26,960 --> 00:10:30,170
felt that was against the spirit of the

00:10:28,490 --> 00:10:32,330
notebook environment we felt that

00:10:30,170 --> 00:10:34,670
changing the output of a cell should

00:10:32,330 --> 00:10:36,350
really be as a result of direct user

00:10:34,670 --> 00:10:38,360
interaction not like by a third party

00:10:36,350 --> 00:10:40,490
and this is particularly important if

00:10:38,360 --> 00:10:42,380
you're running a calculation that takes

00:10:40,490 --> 00:10:43,430
many hours and then you come back to

00:10:42,380 --> 00:10:45,830
your notebook environment you really

00:10:43,430 --> 00:10:47,390
need the context that that calculation

00:10:45,830 --> 00:10:49,850
is finished and then you can actually

00:10:47,390 --> 00:10:51,830
view the visualization so we simply ask

00:10:49,850 --> 00:10:56,780
the user to re-execute the cell which

00:10:51,830 --> 00:11:00,380
we'll do here and then we have our

00:10:56,780 --> 00:11:02,270
freshly optimized structure of ethanol

00:11:00,380 --> 00:11:04,160
and now what we're going to do is we're

00:11:02,270 --> 00:11:05,750
going to dive down deeper into the data

00:11:04,160 --> 00:11:08,140
and actually view the electronic

00:11:05,750 --> 00:11:10,920
orbitals associated with

00:11:08,140 --> 00:11:13,360
structure and here we have an isosurface

00:11:10,920 --> 00:11:16,090
visualization of the electron clouds

00:11:13,360 --> 00:11:17,500
associated with the structure and we can

00:11:16,090 --> 00:11:19,870
adjust various things like the

00:11:17,500 --> 00:11:22,930
isosurface value but it's also possible

00:11:19,870 --> 00:11:26,290
to create a more realistic visualization

00:11:22,930 --> 00:11:28,150
using volume rendering that vtk jf also

00:11:26,290 --> 00:11:30,850
supports so we're going to switch to a

00:11:28,150 --> 00:11:32,440
volume rendering and then we're going to

00:11:30,850 --> 00:11:35,250
have to adjust the transfer function

00:11:32,440 --> 00:11:37,870
adjust the actual color map range and

00:11:35,250 --> 00:11:39,730
the transfer function itself so that we

00:11:37,870 --> 00:11:44,860
get a more realistic visualization of

00:11:39,730 --> 00:11:46,840
the structure and there we have kind of

00:11:44,860 --> 00:11:49,030
a better visualization of the actual

00:11:46,840 --> 00:11:50,740
electron structure itself and you'll

00:11:49,030 --> 00:11:52,450
notice within our notebooks we have this

00:11:50,740 --> 00:11:54,100
show method which basically provides

00:11:52,450 --> 00:11:56,290
some sort of 3d interactive

00:11:54,100 --> 00:11:58,630
visualization but where you see the show

00:11:56,290 --> 00:12:00,550
method the user can also call a method

00:11:58,630 --> 00:12:03,250
called URL and what that does is

00:12:00,550 --> 00:12:06,730
actually display displays an encoded URL

00:12:03,250 --> 00:12:08,830
which points to the same data and the

00:12:06,730 --> 00:12:10,930
same initial visualization conditions

00:12:08,830 --> 00:12:13,480
and so you'll see in the cell we're

00:12:10,930 --> 00:12:18,400
going to be able to call URL on this

00:12:13,480 --> 00:12:20,170
particular orbitals and so we now have

00:12:18,400 --> 00:12:22,360
this encoded URL and that's a nice

00:12:20,170 --> 00:12:24,160
mechanism to share with other users and

00:12:22,360 --> 00:12:26,200
so if we click if they click on the

00:12:24,160 --> 00:12:27,790
particular URL then it will open the

00:12:26,200 --> 00:12:30,040
same data in the same initial

00:12:27,790 --> 00:12:31,540
visualization within the single page

00:12:30,040 --> 00:12:33,730
application and so this could be then

00:12:31,540 --> 00:12:35,230
shared on a mobile phone for example and

00:12:33,730 --> 00:12:36,850
this is using the same underlying data

00:12:35,230 --> 00:12:39,430
and actually using the same underlying

00:12:36,850 --> 00:12:40,990
widgets and you notice down here on the

00:12:39,430 --> 00:12:43,660
right-hand side there's a little icon

00:12:40,990 --> 00:12:45,670
and that's actually a link back to the

00:12:43,660 --> 00:12:47,980
notebook that produced this data so you

00:12:45,670 --> 00:12:49,840
can see the actual notebook when it was

00:12:47,980 --> 00:12:51,520
created and if you click on it you

00:12:49,840 --> 00:12:53,890
actually get a static view of the

00:12:51,520 --> 00:12:56,170
notebook itself we're using MB convert

00:12:53,890 --> 00:12:59,340
to actually take snapshots of the of the

00:12:56,170 --> 00:13:01,660
notebooks when the data was created it

00:12:59,340 --> 00:13:02,830
provides a nice cross linking between

00:13:01,660 --> 00:13:05,860
these kind of two complementary

00:13:02,830 --> 00:13:08,050
environments so we'll switch back to the

00:13:05,860 --> 00:13:10,510
notebook environment and now we're going

00:13:08,050 --> 00:13:11,710
to do an ad if uhrin type of computation

00:13:10,510 --> 00:13:14,740
and we're going to do a frequency

00:13:11,710 --> 00:13:16,810
analysis on our particular structure and

00:13:14,740 --> 00:13:20,620
so again it's going to fire off this job

00:13:16,810 --> 00:13:21,760
running on this from a HPC system and it

00:13:20,620 --> 00:13:26,800
goes through the different state

00:13:21,760 --> 00:13:28,090
it's now running a compressing time and

00:13:26,800 --> 00:13:29,650
it's now complete and so we can

00:13:28,090 --> 00:13:31,120
re-execute this cell and this is

00:13:29,650 --> 00:13:33,730
provides a more interactive

00:13:31,120 --> 00:13:36,070
visualization it's like split view on

00:13:33,730 --> 00:13:38,830
the right hand side we have a chart that

00:13:36,070 --> 00:13:41,020
shows the actual frequencies and their

00:13:38,830 --> 00:13:43,030
intensities and then on the left hand

00:13:41,020 --> 00:13:44,890
side we actually can provide an

00:13:43,030 --> 00:13:46,690
animation in three dimensions of the

00:13:44,890 --> 00:13:49,180
actual vibrational mode that we're

00:13:46,690 --> 00:13:51,220
particularly a Witcher is selecting at

00:13:49,180 --> 00:13:56,080
the time so it looks a little bit like a

00:13:51,220 --> 00:13:57,370
dog and so the final analysis that we're

00:13:56,080 --> 00:13:59,020
going to do within this note this is

00:13:57,370 --> 00:14:00,490
something called a free energy analysis

00:13:59,020 --> 00:14:02,560
which is basically we're going to set up

00:14:00,490 --> 00:14:04,720
a set of equations and we're going to

00:14:02,560 --> 00:14:06,730
find out how much energy is released by

00:14:04,720 --> 00:14:09,370
a reaction the reaction in these

00:14:06,730 --> 00:14:11,350
equations and so what we'll do is we

00:14:09,370 --> 00:14:13,210
actually first of all set our set of

00:14:11,350 --> 00:14:16,360
equations and we're going to use simple

00:14:13,210 --> 00:14:17,980
Python templating and so we now have our

00:14:16,360 --> 00:14:20,290
set of equations within our notebook

00:14:17,980 --> 00:14:22,510
cell and in order to do the free energy

00:14:20,290 --> 00:14:24,280
calculations calculation what we need to

00:14:22,510 --> 00:14:26,950
do is we need an energy level associated

00:14:24,280 --> 00:14:29,200
with each each of the unique reactants

00:14:26,950 --> 00:14:32,740
within that set of equations now there's

00:14:29,200 --> 00:14:34,990
actually eight unique react reactants

00:14:32,740 --> 00:14:37,060
within that set of equations and so when

00:14:34,990 --> 00:14:40,000
we call this high level method show free

00:14:37,060 --> 00:14:41,170
energies for the my reactions then the

00:14:40,000 --> 00:14:43,660
system is going to have to fire off

00:14:41,170 --> 00:14:44,500
eight jobs on our HPC resource and so

00:14:43,660 --> 00:14:45,730
this is where it's particularly

00:14:44,500 --> 00:14:47,170
important that we speed up time because

00:14:45,730 --> 00:14:49,330
this will take ten to fifteen minutes

00:14:47,170 --> 00:14:50,710
for all these jobs to complete and so

00:14:49,330 --> 00:14:52,480
there we're now running and going

00:14:50,710 --> 00:14:54,850
through that uploading and now they're

00:14:52,480 --> 00:14:57,970
complete and so we can now reacts acute

00:14:54,850 --> 00:14:59,590
this and we'll see a simple infovis

00:14:57,970 --> 00:15:03,240
chart showing the free energies

00:14:59,590 --> 00:15:06,370
associated with our simple set set of

00:15:03,240 --> 00:15:09,340
reactions so let's switch back to the

00:15:06,370 --> 00:15:11,440
slides themselves so I hope that that's

00:15:09,340 --> 00:15:13,210
provided some context that we can then

00:15:11,440 --> 00:15:15,280
discuss the architecture the key

00:15:13,210 --> 00:15:17,620
takeaway from the demo should be that a

00:15:15,280 --> 00:15:20,140
no point within interrupt doing the

00:15:17,620 --> 00:15:22,140
analysis were we explicitly saying I

00:15:20,140 --> 00:15:24,550
want to run this particular

00:15:22,140 --> 00:15:26,590
computational job on this patil HPC

00:15:24,550 --> 00:15:29,080
resource it was much more driven by the

00:15:26,590 --> 00:15:30,670
data itself we want to get this off to

00:15:29,080 --> 00:15:32,500
my structure please give me up to my

00:15:30,670 --> 00:15:35,340
structure and if it wasn't there then we

00:15:32,500 --> 00:15:35,340
would initiate a job

00:15:35,580 --> 00:15:40,710
so these computational codes have a wide

00:15:38,700 --> 00:15:42,600
variety of outputs and the outputs tend

00:15:40,710 --> 00:15:44,070
to be non-standard or even non

00:15:42,600 --> 00:15:47,820
structured you can often find yourself

00:15:44,070 --> 00:15:51,000
parsing like a Fortran log file and so

00:15:47,820 --> 00:15:52,980
we needed a standard or a normalized

00:15:51,000 --> 00:15:56,160
form that we could bring this disparate

00:15:52,980 --> 00:15:58,020
set of outputs into a single normalized

00:15:56,160 --> 00:16:01,620
form that can be then curated and stored

00:15:58,020 --> 00:16:02,670
and through the past few years the open

00:16:01,620 --> 00:16:04,110
chemistry project and the wider

00:16:02,670 --> 00:16:06,360
community has been developing the

00:16:04,110 --> 00:16:08,820
standard called chemical Jason which is

00:16:06,360 --> 00:16:11,730
a simple Jason standard for representing

00:16:08,820 --> 00:16:13,500
chemical information it can store things

00:16:11,730 --> 00:16:15,660
like the structure information the

00:16:13,500 --> 00:16:17,610
geometry the various chemical chemical

00:16:15,660 --> 00:16:19,770
identifier so you can look up the

00:16:17,610 --> 00:16:21,420
particular structures and then they can

00:16:19,770 --> 00:16:24,300
prior to also store things like

00:16:21,420 --> 00:16:27,510
properties like melting points atomic

00:16:24,300 --> 00:16:28,980
mass for example and so it before I the

00:16:27,510 --> 00:16:31,380
nice thing about Jason is it's an

00:16:28,980 --> 00:16:33,450
efficient way of representing this data

00:16:31,380 --> 00:16:34,860
and it fits nicely with the stack the

00:16:33,450 --> 00:16:36,600
web stack and also the Python

00:16:34,860 --> 00:16:38,910
environment and then it also can be

00:16:36,600 --> 00:16:41,040
stored efficiently but in a binary form

00:16:38,910 --> 00:16:42,720
because we're actually using MongoDB as

00:16:41,040 --> 00:16:44,310
our kind of back-end data store and

00:16:42,720 --> 00:16:46,380
there's actually some moves in the

00:16:44,310 --> 00:16:49,080
community Molesey are pushing towards

00:16:46,380 --> 00:16:51,900
making it a real standard within the

00:16:49,080 --> 00:16:54,390
community but as well as supporting this

00:16:51,900 --> 00:16:57,090
kind of normalized form we also wanted

00:16:54,390 --> 00:16:58,530
to be able to export the data in other

00:16:57,090 --> 00:17:01,170
formats that already exist out there

00:16:58,530 --> 00:17:03,450
there's existing xml-based formats for

00:17:01,170 --> 00:17:05,640
example and so we provide restful

00:17:03,450 --> 00:17:07,830
endpoints for people to export in kind

00:17:05,640 --> 00:17:09,420
of standard formats and that facilitates

00:17:07,830 --> 00:17:11,040
integration and prevents us kind of

00:17:09,420 --> 00:17:15,209
locking in this valuable data to our

00:17:11,040 --> 00:17:16,740
particular format and so in terms of a

00:17:15,209 --> 00:17:18,750
data management system we're using

00:17:16,740 --> 00:17:20,100
something called Gerda and Gerda's an

00:17:18,750 --> 00:17:22,860
open source project that kit was

00:17:20,100 --> 00:17:24,839
involved in and the idea behind it is it

00:17:22,860 --> 00:17:27,030
allows you to quickly and easily build

00:17:24,839 --> 00:17:28,440
data intensive web applications so

00:17:27,030 --> 00:17:30,570
provides some of the nuts and bolts

00:17:28,440 --> 00:17:33,570
things like authorization management

00:17:30,570 --> 00:17:35,670
user management and data storage and

00:17:33,570 --> 00:17:37,620
dissemination and so it can get you up

00:17:35,670 --> 00:17:40,530
and running very quickly and it can also

00:17:37,620 --> 00:17:42,090
be extended using a set of plugins so

00:17:40,530 --> 00:17:44,190
you can develop plugins to add your own

00:17:42,090 --> 00:17:46,740
data models and that's exactly what we

00:17:44,190 --> 00:17:48,600
did for our platform we had added data

00:17:46,740 --> 00:17:49,380
models for things like calculations and

00:17:48,600 --> 00:17:50,610
structures

00:17:49,380 --> 00:17:54,750
and then they can be served through

00:17:50,610 --> 00:17:55,890
these restful endpoints so in the

00:17:54,750 --> 00:17:58,679
demonstration you saw these very

00:17:55,890 --> 00:18:01,410
high-level API calls like optimize and

00:17:58,679 --> 00:18:03,179
frequencies and we're firing out for HPC

00:18:01,410 --> 00:18:05,700
jobs and so what's involved in actually

00:18:03,179 --> 00:18:07,140
getting these jobs running so the first

00:18:05,700 --> 00:18:09,150
step is something called input

00:18:07,140 --> 00:18:11,490
generation which is actually where you

00:18:09,150 --> 00:18:13,860
generate the file that will control the

00:18:11,490 --> 00:18:15,600
actual computational code and the

00:18:13,860 --> 00:18:16,799
format's of these are very specific to

00:18:15,600 --> 00:18:19,470
particular codes and they're often

00:18:16,799 --> 00:18:21,330
pretty esoteric and it controls things

00:18:19,470 --> 00:18:24,179
like the theory and initial conditions

00:18:21,330 --> 00:18:26,429
and so once you have that input deck you

00:18:24,179 --> 00:18:28,530
can then move it on to your HPC resource

00:18:26,429 --> 00:18:30,090
along with the data now these resources

00:18:28,530 --> 00:18:31,470
tend to be remote they're the sort of

00:18:30,090 --> 00:18:33,030
thing that would be at academic

00:18:31,470 --> 00:18:34,080
institution or a national lab it's not

00:18:33,030 --> 00:18:35,880
the sort of thing that you'd have under

00:18:34,080 --> 00:18:38,070
your desk and so there's a data transfer

00:18:35,880 --> 00:18:41,030
and then you have to generate something

00:18:38,070 --> 00:18:43,950
called a submission script and this is

00:18:41,030 --> 00:18:45,780
basically tells the scheduler which is

00:18:43,950 --> 00:18:48,270
like the gatekeeper of the HPC resource

00:18:45,780 --> 00:18:50,520
the particular program that you want to

00:18:48,270 --> 00:18:51,900
run the particular set of nodes that you

00:18:50,520 --> 00:18:53,340
want to run it on the types of knows

00:18:51,900 --> 00:18:55,080
maybe the amount of memory and then you

00:18:53,340 --> 00:18:56,669
might specify how long you think the

00:18:55,080 --> 00:18:58,620
jobs going to complete and these

00:18:56,669 --> 00:19:00,210
submission scripts are specific to the

00:18:58,620 --> 00:19:02,400
particular edge or and they sometimes

00:19:00,210 --> 00:19:04,650
have site-specific information in them

00:19:02,400 --> 00:19:06,360
as well and then you can use that draw

00:19:04,650 --> 00:19:08,909
that submission script and submit it

00:19:06,360 --> 00:19:10,710
with a set of command line tools that

00:19:08,909 --> 00:19:12,539
again are specific to the scheduler and

00:19:10,710 --> 00:19:13,700
then once your job is complete and you

00:19:12,539 --> 00:19:16,409
have to do some sort of post-processing

00:19:13,700 --> 00:19:18,630
like move the data back to maybe your

00:19:16,409 --> 00:19:20,280
desktop to do the analysis and so the

00:19:18,630 --> 00:19:23,220
takeaway here is that there's a whole

00:19:20,280 --> 00:19:24,720
bunch of steps that are required in

00:19:23,220 --> 00:19:26,970
order for you to get your data but

00:19:24,720 --> 00:19:28,830
they're not directly related to the

00:19:26,970 --> 00:19:30,630
actual kind of knowledge discovery that

00:19:28,830 --> 00:19:31,919
you're trying to do and so we want use

00:19:30,630 --> 00:19:33,390
this to be able to focus on the

00:19:31,919 --> 00:19:36,210
knowledge discovery and not on job

00:19:33,390 --> 00:19:37,710
execution and so the way we've done that

00:19:36,210 --> 00:19:39,809
is we try and shield the user from as

00:19:37,710 --> 00:19:42,659
much of the complexity as we can we make

00:19:39,809 --> 00:19:45,030
job execution implicit with sane

00:19:42,659 --> 00:19:47,250
defaults so a lot of these codes have a

00:19:45,030 --> 00:19:48,630
whole set of different parameters that

00:19:47,250 --> 00:19:51,360
you consume that the user is probably

00:19:48,630 --> 00:19:53,130
only interested in in a handful and so

00:19:51,360 --> 00:19:55,440
when we talk about implicit job

00:19:53,130 --> 00:19:57,510
execution we're talking about initiating

00:19:55,440 --> 00:19:58,980
jobs as a result of searching for a

00:19:57,510 --> 00:20:01,770
particular data set that isn't already

00:19:58,980 --> 00:20:03,150
there and so we're complying these are

00:20:01,770 --> 00:20:05,580
to concentrate on their data

00:20:03,150 --> 00:20:09,540
the analysis rather than the underlying

00:20:05,580 --> 00:20:11,820
underlying codes so one of the

00:20:09,540 --> 00:20:13,860
mechanisms that we use to allow our

00:20:11,820 --> 00:20:17,309
workflows to be moved between HPC

00:20:13,860 --> 00:20:19,230
resources is a scheduler abstraction and

00:20:17,309 --> 00:20:21,600
so this is kind of a gateway to the HPC

00:20:19,230 --> 00:20:24,330
resource and so we write our API so this

00:20:21,600 --> 00:20:26,090
high-level API that we've developed and

00:20:24,330 --> 00:20:28,770
then that allows you to move between

00:20:26,090 --> 00:20:31,350
particular resources and then in terms

00:20:28,770 --> 00:20:33,330
of obstructing away the input decks

00:20:31,350 --> 00:20:35,760
we're using templating so we can provide

00:20:33,330 --> 00:20:36,960
sane defaults and then they use it and

00:20:35,760 --> 00:20:39,540
then we can just override the particular

00:20:36,960 --> 00:20:41,850
ones that the users interested in now

00:20:39,540 --> 00:20:45,150
these jobs take hours to even days to

00:20:41,850 --> 00:20:47,880
run and so they're kind of monitoring

00:20:45,150 --> 00:20:49,500
and Submission interaction with the

00:20:47,880 --> 00:20:51,210
actual scheduler themselves can't really

00:20:49,500 --> 00:20:54,360
be done in like the request thread of an

00:20:51,210 --> 00:20:56,550
HTTP request and probably not even even

00:20:54,360 --> 00:20:59,700
within the kernel itself and so what we

00:20:56,550 --> 00:21:02,490
do is we actually use a distributed task

00:20:59,700 --> 00:21:04,530
queue to offload those operations and so

00:21:02,490 --> 00:21:07,110
that means provides us a mechanism to

00:21:04,530 --> 00:21:09,270
support what we call on offline jet job

00:21:07,110 --> 00:21:11,070
execution which is essentially you can

00:21:09,270 --> 00:21:14,100
run your notebook and that will initiate

00:21:11,070 --> 00:21:15,809
some HPC job and then you can close down

00:21:14,100 --> 00:21:17,490
your notebook environment and even shut

00:21:15,809 --> 00:21:20,220
down your computer go home for the for

00:21:17,490 --> 00:21:22,470
the day you can come back in and whilst

00:21:20,220 --> 00:21:24,450
you're at home the task scheduling the

00:21:22,470 --> 00:21:26,550
actual job execution will continue to

00:21:24,450 --> 00:21:28,140
run it will continue to monitor the

00:21:26,550 --> 00:21:30,120
state of the job and when the jobs

00:21:28,140 --> 00:21:32,309
complain it ingest the data and so you

00:21:30,120 --> 00:21:34,080
can basically restart your notebook and

00:21:32,309 --> 00:21:39,780
just check in on how your job execution

00:21:34,080 --> 00:21:42,090
is is doing so you saw that within our

00:21:39,780 --> 00:21:44,820
web application you can launch notebooks

00:21:42,090 --> 00:21:47,400
from within the web application and so

00:21:44,820 --> 00:21:50,190
we're using Jupiter hub to do that we're

00:21:47,400 --> 00:21:52,200
using the darkest corner so our Jupiter

00:21:50,190 --> 00:21:54,570
lab serve or Jupiter servers are running

00:21:52,200 --> 00:21:56,850
within docker containers the nice thing

00:21:54,570 --> 00:21:59,730
about that for us is that we can then

00:21:56,850 --> 00:22:02,370
have a simple mechanism for deploying a

00:21:59,730 --> 00:22:04,200
complex Jupiter lab environment we can

00:22:02,370 --> 00:22:06,900
preload a docker image with all the

00:22:04,200 --> 00:22:09,030
libraries that the you needed to support

00:22:06,900 --> 00:22:10,920
the work flows and then Jupiter will

00:22:09,030 --> 00:22:14,550
take care of Jupiter hub will take care

00:22:10,920 --> 00:22:16,200
of spawning these containers and so it

00:22:14,550 --> 00:22:16,659
to facilitate that integration we

00:22:16,200 --> 00:22:18,999
actually

00:22:16,659 --> 00:22:21,279
to write a Jupiter hub Authenticator

00:22:18,999 --> 00:22:23,830
which allowed us to cross cross

00:22:21,279 --> 00:22:26,109
authenticate between the web application

00:22:23,830 --> 00:22:28,179
and the duped hub environment and so the

00:22:26,109 --> 00:22:29,830
user would log in with their credentials

00:22:28,179 --> 00:22:31,690
and then we would use those credentials

00:22:29,830 --> 00:22:34,960
also to authenticate with Jupiter hub

00:22:31,690 --> 00:22:37,989
and so that allowed us to then craft a

00:22:34,960 --> 00:22:39,489
simple you are a URL that would then we

00:22:37,989 --> 00:22:40,840
could redirect to Jupiter hub and

00:22:39,489 --> 00:22:45,879
Jupiter hub would take care of spawning

00:22:40,840 --> 00:22:47,739
the notebook environment for us so the

00:22:45,879 --> 00:22:49,330
notebooks encode the workflow and so

00:22:47,739 --> 00:22:50,859
their valuable data and they really

00:22:49,330 --> 00:22:52,899
belong in the data management system

00:22:50,859 --> 00:22:55,029
themselves and so we're storing them

00:22:52,899 --> 00:22:56,320
alongside the data and we're making them

00:22:55,029 --> 00:22:58,210
searchable and we're making them

00:22:56,320 --> 00:22:59,799
available to others and we're also

00:22:58,210 --> 00:23:01,840
interested in versioning and we're

00:22:59,799 --> 00:23:03,340
interested in what the community is

00:23:01,840 --> 00:23:04,960
doing in terms of versioning so if

00:23:03,340 --> 00:23:06,729
you've got ideas we'd be happy to talk

00:23:04,960 --> 00:23:09,039
to you about it we understand that some

00:23:06,729 --> 00:23:11,830
people are doing like git repos to do

00:23:09,039 --> 00:23:13,690
versioning between different versions of

00:23:11,830 --> 00:23:15,190
a notebook but we're interested in doing

00:23:13,690 --> 00:23:17,229
things like diff things so you can see

00:23:15,190 --> 00:23:20,529
how a workflow changes over time in

00:23:17,229 --> 00:23:22,029
order to get the data within a data

00:23:20,529 --> 00:23:25,119
management system we actually had to

00:23:22,029 --> 00:23:27,399
write a Content Manager within the

00:23:25,119 --> 00:23:29,049
notebook environment on the left-hand

00:23:27,399 --> 00:23:31,119
side there's this file browser widget

00:23:29,049 --> 00:23:34,179
now it's actually backed by an API

00:23:31,119 --> 00:23:36,279
within the notebook server itself called

00:23:34,179 --> 00:23:38,200
the Content Manager API and so usually

00:23:36,279 --> 00:23:40,629
it's browsing the local file system

00:23:38,200 --> 00:23:44,440
where the server is running but we

00:23:40,629 --> 00:23:47,559
implemented a API that then brought that

00:23:44,440 --> 00:23:49,419
then browses the dyrdek essentially the

00:23:47,559 --> 00:23:51,519
girder structure the hierarchical

00:23:49,419 --> 00:23:53,859
structure so that allows us to not only

00:23:51,519 --> 00:23:55,450
access data in girder but it also allows

00:23:53,859 --> 00:23:57,190
us to store the notebooks themselves and

00:23:55,450 --> 00:23:58,929
in girder and that's particularly

00:23:57,190 --> 00:24:00,639
important when you're using the docker

00:23:58,929 --> 00:24:02,169
spawner because obviously the storage

00:24:00,639 --> 00:24:04,269
within the containers is kind of

00:24:02,169 --> 00:24:07,539
ethereal but by storing it within our

00:24:04,269 --> 00:24:09,249
datastore is available so that's some of

00:24:07,539 --> 00:24:10,389
the core kind of components of the

00:24:09,249 --> 00:24:12,729
backend and we'll now move to the

00:24:10,389 --> 00:24:14,440
front-end we have this kind of two

00:24:12,729 --> 00:24:15,999
interaction modes we have a web

00:24:14,440 --> 00:24:17,379
application and then we have duped lab

00:24:15,999 --> 00:24:20,229
and we're going to concentrate on

00:24:17,379 --> 00:24:22,059
talking about Jupiter lab at the very

00:24:20,229 --> 00:24:24,399
low level we're actually using web

00:24:22,059 --> 00:24:26,470
components for our visualization

00:24:24,399 --> 00:24:28,299
components the nice thing about web

00:24:26,470 --> 00:24:30,160
component technologies is it basically

00:24:28,299 --> 00:24:32,500
allows you to encapsulate a complex

00:24:30,160 --> 00:24:35,050
component within essentially a new HTML

00:24:32,500 --> 00:24:37,630
tag and so then you can use that HTML

00:24:35,050 --> 00:24:39,070
tag within any infrastructure you want

00:24:37,630 --> 00:24:40,420
any framework you're not tied to a

00:24:39,070 --> 00:24:42,790
particular framework it just has

00:24:40,420 --> 00:24:45,520
attributes just like any other HTML tag

00:24:42,790 --> 00:24:48,040
and so we're using stencil GAF as our

00:24:45,520 --> 00:24:49,690
compiler and what this allows us to do

00:24:48,040 --> 00:24:51,730
is it allows us to share the same vision

00:24:49,690 --> 00:24:54,580
ponents between the web application and

00:24:51,730 --> 00:24:57,850
the notebook itself and we're using two

00:24:54,580 --> 00:24:59,650
packages for our 3d rendering one is vtk

00:24:57,850 --> 00:25:02,170
GS we're using that particularly for

00:24:59,650 --> 00:25:04,000
volume rendering and then we're using 3d

00:25:02,170 --> 00:25:08,710
emoji s that provides more specific

00:25:04,000 --> 00:25:10,690
chemical 3d structure rendering in terms

00:25:08,710 --> 00:25:13,750
of jeeps allowed extensions themselves

00:25:10,690 --> 00:25:16,240
we're using the mime render interface as

00:25:13,750 --> 00:25:17,770
kind of our main extension point and far

00:25:16,240 --> 00:25:19,210
as a simple mechanism for us to

00:25:17,770 --> 00:25:22,240
basically plug in new visualizations

00:25:19,210 --> 00:25:23,920
based on a mine type within the

00:25:22,240 --> 00:25:27,340
components themselves who are using a

00:25:23,920 --> 00:25:29,290
reactor II ducts stack and they fetch

00:25:27,340 --> 00:25:31,360
their data directly from the data server

00:25:29,290 --> 00:25:33,520
rather than communicating with with the

00:25:31,360 --> 00:25:35,080
kernel itself excuse me and the main

00:25:33,520 --> 00:25:37,180
reason for that is that allows us then

00:25:35,080 --> 00:25:39,520
to share much of the code between a web

00:25:37,180 --> 00:25:41,860
application and the actual kernel

00:25:39,520 --> 00:25:44,380
environment itself and they're pretty

00:25:41,860 --> 00:25:45,730
thin by design and that's because most

00:25:44,380 --> 00:25:47,560
of the functionality is in our web

00:25:45,730 --> 00:25:49,690
components and the nice thing about that

00:25:47,560 --> 00:25:51,640
is it really increases your development

00:25:49,690 --> 00:25:54,250
it reduces your development cycle and

00:25:51,640 --> 00:25:55,990
you don't have to have a full notebook

00:25:54,250 --> 00:25:57,460
environment in order to like kind of do

00:25:55,990 --> 00:25:58,900
it these components and that was

00:25:57,460 --> 00:26:01,000
particularly important in the early days

00:25:58,900 --> 00:26:02,590
of dukkha lab when if you were building

00:26:01,000 --> 00:26:04,810
an extension it would take you know many

00:26:02,590 --> 00:26:07,960
minutes to complete so that kind of sped

00:26:04,810 --> 00:26:09,400
up development for us one of the

00:26:07,960 --> 00:26:11,110
interesting challenges when you have

00:26:09,400 --> 00:26:13,540
these very interactive kind of

00:26:11,110 --> 00:26:16,150
visualizations in there in the outputs

00:26:13,540 --> 00:26:17,920
of cells is how you store what we're

00:26:16,150 --> 00:26:20,560
calling interactive provenance

00:26:17,920 --> 00:26:22,780
so you saw in the demo we were selecting

00:26:20,560 --> 00:26:24,700
a particular vibrational mode now that's

00:26:22,780 --> 00:26:25,960
useful information the scientists

00:26:24,700 --> 00:26:27,460
obviously thought that that was a

00:26:25,960 --> 00:26:29,290
particularly interesting vibrational

00:26:27,460 --> 00:26:31,510
mode and so it probably should be stored

00:26:29,290 --> 00:26:32,860
in some way so that people looking at

00:26:31,510 --> 00:26:34,240
the notebook could see that that was the

00:26:32,860 --> 00:26:36,460
particular interaction or even if

00:26:34,240 --> 00:26:38,260
they're changing the particular 3d view

00:26:36,460 --> 00:26:40,390
to a particular orientation then that's

00:26:38,260 --> 00:26:41,710
valuable information and so again we're

00:26:40,390 --> 00:26:43,990
interested in how the community is

00:26:41,710 --> 00:26:45,790
tackling this whether they're storing

00:26:43,990 --> 00:26:47,440
within the notebook file themselves or

00:26:45,790 --> 00:26:49,140
if they've got other ideas would be

00:26:47,440 --> 00:26:52,960
really interested to hear from you and

00:26:49,140 --> 00:26:55,330
so we adopted typescript for extensions

00:26:52,960 --> 00:26:58,480
at the recommendation of the Jupiter lab

00:26:55,330 --> 00:27:00,700
team pretty early on and it turned out

00:26:58,480 --> 00:27:02,290
to be great advice and we're not only

00:27:00,700 --> 00:27:03,850
using it within our notebook extensions

00:27:02,290 --> 00:27:05,680
itself we're actually using it within

00:27:03,850 --> 00:27:07,840
the wider set of components it's really

00:27:05,680 --> 00:27:11,220
nice to have these typed interfaces when

00:27:07,840 --> 00:27:14,860
interacting with multiple applications

00:27:11,220 --> 00:27:17,320
so a few quick words on deployment we

00:27:14,860 --> 00:27:20,290
have a we have quite quite a stack we

00:27:17,320 --> 00:27:22,300
have about eight docker containers for

00:27:20,290 --> 00:27:24,400
the individual components with our stack

00:27:22,300 --> 00:27:26,470
so we're using docker compose as a

00:27:24,400 --> 00:27:28,630
simple mechanism to spin up parts of the

00:27:26,470 --> 00:27:30,280
stack in different environments and then

00:27:28,630 --> 00:27:31,960
we're using ansible for our runtime

00:27:30,280 --> 00:27:33,880
configuration ansible is a nice

00:27:31,960 --> 00:27:36,010
mechanism to where it should allow you

00:27:33,880 --> 00:27:37,450
to write a declarative description of

00:27:36,010 --> 00:27:38,980
how you want your server to have be

00:27:37,450 --> 00:27:40,870
configured and then you can run it

00:27:38,980 --> 00:27:42,250
against your server and then the

00:27:40,870 --> 00:27:44,950
appropriate changes will be made to the

00:27:42,250 --> 00:27:47,680
server and then in terms of deployments

00:27:44,950 --> 00:27:51,430
we've done - we've done one on AWS where

00:27:47,680 --> 00:27:53,440
we have a small set of ec2 instances

00:27:51,430 --> 00:27:55,720
that form our cluster that we can then

00:27:53,440 --> 00:27:58,150
run jobs on and then we've done a more

00:27:55,720 --> 00:27:59,830
elaborate and deployment at the national

00:27:58,150 --> 00:28:02,140
energy research scientific computing

00:27:59,830 --> 00:28:03,480
Center or nurse and that was an

00:28:02,140 --> 00:28:06,100
interesting one because in order to

00:28:03,480 --> 00:28:08,530
allow users to run jobs on their

00:28:06,100 --> 00:28:10,900
supercomputers we had to integrate with

00:28:08,530 --> 00:28:14,080
their credential credentialing system so

00:28:10,900 --> 00:28:15,580
it allow users to log into the web

00:28:14,080 --> 00:28:18,250
application using their nurse

00:28:15,580 --> 00:28:20,830
credentials are provided by the national

00:28:18,250 --> 00:28:22,240
lab and then those credentials will be

00:28:20,830 --> 00:28:24,430
passed through into the notebook and

00:28:22,240 --> 00:28:26,110
write the tokens would be passed through

00:28:24,430 --> 00:28:27,820
into the notebook environment which

00:28:26,110 --> 00:28:31,030
would allow them to initiate jobs on

00:28:27,820 --> 00:28:32,770
Cori which is actually the top I think

00:28:31,030 --> 00:28:34,180
it's the tenth fastest supercomputer in

00:28:32,770 --> 00:28:35,470
the world currently and so it's pretty

00:28:34,180 --> 00:28:37,510
amazing to be able to be in this

00:28:35,470 --> 00:28:39,700
notebook environment and you search for

00:28:37,510 --> 00:28:41,740
a particular calculation and then it

00:28:39,700 --> 00:28:45,220
fires off this job on this really

00:28:41,740 --> 00:28:48,190
sophisticated piece of hardware so we

00:28:45,220 --> 00:28:49,900
have another two years of time left on

00:28:48,190 --> 00:28:51,760
this project and so these are some of

00:28:49,900 --> 00:28:54,070
the kind of high level areas of

00:28:51,760 --> 00:28:56,230
investigation we're looking at extending

00:28:54,070 --> 00:28:57,549
our collaboration features currently you

00:28:56,230 --> 00:28:59,950
can browse other people

00:28:57,549 --> 00:29:01,840
notebooks but we'd like to essentially

00:28:59,950 --> 00:29:04,029
add a fork button so it can copy the

00:29:01,840 --> 00:29:06,970
static view into your own home directory

00:29:04,029 --> 00:29:08,470
and then you can modify it run it or

00:29:06,970 --> 00:29:11,200
just even repeat the results to see

00:29:08,470 --> 00:29:12,850
whether it is indeed a valid notebook

00:29:11,200 --> 00:29:14,409
and then we're interested in real-time

00:29:12,850 --> 00:29:16,090
collaboration within notebooks

00:29:14,409 --> 00:29:17,529
themselves think kind of like Google

00:29:16,090 --> 00:29:19,779
Docs where you can both be editing the

00:29:17,529 --> 00:29:21,879
document at the same time and I know

00:29:19,779 --> 00:29:24,879
that the community is working on how how

00:29:21,879 --> 00:29:26,610
we can might enable that much of the

00:29:24,879 --> 00:29:29,799
work for the phase one was based on a

00:29:26,610 --> 00:29:30,940
computational code called NW chem we

00:29:29,799 --> 00:29:32,859
want to integrate with more

00:29:30,940 --> 00:29:33,940
computational codes and so that's really

00:29:32,859 --> 00:29:36,600
going to test out some of the

00:29:33,940 --> 00:29:39,519
abstractions that we've made over the

00:29:36,600 --> 00:29:41,889
Conner computations and the parameters

00:29:39,519 --> 00:29:44,440
that will be available to search for

00:29:41,889 --> 00:29:46,239
particular calculations with and then

00:29:44,440 --> 00:29:47,980
machine learning is a really hot topic

00:29:46,239 --> 00:29:49,210
in the chemistry community at the moment

00:29:47,980 --> 00:29:51,119
it's actually a really hot topic in

00:29:49,210 --> 00:29:53,320
probably every community at the moment

00:29:51,119 --> 00:29:54,519
and so within the chemistry community

00:29:53,320 --> 00:29:56,919
essentially what they're doing is

00:29:54,519 --> 00:29:59,230
they're using the results of traditional

00:29:56,919 --> 00:30:01,389
computational chemistry jobs they're

00:29:59,230 --> 00:30:03,249
training models and then these models

00:30:01,389 --> 00:30:06,369
can predict really quickly and really

00:30:03,249 --> 00:30:09,429
accurately the properties of new

00:30:06,369 --> 00:30:12,580
chemicals and so we're interested in if

00:30:09,429 --> 00:30:14,230
from two points one is using these

00:30:12,580 --> 00:30:16,989
actual models within our workflows

00:30:14,230 --> 00:30:19,359
themselves and also providing by bolt

00:30:16,989 --> 00:30:21,009
down loads of data existing data so that

00:30:19,359 --> 00:30:24,669
they can use be used as training data

00:30:21,009 --> 00:30:27,129
sets and then finally we're interested

00:30:24,669 --> 00:30:28,809
in using the Semantic Web more in the

00:30:27,129 --> 00:30:30,940
phase one we kind of dabbled a little

00:30:28,809 --> 00:30:32,950
bit in the Semantic Web we're interested

00:30:30,940 --> 00:30:34,330
in enriching our data in terms of the

00:30:32,950 --> 00:30:36,100
metadata associated with these

00:30:34,330 --> 00:30:38,619
calculations by adding things like

00:30:36,100 --> 00:30:41,859
semantic triples and then also pushing

00:30:38,619 --> 00:30:45,369
some of our data to the Semantic Web so

00:30:41,859 --> 00:30:49,539
make it more discoverable by other kind

00:30:45,369 --> 00:30:52,090
of knowledge graphs so thank you very

00:30:49,539 --> 00:30:55,090
much for listening please come and visit

00:30:52,090 --> 00:30:58,330
us at open chemistry org or check out

00:30:55,090 --> 00:30:59,950
our github or the open chemistry project

00:30:58,330 --> 00:31:02,889
has a wide variety of different open

00:30:59,950 --> 00:31:05,169
source projects within the materials and

00:31:02,889 --> 00:31:06,730
chemistry community and would be happy

00:31:05,169 --> 00:31:08,950
to chat to you afterwards and I've got

00:31:06,730 --> 00:31:10,160
some awesome open chemistry stickers as

00:31:08,950 --> 00:31:11,880
well so if you come and chat to me

00:31:10,160 --> 00:31:15,019
you can get one thank you very much

00:31:11,880 --> 00:31:15,019
[Applause]

00:31:15,400 --> 00:31:33,380
anyone got any questions

00:31:17,150 --> 00:31:34,820
eight minutes perfect tres it's all yeah

00:31:33,380 --> 00:31:38,450
it's all available it's all open sources

00:31:34,820 --> 00:31:44,750
yeah what the actual widget within the

00:31:38,450 --> 00:31:46,400
notebook yeah so there's yeah so there's

00:31:44,750 --> 00:31:47,840
there's a quite a lot of complexity or

00:31:46,400 --> 00:31:49,310
there's quite a lot of things going on

00:31:47,840 --> 00:31:51,680
behind it so it's actually two packages

00:31:49,310 --> 00:31:53,540
and it's a package called cumulus which

00:31:51,680 --> 00:31:55,370
is actually available under the kit

00:31:53,540 --> 00:31:57,380
where org and so that's the bit that

00:31:55,370 --> 00:31:59,090
kind of does the the job submission the

00:31:57,380 --> 00:32:00,410
interaction with the scheduler and the

00:31:59,090 --> 00:32:03,020
job monitoring and it uses this

00:32:00,410 --> 00:32:05,180
distributed task queue to do it and then

00:32:03,020 --> 00:32:07,550
the actual components themselves so

00:32:05,180 --> 00:32:14,620
under the open chemistry project I can I

00:32:07,550 --> 00:32:14,620
can send you an email with them yeah yes

00:32:23,980 --> 00:32:29,660
not explicitly I mean certainly a kit

00:32:27,650 --> 00:32:32,090
where we have groups that are working on

00:32:29,660 --> 00:32:33,470
the VR but we haven't really thought

00:32:32,090 --> 00:32:34,760
about applying it directly to this I

00:32:33,470 --> 00:32:37,160
think some of our collaborator I think

00:32:34,760 --> 00:32:38,720
Bert one of our collaborators that at

00:32:37,160 --> 00:32:40,940
Berkeley National Lab he's very

00:32:38,720 --> 00:32:51,790
interested in using VR in the in the

00:32:40,940 --> 00:32:51,790
chemistry kind of well sure yes

00:32:55,600 --> 00:33:08,870
potentially we've got a lot of things on

00:32:58,760 --> 00:33:10,520
our list yes yeah so I think the idea

00:33:08,870 --> 00:33:11,660
with this is that we would use this as

00:33:10,520 --> 00:33:13,940
to kind of make sure that it was a

00:33:11,660 --> 00:33:16,530
simple process and then would let the

00:33:13,940 --> 00:33:18,570
community go nuts with it

00:33:16,530 --> 00:33:21,030
yeah yeah I mean one of the challenges

00:33:18,570 --> 00:33:23,190
with these codes as I mentioned is is

00:33:21,030 --> 00:33:26,070
making sure you can get the format or

00:33:23,190 --> 00:33:35,490
ingesting the formats into our kind of

00:33:26,070 --> 00:33:41,850
standardized normalized form any other

00:33:35,490 --> 00:33:43,450
questions get to go to lunch early thank

00:33:41,850 --> 00:33:48,349
you

00:33:43,450 --> 00:33:48,349

YouTube URL: https://www.youtube.com/watch?v=oG2qOIiOhAc


