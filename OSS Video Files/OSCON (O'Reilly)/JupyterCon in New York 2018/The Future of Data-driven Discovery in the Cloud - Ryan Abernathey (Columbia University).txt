Title: The Future of Data-driven Discovery in the Cloud - Ryan AbernatheyÂ (Columbia University)
Publication date: 2018-08-24
Playlist: JupyterCon in New York 2018
Description: 
	Drawing on his experience with the Pangeo project, Ryan Abernathey makes the case for the large-scale migration of scientific data and research to the cloud. The cloud offers a way to make the largest datasets instantly accessible to the most sophisticated computational techniques. A global scientific data commons could usher in a golden age of data-driven discovery.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,140 --> 00:00:06,000
so I'm an oceanographer I study the

00:00:03,540 --> 00:00:08,069
physics of the ocean trying to

00:00:06,000 --> 00:00:10,920
understand why ocean currents look the

00:00:08,069 --> 00:00:12,900
way they do how they might be changing

00:00:10,920 --> 00:00:16,170
and the role the ocean plays in the

00:00:12,900 --> 00:00:18,150
global climate system what is an

00:00:16,170 --> 00:00:21,150
oceanographer doing speaking at a tech

00:00:18,150 --> 00:00:24,590
conference well the size and complexity

00:00:21,150 --> 00:00:29,369
of ocean datasets has forced us to take

00:00:24,590 --> 00:00:31,500
computation very seriously in our group

00:00:29,369 --> 00:00:35,399
we're very heavy users of the scientific

00:00:31,500 --> 00:00:38,489
Python software stack yesterday were my

00:00:35,399 --> 00:00:40,350
oceanographer hat and I talked about the

00:00:38,489 --> 00:00:43,200
work we're doing in the Pangaea project

00:00:40,350 --> 00:00:47,329
to build tools to make it easier and

00:00:43,200 --> 00:00:52,890
faster and more fun to work with big

00:00:47,329 --> 00:00:54,780
ocean and climate datasets giving the

00:00:52,890 --> 00:00:56,670
keynote on the big stage is an

00:00:54,780 --> 00:01:00,090
opportunity for me to zoom out a little

00:00:56,670 --> 00:01:04,379
bit and look at the state of science as

00:01:00,090 --> 00:01:07,530
a whole all scientific fields are now

00:01:04,379 --> 00:01:10,320
facing challenges related to big data so

00:01:07,530 --> 00:01:12,930
my goal here today is to share what

00:01:10,320 --> 00:01:16,680
those look like for us and ask if they

00:01:12,930 --> 00:01:18,570
look the same to you in your field if so

00:01:16,680 --> 00:01:21,869
we would love to work and collaborate

00:01:18,570 --> 00:01:24,330
together to solve these challenges so

00:01:21,869 --> 00:01:28,610
when I talk about big scientific data

00:01:24,330 --> 00:01:31,290
what do I mean here's an example of

00:01:28,610 --> 00:01:33,930
fluorescence microscopy image of neurons

00:01:31,290 --> 00:01:36,119
in the brain and you can see this is a

00:01:33,930 --> 00:01:39,270
huge image with incredibly rich

00:01:36,119 --> 00:01:40,619
structure and detail and neuroscientists

00:01:39,270 --> 00:01:46,380
are using this to understand how our

00:01:40,619 --> 00:01:48,329
minds work we can also you know if we

00:01:46,380 --> 00:01:50,759
start looking at the earth we see

00:01:48,329 --> 00:01:53,549
similar types of structure right we have

00:01:50,759 --> 00:01:57,810
imagery this is of a river in northern

00:01:53,549 --> 00:02:00,930
Russia and we can see an incredibly rich

00:01:57,810 --> 00:02:06,780
multiscale structure fascinating to the

00:02:00,930 --> 00:02:09,989
eye and fascinating to scientists moving

00:02:06,780 --> 00:02:12,930
more to my field this is a image from

00:02:09,989 --> 00:02:13,920
satellite of the ocean color which tells

00:02:12,930 --> 00:02:16,110
us where phyto

00:02:13,920 --> 00:02:18,599
plankton live where they grow and die

00:02:16,110 --> 00:02:21,050
and how ocean currents move them around

00:02:18,599 --> 00:02:23,370
these are really the lungs of our planet

00:02:21,050 --> 00:02:26,480
and so what happens to them in the

00:02:23,370 --> 00:02:28,920
future is gonna affect our whole society

00:02:26,480 --> 00:02:31,260
you might want to look at the Sun so

00:02:28,920 --> 00:02:33,690
here's an image of the Sun from the NASA

00:02:31,260 --> 00:02:36,300
Solar Dynamics Observatory you can see

00:02:33,690 --> 00:02:39,150
incredibly complex and rich structure

00:02:36,300 --> 00:02:41,910
here and what the Sun does of course

00:02:39,150 --> 00:02:44,489
affects the earth a lot can zoom out

00:02:41,910 --> 00:02:47,489
even more and look at the data from the

00:02:44,489 --> 00:02:50,550
European Space Agency Gaia data released

00:02:47,489 --> 00:02:53,819
- which reveals in unprecedented detail

00:02:50,550 --> 00:02:58,590
the structure and beauty of the galaxy

00:02:53,819 --> 00:03:01,880
that we live in so what a data sets like

00:02:58,590 --> 00:03:05,250
these all have in common they're big

00:03:01,880 --> 00:03:09,180
talking about terabytes to petabytes of

00:03:05,250 --> 00:03:12,090
data they are largely produced through

00:03:09,180 --> 00:03:14,190
big government-funded science projects

00:03:12,090 --> 00:03:16,739
and this is a trend in science where

00:03:14,190 --> 00:03:20,100
before individual researchers would be

00:03:16,739 --> 00:03:22,170
generating data in in their lab now to

00:03:20,100 --> 00:03:26,130
take on big problems we have to work at

00:03:22,170 --> 00:03:27,959
a much larger collaborative scale the

00:03:26,130 --> 00:03:29,489
datasets like these are cited in

00:03:27,959 --> 00:03:31,410
thousands of papers and used by

00:03:29,489 --> 00:03:34,590
thousands of scientists so they have a

00:03:31,410 --> 00:03:36,570
huge impact and they're absolutely ripe

00:03:34,590 --> 00:03:38,489
for new data-driven analysis methods

00:03:36,570 --> 00:03:41,730
like machine learning and artificial

00:03:38,489 --> 00:03:43,950
intelligence for the most part they are

00:03:41,730 --> 00:03:46,579
trapped behind slow FTP servers

00:03:43,950 --> 00:03:53,130
frustrating data access portals and

00:03:46,579 --> 00:03:55,230
fragmented api's okay so what sort of

00:03:53,130 --> 00:03:56,970
science am I talking about I'm not

00:03:55,230 --> 00:03:59,370
talking about science where we just want

00:03:56,970 --> 00:04:01,560
to get a little piece of a big data set

00:03:59,370 --> 00:04:03,510
I'm talking about where we want to look

00:04:01,560 --> 00:04:06,150
at the whole data set so here's a

00:04:03,510 --> 00:04:09,720
fascinating example recent paper in

00:04:06,150 --> 00:04:13,709
science by Alan and Pavelski where they

00:04:09,720 --> 00:04:17,160
analyze the entire Landsat imagery

00:04:13,709 --> 00:04:19,919
archive to determine what area of Earth

00:04:17,160 --> 00:04:23,310
is covered by water in rivers and

00:04:19,919 --> 00:04:25,770
streams and they found out it's 45% more

00:04:23,310 --> 00:04:27,300
than we previously thought it's it's a

00:04:25,770 --> 00:04:29,310
big revision

00:04:27,300 --> 00:04:33,330
this has major implications for the

00:04:29,310 --> 00:04:34,770
carbon-dioxide budget of Earth how do we

00:04:33,330 --> 00:04:38,659
do this kind of science

00:04:34,770 --> 00:04:43,139
well let's rewind to the Stone Age of

00:04:38,659 --> 00:04:44,909
2014 how did this work we would we

00:04:43,139 --> 00:04:47,039
generally have a data provider that's

00:04:44,909 --> 00:04:49,530
got some data that we want if we're

00:04:47,039 --> 00:04:51,840
lucky there's an FTP service there and

00:04:49,530 --> 00:04:55,680
we can just suck the data down on to our

00:04:51,840 --> 00:04:58,319
computer maybe that data provider has

00:04:55,680 --> 00:05:00,509
some weird API that we've never seen

00:04:58,319 --> 00:05:03,599
before so we have to write it learn that

00:05:00,509 --> 00:05:06,360
API write a script to get the data worst

00:05:03,599 --> 00:05:08,849
case scenario there's some sort of GUI

00:05:06,360 --> 00:05:10,469
web browser interface and in that case

00:05:08,849 --> 00:05:12,719
we often just say forget it I'm gonna

00:05:10,469 --> 00:05:14,639
work on something else we supped the

00:05:12,719 --> 00:05:16,530
data down to our computer and we write a

00:05:14,639 --> 00:05:19,710
loop to iterate through all these big

00:05:16,530 --> 00:05:22,889
files and finally we we get to some sort

00:05:19,710 --> 00:05:25,110
of result some sort of plot what we've

00:05:22,889 --> 00:05:28,169
done is created a dark repository I

00:05:25,110 --> 00:05:30,960
really like this term a dark repository

00:05:28,169 --> 00:05:34,169
is a copy of a data set that we've made

00:05:30,960 --> 00:05:36,800
just so we can compute on it I think

00:05:34,169 --> 00:05:40,830
this concept is familiar to lots of you

00:05:36,800 --> 00:05:43,590
so in this workflow the data has to be

00:05:40,830 --> 00:05:45,960
extracted from a remote server and so we

00:05:43,590 --> 00:05:48,870
have to decide what data to download a

00:05:45,960 --> 00:05:50,849
priori this is important because this

00:05:48,870 --> 00:05:55,560
makes us we have to decide what we're

00:05:50,849 --> 00:05:58,409
looking for before we've found it and

00:05:55,560 --> 00:06:00,810
it's it's slow so you know basically you

00:05:58,409 --> 00:06:02,969
you try some calculation you go get

00:06:00,810 --> 00:06:07,020
lunch you come back you see if your

00:06:02,969 --> 00:06:09,930
calculation worked and it's boring so

00:06:07,020 --> 00:06:12,539
you know we've got Facebook and Twitter

00:06:09,930 --> 00:06:15,379
always calling us instead of thinking

00:06:12,539 --> 00:06:18,750
about science right this is a real issue

00:06:15,379 --> 00:06:20,550
so you know the consequences of this

00:06:18,750 --> 00:06:23,490
type of system I observed in my own

00:06:20,550 --> 00:06:25,889
research group our scientists our PhD

00:06:23,490 --> 00:06:27,810
students and postdocs they're actually

00:06:25,889 --> 00:06:30,690
having to learn to be data engineers and

00:06:27,810 --> 00:06:32,699
spending their time writing code to

00:06:30,690 --> 00:06:35,460
process data rather than thinking about

00:06:32,699 --> 00:06:38,460
science problems it forces a

00:06:35,460 --> 00:06:41,290
conservative approach to science because

00:06:38,460 --> 00:06:43,510
of the the pain of working this way

00:06:41,290 --> 00:06:47,980
we have to look for expected things

00:06:43,510 --> 00:06:50,230
rather than discovering new things the

00:06:47,980 --> 00:06:53,020
provenance of the data is obscured so in

00:06:50,230 --> 00:06:54,580
our dark repository it's not connected

00:06:53,020 --> 00:06:56,670
to the data provider anymore what if

00:06:54,580 --> 00:06:59,650
there's a correction to that data set

00:06:56,670 --> 00:07:02,250
and as a consequence it's really almost

00:06:59,650 --> 00:07:05,020
impossible to reproduce this type of

00:07:02,250 --> 00:07:08,920
science even though many scientists are

00:07:05,020 --> 00:07:12,220
working with the same data sets ok so a

00:07:08,920 --> 00:07:15,040
new way of working is emerging and today

00:07:12,220 --> 00:07:17,170
a lot of us are working this way instead

00:07:15,040 --> 00:07:19,690
of just using our personal computers we

00:07:17,170 --> 00:07:22,090
can put our analysis onto some sort of

00:07:19,690 --> 00:07:25,480
big server or cluster that lives at our

00:07:22,090 --> 00:07:28,360
University and thanks to tools like

00:07:25,480 --> 00:07:30,820
jupiter our students and postdocs can

00:07:28,360 --> 00:07:35,290
access that resource share that resource

00:07:30,820 --> 00:07:38,170
and use it to process data in a parallel

00:07:35,290 --> 00:07:39,880
way that's much faster than before so

00:07:38,170 --> 00:07:44,200
you know I have some examples of what

00:07:39,880 --> 00:07:46,330
code using - or x-ray looks like and

00:07:44,200 --> 00:07:48,990
this this is a great development it's

00:07:46,330 --> 00:07:52,180
it's fantastic to be working this way so

00:07:48,990 --> 00:07:54,190
the analysis is much faster these tools

00:07:52,180 --> 00:07:57,550
allow us to think about datasets as a

00:07:54,190 --> 00:07:59,230
whole rather than files and we can

00:07:57,550 --> 00:08:01,780
iterate quickly and explore new not new

00:07:59,230 --> 00:08:05,140
ideas but we still have a dark

00:08:01,780 --> 00:08:08,830
repository so I think you know where I'm

00:08:05,140 --> 00:08:11,710
going this is what we have to be doing

00:08:08,830 --> 00:08:15,490
right we need to be bringing the compute

00:08:11,710 --> 00:08:19,860
together with the data when we do this

00:08:15,490 --> 00:08:23,280
our our high-performance computing our

00:08:19,860 --> 00:08:26,170
parallel clusters can talk directly to

00:08:23,280 --> 00:08:29,470
to where the raw data is stored at high

00:08:26,170 --> 00:08:31,150
bandwidth and we can really iterate

00:08:29,470 --> 00:08:32,919
quickly with our science and we don't

00:08:31,150 --> 00:08:37,540
need to copy the data we don't need to

00:08:32,919 --> 00:08:43,840
make a replica of it this is what we are

00:08:37,540 --> 00:08:46,870
trying to build in the Pangea project so

00:08:43,840 --> 00:08:51,760
I invite you all to go check out Pangaea

00:08:46,870 --> 00:08:53,980
PI data org we're a group of earth

00:08:51,760 --> 00:08:55,089
scientists working with a few software

00:08:53,980 --> 00:08:57,610
engineers to

00:08:55,089 --> 00:08:59,410
build an environment where we can have

00:08:57,610 --> 00:09:02,079
our data and our computing in the same

00:08:59,410 --> 00:09:03,970
place not just one environment but

00:09:02,079 --> 00:09:05,290
actually a set of modular tools that

00:09:03,970 --> 00:09:08,470
allow anyone to create these

00:09:05,290 --> 00:09:10,709
environments we don't have a lot of

00:09:08,470 --> 00:09:13,600
people we don't have a lot of money

00:09:10,709 --> 00:09:16,870
which is fine because what we realized

00:09:13,600 --> 00:09:19,689
is that all of the building blocks for

00:09:16,870 --> 00:09:22,209
these big data science gateways

00:09:19,689 --> 00:09:24,569
basically already exist they just have

00:09:22,209 --> 00:09:27,670
to be plugged together so Jupiter hub

00:09:24,569 --> 00:09:30,790
and in particular the zero to Jupiter

00:09:27,670 --> 00:09:33,730
hub kubernetes project make it really

00:09:30,790 --> 00:09:36,569
easy for you to stand up a Jupiter

00:09:33,730 --> 00:09:40,569
service for many users we now have great

00:09:36,569 --> 00:09:43,930
parallel computing tools we used ask you

00:09:40,569 --> 00:09:45,939
could use something like spark and in

00:09:43,930 --> 00:09:47,680
scientific Python in the scientific

00:09:45,939 --> 00:09:49,300
Python world in the open source world in

00:09:47,680 --> 00:09:52,240
general we've got great domain-specific

00:09:49,300 --> 00:09:54,579
software in our field of climate we use

00:09:52,240 --> 00:09:56,100
X array if you're an astronomer you

00:09:54,579 --> 00:09:58,749
probably use a straw pi and we

00:09:56,100 --> 00:10:02,589
understand how to build cloud optimized

00:09:58,749 --> 00:10:06,009
data formats that allow us to more

00:10:02,589 --> 00:10:09,850
quickly and efficiently access and work

00:10:06,009 --> 00:10:13,360
with big data sets so we've really

00:10:09,850 --> 00:10:15,189
enjoyed building this prototype it is

00:10:13,360 --> 00:10:18,579
allowed our scientists to be more

00:10:15,189 --> 00:10:21,999
productive and have a have more fun and

00:10:18,579 --> 00:10:26,679
be connected directly to the data in in

00:10:21,999 --> 00:10:29,319
a cloud environment but we can't have

00:10:26,679 --> 00:10:32,649
this yet in science we're not there at

00:10:29,319 --> 00:10:36,610
the large scale for the most part data

00:10:32,649 --> 00:10:39,249
repositories are still not accessible to

00:10:36,610 --> 00:10:41,170
computing so what I would like to see

00:10:39,249 --> 00:10:44,769
happen is I would like to see data

00:10:41,170 --> 00:10:47,459
providers think about how these tools

00:10:44,769 --> 00:10:50,800
can interact with their data sets

00:10:47,459 --> 00:10:52,629
directly I would like to see data

00:10:50,800 --> 00:10:57,910
providers putting their data on the

00:10:52,629 --> 00:11:00,309
cloud or on HPC systems in an analysis

00:10:57,910 --> 00:11:02,679
ready optimized format and NASA is

00:11:00,309 --> 00:11:05,019
already going this route so NASA is

00:11:02,679 --> 00:11:08,079
committed to putting a hundred petabytes

00:11:05,019 --> 00:11:08,680
of earth science data on the cloud over

00:11:08,079 --> 00:11:12,310
the next

00:11:08,680 --> 00:11:14,860
five to ten years so what are this uh so

00:11:12,310 --> 00:11:18,730
once we have this sort of cloud native

00:11:14,860 --> 00:11:21,820
science the advantages will be immense

00:11:18,730 --> 00:11:24,760
as scientists we can write expressive

00:11:21,820 --> 00:11:27,910
code interact lazily with full datasets

00:11:24,760 --> 00:11:30,660
and really think about big problems we

00:11:27,910 --> 00:11:33,940
can run calculations on big data sets at

00:11:30,660 --> 00:11:36,700
interactive speed try out new ideas you

00:11:33,940 --> 00:11:39,220
know be creative we're not duplicating

00:11:36,700 --> 00:11:41,080
data we'll save a lot of money we don't

00:11:39,220 --> 00:11:43,630
need to be storing the same datasets a

00:11:41,080 --> 00:11:48,160
thousand different times under people's

00:11:43,630 --> 00:11:50,440
desks across the world if we can build

00:11:48,160 --> 00:11:53,110
this it will really help put the

00:11:50,440 --> 00:11:59,200
curiosity and discovery and fun back

00:11:53,110 --> 00:12:02,170
into science ok so my last slide is very

00:11:59,200 --> 00:12:04,630
busy it's some summarizes some of the

00:12:02,170 --> 00:12:07,420
challenges we face that I want to talk

00:12:04,630 --> 00:12:09,339
to people about how to overcome so as

00:12:07,420 --> 00:12:12,180
scientists we have kind of two options

00:12:09,339 --> 00:12:14,440
of where to build this type of thing

00:12:12,180 --> 00:12:16,529
traditionally we've worked on big

00:12:14,440 --> 00:12:19,390
government high-performance computing

00:12:16,529 --> 00:12:25,270
resources things like NSF succeed

00:12:19,390 --> 00:12:27,400
program or do E's nurse computer the

00:12:25,270 --> 00:12:29,980
commercial cloud is also emerging as a

00:12:27,400 --> 00:12:32,410
very viable place to do data-driven

00:12:29,980 --> 00:12:35,830
computing and each of these platforms

00:12:32,410 --> 00:12:38,529
has their trade-offs so scientists are

00:12:35,830 --> 00:12:41,620
familiar with government HPC centers and

00:12:38,529 --> 00:12:45,430
when they're willing like nurse is you

00:12:41,620 --> 00:12:48,510
can build interactive computing portals

00:12:45,430 --> 00:12:50,920
they're these resources though are

00:12:48,510 --> 00:12:53,170
they're available to all federally

00:12:50,920 --> 00:12:55,240
funded scientists which is great but

00:12:53,170 --> 00:12:57,820
that's also a downside they're available

00:12:55,240 --> 00:12:59,290
only to federally funded scientists what

00:12:57,820 --> 00:13:01,180
about all the other people what about

00:12:59,290 --> 00:13:03,760
people in the developing world who want

00:13:01,180 --> 00:13:05,320
to work with big data sets the

00:13:03,760 --> 00:13:07,300
commercial cloud on the other hand is

00:13:05,320 --> 00:13:10,570
available to anyone with a credit card

00:13:07,300 --> 00:13:14,649
but scientists generally do not know how

00:13:10,570 --> 00:13:18,190
to interact with the cloud and our

00:13:14,649 --> 00:13:20,980
financial system and science is not set

00:13:18,190 --> 00:13:22,570
up to allow scientists to acquire

00:13:20,980 --> 00:13:26,530
large-scale cloud compute

00:13:22,570 --> 00:13:30,250
resources working on traditional HPC

00:13:26,530 --> 00:13:32,790
systems is not inherently interactive

00:13:30,250 --> 00:13:35,440
whereas in the cloud we can burst

00:13:32,790 --> 00:13:40,660
quickly into huge numbers of compute

00:13:35,440 --> 00:13:42,280
nodes via the spot market so there's a

00:13:40,660 --> 00:13:44,710
lot of trade-offs we need to consider

00:13:42,280 --> 00:13:47,320
and I don't know all the answers but

00:13:44,710 --> 00:13:49,150
maybe some of you in this room do so I

00:13:47,320 --> 00:13:50,860
want to close by just inviting you to

00:13:49,150 --> 00:13:52,840
join the discussion happening around

00:13:50,860 --> 00:13:55,540
Pangaea we have a github repository

00:13:52,840 --> 00:13:57,310
where we discuss all this stuff and I

00:13:55,540 --> 00:14:00,570
want to thank you for the opportunity to

00:13:57,310 --> 00:14:00,570
share what we're up to

00:14:07,100 --> 00:14:09,160

YouTube URL: https://www.youtube.com/watch?v=7kDYfUe0Zhw


