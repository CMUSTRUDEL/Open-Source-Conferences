Title: Using Jupyter to Empower Enterprise Analysts - Dave Stuart (Department of Defense)
Publication date: 2018-09-20
Playlist: JupyterCon in New York 2018
Description: 
	Citizen data science: An enterprise use case from inside the US intelligence community
Dave Stuart (Department of Defense )

Each day, thousands of intelligence analysts are hard at work culling and correlating information from a multitude of repositories with fine-grained security. The US Department of Defense (DoD) and the greater intelligence community (IC) face a challenge: How can they empower this community—the majority of whom are not steeped in traditional technical disciplines like software engineering or statistics—to translate their tradecraft into code and gain efficiencies in their workflow?

While the classified environment and mission of the DoD and IC may be unique, they face many common challenges in building grassroots traction of new technologies. Dave Stuart explains how Jupyter was used inside the DoD and IC to empower thousands of “citizen data scientists” to build and share analytics in order to meet the community’s dynamic challenges.

Driving a culture change such as the enterprise-wide adoption of Jupyter fed by organic growth means addressing a variety of challenges, such as closing the gap between data scientists and business (intel) analysts, bringing new users with little or no technical background into the Jupyter community, crowdsourcing solution development by empowering users to create their own solutions, automatically measuring the impact and health of notebooks created across a diverse user base, maximizing the “discoverability” of notebooks to enable users to quickly find relevant analytics for their mission, and securing buy-in from a variety of stakeholders within a large enterprise. Dave details how one very small team evangelized Jupyter across a large and diverse community and built an application called nbgallery (aka Notebook Gallery) that enables the citizen data science community to manage, share, and collaborate on code.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,489 --> 00:00:05,160
so again this is using dupa to empower

00:00:03,929 --> 00:00:07,560
enterprise analysts my name is Dave

00:00:05,160 --> 00:00:09,000
Stewart and uh so the last 15 years

00:00:07,560 --> 00:00:10,589
quick introduction I've worked inside

00:00:09,000 --> 00:00:11,820
the US intelligence community where I've

00:00:10,589 --> 00:00:13,200
worked on multiple efforts to drive

00:00:11,820 --> 00:00:15,120
enterprise wide adoption of new

00:00:13,200 --> 00:00:16,710
technologies kind of always guided by

00:00:15,120 --> 00:00:18,449
this principle of rising tide lifts all

00:00:16,710 --> 00:00:20,010
boats or often when I kind of the

00:00:18,449 --> 00:00:21,390
biggest ways have an impact in the large

00:00:20,010 --> 00:00:23,640
enterprise environment we're talking you

00:00:21,390 --> 00:00:24,599
know tens of thousands of users is it

00:00:23,640 --> 00:00:26,099
tried to increase the technical

00:00:24,599 --> 00:00:27,689
proficiency of the largest possible user

00:00:26,099 --> 00:00:28,859
base and so for the last three years

00:00:27,689 --> 00:00:31,140
I've been leading an effort to do

00:00:28,859 --> 00:00:32,700
exactly that with Jupiter and so this

00:00:31,140 --> 00:00:33,870
presentation is about Jupiter Zeus

00:00:32,700 --> 00:00:35,910
inside the US intelligence community

00:00:33,870 --> 00:00:37,379
knowing that it's the right tool to

00:00:35,910 --> 00:00:38,520
empower thousands of analysts to apply

00:00:37,379 --> 00:00:40,170
code to their tradecraft

00:00:38,520 --> 00:00:42,840
making that tradecraft more efficient

00:00:40,170 --> 00:00:44,160
more shareable and more repeatable this

00:00:42,840 --> 00:00:45,809
talk is also about the technical and

00:00:44,160 --> 00:00:47,699
human challenges of enterprise wide

00:00:45,809 --> 00:00:49,379
adoption of Jupiter because why our

00:00:47,699 --> 00:00:51,390
organization is unique in some aspects

00:00:49,379 --> 00:00:52,859
the challenges that we have to face by

00:00:51,390 --> 00:00:54,239
and large I think will be relatable to

00:00:52,859 --> 00:00:56,250
any other enterprise environment looking

00:00:54,239 --> 00:00:57,000
to adopt you peer at scale and some of

00:00:56,250 --> 00:00:58,949
the approaches that we've taken

00:00:57,000 --> 00:01:00,180
hopefully can help inform other

00:00:58,949 --> 00:01:01,940
enterprises that are looking to adopt

00:01:00,180 --> 00:01:03,870
Jupiter at scale

00:01:01,940 --> 00:01:05,370
so I thought this is kind of a funny way

00:01:03,870 --> 00:01:07,620
to just kind of start out by describing

00:01:05,370 --> 00:01:09,750
what analysts work looks like inside the

00:01:07,620 --> 00:01:11,520
US intelligence community you have that

00:01:09,750 --> 00:01:13,440
top row there which is a more kind of

00:01:11,520 --> 00:01:16,200
pop-culture depiction of what it is

00:01:13,440 --> 00:01:17,700
people think analysts do in the IC

00:01:16,200 --> 00:01:19,440
but that bottom row is a much more

00:01:17,700 --> 00:01:21,390
relatable and a far more realistic view

00:01:19,440 --> 00:01:23,040
of what our analysts look like because

00:01:21,390 --> 00:01:24,870
they're essentially data analysts in an

00:01:23,040 --> 00:01:26,190
enterprise environment and they will

00:01:24,870 --> 00:01:28,020
look no different than I think with a

00:01:26,190 --> 00:01:30,030
financial analyst or insurer insurance

00:01:28,020 --> 00:01:32,670
analyst but for us we call them Intel

00:01:30,030 --> 00:01:34,320
Intel analysts or IAS and so

00:01:32,670 --> 00:01:36,060
particularly doing analysis in a large

00:01:34,320 --> 00:01:38,090
enterprise environment we means we have

00:01:36,060 --> 00:01:41,820
this massive you know analytic user base

00:01:38,090 --> 00:01:43,890
again you know over 10,000 users and the

00:01:41,820 --> 00:01:45,000
traditional model of having analysts

00:01:43,890 --> 00:01:47,250
kind of write requirements at having

00:01:45,000 --> 00:01:48,690
capabilities try to you know dumb you

00:01:47,250 --> 00:01:51,950
know have developers try to create

00:01:48,690 --> 00:01:54,270
solutions for those users is just

00:01:51,950 --> 00:01:58,170
impractical it doesn't address the speed

00:01:54,270 --> 00:02:00,390
and scale of this mission and so in many

00:01:58,170 --> 00:02:02,160
cases and we also need these kind of

00:02:00,390 --> 00:02:03,810
fine-grained sometimes ephemeral

00:02:02,160 --> 00:02:05,640
analytic solutions that only affect

00:02:03,810 --> 00:02:07,110
small number of users for a very short

00:02:05,640 --> 00:02:09,209
period of time and so it can again

00:02:07,110 --> 00:02:10,289
pairing analysts the developers at this

00:02:09,209 --> 00:02:13,410
scale they know the scale of our

00:02:10,289 --> 00:02:14,370
enterprise it doesn't work so what that

00:02:13,410 --> 00:02:15,360
means in real terms is that when

00:02:14,370 --> 00:02:17,670
analysts are presented

00:02:15,360 --> 00:02:19,710
the new problem they go back to a way of

00:02:17,670 --> 00:02:22,020
a manual workflow the requires and they

00:02:19,710 --> 00:02:23,370
use many different tools you know pieced

00:02:22,020 --> 00:02:24,840
together in manual fashion where they

00:02:23,370 --> 00:02:27,000
ultimately dump that data to excel and

00:02:24,840 --> 00:02:28,440
do that final analysis in Excel but

00:02:27,000 --> 00:02:29,640
these kinds of solutions are hard to

00:02:28,440 --> 00:02:31,710
capture they're hard to share and

00:02:29,640 --> 00:02:33,210
they're hard to reproduce and equally

00:02:31,710 --> 00:02:35,220
important they're an inefficient use of

00:02:33,210 --> 00:02:37,710
kind of analyst time and their skillsets

00:02:35,220 --> 00:02:38,760
and so this is a quote here from an

00:02:37,710 --> 00:02:40,790
analyst who's one of our biggest

00:02:38,760 --> 00:02:43,170
advocates in the Jupiter community

00:02:40,790 --> 00:02:44,340
internally and she's got a funny

00:02:43,170 --> 00:02:46,140
anecdote when she was first showing

00:02:44,340 --> 00:02:47,820
Jupiter about two years ago her initial

00:02:46,140 --> 00:02:50,010
reaction was quote no analysts will ever

00:02:47,820 --> 00:02:51,600
use this and she has since you know done

00:02:50,010 --> 00:02:53,040
a full 180 and now she's one of her you

00:02:51,600 --> 00:02:54,959
know strongest advocates in that

00:02:53,040 --> 00:02:56,070
community and you'll see me quote from

00:02:54,959 --> 00:02:57,450
this a number of times about the

00:02:56,070 --> 00:02:58,739
presentation where this is a blog post

00:02:57,450 --> 00:03:01,080
that she wrote kind of describing her

00:02:58,739 --> 00:03:02,910
journey as initially a Jupiter skeptic

00:03:01,080 --> 00:03:04,920
and now really a passionate kind of

00:03:02,910 --> 00:03:06,600
Jupiter advocate but at the start this

00:03:04,920 --> 00:03:07,980
blog post she's talking about how

00:03:06,600 --> 00:03:10,380
looking at her workflow she's

00:03:07,980 --> 00:03:13,020
recognizing how much of that is manual

00:03:10,380 --> 00:03:14,700
kind of menial tasks that really taking

00:03:13,020 --> 00:03:16,680
away from her core job of doing the

00:03:14,700 --> 00:03:18,900
analysis that she wants to be doing and

00:03:16,680 --> 00:03:21,030
so we believe Jupiter is a solution to

00:03:18,900 --> 00:03:22,380
that problem because in particular at

00:03:21,030 --> 00:03:24,390
the highest level what Jupiter has

00:03:22,380 --> 00:03:25,920
enabled us to do is go beyond developers

00:03:24,390 --> 00:03:28,320
writing scripts to analyst writing

00:03:25,920 --> 00:03:29,790
reproducible workflows we've always had

00:03:28,320 --> 00:03:31,410
developers in the community that have it

00:03:29,790 --> 00:03:32,970
had the ability to write scripts but

00:03:31,410 --> 00:03:34,769
again at enterprise scale it's hard to

00:03:32,970 --> 00:03:36,540
pair them with analysts to always answer

00:03:34,769 --> 00:03:39,269
every question analyst has it every time

00:03:36,540 --> 00:03:40,620
they have those questions so we want

00:03:39,269 --> 00:03:42,810
analysts to be able to do a lot of that

00:03:40,620 --> 00:03:44,370
work themselves and Jupiter has been

00:03:42,810 --> 00:03:46,500
really the catalyst that's enabled these

00:03:44,370 --> 00:03:47,790
analysts to do this themselves that's

00:03:46,500 --> 00:03:48,930
for a number of reasons one you know

00:03:47,790 --> 00:03:50,640
being web-based that makes it far more

00:03:48,930 --> 00:03:51,959
approachable to this community that most

00:03:50,640 --> 00:03:53,250
likely will not have had any kind of

00:03:51,959 --> 00:03:55,350
command line development experience

00:03:53,250 --> 00:03:56,760
before and the notebook format really

00:03:55,350 --> 00:03:58,230
lends itself obviously to this

00:03:56,760 --> 00:03:59,700
reproducible workflow where it's

00:03:58,230 --> 00:04:00,470
enabling analyst to document their

00:03:59,700 --> 00:04:03,480
tradecraft

00:04:00,470 --> 00:04:05,820
their their code and documentation all

00:04:03,480 --> 00:04:06,989
in one place in a portable document that

00:04:05,820 --> 00:04:09,420
they can share throughout the community

00:04:06,989 --> 00:04:11,459
for others to reproduce and benefit from

00:04:09,420 --> 00:04:12,840
their work and so further on on that

00:04:11,459 --> 00:04:13,950
blog post again from the same analyst

00:04:12,840 --> 00:04:15,959
she's talking about now

00:04:13,950 --> 00:04:17,280
you know after using Jupiter instead of

00:04:15,959 --> 00:04:18,750
thinking of her workflow largely in

00:04:17,280 --> 00:04:21,299
terms of tools she's thinking in terms

00:04:18,750 --> 00:04:22,470
of questions and data which is exactly

00:04:21,299 --> 00:04:23,849
the level that we want these animals

00:04:22,470 --> 00:04:25,730
operating on we don't want them kind of

00:04:23,849 --> 00:04:27,530
bogged down with the menial manual

00:04:25,730 --> 00:04:29,360
of knowing how you know which tool to

00:04:27,530 --> 00:04:31,640
use and how to use it we want them altom

00:04:29,360 --> 00:04:32,870
utley to be asking questions of the data

00:04:31,640 --> 00:04:35,050
that again try to help them derive

00:04:32,870 --> 00:04:37,130
insight from that data for our purposes

00:04:35,050 --> 00:04:38,630
another huge benefit we get from using

00:04:37,130 --> 00:04:40,070
Jupiter and this is a Brian Greene who

00:04:38,630 --> 00:04:42,650
talked about this a lot in his initial

00:04:40,070 --> 00:04:44,210
talk today in this track is we benefit

00:04:42,650 --> 00:04:46,700
from this massive open source open

00:04:44,210 --> 00:04:47,780
source ecosystem and this is really

00:04:46,700 --> 00:04:51,350
beneficial for an enterprise level

00:04:47,780 --> 00:04:52,670
because while our data and how we might

00:04:51,350 --> 00:04:54,110
collect that data may be unique the

00:04:52,670 --> 00:04:56,870
types of analysis that we're trying to

00:04:54,110 --> 00:04:58,340
do overwhelmingly are shared across any

00:04:56,870 --> 00:05:00,740
other kind of data environment and so

00:04:58,340 --> 00:05:02,000
where there are solutions and obviously

00:05:00,740 --> 00:05:03,710
the Python ecosystem for doing data

00:05:02,000 --> 00:05:06,800
science data analysis data visualization

00:05:03,710 --> 00:05:08,780
is a very strong robust ecosystem where

00:05:06,800 --> 00:05:10,310
we can benefit from that makes us far

00:05:08,780 --> 00:05:11,630
more efficient use of our resources and

00:05:10,310 --> 00:05:13,190
we're not having to kind of recreate and

00:05:11,630 --> 00:05:16,580
you know try to create these solutions

00:05:13,190 --> 00:05:17,930
on our own so our goals for Jupiter are

00:05:16,580 --> 00:05:20,120
first we want to make analyst workflows

00:05:17,930 --> 00:05:21,470
more efficient we want to enable them to

00:05:20,120 --> 00:05:23,630
capture their analytic knowledge to

00:05:21,470 --> 00:05:25,760
share them with others and we want to

00:05:23,630 --> 00:05:28,070
reach analysts at their level because

00:05:25,760 --> 00:05:30,140
while learning the code is learning code

00:05:28,070 --> 00:05:31,820
for some analyst is ok expecting them to

00:05:30,140 --> 00:05:33,200
be a sysadmin is not alright and

00:05:31,820 --> 00:05:34,700
expecting them to be able to install and

00:05:33,200 --> 00:05:36,350
configure these complex environments is

00:05:34,700 --> 00:05:38,080
really outside of the scope of what

00:05:36,350 --> 00:05:40,610
we're trying to do for these analysts

00:05:38,080 --> 00:05:42,050
and also to use Jupiter to enterprise

00:05:40,610 --> 00:05:43,730
scale so we're in Paco's keynote this

00:05:42,050 --> 00:05:45,290
morning talked about some of the the

00:05:43,730 --> 00:05:47,000
challenges that any every enterprise

00:05:45,290 --> 00:05:48,320
will have to face I've been doing that

00:05:47,000 --> 00:05:49,940
and are gonna probably certainly is no

00:05:48,320 --> 00:05:51,680
different so in particular I'll talk

00:05:49,940 --> 00:05:53,510
about these four challenges right the

00:05:51,680 --> 00:05:53,690
challenges of adopting it to our user

00:05:53,510 --> 00:06:00,260
base

00:05:53,690 --> 00:06:02,480
yes group tens of thousands right no no

00:06:00,260 --> 00:06:05,120
no not now but like that I would hope

00:06:02,480 --> 00:06:08,330
would be using it yeah we're in the five

00:06:05,120 --> 00:06:11,600
to ten thousand range now so for one is

00:06:08,330 --> 00:06:13,310
adopting it to our user base two is

00:06:11,600 --> 00:06:14,600
enabling this user base to collaborate

00:06:13,310 --> 00:06:17,750
kind of efficiently effectively across

00:06:14,600 --> 00:06:19,220
this large organization third is

00:06:17,750 --> 00:06:20,900
addressing issues rating the data

00:06:19,220 --> 00:06:22,550
security and in our instance Offices of

00:06:20,900 --> 00:06:23,780
those can be pretty extreme and then

00:06:22,550 --> 00:06:26,840
finally is addressing issues related to

00:06:23,780 --> 00:06:28,730
compliance so in the user base side the

00:06:26,840 --> 00:06:31,040
you know the primary analytic user base

00:06:28,730 --> 00:06:33,260
we're trying to adapt this to our mostly

00:06:31,040 --> 00:06:34,580
non coders I originally had in there

00:06:33,260 --> 00:06:36,110
non-technical that's not exactly

00:06:34,580 --> 00:06:37,460
accurate because they are technical

00:06:36,110 --> 00:06:40,050
analysts they are dealing with data

00:06:37,460 --> 00:06:41,550
day and day out further

00:06:40,050 --> 00:06:42,690
but that kind of common characteristic

00:06:41,550 --> 00:06:44,039
that a lot of them have is that they

00:06:42,690 --> 00:06:45,630
they weren't hired in because they were

00:06:44,039 --> 00:06:47,400
computer scientists or data scientists

00:06:45,630 --> 00:06:50,220
they were hired in for their domain

00:06:47,400 --> 00:06:51,479
knowledge and they most likely will not

00:06:50,220 --> 00:06:53,389
have had previous experience kind of

00:06:51,479 --> 00:06:55,259
doing command-line development before

00:06:53,389 --> 00:06:56,940
again as I mentioned there they these

00:06:55,259 --> 00:06:58,319
are ou domain knowledge experts they're

00:06:56,940 --> 00:06:59,610
the ones with hats were driving insight

00:06:58,319 --> 00:07:01,050
from their data they're the ones who

00:06:59,610 --> 00:07:02,880
understand their data better than

00:07:01,050 --> 00:07:05,490
anybody else and so we think there's a

00:07:02,880 --> 00:07:08,310
huge untapped coding potential in this

00:07:05,490 --> 00:07:09,389
workforce on the collaboration challenge

00:07:08,310 --> 00:07:12,150
sides you know with this large

00:07:09,389 --> 00:07:13,800
geographically dispersed user base where

00:07:12,150 --> 00:07:15,720
as much as possible we want to enable

00:07:13,800 --> 00:07:18,240
these to maximize its discovery and

00:07:15,720 --> 00:07:19,560
collaboration opportunities across the

00:07:18,240 --> 00:07:23,099
variety of analysts at the variety of

00:07:19,560 --> 00:07:25,050
locations for our users on the data

00:07:23,099 --> 00:07:26,699
security side again this is this is not

00:07:25,050 --> 00:07:28,400
a unique challenge in an organization

00:07:26,699 --> 00:07:30,389
but for us it can be pretty extreme

00:07:28,400 --> 00:07:32,490
we're dealing with very sensitive

00:07:30,389 --> 00:07:33,599
subject matter certainly in the

00:07:32,490 --> 00:07:34,889
intelligence community here it's kinda

00:07:33,599 --> 00:07:35,819
it's not an exaggeration of saying we're

00:07:34,889 --> 00:07:38,130
dealing with some of the highest levels

00:07:35,819 --> 00:07:39,810
of classified data that the government

00:07:38,130 --> 00:07:41,990
has and so because of that we have

00:07:39,810 --> 00:07:44,009
extreme fine-grained data security rules

00:07:41,990 --> 00:07:45,960
that's generally governed by this

00:07:44,009 --> 00:07:47,340
need-to-know principle meaning that

00:07:45,960 --> 00:07:48,750
simply being in the community simply

00:07:47,340 --> 00:07:50,940
having a top secret clearance doesn't

00:07:48,750 --> 00:07:54,120
automatically give you access to all

00:07:50,940 --> 00:07:55,770
this data data is very kind of

00:07:54,120 --> 00:07:58,080
compartmentalized and restricted to this

00:07:55,770 --> 00:08:00,509
need-to-know principle of only those who

00:07:58,080 --> 00:08:03,330
have a kind of a mission need-to-know to

00:08:00,509 --> 00:08:04,949
access that data can get access to that

00:08:03,330 --> 00:08:07,560
data and so it's a release in jupiter

00:08:04,949 --> 00:08:09,599
notebooks what that means is the input

00:08:07,560 --> 00:08:12,479
data of a notebook can vary you know

00:08:09,599 --> 00:08:13,830
greatly based on time and user and so

00:08:12,479 --> 00:08:15,120
one user who wants a notebook may have

00:08:13,830 --> 00:08:17,310
different access than authorities and

00:08:15,120 --> 00:08:18,509
another user even though they're within

00:08:17,310 --> 00:08:21,210
our community even though they have the

00:08:18,509 --> 00:08:24,300
same kind of in a level of

00:08:21,210 --> 00:08:26,159
classification access on the compliance

00:08:24,300 --> 00:08:27,780
side also goes along with some of the

00:08:26,159 --> 00:08:29,039
sensitivity aspects of that data we need

00:08:27,780 --> 00:08:32,520
to make sure that where we are

00:08:29,039 --> 00:08:33,899
processing this type of data meets our

00:08:32,520 --> 00:08:35,880
internal compliance for system

00:08:33,899 --> 00:08:37,260
accreditation we also do to make sure

00:08:35,880 --> 00:08:38,490
we're hearing to all of our legal and

00:08:37,260 --> 00:08:42,029
policy obligations and things like

00:08:38,490 --> 00:08:43,680
retention and oversight for that data so

00:08:42,029 --> 00:08:45,450
our approach here on the execution

00:08:43,680 --> 00:08:47,339
environment we can we supply a pre-built

00:08:45,450 --> 00:08:48,690
jupiter container to try to create a

00:08:47,339 --> 00:08:50,100
unified execution environment across

00:08:48,690 --> 00:08:51,420
this large user base to enable them to

00:08:50,100 --> 00:08:51,660
collaborate easier so they're operating

00:08:51,420 --> 00:08:53,879
in this

00:08:51,660 --> 00:08:55,139
environment the infrastructure from

00:08:53,879 --> 00:08:57,000
which we run that environment is a

00:08:55,139 --> 00:08:58,829
femoral personalized VM environment

00:08:57,000 --> 00:09:00,000
where the ephemeral and short-term

00:08:58,829 --> 00:09:01,709
nature really helps let's address some

00:09:00,000 --> 00:09:03,509
of those corporate compliance policies

00:09:01,709 --> 00:09:04,560
and the personalized nature it really

00:09:03,509 --> 00:09:06,959
helps us address the data security

00:09:04,560 --> 00:09:08,850
policy by ensuring that only that one

00:09:06,959 --> 00:09:10,800
user that may have unique authorizations

00:09:08,850 --> 00:09:12,779
you meet at unique accesses to see data

00:09:10,800 --> 00:09:15,389
is allowed in the environment from which

00:09:12,779 --> 00:09:16,860
they can see the notebook results and as

00:09:15,389 --> 00:09:18,360
an aside this ephemeral you know

00:09:16,860 --> 00:09:21,329
literally self-destructing environment

00:09:18,360 --> 00:09:23,579
actually places an even more emphasis on

00:09:21,329 --> 00:09:26,519
their reproducibility of a workflow

00:09:23,579 --> 00:09:27,870
because every time you do something new

00:09:26,519 --> 00:09:29,220
you could have a completely clean

00:09:27,870 --> 00:09:30,540
environment and so you know Jupiter

00:09:29,220 --> 00:09:31,970
notebooks really lends itself for that

00:09:30,540 --> 00:09:34,399
use case and the pairing of these two

00:09:31,970 --> 00:09:36,480
have been very kind of successful for us

00:09:34,399 --> 00:09:37,800
so what this does is it creates what we

00:09:36,480 --> 00:09:38,759
call Micro data science environment

00:09:37,800 --> 00:09:41,009
which is really perfect for that

00:09:38,759 --> 00:09:42,720
individual it gives them a place that is

00:09:41,009 --> 00:09:44,129
you know authorized and accredited to

00:09:42,720 --> 00:09:46,589
handle some very sensitive data to

00:09:44,129 --> 00:09:48,569
perform their analysis but it overlooks

00:09:46,589 --> 00:09:49,829
this larger community because we'll have

00:09:48,569 --> 00:09:51,300
hundreds of unique users kind of

00:09:49,829 --> 00:09:53,579
operating on these independent islands

00:09:51,300 --> 00:09:55,350
of data science that by design aren't

00:09:53,579 --> 00:09:57,630
configured to easily collaborate and

00:09:55,350 --> 00:10:00,029
share with each other so to overcome

00:09:57,630 --> 00:10:01,709
that our team has developed and B

00:10:00,029 --> 00:10:03,000
gallery or notebook gallery as an

00:10:01,709 --> 00:10:04,949
enterprise super drew notebook and

00:10:03,000 --> 00:10:07,649
sharing collaboration platform I note

00:10:04,949 --> 00:10:09,089
there it's only for the code because of

00:10:07,649 --> 00:10:11,970
that sensitivity to the data we don't

00:10:09,089 --> 00:10:13,889
want we can't allow you know a user who

00:10:11,970 --> 00:10:15,180
join a notebook to share the notebook

00:10:13,889 --> 00:10:16,139
with the results that other users who

00:10:15,180 --> 00:10:17,819
may not have the same levels of

00:10:16,139 --> 00:10:19,889
authorities in class and I know accesses

00:10:17,819 --> 00:10:21,240
that they may have we've open-sourced

00:10:19,889 --> 00:10:23,339
released that because you know not being

00:10:21,240 --> 00:10:24,779
kind of a beneficiary of open source we

00:10:23,339 --> 00:10:26,939
wanted to contribute back if and where

00:10:24,779 --> 00:10:28,259
we do have unique approaches that could

00:10:26,939 --> 00:10:30,600
be beneficial to the larger community

00:10:28,259 --> 00:10:32,339
and when M big gallery gives us is this

00:10:30,600 --> 00:10:34,889
kind of you know easy to use repository

00:10:32,339 --> 00:10:36,029
of community authored notebooks often

00:10:34,889 --> 00:10:37,259
within an enterprise when you're looking

00:10:36,029 --> 00:10:38,459
at how to share and collaborate on

00:10:37,259 --> 00:10:40,920
notebooks you look at something like an

00:10:38,459 --> 00:10:42,720
enterprise github or gitlab server but

00:10:40,920 --> 00:10:45,209
as that comment kind of depicts get as a

00:10:42,720 --> 00:10:46,350
as a tool even for those with you know

00:10:45,209 --> 00:10:47,809
strong data science a strong computer

00:10:46,350 --> 00:10:50,009
science backgrounds can still be

00:10:47,809 --> 00:10:51,509
troublesome at times and so you know

00:10:50,009 --> 00:10:52,680
trying to get that used by this analyst

00:10:51,509 --> 00:10:54,050
community that most likely they've never

00:10:52,680 --> 00:10:56,189
done any command-line development before

00:10:54,050 --> 00:10:57,600
we thought could potentially put some of

00:10:56,189 --> 00:11:00,809
these collaboration options out of reach

00:10:57,600 --> 00:11:01,860
for that community so this is what env

00:11:00,809 --> 00:11:03,420
gallery looks like just a web-based

00:11:01,860 --> 00:11:04,620
repository of our notebooks you can go

00:11:03,420 --> 00:11:05,190
in there and search for a notebook when

00:11:04,620 --> 00:11:06,750
you find

00:11:05,190 --> 00:11:08,010
and you're now just viewing a rendering

00:11:06,750 --> 00:11:09,540
of that notebook because it's only the

00:11:08,010 --> 00:11:11,700
code it's not any of the input data

00:11:09,540 --> 00:11:13,320
output results if you want to run that

00:11:11,700 --> 00:11:15,810
notebook now we need to tie together

00:11:13,320 --> 00:11:16,980
these decoupled environments so you have

00:11:15,810 --> 00:11:18,270
NB gallery there on the Left which is

00:11:16,980 --> 00:11:19,680
again only allowing the sharing of the

00:11:18,270 --> 00:11:20,820
code of the notebooks you click the

00:11:19,680 --> 00:11:22,050
little run and Jupiter banner if you

00:11:20,820 --> 00:11:23,610
were an analyst it would launch it over

00:11:22,050 --> 00:11:25,770
to that Jupiter execution environment

00:11:23,610 --> 00:11:27,420
now you're in a place where you actually

00:11:25,770 --> 00:11:28,470
again that personalized ephemeral VM

00:11:27,420 --> 00:11:30,360
environment where you can run that

00:11:28,470 --> 00:11:32,460
notebook you know get access to the data

00:11:30,360 --> 00:11:35,040
that again you may uniquely be

00:11:32,460 --> 00:11:36,540
authorized to see analyze the results if

00:11:35,040 --> 00:11:38,010
you write a new notebook or edit

00:11:36,540 --> 00:11:39,990
existing notebook or want to submit a

00:11:38,010 --> 00:11:41,250
change request for somebody else we

00:11:39,990 --> 00:11:42,060
added a jupiter extension in there so

00:11:41,250 --> 00:11:43,350
again you're not doing it for the

00:11:42,060 --> 00:11:46,020
command-line can do it through you know

00:11:43,350 --> 00:11:47,220
little web options and before that

00:11:46,020 --> 00:11:49,860
notebook leaves that environment we

00:11:47,220 --> 00:11:50,760
automatically strip out the results so

00:11:49,860 --> 00:11:52,440
that again we're not inadvertently

00:11:50,760 --> 00:11:53,700
sharing data to others who may not have

00:11:52,440 --> 00:11:56,760
the same level of authorities and

00:11:53,700 --> 00:11:58,380
accesses so that helps address some of

00:11:56,760 --> 00:12:00,660
these kind of compliance and data

00:11:58,380 --> 00:12:03,210
security challenges I'll spend the most

00:12:00,660 --> 00:12:04,620
you know part of this talk talking about

00:12:03,210 --> 00:12:05,940
what we're doing on the collaboration

00:12:04,620 --> 00:12:09,030
and user base sykes that's been a big

00:12:05,940 --> 00:12:10,470
area of focus for us and particularly

00:12:09,030 --> 00:12:11,970
collaborating at enterprise scale from

00:12:10,470 --> 00:12:13,950
our experience working on some other

00:12:11,970 --> 00:12:15,570
platforms we recognize that you know one

00:12:13,950 --> 00:12:17,160
of the side effects of crowdsourcing

00:12:15,570 --> 00:12:18,900
analytic solutions across a large

00:12:17,160 --> 00:12:20,310
enterprise is you could end up with a

00:12:18,900 --> 00:12:22,470
high volume of solutions as well as

00:12:20,310 --> 00:12:23,880
potentially redundant solutions or

00:12:22,470 --> 00:12:25,440
through no fault of their own users in

00:12:23,880 --> 00:12:27,450
different locations or different offices

00:12:25,440 --> 00:12:28,800
are trying to answer the same question

00:12:27,450 --> 00:12:30,540
and not realizing that they're they're

00:12:28,800 --> 00:12:31,950
both working on it and so they end up

00:12:30,540 --> 00:12:33,270
creating you know just more solution

00:12:31,950 --> 00:12:33,990
more solutions that are actually needed

00:12:33,270 --> 00:12:36,750
for that problem

00:12:33,990 --> 00:12:38,940
so we try to address this in two ways we

00:12:36,750 --> 00:12:40,470
have an effort focused on recommender

00:12:38,940 --> 00:12:41,940
analytics to help analysts easily

00:12:40,470 --> 00:12:44,910
discover notebooks that are relevant to

00:12:41,940 --> 00:12:46,200
them often from within the community and

00:12:44,910 --> 00:12:48,390
we have another effort really focused on

00:12:46,200 --> 00:12:49,950
notebook health that tries to provide

00:12:48,390 --> 00:12:51,360
insight to the user of whether that

00:12:49,950 --> 00:12:54,360
notebook is still functioning and it

00:12:51,360 --> 00:12:55,500
still can be expected to run in the in

00:12:54,360 --> 00:12:57,750
its current environments I'll talk a

00:12:55,500 --> 00:12:58,920
little bit detail about both of these on

00:12:57,750 --> 00:13:00,690
the recommender side this is not a

00:12:58,920 --> 00:13:02,670
unique approach to that problem

00:13:00,690 --> 00:13:04,080
obviously there's many great companies

00:13:02,670 --> 00:13:05,820
out there built around recommending

00:13:04,080 --> 00:13:07,080
products services and movies to people

00:13:05,820 --> 00:13:09,480
we just want to do the same thing with

00:13:07,080 --> 00:13:11,070
notebooks so we've written a series of

00:13:09,480 --> 00:13:13,290
analytics that kind of fall into these

00:13:11,070 --> 00:13:14,610
three categories so look at notebook

00:13:13,290 --> 00:13:16,710
usage things like the trendiness

00:13:14,610 --> 00:13:17,880
of that notebook and notebook health

00:13:16,710 --> 00:13:19,029
which I'll talk in more detail about in

00:13:17,880 --> 00:13:20,590
a little bit

00:13:19,029 --> 00:13:21,880
we have a series of non-personalized

00:13:20,590 --> 00:13:23,980
recommendations things like content

00:13:21,880 --> 00:13:25,960
similarity and user also viewed that we

00:13:23,980 --> 00:13:27,370
measure and then we have a series of

00:13:25,960 --> 00:13:29,440
personalized recommendations where we

00:13:27,370 --> 00:13:31,320
look for similar users to the active

00:13:29,440 --> 00:13:33,670
user within our enterprise environment

00:13:31,320 --> 00:13:35,200
where we have organizational information

00:13:33,670 --> 00:13:36,250
and our organization is going to lend

00:13:35,200 --> 00:13:38,230
themselves to a higher core

00:13:36,250 --> 00:13:40,270
organizational structure we can

00:13:38,230 --> 00:13:42,220
recommend notebooks based on being in an

00:13:40,270 --> 00:13:44,650
organization or a parent or child or

00:13:42,220 --> 00:13:45,850
sister type organization we also

00:13:44,650 --> 00:13:47,140
hard-code notebooks that we think are

00:13:45,850 --> 00:13:49,270
beneficial for new users as a

00:13:47,140 --> 00:13:50,650
recommender so if we recognize that

00:13:49,270 --> 00:13:52,029
you're new to the platform things like

00:13:50,650 --> 00:13:53,470
you know intro to Jupiter intro to

00:13:52,029 --> 00:13:55,330
Python will probably come up in your

00:13:53,470 --> 00:13:56,500
recommended feed and we have a white

00:13:55,330 --> 00:13:58,120
paper that we published if you want to

00:13:56,500 --> 00:13:59,650
be in more detail that goes into that

00:13:58,120 --> 00:14:01,060
the paper goes into much more technical

00:13:59,650 --> 00:14:04,420
detail obviously about what we're doing

00:14:01,060 --> 00:14:05,440
in that regard but how the results of

00:14:04,420 --> 00:14:06,850
these recommender analytics are

00:14:05,440 --> 00:14:08,020
displayed to the users is you come to

00:14:06,850 --> 00:14:08,830
the home page and on the Left that's a

00:14:08,020 --> 00:14:10,720
little snippet of what the home page

00:14:08,830 --> 00:14:12,430
looks like you get kind of aggregate

00:14:10,720 --> 00:14:14,650
results of these analytics so you're

00:14:12,430 --> 00:14:15,910
seeing notebooks that are recommended

00:14:14,650 --> 00:14:17,200
you know based on your previous

00:14:15,910 --> 00:14:19,240
interactions your interest and

00:14:17,200 --> 00:14:21,339
potentially your your role in the

00:14:19,240 --> 00:14:22,930
organization right there on the home

00:14:21,339 --> 00:14:24,400
page and then every time you view a

00:14:22,930 --> 00:14:26,320
notebook we give you the kind of sliding

00:14:24,400 --> 00:14:28,839
bars of recommender is based on content

00:14:26,320 --> 00:14:31,740
similarity of notebooks and that kind of

00:14:28,839 --> 00:14:35,200
user also viewed view the note

00:14:31,740 --> 00:14:37,810
recommenders a notebook health side this

00:14:35,200 --> 00:14:39,640
was another big priority for us because

00:14:37,810 --> 00:14:41,380
the challenge here is that users users

00:14:39,640 --> 00:14:42,880
who discover and run broken notebooks

00:14:41,380 --> 00:14:44,350
will tend to think that they did

00:14:42,880 --> 00:14:45,910
something wrong or the system doesn't

00:14:44,350 --> 00:14:48,100
work and they lose confidence and one or

00:14:45,910 --> 00:14:49,510
the other or both which is an outcome we

00:14:48,100 --> 00:14:51,010
want to avoid particularly when we're

00:14:49,510 --> 00:14:53,230
trying to adopt this to use your base

00:14:51,010 --> 00:14:55,540
that is new to you know this type of

00:14:53,230 --> 00:14:56,950
kind of technical development and so how

00:14:55,540 --> 00:14:57,790
do we define notebook health where we're

00:14:56,950 --> 00:14:59,650
saying notebook health is the

00:14:57,790 --> 00:15:02,140
expectation that a notebook runs in its

00:14:59,650 --> 00:15:03,820
current environment our use case because

00:15:02,140 --> 00:15:05,230
of that sensitivity of data and the

00:15:03,820 --> 00:15:07,480
fine-grained data security rules that we

00:15:05,230 --> 00:15:09,790
have doesn't lends itself to kind of

00:15:07,480 --> 00:15:12,550
automated tests so we had to define a

00:15:09,790 --> 00:15:13,900
system to kind of passively monitor the

00:15:12,550 --> 00:15:15,130
performance of a notebook and infer

00:15:13,900 --> 00:15:17,589
whether or not we think that notebook is

00:15:15,130 --> 00:15:19,959
healthy we use the results of this

00:15:17,589 --> 00:15:21,520
notebook health I mentioned earlier on a

00:15:19,959 --> 00:15:24,070
recommenders because as much as possible

00:15:21,520 --> 00:15:25,839
we want to put notebooks in front of

00:15:24,070 --> 00:15:27,070
users that we believe are healthy and

00:15:25,839 --> 00:15:29,250
then not lead them down a path of

00:15:27,070 --> 00:15:31,170
finding notebooks that we have

00:15:29,250 --> 00:15:34,020
the inference is at least that it's not

00:15:31,170 --> 00:15:35,130
currently functioning all right so how

00:15:34,020 --> 00:15:37,230
do we measure a notebook health whatever

00:15:35,130 --> 00:15:38,790
mean my notebook healthier well first

00:15:37,230 --> 00:15:40,230
and foremost a notebook is only healthy

00:15:38,790 --> 00:15:42,150
at the individual code cells that make

00:15:40,230 --> 00:15:45,300
up that notebook is healthy and so we

00:15:42,150 --> 00:15:46,980
measure that by recording the execution

00:15:45,300 --> 00:15:49,830
status of every cell of every notebook

00:15:46,980 --> 00:15:51,750
within that you know femoral VM compute

00:15:49,830 --> 00:15:53,190
environment because of the data

00:15:51,750 --> 00:15:55,050
sensitivity concerns that we have we

00:15:53,190 --> 00:15:56,630
can't get a lot of granularity out of

00:15:55,050 --> 00:15:58,700
the execution so we're just measuring

00:15:56,630 --> 00:16:00,600
did that notebook throw an exception

00:15:58,700 --> 00:16:01,800
there's a talk earlier today where they

00:16:00,600 --> 00:16:03,150
talked about you know tapping into zero

00:16:01,800 --> 00:16:05,190
and zero i'm cue to get you know much

00:16:03,150 --> 00:16:07,710
more detailed information about the

00:16:05,190 --> 00:16:10,650
execution status of each cell but again

00:16:07,710 --> 00:16:11,700
with our use case we can't do that

00:16:10,650 --> 00:16:12,960
so we're just looking at whether or not

00:16:11,700 --> 00:16:14,520
through an exception which is you know a

00:16:12,960 --> 00:16:15,780
bit of a course look but it's enough for

00:16:14,520 --> 00:16:16,970
us to kind of make some inferences of

00:16:15,780 --> 00:16:19,920
whether or not we think that's healthy

00:16:16,970 --> 00:16:21,150
look to look for things of like how far

00:16:19,920 --> 00:16:22,800
the user makes it into that notebook

00:16:21,150 --> 00:16:24,150
because generally speaking notebooks

00:16:22,800 --> 00:16:26,520
meant to be run kind of linearly from

00:16:24,150 --> 00:16:27,870
top to bottom so that the more cells the

00:16:26,520 --> 00:16:29,700
user is executing the notebook the more

00:16:27,870 --> 00:16:30,780
likely it is that they think that

00:16:29,700 --> 00:16:33,240
notebook is healthy and they're happy

00:16:30,780 --> 00:16:34,830
with its progress and its results we

00:16:33,240 --> 00:16:37,470
also looked to see how many unique users

00:16:34,830 --> 00:16:40,560
and how many how many number of times a

00:16:37,470 --> 00:16:42,630
user has run that notebook again because

00:16:40,560 --> 00:16:45,780
of that data sensitivity challenge that

00:16:42,630 --> 00:16:47,520
keep coming back to a notebook that

00:16:45,780 --> 00:16:48,630
works for one user may not work for a

00:16:47,520 --> 00:16:49,820
different user who has different levels

00:16:48,630 --> 00:16:52,620
of accesses the different authorities

00:16:49,820 --> 00:16:54,120
and so the more people you new people we

00:16:52,620 --> 00:16:56,010
see running a notebook the more

00:16:54,120 --> 00:16:57,420
confidence we gain that that notebook is

00:16:56,010 --> 00:16:59,490
kind of healthy in a general sense as

00:16:57,420 --> 00:17:00,810
opposed to just working for the that one

00:16:59,490 --> 00:17:03,360
user and it's kind of unique sets of

00:17:00,810 --> 00:17:04,949
authorities and then lastly we looked at

00:17:03,360 --> 00:17:06,720
how recently that notebook was executed

00:17:04,949 --> 00:17:09,270
because we operate in a dynamic

00:17:06,720 --> 00:17:10,770
enterprise IT environment where api's

00:17:09,270 --> 00:17:13,110
might change data formats might change

00:17:10,770 --> 00:17:14,280
and other things might change so the

00:17:13,110 --> 00:17:15,839
more recent we've seen a notebook

00:17:14,280 --> 00:17:18,300
successfully executed the more confident

00:17:15,839 --> 00:17:19,740
we are and the longer it's been the less

00:17:18,300 --> 00:17:21,209
confident we are so in practice that's a

00:17:19,740 --> 00:17:23,280
30-day window where we automatically

00:17:21,209 --> 00:17:25,260
decay the health of a notebook if we're

00:17:23,280 --> 00:17:27,120
not seeing it actively used over their

00:17:25,260 --> 00:17:28,590
30-day period and just like the

00:17:27,120 --> 00:17:29,850
recommenders we got a white paper on

00:17:28,590 --> 00:17:31,470
this if you want to go see more detail

00:17:29,850 --> 00:17:32,550
on it the price again much more

00:17:31,470 --> 00:17:35,340
technical detail about what we're doing

00:17:32,550 --> 00:17:37,800
there and then how is this presented to

00:17:35,340 --> 00:17:39,330
the user so every time you discover a

00:17:37,800 --> 00:17:40,740
notebook in MB gallery we put a little

00:17:39,330 --> 00:17:42,390
health icon there you can see it right

00:17:40,740 --> 00:17:43,980
here it's kind of green

00:17:42,390 --> 00:17:45,240
Green is healthy red is unhealthy Grey's

00:17:43,980 --> 00:17:46,560
unknown so they gets you know quick

00:17:45,240 --> 00:17:48,240
indication of whether we think that no

00:17:46,560 --> 00:17:49,410
Brooks healthy in addition they're kind

00:17:48,240 --> 00:17:52,140
of factoring into the recommenders

00:17:49,410 --> 00:17:53,910
analytics if you were to click that icon

00:17:52,140 --> 00:17:56,580
then you get a detailed breakdown of the

00:17:53,910 --> 00:17:58,800
execution status of that notebook over

00:17:56,580 --> 00:18:00,030
the last 30 days where this graph is

00:17:58,800 --> 00:18:02,280
showing you a kind of a cell by cell

00:18:00,030 --> 00:18:04,920
breakdown of all the executions we've

00:18:02,280 --> 00:18:06,210
observed for that notebook and some of

00:18:04,920 --> 00:18:07,860
the challenges we have given the diverse

00:18:06,210 --> 00:18:09,570
use case that we see for notebooks is

00:18:07,860 --> 00:18:11,490
that we need to take into account

00:18:09,570 --> 00:18:12,690
notebooks that might have intentionally

00:18:11,490 --> 00:18:13,890
failing cells because they're part of an

00:18:12,690 --> 00:18:16,950
education class that is meant to show

00:18:13,890 --> 00:18:18,810
you an exception we have taken account

00:18:16,950 --> 00:18:19,620
notebooks that have optional cells maybe

00:18:18,810 --> 00:18:21,450
kind of like a choose your own adventure

00:18:19,620 --> 00:18:23,310
type notebook where depending on who's

00:18:21,450 --> 00:18:24,600
running it they may want to you know out

00:18:23,310 --> 00:18:25,590
Porter and output it in different

00:18:24,600 --> 00:18:27,420
formats we're going to view it in

00:18:25,590 --> 00:18:28,830
different ways and we have to take into

00:18:27,420 --> 00:18:30,810
account notebooks that have external

00:18:28,830 --> 00:18:32,790
dependencies which again and the dynamic

00:18:30,810 --> 00:18:34,680
enterprise IT environment might you know

00:18:32,790 --> 00:18:36,030
have you know infrequent outages that

00:18:34,680 --> 00:18:38,940
will kind of show up in these execution

00:18:36,030 --> 00:18:41,220
status so we actually calculate almost a

00:18:38,940 --> 00:18:42,540
dozen I think unique health metrics

00:18:41,220 --> 00:18:44,640
which aggregate together for that

00:18:42,540 --> 00:18:46,170
overall health metric and again those

00:18:44,640 --> 00:18:49,020
are described in much more detail in

00:18:46,170 --> 00:18:51,600
that white paper if you want to see more

00:18:49,020 --> 00:18:53,430
information about it alright so next

00:18:51,600 --> 00:18:55,080
I'll talk about you know how we're you

00:18:53,430 --> 00:18:57,000
know adapting this to this user base

00:18:55,080 --> 00:18:58,260
through kind of efforts you know around

00:18:57,000 --> 00:19:00,000
kind of Python based training and

00:18:58,260 --> 00:19:02,820
outreach to get more users writing

00:19:00,000 --> 00:19:04,590
Python jupiter' notebooks and you know

00:19:02,820 --> 00:19:07,080
the high level we need to find a balance

00:19:04,590 --> 00:19:08,910
between the needs for training and this

00:19:07,080 --> 00:19:13,070
kind of demanding workload of our user

00:19:08,910 --> 00:19:15,900
base where you know it's and sometimes

00:19:13,070 --> 00:19:17,520
you know can't be expected that we can

00:19:15,900 --> 00:19:20,310
have them take you know days long a week

00:19:17,520 --> 00:19:21,420
long classes to try to learn some of

00:19:20,310 --> 00:19:22,350
these things because it takes them away

00:19:21,420 --> 00:19:24,080
from what were they really supposed to

00:19:22,350 --> 00:19:26,010
be doing as part of their their workload

00:19:24,080 --> 00:19:27,510
another thing to kind of take into

00:19:26,010 --> 00:19:28,620
account is that success in this case

00:19:27,510 --> 00:19:29,760
doesn't mean that we're necessarily

00:19:28,620 --> 00:19:32,370
creating a new kind of computer

00:19:29,760 --> 00:19:34,230
scientist or a new data scientist rather

00:19:32,370 --> 00:19:36,630
you know an analyst who can learn and

00:19:34,230 --> 00:19:38,850
use some code may still have kind of

00:19:36,630 --> 00:19:41,160
tangible benefits and may still be you

00:19:38,850 --> 00:19:42,420
know helpful for for a mission and it's

00:19:41,160 --> 00:19:44,090
kind of reflected in these quotes again

00:19:42,420 --> 00:19:45,830
from that same blog post from that

00:19:44,090 --> 00:19:48,030
analyst I talked about at the beginning

00:19:45,830 --> 00:19:49,560
what she mentions here learning to code

00:19:48,030 --> 00:19:51,360
is not you know a career shift but

00:19:49,560 --> 00:19:53,760
rather means that the better think about

00:19:51,360 --> 00:19:55,110
how to tackle her workflow and she also

00:19:53,760 --> 00:19:55,960
kind of commented that initially when

00:19:55,110 --> 00:19:58,450
she was approached with

00:19:55,960 --> 00:19:59,830
this idea of like you know try to learn

00:19:58,450 --> 00:20:01,930
Python to kind of help you write your

00:19:59,830 --> 00:20:03,730
own notebooks she was afraid that it'd

00:20:01,930 --> 00:20:06,430
be too big of a time commitment to learn

00:20:03,730 --> 00:20:07,420
enough Python to be beneficial but and

00:20:06,430 --> 00:20:09,120
she's talking about here she admitted

00:20:07,420 --> 00:20:11,740
that she was wrong about that and just

00:20:09,120 --> 00:20:14,350
even using some basic coding concepts

00:20:11,740 --> 00:20:15,610
and basic coding skills has helped her

00:20:14,350 --> 00:20:17,470
write notebooks that are having a

00:20:15,610 --> 00:20:18,850
tangible impact and help you know make

00:20:17,470 --> 00:20:22,090
her a workflow more efficient and more

00:20:18,850 --> 00:20:23,200
repeatable and so particular for us

00:20:22,090 --> 00:20:24,550
we've created this very lightweight

00:20:23,200 --> 00:20:26,320
course called intro to Python for

00:20:24,550 --> 00:20:27,940
analysis where its goal is to kind of

00:20:26,320 --> 00:20:29,800
demystify coding concepts for these

00:20:27,940 --> 00:20:31,360
non-traditional coders we think it

00:20:29,800 --> 00:20:33,730
addresses kind of a gap in some of the

00:20:31,360 --> 00:20:35,290
offerings where you know in many cases

00:20:33,730 --> 00:20:36,850
you know classes that we already have

00:20:35,290 --> 00:20:39,340
have this kind of by developer for

00:20:36,850 --> 00:20:40,630
developer mentality or they kind of jump

00:20:39,340 --> 00:20:43,240
right into some of the more kind of

00:20:40,630 --> 00:20:45,040
advanced data science topics where in

00:20:43,240 --> 00:20:46,720
many cases again kind of teaching them

00:20:45,040 --> 00:20:48,940
some you know initial basics can help

00:20:46,720 --> 00:20:50,920
them get started kind of improving their

00:20:48,940 --> 00:20:52,420
workflow we do it all through Jupiter

00:20:50,920 --> 00:20:54,280
notebooks obviously that are hosted in

00:20:52,420 --> 00:20:57,220
an B gallery kind of classroom model

00:20:54,280 --> 00:20:58,870
where analysts can kind of you know do

00:20:57,220 --> 00:21:01,810
some bite-sized chunks of learning you

00:20:58,870 --> 00:21:03,670
know alongside their regular kind of you

00:21:01,810 --> 00:21:05,530
know business tasks they have to be

00:21:03,670 --> 00:21:06,820
working on and we supplement that with

00:21:05,530 --> 00:21:08,410
kind of virtual and in-person mentoring

00:21:06,820 --> 00:21:10,360
sessions that we offer throughout our

00:21:08,410 --> 00:21:11,770
enterprise environment so if you want

00:21:10,360 --> 00:21:12,970
help on exercises if you want to kind of

00:21:11,770 --> 00:21:15,220
ask you know questions or you're

00:21:12,970 --> 00:21:16,990
struggling with something we have a you

00:21:15,220 --> 00:21:18,490
know always maintain virtual presence as

00:21:16,990 --> 00:21:20,170
well as a you know in-person presence

00:21:18,490 --> 00:21:21,580
and a variety of locations that you can

00:21:20,170 --> 00:21:22,860
come in and talk with the mentor how can

00:21:21,580 --> 00:21:24,580
I help resolve some of those problems

00:21:22,860 --> 00:21:26,950
and this is always been you know

00:21:24,580 --> 00:21:28,540
beneficial benefited from this

00:21:26,950 --> 00:21:30,640
grassroots kind of community level

00:21:28,540 --> 00:21:31,840
support we don't have really any kind of

00:21:30,640 --> 00:21:33,460
official resources for this we just have

00:21:31,840 --> 00:21:35,560
a vast network of volunteers within our

00:21:33,460 --> 00:21:36,880
enterprise because what we found and

00:21:35,560 --> 00:21:38,260
what I imagine a lot of enterprises will

00:21:36,880 --> 00:21:40,000
have is there are plenty of people who

00:21:38,260 --> 00:21:41,260
are passionate about Python or

00:21:40,000 --> 00:21:44,050
passionate about data science that are

00:21:41,260 --> 00:21:45,520
more than willing to you know help other

00:21:44,050 --> 00:21:47,500
users within their enterprise kind of

00:21:45,520 --> 00:21:48,910
you know uh you know improve their

00:21:47,500 --> 00:21:50,710
workflows and gain efficiencies and so

00:21:48,910 --> 00:21:51,820
we've been able to kind of tap in give

00:21:50,710 --> 00:21:52,780
them the size of organization there's a

00:21:51,820 --> 00:21:55,600
number of people out there that would be

00:21:52,780 --> 00:21:57,730
able to benefit from their help as a

00:21:55,600 --> 00:21:59,140
little aside to kind of support this use

00:21:57,730 --> 00:22:00,820
case of his on-demand self-paced

00:21:59,140 --> 00:22:03,700
training we created a little Jupiter

00:22:00,820 --> 00:22:05,770
extension called Ordo which provides

00:22:03,700 --> 00:22:06,820
kind of feedback to the user while

00:22:05,770 --> 00:22:07,360
you're running a notebook or whether or

00:22:06,820 --> 00:22:09,480
not you got

00:22:07,360 --> 00:22:12,310
an exercise right if it is a kind of a

00:22:09,480 --> 00:22:14,140
deterministic exercise fun fact about

00:22:12,310 --> 00:22:15,580
that we had a West Point cadet who

00:22:14,140 --> 00:22:18,160
worked for us over the summer created

00:22:15,580 --> 00:22:20,200
and he has now graduated and he is a

00:22:18,160 --> 00:22:22,330
officer in the Army and an infantry unit

00:22:20,200 --> 00:22:24,730
but he created that capability for us

00:22:22,330 --> 00:22:26,320
last summer which is pretty cool another

00:22:24,730 --> 00:22:27,940
thing we did to adopt this to our user

00:22:26,320 --> 00:22:29,320
base is we provide metrics to these

00:22:27,940 --> 00:22:32,890
users that they can use to kind of help

00:22:29,320 --> 00:22:34,180
gain confidence and help kind of a you

00:22:32,890 --> 00:22:35,380
know reinforce the value and the

00:22:34,180 --> 00:22:37,150
contributions they're having within our

00:22:35,380 --> 00:22:38,500
community and so these are metrics that

00:22:37,150 --> 00:22:40,000
show things like the number of unique

00:22:38,500 --> 00:22:42,100
users that have run their notebooks

00:22:40,000 --> 00:22:42,910
within our environment and this quote

00:22:42,100 --> 00:22:44,740
here this is actually from a different

00:22:42,910 --> 00:22:46,570
user system not the same blog post I've

00:22:44,740 --> 00:22:47,710
quoted a number of times already

00:22:46,570 --> 00:22:49,030
but they're saying you know this may

00:22:47,710 --> 00:22:50,830
seem like a little thing on its face and

00:22:49,030 --> 00:22:51,730
I certainly you can understand if you're

00:22:50,830 --> 00:22:53,260
looking at that and saying this seems

00:22:51,730 --> 00:22:55,480
small but within an enterprise

00:22:53,260 --> 00:22:59,140
environment these metrics really do help

00:22:55,480 --> 00:23:00,880
users again gain gain value and gain

00:22:59,140 --> 00:23:02,340
understanding of how their contributions

00:23:00,880 --> 00:23:05,050
are contributing to others across the

00:23:02,340 --> 00:23:06,700
environment and so much so that you know

00:23:05,050 --> 00:23:09,070
we put the stop-start time in there to

00:23:06,700 --> 00:23:11,020
enable users for like performance review

00:23:09,070 --> 00:23:12,460
season to go in there and kind of pick

00:23:11,020 --> 00:23:15,160
the metrics to say you know during this

00:23:12,460 --> 00:23:16,390
six-month 12 month period I've written X

00:23:15,160 --> 00:23:18,520
number of notebooks that have you know

00:23:16,390 --> 00:23:20,350
benefited Y number of users across Z

00:23:18,520 --> 00:23:21,880
number of organizations right showing

00:23:20,350 --> 00:23:23,230
that they're having a bigger impact than

00:23:21,880 --> 00:23:25,510
just locally in their office and they're

00:23:23,230 --> 00:23:27,070
a part of this in a larger community of

00:23:25,510 --> 00:23:30,880
people who are writing as analytics and

00:23:27,070 --> 00:23:50,320
submitting these analytics I can wait to

00:23:30,880 --> 00:23:51,850
the end idea now yeah oh no I'm seeing a

00:23:50,320 --> 00:23:53,620
feedback loop as kind of encouraging

00:23:51,850 --> 00:23:55,060
them to be an active contributor

00:23:53,620 --> 00:23:56,770
maintainer so to speak if somebody's

00:23:55,060 --> 00:23:59,020
notebooks and just again kind of

00:23:56,770 --> 00:24:00,760
recognizing that they can have some

00:23:59,020 --> 00:24:02,860
impact beyond like the one office

00:24:00,760 --> 00:24:05,290
they're in right and potentially you

00:24:02,860 --> 00:24:06,460
know this can fuel like more

00:24:05,290 --> 00:24:07,810
collaboration options because they can

00:24:06,460 --> 00:24:09,580
they can recognize oh there are people

00:24:07,810 --> 00:24:11,940
out there in this universe that are

00:24:09,580 --> 00:24:13,840
using my same you know notebook right

00:24:11,940 --> 00:24:16,540
alright so talk about results in use

00:24:13,840 --> 00:24:18,820
here current status dimension before

00:24:16,540 --> 00:24:20,899
right thousands of users of Jupiter

00:24:18,820 --> 00:24:23,029
notebooks within earned by

00:24:20,899 --> 00:24:24,649
they have authored thousands of

00:24:23,029 --> 00:24:26,450
notebooks and about only in the hundreds

00:24:24,649 --> 00:24:28,250
of authors and it's actually this ten to

00:24:26,450 --> 00:24:29,570
one ratio of notebook users to authors

00:24:28,250 --> 00:24:32,299
and that happens because of that data

00:24:29,570 --> 00:24:34,309
sensitivity where we need users to run

00:24:32,299 --> 00:24:37,100
notebooks under their own kind of

00:24:34,309 --> 00:24:38,299
persona and other own accreditation and

00:24:37,100 --> 00:24:39,529
accesses because they may get different

00:24:38,299 --> 00:24:41,389
results than the author might have

00:24:39,529 --> 00:24:44,000
gotten because they may again have

00:24:41,389 --> 00:24:54,379
unique accesses and authorities there's

00:24:44,000 --> 00:25:06,980
Grafton I don't know if I know jiffy

00:24:54,379 --> 00:25:07,909
sorry oh yeah so I mean this is all this

00:25:06,980 --> 00:25:09,830
is all within the intelligence community

00:25:07,909 --> 00:25:11,960
sis is all on our classified networks

00:25:09,830 --> 00:25:13,429
and probably not like it's only

00:25:11,960 --> 00:25:15,379
accessible like the data up so he's not

00:25:13,429 --> 00:25:18,139
accessible to be download or anything

00:25:15,379 --> 00:25:19,220
else all right so the bottom there the

00:25:18,139 --> 00:25:20,210
graphs are just showing the kind of rate

00:25:19,220 --> 00:25:22,190
of adoption we've had over the last

00:25:20,210 --> 00:25:23,179
three years so on the left there you're

00:25:22,190 --> 00:25:25,250
seeing the total number of cumulative

00:25:23,179 --> 00:25:26,210
notebooks we've written off there within

00:25:25,250 --> 00:25:27,590
our community and the right you're

00:25:26,210 --> 00:25:29,539
seeing the total number of unique users

00:25:27,590 --> 00:25:31,129
per month and what's interesting

00:25:29,539 --> 00:25:32,480
interesting to note is you may have seen

00:25:31,129 --> 00:25:34,279
this tweak and ap2 print they put this

00:25:32,480 --> 00:25:37,279
out there of the 2.6 million notebooks

00:25:34,279 --> 00:25:39,019
that are currently publicly available in

00:25:37,279 --> 00:25:40,070
github and that goes longer than the

00:25:39,019 --> 00:25:41,529
last three years but I think it's the

00:25:40,070 --> 00:25:43,519
last three-and-a-half run was four years

00:25:41,529 --> 00:25:45,019
but it was interesting to note for us

00:25:43,519 --> 00:25:46,669
that those graphs kind of hosts are

00:25:45,019 --> 00:25:49,070
somewhat similar as far as the rate of

00:25:46,669 --> 00:25:50,419
adoption and being inside of a large

00:25:49,070 --> 00:25:51,769
bureaucratic organization inside of

00:25:50,419 --> 00:25:53,360
government right we're not always the

00:25:51,769 --> 00:25:55,639
quickest adopters of new technology and

00:25:53,360 --> 00:25:57,950
so to have that be even close to being

00:25:55,639 --> 00:26:00,230
similar I think is pretty awesome on our

00:25:57,950 --> 00:26:01,610
part so on the use cases side we have

00:26:00,230 --> 00:26:02,899
these three high level use cases right

00:26:01,610 --> 00:26:04,070
kind of the you know burying the lede

00:26:02,899 --> 00:26:05,120
here at the end like this is what we're

00:26:04,070 --> 00:26:07,039
actually using Jupiter notebooks for

00:26:05,120 --> 00:26:08,450
this operational use cases course

00:26:07,039 --> 00:26:10,820
material use case in this building block

00:26:08,450 --> 00:26:12,200
use case on the operational side because

00:26:10,820 --> 00:26:13,370
the sensitivity is obviously about some

00:26:12,200 --> 00:26:15,139
of the work here I can't go into much

00:26:13,370 --> 00:26:18,799
detail how to redact the whole notebook

00:26:15,139 --> 00:26:20,750
here but they kind of share three

00:26:18,799 --> 00:26:23,299
high-level categories right or three

00:26:20,750 --> 00:26:24,529
high-level aspects they support a

00:26:23,299 --> 00:26:26,210
particular business mission function

00:26:24,529 --> 00:26:28,369
again helping that analyst drive insight

00:26:26,210 --> 00:26:30,049
from their data they'll use data from

00:26:28,369 --> 00:26:32,539
corporate repositories that they access

00:26:30,049 --> 00:26:33,290
over api's which in most cases almost

00:26:32,539 --> 00:26:35,300
all cases

00:26:33,290 --> 00:26:36,680
prompts the users for query input so we

00:26:35,300 --> 00:26:38,570
have this kind of flip model of

00:26:36,680 --> 00:26:40,100
interaction with notebooks where all of

00:26:38,570 --> 00:26:41,900
our analysts are generally interacting

00:26:40,100 --> 00:26:43,400
in the notebook at the very beginning of

00:26:41,900 --> 00:26:45,140
it as opposed to kind of interacting at

00:26:43,400 --> 00:26:46,700
the end or in addition to sorry

00:26:45,140 --> 00:26:47,390
interacting at the end with widgets that

00:26:46,700 --> 00:26:49,760
kind of you know look at the

00:26:47,390 --> 00:26:51,230
visualizations and so we're heavy users

00:26:49,760 --> 00:26:53,990
of iPad which is to create kind of user

00:26:51,230 --> 00:26:56,150
friendly forms to query a notebook

00:26:53,990 --> 00:26:57,620
because we'll have acquired query

00:26:56,150 --> 00:27:00,890
parameters that the user will need to

00:26:57,620 --> 00:27:02,000
enter in order to run that notebook all

00:27:00,890 --> 00:27:03,470
right second use case here is course

00:27:02,000 --> 00:27:04,580
material there's a whole track obviously

00:27:03,470 --> 00:27:06,500
on the benefits of Jupiter with an

00:27:04,580 --> 00:27:08,870
education certainly within an enterprise

00:27:06,500 --> 00:27:11,210
we benefit from the notebook format as a

00:27:08,870 --> 00:27:12,770
means for teaching coding but you know

00:27:11,210 --> 00:27:14,120
and we teach formal until the Python

00:27:12,770 --> 00:27:15,500
classes I mentioned that internet Python

00:27:14,120 --> 00:27:17,930
for analysis class taught to Jupiter

00:27:15,500 --> 00:27:19,400
notebooks but the other major benefit we

00:27:17,930 --> 00:27:21,110
get the enterprise level from teaching

00:27:19,400 --> 00:27:23,690
in jupiter notebooks is that is the

00:27:21,110 --> 00:27:25,220
exact same platform that users can apply

00:27:23,690 --> 00:27:27,470
that knowledge for kind of business or

00:27:25,220 --> 00:27:28,820
operational purposes right so we really

00:27:27,470 --> 00:27:30,260
kind of reduce the barriers between the

00:27:28,820 --> 00:27:32,210
learn and apply because they come into a

00:27:30,260 --> 00:27:33,590
class they're learning in that same

00:27:32,210 --> 00:27:35,810
platform they can immediately go and

00:27:33,590 --> 00:27:38,630
apply that to to their use case and

00:27:35,810 --> 00:27:40,700
they're their daily analysis and then

00:27:38,630 --> 00:27:42,080
thirdly here this use case does grown

00:27:40,700 --> 00:27:44,330
organically really over the last three

00:27:42,080 --> 00:27:45,860
years we call building blocks and it's

00:27:44,330 --> 00:27:47,660
where our users are finding a lot of

00:27:45,860 --> 00:27:49,550
value in sharing reproducible code

00:27:47,660 --> 00:27:52,610
snippets for others within the community

00:27:49,550 --> 00:27:54,140
so these notebooks may not almost in all

00:27:52,610 --> 00:27:55,910
cases don't touch any of our kind of

00:27:54,140 --> 00:27:57,470
corporate data for the purposes of

00:27:55,910 --> 00:27:59,930
actually doing analysis they're not part

00:27:57,470 --> 00:28:01,430
of formal training series but they're

00:27:59,930 --> 00:28:02,540
just sharing you know here's how to use

00:28:01,430 --> 00:28:04,120
this library here's how to create this

00:28:02,540 --> 00:28:06,230
visualization here's how to do something

00:28:04,120 --> 00:28:07,790
which could be even as fun as this

00:28:06,230 --> 00:28:10,280
little ASCII art generator which as an

00:28:07,790 --> 00:28:12,620
aside is the first notebook I show a new

00:28:10,280 --> 00:28:14,240
analyst because it provides kind of

00:28:12,620 --> 00:28:15,950
immediate gratification that you've run

00:28:14,240 --> 00:28:18,200
some code and something happens you see

00:28:15,950 --> 00:28:19,970
some output from it and it's broadly

00:28:18,200 --> 00:28:21,290
applicable to everybody right it's not

00:28:19,970 --> 00:28:23,980
kind of restricted to a use case or

00:28:21,290 --> 00:28:23,980
something like that yes

00:28:27,990 --> 00:28:32,049
yeah so on the curation side that's

00:28:30,580 --> 00:28:33,370
something we're actively working right

00:28:32,049 --> 00:28:35,169
now so we're treating it as another

00:28:33,370 --> 00:28:37,870
recommender problem where we look at the

00:28:35,169 --> 00:28:39,700
user base and say you know for this

00:28:37,870 --> 00:28:42,039
given notebook what other author in our

00:28:39,700 --> 00:28:44,169
community will be maybe best suited to

00:28:42,039 --> 00:28:45,909
do that and so that's part of looking at

00:28:44,169 --> 00:28:47,799
you know shared library use and shared

00:28:45,909 --> 00:28:49,150
you know even user base of eight

00:28:47,799 --> 00:28:51,280
somewhere in similar organizations some

00:28:49,150 --> 00:28:53,020
of their mission functions but it's also

00:28:51,280 --> 00:28:54,250
the result of an author contribution

00:28:53,020 --> 00:28:55,270
score metric that we calculate so you

00:28:54,250 --> 00:28:56,590
can't really see it here but there's a

00:28:55,270 --> 00:28:59,049
little icon next to the redacted

00:28:56,590 --> 00:29:01,270
person's name this one here is goal they

00:28:59,049 --> 00:29:03,220
think so they they're you know the top

00:29:01,270 --> 00:29:04,630
ten percentile of authors right and so

00:29:03,220 --> 00:29:07,150
that gets boosted for that recommenders

00:29:04,630 --> 00:29:09,280
as a way to potentially say these are

00:29:07,150 --> 00:29:11,110
the potential best suitors for viewing a

00:29:09,280 --> 00:29:12,940
notebook so we're working on it because

00:29:11,110 --> 00:29:14,740
that also has a challenge with the scale

00:29:12,940 --> 00:29:17,919
of this but don't have it fully out

00:29:14,740 --> 00:29:20,919
there yet all right so one thing we did

00:29:17,919 --> 00:29:22,480
is actually try to analyze what what's

00:29:20,919 --> 00:29:25,120
the breakdown of the number of notebooks

00:29:22,480 --> 00:29:26,440
we see within these three use cases and

00:29:25,120 --> 00:29:28,539
what's kind of interesting about this is

00:29:26,440 --> 00:29:30,070
it's almost 50/50 right half the

00:29:28,539 --> 00:29:31,720
notebooks that our users are writing are

00:29:30,070 --> 00:29:33,580
meant for that kind of operational use

00:29:31,720 --> 00:29:35,650
case to help them do their analysis the

00:29:33,580 --> 00:29:37,150
other half is supporting the education

00:29:35,650 --> 00:29:39,250
use case of helping them better do the

00:29:37,150 --> 00:29:40,659
analysis so the combination of the

00:29:39,250 --> 00:29:43,419
formal course materials or these

00:29:40,659 --> 00:29:45,520
informal building blocks that ultimately

00:29:43,419 --> 00:29:47,770
are meant to support that the

00:29:45,520 --> 00:29:48,760
operational use case all right so lastly

00:29:47,770 --> 00:29:50,380
cuz I think that's all the time here

00:29:48,760 --> 00:29:52,630
I'll talk about the one future effort we

00:29:50,380 --> 00:29:54,549
have looking at how to use Jupiter and

00:29:52,630 --> 00:29:56,200
that is kind of mirroring this use case

00:29:54,549 --> 00:29:58,600
for using Jupiter for reporting and

00:29:56,200 --> 00:29:59,830
dissemination right so you know we heard

00:29:58,600 --> 00:30:01,750
about office this morning the the

00:29:59,830 --> 00:30:04,390
awesome presentation from the guy works

00:30:01,750 --> 00:30:05,919
with Lego and there was these the

00:30:04,390 --> 00:30:07,600
article in the Atlantic and the Paul

00:30:05,919 --> 00:30:09,690
Romer blogpost talking about the impact

00:30:07,600 --> 00:30:12,400
that Jupiter is having within the

00:30:09,690 --> 00:30:14,020
scientific publication market there's

00:30:12,400 --> 00:30:15,549
also now some really exciting news apps

00:30:14,020 --> 00:30:17,380
we saw from the keynote from the guy

00:30:15,549 --> 00:30:18,370
from Columbia but there's you know the

00:30:17,380 --> 00:30:19,750
use now would you Purdue with in

00:30:18,370 --> 00:30:22,299
journalism so there's this LA Times

00:30:19,750 --> 00:30:24,340
article from like a month or two ago to

00:30:22,299 --> 00:30:26,169
use Jupiter can again provide tradecraft

00:30:24,340 --> 00:30:27,039
transparency and how your reporting out

00:30:26,169 --> 00:30:28,929
data

00:30:27,039 --> 00:30:30,370
well the IC has that same problem right

00:30:28,929 --> 00:30:32,559
we have these individual intelligence

00:30:30,370 --> 00:30:34,929
agencies that have unique authorities

00:30:32,559 --> 00:30:36,730
and unique data and their analysts the

00:30:34,929 --> 00:30:38,289
job of them is to analyze that data and

00:30:36,730 --> 00:30:39,970
report out the results for other members

00:30:38,289 --> 00:30:41,530
of the IC as well as

00:30:39,970 --> 00:30:42,700
these you know all Soros analysts are

00:30:41,530 --> 00:30:43,570
trying to you know to kind of finally

00:30:42,700 --> 00:30:46,690
kind of piece together all this

00:30:43,570 --> 00:30:48,130
information into one view of it and we

00:30:46,690 --> 00:30:50,200
think Jupiter could potentially have a

00:30:48,130 --> 00:30:51,490
similar impact where it would enable us

00:30:50,200 --> 00:30:53,910
to provide more kind of tradecraft

00:30:51,490 --> 00:30:56,080
transparency into that analysis

00:30:53,910 --> 00:30:57,550
especially as that analysis is becoming

00:30:56,080 --> 00:30:59,500
you know more data and computationally

00:30:57,550 --> 00:31:01,870
intensive and so we're looking at these

00:30:59,500 --> 00:31:03,250
this use case that's developing it's

00:31:01,870 --> 00:31:04,450
already developed externally for using

00:31:03,250 --> 00:31:05,470
Jupiter for that and and we're now

00:31:04,450 --> 00:31:08,710
thinking we could potentially do

00:31:05,470 --> 00:31:10,390
something similar but will have all the

00:31:08,710 --> 00:31:11,800
same challenges of data access and

00:31:10,390 --> 00:31:13,840
collaboration and and compliance and all

00:31:11,800 --> 00:31:15,940
those other things so there's a lot to

00:31:13,840 --> 00:31:16,870
love to be do on that but you know we've

00:31:15,940 --> 00:31:19,480
sort of thinking about that which is

00:31:16,870 --> 00:31:21,070
kind of interesting exciting I think and

00:31:19,480 --> 00:31:23,770
so with that I think I'm almost out of

00:31:21,070 --> 00:31:25,240
time okay take any questions or okay

00:31:23,770 --> 00:31:33,570
questions alright so happy to take any

00:31:25,240 --> 00:31:33,570
questions if you have any yes yep

00:31:36,120 --> 00:31:47,330
yeah ya know so that's a great and it's

00:31:43,260 --> 00:31:49,440
a great question and that's an active

00:31:47,330 --> 00:31:51,690
challenge of this you know this large

00:31:49,440 --> 00:31:52,890
community you know it's almost are

00:31:51,690 --> 00:31:55,049
hurting cap problem at some level

00:31:52,890 --> 00:31:57,840
alright but you know I just got back

00:31:55,049 --> 00:31:59,309
from the the netflix paper mail talk

00:31:57,840 --> 00:32:01,620
about using no but you know parameterize

00:31:59,309 --> 00:32:03,570
notebooks and you know that one of the

00:32:01,620 --> 00:32:04,770
great slides that we know all of us from

00:32:03,570 --> 00:32:06,480
our team I was watching that kind of

00:32:04,770 --> 00:32:09,179
almost wanted to applaud was you know

00:32:06,480 --> 00:32:10,620
notebooks aren't libraries right and so

00:32:09,179 --> 00:32:12,690
we have that challenge of you know at

00:32:10,620 --> 00:32:14,700
what point do you say this notebook that

00:32:12,690 --> 00:32:16,020
people are either trying to run as a

00:32:14,700 --> 00:32:18,029
parameterised fashion or they're running

00:32:16,020 --> 00:32:19,620
it by just you know copying pasting the

00:32:18,029 --> 00:32:23,130
code like when should that be a library

00:32:19,620 --> 00:32:24,570
and yeah we don't have like strict

00:32:23,130 --> 00:32:26,070
guidelines for that yet it's kind of a

00:32:24,570 --> 00:32:27,020
community effort but like more work I

00:32:26,070 --> 00:32:29,159
think is done there because that's

00:32:27,020 --> 00:32:31,350
becoming a challenge with the scale of

00:32:29,159 --> 00:32:39,480
this string so we need to think about a

00:32:31,350 --> 00:32:41,460
little bit more and anecdotally yeah

00:32:39,480 --> 00:32:43,830
anecdotally yes I can't say they yeah no

00:32:41,460 --> 00:32:45,539
I mean the metrics on it right but but

00:32:43,830 --> 00:32:48,690
yeah I mean like obviously the the point

00:32:45,539 --> 00:32:50,010
of this is to you know Excel based

00:32:48,690 --> 00:32:51,120
workflows are hard to be produced and

00:32:50,010 --> 00:32:53,370
hard to share and how to collaborate on

00:32:51,120 --> 00:32:55,529
and so moving to this is certainly

00:32:53,370 --> 00:33:02,630
helpful is certainly helpful in the

00:32:55,529 --> 00:33:02,630
bacteria yep

00:33:10,680 --> 00:33:22,900
yep yep yeah so I mean every user of a

00:33:21,850 --> 00:33:25,330
notebook and any of those operational

00:33:22,900 --> 00:33:26,710
notebooks they can't be run without

00:33:25,330 --> 00:33:28,330
providing some kind of input right

00:33:26,710 --> 00:33:30,490
because they will require a query that

00:33:28,330 --> 00:33:32,860
require mandated you know input field so

00:33:30,490 --> 00:33:34,780
a user will have to interact with it at

00:33:32,860 --> 00:33:36,130
some level right heavily using widgets

00:33:34,780 --> 00:33:38,260
in our case so we're not having you know

00:33:36,130 --> 00:33:39,850
having them you know change the code and

00:33:38,260 --> 00:33:41,740
kind of change the cells so we did that

00:33:39,850 --> 00:33:43,000
part of it there but that ten to one

00:33:41,740 --> 00:33:44,680
ratio I think I think I forgot to

00:33:43,000 --> 00:33:46,750
mention was it's a great way to

00:33:44,680 --> 00:33:48,700
introduce Jupiter 2 new analysts and

00:33:46,750 --> 00:33:50,560
kind of to sell them on this concept of

00:33:48,700 --> 00:33:52,450
you know it has a tangible impact on

00:33:50,560 --> 00:33:54,310
their workflow they now start to make

00:33:52,450 --> 00:33:57,160
some connections between you know blocks

00:33:54,310 --> 00:33:59,140
or cells of code and tangible functions

00:33:57,160 --> 00:34:00,730
like this cell got my data from this

00:33:59,140 --> 00:34:03,760
repository the cell transformed at this

00:34:00,730 --> 00:34:05,680
cell made a visualization and so most

00:34:03,760 --> 00:34:07,120
likely before they ever tart taking or

00:34:05,680 --> 00:34:08,020
ever get that curiosity to start

00:34:07,120 --> 00:34:09,820
learning Python write their own

00:34:08,020 --> 00:34:11,890
notebooks they're already a semi

00:34:09,820 --> 00:34:13,409
proficient user of notebooks on their

00:34:11,890 --> 00:34:15,429
own so we see it as a great kind of like

00:34:13,409 --> 00:34:17,830
glide path and kind of getting more

00:34:15,429 --> 00:34:19,540
people in that community interested to

00:34:17,830 --> 00:34:30,690
offer their own by using other people's

00:34:19,540 --> 00:34:30,690
notebooks initially yes yeah yeah oh

00:34:32,280 --> 00:34:38,560
yeah no so again you click that just the

00:34:37,300 --> 00:34:40,630
run in Jupiter band I think it blew by

00:34:38,560 --> 00:34:42,190
here a second so you just click that

00:34:40,630 --> 00:34:45,510
little banner it launches it up

00:34:42,190 --> 00:34:48,220
automatically in Jupiter we've even done

00:34:45,510 --> 00:34:49,270
we have two / - boards from some of

00:34:48,220 --> 00:34:50,620
these notebooks that really lend

00:34:49,270 --> 00:34:52,659
themselves to that one almost like a web

00:34:50,620 --> 00:34:54,040
form like look we will automatically

00:34:52,659 --> 00:34:55,390
convert it to Jupiter dashboards and

00:34:54,040 --> 00:34:57,250
then just present the widget based view

00:34:55,390 --> 00:35:03,040
of it to make it even more user friendly

00:34:57,250 --> 00:35:04,090
to users but yeah and we the user will

00:35:03,040 --> 00:35:06,760
never have to touch the command line

00:35:04,090 --> 00:35:08,320
unless they want to and we can try to

00:35:06,760 --> 00:35:10,920
you know just that approachability get

00:35:08,320 --> 00:35:10,920
it at their level

00:35:16,260 --> 00:35:19,260
4'o

00:35:19,569 --> 00:35:22,900
that mean they're all for all these data

00:35:21,190 --> 00:35:24,790
is there their column over corporate AP

00:35:22,900 --> 00:35:27,339
is and they're stored in you know other

00:35:24,790 --> 00:35:28,359
type repository so it's all it's all

00:35:27,339 --> 00:35:52,299
done over you can I level from the

00:35:28,359 --> 00:35:53,859
notebook yeah so I mean you know for the

00:35:52,299 --> 00:35:55,569
staff I mean you leaky counted on one

00:35:53,859 --> 00:35:57,609
hand that that are actually working on

00:35:55,569 --> 00:35:59,319
this but the caveat is the

00:35:57,609 --> 00:36:01,720
infrastructure piece was provided for us

00:35:59,319 --> 00:36:06,760
right so that that is the hard part of

00:36:01,720 --> 00:36:12,599
this right yes I'm in essentially one

00:36:06,760 --> 00:36:14,680
guy that's done all this yeah yeah yeah

00:36:12,599 --> 00:36:17,890
isn't the audience or somewhere but yeah

00:36:14,680 --> 00:36:19,660
he's so yeah but but again I mean like

00:36:17,890 --> 00:36:21,760
the the bigger challenge is how to build

00:36:19,660 --> 00:36:23,109
that infrastructure that can support all

00:36:21,760 --> 00:36:24,280
these users and that ephemeral compute

00:36:23,109 --> 00:36:25,869
environment we didn't have to do that

00:36:24,280 --> 00:36:29,079
right that's what that's what's enabled

00:36:25,869 --> 00:36:31,619
us as a very very small team to get the

00:36:29,079 --> 00:36:31,619
so widely used

00:36:36,839 --> 00:36:41,890
so in in almost all these use cases yeah

00:36:40,779 --> 00:36:43,119
so certainly the people are using it for

00:36:41,890 --> 00:36:44,380
machine learning and using it for kind

00:36:43,119 --> 00:36:46,749
of what you know classically people

00:36:44,380 --> 00:36:50,249
called like data science a lot of this

00:36:46,749 --> 00:36:52,239
use case though is still you know

00:36:50,249 --> 00:36:54,069
reproducible workflows that could be

00:36:52,239 --> 00:36:55,660
thought of as you know automated you

00:36:54,069 --> 00:36:58,450
know automating workflows and at that

00:36:55,660 --> 00:37:00,160
level right so not what is traditionally

00:36:58,450 --> 00:37:02,469
what be data science like there's not a

00:37:00,160 --> 00:37:03,849
lot of I mean again I don't there is

00:37:02,469 --> 00:37:05,559
machine learning and statistical

00:37:03,849 --> 00:37:07,150
analysis type going on but the bulk of

00:37:05,559 --> 00:37:09,460
this workflow is a citizen data science

00:37:07,150 --> 00:37:10,509
use case where it's reproducible

00:37:09,460 --> 00:37:13,319
workflows and some workflow automation

00:37:10,509 --> 00:37:13,319
type tasks

00:37:18,250 --> 00:37:23,420

YouTube URL: https://www.youtube.com/watch?v=9qS1U-ySwzE


