Title: Mary Gray, Senior Researcher at Microsoft Research, interviewed at Next:Economy Summit 2016
Publication date: 2016-10-27
Playlist: Next:Economy Summit 2016
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:00,000 --> 00:00:03,330
hi this is Mike Hendrickson from next

00:00:01,890 --> 00:00:05,130
economy in San Francisco i'm here with

00:00:03,330 --> 00:00:06,450
mary grave from microsoft research how

00:00:05,130 --> 00:00:10,800
you doing good how are you doing I'm

00:00:06,450 --> 00:00:13,230
doing well so Microsoft Research what

00:00:10,800 --> 00:00:15,660
are you guys looking at about the future

00:00:13,230 --> 00:00:18,359
what do you what's on your plate of

00:00:15,660 --> 00:00:21,090
things that you want to discover about

00:00:18,359 --> 00:00:22,260
the future well Microsoft Research is

00:00:21,090 --> 00:00:24,689
probably best known for computer science

00:00:22,260 --> 00:00:26,580
and advancing artificial intelligence

00:00:24,689 --> 00:00:28,529
and machine learning and a few years ago

00:00:26,580 --> 00:00:30,060
they brought a number of us on who look

00:00:28,529 --> 00:00:32,730
at the social implications and the

00:00:30,060 --> 00:00:35,190
cultural impact of technology so my work

00:00:32,730 --> 00:00:37,230
is looking at what is it that every day

00:00:35,190 --> 00:00:39,450
people are experiencing when we

00:00:37,230 --> 00:00:42,090
introduced a guy or we introduce new

00:00:39,450 --> 00:00:43,860
technologies for work into their day and

00:00:42,090 --> 00:00:45,539
what does that do to their home life

00:00:43,860 --> 00:00:48,750
what does that do to the rest of their

00:00:45,539 --> 00:00:50,670
ambitions to their educational access so

00:00:48,750 --> 00:00:52,110
I think a lot of people when they think

00:00:50,670 --> 00:00:54,920
about the future and they think about

00:00:52,110 --> 00:00:57,949
artificial intelligence and robots and

00:00:54,920 --> 00:01:00,510
all these things that are in our path

00:00:57,949 --> 00:01:03,019
that we're on the same trajectory with

00:01:00,510 --> 00:01:06,210
right now how is it going to impact

00:01:03,019 --> 00:01:09,810
humans you know it's interesting because

00:01:06,210 --> 00:01:11,880
I think we we see we certainly see

00:01:09,810 --> 00:01:14,040
technologies innovation artificial

00:01:11,880 --> 00:01:17,250
intelligence changing some of the ways

00:01:14,040 --> 00:01:19,320
that we work for example we can see just

00:01:17,250 --> 00:01:22,890
from natural language processing which

00:01:19,320 --> 00:01:25,290
is the the technology behind speech

00:01:22,890 --> 00:01:29,490
recognition making it possible for us to

00:01:25,290 --> 00:01:32,490
say into our phones command find me if I

00:01:29,490 --> 00:01:35,400
mean this hotel that's a marvel that's a

00:01:32,490 --> 00:01:38,490
really amazing accomplishment for for

00:01:35,400 --> 00:01:42,140
computing it takes a lot of information

00:01:38,490 --> 00:01:45,840
to build up a database to allow a

00:01:42,140 --> 00:01:47,970
program to eventually identify what it

00:01:45,840 --> 00:01:50,579
is and predict what it is that you're

00:01:47,970 --> 00:01:54,869
saying or might say next say to do auto

00:01:50,579 --> 00:01:57,659
correct so all of those successes have

00:01:54,869 --> 00:02:00,270
been built on gathering a lot of data

00:01:57,659 --> 00:02:03,450
that is something that is a part of

00:02:00,270 --> 00:02:06,479
everyday life those are still really

00:02:03,450 --> 00:02:08,060
hard problems imagine a world where now

00:02:06,479 --> 00:02:09,860
we want AI or

00:02:08,060 --> 00:02:12,410
machine learning to figure out how to

00:02:09,860 --> 00:02:14,030
find a restaurant that is equidistant to

00:02:12,410 --> 00:02:15,890
the two of us and we're on opposite

00:02:14,030 --> 00:02:17,780
sides of a town we've never been to and

00:02:15,890 --> 00:02:20,270
we want that restaurant to be something

00:02:17,780 --> 00:02:22,670
that our friends have recommended that's

00:02:20,270 --> 00:02:25,550
a really challenging information problem

00:02:22,670 --> 00:02:27,069
that we are decades away from solving

00:02:25,550 --> 00:02:29,630
well in addition to the information

00:02:27,069 --> 00:02:32,450
problem there's the human element to

00:02:29,630 --> 00:02:34,519
like I want AI to do everything for me I

00:02:32,450 --> 00:02:38,480
mean I would love to have like more

00:02:34,519 --> 00:02:40,280
insightful information in my face so I

00:02:38,480 --> 00:02:42,590
can make better decisions but not

00:02:40,280 --> 00:02:46,280
everyone wants that how do we how do we

00:02:42,590 --> 00:02:48,890
get that melding of the technology with

00:02:46,280 --> 00:02:51,170
the human element I think two things and

00:02:48,890 --> 00:02:53,269
one probably the most important thing is

00:02:51,170 --> 00:02:55,640
for us to recognize the limits of ai ai

00:02:53,269 --> 00:02:58,700
can't really provide any more

00:02:55,640 --> 00:03:01,310
information then it's a mast on us as

00:02:58,700 --> 00:03:03,560
individuals or on us as a society so we

00:03:01,310 --> 00:03:05,599
have to be thinking about what are we

00:03:03,560 --> 00:03:07,190
willing and consciously handing over

00:03:05,599 --> 00:03:09,549
when it comes to the information that we

00:03:07,190 --> 00:03:13,130
exactly that we're opening in to share

00:03:09,549 --> 00:03:16,850
but the other challenge is that for the

00:03:13,130 --> 00:03:19,970
most part AI doesn't allow us to do

00:03:16,850 --> 00:03:24,350
anything beyond what we predictably can

00:03:19,970 --> 00:03:27,290
do already it can it can assume that you

00:03:24,350 --> 00:03:30,019
might want to have the same lunch but it

00:03:27,290 --> 00:03:32,780
can't know what kind of poetry you want

00:03:30,019 --> 00:03:35,209
to write right now for example so there

00:03:32,780 --> 00:03:38,030
are limits to what we're going to be

00:03:35,209 --> 00:03:40,639
able to do with AI that are not really

00:03:38,030 --> 00:03:42,590
technical limits their social questions

00:03:40,639 --> 00:03:46,040
what is it that we want to position a I

00:03:42,590 --> 00:03:48,889
to do for us versus what is it that we

00:03:46,040 --> 00:03:51,650
want to do for ourselves so if you

00:03:48,889 --> 00:03:53,930
combine this though with IOT the

00:03:51,650 --> 00:03:56,269
Internet of Things could I wear a device

00:03:53,930 --> 00:03:59,720
under my skin that would monitor my

00:03:56,269 --> 00:04:01,090
health and then predict breakdowns or

00:03:59,720 --> 00:04:03,250
predict like

00:04:01,090 --> 00:04:05,650
medical things that are going to happen

00:04:03,250 --> 00:04:07,900
in my future I mean are we going to that

00:04:05,650 --> 00:04:09,790
place we're trying I mean we're

00:04:07,900 --> 00:04:12,730
absolutely trying that is a really

00:04:09,790 --> 00:04:14,560
difficult problem to solve because right

00:04:12,730 --> 00:04:16,630
now we don't understand some of the most

00:04:14,560 --> 00:04:19,269
basic biological functions of the human

00:04:16,630 --> 00:04:21,040
body so to be able to predict

00:04:19,269 --> 00:04:23,860
something's breaking down what's the

00:04:21,040 --> 00:04:25,479
next thing I should do to fix it think

00:04:23,860 --> 00:04:27,760
about the common cold we don't really

00:04:25,479 --> 00:04:30,520
have the best idea of how to address the

00:04:27,760 --> 00:04:32,020
common cold so they change they are

00:04:30,520 --> 00:04:34,720
constantly mutating and as for there's a

00:04:32,020 --> 00:04:36,910
really good example as much as we have a

00:04:34,720 --> 00:04:41,169
certain kind of predictability to life

00:04:36,910 --> 00:04:43,330
that lets us develop scripts and AI but

00:04:41,169 --> 00:04:45,160
can anticipate what we might want a lot

00:04:43,330 --> 00:04:46,570
of life is unpredictable a lot of

00:04:45,160 --> 00:04:48,790
language is unpredictable we're

00:04:46,570 --> 00:04:51,850
constantly creating new words new

00:04:48,790 --> 00:04:54,789
phrases new ways of communicating all of

00:04:51,850 --> 00:04:56,830
that makes a I constantly moving

00:04:54,789 --> 00:04:59,380
goalpost we write about it as the

00:04:56,830 --> 00:05:01,830
paradox of automations last mile in the

00:04:59,380 --> 00:05:04,210
book that we're working on that is

00:05:01,830 --> 00:05:06,760
basically looking at how we've always

00:05:04,210 --> 00:05:09,070
dreamed about AI solving everything

00:05:06,760 --> 00:05:11,650
doing everything replacing human toil

00:05:09,070 --> 00:05:14,350
and what we almost always end up doing

00:05:11,650 --> 00:05:17,349
is as we're working towards that last

00:05:14,350 --> 00:05:19,450
mile of getting AI to accomplish

00:05:17,349 --> 00:05:20,950
something for us we start thinking of

00:05:19,450 --> 00:05:23,320
something else we'd like it to try and

00:05:20,950 --> 00:05:26,349
it's that long stretch of time between

00:05:23,320 --> 00:05:28,660
nature creeping exam exactly it's the

00:05:26,349 --> 00:05:32,260
amount of time to be able to figure out

00:05:28,660 --> 00:05:34,810
something like your speech patterns it

00:05:32,260 --> 00:05:37,419
has it's taken us decades to be able to

00:05:34,810 --> 00:05:39,849
amass that technology that doesn't mean

00:05:37,419 --> 00:05:42,130
it's not possible to pretty quickly

00:05:39,849 --> 00:05:45,580
expand that into other languages and

00:05:42,130 --> 00:05:47,470
other other uses but it does mean that

00:05:45,580 --> 00:05:49,720
as we start thinking about what else

00:05:47,470 --> 00:05:50,889
might we want to automate like something

00:05:49,720 --> 00:05:53,260
that's going to be responsive to your

00:05:50,889 --> 00:05:55,510
skin when you're alert or something's

00:05:53,260 --> 00:05:58,090
stressing you out that it might tap you

00:05:55,510 --> 00:06:00,550
and say hey calm down that's a that's a

00:05:58,090 --> 00:06:02,520
beautiful idea being able to distinguish

00:06:00,550 --> 00:06:05,530
when you might need that little nudge

00:06:02,520 --> 00:06:07,570
from you don't need it at all that's

00:06:05,530 --> 00:06:10,270
that's the biggest challenge and that

00:06:07,570 --> 00:06:11,950
that will take time and that will take a

00:06:10,270 --> 00:06:14,620
lot of human labor

00:06:11,950 --> 00:06:16,720
of attention to looking at the modeling

00:06:14,620 --> 00:06:19,060
looking at trial and error what does it

00:06:16,720 --> 00:06:20,530
look like to disrupt you for example so

00:06:19,060 --> 00:06:21,940
you're but that's what you're doing it

00:06:20,530 --> 00:06:25,150
Microsoft right you're working on the

00:06:21,940 --> 00:06:27,940
behavioral human side of how technology

00:06:25,150 --> 00:06:31,270
is in our future yeah i'm looking at the

00:06:27,940 --> 00:06:33,160
places where when we put technology out

00:06:31,270 --> 00:06:35,020
into the world say for example a

00:06:33,160 --> 00:06:36,610
scheduling agent i don't know if you've

00:06:35,020 --> 00:06:38,020
played with any of those recently some

00:06:36,610 --> 00:06:41,110
of the AI BOTS that are out there for

00:06:38,020 --> 00:06:42,580
scheduling all i have charlie oh okay so

00:06:41,110 --> 00:06:46,000
if you've ever been on the receiving end

00:06:42,580 --> 00:06:47,800
of Charlie it's a lot of work right it's

00:06:46,000 --> 00:06:50,920
a lot of human work so those are places

00:06:47,800 --> 00:06:54,400
where we we might be able to imagine an

00:06:50,920 --> 00:06:57,310
AI and a Smart Agent being able to help

00:06:54,400 --> 00:06:59,020
some people some of the time a lot of

00:06:57,310 --> 00:07:01,330
cases where we're not going to be able

00:06:59,020 --> 00:07:03,010
to distribute that kind of resource

00:07:01,330 --> 00:07:05,170
equally that means that there are some

00:07:03,010 --> 00:07:09,070
humans who are manually dealing with

00:07:05,170 --> 00:07:10,600
your AI and when I'm looking at or the

00:07:09,070 --> 00:07:13,030
waste that there are people who are

00:07:10,600 --> 00:07:15,370
often charged with being the back end of

00:07:13,030 --> 00:07:17,530
that AI whether it's for content

00:07:15,370 --> 00:07:20,200
moderation or for responding to a

00:07:17,530 --> 00:07:23,140
service request on a website that seems

00:07:20,200 --> 00:07:24,580
automated but when that request breaks

00:07:23,140 --> 00:07:27,940
down there are people in the background

00:07:24,580 --> 00:07:30,370
who are there to pick up your request in

00:07:27,940 --> 00:07:33,580
keria forward so whether it's alexa

00:07:30,370 --> 00:07:37,300
facebook and google it assistant a lot

00:07:33,580 --> 00:07:39,820
of companies from domino's pizza onward

00:07:37,300 --> 00:07:41,500
are trying to present a I as something

00:07:39,820 --> 00:07:42,790
that magically works when in fact there

00:07:41,500 --> 00:07:44,860
are a lot of people in the background to

00:07:42,790 --> 00:07:47,680
make that happen and but so if it even

00:07:44,860 --> 00:07:50,710
works the future is here but it may not

00:07:47,680 --> 00:07:52,300
be evenly distributed absolutely going

00:07:50,710 --> 00:07:54,100
to be a bigger problem going forward

00:07:52,300 --> 00:07:55,780
that'll become an even bigger problem if

00:07:54,100 --> 00:07:57,300
we don't pay attention to what we can do

00:07:55,780 --> 00:07:59,470
to make this kind of technology

00:07:57,300 --> 00:08:01,630
equitable and available and really

00:07:59,470 --> 00:08:03,460
transparent I think the biggest

00:08:01,630 --> 00:08:07,270
challenge before us is what we call the

00:08:03,460 --> 00:08:09,670
uncanny valley of AI where we may be

00:08:07,270 --> 00:08:13,000
using AI and we don't realize that in

00:08:09,670 --> 00:08:16,210
fact we're using a combination of AI and

00:08:13,000 --> 00:08:17,500
humans in the loop so it becomes we're

00:08:16,210 --> 00:08:20,050
at a really important juncture of

00:08:17,500 --> 00:08:22,570
figuring out if we're creating a new

00:08:20,050 --> 00:08:24,639
economy that's really built on providing

00:08:22,570 --> 00:08:26,620
services and goods through

00:08:24,639 --> 00:08:29,349
an application programming interface and

00:08:26,620 --> 00:08:31,469
API where I can buy the touch of a

00:08:29,349 --> 00:08:34,089
button on my phone have something happen

00:08:31,469 --> 00:08:36,490
whether it's ordering up pizza we're

00:08:34,089 --> 00:08:39,789
having PowerPoint slides created for me

00:08:36,490 --> 00:08:41,890
it becomes a social question a political

00:08:39,789 --> 00:08:45,399
question an economic question what are

00:08:41,890 --> 00:08:48,130
people's roles in that in that creation

00:08:45,399 --> 00:08:49,630
in that value creation are they working

00:08:48,130 --> 00:08:52,480
in the background or the conditions for

00:08:49,630 --> 00:08:54,490
that work and as a consumer I think it's

00:08:52,480 --> 00:08:56,140
on us on all of us to be thinking about

00:08:54,490 --> 00:09:00,100
those questions that sounds like a great

00:08:56,140 --> 00:09:01,990
book humans in the loop yeah so if you

00:09:00,100 --> 00:09:04,149
think about humans in the loop and

00:09:01,990 --> 00:09:05,529
technology and where we're going if we

00:09:04,149 --> 00:09:08,230
sit down next year and have the same

00:09:05,529 --> 00:09:11,019
conversation what would you like to say

00:09:08,230 --> 00:09:13,029
as the society we've tackled and

00:09:11,019 --> 00:09:15,010
accomplished and what do you think we

00:09:13,029 --> 00:09:16,810
can push even further yeah that's a

00:09:15,010 --> 00:09:19,300
great question I mean we've come a long

00:09:16,810 --> 00:09:21,089
way with what are often called platform

00:09:19,300 --> 00:09:24,399
economies of being able to imagine

00:09:21,089 --> 00:09:26,920
services and goods that we can organize

00:09:24,399 --> 00:09:29,620
that we can schedule we can source we

00:09:26,920 --> 00:09:31,540
can manage and pay for through an online

00:09:29,620 --> 00:09:34,480
connection or through our phones or a

00:09:31,540 --> 00:09:36,940
mobile connection that's great and being

00:09:34,480 --> 00:09:38,860
able to see how to make the distribution

00:09:36,940 --> 00:09:40,660
of those goods and services go further

00:09:38,860 --> 00:09:42,880
that they go into all neighborhoods all

00:09:40,660 --> 00:09:46,089
zip codes see who's redlined when

00:09:42,880 --> 00:09:47,890
certain services are provided and who's

00:09:46,089 --> 00:09:50,320
not able to access them to really ask

00:09:47,890 --> 00:09:53,050
those questions but all of these

00:09:50,320 --> 00:09:56,230
businesses that offer something that is

00:09:53,050 --> 00:09:58,779
really scalable something like

00:09:56,230 --> 00:10:00,550
telemedicine where perhaps being able to

00:09:58,779 --> 00:10:02,920
take care of an elder and make sure that

00:10:00,550 --> 00:10:04,600
they receive their medication get the

00:10:02,920 --> 00:10:07,209
prompt that they need that's that's

00:10:04,600 --> 00:10:10,089
something we're all going to need as our

00:10:07,209 --> 00:10:11,500
as our societies are exactly the great

00:10:10,089 --> 00:10:13,449
wave that's about to hit us so it's a

00:10:11,500 --> 00:10:15,250
good example of a year from now what I'd

00:10:13,449 --> 00:10:17,709
like us to see is as a society we've

00:10:15,250 --> 00:10:20,440
really grappled with the kind of economy

00:10:17,709 --> 00:10:23,110
that relies on ondemand labour that

00:10:20,440 --> 00:10:24,819
relies on people working in concert in

00:10:23,110 --> 00:10:26,379
the background with a I

00:10:24,819 --> 00:10:28,749
it's going to require a different social

00:10:26,379 --> 00:10:30,489
safety net than what we have for the

00:10:28,749 --> 00:10:32,499
assumption of a kind of full-time job

00:10:30,489 --> 00:10:34,299
that is built into the way we think

00:10:32,499 --> 00:10:36,789
about our economy right now we're not

00:10:34,299 --> 00:10:38,709
really built for this kind of on-demand

00:10:36,789 --> 00:10:42,399
economy that's constantly working

00:10:38,709 --> 00:10:44,499
through an API and that's what we need

00:10:42,399 --> 00:10:46,089
to change excellent will marry we look

00:10:44,499 --> 00:10:48,629
for that conversation next year thank

00:10:46,089 --> 00:10:48,629
you thank you

00:10:54,990 --> 00:10:57,050

YouTube URL: https://www.youtube.com/watch?v=MdHIjrb6oXY


