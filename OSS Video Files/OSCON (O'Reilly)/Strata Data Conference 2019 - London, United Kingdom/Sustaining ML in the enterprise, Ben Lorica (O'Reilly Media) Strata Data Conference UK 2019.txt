Title: Sustaining ML in the enterprise, Ben Lorica (O'Reilly Media) Strata Data Conference UK 2019
Publication date: 2019-05-16
Playlist: Strata Data Conference 2019 - London, United Kingdom
Description: 
	To view more videos from Strata Data Conference, visit:
http://oreilly.com/go/stratauk19

Ben Lorica is the chief data scientist at Oâ€™Reilly Media. Ben has applied business intelligence, data mining, machine learning, and statistical analysis in a variety of settings, including direct marketing, consumer and market research, targeted advertising, text mining, and financial engineering. His background includes stints with an investment management company, internet startups, and financial service

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,060 --> 00:00:03,929
I want to take a few minutes to

00:00:01,860 --> 00:00:06,990
highlight the results of some recent

00:00:03,929 --> 00:00:09,210
surveys we've conducted and along the

00:00:06,990 --> 00:00:12,469
way describe some trends that we've

00:00:09,210 --> 00:00:15,360
observed but more importantly highlights

00:00:12,469 --> 00:00:19,680
parts of the program in this conference

00:00:15,360 --> 00:00:22,710
over the next few days so last July we

00:00:19,680 --> 00:00:25,019
conducted a survey we drew over 11,000

00:00:22,710 --> 00:00:27,420
respondents and at the time we found

00:00:25,019 --> 00:00:29,460
that many companies were already serious

00:00:27,420 --> 00:00:32,130
about machine learning so we measured

00:00:29,460 --> 00:00:36,090
how many companies were already in

00:00:32,130 --> 00:00:38,989
production as far as machine learning so

00:00:36,090 --> 00:00:42,329
with all the hype with ml and AI

00:00:38,989 --> 00:00:44,910
it's very tempting to jump into complex

00:00:42,329 --> 00:00:46,950
use cases but we found through our

00:00:44,910 --> 00:00:50,850
surveys and actually the survey of other

00:00:46,950 --> 00:00:53,610
companies that the organizations to

00:00:50,850 --> 00:00:56,370
succeed in machine learning tend to

00:00:53,610 --> 00:00:59,129
build upon existing analytic use cases

00:00:56,370 --> 00:01:02,340
so basically you might imagine having a

00:00:59,129 --> 00:01:04,049
business intelligence service that runs

00:01:02,340 --> 00:01:05,970
on some data you already have and

00:01:04,049 --> 00:01:10,350
layering some machine learning on top of

00:01:05,970 --> 00:01:12,960
it so take for example deep learning

00:01:10,350 --> 00:01:17,549
which is the subject of many tops at

00:01:12,960 --> 00:01:21,509
this conference so how are our companies

00:01:17,549 --> 00:01:24,240
using deep learning so do two major ways

00:01:21,509 --> 00:01:26,549
stand out the first is they use deep

00:01:24,240 --> 00:01:28,500
learning to either replace or augment

00:01:26,549 --> 00:01:31,140
machine learning systems that they

00:01:28,500 --> 00:01:35,040
already have or they use deep learning

00:01:31,140 --> 00:01:37,530
to introduce new data types to do any

00:01:35,040 --> 00:01:39,990
some of their systems right so so at

00:01:37,530 --> 00:01:43,110
this conference we have many sessions on

00:01:39,990 --> 00:01:47,490
the use of deep learning for example for

00:01:43,110 --> 00:01:49,500
time series Arun Kejriwal and IRA horn

00:01:47,490 --> 00:01:51,990
will be giving a survey of the use of

00:01:49,500 --> 00:01:55,200
deep learning for time series and also

00:01:51,990 --> 00:01:57,990
text so we have the creators of spark

00:01:55,200 --> 00:02:01,530
NLP and Spacey here at the conference

00:01:57,990 --> 00:02:04,259
and also we have muniya Lamas of Spotify

00:02:01,530 --> 00:02:09,090
who will describe have they modernized

00:02:04,259 --> 00:02:11,340
their recommender systems so machine

00:02:09,090 --> 00:02:14,010
learning is also changing how we

00:02:11,340 --> 00:02:18,000
approach software development it

00:02:14,010 --> 00:02:19,739
self right so so increasingly software

00:02:18,000 --> 00:02:22,040
development will probably look like

00:02:19,739 --> 00:02:25,349
machine learning so you'll have to

00:02:22,040 --> 00:02:28,709
collect training data and use it to

00:02:25,349 --> 00:02:30,480
automate some some software system so

00:02:28,709 --> 00:02:33,480
the important thing to notice we are

00:02:30,480 --> 00:02:37,950
still very much in an empirical era for

00:02:33,480 --> 00:02:41,129
ML so we need big data big compute and

00:02:37,950 --> 00:02:43,470
big models and specifically tools for

00:02:41,129 --> 00:02:48,989
managing training data are going to be

00:02:43,470 --> 00:02:53,819
key to sustaining success in ml so what

00:02:48,989 --> 00:02:56,840
what do you need exactly so you need to

00:02:53,819 --> 00:03:00,989
be able to build pipelines at scale and

00:02:56,840 --> 00:03:03,150
in a routine fashion and to keep those

00:03:00,989 --> 00:03:05,010
pipelines flowing so that you have good

00:03:03,150 --> 00:03:07,230
clean data that will be usable for

00:03:05,010 --> 00:03:09,540
machine learning and to build these

00:03:07,230 --> 00:03:12,989
pipelines repeatedly you need you need

00:03:09,540 --> 00:03:15,750
to have the right tools so with an eye

00:03:12,989 --> 00:03:18,030
towards machine learning we conducted a

00:03:15,750 --> 00:03:21,120
survey late last year so our goal was to

00:03:18,030 --> 00:03:23,519
fold first we wanted to find out what

00:03:21,120 --> 00:03:26,519
tools people are using so no surprise a

00:03:23,519 --> 00:03:29,310
lot of spark a lot of kafka tensorflow

00:03:26,519 --> 00:03:31,739
pipe torch and so on right so but we

00:03:29,310 --> 00:03:33,810
also wanted to find out are people

00:03:31,739 --> 00:03:36,269
building the right things in order to

00:03:33,810 --> 00:03:39,540
sustain machine learning within their

00:03:36,269 --> 00:03:41,669
organizations so one of the main

00:03:39,540 --> 00:03:46,290
questions was what are you building

00:03:41,669 --> 00:03:48,120
so not surprisingly data integration was

00:03:46,290 --> 00:03:50,430
on top of the list because after all

00:03:48,120 --> 00:03:53,519
everything begins with collecting and

00:03:50,430 --> 00:03:56,669
aggregating data so we have many talks

00:03:53,519 --> 00:03:58,409
at this conference we have a whole slate

00:03:56,669 --> 00:04:01,079
of sessions and data integration in

00:03:58,409 --> 00:04:03,569
modern ETL including tops from ted

00:04:01,079 --> 00:04:05,940
Mollusca of Capital One and max you'll

00:04:03,569 --> 00:04:09,569
see of solando but make sure you check

00:04:05,940 --> 00:04:11,909
your program so an important part of

00:04:09,569 --> 00:04:15,000
getting data ready for machine learning

00:04:11,909 --> 00:04:17,190
is preparing and cleaning it so much so

00:04:15,000 --> 00:04:19,019
that there's now even a new research

00:04:17,190 --> 00:04:22,560
area among academics called data

00:04:19,019 --> 00:04:24,900
programming which is basically unifies

00:04:22,560 --> 00:04:27,790
all the techniques for programmatically

00:04:24,900 --> 00:04:30,090
creating training sets

00:04:27,790 --> 00:04:32,650
to that and we are beginning to see

00:04:30,090 --> 00:04:37,450
human-in-the-loop systems where you have

00:04:32,650 --> 00:04:39,550
domain experts training data preparation

00:04:37,450 --> 00:04:42,550
tools that can then operate at scale and

00:04:39,550 --> 00:04:43,930
clean and prepare data at scale so many

00:04:42,550 --> 00:04:46,150
of these companies will be at this

00:04:43,930 --> 00:04:48,160
conference so for example one of the

00:04:46,150 --> 00:04:51,070
leading experts in data programming a

00:04:48,160 --> 00:04:53,500
hub Ilias of you the University of

00:04:51,070 --> 00:04:55,960
Waterloo in Canada but also who founder

00:04:53,500 --> 00:04:59,020
of famer will speak this afternoon on

00:04:55,960 --> 00:05:03,580
how one can solve data cleaning using

00:04:59,020 --> 00:05:06,400
modern machine learning techniques so

00:05:03,580 --> 00:05:09,220
you'll also need to understand what data

00:05:06,400 --> 00:05:10,930
you have and who can access it so as you

00:05:09,220 --> 00:05:13,420
can see about a third of the people in

00:05:10,930 --> 00:05:15,340
our survey already looking at data

00:05:13,420 --> 00:05:19,180
governance solutions and data catalogues

00:05:15,340 --> 00:05:22,320
so there are also open-source tools so a

00:05:19,180 --> 00:05:25,660
couple of Bay Area companies uber has a

00:05:22,320 --> 00:05:28,030
project called data book and we work has

00:05:25,660 --> 00:05:30,880
a project called Marques but there are

00:05:28,030 --> 00:05:33,820
also companies here at our expo hall

00:05:30,880 --> 00:05:36,580
including elation and mu de who are

00:05:33,820 --> 00:05:39,970
building tools in this area if so if

00:05:36,580 --> 00:05:41,800
you're interested in data governance as

00:05:39,970 --> 00:05:44,290
a broad topic

00:05:41,800 --> 00:05:46,150
I recommend a session this afternoon by

00:05:44,290 --> 00:05:48,100
Paco Nathan he will be giving an

00:05:46,150 --> 00:05:53,110
executive briefing on data governance

00:05:48,100 --> 00:05:55,090
and data catalogs so in the past we got

00:05:53,110 --> 00:05:58,810
by with a rather cavalier attitude

00:05:55,090 --> 00:06:00,970
towards data sources but that is ending

00:05:58,810 --> 00:06:05,320
so with discussions around data ethics

00:06:00,970 --> 00:06:07,830
security and privacy it's very important

00:06:05,320 --> 00:06:10,030
to talk about lineage and provenance so

00:06:07,830 --> 00:06:13,060
specifically where does the data come

00:06:10,030 --> 00:06:16,450
from how was it God gathered and how was

00:06:13,060 --> 00:06:19,390
it modified along the way so the need to

00:06:16,450 --> 00:06:21,220
audit and reproduce ML pipelines makes

00:06:19,390 --> 00:06:24,880
it increasingly a legal and security

00:06:21,220 --> 00:06:28,210
issue that's why companies are beginning

00:06:24,880 --> 00:06:30,730
to really seriously build data linear

00:06:28,210 --> 00:06:34,180
solutions so at this conference we have

00:06:30,730 --> 00:06:39,130
a few sessions on this topic including

00:06:34,180 --> 00:06:41,230
talks from Intuit lyft and Accenture but

00:06:39,130 --> 00:06:41,409
they're also open source projects that

00:06:41,230 --> 00:06:43,659
are

00:06:41,409 --> 00:06:46,899
beginning to address data linear so

00:06:43,659 --> 00:06:49,899
there's a project called DVC and Delta

00:06:46,899 --> 00:06:54,969
Lake is also built in some data lineage

00:06:49,899 --> 00:06:58,449
capability so as the number of data

00:06:54,969 --> 00:07:01,119
scientists grows within your company you

00:06:58,449 --> 00:07:03,249
need to start thinking about something

00:07:01,119 --> 00:07:05,889
what something that's called a like a

00:07:03,249 --> 00:07:07,929
data science platform which is basically

00:07:05,889 --> 00:07:12,339
a tool where your data scientists can

00:07:07,929 --> 00:07:15,719
collaborate share features share models

00:07:12,339 --> 00:07:18,519
and also have a standardized set of

00:07:15,719 --> 00:07:20,459
machine learning libraries so many of

00:07:18,519 --> 00:07:22,659
these modern data science platforms

00:07:20,459 --> 00:07:24,309
support multiple machine learning

00:07:22,659 --> 00:07:27,249
libraries right so they tend to support

00:07:24,309 --> 00:07:28,989
the usual deep learning libraries like

00:07:27,249 --> 00:07:32,199
tensorflow and pi torch but also

00:07:28,989 --> 00:07:35,079
scikit-learn and even R so at this

00:07:32,199 --> 00:07:38,739
conference will have many sessions from

00:07:35,079 --> 00:07:40,899
companies specifically they'll talk

00:07:38,739 --> 00:07:43,089
about what trade-offs and design choices

00:07:40,899 --> 00:07:44,860
they made towards building their data

00:07:43,089 --> 00:07:47,589
science platform so some of the

00:07:44,860 --> 00:07:49,659
companies who are going to be presenting

00:07:47,589 --> 00:07:52,139
on their internal data science platforms

00:07:49,659 --> 00:07:56,319
at this conference include Zalando

00:07:52,139 --> 00:07:59,139
Alibaba stitch fix uber and go jack but

00:07:56,319 --> 00:08:02,289
there's also many companies at the at

00:07:59,139 --> 00:08:03,669
our expo hall who offer data science

00:08:02,289 --> 00:08:07,419
platform solutions including our

00:08:03,669 --> 00:08:12,550
partners caldera and a honda data IQ and

00:08:07,419 --> 00:08:15,459
faculty so we found that a majority of

00:08:12,550 --> 00:08:17,619
companies are already using public cloud

00:08:15,459 --> 00:08:21,459
options for at least parts of their data

00:08:17,619 --> 00:08:23,139
infrastructure and in fact we had a

00:08:21,459 --> 00:08:24,879
question where we asked them if they

00:08:23,139 --> 00:08:28,629
were already aware or using serverless

00:08:24,879 --> 00:08:30,879
and about 1/3 of the companies signaled

00:08:28,629 --> 00:08:35,229
that they used one of the 7 serverless

00:08:30,879 --> 00:08:37,240
options we provided so during trainings

00:08:35,229 --> 00:08:39,399
and tutorials we had numerous offerings

00:08:37,240 --> 00:08:41,559
on the topic of serverless

00:08:39,399 --> 00:08:43,750
and will continue to have tops over the

00:08:41,559 --> 00:08:46,120
next few days on the importance of

00:08:43,750 --> 00:08:48,399
serverless for modern data pipelines and

00:08:46,120 --> 00:08:51,040
architectures including a talk today by

00:08:48,399 --> 00:08:53,110
Avner Braverman who will explain the

00:08:51,040 --> 00:08:54,640
role of serverless for data and machine

00:08:53,110 --> 00:08:57,650
learning

00:08:54,640 --> 00:09:00,020
so it's our belief that the use of

00:08:57,650 --> 00:09:02,060
machine learning will continue to grow

00:09:00,020 --> 00:09:05,029
over the next few years right so couple

00:09:02,060 --> 00:09:08,620
the major reasons the first is 5g it's

00:09:05,029 --> 00:09:10,760
it's just beginning to be rolled out and

00:09:08,620 --> 00:09:12,100
5g will probably lead to many

00:09:10,760 --> 00:09:15,140
interesting machine-to-machine

00:09:12,100 --> 00:09:18,170
applications many of which will rely on

00:09:15,140 --> 00:09:21,230
machine learning and secondly towards

00:09:18,170 --> 00:09:23,029
the end of this year we'll begin to see

00:09:21,230 --> 00:09:26,330
specialized hardware for machine

00:09:23,029 --> 00:09:29,120
learning specifically for the training

00:09:26,330 --> 00:09:32,720
and inference of deep learning so I

00:09:29,120 --> 00:09:36,200
suspect that around q3 and q4 of this

00:09:32,720 --> 00:09:38,890
year will for example see new hardware

00:09:36,200 --> 00:09:41,360
for training large deep deep learning

00:09:38,890 --> 00:09:43,760
architectures so here we're talking

00:09:41,360 --> 00:09:47,720
about massive speed ups on the order of

00:09:43,760 --> 00:09:51,620
15 to 20 x in terms of training time or

00:09:47,720 --> 00:09:52,070
40 X event is what I've been led to

00:09:51,620 --> 00:09:55,370
believe

00:09:52,070 --> 00:09:57,650
so imagine a model that took you 40

00:09:55,370 --> 00:09:59,810
hours now takes one hour so now you're

00:09:57,650 --> 00:10:02,510
gonna go to lunch your model training is

00:09:59,810 --> 00:10:04,130
is done so that means that data

00:10:02,510 --> 00:10:06,950
scientists and machine learning

00:10:04,130 --> 00:10:11,390
researchers can experiment and try many

00:10:06,950 --> 00:10:14,060
more architectures so there are also a

00:10:11,390 --> 00:10:16,459
couple of early indicators that machine

00:10:14,060 --> 00:10:18,320
learning will grow within companies so

00:10:16,459 --> 00:10:20,839
Cassie was talking about the title data

00:10:18,320 --> 00:10:23,660
scientist which has been used for the

00:10:20,839 --> 00:10:25,760
last maybe four to five years so a few

00:10:23,660 --> 00:10:28,790
years ago a couple of years ago we began

00:10:25,760 --> 00:10:31,700
to notice a new job title emerging in

00:10:28,790 --> 00:10:34,010
the San Francisco Bay Area and this new

00:10:31,700 --> 00:10:36,290
role was dedicated to production icing

00:10:34,010 --> 00:10:39,080
machine learning so this was the machine

00:10:36,290 --> 00:10:41,240
learning engineer and companies who

00:10:39,080 --> 00:10:44,209
specialized in deep learning even had a

00:10:41,240 --> 00:10:46,459
more specific robots called deep

00:10:44,209 --> 00:10:48,230
learning engineer so the machine

00:10:46,459 --> 00:10:51,010
learning engineer sits somewhere between

00:10:48,230 --> 00:10:54,830
data science and engineering and ops

00:10:51,010 --> 00:10:58,370
they tend to have stronger programming

00:10:54,830 --> 00:11:00,440
skills but more importantly for you they

00:10:58,370 --> 00:11:02,990
are also more highly compensated and

00:11:00,440 --> 00:11:05,360
data scientists so you may want to go

00:11:02,990 --> 00:11:06,310
back to your manager and sneakily tell

00:11:05,360 --> 00:11:08,769
them hey yeah

00:11:06,310 --> 00:11:10,420
maybe I can change my title to machine

00:11:08,769 --> 00:11:13,749
learning engineer and then change jobs

00:11:10,420 --> 00:11:16,240
rank so so they're in fact in my Twitter

00:11:13,749 --> 00:11:17,980
poll there seems to be early indications

00:11:16,240 --> 00:11:20,230
that data scientists are beginning to

00:11:17,980 --> 00:11:22,089
rebrand themselves into this new job

00:11:20,230 --> 00:11:23,079
title now the important thing to

00:11:22,089 --> 00:11:25,240
remember about machine learning

00:11:23,079 --> 00:11:26,980
engineers in practice particularly in

00:11:25,240 --> 00:11:30,819
the Bay Area startups Enis

00:11:26,980 --> 00:11:34,629
they are comfort more of an engineering

00:11:30,819 --> 00:11:36,519
background so the expectation is they

00:11:34,629 --> 00:11:40,389
have stronger programming skills than

00:11:36,519 --> 00:11:43,389
your typical data scientist another sign

00:11:40,389 --> 00:11:45,730
that machine learning is going to

00:11:43,389 --> 00:11:47,980
increase in importance is to look at

00:11:45,730 --> 00:11:50,949
some of the new projects as a really

00:11:47,980 --> 00:11:55,749
gained traction so take for example ml

00:11:50,949 --> 00:11:58,329
flow it's 10 months old as you can see

00:11:55,749 --> 00:12:02,170
there's already over 200 plus companies

00:11:58,329 --> 00:12:04,420
using it and a common use case for ml

00:12:02,170 --> 00:12:07,660
flow is experiment tracking and

00:12:04,420 --> 00:12:10,959
management in fact when ml flow was

00:12:07,660 --> 00:12:12,339
released I kind of suspected it was

00:12:10,959 --> 00:12:15,550
going to be popular because there was

00:12:12,339 --> 00:12:18,639
really no good tool for doing this and

00:12:15,550 --> 00:12:20,610
so it's been confirmed right so you can

00:12:18,639 --> 00:12:23,290
see the number of contributors has grown

00:12:20,610 --> 00:12:25,449
github stars is growing and then more

00:12:23,290 --> 00:12:27,660
importantly the actual use cases in

00:12:25,449 --> 00:12:30,699
production so now there are also

00:12:27,660 --> 00:12:33,089
startups building tools for managing

00:12:30,699 --> 00:12:37,089
machine learning development and

00:12:33,089 --> 00:12:39,490
companies in our expo hall offer similar

00:12:37,089 --> 00:12:45,069
solutions within their data science

00:12:39,490 --> 00:12:47,829
platform or offerings so as the machine

00:12:45,069 --> 00:12:50,500
learning practice expands in many parts

00:12:47,829 --> 00:12:52,240
of your companies it will become clear

00:12:50,500 --> 00:12:55,120
that you will need specialized tools

00:12:52,240 --> 00:12:58,449
right so ml flow is great but it really

00:12:55,120 --> 00:13:02,670
only takes care of ml machine learning

00:12:58,449 --> 00:13:05,649
development right so as you begin to

00:13:02,670 --> 00:13:07,449
evaluate data science platform solutions

00:13:05,649 --> 00:13:09,490
you'll have to ask many questions so

00:13:07,449 --> 00:13:12,249
I've tried to list some of the key

00:13:09,490 --> 00:13:17,110
criteria that these people in the Bay

00:13:12,249 --> 00:13:19,120
Area are talking about so for example we

00:13:17,110 --> 00:13:19,870
talked about we talked a lot about deep

00:13:19,120 --> 00:13:23,140
learning

00:13:19,870 --> 00:13:24,310
but the reality is companies will use

00:13:23,140 --> 00:13:26,260
many types of machine learning

00:13:24,310 --> 00:13:28,750
techniques right

00:13:26,260 --> 00:13:32,770
support vector machines are still used

00:13:28,750 --> 00:13:34,750
within Facebook XG boost is popular and

00:13:32,770 --> 00:13:36,130
so in time series the traditional

00:13:34,750 --> 00:13:38,290
statistical models will still be

00:13:36,130 --> 00:13:42,190
important so you'll need to kind of

00:13:38,290 --> 00:13:44,320
understand how the data set science

00:13:42,190 --> 00:13:46,090
platform you're building is able to

00:13:44,320 --> 00:13:48,910
support a variety of many machine

00:13:46,090 --> 00:13:51,580
learning tools so if you are a manager

00:13:48,910 --> 00:13:54,310
or decision maker struggling with some

00:13:51,580 --> 00:13:57,280
of these topics I highly recommend a

00:13:54,310 --> 00:14:00,370
session this afternoon by speed scam

00:13:57,280 --> 00:14:02,410
watch of workday he will be giving an

00:14:00,370 --> 00:14:05,410
outstanding executive briefing this

00:14:02,410 --> 00:14:08,650
morning around these topics so now Pete

00:14:05,410 --> 00:14:10,690
doesn't come to London often so even if

00:14:08,650 --> 00:14:13,000
you can't come can't come to stop reach

00:14:10,690 --> 00:14:18,460
out so he's one of the really deep

00:14:13,000 --> 00:14:21,190
thinkers in this area so and just like

00:14:18,460 --> 00:14:23,770
data are assets so I talked about data

00:14:21,190 --> 00:14:29,020
governance so data governance solutions

00:14:23,770 --> 00:14:30,550
are really gaining in popularity so more

00:14:29,020 --> 00:14:32,830
and more startups are building data

00:14:30,550 --> 00:14:34,630
governance solutions and more and more

00:14:32,830 --> 00:14:38,470
companies are recognizing that they need

00:14:34,630 --> 00:14:41,440
data governance and data catalogs models

00:14:38,470 --> 00:14:43,900
will also become valuable assets and as

00:14:41,440 --> 00:14:45,880
such they will need to be managed and

00:14:43,900 --> 00:14:48,460
productive so we will also need

00:14:45,880 --> 00:14:50,740
specialized tools for model governance

00:14:48,460 --> 00:14:53,740
and model operations and we're beginning

00:14:50,740 --> 00:14:56,290
to see startups and companies building

00:14:53,740 --> 00:14:58,990
tools for just this purpose so you'll

00:14:56,290 --> 00:15:01,570
need for example you'll need probably

00:14:58,990 --> 00:15:04,360
the ability to list all of the models

00:15:01,570 --> 00:15:09,040
you have right so a model kata log model

00:15:04,360 --> 00:15:12,640
catalog the ability to know who has the

00:15:09,040 --> 00:15:15,370
authority to deploy models or read and

00:15:12,640 --> 00:15:17,590
write certain models and more

00:15:15,370 --> 00:15:21,460
importantly I think if you look at just

00:15:17,590 --> 00:15:23,590
the monitoring of models you will need

00:15:21,460 --> 00:15:27,060
dashboards but these dashboards may have

00:15:23,590 --> 00:15:29,770
specific views right so you might have a

00:15:27,060 --> 00:15:31,990
different dashboard for a data scientist

00:15:29,770 --> 00:15:33,459
you may have a different dashboard for a

00:15:31,990 --> 00:15:35,139
business user and

00:15:33,459 --> 00:15:37,660
you might have a different dashboard for

00:15:35,139 --> 00:15:41,290
the machine learning engineer or the

00:15:37,660 --> 00:15:43,389
data ops person so there will be a great

00:15:41,290 --> 00:15:45,550
talk this morning on model governance

00:15:43,389 --> 00:15:51,610
and model operations for the enterprise

00:15:45,550 --> 00:15:53,589
by Jerry Hsu of datatron so we're also

00:15:51,610 --> 00:15:55,089
beginning to recognize that machine

00:15:53,589 --> 00:15:58,389
learning is much more than just

00:15:55,089 --> 00:16:00,910
optimizing statistical or business

00:15:58,389 --> 00:16:03,819
metrics so we will need to monitor a lot

00:16:00,910 --> 00:16:06,970
of things and in this conference we have

00:16:03,819 --> 00:16:09,069
many great sessions touching on fairness

00:16:06,970 --> 00:16:12,670
explain ability and particularly

00:16:09,069 --> 00:16:15,009
security and privacy so for example

00:16:12,670 --> 00:16:18,369
Mickey Braun is giving a survey talk on

00:16:15,009 --> 00:16:23,009
fair and privacy for serving and secure

00:16:18,369 --> 00:16:25,809
machine learning and after a year hiatus

00:16:23,009 --> 00:16:28,149
Duncan Ross and Francine Bennett are

00:16:25,809 --> 00:16:34,149
back where they're using for data evil

00:16:28,149 --> 00:16:37,089
series this time focus on AI so this

00:16:34,149 --> 00:16:40,209
risks are no longer too radical right so

00:16:37,089 --> 00:16:46,329
they're real so for example a recent

00:16:40,209 --> 00:16:49,149
survey of GDP are found that there have

00:16:46,329 --> 00:16:52,059
been many many reports of breaches

00:16:49,149 --> 00:16:55,629
already right so do so increasingly

00:16:52,059 --> 00:16:58,389
these tools for privacy for serving

00:16:55,629 --> 00:17:00,730
machine learning and data security and

00:16:58,389 --> 00:17:06,069
privacy are going to be required and not

00:17:00,730 --> 00:17:08,829
not optional so I recommend a executive

00:17:06,069 --> 00:17:11,199
briefing today by mark Donsky of opera

00:17:08,829 --> 00:17:15,630
he will give you an update on worldwide

00:17:11,199 --> 00:17:20,679
privacy regulations GDP our California

00:17:15,630 --> 00:17:22,740
Privacy Act and many more so in closing

00:17:20,679 --> 00:17:26,079
we tend to think of machine learning as

00:17:22,740 --> 00:17:29,590
producing a model or an ensemble of

00:17:26,079 --> 00:17:32,260
models that we need to deploy but it

00:17:29,590 --> 00:17:34,809
were increasingly beginning to realize

00:17:32,260 --> 00:17:37,149
that auditing and maintaining machine

00:17:34,809 --> 00:17:40,149
learning can actually be challenging

00:17:37,149 --> 00:17:42,370
because it actually involves a series of

00:17:40,149 --> 00:17:44,100
algorithms right so there's the actual

00:17:42,370 --> 00:17:46,330
model that you will deploy to production

00:17:44,100 --> 00:17:47,380
but there's might be a sequence of

00:17:46,330 --> 00:17:50,500
models

00:17:47,380 --> 00:17:52,179
the trainer or the pipeline that

00:17:50,500 --> 00:17:55,360
involves things like stochastic gradient

00:17:52,179 --> 00:17:58,150
descent that uses data to produce this

00:17:55,360 --> 00:17:59,140
model so managing machine learning

00:17:58,150 --> 00:18:03,370
models

00:17:59,140 --> 00:18:05,290
I can't reinforce enough requires a set

00:18:03,370 --> 00:18:07,960
of foundational tools that I try to

00:18:05,290 --> 00:18:11,700
highlight and which will be the subject

00:18:07,960 --> 00:18:14,920
of many sessions over the next few days

00:18:11,700 --> 00:18:17,170
so we have an outstanding program for

00:18:14,920 --> 00:18:19,300
you over the next few days there will be

00:18:17,170 --> 00:18:21,670
many sessions on topics that are

00:18:19,300 --> 00:18:24,160
critical to making sure that you succeed

00:18:21,670 --> 00:18:27,670
in your journey towards machine learning

00:18:24,160 --> 00:18:29,440
and as a conference organiser so of

00:18:27,670 --> 00:18:31,929
course I'm very proud of the program we

00:18:29,440 --> 00:18:34,030
put together but don't forget to network

00:18:31,929 --> 00:18:36,309
with other people at the conference so

00:18:34,030 --> 00:18:38,559
right so with our speakers with your

00:18:36,309 --> 00:18:40,990
fellow attendees and with our sponsors

00:18:38,559 --> 00:18:42,700
in the expo hall so for the next few

00:18:40,990 --> 00:18:46,000
days this is your data and machine

00:18:42,700 --> 00:18:48,100
learning community and one of the ways

00:18:46,000 --> 00:18:51,490
actually that you can reach out to your

00:18:48,100 --> 00:18:55,390
fellow attendees is using Twitter so use

00:18:51,490 --> 00:18:57,520
the hashtag and and start discussions

00:18:55,390 --> 00:18:59,980
with your fellow attendees so thank you

00:18:57,520 --> 00:19:00,830
and have a good program for the next two

00:18:59,980 --> 00:19:05,339
days

00:19:00,830 --> 00:19:05,339

YouTube URL: https://www.youtube.com/watch?v=ILgPyqyz6aQ


