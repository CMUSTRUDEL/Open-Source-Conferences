Title: Managing Machines - Pete Skomoroch (Workday)
Publication date: 2019-07-18
Playlist: OSCON 2019 - Portland, OR
Description: 
	Machine learning drove massive growth at consumer internet companies over the last decade, and this was enabled by open software, datasets, and AI research. For many problems, machine learning will produce better, faster, and more repeatable decisions at scale. Unfortunately, building and maintaining these systems is still extremely difficult and expensive. As more machine learning software moves to production, many of our traditional tools and best practices in software development will change.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:03,990
so if machine learning is so

00:00:02,159 --> 00:00:05,009
transformative and amazing and open

00:00:03,990 --> 00:00:06,750
source frameworks are not widely

00:00:05,009 --> 00:00:09,030
available and you can download models

00:00:06,750 --> 00:00:11,759
why hasn't every company applied machine

00:00:09,030 --> 00:00:14,099
learning and reinvented itself it turns

00:00:11,759 --> 00:00:16,470
out that even basic machine learning is

00:00:14,099 --> 00:00:18,600
still really hard and managing AI

00:00:16,470 --> 00:00:20,070
projects in a real business is much

00:00:18,600 --> 00:00:22,980
harder than most people realize when

00:00:20,070 --> 00:00:24,900
they start out machine learning isn't

00:00:22,980 --> 00:00:26,990
fairy dust that you can just sprinkle on

00:00:24,900 --> 00:00:30,179
your product and magically make it smart

00:00:26,990 --> 00:00:32,969
and you usually unfortunately can't even

00:00:30,179 --> 00:00:34,710
plug in off-the-shelf cloud api's to

00:00:32,969 --> 00:00:37,290
magically make them intelligent either

00:00:34,710 --> 00:00:39,390
there's a lot of work that people don't

00:00:37,290 --> 00:00:42,000
realize how it has to happen to make

00:00:39,390 --> 00:00:43,980
that successful all right so why is it

00:00:42,000 --> 00:00:45,960
why is machine learning so hard well you

00:00:43,980 --> 00:00:48,180
need to collect lots and lots of

00:00:45,960 --> 00:00:49,230
expensive labeled training data most

00:00:48,180 --> 00:00:51,390
people don't realize it's not just

00:00:49,230 --> 00:00:54,210
enough to have data you actually need

00:00:51,390 --> 00:00:56,699
data paired with a label for most

00:00:54,210 --> 00:00:57,989
problems and those labels are often

00:00:56,699 --> 00:01:01,020
expensive unless you can do something

00:00:57,989 --> 00:01:03,000
like Google and others would have those

00:01:01,020 --> 00:01:05,280
CAPTCHAs that you fill out right is

00:01:03,000 --> 00:01:08,180
there a crosswalk in this picture things

00:01:05,280 --> 00:01:10,619
like that that's you labeling some data

00:01:08,180 --> 00:01:13,229
and unless you have the scale to get to

00:01:10,619 --> 00:01:15,439
get those labels at scale you have to

00:01:13,229 --> 00:01:18,659
pay for it or you have to do it yourself

00:01:15,439 --> 00:01:20,580
so the data the data transformation

00:01:18,659 --> 00:01:22,619
model design training tuning all this

00:01:20,580 --> 00:01:26,549
are still really time-consuming and

00:01:22,619 --> 00:01:28,470
error-prone human processes the media

00:01:26,549 --> 00:01:31,430
coverage of AI often focuses on edge

00:01:28,470 --> 00:01:33,299
cases or AI decisions that went wrong

00:01:31,430 --> 00:01:35,400
it's important to remember that although

00:01:33,299 --> 00:01:37,079
the vast majority of the time most

00:01:35,400 --> 00:01:38,790
models will make good predictions

00:01:37,079 --> 00:01:40,680
machine learning is at its core a

00:01:38,790 --> 00:01:43,560
probabilistic approach to problem

00:01:40,680 --> 00:01:45,090
solving not deterministic right you

00:01:43,560 --> 00:01:48,090
don't know exactly what it's going to do

00:01:45,090 --> 00:01:49,259
when you run it on real data so you

00:01:48,090 --> 00:01:51,299
should expect that every machine

00:01:49,259 --> 00:01:53,310
learning model will fail some percentage

00:01:51,299 --> 00:01:54,960
of the time and if the application is a

00:01:53,310 --> 00:01:56,729
business critical one you should have

00:01:54,960 --> 00:02:00,090
monitoring systems in place to detect

00:01:56,729 --> 00:02:01,259
and handle those failure cases software

00:02:00,090 --> 00:02:03,299
projects usually make progress

00:02:01,259 --> 00:02:06,149
incrementally but because they're closer

00:02:03,299 --> 00:02:08,129
to cutting edge research they can often

00:02:06,149 --> 00:02:09,209
stall for weeks at a time right where

00:02:08,129 --> 00:02:11,459
you have no results and when you

00:02:09,209 --> 00:02:13,470
implement in production you may actually

00:02:11,459 --> 00:02:15,720
get worse results than you had be

00:02:13,470 --> 00:02:17,430
where you rolled out the model so all

00:02:15,720 --> 00:02:19,490
these things cause a lot of a lot of

00:02:17,430 --> 00:02:21,360
pain how many people are out of

00:02:19,490 --> 00:02:24,180
organization where you are doing machine

00:02:21,360 --> 00:02:24,920
learning show hands ok good number wow

00:02:24,180 --> 00:02:28,140
this is great

00:02:24,920 --> 00:02:30,780
so we all probably have felt this pain

00:02:28,140 --> 00:02:32,520
so how do we make it better first let's

00:02:30,780 --> 00:02:33,900
just be more concrete about the current

00:02:32,520 --> 00:02:36,210
development process for machine learning

00:02:33,900 --> 00:02:37,920
that we want to improve projects usually

00:02:36,210 --> 00:02:39,450
start with problem definition and it's

00:02:37,920 --> 00:02:41,190
critical you do this upfront work to

00:02:39,450 --> 00:02:44,880
select the right problem and frame it

00:02:41,190 --> 00:02:46,860
correctly model design is still more art

00:02:44,880 --> 00:02:48,720
than science although it's becoming

00:02:46,860 --> 00:02:52,620
easier because of that trend towards

00:02:48,720 --> 00:02:54,600
open research papers and code data

00:02:52,620 --> 00:02:56,300
collection labeling I just mentioned is

00:02:54,600 --> 00:02:59,160
often the most time-consuming process

00:02:56,300 --> 00:03:01,880
part of the process but we need better

00:02:59,160 --> 00:03:03,720
tools for labeling and data management

00:03:01,880 --> 00:03:05,490
following that comes some form of

00:03:03,720 --> 00:03:07,260
feature engineering so from the raw data

00:03:05,490 --> 00:03:10,320
you're doing a lot of transformations on

00:03:07,260 --> 00:03:12,390
the data to make inputs your machine

00:03:10,320 --> 00:03:15,240
learning models and the tools are almost

00:03:12,390 --> 00:03:16,860
non-existent in that space it finally

00:03:15,240 --> 00:03:19,410
comes model deployment to run on live

00:03:16,860 --> 00:03:21,360
data 80% of the real engineering work in

00:03:19,410 --> 00:03:23,100
pain happens after you deploy your first

00:03:21,360 --> 00:03:25,500
version of your model so for companies

00:03:23,100 --> 00:03:26,459
where you are trying to move to machine

00:03:25,500 --> 00:03:28,080
learning and you haven't shipped

00:03:26,459 --> 00:03:30,239
something yet you have to get there

00:03:28,080 --> 00:03:32,040
faster because the real learning and

00:03:30,239 --> 00:03:34,670
real pain comes when these things are in

00:03:32,040 --> 00:03:34,670
operation

00:03:40,710 --> 00:03:42,770

YouTube URL: https://www.youtube.com/watch?v=dNYg2dgTa1M


