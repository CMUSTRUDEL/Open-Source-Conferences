Title: RL in real life: Bringing reinforcement learning to the enterprise - Edward Jezierski (Microsoft)
Publication date: 2019-09-26
Playlist: Strata Data Conference 2019 - New York, NY
Description: 
	(Sponsored by Microsoft)
We’re entering an era where AI can discover patterns and causality beyond the data we provide. Reinforcement learning (RL) is a powerful technique that lets AI achieve our goals by learning from its own actions and experiences, even when no training data exists.

Microsoft has an ecosystem spanning research, gaming, and the cloud that’s advancing reinforcement learning (RL) and putting it into everyday use. Join Edward Jezierski to see where RL is used practically across Microsoft and imagine the opportunities that exist for your business today.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:04,470
I'm going to be sharing some of the work

00:00:02,850 --> 00:00:06,359
that we've been doing at Microsoft in

00:00:04,470 --> 00:00:08,730
reinforcement learning we've been

00:00:06,359 --> 00:00:10,500
looking at a lot of applications of AI

00:00:08,730 --> 00:00:13,590
and thoroughly you're building all these

00:00:10,500 --> 00:00:15,480
systems and an apps and services that

00:00:13,590 --> 00:00:17,699
take advantage of all the capabilities

00:00:15,480 --> 00:00:19,529
that are coming to light these days if

00:00:17,699 --> 00:00:21,869
you look at the sort of things we can do

00:00:19,529 --> 00:00:23,670
it's amazing how with speech and

00:00:21,869 --> 00:00:25,949
language and understanding what's in our

00:00:23,670 --> 00:00:30,390
data we can expand the power of our

00:00:25,949 --> 00:00:32,099
applications but if we look at what

00:00:30,390 --> 00:00:34,590
these services and what these

00:00:32,099 --> 00:00:36,239
capabilities truly do they help us

00:00:34,590 --> 00:00:38,309
interact with the physical world and

00:00:36,239 --> 00:00:39,840
with users better they help us get this

00:00:38,309 --> 00:00:41,340
kind of like x-ray vision and

00:00:39,840 --> 00:00:43,890
understanding of what's going on in the

00:00:41,340 --> 00:00:46,680
data but there's something that makes

00:00:43,890 --> 00:00:49,710
whatever efforts we put at making our

00:00:46,680 --> 00:00:51,960
systems with AI kind of capped kind of

00:00:49,710 --> 00:00:54,899
it sucks no matter how better we go that

00:00:51,960 --> 00:00:56,579
we add our data which is in the end in

00:00:54,899 --> 00:00:58,350
the middle of all this there are

00:00:56,579 --> 00:01:00,510
business rules right there here's where

00:00:58,350 --> 00:01:02,010
the dirty little secret of our apps is

00:01:00,510 --> 00:01:03,570
that for all the machine learning on one

00:01:02,010 --> 00:01:05,430
side and all the fantastic user

00:01:03,570 --> 00:01:07,740
interaction on the other there is this

00:01:05,430 --> 00:01:09,600
like bunch of nested ifs sitting in the

00:01:07,740 --> 00:01:11,939
middle whereas a bunch of hard-coded

00:01:09,600 --> 00:01:13,979
values and thresholds and assumptions

00:01:11,939 --> 00:01:17,369
about how the world works then in the

00:01:13,979 --> 00:01:21,659
end cap how many results you can get out

00:01:17,369 --> 00:01:23,850
of your applications so the question is

00:01:21,659 --> 00:01:25,770
like then how can we bring AI to that

00:01:23,850 --> 00:01:29,280
area to the area of the business rules

00:01:25,770 --> 00:01:31,530
and how the business operates and the

00:01:29,280 --> 00:01:34,350
type of AI that can do that is called

00:01:31,530 --> 00:01:37,680
reinforcement learning in reinforcement

00:01:34,350 --> 00:01:41,340
learning essentially you take the notion

00:01:37,680 --> 00:01:43,020
of an agent that is operating in an

00:01:41,340 --> 00:01:45,810
environment that includes both your

00:01:43,020 --> 00:01:48,090
users and your data and there's a notion

00:01:45,810 --> 00:01:49,920
of a world or an environment and the

00:01:48,090 --> 00:01:52,380
agent tries things decides to take

00:01:49,920 --> 00:01:54,360
certain actions on the world and then

00:01:52,380 --> 00:01:56,310
learns by observing the outcome of those

00:01:54,360 --> 00:01:58,049
actions and seeing how well they track

00:01:56,310 --> 00:02:00,570
to something you're trying to achieve

00:01:58,049 --> 00:02:02,250
with it and through this cycle it learns

00:02:00,570 --> 00:02:04,979
how to decide and reinforcement learning

00:02:02,250 --> 00:02:09,270
is a type of AI that deals with finding

00:02:04,979 --> 00:02:10,860
out these good decisions now we say okay

00:02:09,270 --> 00:02:12,569
what happens if we want to do this in

00:02:10,860 --> 00:02:13,950
the real world you you read a lot about

00:02:12,569 --> 00:02:16,080
reinforcement learning

00:02:13,950 --> 00:02:18,060
you see like how it went boar games and

00:02:16,080 --> 00:02:20,400
how you can you know get superhuman

00:02:18,060 --> 00:02:22,850
performance in video games and a lot of

00:02:20,400 --> 00:02:24,930
that happens in simulation and

00:02:22,850 --> 00:02:27,600
simulations great so what happens if we

00:02:24,930 --> 00:02:29,340
want to do it in the real world well I

00:02:27,600 --> 00:02:31,290
think turns out there's a lot of things

00:02:29,340 --> 00:02:33,540
that become really complicated if you

00:02:31,290 --> 00:02:37,590
want to train things outside simulation

00:02:33,540 --> 00:02:39,810
and bust AI outside of that so some of

00:02:37,590 --> 00:02:41,100
the things that happen is that first of

00:02:39,810 --> 00:02:43,410
all reality hits you with full

00:02:41,100 --> 00:02:45,390
complexity you can't make baby steps in

00:02:43,410 --> 00:02:47,489
reality we really don't understand the

00:02:45,390 --> 00:02:49,890
curriculum so as we're trying to build

00:02:47,489 --> 00:02:51,600
services that help you make these

00:02:49,890 --> 00:02:53,790
business rules with AI we need to be

00:02:51,600 --> 00:02:55,769
able to learn very fast and adapting

00:02:53,790 --> 00:02:58,230
from a world that hits you day one in

00:02:55,769 --> 00:03:01,260
the face with it's all its messiness and

00:02:58,230 --> 00:03:03,300
its richness then time is inexorable

00:03:01,260 --> 00:03:05,700
there's no rewind this no what is we

00:03:03,300 --> 00:03:07,680
can't say stops up show this other thing

00:03:05,700 --> 00:03:11,370
to this user to see what they would have

00:03:07,680 --> 00:03:13,670
done right and you cannot compare we

00:03:11,370 --> 00:03:16,170
have to make the most in our services to

00:03:13,670 --> 00:03:18,360
extract as much information as possible

00:03:16,170 --> 00:03:20,820
and harvest as much conclusions for

00:03:18,360 --> 00:03:22,440
every data point then baselines are

00:03:20,820 --> 00:03:24,090
shifting the world is changing you don't

00:03:22,440 --> 00:03:25,950
know if what you have got last week you

00:03:24,090 --> 00:03:28,880
should expect from next it's better not

00:03:25,950 --> 00:03:31,230
even to assume that then there's a real

00:03:28,880 --> 00:03:33,930
constraint in which in simulations you

00:03:31,230 --> 00:03:35,700
can just you know insert another quarter

00:03:33,930 --> 00:03:38,549
in the cloud and it gives you a billion

00:03:35,700 --> 00:03:41,579
data points and that's fine in the real

00:03:38,549 --> 00:03:43,019
world you have these few users coming in

00:03:41,579 --> 00:03:45,299
and you have to be able to respond in

00:03:43,019 --> 00:03:47,489
milliseconds and train to every single

00:03:45,299 --> 00:03:50,400
event in real time you can't wait a week

00:03:47,489 --> 00:03:52,200
to push out a new modeling example we

00:03:50,400 --> 00:03:54,780
push out a new model in MSN News every

00:03:52,200 --> 00:03:57,690
15 minutes trained on every single event

00:03:54,780 --> 00:04:02,070
that has just happened and finally that

00:03:57,690 --> 00:04:04,709
user data is valuable and scarce as we

00:04:02,070 --> 00:04:07,530
mentioned and importantly there's no

00:04:04,709 --> 00:04:09,239
undo things have true consequences like

00:04:07,530 --> 00:04:11,280
you can't just try things and say oh

00:04:09,239 --> 00:04:13,140
look that crazy thing found out this

00:04:11,280 --> 00:04:14,850
crazy conclusion that was funny to look

00:04:13,140 --> 00:04:16,560
in an animation when you're talking

00:04:14,850 --> 00:04:20,190
about things that operate in the real

00:04:16,560 --> 00:04:22,710
world you have to understand that your

00:04:20,190 --> 00:04:25,050
exploration has consequences and that

00:04:22,710 --> 00:04:27,030
the ethics has to be designed from the

00:04:25,050 --> 00:04:29,130
ground up in these systems

00:04:27,030 --> 00:04:30,840
you know from the team culture all the

00:04:29,130 --> 00:04:34,530
way up through like guidelines for users

00:04:30,840 --> 00:04:37,890
and the monitoring tools we use so with

00:04:34,530 --> 00:04:40,620
all this these considerations what can

00:04:37,890 --> 00:04:42,450
we provide we can we're building a

00:04:40,620 --> 00:04:44,790
series of services that allow you to do

00:04:42,450 --> 00:04:47,910
real-time personalization contextual

00:04:44,790 --> 00:04:50,100
optimization real-time adaptation of

00:04:47,910 --> 00:04:51,510
autonomous systems to their context and

00:04:50,100 --> 00:04:53,100
even learning from each other like

00:04:51,510 --> 00:04:55,860
imagine you could have a system that

00:04:53,100 --> 00:04:58,290
teaches your support staff how to close

00:04:55,860 --> 00:05:00,390
cases based on the performance of your

00:04:58,290 --> 00:05:01,770
best support workers these are all

00:05:00,390 --> 00:05:04,860
applications of real enforcement

00:05:01,770 --> 00:05:09,810
learning in the real world that we're

00:05:04,860 --> 00:05:11,700
working on and to wrap it up a bit you

00:05:09,810 --> 00:05:14,220
know when we're talking about the agent

00:05:11,700 --> 00:05:16,500
and the world we can't forget that the

00:05:14,220 --> 00:05:19,140
agent and we the people who make them

00:05:16,500 --> 00:05:22,440
are part of this world and you know as

00:05:19,140 --> 00:05:24,150
we bring out AI that has the ability to

00:05:22,440 --> 00:05:27,090
achieve any result we ask for it

00:05:24,150 --> 00:05:29,520
we hope that you have a place for the

00:05:27,090 --> 00:05:32,750
world the people in it in the goals you

00:05:29,520 --> 00:05:32,750
give it thank you very much

00:05:39,020 --> 00:05:41,080

YouTube URL: https://www.youtube.com/watch?v=gL-4GLli_V0


