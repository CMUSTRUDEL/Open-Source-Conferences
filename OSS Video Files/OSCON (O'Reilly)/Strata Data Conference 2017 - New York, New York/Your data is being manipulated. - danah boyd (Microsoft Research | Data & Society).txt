Title: Your data is being manipulated. - danah boyd (Microsoft Research | Data & Society)
Publication date: 2017-09-29
Playlist: Strata Data Conference 2017 - New York, New York
Description: 
	The more that we rely on data to train our models and inform our systems, the more that this data becomes a target for those seeking to manipulate algorithmic systems and undermine trust in data. danah boyd explores how systems are being gamed, how data is vulnerable, and what we need to do to build technical antibodies.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,840 --> 00:00:05,680
training a machine learning system

00:00:02,679 --> 00:00:07,690
requires data lots of it while there are

00:00:05,680 --> 00:00:09,910
some standard corpuses computer science

00:00:07,690 --> 00:00:11,379
researchers startups and big companies

00:00:09,910 --> 00:00:13,510
and probably most of you are

00:00:11,379 --> 00:00:15,309
increasingly hungry for new and

00:00:13,510 --> 00:00:17,679
different forms of data the first

00:00:15,309 --> 00:00:20,019
problem is that all data is biased most

00:00:17,679 --> 00:00:22,150
notably and recognizably by reflecting

00:00:20,019 --> 00:00:24,339
the biases of humans and the society in

00:00:22,150 --> 00:00:27,039
general take for example the popular

00:00:24,339 --> 00:00:29,259
image net dataset because human tatter

00:00:27,039 --> 00:00:31,119
eyes shape faster than they categorize

00:00:29,259 --> 00:00:33,520
by color you end up with some really

00:00:31,119 --> 00:00:34,930
weird artifacts in that system but

00:00:33,520 --> 00:00:36,730
things get even Messier when you're

00:00:34,930 --> 00:00:39,309
starting to deal with social prejudices

00:00:36,730 --> 00:00:41,320
when Latanya Sweeney searched for her

00:00:39,309 --> 00:00:43,539
name on Google she was surprised to be

00:00:41,320 --> 00:00:45,519
given recommendations to see whether or

00:00:43,539 --> 00:00:47,199
not she had a criminal record these were

00:00:45,519 --> 00:00:48,940
the ads that were given to her as a

00:00:47,199 --> 00:00:51,370
curious computer scientist she decided

00:00:48,940 --> 00:00:52,420
to throw in tons of names of both black

00:00:51,370 --> 00:00:55,120
names and white names in the United

00:00:52,420 --> 00:00:57,100
States to see what ads would pop up not

00:00:55,120 --> 00:00:58,719
surprisingly the only ads that received

00:00:57,100 --> 00:01:00,309
criminal justice related products were

00:00:58,719 --> 00:01:02,710
named we were associated with black

00:01:00,309 --> 00:01:05,050
names now this isn't because Google is

00:01:02,710 --> 00:01:06,790
knowingly categorizing people by names

00:01:05,050 --> 00:01:08,470
or even understanding much about the

00:01:06,790 --> 00:01:10,110
person who's doing the searching what's

00:01:08,470 --> 00:01:12,880
happened is that Google has been trained

00:01:10,110 --> 00:01:15,070
systematically to associate black names

00:01:12,880 --> 00:01:17,440
with criminal justice products because

00:01:15,070 --> 00:01:19,990
of the clicks that people have in other

00:01:17,440 --> 00:01:22,750
words Google learned American prejudices

00:01:19,990 --> 00:01:25,900
and American racism and amplified it

00:01:22,750 --> 00:01:27,730
back at all of its users now addressing

00:01:25,900 --> 00:01:29,080
implicit and explicit cultural biases

00:01:27,730 --> 00:01:30,760
and data is gonna be a huge challenge

00:01:29,080 --> 00:01:32,710
for everyone who's trying to build a

00:01:30,760 --> 00:01:35,050
system depending on data classified by

00:01:32,710 --> 00:01:37,870
humans but there's also a new challenge

00:01:35,050 --> 00:01:40,360
emerging the same decentralized actors

00:01:37,870 --> 00:01:41,980
that I told you about the individuals

00:01:40,360 --> 00:01:43,780
who are gaming for fun and profit as

00:01:41,980 --> 00:01:45,310
well as state actors the people who've

00:01:43,780 --> 00:01:47,410
been messing with social media and

00:01:45,310 --> 00:01:49,630
search engines they are increasingly

00:01:47,410 --> 00:01:51,930
eyeing the data that various companies

00:01:49,630 --> 00:01:54,460
use to train and improve their systems

00:01:51,930 --> 00:01:57,160
consider for example the popular use of

00:01:54,460 --> 00:01:59,680
Twitter data or reddit's these are open

00:01:57,160 --> 00:02:01,870
API systems so people love to use these

00:01:59,680 --> 00:02:03,820
to train their models to understand

00:02:01,870 --> 00:02:07,360
natural language to develop metadata

00:02:03,820 --> 00:02:09,849
about links to track social patterns all

00:02:07,360 --> 00:02:12,630
sorts of people have trained models to

00:02:09,849 --> 00:02:14,670
detect depression ranked news in

00:02:12,630 --> 00:02:15,990
and conversation though ignoring the

00:02:14,670 --> 00:02:18,210
fact that these datasets are not

00:02:15,990 --> 00:02:20,490
particularly representative most

00:02:18,210 --> 00:02:22,950
engineers who believe that it's possible

00:02:20,490 --> 00:02:26,010
to actually clean the data and remove

00:02:22,950 --> 00:02:28,770
problematic content I can promise you it

00:02:26,010 --> 00:02:31,410
is not no amount of excluding certain

00:02:28,770 --> 00:02:33,510
subreddits removing categories of tweets

00:02:31,410 --> 00:02:35,760
or ignoring content with problematic

00:02:33,510 --> 00:02:37,850
words will prepare you for those who are

00:02:35,760 --> 00:02:40,890
hell-bent on messing with your systems

00:02:37,850 --> 00:02:42,960
I'm watching countless actors trying to

00:02:40,890 --> 00:02:45,600
develop new strategic ways to

00:02:42,960 --> 00:02:47,700
purposefully mess with systems with an

00:02:45,600 --> 00:02:50,550
eye on messing with the training data

00:02:47,700 --> 00:02:52,620
that all of you use they are trying to

00:02:50,550 --> 00:02:53,970
flow fly below the radar and if you

00:02:52,620 --> 00:02:55,800
don't have a structure in place for

00:02:53,970 --> 00:02:57,810
strategically grappling with held those

00:02:55,800 --> 00:02:59,790
with agenda might try to rat right

00:02:57,810 --> 00:03:00,410
around your best laid plans you're

00:02:59,790 --> 00:03:02,820
vulnerable

00:03:00,410 --> 00:03:05,370
this isn't about accidental or natural

00:03:02,820 --> 00:03:07,920
content it's not even about culturally

00:03:05,370 --> 00:03:11,310
biased data it's about strategically

00:03:07,920 --> 00:03:13,350
gamified content injected into systems

00:03:11,310 --> 00:03:15,540
by people who are trying to guess what

00:03:13,350 --> 00:03:16,740
you will do next now if you want to

00:03:15,540 --> 00:03:18,390
grasp what this means and the

00:03:16,740 --> 00:03:19,800
implications of it consider the

00:03:18,390 --> 00:03:22,290
experiment in this les paper not as

00:03:19,800 --> 00:03:23,700
colleagues published last year in order

00:03:22,290 --> 00:03:26,130
to understand the vulnerabilities of

00:03:23,700 --> 00:03:28,560
computer vision algorithms they decided

00:03:26,130 --> 00:03:30,270
to alter the images of stop signs so

00:03:28,560 --> 00:03:31,170
that humans still believe that they were

00:03:30,270 --> 00:03:33,480
stop signs

00:03:31,170 --> 00:03:36,090
but the neural Nets understood them as

00:03:33,480 --> 00:03:38,430
yield signs think about what that means

00:03:36,090 --> 00:03:39,570
for autonomous vehicles now think about

00:03:38,430 --> 00:03:42,030
that what that means for a whole variety

00:03:39,570 --> 00:03:44,310
of technologies will though your

00:03:42,030 --> 00:03:45,660
technologies be widely adopted if a

00:03:44,310 --> 00:03:48,420
classifier you're using can be

00:03:45,660 --> 00:03:50,040
manipulated so easily now right now most

00:03:48,420 --> 00:03:51,540
successful data injection attacks on

00:03:50,040 --> 00:03:53,610
machine learning models are actually

00:03:51,540 --> 00:03:55,110
happening in the world of research but

00:03:53,610 --> 00:03:57,450
more and more we're seeing people try to

00:03:55,110 --> 00:03:59,130
mess with systems and just because most

00:03:57,450 --> 00:04:01,800
of the mainstream attacks haven't been

00:03:59,130 --> 00:04:03,060
particularly successful yet doesn't mean

00:04:01,800 --> 00:04:06,470
they aren't learning and evolving

00:04:03,060 --> 00:04:06,470

YouTube URL: https://www.youtube.com/watch?v=J2c5P2d2Ft8


