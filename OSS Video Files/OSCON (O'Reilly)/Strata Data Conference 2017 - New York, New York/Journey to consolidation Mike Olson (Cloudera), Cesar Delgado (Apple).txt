Title: Journey to consolidation Mike Olson (Cloudera), Cesar Delgado (Apple)
Publication date: 2017-09-27
Playlist: Strata Data Conference 2017 - New York, New York
Description: 
	Twenty years ago, a company implored us to “think different” about personal computers. Today, Apple continues to live and breathe that legacy. It’s evident in the machine learning and analytics architectures that power many of the company’s most innovative applications. Cesar Delgado joins Mike Olson to discuss how Apple is using its big data stack and expertise to solve non-data problems.

Subscribe to O'Reilly on  YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:02,790 --> 00:00:08,519
20 years ago a remarkable company

00:00:06,189 --> 00:00:13,540
challenged us all to think different

00:00:08,519 --> 00:00:15,910
this month Siri turned six super

00:00:13,540 --> 00:00:17,529
interesting machine learning application

00:00:15,910 --> 00:00:20,350
but you know deploying those

00:00:17,529 --> 00:00:22,750
capabilities at massive scale requires

00:00:20,350 --> 00:00:26,440
deep technical expertise and a

00:00:22,750 --> 00:00:28,779
rigorously engineered platform I am very

00:00:26,440 --> 00:00:30,670
pleased to cede the rest of my keynote

00:00:28,779 --> 00:00:31,029
to someone who understands how to do

00:00:30,670 --> 00:00:33,789
that

00:00:31,029 --> 00:00:35,980
I want to welcome Cesar Delgado from

00:00:33,789 --> 00:00:40,390
Apple who's going to talk to you about

00:00:35,980 --> 00:00:51,040
how his system Siri works at scale

00:00:40,390 --> 00:00:54,010
Cesar hello everyone good morning

00:00:51,040 --> 00:00:54,550
sellout crowd this is pretty good my

00:00:54,010 --> 00:00:56,950
name is Cesar

00:00:54,550 --> 00:00:59,079
I am a platform architect for the Siri

00:00:56,950 --> 00:01:01,090
Operations team and I'm here to talk to

00:00:59,079 --> 00:01:03,430
you about something a little bit

00:01:01,090 --> 00:01:05,860
different so you guys can imagine series

00:01:03,430 --> 00:01:08,439
a very complicated machine learning

00:01:05,860 --> 00:01:11,200
application that takes real-time queries

00:01:08,439 --> 00:01:13,810
from users all over the world

00:01:11,200 --> 00:01:15,189
although the information that's behind

00:01:13,810 --> 00:01:18,219
is very interesting and the big data

00:01:15,189 --> 00:01:21,279
processing is what most people imagine

00:01:18,219 --> 00:01:23,619
serious doing the application platform

00:01:21,279 --> 00:01:25,869
that it's built on is what I'm going to

00:01:23,619 --> 00:01:27,909
talk about today and mostly how Syria

00:01:25,869 --> 00:01:31,149
can actually run with a very very small

00:01:27,909 --> 00:01:33,279
team the way we've done it is when we

00:01:31,149 --> 00:01:36,520
started Syria six years ago we actually

00:01:33,279 --> 00:01:38,649
had a very complicated stack we did what

00:01:36,520 --> 00:01:40,569
we could to bring up the system we use

00:01:38,649 --> 00:01:43,630
virtualization like many people do on

00:01:40,569 --> 00:01:46,319
their first attempt at building a web

00:01:43,630 --> 00:01:50,380
scale type application lots of filers

00:01:46,319 --> 00:01:53,200
and web caching for deploying all these

00:01:50,380 --> 00:01:55,359
machines of course we use zookeeper and

00:01:53,200 --> 00:01:56,919
HBase if anybody of you guys know me

00:01:55,359 --> 00:01:57,419
those two projects are near and dear to

00:01:56,919 --> 00:02:00,459
my heart

00:01:57,419 --> 00:02:02,919
Siri depends on these applications every

00:02:00,459 --> 00:02:04,630
day to support their queries but the

00:02:02,919 --> 00:02:06,969
system is tedious and very hard to

00:02:04,630 --> 00:02:08,739
manage we had to build tools and I have

00:02:06,969 --> 00:02:10,899
to build tools for those tools just to

00:02:08,739 --> 00:02:13,030
keep the system going which is not great

00:02:10,899 --> 00:02:14,680
so the first thing we did is we try to

00:02:13,030 --> 00:02:16,000
simplify it and we just got rid of the

00:02:14,680 --> 00:02:18,730
virtualization layer completely

00:02:16,000 --> 00:02:21,400
we moved the entire application up a

00:02:18,730 --> 00:02:24,040
layer onto mezzos and now we can

00:02:21,400 --> 00:02:26,290
actually manage a cloud of CPU and

00:02:24,040 --> 00:02:28,390
memory where the application can run no

00:02:26,290 --> 00:02:30,880
more silos no more putting processes in

00:02:28,390 --> 00:02:33,550
a box it can be right size add time and

00:02:30,880 --> 00:02:36,280
change dynamically we still depend on

00:02:33,550 --> 00:02:39,580
this large web caching infrastructure

00:02:36,280 --> 00:02:41,290
because we had it but it's kind of a

00:02:39,580 --> 00:02:43,060
pain I don't know if you guys have it

00:02:41,290 --> 00:02:44,530
when you have a tool that you use for

00:02:43,060 --> 00:02:47,860
something and then you find other uses

00:02:44,530 --> 00:02:50,260
it's more interesting now we have HDFS

00:02:47,860 --> 00:02:52,120
under mesos and we also know how to run

00:02:50,260 --> 00:02:54,340
a CFS at scale in our MapReduce cluster

00:02:52,120 --> 00:02:56,200
so we were thinking oh this is kind of

00:02:54,340 --> 00:02:59,080
interesting maybe we can actually use

00:02:56,200 --> 00:03:00,160
the power of HDFS not for analytics but

00:02:59,080 --> 00:03:03,060
for something maybe a little more

00:03:00,160 --> 00:03:06,370
interesting so started thinking okay so

00:03:03,060 --> 00:03:10,480
what if we take the information off

00:03:06,370 --> 00:03:13,840
these filers somehow and use it to our

00:03:10,480 --> 00:03:18,209
advantage we started moving a little bit

00:03:13,840 --> 00:03:21,820
of code over to our HDFS cluster under

00:03:18,209 --> 00:03:23,530
mezzos and then that's where the actual

00:03:21,820 --> 00:03:25,870
binaries for the cirrie code get

00:03:23,530 --> 00:03:29,019
launched on mezzos this way we can get

00:03:25,870 --> 00:03:31,989
gigantic horizontal scaling from the

00:03:29,019 --> 00:03:34,840
power of HDFS reads once we saw that

00:03:31,989 --> 00:03:36,910
that it worked and we were happy we took

00:03:34,840 --> 00:03:40,360
it one step further we we just move

00:03:36,910 --> 00:03:42,610
things over to this data staging demons

00:03:40,360 --> 00:03:44,260
which take all the little models that

00:03:42,610 --> 00:03:46,390
Siri uses and all the information that

00:03:44,260 --> 00:03:48,640
Siri needs and actually takes it from

00:03:46,390 --> 00:03:50,410
the caching layer and caches it on HDFS

00:03:48,640 --> 00:03:52,959
for a little while we were still living

00:03:50,410 --> 00:03:55,720
in this dual mode so we could test the

00:03:52,959 --> 00:03:58,000
system but it seemed to have been

00:03:55,720 --> 00:03:59,200
working really well and because you know

00:03:58,000 --> 00:04:01,090
when you change one thing you have to

00:03:59,200 --> 00:04:03,970
say on your totes at this point we also

00:04:01,090 --> 00:04:06,549
moved on to yarn and that made our life

00:04:03,970 --> 00:04:09,160
a lot easier we could explain to all our

00:04:06,549 --> 00:04:12,930
users hey this is like mazes for Hadoop

00:04:09,160 --> 00:04:15,610
or this is like yarn for the application

00:04:12,930 --> 00:04:17,530
once we succeeded with these little pocs

00:04:15,610 --> 00:04:20,799
we actually just took everything over

00:04:17,530 --> 00:04:23,280
and moved it onto HDFS so application

00:04:20,799 --> 00:04:26,740
models now live on HDFS Siri code

00:04:23,280 --> 00:04:29,289
doesn't quite live on HDFS but

00:04:26,740 --> 00:04:29,920
everything else does and something

00:04:29,289 --> 00:04:32,680
interesting

00:04:29,920 --> 00:04:34,240
that we actually did here which is a

00:04:32,680 --> 00:04:36,160
little bit counterintuitive is we

00:04:34,240 --> 00:04:38,740
actually don't run regular replication

00:04:36,160 --> 00:04:40,270
we actually run 50 or over replicas that

00:04:38,740 --> 00:04:41,740
means that when there's a stampeding

00:04:40,270 --> 00:04:44,050
herd of applications trying to get at

00:04:41,740 --> 00:04:48,820
their data we just take advantage of

00:04:44,050 --> 00:04:51,040
HDFS for free the last stage which is

00:04:48,820 --> 00:04:53,920
what we're working on right now is to

00:04:51,040 --> 00:04:56,770
move completely over to HDFS and get rid

00:04:53,920 --> 00:04:58,270
of all dependency for filers as you guys

00:04:56,770 --> 00:05:01,540
know or if you've ever worked with

00:04:58,270 --> 00:05:03,790
filers they're expensive and they're a

00:05:01,540 --> 00:05:07,060
single point of failure 80 FS is

00:05:03,790 --> 00:05:09,670
dynamics and plus we have expertise in

00:05:07,060 --> 00:05:11,620
running HDFS at scale the other nice

00:05:09,670 --> 00:05:13,510
part is when we grow compute we grow

00:05:11,620 --> 00:05:15,670
storage so every time our models get

00:05:13,510 --> 00:05:16,930
bigger and bigger that's fine so is our

00:05:15,670 --> 00:05:20,260
data centers they're just getting bigger

00:05:16,930 --> 00:05:22,500
and bigger so as of the end of the year

00:05:20,260 --> 00:05:26,140
I can actually say that we will have

00:05:22,500 --> 00:05:27,700
completely lost all our filers in all

00:05:26,140 --> 00:05:29,500
our data centers and the entire

00:05:27,700 --> 00:05:33,420
infrastructure will be running on top of

00:05:29,500 --> 00:05:33,420
HDFS for all our data

00:05:40,040 --> 00:05:42,100

YouTube URL: https://www.youtube.com/watch?v=19YIN2FP9JQ


