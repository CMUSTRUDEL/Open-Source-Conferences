Title: Implementing custom models for machine learning with Lucy Yu (MemSQL)
Publication date: 2017-09-29
Playlist: Strata Data Conference 2017 - New York, New York
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,000 --> 00:00:03,419
hi this is Mike Henrickson from strata

00:00:01,890 --> 00:00:04,950
data in New York City I'm here with

00:00:03,419 --> 00:00:08,480
Lucie from M sequel who see how you

00:00:04,950 --> 00:00:10,830
doing good thanks so can you tell me

00:00:08,480 --> 00:00:12,750
I've had quite a few interviews with

00:00:10,830 --> 00:00:15,540
memc cool folks what's new with you guys

00:00:12,750 --> 00:00:17,820
what what do you guys up to so we just

00:00:15,540 --> 00:00:20,460
recently announced the release of mem

00:00:17,820 --> 00:00:23,609
sequel six which is a major release that

00:00:20,460 --> 00:00:26,160
has improvements in three key points the

00:00:23,609 --> 00:00:28,140
first is enhance online operations to

00:00:26,160 --> 00:00:31,590
keep your mission-critical things always

00:00:28,140 --> 00:00:33,890
available and the second is improve

00:00:31,590 --> 00:00:37,730
query processing and query optimization

00:00:33,890 --> 00:00:41,250
so for example we have vectorized

00:00:37,730 --> 00:00:43,200
compact like query processing now so

00:00:41,250 --> 00:00:47,930
that all of your queries will run a lot

00:00:43,200 --> 00:00:51,570
faster and then third we have improved

00:00:47,930 --> 00:00:54,600
functionality in our extensibility so

00:00:51,570 --> 00:00:59,059
this includes stored procedures which

00:00:54,600 --> 00:01:03,059
allows you to implement your own

00:00:59,059 --> 00:01:04,290
functions and models in non-sequel so

00:01:03,059 --> 00:01:06,720
one of the things we're hearing a lot

00:01:04,290 --> 00:01:08,700
about in this this event at strata data

00:01:06,720 --> 00:01:10,200
and I think we're hearing about it in

00:01:08,700 --> 00:01:13,140
the industry a lot is machine learning

00:01:10,200 --> 00:01:15,030
can you tell me how many equal is active

00:01:13,140 --> 00:01:17,340
in machine learning and more particular

00:01:15,030 --> 00:01:21,180
about how you handle it with real time

00:01:17,340 --> 00:01:25,500
data sure so in machine learning we

00:01:21,180 --> 00:01:28,470
natively support vector operations such

00:01:25,500 --> 00:01:30,990
as dot product that will allow users to

00:01:28,470 --> 00:01:35,700
implement a lot of machine learning

00:01:30,990 --> 00:01:40,380
models we also support scoring and again

00:01:35,700 --> 00:01:42,509
in extensibility we support the ability

00:01:40,380 --> 00:01:44,250
for users to define their own machine

00:01:42,509 --> 00:01:47,420
learning models such as k-means

00:01:44,250 --> 00:01:51,299
clustering in our special syntax

00:01:47,420 --> 00:01:55,219
excellent so your latest work in machine

00:01:51,299 --> 00:01:58,020
learning is around what I mean real time

00:01:55,219 --> 00:02:00,149
is that the rage right now for everyone

00:01:58,020 --> 00:02:02,759
and so you guys have a solution to help

00:02:00,149 --> 00:02:05,610
people that are looking at doing machine

00:02:02,759 --> 00:02:09,690
learning in a real time environment yeah

00:02:05,610 --> 00:02:13,010
so being able to implement custom models

00:02:09,690 --> 00:02:15,560
in them sequel itself provides great

00:02:13,010 --> 00:02:17,329
ability to do machine learning models in

00:02:15,560 --> 00:02:20,390
real time on your real time doodle and

00:02:17,329 --> 00:02:23,239
Men sequel we also have connectors to

00:02:20,390 --> 00:02:25,220
spark so that users can leverage sparks

00:02:23,239 --> 00:02:27,590
multitude of machine learning libraries

00:02:25,220 --> 00:02:30,909
on top of their none sequel data so if

00:02:27,590 --> 00:02:33,140
you think about the whole real-time

00:02:30,909 --> 00:02:37,129
marketplace and you think about machine

00:02:33,140 --> 00:02:38,930
learning why would someone want to put

00:02:37,129 --> 00:02:40,700
all their eggs in the mem sequel basket

00:02:38,930 --> 00:02:42,489
what is that you guys what's your secret

00:02:40,700 --> 00:02:46,159
sauce that you do better than everyone

00:02:42,489 --> 00:02:48,680
we have very fast data loading and the

00:02:46,159 --> 00:02:52,159
ability to support many connections to

00:02:48,680 --> 00:02:55,069
the database simultaneously so one thing

00:02:52,159 --> 00:02:59,000
that people might do is use something

00:02:55,069 --> 00:03:02,000
like spark with its plethora of machine

00:02:59,000 --> 00:03:03,620
learning models contributed by various

00:03:02,000 --> 00:03:05,420
members of the spark community which is

00:03:03,620 --> 00:03:08,840
very large because it's an open source

00:03:05,420 --> 00:03:11,629
project so they might use spark to

00:03:08,840 --> 00:03:14,599
generate machine learning models live

00:03:11,629 --> 00:03:17,810
with real-time streaming data and they

00:03:14,599 --> 00:03:20,419
can they can load that data into men

00:03:17,810 --> 00:03:22,849
sequel and then the data is available

00:03:20,419 --> 00:03:27,500
very quickly for business intelligence

00:03:22,849 --> 00:03:30,199
or clients that leverage mem sequel so

00:03:27,500 --> 00:03:31,940
that analysts can apply data science

00:03:30,199 --> 00:03:34,430
techniques do you see any particular

00:03:31,940 --> 00:03:36,970
industries that are moving more towards

00:03:34,430 --> 00:03:39,560
this real-time machine learning and

00:03:36,970 --> 00:03:41,449
basically partners have been mmm sequel

00:03:39,560 --> 00:03:45,590
do you see any industries moving quicker

00:03:41,449 --> 00:03:47,299
than other ones I'm not sure which

00:03:45,590 --> 00:03:50,359
industries are moving quicker than other

00:03:47,299 --> 00:03:52,160
ones but a use case that I think really

00:03:50,359 --> 00:03:57,769
exemplifies machine learning and then

00:03:52,160 --> 00:03:59,599
sequel is uber they they have like

00:03:57,769 --> 00:04:02,389
machine learning models in the

00:03:59,599 --> 00:04:05,389
background writing writing the model

00:04:02,389 --> 00:04:08,030
results - mmm sequel and these are used

00:04:05,389 --> 00:04:10,669
to power things like surge pricing or

00:04:08,030 --> 00:04:12,979
drivers for example get live real-time

00:04:10,669 --> 00:04:15,109
push notifications for telling them when

00:04:12,979 --> 00:04:17,989
they should have had to a hot area for

00:04:15,109 --> 00:04:21,019
more potential customers so my are my

00:04:17,989 --> 00:04:23,600
most unfavorite thing about uber surge

00:04:21,019 --> 00:04:25,990
pricing is a result of a

00:04:23,600 --> 00:04:28,790
and machine learning I guess the whole

00:04:25,990 --> 00:04:31,310
but maybe we can do an anti surge

00:04:28,790 --> 00:04:33,650
pricing maybe but if you are a driver

00:04:31,310 --> 00:04:36,860
you might think differently absolutely

00:04:33,650 --> 00:04:39,950
absolutely so if we sat down a year from

00:04:36,860 --> 00:04:42,080
now what would you like to say you guys

00:04:39,950 --> 00:04:43,180
are doing differently in the market and

00:04:42,080 --> 00:04:47,870
better

00:04:43,180 --> 00:04:50,450
that meant sweet mmm sequel so better I

00:04:47,870 --> 00:04:52,070
think the canonical way that we say

00:04:50,450 --> 00:04:55,160
we're better is in terms of speed

00:04:52,070 --> 00:04:57,260
because everything is in memory but the

00:04:55,160 --> 00:04:59,360
industry is moving also more towards

00:04:57,260 --> 00:05:01,580
focus on analytical workloads

00:04:59,360 --> 00:05:03,170
where you have a ton of historical data

00:05:01,580 --> 00:05:06,320
you're not necessarily trying to update

00:05:03,170 --> 00:05:08,630
specific rows very often you just want

00:05:06,320 --> 00:05:12,110
to collect batch statistics like large

00:05:08,630 --> 00:05:14,360
counts or aggregates so we have been

00:05:12,110 --> 00:05:17,510
evolving to support that very quickly -

00:05:14,360 --> 00:05:19,540
with our column column store databases

00:05:17,510 --> 00:05:22,340
that we store in disk which is

00:05:19,540 --> 00:05:24,410
attractive to customers because it's

00:05:22,340 --> 00:05:26,660
better for their wallets they don't

00:05:24,410 --> 00:05:28,550
necessarily have to be able to store all

00:05:26,660 --> 00:05:31,670
of their data in memory but it's still

00:05:28,550 --> 00:05:34,310
very fast because we store for example

00:05:31,670 --> 00:05:37,100
indices in memory that help us query it

00:05:34,310 --> 00:05:38,450
very quickly excellent well Lucy we look

00:05:37,100 --> 00:05:40,600
forward to that journey with you thank

00:05:38,450 --> 00:05:40,600
you

00:05:46,480 --> 00:05:48,540

YouTube URL: https://www.youtube.com/watch?v=uPlCYZgdoB0


