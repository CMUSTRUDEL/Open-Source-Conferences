Title: Unleashing intelligence and data analytics at scale 马子雅 (Ziya Ma) (Intel)
Publication date: 2017-09-27
Playlist: Strata Data Conference 2017 - New York, New York
Description: 
	The world’s most valuable currency is data, and it is appreciating at an impressive rate. Every business is becoming a data business, fueling new insights and intelligence, and advanced data analytics is reshaping the enterprise with new discoveries, better customer experiences, and improved products and services, all enabled by actionable insight. Ziya Ma shares how Intel is driving a holistic approach to powering advanced analytics and artificial intelligence workloads and unleashing intelligent and scalable insights from the edge to the cloud to the enterprise. From advanced silicon capabilities to optimized open source software and frameworks, these community-enabling and innovative solutions speed up analytics, increase scale, reduce cost, and improve efficiency by leveraging existing Intel architecture investment.

This keynote is sponsored by Intel.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:01,710 --> 00:00:07,890
I like to share this quote from Jeff

00:00:04,800 --> 00:00:11,610
Immelt with you today that if you walk

00:00:07,890 --> 00:00:14,010
up as the industrial company today you

00:00:11,610 --> 00:00:18,300
will wake up as analytics and a software

00:00:14,010 --> 00:00:21,000
company tomorrow it is so striking that

00:00:18,300 --> 00:00:24,869
a traditional company like GE is gearing

00:00:21,000 --> 00:00:26,790
up for the analytics wave we're seeing

00:00:24,869 --> 00:00:30,680
growing number of use cases for

00:00:26,790 --> 00:00:33,630
analytics and AI such as fraud detection

00:00:30,680 --> 00:00:37,800
autonomous driving supply chain

00:00:33,630 --> 00:00:43,379
optimization cyber security precision

00:00:37,800 --> 00:00:46,489
medicine and so on Intel is committed to

00:00:43,379 --> 00:00:50,039
game-changing analytics and AI solutions

00:00:46,489 --> 00:00:52,159
we have been making major investment for

00:00:50,039 --> 00:00:55,109
driving up our performance

00:00:52,159 --> 00:00:58,230
cost-effectiveness density and program

00:00:55,109 --> 00:01:01,980
ability we offer wide range of

00:00:58,230 --> 00:01:05,210
technologies from general purpose like

00:01:01,980 --> 00:01:10,500
Xeon and Xeon Phi to targeted silicon

00:01:05,210 --> 00:01:13,320
such as FPGA and navona on top of that

00:01:10,500 --> 00:01:17,130
we deliver fully optimize the software

00:01:13,320 --> 00:01:23,219
stack from libraries and frameworks to

00:01:17,130 --> 00:01:25,829
tools and solutions in the interest of

00:01:23,219 --> 00:01:27,960
time I'm going to focus the discussion

00:01:25,829 --> 00:01:32,759
on our newly launched the unscalable

00:01:27,960 --> 00:01:35,100
family and big dl0 scalable family is

00:01:32,759 --> 00:01:39,119
the biggest platform advancement in a

00:01:35,100 --> 00:01:42,840
decade Hadoop and spark stack optimized

00:01:39,119 --> 00:01:45,930
on the unscalable family achieves three

00:01:42,840 --> 00:01:48,719
times performance over the previous Dion

00:01:45,930 --> 00:01:52,350
generation for end-to-end big band

00:01:48,719 --> 00:01:54,270
workloads and shows 2.7 times

00:01:52,350 --> 00:01:57,780
performance for decision support

00:01:54,270 --> 00:02:05,130
workloads and improves performance by

00:01:57,780 --> 00:02:07,740
93% for high band workloads big dao is

00:02:05,130 --> 00:02:10,400
designed for Xeon servers it's a

00:02:07,740 --> 00:02:14,040
distributed deep learning framework

00:02:10,400 --> 00:02:15,600
organically build on Apache spark you

00:02:14,040 --> 00:02:18,840
can run it direct

00:02:15,600 --> 00:02:22,020
from your Hadoop osbahr clusters it's

00:02:18,840 --> 00:02:24,690
very easy to work with you can write big

00:02:22,020 --> 00:02:27,960
deal deep learning applications simply

00:02:24,690 --> 00:02:30,770
with Python or Scala it provides

00:02:27,960 --> 00:02:33,240
comprehensive deep learning support and

00:02:30,770 --> 00:02:37,290
implements about two hundred a layers

00:02:33,240 --> 00:02:40,050
for neural network in addition if you

00:02:37,290 --> 00:02:41,190
have already got pre Trent Cafe

00:02:40,050 --> 00:02:44,070
tensorflow

00:02:41,190 --> 00:02:46,560
or thort muddles big deal can load them

00:02:44,070 --> 00:02:50,040
directly into spark and run inference

00:02:46,560 --> 00:02:52,230
against them you know in the last cup of

00:02:50,040 --> 00:02:54,540
month we got many inquiries from our

00:02:52,230 --> 00:02:58,050
customers on big deals performance and

00:02:54,540 --> 00:03:01,080
scalability big deal deep learning

00:02:58,050 --> 00:03:04,410
training throughput of the unscalable

00:03:01,080 --> 00:03:06,450
family shows up to 72 percent

00:03:04,410 --> 00:03:10,140
performance improvement over the

00:03:06,450 --> 00:03:12,020
previously on generation it can also

00:03:10,140 --> 00:03:15,420
scale out very efficiently

00:03:12,020 --> 00:03:19,530
we tested on a 16 node the unscalable

00:03:15,420 --> 00:03:24,170
cluster it has near linear scalability

00:03:19,530 --> 00:03:28,610
it's a scaling efficiency is up to 92%

00:03:24,170 --> 00:03:32,070
one of our top customers tested on a 64

00:03:28,610 --> 00:03:36,380
noisy on scalable cluster their

00:03:32,070 --> 00:03:36,380
observation is consistent with ours

00:03:36,770 --> 00:03:43,050
cloud service providers like Amazon

00:03:39,780 --> 00:03:47,580
Microsoft and Alibaba enterprise

00:03:43,050 --> 00:03:51,510
customers and analytics is vs like cloud

00:03:47,580 --> 00:03:54,590
era data bricks and blue data have all

00:03:51,510 --> 00:03:54,590
adopted big deal

00:03:55,010 --> 00:04:03,750
JD dot-com is the top online retailer in

00:03:58,890 --> 00:04:06,209
China big deal on Xeon enable each ad to

00:04:03,750 --> 00:04:09,150
streamline is image detection and

00:04:06,209 --> 00:04:12,239
extraction pipeline better meet his

00:04:09,150 --> 00:04:16,169
requirements for flexibility scalability

00:04:12,239 --> 00:04:20,070
and performance per dollar as a result

00:04:16,169 --> 00:04:21,890
JD decided to upgrade its GPU solution

00:04:20,070 --> 00:04:25,770
to zero and big deal

00:04:21,890 --> 00:04:28,529
Caray recently launched its eureka xt

00:04:25,770 --> 00:04:31,589
solution which integrates big deal

00:04:28,529 --> 00:04:38,879
as the default deep-learning library for

00:04:31,589 --> 00:04:40,289
supercomputer scale let's see what our

00:04:38,879 --> 00:04:42,269
customer have to say

00:04:40,289 --> 00:04:44,189
machine learning is going through

00:04:42,269 --> 00:04:46,079
something of a Renaissance because the

00:04:44,189 --> 00:04:46,589
challenge is associated to operating as

00:04:46,079 --> 00:04:48,329
scale

00:04:46,589 --> 00:04:50,249
have been removed in the cloud today

00:04:48,329 --> 00:04:51,929
there are thousands of engineers focused

00:04:50,249 --> 00:04:54,089
on applying these techniques across all

00:04:51,929 --> 00:04:56,549
areas of the Amazon business with use

00:04:54,089 --> 00:04:59,129
cases like Alexa customer service

00:04:56,549 --> 00:05:02,159
robotic fulfillment drone delivery with

00:04:59,129 --> 00:05:04,259
prime air Amazon go AWS customers are

00:05:02,159 --> 00:05:06,119
running large sophisticated machine

00:05:04,259 --> 00:05:07,739
learning models on AWS and the

00:05:06,119 --> 00:05:10,139
computational power of the Intel Xeon

00:05:07,739 --> 00:05:12,569
scalable processor that's the muse more

00:05:10,139 --> 00:05:14,609
data to create innovative new products

00:05:12,569 --> 00:05:16,589
and experiences powered by machine

00:05:14,609 --> 00:05:18,509
learning together with Intel we've

00:05:16,589 --> 00:05:20,189
optimized deep learning engines with the

00:05:18,509 --> 00:05:23,009
latest version of the Intel math kernal

00:05:20,189 --> 00:05:25,019
library and the Intel Xeon scalable

00:05:23,009 --> 00:05:27,089
processors available on the new c5

00:05:25,019 --> 00:05:29,609
instance family to increase inference

00:05:27,089 --> 00:05:31,649
performance by over 100 X we've also

00:05:29,609 --> 00:05:33,569
worked closely with Intel to demonstrate

00:05:31,649 --> 00:05:36,389
how you can use familiar tools such as

00:05:33,569 --> 00:05:38,159
Apache spark and big dl to easily build

00:05:36,389 --> 00:05:40,799
distributed deep learning applications

00:05:38,159 --> 00:05:42,809
on AWS we couldn't be more excited to

00:05:40,799 --> 00:05:44,489
see how customers put them to use as we

00:05:42,809 --> 00:05:54,539
continue to pioneer with our friends at

00:05:44,489 --> 00:05:57,119
Intel Intel is committed to accelerating

00:05:54,539 --> 00:05:59,879
and democratizing technologies for

00:05:57,119 --> 00:06:02,279
analytics and AI we know the future

00:05:59,879 --> 00:06:04,529
because we're building it we look

00:06:02,279 --> 00:06:06,929
forward to furthering our collaboration

00:06:04,529 --> 00:06:08,470
with partners like you with that thank

00:06:06,929 --> 00:06:13,399
you

00:06:08,470 --> 00:06:13,399
[Applause]

00:06:18,080 --> 00:06:20,139

YouTube URL: https://www.youtube.com/watch?v=NNfL1JtqE7g


