Title: SQL Engine Wars Continue and Everybody Wins! Josh Klahr (AtScale)
Publication date: 2016-10-20
Playlist: Strata NYC 2016 - Solutions Showcase Theater
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	                              the topic today is benchmarking which i                               think is everybody's favorite hadoop                               topic to give you a little context this                               is actually the second version of the                               the benchmarks that we've done we're                               looking at sequel on to do query                               performance and what we're trying to                               figure out is of the sequel on dedupe                               engines that are out there hive spark                                impala you'll see we added presto this                                time around which ones are the fastest i                                will do a really quick overview of at                                scale i'm going to talk almost entirely                                about the benchmarks but this is kind of                                useful context to understand why we've                                done the benchmarks the way that we have                                so at scale is basically a business                                intelligence layer and we sit the sit                                between bi tools tableau Cognos                                MicroStrategy Excel the most popular bi                                tool in the world and we provide an                                interface that makes it really easy to                                use those bi tools to query underlying                                data that's sitting on your Hadoop                                cluster the way that we do this is the                                interface we expose is a dimensional                                model in the form of measures and                                dimensions we translate those queries                                into queries that run on the Hadoop                                cluster using the sequel wanna do                                vengeance so we push all of our                                processing down to the Hadoop cluster we                                don't want to be in the business of                                trying to build a better parallel                                processing query engine and the other                                thing that we do in addition to                                satisfying those queries using one of                                the sequel on a doob engines is we build                                aggregate tables so as we see user query                                patterns we start to build up aggregate                                tables that represent commonly requested                                attributes and what that means is the                                next time we see a similar query instead                                of hitting the raw data we can hit the                                aggregate table instead very traditional                                if you've been around in the world of                                data warehousing business intelligence                                using aggregates to improve performance                                a really common practice in the case of                                at scale we're building and managing                                those aggregates and we're doing it on                                the cluster what this means is that                                you'll see the framework for the way we                                do the bi on a new benchmark is we're                                really evaluating the sequel on a doob                                engines for three main characteristics                                the first is when we submit a query                                against billions of rows of data                                what is the what does the profile look                                like because in some cases there might                                not be aggregated if the aggregates                                haven't been built or it's the first                                query after our interface has been                                published we're going to hit the raw                                data so we want to know how fast can                                impala process an                                                     the other thing that we want to look at                                is how fast do these engines on small                                queries our aggregate tables could be on                                the order of a few hundred thousand to a                                million rows to                                                         that's small query in Hadoop land we                                want to know how fast are those queries                                against the aggregate tables and the                                third thing we're looking at is because                                we're supporting production bi workloads                                because we want hundreds of tableau                                users or thousands of MicroStrategy                                users to query our system we look at                                concurrency we want to figure out how                                many concurrent users can hit the at                                scale interface and leverage those                                underlying sequel on dedupe engines                                without the system falling over kinda                                what does that profile look like so                                that's essentially the framework for the                                benchmarks that we've run we've we've                                done these benchmarks on an internal                                   node cluster that we have back in our SK                                labs these clusters are pretty beefy                                    gigs of ram per machine we've got SSD                                hard drives                                                         data set that we looked at is called the                                star schema benchmark or the SSB                                benchmark it's derived from if you're                                familiar with t PCH it's derived from t                                PCH but it turns it into a star schema                                instead of the transactional scheme of                                the tpc h's for this version we looked                                 at impala hive on tez and and hive using                                 ll AP which is live long and process                                 it's the most recent version of hive we                                 looked at presto and we looked at sparks                                 equal so those are the four engines that                                 we considered and we ran each of these                                 engines through                                                          queries range from no joins or one join                                 with a few filters and a few group buys                                                                                                          filters and one of the joins that we did                                 was a really big join and we wanted to                                 test what does it look like to join a                                 billion row customer table with a six                                 billion row                                 fact data set because that's one of the                                 areas where the sea where these engines                                 struggle is when you're doing really big                                 joins and then we ran those same queries                                 against the raw data and then the                                 aggregate data and then we we ran one                                 user                                                                    that's really what the framework looked                                 like what was new for the second edition                                 is the first time around we did in Palo                                 two three we just benchmarked Impala                                    we just benchmarked hive to one last                                 time we did hive                                                       asked he'll actually ships with our own                                 embedded version of spark that we build                                 off of off of the main spark branch so                                 most of the distros have spark                                       ship with with spark                                                   why in a second and we added presto the                                 first time around we didn't do presto                                 for this version of the benchmark we                                 included presto um so a few a few                                 highlights to take away the first is as                                 you as you would expect as we're                                 increasing the complexity of the query                                 query times increase across the board                                 for the different engines one of the                                 things that you'll note is that hive and                                 presto track pretty closely together so                                 hive and presto look pretty similar from                                 a performance perspective up until query                                 for spark and Impala are relatively                                 close together query for has four joins                                 and for group buys and spark actually                                 starts to outperform impala for complex                                 joins because it has multi-threaded                                 multi thought I'd processing and Impala                                 doesn't yet the other thing you see is                                 that the Impala and spark a very                                 sensitive to selectivity each of these                                 queries queries                                                  increasing in terms of the filtering                                 that are in those queries and the                                 performance of Impala one spark                                 increases and that's because some of the                                 stuff that both in pollen spark are                                 doing with one time filtering and and                                 pushing down and doing partition pruning                                 so some of the some of the improvements                                 that have been added in the recent                                 releases                                 what's generating that profile for small                                 query performance one of the things you                                 would have seen in the previous version                                 is I've tended to be a lot slower across                                 the board what we're seeing this time is                                 other than those really small queries                                 which are coming back in under two                                 seconds all of the other queries except                                 for query                                                             why yet hive is performing pretty well                                 on these small data sets this is in                                 large part because we're using ll AP we                                 had ll ap configure that's really a                                 persistent a persistent processing                                 engine so we're not spinning up a hive                                 job for each query that we need to                                 satisfy its running all the time and so                                 that really reduces the latency for                                 these small queries and then the final                                 thing we looked at was really                                 concurrency so what does it look like as                                 we start to add more and more users to                                 the system and we're not necessarily                                 looking to see does response time                                 remains the same as we increase query                                 patterns because these are really                                 throughput based systems and as you                                 would expect performance will get slower                                 and slower as you had more users but                                 what we were looking for was linear                                 degradation performance and also to                                 query start to fail and across all the                                 engines there are no failures so up to                                                                                                      simultaneously submitted queries against                                 these data sets we saw no failures                                 Impala spark and presto tend to do best                                 for concurrency in fact presto you can                                 see when we got up to                                                   queries was the best in terms of                                 concurrent query performance for the                                 kinds of works workloads that worse                                 supporting we really want to start                                 bringing these bi workloads directly to                                 the Hadoop cluster so looking at                                 concurrency is an important aspect of                                 what people are evaluating I'm the other                                 question that that a lot of folks have                                 had is what is really the performance                                 looked like between the last time we did                                 these benchmarks and this time and to me                                 this is the most telling slide and it's                                 the story is a really good one across                                 the board every query engine improved so                                 if you look at the big queries between                                 five one three and five to one we saw a                                                                                                    improved                                                                                                                                         both Cloudera and Hortonworks had                                 sessions yesterday where they were                                 talking about these advancements they're                                 they're real we're seeing them really in                                 our own internal benchmarking of how                                 fast these engines are getting from                                 release to release we're legitimately                                 seeing great performance gains we saw a                                 really good performance in terms of                                 concurrency hive                                                        two times better impala was already                                 pretty good from a concurrency                                 perspective so we didn't see huge gains                                 but you also see on the small queries                                 that hive while the other two engines                                 stayed relatively the same because they                                 already are persistent demons hive with                                 ll AP is around two times faster for                                 those small queries which we thought was                                 was pretty exciting so our punch line                                 here is in the sequel hood on Hadoop                                 Wars which I think they're still going                                 on honestly everybody wins there's great                                 progress across the board I think this                                 is kind of a proof point of the way the                                 open source community is developing and                                 the velocity of development is there's                                 there's really great improvements and                                 what we're seeing is the performance                                 that you can get from the sequel on                                 Hadoop engines in fact that was visiting                                 a big financial services customer today                                 that's doing benchmarking of two old                                 school MPP databases along with Impala                                 and sparks equal in their own                                 independent evaluations and they're                                 seeing comparable performance with the                                 MPP databases and these engines running                                 on to do so we're really to the point                                 where the sequel on to do Benjen are are                                 stacking up against those MPP databases                                 and they're giving you a whole lot of                                 other benefits which is there on cluster                                 you're not moving data the data is                                 multi-purpose so it can be consumed by                                 other processes the management is all                                 integrated with yarn so a lot of great                                 stuff happening in the sequel on I do                                 resource                                 community so that's it this was a lot of                                 stuff in a very very short period of                                 time if you guys want to learn more we                                 haven't published the official benchmark                                 yet that's going to be coming out in the                                 middle of October but if you go to at                                 scale calm / benchmark you can sign up                                 and we will send you the full details                                 the full details are all the queries                                 exactly how we did the set up all the                                 response times our detailed tuning that                                 we did for each of the engines and our                                 evaluation of what were the components                                 that led to those increase in terms of                                 performance was at Parque reading was at                                 runtime filtering etc you can also come                                 visit us we're just over here at booth                                 with booth for                                                   interested in participating we we also                                 do an annual hit maturity survey last                                 year we had over                                                        you participate in the survey you get a                                 copy of the results and it's really                                 looking at what are the main workloads                                 people are putting through Hadoop where                                 are they on that maturity curve all                                 right thanks for coming hope you enjoyed                                 it come visit us
YouTube URL: https://www.youtube.com/watch?v=49OsvRdy7LI


