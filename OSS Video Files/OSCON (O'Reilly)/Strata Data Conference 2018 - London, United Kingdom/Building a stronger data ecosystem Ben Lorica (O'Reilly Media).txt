Title: Building a stronger data ecosystem Ben Lorica (O'Reilly Media)
Publication date: 2018-05-23
Playlist: Strata Data Conference 2018 - London, United Kingdom
Description: 
	To enable the machine learning applications of the future, there remain many interesting and challenging data problems we need to tackle as a community. Ben Lorica discusses some of the pressing problems weâ€™re facing as we collect and store data, particularly in an era when our machine learning models require huge amounts of labeled data.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,870 --> 00:00:06,210
we are living in a highly empirical era

00:00:03,959 --> 00:00:08,430
for machine learning and in particular

00:00:06,210 --> 00:00:11,610
the models that we are using are very

00:00:08,430 --> 00:00:15,260
data hungry so let's take a step back

00:00:11,610 --> 00:00:18,269
and talk about data for a few minutes so

00:00:15,260 --> 00:00:21,240
in our community if there's an adage

00:00:18,269 --> 00:00:23,699
that we've all come to take for granted

00:00:21,240 --> 00:00:26,429
which is that data is more valuable to

00:00:23,699 --> 00:00:28,019
models which is kind of true if you

00:00:26,429 --> 00:00:30,720
think about the number of people you

00:00:28,019 --> 00:00:32,160
talk to most of them will share what

00:00:30,720 --> 00:00:34,740
kind of neural network architecture

00:00:32,160 --> 00:00:37,670
they're using but very few of them will

00:00:34,740 --> 00:00:41,910
talk about what features they're using

00:00:37,670 --> 00:00:44,670
so if data is valuable well let's take a

00:00:41,910 --> 00:00:46,700
step back and try to figure out how do

00:00:44,670 --> 00:00:50,580
we value data

00:00:46,700 --> 00:00:53,430
well first most of us have probably

00:00:50,580 --> 00:00:55,560
built models that required augmenting

00:00:53,430 --> 00:00:59,040
our existing data sets with external

00:00:55,560 --> 00:01:00,690
data so there's data providers that

00:00:59,040 --> 00:01:02,310
we've come to work with so we kind of

00:01:00,690 --> 00:01:05,999
know the value of data because we

00:01:02,310 --> 00:01:08,579
subscribe to these data providers in the

00:01:05,999 --> 00:01:10,850
age of deep learning many of us have

00:01:08,579 --> 00:01:14,820
started working on building our own

00:01:10,850 --> 00:01:18,689
labelled data sets and there are many

00:01:14,820 --> 00:01:21,600
many data providers that I mean data

00:01:18,689 --> 00:01:24,450
labeling services that let us do that

00:01:21,600 --> 00:01:28,619
and we kind of have an idea roughly of

00:01:24,450 --> 00:01:31,350
how much they charge more recently

00:01:28,619 --> 00:01:34,350
there's been a rise at least for

00:01:31,350 --> 00:01:36,539
computer vision of providers that will

00:01:34,350 --> 00:01:41,520
even generate synthetic data for

00:01:36,539 --> 00:01:44,100
training now another way to think about

00:01:41,520 --> 00:01:46,499
data is look at companies who are known

00:01:44,100 --> 00:01:48,030
for having interesting data sets right

00:01:46,499 --> 00:01:50,639
and look at their valuation so I've

00:01:48,030 --> 00:01:52,259
listed a few here mostly in media but

00:01:50,639 --> 00:01:55,009
there are many many examples of

00:01:52,259 --> 00:01:56,999
companies who are well known for

00:01:55,009 --> 00:02:00,719
supplying data scientists with

00:01:56,999 --> 00:02:04,170
interesting data or even metadata and

00:02:00,719 --> 00:02:06,389
then of course there's the whole process

00:02:04,170 --> 00:02:09,209
of building a model so you build a model

00:02:06,389 --> 00:02:11,909
with data you have you augment it and

00:02:09,209 --> 00:02:14,460
you kind of have an idea of what's the

00:02:11,909 --> 00:02:19,050
incremental value of the

00:02:14,460 --> 00:02:23,820
additional data set and then of course

00:02:19,050 --> 00:02:26,160
there's the effect of data on equity

00:02:23,820 --> 00:02:29,280
prices of the data providers themselves

00:02:26,160 --> 00:02:32,610
so here's an example from Equifax which

00:02:29,280 --> 00:02:34,800
suffered a well known data breach but

00:02:32,610 --> 00:02:37,500
it's not limited to data breaches right

00:02:34,800 --> 00:02:41,100
so for example Facebook and Cambridge

00:02:37,500 --> 00:02:43,560
analytic their stock price was affected

00:02:41,100 --> 00:02:47,280
by misuse of data

00:02:43,560 --> 00:02:50,460
not-not-not a data Beach so among the

00:02:47,280 --> 00:02:51,810
stakeholders there's a change in an

00:02:50,460 --> 00:02:55,020
attitude overseer

00:02:51,810 --> 00:02:58,470
so we heard about GDP are so so we're

00:02:55,020 --> 00:03:00,510
hearing from regulators but users and

00:02:58,470 --> 00:03:03,420
consumers are also much more aware about

00:03:00,510 --> 00:03:06,920
the need for control on their part and

00:03:03,420 --> 00:03:09,630
better transparency on the part of

00:03:06,920 --> 00:03:12,660
companies so transparency when it comes

00:03:09,630 --> 00:03:15,150
to what data is being collected what is

00:03:12,660 --> 00:03:17,690
it being used for and how long is it

00:03:15,150 --> 00:03:17,690

YouTube URL: https://www.youtube.com/watch?v=BWvxJ7qwTGM


