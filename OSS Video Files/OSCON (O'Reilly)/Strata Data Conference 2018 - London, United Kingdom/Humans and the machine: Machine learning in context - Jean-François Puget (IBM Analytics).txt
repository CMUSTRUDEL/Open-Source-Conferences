Title: Humans and the machine: Machine learning in context - Jean-François Puget (IBM Analytics)
Publication date: 2018-05-23
Playlist: Strata Data Conference 2018 - London, United Kingdom
Description: 
	Some machine learning proponents claim you only have to provide data to get value. However, reality is a bit more complex. On the way to active analytics for business, we have to answer two big questions: What must happen to data before running machine learning algorithms, and how should machine learning output be used to generate actual business value?

Jean-François Puget demonstrates the vital role of human context in answering those questions. You’ll discover why human context should be embraced as a guide to building better, smarter systems that people will use, trust, and love.

This keynote is sponsored by IBM.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,550 --> 00:00:06,069
hello how are you this morning so don't

00:00:03,340 --> 00:00:09,339
worry I will not speak about GDP are not

00:00:06,069 --> 00:00:11,919
that it's a minor topic you had to talk

00:00:09,339 --> 00:00:14,709
about it but it may be a bit late to

00:00:11,919 --> 00:00:18,970
worry about it with few days before

00:00:14,709 --> 00:00:20,800
complying so I would speak about

00:00:18,970 --> 00:00:22,630
something else that is not discussed

00:00:20,800 --> 00:00:27,640
enough to my taste

00:00:22,630 --> 00:00:31,089
the human factor so we all read this in

00:00:27,640 --> 00:00:33,940
newspaper and social media if you have

00:00:31,089 --> 00:00:38,080
data you apply something magic called

00:00:33,940 --> 00:00:40,420
machine learning and you get value we

00:00:38,080 --> 00:00:42,220
read the same if you replace machine

00:00:40,420 --> 00:00:46,630
learning by AI artificial intelligence

00:00:42,220 --> 00:00:50,050
or the planning and if you think about

00:00:46,630 --> 00:00:54,040
it few years ago we were we were reading

00:00:50,050 --> 00:00:57,010
the same with big data so first that's

00:00:54,040 --> 00:01:01,600
true with these technologies you can

00:00:57,010 --> 00:01:05,140
build a system that deliver value but

00:01:01,600 --> 00:01:07,810
it's no magic you see question marks you

00:01:05,140 --> 00:01:10,539
need to do things before you run your

00:01:07,810 --> 00:01:14,159
favorite machine learning algorithm or

00:01:10,539 --> 00:01:17,710
train your favorite deep learning model

00:01:14,159 --> 00:01:20,289
animals so you must prepare data data

00:01:17,710 --> 00:01:23,350
scientists do a lot of you are data

00:01:20,289 --> 00:01:26,259
scientist you know going from data to

00:01:23,350 --> 00:01:28,539
good model is not that easy and once you

00:01:26,259 --> 00:01:30,399
have models you need to put them in a

00:01:28,539 --> 00:01:33,909
production environment which is also

00:01:30,399 --> 00:01:37,390
something not trivial so I could have

00:01:33,909 --> 00:01:42,249
and we give talks about how our platform

00:01:37,390 --> 00:01:44,799
helps you fill the question marks but

00:01:42,249 --> 00:01:46,960
even with a good platform like I've been

00:01:44,799 --> 00:01:51,399
data science experience the orders of

00:01:46,960 --> 00:01:55,479
course it's not enough because very

00:01:51,399 --> 00:01:57,520
often machine learning and AI is used to

00:01:55,479 --> 00:02:04,060
deal with human to help human make

00:01:57,520 --> 00:02:07,689
better decisions or guide them and this

00:02:04,060 --> 00:02:12,150
is where problems can arise so let me

00:02:07,689 --> 00:02:16,380
give you two examples customers of ours

00:02:12,150 --> 00:02:16,380
so in my first exam

00:02:16,860 --> 00:02:24,870
we developed with a partner for large

00:02:20,110 --> 00:02:29,070
hotel from company I think it is a

00:02:24,870 --> 00:02:32,320
Holiday Inn we developed an automated

00:02:29,070 --> 00:02:35,050
pricing system so we all know that the

00:02:32,320 --> 00:02:39,730
same room can be sold at different price

00:02:35,050 --> 00:02:43,030
depending on when in the year it is the

00:02:39,730 --> 00:02:44,320
stays and how long in advance do you

00:02:43,030 --> 00:02:48,190
make the reservation

00:02:44,320 --> 00:02:51,400
basically the modem and the high or the

00:02:48,190 --> 00:02:53,430
price and the closer to the well it

00:02:51,400 --> 00:02:57,310
depends on the demand but price

00:02:53,430 --> 00:02:59,080
basically said to maximise margin for

00:02:57,310 --> 00:03:03,130
the hotel but not only

00:02:59,080 --> 00:03:07,480
also please frequent customers etc so

00:03:03,130 --> 00:03:11,050
our partner did a very good job and on

00:03:07,480 --> 00:03:13,209
the pilot we found that the margin of

00:03:11,050 --> 00:03:16,180
the hotel was improved by more than two

00:03:13,209 --> 00:03:18,730
percent and at the time of the pilot

00:03:16,180 --> 00:03:22,000
hotel industry was a very low margin I

00:03:18,730 --> 00:03:26,200
think it's a bit better now and this

00:03:22,000 --> 00:03:30,580
made this mean an improvement of 50% of

00:03:26,200 --> 00:03:33,070
their margin 50% so basically your

00:03:30,580 --> 00:03:35,620
profit goes up by 50% so it's it's

00:03:33,070 --> 00:03:37,750
really interesting and at that time this

00:03:35,620 --> 00:03:42,070
would mean for the industry billions of

00:03:37,750 --> 00:03:43,840
additional revenue additional profit so

00:03:42,070 --> 00:03:45,970
when you develop an application with

00:03:43,840 --> 00:03:47,830
this return on investment you would

00:03:45,970 --> 00:03:52,660
think that people would adopt it

00:03:47,830 --> 00:03:56,230
overnight not really that's where the

00:03:52,660 --> 00:03:59,560
human factor comes in so the pilot was

00:03:56,230 --> 00:04:03,670
presented to all the managers worldwide

00:03:59,560 --> 00:04:05,140
for this hotel chain and managers all

00:04:03,670 --> 00:04:09,370
had the same reaction

00:04:05,140 --> 00:04:12,370
they said I know what I'm doing I've

00:04:09,370 --> 00:04:15,370
been doing this for 20 years it's not

00:04:12,370 --> 00:04:17,620
not those young kids called data

00:04:15,370 --> 00:04:22,919
scientists that will teach me how to do

00:04:17,620 --> 00:04:22,919
my job so they did not adopt it

00:04:23,410 --> 00:04:33,250
so the reason why was managers thought

00:04:28,810 --> 00:04:36,850
they were doing a fairly good job and

00:04:33,250 --> 00:04:40,030
actually we had to make them realize

00:04:36,850 --> 00:04:44,140
that no they were leaving money on the

00:04:40,030 --> 00:04:48,730
table we must show them some pain before

00:04:44,140 --> 00:04:52,450
they can accept a cure so what we did

00:04:48,730 --> 00:04:55,050
well our partner did was to do a game a

00:04:52,450 --> 00:04:58,270
game application a gaming application

00:04:55,050 --> 00:05:01,690
with a simulated hotel and simulated

00:04:58,270 --> 00:05:05,200
competitor hotel and managers were asked

00:05:01,690 --> 00:05:08,590
to set room price and the simulator was

00:05:05,200 --> 00:05:11,050
simulating the business and they were

00:05:08,590 --> 00:05:15,460
competing against our automated pricing

00:05:11,050 --> 00:05:19,000
system and the automated pricing system

00:05:15,460 --> 00:05:24,430
was consistently beating the managers by

00:05:19,000 --> 00:05:28,630
few percent margin so here is a snapshot

00:05:24,430 --> 00:05:30,820
of the UI well see if we were selling a

00:05:28,630 --> 00:05:33,790
game with this UI we would not make much

00:05:30,820 --> 00:05:37,330
money right but it's informative for

00:05:33,790 --> 00:05:41,080
managers and what is very important is

00:05:37,330 --> 00:05:44,490
the bottom right number 2.6 is a

00:05:41,080 --> 00:05:51,790
difference in margin between what the

00:05:44,490 --> 00:05:54,790
system was doing versus a manager so

00:05:51,790 --> 00:05:57,220
when people see it they they start again

00:05:54,790 --> 00:05:59,350
and after they've tried several time to

00:05:57,220 --> 00:06:01,990
beat the system they trust it

00:05:59,350 --> 00:06:09,430
they see the value and then adoption

00:06:01,990 --> 00:06:11,910
began so the lesson is when you start an

00:06:09,430 --> 00:06:14,620
AI project a machine learning project

00:06:11,910 --> 00:06:17,230
sure you must think about how you go

00:06:14,620 --> 00:06:21,460
from data to models how you go to models

00:06:17,230 --> 00:06:25,450
to a production environment but more if

00:06:21,460 --> 00:06:29,820
humans are involved in how predictions

00:06:25,450 --> 00:06:34,570
scoring is used then you must imply

00:06:29,820 --> 00:06:37,030
include how human will react from the

00:06:34,570 --> 00:06:39,430
start maybe you need to train there

00:06:37,030 --> 00:06:41,610
maybe you need to revisit your business

00:06:39,430 --> 00:06:45,790
workflow maybe you need to change

00:06:41,610 --> 00:06:47,860
approval process what or maybe you need

00:06:45,790 --> 00:06:50,170
to have a game like this the point is

00:06:47,860 --> 00:06:52,270
you need to make sure that users will

00:06:50,170 --> 00:06:55,990
trust and love the system instead of

00:06:52,270 --> 00:07:01,300
fighting it and make no mistake people

00:06:55,990 --> 00:07:04,810
can feel threatened by AI systems so

00:07:01,300 --> 00:07:08,440
think about how to make people adopt

00:07:04,810 --> 00:07:09,880
what you're building from the start not

00:07:08,440 --> 00:07:12,160
as an afterthought

00:07:09,880 --> 00:07:14,860
so I've discussed what to do once you

00:07:12,160 --> 00:07:20,920
have models let's look at what you do

00:07:14,860 --> 00:07:23,080
before so let me comment this in a

00:07:20,920 --> 00:07:28,740
minute just to stay in the hotel

00:07:23,080 --> 00:07:31,870
industry Orbitz using machine learning

00:07:28,740 --> 00:07:35,650
was also setting price of tomatillo so

00:07:31,870 --> 00:07:38,860
it's it's travel and users soon found

00:07:35,650 --> 00:07:41,320
that if they were connecting using a

00:07:38,860 --> 00:07:44,800
Napper device they were shown more

00:07:41,320 --> 00:07:48,160
expensive price and this was not very

00:07:44,800 --> 00:07:50,590
good for public creation but it was good

00:07:48,160 --> 00:07:54,340
for the machine learning model and

00:07:50,590 --> 00:07:59,260
instead of blaming machine learning we

00:07:54,340 --> 00:08:01,990
should be a bit astonished that machine

00:07:59,260 --> 00:08:06,250
learning learned bias and that's the

00:08:01,990 --> 00:08:09,580
name that Apple owners are spending more

00:08:06,250 --> 00:08:12,400
than other people so if you don't want

00:08:09,580 --> 00:08:15,220
this bias in your system in this case

00:08:12,400 --> 00:08:19,140
it's simple you don't use the device as

00:08:15,220 --> 00:08:22,180
one of your input feature to the model

00:08:19,140 --> 00:08:25,090
then the model will not not learn the

00:08:22,180 --> 00:08:29,860
bias but bias can be a bit more complex

00:08:25,090 --> 00:08:32,200
so MIT made a study all my chocolate

00:08:29,860 --> 00:08:36,040
vendors have been included have a face

00:08:32,200 --> 00:08:39,460
recognition service and they did they

00:08:36,040 --> 00:08:42,580
took members of parliament from all over

00:08:39,460 --> 00:08:45,190
the world and they ran experiment and

00:08:42,580 --> 00:08:46,490
major vendors and in our case we had a

00:08:45,190 --> 00:08:52,820
point three

00:08:46,490 --> 00:08:54,980
rate for recognition of white male we

00:08:52,820 --> 00:09:00,890
were quite pleased about it can improve

00:08:54,980 --> 00:09:02,990
a bit but near-perfect but when when we

00:09:00,890 --> 00:09:08,720
look at other categories like a black

00:09:02,990 --> 00:09:10,190
woman accuracy was the disaster and in

00:09:08,720 --> 00:09:12,170
this case it's not because of the

00:09:10,190 --> 00:09:14,750
algorithm the model whatever it's about

00:09:12,170 --> 00:09:18,890
the training data the training data did

00:09:14,750 --> 00:09:22,580
not have enough diversity so we fixed it

00:09:18,890 --> 00:09:25,940
by retraining the model using more

00:09:22,580 --> 00:09:29,149
representative data set this is just to

00:09:25,940 --> 00:09:31,580
show again that the human factor here

00:09:29,149 --> 00:09:33,500
plays in how you train your models what

00:09:31,580 --> 00:09:37,100
they tell will you use if there is a

00:09:33,500 --> 00:09:41,209
bias in your data the machine learning

00:09:37,100 --> 00:09:44,660
technology will learn it so the

00:09:41,209 --> 00:09:47,089
conclusion is in many case when you

00:09:44,660 --> 00:09:49,820
build your machine learning systems

00:09:47,089 --> 00:09:52,399
think about the human factor in how you

00:09:49,820 --> 00:09:55,550
prepare data make sure you don't inject

00:09:52,399 --> 00:10:00,410
a bias and also make sure that results

00:09:55,550 --> 00:10:03,020
are acceptable and this concludes my my

00:10:00,410 --> 00:10:05,029
talk you can come visit us at the booth

00:10:03,020 --> 00:10:06,900
I will be there if you want to follow up

00:10:05,029 --> 00:10:11,360
thank you very much

00:10:06,900 --> 00:10:11,360

YouTube URL: https://www.youtube.com/watch?v=Zv4aUDHSDzQ


