Title: The Future of Machine Learning is Tiny - Pete Warden (Google)
Publication date: 2019-06-28
Playlist: The O'Reilly Artificial Intelligence Conference 2019, Beijing, China
Description: 
	There are over 250 billion embedded devices active in the world, and the number shipped is growing by 20% every year. They are gathering massive amounts of sensor data, far more than can ever be transmitted or processed in the cloud.

On-device machine learning gives us the ability to turn this wasted data into actionable information, and will enable a massive number of new applications over the next few years. Pete Warden digs into why embedded machine learning is so important, how to implement it on existing chips, and some of the new use cases it will unlock.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,149 --> 00:00:07,919
deep learning is compute bound it hat or

00:00:06,359 --> 00:00:10,710
to put it another way it has a high

00:00:07,919 --> 00:00:14,690
arithmetic intensity and what that means

00:00:10,710 --> 00:00:17,070
in practice is you don't need much

00:00:14,690 --> 00:00:19,410
memory storage you don't need much

00:00:17,070 --> 00:00:23,250
memory access but you do need the

00:00:19,410 --> 00:00:26,070
ability to learn millions or hundreds of

00:00:23,250 --> 00:00:30,769
millions of arithmetic ops in order to

00:00:26,070 --> 00:00:34,649
execute these machine learning models

00:00:30,769 --> 00:00:36,690
luckily that matches what these kind of

00:00:34,649 --> 00:00:38,820
microcontrollers actually have they

00:00:36,690 --> 00:00:42,480
might only have a few hundred kilobytes

00:00:38,820 --> 00:00:44,010
of memory but they're able to run tens

00:00:42,480 --> 00:00:47,570
of millions or hundreds of millions

00:00:44,010 --> 00:00:50,070
instructions every second and

00:00:47,570 --> 00:00:53,520
interestingly enough when I joined

00:00:50,070 --> 00:00:59,399
Google I found that the hey Google team

00:00:53,520 --> 00:01:02,039
were running a 13 kilobyte model on DSPs

00:00:59,399 --> 00:01:06,479
in order to do speech keyword

00:01:02,039 --> 00:01:08,430
recognition and Apple have actually done

00:01:06,479 --> 00:01:10,170
a blog post about how they've been doing

00:01:08,430 --> 00:01:14,010
the same thing for years

00:01:10,170 --> 00:01:15,930
so these speech teams have actually

00:01:14,010 --> 00:01:18,000
found that running your networks on

00:01:15,930 --> 00:01:19,560
these tiny computers is the most

00:01:18,000 --> 00:01:22,560
effective way of dealing with their

00:01:19,560 --> 00:01:25,520
sensor data but it hasn't been something

00:01:22,560 --> 00:01:28,740
that's been widely known either in the

00:01:25,520 --> 00:01:32,850
embedded community or in the machine

00:01:28,740 --> 00:01:34,290
learning community so we already have

00:01:32,850 --> 00:01:36,570
proof of some really practical

00:01:34,290 --> 00:01:38,130
applications where this works they're

00:01:36,570 --> 00:01:44,040
just not very well known because they're

00:01:38,130 --> 00:01:47,189
hidden within big companies and one of

00:01:44,040 --> 00:01:50,729
the really nice things is that because

00:01:47,189 --> 00:01:53,040
deep learning is mostly about doing

00:01:50,729 --> 00:01:55,159
arithmetic it's about doing tens of

00:01:53,040 --> 00:02:00,450
millions or hundreds of millions of

00:01:55,159 --> 00:02:02,310
arithmetic operations a second you can

00:02:00,450 --> 00:02:05,610
actually do it with very very little

00:02:02,310 --> 00:02:08,610
power usage for example even on existing

00:02:05,610 --> 00:02:13,260
hardware it might take five Pico joules

00:02:08,610 --> 00:02:17,760
in order to do one arithmetic operation

00:02:13,260 --> 00:02:22,560
and doing a mobile net v2 image

00:02:17,760 --> 00:02:27,150
recognition model could take around 22

00:02:22,560 --> 00:02:28,739
million operations so that means we can

00:02:27,150 --> 00:02:34,470
make a rough estimate of the power

00:02:28,739 --> 00:02:37,890
required to be about 110 micro joules so

00:02:34,470 --> 00:02:41,489
if you run that mobile net image

00:02:37,890 --> 00:02:44,880
recognition model once a second one

00:02:41,489 --> 00:02:47,819
frame per second that's running at 110

00:02:44,880 --> 00:02:50,130
micro watts which you could run on a

00:02:47,819 --> 00:02:52,860
coin battery even on existing hardware

00:02:50,130 --> 00:02:55,590
for almost a year so this is not

00:02:52,860 --> 00:02:57,480
something that's waiting on new hardware

00:02:55,590 --> 00:02:59,940
coming along this is something that we

00:02:57,480 --> 00:03:02,450
can do on existing hardware that we have

00:02:59,940 --> 00:03:02,450
right now

00:03:08,720 --> 00:03:10,780

YouTube URL: https://www.youtube.com/watch?v=0fLvCezGMko


