Title: Unconventional programming paradigms for the future, now - Carin Meier (Cognitect)
Publication date: 2017-10-03
Playlist: O'Reilly Velocity Conference 2017 - New York, New York
Description: 
	As technology advances, our systems are growing more and more complex, reaching the threshold of what we can handle and even comprehend. We need more than tools to keep it under control. We need new ways of thinking. Carin Meier explores new ways to approach systems and tame complexity for the rapidly changing future.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,460 --> 00:00:05,500
the third unconventional programming

00:00:03,550 --> 00:00:07,690
paradigm his visit visited by this

00:00:05,500 --> 00:00:09,629
machine learning and we're actually

00:00:07,690 --> 00:00:12,129
becoming quite common with us right now

00:00:09,629 --> 00:00:14,679
but in traditional programming as we all

00:00:12,129 --> 00:00:18,609
know you have an input and you have an

00:00:14,679 --> 00:00:21,910
output and you have a function and the

00:00:18,609 --> 00:00:24,789
function is a bit that we code up but

00:00:21,910 --> 00:00:26,529
machine learning changes us right we're

00:00:24,789 --> 00:00:27,999
letting the computer figure out this a

00:00:26,529 --> 00:00:34,000
little bit from it we're turning over

00:00:27,999 --> 00:00:36,280
control to the machine and it's a good

00:00:34,000 --> 00:00:39,850
thing because with neural networks

00:00:36,280 --> 00:00:43,150
there's a sort of universality that it

00:00:39,850 --> 00:00:45,310
can approximate any function guaranteed

00:00:43,150 --> 00:00:49,120
like the proof of universality for NAND

00:00:45,310 --> 00:00:52,200
gates and in fact I really like this

00:00:49,120 --> 00:00:55,360
tweet so gradient descent which is

00:00:52,200 --> 00:00:57,430
optimizations for a neuro network it can

00:00:55,360 --> 00:00:58,840
write better code than you I I'm sorry

00:00:57,430 --> 00:01:00,160
and I think we're just going to have to

00:00:58,840 --> 00:01:03,190
deal more and more with us as

00:01:00,160 --> 00:01:04,960
programmers as we go along so the thing

00:01:03,190 --> 00:01:07,360
about neural networks now is with deep

00:01:04,960 --> 00:01:09,100
learning you can make stacks of them and

00:01:07,360 --> 00:01:11,430
this is actually an architecture for

00:01:09,100 --> 00:01:14,320
something called the vgg 16 architecture

00:01:11,430 --> 00:01:17,110
different layers now with GPUs we can

00:01:14,320 --> 00:01:21,370
glue these all together and they can do

00:01:17,110 --> 00:01:23,200
some pretty amazing things they can do

00:01:21,370 --> 00:01:25,000
things like recognize images you can

00:01:23,200 --> 00:01:27,520
tell the difference between cats and

00:01:25,000 --> 00:01:29,320
dogs with them or maybe you can do

00:01:27,520 --> 00:01:33,060
something a little bit more interesting

00:01:29,320 --> 00:01:36,159
like that like I don't know drive cars

00:01:33,060 --> 00:01:39,370
but the thing people don't talk about a

00:01:36,159 --> 00:01:42,550
lot is they can also create and I find

00:01:39,370 --> 00:01:44,950
this really fascinating there's this

00:01:42,550 --> 00:01:48,520
wonderful site that I encourage you all

00:01:44,950 --> 00:01:53,020
to go to it's called pics to pix and you

00:01:48,520 --> 00:01:56,260
can draw an outline of a cat and you can

00:01:53,020 --> 00:01:59,409
press this process button and using

00:01:56,260 --> 00:02:00,580
these things called gams they have

00:01:59,409 --> 00:02:04,090
neural networks that will actually

00:02:00,580 --> 00:02:07,330
generate and fill in a cat for you in

00:02:04,090 --> 00:02:10,119
the edges that you draw it's a wonderful

00:02:07,330 --> 00:02:13,359
and powerful technique but with any

00:02:10,119 --> 00:02:14,380
powerful technique it can be abused as I

00:02:13,359 --> 00:02:20,660
have done here

00:02:14,380 --> 00:02:27,370
so here is my cat and I'm not sure what

00:02:20,660 --> 00:02:30,110
that is but it's a little scary beware

00:02:27,370 --> 00:02:32,780
but getting these architectures together

00:02:30,110 --> 00:02:35,630
of these deep learning art architectures

00:02:32,780 --> 00:02:39,200
of these layers convolutional and max

00:02:35,630 --> 00:02:42,560
pooling and Ray Lu and all these things

00:02:39,200 --> 00:02:45,940
it takes a lot of skill it takes a lot

00:02:42,560 --> 00:02:50,750
of skill a lot of time and a lot of

00:02:45,940 --> 00:02:52,760
experimentation so you know it in true

00:02:50,750 --> 00:02:55,190
fashion you know why don't we turn this

00:02:52,760 --> 00:02:57,710
over to the computer to do and this is

00:02:55,190 --> 00:03:00,740
exactly what this github project is

00:02:57,710 --> 00:03:02,660
doing this is called deep neural network

00:03:00,740 --> 00:03:06,110
evolution and it takes these

00:03:02,660 --> 00:03:09,410
architectures for deep learning and it

00:03:06,110 --> 00:03:11,390
comes up with the best one by Machine so

00:03:09,410 --> 00:03:13,700
this particular one uses genetic

00:03:11,390 --> 00:03:16,390
programming and the technique it will

00:03:13,700 --> 00:03:19,340
use is it'll say okay let's take a

00:03:16,390 --> 00:03:23,360
thousand or five fouls and are a hundred

00:03:19,340 --> 00:03:26,330
thousand population possible network

00:03:23,360 --> 00:03:28,910
configurations and let them breed and

00:03:26,330 --> 00:03:31,850
let them mutate and let them evolve and

00:03:28,910 --> 00:03:34,430
see which one would actually yield the

00:03:31,850 --> 00:03:37,010
best result and it's no surprise that

00:03:34,430 --> 00:03:39,140
some of the results have been better

00:03:37,010 --> 00:03:41,690
than humans have come up with or even

00:03:39,140 --> 00:03:44,540
imagined have come up with and this is

00:03:41,690 --> 00:03:49,190
something that I see us relying more and

00:03:44,540 --> 00:03:54,340
more on as the time to progress programs

00:03:49,190 --> 00:03:54,340
in effect designing themselves

00:04:00,480 --> 00:04:02,540

YouTube URL: https://www.youtube.com/watch?v=RZKgcRqm9Yw


