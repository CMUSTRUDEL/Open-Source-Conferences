Title: Ray: A Distributed Execution Framework for Emerging AI Applications Michael Jordan (UC Berkeley)
Publication date: 2017-03-17
Playlist: Strata + Hadoop World 2017 - San Jose, California
Description: 
	chael I. Jordan is the Pehong Chen Distinguished Professor in the Department of Electrical Engineering and Computer Science and the Department of Statistics at the University of California, Berkeley. His research interests bridge the computational, statistical, cognitive, and biological sciences; in recent years, he has focused on Bayesian nonparametric analysis, probabilistic graphical models, spectral methods, kernel machines, and applications to problems in distributed computing systems, natural language processing, signal processing, and statistical genetics. Previously, he was a professor at MIT. Michael is a member of the National Academy of Sciences, the National Academy of Engineering, and the American Academy of Arts and Sciences and a fellow of the American Association for the Advancement of Science, the AAAI, ACM, ASA, CSS, IEEE, IMS, ISBA, and SIAM. He has been named a Neyman Lecturer and a Medallion Lecturer by the Institute of Mathematical Statistics. He received the David E. Rumelhart Prize in 2015 and the ACM/AAAI Allen Newell Award in 2009. Michael holds a masterâ€™s degree in mathematics from Arizona State University and a PhD in cognitive science from the University of California, San Diego.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:02,540 --> 00:00:06,710
so this next project is done by machine

00:00:05,090 --> 00:00:09,650
learning students but but wearing a

00:00:06,710 --> 00:00:14,449
systems had in developing a an attempt

00:00:09,650 --> 00:00:16,400
to replace spark okay so we do have a

00:00:14,449 --> 00:00:19,160
new lab that encompasses this project

00:00:16,400 --> 00:00:21,439
and many other projects it's called rise

00:00:19,160 --> 00:00:24,589
lab and I forget the acronym exactly but

00:00:21,439 --> 00:00:26,810
real-time is in there and and and maybe

00:00:24,589 --> 00:00:29,390
that's I forget for good is e stands for

00:00:26,810 --> 00:00:30,800
because someone can help me anyway it's

00:00:29,390 --> 00:00:34,160
so new I don't even know what it stands

00:00:30,800 --> 00:00:37,730
for but it's about real-time

00:00:34,160 --> 00:00:39,590
environments and about live data not

00:00:37,730 --> 00:00:40,879
batch data so really everything to date

00:00:39,590 --> 00:00:42,379
when you start to look at the system

00:00:40,879 --> 00:00:44,719
side of machine learning has been very

00:00:42,379 --> 00:00:46,699
much focused on on batch data in one way

00:00:44,719 --> 00:00:49,430
or another and analytics that take

00:00:46,699 --> 00:00:51,230
indefinite amounts of time there are

00:00:49,430 --> 00:00:53,149
lots and lots of applications including

00:00:51,230 --> 00:00:55,489
all the AI ones but many others where

00:00:53,149 --> 00:00:57,530
there is a time budget of some kind

00:00:55,489 --> 00:00:59,090
including medical applications where

00:00:57,530 --> 00:01:01,429
someone might live or die is unless you

00:00:59,090 --> 00:01:03,199
act quickly as you just heard about and

00:01:01,429 --> 00:01:05,380
certainly the kind of self-driving cars

00:01:03,199 --> 00:01:08,840
and human-in-the-loop situations are

00:01:05,380 --> 00:01:10,220
involved at time budgets so let's look

00:01:08,840 --> 00:01:11,270
at these tasks and try to break them

00:01:10,220 --> 00:01:12,920
apart and think about what are their

00:01:11,270 --> 00:01:14,840
ingredients and thinks about systems

00:01:12,920 --> 00:01:17,090
support that will allow you to make

00:01:14,840 --> 00:01:19,900
real-time actions and decision-making in

00:01:17,090 --> 00:01:22,760
a loop with still the big data context

00:01:19,900 --> 00:01:24,170
so you need flexibility you need to be

00:01:22,760 --> 00:01:26,000
able to put together or not not just

00:01:24,170 --> 00:01:28,370
things like neural nets but planning and

00:01:26,000 --> 00:01:30,040
search and simulation if you looked at

00:01:28,370 --> 00:01:31,910
the next wave of activity after

00:01:30,040 --> 00:01:34,070
applications to computer vision and

00:01:31,910 --> 00:01:35,390
speech and even in speech there was

00:01:34,070 --> 00:01:37,400
things around the neural nets there's

00:01:35,390 --> 00:01:40,940
all kinds of other pieces to these big

00:01:37,400 --> 00:01:42,650
machine learning systems this creates

00:01:40,940 --> 00:01:44,480
all kinds of complex task dependencies

00:01:42,650 --> 00:01:46,640
it's not very easy simply to write a

00:01:44,480 --> 00:01:48,410
MapReduce kind of paradigm you can write

00:01:46,640 --> 00:01:49,940
it but it's not gonna execute very very

00:01:48,410 --> 00:01:52,460
effectively when you have very

00:01:49,940 --> 00:01:54,140
heterogeneous workloads and tasks it

00:01:52,460 --> 00:01:55,310
needs to be adapted to the performance

00:01:54,140 --> 00:01:56,990
of the algorithm as the system is

00:01:55,310 --> 00:02:00,110
learning it's gonna change its flow its

00:01:56,990 --> 00:02:02,900
tasks and then in on the performance

00:02:00,110 --> 00:02:04,550
side we have really the real-time and

00:02:02,900 --> 00:02:06,200
feedback kind of integration that I was

00:02:04,550 --> 00:02:08,509
talking about is which is critical in

00:02:06,200 --> 00:02:10,280
many real-world applications so there

00:02:08,509 --> 00:02:11,840
are systems that target various pieces

00:02:10,280 --> 00:02:13,760
of this what we're trying to do is build

00:02:11,840 --> 00:02:14,790
a system that targets sort of all these

00:02:13,760 --> 00:02:17,800
things

00:02:14,790 --> 00:02:20,110
so very rough cartoon just to start you

00:02:17,800 --> 00:02:22,360
out on the Left we have Hadoop which is

00:02:20,110 --> 00:02:25,390
no longer the name of the conference but

00:02:22,360 --> 00:02:27,340
spark could have been but these are very

00:02:25,390 --> 00:02:28,990
much block synchronous paradigms so

00:02:27,340 --> 00:02:30,160
there was a map step and then there was

00:02:28,990 --> 00:02:32,380
a wait step where everything

00:02:30,160 --> 00:02:33,730
synchronized and that was effective for

00:02:32,380 --> 00:02:35,140
a certain kind of task where you as the

00:02:33,730 --> 00:02:37,150
designer could design it such that each

00:02:35,140 --> 00:02:38,770
task took about the same amount of time

00:02:37,150 --> 00:02:40,660
and needed about the same amount of

00:02:38,770 --> 00:02:42,400
resources that's just not true for many

00:02:40,660 --> 00:02:44,410
many emerging machine learning and AI

00:02:42,400 --> 00:02:47,080
paradigms you need something much more

00:02:44,410 --> 00:02:49,060
like a just-in-time data flow type

00:02:47,080 --> 00:02:51,640
architecture what more task goes when

00:02:49,060 --> 00:02:54,340
all the tasks it depends on are already

00:02:51,640 --> 00:02:56,170
they are finished so building a system

00:02:54,340 --> 00:02:58,810
that supports that and retains all the

00:02:56,170 --> 00:03:01,180
desirable features of Hadoop and spark

00:02:58,810 --> 00:03:03,480
is the goal of our is of our project

00:03:01,180 --> 00:03:03,480
called ray

00:03:09,810 --> 00:03:11,870

YouTube URL: https://www.youtube.com/watch?v=i-l6sv_vQRc


