Title: What's the difference between BI and machine learning with Rob Craft (Google)
Publication date: 2017-03-17
Playlist: Strata + Hadoop World 2017 - San Jose, California
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:00,060 --> 00:00:05,430
hi this is Mike Hendrickson from strata

00:00:02,010 --> 00:00:07,290
San Jose I'm here with Rob craft Rob how

00:00:05,430 --> 00:00:09,389
you doing I'm well okay so you're with

00:00:07,290 --> 00:00:11,099
Google and you're with which group the

00:00:09,389 --> 00:00:13,950
cloud group yeah I mean Google cloud

00:00:11,099 --> 00:00:15,630
platform so one thing I'd like to

00:00:13,950 --> 00:00:17,670
understand a little bit more is that you

00:00:15,630 --> 00:00:20,449
know we're here in a data event and a

00:00:17,670 --> 00:00:23,460
lot of people are still talking about bi

00:00:20,449 --> 00:00:25,500
but this seems to be the darling of the

00:00:23,460 --> 00:00:27,660
last couple years is AI and machine

00:00:25,500 --> 00:00:29,429
learning can you tease out the

00:00:27,660 --> 00:00:33,660
difference between machine learning and

00:00:29,429 --> 00:00:35,880
bi yeah a lot of people think of how do

00:00:33,660 --> 00:00:38,010
i how do i do something different than

00:00:35,880 --> 00:00:40,620
what I've already done is if I could

00:00:38,010 --> 00:00:42,989
understand my data better and business

00:00:40,620 --> 00:00:45,539
intelligence market the last 20 25 30

00:00:42,989 --> 00:00:47,700
years in some cases have been driven for

00:00:45,539 --> 00:00:49,320
taking a large set of data queried at

00:00:47,700 --> 00:00:51,329
large scale provides some sort of

00:00:49,320 --> 00:00:54,539
visualization against it so humans can

00:00:51,329 --> 00:00:55,110
go oh I get why that trend happened past

00:00:54,539 --> 00:00:56,879
tense

00:00:55,110 --> 00:00:58,410
therefore the next time we have this

00:00:56,879 --> 00:01:00,510
problem we should probably have learned

00:00:58,410 --> 00:01:01,530
from that or we can improve business or

00:01:00,510 --> 00:01:03,989
now we understand what the business

00:01:01,530 --> 00:01:05,250
currently is and billions of dollars go

00:01:03,989 --> 00:01:06,750
into that market a whole lot of

00:01:05,250 --> 00:01:09,150
technology that's quite difficult to do

00:01:06,750 --> 00:01:11,580
whole lot of licenses out there now for

00:01:09,150 --> 00:01:13,560
machine learning the idea is how can I

00:01:11,580 --> 00:01:14,970
keep my job versus why I should have

00:01:13,560 --> 00:01:16,530
been fired so why I should have been

00:01:14,970 --> 00:01:18,900
fired is largely the on the chart for

00:01:16,530 --> 00:01:21,150
the VI if you miss Christmas if you

00:01:18,900 --> 00:01:22,740
couldn't get your product from the port

00:01:21,150 --> 00:01:24,840
in Shanghai because weather came in and

00:01:22,740 --> 00:01:26,729
you didn't put a option on airlift

00:01:24,840 --> 00:01:28,110
because that was expensive and you

00:01:26,729 --> 00:01:30,420
didn't have a model that would tell you

00:01:28,110 --> 00:01:32,790
here's the implications if we miss a

00:01:30,420 --> 00:01:34,259
six-hour window at a port dock fee for

00:01:32,790 --> 00:01:35,909
example so what machine learning is

00:01:34,259 --> 00:01:37,979
tries to do is to say from these data

00:01:35,909 --> 00:01:40,950
how do I put a statistical model

00:01:37,979 --> 00:01:44,790
together that can predict with very high

00:01:40,950 --> 00:01:46,140
confidence and shown confidence a

00:01:44,790 --> 00:01:48,030
particular outcome that matters from our

00:01:46,140 --> 00:01:50,310
business and you'll find people doing

00:01:48,030 --> 00:01:51,960
this a lot around human and system

00:01:50,310 --> 00:01:55,619
interaction things like vision systems

00:01:51,960 --> 00:01:56,880
speech translation services we get the

00:01:55,619 --> 00:01:59,040
value of those pretty immediately those

00:01:56,880 --> 00:02:00,600
are those are immediately krokov all how

00:01:59,040 --> 00:02:02,219
do I get that from a business process

00:02:00,600 --> 00:02:03,810
that's the opportunity in front a lot of

00:02:02,219 --> 00:02:06,540
a lot of the enterprise's how do I

00:02:03,810 --> 00:02:08,819
understand cash flow and when I should

00:02:06,540 --> 00:02:10,080
ship a product or hold a product or how

00:02:08,819 --> 00:02:11,819
do I understand when a customers too

00:02:10,080 --> 00:02:13,650
expensive have or lower my cost per

00:02:11,819 --> 00:02:14,849
customer all those things you have

00:02:13,650 --> 00:02:16,980
today they're just locked behind

00:02:14,849 --> 00:02:18,989
multiple databases so we have data on

00:02:16,980 --> 00:02:20,010
those city but we also have massive

00:02:18,989 --> 00:02:23,819
amounts of data

00:02:20,010 --> 00:02:26,760
how does someone manage to to look at a

00:02:23,819 --> 00:02:29,220
problem and apply some machine learning

00:02:26,760 --> 00:02:33,030
to just a massively huge problem and

00:02:29,220 --> 00:02:35,310
still have some sort of real-time result

00:02:33,030 --> 00:02:37,440
because you don't want again that that

00:02:35,310 --> 00:02:39,840
answer to be next week or even tomorrow

00:02:37,440 --> 00:02:42,180
in some cases yep so one of the things

00:02:39,840 --> 00:02:44,459
we've been working on at Google for 14

00:02:42,180 --> 00:02:47,099
years at this point is trying to go from

00:02:44,459 --> 00:02:48,599
rule-based systems to intent fulfillment

00:02:47,099 --> 00:02:51,420
in other words what are the things that

00:02:48,599 --> 00:02:54,660
the system can satisfy and if you can

00:02:51,420 --> 00:02:55,829
create models or statistical models in

00:02:54,660 --> 00:02:58,079
this case machine learning driven

00:02:55,829 --> 00:03:00,480
systems that satisfy those intent at

00:02:58,079 --> 00:03:01,829
large scale the massive data largely

00:03:00,480 --> 00:03:03,359
doesn't matter because all the

00:03:01,829 --> 00:03:05,060
techniques under the covers that so many

00:03:03,359 --> 00:03:07,920
of us already know like MapReduce

00:03:05,060 --> 00:03:09,390
large-scale querying systems we have

00:03:07,920 --> 00:03:10,890
products like spanner at Google which

00:03:09,390 --> 00:03:13,109
are universally consistent and

00:03:10,890 --> 00:03:14,640
immediately available and transact Abul

00:03:13,109 --> 00:03:16,799
with acid support the things which were

00:03:14,640 --> 00:03:18,359
seen as non science of all those things

00:03:16,799 --> 00:03:20,639
are science full today so can I take

00:03:18,359 --> 00:03:22,620
petabytes and X bytes data yes but can i

00:03:20,639 --> 00:03:24,720
down scale up to gigabytes of data

00:03:22,620 --> 00:03:26,760
that's the critical factor for a lot of

00:03:24,720 --> 00:03:28,380
us because when you go through and do

00:03:26,760 --> 00:03:29,609
data science and you're seeing data set

00:03:28,380 --> 00:03:31,379
you'll find that a lot of the data is

00:03:29,609 --> 00:03:33,750
dirty or it's conflicting or there's

00:03:31,379 --> 00:03:35,669
errors in the data and labeling against

00:03:33,750 --> 00:03:37,859
that is a whole science in and of itself

00:03:35,669 --> 00:03:39,900
then you train your model and that's

00:03:37,859 --> 00:03:41,340
where the mathematicians step in from

00:03:39,900 --> 00:03:42,870
where the computer scientists are today

00:03:41,340 --> 00:03:44,790
tooling is going to improve their

00:03:42,870 --> 00:03:46,650
massively in the next couple of years I

00:03:44,790 --> 00:03:48,690
promise you it's been moribund for 20

00:03:46,650 --> 00:03:50,669
years a lot of investments come into

00:03:48,690 --> 00:03:53,340
this space and lastly to your point was

00:03:50,669 --> 00:03:54,930
predictions we want to offer inferable

00:03:53,340 --> 00:03:57,060
predictions means statistically

00:03:54,930 --> 00:03:58,919
significant predictions which you can

00:03:57,060 --> 00:04:00,900
debug which is very difficult with

00:03:58,919 --> 00:04:02,879
neural networks within tens of

00:04:00,900 --> 00:04:05,340
milliseconds and that goes to millions

00:04:02,879 --> 00:04:09,720
of times a second or 100 million times a

00:04:05,340 --> 00:04:12,299
second so that sounds great and Google

00:04:09,720 --> 00:04:13,590
has been serious it was and Google has

00:04:12,299 --> 00:04:15,389
been doing this for a long time right

00:04:13,590 --> 00:04:17,720
how does a large enterprise that may be

00:04:15,389 --> 00:04:22,190
a retail company it started doing this

00:04:17,720 --> 00:04:24,719
so step one largely is get big data done

00:04:22,190 --> 00:04:26,760
big data has been floating around as a

00:04:24,719 --> 00:04:27,000
buzz word almost the worst name thing in

00:04:26,760 --> 00:04:28,740
the

00:04:27,000 --> 00:04:30,900
IOT might be worth what you call big

00:04:28,740 --> 00:04:33,420
data I mean your Google well that's it

00:04:30,900 --> 00:04:35,340
is it's big to you is big enough and

00:04:33,420 --> 00:04:37,740
there's two aspects for big that I think

00:04:35,340 --> 00:04:41,220
are notable because it implies system

00:04:37,740 --> 00:04:43,890
choices one is size of data in air or on

00:04:41,220 --> 00:04:45,270
disk so is it just a lot of things that

00:04:43,890 --> 00:04:47,250
have a lot of spending media against it

00:04:45,270 --> 00:04:49,680
so that's the traditional definition the

00:04:47,250 --> 00:04:52,530
other one is the shape and velocity of

00:04:49,680 --> 00:04:54,090
the data arrival ninety percent of new

00:04:52,530 --> 00:04:56,910
data entering an enterprise storage

00:04:54,090 --> 00:04:59,010
system day is non structured its video

00:04:56,910 --> 00:05:01,470
its tweet feeds its pictures its

00:04:59,010 --> 00:05:02,820
commentary its word Docs that haven't

00:05:01,470 --> 00:05:04,410
been discovered it might be out of date

00:05:02,820 --> 00:05:06,570
with incorrect data of the variety of

00:05:04,410 --> 00:05:08,850
the variety inside of this so you can't

00:05:06,570 --> 00:05:10,169
have a single system saying I understand

00:05:08,850 --> 00:05:12,330
the data but you can certainly have a

00:05:10,169 --> 00:05:14,040
single system that stores the data and

00:05:12,330 --> 00:05:15,990
we've seen over and almost people say

00:05:14,040 --> 00:05:18,680
when in doubt save it and now the

00:05:15,990 --> 00:05:21,090
savings been done now how do i monetize

00:05:18,680 --> 00:05:22,650
save money make money delight my

00:05:21,090 --> 00:05:25,230
customers and that's where machine

00:05:22,650 --> 00:05:27,030
learning steps in with very again simple

00:05:25,230 --> 00:05:29,850
straightforward but massively scalable

00:05:27,030 --> 00:05:31,830
statistical statistical techniques that

00:05:29,850 --> 00:05:33,270
help you gain those insights so right

00:05:31,830 --> 00:05:34,740
now the tooling is very very primitive

00:05:33,270 --> 00:05:36,720
and has been for there super long time

00:05:34,740 --> 00:05:37,440
things like tensorflow which are

00:05:36,720 --> 00:05:39,180
open-source

00:05:37,440 --> 00:05:41,010
allow you to create models yourself

00:05:39,180 --> 00:05:43,500
created on something a Google cloud

00:05:41,010 --> 00:05:45,240
platform or you can deploy those models

00:05:43,500 --> 00:05:47,550
to an actual device like an IOT device

00:05:45,240 --> 00:05:50,250
or your phone so what's big data to you

00:05:47,550 --> 00:05:52,830
could be a few thousand line items out

00:05:50,250 --> 00:05:54,660
of a million line items you have that

00:05:52,830 --> 00:05:56,100
through a visualization system you

00:05:54,660 --> 00:05:58,140
discover these are the things that

00:05:56,100 --> 00:05:59,669
actually matter to my model and the

00:05:58,140 --> 00:06:01,890
system will say my learning rate on

00:05:59,669 --> 00:06:03,240
those pieces of data is very high so

00:06:01,890 --> 00:06:05,430
high and great data scientists who know

00:06:03,240 --> 00:06:07,260
how to use very good tooling 10 suppose

00:06:05,430 --> 00:06:09,510
one another one that we particularly

00:06:07,260 --> 00:06:11,070
make is ml engine we just made it GA

00:06:09,510 --> 00:06:13,110
last week very exciting at our own

00:06:11,070 --> 00:06:15,540
conference we're happy to showcase it

00:06:13,110 --> 00:06:17,580
here and then the full out ml models

00:06:15,540 --> 00:06:19,140
that we run for you like speech natural

00:06:17,580 --> 00:06:21,330
language vision so I mentioned earlier

00:06:19,140 --> 00:06:22,680
some things are unstructured data those

00:06:21,330 --> 00:06:24,510
things are largely homogeneous on how

00:06:22,680 --> 00:06:26,850
you solve them so why not just I'll just

00:06:24,510 --> 00:06:28,350
use those things for 50 cents per 10,000

00:06:26,850 --> 00:06:30,030
calls for it I don't want to invest in

00:06:28,350 --> 00:06:32,550
machine science for there but my own

00:06:30,030 --> 00:06:34,770
earpiece system or how do I do my own

00:06:32,550 --> 00:06:38,330
database mining I want to own that so

00:06:34,770 --> 00:06:39,770
that's why we make tools for both and so

00:06:38,330 --> 00:06:41,900
Google has probably done this well for

00:06:39,770 --> 00:06:45,530
years and we all know that's been the

00:06:41,900 --> 00:06:46,969
case but you guys have evolved and you

00:06:45,530 --> 00:06:49,849
kind of evolved the cloud

00:06:46,969 --> 00:06:52,939
you kind of work cloud 1.0 and you were

00:06:49,849 --> 00:06:55,280
digital natives to begin with how do you

00:06:52,939 --> 00:06:57,319
see that progressing are we at a new era

00:06:55,280 --> 00:07:00,500
of the cloud right now and are we at a

00:06:57,319 --> 00:07:02,330
new inflection point to where all this

00:07:00,500 --> 00:07:04,159
machine learning all this massive

00:07:02,330 --> 00:07:06,979
amounts of data storage retrieval

00:07:04,159 --> 00:07:10,460
real-time streaming all those things are

00:07:06,979 --> 00:07:14,629
converging are we at a new era and if we

00:07:10,460 --> 00:07:16,849
are where is that going that is a great

00:07:14,629 --> 00:07:18,469
question that's paying for a lot of

00:07:16,849 --> 00:07:20,240
people's houses or making a lot of

00:07:18,469 --> 00:07:21,800
people said depending on the outcome I'm

00:07:20,240 --> 00:07:24,229
in the cloud business so I'm a very

00:07:21,800 --> 00:07:26,360
loaded and biased surveyor of the

00:07:24,229 --> 00:07:28,009
marketplace I will say that most people

00:07:26,360 --> 00:07:31,759
agree where maybe 5% on the journey

00:07:28,009 --> 00:07:34,009
measured by customers doing things in it

00:07:31,759 --> 00:07:35,389
which is my view the best corollary

00:07:34,009 --> 00:07:38,150
where people take their dollars where

00:07:35,389 --> 00:07:40,069
people see their value so 5% adoption to

00:07:38,150 --> 00:07:42,169
date typically on the people that adopt

00:07:40,069 --> 00:07:44,900
quickly or the things that cloud can do

00:07:42,169 --> 00:07:47,360
like arbitrarily scalable systems large

00:07:44,900 --> 00:07:48,740
sets of infrastructure arbitrage of

00:07:47,360 --> 00:07:50,180
multiple data sets from multiple

00:07:48,740 --> 00:07:52,550
different suppliers all those things

00:07:50,180 --> 00:07:55,279
cloud is immediately obvious for today

00:07:52,550 --> 00:07:57,110
and largely the security concerns which

00:07:55,279 --> 00:07:59,870
 early growth are being

00:07:57,110 --> 00:08:01,330
addressed in reasonable ways by a lot of

00:07:59,870 --> 00:08:03,740
people even down to core banking

00:08:01,330 --> 00:08:05,270
pharmaceutical oil and gas discovery all

00:08:03,740 --> 00:08:07,339
those customers are in Google Cloud

00:08:05,270 --> 00:08:08,389
today the next step though is getting

00:08:07,339 --> 00:08:10,279
the people that are in the middle of the

00:08:08,389 --> 00:08:12,319
curve we all understand how hard it is

00:08:10,279 --> 00:08:15,560
to convince somebody who has such

00:08:12,319 --> 00:08:17,690
limited budget making a move on existing

00:08:15,560 --> 00:08:19,940
systems which in some way work in some

00:08:17,690 --> 00:08:22,069
ways maybe need some improvements to a

00:08:19,940 --> 00:08:23,569
brand new platform in our case there's

00:08:22,069 --> 00:08:24,919
those two categories everyone's heard

00:08:23,569 --> 00:08:27,229
infrastructure your service and platform

00:08:24,919 --> 00:08:28,879
as a service Google cloud spends a lot

00:08:27,229 --> 00:08:31,550
of time writing fully managed services

00:08:28,879 --> 00:08:33,260
so the idea is sometimes it's not how do

00:08:31,550 --> 00:08:35,779
I do this better it's why are you still

00:08:33,260 --> 00:08:38,360
doing it a great example is do it if I

00:08:35,779 --> 00:08:41,149
had perfectly scalable storage that was

00:08:38,360 --> 00:08:44,180
15 9s available why would I do backups

00:08:41,149 --> 00:08:45,890
if I could do tag lines inside of the

00:08:44,180 --> 00:08:47,560
dataset to indicate this is a Monday

00:08:45,890 --> 00:08:49,490
this is a Tuesday this is up three

00:08:47,560 --> 00:08:52,010
Thursday and you can roll it all back

00:08:49,490 --> 00:08:52,820
back ups as a concept become less than

00:08:52,010 --> 00:08:54,470
important for you as a business

00:08:52,820 --> 00:08:56,300
depending on the day load in the shape

00:08:54,470 --> 00:08:57,650
of the data same thing for things like

00:08:56,300 --> 00:09:01,790
machine learning models and other things

00:08:57,650 --> 00:09:04,220
which people are recognized that data

00:09:01,790 --> 00:09:05,810
mass matters so why do machine learning

00:09:04,220 --> 00:09:07,760
come from all these cloud companies

00:09:05,810 --> 00:09:10,040
first it's super large-scale it's

00:09:07,760 --> 00:09:12,380
because the data is localized compute is

00:09:10,040 --> 00:09:14,030
abundantly available in large

00:09:12,380 --> 00:09:16,720
general-purpose cloud platforms like our

00:09:14,030 --> 00:09:18,560
own and then all you need is science and

00:09:16,720 --> 00:09:20,360
smarts that are written into the

00:09:18,560 --> 00:09:21,680
software and Google has both of those so

00:09:20,360 --> 00:09:23,810
that's probably why we're an early

00:09:21,680 --> 00:09:26,120
leader in the space a long way to go to

00:09:23,810 --> 00:09:28,310
normalize this into everyday assumption

00:09:26,120 --> 00:09:29,990
that it's going to be present and one of

00:09:28,310 --> 00:09:32,210
the signals I look for is how many

00:09:29,990 --> 00:09:33,860
startups right now say with machine

00:09:32,210 --> 00:09:35,240
learning in them which indicates that

00:09:33,860 --> 00:09:36,260
were early yet they want to highlight

00:09:35,240 --> 00:09:38,210
the fact that they think they have

00:09:36,260 --> 00:09:41,350
something better in many cases it's

00:09:38,210 --> 00:09:43,460
substantially better very short story

00:09:41,350 --> 00:09:44,900
translation a Google spend a machine

00:09:43,460 --> 00:09:47,360
learning service for a very long time

00:09:44,900 --> 00:09:48,650
we're pretty good at it we do 103

00:09:47,360 --> 00:09:50,570
languages it's one of the products I

00:09:48,650 --> 00:09:52,220
have some pretty proud of it one of the

00:09:50,570 --> 00:09:54,290
things that we did about four months ago

00:09:52,220 --> 00:09:55,580
is we added neural network supports on

00:09:54,290 --> 00:09:58,340
what traditionally was a heuristic based

00:09:55,580 --> 00:10:00,500
model system and that sounds like okay

00:09:58,340 --> 00:10:03,230
we're just upgrading the tech and the

00:10:00,500 --> 00:10:05,720
model should improve slightly we saw 85%

00:10:03,230 --> 00:10:08,420
fewer errors per call inside of our top

00:10:05,720 --> 00:10:09,950
eight language pairs that's a massive

00:10:08,420 --> 00:10:11,720
improvement than most we've seen in well

00:10:09,950 --> 00:10:13,820
over ten years we're better than human

00:10:11,720 --> 00:10:15,920
translation in some of the languages

00:10:13,820 --> 00:10:17,420
today so if we can do better than human

00:10:15,920 --> 00:10:19,310
the next step obviously is can we speak

00:10:17,420 --> 00:10:21,500
languages that we don't know and the

00:10:19,310 --> 00:10:23,450
answer is yes the models under the cover

00:10:21,500 --> 00:10:25,670
can translate languages that we do not

00:10:23,450 --> 00:10:28,340
have the source from so we're already at

00:10:25,670 --> 00:10:29,810
the rosetta moment for spoken word we've

00:10:28,340 --> 00:10:32,060
had natural language systems for years

00:10:29,810 --> 00:10:34,430
as well taking that ability to

00:10:32,060 --> 00:10:36,230
understand into an environment where

00:10:34,430 --> 00:10:37,280
humans and systems interact protic

00:10:36,230 --> 00:10:39,650
prettily flowingly

00:10:37,280 --> 00:10:42,020
is massively opportunistic so

00:10:39,650 --> 00:10:43,820
self-driving cars people inside of the

00:10:42,020 --> 00:10:45,770
box say where the car goes the car has

00:10:43,820 --> 00:10:47,450
to understand intent fulfil the intent

00:10:45,770 --> 00:10:48,290
and understand the world around it safer

00:10:47,450 --> 00:10:50,060
than a human can

00:10:48,290 --> 00:10:51,620
in many cases we're seeing earlier

00:10:50,060 --> 00:10:53,360
results that it's a lot safer being in a

00:10:51,620 --> 00:10:55,330
self-driving car that is driving myself

00:10:53,360 --> 00:10:58,280
to the convention center this morning

00:10:55,330 --> 00:11:00,470
that's excellent and that's kind of I

00:10:58,280 --> 00:11:02,600
don't want to say scary but interesting

00:11:00,470 --> 00:11:04,220
future coming up soon yeah so let's

00:11:02,600 --> 00:11:05,029
let's talk about the future real quickly

00:11:04,220 --> 00:11:07,519
here

00:11:05,029 --> 00:11:10,399
if you and I sat down 12 months from now

00:11:07,519 --> 00:11:12,439
mmm here next year at this time what

00:11:10,399 --> 00:11:16,060
would you like to say machine learning

00:11:12,439 --> 00:11:18,920
has solved in the world for for humanity

00:11:16,060 --> 00:11:20,689
for Humanity what what can we what can

00:11:18,920 --> 00:11:22,209
we do in that short period of time let

00:11:20,689 --> 00:11:25,519
me make it make it something that is

00:11:22,209 --> 00:11:27,790
very exciting for those of us that are

00:11:25,519 --> 00:11:31,399
already pretty deep in the space

00:11:27,790 --> 00:11:33,439
cat-scans healthcare right you go in you

00:11:31,399 --> 00:11:34,970
get a scan you come out looks clean you

00:11:33,439 --> 00:11:36,949
go on you wait for your next checkup or

00:11:34,970 --> 00:11:38,720
that lump is nothing to worry about

00:11:36,949 --> 00:11:43,120
in many cases though some of us have had

00:11:38,720 --> 00:11:46,129
that scare it is morally objectionable

00:11:43,120 --> 00:11:48,829
if there were a system capable of

00:11:46,129 --> 00:11:51,889
detecting early stage problems before it

00:11:48,829 --> 00:11:54,170
was humanly understandable based on 20

00:11:51,889 --> 00:11:56,720
years of past images of your own health

00:11:54,170 --> 00:11:58,759
system why couldn't a machine learning

00:11:56,720 --> 00:12:00,439
model which might improve massively just

00:11:58,759 --> 00:12:04,250
like our translation system every year

00:12:00,439 --> 00:12:06,649
you should retest all recent records

00:12:04,250 --> 00:12:09,470
with the right date yeah imagine the

00:12:06,649 --> 00:12:11,329
back catalog of early-stage RNA fragment

00:12:09,470 --> 00:12:12,889
detection cancer cells die like

00:12:11,329 --> 00:12:15,379
everything else does when those cells

00:12:12,889 --> 00:12:17,180
die they met RNA fragments the ability

00:12:15,379 --> 00:12:18,980
to pull a cancer cell RNA fragment from

00:12:17,180 --> 00:12:23,329
all your normal blood cell ones is

00:12:18,980 --> 00:12:24,860
almost impossible almost and turns out

00:12:23,329 --> 00:12:26,720
with enough compute and enough data

00:12:24,860 --> 00:12:28,069
processing capability people are

00:12:26,720 --> 00:12:30,230
attacking that problem today and

00:12:28,069 --> 00:12:32,870
machines can solve that machines or the

00:12:30,230 --> 00:12:35,449
techniques right early stage issues and

00:12:32,870 --> 00:12:37,759
healthcare outcomes today scaling it

00:12:35,449 --> 00:12:39,709
down is our heart problem can we turn

00:12:37,759 --> 00:12:41,540
into something available universally

00:12:39,709 --> 00:12:42,769
your versus only at the best hospitals

00:12:41,540 --> 00:12:44,540
in the world that's the challenge we're

00:12:42,769 --> 00:12:45,800
picking up excellent Rob thank you very

00:12:44,540 --> 00:12:48,009
much I won't go thank you thanks for

00:12:45,800 --> 00:12:48,009
having

00:12:53,610 --> 00:12:55,670

YouTube URL: https://www.youtube.com/watch?v=BJtn9qkrHU0


