Title: Launching Pokémon GO Phil Keslin (Niantic, Inc.), Beau Cronin (Embedding.js)
Publication date: 2017-03-15
Playlist: Strata + Hadoop World 2017 - San Jose, California
Description: 
	Pokémon GO was one of the fastest-growing games of all time, becoming a worldwide phenomenon in a matter of days. In conversation with Beau Cronin, Phil Keslin, CTO of Niantic, explains how the engineering team prepared for—and just barely survived—the experience.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Google: http://plus.google.com/+oreillymedia
Captions: 
	00:00:01,450 --> 00:00:06,850
so let's let's go to those first few

00:00:03,940 --> 00:00:08,650
days and weeks and first of all just you

00:00:06,850 --> 00:00:10,420
know take us there you know I mean I

00:00:08,650 --> 00:00:11,679
know that you know in the movies there

00:00:10,420 --> 00:00:13,509
would be a war room and you know big

00:00:11,679 --> 00:00:14,799
screens up on the wall I know that in

00:00:13,509 --> 00:00:16,930
reality was probably you know you guys

00:00:14,799 --> 00:00:19,960
sitting around your workstations and you

00:00:16,930 --> 00:00:21,970
know so niantic is a highly distributed

00:00:19,960 --> 00:00:24,280
engineering team we actually lived in

00:00:21,970 --> 00:00:25,990
three offices later in your pajamas it's

00:00:24,280 --> 00:00:28,600
like even less amor in early a living

00:00:25,990 --> 00:00:32,110
room sitting on the couch a futon in my

00:00:28,600 --> 00:00:33,580
house we have you know we have some

00:00:32,110 --> 00:00:35,620
people we had a couple people in

00:00:33,580 --> 00:00:36,910
bellevue we had one person in sunnyvale

00:00:35,620 --> 00:00:39,100
another person san francisco

00:00:36,910 --> 00:00:40,870
periodically we'd come together in a

00:00:39,100 --> 00:00:42,840
single office to do these things at

00:00:40,870 --> 00:00:46,270
launch that we were we were distributed

00:00:42,840 --> 00:00:48,640
and we pretty much use google hangouts

00:00:46,270 --> 00:00:50,860
for all of our communication ya know i

00:00:48,640 --> 00:00:52,450
sound sound familiar and said what were

00:00:50,860 --> 00:00:55,000
you seeing so you know you went live

00:00:52,450 --> 00:00:57,850
Australia New Zealand you know sort of

00:00:55,000 --> 00:01:00,250
things go vertical almost immediately so

00:00:57,850 --> 00:01:02,110
then you launched in the u.s. not long

00:01:00,250 --> 00:01:05,379
after correct yes about 12 hours later

00:01:02,110 --> 00:01:07,329
Oh out good right that's right ok ok and

00:01:05,379 --> 00:01:11,109
so what happened then the world kind of

00:01:07,329 --> 00:01:13,359
exploded yeah we had we had some pretty

00:01:11,109 --> 00:01:16,600
wild rides along the way we had we had

00:01:13,359 --> 00:01:19,240
some infrastructure problems we had to

00:01:16,600 --> 00:01:21,130
like I said we went in we use google

00:01:19,240 --> 00:01:23,619
cloud for all of our infrastructure and

00:01:21,130 --> 00:01:25,899
we went in with a provisioning profile

00:01:23,619 --> 00:01:27,549
that said we would be not exceed 5 X so

00:01:25,899 --> 00:01:29,259
they gave us enough datastore capacity

00:01:27,549 --> 00:01:31,450
and compute capacity in order to support

00:01:29,259 --> 00:01:34,779
that load and then when we blew through

00:01:31,450 --> 00:01:36,700
it and and hit our quota on many many

00:01:34,779 --> 00:01:37,749
occasions every time we get the quota it

00:01:36,700 --> 00:01:41,020
brought us down they had to bring in

00:01:37,749 --> 00:01:42,939
more resources to bring a speck up thank

00:01:41,020 --> 00:01:45,039
goodness they were able to kind of bring

00:01:42,939 --> 00:01:47,170
that bring the resources into play

00:01:45,039 --> 00:01:48,520
probably in the first couple of things

00:01:47,170 --> 00:01:50,740
like three or four days after we

00:01:48,520 --> 00:01:52,840
launched the US but that was that was

00:01:50,740 --> 00:01:54,549
pretty trying and then ever software

00:01:52,840 --> 00:01:56,380
problems as well just scaling up

00:01:54,549 --> 00:01:57,759
something at fast everybody says when

00:01:56,380 --> 00:01:59,619
you scale something 10x you run into a

00:01:57,759 --> 00:02:01,270
whole new set of problems well we did

00:01:59,619 --> 00:02:04,020
that twice so it was it was pretty

00:02:01,270 --> 00:02:07,419
pretty good pretty pretty pretty rough

00:02:04,020 --> 00:02:09,160
so where there are things that let's see

00:02:07,419 --> 00:02:10,390
a couple questions on this number one is

00:02:09,160 --> 00:02:13,480
there anything that you care to share

00:02:10,390 --> 00:02:15,569
that you think you should have done

00:02:13,480 --> 00:02:17,310
differently or were these all problem

00:02:15,569 --> 00:02:19,230
where is like hey this thing is a

00:02:17,310 --> 00:02:20,819
hundred times more popular than you know

00:02:19,230 --> 00:02:22,590
our wildest dreams you know these are

00:02:20,819 --> 00:02:23,489
the sort of these are the sort of

00:02:22,590 --> 00:02:25,349
problems you're just going to run into

00:02:23,489 --> 00:02:27,239
look we've done differently I think we

00:02:25,349 --> 00:02:30,239
could have spent a little more time

00:02:27,239 --> 00:02:31,980
understanding the performance

00:02:30,239 --> 00:02:34,079
characteristics of third-party software

00:02:31,980 --> 00:02:37,439
mm-hmm we used a couple open source

00:02:34,079 --> 00:02:39,750
libraries when we deployed this and one

00:02:37,439 --> 00:02:43,650
of them has a really nasty distributed

00:02:39,750 --> 00:02:45,120
computing that we ran into every single

00:02:43,650 --> 00:02:47,370
day right around two thirty in the

00:02:45,120 --> 00:02:48,870
afternoon and we thought we'd fix the

00:02:47,370 --> 00:02:50,159
bottleneck and a tooth or any afternoon

00:02:48,870 --> 00:02:52,290
the whole system would fall off a cliff

00:02:50,159 --> 00:02:54,120
right so east coast gets off work people

00:02:52,290 --> 00:02:55,919
start playing yeah it's pretty much as

00:02:54,120 --> 00:02:57,269
soon as the East Coast people and San

00:02:55,919 --> 00:03:02,489
Francisco's tuned to play all the time

00:02:57,269 --> 00:03:04,530
go figure um they the yeah we kept

00:03:02,489 --> 00:03:05,909
falling off a cliff and and I just

00:03:04,530 --> 00:03:07,379
remember it's like a total nail-biter

00:03:05,909 --> 00:03:09,150
you sit there you watch it kids going to

00:03:07,379 --> 00:03:11,159
hit it today and five minutes later boom

00:03:09,150 --> 00:03:12,299
yep system goes down and so what was the

00:03:11,159 --> 00:03:13,379
solution there was it sort of ripping

00:03:12,299 --> 00:03:15,090
that out and putting something else in

00:03:13,379 --> 00:03:17,280
place was it yeah we piling the

00:03:15,090 --> 00:03:18,900
developer and a rather esoteric comment

00:03:17,280 --> 00:03:21,329
about the performance characteristics of

00:03:18,900 --> 00:03:23,400
this library we ripped it out replaced

00:03:21,329 --> 00:03:26,150
it with the standard Java library and

00:03:23,400 --> 00:03:28,530
the problem went away it just went away

00:03:26,150 --> 00:03:30,959
gotcha there you read Stack Overflow

00:03:28,530 --> 00:03:32,819
like everyone else okay yeah she just

00:03:30,959 --> 00:03:36,599
wasn't on Stack Overflow this was this

00:03:32,819 --> 00:03:39,689
was on an esoteric group mailing group

00:03:36,599 --> 00:03:42,229
that our bottleneck finders dug up

00:03:39,689 --> 00:03:42,229

YouTube URL: https://www.youtube.com/watch?v=6D0_xvRdWvU


