Title: Building neural networks for learning and inference with Amir Khosrowshahi (Intel)
Publication date: 2017-10-02
Playlist: O'Reilly Artificial Intelligence Conference 2017 - San Francisco, CA
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,060 --> 00:00:04,380
hi this is Mike Hendrickson from the AI

00:00:02,040 --> 00:00:05,250
conf in San Francisco I'm here with Amir

00:00:04,380 --> 00:00:07,799
from Intel

00:00:05,250 --> 00:00:09,900
Amir how are you doing very good sir

00:00:07,799 --> 00:00:11,790
dear you're in a kind of a new group at

00:00:09,900 --> 00:00:13,559
Intel I mean Intel's got a lot of new

00:00:11,790 --> 00:00:15,389
stuff going on around AI but can you

00:00:13,559 --> 00:00:19,140
unpack a little bit about what you guys

00:00:15,389 --> 00:00:21,539
do in your group so the new group you

00:00:19,140 --> 00:00:23,220
mentioned is called AI PG and it stands

00:00:21,539 --> 00:00:25,650
for artificial intelligence products

00:00:23,220 --> 00:00:28,980
group and it's a full verticle business

00:00:25,650 --> 00:00:31,800
unit that has engineering of various

00:00:28,980 --> 00:00:33,739
sorts it has hardware a silicon low

00:00:31,800 --> 00:00:36,090
level software high level software

00:00:33,739 --> 00:00:37,680
machine learning algorithms all the way

00:00:36,090 --> 00:00:40,620
up to vertical solutions for different

00:00:37,680 --> 00:00:44,129
problem domains such as images speech

00:00:40,620 --> 00:00:46,410
text consumer devices medical financial

00:00:44,129 --> 00:00:48,239
government and so forth so when you say

00:00:46,410 --> 00:00:50,039
your a stack you you really are from the

00:00:48,239 --> 00:00:52,140
hardware all the way through software

00:00:50,039 --> 00:00:54,059
and then you can focus that in on

00:00:52,140 --> 00:00:55,649
different industry verticals as well

00:00:54,059 --> 00:00:58,770
that's right it's somewhat unusual for

00:00:55,649 --> 00:01:00,420
companies such as Intel to have a

00:00:58,770 --> 00:01:03,870
vertical business unit like that but

00:01:00,420 --> 00:01:05,100
it's a sign of the times the the needs

00:01:03,870 --> 00:01:07,740
the business needs are pretty

00:01:05,100 --> 00:01:10,890
significant and industry is very rapidly

00:01:07,740 --> 00:01:13,200
adopting this technology and a vertical

00:01:10,890 --> 00:01:14,670
business unit with all the stuff that

00:01:13,200 --> 00:01:16,710
you would potentially need as a business

00:01:14,670 --> 00:01:18,689
is a better way to address these needs

00:01:16,710 --> 00:01:20,880
quickly and make it less painful for

00:01:18,689 --> 00:01:23,220
businesses to adopt the technology and

00:01:20,880 --> 00:01:25,020
it's the CTO for the screw you're kind

00:01:23,220 --> 00:01:26,790
of setting the technical direction of

00:01:25,020 --> 00:01:29,939
where you'd like to see the product

00:01:26,790 --> 00:01:32,790
group go that's right yes so where are

00:01:29,939 --> 00:01:35,280
you guys going so the remarkable thing

00:01:32,790 --> 00:01:37,590
about and why I'm very excited to be at

00:01:35,280 --> 00:01:39,780
Intel now in this moment in history

00:01:37,590 --> 00:01:42,689
there's a long and storied history to AI

00:01:39,780 --> 00:01:44,909
and computation and I think this is a

00:01:42,689 --> 00:01:47,009
kind of a unique moment it's not clear

00:01:44,909 --> 00:01:48,750
how it's going to pan out but it looks

00:01:47,009 --> 00:01:51,149
very promising and what's interesting

00:01:48,750 --> 00:01:53,490
today is that Intel the iconic chip

00:01:51,149 --> 00:01:55,710
manufacturer long history of success

00:01:53,490 --> 00:01:57,509
most of the world's computer runs on

00:01:55,710 --> 00:01:59,909
Intel processors is actually building

00:01:57,509 --> 00:02:02,659
neural network processors is making

00:01:59,909 --> 00:02:04,860
silicon that's dedicated to processing

00:02:02,659 --> 00:02:06,270
deep learning networks which was

00:02:04,860 --> 00:02:08,250
basically neural networks we've been

00:02:06,270 --> 00:02:10,500
responded and processing it at high

00:02:08,250 --> 00:02:12,840
speeds so it does it can be like a

00:02:10,500 --> 00:02:13,680
real-time stream is that where we're

00:02:12,840 --> 00:02:17,370
getting to with

00:02:13,680 --> 00:02:19,500
I that it'll be instantaneous that's

00:02:17,370 --> 00:02:22,859
that's one of the aspects the way

00:02:19,500 --> 00:02:25,709
there's different ways to break up the

00:02:22,859 --> 00:02:27,959
AI workloads into different areas the

00:02:25,709 --> 00:02:30,180
way we think of it is there's learning

00:02:27,959 --> 00:02:32,480
and then there's inference the learning

00:02:30,180 --> 00:02:36,150
portion of the workflow is you have a

00:02:32,480 --> 00:02:39,450
distribution of data whether it's images

00:02:36,150 --> 00:02:41,430
on the internet or it's video you record

00:02:39,450 --> 00:02:43,409
it when you're driving your car around

00:02:41,430 --> 00:02:45,120
you learn a statistics of that data and

00:02:43,409 --> 00:02:46,739
you learn from it so you learn a neural

00:02:45,120 --> 00:02:48,659
network model and then you have

00:02:46,739 --> 00:02:50,790
inference where you have this learning

00:02:48,659 --> 00:02:53,099
model and you want to perform actions

00:02:50,790 --> 00:02:55,709
like what's in this image is it a cat

00:02:53,099 --> 00:02:58,260
and dog where are they in image what

00:02:55,709 --> 00:03:00,150
this is audio how do you translate this

00:02:58,260 --> 00:03:01,889
audio into text how do you translate

00:03:00,150 --> 00:03:04,530
this text from one language to the next

00:03:01,889 --> 00:03:06,299
those are influenced actions so this is

00:03:04,530 --> 00:03:07,950
one way we look at it and each piece

00:03:06,299 --> 00:03:10,200
potentially requires different kinds of

00:03:07,950 --> 00:03:11,129
silicon the silicon the first piece of

00:03:10,200 --> 00:03:12,569
silicon that we're going to release

00:03:11,129 --> 00:03:15,870
that's a dedicated neural network

00:03:12,569 --> 00:03:18,090
processor is more to address the the

00:03:15,870 --> 00:03:20,430
learning side which is very compute

00:03:18,090 --> 00:03:23,819
intensive and has very stringent

00:03:20,430 --> 00:03:25,919
constraints you has to be distributed it

00:03:23,819 --> 00:03:28,919
has to be scalable robust and so forth

00:03:25,919 --> 00:03:32,790
so this crest series is this neural

00:03:28,919 --> 00:03:35,459
network processor that the technology

00:03:32,790 --> 00:03:39,060
was purchased for my startup Nirvana so

00:03:35,459 --> 00:03:41,849
I was a startup prior to Intel and Intel

00:03:39,060 --> 00:03:44,069
is making it Intel quality so they can

00:03:41,849 --> 00:03:46,709
sell to millions of businesses hopefully

00:03:44,069 --> 00:03:48,900
and hopefully you will see this just

00:03:46,709 --> 00:03:50,689
learning processor and data centers and

00:03:48,900 --> 00:03:55,189
in the future we'll see other kinds of

00:03:50,689 --> 00:03:56,970
processors that are modifications or

00:03:55,189 --> 00:03:58,979
specialized for different kinds of

00:03:56,970 --> 00:04:00,299
workloads like everybody's happy J's and

00:03:58,979 --> 00:04:03,239
things like that are they in your group

00:04:00,299 --> 00:04:05,909
as well so FPGA is it's a large division

00:04:03,239 --> 00:04:07,709
at Intel it was a purchase Altera was

00:04:05,909 --> 00:04:09,959
purchased by Intel so it's a separate

00:04:07,709 --> 00:04:13,220
division but they have very interesting

00:04:09,959 --> 00:04:15,540
AI products so FPGA is our

00:04:13,220 --> 00:04:18,570
reconfigurable finding distributed

00:04:15,540 --> 00:04:21,479
fabrics if you look at the very small at

00:04:18,570 --> 00:04:24,150
the very small scale the FPGA processing

00:04:21,479 --> 00:04:24,770
element is essentially a multiply and

00:04:24,150 --> 00:04:26,479
add and

00:04:24,770 --> 00:04:27,949
and if you look at the elements of a

00:04:26,479 --> 00:04:32,720
neural network that's exactly what a

00:04:27,949 --> 00:04:34,550
neural network element is so neural

00:04:32,720 --> 00:04:38,210
neural network problems translate very

00:04:34,550 --> 00:04:40,699
naturally to FPGAs and a PGA's are

00:04:38,210 --> 00:04:43,490
highly scalable they have great i/o they

00:04:40,699 --> 00:04:46,849
have very low latency so there are use

00:04:43,490 --> 00:04:48,440
cases were FPGAs Excel there's other

00:04:46,849 --> 00:04:50,930
products that Intel and the main product

00:04:48,440 --> 00:04:52,669
is actually Xeon as the CPU right then

00:04:50,930 --> 00:04:55,610
we can talk about that more right so you

00:04:52,669 --> 00:04:58,280
really have I mean Intel really has an

00:04:55,610 --> 00:05:00,680
offering all across and up to the stack

00:04:58,280 --> 00:05:03,830
you never throw up you go across as well

00:05:00,680 --> 00:05:07,039
that's right so the one thing that we

00:05:03,830 --> 00:05:08,599
know about the AI area today is that

00:05:07,039 --> 00:05:10,340
it's changing rapidly and we should

00:05:08,599 --> 00:05:12,470
expect it to continue to change quite

00:05:10,340 --> 00:05:14,900
rapidly so there are potentially

00:05:12,470 --> 00:05:17,870
multiple trajectories on which I will

00:05:14,900 --> 00:05:20,449
involve evolve and one is the trajectory

00:05:17,870 --> 00:05:22,430
which is good for my my groups process

00:05:20,449 --> 00:05:24,380
or the crust is lots of compute you know

00:05:22,430 --> 00:05:26,360
more data you do more multiplies and

00:05:24,380 --> 00:05:29,060
adds you get better training results

00:05:26,360 --> 00:05:32,360
with more data that's one trajectory the

00:05:29,060 --> 00:05:35,090
other trajectory is that businesses are

00:05:32,360 --> 00:05:36,650
adopting its technology and it's not

00:05:35,090 --> 00:05:38,270
just multiplies amounts it's not just

00:05:36,650 --> 00:05:39,889
neural networks if you want to deploy a

00:05:38,270 --> 00:05:42,080
speech engine on the web if you want to

00:05:39,889 --> 00:05:44,630
have an autonomous car that is very safe

00:05:42,080 --> 00:05:47,389
and reliable there's lots of software

00:05:44,630 --> 00:05:49,969
and infrastructure that is required to

00:05:47,389 --> 00:05:52,330
make it successful and as people start

00:05:49,969 --> 00:05:55,219
to adopt AI technologies they realize

00:05:52,330 --> 00:05:57,169
that there is this hurdle and it's not

00:05:55,219 --> 00:05:59,180
just the machine learning component it's

00:05:57,169 --> 00:06:01,370
all the other stuff and there's a lot of

00:05:59,180 --> 00:06:03,849
it and that all runs on zealand's on

00:06:01,370 --> 00:06:07,009
CPUs because it's searching sorting

00:06:03,849 --> 00:06:09,199
stimulating databases serving webpages

00:06:07,009 --> 00:06:10,490
finite state machines lots of things

00:06:09,199 --> 00:06:12,409
that are not neural networks that are

00:06:10,490 --> 00:06:14,419
really essential for deploying a

00:06:12,409 --> 00:06:16,460
successful product so it sounds like

00:06:14,419 --> 00:06:18,380
we're at a point in time where all the

00:06:16,460 --> 00:06:20,719
technology is kind of call us in and

00:06:18,380 --> 00:06:24,500
coming together to make AI a real

00:06:20,719 --> 00:06:29,050
reality is anyone really doing something

00:06:24,500 --> 00:06:32,150
novel and mind-bending yet with AI

00:06:29,050 --> 00:06:35,599
that's a great question so I've been

00:06:32,150 --> 00:06:37,880
living in in this area for the last 10

00:06:35,599 --> 00:06:38,770
years in grad school and I was very

00:06:37,880 --> 00:06:41,380
lucky in my

00:06:38,770 --> 00:06:44,380
graduate program I was around the

00:06:41,380 --> 00:06:46,330
luminaries of the field today like Jeff

00:06:44,380 --> 00:06:47,590
Fenton and others Jeff continues to

00:06:46,330 --> 00:06:49,240
tease me because they used to work on

00:06:47,590 --> 00:06:51,370
Wall Street so what are you doing here

00:06:49,240 --> 00:06:53,949
why are you studying in neuroscience so

00:06:51,370 --> 00:06:56,380
I kind of I was in this environment I

00:06:53,949 --> 00:06:58,720
just saw the gradual improvement over

00:06:56,380 --> 00:07:00,940
the last 10 years and it's this

00:06:58,720 --> 00:07:05,349
Renaissance of neural networks started

00:07:00,940 --> 00:07:06,789
around 2006 in Canada actually and so

00:07:05,349 --> 00:07:08,860
for me it's just been a continual

00:07:06,789 --> 00:07:11,110
improvement over time there's been some

00:07:08,860 --> 00:07:12,970
seminal changes where one algorithm all

00:07:11,110 --> 00:07:16,449
of a sudden was a lot better than the

00:07:12,970 --> 00:07:18,400
previous one so Tunis doesn't seem like

00:07:16,449 --> 00:07:21,520
a huge discontinuity where there was no

00:07:18,400 --> 00:07:23,110
III before and now there was AI and I

00:07:21,520 --> 00:07:25,479
see that also continuing in the future

00:07:23,110 --> 00:07:27,159
we're not gonna have autonomous driving

00:07:25,479 --> 00:07:29,949
in a couple of years it's gonna take a

00:07:27,159 --> 00:07:31,840
long time series gonna get better cars

00:07:29,949 --> 00:07:33,880
are gonna have better features your

00:07:31,840 --> 00:07:37,120
services are gonna get better but you're

00:07:33,880 --> 00:07:39,250
not gonna have robots wandering around

00:07:37,120 --> 00:07:42,340
and stealing jobs from people storing

00:07:39,250 --> 00:07:43,750
jobs from people that's at least I don't

00:07:42,340 --> 00:07:45,400
know how long in the future are we gonna

00:07:43,750 --> 00:07:47,080
have to have an ethical discussion about

00:07:45,400 --> 00:07:48,880
all this as well I mean it I mean

00:07:47,080 --> 00:07:51,759
technology sounds like we can get there

00:07:48,880 --> 00:07:55,330
in the next few years but are we ready

00:07:51,759 --> 00:07:58,120
culturally and ethically about how AI is

00:07:55,330 --> 00:08:01,210
deployed and used I mean you can think

00:07:58,120 --> 00:08:04,270
about like a policing force using AI to

00:08:01,210 --> 00:08:06,759
detect you know things that could have

00:08:04,270 --> 00:08:08,949
built-in bias with them absolutely yes

00:08:06,759 --> 00:08:11,860
there are it's potentially not and

00:08:08,949 --> 00:08:13,960
what's in the mainstream press that

00:08:11,860 --> 00:08:16,229
we're gonna have a killer robots or

00:08:13,960 --> 00:08:18,159
we're gonna have robots that are gonna

00:08:16,229 --> 00:08:21,460
take over the world

00:08:18,159 --> 00:08:25,240
Terminator style it's a more subtle

00:08:21,460 --> 00:08:28,620
issues such as data privacy and security

00:08:25,240 --> 00:08:31,780
and HIPPA of that nature

00:08:28,620 --> 00:08:33,579
AI algorithms are just machine learning

00:08:31,780 --> 00:08:34,930
algorithms that have evolved in the last

00:08:33,579 --> 00:08:37,360
couple of years to become a lot better

00:08:34,930 --> 00:08:40,120
so the issues that existed before still

00:08:37,360 --> 00:08:41,849
exist today and will still be thorny

00:08:40,120 --> 00:08:44,350
issues in the future that will need

00:08:41,849 --> 00:08:45,880
policing regulation and so forth

00:08:44,350 --> 00:08:49,959
but it's not something that is

00:08:45,880 --> 00:08:51,089
completely new and intractable and we

00:08:49,959 --> 00:08:53,160
have to be

00:08:51,089 --> 00:08:56,220
along by therefore humans are always

00:08:53,160 --> 00:08:58,439
going to kind of be in that loop yes I

00:08:56,220 --> 00:09:00,749
think so and I've joked potentially it's

00:08:58,439 --> 00:09:02,790
not funny but if the robots do take over

00:09:00,749 --> 00:09:04,170
they will immediately realize that

00:09:02,790 --> 00:09:06,029
humans are very useful

00:09:04,170 --> 00:09:08,430
we're very power efficient it'll give us

00:09:06,029 --> 00:09:10,259
jobs and all they'll build humans those

00:09:08,430 --> 00:09:12,540
robots will start building humans so

00:09:10,259 --> 00:09:15,509
don't be worried this is a very strange

00:09:12,540 --> 00:09:20,249
dystopian future I could could be movie

00:09:15,509 --> 00:09:22,559
yes so if we were to sit down twelve

00:09:20,249 --> 00:09:25,110
months from now here what would you like

00:09:22,559 --> 00:09:27,689
to say has changed for Intel and your

00:09:25,110 --> 00:09:29,279
product group at that time mm-hmm during

00:09:27,689 --> 00:09:32,550
that 12 months and what would you like

00:09:29,279 --> 00:09:35,459
to see change significantly in the

00:09:32,550 --> 00:09:38,790
industry as well so twofold Intel and

00:09:35,459 --> 00:09:40,649
then the industry so quite a lot I've

00:09:38,790 --> 00:09:43,319
been at Intel for a year and it's really

00:09:40,649 --> 00:09:47,430
remarkable how far we've come along and

00:09:43,319 --> 00:09:50,100
just this year the CEO is well versed in

00:09:47,430 --> 00:09:52,290
AI and is Brian krzanich and he

00:09:50,100 --> 00:09:54,240
understands the it's a very treacherous

00:09:52,290 --> 00:09:58,110
landscape you know you hear hype you

00:09:54,240 --> 00:09:59,879
hear this algorithm is gonna

00:09:58,110 --> 00:10:01,949
revolutionize we're gonna cure cancer or

00:09:59,879 --> 00:10:03,420
this and that and what's happened in the

00:10:01,949 --> 00:10:05,550
last year is that we have a very

00:10:03,420 --> 00:10:07,889
grounded view of AI that things are

00:10:05,550 --> 00:10:09,449
gonna happen along some progression that

00:10:07,889 --> 00:10:15,329
we're gonna have level 3 autonomy in

00:10:09,449 --> 00:10:17,819
cars by 2025 not level 5 by 2020 so we

00:10:15,329 --> 00:10:20,279
have we're very pragmatic Intel is a

00:10:17,819 --> 00:10:24,259
large business so in order for AI to be

00:10:20,279 --> 00:10:28,170
relevant for Intel it has to be big and

00:10:24,259 --> 00:10:31,350
over the last year it has it's been the

00:10:28,170 --> 00:10:32,970
case that this use case Intel is

00:10:31,350 --> 00:10:35,160
discovered by talking to its customers

00:10:32,970 --> 00:10:37,740
and asking what you need that this is an

00:10:35,160 --> 00:10:38,970
enormous use case for them so and

00:10:37,740 --> 00:10:40,529
they've acted really quickly they've

00:10:38,970 --> 00:10:42,959
created this new business unit they've

00:10:40,529 --> 00:10:45,660
had made several acquisitions including

00:10:42,959 --> 00:10:46,800
mobile I my company Nirvana my videos

00:10:45,660 --> 00:10:49,860
and other very interesting technology

00:10:46,800 --> 00:10:51,779
that they purchased so that's been the

00:10:49,860 --> 00:10:55,350
last year I think in the next year I

00:10:51,779 --> 00:10:57,059
would just want more of the same we were

00:10:55,350 --> 00:11:00,750
building really great products for our

00:10:57,059 --> 00:11:02,970
customers since joining Intel I realized

00:11:00,750 --> 00:11:04,040
that customers of Intel had a really

00:11:02,970 --> 00:11:06,529
great experience

00:11:04,040 --> 00:11:09,350
this company for a long period so you

00:11:06,529 --> 00:11:13,459
have ready access to great feedback from

00:11:09,350 --> 00:11:16,070
all levels of enterprise customers csps

00:11:13,459 --> 00:11:17,389
cloud service providers academic

00:11:16,070 --> 00:11:18,920
relationships

00:11:17,389 --> 00:11:20,240
you're just you're given you have all

00:11:18,920 --> 00:11:22,220
the information you need so you just

00:11:20,240 --> 00:11:24,649
have to act and execute and build really

00:11:22,220 --> 00:11:27,199
good products so basically more of the

00:11:24,649 --> 00:11:30,170
same for the next year we just want to

00:11:27,199 --> 00:11:32,389
grow this business and continue to get

00:11:30,170 --> 00:11:34,279
feedback from customers and bringing

00:11:32,389 --> 00:11:34,699
them Silicon get feedback maybe they'll

00:11:34,279 --> 00:11:39,139
hit it

00:11:34,699 --> 00:11:40,579
maybe they'll love it and evolve and

00:11:39,139 --> 00:11:42,370
then the industry what would you like to

00:11:40,579 --> 00:11:45,529
see change in the industry significantly

00:11:42,370 --> 00:11:47,360
I think things are going pretty well so

00:11:45,529 --> 00:11:49,069
for example what would you think is uh

00:11:47,360 --> 00:11:50,899
something that would be of concern like

00:11:49,069 --> 00:11:54,529
the application of maybe AI in

00:11:50,899 --> 00:11:56,360
healthcare or you know maybe solving the

00:11:54,529 --> 00:11:58,610
fake news problem with blockchain and AI

00:11:56,360 --> 00:12:00,769
combined or something like that yeah so

00:11:58,610 --> 00:12:02,389
yeah this is a great so medicine these

00:12:00,769 --> 00:12:04,279
are material things so there's you know

00:12:02,389 --> 00:12:08,170
I talked about height and robots and so

00:12:04,279 --> 00:12:09,740
forth but again there's there's gradual

00:12:08,170 --> 00:12:12,769
improvements and some of the

00:12:09,740 --> 00:12:15,019
improvements are you know jumps in all

00:12:12,769 --> 00:12:20,630
areas in medicine so one concrete area

00:12:15,019 --> 00:12:22,040
is diagnosing basically diabetes through

00:12:20,630 --> 00:12:24,079
you're looking at a retina so does a

00:12:22,040 --> 00:12:26,839
sinkhole diabetic retinopathy where

00:12:24,079 --> 00:12:29,360
evidence of diabetes appears early on in

00:12:26,839 --> 00:12:32,529
your retina you can see it in the fundus

00:12:29,360 --> 00:12:35,720
image I'm a visual neuroscientist before

00:12:32,529 --> 00:12:38,510
before I until I studied the visual

00:12:35,720 --> 00:12:40,250
system so well the this part of the head

00:12:38,510 --> 00:12:43,399
as well as a retina which is part of the

00:12:40,250 --> 00:12:46,279
brain so you can take images of the eye

00:12:43,399 --> 00:12:49,550
the fundus and you can use a neural

00:12:46,279 --> 00:12:52,970
network to to find trouble spots that

00:12:49,550 --> 00:12:55,370
are very early indicators of diabetes so

00:12:52,970 --> 00:12:57,439
this is a material change it's a simple

00:12:55,370 --> 00:12:59,689
idea but it's really material it's going

00:12:57,439 --> 00:13:02,389
to help people a great deal and that's

00:12:59,689 --> 00:13:03,769
available today excellent well Amir we

00:13:02,389 --> 00:13:05,300
look forward to that conversation twelve

00:13:03,769 --> 00:13:07,959
months from now okay thank you very much

00:13:05,300 --> 00:13:07,959
thank you very much

00:13:13,820 --> 00:13:15,880

YouTube URL: https://www.youtube.com/watch?v=_rqCYQliNQQ


