Title: Understanding Automation - Ben Lorica (O'Reilly Media) and Roger Chen (Computable Labs)
Publication date: 2018-05-01
Playlist: Artificial Intelligence Conference 2018 - New York, New York
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:06,000
so a few months ago we conducted a

00:00:03,300 --> 00:00:09,179
survey where we wanted to find out how

00:00:06,000 --> 00:00:12,030
companies are actually engaging in some

00:00:09,179 --> 00:00:14,219
of the technologies and topics covered

00:00:12,030 --> 00:00:17,880
in this conference in particular we

00:00:14,219 --> 00:00:20,490
wanted to see deep learning being one of

00:00:17,880 --> 00:00:22,560
the models or one of the methods that

00:00:20,490 --> 00:00:25,490
has led to the resurgence and interest

00:00:22,560 --> 00:00:28,470
in AI to what extent are companies

00:00:25,490 --> 00:00:31,019
starting to think about deep learning so

00:00:28,470 --> 00:00:34,860
what we found is at least over half of

00:00:31,019 --> 00:00:38,219
the companies already have serious plans

00:00:34,860 --> 00:00:41,640
to use deep learning in in the future

00:00:38,219 --> 00:00:43,950
but as many of you know AI is much more

00:00:41,640 --> 00:00:47,280
than deep learning in fact our closing

00:00:43,950 --> 00:00:49,980
keynote this morning is from one of the

00:00:47,280 --> 00:00:54,030
leading researchers in Bayesian methods

00:00:49,980 --> 00:00:56,070
and yesterday we had a very popular

00:00:54,030 --> 00:00:58,789
tutorial on reinforcement learning and

00:00:56,070 --> 00:01:03,300
we'll have a few more sessions on RL

00:00:58,789 --> 00:01:05,430
over the next few days yeah the plenary

00:01:03,300 --> 00:01:07,740
remains a very popular research topic

00:01:05,430 --> 00:01:09,540
and one measure of that is the number of

00:01:07,740 --> 00:01:11,340
publications that come out on archive

00:01:09,540 --> 00:01:13,229
related to deep learning but one thing

00:01:11,340 --> 00:01:16,020
we noticed in particular is recently

00:01:13,229 --> 00:01:17,820
there have been a lot more terms you

00:01:16,020 --> 00:01:19,770
know associate with these works are in

00:01:17,820 --> 00:01:24,119
particular associated with deep

00:01:19,770 --> 00:01:26,640
reinforcement learning now one thing to

00:01:24,119 --> 00:01:28,439
remember though is that some of the best

00:01:26,640 --> 00:01:29,939
breakthroughs actually combine several

00:01:28,439 --> 00:01:32,130
methods for example some of the

00:01:29,939 --> 00:01:34,200
breakthroughs last year in automating

00:01:32,130 --> 00:01:36,180
the game of Go or automating the game of

00:01:34,200 --> 00:01:38,040
poker actually combined multiple

00:01:36,180 --> 00:01:42,000
techniques related to AI and deep

00:01:38,040 --> 00:01:45,170
learning now many of the data scientists

00:01:42,000 --> 00:01:47,909
here are very very comfortable using

00:01:45,170 --> 00:01:48,390
methods in supervised and a supervised

00:01:47,909 --> 00:01:50,670
learning

00:01:48,390 --> 00:01:53,880
I think reinforcement learning is a

00:01:50,670 --> 00:01:58,170
little newer so one way to describe it

00:01:53,880 --> 00:02:00,180
is it occurs in the context of an agent

00:01:58,170 --> 00:02:03,960
exploring an environment so what you're

00:02:00,180 --> 00:02:06,240
trying to do is learn a policy for how

00:02:03,960 --> 00:02:08,220
that agent will behave in a in that

00:02:06,240 --> 00:02:11,819
environment so if you think of it that

00:02:08,220 --> 00:02:13,040
way you imagine many many applications

00:02:11,819 --> 00:02:17,360
that open

00:02:13,040 --> 00:02:20,450
when you add reinforcement learning your

00:02:17,360 --> 00:02:22,879
tooltip so of course reinforcement is

00:02:20,450 --> 00:02:25,189
not without some challenges as we all

00:02:22,879 --> 00:02:27,409
know deep learning is pretty data hungry

00:02:25,189 --> 00:02:29,870
deep reinforcement learning is arguably

00:02:27,409 --> 00:02:31,940
even more data hungry in addition a lot

00:02:29,870 --> 00:02:33,440
of the recent breakthroughs really came

00:02:31,940 --> 00:02:35,269
through cutting edge research in

00:02:33,440 --> 00:02:37,489
academia so it's gonna take some time to

00:02:35,269 --> 00:02:39,200
translate some of that academic work

00:02:37,489 --> 00:02:41,120
into industry but we're seeing some

00:02:39,200 --> 00:02:42,500
really promising stuff really promising

00:02:41,120 --> 00:02:44,480
developments for example out of the rise

00:02:42,500 --> 00:02:45,769
lab and the rave framework so we think

00:02:44,480 --> 00:02:48,739
we'll have some exciting things around a

00:02:45,769 --> 00:02:50,390
corner for industrial translation and

00:02:48,739 --> 00:02:53,060
that's not to say that RL isn't already

00:02:50,390 --> 00:02:55,459
making in the shrimp act so for example

00:02:53,060 --> 00:02:57,470
mark Hammond of Banzai one of our

00:02:55,459 --> 00:02:58,849
speakers at this conference will spend

00:02:57,470 --> 00:03:01,250
some time talking about how their

00:02:58,849 --> 00:03:03,470
company has actually already deployed

00:03:01,250 --> 00:03:05,540
some RL solutions for industrial

00:03:03,470 --> 00:03:07,819
automation applications and if you

00:03:05,540 --> 00:03:10,069
recall google and other folks have done

00:03:07,819 --> 00:03:11,659
some great work also playing RL to

00:03:10,069 --> 00:03:13,730
improve energy efficiency of

00:03:11,659 --> 00:03:16,819
infrastructure for example energy

00:03:13,730 --> 00:03:19,310
efficiency of data centers let's talk a

00:03:16,819 --> 00:03:21,169
little bit about automation so I think

00:03:19,310 --> 00:03:23,299
many of us sometimes think of automation

00:03:21,169 --> 00:03:26,299
is a binary either you're doing

00:03:23,299 --> 00:03:29,090
automation or you're not but the reality

00:03:26,299 --> 00:03:31,910
is automation occurs on a spectrum so

00:03:29,090 --> 00:03:33,859
for example in the self-driving car

00:03:31,910 --> 00:03:36,379
industry they have very well-defined

00:03:33,859 --> 00:03:39,290
levels of automation and it's only at

00:03:36,379 --> 00:03:40,810
that highest level the fifth level that

00:03:39,290 --> 00:03:43,549
full automation of hers

00:03:40,810 --> 00:03:46,370
so what that means for you as you

00:03:43,549 --> 00:03:49,489
navigate over the next few days the

00:03:46,370 --> 00:03:51,829
sessions in this conference try to

00:03:49,489 --> 00:03:55,010
evaluate whether some of these methods

00:03:51,829 --> 00:03:58,010
are already at that stage where some of

00:03:55,010 --> 00:03:59,659
the tasks in your companies so some of

00:03:58,010 --> 00:04:02,500
the workflows may already lend

00:03:59,659 --> 00:04:05,359
themselves to being partially automated

00:04:02,500 --> 00:04:07,549
one area within enterprise we were

00:04:05,359 --> 00:04:09,169
seeing adoption already is with an IT

00:04:07,549 --> 00:04:10,879
and software development that's no

00:04:09,169 --> 00:04:12,530
surprise because engineers are really

00:04:10,879 --> 00:04:14,150
good at leveraging technology to make

00:04:12,530 --> 00:04:16,070
their jobs easier make working more

00:04:14,150 --> 00:04:17,630
efficient in particular we're seeing

00:04:16,070 --> 00:04:19,909
lots of interesting things related to

00:04:17,630 --> 00:04:22,250
applying AI to database management and

00:04:19,909 --> 00:04:24,800
we actually have Tim Crockett from MIT

00:04:22,250 --> 00:04:26,780
here who will speak to that during this

00:04:24,800 --> 00:04:29,420
conference we've also seen AI

00:04:26,780 --> 00:04:31,310
apply towards automating discovery of

00:04:29,420 --> 00:04:34,840
learning architectures and even towards

00:04:31,310 --> 00:04:37,100
of writing bug free software code

00:04:34,840 --> 00:04:39,830
another area that we've seen lots of

00:04:37,100 --> 00:04:41,510
interests and applications is towards

00:04:39,830 --> 00:04:43,669
conversation of Commerce and interaction

00:04:41,510 --> 00:04:45,889
with customers through through chat BOTS

00:04:43,669 --> 00:04:47,660
now there's a lot to be done still but

00:04:45,889 --> 00:04:49,250
we're excited for what's going to happen

00:04:47,660 --> 00:04:50,600
and what's right around the corner in a

00:04:49,250 --> 00:04:52,490
few years as we solve some of the

00:04:50,600 --> 00:04:55,250
challenging natural language problems

00:04:52,490 --> 00:04:57,740
that face us in this space so as Roger

00:04:55,250 --> 00:05:01,370
alluded to progress in many of these

00:04:57,740 --> 00:05:04,730
applications rely on some basic building

00:05:01,370 --> 00:05:06,620
blocks so with the chat BOTS that means

00:05:04,730 --> 00:05:11,620
natural language generation and natural

00:05:06,620 --> 00:05:14,840
language understanding anything that

00:05:11,620 --> 00:05:16,700
needs a manual labor will need more

00:05:14,840 --> 00:05:19,790
progress in robotics and sensory

00:05:16,700 --> 00:05:22,040
perception among other things and let's

00:05:19,790 --> 00:05:24,500
not forget but really we need all three

00:05:22,040 --> 00:05:26,150
pillars in order to make AI work we need

00:05:24,500 --> 00:05:28,850
large models in order to automate

00:05:26,150 --> 00:05:31,040
complex tasks but we also need big data

00:05:28,850 --> 00:05:32,479
in order to Train it and large compute

00:05:31,040 --> 00:05:35,300
in order to have the computational

00:05:32,479 --> 00:05:38,750
resources to train it as well so with

00:05:35,300 --> 00:05:41,540
that said the AI systems of today may

00:05:38,750 --> 00:05:44,090
look quite different from the AI systems

00:05:41,540 --> 00:05:46,390
in the future so last year at this

00:05:44,090 --> 00:05:50,510
conference we had two keynote speakers

00:05:46,390 --> 00:05:52,760
Josh Tannenbaum of MIT and Dave Ferrucci

00:05:50,510 --> 00:05:55,430
of elemental cognition they both

00:05:52,760 --> 00:05:58,120
described systems that used deep

00:05:55,430 --> 00:06:01,640
learning but combined it with some

00:05:58,120 --> 00:06:03,800
domain knowledge some structure and the

00:06:01,640 --> 00:06:08,510
end result being that their systems

00:06:03,800 --> 00:06:11,570
relied on less data and that interest in

00:06:08,510 --> 00:06:14,539
alternative approaches has continued

00:06:11,570 --> 00:06:17,800
over the last year and what's become

00:06:14,539 --> 00:06:21,710
clear is that progress will rely on a

00:06:17,800 --> 00:06:23,570
multidisciplinary approach the exciting

00:06:21,710 --> 00:06:25,550
news is we have lots of tools and

00:06:23,570 --> 00:06:27,410
techniques spread around a corner that

00:06:25,550 --> 00:06:29,840
includes those coming around in software

00:06:27,410 --> 00:06:32,060
but also new developments with hardware

00:06:29,840 --> 00:06:34,130
that's custom tailored towards handling

00:06:32,060 --> 00:06:35,750
deep learning workloads and something

00:06:34,130 --> 00:06:37,970
that's often underappreciated that we'd

00:06:35,750 --> 00:06:39,870
like to be emphasized to is importance

00:06:37,970 --> 00:06:42,360
of the new paradigm for UX

00:06:39,870 --> 00:06:44,070
design for these AI based products and

00:06:42,360 --> 00:06:45,690
as these new primitives come online for

00:06:44,070 --> 00:06:48,090
AI we're just really excited to see what

00:06:45,690 --> 00:06:51,270
sorts of intelligence stacks will will

00:06:48,090 --> 00:06:53,670
exist so which brings me back to that

00:06:51,270 --> 00:06:57,000
survey I reference at the start of this

00:06:53,670 --> 00:06:59,810
talk so the one the main bottleneck that

00:06:57,000 --> 00:07:02,220
we found was lack of skilled people and

00:06:59,810 --> 00:07:04,340
actually that's why we started this

00:07:02,220 --> 00:07:08,430
conference with two days of training and

00:07:04,340 --> 00:07:11,330
a day of tutorials and there will be a

00:07:08,430 --> 00:07:13,920
lot of opportunities for you to

00:07:11,330 --> 00:07:16,020
interface with speakers but also with

00:07:13,920 --> 00:07:17,430
your peers so make sure you take

00:07:16,020 --> 00:07:18,870
advantage of all the networking

00:07:17,430 --> 00:07:22,020
opportunities at this conference

00:07:18,870 --> 00:07:24,230
including an application called brain

00:07:22,020 --> 00:07:24,230
date

00:07:30,360 --> 00:07:32,419

YouTube URL: https://www.youtube.com/watch?v=dh_87bxIO60


