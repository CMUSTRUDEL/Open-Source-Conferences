Title: MLPerf: A Benchmark Suite for Machine Learning - David Patterson (UC Berkeley)
Publication date: 2018-05-07
Playlist: Artificial Intelligence Conference 2018 - New York, New York
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:05,160
well thank you for your patience I'm

00:00:02,820 --> 00:00:07,950
delighted to tell you about a brand new

00:00:05,160 --> 00:00:09,809
effort and based on my long time in the

00:00:07,950 --> 00:00:11,940
field I think this is at a stark event

00:00:09,809 --> 00:00:15,080
that you're witnessing so we're

00:00:11,940 --> 00:00:17,160
announcing this effort that has

00:00:15,080 --> 00:00:19,350
researchers both from academia and

00:00:17,160 --> 00:00:22,980
Industry around trying to do something

00:00:19,350 --> 00:00:24,150
about benchmarking and we've got

00:00:22,980 --> 00:00:27,300
contributors from these five

00:00:24,150 --> 00:00:29,429
organizations three universities three

00:00:27,300 --> 00:00:31,019
industry firms and the highlighted

00:00:29,429 --> 00:00:33,059
people lots almost twenty people

00:00:31,019 --> 00:00:34,290
participated and the ones that are

00:00:33,059 --> 00:00:38,010
underlined are going to speak to you

00:00:34,290 --> 00:00:41,129
today in a tag team effort so my job is

00:00:38,010 --> 00:00:42,809
to set the stage so let me go over 40

00:00:41,129 --> 00:00:46,200
years of benchmarking in computer

00:00:42,809 --> 00:00:48,300
architecture in the 1970 the way we did

00:00:46,200 --> 00:00:50,670
that was we could guess how fast a

00:00:48,300 --> 00:00:52,680
computer was by just looking at the

00:00:50,670 --> 00:00:54,090
basic instructions about their average

00:00:52,680 --> 00:00:55,829
time and we would calculate how many

00:00:54,090 --> 00:00:59,160
instructions per second our MIPS

00:00:55,829 --> 00:01:00,570
millions of instructions per second that

00:00:59,160 --> 00:01:02,129
didn't work all that well because it

00:01:00,570 --> 00:01:04,460
mattered which program you run not just

00:01:02,129 --> 00:01:06,390
the average instructions and so the next

00:01:04,460 --> 00:01:07,799
iteration to try and improve

00:01:06,390 --> 00:01:09,390
benchmarking was to make synthetic

00:01:07,799 --> 00:01:11,640
programs that were supposed to be

00:01:09,390 --> 00:01:13,920
typical of the workload called wet

00:01:11,640 --> 00:01:15,689
stones and dry stones well one of the

00:01:13,920 --> 00:01:18,000
problems there because it wasn't a real

00:01:15,689 --> 00:01:19,439
program it was just a pretend program is

00:01:18,000 --> 00:01:21,960
if he turned on an optimizing compiler

00:01:19,439 --> 00:01:24,090
would throw most of that code away so

00:01:21,960 --> 00:01:26,009
the solution was you're not allowed to

00:01:24,090 --> 00:01:27,479
use an optimizing compiler so that's not

00:01:26,009 --> 00:01:29,700
such a great idea because in computer

00:01:27,479 --> 00:01:32,820
architecture compilers play this vital

00:01:29,700 --> 00:01:34,740
role the next step to make a small

00:01:32,820 --> 00:01:37,229
program was to use these toy programs

00:01:34,740 --> 00:01:39,659
like our great programming assignments

00:01:37,229 --> 00:01:41,250
like fifty or hundred lines and those

00:01:39,659 --> 00:01:43,259
weren't representative real workloads

00:01:41,250 --> 00:01:45,960
again measured MIPS and then for

00:01:43,259 --> 00:01:47,880
floating-point ones you wouldn't say use

00:01:45,960 --> 00:01:49,799
MIPS you'd use millions of

00:01:47,880 --> 00:01:51,930
floating-point operations per second but

00:01:49,799 --> 00:01:55,020
again that didn't work very well and in

00:01:51,930 --> 00:01:58,860
fact to try and shift the industry away

00:01:55,020 --> 00:02:00,149
from these bed benchmarks in John

00:01:58,860 --> 00:02:03,030
Hennessy and I did this computer

00:02:00,149 --> 00:02:04,560
architecture textbook in 1990 and to try

00:02:03,030 --> 00:02:06,090
and point out the mistakes we had a

00:02:04,560 --> 00:02:08,759
bunch of fallacies in our textbook um

00:02:06,090 --> 00:02:12,450
the first fallacy was peak performance

00:02:08,759 --> 00:02:13,560
doesn't predict real performance this

00:02:12,450 --> 00:02:15,120
industry today right

00:02:13,560 --> 00:02:16,590
now when we talk about new hardware we

00:02:15,120 --> 00:02:19,349
talk about peak performance still which

00:02:16,590 --> 00:02:22,440
is disappointing we pointed out that

00:02:19,349 --> 00:02:24,750
MIPS it doesn't predict performance

00:02:22,440 --> 00:02:26,340
admits as an instruction rate and you

00:02:24,750 --> 00:02:30,000
can have something that has a high MIPS

00:02:26,340 --> 00:02:31,830
rate but takes longer to run a program

00:02:30,000 --> 00:02:33,660
the synthetic programs don't work well

00:02:31,830 --> 00:02:35,780
though they're there they were an

00:02:33,660 --> 00:02:38,130
interesting idea but they failed so

00:02:35,780 --> 00:02:41,880
programs like dry stones no one should

00:02:38,130 --> 00:02:43,739
use those and that megaflops has the

00:02:41,880 --> 00:02:46,620
same problem of MIPS it's a rate and you

00:02:43,739 --> 00:02:49,500
could have a high rate but take longer

00:02:46,620 --> 00:02:51,030
to run programs and so if we go back 30

00:02:49,500 --> 00:02:52,680
years in computer architectures this was

00:02:51,030 --> 00:02:54,720
the state of the world what did that

00:02:52,680 --> 00:02:57,750
mean for people trying to buy and sell

00:02:54,720 --> 00:02:59,880
hardware well that the UNIX marketplace

00:02:57,750 --> 00:03:01,739
was just happening about RISC processors

00:02:59,880 --> 00:03:04,349
and a Salesman would go to a customer

00:03:01,739 --> 00:03:06,269
and say well my computer is really a 10

00:03:04,349 --> 00:03:07,650
myths computer it but those other guys

00:03:06,269 --> 00:03:10,290
that are coming to talk to you they

00:03:07,650 --> 00:03:11,610
don't they're lying and so nobody bought

00:03:10,290 --> 00:03:15,690
anything because you couldn't believe

00:03:11,610 --> 00:03:18,510
any of the into the vendors the reaction

00:03:15,690 --> 00:03:21,060
of that was remarkably for these

00:03:18,510 --> 00:03:24,269
competitive organizations you know HP

00:03:21,060 --> 00:03:26,489
Dec mips Sun Microsystems that competed

00:03:24,269 --> 00:03:29,010
fiercely in the marketplace to create a

00:03:26,489 --> 00:03:30,959
cooperative to create a standard set of

00:03:29,010 --> 00:03:33,390
benchmark so we could agree how to

00:03:30,959 --> 00:03:35,519
measure performance so this has happened

00:03:33,390 --> 00:03:37,590
30 years ago and that first iteration

00:03:35,519 --> 00:03:39,660
had ten programs for integers for

00:03:37,590 --> 00:03:41,940
floating-point you would figure out how

00:03:39,660 --> 00:03:44,400
much faster your machine was than the

00:03:41,940 --> 00:03:46,980
Machine of that year or the VAX 11 780

00:03:44,400 --> 00:03:49,019
and that you calculate the geometric

00:03:46,980 --> 00:03:50,940
geometric mean of that ratio so that

00:03:49,019 --> 00:03:53,730
bigger was better how many times faster

00:03:50,940 --> 00:03:55,980
you thin the back flip in 780 overall

00:03:53,730 --> 00:03:59,220
are for the integer programs or the

00:03:55,980 --> 00:04:01,739
floating-point programs so what was the

00:03:59,220 --> 00:04:03,269
impact of that first of all it's settled

00:04:01,739 --> 00:04:05,579
they've arguments the marketplace so you

00:04:03,269 --> 00:04:07,410
would go and say here's my fast how fast

00:04:05,579 --> 00:04:09,989
mine was and you wouldn't argue about

00:04:07,410 --> 00:04:12,569
performance and but you could say maybe

00:04:09,989 --> 00:04:13,049
for cost or functionality why mine's

00:04:12,569 --> 00:04:15,540
better

00:04:13,049 --> 00:04:18,870
so the UNIX market grew rather than

00:04:15,540 --> 00:04:20,430
argument it had a big impact inside each

00:04:18,870 --> 00:04:21,989
of these companies is because they could

00:04:20,430 --> 00:04:24,330
decide where the engineering effort

00:04:21,989 --> 00:04:26,889
should go they didn't have to argument

00:04:24,330 --> 00:04:30,069
that led to better investments

00:04:26,889 --> 00:04:31,479
the initial cooperativity many people

00:04:30,069 --> 00:04:34,020
want to join so they turned it into a

00:04:31,479 --> 00:04:37,330
corporation with more than 20 members

00:04:34,020 --> 00:04:38,979
they decided universes were important so

00:04:37,330 --> 00:04:41,259
they kept the cost low so universities

00:04:38,979 --> 00:04:43,000
participate and what happened is spec

00:04:41,259 --> 00:04:47,830
became the standard for everybody the

00:04:43,000 --> 00:04:50,770
marketplace papers and textbooks now to

00:04:47,830 --> 00:04:52,810
keep it active both because computers

00:04:50,770 --> 00:04:55,750
were getting faster and because people

00:04:52,810 --> 00:04:59,110
could over-engineer efforts around spec

00:04:55,750 --> 00:05:02,379
every few years they would revise the

00:04:59,110 --> 00:05:04,900
list and this figure which is a little

00:05:02,379 --> 00:05:07,120
bit hard to it was hard to read is the

00:05:04,900 --> 00:05:09,719
history of SPECT over six generations so

00:05:07,120 --> 00:05:11,889
there's 82 benchmarks in that list

00:05:09,719 --> 00:05:14,800
three-fourths of them only lasted a

00:05:11,889 --> 00:05:16,360
single iteration three of integer and

00:05:14,800 --> 00:05:17,860
three floating panel a stood more than

00:05:16,360 --> 00:05:19,569
three but basically you had to refresh

00:05:17,860 --> 00:05:22,840
the list all the time to keep it

00:05:19,569 --> 00:05:25,539
up-to-date and to make it grow to keep

00:05:22,840 --> 00:05:28,419
up with the faster computers the net net

00:05:25,539 --> 00:05:31,449
of all of this is CPU performance had

00:05:28,419 --> 00:05:33,699
this Renaissance period of growing by a

00:05:31,449 --> 00:05:35,289
factor of 1.6 every year for 15 years

00:05:33,699 --> 00:05:38,169
that's doubling every 18 months so that

00:05:35,289 --> 00:05:40,629
was a huge benefit in contrast to spec

00:05:38,169 --> 00:05:41,979
we have the embassy effort for embedded

00:05:40,629 --> 00:05:45,490
computing which started about 10 years

00:05:41,979 --> 00:05:48,460
later it was a non-profit like speck but

00:05:45,490 --> 00:05:50,319
it was very expensive to join to

00:05:48,460 --> 00:05:52,210
preserve the income they restricted

00:05:50,319 --> 00:05:53,770
access to it so universities couldn't

00:05:52,210 --> 00:05:56,169
afford to participate so they couldn't

00:05:53,770 --> 00:05:57,699
use it in their papers and it seemed to

00:05:56,169 --> 00:05:59,319
be more focused on making sure they

00:05:57,699 --> 00:06:01,120
could make money rather than you know

00:05:59,319 --> 00:06:04,479
creating a benchmark that would be good

00:06:01,120 --> 00:06:06,580
for the field they had quality problems

00:06:04,479 --> 00:06:08,409
with those benchmarks maybe because the

00:06:06,580 --> 00:06:11,250
lack of other people's participating and

00:06:08,409 --> 00:06:14,080
more or less it was abandoned today so

00:06:11,250 --> 00:06:15,699
20 20 years ago they tried to do that

00:06:14,080 --> 00:06:17,259
they didn't come up the benchmark what's

00:06:15,699 --> 00:06:19,680
the consequence the embedded community

00:06:17,259 --> 00:06:21,909
they are still using dry stone

00:06:19,680 --> 00:06:24,339
shockingly the thing that Hennessy and I

00:06:21,909 --> 00:06:25,629
said was a terrible idea in 1990 they

00:06:24,339 --> 00:06:27,909
still today and if you design an

00:06:25,629 --> 00:06:30,479
embedded computer you worry about this

00:06:27,909 --> 00:06:33,610
silly program dry stone how fast it runs

00:06:30,479 --> 00:06:35,529
so here we are machine learning what are

00:06:33,610 --> 00:06:36,969
we going to do are we gonna agree on

00:06:35,529 --> 00:06:39,039
benchmarks are we gonna file an embassy

00:06:36,969 --> 00:06:39,820
end up with terrible benchmarks so what

00:06:39,039 --> 00:06:43,570
we're announcing today

00:06:39,820 --> 00:06:45,250
a is ml perf you know spec for ml we're

00:06:43,570 --> 00:06:48,220
gonna try and do a cooperative where we

00:06:45,250 --> 00:06:50,920
try and get great benchmarks to

00:06:48,220 --> 00:06:53,440
accelerate our field that's our first

00:06:50,920 --> 00:06:55,980
goal a fair and useful comparison to

00:06:53,440 --> 00:07:00,130
accelerate progress in machine learning

00:06:55,980 --> 00:07:02,670
we want to like spec serve both the

00:07:00,130 --> 00:07:05,770
commercial needs and the research needs

00:07:02,670 --> 00:07:07,990
we want to enable these fair comparisons

00:07:05,770 --> 00:07:09,970
but even more than what spec want to do

00:07:07,990 --> 00:07:13,900
we also want to accelerate progress and

00:07:09,970 --> 00:07:15,520
machine learning like spec to get be

00:07:13,900 --> 00:07:17,430
sure we believe the results that they're

00:07:15,520 --> 00:07:19,630
reliable we're going to make them

00:07:17,430 --> 00:07:21,310
replicable but we can recreate the

00:07:19,630 --> 00:07:22,690
results make sure everything's there so

00:07:21,310 --> 00:07:25,780
we can do that too so the results are

00:07:22,690 --> 00:07:28,180
believable and like spec we're trying to

00:07:25,780 --> 00:07:30,840
keep it affordable so not only industry

00:07:28,180 --> 00:07:34,060
but universities can afford to do this

00:07:30,840 --> 00:07:35,380
and we're following the plan of agile

00:07:34,060 --> 00:07:37,180
benchmark development what does that

00:07:35,380 --> 00:07:40,450
mean that means we're gonna rapidly in a

00:07:37,180 --> 00:07:41,980
great in in aggravate iterate sorry the

00:07:40,450 --> 00:07:45,130
benchmarks like suspected but even

00:07:41,980 --> 00:07:46,870
faster one reason is machine learning is

00:07:45,130 --> 00:07:48,700
moving a lot faster than the UNIX

00:07:46,870 --> 00:07:49,870
marketplace is so to keep up with

00:07:48,700 --> 00:07:51,940
machine learning we're going to have to

00:07:49,870 --> 00:07:54,370
change those programs even faster

00:07:51,940 --> 00:07:56,110
secondly we'll certainly make mistakes

00:07:54,370 --> 00:07:58,390
just like SPECT it is leaving some

00:07:56,110 --> 00:07:59,560
loopholes that will lead to misleading

00:07:58,390 --> 00:08:02,590
performance so we're going to correct

00:07:59,560 --> 00:08:05,470
those and finally ml hardware is getting

00:08:02,590 --> 00:08:07,750
faster every year and the datasets that

00:08:05,470 --> 00:08:08,920
work today are going to be trivial in

00:08:07,750 --> 00:08:11,560
just a couple of years so we have to

00:08:08,920 --> 00:08:13,180
operate that way so my guess is we're

00:08:11,560 --> 00:08:16,000
going to iterate every year not every

00:08:13,180 --> 00:08:17,380
few years like like spected and but like

00:08:16,000 --> 00:08:19,000
spec we'll have like a quarterly

00:08:17,380 --> 00:08:20,530
deadline and publish all the results

00:08:19,000 --> 00:08:22,630
every every quarter of the assertion

00:08:20,530 --> 00:08:25,270
database okay I have set the stage now

00:08:22,630 --> 00:08:26,500
my colleague professor away from Harvard

00:08:25,270 --> 00:08:28,890
is going to tell you about the benchmark

00:08:26,500 --> 00:08:28,890
selection

00:08:34,889 --> 00:08:36,949

YouTube URL: https://www.youtube.com/watch?v=hQRBLW6giRc


