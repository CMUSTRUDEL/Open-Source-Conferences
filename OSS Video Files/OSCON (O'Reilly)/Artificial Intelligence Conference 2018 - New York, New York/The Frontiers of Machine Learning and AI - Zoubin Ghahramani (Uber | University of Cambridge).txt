Title: The Frontiers of Machine Learning and AI - Zoubin Ghahramani (Uber | University of Cambridge)
Publication date: 2018-05-01
Playlist: Artificial Intelligence Conference 2018 - New York, New York
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:06,690
now ironically many of the exciting

00:00:04,980 --> 00:00:09,120
things that have happened in machine

00:00:06,690 --> 00:00:11,010
learning in the last few years are based

00:00:09,120 --> 00:00:14,700
on deep learning which is definitely

00:00:11,010 --> 00:00:16,680
inspired by brains it's in fact a

00:00:14,700 --> 00:00:19,920
rebranding of an old idea called neural

00:00:16,680 --> 00:00:22,199
networks from the 1970s which is what

00:00:19,920 --> 00:00:25,590
got me in excited about getting to the

00:00:22,199 --> 00:00:28,109
field in the mid-1980s so what are

00:00:25,590 --> 00:00:31,500
neural networks well neural networks are

00:00:28,109 --> 00:00:32,880
basically tunable of nonlinear functions

00:00:31,500 --> 00:00:36,090
with many parameters if you're a

00:00:32,880 --> 00:00:39,390
statistician the map from some inputs to

00:00:36,090 --> 00:00:40,620
some outputs with layers of neurons it's

00:00:39,390 --> 00:00:43,050
called deep learning because you have

00:00:40,620 --> 00:00:44,940
many different layers so there's is

00:00:43,050 --> 00:00:48,480
nothing deep about that it's just many

00:00:44,940 --> 00:00:50,550
layers the weights connecting the

00:00:48,480 --> 00:00:53,340
neurons are tunable and they're tuned to

00:00:50,550 --> 00:00:55,530
reduce errors on the training data now

00:00:53,340 --> 00:00:57,210
they're amazing and much of the

00:00:55,530 --> 00:00:59,370
revolution has happened because of deep

00:00:57,210 --> 00:01:00,930
learning but again anybody who's in the

00:00:59,370 --> 00:01:02,969
field understands that there are

00:01:00,930 --> 00:01:05,640
limitations of deep learning they're

00:01:02,969 --> 00:01:07,409
very data hungry compute-intensive

00:01:05,640 --> 00:01:09,659
poor at representing uncertainty which

00:01:07,409 --> 00:01:12,030
really bothers me actually there

00:01:09,659 --> 00:01:13,979
uninterpretable black boxes lacking in

00:01:12,030 --> 00:01:16,470
transparency difficult to trust and

00:01:13,979 --> 00:01:18,689
easily fooled by adversarial examples

00:01:16,470 --> 00:01:20,250
like this one famously where the neural

00:01:18,689 --> 00:01:22,380
net is pretty good at telling a school

00:01:20,250 --> 00:01:24,960
bus from a dog but then you add a little

00:01:22,380 --> 00:01:27,240
bit of pixel noise in a very particular

00:01:24,960 --> 00:01:31,520
way and it confidently gets it wrong it

00:01:27,240 --> 00:01:34,670
classifies both those images as ostrich

00:01:31,520 --> 00:01:40,170
that's a problem we can't base our

00:01:34,670 --> 00:01:41,820
technology on just that so we really

00:01:40,170 --> 00:01:44,130
need machine learning systems that know

00:01:41,820 --> 00:01:45,780
and they don't know and one way of

00:01:44,130 --> 00:01:47,340
achieving that and this is an area that

00:01:45,780 --> 00:01:49,649
I've worked on a long time is

00:01:47,340 --> 00:01:51,600
probabilistic machine learning it helps

00:01:49,649 --> 00:01:53,159
us better understand the concept of

00:01:51,600 --> 00:01:56,219
learning and overcome some of the

00:01:53,159 --> 00:01:57,990
limitations so probablistic machine

00:01:56,219 --> 00:02:00,570
learning goes back to the mathematics of

00:01:57,990 --> 00:02:04,079
Reverend Thomas Bayes an 18th century

00:02:00,570 --> 00:02:05,700
English nonconformist minister and he

00:02:04,079 --> 00:02:07,290
came up with Bayes rule which was

00:02:05,700 --> 00:02:09,300
written like this it's kind of boring to

00:02:07,290 --> 00:02:11,900
look at like this but I'm gonna rewrite

00:02:09,300 --> 00:02:13,890
it like this so that you can kind of

00:02:11,900 --> 00:02:16,230
think about it more easily

00:02:13,890 --> 00:02:18,030
so Bayes rule tells us how to update our

00:02:16,230 --> 00:02:20,010
beliefs about hypotheses in light of

00:02:18,030 --> 00:02:21,840
data and it tells us that the

00:02:20,010 --> 00:02:23,490
probability of a particular hypothesis

00:02:21,840 --> 00:02:25,980
given the data is the prior probability

00:02:23,490 --> 00:02:28,680
of the hypothesis before observing the

00:02:25,980 --> 00:02:32,640
data multiplied by the probability that

00:02:28,680 --> 00:02:34,680
that hypothesis gives to the data and

00:02:32,640 --> 00:02:36,710
then it's renormalized summing over all

00:02:34,680 --> 00:02:40,320
the hypotheses were willing to consider

00:02:36,710 --> 00:02:42,330
now Bayes rule is also the basis of

00:02:40,320 --> 00:02:44,760
understanding learning so the process of

00:02:42,330 --> 00:02:46,530
going from your prior knowledge before

00:02:44,760 --> 00:02:48,480
observing the data to your posterior

00:02:46,530 --> 00:02:51,570
knowledge after observing data is

00:02:48,480 --> 00:02:56,280
exactly learning and what you gain from

00:02:51,570 --> 00:02:58,650
that is information now just to be clear

00:02:56,280 --> 00:03:01,530
when I use the terms hypotheses and data

00:02:58,650 --> 00:03:03,420
it's incredibly general hypothesis is

00:03:01,530 --> 00:03:04,920
anything that you're uncertain about

00:03:03,420 --> 00:03:08,040
anything you don't know

00:03:04,920 --> 00:03:10,230
data is anything that's measured any

00:03:08,040 --> 00:03:12,390
measured quantity or any sense quantity

00:03:10,230 --> 00:03:14,790
and then when I'm talking about

00:03:12,390 --> 00:03:18,360
probabilities probabilities are meant to

00:03:14,790 --> 00:03:20,190
encode beliefs of the system so it's so

00:03:18,360 --> 00:03:21,360
powerful that you know you can write

00:03:20,190 --> 00:03:22,860
down the foundations of all

00:03:21,360 --> 00:03:25,019
probabilistic machine learning on one

00:03:22,860 --> 00:03:26,790
slide which looks like this and it

00:03:25,019 --> 00:03:29,400
starts from two simple rules including

00:03:26,790 --> 00:03:31,380
Bayes rule so how does it work well if

00:03:29,400 --> 00:03:33,810
you take the optimization view of

00:03:31,380 --> 00:03:35,580
machine learning you have you know say

00:03:33,810 --> 00:03:38,220
the red and the blue data set and you

00:03:35,580 --> 00:03:39,330
won't want to classify them in

00:03:38,220 --> 00:03:41,340
traditional machine learning you

00:03:39,330 --> 00:03:43,170
optimize a classifier that separates the

00:03:41,340 --> 00:03:45,239
red and the blue shown on the left in

00:03:43,170 --> 00:03:46,709
Bayesian machine learning you simply you

00:03:45,239 --> 00:03:50,220
know you're forced by the rules to

00:03:46,709 --> 00:03:53,130
consider all possible classifiers

00:03:50,220 --> 00:03:54,989
consistent with the data so that whole

00:03:53,130 --> 00:03:56,940
cloud of possible classifiers and when

00:03:54,989 --> 00:03:58,440
you average over that which what is what

00:03:56,940 --> 00:04:00,660
problems like machine learning tells you

00:03:58,440 --> 00:04:02,820
what to do you get better uncertainty

00:04:00,660 --> 00:04:04,290
estimates so there's no magic you're

00:04:02,820 --> 00:04:07,410
just accounting for your uncertainty you

00:04:04,290 --> 00:04:09,840
get better uncertainty estimates and in

00:04:07,410 --> 00:04:12,180
fact this has become a very hot topic in

00:04:09,840 --> 00:04:13,709
machine learning you can marry the ideas

00:04:12,180 --> 00:04:15,750
of Bayesian methods with deep learning

00:04:13,709 --> 00:04:17,729
to get Bayesian deep learning we had a

00:04:15,750 --> 00:04:19,890
couple of very successful workshops at

00:04:17,729 --> 00:04:22,130
nips in the last couple of years on this

00:04:19,890 --> 00:04:22,130
topic

00:04:28,180 --> 00:04:30,240

YouTube URL: https://www.youtube.com/watch?v=1I0mxYo-5KY


