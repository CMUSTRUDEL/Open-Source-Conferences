Title: Cognitive biases in the architect's life, Birgitta Boeckeler (ThoughtWorks)
Publication date: 2019-11-07
Playlist: O'Reilly Software Architecture Conference 2019 - Berlin, DE
Description: 
	At the time of writing this, Wikipedia’s “Cognitive bias codex” has more than 200 entries, and it feels to me like Daniel Kahneman’s “Thinking Fast and Slow” is referenced in every other conference talk I’m watching. It’s official: Human beings are just not the rational thinkers we like to think we are.
In this talk, I will go through just a few of the cognitive biases that can trip us up as architects, and how to soften their potentially negative impact.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,999 --> 00:00:04,690
because architecture is the important

00:00:02,889 --> 00:00:06,879
stuff that's often hard to change and

00:00:04,690 --> 00:00:08,500
while we maybe don't have to be so

00:00:06,879 --> 00:00:09,850
vigilant about cognitive biases and

00:00:08,500 --> 00:00:11,830
every little thing that we do every day

00:00:09,850 --> 00:00:14,230
whenever we're making a big decision

00:00:11,830 --> 00:00:16,150
that is potentially hard to change then

00:00:14,230 --> 00:00:18,220
we especially want to take a step back

00:00:16,150 --> 00:00:21,189
and be aware of what might be going on

00:00:18,220 --> 00:00:23,289
and if we constantly assume that we're

00:00:21,189 --> 00:00:24,579
being totally rational then that can

00:00:23,289 --> 00:00:28,300
prevent us from learning from our

00:00:24,579 --> 00:00:30,789
decisions outcome bias is our tendency

00:00:28,300 --> 00:00:33,460
to evaluate the quality of a decision

00:00:30,789 --> 00:00:36,070
based on the outcome of that decision so

00:00:33,460 --> 00:00:36,730
what does that mean or what why is that

00:00:36,070 --> 00:00:38,920
a problem

00:00:36,730 --> 00:00:40,870
so three four years ago I was on a team

00:00:38,920 --> 00:00:43,350
that was using react for the first time

00:00:40,870 --> 00:00:45,550
and we were looking for a framework to

00:00:43,350 --> 00:00:46,660
implement the Flex pattern with react

00:00:45,550 --> 00:00:48,100
and for those of you in front-end

00:00:46,660 --> 00:00:50,950
development you might be aware that

00:00:48,100 --> 00:00:53,050
these days Redux is basically the de

00:00:50,950 --> 00:00:54,580
facto standard to do that but at this at

00:00:53,050 --> 00:00:57,250
the time there was another alternative

00:00:54,580 --> 00:00:58,750
called reflux Jas it's a very

00:00:57,250 --> 00:01:00,820
unfortunate name maybe that should have

00:00:58,750 --> 00:01:02,740
been assigned for us so we were

00:01:00,820 --> 00:01:04,180
evaluating those two things and we were

00:01:02,740 --> 00:01:06,460
trying them both out and we actually

00:01:04,180 --> 00:01:08,710
liked reflux better so we started using

00:01:06,460 --> 00:01:11,530
that in the meantime reflux is hardly

00:01:08,710 --> 00:01:14,230
maintained anymore and you could come in

00:01:11,530 --> 00:01:16,420
and say that was a bad outcome right

00:01:14,230 --> 00:01:17,860
because now we're using a framework at

00:01:16,420 --> 00:01:20,290
the core of how we're building our

00:01:17,860 --> 00:01:22,390
front-end on that team but it's actually

00:01:20,290 --> 00:01:24,640
not being that maintained anymore this

00:01:22,390 --> 00:01:27,640
less community around it than redux and

00:01:24,640 --> 00:01:29,320
so on so this bad outcome but can you

00:01:27,640 --> 00:01:31,210
really tell anything about the quality

00:01:29,320 --> 00:01:34,090
of the decision based on that we often

00:01:31,210 --> 00:01:35,890
say it was a bad decision but maybe we

00:01:34,090 --> 00:01:38,250
should differentiate between outcome and

00:01:35,890 --> 00:01:42,130
decision and that's very hard for us

00:01:38,250 --> 00:01:44,560
another example whenever we decide to

00:01:42,130 --> 00:01:46,270
use the technology because we just out

00:01:44,560 --> 00:01:47,740
of a gut feeling because we heard a

00:01:46,270 --> 00:01:50,470
speaker at the conference talked about

00:01:47,740 --> 00:01:52,180
it or our sister-in-law's cousin works

00:01:50,470 --> 00:01:54,250
at Netflix and they use it or something

00:01:52,180 --> 00:01:55,630
and we use that technology and it's

00:01:54,250 --> 00:01:58,510
actually working out really well for us

00:01:55,630 --> 00:02:01,000
sorry IKEA great decision but was it

00:01:58,510 --> 00:02:03,150
it's a great outcome but was it a good

00:02:01,000 --> 00:02:03,150

YouTube URL: https://www.youtube.com/watch?v=5BvGQ7XTCuQ


