Title: Modern machine learning architectures, Brian Sletten (Bosatsu Consulting)
Publication date: 2019-11-06
Playlist: O'Reilly Software Architecture Conference 2019 - Berlin, DE
Description: 
	Modern machine learning architectures: Data and hardware and platform, oh my

The move toward adopting machine learning in modern systems is not quite the same as simply deploying a new feature or framework. It requires disciplined thinking about where to place your data, where to place your analysis, where to place your models, and more. The choice of language and implementation increasingly have implications on the properties of your runtime system. Many of the most interesting trends in architecture these days fundamentally come down to finding cost-effective ways of doing what you need to do computationally. Machine learning systems are no different and will benefit from these developments as well.
Brian Sletten takes a deep dive into the intersection of data, models, hardware, language, and architecture as it relates to machine learning systems in particular, but the overall industry in general.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,200 --> 00:00:05,240
so in a recent study by IDC they saved

00:00:03,500 --> 00:00:07,520
that by the year twenty five or twenty

00:00:05,240 --> 00:00:09,500
twenty five which is only six years away

00:00:07,520 --> 00:00:11,780
less than six years away we're going to

00:00:09,500 --> 00:00:14,450
expect that the storage industry will

00:00:11,780 --> 00:00:17,000
ship an additional forty to zettabytes

00:00:14,450 --> 00:00:19,279
of capacity and if you're not familiar

00:00:17,000 --> 00:00:21,920
with how big is zettabyte is that's a

00:00:19,279 --> 00:00:25,970
trillion gigabytes so we're going to be

00:00:21,920 --> 00:00:28,850
adding 42 trillion gigabytes in capacity

00:00:25,970 --> 00:00:30,980
we're gonna see IOT devices generating

00:00:28,850 --> 00:00:33,800
things at a rate of about ninety

00:00:30,980 --> 00:00:35,420
zettabytes we're expecting about half of

00:00:33,800 --> 00:00:37,399
the data that's going to be produced

00:00:35,420 --> 00:00:39,639
will be stored on the cloud for the

00:00:37,399 --> 00:00:42,019
reasons that we all know and like and

00:00:39,639 --> 00:00:43,729
that roughly thirty percent of the data

00:00:42,019 --> 00:00:45,829
is gonna have to be handled in real time

00:00:43,729 --> 00:00:47,899
right because we're not going to be

00:00:45,829 --> 00:00:50,289
storing absolutely everything we're

00:00:47,899 --> 00:00:53,209
going to capture things that happen

00:00:50,289 --> 00:00:56,149
interact with them reason over them make

00:00:53,209 --> 00:00:59,359
choices from it but that's going to

00:00:56,149 --> 00:01:02,359
translate into a shift from about thirty

00:00:59,359 --> 00:01:03,469
three zettabytes in existence now to

00:01:02,359 --> 00:01:07,539
about a hundred and seventy-five

00:01:03,469 --> 00:01:09,799
zettabytes by 2025 that's an

00:01:07,539 --> 00:01:12,350
accommodative about sixty one percent

00:01:09,799 --> 00:01:14,450
which is insane and it's going to come

00:01:12,350 --> 00:01:15,289
in these three basic tiers right there's

00:01:14,450 --> 00:01:17,840
the backend

00:01:15,289 --> 00:01:19,880
the cloud-based systems where we push a

00:01:17,840 --> 00:01:21,679
lot of the data up spend some time

00:01:19,880 --> 00:01:24,439
training in the cloud and chunking on

00:01:21,679 --> 00:01:26,509
the data that's there there's also the

00:01:24,439 --> 00:01:28,850
front tier the mobile tier the

00:01:26,509 --> 00:01:30,829
internet-of-things tier where we have

00:01:28,850 --> 00:01:32,509
the data being generated we've got

00:01:30,829 --> 00:01:34,729
sensors that are producing data we've

00:01:32,509 --> 00:01:37,640
got cameras and microphones on our on

00:01:34,729 --> 00:01:39,950
our phones that are being used as

00:01:37,640 --> 00:01:42,649
sources to treat people for medical

00:01:39,950 --> 00:01:44,270
analysis and and whatnot to determine we

00:01:42,649 --> 00:01:46,399
know if there's been evidence of some

00:01:44,270 --> 00:01:48,710
kind of neurological damage in

00:01:46,399 --> 00:01:51,350
somebody's you know facial expressions

00:01:48,710 --> 00:01:52,969
and whatnot and there's sensitivities

00:01:51,350 --> 00:01:55,280
around that like we can't just take that

00:01:52,969 --> 00:01:57,049
data off of a phone and shove it up into

00:01:55,280 --> 00:01:59,359
the cloud without thinking about

00:01:57,049 --> 00:02:01,909
regulation and those sorts of things so

00:01:59,359 --> 00:02:04,399
we're actually imagining this multi tier

00:02:01,909 --> 00:02:06,259
heterogeneous highly paralyzed

00:02:04,399 --> 00:02:08,690
architecture that we're going to have to

00:02:06,259 --> 00:02:10,250
deploy into and we get back to the kinds

00:02:08,690 --> 00:02:12,440
of problems that we were facing at Parab

00:02:10,250 --> 00:02:13,890
on with respect to like the compute and

00:02:12,440 --> 00:02:16,010
data ratios

00:02:13,890 --> 00:02:19,200
it doesn't make sense to be pushing

00:02:16,010 --> 00:02:21,150
zettabytes of data around from the front

00:02:19,200 --> 00:02:23,100
to the back but we also don't

00:02:21,150 --> 00:02:25,260
necessarily want to push our big models

00:02:23,100 --> 00:02:29,850
all the way into small small profile

00:02:25,260 --> 00:02:31,500
devices like phones and whatnot so we

00:02:29,850 --> 00:02:34,020
have to start to think about the models

00:02:31,500 --> 00:02:35,760
how big they are how can we reduce the

00:02:34,020 --> 00:02:38,730
size and that's where things like

00:02:35,760 --> 00:02:40,680
quantization of the models and tooling

00:02:38,730 --> 00:02:42,000
around optimizations to target the

00:02:40,680 --> 00:02:43,459
actual hardware that's going to run on

00:02:42,000 --> 00:02:46,440
are going to become increasingly

00:02:43,459 --> 00:02:48,480
interesting and useful and so this world

00:02:46,440 --> 00:02:49,830
of hey let's do some training let's

00:02:48,480 --> 00:02:54,150
build a model and let's roll it into

00:02:49,830 --> 00:02:55,590
production it's kind of an older view of

00:02:54,150 --> 00:02:57,840
what it means to take machine learning

00:02:55,590 --> 00:02:59,790
into production because we have to deal

00:02:57,840 --> 00:03:02,420
with all of these situations and all

00:02:59,790 --> 00:03:02,420

YouTube URL: https://www.youtube.com/watch?v=bG79ow2Cnr8


