Title: Privacy in the Age of Machine Learning - Ben Lorica (O'Reilly Media)
Publication date: 2018-03-08
Playlist: Strata Data Conference 2018 - San Jose, California
Description: 
	Ben Lorica explores emerging security best practices for business intelligence, machine learning, and mobile computing products.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,060 --> 00:00:05,370
so a lot of this conference is about

00:00:02,490 --> 00:00:08,700
data pipelines data platforms and data

00:00:05,370 --> 00:00:10,800
infrastructure and those are those are

00:00:08,700 --> 00:00:14,370
still probably the bulk of what we as a

00:00:10,800 --> 00:00:17,910
community do but once we have data in

00:00:14,370 --> 00:00:20,310
place we normally do to two things with

00:00:17,910 --> 00:00:23,400
data right so the first is improve our

00:00:20,310 --> 00:00:25,920
decision-making using bi the second is

00:00:23,400 --> 00:00:27,869
to enable some form of automation using

00:00:25,920 --> 00:00:30,420
machine learning so we've long known

00:00:27,869 --> 00:00:32,940
that it's important to secure our data

00:00:30,420 --> 00:00:36,360
platforms in infrastructure but what

00:00:32,940 --> 00:00:38,520
about our analytics are there ways of

00:00:36,360 --> 00:00:42,450
doing analytics that still protect

00:00:38,520 --> 00:00:44,700
privacy it turns out there now some some

00:00:42,450 --> 00:00:48,480
simple techniques that one can use so

00:00:44,700 --> 00:00:51,930
I'll go over a few of them today so

00:00:48,480 --> 00:00:54,930
first let's look at bi so for many

00:00:51,930 --> 00:00:58,559
companies bi is really a sequel database

00:00:54,930 --> 00:01:00,559
and so you can actually do secure

00:00:58,559 --> 00:01:02,969
computation and a sequel database

00:01:00,559 --> 00:01:07,310
companies use things like Hardware

00:01:02,969 --> 00:01:09,930
enclaves or encryption but what about

00:01:07,310 --> 00:01:12,689
fact but what about techniques that

00:01:09,930 --> 00:01:15,540
preserve privacy so I want to highlight

00:01:12,689 --> 00:01:19,799
a recent collaboration between uber and

00:01:15,540 --> 00:01:22,530
UC Berkeley's rice lab so the nice thing

00:01:19,799 --> 00:01:24,540
about their system is it allows data

00:01:22,530 --> 00:01:26,400
analysts to continue to do what they

00:01:24,540 --> 00:01:29,369
normally do which is to write reports

00:01:26,400 --> 00:01:31,920
using sequel and they can write these

00:01:29,369 --> 00:01:33,930
reports and this and the results of this

00:01:31,920 --> 00:01:35,610
reports will protect users privacy so

00:01:33,930 --> 00:01:39,420
you give them access control but you

00:01:35,610 --> 00:01:42,060
don't you don't risk privacy this this

00:01:39,420 --> 00:01:44,399
system is in pilot stage at uber it's

00:01:42,060 --> 00:01:46,140
available at github and the great thing

00:01:44,399 --> 00:01:48,799
about it is you can use it with any

00:01:46,140 --> 00:01:51,780
sequel database so you can't do bi

00:01:48,799 --> 00:01:56,909
privacy preserving preserving bi right

00:01:51,780 --> 00:02:02,040
now but can differential privacy for bi

00:01:56,909 --> 00:02:04,140
scale in an age of IOT the answer is yes

00:02:02,040 --> 00:02:07,200
because we have two concrete examples

00:02:04,140 --> 00:02:10,140
from Apple and Google so they use

00:02:07,200 --> 00:02:12,360
differential privacy for their bi as far

00:02:10,140 --> 00:02:13,800
as studying how users interact with

00:02:12,360 --> 00:02:16,100
their devices

00:02:13,800 --> 00:02:19,440
so for example they they use

00:02:16,100 --> 00:02:21,600
differential privacy for bi on things

00:02:19,440 --> 00:02:25,800
like browsing statistics and typing

00:02:21,600 --> 00:02:27,840
behavior so bi that's privacy per

00:02:25,800 --> 00:02:29,990
serving is available and you can do it

00:02:27,840 --> 00:02:29,990
today

00:02:30,110 --> 00:02:36,030
what about machine learning so I'm gonna

00:02:34,530 --> 00:02:38,430
focus on deep learning because it's a

00:02:36,030 --> 00:02:41,190
hot method but a lot of what I'm going

00:02:38,430 --> 00:02:43,800
to describe applies to other machine

00:02:41,190 --> 00:02:46,220
learning methods so deep learning

00:02:43,800 --> 00:02:49,380
because you can train it asynchronously

00:02:46,220 --> 00:02:51,990
lends itself to shared learning so by

00:02:49,380 --> 00:02:54,870
shared learning I mean imagine a

00:02:51,990 --> 00:02:58,020
scenario where you have a few companies

00:02:54,870 --> 00:03:00,210
who want a to learn a shared model an

00:02:58,020 --> 00:03:02,400
accurate model more accurate than they

00:03:00,210 --> 00:03:04,410
would normally be able to learn just

00:03:02,400 --> 00:03:06,780
using their own data but they don't want

00:03:04,410 --> 00:03:09,210
to share data across organizations it

00:03:06,780 --> 00:03:10,620
turns out that you can do that with deep

00:03:09,210 --> 00:03:13,190
learning because of the asynchronous

00:03:10,620 --> 00:03:13,190
training

00:03:18,920 --> 00:03:20,980

YouTube URL: https://www.youtube.com/watch?v=vZVBSGICm4Y


