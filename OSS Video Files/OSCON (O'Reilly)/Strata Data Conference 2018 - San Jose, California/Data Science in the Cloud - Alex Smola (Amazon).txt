Title: Data Science in the Cloud - Alex Smola (Amazon)
Publication date: 2018-03-08
Playlist: Strata Data Conference 2018 - San Jose, California
Description: 
	Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:00,030 --> 00:00:05,040
so one thing is for instance well let's

00:00:02,820 --> 00:00:06,540
take a linear learner well that's you

00:00:05,040 --> 00:00:08,099
know the basic thing par for the course

00:00:06,540 --> 00:00:10,290
you always need to have that like a

00:00:08,099 --> 00:00:13,530
logistic regression or regression model

00:00:10,290 --> 00:00:16,830
or linear classifier right so what you

00:00:13,530 --> 00:00:20,789
can then do is you can for instance

00:00:16,830 --> 00:00:22,560
train multiple hyper parameters multiple

00:00:20,789 --> 00:00:24,900
loss functions and organization and all

00:00:22,560 --> 00:00:27,090
of that at the same time by streaming

00:00:24,900 --> 00:00:28,710
things through and in the end what you

00:00:27,090 --> 00:00:30,660
can do all your model selection and so

00:00:28,710 --> 00:00:35,460
on and this automatically fits and

00:00:30,660 --> 00:00:38,969
models the right problem so and compared

00:00:35,460 --> 00:00:42,149
to well the best alternative which is

00:00:38,969 --> 00:00:44,850
the yellow and the orange curve our

00:00:42,149 --> 00:00:47,160
curves are on the blue and the gray one

00:00:44,850 --> 00:00:49,230
this is just for different data sets so

00:00:47,160 --> 00:00:51,239
these these are apples to apples

00:00:49,230 --> 00:00:54,510
comparisons and what you can basically

00:00:51,239 --> 00:00:57,210
see is that depending on how much time

00:00:54,510 --> 00:00:58,980
you're willing to invest and how much

00:00:57,210 --> 00:01:01,440
money you're willing to spend we're

00:00:58,980 --> 00:01:05,580
quite a bit cheaper and we're quite a

00:01:01,440 --> 00:01:07,890
bit faster now okay linear learners and

00:01:05,580 --> 00:01:09,570
well the numbers on the Left simply show

00:01:07,890 --> 00:01:14,070
you that yeah it works the same right

00:01:09,570 --> 00:01:16,140
now for factorization machines again

00:01:14,070 --> 00:01:17,790
remember the plot that I told you before

00:01:16,140 --> 00:01:20,340
we want to be in the ideal situation

00:01:17,790 --> 00:01:22,350
where that Green Dot is is level right

00:01:20,340 --> 00:01:25,229
this is exactly what's happening there

00:01:22,350 --> 00:01:27,030
it's basically you know over a number of

00:01:25,229 --> 00:01:30,680
machines and therefore billable time in

00:01:27,030 --> 00:01:33,270
hours as you get you know fewer machines

00:01:30,680 --> 00:01:35,100
as you get as you throw more machines at

00:01:33,270 --> 00:01:37,890
it the cost doesn't really go up but of

00:01:35,100 --> 00:01:39,600
course it goes faster so this is in a

00:01:37,890 --> 00:01:43,320
way the ideal scenario that you want to

00:01:39,600 --> 00:01:44,939
have now of course you can also do

00:01:43,320 --> 00:01:47,220
unsupervised learning like k-means

00:01:44,939 --> 00:01:48,810
clustering okay again the question why

00:01:47,220 --> 00:01:51,090
would you bother with k-means yeah

00:01:48,810 --> 00:01:52,829
because everybody needs it and came in

00:01:51,090 --> 00:01:55,229
sounds easy right I mean that's been

00:01:52,829 --> 00:01:57,930
around for like 20 years but making sure

00:01:55,229 --> 00:02:00,000
that it always works reliably that it

00:01:57,930 --> 00:02:01,469
never breaks right this is the

00:02:00,000 --> 00:02:05,880
difference between writing and nips

00:02:01,469 --> 00:02:07,950
paper and actually deploying this and so

00:02:05,880 --> 00:02:09,869
what we do is we build something that is

00:02:07,950 --> 00:02:12,209
accurate in terms of the objective

00:02:09,869 --> 00:02:13,540
function requires a single pass and can

00:02:12,209 --> 00:02:15,740
be efficiently tuned

00:02:13,540 --> 00:02:18,590
and so we compared to a lot of other

00:02:15,740 --> 00:02:21,800
things that don't quite do this and if

00:02:18,590 --> 00:02:26,000
you look at the throughput this is

00:02:21,800 --> 00:02:27,920
rather a lot there for not just ten

00:02:26,000 --> 00:02:31,580
clusters but also hundred and a thousand

00:02:27,920 --> 00:02:35,660
and so on and the key point is you never

00:02:31,580 --> 00:02:37,150
see this red failed note on the on the

00:02:35,660 --> 00:02:39,230
middle column where it says sage maker

00:02:37,150 --> 00:02:42,590
this is the really important thing for

00:02:39,230 --> 00:02:44,840
the practitioner they would quite often

00:02:42,590 --> 00:02:47,330
be very comfortable in paying maybe ten

00:02:44,840 --> 00:02:49,070
percent more in making sure that getting

00:02:47,330 --> 00:02:52,400
doesn't break I mean this is why we all

00:02:49,070 --> 00:02:55,400
have a car insurance right because and

00:02:52,400 --> 00:02:56,900
you know we pay money for it right but

00:02:55,400 --> 00:02:59,570
we pay money for it in order to make

00:02:56,900 --> 00:03:01,940
sure that it really always performs this

00:02:59,570 --> 00:03:04,150
is exactly what makes things hard in

00:03:01,940 --> 00:03:04,150
practice

00:03:10,190 --> 00:03:12,250

YouTube URL: https://www.youtube.com/watch?v=6ywjIdklqtE


