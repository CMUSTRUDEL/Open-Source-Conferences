Title: T-minus 3, 2, 1: Future-proofing production systems - Kavya Joshi (Samsara)
Publication date: 2017-10-20
Playlist: O'Reilly Velocity Conference 2017 - London, UK
Description: 
	Check out all the keynotes, sessions, and tutorials from Velocity:
https://www.safaribooksonline.com/library/view/velocity-conference-2017/9781491985335/

How does your system perform under load? What are the bottlenecks? How does the system fail at its limits? And, more importantly, how do you stay ahead as your system evolves and its workload grows?

Kavya Joshi shares strategies to prepare systems for flux and scale. Drawing from a range of use cases, including Facebook’s Kraken, which provides shadow traffic, and Samsara’s custom load simulator, Kavya demonstrates how to improve your understanding of your systems as they run today and plan for how they’ll run tomorrow.

Subscribe to O'Reilly on YouTube: http://goo.gl/n3QSYi

Follow O'Reilly on: 
Twitter: http://twitter.com/oreillymedia
Facebook: http://facebook.com/OReilly
Instagram: https://www.instagram.com/oreillymedia
LinkedIn: https://www.linkedin.com/company-beta/8459/
Captions: 
	00:00:03,389 --> 00:00:08,969
my name is Kavya and I'm here today to

00:00:06,509 --> 00:00:11,519
talk to you about analyzing the

00:00:08,969 --> 00:00:14,370
performance of systems now why do we

00:00:11,519 --> 00:00:16,320
care about this well ideally we want to

00:00:14,370 --> 00:00:17,940
provide a good user experience to our

00:00:16,320 --> 00:00:21,060
users so we care about things like

00:00:17,940 --> 00:00:23,100
latency or response time and it would be

00:00:21,060 --> 00:00:23,820
nice if we remained in business while

00:00:23,100 --> 00:00:25,170
doing so

00:00:23,820 --> 00:00:29,070
so we care about things like server

00:00:25,170 --> 00:00:32,009
utilization and capacity planning does

00:00:29,070 --> 00:00:34,170
that sound familiar how many of you here

00:00:32,009 --> 00:00:37,260
have spent many a night trying to answer

00:00:34,170 --> 00:00:39,630
questions like this how much additional

00:00:37,260 --> 00:00:42,120
load can this system support how many

00:00:39,630 --> 00:00:46,950
additional servers do we need are we

00:00:42,120 --> 00:00:48,750
hello over provisioned already so this

00:00:46,950 --> 00:00:51,540
is obviously a very important set of

00:00:48,750 --> 00:00:53,010
questions to answer and today we're

00:00:51,540 --> 00:00:56,610
going to talk about how we're going to

00:00:53,010 --> 00:00:59,010
go about to do this and we're going to

00:00:56,610 --> 00:01:02,219
invoke the deliciously thrilling option

00:00:59,010 --> 00:01:04,290
of using prod now this is not a new idea

00:01:02,219 --> 00:01:06,360
right we just heard a talk on chaos

00:01:04,290 --> 00:01:09,030
engineering but today we're going to

00:01:06,360 --> 00:01:12,060
apply that methodology to performance

00:01:09,030 --> 00:01:14,340
analysis the idea is you apply load to

00:01:12,060 --> 00:01:17,909
the system you gradually ramp it up

00:01:14,340 --> 00:01:20,700
until the system is stressed and you do

00:01:17,909 --> 00:01:23,250
this so you can empirically determine

00:01:20,700 --> 00:01:24,690
how your system behaves under load right

00:01:23,250 --> 00:01:26,190
you can empirically determine its

00:01:24,690 --> 00:01:29,610
performance characteristics its

00:01:26,190 --> 00:01:32,189
bottlenecks to do this we will look at

00:01:29,610 --> 00:01:34,710
two real-world systems that are built to

00:01:32,189 --> 00:01:38,250
do exactly this the first is Facebook's

00:01:34,710 --> 00:01:41,460
Kraken the second is org shim built and

00:01:38,250 --> 00:01:43,140
used at samsara where I work and once we

00:01:41,460 --> 00:01:45,330
talk about these systems let's take a

00:01:43,140 --> 00:01:48,150
step back to leave you with a parting

00:01:45,330 --> 00:01:51,990
thought okay then let's get started

00:01:48,150 --> 00:01:54,420
first up kraken so Kraken is Facebook's

00:01:51,990 --> 00:01:57,479
load simulator it was built in about

00:01:54,420 --> 00:01:59,610
2013 and they use it primarily to

00:01:57,479 --> 00:02:01,680
determine a systems capacity where the

00:01:59,610 --> 00:02:04,530
capacity is the maximum throughput

00:02:01,680 --> 00:02:06,780
requests per second a system can support

00:02:04,530 --> 00:02:09,629
given a particular response time

00:02:06,780 --> 00:02:12,300
constraint right and they use this to

00:02:09,629 --> 00:02:14,550
identify and resolve utilization

00:02:12,300 --> 00:02:16,349
bottlenecks so you have a target

00:02:14,550 --> 00:02:17,110
capacity if your system fails to meet

00:02:16,349 --> 00:02:19,120
that target

00:02:17,110 --> 00:02:22,960
today why does it do why does it fail to

00:02:19,120 --> 00:02:24,670
do so and they claim that Kraken has

00:02:22,960 --> 00:02:28,000
helped them increased Facebook's

00:02:24,670 --> 00:02:31,120
capacity by over 20 percent using the

00:02:28,000 --> 00:02:34,270
same hardware now this is remarkable not

00:02:31,120 --> 00:02:37,390
just as an engineering feat but also man

00:02:34,270 --> 00:02:40,000
that's a hell of a lot of money saved so

00:02:37,390 --> 00:02:43,630
let's look at how Kraken works first

00:02:40,000 --> 00:02:46,300
things first the model of system Kraken

00:02:43,630 --> 00:02:48,780
is designed for write so Kraken assumes

00:02:46,300 --> 00:02:52,600
stateless servers so no WebSockets

00:02:48,780 --> 00:02:54,730
no server affinity they also assume that

00:02:52,600 --> 00:02:58,000
load can be controlled by rerouting

00:02:54,730 --> 00:02:59,200
requests to the system under test and

00:02:58,000 --> 00:03:02,410
you'll see in a second why these

00:02:59,200 --> 00:03:05,500
assumptions are necessary they also

00:03:02,410 --> 00:03:08,170
assume the downstream services respond

00:03:05,500 --> 00:03:10,360
to upstream service load shifts so for

00:03:08,170 --> 00:03:12,940
example if you have a web server wearing

00:03:10,360 --> 00:03:14,230
a database and the database hits a

00:03:12,940 --> 00:03:16,240
bottleneck some sort of resource

00:03:14,230 --> 00:03:18,340
saturation you expect that to be

00:03:16,240 --> 00:03:20,740
reflected in the web server you expect

00:03:18,340 --> 00:03:23,230
to see its throughput drop now this is a

00:03:20,740 --> 00:03:25,360
pretty reasonable assumption and this is

00:03:23,230 --> 00:03:28,269
necessary so you can identify those

00:03:25,360 --> 00:03:30,250
bottlenecks right okay so that's the

00:03:28,269 --> 00:03:33,190
model now let's look at how it actually

00:03:30,250 --> 00:03:35,380
works so there are two pieces to crackin

00:03:33,190 --> 00:03:38,019
the first is the load generation aspect

00:03:35,380 --> 00:03:40,390
and the idea here is what's the best

00:03:38,019 --> 00:03:43,000
representation of live traffic live

00:03:40,390 --> 00:03:45,400
traffic so they use live traffic and

00:03:43,000 --> 00:03:46,989
they do this by employing traffic

00:03:45,400 --> 00:03:49,120
shifting which is a familiar technique

00:03:46,989 --> 00:03:51,700
you adjust the weights of your load

00:03:49,120 --> 00:03:52,800
balancers to reroute traffic to the

00:03:51,700 --> 00:03:55,900
system on the test

00:03:52,800 --> 00:03:57,970
this second piece of kraken is the

00:03:55,900 --> 00:04:00,070
monitoring right you need reliable

00:03:57,970 --> 00:04:02,230
metrics to tell you and to track the

00:04:00,070 --> 00:04:03,850
health of the system so you know when

00:04:02,230 --> 00:04:05,800
it's approaching its limits those are

00:04:03,850 --> 00:04:07,840
the numbers you care about and you also

00:04:05,800 --> 00:04:10,350
know when to back off you don't want to

00:04:07,840 --> 00:04:13,299
cause a production outage while testing

00:04:10,350 --> 00:04:16,150
so Kraken employs these two pieces in a

00:04:13,299 --> 00:04:17,890
feedback loop so let's say we have the

00:04:16,150 --> 00:04:20,560
system and now we run it against a

00:04:17,890 --> 00:04:25,600
cluster and we get a graph that looks

00:04:20,560 --> 00:04:28,840
like this is this graph useful well sure

00:04:25,600 --> 00:04:30,340
it tells us the capacity the max

00:04:28,840 --> 00:04:32,230
throughput the system

00:04:30,340 --> 00:04:35,530
and support right it's simply the

00:04:32,230 --> 00:04:40,210
throughput right below that response

00:04:35,530 --> 00:04:43,960
time threshold we've set ourselves that

00:04:40,210 --> 00:04:47,680
number we get is it good or is there a

00:04:43,960 --> 00:04:51,040
bottleneck well I don't know we have no

00:04:47,680 --> 00:04:53,949
means to evaluate the system we don't

00:04:51,040 --> 00:04:55,810
have any expectations or any targets for

00:04:53,949 --> 00:04:58,530
what we expect from the system for how

00:04:55,810 --> 00:05:01,060
we expect to see the system behave and

00:04:58,530 --> 00:05:03,970
unlike in your relationship no

00:05:01,060 --> 00:05:06,479
expectations and performance analysis is

00:05:03,970 --> 00:05:06,479

YouTube URL: https://www.youtube.com/watch?v=28_x6BQVd6I


