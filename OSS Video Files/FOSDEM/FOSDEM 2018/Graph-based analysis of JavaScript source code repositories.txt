Title: Graph-based analysis of JavaScript source code repositories
Publication date: 2018-02-04
Playlist: FOSDEM 2018
Description: 
	by Gabor Szarnyas

At: FOSDEM 2018
Room: H.2214
Scheduled start: 2018-02-03 16:30:00+01
Captions: 
	00:01:11,790 --> 00:01:16,420
okay so welcome everyone and thanks for

00:01:14,380 --> 00:01:18,700
the kind introduction Michael my name is

00:01:16,420 --> 00:01:21,670
Gabbar Suresh and I'm a final year PhD

00:01:18,700 --> 00:01:24,040
student from Budapest Hungary and in

00:01:21,670 --> 00:01:28,090
this short talk I will talk about how to

00:01:24,040 --> 00:01:31,600
make better software with graphs so as

00:01:28,090 --> 00:01:34,180
Michael said javascript has some sort of

00:01:31,600 --> 00:01:36,070
bad name to it but it's difficult to

00:01:34,180 --> 00:01:38,470
dispute that it's very popular so if you

00:01:36,070 --> 00:01:41,320
go on Stack Overflow is consistently

00:01:38,470 --> 00:01:43,690
ranked among the top languages with

00:01:41,320 --> 00:01:47,560
respect to the number of questions asked

00:01:43,690 --> 00:01:49,720
and it's getting standardized so there

00:01:47,560 --> 00:01:51,790
is a standards body that releases a new

00:01:49,720 --> 00:01:55,930
version of the standard each year called

00:01:51,790 --> 00:01:58,479
ECMAScript and essentially things are

00:01:55,930 --> 00:01:59,979
getting better for the JavaScript

00:01:58,479 --> 00:02:01,720
community is getting a better language

00:01:59,979 --> 00:02:04,090
I'm not going to say that it's the best

00:02:01,720 --> 00:02:06,009
language or it's like the top most

00:02:04,090 --> 00:02:09,640
popular language but it's widely used

00:02:06,009 --> 00:02:11,740
from IOT devices to the browser so it's

00:02:09,640 --> 00:02:13,930
important that we make good JavaScript

00:02:11,740 --> 00:02:15,910
code and one of the techniques to

00:02:13,930 --> 00:02:18,580
guarantee good source code is called

00:02:15,910 --> 00:02:21,190
static analysis the full name is static

00:02:18,580 --> 00:02:23,890
source code analysis which means that we

00:02:21,190 --> 00:02:27,090
test software without compiling and

00:02:23,890 --> 00:02:30,340
executing it so we take the source code

00:02:27,090 --> 00:02:34,810
do some analytics on the source code

00:02:30,340 --> 00:02:37,269
itself and then try to check rules and

00:02:34,810 --> 00:02:40,060
check violations of these rules on the

00:02:37,269 --> 00:02:42,570
source code this is a complimentary

00:02:40,060 --> 00:02:45,480
thing to the traditional testing so

00:02:42,570 --> 00:02:48,720
basically in most continuous integration

00:02:45,480 --> 00:02:52,420
systems nowadays you have your

00:02:48,720 --> 00:02:54,850
development environment you push code to

00:02:52,420 --> 00:02:57,760
the source code repository it then gets

00:02:54,850 --> 00:02:59,350
compiled by the CI server and it gets

00:02:57,760 --> 00:03:03,280
tested by unit tests and integration

00:02:59,350 --> 00:03:05,590
tests and static analysis is sort of

00:03:03,280 --> 00:03:07,720
complimentary to all that it's a

00:03:05,590 --> 00:03:10,540
different step because it just reads the

00:03:07,720 --> 00:03:12,790
source code does some analytics and then

00:03:10,540 --> 00:03:15,370
as a separate feedback loop it returns

00:03:12,790 --> 00:03:17,560
the results to the developer this is

00:03:15,370 --> 00:03:21,040
quite popular so I'm sure most of you

00:03:17,560 --> 00:03:23,830
have seen some of the cloud services

00:03:21,040 --> 00:03:25,810
like coda C code climate and so on

00:03:23,830 --> 00:03:27,760
but the problem with this is is that

00:03:25,810 --> 00:03:29,500
this is an offline feedback loop so you

00:03:27,760 --> 00:03:32,350
commit to your code and then you receive

00:03:29,500 --> 00:03:37,060
an email 15 minutes later that your code

00:03:32,350 --> 00:03:40,030
is violating this and that rules another

00:03:37,060 --> 00:03:44,080
approach is to use command line tools

00:03:40,030 --> 00:03:46,030
and ID integrated tools if you have done

00:03:44,080 --> 00:03:49,210
some C programming there is an old UNIX

00:03:46,030 --> 00:03:51,280
tool called lint this is such a defining

00:03:49,210 --> 00:03:53,920
tool that actually it gave its name to

00:03:51,280 --> 00:03:56,080
the family of source code analytics

00:03:53,920 --> 00:03:57,820
tools called linters and if you're a

00:03:56,080 --> 00:04:01,060
Java developer you're probably aware of

00:03:57,820 --> 00:04:03,190
fine box or PMD and obviously there are

00:04:01,060 --> 00:04:05,800
tools for JavaScript there is es lint

00:04:03,190 --> 00:04:10,120
Facebook's flow engine the turn trail

00:04:05,800 --> 00:04:12,940
system and so on so essentially these

00:04:10,120 --> 00:04:16,299
give pretty good coverage but all of

00:04:12,940 --> 00:04:18,880
them have some drawbacks we tried to do

00:04:16,299 --> 00:04:21,040
analytics over JavaScript in the past

00:04:18,880 --> 00:04:23,710
and we found that there isn't a single

00:04:21,040 --> 00:04:26,110
system that allows users to define

00:04:23,710 --> 00:04:29,650
global rules evaluate those rules

00:04:26,110 --> 00:04:31,960
efficiently and can be extended by

00:04:29,650 --> 00:04:36,010
custom rules so these are pretty

00:04:31,960 --> 00:04:38,140
difficult satisfied advanced obviously

00:04:36,010 --> 00:04:41,280
others have thought of this problem as

00:04:38,140 --> 00:04:43,240
well so checking global rules is

00:04:41,280 --> 00:04:45,720
computationally very expensive operation

00:04:43,240 --> 00:04:48,370
in a large source code repository and

00:04:45,720 --> 00:04:51,250
this is actually so slow that it's

00:04:48,370 --> 00:04:54,190
sometimes even difficult to integrate to

00:04:51,250 --> 00:04:55,570
the CI workload so obviously there are a

00:04:54,190 --> 00:04:58,150
couple of workarounds the first

00:04:55,570 --> 00:05:00,850
workaround is just don't bother with

00:04:58,150 --> 00:05:04,419
global rules write your code in a very

00:05:00,850 --> 00:05:07,840
modular very separated way and then use

00:05:04,419 --> 00:05:11,200
file level static analysis be eslint for

00:05:07,840 --> 00:05:13,870
one does that another workaround is to

00:05:11,200 --> 00:05:17,590
do some battering on your CI analytics

00:05:13,870 --> 00:05:20,919
so you run your build and tests on each

00:05:17,590 --> 00:05:24,580
commit but you only do a single analysis

00:05:20,919 --> 00:05:26,590
a day and also you can do some custom

00:05:24,580 --> 00:05:29,440
algorithms so if you make your algorithm

00:05:26,590 --> 00:05:31,110
smart enough it is going to be fast but

00:05:29,440 --> 00:05:35,950
then it's going to be very difficult to

00:05:31,110 --> 00:05:37,200
extend with new rules so in short we

00:05:35,950 --> 00:05:39,540
made

00:05:37,200 --> 00:05:42,180
important design considerations for the

00:05:39,540 --> 00:05:46,170
product we wanted to create a static

00:05:42,180 --> 00:05:49,110
analysis - for JavaScript that allows

00:05:46,170 --> 00:05:52,560
users to define custom analysis rules be

00:05:49,110 --> 00:05:53,820
those global or local and it should

00:05:52,560 --> 00:05:56,730
provide high performance

00:05:53,820 --> 00:05:59,460
ideally close to real-time evaluation so

00:05:56,730 --> 00:06:01,500
if the user is editing the code in the

00:05:59,460 --> 00:06:03,720
development environment the user should

00:06:01,500 --> 00:06:08,040
be able to receive timely feedback on

00:06:03,720 --> 00:06:10,350
the changes that they made so one of the

00:06:08,040 --> 00:06:12,480
cornerstones of our approach is the

00:06:10,350 --> 00:06:14,640
architecture and the workflow it's all

00:06:12,480 --> 00:06:19,500
built around incrementality which means

00:06:14,640 --> 00:06:22,290
that we want to do some changes we want

00:06:19,500 --> 00:06:24,390
to do the analytics in a way that it

00:06:22,290 --> 00:06:29,250
incorporates the changes made in the

00:06:24,390 --> 00:06:31,830
code so essentially first it analyzes

00:06:29,250 --> 00:06:34,950
the source code on the whole and then

00:06:31,830 --> 00:06:37,050
for each change it uses incremental

00:06:34,950 --> 00:06:38,820
processing so if only a single file is

00:06:37,050 --> 00:06:41,310
changed in a fifteen thousand five a

00:06:38,820 --> 00:06:44,040
positive it tracks the changes to that

00:06:41,310 --> 00:06:46,140
file and second we want to use a

00:06:44,040 --> 00:06:47,520
declarative query language now if you're

00:06:46,140 --> 00:06:49,530
in the graph dev room you can probably

00:06:47,520 --> 00:06:52,260
guess which declarative graphical

00:06:49,530 --> 00:06:56,520
language that is we will get back to

00:06:52,260 --> 00:06:59,700
that in a moment so this is the high

00:06:56,520 --> 00:07:01,200
level architecture of our system it

00:06:59,700 --> 00:07:03,120
starts off with the version control

00:07:01,200 --> 00:07:06,150
system all your code is committed to the

00:07:03,120 --> 00:07:08,190
version control system it's then loaded

00:07:06,150 --> 00:07:10,430
to the workspace of the analyzer where

00:07:08,190 --> 00:07:14,040
it gets transformed to a syntax tree and

00:07:10,430 --> 00:07:16,770
it gasps transforms to a semantic graphs

00:07:14,040 --> 00:07:20,970
we then load this to the graph database

00:07:16,770 --> 00:07:22,950
and we get a set of analysis rules that

00:07:20,970 --> 00:07:26,370
we want to check and then we perform

00:07:22,950 --> 00:07:30,840
continuous checks on the server and give

00:07:26,370 --> 00:07:33,650
feedback to the client continuously so

00:07:30,840 --> 00:07:36,120
what are these steps if you have ever

00:07:33,650 --> 00:07:38,250
played around with a compiler those

00:07:36,120 --> 00:07:40,590
should be very familiar because

00:07:38,250 --> 00:07:43,410
basically this is how most of the

00:07:40,590 --> 00:07:45,450
compilers work essentially they start

00:07:43,410 --> 00:07:47,910
off with the source code which is

00:07:45,450 --> 00:07:51,030
sequence of statements for example this

00:07:47,910 --> 00:07:53,130
is a very simple source code which says

00:07:51,030 --> 00:07:56,670
we declare a variable foo which is equal

00:07:53,130 --> 00:07:58,860
to one divided by zero it uses a

00:07:56,670 --> 00:08:02,130
component called the tokenizer to split

00:07:58,860 --> 00:08:05,010
this into token into tokens tokens are

00:08:02,130 --> 00:08:08,250
the shortest meaningful character

00:08:05,010 --> 00:08:14,450
sequences in the source code so for this

00:08:08,250 --> 00:08:17,520
where foo equals 1 / 0 we get 6 tokens

00:08:14,450 --> 00:08:20,460
the tokens then go through the parser

00:08:17,520 --> 00:08:22,370
which builds the so-called syntax tree

00:08:20,460 --> 00:08:25,320
according to the grammar specification

00:08:22,370 --> 00:08:29,610
for the source code line that we've seen

00:08:25,320 --> 00:08:32,970
we get this syntax tree and this is

00:08:29,610 --> 00:08:34,740
already quite close to what we want to

00:08:32,970 --> 00:08:38,490
use but this is still missing some

00:08:34,740 --> 00:08:40,440
semantic information it's missing on the

00:08:38,490 --> 00:08:43,470
scopes which will be added by the scope

00:08:40,440 --> 00:08:46,910
analyzer and this missing on information

00:08:43,470 --> 00:08:49,470
on various accessibility features so

00:08:46,910 --> 00:08:51,780
essentially the abstract semantic graph

00:08:49,470 --> 00:08:54,810
enriches the abstract syntax tree by

00:08:51,780 --> 00:08:59,250
adding some scope information so we take

00:08:54,810 --> 00:09:02,220
this and add some more edges actually

00:08:59,250 --> 00:09:04,020
once we have already added these edges

00:09:02,220 --> 00:09:07,020
it's no longer a tree because it has

00:09:04,020 --> 00:09:10,440
some cross edges all the scopes are

00:09:07,020 --> 00:09:14,340
defined and also the accessibility kind

00:09:10,440 --> 00:09:19,620
and other meta information are added to

00:09:14,340 --> 00:09:21,830
the specific nodes so this is like

00:09:19,620 --> 00:09:24,420
compiler construction in a nutshell and

00:09:21,830 --> 00:09:27,510
you can see that even though we started

00:09:24,420 --> 00:09:30,240
off with a very simple experiment like 6

00:09:27,510 --> 00:09:32,730
tokens a single line of code we get more

00:09:30,240 --> 00:09:36,750
than 20 nodes and this can be a lot more

00:09:32,730 --> 00:09:39,480
so for a very sophisticated line of code

00:09:36,750 --> 00:09:45,060
we can get 50 to 100 nodes easily so

00:09:39,480 --> 00:09:47,220
these guys are pretty large graphs we

00:09:45,060 --> 00:09:48,840
can do all sorts of pattern matching I

00:09:47,220 --> 00:09:50,790
said that we are going to use a

00:09:48,840 --> 00:09:53,670
declarative graph pattern language and

00:09:50,790 --> 00:09:57,030
this is cipher so if you have a graph

00:09:53,670 --> 00:09:59,340
like this and you know a bit of cipher

00:09:57,030 --> 00:10:01,440
you can actually specify validation

00:09:59,340 --> 00:10:04,140
routes for example you don't want your

00:10:01,440 --> 00:10:06,540
code to do divisions by 0 so

00:10:04,140 --> 00:10:09,300
you create this rule which matches the

00:10:06,540 --> 00:10:12,030
binding identifiers that are in a binary

00:10:09,300 --> 00:10:14,580
expression then do a filtering where the

00:10:12,030 --> 00:10:16,950
expression is a division and the right

00:10:14,580 --> 00:10:20,640
value is a zero and then the projection

00:10:16,950 --> 00:10:22,290
operation to return the binding and this

00:10:20,640 --> 00:10:24,690
is very useful for the developer because

00:10:22,290 --> 00:10:27,120
the developer can fix that instantly

00:10:24,690 --> 00:10:29,160
it's a Van Daan truth that the sooner

00:10:27,120 --> 00:10:32,190
the developer gets feedback on the

00:10:29,160 --> 00:10:35,490
errors that they made the cheaper is to

00:10:32,190 --> 00:10:39,180
fix these errors so ideally we should

00:10:35,490 --> 00:10:42,690
give the developers timely feedback on

00:10:39,180 --> 00:10:45,330
the mistakes they made in the code so

00:10:42,690 --> 00:10:47,670
workflow wise it starts with the

00:10:45,330 --> 00:10:49,680
developers ID and the version control

00:10:47,670 --> 00:10:51,600
system as a first step

00:10:49,680 --> 00:10:56,550
code is loaded from the version control

00:10:51,600 --> 00:11:00,390
system and transformed to tokens ASD and

00:10:56,550 --> 00:11:04,020
ASG step by step then it's transformed

00:11:00,390 --> 00:11:05,910
by a set of cipher queries and Java code

00:11:04,020 --> 00:11:10,500
and is loaded to the graph database and

00:11:05,910 --> 00:11:12,720
once we have this we trace the core

00:11:10,500 --> 00:11:15,660
issues of the errors back to the source

00:11:12,720 --> 00:11:18,600
code and display the errors in the

00:11:15,660 --> 00:11:21,620
developers ID so once we have a workflow

00:11:18,600 --> 00:11:21,620
that like this running

00:11:24,360 --> 00:11:29,670
actually it allows us to do very cool

00:11:27,029 --> 00:11:32,220
things one of my favorite ones is type

00:11:29,670 --> 00:11:34,170
inferencing because as you know

00:11:32,220 --> 00:11:38,190
javascript is a dynamic language and

00:11:34,170 --> 00:11:39,779
it's very easy to write code that throws

00:11:38,190 --> 00:11:42,209
runtime errors because of type

00:11:39,779 --> 00:11:43,920
violations obviously there are some

00:11:42,209 --> 00:11:46,740
workarounds for this you can use

00:11:43,920 --> 00:11:49,620
typescript or other typed flavors of

00:11:46,740 --> 00:11:52,260
JavaScript but you have a lot of legacy

00:11:49,620 --> 00:11:54,810
JavaScript code that's written in plain

00:11:52,260 --> 00:11:58,560
JavaScript and type inferencing is key

00:11:54,810 --> 00:12:02,760
to use those in a way that will not

00:11:58,560 --> 00:12:08,160
return errors while while running the

00:12:02,760 --> 00:12:10,860
the code so another use case is global

00:12:08,160 --> 00:12:14,010
analytics because we have this graph we

00:12:10,860 --> 00:12:16,709
can do a lot of cool reachability style

00:12:14,010 --> 00:12:20,399
queries we can do that code detection we

00:12:16,709 --> 00:12:23,310
can do a detection of async awaits where

00:12:20,399 --> 00:12:25,260
you run an async and it's dangling

00:12:23,310 --> 00:12:28,320
somewhere in the code but you'd never do

00:12:25,260 --> 00:12:30,839
any weight on that piece of asynchronous

00:12:28,320 --> 00:12:34,430
code and you can do potential division

00:12:30,839 --> 00:12:36,870
by zero detection by propagating these

00:12:34,430 --> 00:12:40,589
issues to the code so you can check

00:12:36,870 --> 00:12:44,640
whether value can be zero at the point

00:12:40,589 --> 00:12:46,980
of the time that it's evaluated some tag

00:12:44,640 --> 00:12:50,490
details I think will be very interested

00:12:46,980 --> 00:12:52,470
interesting for this audience one of the

00:12:50,490 --> 00:12:54,959
key issues in implementing gold is is

00:12:52,470 --> 00:12:58,680
that imports and exports are just crazy

00:12:54,959 --> 00:13:02,250
in ECMAScript you have a dozen ways to

00:12:58,680 --> 00:13:04,829
import and even more to export so we

00:13:02,250 --> 00:13:07,769
have drawn this nice matrix of

00:13:04,829 --> 00:13:10,170
compatibility and just to give you an

00:13:07,769 --> 00:13:13,410
idea of how long it takes to implement

00:13:10,170 --> 00:13:17,699
all this single black dot which says

00:13:13,410 --> 00:13:20,279
that that's compatible needs like 15

00:13:17,699 --> 00:13:24,690
lines of quite complex cipher code to

00:13:20,279 --> 00:13:29,519
work with so it's a lot of work to cover

00:13:24,690 --> 00:13:31,199
all these and obviously once we have

00:13:29,519 --> 00:13:33,300
this we have to implement the algorithms

00:13:31,199 --> 00:13:34,800
now as I said we have some propagation

00:13:33,300 --> 00:13:37,130
algorithms where we want to propagate

00:13:34,800 --> 00:13:40,430
some property along the graph

00:13:37,130 --> 00:13:43,850
be that typing formation or the fact

00:13:40,430 --> 00:13:46,460
that this value can be zero or not this

00:13:43,850 --> 00:13:49,280
is actually something that's called run

00:13:46,460 --> 00:13:51,410
to completion scheduling so we give a

00:13:49,280 --> 00:13:53,750
set of transformation rules to the

00:13:51,410 --> 00:13:56,540
system and then ask the system to

00:13:53,750 --> 00:14:00,140
execute it until there are no more

00:13:56,540 --> 00:14:02,780
changes to execute this is actually

00:14:00,140 --> 00:14:04,850
quite difficult to do in plain sight

00:14:02,780 --> 00:14:07,640
first so we use a mix of Java code and

00:14:04,850 --> 00:14:12,590
cipher code and the Java code does the

00:14:07,640 --> 00:14:14,810
propagations while it can another thing

00:14:12,590 --> 00:14:17,630
that we struggle with is efficient

00:14:14,810 --> 00:14:19,820
initialization of the database state so

00:14:17,630 --> 00:14:23,120
in the first implementations the initial

00:14:19,820 --> 00:14:25,340
build of the graph happened with cipher

00:14:23,120 --> 00:14:28,610
statements so we build the graph pretty

00:14:25,340 --> 00:14:30,680
much node by node with separate cipher

00:14:28,610 --> 00:14:34,310
statements and this obviously was quite

00:14:30,680 --> 00:14:38,840
slow so we started to think around this

00:14:34,310 --> 00:14:40,760
with a bit and used CSVs to generate the

00:14:38,840 --> 00:14:43,880
graph so in the for as the first step we

00:14:40,760 --> 00:14:46,370
generated just two CSV files one for the

00:14:43,880 --> 00:14:49,010
nodes and one for relationships and then

00:14:46,370 --> 00:14:50,960
used the neo4j import tool to load it to

00:14:49,010 --> 00:14:53,090
the database this is not a very

00:14:50,960 --> 00:14:55,910
sophisticated approach you could do

00:14:53,090 --> 00:14:59,390
multiple CSVs or binaries or other

00:14:55,910 --> 00:15:02,180
things but already this gave us a 10x

00:14:59,390 --> 00:15:05,030
speed up so it's actually like one days

00:15:02,180 --> 00:15:09,710
of work and the initial load went down

00:15:05,030 --> 00:15:12,440
from an hour to a couple of minutes we

00:15:09,710 --> 00:15:15,320
also stumbled upon regular path queries

00:15:12,440 --> 00:15:17,960
quite regularly because there are a lot

00:15:15,320 --> 00:15:21,260
of cases when we need transitive closure

00:15:17,960 --> 00:15:24,370
on certain combinations so for example

00:15:21,260 --> 00:15:26,570
you can have a situation when you have

00:15:24,370 --> 00:15:28,460
function that's assigned to a variable

00:15:26,570 --> 00:15:30,290
that's in another function that's

00:15:28,460 --> 00:15:33,650
assigned to another variable and so on

00:15:30,290 --> 00:15:36,020
transitively and essentially we would

00:15:33,650 --> 00:15:38,540
want to do a transitive closure style

00:15:36,020 --> 00:15:40,760
operation on those relationship types

00:15:38,540 --> 00:15:45,050
the problem is that it's not supported

00:15:40,760 --> 00:15:46,820
by cipher yet so we created a workaround

00:15:45,050 --> 00:15:50,510
the workaround is let's start the

00:15:46,820 --> 00:15:51,890
transaction add some proxy relationships

00:15:50,510 --> 00:15:56,230
there

00:15:51,890 --> 00:15:59,180
sort of go over those relationships do a

00:15:56,230 --> 00:16:02,420
calculation for transitive closure on

00:15:59,180 --> 00:16:05,170
those proxy relationships and then roll

00:16:02,420 --> 00:16:08,330
the transaction back and essentially

00:16:05,170 --> 00:16:12,170
deleting those edges from the graph this

00:16:08,330 --> 00:16:14,060
is I think a proper workaround but it's

00:16:12,170 --> 00:16:17,300
not the nicest way to express it and

00:16:14,060 --> 00:16:19,339
obviously the cipher team is very well

00:16:17,300 --> 00:16:22,279
aware of this so for the next open

00:16:19,339 --> 00:16:24,140
cipher there is a proposal for creating

00:16:22,279 --> 00:16:27,459
path patterns this allows users to

00:16:24,140 --> 00:16:31,279
create an expression where there are

00:16:27,459 --> 00:16:33,230
several relationships type next to each

00:16:31,279 --> 00:16:37,520
other and then do a transitive closure

00:16:33,230 --> 00:16:40,790
style operation on that ok so I said

00:16:37,520 --> 00:16:43,880
that incrementality is very important in

00:16:40,790 --> 00:16:45,920
this work and actually this was my

00:16:43,880 --> 00:16:50,200
motivation to start working on this

00:16:45,920 --> 00:16:53,120
topic so as I said we built our system

00:16:50,200 --> 00:16:54,830
around cipher queries as you probably

00:16:53,120 --> 00:16:57,230
know there is now an initiative called

00:16:54,830 --> 00:16:59,480
open cipher which aims to deliver a

00:16:57,230 --> 00:17:02,060
standard specification of the cipher

00:16:59,480 --> 00:17:05,059
query language it was released about two

00:17:02,060 --> 00:17:08,720
years ago and it's been actually adapted

00:17:05,059 --> 00:17:11,059
by industrial vendors that are listed on

00:17:08,720 --> 00:17:13,339
the logos and there are also a couple of

00:17:11,059 --> 00:17:15,530
research prototypes most notably there

00:17:13,339 --> 00:17:17,720
is graph flow which is developed by the

00:17:15,530 --> 00:17:20,120
University of Waterloo and there is

00:17:17,720 --> 00:17:22,370
ingre which is my PhD project and

00:17:20,120 --> 00:17:24,470
interestingly enough both of these

00:17:22,370 --> 00:17:28,370
target the same goal it's the

00:17:24,470 --> 00:17:30,500
incremental processing of cipher queries

00:17:28,370 --> 00:17:32,710
so you have a sort of cipher queries and

00:17:30,500 --> 00:17:35,929
you can evaluate them incrementally

00:17:32,710 --> 00:17:37,520
continuously in your system if you're

00:17:35,929 --> 00:17:39,410
interested in some of the details

00:17:37,520 --> 00:17:41,960
last year I was here in the same room

00:17:39,410 --> 00:17:46,150
giving a talk about this system in graph

00:17:41,960 --> 00:17:49,630
and here are a couple of my slides so

00:17:46,150 --> 00:17:51,950
the way in graph works is to first

00:17:49,630 --> 00:17:54,260
compile the open psyshock various

00:17:51,950 --> 00:17:56,030
relational algebra and then transform

00:17:54,260 --> 00:17:58,010
that relational algebra to a

00:17:56,030 --> 00:18:00,980
representation that's incremental

00:17:58,010 --> 00:18:03,020
maintainable and then use an incremental

00:18:00,980 --> 00:18:04,520
relational engine to calculate the

00:18:03,020 --> 00:18:08,690
result of those queries

00:18:04,520 --> 00:18:11,060
in the last year we expanded in graph by

00:18:08,690 --> 00:18:13,070
a lot of new features it now covers the

00:18:11,060 --> 00:18:16,280
substantial fragment of the open cypher

00:18:13,070 --> 00:18:18,740
language including sub-queries functions

00:18:16,280 --> 00:18:20,780
aggregations some of the data

00:18:18,740 --> 00:18:22,850
manipulation operations like create or

00:18:20,780 --> 00:18:25,550
delete and there are some features

00:18:22,850 --> 00:18:29,090
missing on the roadmap like merge remove

00:18:25,550 --> 00:18:31,250
and more sophisticated expressions like

00:18:29,090 --> 00:18:33,910
list comprehensions but it's getting

00:18:31,250 --> 00:18:39,230
nice together and the state of in graph

00:18:33,910 --> 00:18:41,990
almost allows us to evaluate the most

00:18:39,230 --> 00:18:44,990
important javascript static analysis

00:18:41,990 --> 00:18:48,610
queries so it's possible in theory we

00:18:44,990 --> 00:18:50,870
have two papers on that one is about the

00:18:48,610 --> 00:18:52,750
compilation of Scythia queries to

00:18:50,870 --> 00:18:55,190
algebra and the other is on the

00:18:52,750 --> 00:18:58,700
incremental maintenance of those

00:18:55,190 --> 00:19:01,220
relational algebra expressions so this

00:18:58,700 --> 00:19:06,680
is I think a very cool use case for in

00:19:01,220 --> 00:19:09,950
graph so as Michael said his pet peeve

00:19:06,680 --> 00:19:12,980
is software analytics and I think this

00:19:09,950 --> 00:19:15,110
is an area that's very important we as a

00:19:12,980 --> 00:19:17,840
developers we should strive to make

00:19:15,110 --> 00:19:20,600
better software and others have realized

00:19:17,840 --> 00:19:24,290
the need for this and the usefulness of

00:19:20,600 --> 00:19:26,150
graphs for understanding code and

00:19:24,290 --> 00:19:30,080
analyzing code so there is a tool called

00:19:26,150 --> 00:19:33,110
JQ assistant it's basically a code

00:19:30,080 --> 00:19:35,900
comprehension - that scans the software

00:19:33,110 --> 00:19:38,270
turns into a graph and then you can use

00:19:35,900 --> 00:19:40,730
arbitrary cipher queries to understand

00:19:38,270 --> 00:19:42,230
the code and you can reduce the a set of

00:19:40,730 --> 00:19:44,690
validation queries that you want to

00:19:42,230 --> 00:19:49,430
check on each build there is a blog post

00:19:44,690 --> 00:19:52,520
on this on the neo4j blog there's also

00:19:49,430 --> 00:19:54,050
slicer which is closely tied to JQ a

00:19:52,520 --> 00:19:57,830
system this is actually an interactive

00:19:54,050 --> 00:20:00,170
front-end on top of JQ assistant and the

00:19:57,830 --> 00:20:03,470
idea is the same you take a bunch of jar

00:20:00,170 --> 00:20:05,870
files Java files and so on throw it at

00:20:03,470 --> 00:20:07,940
the system it scans it loads it to the

00:20:05,870 --> 00:20:11,120
database and then you can use this

00:20:07,940 --> 00:20:15,050
interactive cipher editor to visualize

00:20:11,120 --> 00:20:17,159
and discover your system it actually has

00:20:15,050 --> 00:20:20,159
an eclipse based IDE

00:20:17,159 --> 00:20:23,970
and as part of that idea it has a

00:20:20,159 --> 00:20:26,700
grammar to provide an editor and funnily

00:20:23,970 --> 00:20:30,539
enough as part of the ingre project we

00:20:26,700 --> 00:20:32,940
managed to extend that grammar by some

00:20:30,539 --> 00:20:34,499
new features we actually added some

00:20:32,940 --> 00:20:37,200
features that were introduced in the

00:20:34,499 --> 00:20:40,259
opus cipher language recently we added a

00:20:37,200 --> 00:20:42,869
scope analyzer and you know you might

00:20:40,259 --> 00:20:44,820
think that you're not using Eclipse so

00:20:42,869 --> 00:20:47,369
this is not very relevant but actually X

00:20:44,820 --> 00:20:50,159
text is quite independent from eclipse

00:20:47,369 --> 00:20:51,509
so you can run it in the web UI so this

00:20:50,159 --> 00:20:54,720
is an editor which allows you to

00:20:51,509 --> 00:20:56,849
refactor cycle queries correctly if you

00:20:54,720 --> 00:21:00,450
do refactoring operation you can

00:20:56,849 --> 00:21:02,399
actually change the value of a variable

00:21:00,450 --> 00:21:07,679
and then it will trace it back through

00:21:02,399 --> 00:21:10,109
the query okay to wrap up if you found

00:21:07,679 --> 00:21:14,460
all this interesting we have to this

00:21:10,109 --> 00:21:16,679
works on days from 2016 and 2017 these

00:21:14,460 --> 00:21:18,629
are very well-written and nice few

00:21:16,679 --> 00:21:22,379
Illustrated works and I think they are

00:21:18,629 --> 00:21:25,229
quite pleasant rates so all these are

00:21:22,379 --> 00:21:28,590
clickable if you're interested and as a

00:21:25,229 --> 00:21:31,200
conclusion I think it's fair to say that

00:21:28,590 --> 00:21:33,539
interesting analysis rules at least some

00:21:31,200 --> 00:21:35,729
of them require a global view of the

00:21:33,539 --> 00:21:39,179
code so it's not enough to just scan a

00:21:35,729 --> 00:21:42,450
file and do a standard linter style

00:21:39,179 --> 00:21:44,759
analysis instead you should use some

00:21:42,450 --> 00:21:48,239
graph representation for your source

00:21:44,759 --> 00:21:50,609
code and property graph databases are

00:21:48,239 --> 00:21:52,470
definitely a good fit for this they are

00:21:50,609 --> 00:21:54,509
very expressive and the cypher clear

00:21:52,470 --> 00:21:58,289
language is quite easy to use and easy

00:21:54,509 --> 00:22:00,570
to understand and in particular these

00:21:58,289 --> 00:22:03,599
are very good use cases for incremental

00:22:00,570 --> 00:22:06,359
graph queries so if you make sure that

00:22:03,599 --> 00:22:08,849
your system incorporates incrementality

00:22:06,359 --> 00:22:10,820
multiple levels you can end up with a

00:22:08,849 --> 00:22:13,769
system that's fast enough for real-time

00:22:10,820 --> 00:22:16,409
answers these are the related resources

00:22:13,769 --> 00:22:18,090
that you can find on github bear in mind

00:22:16,409 --> 00:22:20,340
that these are all academic prototypes

00:22:18,090 --> 00:22:21,929
so they work some of the time on some

00:22:20,340 --> 00:22:26,399
use cases they are more like

00:22:21,929 --> 00:22:28,649
proof-of-concept softwares and I would

00:22:26,399 --> 00:22:31,180
like to thank the whole team that worked

00:22:28,649 --> 00:22:34,300
on these students my colleagues

00:22:31,180 --> 00:22:36,100
and Adam actually Adam Lipe is my old

00:22:34,300 --> 00:22:38,050
friend and he's giving the talk in the

00:22:36,100 --> 00:22:40,690
source code analysis dev room tomorrow

00:22:38,050 --> 00:22:43,120
so if you came here just for the

00:22:40,690 --> 00:22:45,940
JavaScript part and you were left

00:22:43,120 --> 00:22:50,770
unsatisfied you can go there tomorrow at

00:22:45,940 --> 00:22:53,370
4:30 4:20 and tantus talk thank you for

00:22:50,770 --> 00:22:53,370
your attention

00:22:56,730 --> 00:23:19,720
ok questions yeah we can talk we can

00:23:05,950 --> 00:23:24,760
talk here or fine absolutely feel free

00:23:19,720 --> 00:23:38,080
to come along after but any other

00:23:24,760 --> 00:23:39,220
questions Hey ok ok so let me repeat the

00:23:38,080 --> 00:23:41,800
question

00:23:39,220 --> 00:23:48,010
the gentleman is from Firefox I

00:23:41,800 --> 00:23:50,680
understand so yeah ok so the question is

00:23:48,010 --> 00:23:52,840
what code repositories we have tried our

00:23:50,680 --> 00:23:55,420
code on so you're probably concerned

00:23:52,840 --> 00:23:58,870
about scalability obviously we went on

00:23:55,420 --> 00:24:01,600
github and grabbed a couple of the

00:23:58,870 --> 00:24:04,960
source code repositories most notably

00:24:01,600 --> 00:24:07,330
there is treasure 8 which is a cloud

00:24:04,960 --> 00:24:09,100
storage system so it's like Dropbox but

00:24:07,330 --> 00:24:12,960
it's more focused on encryption and

00:24:09,100 --> 00:24:17,890
security and their front-end library is

00:24:12,960 --> 00:24:21,640
approximately 70,000 yeah 70,000 lines

00:24:17,890 --> 00:24:23,920
of JavaScript code and that was the one

00:24:21,640 --> 00:24:25,510
that took us like an hour to load and

00:24:23,920 --> 00:24:28,870
then we optimized it and it went down

00:24:25,510 --> 00:24:31,240
like to like five six minutes so that

00:24:28,870 --> 00:24:36,670
was the largest one that we have used

00:24:31,240 --> 00:24:39,400
and we had a lot of struggle to get a

00:24:36,670 --> 00:24:41,260
parser that works well because we tried

00:24:39,400 --> 00:24:43,660
the Bible parser and the problem with

00:24:41,260 --> 00:24:45,010
that was that it doesn't really provide

00:24:43,660 --> 00:24:47,560
scope information so

00:24:45,010 --> 00:24:50,680
just DSD and it's very difficult to work

00:24:47,560 --> 00:24:55,260
with but this logo here is the logo of

00:24:50,680 --> 00:25:00,010
shape security the S on the figure and

00:24:55,260 --> 00:25:04,000
they have very well written library

00:25:00,010 --> 00:25:05,770
called shift - Java that's an ASD

00:25:04,000 --> 00:25:08,500
builder but that has a lot of scoping

00:25:05,770 --> 00:25:10,030
information that's a very nicely written

00:25:08,500 --> 00:25:12,370
piece of software actually it's

00:25:10,030 --> 00:25:14,950
beautiful Java code the problem with it

00:25:12,370 --> 00:25:17,380
is it's not really maintained so it's a

00:25:14,950 --> 00:25:21,100
well written and we have to maintain it

00:25:17,380 --> 00:25:23,400
now because it's it seems abandoned and

00:25:21,100 --> 00:25:26,770
we actually started to add the

00:25:23,400 --> 00:25:30,220
ECMAScript 2017 features like async and

00:25:26,770 --> 00:25:34,390
await - to the parser which is a work in

00:25:30,220 --> 00:25:50,410
progress now okay any other questions

00:25:34,390 --> 00:25:55,800
yes okay so the question was what do i

00:25:50,410 --> 00:25:59,200
quantify as real-time well essentially

00:25:55,800 --> 00:26:01,930
it should be quick enough for developers

00:25:59,200 --> 00:26:04,030
to appear while they are working on the

00:26:01,930 --> 00:26:07,030
same file so you're writing your file

00:26:04,030 --> 00:26:11,160
make some changes you press you know

00:26:07,030 --> 00:26:14,800
ctrl s command S and it should pop up

00:26:11,160 --> 00:26:18,690
next to the other errors so it should be

00:26:14,800 --> 00:26:18,690
sub-second ideally

00:26:23,650 --> 00:26:32,830
yes yeah so the follow-up question was

00:26:30,150 --> 00:26:35,650
different size of code repositories will

00:26:32,830 --> 00:26:38,500
mean different different execution times

00:26:35,650 --> 00:26:43,390
and whether there is like an average

00:26:38,500 --> 00:26:45,100
dick should take well for this actually

00:26:43,390 --> 00:26:47,110
we planned to use the in graph engine

00:26:45,100 --> 00:26:49,750
more extensively the whole idea of in

00:26:47,110 --> 00:26:53,620
graph is is to build a huge gash on your

00:26:49,750 --> 00:26:57,010
code on on your queries and once you

00:26:53,620 --> 00:27:00,370
have that cash you can do I won't say

00:26:57,010 --> 00:27:02,980
constant time but very very quick clear

00:27:00,370 --> 00:27:06,580
evaluations because you have all the

00:27:02,980 --> 00:27:08,890
interim results of your queries cached

00:27:06,580 --> 00:27:11,890
so essentially if you just want to

00:27:08,890 --> 00:27:14,740
introduce a small change which you

00:27:11,890 --> 00:27:45,220
usually do while developing it should be

00:27:14,740 --> 00:27:47,590
very quick and it should stay within but

00:27:45,220 --> 00:27:49,600
I I'm you know I'm not an experienced

00:27:47,590 --> 00:27:51,880
JavaScript developer but I believe there

00:27:49,600 --> 00:27:54,400
is also a need for queries that are

00:27:51,880 --> 00:27:56,830
global like reachability stuff is this

00:27:54,400 --> 00:28:00,310
Coast it is this piece of code still

00:27:56,830 --> 00:28:03,160
reachable is this still correct from

00:28:00,310 --> 00:28:20,710
typing perspective and so on so you can

00:28:03,160 --> 00:28:23,230
think of of global no but just like more

00:28:20,710 --> 00:28:25,840
motif detection so the question was

00:28:23,230 --> 00:28:29,770
whether we try to identify patterns in

00:28:25,840 --> 00:28:31,570
the graph and no but that's a very

00:28:29,770 --> 00:28:33,850
interesting like a mixture of network

00:28:31,570 --> 00:28:36,790
science and and source code on ethics so

00:28:33,850 --> 00:28:48,730
that's a suggestion Thanks

00:28:36,790 --> 00:28:54,610
okay one last question I think yeah yes

00:28:48,730 --> 00:28:58,540
so Facebook flow actually uses custom

00:28:54,610 --> 00:29:03,610
algorithms to make the evaluation very

00:28:58,540 --> 00:29:05,650
efficient so I so from what I understand

00:29:03,610 --> 00:29:07,330
it does a few things and does those very

00:29:05,650 --> 00:29:08,920
well and very quickly but it's very

00:29:07,330 --> 00:29:11,230
difficult to extend flow with your

00:29:08,920 --> 00:29:13,470
custom rules so if you say that my

00:29:11,230 --> 00:29:16,240
company policy is that you cannot do

00:29:13,470 --> 00:30:15,250
this and that in the code and I want to

00:29:16,240 --> 00:30:17,830
enforce this with my that's you know and

00:30:15,250 --> 00:30:30,730
Jake your system does that for Java code

00:30:17,830 --> 00:30:35,050
already so that's yeah yeah we could use

00:30:30,730 --> 00:30:36,730
some help sir absolutely okay thank you

00:30:35,050 --> 00:30:41,960
again

00:30:36,730 --> 00:30:47,090
[Applause]

00:30:41,960 --> 00:30:54,980
okay the last talk will have a general

00:30:47,090 --> 00:30:54,980
tip of grass medical records and

00:31:04,880 --> 00:32:13,050
like you just because you know we are

00:32:10,860 --> 00:32:15,930
supposed to put them online like half an

00:32:13,050 --> 00:32:18,320
hour before the tow I did that so I hope

00:32:15,930 --> 00:32:18,320
it works

00:32:27,230 --> 00:32:32,150
no no we I think we took

00:32:35,880 --> 00:32:51,150
[Music]

00:32:37,320 --> 00:32:54,390
what start Hey yes sir I asked you a few

00:32:51,150 --> 00:32:56,430
questions okay okay yeah absolutely but

00:32:54,390 --> 00:32:59,420
I think there's a dog here so maybe yeah

00:32:56,430 --> 00:32:59,420
start soon

00:33:04,470 --> 00:33:10,830
I think we can talk let me talk I'm just

00:33:08,190 --> 00:33:12,990
gonna shut this down so no internet

00:33:10,830 --> 00:33:20,810
connection absolutely actually my phone

00:33:12,990 --> 00:33:23,580
is I am but it never works on my Linux

00:33:20,810 --> 00:33:25,530
because of your right to thank you yeah

00:33:23,580 --> 00:33:36,660
but it just never works for me

00:33:25,530 --> 00:33:40,710
I should be besides out here yeah here

00:33:36,660 --> 00:33:47,370
they are so so you should should be able

00:33:40,710 --> 00:33:53,760
to see yeah yeah absolutely and I will

00:33:47,370 --> 00:33:55,940
give the microphone to know so you'll

00:33:53,760 --> 00:33:55,940
have

00:35:05,020 --> 00:35:07,080

YouTube URL: https://www.youtube.com/watch?v=dYBURFmH9Xk


