Title: Make your Go go faster! Optimising performance through reducing memory allocations
Publication date: 2018-02-04
Playlist: FOSDEM 2018
Description: 
	by Bryan Boreham

At: FOSDEM 2018
Room: H.1308 (Rolin)
Scheduled start: 2018-02-03 16:30:00+01
Captions: 
	00:00:04,610 --> 00:00:11,240
iein follow me on twitter that's the

00:00:07,520 --> 00:00:12,290
only reason I do this I get paid by

00:00:11,240 --> 00:00:14,719
people who do this

00:00:12,290 --> 00:00:16,610
DevOps tools online observability

00:00:14,719 --> 00:00:22,070
monitoring stuff like that that's they

00:00:16,610 --> 00:00:24,290
advert I do some open source stuff

00:00:22,070 --> 00:00:26,600
actually everything we've we've works

00:00:24,290 --> 00:00:30,020
does is open source so but I do some

00:00:26,600 --> 00:00:32,149
other stuff as well and program computer

00:00:30,020 --> 00:00:35,390
program optimization making things go

00:00:32,149 --> 00:00:37,430
faster is is like a passion is it's

00:00:35,390 --> 00:00:38,630
basically my video game you know I some

00:00:37,430 --> 00:00:41,870
people will sit and they shoot it

00:00:38,630 --> 00:00:44,060
zombies for several hours i cycles and

00:00:41,870 --> 00:00:47,239
make things go faster so that's where

00:00:44,060 --> 00:00:51,649
I'm coming from I've been working in go

00:00:47,239 --> 00:00:54,140
for three and a half years now and I

00:00:51,649 --> 00:00:56,030
gotta tell you some stuff so let's see

00:00:54,140 --> 00:00:58,730
who what have we got in the room I guess

00:00:56,030 --> 00:01:01,790
who read the abstracts actually of the

00:00:58,730 --> 00:01:04,189
talk ok so you actually know the

00:01:01,790 --> 00:01:07,969
punchline so you could leave now and

00:01:04,189 --> 00:01:11,150
make room for the I don't know it's not

00:01:07,969 --> 00:01:13,220
much of a not much of it huh so yeah

00:01:11,150 --> 00:01:15,140
who's everyone's working with go right

00:01:13,220 --> 00:01:18,380
every nobody's putting their hand up but

00:01:15,140 --> 00:01:19,700
see cuz you're lazy has heard of

00:01:18,380 --> 00:01:20,720
Prometheus it was mentioned a couple of

00:01:19,700 --> 00:01:22,369
talks ago yeah

00:01:20,720 --> 00:01:23,330
I'm gonna I'm gonna use examples from

00:01:22,369 --> 00:01:25,430
that you don't have to know anything

00:01:23,330 --> 00:01:27,409
about it but I just and I always like to

00:01:25,430 --> 00:01:32,420
know who's actually heard of the work I

00:01:27,409 --> 00:01:37,729
do what am I gonna cover stuff stuff

00:01:32,420 --> 00:01:39,799
stuff yeah okay let's get going

00:01:37,729 --> 00:01:43,010
so the three most important things so

00:01:39,799 --> 00:01:44,210
everyone's got a paper and so on are the

00:01:43,010 --> 00:01:47,390
slides are online so you don't really

00:01:44,210 --> 00:01:48,770
need that anyway so so the most

00:01:47,390 --> 00:01:50,240
important thing you need to do when

00:01:48,770 --> 00:01:53,890
you're optimizing your programs is

00:01:50,240 --> 00:01:57,439
measure things do not start optimizing

00:01:53,890 --> 00:01:59,479
until you know what it is doing that is

00:01:57,439 --> 00:02:01,880
the most important thing the second most

00:01:59,479 --> 00:02:03,920
important thing is to still measure and

00:02:01,880 --> 00:02:06,560
the third most important thing is to

00:02:03,920 --> 00:02:10,970
keep on measuring so do always measure

00:02:06,560 --> 00:02:12,079
measure measure never just go change the

00:02:10,970 --> 00:02:13,940
code because you think it's gonna go

00:02:12,079 --> 00:02:14,270
faster because most of the time you're

00:02:13,940 --> 00:02:17,200
wrong

00:02:14,270 --> 00:02:17,200
and you're just gonna waste your time

00:02:17,280 --> 00:02:22,380
what do I mean by that measure first of

00:02:19,830 --> 00:02:24,810
all measure big things you know people

00:02:22,380 --> 00:02:26,880
show up sometimes they they post online

00:02:24,810 --> 00:02:28,740
or whatever they they have a profile

00:02:26,880 --> 00:02:30,240
where something is taking like

00:02:28,740 --> 00:02:32,970
twenty-one milliseconds or something

00:02:30,240 --> 00:02:36,480
like and you know who cares unless you

00:02:32,970 --> 00:02:37,860
unless you're high-frequency traders I

00:02:36,480 --> 00:02:39,690
used to work in our chronic trading I

00:02:37,860 --> 00:02:43,260
hate those guys so unless you're

00:02:39,690 --> 00:02:47,010
actually you know paid by the micro

00:02:43,260 --> 00:02:49,380
second measure big things also that the

00:02:47,010 --> 00:02:51,209
tooling in gold like Sam the profiler

00:02:49,380 --> 00:02:52,590
samples a hundred times a second so

00:02:51,209 --> 00:02:55,230
don't tell me about something that takes

00:02:52,590 --> 00:02:57,300
21 milliseconds because it's a sampling

00:02:55,230 --> 00:02:58,500
error so so measure things that you

00:02:57,300 --> 00:03:01,620
could literally stand there with a

00:02:58,500 --> 00:03:02,940
stopwatch and time and if you don't have

00:03:01,620 --> 00:03:05,100
anything like that then run it a million

00:03:02,940 --> 00:03:07,140
times and and then it will take

00:03:05,100 --> 00:03:08,160
appreciable time so measure measure big

00:03:07,140 --> 00:03:09,600
things first thing because you won't

00:03:08,160 --> 00:03:13,590
just lose the effect unless you're

00:03:09,600 --> 00:03:15,510
bigger big things measure all the time

00:03:13,590 --> 00:03:17,580
you're gonna miss it if you're not

00:03:15,510 --> 00:03:20,040
measuring and you know okay I'm standing

00:03:17,580 --> 00:03:23,519
here as a guy who sells very measurement

00:03:20,040 --> 00:03:27,630
and observability systems and so on but

00:03:23,519 --> 00:03:30,329
we this is this is pretty useful to like

00:03:27,630 --> 00:03:33,959
have things like your CPU usage all the

00:03:30,329 --> 00:03:35,640
time so you can see when things changed

00:03:33,959 --> 00:03:39,239
all that kind of thing

00:03:35,640 --> 00:03:41,370
and the other thing I got into this this

00:03:39,239 --> 00:03:47,430
particular tool is Yeager who uses

00:03:41,370 --> 00:03:49,019
Yeager so there's a there's a bunch of

00:03:47,430 --> 00:03:51,209
tools like this their zip King and

00:03:49,019 --> 00:03:53,130
dapper is the sort of daddy of this

00:03:51,209 --> 00:03:55,709
family and I used to write things like

00:03:53,130 --> 00:03:59,670
this myself when I worked in a chronic

00:03:55,709 --> 00:04:00,510
trading but the basic let's let's do

00:03:59,670 --> 00:04:02,579
technology here

00:04:00,510 --> 00:04:04,670
that's so basically ideas you got you

00:04:02,579 --> 00:04:07,890
got a you got a time line you got a

00:04:04,670 --> 00:04:09,750
horizontal bar illustrating how long

00:04:07,890 --> 00:04:12,780
everything took and then you got a kind

00:04:09,750 --> 00:04:16,829
of hierarchy of of the the breakdown of

00:04:12,780 --> 00:04:19,260
how long things took within that and the

00:04:16,829 --> 00:04:21,810
point is don't go optimizing your goal

00:04:19,260 --> 00:04:24,930
code if it's not actually in the goal

00:04:21,810 --> 00:04:27,990
code that it's slow you know so a first

00:04:24,930 --> 00:04:30,419
approximation most programs will spend

00:04:27,990 --> 00:04:33,089
all of their time waiting on

00:04:30,419 --> 00:04:34,439
so don't don't go hacking around there

00:04:33,089 --> 00:04:35,490
you go code if it's waiting for IO

00:04:34,439 --> 00:04:38,659
because it's not gonna make any

00:04:35,490 --> 00:04:40,710
difference so so this talk is about

00:04:38,659 --> 00:04:43,080
after the time when you've measure

00:04:40,710 --> 00:04:46,289
measure measure after the time when

00:04:43,080 --> 00:04:48,389
you've looked at the the traces and

00:04:46,289 --> 00:04:51,809
you're utterly sure that it is using CPU

00:04:48,389 --> 00:04:56,849
time in your goal code now the talk

00:04:51,809 --> 00:04:59,430
starts okay so what do you do oh talk

00:04:56,849 --> 00:05:01,020
didn't start I'm gonna I'm gonna draw

00:04:59,430 --> 00:05:04,499
examples from this thing which is we've

00:05:01,020 --> 00:05:11,699
cortex this is our this is our

00:05:04,499 --> 00:05:12,689
distributed time series database and you

00:05:11,699 --> 00:05:14,969
don't really have to know anything about

00:05:12,689 --> 00:05:16,349
it other than I'm using it in two

00:05:14,969 --> 00:05:18,149
different ways I use it to draw these

00:05:16,349 --> 00:05:19,919
charts and I also speed it up you know I

00:05:18,149 --> 00:05:27,899
speed up the analytics engine I speed up

00:05:19,919 --> 00:05:29,849
the ingression of data so so hopefully

00:05:27,899 --> 00:05:31,949
that's not too confusing if you if you

00:05:29,849 --> 00:05:34,889
want to see this the very specifics of

00:05:31,949 --> 00:05:36,509
what I've been doing go to github.com we

00:05:34,889 --> 00:05:38,309
Forex cortex and look at all the PRS

00:05:36,509 --> 00:05:42,149
with my name on because most of them are

00:05:38,309 --> 00:05:46,729
about speeding this thing up so yeah I

00:05:42,149 --> 00:05:51,149
just put that up it's it's we ingest

00:05:46,729 --> 00:05:52,620
tens of millions of time series in real

00:05:51,149 --> 00:05:54,089
time from lots of different customers

00:05:52,620 --> 00:05:58,379
and that's why I need to go fast right

00:05:54,089 --> 00:06:02,009
okay know the talk starts profiling so

00:05:58,379 --> 00:06:04,439
everyone knows this right I guess I

00:06:02,009 --> 00:06:08,039
don't know hands up if you're already an

00:06:04,439 --> 00:06:09,659
expert on this slide yeah maybe just

00:06:08,039 --> 00:06:12,809
lazy me don't want to put your hands up

00:06:09,659 --> 00:06:15,990
okay so the talk I'm gonna get into more

00:06:12,809 --> 00:06:20,219
detail but this is the this is the

00:06:15,990 --> 00:06:22,740
simple start go read the blog this is

00:06:20,219 --> 00:06:25,289
the bit I'm not gonna cover you know run

00:06:22,740 --> 00:06:29,759
run your program under the profiler run

00:06:25,289 --> 00:06:32,069
be prof. tool and the the bottom if you

00:06:29,759 --> 00:06:34,800
do this then you will have an HTTP

00:06:32,069 --> 00:06:36,479
endpoint where in your production system

00:06:34,800 --> 00:06:39,930
you go grab a profile which is really

00:06:36,479 --> 00:06:42,289
useful so yeah that's all in the blog

00:06:39,930 --> 00:06:44,639
I'm not going to cover that

00:06:42,289 --> 00:06:48,800
here's a profile here's what you'd get

00:06:44,639 --> 00:06:54,289
out if you run that go tool pre proof

00:06:48,800 --> 00:06:57,449
command and so this is this is a quiz

00:06:54,289 --> 00:06:59,780
okay so who knows who knows what the

00:06:57,449 --> 00:06:59,780
problem is

00:07:02,900 --> 00:07:12,509
okay silence sorry it only profiles when

00:07:10,229 --> 00:07:17,389
it's being tested this is a profile from

00:07:12,509 --> 00:07:21,110
our production system garbage collection

00:07:17,389 --> 00:07:23,610
I I made the I made the words

00:07:21,110 --> 00:07:30,629
highlighted and made some of them a bit

00:07:23,610 --> 00:07:32,159
bigger but the this is very common that

00:07:30,629 --> 00:07:35,250
you will run the profile and you'll see

00:07:32,159 --> 00:07:36,930
these guys show up you know like runtime

00:07:35,250 --> 00:07:39,840
GC drain things like that you'll see

00:07:36,930 --> 00:07:42,300
them in your profile and you'll think

00:07:39,840 --> 00:07:44,460
well darn you know I I don't know

00:07:42,300 --> 00:07:47,520
anything about garbage collection so I

00:07:44,460 --> 00:07:50,880
can't I can't fix that code and it's

00:07:47,520 --> 00:07:55,039
pretty complicated code as well so but

00:07:50,880 --> 00:07:57,479
do not fear I'll tell you what to do

00:07:55,039 --> 00:08:01,639
what is going on with garbage clip

00:07:57,479 --> 00:08:01,639
there's this question do we have plans

00:08:06,260 --> 00:08:10,190
yes I will explain I will explain the

00:08:08,930 --> 00:08:12,050
question was how do I know garbage

00:08:10,190 --> 00:08:13,790
collection is the problem what so yeah

00:08:12,050 --> 00:08:16,820
what I mean is if you see those

00:08:13,790 --> 00:08:19,280
characters runtime GC drain in that

00:08:16,820 --> 00:08:21,890
order somewhere near the top of your

00:08:19,280 --> 00:08:24,860
profile then you have a garbage

00:08:21,890 --> 00:08:29,120
collection problem and and I predict

00:08:24,860 --> 00:08:31,610
right now you have a garbage collection

00:08:29,120 --> 00:08:34,370
problem because it's a garbage collected

00:08:31,610 --> 00:08:35,570
language and unless you anyway let's

00:08:34,370 --> 00:08:36,740
through the rest of the talk and then

00:08:35,570 --> 00:08:40,450
come back to me if I didn't answer your

00:08:36,740 --> 00:08:43,669
question so this is this is

00:08:40,450 --> 00:08:45,170
visualization this is if you hook your

00:08:43,669 --> 00:08:48,950
go program into Prometheus you can get

00:08:45,170 --> 00:08:53,480
this start out for free and and this is

00:08:48,950 --> 00:08:55,670
a sawtooth pattern right the the memory

00:08:53,480 --> 00:08:59,050
builds up and then it goes bang down and

00:08:55,670 --> 00:09:01,700
builds up bang bang builds up builds up

00:08:59,050 --> 00:09:03,230
so it can be more complicated than that

00:09:01,700 --> 00:09:06,290
the garbage collector kind of runs along

00:09:03,230 --> 00:09:08,360
in the background it can be doing other

00:09:06,290 --> 00:09:09,950
stuff but this is this is fairly I want

00:09:08,360 --> 00:09:11,990
you to get that idea that that it

00:09:09,950 --> 00:09:16,490
started doing doing this sawtooth

00:09:11,990 --> 00:09:17,930
pattern all the time okay now why is it

00:09:16,490 --> 00:09:23,480
that interesting well let's talk about

00:09:17,930 --> 00:09:25,510
memory so this is sort of standard

00:09:23,480 --> 00:09:28,900
architecture of a modern processor

00:09:25,510 --> 00:09:36,470
processor sometime in the last 20 years

00:09:28,900 --> 00:09:38,660
and they the processor like the bit

00:09:36,470 --> 00:09:41,240
that's actually making decisions and

00:09:38,660 --> 00:09:43,730
doing things is something like a hundred

00:09:41,240 --> 00:09:46,070
times faster than your memory so there's

00:09:43,730 --> 00:09:47,750
a there's a block page numbers every

00:09:46,070 --> 00:09:50,420
programmer should know where they

00:09:47,750 --> 00:09:52,370
actually write down what those numbers

00:09:50,420 --> 00:09:54,110
are in terms of nanoseconds and so on

00:09:52,370 --> 00:09:57,860
but but it you know it's orders of

00:09:54,110 --> 00:09:59,090
magnitude slower and in order to just

00:09:57,860 --> 00:10:01,070
not have this thing waiting around all

00:09:59,090 --> 00:10:03,940
the time we build it we build a

00:10:01,070 --> 00:10:09,200
hierarchy of caches here typically to

00:10:03,940 --> 00:10:12,580
this is not to scale typically the the

00:10:09,200 --> 00:10:16,130
the level 1 cache l1 cache is like

00:10:12,580 --> 00:10:19,820
hundreds of K and typically the l2 cache

00:10:16,130 --> 00:10:24,410
will be like 2 3 4 megabytes

00:10:19,820 --> 00:10:26,150
and so this the level 1 cache goes that

00:10:24,410 --> 00:10:27,950
same speed is the processor the level 2

00:10:26,150 --> 00:10:31,460
cache goes a bit slower the RAM goes

00:10:27,950 --> 00:10:33,560
horrendously slower so for your program

00:10:31,460 --> 00:10:38,180
to go fast you want everything you're

00:10:33,560 --> 00:10:40,460
doing to be in the cache so there's a

00:10:38,180 --> 00:10:43,640
picture of a cache as you can tell I'm a

00:10:40,460 --> 00:10:47,390
great graphic artist as well as the

00:10:43,640 --> 00:10:49,070
programmer no I'm not but I tried I

00:10:47,390 --> 00:10:50,540
tried to indicate that that's how this

00:10:49,070 --> 00:10:52,190
works there's there's different color

00:10:50,540 --> 00:10:54,470
codes there's bits of bits of memory

00:10:52,190 --> 00:10:55,940
which are being cached in the cache and

00:10:54,470 --> 00:10:58,610
they're also in there one cache in the

00:10:55,940 --> 00:11:02,930
process is actually only working on the

00:10:58,610 --> 00:11:05,810
memory in the l1 cache so think about

00:11:02,930 --> 00:11:07,730
that sawtooth the action of going

00:11:05,810 --> 00:11:09,320
through everything in memory and trying

00:11:07,730 --> 00:11:11,050
to figure out what's garbage and what

00:11:09,320 --> 00:11:14,570
isn't

00:11:11,050 --> 00:11:18,190
basically wipes the cache no maybe not

00:11:14,570 --> 00:11:20,330
absolutely but but that activity of

00:11:18,190 --> 00:11:22,250
going trolling through the memory that

00:11:20,330 --> 00:11:24,800
and just just the activity of allocating

00:11:22,250 --> 00:11:29,870
more memory pushes things out of the

00:11:24,800 --> 00:11:36,200
cache if I move over the line that

00:11:29,870 --> 00:11:50,540
camera cannot see me okay the moment for

00:11:36,200 --> 00:11:52,690
the line okay sorry I can't do graphic

00:11:50,540 --> 00:11:55,640
art and I can't do interpretive dance

00:11:52,690 --> 00:11:57,080
but I do know how to make programs go

00:11:55,640 --> 00:12:01,220
faster and I'm trying to trying to tell

00:11:57,080 --> 00:12:02,540
you yeah so so you don't have to

00:12:01,220 --> 00:12:04,910
understand everything about how a

00:12:02,540 --> 00:12:06,470
processor works but I am trying to get

00:12:04,910 --> 00:12:08,600
across this idea there there are there

00:12:06,470 --> 00:12:11,000
are like technical physical reasons in

00:12:08,600 --> 00:12:13,400
the silicon why running around

00:12:11,000 --> 00:12:14,690
allocating memory throwing it away and

00:12:13,400 --> 00:12:18,260
letting the garbage collector clean it

00:12:14,690 --> 00:12:19,310
up for you he's gonna not only slow your

00:12:18,260 --> 00:12:21,290
program number because the garbage

00:12:19,310 --> 00:12:22,610
collector is doing work but it slows the

00:12:21,290 --> 00:12:24,110
rest of your program down because it

00:12:22,610 --> 00:12:27,910
kicked everything out of cache

00:12:24,110 --> 00:12:31,790
so let's let's look at some anecdotes

00:12:27,910 --> 00:12:32,690
this is another one of the oh that's a

00:12:31,790 --> 00:12:38,870
memory profile

00:12:32,690 --> 00:12:41,600
sorry that's important so in instead of

00:12:38,870 --> 00:12:43,899
saying - CPU profile when you profile

00:12:41,600 --> 00:12:46,879
your program if you say - from M profile

00:12:43,899 --> 00:12:48,199
you will get and then you can ask for

00:12:46,879 --> 00:12:50,600
things like the number of allocated

00:12:48,199 --> 00:12:53,720
objects that the default you get is the

00:12:50,600 --> 00:12:55,490
object in use right now which is not the

00:12:53,720 --> 00:12:57,829
interesting number so you need to you

00:12:55,490 --> 00:13:01,129
need to use a flag like this alyc

00:12:57,829 --> 00:13:02,680
objects and I like to do the cumulative

00:13:01,129 --> 00:13:07,000
so that gives me a sort of a top-down

00:13:02,680 --> 00:13:12,110
view of who's been allocating the most

00:13:07,000 --> 00:13:14,240
things so I looked at this and I see a

00:13:12,110 --> 00:13:16,189
bunch of encoding and I thought you know

00:13:14,240 --> 00:13:19,160
it's not you can go look at the PR if

00:13:16,189 --> 00:13:20,810
you want to see the actual code but you

00:13:19,160 --> 00:13:26,860
need to start if you want to speed this

00:13:20,810 --> 00:13:30,050
up you need to stop creating garbage and

00:13:26,860 --> 00:13:31,129
just as in the real world reuse reduce

00:13:30,050 --> 00:13:32,839
recycle

00:13:31,129 --> 00:13:35,120
I think recycle is basically garbage

00:13:32,839 --> 00:13:37,579
collection so so don't do that one but

00:13:35,120 --> 00:13:39,439
but reusing objects and just reducing

00:13:37,579 --> 00:13:41,769
the number that get allocated is the way

00:13:39,439 --> 00:13:41,769
to go

00:13:42,459 --> 00:13:51,970
so a little bit more detailed profile

00:13:48,339 --> 00:13:54,290
this one so this one is Alec space

00:13:51,970 --> 00:13:57,110
there's a little bit of an unusual one

00:13:54,290 --> 00:13:59,029
because there was this massive this is

00:13:57,110 --> 00:14:00,980
actually a there's a little micro

00:13:59,029 --> 00:14:04,930
benchmark that I did of one of the

00:14:00,980 --> 00:14:07,970
functions in the earlier profile but it

00:14:04,930 --> 00:14:10,699
we were using this library called snappy

00:14:07,970 --> 00:14:12,139
which is a compression library it turns

00:14:10,699 --> 00:14:17,180
out if you if you call this new reader

00:14:12,139 --> 00:14:20,509
function it allocates like a TK just one

00:14:17,180 --> 00:14:23,600
object a TK and think of that sawtooth

00:14:20,509 --> 00:14:27,559
is being driven much that much faster by

00:14:23,600 --> 00:14:31,189
that that allocation this is the timing

00:14:27,559 --> 00:14:33,800
so I'm running I'm running like a real

00:14:31,189 --> 00:14:36,649
call and our is in our staging

00:14:33,800 --> 00:14:40,670
environment every every 5 minutes and

00:14:36,649 --> 00:14:43,730
just timing one particular call and and

00:14:40,670 --> 00:14:46,670
this is the effects of releasing that

00:14:43,730 --> 00:14:50,600
one change tick to using async

00:14:46,670 --> 00:14:52,370
cool which is a built-in to the go

00:14:50,600 --> 00:14:55,760
standard library that's for reusing

00:14:52,370 --> 00:15:00,500
objects that have a high cost of

00:14:55,760 --> 00:15:02,810
allocation so putting that one change in

00:15:00,500 --> 00:15:06,910
which is like like six lines or

00:15:02,810 --> 00:15:10,310
something like that and take that down

00:15:06,910 --> 00:15:13,580
no it's it's what from 90 seconds to

00:15:10,310 --> 00:15:16,670
like seven and a half something like

00:15:13,580 --> 00:15:20,990
it's like a 20% improvement one

00:15:16,670 --> 00:15:25,100
allocation I'm going quite fast because

00:15:20,990 --> 00:15:26,960
because we're low on time this was one

00:15:25,100 --> 00:15:30,500
where this is one where this sort

00:15:26,960 --> 00:15:35,390
routine did a comparison by calling this

00:15:30,500 --> 00:15:37,310
function which did in s printf the the

00:15:35,390 --> 00:15:40,190
cumulative effect of this is to create a

00:15:37,310 --> 00:15:44,090
lot of garbage and and the sort

00:15:40,190 --> 00:15:45,920
comparison is called a lot so instead of

00:15:44,090 --> 00:15:47,090
instead of kind of indirectly going

00:15:45,920 --> 00:15:50,600
through strings I just wrote a

00:15:47,090 --> 00:15:54,020
comparison routine again it's like ten

00:15:50,600 --> 00:16:01,450
lines or something that one got me

00:15:54,020 --> 00:16:01,450
another 20% improvement here so

00:16:03,580 --> 00:16:10,880
and actually I should I should stress so

00:16:08,240 --> 00:16:13,430
this is that there's a massive data

00:16:10,880 --> 00:16:16,540
store distributed data store this time

00:16:13,430 --> 00:16:19,279
includes the time to get it off the disk

00:16:16,540 --> 00:16:21,770
in others it is fundamentally

00:16:19,279 --> 00:16:26,320
bottlenecked on i/o but I was making 20%

00:16:21,770 --> 00:16:29,080
improvements in the whole call by making

00:16:26,320 --> 00:16:32,380
effectively tiny changes to the go code

00:16:29,080 --> 00:16:36,290
so do really worried about your garbage

00:16:32,380 --> 00:16:39,350
ok stack versus heap everyone knows this

00:16:36,290 --> 00:16:43,910
right the who who doesn't quite

00:16:39,350 --> 00:16:46,190
understand stack and heap in go a couple

00:16:43,910 --> 00:16:49,580
of people ok so first thing I should I

00:16:46,190 --> 00:16:51,589
should disclaimer it's not it's not the

00:16:49,580 --> 00:16:54,020
law that there's like a stack and a heap

00:16:51,589 --> 00:16:56,720
it just happens to be that way today and

00:16:54,020 --> 00:16:58,250
the implementation and they you know

00:16:56,720 --> 00:16:59,900
they could make improvements some of the

00:16:58,250 --> 00:17:04,309
things I'm saying could become false in

00:16:59,900 --> 00:17:06,370
the future but at the moment it's pretty

00:17:04,309 --> 00:17:09,079
likely if you do something like this

00:17:06,370 --> 00:17:11,329
your variable will be on the stack and

00:17:09,079 --> 00:17:14,650
if you do something like this then your

00:17:11,329 --> 00:17:18,559
slice will be on the heap so what I mean

00:17:14,650 --> 00:17:21,230
so there you go stack versus heap stacks

00:17:18,559 --> 00:17:24,350
are very neat the only thing you can do

00:17:21,230 --> 00:17:26,059
is stick something on the top so when

00:17:24,350 --> 00:17:28,790
you're finished finished with it you

00:17:26,059 --> 00:17:30,350
just effectively just move the pointer

00:17:28,790 --> 00:17:33,309
don't you just say well you know I don't

00:17:30,350 --> 00:17:36,679
care about that stuff anymore bang gone

00:17:33,309 --> 00:17:38,540
heaps you need to go carefully through

00:17:36,679 --> 00:17:39,920
the whole heap trying to figure out

00:17:38,540 --> 00:17:42,679
which things you're still using in which

00:17:39,920 --> 00:17:46,130
things you earned so the stack is

00:17:42,679 --> 00:17:47,900
enormous ly faster to work with than the

00:17:46,130 --> 00:17:49,100
heap so that's why you want to you want

00:17:47,900 --> 00:17:50,920
to watch out for things that are on the

00:17:49,100 --> 00:17:56,720
heap how does things get on the heap

00:17:50,920 --> 00:17:58,429
they escape ok quiz time again and I I

00:17:56,720 --> 00:18:02,059
just I sat there for half an hour making

00:17:58,429 --> 00:18:04,370
all the fonts bigger because I saw in in

00:18:02,059 --> 00:18:09,050
earlier talks that it was quite hard to

00:18:04,370 --> 00:18:11,420
read so yeah which well we won't let it

00:18:09,050 --> 00:18:12,770
wait for you to maybe compile it or

00:18:11,420 --> 00:18:16,550
whatever so how would you find out

00:18:12,770 --> 00:18:19,790
what's going on so this is a

00:18:16,550 --> 00:18:22,640
benchmark if you run go - test - bench

00:18:19,790 --> 00:18:26,150
then goal we'll we'll run your program

00:18:22,640 --> 00:18:28,250
enough times that it takes a second so

00:18:26,150 --> 00:18:31,550
it ran my micro benchmark like 30

00:18:28,250 --> 00:18:34,550
million times and it said every time run

00:18:31,550 --> 00:18:42,290
that loop it's doing an allocation so

00:18:34,550 --> 00:18:44,630
why is that next thing - mem profile so

00:18:42,290 --> 00:18:48,740
we can see how many allocations and then

00:18:44,630 --> 00:18:52,010
you can you can do this - list so - list

00:18:48,740 --> 00:18:54,320
says show me the actual lines and put a

00:18:52,010 --> 00:18:56,630
count beside them

00:18:54,320 --> 00:18:59,510
so I said this is the number of objects

00:18:56,630 --> 00:19:03,440
allocated so it's on this line that

00:18:59,510 --> 00:19:04,730
we're allocating an object and kind of

00:19:03,440 --> 00:19:06,590
doesn't look like we're allocating an

00:19:04,730 --> 00:19:10,240
object because you know it's a constant

00:19:06,590 --> 00:19:12,970
string and there's no pointers here so

00:19:10,240 --> 00:19:17,810
you know I didn't call make you know why

00:19:12,970 --> 00:19:21,110
why is this on the heap so the next

00:19:17,810 --> 00:19:23,180
stage in this analysis is to tell the

00:19:21,110 --> 00:19:29,360
compiler to print out the escape

00:19:23,180 --> 00:19:31,010
analysis so - GC Flags GC GC does not

00:19:29,360 --> 00:19:36,380
mean garbage collection in this context

00:19:31,010 --> 00:19:39,770
it means go compiler - M says tell me

00:19:36,380 --> 00:19:41,000
about escape analysis - M - M says no

00:19:39,770 --> 00:19:44,620
really tell me about this kit you

00:19:41,000 --> 00:19:51,170
because there you can add it's kind of

00:19:44,620 --> 00:19:54,200
it's verbose I I filtered down this one

00:19:51,170 --> 00:19:57,080
command for that 110 line benchmark

00:19:54,200 --> 00:19:59,210
program prints out like a hundred lines

00:19:57,080 --> 00:20:01,550
so I filtered them down but they're all

00:19:59,210 --> 00:20:05,150
they're all marked with which light I

00:20:01,550 --> 00:20:06,800
don't want that they they're all marked

00:20:05,150 --> 00:20:10,760
with which line in your program they

00:20:06,800 --> 00:20:13,640
came from so this this is the answer

00:20:10,760 --> 00:20:17,810
here it is a parameter - an indirect

00:20:13,640 --> 00:20:21,010
call that's why it escaped and the so

00:20:17,810 --> 00:20:23,180
buff is a IO dot writer in my benchmark

00:20:21,010 --> 00:20:25,100
which I've sort of scrolled off the top

00:20:23,180 --> 00:20:29,060
of the screen but if go back to the

00:20:25,100 --> 00:20:31,130
example that's an interface that makes

00:20:29,060 --> 00:20:33,860
an indirect call

00:20:31,130 --> 00:20:36,230
if I'd actually said buff is a bike bite

00:20:33,860 --> 00:20:38,029
stop buffer it's not an interface as a

00:20:36,230 --> 00:20:40,220
concrete type and actually that

00:20:38,029 --> 00:20:45,759
parameter will not escape in that case

00:20:40,220 --> 00:20:48,230
and the program goes a lot faster so

00:20:45,759 --> 00:20:51,350
take that as read this this yeah escape

00:20:48,230 --> 00:20:54,139
I'll skip analysis is my point if you if

00:20:51,350 --> 00:20:57,139
you can't spot from the high level stats

00:20:54,139 --> 00:21:02,120
why your program is creating garbage GC

00:20:57,139 --> 00:21:07,480
flags - M - M and it will tell you why

00:21:02,120 --> 00:21:09,590
the data is going to the heap generally

00:21:07,480 --> 00:21:11,090
address passed out of a function I mean

00:21:09,590 --> 00:21:12,740
that's the sort of favorite example you

00:21:11,090 --> 00:21:14,360
can't do this and see but you can do it

00:21:12,740 --> 00:21:16,279
and go you can just return a pointer to

00:21:14,360 --> 00:21:19,610
a local variable it will escape to the

00:21:16,279 --> 00:21:20,870
heap parameters of indirect calls that's

00:21:19,610 --> 00:21:22,399
what I just talked about and that's

00:21:20,870 --> 00:21:24,259
that's the things in the brackets and

00:21:22,399 --> 00:21:30,500
the thing before the dot that's also a

00:21:24,259 --> 00:21:33,470
parameter my time is up so there you go

00:21:30,500 --> 00:21:36,400
and look at memory allocation it's

00:21:33,470 --> 00:21:45,310
always memory allocation thank you

00:21:36,400 --> 00:21:45,310

YouTube URL: https://www.youtube.com/watch?v=NS1hmEWv4Ac


