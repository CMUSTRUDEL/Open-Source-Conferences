Title: cassandra
Publication date: 2013-02-05
Playlist: FOSDEM 2012
Description: 
	FOSDEM (Free and Open Source Development European Meeting) is a European event centered around Free and Open Source software development. It is aimed at developers and all interested in the Free and Open Source news in the world. Its goals are to enable developers to meet and to promote the awareness and use of free and open source software. More info at http://fosdem.org
Captions: 
	00:00:00,260 --> 00:00:08,130
I'm I'm syllable and I will talk about

00:00:03,540 --> 00:00:10,920
the Apache Cassandra storage engine so I

00:00:08,130 --> 00:00:14,549
i work for company kong datastax that is

00:00:10,920 --> 00:00:16,379
doing support for Apache Cassandra but

00:00:14,549 --> 00:00:18,529
I'm actually they actually paying me to

00:00:16,379 --> 00:00:21,689
work on the on the Apache project

00:00:18,529 --> 00:00:25,890
full-time so pretty good for me and

00:00:21,689 --> 00:00:27,900
that's well talk about so uh I'll talk

00:00:25,890 --> 00:00:29,580
about three things likely I'll story

00:00:27,900 --> 00:00:32,880
with an introduction to dwell Apache

00:00:29,580 --> 00:00:34,530
Cassandra for maybe some of you don't

00:00:32,880 --> 00:00:36,180
know what it is so it's a distributed

00:00:34,530 --> 00:00:40,590
database but i will tell a little bit

00:00:36,180 --> 00:00:44,820
more than that and then i'll quickly

00:00:40,590 --> 00:00:47,129
explain all the data at work and and and

00:00:44,820 --> 00:00:49,110
we'll talk about the storage engine so

00:00:47,129 --> 00:00:51,059
how do we actually write stuff to the

00:00:49,110 --> 00:00:55,170
scan and read it and why we do it that

00:00:51,059 --> 00:00:58,770
way so app education rise a distributed

00:00:55,170 --> 00:01:04,400
data store and it was created to handle

00:00:58,770 --> 00:01:07,049
a large amount of data ok that is go

00:01:04,400 --> 00:01:08,520
it's an Apache project so it's an open

00:01:07,049 --> 00:01:11,880
source project it's another shipwreck

00:01:08,520 --> 00:01:13,680
since our two year februari 2010 before

00:01:11,880 --> 00:01:17,000
liked was in the Apache Incubator with

00:01:13,680 --> 00:01:19,740
top-level project since two year and

00:01:17,000 --> 00:01:23,580
actually last October we release a

00:01:19,740 --> 00:01:27,450
version one of Cassandra so we felt that

00:01:23,580 --> 00:01:30,180
it was um it was major enough to call it

00:01:27,450 --> 00:01:32,189
a version 1 and as a matter of fact even

00:01:30,180 --> 00:01:34,880
before division 1 it was using

00:01:32,189 --> 00:01:38,009
production in a number of a company

00:01:34,880 --> 00:01:42,090
including some some full lash company

00:01:38,009 --> 00:01:46,200
will further large data sets and so yet

00:01:42,090 --> 00:01:51,000
to give you an idea of size largest

00:01:46,200 --> 00:01:56,219
cluster I know about is about a little

00:01:51,000 --> 00:01:59,939
bit more than 4 400 machines and over

00:01:56,219 --> 00:02:03,479
through the terabytes of data for one

00:01:59,939 --> 00:02:06,240
cluster so ok so a personal is a

00:02:03,479 --> 00:02:07,920
database so you have a client you talk

00:02:06,240 --> 00:02:10,890
to your database you do query so you

00:02:07,920 --> 00:02:12,960
store stuff and you get stuff directly

00:02:10,890 --> 00:02:16,680
what does but it's a

00:02:12,960 --> 00:02:20,490
distributed one so you your database we

00:02:16,680 --> 00:02:23,640
usually have multiple nodes multiple

00:02:20,490 --> 00:02:25,860
machines call nodes and while the goal

00:02:23,640 --> 00:02:29,040
is you can you can actually scale that

00:02:25,860 --> 00:02:31,770
but one thing with the cassandra is a

00:02:29,040 --> 00:02:33,390
fully decentralized system so every of

00:02:31,770 --> 00:02:37,350
those node will actually run the same

00:02:33,390 --> 00:02:40,200
software and each node will know node

00:02:37,350 --> 00:02:42,780
will be specific okay so it's completely

00:02:40,200 --> 00:02:44,580
distributed there is no you know master

00:02:42,780 --> 00:02:49,620
node and slave nodes every node is the

00:02:44,580 --> 00:02:51,660
same it's also replicated database so

00:02:49,620 --> 00:02:53,910
when you when you store data that I

00:02:51,660 --> 00:02:57,060
would be distributed so not every node

00:02:53,910 --> 00:03:00,180
will have a copy of every data that

00:02:57,060 --> 00:03:03,000
being said data is usually replicated so

00:03:00,180 --> 00:03:04,860
replication is built a is building

00:03:03,000 --> 00:03:09,900
Cassandra for from the beginning that's

00:03:04,860 --> 00:03:11,430
a that's a native way it works which

00:03:09,900 --> 00:03:14,190
means that every data will be actually

00:03:11,430 --> 00:03:16,260
replicating more than one node usually

00:03:14,190 --> 00:03:18,960
you can configure you can choose so many

00:03:16,260 --> 00:03:21,630
time each data is replicated and the

00:03:18,960 --> 00:03:25,560
database actually figure out where each

00:03:21,630 --> 00:03:29,460
data should go so it's also a durable

00:03:25,560 --> 00:03:31,710
data store now because it's not an

00:03:29,460 --> 00:03:33,840
in-memory big and I an in-memory grid or

00:03:31,710 --> 00:03:37,370
something like that we do persist

00:03:33,840 --> 00:03:40,140
everything to disk so it's locally a

00:03:37,370 --> 00:03:42,180
durable but it's also it's also

00:03:40,140 --> 00:03:44,370
replicated so you'll still get you

00:03:42,180 --> 00:03:47,520
actually get very very strong durability

00:03:44,370 --> 00:03:50,030
guarantees thanks to replication and the

00:03:47,520 --> 00:03:55,800
fact that we actually are even tech

00:03:50,030 --> 00:03:57,900
durability seriously locally and one of

00:03:55,800 --> 00:04:02,250
the main thing you want is it to be

00:03:57,900 --> 00:04:04,290
scalable scalable mill are two things it

00:04:02,250 --> 00:04:07,200
means that you can add noon and noodles

00:04:04,290 --> 00:04:09,570
easily and it means that when you add

00:04:07,200 --> 00:04:13,500
new nose you are the capacity of the

00:04:09,570 --> 00:04:16,710
cluster we all truly scale linearly with

00:04:13,500 --> 00:04:18,270
the wealth and amount of nodes so the

00:04:16,710 --> 00:04:19,739
way you actually add a new node while

00:04:18,270 --> 00:04:22,590
you start a new node with the software

00:04:19,739 --> 00:04:24,660
and you say you know you configure a few

00:04:22,590 --> 00:04:26,910
IP address that i can connect to the

00:04:24,660 --> 00:04:29,580
other nodes and then you say bootstrap

00:04:26,910 --> 00:04:32,340
and it will join so we call it the ring

00:04:29,580 --> 00:04:35,580
the cluster ring because the way we

00:04:32,340 --> 00:04:37,560
distribute things is by using something

00:04:35,580 --> 00:04:39,990
called a consistent hashing which

00:04:37,560 --> 00:04:41,790
considered the machine on a ring but i

00:04:39,990 --> 00:04:44,880
won't give two minutes down that you can

00:04:41,790 --> 00:04:47,840
check a consistent hashing online but so

00:04:44,880 --> 00:04:50,060
you you ask a note to join any join

00:04:47,840 --> 00:04:54,630
that's that i will be redistributed

00:04:50,060 --> 00:04:56,820
during that operation but it's all done

00:04:54,630 --> 00:04:59,790
under the hood and as a client you don't

00:04:56,820 --> 00:05:02,400
you don't see that happening another

00:04:59,790 --> 00:05:06,450
thing that it's faltaron so it's built

00:05:02,400 --> 00:05:08,940
so that even if a node fail you don't

00:05:06,450 --> 00:05:10,830
see it well hopefully the operator will

00:05:08,940 --> 00:05:14,700
see it and we replayed that at some

00:05:10,830 --> 00:05:19,920
point but at least the user the client

00:05:14,700 --> 00:05:21,780
won't see the failure and because it's

00:05:19,920 --> 00:05:23,790
fully decentralized there is no single

00:05:21,780 --> 00:05:26,040
point of failure so there is no note

00:05:23,790 --> 00:05:28,500
that if it fails well the world cluster

00:05:26,040 --> 00:05:31,860
is down every node is the same so

00:05:28,500 --> 00:05:33,600
everyone can fail this is what we call

00:05:31,860 --> 00:05:35,250
highly available which is a little bit

00:05:33,600 --> 00:05:38,070
of the same thing as full torrent which

00:05:35,250 --> 00:05:40,140
is it tolerate fault but it's really

00:05:38,070 --> 00:05:42,480
transparent even if no they are done you

00:05:40,140 --> 00:05:44,520
can still insert seeing and get stuff

00:05:42,480 --> 00:05:46,650
obviously if you replicate that out only

00:05:44,520 --> 00:05:48,150
once and one node is done you won't be

00:05:46,650 --> 00:05:50,040
able to exit that on that note but

00:05:48,150 --> 00:05:53,070
usually a out more and more replicates

00:05:50,040 --> 00:05:57,750
so you can tolerate some amount of

00:05:53,070 --> 00:05:59,850
failure foolish transparently okay and

00:05:57,750 --> 00:06:02,580
the last thing I want says it's a data

00:05:59,850 --> 00:06:04,140
center where so it's it's built to know

00:06:02,580 --> 00:06:06,900
that data center so you can actually

00:06:04,140 --> 00:06:08,790
have a cluster that cross multiple data

00:06:06,900 --> 00:06:10,680
center you may have one in the US you

00:06:08,790 --> 00:06:13,230
may have one in Europe you can have more

00:06:10,680 --> 00:06:18,500
than that and and they will all form

00:06:13,230 --> 00:06:20,910
only one cluster okay but but the the

00:06:18,500 --> 00:06:24,000
cluster will still be aware of the of

00:06:20,910 --> 00:06:27,870
the data center so what that mean is you

00:06:24,000 --> 00:06:32,040
can for example do things like I want to

00:06:27,870 --> 00:06:33,600
replicate data twice but I want to be

00:06:32,040 --> 00:06:35,970
sure that there is one copy on the data

00:06:33,600 --> 00:06:38,160
in Europe and one copy of that I in the

00:06:35,970 --> 00:06:39,960
US I don't want to have to copy in

00:06:38,160 --> 00:06:40,380
Europe and 0 in the u.s. because the

00:06:39,960 --> 00:06:45,090
goal

00:06:40,380 --> 00:06:47,910
if I lose 11 data center I don't want to

00:06:45,090 --> 00:06:51,210
have prone so you can do that and the

00:06:47,910 --> 00:06:54,120
other thing is that a replication is

00:06:51,210 --> 00:06:56,160
aware of that in the sense that it's

00:06:54,120 --> 00:06:57,570
optimized so for example if you have to

00:06:56,160 --> 00:07:00,300
replicate in the US and you write

00:06:57,570 --> 00:07:03,270
something in Europe so I didn't say a

00:07:00,300 --> 00:07:05,670
client can connect to any node and the

00:07:03,270 --> 00:07:07,980
rest is endowed by a database so oh you

00:07:05,670 --> 00:07:10,800
connect you connect to any node whatever

00:07:07,980 --> 00:07:13,650
you want and the the database with will

00:07:10,800 --> 00:07:17,100
route the request so if you write in

00:07:13,650 --> 00:07:18,990
real Europe and you have to and you need

00:07:17,100 --> 00:07:21,180
to replicate that twice to the US it

00:07:18,990 --> 00:07:23,580
will actually send only one copy over

00:07:21,180 --> 00:07:27,750
the Atlantic and then it were writing

00:07:23,580 --> 00:07:30,180
two nodes in the US and even when you do

00:07:27,750 --> 00:07:33,120
an operation you can actually ask the

00:07:30,180 --> 00:07:35,400
database to you can to respect a given

00:07:33,120 --> 00:07:39,300
contract so for example we can do is say

00:07:35,400 --> 00:07:40,800
I want to write something and as soon as

00:07:39,300 --> 00:07:44,910
the replica in Europe are I've

00:07:40,800 --> 00:07:47,070
acknowledged my my my right i'm good i'm

00:07:44,910 --> 00:07:50,400
ok that the replication in the u.s. is

00:07:47,070 --> 00:07:52,590
actually I see a synchronous because i

00:07:50,400 --> 00:07:55,110
don't know maybe if i pass the story on

00:07:52,590 --> 00:07:58,890
something I just want that when i

00:07:55,110 --> 00:08:01,290
refresh the page I can see my update but

00:07:58,890 --> 00:08:03,900
if it takes one or two seconds to get in

00:08:01,290 --> 00:08:05,730
the US that's okay they won't know that

00:08:03,900 --> 00:08:12,450
I did it say that once they're going to

00:08:05,730 --> 00:08:15,000
go anyway so okay that that was that was

00:08:12,450 --> 00:08:19,080
badly what Cassandra is but I won't talk

00:08:15,000 --> 00:08:22,320
too much of all these replication thing

00:08:19,080 --> 00:08:23,880
what I want to talk today is oh so you

00:08:22,320 --> 00:08:25,860
can there is a lot of documentation

00:08:23,880 --> 00:08:27,750
online on that but what I won't say what

00:08:25,860 --> 00:08:29,970
happened on one on those on those box

00:08:27,750 --> 00:08:33,270
when you receive a query and before that

00:08:29,970 --> 00:08:37,620
I have to say a few words about the data

00:08:33,270 --> 00:08:39,660
mo so first thing is not ask you all ok

00:08:37,620 --> 00:08:44,760
it's a customized what we usually call

00:08:39,660 --> 00:08:48,120
no there is no SQL database it's not

00:08:44,760 --> 00:08:50,370
well you know it's not necessarily

00:08:48,120 --> 00:08:52,050
completely opposed to SQL but what it

00:08:50,370 --> 00:08:54,510
means is that doesn't do

00:08:52,050 --> 00:08:56,459
it doesn't do everything that SQL does

00:08:54,510 --> 00:08:58,800
in particular it doesn't do transaction

00:08:56,459 --> 00:09:01,019
it doesn't rejoint and the reason is

00:08:58,800 --> 00:09:04,350
very simple is if you actually start to

00:09:01,019 --> 00:09:08,810
scale that a base and it's kill it or

00:09:04,350 --> 00:09:11,279
isn't Leon many machines well joins an

00:09:08,810 --> 00:09:13,829
transaction to a lesser extent are

00:09:11,279 --> 00:09:18,480
actually art to do very fast and so

00:09:13,829 --> 00:09:20,579
while we don't try but what I want to

00:09:18,480 --> 00:09:23,040
say here is it's more than a key value

00:09:20,579 --> 00:09:25,620
store I will give a number of example

00:09:23,040 --> 00:09:27,600
it's not just you put some value and you

00:09:25,620 --> 00:09:30,360
and you get it with a key you can do

00:09:27,600 --> 00:09:33,149
much more important stuff much more

00:09:30,360 --> 00:09:34,890
interesting stuff and the data model is

00:09:33,149 --> 00:09:37,649
actually inspired by something called

00:09:34,890 --> 00:09:38,940
google big table so you know Google

00:09:37,649 --> 00:09:40,800
right that database that they actually

00:09:38,940 --> 00:09:44,880
use internally but they publish a paper

00:09:40,800 --> 00:09:47,610
like 2004 i believe and and you know

00:09:44,880 --> 00:09:51,029
they have a data model that locally bit

00:09:47,610 --> 00:09:53,250
like that because the tyler mall was

00:09:51,029 --> 00:09:56,550
inspired it's not the same but it it's

00:09:53,250 --> 00:10:00,270
inspired and it's what we call a cone

00:09:56,550 --> 00:10:04,170
family-based ok but to see the cone

00:10:00,270 --> 00:10:05,940
families is kind of a table so let's

00:10:04,170 --> 00:10:08,010
take an example okay let's take an

00:10:05,940 --> 00:10:11,190
example let's say a very simple example

00:10:08,010 --> 00:10:14,640
i want to you know rewrite a twitter

00:10:11,190 --> 00:10:17,010
clone okay i want to take over twitter

00:10:14,640 --> 00:10:19,740
and i want to sort that in my database

00:10:17,010 --> 00:10:22,290
so first thing I need to store is the

00:10:19,740 --> 00:10:24,470
user profile user will create a profile

00:10:22,290 --> 00:10:27,899
you want to all the data for those users

00:10:24,470 --> 00:10:30,480
so if you if you do that you will first

00:10:27,899 --> 00:10:33,510
start creating a comment family so that

00:10:30,480 --> 00:10:37,260
the yellow stuff my cone family is

00:10:33,510 --> 00:10:39,510
called users and what Mike own family

00:10:37,260 --> 00:10:42,690
will do it it will for each user it will

00:10:39,510 --> 00:10:45,480
keep the profile of the user so you know

00:10:42,690 --> 00:10:48,720
Khan family is kind of a table inside a

00:10:45,480 --> 00:10:53,970
inside a cone family you have rose

00:10:48,720 --> 00:10:57,810
that's a row okay in a row a row as as a

00:10:53,970 --> 00:11:00,630
key which is the greenie thing which is

00:10:57,810 --> 00:11:05,010
the rookie you can you can think of that

00:11:00,630 --> 00:11:05,430
as a primary key for ah the row but we

00:11:05,010 --> 00:11:08,370
call the

00:11:05,430 --> 00:11:10,620
rocky okay and in my example that would

00:11:08,370 --> 00:11:12,660
be a user ID so that can be anything

00:11:10,620 --> 00:11:14,760
that could be that could be the email of

00:11:12,660 --> 00:11:19,560
the user so in my example I've taken

00:11:14,760 --> 00:11:22,200
some you know random user ID as a side

00:11:19,560 --> 00:11:25,440
note in a you know SQL database you

00:11:22,200 --> 00:11:28,080
would usually use some auto increment

00:11:25,440 --> 00:11:30,930
for user ID but in a distributed

00:11:28,080 --> 00:11:34,470
database auto increment is the prettier

00:11:30,930 --> 00:11:38,399
thing to do so you use other stuff I'll

00:11:34,470 --> 00:11:41,760
typically you IDs that's and in a row

00:11:38,399 --> 00:11:45,839
what you have is columns okay so column

00:11:41,760 --> 00:11:49,589
is a well a pair of a of a name and the

00:11:45,839 --> 00:11:52,980
value ok so the you know first name here

00:11:49,589 --> 00:11:56,310
is the is the common name and justin is

00:11:52,980 --> 00:11:58,430
the cone value so in a row i will have a

00:11:56,310 --> 00:12:01,380
number of columns so in that example

00:11:58,430 --> 00:12:03,990
okay for my user i will store the first

00:12:01,380 --> 00:12:06,480
name the last name the burst here and i

00:12:03,990 --> 00:12:08,430
can and more that and my comb family

00:12:06,480 --> 00:12:11,779
will be you know will be composed of all

00:12:08,430 --> 00:12:16,050
those roads so i may have another user

00:12:11,779 --> 00:12:19,770
it will have a new on a new user ID and

00:12:16,050 --> 00:12:22,200
it will have his own progress the first

00:12:19,770 --> 00:12:25,080
thing to notice here is that not every

00:12:22,200 --> 00:12:27,930
row need to have the same column in it

00:12:25,080 --> 00:12:30,000
okay my second new user of an email but

00:12:27,930 --> 00:12:34,770
the first one maybe didn't give me an

00:12:30,000 --> 00:12:37,800
email so you can sing that as a no but

00:12:34,770 --> 00:12:40,200
the difference is we didn't define a

00:12:37,800 --> 00:12:44,130
schema for that so it's a schema less

00:12:40,200 --> 00:12:48,060
database which mean that if you want to

00:12:44,130 --> 00:12:52,350
a new priority to user and you have a 4

00:12:48,060 --> 00:12:54,029
400 million user and you debase you

00:12:52,350 --> 00:12:57,600
don't have to do an elder table that

00:12:54,029 --> 00:12:59,760
will take days or weeks to actually work

00:12:57,600 --> 00:13:03,779
so that's that's the reason why katsuma

00:12:59,760 --> 00:13:06,810
actually as a schema as well that one of

00:13:03,779 --> 00:13:08,970
the reason why it's kim out okay that's

00:13:06,810 --> 00:13:12,870
a fine example that's fairly simple one

00:13:08,970 --> 00:13:15,750
so take another one exam and so here i

00:13:12,870 --> 00:13:18,550
want to write to twitter clone so one

00:13:15,750 --> 00:13:22,560
other thing i want to do is to store the

00:13:18,550 --> 00:13:26,140
it's that an user made so what I want is

00:13:22,560 --> 00:13:28,000
when the user clicks on my tweets I want

00:13:26,140 --> 00:13:32,380
to show him East weights and I want to

00:13:28,000 --> 00:13:34,810
do that in a chronological order so i

00:13:32,380 --> 00:13:37,029
will create a new con son Lee that are

00:13:34,810 --> 00:13:39,850
called timeline and inside I will have

00:13:37,029 --> 00:13:42,610
rows and each for each user I will on

00:13:39,850 --> 00:13:47,550
one row and as my previous example the

00:13:42,610 --> 00:13:50,529
the rocky will be the user the user

00:13:47,550 --> 00:13:55,329
identifier so that's my justin bieber

00:13:50,529 --> 00:13:57,550
user here and the user we'll do twit so

00:13:55,329 --> 00:14:00,130
when it tweets something will insert a

00:13:57,550 --> 00:14:03,100
column and the column name will be a

00:14:00,130 --> 00:14:04,839
timestamp so 0 i will use 0 1 2 3

00:14:03,100 --> 00:14:06,760
because it's an example but in real life

00:14:04,839 --> 00:14:09,880
that would be a timestamp of when the

00:14:06,760 --> 00:14:13,870
tweet has been made to our associate but

00:14:09,880 --> 00:14:19,870
the timestamp to the text of the twit

00:14:13,870 --> 00:14:21,910
okay both names and colon a both name

00:14:19,870 --> 00:14:23,589
and value in a colon and actually bite

00:14:21,910 --> 00:14:25,930
sorry for Cassandra's so you can store

00:14:23,589 --> 00:14:27,940
everything you want in it and in

00:14:25,930 --> 00:14:29,770
particular are you can hear i just

00:14:27,940 --> 00:14:33,370
toured the text but i could store the

00:14:29,770 --> 00:14:35,560
text and i could add an info on on which

00:14:33,370 --> 00:14:38,470
device that which was done or anything

00:14:35,560 --> 00:14:42,160
so you can do all that but that's simple

00:14:38,470 --> 00:14:45,880
example and when the user do more tweets

00:14:42,160 --> 00:14:49,089
will will add to it but what i want to

00:14:45,880 --> 00:14:52,660
notice here is that in in a row the

00:14:49,089 --> 00:14:56,560
columns are ordered so there's an order

00:14:52,660 --> 00:14:58,779
in a row the actual order for the row is

00:14:56,560 --> 00:15:01,540
something define the Cohen family so

00:14:58,779 --> 00:15:04,480
each cone family will define the order

00:15:01,540 --> 00:15:07,829
of the column in the rose okay in that

00:15:04,480 --> 00:15:10,300
example I I pick a you know reverse

00:15:07,829 --> 00:15:12,730
integer order so that's something pretty

00:15:10,300 --> 00:15:15,880
fine but you can actually write your own

00:15:12,730 --> 00:15:17,380
comparator so there's some poor coming

00:15:15,880 --> 00:15:21,060
from that so you can do interesting

00:15:17,380 --> 00:15:23,949
stuff but there always is a an order so

00:15:21,060 --> 00:15:26,470
when the user will do tweets will add

00:15:23,949 --> 00:15:29,020
this in the chronological order so as

00:15:26,470 --> 00:15:31,910
you can imagine the interests of that is

00:15:29,020 --> 00:15:34,130
that if the query you want to do and

00:15:31,910 --> 00:15:36,980
slightly what you want is asked what are

00:15:34,130 --> 00:15:39,440
the last ten tweets that this user made

00:15:36,980 --> 00:15:42,410
while we're able to answer that very

00:15:39,440 --> 00:15:45,080
very quickly because we just find the

00:15:42,410 --> 00:15:48,560
row for that user and just read data

00:15:45,080 --> 00:15:51,230
starting from that point and and and

00:15:48,560 --> 00:15:54,830
that's it so there will be like 16

00:15:51,230 --> 00:15:56,780
vehicle and you can also a person that

00:15:54,830 --> 00:15:59,870
you do is you can imagine there is there

00:15:56,780 --> 00:16:02,180
is tons of co on and you can do a slice

00:15:59,870 --> 00:16:05,900
of a row so you can ask you know what

00:16:02,180 --> 00:16:08,870
are the tweets for you know one week

00:16:05,900 --> 00:16:11,810
three weeks ago give me all the twists

00:16:08,870 --> 00:16:13,520
that this user did three weeks ago so

00:16:11,810 --> 00:16:16,610
sing like that you can answer just

00:16:13,520 --> 00:16:19,190
because it's chronological order and so

00:16:16,610 --> 00:16:21,230
the second remark is that the row can

00:16:19,190 --> 00:16:24,200
actually have lots and lots and left of

00:16:21,230 --> 00:16:25,850
Cola okay there's there's actually is a

00:16:24,200 --> 00:16:28,790
limit on the number of columns you can

00:16:25,850 --> 00:16:32,390
have in one row but that limit is two

00:16:28,790 --> 00:16:34,940
billion so you have you can still put a

00:16:32,390 --> 00:16:37,550
number of saying you know when a user

00:16:34,940 --> 00:16:39,500
has as tweet 2 billion tweets you can

00:16:37,550 --> 00:16:42,440
start you know thinking about solution

00:16:39,500 --> 00:16:44,960
to actually use maybe to roll for for

00:16:42,440 --> 00:16:49,730
that user but usually not not a big

00:16:44,960 --> 00:16:52,430
problem so yeah that the way you you

00:16:49,730 --> 00:16:54,410
would use the that the basics that's

00:16:52,430 --> 00:16:56,240
really is the basic of the data model so

00:16:54,410 --> 00:16:58,460
you have kind of static information

00:16:56,240 --> 00:17:00,710
where every through we have some set of

00:16:58,460 --> 00:17:02,570
info but then you can do much more

00:17:00,710 --> 00:17:05,090
interesting thing by using the fact that

00:17:02,570 --> 00:17:09,620
the the rules are a number of column

00:17:05,090 --> 00:17:11,720
that is that can be pretty large and the

00:17:09,620 --> 00:17:15,410
fact that those are sorted so you can do

00:17:11,720 --> 00:17:17,360
a number of query very efficiently we do

00:17:15,410 --> 00:17:20,120
we do have a I won't go into the details

00:17:17,360 --> 00:17:23,000
but we do have more more interesting

00:17:20,120 --> 00:17:24,800
stuff that all to modeling much more

00:17:23,000 --> 00:17:27,170
easily so we have things like secondary

00:17:24,800 --> 00:17:30,170
indexes if I take my first example the

00:17:27,170 --> 00:17:32,630
profile I can I can create an index on

00:17:30,170 --> 00:17:35,060
the burst here of the user so if I do

00:17:32,630 --> 00:17:37,970
that I'll be able to query well give me

00:17:35,060 --> 00:17:40,040
all the user that are born in the 80s

00:17:37,970 --> 00:17:42,560
for example okay and you can do that oh

00:17:40,040 --> 00:17:44,930
what the database will actually do that

00:17:42,560 --> 00:17:45,680
automatically for you we have something

00:17:44,930 --> 00:17:50,000
called these two

00:17:45,680 --> 00:17:51,920
so well they are just counters but

00:17:50,000 --> 00:17:54,950
because that distributed storage is

00:17:51,920 --> 00:17:57,740
distributed cameras but it's basically

00:17:54,950 --> 00:18:00,380
using the column value if you use that

00:17:57,740 --> 00:18:03,770
it's a common value that just is an int

00:18:00,380 --> 00:18:06,440
and insert insert instead of setting the

00:18:03,770 --> 00:18:08,870
value you actually say increment the

00:18:06,440 --> 00:18:11,360
value by that many are determine the

00:18:08,870 --> 00:18:13,070
value by that many and you can do all of

00:18:11,360 --> 00:18:16,630
those and the database will aggregate

00:18:13,070 --> 00:18:20,030
everything and we have things like

00:18:16,630 --> 00:18:25,820
composite columns so composite columns

00:18:20,030 --> 00:18:29,450
are a column is just a name and a value

00:18:25,820 --> 00:18:31,880
but in fact because that can be anything

00:18:29,450 --> 00:18:34,730
any bite array you can actually stuff

00:18:31,880 --> 00:18:37,280
stuff a number of information both in

00:18:34,730 --> 00:18:40,070
the name and basing the value so you can

00:18:37,280 --> 00:18:43,250
for example you know as a name that is

00:18:40,070 --> 00:18:45,290
composed of multiple component and you

00:18:43,250 --> 00:18:47,120
can define the comparison so that its

00:18:45,290 --> 00:18:49,490
first compare the first value and then

00:18:47,120 --> 00:18:51,980
the second one and the third one and we

00:18:49,490 --> 00:18:54,500
have built-in support for that same

00:18:51,980 --> 00:18:57,200
thing for the value as I said previously

00:18:54,500 --> 00:18:59,270
you could have the tweet of the net the

00:18:57,200 --> 00:19:01,910
sorry the text of the tweet but you can

00:18:59,270 --> 00:19:03,620
have a wisdom in the value you can add

00:19:01,910 --> 00:19:05,570
on with device the tweet was done

00:19:03,620 --> 00:19:09,650
anything like that and you can put all

00:19:05,570 --> 00:19:14,870
that in in a in a in a volume so okay

00:19:09,650 --> 00:19:19,100
that's that's what we are and know what

00:19:14,870 --> 00:19:24,350
I want to talk about is given this data

00:19:19,100 --> 00:19:31,330
model how do we actually store things to

00:19:24,350 --> 00:19:31,330
disk so what do what is the goal here

00:19:31,960 --> 00:19:40,070
one of the goal of Cassandra was too so

00:19:37,250 --> 00:19:42,110
there is one thing that I'm claiming you

00:19:40,070 --> 00:19:45,830
can disagree with I'm claiming that

00:19:42,110 --> 00:19:52,310
right are usually order to scale than

00:19:45,830 --> 00:19:56,870
read and the reason is that if you write

00:19:52,310 --> 00:19:59,360
something you have to you have to write

00:19:56,870 --> 00:20:01,429
the data on disk okay

00:19:59,360 --> 00:20:03,679
but when you do read you can always put

00:20:01,429 --> 00:20:07,400
more caching if you really want to scale

00:20:03,679 --> 00:20:09,890
with we kind of know to do that we add

00:20:07,400 --> 00:20:13,520
more caching or we add more you know we

00:20:09,890 --> 00:20:16,640
duplicate data and we are no more nodes

00:20:13,520 --> 00:20:18,020
to read but you cannot do caching for

00:20:16,640 --> 00:20:19,880
the rights because the goal is to

00:20:18,020 --> 00:20:23,600
actually write it to disk so it doesn't

00:20:19,880 --> 00:20:25,280
disappear and you cannot if you

00:20:23,600 --> 00:20:29,000
duplicate the number of nodes where you

00:20:25,280 --> 00:20:31,520
have your data for you read to be to add

00:20:29,000 --> 00:20:34,610
more read capacity you're actually

00:20:31,520 --> 00:20:40,850
writing more stuff so it's actually make

00:20:34,610 --> 00:20:42,940
it harder for the right so so a lot of

00:20:40,850 --> 00:20:46,900
people wearable to scale reads

00:20:42,940 --> 00:20:49,460
reasonably it's not a wealth simple but

00:20:46,900 --> 00:20:51,650
by the rights were sometimes a little

00:20:49,460 --> 00:20:56,840
bit order so what cassandra tries to do

00:20:51,650 --> 00:21:00,890
is to neck right as fast as it can and

00:20:56,840 --> 00:21:04,100
say well well try them to Reed's will be

00:21:00,890 --> 00:21:06,770
probably a little bit easier and the

00:21:04,100 --> 00:21:10,160
second thing is that cassandra is made

00:21:06,770 --> 00:21:12,679
to work on a commodity hardware so the

00:21:10,160 --> 00:21:16,070
goal is you take a lot of you know you

00:21:12,679 --> 00:21:18,200
text servers but probably not too fancy

00:21:16,070 --> 00:21:20,030
servers and you put all of them and

00:21:18,200 --> 00:21:23,480
that's the way you scale that not buying

00:21:20,030 --> 00:21:25,210
very expensive software and so in

00:21:23,480 --> 00:21:28,549
particular what you want to do is uh

00:21:25,210 --> 00:21:31,240
usually with you spinning disk for for

00:21:28,549 --> 00:21:34,640
that caneva things because spinning disk

00:21:31,240 --> 00:21:39,020
cost compared to what you can store

00:21:34,640 --> 00:21:41,690
spinning disk doesn't cost very much and

00:21:39,020 --> 00:21:43,340
and the thing is as plain this is very

00:21:41,690 --> 00:21:46,100
bad with random i/o so that's something

00:21:43,340 --> 00:21:47,840
to take into into account so if we want

00:21:46,100 --> 00:21:49,669
to and if you do right you will actually

00:21:47,840 --> 00:21:51,950
do all over in the Mayo if you have to

00:21:49,669 --> 00:21:54,410
know modify your database you're right

00:21:51,950 --> 00:21:55,880
your rights will be distributed

00:21:54,410 --> 00:21:57,919
everywhere on you that I said so we have

00:21:55,880 --> 00:22:00,530
to change your files everywhere so the

00:21:57,919 --> 00:22:03,770
goal is to minimize random i/o so how do

00:22:00,530 --> 00:22:08,270
we do that we use something called log

00:22:03,770 --> 00:22:10,700
structures storage I practically work

00:22:08,270 --> 00:22:12,800
that way so you have a node it has some

00:22:10,700 --> 00:22:14,720
are drives and memory

00:22:12,800 --> 00:22:18,200
and what we want to do is write

00:22:14,720 --> 00:22:20,570
something so what won't write is well a

00:22:18,200 --> 00:22:25,220
given column so available column is an

00:22:20,570 --> 00:22:26,660
easy now is in a row so what you give

00:22:25,220 --> 00:22:30,260
when you want to write something you

00:22:26,660 --> 00:22:34,730
give a row key k1 and you give a column

00:22:30,260 --> 00:22:37,850
so c1 with a value v1 you want to write

00:22:34,730 --> 00:22:40,040
that so I assume that it's in one cone

00:22:37,850 --> 00:22:42,380
family there would be another parameter

00:22:40,040 --> 00:22:44,390
which is the Cohen family but let's say

00:22:42,380 --> 00:22:48,350
that I'm writing in one given confirm

00:22:44,390 --> 00:22:51,350
any for example so when we do when we do

00:22:48,350 --> 00:22:57,380
that right we actually okay we actually

00:22:51,350 --> 00:23:00,380
do two things we first write the data in

00:22:57,380 --> 00:23:03,380
something in a instructor in memory that

00:23:00,380 --> 00:23:06,710
we call an end table so we write the you

00:23:03,380 --> 00:23:09,950
know the column k 1 the column c1 in the

00:23:06,710 --> 00:23:12,800
row k 1 and the name table is really

00:23:09,950 --> 00:23:15,590
kind of an ash map of the real key to

00:23:12,800 --> 00:23:18,050
the columns that it contains so the

00:23:15,590 --> 00:23:21,740
window beam table is is empty i just add

00:23:18,050 --> 00:23:24,530
this new this new entry that for k1 I I

00:23:21,740 --> 00:23:29,540
have a column c1 and the thing that we

00:23:24,530 --> 00:23:31,730
do is we do right the right on the on

00:23:29,540 --> 00:23:35,920
disk and we write it in something called

00:23:31,730 --> 00:23:39,580
the comic lot what the commit log do is

00:23:35,920 --> 00:23:43,640
so in the commit log we will write

00:23:39,580 --> 00:23:45,980
queries right Prairie as they as they

00:23:43,640 --> 00:23:48,200
come ok so the commit log is a nap and

00:23:45,980 --> 00:23:51,800
only structure we always add stuff to

00:23:48,200 --> 00:23:54,410
the end and because we do that the

00:23:51,800 --> 00:23:56,150
commit log wounds the commit log womb do

00:23:54,410 --> 00:23:57,980
random i/o it will be sequential I oh

00:23:56,150 --> 00:24:00,490
you just write stuff at the end you

00:23:57,980 --> 00:24:04,790
don't have to move anything on the disk

00:24:00,490 --> 00:24:06,590
but for that to work you need to have

00:24:04,790 --> 00:24:08,630
the commit luck to be on a separate disk

00:24:06,590 --> 00:24:11,420
so that it doesn't do something else

00:24:08,630 --> 00:24:13,250
that it actually do run the mile just to

00:24:11,420 --> 00:24:16,730
come back to the end of that structure

00:24:13,250 --> 00:24:19,370
so that's that's Cassandra configuration

00:24:16,730 --> 00:24:22,160
101 you put your commit log in a

00:24:19,370 --> 00:24:24,350
separate disk you don't have to but you

00:24:22,160 --> 00:24:26,890
won't get the same preferences if you if

00:24:24,350 --> 00:24:30,350
you don't do it so

00:24:26,890 --> 00:24:32,690
everything basically does it and as

00:24:30,350 --> 00:24:34,220
we'll see you don't need a big disk to

00:24:32,690 --> 00:24:36,650
all those commits logs because it will

00:24:34,220 --> 00:24:38,570
actually be removed and and you can

00:24:36,650 --> 00:24:40,550
actually control the size that it can

00:24:38,570 --> 00:24:42,650
take so if you have a disk of 80 gigs

00:24:40,550 --> 00:24:45,170
you can say I don't want my commit luck

00:24:42,650 --> 00:24:47,720
to be more than 80 gigs and you know

00:24:45,170 --> 00:24:53,929
Cassandra we will deal with that so that

00:24:47,720 --> 00:24:57,170
doesn't become that big and when we've

00:24:53,929 --> 00:24:59,660
done that well we're done for that right

00:24:57,170 --> 00:25:03,080
so we actually acknowledge the clients

00:24:59,660 --> 00:25:08,360
we consider well for that node data is

00:25:03,080 --> 00:25:11,030
written so if there is a failure now we

00:25:08,360 --> 00:25:14,660
do have the data on disk so we have we

00:25:11,030 --> 00:25:16,790
have synced that data and the not die

00:25:14,660 --> 00:25:18,830
will restart the node and what the not

00:25:16,790 --> 00:25:21,770
will do it will replay the commit log so

00:25:18,830 --> 00:25:24,020
it will just replay the insert that you

00:25:21,770 --> 00:25:26,750
know where in memory only and hasn't

00:25:24,020 --> 00:25:34,910
been really persisted yet to disk in a

00:25:26,750 --> 00:25:38,210
more stricter it on disk format so all

00:25:34,910 --> 00:25:40,730
right so we'll we'll get more will

00:25:38,210 --> 00:25:42,860
continue receiving rights so of course

00:25:40,730 --> 00:25:44,450
we can actually receive right for more

00:25:42,860 --> 00:25:47,150
than one columns you don't have to write

00:25:44,450 --> 00:25:48,950
one kanal time you can write multiple go

00:25:47,150 --> 00:25:51,800
online time in fact you can actually

00:25:48,950 --> 00:25:54,970
write multiple column in multiple rows

00:25:51,800 --> 00:25:58,970
at a time but let's keep it simple and

00:25:54,970 --> 00:26:02,840
so you write things you can write two

00:25:58,970 --> 00:26:05,570
columns so in the mem table will add a

00:26:02,840 --> 00:26:09,830
new entry for 4k to we actually added to

00:26:05,570 --> 00:26:13,550
2 column for it and in the commit log we

00:26:09,830 --> 00:26:15,800
will just write well we received but one

00:26:13,550 --> 00:26:18,230
kind of important thing is that when we

00:26:15,800 --> 00:26:22,400
write in the commit log it's it's it's

00:26:18,230 --> 00:26:24,260
atomic or more precisely we actually

00:26:22,400 --> 00:26:26,000
write check them and everything to be

00:26:24,260 --> 00:26:30,440
sure that when we read a commit log we

00:26:26,000 --> 00:26:32,030
either read one of those well maybe not

00:26:30,440 --> 00:26:34,520
call that transaction went one of the

00:26:32,030 --> 00:26:37,580
mutation we call it mutation internally

00:26:34,520 --> 00:26:39,420
so we consider one mutation we write it

00:26:37,580 --> 00:26:40,980
atomically in the committee ugh

00:26:39,420 --> 00:26:44,150
I actually mean that when you write more

00:26:40,980 --> 00:26:46,980
than one colon Cassandra do that

00:26:44,150 --> 00:26:51,030
atomically what I mean by that is that

00:26:46,980 --> 00:26:54,030
if i write c1 and c2 in collin kk2 I I

00:26:51,030 --> 00:26:56,580
have the guarantee that either both of

00:26:54,030 --> 00:26:58,770
the colon are persisted are none of them

00:26:56,580 --> 00:27:02,100
are I cannot have the first one

00:26:58,770 --> 00:27:03,870
persistent and not the other one what is

00:27:02,100 --> 00:27:06,270
true though is that we don't do that

00:27:03,870 --> 00:27:08,100
atomically in the name table part so

00:27:06,270 --> 00:27:11,960
it's not easily tits oh it's actually

00:27:08,100 --> 00:27:16,830
possible and likely but possible that

00:27:11,960 --> 00:27:18,510
data read may only see k2 with only see

00:27:16,830 --> 00:27:20,550
one for example and at sea to the

00:27:18,510 --> 00:27:22,290
actually true of the current version of

00:27:20,550 --> 00:27:23,700
Cassandra but the next version that

00:27:22,290 --> 00:27:27,540
should be out in like a month or

00:27:23,700 --> 00:27:30,240
something actually add ease election so

00:27:27,540 --> 00:27:32,750
in next version Cassandra the rise will

00:27:30,240 --> 00:27:32,750

YouTube URL: https://www.youtube.com/watch?v=f1BKJUPmlx8


