Title: Purely Functional GPU Programming with Futhark
Publication date: 2018-03-06
Playlist: FOSDEM 2017
Description: 
	by Troels Henriksen

At: FOSDEM 2017

We present the pure functional array language, Futhark, along with itsoptimising GPU-targeting compiler. Of particular focus are the languagetradeoffs necessary to ensure the ability to efficiently generate high-performance GPU code from a high-level parallel language. We also demonstrate(nested) data-parallel array programming, a programming paradigm that enablesconcise programming of massively parallel systems. We show how Futhark codecan be easily integrated with larger applications written in other language.Finally, we report benchmarks showing that Futhark is able to match theperformance of hand-written code on various published benchmarks.

GPUs and other massively parallel systems are now common, yet programming themis often a painful experience. Languages are often low-level and fragile, withcareful hand-optimisation necessary to obtain good performance. The programmeris often forced to write highly coupled code with little modularity. The high-level languages that exist, often functional in nature, are ofteninsufficiently flexible, or poor performes in practice. We present our work ona programming language that seeks a common ground between imperative andfunctional approaches.

Futhark is a small programming language designed to be compiled to efficientGPU code. It is a statically typed, data-parallel, and purely functional arraylanguage, and comes with a heavily optimising ahead-of-time compiler thatgenerates GPU code via OpenCL. Futhark is not designed for graphicsprogramming, but instead uses the compute power of the GPU to accelerate data-parallel array computations. We support regular nested data-parallelism, aswell as a form of imperative-style in-place modification of arrays, whilestill preserving the purity of the language via the use of a uniqueness typesystem.

The Futhark language and compiler is an ongoing research project. It cancompile nontrivial programs which then run on real GPUs at high speed. TheFuthark compiler employs a set of optimisations (fusion, flattening,distribution, tiling, etc) to shield the programmer from having to know thedetails of the underlying hardware. The Futhark language itself is still veryspartan - due to the basic design criteria requiring the ability to generatehigh-performance GPU code, it takes more effort to support language featuresthat are common in languages with more forgiving compilation targets.Nevertheless, Futhark can already be used for nontrivial programs, and hasbeen used to port several real-world benchmark applications, with performancecomparable to original hand-written GPU (OpenCL or CUDA) code.

Futhark is not intended to replace existing general-purpose languages. Ourintended use case is that Futhark is only used for relatively small butcompute-intensive parts of an application. The Futhark compiler generates codethat can be easily integrated with non-Futhark code. For example, you cancompile a Futhark program to a Python module that internally uses PyOpenCL toexecute code on the GPU, yet looks like an ordinary Python module from theoutside.


Room: H.2213
Scheduled start: 2017-02-04 12:30:00
Captions: 
	00:02:15,760 --> 00:02:26,980
shut out anyone reasonably fast can you

00:02:23,049 --> 00:02:33,430
hear me now okay fine

00:02:26,980 --> 00:02:34,660
okay so I'm going to show you for gaming

00:02:33,430 --> 00:02:36,400
and I'm going to show you how to do a

00:02:34,660 --> 00:02:37,989
rate program in this language that I

00:02:36,400 --> 00:02:39,819
developed with along with other people

00:02:37,989 --> 00:02:41,950
called foo talk I'm going to show you

00:02:39,819 --> 00:02:43,569
how we cow new language cannot all be

00:02:41,950 --> 00:02:46,120
useful by showing how it easily

00:02:43,569 --> 00:02:47,920
interoperate with Python and I'm going

00:02:46,120 --> 00:02:49,239
to talk a little about how the performs

00:02:47,920 --> 00:02:53,140
of this language is compared hand

00:02:49,239 --> 00:02:54,549
written GPU code okay first thing that's

00:02:53,140 --> 00:02:55,840
two kinds of parallelism the one that

00:02:54,549 --> 00:02:58,329
most people think about when they say

00:02:55,840 --> 00:03:00,069
parallelism is tough parallelism may you

00:02:58,329 --> 00:03:01,780
spawn a threat of the thread can go and

00:03:00,069 --> 00:03:03,129
do whatever on some data and you can

00:03:01,780 --> 00:03:05,019
spawn another threat we can go and do

00:03:03,129 --> 00:03:05,980
something entirely all sums on some may

00:03:05,019 --> 00:03:07,540
be the same day that may be something

00:03:05,980 --> 00:03:09,700
else but the two threads are clearly

00:03:07,540 --> 00:03:11,410
independent of each other their

00:03:09,700 --> 00:03:13,540
parallelism is where I take the same

00:03:11,410 --> 00:03:16,900
function or do the same operation on

00:03:13,540 --> 00:03:19,209
multiple elements of some date set so

00:03:16,900 --> 00:03:21,340
the simplest examples is what we in

00:03:19,209 --> 00:03:23,590
function program hold the map which

00:03:21,340 --> 00:03:25,389
takes two arguments a function and an

00:03:23,590 --> 00:03:26,829
array and just you back a new array

00:03:25,389 --> 00:03:28,569
where that function has been applied

00:03:26,829 --> 00:03:31,060
each element of the array so I'm going

00:03:28,569 --> 00:03:32,560
to use in infotrac with us notation for

00:03:31,060 --> 00:03:34,299
add function applications without

00:03:32,560 --> 00:03:37,569
parentheses so this says apply the

00:03:34,299 --> 00:03:39,730
function map to F and this array all

00:03:37,569 --> 00:03:41,650
right no nothing magical going on here

00:03:39,730 --> 00:03:43,599
array programming is an instance of

00:03:41,650 --> 00:03:45,940
parallelism and you've probably already

00:03:43,599 --> 00:03:48,609
done do because numpad for Python and

00:03:45,940 --> 00:03:51,819
similar Lari to other languages is an

00:03:48,609 --> 00:03:53,620
instance of array programming what we do

00:03:51,819 --> 00:03:55,720
Bach operations so we just say we want

00:03:53,620 --> 00:03:57,930
an array of 10 elements each of those

00:03:55,720 --> 00:04:00,160
elements we want to multiply by 2 and

00:03:57,930 --> 00:04:01,720
keeps giving us back a new array and

00:04:00,160 --> 00:04:03,459
then we can multiply these two arrays

00:04:01,720 --> 00:04:05,919
point-wise and then some of the results

00:04:03,459 --> 00:04:08,400
as a dot product doing here but this

00:04:05,919 --> 00:04:10,599
idea of doing bulk operations on

00:04:08,400 --> 00:04:12,310
untraced which can be very large is a

00:04:10,599 --> 00:04:13,780
very good way of to heroism in a way

00:04:12,310 --> 00:04:15,849
that's easy for humans to think about

00:04:13,780 --> 00:04:19,299
and very efficient on massively parallel

00:04:15,849 --> 00:04:20,530
hardware like GPUs array programming is

00:04:19,299 --> 00:04:24,099
act a pretty old model

00:04:20,530 --> 00:04:26,590
it's was seen first APL which was not

00:04:24,099 --> 00:04:28,380
popular for some reason he wasn't

00:04:26,590 --> 00:04:32,070
especially portable so

00:04:28,380 --> 00:04:33,510
let's uh let's do anymore I feel this is

00:04:32,070 --> 00:04:36,930
retire which you can type with ordinary

00:04:33,510 --> 00:04:38,760
keyboard is it's a very small language

00:04:36,930 --> 00:04:40,920
it's kind of a it looks a little bit

00:04:38,760 --> 00:04:44,280
like standard email or Haskell or some

00:04:40,920 --> 00:04:46,440
other generic function language if

00:04:44,280 --> 00:04:48,390
you've seen ot for we can define a

00:04:46,440 --> 00:04:50,970
function that takes this input an array

00:04:48,390 --> 00:04:53,670
of length in and give suspect and the

00:04:50,970 --> 00:04:56,370
array of length in and just as to

00:04:53,670 --> 00:04:58,800
trailer element of that array or we can

00:04:56,370 --> 00:05:02,130
find a function that sums an array using

00:04:58,800 --> 00:05:06,180
reduce which is a function language

00:05:02,130 --> 00:05:08,430
lingo for uses function to turn this

00:05:06,180 --> 00:05:11,190
array of values integers on one value

00:05:08,430 --> 00:05:13,050
concept it just puts this function if

00:05:11,190 --> 00:05:14,520
it's this operate between each of the

00:05:13,050 --> 00:05:16,940
elements on the race so that's that's um

00:05:14,520 --> 00:05:19,200
sorry and this function can be any

00:05:16,940 --> 00:05:20,730
binary function it has to be associative

00:05:19,200 --> 00:05:23,520
to be parallel but let's not worry about

00:05:20,730 --> 00:05:25,710
that that's a little esoteric the nice

00:05:23,520 --> 00:05:27,360
thing of like I said is very freedom so

00:05:25,710 --> 00:05:29,190
when you find a function that it has

00:05:27,360 --> 00:05:31,290
some parallelism inside you can still

00:05:29,190 --> 00:05:33,270
use it inside of another peril context

00:05:31,290 --> 00:05:34,890
so you can do map while we use the sum

00:05:33,270 --> 00:05:36,300
function that we define up here so now

00:05:34,890 --> 00:05:38,250
we have two layers of parallelism you

00:05:36,300 --> 00:05:40,050
are map on the outside and refuge on the

00:05:38,250 --> 00:05:41,850
inside that's called nested parallelism

00:05:40,050 --> 00:05:44,340
and its comparative rare because it's

00:05:41,850 --> 00:05:46,050
triggered compile and one thing that the

00:05:44,340 --> 00:05:47,820
from a compiler will do is turn this

00:05:46,050 --> 00:05:50,370
little parallelism which is neither

00:05:47,820 --> 00:05:51,930
humans and nice and composable in flat

00:05:50,370 --> 00:05:53,430
parallelism which is only kind of

00:05:51,930 --> 00:05:55,650
hardware can be handle so you have your

00:05:53,430 --> 00:05:58,080
own level of parallelism that's tricky

00:05:55,650 --> 00:05:59,670
and it won't finis an explanation of how

00:05:58,080 --> 00:06:02,160
to do that or fortunately you can fit in

00:05:59,670 --> 00:06:05,180
at twenty minutes or so I won't show

00:06:02,160 --> 00:06:07,830
that much of about that futon also has

00:06:05,180 --> 00:06:09,390
sequela loops it's a few language so

00:06:07,830 --> 00:06:12,060
there's no destructive update so you can

00:06:09,390 --> 00:06:15,120
kind of fake them by saying okay start

00:06:12,060 --> 00:06:18,420
with a with the value X equal to one

00:06:15,120 --> 00:06:20,850
then run this number of iterations and

00:06:18,420 --> 00:06:23,580
for iteration computer new value X with

00:06:20,850 --> 00:06:26,340
this equation so multiply X with I plus

00:06:23,580 --> 00:06:31,710
one and then run the loop again until I

00:06:26,340 --> 00:06:33,360
hits n and then X is is returned so it's

00:06:31,710 --> 00:06:34,530
also just a sitting sugar for chain

00:06:33,360 --> 00:06:35,660
recursive function if you use the

00:06:34,530 --> 00:06:38,460
function programming

00:06:35,660 --> 00:06:42,060
arrays can be constructed in rhythm

00:06:38,460 --> 00:06:42,420
building constructs iota which gives us

00:06:42,060 --> 00:06:43,980
back

00:06:42,420 --> 00:06:45,600
and it's us just like range in pylons

00:06:43,980 --> 00:06:47,970
Egyptians began there in range of a

00:06:45,600 --> 00:06:49,920
figures of integers or replicas which

00:06:47,970 --> 00:06:51,390
copies some of you and the Irish

00:06:49,920 --> 00:06:55,530
replicate can also be released but we

00:06:51,390 --> 00:06:57,420
won't i won't be using that so aren't an

00:06:55,530 --> 00:06:59,940
example this is a man brought sit or

00:06:57,420 --> 00:07:03,120
this is a actualization of part

00:06:59,940 --> 00:07:04,890
Mandelbrot said the way to create these

00:07:03,120 --> 00:07:07,530
nice graphics is just to applaud this a

00:07:04,890 --> 00:07:09,090
simple function written in Python to a

00:07:07,530 --> 00:07:11,700
bunch of comic numbers and you can turn

00:07:09,090 --> 00:07:13,950
this function busts sees how many times

00:07:11,700 --> 00:07:15,630
this comic number can go through this

00:07:13,950 --> 00:07:17,820
loop without this condition becoming

00:07:15,630 --> 00:07:20,820
true and with this part of point zero

00:07:17,820 --> 00:07:22,110
neither forever and you just return how

00:07:20,820 --> 00:07:23,670
many times you went through the loop and

00:07:22,110 --> 00:07:25,650
you can use that number to turned into a

00:07:23,670 --> 00:07:27,000
pretty car and then you can get a nice

00:07:25,650 --> 00:07:28,440
visualization but it's basically just

00:07:27,000 --> 00:07:30,690
boy starts running this pretty simple

00:07:28,440 --> 00:07:32,550
solution and but since you run the same

00:07:30,690 --> 00:07:35,460
phone on a whole bunch of comics numbers

00:07:32,550 --> 00:07:37,920
at once you can do that in parallel in

00:07:35,460 --> 00:07:40,980
pi it would look like this where we have

00:07:37,920 --> 00:07:43,980
an array of complex numbers and then we

00:07:40,980 --> 00:07:45,780
do some some weird operations with for

00:07:43,980 --> 00:07:48,570
each of these some complex numbers we

00:07:45,780 --> 00:07:51,450
compare them to this is the stop

00:07:48,570 --> 00:07:54,360
condition and then we figure out which

00:07:51,450 --> 00:07:56,430
ones did not stop yet and then we for

00:07:54,360 --> 00:07:59,370
those that didn't have didn't stop yet

00:07:56,430 --> 00:08:00,720
we set the escape count to the loop

00:07:59,370 --> 00:08:03,240
counter and it's very complicated and

00:08:00,720 --> 00:08:05,370
the original simple controller we had

00:08:03,240 --> 00:08:07,800
before in our mathematical definition is

00:08:05,370 --> 00:08:09,870
kind of gone and obscured but invoice

00:08:07,800 --> 00:08:11,060
now not only is it unreadable is also so

00:08:09,870 --> 00:08:12,990
and that's what I care the most about

00:08:11,060 --> 00:08:15,000
because every iteration of this loop

00:08:12,990 --> 00:08:17,400
which is usually on the order of maybe

00:08:15,000 --> 00:08:19,920
200 200 could cut whatever you want but

00:08:17,400 --> 00:08:22,530
it's usually very large we write three

00:08:19,920 --> 00:08:24,450
arrays so that means we have found a

00:08:22,530 --> 00:08:27,170
memory speed we can't see writes these

00:08:24,450 --> 00:08:29,460
arrays that might be very large memory

00:08:27,170 --> 00:08:33,600
with a problem because memory is very

00:08:29,460 --> 00:08:36,390
very slow and also just how slow in a

00:08:33,600 --> 00:08:38,729
moment in foods that looks like this we

00:08:36,390 --> 00:08:42,780
have our sequential function I showed

00:08:38,729 --> 00:08:44,130
you before which will be in Python

00:08:42,780 --> 00:08:46,860
before it just is right to written food

00:08:44,130 --> 00:08:48,810
truck that's the same thing let me just

00:08:46,860 --> 00:08:50,700
map that not two-dimensional array of

00:08:48,810 --> 00:08:52,260
complex numbers and it's two dimensional

00:08:50,700 --> 00:08:54,570
but you really use this normal

00:08:52,260 --> 00:08:56,279
visualization of the complex plane it

00:08:54,570 --> 00:09:00,569
could be one-dimensional if you

00:08:56,279 --> 00:09:02,339
the interests so the interesting thing

00:09:00,569 --> 00:09:04,829
here is that so really that's only a one

00:09:02,339 --> 00:09:06,839
every written because we just overall

00:09:04,829 --> 00:09:09,300
complex numbers on this simple scalar

00:09:06,839 --> 00:09:10,620
function which don't use any array so we

00:09:09,300 --> 00:09:12,180
can skip it all in registers

00:09:10,620 --> 00:09:15,319
that's a compiler to here but that's

00:09:12,180 --> 00:09:17,339
something that the program can rely on

00:09:15,319 --> 00:09:19,040
the primitive values are kept in

00:09:17,339 --> 00:09:20,670
registers and at the end a

00:09:19,040 --> 00:09:25,410
two-dimensional array is written to

00:09:20,670 --> 00:09:27,839
memory so the moments difference between

00:09:25,410 --> 00:09:30,050
the two styles is something like this I

00:09:27,839 --> 00:09:32,879
mean they both scale right it will as a

00:09:30,050 --> 00:09:35,970
number of complex number working on

00:09:32,879 --> 00:09:37,319
increases don't do why they talk about I

00:09:35,970 --> 00:09:41,009
mean this is an umpire's I whether you

00:09:37,319 --> 00:09:42,749
write a lot of arrays it's hot at 12

00:09:41,009 --> 00:09:44,639
times faster than sequential code that's

00:09:42,749 --> 00:09:48,149
all this is not this is not Python code

00:09:44,639 --> 00:09:51,120
this is cstp code written in a non pie

00:09:48,149 --> 00:09:52,980
style but it's not Python code

00:09:51,120 --> 00:09:54,240
we're in futhark style where we don't

00:09:52,980 --> 00:09:56,879
have all these memory accesses it

00:09:54,240 --> 00:10:00,209
becomes 350 times faster and sequential

00:09:56,879 --> 00:10:01,230
code sequential C code there's a

00:10:00,209 --> 00:10:03,360
significant difference and that's

00:10:01,230 --> 00:10:05,730
entirely down to this what's the circle

00:10:03,360 --> 00:10:08,279
memory wall that modern computation is

00:10:05,730 --> 00:10:10,559
so so much faster than than modern

00:10:08,279 --> 00:10:12,990
memory bank said that you really the old

00:10:10,559 --> 00:10:15,449
I mean touching memory is just a killer

00:10:12,990 --> 00:10:17,519
if you write real life from memory your

00:10:15,449 --> 00:10:19,050
programs could be slow that's it

00:10:17,519 --> 00:10:21,509
so we do it because we kind of have to

00:10:19,050 --> 00:10:22,920
sometimes unfortunately we the user

00:10:21,509 --> 00:10:24,449
can't see the value of registers of

00:10:22,920 --> 00:10:26,100
sometimes we do have to write memory or

00:10:24,449 --> 00:10:27,959
even worse to disk of the screen or what

00:10:26,100 --> 00:10:29,339
have you well you want to avoid it it's

00:10:27,959 --> 00:10:36,779
a very very bad idea if you want our

00:10:29,339 --> 00:10:38,850
coaching fast so foots a little bit

00:10:36,779 --> 00:10:40,439
tricky because it's a pure language so

00:10:38,850 --> 00:10:42,600
one thing is you can you have mutable

00:10:40,439 --> 00:10:44,370
variables you also don't have the

00:10:42,600 --> 00:10:46,559
ability to write to the screen or to a

00:10:44,370 --> 00:10:48,120
file or anywhere so running it is a

00:10:46,559 --> 00:10:51,149
little bit exotic you have to can

00:10:48,120 --> 00:10:52,709
compile a food-truck program and that's

00:10:51,149 --> 00:10:55,939
start by writing a main function that

00:10:52,709 --> 00:10:58,439
takes some input and produce some output

00:10:55,939 --> 00:10:59,699
in this case I just make up some numbers

00:10:58,439 --> 00:11:01,079
I haven't shown you this one doesn't

00:10:59,699 --> 00:11:03,209
matter it just makes play an array of

00:11:01,079 --> 00:11:05,429
complex nervous runs function I showed

00:11:03,209 --> 00:11:07,319
you before it's some small up to reduce

00:11:05,429 --> 00:11:09,389
one incision so that sums all of the

00:11:07,319 --> 00:11:10,170
escape values of all these complex

00:11:09,389 --> 00:11:13,079
numbers doesn't

00:11:10,170 --> 00:11:15,209
doesn't cover anything meaningful we're

00:11:13,079 --> 00:11:17,310
going to run this program where Patil

00:11:15,209 --> 00:11:19,790
food are okay run this function with

00:11:17,310 --> 00:11:22,410
these are guns and leave me the result

00:11:19,790 --> 00:11:25,260
and do that by just compiling it using

00:11:22,410 --> 00:11:26,820
the compiler and then you pass this

00:11:25,260 --> 00:11:29,190
input internal input and you get back

00:11:26,820 --> 00:11:33,290
output and standard output which is

00:11:29,190 --> 00:11:36,170
weird thing but UNIX people like this

00:11:33,290 --> 00:11:38,279
in this case I've all asked the Pico

00:11:36,170 --> 00:11:39,420
when compiling a food-truck program

00:11:38,279 --> 00:11:41,220
standalone program it's not for

00:11:39,420 --> 00:11:43,440
production uses for tp3 bugging and

00:11:41,220 --> 00:11:46,769
benchmark so it has some some useful

00:11:43,440 --> 00:11:48,930
flags one I use is - T which asks it to

00:11:46,769 --> 00:11:51,000
benchmark itself so in this case ok I

00:11:48,930 --> 00:11:53,399
can this is a result and this is a

00:11:51,000 --> 00:11:57,269
runtime in microseconds so six hundred

00:11:53,399 --> 00:11:58,740
and eleven thousand microseconds this is

00:11:57,269 --> 00:12:01,079
using the foot pack C compiler which

00:11:58,740 --> 00:12:04,170
generates security code that is in

00:12:01,079 --> 00:12:06,510
combat with GCC with also the photo

00:12:04,170 --> 00:12:09,000
album shield Pilar which generates GPU

00:12:06,510 --> 00:12:10,980
code and it runs just seven and 1/2

00:12:09,000 --> 00:12:12,389
milliseconds so eight it seems faster

00:12:10,980 --> 00:12:14,370
without any changes to the program

00:12:12,389 --> 00:12:16,410
itself and the perks of doesn't really

00:12:14,370 --> 00:12:20,070
talk about GPUs at all it just uses

00:12:16,410 --> 00:12:22,380
these the parallel Opera Berets map in

00:12:20,070 --> 00:12:24,209
this case and it geometrically runs

00:12:22,380 --> 00:12:29,240
faster when I when run with the in

00:12:24,209 --> 00:12:31,410
compile with the OpenGL compiler but

00:12:29,240 --> 00:12:33,120
this is not the way you want to use

00:12:31,410 --> 00:12:35,940
future you have a nice command line

00:12:33,120 --> 00:12:37,860
program for some you are handle brush

00:12:35,940 --> 00:12:41,250
sets but that's not really what anyone

00:12:37,860 --> 00:12:42,990
needs in practice so the trick is how

00:12:41,250 --> 00:12:44,430
open shield works which is the library

00:12:42,990 --> 00:12:45,839
it used to me there's two libraries for

00:12:44,430 --> 00:12:48,390
communicating with GPUs one is cool

00:12:45,839 --> 00:12:49,920
invidious prize everything and OpenCL

00:12:48,390 --> 00:12:51,390
will use an open standard but this much

00:12:49,920 --> 00:12:53,100
masters you should use for manual

00:12:51,390 --> 00:12:55,110
program it's not as a compiler socket

00:12:53,100 --> 00:12:56,730
though so the way it works is actually

00:12:55,110 --> 00:12:59,880
have two programs you have a program

00:12:56,730 --> 00:13:02,370
running on GPU called the host which

00:12:59,880 --> 00:13:03,660
offers code and data to the GPU which is

00:13:02,370 --> 00:13:07,980
for as iconic as later they just

00:13:03,660 --> 00:13:09,300
sentence and the command and data to so

00:13:07,980 --> 00:13:11,430
the interesting thing is that the CPU

00:13:09,300 --> 00:13:13,470
code doesn't actually compute that much

00:13:11,430 --> 00:13:15,480
in a well-written organ whether by the

00:13:13,470 --> 00:13:16,290
peril seams are large it just

00:13:15,480 --> 00:13:18,319
bookkeeping

00:13:16,290 --> 00:13:21,180
it doesn't have to be fast in particular

00:13:18,319 --> 00:13:22,740
you can have the spew code be in some

00:13:21,180 --> 00:13:23,640
high-level language and easy to

00:13:22,740 --> 00:13:26,480
integrate with

00:13:23,640 --> 00:13:30,960
but but and just talks with you for you

00:13:26,480 --> 00:13:32,910
so the way we don this is that we have

00:13:30,960 --> 00:13:34,500
added a code generator where the host

00:13:32,910 --> 00:13:36,780
level code you know the CPU level code

00:13:34,500 --> 00:13:39,840
the code that you see is written in

00:13:36,780 --> 00:13:41,670
Python so this compiler generates Python

00:13:39,840 --> 00:13:44,870
that internally makes holsters ohms you

00:13:41,670 --> 00:13:47,550
live it's you upload code and aces GPU

00:13:44,870 --> 00:13:49,350
so it just use a different pilar called

00:13:47,550 --> 00:13:51,810
pi open shell and you ask it to create a

00:13:49,350 --> 00:13:54,090
library and then you produces a python

00:13:51,810 --> 00:13:55,380
module Bantle brought that pi which from

00:13:54,090 --> 00:13:58,320
the outside looks like any ordinary

00:13:55,380 --> 00:14:00,030
python module to even start a Python you

00:13:58,320 --> 00:14:01,350
can import it and then it's kind of as a

00:14:00,030 --> 00:14:04,140
kind of strange thing about how you have

00:14:01,350 --> 00:14:06,600
used it it defines a class that you

00:14:04,140 --> 00:14:09,180
instantiate some GPU States and then

00:14:06,600 --> 00:14:11,010
that class or that object defines a

00:14:09,180 --> 00:14:12,420
method for every entry point original

00:14:11,010 --> 00:14:14,100
food-truck program in this case there's

00:14:12,420 --> 00:14:16,290
only the main function and just pass

00:14:14,100 --> 00:14:18,060
that ordinary Python values and you get

00:14:16,290 --> 00:14:21,120
back ordinary Python values as result

00:14:18,060 --> 00:14:23,100
and behind the scenes it has compulsive

00:14:21,120 --> 00:14:24,390
GPU code and is asking is if you take

00:14:23,100 --> 00:14:25,890
through this function for this argument

00:14:24,390 --> 00:14:28,710
and you can call it again and it'll give

00:14:25,890 --> 00:14:31,050
a parity for assault and for passing

00:14:28,710 --> 00:14:33,960
erase and get back erase from the cheap

00:14:31,050 --> 00:14:36,630
you it uses an up hi mary so you can

00:14:33,960 --> 00:14:37,920
pretty easily integrate it with with the

00:14:36,630 --> 00:14:40,200
existing pattern libraries all those

00:14:37,920 --> 00:14:43,170
numpy array is going to be on the cpu so

00:14:40,200 --> 00:14:44,460
to be some cost of copying pat fault so

00:14:43,170 --> 00:14:48,780
you can use that if you really want to

00:14:44,460 --> 00:14:50,100
sum up Mandelbrot sets or we could

00:14:48,780 --> 00:14:51,690
modify that from a little bit and

00:14:50,100 --> 00:14:54,210
instead of just arming up those escapes

00:14:51,690 --> 00:14:56,040
if you compute and turn them into a IP

00:14:54,210 --> 00:14:57,780
pixel values and give us back an array

00:14:56,040 --> 00:14:59,940
it's really a pixel values and we can

00:14:57,780 --> 00:15:02,010
use something like PI game to just lead

00:14:59,940 --> 00:15:04,350
it to the screen and then we would

00:15:02,010 --> 00:15:06,270
something like this and incisive

00:15:04,350 --> 00:15:09,900
Mandelbrot viewer with a Python

00:15:06,270 --> 00:15:12,030
front-end for meddling all the keyboard

00:15:09,900 --> 00:15:14,100
commands and all that stuff but with all

00:15:12,030 --> 00:15:17,100
the completion happening and my insult

00:15:14,100 --> 00:15:20,790
GPU in real time much much faster than

00:15:17,100 --> 00:15:22,350
the CPU could ever hope to this so

00:15:20,790 --> 00:15:24,360
pretty nice division of work between a

00:15:22,350 --> 00:15:26,370
restricted high-performance language and

00:15:24,360 --> 00:15:32,280
a very flexible dynamic and little

00:15:26,370 --> 00:15:33,870
Python language okay so the old reason

00:15:32,280 --> 00:15:35,370
you would ever want use a restricted

00:15:33,870 --> 00:15:37,020
high-performance language is to get high

00:15:35,370 --> 00:15:38,940
performance because it's

00:15:37,020 --> 00:15:40,200
it's not a terrible language I don't

00:15:38,940 --> 00:15:42,570
think after all this time maybe that's

00:15:40,200 --> 00:15:43,920
my Stockholm Syndrome Auggie but it's

00:15:42,570 --> 00:15:46,860
not as nice as you didn't have to use it

00:15:43,920 --> 00:15:48,690
so is it fast it's worth it well it

00:15:46,860 --> 00:15:50,070
depends because I can easily just show

00:15:48,690 --> 00:15:52,260
you some Finnish markka show that is

00:15:50,070 --> 00:15:53,399
mattress and everything else but you

00:15:52,260 --> 00:15:54,870
should we trust that because it's very

00:15:53,399 --> 00:15:57,300
very hard to quantify whether life is

00:15:54,870 --> 00:15:59,610
fast the only way I found that I just

00:15:57,300 --> 00:16:01,830
trust the this least amount is take

00:15:59,610 --> 00:16:04,320
existing programs that I'm that are set

00:16:01,830 --> 00:16:05,670
to be written in good a decent way and

00:16:04,320 --> 00:16:08,610
then pour them to my language and say

00:16:05,670 --> 00:16:10,680
well this is how fast it is now almost

00:16:08,610 --> 00:16:12,540
benchmarks not mean are not really

00:16:10,680 --> 00:16:14,190
really don't really implement algorithms

00:16:12,540 --> 00:16:15,600
that are designed to be parallel so it's

00:16:14,190 --> 00:16:17,730
kind of I can't use the line normal

00:16:15,600 --> 00:16:19,950
language benchmarks you doubt game then

00:16:17,730 --> 00:16:21,480
when the TV on has however because

00:16:19,950 --> 00:16:22,770
they're mutually sequential programs and

00:16:21,480 --> 00:16:24,330
many of them require side effects in

00:16:22,770 --> 00:16:26,029
writing to file screen and whatever and

00:16:24,330 --> 00:16:28,620
I mean language can't really do that

00:16:26,029 --> 00:16:30,209
there is a benchmark suite called Enya

00:16:28,620 --> 00:16:35,190
which I don't like anyone to know unless

00:16:30,209 --> 00:16:37,709
I've done HP in academia yeah

00:16:35,190 --> 00:16:42,600
it's Henry no OpenCL code so hidden GPU

00:16:37,709 --> 00:16:45,209
code of very varying quality much of

00:16:42,600 --> 00:16:48,450
industry by doctors who did released it

00:16:45,209 --> 00:16:50,310
to human parties or write code or by

00:16:48,450 --> 00:16:52,010
physicists which is we are needed but at

00:16:50,310 --> 00:16:55,500
least fast so we Paul

00:16:52,010 --> 00:16:57,810
so we've so we've folded some of these

00:16:55,500 --> 00:17:00,240
Virginia paint marks the photog and we

00:16:57,810 --> 00:17:03,329
run them on put on in immediate review

00:17:00,240 --> 00:17:04,740
and an AMD GPU and this is the speed of

00:17:03,329 --> 00:17:05,939
speed compared to original code I don't

00:17:04,740 --> 00:17:08,760
know if anyone if you can see these

00:17:05,939 --> 00:17:10,439
small numbers but for this one the food

00:17:08,760 --> 00:17:12,000
truck versus four times faster than

00:17:10,439 --> 00:17:14,569
written version on an immediate review

00:17:12,000 --> 00:17:17,189
and on an MD cheap use two times faster

00:17:14,569 --> 00:17:19,439
of course this you misjudge this most

00:17:17,189 --> 00:17:21,390
means that original program is ad that's

00:17:19,439 --> 00:17:22,709
the way a compilers will generate code

00:17:21,390 --> 00:17:25,470
that is significantly better than

00:17:22,709 --> 00:17:27,809
something didn't by an expert who put

00:17:25,470 --> 00:17:30,000
who put enough time to it to write good

00:17:27,809 --> 00:17:32,160
code so you so not these benchmarks are

00:17:30,000 --> 00:17:33,780
not sufficient are not very good except

00:17:32,160 --> 00:17:35,940
some of them where we don't any speed

00:17:33,780 --> 00:17:37,290
handle code but we get clips and of

00:17:35,940 --> 00:17:39,540
course the food track code is vastly

00:17:37,290 --> 00:17:41,160
easier to modify and understand and

00:17:39,540 --> 00:17:44,130
extend that that's what we're going for

00:17:41,160 --> 00:17:46,040
not really trying to beat handwritten

00:17:44,130 --> 00:17:48,929
code with experts we're just trying to

00:17:46,040 --> 00:17:50,100
get closed loop era and providing a much

00:17:48,929 --> 00:17:50,790
better programming experience along the

00:17:50,100 --> 00:17:51,930
way

00:17:50,790 --> 00:17:53,220
this times we have seven teams time

00:17:51,930 --> 00:17:56,070
faster because they were something was

00:17:53,220 --> 00:17:57,450
parallel and really isn't time so it's

00:17:56,070 --> 00:18:01,770
not true that your language is good when

00:17:57,450 --> 00:18:03,810
everyone writes so slow code so and

00:18:01,770 --> 00:18:05,580
sorry it's a small language is very

00:18:03,810 --> 00:18:06,780
simple to learn it's high level so it's

00:18:05,580 --> 00:18:08,370
not actually cheap you are in we could

00:18:06,780 --> 00:18:10,590
generate multi-course view code as well

00:18:08,370 --> 00:18:12,870
it's purely functional just weird what

00:18:10,590 --> 00:18:15,180
fits this hard I'm pretty well it's data

00:18:12,870 --> 00:18:16,650
parallel so there's inbuilt the operator

00:18:15,180 --> 00:18:19,080
sort of pelham meaning and the compiler

00:18:16,650 --> 00:18:20,940
understands I can optimize them and we

00:18:19,080 --> 00:18:22,500
encourage Aaron curry imapilot generates

00:18:20,940 --> 00:18:23,820
good GPU code and the future it will

00:18:22,500 --> 00:18:25,530
also be able to generate good secure

00:18:23,820 --> 00:18:27,930
code and may even cluster code we

00:18:25,530 --> 00:18:29,490
haven't gone there yet we haven't a good

00:18:27,930 --> 00:18:31,230
idea how we can integrate that with the

00:18:29,490 --> 00:18:32,430
language and applications not just Pilon

00:18:31,230 --> 00:18:34,980
that's what we right now but we could

00:18:32,430 --> 00:18:37,410
easily create an Lang a ruby or C sharp

00:18:34,980 --> 00:18:38,790
or whatever front Java doesn't matter

00:18:37,410 --> 00:18:41,640
this is the host code is variable and

00:18:38,790 --> 00:18:43,230
the moments is is okay we've also tried

00:18:41,640 --> 00:18:45,510
them on more challenging benchmark where

00:18:43,230 --> 00:18:47,130
we don't eat them quite as much but do

00:18:45,510 --> 00:18:48,420
pretty respectively and of course the

00:18:47,130 --> 00:18:50,910
foods are called much easier to

00:18:48,420 --> 00:18:54,030
understand and it's all available online

00:18:50,910 --> 00:18:58,160
and August and online is license and all

00:18:54,030 --> 00:18:58,160
and all that off right that's it

00:19:03,740 --> 00:19:08,659
thank very much true questions

00:19:15,470 --> 00:19:18,100
yes

00:19:22,320 --> 00:19:30,309
yes it's a I got a question we have a

00:19:27,429 --> 00:19:32,080
pattern interface and I was out of all

00:19:30,309 --> 00:19:34,059
time a C interface do is not quite as

00:19:32,080 --> 00:19:35,679
mature because C doesn't have I will

00:19:34,059 --> 00:19:37,090
define step for the multi dimension or

00:19:35,679 --> 00:19:39,010
it should look like for example I think

00:19:37,090 --> 00:19:41,559
we could just use numpy pensions but it

00:19:39,010 --> 00:19:42,760
should very easy and we do generate city

00:19:41,559 --> 00:19:44,320
code that works fine as a standalone

00:19:42,760 --> 00:19:55,330
executable and you pieces to make that

00:19:44,320 --> 00:19:58,900
alive with you yes yeah that's what

00:19:55,330 --> 00:20:00,730
that's what the so I was also that we

00:19:58,900 --> 00:20:03,460
have a compiler use the C wrap instead

00:20:00,730 --> 00:20:06,490
of those Python that's what this with us

00:20:03,460 --> 00:20:08,679
AJ doesn't have the - library option so

00:20:06,490 --> 00:20:10,210
we don't integrate fully reusable code

00:20:08,679 --> 00:20:13,240
just iterate the fight the nice rare

00:20:10,210 --> 00:20:15,730
code but that's just because I can see

00:20:13,240 --> 00:20:17,110
doesn't have a table enough numpy that

00:20:15,730 --> 00:20:18,850
we know some convention so we can just

00:20:17,110 --> 00:20:25,170
adopt so it looks a little bit more for

00:20:18,850 --> 00:20:29,820
about how we create an API furs yeah

00:20:25,170 --> 00:20:29,820
yeah sure yes if you wouldn't manually

00:20:34,940 --> 00:20:37,629
sorry

00:20:40,119 --> 00:20:44,840
so hey it wasn't by much because in

00:20:43,039 --> 00:20:47,389
video don't bother support so I'm asked

00:20:44,840 --> 00:20:49,070
about which watched what I was bored is

00:20:47,389 --> 00:20:50,840
necessary now okay so that's two answers

00:20:49,070 --> 00:20:52,639
that the first is I have often

00:20:50,840 --> 00:20:54,409
questioned this time of doing a PhD that

00:20:52,639 --> 00:20:57,979
requires working graphics drivers and

00:20:54,409 --> 00:21:00,349
Linux you can't get your window you all

00:20:57,979 --> 00:21:02,210
know the problem the second is open

00:21:00,349 --> 00:21:03,710
shell self NVIDIA doesn't open shell

00:21:02,210 --> 00:21:05,749
much they support it but the support of

00:21:03,710 --> 00:21:07,789
value version and since vidya hardware

00:21:05,749 --> 00:21:10,009
so popular we can't use features that

00:21:07,789 --> 00:21:11,179
are newer than from OpenGL will - I

00:21:10,009 --> 00:21:13,849
think that's the newest video support

00:21:11,179 --> 00:21:16,639
that's all we need

00:21:13,849 --> 00:21:18,679
it works on all CPUs I've seen in via

00:21:16,639 --> 00:21:20,690
empty and in cell and also a name do you

00:21:18,679 --> 00:21:24,169
want I think an r1 at some point I think

00:21:20,690 --> 00:21:26,679
try it out so we don't we don't use any

00:21:24,169 --> 00:21:26,679
fancy features

00:21:36,099 --> 00:21:40,700
yes that's right on the C and Phi it

00:21:39,830 --> 00:21:41,869
doesn't run very fast

00:21:40,700 --> 00:21:43,879
once correctly it's supported

00:21:41,869 --> 00:21:45,919
oakenshield code but the compiler has

00:21:43,879 --> 00:21:48,679
some assumptions about how memory should

00:21:45,919 --> 00:21:50,570
be accessed to fast that is valid on on

00:21:48,679 --> 00:21:52,009
all modern GPUs but it's not well and

00:21:50,570 --> 00:21:53,889
they don't see and Phi's as far as I can

00:21:52,009 --> 00:21:56,029
see so there's a significant slowdown

00:21:53,889 --> 00:21:57,440
but there could be fixed that's just

00:21:56,029 --> 00:21:59,450
about tweaking the collation pipeline

00:21:57,440 --> 00:22:00,859
for CFI so I think but I don't know that

00:21:59,450 --> 00:22:02,090
much that's what knowles here and fire

00:22:00,859 --> 00:22:04,509
they made a new one i haven't tried that

00:22:02,090 --> 00:22:04,509
one you

00:22:08,350 --> 00:22:15,940
[Applause]

00:22:32,500 --> 00:22:35,599
[Music]

00:23:12,410 --> 00:23:14,440
Oh

00:23:37,820 --> 00:23:44,180
[Music]

00:24:20,650 --> 00:24:27,220
yes yeah so we loaded on this laptop

00:24:24,530 --> 00:24:29,510
right and the song is you don't really

00:24:27,220 --> 00:24:50,840
specific that you need us to like the

00:24:29,510 --> 00:24:54,400
memory using before okay it's being here

00:24:50,840 --> 00:24:54,400

YouTube URL: https://www.youtube.com/watch?v=nkasoiVXHDY


