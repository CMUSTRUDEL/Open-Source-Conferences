Title: From Zero to Portability Apache Beam's Journey to Cross-Language Data Processing
Publication date: 2019-02-08
Playlist: FOSDEM 2019
Description: 
	by Maximilian Michels

At: FOSDEM 2019
https://video.fosdem.org/2019/UA2.118/beam_cross_language.webm


Apache Beam is a programming model for composing parallel and distributed data processing jobs. 

As many other Apache projects, Beam first used Java as its API language. Unsatisfied with the status quo, Beam developers launched the portability project to enable other languages to run with Beam. Currently, Beam has a Java, Python, and a Go API. 

Ultimately, these languages won't just coexist in Apache Beam, but they will complement each other in cross-language data processing jobs. 

In this talk we will learn how it is possible to support multiple languages and why it might be a good idea to combine these languages in data processing jobs. Apache Beam is a programming model for composing parallel and distributed data processing jobs. Once composed, these jobs run on various execution engines like Apache Flink, Apache Spark, or Google Cloud Dataflow. But Apache Beam's vision goes beyond just running on multiple execution engines. 

As many other Apache projects, Beam first used Java as its API language. Unsatisfied with the status quo, Beam developers launched the portability project to enable other languages to run with Beam. Currently, Beam has a Java, Python, and a Go API. That means users are not restricted to the Java ecosystem but can use their favorite Python libraries like Numpy or Tensorflow with Apache Beam. 

Ultimately, these languages won't just coexist in Apache Beam, but they will complement each other in cross-language data processing jobs. For example, reading from Kafka can be done with the Java connector but the data can afterwards be processed in Python. 

In this talk we will learn how it is possible to support multiple languages and why it might be a good idea to combine these languages in data processing jobs. 

Room: UA2.118 (Henriot)
Scheduled start: 2019-02-03 14:30:00+01
Captions: 
	00:00:08,660 --> 00:00:13,150
it's on yeah okay

00:00:18,600 --> 00:00:21,670
[Music]

00:00:24,029 --> 00:00:27,329
please stay

00:00:30,700 --> 00:00:33,970
okay cool

00:00:37,160 --> 00:00:49,460
where I guess I have to scream that's

00:00:46,980 --> 00:00:49,460
weird

00:00:57,739 --> 00:01:01,309
yeah maybe that's better

00:01:10,060 --> 00:01:17,009
[Music]

00:01:12,350 --> 00:01:18,810
hello so um yeah my name is Max and I'm

00:01:17,009 --> 00:01:21,659
a software engineer at the beam project

00:01:18,810 --> 00:01:24,360
and I want to tell you about being today

00:01:21,659 --> 00:01:27,090
and how beam realized its vision for

00:01:24,360 --> 00:01:29,070
portability and what do I mean by

00:01:27,090 --> 00:01:31,140
portability because portability can mean

00:01:29,070 --> 00:01:32,939
a lot of things well first of all and

00:01:31,140 --> 00:01:36,810
you have to listen carefully to

00:01:32,939 --> 00:01:39,030
understand but hey called but the short

00:01:36,810 --> 00:01:40,740
answer is that it enables you to run

00:01:39,030 --> 00:01:42,690
your data processing jobs on top of

00:01:40,740 --> 00:01:44,069
various execution engines like spark or

00:01:42,690 --> 00:01:46,380
flick or Samsung or Google Cloud

00:01:44,069 --> 00:01:48,509
dataflow and you can do that in the

00:01:46,380 --> 00:01:50,580
programming language of your choice so

00:01:48,509 --> 00:01:53,670
that sounds pretty good doesn't it

00:01:50,580 --> 00:01:55,679
so I've put this agenda together so

00:01:53,670 --> 00:01:57,720
first of all I mean some of you might

00:01:55,679 --> 00:01:59,819
know beam BAM I will give like a short

00:01:57,720 --> 00:02:01,350
introduction then we will talk about you

00:01:59,819 --> 00:02:04,920
know a little bit more about portability

00:02:01,350 --> 00:02:06,569
and then how we can actually achieve it

00:02:04,920 --> 00:02:09,750
because there are multiple ways to do

00:02:06,569 --> 00:02:12,060
that and then we let's recap and see um

00:02:09,750 --> 00:02:15,720
how far we are actually with portability

00:02:12,060 --> 00:02:18,209
so what is beam so first of all beam is

00:02:15,720 --> 00:02:20,400
an open source project at the Apache

00:02:18,209 --> 00:02:22,019
Software Foundation so I don't know if

00:02:20,400 --> 00:02:23,280
you know the pipe Apache Software - but

00:02:22,019 --> 00:02:27,329
it's like a framework for developing

00:02:23,280 --> 00:02:29,579
open source software which they provide

00:02:27,329 --> 00:02:32,420
infrastructure and kind of a guide how

00:02:29,579 --> 00:02:35,609
to develop software and open source and

00:02:32,420 --> 00:02:37,230
beam is a project there and it focuses

00:02:35,609 --> 00:02:39,959
on parallel and distribute data

00:02:37,230 --> 00:02:42,150
processing so and you typically run your

00:02:39,959 --> 00:02:44,340
beam job on like multiple machines and

00:02:42,150 --> 00:02:46,709
and you have probably a lot you have

00:02:44,340 --> 00:02:48,079
mostly large data but you can also run

00:02:46,709 --> 00:02:50,700
it on a single machine if you want and

00:02:48,079 --> 00:02:52,170
it has a really cool API which can do

00:02:50,700 --> 00:02:54,390
better and stream processing at the same

00:02:52,170 --> 00:02:56,609
time so often like you have like a batch

00:02:54,390 --> 00:02:59,280
in stream API which are separate and you

00:02:56,609 --> 00:03:01,850
have to like port your bachelor up to

00:02:59,280 --> 00:03:05,069
streaming but in beam it's all the same

00:03:01,850 --> 00:03:07,350
so and and once you've written your job

00:03:05,069 --> 00:03:09,810
you can actually run it on like multiple

00:03:07,350 --> 00:03:12,269
executions engines that's why sometimes

00:03:09,810 --> 00:03:14,190
we say it's like an uber API because I

00:03:12,269 --> 00:03:15,480
use one API but you can execute with

00:03:14,190 --> 00:03:18,420
multiple back

00:03:15,480 --> 00:03:20,510
or execution engine and now you can also

00:03:18,420 --> 00:03:24,540
use your favorite programming language

00:03:20,510 --> 00:03:26,310
so a little bit more detail on this so

00:03:24,540 --> 00:03:30,060
we have I mean this is the vision of

00:03:26,310 --> 00:03:33,540
beam we have the SDKs here on the left

00:03:30,060 --> 00:03:37,050
side and so that's like Java go Python

00:03:33,540 --> 00:03:39,330
scholar and sequel and then we have some

00:03:37,050 --> 00:03:40,980
magic happening and beam which are the

00:03:39,330 --> 00:03:43,080
runners there's a runner for every

00:03:40,980 --> 00:03:46,700
execution back-end and the runner

00:03:43,080 --> 00:03:50,630
translates the beam job in the SDK into

00:03:46,700 --> 00:03:53,120
the language of the execution engine and

00:03:50,630 --> 00:03:57,330
you can see there a bunch of them and

00:03:53,120 --> 00:03:59,069
more and more are coming and yeah I mean

00:03:57,330 --> 00:04:02,459
that's really nice to have that choice

00:03:59,069 --> 00:04:05,760
right so how does the API work like just

00:04:02,459 --> 00:04:09,630
concept wise so in beam they're they're

00:04:05,760 --> 00:04:11,040
called they're RP collections so the

00:04:09,630 --> 00:04:13,500
first of all there there's the pipeline

00:04:11,040 --> 00:04:15,750
the pipeline is like the the object that

00:04:13,500 --> 00:04:17,280
holds all your job information so you

00:04:15,750 --> 00:04:20,190
create that from some options which you

00:04:17,280 --> 00:04:22,169
can pass in there and then you am create

00:04:20,190 --> 00:04:24,870
P collections P collections are created

00:04:22,169 --> 00:04:26,940
by applying transforms to the pipeline

00:04:24,870 --> 00:04:28,830
so you do always like apply transform so

00:04:26,940 --> 00:04:31,050
it's really easy and this can be like

00:04:28,830 --> 00:04:33,330
you can do multiple transforms after

00:04:31,050 --> 00:04:36,750
each other or you can do you can also

00:04:33,330 --> 00:04:39,180
branch like here where you create this P

00:04:36,750 --> 00:04:42,900
call two which is like you know a branch

00:04:39,180 --> 00:04:45,840
of people one so and then you can you

00:04:42,900 --> 00:04:46,440
can run that and that pipeline it's

00:04:45,840 --> 00:04:48,840
pretty sweet

00:04:46,440 --> 00:04:51,510
so transforms are actually quite nice

00:04:48,840 --> 00:04:53,729
abstraction because transforms can be

00:04:51,510 --> 00:04:56,669
either primitive or composite what does

00:04:53,729 --> 00:04:59,520
it mean actually in beam we only have a

00:04:56,669 --> 00:05:02,100
few primitive transforms we only have

00:04:59,520 --> 00:05:04,890
like pardhu group by key assign Windows

00:05:02,100 --> 00:05:07,229
and flatten so I will explain two of

00:05:04,890 --> 00:05:08,789
them in a bit but so basically what that

00:05:07,229 --> 00:05:11,960
means you can define like composer

00:05:08,789 --> 00:05:13,830
transforms would use these and then

00:05:11,960 --> 00:05:15,840
these are actually the composer

00:05:13,830 --> 00:05:17,310
transforms like expanded to this

00:05:15,840 --> 00:05:19,169
primitive ones which is really easy

00:05:17,310 --> 00:05:21,660
because we just need to I mean as a

00:05:19,169 --> 00:05:24,570
runner creator you just need to

00:05:21,660 --> 00:05:27,060
implement those for primitive transforms

00:05:24,570 --> 00:05:28,980
and we can we can do optimizations for

00:05:27,060 --> 00:05:31,320
composite transforms but it's enough to

00:05:28,980 --> 00:05:32,880
that primitive transform so of course

00:05:31,320 --> 00:05:35,490
because this is like a big data

00:05:32,880 --> 00:05:38,640
framework we have to do a little word

00:05:35,490 --> 00:05:40,140
count and for those of you who don't

00:05:38,640 --> 00:05:42,030
know what count is basically you're

00:05:40,140 --> 00:05:44,370
trying to you have a list of words like

00:05:42,030 --> 00:05:47,100
to be or not to be and you try to count

00:05:44,370 --> 00:05:49,740
how often is like a unique word distinct

00:05:47,100 --> 00:05:52,170
word appears in that list it's a way to

00:05:49,740 --> 00:05:54,390
do that is you to use if we are talking

00:05:52,170 --> 00:05:57,210
about beam then use a pardhu which

00:05:54,390 --> 00:05:59,340
stands for parallel do and you would you

00:05:57,210 --> 00:06:01,140
would assign like a key value you would

00:05:59,340 --> 00:06:03,540
transform your words into a key value

00:06:01,140 --> 00:06:05,910
object with like one which stands for

00:06:03,540 --> 00:06:08,880
number of occurrences and then you would

00:06:05,910 --> 00:06:12,060
do a group by key which basically well

00:06:08,880 --> 00:06:15,000
shuffles the data and gives you a list

00:06:12,060 --> 00:06:16,950
of all the values for every distinct key

00:06:15,000 --> 00:06:19,680
and then you can sum them up and you

00:06:16,950 --> 00:06:24,140
know that two is twice in this list and

00:06:19,680 --> 00:06:27,000
B also and the others just once and so

00:06:24,140 --> 00:06:29,460
don't don't get confused now this is

00:06:27,000 --> 00:06:31,440
this looks really ugly and this is

00:06:29,460 --> 00:06:33,510
actually how you would do it in beam but

00:06:31,440 --> 00:06:36,450
we will see we can simplify it a lot so

00:06:33,510 --> 00:06:38,100
we we have the pipeline we created we

00:06:36,450 --> 00:06:40,950
have our list of words in this case like

00:06:38,100 --> 00:06:42,930
hello hello foster and we we have this

00:06:40,950 --> 00:06:45,630
power do this first one with the signs

00:06:42,930 --> 00:06:47,970
like the one and then we do a group by

00:06:45,630 --> 00:06:50,180
key and then we have this loop here in

00:06:47,970 --> 00:06:54,300
the second part which sums it all up

00:06:50,180 --> 00:06:57,390
yeah I mean that was pretty ugly I agree

00:06:54,300 --> 00:07:01,070
I mean I don't know a better way to

00:06:57,390 --> 00:07:04,430
write this any non comprehensible so

00:07:01,070 --> 00:07:07,950
luckily we have composer transforms so

00:07:04,430 --> 00:07:10,320
we we can simplify this now further so

00:07:07,950 --> 00:07:13,410
instead of doing the the first pardhu

00:07:10,320 --> 00:07:15,240
which we're where we do this do the end

00:07:13,410 --> 00:07:17,250
function we just use a map elements

00:07:15,240 --> 00:07:20,220
function which is slightly some more

00:07:17,250 --> 00:07:22,140
simple and we do like an integers perky

00:07:20,220 --> 00:07:26,280
composer transforms but which does

00:07:22,140 --> 00:07:29,060
basically it sounds up the value the

00:07:26,280 --> 00:07:33,600
number of occurrences for each key and

00:07:29,060 --> 00:07:35,310
we can simplify this even further by by

00:07:33,600 --> 00:07:37,170
just using this count per element from

00:07:35,310 --> 00:07:38,620
posit transform so that looks pretty

00:07:37,170 --> 00:07:42,080
simple right

00:07:38,620 --> 00:07:43,670
so they're love these transforms and

00:07:42,080 --> 00:07:45,680
beam and if you read the documentation

00:07:43,670 --> 00:07:47,780
you can you can write really readable

00:07:45,680 --> 00:07:51,470
code even in Java because that is that

00:07:47,780 --> 00:07:53,300
is a Java API and we have of course

00:07:51,470 --> 00:07:56,720
fortunately also a Python API which

00:07:53,300 --> 00:07:59,360
which looks so much nicer so here this

00:07:56,720 --> 00:08:02,180
would be the same initial example we

00:07:59,360 --> 00:08:06,560
just use Lambor functions to that do

00:08:02,180 --> 00:08:08,540
that work count and also in Python we

00:08:06,560 --> 00:08:11,240
have of course these composer transforms

00:08:08,540 --> 00:08:13,010
so this is maybe slightly simpler where

00:08:11,240 --> 00:08:16,240
we have the combined cookie function and

00:08:13,010 --> 00:08:19,610
we passed some same sum as an argument

00:08:16,240 --> 00:08:21,200
this is just a like a very quick look

00:08:19,610 --> 00:08:24,080
into the beam API I thought it would be

00:08:21,200 --> 00:08:25,730
useful there's lots of more Composer

00:08:24,080 --> 00:08:28,100
transforms you can create your own we

00:08:25,730 --> 00:08:31,340
have lots of i/o we have windowing event

00:08:28,100 --> 00:08:33,500
time watermark sight inputs I mean state

00:08:31,340 --> 00:08:35,090
and timers which is it doesn't make

00:08:33,500 --> 00:08:37,430
sense to you at the moment maybe if you

00:08:35,090 --> 00:08:40,490
haven't tried it but it's really useful

00:08:37,430 --> 00:08:43,300
concept once you learn more about beam

00:08:40,490 --> 00:08:46,580
and your pipeline gets more complicated

00:08:43,300 --> 00:08:49,760
so what does portability mean now I mean

00:08:46,580 --> 00:08:51,890
I showed you Java I showed you - where

00:08:49,760 --> 00:08:55,400
does I mean it's I mean that should

00:08:51,890 --> 00:08:57,860
already be working right so let's see

00:08:55,400 --> 00:08:59,780
first what is I mean what are the two

00:08:57,860 --> 00:09:01,520
different kinds of portability in the

00:08:59,780 --> 00:09:04,070
beam context so we have the engine

00:09:01,520 --> 00:09:06,590
portability which is like the ability to

00:09:04,070 --> 00:09:09,080
run it on different execution engines

00:09:06,590 --> 00:09:11,810
and we have the language portability

00:09:09,080 --> 00:09:17,210
which is like using different SDKs for

00:09:11,810 --> 00:09:18,560
composing the pipeline and if we look

00:09:17,210 --> 00:09:20,810
back at the vision which I showed you at

00:09:18,560 --> 00:09:25,480
the beginning this is really I mean how

00:09:20,810 --> 00:09:29,000
it should work right and in terms of

00:09:25,480 --> 00:09:32,660
engine portability it is actually true

00:09:29,000 --> 00:09:34,700
like we own the Java API we we just you

00:09:32,660 --> 00:09:36,770
know these options which we pass to the

00:09:34,700 --> 00:09:39,650
pipeline we just said run off link

00:09:36,770 --> 00:09:42,230
runner and then we do run and it really

00:09:39,650 --> 00:09:43,910
runs on flink that's pretty amazing so

00:09:42,230 --> 00:09:48,410
we have that part covered already and

00:09:43,910 --> 00:09:51,250
now what about language portability why

00:09:48,410 --> 00:09:54,699
would we use other languages well kind

00:09:51,250 --> 00:09:57,279
I mean clear I guess syntax expression

00:09:54,699 --> 00:09:59,110
of communities is a big point because

00:09:57,279 --> 00:10:01,000
there are a lot of people simply don't

00:09:59,110 --> 00:10:02,649
like Java for various reasons which I

00:10:01,000 --> 00:10:05,110
can understand I mean I'd really like to

00:10:02,649 --> 00:10:07,660
have a but it's okay but we also have a

00:10:05,110 --> 00:10:09,370
lot of libraries which is like an

00:10:07,660 --> 00:10:11,199
important factor like tensorflow are

00:10:09,370 --> 00:10:15,220
really like huge libraries which are

00:10:11,199 --> 00:10:18,970
simply not available in in in Java so

00:10:15,220 --> 00:10:22,389
that's a good reason to use Python so I

00:10:18,970 --> 00:10:24,519
was actually lying a bit to you this

00:10:22,389 --> 00:10:26,769
whole this whole portability

00:10:24,519 --> 00:10:29,439
language-wise doesn't really or didn't

00:10:26,769 --> 00:10:32,470
really work so it used to be the case

00:10:29,439 --> 00:10:35,889
that we just I mean basically only we're

00:10:32,470 --> 00:10:38,620
supporting Java and Scala in in the open

00:10:35,889 --> 00:10:40,389
source world and we had like when you

00:10:38,620 --> 00:10:44,560
use like the Google cloud you could run

00:10:40,389 --> 00:10:48,189
Python which is like not so cool right I

00:10:44,560 --> 00:10:50,889
mean it kind of breaks the promise so

00:10:48,189 --> 00:10:53,800
what we what we need is and what we

00:10:50,889 --> 00:10:57,490
worked on in the past like almost two

00:10:53,800 --> 00:11:00,579
years is to build a language portability

00:10:57,490 --> 00:11:04,120
framework into beam and it's runners so

00:11:00,579 --> 00:11:11,079
that we actually can do the full realize

00:11:04,120 --> 00:11:15,100
the full vision so how do we achieve how

00:11:11,079 --> 00:11:18,730
do we achieve it if we look at sort of

00:11:15,100 --> 00:11:21,670
the very abstract translation process of

00:11:18,730 --> 00:11:24,759
a pipeline it used to be like this where

00:11:21,670 --> 00:11:28,899
we had Java and then a bunch of runners

00:11:24,759 --> 00:11:31,000
and they all executed in Java so they

00:11:28,899 --> 00:11:33,279
need to implement their own translation

00:11:31,000 --> 00:11:36,879
way but once they translated it was fine

00:11:33,279 --> 00:11:42,069
now that we have language portability it

00:11:36,879 --> 00:11:44,769
seems like well maybe not very good idea

00:11:42,069 --> 00:11:48,129
but it's presently possible to just you

00:11:44,769 --> 00:11:51,309
know let every SDK figure out a way to

00:11:48,129 --> 00:11:52,809
translate to every execution engine then

00:11:51,309 --> 00:11:54,939
the execution engine has like various

00:11:52,809 --> 00:11:57,730
their own various ways of supporting

00:11:54,939 --> 00:11:59,829
that language but just that just seems

00:11:57,730 --> 00:12:02,709
like a terrible idea very complicated

00:11:59,829 --> 00:12:04,290
and replicating a lot of work so what

00:12:02,709 --> 00:12:07,829
what we did is

00:12:04,290 --> 00:12:11,910
we introduced the the runner API which

00:12:07,829 --> 00:12:13,889
takes the pipeline from the SDK and sort

00:12:11,910 --> 00:12:16,709
of transforms it into a language

00:12:13,889 --> 00:12:19,439
agnostic format let's call it a runner

00:12:16,709 --> 00:12:20,519
API so it's it's based on protobuf I

00:12:19,439 --> 00:12:23,549
mean doesn't really matter it's just

00:12:20,519 --> 00:12:27,389
like a format that is consistent across

00:12:23,549 --> 00:12:30,119
languages so and then what we also need

00:12:27,389 --> 00:12:32,429
it is during execution we have like this

00:12:30,119 --> 00:12:34,079
language dependent parts like when the

00:12:32,429 --> 00:12:35,579
execution engines or most of them are

00:12:34,079 --> 00:12:37,709
actually all of them are written in Java

00:12:35,579 --> 00:12:41,669
so when you have Python you need to

00:12:37,709 --> 00:12:44,699
figure out a way to send data to to that

00:12:41,669 --> 00:12:48,949
Python process and access state and on

00:12:44,699 --> 00:12:53,449
all that and this is called the Sun API

00:12:48,949 --> 00:12:56,389
FN API yeah and that way we pretty much

00:12:53,449 --> 00:12:59,729
only have these two extra layers and

00:12:56,389 --> 00:13:01,859
just have to make sure the runners are

00:12:59,729 --> 00:13:02,100
compatible with that and then we're good

00:13:01,859 --> 00:13:06,959
to go

00:13:02,100 --> 00:13:09,929
so let me simplify this a lot so we have

00:13:06,959 --> 00:13:12,480
the if the old way was like we have the

00:13:09,929 --> 00:13:14,699
SDK and the Runner and we have for

00:13:12,480 --> 00:13:16,319
example a execution engine like linked

00:13:14,699 --> 00:13:18,269
with a bunch of tasks and they all these

00:13:16,319 --> 00:13:21,959
were in Java so and that worked pretty

00:13:18,269 --> 00:13:25,529
well the new way is a bit different so

00:13:21,959 --> 00:13:28,109
in the new way we have the SDK here

00:13:25,529 --> 00:13:31,739
which uses to run our API to produce

00:13:28,109 --> 00:13:36,689
this Universal pipeline format and then

00:13:31,739 --> 00:13:41,309
we actually have the job API which is a

00:13:36,689 --> 00:13:43,350
way to send this pipeline to the job

00:13:41,309 --> 00:13:45,389
server and the job server is really a

00:13:43,350 --> 00:13:47,730
beam concept now it used to be that

00:13:45,389 --> 00:13:49,139
every runner had you know every

00:13:47,730 --> 00:13:51,329
execution and had its own way of

00:13:49,139 --> 00:13:54,119
submitting applications and but we

00:13:51,329 --> 00:13:55,889
wanted to you know really get everything

00:13:54,119 --> 00:13:58,350
portable so we created the job server

00:13:55,889 --> 00:14:02,279
and in the job server the runner

00:13:58,350 --> 00:14:06,539
translates this runner API pipeline and

00:14:02,279 --> 00:14:10,999
then it executed on the engine of your

00:14:06,539 --> 00:14:13,649
choice but of course we have these like

00:14:10,999 --> 00:14:15,089
Python blobs or go blobs in between

00:14:13,649 --> 00:14:17,370
which we don't really understand and

00:14:15,089 --> 00:14:19,980
whenever we have that we

00:14:17,370 --> 00:14:22,590
we have a special well tasked I called

00:14:19,980 --> 00:14:25,020
executable stage which is a fancy name

00:14:22,590 --> 00:14:26,760
for we don't know what to do with this

00:14:25,020 --> 00:14:30,090
so we have to send it to an external

00:14:26,760 --> 00:14:32,580
process which is called the SDK harness

00:14:30,090 --> 00:14:34,710
and that harness exists for every

00:14:32,580 --> 00:14:40,860
language like for Java Python and go

00:14:34,710 --> 00:14:43,260
so whenever so whenever we I mean so we

00:14:40,860 --> 00:14:45,060
put the we create the harness when we

00:14:43,260 --> 00:14:47,490
start a job with the Python code for

00:14:45,060 --> 00:14:50,940
instance and then whenever we receive

00:14:47,490 --> 00:14:52,560
data in that task we we send that to the

00:14:50,940 --> 00:14:54,630
external process the external process

00:14:52,560 --> 00:14:58,590
does its processing in sense that back

00:14:54,630 --> 00:15:00,030
you know it's very simplified and this

00:14:58,590 --> 00:15:03,540
there are some challenges to that

00:15:00,030 --> 00:15:05,190
because there is not a great cost but

00:15:03,540 --> 00:15:06,930
there are some costs when you send data

00:15:05,190 --> 00:15:08,870
to an external process right because you

00:15:06,930 --> 00:15:11,430
need to serialize the data and

00:15:08,870 --> 00:15:13,950
deserialize it again so we build in some

00:15:11,430 --> 00:15:16,800
optimization called fusion which tries

00:15:13,950 --> 00:15:20,460
to combine as many of these Python

00:15:16,800 --> 00:15:23,760
stages for instance into one SDK harness

00:15:20,460 --> 00:15:28,260
so we don't do any like the duplicate

00:15:23,760 --> 00:15:32,850
serialization work how does the SDK

00:15:28,260 --> 00:15:34,410
harness work so first of all the SDK

00:15:32,850 --> 00:15:38,250
owners needs to be bootstrapped somehow

00:15:34,410 --> 00:15:38,700
right so what we typically do is we use

00:15:38,250 --> 00:15:41,190
docker

00:15:38,700 --> 00:15:43,050
so we have an environment which contains

00:15:41,190 --> 00:15:46,320
all the dependencies like my tensor flow

00:15:43,050 --> 00:15:48,120
or my lamp I and and just use this

00:15:46,320 --> 00:15:50,010
docker image directly we can specify

00:15:48,120 --> 00:15:52,260
that in the options that's a really easy

00:15:50,010 --> 00:15:54,960
way of deploying because you you have

00:15:52,260 --> 00:15:56,430
image registry and you just download

00:15:54,960 --> 00:15:58,500
that image automatically and start it

00:15:56,430 --> 00:16:04,260
but some people don't want to use docker

00:15:58,500 --> 00:16:06,090
because for various reasons and so you

00:16:04,260 --> 00:16:07,440
can also start like a process based

00:16:06,090 --> 00:16:10,320
execution but then you have to make sure

00:16:07,440 --> 00:16:13,320
you set up the environment thank you the

00:16:10,320 --> 00:16:15,600
environment like manually and it's also

00:16:13,320 --> 00:16:22,080
possible to run this embedded in case

00:16:15,600 --> 00:16:24,210
your you are using Java and so there's I

00:16:22,080 --> 00:16:26,220
mean there's a lot of happening with of

00:16:24,210 --> 00:16:28,470
communication between like the backend

00:16:26,220 --> 00:16:30,630
and the SDK harness like obviously we

00:16:28,470 --> 00:16:31,329
need to control like we have like

00:16:30,630 --> 00:16:33,129
control play

00:16:31,329 --> 00:16:36,610
a data plane we have a way to access

00:16:33,129 --> 00:16:38,319
State and report progress and also

00:16:36,610 --> 00:16:40,239
logging I mean everything is locked so

00:16:38,319 --> 00:16:41,860
you you know actually was what is

00:16:40,239 --> 00:16:43,540
happening inside external process

00:16:41,860 --> 00:16:48,670
because otherwise debugging it would be

00:16:43,540 --> 00:16:52,809
would be really hard so what is now

00:16:48,670 --> 00:16:58,689
missing is and kind of a problem it is

00:16:52,809 --> 00:17:00,549
not only I mean a runner is is like SDK

00:16:58,689 --> 00:17:04,209
is only complete if you can read and

00:17:00,549 --> 00:17:06,399
write data right because it's not really

00:17:04,209 --> 00:17:08,769
worth anything if we can support all the

00:17:06,399 --> 00:17:13,089
primitive transforms we also have to be

00:17:08,769 --> 00:17:16,240
able to actually have that connectors

00:17:13,089 --> 00:17:18,429
which we have in Java in in any SDK

00:17:16,240 --> 00:17:20,589
available and you can see there a lot of

00:17:18,429 --> 00:17:22,299
them available now it would be kind of a

00:17:20,589 --> 00:17:25,600
lot of work to replicate them and the

00:17:22,299 --> 00:17:27,819
language support for example when you

00:17:25,600 --> 00:17:29,830
want to create a Kafka connector in

00:17:27,819 --> 00:17:32,649
Python the language support is not so

00:17:29,830 --> 00:17:35,260
good in Java it's really good so ideally

00:17:32,649 --> 00:17:39,250
we would we would just use the Java

00:17:35,260 --> 00:17:43,179
connector in Python and not you

00:17:39,250 --> 00:17:44,950
recreated in in Python and turns out we

00:17:43,179 --> 00:17:48,100
can actually do that and that's a pretty

00:17:44,950 --> 00:17:49,659
amazing solution we can simply use that

00:17:48,100 --> 00:17:53,200
process which I've described to run

00:17:49,659 --> 00:17:53,529
cross language pipelines so how does it

00:17:53,200 --> 00:17:55,600
work

00:17:53,529 --> 00:17:57,460
theoretically I mean we're finalizing

00:17:55,600 --> 00:17:59,260
like the specification at the moment but

00:17:57,460 --> 00:18:01,809
it's sort of like this so you have a

00:17:59,260 --> 00:18:04,419
Python job and I mean probably it's not

00:18:01,809 --> 00:18:06,370
going to be named IO expansion but it's

00:18:04,419 --> 00:18:08,679
kind of like it like a demure object

00:18:06,370 --> 00:18:11,260
where you specify your IO like cough

00:18:08,679 --> 00:18:13,090
kayo or maybe the full Java name I mean

00:18:11,260 --> 00:18:16,690
though it will be made a bit simpler and

00:18:13,090 --> 00:18:18,519
you pass some configuration and then of

00:18:16,690 --> 00:18:21,220
course I mean Python doesn't understand

00:18:18,519 --> 00:18:23,440
this but when we do the translation to

00:18:21,220 --> 00:18:25,389
the runner API we actually have like an

00:18:23,440 --> 00:18:28,299
expansion service a Java expansion

00:18:25,389 --> 00:18:31,570
service running if we want to in the

00:18:28,299 --> 00:18:34,690
case of Java and we so we take that stop

00:18:31,570 --> 00:18:40,380
this placeholder and expand it into like

00:18:34,690 --> 00:18:44,320
like a native Java Kafka transform so

00:18:40,380 --> 00:18:45,100
and then when then we do the rest of the

00:18:44,320 --> 00:18:47,860
translation

00:18:45,100 --> 00:18:50,020
and during the when the job runs we

00:18:47,860 --> 00:18:52,419
actually have now two different kinds of

00:18:50,020 --> 00:18:55,650
SDK harness running so we have a Java

00:18:52,419 --> 00:18:58,059
one for our Kafka sauce and then we have

00:18:55,650 --> 00:18:59,679
maybe some Python data processing

00:18:58,059 --> 00:19:01,840
afterwards we will do some map and count

00:18:59,679 --> 00:19:04,270
and we of course also have the native

00:19:01,840 --> 00:19:06,309
trends like native link or whatever

00:19:04,270 --> 00:19:08,410
you're using execution engine transform

00:19:06,309 --> 00:19:11,230
like a group by key which which just

00:19:08,410 --> 00:19:13,030
doesn't need an SDK harness or anything

00:19:11,230 --> 00:19:19,570
because it's supported by the execution

00:19:13,030 --> 00:19:21,220
engine yeah so this is sort of how

00:19:19,570 --> 00:19:22,929
portability works there are a lot of

00:19:21,220 --> 00:19:28,659
details of course but it's a twenty

00:19:22,929 --> 00:19:32,909
minutes talk so how how far are we so we

00:19:28,659 --> 00:19:36,850
have the engine portability and we have

00:19:32,909 --> 00:19:39,490
the language portability almost I would

00:19:36,850 --> 00:19:41,289
say I mean for developers you can try it

00:19:39,490 --> 00:19:44,110
out yourself I have a link for you in

00:19:41,289 --> 00:19:46,570
the end you can try it out it works we

00:19:44,110 --> 00:19:48,760
just have to make it a bit better you

00:19:46,570 --> 00:19:50,559
know there are some some like we have to

00:19:48,760 --> 00:19:52,600
tune a bit of performance although we

00:19:50,559 --> 00:19:56,020
have estimated five to ten percent only

00:19:52,600 --> 00:19:57,370
overhead in most cases and then cross

00:19:56,020 --> 00:19:59,320
language pipeline support needs a bit

00:19:57,370 --> 00:20:01,450
more and specification but that's going

00:19:59,320 --> 00:20:02,950
to happen in next week's there's also

00:20:01,450 --> 00:20:05,919
this fancy thing called bootable do

00:20:02,950 --> 00:20:08,020
event which you can read up but that's

00:20:05,919 --> 00:20:12,820
not so important there's a compatibility

00:20:08,020 --> 00:20:15,010
matrix which tracks like the status for

00:20:12,820 --> 00:20:17,200
portability of all runners there's a

00:20:15,010 --> 00:20:19,360
link here and sling actually it's like

00:20:17,200 --> 00:20:21,640
the best runner I would say because it

00:20:19,360 --> 00:20:24,240
it supports most features at the moment

00:20:21,640 --> 00:20:27,780
and the others are going to catch up and

00:20:24,240 --> 00:20:31,179
that brings me to the end of my talk

00:20:27,780 --> 00:20:33,340
please check out the portability website

00:20:31,179 --> 00:20:35,200
or just go to the normal beam website if

00:20:33,340 --> 00:20:37,630
you want to learn more about beam we

00:20:35,200 --> 00:20:39,880
have mailing lists and an awesome select

00:20:37,630 --> 00:20:42,659
channel which is where were there a lot

00:20:39,880 --> 00:20:43,990
of help for people yeah and that's it

00:20:42,659 --> 00:20:51,839
thank you

00:20:43,990 --> 00:20:51,839
[Applause]

00:21:12,010 --> 00:21:19,810
to compile to what sorry common bytecode

00:21:16,590 --> 00:21:23,170
yeah so the question is why not use

00:21:19,810 --> 00:21:25,840
something like Apache tinker tinker pop

00:21:23,170 --> 00:21:27,510
which uses like an intermediate common

00:21:25,840 --> 00:21:30,130
intermediate format between the

00:21:27,510 --> 00:21:31,950
languages and then or which is like

00:21:30,130 --> 00:21:35,140
bytecode which can then be executed

00:21:31,950 --> 00:21:37,420
there are a lot of other frameworks with

00:21:35,140 --> 00:21:40,090
do that for example flink as a Python

00:21:37,420 --> 00:21:41,710
API which uses item which is sort of

00:21:40,090 --> 00:21:43,870
like the same idea you can generate

00:21:41,710 --> 00:21:46,810
bytecode from Python we want to be able

00:21:43,870 --> 00:21:48,490
to support all kinds of libraries like x

00:21:46,810 --> 00:21:50,590
the flow which is like a native c

00:21:48,490 --> 00:21:53,470
library and that you can only achieve if

00:21:50,590 --> 00:21:56,230
you run like a c python interpreter and

00:21:53,470 --> 00:21:58,440
not like some custom version of python

00:21:56,230 --> 00:22:01,830
which only supports a subset of python

00:21:58,440 --> 00:22:01,830
that's a reason

00:22:20,970 --> 00:22:28,950
I have em so yeah I repeat the question

00:22:26,400 --> 00:22:32,610
so how is the debugging experience like

00:22:28,950 --> 00:22:34,800
in these Python libraries when when you

00:22:32,610 --> 00:22:36,990
run into an error in python like how

00:22:34,800 --> 00:22:39,800
fast you see it and when you execute on

00:22:36,990 --> 00:22:42,210
a on a well essentially java runtime

00:22:39,800 --> 00:22:44,790
it's actually pretty good and it's been

00:22:42,210 --> 00:22:46,590
part of the design so when in python you

00:22:44,790 --> 00:22:50,580
see an exception it will be like

00:22:46,590 --> 00:22:53,310
forwarded directly to to the to the op

00:22:50,580 --> 00:22:56,400
like java operator and it will catch an

00:22:53,310 --> 00:22:58,320
arrow there and so and use you do to the

00:22:56,400 --> 00:23:01,080
logging and stuff like that you actually

00:22:58,320 --> 00:23:02,520
see immediately what cat and the errors

00:23:01,080 --> 00:23:04,320
also sent back it's like so you see the

00:23:02,520 --> 00:23:06,810
error message immediately there and your

00:23:04,320 --> 00:23:11,930
pipeline will fail because if the runner

00:23:06,810 --> 00:23:11,930
receives a failure it should fail yeah

00:23:15,980 --> 00:23:22,770
good question

00:23:17,850 --> 00:23:25,980
I'm not working on yeah so the Python 3

00:23:22,770 --> 00:23:30,930
is it supported or not it is supported

00:23:25,980 --> 00:23:33,330
but it is like 99% done so it is there

00:23:30,930 --> 00:23:35,220
you can use it there are test cases and

00:23:33,330 --> 00:23:38,400
everything it's just not you know

00:23:35,220 --> 00:23:41,880
officially been released because I'm not

00:23:38,400 --> 00:23:44,700
working on the Python site myself so I'm

00:23:41,880 --> 00:23:46,020
expected to be done actually in the 211

00:23:44,700 --> 00:23:51,170
release which is the next bean release

00:23:46,020 --> 00:23:51,170
should be out next month yeah

00:23:51,320 --> 00:23:54,430
[Music]

00:23:59,380 --> 00:24:06,229
thank you

00:24:02,460 --> 00:24:06,229
[Applause]

00:24:12,429 --> 00:24:14,490
you

00:24:20,559 --> 00:24:22,620
you

00:25:01,430 --> 00:25:03,490
you

00:25:08,740 --> 00:25:10,800

YouTube URL: https://www.youtube.com/watch?v=A3L3iKCett4


