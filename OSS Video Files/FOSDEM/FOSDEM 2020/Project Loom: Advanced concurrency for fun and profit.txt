Title: Project Loom: Advanced concurrency for fun and profit
Publication date: 2020-07-13
Playlist: FOSDEM 2020
Description: 
	by Andrew Haley

At: FOSDEM 2020
https://video.fosdem.org/2020/H.1302/loom.webm

Project Loom, an OpenJDK project, is "intended to explore, incubate and deliver Java VM features and APIs built on top of them for the purpose of supporting easy-to-use, high-throughput lightweight concurrency and new programming models on the Java platform."  These feature include Lightweight Threads, delimited continuations, and tail-call elimination.


The speaker, a Project Loom team member, will describe the project in depth, in particular the gnarly details of how coroutine and continuation scheduling mechanism works, and a new feature, Scoped Locals.

Room: H.1302 (Depage)
Scheduled start: 2020-02-01 10:20:00
Captions: 
	00:00:04,590 --> 00:00:12,389
thank you mark who gave an admirable

00:00:08,330 --> 00:00:15,840
introduction to some of the motivation

00:00:12,389 --> 00:00:20,010
behind project loom I'll go over that a

00:00:15,840 --> 00:00:22,440
little bit just for just to add a little

00:00:20,010 --> 00:00:28,380
bit more but I'll also talk a bit about

00:00:22,440 --> 00:00:30,480
how this stuff actually works so one of

00:00:28,380 --> 00:00:31,590
the marvelous things about Java well

00:00:30,480 --> 00:00:34,110
there are two marvelous things about

00:00:31,590 --> 00:00:37,109
Java in its early incarnation firstly

00:00:34,110 --> 00:00:39,480
that there was essentially no innovation

00:00:37,109 --> 00:00:42,210
in Java there was nothing new it was

00:00:39,480 --> 00:00:44,100
just a practical synthesis of a whole

00:00:42,210 --> 00:00:47,820
bunch of stuff that already existed in

00:00:44,100 --> 00:00:49,379
other programming languages a lot of

00:00:47,820 --> 00:00:52,649
them were just research languages though

00:00:49,379 --> 00:00:55,319
the genius of Java was to come up with a

00:00:52,649 --> 00:00:57,960
synthesis of some of the best ideas in

00:00:55,319 --> 00:00:59,699
computer science in a practical language

00:00:57,960 --> 00:01:02,429
that could be used by normal human

00:00:59,699 --> 00:01:06,050
beings that was a tremendous achievement

00:01:02,429 --> 00:01:11,070
and one of the things that Java did was

00:01:06,050 --> 00:01:13,860
concurrency multi-threading which was to

00:01:11,070 --> 00:01:16,439
actually get a portable definition of

00:01:13,860 --> 00:01:18,420
what a thread actually was which didn't

00:01:16,439 --> 00:01:19,860
depend really on any particular hardware

00:01:18,420 --> 00:01:23,039
implementations threads was a

00:01:19,860 --> 00:01:25,320
considerable considerable achievements

00:01:23,039 --> 00:01:26,969
at the time but as Mark said with 25

00:01:25,320 --> 00:01:30,659
years down the road and the cracks are

00:01:26,969 --> 00:01:32,430
beginning to show and servers in

00:01:30,659 --> 00:01:33,930
particular but all sorts of Java

00:01:32,430 --> 00:01:39,630
applications are running a lot of

00:01:33,930 --> 00:01:42,630
threads but manual use of threads II's

00:01:39,630 --> 00:01:45,960
using Java dot Languedoc thread by hand

00:01:42,630 --> 00:01:48,539
is clumsy error-prone you can end up

00:01:45,960 --> 00:01:50,789
with a whole load of threads hanging

00:01:48,539 --> 00:01:52,049
around not doing much and also that they

00:01:50,789 --> 00:01:54,390
were very heavyweight because they

00:01:52,049 --> 00:01:57,479
require on kernel lightweight processes

00:01:54,390 --> 00:02:02,490
now a kernel lightweight process in

00:01:57,479 --> 00:02:05,810
Linux is not really our idea at our end

00:02:02,490 --> 00:02:11,270
of what lightweight actually means even

00:02:05,810 --> 00:02:13,440
on a 32-bit system it can sometimes

00:02:11,270 --> 00:02:17,370
allocate a megabyte of address space

00:02:13,440 --> 00:02:20,800
just for the thread local heap

00:02:17,370 --> 00:02:23,670
so what we actually need again as Mark

00:02:20,800 --> 00:02:29,140
said is some more lightweight

00:02:23,670 --> 00:02:30,970
representation we don't want to we don't

00:02:29,140 --> 00:02:32,380
want the kernel to have to preempt

00:02:30,970 --> 00:02:35,260
threads we want to do it in user space

00:02:32,380 --> 00:02:38,260
because those of you have measured it

00:02:35,260 --> 00:02:40,360
we'll know that on any kind of Unix a

00:02:38,260 --> 00:02:42,730
Linux system it takes an ungodly long

00:02:40,360 --> 00:02:44,970
time to get into the kernel and back out

00:02:42,730 --> 00:02:48,310
again usually about a microsecond or so

00:02:44,970 --> 00:02:51,250
and pre-empting threads is quite

00:02:48,310 --> 00:02:52,870
expensive all right I should give Ron

00:02:51,250 --> 00:02:54,400
credit at this point there's a couple of

00:02:52,870 --> 00:02:56,620
the slides that I stole from you so

00:02:54,400 --> 00:03:00,280
thank you I'm sure you recognize them

00:02:56,620 --> 00:03:03,880
and Java threads don't need a lot of

00:03:00,280 --> 00:03:05,680
this stuff so again as Mark said

00:03:03,880 --> 00:03:09,310
programmers have responded to this by

00:03:05,680 --> 00:03:11,530
using reactive programming so you would

00:03:09,310 --> 00:03:13,840
like lots and lots of little tasks and

00:03:11,530 --> 00:03:16,510
the task would there's all run a

00:03:13,840 --> 00:03:18,040
synchronously and they don't block so

00:03:16,510 --> 00:03:19,450
whenever you need to block what you

00:03:18,040 --> 00:03:22,360
actually do is send the message out so

00:03:19,450 --> 00:03:24,310
you will have your code and it will send

00:03:22,360 --> 00:03:28,120
a message to the database service saying

00:03:24,310 --> 00:03:30,550
can I have a lookup for this please and

00:03:28,120 --> 00:03:32,680
the database server would then send a

00:03:30,550 --> 00:03:36,990
message to somebody else who would in

00:03:32,680 --> 00:03:39,280
turn respond to the result of the query

00:03:36,990 --> 00:03:43,990
there are people who like doing this

00:03:39,280 --> 00:03:45,580
stuff but it's quite difficult to write

00:03:43,990 --> 00:03:52,420
it's very difficult to understand

00:03:45,580 --> 00:03:54,220
debugging it is hilarious and so but

00:03:52,420 --> 00:03:56,380
this this this was done a while back

00:03:54,220 --> 00:03:59,050
this was done in this small talk eighty

00:03:56,380 --> 00:04:01,510
user interfaces back in what forty years

00:03:59,050 --> 00:04:03,880
ago where the system would be forever

00:04:01,510 --> 00:04:05,530
sending new messages which you would

00:04:03,880 --> 00:04:07,660
have to handle some way but it's

00:04:05,530 --> 00:04:10,480
difficult to do and I was despite it

00:04:07,660 --> 00:04:12,100
being pretty efficient we don't need to

00:04:10,480 --> 00:04:15,100
have so many threads we just schedule

00:04:12,100 --> 00:04:17,650
everything onto thread pools now if you

00:04:15,100 --> 00:04:20,410
if your thread pool is the same as size

00:04:17,650 --> 00:04:21,940
as the number of actual cores you have

00:04:20,410 --> 00:04:24,670
in your physical machine that works

00:04:21,940 --> 00:04:29,350
beautifully because the operating system

00:04:24,670 --> 00:04:33,650
never needs to preempt any threads

00:04:29,350 --> 00:04:35,420
so yes yes I've got a got a bit ahead of

00:04:33,650 --> 00:04:38,810
myself now oh yes the unit tests are

00:04:35,420 --> 00:04:40,970
difficult to maintain so why not reduce

00:04:38,810 --> 00:04:42,770
the weight of instances of thread Java

00:04:40,970 --> 00:04:44,300
threads don't need very much context

00:04:42,770 --> 00:04:46,700
really a certainly an awful lot less

00:04:44,300 --> 00:04:48,320
than kernel threads do and we should be

00:04:46,700 --> 00:04:50,330
able to get the total footprint of a

00:04:48,320 --> 00:04:52,580
thread down to a few hundred bytes this

00:04:50,330 --> 00:04:55,690
has been done in the past I mean the

00:04:52,580 --> 00:04:58,430
word systems going back even as far as

00:04:55,690 --> 00:05:00,830
the 1960s I believe with

00:04:58,430 --> 00:05:02,480
super-lightweight threads to do this

00:05:00,830 --> 00:05:07,280
sort of thing so there is a fair bit of

00:05:02,480 --> 00:05:11,780
prior art here but how can we bring this

00:05:07,280 --> 00:05:14,150
to Java so yes there are OS threads

00:05:11,780 --> 00:05:18,080
heavy right megabytes I've said all of

00:05:14,150 --> 00:05:20,690
that this is what we can do we can get

00:05:18,080 --> 00:05:24,020
userspace threads down to a few hundreds

00:05:20,690 --> 00:05:26,600
of bytes the stack that gets sock okay

00:05:24,020 --> 00:05:30,470
gets allocated sorry the important thing

00:05:26,600 --> 00:05:32,150
here is that the stack for a userspace

00:05:30,470 --> 00:05:35,030
thread is just going to be a few hundred

00:05:32,150 --> 00:05:38,240
bytes whereas the smallest stack that a

00:05:35,030 --> 00:05:41,600
kernel thread can possibly have is one

00:05:38,240 --> 00:05:45,020
kernel page and these are allocated

00:05:41,600 --> 00:05:48,140
lazily as you grow your spec clearly if

00:05:45,020 --> 00:05:50,060
you can fit several thread stacks into a

00:05:48,140 --> 00:05:52,100
single page which you certainly can I

00:05:50,060 --> 00:05:55,190
mean pages are typically 4k but they may

00:05:52,100 --> 00:06:01,870
be as big as 64 K you really are winning

00:05:55,190 --> 00:06:01,870
big-time yes yes yes yes right

00:06:01,960 --> 00:06:09,380
but thread locals and thread counts

00:06:05,210 --> 00:06:10,850
where they used all over the place so

00:06:09,380 --> 00:06:13,520
there's some parts of the API that are

00:06:10,850 --> 00:06:19,490
no longer a match for this lightweight

00:06:13,520 --> 00:06:21,680
way of working and thread could be

00:06:19,490 --> 00:06:23,840
cleaned up by moving removing long

00:06:21,680 --> 00:06:25,820
deprecated methods but as we all know

00:06:23,840 --> 00:06:29,330
it's extremely difficult to remove

00:06:25,820 --> 00:06:32,000
anything from Java so we really need a

00:06:29,330 --> 00:06:32,480
better abstraction for all of this so

00:06:32,000 --> 00:06:35,390
here we are

00:06:32,480 --> 00:06:36,290
virtual threads let's implement just

00:06:35,390 --> 00:06:37,970
what we need

00:06:36,290 --> 00:06:40,880
let's switch between threads and years

00:06:37,970 --> 00:06:41,599
of space let's only keep as much spec as

00:06:40,880 --> 00:06:44,419
we need

00:06:41,599 --> 00:06:45,919
now we won't be able to block in native

00:06:44,419 --> 00:06:48,259
code because that requires a full

00:06:45,919 --> 00:06:52,669
colonel task switch but there is a way

00:06:48,259 --> 00:06:55,939
around this there have been a few

00:06:52,669 --> 00:06:58,729
changes in the project recently but most

00:06:55,939 --> 00:07:02,179
particularly a virtual thread is now a

00:06:58,729 --> 00:07:03,830
subclass of java.lang thread now

00:07:02,179 --> 00:07:06,080
whenever virtual flesh is running it is

00:07:03,830 --> 00:07:07,520
mounted on a carrier third this is very

00:07:06,080 --> 00:07:09,770
important so your carrier thread will

00:07:07,520 --> 00:07:13,039
just be a thread out of your usual

00:07:09,770 --> 00:07:15,379
thread pool and when we switch virtual

00:07:13,039 --> 00:07:21,680
threads we have to dismount the virtual

00:07:15,379 --> 00:07:23,119
thread from its carrier thread yeah

00:07:21,680 --> 00:07:27,020
these slides are in a slightly funny

00:07:23,119 --> 00:07:32,029
order the problem is you've got your

00:07:27,020 --> 00:07:34,309
stack which is sitting on a carrier

00:07:32,029 --> 00:07:36,379
third this is this is the actual stack

00:07:34,309 --> 00:07:38,809
that's been provided to us by the kernel

00:07:36,379 --> 00:07:41,419
in the stack is the record of execution

00:07:38,809 --> 00:07:46,039
of your Java program what we actually

00:07:41,419 --> 00:07:48,649
need to do is to detach the stack frames

00:07:46,039 --> 00:07:51,610
from this back move them into the Java

00:07:48,649 --> 00:07:54,019
heap somewhere and then mount another

00:07:51,610 --> 00:07:55,909
virtual thread onto the same carrier

00:07:54,019 --> 00:08:01,599
thread and to do that we have to copy

00:07:55,909 --> 00:08:03,349
the stack now when I first saw this I

00:08:01,599 --> 00:08:06,680
was appalled

00:08:03,349 --> 00:08:08,869
you mean every time that we cop every

00:08:06,680 --> 00:08:11,029
time we dismount a thread for any

00:08:08,869 --> 00:08:15,289
blocking call at all we're having to

00:08:11,029 --> 00:08:17,719
copy the entire stack around how can

00:08:15,289 --> 00:08:20,329
this possibly make any sense shouldn't

00:08:17,719 --> 00:08:22,309
we just allocate stacks for virtual

00:08:20,329 --> 00:08:23,959
threads on the heap instead rather than

00:08:22,309 --> 00:08:28,699
I mean it's the obvious other way of

00:08:23,959 --> 00:08:31,899
doing it rather than allocating them in

00:08:28,699 --> 00:08:34,099
the stack space now it sounds like

00:08:31,899 --> 00:08:36,199
copying this stack is going to be a

00:08:34,099 --> 00:08:38,689
fabulously expensive operation but it

00:08:36,199 --> 00:08:42,409
it's actually isn't there's a couple of

00:08:38,689 --> 00:08:45,139
reasons for this one is that our

00:08:42,409 --> 00:08:48,500
computers are tremendously good at

00:08:45,139 --> 00:08:51,110
copying anybody who's spent a while

00:08:48,500 --> 00:08:53,149
observing the computer programs that

00:08:51,110 --> 00:08:54,089
actually run on our computers every day

00:08:53,149 --> 00:08:55,529
well

00:08:54,089 --> 00:08:58,860
observed that they spend most of their

00:08:55,529 --> 00:09:00,569
time just moving stuff around that's the

00:08:58,860 --> 00:09:03,899
nature of computers that's the nature of

00:09:00,569 --> 00:09:06,329
how they're used and therefore the

00:09:03,899 --> 00:09:08,040
people who design the computers that we

00:09:06,329 --> 00:09:11,129
use have gone to extraordinary lengths

00:09:08,040 --> 00:09:15,209
to make just moving stuff around very

00:09:11,129 --> 00:09:17,809
fast particularly with caches and

00:09:15,209 --> 00:09:21,779
particularly the accessing dynamic Ram

00:09:17,809 --> 00:09:24,839
sequentially is very very quick and it

00:09:21,779 --> 00:09:27,300
does prefetching and so on well we don't

00:09:24,839 --> 00:09:29,009
actually have to copy the entire stack

00:09:27,300 --> 00:09:30,959
when a virtual thread is a mounted now

00:09:29,009 --> 00:09:33,449
all we actually have to copy are the

00:09:30,959 --> 00:09:37,079
frames that have been altered since last

00:09:33,449 --> 00:09:39,180
time we unmounted the virtual thread the

00:09:37,079 --> 00:09:41,519
details of precisely how this works are

00:09:39,180 --> 00:09:44,519
kind of gnarly and this is return

00:09:41,519 --> 00:09:48,569
barriers thank you if you want to give

00:09:44,519 --> 00:09:51,209
it a name but at that point you're

00:09:48,569 --> 00:09:54,120
starting to see why this is a cheap

00:09:51,209 --> 00:09:57,050
operation the other thing to observe is

00:09:54,120 --> 00:10:00,449
that Java stack frames are small and

00:09:57,050 --> 00:10:02,189
they're small because you don't have

00:10:00,449 --> 00:10:04,050
local strings you don't have local

00:10:02,189 --> 00:10:09,749
arrays you don't have any of this stuff

00:10:04,050 --> 00:10:11,730
all that is in a java thread are your

00:10:09,749 --> 00:10:13,769
local variables and your local variables

00:10:11,730 --> 00:10:15,600
are always either scalars or references

00:10:13,769 --> 00:10:17,459
to an object somewhere else so the

00:10:15,600 --> 00:10:22,559
threads are small copying them on and

00:10:17,459 --> 00:10:24,300
off when we unmount is pretty cheap but

00:10:22,559 --> 00:10:26,670
we can't get away with that with native

00:10:24,300 --> 00:10:29,999
code we can't unmount stacks with native

00:10:26,670 --> 00:10:33,600
frames the reason reasons for this are

00:10:29,999 --> 00:10:37,170
quite complicated but the problem is

00:10:33,600 --> 00:10:38,999
that native stacks often contain

00:10:37,170 --> 00:10:41,790
pointers that a point isn't pointing

00:10:38,999 --> 00:10:44,040
into the stack frame and we'd have to do

00:10:41,790 --> 00:10:46,790
some really fancy footwork of relocating

00:10:44,040 --> 00:10:50,550
the stack frame in if we wanted to

00:10:46,790 --> 00:10:54,389
unmount a virtual thread from a stack

00:10:50,550 --> 00:10:57,740
over here and copy it to a stack over to

00:10:54,389 --> 00:10:57,740
a carrier thread over there

00:10:58,209 --> 00:11:05,519
all right so let's say we've got an

00:11:00,970 --> 00:11:08,139
unmounted thread over here somewhere

00:11:05,519 --> 00:11:11,499
what do we do about object pointers

00:11:08,139 --> 00:11:14,230
because we know that saved on the stack

00:11:11,499 --> 00:11:16,420
there will be a whole bunch of object

00:11:14,230 --> 00:11:19,059
pointers and the garbage collector this

00:11:16,420 --> 00:11:20,040
is Java is moving stuff around all the

00:11:19,059 --> 00:11:23,949
time

00:11:20,040 --> 00:11:26,230
how will the garbage collector be able

00:11:23,949 --> 00:11:28,600
to do that because if you look at the

00:11:26,230 --> 00:11:30,670
structure of this class here Java line

00:11:28,600 --> 00:11:34,290
continuation I should just explain a

00:11:30,670 --> 00:11:37,569
continuation is basically just the

00:11:34,290 --> 00:11:40,540
running context of a Java program a

00:11:37,569 --> 00:11:44,470
virtual thread is composed of its

00:11:40,540 --> 00:11:46,720
continuation plus a bit more stuff so

00:11:44,470 --> 00:11:51,639
when we save the stack we just copy it

00:11:46,720 --> 00:11:54,220
into this Java array here that's just an

00:11:51,639 --> 00:11:57,249
array events but the garbage collector

00:11:54,220 --> 00:12:00,749
is going to want to continue to run and

00:11:57,249 --> 00:12:04,119
it's going to move objects around which

00:12:00,749 --> 00:12:06,369
is going to invalidate some of the

00:12:04,119 --> 00:12:09,160
pointers in that enter a that's the copy

00:12:06,369 --> 00:12:11,649
of the stack and what we used to do was

00:12:09,160 --> 00:12:16,779
to scan the whole stack find out all of

00:12:11,649 --> 00:12:23,350
the words in the stack that were in fact

00:12:16,779 --> 00:12:25,209
object pointers or oops and copy those

00:12:23,350 --> 00:12:26,769
into a separate object array and we'd

00:12:25,209 --> 00:12:29,679
expose that to the garbage collector and

00:12:26,769 --> 00:12:32,740
then when we remounted the virtual

00:12:29,679 --> 00:12:35,230
thread it would copy them all back now

00:12:32,740 --> 00:12:40,540
the problem with this is that actually

00:12:35,230 --> 00:12:42,490
finding out which words in the stack our

00:12:40,540 --> 00:12:44,589
object pointers and which words are just

00:12:42,490 --> 00:12:47,529
integers is really quite an expensive

00:12:44,589 --> 00:12:49,899
operation you have to trawl through the

00:12:47,529 --> 00:12:55,119
metadata of all the methods that are on

00:12:49,899 --> 00:12:56,649
the stack granted the result is just a

00:12:55,119 --> 00:12:58,119
bitmap it's either this word is either

00:12:56,649 --> 00:13:00,459
an object or it's not

00:12:58,119 --> 00:13:02,350
we're actually scanning and on scanning

00:13:00,459 --> 00:13:04,689
and so on was really quite painful

00:13:02,350 --> 00:13:06,610
considerably more painful I have to say

00:13:04,689 --> 00:13:10,569
than the business of just copying the

00:13:06,610 --> 00:13:11,990
data into and out of the array but we

00:13:10,569 --> 00:13:13,970
have a new algorithm which

00:13:11,990 --> 00:13:16,910
we're on implemented a few weeks ago or

00:13:13,970 --> 00:13:21,200
something where the garbage collector

00:13:16,910 --> 00:13:23,210
can actually scan what's in there as

00:13:21,200 --> 00:13:26,840
long as it stays in the new generation

00:13:23,210 --> 00:13:30,650
if it stays in the old generation sorry

00:13:26,840 --> 00:13:32,540
if it gets if if the virtual thread gets

00:13:30,650 --> 00:13:34,310
promoted into the old generation I think

00:13:32,540 --> 00:13:35,720
then we have to do the whole thing of

00:13:34,310 --> 00:13:37,760
scanning the stack and setting at the

00:13:35,720 --> 00:13:43,300
pointers and so on I think that's one

00:13:37,760 --> 00:13:43,300
nodding or not good enough right

00:13:43,420 --> 00:13:51,320
okay synchronized blocks now those of

00:13:48,560 --> 00:13:54,680
you unfortunate enough to have actually

00:13:51,320 --> 00:13:56,810
written Java VM at the very very low

00:13:54,680 --> 00:13:59,000
level will know that the way that

00:13:56,810 --> 00:14:02,290
synchronized blocks work is some very

00:13:59,000 --> 00:14:06,620
very hairy handwritten assembly code

00:14:02,290 --> 00:14:08,630
which makes assumptions that this really

00:14:06,620 --> 00:14:09,980
is running on the native stack and you

00:14:08,630 --> 00:14:14,180
can block and you can call into the

00:14:09,980 --> 00:14:15,800
operating system and so on we can't do

00:14:14,180 --> 00:14:18,320
anything about this with virtual thread

00:14:15,800 --> 00:14:20,930
if you actually say synchronized and the

00:14:18,320 --> 00:14:24,620
synchronized has to block then you are

00:14:20,930 --> 00:14:26,150
going to block the carrier thread which

00:14:24,620 --> 00:14:27,680
you really really don't want to do

00:14:26,150 --> 00:14:29,390
because now you've got one for your

00:14:27,680 --> 00:14:32,450
thread that you can use to do some work

00:14:29,390 --> 00:14:34,400
but people are more and more these days

00:14:32,450 --> 00:14:36,200
using the locks from Java util

00:14:34,400 --> 00:14:38,050
concurrent rather than just synchronized

00:14:36,200 --> 00:14:42,470
blocks and these work perfectly well

00:14:38,050 --> 00:14:46,100
with Loom virtual thread state unmount

00:14:42,470 --> 00:14:48,020
the virtual thread if they block so that

00:14:46,100 --> 00:14:50,150
works fine so we've had to go through

00:14:48,020 --> 00:14:53,090
the Java IO library replacing these

00:14:50,150 --> 00:14:55,640
synchronized blocks you know it only has

00:14:53,090 --> 00:14:57,620
to do it once and thread yield hands off

00:14:55,640 --> 00:15:00,710
to continuation yield on mounting the

00:14:57,620 --> 00:15:04,040
virtual thread or good now the next bit

00:15:00,710 --> 00:15:07,630
is it's called possible futures here

00:15:04,040 --> 00:15:10,820
that's not really right the first one is

00:15:07,630 --> 00:15:12,830
structured concurrency which i think is

00:15:10,820 --> 00:15:16,670
definitely going to happen the second

00:15:12,830 --> 00:15:19,550
one is scope locals which may or may not

00:15:16,670 --> 00:15:21,890
happen but I want to talk about that

00:15:19,550 --> 00:15:24,520
because it's mine because I did it and I

00:15:21,890 --> 00:15:24,520
think it's interesting

00:15:25,399 --> 00:15:28,649
okay

00:15:26,610 --> 00:15:30,480
so let's think a bit about structured

00:15:28,649 --> 00:15:31,860
programming the traditional structured

00:15:30,480 --> 00:15:34,260
programming is all your control

00:15:31,860 --> 00:15:36,660
structures have it in at the top and and

00:15:34,260 --> 00:15:38,760
out at the bottom you can reason about

00:15:36,660 --> 00:15:40,790
programs much more easily if you use

00:15:38,760 --> 00:15:45,660
structured programming everything nests

00:15:40,790 --> 00:15:47,850
nicely when you think about what's

00:15:45,660 --> 00:15:52,040
actually going on with threaded

00:15:47,850 --> 00:15:54,329
programming it is the most gloriously

00:15:52,040 --> 00:15:56,190
unstructured way of programming you can

00:15:54,329 --> 00:15:57,990
possibly imagine not only is there not

00:15:56,190 --> 00:16:00,000
one in one out at the top well there's

00:15:57,990 --> 00:16:01,470
one in and as many out and they spawn

00:16:00,000 --> 00:16:03,209
over here and they start running over

00:16:01,470 --> 00:16:07,920
there and then they send messages to

00:16:03,209 --> 00:16:09,990
each other and if with Project loon

00:16:07,920 --> 00:16:11,850
you're going to have tens of thousands

00:16:09,990 --> 00:16:13,290
of thread or hundreds of thousands which

00:16:11,850 --> 00:16:16,050
we can do because they're only a few

00:16:13,290 --> 00:16:21,329
hundred bytes we somehow have to find a

00:16:16,050 --> 00:16:24,029
way to constrain that complexity in such

00:16:21,329 --> 00:16:26,250
a way that we can predict how a program

00:16:24,029 --> 00:16:26,790
is going to work we can analyze it and

00:16:26,250 --> 00:16:28,800
so on

00:16:26,790 --> 00:16:30,089
so simply firing off thousands and

00:16:28,800 --> 00:16:31,699
thousands of threads and passing

00:16:30,089 --> 00:16:33,779
messages back and forth and so on

00:16:31,699 --> 00:16:36,839
probably isn't going to work all that

00:16:33,779 --> 00:16:41,630
well yes old spaghetti Fortran programs

00:16:36,839 --> 00:16:44,220
have got nothing on this so here we are

00:16:41,630 --> 00:16:46,980
structured concurrency this is the idea

00:16:44,220 --> 00:16:51,149
and it's a very very simple idea that if

00:16:46,980 --> 00:16:53,940
you have a thread and it splits into a

00:16:51,149 --> 00:16:57,089
whole bunch of other threads then we

00:16:53,940 --> 00:16:58,769
want to have a join at the bottom when

00:16:57,089 --> 00:16:59,930
all of the other threads terminate and

00:16:58,769 --> 00:17:02,610
we carry on

00:16:59,930 --> 00:17:05,819
whoop-dee-doo this is structured and

00:17:02,610 --> 00:17:08,160
what's more if the threads have just

00:17:05,819 --> 00:17:10,199
done some purely functional computation

00:17:08,160 --> 00:17:11,669
for you and they all join together at

00:17:10,199 --> 00:17:14,730
the end what you've actually got there

00:17:11,669 --> 00:17:17,730
is a function you can analyze it you can

00:17:14,730 --> 00:17:21,449
reason about it it has no side effects

00:17:17,730 --> 00:17:25,370
but you've been able to use concurrency

00:17:21,449 --> 00:17:30,830
to make it more efficient so here we are

00:17:25,370 --> 00:17:34,020
here is an example of a structured

00:17:30,830 --> 00:17:38,279
concurrency construct this is your

00:17:34,020 --> 00:17:43,590
executor service here you submit to

00:17:38,279 --> 00:17:45,809
tasks for to execute and this is a try

00:17:43,590 --> 00:17:48,210
with resources so when you get to the

00:17:45,809 --> 00:17:52,200
end they both both joined together and

00:17:48,210 --> 00:17:54,450
it won't he won't terminate until

00:17:52,200 --> 00:17:57,419
they've both finished the executors

00:17:54,450 --> 00:17:59,179
submit returns the future that can be

00:17:57,419 --> 00:18:01,980
queried for a result of whatever

00:17:59,179 --> 00:18:03,809
computation you were doing there I don't

00:18:01,980 --> 00:18:06,740
I don't handle it there but you would

00:18:03,809 --> 00:18:10,470
you would need to assign it to something

00:18:06,740 --> 00:18:12,570
our handling and cancellation works much

00:18:10,470 --> 00:18:14,549
better because everybody joins therefore

00:18:12,570 --> 00:18:16,139
it's the responsibility of the joint

00:18:14,549 --> 00:18:18,570
point to handle anything that went wrong

00:18:16,139 --> 00:18:21,750
in any of these threads that you just

00:18:18,570 --> 00:18:23,429
learnt out and also thread cancellation

00:18:21,750 --> 00:18:26,250
is pretty cool as well because you can

00:18:23,429 --> 00:18:28,080
either cancel one of the child threads

00:18:26,250 --> 00:18:30,000
or you can cancel the parent thread in

00:18:28,080 --> 00:18:33,179
which case it'll all get propagated and

00:18:30,000 --> 00:18:35,009
so on and so on now this doesn't require

00:18:33,179 --> 00:18:36,539
virtual threads the structure

00:18:35,009 --> 00:18:39,149
concurrency works perfectly well with

00:18:36,539 --> 00:18:41,850
any kind of thread but it's very nice

00:18:39,149 --> 00:18:43,409
for this kind of work and so I've been

00:18:41,850 --> 00:18:45,269
looking at how far back this goes and

00:18:43,409 --> 00:18:50,240
I'm fairly sure that the Burroughs large

00:18:45,269 --> 00:18:55,940
systems of the 1960s worked this way so

00:18:50,240 --> 00:18:58,230
yeah it's it's good ok now thread locals

00:18:55,940 --> 00:19:00,990
Java stayed local it's kind of

00:18:58,230 --> 00:19:03,389
heavyweight it's slow and all the rest

00:19:00,990 --> 00:19:06,590
of it now I'm going to try now to open a

00:19:03,389 --> 00:19:06,590
link let's see

00:19:17,710 --> 00:19:20,710
Shh

00:19:21,460 --> 00:19:30,080
aha here's one I opened earlier this is

00:19:26,360 --> 00:19:33,440
an analysis that I did a couple of years

00:19:30,080 --> 00:19:36,110
ago of what actually happens when you

00:19:33,440 --> 00:19:38,210
say thread-local get and there's a

00:19:36,110 --> 00:19:39,560
tradition of my talks at frost em none

00:19:38,210 --> 00:19:44,210
of them are complete without some

00:19:39,560 --> 00:19:48,830
assembly language okay thank you this is

00:19:44,210 --> 00:19:51,410
what thread-local get actually does it

00:19:48,830 --> 00:19:53,480
does a whole bunch of reads from thread

00:19:51,410 --> 00:19:55,370
metadata we just read locals for a local

00:19:53,480 --> 00:19:59,120
table length field thread local hash

00:19:55,370 --> 00:20:00,950
code look it up in a table do the

00:19:59,120 --> 00:20:02,630
garbage collector magic because it's a

00:20:00,950 --> 00:20:05,450
WIC reference we now have our thread

00:20:02,630 --> 00:20:08,840
local and we done so read local get is

00:20:05,450 --> 00:20:12,440
twelve field loads five conditional

00:20:08,840 --> 00:20:16,100
branches this is not by any standard a

00:20:12,440 --> 00:20:17,810
lightweight operation so this was a

00:20:16,100 --> 00:20:21,050
couple of years ago and the question is

00:20:17,810 --> 00:20:27,320
can we actually do any better than this

00:20:21,050 --> 00:20:29,450
and I kind of hope we can so this is the

00:20:27,320 --> 00:20:33,200
this is the proposal for scope locals

00:20:29,450 --> 00:20:35,720
and the idea here is to do something

00:20:33,200 --> 00:20:39,260
rather similar to structured concurrency

00:20:35,720 --> 00:20:41,660
you will declare sorry you will bind the

00:20:39,260 --> 00:20:43,550
scope local at some points in your

00:20:41,660 --> 00:20:48,140
programs nesting it will then be visible

00:20:43,550 --> 00:20:51,110
to everything you call by doing your

00:20:48,140 --> 00:20:55,370
scope local get and it will disappear

00:20:51,110 --> 00:21:00,320
when you exit the same scope there will

00:20:55,370 --> 00:21:05,750
also be inherited by your child threads

00:21:00,320 --> 00:21:07,790
in your structure concurrency now it

00:21:05,750 --> 00:21:11,450
makes sense for them to inherited it

00:21:07,790 --> 00:21:13,610
doesn't make very much sense for local

00:21:11,450 --> 00:21:14,780
these Scott locals to be mutable ID only

00:21:13,610 --> 00:21:17,750
it makes very much sense for thread

00:21:14,780 --> 00:21:19,790
locals to be mutable either frankly but

00:21:17,750 --> 00:21:20,750
I don't think anybody understood that

00:21:19,790 --> 00:21:24,610
when there

00:21:20,750 --> 00:21:27,050
done 15 years ago or whatever it was

00:21:24,610 --> 00:21:32,840
okay and is and here's what it looks

00:21:27,050 --> 00:21:36,100
like you would launch your child tasks

00:21:32,840 --> 00:21:39,280
but you would bind a value to your

00:21:36,100 --> 00:21:41,570
integer there and then in this is

00:21:39,280 --> 00:21:44,570
execute swim bar and then in foo you

00:21:41,570 --> 00:21:47,960
would say I ain't get so it's like a

00:21:44,570 --> 00:21:50,450
thread-local but we've made it better by

00:21:47,960 --> 00:21:52,340
making it less powerful this is a

00:21:50,450 --> 00:21:56,330
crucial observation about a lot of this

00:21:52,340 --> 00:21:57,650
stuff is that we've got interfaces and

00:21:56,330 --> 00:21:59,720
constructs and so on that are

00:21:57,650 --> 00:22:01,640
tremendously powerful but in many ways

00:21:59,720 --> 00:22:04,220
they are too powerful and the sheer

00:22:01,640 --> 00:22:05,600
versatility of these constructs gets in

00:22:04,220 --> 00:22:08,570
the way of doing really efficient

00:22:05,600 --> 00:22:10,640
implementations and it also gets in the

00:22:08,570 --> 00:22:15,190
way of the programmer being able to

00:22:10,640 --> 00:22:19,250
reason about invariants and so on so

00:22:15,190 --> 00:22:21,470
scope locals and a fixed size local

00:22:19,250 --> 00:22:24,710
cache is the magic is what I've done is

00:22:21,470 --> 00:22:28,460
that every carrier thread has a fixed

00:22:24,710 --> 00:22:30,890
size cache of 16 entries where the most

00:22:28,460 --> 00:22:33,920
recent Scout locals that you've asked

00:22:30,890 --> 00:22:37,340
for are stored and from this will load a

00:22:33,920 --> 00:22:40,010
point at the locals cache c2 is plenty

00:22:37,340 --> 00:22:43,700
clever enough to hoist scoped locals

00:22:40,010 --> 00:22:45,710
into registers now that means the 12

00:22:43,700 --> 00:22:50,390
loads and 5 conditional branches that I

00:22:45,710 --> 00:22:53,480
showed you for thread local can be

00:22:50,390 --> 00:22:55,490
reduced to just if Skott locals are used

00:22:53,480 --> 00:22:57,230
in a loop they will be hoisted into

00:22:55,490 --> 00:23:02,120
registers at the start of the loop and

00:22:57,230 --> 00:23:03,920
they will stay there so this is what it

00:23:02,120 --> 00:23:07,130
looks like you've got a carrier thread

00:23:03,920 --> 00:23:10,780
here which has this 16 entry cash for

00:23:07,130 --> 00:23:13,700
scope locals you've got virtual threads

00:23:10,780 --> 00:23:16,070
every one of the virtual threads will

00:23:13,700 --> 00:23:19,160
have a scope local hash map for its

00:23:16,070 --> 00:23:20,990
local bindings when your program queries

00:23:19,160 --> 00:23:23,510
are scoped local it will search through

00:23:20,990 --> 00:23:27,440
the virtual threads through their

00:23:23,510 --> 00:23:29,600
parents through the structured

00:23:27,440 --> 00:23:31,400
concurrency if they essentially it looks

00:23:29,600 --> 00:23:33,980
like a cactus if you can imagine with

00:23:31,400 --> 00:23:34,610
multiple branches load the value into

00:23:33,980 --> 00:23:38,899
the care

00:23:34,610 --> 00:23:41,269
and the next time that that cache is

00:23:38,899 --> 00:23:45,080
queried it will find yours the value of

00:23:41,269 --> 00:23:47,450
your Scout local and lift it and that's

00:23:45,080 --> 00:23:49,100
very very fast worst-case is basically

00:23:47,450 --> 00:23:52,750
just a couple of instructions if you've

00:23:49,100 --> 00:23:57,110
got a cache hit for your scope local

00:23:52,750 --> 00:24:00,010
this works because scope locals are

00:23:57,110 --> 00:24:02,720
immutable this is absolutely crucial

00:24:00,010 --> 00:24:04,580
immutability is fantastic because once

00:24:02,720 --> 00:24:06,679
you've guaranteed that something is

00:24:04,580 --> 00:24:08,570
immutable you can copy it you can cache

00:24:06,679 --> 00:24:12,889
it you can do all of these wonderful

00:24:08,570 --> 00:24:16,510
things so by making thread locals less

00:24:12,889 --> 00:24:19,580
powerful giving them a fixed lifetime

00:24:16,510 --> 00:24:22,039
doing it in the simplest possible way

00:24:19,580 --> 00:24:25,460
what we've got is tremendously improved

00:24:22,039 --> 00:24:27,500
performance so we don't the effectively

00:24:25,460 --> 00:24:31,149
the cost of a scope locally is about the

00:24:27,500 --> 00:24:36,940
same as the cost of a load of a field

00:24:31,149 --> 00:24:36,940
from an object and I'm done

00:24:41,950 --> 00:24:44,010

YouTube URL: https://www.youtube.com/watch?v=2xNo-Yv0brg


