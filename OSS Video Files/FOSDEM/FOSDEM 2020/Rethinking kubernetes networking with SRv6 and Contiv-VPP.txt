Title: Rethinking kubernetes networking with SRv6 and Contiv-VPP
Publication date: 2020-07-16
Playlist: FOSDEM 2020
Description: 
	by Ahmed Abdelsalam, Miroslaw Walukiewicz, Filip Gschwandtner and Daniel Bernier

At: FOSDEM 2020
https://video.fosdem.org/2020/H.1308/rethinking_kubernetes_networking_with_srv6.webm

Kubernetes (k8s) is currently the de-facto standard for containers orchestration. However, K8s does not provide any solution for handling containers networking. Instead, it offloads the networking to third-party certified plugins called CNI plugins. Contiv-VPP is a k8s CNI plugin that offers fast I/O by leveraging the carrier-grade capabilities of VPP and DPDK in the dataplane.


The adoption of containers and microservices calls for IPv6 to provide addressing and reachability for such massive number of endpoints. SRv6 leverages the IPv6 dataplane to provide overlay networking, traffic engineering, load balancing, network policy and service chaining.


In this talk, we present an SRv6-based solution for k8s networking. We will show how SRv6 is used for pod-to-pod communication, k8s services and service function chaining (SFC), and how SRv6 solves several k8s networking challenges. We will also show the integration of our solution in Contiv-VPP. This solution is the result of combined effort between Bell Canada, Cisco and Pantheon.tech.

Room: H.1308 (Rolin)
Scheduled start: 2020-02-01 13:10:00
Captions: 
	00:00:07,149 --> 00:00:15,259
so good afternoon thanks for your time I

00:00:11,750 --> 00:00:18,259
know it's quite heavy after lunch we

00:00:15,259 --> 00:00:20,689
have a 15-minute talk so today I'm we're

00:00:18,259 --> 00:00:23,689
gonna talk about kubernetes networking

00:00:20,689 --> 00:00:27,439
with services and 20 PPP it's another

00:00:23,689 --> 00:00:29,119
way to think about kubernetes nothing my

00:00:27,439 --> 00:00:32,110
name is Devin Absalom I work for Cisco

00:00:29,119 --> 00:00:34,640
Systems I have with me Roscoe works for

00:00:32,110 --> 00:00:36,890
pension and I have married cords for

00:00:34,640 --> 00:00:40,549
antenna and this is gonna be a joint

00:00:36,890 --> 00:00:42,530
talk so our agenda for today we will go

00:00:40,549 --> 00:00:44,720
very briefly on kubernetes not talking

00:00:42,530 --> 00:00:47,780
fortunately we have two talks before so

00:00:44,720 --> 00:00:49,790
this part was was covered and we will

00:00:47,780 --> 00:00:51,619
talk about a service six some

00:00:49,790 --> 00:00:53,420
introduction to the technology and also

00:00:51,619 --> 00:00:57,170
how it can work with kubernetes

00:00:53,420 --> 00:01:01,250
networking and Rustom will cover the 20

00:00:57,170 --> 00:01:04,420
VPP part and Eric will go into the Exide

00:01:01,250 --> 00:01:06,460
acceleration of estar v6 using the Intel

00:01:04,420 --> 00:01:09,020
smart Nick

00:01:06,460 --> 00:01:11,360
so kubernetes not looking just in one

00:01:09,020 --> 00:01:12,320
slide so kubernetes doesn't do anything

00:01:11,360 --> 00:01:15,350
for networking

00:01:12,320 --> 00:01:19,850
it basically offloads this function to

00:01:15,350 --> 00:01:22,190
CNI plugins and those CNI plugins are

00:01:19,850 --> 00:01:24,380
supposed to do two main function the

00:01:22,190 --> 00:01:29,660
first one is connectivity so when you

00:01:24,380 --> 00:01:31,610
create a new kubernetes pod the job of

00:01:29,660 --> 00:01:34,430
the CNI plugin is basically to create

00:01:31,610 --> 00:01:37,670
kind some interface inside the pod

00:01:34,430 --> 00:01:40,220
connect this interface to the network

00:01:37,670 --> 00:01:43,940
fabric can be either v switch or

00:01:40,220 --> 00:01:46,670
whatever and allocate an IP address to

00:01:43,940 --> 00:01:50,030
this bond the second functionality is to

00:01:46,670 --> 00:01:54,080
make this pod reachable through through

00:01:50,030 --> 00:01:56,780
the cluster so CNI plugin needs to do

00:01:54,080 --> 00:01:59,120
just these two things different

00:01:56,780 --> 00:02:04,340
technologies and different ways to do it

00:01:59,120 --> 00:02:06,260
and for the IP addressing basically all

00:02:04,340 --> 00:02:09,289
your copper nets pods needs IP IP

00:02:06,260 --> 00:02:11,720
addresses and unfortunately we don't

00:02:09,289 --> 00:02:16,310
have enough ipv4 addresses anymore in

00:02:11,720 --> 00:02:18,090
Europe this was a talk in Reb 78 where

00:02:16,310 --> 00:02:20,610
they projected we

00:02:18,090 --> 00:02:24,120
we expect the ipv4 addresses to be

00:02:20,610 --> 00:02:27,630
exhausted and actually in Europe it was

00:02:24,120 --> 00:02:31,290
supposed to to finish by January 2020

00:02:27,630 --> 00:02:33,569
but three months before they announced

00:02:31,290 --> 00:02:36,239
e-z already assigned the last briefing

00:02:33,569 --> 00:02:38,880
so we don't have any ID before anymore

00:02:36,239 --> 00:02:42,209
in Europe some some service provider

00:02:38,880 --> 00:02:44,670
they do have but right who sends ipv4

00:02:42,209 --> 00:02:48,660
others they don't have anymore so the

00:02:44,670 --> 00:02:50,970
solution for this is to use ipv6 so and

00:02:48,660 --> 00:02:53,430
we are covering three main problem

00:02:50,970 --> 00:02:55,260
statement some people might not agree

00:02:53,430 --> 00:02:57,120
with the problem statement some people

00:02:55,260 --> 00:02:59,010
might not agree with our solution but

00:02:57,120 --> 00:03:02,209
this is at least the problem statement

00:02:59,010 --> 00:03:06,569
and the solution from our point of view

00:03:02,209 --> 00:03:09,840
and the second problem when we use ipv6

00:03:06,569 --> 00:03:13,230
for for container for addressing

00:03:09,840 --> 00:03:15,330
giving address to kubernetes pots we

00:03:13,230 --> 00:03:17,489
will need to implement all of the use

00:03:15,330 --> 00:03:20,130
cases of of kubernetes like both about

00:03:17,489 --> 00:03:21,980
communication network policy services

00:03:20,130 --> 00:03:25,920
services chaining English and

00:03:21,980 --> 00:03:29,209
communication between clusters and the

00:03:25,920 --> 00:03:32,640
question is that do we need to to do

00:03:29,209 --> 00:03:35,069
this use cases in ipv6 the same way we

00:03:32,640 --> 00:03:38,700
do it an ipv4 or should we think about

00:03:35,069 --> 00:03:41,220
them in more ipv6 native way and from

00:03:38,700 --> 00:03:43,829
our point of view that is our v6 I will

00:03:41,220 --> 00:03:45,359
explain what is a service 6 later can

00:03:43,829 --> 00:03:51,799
provide a solution for this problem

00:03:45,359 --> 00:03:55,709
statement the third one is is the i/o

00:03:51,799 --> 00:03:58,200
folder for the pod some some kind of

00:03:55,709 --> 00:04:02,100
workloads they need very fast I origin

00:03:58,200 --> 00:04:05,549
you need to have a lot Yoram your body

00:04:02,100 --> 00:04:07,739
requires to Bro to process like a lot of

00:04:05,549 --> 00:04:10,500
packets per second so how would you how

00:04:07,739 --> 00:04:12,239
would you provide this this I go to to

00:04:10,500 --> 00:04:14,340
through with the kubernetes pods you

00:04:12,239 --> 00:04:16,289
have several options in the data plane

00:04:14,340 --> 00:04:18,840
you can use the kernel forwarding you

00:04:16,289 --> 00:04:21,510
can use something like e PPF with XE DB

00:04:18,840 --> 00:04:25,530
you can use something like v BB with DVD

00:04:21,510 --> 00:04:28,409
k and from our point of view again for

00:04:25,530 --> 00:04:31,980
this we think that v BP is a solution

00:04:28,409 --> 00:04:34,350
for that or you can have also some way

00:04:31,980 --> 00:04:38,250
depends on your use case you can have a

00:04:34,350 --> 00:04:41,280
kind of accelerated way to use to use

00:04:38,250 --> 00:04:43,980
VPP and on the right I show some numbers

00:04:41,280 --> 00:04:46,140
of some comparison between the

00:04:43,980 --> 00:04:48,630
forwarding of the of the Linux kernel

00:04:46,140 --> 00:04:50,880
compared to VB P and in the secondary

00:04:48,630 --> 00:04:53,400
ROM is that V BP when you use it as a

00:04:50,880 --> 00:04:57,090
soft and software or when you offload it

00:04:53,400 --> 00:04:59,970
to a smart link so what is the service

00:04:57,090 --> 00:05:03,060
six services basically is a source

00:04:59,970 --> 00:05:05,550
routing mechanism so you defined that

00:05:03,060 --> 00:05:08,310
you define the path or the forwarding

00:05:05,550 --> 00:05:11,070
path of the packet at the source how we

00:05:08,310 --> 00:05:13,830
do it you in you attached to the packet

00:05:11,070 --> 00:05:16,680
a list of instruction or rest of

00:05:13,830 --> 00:05:18,780
endpoint that that needs to process this

00:05:16,680 --> 00:05:22,860
packet these endpoints we call them

00:05:18,780 --> 00:05:25,140
segments or our service six segments and

00:05:22,860 --> 00:05:30,030
each segment should have a segment idea

00:05:25,140 --> 00:05:32,310
and segments segments can have two

00:05:30,030 --> 00:05:35,100
different meaning one one meaning can be

00:05:32,310 --> 00:05:38,550
a topological segment like going to node

00:05:35,100 --> 00:05:40,770
one or two or three before reaching the

00:05:38,550 --> 00:05:43,980
destination or it can have like a

00:05:40,770 --> 00:05:46,950
service meaning or NFV meaning by going

00:05:43,980 --> 00:05:49,020
to function one or service network

00:05:46,950 --> 00:05:51,030
function one and two and three before

00:05:49,020 --> 00:05:54,630
before before reaching the destination

00:05:51,030 --> 00:05:57,570
and what a services can provide you for

00:05:54,630 --> 00:06:00,030
its scalability since you you push the

00:05:57,570 --> 00:06:03,000
packet path at the source you basically

00:06:00,030 --> 00:06:06,420
remove all of the states in you from the

00:06:03,000 --> 00:06:07,920
fabric of your networking and with the

00:06:06,420 --> 00:06:10,230
service six you can eliminate some of

00:06:07,920 --> 00:06:13,170
the protocol you already you you already

00:06:10,230 --> 00:06:15,120
use like for traffic engineering use

00:06:13,170 --> 00:06:17,730
cases if you need to traffic engineer it

00:06:15,120 --> 00:06:19,590
inside your network fabric for some use

00:06:17,730 --> 00:06:21,150
cases like services chaining and for

00:06:19,590 --> 00:06:24,990
overlay and it gives you end-to-end

00:06:21,150 --> 00:06:27,570
connectivity it has segment routing has

00:06:24,990 --> 00:06:30,870
two implementation basically one for the

00:06:27,570 --> 00:06:34,590
MPLS data plane and we will not go in in

00:06:30,870 --> 00:06:37,470
this direction which basically Maps this

00:06:34,590 --> 00:06:39,960
segment identifier to MPLS label the

00:06:37,470 --> 00:06:43,530
second one is for the ipv6 data plane

00:06:39,960 --> 00:06:46,169
where each segment is mapped as an ipv6

00:06:43,530 --> 00:06:49,680
address and you insert you

00:06:46,169 --> 00:06:51,779
add to the packet a routing extension

00:06:49,680 --> 00:06:54,439
header that carries a list of this of

00:06:51,779 --> 00:06:57,629
this instead of this ipv6 addresses

00:06:54,439 --> 00:07:00,539
before explaining how it works this is

00:06:57,629 --> 00:07:03,300
this is for the ecosystem so as our

00:07:00,539 --> 00:07:05,159
basics has a very rich ecosystem so when

00:07:03,300 --> 00:07:07,050
you decide to implement a service 6 you

00:07:05,159 --> 00:07:09,539
basically you are not in your own so you

00:07:07,050 --> 00:07:12,060
have you have support from network

00:07:09,539 --> 00:07:14,400
vendor from network equipment

00:07:12,060 --> 00:07:16,409
manufacturer you have support in

00:07:14,400 --> 00:07:19,379
martinique you have a merchant silicone

00:07:16,409 --> 00:07:25,439
you have an open source and you have

00:07:19,379 --> 00:07:29,370
some nav as well so a service 6 is

00:07:25,439 --> 00:07:31,860
defined basically as an RFC as a draft

00:07:29,370 --> 00:07:34,199
in the IETF and basically it defines

00:07:31,860 --> 00:07:36,270
what is a network as a service agnostic

00:07:34,199 --> 00:07:39,689
program their service 6 not programming

00:07:36,270 --> 00:07:42,990
is a model where you encode in the

00:07:39,689 --> 00:07:44,969
packet the processing bus and we as we

00:07:42,990 --> 00:07:48,389
said this will be implemented as a

00:07:44,969 --> 00:07:49,979
number of segments just to to give more

00:07:48,389 --> 00:07:52,649
details what is an a service six

00:07:49,979 --> 00:07:56,159
segments or a cell is basically an ipv6

00:07:52,649 --> 00:07:59,159
address which which divided in two parts

00:07:56,159 --> 00:08:01,110
the first is a locator which node should

00:07:59,159 --> 00:08:03,779
process the packet and the second one is

00:08:01,110 --> 00:08:06,569
the function which which function I

00:08:03,779 --> 00:08:09,569
should I should execute in the packet at

00:08:06,569 --> 00:08:12,060
this node and here how your bucket looks

00:08:09,569 --> 00:08:16,110
like so you get your normal payload can

00:08:12,060 --> 00:08:18,839
be ipv4 ipv6 TCP UDP whatever and then

00:08:16,110 --> 00:08:21,120
you encapsulate this packet into an ipv6

00:08:18,839 --> 00:08:23,339
encapsulation and in this ipv6

00:08:21,120 --> 00:08:26,789
encapsulation you carry a list of of

00:08:23,339 --> 00:08:29,159
segments that basically defines the path

00:08:26,789 --> 00:08:31,139
of the packet and each nordwind

00:08:29,159 --> 00:08:33,060
processes this packet it will update the

00:08:31,139 --> 00:08:35,969
destination address with the next note

00:08:33,060 --> 00:08:39,269
that should process the packet so here I

00:08:35,969 --> 00:08:41,310
have I need I need the packet before

00:08:39,269 --> 00:08:44,579
reaching the destination to go through

00:08:41,310 --> 00:08:47,190
three nodes inside inside the network or

00:08:44,579 --> 00:08:50,060
inside my kubernetes cluster so it will

00:08:47,190 --> 00:08:53,279
I will include the IDs for this node and

00:08:50,060 --> 00:08:56,519
the and every time I process the packet

00:08:53,279 --> 00:08:58,410
I just update the active segment pointer

00:08:56,519 --> 00:09:00,060
to be the next segment and which we

00:08:58,410 --> 00:09:03,030
carried in the destination address of

00:09:00,060 --> 00:09:05,490
the packet and this is how the segments

00:09:03,030 --> 00:09:08,270
routing header is defined in the IETF so

00:09:05,490 --> 00:09:11,280
basically it has some common common

00:09:08,270 --> 00:09:14,310
fields as any routing extension header

00:09:11,280 --> 00:09:17,010
plus the CID list or the path of the

00:09:14,310 --> 00:09:20,310
packet which encoded as ipv6 addresses

00:09:17,010 --> 00:09:23,340
and there are two way to two main types

00:09:20,310 --> 00:09:26,190
of behavior that that you can that you

00:09:23,340 --> 00:09:28,980
come to execute in the packet the first

00:09:26,190 --> 00:09:30,810
one what we call the head and is this is

00:09:28,980 --> 00:09:34,080
where you do the encapsulation so you

00:09:30,810 --> 00:09:35,910
have two flavors either you want to to

00:09:34,080 --> 00:09:38,580
do layers two networking so you include

00:09:35,910 --> 00:09:40,890
the layer 2 frame inside there service

00:09:38,580 --> 00:09:44,250
six encapsulation or you do layer 3 by

00:09:40,890 --> 00:09:47,550
including the ipv4 or ipv6 traffic and

00:09:44,250 --> 00:09:51,150
the other behavior this one these are

00:09:47,550 --> 00:09:53,820
the one you execute on the node defined

00:09:51,150 --> 00:09:55,320
in the packet header for several us

00:09:53,820 --> 00:09:57,690
cases some use cases like traffic

00:09:55,320 --> 00:09:59,250
engineering some for for for just

00:09:57,690 --> 00:10:02,730
overlay if you need to connect to

00:09:59,250 --> 00:10:06,420
kubernetes the worker node and some

00:10:02,730 --> 00:10:08,700
other for services chaining and this is

00:10:06,420 --> 00:10:11,880
just I will give two example one is for

00:10:08,700 --> 00:10:15,240
overlay so I have considered this green

00:10:11,880 --> 00:10:17,250
overlay as your as to kubernetes pods so

00:10:15,240 --> 00:10:18,600
they need to speak to each other through

00:10:17,250 --> 00:10:20,910
the network fabric so this is the

00:10:18,600 --> 00:10:23,280
kubernetes knot and and the other one is

00:10:20,910 --> 00:10:24,690
another on another kubernetes not so

00:10:23,280 --> 00:10:27,270
basically you encapsulate you

00:10:24,690 --> 00:10:29,420
encapsulate the packet into a service 16

00:10:27,270 --> 00:10:32,820
capsulation but for some use cases

00:10:29,420 --> 00:10:35,010
someone might need to do some traffic

00:10:32,820 --> 00:10:38,120
engineering inside inside the fabric so

00:10:35,010 --> 00:10:41,190
you get your kubernetes not connected to

00:10:38,120 --> 00:10:43,380
to a data center fabric and in this data

00:10:41,190 --> 00:10:46,860
center fabric there are some some i need

00:10:43,380 --> 00:10:49,200
to take a faster bus to go to the other

00:10:46,860 --> 00:10:51,960
node or a low latency bus so you can

00:10:49,200 --> 00:10:55,740
enforce this kind of paths by adding a

00:10:51,960 --> 00:10:57,800
new segment to do this so the first the

00:10:55,740 --> 00:11:00,780
the low latency bus here is not the one

00:10:57,800 --> 00:11:03,210
from directly from 1 to 2 but if you go

00:11:00,780 --> 00:11:07,490
1 3 2 this is a low latency path so you

00:11:03,210 --> 00:11:12,060
can enforce this also inside the fabric

00:11:07,490 --> 00:11:13,830
just I will I will do two slides on the

00:11:12,060 --> 00:11:14,220
kubernetes with their services and then

00:11:13,830 --> 00:11:16,470
I will

00:11:14,220 --> 00:11:19,050
I will hand it to tourists Oh to speak

00:11:16,470 --> 00:11:24,690
about the support of a service sitting

00:11:19,050 --> 00:11:27,120
in in in quantum vbp so what you have

00:11:24,690 --> 00:11:30,570
now for four kubernetes networking is

00:11:27,120 --> 00:11:33,180
basically for each when you when you

00:11:30,570 --> 00:11:36,030
want to implement load balancing or ie

00:11:33,180 --> 00:11:37,680
kubernetes service you rely on some

00:11:36,030 --> 00:11:40,290
feature in the Linux kernel like the

00:11:37,680 --> 00:11:43,140
like the Linux iptables net or if you

00:11:40,290 --> 00:11:45,360
use a CNI plugin that uses VPP in the

00:11:43,140 --> 00:11:48,300
data plane you you do use the vb peanut

00:11:45,360 --> 00:11:50,910
engine the same for port forwarding for

00:11:48,300 --> 00:11:53,790
the network topology as mentioned in in

00:11:50,910 --> 00:11:56,520
the previous talks people use the Linux

00:11:53,790 --> 00:11:57,960
IP table firewalls or people using vbz

00:11:56,520 --> 00:12:00,240
use the BPP Eccles

00:11:57,960 --> 00:12:03,180
for overlay with different protocol like

00:12:00,240 --> 00:12:06,360
the exelon IP naívi each CN i plug and

00:12:03,180 --> 00:12:09,240
support one protocol or another and for

00:12:06,360 --> 00:12:11,400
some some some use cases for example for

00:12:09,240 --> 00:12:15,020
service provider when they want to do

00:12:11,400 --> 00:12:18,840
some services chaining between the bugs

00:12:15,020 --> 00:12:20,490
it's the way they do it they create

00:12:18,840 --> 00:12:23,310
different tunnel and they try to stitch

00:12:20,490 --> 00:12:26,040
this tunnel together and the result of

00:12:23,310 --> 00:12:29,850
this model that you get kind of net

00:12:26,040 --> 00:12:33,540
everywhere you get also a quite complex

00:12:29,850 --> 00:12:35,880
network policy model which basically

00:12:33,540 --> 00:12:37,800
relies on the container IPs and the

00:12:35,880 --> 00:12:40,920
containers in kubernetes or the pods

00:12:37,800 --> 00:12:44,130
they come and go very fast so every time

00:12:40,920 --> 00:12:47,790
you create a new Co a new pod you need

00:12:44,130 --> 00:12:51,630
to update the IP table rules across all

00:12:47,790 --> 00:12:53,460
all node plus IP tables as people

00:12:51,630 --> 00:12:56,930
mentioned before with not was not

00:12:53,460 --> 00:12:59,790
designed for this very fast forwarding

00:12:56,930 --> 00:13:03,690
services chaining is is complex I would

00:12:59,790 --> 00:13:07,890
say almost almost impossible to do

00:13:03,690 --> 00:13:09,810
currently and for some use cases like if

00:13:07,890 --> 00:13:12,810
you want to implement some inter cluster

00:13:09,810 --> 00:13:15,450
communication hybrid cloud with multi

00:13:12,810 --> 00:13:20,280
cloud or if you want to implement a kind

00:13:15,450 --> 00:13:22,110
of network wide policy I mean I myself I

00:13:20,280 --> 00:13:26,339
don't know the solution so if someone

00:13:22,110 --> 00:13:28,120
knows can tell me so how we think a

00:13:26,339 --> 00:13:30,460
services can simplify

00:13:28,120 --> 00:13:32,890
this the way we think about it is just

00:13:30,460 --> 00:13:36,160
one technology that you can use it to

00:13:32,890 --> 00:13:38,080
implement at least most of your use

00:13:36,160 --> 00:13:40,720
cases because it has the instructions

00:13:38,080 --> 00:13:43,300
for that so you want to implement an

00:13:40,720 --> 00:13:47,650
overlay a service six provides you the

00:13:43,300 --> 00:13:49,630
the the instructions to the in-cab and

00:13:47,650 --> 00:13:51,700
that encapsulation and decapsulation if

00:13:49,630 --> 00:13:53,860
you want to implement a policy model

00:13:51,700 --> 00:13:57,580
that doesn't rely based on the

00:13:53,860 --> 00:14:00,100
containers IDs you can leverage some of

00:13:57,580 --> 00:14:02,890
the metadata in the encapsulation to to

00:14:00,100 --> 00:14:07,660
implement the policy using labels some

00:14:02,890 --> 00:14:09,850
use cases like port forwarding by

00:14:07,660 --> 00:14:12,370
assigning some an ipv6 address to each

00:14:09,850 --> 00:14:14,589
to each application there was some good

00:14:12,370 --> 00:14:19,240
slides from facebook on this but i

00:14:14,589 --> 00:14:22,600
forget to add the link and for load

00:14:19,240 --> 00:14:24,339
balancing you get what we call segment

00:14:22,600 --> 00:14:26,950
routing policy which you can have a

00:14:24,339 --> 00:14:30,250
multiple backends which basically does

00:14:26,950 --> 00:14:33,310
this without without having to do net

00:14:30,250 --> 00:14:35,470
and services chaining you get services

00:14:33,310 --> 00:14:37,480
chaining out-of-the-box because you have

00:14:35,470 --> 00:14:38,950
an extension header where you can encode

00:14:37,480 --> 00:14:40,900
the bus of the packet so you don't need

00:14:38,950 --> 00:14:42,790
to create several tunnels and try to

00:14:40,900 --> 00:14:44,920
stitch them you can include the bus of

00:14:42,790 --> 00:14:48,310
the packet from the beginning and for

00:14:44,920 --> 00:14:52,110
the other use cases you can leverage the

00:14:48,310 --> 00:14:55,540
SR v6 and some control plane like

00:14:52,110 --> 00:14:57,880
network service mesh I will just cover

00:14:55,540 --> 00:15:00,010
one one use case is the network policy

00:14:57,880 --> 00:15:02,350
if you want a network to implement a

00:15:00,010 --> 00:15:04,450
network a policy on the scale that

00:15:02,350 --> 00:15:08,170
basically does not rely on containers I

00:15:04,450 --> 00:15:10,480
in container IPS so here just these two

00:15:08,170 --> 00:15:12,279
but the blue part is as your as you as

00:15:10,480 --> 00:15:15,100
within your kubernetes node and this

00:15:12,279 --> 00:15:20,170
green part is across across your your

00:15:15,100 --> 00:15:22,900
data center fabric so we we will use so

00:15:20,170 --> 00:15:25,920
I have two container so I have I have my

00:15:22,900 --> 00:15:28,690
my kubernetes cluster is implementing

00:15:25,920 --> 00:15:31,420
workload from several tenants or from

00:15:28,690 --> 00:15:34,120
several application tiers and I want to

00:15:31,420 --> 00:15:37,720
implement a policy between those those

00:15:34,120 --> 00:15:40,810
different groups so the way I will do it

00:15:37,720 --> 00:15:41,980
I will in code I don't want I don't want

00:15:40,810 --> 00:15:45,010
to implement it big

00:15:41,980 --> 00:15:47,860
on the container I be because this way

00:15:45,010 --> 00:15:49,630
every time I create a new container on

00:15:47,860 --> 00:15:51,880
this node I have to go to all of the

00:15:49,630 --> 00:15:54,220
other nodes and update the IP table

00:15:51,880 --> 00:15:56,650
rules or the actual there in order to

00:15:54,220 --> 00:15:59,290
block the traffic so that I need to have

00:15:56,650 --> 00:16:02,290
a kind of a common identity to each

00:15:59,290 --> 00:16:04,360
container or to each group and based on

00:16:02,290 --> 00:16:06,970
this identity I can filter the traffic

00:16:04,360 --> 00:16:10,030
so the way we do it here when you do the

00:16:06,970 --> 00:16:12,580
SRV 16 capsulation 2 to send the packet

00:16:10,030 --> 00:16:14,710
across the fabric from one from one

00:16:12,580 --> 00:16:17,110
coober not to another um could you

00:16:14,710 --> 00:16:19,540
include the source the source of the

00:16:17,110 --> 00:16:23,440
packet so this packet that comes from

00:16:19,540 --> 00:16:27,760
from from the pod r1f kami is coming

00:16:23,440 --> 00:16:29,860
from the the group LED and when you when

00:16:27,760 --> 00:16:33,130
you do you remove the encapsulation at

00:16:29,860 --> 00:16:35,440
the other node before before handing the

00:16:33,130 --> 00:16:37,480
packet to to the other container or the

00:16:35,440 --> 00:16:39,850
other kubernetes pod basically you

00:16:37,480 --> 00:16:42,550
compare the source group of the packet

00:16:39,850 --> 00:16:45,730
to the source to the destination group

00:16:42,550 --> 00:16:48,610
or the group of the destination of

00:16:45,730 --> 00:16:52,030
destination so what this gives you

00:16:48,610 --> 00:16:54,720
better than then than the IP table roads

00:16:52,030 --> 00:16:57,670
or the normal firewall rule basically

00:16:54,720 --> 00:17:00,460
you get a scalable Network policy

00:16:57,670 --> 00:17:04,510
because now your policy does not rely

00:17:00,460 --> 00:17:06,930
anymore on the container IB so my polish

00:17:04,510 --> 00:17:10,180
table will all will all will only have

00:17:06,930 --> 00:17:13,780
some rules based on the group so I have

00:17:10,180 --> 00:17:16,270
a group grab when group read wants to

00:17:13,780 --> 00:17:18,670
speak to guru Bloo I accept the traffic

00:17:16,270 --> 00:17:22,150
but when group read won't speak to group

00:17:18,670 --> 00:17:24,640
green I drop this traffic say I I have I

00:17:22,150 --> 00:17:27,520
added a different kubernetes note and I

00:17:24,640 --> 00:17:29,950
added different new pods from group read

00:17:27,520 --> 00:17:32,620
or group green my bullish table will not

00:17:29,950 --> 00:17:36,100
change because each packet will come

00:17:32,620 --> 00:17:39,220
with with with the label or already

00:17:36,100 --> 00:17:42,340
identified and I will I will just filter

00:17:39,220 --> 00:17:44,350
based on this second is its integrated

00:17:42,340 --> 00:17:46,570
inside your your overlay so you don't

00:17:44,350 --> 00:17:49,990
like to implement a new technology to do

00:17:46,570 --> 00:17:52,540
to do policy you don't need to use a new

00:17:49,990 --> 00:17:54,610
firewall to do the policy the policy is

00:17:52,540 --> 00:17:55,060
already implemented inside inside your

00:17:54,610 --> 00:17:57,850
over

00:17:55,060 --> 00:18:00,130
the second the third is independent of

00:17:57,850 --> 00:18:02,500
the container IPS because basically it

00:18:00,130 --> 00:18:05,680
relies on the group of the object

00:18:02,500 --> 00:18:08,410
containers and with this I will hand it

00:18:05,680 --> 00:18:08,980
to Rosco to speak about the services in

00:18:08,410 --> 00:18:13,840
context

00:18:08,980 --> 00:18:17,080
yeah thanks Emmett yeah so before I go

00:18:13,840 --> 00:18:20,800
into SR v6 in County VP PC and I would

00:18:17,080 --> 00:18:23,710
just tell you some details about Conti

00:18:20,800 --> 00:18:29,040
bpp so continued piece yet another CNI

00:18:23,710 --> 00:18:31,600
but this one uses VPP as its data plane

00:18:29,040 --> 00:18:35,590
what which is dedicated to access the

00:18:31,600 --> 00:18:37,870
network interface and has the Q proxy

00:18:35,590 --> 00:18:41,400
for implement it on VPP for network

00:18:37,870 --> 00:18:44,140
policies and services as well

00:18:41,400 --> 00:18:47,200
it is production ready passes all

00:18:44,140 --> 00:18:50,350
kubernetes conformance tests so we can

00:18:47,200 --> 00:18:52,930
use it as any other CNI but apart from

00:18:50,350 --> 00:18:55,800
that it is really good for different

00:18:52,930 --> 00:18:58,930
cloud native networking deployments

00:18:55,800 --> 00:19:01,420
meaning if you want to deploy some

00:18:58,930 --> 00:19:05,920
network functionality as a set of micro

00:19:01,420 --> 00:19:09,070
services running in kubernetes for those

00:19:05,920 --> 00:19:12,790
we have features like we allow multiple

00:19:09,070 --> 00:19:15,420
network interfaces per each pot and

00:19:12,790 --> 00:19:18,910
actually different kinds of interfaces

00:19:15,420 --> 00:19:22,810
we have support for multiple isolated

00:19:18,910 --> 00:19:25,000
networks l2 or l3 we do have support for

00:19:22,810 --> 00:19:28,270
service training between the ports for

00:19:25,000 --> 00:19:30,910
CNF deployments and of course since we

00:19:28,270 --> 00:19:35,260
are here because of SRB six we will

00:19:30,910 --> 00:19:40,150
support ipv6 and have some as IVC as our

00:19:35,260 --> 00:19:42,820
v6 features implemented very briefly the

00:19:40,150 --> 00:19:46,120
loop added at the data plane so on each

00:19:42,820 --> 00:19:50,770
component is note we're on one we switch

00:19:46,120 --> 00:19:54,010
spot which which executes VPP

00:19:50,770 --> 00:19:56,290
VPP uses DP decade to to access the

00:19:54,010 --> 00:19:59,860
network interface which interconnects

00:19:56,290 --> 00:20:03,040
with we the node with other nodes in the

00:19:59,860 --> 00:20:05,140
cluster and between VPP and the pots we

00:20:03,040 --> 00:20:08,559
have the interfaces by default you would

00:20:05,140 --> 00:20:10,720
get tap interfaces from VPP into the

00:20:08,559 --> 00:20:14,590
network namespaces of the individual

00:20:10,720 --> 00:20:18,399
pots between the nodes we by default use

00:20:14,590 --> 00:20:23,019
the eggs on tunnels and we'll see what

00:20:18,399 --> 00:20:26,080
we can do with as our v6 instead this is

00:20:23,019 --> 00:20:28,840
one of the one of the features that

00:20:26,080 --> 00:20:32,080
continued PP implements for CNF

00:20:28,840 --> 00:20:35,409
deployments so what say we have two two

00:20:32,080 --> 00:20:39,220
CNF ports which need to talk between

00:20:35,409 --> 00:20:42,070
each other let's say on l2 level so they

00:20:39,220 --> 00:20:44,230
can have a first network interface

00:20:42,070 --> 00:20:46,330
connected to the default Network and

00:20:44,230 --> 00:20:48,879
they can have additional network

00:20:46,330 --> 00:20:52,360
interfaces connected to additional

00:20:48,879 --> 00:20:56,470
networks the way you define these in

00:20:52,360 --> 00:20:58,720
continued PP is that in order to connect

00:20:56,470 --> 00:21:02,200
multiple interfaces interfaces towards

00:20:58,720 --> 00:21:05,830
the pot you used County v PP annotation

00:21:02,200 --> 00:21:08,289
custom if where you where Utah where you

00:21:05,830 --> 00:21:11,230
can define the name of the interface in

00:21:08,289 --> 00:21:13,149
the pot type of the interface and the

00:21:11,230 --> 00:21:15,730
network where you have very want to have

00:21:13,149 --> 00:21:18,700
it connected the types that we support

00:21:15,730 --> 00:21:21,759
currently is the table interface between

00:21:18,700 --> 00:21:22,779
VPP and the pot then beat interface and

00:21:21,759 --> 00:21:29,080
my mouth

00:21:22,779 --> 00:21:31,119
MMF is is memory interface which can be

00:21:29,080 --> 00:21:33,820
used in case that the CNF supports that

00:21:31,119 --> 00:21:35,799
and it allows to forward the packet

00:21:33,820 --> 00:21:38,440
between the V switch VPP and the C and

00:21:35,799 --> 00:21:44,289
I've through the share memory so

00:21:38,440 --> 00:21:48,669
bypassing the colonel this is another

00:21:44,289 --> 00:21:51,639
use case of CNF deployments in this case

00:21:48,669 --> 00:21:54,330
we again have pots with multiple

00:21:51,639 --> 00:21:57,610
interfaces in this case they are managed

00:21:54,330 --> 00:22:00,580
interfaces and we want to have them

00:21:57,610 --> 00:22:04,119
connected in a chain so we want to have

00:22:00,580 --> 00:22:07,539
a chain which starts in in Port CNF one

00:22:04,119 --> 00:22:10,929
goes through the pot CNF to and ends in

00:22:07,539 --> 00:22:13,749
the pot CNF three those pots can can be

00:22:10,929 --> 00:22:16,779
run on any node and in the kubernetes

00:22:13,749 --> 00:22:18,700
cluster so once you define this kind of

00:22:16,779 --> 00:22:22,570
service function as shown on the right

00:22:18,700 --> 00:22:24,820
side of the slide you just refer to the

00:22:22,570 --> 00:22:28,690
both labels as in kubernetes services

00:22:24,820 --> 00:22:31,899
then you refer to the name of the

00:22:28,690 --> 00:22:35,799
interface which you have given in the

00:22:31,899 --> 00:22:37,750
pot spec and you basically define the

00:22:35,799 --> 00:22:42,159
service chain as an ordered list of

00:22:37,750 --> 00:22:44,620
these pots and their interfaces this is

00:22:42,159 --> 00:22:46,990
an this is an implementation which uses

00:22:44,620 --> 00:22:52,919
auto cross connects to create the chain

00:22:46,990 --> 00:22:57,399
so the chain in this case is l2 based

00:22:52,919 --> 00:23:00,279
based on cross connects on the same VPP

00:22:57,399 --> 00:23:02,440
reseach instance or cross connects

00:23:00,279 --> 00:23:04,720
between the vehicle and Tunnel and the

00:23:02,440 --> 00:23:08,500
interfaces when well we need to go multi

00:23:04,720 --> 00:23:13,659
node will see again later what we can do

00:23:08,500 --> 00:23:16,570
for the same use case with our v6 and is

00:23:13,659 --> 00:23:21,549
just just an extension of the previous

00:23:16,570 --> 00:23:23,559
case to show that you can chain the the

00:23:21,549 --> 00:23:25,419
interface is not only between the pots

00:23:23,559 --> 00:23:27,669
but you can also change with some

00:23:25,419 --> 00:23:31,299
external the PDK interfaces or sub

00:23:27,669 --> 00:23:35,470
interfaces okay what's going on as our

00:23:31,299 --> 00:23:38,610
v6 so by default if you deploy come to

00:23:35,470 --> 00:23:42,730
be PPC and I you have ipv4 networking

00:23:38,610 --> 00:23:47,110
you can switch that to ipv6 and then you

00:23:42,730 --> 00:23:50,700
can optionally enable as our v6 and once

00:23:47,110 --> 00:23:54,159
you enable as our v6 in ipv6 deployment

00:23:50,700 --> 00:23:57,879
what do you get by default automatically

00:23:54,159 --> 00:23:59,350
is that instead of the VX one tunnel

00:23:57,879 --> 00:24:02,039
overlay between the nodes

00:23:59,350 --> 00:24:05,830
you would get an overlay with as our v6

00:24:02,039 --> 00:24:10,950
so whenever put on a node one needs to

00:24:05,830 --> 00:24:14,590
communicate to the port on the node to

00:24:10,950 --> 00:24:18,490
the the packet is steered into an asura

00:24:14,590 --> 00:24:22,360
vc v6 policy based on the destination IP

00:24:18,490 --> 00:24:26,200
subnet of that node the other v6 policy

00:24:22,360 --> 00:24:28,210
would have an incitement list which

00:24:26,200 --> 00:24:30,580
would contain just one segment which

00:24:28,210 --> 00:24:32,919
identifies the other node where the

00:24:30,580 --> 00:24:35,289
packet needs to traverse between the

00:24:32,919 --> 00:24:36,519
nodes you the packet is encapsulated

00:24:35,289 --> 00:24:40,649
with

00:24:36,519 --> 00:24:45,029
v6 header when it comes to to proper

00:24:40,649 --> 00:24:49,839
proper note it is the capsulated in the

00:24:45,029 --> 00:24:51,909
in the d t6 locales it function which

00:24:49,839 --> 00:24:54,549
does there's our v6 decapsulation and

00:24:51,909 --> 00:24:57,249
stable cup in ipv6 table and then

00:24:54,549 --> 00:25:02,559
forwards the packet towards the

00:24:57,249 --> 00:25:07,089
destination pot the other thing that you

00:25:02,559 --> 00:25:09,700
can optionally enable in income TV PP if

00:25:07,089 --> 00:25:15,820
you have a v6 deployment is kubernetes

00:25:09,700 --> 00:25:19,539
services implementation six so for ipv4

00:25:15,820 --> 00:25:21,219
we implement kubernetes services as most

00:25:19,539 --> 00:25:23,999
of the sea and ice using the network

00:25:21,219 --> 00:25:27,849
address translation and load balancing

00:25:23,999 --> 00:25:30,009
after not with the service six we can

00:25:27,849 --> 00:25:33,309
actually get rid of the network address

00:25:30,009 --> 00:25:36,099
translation and the way we do it is that

00:25:33,309 --> 00:25:40,869
whenever a port needs to talk to a

00:25:36,099 --> 00:25:44,709
service which is actually a set of

00:25:40,869 --> 00:25:48,549
back-end pots that that as a backends

00:25:44,709 --> 00:25:51,369
for that service we want to somehow old

00:25:48,549 --> 00:25:56,440
bonds between between the pots and with

00:25:51,369 --> 00:25:59,099
a v6 we again what say what said that

00:25:56,440 --> 00:26:01,869
pod one wants to communicate with some

00:25:59,099 --> 00:26:03,849
service endpoint and in this case the

00:26:01,869 --> 00:26:06,070
service endpoint can be either port to

00:26:03,849 --> 00:26:10,239
on the same note or the put two on the

00:26:06,070 --> 00:26:13,389
other node so so let's say we have a

00:26:10,239 --> 00:26:17,049
cluster IP kubernetes service so it is a

00:26:13,389 --> 00:26:19,539
virtual IP address when the when the

00:26:17,049 --> 00:26:23,019
packet from the pod one comes to the VPP

00:26:19,539 --> 00:26:25,059
we steer that packet into an asura v6

00:26:23,019 --> 00:26:29,109
policy based on the destination IP

00:26:25,059 --> 00:26:31,359
address cluster IP and then there is our

00:26:29,109 --> 00:26:34,599
v6 policy in this particular case would

00:26:31,359 --> 00:26:36,369
have to segment lists one would would be

00:26:34,599 --> 00:26:38,349
path towards the pot two on the same

00:26:36,369 --> 00:26:40,059
note and the other segment list would be

00:26:38,349 --> 00:26:42,700
the path towards the pots two on the

00:26:40,059 --> 00:26:44,940
other node and we basically award

00:26:42,700 --> 00:26:48,249
balance between those two segments lists

00:26:44,940 --> 00:26:50,350
in case of the same note the segment

00:26:48,249 --> 00:26:52,720
list would have just one second

00:26:50,350 --> 00:26:55,360
and inside of it and that would be the

00:26:52,720 --> 00:26:57,960
local seat with with the capsulation of

00:26:55,360 --> 00:27:01,419
sr v6 and cross-connect to arch the

00:26:57,960 --> 00:27:03,130
positive interface in case if it's all

00:27:01,419 --> 00:27:06,370
if it is all violence to the other

00:27:03,130 --> 00:27:09,280
segment list that one would have two

00:27:06,370 --> 00:27:13,780
segments in the list the first segment

00:27:09,280 --> 00:27:17,520
would would walk across it and shown on

00:27:13,780 --> 00:27:21,630
the note 2 and the other one would would

00:27:17,520 --> 00:27:26,740
forward the note towards the positive

00:27:21,630 --> 00:27:29,590
interface and the third thing that we

00:27:26,740 --> 00:27:32,590
can do with our v6 is service training

00:27:29,590 --> 00:27:36,220
so I've shown the service channel based

00:27:32,590 --> 00:27:41,169
on cross connects and this is a another

00:27:36,220 --> 00:27:44,740
way of doing that with there's our v6 we

00:27:41,169 --> 00:27:47,590
implement only snake based service

00:27:44,740 --> 00:27:49,659
chains so whenever traffic needs to

00:27:47,590 --> 00:27:52,750
traverse through multiple CN FS we

00:27:49,659 --> 00:27:56,289
always need to go to VPP and then to the

00:27:52,750 --> 00:28:01,330
other directly that is the limitation of

00:27:56,289 --> 00:28:03,429
continuity peace CNI currently and

00:28:01,330 --> 00:28:05,409
whenever you want to use as our v6 for

00:28:03,429 --> 00:28:08,350
service chaining you use the exactly

00:28:05,409 --> 00:28:11,440
same API as I've shown for the LT cross

00:28:08,350 --> 00:28:14,409
connect service chain so how it works

00:28:11,440 --> 00:28:17,530
with our v6 so let's say that this is

00:28:14,409 --> 00:28:21,549
our our chain that we want to achieve so

00:28:17,530 --> 00:28:23,799
we we want to have one CNF pot which

00:28:21,549 --> 00:28:26,530
would act as input whenever a packet

00:28:23,799 --> 00:28:28,929
comes out of that CNF we want that

00:28:26,530 --> 00:28:31,120
packet to go to CNF one pot from there

00:28:28,929 --> 00:28:36,039
to CNF to pot and from there to see

00:28:31,120 --> 00:28:39,190
another output put how it is rendered

00:28:36,039 --> 00:28:43,360
into network configuration with the

00:28:39,190 --> 00:28:47,020
Thera v6 in county VPP is this so first

00:28:43,360 --> 00:28:50,640
we steer the packet based on what's a

00:28:47,020 --> 00:28:53,590
destination IP into an SR v6 policy

00:28:50,640 --> 00:28:57,429
which in this case would be a little bit

00:28:53,590 --> 00:29:00,100
more complex it would contain a single

00:28:57,429 --> 00:29:04,510
segment list with multiple segments each

00:29:00,100 --> 00:29:08,260
segment does its its job in this pot so

00:29:04,510 --> 00:29:14,140
the first one is the the local sit ad

00:29:08,260 --> 00:29:16,630
which pretty much takes out a b6 header

00:29:14,140 --> 00:29:20,140
from the packet forwarded to the to the

00:29:16,630 --> 00:29:22,540
CNF one pot and when the packet comes

00:29:20,140 --> 00:29:24,940
back from the CNF one it it puts it as

00:29:22,540 --> 00:29:28,450
our v6 header baked to the packet and

00:29:24,940 --> 00:29:34,540
then goes to the next segment which

00:29:28,450 --> 00:29:36,640
would which would which would let the

00:29:34,540 --> 00:29:39,010
packet Traverse to the proper note that

00:29:36,640 --> 00:29:42,340
would be the opposite end on the note 2

00:29:39,010 --> 00:29:46,419
and from there it goes to another locale

00:29:42,340 --> 00:29:48,640
sit ad again there is decapsulation from

00:29:46,419 --> 00:29:50,580
from and as our v6 the packet goes to

00:29:48,640 --> 00:29:52,210
CNF to when it comes back again

00:29:50,580 --> 00:29:55,179
encapsulation and goes to the next

00:29:52,210 --> 00:29:59,080
segment in the list which would be

00:29:55,179 --> 00:30:04,000
eventually the locals it the x6 which

00:29:59,080 --> 00:30:09,010
just forward the capsulated packet to

00:30:04,000 --> 00:30:11,230
the CNF output one I think that we can

00:30:09,010 --> 00:30:13,120
do with as our v6 and during of service

00:30:11,230 --> 00:30:15,720
chains and cannot do with cross connect

00:30:13,120 --> 00:30:19,720
is that we can have a multi-part

00:30:15,720 --> 00:30:22,149
multi-part rendering of chain so in case

00:30:19,720 --> 00:30:24,850
that we have multiple ports that that

00:30:22,149 --> 00:30:29,799
match the pot selection criteria

00:30:24,850 --> 00:30:32,440
defining the SFC API definition we can

00:30:29,799 --> 00:30:38,169
create multiple chains and to hold

00:30:32,440 --> 00:30:41,830
balance between them and of course all

00:30:38,169 --> 00:30:44,740
of these works even even on multi node

00:30:41,830 --> 00:30:48,700
even if none of the CNF surrounds on

00:30:44,740 --> 00:30:51,340
that particular node if CNF input 3

00:30:48,700 --> 00:30:53,289
would be the input port the the traffic

00:30:51,340 --> 00:30:54,850
is steer into and as our v6 policy and

00:30:53,289 --> 00:30:56,890
from there it goes to the proper note

00:30:54,850 --> 00:31:00,580
with C nf1 and

00:30:56,890 --> 00:31:01,120
or CNF 1 1 1 or 1 2 and then the rest of

00:31:00,580 --> 00:31:03,610
the chain

00:31:01,120 --> 00:31:06,280
everything works dynamically so so if

00:31:03,610 --> 00:31:07,809
you let say shut down one of the nodes

00:31:06,280 --> 00:31:11,890
the CNF would

00:31:07,809 --> 00:31:13,809
reschedule on a different note and the

00:31:11,890 --> 00:31:18,120
forwarding through the chain still still

00:31:13,809 --> 00:31:18,120
works ok

00:31:20,500 --> 00:31:28,730
so thanks and now we take a look at how

00:31:26,480 --> 00:31:31,730
we can how we can accelerate as our v6

00:31:28,730 --> 00:31:33,470
with smiliness okay

00:31:31,730 --> 00:31:37,760
can you hear me the microphone works

00:31:33,470 --> 00:31:39,650
okay thank you okay I want to talk to

00:31:37,760 --> 00:31:41,450
you something about the accelerator this

00:31:39,650 --> 00:31:43,430
conference is mostly about the software

00:31:41,450 --> 00:31:47,170
but I want to talk something about how

00:31:43,430 --> 00:31:51,520
can use the hardware to making software

00:31:47,170 --> 00:31:56,900
working faster yes and making our

00:31:51,520 --> 00:31:59,570
implementing faster yes this January I

00:31:56,900 --> 00:32:02,020
visited our spirit or our home the

00:31:59,570 --> 00:32:07,250
Computer History Museum in Mountain View

00:32:02,020 --> 00:32:09,920
that we found the first Network art yes

00:32:07,250 --> 00:32:12,110
what was created over the world here so

00:32:09,920 --> 00:32:15,440
it is like and this picture is maybe it

00:32:12,110 --> 00:32:18,980
is not clear and I use this one to

00:32:15,440 --> 00:32:21,950
explain what is the our accelerator with

00:32:18,980 --> 00:32:24,110
the FPGA which is exactly this which is

00:32:21,950 --> 00:32:27,020
that Hardware making executive some

00:32:24,110 --> 00:32:29,420
function like this first card is we

00:32:27,020 --> 00:32:31,460
connecting here the network interfaces

00:32:29,420 --> 00:32:34,820
when we trying to put some traffic to

00:32:31,460 --> 00:32:37,490
the hostess it is just and our

00:32:34,820 --> 00:32:41,210
accelerators can make the multiple

00:32:37,490 --> 00:32:44,330
functions and by default it behaves like

00:32:41,210 --> 00:32:47,300
discourteous is doing nothing but with

00:32:44,330 --> 00:32:50,720
this accelerator we can do some more

00:32:47,300 --> 00:32:53,390
complex fixes why we should do some more

00:32:50,720 --> 00:32:55,850
complex fixes because for example

00:32:53,390 --> 00:32:59,510
alcoholics from Cisco is implementing

00:32:55,850 --> 00:33:03,890
that a lot of the new protocols is which

00:32:59,510 --> 00:33:07,730
provides some bottlenecks to the

00:33:03,890 --> 00:33:13,510
hardware processing ahmed explained us

00:33:07,730 --> 00:33:15,800
that how looks like the SLV 6 and

00:33:13,510 --> 00:33:18,500
normally when we have the normal card

00:33:15,800 --> 00:33:21,710
without any acceleration this network

00:33:18,500 --> 00:33:24,260
card this network card should be may

00:33:21,710 --> 00:33:26,450
should do all the packet processing

00:33:24,260 --> 00:33:28,130
going through there for example parsing

00:33:26,450 --> 00:33:30,110
of the headers making the decision of

00:33:28,130 --> 00:33:30,900
the headers with every header we should

00:33:30,110 --> 00:33:33,000
make the forward

00:33:30,900 --> 00:33:35,190
decision we should make a look up next

00:33:33,000 --> 00:33:38,880
look up next look up next look up yes it

00:33:35,190 --> 00:33:41,670
is when we want to do work make this

00:33:38,880 --> 00:33:44,130
under several layer it is that quite

00:33:41,670 --> 00:33:48,180
complex even for the very good software

00:33:44,130 --> 00:33:51,020
like the VPP is doing yes and it is the

00:33:48,180 --> 00:33:55,590
reason to including the accelerators yes

00:33:51,020 --> 00:33:58,020
we have in our models we have here the

00:33:55,590 --> 00:34:00,390
model when we making that some

00:33:58,020 --> 00:34:04,440
connection of the two via nerves or the

00:34:00,390 --> 00:34:08,940
two containers yes through the VPP when

00:34:04,440 --> 00:34:13,200
we want to accelerate or want to process

00:34:08,940 --> 00:34:16,620
the error series as a segment routing

00:34:13,200 --> 00:34:20,040
traffic faster yes and the problem with

00:34:16,620 --> 00:34:21,929
the packet processing is that because of

00:34:20,040 --> 00:34:24,240
the number of the lookups what we are

00:34:21,929 --> 00:34:28,260
doing inside of the software the less

00:34:24,240 --> 00:34:30,629
packets means less packets or the

00:34:28,260 --> 00:34:32,850
shorter packets means more problem and

00:34:30,629 --> 00:34:35,370
have more impact on the performance yes

00:34:32,850 --> 00:34:38,399
of course when we are using only the

00:34:35,370 --> 00:34:41,220
video traffic or we for example

00:34:38,399 --> 00:34:44,159
streaming only the YouTube or some it is

00:34:41,220 --> 00:34:46,950
not a big problem but for example when

00:34:44,159 --> 00:34:49,139
we are going to the word of the IOT or

00:34:46,950 --> 00:34:51,780
the shorter packet of the voice it's

00:34:49,139 --> 00:34:54,419
still that this problem of the packet

00:34:51,780 --> 00:34:59,730
processing is going to be be a bigger

00:34:54,419 --> 00:35:02,610
and bigger problem what we are doing in

00:34:59,730 --> 00:35:04,170
this operation is this picture presence

00:35:02,610 --> 00:35:06,390
how we are working without the

00:35:04,170 --> 00:35:08,310
accelerators yes it is just the inside

00:35:06,390 --> 00:35:10,770
of the card we are doing not

00:35:08,310 --> 00:35:13,050
accelerators so all the services

00:35:10,770 --> 00:35:16,890
processing is doing in the VPP router

00:35:13,050 --> 00:35:19,200
yes and it is nothing more our card

00:35:16,890 --> 00:35:23,460
accelerator works like the normal Nick

00:35:19,200 --> 00:35:26,190
curve yes it is nothing happens here in

00:35:23,460 --> 00:35:29,430
the accelerated model we have exactly

00:35:26,190 --> 00:35:31,770
the same model but we pushing the part

00:35:29,430 --> 00:35:35,010
of the acceleration I don't say that we

00:35:31,770 --> 00:35:37,170
pushing everything cos the FPGA and the

00:35:35,010 --> 00:35:40,560
hardware accelerators in this model is

00:35:37,170 --> 00:35:43,800
not there for example model which can do

00:35:40,560 --> 00:35:44,400
everything yes that we still we are

00:35:43,800 --> 00:35:47,400
making

00:35:44,400 --> 00:35:49,950
accelerator and this accelerator still

00:35:47,400 --> 00:35:52,380
workin give the BPP router but the sense

00:35:49,950 --> 00:35:54,270
of the acceleration is to make the job

00:35:52,380 --> 00:35:57,150
of the VP router software will be louder

00:35:54,270 --> 00:36:00,480
faster yes to limit number of the lookup

00:35:57,150 --> 00:36:02,880
series inside of the hardware and

00:36:00,480 --> 00:36:05,970
additional problem what we solving with

00:36:02,880 --> 00:36:08,279
this model not connecting the VM or the

00:36:05,970 --> 00:36:10,740
Vienna for the container directly to the

00:36:08,279 --> 00:36:15,329
FPGA in this model is to management yes

00:36:10,740 --> 00:36:18,210
we our cart in this model or our FPGA is

00:36:15,329 --> 00:36:20,400
hidden inside of the VPP so from the

00:36:18,210 --> 00:36:21,779
user point of view whatever software we

00:36:20,400 --> 00:36:23,339
are using for the managing like the

00:36:21,779 --> 00:36:26,670
county VPP which is the very good

00:36:23,339 --> 00:36:30,720
example it is invisible to this software

00:36:26,670 --> 00:36:33,500
yes to the user yes we accelerating

00:36:30,720 --> 00:36:40,109
their VPP or some function of the VPP

00:36:33,500 --> 00:36:43,230
not the not the overall data pervious it

00:36:40,109 --> 00:36:45,839
also in our models our FPGA is today

00:36:43,230 --> 00:36:48,180
either quite limited in the space and of

00:36:45,839 --> 00:36:50,670
course we couldn't put all the internet

00:36:48,180 --> 00:36:54,089
here in there PGA and it also help us to

00:36:50,670 --> 00:36:58,170
limit our acceleration to the to the

00:36:54,089 --> 00:37:00,510
model where is really necessary yes to

00:36:58,170 --> 00:37:05,369
limit the functionality what is really

00:37:00,510 --> 00:37:08,220
necessary and the most useful what we

00:37:05,369 --> 00:37:13,170
are achieving that way yes here is some

00:37:08,220 --> 00:37:16,770
pictures of which presents that what we

00:37:13,170 --> 00:37:19,740
can achieve this line which is that in

00:37:16,770 --> 00:37:22,470
the gray one is the way how we are

00:37:19,740 --> 00:37:24,029
working what we are can achieve with the

00:37:22,470 --> 00:37:26,579
pure software yes with all the

00:37:24,029 --> 00:37:28,529
acceleration is we could see that the

00:37:26,579 --> 00:37:31,890
overall path of the overall performance

00:37:28,529 --> 00:37:34,020
we can achieve because there are a

00:37:31,890 --> 00:37:35,760
number of the slow cups and the

00:37:34,020 --> 00:37:38,010
complexity of the processing includes

00:37:35,760 --> 00:37:41,910
the complexity in the packet processing

00:37:38,010 --> 00:37:45,150
at to make a processing efficient we

00:37:41,910 --> 00:37:47,279
should use the many many courses you see

00:37:45,150 --> 00:37:52,380
that for example to achieving the 36

00:37:47,279 --> 00:37:56,190
gigabytes for the 192 bytes packets we

00:37:52,380 --> 00:37:58,090
need to use the 12 course yes Intel

00:37:56,190 --> 00:38:00,670
asipi us have their fault

00:37:58,090 --> 00:38:02,860
for the 28 courts and it is not very

00:38:00,670 --> 00:38:06,670
efficient way to work that to use that -

00:38:02,860 --> 00:38:08,680
of course - from the 28 to make just

00:38:06,670 --> 00:38:10,360
that in a packet processing yes and

00:38:08,680 --> 00:38:11,530
nothing more yes it is just for the

00:38:10,360 --> 00:38:14,380
infrastructure yes

00:38:11,530 --> 00:38:17,560
with our accelerate or we can limit we

00:38:14,380 --> 00:38:20,470
can achieve the fork using the

00:38:17,560 --> 00:38:23,410
four-course 44 Giga bits or with the six

00:38:20,470 --> 00:38:27,210
cores 50 Giga bits yes and everything

00:38:23,410 --> 00:38:32,380
all more cores all and we are freeing

00:38:27,210 --> 00:38:36,580
more cores to the to the users yes so

00:38:32,380 --> 00:38:38,770
user can use efficiently to make our

00:38:36,580 --> 00:38:41,170
core CPU cores or to making the

00:38:38,770 --> 00:38:42,970
processing faster also making it much

00:38:41,170 --> 00:38:44,920
more efficiently having the same

00:38:42,970 --> 00:38:49,270
flexibility what is delivered with the

00:38:44,920 --> 00:38:51,910
SR v6 and the VP here this picture

00:38:49,270 --> 00:38:55,210
presents the more example what we are

00:38:51,910 --> 00:39:01,860
doing and we can achieve for example

00:38:55,210 --> 00:39:04,690
saving 8 to 10 courses by this one is

00:39:01,860 --> 00:39:09,280
Intel unfortunately do not provide this

00:39:04,690 --> 00:39:12,340
operation all this solution directly we

00:39:09,280 --> 00:39:13,930
are working with our partner HCl which

00:39:12,340 --> 00:39:16,780
is the company from India who is our

00:39:13,930 --> 00:39:18,850
partner who deliver ink and the testing

00:39:16,780 --> 00:39:20,620
the solution for our end customer what

00:39:18,850 --> 00:39:23,740
the Intel is really doing in to

00:39:20,620 --> 00:39:26,710
delivering the hardware so which can we

00:39:23,740 --> 00:39:29,020
can do this this operation a service 6

00:39:26,710 --> 00:39:47,110
and many many other examples use of the

00:39:29,020 --> 00:39:48,940
acceleration is ok so just as we say

00:39:47,110 --> 00:39:52,410
like kubernetes does not provide any

00:39:48,940 --> 00:39:55,600
solution to to not working you need to

00:39:52,410 --> 00:40:00,340
pick your CNI plugins that you will use

00:39:55,600 --> 00:40:02,500
to do the networking and CNI plugins as

00:40:00,340 --> 00:40:04,870
we said like they provide 2 main

00:40:02,500 --> 00:40:08,470
function in kubernetes the connectivity

00:40:04,870 --> 00:40:10,530
and the reach ability and we need IV v6

00:40:08,470 --> 00:40:14,140
to provide

00:40:10,530 --> 00:40:18,069
i ps4 these containers or kubernetes

00:40:14,140 --> 00:40:20,200
pods and we believe that a service 6 by

00:40:18,069 --> 00:40:23,200
leveraging the ipv6 data plane can

00:40:20,200 --> 00:40:26,500
handle various kubernetes use cases in a

00:40:23,200 --> 00:40:30,130
more simple and scalar scalable way and

00:40:26,500 --> 00:40:33,310
we given this talk to examples of us our

00:40:30,130 --> 00:40:36,930
basic support boss in quantity PP to do

00:40:33,310 --> 00:40:40,720
as a CNI plugin and also accelerating

00:40:36,930 --> 00:40:43,720
the J's our v6 processing using the

00:40:40,720 --> 00:40:46,470
smartness in order to free let's say

00:40:43,720 --> 00:40:49,960
more cores in your servers for

00:40:46,470 --> 00:41:08,890
application workload and with this thank

00:40:49,960 --> 00:41:12,190
you and ready to for any questions no

00:41:08,890 --> 00:41:14,470
actually it was this 192 it was this was

00:41:12,190 --> 00:41:16,140
the side or the size of the packet so if

00:41:14,470 --> 00:41:19,240
you speak about the service six

00:41:16,140 --> 00:41:22,599
encapsulation so basically it depends on

00:41:19,240 --> 00:41:30,250
the use case so if I go back to the

00:41:22,599 --> 00:41:33,010
overlay okay so so the question was how

00:41:30,250 --> 00:41:38,200
much of overhead is our v6 add to the

00:41:33,010 --> 00:41:41,740
packet how much bytes service exceeds as

00:41:38,200 --> 00:41:43,270
an overhead added to the packet so for

00:41:41,740 --> 00:41:44,890
the North forum for most of the use

00:41:43,270 --> 00:41:48,760
cases when you want you to do just

00:41:44,890 --> 00:41:51,849
overlay basically it just an ipv6 outer

00:41:48,760 --> 00:41:54,910
header so it's the same as IP n IP

00:41:51,849 --> 00:41:57,910
encapsulation so you are just ipv6 if

00:41:54,910 --> 00:42:01,119
you want to implement some more advanced

00:41:57,910 --> 00:42:03,069
use cases like like traffic engineering

00:42:01,119 --> 00:42:05,770
for example when you need to send the

00:42:03,069 --> 00:42:08,770
packet through several nodes so in this

00:42:05,770 --> 00:42:12,160
case you will need to have an S or v6

00:42:08,770 --> 00:42:14,980
header as well and and based on how many

00:42:12,160 --> 00:42:20,079
how many how many nodes you need to need

00:42:14,980 --> 00:42:22,930
to process a packet well actually is not

00:42:20,079 --> 00:42:23,569
is not it's it's how many how many nodes

00:42:22,930 --> 00:42:24,979
you need

00:42:23,569 --> 00:42:27,680
addressed in the past so I'm sending

00:42:24,979 --> 00:42:29,930
traffic from X to Y through one two

00:42:27,680 --> 00:42:34,279
three so you need to add as a segment

00:42:29,930 --> 00:42:36,319
for for each for each known as an ipv6

00:42:34,279 --> 00:43:00,709
address because the nodes are ipv6

00:42:36,319 --> 00:43:03,769
addresses well also depends here in use

00:43:00,709 --> 00:43:05,779
case so there are two two two two ways

00:43:03,769 --> 00:43:07,190
to encapsulate the traffic so if you

00:43:05,779 --> 00:43:09,170
need to implement some layer two

00:43:07,190 --> 00:43:10,999
services you can you can encapsulate the

00:43:09,170 --> 00:43:14,269
whole layer 2 frame inside the packet

00:43:10,999 --> 00:43:17,509
but if you need to do just layer 3

00:43:14,269 --> 00:43:19,309
services or kind of layer 3 VPN so

00:43:17,509 --> 00:43:22,449
basically you can include you can

00:43:19,309 --> 00:43:26,630
encapsulate just the layer 3 traffic

00:43:22,449 --> 00:43:29,119
either ipv4 or ipv6 a service six

00:43:26,630 --> 00:43:30,709
defines different models for the

00:43:29,119 --> 00:43:33,559
application of the container which is

00:43:30,709 --> 00:43:36,469
the service six aware and it does the

00:43:33,559 --> 00:43:39,289
service 6 not our yes so when the is the

00:43:36,469 --> 00:43:42,410
service 6 not our the hardware of the

00:43:39,289 --> 00:43:44,420
VPP does the strip the VPP at the asari

00:43:42,410 --> 00:43:47,539
v6 header and when the packet is sent

00:43:44,420 --> 00:43:49,279
out it adds it again so the the tunnel

00:43:47,539 --> 00:43:54,410
of the service external is not visible

00:43:49,279 --> 00:43:56,209
to the VN to the application yes but for

00:43:54,410 --> 00:43:59,479
example when the application is a

00:43:56,209 --> 00:44:02,989
service 6 aware it can achieve received

00:43:59,479 --> 00:44:05,660
all the packets with the all the all the

00:44:02,989 --> 00:44:08,890
encapsulation it is depending what the

00:44:05,660 --> 00:44:12,170
option here is the added here assiduous

00:44:08,890 --> 00:44:14,449
configured in the routing table yes on

00:44:12,170 --> 00:44:16,940
the VPP yeah default for the last 3 for

00:44:14,449 --> 00:44:19,549
the last 3 operation so basically when

00:44:16,940 --> 00:44:22,579
you implement services chain so you can

00:44:19,549 --> 00:44:26,119
have your your your network function or

00:44:22,579 --> 00:44:28,670
CNF or a service excel where so they can

00:44:26,119 --> 00:44:30,799
process and skip this encapsulation and

00:44:28,670 --> 00:44:33,440
process the packet say you have a

00:44:30,799 --> 00:44:36,230
firewall that needs to apply some rules

00:44:33,440 --> 00:44:38,330
on the original packet so

00:44:36,230 --> 00:44:39,950
as at the firewall is aware of the

00:44:38,330 --> 00:44:42,770
encapsulation and can apply the rule

00:44:39,950 --> 00:44:45,080
directly or it's unaware in this case

00:44:42,770 --> 00:44:48,320
you need to strip out the encapsulation

00:44:45,080 --> 00:45:07,250
and this is where the intend card can do

00:44:48,320 --> 00:45:09,680
it at the higher processing rate times

00:45:07,250 --> 00:45:12,160
out I will take it off with the question

00:45:09,680 --> 00:45:15,260
I can repeat the question I'm sorry

00:45:12,160 --> 00:45:20,050
so basically the question was if the

00:45:15,260 --> 00:45:20,050
application is us our v6 unaware and

00:45:20,109 --> 00:45:25,640
will will will the Ruby away or or la

00:45:24,050 --> 00:45:27,710
layer between the application and the

00:45:25,640 --> 00:45:31,520
network that handles an encapsulation

00:45:27,710 --> 00:45:33,320
that's true so it so if your application

00:45:31,520 --> 00:45:35,390
is not aware of the service 6

00:45:33,320 --> 00:45:38,000
encapsulation there are three different

00:45:35,390 --> 00:45:40,510
ways of doing this kind of proxy between

00:45:38,000 --> 00:45:43,490
the application and and and

00:45:40,510 --> 00:46:11,090
infrastructure but if your application

00:45:43,490 --> 00:46:13,010
is I'm I'm not sure which which part

00:46:11,090 --> 00:46:17,980
exactly are you referring to but from

00:46:13,010 --> 00:46:17,980
from the slide here all of this at least

00:46:18,460 --> 00:46:24,890
up to hear all of this behavior are

00:46:20,869 --> 00:46:26,810
supported and in the Linux kernel so for

00:46:24,890 --> 00:46:30,609
the proxy behavior are implemented

00:46:26,810 --> 00:46:30,609
currently as a Linux kernel module

00:46:32,380 --> 00:46:34,440

YouTube URL: https://www.youtube.com/watch?v=c_-S5eJP_Mo


