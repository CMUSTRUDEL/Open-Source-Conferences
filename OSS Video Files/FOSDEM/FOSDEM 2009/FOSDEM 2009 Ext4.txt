Title: FOSDEM 2009 Ext4
Publication date: 2011-12-22
Playlist: FOSDEM 2009
Description: 
	This presentation will discuss history of ext4, its features and advantages, and how best to use the ext4 filesystem.

The latest generation of the ext2/ext3 filesystems is the ext4 filesystem, which recently left the development status of 2.6.28. With extents, delayed allocation, multiblock allocation, persistent preallocation, and its other new features, it is substantally faster and more efficient compared to the ext3 filesystem.

By Theodore Ts'o

FOSDEM (Free and Open Source Development European Meeting) is a European event centered around Free and Open Source software development. It is aimed at developers and all interested in the Free and Open Source news in the world. Its goals are to enable developers to meet and to promote the awareness and use of free and open source software. More info at http://fosdem.org
Captions: 
	00:00:07,400 --> 00:00:12,090
first of all I'd like to thank you all

00:00:09,900 --> 00:00:15,049
for coming and I'd really like to thank

00:00:12,090 --> 00:00:19,140
the FOSDEM organizers this is actually

00:00:15,049 --> 00:00:21,240
my first time presenting at FOSDEM first

00:00:19,140 --> 00:00:23,640
time I've been at FOSDEM and it's been a

00:00:21,240 --> 00:00:26,250
lot of fun I really enjoyed myself so

00:00:23,640 --> 00:00:29,099
thank you all for coming and thank the

00:00:26,250 --> 00:00:31,890
FOSDEM organizers for inviting me please

00:00:29,099 --> 00:00:34,620
bear with me this is a presentation I

00:00:31,890 --> 00:00:36,390
had to create on the fly because my

00:00:34,620 --> 00:00:38,879
primary laptop got stolen at the

00:00:36,390 --> 00:00:41,280
Brussels train station so I had this

00:00:38,879 --> 00:00:44,700
cool demo I was going to show showing

00:00:41,280 --> 00:00:47,969
how quick fsck was on a file system that

00:00:44,700 --> 00:00:50,430
I had been using since July except it

00:00:47,969 --> 00:00:52,920
got stolen so wikitravel has all of this

00:00:50,430 --> 00:00:54,930
stuff about you know things you have to

00:00:52,920 --> 00:00:57,180
be careful pickpockets work in teams

00:00:54,930 --> 00:01:00,559
they'll distract you grab your laptop

00:00:57,180 --> 00:01:05,580
bag I'm here to tell you it's all true

00:01:00,559 --> 00:01:07,260
so yeah I learned that the hard way

00:01:05,580 --> 00:01:09,930
anyway fortunately I happen to be

00:01:07,260 --> 00:01:11,310
carrying a backup netbook that was

00:01:09,930 --> 00:01:13,140
planning on using for crash and burn

00:01:11,310 --> 00:01:14,610
testing I was actually planning on

00:01:13,140 --> 00:01:17,130
getting some development work done over

00:01:14,610 --> 00:01:18,600
the weekend which didn't happen but

00:01:17,130 --> 00:01:20,840
that's okay

00:01:18,600 --> 00:01:22,890
and so why don't we get started and

00:01:20,840 --> 00:01:26,310
first let me talk a little bit about

00:01:22,890 --> 00:01:29,700
some of the good things about the ext3

00:01:26,310 --> 00:01:32,939
file system it's probably the most

00:01:29,700 --> 00:01:35,729
widely used file system in Linux and it

00:01:32,939 --> 00:01:38,820
it's code that therefore has been around

00:01:35,729 --> 00:01:42,659
for a long time people trust it you know

00:01:38,820 --> 00:01:44,939
it's been well shaken down also very

00:01:42,659 --> 00:01:48,000
very important and this is probably one

00:01:44,939 --> 00:01:51,630
of those things that a number of file

00:01:48,000 --> 00:01:54,720
system efforts before didn't didn't

00:01:51,630 --> 00:01:57,479
really pick up on ext3 has an extremely

00:01:54,720 --> 00:02:01,020
diverse development community which

00:01:57,479 --> 00:02:03,270
means we've have developers from Red Hat

00:02:01,020 --> 00:02:07,640
from cluster FS which was since

00:02:03,270 --> 00:02:12,690
purchased by Sun we have developers from

00:02:07,640 --> 00:02:14,940
Sousa Red Hat IBM

00:02:12,690 --> 00:02:19,440
and so that actually is really really

00:02:14,940 --> 00:02:20,700
useful because it means that number one

00:02:19,440 --> 00:02:22,650
you don't have to worry about what

00:02:20,700 --> 00:02:24,090
happens if one company decides that it's

00:02:22,650 --> 00:02:26,190
time to cut back on their kernel

00:02:24,090 --> 00:02:28,860
development budget but it's also

00:02:26,190 --> 00:02:32,549
important because if a distribution

00:02:28,860 --> 00:02:34,049
wants to support a file system they need

00:02:32,549 --> 00:02:36,569
to feel comfortable that they have

00:02:34,049 --> 00:02:38,069
people who understand it well enough

00:02:36,569 --> 00:02:39,870
that they can actually help their

00:02:38,069 --> 00:02:43,650
customers if their customers have

00:02:39,870 --> 00:02:45,060
problems with it historically I don't I

00:02:43,650 --> 00:02:47,849
can't speak for Red Hat

00:02:45,060 --> 00:02:51,630
but until very recently Red Hat did not

00:02:47,849 --> 00:02:53,280
have an XFS engineer on staff and I

00:02:51,630 --> 00:02:56,849
don't believe it was a coincidence that

00:02:53,280 --> 00:02:58,769
Red Hat didn't support XFS it's only

00:02:56,849 --> 00:03:01,709
recently that Eric Sandeen who was a

00:02:58,769 --> 00:03:04,739
former XFS developer he's now helping us

00:03:01,709 --> 00:03:07,379
out with the hd4 joined Red Hat and now

00:03:04,739 --> 00:03:09,120
they're going to be including X vest

00:03:07,379 --> 00:03:11,970
support I have my understanding is at

00:03:09,120 --> 00:03:14,040
least in preview form in a rel update

00:03:11,970 --> 00:03:16,709
and then they'll be supporting it fully

00:03:14,040 --> 00:03:19,850
in the future but again it points out

00:03:16,709 --> 00:03:23,340
the fact that if you don't have

00:03:19,850 --> 00:03:24,900
developers at a distribution it's really

00:03:23,340 --> 00:03:26,579
not surprising the distribution it's

00:03:24,900 --> 00:03:29,150
going to be really hesitant supporting

00:03:26,579 --> 00:03:31,970
something as critical as a file system

00:03:29,150 --> 00:03:34,889
another example of that would be JFS

00:03:31,970 --> 00:03:37,200
ibm's JFS which is a very good file

00:03:34,889 --> 00:03:39,599
system and at the time when it was

00:03:37,200 --> 00:03:42,690
introduced there were ways in which it

00:03:39,599 --> 00:03:44,579
was in fact far better than ext3 there

00:03:42,690 --> 00:03:47,720
was only one problem which was almost

00:03:44,579 --> 00:03:51,260
the entire development team was at IBM

00:03:47,720 --> 00:03:53,310
Red Hat and Sousa didn't have any

00:03:51,260 --> 00:03:55,919
engineers who were really familiar with

00:03:53,310 --> 00:03:58,410
JFS and surprise surprise they were

00:03:55,919 --> 00:04:00,329
really hesitant in supporting it and

00:03:58,410 --> 00:04:02,579
that's that's been a really big deal so

00:04:00,329 --> 00:04:06,120
one of the things that I've told the

00:04:02,579 --> 00:04:07,590
btrfs folks and a big supporter of btrfs

00:04:06,120 --> 00:04:09,690
I really believe it's going to be a

00:04:07,590 --> 00:04:11,489
great file system although people who

00:04:09,690 --> 00:04:13,200
think it's going to be ready in the

00:04:11,489 --> 00:04:16,169
short term are probably a little bit too

00:04:13,200 --> 00:04:17,150
over enthusiastic I'll talk a little bit

00:04:16,169 --> 00:04:19,560
more about that later

00:04:17,150 --> 00:04:22,229
but one things I told them is you've got

00:04:19,560 --> 00:04:23,820
to recruit people from across the Linux

00:04:22,229 --> 00:04:25,470
industry if you want to be successful

00:04:23,820 --> 00:04:28,980
because it's just

00:04:25,470 --> 00:04:30,630
it's the realities of development so

00:04:28,980 --> 00:04:34,290
there are also a couple of things that

00:04:30,630 --> 00:04:38,040
are not so good about ext3 a lot of

00:04:34,290 --> 00:04:40,680
silly limitations perhaps the most

00:04:38,040 --> 00:04:44,520
stupid one is the fact that we can only

00:04:40,680 --> 00:04:49,440
have 32,000 subdirectories actually that

00:04:44,520 --> 00:04:51,540
should be 30 mm not 32 768 we have

00:04:49,440 --> 00:04:54,030
second resolution time stamps which is a

00:04:51,540 --> 00:04:56,100
bit of an issue given that computers are

00:04:54,030 --> 00:04:58,380
kind of fast now when you can compile a

00:04:56,100 --> 00:04:59,670
file and well under a second which is

00:04:58,380 --> 00:05:03,030
sort of an issue of you're going to be

00:04:59,670 --> 00:05:06,510
using make which likes to track based on

00:05:03,030 --> 00:05:08,130
time stamps and you know 16 terabytes is

00:05:06,510 --> 00:05:11,040
starting to actually be a real

00:05:08,130 --> 00:05:14,880
limitation and perhaps the biggest

00:05:11,040 --> 00:05:17,370
problem with ext3 has been its

00:05:14,880 --> 00:05:19,680
performance limitations now some of that

00:05:17,370 --> 00:05:24,000
has been deliberate ext3 we've always

00:05:19,680 --> 00:05:26,280
taken the position that we care a whole

00:05:24,000 --> 00:05:30,510
lot more about making sure the data is

00:05:26,280 --> 00:05:32,760
safe than it being fast because if it's

00:05:30,510 --> 00:05:34,380
people get really cranky when they lose

00:05:32,760 --> 00:05:36,720
data that's probably the simplest way I

00:05:34,380 --> 00:05:38,750
can put it you know it's one thing to

00:05:36,720 --> 00:05:42,140
win the benchmark Wars but first of all

00:05:38,750 --> 00:05:45,000
many many workloads are not even

00:05:42,140 --> 00:05:47,460
filesystem mount right so if you have a

00:05:45,000 --> 00:05:49,650
super fast benchmarking result but in

00:05:47,460 --> 00:05:52,229
real life you're actually really CPU

00:05:49,650 --> 00:05:54,720
bound then it may not really matter and

00:05:52,229 --> 00:05:57,750
then if you lose your source tree people

00:05:54,720 --> 00:06:02,400
get cranky so we've historically been

00:05:57,750 --> 00:06:04,890
very very conservative with ext3 but

00:06:02,400 --> 00:06:07,169
over time that's started to become a

00:06:04,890 --> 00:06:10,919
real limitation and so it was time to

00:06:07,169 --> 00:06:13,530
try to add new features and make ext3

00:06:10,919 --> 00:06:17,160
into you know what I would call a modern

00:06:13,530 --> 00:06:20,340
file system now this brings up an

00:06:17,160 --> 00:06:24,300
interesting philosophical question which

00:06:20,340 --> 00:06:26,760
is is ext4 really a new file system it's

00:06:24,300 --> 00:06:28,680
certainly a new file system subdirectory

00:06:26,760 --> 00:06:32,400
so if you look in the kernel sources

00:06:28,680 --> 00:06:35,940
under FS slash ext4 you will see a

00:06:32,400 --> 00:06:39,370
complete source code this is source code

00:06:35,940 --> 00:06:43,300
that was forked in to 6:19

00:06:39,370 --> 00:06:47,699
but it's important to remember that EXT

00:06:43,300 --> 00:06:52,540
in ext2 ext3 ext4 stands for extended

00:06:47,699 --> 00:06:55,960
and in fact EXT for as far as the file

00:06:52,540 --> 00:06:58,479
system format is concerned is actually a

00:06:55,960 --> 00:07:02,350
collection of new features that can be

00:06:58,479 --> 00:07:05,440
individually enabled or disabled so some

00:07:02,350 --> 00:07:09,010
of them are extents some of them are a

00:07:05,440 --> 00:07:12,910
huge file dura underscore and link so on

00:07:09,010 --> 00:07:14,680
and so forth and together if you if you

00:07:12,910 --> 00:07:18,010
enable all these features then you would

00:07:14,680 --> 00:07:22,060
get the full effect of ext4 and the ext4

00:07:18,010 --> 00:07:24,010
file system driver in the linux kernel

00:07:22,060 --> 00:07:28,479
supports all of these new file system

00:07:24,010 --> 00:07:32,530
features but you can also run a standard

00:07:28,479 --> 00:07:37,090
ext3 file system and mounted as ext4 and

00:07:32,530 --> 00:07:40,060
it will work just fine in fact as of two

00:07:37,090 --> 00:07:43,930
6:29 which is the next stable kernel

00:07:40,060 --> 00:07:47,260
release we're currently at - 629 rc3 you

00:07:43,930 --> 00:07:49,150
will actually be able to mount an ext to

00:07:47,260 --> 00:07:52,630
file system which is to say a file

00:07:49,150 --> 00:07:55,479
system without a journal on the ext4

00:07:52,630 --> 00:07:57,340
filesystem driver core and this was

00:07:55,479 --> 00:08:00,520
actually code that was contributed to us

00:07:57,340 --> 00:08:03,550
from Google that allowed us to be able

00:08:00,520 --> 00:08:08,320
to mount a file system without a journal

00:08:03,550 --> 00:08:11,199
with ext4 codebase ext3 simply because

00:08:08,320 --> 00:08:13,120
way back when when Steven Tweedy was

00:08:11,199 --> 00:08:15,550
developing hd3 we had forked the

00:08:13,120 --> 00:08:19,000
codebase in order to make life simpler

00:08:15,550 --> 00:08:21,880
he had written the code such that the

00:08:19,000 --> 00:08:23,560
journal had to be enabled and in fact if

00:08:21,880 --> 00:08:26,740
the journal was not present and you

00:08:23,560 --> 00:08:30,099
tried to mount it as ext3 ext4 would

00:08:26,740 --> 00:08:34,409
just refuse them out Google as it turns

00:08:30,099 --> 00:08:37,870
out wanted the advanced features of ext4

00:08:34,409 --> 00:08:39,430
because extents and all the rest proved

00:08:37,870 --> 00:08:42,159
to have some really nice performance

00:08:39,430 --> 00:08:45,790
benefits for them but Google doesn't

00:08:42,159 --> 00:08:48,280
believe in journals because Google has

00:08:45,790 --> 00:08:50,950
the theory that if the system ever

00:08:48,280 --> 00:08:52,690
crashes you wipe the hard drive and you

00:08:50,950 --> 00:08:55,300
could recover from the other

00:08:52,690 --> 00:08:56,650
two redundant backups right and if

00:08:55,300 --> 00:08:59,170
you're gonna do that and you don't have

00:08:56,650 --> 00:09:01,150
to worry about fsck ting the drive

00:08:59,170 --> 00:09:03,850
because if the system ever crashes you

00:09:01,150 --> 00:09:06,280
just wipe the disk and you know copy

00:09:03,850 --> 00:09:08,470
from a backup then you don't actually

00:09:06,280 --> 00:09:09,880
need to recover from Journal and they

00:09:08,470 --> 00:09:13,030
got a little bit of the performance

00:09:09,880 --> 00:09:15,910
boost by running without the journal so

00:09:13,030 --> 00:09:19,660
in the latest two 629 you'll actually be

00:09:15,910 --> 00:09:22,420
able to enable all of the ext4 features

00:09:19,660 --> 00:09:23,710
but disable the journal because Google

00:09:22,420 --> 00:09:26,140
was interested in running in that in

00:09:23,710 --> 00:09:28,060
that fashion it also turns out you could

00:09:26,140 --> 00:09:31,680
run with all the features disabled and

00:09:28,060 --> 00:09:35,050
mount a standard ext2 file system on

00:09:31,680 --> 00:09:37,600
ext4 you would still get some of the

00:09:35,050 --> 00:09:41,230
performance benefits that don't depend

00:09:37,600 --> 00:09:42,490
on the file system format but it's more

00:09:41,230 --> 00:09:47,320
interesting just simply from a

00:09:42,490 --> 00:09:49,720
flexibility point of view so why did we

00:09:47,320 --> 00:09:52,360
even bother to actually fork the code

00:09:49,720 --> 00:09:56,500
and again this was just simply from us a

00:09:52,360 --> 00:10:00,070
matter of development stability ext3 has

00:09:56,500 --> 00:10:01,900
a huge you know user base including

00:10:00,070 --> 00:10:03,550
leanest Torvalds and Andrew Morton and

00:10:01,900 --> 00:10:05,650
they would get cranky if their file

00:10:03,550 --> 00:10:08,830
systems got destroyed and their

00:10:05,650 --> 00:10:12,010
sorceries were wiped out and so we had a

00:10:08,830 --> 00:10:13,990
lot more opportunity to experiment if we

00:10:12,010 --> 00:10:15,190
just simply fork the code base and we

00:10:13,990 --> 00:10:17,230
didn't have to worry that we might

00:10:15,190 --> 00:10:20,290
accidentally trash you know some

00:10:17,230 --> 00:10:21,760
important people's code at the same time

00:10:20,290 --> 00:10:24,180
it also allowed us to do all of our

00:10:21,760 --> 00:10:26,770
development in in the mainline tree

00:10:24,180 --> 00:10:30,130
which was also a big help so that's what

00:10:26,770 --> 00:10:33,310
we actually did but from a theoretical

00:10:30,130 --> 00:10:35,470
point of view it's not really a new file

00:10:33,310 --> 00:10:37,990
system except that we added a whole lot

00:10:35,470 --> 00:10:41,110
of code to it we started with ext 3 we

00:10:37,990 --> 00:10:45,339
added new extensions to it from the user

00:10:41,110 --> 00:10:50,200
space code we use the same etfs frogs to

00:10:45,339 --> 00:10:51,580
support ext2 ext3 and now EXT for you

00:10:50,200 --> 00:10:54,220
just simply have to have a new enough

00:10:51,580 --> 00:10:57,400
version of e 2 FS Prague's so you know

00:10:54,220 --> 00:10:58,720
is a new file system is it not it really

00:10:57,400 --> 00:11:03,040
depends on your point of view it is

00:10:58,720 --> 00:11:05,050
definitely a new file system codebase

00:11:03,040 --> 00:11:06,790
I'm not even sure you could call it a

00:11:05,050 --> 00:11:09,910
new implementation it's just simply a

00:11:06,790 --> 00:11:14,260
more advanced version with new features

00:11:09,910 --> 00:11:17,589
so pays your money takes your choices so

00:11:14,260 --> 00:11:20,890
what's new in ext for there are a huge

00:11:17,589 --> 00:11:24,459
number of features that are new probably

00:11:20,890 --> 00:11:26,350
the biggest one is extents and then the

00:11:24,459 --> 00:11:29,430
changes to the block allocator and I'll

00:11:26,350 --> 00:11:31,870
talk more about those in just a moment

00:11:29,430 --> 00:11:35,500
some of the other features that we have

00:11:31,870 --> 00:11:37,690
added are simply to address problems

00:11:35,500 --> 00:11:40,770
that I've already alluded to before

00:11:37,690 --> 00:11:46,990
for example we remove that really stupid

00:11:40,770 --> 00:11:51,520
32,000 subdirectory limitation nfsv4 has

00:11:46,990 --> 00:11:54,490
a requirement for a 64 bit unique

00:11:51,520 --> 00:11:58,540
version ID that gets bumped whenever a

00:11:54,490 --> 00:12:00,910
file is changed in any way

00:11:58,540 --> 00:12:03,970
and they need that specifically so that

00:12:00,910 --> 00:12:07,060
they can do reliable caching I'm not an

00:12:03,970 --> 00:12:09,550
NFS before expert I think they have some

00:12:07,060 --> 00:12:11,670
Cluj that makes the caching less

00:12:09,550 --> 00:12:14,650
efficient if you don't have that feature

00:12:11,670 --> 00:12:16,810
but the NFS before people really wanted

00:12:14,650 --> 00:12:21,970
it so while we were in there we added

00:12:16,810 --> 00:12:24,790
the nfsv4 version ID we also and this is

00:12:21,970 --> 00:12:27,550
in the sort of category of stupid

00:12:24,790 --> 00:12:28,750
changes that was really easy to do once

00:12:27,550 --> 00:12:33,910
you're actually going to open up the

00:12:28,750 --> 00:12:38,760
code we now store the size of the file

00:12:33,910 --> 00:12:43,030
in units of a filesystem block size as

00:12:38,760 --> 00:12:45,910
opposed to the POSIX mandated 512 sector

00:12:43,030 --> 00:12:50,260
size which is a mistake perpetrated by

00:12:45,910 --> 00:12:53,560
system 5 unix and that basically gave us

00:12:50,260 --> 00:12:56,980
a very painless way of expanding the

00:12:53,560 --> 00:12:59,950
maximum size of the file from 2

00:12:56,980 --> 00:13:02,290
terabytes to 16 terabytes if you're

00:12:59,950 --> 00:13:05,110
using a fork a block size file system

00:13:02,290 --> 00:13:08,140
and if you're on you know a night a neom

00:13:05,110 --> 00:13:11,829
system or a power system and use it even

00:13:08,140 --> 00:13:14,829
bigger block size such as 16 K 32 K

00:13:11,829 --> 00:13:17,470
block size you know you get another a

00:13:14,829 --> 00:13:18,790
couple of powers of two out of that and

00:13:17,470 --> 00:13:19,420
that was just something that we could do

00:13:18,790 --> 00:13:22,210
that was act

00:13:19,420 --> 00:13:23,800
be very very easy we'll talk a little

00:13:22,210 --> 00:13:26,400
bit later about why we didn't actually

00:13:23,800 --> 00:13:29,220
change that to expand that even further

00:13:26,400 --> 00:13:32,820
and it's something we could do it's just

00:13:29,220 --> 00:13:36,580
something we didn't do this time around

00:13:32,820 --> 00:13:39,820
we added a TA trim support this is

00:13:36,580 --> 00:13:43,180
support that we'll be showing up in some

00:13:39,820 --> 00:13:44,970
of the new big storage sub systems that

00:13:43,180 --> 00:13:48,130
do something called thin provisioning

00:13:44,970 --> 00:13:49,990
where you've got a large number of block

00:13:48,130 --> 00:13:53,200
devices that might not be completely

00:13:49,990 --> 00:13:56,110
full and we can the file system when you

00:13:53,200 --> 00:13:58,390
delete a file can tell the block device

00:13:56,110 --> 00:14:01,450
we're not using these blocks anymore so

00:13:58,390 --> 00:14:04,630
you can use them for something else it's

00:14:01,450 --> 00:14:06,460
also useful for solid state disks for

00:14:04,630 --> 00:14:09,640
the same reason they can do a better job

00:14:06,460 --> 00:14:13,000
we're leveling if the file system can

00:14:09,640 --> 00:14:15,790
inform the block the the solid state

00:14:13,000 --> 00:14:18,160
disk that these blocks are no longer in

00:14:15,790 --> 00:14:20,200
use so you can use them for we're

00:14:18,160 --> 00:14:23,080
leveling the support is in the file

00:14:20,200 --> 00:14:25,990
system the low-level code to actually

00:14:23,080 --> 00:14:28,900
send the trim commands to the devices

00:14:25,990 --> 00:14:31,240
has not actually hit main line yet and

00:14:28,900 --> 00:14:32,530
my understanding is it's because the

00:14:31,240 --> 00:14:35,730
people who were in charge of writing

00:14:32,530 --> 00:14:38,380
that bit of code doesn't have hardware

00:14:35,730 --> 00:14:40,630
that actually implements the features

00:14:38,380 --> 00:14:42,070
yet or something like that you know as

00:14:40,630 --> 00:14:44,290
far as I'm concerned I have all the file

00:14:42,070 --> 00:14:47,290
system code hooked up it's just it's not

00:14:44,290 --> 00:14:49,690
talking to any real devices yet but it's

00:14:47,290 --> 00:14:51,250
something that I've been told is going

00:14:49,690 --> 00:14:54,520
to be a really big deal for solid state

00:14:51,250 --> 00:14:57,670
disks and for thin provisioning so that

00:14:54,520 --> 00:15:00,780
we have that in there already another

00:14:57,670 --> 00:15:03,210
thing that we've added is check sums in

00:15:00,780 --> 00:15:05,350
certain bits of the metadata

00:15:03,210 --> 00:15:07,900
specifically the journal and the block

00:15:05,350 --> 00:15:11,410
group descriptors and that's all that's

00:15:07,900 --> 00:15:13,930
allowed us to reliably put in the block

00:15:11,410 --> 00:15:16,810
group descriptors what part of the an

00:15:13,930 --> 00:15:18,490
inode table is actually in use and what

00:15:16,810 --> 00:15:20,980
part of the inode table is not and that

00:15:18,490 --> 00:15:23,350
that's allowed us to speed up fsck so

00:15:20,980 --> 00:15:25,840
there have been a lot of little tiny

00:15:23,350 --> 00:15:27,880
improvements that we sort of made while

00:15:25,840 --> 00:15:30,700
the patient was opened up for surgery as

00:15:27,880 --> 00:15:32,630
it were but probably the biggest one

00:15:30,700 --> 00:15:36,350
as far as ext4

00:15:32,630 --> 00:15:39,220
concerned is extense and then related to

00:15:36,350 --> 00:15:42,470
extents the block allocators so let's

00:15:39,220 --> 00:15:46,220
dive into that how many of you are

00:15:42,470 --> 00:15:49,580
familiar with the indirect block map

00:15:46,220 --> 00:15:51,440
system that ext2 ext3 use how many

00:15:49,580 --> 00:15:54,680
people are familiar okay some people are

00:15:51,440 --> 00:15:58,430
something some people might not be so

00:15:54,680 --> 00:16:03,680
quick review inside the inode through

00:15:58,430 --> 00:16:07,190
ext2 and ext3 there is room for 15 block

00:16:03,680 --> 00:16:10,640
pointers 15 32-bit block numbers the

00:16:07,190 --> 00:16:15,080
first 12 0 through 11 in the IEEE data

00:16:10,640 --> 00:16:18,770
array are used to map direct blocks and

00:16:15,080 --> 00:16:21,320
so if your file is less than 12 less

00:16:18,770 --> 00:16:23,390
than or equal to 12 blocks long if

00:16:21,320 --> 00:16:27,950
you're using a 4k file system for K

00:16:23,390 --> 00:16:30,590
block size file system that's 48 K the

00:16:27,950 --> 00:16:33,680
location of all of those blocks can be

00:16:30,590 --> 00:16:35,570
stored in the inode and we and you don't

00:16:33,680 --> 00:16:37,970
have to do do anything else it's all

00:16:35,570 --> 00:16:41,600
there and it's just mapped so in this

00:16:37,970 --> 00:16:45,290
case here in this example the inode the

00:16:41,600 --> 00:16:50,930
first 12 blocks are located at block

00:16:45,290 --> 00:16:53,270
block numbers 200 through 211 now if the

00:16:50,930 --> 00:16:56,180
file is any bigger than that there's no

00:16:53,270 --> 00:17:00,500
more room for direct blocks inside the

00:16:56,180 --> 00:17:02,810
inode so we allocate in the second

00:17:00,500 --> 00:17:06,199
column to the right on the top that gray

00:17:02,810 --> 00:17:09,560
box an indirect block and we put a

00:17:06,199 --> 00:17:11,750
pointer which is a slot number 12 and

00:17:09,560 --> 00:17:15,410
the I data that points to the indirect

00:17:11,750 --> 00:17:18,310
block and there we have room again if

00:17:15,410 --> 00:17:21,680
we're using a fork a block file system

00:17:18,310 --> 00:17:23,180
1024 block numbers that can go in an

00:17:21,680 --> 00:17:25,699
indirect lock and that will give you a

00:17:23,180 --> 00:17:29,740
range of locks now if it turns out that

00:17:25,699 --> 00:17:32,390
that's not enough room we can insert an

00:17:29,740 --> 00:17:36,200
indirect block and that's the light blue

00:17:32,390 --> 00:17:38,930
and so we have a pointer in slot 13 to a

00:17:36,200 --> 00:17:44,120
double in direct block and each double

00:17:38,930 --> 00:17:45,120
indirect lock will point to 256 indirect

00:17:44,120 --> 00:17:49,080
blocks

00:17:45,120 --> 00:17:51,600
which then contain 256 block pointers to

00:17:49,080 --> 00:17:53,730
the file and finally if that's not

00:17:51,600 --> 00:17:55,559
enough we have room for a triple

00:17:53,730 --> 00:17:59,550
indirect block in a triple and direct

00:17:55,559 --> 00:18:03,809
lock has 256 slots each one points at a

00:17:59,550 --> 00:18:07,460
double indirect block 256 slots each of

00:18:03,809 --> 00:18:10,260
those blocks slots points at 256

00:18:07,460 --> 00:18:16,170
indirect blocks which then goes to a

00:18:10,260 --> 00:18:19,440
file and 256 x 256 x 256 times a 4k

00:18:16,170 --> 00:18:25,020
block size is a really big number and so

00:18:19,440 --> 00:18:27,330
that's how indirect blocks work now it

00:18:25,020 --> 00:18:30,809
turns out this system is incredibly

00:18:27,330 --> 00:18:33,510
inefficient for really large files right

00:18:30,809 --> 00:18:36,690
if you're using a ax III and you ever

00:18:33,510 --> 00:18:38,250
have to delete a huge iso image and it

00:18:36,690 --> 00:18:40,830
really doesn't matter whether or not is

00:18:38,250 --> 00:18:43,770
the CD or a DVD iso image the DVD iso

00:18:40,830 --> 00:18:46,350
image will take even longer it will take

00:18:43,770 --> 00:18:48,330
a long time to delete and the reason

00:18:46,350 --> 00:18:49,800
that it takes a long time to delete is

00:18:48,330 --> 00:18:54,420
that it has to read all of those

00:18:49,800 --> 00:18:56,940
indirect blocks and then free the block

00:18:54,420 --> 00:18:58,440
pointers in the indirect blocks and the

00:18:56,940 --> 00:19:00,360
double indirect block and the triple

00:18:58,440 --> 00:19:03,960
indirect blocks and that takes a very

00:19:00,360 --> 00:19:06,270
very long time and it's especially

00:19:03,960 --> 00:19:08,670
inefficient when you consider that the

00:19:06,270 --> 00:19:11,540
file system is actually going to fairly

00:19:08,670 --> 00:19:14,370
great lengths to keep files contiguous

00:19:11,540 --> 00:19:18,050
so most of the time what you actually

00:19:14,370 --> 00:19:20,330
see in these indirect blocks are

00:19:18,050 --> 00:19:26,880
increasing sequences of block numbers

00:19:20,330 --> 00:19:28,740
200 201 202 203 204 205 and that's not a

00:19:26,880 --> 00:19:30,840
very efficient way of storing that type

00:19:28,740 --> 00:19:33,809
of information right a much more

00:19:30,840 --> 00:19:36,270
efficient way is to use something called

00:19:33,809 --> 00:19:38,700
an extent and an extent is just simply a

00:19:36,270 --> 00:19:42,720
way of saying we're gonna start at

00:19:38,700 --> 00:19:45,390
logical blocks 0 and logical blocks 0 is

00:19:42,720 --> 00:19:48,450
going to be located at physical block

00:19:45,390 --> 00:19:51,690
200 and that's going to continue for a

00:19:48,450 --> 00:19:54,480
thousand blocks so if we have a thousand

00:19:51,690 --> 00:19:57,570
blocks free on disk and we can allocate

00:19:54,480 --> 00:19:58,590
it contiguously to the file then I only

00:19:57,570 --> 00:20:00,450
need

00:19:58,590 --> 00:20:04,350
very small amount of room room to

00:20:00,450 --> 00:20:07,830
support three integers to encode what

00:20:04,350 --> 00:20:10,620
previously would have taken four

00:20:07,830 --> 00:20:12,450
thousand bytes to store right thousand

00:20:10,620 --> 00:20:15,539
entries one for each block and instead

00:20:12,450 --> 00:20:17,700
we just simply stay that starting at

00:20:15,539 --> 00:20:19,559
block 0 and going on for a thousand

00:20:17,700 --> 00:20:24,779
blocks we're gonna use the range

00:20:19,559 --> 00:20:27,380
starting at block 200 so this is what

00:20:24,779 --> 00:20:30,270
the on disk extents format looks like

00:20:27,380 --> 00:20:33,870
this code the extents work was actually

00:20:30,270 --> 00:20:36,630
contributed by cluster FS and andreas

00:20:33,870 --> 00:20:40,590
Stihl Geron and company and they

00:20:36,630 --> 00:20:43,440
actually used ext3 as the back-end

00:20:40,590 --> 00:20:46,260
storage for their cluster filesystem

00:20:43,440 --> 00:20:47,970
which they called lustre and they needed

00:20:46,260 --> 00:20:51,570
to get better performance out of it and

00:20:47,970 --> 00:20:54,390
so they actually enhanced their version

00:20:51,570 --> 00:20:57,029
of ext3 to have extents and then they

00:20:54,390 --> 00:21:01,529
contributed that code back to us many

00:20:57,029 --> 00:21:04,620
many thanks to to lustre and so we sort

00:21:01,529 --> 00:21:07,070
of stuck with this particular format and

00:21:04,620 --> 00:21:13,020
what this format effectively gives us is

00:21:07,070 --> 00:21:16,740
48 bits of logical block numbers and 32

00:21:13,020 --> 00:21:19,140
bits of sorry 32 bits of logical block

00:21:16,740 --> 00:21:22,740
numbers and 48 bits of physical block

00:21:19,140 --> 00:21:25,320
numbers and a lot of people ask us why

00:21:22,740 --> 00:21:27,870
didn't you go to 64 and the answer was

00:21:25,320 --> 00:21:29,880
well this is what lustre was using them

00:21:27,870 --> 00:21:32,520
we wanted to stay compatible with lustre

00:21:29,880 --> 00:21:35,549
because after all they contributed a lot

00:21:32,520 --> 00:21:38,539
of really good code to us there was

00:21:35,549 --> 00:21:41,309
thinking that at some point we would add

00:21:38,539 --> 00:21:44,070
support for an alternate data structure

00:21:41,309 --> 00:21:46,970
that would in fact give us 64 bit

00:21:44,070 --> 00:21:50,419
logical 64 bit physical block numbers

00:21:46,970 --> 00:21:53,700
and basically instead of a 12 byte

00:21:50,419 --> 00:21:55,679
structure would probably take you know a

00:21:53,700 --> 00:21:58,350
bit more than that it'd probably be a 16

00:21:55,679 --> 00:22:00,929
16 byte structure and we have a version

00:21:58,350 --> 00:22:02,940
field in the extent header where we

00:22:00,929 --> 00:22:05,190
could actually indicate this is a new

00:22:02,940 --> 00:22:06,960
version of the extent header and we may

00:22:05,190 --> 00:22:10,200
very well do that at some point in the

00:22:06,960 --> 00:22:12,030
future it turns out that 48 bits is a

00:22:10,200 --> 00:22:12,390
very large number you're ready you're

00:22:12,030 --> 00:22:16,800
ready

00:22:12,390 --> 00:22:20,670
up to an exabyte with with 48 bits of

00:22:16,800 --> 00:22:22,620
physical block numbering and we wanted

00:22:20,670 --> 00:22:24,570
to get ext4 out there sooner rather than

00:22:22,620 --> 00:22:26,700
later so we've sort of stuck with the

00:22:24,570 --> 00:22:30,630
very simple maybe at some point in the

00:22:26,700 --> 00:22:34,200
future we'll expand it but for many many

00:22:30,630 --> 00:22:35,820
users you know an exabyte is more than

00:22:34,200 --> 00:22:40,500
enough space for what they would

00:22:35,820 --> 00:22:42,740
actually want to use it for so this is

00:22:40,500 --> 00:22:47,880
what the extent map actually looks like

00:22:42,740 --> 00:22:50,520
in the eye data field we we store a

00:22:47,880 --> 00:22:54,200
small header structure which indicates

00:22:50,520 --> 00:22:57,060
how deep the tree is what version of the

00:22:54,200 --> 00:23:02,670
extend structure we have and then

00:22:57,060 --> 00:23:05,280
pointers to the location on disk now we

00:23:02,670 --> 00:23:08,300
can store up to three of those extents

00:23:05,280 --> 00:23:13,020
structures in the inode body directly

00:23:08,300 --> 00:23:16,020
and as it turns out and I'll show you

00:23:13,020 --> 00:23:18,840
some numbers in a moment the vast

00:23:16,020 --> 00:23:22,230
majority of your files on a fairly

00:23:18,840 --> 00:23:27,270
standard file system will in fact fit in

00:23:22,230 --> 00:23:30,210
under three extents in fact on the file

00:23:27,270 --> 00:23:34,350
system that got stolen on Friday I'd

00:23:30,210 --> 00:23:36,350
been running XD for full since July and

00:23:34,350 --> 00:23:38,940
I think I had you know done a couple of

00:23:36,350 --> 00:23:40,800
full backup and restore once or twice

00:23:38,940 --> 00:23:42,720
during that period but it been my

00:23:40,800 --> 00:23:48,390
primary file system I'd been using it

00:23:42,720 --> 00:23:51,120
for quite a while 128 128 gigs

00:23:48,390 --> 00:23:55,500
it was my you know primary laptop it had

00:23:51,120 --> 00:24:00,870
to bun to on it one - Hardy on it and I

00:23:55,500 --> 00:24:06,030
had all of one file I'm sorry I'm that

00:24:00,870 --> 00:24:09,060
that's not right I had all of I had you

00:24:06,030 --> 00:24:12,810
know several several hundred thousand

00:24:09,060 --> 00:24:16,290
files on it and I had maybe 700 or 800

00:24:12,810 --> 00:24:18,210
files that spilled over to a single

00:24:16,290 --> 00:24:22,030
extent block

00:24:18,210 --> 00:24:24,520
as an a/b tree that had a single leaf

00:24:22,030 --> 00:24:28,480
block and that leaf block had room for

00:24:24,520 --> 00:24:32,110
129 extents and then I had a single file

00:24:28,480 --> 00:24:36,280
that had a extent tree that was too deep

00:24:32,110 --> 00:24:40,930
that had one index node and then a

00:24:36,280 --> 00:24:43,770
number of of leaf nodes but the vast

00:24:40,930 --> 00:24:46,630
majority of the files 99% of the files

00:24:43,770 --> 00:24:51,610
all of the extents lived inside the

00:24:46,630 --> 00:24:53,920
inode because they were under they were

00:24:51,610 --> 00:24:55,990
under three extents and in fact

00:24:53,920 --> 00:24:58,660
something like 95 percent of them were

00:24:55,990 --> 00:25:01,750
encoded in a single extent and that that

00:24:58,660 --> 00:25:05,860
was because of changes in the block

00:25:01,750 --> 00:25:09,280
allocator so for the more complicated

00:25:05,860 --> 00:25:11,590
files and as I mentioned on my file

00:25:09,280 --> 00:25:13,840
system where I had been

00:25:11,590 --> 00:25:15,790
you know torturing torturing the file

00:25:13,840 --> 00:25:20,350
system fairly badly I was using it for

00:25:15,790 --> 00:25:22,990
normal use I had exactly one file that

00:25:20,350 --> 00:25:26,230
looked like this where I had the inode

00:25:22,990 --> 00:25:27,880
table an index node that index node

00:25:26,230 --> 00:25:31,630
could store up to a hundred and

00:25:27,880 --> 00:25:33,340
twenty-nine leaf nodes and each leaf

00:25:31,630 --> 00:25:37,720
node could store up to a hundred and

00:25:33,340 --> 00:25:42,400
twenty-nine contiguous extents and that

00:25:37,720 --> 00:25:44,200
one file was in fact a sparse ext3

00:25:42,400 --> 00:25:46,450
extent images I had been using for

00:25:44,200 --> 00:25:49,300
testing you know the short version is I

00:25:46,450 --> 00:25:50,590
had to deliberately create files that

00:25:49,300 --> 00:25:54,310
were deep enough that I could actually

00:25:50,590 --> 00:25:56,710
exercise the extend tree code because in

00:25:54,310 --> 00:26:00,610
theory this tree can you know grow to

00:25:56,710 --> 00:26:02,470
two three four levels deep but in fact

00:26:00,610 --> 00:26:05,350
you have to really torture the file

00:26:02,470 --> 00:26:08,320
system to get it to generate that most

00:26:05,350 --> 00:26:11,050
of the time you either have a single

00:26:08,320 --> 00:26:14,050
leaf node pointed from the body the

00:26:11,050 --> 00:26:17,350
inode table and the vast majority of the

00:26:14,050 --> 00:26:20,140
time you just simply have one two maybe

00:26:17,350 --> 00:26:22,030
three extents in the inode table because

00:26:20,140 --> 00:26:24,710
the file is that basically contiguous on

00:26:22,030 --> 00:26:27,259
disk so

00:26:24,710 --> 00:26:29,419
we can handle sparse files and we can

00:26:27,259 --> 00:26:32,570
handle files where the file system gets

00:26:29,419 --> 00:26:36,559
very very badly fragmented in practice

00:26:32,570 --> 00:26:38,499
I've been noticing that eesti fours anti

00:26:36,559 --> 00:26:41,809
fragmentation algorithms are good enough

00:26:38,499 --> 00:26:44,659
that at least for you know my general

00:26:41,809 --> 00:26:46,999
workload it's fairly rare now I'm sure

00:26:44,659 --> 00:26:49,700
someone out here will have a workload

00:26:46,999 --> 00:26:51,740
that will prove me wrong and that's okay

00:26:49,700 --> 00:26:53,869
we have an online Defragmenter that

00:26:51,740 --> 00:26:58,759
we're hoping to get done but that's not

00:26:53,869 --> 00:27:00,799
that's not in mainline yet so part of

00:26:58,759 --> 00:27:03,529
the reason why the code is so

00:27:00,799 --> 00:27:05,869
fragmentation resistant is because of

00:27:03,529 --> 00:27:08,690
changes to the block allocator and this

00:27:05,869 --> 00:27:12,919
is also code that was contributed by

00:27:08,690 --> 00:27:14,980
lustre FS and andreas Dildar and the

00:27:12,919 --> 00:27:17,299
reason why they needed it is because

00:27:14,980 --> 00:27:20,029
extents work best if the files are

00:27:17,299 --> 00:27:22,669
contiguous in fact if your file system

00:27:20,029 --> 00:27:24,710
is really badly fragmented so that you

00:27:22,669 --> 00:27:26,330
have you know a free block here and a

00:27:24,710 --> 00:27:30,919
free block there and a free block here

00:27:26,330 --> 00:27:33,499
it takes 12 bytes to encode an extent so

00:27:30,919 --> 00:27:36,139
if you have lots of singleton free

00:27:33,499 --> 00:27:37,669
blocks on the file system extents can

00:27:36,139 --> 00:27:40,850
actually be a less efficient way of

00:27:37,669 --> 00:27:43,100
encoding the file map data and then just

00:27:40,850 --> 00:27:45,710
simply using a normal indirect block now

00:27:43,100 --> 00:27:47,629
in practice that doesn't happen but one

00:27:45,710 --> 00:27:50,029
of the reasons why is because of the

00:27:47,629 --> 00:27:52,820
multi block allocator and the multi

00:27:50,029 --> 00:27:55,700
block allocator which again came from

00:27:52,820 --> 00:27:58,249
lustre gave us two things number one it

00:27:55,700 --> 00:28:01,220
gave us delayed allocation which means

00:27:58,249 --> 00:28:04,730
we don't actually allocate files until

00:28:01,220 --> 00:28:07,850
the very last minute when either the

00:28:04,730 --> 00:28:09,710
application has explicitly requested the

00:28:07,850 --> 00:28:13,820
data to be flushed out to disk with an F

00:28:09,710 --> 00:28:15,499
sinc call or dirty the page dirty

00:28:13,820 --> 00:28:19,690
cleaner has decided that it's time to

00:28:15,499 --> 00:28:22,639
actually push blocks out to disk and

00:28:19,690 --> 00:28:26,119
then the other part is the multi block

00:28:22,639 --> 00:28:29,210
allocator which when it allocates blocks

00:28:26,119 --> 00:28:31,029
it allocates blocks based on how much it

00:28:29,210 --> 00:28:34,460
actually how much data it needs to write

00:28:31,029 --> 00:28:36,679
the previous block allocator allocated a

00:28:34,460 --> 00:28:38,269
single block at a time and about the

00:28:36,679 --> 00:28:41,090
only thing at new

00:28:38,269 --> 00:28:43,460
the previous flock was located at block

00:28:41,090 --> 00:28:45,259
N and so the first block II would

00:28:43,460 --> 00:28:47,570
actually try to find would be block n

00:28:45,259 --> 00:28:49,370
plus one and if that wasn't there it

00:28:47,570 --> 00:28:52,879
would try block n plus two and and so

00:28:49,370 --> 00:28:55,549
was actually fairly stupid the multi

00:28:52,879 --> 00:28:58,490
block allocator will know that we're

00:28:55,549 --> 00:29:01,250
going to be allocating a dozen blocks or

00:28:58,490 --> 00:29:04,909
two hundred blocks and it will actually

00:29:01,250 --> 00:29:06,200
search for enough free space for the

00:29:04,909 --> 00:29:08,419
requested amount of space that we

00:29:06,200 --> 00:29:11,269
actually need to allocate and that's one

00:29:08,419 --> 00:29:13,370
of the reasons why most of the files on

00:29:11,269 --> 00:29:18,259
disk actually turn out to be a

00:29:13,370 --> 00:29:21,250
contiguous on disk and this is by the

00:29:18,259 --> 00:29:24,470
way responsible for most of a XD force

00:29:21,250 --> 00:29:26,690
performance improvements now there is

00:29:24,470 --> 00:29:32,419
one little tiny gotcha with the delayed

00:29:26,690 --> 00:29:34,909
allocation code and that is that what

00:29:32,419 --> 00:29:40,000
many application writers had been used

00:29:34,909 --> 00:29:43,100
to was EXT threes ordered mode semantics

00:29:40,000 --> 00:29:45,980
and ext3 zorder mode semantics

00:29:43,100 --> 00:29:49,100
effectively said before we do a journal

00:29:45,980 --> 00:29:52,370
commit we will make sure that any blocks

00:29:49,100 --> 00:29:54,710
that have been allocated on disk will in

00:29:52,370 --> 00:29:57,590
fact be written to disk before we slam

00:29:54,710 --> 00:30:00,470
the inode on to disk and do a commit and

00:29:57,590 --> 00:30:03,740
this guarantees that you never get stale

00:30:00,470 --> 00:30:07,129
data right because stale data could be a

00:30:03,740 --> 00:30:08,840
security problem because it's previously

00:30:07,129 --> 00:30:11,179
written data that possibly belonged to

00:30:08,840 --> 00:30:13,789
another user and you might be exposing

00:30:11,179 --> 00:30:16,250
that if the system crashes if the inode

00:30:13,789 --> 00:30:19,639
has been written today if the inode has

00:30:16,250 --> 00:30:22,490
been written to disk but the data had

00:30:19,639 --> 00:30:24,830
not been written out to disk and so the

00:30:22,490 --> 00:30:29,480
default mode that most people used for

00:30:24,830 --> 00:30:32,269
ext3 was force a journal commit every

00:30:29,480 --> 00:30:35,059
five seconds and use order mode

00:30:32,269 --> 00:30:39,799
semantics now in practice what this

00:30:35,059 --> 00:30:43,039
meant was if you wrote a file and closed

00:30:39,799 --> 00:30:47,029
it within five seconds it was guaranteed

00:30:43,039 --> 00:30:50,110
to be on disk and a lot of people just

00:30:47,029 --> 00:30:53,500
sort of assumed that that was normal

00:30:50,110 --> 00:30:56,360
file systems that do delayed allocation

00:30:53,500 --> 00:30:57,980
will not actually do this they will not

00:30:56,360 --> 00:31:00,110
actually force the data out to disk

00:30:57,980 --> 00:31:03,559
because we haven't even allocated the

00:31:00,110 --> 00:31:05,779
data on disk and so what ext4 would do

00:31:03,559 --> 00:31:08,840
under these conditions is you might

00:31:05,779 --> 00:31:10,820
write a dot file and you know some of

00:31:08,840 --> 00:31:14,059
these application programmers would

00:31:10,820 --> 00:31:17,630
rewrite a dot file without leaving a

00:31:14,059 --> 00:31:21,529
backup so they would truncate rewrite

00:31:17,630 --> 00:31:24,799
the data and close it and if the file

00:31:21,529 --> 00:31:26,690
had not actually been allocated then

00:31:24,799 --> 00:31:29,659
there would be no data actually push out

00:31:26,690 --> 00:31:32,299
to disk and if the data had not been

00:31:29,659 --> 00:31:34,700
pushed out to disk we now have to wait

00:31:32,299 --> 00:31:37,640
for the page cleaner to decide that it's

00:31:34,700 --> 00:31:41,360
time to write dirty data back to disk

00:31:37,640 --> 00:31:44,120
and the default for that is 30 seconds

00:31:41,360 --> 00:31:45,919
and the page cleaner doesn't actually

00:31:44,120 --> 00:31:47,779
write out all the dirty disk it will

00:31:45,919 --> 00:31:49,909
actually stage it out so that data will

00:31:47,779 --> 00:31:52,490
start getting written out to disk after

00:31:49,909 --> 00:31:55,070
30 seconds of gone by and if you've

00:31:52,490 --> 00:31:56,960
dirtied a lot of data blocks it might

00:31:55,070 --> 00:31:58,580
take another 30 seconds before

00:31:56,960 --> 00:32:00,740
everything has been written out because

00:31:58,580 --> 00:32:02,419
it you know doesn't want to overload the

00:32:00,740 --> 00:32:05,149
system so it actually does it in little

00:32:02,419 --> 00:32:10,130
tiny chunks spaced out over five second

00:32:05,149 --> 00:32:13,909
intervals if you turn on laptop mode to

00:32:10,130 --> 00:32:17,929
save your battery that 30 seconds can

00:32:13,909 --> 00:32:20,870
get expanded to like two minutes and now

00:32:17,929 --> 00:32:23,600
what you end up happening is it can be a

00:32:20,870 --> 00:32:25,990
good two to five minutes before data

00:32:23,600 --> 00:32:28,610
that had been written to disk is

00:32:25,990 --> 00:32:31,159
actually sorry data that had actually

00:32:28,610 --> 00:32:32,659
been written by an application might

00:32:31,159 --> 00:32:34,970
take two to five minutes before it

00:32:32,659 --> 00:32:37,549
actually is written on to disk so if

00:32:34,970 --> 00:32:40,940
your system crashes you can actually

00:32:37,549 --> 00:32:44,179
lose more data now this is in fact all

00:32:40,940 --> 00:32:47,179
legit right if you look at the POSIX

00:32:44,179 --> 00:32:51,500
specification it essentially says unless

00:32:47,179 --> 00:32:54,320
you call F sync all bets are off

00:32:51,500 --> 00:32:57,270
and it was just simply that many

00:32:54,320 --> 00:33:01,500
application programmers were used to

00:32:57,270 --> 00:33:06,780
the behavior of ext3 and not bothering

00:33:01,500 --> 00:33:09,570
to call fsync now I say this worried a

00:33:06,780 --> 00:33:13,560
little bit that everyone will now use f

00:33:09,570 --> 00:33:16,500
sinc a lot and the reason is because in

00:33:13,560 --> 00:33:20,820
recent years I have noticed a disturbing

00:33:16,500 --> 00:33:23,310
tendency by application writers some of

00:33:20,820 --> 00:33:26,310
you may be in this room to generate

00:33:23,310 --> 00:33:28,980
hundreds and hundreds of dot files like

00:33:26,310 --> 00:33:31,230
if I look under dot kinome and not KDE I

00:33:28,980 --> 00:33:33,240
see hundreds and hundreds of individual

00:33:31,230 --> 00:33:35,700
dot files that you know each contain

00:33:33,240 --> 00:33:37,470
huge amounts of data actually they don't

00:33:35,700 --> 00:33:39,630
contain huge amounts of data that's the

00:33:37,470 --> 00:33:41,370
problem they each contain like three or

00:33:39,630 --> 00:33:43,620
four bytes of data but there are

00:33:41,370 --> 00:33:45,870
hundreds and hundreds of files and if

00:33:43,620 --> 00:33:48,450
you call F sync on every single one you

00:33:45,870 --> 00:33:51,000
will really you know pound your system

00:33:48,450 --> 00:33:53,370
with a hammer pretty badly because it's

00:33:51,000 --> 00:33:54,900
going to force a lot of data to disk and

00:33:53,370 --> 00:33:58,640
you'll be forcing a commit for every

00:33:54,900 --> 00:34:01,350
single one of these F syncs you know

00:33:58,640 --> 00:34:03,090
probably the right answer is to use F

00:34:01,350 --> 00:34:05,670
data sync that's not going to be quite

00:34:03,090 --> 00:34:07,890
so painful and will actually have most

00:34:05,670 --> 00:34:10,200
of the semantics so you know if you guys

00:34:07,890 --> 00:34:12,630
are gonna stick with using lots of these

00:34:10,200 --> 00:34:15,270
little individual dot files each ones

00:34:12,630 --> 00:34:18,630
that contain a few bytes yeah you

00:34:15,270 --> 00:34:21,150
probably want to use F data sync or you

00:34:18,630 --> 00:34:23,670
might want to consider using SQL Lite or

00:34:21,150 --> 00:34:25,620
some kind of proper database because

00:34:23,670 --> 00:34:28,170
it's very clear what's going on here is

00:34:25,620 --> 00:34:30,330
you know people decided that you know

00:34:28,170 --> 00:34:33,210
the Windows registry was evil so will be

00:34:30,330 --> 00:34:34,950
the anti windows and instead you now

00:34:33,210 --> 00:34:37,440
have hundreds and hundreds of these

00:34:34,950 --> 00:34:40,500
little tiny files which you know isn't

00:34:37,440 --> 00:34:42,810
such a bright idea either but you know

00:34:40,500 --> 00:34:44,730
be that as it may I know I cannot

00:34:42,810 --> 00:34:48,240
influence what application programmers

00:34:44,730 --> 00:34:49,980
choose to do all us file system authors

00:34:48,240 --> 00:34:51,540
can really do is sort of adapt to what

00:34:49,980 --> 00:34:53,850
the application

00:34:51,540 --> 00:34:56,730
you know developer community actually

00:34:53,850 --> 00:34:59,580
throws at us so we may end up actually

00:34:56,730 --> 00:35:04,440
trying to store data into the IEEE data

00:34:59,580 --> 00:35:06,590
array and the reason why we did in lo

00:35:04,440 --> 00:35:10,170
these many years ago was it used to be

00:35:06,590 --> 00:35:11,079
nobody was insane enough to use lots and

00:35:10,170 --> 00:35:12,519
lots of little

00:35:11,079 --> 00:35:13,779
tiny files I mean I actually at one

00:35:12,519 --> 00:35:15,819
point took a look in and said there was

00:35:13,779 --> 00:35:17,829
actually very few of them so we never

00:35:15,819 --> 00:35:20,769
bothered to store data in the IEEE data

00:35:17,829 --> 00:35:23,079
array but these days it looks like there

00:35:20,769 --> 00:35:25,779
are a lot of app writers that have lots

00:35:23,079 --> 00:35:27,690
of files that are under 60 bytes and so

00:35:25,779 --> 00:35:32,259
maybe we have to revisit that decision

00:35:27,690 --> 00:35:34,829
all of that being said delayed

00:35:32,259 --> 00:35:37,029
allocations just sort of exposed that

00:35:34,829 --> 00:35:40,509
because I've gotten one or two bug

00:35:37,029 --> 00:35:45,969
reports of the form you know I was using

00:35:40,509 --> 00:35:48,609
ext4 crappy and Vidya driver crashed my

00:35:45,969 --> 00:35:52,059
system and I had several hundred zero

00:35:48,609 --> 00:35:54,160
link files in dhaka gnome or KDE I think

00:35:52,059 --> 00:35:57,279
I got one of each so this is not a

00:35:54,160 --> 00:36:00,309
genome versus KDE thing both desktops

00:35:57,279 --> 00:36:01,989
seem to be doing that and it's like you

00:36:00,309 --> 00:36:03,339
know my first thing was oh my god how

00:36:01,989 --> 00:36:06,069
come they have so many of these little

00:36:03,339 --> 00:36:08,019
tiny files and why are they rewriting

00:36:06,069 --> 00:36:10,839
them all the time because that's got to

00:36:08,019 --> 00:36:12,579
be a performance hit right there and I'm

00:36:10,839 --> 00:36:14,410
not sure I want to know the answer but

00:36:12,579 --> 00:36:16,359
if someone from the government KDE

00:36:14,410 --> 00:36:18,789
environment you know communities want to

00:36:16,359 --> 00:36:21,009
tell me why you're apparently constantly

00:36:18,789 --> 00:36:23,949
rewriting hundreds of these files in you

00:36:21,009 --> 00:36:26,289
know the user's home directory you know

00:36:23,949 --> 00:36:29,799
now you know get myself a good stiff

00:36:26,289 --> 00:36:31,539
drink and then you can tell me but you

00:36:29,799 --> 00:36:33,910
know it's one of the things we're

00:36:31,539 --> 00:36:36,789
looking at one things that we may end up

00:36:33,910 --> 00:36:39,339
doing is have some heuristic where if

00:36:36,789 --> 00:36:42,069
the file is small and we noticed that it

00:36:39,339 --> 00:36:46,180
was in a truncate or remove we'll

00:36:42,069 --> 00:36:48,819
actually immediately map the files on

00:36:46,180 --> 00:36:51,549
close which is less heavyweight than

00:36:48,819 --> 00:36:53,380
actually calling F sank eric Sandeen

00:36:51,549 --> 00:36:56,349
tells me X FS had to do something very

00:36:53,380 --> 00:36:59,849
similar x FS apparently has this Cluj

00:36:56,349 --> 00:37:03,190
where if a file has ever been truncated

00:36:59,849 --> 00:37:05,229
it implies an F sink as soon as you try

00:37:03,190 --> 00:37:07,900
to close it and that's because there are

00:37:05,229 --> 00:37:10,930
so many application writers that got

00:37:07,900 --> 00:37:12,999
kind of lazy about assuming that they

00:37:10,930 --> 00:37:14,799
could just simply do that and then X F s

00:37:12,999 --> 00:37:19,029
is delayed allocation hit them so

00:37:14,799 --> 00:37:21,640
apparently this is not a new problem so

00:37:19,029 --> 00:37:24,460
that's one another interesting feature

00:37:21,640 --> 00:37:27,369
that we have is something called

00:37:24,460 --> 00:37:30,190
system pre allocation this allows blocks

00:37:27,369 --> 00:37:33,220
to be assigned to files without having

00:37:30,190 --> 00:37:35,589
to initialize them first the original

00:37:33,220 --> 00:37:38,619
use of this was for databases and

00:37:35,589 --> 00:37:40,599
streaming video files where if you know

00:37:38,619 --> 00:37:43,270
that you're going to eventually fill a

00:37:40,599 --> 00:37:45,730
gigabyte on disk because you're going to

00:37:43,270 --> 00:37:47,349
be recording an hour of video and an

00:37:45,730 --> 00:37:50,530
hour of video compressed is about a

00:37:47,349 --> 00:37:54,520
gigabyte you can tell the system please

00:37:50,530 --> 00:37:56,320
pre-allocate a gigabyte on disk and then

00:37:54,520 --> 00:37:58,510
the filesystem can allocate that space

00:37:56,320 --> 00:38:01,770
contiguously because you know exactly

00:37:58,510 --> 00:38:06,430
how big it is this can also be useful

00:38:01,770 --> 00:38:09,010
for package packaging packaging systems

00:38:06,430 --> 00:38:11,560
like rpm and D package if you know how

00:38:09,010 --> 00:38:13,510
big the file is the file system will be

00:38:11,560 --> 00:38:16,660
able to do a better job if you tell it

00:38:13,510 --> 00:38:18,430
please pre-allocate me the space because

00:38:16,660 --> 00:38:21,099
then it can then pre-allocate exactly

00:38:18,430 --> 00:38:22,990
how much space it needs and you can you

00:38:21,099 --> 00:38:27,099
know reduce fragmentation by a little

00:38:22,990 --> 00:38:30,520
bit if you can actually do that another

00:38:27,099 --> 00:38:33,550
interesting use of this is for files

00:38:30,520 --> 00:38:35,710
that are grown via append so if you

00:38:33,550 --> 00:38:38,740
append you know a log file is constantly

00:38:35,710 --> 00:38:41,410
being appended to a UNIX male spool file

00:38:38,740 --> 00:38:42,820
is constantly being appended to and if

00:38:41,410 --> 00:38:44,830
you know that that's happening one

00:38:42,820 --> 00:38:46,630
things you can do is just simply pre

00:38:44,830 --> 00:38:49,240
allocate space if you know roughly how

00:38:46,630 --> 00:38:51,220
big the log file is you can pre allocate

00:38:49,240 --> 00:38:53,950
the space and then the log file will be

00:38:51,220 --> 00:38:58,060
contiguous on disk because you know

00:38:53,950 --> 00:39:01,119
you've pre-allocated it now you can

00:38:58,060 --> 00:39:03,520
access this via the G Lib C POSIX F

00:39:01,119 --> 00:39:06,970
allocate call but the problem with the

00:39:03,520 --> 00:39:10,000
POSIX F allocate call is twofold number

00:39:06,970 --> 00:39:12,490
one if you happen to be on a file system

00:39:10,000 --> 00:39:14,140
that doesn't support pre-allocate it

00:39:12,490 --> 00:39:18,369
will do it the old-fashioned way and

00:39:14,140 --> 00:39:20,680
just simply write blocks of zeros which

00:39:18,369 --> 00:39:23,680
is very very slow and so there are some

00:39:20,680 --> 00:39:26,109
cases where if F allocate doesn't exist

00:39:23,680 --> 00:39:29,230
you would rather the call do nothing and

00:39:26,109 --> 00:39:32,770
the G Lib C POSIX F allocate doesn't do

00:39:29,230 --> 00:39:35,080
that the other thing about POSIX F

00:39:32,770 --> 00:39:38,200
allocate is it always changes the eye

00:39:35,080 --> 00:39:41,020
size field and so therefore if you

00:39:38,200 --> 00:39:42,880
look at the file using LS dash L it will

00:39:41,020 --> 00:39:44,890
actually show that the file is a

00:39:42,880 --> 00:39:48,970
gigabyte after you've pre-allocated a

00:39:44,890 --> 00:39:52,660
gigabyte on space gigabyte on disk if

00:39:48,970 --> 00:39:54,910
you use the raw Linux system call you

00:39:52,660 --> 00:39:57,820
can get a hard failure if the filesystem

00:39:54,910 --> 00:40:00,910
doesn't actually support F allocate more

00:39:57,820 --> 00:40:04,480
importantly you can let eyes--eyes

00:40:00,910 --> 00:40:06,190
remain at the original size and now what

00:40:04,480 --> 00:40:08,770
you've done is you've pre-allocated the

00:40:06,190 --> 00:40:10,540
space on disk but i size still shows

00:40:08,770 --> 00:40:12,880
that the file is zero length or whatever

00:40:10,540 --> 00:40:15,670
the original file is and now you can do

00:40:12,880 --> 00:40:17,829
tail - f tail - f will do the right

00:40:15,670 --> 00:40:21,099
thing and then as you append to the log

00:40:17,829 --> 00:40:23,500
file the file will grow into the pre

00:40:21,099 --> 00:40:25,810
allocated space and eye size will grow

00:40:23,500 --> 00:40:27,520
along with it and that can be a very

00:40:25,810 --> 00:40:30,130
nice feature and what that basically

00:40:27,520 --> 00:40:32,530
means is we've been pounding on the g

00:40:30,130 --> 00:40:34,930
Lipsy folks to actually expose the raw a

00:40:32,530 --> 00:40:39,040
Linux system call because it does a lot

00:40:34,930 --> 00:40:40,150
more than POSIX F allocated so let me

00:40:39,040 --> 00:40:41,859
talk a little bit about performance

00:40:40,150 --> 00:40:44,410
charts

00:40:41,859 --> 00:40:49,240
there's old line about you know you know

00:40:44,410 --> 00:40:51,160
lies darned lies and benchmarks and so

00:40:49,240 --> 00:40:53,710
the first thing I'll tell people before

00:40:51,160 --> 00:40:55,300
you believe benchmarks is to ask you

00:40:53,710 --> 00:40:58,119
know are the benchmarks fair are they

00:40:55,300 --> 00:40:59,380
repeatable and do they fairly represent

00:40:58,119 --> 00:41:01,780
the workload that you're actually using

00:40:59,380 --> 00:41:03,400
because a lot of times people will look

00:41:01,780 --> 00:41:05,230
at benchmarks and say this is the file

00:41:03,400 --> 00:41:08,200
system I want to use look how great it

00:41:05,230 --> 00:41:10,869
is and if you don't ask yourself whether

00:41:08,200 --> 00:41:12,400
or not that file system is even

00:41:10,869 --> 00:41:14,619
applicable to the kind of work that you

00:41:12,400 --> 00:41:17,020
do remember what I said earlier many

00:41:14,619 --> 00:41:17,970
workloads are not even disk bound or

00:41:17,020 --> 00:41:22,089
filesystem bound

00:41:17,970 --> 00:41:25,770
kind of pointless one really good effort

00:41:22,089 --> 00:41:28,569
you can find it at btrfs box called net

00:41:25,770 --> 00:41:30,640
it's done by a guy named Steven Pratt

00:41:28,569 --> 00:41:33,579
who is a member of IBM's performance

00:41:30,640 --> 00:41:37,450
team and if people want an example of

00:41:33,579 --> 00:41:40,210
how to actually do good benchmarking

00:41:37,450 --> 00:41:41,829
take a look at his site he documents the

00:41:40,210 --> 00:41:44,770
hardware and software configurations

00:41:41,829 --> 00:41:47,680
that are used and he tests multiple

00:41:44,770 --> 00:41:49,040
configurations and this is why this is

00:41:47,680 --> 00:41:51,680
important

00:41:49,040 --> 00:41:53,480
so this is large files creates using a

00:41:51,680 --> 00:41:58,070
raid file system

00:41:53,480 --> 00:41:59,780
red is ext3 Green is HD for dev this is

00:41:58,070 --> 00:42:01,640
back in October

00:41:59,780 --> 00:42:05,180
he has newer results but I didn't have

00:42:01,640 --> 00:42:11,080
time to update the this these particular

00:42:05,180 --> 00:42:13,570
charts blue is XFS red or hot pink is

00:42:11,080 --> 00:42:16,820
JFS and then the last three are

00:42:13,570 --> 00:42:19,850
different versions of btrfs and this is

00:42:16,820 --> 00:42:24,860
a very early version of btrfs and you

00:42:19,850 --> 00:42:27,710
can see with this one that ext3 in red

00:42:24,860 --> 00:42:30,890
is you know kind of low ext4 is a whole

00:42:27,710 --> 00:42:31,490
lot better almost as good as XFS but not

00:42:30,890 --> 00:42:33,710
quite

00:42:31,490 --> 00:42:35,450
JFS is a little bit lower and you know

00:42:33,710 --> 00:42:39,890
this one says okay that's pretty good

00:42:35,450 --> 00:42:43,190
promise as good as as XFS this is with

00:42:39,890 --> 00:42:46,070
16 threads and with 16 threads now you

00:42:43,190 --> 00:42:49,130
see that xt 4 is still a whole lot

00:42:46,070 --> 00:42:53,290
better than the HD 3 but it's nowhere

00:42:49,130 --> 00:42:56,420
near where XFS is with 16 threats and

00:42:53,290 --> 00:43:01,250
btrfs --is you know down there here's

00:42:56,420 --> 00:43:05,150
with 128 threads 128 threads now XFS is

00:43:01,250 --> 00:43:08,840
way down there HD 4 is way up there so

00:43:05,150 --> 00:43:11,150
if I'm going to sell XD 4 as the best

00:43:08,840 --> 00:43:15,200
file system ever which chart do you

00:43:11,150 --> 00:43:17,570
think I'm going to use right and this is

00:43:15,200 --> 00:43:20,660
just simply what's large file creates if

00:43:17,570 --> 00:43:25,700
we do large file random reads this is

00:43:20,660 --> 00:43:28,190
with one thread at 16 threads there's

00:43:25,700 --> 00:43:31,400
128 threads so large file random reads

00:43:28,190 --> 00:43:33,950
you can see that in some cases exe 3 is

00:43:31,400 --> 00:43:36,170
actually better than ext4 I don't know

00:43:33,950 --> 00:43:38,450
why I suspect it has to do with changes

00:43:36,170 --> 00:43:40,280
in the layout algorithms that we can

00:43:38,450 --> 00:43:42,890
still fix so there's still some cheating

00:43:40,280 --> 00:43:44,540
work we may need to do large file random

00:43:42,890 --> 00:43:49,490
writes you can see we're way better in

00:43:44,540 --> 00:43:52,610
the knee XD 3 16 threads 128 threads

00:43:49,490 --> 00:43:54,500
here's sequential reads

00:43:52,610 --> 00:43:57,590
and the main thing I want to get across

00:43:54,500 --> 00:44:00,500
here is these bars are fluctuating

00:43:57,590 --> 00:44:03,140
loudly right this is why benchmarks can

00:44:00,500 --> 00:44:05,330
be highly misleading if someone only

00:44:03,140 --> 00:44:09,290
shows you one chart they're trying to

00:44:05,330 --> 00:44:11,290
sell you something for some reason the

00:44:09,290 --> 00:44:14,060
mail some mail server' simulation

00:44:11,290 --> 00:44:15,800
workload which is a mixed readwrite

00:44:14,060 --> 00:44:20,450
workload that tries to simulate a mail

00:44:15,800 --> 00:44:22,730
server simulation xv4 does really well I

00:44:20,450 --> 00:44:26,480
know I can't tell you why but it just

00:44:22,730 --> 00:44:27,950
happens to be really well except on 128

00:44:26,480 --> 00:44:31,580
threads where the Machine apparently

00:44:27,950 --> 00:44:35,180
crashed and I can't tell you why either

00:44:31,580 --> 00:44:37,250
this was also last October this is now

00:44:35,180 --> 00:44:38,720
with the single disc alright and one of

00:44:37,250 --> 00:44:42,590
the interesting things with single disc

00:44:38,720 --> 00:44:45,530
is btrfs is now way better than a number

00:44:42,590 --> 00:44:49,640
of the file systems as we go through the

00:44:45,530 --> 00:44:51,680
various benchmarks and you can see here

00:44:49,640 --> 00:44:53,720
that on some of these benchmarks btrfs

00:44:51,680 --> 00:44:56,540
is actually doing very very well on a

00:44:53,720 --> 00:45:00,080
single disc not doing so well on raid

00:44:56,540 --> 00:45:02,500
again this is last october btrfs is file

00:45:00,080 --> 00:45:05,030
format has not been finalized yet

00:45:02,500 --> 00:45:07,670
certainly wasn't finalized as of October

00:45:05,030 --> 00:45:08,930
and they were still tuning it so you

00:45:07,670 --> 00:45:15,380
know again these results are a little

00:45:08,930 --> 00:45:16,910
bit unfair you can see here and then

00:45:15,380 --> 00:45:18,830
here's the mail server simulation where

00:45:16,910 --> 00:45:19,460
xt4 apparently walks all over the

00:45:18,830 --> 00:45:24,380
competition

00:45:19,460 --> 00:45:26,360
but again workloads matter right so I'm

00:45:24,380 --> 00:45:28,580
not going to tell you the xt4 is better

00:45:26,360 --> 00:45:31,250
than all other file systems on some

00:45:28,580 --> 00:45:33,950
workloads it does pretty well we still

00:45:31,250 --> 00:45:36,470
need to do some tuning work but it's

00:45:33,950 --> 00:45:37,760
it's always useful to know that ok this

00:45:36,470 --> 00:45:39,140
is actually something kind of

00:45:37,760 --> 00:45:43,040
interesting because we didn't actually

00:45:39,140 --> 00:45:46,190
plan for it but it turned out that a lot

00:45:43,040 --> 00:45:48,320
of the improvements that we did to

00:45:46,190 --> 00:45:51,970
improve general read/write performance

00:45:48,320 --> 00:45:55,790
also made a huge difference for ext4

00:45:51,970 --> 00:45:58,280
and I think looking at it a lot of it

00:45:55,790 --> 00:46:01,760
has to do with the fact that we're doing

00:45:58,280 --> 00:46:04,280
much fewer indirect block reads compared

00:46:01,760 --> 00:46:05,930
the extent reads and the uninitialized

00:46:04,280 --> 00:46:08,780
block groups means that you don't

00:46:05,930 --> 00:46:12,829
to scan the entire I know table if the

00:46:08,780 --> 00:46:16,940
inode table blocks aren't in use so this

00:46:12,829 --> 00:46:19,309
is results from my 128 Meg file system

00:46:16,940 --> 00:46:22,550
on the laptop that was stolen back in

00:46:19,309 --> 00:46:25,609
September and they were actually

00:46:22,550 --> 00:46:29,150
identical copies I've been using HT for

00:46:25,609 --> 00:46:31,190
in production use for about two or three

00:46:29,150 --> 00:46:33,380
months at that point and I just simply

00:46:31,190 --> 00:46:37,130
made a copy of everything on my file

00:46:33,380 --> 00:46:40,910
system onto a fresh ext3 file system so

00:46:37,130 --> 00:46:42,859
xt3 actually had a benefit over ext4

00:46:40,910 --> 00:46:45,500
because it was a fresh copy and it was

00:46:42,859 --> 00:46:48,260
totally defragged whereas ext4 i've been

00:46:45,500 --> 00:46:50,470
using it for two or three months and you

00:46:48,260 --> 00:46:55,160
can see that passed one of fsck

00:46:50,470 --> 00:46:58,130
on ext4 was 17 seconds on East III it

00:46:55,160 --> 00:47:00,410
was 382 seconds and take a look at the

00:46:58,130 --> 00:47:02,960
number of megabytes read/write we went

00:47:00,410 --> 00:47:06,650
from you know over 23 hundred megabytes

00:47:02,960 --> 00:47:08,270
read down to 233 and that's where a lot

00:47:06,650 --> 00:47:10,549
of speed-up comes from you're just we're

00:47:08,270 --> 00:47:12,140
just simply needing to read fewer blocks

00:47:10,549 --> 00:47:14,780
on disk and we're having to do a lot

00:47:12,140 --> 00:47:18,069
less seeking and we saved most of the

00:47:14,780 --> 00:47:20,720
time on past one and pass two again

00:47:18,069 --> 00:47:24,440
there's not that much difference in the

00:47:20,720 --> 00:47:28,339
directory reads but the directories and

00:47:24,440 --> 00:47:29,720
in fact on on this one here hd3 took

00:47:28,339 --> 00:47:31,040
less time to read the directories

00:47:29,720 --> 00:47:34,579
because the directories were contiguous

00:47:31,040 --> 00:47:36,680
because we'd done a fresh fresh copy but

00:47:34,579 --> 00:47:39,230
there were fewer reads for ext4 because

00:47:36,680 --> 00:47:43,369
there were no indirect locks so you can

00:47:39,230 --> 00:47:47,390
see there the the net is you go from 424

00:47:43,369 --> 00:47:50,900
seconds down to 63 seconds the general

00:47:47,390 --> 00:47:53,480
rule of thumb that I found is 64 if you

00:47:50,900 --> 00:47:57,430
use a freshly formatted ext4 file system

00:47:53,480 --> 00:48:00,829
saves you somewhere between 6 to 8 times

00:47:57,430 --> 00:48:05,450
it's 6 to 8 times faster so take your

00:48:00,829 --> 00:48:08,380
xt3 fsck time divide it by 7 and that's

00:48:05,450 --> 00:48:11,960
roughly what it will be under ext4

00:48:08,380 --> 00:48:16,040
so if you want to use the xt

00:48:11,960 --> 00:48:18,230
you need e to FS Prague's 1.41 i really

00:48:16,040 --> 00:48:19,280
recommend that you go to e 2 FS Prague's

00:48:18,230 --> 00:48:20,870
1.41

00:48:19,280 --> 00:48:24,710
for because we fixed a whole bunch of

00:48:20,870 --> 00:48:28,190
xt4 related bugs you need at least a two

00:48:24,710 --> 00:48:33,020
627 kernel or newer I strongly recommend

00:48:28,190 --> 00:48:35,300
to 628 and the for stable branch that

00:48:33,020 --> 00:48:38,330
stuff will hit the stable kernels fairly

00:48:35,300 --> 00:48:40,100
soon it just hasn't yet that was one of

00:48:38,330 --> 00:48:43,520
the things I was going to work on before

00:48:40,100 --> 00:48:46,070
my laptop got stolen but that's okay and

00:48:43,520 --> 00:48:48,650
there is a two 6:27 for stable kernel

00:48:46,070 --> 00:48:51,320
again both these will be sent off to the

00:48:48,650 --> 00:48:52,640
stable kernels maintainer soon and of

00:48:51,320 --> 00:48:55,430
course you'll need a file system to

00:48:52,640 --> 00:48:59,360
mount you can just simply use a

00:48:55,430 --> 00:49:02,150
completely unconverted ext3 file system

00:48:59,360 --> 00:49:03,680
and the delayed allocation will help you

00:49:02,150 --> 00:49:05,990
so you will get somewhat better

00:49:03,680 --> 00:49:08,630
performance just simply taking a

00:49:05,990 --> 00:49:12,860
completely unconverted file system from

00:49:08,630 --> 00:49:14,660
ext3 you can enable features such as

00:49:12,860 --> 00:49:19,070
extents the huge files features

00:49:14,660 --> 00:49:21,290
directory and Link directory I sighs or

00:49:19,070 --> 00:49:24,980
sorry that should be derp index actually

00:49:21,290 --> 00:49:28,520
on a particular file system if you

00:49:24,980 --> 00:49:30,830
enable uh Nannette BG or derp index you

00:49:28,520 --> 00:49:33,470
will have to force an fsck after you

00:49:30,830 --> 00:49:35,330
actually enable those feature flags that

00:49:33,470 --> 00:49:38,660
will get you some of the performance of

00:49:35,330 --> 00:49:41,480
ext4 but you will only use extents for

00:49:38,660 --> 00:49:43,220
the newly created files the old files on

00:49:41,480 --> 00:49:46,700
the file system will still use the old

00:49:43,220 --> 00:49:49,130
indirect blocks or you can create a

00:49:46,700 --> 00:49:50,960
completely fresh ext4 file system then

00:49:49,130 --> 00:49:53,030
do a dump restore and you'll get the

00:49:50,960 --> 00:49:55,610
best performance from that but it's up

00:49:53,030 --> 00:49:57,110
to you how you want to do things if you

00:49:55,610 --> 00:49:59,720
just simply want to play around with the

00:49:57,110 --> 00:50:02,720
HD four you can just simply you know I

00:49:59,720 --> 00:50:04,970
leave your file system unconverted one

00:50:02,720 --> 00:50:07,580
warning is at the moment once you start

00:50:04,970 --> 00:50:10,430
converting to ext4 we don't have a good

00:50:07,580 --> 00:50:13,520
way of going back in time and

00:50:10,430 --> 00:50:17,390
unconverted so if you want to get

00:50:13,520 --> 00:50:20,630
involved there's ext4 mailing list the

00:50:17,390 --> 00:50:23,000
latest XD for patch series we I have a

00:50:20,630 --> 00:50:25,370
git tree and I also have a patch

00:50:23,000 --> 00:50:28,340
directory at this point the get tree is

00:50:25,370 --> 00:50:31,280
probably the most up-to-date we do have

00:50:28,340 --> 00:50:33,059
an XD for wiki which is a txt for wiki

00:50:31,280 --> 00:50:35,130
kernel.org

00:50:33,059 --> 00:50:37,019
it still needs a lot of work if someone

00:50:35,130 --> 00:50:39,269
would like to jump in I would love some

00:50:37,019 --> 00:50:40,229
help at the moment it's actually a

00:50:39,269 --> 00:50:43,319
little embarrassing

00:50:40,229 --> 00:50:45,449
Colonel Newby zorg's xt for article is

00:50:43,319 --> 00:50:48,420
actually better than what we have on the

00:50:45,449 --> 00:50:50,400
wiki so if somebody wants to help me you

00:50:48,420 --> 00:50:53,069
know improve the ext4 wiki I'd really

00:50:50,400 --> 00:50:54,539
appreciate it we do have a weekly

00:50:53,069 --> 00:50:55,829
conference call if there's people

00:50:54,539 --> 00:50:59,609
someone who's really interested in

00:50:55,829 --> 00:51:02,849
diving in deep contact me about that and

00:50:59,609 --> 00:51:06,329
we have an IRC channel and this is the

00:51:02,849 --> 00:51:08,789
ext4 development team and I'm probably

00:51:06,329 --> 00:51:10,349
missing a couple of people but these are

00:51:08,789 --> 00:51:12,539
people who've been working on it for the

00:51:10,349 --> 00:51:14,489
last couple of years and they do a lot

00:51:12,539 --> 00:51:16,559
of hard work I'm the guy who basically

00:51:14,489 --> 00:51:18,359
does Q way and all the integration work

00:51:16,559 --> 00:51:21,329
and then a lot of the user space

00:51:18,359 --> 00:51:24,599
utilities so with that I know I ran a

00:51:21,329 --> 00:51:25,920
bit over time so I don't know maybe I

00:51:24,599 --> 00:51:27,449
have time for maybe one or two questions

00:51:25,920 --> 00:51:29,849
and then I'll be happy to stick around

00:51:27,449 --> 00:51:36,359
and ask some more questions yeah in the

00:51:29,849 --> 00:51:40,170
middle there thank you

00:51:36,359 --> 00:51:43,229
I was interested to to know if there are

00:51:40,170 --> 00:51:45,179
any good solutions for the sinking

00:51:43,229 --> 00:51:50,400
problem that you mentioned so I'm

00:51:45,179 --> 00:51:52,559
involved in laptop mode things and the

00:51:50,400 --> 00:51:57,299
the default is actually not two minutes

00:51:52,559 --> 00:51:59,609
for 10 minutes and yeah we've got in a

00:51:57,299 --> 00:52:01,920
lot of time getting applications to to

00:51:59,609 --> 00:52:04,579
drop all their f sinkholes yeah just

00:52:01,920 --> 00:52:07,219
because any one of those will yeah

00:52:04,579 --> 00:52:10,769
there's no way to get rid of them yeah I

00:52:07,219 --> 00:52:13,799
I think the short version is F data sink

00:52:10,769 --> 00:52:15,839
seems to be a good compromise for now we

00:52:13,799 --> 00:52:20,069
are looking into ways of solving the f

00:52:15,839 --> 00:52:22,890
sink problem but it's it's it's it's in

00:52:20,069 --> 00:52:24,269
really tricky code so we know about it

00:52:22,890 --> 00:52:28,380
it's one of those things we'd love to

00:52:24,269 --> 00:52:30,089
fix and it's on our on our hit list

00:52:28,380 --> 00:52:31,709
so yeah it's that's one of those little

00:52:30,089 --> 00:52:35,490
embarrassing bits that we really want to

00:52:31,709 --> 00:52:50,130
try to fix so yeah

00:52:35,490 --> 00:52:53,820
any other maybe I take one more yeah in

00:52:50,130 --> 00:52:56,280
sort of a related question for databases

00:52:53,820 --> 00:52:58,440
and also presumably for a lot of those

00:52:56,280 --> 00:53:00,270
other applications doing F sync they

00:52:58,440 --> 00:53:02,370
don't necessarily need the sync to

00:53:00,270 --> 00:53:04,470
happen immediately they just have to

00:53:02,370 --> 00:53:06,300
know that it and when it happens they

00:53:04,470 --> 00:53:09,030
have to know that it hasn't happened yet

00:53:06,300 --> 00:53:12,840
so they can keep their they can avoid

00:53:09,030 --> 00:53:14,820
sending a commit confirmation or telling

00:53:12,840 --> 00:53:19,200
some other replication so is there any

00:53:14,820 --> 00:53:21,150
sort of non-blocking f sync that no why

00:53:19,200 --> 00:53:22,710
don't we talk I'd love to hear from

00:53:21,150 --> 00:53:24,000
database people on that one

00:53:22,710 --> 00:53:26,130
but we should probably take that one

00:53:24,000 --> 00:53:28,500
offline and I know I'm really running

00:53:26,130 --> 00:53:30,300
over so maybe I'll be happy to stand on

00:53:28,500 --> 00:53:31,500
the hallway and take questions for

00:53:30,300 --> 00:53:33,660
people who are interested but I don't

00:53:31,500 --> 00:53:35,790
want to get people late for their next

00:53:33,660 --> 00:53:38,090
talk so thank you very much for your

00:53:35,790 --> 00:53:38,090
attention

00:53:41,280 --> 00:53:43,340

YouTube URL: https://www.youtube.com/watch?v=Fhixp2Opomk


