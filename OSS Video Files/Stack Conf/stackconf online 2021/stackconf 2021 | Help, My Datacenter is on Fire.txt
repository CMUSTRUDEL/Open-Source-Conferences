Title: stackconf 2021 | Help, My Datacenter is on Fire
Publication date: 2021-06-24
Playlist: stackconf online 2021
Description: 
	by Kris Buytaert

Most people will claim that this never happens, others hope it never happens, but it happened on March 10, 2021, and it was not just the 1 datacenter that got impacted, but the whole campus of the provider that got powered down. This talk will explain how our customers survived this outage, how our culture, opensource tooling and automation saved the da(y,ta). A talk about disaster recovery, business continuity plans and building cloud agnostic stacks that survive disasters.


NETWAYS
Konferenzen: https://www.netways.de/events
Schulungen: https://www.netways.de/schulungen
Shop: https://shop.netways.de/
Blog: http://blog.netways.de/
NWS: https://nws.netways.de 

Webinare
Archiv Link: https://www.netways.de/netways/webinare/

Social Media
SlideShare: http://de.slideshare.net/netways
YouTube: https://www.netways.de/youtube
Facebook: https://www.facebook.com/netways
Twitter: https://twitter.com/netways
Instagram: https://www.instagram.com/netwaysgmbh/


Musik: https://www.frametraxx.de/
Captions: 
	00:00:05,660 --> 00:00:13,119
[Applause]

00:00:06,120 --> 00:00:13,119
[Music]

00:00:14,080 --> 00:00:19,039
good morning

00:00:16,480 --> 00:00:21,840
so today i'm going to talk about the

00:00:19,039 --> 00:00:24,960
great fire of 2021

00:00:21,840 --> 00:00:28,840
and for a lot of people that means

00:00:24,960 --> 00:00:32,960
march 10th 2021 when

00:00:28,840 --> 00:00:36,000
ovh had a huge data center fire

00:00:32,960 --> 00:00:36,719
for me it started at almost four o'clock

00:00:36,000 --> 00:00:39,600
in the morning

00:00:36,719 --> 00:00:40,559
when one of our on-call engineers called

00:00:39,600 --> 00:00:43,600
me

00:00:40,559 --> 00:00:45,360
because he was in real trouble

00:00:43,600 --> 00:00:47,200
and actually the first time the phone

00:00:45,360 --> 00:00:49,039
rang i

00:00:47,200 --> 00:00:50,559
didn't realize the phone was ringing and

00:00:49,039 --> 00:00:53,680
i

00:00:50,559 --> 00:00:54,879
pushed it off again and then two minutes

00:00:53,680 --> 00:00:58,000
later he called me again

00:00:54,879 --> 00:01:00,160
and while i was waking up he said our

00:00:58,000 --> 00:01:01,840
data center is on fire

00:01:00,160 --> 00:01:04,320
and when you get that call you start

00:01:01,840 --> 00:01:06,799
thinking like wait what

00:01:04,320 --> 00:01:08,640
what did he just say what just happened

00:01:06,799 --> 00:01:10,880
you can't get a

00:01:08,640 --> 00:01:12,720
partial panic attack in the sense of it

00:01:10,880 --> 00:01:14,640
can be that bad

00:01:12,720 --> 00:01:16,000
so i was heading downstairs i was

00:01:14,640 --> 00:01:19,920
starting to realize like

00:01:16,000 --> 00:01:25,200
what is really going on and by the time

00:01:19,920 --> 00:01:26,799
i was downstairs i found these tweets

00:01:25,200 --> 00:01:28,560
this was the public announcement that

00:01:26,799 --> 00:01:30,560
there was a real

00:01:28,560 --> 00:01:32,320
major incident in strasbourg where there

00:01:30,560 --> 00:01:35,759
was a fire in the building

00:01:32,320 --> 00:01:37,280
and that not only the data center that

00:01:35,759 --> 00:01:40,000
was impacted

00:01:37,280 --> 00:01:41,439
was down but that the fire services have

00:01:40,000 --> 00:01:46,240
decided to also

00:01:41,439 --> 00:01:48,079
power down the rest of that campus

00:01:46,240 --> 00:01:50,000
and the fine line was well basically

00:01:48,079 --> 00:01:51,680
it's time to activate your disaster

00:01:50,000 --> 00:01:53,200
recovery plan

00:01:51,680 --> 00:01:54,720
the rest of this talk is going to be

00:01:53,200 --> 00:01:58,960
about that

00:01:54,720 --> 00:02:02,000
those actions so you can learn from

00:01:58,960 --> 00:02:04,000
what we did that night

00:02:02,000 --> 00:02:05,119
my name is chris i used to be a

00:02:04,000 --> 00:02:08,720
developer

00:02:05,119 --> 00:02:09,119
came operations guy and for the past 15

00:02:08,720 --> 00:02:11,440
years

00:02:09,119 --> 00:02:13,520
i've been talking about automation about

00:02:11,440 --> 00:02:15,920
infrastructures code about

00:02:13,520 --> 00:02:17,599
surviving the 10th floor test and

00:02:15,920 --> 00:02:20,160
actually this is

00:02:17,599 --> 00:02:20,720
a talk where all of that experience all

00:02:20,160 --> 00:02:23,920
of

00:02:20,720 --> 00:02:24,480
the things we've been talking about came

00:02:23,920 --> 00:02:29,440
to be

00:02:24,480 --> 00:02:32,000
reality if you look at the public impact

00:02:29,440 --> 00:02:35,040
according to netcraft there was 3.6

00:02:32,000 --> 00:02:36,000
million websites across 460 000

00:02:35,040 --> 00:02:39,920
different domains being

00:02:36,000 --> 00:02:43,599
impacted that sounds huge and

00:02:39,920 --> 00:02:47,840
for a lot of people this really was huge

00:02:43,599 --> 00:02:51,680
for us obviously there was impact

00:02:47,840 --> 00:02:53,840
but it wasn't huge we survived this

00:02:51,680 --> 00:02:53,840
thing

00:02:53,920 --> 00:02:57,120
our immediate assessment at four o'clock

00:02:56,000 --> 00:02:59,040
in the morning was

00:02:57,120 --> 00:03:01,280
which customer facing production

00:02:59,040 --> 00:03:03,040
services have been lost in this

00:03:01,280 --> 00:03:05,200
and then after that what internal

00:03:03,040 --> 00:03:07,280
production services have been lost and

00:03:05,200 --> 00:03:09,280
do we need to recover any of those in

00:03:07,280 --> 00:03:12,879
order to recover the production

00:03:09,280 --> 00:03:13,440
services we were looking at priorities

00:03:12,879 --> 00:03:16,000
like

00:03:13,440 --> 00:03:16,640
which services are actually supposed to

00:03:16,000 --> 00:03:20,000
be

00:03:16,640 --> 00:03:21,599
24 7 generating platforms which services

00:03:20,000 --> 00:03:22,080
are actually tools that are only being

00:03:21,599 --> 00:03:25,360
used

00:03:22,080 --> 00:03:28,400
during office hours and

00:03:25,360 --> 00:03:30,159
what parts of these services can

00:03:28,400 --> 00:03:32,879
be restored what part of services have

00:03:30,159 --> 00:03:36,319
been restored already

00:03:32,879 --> 00:03:39,519
and it actually was not that bad

00:03:36,319 --> 00:03:42,239
our immediate visible part was that

00:03:39,519 --> 00:03:45,760
most of our customers had automatically

00:03:42,239 --> 00:03:49,280
failed over to a secondary data center

00:03:45,760 --> 00:03:52,159
there was one platform where

00:03:49,280 --> 00:03:53,840
the failover of the public ip address

00:03:52,159 --> 00:03:56,480
had failed

00:03:53,840 --> 00:03:57,519
there was another customer which

00:03:56,480 --> 00:04:00,319
actually had

00:03:57,519 --> 00:04:02,080
their whole stack spread over two

00:04:00,319 --> 00:04:05,280
physical data centers but that was

00:04:02,080 --> 00:04:07,040
stressful one as fast group two so they

00:04:05,280 --> 00:04:09,040
were completely offline

00:04:07,040 --> 00:04:10,959
and then we also had one customer where

00:04:09,040 --> 00:04:12,799
actually that data center was the

00:04:10,959 --> 00:04:15,439
disaster recovery site so

00:04:12,799 --> 00:04:18,400
that disaster recovery site was

00:04:15,439 --> 00:04:18,400
partially destroyed

00:04:19,680 --> 00:04:23,040
so the failing vip was one we needed to

00:04:21,359 --> 00:04:23,840
tackle because that was business

00:04:23,040 --> 00:04:27,680
impacting

00:04:23,840 --> 00:04:30,160
uh it was pretty much the api call to

00:04:27,680 --> 00:04:32,160
the ova chances to tell us like move

00:04:30,160 --> 00:04:33,440
that ips to another service

00:04:32,160 --> 00:04:36,240
and what we did at that point was

00:04:33,440 --> 00:04:37,040
manually change the dns of the incoming

00:04:36,240 --> 00:04:39,040
traffic

00:04:37,040 --> 00:04:41,199
and use the public ip address that we

00:04:39,040 --> 00:04:42,639
still had available that we could use

00:04:41,199 --> 00:04:44,560
the public eye theaters of one of the

00:04:42,639 --> 00:04:47,199
load balancers to do that

00:04:44,560 --> 00:04:48,800
um for those who know me you realize

00:04:47,199 --> 00:04:49,440
that this is when you end up having a

00:04:48,800 --> 00:04:53,440
dns

00:04:49,440 --> 00:04:55,600
problem because that stack was

00:04:53,440 --> 00:04:57,680
kind of fully under our control except

00:04:55,600 --> 00:04:58,800
for one domain that that customer was

00:04:57,680 --> 00:05:00,160
using

00:04:58,800 --> 00:05:03,199
and that's where we lost most of the

00:05:00,160 --> 00:05:06,160
time we lost about 60 minutes

00:05:03,199 --> 00:05:06,800
because we could not update the dns and

00:05:06,160 --> 00:05:09,440
we couldn't

00:05:06,800 --> 00:05:10,639
reach anybody booked updated yes and by

00:05:09,440 --> 00:05:14,479
the time

00:05:10,639 --> 00:05:18,400
they eventually had updated the dns

00:05:14,479 --> 00:05:19,280
over an hour got lost the secondary part

00:05:18,400 --> 00:05:21,199
there was that

00:05:19,280 --> 00:05:23,199
some customer devices that were talking

00:05:21,199 --> 00:05:25,520
to that iot stack

00:05:23,199 --> 00:05:27,360
still had hard coded ip addresses

00:05:25,520 --> 00:05:28,479
because the devices that were talking to

00:05:27,360 --> 00:05:30,160
it

00:05:28,479 --> 00:05:32,479
had no other options so there we needed

00:05:30,160 --> 00:05:33,919
to do some manual interventions

00:05:32,479 --> 00:05:36,320
so that was one of the first technical

00:05:33,919 --> 00:05:36,320
problems

00:05:36,400 --> 00:05:39,520
the second problem was the platform that

00:05:38,720 --> 00:05:43,919
didn't have

00:05:39,520 --> 00:05:45,759
any redundancy in a different campus

00:05:43,919 --> 00:05:47,440
so what we decided there is we're going

00:05:45,759 --> 00:05:49,039
to rebootstrap this stack and we're

00:05:47,440 --> 00:05:50,400
going to spin this up again in a

00:05:49,039 --> 00:05:51,440
different data center at a different

00:05:50,400 --> 00:05:53,600
supplier

00:05:51,440 --> 00:05:54,800
we still had spare hardware around so we

00:05:53,600 --> 00:05:57,280
could do that

00:05:54,800 --> 00:05:58,880
and because we had everything fully

00:05:57,280 --> 00:06:00,479
automated

00:05:58,880 --> 00:06:01,919
we could restore the most recent black

00:06:00,479 --> 00:06:04,319
app which was kind of

00:06:01,919 --> 00:06:06,000
two hours old and as this is a platform

00:06:04,319 --> 00:06:09,680
it was only used mostly

00:06:06,000 --> 00:06:10,479
during daytime that was the exact data

00:06:09,680 --> 00:06:13,199
we needed

00:06:10,479 --> 00:06:14,160
we could reboot that completely from

00:06:13,199 --> 00:06:17,759
scratch

00:06:14,160 --> 00:06:20,880
and be up and running again before 9am

00:06:17,759 --> 00:06:23,360
on the wednesday morning um

00:06:20,880 --> 00:06:24,960
at 9am the thing we were still trying to

00:06:23,360 --> 00:06:26,319
improve was the actual performance of

00:06:24,960 --> 00:06:27,280
the platform but if we wouldn't have

00:06:26,319 --> 00:06:29,360
told the customer

00:06:27,280 --> 00:06:31,360
that their whole data center their whole

00:06:29,360 --> 00:06:34,319
stack was done up in fire

00:06:31,360 --> 00:06:35,759
they wouldn't have noticed it um

00:06:34,319 --> 00:06:37,280
obviously the problem we were facing

00:06:35,759 --> 00:06:38,800
there was an mtu problem between the

00:06:37,280 --> 00:06:42,800
load balancers and

00:06:38,800 --> 00:06:44,880
database web servers and

00:06:42,800 --> 00:06:48,240
it's not always a dns problem sometimes

00:06:44,880 --> 00:06:50,960
it is an mtv problem

00:06:48,240 --> 00:06:53,360
so what was our impact during that night

00:06:50,960 --> 00:06:56,639
we lost 13 physical servers

00:06:53,360 --> 00:07:00,840
we lost about 135 vms

00:06:56,639 --> 00:07:03,280
the root cause of that outage was

00:07:00,840 --> 00:07:05,440
potentially that there was ubs

00:07:03,280 --> 00:07:07,919
maintenance

00:07:05,440 --> 00:07:08,960
so was that something that could have

00:07:07,919 --> 00:07:12,319
been prevented

00:07:08,960 --> 00:07:13,759
probably so customer facing we really

00:07:12,319 --> 00:07:15,199
didn't have that many problems

00:07:13,759 --> 00:07:16,720
internally

00:07:15,199 --> 00:07:19,120
we had a couple of stacks that we needed

00:07:16,720 --> 00:07:21,599
to respin that we need to restore

00:07:19,120 --> 00:07:23,440
but pretty much all of those were

00:07:21,599 --> 00:07:25,280
automated

00:07:23,440 --> 00:07:27,280
a lot of our test infrastructure was

00:07:25,280 --> 00:07:28,639
gone because that's not spread over

00:07:27,280 --> 00:07:30,400
multiple data centers

00:07:28,639 --> 00:07:32,639
a couple of our development environments

00:07:30,400 --> 00:07:33,520
were gone but we can all spin them again

00:07:32,639 --> 00:07:37,280
and and

00:07:33,520 --> 00:07:39,120
also at six a.m in the morning

00:07:37,280 --> 00:07:40,880
you joke about hey why is half of my

00:07:39,120 --> 00:07:41,280
cube clothes are gone and who was joking

00:07:40,880 --> 00:07:43,599
about

00:07:41,280 --> 00:07:45,840
destroying your needs with fire because

00:07:43,599 --> 00:07:45,840
you know

00:07:47,520 --> 00:07:50,639
if you look at that night there was the

00:07:49,120 --> 00:07:53,360
on-call engineering me

00:07:50,639 --> 00:07:54,960
um we didn't actually escalate further

00:07:53,360 --> 00:07:56,800
to more people because

00:07:54,960 --> 00:07:58,879
we had most of what we needed to recover

00:07:56,800 --> 00:08:02,160
under control

00:07:58,879 --> 00:08:04,080
speeding up everything again was about

00:08:02,160 --> 00:08:06,479
18 hours of work

00:08:04,080 --> 00:08:07,599
mostly coordinating what needed to be

00:08:06,479 --> 00:08:11,039
spun up

00:08:07,599 --> 00:08:12,639
what was already already talking to end

00:08:11,039 --> 00:08:13,199
users let them verify things were

00:08:12,639 --> 00:08:17,840
actually

00:08:13,199 --> 00:08:20,639
working again um but it was

00:08:17,840 --> 00:08:22,240
not building things it was enabling

00:08:20,639 --> 00:08:23,680
things and deciding where we were going

00:08:22,240 --> 00:08:25,199
to launch them

00:08:23,680 --> 00:08:26,800
and the biggest part obviously wasn't

00:08:25,199 --> 00:08:29,599
waiting for the backups to be restored

00:08:26,800 --> 00:08:32,960
in a different data center

00:08:29,599 --> 00:08:32,960
because that just takes time

00:08:33,760 --> 00:08:38,320
around 9 10 what we initially thought at

00:08:37,839 --> 00:08:40,159
night

00:08:38,320 --> 00:08:41,360
everything is fine we looked at the

00:08:40,159 --> 00:08:43,200
monitoring

00:08:41,360 --> 00:08:44,959
we actually realized we'd overlooked one

00:08:43,200 --> 00:08:48,000
customer we'd overlooked

00:08:44,959 --> 00:08:49,600
a cluster cluster that at first sight

00:08:48,000 --> 00:08:51,839
looked completely healthy

00:08:49,600 --> 00:08:52,800
because it yes there was a note missing

00:08:51,839 --> 00:08:54,480
um

00:08:52,800 --> 00:08:56,959
but it was an underlying problem that we

00:08:54,480 --> 00:08:59,440
didn't detect in the middle of the chaos

00:08:56,959 --> 00:09:00,240
so at that point we decided to hey we're

00:08:59,440 --> 00:09:02,240
going to

00:09:00,240 --> 00:09:03,519
switch this to a one node because all

00:09:02,240 --> 00:09:05,519
the data was still there

00:09:03,519 --> 00:09:08,160
we switched this to a one node mount

00:09:05,519 --> 00:09:09,920
point just mounted over nfs

00:09:08,160 --> 00:09:11,279
and the application can continue working

00:09:09,920 --> 00:09:12,560
because we had intermittent files that

00:09:11,279 --> 00:09:15,360
weren't actually being

00:09:12,560 --> 00:09:16,880
read so don't try this at home because

00:09:15,360 --> 00:09:19,040
the moment when you use

00:09:16,880 --> 00:09:20,399
cluster as a direct file system you're

00:09:19,040 --> 00:09:21,839
going to have troubles later

00:09:20,399 --> 00:09:23,440
you're going to need to recopy and

00:09:21,839 --> 00:09:24,399
re-add all the files again so they're

00:09:23,440 --> 00:09:26,080
being touched

00:09:24,399 --> 00:09:27,600
and that people know that they're being

00:09:26,080 --> 00:09:29,600
well the system knows that they've been

00:09:27,600 --> 00:09:32,399
touched again

00:09:29,600 --> 00:09:34,000
so no data was lost no customers were

00:09:32,399 --> 00:09:37,600
actually having trouble

00:09:34,000 --> 00:09:39,040
and we were kind of happy um

00:09:37,600 --> 00:09:41,279
a couple of internal tools were being

00:09:39,040 --> 00:09:43,519
restored we verified that

00:09:41,279 --> 00:09:44,480
all of the primary nodes that typically

00:09:43,519 --> 00:09:46,560
made the backups

00:09:44,480 --> 00:09:48,480
were not also the backups were

00:09:46,560 --> 00:09:50,800
configured on a secondary node so that

00:09:48,480 --> 00:09:52,399
in the evening at night we were actually

00:09:50,800 --> 00:09:54,080
taking backups again

00:09:52,399 --> 00:09:56,080
we were verifying that we had sufficient

00:09:54,080 --> 00:09:59,440
disk space on those backup nodes

00:09:56,080 --> 00:09:59,700
to make the backups and what we realized

00:09:59,440 --> 00:10:01,680
well

00:09:59,700 --> 00:10:02,560
[Music]

00:10:01,680 --> 00:10:05,120
you know what is saying where the

00:10:02,560 --> 00:10:06,880
shoemaker always wears the voice choose

00:10:05,120 --> 00:10:09,120
our customer platforms were quite good

00:10:06,880 --> 00:10:10,480
but the problems we really had

00:10:09,120 --> 00:10:11,920
the things where we really waste the

00:10:10,480 --> 00:10:14,640
time having to restore things and

00:10:11,920 --> 00:10:18,160
reprovision was our own internal tools

00:10:14,640 --> 00:10:19,920
our own next cloud our own red mine

00:10:18,160 --> 00:10:21,760
uh mosfet might actually use case right

00:10:19,920 --> 00:10:24,480
good luck

00:10:21,760 --> 00:10:25,440
and we also realized that we started to

00:10:24,480 --> 00:10:27,680
have a new challenge

00:10:25,440 --> 00:10:28,560
because we were not the only ones who

00:10:27,680 --> 00:10:31,200
had lost data

00:10:28,560 --> 00:10:32,079
i lost hardware everybody needed new

00:10:31,200 --> 00:10:34,959
hardware so it was

00:10:32,079 --> 00:10:36,160
really like we need to get replacements

00:10:34,959 --> 00:10:37,839
for this hardware

00:10:36,160 --> 00:10:39,600
we really need to be able to spin it up

00:10:37,839 --> 00:10:41,360
and ovh is not going to be the one who's

00:10:39,600 --> 00:10:42,800
going to give it fast to us so

00:10:41,360 --> 00:10:44,839
we spun up hardware at a different

00:10:42,800 --> 00:10:48,000
supplier we already had some things

00:10:44,839 --> 00:10:51,200
there and we just

00:10:48,000 --> 00:10:52,800
move things there we did some wrong

00:10:51,200 --> 00:10:54,640
decisions on day two because we kind of

00:10:52,800 --> 00:10:56,399
had the id to

00:10:54,640 --> 00:10:59,040
what about we use a new supplier what

00:10:56,399 --> 00:11:02,240
about you tried to use

00:10:59,040 --> 00:11:04,320
one we've never played and

00:11:02,240 --> 00:11:05,839
while that on a system level worked

00:11:04,320 --> 00:11:07,839
perfectly we were

00:11:05,839 --> 00:11:10,399
spending time figuring out how we would

00:11:07,839 --> 00:11:11,839
do network redundancy and load balancing

00:11:10,399 --> 00:11:14,240
strategies with them right and how we

00:11:11,839 --> 00:11:16,720
would be triggering failover

00:11:14,240 --> 00:11:18,240
while we actually could just spin up

00:11:16,720 --> 00:11:20,720
things that suppliers we were already

00:11:18,240 --> 00:11:20,720
dealing with

00:11:20,800 --> 00:11:25,120
so the third phase of that mic was

00:11:23,519 --> 00:11:27,040
basically

00:11:25,120 --> 00:11:29,120
verifying if everything was back in

00:11:27,040 --> 00:11:30,480
place

00:11:29,120 --> 00:11:32,800
figuring out when the first

00:11:30,480 --> 00:11:34,880
announcements were coming like

00:11:32,800 --> 00:11:36,000
what is going to come back at what rate

00:11:34,880 --> 00:11:37,440
is it going to come back

00:11:36,000 --> 00:11:38,959
how is it going to come back are you

00:11:37,440 --> 00:11:39,920
just going to turn it on and are we

00:11:38,959 --> 00:11:43,279
going to

00:11:39,920 --> 00:11:44,640
see notes pop up again

00:11:43,279 --> 00:11:47,360
or are they going to do them in

00:11:44,640 --> 00:11:47,360
controlled way

00:11:47,440 --> 00:11:53,760
if we have development and acceptance

00:11:50,000 --> 00:11:56,079
platforms that are now impacted

00:11:53,760 --> 00:11:57,440
which ones do we really need to be back

00:11:56,079 --> 00:11:58,720
so that we can actually trigger our

00:11:57,440 --> 00:12:00,480
pipelines and then we can

00:11:58,720 --> 00:12:02,560
do our continuous delivery for those

00:12:00,480 --> 00:12:04,880
types again

00:12:02,560 --> 00:12:07,920
and obviously the hardware what do we

00:12:04,880 --> 00:12:07,920
really need in this phase

00:12:08,000 --> 00:12:11,680
the other thing we realized is for that

00:12:10,880 --> 00:12:15,680
one customer

00:12:11,680 --> 00:12:18,000
where it was their dr site that was gone

00:12:15,680 --> 00:12:18,959
we needed a new dr plan we needed to

00:12:18,000 --> 00:12:22,639
figure out

00:12:18,959 --> 00:12:22,639
what we were going to do with them

00:12:22,839 --> 00:12:29,360
so putting in priorities on

00:12:25,600 --> 00:12:31,680
what was the hardest part

00:12:29,360 --> 00:12:34,000
trying to anticipate um what we were

00:12:31,680 --> 00:12:36,000
going to get back at what point

00:12:34,000 --> 00:12:38,240
which was initially we're going to get

00:12:36,000 --> 00:12:39,519
this back by the end of the week then it

00:12:38,240 --> 00:12:41,040
became

00:12:39,519 --> 00:12:42,639
well some of it is not going to come

00:12:41,040 --> 00:12:44,880
back and then

00:12:42,639 --> 00:12:46,480
eventually some of the things came back

00:12:44,880 --> 00:12:48,079
in a totally unusual state

00:12:46,480 --> 00:12:50,000
like a month later but by then we'd

00:12:48,079 --> 00:12:53,519
already

00:12:50,000 --> 00:12:56,800
in our mind decommissioned them

00:12:53,519 --> 00:12:59,360
so we build a new plan for the dr site

00:12:56,800 --> 00:13:01,200
the question at that moment is do we

00:12:59,360 --> 00:13:02,079
need one now do we spin this up again

00:13:01,200 --> 00:13:05,279
already

00:13:02,079 --> 00:13:07,440
or are we going to assume

00:13:05,279 --> 00:13:09,519
and hope we don't get a double failure

00:13:07,440 --> 00:13:11,760
or given that it's only partially

00:13:09,519 --> 00:13:13,279
impacted is this sufficient for us for

00:13:11,760 --> 00:13:15,040
now

00:13:13,279 --> 00:13:16,639
so one of our priorities actually was to

00:13:15,040 --> 00:13:18,880
respin that new dr site

00:13:16,639 --> 00:13:20,639
so that in case something else happened

00:13:18,880 --> 00:13:21,920
we could do this

00:13:20,639 --> 00:13:24,720
and i'll come back to why that was

00:13:21,920 --> 00:13:28,160
trivial for us it's pretty much because

00:13:24,720 --> 00:13:28,160
i'll be using infrastructure's code

00:13:30,240 --> 00:13:34,079
why did we survive this why did we

00:13:32,639 --> 00:13:37,680
really have not that much

00:13:34,079 --> 00:13:38,079
impact um we've been saying this for a

00:13:37,680 --> 00:13:40,000
year

00:13:38,079 --> 00:13:42,160
in the devops movement but although made

00:13:40,000 --> 00:13:44,800
all the things is really what saved us

00:13:42,160 --> 00:13:46,240
we really use infrastructure as good we

00:13:44,800 --> 00:13:47,920
really use

00:13:46,240 --> 00:13:49,600
everything under configuration

00:13:47,920 --> 00:13:50,399
management we have desired state in

00:13:49,600 --> 00:13:53,600
place

00:13:50,399 --> 00:13:54,800
and every single component of a stack is

00:13:53,600 --> 00:13:56,480
matched

00:13:54,800 --> 00:13:58,320
while we see a lot of people out there

00:13:56,480 --> 00:14:00,720
we're doing for circus code up to a way

00:13:58,320 --> 00:14:02,639
where they just provision something

00:14:00,720 --> 00:14:04,160
up to the operating system level or even

00:14:02,639 --> 00:14:06,320
up to the middle where

00:14:04,160 --> 00:14:07,920
but don't go into the application level

00:14:06,320 --> 00:14:08,720
and have different themes that need to

00:14:07,920 --> 00:14:11,839
come in

00:14:08,720 --> 00:14:13,760
and build the application on top of it

00:14:11,839 --> 00:14:15,360
we basically spin up everything from

00:14:13,760 --> 00:14:17,519
scratch and we automate it

00:14:15,360 --> 00:14:18,560
all the way to like if a box disappears

00:14:17,519 --> 00:14:19,839
i spin it up again

00:14:18,560 --> 00:14:22,720
it's gonna be perfectly a part of the

00:14:19,839 --> 00:14:22,720
cluster it's gonna work

00:14:22,959 --> 00:14:26,240
so real infrastructural code our

00:14:24,959 --> 00:14:27,760
architecture

00:14:26,240 --> 00:14:29,600
having backups and really the fact that

00:14:27,760 --> 00:14:32,079
we responded to this really fast is what

00:14:29,600 --> 00:14:32,079
saved us

00:14:32,480 --> 00:14:39,760
so we use public we've been using public

00:14:36,639 --> 00:14:41,680
for managing those things we can

00:14:39,760 --> 00:14:43,600
provision vms we can deploy applications

00:14:41,680 --> 00:14:45,760
we can deploy them with database schemas

00:14:43,600 --> 00:14:46,480
and it is one person who can do this it

00:14:45,760 --> 00:14:49,040
is

00:14:46,480 --> 00:14:50,880
nobody else who needs to be involved the

00:14:49,040 --> 00:14:51,519
automation is so that when we spin up a

00:14:50,880 --> 00:14:53,040
node

00:14:51,519 --> 00:14:55,279
the load balancer is going to be

00:14:53,040 --> 00:14:56,160
reconfigured the monitoring is going to

00:14:55,279 --> 00:14:58,560
be adapted

00:14:56,160 --> 00:14:59,440
the databases are going to be clustered

00:14:58,560 --> 00:15:02,480
it's really

00:14:59,440 --> 00:15:04,399
completely automated and everything

00:15:02,480 --> 00:15:05,920
which has been in production for that

00:15:04,399 --> 00:15:08,240
environment is going to

00:15:05,920 --> 00:15:09,360
be exactly the same version when we spin

00:15:08,240 --> 00:15:10,880
it up

00:15:09,360 --> 00:15:12,639
it's going to be deployed from our

00:15:10,880 --> 00:15:13,120
internal vm repositories it's going to

00:15:12,639 --> 00:15:14,880
be

00:15:13,120 --> 00:15:17,199
certainly that it's going to be the same

00:15:14,880 --> 00:15:20,560
package it was before

00:15:17,199 --> 00:15:22,160
we lost the instance and we do that

00:15:20,560 --> 00:15:23,760
through full automation everything is a

00:15:22,160 --> 00:15:25,360
pipeline our purpose code base is a

00:15:23,760 --> 00:15:27,279
pipeline our hero code base as a

00:15:25,360 --> 00:15:29,600
pipeline dns is a pipeline

00:15:27,279 --> 00:15:33,680
our jenkins applications are a pipeline

00:15:29,600 --> 00:15:36,639
so even our pipelines our pipelines

00:15:33,680 --> 00:15:36,959
we do that also in a mindset where we

00:15:36,639 --> 00:15:39,199
are

00:15:36,959 --> 00:15:40,240
completely cloud native we don't own

00:15:39,199 --> 00:15:43,519
hardware

00:15:40,240 --> 00:15:45,839
we use bare metal on demand at a

00:15:43,519 --> 00:15:48,959
fraction of the price of what

00:15:45,839 --> 00:15:50,959
primary cloud providers like aws charge

00:15:48,959 --> 00:15:52,399
we use headset reso vh we use other

00:15:50,959 --> 00:15:54,560
suppliers and we basically can spin up

00:15:52,399 --> 00:15:56,240
new hardware in 120 seconds

00:15:54,560 --> 00:15:57,920
except in the middle of a fire and

00:15:56,240 --> 00:16:00,959
decommission them when we need

00:15:57,920 --> 00:16:03,360
our vms our defined input in code

00:16:00,959 --> 00:16:05,199
we typically use something like ansible

00:16:03,360 --> 00:16:05,839
to boots japanese and then peppa takes

00:16:05,199 --> 00:16:09,120
over

00:16:05,839 --> 00:16:12,560
and actually takes on desired state

00:16:09,120 --> 00:16:15,199
we've been multi-cloud by origin

00:16:12,560 --> 00:16:16,800
we use for every important stack

00:16:15,199 --> 00:16:20,720
multiple suppliers

00:16:16,800 --> 00:16:24,959
and the deployment of that

00:16:20,720 --> 00:16:27,680
is identical the workloads are flat

00:16:24,959 --> 00:16:29,360
and when we have a customer that has a

00:16:27,680 --> 00:16:30,480
disaster recovery site

00:16:29,360 --> 00:16:33,199
it's actually going to be with a

00:16:30,480 --> 00:16:33,199
different supplier

00:16:33,839 --> 00:16:37,519
within those different suppliers we use

00:16:35,279 --> 00:16:39,120
multiple data centers

00:16:37,519 --> 00:16:41,040
and we learned there now that we also

00:16:39,120 --> 00:16:44,320
need to have not only multiple data

00:16:41,040 --> 00:16:47,360
centers but multiple campuses

00:16:44,320 --> 00:16:50,480
and we really are

00:16:47,360 --> 00:16:51,440
completely cloud independent everything

00:16:50,480 --> 00:16:53,680
we built

00:16:51,440 --> 00:16:54,480
is built on top of open source

00:16:53,680 --> 00:16:58,639
components

00:16:54,480 --> 00:17:02,079
it can crash we build for failure

00:16:58,639 --> 00:17:04,880
we can lose a bare metal server and it

00:17:02,079 --> 00:17:05,600
doesn't have impact we can re-bootstrap

00:17:04,880 --> 00:17:07,600
everything and

00:17:05,600 --> 00:17:09,199
only the user-generated content is

00:17:07,600 --> 00:17:11,360
backed up and all of this is

00:17:09,199 --> 00:17:12,480
built on top of open source tools

00:17:11,360 --> 00:17:15,520
everything critical

00:17:12,480 --> 00:17:18,559
for a customer is gonna be redundant

00:17:15,520 --> 00:17:21,919
so yes components can and will

00:17:18,559 --> 00:17:22,959
disappear from our setup and we build it

00:17:21,919 --> 00:17:25,600
cloud agnostic

00:17:22,959 --> 00:17:26,240
a vm is vm it doesn't matter where it

00:17:25,600 --> 00:17:28,640
lives

00:17:26,240 --> 00:17:29,360
it can live in a data center with a

00:17:28,640 --> 00:17:32,000
customer

00:17:29,360 --> 00:17:32,559
it can live in the public cloud it can

00:17:32,000 --> 00:17:36,320
live in

00:17:32,559 --> 00:17:36,320
any flavor of public cloud vendor

00:17:36,880 --> 00:17:40,640
what do we switch from one vendor to

00:17:38,480 --> 00:17:43,679
another one is

00:17:40,640 --> 00:17:45,760
figured out when we deploy it like how

00:17:43,679 --> 00:17:48,480
you deal with public ip addresses

00:17:45,760 --> 00:17:50,559
how you deal with internal networking

00:17:48,480 --> 00:17:52,400
those are puppet profiles that are being

00:17:50,559 --> 00:17:53,919
included based on the facts on where

00:17:52,400 --> 00:17:56,799
things are being deployed

00:17:53,919 --> 00:17:59,039
so if we deploy an application stack in

00:17:56,799 --> 00:17:59,360
one supplier say in ovh and the next day

00:17:59,039 --> 00:18:02,480
we

00:17:59,360 --> 00:18:05,200
move it to say hetzner we

00:18:02,480 --> 00:18:05,919
don't have to change any code it's going

00:18:05,200 --> 00:18:07,120
to be

00:18:05,919 --> 00:18:08,559
high available it's going to have a

00:18:07,120 --> 00:18:11,120
different type theaters but it's still

00:18:08,559 --> 00:18:11,120
going to work

00:18:11,200 --> 00:18:17,520
typically every stack we have is

00:18:14,559 --> 00:18:19,039
isolated specifically for that customer

00:18:17,520 --> 00:18:21,520
single purpose vms

00:18:19,039 --> 00:18:23,360
single purpose database cluster single

00:18:21,520 --> 00:18:25,600
purpose storage cluster

00:18:23,360 --> 00:18:27,120
single purpose load balancers so if

00:18:25,600 --> 00:18:29,919
there was a problem that problem

00:18:27,120 --> 00:18:31,760
is only going to be impacted for that

00:18:29,919 --> 00:18:34,080
specific project for that specific

00:18:31,760 --> 00:18:36,960
customer

00:18:34,080 --> 00:18:40,799
and everything is multi-data center so

00:18:36,960 --> 00:18:43,840
even if a data center completely crashes

00:18:40,799 --> 00:18:43,840
it's gonna work

00:18:44,160 --> 00:18:48,000
obviously what we learned now is that we

00:18:46,080 --> 00:18:50,480
need multi-campus

00:18:48,000 --> 00:18:51,760
data centers if they are on the same

00:18:50,480 --> 00:18:54,080
campus and if they're

00:18:51,760 --> 00:18:57,120
close to each other probably not gonna

00:18:54,080 --> 00:18:58,320
work in the future

00:18:57,120 --> 00:19:00,720
if we build things which are high

00:18:58,320 --> 00:19:01,520
available that means we cannot use local

00:19:00,720 --> 00:19:04,559
files

00:19:01,520 --> 00:19:04,960
if we have local files we use cluster or

00:19:04,559 --> 00:19:07,280
we

00:19:04,960 --> 00:19:08,480
still have the rbd clusters which we're

00:19:07,280 --> 00:19:10,080
using

00:19:08,480 --> 00:19:11,919
to actually have active passive or in

00:19:10,080 --> 00:19:15,440
the gluster case multi-active

00:19:11,919 --> 00:19:18,720
nodes every single of our mysql setups

00:19:15,440 --> 00:19:21,440
is replicated our elastics

00:19:18,720 --> 00:19:22,720
are all backup they're all multiple

00:19:21,440 --> 00:19:24,400
nodes

00:19:22,720 --> 00:19:26,559
unless of course if they're just for

00:19:24,400 --> 00:19:28,320
performance and then we can regenerate

00:19:26,559 --> 00:19:30,000
the data sets if we need them

00:19:28,320 --> 00:19:31,600
and we also have multiple instances of

00:19:30,000 --> 00:19:35,600
our queueing systems and all of them so

00:19:31,600 --> 00:19:35,600
everything we build is high available

00:19:36,080 --> 00:19:39,600
our vms are on the local disk which

00:19:37,919 --> 00:19:42,799
takes away

00:19:39,600 --> 00:19:44,640
the need of having a centralized file

00:19:42,799 --> 00:19:46,960
system to put the images on

00:19:44,640 --> 00:19:48,640
and we can spin up those instances again

00:19:46,960 --> 00:19:51,440
because they're 100 per

00:19:48,640 --> 00:19:52,559
ties there's no difference in config

00:19:51,440 --> 00:19:56,000
when we spin them up so

00:19:52,559 --> 00:19:59,039
we treat our vms already as disposable

00:19:56,000 --> 00:20:00,400
and for the other user data it's either

00:19:59,039 --> 00:20:02,880
on application level

00:20:00,400 --> 00:20:04,840
or it's in a distributed storage system

00:20:02,880 --> 00:20:08,559
and we do not use rate for

00:20:04,840 --> 00:20:10,159
rpms because all the data is already

00:20:08,559 --> 00:20:11,919
spread over multiple nodes on the

00:20:10,159 --> 00:20:13,919
network

00:20:11,919 --> 00:20:16,000
obviously our backups are automated

00:20:13,919 --> 00:20:19,600
they're part of every puppet profile

00:20:16,000 --> 00:20:20,080
and are always both onsite and on remote

00:20:19,600 --> 00:20:23,840
site

00:20:20,080 --> 00:20:23,840
which is why we could restore so fast

00:20:25,440 --> 00:20:29,200
where is their data documentation live

00:20:27,679 --> 00:20:31,360
well our documentation lives

00:20:29,200 --> 00:20:32,720
in an mk docs based git repository which

00:20:31,360 --> 00:20:34,720
is typically hosted

00:20:32,720 --> 00:20:35,840
accessible for everybody but in the case

00:20:34,720 --> 00:20:39,280
of disaster

00:20:35,840 --> 00:20:40,960
people can just run an mkdoc surf on the

00:20:39,280 --> 00:20:42,880
local copy of their documentation which

00:20:40,960 --> 00:20:44,720
might be slightly out of date

00:20:42,880 --> 00:20:46,240
but they have the local documentation

00:20:44,720 --> 00:20:48,880
they have everything available which

00:20:46,240 --> 00:20:53,919
they need

00:20:48,880 --> 00:20:53,919
so we did do learn a couple of lessons

00:20:54,640 --> 00:20:58,720
one of the things we were lucky with is

00:20:57,440 --> 00:21:02,080
that we still have

00:20:58,720 --> 00:21:03,360
spare material around because if such a

00:21:02,080 --> 00:21:05,600
case happens

00:21:03,360 --> 00:21:07,120
your supplier is gonna at some point be

00:21:05,600 --> 00:21:09,679
short on hardware

00:21:07,120 --> 00:21:10,799
and you might need more than they have

00:21:09,679 --> 00:21:13,840
available

00:21:10,799 --> 00:21:15,600
so we could switch over fast we had a

00:21:13,840 --> 00:21:16,000
little bit and not that much we had a

00:21:15,600 --> 00:21:20,799
little bit

00:21:16,000 --> 00:21:20,799
more resources available than we needed

00:21:21,520 --> 00:21:26,480
we also knew that we could provision

00:21:24,240 --> 00:21:29,679
those resources on multiple

00:21:26,480 --> 00:21:31,919
providers the other thing is

00:21:29,679 --> 00:21:32,799
obviously that a data center is not a

00:21:31,919 --> 00:21:37,520
data center

00:21:32,799 --> 00:21:40,080
um even if it's different buildings

00:21:37,520 --> 00:21:41,679
on the same campus you want to spread

00:21:40,080 --> 00:21:43,679
redundancy there

00:21:41,679 --> 00:21:46,400
obviously you need to figure out what

00:21:43,679 --> 00:21:49,120
your customer wants to pay for

00:21:46,400 --> 00:21:50,480
what or what value you want to put to it

00:21:49,120 --> 00:21:52,480
but

00:21:50,480 --> 00:21:54,320
spreading it geographically over

00:21:52,480 --> 00:21:57,760
multiple cities

00:21:54,320 --> 00:21:59,360
obviously really important

00:21:57,760 --> 00:22:01,440
the shoemaker problem is definitely one

00:21:59,360 --> 00:22:04,400
we need to fix

00:22:01,440 --> 00:22:05,280
internal services are often the ones you

00:22:04,400 --> 00:22:07,120
spend

00:22:05,280 --> 00:22:08,480
least amount of time on the least amount

00:22:07,120 --> 00:22:10,799
priority

00:22:08,480 --> 00:22:11,679
but they are still critical if you

00:22:10,799 --> 00:22:13,840
depend

00:22:11,679 --> 00:22:16,240
on certain services in order to be able

00:22:13,840 --> 00:22:17,280
to spin up your infrastructure

00:22:16,240 --> 00:22:20,159
you need to make sure that they're

00:22:17,280 --> 00:22:20,159
always available

00:22:21,120 --> 00:22:24,880
not something we learned something i've

00:22:23,360 --> 00:22:27,520
known for

00:22:24,880 --> 00:22:29,200
close to two decades is that it is a

00:22:27,520 --> 00:22:32,559
 dns problem

00:22:29,200 --> 00:22:33,440
we really want to have control over the

00:22:32,559 --> 00:22:35,919
dns of

00:22:33,440 --> 00:22:37,360
all the production sites you run because

00:22:35,919 --> 00:22:39,440
if some third party

00:22:37,360 --> 00:22:41,360
is the only one who has access over that

00:22:39,440 --> 00:22:43,840
dns

00:22:41,360 --> 00:22:45,520
then you might be in trouble and if it's

00:22:43,840 --> 00:22:47,360
not a dns problem

00:22:45,520 --> 00:22:50,159
that's potentially an interview problem

00:22:47,360 --> 00:22:50,159
in 2021

00:22:51,120 --> 00:22:57,120
it was a long night

00:22:54,559 --> 00:22:59,120
and i once again want to thank everybody

00:22:57,120 --> 00:23:01,039
who helped

00:22:59,120 --> 00:23:02,400
from the internal team who helped to get

00:23:01,039 --> 00:23:06,320
that stack up and running

00:23:02,400 --> 00:23:07,840
again after eight hours

00:23:06,320 --> 00:23:09,600
the two people who started went to bed

00:23:07,840 --> 00:23:11,200
and went to sleep and

00:23:09,600 --> 00:23:12,880
got a couple of hours of sleep and went

00:23:11,200 --> 00:23:14,640
back to figure out what the series was

00:23:12,880 --> 00:23:17,919
but

00:23:14,640 --> 00:23:23,840
it really is a team effort to get this

00:23:17,919 --> 00:23:23,840
once implemented but also recovered

00:23:24,000 --> 00:23:27,360
we survived this because of our use of

00:23:26,080 --> 00:23:30,559
open source tools

00:23:27,360 --> 00:23:32,960
because of our use of sane architectures

00:23:30,559 --> 00:23:34,480
and because of thinking about how to

00:23:32,960 --> 00:23:35,280
deploy software and how to keep it

00:23:34,480 --> 00:23:39,120
running

00:23:35,280 --> 00:23:42,000
even in this case and i hope that

00:23:39,120 --> 00:23:44,159
you actually do the same so that if the

00:23:42,000 --> 00:23:46,799
next time somebody calls and says hey

00:23:44,159 --> 00:23:48,720
my data center is on fire you go like

00:23:46,799 --> 00:23:51,039
yeah it's only one data center

00:23:48,720 --> 00:23:52,960
that's not really a big problem which is

00:23:51,039 --> 00:23:55,919
kind of what the state of our mind was

00:23:52,960 --> 00:23:58,799
after half an hour realizing it's only

00:23:55,919 --> 00:23:58,799
three data centers

00:23:58,960 --> 00:24:07,039
so with that this meme is now held again

00:24:04,640 --> 00:24:08,720
it worked on my machine and it really

00:24:07,039 --> 00:24:12,000
was in fire

00:24:08,720 --> 00:24:19,840
so thank you for your attention

00:24:12,000 --> 00:24:19,840
and start a discussion

00:24:20,710 --> 00:24:25,900
[Music]

00:24:30,000 --> 00:24:32,080

YouTube URL: https://www.youtube.com/watch?v=zDfH0DpHT3s


