Title: stackconf 2021 | Kubernetes Native Continuous Deployment with FluxCD, Flagger, and Linkerd
Publication date: 2021-06-24
Playlist: stackconf online 2021
Description: 
	by Or Elimelech  and Leonid Belkind

With many services going online that have rapidly growing user bases plus the expectation of being both resilient and innovative at the same time, continuous delivery has become a necessary practice. By employing practices like automated gating, CD helps organizations grow with confidence, and limit (or completely circumvent) having to wait for manual checks and approvals.
This talk will discuss and demonstrate a Kubernetes native CD pipeline using FluxCD, Flagger and Linkerd. I will discuss the benefits we gained in the process of employing this pipeline at StackPulse.Three key learnings audience will take away from the session:

- How to increase velocity and deployment safety by adopting CD
- How great tooling can reflect your culture â€” not change it


NETWAYS
Konferenzen: https://www.netways.de/events
Schulungen: https://www.netways.de/schulungen
Shop: https://shop.netways.de/
Blog: http://blog.netways.de/
NWS: https://nws.netways.de 

Webinare
Archiv Link: https://www.netways.de/netways/webinare/

Social Media
SlideShare: http://de.slideshare.net/netways
YouTube: https://www.netways.de/youtube
Facebook: https://www.facebook.com/netways
Twitter: https://twitter.com/netways
Instagram: https://www.instagram.com/netwaysgmbh/


Musik: https://www.frametraxx.de/
Captions: 
	00:00:05,660 --> 00:00:13,119
[Applause]

00:00:06,120 --> 00:00:13,119
[Music]

00:00:13,440 --> 00:00:16,240
hello

00:00:14,000 --> 00:00:17,520
and welcome to this presentation about

00:00:16,240 --> 00:00:20,240
kubernetes native

00:00:17,520 --> 00:00:20,880
continuous deployment made with flux

00:00:20,240 --> 00:00:23,439
flagger

00:00:20,880 --> 00:00:25,199
linker d and additional tools my name is

00:00:23,439 --> 00:00:26,160
leonids i'm the chief technology officer

00:00:25,199 --> 00:00:28,480
at stackpoles

00:00:26,160 --> 00:00:29,519
with me is ore our site reliability

00:00:28,480 --> 00:00:31,840
engineering leads

00:00:29,519 --> 00:00:32,880
and in this presentation we will tell

00:00:31,840 --> 00:00:35,200
you all about

00:00:32,880 --> 00:00:36,160
our continuous deployment system so

00:00:35,200 --> 00:00:38,800
we'll start by

00:00:36,160 --> 00:00:40,800
explaining why do we even need it and

00:00:38,800 --> 00:00:43,280
how important it is

00:00:40,800 --> 00:00:44,960
then we will talk from the high level

00:00:43,280 --> 00:00:46,239
perspective that will be my part in this

00:00:44,960 --> 00:00:49,360
conversation

00:00:46,239 --> 00:00:51,840
about how it works and then we will

00:00:49,360 --> 00:00:52,960
zoom in on each and every component in

00:00:51,840 --> 00:00:55,840
the system

00:00:52,960 --> 00:00:56,640
and ask questions hopefully difficult

00:00:55,840 --> 00:00:59,440
ones

00:00:56,640 --> 00:01:00,079
about why certain architectural choices

00:00:59,440 --> 00:01:02,079
were made

00:01:00,079 --> 00:01:03,440
what is the exact function of each and

00:01:02,079 --> 00:01:05,280
every component what are the

00:01:03,440 --> 00:01:07,040
alternatives that we considered and

00:01:05,280 --> 00:01:08,799
decided not to choose

00:01:07,040 --> 00:01:10,640
that's it hopefully in the end of this

00:01:08,799 --> 00:01:13,119
talk we will leave you with a lot of

00:01:10,640 --> 00:01:13,840
lessons learned and food for thought on

00:01:13,119 --> 00:01:16,400
how to build

00:01:13,840 --> 00:01:18,960
your own continuous deployment for

00:01:16,400 --> 00:01:22,159
kubernetes based applications

00:01:18,960 --> 00:01:24,640
so first and foremost we are a

00:01:22,159 --> 00:01:26,240
fast-growing enterprise grade software

00:01:24,640 --> 00:01:28,880
as a service solution

00:01:26,240 --> 00:01:30,640
as a result when penetrating the market

00:01:28,880 --> 00:01:34,320
since we are a young company

00:01:30,640 --> 00:01:37,360
being able to deliver new functionality

00:01:34,320 --> 00:01:39,759
fast and in a reliable manner is not

00:01:37,360 --> 00:01:44,960
just a technical consideration for us

00:01:39,759 --> 00:01:47,920
it is a business critical capability

00:01:44,960 --> 00:01:48,720
furthermore since we are delivering as i

00:01:47,920 --> 00:01:52,560
already mentioned

00:01:48,720 --> 00:01:55,600
an enterprise grades sas our customers

00:01:52,560 --> 00:01:58,000
rely on us to be there for them we are

00:01:55,600 --> 00:02:00,399
an automation and orchestration platform

00:01:58,000 --> 00:02:01,840
which means our customers rely on an

00:02:00,399 --> 00:02:04,320
ability to execute

00:02:01,840 --> 00:02:05,280
their automated workflows every time

00:02:04,320 --> 00:02:07,840
where they need it

00:02:05,280 --> 00:02:09,200
these workflows may be mission critical

00:02:07,840 --> 00:02:12,160
for their environments

00:02:09,200 --> 00:02:13,520
and we should be there for them wherever

00:02:12,160 --> 00:02:15,280
and whenever they need them

00:02:13,520 --> 00:02:17,040
as a service of course and as an

00:02:15,280 --> 00:02:21,120
organization we are

00:02:17,040 --> 00:02:22,080
soc2 compliant hipaa compliant iso 27001

00:02:21,120 --> 00:02:24,400
compliant

00:02:22,080 --> 00:02:25,360
which means that we should be extremely

00:02:24,400 --> 00:02:29,920
aware

00:02:25,360 --> 00:02:31,680
of what goes on into our production

00:02:29,920 --> 00:02:34,080
we have extensive prior experience in

00:02:31,680 --> 00:02:38,080
building software as a service solutions

00:02:34,080 --> 00:02:40,959
and every time we did pretty good

00:02:38,080 --> 00:02:42,080
based to our own scores on continuous

00:02:40,959 --> 00:02:44,560
integration

00:02:42,080 --> 00:02:45,840
we do a lot of automated testing we do a

00:02:44,560 --> 00:02:47,760
lot of gating

00:02:45,840 --> 00:02:48,879
but this is actually the first time

00:02:47,760 --> 00:02:51,200
where we're taking it

00:02:48,879 --> 00:02:52,000
all the way to continuous deployments

00:02:51,200 --> 00:02:54,480
because we are

00:02:52,000 --> 00:02:56,160
so aware of the costs that the

00:02:54,480 --> 00:02:58,239
organization had to pay

00:02:56,160 --> 00:02:59,360
when stopping just at the continuous

00:02:58,239 --> 00:03:02,000
integration

00:02:59,360 --> 00:03:03,840
so for us historically continuous

00:03:02,000 --> 00:03:04,239
deployment was pretty much the first

00:03:03,840 --> 00:03:07,440
thing

00:03:04,239 --> 00:03:08,879
we introduced to our architecture way

00:03:07,440 --> 00:03:11,920
before we developed

00:03:08,879 --> 00:03:14,480
large chunks of business logic

00:03:11,920 --> 00:03:16,040
our stack is pretty straightforward we

00:03:14,480 --> 00:03:18,560
are a kubernetes

00:03:16,040 --> 00:03:20,159
microservices-based operations we use

00:03:18,560 --> 00:03:23,440
github

00:03:20,159 --> 00:03:26,319
as our source versioning

00:03:23,440 --> 00:03:27,040
we run a pretty standard multi-repo

00:03:26,319 --> 00:03:29,120
approach

00:03:27,040 --> 00:03:30,480
on top of github therefore you could

00:03:29,120 --> 00:03:33,440
pretty much imagine

00:03:30,480 --> 00:03:34,799
how the development life cycle is from

00:03:33,440 --> 00:03:36,640
this point on of course

00:03:34,799 --> 00:03:38,720
we are moving on to explain how the

00:03:36,640 --> 00:03:42,159
continuous delivery works

00:03:38,720 --> 00:03:45,040
the strategy that we chose is a canary

00:03:42,159 --> 00:03:47,040
deployment which means that every time a

00:03:45,040 --> 00:03:47,760
new business logic in one of our

00:03:47,040 --> 00:03:50,480
services

00:03:47,760 --> 00:03:52,480
is being delivered to production we

00:03:50,480 --> 00:03:55,360
progressively

00:03:52,480 --> 00:03:56,400
shift parts of the user activity traffic

00:03:55,360 --> 00:03:59,519
for us

00:03:56,400 --> 00:04:01,840
to these new versions while continuously

00:03:59,519 --> 00:04:03,760
monitoring how they are doing and only

00:04:01,840 --> 00:04:05,840
when we are satisfied with the results

00:04:03,760 --> 00:04:08,080
will we promote the newly deployed

00:04:05,840 --> 00:04:11,120
functionality to become as a primary

00:04:08,080 --> 00:04:14,319
service handling the traffic of all

00:04:11,120 --> 00:04:16,079
our customers activities such processes

00:04:14,319 --> 00:04:18,880
can happen by the way in parallel

00:04:16,079 --> 00:04:19,840
for multiple services and for us being

00:04:18,880 --> 00:04:22,479
continuous

00:04:19,840 --> 00:04:23,199
means that during the day our system

00:04:22,479 --> 00:04:26,240
even in

00:04:23,199 --> 00:04:28,960
less busy days is probably handling tens

00:04:26,240 --> 00:04:29,680
of such deployments which of course

00:04:28,960 --> 00:04:31,919
could grow

00:04:29,680 --> 00:04:33,600
as the company grows and the team grows

00:04:31,919 --> 00:04:37,199
so how does it work

00:04:33,600 --> 00:04:39,520
of course it all begins with a developer

00:04:37,199 --> 00:04:40,960
delivering certain business logic or

00:04:39,520 --> 00:04:43,120
configuration changes

00:04:40,960 --> 00:04:45,680
into a main branch of one of the service

00:04:43,120 --> 00:04:48,720
repositories

00:04:45,680 --> 00:04:51,040
that delivery triggers a

00:04:48,720 --> 00:04:51,759
continuous integration pipeline we

00:04:51,040 --> 00:04:54,320
happen to use

00:04:51,759 --> 00:04:55,199
circle ci for our continuous integration

00:04:54,320 --> 00:04:58,400
pipelines

00:04:55,199 --> 00:05:01,840
that includes tests on various levels

00:04:58,400 --> 00:05:02,320
building container images and deploying

00:05:01,840 --> 00:05:05,680
them

00:05:02,320 --> 00:05:08,720
into artifactory so we use particularly

00:05:05,680 --> 00:05:10,880
google container registry as our store

00:05:08,720 --> 00:05:12,000
for our main artifacts the ones that we

00:05:10,880 --> 00:05:15,440
will focus on

00:05:12,000 --> 00:05:17,680
which are of course container images

00:05:15,440 --> 00:05:18,960
this is at the end of this continuous

00:05:17,680 --> 00:05:22,080
integration pipeline

00:05:18,960 --> 00:05:24,479
where the artifacts are updated

00:05:22,080 --> 00:05:25,919
as a result of a successful build this

00:05:24,479 --> 00:05:26,639
is where the continuous deployment

00:05:25,919 --> 00:05:29,759
process

00:05:26,639 --> 00:05:32,800
actually begins so we

00:05:29,759 --> 00:05:35,919
push the artifacts and then

00:05:32,800 --> 00:05:38,720
this process triggers flux

00:05:35,919 --> 00:05:40,320
continuous deployments that listens for

00:05:38,720 --> 00:05:43,520
lack of a better technical term

00:05:40,320 --> 00:05:46,000
to these updates both in the releases on

00:05:43,520 --> 00:05:47,360
github service repos as well as in the

00:05:46,000 --> 00:05:50,400
image repository

00:05:47,360 --> 00:05:51,440
and that's what triggers the process

00:05:50,400 --> 00:05:53,919
of course at the beginning of the

00:05:51,440 --> 00:05:55,520
process we synchronize

00:05:53,919 --> 00:05:56,960
with the latest changes in all the

00:05:55,520 --> 00:05:59,600
configuration files

00:05:56,960 --> 00:06:00,560
as well as the binaries and when

00:05:59,600 --> 00:06:03,520
conditions

00:06:00,560 --> 00:06:04,639
are sufficient to begin the actual

00:06:03,520 --> 00:06:07,919
deployment

00:06:04,639 --> 00:06:09,120
we initiate it by updating the canary

00:06:07,919 --> 00:06:11,840
deployments

00:06:09,120 --> 00:06:12,720
that constantly exists in our kubernetes

00:06:11,840 --> 00:06:15,759
clusters

00:06:12,720 --> 00:06:18,960
we update it with the relevant version

00:06:15,759 --> 00:06:20,319
of the container image that we are about

00:06:18,960 --> 00:06:24,160
to deploy

00:06:20,319 --> 00:06:26,960
and we start increasing the amount of

00:06:24,160 --> 00:06:28,880
canary pods right the actual containers

00:06:26,960 --> 00:06:31,440
that will be handling traffic

00:06:28,880 --> 00:06:33,440
that belong to this new version that we

00:06:31,440 --> 00:06:35,919
are deploying to production

00:06:33,440 --> 00:06:36,720
from this point on the control over the

00:06:35,919 --> 00:06:39,600
process

00:06:36,720 --> 00:06:41,840
moves from the githubs operator flux

00:06:39,600 --> 00:06:44,560
whose main purpose is to initiate it

00:06:41,840 --> 00:06:45,919
into progressive deployment operator

00:06:44,560 --> 00:06:49,199
flagger

00:06:45,919 --> 00:06:51,120
so the main duty of flagger and we will

00:06:49,199 --> 00:06:54,319
talk about it much much more

00:06:51,120 --> 00:06:55,039
is to gradually start shifting the

00:06:54,319 --> 00:06:57,680
traffic

00:06:55,039 --> 00:07:00,080
towards new versions of the components

00:06:57,680 --> 00:07:02,560
while continuously validating

00:07:00,080 --> 00:07:03,919
that they are functioning according to

00:07:02,560 --> 00:07:07,039
our expectations

00:07:03,919 --> 00:07:10,080
so at first like we said

00:07:07,039 --> 00:07:13,599
the amount of pods will be adjusted and

00:07:10,080 --> 00:07:16,800
a traffic split configuration

00:07:13,599 --> 00:07:17,280
will be defined to start sending let's

00:07:16,800 --> 00:07:20,720
say

00:07:17,280 --> 00:07:22,960
first 10 of the traffic

00:07:20,720 --> 00:07:24,560
by the way at this point or maybe even

00:07:22,960 --> 00:07:28,400
prior to this point

00:07:24,560 --> 00:07:29,199
we trigger execution of end-to-end test

00:07:28,400 --> 00:07:31,440
sequences

00:07:29,199 --> 00:07:33,039
on this component in production to make

00:07:31,440 --> 00:07:34,720
sure that we even pass the gate that

00:07:33,039 --> 00:07:38,000
prepares us to this thing

00:07:34,720 --> 00:07:40,720
but still let's say that 10 of

00:07:38,000 --> 00:07:41,840
all production traffic of all users is

00:07:40,720 --> 00:07:44,080
already flowing

00:07:41,840 --> 00:07:45,360
through these new versions we would

00:07:44,080 --> 00:07:48,160
define a period of time

00:07:45,360 --> 00:07:49,120
all that of course is configurable and

00:07:48,160 --> 00:07:52,240
we would

00:07:49,120 --> 00:07:53,520
scrape health metrics from our codes

00:07:52,240 --> 00:07:56,720
using prometheus

00:07:53,520 --> 00:07:57,440
to make a decision whether these canary

00:07:56,720 --> 00:07:59,680
pods

00:07:57,440 --> 00:08:00,960
are functioning sufficiently well and

00:07:59,680 --> 00:08:03,280
are now candidates

00:08:00,960 --> 00:08:05,280
to be increased in the amount of

00:08:03,280 --> 00:08:07,360
production traffic they're handling

00:08:05,280 --> 00:08:09,680
let's say that this was indeed the case

00:08:07,360 --> 00:08:12,000
we update traffic split again

00:08:09,680 --> 00:08:13,120
we promote it either by five percent or

00:08:12,000 --> 00:08:15,120
by ten percent

00:08:13,120 --> 00:08:16,560
that of course is again configurable

00:08:15,120 --> 00:08:20,000
both the time interval

00:08:16,560 --> 00:08:23,440
and the actual jump and again

00:08:20,000 --> 00:08:25,120
query various metrics to make sure

00:08:23,440 --> 00:08:27,759
that they are functioning according to

00:08:25,120 --> 00:08:31,199
expectations

00:08:27,759 --> 00:08:34,240
if at any point during the process

00:08:31,199 --> 00:08:36,959
the results of the query make us believe

00:08:34,240 --> 00:08:38,800
that the components are not functioning

00:08:36,959 --> 00:08:40,880
according to our expectations

00:08:38,800 --> 00:08:43,200
we will immediately trigger the canary

00:08:40,880 --> 00:08:44,959
rollback in essence secondary rollback

00:08:43,200 --> 00:08:47,680
is just shifting the traffic back

00:08:44,959 --> 00:08:49,600
to existing untouched primary service

00:08:47,680 --> 00:08:51,200
codes

00:08:49,600 --> 00:08:54,240
decreasing the amount of replicas on the

00:08:51,200 --> 00:08:56,320
canary deployments to zero

00:08:54,240 --> 00:08:58,320
and of course notifying the relevant

00:08:56,320 --> 00:09:01,839
parties about the logical

00:08:58,320 --> 00:09:04,880
failure of a canary but if the process

00:09:01,839 --> 00:09:06,880
continues successfully and we again

00:09:04,880 --> 00:09:09,920
increase the amount of traffic going

00:09:06,880 --> 00:09:13,040
through canary pods even more

00:09:09,920 --> 00:09:15,279
and then even more all the way

00:09:13,040 --> 00:09:16,240
to the point where we are confident in

00:09:15,279 --> 00:09:19,440
their functioning

00:09:16,240 --> 00:09:21,760
so that we can shift it to 100

00:09:19,440 --> 00:09:24,160
what happens then is the logical

00:09:21,760 --> 00:09:26,800
promotion process of newly deployed

00:09:24,160 --> 00:09:28,080
functionality to become the primary and

00:09:26,800 --> 00:09:32,080
it works this way

00:09:28,080 --> 00:09:34,800
so what happens is that we first

00:09:32,080 --> 00:09:36,000
take the resource definitions of our

00:09:34,800 --> 00:09:38,240
canary deployments

00:09:36,000 --> 00:09:39,760
that of course contain all the

00:09:38,240 --> 00:09:41,920
configuration changes

00:09:39,760 --> 00:09:43,839
as well as the container image version

00:09:41,920 --> 00:09:46,560
with all the business logic changes

00:09:43,839 --> 00:09:47,680
and we override the primary deployments

00:09:46,560 --> 00:09:50,800
for that

00:09:47,680 --> 00:09:54,320
particular service this

00:09:50,800 --> 00:09:57,040
in essence triggers a very kubernetes

00:09:54,320 --> 00:09:57,920
native upgrade process where a new

00:09:57,040 --> 00:10:00,160
replica set

00:09:57,920 --> 00:10:01,920
is created with the container image and

00:10:00,160 --> 00:10:02,720
the configurations belonging to the new

00:10:01,920 --> 00:10:05,200
version

00:10:02,720 --> 00:10:06,480
new pods are created in this replica set

00:10:05,200 --> 00:10:08,480
and the moment

00:10:06,480 --> 00:10:10,240
their health and liveliness probe

00:10:08,480 --> 00:10:13,680
reports positive

00:10:10,240 --> 00:10:16,000
health and liveliness every time a

00:10:13,680 --> 00:10:17,680
pod from the previous replica set is

00:10:16,000 --> 00:10:20,720
being gradually terminated

00:10:17,680 --> 00:10:22,640
and replaced with the new pot

00:10:20,720 --> 00:10:24,560
this way at the end of this kubernetes

00:10:22,640 --> 00:10:26,880
native process we reach a state

00:10:24,560 --> 00:10:27,680
where there is a primary service

00:10:26,880 --> 00:10:29,440
deployment

00:10:27,680 --> 00:10:30,720
with exactly the same settings as our

00:10:29,440 --> 00:10:33,760
original canary one

00:10:30,720 --> 00:10:34,640
and with the fully populated replica

00:10:33,760 --> 00:10:37,680
sets

00:10:34,640 --> 00:10:40,800
at which point we decrease the amount of

00:10:37,680 --> 00:10:42,640
canary pods again to zero we shift

00:10:40,800 --> 00:10:44,399
of course all the traffic on the traffic

00:10:42,640 --> 00:10:47,279
split level we already did this

00:10:44,399 --> 00:10:48,320
to primary parts and that actually

00:10:47,279 --> 00:10:51,440
constitutes

00:10:48,320 --> 00:10:52,320
a successful completion of our canary

00:10:51,440 --> 00:10:55,519
process

00:10:52,320 --> 00:10:58,000
so as you can see it is designed to be

00:10:55,519 --> 00:10:59,360
very native for the kubernetes

00:10:58,000 --> 00:11:02,480
environment

00:10:59,360 --> 00:11:04,800
to dive in a bit more during various

00:11:02,480 --> 00:11:07,360
stages of our progressive deployment

00:11:04,800 --> 00:11:07,920
we use the capability that flagger has

00:11:07,360 --> 00:11:11,120
and

00:11:07,920 --> 00:11:13,760
we call out external web hooks

00:11:11,120 --> 00:11:14,640
to our own service we call it puerta

00:11:13,760 --> 00:11:17,120
because it does

00:11:14,640 --> 00:11:17,839
certain gates and in this service we

00:11:17,120 --> 00:11:20,000
enrich

00:11:17,839 --> 00:11:21,839
the progressive deployments with

00:11:20,000 --> 00:11:25,040
additional functionality

00:11:21,839 --> 00:11:27,040
for example in a pre-roll out

00:11:25,040 --> 00:11:28,880
webhook which means before we start

00:11:27,040 --> 00:11:31,920
shifting the production traffic

00:11:28,880 --> 00:11:35,360
we trigger our end-to-end tests

00:11:31,920 --> 00:11:38,000
right that cover a lot of user scenarios

00:11:35,360 --> 00:11:39,519
synthetically in order to increase our

00:11:38,000 --> 00:11:42,800
confidence in the fact that

00:11:39,519 --> 00:11:45,839
we can promote this thing because most

00:11:42,800 --> 00:11:48,320
important hopefully within time all user

00:11:45,839 --> 00:11:51,519
flows have been tested

00:11:48,320 --> 00:11:52,320
we do more than just prometheus query

00:11:51,519 --> 00:11:54,160
and we check

00:11:52,320 --> 00:11:55,760
success rates and various latency

00:11:54,160 --> 00:11:59,040
metrics as a part of every

00:11:55,760 --> 00:12:01,040
rollout promotion on a post rollout for

00:11:59,040 --> 00:12:04,639
instance inside our staging environments

00:12:01,040 --> 00:12:07,839
we go back to our github repos and mark

00:12:04,639 --> 00:12:11,120
the release only after a successful

00:12:07,839 --> 00:12:12,959
canary promotion in in production

00:12:11,120 --> 00:12:15,279
so we can enrich this process and we

00:12:12,959 --> 00:12:18,000
actually do that quite a lot

00:12:15,279 --> 00:12:18,399
last but definitely not least in the

00:12:18,000 --> 00:12:21,519
list

00:12:18,399 --> 00:12:22,160
of tools or processes that in our view

00:12:21,519 --> 00:12:25,120
are

00:12:22,160 --> 00:12:25,920
very imperative to succeed in continuous

00:12:25,120 --> 00:12:28,079
deployment

00:12:25,920 --> 00:12:30,399
is our ability to roll out new

00:12:28,079 --> 00:12:33,760
functionality or functionality changes

00:12:30,399 --> 00:12:34,800
under a feature flag so what it is in

00:12:33,760 --> 00:12:37,839
essence

00:12:34,800 --> 00:12:38,240
is that uh on the development r d level

00:12:37,839 --> 00:12:40,959
we

00:12:38,240 --> 00:12:41,519
surround changes in business logic with

00:12:40,959 --> 00:12:44,079
a

00:12:41,519 --> 00:12:45,760
request sent to an external system in

00:12:44,079 --> 00:12:47,680
our case it's an open source project

00:12:45,760 --> 00:12:49,839
called flip t or flipped

00:12:47,680 --> 00:12:51,440
uh and we provide it with a lot of

00:12:49,839 --> 00:12:54,480
details on the session

00:12:51,440 --> 00:12:57,519
and of course which flag which decision

00:12:54,480 --> 00:13:01,040
we are looking for a resolution on

00:12:57,519 --> 00:13:04,480
and that system based on a rule-based

00:13:01,040 --> 00:13:06,480
high-level configurable policy returns

00:13:04,480 --> 00:13:08,000
a verdict for this particular set of

00:13:06,480 --> 00:13:09,279
flag and session data

00:13:08,000 --> 00:13:12,320
whether the functionality should be

00:13:09,279 --> 00:13:14,959
enabled or not relinquishing the control

00:13:12,320 --> 00:13:16,079
over what users will experience right

00:13:14,959 --> 00:13:19,120
from the

00:13:16,079 --> 00:13:21,440
engineering floor to maybe

00:13:19,120 --> 00:13:22,240
reliability engineers and actually even

00:13:21,440 --> 00:13:25,360
all the way

00:13:22,240 --> 00:13:27,519
to our product managers

00:13:25,360 --> 00:13:28,480
just to remind you before starting to

00:13:27,519 --> 00:13:31,760
drill down

00:13:28,480 --> 00:13:34,320
here are our star actors in this movie

00:13:31,760 --> 00:13:34,959
so on the ci side of course we have

00:13:34,320 --> 00:13:37,120
github

00:13:34,959 --> 00:13:38,240
as our source version and configuration

00:13:37,120 --> 00:13:40,560
version repository

00:13:38,240 --> 00:13:42,399
our single source of truth and as i

00:13:40,560 --> 00:13:44,480
already mentioned circle ci

00:13:42,399 --> 00:13:45,440
as our continuous integration

00:13:44,480 --> 00:13:47,120
infrastructure

00:13:45,440 --> 00:13:49,680
today we will not be touching these a

00:13:47,120 --> 00:13:51,440
lot then of course comes the stage the

00:13:49,680 --> 00:13:53,600
very stage we are focusing on

00:13:51,440 --> 00:13:55,440
and here of course the git ups operator

00:13:53,600 --> 00:13:56,480
flux that we already mentioned and we'll

00:13:55,440 --> 00:13:58,639
talk more about

00:13:56,480 --> 00:14:00,079
the progressive deployment operator

00:13:58,639 --> 00:14:04,000
flagger

00:14:00,079 --> 00:14:06,000
linker d our service mesh that

00:14:04,000 --> 00:14:07,120
plays a very important role in our

00:14:06,000 --> 00:14:09,680
ability to do this

00:14:07,120 --> 00:14:12,240
traffic shift and gain confidence that

00:14:09,680 --> 00:14:15,680
indeed canary components are functioning

00:14:12,240 --> 00:14:16,160
and in a post-roll out world our control

00:14:15,680 --> 00:14:18,399
over

00:14:16,160 --> 00:14:19,680
functionality enablement for different

00:14:18,399 --> 00:14:22,480
product sessions

00:14:19,680 --> 00:14:22,880
using this flag flipping that is also

00:14:22,480 --> 00:14:26,240
known

00:14:22,880 --> 00:14:27,360
under a different name as dark launching

00:14:26,240 --> 00:14:29,279
so for the next piece of our

00:14:27,360 --> 00:14:31,279
conversation i'm joined by ore as

00:14:29,279 --> 00:14:32,720
promised don't say i don't deliver

00:14:31,279 --> 00:14:34,399
and we'll drill down into these

00:14:32,720 --> 00:14:35,120
components starting with cd i don't

00:14:34,399 --> 00:14:37,920
think there is

00:14:35,120 --> 00:14:39,600
much interest to dive into ci hopefully

00:14:37,920 --> 00:14:43,440
will make his life difficult

00:14:39,600 --> 00:14:47,040
with really intensive questions so

00:14:43,440 --> 00:14:49,839
let's start with flux

00:14:47,040 --> 00:14:50,880
so or as i mentioned um our way of

00:14:49,839 --> 00:14:53,199
working with flux

00:14:50,880 --> 00:14:54,800
is that it works as a kind of

00:14:53,199 --> 00:14:57,279
reconciliation loop right

00:14:54,800 --> 00:14:58,000
it waits for releases to be updated on

00:14:57,279 --> 00:14:59,680
github

00:14:58,000 --> 00:15:01,680
and for new images to be pushed to our

00:14:59,680 --> 00:15:04,000
artifactory and then it acts

00:15:01,680 --> 00:15:05,519
tell me why is this important i mean so

00:15:04,000 --> 00:15:07,519
many people that i've spoken with

00:15:05,519 --> 00:15:08,720
they actually initiate their continuous

00:15:07,519 --> 00:15:11,360
deployments

00:15:08,720 --> 00:15:12,639
as a last step in a successful

00:15:11,360 --> 00:15:14,040
continuous integration

00:15:12,639 --> 00:15:16,320
so why is it important to do this

00:15:14,040 --> 00:15:19,760
reconciliation book yeah so

00:15:16,320 --> 00:15:23,360
um flex flux acts as

00:15:19,760 --> 00:15:25,920
a component you are right it's a

00:15:23,360 --> 00:15:26,959
reconciliation loop for kubernetes and

00:15:25,920 --> 00:15:29,519
it behave

00:15:26,959 --> 00:15:30,000
behaves the same way as kubernetes does

00:15:29,519 --> 00:15:34,800
it

00:15:30,000 --> 00:15:38,000
it accepts uh declarative data and

00:15:34,800 --> 00:15:39,440
reconciles it until uh what you've

00:15:38,000 --> 00:15:41,440
requested that

00:15:39,440 --> 00:15:43,040
is achieved on the cluster so like

00:15:41,440 --> 00:15:46,000
brings the production states

00:15:43,040 --> 00:15:46,800
to what we want it to be okay yeah so so

00:15:46,000 --> 00:15:50,160
the thing with

00:15:46,800 --> 00:15:53,279
flux it is that it helps with

00:15:50,160 --> 00:15:56,639
lots of different scenarios um

00:15:53,279 --> 00:16:00,959
it helps here in in the cd pipeline but

00:15:56,639 --> 00:16:05,120
flux also uh monitors uh git repose

00:16:00,959 --> 00:16:08,320
um uh for kubernetes configurations

00:16:05,120 --> 00:16:11,199
yes sir helps sres and

00:16:08,320 --> 00:16:12,399
cluster administrators in order to

00:16:11,199 --> 00:16:16,000
achieve

00:16:12,399 --> 00:16:18,720
state that comes from git and

00:16:16,000 --> 00:16:19,680
that is multi-cluster multi-region and

00:16:18,720 --> 00:16:23,040
you can

00:16:19,680 --> 00:16:23,759
span out multiple clusters that behaves

00:16:23,040 --> 00:16:26,160
the same

00:16:23,759 --> 00:16:27,519
all right only simple similar

00:16:26,160 --> 00:16:29,440
similarities between

00:16:27,519 --> 00:16:30,639
annotations and stuff if it's

00:16:29,440 --> 00:16:32,480
multi-region

00:16:30,639 --> 00:16:34,800
and you want to have a different

00:16:32,480 --> 00:16:37,360
behavior in a specific

00:16:34,800 --> 00:16:38,079
manner in only one configuration you can

00:16:37,360 --> 00:16:41,120
achieve that

00:16:38,079 --> 00:16:44,480
the thing with this uh

00:16:41,120 --> 00:16:47,680
component is that it uses pull

00:16:44,480 --> 00:16:50,959
and not push yes so

00:16:47,680 --> 00:16:54,000
the permission is

00:16:50,959 --> 00:16:57,120
uh given only to the component

00:16:54,000 --> 00:17:00,079
via the the cluster so the administrator

00:16:57,120 --> 00:17:02,000
that have the permission to manage right

00:17:00,079 --> 00:17:03,040
specific name space that specific

00:17:02,000 --> 00:17:06,400
cluster

00:17:03,040 --> 00:17:09,439
can uh do that in in

00:17:06,400 --> 00:17:13,679
flux only and not give up the

00:17:09,439 --> 00:17:17,120
permissions and and uh cluster

00:17:13,679 --> 00:17:20,480
administration to a ci uh product

00:17:17,120 --> 00:17:22,640
that okay acts on uh uh

00:17:20,480 --> 00:17:24,160
an external part of the network and

00:17:22,640 --> 00:17:25,120
definitely not a part of my production

00:17:24,160 --> 00:17:27,760
yeah

00:17:25,120 --> 00:17:28,559
um and and the thing the thing with

00:17:27,760 --> 00:17:32,160
ownership

00:17:28,559 --> 00:17:32,640
and microservices is that uh developer

00:17:32,160 --> 00:17:35,600
teams

00:17:32,640 --> 00:17:36,000
are autonomous and they can manage their

00:17:35,600 --> 00:17:39,039
own

00:17:36,000 --> 00:17:41,120
uh ci pipelines and

00:17:39,039 --> 00:17:42,799
right yeah and you want them to be able

00:17:41,120 --> 00:17:45,840
to do that and

00:17:42,799 --> 00:17:47,919
create different artifacts and stuff but

00:17:45,840 --> 00:17:49,520
you want to control what goes into

00:17:47,919 --> 00:17:51,840
production and you want to separate

00:17:49,520 --> 00:17:53,919
those uh steps

00:17:51,840 --> 00:17:55,440
understood yes so to sum this thing up

00:17:53,919 --> 00:17:58,640
to make sure that i understand

00:17:55,440 --> 00:18:01,760
a it is allowing me a separation

00:17:58,640 --> 00:18:05,600
and an encapsulation of my cd pipeline

00:18:01,760 --> 00:18:09,600
meaning ci's job is to deliver artifacts

00:18:05,600 --> 00:18:12,320
and it kind of stops there whereas cd

00:18:09,600 --> 00:18:14,160
takes these artifacts first second of

00:18:12,320 --> 00:18:16,799
all is the point where we

00:18:14,160 --> 00:18:17,440
don't deliver to the ci infrastructure

00:18:16,799 --> 00:18:20,640
any

00:18:17,440 --> 00:18:22,480
credentials any network access anything

00:18:20,640 --> 00:18:24,000
that will allow it to pierce the

00:18:22,480 --> 00:18:25,520
security uh permissions of the

00:18:24,000 --> 00:18:26,640
production environment and initiate

00:18:25,520 --> 00:18:30,080
processes there

00:18:26,640 --> 00:18:32,480
it's the pool thing and um and

00:18:30,080 --> 00:18:35,039
uh this this thing with autonomous um i

00:18:32,480 --> 00:18:37,120
have a question so um

00:18:35,039 --> 00:18:38,480
this means that inside each and every

00:18:37,120 --> 00:18:41,039
production environment

00:18:38,480 --> 00:18:43,039
flux itself should be treated as a

00:18:41,039 --> 00:18:45,440
production grade component because if

00:18:43,039 --> 00:18:46,080
for some reason it is down it is not

00:18:45,440 --> 00:18:48,400
pulling

00:18:46,080 --> 00:18:49,919
these changes it means that my cd

00:18:48,400 --> 00:18:50,720
pipeline will not be launched how do we

00:18:49,919 --> 00:18:52,559
monitor that

00:18:50,720 --> 00:18:54,640
how do you for instance know that right

00:18:52,559 --> 00:18:56,320
now our cd pipeline is functional

00:18:54,640 --> 00:18:58,400
and the next delivery is made by the

00:18:56,320 --> 00:18:59,760
engineering will actually get rolled out

00:18:58,400 --> 00:19:02,720
to production

00:18:59,760 --> 00:19:04,240
yeah yeah that's a great question so uh

00:19:02,720 --> 00:19:07,280
flux comes with uh

00:19:04,240 --> 00:19:10,320
with prometheus metrics built in

00:19:07,280 --> 00:19:13,760
and you can monitor the app metric

00:19:10,320 --> 00:19:16,799
and you can uh configure some

00:19:13,760 --> 00:19:20,320
web books that flux emits

00:19:16,799 --> 00:19:24,880
on failed uh uh apply

00:19:20,320 --> 00:19:27,600
to the cluster uh and uh failed um

00:19:24,880 --> 00:19:28,559
attempts yeah failed attempts of

00:19:27,600 --> 00:19:31,360
updating

00:19:28,559 --> 00:19:32,720
images and pulling from git and maybe

00:19:31,360 --> 00:19:34,640
pushing to git

00:19:32,720 --> 00:19:36,720
and similarly if the metrics are not

00:19:34,640 --> 00:19:38,559
arriving i can alert in my

00:19:36,720 --> 00:19:40,559
monitoring system on the fact that

00:19:38,559 --> 00:19:42,799
nothing is okay that makes sense

00:19:40,559 --> 00:19:44,320
uh one maybe a smaller question in

00:19:42,799 --> 00:19:46,480
relation to the previous ones

00:19:44,320 --> 00:19:48,640
so i know that different organizations

00:19:46,480 --> 00:19:51,280
deploy things in kubernetes

00:19:48,640 --> 00:19:52,720
uh in different ways we for instance we

00:19:51,280 --> 00:19:56,720
use

00:19:52,720 --> 00:19:58,720
yamo directly defining resources

00:19:56,720 --> 00:20:00,320
and when needed we template it using the

00:19:58,720 --> 00:20:02,080
customized tools i know that many

00:20:00,320 --> 00:20:04,159
organizations are using helm trucks

00:20:02,080 --> 00:20:05,360
as their main mechanism for deployment

00:20:04,159 --> 00:20:07,120
does flux

00:20:05,360 --> 00:20:09,600
care about how it actually initiates the

00:20:07,120 --> 00:20:13,039
deployment or is it agnostic

00:20:09,600 --> 00:20:15,440
so there is a way to to achieve uh

00:20:13,039 --> 00:20:17,679
agnostic way of deployment of deploying

00:20:15,440 --> 00:20:20,799
uh you can create your own

00:20:17,679 --> 00:20:21,360
scripts and stuff but flux comes with

00:20:20,799 --> 00:20:24,240
building

00:20:21,360 --> 00:20:24,880
uh built-in support for customize and

00:20:24,240 --> 00:20:29,280
helm

00:20:24,880 --> 00:20:31,679
yeah so it can parse the helm charts

00:20:29,280 --> 00:20:33,440
and actually build the template from the

00:20:31,679 --> 00:20:36,880
uh go template

00:20:33,440 --> 00:20:39,200
and um then

00:20:36,880 --> 00:20:40,799
build the the output configuration and

00:20:39,200 --> 00:20:41,760
right apply that specific for the

00:20:40,799 --> 00:20:43,840
environment yeah

00:20:41,760 --> 00:20:44,880
absolutely so native support both for

00:20:43,840 --> 00:20:47,679
customize

00:20:44,880 --> 00:20:48,640
if you are a fan of writing explicit

00:20:47,679 --> 00:20:50,880
yeah well resources

00:20:48,640 --> 00:20:52,799
patching and not uh templating and

00:20:50,880 --> 00:20:56,000
writing

00:20:52,799 --> 00:20:59,440
yeah yeah if you want to write a

00:20:56,000 --> 00:21:03,360
native yaml uh code and note

00:20:59,440 --> 00:21:05,600
code data instead of configuration yeah

00:21:03,360 --> 00:21:06,880
that would be yeah the thing the thing

00:21:05,600 --> 00:21:10,080
with customize is

00:21:06,880 --> 00:21:12,640
that it takes the beauty of uh

00:21:10,080 --> 00:21:13,360
declarative language uh configuration

00:21:12,640 --> 00:21:16,799
language of

00:21:13,360 --> 00:21:20,400
kubernetes and says we don't

00:21:16,799 --> 00:21:23,760
write code to in order to generate uh

00:21:20,400 --> 00:21:24,240
the the output yaml we just write proper

00:21:23,760 --> 00:21:27,200
yaman

00:21:24,240 --> 00:21:27,840
and we can use either the base or the

00:21:27,200 --> 00:21:31,280
patch

00:21:27,840 --> 00:21:32,320
as a standalone and extended so you may

00:21:31,280 --> 00:21:34,720
choose your own

00:21:32,320 --> 00:21:36,240
philosophy of deploying whether you

00:21:34,720 --> 00:21:38,960
happen to agree with or

00:21:36,240 --> 00:21:39,600
that does this thing with declarative

00:21:38,960 --> 00:21:41,520
yaml

00:21:39,600 --> 00:21:43,360
or you would like to use helm charts it

00:21:41,520 --> 00:21:45,200
all is very much native

00:21:43,360 --> 00:21:46,799
okay let's move to the actual

00:21:45,200 --> 00:21:49,840
progressive delivery stage

00:21:46,799 --> 00:21:52,640
i just yeah i just want to mention uh

00:21:49,840 --> 00:21:53,840
two more advantage advantages very

00:21:52,640 --> 00:21:57,200
important flux

00:21:53,840 --> 00:21:59,600
that is not related uh to uh

00:21:57,200 --> 00:22:01,200
the cd pipeline and developers okay i

00:21:59,600 --> 00:22:04,159
really like it as an sre

00:22:01,200 --> 00:22:05,840
that i can use it as a drp mechanism i

00:22:04,159 --> 00:22:08,960
have everything in git and i can

00:22:05,840 --> 00:22:10,320
set up a new cluster and it will behave

00:22:08,960 --> 00:22:12,880
exactly the same as

00:22:10,320 --> 00:22:13,679
the previous cluster and the mean time

00:22:12,880 --> 00:22:16,960
to recover

00:22:13,679 --> 00:22:18,640
from this is basically zero

00:22:16,960 --> 00:22:20,159
since you have the entire configuration

00:22:18,640 --> 00:22:22,640
and the images are stored

00:22:20,159 --> 00:22:23,679
somewhere else and hopefully you back

00:22:22,640 --> 00:22:25,840
them up too

00:22:23,679 --> 00:22:26,960
and uh of course we do that what do you

00:22:25,840 --> 00:22:30,000
mean

00:22:26,960 --> 00:22:31,280
yeah so uh that's i think that's a great

00:22:30,000 --> 00:22:34,799
advantage of

00:22:31,280 --> 00:22:36,320
of uh uh one con component that is in in

00:22:34,799 --> 00:22:39,760
your clustering

00:22:36,320 --> 00:22:41,679
acts as a different

00:22:39,760 --> 00:22:43,039
roles for different people in the

00:22:41,679 --> 00:22:44,960
company and

00:22:43,039 --> 00:22:47,440
well one more thing i want to mention

00:22:44,960 --> 00:22:49,840
about flux is multi-tenancy

00:22:47,440 --> 00:22:50,799
oh okay all right what does that mean it

00:22:49,840 --> 00:22:53,679
means like

00:22:50,799 --> 00:22:54,799
we said about uh the ci pipelines and

00:22:53,679 --> 00:22:58,000
the ownership

00:22:54,799 --> 00:23:01,360
developers want to manage uh

00:22:58,000 --> 00:23:03,840
if you have a few uh dev teams that

00:23:01,360 --> 00:23:05,600
are separate and have their own name

00:23:03,840 --> 00:23:08,400
space and quota and

00:23:05,600 --> 00:23:08,720
and limits and everything configured by

00:23:08,400 --> 00:23:11,919
the

00:23:08,720 --> 00:23:14,799
organizational sre team you can have

00:23:11,919 --> 00:23:16,000
your namespace and in that namespace

00:23:14,799 --> 00:23:19,039
manage everything

00:23:16,000 --> 00:23:21,440
and have flux installed

00:23:19,039 --> 00:23:22,159
into that namespace and manage that

00:23:21,440 --> 00:23:26,480
namespace

00:23:22,159 --> 00:23:29,520
from a different repo and the sre

00:23:26,480 --> 00:23:32,960
has the uh cluster wide

00:23:29,520 --> 00:23:35,200
flux and all right per team you have

00:23:32,960 --> 00:23:36,159
the advantage of managing your own

00:23:35,200 --> 00:23:38,720
resources

00:23:36,159 --> 00:23:40,320
from your own git repo and deployments

00:23:38,720 --> 00:23:43,279
and your policy

00:23:40,320 --> 00:23:44,559
and you you get the best of both worlds

00:23:43,279 --> 00:23:46,080
so it's very important

00:23:44,559 --> 00:23:48,320
the fact that within different

00:23:46,080 --> 00:23:51,440
namespaces of even the same cluster

00:23:48,320 --> 00:23:53,360
i could run very different strategies uh

00:23:51,440 --> 00:23:56,000
in terms of continuous deployment and

00:23:53,360 --> 00:23:56,640
git ups thanks to different instances of

00:23:56,000 --> 00:23:59,039
flux

00:23:56,640 --> 00:23:59,760
that's a very important comment okay

00:23:59,039 --> 00:24:02,880
progressive

00:23:59,760 --> 00:24:05,360
delivery so this is the component

00:24:02,880 --> 00:24:06,720
that takes the center stage after flux

00:24:05,360 --> 00:24:09,679
completes its job

00:24:06,720 --> 00:24:11,520
and in here we are talking about

00:24:09,679 --> 00:24:13,919
implementing a strategy

00:24:11,520 --> 00:24:15,440
for rolling something out in our case we

00:24:13,919 --> 00:24:18,240
will be focusing on canary

00:24:15,440 --> 00:24:18,799
because this is what we are doing so um

00:24:18,240 --> 00:24:21,840
first

00:24:18,799 --> 00:24:24,240
a very important

00:24:21,840 --> 00:24:25,679
question uh does it make sense ever to

00:24:24,240 --> 00:24:28,720
use flagger

00:24:25,679 --> 00:24:31,600
without flux or is this tool

00:24:28,720 --> 00:24:33,440
good only when you use flux as your git

00:24:31,600 --> 00:24:36,480
ops operator is there such a thing

00:24:33,440 --> 00:24:39,600
yeah so uh flux and slugger was

00:24:36,480 --> 00:24:42,000
built by the same tune yeah and and you

00:24:39,600 --> 00:24:45,279
can see it's a complementary uh

00:24:42,000 --> 00:24:48,559
uh solution but the thing is it

00:24:45,279 --> 00:24:52,000
behaves as the unix philosophy says uh

00:24:48,559 --> 00:24:55,120
do one thing well and actually flagger

00:24:52,000 --> 00:24:58,880
just uh triggers a new canary

00:24:55,120 --> 00:25:02,960
based on new deployment change

00:24:58,880 --> 00:25:05,200
so you can just run coop cdl edit

00:25:02,960 --> 00:25:06,799
and and and flagger and trigger will

00:25:05,200 --> 00:25:09,919
trigger a job

00:25:06,799 --> 00:25:11,600
you can use if you already have a

00:25:09,919 --> 00:25:14,880
deployment mechanism and you

00:25:11,600 --> 00:25:17,919
actually edit and apply deployments from

00:25:14,880 --> 00:25:18,799
ci like you are used to uh you don't

00:25:17,919 --> 00:25:21,279
have to use

00:25:18,799 --> 00:25:22,240
flux in order to use flagger very

00:25:21,279 --> 00:25:25,279
important

00:25:22,240 --> 00:25:27,679
yeah so uh they are

00:25:25,279 --> 00:25:28,320
a complementary components but they can

00:25:27,679 --> 00:25:32,159
work

00:25:28,320 --> 00:25:34,960
it as a standalone and

00:25:32,159 --> 00:25:35,679
one can live without the other so

00:25:34,960 --> 00:25:38,080
flagger

00:25:35,679 --> 00:25:40,240
only triggers a new canary based on

00:25:38,080 --> 00:25:42,960
changes to the main

00:25:40,240 --> 00:25:44,559
the apex deployment state of stateful

00:25:42,960 --> 00:25:47,440
set etc

00:25:44,559 --> 00:25:48,080
so as i already told our viewers um one

00:25:47,440 --> 00:25:50,480
of the most

00:25:48,080 --> 00:25:51,679
important pieces in in a canary

00:25:50,480 --> 00:25:54,880
deployment

00:25:51,679 --> 00:25:57,919
is this ability to establish did

00:25:54,880 --> 00:25:58,640
this new canary pods or these new canary

00:25:57,919 --> 00:26:01,200
pods

00:25:58,640 --> 00:26:01,919
actually manage to handle the traffic

00:26:01,200 --> 00:26:04,480
correctly

00:26:01,919 --> 00:26:06,559
and of course we do that via prometheus

00:26:04,480 --> 00:26:08,720
by scraping various metrics now or

00:26:06,559 --> 00:26:10,960
these are not just your typical

00:26:08,720 --> 00:26:12,080
liveliness and health metrics right we

00:26:10,960 --> 00:26:13,919
are looking deeper

00:26:12,080 --> 00:26:15,760
uh could you please tell those of our

00:26:13,919 --> 00:26:16,720
viewers who don't necessarily have a

00:26:15,760 --> 00:26:20,720
very advanced

00:26:16,720 --> 00:26:22,640
metrics in in their application pods

00:26:20,720 --> 00:26:24,320
what is like the bare minimum what kind

00:26:22,640 --> 00:26:26,960
of metrics would you be looking for

00:26:24,320 --> 00:26:27,600
in order to make this you know confident

00:26:26,960 --> 00:26:28,880
promotion

00:26:27,600 --> 00:26:31,279
in progressive deployment what do you

00:26:28,880 --> 00:26:33,840
need so in order to use

00:26:31,279 --> 00:26:34,480
flagger you need another component that

00:26:33,840 --> 00:26:37,840
is

00:26:34,480 --> 00:26:38,240
either leveraging an smi spec uh service

00:26:37,840 --> 00:26:41,440
mesh

00:26:38,240 --> 00:26:44,720
interface oh uh uh

00:26:41,440 --> 00:26:48,000
more robust uh

00:26:44,720 --> 00:26:48,480
service mesh solutions like eco and link

00:26:48,000 --> 00:26:52,080
rd

00:26:48,480 --> 00:26:55,520
absolutely um and these components

00:26:52,080 --> 00:26:57,760
are aware of application metrics and

00:26:55,520 --> 00:26:59,919
uh right instrument the application

00:26:57,760 --> 00:27:03,520
automatically so you don't have

00:26:59,919 --> 00:27:06,559
um yeah so you get you get success rate

00:27:03,520 --> 00:27:08,320
and and latency out of the box with so i

00:27:06,559 --> 00:27:11,440
don't need to do anything i have my

00:27:08,320 --> 00:27:13,520
regular microservice either rest or grpc

00:27:11,440 --> 00:27:15,360
and these things will actually give

00:27:13,520 --> 00:27:17,360
flagger the ability

00:27:15,360 --> 00:27:18,799
to figure out whether the success rate

00:27:17,360 --> 00:27:21,200
uh with this new version is

00:27:18,799 --> 00:27:22,799
significantly oh that's that's great

00:27:21,200 --> 00:27:25,600
are indeed success rate by the way and

00:27:22,799 --> 00:27:28,640
latency the things you're looking for

00:27:25,600 --> 00:27:30,960
so these are the built-in metrics you

00:27:28,640 --> 00:27:31,760
get in flyer you can use custom metrics

00:27:30,960 --> 00:27:35,770
for example

00:27:31,760 --> 00:27:37,200
we use a google pop sub and we can

00:27:35,770 --> 00:27:40,240
[Music]

00:27:37,200 --> 00:27:43,520
fail a canary build based on

00:27:40,240 --> 00:27:46,399
uh latency in the queue and

00:27:43,520 --> 00:27:47,120
stock messages and stuff so you can yeah

00:27:46,399 --> 00:27:50,640
so you can

00:27:47,120 --> 00:27:53,520
you can actually depends on the traffic

00:27:50,640 --> 00:27:55,120
of the service if it doesn't get an hp

00:27:53,520 --> 00:27:57,279
and grpc and you want to alert

00:27:55,120 --> 00:27:58,240
something else and fail the deployment

00:27:57,279 --> 00:28:00,640
even on

00:27:58,240 --> 00:28:01,360
custom metrics you built into the app

00:28:00,640 --> 00:28:04,640
and

00:28:01,360 --> 00:28:07,200
it yourself you can do that uh the basic

00:28:04,640 --> 00:28:08,240
the basic uh that comes with flagger and

00:28:07,200 --> 00:28:11,279
supports

00:28:08,240 --> 00:28:14,320
the service mesh you have is

00:28:11,279 --> 00:28:17,360
latency and success rate okay and

00:28:14,320 --> 00:28:18,080
you can say uh the threshold for this

00:28:17,360 --> 00:28:21,600
canary

00:28:18,080 --> 00:28:22,960
is 99 success well that's a pretty high

00:28:21,600 --> 00:28:24,000
but let's say that i want to shoot for a

00:28:22,960 --> 00:28:27,520
high reliability

00:28:24,000 --> 00:28:30,799
so if if the new canary deployment

00:28:27,520 --> 00:28:34,559
achieves 98 you can just fail

00:28:30,799 --> 00:28:37,200
the canary and roll back the traffic

00:28:34,559 --> 00:28:38,320
to uh the primary the thing with this is

00:28:37,200 --> 00:28:41,520
that

00:28:38,320 --> 00:28:46,399
unlike uh normal kubernetes deployment

00:28:41,520 --> 00:28:49,360
you get only a chunk of your traffic

00:28:46,399 --> 00:28:50,399
failing so if you are promoting five

00:28:49,360 --> 00:28:53,120
percent

00:28:50,399 --> 00:28:54,399
uh to the canary instance only five

00:28:53,120 --> 00:28:57,279
percent of your traffic

00:28:54,399 --> 00:28:59,120
will get affected and get affected which

00:28:57,279 --> 00:28:59,760
means that again not necessarily fully

00:28:59,120 --> 00:29:03,039
failed right

00:28:59,760 --> 00:29:04,880
it is so it is in essence a blast radius

00:29:03,039 --> 00:29:05,360
management mechanism that's what it is

00:29:04,880 --> 00:29:08,559
yeah

00:29:05,360 --> 00:29:08,799
um one uh sort of like curious question

00:29:08,559 --> 00:29:11,039
i

00:29:08,799 --> 00:29:12,080
i previously mentioned that we extended

00:29:11,039 --> 00:29:14,080
the functionality

00:29:12,080 --> 00:29:16,480
of what flagger is doing in different

00:29:14,080 --> 00:29:19,440
stages with our own service

00:29:16,480 --> 00:29:20,960
puerta how important it is um is is

00:29:19,440 --> 00:29:22,960
flagger let's say for those of

00:29:20,960 --> 00:29:24,240
our viewers who'd like to get started on

00:29:22,960 --> 00:29:26,960
progressive deployment

00:29:24,240 --> 00:29:28,799
is it good enough without any extensions

00:29:26,960 --> 00:29:29,440
or do you really need some sort of bare

00:29:28,799 --> 00:29:31,440
minimum

00:29:29,440 --> 00:29:32,960
of custom hooks in order to get started

00:29:31,440 --> 00:29:36,000
what do you think here

00:29:32,960 --> 00:29:38,559
so we wanted to extend uh

00:29:36,000 --> 00:29:40,720
flagger in order to support our

00:29:38,559 --> 00:29:43,840
philosophy and the way we believe

00:29:40,720 --> 00:29:46,960
right the gates should behave and

00:29:43,840 --> 00:29:47,520
uh like time constraints for deployments

00:29:46,960 --> 00:29:49,919
and

00:29:47,520 --> 00:29:50,880
release training and stuff the thing

00:29:49,919 --> 00:29:54,399
with flagger

00:29:50,880 --> 00:29:57,679
is that it's really really simple

00:29:54,399 --> 00:29:59,840
uh unlike spinnaker and huge

00:29:57,679 --> 00:30:01,600
solutions that we came before kubernetes

00:29:59,840 --> 00:30:02,720
it is a lightweight and very simple

00:30:01,600 --> 00:30:05,279
operator very true

00:30:02,720 --> 00:30:06,080
very lightweight and in order to extend

00:30:05,279 --> 00:30:09,760
it you just

00:30:06,080 --> 00:30:12,399
need to support the the

00:30:09,760 --> 00:30:14,159
flagger web books so flagger gives you a

00:30:12,399 --> 00:30:17,039
set of web books and tells you

00:30:14,159 --> 00:30:17,840
exactly when it will shoot them so you

00:30:17,039 --> 00:30:22,200
have

00:30:17,840 --> 00:30:25,279
a pre-rollout uh pre uh

00:30:22,200 --> 00:30:27,039
pre-release pre yeah

00:30:25,279 --> 00:30:28,480
and different different stages yeah you

00:30:27,039 --> 00:30:32,640
have all the stages and

00:30:28,480 --> 00:30:33,360
and you can set and you can configure a

00:30:32,640 --> 00:30:35,520
web book

00:30:33,360 --> 00:30:36,399
that will shoot to an end point you

00:30:35,520 --> 00:30:40,320
configure

00:30:36,399 --> 00:30:44,000
even launching your uh e2e pipeline via

00:30:40,320 --> 00:30:47,039
uh circle ci and stuff and

00:30:44,000 --> 00:30:47,919
you you get that uh flexibility via web

00:30:47,039 --> 00:30:51,279
hooks and

00:30:47,919 --> 00:30:54,559
you don't need to extend flagger in

00:30:51,279 --> 00:30:54,960
like forking it and absolutely no okay

00:30:54,559 --> 00:30:57,279
yes

00:30:54,960 --> 00:30:59,120
we definitely use the out-of-the-box one

00:30:57,279 --> 00:31:01,679
okay you know what you mentioned

00:30:59,120 --> 00:31:02,799
service mesh and its role let's talk

00:31:01,679 --> 00:31:04,960
about the service mesh

00:31:02,799 --> 00:31:06,080
so for me this is the first time i'm

00:31:04,960 --> 00:31:07,679
using service mesh

00:31:06,080 --> 00:31:10,000
in in a production environment not for

00:31:07,679 --> 00:31:13,519
ore for me really in a

00:31:10,000 --> 00:31:15,679
nutshell service mesh is a web of

00:31:13,519 --> 00:31:17,039
proxies right attached to each and every

00:31:15,679 --> 00:31:20,159
pod as a sidecar

00:31:17,039 --> 00:31:21,600
i think right uh so that every outbound

00:31:20,159 --> 00:31:23,840
communication from the pod

00:31:21,600 --> 00:31:24,720
goes through these proxies in essence

00:31:23,840 --> 00:31:26,720
every inbound

00:31:24,720 --> 00:31:28,240
also has to come from some other proxy

00:31:26,720 --> 00:31:29,360
there's just no other way to talk to

00:31:28,240 --> 00:31:32,799
different pods

00:31:29,360 --> 00:31:35,440
and all of them have a common

00:31:32,799 --> 00:31:37,360
control plane uh through which we can do

00:31:35,440 --> 00:31:38,960
many things not necessarily related to

00:31:37,360 --> 00:31:42,000
uh continuous deployment right

00:31:38,960 --> 00:31:44,000
or mentioned the monitoring of various

00:31:42,000 --> 00:31:46,159
metrics uh definitely the security

00:31:44,000 --> 00:31:49,519
policy who can talk to you

00:31:46,159 --> 00:31:52,880
and do what particularly though

00:31:49,519 --> 00:31:55,760
in the continuous deployment world

00:31:52,880 --> 00:31:57,360
what are the special capabilities that

00:31:55,760 --> 00:31:59,279
service mesh gives you

00:31:57,360 --> 00:32:01,360
as opposed to doing the same continuous

00:31:59,279 --> 00:32:04,559
deployment with the same flagger

00:32:01,360 --> 00:32:05,279
albeit only with my typical ingress

00:32:04,559 --> 00:32:06,960
controller

00:32:05,279 --> 00:32:08,399
what is the functional gap that we are

00:32:06,960 --> 00:32:12,480
gaining here

00:32:08,399 --> 00:32:15,440
so the smi traffic slid

00:32:12,480 --> 00:32:16,559
object is updated by the flagger

00:32:15,440 --> 00:32:20,159
mechanism and

00:32:16,559 --> 00:32:20,799
can actually write uh the and change the

00:32:20,159 --> 00:32:24,240
weights

00:32:20,799 --> 00:32:27,279
yep and the service mesh

00:32:24,240 --> 00:32:29,600
that receives the the traffic split and

00:32:27,279 --> 00:32:30,559
and applies it to the traffic you can

00:32:29,600 --> 00:32:33,919
actually

00:32:30,559 --> 00:32:35,600
see the entire traffic because it sits

00:32:33,919 --> 00:32:37,360
as well all of it runs through proxies

00:32:35,600 --> 00:32:40,880
yeah absolutely the entire

00:32:37,360 --> 00:32:42,799
the entire uh kubernetes mesh is

00:32:40,880 --> 00:32:44,960
actually talking to each other via the

00:32:42,799 --> 00:32:46,880
proxies so you get

00:32:44,960 --> 00:32:48,880
additional stuff like instrumentation

00:32:46,880 --> 00:32:51,840
and tls and everything

00:32:48,880 --> 00:32:53,600
everything is secure and you never use

00:32:51,840 --> 00:32:56,480
http inside your mesh but

00:32:53,600 --> 00:32:58,159
it's transparent yeah and and these are

00:32:56,480 --> 00:33:01,519
the benefits still regardless of

00:32:58,159 --> 00:33:04,720
yeah yeah exactly but the thing is that

00:33:01,519 --> 00:33:08,559
if as an application

00:33:04,720 --> 00:33:11,360
i call you i call you via

00:33:08,559 --> 00:33:12,559
the the proxy yes it sees the entire

00:33:11,360 --> 00:33:15,840
traffic

00:33:12,559 --> 00:33:18,960
it can say i got a i got a config

00:33:15,840 --> 00:33:22,159
that says i need to send five percent

00:33:18,960 --> 00:33:25,279
ten percent in this case but yeah and

00:33:22,159 --> 00:33:26,080
uh ten percent to instead to you to a

00:33:25,279 --> 00:33:29,519
new instance

00:33:26,080 --> 00:33:32,640
yep and uh this happens transparently

00:33:29,519 --> 00:33:35,600
on the proxy without you ever

00:33:32,640 --> 00:33:36,799
configuring an application and ever

00:33:35,600 --> 00:33:38,880
knowing about

00:33:36,799 --> 00:33:39,919
where to send traffic so you your

00:33:38,880 --> 00:33:41,840
application

00:33:39,919 --> 00:33:43,120
speaks i'm just calling service day

00:33:41,840 --> 00:33:44,880
called service b

00:33:43,120 --> 00:33:47,279
and somehow this traffic gets split

00:33:44,880 --> 00:33:49,919
between b and the upcoming canary

00:33:47,279 --> 00:33:50,720
but wait uh in theory or actually in

00:33:49,919 --> 00:33:52,880
practice

00:33:50,720 --> 00:33:54,399
uh many people unfortunately do not have

00:33:52,880 --> 00:33:56,000
service meshes deployed

00:33:54,399 --> 00:33:57,840
so for them for instance when they

00:33:56,000 --> 00:33:59,039
consider doing progressive deployment

00:33:57,840 --> 00:34:01,600
with flagger

00:33:59,039 --> 00:34:02,880
probably the more appropriate diagram

00:34:01,600 --> 00:34:05,840
would be something like

00:34:02,880 --> 00:34:07,519
this where the mechanism through which

00:34:05,840 --> 00:34:09,760
traffic splits

00:34:07,519 --> 00:34:10,879
is being enforced is an ingress

00:34:09,760 --> 00:34:12,399
controller yeah

00:34:10,879 --> 00:34:14,079
there are a lot of popular ingers

00:34:12,399 --> 00:34:15,839
controllers and quite frankly

00:34:14,079 --> 00:34:18,000
most of them at least the most popular

00:34:15,839 --> 00:34:21,200
ones are indeed supported by flagger

00:34:18,000 --> 00:34:23,280
so what is um what's the big difference

00:34:21,200 --> 00:34:24,399
is it exactly the same benefit you get

00:34:23,280 --> 00:34:26,560
for your canaries

00:34:24,399 --> 00:34:27,839
or is there still a gap and a reason why

00:34:26,560 --> 00:34:29,599
you should consider

00:34:27,839 --> 00:34:31,280
service mesh in order to build a real

00:34:29,599 --> 00:34:34,240
progressive deployment

00:34:31,280 --> 00:34:35,359
so um you don't really need a service

00:34:34,240 --> 00:34:37,359
mesh uh

00:34:35,359 --> 00:34:38,720
if you don't have to it's a big

00:34:37,359 --> 00:34:41,599
adventure uh

00:34:38,720 --> 00:34:43,440
and takes a lot of convincing inside the

00:34:41,599 --> 00:34:46,240
organization but you can start with your

00:34:43,440 --> 00:34:48,720
ingest controller every kubernetes has

00:34:46,240 --> 00:34:49,599
absolutely ingers controller and flyer

00:34:48,720 --> 00:34:53,119
supports

00:34:49,599 --> 00:34:56,240
a lot of them and the thing with

00:34:53,119 --> 00:34:57,599
ingress is that canar you will benefit

00:34:56,240 --> 00:35:01,040
canary only for

00:34:57,599 --> 00:35:03,839
the first hop right the top sort of like

00:35:01,040 --> 00:35:04,720
tier of my services because these are

00:35:03,839 --> 00:35:06,480
the ones

00:35:04,720 --> 00:35:07,760
receiving traffic directly from the

00:35:06,480 --> 00:35:09,440
ingress controller

00:35:07,760 --> 00:35:11,200
and there of course i'll be able to do

00:35:09,440 --> 00:35:12,960
the split uh what will happen to the

00:35:11,200 --> 00:35:15,119
rest of my services right

00:35:12,960 --> 00:35:16,640
the the deployments kubernetes will

00:35:15,119 --> 00:35:19,760
still create pods

00:35:16,640 --> 00:35:20,400
who will get the traffic the the for

00:35:19,760 --> 00:35:22,000
instance just

00:35:20,400 --> 00:35:23,920
to explain so here we have in the

00:35:22,000 --> 00:35:26,000
schematics the nginx ingress

00:35:23,920 --> 00:35:27,040
calls this either service primary and

00:35:26,000 --> 00:35:29,520
service canary

00:35:27,040 --> 00:35:30,640
let's imagine that this service calls

00:35:29,520 --> 00:35:33,359
another

00:35:30,640 --> 00:35:35,200
b service yeah unfortunately there we do

00:35:33,359 --> 00:35:37,359
not control a traffic street because

00:35:35,200 --> 00:35:38,880
in the absence of service mesh it just

00:35:37,359 --> 00:35:41,760
goes over the overlay network

00:35:38,880 --> 00:35:42,240
so how will let's say i deploy out a new

00:35:41,760 --> 00:35:44,240
pods

00:35:42,240 --> 00:35:45,359
what will happen just a round robin

00:35:44,240 --> 00:35:48,640
random yes

00:35:45,359 --> 00:35:52,079
so you you wouldn't use the canary uh

00:35:48,640 --> 00:35:54,960
canary uh crd in uh

00:35:52,079 --> 00:35:57,119
in internal services because you won't

00:35:54,960 --> 00:36:00,320
benefit from the traffic split

00:35:57,119 --> 00:36:03,440
understood and the thing is

00:36:00,320 --> 00:36:06,320
that most most architectures

00:36:03,440 --> 00:36:07,760
is using some kind of api gateway that

00:36:06,320 --> 00:36:08,880
routes all the traffic to internal

00:36:07,760 --> 00:36:13,359
services

00:36:08,880 --> 00:36:16,480
so only this service the api gateway

00:36:13,359 --> 00:36:19,280
will benefit from canary because

00:36:16,480 --> 00:36:20,079
the traffic split won't work internally

00:36:19,280 --> 00:36:22,640
so

00:36:20,079 --> 00:36:23,839
we at stackpools believe that each

00:36:22,640 --> 00:36:26,960
service should have

00:36:23,839 --> 00:36:29,359
a canary rollout so absolutely yeah so

00:36:26,960 --> 00:36:30,480
we have lots of microservices talking to

00:36:29,359 --> 00:36:33,920
each other

00:36:30,480 --> 00:36:35,040
and we'd like each one of them to have a

00:36:33,920 --> 00:36:38,720
canary

00:36:35,040 --> 00:36:41,280
and by using service mesh we are getting

00:36:38,720 --> 00:36:42,640
the traffic split exactly no matter how

00:36:41,280 --> 00:36:44,000
deep the service relies in our

00:36:42,640 --> 00:36:46,880
architecture so again

00:36:44,000 --> 00:36:47,680
to sum this point up if you don't use

00:36:46,880 --> 00:36:49,280
service mesh

00:36:47,680 --> 00:36:51,359
and again we are fully aware that this

00:36:49,280 --> 00:36:52,320
is a technology that is more rarely seen

00:36:51,359 --> 00:36:53,839
in production

00:36:52,320 --> 00:36:56,800
in order to do a real progressive

00:36:53,839 --> 00:36:59,280
deployment it is quite easy to benefit

00:36:56,800 --> 00:37:01,040
from gaining a canary on your top tier

00:36:59,280 --> 00:37:04,480
sort of like out facing

00:37:01,040 --> 00:37:07,520
services when it comes deeper either api

00:37:04,480 --> 00:37:10,079
gateway or unfortunately doing

00:37:07,520 --> 00:37:11,359
real canary just for your top tiers is

00:37:10,079 --> 00:37:13,440
the solution you're uh

00:37:11,359 --> 00:37:15,280
you're left with it's it's a good it's a

00:37:13,440 --> 00:37:16,160
good solution man because most people

00:37:15,280 --> 00:37:19,440
don't have

00:37:16,160 --> 00:37:20,240
uh at all but the thing is with api

00:37:19,440 --> 00:37:23,440
gateways

00:37:20,240 --> 00:37:26,640
is that if they accept all your traffic

00:37:23,440 --> 00:37:29,760
yeah and you yeah you fail there

00:37:26,640 --> 00:37:30,480
then nothing will work and it's a good

00:37:29,760 --> 00:37:33,359
thing to do

00:37:30,480 --> 00:37:34,320
with a gradual rollout even for an apa

00:37:33,359 --> 00:37:36,320
gateway and

00:37:34,320 --> 00:37:38,000
it's a good thing to do anyway you know

00:37:36,320 --> 00:37:39,359
what you mentioned gradual rollout let's

00:37:38,000 --> 00:37:40,640
talk about maybe one of the more

00:37:39,359 --> 00:37:43,760
controversial

00:37:40,640 --> 00:37:45,920
subjects we have here so guys by now you

00:37:43,760 --> 00:37:48,320
know pretty much about how we work

00:37:45,920 --> 00:37:49,119
you know that we do a lot of automated

00:37:48,320 --> 00:37:51,040
gatings

00:37:49,119 --> 00:37:52,240
we do them inside our continuous

00:37:51,040 --> 00:37:53,920
integration pipeline

00:37:52,240 --> 00:37:55,520
we do them at various stages of our

00:37:53,920 --> 00:37:58,480
continuous delivery pipeline

00:37:55,520 --> 00:38:00,480
and yet we are still huge believers in

00:37:58,480 --> 00:38:04,400
dark launching or flag slipping

00:38:00,480 --> 00:38:07,280
which means in essence that every time a

00:38:04,400 --> 00:38:08,480
significant portion of our business

00:38:07,280 --> 00:38:11,040
logic changes

00:38:08,480 --> 00:38:11,760
on the engineering level people

00:38:11,040 --> 00:38:13,680
surrounded

00:38:11,760 --> 00:38:15,599
by this conditional block where they

00:38:13,680 --> 00:38:17,040
reach out to an external system

00:38:15,599 --> 00:38:19,359
there are a number of commercial and

00:38:17,040 --> 00:38:20,240
open source solutions we chose flip t as

00:38:19,359 --> 00:38:23,119
you can see

00:38:20,240 --> 00:38:23,680
uh and uh sort of like that surrounded

00:38:23,119 --> 00:38:26,160
block

00:38:23,680 --> 00:38:26,720
provides the session info the user the

00:38:26,160 --> 00:38:29,280
account

00:38:26,720 --> 00:38:30,720
geography ip time of day god knows what

00:38:29,280 --> 00:38:34,640
a lot of parameters

00:38:30,720 --> 00:38:36,000
and gets a decision made by an external

00:38:34,640 --> 00:38:37,280
system

00:38:36,000 --> 00:38:40,000
whether the functionality should be

00:38:37,280 --> 00:38:41,599
enabled or not now why do we need this

00:38:40,000 --> 00:38:44,240
we go through so much trouble with

00:38:41,599 --> 00:38:46,400
automated gating end-to-end testing

00:38:44,240 --> 00:38:47,359
that this progressive canary where we

00:38:46,400 --> 00:38:50,240
gradually

00:38:47,359 --> 00:38:50,800
flip traffic why do we need this

00:38:50,240 --> 00:38:53,200
additional

00:38:50,800 --> 00:38:55,040
logical level of control isn't it

00:38:53,200 --> 00:38:59,040
excessive in your opinion

00:38:55,040 --> 00:39:01,760
so the thing about canarying is that

00:38:59,040 --> 00:39:02,400
it does that for the entire instance

00:39:01,760 --> 00:39:04,320
okay

00:39:02,400 --> 00:39:05,760
the service that we are deploying of

00:39:04,320 --> 00:39:07,599
course we are deploying

00:39:05,760 --> 00:39:09,040
a binary okay we are deploying or

00:39:07,599 --> 00:39:12,320
configuration changes

00:39:09,040 --> 00:39:15,119
configuration exactly so this thing

00:39:12,320 --> 00:39:17,440
affects the entire um

00:39:15,119 --> 00:39:18,480
blob that released to production

00:39:17,440 --> 00:39:20,560
absolutely

00:39:18,480 --> 00:39:22,400
the service is the service right however

00:39:20,560 --> 00:39:23,920
amount of end points it serves all of

00:39:22,400 --> 00:39:26,880
them get affected big time

00:39:23,920 --> 00:39:28,320
and and this is a very expensive

00:39:26,880 --> 00:39:30,560
operation and

00:39:28,320 --> 00:39:32,960
like i'm sure to make it less expensive

00:39:30,560 --> 00:39:36,640
with granular updates but still it is

00:39:32,960 --> 00:39:40,160
but yeah it takes time to run a canary

00:39:36,640 --> 00:39:42,960
and we need a lot of confidence

00:39:40,160 --> 00:39:44,240
in our gating service and we do that

00:39:42,960 --> 00:39:47,040
with

00:39:44,240 --> 00:39:48,720
end-to-end testing and hundreds of

00:39:47,040 --> 00:39:50,240
scenarios that within time will turn

00:39:48,720 --> 00:39:53,839
into probably thousands

00:39:50,240 --> 00:39:54,400
and still and and we test in canary we

00:39:53,839 --> 00:39:57,839
test

00:39:54,400 --> 00:39:59,040
the the entire service is not breaking

00:39:57,839 --> 00:40:01,520
its contract and

00:39:59,040 --> 00:40:02,400
everything and if it does settle flows

00:40:01,520 --> 00:40:05,920
yes

00:40:02,400 --> 00:40:08,960
so this is one set of gates

00:40:05,920 --> 00:40:13,040
yes sir with new

00:40:08,960 --> 00:40:17,040
features and and new releases

00:40:13,040 --> 00:40:18,880
of new pages and whatever functionality

00:40:17,040 --> 00:40:21,520
yeah really whatever is

00:40:18,880 --> 00:40:22,800
you want to control not at the instance

00:40:21,520 --> 00:40:26,079
level but at that

00:40:22,800 --> 00:40:26,720
code level you want to hide a chunk of

00:40:26,079 --> 00:40:29,920
code

00:40:26,720 --> 00:40:31,280
or a page or a single thing inside the

00:40:29,920 --> 00:40:34,880
same binary

00:40:31,280 --> 00:40:35,839
so with feature flags you can either use

00:40:34,880 --> 00:40:39,839
a b testing

00:40:35,839 --> 00:40:41,839
to to measure your user's behavior

00:40:39,839 --> 00:40:43,599
and true that's a separate they have it

00:40:41,839 --> 00:40:46,000
yeah and

00:40:43,599 --> 00:40:47,280
we use feature flagging in that context

00:40:46,000 --> 00:40:51,119
right for

00:40:47,280 --> 00:40:54,800
um like you said before less spread use

00:40:51,119 --> 00:40:57,760
reduction yes sir and we can release

00:40:54,800 --> 00:40:59,520
new features often and actually turn

00:40:57,760 --> 00:41:03,520
them off if something goes wrong

00:40:59,520 --> 00:41:06,319
instead of rolling uh back the entire um

00:41:03,520 --> 00:41:06,880
blob yep the entire service yeah which

00:41:06,319 --> 00:41:10,000
is

00:41:06,880 --> 00:41:10,720
like i said expensive expensive uh and

00:41:10,000 --> 00:41:12,480
risky

00:41:10,720 --> 00:41:15,280
by the way not only expensive but it

00:41:12,480 --> 00:41:18,160
also is risky in terms of um

00:41:15,280 --> 00:41:18,880
it's expensive to uh roll back we

00:41:18,160 --> 00:41:22,720
usually

00:41:18,880 --> 00:41:25,680
just turn off a flag fix the code

00:41:22,720 --> 00:41:27,520
and roll out a new uh a new uh so always

00:41:25,680 --> 00:41:31,520
forward rolling yeah

00:41:27,520 --> 00:41:34,640
we we tend to do it forward unless

00:41:31,520 --> 00:41:38,480
this fix will take more time

00:41:34,640 --> 00:41:41,520
than rolling out yeah and

00:41:38,480 --> 00:41:44,240
it's a set of uh trade-offs we

00:41:41,520 --> 00:41:44,720
prefer to just turn off that chunk of

00:41:44,240 --> 00:41:47,680
code

00:41:44,720 --> 00:41:48,480
and move forward fix it release a new

00:41:47,680 --> 00:41:52,720
version

00:41:48,480 --> 00:41:55,040
and this mitigates the entire uh uh

00:41:52,720 --> 00:41:56,079
response sort of like it's a risk that

00:41:55,040 --> 00:41:57,680
we have in production

00:41:56,079 --> 00:41:59,760
one important piece to add before we

00:41:57,680 --> 00:42:01,839
move ahead for flag slipping

00:41:59,760 --> 00:42:03,920
is that it is very important to have a

00:42:01,839 --> 00:42:06,319
process that within time

00:42:03,920 --> 00:42:07,920
systematically identifies flags that

00:42:06,319 --> 00:42:09,040
were already turned on for general

00:42:07,920 --> 00:42:11,359
availability

00:42:09,040 --> 00:42:12,480
goes back to the code and removes these

00:42:11,359 --> 00:42:14,400
conditional blocks

00:42:12,480 --> 00:42:15,599
because otherwise if you don't do it and

00:42:14,400 --> 00:42:16,960
and we've seen environments where

00:42:15,599 --> 00:42:19,280
unfortunately it doesn't happen

00:42:16,960 --> 00:42:21,280
your code will turn into something

00:42:19,280 --> 00:42:23,040
spaghetti it's some other type of pasta

00:42:21,280 --> 00:42:25,200
where every new addition is sort of like

00:42:23,040 --> 00:42:26,720
surrounded by blocks etc right

00:42:25,200 --> 00:42:28,839
it is very important to understand that

00:42:26,720 --> 00:42:31,200
if you go this route you need to have a

00:42:28,839 --> 00:42:33,119
discipline to make it temporary

00:42:31,200 --> 00:42:35,119
temporary is not from today to tomorrow

00:42:33,119 --> 00:42:37,599
sometimes it may take us a month

00:42:35,119 --> 00:42:38,800
to gain confidence in a certain change

00:42:37,599 --> 00:42:41,200
or if

00:42:38,800 --> 00:42:43,200
we do a b testing then you know what one

00:42:41,200 --> 00:42:43,680
of them will end up being not the chosen

00:42:43,200 --> 00:42:47,119
option

00:42:43,680 --> 00:42:50,079
but still so um guys i sure hope that

00:42:47,119 --> 00:42:50,400
it is useful our discussion here to sum

00:42:50,079 --> 00:42:52,240
up

00:42:50,400 --> 00:42:53,680
some of the points first of all

00:42:52,240 --> 00:42:55,680
application metrics

00:42:53,680 --> 00:42:57,119
that are so important for performing

00:42:55,680 --> 00:42:59,440
progressive deployments

00:42:57,119 --> 00:43:00,480
could be gained automatically by using

00:42:59,440 --> 00:43:02,640
service mesh

00:43:00,480 --> 00:43:04,560
latency success rate etc but if you do

00:43:02,640 --> 00:43:07,119
not have service mesh you can still

00:43:04,560 --> 00:43:08,000
do the same metrics applicatively by

00:43:07,119 --> 00:43:11,680
yourself

00:43:08,000 --> 00:43:14,240
and this is um like 50

00:43:11,680 --> 00:43:16,000
of the benefit we gain by using service

00:43:14,240 --> 00:43:18,800
mesh the other 50

00:43:16,000 --> 00:43:19,520
is the fact that we can now do the

00:43:18,800 --> 00:43:22,400
traffic

00:43:19,520 --> 00:43:23,359
shift not only on the top tier right in

00:43:22,400 --> 00:43:26,800
the entry level

00:43:23,359 --> 00:43:28,880
but actually inside even very deep in in

00:43:26,800 --> 00:43:30,160
sort of like second third fourth fifth

00:43:28,880 --> 00:43:33,839
no matter how deep

00:43:30,160 --> 00:43:36,240
tier of our services and that piece

00:43:33,839 --> 00:43:37,760
is the benefit that you will get easily

00:43:36,240 --> 00:43:39,680
only with service mesh

00:43:37,760 --> 00:43:41,040
trying to close that gap with an api

00:43:39,680 --> 00:43:44,000
gateway is possible

00:43:41,040 --> 00:43:46,000
but it's not easy um we did custom gates

00:43:44,000 --> 00:43:48,560
from our progressive rollout

00:43:46,000 --> 00:43:50,400
but it is not mandatory we we used it to

00:43:48,560 --> 00:43:52,880
express our own culture

00:43:50,400 --> 00:43:54,000
um flex flipping as you've seen for us

00:43:52,880 --> 00:43:57,280
again it is a very

00:43:54,000 --> 00:44:00,480
main thing we couldn't imagine our life

00:43:57,280 --> 00:44:01,200
without it and remember that piece we

00:44:00,480 --> 00:44:03,599
started with

00:44:01,200 --> 00:44:04,480
the fact that our continuous deployment

00:44:03,599 --> 00:44:07,640
pipeline

00:44:04,480 --> 00:44:10,560
is separated from the ci by a

00:44:07,640 --> 00:44:12,640
reconciliation loop which is declarative

00:44:10,560 --> 00:44:14,240
this is the state we desire in our

00:44:12,640 --> 00:44:16,240
production and now

00:44:14,240 --> 00:44:17,520
it's a goal of a certain continuous

00:44:16,240 --> 00:44:19,760
component to

00:44:17,520 --> 00:44:20,960
maintain that state no matter what

00:44:19,760 --> 00:44:23,760
changes it right so

00:44:20,960 --> 00:44:25,119
it could be either the desired changes

00:44:23,760 --> 00:44:27,920
and we now need to

00:44:25,119 --> 00:44:28,880
fix the production or for some reason

00:44:27,920 --> 00:44:31,280
the production

00:44:28,880 --> 00:44:32,560
state changes and we need to align it

00:44:31,280 --> 00:44:35,359
back to the design

00:44:32,560 --> 00:44:36,240
and also like i said before so we

00:44:35,359 --> 00:44:38,319
believe in

00:44:36,240 --> 00:44:39,920
an infrastructure's code and going

00:44:38,319 --> 00:44:42,720
through the same

00:44:39,920 --> 00:44:44,800
procedures as developers absolutely by

00:44:42,720 --> 00:44:47,200
using a reconciliation loop

00:44:44,800 --> 00:44:48,720
that enforces people to go through git

00:44:47,200 --> 00:44:51,680
because if they change

00:44:48,720 --> 00:44:52,720
manually and five minutes after flux

00:44:51,680 --> 00:44:55,680
runs

00:44:52,720 --> 00:44:57,119
it runs over the changes absolutely

00:44:55,680 --> 00:45:00,160
that's the reconciliation loop

00:44:57,119 --> 00:45:03,680
yeah and it enforces devs and

00:45:00,160 --> 00:45:06,480
sres to go through the the

00:45:03,680 --> 00:45:07,839
normal processes as developers going

00:45:06,480 --> 00:45:11,200
through prs

00:45:07,839 --> 00:45:12,240
people audit it we get all the benefits

00:45:11,200 --> 00:45:15,680
of git

00:45:12,240 --> 00:45:18,880
and code inside infrastructure

00:45:15,680 --> 00:45:22,400
deployments and everything is audited

00:45:18,880 --> 00:45:25,680
and viewable reviewable and

00:45:22,400 --> 00:45:26,000
sounds great yeah it sounds guys we are

00:45:25,680 --> 00:45:28,240
all

00:45:26,000 --> 00:45:29,359
in lineage and we sure as hell hope that

00:45:28,240 --> 00:45:32,240
you enjoyed

00:45:29,359 --> 00:45:33,119
this presentation we are you're

00:45:32,240 --> 00:45:34,880
available

00:45:33,119 --> 00:45:47,839
we're available for any questions reach

00:45:34,880 --> 00:45:47,839
out to us thank you thank you very much

00:45:51,920 --> 00:45:54,000

YouTube URL: https://www.youtube.com/watch?v=f9ttyXNHp7k


