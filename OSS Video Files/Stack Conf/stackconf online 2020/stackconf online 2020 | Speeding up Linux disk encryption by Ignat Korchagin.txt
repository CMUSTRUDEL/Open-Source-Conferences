Title: stackconf online 2020 | Speeding up Linux disk encryption by Ignat Korchagin
Publication date: 2020-06-27
Playlist: stackconf online 2020
Description: 
	Encrypting data at rest is a must-have for any modern SaaS company. And if you run your software stack on Linux, LUKS/dm-crypt [1] is the usual go-to solution. However, as the storage becomes faster, the IO latency, introduced by dm-crypt becomes rather noticeable, especially on IO intensive workloads.

At first glance it may seem natural, because data encryption is considered an expensive operation. But most modern hardware (specifically x86 and arm64) platforms have hardware optimisations to make encryption fast and less CPU intensive. Nevertheless, even on such hardware transparent disk encryption performs quite poorly.


NETWAYS
Konferenzen: https://www.netways.de/events
Schulungen: https://www.netways.de/schulungen
Shop: https://shop.netways.de/
Blog: http://blog.netways.de/
NWS: https://nws.netways.de 

Webinare
Archiv Link: https://www.netways.de/webinare/archi...
Aktuell: https://www.netways.de/wb

Social Media
SlideShare: http://de.slideshare.net/netways
YouTube: https://www.netways.de/youtube
Facebook: https://www.facebook.com/netways
Twitter: https://twitter.com/netways
Instagram: https://www.instagram.com/netwaysgmbh/

Music: Walking on Air - https://www.frametraxx.de/
Captions: 
	00:00:00,450 --> 00:00:13,529
[Music]

00:00:13,900 --> 00:00:20,240
hello everyone did this thing on I

00:00:18,650 --> 00:00:22,670
always wanted to do that

00:00:20,240 --> 00:00:25,160
hello everyone thanks for tuning in and

00:00:22,670 --> 00:00:26,960
my name is Ignat and today we're going

00:00:25,160 --> 00:00:29,930
to talk about how to speed up disk

00:00:26,960 --> 00:00:32,599
encryption and Linux and just so you

00:00:29,930 --> 00:00:34,670
know this talk is pre-recorded so so you

00:00:32,599 --> 00:00:36,680
get the best quality and probably

00:00:34,670 --> 00:00:41,269
because I have very bad broadband at

00:00:36,680 --> 00:00:43,909
home but I supposed to be online when

00:00:41,269 --> 00:00:48,949
you this talk is being streamed so I

00:00:43,909 --> 00:00:52,580
will I should be here to answer all the

00:00:48,949 --> 00:00:55,159
questions you might have but so the

00:00:52,580 --> 00:00:57,860
conference organizers promise to

00:00:55,159 --> 00:01:00,350
organize the online chat for us to

00:00:57,860 --> 00:01:03,379
communicate however something goes wrong

00:01:00,350 --> 00:01:06,280
is something it doesn't happen as it

00:01:03,379 --> 00:01:08,600
should every slide in my presentation

00:01:06,280 --> 00:01:10,909
including the first one has my Twitter

00:01:08,600 --> 00:01:14,630
handle so please feel free to reach out

00:01:10,909 --> 00:01:17,800
with any questions you have during or

00:01:14,630 --> 00:01:22,040
after the presentation or any time okay

00:01:17,800 --> 00:01:24,860
so let's go forward first of all a

00:01:22,040 --> 00:01:27,110
little bit about myself I work at

00:01:24,860 --> 00:01:31,070
Klopfer I mostly do performance and

00:01:27,110 --> 00:01:33,560
security I also am passionate about a

00:01:31,070 --> 00:01:36,140
cryptography and I enjoy low-level

00:01:33,560 --> 00:01:39,860
programming something like Linux

00:01:36,140 --> 00:01:43,430
low-level kernel implementations boot

00:01:39,860 --> 00:01:46,580
loaders firmware etcetera etcetera and

00:01:43,430 --> 00:01:48,560
sometimes embedded systems that's why

00:01:46,580 --> 00:01:49,780
we're going to talk a lot about the next

00:01:48,560 --> 00:01:54,650
goal these days

00:01:49,780 --> 00:01:57,170
okay let's move to encrypting data with

00:01:54,650 --> 00:02:01,580
disk encryption we were going to talk

00:01:57,170 --> 00:02:04,340
about encrypting data at rest so what

00:02:01,580 --> 00:02:07,610
does it mean to encrypt data at rest

00:02:04,340 --> 00:02:09,259
data address means all the data you

00:02:07,610 --> 00:02:11,690
store on some kind of a persistent

00:02:09,259 --> 00:02:14,750
storage should be encrypted and this is

00:02:11,690 --> 00:02:17,480
a must-have for any modern SAS company

00:02:14,750 --> 00:02:19,819
and probably most users

00:02:17,480 --> 00:02:24,200
days and put their laptops as well just

00:02:19,819 --> 00:02:27,230
to make sure this is an easy way to make

00:02:24,200 --> 00:02:29,060
yourself and your data secure and it

00:02:27,230 --> 00:02:36,769
makes much harder for a potential

00:02:29,060 --> 00:02:41,480
attacker to implement any breach in the

00:02:36,769 --> 00:02:44,720
system because they get access to the

00:02:41,480 --> 00:02:47,659
data tissue in terms of implementation

00:02:44,720 --> 00:02:49,790
how is actually data being encrypted

00:02:47,659 --> 00:02:52,879
when installed there are multiple levels

00:02:49,790 --> 00:02:55,250
of that and to understand all of them we

00:02:52,879 --> 00:02:57,079
need to review the storage stack for it

00:02:55,250 --> 00:02:59,450
this is the typical operating system

00:02:57,079 --> 00:03:02,150
storage step so at the top of the stack

00:02:59,450 --> 00:03:04,790
we have our applications of services

00:03:02,150 --> 00:03:07,549
which run on our hardware or some

00:03:04,790 --> 00:03:10,579
somewhere in the cloud application user

00:03:07,549 --> 00:03:14,569
usually read and write data in files so

00:03:10,579 --> 00:03:17,420
and the Sun and so they communicate with

00:03:14,569 --> 00:03:21,980
the file system file system translate

00:03:17,420 --> 00:03:23,810
these files into blocks because the

00:03:21,980 --> 00:03:26,630
underlying storage is usually some kind

00:03:23,810 --> 00:03:32,859
of a block storage and block storage can

00:03:26,630 --> 00:03:37,190
only read and store and retrieve data in

00:03:32,859 --> 00:03:38,900
blocks so that way that's why underneath

00:03:37,190 --> 00:03:41,049
the file system we usually have an

00:03:38,900 --> 00:03:43,730
operating system block subsystem which

00:03:41,049 --> 00:03:46,310
to receive these blocks from the file

00:03:43,730 --> 00:03:48,709
system and then forward them to some

00:03:46,310 --> 00:03:51,200
storage hardware so block system is

00:03:48,709 --> 00:03:53,120
usually pronounced device drivers to

00:03:51,200 --> 00:03:56,060
access different types of storage

00:03:53,120 --> 00:03:59,090
hardware like as these spinning disks

00:03:56,060 --> 00:04:02,269
and we need disks and other types of

00:03:59,090 --> 00:04:05,440
storage so with respect to the storage

00:04:02,269 --> 00:04:08,950
stack we can encrypt data at each level

00:04:05,440 --> 00:04:13,129
we can encrypt data at storage hardware

00:04:08,950 --> 00:04:15,230
level we can also so technically you can

00:04:13,129 --> 00:04:20,479
just buy disks which do encryption and

00:04:15,230 --> 00:04:22,310
for you we can also include data in the

00:04:20,479 --> 00:04:26,020
operating system block subsystem which

00:04:22,310 --> 00:04:27,220
is at a usual the most typical use case

00:04:26,020 --> 00:04:30,010
exam

00:04:27,220 --> 00:04:32,170
is in Linux we have lock city and crate

00:04:30,010 --> 00:04:35,440
which were then going to extensively

00:04:32,170 --> 00:04:37,780
talk about this presentation in Windows

00:04:35,440 --> 00:04:42,370
we have the famous BitLocker and you

00:04:37,780 --> 00:04:44,710
might have this file volt in my code we

00:04:42,370 --> 00:04:46,960
can encrypt data in a file system there

00:04:44,710 --> 00:04:49,120
on now there are file system which

00:04:46,960 --> 00:04:52,420
actually support transparent data

00:04:49,120 --> 00:04:53,860
encryption specifically Linux examples

00:04:52,420 --> 00:04:57,070
are equipped the fast

00:04:53,860 --> 00:04:59,680
or the new FS script previously known as

00:04:57,070 --> 00:05:02,370
XT for encryption but now it supports

00:04:59,680 --> 00:05:05,350
more file systems than just weeks before

00:05:02,370 --> 00:05:08,380
and of course you can just encrypt the

00:05:05,350 --> 00:05:11,230
data in your application you can use

00:05:08,380 --> 00:05:15,310
some kind of crypto library to encrypt

00:05:11,230 --> 00:05:17,380
abate it before even sending up let's

00:05:15,310 --> 00:05:19,780
review pros and cons of each layer so

00:05:17,380 --> 00:05:22,720
for storage hardware quick encryption

00:05:19,780 --> 00:05:25,390
the obvious advantages are it's just

00:05:22,720 --> 00:05:27,340
fair if you buy a desk which can equip

00:05:25,390 --> 00:05:30,310
data you don't have to do anything else

00:05:27,340 --> 00:05:32,500
equal to one you don't become that's why

00:05:30,310 --> 00:05:34,150
you don't need much configuration or we

00:05:32,500 --> 00:05:37,390
need to provide it like an encryption

00:05:34,150 --> 00:05:39,490
key or password and the disk will do it

00:05:37,390 --> 00:05:42,310
for you it's fully transparent to your

00:05:39,490 --> 00:05:44,440
application and services so they don't

00:05:42,310 --> 00:05:46,300
even know that the data is a sent to

00:05:44,440 --> 00:05:48,160
disk is being transparently encrypted

00:05:46,300 --> 00:05:50,740
and it's usually faster than other

00:05:48,160 --> 00:05:53,860
layers because encryption is done in the

00:05:50,740 --> 00:05:57,220
hardware and we don't use the host CPU

00:05:53,860 --> 00:06:00,070
resources to perform the encryption the

00:05:57,220 --> 00:06:03,250
cons are there is no visibility into the

00:06:00,070 --> 00:06:04,710
implementation and most of the

00:06:03,250 --> 00:06:08,440
implementations are proprietary

00:06:04,710 --> 00:06:11,070
proprietary is a fully audited which

00:06:08,440 --> 00:06:14,440
sometimes leads to poor security and

00:06:11,070 --> 00:06:16,630
there was a recent study of security of

00:06:14,440 --> 00:06:19,540
hardware disk encryption in different

00:06:16,630 --> 00:06:22,930
discs and the results were so bad so

00:06:19,540 --> 00:06:25,210
Microsoft for example decided to switch

00:06:22,930 --> 00:06:28,790
to software disk encryption by default

00:06:25,210 --> 00:06:31,760
in it the clock implemented

00:06:28,790 --> 00:06:34,630
and hiring the stack we have locally

00:06:31,760 --> 00:06:38,390
encryption again it's very similar to

00:06:34,630 --> 00:06:40,610
Hardware full disk encryption except

00:06:38,390 --> 00:06:42,980
that implemented in the block layer

00:06:40,610 --> 00:06:45,320
subsystem of the operating system it has

00:06:42,980 --> 00:06:47,420
similar prongs so brahs

00:06:45,320 --> 00:06:49,850
so it also requires a little

00:06:47,420 --> 00:06:51,530
configuration it's also fully

00:06:49,850 --> 00:06:53,600
transparent or application

00:06:51,530 --> 00:06:58,460
unlike Hardware disk encryption it's

00:06:53,600 --> 00:07:00,860
usually open and/or auditable so if you

00:06:58,460 --> 00:07:02,600
use an open-source system like the

00:07:00,860 --> 00:07:04,160
operating system like Linux you can look

00:07:02,600 --> 00:07:08,150
into the source and make sure it does

00:07:04,160 --> 00:07:10,730
what it describes to do and the

00:07:08,150 --> 00:07:13,930
downsides are it requires somewhat

00:07:10,730 --> 00:07:16,700
specialized crypto so encrypting and

00:07:13,930 --> 00:07:20,870
independent blocks on a storage is kind

00:07:16,700 --> 00:07:24,230
of a hard problem so you need to use a

00:07:20,870 --> 00:07:28,280
specialized cipher modes to actually do

00:07:24,230 --> 00:07:30,080
secure encryption there are some

00:07:28,280 --> 00:07:32,660
performance issues which we are going to

00:07:30,080 --> 00:07:34,880
talk about in this presentation because

00:07:32,660 --> 00:07:37,520
we use the host CPU resource to actually

00:07:34,880 --> 00:07:41,270
do the encryption and your encryption

00:07:37,520 --> 00:07:46,850
keys stay in RAM because the cost CPU is

00:07:41,270 --> 00:07:48,350
done the encryption key to harness that

00:07:46,850 --> 00:07:51,020
we have file system level encryption

00:07:48,350 --> 00:07:54,620
it's also somewhat transparent to

00:07:51,020 --> 00:07:57,140
applications it's also open if you use

00:07:54,620 --> 00:07:59,980
an open source operating system it is

00:07:57,140 --> 00:08:04,010
more fine-grained so unlike block level

00:07:59,980 --> 00:08:05,900
and data encryption with file encryption

00:08:04,010 --> 00:08:08,510
you can have more flexibility in terms

00:08:05,900 --> 00:08:10,790
of you can encrypt specific directories

00:08:08,510 --> 00:08:13,340
not the whole file system you can have

00:08:10,790 --> 00:08:14,210
different keys for different directory

00:08:13,340 --> 00:08:16,310
per user

00:08:14,210 --> 00:08:20,870
etcetera etcetera and there is usually

00:08:16,310 --> 00:08:23,690
more choice of crypto and some integrity

00:08:20,870 --> 00:08:25,640
support sometimes the downsides are

00:08:23,690 --> 00:08:29,630
again performance issues with encryption

00:08:25,640 --> 00:08:32,240
software encryption keys in RAM it's

00:08:29,630 --> 00:08:33,000
some more flexibility comes with the

00:08:32,240 --> 00:08:34,740
need of more

00:08:33,000 --> 00:08:37,680
this configuration we actually need to

00:08:34,740 --> 00:08:40,580
configure everything which do return to

00:08:37,680 --> 00:08:43,530
include which key to use etc etc and

00:08:40,580 --> 00:08:46,260
somewhat decreased security because this

00:08:43,530 --> 00:08:49,070
filesystem layer encryption you have

00:08:46,260 --> 00:08:51,780
some unencrypted meta data for example

00:08:49,070 --> 00:08:53,940
with block level encryption everything

00:08:51,780 --> 00:08:56,130
on the desk is being encrypted including

00:08:53,940 --> 00:08:58,380
free space with filesystem layer

00:08:56,130 --> 00:09:01,230
encryption we only encrypt data in files

00:08:58,380 --> 00:09:04,560
and sometimes a file names but not the

00:09:01,230 --> 00:09:06,840
file size don't encrypt free space so

00:09:04,560 --> 00:09:09,180
there is a lot of auxilary information

00:09:06,840 --> 00:09:11,280
available to a potential attacker which

00:09:09,180 --> 00:09:14,550
may or may not be usual depending on

00:09:11,280 --> 00:09:16,080
this button and on the top of the stack

00:09:14,550 --> 00:09:17,730
we can do our encryption in the

00:09:16,080 --> 00:09:19,080
application itself again it's open

00:09:17,730 --> 00:09:21,870
because we wrote it

00:09:19,080 --> 00:09:24,270
it's very fine-grained so you can write

00:09:21,870 --> 00:09:27,090
it as you like and you have foolproof

00:09:24,270 --> 00:09:29,400
flexibility we can use any algorithms

00:09:27,090 --> 00:09:34,020
you want anyway we're on the downside

00:09:29,400 --> 00:09:36,150
again your encryption theory Ram and you

00:09:34,020 --> 00:09:38,160
actually need to code it yourself so

00:09:36,150 --> 00:09:39,900
it's not transparent to your application

00:09:38,160 --> 00:09:43,020
you need to implement the encryption

00:09:39,900 --> 00:09:46,890
code either using sublight some like the

00:09:43,020 --> 00:09:48,870
world from scratch or not you again you

00:09:46,890 --> 00:09:51,750
have the unencrypted metadata problem

00:09:48,870 --> 00:09:55,400
and the downside is full crypto

00:09:51,750 --> 00:09:58,230
flexibility actually implementing crypto

00:09:55,400 --> 00:10:00,839
yourself is quite hard even if you use a

00:09:58,230 --> 00:10:03,510
well-known cryptographic library because

00:10:00,839 --> 00:10:06,060
there are a lot of caveats so usually

00:10:03,510 --> 00:10:09,410
the good choice here is don't roll your

00:10:06,060 --> 00:10:09,410
own filter and rely on

00:10:10,750 --> 00:10:16,000
so let's talk about block layer software

00:10:14,060 --> 00:10:19,430
encryption and let's talk about clinics

00:10:16,000 --> 00:10:23,330
close for like many SAS companies we

00:10:19,430 --> 00:10:26,000
chose to use block level encryption in

00:10:23,330 --> 00:10:28,580
software because we don't trust Hardware

00:10:26,000 --> 00:10:30,830
enough to the same as Microsoft to do it

00:10:28,580 --> 00:10:33,650
for us but we don't need all the

00:10:30,830 --> 00:10:35,930
additional flexibility and in complexity

00:10:33,650 --> 00:10:38,330
from the application and filesystem side

00:10:35,930 --> 00:10:40,340
we just want to encrypt everything we

00:10:38,330 --> 00:10:42,230
don't true we don't want to pick the

00:10:40,340 --> 00:10:44,510
data which should be encrypted it should

00:10:42,230 --> 00:10:47,090
not we just want to say that we treat

00:10:44,510 --> 00:10:49,490
with respect to security we treat all

00:10:47,090 --> 00:10:53,390
data equally so we would like everything

00:10:49,490 --> 00:10:57,290
to be encrypted by the phone and we use

00:10:53,390 --> 00:10:58,820
Linux everywhere so that's why for the

00:10:57,290 --> 00:11:00,770
rest of the presentation we're going to

00:10:58,820 --> 00:11:04,400
talk about the implementation of disk

00:11:00,770 --> 00:11:08,870
encryption block level disk encryption

00:11:04,400 --> 00:11:12,710
on Linux which is known as locks or the

00:11:08,870 --> 00:11:13,970
anchor so the encrypt is a kernel side

00:11:12,710 --> 00:11:18,430
part of the disk encryption

00:11:13,970 --> 00:11:18,430
implementation locks into the user space

00:11:20,440 --> 00:11:25,390
okay what is to understand what it's DM

00:11:23,140 --> 00:11:27,610
crypt or lock rocks we need to

00:11:25,390 --> 00:11:30,010
understand what is device mapper

00:11:27,610 --> 00:11:33,070
so the encrypt is a module which is part

00:11:30,010 --> 00:11:36,040
of the general more generic Linux kernel

00:11:33,070 --> 00:11:40,450
framework or device mapper and what that

00:11:36,040 --> 00:11:41,890
framework does it allows modules which

00:11:40,450 --> 00:11:44,410
are part of this framework to be

00:11:41,890 --> 00:11:46,510
inserted between applications and block

00:11:44,410 --> 00:11:49,060
device drivers to provide additional

00:11:46,510 --> 00:11:51,370
different additional functionality let's

00:11:49,060 --> 00:11:54,250
see an example so let's say we have our

00:11:51,370 --> 00:11:56,050
application of services which read write

00:11:54,250 --> 00:11:58,480
files from the file system so they

00:11:56,050 --> 00:12:00,430
communicate with the file systems and by

00:11:58,480 --> 00:12:03,070
default the file system just communicate

00:12:00,430 --> 00:12:06,370
with blog device drivers they convert

00:12:03,070 --> 00:12:08,500
file i/o team block io and just send the

00:12:06,370 --> 00:12:10,600
blocks to block device drivers to be

00:12:08,500 --> 00:12:13,600
stored and real shortly so the wife

00:12:10,600 --> 00:12:15,520
swapper allows modules to be inserted in

00:12:13,600 --> 00:12:18,190
between file systems and block device

00:12:15,520 --> 00:12:21,610
drivers and depending on which module it

00:12:18,190 --> 00:12:23,650
is or in deployment a ssin we can

00:12:21,610 --> 00:12:26,110
provide additional functionality so for

00:12:23,650 --> 00:12:29,560
example there is a DM raid module which

00:12:26,110 --> 00:12:31,900
is useful for implementing software raid

00:12:29,560 --> 00:12:33,970
arrays there is a demurrer module which

00:12:31,900 --> 00:12:36,120
can transparently backup your data to a

00:12:33,970 --> 00:12:38,860
secondary storage as you write it and

00:12:36,120 --> 00:12:41,050
there is and we're going to talk about

00:12:38,860 --> 00:12:43,630
the encrypt model which transparently

00:12:41,050 --> 00:12:46,540
encrypts of the crips block at your

00:12:43,630 --> 00:12:49,690
request as we go through the device

00:12:46,540 --> 00:12:54,130
drivers so let's zoom in into the

00:12:49,690 --> 00:12:58,530
encrypt and let's see how it works on a

00:12:54,130 --> 00:13:01,120
like 1000 from 1000 feet view so again

00:12:58,530 --> 00:13:05,100
we'll skip the application part here we

00:13:01,120 --> 00:13:07,390
have the file systems which sand block

00:13:05,100 --> 00:13:09,070
which send block at your request to

00:13:07,390 --> 00:13:12,880
block device drivers so the encrypt

00:13:09,070 --> 00:13:15,700
itself inserts itself in between and it

00:13:12,880 --> 00:13:17,680
basically encrypts

00:13:15,700 --> 00:13:20,260
every right before sending it to the

00:13:17,680 --> 00:13:23,669
block device driver and the creeps every

00:13:20,260 --> 00:13:26,139
read before passing it back to the first

00:13:23,669 --> 00:13:28,660
the nice thing about the encrypted

00:13:26,139 --> 00:13:30,789
doesn't implement crypto on its own but

00:13:28,660 --> 00:13:32,739
it uses well-defined Linux crypto API

00:13:30,789 --> 00:13:34,869
which is also part of the Linux

00:13:32,739 --> 00:13:38,079
framework and provide generic traffic

00:13:34,869 --> 00:13:40,479
services so we kind of have a separation

00:13:38,079 --> 00:13:45,609
here like gluto implementation from its

00:13:40,479 --> 00:13:50,199
natural user but not everything is great

00:13:45,609 --> 00:13:53,979
so at some point we noticed we have some

00:13:50,199 --> 00:13:57,009
performance issues with encrypted disk

00:13:53,979 --> 00:14:00,789
and we decided to take a closer look how

00:13:57,009 --> 00:14:05,649
performant the Linux disk encryption

00:14:00,789 --> 00:14:08,249
implementation is so we will check we

00:14:05,649 --> 00:14:11,999
will do some DM creep benchmarking here

00:14:08,249 --> 00:14:14,679
when you do any kind of benchmarking

00:14:11,999 --> 00:14:16,929
basically you always introduce the bias

00:14:14,679 --> 00:14:19,089
of underlying hardware so if you

00:14:16,929 --> 00:14:22,269
benchmark on the slow this could get bad

00:14:19,089 --> 00:14:25,209
result if you benchmark on a fast modern

00:14:22,269 --> 00:14:27,549
SSD you get better result but to

00:14:25,209 --> 00:14:29,589
eliminate all the bias let's do the

00:14:27,549 --> 00:14:33,159
benchmarking on the fastest storage

00:14:29,589 --> 00:14:35,619
layer possible which is RAM and in Linux

00:14:33,159 --> 00:14:39,549
there is a module which allows you to

00:14:35,619 --> 00:14:42,399
create to simulate a disk fully in RAM

00:14:39,549 --> 00:14:44,919
so that's how we will try to remove the

00:14:42,399 --> 00:14:48,970
bias of the real Hardware from our

00:14:44,919 --> 00:14:50,769
benchmarks so to benchmark be purely the

00:14:48,970 --> 00:14:54,519
encrypt implementation we will create

00:14:50,769 --> 00:14:56,350
this four gig ram disks and by the way

00:14:54,519 --> 00:14:59,579
all these comments have been pasted from

00:14:56,350 --> 00:15:02,499
the legal terminal so consider it like a

00:14:59,579 --> 00:15:05,720
non-filing demo and you can actually

00:15:02,499 --> 00:15:09,380
retrace the steps yourself

00:15:05,720 --> 00:15:11,330
they have laptops so okay we create this

00:15:09,380 --> 00:15:15,860
the first common we will just create

00:15:11,330 --> 00:15:19,670
this RAM disk for 4 gig size and the

00:15:15,860 --> 00:15:22,130
second secondly we will allocate file to

00:15:19,670 --> 00:15:26,240
me 2 megabyte file I will just mention

00:15:22,130 --> 00:15:30,080
it I will just mention why right now we

00:15:26,240 --> 00:15:33,140
will use that file to set up a DM DM

00:15:30,080 --> 00:15:36,170
crypt instance on top of our RAM disk

00:15:33,140 --> 00:15:40,550
but we will use it as a detached header

00:15:36,170 --> 00:15:43,580
I will explain why in a second so this

00:15:40,550 --> 00:15:47,510
sets up at the encrypt instance on top

00:15:43,580 --> 00:15:51,680
of our and you will newly created from

00:15:47,510 --> 00:15:53,990
disk and finally we just unlock that

00:15:51,680 --> 00:15:57,980
newly created from disk so we get a new

00:15:53,990 --> 00:16:01,280
DM crypt instance its top of our

00:15:57,980 --> 00:16:03,890
language so here is our storage stack so

00:16:01,280 --> 00:16:08,750
at the bottom we have our brand base

00:16:03,890 --> 00:16:11,390
disk on top of it we created the encrypt

00:16:08,750 --> 00:16:16,430
instance so we can transparently encrypt

00:16:11,390 --> 00:16:19,010
data which goes into our RAM disk for

00:16:16,430 --> 00:16:21,410
the purposes of this benchmarking we

00:16:19,010 --> 00:16:23,990
also don't want to introduce any bias

00:16:21,410 --> 00:16:26,150
introduced by any particular file system

00:16:23,990 --> 00:16:28,310
implementation so we will not use any

00:16:26,150 --> 00:16:32,050
file system here but instead we will

00:16:28,310 --> 00:16:36,020
just write data directly to our

00:16:32,050 --> 00:16:42,800
encrypted into our the encrypt instance

00:16:36,020 --> 00:16:44,690
and we will compare to the performance

00:16:42,800 --> 00:16:47,480
of the same data being written to the

00:16:44,690 --> 00:16:50,240
under purely to the underlying log

00:16:47,480 --> 00:16:52,970
device in unencrypted manner that's why

00:16:50,240 --> 00:16:55,640
we created a detached header here so if

00:16:52,970 --> 00:16:57,650
we use the default non detach Handler

00:16:55,640 --> 00:17:00,080
and locks the header would be stored and

00:16:57,650 --> 00:17:03,430
the first two megabyte of our RAM disk

00:17:00,080 --> 00:17:06,199
and if we just start writing random data

00:17:03,430 --> 00:17:09,110
by passing out the encrypt instance we

00:17:06,199 --> 00:17:12,130
might accidentally override our header

00:17:09,110 --> 00:17:15,669
file and just corrupt the whole pro

00:17:12,130 --> 00:17:19,120
so the massage habit just makes it easy

00:17:15,669 --> 00:17:21,549
to both read and write from an encrypted

00:17:19,120 --> 00:17:24,809
instance and from the underlying device

00:17:21,549 --> 00:17:28,600
safely at any second

00:17:24,809 --> 00:17:32,830
okay so let's test the performance of

00:17:28,600 --> 00:17:35,410
the actual RAM disks unencrypted so for

00:17:32,830 --> 00:17:38,470
this we will create a simulated aureole

00:17:35,410 --> 00:17:40,720
workload which is a simple 50/50

00:17:38,470 --> 00:17:44,740
sequential we'd write workload with

00:17:40,720 --> 00:17:48,010
block size of 4 kilobytes so notice

00:17:44,740 --> 00:17:50,950
we're using the dev Ram device directly

00:17:48,010 --> 00:17:52,360
here so at this point all the data being

00:17:50,950 --> 00:17:55,299
read and breathing is not being

00:17:52,360 --> 00:17:57,880
encrypted or decoder if we run this

00:17:55,299 --> 00:18:00,539
workflow for a while we will see that

00:17:57,880 --> 00:18:05,830
the average throughput we can get is

00:18:00,539 --> 00:18:08,730
around one megabyte per second of reads

00:18:05,830 --> 00:18:11,200
and why gigabyte per second of right so

00:18:08,730 --> 00:18:14,049
cumulatively we get somewhere around two

00:18:11,200 --> 00:18:18,789
gigabyte per second of move right smooth

00:18:14,049 --> 00:18:21,280
which is quite fast because and the read

00:18:18,789 --> 00:18:24,220
and write throughput is same here

00:18:21,280 --> 00:18:26,890
because we use Ram disk and it's not

00:18:24,220 --> 00:18:30,730
much different from the loop with either

00:18:26,890 --> 00:18:34,150
to be the right Conrad so the next step

00:18:30,730 --> 00:18:36,730
let's replace the same workload but this

00:18:34,150 --> 00:18:39,760
time we will be played on the DM crypt

00:18:36,730 --> 00:18:43,299
instance on top of our Ram disk so that

00:18:39,760 --> 00:18:46,780
means that every block will be encrypted

00:18:43,299 --> 00:18:49,929
or decrypted in transit on the fly and

00:18:46,780 --> 00:18:56,230
if we run this workload we will see that

00:18:49,929 --> 00:19:00,240
our swoop would drop up to 150 megabyte

00:18:56,230 --> 00:19:03,909
per second roughly in every direction

00:19:00,240 --> 00:19:06,370
which is actually we could expect that

00:19:03,909 --> 00:19:09,400
the throughput would be lower because

00:19:06,370 --> 00:19:11,230
now we use more resources with this CPU

00:19:09,400 --> 00:19:14,679
to encrypt and decrypt data on the fly

00:19:11,230 --> 00:19:17,350
but this kind of feels like seven times

00:19:14,679 --> 00:19:18,950
slower is too much just for a simple

00:19:17,350 --> 00:19:24,059
encryption

00:19:18,950 --> 00:19:26,640
moreover if we assume let's assume that

00:19:24,059 --> 00:19:30,900
our crypto is law but we can benchmark

00:19:26,640 --> 00:19:32,850
it so the lux userspace utility which is

00:19:30,900 --> 00:19:35,070
called creep setup has a bank in in

00:19:32,850 --> 00:19:37,980
embedded benchmark which you can run and

00:19:35,070 --> 00:19:41,370
you can compare the performance of

00:19:37,980 --> 00:19:43,770
different crypto algorithms at this

00:19:41,370 --> 00:19:46,770
point we know we use is XTS for

00:19:43,770 --> 00:19:50,070
encryption and if you run that benchmark

00:19:46,770 --> 00:19:52,200
you will see that purely encrypting and

00:19:50,070 --> 00:19:56,100
decrypting data you can get somewhere

00:19:52,200 --> 00:20:01,350
around two gigabyte per second of

00:19:56,100 --> 00:20:03,510
throughput so if we do simple back of

00:20:01,350 --> 00:20:06,029
the envelope calculation we just assume

00:20:03,510 --> 00:20:09,740
the worst case that we reading all the

00:20:06,029 --> 00:20:11,820
data from disk in one step and

00:20:09,740 --> 00:20:14,130
sequentially just decrypting it in

00:20:11,820 --> 00:20:16,980
another step we should get somewhere

00:20:14,130 --> 00:20:19,399
around 700 megabytes per second of

00:20:16,980 --> 00:20:22,890
throughput but in the end we actually

00:20:19,399 --> 00:20:26,250
get slightly less than 300 megabyte per

00:20:22,890 --> 00:20:29,520
second of combines group which is far

00:20:26,250 --> 00:20:34,049
less than even we projected in worst

00:20:29,520 --> 00:20:36,750
case so we try to improve something

00:20:34,049 --> 00:20:39,210
so we tried switch into different

00:20:36,750 --> 00:20:43,230
cryptographic algorithms but according

00:20:39,210 --> 00:20:45,000
to creep saddam benchmark is 60s and it

00:20:43,230 --> 00:20:48,539
seems to be the fastest algorithm at

00:20:45,000 --> 00:20:51,690
least on x86 platform we also try to

00:20:48,539 --> 00:20:53,580
experiment with different encrypt option

00:20:51,690 --> 00:20:54,870
of slides so when you instantiate the

00:20:53,580 --> 00:20:57,299
encrypting stands there are some

00:20:54,870 --> 00:20:59,580
additional slides you can specify this

00:20:57,299 --> 00:21:01,799
cryptic name same clip CPU and submit

00:20:59,580 --> 00:21:03,750
encrypt CPU they're marked as

00:21:01,799 --> 00:21:09,059
performance related flags who tried

00:21:03,750 --> 00:21:11,399
these but some flags some flag actually

00:21:09,059 --> 00:21:14,220
then reduced our sweet food some flag

00:21:11,399 --> 00:21:18,360
slightly improved it but it was no

00:21:14,220 --> 00:21:20,760
significant improvement action at some

00:21:18,360 --> 00:21:22,710
point we were so desperate that our

00:21:20,760 --> 00:21:24,480
encryption is so slow we tried file

00:21:22,710 --> 00:21:27,120
system level encryption but in the end

00:21:24,480 --> 00:21:28,360
it ended up being much slow through our

00:21:27,120 --> 00:21:31,269
workload

00:21:28,360 --> 00:21:33,730
also the it would be potential less

00:21:31,269 --> 00:21:39,880
secure because we don't include the file

00:21:33,730 --> 00:21:43,720
metadata so we were a despair at this

00:21:39,880 --> 00:21:46,269
time and we hated the bad performance

00:21:43,720 --> 00:21:48,519
but there was nothing we can do about we

00:21:46,269 --> 00:21:50,710
were so desperate so we decided to us in

00:21:48,519 --> 00:21:55,450
the community and at some point we wrote

00:21:50,710 --> 00:21:58,659
to the DM Creek mailing list it was out

00:21:55,450 --> 00:22:00,760
finding and say hey this performance

00:21:58,659 --> 00:22:03,519
does not look great and can we do

00:22:00,760 --> 00:22:07,029
something about it and but we received

00:22:03,519 --> 00:22:09,669
somewhat unuseful response is basically

00:22:07,029 --> 00:22:11,620
if the numbers disturb you then this is

00:22:09,669 --> 00:22:14,110
from lack of understanding and your side

00:22:11,620 --> 00:22:17,049
your problem where that encryption is a

00:22:14,110 --> 00:22:19,630
heavyweight operation and at this point

00:22:17,049 --> 00:22:22,299
I was surprised like a script oh is that

00:22:19,630 --> 00:22:24,519
expensive and what I did I did it just a

00:22:22,299 --> 00:22:28,330
simple scientific research by googling

00:22:24,519 --> 00:22:30,399
into Google search is crypto expensive

00:22:28,330 --> 00:22:33,490
and one of the first meaningful results

00:22:30,399 --> 00:22:35,980
of found is the blog post from our own

00:22:33,490 --> 00:22:38,590
company where one of my colleagues

00:22:35,980 --> 00:22:41,799
actually investigated the cost of crypto

00:22:38,590 --> 00:22:44,200
but in terms of TLS so closer does a lot

00:22:41,799 --> 00:22:46,120
of TLS connection so at some point one

00:22:44,200 --> 00:22:49,029
of our engineers decided to take a look

00:22:46,120 --> 00:22:53,169
how much of a CPU we actually spend on

00:22:49,029 --> 00:22:55,570
doing crypto and their conclusion was

00:22:53,169 --> 00:22:58,450
actually we don't spend much resources

00:22:55,570 --> 00:23:01,120
and in a modern hardware crypto is very

00:22:58,450 --> 00:23:04,299
cheap and even a cloud for a scale so

00:23:01,120 --> 00:23:08,350
even if we perform millions of TLS

00:23:04,299 --> 00:23:10,389
connections a second we don't spend too

00:23:08,350 --> 00:23:12,279
much CPU on cryptography because it's so

00:23:10,389 --> 00:23:15,309
optimized and implemented in hardware

00:23:12,279 --> 00:23:20,889
these days then it's a it's a minor

00:23:15,309 --> 00:23:22,870
thing so if crypto is so cheap in terms

00:23:20,889 --> 00:23:24,970
of network connections why should it be

00:23:22,870 --> 00:23:26,860
expensive when you store data in this

00:23:24,970 --> 00:23:32,080
there is not much big difference

00:23:26,860 --> 00:23:34,600
actually and actually most TLS and

00:23:32,080 --> 00:23:38,380
data storage encryption used most of the

00:23:34,600 --> 00:23:40,809
same algorithms so at this point and

00:23:38,380 --> 00:23:42,700
because Linux is a nice open source

00:23:40,809 --> 00:23:45,700
operating system we decided to look at

00:23:42,700 --> 00:23:48,010
VB encrypt implementation and see if

00:23:45,700 --> 00:23:50,950
something can be included but we expect

00:23:48,010 --> 00:23:54,040
is a simple module we just encrypt or

00:23:50,950 --> 00:23:58,720
decrypt data as it passes through but in

00:23:54,040 --> 00:24:02,080
the end it actually ended up being much

00:23:58,720 --> 00:24:03,850
more complex than we expected so let's

00:24:02,080 --> 00:24:06,670
review the life of an encrypted bio

00:24:03,850 --> 00:24:08,500
request so again we have our file

00:24:06,670 --> 00:24:11,890
systems which have block device drivers

00:24:08,500 --> 00:24:15,010
and we have the encrypt with script or

00:24:11,890 --> 00:24:17,530
API in between so when a file system

00:24:15,010 --> 00:24:19,450
issues a write request the encrypt does

00:24:17,530 --> 00:24:23,590
not immediately submits it to a block

00:24:19,450 --> 00:24:27,070
device file instead it queues it is in

00:24:23,590 --> 00:24:29,980
an as to be executed on an asynchronous

00:24:27,070 --> 00:24:33,160
read it runs once read per the encrypt

00:24:29,980 --> 00:24:35,230
instance at some point later when that

00:24:33,160 --> 00:24:37,510
threat is actually being scheduled on

00:24:35,230 --> 00:24:41,350
the CPU and executed that request is

00:24:37,510 --> 00:24:44,080
being sent to be encrypted to the crypto

00:24:41,350 --> 00:24:45,880
API but modern crypto API is actually

00:24:44,080 --> 00:24:48,670
also a synchronous so it might not

00:24:45,880 --> 00:24:51,970
process the request immediately but

00:24:48,670 --> 00:24:54,040
decide to queue it again on a different

00:24:51,970 --> 00:24:56,860
a synchronous thread which sometimes

00:24:54,040 --> 00:24:58,750
they call CACREP D and they have like

00:24:56,860 --> 00:25:04,480
one thread per CPU so it's slightly

00:24:58,750 --> 00:25:07,330
faster so at some point crypto API

00:25:04,480 --> 00:25:10,300
processes the requests so it encrypts

00:25:07,330 --> 00:25:13,690
the write request and returns back sorry

00:25:10,300 --> 00:25:15,580
and returns back to the uncrate but

00:25:13,690 --> 00:25:18,130
again the encrypt does not immediately

00:25:15,580 --> 00:25:20,920
submit the encrypted by a request to

00:25:18,130 --> 00:25:24,490
block device driver it queues it on

00:25:20,920 --> 00:25:27,130
another structure a red-black tree for

00:25:24,490 --> 00:25:30,420
sorting so it buffers some of the

00:25:27,130 --> 00:25:32,590
requests and sort them to send the

00:25:30,420 --> 00:25:35,830
accumulated requests in a sequential

00:25:32,590 --> 00:25:37,960
manner to a block device back when the

00:25:35,830 --> 00:25:39,730
requests are ready to be sent there

00:25:37,960 --> 00:25:42,520
again they are not being sent

00:25:39,730 --> 00:25:43,070
immediately there a queue for sending on

00:25:42,520 --> 00:25:46,269
another

00:25:43,070 --> 00:25:49,909
a synchronous read called DM Creek right

00:25:46,269 --> 00:25:52,580
for sanding when the threat will be

00:25:49,909 --> 00:25:55,250
executed by the CPU and at some point

00:25:52,580 --> 00:25:59,179
later that request is being delivered to

00:25:55,250 --> 00:26:01,130
the global iceberg similar thing happens

00:25:59,179 --> 00:26:03,740
for read when a file system issues a

00:26:01,130 --> 00:26:05,960
read request it's been killed by the

00:26:03,740 --> 00:26:09,049
encrypt on a rather a synchronous thread

00:26:05,960 --> 00:26:12,620
called cake with d io when the thread

00:26:09,049 --> 00:26:15,110
executes so that request is being

00:26:12,620 --> 00:26:17,059
forwarded to the blog device driver so

00:26:15,110 --> 00:26:19,070
the blog device driver goes to the

00:26:17,059 --> 00:26:23,179
hardware retrieves the encrypted data

00:26:19,070 --> 00:26:26,000
and returns it back to the D encrypt

00:26:23,179 --> 00:26:29,029
instance but the encrypt instance

00:26:26,000 --> 00:26:31,460
schedules it for decryption meaning

00:26:29,029 --> 00:26:34,759
queues it on a familiar already

00:26:31,460 --> 00:26:37,370
k-kwik D a synchronous read which later

00:26:34,759 --> 00:26:39,350
sends it to crypto API to another

00:26:37,370 --> 00:26:41,779
potentially another synchronous read

00:26:39,350 --> 00:26:45,980
called cake redeem which actually

00:26:41,779 --> 00:26:47,659
performs the decryption and then it

00:26:45,980 --> 00:26:51,919
returns the decrypted result of the

00:26:47,659 --> 00:26:57,259
fastest well that's a lot of queueing

00:26:51,919 --> 00:27:00,470
for simply handling one request like

00:26:57,259 --> 00:27:04,090
read or write request and this o queuing

00:27:00,470 --> 00:27:08,360
remind me of a press nice presentation I

00:27:04,090 --> 00:27:10,309
saw on one of the asari corn using

00:27:08,360 --> 00:27:13,190
accessory Commons in the pour from

00:27:10,309 --> 00:27:16,789
Google and this presentation was more

00:27:13,190 --> 00:27:24,110
generic and it was about the dependency

00:27:16,789 --> 00:27:26,690
of tail latency with respect to choose

00:27:24,110 --> 00:27:28,970
and complex system and it's a very

00:27:26,690 --> 00:27:31,850
interesting presentation on its own and

00:27:28,970 --> 00:27:33,769
I strongly advise everyone to watch it

00:27:31,850 --> 00:27:37,009
it's quite short it's 20 minutes but

00:27:33,769 --> 00:27:38,929
it's very a compact and precise but one

00:27:37,009 --> 00:27:41,750
of the takeaways I took out from there

00:27:38,929 --> 00:27:44,830
is that a significant amount of tail

00:27:41,750 --> 00:27:49,090
latency is due to queuing effects and

00:27:44,830 --> 00:27:54,649
this kind of is the case here so

00:27:49,090 --> 00:27:55,440
basically we queue requests at most four

00:27:54,649 --> 00:27:58,200
times

00:27:55,440 --> 00:28:01,159
for every ride and week you each read

00:27:58,200 --> 00:28:04,970
requests at most three times every week

00:28:01,159 --> 00:28:07,620
and this can be quite damaging

00:28:04,970 --> 00:28:11,340
potentially on a business system where

00:28:07,620 --> 00:28:17,340
system CPU is busy implementing actually

00:28:11,340 --> 00:28:19,409
running our application work so before

00:28:17,340 --> 00:28:22,769
trying to modify anything we would like

00:28:19,409 --> 00:28:25,590
to understand why these cues exist so I

00:28:22,769 --> 00:28:27,600
don't expect someone to just randomly

00:28:25,590 --> 00:28:29,100
add like use because they wanted to

00:28:27,600 --> 00:28:32,190
there probably was a reason for these

00:28:29,100 --> 00:28:34,080
cues to be added there so we decided to

00:28:32,190 --> 00:28:37,799
do a little bit of good archeology

00:28:34,080 --> 00:28:40,500
luckily Linux source code is stored and

00:28:37,799 --> 00:28:43,679
get so you can Hana trace back the

00:28:40,500 --> 00:28:45,899
history and try to understand all the

00:28:43,679 --> 00:28:50,519
decision-making process around each code

00:28:45,899 --> 00:28:51,960
change however the initial K cryptic

00:28:50,519 --> 00:28:55,129
community encrypt was there from the

00:28:51,960 --> 00:28:59,100
beginning from when basically Linux

00:28:55,129 --> 00:29:02,159
started to host its get repository and

00:28:59,100 --> 00:29:07,769
publicly accessible repo it happened

00:29:02,159 --> 00:29:10,350
2005 and it was a only fully read it was

00:29:07,769 --> 00:29:13,049
the comment it would be very unwise to

00:29:10,350 --> 00:29:17,059
decryption in in interrupt context and

00:29:13,049 --> 00:29:19,950
it kind of makes sense in 2005 because

00:29:17,059 --> 00:29:23,610
when you do a read request some device

00:29:19,950 --> 00:29:26,039
drivers will just send your request to

00:29:23,610 --> 00:29:28,799
the actual hardware and hardware may

00:29:26,039 --> 00:29:31,139
notify the host CPU that your data is

00:29:28,799 --> 00:29:33,389
ready by interrupts so you may be

00:29:31,139 --> 00:29:37,860
actually processing with requesting an

00:29:33,389 --> 00:29:40,470
interrupt context however so that's why

00:29:37,860 --> 00:29:42,809
kqd was added more to do decryption in

00:29:40,470 --> 00:29:45,990
interrupts context however however it

00:29:42,809 --> 00:29:49,889
was really necessary in 2005 because

00:29:45,990 --> 00:29:52,500
Linux crypto API in 2005 was not a

00:29:49,889 --> 00:29:54,240
synchronous as it is now so that's why

00:29:52,500 --> 00:29:55,919
the encrypt has this workaround

00:29:54,240 --> 00:29:58,289
to not to perform decryption in

00:29:55,919 --> 00:30:00,210
interrupt context these days probably

00:29:58,289 --> 00:30:03,029
because when you speak to a pair is a

00:30:00,210 --> 00:30:04,200
synchronous itself you don't need the

00:30:03,029 --> 00:30:06,750
code to D anymore

00:30:04,200 --> 00:30:09,769
because Linux crypt API should be smart

00:30:06,750 --> 00:30:12,510
enough to actually upload your

00:30:09,769 --> 00:30:15,950
encryption requests synchronous rather

00:30:12,510 --> 00:30:19,230
not do it in context in the first place

00:30:15,950 --> 00:30:24,690
later some queuing was added to reduce

00:30:19,230 --> 00:30:26,940
kernel stack usage in 2006 so actually

00:30:24,690 --> 00:30:30,059
my initial thought was the queuing was

00:30:26,940 --> 00:30:32,490
added to for some I don't know some

00:30:30,059 --> 00:30:34,080
parallel processing of the requests but

00:30:32,490 --> 00:30:36,450
it's not actually the case

00:30:34,080 --> 00:30:38,789
so kernel developers tried to reduce

00:30:36,450 --> 00:30:41,250
kernel stack usage so minimize the

00:30:38,789 --> 00:30:43,289
function call stack and that's why they

00:30:41,250 --> 00:30:45,179
added this asynchronous behavior to

00:30:43,289 --> 00:30:47,880
actually like return from the function

00:30:45,179 --> 00:30:52,019
earlier and not use and not make the

00:30:47,880 --> 00:30:54,600
stack deeper however kernel stack was

00:30:52,019 --> 00:31:00,090
increased and later so it might not be

00:30:54,600 --> 00:31:02,070
necessary a floating writes to uh

00:31:00,090 --> 00:31:05,519
synchronous read and I or sorting was

00:31:02,070 --> 00:31:09,330
implement in 2015 with the following git

00:31:05,519 --> 00:31:11,250
commit message it's basically to improve

00:31:09,330 --> 00:31:14,190
performance on spinning this because

00:31:11,250 --> 00:31:16,740
spinning disks like sequential reads and

00:31:14,190 --> 00:31:20,130
writes more than randomly the survives

00:31:16,740 --> 00:31:23,010
but it may improve SSDs which might be

00:31:20,130 --> 00:31:25,740
the case in 2015 because as these were

00:31:23,010 --> 00:31:28,590
much less mature than today it the

00:31:25,740 --> 00:31:30,809
chemical message also mentions that it's

00:31:28,590 --> 00:31:32,820
better for cfq scheduler which is

00:31:30,809 --> 00:31:36,110
actually being deprecated and removed

00:31:32,820 --> 00:31:40,139
from the modern Linux Chrome and

00:31:36,110 --> 00:31:42,149
immediately at the same year there were

00:31:40,139 --> 00:31:43,919
commits to optionally revert some of the

00:31:42,149 --> 00:31:45,450
queue so we were not the first one to

00:31:43,919 --> 00:31:48,179
experience the performance degradation

00:31:45,450 --> 00:31:51,000
from the extensive cooling the end creep

00:31:48,179 --> 00:31:54,179
so these optional Flags we tried earlier

00:31:51,000 --> 00:31:56,460
we're actually added in 2015 to bypass

00:31:54,179 --> 00:32:00,330
some of the queuing mentioning that in

00:31:56,460 --> 00:32:03,389
some cases it reduced performance so

00:32:00,330 --> 00:32:05,230
things to reconsider most code was added

00:32:03,389 --> 00:32:07,240
with spinning disks in mind

00:32:05,230 --> 00:32:09,730
where this guy Oh latency is much higher

00:32:07,240 --> 00:32:12,299
than chedule England's for modern SSDs

00:32:09,730 --> 00:32:15,730
and more than other like storage

00:32:12,299 --> 00:32:19,090
Shabalin latency Sabula latency is

00:32:15,730 --> 00:32:22,120
comparable to disk i/o latency so that's

00:32:19,090 --> 00:32:26,160
why this a synchronous buffet behavior

00:32:22,120 --> 00:32:29,140
is much worse to space for performance

00:32:26,160 --> 00:32:32,410
probably sorting I requesting the

00:32:29,140 --> 00:32:33,100
encrypt violates the units do one thing

00:32:32,410 --> 00:32:36,040
and do it well

00:32:33,100 --> 00:32:38,380
single responsibility principle so

00:32:36,040 --> 00:32:40,540
sorting your request is the task for our

00:32:38,380 --> 00:32:43,630
scheduler and like probability and proof

00:32:40,540 --> 00:32:45,160
should not take part and it should do

00:32:43,630 --> 00:32:48,790
what it's designed to be like within

00:32:45,160 --> 00:32:50,559
decrypt data and cake Rudy may be

00:32:48,790 --> 00:32:52,720
redundant these days there's more in

00:32:50,559 --> 00:32:54,790
Linux crypto API is asynchronous itself

00:32:52,720 --> 00:32:57,100
so there is no need for workarounds to

00:32:54,790 --> 00:33:00,250
avoid encryption and interrupt context

00:32:57,100 --> 00:33:03,400
what it actually does is just a flawed a

00:33:00,250 --> 00:33:06,880
buyer request or a synchronous read just

00:33:03,400 --> 00:33:10,919
to be flawed it again in linux crypto

00:33:06,880 --> 00:33:14,020
API so we're just doubling the slot here

00:33:10,919 --> 00:33:17,740
so having this is mine we decided to do

00:33:14,020 --> 00:33:21,360
a cleanup so we just decided to remove

00:33:17,740 --> 00:33:24,280
all this complexity and turn this

00:33:21,360 --> 00:33:26,290
complex model back into what it should

00:33:24,280 --> 00:33:29,350
be a simple module we just encrypts and

00:33:26,290 --> 00:33:31,860
decrypts data on the fly also to

00:33:29,350 --> 00:33:34,480
eliminate the potential impact of the

00:33:31,860 --> 00:33:36,640
randomized scheduling latency we also

00:33:34,480 --> 00:33:40,630
wanted to try to use fully synchronous

00:33:36,640 --> 00:33:42,429
Linux crypto API and see how much

00:33:40,630 --> 00:33:46,840
performance gain can you make to do

00:33:42,429 --> 00:33:50,980
fully synchronous and request an i/o

00:33:46,840 --> 00:33:53,380
request processing CD and clip so that's

00:33:50,980 --> 00:33:55,750
what we did we did a simple patch to the

00:33:53,380 --> 00:33:58,809
encryption module which introduces yet

00:33:55,750 --> 00:34:02,650
another runtime flag which we can flip

00:33:58,809 --> 00:34:05,799
now and flipping this flag it makes the

00:34:02,650 --> 00:34:07,820
encrypt to bypass all the Q's as and a

00:34:05,799 --> 00:34:10,200
synchronous threads and it's implemented

00:34:07,820 --> 00:34:14,010
then scripta API is a bit more

00:34:10,200 --> 00:34:16,020
complicated because by default when you

00:34:14,010 --> 00:34:18,480
request a specific algorithm from

00:34:16,020 --> 00:34:20,220
liang's crypto API you might get

00:34:18,480 --> 00:34:22,740
different deployment a chinois clinic

00:34:20,220 --> 00:34:24,750
script API has may have several

00:34:22,740 --> 00:34:27,390
implementation from the same algorithm

00:34:24,750 --> 00:34:31,260
and it will pick the best one depending

00:34:27,390 --> 00:34:33,060
on the configured priority but here we

00:34:31,260 --> 00:34:36,179
didn't want to take any chances we want

00:34:33,060 --> 00:34:40,340
to use the fastest available ever is and

00:34:36,179 --> 00:34:42,690
I x86 hardware is implementation and

00:34:40,340 --> 00:34:45,210
there are like synchronous web and

00:34:42,690 --> 00:34:46,740
synchronous variant of them the problem

00:34:45,210 --> 00:34:48,929
is that the synchronous Iassogna

00:34:46,740 --> 00:34:51,450
implementation means kernel is marked as

00:34:48,929 --> 00:34:54,030
internal which means it can only be used

00:34:51,450 --> 00:34:56,850
by other crypto API modules and not

00:34:54,030 --> 00:35:01,200
outside modules from crypto API the

00:34:56,850 --> 00:35:03,390
another part here is that Hardware

00:35:01,200 --> 00:35:06,240
implementation of IES and x86 system

00:35:03,390 --> 00:35:10,890
requires the usage of FPU floating-point

00:35:06,240 --> 00:35:14,340
unit but sometimes you cannot use in

00:35:10,890 --> 00:35:16,620
some rare cases the floating-point unit

00:35:14,340 --> 00:35:19,620
is not available for usage in some

00:35:16,620 --> 00:35:22,290
interrupt contexts which again if we do

00:35:19,620 --> 00:35:25,710
a fully synchronous processing we may

00:35:22,290 --> 00:35:28,310
end up being an interrupt context when

00:35:25,710 --> 00:35:28,310
we do

00:35:29,670 --> 00:35:35,309
so thought but it's very rare so to

00:35:33,359 --> 00:35:38,400
address all these cases were implemented

00:35:35,309 --> 00:35:41,759
yet another crypto API model called XTS

00:35:38,400 --> 00:35:44,640
proxy which is a basic basically a

00:35:41,759 --> 00:35:47,749
dedicated synchronous I guess XTS

00:35:44,640 --> 00:35:50,700
implementation but it doesn't implement

00:35:47,749 --> 00:35:54,869
its own crypto on its own it's basically

00:35:50,700 --> 00:35:57,599
a simple switch where the this crypto

00:35:54,869 --> 00:35:59,309
API module when it receives any

00:35:57,599 --> 00:36:03,059
encryption or decryption requests it

00:35:59,309 --> 00:36:05,789
just checks if we can use FPU in this

00:36:03,059 --> 00:36:09,029
execution context if yes which happens

00:36:05,789 --> 00:36:13,470
like 99% of the cases before the request

00:36:09,029 --> 00:36:16,279
to the internal is an AI implementation

00:36:13,470 --> 00:36:21,210
hardware buys Iassogna implementation

00:36:16,279 --> 00:36:24,599
for our cpu in rare cases where we

00:36:21,210 --> 00:36:26,430
cannot and we can use this internal

00:36:24,599 --> 00:36:28,559
implementation because we're crypto API

00:36:26,430 --> 00:36:31,259
models ourselves and we are allowed to

00:36:28,559 --> 00:36:33,420
call other internal numbers in were

00:36:31,259 --> 00:36:36,329
cases where we can't use a few we just

00:36:33,420 --> 00:36:39,420
fall back to the generic still

00:36:36,329 --> 00:36:41,069
synchronous is implementation and

00:36:39,420 --> 00:36:44,640
software which doesn't require a fee

00:36:41,069 --> 00:36:47,279
it's it's much lower but because we use

00:36:44,640 --> 00:36:49,079
it very rarely should we expect it

00:36:47,279 --> 00:36:51,989
shouldn't create too much of the P and

00:36:49,079 --> 00:36:53,970
the module itself is fully synchronous

00:36:51,989 --> 00:36:57,599
so it will never upload any encryption

00:36:53,970 --> 00:37:01,859
requests and a synchronous plan ok let's

00:36:57,599 --> 00:37:04,829
see our performance now so we will

00:37:01,859 --> 00:37:07,259
restart our workload on our D unclipped

00:37:04,829 --> 00:37:10,319
instance and we will start our workload

00:37:07,259 --> 00:37:13,589
first because we also wanted to show

00:37:10,319 --> 00:37:18,630
that our patch is flexible enough so you

00:37:13,589 --> 00:37:21,269
can sleep you can flip the behavior at

00:37:18,630 --> 00:37:23,460
runtime even under production load with

00:37:21,269 --> 00:37:25,130
almost no impact so basically we can

00:37:23,460 --> 00:37:28,980
experiment in production with this

00:37:25,130 --> 00:37:33,470
without bringing down and draining any

00:37:28,980 --> 00:37:36,069
server so that means we will start our

00:37:33,470 --> 00:37:40,630
workload first and then the world

00:37:36,069 --> 00:37:44,380
our behavior so first step is to ensure

00:37:40,630 --> 00:37:48,369
our custom Krypton model is loaded so we

00:37:44,380 --> 00:37:51,900
just want probit then we execute this

00:37:48,369 --> 00:37:55,589
horrible comment what it basically does

00:37:51,900 --> 00:37:59,469
it reconfigures our D encrypting stands

00:37:55,589 --> 00:38:03,699
for two things the first thing we just

00:37:59,469 --> 00:38:06,249
tell the B encrypt instance instead of

00:38:03,699 --> 00:38:07,959
just requesting any is 60s

00:38:06,249 --> 00:38:09,759
implementation from the kernel and

00:38:07,959 --> 00:38:12,420
require on the kernel contribute

00:38:09,759 --> 00:38:15,579
priorities to deliver the best one

00:38:12,420 --> 00:38:17,589
explicitly request our XTX proxy model

00:38:15,579 --> 00:38:19,359
so don't ask the kernel to make a

00:38:17,589 --> 00:38:22,599
decision for you just request that

00:38:19,359 --> 00:38:24,430
particular implementation and the same

00:38:22,599 --> 00:38:27,459
the second thing we do here is we just

00:38:24,430 --> 00:38:29,799
actually enable our runtime flag so we

00:38:27,459 --> 00:38:32,680
tell the encrypt now to bypass all the

00:38:29,799 --> 00:38:35,559
queues and a synchronous threads in the

00:38:32,680 --> 00:38:37,089
implementation for every request the

00:38:35,559 --> 00:38:39,609
final step we need to do here is

00:38:37,089 --> 00:38:44,130
actually for our changes to take effect

00:38:39,609 --> 00:38:48,670
we need to do this suspend visual thing

00:38:44,130 --> 00:38:50,739
and here is the result if you plot plot

00:38:48,670 --> 00:38:53,289
the read and write throughput on when

00:38:50,739 --> 00:38:56,979
fancy perform a dashboard you will see

00:38:53,289 --> 00:38:59,650
the following picture so here is the

00:38:56,979 --> 00:39:01,509
place we can able our flag and we can

00:38:59,650 --> 00:39:05,859
see that our reads through food

00:39:01,509 --> 00:39:10,150
immediately more than double the same

00:39:05,859 --> 00:39:13,749
thing happens for right so again when we

00:39:10,150 --> 00:39:16,569
enable our or our custom actual custom :

00:39:13,749 --> 00:39:20,650
custom flag we see doubling in in the

00:39:16,569 --> 00:39:23,170
right people to show you that we're not

00:39:20,650 --> 00:39:25,329
chasing ghosts here this is a snapshot

00:39:23,170 --> 00:39:28,839
from an actual production system and

00:39:25,329 --> 00:39:31,329
real hardware so this is a real SSD from

00:39:28,839 --> 00:39:34,479
our production and here the yellow line

00:39:31,329 --> 00:39:38,049
is basically the measured IO latency of

00:39:34,479 --> 00:39:42,099
the raw desk itself and the Green Line

00:39:38,049 --> 00:39:44,259
is the DM crypt instance latency on top

00:39:42,099 --> 00:39:48,500
of the same date so here you can see so

00:39:44,259 --> 00:39:50,630
basically before by default the DM crypt

00:39:48,500 --> 00:39:52,790
interviewed it like doubles as a

00:39:50,630 --> 00:39:55,550
perceived like latency from the

00:39:52,790 --> 00:39:58,220
applications perspective but when we

00:39:55,550 --> 00:40:00,860
enable our flag these latencies like

00:39:58,220 --> 00:40:05,360
converge and we can actually see that

00:40:00,860 --> 00:40:06,770
they encrypted device software include

00:40:05,360 --> 00:40:09,320
two device latency is almost

00:40:06,770 --> 00:40:11,630
indistinguishable from like unencrypted

00:40:09,320 --> 00:40:13,970
device latency so it's basically we our

00:40:11,630 --> 00:40:16,970
bottleneck on the actual hardware like

00:40:13,970 --> 00:40:20,030
that see here now the interesting thing

00:40:16,970 --> 00:40:21,980
is like our search service impact of our

00:40:20,030 --> 00:40:29,450
change so here will be the three-way

00:40:21,980 --> 00:40:33,020
comparison of the service of the 99th

00:40:29,450 --> 00:40:35,150
percentile response time of a service

00:40:33,020 --> 00:40:37,730
which is responsible for fetching a

00:40:35,150 --> 00:40:42,290
cached asset from our CDM to our

00:40:37,730 --> 00:40:44,630
customers and here you can see that the

00:40:42,290 --> 00:40:49,700
green line is the server which has

00:40:44,630 --> 00:40:52,850
unencrypted disk the red line which you

00:40:49,700 --> 00:40:55,100
see the significant impact introduced by

00:40:52,850 --> 00:40:58,000
applying a Linux standard disk

00:40:55,100 --> 00:41:01,280
encryption on on top so like our service

00:40:58,000 --> 00:41:03,890
99th percentile is much worse and the

00:41:01,280 --> 00:41:06,130
blue line here is the same encrypted

00:41:03,890 --> 00:41:09,290
server but with our patched

00:41:06,130 --> 00:41:10,940
implementation and you can see that from

00:41:09,290 --> 00:41:13,250
service perspective it's almost

00:41:10,940 --> 00:41:16,310
indistinguishable from an unencrypted

00:41:13,250 --> 00:41:18,860
disk so again we are not bottleneck

00:41:16,310 --> 00:41:23,860
anymore on and the fiction itself where

00:41:18,860 --> 00:41:23,860
bottom like the performance itself

00:41:24,110 --> 00:41:33,030
so that's basically what we learned here

00:41:28,020 --> 00:41:35,760
that we prefer when to use the patch a

00:41:33,030 --> 00:41:38,040
simple patch which may improve linux

00:41:35,760 --> 00:41:41,490
disk encryption performance around by

00:41:38,040 --> 00:41:43,170
200 and sometimes 200% moreover it's

00:41:41,490 --> 00:41:45,030
fully compatible with stock linux

00:41:43,170 --> 00:41:47,880
decrypt so we didn't introduce a new

00:41:45,030 --> 00:41:50,010
fancy crypto and new fancy formats we

00:41:47,880 --> 00:41:54,150
just like change the implementation of

00:41:50,010 --> 00:41:56,160
of the be encrypt itself and the

00:41:54,150 --> 00:41:58,740
immediately get the performance gain and

00:41:56,160 --> 00:42:00,780
moreover it can be enabled disabled and

00:41:58,740 --> 00:42:04,980
wrong time without service disruption so

00:42:00,780 --> 00:42:06,690
we can actually have a like safe switch

00:42:04,980 --> 00:42:10,890
if something goes really wrong we can

00:42:06,690 --> 00:42:16,170
quickly disable it without impacting any

00:42:10,890 --> 00:42:18,390
services we reconvince ourselves that

00:42:16,170 --> 00:42:23,130
modern crypto is fast and cheap don't

00:42:18,390 --> 00:42:26,400
rush to blame your performance issues on

00:42:23,130 --> 00:42:28,020
crypto try to look usually the

00:42:26,400 --> 00:42:31,100
performance back on somewhere else you

00:42:28,020 --> 00:42:33,960
just have to find it and finally an

00:42:31,100 --> 00:42:39,960
extra queuing may become full on modern

00:42:33,960 --> 00:42:42,270
Lola latency storage these patches were

00:42:39,960 --> 00:42:43,800
not submitted to the upstream Linux yet

00:42:42,270 --> 00:42:47,040
because they require a little bit of

00:42:43,800 --> 00:42:49,110
more work so from our studies now the

00:42:47,040 --> 00:42:52,200
patch improves performance and small

00:42:49,110 --> 00:42:55,590
size has no small block size high ops

00:42:52,200 --> 00:42:58,170
workload which is what our CDN cache

00:42:55,590 --> 00:43:01,080
workload looks like but if you include

00:42:58,170 --> 00:43:03,720
it in increase the weave right block

00:43:01,080 --> 00:43:06,270
sizes like the tipping point is around 2

00:43:03,720 --> 00:43:08,850
megabyte it actually sometimes those

00:43:06,270 --> 00:43:13,070
shows worse performance on some other

00:43:08,850 --> 00:43:15,900
workloads again the whole setup assumes

00:43:13,070 --> 00:43:17,490
hardware accelerated crypto so it's now

00:43:15,900 --> 00:43:20,790
currently works and only on the

00:43:17,490 --> 00:43:21,380
exercises its platform sways Hardware

00:43:20,790 --> 00:43:24,290
accelerate

00:43:21,380 --> 00:43:27,040
is implementation present which is most

00:43:24,290 --> 00:43:30,380
more than an x86 platform but still and

00:43:27,040 --> 00:43:32,900
finally your mileage may have arrived we

00:43:30,380 --> 00:43:35,990
tested it in our workload it could be a

00:43:32,900 --> 00:43:39,080
workload but maybe on different

00:43:35,990 --> 00:43:43,190
workloads it might be behave differently

00:43:39,080 --> 00:43:46,100
so always measure before deploying it to

00:43:43,190 --> 00:43:47,570
production and we will be grateful if

00:43:46,100 --> 00:43:49,700
you let us know the results so we can

00:43:47,570 --> 00:43:51,650
improve we can together we can improve

00:43:49,700 --> 00:43:54,640
the implementation further Alexa made it

00:43:51,650 --> 00:43:58,880
to the absolute limits for the project

00:43:54,640 --> 00:44:02,960
so some links first to adjust man pages

00:43:58,880 --> 00:44:07,880
for the crib setup use of space utility

00:44:02,960 --> 00:44:12,350
and diem we encrypt in general or device

00:44:07,880 --> 00:44:13,850
mapper you have to know you have to see

00:44:12,350 --> 00:44:16,730
those if you don't know how to set up

00:44:13,850 --> 00:44:21,020
the Linux disk encryption the third link

00:44:16,730 --> 00:44:23,330
is the is our blog post about the

00:44:21,020 --> 00:44:25,820
contents presented in this presentation

00:44:23,330 --> 00:44:29,300
and much more and there are also more

00:44:25,820 --> 00:44:31,970
details and numbers and so I advise to

00:44:29,300 --> 00:44:36,200
go therefore through the details and

00:44:31,970 --> 00:44:38,750
finally our github Linux repository

00:44:36,200 --> 00:44:43,010
where the patches discussed in these

00:44:38,750 --> 00:44:46,000
presentations are published so you can

00:44:43,010 --> 00:44:46,000
try them yourselves

00:44:46,210 --> 00:44:52,180
some feedback that's basically it now

00:44:51,040 --> 00:44:55,480
it's time for questions

00:44:52,180 --> 00:44:57,820
I hope I'm online now on the chat

00:44:55,480 --> 00:45:01,870
waiting for questions if not please

00:44:57,820 --> 00:45:04,450
reach out on Twitter I would be happy to

00:45:01,870 --> 00:45:05,370
follow up on any questions you might

00:45:04,450 --> 00:45:10,980
have

00:45:05,370 --> 00:45:10,980
thank you stay safe and have a nice day

00:45:11,930 --> 00:45:28,420

YouTube URL: https://www.youtube.com/watch?v=Dro1k7UcPaU


