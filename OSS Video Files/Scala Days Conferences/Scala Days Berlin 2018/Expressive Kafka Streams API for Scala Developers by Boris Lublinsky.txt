Title: Expressive Kafka Streams API for Scala Developers by Boris Lublinsky
Publication date: 2018-09-20
Playlist: Scala Days Berlin 2018
Description: 
	This video was recorded at Scala Days Berlin 2018
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Find more information and the abstract here: 
https://eu.scaladays.org/lect-6949-expressive-kafka-streams-api-for-scala-developers.html
Captions: 
	00:00:04,600 --> 00:00:13,360
so I'm talking here technically the bulk

00:00:08,950 --> 00:00:17,200
of the job was done by departures I will

00:00:13,360 --> 00:00:22,240
call it from light B&D and this is the

00:00:17,200 --> 00:00:26,170
work of many of the members of Fez data

00:00:22,240 --> 00:00:29,560
teams I'm here because I am was the

00:00:26,170 --> 00:00:33,070
first one that was so disgusted by using

00:00:29,560 --> 00:00:37,090
javac kafka streams Java API sin Scala

00:00:33,070 --> 00:00:42,300
and this is kind of started the whole

00:00:37,090 --> 00:00:48,250
work but before we delve into API let's

00:00:42,300 --> 00:00:51,760
start from the beginning so this all

00:00:48,250 --> 00:00:54,520
started because we decided that we need

00:00:51,760 --> 00:00:58,780
to be able to process streaming data and

00:00:54,520 --> 00:01:02,469
if you manage to attend the previous

00:00:58,780 --> 00:01:05,140
talk by Duncan who is sitting here and

00:01:02,469 --> 00:01:07,780
presenting that he doesn't hear me he

00:01:05,140 --> 00:01:10,869
was talking a lot about importance of

00:01:07,780 --> 00:01:14,439
streaming and everything else and I

00:01:10,869 --> 00:01:17,350
think this statement emphasized the

00:01:14,439 --> 00:01:21,430
importance of streaming and explains

00:01:17,350 --> 00:01:24,159
very well why we care about streaming so

00:01:21,430 --> 00:01:28,470
when it comes to streaming we have two

00:01:24,159 --> 00:01:31,840
options is Jay Krebs was putting it

00:01:28,470 --> 00:01:36,189
there is a traditional way which is kind

00:01:31,840 --> 00:01:38,890
of MapReduce way which is based on a

00:01:36,189 --> 00:01:41,909
stream processing engine and there is

00:01:38,890 --> 00:01:47,079
more the way he called it hipsters way

00:01:41,909 --> 00:01:50,619
using micro services to do streaming

00:01:47,079 --> 00:01:57,969
data processing and the theory behind

00:01:50,619 --> 00:02:02,110
this is that when streaming actually

00:01:57,969 --> 00:02:06,000
started the first streaming engine that

00:02:02,110 --> 00:02:10,240
I'm aware of is Torme and this was

00:02:06,000 --> 00:02:13,450
created at the time when MapReduce was

00:02:10,240 --> 00:02:15,400
very popular and everybody was on the

00:02:13,450 --> 00:02:17,140
assumption that you are dealing with a

00:02:15,400 --> 00:02:20,050
lot of the eight

00:02:17,140 --> 00:02:23,140
you need the real a server that is

00:02:20,050 --> 00:02:27,850
managing instances in doing a lot of

00:02:23,140 --> 00:02:32,550
things for you but and this was in part

00:02:27,850 --> 00:02:36,430
driven by lambda architecture that was

00:02:32,550 --> 00:02:38,950
introduced by nathan mars because the

00:02:36,430 --> 00:02:42,010
thought process was you are doing doing

00:02:38,950 --> 00:02:48,580
page and this is human workhorse and

00:02:42,010 --> 00:02:51,580
streaming just supplemented our industry

00:02:48,580 --> 00:02:54,700
is moving very fast and very soon after

00:02:51,580 --> 00:02:57,640
lambda architecture there appeared cop

00:02:54,700 --> 00:02:59,110
architecture that was saying well if

00:02:57,640 --> 00:03:01,450
you're streaming is good enough you

00:02:59,110 --> 00:03:04,420
don't necessarily have to do the beach

00:03:01,450 --> 00:03:09,480
to supplement it you can just piggyback

00:03:04,420 --> 00:03:12,180
off streaming for everything and this is

00:03:09,480 --> 00:03:14,560
where people started to realize that

00:03:12,180 --> 00:03:17,500
when you are doing streaming data

00:03:14,560 --> 00:03:19,630
processing you don't have to deal with

00:03:17,500 --> 00:03:23,260
this huge corpus of data you are

00:03:19,630 --> 00:03:28,540
typically dealing with either micro

00:03:23,260 --> 00:03:31,630
batch a spark to us or small windows or

00:03:28,540 --> 00:03:36,970
even individual messages and it turns

00:03:31,630 --> 00:03:39,430
out that in GM solutions are good enough

00:03:36,970 --> 00:03:42,549
for a lot of streaming application

00:03:39,430 --> 00:03:46,390
problems and that's why the second

00:03:42,549 --> 00:03:48,720
option is a stream process library so

00:03:46,390 --> 00:03:55,350
which one should you use

00:03:48,720 --> 00:03:58,180
well SPE is a good field for their

00:03:55,350 --> 00:04:01,090
applications that require features that

00:03:58,180 --> 00:04:03,579
are provided by stream processing engine

00:04:01,090 --> 00:04:07,150
and most notably these features is

00:04:03,579 --> 00:04:11,769
scalability restart ability failover

00:04:07,150 --> 00:04:15,730
support all these good things that we

00:04:11,769 --> 00:04:20,890
are taking as granted the caveat of this

00:04:15,730 --> 00:04:24,250
is if you are doing this you have to

00:04:20,890 --> 00:04:26,620
have a team maintaining the server you

00:04:24,250 --> 00:04:28,330
have to adhere their programming model

00:04:26,620 --> 00:04:29,160
you have to adhere to their deployment

00:04:28,330 --> 00:04:32,250
model

00:04:29,160 --> 00:04:34,830
on another hand if you are using a

00:04:32,250 --> 00:04:37,320
lightweight libraries like Kafka streams

00:04:34,830 --> 00:04:42,180
you write your code pretty much the way

00:04:37,320 --> 00:04:44,700
that fits your problem best but you have

00:04:42,180 --> 00:04:50,670
to deal yourself with the infrastructure

00:04:44,700 --> 00:04:54,750
concerns so Kafka streams how many

00:04:50,670 --> 00:04:56,220
people in the audience know or used or

00:04:54,750 --> 00:05:00,180
hate or love

00:04:56,220 --> 00:05:05,370
Kafka thrips okay so quite a few but I

00:05:00,180 --> 00:05:07,830
just a reminder so Kafka streams is a

00:05:05,370 --> 00:05:11,960
client library for processing and

00:05:07,830 --> 00:05:15,360
analyzing data using Kafka it provides

00:05:11,960 --> 00:05:18,090
all the fashionable stream processing

00:05:15,360 --> 00:05:20,610
concepts properly distinguishing between

00:05:18,090 --> 00:05:25,620
the wrong time and processing time we're

00:05:20,610 --> 00:05:29,520
doing support etc and it provides simple

00:05:25,620 --> 00:05:33,060
and diffusion management of the

00:05:29,520 --> 00:05:36,420
application States based on the streams

00:05:33,060 --> 00:05:38,760
table the other idea it looks absolutely

00:05:36,420 --> 00:05:42,150
great when you try to use it for the

00:05:38,760 --> 00:05:45,990
first time it has its own quirks because

00:05:42,150 --> 00:05:51,900
if you know the tables are backed up by

00:05:45,990 --> 00:05:54,390
Q's here they are using a Duncan

00:05:51,900 --> 00:05:57,750
favorite event sourcing which works

00:05:54,390 --> 00:06:00,120
great with one little problem if you're

00:05:57,750 --> 00:06:02,220
writing a lot to the table and you're

00:06:00,120 --> 00:06:04,110
trying to restore the table from the

00:06:02,220 --> 00:06:07,350
application that was up for the couple

00:06:04,110 --> 00:06:11,250
of days it can take 10 to 15 minutes to

00:06:07,350 --> 00:06:14,640
restore the state always drive me insane

00:06:11,250 --> 00:06:16,970
one of the examples where the solution

00:06:14,640 --> 00:06:22,830
doesn't really feel the problem but

00:06:16,970 --> 00:06:27,780
using Kafka for everything was great so

00:06:22,830 --> 00:06:31,200
the other thing is is fairly low over

00:06:27,780 --> 00:06:33,750
here it provides additional hour

00:06:31,200 --> 00:06:39,289
integration with other system except for

00:06:33,750 --> 00:06:42,310
Kafka leveraging Kafka connect again

00:06:39,289 --> 00:06:44,710
theoretically it all works great

00:06:42,310 --> 00:06:48,280
tickly if you try to integrate Kafka

00:06:44,710 --> 00:06:52,300
connect with Kafka streams your up for

00:06:48,280 --> 00:06:55,780
if you unpleasant surprises it doesn't

00:06:52,300 --> 00:06:59,169
quite work out of the box but in general

00:06:55,780 --> 00:07:01,660
it works support for scalability and

00:06:59,169 --> 00:07:05,290
load balancing based on Kafka

00:07:01,660 --> 00:07:06,820
partitioning I think you guys should

00:07:05,290 --> 00:07:09,610
know what this means

00:07:06,820 --> 00:07:13,480
I mean basically if your topic here's

00:07:09,610 --> 00:07:16,660
ten partitions you can have up to ten

00:07:13,480 --> 00:07:19,840
independent prisoners each one will be

00:07:16,660 --> 00:07:25,660
assigned its own partition if you have

00:07:19,840 --> 00:07:29,169
less than ten then some of the consumers

00:07:25,660 --> 00:07:31,600
will be si an additional partitions if

00:07:29,169 --> 00:07:34,600
you have more than T and then some of

00:07:31,600 --> 00:07:36,940
the consumers are going to be idle so

00:07:34,600 --> 00:07:39,580
when you are thinking about deployment

00:07:36,940 --> 00:07:42,840
think about the amount of partitions

00:07:39,580 --> 00:07:46,570
that you are dealing with this is where

00:07:42,840 --> 00:07:49,270
stream processing engines are so

00:07:46,570 --> 00:07:52,840
effective because they basically look at

00:07:49,270 --> 00:07:55,270
the topic and then they say okay it has

00:07:52,840 --> 00:07:59,550
ten partition I'll start an executor

00:07:55,270 --> 00:08:02,680
here you have to manage this by hands

00:07:59,550 --> 00:08:05,260
the other thing if you haven't tried it

00:08:02,680 --> 00:08:09,570
I strongly recommend trying queryable

00:08:05,260 --> 00:08:17,800
State this is very very convenient

00:08:09,570 --> 00:08:19,720
concept which allows you to take a peek

00:08:17,800 --> 00:08:21,640
into what's happening within the

00:08:19,720 --> 00:08:24,310
application because queryable state

00:08:21,640 --> 00:08:27,160
allows you to query a Kafka streams

00:08:24,310 --> 00:08:29,380
application and if it is written

00:08:27,160 --> 00:08:38,260
correctly you can see what exactly is

00:08:29,380 --> 00:08:43,920
happening and the last thing is Kafka

00:08:38,260 --> 00:08:46,570
streams provide sequel interface but

00:08:43,920 --> 00:08:49,780
unfortunately at least from my point of

00:08:46,570 --> 00:08:53,530
view the sequel interface is not part of

00:08:49,780 --> 00:08:55,960
Kafka streams is a separate application

00:08:53,530 --> 00:08:59,350
which you have to write separately so

00:08:55,960 --> 00:09:03,460
you can't really use a sequel inside

00:08:59,350 --> 00:09:09,040
Kafka streams application to transform

00:09:03,460 --> 00:09:15,250
the data so what Kefka streams is good

00:09:09,040 --> 00:09:18,580
for ETL is very easy to write using

00:09:15,250 --> 00:09:21,490
Kafka streams aggregation are you

00:09:18,580 --> 00:09:25,240
leverage K table and it becomes really

00:09:21,490 --> 00:09:28,660
easy to write the aggregation the nice

00:09:25,240 --> 00:09:31,990
thing about Kafka stream is it employs

00:09:28,660 --> 00:09:35,500
to the largest extent stream table

00:09:31,990 --> 00:09:37,120
duality so the api's are exactly the

00:09:35,500 --> 00:09:42,310
same where they are working with the

00:09:37,120 --> 00:09:45,250
streams or with the table flexible

00:09:42,310 --> 00:09:48,490
integration model you can do in memory

00:09:45,250 --> 00:09:50,920
integration and also very simplified

00:09:48,490 --> 00:09:54,850
example of this or you can do

00:09:50,920 --> 00:09:57,430
integration of a Kafka having one Kafka

00:09:54,850 --> 00:09:59,650
streams reading one of the topics

00:09:57,430 --> 00:10:02,700
processing data writing to another topic

00:09:59,650 --> 00:10:06,280
so that you can string together multiple

00:10:02,700 --> 00:10:10,300
Kafka streams implement a plication x'

00:10:06,280 --> 00:10:14,670
to achieve your overall goal and the N

00:10:10,300 --> 00:10:18,400
it supports effectively one semantics

00:10:14,670 --> 00:10:21,880
this is one thing that bothers me

00:10:18,400 --> 00:10:24,520
significantly because if you guys are

00:10:21,880 --> 00:10:28,860
following Kafka carefully they've now

00:10:24,520 --> 00:10:33,610
introduced transactional semantics and

00:10:28,860 --> 00:10:36,580
I'm just not convinced let's put it this

00:10:33,610 --> 00:10:38,500
way very carefully because they kind of

00:10:36,580 --> 00:10:41,580
implement to face commit but this

00:10:38,500 --> 00:10:46,450
two-phase commit is only on the same

00:10:41,580 --> 00:10:51,360
Kafka cluster so I am starting to

00:10:46,450 --> 00:10:56,410
question the sanity of our industry

00:10:51,360 --> 00:11:01,920
Kafka dreams APR is up until now it only

00:10:56,410 --> 00:11:04,180
heared Java API eyes but if you look it

00:11:01,920 --> 00:11:08,200
Kafka streams

00:11:04,180 --> 00:11:10,750
although they emphasize mostly DSL in

00:11:08,200 --> 00:11:12,670
reality they produce too they provide

00:11:10,750 --> 00:11:16,630
two types of the API eyes

00:11:12,670 --> 00:11:19,290
one of them is process topology which is

00:11:16,630 --> 00:11:24,520
kind of similar to what storm used to do

00:11:19,290 --> 00:11:27,310
and the second one is the DSL there they

00:11:24,520 --> 00:11:30,010
mostly promote which is based on the

00:11:27,310 --> 00:11:32,740
collection transformation the same thing

00:11:30,010 --> 00:11:36,580
that is done by SPARC the same thing

00:11:32,740 --> 00:11:40,570
that is done by fleeing although they

00:11:36,580 --> 00:11:43,779
promote a DSL for the most part there is

00:11:40,570 --> 00:11:47,290
quite a few applications where usage of

00:11:43,779 --> 00:11:49,800
the process topology can lead to by far

00:11:47,290 --> 00:11:54,100
more efficient applications

00:11:49,800 --> 00:11:56,970
so what's process topology so this

00:11:54,100 --> 00:12:02,200
simple picture shows it all basically

00:11:56,970 --> 00:12:05,200
you represent your application as a set

00:12:02,200 --> 00:12:09,370
of connected processors and you just

00:12:05,200 --> 00:12:12,100
connect them by name and copying to the

00:12:09,370 --> 00:12:19,779
builds topology and everything works

00:12:12,100 --> 00:12:23,830
fine so if you write process topology

00:12:19,779 --> 00:12:26,940
using Java API it looks something like

00:12:23,830 --> 00:12:33,730
this you write the definition of

00:12:26,940 --> 00:12:36,730
processors and then you can add them

00:12:33,730 --> 00:12:38,410
together very simple very

00:12:36,730 --> 00:12:41,410
straightforward it's completely up to

00:12:38,410 --> 00:12:45,010
you what you write within the processor

00:12:41,410 --> 00:12:48,120
so it's really a very powerful model so

00:12:45,010 --> 00:12:51,880
if we try to use this API since color

00:12:48,120 --> 00:12:54,370
well look it looks pretty nice you don't

00:12:51,880 --> 00:13:00,910
really have to do anything it looks as

00:12:54,370 --> 00:13:07,020
nice as the Java API is so it's exactly

00:13:00,910 --> 00:13:11,079
the same syntax and we don't need to do

00:13:07,020 --> 00:13:14,950
much when it comes to the DSL

00:13:11,079 --> 00:13:17,180
the story is a little bit different so

00:13:14,950 --> 00:13:19,400
they say all ears

00:13:17,180 --> 00:13:26,930
abstraction for streams and tables in

00:13:19,400 --> 00:13:28,940
the form of K 3 and K table so is the

00:13:26,930 --> 00:13:33,020
clarity of functional programming style

00:13:28,940 --> 00:13:40,240
and if you look at Java code it looks

00:13:33,020 --> 00:13:44,830
quite nice so it's very fluent our code

00:13:40,240 --> 00:13:49,880
there is nothing wrong with this and

00:13:44,830 --> 00:13:52,940
everything is very beautiful but if you

00:13:49,880 --> 00:13:56,560
try to use it in Scala and this was the

00:13:52,940 --> 00:14:00,670
main driving factor for me

00:13:56,560 --> 00:14:06,530
so the initial definition looks fine but

00:14:00,670 --> 00:14:10,120
then you get this ugly thing because you

00:14:06,530 --> 00:14:13,580
have to explicitly specify the type of

00:14:10,120 --> 00:14:16,400
everything and everybody who ever tried

00:14:13,580 --> 00:14:24,050
to do it or look at it just turn around

00:14:16,400 --> 00:14:28,150
and disgust and use Java well this is

00:14:24,050 --> 00:14:30,910
bad but this is even worse

00:14:28,150 --> 00:14:32,900
so you can't really do any

00:14:30,910 --> 00:14:36,820
transformation for every transformation

00:14:32,900 --> 00:14:36,820
you have to write something like this

00:14:37,090 --> 00:14:44,540
uh-huh

00:14:38,710 --> 00:14:52,250
so what's the problem it's very simple

00:14:44,540 --> 00:14:56,330
it's temperature so the idea behind

00:14:52,250 --> 00:14:59,200
Scala library was very simple but the

00:14:56,330 --> 00:15:02,870
type inference less boilerplate code

00:14:59,200 --> 00:15:06,820
usual builder style implicit realizers

00:15:02,870 --> 00:15:06,820
and by the type safety

00:15:07,090 --> 00:15:16,400
let me explain one more thing here so

00:15:11,980 --> 00:15:20,030
when we started to a king about scholar

00:15:16,400 --> 00:15:22,430
guys for Kafka streams the group of six

00:15:20,030 --> 00:15:28,400
people split in about five different

00:15:22,430 --> 00:15:30,860
camps because I my take was let's just

00:15:28,400 --> 00:15:32,690
preserve what the heavens

00:15:30,860 --> 00:15:37,070
and make it usable for scholar

00:15:32,690 --> 00:15:38,630
developers so no syntax improvements

00:15:37,070 --> 00:15:41,540
nothing specific

00:15:38,630 --> 00:15:46,190
and the driving factor behind this was

00:15:41,540 --> 00:15:50,930
the fact that they evolved their Java

00:15:46,190 --> 00:15:56,780
API and we shouldn't create incompatible

00:15:50,930 --> 00:16:00,740
model their other four groups we were

00:15:56,780 --> 00:16:04,070
proposing a functional changes to the

00:16:00,740 --> 00:16:08,660
api's semantic changes to the api's and

00:16:04,070 --> 00:16:11,690
for one of the few times in my life I

00:16:08,660 --> 00:16:17,740
won maybe because I had the loudest

00:16:11,690 --> 00:16:20,900
voice but their oral design is basically

00:16:17,740 --> 00:16:23,900
mimic the existing Java library with the

00:16:20,900 --> 00:16:29,690
beta type inference and all other

00:16:23,900 --> 00:16:32,300
goodies so the idea behind the library

00:16:29,690 --> 00:16:34,720
implementation is very simple it just

00:16:32,300 --> 00:16:38,810
rapping the existing Java API is

00:16:34,720 --> 00:16:48,340
exposing the same semantics in the

00:16:38,810 --> 00:16:53,570
scholar syntax the other thing that it

00:16:48,340 --> 00:17:02,090
relies heavily is in places for the

00:16:53,570 --> 00:17:08,390
conversion and finally more in places

00:17:02,090 --> 00:17:13,970
for functional conversions to allow for

00:17:08,390 --> 00:17:17,300
same type support so once this was put

00:17:13,970 --> 00:17:20,690
in place we can return back to our

00:17:17,300 --> 00:17:23,390
original example and this look good from

00:17:20,690 --> 00:17:30,620
the very beginning but this looks by far

00:17:23,390 --> 00:17:33,200
nicer and effectively what you see here

00:17:30,620 --> 00:17:38,980
is pretty much the same Java code with

00:17:33,200 --> 00:17:42,830
the Scala syntax and this was one of the

00:17:38,980 --> 00:17:44,610
driving factors because you can pick up

00:17:42,830 --> 00:17:48,480
Java the community

00:17:44,610 --> 00:17:51,150
and you can use it for Scala directly it

00:17:48,480 --> 00:17:52,130
works out of the box the code looks nice

00:17:51,150 --> 00:17:57,870
and clear

00:17:52,130 --> 00:18:00,840
so after this was done uh we've also

00:17:57,870 --> 00:18:04,350
decided to improve one more thing and

00:18:00,840 --> 00:18:08,820
this is dealing with your des you guys

00:18:04,350 --> 00:18:11,730
know what surges are serializers

00:18:08,820 --> 00:18:14,190
deserialize errs so our caffeine

00:18:11,730 --> 00:18:18,929
journalist towards everything as byte

00:18:14,190 --> 00:18:22,640
arrays which means that in order to get

00:18:18,929 --> 00:18:25,080
our data in and out of Kafka in a very

00:18:22,640 --> 00:18:28,380
in any meaningful way

00:18:25,080 --> 00:18:31,860
you have to marshal and marshal this

00:18:28,380 --> 00:18:36,120
data and this is the job of serializers

00:18:31,860 --> 00:18:40,309
and deserialize errs and if you look at

00:18:36,120 --> 00:18:43,590
the job api's it hears Thursdays

00:18:40,309 --> 00:18:51,419
sprinkled all over the place which is

00:18:43,590 --> 00:18:55,500
okay but could be improved so one thing

00:18:51,419 --> 00:19:00,169
that we've actually improved in the java

00:18:55,500 --> 00:19:05,070
api is introduction of implicit surveys

00:19:00,169 --> 00:19:08,520
so we decided that this was really ugly

00:19:05,070 --> 00:19:13,770
and not typesafe this is how Java does

00:19:08,520 --> 00:19:17,610
it so instead of these are the Scala

00:19:13,770 --> 00:19:23,549
library does this so it just introduced

00:19:17,610 --> 00:19:26,940
in places for everything that surgeries

00:19:23,549 --> 00:19:33,020
are doing and now you don't even have to

00:19:26,940 --> 00:19:33,020
use them they hidden from here so

00:19:35,390 --> 00:19:44,370
instead of hoping that you've done

00:19:40,799 --> 00:19:47,040
everything right and explicitly writing

00:19:44,370 --> 00:19:47,700
serialize RTC realizers all over the

00:19:47,040 --> 00:19:50,309
place

00:19:47,700 --> 00:19:53,790
this color library is doing completely

00:19:50,309 --> 00:19:57,920
so you have green tea it typed type

00:19:53,790 --> 00:20:03,780
safety and you have by far less

00:19:57,920 --> 00:20:08,700
boilerplate boilerplate code so with

00:20:03,780 --> 00:20:18,059
this in place this is how everything

00:20:08,700 --> 00:20:21,410
looks like so sir this definition just

00:20:18,059 --> 00:20:25,200
disappeared from your code which make it

00:20:21,410 --> 00:20:29,070
simpler advisor and if you don't hear

00:20:25,200 --> 00:20:31,770
serializers for something then Scala

00:20:29,070 --> 00:20:33,750
compiler will scream it you really

00:20:31,770 --> 00:20:37,110
loudly and you will know that you have

00:20:33,750 --> 00:20:42,799
to edit in ten places and it will tell

00:20:37,110 --> 00:20:48,919
you where it is missing so as a result

00:20:42,799 --> 00:20:52,500
this is how the api's are looking like

00:20:48,919 --> 00:20:54,720
so in places are already in place by

00:20:52,500 --> 00:20:57,150
Scala he and the only thing that you

00:20:54,720 --> 00:21:03,030
have to specify are the variables that

00:20:57,150 --> 00:21:12,960
you need and with this their application

00:21:03,030 --> 00:21:16,890
code is looking even more concise so

00:21:12,960 --> 00:21:19,679
this is basically why we're doing it

00:21:16,890 --> 00:21:22,559
and what's the advantage of doing it and

00:21:19,679 --> 00:21:26,360
even Scala guy is knocking his hair

00:21:22,559 --> 00:21:26,360
saying yeah it's the right thing to do

00:21:28,460 --> 00:21:35,600
okay so this is for the standard Sergius

00:21:32,970 --> 00:21:39,030
that are provided by Kafka streamium

00:21:35,600 --> 00:21:42,960
what if you have to have your custom

00:21:39,030 --> 00:21:45,150
ones well it's exactly the same thing

00:21:42,960 --> 00:21:47,790
you just have to implement your own

00:21:45,150 --> 00:21:57,440
servers and you have to write your own

00:21:47,790 --> 00:21:57,440
in places and this is how this is done

00:21:58,400 --> 00:22:06,030
so when we were moving this code to

00:22:03,000 --> 00:22:08,080
Concord insisted for some reason these

00:22:06,030 --> 00:22:10,390
people are in love with every

00:22:08,080 --> 00:22:13,000
beats me I'm still trying to figure out

00:22:10,390 --> 00:22:15,040
why I was trying for the last year and a

00:22:13,000 --> 00:22:18,580
half and I still don't have an answer

00:22:15,040 --> 00:22:23,380
but it was mandatory for us to show how

00:22:18,580 --> 00:22:28,960
I've reserved it let's find it you guys

00:22:23,380 --> 00:22:33,630
have big fans of Avril ok yes I'm not

00:22:28,960 --> 00:22:37,540
the only one so it was mandatory for us

00:22:33,630 --> 00:22:45,130
to provide the example with the Opera

00:22:37,540 --> 00:22:48,480
Thursday and this is why it's here so in

00:22:45,130 --> 00:22:51,670
this is how the code looks like with the

00:22:48,480 --> 00:22:53,740
custom searches so it's the same clean

00:22:51,670 --> 00:22:55,720
code you just have to implement your

00:22:53,740 --> 00:23:01,300
owns you realize there is deserialize

00:22:55,720 --> 00:23:04,450
errs ok so this is for the L cell

00:23:01,300 --> 00:23:08,110
support but as I mentioned there is one

00:23:04,450 --> 00:23:10,210
more feature in Kafka streams that I'm

00:23:08,110 --> 00:23:12,850
particularly fond of and this is

00:23:10,210 --> 00:23:16,030
queryable state and this diagram

00:23:12,850 --> 00:23:19,180
basically illustrates the advantages of

00:23:16,030 --> 00:23:21,550
using of the queryable state you don't

00:23:19,180 --> 00:23:24,670
have to have an additional database on

00:23:21,550 --> 00:23:26,800
the side you don't have to send data

00:23:24,670 --> 00:23:30,390
back and forth you can just query

00:23:26,800 --> 00:23:34,330
directly the current execution of Kafka

00:23:30,390 --> 00:23:38,370
of Kafka streams and I get everything

00:23:34,330 --> 00:23:41,260
that you need so details

00:23:38,370 --> 00:23:43,630
remember I was talking about the fact

00:23:41,260 --> 00:23:46,600
that caucus rooms application allow you

00:23:43,630 --> 00:23:48,670
to scale if you have multiple partition

00:23:46,600 --> 00:23:50,740
you can have multiple instances of the

00:23:48,670 --> 00:23:55,480
same Kafka stream application that is

00:23:50,740 --> 00:23:58,570
doing exactly the same thing so when it

00:23:55,480 --> 00:24:01,740
when we talk about queryable stays there

00:23:58,570 --> 00:24:07,260
are two things to consider there is a

00:24:01,740 --> 00:24:12,010
local variable state which is completely

00:24:07,260 --> 00:24:15,160
property of the running JVM and there is

00:24:12,010 --> 00:24:17,290
remote state if you have multiple

00:24:15,160 --> 00:24:19,900
instances of the same Kafka streams

00:24:17,290 --> 00:24:21,820
applications in order for you to be able

00:24:19,900 --> 00:24:28,080
to reconcile

00:24:21,820 --> 00:24:32,650
you have to talk to all the instances so

00:24:28,080 --> 00:24:37,990
Kafka streams are natively provide all

00:24:32,650 --> 00:24:41,830
the required functionality or for the

00:24:37,990 --> 00:24:45,460
local case for the remote case are

00:24:41,830 --> 00:24:48,790
they're basically saying well it's not

00:24:45,460 --> 00:24:55,860
so hard and this is how you implement

00:24:48,790 --> 00:24:59,140
this you basically have to implement our

00:24:55,860 --> 00:25:01,690
RPC layer that talks between the

00:24:59,140 --> 00:25:05,260
instances and allows you to give the

00:25:01,690 --> 00:25:09,310
information well and they provide the

00:25:05,260 --> 00:25:13,210
sample code when I first looked at the

00:25:09,310 --> 00:25:17,530
sample code I'm old enough so I still

00:25:13,210 --> 00:25:21,400
remember what the squiggly get is and

00:25:17,530 --> 00:25:24,370
what the squiggly path is it's if you

00:25:21,400 --> 00:25:29,970
guys don't know it's Jax artists here

00:25:24,370 --> 00:25:32,770
jax-rs I'm a lot of guys on our team

00:25:29,970 --> 00:25:35,290
were just looking at they think what the

00:25:32,770 --> 00:25:41,980
hell is that I've never seen this thing

00:25:35,290 --> 00:25:45,160
before so this was not the only thing

00:25:41,980 --> 00:25:51,460
you have to write quite a few of the

00:25:45,160 --> 00:25:55,630
boilerplate code to make this VI King so

00:25:51,460 --> 00:25:56,050
we decided that we absolutely don't like

00:25:55,630 --> 00:25:59,860
it

00:25:56,050 --> 00:26:06,130
besides we were polite band with own arc

00:25:59,860 --> 00:26:08,610
HTTP we can do things better so this is

00:26:06,130 --> 00:26:14,700
the second vibrator that we have created

00:26:08,610 --> 00:26:19,150
which is a library for queryable state

00:26:14,700 --> 00:26:22,210
so it basically organized in three main

00:26:19,150 --> 00:26:24,630
components HTTP services and she

00:26:22,210 --> 00:26:24,630
realises

00:26:26,820 --> 00:26:42,720
and I it those are the main classes that

00:26:33,930 --> 00:26:49,620
are provided and with this in place yeah

00:26:42,720 --> 00:26:51,720
this is much nicer more readable code so

00:26:49,620 --> 00:26:54,990
basically we were trying to attack both

00:26:51,720 --> 00:26:57,990
sides how you write Kafka streams

00:26:54,990 --> 00:27:02,550
implementation using scour and how you

00:26:57,990 --> 00:27:05,850
use query about state we also did a

00:27:02,550 --> 00:27:11,730
couple of provisions for distributed

00:27:05,850 --> 00:27:15,300
query handling because we need to

00:27:11,730 --> 00:27:18,600
support multiple physical machines we

00:27:15,300 --> 00:27:25,320
need to query all them to support to

00:27:18,600 --> 00:27:29,490
combine together all the local states so

00:27:25,320 --> 00:27:31,740
the query service interacts with Kafka

00:27:29,490 --> 00:27:33,810
streams metadata service which returns

00:27:31,740 --> 00:27:36,960
you back information about all the

00:27:33,810 --> 00:27:40,920
active nodes so now you can our query

00:27:36,960 --> 00:27:44,730
each of them and you combine things

00:27:40,920 --> 00:27:47,550
together the other thing is I in order

00:27:44,730 --> 00:27:49,530
to make sure that if you redeploy and

00:27:47,550 --> 00:27:55,080
some of your partitions will move to the

00:27:49,530 --> 00:27:58,260
different machines we put invalid state

00:27:55,080 --> 00:28:00,450
except state exceptions so we added a

00:27:58,260 --> 00:28:05,820
little bit more about us for you to deal

00:28:00,450 --> 00:28:07,410
in a distributed case so where are we

00:28:05,820 --> 00:28:13,980
with this right now

00:28:07,410 --> 00:28:18,260
so caca streams Scala we didn't invented

00:28:13,980 --> 00:28:22,800
this thing it was actually originated by

00:28:18,260 --> 00:28:27,210
Alexis okay I'm not going to butcher his

00:28:22,800 --> 00:28:31,790
last name but this was the first thing

00:28:27,210 --> 00:28:35,700
that came during the initial search but

00:28:31,790 --> 00:28:39,030
his implementation was completely

00:28:35,700 --> 00:28:41,460
rewritten the ideas were

00:28:39,030 --> 00:28:43,100
kind of similar the implementation is

00:28:41,460 --> 00:28:49,350
quite different

00:28:43,100 --> 00:28:52,710
we've internally have this in version

00:28:49,350 --> 00:28:56,730
zero to one and I you can download it

00:28:52,710 --> 00:29:00,720
from light band github we've also worked

00:28:56,730 --> 00:29:05,610
with Kafka community quite a bit and we

00:29:00,720 --> 00:29:08,940
went through Kafka improvement requests

00:29:05,610 --> 00:29:12,690
and it was accepted and finally I'm

00:29:08,940 --> 00:29:16,080
happy to tell you that it is a part of

00:29:12,690 --> 00:29:18,860
the official Apache Kafka library so you

00:29:16,080 --> 00:29:22,080
don't have to go to us you can go to

00:29:18,860 --> 00:29:27,750
apply to Kafka Soares and download it

00:29:22,080 --> 00:29:30,690
from there I know that our code had my

00:29:27,750 --> 00:29:33,540
Marian support I don't know whether

00:29:30,690 --> 00:29:36,510
budget code already has made in support

00:29:33,540 --> 00:29:39,720
you might have to wait for the next

00:29:36,510 --> 00:29:42,600
version of calculus to have making

00:29:39,720 --> 00:29:48,870
support for this library but if you go

00:29:42,600 --> 00:29:53,400
to ours is in maven so it does work fine

00:29:48,870 --> 00:29:58,320
and kappa stream query is only our

00:29:53,400 --> 00:30:02,300
library because apache Kafka was not

00:29:58,320 --> 00:30:05,490
interested in this they were saying well

00:30:02,300 --> 00:30:08,520
we're not defining how you guys do this

00:30:05,490 --> 00:30:11,190
it's completely up to you so we're

00:30:08,520 --> 00:30:15,390
maintaining it internally inside light

00:30:11,190 --> 00:30:19,290
band it's still in version zero one one

00:30:15,390 --> 00:30:22,890
are it's available from our github

00:30:19,290 --> 00:30:27,650
Reaper which is opened and it's also

00:30:22,890 --> 00:30:27,650
available in Marian

00:30:31,669 --> 00:30:39,479
pretty much the same thing in

00:30:36,109 --> 00:30:42,690
considering that this is the last

00:30:39,479 --> 00:30:46,559
presentation of the day I figured you

00:30:42,690 --> 00:30:49,830
guys are willing to explore Berlin or do

00:30:46,559 --> 00:30:53,639
whatever you want to do so we are

00:30:49,830 --> 00:30:58,529
finishing a little bit earlier so if you

00:30:53,639 --> 00:31:03,080
have any questions go ahead and ask them

00:30:58,529 --> 00:31:03,080
other than that I'm done

00:31:03,720 --> 00:31:09,430

YouTube URL: https://www.youtube.com/watch?v=QGyR-07nv94


