Title: A Tale of Two Monix Stream by Alexandru Nedelcu
Publication date: 2018-09-20
Playlist: Scala Days Berlin 2018
Description: 
	This video was recorded at Scala Days Berlin 2018
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Find more information and the abstract here: 
https://eu.scaladays.org/lect-6938-a-tale-of-two-monix-streams.html
Captions: 
	00:00:04,620 --> 00:00:11,910
hi everybody I'm Alexandra Liddell COO

00:00:08,690 --> 00:00:14,369
I'm a software engineer from Bucharest

00:00:11,910 --> 00:00:18,510
Romania if you want to know more about

00:00:14,369 --> 00:00:20,039
me that's my Twitter account I spent way

00:00:18,510 --> 00:00:23,339
too much time on Twitter that's my

00:00:20,039 --> 00:00:25,410
website personal blog and I'm working

00:00:23,339 --> 00:00:29,970
for Oreo if you're ever in Bucharest

00:00:25,410 --> 00:00:31,140
come and say hi we are friendly so today

00:00:29,970 --> 00:00:35,780
I'm going to talk about bollocks

00:00:31,140 --> 00:00:37,980
bollocks has been my hobby for the past

00:00:35,780 --> 00:00:41,250
several years already

00:00:37,980 --> 00:00:44,010
it's a Scholars College's library for

00:00:41,250 --> 00:00:46,320
composing a synchronous programmes it

00:00:44,010 --> 00:00:49,620
exposes a bunch of used for high-level

00:00:46,320 --> 00:00:53,360
abstractions for working with asynchrony

00:00:49,620 --> 00:00:56,220
it's a type level project which means

00:00:53,360 --> 00:01:00,540
for you it means that it adheres to

00:00:56,220 --> 00:01:02,280
certain quality standards let's say plus

00:01:00,540 --> 00:01:04,860
it interoperate swell with the rest of

00:01:02,280 --> 00:01:07,650
the ecosystem and it's currently at

00:01:04,860 --> 00:01:11,399
release master release candidate one

00:01:07,650 --> 00:01:15,179
release candidate two is a little

00:01:11,399 --> 00:01:18,600
delayed but it's going to be released in

00:01:15,179 --> 00:01:20,759
the following week so and this version

00:01:18,600 --> 00:01:24,600
three that is going to be released soon

00:01:20,759 --> 00:01:27,689
it's a major version in introducing lots

00:01:24,600 --> 00:01:29,640
of goodies so Version three

00:01:27,689 --> 00:01:33,270
it's about deep integration with type

00:01:29,640 --> 00:01:35,670
level cats which is the new standard

00:01:33,270 --> 00:01:38,729
library for functional programming in

00:01:35,670 --> 00:01:41,729
Scala it introduces the iterance data

00:01:38,729 --> 00:01:44,399
type which is for a lawful pool based

00:01:41,729 --> 00:01:45,960
streaming and I'm going to talk about it

00:01:44,399 --> 00:01:48,719
in the second part of this presentation

00:01:45,960 --> 00:01:54,659
and it contains major improvements

00:01:48,719 --> 00:01:57,359
across the board the project as little

00:01:54,659 --> 00:02:00,060
history started in 2014 it was

00:01:57,359 --> 00:02:03,479
originally called money for and it was

00:02:00,060 --> 00:02:06,689
developed because I had a need for

00:02:03,479 --> 00:02:09,090
developing software that controls and

00:02:06,689 --> 00:02:11,220
monitors power plants it was inspired by

00:02:09,090 --> 00:02:15,190
Eric Shaw I was actually inspired by

00:02:11,220 --> 00:02:18,910
that reactive course on Coursera

00:02:15,190 --> 00:02:20,800
which I didn't like so much as the

00:02:18,910 --> 00:02:24,820
functional programming course but I

00:02:20,800 --> 00:02:28,570
liked Eric's presentation on the subject

00:02:24,820 --> 00:02:31,810
and I renamed it to monix on December

00:02:28,570 --> 00:02:33,760
13th the following year and I have to

00:02:31,810 --> 00:02:36,640
mention strange things happen to me

00:02:33,760 --> 00:02:38,620
around New Year's by I mean like every

00:02:36,640 --> 00:02:41,080
year I have like this existential crisis

00:02:38,620 --> 00:02:46,090
where I become suddenly productive on

00:02:41,080 --> 00:02:49,510
github and if you're ever wondering from

00:02:46,090 --> 00:02:52,060
where the logo is coming from it's a

00:02:49,510 --> 00:02:54,910
combination of scholars logo plus

00:02:52,060 --> 00:02:59,530
amateur bastard and I made it myself in

00:02:54,910 --> 00:03:02,140
Inkscape so yeah this talk is about

00:02:59,530 --> 00:03:04,300
streaming approaches and this image

00:03:02,140 --> 00:03:08,230
should be a metaphor for you know how

00:03:04,300 --> 00:03:10,300
the information is flowing it's supposed

00:03:08,230 --> 00:03:13,840
to convince you that I know what I'm

00:03:10,300 --> 00:03:16,630
talking about so push based streaming

00:03:13,840 --> 00:03:20,860
this is what observable is about and it

00:03:16,630 --> 00:03:23,890
was its origins are in reactive vixx

00:03:20,860 --> 00:03:25,630
also called reactive extensions and it

00:03:23,890 --> 00:03:29,080
was introduced by these fine folks

00:03:25,630 --> 00:03:31,090
working for for Microsoft out of which

00:03:29,080 --> 00:03:34,870
Eric measure has always been an

00:03:31,090 --> 00:03:37,300
inspiration and the basic idea is that

00:03:34,870 --> 00:03:40,330
starting from the basic iterator and

00:03:37,300 --> 00:03:46,540
iterable pattern which has several

00:03:40,330 --> 00:03:48,730
problems like it's synchronous you

00:03:46,540 --> 00:03:54,660
cannot describe asynchronous processing

00:03:48,730 --> 00:03:59,160
with it it doesn't close resources and

00:03:54,660 --> 00:04:03,010
it has a pretty dirty protocol let's say

00:03:59,160 --> 00:04:05,950
we can actually flip flip it around and

00:04:03,010 --> 00:04:09,190
convert that to a push based abstraction

00:04:05,950 --> 00:04:11,320
so in our case we don't longer have the

00:04:09,190 --> 00:04:14,200
iterable as the factory we've got you

00:04:11,320 --> 00:04:16,870
observable which receives a subscriber

00:04:14,200 --> 00:04:19,060
that gets subscribed to events and then

00:04:16,870 --> 00:04:21,549
the observer starts receiving events on

00:04:19,060 --> 00:04:24,550
next on next on next until a final event

00:04:21,549 --> 00:04:26,890
and the stream can end in can end in

00:04:24,550 --> 00:04:29,110
every in success with a non complete or

00:04:26,890 --> 00:04:35,289
in error and it receives like

00:04:29,110 --> 00:04:37,690
an error so this divergence by the way

00:04:35,289 --> 00:04:43,210
from the traversable inst color standard

00:04:37,690 --> 00:04:44,740
library traversable due to the due to

00:04:43,210 --> 00:04:47,259
its interface it has an implicit

00:04:44,740 --> 00:04:49,629
contract in it that it cannot describe a

00:04:47,259 --> 00:04:51,789
synchronous streaming because there is

00:04:49,629 --> 00:04:54,759
no way to know whether the stream ended

00:04:51,789 --> 00:04:57,400
or not but observable has like a very

00:04:54,759 --> 00:04:58,240
explicit event in it that ok the stream

00:04:57,400 --> 00:05:00,610
is now complete

00:04:58,240 --> 00:05:03,849
this interface too has problems like it

00:05:00,610 --> 00:05:05,740
has no ability to do bad pressure we'll

00:05:03,849 --> 00:05:08,680
talk about that in a moment so if you

00:05:05,740 --> 00:05:12,099
think about state machines as I said you

00:05:08,680 --> 00:05:14,259
receive on next or next events until

00:05:12,099 --> 00:05:18,069
either on computer or mirror or happens

00:05:14,259 --> 00:05:20,819
or until against the early cancellation

00:05:18,069 --> 00:05:24,099
event happens from the consumer side

00:05:20,819 --> 00:05:26,169
also in the original area so that

00:05:24,099 --> 00:05:28,360
specification cancellation is a little

00:05:26,169 --> 00:05:33,159
unwieldy because you have to work with

00:05:28,360 --> 00:05:35,409
forward references observable is to do

00:05:33,159 --> 00:05:40,419
leave iterable or you can think about it

00:05:35,409 --> 00:05:45,460
as its evil twin Erik measure is fond of

00:05:40,419 --> 00:05:47,940
saying that and so as I said problems

00:05:45,460 --> 00:05:51,130
whenever we've got a pushed based

00:05:47,940 --> 00:05:53,289
streaming approach like that the problem

00:05:51,130 --> 00:05:56,289
is that we've got no protection against

00:05:53,289 --> 00:05:58,569
slow consumers or infest producers and

00:05:56,289 --> 00:06:02,440
we also have these problems when we work

00:05:58,569 --> 00:06:03,940
directly with akka actors so when doing

00:06:02,440 --> 00:06:06,909
that you either have to implement

00:06:03,940 --> 00:06:09,009
throttling meaning you start dropping

00:06:06,909 --> 00:06:11,919
events on the floor whenever your

00:06:09,009 --> 00:06:13,690
internal buffer fills up or whatever or

00:06:11,919 --> 00:06:16,090
you come up with the same sampling

00:06:13,690 --> 00:06:18,099
strategy but the thing is that the

00:06:16,090 --> 00:06:20,080
buffers are essentially unbounded

00:06:18,099 --> 00:06:22,539
because you don't have a protocol in

00:06:20,080 --> 00:06:24,279
there that does by pressuring on top of

00:06:22,539 --> 00:06:26,319
actors you have to you can implement it

00:06:24,279 --> 00:06:30,159
yourself but you know it's kind of

00:06:26,319 --> 00:06:32,500
unwieldy so as a piece of trivia flatmap

00:06:30,159 --> 00:06:34,150
in the original Rick's Eric's donated

00:06:32,500 --> 00:06:36,039
specification is alias to mush map

00:06:34,150 --> 00:06:38,020
because concat map which is like the

00:06:36,039 --> 00:06:41,060
monadic bind that we know from scholar

00:06:38,020 --> 00:06:43,520
standard collections the

00:06:41,060 --> 00:06:46,190
cat map isn't safe because it uses

00:06:43,520 --> 00:06:49,300
unbounded buffering so your process can

00:06:46,190 --> 00:06:54,139
blow up with an out of memory exception

00:06:49,300 --> 00:06:55,880
and as an alternative the full set at

00:06:54,139 --> 00:06:58,730
light band came up with the reactive

00:06:55,880 --> 00:07:00,800
streams protocol which kind of resembles

00:06:58,730 --> 00:07:04,490
that but introducing it reduces a

00:07:00,800 --> 00:07:06,620
protocol for back pressure basically you

00:07:04,490 --> 00:07:09,680
receive a subscription with a request in

00:07:06,620 --> 00:07:11,510
it and then you start the consumer has

00:07:09,680 --> 00:07:13,310
to communicate demand to the producer

00:07:11,510 --> 00:07:15,620
give me the next ten elements give me

00:07:13,310 --> 00:07:18,800
the next ten elements and the producer

00:07:15,620 --> 00:07:21,560
is bound by that contract if you read

00:07:18,800 --> 00:07:23,120
the reactive streams specification it's

00:07:21,560 --> 00:07:25,100
kind of a low-level protocol because

00:07:23,120 --> 00:07:27,680
there are all of these weird conditions

00:07:25,100 --> 00:07:30,590
what happens in the presence of errors

00:07:27,680 --> 00:07:33,410
what operations are supposed to be

00:07:30,590 --> 00:07:35,960
concurrent or not and so on so it's

00:07:33,410 --> 00:07:37,910
basically for library authors it's not

00:07:35,960 --> 00:07:38,690
for users because we've got better

00:07:37,910 --> 00:07:41,000
things to do

00:07:38,690 --> 00:07:42,889
but the libraries can implement reactive

00:07:41,000 --> 00:07:47,419
streams for interoperability so it's

00:07:42,889 --> 00:07:49,610
great for that before reactive streams

00:07:47,419 --> 00:07:52,789
weather was a thing however I had the

00:07:49,610 --> 00:07:54,410
idea to work with in that protocol to

00:07:52,789 --> 00:07:56,630
introduce future from the standard

00:07:54,410 --> 00:07:59,870
library for implementing back pressure

00:07:56,630 --> 00:08:03,700
so the idea is that or next can return a

00:07:59,870 --> 00:08:07,400
future event and then the producer is

00:08:03,700 --> 00:08:10,700
bound by the contract of waiting on that

00:08:07,400 --> 00:08:12,620
feature for sending the next element

00:08:10,700 --> 00:08:14,780
this is sort of a mixture between

00:08:12,620 --> 00:08:17,630
apple-based and the push based approach

00:08:14,780 --> 00:08:24,500
is still push based it's a little hard

00:08:17,630 --> 00:08:26,960
to explain why but it works well and the

00:08:24,500 --> 00:08:30,070
second idea I had was to introduce

00:08:26,960 --> 00:08:34,070
consumer-driven cancellation which is

00:08:30,070 --> 00:08:37,760
okay it resembles reactive stream very

00:08:34,070 --> 00:08:40,190
active streaming stuff so instead of

00:08:37,760 --> 00:08:41,779
working with the future unit we can work

00:08:40,190 --> 00:08:43,310
with a feature of acknowledgment the

00:08:41,779 --> 00:08:45,170
acknowledgement being a simple

00:08:43,310 --> 00:08:48,720
enumeration that tells the producer

00:08:45,170 --> 00:08:51,389
continue or stop and

00:08:48,720 --> 00:08:53,569
this is basically the full protocol

00:08:51,389 --> 00:08:56,129
there are some low level details in it

00:08:53,569 --> 00:08:58,019
like what happens with the final

00:08:56,129 --> 00:09:01,410
complete event is it bad pressured or

00:08:58,019 --> 00:09:03,810
not but as you may notice this is like a

00:09:01,410 --> 00:09:06,930
very it's still like a very impure low

00:09:03,810 --> 00:09:10,829
level protocol I guess that if you love

00:09:06,930 --> 00:09:18,269
working with raka actors you can also

00:09:10,829 --> 00:09:21,750
love this but basically you have to rely

00:09:18,269 --> 00:09:24,480
on shared mutable state and it's kind of

00:09:21,750 --> 00:09:27,240
low level but the observable just like

00:09:24,480 --> 00:09:28,949
akka streams the observable is a high

00:09:27,240 --> 00:09:32,250
level data type and all of those details

00:09:28,949 --> 00:09:34,949
are properly encapsulated so you don't

00:09:32,250 --> 00:09:38,129
usually have a need to work with that

00:09:34,949 --> 00:09:40,649
low-level protocol and unless you really

00:09:38,129 --> 00:09:42,870
need it and observer is basically

00:09:40,649 --> 00:09:45,449
behaves like a lazy collection like a

00:09:42,870 --> 00:09:48,360
school like a Scala collection but the

00:09:45,449 --> 00:09:50,610
lazy one that can suspend side effects

00:09:48,360 --> 00:09:52,680
and do all sorts of neat things do all

00:09:50,610 --> 00:09:56,100
sorts of aggregations and throttling and

00:09:52,680 --> 00:09:58,620
buffering and so on and usually you work

00:09:56,100 --> 00:10:01,379
with it like with high-level operations

00:09:58,620 --> 00:10:03,990
that describe the processing that you

00:10:01,379 --> 00:10:06,839
want to do with purely pure functions

00:10:03,990 --> 00:10:10,079
let's say and in order to execute an

00:10:06,839 --> 00:10:11,759
observable in order to execute the

00:10:10,079 --> 00:10:14,699
described computation you have to

00:10:11,759 --> 00:10:17,839
subscribe to it subscription is still a

00:10:14,699 --> 00:10:21,240
low-level operation so what we are doing

00:10:17,839 --> 00:10:25,430
is to also provide operators fold

00:10:21,240 --> 00:10:28,620
operators that return tasks instead of

00:10:25,430 --> 00:10:30,750
having to do subscriptions tasks is a

00:10:28,620 --> 00:10:33,449
high-level data type that represents

00:10:30,750 --> 00:10:35,670
basically the IO monad from Haskell but

00:10:33,449 --> 00:10:38,699
it's in Scala and is concurrent and it's

00:10:35,670 --> 00:10:41,250
great and it also interoperate swell

00:10:38,699 --> 00:10:42,269
with colors future there is a cancelable

00:10:41,250 --> 00:10:44,250
future in monix

00:10:42,269 --> 00:10:45,930
but you to interoperate with Colossus

00:10:44,250 --> 00:10:47,790
feature because it inherits from it and

00:10:45,930 --> 00:10:50,819
it works properly and if you ever feel

00:10:47,790 --> 00:10:53,629
the need for a cancelable future we have

00:10:50,819 --> 00:10:56,809
got one in Unix it's actually in UNIX

00:10:53,629 --> 00:11:00,720
execution where all the dirty stuff goes

00:10:56,809 --> 00:11:02,460
so observable is some reddit type our

00:11:00,720 --> 00:11:05,070
flat map is the magnetic

00:11:02,460 --> 00:11:07,649
map it passes all the laws because it's

00:11:05,070 --> 00:11:10,830
lazy and you suspend side effects this

00:11:07,649 --> 00:11:15,950
is an example where we are we are

00:11:10,830 --> 00:11:19,560
breeding lines from a file but this this

00:11:15,950 --> 00:11:21,420
describes what we call a cold data

00:11:19,560 --> 00:11:23,730
source meaning that you have to

00:11:21,420 --> 00:11:26,220
subscribe to it in order to read that

00:11:23,730 --> 00:11:28,890
file because just calling the function

00:11:26,220 --> 00:11:32,310
won't do anything and if you are

00:11:28,890 --> 00:11:37,500
familiar with the i/o datatype or with

00:11:32,310 --> 00:11:38,250
tasks from from Scala observable itself

00:11:37,500 --> 00:11:42,270
is IO

00:11:38,250 --> 00:11:44,730
ish it doesn't need an IO or task to

00:11:42,270 --> 00:11:47,130
evaluate and this is an important point

00:11:44,730 --> 00:11:49,020
which I'll talk about in the second part

00:11:47,130 --> 00:11:50,100
of the presentation where I'm going to

00:11:49,020 --> 00:11:53,339
talk about iterance

00:11:50,100 --> 00:11:56,190
so what is observable great about it's

00:11:53,339 --> 00:11:58,800
great about of doing reactive operations

00:11:56,190 --> 00:12:02,730
like for example switch map which is a

00:11:58,800 --> 00:12:04,470
really concurrent operation I would

00:12:02,730 --> 00:12:06,180
probably need a whole talk to describe

00:12:04,470 --> 00:12:09,120
what you can do is switch map because

00:12:06,180 --> 00:12:10,890
it's such a powerful thing but you

00:12:09,120 --> 00:12:13,529
basically can describe for example a

00:12:10,890 --> 00:12:17,190
debounce which is already provided

00:12:13,529 --> 00:12:18,900
debounce sampling throttling echoing the

00:12:17,190 --> 00:12:20,940
last element in case the source goes

00:12:18,900 --> 00:12:23,279
silent and we've got the variations

00:12:20,940 --> 00:12:25,350
based on that like in case the source

00:12:23,279 --> 00:12:30,750
goes silent start repeating the last

00:12:25,350 --> 00:12:34,620
event and all of that makes it easy to

00:12:30,750 --> 00:12:37,410
build a pipeline of where you need where

00:12:34,620 --> 00:12:40,500
you process events coming from real-time

00:12:37,410 --> 00:12:44,240
data sources like what we did when we

00:12:40,500 --> 00:12:47,610
were monitoring power power plants so

00:12:44,240 --> 00:12:51,270
yeah this is an example where we filter

00:12:47,610 --> 00:12:53,400
out the repeated elements from the

00:12:51,270 --> 00:12:56,459
source we are sampling those events

00:12:53,400 --> 00:13:00,089
every one seconds like I mean don't emit

00:12:56,459 --> 00:13:02,250
events for more more events than one

00:13:00,089 --> 00:13:04,350
every second and then if the source

00:13:02,250 --> 00:13:06,870
called silent repeats the last element

00:13:04,350 --> 00:13:09,810
every 5 seconds so it has a lot of

00:13:06,870 --> 00:13:12,329
powerful operations like that and I'm

00:13:09,810 --> 00:13:15,770
not going to talk about this one the

00:13:12,329 --> 00:13:15,770
observable optimizations

00:13:16,330 --> 00:13:25,000
I did a lot of work in optimizing

00:13:21,100 --> 00:13:28,330
observable for example flat map as a

00:13:25,000 --> 00:13:30,610
case study its models are complex state

00:13:28,330 --> 00:13:32,170
machines for eliminating basically

00:13:30,610 --> 00:13:34,540
asynchronous boundaries from it because

00:13:32,170 --> 00:13:36,510
those are bad for throughput it deals

00:13:34,540 --> 00:13:39,760
with concurrency by means of one atomic

00:13:36,510 --> 00:13:41,740
with cache line padding and using gate

00:13:39,760 --> 00:13:43,390
instead platform for instance rinsings

00:13:41,740 --> 00:13:45,340
and I really encourage you to look at

00:13:43,390 --> 00:13:47,530
the monix execution sub projects because

00:13:45,340 --> 00:13:53,530
I've got a lot of law really low-level

00:13:47,530 --> 00:13:56,140
concurrency abstractions in there and we

00:13:53,530 --> 00:13:59,320
are also using like this awesome library

00:13:56,140 --> 00:14:01,600
known only by library authors called JC

00:13:59,320 --> 00:14:04,210
tools exposing really fast

00:14:01,600 --> 00:14:06,190
concurrent queues queue implementations

00:14:04,210 --> 00:14:10,770
because we've got scenarios where we

00:14:06,190 --> 00:14:14,880
we've got multi producer single consumer

00:14:10,770 --> 00:14:17,170
we've got such scenarios so it's it's

00:14:14,880 --> 00:14:19,180
those implementations are way faster

00:14:17,170 --> 00:14:24,910
than what you can find in Java Scala

00:14:19,180 --> 00:14:26,950
Java's was Scala standard libraries so

00:14:24,910 --> 00:14:29,830
as a consequence observable basically

00:14:26,950 --> 00:14:32,830
has best-in-class performance it

00:14:29,830 --> 00:14:34,630
competes with every other library it's

00:14:32,830 --> 00:14:37,030
not the best when you are doing

00:14:34,630 --> 00:14:39,220
benchmarks you basically optimize for

00:14:37,030 --> 00:14:41,110
the things you care about and I mean

00:14:39,220 --> 00:14:43,300
that's what was authored will show you

00:14:41,110 --> 00:14:45,580
the things they care about but it

00:14:43,300 --> 00:14:47,860
performance is pretty good overall and

00:14:45,580 --> 00:14:50,860
it provides referential transparency and

00:14:47,860 --> 00:14:54,010
it's one of those cases where the API is

00:14:50,860 --> 00:14:56,380
pretty much pure but it has dirty

00:14:54,010 --> 00:15:02,890
internals which is an interesting

00:14:56,380 --> 00:15:04,840
approach I mean coming like me from the

00:15:02,890 --> 00:15:09,700
Java side instead of coming from the

00:15:04,840 --> 00:15:12,700
other side from husker let's say this is

00:15:09,700 --> 00:15:16,900
in contrast with the other approach

00:15:12,700 --> 00:15:19,090
right so right now let's talk about pool

00:15:16,900 --> 00:15:21,220
base dreaming and iterate is another

00:15:19,090 --> 00:15:25,900
alternative introduced in monix in its

00:15:21,220 --> 00:15:28,550
own sub project and it's meant to model

00:15:25,900 --> 00:15:31,820
or pull up purely functional

00:15:28,550 --> 00:15:34,010
your based approach goatee is known of

00:15:31,820 --> 00:15:36,769
is known to have said architecture is

00:15:34,010 --> 00:15:38,750
frozen music which inspired John Bentley

00:15:36,769 --> 00:15:41,540
to say that that data structures are

00:15:38,750 --> 00:15:43,760
frozen algorithms you may know it John

00:15:41,540 --> 00:15:47,930
Bentley as the author of the programming

00:15:43,760 --> 00:15:50,990
per book and the key insights in

00:15:47,930 --> 00:15:53,600
designing FB programs that I learned the

00:15:50,990 --> 00:15:56,120
hard way because you know it's one of

00:15:53,600 --> 00:15:59,470
those things where you have to learn by

00:15:56,120 --> 00:16:02,360
stealing the trait from others is to

00:15:59,470 --> 00:16:05,300
when designing an EFI program you have

00:16:02,360 --> 00:16:07,279
to think about freezing algorithms into

00:16:05,300 --> 00:16:09,410
immutable data structures you have to

00:16:07,279 --> 00:16:13,040
think about state machines most of the

00:16:09,410 --> 00:16:14,720
time and you have to be lazy and how can

00:16:13,040 --> 00:16:16,970
you be lazing in a strict language like

00:16:14,720 --> 00:16:18,950
Scala where you turn simple values into

00:16:16,970 --> 00:16:22,700
functions and you suspend side effects

00:16:18,950 --> 00:16:24,170
in IO or tasks or whatever so this is

00:16:22,700 --> 00:16:25,880
the part where I start talking about

00:16:24,170 --> 00:16:32,300
state machines because I have a real

00:16:25,880 --> 00:16:34,520
fetish for it we can start by from the

00:16:32,300 --> 00:16:39,649
scholars standard list which is

00:16:34,520 --> 00:16:41,660
basically and what they call an ADT list

00:16:39,649 --> 00:16:43,970
node can be either a cons like a

00:16:41,660 --> 00:16:46,700
combination from a head and the rest of

00:16:43,970 --> 00:16:48,470
the stream or an eel which represents

00:16:46,700 --> 00:16:50,240
the empty list so this is like a really

00:16:48,470 --> 00:16:52,279
simple state machine by the way because

00:16:50,240 --> 00:16:54,980
in order to consume the whole list you

00:16:52,279 --> 00:16:56,779
have to process the list and follow the

00:16:54,980 --> 00:16:59,079
tail element until the end and then

00:16:56,779 --> 00:17:02,870
wager when you're at the end you're done

00:16:59,079 --> 00:17:05,350
so we could say something like this we

00:17:02,870 --> 00:17:08,030
are already renaming it to iterance and

00:17:05,350 --> 00:17:10,400
replacing that rest of the stream with a

00:17:08,030 --> 00:17:14,059
lazy function because we are we are we

00:17:10,400 --> 00:17:17,059
want to be lazy and we can have errors

00:17:14,059 --> 00:17:20,089
because we have functions in it so it's

00:17:17,059 --> 00:17:22,610
not like we can have a negative value

00:17:20,089 --> 00:17:24,500
evaluated list anymore so because that's

00:17:22,610 --> 00:17:26,569
a function you can throw an error well

00:17:24,500 --> 00:17:28,610
we need kind of need some way to

00:17:26,569 --> 00:17:30,380
represent errors without actually

00:17:28,610 --> 00:17:32,480
throwing them because throwing errors is

00:17:30,380 --> 00:17:35,630
not cool so this is a state machine and

00:17:32,480 --> 00:17:39,740
conditions are hold error or hold

00:17:35,630 --> 00:17:41,240
none which represents success and let's

00:17:39,740 --> 00:17:42,380
say that we want to do resource

00:17:41,240 --> 00:17:46,160
management and this is

00:17:42,380 --> 00:17:48,710
problem with something like iterable so

00:17:46,160 --> 00:17:50,990
if we went to the resource management we

00:17:48,710 --> 00:17:53,960
present the user latitude at each point

00:17:50,990 --> 00:17:56,000
with with the option of doing an or

00:17:53,960 --> 00:17:58,600
litter elimination by introducing a stop

00:17:56,000 --> 00:18:02,560
function in that in that data structure

00:17:58,600 --> 00:18:04,880
so at each at each point of the

00:18:02,560 --> 00:18:07,460
processing the consumer has the choice

00:18:04,880 --> 00:18:11,090
does it go for the rest of the stream or

00:18:07,460 --> 00:18:14,770
does it stop and based on this you can

00:18:11,090 --> 00:18:17,570
implement resources safe let's say

00:18:14,770 --> 00:18:21,470
operators on top like take if you do a

00:18:17,570 --> 00:18:23,720
take 100 let's say from an iterable when

00:18:21,470 --> 00:18:25,820
an iterator is not going to be safe is

00:18:23,720 --> 00:18:27,380
that iterator goes over a file because

00:18:25,820 --> 00:18:31,730
it's going to leave the file handle open

00:18:27,380 --> 00:18:33,290
and that's not what we want and because

00:18:31,730 --> 00:18:36,050
we are lazy we are going to introduce

00:18:33,290 --> 00:18:38,270
another state called suspend which

00:18:36,050 --> 00:18:40,700
doesn't have a current element and it

00:18:38,270 --> 00:18:43,610
allows you to defer the rest of the

00:18:40,700 --> 00:18:45,980
processing until later let's say so or

00:18:43,610 --> 00:18:48,800
it allows you to eliminate elements from

00:18:45,980 --> 00:18:51,500
the stream this is what suspends does so

00:18:48,800 --> 00:18:53,540
right now we can have like in the stream

00:18:51,500 --> 00:18:55,490
next suspend next suspend let's say

00:18:53,540 --> 00:18:56,990
until the end of the stream which can

00:18:55,490 --> 00:18:59,620
terminate if you're in court on your

00:18:56,990 --> 00:19:02,570
list stop this is a state machine and

00:18:59,620 --> 00:19:05,540
how do you work with this you build an

00:19:02,570 --> 00:19:08,870
interpreter for it and let's say I mean

00:19:05,540 --> 00:19:13,070
you know like FB developers you start

00:19:08,870 --> 00:19:15,830
doing pattern matching like crazy so to

00:19:13,070 --> 00:19:17,870
implement the filter operation you do

00:19:15,830 --> 00:19:19,760
pattern matching on that stream if it's

00:19:17,870 --> 00:19:22,100
simply your return empty if it's a

00:19:19,760 --> 00:19:23,930
suspend you return the suspend by

00:19:22,100 --> 00:19:26,570
creating a closure here that applies

00:19:23,930 --> 00:19:28,640
filter to the rest of the stream as you

00:19:26,570 --> 00:19:30,530
may know in Scala this is not stack safe

00:19:28,640 --> 00:19:34,760
and it will blow up but we can solve

00:19:30,530 --> 00:19:37,910
that and we can say okay if we have an S

00:19:34,760 --> 00:19:40,130
or next and it satisfies the predicate

00:19:37,910 --> 00:19:42,320
we can return it but apply filter to the

00:19:40,130 --> 00:19:45,230
rest of the stream otherwise suspends

00:19:42,320 --> 00:19:48,350
and we've got a filter operation defined

00:19:45,230 --> 00:19:50,570
that's not stack safe of course Scala

00:19:48,350 --> 00:19:52,700
has problems like that because it's only

00:19:50,570 --> 00:19:53,960
Gurley evaluated language great for

00:19:52,700 --> 00:19:56,060
performance when you're dealing with

00:19:53,960 --> 00:19:58,250
mutable stuff

00:19:56,060 --> 00:20:00,140
so great for functional programming so

00:19:58,250 --> 00:20:02,480
what we do in Scala is to start work

00:20:00,140 --> 00:20:05,810
working with trampolines trampolines or

00:20:02,480 --> 00:20:08,240
with execution contexts so we could say

00:20:05,810 --> 00:20:10,730
let's work with future and future has a

00:20:08,240 --> 00:20:12,740
stack say flat map because it pushes

00:20:10,730 --> 00:20:15,770
those three doubles in the execution

00:20:12,740 --> 00:20:18,200
context but future is not a function and

00:20:15,770 --> 00:20:20,150
we need functions I mean this top here

00:20:18,200 --> 00:20:23,570
would be useless if it were for a future

00:20:20,150 --> 00:20:26,360
unit we need the function in it we could

00:20:23,570 --> 00:20:29,750
turn that into a function I mean this is

00:20:26,360 --> 00:20:32,870
called a thunk parameter loss function

00:20:29,750 --> 00:20:36,650
that on a variation returns efficient

00:20:32,870 --> 00:20:38,780
and this would work but we already have

00:20:36,650 --> 00:20:40,880
a task in mornings and it's a fairly

00:20:38,780 --> 00:20:44,420
performance task and it has a memory

00:20:40,880 --> 00:20:48,460
safe flat map and map implementations

00:20:44,420 --> 00:20:53,350
and we can work around the need for that

00:20:48,460 --> 00:20:57,650
and task is a function I mean you can

00:20:53,350 --> 00:20:59,360
consider it as being a function with

00:20:57,650 --> 00:21:01,940
which you can describe side effects so

00:20:59,360 --> 00:21:03,620
that works or we could work with Cueva

00:21:01,940 --> 00:21:06,920
Wavell is a data type in UNIX that's

00:21:03,620 --> 00:21:09,830
like tasks but it guarantees synchronous

00:21:06,920 --> 00:21:12,980
execution or we could work with the new

00:21:09,830 --> 00:21:18,260
cat effect i/o I mean like do we really

00:21:12,980 --> 00:21:20,360
have to choose so we can start playing

00:21:18,260 --> 00:21:24,830
in the big boys League and do parametric

00:21:20,360 --> 00:21:28,570
polymorphism and introduce an F we say

00:21:24,830 --> 00:21:31,580
we want to you know work with any F and

00:21:28,570 --> 00:21:34,100
the interesting thing about it is that

00:21:31,580 --> 00:21:37,160
the actual restrictions about what F is

00:21:34,100 --> 00:21:39,290
comes on the operations themselves so in

00:21:37,160 --> 00:21:42,530
this case we are saying F must implement

00:21:39,290 --> 00:21:45,500
sync which is like what I plus described

00:21:42,530 --> 00:21:47,930
in case effect that says this is a monad

00:21:45,500 --> 00:21:51,080
that heaven has a memory safe flat map

00:21:47,930 --> 00:21:53,660
and that can suspend side effects with

00:21:51,080 --> 00:21:56,450
that law we can describe chaining in our

00:21:53,660 --> 00:22:02,450
streaming and we will be safe in the

00:21:56,450 --> 00:22:04,580
knowledge that it won't blow up it won't

00:22:02,450 --> 00:22:10,040
blow up this the call stack it will be

00:22:04,580 --> 00:22:12,380
safe to use let's say so now

00:22:10,040 --> 00:22:17,240
it works for IO it works for tusk it

00:22:12,380 --> 00:22:18,640
works for quaver and it runs again it's

00:22:17,240 --> 00:22:20,990
a high level data type that

00:22:18,640 --> 00:22:22,880
pattern-matching I just show you you

00:22:20,990 --> 00:22:25,220
don't really have to do it because it

00:22:22,880 --> 00:22:27,740
already provides operators that that we

00:22:25,220 --> 00:22:29,300
could use just like observable it

00:22:27,740 --> 00:22:32,330
actually provides many of the same

00:22:29,300 --> 00:22:34,730
operators except that the concurrent

00:22:32,330 --> 00:22:36,320
ones are really hard are harder to

00:22:34,730 --> 00:22:40,570
implement then with a push based

00:22:36,320 --> 00:22:43,700
approach so but we are getting there and

00:22:40,570 --> 00:22:46,100
the current version it's already really

00:22:43,700 --> 00:22:50,000
useful even without switch map and

00:22:46,100 --> 00:22:53,060
throttling and so on and you can work

00:22:50,000 --> 00:22:54,620
with a yo you can work with quaver you

00:22:53,060 --> 00:22:57,940
can basically shove anything in there

00:22:54,620 --> 00:23:00,650
that implements sync and this this

00:22:57,940 --> 00:23:02,720
construct right here is code partially

00:23:00,650 --> 00:23:05,090
evaluated type basically you're doing

00:23:02,720 --> 00:23:06,500
like a trick we will supply don't be

00:23:05,090 --> 00:23:09,350
scared by it because it's nothing

00:23:06,500 --> 00:23:14,000
special it's a it's like a trick we're

00:23:09,350 --> 00:23:16,750
doing for the builders right saying but

00:23:14,000 --> 00:23:22,820
it's yeah

00:23:16,750 --> 00:23:27,770
so it has performance issues like all

00:23:22,820 --> 00:23:30,080
things in Scala that are too pure the

00:23:27,770 --> 00:23:32,270
problem is that it's basically a linked

00:23:30,080 --> 00:23:35,650
list linked lists are terrible for

00:23:32,270 --> 00:23:39,140
performance and it's a linked list that

00:23:35,650 --> 00:23:41,600
introduces lazy or asynchronous

00:23:39,140 --> 00:23:45,560
boundaries at each step and those are

00:23:41,600 --> 00:23:47,870
terrible as well so in order to to make

00:23:45,560 --> 00:23:49,820
stuff more performant when working with

00:23:47,870 --> 00:23:52,250
functional programming we really need to

00:23:49,820 --> 00:23:55,100
find ways to work with arrays and to

00:23:52,250 --> 00:24:00,770
avoid essentially lazy a synchronous

00:23:55,100 --> 00:24:02,690
boundaries so what we can do I mean I

00:24:00,770 --> 00:24:05,810
don't know I mean what can iterate over

00:24:02,690 --> 00:24:08,600
arrays efficiently with like near zero

00:24:05,810 --> 00:24:11,870
performance well if you ignore the

00:24:08,600 --> 00:24:17,570
boxing they do I mean if only we had

00:24:11,870 --> 00:24:19,820
such an abstraction but you know what if

00:24:17,570 --> 00:24:23,630
we introduced in our internal state

00:24:19,820 --> 00:24:26,510
nodes that wrap iterables and the

00:24:23,630 --> 00:24:32,320
traitors well now we can shovel raising

00:24:26,510 --> 00:24:35,480
them and process stuff in batches so

00:24:32,320 --> 00:24:37,100
instead of introducing lazy where a

00:24:35,480 --> 00:24:39,080
synchronous boundaries then it will be

00:24:37,100 --> 00:24:42,080
evaluated at just step and which are

00:24:39,080 --> 00:24:47,180
slow you can simply stream stuff in

00:24:42,080 --> 00:24:49,010
batches and I'm going to be honest with

00:24:47,180 --> 00:24:51,770
you at this point this is no longer a

00:24:49,010 --> 00:24:53,990
purely functional data structure I mean

00:24:51,770 --> 00:24:56,270
it is in spirit but not in actual

00:24:53,990 --> 00:24:59,900
implementation because it has an

00:24:56,270 --> 00:25:02,330
iterator in it but because F can suspend

00:24:59,900 --> 00:25:04,370
side effects that doesn't matter for the

00:25:02,330 --> 00:25:09,920
operators because the operators are

00:25:04,370 --> 00:25:12,080
meant to suspend the are meant to be

00:25:09,920 --> 00:25:14,090
referential a transparent so whenever we

00:25:12,080 --> 00:25:17,030
have got processing that triggers side

00:25:14,090 --> 00:25:19,550
effects on iterators those get suspended

00:25:17,030 --> 00:25:21,020
and in turn you achieve performance and

00:25:19,550 --> 00:25:24,020
now I'm going to do a comparison between

00:25:21,020 --> 00:25:27,290
between iterator and ether intent

00:25:24,020 --> 00:25:29,600
observable and as a really cool case

00:25:27,290 --> 00:25:32,260
study will be the implementation of scan

00:25:29,600 --> 00:25:34,880
evals candy values like the essence of

00:25:32,260 --> 00:25:37,700
reactive programming with reactive X

00:25:34,880 --> 00:25:42,590
scan actually not scan even scary well I

00:25:37,700 --> 00:25:44,480
think it's an innovation in UNIX but as

00:25:42,590 --> 00:25:48,680
a really cool case study I implemented

00:25:44,480 --> 00:25:50,240
it for for both and this would be like

00:25:48,680 --> 00:25:54,530
the signature for iterance

00:25:50,240 --> 00:25:55,880
it has a sink restriction in it and you

00:25:54,530 --> 00:25:57,560
don't have to understand the

00:25:55,880 --> 00:25:59,470
implementation but this is pretty much

00:25:57,560 --> 00:26:02,780
the gist of it I mean it's like a

00:25:59,470 --> 00:26:04,700
recursive function that basically does

00:26:02,780 --> 00:26:06,890
pattern matching there's nothing special

00:26:04,700 --> 00:26:10,610
about it the cool thing is that mere

00:26:06,890 --> 00:26:12,470
mortals can do this on the other hand

00:26:10,610 --> 00:26:14,810
for observable we introduced an effect

00:26:12,470 --> 00:26:18,020
restriction because observable does

00:26:14,810 --> 00:26:21,200
evaluation by itself of effect being

00:26:18,020 --> 00:26:23,930
larger than then sink being a sub type

00:26:21,200 --> 00:26:27,290
of thing and it's more restrictive and

00:26:23,930 --> 00:26:31,390
we affect basically represents the

00:26:27,290 --> 00:26:34,640
ability to evaluate an effect so

00:26:31,390 --> 00:26:36,560
observable needs this because it can no

00:26:34,640 --> 00:26:36,970
longer defer that evaluation to the

00:26:36,560 --> 00:26:40,090
under

00:26:36,970 --> 00:26:42,040
effect naturally understand this but

00:26:40,090 --> 00:26:48,400
it's a it's a really cool trade-off to

00:26:42,040 --> 00:26:51,040
make and the implementation is actually

00:26:48,400 --> 00:26:54,550
specialized for tasks and then we

00:26:51,040 --> 00:26:57,160
convert from effector to task I think we

00:26:54,550 --> 00:27:00,250
can with a new additions to catch effect

00:26:57,160 --> 00:27:03,850
I think I could describe scan eval

00:27:00,250 --> 00:27:06,970
entirely via the type classes in catch

00:27:03,850 --> 00:27:08,680
effect but right now it's specialized

00:27:06,970 --> 00:27:13,050
for tasks actually and we are doing

00:27:08,680 --> 00:27:15,100
conversions and the thing about

00:27:13,050 --> 00:27:16,870
observables can map is that it's

00:27:15,100 --> 00:27:18,820
implementation is essentially that of

00:27:16,870 --> 00:27:21,220
flat map and I mentioned flat map on a

00:27:18,820 --> 00:27:24,250
server before is it does like really

00:27:21,220 --> 00:27:26,080
weird stuff internally to achieve

00:27:24,250 --> 00:27:29,940
performance to get rid of a synchronous

00:27:26,080 --> 00:27:32,620
boundaries you have to be like a

00:27:29,940 --> 00:27:35,710
concurrency guru for the JVM to do that

00:27:32,620 --> 00:27:37,750
and I'm not that I mean I I'm still

00:27:35,710 --> 00:27:40,210
unsure if if the implementation is

00:27:37,750 --> 00:27:42,670
correct I can only say that it's correct

00:27:40,210 --> 00:27:45,370
because I've ran a lot of tests on it

00:27:42,670 --> 00:27:47,380
but it's because it deals with java's

00:27:45,370 --> 00:27:50,470
memory model with concurrency rules

00:27:47,380 --> 00:27:52,360
related to Java it's really hard to

00:27:50,470 --> 00:27:54,460
reason about it but on the other hand

00:27:52,360 --> 00:27:58,440
the implementation for a turrent

00:27:54,460 --> 00:28:01,780
is is something that's understandable so

00:27:58,440 --> 00:28:07,330
to do about I did a bunch of benchmarks

00:28:01,780 --> 00:28:09,370
and the blue and the orange lines are

00:28:07,330 --> 00:28:12,670
observable so blue is flat scan

00:28:09,370 --> 00:28:15,460
observable as Cannavale and the gray bar

00:28:12,670 --> 00:28:17,350
is kin evil and from iterance

00:28:15,460 --> 00:28:20,440
and deterrent is only decent because I

00:28:17,350 --> 00:28:22,510
did that optimization with iterator so

00:28:20,440 --> 00:28:24,790
it by being able to stream stuff in

00:28:22,510 --> 00:28:27,100
batches we can apply organizations there

00:28:24,790 --> 00:28:30,430
the performance is less but it's still

00:28:27,100 --> 00:28:33,040
decent and you can pretty much say about

00:28:30,430 --> 00:28:35,890
it that observable has performance but

00:28:33,040 --> 00:28:39,280
it runt has risen and depending on the

00:28:35,890 --> 00:28:41,110
use case that you have you make that

00:28:39,280 --> 00:28:43,390
trade-off do you want performance on do

00:28:41,110 --> 00:28:46,120
you want reason well observable is

00:28:43,390 --> 00:28:48,490
useful for reactive stuff is like told

00:28:46,120 --> 00:28:50,130
or Europe or this is another benchmark

00:28:48,490 --> 00:28:51,990
showing the

00:28:50,130 --> 00:28:56,039
performance impact of doing stuff in

00:28:51,990 --> 00:28:59,120
batches this green bar right here

00:28:56,039 --> 00:29:02,490
represents iterance that operates with

00:28:59,120 --> 00:29:05,460
batched iterators underneath underneath

00:29:02,490 --> 00:29:07,320
with patched arrays basically and this

00:29:05,460 --> 00:29:09,840
one is without so the performance

00:29:07,320 --> 00:29:14,160
implications can be quite huge and this

00:29:09,840 --> 00:29:22,020
will do like blue bar is the throughput

00:29:14,160 --> 00:29:25,289
of observable which exceeds both so when

00:29:22,020 --> 00:29:28,380
analyzing the differences between them

00:29:25,289 --> 00:29:31,200
one interesting thing is that observable

00:29:28,380 --> 00:29:34,740
cannot have a third right operation only

00:29:31,200 --> 00:29:36,720
two described folds right

00:29:34,740 --> 00:29:39,390
I'm not sure if you're familiar with it

00:29:36,720 --> 00:29:41,280
in Scala standard collections it's not

00:29:39,390 --> 00:29:43,049
exactly right because third right is

00:29:41,280 --> 00:29:45,240
supposed to bill raises such that you

00:29:43,049 --> 00:29:49,080
are then able to short-circuit the

00:29:45,240 --> 00:29:53,490
processing it's not actually the fault

00:29:49,080 --> 00:29:56,429
writer that we want but it's a pretty

00:29:53,490 --> 00:29:58,770
cool operation it's not possible for

00:29:56,429 --> 00:30:00,720
observable because observable is not a

00:29:58,770 --> 00:30:02,909
recursive data structure you basically

00:30:00,720 --> 00:30:07,380
need something to be pull based in order

00:30:02,909 --> 00:30:09,450
to describe a fault right for it we can

00:30:07,380 --> 00:30:13,710
work with substitutes like fold while

00:30:09,450 --> 00:30:15,720
left L which I came up with what you

00:30:13,710 --> 00:30:17,640
don't can have a fault right it's not

00:30:15,720 --> 00:30:20,250
exactly the signature that you get in

00:30:17,640 --> 00:30:23,309
Haskell or in Scala because you need a

00:30:20,250 --> 00:30:32,400
cancellation token to be in there it's I

00:30:23,309 --> 00:30:34,919
mean either otherwise we this resource

00:30:32,400 --> 00:30:37,140
handling cannot be automatic in this

00:30:34,919 --> 00:30:38,940
case you basically need to leave the

00:30:37,140 --> 00:30:41,400
user in charge so in case the user

00:30:38,940 --> 00:30:43,440
short-circuits the processing in is that

00:30:41,400 --> 00:30:46,110
cancellation token to close the fire

00:30:43,440 --> 00:30:48,179
handlers and so on and it's a really

00:30:46,110 --> 00:30:50,490
powerful operation you can describe

00:30:48,179 --> 00:30:52,679
something like exists with it so it

00:30:50,490 --> 00:30:55,289
would short-circuit the processing if

00:30:52,679 --> 00:30:58,470
the predicate is satisfied it does a

00:30:55,289 --> 00:30:59,309
stop which releases resources followed

00:30:58,470 --> 00:31:04,029
by true

00:30:59,309 --> 00:31:06,190
as a result who are similar for for all

00:31:04,029 --> 00:31:10,299
we can even describe a memory safe

00:31:06,190 --> 00:31:12,970
concat operation for it although we

00:31:10,299 --> 00:31:16,360
don't really do that because we care

00:31:12,970 --> 00:31:18,580
about performance implications so concat

00:31:16,360 --> 00:31:20,289
has its own implementation but we could

00:31:18,580 --> 00:31:22,419
do this and it would still have useful

00:31:20,289 --> 00:31:24,490
characteristics and this was an

00:31:22,419 --> 00:31:28,120
embarrassing Twitter moment for me

00:31:24,490 --> 00:31:29,799
because I was kind of pissed off that I

00:31:28,120 --> 00:31:33,570
couldn't implement fault right for

00:31:29,799 --> 00:31:36,490
observable and for iterance I finally

00:31:33,570 --> 00:31:41,499
realized eventually that I need a third

00:31:36,490 --> 00:31:44,860
parameter the thing is that a fault

00:31:41,499 --> 00:31:46,749
right operation is to reflect the shape

00:31:44,860 --> 00:31:51,360
of the data constructors is what they

00:31:46,749 --> 00:31:55,509
call the cat a morphism it's a really

00:31:51,360 --> 00:31:58,600
it's really powerful stuff and we can't

00:31:55,509 --> 00:32:01,539
describe it for observable so in

00:31:58,600 --> 00:32:03,820
conclusion observable is best for

00:32:01,539 --> 00:32:06,490
reactive operations shared data sources

00:32:03,820 --> 00:32:08,740
of which I haven't talked about I mean

00:32:06,490 --> 00:32:11,860
it's really good of splitting on an

00:32:08,740 --> 00:32:14,009
operator in to and applying batching and

00:32:11,860 --> 00:32:17,529
blood by pressuring their throttling

00:32:14,009 --> 00:32:19,629
buffering performance and it rent is

00:32:17,529 --> 00:32:23,049
best for is their implementation

00:32:19,629 --> 00:32:25,960
reasoning and basically sometimes I mean

00:32:23,049 --> 00:32:27,940
you have like a sequence of i/o where

00:32:25,960 --> 00:32:30,429
task operations already defined and you

00:32:27,940 --> 00:32:32,889
want to make that into a stream so why

00:32:30,429 --> 00:32:35,799
not use an abstraction that does that

00:32:32,889 --> 00:32:39,549
naturally because with observable it's

00:32:35,799 --> 00:32:41,409
kind of a stretch and both implement the

00:32:39,549 --> 00:32:43,480
reactive streams protocol which means

00:32:41,409 --> 00:32:45,970
they have interoperability with other

00:32:43,480 --> 00:32:48,070
screamin swimming libraries I mean you

00:32:45,970 --> 00:32:50,830
can take an observable on a knitter ant

00:32:48,070 --> 00:32:56,110
and consume it with a pipe from Apple

00:32:50,830 --> 00:33:00,580
streams or you can take other streams

00:32:56,110 --> 00:33:04,090
data source and consume it with monix

00:33:00,580 --> 00:33:06,249
consumer so and both do back pressure in

00:33:04,090 --> 00:33:10,080
and save resource management and one

00:33:06,249 --> 00:33:14,279
more thing in in my work I noticed that

00:33:10,080 --> 00:33:17,410
when you import abstractions from

00:33:14,279 --> 00:33:21,820
Haskell they usually

00:33:17,410 --> 00:33:26,020
from performance issues because the

00:33:21,820 --> 00:33:28,390
developers want elegance in

00:33:26,020 --> 00:33:30,490
implementation I'm say screw elegance

00:33:28,390 --> 00:33:35,920
and implementation I mean if it's

00:33:30,490 --> 00:33:37,660
properly encapsulated you need to

00:33:35,920 --> 00:33:39,700
achieve a good throughput such that the

00:33:37,660 --> 00:33:43,780
user doesn't have to worry about it the

00:33:39,700 --> 00:33:46,090
user can then worry about it who can

00:33:43,780 --> 00:33:48,910
then worry about their own business

00:33:46,090 --> 00:33:49,840
logic or whatever so performance is not

00:33:48,910 --> 00:33:52,360
important

00:33:49,840 --> 00:33:55,270
but it's not it's usually not important

00:33:52,360 --> 00:33:57,910
in applications not in libraries so if

00:33:55,270 --> 00:34:00,550
you allow some impurity but that's

00:33:57,910 --> 00:34:05,520
properly encapsulated like cool things

00:34:00,550 --> 00:34:09,550
can happen in Scala libraries anyway so

00:34:05,520 --> 00:34:17,740
that was it you know I think we have

00:34:09,550 --> 00:34:21,700
some time left for questions oh by the

00:34:17,740 --> 00:34:23,830
way the website has a lot of

00:34:21,700 --> 00:34:27,100
documentation in it and more is coming

00:34:23,830 --> 00:34:30,760
and you can follow the Twitter account

00:34:27,100 --> 00:34:34,150
or the organization on github

00:34:30,760 --> 00:34:36,280
for news and announcements and we forgot

00:34:34,150 --> 00:34:38,710
a friendly guitar channel that I forgot

00:34:36,280 --> 00:34:41,980
to mention here if you want to chat

00:34:38,710 --> 00:34:46,030
about it okay great yeah we actually

00:34:41,980 --> 00:34:47,830
have ten minutes for questions so who

00:34:46,030 --> 00:34:50,040
wants to go first I come there and then

00:34:47,830 --> 00:34:50,040
there

00:34:56,739 --> 00:35:03,069
could you say how ignorant really

00:35:00,319 --> 00:35:08,150
compared to FS two streams

00:35:03,069 --> 00:35:10,369
yeah at this point isn't has fewer

00:35:08,150 --> 00:35:13,219
operations defined because FS two has

00:35:10,369 --> 00:35:15,799
been developed for a longer as a

00:35:13,219 --> 00:35:19,989
difference it runt is a lot more

00:35:15,799 --> 00:35:24,279
explicit in its internal encoding about

00:35:19,989 --> 00:35:27,769
what I've said finalize errs about stop

00:35:24,279 --> 00:35:30,289
and you can actually work with its

00:35:27,769 --> 00:35:34,069
internal encoding you can understand it

00:35:30,289 --> 00:35:39,440
the FS tones the other hand try to tries

00:35:34,069 --> 00:35:43,029
to be smarter about about cancellation

00:35:39,440 --> 00:35:45,680
because their priority was to describe

00:35:43,029 --> 00:35:48,319
concurrent operations that are more

00:35:45,680 --> 00:35:53,930
naturally described with observable

00:35:48,319 --> 00:35:56,180
let's say I think right now it Hrant has

00:35:53,930 --> 00:35:59,719
the simpler implementation I have no

00:35:56,180 --> 00:36:04,880
idea how that will evolve but it's

00:35:59,719 --> 00:36:07,190
basically a another exploration of the

00:36:04,880 --> 00:36:15,410
design space let's say if you'll take a

00:36:07,190 --> 00:36:19,279
look I think yeah I'm not sure what to

00:36:15,410 --> 00:36:22,430
say there they are similar in approaches

00:36:19,279 --> 00:36:24,200
but not in implementation each round has

00:36:22,430 --> 00:36:27,079
a simple implementation but at this

00:36:24,200 --> 00:36:29,930
point also does less so but there is

00:36:27,079 --> 00:36:32,269
virtue at in being simpler and doing

00:36:29,930 --> 00:36:34,009
less I want to introduce a merge

00:36:32,269 --> 00:36:35,539
operation for example but on the other

00:36:34,009 --> 00:36:37,420
hand I'm not sure if it's worth it

00:36:35,539 --> 00:36:44,960
because if users want to do merging

00:36:37,420 --> 00:36:46,759
observable is far better for that yes

00:36:44,960 --> 00:36:49,099
this was a talk I think in the same room

00:36:46,759 --> 00:36:50,960
about growl VM where the speaker

00:36:49,099 --> 00:36:53,059
presented quite impressive performance

00:36:50,960 --> 00:36:55,519
gains particularly on the highly

00:36:53,059 --> 00:36:57,950
polymorphic and functional code I wonder

00:36:55,519 --> 00:37:01,309
if you try to run you know it runs on

00:36:57,950 --> 00:37:04,489
growl VM and how numbers compare if you

00:37:01,309 --> 00:37:06,050
have no but it's an awesome development

00:37:04,489 --> 00:37:07,670
I'm really excited about it I

00:37:06,050 --> 00:37:10,130
what about it so they are doing better

00:37:07,670 --> 00:37:12,950
escape analysis and they can like get

00:37:10,130 --> 00:37:15,310
rid of short-term allocations much more

00:37:12,950 --> 00:37:21,580
efficiently I hope to try it out soon

00:37:15,310 --> 00:37:21,580

YouTube URL: https://www.youtube.com/watch?v=y7QfAWIun2k


