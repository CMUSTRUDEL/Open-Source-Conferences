Title: The Promise of Event Driven Programming with Fast Data by Duncan DeVore
Publication date: 2018-09-20
Playlist: Scala Days Berlin 2018
Description: 
	This video was recorded at Scala Days Berlin 2018
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

More information and the abstract can be found here:
https://eu.scaladays.org/lect-6945-the-promise-of-event-driven-programming-with-fast-data-....html
Captions: 
	00:00:04,730 --> 00:00:08,519
well good afternoon everyone are you

00:00:06,960 --> 00:00:12,059
having a good time here at Scoville days

00:00:08,519 --> 00:00:13,709
Berlin yep good good yeah I love Berlin

00:00:12,059 --> 00:00:15,900
it's a lot of fun the European Scala

00:00:13,709 --> 00:00:18,240
days are there's a great vibe about them

00:00:15,900 --> 00:00:21,480
so it's quite an honor and a joy to be

00:00:18,240 --> 00:00:24,689
here I'm gonna talk about something

00:00:21,480 --> 00:00:27,359
today around the idea of Micra services

00:00:24,689 --> 00:00:31,289
and in conjunction with the notion of

00:00:27,359 --> 00:00:33,150
fast data and we'll talk about what I

00:00:31,289 --> 00:00:35,430
mean by that and what micro services

00:00:33,150 --> 00:00:38,100
aren't fast data are two kind of level

00:00:35,430 --> 00:00:40,710
set ourselves and then after we do that

00:00:38,100 --> 00:00:43,890
we're going to take a look at a design

00:00:40,710 --> 00:00:46,290
for a production system that would be

00:00:43,890 --> 00:00:50,060
implementing these things and what it

00:00:46,290 --> 00:00:53,880
might look like so a little bit about me

00:00:50,060 --> 00:00:57,510
I started out many years ago as a VP of

00:00:53,880 --> 00:00:59,250
Engineering and I liked typesafe so much

00:00:57,510 --> 00:01:02,160
that I left that position and joined

00:00:59,250 --> 00:01:04,379
them as a senior software engineer I was

00:01:02,160 --> 00:01:09,780
on the insider monitoring team for two

00:01:04,379 --> 00:01:12,570
years and now I am systems engineer and

00:01:09,780 --> 00:01:15,570
I work still in it with engineering but

00:01:12,570 --> 00:01:17,340
also with our clients to designing and

00:01:15,570 --> 00:01:21,859
helping them understand how to build

00:01:17,340 --> 00:01:24,569
really large robust distributed systems

00:01:21,859 --> 00:01:27,210
so I've been building these systems for

00:01:24,569 --> 00:01:29,299
about 10 years and it's been delightful

00:01:27,210 --> 00:01:31,679
and horrible all at the same time

00:01:29,299 --> 00:01:34,020
there's a lot of crazy things going on

00:01:31,679 --> 00:01:35,999
but when I ran into it about 12 years

00:01:34,020 --> 00:01:38,340
ago I realized the design or the

00:01:35,999 --> 00:01:40,920
monolithic style that I was used to was

00:01:38,340 --> 00:01:42,479
not going to work I was in the energy

00:01:40,920 --> 00:01:45,569
industry and the volume of data that we

00:01:42,479 --> 00:01:49,319
were using was enormous so that led me

00:01:45,569 --> 00:01:51,270
down this path and took the opportunity

00:01:49,319 --> 00:01:53,369
with some of my friends Sean Walsh and

00:01:51,270 --> 00:01:56,340
Brian Hanafy to read up write a book

00:01:53,369 --> 00:01:58,770
about it you know using the reactive

00:01:56,340 --> 00:02:01,139
notion it's kind of a sister book to

00:01:58,770 --> 00:02:04,859
roland Coons and Jamie Alan's and

00:02:01,139 --> 00:02:07,139
Brian's book there's is more design

00:02:04,859 --> 00:02:12,120
pattern based ours is more real-world

00:02:07,139 --> 00:02:16,620
implementation and that's my Twitter and

00:02:12,120 --> 00:02:19,410
github accounts so

00:02:16,620 --> 00:02:20,910
you know light bends anybody not heard

00:02:19,410 --> 00:02:24,630
of light Bend

00:02:20,910 --> 00:02:28,320
we're kind of the people behind scala

00:02:24,630 --> 00:02:31,620
akka play legume and what we call our

00:02:28,320 --> 00:02:33,600
fast data platform and one of the things

00:02:31,620 --> 00:02:37,020
that started this entire process was

00:02:33,600 --> 00:02:39,990
this whole idea behind a reactive and

00:02:37,020 --> 00:02:42,000
how can we build systems or business

00:02:39,990 --> 00:02:44,760
systems and not just business systems

00:02:42,000 --> 00:02:46,920
but systems that would be able to stay

00:02:44,760 --> 00:02:49,830
up and run because the demand that

00:02:46,920 --> 00:02:52,050
customers want or 100% uptime page's the

00:02:49,830 --> 00:02:55,650
load and under a second you know if for

00:02:52,050 --> 00:02:58,110
everything so the idea of reactive is

00:02:55,650 --> 00:03:00,810
ready to respond to an input or stimulus

00:02:58,110 --> 00:03:03,270
and then of course we have the reactive

00:03:00,810 --> 00:03:05,370
manifesto which was kind of like a

00:03:03,270 --> 00:03:08,700
superset of all this it's a very high

00:03:05,370 --> 00:03:10,410
level abstraction to think about and it

00:03:08,700 --> 00:03:14,010
doesn't necessarily have to apply to

00:03:10,410 --> 00:03:15,720
just you know JVM or or Scala and a cat

00:03:14,010 --> 00:03:18,810
style applications it can apply to other

00:03:15,720 --> 00:03:22,590
things as well and to date it has over

00:03:18,810 --> 00:03:24,570
20,000 signatures so this diagram I

00:03:22,590 --> 00:03:27,180
think is really really really important

00:03:24,570 --> 00:03:28,800
because it kind of gives you and we've

00:03:27,180 --> 00:03:30,450
all seen it but I think one of the

00:03:28,800 --> 00:03:31,709
things that we missed sometimes or at

00:03:30,450 --> 00:03:33,720
least I missed for a while was the

00:03:31,709 --> 00:03:35,910
arrows right the arrows are very

00:03:33,720 --> 00:03:37,709
significant so at the top you have

00:03:35,910 --> 00:03:40,110
responsiveness we all know what that is

00:03:37,709 --> 00:03:42,000
we have to respond it doesn't matter

00:03:40,110 --> 00:03:45,239
what's going on the customer wants a

00:03:42,000 --> 00:03:46,980
response in order to facilitate that we

00:03:45,239 --> 00:03:48,989
have to be elastic we have to be able to

00:03:46,980 --> 00:03:50,880
scale in and out and up and down and we

00:03:48,989 --> 00:03:53,459
have to be resilient we have to

00:03:50,880 --> 00:03:55,800
self-heal so you'll notice that the

00:03:53,459 --> 00:03:59,519
arrows between resiliency and elasticity

00:03:55,800 --> 00:04:01,170
are bi-directional so in order to be

00:03:59,519 --> 00:04:03,360
elastic sometimes we have to do

00:04:01,170 --> 00:04:05,190
something that is resilient and in order

00:04:03,360 --> 00:04:07,230
to become resilient sometimes we have to

00:04:05,190 --> 00:04:09,260
do something that's elastic so one of

00:04:07,230 --> 00:04:11,940
the ways we can be resilient is to

00:04:09,260 --> 00:04:14,820
expand horizontally or scale

00:04:11,940 --> 00:04:16,830
horizontally and ultimately all this

00:04:14,820 --> 00:04:19,590
stuff is driven by something called a

00:04:16,830 --> 00:04:22,109
message driven architecture and that

00:04:19,590 --> 00:04:24,900
applies directly to how we're going to

00:04:22,109 --> 00:04:26,490
define microservices and then you'll see

00:04:24,900 --> 00:04:29,460
the two pillars elasticity and

00:04:26,490 --> 00:04:35,400
resilience support responsiveness and

00:04:29,460 --> 00:04:38,960
Driven responds supports them all so a

00:04:35,400 --> 00:04:42,930
little bit about us we have open source

00:04:38,960 --> 00:04:45,120
offerings play Accola gyum etc those are

00:04:42,930 --> 00:04:47,849
our core open source offerings I'm sure

00:04:45,120 --> 00:04:50,449
many of you are used to them Scala is

00:04:47,849 --> 00:04:53,069
also one and we have these different

00:04:50,449 --> 00:04:54,599
concepts that we have and embedded into

00:04:53,069 --> 00:04:57,870
something that we call our reactive

00:04:54,599 --> 00:05:00,210
platform or which contains not only our

00:04:57,870 --> 00:05:02,509
open source but also our commercial

00:05:00,210 --> 00:05:05,610
offerings so things like monitoring

00:05:02,509 --> 00:05:09,990
telemetry gathering insights split-brain

00:05:05,610 --> 00:05:13,199
resolver for clusters etc something new

00:05:09,990 --> 00:05:15,990
that we've been working on and is kind

00:05:13,199 --> 00:05:18,570
of related to our talk today a big chunk

00:05:15,990 --> 00:05:20,820
of it is this idea behind what we call

00:05:18,570 --> 00:05:23,580
our fast data platform and essentially

00:05:20,820 --> 00:05:26,699
the idea is is when you're integrating

00:05:23,580 --> 00:05:28,800
things like services or micro services

00:05:26,699 --> 00:05:30,780
and you want to take advantage of things

00:05:28,800 --> 00:05:33,090
like streaming data it's a rather

00:05:30,780 --> 00:05:34,680
complex setup how do you do it where do

00:05:33,090 --> 00:05:37,530
you do it and and that's going to be the

00:05:34,680 --> 00:05:40,110
core of our talk today but in this

00:05:37,530 --> 00:05:41,669
particular product that we have we

00:05:40,110 --> 00:05:43,590
integrate all that stuff that you see on

00:05:41,669 --> 00:05:45,830
the screen we're integrating other stuff

00:05:43,590 --> 00:05:48,690
as well we provide support for it etc

00:05:45,830 --> 00:05:52,169
and this is kind of like a future of

00:05:48,690 --> 00:05:57,419
where we see general application design

00:05:52,169 --> 00:06:00,090
heading ok enough of that we are going

00:05:57,419 --> 00:06:01,830
to talk about several topics and I'm

00:06:00,090 --> 00:06:04,070
going to walk through a discussion about

00:06:01,830 --> 00:06:06,659
each one of these so one obviously is

00:06:04,070 --> 00:06:09,599
microservices another one is called

00:06:06,659 --> 00:06:13,039
promis theory which is core to or we

00:06:09,599 --> 00:06:18,810
believe is core two microservice design

00:06:13,039 --> 00:06:22,349
event sourcing crud right relational

00:06:18,810 --> 00:06:24,330
models relational state models fast data

00:06:22,349 --> 00:06:26,180
in and of itself and one that I'm

00:06:24,330 --> 00:06:30,840
particularly fond of feedback control

00:06:26,180 --> 00:06:33,780
feedback control is an emerging pattern

00:06:30,840 --> 00:06:37,289
and technology and software design that

00:06:33,780 --> 00:06:39,810
really stems from regular mechanical

00:06:37,289 --> 00:06:41,880
design and so forth but it's an

00:06:39,810 --> 00:06:42,870
interesting topic in software design as

00:06:41,880 --> 00:06:46,050
we'll see

00:06:42,870 --> 00:06:48,330
so first of all microservices you know

00:06:46,050 --> 00:06:51,060
everybody has a different definition for

00:06:48,330 --> 00:06:53,479
them one of the common definitions is

00:06:51,060 --> 00:06:56,310
this the idea that you're building

00:06:53,479 --> 00:07:00,240
systems that are going to join together

00:06:56,310 --> 00:07:03,479
in some fashion to represent a a context

00:07:00,240 --> 00:07:04,949
for an application and these systems one

00:07:03,479 --> 00:07:07,320
of the advantages to doing it this way

00:07:04,949 --> 00:07:09,120
is you can have multiple teams that

00:07:07,320 --> 00:07:10,949
could be separated physically they can

00:07:09,120 --> 00:07:13,620
design develop and manage and deploy

00:07:10,949 --> 00:07:15,060
their applications independent of one

00:07:13,620 --> 00:07:16,950
another and I think that's a great

00:07:15,060 --> 00:07:20,750
definition but I think there's a better

00:07:16,950 --> 00:07:23,820
definition and it's this one a system of

00:07:20,750 --> 00:07:26,520
autonomous collaborative system Arda

00:07:23,820 --> 00:07:28,550
services services I don't know me the

00:07:26,520 --> 00:07:31,169
Greek word it essentially means

00:07:28,550 --> 00:07:32,639
self-governing so the idea is is when

00:07:31,169 --> 00:07:34,530
you're designing a system you're

00:07:32,639 --> 00:07:37,080
micro-service you want it to be

00:07:34,530 --> 00:07:41,940
self-governing ie it stands on its own

00:07:37,080 --> 00:07:43,770
regardless of feedback or whatever's

00:07:41,940 --> 00:07:46,320
going on and around it and this is one

00:07:43,770 --> 00:07:48,180
of the key components behind reactive so

00:07:46,320 --> 00:07:51,810
some of the key concepts we'll talk

00:07:48,180 --> 00:07:54,210
about this next but is think in promises

00:07:51,810 --> 00:07:58,320
inside your design as opposed to

00:07:54,210 --> 00:08:01,110
obligations another one is keep your

00:07:58,320 --> 00:08:03,750
services small hence the name micro who

00:08:01,110 --> 00:08:05,610
here likes functional programming right

00:08:03,750 --> 00:08:06,599
why don't we like it because it's it's

00:08:05,610 --> 00:08:08,849
pretty straightforward it's

00:08:06,599 --> 00:08:10,740
mathematically if you put the same input

00:08:08,849 --> 00:08:12,840
you will always get the same output it

00:08:10,740 --> 00:08:14,250
does one thing I've seen people write

00:08:12,840 --> 00:08:16,860
functional code that does like six

00:08:14,250 --> 00:08:18,450
things and it they use you know strange

00:08:16,860 --> 00:08:21,930
symbols that nobody can read except for

00:08:18,450 --> 00:08:23,430
them and the point is is that it's not

00:08:21,930 --> 00:08:25,410
functional because it's doing six things

00:08:23,430 --> 00:08:27,479
within its alright so you keep it small

00:08:25,410 --> 00:08:30,539
the same thing with micro services try

00:08:27,479 --> 00:08:32,099
to keep them as small as possible one of

00:08:30,539 --> 00:08:34,380
the ways to think about micro services

00:08:32,099 --> 00:08:37,709
is from a business perspective if two

00:08:34,380 --> 00:08:39,959
business concepts exist and are

00:08:37,709 --> 00:08:41,849
inexorably tied together in other words

00:08:39,959 --> 00:08:44,850
if one is down the other one is useless

00:08:41,849 --> 00:08:48,150
then those two are probably involved in

00:08:44,850 --> 00:08:51,690
a single micro service right and so I

00:08:48,150 --> 00:08:53,190
would encourage you to to when you

00:08:51,690 --> 00:08:55,200
design your micro services to think

00:08:53,190 --> 00:08:56,690
about things like that as well obviously

00:08:55,200 --> 00:08:59,360
cluster your

00:08:56,690 --> 00:09:01,670
services for resilience so you have one

00:08:59,360 --> 00:09:03,590
micro servers say it's a search engine

00:09:01,670 --> 00:09:05,630
or whatever and you can have multiple

00:09:03,590 --> 00:09:08,270
instances running cluster for resilience

00:09:05,630 --> 00:09:13,010
across different regions or what have

00:09:08,270 --> 00:09:15,140
you and the other thing that I often

00:09:13,010 --> 00:09:17,090
find is things like consistency or

00:09:15,140 --> 00:09:18,290
eventual consistency how long is it

00:09:17,090 --> 00:09:21,380
going to take for me to get that update

00:09:18,290 --> 00:09:24,770
and load times are determined by your

00:09:21,380 --> 00:09:26,600
SLA not the engineer right so when

00:09:24,770 --> 00:09:28,400
people ask me that question I say well

00:09:26,600 --> 00:09:30,680
what do you want what is the business

00:09:28,400 --> 00:09:32,390
expect you know some things can be

00:09:30,680 --> 00:09:33,980
eventually consistent in a minute or two

00:09:32,390 --> 00:09:38,540
other things have to be eventually

00:09:33,980 --> 00:09:40,670
consistent in milliseconds so that's you

00:09:38,540 --> 00:09:44,360
know philosophically that's how that

00:09:40,670 --> 00:09:47,060
stuff gets defined and do things like

00:09:44,360 --> 00:09:49,070
use polyglot persistence we're a strong

00:09:47,060 --> 00:09:49,640
believer and using the right tools for

00:09:49,070 --> 00:09:52,610
the right job

00:09:49,640 --> 00:09:54,770
so one micro service might use a no

00:09:52,610 --> 00:09:56,630
sequel database another micro service

00:09:54,770 --> 00:10:00,800
might use a relational database because

00:09:56,630 --> 00:10:02,660
it needs strong consistency etc we or I

00:10:00,800 --> 00:10:04,970
any ways was kind of predisposed to

00:10:02,660 --> 00:10:06,860
let's have one database that's clustered

00:10:04,970 --> 00:10:08,870
and everybody talks to it and that's

00:10:06,860 --> 00:10:11,240
really not the best model even though it

00:10:08,870 --> 00:10:14,570
works relatively well it is a single

00:10:11,240 --> 00:10:17,330
point of failure so in designing micro

00:10:14,570 --> 00:10:22,490
services and looking at this idea of

00:10:17,330 --> 00:10:25,880
micro services being independent not

00:10:22,490 --> 00:10:28,160
relying on one another standing on their

00:10:25,880 --> 00:10:30,470
own in the in the event of failure we

00:10:28,160 --> 00:10:31,910
realize a couple things and this right

00:10:30,470 --> 00:10:34,190
here I think is one of the most

00:10:31,910 --> 00:10:36,890
important things when you move into

00:10:34,190 --> 00:10:39,460
distributed computing and the end the

00:10:36,890 --> 00:10:43,220
idea is regardless of the storage medium

00:10:39,460 --> 00:10:46,190
our view of state is always of the past

00:10:43,220 --> 00:10:48,500
so this is true with human beings it's

00:10:46,190 --> 00:10:50,510
true with this systems when I receive a

00:10:48,500 --> 00:10:54,200
piece of information and I update my

00:10:50,510 --> 00:10:57,110
state internally that is a historical

00:10:54,200 --> 00:10:59,780
current state as far as I'm concerned

00:10:57,110 --> 00:11:01,460
it's my reality but something external

00:10:59,780 --> 00:11:03,680
to me may have changed and I just

00:11:01,460 --> 00:11:06,440
haven't received the information yet and

00:11:03,680 --> 00:11:08,300
that becomes very important to

00:11:06,440 --> 00:11:09,960
understand when you get into complex

00:11:08,300 --> 00:11:12,270
systems with

00:11:09,960 --> 00:11:13,790
time series data or bitemporal time

00:11:12,270 --> 00:11:17,520
series data where you have multiple

00:11:13,790 --> 00:11:19,560
points for the same point in time this

00:11:17,520 --> 00:11:20,340
this becomes incredibly important to

00:11:19,560 --> 00:11:21,990
understand

00:11:20,340 --> 00:11:25,560
so you're basically dealing with a

00:11:21,990 --> 00:11:27,630
sliding window where now is in the

00:11:25,560 --> 00:11:29,490
middle depending on how far you go back

00:11:27,630 --> 00:11:31,770
it could be minutes days weeks whatever

00:11:29,490 --> 00:11:34,440
that's all historical data and going

00:11:31,770 --> 00:11:36,120
forward is all predictive data and so as

00:11:34,440 --> 00:11:38,400
a reading comes in whatever it may be

00:11:36,120 --> 00:11:41,279
you're going to update the current

00:11:38,400 --> 00:11:43,560
reading and it'll change from predictive

00:11:41,279 --> 00:11:45,510
to now but you may also get a reading

00:11:43,560 --> 00:11:47,250
two minutes later or maybe an hour later

00:11:45,510 --> 00:11:49,350
for that same point in time that you

00:11:47,250 --> 00:11:52,320
have to go back and update that so these

00:11:49,350 --> 00:11:53,820
types of data structures can be complex

00:11:52,320 --> 00:11:57,210
and and it's very important to

00:11:53,820 --> 00:11:59,010
understand these ideas so inside data

00:11:57,210 --> 00:12:00,510
that's the data inside your microservice

00:11:59,010 --> 00:12:04,589
that's your current present that's your

00:12:00,510 --> 00:12:07,640
reality that's what you know outside

00:12:04,589 --> 00:12:09,690
data that you're going to receive is

00:12:07,640 --> 00:12:12,360
historical once you receive it and

00:12:09,690 --> 00:12:14,820
process it it is now historical right

00:12:12,360 --> 00:12:17,640
you don't know in that other service if

00:12:14,820 --> 00:12:19,980
that data has changed and that's a very

00:12:17,640 --> 00:12:22,710
important idea to you know kind of

00:12:19,980 --> 00:12:26,160
wrestle with and then when you ask a

00:12:22,710 --> 00:12:27,900
question or you you pull or push or not

00:12:26,160 --> 00:12:30,540
push but pull from another service or

00:12:27,900 --> 00:12:33,000
another service pushes to you then you

00:12:30,540 --> 00:12:34,200
that is your hope for the future right

00:12:33,000 --> 00:12:36,000
because you may not get it in

00:12:34,200 --> 00:12:38,700
distributed system because of latency

00:12:36,000 --> 00:12:41,060
and so forth and then the last thing

00:12:38,700 --> 00:12:45,300
that we would say as a result of these

00:12:41,060 --> 00:12:48,870
three first bullets we say hey own your

00:12:45,300 --> 00:12:51,060
own data okay so what I mean by that is

00:12:48,870 --> 00:12:52,530
this this design here on the Left we

00:12:51,060 --> 00:12:54,000
have a bunch of Micra services they

00:12:52,530 --> 00:12:56,640
could be running independently on their

00:12:54,000 --> 00:12:59,100
own JVMs etc however they're all talking

00:12:56,640 --> 00:13:01,770
to a single database if that database

00:12:59,100 --> 00:13:04,200
begins to experience problems or

00:13:01,770 --> 00:13:06,930
difficulties then that's going to affect

00:13:04,200 --> 00:13:09,630
every the entire application right every

00:13:06,930 --> 00:13:12,060
service that you have so a better design

00:13:09,630 --> 00:13:14,400
is design on the right

00:13:12,060 --> 00:13:16,709
where each micro-service owns its own

00:13:14,400 --> 00:13:18,870
data and the appropriate persistence

00:13:16,709 --> 00:13:21,510
store that makes the most sense for it

00:13:18,870 --> 00:13:23,350
so we have a payment database we have a

00:13:21,510 --> 00:13:25,420
search cache we have a

00:13:23,350 --> 00:13:27,400
database now one of the things that this

00:13:25,420 --> 00:13:29,920
implement are in furs is you're going to

00:13:27,400 --> 00:13:31,630
have duplicate data right it just is

00:13:29,920 --> 00:13:35,980
what it is we have duplicate data in our

00:13:31,630 --> 00:13:37,690
life you know we file tax returns and we

00:13:35,980 --> 00:13:39,520
determine what the government owes us

00:13:37,690 --> 00:13:42,310
and then we find out that we actually

00:13:39,520 --> 00:13:44,050
owe them money right so you know it is a

00:13:42,310 --> 00:13:45,670
an eventually consistent model

00:13:44,050 --> 00:13:48,190
everything that we do is eventually

00:13:45,670 --> 00:13:50,980
consistent yet in many ways we have a

00:13:48,190 --> 00:13:53,440
tendency to try to force some type of

00:13:50,980 --> 00:13:56,590
strong consistency and these types of

00:13:53,440 --> 00:13:59,830
systems and it just doesn't work so one

00:13:56,590 --> 00:14:01,980
of the ways to I think embrace this idea

00:13:59,830 --> 00:14:05,050
or this philosophy behind reactive

00:14:01,980 --> 00:14:07,480
something that we've been talking about

00:14:05,050 --> 00:14:10,800
is the idea of promise theory and

00:14:07,480 --> 00:14:13,000
promise theory is the notion that

00:14:10,800 --> 00:14:14,920
essentially you are going to declare

00:14:13,000 --> 00:14:18,160
your intent to the outside world what

00:14:14,920 --> 00:14:21,100
your purpose is and as a result you will

00:14:18,160 --> 00:14:22,710
in increase the recipients certainty

00:14:21,100 --> 00:14:25,450
about your come

00:14:22,710 --> 00:14:27,490
your claim and that claim could be

00:14:25,450 --> 00:14:31,000
related to past present or future so the

00:14:27,490 --> 00:14:33,330
idea is I am NOT going to tie my

00:14:31,000 --> 00:14:36,310
behavior to someone else's performance

00:14:33,330 --> 00:14:38,830
that's an obligation if I have

00:14:36,310 --> 00:14:40,600
microservice a and I need something from

00:14:38,830 --> 00:14:43,780
like a service a in order to do my job

00:14:40,600 --> 00:14:47,680
in microservice B that's a code smell I

00:14:43,780 --> 00:14:51,340
have a problem okay now as time goes on

00:14:47,680 --> 00:14:54,130
if microservice a doesn't work my delta

00:14:51,340 --> 00:14:56,710
of error of what reality is will

00:14:54,130 --> 00:15:00,030
increase and so microservice a comes

00:14:56,710 --> 00:15:02,830
back online but I should be able to

00:15:00,030 --> 00:15:04,480
operate without impedance because

00:15:02,830 --> 00:15:07,390
microservice a isn't working for some

00:15:04,480 --> 00:15:10,960
reason so I'm going to promise behavior

00:15:07,390 --> 00:15:14,920
I'm not going to oblige someone else to

00:15:10,960 --> 00:15:16,780
perform for me and then if there's

00:15:14,920 --> 00:15:18,730
something that I expect or something

00:15:16,780 --> 00:15:21,250
that I'm asking and I don't get it my

00:15:18,730 --> 00:15:23,560
hey my behavior has promised that I will

00:15:21,250 --> 00:15:25,120
work and so therefore I have an in some

00:15:23,560 --> 00:15:29,380
other way I have to take care of it a

00:15:25,120 --> 00:15:33,700
back-up plan or what have you so some of

00:15:29,380 --> 00:15:34,950
the key concepts behind this is as I had

00:15:33,700 --> 00:15:37,329
mentioned thinking promises not

00:15:34,950 --> 00:15:39,489
obligations autonomy

00:15:37,329 --> 00:15:41,649
self-governance makes information local

00:15:39,489 --> 00:15:43,660
you can't self-govern unless you have

00:15:41,649 --> 00:15:45,040
all the information that you need if you

00:15:43,660 --> 00:15:47,170
need to rely on someone else for

00:15:45,040 --> 00:15:50,889
information then you've now given up

00:15:47,170 --> 00:15:52,989
part of your governance and as a result

00:15:50,889 --> 00:15:57,779
it leads to a greater certainty and

00:15:52,989 --> 00:15:57,779
stability for your system okay

00:15:59,100 --> 00:16:03,819
autonomous services or services based on

00:16:01,959 --> 00:16:05,920
promise Theory can only promise their

00:16:03,819 --> 00:16:07,449
own behavior that's where they draw the

00:16:05,920 --> 00:16:09,670
line they're responsible for their own

00:16:07,449 --> 00:16:12,910
behavior and actions so when you build a

00:16:09,670 --> 00:16:15,220
system that is obligated you diverge

00:16:12,910 --> 00:16:17,709
into an unpredictable outcome from the

00:16:15,220 --> 00:16:19,959
beginning you have a pretty defined

00:16:17,709 --> 00:16:21,639
beginning but you have no idea if it's

00:16:19,959 --> 00:16:24,189
gonna happen or not because you don't

00:16:21,639 --> 00:16:27,220
have control over the data or control

00:16:24,189 --> 00:16:30,069
over something so you diverge into a

00:16:27,220 --> 00:16:32,049
decreased certainty of whether it's

00:16:30,069 --> 00:16:33,429
going to work whereas with promises you

00:16:32,049 --> 00:16:36,069
kind of start with an unpredictable

00:16:33,429 --> 00:16:37,389
beginning yeah I state what I'm gonna do

00:16:36,069 --> 00:16:39,009
I'm not quite sure how it's going to

00:16:37,389 --> 00:16:41,170
work out but it will work out because I

00:16:39,009 --> 00:16:42,730
promise it will and that leads me to

00:16:41,170 --> 00:16:45,129
something that gives me increased

00:16:42,730 --> 00:16:48,879
certainty so these are ideas when you're

00:16:45,129 --> 00:16:50,889
building systems to think about if you

00:16:48,879 --> 00:16:54,189
want your system to be successful when I

00:16:50,889 --> 00:16:57,009
built our big system at Veridian for two

00:16:54,189 --> 00:16:58,689
years and never crashed a single time it

00:16:57,009 --> 00:17:02,230
was 132 JVMs

00:16:58,689 --> 00:17:04,389
and I just stood back and and was amazed

00:17:02,230 --> 00:17:07,510
because I build a lot of systems and and

00:17:04,389 --> 00:17:09,850
you know you have problems but we built

00:17:07,510 --> 00:17:12,159
everything isolated bulkheaded I'm sure

00:17:09,850 --> 00:17:14,799
you've heard all the terms and it works

00:17:12,159 --> 00:17:18,339
very very well one of the things that

00:17:14,799 --> 00:17:21,459
helps with this is event sourcing right

00:17:18,339 --> 00:17:22,899
so we've heard of it before I'm sure

00:17:21,459 --> 00:17:25,000
Martin Fowler has a pretty good

00:17:22,899 --> 00:17:28,539
definition essentially you're going to

00:17:25,000 --> 00:17:30,010
get in events or commands really you're

00:17:28,539 --> 00:17:31,389
gonna process that command and you're

00:17:30,010 --> 00:17:33,820
gonna turn it into one or more events

00:17:31,389 --> 00:17:36,429
and then that event is going to be

00:17:33,820 --> 00:17:40,120
stored and it essentially gives you an

00:17:36,429 --> 00:17:43,179
audit record of behavior right as a

00:17:40,120 --> 00:17:45,549
result we can adjust the state of our

00:17:43,179 --> 00:17:48,130
application retroactively Lee not only

00:17:45,549 --> 00:17:49,870
that we can go back and look at little

00:17:48,130 --> 00:17:51,330
time segments and we'll talk about

00:17:49,870 --> 00:17:53,399
streaming

00:17:51,330 --> 00:17:55,590
in many ways it gives you kind of a

00:17:53,399 --> 00:17:57,539
streaming environment where you can take

00:17:55,590 --> 00:17:59,659
you can set up synthetic boundaries

00:17:57,539 --> 00:18:03,419
temporal boundaries within a particular

00:17:59,659 --> 00:18:07,080
sequence of events and run them and see

00:18:03,419 --> 00:18:09,120
what happens this is very common when I

00:18:07,080 --> 00:18:11,309
was in the industry an energy industry

00:18:09,120 --> 00:18:14,820
this was a common thing that we did all

00:18:11,309 --> 00:18:17,220
the time so some nice things about it is

00:18:14,820 --> 00:18:19,710
your storage system now becomes additive

00:18:17,220 --> 00:18:22,679
which means it's very easy to shard and

00:18:19,710 --> 00:18:24,480
there's generally a single key right so

00:18:22,679 --> 00:18:26,220
you're going to use a hash and

00:18:24,480 --> 00:18:31,020
distribute your data across your

00:18:26,220 --> 00:18:33,029
clustered store the nice thing about

00:18:31,020 --> 00:18:35,010
that is these these architectures

00:18:33,029 --> 00:18:39,600
distribute very well as opposed to

00:18:35,010 --> 00:18:42,000
having some complex compound key there's

00:18:39,600 --> 00:18:43,409
a lot less locks to deal with you have a

00:18:42,000 --> 00:18:45,510
tendency to store current state in

00:18:43,409 --> 00:18:47,100
memory with these models anyway so you

00:18:45,510 --> 00:18:48,960
don't have to hit a disk generally if

00:18:47,100 --> 00:18:53,970
somebody asks you know what is your

00:18:48,960 --> 00:18:56,039
current state also as I had mentioned in

00:18:53,970 --> 00:18:59,419
an event store there's generally one key

00:18:56,039 --> 00:19:04,799
for an event which could represent a

00:18:59,419 --> 00:19:08,490
significant amount of data and criteria

00:19:04,799 --> 00:19:12,330
or behavior is tracked from the

00:19:08,490 --> 00:19:14,640
inception of the event stream so I'll

00:19:12,330 --> 00:19:16,590
talk about crud here in a minute and one

00:19:14,640 --> 00:19:18,690
of the challenges behind it but it kind

00:19:16,590 --> 00:19:20,880
of gives you this full view so the the

00:19:18,690 --> 00:19:24,179
granularity of your event model is going

00:19:20,880 --> 00:19:26,700
to give you if it's real granular you're

00:19:24,179 --> 00:19:29,360
gonna have more control over analysis if

00:19:26,700 --> 00:19:31,700
it's if it's not very granular then

00:19:29,360 --> 00:19:35,039
you're not going to have as much control

00:19:31,700 --> 00:19:38,429
and the other thing is you can ask

00:19:35,039 --> 00:19:40,710
questions as the previous bullet from

00:19:38,429 --> 00:19:42,570
origin so you don't have to worry about

00:19:40,710 --> 00:19:45,510
I implemented a new feature to track

00:19:42,570 --> 00:19:47,880
whether I deleted socks or not right

00:19:45,510 --> 00:19:51,059
it's just an event delete and you can

00:19:47,880 --> 00:19:52,860
track that from the beginning and that

00:19:51,059 --> 00:19:55,380
leads to one of the greatest business

00:19:52,860 --> 00:19:57,600
values you can answer questions not ask

00:19:55,380 --> 00:19:59,730
and the extent of questions that you can

00:19:57,600 --> 00:20:03,049
answer is directly related to the

00:19:59,730 --> 00:20:03,049
granularity of your event model

00:20:03,260 --> 00:20:08,179
it's a natural audit log that was huge

00:20:05,450 --> 00:20:09,860
for me at in the energy industry when we

00:20:08,179 --> 00:20:10,850
worked with different energy companies

00:20:09,860 --> 00:20:13,340
and we worked with the government

00:20:10,850 --> 00:20:14,960
everything had to be audited they looked

00:20:13,340 --> 00:20:18,260
at our design they're like okay you got

00:20:14,960 --> 00:20:20,179
everything audited out of the box and so

00:20:18,260 --> 00:20:23,389
this is your canonical example right a

00:20:20,179 --> 00:20:26,299
ledger more mature business models use

00:20:23,389 --> 00:20:28,070
event sourcing in a lot of cases you

00:20:26,299 --> 00:20:29,389
know obviously accounting has been

00:20:28,070 --> 00:20:32,380
around for a long long time

00:20:29,389 --> 00:20:36,080
and this represents debits and credits

00:20:32,380 --> 00:20:38,450
sequentially stored as events and you're

00:20:36,080 --> 00:20:43,130
able to derive what your current balance

00:20:38,450 --> 00:20:44,570
is Soak right something we're all very

00:20:43,130 --> 00:20:48,350
familiar with create read update and

00:20:44,570 --> 00:20:52,760
delete they're actually events - they're

00:20:48,350 --> 00:20:54,370
just not very granular and the the four

00:20:52,760 --> 00:20:57,610
different functions that we have in

00:20:54,370 --> 00:21:01,250
storing data primarily in relational

00:20:57,610 --> 00:21:03,019
structures what I really mean though is

00:21:01,250 --> 00:21:06,919
I'm talking about the notion of a

00:21:03,019 --> 00:21:09,529
relational currentstate model so when

00:21:06,919 --> 00:21:11,090
you have a relational database and I

00:21:09,529 --> 00:21:14,120
like relational theory I think it's

00:21:11,090 --> 00:21:16,519
really neat but we typically or

00:21:14,120 --> 00:21:19,039
generally store things as current state

00:21:16,519 --> 00:21:22,820
models and I'll explain in a diagram

00:21:19,039 --> 00:21:25,100
what I mean in a minute before that

00:21:22,820 --> 00:21:26,600
though some of the things in crud is

00:21:25,100 --> 00:21:29,470
essentially you have this idea of

00:21:26,600 --> 00:21:32,000
representing change between two points

00:21:29,470 --> 00:21:34,279
and that's basically referred to as a

00:21:32,000 --> 00:21:35,659
Delta in the energy industry we have

00:21:34,279 --> 00:21:37,700
something called a SCADA system and the

00:21:35,659 --> 00:21:40,820
SCADA system does something similar to

00:21:37,700 --> 00:21:42,260
this but it does capture all the events

00:21:40,820 --> 00:21:45,169
in sequence what it does for

00:21:42,260 --> 00:21:47,029
optimization is if the previous reading

00:21:45,169 --> 00:21:49,100
is the same as the current reading it

00:21:47,029 --> 00:21:51,200
doesn't store the current reading so the

00:21:49,100 --> 00:21:52,460
gap where there's no reading stored it's

00:21:51,200 --> 00:21:54,559
assumed that it's the value of the

00:21:52,460 --> 00:21:56,690
previous previous reading until that

00:21:54,559 --> 00:22:02,389
reading changes then it'll store that so

00:21:56,690 --> 00:22:05,269
it's a very efficient model these deltas

00:22:02,389 --> 00:22:08,559
are implied inside the tool that you're

00:22:05,269 --> 00:22:12,379
using such as an object you know an ORM

00:22:08,559 --> 00:22:13,970
and they manage all this for you and

00:22:12,379 --> 00:22:15,139
essentially they're going to save the

00:22:13,970 --> 00:22:17,040
state they're going to calculate the

00:22:15,139 --> 00:22:18,240
differences to get the Delta

00:22:17,040 --> 00:22:21,930
then they're gonna update the backing

00:22:18,240 --> 00:22:25,310
model and flush that to the database as

00:22:21,930 --> 00:22:30,360
a result in this current state model

00:22:25,310 --> 00:22:32,790
there is a side effect or something that

00:22:30,360 --> 00:22:35,480
occurs which is is unfortunate and that

00:22:32,790 --> 00:22:37,890
is essentially rather than tracking

00:22:35,480 --> 00:22:40,500
behavior or intent which is what we're

00:22:37,890 --> 00:22:42,900
really interested in in our applications

00:22:40,500 --> 00:22:44,730
yeah we're just storing data we're

00:22:42,900 --> 00:22:47,940
updating the current state of data so we

00:22:44,730 --> 00:22:50,910
lose a significant amount of money or

00:22:47,940 --> 00:22:53,070
not money but but data about our

00:22:50,910 --> 00:22:55,770
customers or whatever our system is

00:22:53,070 --> 00:22:59,310
doing and auditing almost always is

00:22:55,770 --> 00:23:00,870
explicit so if you are going to write

00:22:59,310 --> 00:23:02,250
something to an order line table and you

00:23:00,870 --> 00:23:03,420
need to audit it you generally have to

00:23:02,250 --> 00:23:05,420
implement it you either turn it on a

00:23:03,420 --> 00:23:10,260
database you write a trigger you

00:23:05,420 --> 00:23:12,900
implement it and your Ord so this is our

00:23:10,260 --> 00:23:15,390
relational model we have an ordered line

00:23:12,900 --> 00:23:18,270
table a shipping table and an order

00:23:15,390 --> 00:23:21,000
table and right now we have three items

00:23:18,270 --> 00:23:24,630
if a customer were to delete something

00:23:21,000 --> 00:23:26,610
before that order ships then we would

00:23:24,630 --> 00:23:28,980
only have two items and we would have no

00:23:26,610 --> 00:23:31,290
notion that an item was deleted unless

00:23:28,980 --> 00:23:33,990
we had implemented auditing in an event

00:23:31,290 --> 00:23:35,910
source model that's automatic right

00:23:33,990 --> 00:23:38,700
because it's just a sequences and append

00:23:35,910 --> 00:23:41,820
of an event and of course shipping

00:23:38,700 --> 00:23:44,460
information we're third normal form all

00:23:41,820 --> 00:23:48,090
right so the next topic fast data what

00:23:44,460 --> 00:23:50,780
is it it's an interesting concept Dean

00:23:48,090 --> 00:23:53,850
or fast data guru this is his definition

00:23:50,780 --> 00:23:56,370
data is processed as it arrives leading

00:23:53,850 --> 00:24:01,140
to a systems call fast data systems that

00:23:56,370 --> 00:24:03,930
ingest and process continuously data and

00:24:01,140 --> 00:24:08,370
that can be done potentially for an

00:24:03,930 --> 00:24:10,350
infinite amount of time so your fast

00:24:08,370 --> 00:24:12,060
data systems have a tendency to look

00:24:10,350 --> 00:24:13,590
something like this and one of the

00:24:12,060 --> 00:24:17,850
things are really good at is this notion

00:24:13,590 --> 00:24:20,190
of of anomaly detection which is fairly

00:24:17,850 --> 00:24:21,660
important so fraud detection this have

00:24:20,190 --> 00:24:24,390
you ever got a call from your credit

00:24:21,660 --> 00:24:26,100
card company or a text that says hey we

00:24:24,390 --> 00:24:27,510
suspect something is done wrong well

00:24:26,100 --> 00:24:30,269
that's because they're processing the

00:24:27,510 --> 00:24:33,779
data and something tripped

00:24:30,269 --> 00:24:37,499
and anomaly and as a result I mean

00:24:33,779 --> 00:24:39,119
something tripped a violation and as a

00:24:37,499 --> 00:24:41,159
result they're going to text you or what

00:24:39,119 --> 00:24:43,889
have you and so we have this idea that

00:24:41,159 --> 00:24:45,389
the issue though is a lot of times this

00:24:43,889 --> 00:24:47,969
notion of this type of system is

00:24:45,389 --> 00:24:51,450
completely separate from our regular

00:24:47,969 --> 00:24:54,119
micro service design and or even worse

00:24:51,450 --> 00:24:56,190
we take a platform like this like

00:24:54,119 --> 00:24:58,499
Catherine or SPARC and we say well I can

00:24:56,190 --> 00:25:00,239
do everything right it can store data

00:24:58,499 --> 00:25:01,769
for an unlimited amount of time I can

00:25:00,239 --> 00:25:03,779
write sequel queries the access on my

00:25:01,769 --> 00:25:07,049
data and we start to use a tool like

00:25:03,779 --> 00:25:08,639
that to build our application

00:25:07,049 --> 00:25:11,969
you know what would normally be a

00:25:08,639 --> 00:25:16,919
microcircuits to problems because of

00:25:11,969 --> 00:25:20,909
performance etc so some of the the ideas

00:25:16,919 --> 00:25:21,450
behind fast data is the boundaries all

00:25:20,909 --> 00:25:23,249
right

00:25:21,450 --> 00:25:25,469
whether you're processing real time data

00:25:23,249 --> 00:25:28,109
or near real-time data what those

00:25:25,469 --> 00:25:29,999
temporal boundaries are or how often it

00:25:28,109 --> 00:25:34,019
needs to be processed again are defined

00:25:29,999 --> 00:25:36,479
by the SLA I think the most important

00:25:34,019 --> 00:25:40,109
thing is that we have a tendency to

00:25:36,479 --> 00:25:42,929
overlook is about streaming data is that

00:25:40,109 --> 00:25:45,839
the boundaries for a chunk of data

00:25:42,929 --> 00:25:48,029
inside a streaming model they're

00:25:45,839 --> 00:25:49,799
synthetic you set them there is no

00:25:48,029 --> 00:25:51,209
beginning and end if you're doing a

00:25:49,799 --> 00:25:53,070
batch there's a beginning and end you

00:25:51,209 --> 00:25:54,419
have a chunk of data or if you're doing

00:25:53,070 --> 00:25:56,009
you know like traditional streaming of

00:25:54,419 --> 00:25:58,320
an image to a web page yeah there's a

00:25:56,009 --> 00:26:00,119
beginning and end but in this type of

00:25:58,320 --> 00:26:02,519
scenario where you're you're constantly

00:26:00,119 --> 00:26:03,839
getting data in you have to think a

00:26:02,519 --> 00:26:06,479
little bit different so you're going to

00:26:03,839 --> 00:26:08,549
get a piece of the puzzle right at a

00:26:06,479 --> 00:26:10,349
moment in time and you're gonna have to

00:26:08,549 --> 00:26:12,809
reason about that you're not going to

00:26:10,349 --> 00:26:14,700
have all the information and as you get

00:26:12,809 --> 00:26:17,070
more and more information the picture

00:26:14,700 --> 00:26:19,019
becomes more and more clear that's a

00:26:17,070 --> 00:26:21,029
totally different way to think not

00:26:19,019 --> 00:26:22,859
something that I think or at least I

00:26:21,029 --> 00:26:24,989
wasn't used to it and it has

00:26:22,859 --> 00:26:27,239
implications on how you're designing

00:26:24,989 --> 00:26:29,399
your system as I had mentioned they can

00:26:27,239 --> 00:26:32,249
become they could be potentially

00:26:29,399 --> 00:26:34,639
infinite and also when you're dealing

00:26:32,249 --> 00:26:38,639
with streams you have this new notion of

00:26:34,639 --> 00:26:41,399
you know this continuous flow so there's

00:26:38,639 --> 00:26:43,679
typically maybe a sink and a source

00:26:41,399 --> 00:26:44,160
somewhere and so back pressure should be

00:26:43,679 --> 00:26:48,150
part

00:26:44,160 --> 00:26:50,850
of the streaming library that you use in

00:26:48,150 --> 00:26:53,490
the streaming world reality is based on

00:26:50,850 --> 00:26:55,680
snapshots right you're going to take a

00:26:53,490 --> 00:26:57,810
snapshot of data you have a synthetic

00:26:55,680 --> 00:26:59,940
beginning synthetic end and that's gonna

00:26:57,810 --> 00:27:01,980
be your reality that reality may be

00:26:59,940 --> 00:27:03,780
partial and in fact most cases it will

00:27:01,980 --> 00:27:08,730
be partial but you have to know how to

00:27:03,780 --> 00:27:10,680
deal with that and then to understand it

00:27:08,730 --> 00:27:13,860
we you know many of the streaming

00:27:10,680 --> 00:27:16,500
libraries are now providing more sequel

00:27:13,860 --> 00:27:19,830
like commands so doing things like group

00:27:16,500 --> 00:27:21,660
by and join in in the context of

00:27:19,830 --> 00:27:25,680
streaming data are very popular

00:27:21,660 --> 00:27:27,510
operations all right so the last beast

00:27:25,680 --> 00:27:30,900
or puzzle was feedback control and this

00:27:27,510 --> 00:27:34,070
is the one most interested in feedback

00:27:30,900 --> 00:27:37,590
control so the idea is I want to

00:27:34,070 --> 00:27:41,190
constantly compare my systems actual

00:27:37,590 --> 00:27:43,800
behavior to its desired behavior and as

00:27:41,190 --> 00:27:46,110
a result of that comparison if the

00:27:43,800 --> 00:27:48,600
actual behavior differs from what the

00:27:46,110 --> 00:27:50,880
desired behavior is then I'm going to

00:27:48,600 --> 00:27:53,400
take some corrective action and I'm

00:27:50,880 --> 00:27:57,420
going to apply that corrective action to

00:27:53,400 --> 00:28:00,510
my system and counteract it the result

00:27:57,420 --> 00:28:02,670
of that is going to be a deviation right

00:28:00,510 --> 00:28:06,450
and that deviation is then going to

00:28:02,670 --> 00:28:09,030
replace the deviation that occurred from

00:28:06,450 --> 00:28:14,850
this difference and behavior between

00:28:09,030 --> 00:28:17,280
desired and actual okay we do this all

00:28:14,850 --> 00:28:20,730
the time in an exercise right we do an

00:28:17,280 --> 00:28:22,860
exercise this is the behavior that I'm

00:28:20,730 --> 00:28:24,540
getting from it this is the desired

00:28:22,860 --> 00:28:26,160
behavior so therefore I'm going to

00:28:24,540 --> 00:28:28,020
modify my exercise and do something

00:28:26,160 --> 00:28:29,490
different again all the things that

00:28:28,020 --> 00:28:32,490
we're talking about are what we do

00:28:29,490 --> 00:28:34,200
subconsciously every single day yet when

00:28:32,490 --> 00:28:36,930
we go to build systems computer systems

00:28:34,200 --> 00:28:41,190
we have a tendency to not do these types

00:28:36,930 --> 00:28:42,990
of things so another nice thing about

00:28:41,190 --> 00:28:44,610
feedback controls it can be very

00:28:42,990 --> 00:28:46,680
isolated it doesn't have to understand

00:28:44,610 --> 00:28:49,290
the entire system again functional

00:28:46,680 --> 00:28:50,700
programming right it does one thing same

00:28:49,290 --> 00:28:52,260
thing with feedback control feedback

00:28:50,700 --> 00:28:55,050
control could be very simple like your

00:28:52,260 --> 00:28:57,490
thermostat in your house you know it you

00:28:55,050 --> 00:28:59,920
set a temperature to 78 degrees it read

00:28:57,490 --> 00:29:02,140
the temperature it is not 78 degrees at

00:28:59,920 --> 00:29:04,450
74 degrees so internally it kicks the

00:29:02,140 --> 00:29:06,309
temperature up so it can catch up then

00:29:04,450 --> 00:29:08,260
it goes up to 75 degrees and it says

00:29:06,309 --> 00:29:12,070
okay too hot turn it tune it down to 73

00:29:08,260 --> 00:29:15,880
it drops to 74 then it's the set point

00:29:12,070 --> 00:29:18,270
is is equalized basically the idea

00:29:15,880 --> 00:29:21,280
feedback control is very very common in

00:29:18,270 --> 00:29:23,530
physical systems bringing it to the

00:29:21,280 --> 00:29:25,750
software world though is is I think

00:29:23,530 --> 00:29:27,400
paramount to things like machine

00:29:25,750 --> 00:29:29,230
learning and how we're going to reason

00:29:27,400 --> 00:29:31,950
about behavior but it is a little bit

00:29:29,230 --> 00:29:34,630
more challenging than a physical system

00:29:31,950 --> 00:29:37,000
essentially with feedback control you're

00:29:34,630 --> 00:29:38,380
giving the idea of I want to be able to

00:29:37,000 --> 00:29:42,250
nudge the system in a particular

00:29:38,380 --> 00:29:47,650
direction to more aligned actual with

00:29:42,250 --> 00:29:50,170
desired they're self-correcting right

00:29:47,650 --> 00:29:52,870
and so the idea is is you have an

00:29:50,170 --> 00:29:55,650
external disturbance and the feedback

00:29:52,870 --> 00:29:58,270
control or the feedback loop and control

00:29:55,650 --> 00:30:00,940
process is going to recognize that

00:29:58,270 --> 00:30:05,070
external disturbance and it's going to

00:30:00,940 --> 00:30:07,059
essentially take a corrective action and

00:30:05,070 --> 00:30:10,059
one of the things that you have to be

00:30:07,059 --> 00:30:11,710
careful of is not to overcorrect right

00:30:10,059 --> 00:30:14,020
so this is where data scientists come in

00:30:11,710 --> 00:30:15,700
or engineers that really understand the

00:30:14,020 --> 00:30:17,470
process that they're doing if you

00:30:15,700 --> 00:30:19,510
overcorrect all kinds of things can

00:30:17,470 --> 00:30:20,890
happen you could you know if you

00:30:19,510 --> 00:30:22,870
overcorrect an energy you can blow

00:30:20,890 --> 00:30:25,020
transformer you know there's there's a

00:30:22,870 --> 00:30:28,030
lot of things so you have to understand

00:30:25,020 --> 00:30:30,010
ultimately what is your acceptable delta

00:30:28,030 --> 00:30:35,530
of error in the context that you're

00:30:30,010 --> 00:30:38,050
you're controlling and essentially as I

00:30:35,530 --> 00:30:41,890
had mentioned they replace the deviation

00:30:38,050 --> 00:30:43,750
with another so in computer science

00:30:41,890 --> 00:30:47,050
however it's a little bit different

00:30:43,750 --> 00:30:48,760
because the systems are less constrained

00:30:47,050 --> 00:30:51,640
with a thermostat it's very

00:30:48,760 --> 00:30:52,929
black-and-white very well defined it's

00:30:51,640 --> 00:30:56,110
the same thing with like building a

00:30:52,929 --> 00:30:58,210
bridge right in those types of

00:30:56,110 --> 00:31:01,360
engineering projects they're constants

00:30:58,210 --> 00:31:04,480
the river weather or the materials etc

00:31:01,360 --> 00:31:07,419
in software that's not the case right it

00:31:04,480 --> 00:31:10,300
evolves it changes as we're designing a

00:31:07,419 --> 00:31:11,410
system so we need to recognize that as

00:31:10,300 --> 00:31:15,340
we begin to

00:31:11,410 --> 00:31:17,200
implement these types of things another

00:31:15,340 --> 00:31:19,810
thing is is when you're doing this part

00:31:17,200 --> 00:31:21,850
of this is going to be anomaly detection

00:31:19,810 --> 00:31:23,950
so the idea behind anomaly detection is

00:31:21,850 --> 00:31:26,260
a lot of times what we'll do is we'll

00:31:23,950 --> 00:31:28,390
set thresholds right if so for example

00:31:26,260 --> 00:31:30,880
let's take an actor in akka and say if

00:31:28,390 --> 00:31:32,110
the actors mailbox exceeds 500 messages

00:31:30,880 --> 00:31:34,330
throw an alert

00:31:32,110 --> 00:31:37,540
well the question I would ask you is

00:31:34,330 --> 00:31:40,000
okay is that it really a problem though

00:31:37,540 --> 00:31:42,130
is you know if the actor mailbox does

00:31:40,000 --> 00:31:44,890
exceed 500 messages for some systems

00:31:42,130 --> 00:31:47,410
that may be perfectly fine right for

00:31:44,890 --> 00:31:49,510
other systems that may not so thresholds

00:31:47,410 --> 00:31:52,930
are kind of misleading right they can

00:31:49,510 --> 00:31:54,730
cause allergic and other things that can

00:31:52,930 --> 00:31:55,030
be problematic so we have to be careful

00:31:54,730 --> 00:31:57,670
of that

00:31:55,030 --> 00:31:59,620
so anomaly detection is hey I have a

00:31:57,670 --> 00:32:02,320
whole bunch of data here all of it looks

00:31:59,620 --> 00:32:04,090
strange let's apply some type of

00:32:02,320 --> 00:32:06,220
corrective algorithm to it we're

00:32:04,090 --> 00:32:09,790
smoothing algorithm to it and as a

00:32:06,220 --> 00:32:12,250
result we can essentially figure out

00:32:09,790 --> 00:32:14,380
what the correct value should be or it

00:32:12,250 --> 00:32:16,030
could be an outlier right in our

00:32:14,380 --> 00:32:17,830
industry we would get readings that

00:32:16,030 --> 00:32:20,830
would jump that would spike and that

00:32:17,830 --> 00:32:22,780
could cost a customer a lot of money so

00:32:20,830 --> 00:32:25,510
we applied an anomaly detection

00:32:22,780 --> 00:32:29,380
algorithm to it and in most cases it was

00:32:25,510 --> 00:32:31,540
just a erroneous point and we would

00:32:29,380 --> 00:32:33,370
adjust it in line and that's where

00:32:31,540 --> 00:32:35,230
smoothing algorithms comes and come in

00:32:33,370 --> 00:32:37,240
right as you receive your data you're

00:32:35,230 --> 00:32:38,860
going to take a look at it again in that

00:32:37,240 --> 00:32:40,330
temporal window the synthetic boundaries

00:32:38,860 --> 00:32:42,220
and you're going to make some decisions

00:32:40,330 --> 00:32:46,110
about it on how you're gonna process it

00:32:42,220 --> 00:32:48,550
what you're gonna do and so forth and

00:32:46,110 --> 00:32:49,720
then obviously this is one of the most

00:32:48,550 --> 00:32:51,190
important things and this is you're

00:32:49,720 --> 00:32:53,500
going to train your model whatever your

00:32:51,190 --> 00:32:55,990
model is that's implementing feedback

00:32:53,500 --> 00:32:58,030
control or machine learning you need to

00:32:55,990 --> 00:33:00,180
train it with historical data and as it

00:32:58,030 --> 00:33:02,290
trains it will get better and better and

00:33:00,180 --> 00:33:04,510
or at least in theory it'll get better

00:33:02,290 --> 00:33:07,870
and provide better results so your

00:33:04,510 --> 00:33:09,520
typical canonical example here's is this

00:33:07,870 --> 00:33:11,470
you have a disturbance it comes into the

00:33:09,520 --> 00:33:14,140
system as an input the system has a

00:33:11,470 --> 00:33:15,780
status sends it to basically a measuring

00:33:14,140 --> 00:33:19,810
element that is going to implement

00:33:15,780 --> 00:33:21,490
feedback it is then going to access a

00:33:19,810 --> 00:33:23,830
set point and it's either going to

00:33:21,490 --> 00:33:24,909
increase it or decrease it whatever that

00:33:23,830 --> 00:33:26,649
means and you're

00:33:24,909 --> 00:33:28,539
it doesn't necessarily have to be you

00:33:26,649 --> 00:33:30,729
know add one to an integer decrease

00:33:28,539 --> 00:33:33,039
whatever and as a result it's going to

00:33:30,729 --> 00:33:36,399
generate this error the the controller

00:33:33,039 --> 00:33:37,690
is then going to take create a command

00:33:36,399 --> 00:33:39,879
and send it back to what we're calling

00:33:37,690 --> 00:33:42,369
an effector and the effector is going to

00:33:39,879 --> 00:33:44,070
implement control that feedback is then

00:33:42,369 --> 00:33:46,149
going to go all the way back up to our

00:33:44,070 --> 00:33:48,129
entrance and they're going to do it

00:33:46,149 --> 00:33:51,639
again and again and again right and

00:33:48,129 --> 00:33:56,109
that's the notion of this dnews is a

00:33:51,639 --> 00:33:59,289
great point in his in his book about

00:33:56,109 --> 00:34:02,499
this so all right I want to run him

00:33:59,289 --> 00:34:04,210
behind a little bit so I'm gonna go a

00:34:02,499 --> 00:34:07,239
little bit faster we have all these

00:34:04,210 --> 00:34:08,200
things that we're talking about so now

00:34:07,239 --> 00:34:10,179
we're going to talk about building

00:34:08,200 --> 00:34:15,760
systems you know now that we have this

00:34:10,179 --> 00:34:18,339
information how do we do it so you'll

00:34:15,760 --> 00:34:20,559
recall in microservices we talked about

00:34:18,339 --> 00:34:22,659
these different aspects that become

00:34:20,559 --> 00:34:24,849
important right we're familiar with them

00:34:22,659 --> 00:34:28,899
on your own data polyglot persistence

00:34:24,849 --> 00:34:30,940
etc so we start with a micro service so

00:34:28,899 --> 00:34:32,169
this would be our first design so we

00:34:30,940 --> 00:34:36,849
have these micro services they have

00:34:32,169 --> 00:34:42,399
their own data okay now we have this

00:34:36,849 --> 00:34:44,260
notion of when do we use crud so if you

00:34:42,399 --> 00:34:45,789
care about history use event sourcing if

00:34:44,260 --> 00:34:46,809
you care about auditing event sourcing

00:34:45,789 --> 00:34:48,909
if you're going to charge your data

00:34:46,809 --> 00:34:51,909
event sourcing if you need strong

00:34:48,909 --> 00:34:53,799
consistency right crud may be a good

00:34:51,909 --> 00:34:55,659
version or a relational model

00:34:53,799 --> 00:34:57,309
if you don't care about current state

00:34:55,659 --> 00:34:59,980
and I've seen many applications that

00:34:57,309 --> 00:35:02,650
really don't care then cruds a perfect

00:34:59,980 --> 00:35:05,650
example as long as you know availability

00:35:02,650 --> 00:35:07,750
isn't a big issue so now we've

00:35:05,650 --> 00:35:09,700
implemented these ideas so in our search

00:35:07,750 --> 00:35:13,450
cache that's a crud based as we're just

00:35:09,700 --> 00:35:15,940
updating it and our other two micro

00:35:13,450 --> 00:35:20,319
services we have a payment database with

00:35:15,940 --> 00:35:26,319
no sequel and event sourcing etc so now

00:35:20,319 --> 00:35:28,690
fast data right again we went over these

00:35:26,319 --> 00:35:30,339
things the one thing about fast data is

00:35:28,690 --> 00:35:31,930
we need to understand it's based on

00:35:30,339 --> 00:35:34,180
streaming we have these synthetic

00:35:31,930 --> 00:35:36,910
boundaries and fast data should be

00:35:34,180 --> 00:35:38,560
orthogonal to our micro service and I'll

00:35:36,910 --> 00:35:40,720
show you that in this design not

00:35:38,560 --> 00:35:42,580
say that you can't have streaming within

00:35:40,720 --> 00:35:45,370
a microservice and you can call the fast

00:35:42,580 --> 00:35:49,300
data but as a result one of the ways

00:35:45,370 --> 00:35:53,410
that we project this or say you should

00:35:49,300 --> 00:35:54,760
do it is by making an orthogonal and one

00:35:53,410 --> 00:35:56,740
thing you should remember fast data

00:35:54,760 --> 00:35:58,180
isn't necessarily a historical

00:35:56,740 --> 00:36:02,140
persistence store that's not what it was

00:35:58,180 --> 00:36:05,110
designed for so I like to think of it

00:36:02,140 --> 00:36:07,450
this way our data backplane is our fast

00:36:05,110 --> 00:36:09,040
data can be caf-co whatever around that

00:36:07,450 --> 00:36:11,470
we have all these little micro services

00:36:09,040 --> 00:36:13,510
that are self-governing and have their

00:36:11,470 --> 00:36:16,360
own rule they all pull from this central

00:36:13,510 --> 00:36:17,650
stream and then they modify the data or

00:36:16,360 --> 00:36:21,970
do whatever they got to do to it to make

00:36:17,650 --> 00:36:23,980
it up liable to their context so in a

00:36:21,970 --> 00:36:26,110
design we would have something like this

00:36:23,980 --> 00:36:30,190
we have our micro services and we have

00:36:26,110 --> 00:36:34,450
our data backplane so now we're going to

00:36:30,190 --> 00:36:36,790
implement feedback control again we

00:36:34,450 --> 00:36:38,380
talked about the different aspects of

00:36:36,790 --> 00:36:43,410
feedback control and how we want to do

00:36:38,380 --> 00:36:46,000
that everybody recognize this

00:36:43,410 --> 00:36:48,160
supervisory control in akka that's

00:36:46,000 --> 00:36:50,740
feedback control right you have

00:36:48,160 --> 00:36:56,970
implemented push based feedback control

00:36:50,740 --> 00:37:00,040
push from the child to the supervisor in

00:36:56,970 --> 00:37:01,570
bigger applications we can pull it off

00:37:00,040 --> 00:37:04,510
to the right and we can implement it

00:37:01,570 --> 00:37:07,210
through things like an ER off wrap rapid

00:37:04,510 --> 00:37:10,390
miner and spark machine learning

00:37:07,210 --> 00:37:16,170
libraries etc alright so we're almost

00:37:10,390 --> 00:37:20,800
there but we're missing one thing and

00:37:16,170 --> 00:37:22,960
what we're missing is insight and this

00:37:20,800 --> 00:37:25,570
is kind of like a whole system right we

00:37:22,960 --> 00:37:27,670
have our fast data we have our data

00:37:25,570 --> 00:37:30,490
backplane we have our persistence

00:37:27,670 --> 00:37:32,380
storage we have mechanisms for capturing

00:37:30,490 --> 00:37:35,710
data in regards to insight elastic

00:37:32,380 --> 00:37:40,690
search etc we can we can visualize it

00:37:35,710 --> 00:37:43,030
with Griffin ax or Cabana etc and now we

00:37:40,690 --> 00:37:44,170
have not only a system that's reactive

00:37:43,030 --> 00:37:47,920
with all these components we've been

00:37:44,170 --> 00:37:51,660
talking about but it also is monitored

00:37:47,920 --> 00:37:51,660
you have insight into what's going on

00:37:52,650 --> 00:37:58,960
so in insight you know instrumentation

00:37:56,800 --> 00:38:01,030
is a logo should be a local local

00:37:58,960 --> 00:38:03,970
aggregation of events which then gets

00:38:01,030 --> 00:38:07,390
passed out into some collector collect

00:38:03,970 --> 00:38:09,730
the collection can be again a local

00:38:07,390 --> 00:38:11,740
registry for optimization and then

00:38:09,730 --> 00:38:16,720
aggregation you can dump it into a calf

00:38:11,740 --> 00:38:19,180
cluster and the last couple notions are

00:38:16,720 --> 00:38:20,800
storage you can use as we saw there

00:38:19,180 --> 00:38:23,020
elastic search for events

00:38:20,800 --> 00:38:25,840
Kassandra time series database for

00:38:23,020 --> 00:38:30,060
metrics spark for analytics Rieman for

00:38:25,840 --> 00:38:33,730
notifications and Griffin and Cabana for

00:38:30,060 --> 00:38:34,870
exploration and and data discovery so if

00:38:33,730 --> 00:38:38,440
you're familiar with this tools

00:38:34,870 --> 00:38:41,140
okay so that's it I want to open up for

00:38:38,440 --> 00:38:47,070
questions for anybody or you can come up

00:38:41,140 --> 00:38:47,070

YouTube URL: https://www.youtube.com/watch?v=q_tyCiK1gds


