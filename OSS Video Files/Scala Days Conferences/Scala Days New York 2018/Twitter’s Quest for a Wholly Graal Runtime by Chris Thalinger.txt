Title: Twitter’s Quest for a Wholly Graal Runtime by Chris Thalinger
Publication date: 2018-09-21
Playlist: Scala Days New York 2018
Description: 
	This video was recorded at Scala Days New York 2018
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

More information and the abstract can be found here:
https://na.scaladays.org/schedule/twitters-quest-for-a-wholly-graal-runtime
Captions: 
	00:00:03,540 --> 00:00:09,120
twitter has a small vm team so we have

00:00:07,200 --> 00:00:11,219
we are about four core people working on

00:00:09,120 --> 00:00:12,540
the JVM we have two other team members

00:00:11,219 --> 00:00:16,380
that are doing slightly different things

00:00:12,540 --> 00:00:19,050
but we have three TC engineers and the

00:00:16,380 --> 00:00:20,820
TC engineers are basically 24/7 busy

00:00:19,050 --> 00:00:22,890
fixing all the chassis issues that are

00:00:20,820 --> 00:00:25,439
that the whole world has rhythm and the

00:00:22,890 --> 00:00:28,259
Stu and then I'm the compiler engineer

00:00:25,439 --> 00:00:29,849
and I do the fun stuff so and then I

00:00:28,259 --> 00:00:31,230
tour the world and tell people about the

00:00:29,849 --> 00:00:34,020
cool things that we've done at Twitter

00:00:31,230 --> 00:00:36,210
and if you're going to tweet about this

00:00:34,020 --> 00:00:38,550
talk please at that hashtag Twitter VM

00:00:36,210 --> 00:00:42,690
teams all of my people at home know that

00:00:38,550 --> 00:00:47,310
was actually here so what's the goal of

00:00:42,690 --> 00:00:48,900
this talk and it is to save money that's

00:00:47,310 --> 00:00:50,970
the goal of this talk so I'm glad you're

00:00:48,900 --> 00:00:55,140
all here I'm going to sell you some

00:00:50,970 --> 00:00:56,579
stuff if you want to no I'm not but I'll

00:00:55,140 --> 00:00:59,010
talk about the money saving part a

00:00:56,579 --> 00:01:01,649
little bit later so I don't know if you

00:00:59,010 --> 00:01:04,670
guys know me my name is Chris Salinger I

00:01:01,649 --> 00:01:09,590
work on champions for a long time now I

00:01:04,670 --> 00:01:13,140
was always a compiler engineer so and I

00:01:09,590 --> 00:01:14,250
see some older faces in here so I at

00:01:13,140 --> 00:01:16,350
this point I'd like to call out people

00:01:14,250 --> 00:01:18,150
I'm not sure if it's worth if it works

00:01:16,350 --> 00:01:20,580
here too because I usually speak of Java

00:01:18,150 --> 00:01:24,840
conferences so who remembers canoe class

00:01:20,580 --> 00:01:26,940
path yeah some people okay like two

00:01:24,840 --> 00:01:30,120
three old people over there so back in

00:01:26,940 --> 00:01:31,440
the day you know when Sun still had Java

00:01:30,120 --> 00:01:32,850
closed tourists it was something called

00:01:31,440 --> 00:01:36,210
canoe class path was an open-source

00:01:32,850 --> 00:01:41,940
implementation by new off the Java class

00:01:36,210 --> 00:01:46,950
libraries he remembers now no new new

00:01:41,940 --> 00:01:49,049
yes yeah Oh exactly

00:01:46,950 --> 00:01:50,549
so back in the day we worked we were

00:01:49,049 --> 00:01:52,470
working all on this stuff and we were

00:01:50,549 --> 00:01:54,270
the Wild West and we tried to liberate

00:01:52,470 --> 00:01:56,939
Java Radin and some they were the bad

00:01:54,270 --> 00:01:58,500
guys and we all met up at FOSDEM in

00:01:56,939 --> 00:02:01,200
Brussels and drank a lot of beer and I

00:01:58,500 --> 00:02:04,770
was a lot of fun and then in 2007 eight

00:02:01,200 --> 00:02:07,470
some open source java finally and then

00:02:04,770 --> 00:02:08,849
they showed up at FOSDEM - and and we

00:02:07,470 --> 00:02:10,319
thought oh yeah you guys are actually

00:02:08,849 --> 00:02:11,639
cool because they bought us beer and you

00:02:10,319 --> 00:02:14,099
know you know how the world works and

00:02:11,639 --> 00:02:15,840
and then a few years later I started to

00:02:14,099 --> 00:02:18,450
work for Sun

00:02:15,840 --> 00:02:19,769
then we've got acquired by Oracle and

00:02:18,450 --> 00:02:23,400
that was always part of the hospital

00:02:19,769 --> 00:02:24,330
compiler team so I was working mostly on

00:02:23,400 --> 00:02:26,340
c2

00:02:24,330 --> 00:02:28,860
a little bit on c1 interpreter stuff as

00:02:26,340 --> 00:02:31,230
well but mostly c2 and then these are

00:02:28,860 --> 00:02:33,180
kind of the three biggest things that

00:02:31,230 --> 00:02:35,819
I've worked on during my time at Sun and

00:02:33,180 --> 00:02:38,819
Oracle was one kazar 292 I was always

00:02:35,819 --> 00:02:40,260
working on the invokedynamic I basically

00:02:38,819 --> 00:02:41,010
wrote all the compiler support for

00:02:40,260 --> 00:02:42,569
invokedynamic

00:02:41,010 --> 00:02:44,459
a little bit of interpreter support

00:02:42,569 --> 00:02:45,870
ported all the stuff to spark and you

00:02:44,459 --> 00:02:48,239
know whatever comes with that

00:02:45,870 --> 00:02:51,120
so John Rosen now we've done this for

00:02:48,239 --> 00:02:52,829
quite a while and then there was a

00:02:51,120 --> 00:02:54,750
problem with the first implementation of

00:02:52,829 --> 00:02:57,450
that and then we had to re-implement a

00:02:54,750 --> 00:03:00,840
lot of stuff and we moved a lot of logic

00:02:57,450 --> 00:03:02,910
from the VM into Java and so I wrote a

00:03:00,840 --> 00:03:06,690
lot of that Java code to if you ever

00:03:02,910 --> 00:03:08,160
heard about lamb the forum's maybe not

00:03:06,690 --> 00:03:13,319
it's like an internal implementation

00:03:08,160 --> 00:03:16,260
detail so if there is an issue of a bug

00:03:13,319 --> 00:03:18,299
you could technically blame me don't do

00:03:16,260 --> 00:03:19,709
that because I think my code was

00:03:18,299 --> 00:03:23,370
perfectly fine of the people who touched

00:03:19,709 --> 00:03:26,190
it after me they broke it okay then we

00:03:23,370 --> 00:03:27,510
were doing chip 243 the Java level JVM

00:03:26,190 --> 00:03:28,829
compiler interface we're going to hear

00:03:27,510 --> 00:03:31,859
about this a little bit later so we

00:03:28,829 --> 00:03:35,489
introduced this we took the interface

00:03:31,859 --> 00:03:38,099
that growl had and basically extracted

00:03:35,489 --> 00:03:40,500
that and made it an official API in a

00:03:38,099 --> 00:03:42,780
way and put that into JDK 9 so that the

00:03:40,500 --> 00:03:45,799
the idea behind it was we put it in the

00:03:42,780 --> 00:03:48,299
official open JDK Oracle JDK

00:03:45,799 --> 00:03:50,400
distribution and then you could just

00:03:48,299 --> 00:03:52,799
grab an external JIT compiler and plug

00:03:50,400 --> 00:03:54,930
it in that's the idea behind it and then

00:03:52,799 --> 00:03:58,560
we also did chap 295 ahead of time

00:03:54,930 --> 00:04:01,049
compilers compilation in JDK 9 and the

00:03:58,560 --> 00:04:03,630
out of time compilation in in open JDK

00:04:01,049 --> 00:04:05,090
users Gras as the coach innovating

00:04:03,630 --> 00:04:08,430
back-end so it's basically a

00:04:05,090 --> 00:04:10,889
command-line tool that loads in class

00:04:08,430 --> 00:04:12,510
files and then sends it over to growl

00:04:10,889 --> 00:04:14,310
and groan composite and then the other

00:04:12,510 --> 00:04:15,840
end you get a shared library out of it

00:04:14,310 --> 00:04:20,130
that's that's pretty much how it works

00:04:15,840 --> 00:04:23,180
and so it's also using JVM CI and now I

00:04:20,130 --> 00:04:24,400
work for Twitter great company love it

00:04:23,180 --> 00:04:27,000
ok

00:04:24,400 --> 00:04:29,650
I'm pretty sure you know what Twitter is

00:04:27,000 --> 00:04:32,050
you know it's a huge distributed system

00:04:29,650 --> 00:04:33,880
obviously we are using micro services

00:04:32,050 --> 00:04:35,650
right so we have to eat serve as a user

00:04:33,880 --> 00:04:37,690
service these are kind of the biggest

00:04:35,650 --> 00:04:39,970
ones we have right it's kind of all

00:04:37,690 --> 00:04:41,620
these four pretty much make Twitter and

00:04:39,970 --> 00:04:46,360
then they're small there are a bunch of

00:04:41,620 --> 00:04:48,040
smaller ones as well so we have many

00:04:46,360 --> 00:04:49,720
many many TV amps per service obviously

00:04:48,040 --> 00:04:51,430
you have thousands of machines running

00:04:49,720 --> 00:04:53,410
thousands of servers and we have

00:04:51,430 --> 00:04:55,570
multiple data centers so it's you know

00:04:53,410 --> 00:04:58,030
it's kind of big it's maybe not as Vegas

00:04:55,570 --> 00:05:02,710
Amazon or Google but you know it has a

00:04:58,030 --> 00:05:04,330
good size and so Twitter in general

00:05:02,710 --> 00:05:06,760
we're doing a lot of open source we love

00:05:04,330 --> 00:05:10,419
open source we also give back so we use

00:05:06,760 --> 00:05:12,910
a lot of open source in our product

00:05:10,419 --> 00:05:14,650
services whatever we do we also give

00:05:12,910 --> 00:05:17,050
back to the community a lot there's this

00:05:14,650 --> 00:05:19,660
github i/o I always forget what it's

00:05:17,050 --> 00:05:22,539
called like there's a Twitter thingy and

00:05:19,660 --> 00:05:23,830
so for us but so everyone knows what

00:05:22,539 --> 00:05:25,900
brawl is right I didn't ask that

00:05:23,830 --> 00:05:29,289
question people Noah crawl is right I

00:05:25,900 --> 00:05:32,590
should say I'm not talking about brawl

00:05:29,289 --> 00:05:34,539
BM okay if you came to hear about brawl

00:05:32,590 --> 00:05:37,660
VM you're in the wrong room I'm not

00:05:34,539 --> 00:05:39,520
talking about growl VM gravy M has more

00:05:37,660 --> 00:05:42,430
technologies in it this I'm talking

00:05:39,520 --> 00:05:45,479
about growl the JIT compiler okay so raw

00:05:42,430 --> 00:05:47,979
VM has basically growl a JIT compiler

00:05:45,479 --> 00:05:49,870
substrate VM and truffle that's kind of

00:05:47,979 --> 00:05:52,720
what gravy emits right but I'm only

00:05:49,870 --> 00:05:55,930
talking about raw the compiler nothing

00:05:52,720 --> 00:05:57,520
else so growl for us since it's open

00:05:55,930 --> 00:06:00,550
source it's a good fit you know we just

00:05:57,520 --> 00:06:02,710
included in our take a and and then we

00:06:00,550 --> 00:06:04,840
run with it and we're also contributing

00:06:02,710 --> 00:06:07,389
back to brawl a little bit so I'll show

00:06:04,840 --> 00:06:11,110
you an example later what we did we have

00:06:07,389 --> 00:06:13,840
our own jdk kinda you know it's it's

00:06:11,110 --> 00:06:17,320
basically a clone of open JDK 8ug yes we

00:06:13,840 --> 00:06:19,449
still run on eight and so we have we

00:06:17,320 --> 00:06:21,880
back ported chapter 43 because I said we

00:06:19,449 --> 00:06:23,979
included in it to nine but we back

00:06:21,880 --> 00:06:26,650
ported it to eight we have a copy of

00:06:23,979 --> 00:06:28,419
Gras which is a one-to-one copy of what

00:06:26,650 --> 00:06:30,940
you can get on github there are no

00:06:28,419 --> 00:06:32,680
changes then we have something that's

00:06:30,940 --> 00:06:34,270
called contrail that will go away pretty

00:06:32,680 --> 00:06:36,430
soon because oracle decided to

00:06:34,270 --> 00:06:38,080
open-source JFR so it's basically the

00:06:36,430 --> 00:06:42,250
same thing as JFR

00:06:38,080 --> 00:06:43,990
and we had CMS improvements I think that

00:06:42,250 --> 00:06:48,759
that's not the case anymore we up

00:06:43,990 --> 00:06:51,699
streamed all this so okay-y Gras in

00:06:48,759 --> 00:06:54,190
general so why would we want to run on

00:06:51,699 --> 00:06:57,669
Gras or why do we want growl to be part

00:06:54,190 --> 00:07:01,659
of OpenJDK so see - do people know what

00:06:57,669 --> 00:07:04,030
situ is okay No

00:07:01,659 --> 00:07:07,000
so see - okay people know what hotspot

00:07:04,030 --> 00:07:08,919
is yes the JVM of openjdk okay so

00:07:07,000 --> 00:07:10,090
hotspot has to cheat compilers you know

00:07:08,919 --> 00:07:13,270
what it compilers are just-in-time

00:07:10,090 --> 00:07:16,389
compilers yes they produce they move to

00:07:13,270 --> 00:07:18,310
take Java bytecode and on the during

00:07:16,389 --> 00:07:19,780
runtime on the fly just-in-time compiler

00:07:18,310 --> 00:07:22,150
to native codes or the application runs

00:07:19,780 --> 00:07:24,130
faster that's a JIT compiler and so hot

00:07:22,150 --> 00:07:26,259
butter has to cheat compilers called C 1

00:07:24,130 --> 00:07:28,330
or client compiler and the other one is

00:07:26,259 --> 00:07:30,159
called C 2 or server compiler you might

00:07:28,330 --> 00:07:31,659
remember the - client their server thing

00:07:30,159 --> 00:07:34,659
it you used 10 years ago

00:07:31,659 --> 00:07:36,250
I mean out of 10 but 5 so that's not

00:07:34,659 --> 00:07:41,169
required anymore but the compilers are

00:07:36,250 --> 00:07:43,840
still there so and C 2 is very old

00:07:41,169 --> 00:07:46,630
already I'm not even sure how old at

00:07:43,840 --> 00:07:49,990
least 10 or 15 years and it's very old

00:07:46,630 --> 00:07:52,719
and very complex so I've worked on C 2

00:07:49,990 --> 00:07:55,419
quite a bit I fixed a lot of bugs the

00:07:52,719 --> 00:07:58,539
learning curve of C 2 is very very steep

00:07:55,419 --> 00:08:00,550
so these days everyone is very impatient

00:07:58,539 --> 00:08:02,259
right you you grab a framework from

00:08:00,550 --> 00:08:04,750
Vietnam and you look at it for a week or

00:08:02,259 --> 00:08:06,819
two and then you think and then you do

00:08:04,750 --> 00:08:09,610
you expect to understand it or after

00:08:06,819 --> 00:08:12,729
month or two maybe I started to work on

00:08:09,610 --> 00:08:14,130
C - and it took me about three to four

00:08:12,729 --> 00:08:18,940
years to fully understand how it works

00:08:14,130 --> 00:08:21,969
okay so we had an issue around the time

00:08:18,940 --> 00:08:23,979
when Oracle acquired some that we lost a

00:08:21,969 --> 00:08:26,710
few people of the hotspot compiler team

00:08:23,979 --> 00:08:28,270
and then we had to hire new people okay

00:08:26,710 --> 00:08:30,219
some of them have now worked on a

00:08:28,270 --> 00:08:32,890
compiler before some did but they've

00:08:30,219 --> 00:08:35,919
never worked with C - before one of the

00:08:32,890 --> 00:08:38,950
problems was that some of them got

00:08:35,919 --> 00:08:40,510
frustrated and then left after you know

00:08:38,950 --> 00:08:42,459
a year and a half or two because they

00:08:40,510 --> 00:08:44,709
realized yeah I mean I don't know the

00:08:42,459 --> 00:08:46,630
exact reasons but I'm just speculating

00:08:44,709 --> 00:08:49,540
they either thought okay I'm stupid I

00:08:46,630 --> 00:08:52,600
don't understand this or

00:08:49,540 --> 00:08:55,510
whatever right so it's a big issue

00:08:52,600 --> 00:08:57,580
especially going forward because the TVM

00:08:55,510 --> 00:08:59,890
in my opinion is not going away anytime

00:08:57,580 --> 00:09:01,870
soon because a lot of the cool new

00:08:59,890 --> 00:09:03,760
languages like Scala and Kotlin they run

00:09:01,870 --> 00:09:05,620
on top of the JVM and leverage to JVM

00:09:03,760 --> 00:09:07,150
because you get scalability and she sees

00:09:05,620 --> 00:09:08,710
and all this stuff for free and the

00:09:07,150 --> 00:09:11,590
performance so it's not going away but

00:09:08,710 --> 00:09:15,850
we need people to understand the JVM

00:09:11,590 --> 00:09:19,900
right so we need to replace situ and so

00:09:15,850 --> 00:09:22,690
in there's also in the last at least

00:09:19,900 --> 00:09:26,260
four years or maybe even five there were

00:09:22,690 --> 00:09:27,940
no major optimizations done in situ yeah

00:09:26,260 --> 00:09:29,800
we there were there were some intrinsic

00:09:27,940 --> 00:09:32,440
work going on and Intel you know until

00:09:29,800 --> 00:09:33,760
is coming out with new AVX and SSE

00:09:32,440 --> 00:09:35,800
instructions wider and wider and wider

00:09:33,760 --> 00:09:38,290
yes we have we have some handwritten

00:09:35,800 --> 00:09:40,650
assembler code intrinsic

00:09:38,290 --> 00:09:42,640
they were added to c2 but there was no

00:09:40,650 --> 00:09:45,010
okay let's you know

00:09:42,640 --> 00:09:46,750
reimplemented scape analysis or inlining

00:09:45,010 --> 00:09:48,460
what that nothing like this happened and

00:09:46,750 --> 00:09:50,740
one of the reasons why this did this

00:09:48,460 --> 00:09:53,230
didn't happen is because it's a complex

00:09:50,740 --> 00:09:55,450
no-one didn't want to touch it it works

00:09:53,230 --> 00:09:58,540
for everyone in the world pretty much so

00:09:55,450 --> 00:10:00,610
it's it's difficult and then in my

00:09:58,540 --> 00:10:03,520
personal opinion see to Rich's end of

00:10:00,610 --> 00:10:07,540
life a long time ago so on the other

00:10:03,520 --> 00:10:09,220
hand you know brawl is already I'm gonna

00:10:07,540 --> 00:10:11,760
even sure how old it is now but it's at

00:10:09,220 --> 00:10:14,830
least five six seven years old I think

00:10:11,760 --> 00:10:17,590
but it from ground up the design is much

00:10:14,830 --> 00:10:19,450
different than C 2 s so the it's a very

00:10:17,590 --> 00:10:21,220
modular design of the built is to make

00:10:19,450 --> 00:10:23,020
sure that you not you're not breaking

00:10:21,220 --> 00:10:24,640
those modular design it makes sure that

00:10:23,020 --> 00:10:27,520
you don't have circular dependencies it

00:10:24,640 --> 00:10:28,810
makes sure that architecture depend no

00:10:27,520 --> 00:10:31,360
the other way around architecture

00:10:28,810 --> 00:10:34,330
independent packages or marches what

00:10:31,360 --> 00:10:35,890
what they call it are not depending on

00:10:34,330 --> 00:10:37,540
architecture dependent stuff you know

00:10:35,890 --> 00:10:39,580
all these things that you don't want you

00:10:37,540 --> 00:10:42,010
don't want this spaghetti code that

00:10:39,580 --> 00:10:44,530
everything touches everything and so

00:10:42,010 --> 00:10:46,510
growl has a very good design in that

00:10:44,530 --> 00:10:48,820
regard and then very very important at

00:10:46,510 --> 00:10:50,500
the bottom it also has a better inlining

00:10:48,820 --> 00:10:53,380
implementation and a better escape

00:10:50,500 --> 00:10:55,180
analysis implementation so I'm not going

00:10:53,380 --> 00:10:56,410
to explain this in detail but we're

00:10:55,180 --> 00:10:58,240
going to talk about this a little bit

00:10:56,410 --> 00:10:59,470
later when we talk about performance

00:10:58,240 --> 00:11:03,190
numbers in graphs

00:10:59,470 --> 00:11:05,500
ok so I started to work for

00:11:03,190 --> 00:11:07,270
Twitter about two years ago and so what

00:11:05,500 --> 00:11:09,460
I'm going to show you is pretty much the

00:11:07,270 --> 00:11:11,260
first year I was at Twitter when we

00:11:09,460 --> 00:11:12,910
started running stuff one of the reasons

00:11:11,260 --> 00:11:17,380
why I left Oracle and went to Twitter is

00:11:12,910 --> 00:11:19,570
I wanted to run use draw in a production

00:11:17,380 --> 00:11:23,260
environment I wanted to see how it works

00:11:19,570 --> 00:11:25,810
if it works right and so we started

00:11:23,260 --> 00:11:26,830
running our services and then these were

00:11:25,810 --> 00:11:28,840
the bugs we found

00:11:26,830 --> 00:11:30,340
okay so I'm going through these a little

00:11:28,840 --> 00:11:33,460
bit if you don't fully understand what's

00:11:30,340 --> 00:11:38,050
going on that's fine so we have this one

00:11:33,460 --> 00:11:40,930
issue where we had like this when you

00:11:38,050 --> 00:11:42,640
when you compile stuff sometimes the JVM

00:11:40,930 --> 00:11:44,770
can't compile methods for some reasons

00:11:42,640 --> 00:11:46,690
and there's in this particular case it

00:11:44,770 --> 00:11:48,820
was not able to do this on-site

00:11:46,690 --> 00:11:50,470
replacement compilation and then the

00:11:48,820 --> 00:11:52,450
output look like compiled skipped or

00:11:50,470 --> 00:11:54,280
czar with locks not supported right and

00:11:52,450 --> 00:11:56,740
then it through an exception because

00:11:54,280 --> 00:11:57,940
scroll is written in Java so you get an

00:11:56,740 --> 00:12:00,250
exception out of it it kind of looks

00:11:57,940 --> 00:12:02,020
like this and you see it as a gnostic

00:12:00,250 --> 00:12:05,140
replacement phase and it's trying to do

00:12:02,020 --> 00:12:07,600
stuff but it can't okay so we discussed

00:12:05,140 --> 00:12:09,670
this we so I saw this in our locks when

00:12:07,600 --> 00:12:14,050
I was turning on print compilation I saw

00:12:09,670 --> 00:12:16,480
this and and so there's a Oracle Labs

00:12:14,050 --> 00:12:19,630
employee Tom we discussed this for a

00:12:16,480 --> 00:12:23,500
little bit and we decided that it's not

00:12:19,630 --> 00:12:25,330
really a big issue because we all of you

00:12:23,500 --> 00:12:27,460
pretty much are running by default into

00:12:25,330 --> 00:12:30,130
your compilation do people know what

00:12:27,460 --> 00:12:31,660
your compilation is kind of I could

00:12:30,130 --> 00:12:35,560
explain it it's not that important for

00:12:31,660 --> 00:12:37,330
this talk but it basically you can you

00:12:35,560 --> 00:12:39,730
compile with c1 first and then later

00:12:37,330 --> 00:12:42,060
with T to to get peak performance so if

00:12:39,730 --> 00:12:45,730
you can't compile with the top level

00:12:42,060 --> 00:12:47,410
with a top-tier compiler c2 or all you

00:12:45,730 --> 00:12:48,730
still have c1 compiled code so you're

00:12:47,410 --> 00:12:50,110
not running interpreted you're still

00:12:48,730 --> 00:12:53,170
running a native code and that's that's

00:12:50,110 --> 00:12:56,380
we that's good enough and in this

00:12:53,170 --> 00:12:58,480
particular case the method was not very

00:12:56,380 --> 00:13:00,040
important you know I got compiled after

00:12:58,480 --> 00:13:02,080
a while it was something that was used

00:13:00,040 --> 00:13:04,330
enough but not feeling the hot path so

00:13:02,080 --> 00:13:07,900
we said okay it's cool doesn't matter

00:13:04,330 --> 00:13:11,320
turns out that completely independently

00:13:07,900 --> 00:13:15,190
and a little bit later this guy fixed it

00:13:11,320 --> 00:13:16,540
so and it was about what a thousand

00:13:15,190 --> 00:13:20,020
lines of new code

00:13:16,540 --> 00:13:22,570
so it's quite a bit and so I'm saying

00:13:20,020 --> 00:13:25,450
technically it's still open and so I

00:13:22,570 --> 00:13:27,070
looked at you know I verified that it

00:13:25,450 --> 00:13:29,020
was actually fixed I was running I was

00:13:27,070 --> 00:13:32,020
running the service again and I was

00:13:29,020 --> 00:13:33,610
seeing these other exceptions the top

00:13:32,020 --> 00:13:36,400
two ones that are saying no on stack

00:13:33,610 --> 00:13:40,120
replacing note generated and so it turns

00:13:36,400 --> 00:13:42,670
out does my mouse cursor does not so it

00:13:40,120 --> 00:13:45,520
turns out as tom says he looked at this

00:13:42,670 --> 00:13:47,050
code and then he says there's a problem

00:13:45,520 --> 00:13:49,060
with the optimizing on static field

00:13:47,050 --> 00:13:51,400
access in the static class initializer

00:13:49,060 --> 00:13:53,290
okay and then he looked a little bit

00:13:51,400 --> 00:13:55,180
deeper into the sea to code and he said

00:13:53,290 --> 00:13:59,050
oh yeah there's a there's some small

00:13:55,180 --> 00:14:01,930
logic nc2 that handles that and that

00:13:59,050 --> 00:14:03,460
little bit of logic in situ parser is is

00:14:01,930 --> 00:14:06,370
this method that's called static field

00:14:03,460 --> 00:14:08,380
okay and seal in it okay so the problem

00:14:06,370 --> 00:14:10,390
is you're compiling your static crashing

00:14:08,380 --> 00:14:12,220
initializer and the static class

00:14:10,390 --> 00:14:14,230
initializer makes sure that you're you

00:14:12,220 --> 00:14:15,700
final fields I initialize but you

00:14:14,230 --> 00:14:17,310
actually meet them when you compile the

00:14:15,700 --> 00:14:20,260
code so it's like a catch-22 situation

00:14:17,310 --> 00:14:22,420
but since you are the compiler you know

00:14:20,260 --> 00:14:26,050
it's fine to X system because you know

00:14:22,420 --> 00:14:27,880
the value okay and then important like

00:14:26,050 --> 00:14:29,740
the last line of the comment says better

00:14:27,880 --> 00:14:31,540
to check now than to be optimized as

00:14:29,740 --> 00:14:33,820
soon as we execute I don't know if you

00:14:31,540 --> 00:14:35,920
know what the optimization is but it's

00:14:33,820 --> 00:14:37,720
basically you run your natively compiled

00:14:35,920 --> 00:14:40,150
code and then something happens that you

00:14:37,720 --> 00:14:43,840
didn't expect and then you fall back to

00:14:40,150 --> 00:14:46,570
interpretation which is bad okay so in

00:14:43,840 --> 00:14:49,330
this case you all know that the static

00:14:46,570 --> 00:14:52,270
class initialize is only run once okay

00:14:49,330 --> 00:14:54,460
usually they're not compiled but in if

00:14:52,270 --> 00:14:58,180
you are going to compile it it means

00:14:54,460 --> 00:15:01,090
it's either very long or it has loops in

00:14:58,180 --> 00:15:03,880
it right so it's kind of important when

00:15:01,090 --> 00:15:05,380
you load a class that this finishes fast

00:15:03,880 --> 00:15:07,870
because the whole system's basically

00:15:05,380 --> 00:15:09,700
waiting for you to load that class so if

00:15:07,870 --> 00:15:11,650
we are going if you're already waiting

00:15:09,700 --> 00:15:13,300
for this class to be loaded and it takes

00:15:11,650 --> 00:15:15,640
a long time and then we have the time to

00:15:13,300 --> 00:15:17,110
actually compile it and then we compile

00:15:15,640 --> 00:15:18,310
it in a way that we immediately be

00:15:17,110 --> 00:15:20,530
optimizing and fall back to the

00:15:18,310 --> 00:15:22,180
interpreter we wasted a lot of time so

00:15:20,530 --> 00:15:26,020
we have to make sure that this works

00:15:22,180 --> 00:15:29,690
good and fine and so the fix was them to

00:15:26,020 --> 00:15:31,760
to add that little piece of C++ logic in

00:15:29,690 --> 00:15:35,200
and you can see it was like 31 lines of

00:15:31,760 --> 00:15:38,720
code so that was fixed that was good

00:15:35,200 --> 00:15:42,200
then we had this one that was actually a

00:15:38,720 --> 00:15:44,660
crash a sec V with this very long fatal

00:15:42,200 --> 00:15:46,850
error message and the important one is

00:15:44,660 --> 00:15:49,850
here where it says long running

00:15:46,850 --> 00:15:51,860
processes couple days so I was running a

00:15:49,850 --> 00:15:55,130
service and after a couple days of

00:15:51,860 --> 00:15:57,520
crashed and I had no idea what the hell

00:15:55,130 --> 00:16:00,050
was going on and then I was looking at

00:15:57,520 --> 00:16:01,520
the stuff that we were doing like on the

00:16:00,050 --> 00:16:03,170
command line with the things we were

00:16:01,520 --> 00:16:04,910
loading and running and passing through

00:16:03,170 --> 00:16:07,580
the JVM it turns out that we're using

00:16:04,910 --> 00:16:10,850
something called heap stir and heap stir

00:16:07,580 --> 00:16:14,600
is an agent that does heat profiling

00:16:10,850 --> 00:16:18,290
okay so agent means instruments bytecode

00:16:14,600 --> 00:16:20,120
and if you if you're profiling if you do

00:16:18,290 --> 00:16:22,070
heap profiling you basically have to

00:16:20,120 --> 00:16:24,920
instrument all the new vehicles when you

00:16:22,070 --> 00:16:26,750
allocate you know memory you you're

00:16:24,920 --> 00:16:31,490
collecting all the types of classes that

00:16:26,750 --> 00:16:32,960
you're you're actually allocating so we

00:16:31,490 --> 00:16:35,090
discussed this a little bit this is all

00:16:32,960 --> 00:16:35,510
like this is a screen screenshots from

00:16:35,090 --> 00:16:37,880
github

00:16:35,510 --> 00:16:39,830
you know issues so you can you know just

00:16:37,880 --> 00:16:42,890
go there and read it all up with what we

00:16:39,830 --> 00:16:46,160
discussed so so duck says well it turns

00:16:42,890 --> 00:16:48,110
out since growl is written in Java right

00:16:46,160 --> 00:16:50,630
and it has something it's called

00:16:48,110 --> 00:16:52,220
snippets I'm not going to explain it too

00:16:50,630 --> 00:16:54,320
much in detail it's something like in

00:16:52,220 --> 00:16:56,800
intrinsic and the compiler handles it in

00:16:54,320 --> 00:17:00,350
a very special way and so there is a

00:16:56,800 --> 00:17:02,630
there's a snippet and for the double

00:17:00,350 --> 00:17:05,030
value off thingy here and it uses double

00:17:02,630 --> 00:17:08,390
dot value off and double dot value off

00:17:05,030 --> 00:17:10,400
doesn't new okay so the agent

00:17:08,390 --> 00:17:12,620
instrumented the bike code that grah

00:17:10,400 --> 00:17:14,240
handled in a very special way but then

00:17:12,620 --> 00:17:16,880
it suddenly changed the bytecode it made

00:17:14,240 --> 00:17:18,530
it bigger and introduce new byte codes

00:17:16,880 --> 00:17:19,940
in there and then the baikin and the

00:17:18,530 --> 00:17:21,860
compiled code didn't match up anymore

00:17:19,940 --> 00:17:24,860
that's where the crash came from and

00:17:21,860 --> 00:17:26,540
then you know tanden said something

00:17:24,860 --> 00:17:28,040
something and then Doug says maybe it's

00:17:26,540 --> 00:17:30,770
time to bite the bullet and parts to buy

00:17:28,040 --> 00:17:34,490
clothes for snippets in a in a special

00:17:30,770 --> 00:17:38,020
way which they did and it added two

00:17:34,490 --> 00:17:38,020
thousand seven hundred lines of code so

00:17:38,320 --> 00:17:43,690
this any deleted four hundred so like

00:17:41,120 --> 00:17:45,920
2500 new lines of code

00:17:43,690 --> 00:17:48,830
this never happened is never showed up

00:17:45,920 --> 00:17:50,630
in internal testing at Oracle but it's

00:17:48,830 --> 00:17:52,910
something that happens in outside in the

00:17:50,630 --> 00:17:55,160
real world like we all use agents for

00:17:52,910 --> 00:17:58,850
stuff and so this was an important part

00:17:55,160 --> 00:18:02,950
to find that because as I said people do

00:17:58,850 --> 00:18:05,660
this all the time good part number three

00:18:02,950 --> 00:18:07,190
so I was I was running some stuff

00:18:05,660 --> 00:18:08,600
probably the tweet service I can't

00:18:07,190 --> 00:18:11,120
remember and then I was looking at the

00:18:08,600 --> 00:18:13,850
logs and every now and then I saw like a

00:18:11,120 --> 00:18:15,980
ton of exceptions you know flying by and

00:18:13,850 --> 00:18:19,100
and I really didn't know where they were

00:18:15,980 --> 00:18:20,570
coming from the the bad thing about and

00:18:19,100 --> 00:18:22,100
you probably know this better than I do

00:18:20,570 --> 00:18:23,870
because I know nothing about micro

00:18:22,100 --> 00:18:25,780
services but the bad thing is if you

00:18:23,870 --> 00:18:27,950
have a micro service architecture and

00:18:25,780 --> 00:18:29,390
something goes wrong you don't even know

00:18:27,950 --> 00:18:31,070
where it's coming from right especially

00:18:29,390 --> 00:18:32,960
if it's a connection exception is it

00:18:31,070 --> 00:18:34,280
yourself is that the guy you're talking

00:18:32,960 --> 00:18:36,550
to or is this the other guy you're

00:18:34,280 --> 00:18:39,320
talking to you don't know and so for me

00:18:36,550 --> 00:18:40,880
I'm not an expert in all this I really

00:18:39,320 --> 00:18:42,530
didn't know what to do at this point to

00:18:40,880 --> 00:18:46,220
figure out where this is coming from and

00:18:42,530 --> 00:18:47,870
so then at one point I think what what

00:18:46,220 --> 00:18:49,850
happened was we were updating from

00:18:47,870 --> 00:18:52,010
Nettie 3 to Nettie for something like

00:18:49,850 --> 00:18:56,270
this I can't remember so I decided to

00:18:52,010 --> 00:18:57,860
run the native 4 test suite and so I was

00:18:56,270 --> 00:18:59,840
running it and then Nettie possible

00:18:57,860 --> 00:19:02,350
failure but ok yeah that's interesting

00:18:59,840 --> 00:19:05,420
maybe we should look into this and so

00:19:02,350 --> 00:19:08,150
that's a very interesting bug so it

00:19:05,420 --> 00:19:10,880
turns out you guys know the reverse

00:19:08,150 --> 00:19:12,440
bites method on the number of classes

00:19:10,880 --> 00:19:14,870
you know short dot reverse bites and

00:19:12,440 --> 00:19:16,970
physical swaps the bites so it turns out

00:19:14,870 --> 00:19:20,090
that was wrong that that got compiled

00:19:16,970 --> 00:19:23,450
wrong and this is done all the time

00:19:20,090 --> 00:19:27,650
right but in this particular case it

00:19:23,450 --> 00:19:29,330
didn't work and then tom says oh it does

00:19:27,650 --> 00:19:32,900
an incorrect canonicalization bla bla

00:19:29,330 --> 00:19:36,890
bla so it turns out the fix was a two

00:19:32,900 --> 00:19:40,220
line fix right it's 68 lines of code

00:19:36,890 --> 00:19:42,710
because Tom added a test case but it was

00:19:40,220 --> 00:19:45,080
it was a two line fix really so very

00:19:42,710 --> 00:19:47,510
very interesting like through testing

00:19:45,080 --> 00:19:48,620
all the years never happened but

00:19:47,510 --> 00:19:52,630
suddenly you know in the real-world

00:19:48,620 --> 00:19:56,000
scenario happened and this I think yes

00:19:52,630 --> 00:19:58,740
these were all the bugs we found

00:19:56,000 --> 00:20:00,330
since then no box and I think the last

00:19:58,740 --> 00:20:03,510
one we fix this directionally like a

00:20:00,330 --> 00:20:05,970
date that September 2016

00:20:03,510 --> 00:20:08,850
okay that's a that's a year and a half

00:20:05,970 --> 00:20:11,070
ago and and since then no issue so these

00:20:08,850 --> 00:20:13,140
were you see that they were kind of you

00:20:11,070 --> 00:20:14,400
know especially the agent one was kind

00:20:13,140 --> 00:20:17,460
of related to stuff that we were doing

00:20:14,400 --> 00:20:20,310
and so on so growl is is a very stable

00:20:17,460 --> 00:20:24,210
compiler to be honest yeah so since then

00:20:20,310 --> 00:20:26,940
we didn't have an issue so then let me

00:20:24,210 --> 00:20:28,920
tell me tell me about one thing I did I

00:20:26,940 --> 00:20:30,570
didn't have a lot of time to actually do

00:20:28,920 --> 00:20:34,950
some work on Grob but one thing we did

00:20:30,570 --> 00:20:37,040
was you know that in jdk 9 we have

00:20:34,950 --> 00:20:38,880
something called compact strings now and

00:20:37,040 --> 00:20:40,170
compact strings the way it was

00:20:38,880 --> 00:20:42,420
implemented it's a little unfortunate

00:20:40,170 --> 00:20:46,800
but it was implemented with handwritten

00:20:42,420 --> 00:20:49,440
assembler intrinsics because c2 i wanted

00:20:46,800 --> 00:20:51,960
it to be implemented with unsafe but c2

00:20:49,440 --> 00:20:54,960
couldn't optimize the code so well so

00:20:51,960 --> 00:20:57,570
Oracle decided to actually write you

00:20:54,960 --> 00:20:59,730
know the assembler by hand which is

00:20:57,570 --> 00:21:01,440
annoying because that means you have to

00:20:59,730 --> 00:21:03,090
do it in growth as well okay so we

00:21:01,440 --> 00:21:05,880
started doing this because that was

00:21:03,090 --> 00:21:08,460
before the whole Oracle a new release

00:21:05,880 --> 00:21:09,840
cadence you know was was announced and

00:21:08,460 --> 00:21:11,550
we thought we're actually moving from 8

00:21:09,840 --> 00:21:13,020
to 9 and we thought ok we should

00:21:11,550 --> 00:21:14,190
implement this because there's a

00:21:13,020 --> 00:21:16,110
performance impact then

00:21:14,190 --> 00:21:20,070
and so there's handwritten assembly code

00:21:16,110 --> 00:21:22,140
in C++ for all SSE AVX avx-512 and so on

00:21:20,070 --> 00:21:24,810
and so on so we needed to part that over

00:21:22,140 --> 00:21:26,730
to grow up this is basically one of the

00:21:24,810 --> 00:21:29,400
benchmarks and if you look at the third

00:21:26,730 --> 00:21:32,310
line that was grabbed before and it took

00:21:29,400 --> 00:21:33,930
what 2600 whatever that is nanoseconds

00:21:32,310 --> 00:21:36,990
per operation and then with the

00:21:33,930 --> 00:21:39,000
intrinsic sits 126 right so this is this

00:21:36,990 --> 00:21:41,310
is just to show this is not any better

00:21:39,000 --> 00:21:44,700
than C 2 it's exactly the same it's just

00:21:41,310 --> 00:21:49,350
we need feature parity and grah what we

00:21:44,700 --> 00:21:50,670
have in C 2 so we did this then I

00:21:49,350 --> 00:21:52,260
started traveling and do all these

00:21:50,670 --> 00:21:55,050
conferences so I couldn't finish it up

00:21:52,260 --> 00:21:56,550
but Demetri fortunately he fixed that

00:21:55,050 --> 00:21:58,290
and as you can see we had to port over

00:21:56,550 --> 00:22:00,930
about a thousand lines of handwritten

00:21:58,290 --> 00:22:04,050
assembly code integral and I just saw a

00:22:00,930 --> 00:22:06,060
ticket today because there are 3 or 4

00:22:04,050 --> 00:22:08,850
more smaller methods that need to be

00:22:06,060 --> 00:22:11,220
brought over and it just saw

00:22:08,850 --> 00:22:13,290
a PR for this today so someone at work

00:22:11,220 --> 00:22:15,570
was working on this to get it in before

00:22:13,290 --> 00:22:20,940
I hope before 11:00 comes out I would be

00:22:15,570 --> 00:22:23,670
good okay this is the interesting part

00:22:20,940 --> 00:22:28,080
so now we're talking about numbers and

00:22:23,670 --> 00:22:30,420
I'll show you a bunch of graphs so the

00:22:28,080 --> 00:22:31,740
tweet service at Twitter is a finagle

00:22:30,420 --> 00:22:33,840
thrift service you guys probably know

00:22:31,740 --> 00:22:35,760
what finagle is I don't really

00:22:33,840 --> 00:22:38,820
it's an extensible RPC system for the

00:22:35,760 --> 00:22:41,820
TVM who know I don't know most important

00:22:38,820 --> 00:22:43,590
thing it's 92 percent Scala code you

00:22:41,820 --> 00:22:46,110
guys know what that is right I you know

00:22:43,590 --> 00:22:49,470
I can't write a single line of Scala

00:22:46,110 --> 00:22:51,510
code by the way I really can't but I

00:22:49,470 --> 00:22:54,750
don't have to because everything I speak

00:22:51,510 --> 00:22:57,090
is Java byte code so so the tweet

00:22:54,750 --> 00:22:59,190
service runs with that stuff right so

00:22:57,090 --> 00:23:01,980
every all almost all of our micro

00:22:59,190 --> 00:23:04,170
services are written in Scala and I've

00:23:01,980 --> 00:23:05,990
given this presentation many many many

00:23:04,170 --> 00:23:09,270
times in the last eight months and

00:23:05,990 --> 00:23:10,950
usually at Java conferences okay so and

00:23:09,270 --> 00:23:13,710
that was important you know to show

00:23:10,950 --> 00:23:15,750
people what Gras could potentially do

00:23:13,710 --> 00:23:17,460
for them but to be honest this is the

00:23:15,750 --> 00:23:18,870
last conference from me for awhile and

00:23:17,460 --> 00:23:21,930
this is actually the most important one

00:23:18,870 --> 00:23:23,970
because you're a scholar people and Rob

00:23:21,930 --> 00:23:27,900
works really really well for Scala code

00:23:23,970 --> 00:23:30,840
and you will see that in a minute okay

00:23:27,900 --> 00:23:32,820
so my test setup was I had a dedicated

00:23:30,840 --> 00:23:35,490
machine per instance configuration

00:23:32,820 --> 00:23:37,230
I had dedicated machines because in our

00:23:35,490 --> 00:23:39,180
production cluster you know you have you

00:23:37,230 --> 00:23:40,410
have multiple things running on the same

00:23:39,180 --> 00:23:42,930
machine there's a lot of crosstalking

00:23:40,410 --> 00:23:44,220
going on and so you know you you want to

00:23:42,930 --> 00:23:47,520
get that out and you want you want

00:23:44,220 --> 00:23:49,620
really good you know numbers benchmark

00:23:47,520 --> 00:23:52,860
numbers that are not just distorted and

00:23:49,620 --> 00:23:55,950
then all instances receive the exact

00:23:52,860 --> 00:23:58,590
same requests that's important not the

00:23:55,950 --> 00:24:00,960
same number the exact same request and

00:23:58,590 --> 00:24:03,420
that's important because the tweak could

00:24:00,960 --> 00:24:06,060
be one byte long or a tweet could be 280

00:24:03,420 --> 00:24:07,470
and there's a very different allocation

00:24:06,060 --> 00:24:08,760
pattern if you do this so all of the

00:24:07,470 --> 00:24:10,740
instances receive the exact same

00:24:08,760 --> 00:24:13,590
requests we've run with that version of

00:24:10,740 --> 00:24:16,020
JVM CIN grah not that important we use

00:24:13,590 --> 00:24:18,330
the default tiered set up that means we

00:24:16,020 --> 00:24:20,160
we start up and then we compile with c1

00:24:18,330 --> 00:24:22,559
and then withdrawal that's what we do

00:24:20,160 --> 00:24:25,710
since eight we don't have a or T we do

00:24:22,559 --> 00:24:27,389
this if the Grob bootstrapping would be

00:24:25,710 --> 00:24:29,820
an issue for you I'm not going into the

00:24:27,389 --> 00:24:31,499
details here there's another talk you

00:24:29,820 --> 00:24:32,850
can find it on YouTube

00:24:31,499 --> 00:24:35,279
maybe I'll mention it later again I

00:24:32,850 --> 00:24:38,490
can't remember its how to use Gras in

00:24:35,279 --> 00:24:40,080
real life to Google for it or search on

00:24:38,490 --> 00:24:41,909
youtube for it and then I'll explain all

00:24:40,080 --> 00:24:44,519
this the bootstrapping part that it's

00:24:41,909 --> 00:24:48,539
not an issue but if it would be an issue

00:24:44,519 --> 00:24:49,889
and you run on ten nine or ten and I'm

00:24:48,539 --> 00:24:52,830
pretty sure everyone in here is running

00:24:49,889 --> 00:24:54,570
on ten in production today yes you could

00:24:52,830 --> 00:24:56,659
technically äôt compile growl and then

00:24:54,570 --> 00:25:01,499
the bootstrapping would not be a problem

00:24:56,659 --> 00:25:03,389
ok so let's see the numbers and look at

00:25:01,499 --> 00:25:06,600
the graphs it's good that it's actually

00:25:03,389 --> 00:25:10,649
cut off here on the left this is this is

00:25:06,600 --> 00:25:13,649
24 hours of tweets right so you can see

00:25:10,649 --> 00:25:15,779
and then one thing you can't see that's

00:25:13,649 --> 00:25:18,059
why I say it's good there is no y axis

00:25:15,779 --> 00:25:20,940
and the reason why there's no y axis is

00:25:18,059 --> 00:25:22,529
because I'm not allowed to tell you ok

00:25:20,940 --> 00:25:24,659
but I'll show the numbers to you in a

00:25:22,529 --> 00:25:26,309
way that you will understand and see how

00:25:24,659 --> 00:25:31,169
much we're saving here so we are

00:25:26,309 --> 00:25:34,139
comparing c2 of of JDK 8 then Gras and

00:25:31,169 --> 00:25:36,629
then I also put in JDK 9 numbers just to

00:25:34,139 --> 00:25:38,669
see if there would be a difference okay

00:25:36,629 --> 00:25:40,429
and the important thing to see on this

00:25:38,669 --> 00:25:41,639
slide is that they are all the same ok

00:25:40,429 --> 00:25:44,249
good

00:25:41,639 --> 00:25:46,379
so the tweet service uses parallel GC

00:25:44,249 --> 00:25:47,999
and so we're looking at its current

00:25:46,379 --> 00:25:49,830
cycles here there's a moving average of

00:25:47,999 --> 00:25:52,740
60 minutes so it's a little smooth out

00:25:49,830 --> 00:25:56,519
it's easier to see so there's a c2 and

00:25:52,740 --> 00:25:58,169
as I said earlier that broth has a

00:25:56,519 --> 00:25:59,700
better escape analysis implementations

00:25:58,169 --> 00:26:02,369
of what we would like to see here is

00:25:59,700 --> 00:26:04,230
less scavenge cycles ok so let's look at

00:26:02,369 --> 00:26:06,179
this and actually yes that's the case

00:26:04,230 --> 00:26:08,190
that's very good because that means

00:26:06,179 --> 00:26:09,929
we're not allocating so much memory and

00:26:08,190 --> 00:26:13,559
it means then we don't have to collect

00:26:09,929 --> 00:26:17,129
all this garbage ok we have the same for

00:26:13,559 --> 00:26:22,259
9 and the same for 9 and this is roughly

00:26:17,129 --> 00:26:25,019
a 2.5 percent reduction in cycles that's

00:26:22,259 --> 00:26:28,230
not a lot but it's something right if

00:26:25,019 --> 00:26:31,150
you don't have to do 2.5% of the cycles

00:26:28,230 --> 00:26:36,110
you save right

00:26:31,150 --> 00:26:38,840
them you know what Sree some people who

00:26:36,110 --> 00:26:40,880
take care of their services they they've

00:26:38,840 --> 00:26:42,890
very closely look at their metrics and

00:26:40,880 --> 00:26:45,110
some of them when they started running

00:26:42,890 --> 00:26:47,750
withdrawal they were screaming Oh memory

00:26:45,110 --> 00:26:51,680
leak memory leak and what they saw was

00:26:47,750 --> 00:26:54,800
here at the bottom like a 40% increase

00:26:51,680 --> 00:26:58,070
in old chin usage and the reason for

00:26:54,800 --> 00:27:01,540
this is Gras is a java application it

00:26:58,070 --> 00:27:04,910
has some state and it's 40 mix roughly

00:27:01,540 --> 00:27:06,260
but that's not a ratio of the old Chen

00:27:04,910 --> 00:27:07,820
it's just for Team X right it doesn't

00:27:06,260 --> 00:27:10,700
matter how big your chin is if it's a

00:27:07,820 --> 00:27:12,500
hundred megabyte megabytes it's 440 if

00:27:10,700 --> 00:27:14,300
it's if your ocean is 2 terabytes it's

00:27:12,500 --> 00:27:16,550
40 megabytes it doesn't matter it's just

00:27:14,300 --> 00:27:18,140
a state you have and then the same I

00:27:16,550 --> 00:27:20,480
don't have a graph where it but the same

00:27:18,140 --> 00:27:22,130
is the case for meta space right because

00:27:20,480 --> 00:27:23,840
you have to load classes like the

00:27:22,130 --> 00:27:26,510
classes take up some memory and that's

00:27:23,840 --> 00:27:27,940
roughly between 20 and 30 megabytes so

00:27:26,510 --> 00:27:30,500
it's not the end of the world really

00:27:27,940 --> 00:27:34,220
but people complained about it and

00:27:30,500 --> 00:27:36,590
rightly so and it was good they did most

00:27:34,220 --> 00:27:39,410
important graph use the CPU time what we

00:27:36,590 --> 00:27:41,690
really want is to save user CPU time

00:27:39,410 --> 00:27:43,940
because that means we can reduce the

00:27:41,690 --> 00:27:46,090
size of our instances of our clusters

00:27:43,940 --> 00:27:49,850
basically okay so there's a c2 and

00:27:46,090 --> 00:27:52,870
there's a scroll that's really nice we

00:27:49,850 --> 00:27:55,460
can't tell yet how much it is this is 9

00:27:52,870 --> 00:27:58,430
it seems it's better I don't think it

00:27:55,460 --> 00:28:00,260
really is what can happen sometimes is

00:27:58,430 --> 00:28:02,300
that in lining decisions are done

00:28:00,260 --> 00:28:03,650
differently on different runs and so I

00:28:02,300 --> 00:28:05,570
don't think that actually c2 was

00:28:03,650 --> 00:28:07,940
improved in that case and then as you

00:28:05,570 --> 00:28:10,400
can see is brawl with 9 is exactly the

00:28:07,940 --> 00:28:14,690
same so let's put this in a ratio graph

00:28:10,400 --> 00:28:20,600
and you can almost not really see it on

00:28:14,690 --> 00:28:24,020
the side here but it's 11% 11% reduction

00:28:20,600 --> 00:28:25,370
in CPU utilization is huge I don't know

00:28:24,020 --> 00:28:27,590
how many compiler engineers are in this

00:28:25,370 --> 00:28:31,190
room there's at least one usually

00:28:27,590 --> 00:28:33,530
there's none but there's one if you get

00:28:31,190 --> 00:28:34,820
if you you know if you write an

00:28:33,530 --> 00:28:36,770
improvement or make an improvement in

00:28:34,820 --> 00:28:39,440
the compiler in the native compiler and

00:28:36,770 --> 00:28:42,740
you get 1% that's cool right if you get

00:28:39,440 --> 00:28:45,770
2% that's great but if you get 11

00:28:42,740 --> 00:28:50,360
it's ridiculous right and we just we

00:28:45,770 --> 00:28:54,020
just switched up the chicken fighter all

00:28:50,360 --> 00:28:57,529
right so the tweet service as of today

00:28:54,020 --> 00:29:01,039
and for about a year now I think because

00:28:57,529 --> 00:29:04,700
it's tuned now Twitter's tweet service

00:29:01,039 --> 00:29:06,020
runs 100% on growling production and we

00:29:04,700 --> 00:29:08,539
didn't have initiative since then by the

00:29:06,020 --> 00:29:10,309
way and yeah you should tweet that right

00:29:08,539 --> 00:29:11,840
now so you try it out if it actually

00:29:10,309 --> 00:29:12,409
works so if you're losing a tweet or

00:29:11,840 --> 00:29:14,840
something

00:29:12,409 --> 00:29:17,059
no it runs fine and then we're also

00:29:14,840 --> 00:29:18,559
running the other bunch that I mentioned

00:29:17,059 --> 00:29:20,659
early at the very beginning like the

00:29:18,559 --> 00:29:22,520
biggest services we have the tweet the

00:29:20,659 --> 00:29:25,070
social graph service and the user

00:29:22,520 --> 00:29:28,549
service they are also running 100% on

00:29:25,070 --> 00:29:30,350
growth plus another you know number

00:29:28,549 --> 00:29:31,640
small number of other service that are

00:29:30,350 --> 00:29:34,039
not that important but these are our

00:29:31,640 --> 00:29:36,020
biggest ones in terms of instance size

00:29:34,039 --> 00:29:42,830
and so that's where we save most of the

00:29:36,020 --> 00:29:44,570
money ok interesting for me was this 11%

00:29:42,830 --> 00:29:46,460
of reduction in CPU time where is it

00:29:44,570 --> 00:29:48,799
really coming from is it just the escape

00:29:46,460 --> 00:29:51,049
analysis is it because we don't have to

00:29:48,799 --> 00:29:52,520
allocate these temporary objects that

00:29:51,049 --> 00:29:54,860
means your code gets tighter you don't

00:29:52,520 --> 00:29:57,649
have to collect them you know is it that

00:29:54,860 --> 00:29:59,960
so I I made an experiment and looked at

00:29:57,649 --> 00:30:01,850
this and I just ran the tweet service

00:29:59,960 --> 00:30:05,000
again and turned off as keep analysis

00:30:01,850 --> 00:30:07,130
okay this is basically again the request

00:30:05,000 --> 00:30:08,390
would for 24 hours the graph is

00:30:07,130 --> 00:30:11,809
different because I ran a different

00:30:08,390 --> 00:30:14,809
experiment and this is again the

00:30:11,809 --> 00:30:16,279
scavenge cycle graph and here that now

00:30:14,809 --> 00:30:18,159
because we have turned off escape

00:30:16,279 --> 00:30:21,649
analysis should be exactly the same and

00:30:18,159 --> 00:30:23,390
it is so that works fine so we're

00:30:21,649 --> 00:30:25,010
comparing actually apples to apples and

00:30:23,390 --> 00:30:26,539
so here is this use of CPU time without

00:30:25,010 --> 00:30:28,909
escape analysis and here it's with

00:30:26,539 --> 00:30:31,270
withdrawal so there is even an

00:30:28,909 --> 00:30:36,860
improvement without escape analysis and

00:30:31,270 --> 00:30:38,899
again you know ratio and it's 5% so just

00:30:36,860 --> 00:30:41,840
the better inlining implementation in

00:30:38,899 --> 00:30:43,309
grah can give you a 5% improvement with

00:30:41,840 --> 00:30:47,270
your Scala code again remember this is

00:30:43,309 --> 00:30:49,640
all scalar code right that was very

00:30:47,270 --> 00:30:51,289
interesting to me because I thought it's

00:30:49,640 --> 00:30:53,889
probably mostly escape analysis but

00:30:51,289 --> 00:30:57,409
there was a lot of inlining as well

00:30:53,889 --> 00:31:01,039
so how much money are we talking no I

00:30:57,409 --> 00:31:02,149
can tell you I couldn't what do you

00:31:01,039 --> 00:31:03,799
think I can tell you I couldn't even

00:31:02,149 --> 00:31:05,679
show you a y-axis do you think I can

00:31:03,799 --> 00:31:09,580
tell you of course not

00:31:05,679 --> 00:31:11,720
so we're making up a fictitious company

00:31:09,580 --> 00:31:13,549
and we do a little back-of-the-envelope

00:31:11,720 --> 00:31:15,289
calculation to I don't know how many

00:31:13,549 --> 00:31:17,509
people are in here that have data

00:31:15,289 --> 00:31:21,289
centers and they are familiar how how

00:31:17,509 --> 00:31:23,059
much it costs I didn't know it so I was

00:31:21,289 --> 00:31:25,700
just googling for some cloud providers

00:31:23,059 --> 00:31:29,419
how much they actually charge right and

00:31:25,700 --> 00:31:31,429
so I calculated that out pert so per CPU

00:31:29,419 --> 00:31:36,370
core dollars per year it's like between

00:31:31,429 --> 00:31:39,259
what 72 and $210 per year per CPU core

00:31:36,370 --> 00:31:41,570
number one takeaway from that slide if

00:31:39,259 --> 00:31:43,610
you're choosing the wrong cloud provider

00:31:41,570 --> 00:31:45,080
you're screwed anyway right no compiler

00:31:43,610 --> 00:31:49,460
can help you save money if you pick the

00:31:45,080 --> 00:31:51,110
210 one but I didn't know so I

00:31:49,460 --> 00:31:53,659
I took the average of one hundred twenty

00:31:51,110 --> 00:31:56,360
seven dollars per year per CPU core

00:31:53,659 --> 00:31:58,879
really so how many cores are we talking

00:31:56,360 --> 00:32:00,710
right again I can tell you how many we

00:31:58,879 --> 00:32:02,480
are using but there is a bloomberg

00:32:00,710 --> 00:32:04,549
article from 2014 that talks about

00:32:02,480 --> 00:32:08,360
Amazon and Google and Microsoft and it

00:32:04,549 --> 00:32:11,210
says where does it say that Amazon here

00:32:08,360 --> 00:32:13,429
a conservative estimate puts Amazon over

00:32:11,210 --> 00:32:16,100
1.5 million service globally and then

00:32:13,429 --> 00:32:19,669
this other person that gardeners has two

00:32:16,100 --> 00:32:23,389
million service ok service right a

00:32:19,669 --> 00:32:24,889
server has usually 24 cores so these are

00:32:23,389 --> 00:32:27,259
ridiculous numbers and then at the

00:32:24,889 --> 00:32:30,230
bottom it says about Microsoft 17

00:32:27,259 --> 00:32:31,700
regions above about Steve Ballmer said

00:32:30,230 --> 00:32:35,059
the company had over a million servers

00:32:31,700 --> 00:32:39,139
and Google had even more so it's

00:32:35,059 --> 00:32:41,240
humongous right but obviously your

00:32:39,139 --> 00:32:43,190
company is not as big as Google I'm

00:32:41,240 --> 00:32:44,509
assuming at least so we're just picking

00:32:43,190 --> 00:32:47,090
a random number of ten thousand servers

00:32:44,509 --> 00:32:48,889
it might be a little bit bit too big but

00:32:47,090 --> 00:32:51,500
you know if you're running a decently

00:32:48,889 --> 00:32:53,690
sized operation maybe that's ok so you

00:32:51,500 --> 00:32:56,389
have 10,000 server through 24 cores

00:32:53,690 --> 00:32:59,330
that's 100 premise $27 per year per CPU

00:32:56,389 --> 00:33:01,250
current times 24 times 10,000 is three

00:32:59,330 --> 00:33:02,119
million dollars to just run whatever

00:33:01,250 --> 00:33:05,720
business you're running

00:33:02,119 --> 00:33:07,280
ok that's your expense if you could save

00:33:05,720 --> 00:33:11,060
11 percent

00:33:07,280 --> 00:33:13,610
that that's a nice chunk of money it's

00:33:11,060 --> 00:33:15,080
more than I get paid I don't know how

00:33:13,610 --> 00:33:17,410
much you guys get paid but it's more

00:33:15,080 --> 00:33:17,410
than I do

00:33:18,400 --> 00:33:26,450
so 11 percent is really nice but as

00:33:23,540 --> 00:33:28,310
we've seen from this one graph it's it's

00:33:26,450 --> 00:33:29,870
a lot inlining it's like half half

00:33:28,310 --> 00:33:32,750
roughly it's in lining and escape

00:33:29,870 --> 00:33:35,060
analysis so the question is what if we

00:33:32,750 --> 00:33:37,840
inline a little bit more can we actually

00:33:35,060 --> 00:33:40,640
get more out of it and so what I did was

00:33:37,840 --> 00:33:42,200
I set down one afternoon that was just

00:33:40,640 --> 00:33:44,600
fiddling around with inlining parameters

00:33:42,200 --> 00:33:46,760
for like two three hours or something

00:33:44,600 --> 00:33:49,130
like this like manually changing them

00:33:46,760 --> 00:33:50,480
looking at you know log output what

00:33:49,130 --> 00:33:51,980
could be really in line more tweak this

00:33:50,480 --> 00:33:54,710
a little bit blah blah blah so it did

00:33:51,980 --> 00:33:56,690
this and I ran the experiment again and

00:33:54,710 --> 00:33:58,280
I actually ran that experiment at the

00:33:56,690 --> 00:34:00,560
same time as my first experiment so

00:33:58,280 --> 00:34:02,780
you've seen that draft before and then

00:34:00,560 --> 00:34:04,670
we have this new color the purple that's

00:34:02,780 --> 00:34:06,130
my experiment with the change in lining

00:34:04,670 --> 00:34:08,750
parameters okay

00:34:06,130 --> 00:34:11,690
against scavenge cycles you know that

00:34:08,750 --> 00:34:12,770
graph you've seen it before and I

00:34:11,690 --> 00:34:16,040
actually could squeeze a little bit more

00:34:12,770 --> 00:34:18,919
out of it and it's roughly a 1.5

00:34:16,040 --> 00:34:20,830
reduction like 1.5 percent reduction

00:34:18,919 --> 00:34:23,840
which is pretty good actually

00:34:20,830 --> 00:34:26,270
and then this use of CPU time graph

00:34:23,840 --> 00:34:31,970
you've seen that before and yes better

00:34:26,270 --> 00:34:33,260
and that's an additional 2% but just

00:34:31,970 --> 00:34:37,419
screwing around a little bit really

00:34:33,260 --> 00:34:41,810
right and then the 2% was what the

00:34:37,419 --> 00:34:43,130
$300,000 we had 2% is like $60,000 but

00:34:41,810 --> 00:34:45,710
just fiddling around for two hours I

00:34:43,130 --> 00:34:49,280
would be nice I didn't get it but you

00:34:45,710 --> 00:34:52,790
know I would be cool so this is this is

00:34:49,280 --> 00:34:55,310
obviously no human should sit there and

00:34:52,790 --> 00:34:56,450
do this right there is there's a buzz

00:34:55,310 --> 00:34:59,060
word that could do this it's called

00:34:56,450 --> 00:35:00,830
machine learning and we're actually

00:34:59,060 --> 00:35:02,180
doing this by the way and so I'm not

00:35:00,830 --> 00:35:04,190
going to tell you too much about it

00:35:02,180 --> 00:35:06,170
because that will be my next talk so

00:35:04,190 --> 00:35:11,300
next year when I come back I'll tell you

00:35:06,170 --> 00:35:14,810
about that your company I'm pretty sure

00:35:11,300 --> 00:35:16,820
does not have its own be empty so for

00:35:14,810 --> 00:35:20,000
you support is probably important so how

00:35:16,820 --> 00:35:21,180
good is scroll supported by Oracle or

00:35:20,000 --> 00:35:26,040
open

00:35:21,180 --> 00:35:30,350
so as I said earlier JDK 9 contains Gras

00:35:26,040 --> 00:35:33,510
because a of T is using it and then

00:35:30,350 --> 00:35:35,010
since I was working on it I made it so

00:35:33,510 --> 00:35:37,140
that you actually could use it as a JIT

00:35:35,010 --> 00:35:40,500
compiler and I never knew that but you

00:35:37,140 --> 00:35:42,210
know we made it that way I I was at

00:35:40,500 --> 00:35:44,010
FOSDEM this year and I was talking to

00:35:42,210 --> 00:35:45,840
John Rosen mark Reinhold about it they'd

00:35:44,010 --> 00:35:47,100
they watched my presentation and I

00:35:45,840 --> 00:35:49,290
marked Ryan house later came up to me

00:35:47,100 --> 00:35:53,550
and said I didn't know you could use it

00:35:49,290 --> 00:35:56,120
as a cheat compiler that's it so you

00:35:53,550 --> 00:35:59,760
came in 9 but it's even better because

00:35:56,120 --> 00:36:02,190
there's chapter 3 17 in JDK 10 now and

00:35:59,760 --> 00:36:02,880
basically Oracle put it in there

00:36:02,190 --> 00:36:05,820
officially

00:36:02,880 --> 00:36:07,920
so still experimental but it's there and

00:36:05,820 --> 00:36:11,340
you can turn it on with these flags that

00:36:07,920 --> 00:36:13,470
I just showed you here at the bottom so

00:36:11,340 --> 00:36:16,140
that's that's kind of the closest you

00:36:13,470 --> 00:36:18,480
can get right now to being supported it

00:36:16,140 --> 00:36:20,370
doesn't really mean you can't get the

00:36:18,480 --> 00:36:21,840
real support by Oracle but if something

00:36:20,370 --> 00:36:23,310
goes wrong if it crashes you can't get

00:36:21,840 --> 00:36:25,410
at least talk to them and they will

00:36:23,310 --> 00:36:28,650
probably fix it or or collapse people

00:36:25,410 --> 00:36:30,660
whoever right yeah this is the other

00:36:28,650 --> 00:36:33,150
talk I was mentioning earlier how do you

00:36:30,660 --> 00:36:35,700
use scroll so just just Google for that

00:36:33,150 --> 00:36:37,950
one watch it it's it's I'm doing it's

00:36:35,700 --> 00:36:39,810
basically one one hour of just demos I

00:36:37,950 --> 00:36:41,340
fire up a completely empty cloud

00:36:39,810 --> 00:36:42,810
instance and then download everything

00:36:41,340 --> 00:36:44,360
you need and show you what to do to

00:36:42,810 --> 00:36:46,350
actually run I show a bunch of

00:36:44,360 --> 00:36:48,210
benchmarks tell you about bootstrapping

00:36:46,350 --> 00:36:50,310
Java memory heap usage and all these

00:36:48,210 --> 00:36:50,970
things and it's it's actually not that

00:36:50,310 --> 00:36:54,300
scary

00:36:50,970 --> 00:36:56,760
so and I say it again we are using this

00:36:54,300 --> 00:37:00,300
in production today like for a very long

00:36:56,760 --> 00:37:01,980
time and it's perfectly fine then there

00:37:00,300 --> 00:37:04,350
is something called project metropolis

00:37:01,980 --> 00:37:06,690
which was proposed like in September

00:37:04,350 --> 00:37:09,360
last year by John Rose and at the bottom

00:37:06,690 --> 00:37:12,030
you know it says our starting point is

00:37:09,360 --> 00:37:13,830
early proposals for using Gras the using

00:37:12,030 --> 00:37:16,110
the Gras compiler and äôt static

00:37:13,830 --> 00:37:19,920
compilation technology to replace the

00:37:16,110 --> 00:37:21,420
hot spot server compiler c2 exactly what

00:37:19,920 --> 00:37:23,610
we want we want to get rid of it and

00:37:21,420 --> 00:37:26,580
possibly out of components of hot spot

00:37:23,610 --> 00:37:28,830
so what this says is that we would like

00:37:26,580 --> 00:37:31,170
Oracle and the open JDK community would

00:37:28,830 --> 00:37:32,730
like to rewrite parts of hot spot in

00:37:31,170 --> 00:37:35,040
Java

00:37:32,730 --> 00:37:36,690
the perfect example is is the compiler

00:37:35,040 --> 00:37:39,420
because it's like it's an optional

00:37:36,690 --> 00:37:41,369
module right the GC the only implement

00:37:39,420 --> 00:37:42,839
the GC in Java it's not a good idea but

00:37:41,369 --> 00:37:44,700
you could do other things like you could

00:37:42,839 --> 00:37:47,309
do the by could verify would be super

00:37:44,700 --> 00:37:47,910
easy or hopefully the interpreter that

00:37:47,309 --> 00:37:50,760
would be great

00:37:47,910 --> 00:37:52,920
so did now I don't think anyone's

00:37:50,760 --> 00:37:54,869
actively working on this yet I know

00:37:52,920 --> 00:37:56,640
there is some work being done with

00:37:54,869 --> 00:37:58,380
getting substrate VM into hotspot so

00:37:56,640 --> 00:38:00,599
that this T compilation that the

00:37:58,380 --> 00:38:02,280
bootstrapping goes away but this this is

00:38:00,599 --> 00:38:03,869
a very nice project if I didn't work for

00:38:02,280 --> 00:38:08,460
Twitter I would probably work on this

00:38:03,869 --> 00:38:11,099
stuff okay so lastly this slide is just

00:38:08,460 --> 00:38:12,780
here for the Java conferences as I was

00:38:11,099 --> 00:38:15,119
always mentioning earlier I don't really

00:38:12,780 --> 00:38:16,770
have to say this today because your

00:38:15,119 --> 00:38:19,680
stuff is probably written in Scala right

00:38:16,770 --> 00:38:21,630
so but with Java it's it's slightly

00:38:19,680 --> 00:38:25,290
different I'm just mentioning it the

00:38:21,630 --> 00:38:27,059
reason is I don't know if you guys I've

00:38:25,290 --> 00:38:29,569
ever looked at the byte code that Scala

00:38:27,059 --> 00:38:32,099
C produces it's horrifying

00:38:29,569 --> 00:38:34,740
it's like when you look at at bye cut

00:38:32,099 --> 00:38:37,230
that Java C produces it's it's very flat

00:38:34,740 --> 00:38:38,940
it's very easy to read if you look at

00:38:37,230 --> 00:38:40,859
Scala code it's ridiculous it's very

00:38:38,940 --> 00:38:42,809
complicated Scala has a very polymorphic

00:38:40,859 --> 00:38:44,099
nature to it it allocates a lot of

00:38:42,809 --> 00:38:46,680
temporary objects you know all that

00:38:44,099 --> 00:38:48,390
stuff right so the inlining and the

00:38:46,680 --> 00:38:51,599
escape analysis here really comes into

00:38:48,390 --> 00:38:55,430
play when you run Java then Guerard

00:38:51,599 --> 00:38:59,640
can't do that much right and it's also

00:38:55,430 --> 00:39:02,700
c2 has been optimized for for all the

00:38:59,640 --> 00:39:04,589
chava code out there for a long time but

00:39:02,700 --> 00:39:07,410
more importantly the Java code has been

00:39:04,589 --> 00:39:09,000
optimized for c2 right so if you

00:39:07,410 --> 00:39:11,579
suddenly bring in a new compiler it's

00:39:09,000 --> 00:39:14,460
very difficult to run that code better

00:39:11,579 --> 00:39:16,740
than with the existing one it's like my

00:39:14,460 --> 00:39:18,799
rule of thumb is it's a 50-50 chance if

00:39:16,740 --> 00:39:21,390
Brawl runs your Java code better or not

00:39:18,799 --> 00:39:23,579
I've see I've seen it I've seen

00:39:21,390 --> 00:39:25,530
benchmarks that run much better up to

00:39:23,579 --> 00:39:29,130
10% I've seen benchmarks that actually

00:39:25,530 --> 00:39:31,049
run slower so it's whatever your mileage

00:39:29,130 --> 00:39:34,859
may vary but again you just call the

00:39:31,049 --> 00:39:37,530
people's it doesn't really matter okay

00:39:34,859 --> 00:39:41,450
that was almost it my summary for this

00:39:37,530 --> 00:39:44,299
talk is this

00:39:41,450 --> 00:39:47,900
that's really all I want so I'm giving

00:39:44,299 --> 00:39:50,809
all these presentations for the one

00:39:47,900 --> 00:39:52,760
reason I want you to try it and the

00:39:50,809 --> 00:39:56,359
reason I want you to try it is because

00:39:52,760 --> 00:39:59,380
we want to replace C 2 in open JDK with

00:39:56,359 --> 00:40:02,569
Gras but it's not going to happen until

00:39:59,380 --> 00:40:04,760
it's a mature stable compiler right

00:40:02,569 --> 00:40:06,740
otherwise Oracle will never make it the

00:40:04,760 --> 00:40:08,119
default compiler but the problem is if

00:40:06,740 --> 00:40:12,200
it's not the default compiler no one's

00:40:08,119 --> 00:40:14,299
using it uses either catch-22 so that's

00:40:12,200 --> 00:40:16,880
why I'm touring around and encouraging

00:40:14,299 --> 00:40:21,670
you to give this a try and again you are

00:40:16,880 --> 00:40:24,859
Scala people I give you a 99.9 percent

00:40:21,670 --> 00:40:27,859
assurance that your Scala code will run

00:40:24,859 --> 00:40:31,790
faster with raw I've not seen Scala code

00:40:27,859 --> 00:40:34,940
that runs worse so give it a try it's

00:40:31,790 --> 00:40:38,690
very easy when you run on 10 it's very

00:40:34,940 --> 00:40:40,010
easy you could probably not run it on 10

00:40:38,690 --> 00:40:42,200
in production but maybe you have some

00:40:40,010 --> 00:40:44,450
experimental setup somewhere or our pet

00:40:42,200 --> 00:40:46,670
project or our new service that you're

00:40:44,450 --> 00:40:50,359
working on who knows what you can also

00:40:46,670 --> 00:40:52,069
download an eighth version a Java 8

00:40:50,359 --> 00:40:53,660
version with growling it from the Oracle

00:40:52,069 --> 00:40:56,540
technology Network so or collapse

00:40:53,660 --> 00:40:59,839
provides a binary for that if that's

00:40:56,540 --> 00:41:03,760
your only way out and with that please

00:40:59,839 --> 00:41:03,760
try it thank you very much

00:41:07,330 --> 00:41:13,460
and I yeah

00:41:10,010 --> 00:41:17,390
the hands already go up so yes all right

00:41:13,460 --> 00:41:19,580
first first row why did the early talk

00:41:17,390 --> 00:41:21,200
by Kristian where I think your alt

00:41:19,580 --> 00:41:23,420
compiled Scala see I think that that was

00:41:21,200 --> 00:41:26,300
it right why did they get a 30%

00:41:23,420 --> 00:41:28,760
improvement but we only get 10 the

00:41:26,300 --> 00:41:33,590
answer is ecology stinks right it's

00:41:28,760 --> 00:41:35,030
shitty code we we have now I've been

00:41:33,590 --> 00:41:36,890
told this many times I have no idea

00:41:35,030 --> 00:41:41,530
about Scala but I know that Scala C is a

00:41:36,890 --> 00:41:42,740
slow compiler and and so if if you can

00:41:41,530 --> 00:41:45,380
yeah

00:41:42,740 --> 00:41:47,390
so if you can improve that one one big

00:41:45,380 --> 00:41:50,870
issue with Scala C as far as I know and

00:41:47,390 --> 00:41:53,420
Java C has the same problem is the JVM

00:41:50,870 --> 00:41:55,700
startup is not very fast right so if we

00:41:53,420 --> 00:41:59,270
can improve KVM startup you can improve

00:41:55,700 --> 00:42:00,650
a lot on that front but this is like a

00:41:59,270 --> 00:42:01,850
running you know this is a running

00:42:00,650 --> 00:42:04,970
service that runs for hours and hours

00:42:01,850 --> 00:42:07,220
and days so it you can't really compare

00:42:04,970 --> 00:42:09,620
a source code compile it to something

00:42:07,220 --> 00:42:10,910
like a service you know what I'm saying

00:42:09,620 --> 00:42:12,260
does that make any sense it doesn't look

00:42:10,910 --> 00:42:17,210
like you're happy with the answer but

00:42:12,260 --> 00:42:19,550
well then I change my answer to no but I

00:42:17,210 --> 00:42:21,620
mean like everything there's an answer

00:42:19,550 --> 00:42:23,930
for you and the answer is it depends

00:42:21,620 --> 00:42:25,430
it's like it depends on the code it

00:42:23,930 --> 00:42:27,890
really does I have to repeat the

00:42:25,430 --> 00:42:31,730
question so where where does cross stand

00:42:27,890 --> 00:42:34,910
right now with with vector up vector

00:42:31,730 --> 00:42:38,140
instruction support compared to C 2 so

00:42:34,910 --> 00:42:42,350
there are there are two ways or two

00:42:38,140 --> 00:42:44,560
usages use cases use it just for vector

00:42:42,350 --> 00:42:48,590
instructions in situ one is in

00:42:44,560 --> 00:42:51,260
intrinsics like handwritten stuff that

00:42:48,590 --> 00:42:53,180
you can just maybe you already have that

00:42:51,260 --> 00:42:54,320
like the contribution I showed you was

00:42:53,180 --> 00:42:54,980
basically seeing the instructions

00:42:54,320 --> 00:42:57,470
porting over

00:42:54,980 --> 00:42:59,570
that's a handwritten part then maybe you

00:42:57,470 --> 00:43:01,010
were talking about loop octave it out to

00:42:59,570 --> 00:43:04,250
vectorization that's what you're talking

00:43:01,010 --> 00:43:06,380
about yes there is no as of today as far

00:43:04,250 --> 00:43:08,180
as I know there's no loop auto

00:43:06,380 --> 00:43:10,160
vectorization in the open-source version

00:43:08,180 --> 00:43:14,260
of crawl there is one in the close

00:43:10,160 --> 00:43:17,210
source on the closed version but I I

00:43:14,260 --> 00:43:18,770
think I remember an email not too long

00:43:17,210 --> 00:43:19,490
ago that they're actually open sourcing

00:43:18,770 --> 00:43:22,369
that partner

00:43:19,490 --> 00:43:24,829
so the question is if I if I try the

00:43:22,369 --> 00:43:27,140
same inlining parameter tweaking with C

00:43:24,829 --> 00:43:30,650
- sure

00:43:27,140 --> 00:43:35,000
no I did not it potentially will help

00:43:30,650 --> 00:43:40,059
yes the reason why I didn't do it is

00:43:35,000 --> 00:43:43,450
because I want to get rid of it right so

00:43:40,059 --> 00:43:46,339
the question is how stable growl is

00:43:43,450 --> 00:43:51,500
regarding the optimizations and Layton

00:43:46,339 --> 00:43:53,750
sees and things like this yeah okay so

00:43:51,500 --> 00:43:56,089
if you talk about the optimization like

00:43:53,750 --> 00:43:58,190
what I think you're talking about like D

00:43:56,089 --> 00:44:00,349
optimizing from compile code into

00:43:58,190 --> 00:44:02,089
interpreting with decide what are you

00:44:00,349 --> 00:44:03,800
saying yeah I mean that's that's very

00:44:02,089 --> 00:44:05,559
difficult to answer then the answer I

00:44:03,800 --> 00:44:09,109
can give you is we are not seeing this

00:44:05,559 --> 00:44:10,790
so for you if you really have that issue

00:44:09,109 --> 00:44:12,980
and you think you're constantly be

00:44:10,790 --> 00:44:14,540
optimizing and recompiling you would

00:44:12,980 --> 00:44:16,880
have to look at the compilation output

00:44:14,540 --> 00:44:19,280
and see where this is coming from but we

00:44:16,880 --> 00:44:21,829
don't have that no we it's very stable

00:44:19,280 --> 00:44:23,869
you know I told you I mean this you know

00:44:21,829 --> 00:44:26,359
we're running thousands of instances of

00:44:23,869 --> 00:44:28,790
these services we we did we deploy them

00:44:26,359 --> 00:44:30,829
multiple times a week so they start up a

00:44:28,790 --> 00:44:33,109
lot a lot of compilations going on I'm

00:44:30,829 --> 00:44:35,900
Kent le there's a there's a ton of the

00:44:33,109 --> 00:44:38,059
optimizations happening all the time but

00:44:35,900 --> 00:44:39,920
it stabilizes itself like it gets to its

00:44:38,059 --> 00:44:41,270
peak performance and it stays there so

00:44:39,920 --> 00:44:43,640
it's it's not it's not any different

00:44:41,270 --> 00:44:46,099
than C - not for us now does it help

00:44:43,640 --> 00:44:48,470
with i/o operations as well is that your

00:44:46,099 --> 00:44:51,260
question I mean we do a lot of i/o as

00:44:48,470 --> 00:44:53,930
well but it it can't really help with

00:44:51,260 --> 00:44:55,640
i/o right because IO calls out into the

00:44:53,930 --> 00:44:58,599
kernel and then you wait for it there's

00:44:55,640 --> 00:45:01,579
nothing the JVM compiler can do about it

00:44:58,599 --> 00:45:03,410
but it's like the logic that runs on top

00:45:01,579 --> 00:45:05,869
of it it's like all the all your

00:45:03,410 --> 00:45:08,809
business logic that Drock and optimize

00:45:05,869 --> 00:45:11,299
that but not IO know he wants to know

00:45:08,809 --> 00:45:16,910
again what versions of open JDK have

00:45:11,299 --> 00:45:21,559
crawling it there's on Linux x86 64 you

00:45:16,910 --> 00:45:23,240
can nine has that not eight eight you

00:45:21,559 --> 00:45:26,180
can get from the Oracle technology

00:45:23,240 --> 00:45:28,880
Network if you if it type in Google otm

00:45:26,180 --> 00:45:30,559
draw the first here is the one you want

00:45:28,880 --> 00:45:31,779
you can download an eighth version from

00:45:30,559 --> 00:45:36,279
there

00:45:31,779 --> 00:45:42,309
JDK 10 has growling it and for all the

00:45:36,279 --> 00:45:44,710
oh it's what any 11 it's the same thing

00:45:42,309 --> 00:45:47,529
in 10 it's almost the same thing right

00:45:44,710 --> 00:45:50,259
so it's OpenJDK in open JDK 10 you have

00:45:47,529 --> 00:45:55,829
growl yes for all the platforms Windows

00:45:50,259 --> 00:45:58,119
Mac and Linux well really good results

00:45:55,829 --> 00:46:01,739
yeah I mean the reason why I'm not

00:45:58,119 --> 00:46:07,749
talking about enterprise crawl is as a

00:46:01,739 --> 00:46:07,960
philosophical one maybe but it ok why

00:46:07,749 --> 00:46:10,569
not

00:46:07,960 --> 00:46:17,890
it's like the last talk for a while for

00:46:10,569 --> 00:46:20,170
me maybe maybe the last one forever no

00:46:17,890 --> 00:46:22,059
no I can say that so we were we were

00:46:20,170 --> 00:46:23,650
experimenting like I did the same thing

00:46:22,059 --> 00:46:26,140
as here with the tweet service in the

00:46:23,650 --> 00:46:28,599
experimental setup I tested open-source

00:46:26,140 --> 00:46:30,279
crawl and Anna price crawl and with open

00:46:28,599 --> 00:46:33,130
source it was like 10 11 percent right

00:46:30,279 --> 00:46:34,539
and then we got like 13 out of it when I

00:46:33,130 --> 00:46:38,859
tweaked it a little bit and with

00:46:34,539 --> 00:46:42,670
enterprise growling was 20 but a

00:46:38,859 --> 00:46:45,999
customer that's the philosophical part

00:46:42,670 --> 00:46:48,519
by the way so the question is if if I

00:46:45,999 --> 00:46:50,319
think that the source code will change

00:46:48,519 --> 00:46:54,160
so they will it will run better and

00:46:50,319 --> 00:46:58,059
growl than it does now on see to it

00:46:54,160 --> 00:47:00,460
might well so when I when I say that

00:46:58,059 --> 00:47:03,819
source code has been optimized 42 it's

00:47:00,460 --> 00:47:06,640
it almost exclusively has to do with how

00:47:03,819 --> 00:47:08,289
big methods are because inlining is the

00:47:06,640 --> 00:47:09,759
mother of all optimizations right and

00:47:08,289 --> 00:47:11,349
inlining can give you a lot of

00:47:09,759 --> 00:47:16,390
improvement or can destroy everything

00:47:11,349 --> 00:47:18,640
and so people when they did benchmarking

00:47:16,390 --> 00:47:20,859
they might have reduced method sizes so

00:47:18,640 --> 00:47:22,869
they did that they got in line or things

00:47:20,859 --> 00:47:26,920
like this and and Grassi and landing

00:47:22,869 --> 00:47:28,450
just works differently so it might

00:47:26,920 --> 00:47:31,420
change on that front I don't think

00:47:28,450 --> 00:47:34,059
they're there are any code patterns that

00:47:31,420 --> 00:47:36,579
work better on c2 or Gras yeah maybe

00:47:34,059 --> 00:47:38,170
maybe because the loop vectorization or

00:47:36,579 --> 00:47:39,729
whatever works a little differently but

00:47:38,170 --> 00:47:41,010
I don't think so I think it has more to

00:47:39,729 --> 00:47:43,230
do with the

00:47:41,010 --> 00:47:45,390
how big methods are and how the factory

00:47:43,230 --> 00:47:49,140
you know how you factor your code

00:47:45,390 --> 00:47:52,440
basically but that was always a pain

00:47:49,140 --> 00:47:56,390
point with c2 just a way the inlining is

00:47:52,440 --> 00:47:59,880
implemented in c2 it's very stupid and

00:47:56,390 --> 00:48:03,240
garage inlining policy it's much much

00:47:59,880 --> 00:48:06,540
smarter so the need for doing this

00:48:03,240 --> 00:48:09,660
should be less I hope I hope that's the

00:48:06,540 --> 00:48:11,520
outcome we have one because you've

00:48:09,660 --> 00:48:15,390
mentioned coke patterns and maybe I

00:48:11,520 --> 00:48:17,940
should mention it here we have one guy

00:48:15,390 --> 00:48:19,740
on our team Flavio he's a scholar guy

00:48:17,940 --> 00:48:21,330
right Heaton he knows calico he's not

00:48:19,740 --> 00:48:25,140
really champion guy but he knows all the

00:48:21,330 --> 00:48:28,200
Scala stuff and - he's looking at Scala

00:48:25,140 --> 00:48:30,060
patterns right now that can be optimized

00:48:28,200 --> 00:48:31,440
by Gras better because that that's

00:48:30,060 --> 00:48:32,820
important for us right the typical

00:48:31,440 --> 00:48:34,950
whatever scalloped add-ons you use every

00:48:32,820 --> 00:48:36,660
day maybe we can do something in Gras to

00:48:34,950 --> 00:48:39,780
optimize these better so we were looking

00:48:36,660 --> 00:48:42,540
at this I hope it helps

00:48:39,780 --> 00:48:44,220
we'll see so the question is if we if

00:48:42,540 --> 00:48:46,200
you're running all of our services on

00:48:44,220 --> 00:48:51,120
growler just a subset the answer today

00:48:46,200 --> 00:48:53,880
is only a subset the first well yeah

00:48:51,120 --> 00:48:55,560
almost two years I would say that when I

00:48:53,880 --> 00:48:59,190
joined Twitter especially in the first

00:48:55,560 --> 00:49:02,160
year and I you know you can imagine I I

00:48:59,190 --> 00:49:03,720
come to Twitter and then I say hey and I

00:49:02,160 --> 00:49:05,610
go to a service owner right

00:49:03,720 --> 00:49:07,590
I say hey there's this experimental

00:49:05,610 --> 00:49:10,560
chick compiler that no one's using in

00:49:07,590 --> 00:49:12,290
production would you like to try it what

00:49:10,560 --> 00:49:14,700
do you think his answer was so

00:49:12,290 --> 00:49:17,100
everything I did that Twitter in my

00:49:14,700 --> 00:49:18,750
first year was not was not software

00:49:17,100 --> 00:49:20,520
engineering it was social engineering

00:49:18,750 --> 00:49:22,710
I was hand holding a lot of people's

00:49:20,520 --> 00:49:25,560
hands they it will be fine we'll be fine

00:49:22,710 --> 00:49:28,050
so it was hard for me when I got the

00:49:25,560 --> 00:49:29,490
first big service it then it was easier

00:49:28,050 --> 00:49:31,410
because I could say hey look this big

00:49:29,490 --> 00:49:35,660
service runs fine maybe you want to try

00:49:31,410 --> 00:49:39,030
it as well so right now it's maybe 20 25

00:49:35,660 --> 00:49:41,820
services that run on gras out of

00:49:39,030 --> 00:49:44,190
hundreds but after you know as I said

00:49:41,820 --> 00:49:45,900
this is the last talk for a while the

00:49:44,190 --> 00:49:48,240
next step for us will be to switch all

00:49:45,900 --> 00:49:50,010
of them so we've we've implemented some

00:49:48,240 --> 00:49:51,630
logic internally where we can flip the

00:49:50,010 --> 00:49:52,890
switch and then all of all of our

00:49:51,630 --> 00:49:53,900
services are running on crawl that

00:49:52,890 --> 00:49:59,090
should happen in the neck

00:49:53,900 --> 00:50:04,700
a couple months and I hope I get a cut

00:49:59,090 --> 00:50:07,790
of the money savings more questions last

00:50:04,700 --> 00:50:09,320
chance or you can ask me outside if you

00:50:07,790 --> 00:50:12,639
want thank you very much

00:50:09,320 --> 00:50:12,639

YouTube URL: https://www.youtube.com/watch?v=PtgKmzgIh4c


