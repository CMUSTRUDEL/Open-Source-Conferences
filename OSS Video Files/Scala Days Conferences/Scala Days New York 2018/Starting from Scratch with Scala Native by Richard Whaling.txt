Title: Starting from Scratch with Scala Native by Richard Whaling
Publication date: 2018-09-22
Playlist: Scala Days New York 2018
Description: 
	This video was recorded at Scala Days New York 2018
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

More information and the abstract can be found here:
https://na.scaladays.org/schedule/starting-from-scratch-with-scala-native
Captions: 
	00:00:04,970 --> 00:00:10,379
starting from scratch with Scala native

00:00:07,519 --> 00:00:11,730
so this is a talk about Scala native

00:00:10,379 --> 00:00:14,880
you're in the right room if that's what

00:00:11,730 --> 00:00:16,920
you came here for it's also this is what

00:00:14,880 --> 00:00:18,900
I'm trying this time is to just give

00:00:16,920 --> 00:00:21,149
sort of an introduction to systems

00:00:18,900 --> 00:00:24,869
programming sort of from the ground

00:00:21,149 --> 00:00:27,840
floor in Scala and in Scala dated in

00:00:24,869 --> 00:00:29,520
particular right and in getting there I

00:00:27,840 --> 00:00:31,559
think it's also become a talk just about

00:00:29,520 --> 00:00:34,350
working with emerging technology Scala

00:00:31,559 --> 00:00:36,929
native is surprisingly robust but also

00:00:34,350 --> 00:00:38,640
still quite new it's also just about

00:00:36,929 --> 00:00:41,730
learning to rely on your operating

00:00:38,640 --> 00:00:44,519
system and your your soup machine itself

00:00:41,730 --> 00:00:46,949
as a platform for writing code on rather

00:00:44,519 --> 00:00:49,409
than the Java Virtual Machine and

00:00:46,949 --> 00:00:51,030
frameworks and runtimes that we've sort

00:00:49,409 --> 00:00:54,539
of come to rely on over the last couple

00:00:51,030 --> 00:00:56,609
decades or in other words this is a talk

00:00:54,539 --> 00:01:00,300
about how to get things done without the

00:00:56,609 --> 00:01:01,769
JVM so in terms of the actual content

00:01:00,300 --> 00:01:03,479
I'm gonna start with a really quick

00:01:01,769 --> 00:01:05,880
introduction this is what Scala native

00:01:03,479 --> 00:01:07,650
is and then spend a fair amount of time

00:01:05,880 --> 00:01:09,120
just talking about how to work like

00:01:07,650 --> 00:01:12,120
close to the metal like what does it

00:01:09,120 --> 00:01:14,310
mean to work at a at a lower level

00:01:12,120 --> 00:01:16,590
without a virtual machine doing work for

00:01:14,310 --> 00:01:18,360
you and then we're gonna go right from

00:01:16,590 --> 00:01:21,780
there into writing a real program with

00:01:18,360 --> 00:01:23,370
real data at scale we're gonna take the

00:01:21,780 --> 00:01:25,500
Google engrams data set which I'll talk

00:01:23,370 --> 00:01:27,750
a lot more about when we get there

00:01:25,500 --> 00:01:31,740
and work through a few simple algorithms

00:01:27,750 --> 00:01:33,360
on it sort of a maximum finder and also

00:01:31,740 --> 00:01:34,650
a sort I don't think we're gonna have

00:01:33,360 --> 00:01:37,440
time to get to the aggregation but we'll

00:01:34,650 --> 00:01:39,300
see if I go really fast and for all of

00:01:37,440 --> 00:01:41,220
the algorithms we have performance

00:01:39,300 --> 00:01:44,040
numbers comparing our Scala native

00:01:41,220 --> 00:01:46,950
implementation to a vaguely equivalent

00:01:44,040 --> 00:01:49,140
of vanilla Scala implementation so we'll

00:01:46,950 --> 00:01:51,420
have some empirical basis for looking at

00:01:49,140 --> 00:01:53,520
what we've done and that will conclude

00:01:51,420 --> 00:01:54,990
the empirical observations and then I'll

00:01:53,520 --> 00:01:57,180
wave my hands and make some wild

00:01:54,990 --> 00:02:00,570
speculations about the future and broad

00:01:57,180 --> 00:02:02,370
trends this one does about me I'm a

00:02:00,570 --> 00:02:03,960
Scala native contributor but I'm

00:02:02,370 --> 00:02:07,770
speaking only for myself here and I'm

00:02:03,960 --> 00:02:10,140
not a member of the core team and I

00:02:07,770 --> 00:02:13,230
can't speak for where Dennis or Martin

00:02:10,140 --> 00:02:15,239
see it going I am the author of modern

00:02:13,230 --> 00:02:16,760
systems programming in Scala the first

00:02:15,239 --> 00:02:19,239
book about Scala native it's come

00:02:16,760 --> 00:02:22,549
now hopefully this year from pragmatic

00:02:19,239 --> 00:02:26,000
and I'm a data engineer at m1 Finance in

00:02:22,549 --> 00:02:28,689
Chicago obligatory plug in one finance

00:02:26,000 --> 00:02:31,459
is a simple powerful free way to invest

00:02:28,689 --> 00:02:34,819
and we have an awesome app come check us

00:02:31,459 --> 00:02:38,299
out and I'm on Twitter at Richard Whalen

00:02:34,819 --> 00:02:40,069
and I tweeted out these slides I tweeted

00:02:38,299 --> 00:02:41,480
out my strange loop top from last year

00:02:40,069 --> 00:02:44,450
about how to build a web server and

00:02:41,480 --> 00:02:46,010
Scala native and while I tweet lots of

00:02:44,450 --> 00:02:48,379
animal memes and stuff too if you like

00:02:46,010 --> 00:02:51,530
animals so yeah without further ado

00:02:48,379 --> 00:02:52,970
let's get started so Scala native we

00:02:51,530 --> 00:02:56,540
love it because it's Scala

00:02:52,970 --> 00:02:59,930
right much like Scala j/s Scala native

00:02:56,540 --> 00:03:02,989
is Scala C plug-in basically it patches

00:02:59,930 --> 00:03:05,720
the Scala compiler to an LLVM byte code

00:03:02,989 --> 00:03:07,519
instead of JVM bytecode the reason that

00:03:05,720 --> 00:03:09,409
becomes an ahead of time compiler right

00:03:07,519 --> 00:03:12,590
is if for people who are less familiar

00:03:09,409 --> 00:03:14,060
with a LLVM isn't a runtime virtual

00:03:12,590 --> 00:03:16,639
machine the way the java virtual machine

00:03:14,060 --> 00:03:18,940
is it's really more of a compiler

00:03:16,639 --> 00:03:21,859
framework so it eventually generates

00:03:18,940 --> 00:03:24,799
machine bytecode the russ compiler runs

00:03:21,859 --> 00:03:29,720
on LLVM clang apple c compiler runs ILO

00:03:24,799 --> 00:03:31,549
vm etc etc this when you when you're

00:03:29,720 --> 00:03:33,260
just emitting like a compact like three

00:03:31,549 --> 00:03:35,030
or four megabyte native binary like this

00:03:33,260 --> 00:03:37,099
you get programs that start up much

00:03:35,030 --> 00:03:39,709
faster in like tens of milliseconds

00:03:37,099 --> 00:03:41,419
instead of you know sometimes seconds

00:03:39,709 --> 00:03:43,069
waiting for a JVM to boot all the way up

00:03:41,419 --> 00:03:46,819
right so for command-line tools it's

00:03:43,069 --> 00:03:48,620
great tools like Scala format Scala fix

00:03:46,819 --> 00:03:51,169
things like that or obvious low-hanging

00:03:48,620 --> 00:03:54,349
fruit for Scala native right

00:03:51,169 --> 00:03:57,199
Scala C itself has been seen running in

00:03:54,349 --> 00:03:59,209
Scala native which is pretty cool but

00:03:57,199 --> 00:04:01,730
the the trick and the trade-off with

00:03:59,209 --> 00:04:04,310
that right is that you lose the JVM a

00:04:01,730 --> 00:04:07,340
lot of the JVM facilities that you come

00:04:04,310 --> 00:04:09,949
to rely on or are gone you were lose a

00:04:07,340 --> 00:04:11,900
lot of JDK classes you definitely lose

00:04:09,949 --> 00:04:13,370
things like dynamic class loading and

00:04:11,900 --> 00:04:15,440
stuff like that so getting something

00:04:13,370 --> 00:04:16,970
like SBT to itself to run in Scala

00:04:15,440 --> 00:04:18,019
native it's probably gonna be a lot

00:04:16,970 --> 00:04:20,269
harder

00:04:18,019 --> 00:04:23,620
that said Scala native much like Scala

00:04:20,269 --> 00:04:26,719
jeaious does include implementations of

00:04:23,620 --> 00:04:30,050
several hundred JDK classes enough to

00:04:26,719 --> 00:04:31,789
make a large proportion of like relic

00:04:30,050 --> 00:04:34,220
Tivoli straightforward programs just

00:04:31,789 --> 00:04:36,229
sort of run out of the box but if

00:04:34,220 --> 00:04:38,960
something is missing you can also

00:04:36,229 --> 00:04:41,180
implement it yourself or just implement

00:04:38,960 --> 00:04:43,610
awesome other stuff like we are going to

00:04:41,180 --> 00:04:46,009
today because it provides this really

00:04:43,610 --> 00:04:48,680
amazing set of types and functions for

00:04:46,009 --> 00:04:51,319
for interoperability with with C

00:04:48,680 --> 00:04:54,639
programs but also just for writing Scala

00:04:51,319 --> 00:04:57,319
programs with broadly equivalent power

00:04:54,639 --> 00:05:00,229
to like C or rust or something like that

00:04:57,319 --> 00:05:01,699
and writing those kinds of programs is

00:05:00,229 --> 00:05:05,509
sort of what this talk focus is on

00:05:01,699 --> 00:05:07,039
rather than just hey switch your SBT at

00:05:05,509 --> 00:05:08,629
a compiler plugin and recompile your

00:05:07,039 --> 00:05:11,500
program this is about how to like really

00:05:08,629 --> 00:05:14,750
lean in to programming for Scala native

00:05:11,500 --> 00:05:17,900
so for but for the basics right like

00:05:14,750 --> 00:05:20,240
this like trivial Scala hello world this

00:05:17,900 --> 00:05:22,849
just works in Scala native this will

00:05:20,240 --> 00:05:24,050
compile it'll print out about it'll

00:05:22,849 --> 00:05:27,440
eventually it'll it'll print out a

00:05:24,050 --> 00:05:29,240
little more Diagnostics from here SBT as

00:05:27,440 --> 00:05:32,270
it's actually doing quite a lot of work

00:05:29,240 --> 00:05:33,979
to generate a native executable binary

00:05:32,270 --> 00:05:36,979
but it eventually spits out a four

00:05:33,979 --> 00:05:40,880
megabyte file that prints hello hello

00:05:36,979 --> 00:05:43,069
Scala days right however you can also go

00:05:40,880 --> 00:05:45,529
a little bit deeper you can import the

00:05:43,069 --> 00:05:47,810
Scala native dot native package and then

00:05:45,529 --> 00:05:49,400
you can import standard i/o from there

00:05:47,810 --> 00:05:51,949
and then all of a sudden you have this

00:05:49,400 --> 00:05:54,289
you have printf just so I can sort of

00:05:51,949 --> 00:05:58,099
gauge the audience who here who hears

00:05:54,289 --> 00:06:00,529
use printf cool all right

00:05:58,099 --> 00:06:03,430
yeah so this isn't like a wrapper this

00:06:00,529 --> 00:06:05,870
like I've looked at the the LLVM like

00:06:03,430 --> 00:06:08,389
intermediate code for this when you do

00:06:05,870 --> 00:06:12,379
this in Scala native it's literally

00:06:08,389 --> 00:06:14,719
invoking the the G Lib C printf function

00:06:12,379 --> 00:06:16,699
right and it's doing that because when

00:06:14,719 --> 00:06:19,190
Scala native uses types they're

00:06:16,699 --> 00:06:21,680
compatible with C which things like

00:06:19,190 --> 00:06:23,539
instant floats just work for things here

00:06:21,680 --> 00:06:25,580
we're using like C strings instead of

00:06:23,539 --> 00:06:28,520
regular strings and you'll see right

00:06:25,580 --> 00:06:30,259
that I'm I'm putting a little C in front

00:06:28,520 --> 00:06:32,539
of the string literals to tell it to

00:06:30,259 --> 00:06:35,090
build C strings that's because those are

00:06:32,539 --> 00:06:38,180
actually strings the way they work in a

00:06:35,090 --> 00:06:40,729
C program which is exactly as awful as

00:06:38,180 --> 00:06:42,910
it sounds it's have quite a few slides

00:06:40,729 --> 00:06:45,190
today to discuss

00:06:42,910 --> 00:06:48,640
but it means you can like throw around

00:06:45,190 --> 00:06:51,160
strings pass them to printf and do IO as

00:06:48,640 --> 00:06:55,360
quickly and as dangerously as one does

00:06:51,160 --> 00:06:57,160
and see for better for worse but to even

00:06:55,360 --> 00:06:58,810
like talk about how one really like

00:06:57,160 --> 00:07:00,610
writes programs like that much less

00:06:58,810 --> 00:07:02,470
writes them safely I want to just sort

00:07:00,610 --> 00:07:04,540
of take a step back and throw some of

00:07:02,470 --> 00:07:06,220
the fundamental concepts out maybe more

00:07:04,540 --> 00:07:07,510
as a refresher just because me talking

00:07:06,220 --> 00:07:09,820
for 10 minutes isn't going to be the

00:07:07,510 --> 00:07:12,550
equivalent of like a couple of weeks of

00:07:09,820 --> 00:07:13,870
coursework but III think Scala native

00:07:12,550 --> 00:07:15,490
really packages up a lot of these

00:07:13,870 --> 00:07:17,410
concepts and in a way that that's

00:07:15,490 --> 00:07:21,070
cleaner than they're usually taught so I

00:07:17,410 --> 00:07:22,600
I have high hopes so the the most

00:07:21,070 --> 00:07:24,430
important thing is that there's a pretty

00:07:22,600 --> 00:07:26,560
small number of data types that are

00:07:24,430 --> 00:07:29,080
actually primitive and so primitive of

00:07:26,560 --> 00:07:31,540
various sizes signed and unsigned floats

00:07:29,080 --> 00:07:34,300
and bytes themselves which are really

00:07:31,540 --> 00:07:36,040
just unfortunately they're signed in for

00:07:34,300 --> 00:07:38,350
compatibility with Java which is really

00:07:36,040 --> 00:07:40,410
regrettable but they're sort of the most

00:07:38,350 --> 00:07:44,140
primitive data type of them all right

00:07:40,410 --> 00:07:46,210
any unmanaged data that's outside of the

00:07:44,140 --> 00:07:48,220
domain of the garbage collector rate is

00:07:46,210 --> 00:07:49,930
going to have an address and that

00:07:48,220 --> 00:07:52,990
address can be represented by a pointer

00:07:49,930 --> 00:07:54,580
and a pointer is just any modern

00:07:52,990 --> 00:07:56,230
environment that's going to be an 8 byte

00:07:54,580 --> 00:07:58,450
unsigned integer it's just the numeric

00:07:56,230 --> 00:08:00,310
address in memory where the data happens

00:07:58,450 --> 00:08:02,140
to live because these pointers are

00:08:00,310 --> 00:08:04,720
themselves numeric data types you can do

00:08:02,140 --> 00:08:06,520
arithmetic manipulations on them and if

00:08:04,720 --> 00:08:08,470
you structure your data to support it

00:08:06,520 --> 00:08:10,419
right a huge number of things that

00:08:08,470 --> 00:08:11,890
require multiple lookups cache misses

00:08:10,419 --> 00:08:14,380
and in directions and higher-level

00:08:11,890 --> 00:08:16,900
languages are a rhythmic pointer

00:08:14,380 --> 00:08:18,430
arithmetic and sea or in Scala native

00:08:16,900 --> 00:08:20,890
which can either be done at constant

00:08:18,430 --> 00:08:24,630
time or often just computed and at

00:08:20,890 --> 00:08:27,550
compile time in fact entirely statically

00:08:24,630 --> 00:08:29,200
pointers are typed you'll see in Scala

00:08:27,550 --> 00:08:32,410
native a point pointer is just a generic

00:08:29,200 --> 00:08:34,990
it's great but you can cast them to

00:08:32,410 --> 00:08:36,580
other types that's a that's a compile

00:08:34,990 --> 00:08:38,620
time coercion right that's not like a

00:08:36,580 --> 00:08:41,740
runtime it doesn't introspect the data

00:08:38,620 --> 00:08:44,530
at all it's it's purely just changing

00:08:41,740 --> 00:08:46,360
the try to make things line up which to

00:08:44,530 --> 00:08:47,770
us Scala developers right is something

00:08:46,360 --> 00:08:49,810
to be avoided but when you're working

00:08:47,770 --> 00:08:52,990
with C api's it's often necessary a

00:08:49,810 --> 00:08:55,870
large number of legacy C api's including

00:08:52,990 --> 00:08:56,620
like the bsd sockets api just require

00:08:55,870 --> 00:09:00,279
you to

00:08:56,620 --> 00:09:01,660
like brazenly coerce tough one type to

00:09:00,279 --> 00:09:03,100
another even when they aren't in like a

00:09:01,660 --> 00:09:04,900
union or anything like that

00:09:03,100 --> 00:09:07,480
it's called tight punting and it's

00:09:04,900 --> 00:09:10,270
really painful but sometimes you have to

00:09:07,480 --> 00:09:12,760
do it and the other thing that casting

00:09:10,270 --> 00:09:15,310
does in situations like that is it lets

00:09:12,760 --> 00:09:17,410
you basically emulate a lot of the

00:09:15,310 --> 00:09:19,630
functionality and behavior of a more

00:09:17,410 --> 00:09:22,540
robust type system you can build like

00:09:19,630 --> 00:09:27,070
things that resemble Union types are

00:09:22,540 --> 00:09:28,480
more abstract types or inheritance and

00:09:27,070 --> 00:09:30,580
things like that

00:09:28,480 --> 00:09:32,230
awkwardly and I don't think were gonna

00:09:30,580 --> 00:09:33,490
get too deep into that but but you

00:09:32,230 --> 00:09:34,990
should know it's there because we will

00:09:33,490 --> 00:09:37,810
see some sort of generic programming

00:09:34,990 --> 00:09:39,220
patterns a little later on so those are

00:09:37,810 --> 00:09:40,960
the basics there's we also we need to

00:09:39,220 --> 00:09:43,779
talk about like a handful of like

00:09:40,960 --> 00:09:45,940
low-level like compound data structures

00:09:43,779 --> 00:09:48,010
the the first and probably most

00:09:45,940 --> 00:09:50,440
important one is a struct which is a lot

00:09:48,010 --> 00:09:53,470
like there's a lot like a case class or

00:09:50,440 --> 00:09:56,620
a tuple a product right named typed

00:09:53,470 --> 00:09:59,230
Fields the difference is the the order

00:09:56,620 --> 00:10:01,270
of the fields and the the size of each

00:09:59,230 --> 00:10:03,279
of those fields is static right

00:10:01,270 --> 00:10:06,580
so the addres the office of the address

00:10:03,279 --> 00:10:08,500
of any field of a struct is also again

00:10:06,580 --> 00:10:11,320
known at compile time just as an offset

00:10:08,500 --> 00:10:14,290
from the the address of the start of the

00:10:11,320 --> 00:10:16,660
struct and then you also have arrays and

00:10:14,290 --> 00:10:19,630
I think most folks are familiar with

00:10:16,660 --> 00:10:22,630
arrays and honestly arrays are not that

00:10:19,630 --> 00:10:24,730
far from from Java arrays right it's

00:10:22,630 --> 00:10:27,070
it's a it's an index sequence data

00:10:24,730 --> 00:10:30,250
structure the difference is it does

00:10:27,070 --> 00:10:33,370
refer quite directly to a particular

00:10:30,250 --> 00:10:35,980
block of contiguous memory that only

00:10:33,370 --> 00:10:38,500
contains items of the exact same type

00:10:35,980 --> 00:10:40,870
that are of the exact same size because

00:10:38,500 --> 00:10:42,970
they all occupy the exact same amount of

00:10:40,870 --> 00:10:45,300
memory you can also just compute the

00:10:42,970 --> 00:10:47,560
position of any item in your array again

00:10:45,300 --> 00:10:49,690
statically just by multiplying the size

00:10:47,560 --> 00:10:50,950
times the index that you want and will

00:10:49,690 --> 00:10:53,770
actually do that ourselves

00:10:50,950 --> 00:10:55,330
shortly again both of these are

00:10:53,770 --> 00:10:57,190
constrained that the only things you can

00:10:55,330 --> 00:10:58,959
put into these compound primitive these

00:10:57,190 --> 00:11:01,330
compound like low-level data types are

00:10:58,959 --> 00:11:03,790
other things that have like a statically

00:11:01,330 --> 00:11:06,010
known size so like primitives pointers

00:11:03,790 --> 00:11:08,380
arrays and structs basically you can't

00:11:06,010 --> 00:11:09,710
put a case class into an array for

00:11:08,380 --> 00:11:13,040
example much

00:11:09,710 --> 00:11:15,770
like or like like objects or regular

00:11:13,040 --> 00:11:17,390
classes and things like that so it ends

00:11:15,770 --> 00:11:18,770
up creating sort of a bright line and

00:11:17,390 --> 00:11:21,920
the type system between sort of the

00:11:18,770 --> 00:11:24,500
unmanaged Scala native classes and the

00:11:21,920 --> 00:11:26,899
higher-level like regular vanilla Scala

00:11:24,500 --> 00:11:28,580
classes that still have like normal

00:11:26,899 --> 00:11:31,640
semantics and garbage collection and

00:11:28,580 --> 00:11:34,790
stuff like that finally we have to talk

00:11:31,640 --> 00:11:36,350
about strings because in C and in Scala

00:11:34,790 --> 00:11:38,420
native strings are not a first-class

00:11:36,350 --> 00:11:42,200
data type a string is just a pointer to

00:11:38,420 --> 00:11:45,380
some bytes somewhere in particular you

00:11:42,200 --> 00:11:48,410
there a function like arrays but because

00:11:45,380 --> 00:11:50,779
we actually lose any runtime knowledge

00:11:48,410 --> 00:11:52,040
of the size of a race right strings are

00:11:50,779 --> 00:11:54,230
painful and dangerous

00:11:52,040 --> 00:11:57,890
to work with and figure out how to do it

00:11:54,230 --> 00:11:59,060
safely is not awesome but it's sort of

00:11:57,890 --> 00:12:00,649
the first thing you have to do to even

00:11:59,060 --> 00:12:04,520
to write a functioning hello world

00:12:00,649 --> 00:12:07,790
program so C strings work like this

00:12:04,520 --> 00:12:10,399
basically one byte per character laid

00:12:07,790 --> 00:12:12,350
out one and one after the other and the

00:12:10,399 --> 00:12:15,200
way you know where the end is is if you

00:12:12,350 --> 00:12:18,800
look at the end you have the binary 0

00:12:15,200 --> 00:12:22,610
and as the last character after the

00:12:18,800 --> 00:12:26,420
exclamation mark basically this is how C

00:12:22,610 --> 00:12:28,760
strings indicate their length you have

00:12:26,420 --> 00:12:31,250
the address of the first character in

00:12:28,760 --> 00:12:33,170
the string that's the value of the C

00:12:31,250 --> 00:12:35,930
string is in fact just the position of

00:12:33,170 --> 00:12:37,640
the first character and if you have a

00:12:35,930 --> 00:12:39,620
string manipulating function it just

00:12:37,640 --> 00:12:41,750
reads until it reaches this terminating

00:12:39,620 --> 00:12:44,060
mark and of course the way this can go

00:12:41,750 --> 00:12:46,850
horribly wrong is if you forget to add

00:12:44,060 --> 00:12:48,230
that terminating mark on to be hint your

00:12:46,850 --> 00:12:50,510
string manipulating function will

00:12:48,230 --> 00:12:52,160
happily go off the end into some unsafe

00:12:50,510 --> 00:12:53,750
piece of memory until it encounters

00:12:52,160 --> 00:12:57,470
something else that looks like a binary

00:12:53,750 --> 00:12:58,959
0 and this happens so much because the C

00:12:57,470 --> 00:13:01,670
standard library is so broken

00:12:58,959 --> 00:13:03,890
fortunately we are Scala developers and

00:13:01,670 --> 00:13:04,730
we're good at abstraction and we can do

00:13:03,890 --> 00:13:06,970
better than this

00:13:04,730 --> 00:13:11,600
and we can protect ourselves from this

00:13:06,970 --> 00:13:13,820
but I am gonna have to complain for the

00:13:11,600 --> 00:13:16,420
next 30 minutes or so under the hood

00:13:13,820 --> 00:13:19,610
like if you look at the Scala native

00:13:16,420 --> 00:13:21,770
built-ins see string is actually just a

00:13:19,610 --> 00:13:22,750
type alias for a pointer to a C

00:13:21,770 --> 00:13:24,850
character with

00:13:22,750 --> 00:13:25,780
and that it's really just an alias to a

00:13:24,850 --> 00:13:28,300
pointer to bytes

00:13:25,780 --> 00:13:30,000
it's about as primitive of a

00:13:28,300 --> 00:13:31,960
representation of a string as you get

00:13:30,000 --> 00:13:34,630
the other thing to caught is that

00:13:31,960 --> 00:13:36,460
they're mutable it doesn't really behave

00:13:34,630 --> 00:13:38,950
like a like a good well-behaved

00:13:36,460 --> 00:13:41,650
immutable string like we typically get

00:13:38,950 --> 00:13:43,390
in modern languages this also makes it

00:13:41,650 --> 00:13:46,330
really powerful for doing like zero copy

00:13:43,390 --> 00:13:50,260
IO and stuff like that but you have to

00:13:46,330 --> 00:13:52,210
be cautious with it so we can write like

00:13:50,260 --> 00:13:53,920
a simple program that shows some of

00:13:52,210 --> 00:13:56,230
these properties right where we just

00:13:53,920 --> 00:13:59,800
take a string we calculate its length

00:13:56,230 --> 00:14:01,870
with the C string length function we can

00:13:59,800 --> 00:14:03,840
print some Diagnostics about it but then

00:14:01,870 --> 00:14:07,180
we can also just sort of iterate over

00:14:03,840 --> 00:14:08,200
the the string and I think yeah there we

00:14:07,180 --> 00:14:10,480
go

00:14:08,200 --> 00:14:13,180
so the idea is once we know the length

00:14:10,480 --> 00:14:15,280
we can just iterate over the characters

00:14:13,180 --> 00:14:19,540
in it one character at a time and then

00:14:15,280 --> 00:14:21,010
we can access them by just grabbing them

00:14:19,540 --> 00:14:23,680
the way we would any other indexed

00:14:21,010 --> 00:14:26,380
sequence the difference right is because

00:14:23,680 --> 00:14:28,690
this is just a pointer dereference if

00:14:26,380 --> 00:14:31,600
you go off the end this is not gonna

00:14:28,690 --> 00:14:35,589
throw a nice clean like you know array

00:14:31,600 --> 00:14:37,930
index out of bounds exception this will

00:14:35,589 --> 00:14:39,280
might seg fault it might return garbage

00:14:37,930 --> 00:14:42,220
data from somewhere else and you're

00:14:39,280 --> 00:14:43,930
stacking your heap you want to be really

00:14:42,220 --> 00:14:47,620
cautious when you're working with arrays

00:14:43,930 --> 00:14:50,740
directly but it's also right namely fast

00:14:47,620 --> 00:14:52,750
and like in general it's gonna be

00:14:50,740 --> 00:14:53,980
constant time the other thing is that

00:14:52,750 --> 00:14:56,200
again because it's just pointer

00:14:53,980 --> 00:14:58,330
arithmetic we can do this ourselves and

00:14:56,200 --> 00:15:00,700
I'm decided to rewrite it this way just

00:14:58,330 --> 00:15:03,040
so we could just see the the two

00:15:00,700 --> 00:15:06,600
important pointer arithmetic operations

00:15:03,040 --> 00:15:08,680
at work so our codes basically the same

00:15:06,600 --> 00:15:10,420
what we're doing though is instead of

00:15:08,680 --> 00:15:11,920
just grabbing a character in one step

00:15:10,420 --> 00:15:13,630
we're doing in two steps first we're

00:15:11,920 --> 00:15:17,200
computing the address of the character

00:15:13,630 --> 00:15:19,150
at the index we care about right so we

00:15:17,200 --> 00:15:21,760
take the base address of the string and

00:15:19,150 --> 00:15:24,460
we add the offset to compute the the

00:15:21,760 --> 00:15:25,900
address of the character and then to

00:15:24,460 --> 00:15:28,660
actually get the value of the character

00:15:25,900 --> 00:15:31,540
we dereference it with the exclamation

00:15:28,660 --> 00:15:33,730
mark or bang operator it's um equivalent

00:15:31,540 --> 00:15:36,010
to the asterisk and C right for people

00:15:33,730 --> 00:15:36,370
who've seen um C or go or something like

00:15:36,010 --> 00:15:38,980
that

00:15:36,370 --> 00:15:42,550
so when we run this we'll see something

00:15:38,980 --> 00:15:45,249
like this and not to like linger over a

00:15:42,550 --> 00:15:46,749
bunch of like hexadecimal gibberish but

00:15:45,249 --> 00:15:48,339
I think this actually demonstrates some

00:15:46,749 --> 00:15:51,670
cool stuff so I just wanted to call it

00:15:48,339 --> 00:15:53,529
out first of all the string itself right

00:15:51,670 --> 00:15:57,100
like the content of the string according

00:15:53,529 --> 00:15:59,230
to string length is 12 bytes long but if

00:15:57,100 --> 00:16:01,269
you were to count the lines here there's

00:15:59,230 --> 00:16:04,149
actually 13 of them because string

00:16:01,269 --> 00:16:06,430
length does not count the terminating

00:16:04,149 --> 00:16:08,160
zero byte which is necessary for the

00:16:06,430 --> 00:16:10,839
string to function it with integrity

00:16:08,160 --> 00:16:14,019
right so there's there's 13 bytes to

00:16:10,839 --> 00:16:15,999
store a 12 by 12 bytes string it's very

00:16:14,019 --> 00:16:18,009
important to remember and then the

00:16:15,999 --> 00:16:19,509
actual value of the string itself is

00:16:18,009 --> 00:16:21,670
just a pointer which means it's the

00:16:19,509 --> 00:16:24,300
straight the the value of the string is

00:16:21,670 --> 00:16:27,160
just 8 bytes it's precisely this

00:16:24,300 --> 00:16:29,860
hexadecimal address but if you look the

00:16:27,160 --> 00:16:33,069
the address is literally the same value

00:16:29,860 --> 00:16:34,389
as the address of the first character in

00:16:33,069 --> 00:16:36,490
the string there's there's no way to

00:16:34,389 --> 00:16:38,290
distinguish those those two things are

00:16:36,490 --> 00:16:40,089
the same as far as the type system is

00:16:38,290 --> 00:16:43,240
concerned which feels a little bit like

00:16:40,089 --> 00:16:46,319
a paradox but it is surprisingly elegant

00:16:43,240 --> 00:16:48,370
once you learn how to work with it so

00:16:46,319 --> 00:16:50,199
that's enough of me talking about how

00:16:48,370 --> 00:16:53,589
terrible strings are we also need to

00:16:50,199 --> 00:16:54,939
talk about memory allocation like I was

00:16:53,589 --> 00:16:57,850
saying earlier when you're using regular

00:16:54,939 --> 00:17:00,490
Scala classes case classes things like

00:16:57,850 --> 00:17:02,079
that the Scala like Scala natives

00:17:00,490 --> 00:17:03,670
garbage collector is in full effect and

00:17:02,079 --> 00:17:05,740
it runs great when you're working with

00:17:03,670 --> 00:17:07,569
these C compatible types you can do

00:17:05,740 --> 00:17:10,329
stack allocation and heap allocation

00:17:07,569 --> 00:17:12,159
just like you would in a C program

00:17:10,329 --> 00:17:14,949
Scala native also has this really cool

00:17:12,159 --> 00:17:16,750
zone allocator which is awesome I don't

00:17:14,949 --> 00:17:18,970
have time to cover it today

00:17:16,750 --> 00:17:22,299
the neat thing that though that Scala

00:17:18,970 --> 00:17:24,130
native does that go and rust and C don't

00:17:22,299 --> 00:17:27,220
do is stack allocation is actually

00:17:24,130 --> 00:17:28,779
explicit here which is surprisingly

00:17:27,220 --> 00:17:32,500
innovative it means you don't have to do

00:17:28,779 --> 00:17:34,659
an address of operation ever and it

00:17:32,500 --> 00:17:37,179
makes you much more formal about where

00:17:34,659 --> 00:17:39,279
you're pulling pointers off the stack it

00:17:37,179 --> 00:17:42,010
makes it much harder to leak them the

00:17:39,279 --> 00:17:43,750
really thing to remember about stack

00:17:42,010 --> 00:17:45,789
allocation is that it's literally

00:17:43,750 --> 00:17:48,280
allocating some number of bytes of

00:17:45,789 --> 00:17:51,250
memory for you on the

00:17:48,280 --> 00:17:54,760
the the like machine level call stack

00:17:51,250 --> 00:17:58,270
and it is only valid until the function

00:17:54,760 --> 00:18:00,490
that allocates returns once you return

00:17:58,270 --> 00:18:02,560
that stack frame no longer exists and

00:18:00,490 --> 00:18:04,240
will get reused the next time some other

00:18:02,560 --> 00:18:07,240
function calls that deep into the stack

00:18:04,240 --> 00:18:09,100
right so leaking a pointer that just has

00:18:07,240 --> 00:18:10,750
the address of somewhere in your stack

00:18:09,100 --> 00:18:14,020
that's been clobbered a couple dozen

00:18:10,750 --> 00:18:16,060
times is a classic C programming error

00:18:14,020 --> 00:18:17,680
it's pretty hard to do in Scala native

00:18:16,060 --> 00:18:21,340
again just because we've made it

00:18:17,680 --> 00:18:23,110
explicit here also the the nice thing

00:18:21,340 --> 00:18:25,690
here is that it's taking type parameters

00:18:23,110 --> 00:18:27,280
which is a lot cleaner than good old

00:18:25,690 --> 00:18:31,860
malik which is why we should talk about

00:18:27,280 --> 00:18:34,660
malloc next who hears use malloc yeah

00:18:31,860 --> 00:18:39,880
it's it's notorious it's kind of

00:18:34,660 --> 00:18:41,890
unpleasant but it it works it's it's a

00:18:39,880 --> 00:18:44,790
lot lower level than the the way Scala

00:18:41,890 --> 00:18:47,950
native implements stack allocation it

00:18:44,790 --> 00:18:49,990
the the C the C implementation takes an

00:18:47,950 --> 00:18:51,370
integer as an argument you say hey this

00:18:49,990 --> 00:18:54,160
is how many bytes I want it gives you

00:18:51,370 --> 00:18:56,230
that many bytes back and in C it'll be a

00:18:54,160 --> 00:18:58,240
void pointer Scala native doesn't have

00:18:56,230 --> 00:19:00,280
void pointers it just has a pointer to

00:18:58,240 --> 00:19:02,650
bytes which i think is much cleaner

00:19:00,280 --> 00:19:04,870
actually but it also doesn't have any

00:19:02,650 --> 00:19:07,750
like implicit casts on that so you'll

00:19:04,870 --> 00:19:10,510
see what i'm doing here is i if i want a

00:19:07,750 --> 00:19:13,000
pointer to a buffer of three intz i'm

00:19:10,510 --> 00:19:14,890
malik three times the size of an integer

00:19:13,000 --> 00:19:16,810
and then i cast that to a pointer of

00:19:14,890 --> 00:19:19,450
integers right and that's actually a

00:19:16,810 --> 00:19:21,840
little more verbose than c is but i find

00:19:19,450 --> 00:19:24,400
it's actually a lot cleaner and safer

00:19:21,840 --> 00:19:26,500
the other thing about arrays right is

00:19:24,400 --> 00:19:28,840
these are these are index sequences but

00:19:26,500 --> 00:19:31,930
they there have a fixed size unless we

00:19:28,840 --> 00:19:34,150
manually resize them to resize them we

00:19:31,930 --> 00:19:35,830
use realloc which is usually pretty

00:19:34,150 --> 00:19:38,140
obscure but we're actually gonna use it

00:19:35,830 --> 00:19:40,950
in like about 10 minutes to sort of

00:19:38,140 --> 00:19:43,630
write a slab allocator kind of doodad

00:19:40,950 --> 00:19:46,330
basically you have to cast your your

00:19:43,630 --> 00:19:48,790
array back down to a pointer of bytes

00:19:46,330 --> 00:19:51,570
passing the new size and then cast it

00:19:48,790 --> 00:19:53,980
again so it's there's two casts there

00:19:51,570 --> 00:19:55,900
that's said again we're in scala we're

00:19:53,980 --> 00:19:57,670
good at abstraction so if we wanted to

00:19:55,900 --> 00:20:00,190
write like a he bellick function that

00:19:57,670 --> 00:20:01,440
had more like the ergonomics of stack

00:20:00,190 --> 00:20:03,389
Alec it's right here

00:20:01,440 --> 00:20:05,549
it's a one-liner you just take a type

00:20:03,389 --> 00:20:08,159
parameter how many things you want easy

00:20:05,549 --> 00:20:10,470
and you'll see we can abstract over like

00:20:08,159 --> 00:20:11,789
aggro a bull array pretty easily well in

00:20:10,470 --> 00:20:14,190
a second

00:20:11,789 --> 00:20:16,440
also realloc is dangerous you always

00:20:14,190 --> 00:20:18,120
have to free your pointers this isn't

00:20:16,440 --> 00:20:20,070
the time or space for me to continue

00:20:18,120 --> 00:20:23,820
ranting about that but I do have to say

00:20:20,070 --> 00:20:25,889
for your pointers and the last thing

00:20:23,820 --> 00:20:27,690
sort of on the sea Interop angle I want

00:20:25,889 --> 00:20:29,659
to talk about is the foreign function

00:20:27,690 --> 00:20:32,129
interface that Scala native provides

00:20:29,659 --> 00:20:34,799
which i think is really slick like I've

00:20:32,129 --> 00:20:36,870
been doing like cff I kind of stuff for

00:20:34,799 --> 00:20:39,480
most of my career and this is probably

00:20:36,870 --> 00:20:42,509
the best one I've ever used if you want

00:20:39,480 --> 00:20:45,120
to import a function from either the C

00:20:42,509 --> 00:20:47,639
standard library or just a third-party C

00:20:45,120 --> 00:20:49,379
shared library you found on github this

00:20:47,639 --> 00:20:51,809
is how you do it all you have to do is

00:20:49,379 --> 00:20:54,889
translate its signature to a Scala

00:20:51,809 --> 00:20:57,090
native signature there's a table in the

00:20:54,889 --> 00:20:59,639
in the Scala native Docs for doing the

00:20:57,090 --> 00:21:02,129
translation and then you just put it in

00:20:59,639 --> 00:21:05,220
one of these external sand supply extern

00:21:02,129 --> 00:21:06,899
for the value of it and that's literally

00:21:05,220 --> 00:21:08,909
it then when you invoke it

00:21:06,899 --> 00:21:11,159
Scala native will invoke the function

00:21:08,909 --> 00:21:13,259
you hooked it up to and it works pretty

00:21:11,159 --> 00:21:15,330
magically here I'm actually just hooking

00:21:13,259 --> 00:21:17,340
it up to some c standard library

00:21:15,330 --> 00:21:19,529
functions most of these are actually

00:21:17,340 --> 00:21:21,330
provided in the standard i/o package and

00:21:19,529 --> 00:21:24,480
most of the things you'd actually use

00:21:21,330 --> 00:21:26,279
are but like in my strange loop talk I

00:21:24,480 --> 00:21:29,970
wrote bindings for most of libuv

00:21:26,279 --> 00:21:32,610
the nodejs loop library and it's just

00:21:29,970 --> 00:21:33,990
about as simple really really powerful

00:21:32,610 --> 00:21:36,480
stuff and it really gives you super

00:21:33,990 --> 00:21:38,039
powers especially in the absence of like

00:21:36,480 --> 00:21:43,289
the JVM and the things you would

00:21:38,039 --> 00:21:45,210
otherwise rely on so probably there's a

00:21:43,289 --> 00:21:47,820
couple C functions we should talk about

00:21:45,210 --> 00:21:50,389
before we move on just so people have

00:21:47,820 --> 00:21:55,230
seen them we've seen F we've seen printf

00:21:50,389 --> 00:21:57,269
F gets is probably the only string IO

00:21:55,230 --> 00:21:59,610
reading function I would actually

00:21:57,269 --> 00:22:01,440
recommend using it reads a line of text

00:21:59,610 --> 00:22:03,539
from standard input into an array of

00:22:01,440 --> 00:22:05,309
some maximum size it takes an argument

00:22:03,539 --> 00:22:06,720
for the maximum size to read which is

00:22:05,309 --> 00:22:11,580
really good because it prevents you from

00:22:06,720 --> 00:22:13,990
overflowing off the end s scanf is sort

00:22:11,580 --> 00:22:17,260
of the the inverse of printf it

00:22:13,990 --> 00:22:20,020
data from its a formatted input function

00:22:17,260 --> 00:22:23,020
basically that reads data from string

00:22:20,020 --> 00:22:25,059
into a more structured memory and it

00:22:23,020 --> 00:22:27,100
takes a format string just like printf

00:22:25,059 --> 00:22:27,460
does we'll see some examples of it

00:22:27,100 --> 00:22:30,580
shortly

00:22:27,460 --> 00:22:32,590
and then for actual string manipulation

00:22:30,580 --> 00:22:34,330
functions we're gonna use string comp a

00:22:32,590 --> 00:22:36,880
bit just for it's a comparator it

00:22:34,330 --> 00:22:38,440
returns negative Z or positive based on

00:22:36,880 --> 00:22:39,820
whether one string is less than greater

00:22:38,440 --> 00:22:41,650
than equal to the other like any

00:22:39,820 --> 00:22:44,830
comparator would and then

00:22:41,650 --> 00:22:46,750
notoriously all of the functions in the

00:22:44,830 --> 00:22:49,120
c standard library for copying strings

00:22:46,750 --> 00:22:51,280
are broken this the string copy is the

00:22:49,120 --> 00:22:53,080
least broken one but I actually found I

00:22:51,280 --> 00:22:54,820
couldn't use it safely and there will be

00:22:53,080 --> 00:22:56,920
a wrapper around it and a couple of

00:22:54,820 --> 00:22:58,570
places where I use it here I had to cut

00:22:56,920 --> 00:23:01,960
this slide or actually what derive the

00:22:58,570 --> 00:23:02,980
wrapper but it's some whoo yeah so this

00:23:01,960 --> 00:23:05,380
is the moment where I take a breath

00:23:02,980 --> 00:23:06,790
check my time how are people doing are

00:23:05,380 --> 00:23:09,520
people feeling good about this so far or

00:23:06,790 --> 00:23:11,830
no I'm not going too fast cool so we're

00:23:09,520 --> 00:23:14,260
gonna write some real programs now this

00:23:11,830 --> 00:23:16,510
systems programming is never trivial but

00:23:14,260 --> 00:23:18,160
I I mean the reason I'm writing a book

00:23:16,510 --> 00:23:19,960
about this is that I do believe that

00:23:18,160 --> 00:23:23,050
Scala native does present it in a way

00:23:19,960 --> 00:23:24,790
that's actually more clear than see that

00:23:23,050 --> 00:23:26,770
working of the language that really

00:23:24,790 --> 00:23:31,450
supports type parameters is a real thing

00:23:26,770 --> 00:23:33,730
make makes it work also Scala natives

00:23:31,450 --> 00:23:35,770
compiler is totally state of the art I

00:23:33,730 --> 00:23:37,660
think like Thursday or Friday dentist

00:23:35,770 --> 00:23:40,090
weeded out some numbers for the new

00:23:37,660 --> 00:23:43,450
optimizer that are sort of breathtaking

00:23:40,090 --> 00:23:46,000
it's moving really fast but I get really

00:23:43,450 --> 00:23:48,429
excited where Scala native lets you

00:23:46,000 --> 00:23:50,350
write programs that you couldn't with

00:23:48,429 --> 00:23:52,630
vanilla Scala where you're really like

00:23:50,350 --> 00:23:55,000
opening up the hood and working in a

00:23:52,630 --> 00:23:56,440
fundamentally lower level which isn't

00:23:55,000 --> 00:23:59,650
something that a compiler really gives

00:23:56,440 --> 00:24:03,070
you in treating Scala native as a DSL

00:23:59,650 --> 00:24:05,890
for writing C in some ways is sort of

00:24:03,070 --> 00:24:07,420
where we're where my heart is and it's

00:24:05,890 --> 00:24:09,640
gonna let us write programs that are

00:24:07,420 --> 00:24:10,809
pretty pretty different but also have

00:24:09,640 --> 00:24:14,260
some interesting performance

00:24:10,809 --> 00:24:16,660
characteristics so to show that though

00:24:14,260 --> 00:24:21,610
we need some real data Google Ingram's

00:24:16,660 --> 00:24:23,740
is this 50 megabyte data set that's word

00:24:21,610 --> 00:24:27,530
counts for the entire Google books

00:24:23,740 --> 00:24:29,360
corpus it's tab delimited text files for

00:24:27,530 --> 00:24:31,130
zishe they're separated by the first

00:24:29,360 --> 00:24:32,990
letter of a given word so like just the

00:24:31,130 --> 00:24:35,870
the a where it's as two gigabytes and

00:24:32,990 --> 00:24:39,530
that's what I'm gonna use today just in

00:24:35,870 --> 00:24:40,430
the interest of sanity and we're just

00:24:39,530 --> 00:24:42,800
going to write some pretty simple

00:24:40,430 --> 00:24:44,750
algorithms that work on this non-trivial

00:24:42,800 --> 00:24:46,790
data set and see how it scales as we

00:24:44,750 --> 00:24:49,100
throw more data at it basically so like

00:24:46,790 --> 00:24:51,440
we're gonna find the maximum word word

00:24:49,100 --> 00:24:52,610
count we're gonna find the top 20 which

00:24:51,440 --> 00:24:54,500
is actually a so we're gonna treat that

00:24:52,610 --> 00:24:56,300
as a sorting problem I don't think we

00:24:54,500 --> 00:24:56,840
have the time to mix sorting and

00:24:56,300 --> 00:24:58,370
aggregation

00:24:56,840 --> 00:25:00,050
that's oh there's a really cool like

00:24:58,370 --> 00:25:02,740
sort of in-place accumulation hack you

00:25:00,050 --> 00:25:04,940
can do there the files look like this

00:25:02,740 --> 00:25:06,770
they have the word a lot of the words

00:25:04,940 --> 00:25:08,390
have part of speech tags this isn't an

00:25:06,770 --> 00:25:11,180
NLP talk so ignore the part of speech

00:25:08,390 --> 00:25:12,980
tags it has the year it has the count

00:25:11,180 --> 00:25:14,720
and then the last column is the dot

00:25:12,980 --> 00:25:16,970
count the number of books in which it

00:25:14,720 --> 00:25:19,340
occurs which you'd need for like tf-idf

00:25:16,970 --> 00:25:20,660
this is an information retrieval talk so

00:25:19,340 --> 00:25:23,240
we're gonna parse it but we can ignore

00:25:20,660 --> 00:25:24,860
it the the one we care about is the

00:25:23,240 --> 00:25:28,370
actual number of occurrences that third

00:25:24,860 --> 00:25:30,320
column there so I'm gonna say if we're

00:25:28,370 --> 00:25:32,990
gonna write like the most naive like

00:25:30,320 --> 00:25:34,790
vanilla Java implementation of like how

00:25:32,990 --> 00:25:35,870
to find the the maximum word and a file

00:25:34,790 --> 00:25:37,850
like that it would look something like

00:25:35,870 --> 00:25:41,180
this if we're not being especially

00:25:37,850 --> 00:25:43,610
idiomatic and using VARs and mutating

00:25:41,180 --> 00:25:46,520
state and all that just walk through

00:25:43,610 --> 00:25:50,480
standard in split things on whitespace

00:25:46,520 --> 00:25:52,790
um convert the count to an integer and

00:25:50,480 --> 00:25:56,090
then just compare our count and mutate

00:25:52,790 --> 00:25:58,420
our state when necessary and this this

00:25:56,090 --> 00:26:02,870
works it's not super fast but it works

00:25:58,420 --> 00:26:04,610
to do this in Scala native we actually

00:26:02,870 --> 00:26:06,350
we should strategize with Boyer write

00:26:04,610 --> 00:26:07,640
code like this when you're working close

00:26:06,350 --> 00:26:10,220
to the metal and managing memory

00:26:07,640 --> 00:26:12,170
yourself it's incredibly important that

00:26:10,220 --> 00:26:13,820
you have a plan of attack and a

00:26:12,170 --> 00:26:15,560
discipline guiding the way you're using

00:26:13,820 --> 00:26:16,910
memory before you write your first line

00:26:15,560 --> 00:26:19,600
of code once you have that strategy in

00:26:16,910 --> 00:26:22,670
place it's a bit tedious but it works

00:26:19,600 --> 00:26:25,100
our plan is to only allocate enough

00:26:22,670 --> 00:26:27,110
memory for the current maximum that

00:26:25,100 --> 00:26:28,580
we've seen and for us the single line of

00:26:27,110 --> 00:26:30,500
current input that's all we need to

00:26:28,580 --> 00:26:32,600
allocate right and then we're just going

00:26:30,500 --> 00:26:34,520
to recycle that data as we go and try to

00:26:32,600 --> 00:26:36,770
get our allocations as far down as we

00:26:34,520 --> 00:26:39,590
can right because we're gonna have to

00:26:36,770 --> 00:26:41,390
parse two gigabytes of data about 86

00:26:39,590 --> 00:26:43,970
million rows

00:26:41,390 --> 00:26:45,620
so avoiding allocating 86 million

00:26:43,970 --> 00:26:48,500
strings right is going to give us a lot

00:26:45,620 --> 00:26:51,260
of performance so the idea is we're

00:26:48,500 --> 00:26:51,890
going to use F gets we're gonna read one

00:26:51,260 --> 00:26:54,170
line at a time

00:26:51,890 --> 00:26:56,390
from standard input into our line buffer

00:26:54,170 --> 00:26:59,300
we're just gonna cap it at a thousand 24

00:26:56,390 --> 00:27:00,740
characters to be safe and F gets returns

00:26:59,300 --> 00:27:03,530
to know when it's done so this will just

00:27:00,740 --> 00:27:05,660
read until it reads everything and this

00:27:03,530 --> 00:27:09,350
is a weird little C idiom that I wanted

00:27:05,660 --> 00:27:12,740
to call out so one thing you can do with

00:27:09,350 --> 00:27:14,420
with pointers and C's you can treat them

00:27:12,740 --> 00:27:17,630
like arrays right but you can also just

00:27:14,420 --> 00:27:19,520
treat them as mutable cells and passing

00:27:17,630 --> 00:27:22,310
a pointer into a function that doesn't

00:27:19,520 --> 00:27:23,930
return anything in idiomatic C right as

00:27:22,310 --> 00:27:25,430
a way to indicate I'm passing these

00:27:23,930 --> 00:27:27,290
things in especially if it's

00:27:25,430 --> 00:27:29,840
uninitialized because it may or may not

00:27:27,290 --> 00:27:32,600
get overwritten while it's while this

00:27:29,840 --> 00:27:33,560
function executes and it might be in a

00:27:32,600 --> 00:27:34,180
different state when this function

00:27:33,560 --> 00:27:37,580
returns

00:27:34,180 --> 00:27:40,550
so to avoid allocation what we're gonna

00:27:37,580 --> 00:27:43,880
do is we're going to allocate the count

00:27:40,550 --> 00:27:46,070
the word and the year outside of our

00:27:43,880 --> 00:27:47,900
actual like scan and compare function

00:27:46,070 --> 00:27:49,940
that's that's parsing them and we're

00:27:47,900 --> 00:27:52,900
actually gonna do the comparison inside

00:27:49,940 --> 00:27:56,150
there and a sign back out which is a

00:27:52,900 --> 00:27:57,770
very idiomatically like in c territory

00:27:56,150 --> 00:27:59,990
here in the next example we're gonna go

00:27:57,770 --> 00:28:03,320
a little cleaner but I did want to like

00:27:59,990 --> 00:28:04,790
really do it one for one port here the

00:28:03,320 --> 00:28:07,040
scan and compare function ends up being

00:28:04,790 --> 00:28:10,190
about as long as the main routine we

00:28:07,040 --> 00:28:14,420
have to stack allocated ghin right just

00:28:10,190 --> 00:28:16,220
to get temporary storage for the account

00:28:14,420 --> 00:28:17,390
the word of the year the cool thing with

00:28:16,220 --> 00:28:19,220
stack allocation though is it's

00:28:17,390 --> 00:28:21,680
basically free you're just bumping a

00:28:19,220 --> 00:28:23,810
stack pointer and in general the

00:28:21,680 --> 00:28:25,820
compiler knows exactly how much memory

00:28:23,810 --> 00:28:28,070
is getting allocated for the invocation

00:28:25,820 --> 00:28:31,100
of this function so it's it's about as

00:28:28,070 --> 00:28:35,690
free as allocation gets we're gonna use

00:28:31,100 --> 00:28:37,940
scanf to just scan directly into the

00:28:35,690 --> 00:28:39,950
pointers that we've allocated here this

00:28:37,940 --> 00:28:41,960
temp word temp count temp year and tempo

00:28:39,950 --> 00:28:44,360
dot count we have to check that we

00:28:41,960 --> 00:28:46,610
matched four things because scanf is

00:28:44,360 --> 00:28:52,100
insane and instead of having exceptions

00:28:46,610 --> 00:28:55,310
it will happily just give you partial or

00:28:52,100 --> 00:28:56,900
garbage data but that's a whole

00:28:55,310 --> 00:28:58,340
and then once we have it in our

00:28:56,900 --> 00:29:00,590
temporary storage then we can actually

00:28:58,340 --> 00:29:04,070
do our comparison and decide how to

00:29:00,590 --> 00:29:05,960
update the the permanent storage and

00:29:04,070 --> 00:29:07,760
this is actually worth stepping through

00:29:05,960 --> 00:29:10,880
a little bit because it's a idiomatic

00:29:07,760 --> 00:29:12,830
we're we're doing a dereference on both

00:29:10,880 --> 00:29:15,640
the left hand side and the right hand

00:29:12,830 --> 00:29:19,040
side of an assignment right we're saying

00:29:15,640 --> 00:29:22,220
dereference max count equals dereference

00:29:19,040 --> 00:29:25,010
temp count what that means is that it's

00:29:22,220 --> 00:29:27,920
going to first dereference the the

00:29:25,010 --> 00:29:30,080
pointer temp count to get the value that

00:29:27,920 --> 00:29:33,620
we've read into the pointer and then

00:29:30,080 --> 00:29:36,650
it's going to assign that to the memory

00:29:33,620 --> 00:29:39,380
pointed at by the max count pointer

00:29:36,650 --> 00:29:42,200
right so so basically it's dereferencing

00:29:39,380 --> 00:29:44,210
one mutable cell and storing into the

00:29:42,200 --> 00:29:46,010
location indicated by another mutable

00:29:44,210 --> 00:29:48,800
cell that works for counting year

00:29:46,010 --> 00:29:50,960
because they're both numeric and atomic

00:29:48,800 --> 00:29:53,840
values if we were to try to do that with

00:29:50,960 --> 00:29:55,430
a string though we wouldn't get the

00:29:53,840 --> 00:29:57,410
behavior we want a string is just a

00:29:55,430 --> 00:30:00,080
pointer to bytes so when we dereference

00:29:57,410 --> 00:30:02,690
a string the result of dereference of

00:30:00,080 --> 00:30:05,270
just a an exclamation dereference or an

00:30:02,690 --> 00:30:06,620
asterisk dereference of a string is just

00:30:05,270 --> 00:30:08,870
gonna be the first character of the

00:30:06,620 --> 00:30:10,730
string and then it's gonna store that at

00:30:08,870 --> 00:30:12,620
the address of the first character of

00:30:10,730 --> 00:30:15,080
the destination string not what we want

00:30:12,620 --> 00:30:18,500
it all this is where we have to use a

00:30:15,080 --> 00:30:20,530
string copying function and all the

00:30:18,500 --> 00:30:23,450
standard ones are broken so I wrapped it

00:30:20,530 --> 00:30:25,190
but I'll have to save that for another

00:30:23,450 --> 00:30:27,170
time because I just I'm a little behind

00:30:25,190 --> 00:30:30,410
and I don't think I can show you how how

00:30:27,170 --> 00:30:31,910
to wrap it but straight I really want to

00:30:30,410 --> 00:30:35,600
replace the entire C standard string

00:30:31,910 --> 00:30:37,280
library so once we once we've written

00:30:35,600 --> 00:30:40,130
this we're basically ready to write our

00:30:37,280 --> 00:30:42,140
code and when you run this on like a

00:30:40,130 --> 00:30:44,570
hundred megabytes of data the performant

00:30:42,140 --> 00:30:47,270
Scala Natives a little bit faster all of

00:30:44,570 --> 00:30:49,910
these numbers I cut out the JVM startup

00:30:47,270 --> 00:30:51,680
time I didn't start the timing until

00:30:49,910 --> 00:30:53,660
after the JVM was fully booted and

00:30:51,680 --> 00:30:54,950
actually executing Scala code right so

00:30:53,660 --> 00:30:57,920
we're actually giving the JVM of

00:30:54,950 --> 00:30:59,450
moderately unfair advantage here natives

00:30:57,920 --> 00:31:02,360
still beats it with a hundred megabytes

00:30:59,450 --> 00:31:05,860
of data at rant natives in like 4.7

00:31:02,360 --> 00:31:08,160
seconds JVM is in like five point four

00:31:05,860 --> 00:31:09,810
but this actually diverges

00:31:08,160 --> 00:31:13,050
we throw more data into it so by the

00:31:09,810 --> 00:31:16,500
time we're at 500 megabytes of data the

00:31:13,050 --> 00:31:18,720
JVM is in about 29 seconds natives at 15

00:31:16,500 --> 00:31:20,310
seconds so twice as fast by the time you

00:31:18,720 --> 00:31:23,220
get up to 1100 megabytes

00:31:20,310 --> 00:31:27,240
Java's 90 seconds native is 30 seconds

00:31:23,220 --> 00:31:29,970
by the time you get to 1700 basically

00:31:27,240 --> 00:31:33,270
the whole file the JVM is running it at

00:31:29,970 --> 00:31:35,790
a 186 seconds that's three minutes and

00:31:33,270 --> 00:31:37,800
natives in 43 seconds about four times

00:31:35,790 --> 00:31:40,290
faster so you see it's we're not talking

00:31:37,800 --> 00:31:41,790
Oh native is five percent faster than

00:31:40,290 --> 00:31:43,320
hotspot or 10 percent faster we're

00:31:41,790 --> 00:31:47,340
really talking about things that

00:31:43,320 --> 00:31:49,650
diverged over over time that look pretty

00:31:47,340 --> 00:31:51,330
nonlinear to me honestly so this is

00:31:49,650 --> 00:31:53,310
exciting but it's also a little trivial

00:31:51,330 --> 00:31:55,940
right we're doing almost no allocations

00:31:53,310 --> 00:31:58,800
we're sort of using some weird C idioms

00:31:55,940 --> 00:32:01,290
and we're a little bit off you couldn't

00:31:58,800 --> 00:32:03,750
think of a better example for native

00:32:01,290 --> 00:32:04,620
kicking the je viens but it's a part to

00:32:03,750 --> 00:32:06,480
use strong language

00:32:04,620 --> 00:32:09,120
so let's come up with something a little

00:32:06,480 --> 00:32:11,490
a little maybe that tests some different

00:32:09,120 --> 00:32:14,310
conditions I guess now we're gonna sort

00:32:11,490 --> 00:32:16,050
the exact same file this is gonna use

00:32:14,310 --> 00:32:18,120
heat much more intensively this doesn't

00:32:16,050 --> 00:32:20,060
generate garbage right it's just reading

00:32:18,120 --> 00:32:23,190
a bunch of data and keeping it around

00:32:20,060 --> 00:32:24,930
and that's the inverse of the

00:32:23,190 --> 00:32:28,440
performance characteristics of the last

00:32:24,930 --> 00:32:30,450
program rewrote to solve this well to do

00:32:28,440 --> 00:32:32,310
this in Java I'm just going to use an

00:32:30,450 --> 00:32:33,960
array buffer I'm gonna create it I'm

00:32:32,310 --> 00:32:35,880
gonna actually create an in Graham case

00:32:33,960 --> 00:32:37,950
class to store these things and model

00:32:35,880 --> 00:32:41,460
them but otherwise the codes pretty much

00:32:37,950 --> 00:32:44,160
the same and then for the the actual

00:32:41,460 --> 00:32:47,490
sorting code just sorted sorting the

00:32:44,160 --> 00:32:50,460
array buffer right doing this a native

00:32:47,490 --> 00:32:52,440
is again we I want to be strategic we're

00:32:50,460 --> 00:32:54,900
gonna create a struct to model our

00:32:52,440 --> 00:32:56,310
engrams we talked about strips but I

00:32:54,900 --> 00:32:58,260
didn't show you the syntax I'll show you

00:32:56,310 --> 00:33:00,150
that really quick we're gonna read that

00:32:58,260 --> 00:33:01,710
into an array and of course we're gonna

00:33:00,150 --> 00:33:03,180
have to resize that array as we go

00:33:01,710 --> 00:33:04,830
because we don't know how many things

00:33:03,180 --> 00:33:07,530
we're going to read that's kind of

00:33:04,830 --> 00:33:09,660
tricky to do but we'll see that we can

00:33:07,530 --> 00:33:11,370
wrap it and make it same and then we're

00:33:09,660 --> 00:33:13,320
gonna sort it to do that we're gonna

00:33:11,370 --> 00:33:15,000
need not just structs and Malik and

00:33:13,320 --> 00:33:17,160
realloc we're also going to need Q sort

00:33:15,000 --> 00:33:19,140
the C standard library quicksort

00:33:17,160 --> 00:33:21,270
function which is really fast and really

00:33:19,140 --> 00:33:24,390
powerful a little tricky to use

00:33:21,270 --> 00:33:26,760
but awesome just really quickly structs

00:33:24,390 --> 00:33:28,830
work like this in the current release of

00:33:26,760 --> 00:33:30,630
Scala native struct fields aren't named

00:33:28,830 --> 00:33:31,920
they're treated more like tuples that's

00:33:30,630 --> 00:33:34,770
changing

00:33:31,920 --> 00:33:36,330
whenever the interrupt 2.0 version which

00:33:34,770 --> 00:33:38,670
I think is the Oh dot for release comes

00:33:36,330 --> 00:33:41,460
out and then the structs will have named

00:33:38,670 --> 00:33:43,470
fields like case classes The Strokes

00:33:41,460 --> 00:33:44,700
we're using here small so it's not

00:33:43,470 --> 00:33:46,830
something we really need to worry about

00:33:44,700 --> 00:33:47,910
but just to call out is something that

00:33:46,830 --> 00:33:50,520
might be a little odd if you look

00:33:47,910 --> 00:33:53,670
closely at the code and just reminding

00:33:50,520 --> 00:33:56,550
that the the the fields are laid out in

00:33:53,670 --> 00:33:58,680
contiguous memory like literally like

00:33:56,550 --> 00:34:00,210
one one one byte after the other which

00:33:58,680 --> 00:34:04,350
turns out to be really great for like

00:34:00,210 --> 00:34:07,200
cache locality and stuff like that then

00:34:04,350 --> 00:34:09,240
yeah - so it actually model our Engram

00:34:07,200 --> 00:34:12,000
is a struct we just do it like this it's

00:34:09,240 --> 00:34:14,880
a struct containing a C string and three

00:34:12,000 --> 00:34:16,409
intz the one thing that's tricky is that

00:34:14,880 --> 00:34:18,270
string right because it's a string of

00:34:16,409 --> 00:34:20,700
variable length you can't really fit a

00:34:18,270 --> 00:34:22,800
string of variable length inside the

00:34:20,700 --> 00:34:26,130
contiguous memory of a structure that

00:34:22,800 --> 00:34:28,380
has a known and fixed length the the way

00:34:26,130 --> 00:34:30,210
you get out of that right is the struct

00:34:28,380 --> 00:34:32,130
is only containing the pointer to the

00:34:30,210 --> 00:34:32,940
address of where the actual string

00:34:32,130 --> 00:34:35,429
content lives

00:34:32,940 --> 00:34:37,500
it contains exactly eight bytes in the

00:34:35,429 --> 00:34:38,970
struct for that address and then I as

00:34:37,500 --> 00:34:42,060
the programmer am responsible for

00:34:38,970 --> 00:34:44,640
somehow or another allocating some some

00:34:42,060 --> 00:34:48,360
space for the string somewhere else and

00:34:44,640 --> 00:34:50,010
we'll see different ways to do that but

00:34:48,360 --> 00:34:51,240
the other thing is these strings are

00:34:50,010 --> 00:34:54,060
going to need a need to outlive the

00:34:51,240 --> 00:34:56,640
function that reads and parses them so

00:34:54,060 --> 00:34:59,310
we are gonna use heap memory and malloc

00:34:56,640 --> 00:35:01,860
and and it's prints for doing this so

00:34:59,310 --> 00:35:03,270
we're gonna try to just wrap malloc with

00:35:01,860 --> 00:35:05,280
this like wrapped array class I just

00:35:03,270 --> 00:35:08,760
sort of sort of wrote for this it's just

00:35:05,280 --> 00:35:10,950
gonna store a pointer to our array it's

00:35:08,760 --> 00:35:12,630
going to store the number of items

00:35:10,950 --> 00:35:15,860
currently used and also the number of

00:35:12,630 --> 00:35:18,510
items currently allocated thank you and

00:35:15,860 --> 00:35:20,490
basically by tracking the number the the

00:35:18,510 --> 00:35:22,230
usage and the allocation separately it

00:35:20,490 --> 00:35:24,600
allows us to over allocate which allows

00:35:22,230 --> 00:35:25,260
us to invoke realloc much less

00:35:24,600 --> 00:35:27,360
frequently

00:35:25,260 --> 00:35:29,460
the thing with realloc is because arrays

00:35:27,360 --> 00:35:31,170
do have to be in a single contiguous

00:35:29,460 --> 00:35:32,670
region of memory if there's some other

00:35:31,170 --> 00:35:34,300
thing on the other side of them that's

00:35:32,670 --> 00:35:36,130
blocking you from growing into that's

00:35:34,300 --> 00:35:37,450
face it will just have to be copied and

00:35:36,130 --> 00:35:39,970
relocated somewhere else that can be

00:35:37,450 --> 00:35:41,710
quite expensive I've seen it take 50 60

00:35:39,970 --> 00:35:43,180
milliseconds which is no garbage

00:35:41,710 --> 00:35:45,010
collection pause but if we're doing at

00:35:43,180 --> 00:35:47,410
86 million times you don't want to eat

00:35:45,010 --> 00:35:49,150
that cost 86 million times so instead

00:35:47,410 --> 00:35:51,250
we're going to grow by very large chunks

00:35:49,150 --> 00:35:53,590
so basically we can have a tiny little

00:35:51,250 --> 00:35:55,540
factory helper and a wrapper around

00:35:53,590 --> 00:35:57,820
realloc that hides some of the cast

00:35:55,540 --> 00:35:59,260
stain and the tape type parameters I'm a

00:35:57,820 --> 00:36:02,710
little behind time so I think I have to

00:35:59,260 --> 00:36:04,690
go quick Q sort is also worth looking at

00:36:02,710 --> 00:36:06,130
quickly though this is as close to C

00:36:04,690 --> 00:36:09,370
gets to generic programming pattern

00:36:06,130 --> 00:36:10,960
patterns in that it'll sort an array of

00:36:09,370 --> 00:36:13,030
any type you care to throw at it

00:36:10,960 --> 00:36:14,530
but instead of taking like a type

00:36:13,030 --> 00:36:16,720
parameter like a scholar method would

00:36:14,530 --> 00:36:19,000
instead it just takes a pointer to bytes

00:36:16,720 --> 00:36:21,010
but it also takes the number of items as

00:36:19,000 --> 00:36:22,510
well as the size of each item and then

00:36:21,010 --> 00:36:24,190
you pass in a comparator which is

00:36:22,510 --> 00:36:26,170
actually a function pointer C of course

00:36:24,190 --> 00:36:27,760
has function pointers but Scala makes

00:36:26,170 --> 00:36:29,590
them so much easier to work with and

00:36:27,760 --> 00:36:31,360
then the comparator is actually

00:36:29,590 --> 00:36:33,580
responsible for doing the casting from

00:36:31,360 --> 00:36:36,250
pointer bite back up to whatever actual

00:36:33,580 --> 00:36:38,500
type so if we want to sort our engrams

00:36:36,250 --> 00:36:40,870
by descending by count we do it like

00:36:38,500 --> 00:36:44,830
this I don't have time to to linger on

00:36:40,870 --> 00:36:47,320
this unfortunately go a little slow so I

00:36:44,830 --> 00:36:50,230
went really aggressive and allocated a

00:36:47,320 --> 00:36:52,660
million items at a time so we're gonna

00:36:50,230 --> 00:36:55,540
allocate about 20 megabytes in chunks

00:36:52,660 --> 00:36:57,340
but we have two gigabytes of data to

00:36:55,540 --> 00:37:00,130
hold around so I actually think that's a

00:36:57,340 --> 00:37:03,250
fair optimization and otherwise the data

00:37:00,130 --> 00:37:05,950
is pretty similar we we iterate over F

00:37:03,250 --> 00:37:07,360
get over standard in with F gets we

00:37:05,950 --> 00:37:08,350
check to see if we need to grow the

00:37:07,360 --> 00:37:10,060
array we do

00:37:08,350 --> 00:37:12,970
and once we've ensured that we have

00:37:10,060 --> 00:37:14,410
space we can parse and I'm gonna write

00:37:12,970 --> 00:37:18,040
the parse line function in the next

00:37:14,410 --> 00:37:20,770
slide we can parse directly into the

00:37:18,040 --> 00:37:23,440
block of memory indicated by the the

00:37:20,770 --> 00:37:26,280
next free item in the array which is

00:37:23,440 --> 00:37:28,510
just a ray dot data plus array dot used

00:37:26,280 --> 00:37:30,400
sort of sort of awesome when the pointer

00:37:28,510 --> 00:37:32,410
arithmetic is is clean and actually

00:37:30,400 --> 00:37:34,360
works like this once our air is filled

00:37:32,410 --> 00:37:38,740
up we just call Q sort and then print it

00:37:34,360 --> 00:37:40,900
out so yeah I was surprised by how

00:37:38,740 --> 00:37:42,820
little code that took actually and then

00:37:40,900 --> 00:37:46,300
parse line is actually easier than our

00:37:42,820 --> 00:37:48,260
parsing exam from the last example I in

00:37:46,300 --> 00:37:50,810
fact I'm taking 4x

00:37:48,260 --> 00:37:52,910
just to break the fields up just to get

00:37:50,810 --> 00:37:56,480
around the tuple and like tuple notation

00:37:52,910 --> 00:37:58,940
I'm literally using scanf directly into

00:37:56,480 --> 00:38:01,550
the array so it's just reading them

00:37:58,940 --> 00:38:03,710
right into right into place one cool

00:38:01,550 --> 00:38:06,860
thing that's standard see now is you can

00:38:03,710 --> 00:38:09,470
ask scanf to malloc string storage for

00:38:06,860 --> 00:38:11,320
you at this MS modifier which is a

00:38:09,470 --> 00:38:14,180
really cool little trick and made this

00:38:11,320 --> 00:38:18,920
way faster rate and easier to fit into

00:38:14,180 --> 00:38:20,780
some slides so how does this perform so

00:38:18,920 --> 00:38:23,660
they're they're within a few hundred

00:38:20,780 --> 00:38:25,700
milliseconds initially the JVM actually

00:38:23,660 --> 00:38:28,100
does the sort faster but native catches

00:38:25,700 --> 00:38:32,000
up to it on i/o native wins by a

00:38:28,100 --> 00:38:35,300
fraction right but they again native

00:38:32,000 --> 00:38:38,420
continues to sort of win as we throw

00:38:35,300 --> 00:38:40,280
more data into it and it's not actually

00:38:38,420 --> 00:38:45,440
until you get to about 700 gigabytes

00:38:40,280 --> 00:38:47,660
that native sorting is actually slow is

00:38:45,440 --> 00:38:50,060
actually faster than the JVM the JVM is

00:38:47,660 --> 00:38:51,530
really good at tight inner

00:38:50,060 --> 00:38:54,950
loops that are running millions of times

00:38:51,530 --> 00:38:57,470
comparing integers right and it's it's

00:38:54,950 --> 00:39:00,920
going to be hard for any t fully t

00:38:57,470 --> 00:39:03,410
compiled program to be a tight inner

00:39:00,920 --> 00:39:06,590
loop in a quicksort right but if you

00:39:03,410 --> 00:39:08,450
give it enough data we can and here

00:39:06,590 --> 00:39:10,310
what's really interesting is how this

00:39:08,450 --> 00:39:13,640
goes off the totally goes off the charts

00:39:10,310 --> 00:39:15,680
as we proceed and after I got to about

00:39:13,640 --> 00:39:18,320
eleven hundred megabytes the file

00:39:15,680 --> 00:39:21,410
wouldn't sort on my laptop with like

00:39:18,320 --> 00:39:23,570
seven gigabyte docker BM whereas native

00:39:21,410 --> 00:39:25,070
it still it's slowed down a bit sorting

00:39:23,570 --> 00:39:27,500
is not linear and it's not going to be

00:39:25,070 --> 00:39:29,720
linear but it still maintains consistent

00:39:27,500 --> 00:39:32,030
performance even as the heat grows quite

00:39:29,720 --> 00:39:35,270
large so I was I was pretty happy with

00:39:32,030 --> 00:39:38,330
that I love this really neat aggregation

00:39:35,270 --> 00:39:39,770
example I don't think I have time for it

00:39:38,330 --> 00:39:42,170
in fact I know I don't have time for it

00:39:39,770 --> 00:39:43,850
the cool thing is that if you pre

00:39:42,170 --> 00:39:45,500
aggregate your data to get the size of

00:39:43,850 --> 00:39:48,890
the array down by two orders of

00:39:45,500 --> 00:39:51,080
magnitude native starts winning the sort

00:39:48,890 --> 00:39:52,970
performance again even at the smaller

00:39:51,080 --> 00:39:55,850
data sizes because it's not giving the

00:39:52,970 --> 00:39:58,430
JVM time to warm up actually which I

00:39:55,850 --> 00:40:01,110
thought was a neat little finding but

00:39:58,430 --> 00:40:03,090
again similar trends

00:40:01,110 --> 00:40:06,210
and a fun application of allocation

00:40:03,090 --> 00:40:07,710
hacks so that concludes the empirical

00:40:06,210 --> 00:40:08,610
portions of my talk now I get to weigh

00:40:07,710 --> 00:40:10,080
of my hands and make vague

00:40:08,610 --> 00:40:14,880
generalizations which is my favorite

00:40:10,080 --> 00:40:17,040
part so but III think there's a pretty

00:40:14,880 --> 00:40:20,040
clear like argument I'm making here that

00:40:17,040 --> 00:40:22,710
there are benefits to using a C style

00:40:20,040 --> 00:40:24,570
memory model within the context of a

00:40:22,710 --> 00:40:25,560
larger garbage-collected programming

00:40:24,570 --> 00:40:27,090
environment I'm not saying we should

00:40:25,560 --> 00:40:28,440
only write code like this but they're

00:40:27,090 --> 00:40:30,000
clearly cases where it makes a

00:40:28,440 --> 00:40:33,180
significant difference and not an

00:40:30,000 --> 00:40:36,330
incremental one and also that the the

00:40:33,180 --> 00:40:37,680
JVM s memory model doesn't seem like it

00:40:36,330 --> 00:40:39,270
works really well when you're doing a

00:40:37,680 --> 00:40:43,770
lot of i/o and you have a really big

00:40:39,270 --> 00:40:46,080
heap which is again maybe obvious but

00:40:43,770 --> 00:40:47,460
worth calling out actually and this is

00:40:46,080 --> 00:40:49,020
sort of that governs how I think about

00:40:47,460 --> 00:40:51,420
where Scala native really could could

00:40:49,020 --> 00:40:53,370
make an impact in addition to where it's

00:40:51,420 --> 00:40:55,380
already like hitting with command-line

00:40:53,370 --> 00:40:56,760
tools now with the caveat performance

00:40:55,380 --> 00:40:58,380
isn't everything right I don't want to

00:40:56,760 --> 00:41:00,930
trade-off safety or stability for

00:40:58,380 --> 00:41:02,790
performance unsafe memory is called

00:41:00,930 --> 00:41:03,540
unsafe for a reason it's really hard to

00:41:02,790 --> 00:41:05,520
do this right

00:41:03,540 --> 00:41:08,430
I definitely overflowed some buffers and

00:41:05,520 --> 00:41:09,660
seg faulted when I was writing this C

00:41:08,430 --> 00:41:11,760
programs are great when they're little

00:41:09,660 --> 00:41:15,030
artisanal code written by one person in

00:41:11,760 --> 00:41:18,150
a few sittings but giant C code bases

00:41:15,030 --> 00:41:20,430
are a nightmare but we've also gotten

00:41:18,150 --> 00:41:23,700
much better at writing good delivering

00:41:20,430 --> 00:41:25,920
software in small programs right in a

00:41:23,700 --> 00:41:27,870
way that wasn't possible a few years ago

00:41:25,920 --> 00:41:29,190
like containers and Cooper Nettie's and

00:41:27,870 --> 00:41:31,860
things like that like I don't want to

00:41:29,190 --> 00:41:33,870
throw around dumb buzzwords but writing

00:41:31,860 --> 00:41:35,610
small programs that compose is really

00:41:33,870 --> 00:41:38,070
awesome and it makes techniques like

00:41:35,610 --> 00:41:39,390
this more palatable right the other

00:41:38,070 --> 00:41:41,400
thing is that we that the scala

00:41:39,390 --> 00:41:42,750
community has gotten very very good at

00:41:41,400 --> 00:41:45,840
meta programming in the last few years

00:41:42,750 --> 00:41:49,050
like I think we've surpassed the lisps

00:41:45,840 --> 00:41:51,060
finally of this and it opens up some new

00:41:49,050 --> 00:41:52,590
opportunities so here I'm just going to

00:41:51,060 --> 00:41:55,860
sling some citations at you

00:41:52,590 --> 00:41:58,110
tarik roms and not Amin have these two

00:41:55,860 --> 00:42:00,690
really cool papers both of which are

00:41:58,110 --> 00:42:02,630
actually compiling Scala to see with

00:42:00,690 --> 00:42:05,160
this lightweight modular staging plugin

00:42:02,630 --> 00:42:07,790
this one in particular is breathtaking

00:42:05,160 --> 00:42:11,190
it's 500 lines of Scala it's clean code

00:42:07,790 --> 00:42:12,870
and it's it feels like magic right but

00:42:11,190 --> 00:42:14,940
the the really neat thing is the follow

00:42:12,870 --> 00:42:17,910
up LMS verified

00:42:14,940 --> 00:42:20,069
which takes a parser combinator writes

00:42:17,910 --> 00:42:23,130
an HTTP parser and the parser combinator

00:42:20,069 --> 00:42:25,920
and then emits not just C code but also

00:42:23,130 --> 00:42:30,569
a proof that verifies the memory safety

00:42:25,920 --> 00:42:32,339
of the generated C code and the that

00:42:30,569 --> 00:42:34,920
seems like a really powerful technique

00:42:32,339 --> 00:42:37,319
right and if we could target Scala

00:42:34,920 --> 00:42:38,849
native as a staged programming target

00:42:37,319 --> 00:42:41,519
rather than C I think it's saying we can

00:42:38,849 --> 00:42:44,279
conceivably write quite a lot of really

00:42:41,519 --> 00:42:46,200
really good software in and once I

00:42:44,279 --> 00:42:47,640
finish writing this introductory book on

00:42:46,200 --> 00:42:49,309
systems programming that's certainly

00:42:47,640 --> 00:42:53,009
where I would like to see things go in

00:42:49,309 --> 00:42:55,500
the the the I guess the reason it seems

00:42:53,009 --> 00:42:57,990
really relevant to me is that in fact a

00:42:55,500 --> 00:43:00,240
lot of the Scala people right are in

00:42:57,990 --> 00:43:03,269
fact in this large heap lots of i/o

00:43:00,240 --> 00:43:05,279
domain right I use spark and akka and

00:43:03,269 --> 00:43:08,309
Kafka every day I love them right

00:43:05,279 --> 00:43:09,599
they're great but I'm also worried that

00:43:08,309 --> 00:43:10,829
they're gonna struggle to keep up with

00:43:09,599 --> 00:43:13,980
some of the hardware changes that are

00:43:10,829 --> 00:43:16,529
like coming like now I think in Intel

00:43:13,980 --> 00:43:19,349
started shipping these non-volatile dims

00:43:16,529 --> 00:43:21,750
like this month honestly right these are

00:43:19,349 --> 00:43:23,789
durable byte addressable storage they

00:43:21,750 --> 00:43:26,190
don't cost that much more than DRAM and

00:43:23,789 --> 00:43:28,019
they are not that much slower than DRAM

00:43:26,190 --> 00:43:29,819
so all of a sudden you have this

00:43:28,019 --> 00:43:31,500
heterogeneous heap where you want to

00:43:29,819 --> 00:43:33,240
keep things that look like objects but

00:43:31,500 --> 00:43:34,529
you certainly don't want to garbage

00:43:33,240 --> 00:43:36,240
collect them because they're supposed to

00:43:34,529 --> 00:43:38,819
stay around even after your program

00:43:36,240 --> 00:43:40,559
exits other programs might be reading to

00:43:38,819 --> 00:43:43,380
them you can even read and write to them

00:43:40,559 --> 00:43:45,380
over a network and I think it's going to

00:43:43,380 --> 00:43:47,819
change and break just about everything

00:43:45,380 --> 00:43:50,549
there's this de Goya paper that

00:43:47,819 --> 00:43:51,779
came out of Microsoft which I'm still

00:43:50,549 --> 00:43:53,519
trying to make sense of because it

00:43:51,779 --> 00:43:55,470
really does seem to break the cap

00:43:53,519 --> 00:43:58,349
theorem I think the idea is if you're

00:43:55,470 --> 00:44:00,240
doing remote direct memory access your

00:43:58,349 --> 00:44:02,220
NIC is writing into a ring buffer on the

00:44:00,240 --> 00:44:03,839
NIC of some other machine you don't have

00:44:02,220 --> 00:44:06,240
the asynchronous network that the cap

00:44:03,839 --> 00:44:09,299
theorem presumes you actually have a

00:44:06,240 --> 00:44:11,880
synchronous network on non reliable like

00:44:09,299 --> 00:44:14,460
commodity ethernet which i think is how

00:44:11,880 --> 00:44:19,230
it gets around it but I think this is

00:44:14,460 --> 00:44:22,859
really exciting obviously and yeah so

00:44:19,230 --> 00:44:26,009
with that note of like yeah if I'm going

00:44:22,859 --> 00:44:28,349
to be directly writing into the memory

00:44:26,009 --> 00:44:28,680
of other machines I certainly want

00:44:28,349 --> 00:44:30,180
something

00:44:28,680 --> 00:44:33,059
it gives me direct like pointer

00:44:30,180 --> 00:44:35,790
arithmetic and buffer access like Scala

00:44:33,059 --> 00:44:37,470
native does which is why I hope that if

00:44:35,790 --> 00:44:39,359
we do have to make that kind of hard

00:44:37,470 --> 00:44:41,579
break with the past then Ascot Scala

00:44:39,359 --> 00:44:44,369
native isn't a step back to where we

00:44:41,579 --> 00:44:46,980
were 40 years ago with C it's a step

00:44:44,369 --> 00:44:50,210
forward into whatever this strange new

00:44:46,980 --> 00:44:57,110
thing is and that's my talk thank you

00:44:50,210 --> 00:44:57,110

YouTube URL: https://www.youtube.com/watch?v=qaEZ7rxfdkU


