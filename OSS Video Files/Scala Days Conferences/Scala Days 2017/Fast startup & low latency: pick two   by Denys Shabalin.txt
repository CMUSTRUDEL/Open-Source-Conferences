Title: Fast startup & low latency: pick two   by Denys Shabalin
Publication date: 2017-06-28
Playlist: Scala Days 2017
Description: 
	This video was recorded at Scala Days Copenhagen 2017
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Abstract: 
JVM is a blessing. JVM is a curse. 

Startup time and predictable performance are extremely hard to achieve on the JVM due to the complexity of the underlying VM. This makes Scala unsuitable for writing applications that are sensitive to these requirements.

In this talk, we're going to show how Scala Native enables lightweight system programming without breaking a sweat.
Captions: 
	00:00:04,170 --> 00:00:11,440
hello everyone I'm really happy to be

00:00:07,960 --> 00:00:13,350
today I'm Dennis and I'm Lucas and today

00:00:11,440 --> 00:00:16,000
we're going to talk about Scalla native

00:00:13,350 --> 00:00:18,730
so Scala native is this weird research

00:00:16,000 --> 00:00:21,849
project that we announced a year ago at

00:00:18,730 --> 00:00:24,130
Scala day 16 in New York and to be

00:00:21,849 --> 00:00:27,099
honest I didn't expect people to respond

00:00:24,130 --> 00:00:29,019
too much to it because I know it was

00:00:27,099 --> 00:00:31,630
weird but people somehow were super

00:00:29,019 --> 00:00:33,970
interested and the core idea of the

00:00:31,630 --> 00:00:37,030
project is just a very simple concept

00:00:33,970 --> 00:00:39,610
and the concept is let's compile skull

00:00:37,030 --> 00:00:41,440
ahead of time without the VM let's just

00:00:39,610 --> 00:00:44,260
compile it to native code straight away

00:00:41,440 --> 00:00:46,360
and the best way to do it right now it's

00:00:44,260 --> 00:00:48,850
through a LVM compiler infrastructure

00:00:46,360 --> 00:00:51,760
project and it's amazing and this

00:00:48,850 --> 00:00:55,150
project is developed by EPFL and Scala

00:00:51,760 --> 00:00:58,060
center but not just these two entities

00:00:55,150 --> 00:01:00,520
but we've got an amazing number of

00:00:58,060 --> 00:01:02,530
contributors in past year we've got 55

00:01:00,520 --> 00:01:04,839
contributors and like most of them are

00:01:02,530 --> 00:01:08,230
external and I have never even met them

00:01:04,839 --> 00:01:11,620
in real life and we closed summit 383

00:01:08,230 --> 00:01:14,620
for requests and six 246 issues and did

00:01:11,620 --> 00:01:15,820
the three releases already and I would

00:01:14,620 --> 00:01:18,820
like to thank everyone who contributed

00:01:15,820 --> 00:01:23,050
at the sky if ever you're awesome even

00:01:18,820 --> 00:01:25,870
if you did a minor type of change it's

00:01:23,050 --> 00:01:28,360
amazing I'm like Emeril thankful I think

00:01:25,870 --> 00:01:31,990
the project wouldn't be there which is

00:01:28,360 --> 00:01:34,540
right now without you so just a bit

00:01:31,990 --> 00:01:38,890
overview what happened in past few

00:01:34,540 --> 00:01:39,820
months so we released a very first very

00:01:38,890 --> 00:01:42,490
preview e

00:01:39,820 --> 00:01:48,040
release which was called zero point one

00:01:42,490 --> 00:01:51,220
on March 14 2017 it was a first release

00:01:48,040 --> 00:01:53,380
and the criteria we used for one to do

00:01:51,220 --> 00:01:56,500
it was we wanted all of scale language

00:01:53,380 --> 00:01:57,760
to be supported even am weird special

00:01:56,500 --> 00:01:59,890
features like structural types which

00:01:57,760 --> 00:02:01,210
people don't typically use but we still

00:01:59,890 --> 00:02:04,119
wanted to claim the full language

00:02:01,210 --> 00:02:06,670
because that's a big deal we also work

00:02:04,119 --> 00:02:10,030
load on SBT integration and making sure

00:02:06,670 --> 00:02:12,370
that SBT projects using cross-platform

00:02:10,030 --> 00:02:14,969
SVG projects which were previously cross

00:02:12,370 --> 00:02:17,170
compile and get against Scala GS and

00:02:14,969 --> 00:02:19,530
scholar and JVM

00:02:17,170 --> 00:02:23,470
seamlessly be ported over to native

00:02:19,530 --> 00:02:25,599
without not many changes and lastly we

00:02:23,470 --> 00:02:27,760
need enough core libraries to get the

00:02:25,599 --> 00:02:30,840
standard library working and enough core

00:02:27,760 --> 00:02:35,080
libraries to allow for simple projects

00:02:30,840 --> 00:02:38,650
and there are two we continued as zero

00:02:35,080 --> 00:02:41,950
to was released slightly of six weeks to

00:02:38,650 --> 00:02:43,989
release every six weeks a next numbered

00:02:41,950 --> 00:02:47,500
release as 0-2 was mostly focused on

00:02:43,989 --> 00:02:51,150
improving the library story and we spend

00:02:47,500 --> 00:02:54,220
all the time on file i/o from Del Rio we

00:02:51,150 --> 00:02:55,959
did our regular expressions on from Java

00:02:54,220 --> 00:02:57,430
util reg X which was pretty big deal

00:02:55,959 --> 00:02:59,200
because many operations on strings

00:02:57,430 --> 00:03:02,049
internally rely on regular expressions

00:02:59,200 --> 00:03:03,370
and first two were contributed by guys

00:03:02,049 --> 00:03:06,220
from Scala Center and they're pretty

00:03:03,370 --> 00:03:08,680
cool and we also did event loop based

00:03:06,220 --> 00:03:12,040
futures so it's similar to futures in

00:03:08,680 --> 00:03:14,769
Scala GS so we have one hardware thread

00:03:12,040 --> 00:03:17,290
and then we schedule features on one

00:03:14,769 --> 00:03:20,410
hardware side which allows 400

00:03:17,290 --> 00:03:23,910
applications and now essentially what

00:03:20,410 --> 00:03:26,170
this talk is gonna actually be about is

00:03:23,910 --> 00:03:28,810
it's going to be about our upcoming

00:03:26,170 --> 00:03:32,410
release which is tentatively scheduled

00:03:28,810 --> 00:03:34,000
for next week so and the main problem we

00:03:32,410 --> 00:03:35,440
were trying to solve and like the only

00:03:34,000 --> 00:03:38,230
problem we really want to solve in this

00:03:35,440 --> 00:03:40,120
release was this issue which was opened

00:03:38,230 --> 00:03:44,260
a bit more than a year ago and the issue

00:03:40,120 --> 00:03:45,609
is called better GC and to understand

00:03:44,260 --> 00:03:48,780
this issue like it takes a bit of

00:03:45,609 --> 00:03:52,209
context but essentially the question is

00:03:48,780 --> 00:03:56,320
what's better GC n where it's going to

00:03:52,209 --> 00:03:57,970
come from so to understand why we need

00:03:56,320 --> 00:04:00,640
better DC we first need to understand

00:03:57,970 --> 00:04:03,370
what do we have at the moment right now

00:04:00,640 --> 00:04:06,850
our current garbage collection collector

00:04:03,370 --> 00:04:09,880
loop which we shipped in a 0.2 and 0.1

00:04:06,850 --> 00:04:12,489
as volumes EC so Boheme GC is

00:04:09,880 --> 00:04:14,410
conservative garbage collector it was

00:04:12,489 --> 00:04:16,750
originally designed for C C++

00:04:14,410 --> 00:04:18,579
environments where compiler doesn't

00:04:16,750 --> 00:04:22,030
really know much about your program

00:04:18,579 --> 00:04:26,560
wherever type safety is very remote and

00:04:22,030 --> 00:04:28,060
distant concept and it was a very good

00:04:26,560 --> 00:04:31,120
starting point because it let us

00:04:28,060 --> 00:04:33,729
postpone GC as a problem for a while

00:04:31,120 --> 00:04:36,100
just work but the only problem we have

00:04:33,729 --> 00:04:38,260
with it is that it's conservative so

00:04:36,100 --> 00:04:41,080
what does this mean exactly so

00:04:38,260 --> 00:04:44,440
conservative GC works in environments

00:04:41,080 --> 00:04:47,229
where it doesn't really know that much

00:04:44,440 --> 00:04:49,389
about your program so it really has to

00:04:47,229 --> 00:04:52,360
guess a lot and there are like two

00:04:49,389 --> 00:04:55,660
varieties so there are conservative GCS

00:04:52,360 --> 00:04:59,490
which just handle conservative roots but

00:04:55,660 --> 00:04:59,490
still have precise type information and

00:04:59,669 --> 00:05:04,350
fully conservative GCS which neither

00:05:01,960 --> 00:05:06,880
have information about the roots or

00:05:04,350 --> 00:05:08,919
information about the allocations so the

00:05:06,880 --> 00:05:11,530
way we were using Boyan before was fully

00:05:08,919 --> 00:05:14,169
conservative GC so it truly did not know

00:05:11,530 --> 00:05:16,419
at all anything about the semantics of

00:05:14,169 --> 00:05:18,539
Scala or the way objects are laid out in

00:05:16,419 --> 00:05:21,789
memory says had to guess quite a bit and

00:05:18,539 --> 00:05:23,229
of course this guessing is not free so

00:05:21,789 --> 00:05:26,949
the more you guess the more time it

00:05:23,229 --> 00:05:29,500
takes to GC and to understand basically

00:05:26,949 --> 00:05:32,740
what kind of overhead it has reported

00:05:29,500 --> 00:05:34,840
some benchmarks from smart are we passed

00:05:32,740 --> 00:05:37,090
yet so it's an excellent repo which

00:05:34,840 --> 00:05:39,760
contains a nice well-rounded sense of

00:05:37,090 --> 00:05:41,500
benchmarks for the test standard high

00:05:39,760 --> 00:05:46,810
level object-oriented features like

00:05:41,500 --> 00:05:48,690
virtual dispatch and I know high-level

00:05:46,810 --> 00:05:51,190
features not low-level features and

00:05:48,690 --> 00:05:53,500
essentially yeah we got some numbers and

00:05:51,190 --> 00:05:55,599
if you just don't have anything to

00:05:53,500 --> 00:05:57,460
compare to yeah it just numbers which

00:05:55,599 --> 00:05:59,680
are basically the baseline so it's not

00:05:57,460 --> 00:06:02,320
very useful so the first question we

00:05:59,680 --> 00:06:04,240
asked is how does this how slow is it

00:06:02,320 --> 00:06:06,160
really but comparing to other languages

00:06:04,240 --> 00:06:07,930
or other implementations isn't really

00:06:06,160 --> 00:06:10,210
fair because you can't really compare

00:06:07,930 --> 00:06:11,710
disease in isolation because disease are

00:06:10,210 --> 00:06:13,060
tightly coupled with the language

00:06:11,710 --> 00:06:15,010
implementation and you cannot just

00:06:13,060 --> 00:06:17,289
easily take it out so biome is an

00:06:15,010 --> 00:06:19,389
exception but all high-performance GCS

00:06:17,289 --> 00:06:21,430
are extremely tightly coupled with the

00:06:19,389 --> 00:06:23,650
run time and the compiler czar built for

00:06:21,430 --> 00:06:26,470
it so it's really hard to compare GC so

00:06:23,650 --> 00:06:28,120
you have to have with multiple GC

00:06:26,470 --> 00:06:29,680
implementations on the same language on

00:06:28,120 --> 00:06:33,190
the same compiler to truly be able to

00:06:29,680 --> 00:06:35,289
compare garbage collectors so we had to

00:06:33,190 --> 00:06:39,070
have some kind of baseline and a

00:06:35,289 --> 00:06:40,659
baseline arrived in zero point two and

00:06:39,070 --> 00:06:43,419
the baseline is called native GC known

00:06:40,659 --> 00:06:44,960
and essentially what native GC known

00:06:43,419 --> 00:06:47,569
does it completely disables

00:06:44,960 --> 00:06:49,160
bridge collector it might be a bit weird

00:06:47,569 --> 00:06:52,400
of an idea but it's actually rather

00:06:49,160 --> 00:06:54,259
interesting for some use cases so it's

00:06:52,400 --> 00:06:55,550
also the simplest form of garbage

00:06:54,259 --> 00:06:57,530
collection because there is no work done

00:06:55,550 --> 00:07:00,650
to collect garbage you just allocate

00:06:57,530 --> 00:07:03,680
memory indefinitely and that's it so you

00:07:00,650 --> 00:07:05,240
never free and essentially this is

00:07:03,680 --> 00:07:06,770
actually practical for some short-lived

00:07:05,240 --> 00:07:09,080
command-line tools like maybe scallion

00:07:06,770 --> 00:07:10,370
tea where you don't really care about

00:07:09,080 --> 00:07:12,770
memory management too much you just

00:07:10,370 --> 00:07:15,889
allocate a bunch of garbage and it's

00:07:12,770 --> 00:07:18,310
done in less than a second and also it's

00:07:15,889 --> 00:07:21,050
sometimes used in industry for it

00:07:18,310 --> 00:07:23,509
applications with insane requirements

00:07:21,050 --> 00:07:25,910
for print ability because GC does add

00:07:23,509 --> 00:07:27,259
this degree of unpredictability to your

00:07:25,910 --> 00:07:28,550
code because you never know when it's

00:07:27,259 --> 00:07:30,349
going to kick in you never know how much

00:07:28,550 --> 00:07:34,130
it's going to take and so on the force

00:07:30,349 --> 00:07:35,840
like for example and nineteen and as far

00:07:34,130 --> 00:07:40,280
into the past was in 1995 there was

00:07:35,840 --> 00:07:43,449
interesting discussion by Kent Mitchell

00:07:40,280 --> 00:07:48,430
who was doing some consulting for a

00:07:43,449 --> 00:07:48,430
project which was making military

00:07:48,639 --> 00:07:54,830
missiles in other and other is high

00:07:51,770 --> 00:07:57,409
level is like language which was we just

00:07:54,830 --> 00:07:59,389
still used in some fields like aerospace

00:07:57,409 --> 00:08:01,639
and essentially the problem was he found

00:07:59,389 --> 00:08:03,289
a memory leak and he was really trying

00:08:01,639 --> 00:08:04,490
to understand like how come this was

00:08:03,289 --> 00:08:07,729
going to be shipped in production like

00:08:04,490 --> 00:08:09,860
soon and the answer he got is that they

00:08:07,729 --> 00:08:11,930
measured precisely how much it takes and

00:08:09,860 --> 00:08:13,880
just put enough memory so that when

00:08:11,930 --> 00:08:18,159
rocket hit the target it just garbage

00:08:13,880 --> 00:08:20,570
collects basically on and even more

00:08:18,159 --> 00:08:23,030
mature and more modern programming

00:08:20,570 --> 00:08:25,039
languages and and VMs like JVM are

00:08:23,030 --> 00:08:26,180
considering this as an option because

00:08:25,039 --> 00:08:29,840
it's actually a very interesting

00:08:26,180 --> 00:08:33,110
baseline for comparison the program

00:08:29,840 --> 00:08:34,820
poses gep draft for JVM I don't know

00:08:33,110 --> 00:08:36,740
with its current state but essentially

00:08:34,820 --> 00:08:39,500
the idea is is same just have a mode for

00:08:36,740 --> 00:08:42,560
GC that doesn't DC and it's actually

00:08:39,500 --> 00:08:44,750
pretty cool so needless to say is the

00:08:42,560 --> 00:08:47,390
main interest we had for it was to have

00:08:44,750 --> 00:08:51,020
some baseline performance numbers that

00:08:47,390 --> 00:08:53,930
will tell us and show us how much do we

00:08:51,020 --> 00:08:56,990
really suck on GC and here our numbers

00:08:53,930 --> 00:08:58,060
is compare no GC and boy in DC as you

00:08:56,990 --> 00:09:00,910
can see it

00:08:58,060 --> 00:09:03,610
to get pretty bad on some benchmarks it

00:09:00,910 --> 00:09:06,910
gets all the way to 5x slower with

00:09:03,610 --> 00:09:08,890
boi-ing C versus no GC and needless to

00:09:06,910 --> 00:09:10,660
say it's pretty bad and the bonus is

00:09:08,890 --> 00:09:12,190
going to see I really don't know how

00:09:10,660 --> 00:09:14,740
fast color native is because it's very

00:09:12,190 --> 00:09:15,160
unpredictable and it's really hard to

00:09:14,740 --> 00:09:17,140
tell

00:09:15,160 --> 00:09:19,210
so obviously this basically frames the

00:09:17,140 --> 00:09:21,760
start of the discussion of why we need a

00:09:19,210 --> 00:09:24,400
better DC and the answer is because it's

00:09:21,760 --> 00:09:27,190
truly bad so it's typically on average

00:09:24,400 --> 00:09:30,880
like twice slower than no GC which is

00:09:27,190 --> 00:09:32,950
like pretty bad so the question stands

00:09:30,880 --> 00:09:35,350
now we need negative GC : equals

00:09:32,950 --> 00:09:37,990
something what is going to be and this

00:09:35,350 --> 00:09:39,730
Sampson is actually there are many many

00:09:37,990 --> 00:09:42,060
different solutions and the design space

00:09:39,730 --> 00:09:45,970
of solution is actually pretty big a

00:09:42,060 --> 00:09:49,480
very oversimplified and probably for

00:09:45,970 --> 00:09:51,250
like not correct version of how these

00:09:49,480 --> 00:09:54,790
can be partitioned by design decisions

00:09:51,250 --> 00:09:56,200
is here so you have I picked like two

00:09:54,790 --> 00:09:58,090
accesses they were probably like way

00:09:56,200 --> 00:10:00,420
more in the z space but just to access

00:09:58,090 --> 00:10:03,580
that we care about the DES moment is

00:10:00,420 --> 00:10:08,020
first access is move ability of the GC

00:10:03,580 --> 00:10:09,850
does the GC move objects around and the

00:10:08,020 --> 00:10:12,400
second axis is the one routine

00:10:09,850 --> 00:10:14,590
struggling so far is easy to see

00:10:12,400 --> 00:10:18,250
conservative or precise essentially you

00:10:14,590 --> 00:10:20,470
have two accesses and only things above

00:10:18,250 --> 00:10:23,350
a diagonal are possible so stamp of

00:10:20,470 --> 00:10:26,770
stuff in a bottom right is not possible

00:10:23,350 --> 00:10:30,910
because for always moving GC you must

00:10:26,770 --> 00:10:33,250
have a fully precise stack so now we

00:10:30,910 --> 00:10:36,870
have this like two camps so camps in the

00:10:33,250 --> 00:10:40,390
bottom is a standard trade of space for

00:10:36,870 --> 00:10:44,080
GTS and VMs so the core kind of

00:10:40,390 --> 00:10:46,750
foundational like for generation of GC

00:10:44,080 --> 00:10:51,130
is copying GC so typically you see early

00:10:46,750 --> 00:10:51,700
generation copying GC and a second

00:10:51,130 --> 00:10:53,740
generation

00:10:51,700 --> 00:10:56,590
marking sweeper mark compact or some

00:10:53,740 --> 00:10:59,520
weird hybrid of the do is basically the

00:10:56,590 --> 00:11:02,650
quintessential standard generation of GC

00:10:59,520 --> 00:11:04,360
formula and the main point of copying GC

00:11:02,650 --> 00:11:07,930
and why copying GC actually a good idea

00:11:04,360 --> 00:11:09,700
is the fact that by copying GC can

00:11:07,930 --> 00:11:11,920
optimize application for best memory

00:11:09,700 --> 00:11:15,009
locality and

00:11:11,920 --> 00:11:17,439
because it compacts it can also bump

00:11:15,009 --> 00:11:19,089
allocate most of the time so bump

00:11:17,439 --> 00:11:21,999
allocation is not the fastest way to

00:11:19,089 --> 00:11:24,399
allocate that we know today but of

00:11:21,999 --> 00:11:26,679
course it's not free and so fully

00:11:24,399 --> 00:11:28,899
precise DC has non-trivial engineering

00:11:26,679 --> 00:11:31,749
costs to support fully precise Tech's

00:11:28,899 --> 00:11:34,559
and it also requires compiler to be very

00:11:31,749 --> 00:11:37,839
careful about GC references versus

00:11:34,559 --> 00:11:40,329
unmanaged references and essentially it

00:11:37,839 --> 00:11:44,100
is possible on LLVM on latest latest

00:11:40,329 --> 00:11:47,439
version of l vm i finally start to get a

00:11:44,100 --> 00:11:50,309
reasonably good support for fully

00:11:47,439 --> 00:11:52,899
precise disease in latest releases but

00:11:50,309 --> 00:11:54,369
Aldridge's still have outdated this

00:11:52,899 --> 00:11:58,389
infrastructure which we are not going to

00:11:54,369 --> 00:12:00,040
use maybe this is an interesting place

00:11:58,389 --> 00:12:02,980
to be in the future but right now LVN

00:12:00,040 --> 00:12:04,749
doesn't at least old versions LVN which

00:12:02,980 --> 00:12:07,209
are people typically use which come

00:12:04,749 --> 00:12:10,929
bundled and and linux are typically

00:12:07,209 --> 00:12:13,419
don't purchase yet so and now you have a

00:12:10,929 --> 00:12:17,529
separate kind of camp and separate camp

00:12:13,419 --> 00:12:19,839
is of non-moving GCS and here you

00:12:17,529 --> 00:12:21,429
typically have some kind of reference

00:12:19,839 --> 00:12:23,589
counting hybrids and some kind of

00:12:21,429 --> 00:12:25,529
marking sleep hybrids and this is the

00:12:23,589 --> 00:12:28,749
most standard pic 480 compilers because

00:12:25,529 --> 00:12:31,569
non-moving GC actually simplifies GCC

00:12:28,749 --> 00:12:35,649
compiler interface and it gives compiler

00:12:31,569 --> 00:12:38,639
more freedom to do things because

00:12:35,649 --> 00:12:41,679
especially on a fully conservative or

00:12:38,639 --> 00:12:45,819
conservative roots and solutions you

00:12:41,679 --> 00:12:47,169
don't have to have a gel compiler what's

00:12:45,819 --> 00:12:48,759
going on this is basically the space we

00:12:47,169 --> 00:12:53,559
want to be we don't really want to

00:12:48,759 --> 00:12:56,829
integrate with LEM too far if so but of

00:12:53,559 --> 00:12:58,449
course it's so there are two standard

00:12:56,829 --> 00:13:00,249
solutions the first one is reference

00:12:58,449 --> 00:13:02,019
counting reference counting is the

00:13:00,249 --> 00:13:05,799
solutions used by many languages right

00:13:02,019 --> 00:13:08,049
now in 80 space and it's basically what

00:13:05,799 --> 00:13:09,519
it does is so every object has a number

00:13:08,049 --> 00:13:13,149
of references from other objects or

00:13:09,519 --> 00:13:14,739
stack and this is a simple solution it's

00:13:13,149 --> 00:13:16,059
really easy to implement but to make it

00:13:14,739 --> 00:13:17,919
practical for Scala you will need

00:13:16,059 --> 00:13:20,230
something more advanced like you would

00:13:17,919 --> 00:13:21,920
need to have a special and cycle

00:13:20,230 --> 00:13:24,440
collector to trace

00:13:21,920 --> 00:13:26,360
expected cycles because reference

00:13:24,440 --> 00:13:28,130
counting on its own core idea cannot

00:13:26,360 --> 00:13:30,260
handle psychic data structures because

00:13:28,130 --> 00:13:31,850
let's say you have two objects it point

00:13:30,260 --> 00:13:34,310
to one another we will always have a

00:13:31,850 --> 00:13:37,010
nonzero reference count which never goes

00:13:34,310 --> 00:13:39,800
to zero and apart from that it also

00:13:37,010 --> 00:13:41,980
requires constant overhead on the

00:13:39,800 --> 00:13:46,279
application performance because of the

00:13:41,980 --> 00:13:47,810
extra work necessary as to up constantly

00:13:46,279 --> 00:13:50,540
keep this reference count up to date

00:13:47,810 --> 00:13:52,339
this work is not there for a tracing

00:13:50,540 --> 00:13:54,740
garbage collector because for tracing

00:13:52,339 --> 00:13:56,720
garbage collection you never have to

00:13:54,740 --> 00:13:58,190
update anything during application

00:13:56,720 --> 00:14:03,620
application time we only update things

00:13:58,190 --> 00:14:04,639
during actual DC and then there is one

00:14:03,620 --> 00:14:06,880
more simple idea which is a

00:14:04,639 --> 00:14:09,620
quintessential

00:14:06,880 --> 00:14:11,360
decades-old marking Soup garbage

00:14:09,620 --> 00:14:13,310
collection and the idea again is very

00:14:11,360 --> 00:14:14,899
simple just traverse the hip you mark

00:14:13,310 --> 00:14:17,480
every single object which is reachable

00:14:14,899 --> 00:14:21,370
and then you go through hip once again

00:14:17,480 --> 00:14:24,410
and you sweep all the objects which are

00:14:21,370 --> 00:14:27,920
not reachable to some data structure

00:14:24,410 --> 00:14:30,050
like free leads and both GCS actually

00:14:27,920 --> 00:14:31,880
are very problematic in some ways

00:14:30,050 --> 00:14:35,750
because they are non moving so it means

00:14:31,880 --> 00:14:38,839
a GC has a very little freedom to keep

00:14:35,750 --> 00:14:40,459
fragmentation and lo and it has no

00:14:38,839 --> 00:14:44,480
freedom to improve memory locality at

00:14:40,459 --> 00:14:46,670
all because the protocol is the GCMs

00:14:44,480 --> 00:14:49,519
follows it never moves objects in memory

00:14:46,670 --> 00:14:52,370
and typically it's also backed by free

00:14:49,519 --> 00:14:53,930
lists which are not competitive in terms

00:14:52,370 --> 00:14:57,890
of allocation performance compared to

00:14:53,930 --> 00:15:00,140
bump allocation so now we are basically

00:14:57,890 --> 00:15:01,579
so we have some kind of background so we

00:15:00,140 --> 00:15:04,610
understand what kind of G sees people

00:15:01,579 --> 00:15:06,140
typically use and we are probably in the

00:15:04,610 --> 00:15:08,269
worst possible combinations of two

00:15:06,140 --> 00:15:09,800
features at the moment so we have fully

00:15:08,269 --> 00:15:12,140
conservative non moving garbage

00:15:09,800 --> 00:15:14,029
collector so it's like truly bad and

00:15:12,140 --> 00:15:17,269
you've seen the numbers it can get up to

00:15:14,029 --> 00:15:19,550
5 times slower compared to not having a

00:15:17,269 --> 00:15:21,230
garbage collector at all so the first

00:15:19,550 --> 00:15:24,470
question is like we have to move in the

00:15:21,230 --> 00:15:27,470
design space somewhere and the first

00:15:24,470 --> 00:15:30,380
thing we decided to try on is to see how

00:15:27,470 --> 00:15:32,839
much overhead does does

00:15:30,380 --> 00:15:35,149
fully conservative versus conservative

00:15:32,839 --> 00:15:35,900
roots has because for fully conservative

00:15:35,149 --> 00:15:41,620
you don't know

00:15:35,900 --> 00:15:43,880
neither the stack nor the layout of

00:15:41,620 --> 00:15:46,130
things in memory so you really have to

00:15:43,880 --> 00:15:50,390
guess a lot and the first thing we want

00:15:46,130 --> 00:15:52,910
to try is is to go to the left and to

00:15:50,390 --> 00:15:55,870
the left means and have to give you see

00:15:52,910 --> 00:16:00,110
more information and this is where our

00:15:55,870 --> 00:16:03,490
first experiment precise mostly precise

00:16:00,110 --> 00:16:06,500
markings it comes in and around like

00:16:03,490 --> 00:16:07,130
February Lukas was looking for a project

00:16:06,500 --> 00:16:11,510
to work on

00:16:07,130 --> 00:16:12,980
right and I suggested for him try

00:16:11,510 --> 00:16:16,310
mark-and-sweep it shouldn't be that bad

00:16:12,980 --> 00:16:19,010
it's probably b-boying like easily right

00:16:16,310 --> 00:16:22,240
yeah it looked kind of scary but you

00:16:19,010 --> 00:16:24,590
convinced me so I started working on

00:16:22,240 --> 00:16:27,110
mark and sweep with conservative roots

00:16:24,590 --> 00:16:29,780
so mark and sweep has been around

00:16:27,110 --> 00:16:32,510
forever it's really old but it's rather

00:16:29,780 --> 00:16:35,540
simple so it has two phases the first

00:16:32,510 --> 00:16:38,180
one is the marking phase which is here

00:16:35,540 --> 00:16:40,250
to identify the live objects and then

00:16:38,180 --> 00:16:41,870
comes the sweeping phase which goes

00:16:40,250 --> 00:16:44,150
through the heap to collect the garbage

00:16:41,870 --> 00:16:47,270
and return it to the allocator for new

00:16:44,150 --> 00:16:50,810
allocation so what does it mean to have

00:16:47,270 --> 00:16:53,930
conservative roots so conservative roots

00:16:50,810 --> 00:16:55,880
means that elements on the stack for

00:16:53,930 --> 00:16:59,000
example it can point anywhere they can

00:16:55,880 --> 00:17:01,760
point outside the heap but also inside

00:16:59,000 --> 00:17:03,890
the heap and even more inside the heap

00:17:01,760 --> 00:17:06,740
they don't only point to object headers

00:17:03,890 --> 00:17:09,230
but they can point anywhere so we have

00:17:06,740 --> 00:17:13,100
to handle them carefully to resolve the

00:17:09,230 --> 00:17:15,920
header of the object so for inside the

00:17:13,100 --> 00:17:18,620
heap because the the heap itself is

00:17:15,920 --> 00:17:21,320
precise the compiler emits information

00:17:18,620 --> 00:17:25,150
for every type that is used for variable

00:17:21,320 --> 00:17:28,940
AGC to to know exactly which values are

00:17:25,150 --> 00:17:31,940
references and which are not so in our

00:17:28,940 --> 00:17:34,550
case we have three type of routes the

00:17:31,940 --> 00:17:36,260
first ones are registers they're not on

00:17:34,550 --> 00:17:38,690
the slide because they are simply dumped

00:17:36,260 --> 00:17:42,020
onto the stack then we have the stack

00:17:38,690 --> 00:17:45,640
and finally the modules the modules are

00:17:42,020 --> 00:17:48,110
precise there are the SCADA objects so

00:17:45,640 --> 00:17:49,670
precise means that they're either now or

00:17:48,110 --> 00:17:54,140
point exactly to the head

00:17:49,670 --> 00:17:56,840
of an object so now look let's look at

00:17:54,140 --> 00:17:59,060
the the marking phase so what the

00:17:56,840 --> 00:18:02,000
marking phase does it it goes through

00:17:59,060 --> 00:18:04,730
the roots and does a breadth-first

00:18:02,000 --> 00:18:07,070
search traversal of the life object

00:18:04,730 --> 00:18:11,420
graph so for example here the first

00:18:07,070 --> 00:18:14,930
element points into the heap and we

00:18:11,420 --> 00:18:16,970
follow it we mark it and afterwards we

00:18:14,930 --> 00:18:20,690
need to mark all its children so in this

00:18:16,970 --> 00:18:23,240
case there's only one we mark it and now

00:18:20,690 --> 00:18:25,610
we're done with the first route so we go

00:18:23,240 --> 00:18:29,180
to the next one we follow the pointer

00:18:25,610 --> 00:18:30,950
market here we have two children but the

00:18:29,180 --> 00:18:32,890
first one's already marked so we stop

00:18:30,950 --> 00:18:36,110
here we don't have to do anything and we

00:18:32,890 --> 00:18:39,710
mark the second one same thing for

00:18:36,110 --> 00:18:42,650
modules so we follow it mark it and same

00:18:39,710 --> 00:18:45,620
thing with the children so now we're

00:18:42,650 --> 00:18:47,570
done with the marking phase so our heap

00:18:45,620 --> 00:18:48,650
has some objects that are marked and

00:18:47,570 --> 00:18:51,530
some that are not

00:18:48,650 --> 00:18:53,870
and the goal of the sweeping phase is to

00:18:51,530 --> 00:18:56,180
go through the heap and collect all

00:18:53,870 --> 00:18:59,000
objects that are not marked to return it

00:18:56,180 --> 00:19:01,670
to the allocator for new allocations so

00:18:59,000 --> 00:19:04,670
to do this we simply go through the heap

00:19:01,670 --> 00:19:07,790
object by object and if there are marked

00:19:04,670 --> 00:19:10,940
we unmarked them like the two first ones

00:19:07,790 --> 00:19:14,660
and if they're not marked there now free

00:19:10,940 --> 00:19:17,240
and return to the allocator and we do

00:19:14,660 --> 00:19:22,130
this for every object in the heap on

00:19:17,240 --> 00:19:23,990
market and so on so this is what it

00:19:22,130 --> 00:19:25,670
looks like after collection so all the

00:19:23,990 --> 00:19:28,910
blue objects are free and have been

00:19:25,670 --> 00:19:32,930
returned to the allocator for new

00:19:28,910 --> 00:19:36,410
allocations so the results we got were

00:19:32,930 --> 00:19:40,730
rather interesting but we were still not

00:19:36,410 --> 00:19:44,780
satisfied so here you see the benchmark

00:19:40,730 --> 00:19:46,550
comparison with Boehm and now GC so the

00:19:44,780 --> 00:19:49,790
average performance of the average

00:19:46,550 --> 00:19:53,090
overhead went from around 100 percent to

00:19:49,790 --> 00:19:56,200
25 percent and you can see this very

00:19:53,090 --> 00:19:59,600
well on the benchmarks like tracer which

00:19:56,200 --> 00:20:01,760
has a lot of live objects so the tracing

00:19:59,600 --> 00:20:02,650
part the marketing part is really

00:20:01,760 --> 00:20:05,050
expensive

00:20:02,650 --> 00:20:07,750
but because we have a precise heap it

00:20:05,050 --> 00:20:12,100
got cheaper but we also have benchmarks

00:20:07,750 --> 00:20:14,559
like GC bench and this benchmark is

00:20:12,100 --> 00:20:17,620
allocation bound so it locates a lot and

00:20:14,559 --> 00:20:22,090
it still it still has around 100 percent

00:20:17,620 --> 00:20:24,400
overhead so this is pretty bad and the

00:20:22,090 --> 00:20:27,930
problem here is that conventional

00:20:24,400 --> 00:20:31,800
marking sweep allocators use freely and

00:20:27,930 --> 00:20:34,210
free lists are slow so we saw that

00:20:31,800 --> 00:20:40,120
mark-and-sweep was not the solution we

00:20:34,210 --> 00:20:42,760
were looking for so and here we are so

00:20:40,120 --> 00:20:45,250
we now have two solutions none of them

00:20:42,760 --> 00:20:47,220
are good enough so it's not good so we

00:20:45,250 --> 00:20:50,020
have to keep looking I guess and

00:20:47,220 --> 00:20:52,690
essentially the problem that was

00:20:50,020 --> 00:20:54,040
described as Lucas is that allocation in

00:20:52,690 --> 00:20:57,160
non moving sediment is actually a bit

00:20:54,040 --> 00:20:59,920
tricky and you really cannot easily do

00:20:57,160 --> 00:21:03,400
by application it's very tricky to fool

00:20:59,920 --> 00:21:05,470
of in a fully known movie set setting so

00:21:03,400 --> 00:21:08,230
we kept looking naturally so because

00:21:05,470 --> 00:21:09,760
this was like just mark-and-sweep wasn't

00:21:08,230 --> 00:21:12,880
good enough even though it did improve

00:21:09,760 --> 00:21:15,850
on upon Boehm which mostly because it

00:21:12,880 --> 00:21:18,460
had more information so the next place

00:21:15,850 --> 00:21:22,000
we wanted to DRI is actually this super

00:21:18,460 --> 00:21:23,890
weird and mostly not well researched

00:21:22,000 --> 00:21:25,780
space of mostly moving garbage

00:21:23,890 --> 00:21:29,080
collection the mostly moving garbage

00:21:25,780 --> 00:21:31,840
collection is a different it's a

00:21:29,080 --> 00:21:33,640
trade-off between a fully moving and

00:21:31,840 --> 00:21:36,820
non-moving and essentially the idea is

00:21:33,640 --> 00:21:39,550
GC can move stuff around unless the

00:21:36,820 --> 00:21:41,200
objects are pinned so you use split

00:21:39,550 --> 00:21:42,520
objects in two types the one which can

00:21:41,200 --> 00:21:44,920
be moved around and the ones which

00:21:42,520 --> 00:21:46,630
cannot be moved around and essentially

00:21:44,920 --> 00:21:48,309
everything referred from the roots you

00:21:46,630 --> 00:21:50,260
can still keep Zeus conservative because

00:21:48,309 --> 00:21:52,630
you can pin those objects down and make

00:21:50,260 --> 00:21:56,050
sure the stuff reference from road never

00:21:52,630 --> 00:21:58,120
changes location in memory and run to

00:21:56,050 --> 00:22:00,340
GCS actually probably more but

00:21:58,120 --> 00:22:02,170
essentially two well-known solutions in

00:22:00,340 --> 00:22:04,750
this space the first one is called

00:22:02,170 --> 00:22:10,120
Bartlett and it's a hybrid of a copy in

00:22:04,750 --> 00:22:12,610
GC for a most moving use case and it's

00:22:10,120 --> 00:22:15,920
underlined a GC technology for safari

00:22:12,610 --> 00:22:19,130
and that kit so it's actually

00:22:15,920 --> 00:22:22,460
pretty usable and it's based on under

00:22:19,130 --> 00:22:24,370
work by Joe Bartlett and compact and

00:22:22,460 --> 00:22:27,860
garbage collection with ambiguous roots

00:22:24,370 --> 00:22:30,290
but another one as also guessed is

00:22:27,860 --> 00:22:32,690
called Amex and it's a marked reagent

00:22:30,290 --> 00:22:34,430
harvest collector market only problem

00:22:32,690 --> 00:22:36,950
never heard this term before which is

00:22:34,430 --> 00:22:39,380
actually an its own family of garbage

00:22:36,950 --> 00:22:41,660
collectors which are not that well-known

00:22:39,380 --> 00:22:44,830
because they just did beard today less

00:22:41,660 --> 00:22:49,520
than 10 years ago on the scene and

00:22:44,830 --> 00:22:51,440
essentially it's a very simple idea and

00:22:49,520 --> 00:22:54,370
it's also exhibit on paper

00:22:51,440 --> 00:22:59,540
offers one pass defragmentation which

00:22:54,370 --> 00:23:02,120
gives it is compact in nature so the

00:22:59,540 --> 00:23:03,590
original was from the paper a makes a

00:23:02,120 --> 00:23:05,060
mark region garbage collector with space

00:23:03,590 --> 00:23:07,810
efficiency fast collection and their

00:23:05,060 --> 00:23:12,410
performance by Stephen Blackburn and

00:23:07,810 --> 00:23:14,180
Katherine McKinley and we really like

00:23:12,410 --> 00:23:16,760
this idea because it was quite close to

00:23:14,180 --> 00:23:19,340
and quite workable and easy to do based

00:23:16,760 --> 00:23:21,470
on marking soup prototype we had so it

00:23:19,340 --> 00:23:23,240
took us what like maybe three weeks to

00:23:21,470 --> 00:23:25,970
do a first hack of a prototype yeah like

00:23:23,240 --> 00:23:28,490
two or three weeks so the core idea is

00:23:25,970 --> 00:23:30,920
pretty much the same as for

00:23:28,490 --> 00:23:32,570
mark-and-sweep the difference is that we

00:23:30,920 --> 00:23:35,780
have a bit more of a structure in the

00:23:32,570 --> 00:23:39,260
heap so before we had the heap and just

00:23:35,780 --> 00:23:41,360
the objects inside the heap now the heap

00:23:39,260 --> 00:23:44,030
is separated into blocks these blocks

00:23:41,360 --> 00:23:47,120
are around 32 kilobytes large so they're

00:23:44,030 --> 00:23:49,130
pretty large and then inside these

00:23:47,120 --> 00:23:51,650
blocks we have lines the lines are

00:23:49,130 --> 00:23:55,820
pretty small they fit into like four

00:23:51,650 --> 00:23:59,420
cache cache lines and these lines can

00:23:55,820 --> 00:24:02,240
either be free here in blue or allocated

00:23:59,420 --> 00:24:04,220
with objects and the block also has

00:24:02,240 --> 00:24:07,160
three types so they can be either

00:24:04,220 --> 00:24:10,010
unavailable if there is no free line in

00:24:07,160 --> 00:24:12,080
it they can be recyclable if we have

00:24:10,010 --> 00:24:15,650
some free lines and some allocated lines

00:24:12,080 --> 00:24:16,480
or they can be completely free like the

00:24:15,650 --> 00:24:20,750
last one

00:24:16,480 --> 00:24:23,690
so how allocation works here is that we

00:24:20,750 --> 00:24:26,000
do dump allocation on three lines so

00:24:23,690 --> 00:24:28,310
this means that we have a cursor at the

00:24:26,000 --> 00:24:30,260
beginning of the lines and one at the

00:24:28,310 --> 00:24:33,260
end and when we want to

00:24:30,260 --> 00:24:37,130
get an object if the size of the object

00:24:33,260 --> 00:24:40,520
fits between these two cursors we added

00:24:37,130 --> 00:24:43,309
and update the cursor and we do it like

00:24:40,520 --> 00:24:46,429
this and this is very good because donto

00:24:43,309 --> 00:24:48,590
location helps a lot with memory

00:24:46,429 --> 00:24:50,720
locality because objects that are

00:24:48,590 --> 00:24:54,440
allocated together are often accessed

00:24:50,720 --> 00:24:56,150
together so that's really good and if

00:24:54,440 --> 00:24:59,390
you even if you want to allocate large

00:24:56,150 --> 00:25:01,160
objects we can allocate them on several

00:24:59,390 --> 00:25:05,179
lines at the time that's not a problem

00:25:01,160 --> 00:25:07,100
and once we're out of space we're going

00:25:05,179 --> 00:25:11,510
to look for the next line that's free

00:25:07,100 --> 00:25:15,260
and do allocation so that's it for

00:25:11,510 --> 00:25:17,600
allocation and the marking phase is

00:25:15,260 --> 00:25:20,480
pretty much the same as for marking

00:25:17,600 --> 00:25:23,090
sweep the only difference is that now we

00:25:20,480 --> 00:25:26,390
not only mark objects but we also mark

00:25:23,090 --> 00:25:29,660
blocks and lines so for example here on

00:25:26,390 --> 00:25:33,919
the first reference we follow it we mark

00:25:29,660 --> 00:25:36,590
the object the line and the block we

00:25:33,919 --> 00:25:38,120
mark the child here the line and the

00:25:36,590 --> 00:25:42,260
block is already marked so we don't have

00:25:38,120 --> 00:25:45,080
to do this and same thing with the

00:25:42,260 --> 00:25:48,710
second one we mark the lines and the

00:25:45,080 --> 00:25:51,580
object so that's it for the marking

00:25:48,710 --> 00:25:55,429
phase so it's pretty much the same but

00:25:51,580 --> 00:25:58,490
the sweeping phase got improved a lot so

00:25:55,429 --> 00:26:00,410
here in this case the block is marked so

00:25:58,490 --> 00:26:04,730
we will have to go through it line by

00:26:00,410 --> 00:26:07,160
line so here on the first line it's also

00:26:04,730 --> 00:26:10,640
marked so we have to go and unmarked the

00:26:07,160 --> 00:26:14,900
line unmarked the objects same thing

00:26:10,640 --> 00:26:18,020
here but now this line is not marked so

00:26:14,900 --> 00:26:21,080
all at once we just say this line is

00:26:18,020 --> 00:26:23,059
free same thing for here and for the

00:26:21,080 --> 00:26:25,840
second block because it's not marked we

00:26:23,059 --> 00:26:31,220
don't have to do anything it's just free

00:26:25,840 --> 00:26:33,200
so this improves a lot the performance

00:26:31,220 --> 00:26:35,990
of a mix was quite a surprise to us

00:26:33,200 --> 00:26:37,669
right yeah I remember at some point when

00:26:35,990 --> 00:26:39,620
you just had the first prototype you

00:26:37,669 --> 00:26:41,990
were like trying to really hard to

00:26:39,620 --> 00:26:43,190
figure out why did memset zero became so

00:26:41,990 --> 00:26:45,860
slow yeah

00:26:43,190 --> 00:26:47,660
three before his mark in sweep clearing

00:26:45,860 --> 00:26:49,670
the memory would never show up in the

00:26:47,660 --> 00:26:51,680
profiles but somehow now it gets really

00:26:49,670 --> 00:26:53,600
slow so we were trying to debug it like

00:26:51,680 --> 00:26:55,550
we're trying to figure out a recall and

00:26:53,600 --> 00:26:58,100
memset zero too much or something and

00:26:55,550 --> 00:26:59,870
it's only until we debug it and deal

00:26:58,100 --> 00:27:03,110
more and actually did run the benchmarks

00:26:59,870 --> 00:27:06,890
did we see the attack was actually not a

00:27:03,110 --> 00:27:09,170
best time the performance improved a lot

00:27:06,890 --> 00:27:12,050
and when I say a lot it went from the

00:27:09,170 --> 00:27:15,350
worst case 2x2 to typical worst case of

00:27:12,050 --> 00:27:17,810
like 20% overhead and maybe benchmarks

00:27:15,350 --> 00:27:19,370
is way lower than that and the very

00:27:17,810 --> 00:27:23,510
worst case on a single measurement we

00:27:19,370 --> 00:27:26,000
have is around 50% a typical average of

00:27:23,510 --> 00:27:28,550
overhead or our benchmarks is just 10%

00:27:26,000 --> 00:27:30,530
and of course naturally it's like wave

00:27:28,550 --> 00:27:32,690
letters and Boyan which has worst case

00:27:30,530 --> 00:27:35,120
overhead of 5x and typical overhead of

00:27:32,690 --> 00:27:37,070
hundred percent over no GC so you pay

00:27:35,120 --> 00:27:40,250
for GC but it's like 10 yo to cost of 10

00:27:37,070 --> 00:27:43,100
percent so it's really nothing and I'm

00:27:40,250 --> 00:27:44,660
pretty sure this does qualify as good

00:27:43,100 --> 00:27:46,970
you see maybe not the best issue the

00:27:44,660 --> 00:27:49,400
world has ever seen yet but so we have

00:27:46,970 --> 00:27:56,090
to close the ticket now because it's

00:27:49,400 --> 00:27:58,940
been going on for too long yeah okay

00:27:56,090 --> 00:28:05,890
cool yeah we're currently let's call

00:27:58,940 --> 00:28:05,890
these guys you don't see it on now okay

00:28:08,980 --> 00:28:16,390
it's like this so we are solid eight

00:28:13,450 --> 00:28:22,320
anammox is pretty good guys

00:28:16,390 --> 00:28:26,380
[Applause]

00:28:22,320 --> 00:28:29,230
okay so this is basically what's been a

00:28:26,380 --> 00:28:33,640
kind of topic of our targets we finally

00:28:29,230 --> 00:28:35,950
get a good GC and this new good GC is

00:28:33,640 --> 00:28:39,370
coming as a prototype in zero three it's

00:28:35,950 --> 00:28:41,290
not enabled by default but it will

00:28:39,370 --> 00:28:44,590
slowly be enabled later ready for now

00:28:41,290 --> 00:28:46,240
you can obtain by native GC MX we're

00:28:44,590 --> 00:28:49,030
going to support Boehm at least as long

00:28:46,240 --> 00:28:51,100
as it is not a default it will stay

00:28:49,030 --> 00:28:53,560
there for some time but naturally we

00:28:51,100 --> 00:28:56,260
expect NX to be unconditionally faster

00:28:53,560 --> 00:28:57,760
and if it's not faster than Boyan please

00:28:56,260 --> 00:28:59,830
tell us it's actually it should be like

00:28:57,760 --> 00:29:01,600
way way faster and like on every single

00:28:59,830 --> 00:29:04,600
workout with fryer that's way way faster

00:29:01,600 --> 00:29:07,510
and there are a few other nice features

00:29:04,600 --> 00:29:10,780
that are coming in 0.3 and so we get as

00:29:07,510 --> 00:29:12,730
pedestrian framework integration has

00:29:10,780 --> 00:29:14,470
been contributed by Martin do come from

00:29:12,730 --> 00:29:17,380
Scala Center we have initial support

00:29:14,470 --> 00:29:19,120
from file i/o and zip drawers API is

00:29:17,380 --> 00:29:20,530
also more marked into him and we also

00:29:19,120 --> 00:29:22,810
have very nice thing we have smaller

00:29:20,530 --> 00:29:26,410
binaries now so we did some work on

00:29:22,810 --> 00:29:29,110
optimizing overhead of additional

00:29:26,410 --> 00:29:31,360
metadata with the soup that we dumped

00:29:29,110 --> 00:29:34,030
next to your code in native binaries and

00:29:31,360 --> 00:29:35,350
on some pathological cases it can be ten

00:29:34,030 --> 00:29:37,240
times smaller but typically I would

00:29:35,350 --> 00:29:41,010
expect like 20 maybe percent smaller

00:29:37,240 --> 00:29:44,010
binaries and that's around it for today

00:29:41,010 --> 00:29:44,010
Thanks

00:29:48,420 --> 00:29:52,540
how much you would you consider the

00:29:50,860 --> 00:29:54,610
project at this point is it production

00:29:52,540 --> 00:29:56,230
already a year from production five

00:29:54,610 --> 00:29:58,150
years from production is there any

00:29:56,230 --> 00:29:59,980
estimate to that I'm not going to give

00:29:58,150 --> 00:30:02,440
you any estimates because the estimates

00:29:59,980 --> 00:30:04,330
are hard but the bigger is version

00:30:02,440 --> 00:30:04,930
numbers more stabilities right this is

00:30:04,330 --> 00:30:09,550
how it works

00:30:04,930 --> 00:30:12,030
[Laughter]

00:30:09,550 --> 00:30:15,460
did you test it on large heaps like

00:30:12,030 --> 00:30:18,730
hundreds of geeks and collection times

00:30:15,460 --> 00:30:19,540
so the question was how does it scale to

00:30:18,730 --> 00:30:22,330
giant heaps

00:30:19,540 --> 00:30:26,280
so it's still so it's still a market in

00:30:22,330 --> 00:30:29,110
DC so it has like typical cost of a

00:30:26,280 --> 00:30:32,200
standard stop the world mark in DC has

00:30:29,110 --> 00:30:34,240
and it does put a due amount of work

00:30:32,200 --> 00:30:36,880
proportional to the wife heap size this

00:30:34,240 --> 00:30:38,110
is not solved yet so the post times

00:30:36,880 --> 00:30:41,740
basically are proportion of the number

00:30:38,110 --> 00:30:43,060
of memory allocated it's not really

00:30:41,740 --> 00:30:44,560
proportional that much the number of

00:30:43,060 --> 00:30:46,560
memory you have because Susan is not

00:30:44,560 --> 00:30:49,180
super fast compared to mark and SIP

00:30:46,560 --> 00:30:50,620
American Serbs was Subin was very

00:30:49,180 --> 00:30:53,380
problematic but here's basically just

00:30:50,620 --> 00:30:55,780
life object ice essentially is a little

00:30:53,380 --> 00:31:01,210
the cost so this is not completely

00:30:55,780 --> 00:31:05,440
solved yet so given a niche LLVM is

00:31:01,210 --> 00:31:07,000
target you know what are you seeing in

00:31:05,440 --> 00:31:09,880
terms of our presumed dead code

00:31:07,000 --> 00:31:12,940
elimination is possible as part of

00:31:09,880 --> 00:31:15,820
linking and then in relation to that

00:31:12,940 --> 00:31:17,860
what are you observing in terms of

00:31:15,820 --> 00:31:22,840
resident memory sizes of your processes

00:31:17,860 --> 00:31:24,940
running versus J equivalent JVM so we

00:31:22,840 --> 00:31:28,720
didn't truly benchmark so we can't tell

00:31:24,940 --> 00:31:30,880
for sure but we have way cheaper heap

00:31:28,720 --> 00:31:32,530
typically because the first of all we

00:31:30,880 --> 00:31:34,420
don't have copying early generation

00:31:32,530 --> 00:31:37,570
which dub the case memory like area

00:31:34,420 --> 00:31:39,550
twice because it needs it like to copy

00:31:37,570 --> 00:31:43,300
somewhere right and we also don't have

00:31:39,550 --> 00:31:47,650
all the jet overhead typical jet

00:31:43,300 --> 00:31:49,140
code loaded code optimized code and all

00:31:47,650 --> 00:31:52,060
of the intermediate that affected

00:31:49,140 --> 00:31:55,690
compiler users so I would expect we have

00:31:52,060 --> 00:31:59,320
like at least like 50 200 megabytes like

00:31:55,690 --> 00:32:02,140
just advantage parental on a 5 5 12 heap

00:31:59,320 --> 00:32:03,340
so at least like 10% advantage

00:32:02,140 --> 00:32:06,370
in terms of how much data can fit in

00:32:03,340 --> 00:32:08,260
memory for the same head size but that's

00:32:06,370 --> 00:32:12,420
my rough estimate I haven't truly

00:32:08,260 --> 00:32:15,700
measured how much is it the same

00:32:12,420 --> 00:32:19,270
codebase I'll the same light that I said

00:32:15,700 --> 00:32:22,450
takes in both JVM and native so we yeah

00:32:19,270 --> 00:32:23,580
but I expected better every done

00:32:22,450 --> 00:32:26,400
I mean it's dead code elimination

00:32:23,580 --> 00:32:30,340
possible though true linking

00:32:26,400 --> 00:32:33,160
coordination we did sorry dead dead code

00:32:30,340 --> 00:32:34,750
elimination so we do so that code

00:32:33,160 --> 00:32:37,930
elimination happens actually a lot also

00:32:34,750 --> 00:32:41,860
first of all we do that code limit

00:32:37,930 --> 00:32:43,780
ourselves before LVM so we do a simple

00:32:41,860 --> 00:32:46,060
version of Scala GS global whole program

00:32:43,780 --> 00:32:47,920
does coordination it's slightly stupider

00:32:46,060 --> 00:32:50,470
because we don't really care about code

00:32:47,920 --> 00:32:53,020
size as much as college ESS so we

00:32:50,470 --> 00:32:55,240
basically trade a simpler faster like

00:32:53,020 --> 00:32:58,330
that coordination but it still happens

00:32:55,240 --> 00:32:59,980
at length time and of course LVN

00:32:58,330 --> 00:33:02,170
optimizes it even further after us but

00:32:59,980 --> 00:33:05,280
we help it by pre optimizing it

00:33:02,170 --> 00:33:11,010
beforehand so I guess there are

00:33:05,280 --> 00:33:14,020
trade-offs in this in mix GC collector

00:33:11,010 --> 00:33:17,860
the sizes of the blocks and the sizes of

00:33:14,020 --> 00:33:20,670
lines yeah how is that decided upon so

00:33:17,860 --> 00:33:24,550
essentially and so the original paper

00:33:20,670 --> 00:33:26,800
argues for 32k blocks and one high and

00:33:24,550 --> 00:33:29,550
twenty eight byte lines the lines are

00:33:26,800 --> 00:33:32,830
supposed to be very small because you

00:33:29,550 --> 00:33:34,390
never sleep an object basically sleep on

00:33:32,830 --> 00:33:35,830
line basis if you lines are too big you

00:33:34,390 --> 00:33:38,470
will have example if you have just one

00:33:35,830 --> 00:33:40,030
object in line it will be dirty so you

00:33:38,470 --> 00:33:43,420
will basically just keep too much memory

00:33:40,030 --> 00:33:46,540
you are not available for allocation so

00:33:43,420 --> 00:33:48,460
lines are supposed to be small and it's

00:33:46,540 --> 00:33:52,390
128 now and blocks are supposed to be

00:33:48,460 --> 00:33:54,880
large and it's basically the main

00:33:52,390 --> 00:33:57,130
invariant we haven't truly we try to

00:33:54,880 --> 00:34:00,760
benchmark in on a older implementation

00:33:57,130 --> 00:34:03,280
of a mix ahead on different sizes of

00:34:00,760 --> 00:34:05,350
blocks but it it seems like it is one

00:34:03,280 --> 00:34:07,270
picked by the original papers it is a

00:34:05,350 --> 00:34:09,580
good trade-off in terms of blocking line

00:34:07,270 --> 00:34:12,909
ties we might do some more when we have

00:34:09,580 --> 00:34:14,770
more real-world work those little bit

00:34:12,909 --> 00:34:15,580
more but I think the current trade-off

00:34:14,770 --> 00:34:17,470
of absurdity

00:34:15,580 --> 00:34:21,730
okay and whaha and 28 is a pretty good

00:34:17,470 --> 00:34:23,110
trade-off hi hey I was wondering if you

00:34:21,730 --> 00:34:25,900
were planning any other features that

00:34:23,110 --> 00:34:27,460
would require changes to the runtime

00:34:25,900 --> 00:34:30,610
such as green threads

00:34:27,460 --> 00:34:32,650
I would love green thread to happen but

00:34:30,610 --> 00:34:34,240
it just we don't have anything at the

00:34:32,650 --> 00:34:36,790
moment and the sensory at the moment

00:34:34,240 --> 00:34:38,950
just an idea something like goes

00:34:36,790 --> 00:34:43,510
goroutines built-in into the runtime

00:34:38,950 --> 00:34:45,430
would be super nice but essentially we

00:34:43,510 --> 00:34:46,870
will have safe points for because as

00:34:45,430 --> 00:34:48,310
soon as you have multi-threading you

00:34:46,870 --> 00:34:51,640
will need take points to stop all the

00:34:48,310 --> 00:34:53,530
strides to start the GC and safe points

00:34:51,640 --> 00:34:56,650
can also be used for preemption for

00:34:53,530 --> 00:34:57,700
green thread so the answer is it would

00:34:56,650 --> 00:35:00,820
be really cool to have it we don't have

00:34:57,700 --> 00:35:03,360
anything yet there it looks like we have

00:35:00,820 --> 00:35:07,270
no more questions okay thanks for coming

00:35:03,360 --> 00:35:09,330
[Applause]

00:35:07,270 --> 00:35:09,330

YouTube URL: https://www.youtube.com/watch?v=h311L2sDA4g


