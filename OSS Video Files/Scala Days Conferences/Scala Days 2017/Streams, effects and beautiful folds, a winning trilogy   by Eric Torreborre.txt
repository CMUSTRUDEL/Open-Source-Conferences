Title: Streams, effects and beautiful folds, a winning trilogy   by Eric Torreborre
Publication date: 2017-06-28
Playlist: Scala Days 2017
Description: 
	This video was recorded at Scala Days Copenhagen 2017
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Abstract: 
Most applications are just reading data, transforming it and writing it somewhere else. And there are great libraries in the Scala eco-system to support these use cases: Akka-Stream, fs2, Monix,... But if you look under the hood and try to understand how those libraries work you might be a bit scared by their complexity!

In this talk you will learn how to build a very minimal "streaming library" where all the difficult concerns are left to other libraries: eff for asynchronous computations and resources management, origami for extracting useful data out of the stream. Then you will able to decide how to spend your complexity budget and when you should pay for more powerful abstractions.
Captions: 
	00:00:03,470 --> 00:00:10,650
okay that go so hi everyone my name is

00:00:06,779 --> 00:00:13,590
Eric toy ball I please write the app use

00:00:10,650 --> 00:00:15,959
I work for Toronto Toronto is a huge

00:00:13,590 --> 00:00:19,109
online fashion store we sell t-shirts

00:00:15,959 --> 00:00:21,179
pants choose all of that and we have

00:00:19,109 --> 00:00:23,400
lots and lots of Engineers so if you

00:00:21,179 --> 00:00:26,130
thinking about joining please visit the

00:00:23,400 --> 00:00:28,259
booth today I want to tell you a nice

00:00:26,130 --> 00:00:30,539
story so in the universe somewhere

00:00:28,259 --> 00:00:33,170
there's this incredible thing it's a

00:00:30,539 --> 00:00:36,510
huge computer with infinite memory

00:00:33,170 --> 00:00:38,039
infinite memory and boundless CPU it can

00:00:36,510 --> 00:00:41,010
do whatever computation you throughout

00:00:38,039 --> 00:00:43,800
it it will do it it's very great it has

00:00:41,010 --> 00:00:44,340
this great developer that guy is super

00:00:43,800 --> 00:00:46,289
smart

00:00:44,340 --> 00:00:48,000
it can hold millions of mutable

00:00:46,289 --> 00:00:49,440
variables in his head and do all

00:00:48,000 --> 00:00:52,309
computations all at once and then

00:00:49,440 --> 00:00:54,780
program is really good at it

00:00:52,309 --> 00:00:57,390
unfortunately that's that's this is just

00:00:54,780 --> 00:00:58,949
a story right it's just in the movies we

00:00:57,390 --> 00:01:00,899
are living in a planet that has very

00:00:58,949 --> 00:01:04,800
finite resources who should take care of

00:01:00,899 --> 00:01:06,630
them and as developers well we are on

00:01:04,800 --> 00:01:09,720
average we're just average by definition

00:01:06,630 --> 00:01:11,600
of the world average so we do what we do

00:01:09,720 --> 00:01:14,490
the best and what do we do every day

00:01:11,600 --> 00:01:16,620
there's a wise man who said basically

00:01:14,490 --> 00:01:17,100
everything that you're doing in your day

00:01:16,620 --> 00:01:18,950
job

00:01:17,100 --> 00:01:21,210
is taking some data from somewhere

00:01:18,950 --> 00:01:21,630
transforming it and putting it somewhere

00:01:21,210 --> 00:01:23,900
else

00:01:21,630 --> 00:01:25,580
so who in the room is not doing this

00:01:23,900 --> 00:01:28,260
every day

00:01:25,580 --> 00:01:30,270
ok that's what I thought right we're all

00:01:28,260 --> 00:01:32,220
doing that in some form or another it's

00:01:30,270 --> 00:01:34,080
a very broad definition let's have a

00:01:32,220 --> 00:01:35,120
look at one of those applications that

00:01:34,080 --> 00:01:37,260
would look like this

00:01:35,120 --> 00:01:39,570
so let's say you want to read from a

00:01:37,260 --> 00:01:41,010
file that has temperatures and you want

00:01:39,570 --> 00:01:42,930
to convert them to something else

00:01:41,010 --> 00:01:45,870
so how would you do that in Scala it

00:01:42,930 --> 00:01:48,930
would just open the two files then

00:01:45,870 --> 00:01:50,850
iterate on all the lines maybe filter

00:01:48,930 --> 00:01:53,340
some of them out because they have

00:01:50,850 --> 00:01:55,250
commands and you don't want them and do

00:01:53,340 --> 00:01:59,550
your conversion and write the output

00:01:55,250 --> 00:02:01,170
that's what you would do so what's good

00:01:59,550 --> 00:02:03,690
and what's bad about this code above

00:02:01,170 --> 00:02:05,820
because it's kind of working right doing

00:02:03,690 --> 00:02:08,520
the job so the first thing that's that's

00:02:05,820 --> 00:02:10,890
good about this code is that because we

00:02:08,520 --> 00:02:13,109
have finite resources it's smart enough

00:02:10,890 --> 00:02:15,209
it's not going to load the whole content

00:02:13,109 --> 00:02:16,030
of the file in memory using an iterator

00:02:15,209 --> 00:02:18,040
to do this

00:02:16,030 --> 00:02:19,630
doesn't have to load all the lines at

00:02:18,040 --> 00:02:21,610
once then process them and then write

00:02:19,630 --> 00:02:23,140
them out so that's nice

00:02:21,610 --> 00:02:26,860
that's pretty nice and probably is doing

00:02:23,140 --> 00:02:29,740
that pretty fast as well but there are

00:02:26,860 --> 00:02:32,470
some difficulties what's not so good

00:02:29,740 --> 00:02:34,120
about this code so one issue about this

00:02:32,470 --> 00:02:36,400
code is that it's using the for each

00:02:34,120 --> 00:02:39,130
method so basically it's returning units

00:02:36,400 --> 00:02:40,860
so as a consumer of that code you don't

00:02:39,130 --> 00:02:43,720
really know what it is doing you have to

00:02:40,860 --> 00:02:46,209
go look at the implementation to see

00:02:43,720 --> 00:02:47,890
okay doing filtering is it writing

00:02:46,209 --> 00:02:49,959
somewhere what is it doing really so

00:02:47,890 --> 00:02:52,690
it's not obvious to know what it is

00:02:49,959 --> 00:02:54,730
doing another thing that's not so good

00:02:52,690 --> 00:02:56,650
is that it's taking each line and doing

00:02:54,730 --> 00:02:58,510
some conversions like assuming that all

00:02:56,650 --> 00:03:01,390
the strings that are not commands can be

00:02:58,510 --> 00:03:03,010
converted to double but as we know we

00:03:01,390 --> 00:03:05,590
are dealing with data it can be really

00:03:03,010 --> 00:03:07,840
messy and that might just blow up and

00:03:05,590 --> 00:03:09,519
what would happen if that blows up if

00:03:07,840 --> 00:03:11,920
you cannot convert to double you have an

00:03:09,519 --> 00:03:14,560
exception and maybe you cannot close

00:03:11,920 --> 00:03:17,110
yourselves and that means you are going

00:03:14,560 --> 00:03:18,940
to leak some resources and again we've

00:03:17,110 --> 00:03:21,760
lived on the planet with very finite

00:03:18,940 --> 00:03:23,890
resources and file handles are such

00:03:21,760 --> 00:03:25,870
resources we should make sure we closed

00:03:23,890 --> 00:03:27,880
them properly so if you want to fix that

00:03:25,870 --> 00:03:29,890
code you probably need to add some

00:03:27,880 --> 00:03:32,410
try-catch block and finally and make

00:03:29,890 --> 00:03:36,100
sure things are closed properly so it

00:03:32,410 --> 00:03:37,750
becomes a bit more messy again another

00:03:36,100 --> 00:03:40,269
issue with the piece of code that we've

00:03:37,750 --> 00:03:42,190
seen is that if you want to have to add

00:03:40,269 --> 00:03:43,720
one more piece of behavior like count

00:03:42,190 --> 00:03:46,900
the number of lines because you want to

00:03:43,720 --> 00:03:49,690
say we I mean lines did I converted

00:03:46,900 --> 00:03:51,970
it's like conceptually just adding one

00:03:49,690 --> 00:03:54,160
piece of behavior but effectively you

00:03:51,970 --> 00:03:56,440
will have to add this thing into three

00:03:54,160 --> 00:03:58,120
different places so at the beginning of

00:03:56,440 --> 00:04:00,519
the code you need a variable then you

00:03:58,120 --> 00:04:02,109
need to increment it and then finally

00:04:00,519 --> 00:04:05,140
you need to output your your results

00:04:02,109 --> 00:04:06,730
it's like one behavior gets splitted

00:04:05,140 --> 00:04:08,440
into three places it's not very

00:04:06,730 --> 00:04:10,329
compositional it's not so nice

00:04:08,440 --> 00:04:12,910
you have to kind of you're trying to

00:04:10,329 --> 00:04:16,500
cram everything at the same place not so

00:04:12,910 --> 00:04:19,359
good can we do some anything better to

00:04:16,500 --> 00:04:22,510
still do streaming not have all the

00:04:19,359 --> 00:04:25,060
lines into memory but have better

00:04:22,510 --> 00:04:27,220
properties and actually of course we can

00:04:25,060 --> 00:04:29,860
and the solution is string user serving

00:04:27,220 --> 00:04:32,169
library right let's should be the

00:04:29,860 --> 00:04:35,080
dissolution or can go by other names

00:04:32,169 --> 00:04:36,430
like to Ricky's or use observables but

00:04:35,080 --> 00:04:39,159
there are solutions for this problem

00:04:36,430 --> 00:04:41,289
it's streaming libraries so if you are

00:04:39,159 --> 00:04:43,689
newcomer to Scala and someone tells you

00:04:41,289 --> 00:04:44,590
okay use a streaming library so which

00:04:43,689 --> 00:04:46,210
one should I take

00:04:44,590 --> 00:04:48,340
and you start having a look at those

00:04:46,210 --> 00:04:51,520
trimming libraries and you open the hood

00:04:48,340 --> 00:04:53,439
and what's oh what's inside and oh my

00:04:51,520 --> 00:04:55,419
it's actually pretty complicated and

00:04:53,439 --> 00:04:56,949
you're thinking I'm trying to solve a

00:04:55,419 --> 00:05:00,099
simple problem why it's so complicated

00:04:56,949 --> 00:05:01,840
so we're going to make a small tour of

00:05:00,099 --> 00:05:03,370
all the different swimming libraries and

00:05:01,840 --> 00:05:05,379
try to understand why they are

00:05:03,370 --> 00:05:08,500
complicated and why why really are

00:05:05,379 --> 00:05:10,689
they're trying to achieve so the

00:05:08,500 --> 00:05:12,310
granddaddy of all streaming libraries

00:05:10,689 --> 00:05:16,419
and we're going to make a detour by

00:05:12,310 --> 00:05:18,159
Haskell is the conduit library and as

00:05:16,419 --> 00:05:19,629
you can see that's the main data type in

00:05:18,159 --> 00:05:21,909
conduit so maybe you're not familiar

00:05:19,629 --> 00:05:25,779
with Haskell but all the letters io m

00:05:21,909 --> 00:05:27,610
are our type parameters and well you

00:05:25,779 --> 00:05:29,770
already have four type parameters for

00:05:27,610 --> 00:05:31,330
streaming library so kind of encoding

00:05:29,770 --> 00:05:34,150
different types of things like the

00:05:31,330 --> 00:05:36,699
inputs value the output value some kind

00:05:34,150 --> 00:05:39,789
of effect with the monad and some kind

00:05:36,699 --> 00:05:41,740
of final value do we really need all of

00:05:39,789 --> 00:05:43,690
that for string library now that's

00:05:41,740 --> 00:05:45,909
interesting I don't know because the

00:05:43,690 --> 00:05:48,789
next arbor in Haskell does even worse is

00:05:45,909 --> 00:05:51,039
has six type parameters and now we have

00:05:48,789 --> 00:05:52,539
a and a prime D and B prime because

00:05:51,039 --> 00:05:54,419
apparently the information can flow

00:05:52,539 --> 00:05:57,219
upstream that can also flow downstream

00:05:54,419 --> 00:05:59,319
wow I didn't realize that for reading a

00:05:57,219 --> 00:06:01,900
simple file we had different flows of

00:05:59,319 --> 00:06:05,949
information okay more and more complex

00:06:01,900 --> 00:06:08,560
and there are this interesting libraries

00:06:05,949 --> 00:06:10,240
in this one here is in Scala but it's

00:06:08,560 --> 00:06:11,830
actually infiltration of an existing

00:06:10,240 --> 00:06:15,039
library in Haskell is called machines

00:06:11,830 --> 00:06:17,409
and this one is pretty mystifying if you

00:06:15,039 --> 00:06:19,599
read the the documentation says that you

00:06:17,409 --> 00:06:22,029
have a machine you can come plan you can

00:06:19,599 --> 00:06:24,939
compile it to a machine core routine

00:06:22,029 --> 00:06:26,199
driven it's real I don't even know what

00:06:24,939 --> 00:06:27,699
that thing is it's really hard to

00:06:26,199 --> 00:06:30,339
understand if you just want to read a

00:06:27,699 --> 00:06:31,990
file it's really not obvious so then

00:06:30,339 --> 00:06:33,639
you're thinking okay this is all this is

00:06:31,990 --> 00:06:35,199
Haskell those guys are crazy they won't

00:06:33,639 --> 00:06:38,110
this is doing crazy stuff

00:06:35,199 --> 00:06:40,240
so in Scala we have like some nice

00:06:38,110 --> 00:06:42,219
libraries like a stream so I should just

00:06:40,240 --> 00:06:43,479
use that so who in the room is currently

00:06:42,219 --> 00:06:46,569
using our custom

00:06:43,479 --> 00:06:51,909
who who really understands the internal

00:06:46,569 --> 00:06:55,479
logic a stream let's good on you because

00:06:51,909 --> 00:06:57,669
so the motivation for ARCA stream is is

00:06:55,479 --> 00:06:59,379
the first one is like let's solve the

00:06:57,669 --> 00:07:01,539
trimming problem data is too large to

00:06:59,379 --> 00:07:03,669
fit in memory like a stream switch I'll

00:07:01,539 --> 00:07:06,159
solve that the second one is actually

00:07:03,669 --> 00:07:08,229
interesting is actors offer no static

00:07:06,159 --> 00:07:09,699
guarantee I didn't know I had an actor

00:07:08,229 --> 00:07:10,779
problem it's like someone telling me oh

00:07:09,699 --> 00:07:13,270
you have a drinking problem

00:07:10,779 --> 00:07:15,759
really but apparently there's an actor

00:07:13,270 --> 00:07:17,669
program and then there's this idea of

00:07:15,759 --> 00:07:19,599
back pressure that should be handled and

00:07:17,669 --> 00:07:21,789
okay oh that's interesting

00:07:19,599 --> 00:07:23,319
now there's a new problem and you had

00:07:21,789 --> 00:07:25,719
streaming as a problem but back pressure

00:07:23,319 --> 00:07:28,029
is also one so back pushers when you're

00:07:25,719 --> 00:07:30,879
trying to do some processing and someone

00:07:28,029 --> 00:07:33,219
keeps sending more work at you and you

00:07:30,879 --> 00:07:34,479
say oh I cannot handle it anymore so

00:07:33,219 --> 00:07:37,060
apparently that's something we need to

00:07:34,479 --> 00:07:39,909
deal with so how is it done in like a

00:07:37,060 --> 00:07:42,460
stream so the main data structure is a

00:07:39,909 --> 00:07:45,460
flow and now we are down to three type

00:07:42,460 --> 00:07:47,169
parameters inputs outputs and value

00:07:45,460 --> 00:07:49,449
that's going to be matter realized like

00:07:47,169 --> 00:07:53,050
at the end you are a king you're going

00:07:49,449 --> 00:07:54,939
to end up with one value and but it

00:07:53,050 --> 00:07:58,389
extends something called a graph and

00:07:54,939 --> 00:08:00,339
using a flow shape so what what that

00:07:58,389 --> 00:08:01,360
means is that in a castrum not only

00:08:00,339 --> 00:08:03,249
you're trying to solve the streaming

00:08:01,360 --> 00:08:04,719
problem but you're also trying to

00:08:03,249 --> 00:08:06,759
represent the fact that you have

00:08:04,719 --> 00:08:09,370
different processing entities as a graph

00:08:06,759 --> 00:08:11,469
of processing entities and you want to

00:08:09,370 --> 00:08:13,409
do to know what's the shape of that

00:08:11,469 --> 00:08:16,060
graph and you want to represent that and

00:08:13,409 --> 00:08:18,039
actually it turns out that just wanting

00:08:16,060 --> 00:08:20,709
to add just having these constraints

00:08:18,039 --> 00:08:24,580
interred in your streaming library makes

00:08:20,709 --> 00:08:27,219
it a bit more complex the other

00:08:24,580 --> 00:08:29,529
well-known library is FS - so who's

00:08:27,219 --> 00:08:31,599
using FS to the complement of the acha

00:08:29,529 --> 00:08:34,719
stream or not a lot well I was expecting

00:08:31,599 --> 00:08:37,300
the or called--it stream okay even let's

00:08:34,719 --> 00:08:39,610
know yeah moving okay so that's the

00:08:37,300 --> 00:08:42,729
functional programming equivalent of a

00:08:39,610 --> 00:08:44,649
castrum if you want and here the design

00:08:42,729 --> 00:08:46,360
goals are to be compositional no

00:08:44,649 --> 00:08:48,100
surprise for people coming from

00:08:46,360 --> 00:08:51,149
functional programming being expressive

00:08:48,100 --> 00:08:53,680
and oh there's a new concern which

00:08:51,149 --> 00:08:55,620
reflects the one we had when reading the

00:08:53,680 --> 00:08:58,800
files is resource safety so

00:08:55,620 --> 00:09:00,900
it looks like in ssj2 resource safety is

00:08:58,800 --> 00:09:03,300
baked in the library it's like something

00:09:00,900 --> 00:09:05,910
you should read care care about why is

00:09:03,300 --> 00:09:08,220
it not mentioned in a gas stream and the

00:09:05,910 --> 00:09:10,170
main motivation is kind of the question

00:09:08,220 --> 00:09:11,970
does that mean that a cache windows and

00:09:10,170 --> 00:09:14,400
handle it does that mean that I have to

00:09:11,970 --> 00:09:16,140
add more coat on top of that so if

00:09:14,400 --> 00:09:19,920
you're new to streaming libraries you

00:09:16,140 --> 00:09:21,720
might wonder and speed of course so

00:09:19,920 --> 00:09:23,700
what's the main data structure NFS -

00:09:21,720 --> 00:09:26,040
it's a stream oh and this time it looks

00:09:23,700 --> 00:09:28,740
simpler because you have just one

00:09:26,040 --> 00:09:30,150
outputs parameter type parameter to

00:09:28,740 --> 00:09:33,360
describe the things you are emitting

00:09:30,150 --> 00:09:35,670
values of type oh and something that's

00:09:33,360 --> 00:09:38,279
very common in in functional programming

00:09:35,670 --> 00:09:40,710
is a type constructor F that's going to

00:09:38,279 --> 00:09:43,050
denote the effects you're going to have

00:09:40,710 --> 00:09:45,240
so as you are producing those values of

00:09:43,050 --> 00:09:47,130
type oh you might do some effects like

00:09:45,240 --> 00:09:50,210
reading from the file that's an effect

00:09:47,130 --> 00:09:54,450
and you generally encode this in a type

00:09:50,210 --> 00:09:56,460
constructor in Skyrim so in a way if

00:09:54,450 --> 00:09:59,460
this does everything that a castering

00:09:56,460 --> 00:10:02,910
does is simpler just to type parameters

00:09:59,460 --> 00:10:04,500
but then you look inside what is it and

00:10:02,910 --> 00:10:05,880
then you have an explosion of concepts

00:10:04,500 --> 00:10:08,250
like you need to know about string

00:10:05,880 --> 00:10:10,589
course tack different types of segments

00:10:08,250 --> 00:10:12,690
there's a notion of scope you learn that

00:10:10,589 --> 00:10:14,250
the data is chunked into memory and the

00:10:12,690 --> 00:10:17,370
strengths they need to be preserved as

00:10:14,250 --> 00:10:21,510
you do transformation oh all sorts of

00:10:17,370 --> 00:10:25,740
complexity jumps at you the side will

00:10:21,510 --> 00:10:27,630
get swayed so swive is another library

00:10:25,740 --> 00:10:29,990
which in some ways look a bit like a

00:10:27,630 --> 00:10:33,930
castrum that makes different trade-offs

00:10:29,990 --> 00:10:38,190
wants to be very fast simple debuggable

00:10:33,930 --> 00:10:40,560
and so on now just to type parameters

00:10:38,190 --> 00:10:43,830
and maybe essentially just one something

00:10:40,560 --> 00:10:46,880
supporting some stream operations and it

00:10:43,830 --> 00:10:49,560
says that oh it says that he wants to be

00:10:46,880 --> 00:10:51,900
representing graph components so again

00:10:49,560 --> 00:10:53,730
you have this idea that possibly it's

00:10:51,900 --> 00:10:56,010
useful to represent a graph of

00:10:53,730 --> 00:10:58,620
components and because of that if you

00:10:56,010 --> 00:11:00,959
look inside sways it starts becoming

00:10:58,620 --> 00:11:03,029
slightly more complex again because you

00:11:00,959 --> 00:11:05,400
need to represent all of that and then

00:11:03,029 --> 00:11:07,690
new concepts appear like you need to

00:11:05,400 --> 00:11:09,700
sign in at some stage

00:11:07,690 --> 00:11:11,470
you have something called a spout and

00:11:09,700 --> 00:11:14,020
it's using shapeless in many places

00:11:11,470 --> 00:11:16,540
because it's tracking very precisely the

00:11:14,020 --> 00:11:18,850
types of all the transformations so that

00:11:16,540 --> 00:11:22,240
also makes it a library that's on the

00:11:18,850 --> 00:11:26,950
surface pretty Pleasant but internally a

00:11:22,240 --> 00:11:28,150
bit harder to understand anyone knows

00:11:26,950 --> 00:11:30,280
about it erectus

00:11:28,150 --> 00:11:31,900
there's one two three four five so yeah

00:11:30,280 --> 00:11:33,880
so yeah used to be to rake it in play

00:11:31,900 --> 00:11:37,660
and that's also something that's coming

00:11:33,880 --> 00:11:39,580
from from the Haskell iterate is they

00:11:37,660 --> 00:11:42,550
want to do resource management trimming

00:11:39,580 --> 00:11:44,470
fusion Oh new concern fusion what was it

00:11:42,550 --> 00:11:45,790
all about so this one is pretty simple

00:11:44,470 --> 00:11:47,560
it's not really mentioned by the other

00:11:45,790 --> 00:11:49,840
ones because it's kind of natural that

00:11:47,560 --> 00:11:51,970
they are going to few stuff it's the

00:11:49,840 --> 00:11:53,980
idea that if you have to map operations

00:11:51,970 --> 00:11:56,080
when you're processing something you are

00:11:53,980 --> 00:11:57,700
not going to read your string twice just

00:11:56,080 --> 00:11:59,200
to do those two transformations you can

00:11:57,700 --> 00:12:02,440
just fuse the two Matt's operation at

00:11:59,200 --> 00:12:04,300
once and do that all at once makes sense

00:12:02,440 --> 00:12:07,330
but it says that it's not really for

00:12:04,300 --> 00:12:09,090
concurrency so if you want to do any

00:12:07,330 --> 00:12:12,340
kind of concurrency use your course

00:12:09,090 --> 00:12:14,670
maybe you will not use iterative and the

00:12:12,340 --> 00:12:16,450
main concepts in its rate is are

00:12:14,670 --> 00:12:19,020
interesting compared to what we've seen

00:12:16,450 --> 00:12:22,180
before just not one thing encoding

00:12:19,020 --> 00:12:24,520
everything it means to about processing

00:12:22,180 --> 00:12:25,930
and streaming they are free think

00:12:24,520 --> 00:12:29,650
there's an enumerator

00:12:25,930 --> 00:12:31,990
to output some values enumerate T that

00:12:29,650 --> 00:12:34,720
transform those values and iterate II

00:12:31,990 --> 00:12:37,510
that accumulates some values and finally

00:12:34,720 --> 00:12:40,060
producing produces an output so we will

00:12:37,510 --> 00:12:42,070
see more about this iterative thing the

00:12:40,060 --> 00:12:44,560
names are very scary to me when I first

00:12:42,070 --> 00:12:48,540
read about that what's hard for me to

00:12:44,560 --> 00:12:51,490
understand and the last one is monix

00:12:48,540 --> 00:12:54,339
which is famous for is it's a library

00:12:51,490 --> 00:12:59,080
that famous for its task at the data

00:12:54,339 --> 00:13:01,870
type but it can also do streaming and it

00:12:59,080 --> 00:13:04,360
has to be asynchronous reactive

00:13:01,870 --> 00:13:07,630
streaming and also dealing with back

00:13:04,360 --> 00:13:08,920
pressure and the main abstractions here

00:13:07,630 --> 00:13:12,339
are the fact that you can have an

00:13:08,920 --> 00:13:14,110
observable emitting some ace and you can

00:13:12,339 --> 00:13:16,300
have consumers that are going to consume

00:13:14,110 --> 00:13:19,430
these eggs and do something interesting

00:13:16,300 --> 00:13:22,490
with that so

00:13:19,430 --> 00:13:24,650
lots of libraries that apparently on the

00:13:22,490 --> 00:13:27,410
surface trying to do the same thing

00:13:24,650 --> 00:13:29,270
which is streaming but they all have

00:13:27,410 --> 00:13:31,130
their different differences they are not

00:13:29,270 --> 00:13:33,770
exactly the same they put in faces on

00:13:31,130 --> 00:13:41,540
some some stuff and some not some other

00:13:33,770 --> 00:13:42,080
things so my question is how can we how

00:13:41,540 --> 00:13:43,550
can we

00:13:42,080 --> 00:13:46,640
is it possible to deal with all those

00:13:43,550 --> 00:13:49,780
concerns like composition concurrency

00:13:46,640 --> 00:13:53,030
back pressure resource safety topology

00:13:49,780 --> 00:13:54,590
in different libraries does it have to

00:13:53,030 --> 00:13:57,320
be crammed everything under the same

00:13:54,590 --> 00:13:59,630
library so that it effectively makes it

00:13:57,320 --> 00:14:01,220
too real complex beast to understand so

00:13:59,630 --> 00:14:02,930
this is what I want to explore with you

00:14:01,220 --> 00:14:04,940
today is it possible to reconstruct all

00:14:02,930 --> 00:14:08,870
of that from the ground up in different

00:14:04,940 --> 00:14:11,810
libraries okay it explode all the things

00:14:08,870 --> 00:14:13,550
so they can be more manageable so we

00:14:11,810 --> 00:14:16,360
will see how we can reproduce some of

00:14:13,550 --> 00:14:19,610
that using three libraries producer

00:14:16,360 --> 00:14:22,520
origami which is a folding library and F

00:14:19,610 --> 00:14:24,290
which is an effect library so the first

00:14:22,520 --> 00:14:26,750
one is producer so we need to solve

00:14:24,290 --> 00:14:28,070
what's the best way the most in a way

00:14:26,750 --> 00:14:31,970
natural way to solve the streaming

00:14:28,070 --> 00:14:35,270
problem and you can have a look online

00:14:31,970 --> 00:14:37,160
for this librarian it's on github so if

00:14:35,270 --> 00:14:39,110
you want to stream stuff you need to

00:14:37,160 --> 00:14:40,850
make sure that at any point in time you

00:14:39,110 --> 00:14:42,950
don't have too much elements in memory

00:14:40,850 --> 00:14:45,410
so either you have no elements that's

00:14:42,950 --> 00:14:48,320
the situation you can come home or you

00:14:45,410 --> 00:14:50,750
have one also not to have all you have a

00:14:48,320 --> 00:14:53,450
bunch of elements but not more than your

00:14:50,750 --> 00:14:55,580
memory and when you're done with those

00:14:53,450 --> 00:14:58,130
elements you have some kind of pointer

00:14:55,580 --> 00:14:59,960
for the next thing to do right and the

00:14:58,130 --> 00:15:03,200
next thing to do is what well it's

00:14:59,960 --> 00:15:06,050
either 0 element or 1 element or n

00:15:03,200 --> 00:15:08,150
elements and the next thing to do so you

00:15:06,050 --> 00:15:10,370
have this kind of recursive data

00:15:08,150 --> 00:15:12,080
structure that's precisely going to

00:15:10,370 --> 00:15:13,910
encode this idea of I don't want too

00:15:12,080 --> 00:15:16,160
much stuff into memory so if you

00:15:13,910 --> 00:15:18,770
translate this idea into some scalar

00:15:16,160 --> 00:15:20,330
code you can write something like this

00:15:18,770 --> 00:15:22,760
where you have the producer that's

00:15:20,330 --> 00:15:25,580
enclosing a stream and you have those

00:15:22,760 --> 00:15:28,010
three cases either you're done or you

00:15:25,580 --> 00:15:31,490
have one element or you have a bunch of

00:15:28,010 --> 00:15:33,350
elements and the next producer

00:15:31,490 --> 00:15:35,779
so what can we do with this data

00:15:33,350 --> 00:15:37,490
structure sort of sorry the first thing

00:15:35,779 --> 00:15:40,160
the other thing I need to mention is

00:15:37,490 --> 00:15:45,079
that all of that is kind of enclosed

00:15:40,160 --> 00:15:48,230
into an m-type constructor that we are

00:15:45,079 --> 00:15:50,269
going to use for FX that means that you

00:15:48,230 --> 00:15:52,670
don't want to evaluate all the producers

00:15:50,269 --> 00:15:54,529
all the time and those things might come

00:15:52,670 --> 00:15:56,839
from a disk somewhere so you're going to

00:15:54,529 --> 00:15:58,249
have side effects and you will use the

00:15:56,839 --> 00:16:00,860
fact that M is a monads

00:15:58,249 --> 00:16:04,429
like the i/o monad for example - to

00:16:00,860 --> 00:16:06,889
represent that so how can we even create

00:16:04,429 --> 00:16:09,529
producers so we can have some smart

00:16:06,889 --> 00:16:12,740
constructors like that like Don just one

00:16:09,529 --> 00:16:16,490
more elements or just emit a bunch of

00:16:12,740 --> 00:16:18,860
elements right away you can also create

00:16:16,490 --> 00:16:21,230
a producer from an iterator that's going

00:16:18,860 --> 00:16:24,319
to read the next element until it has

00:16:21,230 --> 00:16:27,980
ego next next next next and if there's

00:16:24,319 --> 00:16:31,040
no next you're done ok all you could

00:16:27,980 --> 00:16:32,300
repeat the value infinitely and it's not

00:16:31,040 --> 00:16:36,290
very hard to implement this method

00:16:32,300 --> 00:16:38,209
you're just doing a and the next thing

00:16:36,290 --> 00:16:40,459
will be repeat value and the next thing

00:16:38,209 --> 00:16:42,470
will be repeat value and so on or you

00:16:40,459 --> 00:16:45,889
could use an unfold method that starts

00:16:42,470 --> 00:16:47,990
from a seed that tries to find what's

00:16:45,889 --> 00:16:50,899
the next element and using an option

00:16:47,990 --> 00:16:53,809
says ok either I'm done or I want to

00:16:50,899 --> 00:16:56,509
compute more elements as as I go so

00:16:53,809 --> 00:16:59,329
those are ways to create finite

00:16:56,509 --> 00:17:01,730
producers but also infinite ones if you

00:16:59,329 --> 00:17:05,480
want to create producers that produce

00:17:01,730 --> 00:17:06,740
elements forever you can also do it so

00:17:05,480 --> 00:17:08,839
what can you do with those producers

00:17:06,740 --> 00:17:10,789
well kind of things we want to do with

00:17:08,839 --> 00:17:12,529
that is transform elements so we want to

00:17:10,789 --> 00:17:14,569
map on them and it's not how to

00:17:12,529 --> 00:17:17,089
implement because this M is a monad it

00:17:14,569 --> 00:17:19,870
has a map operation and the

00:17:17,089 --> 00:17:22,970
implementation is pretty straightforward

00:17:19,870 --> 00:17:25,459
the next thing we we might want to do is

00:17:22,970 --> 00:17:27,620
to append to producers together so we

00:17:25,459 --> 00:17:29,390
say you run the first one if it's

00:17:27,620 --> 00:17:32,020
finished you can start the second one

00:17:29,390 --> 00:17:34,850
that's very useful operation to have and

00:17:32,020 --> 00:17:36,649
this one we need to use flat map so we

00:17:34,850 --> 00:17:39,620
need to have this flat map operation on

00:17:36,649 --> 00:17:41,660
em to be able to implement to implement

00:17:39,620 --> 00:17:43,940
this

00:17:41,660 --> 00:17:46,490
but you can also apparent that not on

00:17:43,940 --> 00:17:49,400
the producer datatype itself so you can

00:17:46,490 --> 00:17:51,350
say I want to produce a new producer for

00:17:49,400 --> 00:17:53,810
each element that I'm that I'm seeing

00:17:51,350 --> 00:17:55,760
and it's also possible so the

00:17:53,810 --> 00:17:58,610
implementation is a bit more involved

00:17:55,760 --> 00:18:00,530
but actually if you sit down for a

00:17:58,610 --> 00:18:02,180
minute if you follow the types and go

00:18:00,530 --> 00:18:05,000
through all the cases it's not that hard

00:18:02,180 --> 00:18:07,730
to implement this all means that this

00:18:05,000 --> 00:18:10,970
nice data type is Moana also because it

00:18:07,730 --> 00:18:13,070
has matte flat matte and cure and okay

00:18:10,970 --> 00:18:15,590
simply said well-behaved and nice data

00:18:13,070 --> 00:18:16,610
type and with this you can do many of

00:18:15,590 --> 00:18:18,800
the things you can do with collections

00:18:16,610 --> 00:18:22,460
so you can filter you can take you can

00:18:18,800 --> 00:18:25,010
drop you can reach UNK because if it's

00:18:22,460 --> 00:18:26,930
if it's evaluating M elements in memory

00:18:25,010 --> 00:18:30,410
you can say oh now I want to evaluate

00:18:26,930 --> 00:18:32,390
more or less you can produce creative

00:18:30,410 --> 00:18:36,230
producer is going to be a recite in a

00:18:32,390 --> 00:18:39,080
way and you can implement also some

00:18:36,230 --> 00:18:43,060
operations that are going to do some

00:18:39,080 --> 00:18:45,860
some state computation so you can create

00:18:43,060 --> 00:18:48,320
transcripts from a producer of type a

00:18:45,860 --> 00:18:51,260
you can create producer of Tidy that's

00:18:48,320 --> 00:18:53,510
going to compute all the B's taking the

00:18:51,260 --> 00:18:56,270
current a the current state to compute

00:18:53,510 --> 00:18:58,010
the next B and this is again not very

00:18:56,270 --> 00:19:00,830
hard to implement and if you implement

00:18:58,010 --> 00:19:03,230
it then it opens a whole lot of

00:19:00,830 --> 00:19:06,110
functions that come for free so like zip

00:19:03,230 --> 00:19:08,690
with index for example it's very easy to

00:19:06,110 --> 00:19:11,600
implement this with scan or zip with the

00:19:08,690 --> 00:19:13,250
next element where you you can have the

00:19:11,600 --> 00:19:15,200
current elements and the next element

00:19:13,250 --> 00:19:16,640
and this is an option because if you are

00:19:15,200 --> 00:19:18,560
at the end of the stream there's no not

00:19:16,640 --> 00:19:20,930
element but this is really nice because

00:19:18,560 --> 00:19:22,760
when you're streaming data generally you

00:19:20,930 --> 00:19:24,470
just see one element at a time but

00:19:22,760 --> 00:19:26,210
sometimes it's useful to see bit more

00:19:24,470 --> 00:19:27,830
context around that element so if you

00:19:26,210 --> 00:19:30,710
use zip with next

00:19:27,830 --> 00:19:32,450
zip with curvy previous I always if with

00:19:30,710 --> 00:19:34,700
previous and next and you can even

00:19:32,450 --> 00:19:37,730
extend that to a bunch of elements you

00:19:34,700 --> 00:19:39,470
can also progress on your stream having

00:19:37,730 --> 00:19:43,880
the context around the current element

00:19:39,470 --> 00:19:45,800
so that's super useful but up to now we

00:19:43,880 --> 00:19:48,560
haven't been doing really anything right

00:19:45,800 --> 00:19:52,730
just creating stuff transforming it not

00:19:48,560 --> 00:19:55,250
really we haven't run anything so how to

00:19:52,730 --> 00:19:58,130
run a producer you can run it to get

00:19:55,250 --> 00:20:00,650
list of elements in a way it looks a bit

00:19:58,130 --> 00:20:02,450
silly because we do all this work to

00:20:00,650 --> 00:20:04,040
avoid having all the elements in memory

00:20:02,450 --> 00:20:05,960
and then we produce the list of all the

00:20:04,040 --> 00:20:07,760
elements right so it's completely silly

00:20:05,960 --> 00:20:10,760
but it's very useful for testing

00:20:07,760 --> 00:20:12,830
obviously if you want to test on just a

00:20:10,760 --> 00:20:15,260
bunch of elements you can do that or you

00:20:12,830 --> 00:20:17,570
we might want to run up to the last

00:20:15,260 --> 00:20:20,210
element which might or might not be

00:20:17,570 --> 00:20:21,950
available in that case it looks also a

00:20:20,210 --> 00:20:25,910
bit silly because why would you want to

00:20:21,950 --> 00:20:27,620
get just the last element why and it's

00:20:25,910 --> 00:20:30,260
not actually not silly because this M

00:20:27,620 --> 00:20:32,720
monad might have some effects it might

00:20:30,260 --> 00:20:34,970
read from file so in that case this

00:20:32,720 --> 00:20:37,700
method is used to to run all those

00:20:34,970 --> 00:20:39,500
effects one by one so it is really going

00:20:37,700 --> 00:20:42,080
to do something even if it doesn't

00:20:39,500 --> 00:20:45,260
return some value that super interesting

00:20:42,080 --> 00:20:47,090
it is going to do something and there

00:20:45,260 --> 00:20:49,580
are two other methods which you can

00:20:47,090 --> 00:20:52,340
implement on producer which are very

00:20:49,580 --> 00:20:55,010
useful fold is a method that's going to

00:20:52,340 --> 00:20:58,280
take the food producer and compute some

00:20:55,010 --> 00:21:00,320
states starting with an initial value

00:20:58,280 --> 00:21:02,420
and for each elements you have you

00:21:00,320 --> 00:21:05,210
update the state possibly with some

00:21:02,420 --> 00:21:07,820
effects and eventually you can transform

00:21:05,210 --> 00:21:10,430
the final state into final results and

00:21:07,820 --> 00:21:11,900
you have also a slightly different

00:21:10,430 --> 00:21:14,240
version of that where you take an

00:21:11,900 --> 00:21:18,170
existing producer producing some a and

00:21:14,240 --> 00:21:21,440
you can observe those A's accumulating

00:21:18,170 --> 00:21:23,510
some states so you can go through all

00:21:21,440 --> 00:21:25,880
the ways in memory and every time you

00:21:23,510 --> 00:21:28,270
have a new a you do some kind of a site

00:21:25,880 --> 00:21:30,980
like write to database at this stage and

00:21:28,270 --> 00:21:34,130
and you can do this thankfully because

00:21:30,980 --> 00:21:37,130
there's a parameter to take to to to

00:21:34,130 --> 00:21:41,000
update the state as well so that's

00:21:37,130 --> 00:21:44,180
really useful and with all of this we

00:21:41,000 --> 00:21:46,490
can start rewriting the the example we

00:21:44,180 --> 00:21:50,150
we had in the beginning so we can read

00:21:46,490 --> 00:21:51,680
lines from a song as an iterator of

00:21:50,150 --> 00:21:53,930
strings we can create a producer from

00:21:51,680 --> 00:21:55,910
that and we can start processing that

00:21:53,930 --> 00:21:58,520
file so in that case you can do filter

00:21:55,910 --> 00:22:01,460
removing all the lines with comments and

00:21:58,520 --> 00:22:04,850
empty lines we can transform those lines

00:22:01,460 --> 00:22:06,500
and we can fold through the counts and

00:22:04,850 --> 00:22:08,450
in this case

00:22:06,500 --> 00:22:11,870
doing the counties is really like adding

00:22:08,450 --> 00:22:13,850
one operation in one place to count the

00:22:11,870 --> 00:22:15,770
number of lines the only issue that

00:22:13,850 --> 00:22:17,840
example is that we are going to do all

00:22:15,770 --> 00:22:20,210
the processing getting the note final

00:22:17,840 --> 00:22:22,250
number of lines but we haven't really

00:22:20,210 --> 00:22:23,990
written the lines anywhere so we did the

00:22:22,250 --> 00:22:26,960
transformation in memory at some stage

00:22:23,990 --> 00:22:29,090
but it's lost but that's the best we can

00:22:26,960 --> 00:22:30,140
do for now with with what we have but we

00:22:29,090 --> 00:22:33,220
can do better than this

00:22:30,140 --> 00:22:36,080
and that's what we are going to see next

00:22:33,220 --> 00:22:38,210
but now so what we've seen is that with

00:22:36,080 --> 00:22:41,330
this simple data structure we can solve

00:22:38,210 --> 00:22:42,919
the trimming problem it's very

00:22:41,330 --> 00:22:45,020
compositional because you have all sorts

00:22:42,919 --> 00:22:50,150
of operators you can define like filter

00:22:45,020 --> 00:22:52,120
map flatmap victories and so on and it

00:22:50,150 --> 00:22:55,880
kind of solved the backpressure problem

00:22:52,120 --> 00:22:58,490
why is because we are evaluating lots of

00:22:55,880 --> 00:23:00,799
elements but the producer decides when

00:22:58,490 --> 00:23:04,010
you want to evaluate stuff so it's doing

00:23:00,799 --> 00:23:06,320
something and it's not until it has

00:23:04,010 --> 00:23:08,750
finished doing that thing that it starts

00:23:06,320 --> 00:23:10,669
doing the next thing so there's no one

00:23:08,750 --> 00:23:13,190
really pushing anything to that producer

00:23:10,669 --> 00:23:17,780
to this computation to this long-running

00:23:13,190 --> 00:23:20,809
computation okay now let's see how we

00:23:17,780 --> 00:23:24,049
can deal with some some aspect of

00:23:20,809 --> 00:23:27,020
topology so we are producing elements in

00:23:24,049 --> 00:23:29,299
one line and and we would like to send

00:23:27,020 --> 00:23:31,909
some work to some other people to do and

00:23:29,299 --> 00:23:32,570
say oh can you please put this element

00:23:31,909 --> 00:23:34,250
in a foul

00:23:32,570 --> 00:23:36,020
can you please compute the number of

00:23:34,250 --> 00:23:37,820
elements can you please do this can you

00:23:36,020 --> 00:23:40,159
please do that have some kind of find

00:23:37,820 --> 00:23:45,740
out how would you model the some out

00:23:40,159 --> 00:23:50,059
behavior with this and this is provided

00:23:45,740 --> 00:23:51,559
by a library called origami so let's go

00:23:50,059 --> 00:23:54,770
back to this full function that was

00:23:51,559 --> 00:23:58,340
accumulating some states while running

00:23:54,770 --> 00:24:00,799
the the producer if we struct

00:23:58,340 --> 00:24:03,740
this whole function is - its fur its own

00:24:00,799 --> 00:24:05,360
thing as a salt object right it's almost

00:24:03,740 --> 00:24:09,530
the same definition I just made it the

00:24:05,360 --> 00:24:13,370
first class object so we have type s for

00:24:09,530 --> 00:24:16,130
the states the start state if we do some

00:24:13,370 --> 00:24:18,049
folding when we have new elements and

00:24:16,130 --> 00:24:20,380
based on the previous state and we

00:24:18,049 --> 00:24:23,110
finalized the the last value

00:24:20,380 --> 00:24:24,549
what can we do with that how while you

00:24:23,110 --> 00:24:27,910
would it be useful to have this as a

00:24:24,549 --> 00:24:29,500
first-class entity so one thing we can

00:24:27,910 --> 00:24:32,350
do is to count the number of elements

00:24:29,500 --> 00:24:35,320
with this so we can define a fault

00:24:32,350 --> 00:24:37,419
that's account fault where we say okay

00:24:35,320 --> 00:24:39,179
the start is zero every time you have a

00:24:37,419 --> 00:24:41,559
new element to just add plus one and

00:24:39,179 --> 00:24:45,880
eventually you return the value you

00:24:41,559 --> 00:24:49,210
computed and it turns out that this kind

00:24:45,880 --> 00:24:51,789
of computation where you have and zero

00:24:49,210 --> 00:24:54,010
elements when you are aggregating some

00:24:51,789 --> 00:24:55,870
information is more or less the

00:24:54,010 --> 00:25:00,039
trademark of the minoan and there are

00:24:55,870 --> 00:25:02,080
many monoeyes in nature so there's in

00:25:00,039 --> 00:25:04,090
the if you look at the origami library

00:25:02,080 --> 00:25:05,620
you can define count in just one line of

00:25:04,090 --> 00:25:08,370
code because many things are behaving

00:25:05,620 --> 00:25:12,610
like accounts having a zero element and

00:25:08,370 --> 00:25:15,220
aggregating some data it turns out that

00:25:12,610 --> 00:25:17,500
this concept of a fault is is not

00:25:15,220 --> 00:25:19,809
something that's really really new it

00:25:17,500 --> 00:25:21,820
looks it's resemble it's very close to

00:25:19,809 --> 00:25:24,460
something called co-routine so if you

00:25:21,820 --> 00:25:26,620
look at kuru things in Python they are

00:25:24,460 --> 00:25:28,480
almost the same so this is according to

00:25:26,620 --> 00:25:31,929
count the number of elements so you have

00:25:28,480 --> 00:25:34,030
some internal states and every time you

00:25:31,929 --> 00:25:36,280
receive a new value you update that

00:25:34,030 --> 00:25:39,070
state and how did you use this curve

00:25:36,280 --> 00:25:42,070
routine in Titan well you need to start

00:25:39,070 --> 00:25:43,900
it you need to send elements regularly

00:25:42,070 --> 00:25:46,210
to it and finally you need to close it

00:25:43,900 --> 00:25:49,030
it's almost the same structure and

00:25:46,210 --> 00:25:52,570
that's for a good reason that's the same

00:25:49,030 --> 00:25:54,340
thing we are doing so once we have this

00:25:52,570 --> 00:25:59,110
full abstraction we can define a method

00:25:54,340 --> 00:26:00,400
called - and send a producer and all the

00:25:59,110 --> 00:26:02,380
elements that are being produced to

00:26:00,400 --> 00:26:05,679
account and we will get the count of the

00:26:02,380 --> 00:26:07,720
number of elements but we can do a lot

00:26:05,679 --> 00:26:10,150
more because count is just one example

00:26:07,720 --> 00:26:12,010
you can count you can get the maximum

00:26:10,150 --> 00:26:15,220
the minimum you can get the first end

00:26:12,010 --> 00:26:17,230
the last end you can do things with

00:26:15,220 --> 00:26:19,960
Bereans gets if all the balloons are

00:26:17,230 --> 00:26:22,240
true or just one you can multiply things

00:26:19,960 --> 00:26:23,980
together you can do all kinds of

00:26:22,240 --> 00:26:26,980
statistics you want with that you can do

00:26:23,980 --> 00:26:29,460
average balance you can do the quantiles

00:26:26,980 --> 00:26:32,500
you can even have a probabilistic

00:26:29,460 --> 00:26:34,000
algorithms implemented as false because

00:26:32,500 --> 00:26:36,190
they are essentially for

00:26:34,000 --> 00:26:39,550
of accumulating some states and giving

00:26:36,190 --> 00:26:41,740
you a final answer and there's a very

00:26:39,550 --> 00:26:43,720
fundamental operation which is expanding

00:26:41,740 --> 00:26:46,060
even more what you can do with false is

00:26:43,720 --> 00:26:47,260
the zip operation and it's really easy

00:26:46,060 --> 00:26:50,050
to implement

00:26:47,260 --> 00:26:52,360
just try it at home it's super easy so

00:26:50,050 --> 00:26:54,130
you take two different folds you create

00:26:52,360 --> 00:26:55,660
a new folder on the two that's going to

00:26:54,130 --> 00:26:58,750
return the pair of the two results

00:26:55,660 --> 00:27:01,990
that's basically what it's doing so with

00:26:58,750 --> 00:27:05,560
this you can zip two folds together like

00:27:01,990 --> 00:27:07,660
counts and maximum and send all the

00:27:05,560 --> 00:27:09,720
elements to do two different

00:27:07,660 --> 00:27:14,380
computations independent computations

00:27:09,720 --> 00:27:17,070
joined at once and that can be written

00:27:14,380 --> 00:27:20,200
with this strange-looking operator

00:27:17,070 --> 00:27:24,610
this means that folds they have actually

00:27:20,200 --> 00:27:26,320
a more formal catarrhal categorical

00:27:24,610 --> 00:27:29,590
structure so they are applicative and

00:27:26,320 --> 00:27:31,540
because of that we can even go further

00:27:29,590 --> 00:27:34,150
with false you can compute with false

00:27:31,540 --> 00:27:36,580
you can define our with netic operations

00:27:34,150 --> 00:27:38,860
on false so if you have a fold to do

00:27:36,580 --> 00:27:42,280
some addition a fault to count elements

00:27:38,860 --> 00:27:45,790
you can divide folds together to compute

00:27:42,280 --> 00:27:47,680
the average let's recall you can even

00:27:45,790 --> 00:27:51,550
implement some more complex and crazy

00:27:47,680 --> 00:27:54,850
formulas where you can compute the sum

00:27:51,550 --> 00:27:56,560
of squares for example like this and how

00:27:54,850 --> 00:27:58,350
did you do the sum of squares well you

00:27:56,560 --> 00:28:01,270
already have a fault during the audition

00:27:58,350 --> 00:28:03,850
but you want to try to add squares so

00:28:01,270 --> 00:28:06,640
what do you do you use the control map

00:28:03,850 --> 00:28:08,530
operation on the fault to adapt the

00:28:06,640 --> 00:28:10,780
incoming elements instead of receiving

00:28:08,530 --> 00:28:13,090
them as they are and add them you just

00:28:10,780 --> 00:28:15,370
Square them before so you take an

00:28:13,090 --> 00:28:17,740
existing fault call plus you can come up

00:28:15,370 --> 00:28:21,520
on it to do the square and now boom you

00:28:17,740 --> 00:28:25,900
have a sum of squares so that's very

00:28:21,520 --> 00:28:28,180
nice so in a way Falls are a very simple

00:28:25,900 --> 00:28:30,520
answer to this topology problem where

00:28:28,180 --> 00:28:32,610
you have one stream emitting like

00:28:30,520 --> 00:28:34,780
elements in one direction and that

00:28:32,610 --> 00:28:37,660
conceptually you want to send to two

00:28:34,780 --> 00:28:42,660
different types of processing that's one

00:28:37,660 --> 00:28:44,740
way of doing that another very important

00:28:42,660 --> 00:28:47,290
specialization of fault is called sinks

00:28:44,740 --> 00:28:48,970
is cases where you don't

00:28:47,290 --> 00:28:52,270
we care about the final value you just

00:28:48,970 --> 00:28:53,710
care about the effects of what you are

00:28:52,270 --> 00:28:56,980
going to do every time you have some new

00:28:53,710 --> 00:29:00,280
element and some new states and one one

00:28:56,980 --> 00:29:02,140
way to create a sync is to for it all

00:29:00,280 --> 00:29:03,730
has a function taking each element and

00:29:02,140 --> 00:29:05,470
doing some side effect like writing to

00:29:03,730 --> 00:29:08,560
the file so it's very easy to create a

00:29:05,470 --> 00:29:10,780
fall from from from this function so for

00:29:08,560 --> 00:29:13,660
example we can create a console fault

00:29:10,780 --> 00:29:17,140
that's going to take each element and

00:29:13,660 --> 00:29:19,480
output it to the console and we can omit

00:29:17,140 --> 00:29:22,050
all the list to the console like that

00:29:19,480 --> 00:29:24,490
but because we have all these zips and

00:29:22,050 --> 00:29:27,460
composition of falls that's possible now

00:29:24,490 --> 00:29:30,190
we can do two things at once we can both

00:29:27,460 --> 00:29:32,800
count the number of elements and we can

00:29:30,190 --> 00:29:34,600
also send them to the console so we can

00:29:32,800 --> 00:29:36,490
do both computations that are side

00:29:34,600 --> 00:29:43,330
effecting and computations that are pure

00:29:36,490 --> 00:29:45,130
in the same thing so now we can write to

00:29:43,330 --> 00:29:46,600
a file as well so we can print to a

00:29:45,130 --> 00:29:48,220
console we can also write to a file so

00:29:46,600 --> 00:29:51,130
we can define you think that's going to

00:29:48,220 --> 00:29:53,670
write to given path and we can define a

00:29:51,130 --> 00:29:56,260
fault that's going to do the outputs of

00:29:53,670 --> 00:29:59,200
our processing where we read the lines

00:29:56,260 --> 00:30:02,890
we do the filtering we do the mapping to

00:29:59,200 --> 00:30:04,570
transform the each line into a double

00:30:02,890 --> 00:30:06,850
and then it's double into a Celsius

00:30:04,570 --> 00:30:09,190
degree and then we output all of this

00:30:06,850 --> 00:30:13,840
and we eventually we get the number of

00:30:09,190 --> 00:30:15,910
lines we processed so the origami

00:30:13,840 --> 00:30:18,990
library and the concept of fold is

00:30:15,910 --> 00:30:21,940
actually super nice because so it's very

00:30:18,990 --> 00:30:23,740
friendly to streaming library obviously

00:30:21,940 --> 00:30:27,370
you can plug this onto a streaming

00:30:23,740 --> 00:30:28,930
library it's one way to ensure this idea

00:30:27,370 --> 00:30:30,640
of sending different computations to

00:30:28,930 --> 00:30:33,790
different places and it's very

00:30:30,640 --> 00:30:36,640
compositional so it's regret honestly I

00:30:33,790 --> 00:30:39,930
love false it's you should you should

00:30:36,640 --> 00:30:39,930
have a look at that it is very beautiful

00:30:40,380 --> 00:30:45,040
we are still left with lots lots of

00:30:43,060 --> 00:30:46,720
problems I mean lots of issues are still

00:30:45,040 --> 00:30:49,120
not solved right we know how to produce

00:30:46,720 --> 00:30:52,840
elements we know how to transform them

00:30:49,120 --> 00:30:55,390
we know how to get a final value out of

00:30:52,840 --> 00:30:58,090
all our processing we still haven't

00:30:55,390 --> 00:31:00,970
dealt at all with concurrency with

00:30:58,090 --> 00:31:01,480
safety and resources and actually back

00:31:00,970 --> 00:31:04,000
pressure

00:31:01,480 --> 00:31:08,350
still naturally handled right and we are

00:31:04,000 --> 00:31:10,389
going to see more about that so now we

00:31:08,350 --> 00:31:12,010
are going to use another library to try

00:31:10,389 --> 00:31:15,880
to handle those concerns and this one is

00:31:12,010 --> 00:31:18,460
called s so actually it would take me a

00:31:15,880 --> 00:31:22,779
full other presentation to talk properly

00:31:18,460 --> 00:31:25,480
about F so f is a moon ad that kind of

00:31:22,779 --> 00:31:28,299
encodes all sorts of other monads into

00:31:25,480 --> 00:31:31,210
one data structure I just want to give

00:31:28,299 --> 00:31:33,700
you some kind of idea today of what it

00:31:31,210 --> 00:31:35,500
is doing and how it's doing it so if you

00:31:33,700 --> 00:31:38,049
are trying to compute with the either

00:31:35,500 --> 00:31:39,220
data type where which is basically

00:31:38,049 --> 00:31:41,139
representing the fact that some

00:31:39,220 --> 00:31:42,850
computation can fail and if a

00:31:41,139 --> 00:31:44,830
computation fails you want to have an

00:31:42,850 --> 00:31:47,320
error message that's the easier data

00:31:44,830 --> 00:31:49,840
type so you can use the file compression

00:31:47,320 --> 00:31:53,590
and have in a flat map all those

00:31:49,840 --> 00:31:55,899
computations if you took the the f hat

00:31:53,590 --> 00:31:57,070
you are you're going to see this a bit

00:31:55,899 --> 00:31:59,049
differently you are going to say oh my

00:31:57,070 --> 00:32:02,889
data type actually represents some

00:31:59,049 --> 00:32:05,320
requests I have some requests so a left

00:32:02,889 --> 00:32:07,720
request is a request where I'm saying o

00:32:05,320 --> 00:32:09,639
has no value sorry I just have an error

00:32:07,720 --> 00:32:11,620
message and then I have a write request

00:32:09,639 --> 00:32:14,260
where I think I'm saying oh I have a

00:32:11,620 --> 00:32:16,360
value of that a and I'm sending this

00:32:14,260 --> 00:32:17,679
request to an interpreter that's

00:32:16,360 --> 00:32:19,840
supposed to know what to do with them

00:32:17,679 --> 00:32:22,720
and generally the interpreter will say

00:32:19,840 --> 00:32:24,399
oh you have a left value oh I can do

00:32:22,720 --> 00:32:26,080
anything either so I'm just rubbing

00:32:24,399 --> 00:32:28,750
their message that's what I'm returning

00:32:26,080 --> 00:32:31,269
oh you have a right value now I know how

00:32:28,750 --> 00:32:33,309
to extract it from the writes and now I

00:32:31,269 --> 00:32:36,340
know I can trigger a continuation for

00:32:33,309 --> 00:32:38,590
this to do other computations and with F

00:32:36,340 --> 00:32:41,639
not only the other computations will be

00:32:38,590 --> 00:32:45,070
some other either requests but it can be

00:32:41,639 --> 00:32:46,419
future computations it can be optional

00:32:45,070 --> 00:32:49,960
computations all sorts of other

00:32:46,419 --> 00:32:51,940
computations so this is the same code

00:32:49,960 --> 00:32:54,220
almost written slightly differently and

00:32:51,940 --> 00:32:57,279
the run either thing that you see is

00:32:54,220 --> 00:33:01,059
actually calling the interpreter to to

00:32:57,279 --> 00:33:02,500
to interpret those requests and if you

00:33:01,059 --> 00:33:05,440
look at the library you have lots of

00:33:02,500 --> 00:33:07,059
those effects that you can mix in the

00:33:05,440 --> 00:33:09,429
same computation and the type system

00:33:07,059 --> 00:33:11,019
will ensure that you interpret all of

00:33:09,429 --> 00:33:13,450
them at the right time at the right

00:33:11,019 --> 00:33:14,110
place and so on and in particular in F

00:33:13,450 --> 00:33:16,260
you

00:33:14,110 --> 00:33:18,309
all sorts of effects for supporting

00:33:16,260 --> 00:33:20,980
concurrency and asynchronous programming

00:33:18,309 --> 00:33:23,980
so it has support for scallop futures

00:33:20,980 --> 00:33:26,380
Twitter futures and all the zoo of tasks

00:33:23,980 --> 00:33:29,160
that we have like a scholarship task

00:33:26,380 --> 00:33:31,480
monix task and the task from access to

00:33:29,160 --> 00:33:35,370
they are all slightly different so they

00:33:31,480 --> 00:33:38,049
all deserve their own their own effect

00:33:35,370 --> 00:33:40,510
so I cannot spend too much time on that

00:33:38,049 --> 00:33:44,670
but what that means is that if you use f

00:33:40,510 --> 00:33:47,919
as a monad with your producer and if you

00:33:44,670 --> 00:33:49,510
use f as a monad for your folds that

00:33:47,919 --> 00:33:52,150
means that you can run a sequence

00:33:49,510 --> 00:33:54,040
computation so you've extracted the

00:33:52,150 --> 00:33:56,710
concern of doing concurrent concurrent

00:33:54,040 --> 00:33:59,080
programming into another library but you

00:33:56,710 --> 00:34:01,600
can add more concern and this one I want

00:33:59,080 --> 00:34:04,240
to talk about today because I think it

00:34:01,600 --> 00:34:05,860
could be one way to see backpressure but

00:34:04,240 --> 00:34:07,840
and also i want to talk about it because

00:34:05,860 --> 00:34:09,639
i think it's an interesting problem so

00:34:07,840 --> 00:34:12,159
let's say you have some streaming data

00:34:09,639 --> 00:34:13,960
you have a list of billions and you want

00:34:12,159 --> 00:34:17,649
to implement the all operation saying

00:34:13,960 --> 00:34:19,450
are they all true or not and it's not

00:34:17,649 --> 00:34:21,639
too hard to implement because you say

00:34:19,450 --> 00:34:23,169
you use a for left and you say initial

00:34:21,639 --> 00:34:25,899
value is true and then you try to end

00:34:23,169 --> 00:34:29,050
all of them and you get the final result

00:34:25,899 --> 00:34:31,510
the trouble is is as soon as you have a

00:34:29,050 --> 00:34:35,619
false value you know that you can stop

00:34:31,510 --> 00:34:37,540
here otherwise you are going to you're

00:34:35,619 --> 00:34:39,369
going to keep the same value for no good

00:34:37,540 --> 00:34:40,720
reason because it's never going to

00:34:39,369 --> 00:34:42,340
change it's going to be always the same

00:34:40,720 --> 00:34:44,679
so you're going to do a lot of

00:34:42,340 --> 00:34:47,679
processing for no good reason you could

00:34:44,679 --> 00:34:50,820
just stop here so what can we do with

00:34:47,679 --> 00:34:50,820
producers and false

00:34:51,119 --> 00:34:55,629
tu-tu-tu-tu-tu-tu change that to make it

00:34:53,169 --> 00:34:57,280
better and if you remember producers

00:34:55,629 --> 00:35:00,220
they are just sending some data to the

00:34:57,280 --> 00:35:01,900
falls and the folds are consuming but

00:35:00,220 --> 00:35:04,450
they cannot really tell to the producer

00:35:01,900 --> 00:35:06,160
a my computation is never going to

00:35:04,450 --> 00:35:08,500
change be careful because now it's

00:35:06,160 --> 00:35:10,960
always going to be the same so how could

00:35:08,500 --> 00:35:12,820
we signal to a producer that the value

00:35:10,960 --> 00:35:15,369
is never going to change

00:35:12,820 --> 00:35:18,520
let's have a look at that so one way to

00:35:15,369 --> 00:35:20,050
do this is to use an effect to say not

00:35:18,520 --> 00:35:22,810
only we are going to compute value

00:35:20,050 --> 00:35:24,820
values and process the current state but

00:35:22,810 --> 00:35:27,790
we are going to add some additional

00:35:24,820 --> 00:35:29,320
value on top of that and it's I don't

00:35:27,790 --> 00:35:31,630
to understand the code here but the idea

00:35:29,320 --> 00:35:34,060
is that when you're doing logging in

00:35:31,630 --> 00:35:35,860
your normal services or whatever program

00:35:34,060 --> 00:35:38,410
you do this you could do some

00:35:35,860 --> 00:35:40,090
computation and you put some warning

00:35:38,410 --> 00:35:41,970
somewhere some additional piece of

00:35:40,090 --> 00:35:44,770
information that you find useful and

00:35:41,970 --> 00:35:46,630
generally you flush that to disk in this

00:35:44,770 --> 00:35:50,380
case we want this information to flow

00:35:46,630 --> 00:35:53,980
back to the producer so you can create a

00:35:50,380 --> 00:35:56,950
fault for all the Bereans that's going

00:35:53,980 --> 00:36:00,310
to use this effects using the esplanade

00:35:56,950 --> 00:36:02,800
which is basically going to say a if now

00:36:00,310 --> 00:36:04,900
I know that this value is the value I

00:36:02,800 --> 00:36:07,480
want to return but I'm kind of

00:36:04,900 --> 00:36:11,320
decorating it by saying this value is

00:36:07,480 --> 00:36:15,010
never going to change and and also now

00:36:11,320 --> 00:36:16,810
my monad is also kind of annotated by

00:36:15,010 --> 00:36:19,240
the fact that I'm using the same effect

00:36:16,810 --> 00:36:20,830
so if I'm using that fault I will have

00:36:19,240 --> 00:36:23,170
to know about the same effect I will

00:36:20,830 --> 00:36:26,320
have to interpret it and based on that

00:36:23,170 --> 00:36:30,370
it will be possible to implement a

00:36:26,320 --> 00:36:32,950
method do doing the folding but knowing

00:36:30,370 --> 00:36:36,130
about short-circuiting so a method that

00:36:32,950 --> 00:36:40,210
for short that knows that maybe the fold

00:36:36,130 --> 00:36:41,890
you're passing is is useless after some

00:36:40,210 --> 00:36:45,820
stage it's not never going to give you

00:36:41,890 --> 00:36:47,800
more information and if we run all that

00:36:45,820 --> 00:36:49,420
code we can see that really what's

00:36:47,800 --> 00:36:52,330
what's happening so if you have a list

00:36:49,420 --> 00:36:54,130
with all true values is going really

00:36:52,330 --> 00:36:56,320
going to go through the end of the list

00:36:54,130 --> 00:36:58,570
and print them out because they will be

00:36:56,320 --> 00:37:00,280
all true but in the second case you have

00:36:58,570 --> 00:37:02,200
one false value in the middle and it's

00:37:00,280 --> 00:37:04,120
really going to stop there because now

00:37:02,200 --> 00:37:04,540
we know that it's always going to be

00:37:04,120 --> 00:37:06,880
false

00:37:04,540 --> 00:37:10,120
so that's quite nice and that means that

00:37:06,880 --> 00:37:11,980
using effects you have a way to push

00:37:10,120 --> 00:37:14,200
information in the other way in the

00:37:11,980 --> 00:37:16,660
other direction so possibly that could

00:37:14,200 --> 00:37:19,030
be a way in the future to use this for

00:37:16,660 --> 00:37:21,240
encoding back pressure where you have

00:37:19,030 --> 00:37:23,410
consumers doing their thing but also

00:37:21,240 --> 00:37:24,810
giving back some information to the

00:37:23,410 --> 00:37:27,610
producer

00:37:24,810 --> 00:37:29,530
okay what about safety resources and how

00:37:27,610 --> 00:37:34,660
do we close files that's super important

00:37:29,530 --> 00:37:36,520
right so in F you also have support for

00:37:34,660 --> 00:37:39,370
safety so there's an effect called the

00:37:36,520 --> 00:37:41,230
safest act where you can take a bunch of

00:37:39,370 --> 00:37:41,710
methods so one of them is opening a

00:37:41,230 --> 00:37:44,140
resource

00:37:41,710 --> 00:37:46,210
the other one is using it and the third

00:37:44,140 --> 00:37:47,770
one is closing it but it turns out that

00:37:46,210 --> 00:37:49,000
the one in the middle using the results

00:37:47,770 --> 00:37:51,190
might fail it might throw an exception

00:37:49,000 --> 00:37:52,780
though that's terrible and you want to

00:37:51,190 --> 00:37:55,600
make sure that the last one closed is

00:37:52,780 --> 00:37:57,790
really going to be cold so with the safe

00:37:55,600 --> 00:37:59,950
effect you can define an operation

00:37:57,790 --> 00:38:02,590
called bracket that takes the first

00:37:59,950 --> 00:38:04,870
operation the second the third and that

00:38:02,590 --> 00:38:07,600
will make sure that whatever happens

00:38:04,870 --> 00:38:10,840
with the second operation the third one

00:38:07,600 --> 00:38:12,670
will always be cold always and this

00:38:10,840 --> 00:38:14,320
behavior again doesn't have to be in the

00:38:12,670 --> 00:38:16,210
producer library doesn't have to be in

00:38:14,320 --> 00:38:19,630
your swimming library it can be it's

00:38:16,210 --> 00:38:22,600
like some kind of ordinal context comes

00:38:19,630 --> 00:38:23,860
concept and in this example what we see

00:38:22,600 --> 00:38:25,930
is that if you run two different

00:38:23,860 --> 00:38:28,830
programs one not throwing an exception

00:38:25,930 --> 00:38:32,110
another one throwing in the first case

00:38:28,830 --> 00:38:33,460
the the file would be closed but also in

00:38:32,110 --> 00:38:36,220
the second case even if you have an

00:38:33,460 --> 00:38:38,650
exception so we can have a special monad

00:38:36,220 --> 00:38:42,190
just for handling resources properly and

00:38:38,650 --> 00:38:46,240
we can even bake this into the producer

00:38:42,190 --> 00:38:48,970
library and reproduce safely something

00:38:46,240 --> 00:38:52,270
that you have enslaved for example so

00:38:48,970 --> 00:38:55,750
this is from this wave tutorial where

00:38:52,270 --> 00:39:01,150
you want to do an md5 computation on the

00:38:55,750 --> 00:39:04,360
file and the trouble is that if it's not

00:39:01,150 --> 00:39:06,430
entirely obvious how if any of this map

00:39:04,360 --> 00:39:07,960
operation is throwing an exception is

00:39:06,430 --> 00:39:12,220
the file going to be closed or not

00:39:07,960 --> 00:39:15,160
eventually right and with this

00:39:12,220 --> 00:39:16,960
combination of producer fold and F we

00:39:15,160 --> 00:39:19,960
can make sure it's going to be to be

00:39:16,960 --> 00:39:22,270
closed so how to do this well we need to

00:39:19,960 --> 00:39:24,910
define a fault for computing the md5 and

00:39:22,270 --> 00:39:27,130
again this is why Falls are super useful

00:39:24,910 --> 00:39:29,530
you don't need to know about the

00:39:27,130 --> 00:39:30,970
streaming library or using you're just

00:39:29,530 --> 00:39:33,730
encapsulating the piece of functionality

00:39:30,970 --> 00:39:37,120
that that is strictly doing that md5

00:39:33,730 --> 00:39:39,670
computation receiving elements taking a

00:39:37,120 --> 00:39:41,980
message digest and outputting the final

00:39:39,670 --> 00:39:43,870
result and in passing you can see that

00:39:41,980 --> 00:39:46,900
it's it's also nice because all the

00:39:43,870 --> 00:39:48,970
state is encapsulated and in this case a

00:39:46,900 --> 00:39:51,760
message digest is a mutable object

00:39:48,970 --> 00:39:54,790
easily so it has to be hidden and it's

00:39:51,760 --> 00:39:55,460
not exposed and you just see the final

00:39:54,790 --> 00:39:59,119
results

00:39:55,460 --> 00:40:00,970
and once you have this you can both read

00:39:59,119 --> 00:40:04,430
the content from your file

00:40:00,970 --> 00:40:06,319
asynchronously you can send it to two

00:40:04,430 --> 00:40:08,750
foals in that case one that's doing the

00:40:06,319 --> 00:40:11,660
md5 computation the other one that's

00:40:08,750 --> 00:40:14,089
printing to the console and when you run

00:40:11,660 --> 00:40:15,589
the size effect it will make sure that

00:40:14,089 --> 00:40:17,480
even if there is an exception in the

00:40:15,589 --> 00:40:21,609
middle everything will be closed

00:40:17,480 --> 00:40:23,900
properly so you have resource safety and

00:40:21,609 --> 00:40:26,030
because this is all asynchronous you

00:40:23,900 --> 00:40:28,280
need to run the future effect that's

00:40:26,030 --> 00:40:33,079
going to give you back a future

00:40:28,280 --> 00:40:36,040
eventually so what we've seen is that

00:40:33,079 --> 00:40:39,290
with the F library we can now deal with

00:40:36,040 --> 00:40:42,710
concurrency we can deal with resource

00:40:39,290 --> 00:40:44,839
safety and we can possibly deal with

00:40:42,710 --> 00:40:46,880
that pressure this idea that even when

00:40:44,839 --> 00:40:49,280
you consume elements you need to send

00:40:46,880 --> 00:40:51,700
back some information to the person

00:40:49,280 --> 00:40:54,500
that's pushing some data to you

00:40:51,700 --> 00:40:57,770
unfortunately this is this is still not

00:40:54,500 --> 00:40:59,420
enough because the real word is a bit

00:40:57,770 --> 00:41:01,910
more complex than this when you have an

00:40:59,420 --> 00:41:06,049
HTTP server somewhere even if you have a

00:41:01,910 --> 00:41:09,650
nice SP library that's really pulling

00:41:06,049 --> 00:41:12,200
data as it improve processing data as it

00:41:09,650 --> 00:41:14,000
comes you have clients pushing that down

00:41:12,200 --> 00:41:16,309
to you as fast as they can they want to

00:41:14,000 --> 00:41:17,990
have things being processed so how did

00:41:16,309 --> 00:41:19,700
you deal with that you really need

00:41:17,990 --> 00:41:22,849
something that does the interface

00:41:19,700 --> 00:41:25,910
between your functional abstraction and

00:41:22,849 --> 00:41:28,339
the real messy world so in that case

00:41:25,910 --> 00:41:30,530
what's really needed is actually a

00:41:28,339 --> 00:41:32,869
fourth library it's just not possible to

00:41:30,530 --> 00:41:35,059
deal with just three because you need to

00:41:32,869 --> 00:41:37,670
have a notion of queue that's going to

00:41:35,059 --> 00:41:40,990
do several things just anchor those

00:41:37,670 --> 00:41:44,329
elements and that's also able to say

00:41:40,990 --> 00:41:46,220
communicate back to the clients a no

00:41:44,329 --> 00:41:50,900
more please and then you can use things

00:41:46,220 --> 00:41:52,460
like TCP as an underlying protocol to to

00:41:50,900 --> 00:41:54,500
push some information back to the client

00:41:52,460 --> 00:41:56,900
to tell them a no more so we did some

00:41:54,500 --> 00:41:59,210
smart queues and some specialized is to

00:41:56,900 --> 00:42:00,920
do this but you have also more

00:41:59,210 --> 00:42:02,900
opportunities if you implement a

00:42:00,920 --> 00:42:04,880
queueing library as a separate again

00:42:02,900 --> 00:42:06,230
separate concept because there are all

00:42:04,880 --> 00:42:09,020
sorts of interesting things you can do

00:42:06,230 --> 00:42:11,300
with queues you can merge skews together

00:42:09,020 --> 00:42:13,130
and you can think about many different

00:42:11,300 --> 00:42:15,340
interesting ways to merge skews together

00:42:13,130 --> 00:42:18,260
where for example if you have some

00:42:15,340 --> 00:42:19,700
Twitter feed and a Facebook feed and you

00:42:18,260 --> 00:42:22,010
want to do some social sentiment

00:42:19,700 --> 00:42:23,780
analysis and you want both of those

00:42:22,010 --> 00:42:25,100
feeds to be merged together maybe they

00:42:23,780 --> 00:42:27,710
have different speeds so you want

00:42:25,100 --> 00:42:29,810
different strategies for merging them so

00:42:27,710 --> 00:42:31,790
I think there's an opportunity to

00:42:29,810 --> 00:42:33,410
complement those three libraries with

00:42:31,790 --> 00:42:35,480
another one that we'll just deal with

00:42:33,410 --> 00:42:38,900
the queueing that would be smart enough

00:42:35,480 --> 00:42:40,820
about that so it's more of a quadrilogy

00:42:38,900 --> 00:42:42,950
that I'm proposing rather than just a

00:42:40,820 --> 00:42:45,320
trilogy but as you can see with the

00:42:42,950 --> 00:42:47,420
trilogy we can already go pretty far in

00:42:45,320 --> 00:42:51,470
trying to reproduce what the streaming

00:42:47,420 --> 00:42:53,420
libraries are doing and I hope I was

00:42:51,470 --> 00:42:55,910
able to convey that they are really

00:42:53,420 --> 00:42:57,980
great they are also very complex because

00:42:55,910 --> 00:43:02,570
they try to do lots of things at the

00:42:57,980 --> 00:43:04,190
same time but it's possibly it may be

00:43:02,570 --> 00:43:06,350
possible to separate all those concerns

00:43:04,190 --> 00:43:08,869
as different things I think it's

00:43:06,350 --> 00:43:11,600
something worth exploring and ultimately

00:43:08,869 --> 00:43:15,770
I think it's also a very good exercise

00:43:11,600 --> 00:43:18,350
in in programming just I would really

00:43:15,770 --> 00:43:20,840
advise anyone coming being new to ASCII

00:43:18,350 --> 00:43:23,000
or even to Scala to try to implement its

00:43:20,840 --> 00:43:24,619
own streaming library by just okay can

00:43:23,000 --> 00:43:27,260
you solve the string problem yes

00:43:24,619 --> 00:43:28,910
implement something and I'll add more

00:43:27,260 --> 00:43:31,340
concerns on top on that can you do

00:43:28,910 --> 00:43:32,840
concurrency can you do cueing can you

00:43:31,340 --> 00:43:37,130
solve the back pressure problem can you

00:43:32,840 --> 00:43:40,430
do it composable and so on and so forth

00:43:37,130 --> 00:43:42,859
and as you will do this you will first

00:43:40,430 --> 00:43:44,119
learn lots of great techniques because

00:43:42,859 --> 00:43:47,090
you need to know about all of those

00:43:44,119 --> 00:43:48,950
techniques and you will probably end up

00:43:47,090 --> 00:43:50,960
in a different space that just create

00:43:48,950 --> 00:43:52,700
your own a very original streaming

00:43:50,960 --> 00:43:56,060
library so I think it's great to be

00:43:52,700 --> 00:43:59,950
sized and that's basically it for me and

00:43:56,060 --> 00:43:59,950
today any questions

00:44:03,600 --> 00:44:08,940
so we saw that we were creating

00:44:06,840 --> 00:44:12,120
producers and all the streams were

00:44:08,940 --> 00:44:14,100
evaluated using folds the folds

00:44:12,120 --> 00:44:17,610
inherently have a sense of state and

00:44:14,100 --> 00:44:19,470
where I lost you was how do these things

00:44:17,610 --> 00:44:21,180
work concurrently because the state

00:44:19,470 --> 00:44:23,760
might be different in different threads

00:44:21,180 --> 00:44:26,730
that are running at the same time so how

00:44:23,760 --> 00:44:29,940
do streams and folds work together in a

00:44:26,730 --> 00:44:32,160
concurrent environment so so you can

00:44:29,940 --> 00:44:34,650
have different things being concurrent

00:44:32,160 --> 00:44:36,330
so the you can have some threads doing

00:44:34,650 --> 00:44:39,060
the evaluation of the producer like

00:44:36,330 --> 00:44:41,760
reading from file using some threads you

00:44:39,060 --> 00:44:44,850
can have some threads doing the the

00:44:41,760 --> 00:44:47,070
folding separately and the state is

00:44:44,850 --> 00:44:50,010
encapsulated I mean each fault has its

00:44:47,070 --> 00:44:51,810
own state for its own purpose its own

00:44:50,010 --> 00:44:55,410
computation doesn't share of state with

00:44:51,810 --> 00:45:01,170
other falls down all isolated but

00:44:55,410 --> 00:45:02,790
eventually I mean if you the fourth need

00:45:01,170 --> 00:45:04,500
needs to terminate before you can

00:45:02,790 --> 00:45:07,800
evaluate the next part in processor

00:45:04,500 --> 00:45:09,840
anyway so it's not you know in that

00:45:07,800 --> 00:45:12,180
sense and let the for returns unit and

00:45:09,840 --> 00:45:16,500
you don't prepare about the results it's

00:45:12,180 --> 00:45:18,900
not super concurrent so maybe I that for

00:45:16,500 --> 00:45:22,050
this reason it will not be as efficient

00:45:18,900 --> 00:45:24,840
as other libraries that are more more

00:45:22,050 --> 00:45:26,840
push oriented libraries and if I

00:45:24,840 --> 00:45:33,140
remember some benchmarks that's the case

00:45:26,840 --> 00:45:39,679
yeah okay thank you

00:45:33,140 --> 00:45:39,679

YouTube URL: https://www.youtube.com/watch?v=wFpUG2jGxVg


