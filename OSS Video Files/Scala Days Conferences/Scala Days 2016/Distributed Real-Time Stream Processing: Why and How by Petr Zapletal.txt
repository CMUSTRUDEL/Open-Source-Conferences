Title: Distributed Real-Time Stream Processing: Why and How by Petr Zapletal
Publication date: 2017-01-19
Playlist: Scala Days 2016
Description: 
	This video was recorded at Scala Days Berlin 2016
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Anstract:
In this talk we are going to discuss various state of the art open-source distributed streaming frameworks, their similarities and differences, implementation trade-offs, their intended use-cases and how to choose between them. I’m going to focus on the popular frameworks including Spark Streaming, Storm, Samza and Flink. In addition, I’m going to cover theoretical introduction, common pitfalls, popular architectures and many more. 

The demand for stream processing is increasing. Immense amounts of data has to be processed fast from a rapidly growing set of disparate data sources. This pushes the limits of traditional data processing infrastructures. These stream-based applications include trading, social networks, Internet of things or system monitoring, are becoming more and more important. A number of powerful, easy-to-use open source platforms have emerged to address this. 

My goal is to provide comprehensive overview about modern streaming solutions and to help fellow developers with picking the best possible decision for their particular use-case. This talk should be interesting for anyone who is thinking about, implementing or have already deployed streaming solution.
Captions: 
	00:00:00,000 --> 00:00:05,100
my name is Peter and I work for cake

00:00:02,340 --> 00:00:08,280
solutions we are a constituency company

00:00:05,100 --> 00:00:10,559
focusing on building reactive and data

00:00:08,280 --> 00:00:13,110
processing applications using

00:00:10,559 --> 00:00:17,310
technologies such as color like a spark

00:00:13,110 --> 00:00:20,580
and many others in this presentation I'm

00:00:17,310 --> 00:00:23,340
going to talk about distributed stream

00:00:20,580 --> 00:00:26,070
processing this area at Chuck squad

00:00:23,340 --> 00:00:29,400
attention these days and I firmly

00:00:26,070 --> 00:00:34,710
believe you will find next 45 minutes

00:00:29,400 --> 00:00:37,920
interesting so what am I going to talk

00:00:34,710 --> 00:00:40,500
about I will start with short

00:00:37,920 --> 00:00:43,710
introduction or our reasons behind these

00:00:40,500 --> 00:00:47,910
increasing demand for data processing

00:00:43,710 --> 00:00:50,180
and how to address it then I'm going to

00:00:47,910 --> 00:00:53,550
talk about stream processing in general

00:00:50,180 --> 00:00:57,030
I also about the challenges we have to

00:00:53,550 --> 00:00:59,430
expect after that I like to talk about

00:00:57,030 --> 00:01:01,980
available frameworks what are

00:00:59,430 --> 00:01:05,580
similarities and differences and also

00:01:01,980 --> 00:01:07,890
there are typically use cases finally we

00:01:05,580 --> 00:01:11,340
will conclude with general guidelines

00:01:07,890 --> 00:01:13,979
and recommendations I like to say this

00:01:11,340 --> 00:01:16,500
talk is based on my personal opinions

00:01:13,979 --> 00:01:21,330
and I'm definitely biased and in some

00:01:16,500 --> 00:01:23,580
way huge amounts of data has to be

00:01:21,330 --> 00:01:27,140
processed fast from a rapidly growing

00:01:23,580 --> 00:01:30,360
set of dissipate data sources like

00:01:27,140 --> 00:01:32,850
trading social networks I with the

00:01:30,360 --> 00:01:35,400
system monitoring and so on and this

00:01:32,850 --> 00:01:37,439
pushes limits of the traditional batch

00:01:35,400 --> 00:01:40,820
processing structures because they are

00:01:37,439 --> 00:01:43,520
often simply not good a half and three

00:01:40,820 --> 00:01:46,590
processing might be a good ready to go

00:01:43,520 --> 00:01:49,290
we want to process incoming data on the

00:01:46,590 --> 00:01:52,380
fly I do we want to be able to react to

00:01:49,290 --> 00:01:58,729
events as they occur as a latency really

00:01:52,380 --> 00:02:01,049
matters here and as you suspect

00:01:58,729 --> 00:02:03,799
distributed stream processing is

00:02:01,049 --> 00:02:07,170
continuous processing aggregations and

00:02:03,799 --> 00:02:09,330
analyzes of unbolted data it is a

00:02:07,170 --> 00:02:12,900
general computational model as MapReduce

00:02:09,330 --> 00:02:16,079
but we expect our latencies and mail

00:02:12,900 --> 00:02:19,799
or in seconds systems are usually

00:02:16,079 --> 00:02:23,879
modeled as directed acyclic graphs da

00:02:19,799 --> 00:02:27,110
G's or ducks duck is a graphic

00:02:23,879 --> 00:02:29,519
representation of chain of task and

00:02:27,110 --> 00:02:32,900
reuse it for a description of the

00:02:29,519 --> 00:02:35,430
topology I will help myself with

00:02:32,900 --> 00:02:37,079
terminology from acha streams a little

00:02:35,430 --> 00:02:39,620
bit but I'm sure it would be clear

00:02:37,079 --> 00:02:42,569
anyway so as you can see the picture

00:02:39,620 --> 00:02:45,629
data flows through China processors from

00:02:42,569 --> 00:02:48,690
sources two sinks and which represents

00:02:45,629 --> 00:02:50,790
the streaming task and speaking about

00:02:48,690 --> 00:02:52,620
acha streams I think it's very important

00:02:50,790 --> 00:02:55,230
to emphasize the word distributed

00:02:52,620 --> 00:02:57,750
because even local solutions can create

00:02:55,230 --> 00:02:59,730
an exact but we are going to focus only

00:02:57,750 --> 00:03:07,590
on solutions running on multiple

00:02:59,730 --> 00:03:09,959
machines when choosing between different

00:03:07,590 --> 00:03:11,760
systems there is a couple of points we

00:03:09,959 --> 00:03:14,280
should take care of so let's start with

00:03:11,760 --> 00:03:16,590
the runtime and programming model the

00:03:14,280 --> 00:03:18,389
programming model provided by platforms

00:03:16,590 --> 00:03:20,849
determines all of its features and

00:03:18,389 --> 00:03:23,459
should be sufficient to handle all

00:03:20,849 --> 00:03:25,349
possible cases for an application this

00:03:23,459 --> 00:03:29,459
is a really crucial topic and I will

00:03:25,349 --> 00:03:31,530
come back to it very soon the functional

00:03:29,459 --> 00:03:34,530
primitives exposed by a framework should

00:03:31,530 --> 00:03:37,019
be able to provide rich functionalities

00:03:34,530 --> 00:03:39,419
at individual message levels like map or

00:03:37,019 --> 00:03:41,099
filter which are pretty easy to

00:03:39,419 --> 00:03:43,949
implement even if you want to scare a

00:03:41,099 --> 00:03:45,470
lot but it should also provides across

00:03:43,949 --> 00:03:47,489
message functionalities like

00:03:45,470 --> 00:03:51,209
aggregations and across streams

00:03:47,489 --> 00:03:54,629
operations like joint for example which

00:03:51,209 --> 00:03:57,449
are much harder to scale and state

00:03:54,629 --> 00:03:58,949
management most of applications have

00:03:57,449 --> 00:04:01,319
some kind of Stateville processing logic

00:03:58,949 --> 00:04:04,229
with that recreates maintaining a state

00:04:01,319 --> 00:04:06,900
and a platform should allows us to

00:04:04,229 --> 00:04:10,829
maintain access and update the state

00:04:06,900 --> 00:04:13,590
information for message our grantees we

00:04:10,829 --> 00:04:15,590
have a couple classes like animals ones

00:04:13,590 --> 00:04:19,620
at least once at exactly once an

00:04:15,590 --> 00:04:22,049
important thing to consider fellers can

00:04:19,620 --> 00:04:24,670
and will happen at various levels like

00:04:22,049 --> 00:04:27,670
network partitions disk failure

00:04:24,670 --> 00:04:29,410
or nodes going down and so on and we

00:04:27,670 --> 00:04:31,990
expect our platform should be able to

00:04:29,410 --> 00:04:33,610
recover from all such failures from

00:04:31,990 --> 00:04:37,630
their last social success with state

00:04:33,610 --> 00:04:39,220
before harming its result and then we

00:04:37,630 --> 00:04:42,070
have more performance related

00:04:39,220 --> 00:04:43,630
requirements like latency throughput and

00:04:42,070 --> 00:04:45,970
scalability which are obviously

00:04:43,630 --> 00:04:49,360
extremely important and streaming

00:04:45,970 --> 00:04:52,270
applications we should also take care of

00:04:49,360 --> 00:04:54,190
maturity at adoption level this

00:04:52,270 --> 00:04:57,220
information could give us a clue about

00:04:54,190 --> 00:05:00,240
potential support available libraries or

00:04:57,220 --> 00:05:03,850
even stack over for answers and so on

00:05:00,240 --> 00:05:05,740
and also last but not least the ease of

00:05:03,850 --> 00:05:08,230
development and the ease of operability

00:05:05,740 --> 00:05:10,450
you know it's great when we have like a

00:05:08,230 --> 00:05:12,820
super fancy system which covers all

00:05:10,450 --> 00:05:15,100
rights cases but we cannot write a

00:05:12,820 --> 00:05:20,290
program for it or if it cannot deploy it

00:05:15,100 --> 00:05:22,510
we had done anyway so let's talk about

00:05:20,290 --> 00:05:24,430
runtime and programming model which is

00:05:22,510 --> 00:05:26,860
probably the most important tradable

00:05:24,430 --> 00:05:29,350
system because it defines expressiveness

00:05:26,860 --> 00:05:31,720
possible operations and future

00:05:29,350 --> 00:05:36,640
limitations therefore it defines them

00:05:31,720 --> 00:05:38,230
capabilities and its use cases there are

00:05:36,640 --> 00:05:41,170
two distinctive approaches how to

00:05:38,230 --> 00:05:43,090
implement streaming system first one do

00:05:41,170 --> 00:05:45,310
negative streaming it means all incoming

00:05:43,090 --> 00:05:50,380
records or events if you will our

00:05:45,310 --> 00:05:52,900
process as they arrive one by one second

00:05:50,380 --> 00:05:54,730
approach is called micro batching short

00:05:52,900 --> 00:05:57,640
batches are created from incoming

00:05:54,730 --> 00:05:59,410
records and go through the system these

00:05:57,640 --> 00:06:01,630
batches are created according to

00:05:59,410 --> 00:06:07,210
prettify time constant typically every

00:06:01,630 --> 00:06:10,540
couple of seconds both approaches have

00:06:07,210 --> 00:06:12,820
inherent advantages and disadvantages so

00:06:10,540 --> 00:06:14,800
let's start with native streaming to

00:06:12,820 --> 00:06:17,470
great advantage of native streaming is

00:06:14,800 --> 00:06:20,380
its expressiveness because it takes a

00:06:17,470 --> 00:06:24,250
stream as it is it's not limited by any

00:06:20,380 --> 00:06:26,620
initial abstraction over it also also

00:06:24,250 --> 00:06:28,780
records are processed immediately upon

00:06:26,620 --> 00:06:31,300
arrival achievable agencies of these

00:06:28,780 --> 00:06:34,560
systems are always better than is micro

00:06:31,300 --> 00:06:36,910
batching companions apart from that

00:06:34,560 --> 00:06:38,060
state flow operations are much easier to

00:06:36,910 --> 00:06:39,590
implement as

00:06:38,060 --> 00:06:42,380
we'll see in the next couple of minutes

00:06:39,590 --> 00:06:44,900
a native steering system have usually

00:06:42,380 --> 00:06:46,790
local throughput and fault tolerance is

00:06:44,900 --> 00:06:50,750
much more expensive assistant has to

00:06:46,790 --> 00:06:52,490
take care of every single record also

00:06:50,750 --> 00:06:54,889
room balancing is kind of issue let's

00:06:52,490 --> 00:06:57,139
say we have a data partition right key

00:06:54,889 --> 00:06:59,389
and we want to process it if you're

00:06:57,139 --> 00:07:01,970
processing or from some key or the

00:06:59,389 --> 00:07:04,430
partition it's more resource intensive

00:07:01,970 --> 00:07:09,410
for any reason this partition quickly

00:07:04,430 --> 00:07:12,050
becomes jobs bottleneck splitting stream

00:07:09,410 --> 00:07:15,710
into micro batches inevitably reduces

00:07:12,050 --> 00:07:18,110
6-10 expressiveness some operations

00:07:15,710 --> 00:07:20,360
especially state management or or joint

00:07:18,110 --> 00:07:22,460
and split are much harder to implement a

00:07:20,360 --> 00:07:25,669
system has to manipulate with whole

00:07:22,460 --> 00:07:27,110
batch we're over the batch entire

00:07:25,669 --> 00:07:29,570
connects two things which should never

00:07:27,110 --> 00:07:33,979
be connected and infrastructure property

00:07:29,570 --> 00:07:36,410
and a business logic on the contrary for

00:07:33,979 --> 00:07:38,180
torrents is my simple system just sends

00:07:36,410 --> 00:07:39,919
every batch to work note and if

00:07:38,180 --> 00:07:43,400
something goes wrong it can just use it

00:07:39,919 --> 00:07:45,710
a friend asta it's good to remark we can

00:07:43,400 --> 00:07:50,180
build microbe etching system atop native

00:07:45,710 --> 00:07:51,500
streaming quite easily programming

00:07:50,180 --> 00:07:53,560
models can be classified as

00:07:51,500 --> 00:07:55,610
compositional and declarative

00:07:53,560 --> 00:07:57,800
compositional a pro to provide basic

00:07:55,610 --> 00:08:00,039
building blocks like sources or

00:07:57,800 --> 00:08:04,220
operators and they must be tied together

00:08:00,039 --> 00:08:05,750
in order to create expected to poggi you

00:08:04,220 --> 00:08:08,810
components can be usually defined by

00:08:05,750 --> 00:08:11,450
implementing some kind of interfaces on

00:08:08,810 --> 00:08:14,810
the contrary operators in aquatic api's

00:08:11,450 --> 00:08:16,850
are defined as higher-order functions it

00:08:14,810 --> 00:08:20,030
also stew write function functional code

00:08:16,850 --> 00:08:22,850
with abstract types I'll all expensive

00:08:20,030 --> 00:08:26,090
stuff we love and system creates and

00:08:22,850 --> 00:08:28,639
optimize this topology itself also the

00:08:26,090 --> 00:08:31,160
crowd kpi's usually provide more

00:08:28,639 --> 00:08:33,530
advanced operations like been doing or

00:08:31,160 --> 00:08:35,659
state management out of the box I'm

00:08:33,530 --> 00:08:40,760
going to show you some concept was very

00:08:35,659 --> 00:08:43,219
soon there is number of diverse imag

00:08:40,760 --> 00:08:46,100
available and is that are impossible to

00:08:43,219 --> 00:08:47,870
cover all of them in just one session so

00:08:46,100 --> 00:08:49,850
I have been forced to limit it somehow

00:08:47,870 --> 00:08:50,970
and I decided to go for a popular

00:08:49,850 --> 00:08:53,850
systemic solution from

00:08:50,970 --> 00:08:57,629
Apache landscape therefore we are going

00:08:53,850 --> 00:08:59,610
to focus on apache storm and it's been

00:08:57,629 --> 00:09:03,149
tried out and on streaming module or

00:08:59,610 --> 00:09:05,879
very popular spark we are also going to

00:09:03,149 --> 00:09:10,410
talk about streaming system behind

00:09:05,879 --> 00:09:12,089
Lincoln named Samsa and finally we are

00:09:10,410 --> 00:09:16,470
going to discuss to promise the Apache

00:09:12,089 --> 00:09:18,660
project I packs and flank I believe this

00:09:16,470 --> 00:09:20,730
is a great traction because even if all

00:09:18,660 --> 00:09:22,350
of them are streaming systems they do

00:09:20,730 --> 00:09:25,829
approach valley with challenges very

00:09:22,350 --> 00:09:28,439
differently unfortunately I won't talk

00:09:25,829 --> 00:09:32,009
about proprietary streaming system like

00:09:28,439 --> 00:09:33,779
Google Mughal or amazon kinesis and also

00:09:32,009 --> 00:09:36,689
we are going to miss interesting but

00:09:33,779 --> 00:09:39,990
still limited adopted systems like my

00:09:36,689 --> 00:09:45,060
beloved Intel gear pump so that maybe

00:09:39,990 --> 00:09:47,550
for next time Apache storm was

00:09:45,060 --> 00:09:51,389
originally created by native marks and

00:09:47,550 --> 00:09:53,279
his team at back type in 2010 let three

00:09:51,389 --> 00:09:57,199
was acquired open source by Twitter and

00:09:53,279 --> 00:10:01,079
it became Apache total project in 2014

00:09:57,199 --> 00:10:03,540
if of any gaps stone was pioneered in

00:10:01,079 --> 00:10:06,800
rats large-scale symbols of sync and

00:10:03,540 --> 00:10:09,480
became de facto industrial standard

00:10:06,800 --> 00:10:12,480
stone is the native streaming system and

00:10:09,480 --> 00:10:15,300
provides local IP I also strongly

00:10:12,480 --> 00:10:17,490
suspect for topology definition and it

00:10:15,300 --> 00:10:20,370
also implement store multi-language

00:10:17,490 --> 00:10:22,800
protocol this basically allows us to

00:10:20,370 --> 00:10:25,649
implement our solutions and large number

00:10:22,800 --> 00:10:30,959
of languages and of course car is one of

00:10:25,649 --> 00:10:32,870
them tried n is high-level microbe

00:10:30,959 --> 00:10:35,250
etching system the top storm it

00:10:32,870 --> 00:10:38,160
simplifies to boji building process and

00:10:35,250 --> 00:10:40,379
also as high level operations like

00:10:38,160 --> 00:10:42,149
windowing aggregations or state

00:10:40,379 --> 00:10:45,540
management which are not need to be

00:10:42,149 --> 00:10:48,110
supported and storm in addition storm

00:10:45,540 --> 00:10:52,490
try to provide exactly once delivery

00:10:48,110 --> 00:10:55,949
titan have java closure and scott api's

00:10:52,490 --> 00:10:58,259
as we all know spark is very popular

00:10:55,949 --> 00:11:00,420
batch processing forever these days the

00:10:58,259 --> 00:11:03,689
couple of building libraries like sparks

00:11:00,420 --> 00:11:04,700
equal i'm emily and of course parks

00:11:03,689 --> 00:11:06,680
tuning

00:11:04,700 --> 00:11:08,780
sparse on time is built for batch

00:11:06,680 --> 00:11:11,150
processing and therefore sparks

00:11:08,780 --> 00:11:14,570
streaming as it was added a little bit

00:11:11,150 --> 00:11:16,520
lighter does microbe etching the stream

00:11:14,570 --> 00:11:19,370
of input data is adjusted by the

00:11:16,520 --> 00:11:21,230
receivers which create micro batches and

00:11:19,370 --> 00:11:26,330
these micro batches are processed in a

00:11:21,230 --> 00:11:28,760
similar way as a despotic jobs spark

00:11:26,330 --> 00:11:35,480
steaming provides high level API and

00:11:28,760 --> 00:11:37,280
scala java and biden some was originally

00:11:35,480 --> 00:11:39,950
developed in lincoln as a proprietary

00:11:37,280 --> 00:11:42,050
streaming solution and with cough gouges

00:11:39,950 --> 00:11:45,470
add a great Lincoln's contribution to

00:11:42,050 --> 00:11:48,320
our community it became key part of the

00:11:45,470 --> 00:11:50,480
infrastructure as we are going to see a

00:11:48,320 --> 00:11:53,360
little bit later sums up builds heavily

00:11:50,480 --> 00:11:56,450
on cough castle basis of a I both

00:11:53,360 --> 00:12:01,370
together integrates really well and also

00:11:56,450 --> 00:12:02,840
sums up provides compositional API apex

00:12:01,370 --> 00:12:05,960
is the Hydra focus streaming system

00:12:02,840 --> 00:12:08,630
backed by execu- right now it provides

00:12:05,960 --> 00:12:11,750
compositional API for sky and Java you

00:12:08,630 --> 00:12:13,790
can also use visual tool for assembly

00:12:11,750 --> 00:12:16,610
application which is kind of a nice

00:12:13,790 --> 00:12:20,690
feature also high level API is under

00:12:16,610 --> 00:12:24,080
construction apex also comes with the

00:12:20,690 --> 00:12:25,630
library operators named Mel heart and as

00:12:24,080 --> 00:12:28,070
I'm going to show you a little bit later

00:12:25,630 --> 00:12:32,030
apex implements interesting compromise

00:12:28,070 --> 00:12:36,530
between native streaming and micro

00:12:32,030 --> 00:12:39,230
batching and last but not least link

00:12:36,530 --> 00:12:42,410
blankets pretty old project it has its

00:12:39,230 --> 00:12:44,900
origin in 2008 but right now it's

00:12:42,410 --> 00:12:46,970
getting quite a lot of attention clink

00:12:44,900 --> 00:12:51,140
is is a negative streaming system and

00:12:46,970 --> 00:12:53,450
provides high level API frink also

00:12:51,140 --> 00:12:55,970
provides API for batch processing like

00:12:53,450 --> 00:12:58,640
spark but there is a fundamental

00:12:55,970 --> 00:13:00,470
distinction between these two fling

00:12:58,640 --> 00:13:03,170
handles badge as a special case of

00:13:00,470 --> 00:13:04,850
streaming everything is a stream and it

00:13:03,170 --> 00:13:09,370
is definitely better abstraction because

00:13:04,850 --> 00:13:09,370
this is how the word that looks like

00:13:10,230 --> 00:13:14,420
so there was a quick interaction of the

00:13:12,270 --> 00:13:17,340
systems and as you can see the table

00:13:14,420 --> 00:13:20,610
they do have pretty different rights now

00:13:17,340 --> 00:13:22,530
let's take a look at code samples and of

00:13:20,610 --> 00:13:27,330
course nothing is more important than

00:13:22,530 --> 00:13:30,090
camping words you know what count is

00:13:27,330 --> 00:13:34,350
something like Hello worth of data

00:13:30,090 --> 00:13:38,310
processing so let's start with storm and

00:13:34,350 --> 00:13:42,180
please note the example was simplified

00:13:38,310 --> 00:13:44,700
significantly first let's take a look at

00:13:42,180 --> 00:13:47,700
its topology definition as you can see

00:13:44,700 --> 00:13:50,370
we have to defy the spot or if you want

00:13:47,700 --> 00:13:52,760
a source and there is a boat a

00:13:50,370 --> 00:13:56,730
processing component which splits text

00:13:52,760 --> 00:13:59,060
into the words then I have defined add a

00:13:56,730 --> 00:14:03,510
boat for actual word cloud calculation

00:13:59,060 --> 00:14:07,620
also take a look at the magic numbers 5

00:14:03,510 --> 00:14:09,450
8 and 12 these are the person hints and

00:14:07,620 --> 00:14:12,830
they define how many independent spread

00:14:09,450 --> 00:14:15,990
our custom will be used for execution of

00:14:12,830 --> 00:14:21,260
every single component as you can see

00:14:15,990 --> 00:14:24,090
always very manual and low level and

00:14:21,260 --> 00:14:27,450
let's focus now how is the actual work

00:14:24,090 --> 00:14:29,700
on both implanted as long as storm does

00:14:27,450 --> 00:14:31,980
don't have an build support for managed

00:14:29,700 --> 00:14:34,680
state so i have to find local state

00:14:31,980 --> 00:14:37,290
which is far from big idea but let's say

00:14:34,680 --> 00:14:39,710
it's good as a sample I thought apart

00:14:37,290 --> 00:14:42,480
from that it's not very interesting so

00:14:39,710 --> 00:14:47,490
so let's move on and take a look at

00:14:42,480 --> 00:14:49,920
trident as I mentioned before china is

00:14:47,490 --> 00:14:51,630
storms micro batching extension and try

00:14:49,920 --> 00:14:53,790
then apart from many other goodies

00:14:51,630 --> 00:14:56,970
provide state management which is pretty

00:14:53,790 --> 00:14:59,760
useful and implementing word count as

00:14:56,970 --> 00:15:02,250
you can see I could use help operations

00:14:59,760 --> 00:15:04,920
like each and group by so it is a little

00:15:02,250 --> 00:15:09,470
bit better and also i was able to use

00:15:04,920 --> 00:15:09,470
trial and manage state for storing count

00:15:09,500 --> 00:15:16,350
and now at the time for petty ducati api

00:15:12,930 --> 00:15:18,240
provided by apache spark also keep in

00:15:16,350 --> 00:15:20,580
mind on the contrary to previous

00:15:18,240 --> 00:15:22,800
examples which were really simplified

00:15:20,580 --> 00:15:23,649
this is nearly all code you need to run

00:15:22,800 --> 00:15:28,119
this simple stream

00:15:23,649 --> 00:15:31,269
ink or count every spark steaming job

00:15:28,119 --> 00:15:32,709
requires streaming contacts is basically

00:15:31,269 --> 00:15:35,680
an entry point to the streaming

00:15:32,709 --> 00:15:38,199
functionality swimming contacts pays the

00:15:35,680 --> 00:15:40,540
configuration which is as you can see in

00:15:38,199 --> 00:15:42,429
our case or a limited but more

00:15:40,540 --> 00:15:47,379
importantly it'll find its batch

00:15:42,429 --> 00:15:49,420
interval which is set to one second and

00:15:47,379 --> 00:15:52,860
now you can see whole world come

00:15:49,420 --> 00:15:55,929
computation quite your friends isn't it

00:15:52,860 --> 00:15:58,899
it's the reason why spark is sometimes

00:15:55,929 --> 00:16:00,730
called distribute its color as you can

00:15:58,899 --> 00:16:03,610
see it's quite standard functional court

00:16:00,730 --> 00:16:05,619
and spark takes care of the topology

00:16:03,610 --> 00:16:11,139
definition and it's distributed

00:16:05,619 --> 00:16:13,449
execution and now the last part of every

00:16:11,139 --> 00:16:16,089
spark stealing job starting the

00:16:13,449 --> 00:16:21,399
computation keep in mind one start the

00:16:16,089 --> 00:16:23,769
job cannot be modified now let's take a

00:16:21,399 --> 00:16:27,009
look at apache Sansa and a

00:16:23,769 --> 00:16:28,959
representative of compositional API the

00:16:27,009 --> 00:16:31,720
topology is defined in Santos properties

00:16:28,959 --> 00:16:35,259
file so we will find it here but first

00:16:31,720 --> 00:16:37,230
is important the task has defined its

00:16:35,259 --> 00:16:39,279
input and output channels and

00:16:37,230 --> 00:16:43,509
communication goes through Kafka's

00:16:39,279 --> 00:16:45,519
topics in our case whole topology is

00:16:43,509 --> 00:16:49,059
this work on task we just all the work

00:16:45,519 --> 00:16:52,029
and some that components are defined by

00:16:49,059 --> 00:16:54,429
implementing particular interfaces in

00:16:52,029 --> 00:16:57,220
this case it's a stream task and I have

00:16:54,429 --> 00:17:00,610
just over in the method process its

00:16:57,220 --> 00:17:02,290
parameter list when they always need for

00:17:00,610 --> 00:17:06,579
connecting with the rest of the system

00:17:02,290 --> 00:17:11,649
and the computational itself is just the

00:17:06,579 --> 00:17:14,020
simplest car and now it's time to take a

00:17:11,649 --> 00:17:16,750
look at apex as you can see it's a

00:17:14,020 --> 00:17:20,380
classic computational API and again the

00:17:16,750 --> 00:17:22,959
snip bad was simplified first we have to

00:17:20,380 --> 00:17:25,659
define jobs topology we have to add

00:17:22,959 --> 00:17:29,320
components to duck and connect them wave

00:17:25,659 --> 00:17:31,360
streams and here's the definition of one

00:17:29,320 --> 00:17:34,330
of the operators this one splits in

00:17:31,360 --> 00:17:36,129
current strings the code itself is

00:17:34,330 --> 00:17:39,980
prickly I guess

00:17:36,129 --> 00:17:42,139
now let's take a look at flank as you

00:17:39,980 --> 00:17:44,480
can see ap is pretty similar to spark

00:17:42,139 --> 00:17:49,070
swimming but notice we are not setting

00:17:44,480 --> 00:17:50,960
any budget interval computational itself

00:17:49,070 --> 00:17:53,990
is pretty straightforward there's just a

00:17:50,960 --> 00:18:00,139
couple functional course and fling takes

00:17:53,990 --> 00:18:02,720
care of rest and now it's time to look

00:18:00,139 --> 00:18:05,690
at more interesting problems of steering

00:18:02,720 --> 00:18:07,730
processing startlingly for torrents you

00:18:05,690 --> 00:18:10,700
know photons in streaming systems is

00:18:07,730 --> 00:18:12,289
inherently harder than in batch when

00:18:10,700 --> 00:18:15,019
facing an error in batch processing

00:18:12,289 --> 00:18:18,409
system we can just restart a part of the

00:18:15,019 --> 00:18:20,210
computation and we are good but this is

00:18:18,409 --> 00:18:23,539
much harder in swimming scenarios

00:18:20,210 --> 00:18:27,499
because later are still in coming and a

00:18:23,539 --> 00:18:30,200
lot of jobs can have 24 7 our challenge

00:18:27,499 --> 00:18:32,779
we have to face is static consistency

00:18:30,200 --> 00:18:35,539
because in the end of the day we have to

00:18:32,779 --> 00:18:37,730
start the plague events and of course

00:18:35,539 --> 00:18:41,240
look all state operations are an

00:18:37,730 --> 00:18:44,360
important as you will see photo runs it

00:18:41,240 --> 00:18:50,419
can be pretty hard so let's take a look

00:18:44,360 --> 00:18:53,119
how our systems diller that storm uses a

00:18:50,419 --> 00:18:54,679
mechanism of obscene backup and a core

00:18:53,119 --> 00:18:57,730
acknowledgments to guarantee that

00:18:54,679 --> 00:18:59,570
messages re processed after a failure

00:18:57,730 --> 00:19:01,429
acknowledgement works as follows an

00:18:59,570 --> 00:19:03,590
operator sends back through previous

00:19:01,429 --> 00:19:04,879
operator and acknowledgement for every

00:19:03,590 --> 00:19:08,240
single record this has been processed

00:19:04,879 --> 00:19:11,570
and the source of the topology keeps a

00:19:08,240 --> 00:19:14,210
backup of all records it writes one

00:19:11,570 --> 00:19:16,789
receive acknowledgments from originated

00:19:14,210 --> 00:19:22,429
records add the Lessing's the backup can

00:19:16,789 --> 00:19:24,289
be discarded safely and failure if look

00:19:22,429 --> 00:19:27,129
no or acknowledgments have been received

00:19:24,289 --> 00:19:30,110
the records are applied by the source

00:19:27,129 --> 00:19:32,419
this grant is no later loss but just

00:19:30,110 --> 00:19:34,909
result in duplicate records passing

00:19:32,419 --> 00:19:38,480
through the system it's basically an

00:19:34,909 --> 00:19:41,299
advanced diary for us some implement

00:19:38,480 --> 00:19:44,149
this new color on color mechanism that

00:19:41,299 --> 00:19:45,710
only requires few bites storage per

00:19:44,149 --> 00:19:48,559
soldier court to direct the

00:19:45,710 --> 00:19:49,580
acknowledgments but in general political

00:19:48,559 --> 00:19:51,820
acknowledgment

00:19:49,580 --> 00:19:54,380
veterus regardless of their performance

00:19:51,820 --> 00:19:57,200
failing offering exactly once the

00:19:54,380 --> 00:20:00,790
delivery tues burning application

00:19:57,200 --> 00:20:03,080
developer with your application also

00:20:00,790 --> 00:20:05,810
stores like heisman is low throughput

00:20:03,080 --> 00:20:08,720
and has problems with full control as

00:20:05,810 --> 00:20:13,540
the echo john mechanism often forced the

00:20:08,720 --> 00:20:13,540
classifiers failures under back pressure

00:20:15,910 --> 00:20:22,370
spark streaming and its micro batching

00:20:19,220 --> 00:20:25,670
semantics for a different approach the

00:20:22,370 --> 00:20:27,740
idea is terribly simple spark process is

00:20:25,670 --> 00:20:29,870
micro batch of arrows worker nodes and

00:20:27,740 --> 00:20:33,410
each micro batch may either succeed or

00:20:29,870 --> 00:20:35,390
fail add a failure the micro batch can

00:20:33,410 --> 00:20:39,320
be simply computed as they are all

00:20:35,390 --> 00:20:43,400
persistent and immutable so exactly

00:20:39,320 --> 00:20:45,890
month divert a maid is it some such

00:20:43,400 --> 00:20:48,320
approach is also very different it takes

00:20:45,890 --> 00:20:50,690
an advantage of durable opposite based

00:20:48,320 --> 00:20:53,270
messaging system it's usually cough

00:20:50,690 --> 00:20:56,360
cough course some some widows offsets of

00:20:53,270 --> 00:20:59,420
this task and moves it when message is

00:20:56,360 --> 00:21:01,790
processed offset can beat reported in a

00:20:59,420 --> 00:21:04,490
persistent storage and restored in case

00:21:01,790 --> 00:21:06,440
of failure the problem is valid restores

00:21:04,490 --> 00:21:08,900
offsets from the last checkpoint is

00:21:06,440 --> 00:21:11,120
doesn't know which upcoming messages

00:21:08,900 --> 00:21:15,820
were processed and it might do it twice

00:21:11,120 --> 00:21:18,230
so that at least once delivery for us as

00:21:15,820 --> 00:21:20,420
we know there are two distinct

00:21:18,230 --> 00:21:23,300
approaches how to implement stream

00:21:20,420 --> 00:21:26,000
processing the native streaming and the

00:21:23,300 --> 00:21:28,210
micro batch apex takes a little bit

00:21:26,000 --> 00:21:30,530
different I would say a hybrid approach

00:21:28,210 --> 00:21:33,320
which they called windows stream

00:21:30,530 --> 00:21:35,210
real-time event stream processing so

00:21:33,320 --> 00:21:37,670
what does it mean basically apex

00:21:35,210 --> 00:21:40,940
politically send some kind of markers

00:21:37,670 --> 00:21:44,000
and beacons for a stream and I used to

00:21:40,940 --> 00:21:46,580
track the process events in the in case

00:21:44,000 --> 00:21:48,830
of failure it works quite well it's it's

00:21:46,580 --> 00:21:51,200
efficient there's no artificial I tensei

00:21:48,830 --> 00:21:53,450
but as you may see in a picture your

00:21:51,200 --> 00:21:55,880
application windows must be multiplies

00:21:53,450 --> 00:21:58,720
of the system windows and it might be a

00:21:55,880 --> 00:21:58,720
limiting factor

00:21:59,590 --> 00:22:04,270
Frank approach is based on distributed

00:22:02,110 --> 00:22:06,700
slap shot which keeps the state of

00:22:04,270 --> 00:22:10,419
streaming job and it is kind of similar

00:22:06,700 --> 00:22:13,480
to Apex fringe markers are cool barriers

00:22:10,419 --> 00:22:15,400
and are sent from the stream when Barry

00:22:13,480 --> 00:22:17,230
reaches the operator operator

00:22:15,400 --> 00:22:19,990
checkpoints corresponding part of the

00:22:17,230 --> 00:22:22,659
stream so if you compared to storm and

00:22:19,990 --> 00:22:24,549
it's much more efficient as it doesn't

00:22:22,659 --> 00:22:27,760
have to acknowledge every single record

00:22:24,549 --> 00:22:29,470
but does it in small batches but don't

00:22:27,760 --> 00:22:31,539
confuse the still native streaming

00:22:29,470 --> 00:22:34,690
conceptual it is very different from

00:22:31,539 --> 00:22:37,659
spark and also flings window ink is not

00:22:34,690 --> 00:22:40,360
limited in any way lastly book eight

00:22:37,659 --> 00:22:45,279
bags and fling provides all generally

00:22:40,360 --> 00:22:47,409
grantees most of the non-trivial

00:22:45,279 --> 00:22:49,659
streaming applications have some kind of

00:22:47,409 --> 00:22:51,730
state on the contrary of stealth

00:22:49,659 --> 00:22:54,640
operation when we have just an input

00:22:51,730 --> 00:22:57,370
then processing and output we have an

00:22:54,640 --> 00:22:59,470
input and state then we do processing

00:22:57,370 --> 00:23:02,860
and we have an output with modified

00:22:59,470 --> 00:23:04,809
snake we have to manage our state passes

00:23:02,860 --> 00:23:08,500
it any case of failure we expect our

00:23:04,809 --> 00:23:10,330
state to be recreated the location of

00:23:08,500 --> 00:23:12,610
the state might be problem it's a bit as

00:23:10,330 --> 00:23:15,070
we don't we do not have always exactly

00:23:12,610 --> 00:23:18,190
once guarantee so some of the records

00:23:15,070 --> 00:23:22,330
may be replied multiple times and this

00:23:18,190 --> 00:23:24,010
is not what we want usually as we know

00:23:22,330 --> 00:23:26,380
stone provides at least one survey

00:23:24,010 --> 00:23:28,679
grantees so how can we achieve exactly

00:23:26,380 --> 00:23:30,760
one semantics provided by trial and

00:23:28,679 --> 00:23:33,730
conceptually it is quite simple you just

00:23:30,760 --> 00:23:35,529
start committing all records and but

00:23:33,730 --> 00:23:37,690
obviously it is not very efficient so

00:23:35,529 --> 00:23:39,960
you start doing in small batches then do

00:23:37,690 --> 00:23:42,100
some optimizations and here we are

00:23:39,960 --> 00:23:43,659
chatham provides a cup of litigating

00:23:42,100 --> 00:23:47,470
these components for storing states

00:23:43,659 --> 00:23:49,270
which can be accessed by streams it's

00:23:47,470 --> 00:23:53,289
not very convenient but it's definitely

00:23:49,270 --> 00:23:56,260
usable when thinking about state

00:23:53,289 --> 00:23:58,870
operations in super saying we usually

00:23:56,260 --> 00:24:00,490
have along an operator with a state and

00:23:58,870 --> 00:24:02,919
a stream of Records passing through it

00:24:00,490 --> 00:24:04,600
and as we know sparks Dimmick is micro

00:24:02,919 --> 00:24:07,630
batching systems and therefore is

00:24:04,600 --> 00:24:10,270
implemented differently basically spark

00:24:07,630 --> 00:24:12,820
streaming manages state as another

00:24:10,270 --> 00:24:13,870
microbe extreme so during processing of

00:24:12,820 --> 00:24:15,820
each micro batch

00:24:13,870 --> 00:24:18,070
sparks takes and current state and a

00:24:15,820 --> 00:24:20,860
function representing the operation and

00:24:18,070 --> 00:24:25,660
result is a process micro batch and

00:24:20,860 --> 00:24:28,059
updated state sense of solutions for

00:24:25,660 --> 00:24:31,480
everything is just pushing out to Kafka

00:24:28,059 --> 00:24:34,930
and problem solved and it also works in

00:24:31,480 --> 00:24:37,570
a context of state management Samsa has

00:24:34,930 --> 00:24:39,940
to do state for operators so any task

00:24:37,570 --> 00:24:43,270
get hold of state and the state

00:24:39,940 --> 00:24:44,920
changelog is pushed to Kafka if needed

00:24:43,270 --> 00:24:48,340
state can be easily recreated from

00:24:44,920 --> 00:24:50,740
Kafka's topic to make it a little bit

00:24:48,340 --> 00:24:53,800
faster some that allows us to plug in

00:24:50,740 --> 00:24:57,720
giver stores as local storage so it

00:24:53,800 --> 00:24:59,830
doesn't have to go to Kafka all the time

00:24:57,720 --> 00:25:02,820
unfortunately sums up provides at least

00:24:59,830 --> 00:25:06,160
once daily only and it hurts a lot but

00:25:02,820 --> 00:25:10,929
to the implementation of exactly ones

00:25:06,160 --> 00:25:14,620
delivery is planned epic JPEGs maintains

00:25:10,929 --> 00:25:16,840
two types of state firstly apex give us

00:25:14,620 --> 00:25:20,290
a fancy ability to change its topology

00:25:16,840 --> 00:25:22,840
dynamically on runtime so it's racist

00:25:20,290 --> 00:25:26,410
and passes it stack into a persistent

00:25:22,840 --> 00:25:28,929
storage usually HDFS apart from that

00:25:26,410 --> 00:25:31,080
apex provides both stateless and stable

00:25:28,929 --> 00:25:33,340
breathless as you can see in the picture

00:25:31,080 --> 00:25:35,880
apex provides long-running operators

00:25:33,340 --> 00:25:38,140
conceptually very similar to Samsung

00:25:35,880 --> 00:25:43,150
understand this is of course they're

00:25:38,140 --> 00:25:45,309
safe into a parison storage fling

00:25:43,150 --> 00:25:48,070
provides the flu burritos like Samsa

00:25:45,309 --> 00:25:50,950
I'll or apex and working in flame we can

00:25:48,070 --> 00:25:53,590
use two different types of states first

00:25:50,950 --> 00:25:55,750
one is a traditional or or local state

00:25:53,590 --> 00:25:57,970
if you will it is a current state of

00:25:55,750 --> 00:25:59,800
particle operator instance only you know

00:25:57,970 --> 00:26:02,980
these guys do not interact between each

00:25:59,800 --> 00:26:05,290
other apart from that fling provides

00:26:02,980 --> 00:26:08,110
partition it or your key state if you

00:26:05,290 --> 00:26:13,360
will which basically maintains state of

00:26:08,110 --> 00:26:16,179
whole partition so let's take one more

00:26:13,360 --> 00:26:19,900
look how to count words focusing on

00:26:16,179 --> 00:26:21,550
state management so let's start with

00:26:19,900 --> 00:26:24,340
trial and you may have seen a snippet

00:26:21,550 --> 00:26:25,740
already as it is fairly similar as

00:26:24,340 --> 00:26:28,710
before

00:26:25,740 --> 00:26:31,320
we can create stay by calling person

00:26:28,710 --> 00:26:33,480
aggregate important argument is count

00:26:31,320 --> 00:26:36,840
which is a building component for

00:26:33,480 --> 00:26:38,190
storing numbers as I said if you would

00:26:36,840 --> 00:26:42,210
like to process data flow rate you will

00:26:38,190 --> 00:26:44,130
have to create a string quartet sparse

00:26:42,210 --> 00:26:47,640
the Catholic approach is a little bit

00:26:44,130 --> 00:26:50,280
better first we have to create a DD used

00:26:47,640 --> 00:26:52,290
as an initial state then we have to

00:26:50,280 --> 00:26:54,690
define a transition function which takes

00:26:52,290 --> 00:26:56,760
the word it's count and current state

00:26:54,690 --> 00:26:59,100
this function does the computation

00:26:56,760 --> 00:27:02,400
updates the state and returns a new

00:26:59,100 --> 00:27:05,550
result finally we can put all bits

00:27:02,400 --> 00:27:10,559
together and get a stage stream which

00:27:05,550 --> 00:27:13,800
contains are what count so let's take a

00:27:10,559 --> 00:27:16,440
look at Sansa firstly we need to define

00:27:13,800 --> 00:27:19,440
our state it is Katie's key value store

00:27:16,440 --> 00:27:22,980
and we also have to define how it should

00:27:19,440 --> 00:27:26,040
be initialized and then we can use it

00:27:22,980 --> 00:27:29,940
drink computation as you can see it is

00:27:26,040 --> 00:27:33,300
pretty straightforward apex is new path

00:27:29,940 --> 00:27:37,140
looks also similar as before I have just

00:27:33,300 --> 00:27:39,890
added counter a building component for

00:27:37,140 --> 00:27:42,990
counting words receive on its input port

00:27:39,890 --> 00:27:46,110
but I could also add a state to any

00:27:42,990 --> 00:27:49,559
other component if needed simple and

00:27:46,110 --> 00:27:53,610
final let's take a look at blink blink

00:27:49,559 --> 00:27:55,860
provides very nice and neat API we just

00:27:53,610 --> 00:27:58,140
call a function average state which

00:27:55,860 --> 00:28:00,570
takes as an argument function with two

00:27:58,140 --> 00:28:02,970
parameters first one is a word to

00:28:00,570 --> 00:28:06,900
process and second one is a state

00:28:02,970 --> 00:28:12,270
function returns process output add a

00:28:06,900 --> 00:28:15,570
new state I really wanted to shew some

00:28:12,270 --> 00:28:18,540
nice performance comparisons but all or

00:28:15,570 --> 00:28:20,550
not a reasonable comparison is a topic

00:28:18,540 --> 00:28:23,550
probably for all thought maybe more and

00:28:20,550 --> 00:28:25,290
I won't do it here but Allah couple of

00:28:23,550 --> 00:28:27,929
guys built already and I'm happy to

00:28:25,290 --> 00:28:32,460
reference them so for now just just in

00:28:27,929 --> 00:28:34,620
general when we talk about performance

00:28:32,460 --> 00:28:37,220
and stream processing we mostly talk

00:28:34,620 --> 00:28:39,980
about latency and throughput

00:28:37,220 --> 00:28:42,049
it depends on many variables but in

00:28:39,980 --> 00:28:43,940
general and for the simple task we can

00:28:42,049 --> 00:28:46,120
expect hundreds thousands or even

00:28:43,940 --> 00:28:49,900
millions of records being processed

00:28:46,120 --> 00:28:52,669
paranoid per second good thing is that

00:28:49,900 --> 00:28:54,710
these systems have considerable

00:28:52,669 --> 00:28:56,960
horizontal scanning capabilities so we

00:28:54,710 --> 00:29:00,010
can usually edges performance according

00:28:56,960 --> 00:29:02,539
to our needs or according to our budget

00:29:00,010 --> 00:29:06,230
who I don't say in case of micro batch

00:29:02,539 --> 00:29:09,049
we usually thinking in seconds in case

00:29:06,230 --> 00:29:11,270
of native streaming we can expect lower

00:29:09,049 --> 00:29:14,030
handles of malaise for most of the

00:29:11,270 --> 00:29:16,159
systems but tune storm or apex can

00:29:14,030 --> 00:29:21,080
operate in tents or under good

00:29:16,159 --> 00:29:22,970
circumstances even in milliseconds also

00:29:21,080 --> 00:29:25,220
it's important keep in mind the cause of

00:29:22,970 --> 00:29:28,640
delivery guarantees for torrents and

00:29:25,220 --> 00:29:31,039
state management for example turning on

00:29:28,640 --> 00:29:33,289
42 runs may cause do like ten to fifteen

00:29:31,039 --> 00:29:34,970
percent but in case of storm it could be

00:29:33,289 --> 00:29:38,200
like seventy percent of your crew pulled

00:29:34,970 --> 00:29:42,049
so there is no free lunch as always and

00:29:38,200 --> 00:29:44,059
during the talk I have shown you you

00:29:42,049 --> 00:29:46,370
stay bless and step through what can

00:29:44,059 --> 00:29:48,350
exempt us and of course stateless would

00:29:46,370 --> 00:29:50,900
be faster in case you're wondering how

00:29:48,350 --> 00:29:52,370
much so in the context of our chief

00:29:50,900 --> 00:29:54,890
laying dude a friend was like twenty

00:29:52,370 --> 00:29:58,250
five percent but in case of spark it was

00:29:54,890 --> 00:30:00,169
I on fifty percent I'm pretty sure it

00:29:58,250 --> 00:30:01,880
can be tuned but this could gives us an

00:30:00,169 --> 00:30:06,679
idea this is something what we should

00:30:01,880 --> 00:30:09,380
have in mind and speaking about tuning

00:30:06,679 --> 00:30:11,990
Google systems has very rich doing

00:30:09,380 --> 00:30:13,760
options which may lead to significant

00:30:11,990 --> 00:30:17,950
bathroom and gains and you should always

00:30:13,760 --> 00:30:20,690
try and find time to take a look at it

00:30:17,950 --> 00:30:23,510
also it's important to have in mind or

00:30:20,690 --> 00:30:25,640
operations are distributed and sending

00:30:23,510 --> 00:30:28,070
data through network is where it expands

00:30:25,640 --> 00:30:30,679
the preparation so try to take that an

00:30:28,070 --> 00:30:34,000
advantage of data locality I also try to

00:30:30,679 --> 00:30:36,380
tune up your applications realization I

00:30:34,000 --> 00:30:38,299
just love to discuss all the performance

00:30:36,380 --> 00:30:42,850
who by give you basic ideas what to

00:30:38,299 --> 00:30:42,850
expect but we have to move on

00:30:43,510 --> 00:30:47,710
when picking on the framework for

00:30:45,760 --> 00:30:50,110
application you should always consider

00:30:47,710 --> 00:30:55,180
its maturity so let's take a quick look

00:30:50,110 --> 00:30:57,460
how does it look like in our cases storm

00:30:55,180 --> 00:31:00,400
was the first mainstream Stimson system

00:30:57,460 --> 00:31:02,800
is used by many companies for as an

00:31:00,400 --> 00:31:04,540
example we can have Yahoo's but Spotify

00:31:02,800 --> 00:31:08,260
but they're like tens of them in the

00:31:04,540 --> 00:31:10,540
hands of them spark is one of the most

00:31:08,260 --> 00:31:13,480
chaining scare abilities these days and

00:31:10,540 --> 00:31:16,810
one of the engines behinds cars

00:31:13,480 --> 00:31:18,940
popularity sponsor option grows every

00:31:16,810 --> 00:31:22,780
day it's used by companies like Netflix

00:31:18,940 --> 00:31:27,190
Isco datastax IBM tech solutions and so

00:31:22,780 --> 00:31:29,650
on some that is used by Lincoln and also

00:31:27,190 --> 00:31:33,970
by tens of other companies as an example

00:31:29,650 --> 00:31:36,340
we can have netflix or where i'll do

00:31:33,970 --> 00:31:38,140
apex created very recently it has been

00:31:36,340 --> 00:31:40,660
adopted by a cup of corporate clients

00:31:38,140 --> 00:31:43,810
like Gigi paddocks cloud capital one or

00:31:40,660 --> 00:31:47,740
silver spring networks and I'm pretty

00:31:43,810 --> 00:31:50,590
sure we're out all the way Frank is also

00:31:47,740 --> 00:31:52,060
an emerging project but we can see its

00:31:50,590 --> 00:31:54,540
first production deployments and again

00:31:52,060 --> 00:31:57,310
i'm i'm sure more than four very soon

00:31:54,540 --> 00:31:59,590
for example i heard amazon was awaiting

00:31:57,310 --> 00:32:02,460
it i'm also capital one is just saying

00:31:59,590 --> 00:32:02,460
it and so on

00:32:08,540 --> 00:32:14,280
so we have just finished based in

00:32:11,130 --> 00:32:17,040
comparison of choosing systems which to

00:32:14,280 --> 00:32:19,140
be most of my time and we discuss how we

00:32:17,040 --> 00:32:21,150
approach my own challenges which needs

00:32:19,140 --> 00:32:24,420
to be sorted out when implementing

00:32:21,150 --> 00:32:26,940
distributed sympathetic system you may

00:32:24,420 --> 00:32:29,790
take a quick look at a summary of from

00:32:26,940 --> 00:32:32,070
my opinion direct eat right and now the

00:32:29,790 --> 00:32:35,400
time to move on on the last part of his

00:32:32,070 --> 00:32:37,890
talk frame for recommendations I had to

00:32:35,400 --> 00:32:39,930
say this part is the most opinion based

00:32:37,890 --> 00:32:46,350
by far but I was really trying to be

00:32:39,930 --> 00:32:49,140
fair so so let's move on the answer for

00:32:46,350 --> 00:32:52,710
the typical question which one should i

00:32:49,140 --> 00:32:57,480
use or which one is the best as always

00:32:52,710 --> 00:33:00,510
it depends so in general always try to

00:32:57,480 --> 00:33:01,770
evaluate requirements or application

00:33:00,510 --> 00:33:04,110
carefully and be sure you fully

00:33:01,770 --> 00:33:07,980
understand the consequences of choosing

00:33:04,110 --> 00:33:10,200
particular framework also try to fully

00:33:07,980 --> 00:33:13,490
understand its internals as improper use

00:33:10,200 --> 00:33:16,350
may have like disastrous consequences

00:33:13,490 --> 00:33:19,050
for programming model I think most of

00:33:16,350 --> 00:33:20,670
you guys would prefer hile the API and

00:33:19,050 --> 00:33:23,430
it makes sense you know it's more

00:33:20,670 --> 00:33:26,370
elegant more proactive and so on but on

00:33:23,430 --> 00:33:28,350
the other hand hell ap ice might hide a

00:33:26,370 --> 00:33:30,510
little details you will have to

00:33:28,350 --> 00:33:33,530
understand once you're facing an issue

00:33:30,510 --> 00:33:36,720
and I have seen little problems of that

00:33:33,530 --> 00:33:39,240
so i will recommend flowing if you want

00:33:36,720 --> 00:33:40,860
to do like a lot of data science analyze

00:33:39,240 --> 00:33:44,070
this or if you want to apply your Apple

00:33:40,860 --> 00:33:47,820
I think the hell the APR is a great way

00:33:44,070 --> 00:33:50,340
to go if you expect more data intensive

00:33:47,820 --> 00:33:52,800
operations like crunching 3 by 2 blocks

00:33:50,340 --> 00:33:55,200
or if you want to manage your darkly

00:33:52,800 --> 00:33:58,470
precisely compositional API might

00:33:55,200 --> 00:34:01,140
definitely make sense so bring it

00:33:58,470 --> 00:34:05,430
through what do you need and which I pro

00:34:01,140 --> 00:34:08,190
suits you better I'll also recommend go

00:34:05,430 --> 00:34:10,770
for framework with all the various

00:34:08,190 --> 00:34:12,929
semantics available as usual don't want

00:34:10,770 --> 00:34:15,510
to limit yourself especially if you are

00:34:12,929 --> 00:34:17,840
not sure what to expect and as you don't

00:34:15,510 --> 00:34:20,490
know this quite common in our industry

00:34:17,840 --> 00:34:21,600
but of course there are definite use

00:34:20,490 --> 00:34:23,760
cases when

00:34:21,600 --> 00:34:29,700
at least once or animals once David

00:34:23,760 --> 00:34:31,470
grantees are all we need also keep in

00:34:29,700 --> 00:34:33,840
mind which might be a little bit

00:34:31,470 --> 00:34:36,320
surprising a system supporting exactly

00:34:33,840 --> 00:34:39,330
what gun the doesn't have to support

00:34:36,320 --> 00:34:44,370
weaker guarantees and yes I'm talking

00:34:39,330 --> 00:34:46,500
about Park streaming this point might be

00:34:44,370 --> 00:34:48,810
tied together the previous one a little

00:34:46,500 --> 00:34:50,610
bit most of the streaming applications

00:34:48,810 --> 00:34:53,220
are stateful and as we have seen this

00:34:50,610 --> 00:34:54,540
area might be challenging so the state

00:34:53,220 --> 00:34:56,640
management of a particular framework

00:34:54,540 --> 00:35:00,870
should be early app on your ovulation

00:34:56,640 --> 00:35:03,720
list us to make sure your system is able

00:35:00,870 --> 00:35:06,810
to recover quickly you can use house

00:35:03,720 --> 00:35:10,080
monkey or similar to for testing because

00:35:06,810 --> 00:35:12,750
as we discussed further cover is crucial

00:35:10,080 --> 00:35:17,610
and simplest thing remember you know

00:35:12,750 --> 00:35:20,090
data are still in coming and now let's

00:35:17,610 --> 00:35:24,390
take a look at particular frameworks

00:35:20,090 --> 00:35:27,240
storm is still a decent fit for small

00:35:24,390 --> 00:35:30,080
and fast task if you came in the able

00:35:27,240 --> 00:35:33,450
latency store might be a good way to go

00:35:30,080 --> 00:35:36,570
and also keep in mind for three photons

00:35:33,450 --> 00:35:39,540
or trade instead management hurts a

00:35:36,570 --> 00:35:41,940
performance a lot interesting option

00:35:39,540 --> 00:35:45,150
might be a potential update to Twitter

00:35:41,940 --> 00:35:47,130
on which is designed as storms

00:35:45,150 --> 00:35:49,740
replacement and should be better in

00:35:47,130 --> 00:35:53,400
every single point but it also keeps the

00:35:49,740 --> 00:35:55,920
API and the best thing is here on was

00:35:53,400 --> 00:35:58,410
open source very recently literally just

00:35:55,920 --> 00:36:00,990
couple of weeks ago it is a little bit

00:35:58,410 --> 00:36:04,170
uncharted territory but if you like

00:36:00,990 --> 00:36:06,680
storms API is definitely worse to try

00:36:04,170 --> 00:36:06,680
this one out

00:36:08,390 --> 00:36:13,950
for spark streaming you should

00:36:10,500 --> 00:36:16,290
definitely destroyed if spark is or the

00:36:13,950 --> 00:36:19,140
part of your infrastructure because in

00:36:16,290 --> 00:36:21,780
this case swimming comes basically for

00:36:19,140 --> 00:36:25,050
free and you can also take an advantage

00:36:21,780 --> 00:36:27,630
of various parks libraries apart from

00:36:25,050 --> 00:36:30,360
that there's a bunch of helpful tools

00:36:27,630 --> 00:36:32,360
available like red bull or spinal book

00:36:30,360 --> 00:36:34,560
or the data exploration for example

00:36:32,360 --> 00:36:37,950
universe power equals this time is

00:36:34,560 --> 00:36:39,990
really impressive and you should always

00:36:37,950 --> 00:36:43,040
keep in mind micro batching annotations

00:36:39,990 --> 00:36:47,280
which may really become a showstopper

00:36:43,040 --> 00:36:51,540
also be sure latency is not critical for

00:36:47,280 --> 00:36:53,610
you when thinking about adopting Sansa

00:36:51,540 --> 00:36:56,190
kafka should be a cornerstone over

00:36:53,610 --> 00:36:58,410
architecture I know it's pluggable but

00:36:56,190 --> 00:37:01,770
nearly everyone or maybe everyone is

00:36:58,410 --> 00:37:04,860
using Kafka so I just think of that also

00:37:01,770 --> 00:37:06,780
as mentioned before Sansa is ship a part

00:37:04,860 --> 00:37:09,690
of local storage and it's great for

00:37:06,780 --> 00:37:13,140
managing large states it can handle

00:37:09,690 --> 00:37:16,170
states of tens of gigabytes easily which

00:37:13,140 --> 00:37:19,710
is pretty nice not keep in mind sams us

00:37:16,170 --> 00:37:21,000
at least one day validation assume if

00:37:19,710 --> 00:37:23,430
you like something you should also

00:37:21,000 --> 00:37:25,380
consider newly introduced cough cough

00:37:23,430 --> 00:37:27,240
streams which offer a similar

00:37:25,380 --> 00:37:31,260
functionality with a little bit nicer

00:37:27,240 --> 00:37:33,900
API and are operated by kafka itself

00:37:31,260 --> 00:37:36,600
with degree of costly nice like library

00:37:33,900 --> 00:37:39,330
of Kafka so this is a really big ring

00:37:36,600 --> 00:37:44,540
for operation as Kafka is basically all

00:37:39,330 --> 00:37:47,430
you need if you prefer a level /

00:37:44,540 --> 00:37:50,490
compositional approach and you are also

00:37:47,430 --> 00:37:53,190
highly positive I believe apex might be

00:37:50,490 --> 00:37:56,220
a great choice for you it gives you fine

00:37:53,190 --> 00:37:58,410
fine grain access to that so you can get

00:37:56,220 --> 00:38:00,720
really most of it therefore its

00:37:58,410 --> 00:38:04,320
performance especially Shiva latencies

00:38:00,720 --> 00:38:07,650
are truly excellent move I packs a

00:38:04,320 --> 00:38:11,100
loathsome dynamic dark changes which is

00:38:07,650 --> 00:38:13,410
kind of unique feature as you see apex

00:38:11,100 --> 00:38:15,450
offers interesting options which as I

00:38:13,410 --> 00:38:19,280
believe all right it's emerging but

00:38:15,450 --> 00:38:19,280
already graduated status

00:38:20,390 --> 00:38:25,560
Frank is conceptually great streaming

00:38:23,070 --> 00:38:27,990
system which fits very most streaming

00:38:25,560 --> 00:38:30,240
use cases and it often provides

00:38:27,990 --> 00:38:33,030
progressive functionality like advanced

00:38:30,240 --> 00:38:36,990
windowing or time and link which may not

00:38:33,030 --> 00:38:38,370
be implemented by its competitors so you

00:38:36,990 --> 00:38:41,220
should always consider flank when you

00:38:38,370 --> 00:38:44,030
need a functionality which might be hard

00:38:41,220 --> 00:38:47,340
to implement in park or generally in any

00:38:44,030 --> 00:38:50,700
micro budgeting system and apart from

00:38:47,340 --> 00:38:52,940
that link also has an API for footage

00:38:50,700 --> 00:38:56,210
processing which may be pretty useful

00:38:52,940 --> 00:38:59,490
but you need to have enough courage to

00:38:56,210 --> 00:39:07,380
adopt an emerging project and also do

00:38:59,490 --> 00:39:09,600
not forget check out its roadmap and the

00:39:07,380 --> 00:39:11,730
last thing I want to mention today is

00:39:09,600 --> 00:39:15,840
data flow and it's open source

00:39:11,730 --> 00:39:18,650
initiative data flow is a part of Google

00:39:15,840 --> 00:39:21,690
cloud platform and color form has all

00:39:18,650 --> 00:39:24,990
sorts of things in it as huge into

00:39:21,690 --> 00:39:27,630
storage the query call pops up some

00:39:24,990 --> 00:39:31,350
tools for data analysis and so on and

00:39:27,630 --> 00:39:33,240
also aforementioned come with the flu it

00:39:31,350 --> 00:39:38,130
is glucose managed service for batch and

00:39:33,240 --> 00:39:39,780
reprocessing with unified API and it's

00:39:38,130 --> 00:39:42,480
built upon well known Google

00:39:39,780 --> 00:39:45,030
technologies such as MapReduce for batch

00:39:42,480 --> 00:39:47,670
processing from Java for programming

00:39:45,030 --> 00:39:50,880
model definition and milvia for simple

00:39:47,670 --> 00:39:53,640
sink and all of them are very good you

00:39:50,880 --> 00:39:55,770
know it's google you may have you may be

00:39:53,640 --> 00:39:58,230
asking what I'm talking about that as i

00:39:55,770 --> 00:40:00,750
said i was speaking about open source

00:39:58,230 --> 00:40:04,080
frameworks and it is clearly google's /

00:40:00,750 --> 00:40:06,710
beta a solution but we will decided to

00:40:04,080 --> 00:40:09,840
open source data flow SDK recently and

00:40:06,710 --> 00:40:13,590
guys behind both spark and flank have

00:40:09,840 --> 00:40:15,990
implemented its runners so now we have

00:40:13,590 --> 00:40:19,440
an ability to run jobs defined by data

00:40:15,990 --> 00:40:22,380
API in Google cloud platform and flank

00:40:19,440 --> 00:40:26,390
orange park and it's very probable more

00:40:22,380 --> 00:40:26,390
engines will fall very soon

00:40:26,680 --> 00:40:33,940
beta flow provides API in Java and in

00:40:30,310 --> 00:40:35,380
patent implemented by Google itself and

00:40:33,940 --> 00:40:38,820
also I have found a couple of scuff

00:40:35,380 --> 00:40:41,170
yourselves already apart from that

00:40:38,820 --> 00:40:43,870
google and a number of partners

00:40:41,170 --> 00:40:47,920
submitted this as a new apache proposal

00:40:43,870 --> 00:40:51,310
name apache beam I think beam has a good

00:40:47,920 --> 00:40:54,640
chance to be the unifying API that gives

00:40:51,310 --> 00:40:59,110
us a nice way to write once and around

00:40:54,640 --> 00:41:02,860
everywhere but it's important to say all

00:40:59,110 --> 00:41:04,780
this all of this is quite recent and the

00:41:02,860 --> 00:41:07,780
implementation of the promise features

00:41:04,780 --> 00:41:13,240
might be missing butterflies the worst

00:41:07,780 --> 00:41:16,720
to try this out so now it's time for

00:41:13,240 --> 00:41:19,780
questions so we have any but also I'd be

00:41:16,720 --> 00:41:22,390
found anyway and always happy to discuss

00:41:19,780 --> 00:41:31,380
our stuff so so just find me I'm usually

00:41:22,390 --> 00:41:31,380
a la bouff thank you very much

00:41:34,490 --> 00:41:36,550

YouTube URL: https://www.youtube.com/watch?v=FdcOBNSxaWc


