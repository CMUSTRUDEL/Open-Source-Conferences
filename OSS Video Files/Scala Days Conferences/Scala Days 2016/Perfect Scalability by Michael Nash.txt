Title: Perfect Scalability by Michael Nash
Publication date: 2017-01-19
Playlist: Scala Days 2016
Description: 
	This video was recorded at Scala Days Berlin 2016
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Anstract:
One of the great benefits of the Lightbend ecosystem is its ability to empower great scalability, and it is often considered for this very reason.Indeed, if employed correctly, Scala, Akka and the rest can make it possible to much more easily write systems that scale up (and out) to extremes. However, not every design is able to scale, and the approach and architecture can sharply limit this option, no matter how good the tools. What does ""perfect scalability"" look like? Is there even such a thing? Can systems be designed to scale virtually without limit? Where does the pattern break down, and what can you do about it?

In this session, we will examine the practical architectural constraints on systems intended to scale up in near-linear fashion. It turns out that having the ability to scale to extreme load is more about what not to do than it is about what to do. Why do some system scale up and others don't? How can you take a design that has problems and refactor to a design that has fewer limits? Our teams encounter these problems every day, and we keep track of what works and what doesn't in the real world. What have we seen in the field? What proven real-world design and architecture approaches can we use to help ensure our systems can scale, and what should we avoid? How can we leverage the power of the Lightbend platform to architect such systems? Which parts for which kinds of problems? How does Akka and the actor model fit these patterns? How does Spark, Kafka, Akka streaming?

Highly scalable systems often put together tools such as Docker, Ansible, Salt, Mesos, ConductR with techniques such as microservices, monitoring, and continious delivery. Automation of the deploy pipeline and deep performance monitoring are essential parts of highly scalable systems - we will look at examples of such systems, and which of the tools in the stack they employ, and why. In this talk, we'll examine both the practices and the pitfalls, and what combinations we have used to scale not only within single clusters, but across data centers for continent-spanning applications where required.We will use use-cases all the way from massive IoT scale wearable devices all the way to high finance, and find the commonalities in the solutions that don't limit their own expansion. If your organization needs to take your scalability to significantly higher levels, this talk will be where you need to start.
Captions: 
	00:00:03,240 --> 00:00:11,250
good afternoon thanks for coming out

00:00:08,160 --> 00:00:12,840
if you're used to hearing a little bit

00:00:11,250 --> 00:00:14,040
about scalability at conferences like

00:00:12,840 --> 00:00:16,199
this we're not going to waste our time

00:00:14,040 --> 00:00:17,760
on just merely good scalability we're

00:00:16,199 --> 00:00:19,320
going to talk about perfect scalability

00:00:17,760 --> 00:00:23,430
so that's not what you want to hear

00:00:19,320 --> 00:00:26,430
you're in the wrong room so Who am I

00:00:23,430 --> 00:00:28,410
who's this guy I am Michael Nash I'm the

00:00:26,430 --> 00:00:30,720
director of capabilities at light Bend

00:00:28,410 --> 00:00:32,669
I've worked with Scala NACA for a long

00:00:30,720 --> 00:00:34,320
time since before there was an actor and

00:00:32,669 --> 00:00:36,720
I've been a software developer for an

00:00:34,320 --> 00:00:37,920
embarrassingly long time that's not the

00:00:36,720 --> 00:00:40,649
interesting part what are we going to

00:00:37,920 --> 00:00:42,390
talk about you have no doubt heard the

00:00:40,649 --> 00:00:42,690
word many times at a conference like

00:00:42,390 --> 00:00:45,210
this

00:00:42,690 --> 00:00:47,040
scalability we're going to look at it a

00:00:45,210 --> 00:00:50,640
little more intently we're gonna think

00:00:47,040 --> 00:00:52,079
about what the scalability mean how does

00:00:50,640 --> 00:00:53,790
it relate to performance they're not

00:00:52,079 --> 00:00:56,399
quite the same but they're related and

00:00:53,790 --> 00:00:59,760
what characterizes a scalable

00:00:56,399 --> 00:01:02,300
architecture and design wipin

00:00:59,760 --> 00:01:05,070
technologies and Scala and akka are

00:01:02,300 --> 00:01:06,719
ideal for building scalable systems but

00:01:05,070 --> 00:01:08,369
you can also build systems that don't

00:01:06,719 --> 00:01:10,140
scale with those tools what's the

00:01:08,369 --> 00:01:12,450
difference what characteristics do we

00:01:10,140 --> 00:01:15,119
see in systems that scale well and in

00:01:12,450 --> 00:01:17,100
systems that don't and what's perfect

00:01:15,119 --> 00:01:19,650
scalability how do we know we got it

00:01:17,100 --> 00:01:22,350
right well what would the target be to

00:01:19,650 --> 00:01:25,380
say okay that's scaling as well as I can

00:01:22,350 --> 00:01:27,150
make it scale I think it was Stephen

00:01:25,380 --> 00:01:28,530
Hawking first said that every formula

00:01:27,150 --> 00:01:31,140
you have in your presentation you lose

00:01:28,530 --> 00:01:35,970
50% of your audience so I have to so

00:01:31,140 --> 00:01:38,430
that means everybody leaves if but it's

00:01:35,970 --> 00:01:40,229
down it's down the way a little so first

00:01:38,430 --> 00:01:41,280
let's just define scalability it's

00:01:40,229 --> 00:01:43,259
always good to make sure we know what

00:01:41,280 --> 00:01:44,640
we're talking about so scalability when

00:01:43,259 --> 00:01:47,270
I say scalability I don't mean

00:01:44,640 --> 00:01:50,100
performance an increase in performance

00:01:47,270 --> 00:01:52,950
means I can run the same load in less

00:01:50,100 --> 00:01:54,990
time so related but not quite the same

00:01:52,950 --> 00:01:56,820
so in other words I can handle the same

00:01:54,990 --> 00:01:58,500
number of requests in a shorter amount

00:01:56,820 --> 00:02:02,579
of time is another way to say that

00:01:58,500 --> 00:02:04,740
that's performance adding hardware to

00:02:02,579 --> 00:02:06,659
increase performance increases the speed

00:02:04,740 --> 00:02:08,369
of handling requests but doesn't

00:02:06,659 --> 00:02:10,349
necessarily increase the number of

00:02:08,369 --> 00:02:12,599
requests you can handle there's a subtle

00:02:10,349 --> 00:02:14,370
difference in terminology there so let's

00:02:12,599 --> 00:02:16,599
look at the other side if you increase

00:02:14,370 --> 00:02:18,549
scalability on a system

00:02:16,599 --> 00:02:22,180
now you can handle a larger load

00:02:18,549 --> 00:02:24,609
keywords without failure right so a

00:02:22,180 --> 00:02:27,129
larger load potentially even on the same

00:02:24,609 --> 00:02:29,739
hardware without failing but we can also

00:02:27,129 --> 00:02:32,260
more importantly handle more requests in

00:02:29,739 --> 00:02:33,670
the same amount of time often when we

00:02:32,260 --> 00:02:35,769
increase scalability we may have an

00:02:33,670 --> 00:02:36,609
effect on performance and vice versa but

00:02:35,769 --> 00:02:39,250
they're very different

00:02:36,609 --> 00:02:41,379
adding hardware to a scalable system

00:02:39,250 --> 00:02:43,419
should increase your ability to handle

00:02:41,379 --> 00:02:45,489
more requests a larger amount of

00:02:43,419 --> 00:02:48,340
requests not necessarily make any one of

00:02:45,489 --> 00:02:49,780
those requests go faster so subtle but

00:02:48,340 --> 00:02:51,900
different it's pretty simple on the

00:02:49,780 --> 00:02:54,310
diagram so if you've got a system and

00:02:51,900 --> 00:02:56,260
increasing response time goes this way

00:02:54,310 --> 00:02:57,639
and the number of requests go this way

00:02:56,260 --> 00:02:58,780
when you start you often have a curve

00:02:57,639 --> 00:03:00,939
that looks a little bit like this and

00:02:58,780 --> 00:03:03,250
bad news starts to happen somewhere up

00:03:00,939 --> 00:03:04,689
in in this region where perhaps after

00:03:03,250 --> 00:03:06,819
this you actually start to encounter

00:03:04,689 --> 00:03:10,000
errors or at least you get

00:03:06,819 --> 00:03:12,219
ever-increasing response time if you

00:03:10,000 --> 00:03:14,019
increase the performance of that system

00:03:12,219 --> 00:03:16,780
what you do is you don't change the

00:03:14,019 --> 00:03:19,659
shape of the line necessarily you move

00:03:16,780 --> 00:03:22,120
it down so in terms of response time

00:03:19,659 --> 00:03:25,120
this is a pure performance increase

00:03:22,120 --> 00:03:26,650
without affecting scalability if we look

00:03:25,120 --> 00:03:27,819
at the converse so if we go the other

00:03:26,650 --> 00:03:30,220
way and say all right what to

00:03:27,819 --> 00:03:32,979
scalability looked like then it's moving

00:03:30,220 --> 00:03:34,419
the line this way or changing the shape

00:03:32,979 --> 00:03:36,519
of the line sometimes frequently

00:03:34,419 --> 00:03:38,919
changing the shape of the line so if the

00:03:36,519 --> 00:03:40,959
line doesn't necessarily come down but

00:03:38,919 --> 00:03:42,519
just goes to the right that means we're

00:03:40,959 --> 00:03:44,019
now handling a larger number of requests

00:03:42,519 --> 00:03:46,569
but each request is taking about the

00:03:44,019 --> 00:03:48,310
same amount of time that's the dividing

00:03:46,569 --> 00:03:50,560
line between scalability and performance

00:03:48,310 --> 00:03:52,359
and what increasing one means without

00:03:50,560 --> 00:03:53,560
necessarily increasing the other as I

00:03:52,359 --> 00:03:55,449
said they're coupled they're highly

00:03:53,560 --> 00:03:57,340
related usually when you change one you

00:03:55,449 --> 00:03:59,169
change the other and you have to measure

00:03:57,340 --> 00:04:01,269
very carefully like this graph as the

00:03:59,169 --> 00:04:02,769
result would be on a real system I made

00:04:01,269 --> 00:04:04,930
this one up but would be on a real

00:04:02,769 --> 00:04:07,180
system obviously the result of doing a

00:04:04,930 --> 00:04:08,829
lot of measurements under load and it's

00:04:07,180 --> 00:04:12,180
very hard to get repeatability etc etc

00:04:08,829 --> 00:04:14,859
so if that's scalability what's perfect

00:04:12,180 --> 00:04:16,389
scalability what would the ideal be what

00:04:14,859 --> 00:04:18,459
would be what would be at the top of the

00:04:16,389 --> 00:04:20,440
goal chart if we said okay what's the

00:04:18,459 --> 00:04:23,469
best possible scalability we can achieve

00:04:20,440 --> 00:04:26,469
well basically it would mean simply

00:04:23,469 --> 00:04:28,240
enough if we add more resources we can

00:04:26,469 --> 00:04:30,410
handle higher load

00:04:28,240 --> 00:04:31,940
perfect scalability so that's

00:04:30,410 --> 00:04:33,890
scalability at all

00:04:31,940 --> 00:04:36,680
perfect scalability would mean that that

00:04:33,890 --> 00:04:38,510
increases linear in other words if the

00:04:36,680 --> 00:04:40,430
relationship between additional

00:04:38,510 --> 00:04:42,940
resources more nodes let's say or more

00:04:40,430 --> 00:04:46,850
memory or more CPUs or more whatever

00:04:42,940 --> 00:04:48,860
results more qubits in the future and

00:04:46,850 --> 00:04:52,610
that additional capacity for load is

00:04:48,860 --> 00:04:54,650
linear then the scalability is perfect

00:04:52,610 --> 00:04:57,020
in other words if we could handle a

00:04:54,650 --> 00:04:59,420
thousand requests in some period of time

00:04:57,020 --> 00:05:02,150
on or a thousand requests without

00:04:59,420 --> 00:05:04,100
failure on one node we can handle 2,000

00:05:02,150 --> 00:05:06,530
requests if we add two nodes if that

00:05:04,100 --> 00:05:09,290
trend continued we'd have perfect

00:05:06,530 --> 00:05:11,540
scalability doesn't often happen but it

00:05:09,290 --> 00:05:13,280
can and there are a lot of there are a

00:05:11,540 --> 00:05:14,900
lot of ways to make it not happen and I

00:05:13,280 --> 00:05:17,120
can talk with great authority on those

00:05:14,900 --> 00:05:19,490
the way is to make it happen that's a

00:05:17,120 --> 00:05:21,320
little harder so in other words our

00:05:19,490 --> 00:05:24,230
graph should look like this if we hit

00:05:21,320 --> 00:05:26,660
perfect scalability eventually this line

00:05:24,230 --> 00:05:29,090
in the large it may have ripples but

00:05:26,660 --> 00:05:31,850
this line should in the large be flat so

00:05:29,090 --> 00:05:32,750
we add more resources so somewhere in

00:05:31,850 --> 00:05:34,730
here we're gonna have to add another

00:05:32,750 --> 00:05:35,810
node let's say then we add another node

00:05:34,730 --> 00:05:37,490
in another node and another node in

00:05:35,810 --> 00:05:39,050
another node if this line just keeps

00:05:37,490 --> 00:05:41,120
going off to the right never goes up

00:05:39,050 --> 00:05:44,270
again we've achieved perfect scalability

00:05:41,120 --> 00:05:45,790
simple enough right everybody with me so

00:05:44,270 --> 00:05:48,740
far

00:05:45,790 --> 00:05:50,270
so let's look at an example of a

00:05:48,740 --> 00:05:52,550
perfectly scalable system are really

00:05:50,270 --> 00:05:54,530
really simple perfectly scalable system

00:05:52,550 --> 00:05:56,780
just to explore some of these

00:05:54,530 --> 00:05:59,240
fundamental concepts so let's say we

00:05:56,780 --> 00:06:02,000
have a system that has two integers it

00:05:59,240 --> 00:06:03,830
has an HTTP API two numbers are passed

00:06:02,000 --> 00:06:05,450
as parameters on a URL yes I know

00:06:03,830 --> 00:06:07,280
terrible design and the result is the

00:06:05,450 --> 00:06:09,230
response okay that's gonna perform

00:06:07,280 --> 00:06:11,840
pretty good almost no matter what you

00:06:09,230 --> 00:06:15,310
write that in it's going to perform

00:06:11,840 --> 00:06:19,100
pretty good will it scale well probably

00:06:15,310 --> 00:06:21,410
why does it scale so imagine that system

00:06:19,100 --> 00:06:23,420
and imagine adding new resources to it

00:06:21,410 --> 00:06:25,220
eg bigger computer or many computers

00:06:23,420 --> 00:06:26,480
because both of those are possible ones

00:06:25,220 --> 00:06:28,940
vertical scalability the others

00:06:26,480 --> 00:06:31,160
horizontal scalability so we're dumping

00:06:28,940 --> 00:06:33,470
new resources on it it goes faster why

00:06:31,160 --> 00:06:34,700
so what have we achieved what are the

00:06:33,470 --> 00:06:37,070
characteristics what are the

00:06:34,700 --> 00:06:39,080
fundamentals of this system that mean

00:06:37,070 --> 00:06:41,000
that it could scale well there's no

00:06:39,080 --> 00:06:41,719
state we had two integers we spit up the

00:06:41,000 --> 00:06:43,699
answer that's it

00:06:41,719 --> 00:06:45,739
we're not saying we add cumulatively

00:06:43,699 --> 00:06:47,089
integers forever that would be different

00:06:45,739 --> 00:06:48,799
that would actually be a very different

00:06:47,089 --> 00:06:51,889
design and that would share something

00:06:48,799 --> 00:06:53,989
the individual computations sure nothing

00:06:51,889 --> 00:06:55,699
there's no opportunity for contention

00:06:53,989 --> 00:06:57,559
and we'll talk a lot about contention

00:06:55,699 --> 00:06:58,939
because it's a big enemy and all of the

00:06:57,559 --> 00:07:00,349
computations are independent doesn't

00:06:58,939 --> 00:07:02,059
matter if you add two and two and you

00:07:00,349 --> 00:07:03,110
add Forum forward they both work they've

00:07:02,059 --> 00:07:06,319
got nothing to do with each other

00:07:03,110 --> 00:07:08,989
there's no shared computational state

00:07:06,319 --> 00:07:11,860
between those two elements now is this

00:07:08,989 --> 00:07:14,809
perfect scalability it's interesting

00:07:11,860 --> 00:07:16,459
it's actually flawed launch looked

00:07:14,809 --> 00:07:18,319
pretty good but somewhere wrong about

00:07:16,459 --> 00:07:19,999
here something went wrong well what

00:07:18,319 --> 00:07:21,919
would happen if you kept pushing that

00:07:19,999 --> 00:07:23,539
line if you kept adding resources and

00:07:21,919 --> 00:07:25,399
you kept adding load where would we

00:07:23,539 --> 00:07:27,800
eventually fail it's interesting where

00:07:25,399 --> 00:07:29,329
we'd fail likely where we would fail

00:07:27,800 --> 00:07:31,369
I've naturally tried this but I've seen

00:07:29,329 --> 00:07:32,629
systems like this where we would fail is

00:07:31,369 --> 00:07:34,610
that all of these moons are on a single

00:07:32,629 --> 00:07:35,809
HTTP namespace it's entirely possible

00:07:34,610 --> 00:07:37,809
they're all going through a single

00:07:35,809 --> 00:07:39,709
hardware load balancer for example

00:07:37,809 --> 00:07:41,659
eventually something's going to create a

00:07:39,709 --> 00:07:44,209
bottleneck that's because something is

00:07:41,659 --> 00:07:46,189
shared in this case very little and yes

00:07:44,209 --> 00:07:48,139
we can scale it tremendously but it's

00:07:46,189 --> 00:07:49,669
not perfect scalability there is a limit

00:07:48,139 --> 00:07:50,949
and that's the difference that's the

00:07:49,669 --> 00:07:53,269
differentiator I'm drawing between

00:07:50,949 --> 00:07:55,909
perfect scalability where theoretically

00:07:53,269 --> 00:07:57,800
there is no limit and really good

00:07:55,909 --> 00:08:00,379
scalability where yes at some point

00:07:57,800 --> 00:08:02,149
you're going to find a wall again so

00:08:00,379 --> 00:08:03,110
eventually we hit Network issues is

00:08:02,149 --> 00:08:04,489
really what it amounts to the

00:08:03,110 --> 00:08:05,779
computations themselves they're never

00:08:04,489 --> 00:08:07,300
going to be the problem we had enough

00:08:05,779 --> 00:08:09,409
CPU it's going to go faster and faster

00:08:07,300 --> 00:08:11,300
seldom do we have a system that's quite

00:08:09,409 --> 00:08:12,679
that simple however we actually have the

00:08:11,300 --> 00:08:14,029
bottlenecks come up in all sorts of

00:08:12,679 --> 00:08:17,329
different and interesting places we'll

00:08:14,029 --> 00:08:20,029
talk about those so how would we fix it

00:08:17,329 --> 00:08:22,369
yes that's a rocket with duct tape and

00:08:20,029 --> 00:08:25,119
that is a petrol station behind it what

00:08:22,369 --> 00:08:25,119
could possibly go wrong

00:08:25,570 --> 00:08:29,170
I'm not saying you should use duct tape

00:08:27,430 --> 00:08:29,710
or Rockets with petrol stations but you

00:08:29,170 --> 00:08:31,360
get the idea

00:08:29,710 --> 00:08:33,220
how would we fix it well we would fix it

00:08:31,360 --> 00:08:35,140
in this case by breaking up that

00:08:33,220 --> 00:08:36,700
namespace for the sake of argument put

00:08:35,140 --> 00:08:38,700
them on different data centers

00:08:36,700 --> 00:08:41,650
distribute them across different AWS

00:08:38,700 --> 00:08:43,450
regions let's say the client might need

00:08:41,650 --> 00:08:44,680
to be smarter it might need to randomly

00:08:43,450 --> 00:08:47,500
pick one of these to send its to

00:08:44,680 --> 00:08:49,930
integers to but we would eliminate the

00:08:47,500 --> 00:08:51,850
one thing we were sharing and therefore

00:08:49,930 --> 00:08:54,100
we would have something much closer to

00:08:51,850 --> 00:08:55,930
perfect scalability likely as far as any

00:08:54,100 --> 00:08:58,150
reasonable limit so we could put on and

00:08:55,930 --> 00:09:00,550
it would be perfect scalability so what

00:08:58,150 --> 00:09:02,200
do we do that made that help like we

00:09:00,550 --> 00:09:03,790
know what to do why what is the

00:09:02,200 --> 00:09:06,760
characteristic of what we just did to

00:09:03,790 --> 00:09:09,040
help well what we did we shared less we

00:09:06,760 --> 00:09:10,720
took the one tiny little bit that we

00:09:09,040 --> 00:09:11,530
were sharing in our entire system when

00:09:10,720 --> 00:09:14,350
we stopped doing it

00:09:11,530 --> 00:09:16,060
we stopped sharing that is one of the

00:09:14,350 --> 00:09:18,460
characteristics that will explore that

00:09:16,060 --> 00:09:19,590
sharing is a bad thing unlike what you

00:09:18,460 --> 00:09:22,660
might teach you kids

00:09:19,590 --> 00:09:24,970
it's actually talked about it begins way

00:09:22,660 --> 00:09:26,320
back I'm sure some of you with as much

00:09:24,970 --> 00:09:28,210
gray hair as me can remember

00:09:26,320 --> 00:09:29,890
em dolls law when I'm dolls law was a

00:09:28,210 --> 00:09:31,990
big deal it's not talked about as much

00:09:29,890 --> 00:09:33,460
now because you have to stretch it and

00:09:31,990 --> 00:09:35,950
change it a little bit to apply to a

00:09:33,460 --> 00:09:38,940
distributed system however the idea is

00:09:35,950 --> 00:09:41,920
that it still applies the ideas in the

00:09:38,940 --> 00:09:45,550
portion of your programs compute time

00:09:41,920 --> 00:09:47,890
that can be parallelized compared to the

00:09:45,550 --> 00:09:52,000
portion that requires sequential

00:09:47,890 --> 00:09:53,710
operation the ratio is one combination

00:09:52,000 --> 00:09:54,820
is 100 percent of your execution time in

00:09:53,710 --> 00:09:57,010
other words if you could say 50 percent

00:09:54,820 --> 00:09:58,810
parallelizable 50 percent must be done

00:09:57,010 --> 00:10:01,960
sequential and obviously the totals 100

00:09:58,810 --> 00:10:04,330
100 minus P is the upper bound on how

00:10:01,960 --> 00:10:07,270
much any parallelism or distribution can

00:10:04,330 --> 00:10:09,970
help the theory says that in a system

00:10:07,270 --> 00:10:13,360
where P is only 50% I can add all the

00:10:09,970 --> 00:10:15,520
nodes I want to compute that 50% in

00:10:13,360 --> 00:10:17,560
parallel eventually I'll hit a wall

00:10:15,520 --> 00:10:18,910
because the other 50% can't be

00:10:17,560 --> 00:10:21,610
parallelized and therefore I'm not

00:10:18,910 --> 00:10:23,980
getting anywhere so therefore in every

00:10:21,610 --> 00:10:25,780
parallel and concurrent system we seek

00:10:23,980 --> 00:10:27,430
to minimize that portion it's one of the

00:10:25,780 --> 00:10:30,790
design principles behind actor driven

00:10:27,430 --> 00:10:33,370
systems of course and I just said that

00:10:30,790 --> 00:10:34,930
yes ok there was a thing called mr.

00:10:33,370 --> 00:10:36,550
funds counter argument which was very

00:10:34,930 --> 00:10:37,900
interesting however that all gets

00:10:36,550 --> 00:10:39,250
wrapped together into here's my

00:10:37,900 --> 00:10:41,800
second of two formulas you see you're

00:10:39,250 --> 00:10:44,650
all still here called good throws lower

00:10:41,800 --> 00:10:46,390
or the universal law of computational

00:10:44,650 --> 00:10:48,850
skill ability that's a little harder to

00:10:46,390 --> 00:10:50,860
say but the idea is we then take and do

00:10:48,850 --> 00:10:52,510
ye well yeah okay back back back we go

00:10:50,860 --> 00:10:54,340
we then take into account the fact that

00:10:52,510 --> 00:10:57,580
I don't know how to run the remote there

00:10:54,340 --> 00:10:59,740
we go which count doctoral rescue did

00:10:57,580 --> 00:11:01,480
this so I don't feel too bad we take

00:10:59,740 --> 00:11:03,460
into account the coherency delay so in

00:11:01,480 --> 00:11:06,010
other words the ability of the system to

00:11:03,460 --> 00:11:07,750
become eventually consistent assuming

00:11:06,010 --> 00:11:08,200
their shared state must be taken into

00:11:07,750 --> 00:11:10,600
account

00:11:08,200 --> 00:11:12,790
this basically updates Amdahl's law into

00:11:10,600 --> 00:11:14,290
the distributed world not going to go

00:11:12,790 --> 00:11:15,700
into the details and the computations

00:11:14,290 --> 00:11:17,080
but there is such a thing as the

00:11:15,700 --> 00:11:19,230
universal law of computational

00:11:17,080 --> 00:11:22,420
scalability and I very much recommend

00:11:19,230 --> 00:11:26,200
reading some of the work by dr. Gunter

00:11:22,420 --> 00:11:28,450
very interesting so bottom line is that

00:11:26,200 --> 00:11:30,820
each of these laws are telling us that

00:11:28,450 --> 00:11:32,440
somewhere down that curve there's a wall

00:11:30,820 --> 00:11:34,510
there's something we're going to run

00:11:32,440 --> 00:11:35,980
into that says beyond here we're going

00:11:34,510 --> 00:11:38,140
to have a hard time scaling for some

00:11:35,980 --> 00:11:40,330
fundamental reason not because I just

00:11:38,140 --> 00:11:41,650
haven't paid Amazon enough money or herm

00:11:40,330 --> 00:11:43,300
whatever my host is or haven't bought

00:11:41,650 --> 00:11:45,670
enough computers or I'm configured it

00:11:43,300 --> 00:11:48,640
correctly you can't tune it beyond these

00:11:45,670 --> 00:11:50,830
design limitations so at the high ends

00:11:48,640 --> 00:11:53,470
of scalability often many of the systems

00:11:50,830 --> 00:11:55,210
we build will be perfectly happy well

00:11:53,470 --> 00:11:57,640
out of the range of perfect scalability

00:11:55,210 --> 00:11:59,440
because we'll be below that point in the

00:11:57,640 --> 00:12:01,840
curve where the dogleg goes crazy and we

00:11:59,440 --> 00:12:03,880
have these problems right not a problem

00:12:01,840 --> 00:12:06,820
however if you're building a system now

00:12:03,880 --> 00:12:09,370
that you expect to be put under a great

00:12:06,820 --> 00:12:11,470
deal more load in the future then you

00:12:09,370 --> 00:12:13,840
could be setting yourself up for success

00:12:11,470 --> 00:12:16,090
being the way you fail so in other words

00:12:13,840 --> 00:12:17,320
the number of users that jump onto your

00:12:16,090 --> 00:12:19,450
system because their systems are very

00:12:17,320 --> 00:12:21,040
successful suddenly creates the very

00:12:19,450 --> 00:12:23,710
problem that you didn't have when it was

00:12:21,040 --> 00:12:25,720
originally built that's the wall that's

00:12:23,710 --> 00:12:26,980
what I mean by the wall so it's common

00:12:25,720 --> 00:12:28,630
to reach a point where you can throw

00:12:26,980 --> 00:12:30,460
more resources at a system all you want

00:12:28,630 --> 00:12:32,650
it doesn't go faster it actually goes

00:12:30,460 --> 00:12:34,360
slower because the coordination time is

00:12:32,650 --> 00:12:35,560
actually taking longer and longer and I

00:12:34,360 --> 00:12:37,060
think we've all played with that a

00:12:35,560 --> 00:12:38,380
little bit the first couple of times you

00:12:37,060 --> 00:12:40,000
play with acqua for example you'll write

00:12:38,380 --> 00:12:41,350
a system like this where you add more

00:12:40,000 --> 00:12:44,320
actors it doesn't go any faster it

00:12:41,350 --> 00:12:46,510
actually starts to slow down so as

00:12:44,320 --> 00:12:48,370
Thomas Edison once said you have not in

00:12:46,510 --> 00:12:50,530
fact failed but we have found 10,000

00:12:48,370 --> 00:12:51,260
ways that don't work and I think the

00:12:50,530 --> 00:12:53,240
history

00:12:51,260 --> 00:12:55,250
of distribution and parallel systems

00:12:53,240 --> 00:12:57,380
have demonstrated in many many different

00:12:55,250 --> 00:12:59,900
ways where we still have a bottleneck

00:12:57,380 --> 00:13:01,400
and we still have a wall and as I said

00:12:59,900 --> 00:13:04,220
I'm an expert on systems that didn't

00:13:01,400 --> 00:13:05,570
necessarily scale so I can talk a little

00:13:04,220 --> 00:13:09,020
bit about what some of those ways are

00:13:05,570 --> 00:13:10,640
there aren't 10,000 there's fewer so how

00:13:09,020 --> 00:13:13,430
do we avoid the wall in other words how

00:13:10,640 --> 00:13:16,550
do we get a system whereby there may be

00:13:13,430 --> 00:13:18,740
a slowdown in the advantage we get when

00:13:16,550 --> 00:13:20,300
we add more resources but we never go

00:13:18,740 --> 00:13:22,190
into negative territory and we never hit

00:13:20,300 --> 00:13:23,810
zero so if you throw more hardware at it

00:13:22,190 --> 00:13:25,070
it will just keep getting more and more

00:13:23,810 --> 00:13:27,050
capable of handling loads not

00:13:25,070 --> 00:13:29,030
necessarily faster it's easy to say it

00:13:27,050 --> 00:13:30,650
will get faster won't necessarily it

00:13:29,030 --> 00:13:35,030
will get more capable of handling load

00:13:30,650 --> 00:13:37,610
more scalable the way I've seen that

00:13:35,030 --> 00:13:40,040
achieved is as I said we've seen many

00:13:37,610 --> 00:13:43,310
systems that won't scale usually they

00:13:40,040 --> 00:13:46,220
have always actually they have one of

00:13:43,310 --> 00:13:48,410
these enemies comes to the fore as the

00:13:46,220 --> 00:13:52,040
problem that is causing the limitation

00:13:48,410 --> 00:13:54,080
that's causing the wall so some of the

00:13:52,040 --> 00:13:57,200
enemies of scalability or what I want to

00:13:54,080 --> 00:13:58,430
talk about and they are just quickly and

00:13:57,200 --> 00:14:00,830
there's a few others but these are the

00:13:58,430 --> 00:14:02,210
top ones contention shared state which

00:14:00,830 --> 00:14:04,310
aren't quite the same thing but again

00:14:02,210 --> 00:14:06,530
are quite closely related sharing

00:14:04,310 --> 00:14:08,960
sharing in general actually not

00:14:06,530 --> 00:14:10,940
necessarily sharing state ordering and

00:14:08,960 --> 00:14:13,670
sequence which when you think about it

00:14:10,940 --> 00:14:15,440
are also a kind of sharing communication

00:14:13,670 --> 00:14:17,390
which sounds a little weird I'll just

00:14:15,440 --> 00:14:19,190
blame that a bit more and failure which

00:14:17,390 --> 00:14:21,980
seems entirely obvious but I'll explain

00:14:19,190 --> 00:14:24,860
it a little bit further as well so let's

00:14:21,980 --> 00:14:28,520
look at some of these contention is

00:14:24,860 --> 00:14:30,560
probably a category of problems that is

00:14:28,520 --> 00:14:32,230
top of the list and contention

00:14:30,560 --> 00:14:34,250
essentially comes from having

00:14:32,230 --> 00:14:35,810
parallelism or distribution not

00:14:34,250 --> 00:14:37,520
concurrency concurrency will never give

00:14:35,810 --> 00:14:39,200
you contention because concurrency is

00:14:37,520 --> 00:14:41,750
not necessarily parallelism but

00:14:39,200 --> 00:14:43,670
parallelism eg more than one actual CPU

00:14:41,750 --> 00:14:46,750
and distribution more than one actual

00:14:43,670 --> 00:14:49,820
machine will eventually create a

00:14:46,750 --> 00:14:51,980
contention problem assuming there is any

00:14:49,820 --> 00:14:53,660
form of shared state and any form is a

00:14:51,980 --> 00:14:56,030
big sentence there's a lot of different

00:14:53,660 --> 00:14:58,130
kinds of shared State so no shared

00:14:56,030 --> 00:14:59,720
resources avoids it there you go

00:14:58,130 --> 00:15:00,950
simple right I've given you all the

00:14:59,720 --> 00:15:02,330
answer now you know how to write

00:15:00,950 --> 00:15:04,280
perfectly scalable systems don't share

00:15:02,330 --> 00:15:05,619
any state anywhere it's not that simple

00:15:04,280 --> 00:15:09,439
I know you know

00:15:05,619 --> 00:15:10,999
so avoiding sharing and the the answer

00:15:09,439 --> 00:15:14,629
is really getting stopped their own

00:15:10,999 --> 00:15:17,359
stick well what I mean is denormalize as

00:15:14,629 --> 00:15:19,189
needed so if you have state that

00:15:17,359 --> 00:15:22,339
individual elements of your application

00:15:19,189 --> 00:15:23,959
would normally share instead of sharing

00:15:22,339 --> 00:15:25,969
yet them each their own stick get to

00:15:23,959 --> 00:15:27,979
meet your copy of that state and then

00:15:25,969 --> 00:15:29,209
devise a means for updating that state

00:15:27,979 --> 00:15:31,039
in an appropriate fashion what I'm

00:15:29,209 --> 00:15:34,249
really saying and what it leads to is

00:15:31,039 --> 00:15:36,319
eventual consistency event sourcing CQRS

00:15:34,249 --> 00:15:37,699
these are techniques to get there but

00:15:36,319 --> 00:15:40,339
the fundamental you're trying to achieve

00:15:37,699 --> 00:15:43,159
is to reduce the sharing and reduce the

00:15:40,339 --> 00:15:45,949
contention those are all methodologies

00:15:43,159 --> 00:15:47,709
for for making updates possible in a

00:15:45,949 --> 00:15:50,629
system that doesn't directly share data

00:15:47,709 --> 00:15:52,279
so state there is nothing necessarily

00:15:50,629 --> 00:15:55,039
evil about state unless of course you're

00:15:52,279 --> 00:15:58,129
a hospital programmer however state is

00:15:55,039 --> 00:15:59,059
fine but state must be private private

00:15:58,129 --> 00:16:01,159
at various levels

00:15:59,059 --> 00:16:03,109
it ends up private to actors it ends up

00:16:01,159 --> 00:16:05,119
private to services and ends up private

00:16:03,109 --> 00:16:07,099
to nodes at various levels of

00:16:05,119 --> 00:16:09,739
granularity that state is kept private

00:16:07,099 --> 00:16:11,389
then in some fashion if that state

00:16:09,739 --> 00:16:12,409
changes if the state never changes well

00:16:11,389 --> 00:16:14,659
you don't have a problem what are you

00:16:12,409 --> 00:16:16,129
doing here that's great you just put the

00:16:14,659 --> 00:16:17,839
state on every machine it never changes

00:16:16,129 --> 00:16:20,419
obviously we're building systems where

00:16:17,839 --> 00:16:22,459
the state does change so things such as

00:16:20,419 --> 00:16:24,889
mechanisms and there are many for

00:16:22,459 --> 00:16:28,279
broadcasting the deltas to that state

00:16:24,889 --> 00:16:30,019
are typically used to update that state

00:16:28,279 --> 00:16:31,579
individually though so in other words I

00:16:30,019 --> 00:16:33,439
don't say change your state to this I

00:16:31,579 --> 00:16:35,749
say this thing that's happened in the

00:16:33,439 --> 00:16:37,309
overall system and the system the node

00:16:35,749 --> 00:16:39,469
may in fact choose to update its local

00:16:37,309 --> 00:16:40,699
state so private state I just said the

00:16:39,469 --> 00:16:43,309
same thing the in private state can then

00:16:40,699 --> 00:16:45,169
be updated from these deltas after the

00:16:43,309 --> 00:16:47,989
fact which is the bottom line of

00:16:45,169 --> 00:16:49,489
eventual consistency of course what's

00:16:47,989 --> 00:16:52,099
interesting is that's advocating

00:16:49,489 --> 00:16:54,919
communication the next enemy of

00:16:52,099 --> 00:16:56,319
scalability is communication so this is

00:16:54,919 --> 00:16:58,489
a fine balancing act as you can imagine

00:16:56,319 --> 00:17:01,189
limiting communication this sounds very

00:16:58,489 --> 00:17:02,479
strange for people building distributed

00:17:01,189 --> 00:17:05,029
systems while they must communicate with

00:17:02,479 --> 00:17:07,490
each other yes but in your design

00:17:05,029 --> 00:17:10,159
considerations think of communication as

00:17:07,490 --> 00:17:11,600
a cost it's on the debit side of the

00:17:10,159 --> 00:17:14,389
spreadsheet it is not to your advantage

00:17:11,600 --> 00:17:16,730
to have systems communicate it

00:17:14,389 --> 00:17:18,589
point-to-point communication which is a

00:17:16,730 --> 00:17:20,689
special case of communication

00:17:18,589 --> 00:17:22,520
especially an enemy because it's a form

00:17:20,689 --> 00:17:25,520
of coupling as well as a high-cost

00:17:22,520 --> 00:17:26,870
so now you have two problems take into

00:17:25,520 --> 00:17:28,400
account locality

00:17:26,870 --> 00:17:30,590
when considering that cost in other

00:17:28,400 --> 00:17:32,539
words where are you communicating the

00:17:30,590 --> 00:17:33,890
network is not of infinite speed one of

00:17:32,539 --> 00:17:36,830
those fallacies that we all live with

00:17:33,890 --> 00:17:39,529
and being able for example to distribute

00:17:36,830 --> 00:17:40,789
in a cluster amongst multiple data

00:17:39,529 --> 00:17:43,039
centers turns out to be a bad idea

00:17:40,789 --> 00:17:44,330
that's that's a problem and it's a

00:17:43,039 --> 00:17:47,750
problem that has to be overcome because

00:17:44,330 --> 00:17:49,370
the locality of the gossip protocol

00:17:47,750 --> 00:17:50,929
assumes that we're talking about

00:17:49,370 --> 00:17:53,029
something that is on a very fast network

00:17:50,929 --> 00:17:54,710
link not something that I have to go

00:17:53,029 --> 00:17:56,720
across the continent to communicate with

00:17:54,710 --> 00:17:58,070
so that's an example of a design

00:17:56,720 --> 00:18:01,309
consideration you'd have to take into

00:17:58,070 --> 00:18:04,669
account to say communication costs it

00:18:01,309 --> 00:18:07,340
cost me money it cost me time bigger

00:18:04,669 --> 00:18:11,270
than communication in terms of its cost

00:18:07,340 --> 00:18:12,950
is to avoid ordering I don't mean buying

00:18:11,270 --> 00:18:16,970
things on Amazon what I mean is a

00:18:12,950 --> 00:18:18,020
sequence so sequence by definition if

00:18:16,970 --> 00:18:20,000
you think about it from a mathematical

00:18:18,020 --> 00:18:21,470
point of view leads to shared State

00:18:20,000 --> 00:18:24,049
somebody has to determine what the

00:18:21,470 --> 00:18:25,250
sequences did is this the next event or

00:18:24,049 --> 00:18:26,870
the previous event well somewhere along

00:18:25,250 --> 00:18:28,399
the line there has to be state that

00:18:26,870 --> 00:18:30,049
determines if this is the next event or

00:18:28,399 --> 00:18:31,880
the previous event it leads to

00:18:30,049 --> 00:18:33,529
contention because at some point perhaps

00:18:31,880 --> 00:18:34,789
we're going to queue these events well

00:18:33,529 --> 00:18:36,590
if we're going to preserve their state

00:18:34,789 --> 00:18:38,270
if we're going to preserve their

00:18:36,590 --> 00:18:39,770
sequence then we have a lot more trouble

00:18:38,270 --> 00:18:43,279
queuing these events than if we didn't

00:18:39,770 --> 00:18:45,289
and it limits scalability so it's almost

00:18:43,279 --> 00:18:46,730
the same as in the programmatic sense

00:18:45,289 --> 00:18:48,919
and in the functional programming sense

00:18:46,730 --> 00:18:50,659
of staying saying state commutative

00:18:48,919 --> 00:18:52,490
where orders can be applied in any

00:18:50,659 --> 00:18:54,799
operation if you can do that in the

00:18:52,490 --> 00:18:57,049
large it works just as well as it does

00:18:54,799 --> 00:18:58,850
in the small if your operations can

00:18:57,049 --> 00:19:00,950
stand that if they can't try to find

00:18:58,850 --> 00:19:02,210
other operations it's possible usually

00:19:00,950 --> 00:19:05,809
to design a system and change your

00:19:02,210 --> 00:19:06,890
algorithm such as that is possible we'll

00:19:05,809 --> 00:19:09,500
talk about that a little more in detail

00:19:06,890 --> 00:19:12,140
of course one of the things about a

00:19:09,500 --> 00:19:13,940
scalable system it's usually a

00:19:12,140 --> 00:19:15,110
distributed system eg there are many

00:19:13,940 --> 00:19:17,210
machines involved there are many

00:19:15,110 --> 00:19:19,220
networks many CPUs lots and lots of

00:19:17,210 --> 00:19:22,970
pieces it can break typically they will

00:19:19,220 --> 00:19:26,960
so the distributed system is more likely

00:19:22,970 --> 00:19:28,429
to have something fail ideally if we

00:19:26,960 --> 00:19:31,610
build it right however it is much less

00:19:28,429 --> 00:19:32,360
likely to fail as a system so the sound

00:19:31,610 --> 00:19:34,429
contradictory but

00:19:32,360 --> 00:19:35,929
basically one piece can fail the ability

00:19:34,429 --> 00:19:37,970
for the whole system to fail however

00:19:35,929 --> 00:19:40,070
should actually be going up not going

00:19:37,970 --> 00:19:41,600
down it's very easy if you don't

00:19:40,070 --> 00:19:42,260
consider that failure correctly and how

00:19:41,600 --> 00:19:44,090
to handle it

00:19:42,260 --> 00:19:45,620
to do the reverse to actually build a

00:19:44,090 --> 00:19:47,720
distributed system such that it is in

00:19:45,620 --> 00:19:50,059
fact way easier for it to fail then a

00:19:47,720 --> 00:19:52,100
single node system which actually has

00:19:50,059 --> 00:19:54,980
accounted for failure of a few systems

00:19:52,100 --> 00:19:56,720
to be deployed so also a distributed

00:19:54,980 --> 00:19:59,330
system has far more opportunity to be

00:19:56,720 --> 00:20:02,299
likely to survive that failure and again

00:19:59,330 --> 00:20:04,790
the less we share the less likely is

00:20:02,299 --> 00:20:07,250
system failure and that's a strange

00:20:04,790 --> 00:20:08,900
combination as well so not only can we

00:20:07,250 --> 00:20:10,640
be more scalable if we share fewer

00:20:08,900 --> 00:20:12,679
things and watch our communication very

00:20:10,640 --> 00:20:14,270
carefully but it also has a direct

00:20:12,679 --> 00:20:19,010
relationship to the ability to have our

00:20:14,270 --> 00:20:20,690
systems recover from failure so part of

00:20:19,010 --> 00:20:22,010
avoiding sequence all of these things

00:20:20,690 --> 00:20:24,049
are tied together and I think you can

00:20:22,010 --> 00:20:27,080
see that part of avoiding sequence is to

00:20:24,049 --> 00:20:28,309
avoid the idea of linear time this does

00:20:27,080 --> 00:20:30,380
not mean you require a time machine

00:20:28,309 --> 00:20:32,960
although that would be very cool what it

00:20:30,380 --> 00:20:35,720
means is using things such as saga

00:20:32,960 --> 00:20:39,140
pattern finite state machines and symbol

00:20:35,720 --> 00:20:40,130
use actors to avoid linear processing so

00:20:39,140 --> 00:20:42,169
in other words when you find yourself

00:20:40,130 --> 00:20:43,880
writing code that is a series of steps

00:20:42,169 --> 00:20:45,410
in the traditional iterative fashion

00:20:43,880 --> 00:20:47,809
even if you're doing in a highly

00:20:45,410 --> 00:20:49,970
functional functional way think about

00:20:47,809 --> 00:20:51,740
the fact that it's possible some of

00:20:49,970 --> 00:20:54,169
those steps possibly intermediate steps

00:20:51,740 --> 00:20:55,910
don't need to be done sequentially so

00:20:54,169 --> 00:20:58,580
that sequence perhaps could be broken up

00:20:55,910 --> 00:20:59,840
why am i insisting that it be executed

00:20:58,580 --> 00:21:01,669
sequentially because when you write code

00:20:59,840 --> 00:21:03,710
line line line line like that without

00:21:01,669 --> 00:21:05,150
taking any other steps you're saying I'm

00:21:03,710 --> 00:21:07,070
insisting that these steps be done

00:21:05,150 --> 00:21:07,760
sequentially you're imposing that

00:21:07,070 --> 00:21:10,160
requirement

00:21:07,760 --> 00:21:13,010
good idea perhaps not in your system it

00:21:10,160 --> 00:21:14,570
may not be required so communications

00:21:13,010 --> 00:21:15,860
and this is I realize preach it a little

00:21:14,570 --> 00:21:18,169
bit to the choir communications

00:21:15,860 --> 00:21:20,750
especially between services must be

00:21:18,169 --> 00:21:22,760
asynchronous and non-blocking so

00:21:20,750 --> 00:21:26,750
fire-and-forget is a far more scalable

00:21:22,760 --> 00:21:29,600
pattern than ask for instance yes it

00:21:26,750 --> 00:21:31,429
means design changes though so this is

00:21:29,600 --> 00:21:32,179
one of the fundamental principles of

00:21:31,429 --> 00:21:34,910
scalability

00:21:32,179 --> 00:21:36,590
you can't retrofit it you can't say

00:21:34,910 --> 00:21:38,679
right we've written the system it works

00:21:36,590 --> 00:21:41,660
beautifully now let's make it scale

00:21:38,679 --> 00:21:43,940
that's a little late it's not if you

00:21:41,660 --> 00:21:45,130
don't mind rewriting or redesigning at

00:21:43,940 --> 00:21:48,220
the very least

00:21:45,130 --> 00:21:50,530
but if you start with design principles

00:21:48,220 --> 00:21:52,390
that would not fall into any of the

00:21:50,530 --> 00:21:54,670
pitfalls that we've been talking about

00:21:52,390 --> 00:21:58,150
then you will be less likely to find

00:21:54,670 --> 00:21:59,650
yourself failing because of success so

00:21:58,150 --> 00:22:01,540
in other words success comes for your

00:21:59,650 --> 00:22:03,940
organization in your application tons

00:22:01,540 --> 00:22:06,010
and tons of users come whoops now we

00:22:03,940 --> 00:22:07,420
discover a scalability is a problem yeah

00:22:06,010 --> 00:22:09,280
okay Val ittle bit back to the drawing

00:22:07,420 --> 00:22:12,190
board very very difficult to bought it

00:22:09,280 --> 00:22:13,870
bolted on after the case typically as we

00:22:12,190 --> 00:22:15,160
said before you may need in fact a

00:22:13,870 --> 00:22:17,710
totally different algorithm even to

00:22:15,160 --> 00:22:19,420
handle some minor things so building

00:22:17,710 --> 00:22:20,650
services designed to adhere to these

00:22:19,420 --> 00:22:22,630
principles and these principles are

00:22:20,650 --> 00:22:24,100
mostly things to avoid as we saw there

00:22:22,630 --> 00:22:27,520
not so much things to do there things to

00:22:24,100 --> 00:22:29,800
not do and tuning can't fix a bad design

00:22:27,520 --> 00:22:31,780
they can fix that tuning that's all

00:22:29,800 --> 00:22:34,870
tuning could do for you is get the most

00:22:31,780 --> 00:22:36,130
out of the design that you have which

00:22:34,870 --> 00:22:39,160
when you say it quickly sounds pretty

00:22:36,130 --> 00:22:40,750
obvious a lot of scalability is so

00:22:39,160 --> 00:22:42,700
what's the scalable architecture looked

00:22:40,750 --> 00:22:44,710
like as opposed to necessarily at the

00:22:42,700 --> 00:22:46,810
micro level a scalable design what is a

00:22:44,710 --> 00:22:48,250
scalable architecture well obviously the

00:22:46,810 --> 00:22:49,780
reactive architecture we believe is

00:22:48,250 --> 00:22:52,090
highly scalable and it has

00:22:49,780 --> 00:22:54,400
characteristics such as no single points

00:22:52,090 --> 00:22:55,810
of contention so there's no single

00:22:54,400 --> 00:22:57,820
database everybody's talking to for

00:22:55,810 --> 00:23:00,130
instance no point on the on the network

00:22:57,820 --> 00:23:02,740
that is a single instance nothing shared

00:23:00,130 --> 00:23:04,930
so as little shared as possible is maybe

00:23:02,740 --> 00:23:06,730
the the practical way to say that no

00:23:04,930 --> 00:23:08,040
state would be ideal that would be a

00:23:06,730 --> 00:23:10,360
perfectly scalable architecture

00:23:08,040 --> 00:23:12,340
definitely no sequence this is a big one

00:23:10,360 --> 00:23:13,780
in terms of actual stuff we've seen out

00:23:12,340 --> 00:23:15,550
on the client sites in the trenches

00:23:13,780 --> 00:23:18,310
that's it's surprising how expensive

00:23:15,550 --> 00:23:19,570
that is and no synchronous persistence

00:23:18,310 --> 00:23:22,240
I'll talk another few words about

00:23:19,570 --> 00:23:23,920
persistence in a few minutes something

00:23:22,240 --> 00:23:27,430
that's often forgotten about scalability

00:23:23,920 --> 00:23:30,010
though is that it goes both ways you

00:23:27,430 --> 00:23:32,410
have to be able to scale down and up not

00:23:30,010 --> 00:23:34,450
just up so scaling up whether it's

00:23:32,410 --> 00:23:35,650
horizontal or vertical is all very well

00:23:34,450 --> 00:23:38,200
and good but what happens when the load

00:23:35,650 --> 00:23:39,520
decreases we discover that users don't

00:23:38,200 --> 00:23:41,830
come flocking to our new system that

00:23:39,520 --> 00:23:44,320
we've got 50 nodes configured for

00:23:41,830 --> 00:23:45,580
elasticity is actually a very important

00:23:44,320 --> 00:23:47,110
attribute of a system some of our

00:23:45,580 --> 00:23:49,030
clients in fact have systems where

00:23:47,110 --> 00:23:50,800
elasticity is one of its most critical

00:23:49,030 --> 00:23:52,570
features because they have incredibly

00:23:50,800 --> 00:23:54,160
spiky load so they have an enormous

00:23:52,570 --> 00:23:55,300
number of users coming in a very short

00:23:54,160 --> 00:23:58,460
period of time

00:23:55,300 --> 00:24:00,890
so we have to be able to scale down as

00:23:58,460 --> 00:24:02,780
well as scaling up well again talk a

00:24:00,890 --> 00:24:03,340
little bit more about that in a few

00:24:02,780 --> 00:24:05,450
minutes

00:24:03,340 --> 00:24:06,860
so at the episode we talked about

00:24:05,450 --> 00:24:09,020
scaling down we need to be able to run

00:24:06,860 --> 00:24:10,370
things for example in our local laptops

00:24:09,020 --> 00:24:11,630
and determine whether it is scalable

00:24:10,370 --> 00:24:13,040
before we're even going to deploy them

00:24:11,630 --> 00:24:14,570
into a cluster let's talk about the

00:24:13,040 --> 00:24:16,070
other end of the spectrum what are some

00:24:14,570 --> 00:24:18,560
of the characteristics of highly

00:24:16,070 --> 00:24:20,600
scalable ultra large scale systems so

00:24:18,560 --> 00:24:21,980
very very large systems with thousands

00:24:20,600 --> 00:24:23,090
of nodes that we've encountered a few

00:24:21,980 --> 00:24:25,700
times

00:24:23,090 --> 00:24:28,250
they tend to be systems of systems so

00:24:25,700 --> 00:24:30,730
they tend to have independent components

00:24:28,250 --> 00:24:33,500
that are larger than a single system

00:24:30,730 --> 00:24:35,360
cooperating so there's communication

00:24:33,500 --> 00:24:37,280
happening across all series of systems

00:24:35,360 --> 00:24:39,410
they share a lot of the characteristics

00:24:37,280 --> 00:24:41,750
of organic eco systems that is there are

00:24:39,410 --> 00:24:44,180
things like duplication wasted pieces

00:24:41,750 --> 00:24:46,310
but they also share some of the positive

00:24:44,180 --> 00:24:47,810
characteristics which is pieces can fail

00:24:46,310 --> 00:24:49,580
and die and even beery completely

00:24:47,810 --> 00:24:51,890
replaced the organism as a whole

00:24:49,580 --> 00:24:54,320
eg the whole system keeps going so

00:24:51,890 --> 00:24:55,970
entire subsystems are replaced on ultra

00:24:54,320 --> 00:24:58,430
large-scale systems without necessarily

00:24:55,970 --> 00:25:00,860
affecting overall operation features

00:24:58,430 --> 00:25:02,450
evolve continuously while the systems in

00:25:00,860 --> 00:25:03,830
operation so these are some of the

00:25:02,450 --> 00:25:05,900
characteristics that would be nice to

00:25:03,830 --> 00:25:08,090
think about in your design such that if

00:25:05,900 --> 00:25:09,470
you ever say hey this is really working

00:25:08,090 --> 00:25:11,300
and we're going to become an ultra

00:25:09,470 --> 00:25:13,010
large-scale system there's no more back

00:25:11,300 --> 00:25:15,470
to the drawing board your design is in

00:25:13,010 --> 00:25:17,330
fact tolerant of extreme scale so the

00:25:15,470 --> 00:25:19,460
ability to evolve adding new features

00:25:17,330 --> 00:25:20,720
all the time to pieces that weren't even

00:25:19,460 --> 00:25:23,570
thought of in the original design

00:25:20,720 --> 00:25:26,330
doesn't necessarily bring the system to

00:25:23,570 --> 00:25:27,320
its knees often ultra large-scale

00:25:26,330 --> 00:25:29,450
systems are internally inconsistent

00:25:27,320 --> 00:25:30,680
again much like organisms there are

00:25:29,450 --> 00:25:32,060
things actually fighting with each other

00:25:30,680 --> 00:25:33,890
to different ways of doing something

00:25:32,060 --> 00:25:35,870
that's ok if your system could be

00:25:33,890 --> 00:25:39,980
tolerant of that you can deal with scale

00:25:35,870 --> 00:25:41,840
much more easily the users effect the

00:25:39,980 --> 00:25:43,760
overall emergent behavior so in other

00:25:41,840 --> 00:25:46,760
words you cannot actually directly

00:25:43,760 --> 00:25:49,370
predict under user load this system will

00:25:46,760 --> 00:25:51,170
look like this it doesn't work at large

00:25:49,370 --> 00:25:53,330
scale you don't know you must measure

00:25:51,170 --> 00:25:55,400
and even when you measure and you

00:25:53,330 --> 00:25:56,660
simulate load tests are a great thing

00:25:55,400 --> 00:25:59,030
they very much encourage them however

00:25:56,660 --> 00:26:00,740
they're not enough you also need to

00:25:59,030 --> 00:26:02,690
monitor to see what will the system

00:26:00,740 --> 00:26:05,420
actually do when we put it out there and

00:26:02,690 --> 00:26:07,070
again adhering to principles is easier

00:26:05,420 --> 00:26:08,360
than trying to predict behavior you

00:26:07,070 --> 00:26:10,040
don't know how many users are gonna law

00:26:08,360 --> 00:26:11,270
you know once it's you know that's a

00:26:10,040 --> 00:26:12,890
very very simple example but the

00:26:11,270 --> 00:26:15,260
characteristics of the system under load

00:26:12,890 --> 00:26:17,330
are usually unknown until the system is

00:26:15,260 --> 00:26:19,100
under load and this is what's

00:26:17,330 --> 00:26:21,980
interesting I found is that in any given

00:26:19,100 --> 00:26:23,990
time some pieces of a ultra large scale

00:26:21,980 --> 00:26:25,910
system will be down that's normal so

00:26:23,990 --> 00:26:28,040
failure is not something you necessarily

00:26:25,910 --> 00:26:29,870
even recover from quickly there may be

00:26:28,040 --> 00:26:33,320
catastrophic failures of some subsystems

00:26:29,870 --> 00:26:34,940
but the overall system continues so one

00:26:33,320 --> 00:26:37,670
of the reasons for catastrophic failure

00:26:34,940 --> 00:26:39,410
of some subsystems is spike load and I

00:26:37,670 --> 00:26:41,720
mentioned that we've seen clients where

00:26:39,410 --> 00:26:43,400
spike load is the norm they have some

00:26:41,720 --> 00:26:45,470
scheduled event that happens every day

00:26:43,400 --> 00:26:47,450
at a certain period of time sometimes

00:26:45,470 --> 00:26:49,400
that's far easier to deal with because

00:26:47,450 --> 00:26:50,720
you know it's coming the spike load that

00:26:49,400 --> 00:26:52,490
you don't know is coming is of course

00:26:50,720 --> 00:26:54,679
much more difficult so we've dealt with

00:26:52,490 --> 00:26:56,870
some systems where they respond to

00:26:54,679 --> 00:26:58,460
emergencies and of course the spike load

00:26:56,870 --> 00:27:00,740
is naturally by its very nature

00:26:58,460 --> 00:27:02,059
completely unpredictable and that would

00:27:00,740 --> 00:27:03,620
be a really bad time to fail obviously

00:27:02,059 --> 00:27:05,090
you know if you happen to be the fire

00:27:03,620 --> 00:27:07,100
alarm under load would be a terrible

00:27:05,090 --> 00:27:08,320
time to actually go down so sometimes

00:27:07,100 --> 00:27:11,570
you get more users than you expect

00:27:08,320 --> 00:27:13,640
scalability means that you can add nodes

00:27:11,570 --> 00:27:15,230
but it doesn't solve this problem the

00:27:13,640 --> 00:27:18,679
angry mob with the burning torches is

00:27:15,230 --> 00:27:22,070
not solved by being scalable it's solved

00:27:18,679 --> 00:27:24,169
by being elastic and being responsive to

00:27:22,070 --> 00:27:26,480
that elasticity so in other words as

00:27:24,169 --> 00:27:28,549
load increases if your system is

00:27:26,480 --> 00:27:30,230
predictive enough to say ah load is

00:27:28,549 --> 00:27:31,760
increasing at the following rate great

00:27:30,230 --> 00:27:33,559
I'm going to get ahead of it and spin up

00:27:31,760 --> 00:27:35,210
five more servers I only need one to

00:27:33,559 --> 00:27:37,580
handle this load but I'm gonna spend up

00:27:35,210 --> 00:27:39,230
five because then the lag time doesn't

00:27:37,580 --> 00:27:41,270
kill you because that's the problem with

00:27:39,230 --> 00:27:42,799
an elastic system an elastic system is

00:27:41,270 --> 00:27:45,530
not likely to be able to respond fast

00:27:42,799 --> 00:27:47,059
enough to additional load so if you

00:27:45,530 --> 00:27:49,250
don't know the load is coming you have

00:27:47,059 --> 00:27:50,990
two choices either rent lots of servers

00:27:49,250 --> 00:27:52,880
and have them all sitting there idle or

00:27:50,990 --> 00:27:55,520
have the ability to predictively

00:27:52,880 --> 00:27:57,260
increase capacity in response to

00:27:55,520 --> 00:27:58,040
increasing load before the load is

00:27:57,260 --> 00:28:00,590
actually spiked

00:27:58,040 --> 00:28:03,350
very tricky but it's a characteristic of

00:28:00,590 --> 00:28:04,910
highly scalable systems another very

00:28:03,350 --> 00:28:06,169
common characteristic that we see and

00:28:04,910 --> 00:28:08,150
now we're getting a little bit into the

00:28:06,169 --> 00:28:10,669
weeds of how do we avoid some of those

00:28:08,150 --> 00:28:12,230
enemies of scalability but another

00:28:10,669 --> 00:28:13,700
common one we've seen is something

00:28:12,230 --> 00:28:15,950
called command sourcing so to

00:28:13,700 --> 00:28:18,320
differentiate in a message driven system

00:28:15,950 --> 00:28:20,840
I'm saying that a command is a request

00:28:18,320 --> 00:28:21,380
for something that could fail so you

00:28:20,840 --> 00:28:23,600
know

00:28:21,380 --> 00:28:25,160
thing well I may not do something there

00:28:23,600 --> 00:28:27,350
may be a failure in the system you maybe

00:28:25,160 --> 00:28:29,570
give me an invalid request so something

00:28:27,350 --> 00:28:31,490
that has is not happening in the past

00:28:29,570 --> 00:28:33,800
it's happening right now where as an

00:28:31,490 --> 00:28:35,600
event so events are seen being very

00:28:33,800 --> 00:28:37,640
different an event is something that has

00:28:35,600 --> 00:28:38,090
already happened I can choose to ignore

00:28:37,640 --> 00:28:39,920
it

00:28:38,090 --> 00:28:41,780
but it can't fail it's we're talking

00:28:39,920 --> 00:28:46,460
about the past so it's outside my light

00:28:41,780 --> 00:28:48,410
gum and if we persist commands in coming

00:28:46,460 --> 00:28:50,570
to our system and then handle them

00:28:48,410 --> 00:28:54,500
asynchronously we have the ability to

00:28:50,570 --> 00:28:56,090
handle spikes much more adaptively so

00:28:54,500 --> 00:28:57,620
this is a very common pattern that we

00:28:56,090 --> 00:29:00,140
see to solve that and we often see the

00:28:57,620 --> 00:29:02,180
tool Kafka in this role where commands

00:29:00,140 --> 00:29:04,070
are entering a system immediately being

00:29:02,180 --> 00:29:05,030
queued and persisted so we can't lose

00:29:04,070 --> 00:29:06,560
the command we can immediately

00:29:05,030 --> 00:29:09,020
acknowledge this is the client yep got

00:29:06,560 --> 00:29:10,850
it thank you and then process the

00:29:09,020 --> 00:29:12,590
command asynchronously we know that it

00:29:10,850 --> 00:29:15,350
will eventually be processed there's

00:29:12,590 --> 00:29:17,300
that eventually word again this is also

00:29:15,350 --> 00:29:20,060
very similar to the idea of being able

00:29:17,300 --> 00:29:21,320
to degrade gracefully now though I love

00:29:20,060 --> 00:29:23,180
this quote which is actually a comedian

00:29:21,320 --> 00:29:24,440
not a computer scientist who said it an

00:29:23,180 --> 00:29:25,280
escalator can never break it only

00:29:24,440 --> 00:29:26,780
becomes stairs

00:29:25,280 --> 00:29:29,630
so in other words if you have the

00:29:26,780 --> 00:29:31,550
ability to reduce your capacity but the

00:29:29,630 --> 00:29:33,140
system is still operational that's far

00:29:31,550 --> 00:29:35,360
better than if identical later broke by

00:29:33,140 --> 00:29:36,080
you know falling down I would that would

00:29:35,360 --> 00:29:38,210
be unpleasant

00:29:36,080 --> 00:29:40,160
same thing with systems design so

00:29:38,210 --> 00:29:42,470
portions of a system should be able to

00:29:40,160 --> 00:29:45,500
fail without affecting other portions in

00:29:42,470 --> 00:29:46,840
fact not this is related to the circuit

00:29:45,500 --> 00:29:49,460
breaker pattern that we often hear

00:29:46,840 --> 00:29:51,560
talked about in the sense that portions

00:29:49,460 --> 00:29:53,390
of a system that have failed should in

00:29:51,560 --> 00:29:55,100
fact potentially be isolated from other

00:29:53,390 --> 00:29:56,930
portions of the system so they don't

00:29:55,100 --> 00:29:58,910
create a continual bottleneck so for

00:29:56,930 --> 00:30:00,260
example if talking to that external

00:29:58,910 --> 00:30:01,400
services all of a sudden getting really

00:30:00,260 --> 00:30:03,620
slow maybe we shouldn't talk to that

00:30:01,400 --> 00:30:06,680
external service for a few milliseconds

00:30:03,620 --> 00:30:08,090
while it gets its act together this is

00:30:06,680 --> 00:30:09,800
sometimes really hard because sometimes

00:30:08,090 --> 00:30:11,870
it's really hard to predict it but again

00:30:09,800 --> 00:30:13,360
it's a design issue not a tuning issue

00:30:11,870 --> 00:30:17,540
you can't tune in graceful degradation

00:30:13,360 --> 00:30:20,360
after the fact no I did not

00:30:17,540 --> 00:30:22,040
so micro-services you've probably again

00:30:20,360 --> 00:30:22,910
heard this word once or twice in the

00:30:22,040 --> 00:30:25,130
last few days

00:30:22,910 --> 00:30:27,770
what do micro services have to do with

00:30:25,130 --> 00:30:29,780
scalability a lot they come with a cost

00:30:27,770 --> 00:30:32,300
however we won't deny that micro

00:30:29,780 --> 00:30:34,700
services are add complexity and

00:30:32,300 --> 00:30:35,250
sophistication to a system they're worth

00:30:34,700 --> 00:30:38,400
it

00:30:35,250 --> 00:30:40,530
if they provide a sync communication

00:30:38,400 --> 00:30:42,330
with other services or otherwise we've

00:30:40,530 --> 00:30:44,420
just created a monolith in pieces so

00:30:42,330 --> 00:30:47,310
we've created a model if it's sliced up

00:30:44,420 --> 00:30:49,260
isolation eg failure doesn't bring down

00:30:47,310 --> 00:30:51,690
the ability to handle all load

00:30:49,260 --> 00:30:53,900
immediately otherwise again we've just

00:30:51,690 --> 00:30:57,390
created a model if that's been broken

00:30:53,900 --> 00:30:59,070
and a single responsibility this is

00:30:57,390 --> 00:31:00,690
important from a scalability four point

00:30:59,070 --> 00:31:02,900
of view because then functions can be

00:31:00,690 --> 00:31:06,030
tuned independently so for example if

00:31:02,900 --> 00:31:08,520
let's say we have a shopping cart

00:31:06,030 --> 00:31:09,900
component of our system and the service

00:31:08,520 --> 00:31:11,490
that receives new elements into the

00:31:09,900 --> 00:31:13,020
shopping cart it's the thing that is the

00:31:11,490 --> 00:31:15,090
bottleneck on our system great spin up

00:31:13,020 --> 00:31:17,040
lots of instances of that service not

00:31:15,090 --> 00:31:19,020
lost of instances of all services just

00:31:17,040 --> 00:31:20,400
that one that's possible if you've

00:31:19,020 --> 00:31:22,080
broken up services into single

00:31:20,400 --> 00:31:23,970
responsibility it isn't if you haven't

00:31:22,080 --> 00:31:26,310
which is one of the problems with

00:31:23,970 --> 00:31:27,620
monoliths so this and this is a key one

00:31:26,310 --> 00:31:30,180
I'll go into this a little more detail

00:31:27,620 --> 00:31:31,710
your micro services having their own

00:31:30,180 --> 00:31:34,380
data which is not shared with other

00:31:31,710 --> 00:31:36,450
services is key to sum to scalability

00:31:34,380 --> 00:31:37,470
and I've got a whole slide about the Hat

00:31:36,450 --> 00:31:40,980
in a couple of minutes that we'll look

00:31:37,470 --> 00:31:42,480
at also very much related to the idea of

00:31:40,980 --> 00:31:44,640
micro services and again a design

00:31:42,480 --> 00:31:46,560
principle is that if your systems

00:31:44,640 --> 00:31:47,910
diagram starts to look like this you are

00:31:46,560 --> 00:31:50,760
going to have a very hard time scaling

00:31:47,910 --> 00:31:52,560
that's mmm this is not a happy systems

00:31:50,760 --> 00:31:55,950
diagram this is a Rube Goldberg machine

00:31:52,560 --> 00:31:57,480
more complex is more opportunities for

00:31:55,950 --> 00:31:59,790
the enemies of scalability women talking

00:31:57,480 --> 00:32:01,350
about so basically if you're taking the

00:31:59,790 --> 00:32:03,300
approach that my design is going to

00:32:01,350 --> 00:32:06,060
follow these principles there are more

00:32:03,300 --> 00:32:07,590
places in a complex design for that to

00:32:06,060 --> 00:32:09,690
screw up than there are in a simple

00:32:07,590 --> 00:32:11,250
design so simple actually skills better

00:32:09,690 --> 00:32:13,170
than complicated it sounds easy when you

00:32:11,250 --> 00:32:14,580
say it that way all things being equal

00:32:13,170 --> 00:32:17,640
easy is better than hard of course

00:32:14,580 --> 00:32:19,830
simple patterns consistently applied boy

00:32:17,640 --> 00:32:23,130
those are two critical sentences that

00:32:19,830 --> 00:32:24,570
are often not quite the case as I'm sure

00:32:23,130 --> 00:32:26,430
you've seen in many systems you'll end

00:32:24,570 --> 00:32:27,480
up with some simple patterns and then

00:32:26,430 --> 00:32:29,490
they haven't been consistently applied

00:32:27,480 --> 00:32:30,930
across all of your services because this

00:32:29,490 --> 00:32:33,240
one's a special snowflake and we have to

00:32:30,930 --> 00:32:35,930
do it a different way try to avoid that

00:32:33,240 --> 00:32:38,340
it's far better to keep that consistency

00:32:35,930 --> 00:32:41,940
no global now so this is again related

00:32:38,340 --> 00:32:43,410
to sequence and related to timing a man

00:32:41,940 --> 00:32:45,090
with two watches never knows what time

00:32:43,410 --> 00:32:46,980
it is one of my favorite favorite quotes

00:32:45,090 --> 00:32:49,130
and the essence is that he can never be

00:32:46,980 --> 00:32:50,690
sure because there are two different

00:32:49,130 --> 00:32:52,309
while the distributed system never knows

00:32:50,690 --> 00:32:53,419
what time it is either no matter how

00:32:52,309 --> 00:32:55,840
many times you synchronize your clocks

00:32:53,419 --> 00:32:58,399
that's a really hard problem

00:32:55,840 --> 00:33:00,260
causal ordering not casual causal

00:32:58,399 --> 00:33:02,840
ordering I type out that several times

00:33:00,260 --> 00:33:05,090
when I was diving is better than clock

00:33:02,840 --> 00:33:06,919
time ordering but not caring about order

00:33:05,090 --> 00:33:09,289
at all and being completely commutative

00:33:06,919 --> 00:33:12,169
is better still so if there is something

00:33:09,289 --> 00:33:14,390
which is necessary to be ordered far

00:33:12,169 --> 00:33:16,580
better to say it do link list style

00:33:14,390 --> 00:33:19,730
where I can point to the one that came

00:33:16,580 --> 00:33:21,770
before me not necessarily in time just

00:33:19,730 --> 00:33:23,750
here's my parent or is the ID of my

00:33:21,770 --> 00:33:25,730
parent that's causal ordering and it's

00:33:23,750 --> 00:33:27,049
far superior to actually sticking a time

00:33:25,730 --> 00:33:28,640
stamp on something and hoping that you

00:33:27,049 --> 00:33:31,809
can order it after the fact that almost

00:33:28,640 --> 00:33:34,279
never works and I highly scalable system

00:33:31,809 --> 00:33:37,070
persistence very much again related to

00:33:34,279 --> 00:33:39,200
sequence not being entirely futile

00:33:37,070 --> 00:33:41,690
persistence doesn't necessarily have to

00:33:39,200 --> 00:33:43,340
be a bottleneck the most common problem

00:33:41,690 --> 00:33:45,080
we've seen in distributed systems that

00:33:43,340 --> 00:33:48,140
are trying to scale is actually that

00:33:45,080 --> 00:33:49,940
persistence is done too much there is

00:33:48,140 --> 00:33:53,960
too much persistence what I mean by that

00:33:49,940 --> 00:33:58,130
is that persistence is actually only

00:33:53,960 --> 00:33:59,870
required where you need to recover so

00:33:58,130 --> 00:34:01,370
for the sake of argument provided your

00:33:59,870 --> 00:34:02,690
system is idempotent and we can repeat

00:34:01,370 --> 00:34:04,640
events which is something I'll talk

00:34:02,690 --> 00:34:06,620
about in a minute it is entirely

00:34:04,640 --> 00:34:08,540
possible if I command source all of the

00:34:06,620 --> 00:34:12,830
incoming requests to my system therefore

00:34:08,540 --> 00:34:15,230
they can't be lost that I can press I

00:34:12,830 --> 00:34:16,790
can persist only at that point and the

00:34:15,230 --> 00:34:18,109
entire remainder of my operation

00:34:16,790 --> 00:34:19,849
requires no persistence I could do

00:34:18,109 --> 00:34:21,349
everything in memory because if for the

00:34:19,849 --> 00:34:23,300
sake of argument I were to lose that

00:34:21,349 --> 00:34:24,830
operation partway through the system

00:34:23,300 --> 00:34:26,359
while I command source I never went back

00:34:24,830 --> 00:34:29,060
and said yes I've dealt with that

00:34:26,359 --> 00:34:30,830
command so I just do it again therefore

00:34:29,060 --> 00:34:32,960
I don't actually require persistence at

00:34:30,830 --> 00:34:34,520
all of the other stages of my system now

00:34:32,960 --> 00:34:36,169
again there are millions subtleties to

00:34:34,520 --> 00:34:38,750
that statement but what it means is that

00:34:36,169 --> 00:34:40,040
it's entirely possible to save things a

00:34:38,750 --> 00:34:41,570
whole lot less often than you think you

00:34:40,040 --> 00:34:43,820
might need to and of course as we all

00:34:41,570 --> 00:34:46,190
know persisting anywhere is much more

00:34:43,820 --> 00:34:48,589
expensive than not persisting at all the

00:34:46,190 --> 00:34:49,879
key thing about persistence is to keep

00:34:48,589 --> 00:34:52,099
your hands out of what with all OPD

00:34:49,879 --> 00:34:54,649
other people's databases meaning from

00:34:52,099 --> 00:34:56,030
microservice point of view the worst

00:34:54,649 --> 00:34:57,950
thing to share in the world as a

00:34:56,030 --> 00:34:59,570
database or a persistent store of any

00:34:57,950 --> 00:35:00,349
kind I'm using database just as often

00:34:59,570 --> 00:35:01,950
that's what it is

00:35:00,349 --> 00:35:04,530
if your services

00:35:01,950 --> 00:35:06,570
database your database is your monolith

00:35:04,530 --> 00:35:07,800
that's not my quote somebody else came

00:35:06,570 --> 00:35:09,690
up with that originally but basically

00:35:07,800 --> 00:35:11,310
what you've said is you have lots of

00:35:09,690 --> 00:35:13,470
different api's through a big monolith

00:35:11,310 --> 00:35:15,270
and it's called your database right you

00:35:13,470 --> 00:35:16,980
have not in fact gotten most of the

00:35:15,270 --> 00:35:18,000
advantages of micro-services so

00:35:16,980 --> 00:35:20,400
therefore they'll look really expensive

00:35:18,000 --> 00:35:21,839
so services I should repeat myself again

00:35:20,400 --> 00:35:23,970
services must keep their midst out of

00:35:21,839 --> 00:35:25,290
other people's databases CR DT is an

00:35:23,970 --> 00:35:26,579
event sourcing are ways to share that

00:35:25,290 --> 00:35:28,589
are far safer than reaching into

00:35:26,579 --> 00:35:30,180
somebody else's database distributed

00:35:28,589 --> 00:35:32,220
transactions I'll simply say that the

00:35:30,180 --> 00:35:34,290
picture says it all the multi-tentacled

00:35:32,220 --> 00:35:36,420
monster that they are actually an

00:35:34,290 --> 00:35:37,800
anti-pattern so distributed transactions

00:35:36,420 --> 00:35:39,300
are not the answer we thought there were

00:35:37,800 --> 00:35:41,490
25 years ago

00:35:39,300 --> 00:35:44,760
they're an answer all right provided you

00:35:41,490 --> 00:35:46,530
want to have the world stop and halt the

00:35:44,760 --> 00:35:48,510
scalability of your system while you do

00:35:46,530 --> 00:35:50,190
something across multiple nodes so if

00:35:48,510 --> 00:35:51,869
you find yourself looking for a way to

00:35:50,190 --> 00:35:53,640
do distributed transactions in your

00:35:51,869 --> 00:35:55,770
micro services you have a design problem

00:35:53,640 --> 00:35:59,609
not a lack of distributed transactions

00:35:55,770 --> 00:36:01,650
problem so allow me to repeat myself I

00:35:59,609 --> 00:36:04,800
do this quite a bit because I'm item

00:36:01,650 --> 00:36:07,770
potent idempotency avoids the need for

00:36:04,800 --> 00:36:09,510
sequence to some degree so for example

00:36:07,770 --> 00:36:10,770
if it's OK to do something again well

00:36:09,510 --> 00:36:12,500
then it doesn't necessarily matter what

00:36:10,770 --> 00:36:14,520
order I get them in I can simply

00:36:12,500 --> 00:36:17,670
reprocess some of the elements of my

00:36:14,520 --> 00:36:19,319
sequence it helps to allow events to be

00:36:17,670 --> 00:36:22,200
handled in any order it's not enough but

00:36:19,319 --> 00:36:24,359
it helps and it often avoids the need

00:36:22,200 --> 00:36:26,130
for persistence because as I said back

00:36:24,359 --> 00:36:27,930
in the command source in the example if

00:36:26,130 --> 00:36:30,329
halfway through that complex command

00:36:27,930 --> 00:36:32,339
everything went to pieces and it didn't

00:36:30,329 --> 00:36:33,630
get completed if it is possible for me

00:36:32,339 --> 00:36:36,480
without damage to the system without

00:36:33,630 --> 00:36:37,920
inconsistency to simply reprocess then I

00:36:36,480 --> 00:36:40,079
don't need to persist partway through

00:36:37,920 --> 00:36:41,940
the steps because it's ok to simply

00:36:40,079 --> 00:36:43,980
start again now may not be performant to

00:36:41,940 --> 00:36:45,329
start again may not be efficient but it

00:36:43,980 --> 00:36:47,700
may actually be faster from a

00:36:45,329 --> 00:36:49,319
scalability poor it may be more scalable

00:36:47,700 --> 00:36:50,819
sorry faster is not the same thing as

00:36:49,319 --> 00:36:52,980
more skill may be more scalable from

00:36:50,819 --> 00:36:56,369
that perspective so when I can recover

00:36:52,980 --> 00:36:57,750
from the original command DDD and

00:36:56,369 --> 00:36:59,750
scalability I want to mention this very

00:36:57,750 --> 00:37:02,940
briefly dd meaning domain driven design

00:36:59,750 --> 00:37:05,160
consistency helps consistency of design

00:37:02,940 --> 00:37:06,750
is critical in a large-scale system

00:37:05,160 --> 00:37:09,240
because a large-scale system doesn't

00:37:06,750 --> 00:37:10,770
always mean under a great deal of load

00:37:09,240 --> 00:37:12,420
it may also mean a really big system

00:37:10,770 --> 00:37:13,380
that has a lot of elements a lot of

00:37:12,420 --> 00:37:14,480
different features a lot of

00:37:13,380 --> 00:37:16,310
functionality

00:37:14,480 --> 00:37:18,680
it's critical to come up with the

00:37:16,310 --> 00:37:20,060
patterns such as DDD onion architecture

00:37:18,680 --> 00:37:21,829
ports and adapters there's many

00:37:20,060 --> 00:37:24,290
different patterns all related that

00:37:21,829 --> 00:37:26,750
allow you to build micro services with

00:37:24,290 --> 00:37:28,490
with consistency I can't even speak with

00:37:26,750 --> 00:37:30,410
consistency apparently there's also a

00:37:28,490 --> 00:37:32,119
concept called distributed domain driven

00:37:30,410 --> 00:37:33,829
design I'd invite you to google we don't

00:37:32,119 --> 00:37:35,180
have time to go into it in detail it can

00:37:33,829 --> 00:37:37,579
solve a lot of hard problems and

00:37:35,180 --> 00:37:40,010
scalability as well so what we're really

00:37:37,579 --> 00:37:41,690
saying is that by encapsulating what's

00:37:40,010 --> 00:37:44,119
called bounded context and the idea of

00:37:41,690 --> 00:37:46,400
DDD into a single service or micro

00:37:44,119 --> 00:37:48,589
service or right-size service as one

00:37:46,400 --> 00:37:51,020
would call it communication can be

00:37:48,589 --> 00:37:52,700
limited sharing can be eliminated and

00:37:51,020 --> 00:37:55,400
now we're starting to defeat some of

00:37:52,700 --> 00:37:57,579
those enemies of scalability now of

00:37:55,400 --> 00:37:59,599
course it's not all about scalability

00:37:57,579 --> 00:38:00,859
scalability is not the only concern of a

00:37:59,599 --> 00:38:01,849
system you've got other things that you

00:38:00,859 --> 00:38:02,810
have to worry about you have to worry

00:38:01,849 --> 00:38:04,369
about features you have to worry about

00:38:02,810 --> 00:38:05,480
how fast can I code it have to worry

00:38:04,369 --> 00:38:07,880
about keeping it simple you have to

00:38:05,480 --> 00:38:11,630
worry about the cost all of these things

00:38:07,880 --> 00:38:14,660
must balance of course but again if we

00:38:11,630 --> 00:38:16,609
avoid some of the pitfalls by simply not

00:38:14,660 --> 00:38:17,900
doing some things and keep the design

00:38:16,609 --> 00:38:19,880
principles in mind from the beginning

00:38:17,900 --> 00:38:21,650
will actually save ourselves a lot of

00:38:19,880 --> 00:38:24,319
time on refactoring and trying to tune a

00:38:21,650 --> 00:38:25,460
system that actually can't scale a key

00:38:24,319 --> 00:38:27,020
thing that I should mention about

00:38:25,460 --> 00:38:28,250
scalability is that it's all very well

00:38:27,020 --> 00:38:30,829
and good to design a highly scalable

00:38:28,250 --> 00:38:32,599
system you must verify it it's not

00:38:30,829 --> 00:38:34,460
possible to predict as I said the

00:38:32,599 --> 00:38:37,130
operation of a distributed system by

00:38:34,460 --> 00:38:39,470
definition it's non-deterministic things

00:38:37,130 --> 00:38:42,740
are happening in parallel so distributed

00:38:39,470 --> 00:38:44,089
in parallel systems need monitoring they

00:38:42,740 --> 00:38:45,500
need monitoring more than they need

00:38:44,089 --> 00:38:47,359
testing I think they need testing quite

00:38:45,500 --> 00:38:49,520
a bit as well however they also need

00:38:47,359 --> 00:38:50,839
monitoring that is the ability to see

00:38:49,520 --> 00:38:52,700
what's going on with the system at

00:38:50,839 --> 00:38:54,319
runtime in a deployed production

00:38:52,700 --> 00:38:55,640
environment it's not possible to

00:38:54,319 --> 00:38:58,280
simulate the operation of a highly

00:38:55,640 --> 00:39:00,200
complex distributed system the log is

00:38:58,280 --> 00:39:02,960
not enough the log is not monitoring so

00:39:00,200 --> 00:39:04,280
log aggregation VM node monitoring

00:39:02,960 --> 00:39:06,470
that's all fundamental you need that

00:39:04,280 --> 00:39:08,030
absolutely but it's not enough it will

00:39:06,470 --> 00:39:09,710
not allow you unless you can read log

00:39:08,030 --> 00:39:11,450
files a whole lot faster than I can turn

00:39:09,710 --> 00:39:13,579
them into graphs in your mind it's

00:39:11,450 --> 00:39:15,290
nowhere near enough to actually give you

00:39:13,579 --> 00:39:17,329
a picture of what's going on where the

00:39:15,290 --> 00:39:18,859
bottlenecks are what systems are failing

00:39:17,329 --> 00:39:20,569
which were the where the where the

00:39:18,859 --> 00:39:23,450
difficulties are you need to be able to

00:39:20,569 --> 00:39:25,160
monitor throughput response time the

00:39:23,450 --> 00:39:27,319
other problem of course again remember

00:39:25,160 --> 00:39:28,069
the balancing elephant is that if you

00:39:27,319 --> 00:39:29,690
monitor too

00:39:28,069 --> 00:39:31,640
much you slow your system down you can

00:39:29,690 --> 00:39:33,589
actually make a non scalable system by

00:39:31,640 --> 00:39:38,119
over monitoring it so monitoring itself

00:39:33,589 --> 00:39:40,249
is like communication it's a cost DevOps

00:39:38,119 --> 00:39:41,839
matters a lot particularly in

00:39:40,249 --> 00:39:43,400
distributed systems the developers of

00:39:41,839 --> 00:39:44,869
the system have to be a little more

00:39:43,400 --> 00:39:46,579
aware and a little closer to the network

00:39:44,869 --> 00:39:48,949
then perhaps we had to be back in the

00:39:46,579 --> 00:39:50,930
j2ee world being able to do something

00:39:48,949 --> 00:39:52,940
like for example a rolling upgrade is

00:39:50,930 --> 00:39:54,829
critical to the idea of maintaining load

00:39:52,940 --> 00:39:56,150
handling capacity because my load

00:39:54,829 --> 00:39:57,829
handling and therefore my overall

00:39:56,150 --> 00:39:59,869
scalability goes to zero if the way I

00:39:57,829 --> 00:40:01,369
upgrade is turn off all the lights put a

00:39:59,869 --> 00:40:01,880
new version out turn it back on and hope

00:40:01,369 --> 00:40:04,430
for the best

00:40:01,880 --> 00:40:05,959
mm-hmm not a great plan for scalability

00:40:04,430 --> 00:40:07,489
right because effectively my overall

00:40:05,959 --> 00:40:09,499
scalable he's gone to zero when I turned

00:40:07,489 --> 00:40:11,539
everything off so we have to be able to

00:40:09,499 --> 00:40:13,039
do rolling updates that introduces

00:40:11,539 --> 00:40:14,599
difficulties as you may have heard in

00:40:13,039 --> 00:40:15,799
other talks with things like event

00:40:14,599 --> 00:40:18,140
sourcing and so on these have to be

00:40:15,799 --> 00:40:20,239
thought about at design time being able

00:40:18,140 --> 00:40:22,459
to deploy any one micro service

00:40:20,239 --> 00:40:24,709
continually anywhere it's needed eg

00:40:22,459 --> 00:40:27,109
location independence is critical that's

00:40:24,709 --> 00:40:28,489
a fundamental that's a basic and it's

00:40:27,109 --> 00:40:30,259
not just the technology on the tools

00:40:28,489 --> 00:40:31,549
obviously it's great we're at a

00:40:30,259 --> 00:40:33,049
technical conference where learn about

00:40:31,549 --> 00:40:35,390
all these technologies and tools a

00:40:33,049 --> 00:40:37,099
culture within an organization has to

00:40:35,390 --> 00:40:38,900
support the idea that things are going

00:40:37,099 --> 00:40:40,609
to be broken up organizationally in

00:40:38,900 --> 00:40:43,309
order to make me writing micro services

00:40:40,609 --> 00:40:45,410
effective so often in this kind of

00:40:43,309 --> 00:40:46,549
DevOps space we see type satellite bands

00:40:45,410 --> 00:40:49,999
owned conductor

00:40:46,549 --> 00:40:51,559
meso CCOs dr. Jenkins those are all some

00:40:49,999 --> 00:40:54,140
of the tools that are used in this space

00:40:51,559 --> 00:40:55,699
it is almost always an area that is

00:40:54,140 --> 00:40:57,619
overlooked and neglected when we see

00:40:55,699 --> 00:40:58,910
large-scale systems everybody's like

00:40:57,619 --> 00:41:02,809
well we'll think about the DevOps at the

00:40:58,910 --> 00:41:05,359
end usually doesn't work that well okay

00:41:02,809 --> 00:41:07,549
almost out of time conclusion quick

00:41:05,359 --> 00:41:09,109
conclusion perfect scalability is

00:41:07,549 --> 00:41:11,449
perfectly achievable we have seen

00:41:09,109 --> 00:41:13,759
systems that respond in this fashion but

00:41:11,449 --> 00:41:15,559
not with every design so it is a design

00:41:13,759 --> 00:41:17,089
issue it's a design time problem it's

00:41:15,559 --> 00:41:18,829
not a technology problem it's not how

00:41:17,089 --> 00:41:21,259
you write your code per se it's how you

00:41:18,829 --> 00:41:23,479
build your architecture if you avoid the

00:41:21,259 --> 00:41:25,009
enemies of scalability in your design

00:41:23,479 --> 00:41:25,279
they'll probably do better than if you

00:41:25,009 --> 00:41:27,349
don't

00:41:25,279 --> 00:41:29,749
yes I guess the Summum sum up of this

00:41:27,349 --> 00:41:32,569
whole talk find those patterns of design

00:41:29,749 --> 00:41:34,459
that don't use these enemies monitor and

00:41:32,569 --> 00:41:35,930
adjust and embrace and handle failure

00:41:34,459 --> 00:41:39,469
pieces of your system are always going

00:41:35,930 --> 00:41:41,740
to be broken that's normal and that's it

00:41:39,469 --> 00:41:45,220
anybody any questions

00:41:41,740 --> 00:41:45,220
anyone looked like that

00:41:51,000 --> 00:41:55,180
they're like three minutes so we have a

00:41:53,200 --> 00:41:59,010
couple couple of spaces for questions

00:41:55,180 --> 00:42:00,670
no stun silence tomatoes anything please

00:41:59,010 --> 00:42:02,050
yeah he'll have to wait for the

00:42:00,670 --> 00:42:02,589
microphone I won't hear a thing from way

00:42:02,050 --> 00:42:07,150
back there

00:42:02,589 --> 00:42:09,460
I also barely can see you so is it like

00:42:07,150 --> 00:42:11,770
also like scalability I would say some

00:42:09,460 --> 00:42:14,130
business platform decision because of

00:42:11,770 --> 00:42:16,390
course you could write you know like a

00:42:14,130 --> 00:42:18,970
stateless web tier or something like a

00:42:16,390 --> 00:42:21,339
good database well if you run in your

00:42:18,970 --> 00:42:23,859
ten servers like no matter what you do

00:42:21,339 --> 00:42:25,750
how well you've read your software at

00:42:23,859 --> 00:42:27,790
some point you may be screwed but if you

00:42:25,750 --> 00:42:30,280
run in a cloud that you could like spin

00:42:27,790 --> 00:42:33,280
up a new instance is you get much more

00:42:30,280 --> 00:42:35,109
flexibility yes absolutely true small

00:42:33,280 --> 00:42:37,359
pieces distributed across the network

00:42:35,109 --> 00:42:39,130
are usually better no question so what

00:42:37,359 --> 00:42:40,480
do you recommend as a light band what

00:42:39,130 --> 00:42:42,730
kind of like platform would you

00:42:40,480 --> 00:42:44,410
recommend for like using to boot this

00:42:42,730 --> 00:42:46,630
kind of a cable system

00:42:44,410 --> 00:42:48,660
I would say like Binaca the light burn

00:42:46,630 --> 00:42:53,380
reactive platform will be a good start

00:42:48,660 --> 00:42:55,750
sorry prejudiced I work for them you

00:42:53,380 --> 00:42:58,869
mean platform in terms of cloud platform

00:42:55,750 --> 00:43:01,089
pass oh to be honest I don't think

00:42:58,869 --> 00:43:03,339
that's very important I think a lot of

00:43:01,089 --> 00:43:06,819
cloud providers have the excellent

00:43:03,339 --> 00:43:09,280
infrastructure that is horribly abused

00:43:06,819 --> 00:43:11,800
by terrible design most of the time so

00:43:09,280 --> 00:43:14,410
usually your platform provider will not

00:43:11,800 --> 00:43:15,910
be your problem it will be something in

00:43:14,410 --> 00:43:17,619
your design that is bottlenecking you

00:43:15,910 --> 00:43:19,599
far before your platform provider runs

00:43:17,619 --> 00:43:21,790
out of servers to sell you so it

00:43:19,599 --> 00:43:23,980
literally doesn't matter that much any

00:43:21,790 --> 00:43:25,180
of the big names that don't have

00:43:23,980 --> 00:43:28,390
horrible problems in their cloud

00:43:25,180 --> 00:43:30,160
platform are probably fine sorry I know

00:43:28,390 --> 00:43:31,750
that's a vague answer but I don't think

00:43:30,160 --> 00:43:35,200
it matters that anywhere near as much as

00:43:31,750 --> 00:43:38,790
architecture and design matter anybody

00:43:35,200 --> 00:43:38,790
else please

00:43:40,440 --> 00:43:45,820
sorry to make you wait thank you

00:43:43,210 --> 00:43:48,790
you have mentioned that it's a actually

00:43:45,820 --> 00:43:51,790
bad idea to run distributed actors

00:43:48,790 --> 00:43:53,590
across different data centers right not

00:43:51,790 --> 00:43:55,690
necessarily but to have a single Acker

00:43:53,590 --> 00:43:57,280
cluster span multiple data centers can

00:43:55,690 --> 00:43:59,080
be problematic yes okay could you a

00:43:57,280 --> 00:44:01,180
little bit explain why because well as

00:43:59,080 --> 00:44:02,890
far as I know the whole idea of the

00:44:01,180 --> 00:44:06,190
actor model is that it doesn't really

00:44:02,890 --> 00:44:08,290
matter what what is the response time

00:44:06,190 --> 00:44:10,630
between actors or that's true it is

00:44:08,290 --> 00:44:12,640
asynchronous it's from a scalability

00:44:10,630 --> 00:44:15,670
point of view you have to think about

00:44:12,640 --> 00:44:17,500
the design such that messages that are

00:44:15,670 --> 00:44:20,470
going to be transmitted between data

00:44:17,500 --> 00:44:21,640
centers eg between clusters is normally

00:44:20,470 --> 00:44:23,800
what we'd recommend so in other words

00:44:21,640 --> 00:44:25,630
spanning a single actor clusters spanned

00:44:23,800 --> 00:44:28,090
across multiple data centers not one

00:44:25,630 --> 00:44:30,610
rack not racks but like across the

00:44:28,090 --> 00:44:32,170
country means that the link between

00:44:30,610 --> 00:44:34,390
those two data centers is typically

00:44:32,170 --> 00:44:37,750
higher latency and lower throughput and

00:44:34,390 --> 00:44:39,460
slower than the link between two servers

00:44:37,750 --> 00:44:41,200
sitting in the same rack so what that

00:44:39,460 --> 00:44:43,330
means is that at some point you may need

00:44:41,200 --> 00:44:45,640
to adjust the tuning of the gossip

00:44:43,330 --> 00:44:47,260
protocol that keeps the cluster together

00:44:45,640 --> 00:44:49,030
and determines cluster membership in

00:44:47,260 --> 00:44:50,440
order to handle that lower latency which

00:44:49,030 --> 00:44:52,720
means you're handling it for everything

00:44:50,440 --> 00:44:54,670
so there's one problem the second one is

00:44:52,720 --> 00:44:57,790
that if you don't design your systems

00:44:54,670 --> 00:44:59,830
such that it is aware of messages again

00:44:57,790 --> 00:45:02,200
location independence is great in ACTA

00:44:59,830 --> 00:45:03,790
however if you know that some of your

00:45:02,200 --> 00:45:06,340
messages are going to be sent over a

00:45:03,790 --> 00:45:07,960
slow link relatively speaking compared

00:45:06,340 --> 00:45:09,940
to local messages that are sent over a

00:45:07,960 --> 00:45:12,040
high link you may want to have for

00:45:09,940 --> 00:45:15,190
example a circuit breaker actor around

00:45:12,040 --> 00:45:16,930
that that allows it to say my timeout is

00:45:15,190 --> 00:45:18,790
going to be a lot higher my retry

00:45:16,930 --> 00:45:20,080
threshold from my message is going to be

00:45:18,790 --> 00:45:21,940
a lot higher when I'm waiting for

00:45:20,080 --> 00:45:23,470
responses because I'm the guy that talks

00:45:21,940 --> 00:45:24,910
to the other data center what we

00:45:23,470 --> 00:45:26,560
typically find the pattern that works

00:45:24,910 --> 00:45:29,830
well getting a little bit into the weeds

00:45:26,560 --> 00:45:33,190
is a single active cluster in one data

00:45:29,830 --> 00:45:34,930
center and then a cluster client right

00:45:33,190 --> 00:45:36,850
for the other data center so that

00:45:34,930 --> 00:45:38,740
there's a narrow pipe so to speak that

00:45:36,850 --> 00:45:40,540
goes between data centers and there's a

00:45:38,740 --> 00:45:41,980
guardian actor that says okay my job is

00:45:40,540 --> 00:45:44,560
just to move messages that are actually

00:45:41,980 --> 00:45:46,720
destined for over there to over there

00:45:44,560 --> 00:45:48,910
but those messages if the volume of

00:45:46,720 --> 00:45:50,680
those messages is very high then you may

00:45:48,910 --> 00:45:51,470
need to tune your echo cluster to

00:45:50,680 --> 00:45:53,420
compensate

00:45:51,470 --> 00:45:56,299
that's the short answer okay sue thank

00:45:53,420 --> 00:45:57,770
you mm-hmm it's that is a tuning problem

00:45:56,299 --> 00:46:00,410
but it's also one that you can think

00:45:57,770 --> 00:46:02,539
about in design so we have had clusters

00:46:00,410 --> 00:46:04,490
that have extremely large numbers of

00:46:02,539 --> 00:46:07,010
members you know thousands and that has

00:46:04,490 --> 00:46:09,349
cropped up a couple of times anybody

00:46:07,010 --> 00:46:12,400
else we're just about out of time in any

00:46:09,349 --> 00:46:12,400

YouTube URL: https://www.youtube.com/watch?v=NFvf8b6SbGE


