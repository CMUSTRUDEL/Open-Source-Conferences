Title: Programming with Futures, Lattices and Quiescence by Philipp Haller
Publication date: 2017-01-19
Playlist: Scala Days 2016
Description: 
	This video was recorded at Scala Days Berlin 2016
follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Abstract:
Futures and promises in Scala are an integral part of asynchronous and concurrent code. Popular websites rely on futures for responsiveness in the presence of a large number of concurrent visitors. Furthermore, futures work well together with functional programming abstractions, thanks to the nature of future-based computations--single-assignment dataflow. However, futures also have important restrictions. For example, a future is completed with at most one result. Therefore, it is impossible to complete a future with a preliminary result and subsequently refine the result, for example, when more precise information becomes available. Finally, futures do not support resolving cyclic dependencies, instead resulting in deadlocks when such dependencies occur.
In this talk, I report on an extension of Scala's futures with lattices and quiescence, inspired by related features in Haskell's LVish package and the LVars programming model. In this extended model the state of a future is an element of a lattice. Importantly, multiple updates of its corresponding "promise" are possible where updates correspond to join operations of the lattice. In addition, resolution of cyclic dependencies is supported through a mechanism based on detecting quiescence of the underlying execution context. The programming model is currently being exploited in the context of OPAL, a new Scala-based, concurrent static analysis framework developed at Technische UniversitÃ¤t Darmstadt. In the last part of my talk I will report on experimental results (performance, code complexity) using lattice-based futures for several large-scale static analysis tasks (e.g., purity analysis, bug finding) with OPAL.
Captions: 
	00:00:03,010 --> 00:00:11,150
welcome to my talk I've seen this is a

00:00:07,310 --> 00:00:16,570
very long afternoon session so i hope

00:00:11,150 --> 00:00:19,100
everyone had another coffee before this

00:00:16,570 --> 00:00:22,220
so this is in the advanced track but

00:00:19,100 --> 00:00:26,359
it's it's not going to be that with that

00:00:22,220 --> 00:00:28,519
that of an advanced talk although one of

00:00:26,359 --> 00:00:31,609
the big things i want you to take from

00:00:28,519 --> 00:00:35,110
this talk is how to spell quiescence

00:00:31,609 --> 00:00:40,030
that's really that's really the key here

00:00:35,110 --> 00:00:44,510
so one thing of course you should do is

00:00:40,030 --> 00:00:47,780
rate this session and this is going to

00:00:44,510 --> 00:00:49,850
be tough because I'm directly in

00:00:47,780 --> 00:00:53,210
parallel there's Alex speaking so people

00:00:49,850 --> 00:00:57,199
will compare you know our two talks I'm

00:00:53,210 --> 00:00:58,969
sure ok so this talks about concurrent

00:00:57,199 --> 00:01:01,460
programming and the big question is well

00:00:58,969 --> 00:01:03,260
have resolved this problem yet like it's

00:01:01,460 --> 00:01:05,600
concurrent programming now super easy

00:01:03,260 --> 00:01:10,640
and everyone can do it and nobody makes

00:01:05,600 --> 00:01:15,290
any mistakes and so on well I don't know

00:01:10,640 --> 00:01:18,370
but you know there's there's a lot of

00:01:15,290 --> 00:01:23,030
promising programming models out there

00:01:18,370 --> 00:01:25,190
right and abstractions and for example

00:01:23,030 --> 00:01:30,710
monitors are great they were so great

00:01:25,190 --> 00:01:32,630
that son decided to bake it into Java we

00:01:30,710 --> 00:01:37,730
have futures and promises which are

00:01:32,630 --> 00:01:43,010
quite widely used obviously a sink and a

00:01:37,730 --> 00:01:45,380
weight is part of C sharp F sharp hack

00:01:43,010 --> 00:01:49,790
and we have it in skala as well to

00:01:45,380 --> 00:01:51,710
simplify programming with futures once

00:01:49,790 --> 00:01:54,620
upon a time software transactional

00:01:51,710 --> 00:01:58,400
memory was the best thing in the world

00:01:54,620 --> 00:02:03,380
it didn't turn out to be that big of a

00:01:58,400 --> 00:02:05,990
deal after after all actors of course

00:02:03,380 --> 00:02:08,270
have caught on quite a bit and if you've

00:02:05,990 --> 00:02:14,090
used a cow before you've also used

00:02:08,270 --> 00:02:16,490
actors I'm sure John calculus has

00:02:14,090 --> 00:02:21,290
inspired many programming models

00:02:16,490 --> 00:02:24,920
there are agents CSP which is actually

00:02:21,290 --> 00:02:27,560
quite old and has issues with

00:02:24,920 --> 00:02:30,560
distribution right and so on and we have

00:02:27,560 --> 00:02:32,030
reactive streams and you know we just

00:02:30,560 --> 00:02:36,140
keep on doing these things right we

00:02:32,030 --> 00:02:38,750
propose new things and the newest thing

00:02:36,140 --> 00:02:41,900
will always you know make everything so

00:02:38,750 --> 00:02:44,360
much better right and of course I'm also

00:02:41,900 --> 00:02:47,180
charged as guilty here because I've been

00:02:44,360 --> 00:02:53,380
working on different systems for for a

00:02:47,180 --> 00:02:57,800
long time and and you know and this is

00:02:53,380 --> 00:03:01,160
list on the left is not it's not enough

00:02:57,800 --> 00:03:04,580
I also have you know other more research

00:03:01,160 --> 00:03:07,520
projects and so on that many of which

00:03:04,580 --> 00:03:12,350
are related to concurrency for example

00:03:07,520 --> 00:03:15,290
flow pools is a pretty cool project we

00:03:12,350 --> 00:03:17,900
did also with Alex Paco pets and others

00:03:15,290 --> 00:03:20,330
at epfl on deterministic concurrency

00:03:17,900 --> 00:03:23,270
which is actually also the topic of this

00:03:20,330 --> 00:03:26,360
talk then sports is a bit more general

00:03:23,270 --> 00:03:30,080
which but also wants to make closer

00:03:26,360 --> 00:03:32,720
safer to use in a concurrent setting so

00:03:30,080 --> 00:03:34,610
now of course the question is well why

00:03:32,720 --> 00:03:38,600
are there so many concurrent programming

00:03:34,610 --> 00:03:42,110
models and well people basically have

00:03:38,600 --> 00:03:46,540
realized that it's a great way to sell

00:03:42,110 --> 00:03:46,540
consulting services all right and

00:03:49,700 --> 00:03:56,280
you know I I have some track record on

00:03:53,250 --> 00:03:58,290
this as well but well of course the

00:03:56,280 --> 00:04:02,940
truth is it's just very difficult issue

00:03:58,290 --> 00:04:05,060
right and because there's many things I

00:04:02,940 --> 00:04:09,660
can go wrong we can have race conditions

00:04:05,060 --> 00:04:12,750
deadlocks live locks we can violate

00:04:09,660 --> 00:04:18,989
fairness which can lead to issues and so

00:04:12,750 --> 00:04:20,610
on right and in fact there's a kind of

00:04:18,989 --> 00:04:23,670
even more fundamental issue which is

00:04:20,610 --> 00:04:25,020
just non determinism which means that in

00:04:23,670 --> 00:04:27,900
that's at the root of zero of the

00:04:25,020 --> 00:04:30,090
hazards so non determinism can be the

00:04:27,900 --> 00:04:32,310
cause of race condition it can be the

00:04:30,090 --> 00:04:33,540
cost of a deadlock if we acquire locks

00:04:32,310 --> 00:04:36,510
in different orders non

00:04:33,540 --> 00:04:39,960
deterministically right so it's actually

00:04:36,510 --> 00:04:42,810
a core issue and what is non determinism

00:04:39,960 --> 00:04:45,390
right and perhaps the most simple

00:04:42,810 --> 00:04:48,750
example is looks of it like this I try

00:04:45,390 --> 00:04:54,210
to be realistic so I have a volatile

00:04:48,750 --> 00:04:58,290
variable and well if we concurrently set

00:04:54,210 --> 00:05:00,990
this variable to some value then the

00:04:58,290 --> 00:05:04,890
question is what's the value when the

00:05:00,990 --> 00:05:09,570
method returns right and of course it

00:05:04,890 --> 00:05:13,020
could be two or one for example cannot

00:05:09,570 --> 00:05:16,080
be 0 but well and what's the value when

00:05:13,020 --> 00:05:20,640
the future is completed we don't know

00:05:16,080 --> 00:05:24,000
right and there can be many variations

00:05:20,640 --> 00:05:27,150
on this and in this case the value could

00:05:24,000 --> 00:05:33,870
also be 0 when the method returns so

00:05:27,150 --> 00:05:36,380
it's that's the simplest possible way

00:05:33,870 --> 00:05:40,590
and of course in in real code this is

00:05:36,380 --> 00:05:44,700
can be much more hidden right but of

00:05:40,590 --> 00:05:48,450
course this reordering of operations is

00:05:44,700 --> 00:05:52,710
not always an issue right for example

00:05:48,450 --> 00:05:54,510
let's say we have concurrent set so i'm

00:05:52,710 --> 00:05:57,930
using the try map here because it's a

00:05:54,510 --> 00:05:59,820
really awesome data structure by alex

00:05:57,930 --> 00:06:02,370
walker pets and

00:05:59,820 --> 00:06:05,940
I'm using it as a set so the keys here

00:06:02,370 --> 00:06:08,490
are the values in my set and of course I

00:06:05,940 --> 00:06:11,250
can now concurrently add things to my

00:06:08,490 --> 00:06:13,320
set and in this example well the nice

00:06:11,250 --> 00:06:15,480
thing is that at least it doesn't matter

00:06:13,320 --> 00:06:19,410
eventually there will always be both

00:06:15,480 --> 00:06:21,060
values 1 and 2 in the set so that's nice

00:06:19,410 --> 00:06:25,860
right I can fill up sets concurrently

00:06:21,060 --> 00:06:28,200
and that works out pretty well so it

00:06:25,860 --> 00:06:31,700
really depends on the data type that

00:06:28,200 --> 00:06:35,700
we're using but not only the data type

00:06:31,700 --> 00:06:38,550
but also the operations that were we're

00:06:35,700 --> 00:06:42,180
using so for example our nice try map

00:06:38,550 --> 00:06:46,290
here well we still run into issues if we

00:06:42,180 --> 00:06:48,510
mix put sand contains for example right

00:06:46,290 --> 00:06:51,660
so because in this case well we can

00:06:48,510 --> 00:06:54,060
currently put values into our set but

00:06:51,660 --> 00:06:58,590
then if you can currently check if the

00:06:54,060 --> 00:07:00,840
set contains one then this condition can

00:06:58,590 --> 00:07:04,320
non deterministically evaluate to true

00:07:00,840 --> 00:07:07,770
or false so that means we can't just mix

00:07:04,320 --> 00:07:09,750
operations arbitrarily right so even

00:07:07,770 --> 00:07:13,200
though we have a nice thread safe data

00:07:09,750 --> 00:07:16,740
structure and so on we still can't is

00:07:13,200 --> 00:07:19,920
still a non-deterministic program all

00:07:16,740 --> 00:07:22,530
right so now the you know some important

00:07:19,920 --> 00:07:25,830
questions I think are well how do we

00:07:22,530 --> 00:07:28,170
know that we've written a deterministic

00:07:25,830 --> 00:07:31,470
concurrent program that's that's a basic

00:07:28,170 --> 00:07:33,150
question right so in deterministic means

00:07:31,470 --> 00:07:34,950
well it's essentially a functional

00:07:33,150 --> 00:07:37,110
program if we give it the same inputs

00:07:34,950 --> 00:07:41,550
how can we know that we will get the

00:07:37,110 --> 00:07:43,230
same outputs right and well the thing is

00:07:41,550 --> 00:07:46,860
that there's always essentially a

00:07:43,230 --> 00:07:50,400
possibility for highs in box where you

00:07:46,860 --> 00:07:52,080
know there's no race in no data rise if

00:07:50,400 --> 00:07:55,170
you run this a million times but then

00:07:52,080 --> 00:07:57,350
maybe in the end run million and a one

00:07:55,170 --> 00:07:59,610
and one there's there's the data race

00:07:57,350 --> 00:08:03,750
right and of course these things are

00:07:59,610 --> 00:08:06,210
extremely tough to 2d back and even

00:08:03,750 --> 00:08:11,640
writing a good regression test can we

00:08:06,210 --> 00:08:13,470
can be tricky right so basically what we

00:08:11,640 --> 00:08:17,250
want is

00:08:13,470 --> 00:08:19,580
as more a simpler way to determine

00:08:17,250 --> 00:08:23,930
whether some code is actually

00:08:19,580 --> 00:08:23,930
deterministic some simple criteria

00:08:24,110 --> 00:08:32,360
another important question is well of

00:08:29,190 --> 00:08:35,130
course we can impose very strict rules

00:08:32,360 --> 00:08:37,229
on to our code that ensures

00:08:35,130 --> 00:08:39,840
deterministic right there's certainly

00:08:37,229 --> 00:08:41,940
certain patterns I showed you one which

00:08:39,840 --> 00:08:45,060
is I just create a concurrent set and I

00:08:41,940 --> 00:08:46,860
only allow additions to the set well

00:08:45,060 --> 00:08:48,630
that's going to be fine that's

00:08:46,860 --> 00:08:50,550
deterministic eventually the set will

00:08:48,630 --> 00:08:53,760
always contain the same values but

00:08:50,550 --> 00:08:57,540
that's a very restricted model right so

00:08:53,760 --> 00:08:59,790
we still need expressivity in in the

00:08:57,540 --> 00:09:02,690
programs that we can express and the

00:08:59,790 --> 00:09:05,850
while they stay deterministic right

00:09:02,690 --> 00:09:08,730
because while draconian restrictions are

00:09:05,850 --> 00:09:11,700
not really desired so that's the second

00:09:08,730 --> 00:09:15,450
goal is how can we reconcile determinism

00:09:11,700 --> 00:09:17,930
in expert civet e right and this is well

00:09:15,450 --> 00:09:24,480
that's the topic of ongoing research and

00:09:17,930 --> 00:09:30,480
I'm going to give you one one approach

00:09:24,480 --> 00:09:33,960
that is quite interesting for some real

00:09:30,480 --> 00:09:37,890
applications so let's look at our

00:09:33,960 --> 00:09:40,880
approach that we do here so what the

00:09:37,890 --> 00:09:47,550
story is about is essentially extending

00:09:40,880 --> 00:09:52,050
futures and promises with lattice based

00:09:47,550 --> 00:09:56,790
operations and well the reason is that

00:09:52,050 --> 00:10:00,270
if we have if the data is based on a

00:09:56,790 --> 00:10:03,180
lattice then we have guarantees like

00:10:00,270 --> 00:10:07,140
commutativity and associativity an

00:10:03,180 --> 00:10:10,920
idempotent which are useful to guarantee

00:10:07,140 --> 00:10:13,770
determinism the second thing is

00:10:10,920 --> 00:10:15,420
quiescence right and you're going to

00:10:13,770 --> 00:10:17,220
read this word over and over again in

00:10:15,420 --> 00:10:19,830
this talk so that you will get to know

00:10:17,220 --> 00:10:22,770
how to spell it right and but it's

00:10:19,830 --> 00:10:26,070
what's interesting about quiescence is I

00:10:22,770 --> 00:10:27,180
it turns out that this is also crucial

00:10:26,070 --> 00:10:29,550
for

00:10:27,180 --> 00:10:33,030
determinism this is actually very

00:10:29,550 --> 00:10:37,950
surprising and I hope my examples later

00:10:33,030 --> 00:10:40,080
will will show this also why quietens is

00:10:37,950 --> 00:10:42,180
important and and I found this very

00:10:40,080 --> 00:10:46,980
surprising because it's not a concept

00:10:42,180 --> 00:10:49,950
that we usually deal with right but I

00:10:46,980 --> 00:10:52,650
think in the future we will see more ap

00:10:49,950 --> 00:10:57,780
is that use the word questions in them

00:10:52,650 --> 00:11:00,150
so and the third thing is that we will

00:10:57,780 --> 00:11:03,270
we want to build concurrent programs

00:11:00,150 --> 00:11:06,740
where the data dependencies are not

00:11:03,270 --> 00:11:10,200
super simple where they can also be

00:11:06,740 --> 00:11:13,100
cyclic and that's also partially because

00:11:10,200 --> 00:11:18,480
of our application which is large-scale

00:11:13,100 --> 00:11:21,390
static analysis of code and there we

00:11:18,480 --> 00:11:24,870
actually have cyclic dependencies quite

00:11:21,390 --> 00:11:28,040
often so we were looking at ways to to

00:11:24,870 --> 00:11:31,080
support those with futures and promises

00:11:28,040 --> 00:11:32,880
that's not really possible right so this

00:11:31,080 --> 00:11:36,780
actually is an increase in expressive ed

00:11:32,880 --> 00:11:39,450
and of course the goal is to support

00:11:36,780 --> 00:11:43,260
this while also again still still have

00:11:39,450 --> 00:11:45,750
determinism okay and I'm also going to

00:11:43,260 --> 00:11:50,310
tell you a little bit about applying

00:11:45,750 --> 00:11:51,870
this this model too well like I said

00:11:50,310 --> 00:11:54,750
static analysis and here we're

00:11:51,870 --> 00:11:57,930
interested in the performance of course

00:11:54,750 --> 00:12:02,850
but also expressivity and and and all

00:11:57,930 --> 00:12:05,610
general the benefits of what we do ok so

00:12:02,850 --> 00:12:10,500
this model is called reactive a sink and

00:12:05,610 --> 00:12:13,080
this maybe sounds a bit funny but it is

00:12:10,500 --> 00:12:14,340
related to reactive programming or well

00:12:13,080 --> 00:12:16,920
also functional reactive programming

00:12:14,340 --> 00:12:18,270
although what we do is not it's not

00:12:16,920 --> 00:12:23,400
completely functional in the sense that

00:12:18,270 --> 00:12:27,000
you know we will do we will do updates

00:12:23,400 --> 00:12:29,820
off of data so it's not functional

00:12:27,000 --> 00:12:32,010
reactive in that sense right but it is

00:12:29,820 --> 00:12:35,400
asynchronous and it is reactive so

00:12:32,010 --> 00:12:39,660
that's why this is sort of the name for

00:12:35,400 --> 00:12:41,330
now but what we do is we use two core

00:12:39,660 --> 00:12:43,770
abstractions and

00:12:41,330 --> 00:12:46,920
analogous to futures and promises we

00:12:43,770 --> 00:12:50,090
have one abstraction called cells a cell

00:12:46,920 --> 00:12:53,400
which is similar to a future so it's a

00:12:50,090 --> 00:12:56,550
an interface to read a value that's

00:12:53,400 --> 00:12:59,490
asynchronously computed and the cell

00:12:56,550 --> 00:13:02,420
completer is like a promise it's a way

00:12:59,490 --> 00:13:06,210
to complete a cell with with a value and

00:13:02,420 --> 00:13:09,270
but these are right so we can think of

00:13:06,210 --> 00:13:11,010
cells extending futures and sell

00:13:09,270 --> 00:13:13,680
completers extending promises although

00:13:11,010 --> 00:13:15,150
this is in quotation marks so this is in

00:13:13,680 --> 00:13:22,260
the implementations not actually done

00:13:15,150 --> 00:13:25,230
this way but yeah we'll we'll see but

00:13:22,260 --> 00:13:27,830
what's very special is that the value

00:13:25,230 --> 00:13:31,440
that these cells and cell completers

00:13:27,830 --> 00:13:33,870
contain they must be taken from a

00:13:31,440 --> 00:13:39,090
lattice so there must be a type class

00:13:33,870 --> 00:13:42,480
instance for for a lattice okay and I'll

00:13:39,090 --> 00:13:47,730
give you several examples if you don't

00:13:42,480 --> 00:13:49,980
remember your discrete math okay and but

00:13:47,730 --> 00:13:52,020
what what the lattice what the purpose

00:13:49,980 --> 00:13:55,440
is is that we we can do monotonic

00:13:52,020 --> 00:13:57,510
updates to two cells so in contrast to

00:13:55,440 --> 00:14:00,600
futures which we can complete only once

00:13:57,510 --> 00:14:02,940
in this case we can actually are you

00:14:00,600 --> 00:14:05,400
know Monica monotonically grow the value

00:14:02,940 --> 00:14:09,600
that's contained in a cell can be very

00:14:05,400 --> 00:14:11,310
useful okay so let me give you an

00:14:09,600 --> 00:14:16,230
example so let's say we have a social

00:14:11,310 --> 00:14:18,660
graph right and its vertex is a user and

00:14:16,230 --> 00:14:23,820
we want to traverse the graph and

00:14:18,660 --> 00:14:26,310
collect IDs of interesting users right

00:14:23,820 --> 00:14:29,100
so let's say they want to find all the

00:14:26,310 --> 00:14:32,610
users that are that seem to be

00:14:29,100 --> 00:14:35,280
supporters of Bernie Sanders and we want

00:14:32,610 --> 00:14:38,610
to figure out if we can sway them to

00:14:35,280 --> 00:14:42,060
support clinton with a mass emailing or

00:14:38,610 --> 00:14:43,680
something like that and of course the

00:14:42,060 --> 00:14:49,590
graph is going to be large so we need to

00:14:43,680 --> 00:14:50,850
do this traversal concurrently okay so

00:14:49,590 --> 00:14:53,640
what we can do with these cells is

00:14:50,850 --> 00:14:53,910
really to say okay we just collect all

00:14:53,640 --> 00:14:58,230
the

00:14:53,910 --> 00:15:01,530
the IDS in a cell and so the cell will

00:14:58,230 --> 00:15:05,100
contain a set of ID's right or set of

00:15:01,530 --> 00:15:06,930
integers and the only risk or the only

00:15:05,100 --> 00:15:09,690
requirement that we have here is that

00:15:06,930 --> 00:15:14,790
the well that we have a lattice right

00:15:09,690 --> 00:15:18,570
and but that's okay because because

00:15:14,790 --> 00:15:23,460
mathematics tells us that the subset of

00:15:18,570 --> 00:15:26,610
a set or all the subsets of a set form a

00:15:23,460 --> 00:15:28,980
lattice right so in particular if if the

00:15:26,610 --> 00:15:32,010
cell only contains a set of integers

00:15:28,980 --> 00:15:34,170
well that's that's an element of a

00:15:32,010 --> 00:15:37,320
lattice of all the subsets of integers

00:15:34,170 --> 00:15:40,860
of all the integers ok so we're fine

00:15:37,320 --> 00:15:43,800
with that and so how does this look like

00:15:40,860 --> 00:15:45,720
and I'm simplifying slightly here

00:15:43,800 --> 00:15:48,540
because i'm going to show you certain

00:15:45,720 --> 00:15:50,790
aspects of this model later on so we're

00:15:48,540 --> 00:15:53,460
building this step by step but what we

00:15:50,790 --> 00:15:57,300
do is we need to first create a cell

00:15:53,460 --> 00:16:00,660
completer because we want to put ids as

00:15:57,300 --> 00:16:02,610
we find them into the cell and we say

00:16:00,660 --> 00:16:09,290
well this contains a set of int all

00:16:02,610 --> 00:16:12,810
right and now we need to have a lattice

00:16:09,290 --> 00:16:15,630
instance right because the cell

00:16:12,810 --> 00:16:17,790
completer will not let us create so we

00:16:15,630 --> 00:16:21,840
cannot create a cell complete completer

00:16:17,790 --> 00:16:26,520
unless there is an implicit of type

00:16:21,840 --> 00:16:28,290
lattice of set of int right and so this

00:16:26,520 --> 00:16:32,760
what we do here we just provide a very

00:16:28,290 --> 00:16:35,160
simple instance an implicit object which

00:16:32,760 --> 00:16:40,100
implements the lattice trade here and

00:16:35,160 --> 00:16:42,870
this has just two members empty which is

00:16:40,100 --> 00:16:44,640
well the least element of the lattice so

00:16:42,870 --> 00:16:47,400
it's just empty set this is what we

00:16:44,640 --> 00:16:50,120
start with so when we create a cell we

00:16:47,400 --> 00:16:55,560
start with in contains an empty set

00:16:50,120 --> 00:16:57,930
basically and when we and then we need

00:16:55,560 --> 00:17:01,920
to implement the joint operation which

00:16:57,930 --> 00:17:04,800
is fundamental so if we join just as

00:17:01,920 --> 00:17:06,450
well how do you merge two values right

00:17:04,800 --> 00:17:07,740
two sets of ins how do you merge them

00:17:06,450 --> 00:17:10,730
and well we just

00:17:07,740 --> 00:17:14,459
compute the union of them right so

00:17:10,730 --> 00:17:18,480
that's the the lattice and in fact this

00:17:14,459 --> 00:17:20,010
is more precisely sir bounded join semi

00:17:18,480 --> 00:17:23,910
lattice and it's bounded because it has

00:17:20,010 --> 00:17:25,860
a least element here and it's join semi

00:17:23,910 --> 00:17:30,059
lattice because we only were only

00:17:25,860 --> 00:17:32,090
interested in joins not in meets so we

00:17:30,059 --> 00:17:37,200
don't compute the the meat we only ever

00:17:32,090 --> 00:17:39,809
grow things here okay and and so now if

00:17:37,200 --> 00:17:45,570
we have such a cell completer user IDs

00:17:39,809 --> 00:17:49,590
we can put sets into it as we find them

00:17:45,570 --> 00:17:51,600
so let's say we find the user ID then we

00:17:49,590 --> 00:17:56,220
just create a set that contains that and

00:17:51,600 --> 00:17:58,350
we call put next to put it into the put

00:17:56,220 --> 00:18:02,250
it into the cell and what this does is

00:17:58,350 --> 00:18:05,670
it it will take the current value that's

00:18:02,250 --> 00:18:08,910
in our cell and compute the join of the

00:18:05,670 --> 00:18:10,890
current value with this with the

00:18:08,910 --> 00:18:12,510
argument of put next right so we just

00:18:10,890 --> 00:18:16,800
compute the join so that we have both

00:18:12,510 --> 00:18:18,570
the old set plus the new set right very

00:18:16,800 --> 00:18:21,240
simple we just add it to the to the set

00:18:18,570 --> 00:18:23,580
okay so this is not very different from

00:18:21,240 --> 00:18:25,950
having a concurrent hash set and just

00:18:23,580 --> 00:18:27,420
adding things concurrently right but is

00:18:25,950 --> 00:18:31,800
this a bit more general because we can

00:18:27,420 --> 00:18:34,980
have well I'll tell you later why this

00:18:31,800 --> 00:18:40,260
is more general and what else you can do

00:18:34,980 --> 00:18:42,240
with it okay alright so now the question

00:18:40,260 --> 00:18:45,630
is well once we've done this whole

00:18:42,240 --> 00:18:48,210
traversal how can we read the result and

00:18:45,630 --> 00:18:52,050
work with it work with all the users we

00:18:48,210 --> 00:18:53,640
found and well the issue is if you do

00:18:52,050 --> 00:18:57,510
such a thing and you have a large graph

00:18:53,640 --> 00:19:00,150
then this is not really it's not really

00:18:57,510 --> 00:19:02,910
a data parallel operation where you know

00:19:00,150 --> 00:19:04,350
when when you're when you're done the

00:19:02,910 --> 00:19:06,179
problem is that you have a lots of

00:19:04,350 --> 00:19:09,600
concurrent activities and this is not

00:19:06,179 --> 00:19:11,010
this is not limited to this example this

00:19:09,600 --> 00:19:12,690
is in other examples you have the same

00:19:11,010 --> 00:19:15,210
problem that you have lots of concurrent

00:19:12,690 --> 00:19:19,980
activity going on and in this case we

00:19:15,210 --> 00:19:21,270
don't know when this value is not going

00:19:19,980 --> 00:19:23,130
to change anymore when the valve

00:19:21,270 --> 00:19:25,890
you of our cell it's not going to change

00:19:23,130 --> 00:19:28,410
anymore basically you know they could

00:19:25,890 --> 00:19:30,060
still be ongoing concurrent activities

00:19:28,410 --> 00:19:35,370
so there could be some sub graph that is

00:19:30,060 --> 00:19:36,720
still being traversed and of course you

00:19:35,370 --> 00:19:38,790
could think that well okay let's use

00:19:36,720 --> 00:19:41,750
some sort of latches and things like

00:19:38,790 --> 00:19:45,870
that or use an actor that you notify

00:19:41,750 --> 00:19:50,970
things but that can be very error-prone

00:19:45,870 --> 00:19:52,320
and also once you do that you run into

00:19:50,970 --> 00:19:55,170
the issue that you can still introduce

00:19:52,320 --> 00:19:59,060
things like dead locks and and other

00:19:55,170 --> 00:20:02,340
things so this manual synchronization

00:19:59,060 --> 00:20:04,530
well again you go back to the problem of

00:20:02,340 --> 00:20:06,560
how can I make sure that what I'm doing

00:20:04,530 --> 00:20:09,360
is correct and it's not going to

00:20:06,560 --> 00:20:14,870
suddenly stop if I have a large enough

00:20:09,360 --> 00:20:17,340
graph okay so the solution is actually

00:20:14,870 --> 00:20:20,580
well that's actually the wrong word so

00:20:17,340 --> 00:20:22,710
sorry about that it's actually the

00:20:20,580 --> 00:20:26,640
opposite is quite a sense of course so

00:20:22,710 --> 00:20:32,160
quiet since it means that well what is

00:20:26,640 --> 00:20:34,800
questions mean it means a situation

00:20:32,160 --> 00:20:37,620
where the values of the cells are

00:20:34,800 --> 00:20:40,800
guaranteed not to change anymore right

00:20:37,620 --> 00:20:43,650
and so what we want to do is we want to

00:20:40,800 --> 00:20:47,280
check that there are no concurrent

00:20:43,650 --> 00:20:49,200
activities ongoing or scheduled right it

00:20:47,280 --> 00:20:51,630
may not have been started but they might

00:20:49,200 --> 00:20:55,710
be scheduled that could still change the

00:20:51,630 --> 00:20:57,900
value okay and we don't want to manage

00:20:55,710 --> 00:21:01,080
this explicitly but we rather want to

00:20:57,900 --> 00:21:03,120
give this as a task to our threat pool

00:21:01,080 --> 00:21:05,460
so the threat rule should detect the

00:21:03,120 --> 00:21:08,580
situation right because the stretch pool

00:21:05,460 --> 00:21:13,140
knows well which tasks are ongoing which

00:21:08,580 --> 00:21:15,390
tasks have been scheduled right and so

00:21:13,140 --> 00:21:18,510
now how does this help us well let's

00:21:15,390 --> 00:21:20,760
revisit the example what we do is now we

00:21:18,510 --> 00:21:23,190
extend the API so instead of just having

00:21:20,760 --> 00:21:26,820
cells and cell completers we also use

00:21:23,190 --> 00:21:28,440
what we call a handler pool so that's

00:21:26,820 --> 00:21:32,010
essentially that's like an execution

00:21:28,440 --> 00:21:34,110
context that you use for futures except

00:21:32,010 --> 00:21:35,020
that in this case there's some API that

00:21:34,110 --> 00:21:38,170
we need

00:21:35,020 --> 00:21:43,240
use explicitly so it's not all implicit

00:21:38,170 --> 00:21:45,190
and I'll show you why and this has to be

00:21:43,240 --> 00:21:48,700
associated with with the cell computer

00:21:45,190 --> 00:21:54,760
and now we can again traverse our graph

00:21:48,700 --> 00:21:57,940
put user IDs into the cell but when we

00:21:54,760 --> 00:22:03,190
want to read the the result we say well

00:21:57,940 --> 00:22:06,880
we register a on quiescent handler right

00:22:03,190 --> 00:22:09,130
so is a pool dot on quiescent some cell

00:22:06,880 --> 00:22:11,470
so the cell completer has a cell

00:22:09,130 --> 00:22:13,780
associated with it so this is like with

00:22:11,470 --> 00:22:18,310
a promise each promise has a future

00:22:13,780 --> 00:22:22,830
associated right so what we do is we say

00:22:18,310 --> 00:22:26,620
well once the pool is quiescent please

00:22:22,830 --> 00:22:28,390
read the value that's in this cell the

00:22:26,620 --> 00:22:31,360
cell corresponding to the to this

00:22:28,390 --> 00:22:34,680
completer and and here we have a closer

00:22:31,360 --> 00:22:38,140
to you know work with the collected IDs

00:22:34,680 --> 00:22:41,440
okay and so the nice thing is that when

00:22:38,140 --> 00:22:45,130
this this this is triggered once we know

00:22:41,440 --> 00:22:49,120
the entire concurrent traversal is for

00:22:45,130 --> 00:22:50,530
sure finished right and the cool thing

00:22:49,120 --> 00:22:54,910
is there there are no barriers or

00:22:50,530 --> 00:22:59,860
anything like that in this code okay and

00:22:54,910 --> 00:23:04,390
and of course afterwards you know we can

00:22:59,860 --> 00:23:07,930
we can again launch additional like

00:23:04,390 --> 00:23:09,940
follow up computations right but we have

00:23:07,930 --> 00:23:12,040
so we can structure our computation in

00:23:09,940 --> 00:23:14,350
in phases right where we do a phase

00:23:12,040 --> 00:23:16,990
which goes completely crazy lots of

00:23:14,350 --> 00:23:19,180
concurrent activity and then we say okay

00:23:16,990 --> 00:23:21,790
well now let's just wait until requires

00:23:19,180 --> 00:23:23,410
and and then we have a deterministic ref

00:23:21,790 --> 00:23:25,300
deterministic results that we can read

00:23:23,410 --> 00:23:28,030
them from the cells you know work with

00:23:25,300 --> 00:23:29,920
them and then we can spawn off a new

00:23:28,030 --> 00:23:36,580
phase that again spawns lots of

00:23:29,920 --> 00:23:38,980
concurrent activity okay so and and this

00:23:36,580 --> 00:23:43,690
is safe and like the important bit is

00:23:38,980 --> 00:23:45,940
that this is still all deterministic

00:23:43,690 --> 00:23:48,340
right that's the key thing is a safety

00:23:45,940 --> 00:23:48,830
safe means that we know the values are

00:23:48,340 --> 00:23:51,919
not going

00:23:48,830 --> 00:23:55,490
change and because we use lattices the

00:23:51,919 --> 00:24:00,289
cells will always have the same values

00:23:55,490 --> 00:24:01,940
in them once we reach this point all

00:24:00,289 --> 00:24:03,950
right so let's talk a little bit more

00:24:01,940 --> 00:24:06,140
about handler pools what they what they

00:24:03,950 --> 00:24:09,260
are so it's essentially an execution

00:24:06,140 --> 00:24:11,779
context with certain extensions one is

00:24:09,260 --> 00:24:15,019
the this event driven quiescence API

00:24:11,779 --> 00:24:20,510
that where I showed you one one method

00:24:15,019 --> 00:24:23,840
on quiescent right we can also or the

00:24:20,510 --> 00:24:27,130
pool is also critical to resolve for

00:24:23,840 --> 00:24:29,899
resolving dependencies between cells and

00:24:27,130 --> 00:24:33,649
that's another thing that I want to talk

00:24:29,899 --> 00:24:35,960
about next which is which gains some

00:24:33,649 --> 00:24:40,070
expert civet e also with respective

00:24:35,960 --> 00:24:44,450
futures so basically this whole

00:24:40,070 --> 00:24:49,429
dependency issue is related to data flow

00:24:44,450 --> 00:24:51,169
a concurrent data flow and just like

00:24:49,429 --> 00:24:52,909
futures with cells we have a

00:24:51,169 --> 00:24:54,380
non-blocking interface right where you

00:24:52,909 --> 00:24:57,250
have on on the lowest level we have

00:24:54,380 --> 00:25:02,260
callbacks that get invoked once a cell

00:24:57,250 --> 00:25:05,210
receives an update for example right and

00:25:02,260 --> 00:25:06,980
on top of those callbacks we can we can

00:25:05,210 --> 00:25:09,610
create high-level Combinator's just like

00:25:06,980 --> 00:25:12,980
with futures right we can have typed

00:25:09,610 --> 00:25:18,830
Combinator's like map and filter and so

00:25:12,980 --> 00:25:20,630
forth and so one important purpose is to

00:25:18,830 --> 00:25:23,200
actually express some kind of data flow

00:25:20,630 --> 00:25:26,120
right concurrent data flow through our

00:25:23,200 --> 00:25:29,330
application and if we if we go back to

00:25:26,120 --> 00:25:32,419
futures then if you've used futures

00:25:29,330 --> 00:25:34,519
before with the commentators then this

00:25:32,419 --> 00:25:37,610
looks familiar right you have a future

00:25:34,519 --> 00:25:40,340
you call map pass a function filter with

00:25:37,610 --> 00:25:42,500
a predicate and so on right so this this

00:25:40,340 --> 00:25:45,139
is not cells this is just plain futures

00:25:42,500 --> 00:25:48,889
here and if you think you can think of

00:25:45,139 --> 00:25:52,399
this as creating a data flow graph right

00:25:48,889 --> 00:25:56,090
where you start with a future and this

00:25:52,399 --> 00:25:59,270
here is a map operation with a with fun

00:25:56,090 --> 00:26:01,530
which results in a future prime which is

00:25:59,270 --> 00:26:04,410
not which is not shown here right

00:26:01,530 --> 00:26:06,210
that's the result of map and here is

00:26:04,410 --> 00:26:10,110
filter with predicate and the result is

00:26:06,210 --> 00:26:13,800
some future prime prime okay so this is

00:26:10,110 --> 00:26:15,450
how we build data flow graphs and the

00:26:13,800 --> 00:26:18,510
same is true for cells we can do the

00:26:15,450 --> 00:26:21,530
same thing and now the question is well

00:26:18,510 --> 00:26:23,910
what if my data flow graph has cycles

00:26:21,530 --> 00:26:26,400
now so with with futures we can't

00:26:23,910 --> 00:26:29,580
actually express cycles they're not

00:26:26,400 --> 00:26:31,770
going to be resolved right this is there

00:26:29,580 --> 00:26:37,110
is going to be a point where things just

00:26:31,770 --> 00:26:40,830
stop and we can't resolve them but with

00:26:37,110 --> 00:26:42,800
cells we can actually deal with them so

00:26:40,830 --> 00:26:46,430
let me first give you an example for

00:26:42,800 --> 00:26:51,090
when data flow graphs can have cycles

00:26:46,430 --> 00:26:53,370
and the example I want to take from from

00:26:51,090 --> 00:26:55,590
our main application that i'm going to

00:26:53,370 --> 00:26:59,810
show you later which is static analysis

00:26:55,590 --> 00:27:03,150
of JVM bytecode so we want to do here is

00:26:59,810 --> 00:27:05,880
for example determine the purity of

00:27:03,150 --> 00:27:07,710
methods yeah so we're given some class

00:27:05,880 --> 00:27:10,290
files and we want to figure out well

00:27:07,710 --> 00:27:12,960
which of which of the methods are pure

00:27:10,290 --> 00:27:15,930
and so we have a bunch of rules that say

00:27:12,960 --> 00:27:19,530
for example well a method is impure if

00:27:15,930 --> 00:27:21,390
it accesses a non-final field or a

00:27:19,530 --> 00:27:24,000
method is impure if it calls another

00:27:21,390 --> 00:27:29,130
impure method and so on right so we have

00:27:24,000 --> 00:27:33,120
a collection of rules that we check with

00:27:29,130 --> 00:27:36,390
that the static analysis checks and if

00:27:33,120 --> 00:27:39,720
if a method cannot be determined as

00:27:36,390 --> 00:27:41,160
being impure well then of course it

00:27:39,720 --> 00:27:42,900
should be marked as pure if there's no

00:27:41,160 --> 00:27:46,200
rule that tells us that it must be

00:27:42,900 --> 00:27:51,890
impure then the method we can safely say

00:27:46,200 --> 00:27:54,750
it's pure and so we can visualize the

00:27:51,890 --> 00:27:59,370
dependencies between methods very easily

00:27:54,750 --> 00:28:01,950
so method a depends on be if it calls be

00:27:59,370 --> 00:28:06,420
right because the purity of a depends on

00:28:01,950 --> 00:28:09,330
the purity of B so if B is impure and a

00:28:06,420 --> 00:28:11,490
calls be well then a is also impure at

00:28:09,330 --> 00:28:15,480
least according to this this purity

00:28:11,490 --> 00:28:18,150
analysis and well of course be can

00:28:15,480 --> 00:28:20,310
I'll see right so that if C is impure

00:28:18,150 --> 00:28:25,260
then B is impure and so on and of course

00:28:20,310 --> 00:28:26,730
we can have a cycle as well right and so

00:28:25,260 --> 00:28:32,760
they can all depend on each other and

00:28:26,730 --> 00:28:37,350
moreover it may even be the case that we

00:28:32,760 --> 00:28:41,930
do we do concurrent analysis right and

00:28:37,350 --> 00:28:44,850
at some point our pool is quiescent and

00:28:41,930 --> 00:28:47,160
there are still cells where we have not

00:28:44,850 --> 00:28:49,440
determined whether they are pure or not

00:28:47,160 --> 00:28:50,790
right so there are still methods that

00:28:49,440 --> 00:28:54,450
where we don't know whether they are

00:28:50,790 --> 00:28:56,310
pure or not right and by the way each

00:28:54,450 --> 00:28:58,380
method has a cell which tells okay is

00:28:56,310 --> 00:29:01,080
that method pure or not right and so we

00:28:58,380 --> 00:29:03,390
may have this cycle where we say well we

00:29:01,080 --> 00:29:05,940
know that a calls be because CC calls a

00:29:03,390 --> 00:29:08,430
but as all we know and there is no rule

00:29:05,940 --> 00:29:12,420
that tells us that any one of these is

00:29:08,430 --> 00:29:20,340
impure right so then then what do we do

00:29:12,420 --> 00:29:23,190
well the idea is that we we kind of use

00:29:20,340 --> 00:29:25,950
resolution policies that we can plug in

00:29:23,190 --> 00:29:27,300
and they can actually be very simple so

00:29:25,950 --> 00:29:30,360
and they I think they typically are

00:29:27,300 --> 00:29:32,970
simple at least in our applications

00:29:30,360 --> 00:29:36,150
where basically in the purity analysis

00:29:32,970 --> 00:29:38,790
we say well if we have such a cycle

00:29:36,150 --> 00:29:41,490
right then all of these cells they

00:29:38,790 --> 00:29:44,250
should be resolved to pure because there

00:29:41,490 --> 00:29:48,050
is no rule that would that was triggered

00:29:44,250 --> 00:29:53,730
to make any one of these methods impure

00:29:48,050 --> 00:29:55,650
right so and and with cells we can

00:29:53,730 --> 00:30:01,290
express exactly this kind of resolution

00:29:55,650 --> 00:30:05,430
these resolution policies so the way

00:30:01,290 --> 00:30:07,950
this looks like is is actually the

00:30:05,430 --> 00:30:13,200
second type parameter that I haven't

00:30:07,950 --> 00:30:17,430
talked about so far and this API is

00:30:13,200 --> 00:30:19,470
still subject to two tweaks and so on so

00:30:17,430 --> 00:30:22,110
you know don't take this all too

00:30:19,470 --> 00:30:25,190
literally but what we do is basically

00:30:22,110 --> 00:30:28,260
have something called a key for now

00:30:25,190 --> 00:30:29,190
which says well okay we have we have a

00:30:28,260 --> 00:30:31,650
lattice

00:30:29,190 --> 00:30:34,170
which is the purity lattice and the

00:30:31,650 --> 00:30:36,960
purity lattice just says well we have

00:30:34,170 --> 00:30:40,950
unknown purity and from that we can do

00:30:36,960 --> 00:30:44,580
in a monotonic update either to pure or

00:30:40,950 --> 00:30:46,140
impure and that's basically it and then

00:30:44,580 --> 00:30:49,380
we have a top element which is reached

00:30:46,140 --> 00:30:51,930
if if we have actually conflicting

00:30:49,380 --> 00:30:53,490
information right so if if we update to

00:30:51,930 --> 00:30:56,820
pure and then later on we update to

00:30:53,490 --> 00:31:00,150
impure that would go to the top element

00:30:56,820 --> 00:31:02,220
of the lattice which indicates an a

00:31:00,150 --> 00:31:03,960
failure essentially so just like with

00:31:02,220 --> 00:31:06,270
promises you can complete them with

00:31:03,960 --> 00:31:09,150
failure you can also complete a cell

00:31:06,270 --> 00:31:11,010
with a failure that way right so we have

00:31:09,150 --> 00:31:12,480
this this is our lattice purity it's a

00:31:11,010 --> 00:31:15,650
very simple lattice there are not many

00:31:12,480 --> 00:31:19,800
elements in it right but what we also

00:31:15,650 --> 00:31:22,950
specify is is this key and the key tells

00:31:19,800 --> 00:31:25,740
us how to resolve how to resolve cycles

00:31:22,950 --> 00:31:30,690
right and this method simply says well

00:31:25,740 --> 00:31:33,330
given a collection of cells you know how

00:31:30,690 --> 00:31:39,300
should these be resolved once we have

00:31:33,330 --> 00:31:42,080
this cycle and this is not it doesn't

00:31:39,300 --> 00:31:45,390
have to be a cycle in fact it's it's

00:31:42,080 --> 00:31:49,050
strongly connected component right

00:31:45,390 --> 00:31:51,870
because in general we can have graphs

00:31:49,050 --> 00:31:53,910
that that look like that where a

00:31:51,870 --> 00:31:56,780
strongly connected component says every

00:31:53,910 --> 00:32:00,000
vertex is reachable from every other

00:31:56,780 --> 00:32:01,890
vertex right and in this case the

00:32:00,000 --> 00:32:04,950
resolution strategy is super simple we

00:32:01,890 --> 00:32:07,110
just say well each cell should be

00:32:04,950 --> 00:32:11,730
resolved to pure so pure is an element

00:32:07,110 --> 00:32:14,390
from the purity lattice right so that's

00:32:11,730 --> 00:32:19,310
basically what what what we do here and

00:32:14,390 --> 00:32:23,000
again what and and this is what the cell

00:32:19,310 --> 00:32:25,650
model provides is basically it says well

00:32:23,000 --> 00:32:27,360
you can wait for quiescence and i'm

00:32:25,650 --> 00:32:30,000
going to show you this concrete example

00:32:27,360 --> 00:32:32,820
later you can wait for clients and when

00:32:30,000 --> 00:32:35,340
you're quiet and it will check well are

00:32:32,820 --> 00:32:37,590
there any strongly connected components

00:32:35,340 --> 00:32:39,300
that are unresolved right and if they

00:32:37,590 --> 00:32:42,150
are then we're going to apply the

00:32:39,300 --> 00:32:45,210
strategy that you've specified

00:32:42,150 --> 00:32:48,630
okay so basically in the purity analysis

00:32:45,210 --> 00:32:51,690
what we do is it's actually rather

00:32:48,630 --> 00:32:53,160
straightforward so let's say we we go we

00:32:51,690 --> 00:32:56,370
look at all the class files in our

00:32:53,160 --> 00:32:59,070
project and all the methods we create a

00:32:56,370 --> 00:33:01,590
cell completer for each method right and

00:32:59,070 --> 00:33:04,890
this needs a pool that we've created

00:33:01,590 --> 00:33:06,870
before a handler pool and we have this

00:33:04,890 --> 00:33:12,120
purity key which tells us how to resolve

00:33:06,870 --> 00:33:14,550
cycles right and then we will simply you

00:33:12,120 --> 00:33:17,430
know spawn concurrent the concurrent

00:33:14,550 --> 00:33:19,410
analysis of all these different methods

00:33:17,430 --> 00:33:22,620
so they will all concurrently be

00:33:19,410 --> 00:33:25,920
analyzed and you know during the

00:33:22,620 --> 00:33:28,770
analysis of a method we may have to wait

00:33:25,920 --> 00:33:31,260
until we know the result of analyzing a

00:33:28,770 --> 00:33:33,410
method that is being called right so we

00:33:31,260 --> 00:33:37,940
have all these dependencies between

00:33:33,410 --> 00:33:40,350
between these cells and cell completers

00:33:37,940 --> 00:33:42,960
right and then but what we do at the end

00:33:40,350 --> 00:33:46,320
is we say well okay let's wait for

00:33:42,960 --> 00:33:47,670
acquiescence right and we not only do

00:33:46,320 --> 00:33:50,040
that so we're actually not waiting

00:33:47,670 --> 00:33:54,300
instead we we get a future and this

00:33:50,040 --> 00:33:58,710
future is completed once once the pool

00:33:54,300 --> 00:34:01,410
is quiescent and we've also done

00:33:58,710 --> 00:34:05,360
resolution right so we wait until the

00:34:01,410 --> 00:34:09,419
thing is the pool is quiescent and then

00:34:05,360 --> 00:34:11,909
this method will then also say okay

00:34:09,419 --> 00:34:14,220
let's look at all the cells and check if

00:34:11,909 --> 00:34:15,870
there are any cyclic dependencies that

00:34:14,220 --> 00:34:18,210
have not been resolved yet and then

00:34:15,870 --> 00:34:21,659
apply the strategy like in this case

00:34:18,210 --> 00:34:23,490
this specified by the by that key okay

00:34:21,659 --> 00:34:28,890
and once all of that is done we have

00:34:23,490 --> 00:34:30,360
this future is completed ok so the yeah

00:34:28,890 --> 00:34:31,830
I mean of course what I haven't shown

00:34:30,360 --> 00:34:34,020
you is this Annalise method which is

00:34:31,830 --> 00:34:36,659
where all the complicated analysis takes

00:34:34,020 --> 00:34:43,230
place right but this is how we deal with

00:34:36,659 --> 00:34:47,100
the the overall setup ok so let's have a

00:34:43,230 --> 00:34:51,419
look at some some results right because

00:34:47,100 --> 00:34:54,750
we actually applied this to like I said

00:34:51,419 --> 00:34:57,630
analyzing JVM bytecode and there's

00:34:54,750 --> 00:35:01,200
new framework called opal which is

00:34:57,630 --> 00:35:04,320
written in Scala which is actually a

00:35:01,200 --> 00:35:10,320
completely from scratch implementation

00:35:04,320 --> 00:35:12,960
of bytecode toolkit quite extensible and

00:35:10,320 --> 00:35:14,880
what not quite flexible it's also fully

00:35:12,960 --> 00:35:19,500
concurrent it's fully concurrent

00:35:14,880 --> 00:35:21,600
framework and what we did was and while

00:35:19,500 --> 00:35:23,820
here you can check it out this is

00:35:21,600 --> 00:35:30,450
actually not my project but I've worked

00:35:23,820 --> 00:35:32,670
with the people who did this and what we

00:35:30,450 --> 00:35:34,470
did was we rewrote some of the analyses

00:35:32,670 --> 00:35:37,410
right so purity analysis have showed you

00:35:34,470 --> 00:35:40,590
also immutability analysis so we check

00:35:37,410 --> 00:35:45,810
whether a class is immutable for example

00:35:40,590 --> 00:35:48,990
and and we ran this on jdk 8 right on RT

00:35:45,810 --> 00:35:52,040
Doge are so this has lots of classes and

00:35:48,990 --> 00:35:57,390
methods right so this has like more than

00:35:52,040 --> 00:35:59,910
150,000 methods and and so on right so

00:35:57,390 --> 00:36:05,490
it's quite a huge static analysis task

00:35:59,910 --> 00:36:09,630
and what we grabbed some some

00:36:05,490 --> 00:36:11,220
interesting results ok the disclaimer is

00:36:09,630 --> 00:36:14,850
that we haven't fully optimized our

00:36:11,220 --> 00:36:17,340
implementation yet but we have some

00:36:14,850 --> 00:36:19,770
interesting numbers on this is on a

00:36:17,340 --> 00:36:21,990
small machine this is like two or four

00:36:19,770 --> 00:36:24,180
core machine something like that not

00:36:21,990 --> 00:36:26,850
nothing special we're going to run this

00:36:24,180 --> 00:36:31,170
on a much larger machine this week and

00:36:26,850 --> 00:36:33,600
so on right so this is quite fresh from

00:36:31,170 --> 00:36:37,770
the printing press actually so the thing

00:36:33,600 --> 00:36:41,490
is that the this is the oh pal

00:36:37,770 --> 00:36:44,610
implementation before before using cells

00:36:41,490 --> 00:36:47,520
and so for immutability for example to

00:36:44,610 --> 00:36:51,440
analyze the whole JDK 8 takes like 3.3

00:36:47,520 --> 00:36:54,330
seconds and with reactive async this is

00:36:51,440 --> 00:36:57,330
faster it's about it's like fifteen

00:36:54,330 --> 00:36:59,310
percent faster and I think we will be

00:36:57,330 --> 00:37:01,380
able to make make this significantly

00:36:59,310 --> 00:37:05,370
faster as well once we start looking

00:37:01,380 --> 00:37:08,070
really into making things more efficient

00:37:05,370 --> 00:37:08,580
and so on but this is quite nice but

00:37:08,070 --> 00:37:10,290
this is

00:37:08,580 --> 00:37:12,450
not the only thing why I'm excited about

00:37:10,290 --> 00:37:14,520
this because one of the reasons why it's

00:37:12,450 --> 00:37:18,780
really interesting is that the code size

00:37:14,520 --> 00:37:22,920
of the analyses was cut down by a factor

00:37:18,780 --> 00:37:27,260
of two so and that's nice because the we

00:37:22,920 --> 00:37:27,260
compared Scala with Scala code right and

00:37:28,490 --> 00:37:34,380
Michael a mile hike back is the main

00:37:32,130 --> 00:37:36,270
author of a pal he has lots of Scylla

00:37:34,380 --> 00:37:39,450
experience too so thus calico d rights

00:37:36,270 --> 00:37:42,780
is is quite good and we still could

00:37:39,450 --> 00:37:45,510
reduce the the code size of each

00:37:42,780 --> 00:37:48,030
analysis by at least a factor of two and

00:37:45,510 --> 00:37:52,380
it's not it's not less readable or

00:37:48,030 --> 00:37:53,760
anything like that and plus we can and

00:37:52,380 --> 00:37:57,140
we can actually be confident that the

00:37:53,760 --> 00:37:59,850
new analyses are actually deterministic

00:37:57,140 --> 00:38:02,930
right so we I think this is a this is

00:37:59,850 --> 00:38:06,060
too strong points here coupled with

00:38:02,930 --> 00:38:09,540
actually a faster analysis right so I

00:38:06,060 --> 00:38:14,070
think this is promising but we still

00:38:09,540 --> 00:38:18,080
need we still want to do some more I get

00:38:14,070 --> 00:38:21,240
some more experience on this so there's

00:38:18,080 --> 00:38:23,640
quite a bit of ongoing in future work of

00:38:21,240 --> 00:38:28,280
course we need to look more into

00:38:23,640 --> 00:38:32,520
benchmarking in optimization then

00:38:28,280 --> 00:38:34,920
determinism right now basically you know

00:38:32,520 --> 00:38:37,740
we can we can tell you your code is

00:38:34,920 --> 00:38:39,930
deterministic if you use the API

00:38:37,740 --> 00:38:44,010
correctly I mean if you you know if you

00:38:39,930 --> 00:38:46,200
stick two if you stick to the the API

00:38:44,010 --> 00:38:49,350
that we provide that's deterministic

00:38:46,200 --> 00:38:51,870
like you know put next and and you know

00:38:49,350 --> 00:38:54,990
on quietened and so on quiet and resolve

00:38:51,870 --> 00:38:56,940
cells and ends and things like that then

00:38:54,990 --> 00:38:59,130
you you you can you can be sure it's

00:38:56,940 --> 00:39:00,660
deterministic but it's not checked by

00:38:59,130 --> 00:39:02,430
the compiler that you do that you can

00:39:00,660 --> 00:39:04,800
still do crazy stuff so you can still do

00:39:02,430 --> 00:39:08,100
like in the on quiescent handler you

00:39:04,800 --> 00:39:10,500
could still you know do a side effect to

00:39:08,100 --> 00:39:12,690
some other thing or use or mix it with

00:39:10,500 --> 00:39:14,820
other concurrency abstractions so we

00:39:12,690 --> 00:39:16,800
don't check for that so the idea is that

00:39:14,820 --> 00:39:21,210
in the future we actually want to do

00:39:16,800 --> 00:39:22,440
affect checking so that determinism is

00:39:21,210 --> 00:39:25,920
an effect or

00:39:22,440 --> 00:39:28,500
rather you know rest of the effect

00:39:25,920 --> 00:39:30,720
system can tell you do you have the

00:39:28,500 --> 00:39:35,130
capability to do something that's not

00:39:30,720 --> 00:39:36,660
deterministic and right and and so this

00:39:35,130 --> 00:39:41,220
is something that would be really cool

00:39:36,660 --> 00:39:44,790
to look into in the context of effects

00:39:41,220 --> 00:39:46,470
in in dotty right and then of course the

00:39:44,790 --> 00:39:48,599
other question is well just like a

00:39:46,470 --> 00:39:51,150
single weight simplifies programming

00:39:48,599 --> 00:39:53,450
with futures you know could could there

00:39:51,150 --> 00:40:01,349
be analogous support that simplifies

00:39:53,450 --> 00:40:03,480
working with cells okay so I think we're

00:40:01,349 --> 00:40:06,750
ready to conclude so that there's also

00:40:03,480 --> 00:40:09,180
some time for questions so um what I've

00:40:06,750 --> 00:40:12,030
showed you is kind of a new concurrent

00:40:09,180 --> 00:40:16,050
programming model I should also say that

00:40:12,030 --> 00:40:18,810
this is heavily inspired by alvars in

00:40:16,050 --> 00:40:21,500
Haskell which is quite recent so that's

00:40:18,810 --> 00:40:25,650
just within the last couple of years a

00:40:21,500 --> 00:40:26,609
project in Haskell but as we know has to

00:40:25,650 --> 00:40:30,060
lose a very different language from

00:40:26,609 --> 00:40:32,010
Scala so this is in fact not actually

00:40:30,060 --> 00:40:33,390
just a reimplement ation of the model

00:40:32,010 --> 00:40:38,609
it's quite different from the Haskell

00:40:33,390 --> 00:40:41,190
solution and well the key idea is to

00:40:38,609 --> 00:40:43,950
combine lattices and quiescence to get

00:40:41,190 --> 00:40:47,000
something that allows you to write

00:40:43,950 --> 00:40:49,950
deterministic concurrent programs

00:40:47,000 --> 00:40:51,750
support cyclic dependencies which is

00:40:49,950 --> 00:40:55,770
crucial at least for the applications

00:40:51,750 --> 00:40:57,270
that we've used it for so far I think

00:40:55,770 --> 00:41:02,069
the preliminary results are quite

00:40:57,270 --> 00:41:04,290
promising and yeah so future work is

00:41:02,069 --> 00:41:09,420
sort of static checking of determinism

00:41:04,290 --> 00:41:11,700
and you can check it out for kit and so

00:41:09,420 --> 00:41:16,170
on it's still like I said the API is

00:41:11,700 --> 00:41:18,240
still a bit in flux so you know there's

00:41:16,170 --> 00:41:23,160
no there's no one dot zero release or

00:41:18,240 --> 00:41:26,060
anything close to that okay then thanks

00:41:23,160 --> 00:41:26,060
for attention and

00:41:32,570 --> 00:41:36,500
I'm happy to take questions

00:41:57,029 --> 00:42:02,640
thank you out of maybe because my

00:42:00,809 --> 00:42:04,650
ignorance but what is it I can

00:42:02,640 --> 00:42:07,140
accomplish using this instead of using

00:42:04,650 --> 00:42:10,499
an observable sequence a reactive

00:42:07,140 --> 00:42:13,529
sequence where the values come in and

00:42:10,499 --> 00:42:16,079
then I collect them and I said instead

00:42:13,529 --> 00:42:19,709
of using a lattice and waiting for

00:42:16,079 --> 00:42:22,259
questions okay and so the right so

00:42:19,709 --> 00:42:29,519
what's the advantage well it's hard to

00:42:22,259 --> 00:42:32,640
say in general of course so it really

00:42:29,519 --> 00:42:34,619
depends on what your requirements are I

00:42:32,640 --> 00:42:37,169
mean like if you if you if you don't

00:42:34,619 --> 00:42:40,019
have let's say cyclic dependencies right

00:42:37,169 --> 00:42:43,579
then maybe you don't need the power of

00:42:40,019 --> 00:42:45,839
this but you're you're you're fine with

00:42:43,579 --> 00:42:47,849
maybe a stream based solution or

00:42:45,839 --> 00:42:50,999
something like that for sure but also I

00:42:47,849 --> 00:42:55,799
mean this is huy essence is good if you

00:42:50,999 --> 00:42:58,409
want to if you want to wait for a

00:42:55,799 --> 00:43:01,739
complex computation to actually you know

00:42:58,409 --> 00:43:03,329
eventually terminate right if you have

00:43:01,739 --> 00:43:05,189
streams then sometimes you don't

00:43:03,329 --> 00:43:08,400
actually terminate ever maybe right you

00:43:05,189 --> 00:43:11,189
just do just have incoming events or

00:43:08,400 --> 00:43:12,979
values and you you process them as they

00:43:11,189 --> 00:43:17,849
come in and it goes through some kind of

00:43:12,979 --> 00:43:22,380
pipeline and something like that then of

00:43:17,849 --> 00:43:24,839
course stream based system could be

00:43:22,380 --> 00:43:27,390
could be more appropriate so this is

00:43:24,839 --> 00:43:30,539
really for this is essentially what it

00:43:27,390 --> 00:43:33,839
this is for is is concurrent fixed point

00:43:30,539 --> 00:43:36,659
computations right where you actually so

00:43:33,839 --> 00:43:39,619
a fixed point computation is is a

00:43:36,659 --> 00:43:42,419
computation where you you you compute

00:43:39,619 --> 00:43:45,059
results and they can trigger the

00:43:42,419 --> 00:43:47,339
computation of other concurrent

00:43:45,059 --> 00:43:49,919
computations and you don't actually know

00:43:47,339 --> 00:43:51,390
when you are finished right so and this

00:43:49,919 --> 00:43:53,309
is really powerful because you can just

00:43:51,390 --> 00:43:56,549
keep the computation running and trigger

00:43:53,309 --> 00:43:58,709
like updates trigger other computations

00:43:56,549 --> 00:44:00,809
and updates and then you can just say

00:43:58,709 --> 00:44:03,929
well you know just do this until your

00:44:00,809 --> 00:44:05,669
client and that means you have reached a

00:44:03,929 --> 00:44:07,799
fixed point because nothing's changing

00:44:05,669 --> 00:44:10,039
anymore so of course if you don't have

00:44:07,799 --> 00:44:10,039
this

00:44:10,040 --> 00:44:14,730
requirement and you know maybe a less

00:44:12,510 --> 00:44:18,150
powerful solution is maybe even better

00:44:14,730 --> 00:44:21,330
because well as we heard in Martin's

00:44:18,150 --> 00:44:25,940
keynote the principle of least power is

00:44:21,330 --> 00:44:25,940
probably good too yeah

00:44:33,170 --> 00:44:38,809
yeah you talked about quiescence very

00:44:36,410 --> 00:44:42,170
much in well as you say there is a batch

00:44:38,809 --> 00:44:43,339
mode kind of property you have a batch

00:44:42,170 --> 00:44:45,530
of computation that will eventually

00:44:43,339 --> 00:44:48,319
finish and you wait for quiescence is

00:44:45,530 --> 00:44:50,990
there any value in a maybe a weaker

00:44:48,319 --> 00:44:52,880
notion of quiescence foreign for an

00:44:50,990 --> 00:44:56,809
online computation kind of case can you

00:44:52,880 --> 00:44:59,540
define grecins for a data set in with

00:44:56,809 --> 00:45:01,970
respect to some set of tasks have you

00:44:59,540 --> 00:45:06,500
looked at that at all hmm that's it's a

00:45:01,970 --> 00:45:10,190
very good question so so far I haven't

00:45:06,500 --> 00:45:13,819
really looked into this really so i

00:45:10,190 --> 00:45:16,549
don't i don't know but one thing that i

00:45:13,819 --> 00:45:19,130
think could be interesting is this this

00:45:16,549 --> 00:45:22,549
idea of having phases right where we

00:45:19,130 --> 00:45:24,380
have one phrase that where you do lots

00:45:22,549 --> 00:45:26,089
of concurrent things and you come to a

00:45:24,380 --> 00:45:27,890
quiescent point and then you start the

00:45:26,089 --> 00:45:32,030
next phase and this is a little bit

00:45:27,890 --> 00:45:34,940
related to things like spark streaming

00:45:32,030 --> 00:45:36,950
or so right where we have patches that

00:45:34,940 --> 00:45:39,020
are you know we have a stream but you

00:45:36,950 --> 00:45:40,609
just used to still package things up in

00:45:39,020 --> 00:45:42,349
batches and then you process those

00:45:40,609 --> 00:45:45,589
batches and then you move on to the next

00:45:42,349 --> 00:45:47,990
ones so maybe something analogous could

00:45:45,589 --> 00:45:51,579
be used actually right but I haven't

00:45:47,990 --> 00:45:51,579
looked into this concretely

00:46:03,250 --> 00:46:11,360
yes two things I guess from my

00:46:08,750 --> 00:46:13,250
understanding the lattice is it's not

00:46:11,360 --> 00:46:16,160
proven to be a lattice is something I

00:46:13,250 --> 00:46:18,500
say so let's say we had the lapped is

00:46:16,160 --> 00:46:21,410
defined for adding things to a double

00:46:18,500 --> 00:46:23,300
counter rounding errors wouldn't be

00:46:21,410 --> 00:46:25,369
deterministic that that's just a

00:46:23,300 --> 00:46:27,140
clarification I guess that's just we say

00:46:25,369 --> 00:46:29,180
it's the lattice and that's how it's

00:46:27,140 --> 00:46:31,520
deterministic right yeah that's right

00:46:29,180 --> 00:46:33,170
there's no checking too yeah there's no

00:46:31,520 --> 00:46:35,510
checking whether it's actually a lattice

00:46:33,170 --> 00:46:39,619
you just say that yeah so the other

00:46:35,510 --> 00:46:42,020
thing is just an observation quiet and

00:46:39,619 --> 00:46:45,110
so I think one example of that would be

00:46:42,020 --> 00:46:46,970
a user interface where you have changes

00:46:45,110 --> 00:46:48,590
that you wouldn't really want to redraw

00:46:46,970 --> 00:46:51,590
because it's not finished it's not

00:46:48,590 --> 00:46:53,630
stable right when you come to choir sins

00:46:51,590 --> 00:46:56,119
face you redraw the whole thing correct

00:46:53,630 --> 00:46:58,610
and you start then that might start a

00:46:56,119 --> 00:47:01,820
new thing yeah so equations would be

00:46:58,610 --> 00:47:03,920
some kind of stage where you are

00:47:01,820 --> 00:47:07,700
conforming to some requirements where

00:47:03,920 --> 00:47:10,220
you are consistent correct or in other

00:47:07,700 --> 00:47:12,109
applications you are in some consistent

00:47:10,220 --> 00:47:15,800
state and you can generate a side effect

00:47:12,109 --> 00:47:18,800
right right right send send send an

00:47:15,800 --> 00:47:20,810
invoice or you know mmm printer price

00:47:18,800 --> 00:47:22,640
values correct so that's a very good

00:47:20,810 --> 00:47:25,510
observation right so you this could be

00:47:22,640 --> 00:47:28,070
used for things like user interfaces or

00:47:25,510 --> 00:47:30,980
right where there's a change which

00:47:28,070 --> 00:47:33,440
triggers updates and you want that all

00:47:30,980 --> 00:47:36,020
of these updates it should all be done

00:47:33,440 --> 00:47:37,609
and and that's again quiet and so when

00:47:36,020 --> 00:47:39,500
when things are quiet and then you can

00:47:37,609 --> 00:47:41,869
then the nice thing is right where i

00:47:39,500 --> 00:47:43,840
showed you this on quiet and what you

00:47:41,869 --> 00:47:46,700
get when you reach that point is is

00:47:43,840 --> 00:47:49,520
typically an immutable immutable data

00:47:46,700 --> 00:47:51,109
structure that you've collected in your

00:47:49,520 --> 00:47:54,100
cell and that's nice because it's an

00:47:51,109 --> 00:47:56,030
immutable thing which you can then

00:47:54,100 --> 00:47:58,100
process with it's not going to change

00:47:56,030 --> 00:48:00,140
anymore right then you can you have a

00:47:58,100 --> 00:48:05,510
handle on to the on the result and you

00:48:00,140 --> 00:48:09,040
can then process that further yeah great

00:48:05,510 --> 00:48:09,040
any more questions or

00:48:13,480 --> 00:48:23,450
what if the join me turd is not

00:48:19,840 --> 00:48:25,100
commutative what if the giant method is

00:48:23,450 --> 00:48:28,640
not commutative well then you have not

00:48:25,100 --> 00:48:30,260
defined a lattice then it's not correct

00:48:28,640 --> 00:48:33,050
but I think so the thing is with the

00:48:30,260 --> 00:48:35,300
lattices I think it's it's you should

00:48:33,050 --> 00:48:38,480
look at these similar to see our dps

00:48:35,300 --> 00:48:40,790
right conflict-free replicated data

00:48:38,480 --> 00:48:42,640
types if someone knows about these very

00:48:40,790 --> 00:48:46,130
interesting sort distributed computing

00:48:42,640 --> 00:48:47,810
but this is very much related to

00:48:46,130 --> 00:48:49,220
lattices because they're all so you want

00:48:47,810 --> 00:48:52,580
operations to have certain properties

00:48:49,220 --> 00:48:54,530
like commutativity and I think that the

00:48:52,580 --> 00:48:57,860
idea is that you know there will be

00:48:54,530 --> 00:49:00,830
libraries of lattices right and you just

00:48:57,860 --> 00:49:03,170
pick one right and and the person who

00:49:00,830 --> 00:49:06,160
dis defined it made sure it's a lattice

00:49:03,170 --> 00:49:06,160
actually and yeah

00:49:13,550 --> 00:49:21,120
just a simple question what requirement

00:49:17,010 --> 00:49:23,480
for what this gives you over commutative

00:49:21,120 --> 00:49:27,630
Manu it for example of alien moon wait

00:49:23,480 --> 00:49:33,720
why it can't serve that all of the

00:49:27,630 --> 00:49:39,320
lattice well okay so so I mean of course

00:49:33,720 --> 00:49:41,520
you could base the lattice on to other

00:49:39,320 --> 00:49:43,380
abstractions right i mean it doesn't

00:49:41,520 --> 00:49:45,180
really matter i mean as long as what you

00:49:43,380 --> 00:49:48,270
define ends up being a lattice that's

00:49:45,180 --> 00:49:52,650
fine right so that's not really the

00:49:48,270 --> 00:49:54,980
model doesn't restrict you there except

00:49:52,650 --> 00:49:58,050
for maybe the API right which is

00:49:54,980 --> 00:50:01,530
specific but maybe one again I mean

00:49:58,050 --> 00:50:03,060
lapis is not used that much but this

00:50:01,530 --> 00:50:08,850
should probably be some standard

00:50:03,060 --> 00:50:11,120
interface right that's one more question

00:50:08,850 --> 00:50:11,120
in the back

00:50:23,599 --> 00:50:29,489
is it on oh thank you so I think it's a

00:50:27,690 --> 00:50:32,309
bit it's a little bit on the line up

00:50:29,489 --> 00:50:33,900
with previous questions but in which are

00:50:32,309 --> 00:50:35,549
exactly properties the algebraic

00:50:33,900 --> 00:50:38,730
properties of the lattice that you will

00:50:35,549 --> 00:50:40,349
need a tool i mean i understand that abs

00:50:38,730 --> 00:50:42,150
that these cells the value of the cells

00:50:40,349 --> 00:50:46,140
are somehow being computed incrementally

00:50:42,150 --> 00:50:48,960
am i am i right yes you're right so the

00:50:46,140 --> 00:50:51,509
idea is that the basic order will be

00:50:48,960 --> 00:50:54,059
about the the order the parcel early

00:50:51,509 --> 00:50:56,130
indelicacy say whether they are more

00:50:54,059 --> 00:50:58,460
results or relation whether the result

00:50:56,130 --> 00:51:00,119
display more or less compute right

00:50:58,460 --> 00:51:03,119
instead and again I didn't fully

00:51:00,119 --> 00:51:05,430
understand what your son I like this is

00:51:03,119 --> 00:51:08,249
a kind of an order a partial order right

00:51:05,430 --> 00:51:10,079
an element and in this case the set of

00:51:08,249 --> 00:51:12,720
elements will be the possibility

00:51:10,079 --> 00:51:14,249
possible result or correct possible

00:51:12,720 --> 00:51:17,099
results and the order will be whether

00:51:14,249 --> 00:51:19,049
they are more they contain more results

00:51:17,099 --> 00:51:21,599
that will say that was an example you

00:51:19,049 --> 00:51:23,670
mentioned the subset correct this upset

00:51:21,599 --> 00:51:27,299
over between aim the power set lattice

00:51:23,670 --> 00:51:29,369
right so in this case which are the

00:51:27,299 --> 00:51:31,999
properties that you will need Darien's

00:51:29,369 --> 00:51:33,839
you it's you say that this is about a

00:51:31,999 --> 00:51:36,210
getting to a fixed point through the

00:51:33,839 --> 00:51:40,049
monotonic function wanna drink on this

00:51:36,210 --> 00:51:42,059
lattice yes ok so the ad so what you're

00:51:40,049 --> 00:51:43,920
saying is that if you guys have any

00:51:42,059 --> 00:51:45,930
monotonic function in the lattice it

00:51:43,920 --> 00:51:49,099
will eventually reach a fixed point

00:51:45,930 --> 00:51:51,869
correct you can assume as listen values

00:51:49,099 --> 00:51:53,400
but one thing is knowing that it reaches

00:51:51,869 --> 00:51:55,140
an fixed point but they when you have

00:51:53,400 --> 00:51:57,029
the implementation of the cell how do

00:51:55,140 --> 00:52:00,150
you know that they each already rich

00:51:57,029 --> 00:52:02,849
that fixed point well that's what

00:52:00,150 --> 00:52:04,650
quiescence tells you right that's what

00:52:02,849 --> 00:52:06,150
that's how you can tell whether you've

00:52:04,650 --> 00:52:08,190
reached a fixed point because there's no

00:52:06,150 --> 00:52:09,839
they're note changes being done anymore

00:52:08,190 --> 00:52:12,390
there cannot be any changes anymore

00:52:09,839 --> 00:52:14,069
actually you show you so every date has

00:52:12,390 --> 00:52:16,799
been computed over a fixed set of the

00:52:14,069 --> 00:52:18,450
data right way fish of them in the

00:52:16,799 --> 00:52:19,980
records so you know the data is not

00:52:18,450 --> 00:52:21,390
going to change anymore and also you

00:52:19,980 --> 00:52:23,849
don't have cycles that haven't been

00:52:21,390 --> 00:52:25,710
resolved yet okay and for the cycles the

00:52:23,849 --> 00:52:29,009
distribution for the seconds if you want

00:52:25,710 --> 00:52:31,890
to get the sort of collective questions

00:52:29,009 --> 00:52:34,970
of the whole a of all day by cells in

00:52:31,890 --> 00:52:37,440
they said right yeah

00:52:34,970 --> 00:52:39,570
exactly thank you very much yeah thanks

00:52:37,440 --> 00:52:42,410
all right I think we're out of time so

00:52:39,570 --> 00:52:42,410

YouTube URL: https://www.youtube.com/watch?v=S9xxhyDYoZk


