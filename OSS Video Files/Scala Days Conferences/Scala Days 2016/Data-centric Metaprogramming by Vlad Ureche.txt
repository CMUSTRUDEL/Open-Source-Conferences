Title: Data-centric Metaprogramming by Vlad Ureche
Publication date: 2017-01-19
Playlist: Scala Days 2016
Description: 
	This video was recorded at Scala Days Berlin 2016
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Anstract:
We can compose data structures like LEGO bricks: a relational employee table can be modelled as a `Vector[Employee]`, where we use the standard `Vector` collection. Yet, few programmers know just how inefficient this is: iterating requires dereferencing a pointer for each employee and a good part of the memory is occupied by redundant bookkeeping information.

Data-centric metaprogramming is a technique that allows developers to tweak how their data structures are stored in memory, thus improving performance. For example, we can use `Vector[Employee]` throughout the program, despite its inefficiency. Then, when performance starts to matter, we simply instruct the compiler how to store the `Vector[Employee]` more efficiently, using separate arrays (or vectors) for each component. In turn, the compiler uses this information to optimize our code, automatically switching to the improved memory layout for the `Vector[Employee]`. This makes premature optimization redundant: we write the code using our favorite abstractions and, only when necessary, we tune them after the fact.

There are many usecases for data-centric metaprogramming. For example, applied to Spark, it can produce 40% speedups. The Scala compiler plugin that enables data-centric metaprogramming is developed at github.com/miniboxing/ildl-plugin and is documented on scala-ildl.org.

This way we avoid the misinterpretation that the newly introduced whole-wold Dataset optimisation (URL: https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.html) relies on the data-centric metaprogramming approach, which is not the case.
Captions: 
	00:00:00,079 --> 00:00:04,680
thank you thank you everyone for coming

00:00:02,490 --> 00:00:07,109
it's really exciting to see so many

00:00:04,680 --> 00:00:09,809
people in the room I'm going to talk

00:00:07,109 --> 00:00:11,340
about data centric metaprogramming my

00:00:09,809 --> 00:00:13,980
name is Vlad I came on screen you have

00:00:11,340 --> 00:00:16,680
my coordinates in case you I'm a

00:00:13,980 --> 00:00:19,560
software engineer at cyber Haven and I

00:00:16,680 --> 00:00:22,529
just graduated from EPFL and my main

00:00:19,560 --> 00:00:25,859
project is Scala mini boxing what I'm

00:00:22,529 --> 00:00:27,539
going to talk to you about today is was

00:00:25,859 --> 00:00:30,060
originally part of the mini boxing

00:00:27,539 --> 00:00:33,079
project but then seeing its potential I

00:00:30,060 --> 00:00:37,050
try to push it to a different project

00:00:33,079 --> 00:00:40,620
separate during the presentation I will

00:00:37,050 --> 00:00:44,370
be giving some technical details please

00:00:40,620 --> 00:00:47,100
do stop me if what I explain is not very

00:00:44,370 --> 00:00:53,219
clear to you if we have plenty of time

00:00:47,100 --> 00:00:55,829
so please directly ask so first we're

00:00:53,219 --> 00:00:57,960
going to look at motivation and the

00:00:55,829 --> 00:01:00,930
motivation comes from the object

00:00:57,960 --> 00:01:03,199
composition namely if you take the

00:01:00,930 --> 00:01:07,409
vector class in the Scala library and

00:01:03,199 --> 00:01:09,990
you have your very own defined employee

00:01:07,409 --> 00:01:13,110
class for example maybe it corresponds

00:01:09,990 --> 00:01:16,799
to a table row you will compose these

00:01:13,110 --> 00:01:19,170
two and get a vector of your employee so

00:01:16,799 --> 00:01:22,400
far so good what is bad about this is

00:01:19,170 --> 00:01:26,430
that if you're traversing this vector

00:01:22,400 --> 00:01:29,790
you will be dereferencing a pointer each

00:01:26,430 --> 00:01:33,299
time you're visiting an element and this

00:01:29,790 --> 00:01:34,829
can be very harmful for performance of

00:01:33,299 --> 00:01:38,640
course there is a better way to

00:01:34,829 --> 00:01:41,700
represent the data without having each

00:01:38,640 --> 00:01:45,990
employee as a different object we could

00:01:41,700 --> 00:01:48,090
take a column-oriented storage and this

00:01:45,990 --> 00:01:51,930
would mean that we put the IDS one after

00:01:48,090 --> 00:01:53,720
the others the other and so on this is

00:01:51,930 --> 00:01:56,729
very good because it gives us

00:01:53,720 --> 00:02:01,110
performance and makes a much better use

00:01:56,729 --> 00:02:05,969
of of the heap we use less memory and

00:02:01,110 --> 00:02:08,520
put less pressure on the GC okay so we

00:02:05,969 --> 00:02:11,819
see the problem now right we have object

00:02:08,520 --> 00:02:12,970
composition it's great but it leads to

00:02:11,819 --> 00:02:16,540
suboptimal

00:02:12,970 --> 00:02:20,530
data structures if we look at a vector

00:02:16,540 --> 00:02:23,860
of tea it is unaware of employee of the

00:02:20,530 --> 00:02:26,440
employee class we defined so that makes

00:02:23,860 --> 00:02:29,410
it suboptimal the way it stores data is

00:02:26,440 --> 00:02:31,180
sum up and this is not really limited to

00:02:29,410 --> 00:02:34,990
vector it's actually a problem that

00:02:31,180 --> 00:02:38,320
affects all generics and it also affects

00:02:34,990 --> 00:02:41,920
all the collections and it also affects

00:02:38,320 --> 00:02:45,010
functions will see later and most people

00:02:41,920 --> 00:02:47,320
here in the room I assume you already

00:02:45,010 --> 00:02:50,740
know better representations for your

00:02:47,320 --> 00:02:53,650
data but you don't you can't just

00:02:50,740 --> 00:02:56,170
manually go in a code base and start

00:02:53,650 --> 00:02:58,600
changing every vector of employee by

00:02:56,170 --> 00:03:01,570
something else it's too much work and

00:02:58,600 --> 00:03:05,709
it's not maintainable so as a compiler

00:03:01,570 --> 00:03:08,230
hacker I think that the compiler should

00:03:05,709 --> 00:03:11,950
do that for you and I'll try to convince

00:03:08,230 --> 00:03:14,670
you why but before that you might think

00:03:11,950 --> 00:03:18,430
okay we've heard so much about

00:03:14,670 --> 00:03:21,250
optimizers in this edition of scala days

00:03:18,430 --> 00:03:24,519
we've heard about the scala GS optimizer

00:03:21,250 --> 00:03:28,600
we've heard about the dotty linker we've

00:03:24,519 --> 00:03:31,870
heard about scala native so why do we

00:03:28,600 --> 00:03:36,040
need something more all these optimizers

00:03:31,870 --> 00:03:37,780
do a great job but they're bound to one

00:03:36,040 --> 00:03:42,430
constraint they have to respect the

00:03:37,780 --> 00:03:45,850
semantics so no change they do can

00:03:42,430 --> 00:03:50,950
affect any of the possible corner cases

00:03:45,850 --> 00:03:53,920
that you have for a certain statement

00:03:50,950 --> 00:03:55,299
out first certain expression so that

00:03:53,920 --> 00:03:59,440
means they have to be pretty

00:03:55,299 --> 00:04:02,290
conservative in what they do now us

00:03:59,440 --> 00:04:05,500
programmers have full control over your

00:04:02,290 --> 00:04:08,200
code base that means you know what is

00:04:05,500 --> 00:04:11,680
accessed when it is accessed and how it

00:04:08,200 --> 00:04:14,830
is accessed and that lets you break

00:04:11,680 --> 00:04:18,430
semantics just enough to speculate that

00:04:14,830 --> 00:04:22,960
or about what will happen to your data

00:04:18,430 --> 00:04:25,330
and that will let you use better have

00:04:22,960 --> 00:04:29,810
better data representations

00:04:25,330 --> 00:04:31,310
okay so the current challenges you have

00:04:29,810 --> 00:04:33,260
no way knowing a better data

00:04:31,310 --> 00:04:35,450
representation is not enough you don't

00:04:33,260 --> 00:04:39,740
have a way to communicate that to the

00:04:35,450 --> 00:04:41,690
compiler so we're basically in a

00:04:39,740 --> 00:04:46,340
situation where we're stuck with either

00:04:41,690 --> 00:04:49,430
safe code or fast code and this is where

00:04:46,340 --> 00:04:51,260
my my project comes in their eccentric

00:04:49,430 --> 00:04:53,900
meta programming is a scholar compiler

00:04:51,260 --> 00:04:57,320
plugin that lets you tune the way where

00:04:53,900 --> 00:05:00,080
you represent data in your program this

00:04:57,320 --> 00:05:04,040
website is Scala il dl you can read

00:05:00,080 --> 00:05:05,960
about it and see more and try it out now

00:05:04,040 --> 00:05:09,560
let's talk about the transformation for

00:05:05,960 --> 00:05:12,230
a moment and the transformation when

00:05:09,560 --> 00:05:14,500
you're transforming data representation

00:05:12,230 --> 00:05:18,080
there are actually two steps involve

00:05:14,500 --> 00:05:20,030
first part is coming up with the

00:05:18,080 --> 00:05:21,860
definition for the transformation coming

00:05:20,030 --> 00:05:25,640
up with the better data structure and

00:05:21,860 --> 00:05:28,900
this is fundamentally something you as a

00:05:25,640 --> 00:05:32,230
programmer only know how to do because

00:05:28,900 --> 00:05:35,290
it's based on a speculation is based on

00:05:32,230 --> 00:05:37,460
knowing how the data is accessed and

00:05:35,290 --> 00:05:40,430
very interestingly it's a one-time

00:05:37,460 --> 00:05:42,800
effort so you once you defined the

00:05:40,430 --> 00:05:44,780
better data representation this is all

00:05:42,800 --> 00:05:46,580
the effort it takes so I think this is

00:05:44,780 --> 00:05:49,310
the part that should be done by the

00:05:46,580 --> 00:05:51,800
programmer and this will a compiler will

00:05:49,310 --> 00:05:54,920
never do for you and then there's the

00:05:51,800 --> 00:05:57,170
application part which is the repetitive

00:05:54,920 --> 00:06:00,710
and tedious part of just going into the

00:05:57,170 --> 00:06:03,500
code and modifying it such that it uses

00:06:00,710 --> 00:06:06,380
the better data representation and this

00:06:03,500 --> 00:06:08,630
is pretty pre annoying because if you

00:06:06,380 --> 00:06:12,260
want to have a high-level code base that

00:06:08,630 --> 00:06:13,970
is easily maintainable going into the

00:06:12,260 --> 00:06:15,680
source code and modifying data

00:06:13,970 --> 00:06:18,950
representation is something you won't

00:06:15,680 --> 00:06:22,880
want to do it's better to leave it to

00:06:18,950 --> 00:06:25,910
the compiler so let's focus on the

00:06:22,880 --> 00:06:29,480
definition part let me show you yes i

00:06:25,910 --> 00:06:32,660
did i see a question back there okay so

00:06:29,480 --> 00:06:35,750
let's look at a definition how how could

00:06:32,660 --> 00:06:37,910
we define such a transformation here's

00:06:35,750 --> 00:06:38,289
the example here is the transformation

00:06:37,910 --> 00:06:41,919
for

00:06:38,289 --> 00:06:45,219
the example I gave you earlier and what

00:06:41,919 --> 00:06:49,300
you see here is the two types the target

00:06:45,219 --> 00:06:52,539
and the result what we're changing then

00:06:49,300 --> 00:06:56,139
we tell the compiler whenever you need

00:06:52,539 --> 00:06:59,520
to to change values of one type today

00:06:56,139 --> 00:07:02,999
the other here's how to do it and

00:06:59,520 --> 00:07:06,219
finally we tell the compiler how to run

00:07:02,999 --> 00:07:10,319
methods on the vector of the employee on

00:07:06,219 --> 00:07:13,779
the new representation this is a very

00:07:10,319 --> 00:07:15,759
short cut because it could transform

00:07:13,779 --> 00:07:18,669
them back to a vector of employee and

00:07:15,759 --> 00:07:20,979
run the method on that representation

00:07:18,669 --> 00:07:23,199
but it's not very interesting you want

00:07:20,979 --> 00:07:26,439
to execute directly on the new

00:07:23,199 --> 00:07:31,029
representation this is all there is to

00:07:26,439 --> 00:07:33,759
defining a transformation and then the

00:07:31,029 --> 00:07:36,249
application part is all in the hands of

00:07:33,759 --> 00:07:41,080
the compiler I won't go into the details

00:07:36,249 --> 00:07:42,939
of how this works there's a paper on it

00:07:41,080 --> 00:07:46,659
and its pretty long and pretty tedious

00:07:42,939 --> 00:07:49,899
on how it works but I'm more interested

00:07:46,659 --> 00:07:52,269
in showing you some challenges that we

00:07:49,899 --> 00:07:55,659
face during the development and that

00:07:52,269 --> 00:07:58,689
will give you a an idea of how this

00:07:55,659 --> 00:08:02,379
whole thing works and the first

00:07:58,689 --> 00:08:05,409
challenge is open world let's see what

00:08:02,379 --> 00:08:08,289
this is about so we let's look at this

00:08:05,409 --> 00:08:10,990
scenario we we have a vector we have the

00:08:08,289 --> 00:08:13,439
employee class we have the vector of

00:08:10,990 --> 00:08:17,559
employee throughout our code and

00:08:13,439 --> 00:08:19,930
suddenly some one of the developer says

00:08:17,559 --> 00:08:23,680
alright i'll change it to a better

00:08:19,930 --> 00:08:26,529
representation all good and well until

00:08:23,680 --> 00:08:31,360
somebody comes up with a new employee or

00:08:26,529 --> 00:08:35,130
a subclass of the employee which adds a

00:08:31,360 --> 00:08:39,159
department field so what happens then

00:08:35,130 --> 00:08:42,009
well oops it's not really meant to to

00:08:39,159 --> 00:08:45,420
happen and this is the open world

00:08:42,009 --> 00:08:48,550
assumption globally anything can happen

00:08:45,420 --> 00:08:50,360
you could subclass vector you could sub

00:08:48,550 --> 00:08:53,190
class

00:08:50,360 --> 00:08:55,860
you could sub class employee or the

00:08:53,190 --> 00:08:59,640
vector behavior might change what I

00:08:55,860 --> 00:09:02,700
would say is locally in a code base you

00:08:59,640 --> 00:09:05,550
as the programmer have full control you

00:09:02,700 --> 00:09:09,390
know the employee class you can make it

00:09:05,550 --> 00:09:11,279
final or you can say whenever something

00:09:09,390 --> 00:09:14,730
gets into that list if it's not an

00:09:11,279 --> 00:09:18,750
employee class if it's something else we

00:09:14,730 --> 00:09:22,560
reject it and you can also limit the

00:09:18,750 --> 00:09:26,310
code transformation to that code which

00:09:22,560 --> 00:09:28,680
suits your your speculation so that

00:09:26,310 --> 00:09:33,300
parts of the code the parts of the code

00:09:28,680 --> 00:09:36,390
that fulfill the day invariants you you

00:09:33,300 --> 00:09:40,020
want it so how can you do that the

00:09:36,390 --> 00:09:43,830
answer is using scopes what is the scope

00:09:40,020 --> 00:09:46,140
let's look at this method its indexing a

00:09:43,830 --> 00:09:50,160
seller the salary of everybody in a

00:09:46,140 --> 00:09:55,970
company or you will probably recognize

00:09:50,160 --> 00:09:58,710
the syntax if we wrap this scope

00:09:55,970 --> 00:10:01,860
transform with the transformation we

00:09:58,710 --> 00:10:03,900
just defined around this method suddenly

00:10:01,860 --> 00:10:06,510
it will be running on the new

00:10:03,900 --> 00:10:08,670
representation so the interfaces remain

00:10:06,510 --> 00:10:11,339
the same the colors don't need to be

00:10:08,670 --> 00:10:13,830
changed by you they're changed by the

00:10:11,339 --> 00:10:19,980
compiler and suddenly this will be

00:10:13,830 --> 00:10:22,530
faster now da ok so this I said so

00:10:19,980 --> 00:10:25,190
scopes can run rep statements can wrap

00:10:22,530 --> 00:10:27,720
pretty much anything in your code and

00:10:25,190 --> 00:10:31,920
it's in line immediately after the

00:10:27,720 --> 00:10:34,470
parser and definitions inside the scope

00:10:31,920 --> 00:10:38,070
are visible outside and before you ask

00:10:34,470 --> 00:10:40,040
it's not a macro you unfortunately you

00:10:38,070 --> 00:10:43,530
couldn't do that with a macro so

00:10:40,040 --> 00:10:46,700
transform is a is a special marker that

00:10:43,530 --> 00:10:50,490
the compiler with the plug-in recognizes

00:10:46,700 --> 00:10:53,660
okay so what do we use scopes for we

00:10:50,490 --> 00:10:58,080
mark locally closed parts of the code

00:10:53,660 --> 00:11:01,059
that we know can be transformed and in

00:10:58,080 --> 00:11:03,729
values incoming and outgoing from this

00:11:01,059 --> 00:11:05,769
go through our own conversions the

00:11:03,729 --> 00:11:09,189
conversions that we wrote specifically

00:11:05,769 --> 00:11:11,889
and this lets us reject unexpected

00:11:09,189 --> 00:11:14,879
values so if some new programmer doesn't

00:11:11,889 --> 00:11:19,509
know about the rules this will stop them

00:11:14,879 --> 00:11:23,919
and now let's look at another challenge

00:11:19,509 --> 00:11:27,099
namely the the fact that we have let me

00:11:23,919 --> 00:11:29,079
not give it a I won't give you the key

00:11:27,099 --> 00:11:31,359
here tell me what is the best

00:11:29,079 --> 00:11:40,929
representation for a vector of employee

00:11:31,359 --> 00:11:44,049
who thinks they know nobody really

00:11:40,929 --> 00:11:47,049
nobody knows the best okay thank you yes

00:11:44,049 --> 00:11:49,869
that is the answer because it depends

00:11:47,049 --> 00:11:52,749
right it depends on the case if you're

00:11:49,869 --> 00:11:54,699
going to iterate through the impactor of

00:11:52,749 --> 00:11:57,699
employee you're better off with a

00:11:54,699 --> 00:12:01,179
column-oriented storage if you're

00:11:57,699 --> 00:12:03,639
working in memory with the data you will

00:12:01,179 --> 00:12:07,749
probably want some very very compact

00:12:03,639 --> 00:12:10,659
binary representation finally if you're

00:12:07,749 --> 00:12:14,799
working with communicating with a JSON

00:12:10,659 --> 00:12:17,409
server or an XML server you will want to

00:12:14,799 --> 00:12:20,889
store that data in the particular format

00:12:17,409 --> 00:12:23,559
you're going to use the community so it

00:12:20,889 --> 00:12:26,049
really depends what is on your use case

00:12:23,559 --> 00:12:30,429
what is the best representation for your

00:12:26,049 --> 00:12:33,129
data and the scoops allow us to mix the

00:12:30,429 --> 00:12:37,449
representations for example we've seen

00:12:33,129 --> 00:12:41,709
here the index salary method transformed

00:12:37,449 --> 00:12:45,879
with a column-oriented storage now if we

00:12:41,709 --> 00:12:47,979
just change the transformation we use

00:12:45,879 --> 00:12:49,889
for for that scope suddenly we're

00:12:47,979 --> 00:12:52,719
working on a compact binary

00:12:49,889 --> 00:12:55,779
representation or on adjacent based

00:12:52,719 --> 00:12:58,779
representation so it's as easy as it

00:12:55,779 --> 00:13:02,079
gets to change certain parts of the code

00:12:58,779 --> 00:13:04,299
to different representations which

00:13:02,079 --> 00:13:06,849
brings us to the next topic how do you

00:13:04,299 --> 00:13:09,429
compose parts of the code that use

00:13:06,849 --> 00:13:12,069
different transformations for example

00:13:09,429 --> 00:13:13,939
here I have a method that indexes all

00:13:12,069 --> 00:13:18,220
the salaries by 1%

00:13:13,939 --> 00:13:22,039
and it's calling the index salary method

00:13:18,220 --> 00:13:25,220
which is transformed so here we have a

00:13:22,039 --> 00:13:27,829
call from some code that has not been

00:13:25,220 --> 00:13:30,139
transformed to some code that has been

00:13:27,829 --> 00:13:33,259
transformed so we have original code and

00:13:30,139 --> 00:13:38,509
transformed code and how do we handle

00:13:33,259 --> 00:13:42,439
calls between them it actually happens

00:13:38,509 --> 00:13:44,629
that we have an entire array of cases to

00:13:42,439 --> 00:13:47,839
cover original code or transform code

00:13:44,629 --> 00:13:50,479
calling all these cases and i'm going to

00:13:47,839 --> 00:13:54,259
show you what happens in some of these

00:13:50,479 --> 00:13:57,799
cases so for example if we have original

00:13:54,259 --> 00:14:00,109
code calling original code that's easy

00:13:57,799 --> 00:14:02,539
we don't need to do anything nothing is

00:14:00,109 --> 00:14:05,389
transformed what about the cases where

00:14:02,539 --> 00:14:09,519
some original code calls transform core

00:14:05,389 --> 00:14:12,489
code or vice versa well the compiler

00:14:09,519 --> 00:14:14,929
automatically figures this and

00:14:12,489 --> 00:14:17,659
introduces conversions at the right

00:14:14,929 --> 00:14:20,029
places for example we could switch from

00:14:17,659 --> 00:14:22,569
the column-oriented storage to the role

00:14:20,029 --> 00:14:27,679
oriented storage we had before or back

00:14:22,569 --> 00:14:30,289
as necessary now another question is

00:14:27,679 --> 00:14:32,720
what happens if you have the vector of

00:14:30,289 --> 00:14:35,599
employee in JSON format and you suddenly

00:14:32,720 --> 00:14:38,769
want to transform it to something else

00:14:35,599 --> 00:14:41,479
to a binary blob let's say this is a

00:14:38,769 --> 00:14:44,659
hard question and it involves

00:14:41,479 --> 00:14:47,179
transforming twice or having an

00:14:44,659 --> 00:14:49,720
optimized transformation conversion

00:14:47,179 --> 00:14:52,909
between the two and maybe the hardest

00:14:49,720 --> 00:14:56,449
case that we have is what happens when

00:14:52,909 --> 00:15:00,319
you have transformed code that oh I'm

00:14:56,449 --> 00:15:03,319
sorry I've no so if you if you have the

00:15:00,319 --> 00:15:05,899
same transformation we don't have to

00:15:03,319 --> 00:15:08,149
introduce any conversions and that works

00:15:05,899 --> 00:15:11,839
even across separate compilation which

00:15:08,149 --> 00:15:15,769
is a very difficult thing because what

00:15:11,839 --> 00:15:17,720
happens is one compilation run has to be

00:15:15,769 --> 00:15:20,359
aware of all the transformations that

00:15:17,720 --> 00:15:23,869
happened in the other compilation runs

00:15:20,359 --> 00:15:25,900
and finally with a different

00:15:23,869 --> 00:15:29,940
transformation that I already told you

00:15:25,900 --> 00:15:31,870
you have to go twice so these are all

00:15:29,940 --> 00:15:34,600
conversions that you have to do

00:15:31,870 --> 00:15:37,510
automatically in the cut the compiler

00:15:34,600 --> 00:15:40,630
does automatically for you and if you

00:15:37,510 --> 00:15:43,690
think so far is very complicated and

00:15:40,630 --> 00:15:46,600
there are many cases think about

00:15:43,690 --> 00:15:50,410
overriding as well this introduces a new

00:15:46,600 --> 00:15:52,870
set of challenges let's take for example

00:15:50,410 --> 00:15:56,170
this printer class that takes a vector

00:15:52,870 --> 00:15:59,020
of tea and just prints the elements to

00:15:56,170 --> 00:16:02,050
the screen and let's define this

00:15:59,020 --> 00:16:05,080
employee printer which extends printer

00:16:02,050 --> 00:16:07,390
of employee the print method in the

00:16:05,080 --> 00:16:11,950
class implements the the one in the

00:16:07,390 --> 00:16:16,210
trait if we were to wrap this class in a

00:16:11,950 --> 00:16:19,720
scope the signature for method print

00:16:16,210 --> 00:16:22,900
would no longer implement the one from

00:16:19,720 --> 00:16:24,940
from the trait so this is a big problem

00:16:22,900 --> 00:16:27,670
this is something that if you were to

00:16:24,940 --> 00:16:30,240
rewrite code on your own you would have

00:16:27,670 --> 00:16:33,400
to go in and define the second method

00:16:30,240 --> 00:16:36,940
the good thing is all these things are

00:16:33,400 --> 00:16:38,650
taken care for you by the compiler so

00:16:36,940 --> 00:16:40,420
once you've defined the data transfer

00:16:38,650 --> 00:16:45,070
data representation transformation

00:16:40,420 --> 00:16:47,740
everything else is automated now let's

00:16:45,070 --> 00:16:51,160
look at some applications to see exactly

00:16:47,740 --> 00:16:53,740
how we can use this for example we've

00:16:51,160 --> 00:16:58,210
shown column-oriented storage that's one

00:16:53,740 --> 00:17:02,110
case and in some benchmarks we got up to

00:16:58,210 --> 00:17:05,740
5x speed up by deploying this

00:17:02,110 --> 00:17:10,120
transformation or for example we can

00:17:05,740 --> 00:17:12,640
retrofit the value class status like you

00:17:10,120 --> 00:17:16,750
haven't for example in Scala native at

00:17:12,640 --> 00:17:20,470
struct we can have this on classes in

00:17:16,750 --> 00:17:22,720
Scala for example a tuple the tuple in

00:17:20,470 --> 00:17:26,080
Scala is specialized but it's not a

00:17:22,720 --> 00:17:28,960
value class so it has to be allocated on

00:17:26,080 --> 00:17:30,790
the heap well we can transform that and

00:17:28,960 --> 00:17:35,740
we can make it allocated on the stack

00:17:30,790 --> 00:17:38,030
and this is pretty ridiculous so it gets

00:17:35,740 --> 00:17:41,060
14 x faster if we

00:17:38,030 --> 00:17:43,310
that in veg parts so it's very important

00:17:41,060 --> 00:17:47,030
to to use the best data representation

00:17:43,310 --> 00:17:49,940
for for your task another example is

00:17:47,030 --> 00:17:53,660
deforestation so probably some of you

00:17:49,940 --> 00:17:56,720
know have half code like this in your

00:17:53,660 --> 00:17:59,510
code bases so you have a list or some

00:17:56,720 --> 00:18:02,360
collection you map once and then you map

00:17:59,510 --> 00:18:05,080
another map function to it and after

00:18:02,360 --> 00:18:08,060
each map what happens is that the

00:18:05,080 --> 00:18:12,470
program computes an intermediate list

00:18:08,060 --> 00:18:15,350
and after adding one it computes an a

00:18:12,470 --> 00:18:18,260
new list after multiplying by 2 it

00:18:15,350 --> 00:18:21,500
computes a new list and finally when you

00:18:18,260 --> 00:18:24,440
call some it gives you the final result

00:18:21,500 --> 00:18:26,810
so this is not really great because we

00:18:24,440 --> 00:18:30,470
could get rid of the intermediate lists

00:18:26,810 --> 00:18:32,390
if you if we know the functions don't

00:18:30,470 --> 00:18:36,280
have any side effects because for

00:18:32,390 --> 00:18:39,710
example if we had print here and here it

00:18:36,280 --> 00:18:43,670
wouldn't be correct to get rid of the

00:18:39,710 --> 00:18:46,550
the lists so we can if we know for

00:18:43,670 --> 00:18:49,760
example as programmers that we our

00:18:46,550 --> 00:18:52,910
functions are pure we can do we can just

00:18:49,760 --> 00:18:56,210
wrap the code in a transformation that

00:18:52,910 --> 00:18:59,840
does deforestation and what will happen

00:18:56,210 --> 00:19:03,200
is each map will accumulate the function

00:18:59,840 --> 00:19:05,840
and these will only be executed the

00:19:03,200 --> 00:19:08,800
functions will only be executed when we

00:19:05,840 --> 00:19:11,690
compute the final result so the sum and

00:19:08,800 --> 00:19:14,750
this is six times faster you could go to

00:19:11,690 --> 00:19:17,510
arbitrary speed ups in this case just

00:19:14,750 --> 00:19:22,070
put more maps or most more filters and

00:19:17,510 --> 00:19:23,990
you get more benefits I also told you

00:19:22,070 --> 00:19:26,540
about functions so I i talked about

00:19:23,990 --> 00:19:29,660
collections so far in containers but

00:19:26,540 --> 00:19:32,480
let's look at also add functions oh I

00:19:29,660 --> 00:19:34,790
wanted to make sure you know that this

00:19:32,480 --> 00:19:37,520
is research so it might not make it into

00:19:34,790 --> 00:19:41,420
a product but you can play with it

00:19:37,520 --> 00:19:43,910
nevertheless this is something on spark

00:19:41,420 --> 00:19:46,310
that I did and just to make sure

00:19:43,910 --> 00:19:49,450
everyone is on the same page I'm going

00:19:46,310 --> 00:19:51,000
to show you a bit about our dd's

00:19:49,450 --> 00:19:53,760
reliable district

00:19:51,000 --> 00:19:57,450
data sets this is one of the key

00:19:53,760 --> 00:20:02,130
abstractions in in spark and an RDD can

00:19:57,450 --> 00:20:04,860
actually have to be into a situation it

00:20:02,130 --> 00:20:08,280
can have primary data which is for

00:20:04,860 --> 00:20:12,270
example data coming from a CSV file or

00:20:08,280 --> 00:20:17,490
can be D right from another rdd which is

00:20:12,270 --> 00:20:21,180
for example by mapping a function and if

00:20:17,490 --> 00:20:23,640
we look at closer how mapping works it's

00:20:21,180 --> 00:20:26,490
usually a function a user a programmer

00:20:23,640 --> 00:20:30,660
gives a function that takes an object X

00:20:26,490 --> 00:20:33,900
and returns an object why but in fact is

00:20:30,660 --> 00:20:38,250
more complicated because the primary

00:20:33,900 --> 00:20:41,340
data is encoded in some format it's

00:20:38,250 --> 00:20:43,680
serialized so before running this

00:20:41,340 --> 00:20:46,890
function we actually need to take the

00:20:43,680 --> 00:20:51,150
encoded data decode it to produce the

00:20:46,890 --> 00:20:54,810
object X and after running the function

00:20:51,150 --> 00:20:56,460
executing and producing object why we

00:20:54,810 --> 00:20:58,890
actually need to encode it back to

00:20:56,460 --> 00:21:00,330
serialize it back down to to some

00:20:58,890 --> 00:21:02,850
representation some encoded

00:21:00,330 --> 00:21:06,300
representation this is not great because

00:21:02,850 --> 00:21:10,410
we need to allocate to objects that we

00:21:06,300 --> 00:21:13,440
could get rid of ok so how could we get

00:21:10,410 --> 00:21:16,740
rid of these objects well if we had a

00:21:13,440 --> 00:21:18,870
modified version of the user function it

00:21:16,740 --> 00:21:23,340
could operate directly on the encoded

00:21:18,870 --> 00:21:26,370
data and output encoded data of course

00:21:23,340 --> 00:21:28,860
it's nowhere near as simple as it looks

00:21:26,370 --> 00:21:30,900
and I'm going to show you some

00:21:28,860 --> 00:21:33,420
challenges that I faced one when trying

00:21:30,900 --> 00:21:35,850
this out so in some cases the

00:21:33,420 --> 00:21:39,000
transformation is not possible you can

00:21:35,850 --> 00:21:43,410
imagine calling outside methods like

00:21:39,000 --> 00:21:47,190
Java methods or Java calling J&I calling

00:21:43,410 --> 00:21:49,800
C code that we cannot transform so what

00:21:47,190 --> 00:21:52,080
we we do in those cases we issue

00:21:49,800 --> 00:21:56,070
compiler warnings we let the programmers

00:21:52,080 --> 00:21:58,110
know that a method is not possible or a

00:21:56,070 --> 00:22:01,309
function is not possible to transform

00:21:58,110 --> 00:22:03,259
and we give them the exact reason

00:22:01,309 --> 00:22:07,610
this is not possible to it's not

00:22:03,259 --> 00:22:09,850
possible to transform it fine also we we

00:22:07,610 --> 00:22:12,710
suggest how to fix the problem or

00:22:09,850 --> 00:22:14,960
enclose the the other method that is not

00:22:12,710 --> 00:22:18,440
transforming a scope or if it's outside

00:22:14,960 --> 00:22:21,710
is for example Java it's not possible to

00:22:18,440 --> 00:22:24,259
do it express it in Scala and this is

00:22:21,710 --> 00:22:26,690
all reusing the the machinery in the

00:22:24,259 --> 00:22:28,999
mini boxing plugins so there's something

00:22:26,690 --> 00:22:35,179
it's not something new it's just reusing

00:22:28,999 --> 00:22:41,320
what exists already ok so internal API

00:22:35,179 --> 00:22:44,539
spark uses iterators everywhere so

00:22:41,320 --> 00:22:46,820
iterators require materializing values I

00:22:44,539 --> 00:22:51,110
had to replace them by pretty complex

00:22:46,820 --> 00:22:55,009
buffers and it took some extensive

00:22:51,110 --> 00:22:58,850
refactoring and rewriting the prototype

00:22:55,009 --> 00:23:01,129
I developed I would actually call it a

00:22:58,850 --> 00:23:03,580
hack rather than a prototype it's a

00:23:01,129 --> 00:23:07,549
modified version of the spark core and

00:23:03,580 --> 00:23:09,399
the rdd the representation data

00:23:07,549 --> 00:23:12,950
representation in the rdd is

00:23:09,399 --> 00:23:17,419
configurable it's quite limited because

00:23:12,950 --> 00:23:19,940
you can only use map map filter and flat

00:23:17,419 --> 00:23:23,119
map that are optimized it's not the full

00:23:19,940 --> 00:23:25,279
set of the full API that is getting

00:23:23,119 --> 00:23:28,779
transformed right now mainly because I

00:23:25,279 --> 00:23:32,539
didn't want to to modify all the code

00:23:28,779 --> 00:23:34,129
but and there are large parts of the

00:23:32,539 --> 00:23:37,399
automation that still need to be done

00:23:34,129 --> 00:23:40,610
but if we take this example of a

00:23:37,399 --> 00:23:42,950
paralyzing a collection mapping

00:23:40,610 --> 00:23:44,899
filtering and then collecting it in

00:23:42,950 --> 00:23:48,950
order automatically does deforestation

00:23:44,899 --> 00:23:52,580
but we can further squeeze about forty

00:23:48,950 --> 00:23:54,529
five percent speed up by tuning the data

00:23:52,580 --> 00:23:59,019
representation in the rd DS and the

00:23:54,529 --> 00:24:01,610
functions so more more details on this

00:23:59,019 --> 00:24:04,369
watch for more details on this watch

00:24:01,610 --> 00:24:09,740
this spark some and talk I gave a while

00:24:04,369 --> 00:24:13,190
ago ok so let's conclude I'm going to

00:24:09,740 --> 00:24:14,560
finish earlier so we have plenty of time

00:24:13,190 --> 00:24:17,600
for quest

00:24:14,560 --> 00:24:21,850
we saw that object oriented composition

00:24:17,600 --> 00:24:24,980
gives us inefficient representations and

00:24:21,850 --> 00:24:27,860
one of one of the solutions we have is

00:24:24,980 --> 00:24:32,060
data centric metaprogramming that lets

00:24:27,860 --> 00:24:33,770
us give the best use the best

00:24:32,060 --> 00:24:36,410
representation for our data and

00:24:33,770 --> 00:24:39,740
everything else is automated by the

00:24:36,410 --> 00:24:43,430
compiler questions is it possible yes

00:24:39,740 --> 00:24:46,100
definitely is it easy now not really

00:24:43,430 --> 00:24:49,340
it's pretty complicated what happens in

00:24:46,100 --> 00:24:52,040
the compiler and I would like to ask you

00:24:49,340 --> 00:24:54,620
whether it's worth it and whether you

00:24:52,040 --> 00:24:58,820
would find use cases for this in your

00:24:54,620 --> 00:25:02,710
projects with this I thank you and for

00:24:58,820 --> 00:25:02,710
more information visit the website

00:25:07,920 --> 00:25:16,230
I see a question there yes you talked

00:25:14,190 --> 00:25:19,530
about this object oriented the

00:25:16,230 --> 00:25:22,440
representation is inefficient I wonder

00:25:19,530 --> 00:25:26,490
has that always been the case or is that

00:25:22,440 --> 00:25:29,850
sort of something that is caused by the

00:25:26,490 --> 00:25:32,700
sort of modern CPU design with a lot of

00:25:29,850 --> 00:25:37,170
caches and stuff or was it the same sort

00:25:32,700 --> 00:25:42,240
of 25 years ago so 25 years ago we

00:25:37,170 --> 00:25:45,900
didn't have that much flexibility all of

00:25:42,240 --> 00:25:48,210
the inefficiency in data representations

00:25:45,900 --> 00:25:50,370
that we use today comes from the fact

00:25:48,210 --> 00:25:53,550
that languages offer us the flexibility

00:25:50,370 --> 00:25:56,250
so the flex what do I mean by

00:25:53,550 --> 00:25:59,760
flexibility for example you can evolve

00:25:56,250 --> 00:26:01,710
the vector implementation you can

00:25:59,760 --> 00:26:04,140
subclass vector you can sub class

00:26:01,710 --> 00:26:06,780
employee and all of these are

00:26:04,140 --> 00:26:10,340
independent of each other and they still

00:26:06,780 --> 00:26:14,010
are able to interoperate if you think of

00:26:10,340 --> 00:26:16,860
a better representation it usually has

00:26:14,010 --> 00:26:19,790
to fix something it has to say all right

00:26:16,860 --> 00:26:22,260
employee doesn't evolve from now or

00:26:19,790 --> 00:26:25,950
vector doesn't involve or neither of

00:26:22,260 --> 00:26:29,400
them evolves so this is I wouldn't say

00:26:25,950 --> 00:26:32,280
it it's a bad thing what we have now I

00:26:29,400 --> 00:26:35,460
would say that it's just something that

00:26:32,280 --> 00:26:39,540
we pay for the flexibility in terms of

00:26:35,460 --> 00:26:43,410
performance did I answer your question

00:26:39,540 --> 00:26:45,960
or well not really maybe can you

00:26:43,410 --> 00:26:48,600
rephrase it okay so so my theory is that

00:26:45,960 --> 00:26:51,540
that this performance boost that you get

00:26:48,600 --> 00:26:54,300
by this perhaps object decomposition

00:26:51,540 --> 00:26:58,560
that you wouldn't get have gotten that

00:26:54,300 --> 00:27:00,630
sort of honor sort of Intel 386 or 0 20

00:26:58,560 --> 00:27:04,320
20 years ago but you will get it on a

00:27:00,630 --> 00:27:07,620
modern CPU okay I see so something that

00:27:04,320 --> 00:27:12,180
when you you mean that something relies

00:27:07,620 --> 00:27:14,520
on the cash for example oh yes it is one

00:27:12,180 --> 00:27:17,460
of the optimizations you can have

00:27:14,520 --> 00:27:19,420
relying on the cash it's not necessarily

00:27:17,460 --> 00:27:23,120
tied 2-2

00:27:19,420 --> 00:27:25,190
the techniques here because you can do

00:27:23,120 --> 00:27:27,500
other optimizations that don't rely

00:27:25,190 --> 00:27:30,170
necessarily on the cash or on some

00:27:27,500 --> 00:27:32,510
features of the processor but generally

00:27:30,170 --> 00:27:35,690
speaking yes you you do some speculation

00:27:32,510 --> 00:27:38,120
where you say I think if I structure my

00:27:35,690 --> 00:27:41,270
data in this way it's going to the

00:27:38,120 --> 00:27:45,070
processor is going to execute faster so

00:27:41,270 --> 00:27:47,510
yes it is related in that sense to to

00:27:45,070 --> 00:27:52,070
modern architectures processor

00:27:47,510 --> 00:27:55,460
architectures yeah yes so I had two

00:27:52,070 --> 00:27:59,630
questions first one is when bypassing

00:27:55,460 --> 00:28:02,330
methods like you shown in the example if

00:27:59,630 --> 00:28:04,490
I don't bypass a method it will there be

00:28:02,330 --> 00:28:07,730
in a conversion if I use that method

00:28:04,490 --> 00:28:09,500
within the one of those scopes so what

00:28:07,730 --> 00:28:11,210
happens if you don't have a bypass

00:28:09,500 --> 00:28:14,330
method first of all you get a warning

00:28:11,210 --> 00:28:16,400
that tells you hey I'm going this is

00:28:14,330 --> 00:28:18,920
suboptimal and the compiler

00:28:16,400 --> 00:28:21,770
automatically converts to the original

00:28:18,920 --> 00:28:24,290
representation which can be very

00:28:21,770 --> 00:28:27,410
expensive right and invokes the method

00:28:24,290 --> 00:28:31,520
this is something that is done to have

00:28:27,410 --> 00:28:34,820
some some version of the code that is

00:28:31,520 --> 00:28:36,920
still valid during compilation son of

00:28:34,820 --> 00:28:39,710
course you'll know yeah so my second

00:28:36,920 --> 00:28:42,350
question is because the actual

00:28:39,710 --> 00:28:44,480
conversion the initial conversion from

00:28:42,350 --> 00:28:47,290
examining your example vector of

00:28:44,480 --> 00:28:50,620
employee to employee vector that would

00:28:47,290 --> 00:28:54,500
require going through the whole vector

00:28:50,620 --> 00:28:56,930
so so we're aware or the where are the

00:28:54,500 --> 00:28:59,270
performance sort of where does it is it

00:28:56,930 --> 00:29:01,630
more performant to do that I suppose you

00:28:59,270 --> 00:29:05,780
have to do have something that does

00:29:01,630 --> 00:29:08,270
multiple iterations over the vector for

00:29:05,780 --> 00:29:10,130
it to actually be more performant do you

00:29:08,270 --> 00:29:13,580
have some kind of cut off where it

00:29:10,130 --> 00:29:18,470
starts paying off that's a very good

00:29:13,580 --> 00:29:20,990
question or in the benchmarks what I did

00:29:18,470 --> 00:29:24,370
was to build up the data structure from

00:29:20,990 --> 00:29:27,590
scratch element by element in which case

00:29:24,370 --> 00:29:30,230
you you build it up directly in the

00:29:27,590 --> 00:29:32,270
optimized representation but I can

00:29:30,230 --> 00:29:33,190
imagine in some cases the cost of

00:29:32,270 --> 00:29:37,100
converge

00:29:33,190 --> 00:29:40,789
would be greater than the cost of that

00:29:37,100 --> 00:29:43,250
the gains that you get and I think this

00:29:40,789 --> 00:29:45,710
is ultimately something that only you as

00:29:43,250 --> 00:29:48,529
a programmer will be able to benchmark

00:29:45,710 --> 00:29:51,080
on a case-by-case basis and decide

00:29:48,529 --> 00:29:54,230
whether an optimization is actually an

00:29:51,080 --> 00:29:58,150
optimization or addy optimization and it

00:29:54,230 --> 00:30:01,039
hurts performance so this is why the

00:29:58,150 --> 00:30:03,710
message I'm trying to send is I put the

00:30:01,039 --> 00:30:06,320
power in your hands it's up to you how

00:30:03,710 --> 00:30:09,260
you use it and how you transform the

00:30:06,320 --> 00:30:19,330
data the compiler does the tedious hard

00:30:09,260 --> 00:30:22,900
work so has it two questions

00:30:19,330 --> 00:30:26,230
I have a on the comment about the

00:30:22,900 --> 00:30:27,940
architectures I think actually the there

00:30:26,230 --> 00:30:30,160
are the ways we use the architectures

00:30:27,940 --> 00:30:32,680
are actually worse in some scenarios

00:30:30,160 --> 00:30:34,450
especially for certain cases like if you

00:30:32,680 --> 00:30:36,700
have the vector of all the arrays I'm

00:30:34,450 --> 00:30:38,800
iterating through in the same cache

00:30:36,700 --> 00:30:41,530
lines I will get better performance no

00:30:38,800 --> 00:30:44,200
matter what version of the harder 386 or

00:30:41,530 --> 00:30:47,980
that modern one will also happen there's

00:30:44,200 --> 00:30:53,140
actually a talk by the guy from forgot

00:30:47,980 --> 00:30:54,580
his name Martin Thompson on how small

00:30:53,140 --> 00:30:56,500
changes to the way you navigate through

00:30:54,580 --> 00:30:59,500
memory will do massive impacts on the

00:30:56,500 --> 00:31:01,270
performance I have so in general just

00:30:59,500 --> 00:31:04,930
good strategies will improve the

00:31:01,270 --> 00:31:06,820
question I have is what's are in your

00:31:04,930 --> 00:31:08,530
experiences have you been trying to see

00:31:06,820 --> 00:31:09,970
for example if I start doing a bunch of

00:31:08,530 --> 00:31:13,030
transformation I might lose information

00:31:09,970 --> 00:31:14,680
especially in the data rich context

00:31:13,030 --> 00:31:17,260
might be hard to check so is there a way

00:31:14,680 --> 00:31:20,080
to do this should I try small and then

00:31:17,260 --> 00:31:21,970
scale up or how do I approach this

00:31:20,080 --> 00:31:26,320
practically as I put more and more

00:31:21,970 --> 00:31:29,230
transformations yes thank you for that

00:31:26,320 --> 00:31:32,830
question that's that's a tough one so I

00:31:29,230 --> 00:31:36,640
wouldn't know how to you can start small

00:31:32,830 --> 00:31:39,880
of course and see how it scales up if it

00:31:36,640 --> 00:31:42,240
scales in all cases if you have usually

00:31:39,880 --> 00:31:45,430
what will happen in my experience what

00:31:42,240 --> 00:31:47,950
developing these transformations is I

00:31:45,430 --> 00:31:49,990
get guided by the compiler the compiler

00:31:47,950 --> 00:31:52,390
starts telling me hey you need to also

00:31:49,990 --> 00:31:54,880
add this bypass method or you have a

00:31:52,390 --> 00:31:57,040
double conversion here could you please

00:31:54,880 --> 00:32:01,870
add the direct conversion between these

00:31:57,040 --> 00:32:04,450
two and as I add more code to the code

00:32:01,870 --> 00:32:08,620
base I transform I constantly get these

00:32:04,450 --> 00:32:10,590
warnings that's basically tell me what

00:32:08,620 --> 00:32:14,050
is the next step that needs to be done I

00:32:10,590 --> 00:32:16,210
don't know if I answer your question

00:32:14,050 --> 00:32:19,840
entirely because I don't have the

00:32:16,210 --> 00:32:22,150
experience of a huge code base even the

00:32:19,840 --> 00:32:25,450
spark or the part that I modified I

00:32:22,150 --> 00:32:30,880
still consider it rather small it's in

00:32:25,450 --> 00:32:32,840
the order of let's say k lines of code

00:32:30,880 --> 00:32:36,320
so it's not

00:32:32,840 --> 00:32:40,309
huge in the sense of tens of thousands

00:32:36,320 --> 00:32:44,000
of lines so there was a talk yesterday

00:32:40,309 --> 00:32:47,210
about the dotty linker and it also

00:32:44,000 --> 00:32:50,380
allows rewriting of cold what's the

00:32:47,210 --> 00:32:56,659
relationship between these two solutions

00:32:50,380 --> 00:32:59,750
um so I guess the yes so the the main

00:32:56,659 --> 00:33:05,450
difference the way I perceive it right

00:32:59,750 --> 00:33:09,110
now is in the dolly linker you have more

00:33:05,450 --> 00:33:11,630
syntactic rules for transforming the

00:33:09,110 --> 00:33:13,520
code such as for example if you have two

00:33:11,630 --> 00:33:19,070
maps one happening one after the other

00:33:13,520 --> 00:33:23,809
you rewrite that to a single map but the

00:33:19,070 --> 00:33:25,610
focus is on transforming code the

00:33:23,809 --> 00:33:29,029
transforming the code itself of course

00:33:25,610 --> 00:33:31,700
you can you can put you can constrain

00:33:29,029 --> 00:33:35,500
the types of those expressions involved

00:33:31,700 --> 00:33:38,690
on the other hand what I present here is

00:33:35,500 --> 00:33:40,640
focused on the data so you want to

00:33:38,690 --> 00:33:45,440
transform not the code the code is a

00:33:40,640 --> 00:33:48,679
secondary concern the main point is to

00:33:45,440 --> 00:33:51,260
transform the way data is represented so

00:33:48,679 --> 00:33:54,169
the the rewrite rules as far as i know

00:33:51,260 --> 00:33:56,149
will not transform the inner data

00:33:54,169 --> 00:34:00,370
representation will only transform the

00:33:56,149 --> 00:34:04,210
code to make it more efficient outside

00:34:00,370 --> 00:34:04,210
did answer your question

00:34:07,470 --> 00:34:12,520
yeah can you put a bit more light on

00:34:10,330 --> 00:34:15,909
wise is the reference in in case of

00:34:12,520 --> 00:34:18,610
employee is on is slow so basically what

00:34:15,909 --> 00:34:23,310
resource suffering more is it CPU cycles

00:34:18,610 --> 00:34:28,030
for like what why is it slow okay so it

00:34:23,310 --> 00:34:32,110
depends a lot on Honda youth the case so

00:34:28,030 --> 00:34:34,179
in some cases your CPU bound in other

00:34:32,110 --> 00:34:38,200
cases your memory bound in other cases

00:34:34,179 --> 00:34:42,510
your i/o bound but the typical problem

00:34:38,200 --> 00:34:46,060
that this solution will resolve is

00:34:42,510 --> 00:34:49,929
memory bound operations so things that

00:34:46,060 --> 00:34:52,929
you do in memory but you do so

00:34:49,929 --> 00:34:55,360
inefficiently that you could do much

00:34:52,929 --> 00:34:58,620
better if you didn't if you used a

00:34:55,360 --> 00:35:01,740
different way to structure the data

00:34:58,620 --> 00:35:01,740
thank you

00:35:03,790 --> 00:35:07,410
see one question there

00:35:15,480 --> 00:35:23,830
yes maybe this was answered yearn to

00:35:18,400 --> 00:35:26,950
talk but before this there was a talk

00:35:23,830 --> 00:35:29,220
from a gene about scala meta with this

00:35:26,950 --> 00:35:31,930
like how does that how does

00:35:29,220 --> 00:35:34,510
metaprogramming relate to this for me

00:35:31,930 --> 00:35:35,770
looking from the outside science scenes

00:35:34,510 --> 00:35:38,130
that you could do a lot of the same

00:35:35,770 --> 00:35:42,460
things but are there any sort of

00:35:38,130 --> 00:35:45,010
restrictions or limitations when

00:35:42,460 --> 00:35:48,070
compared so it's meta programming is is

00:35:45,010 --> 00:35:51,490
is a very broad topic and especially the

00:35:48,070 --> 00:35:55,090
way Eugene sees it it means changing

00:35:51,490 --> 00:36:01,050
anything in your program in any way

00:35:55,090 --> 00:36:03,180
possible and to some extent I feel that

00:36:01,050 --> 00:36:07,030
constraining it a little bit and

00:36:03,180 --> 00:36:10,150
focusing it on on a specific topic can

00:36:07,030 --> 00:36:13,240
give you more tangible results such as

00:36:10,150 --> 00:36:16,750
this data centric metaprogramming it's

00:36:13,240 --> 00:36:20,940
aimed at a single use case data

00:36:16,750 --> 00:36:23,530
representation it's much more limited

00:36:20,940 --> 00:36:25,180
but on the other hand it doesn't have

00:36:23,530 --> 00:36:28,410
all the complexity that you would have

00:36:25,180 --> 00:36:31,500
in writing a macro for example that

00:36:28,410 --> 00:36:35,980
transforms the code in such a way that

00:36:31,500 --> 00:36:40,360
would get you the same benefits ok thank

00:36:35,980 --> 00:36:43,840
you I've just seen any positive impact

00:36:40,360 --> 00:36:46,300
on the garbage collection or commenting

00:36:43,840 --> 00:36:50,560
on the garbage collection or I don't

00:36:46,300 --> 00:36:53,130
have so much experience with with

00:36:50,560 --> 00:36:58,090
problems related to garbage collection

00:36:53,130 --> 00:37:00,850
but what I can say is every time you you

00:36:58,090 --> 00:37:04,230
lower the hip footprint you're less

00:37:00,850 --> 00:37:07,920
likely to run into GC problems and

00:37:04,230 --> 00:37:10,060
that's a trade-off I mean most of these

00:37:07,920 --> 00:37:13,690
transformations are probably going to

00:37:10,060 --> 00:37:18,100
get rid of some alignment some object

00:37:13,690 --> 00:37:20,110
headers which might will will reduce the

00:37:18,100 --> 00:37:22,510
memory footprint of course you could

00:37:20,110 --> 00:37:25,960
write a data transfer me and data

00:37:22,510 --> 00:37:28,690
transformation that gives you better

00:37:25,960 --> 00:37:31,000
speed up at the trade-off of

00:37:28,690 --> 00:37:34,230
using more memory in which case you

00:37:31,000 --> 00:37:37,089
might be running into some GC trouble

00:37:34,230 --> 00:37:41,440
did I answer your question is the

00:37:37,089 --> 00:37:44,190
interview thank you one more question

00:37:41,440 --> 00:37:44,190
there

00:37:49,960 --> 00:37:56,800
I'm wondering about this object

00:37:53,970 --> 00:37:58,750
decomposition again this column oriented

00:37:56,800 --> 00:38:01,599
way of storing them when you have

00:37:58,750 --> 00:38:04,900
strings or you'd answer on concatenating

00:38:01,599 --> 00:38:08,380
all the strings in a single object or in

00:38:04,900 --> 00:38:13,540
some way or so this has been an ongoing

00:38:08,380 --> 00:38:16,119
discussion that the Java architects have

00:38:13,540 --> 00:38:20,619
been thinking a lot about what is the

00:38:16,119 --> 00:38:24,820
best way to to merge strings lazily or

00:38:20,619 --> 00:38:28,950
eagerly and it's really down to each

00:38:24,820 --> 00:38:32,440
case what is the best thing to do or

00:38:28,950 --> 00:38:35,890
what I can say is you start off with

00:38:32,440 --> 00:38:38,290
strings and using a data representation

00:38:35,890 --> 00:38:41,650
transformation you can go either way you

00:38:38,290 --> 00:38:44,290
can eagerly march strings concatenate

00:38:41,650 --> 00:38:46,869
strings or you can make it lazily it's

00:38:44,290 --> 00:38:50,730
up to you it gives you as the programmer

00:38:46,869 --> 00:38:59,560
the power to choose what is the best way

00:38:50,730 --> 00:39:01,780
depends a lot on on your program okay so

00:38:59,560 --> 00:39:04,740
I don't see any more questions thank you

00:39:01,780 --> 00:39:04,740
all for being here

00:39:09,829 --> 00:39:11,890

YouTube URL: https://www.youtube.com/watch?v=jYAVHzpw0Ys


