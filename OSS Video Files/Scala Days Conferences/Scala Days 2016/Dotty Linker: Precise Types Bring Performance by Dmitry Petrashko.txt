Title: Dotty Linker: Precise Types Bring Performance by Dmitry Petrashko
Publication date: 2017-01-19
Playlist: Scala Days 2016
Description: 
	This video was recorded at Scala Days Berlin 2016
follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Abstract:
Common arguments for using more elaborate type systems include safety and documentation. But we will show how more expressive type systems can be used to drive novel powerful optimizations and make the program faster. Based on this principle, we built the Dotty Linker, a whole-program optimizer that represents a breakthrough in optimization of Scala code. We will demonstrate how the linker is capable of reducing the performance overhead of commonly-used Scala features such as generic methods and classes, lazy vals, implicit conversions and closures.
Captions: 
	00:00:03,310 --> 00:00:09,460
my name is Dmitri Petrov co I'm student

00:00:06,640 --> 00:00:13,360
of Martin Luther ski working under his

00:00:09,460 --> 00:00:15,820
supervision and i'm here to present you

00:00:13,360 --> 00:00:19,689
one of the new parts of the ecosystem of

00:00:15,820 --> 00:00:23,499
doing so yeah you can find me on github

00:00:19,689 --> 00:00:25,810
I'm dark dimas ever were before this I

00:00:23,499 --> 00:00:27,699
have been working on macro generated

00:00:25,810 --> 00:00:29,820
collections first scala which were

00:00:27,699 --> 00:00:32,110
substantially faster than the current

00:00:29,820 --> 00:00:34,329
both standard and parallel collections

00:00:32,110 --> 00:00:37,390
and while doing on this end the stood

00:00:34,329 --> 00:00:40,150
that there's a lot to be improved about

00:00:37,390 --> 00:00:43,120
both memory layout and performance of

00:00:40,150 --> 00:00:44,860
scholar generated by code so in order to

00:00:43,120 --> 00:00:47,230
implement it not only for collections

00:00:44,860 --> 00:00:49,750
but for arbitrary is color code I've

00:00:47,230 --> 00:00:53,980
joined Martin in effort in building the

00:00:49,750 --> 00:00:57,810
new compiler darling and we've succeeded

00:00:53,980 --> 00:00:59,800
in building it I would say and since

00:00:57,810 --> 00:01:02,320
thought a bootstrapped I have been

00:00:59,800 --> 00:01:05,019
working on making the optimizer part of

00:01:02,320 --> 00:01:06,549
Dottie which is Dottie linker and I'm

00:01:05,019 --> 00:01:09,490
also supervising new students who now

00:01:06,549 --> 00:01:10,899
breakin da ting so to say that I worked

00:01:09,490 --> 00:01:13,270
on Dottie you can have a look at this

00:01:10,899 --> 00:01:15,130
graph where you can see that more or

00:01:13,270 --> 00:01:17,109
less if you have a bug in Dottie the

00:01:15,130 --> 00:01:19,390
like foot of me introducing this bug is

00:01:17,109 --> 00:01:24,310
s hi but a bit bigger than like it

00:01:19,390 --> 00:01:29,789
Martin introducing this book so I'm also

00:01:24,310 --> 00:01:32,619
the person likely to fix it yeah ok so

00:01:29,789 --> 00:01:35,950
this talk will be about how to build

00:01:32,619 --> 00:01:38,289
fast Scala code how to compile Scala in

00:01:35,950 --> 00:01:40,210
too fast code in order to understand

00:01:38,289 --> 00:01:43,799
what's fast code we need to first

00:01:40,210 --> 00:01:46,299
understand why why there is a

00:01:43,799 --> 00:01:48,399
possibility for improvement why Scala

00:01:46,299 --> 00:01:51,189
can be faster what makes calais slower

00:01:48,399 --> 00:01:53,799
now so there are two reasons for it to

00:01:51,189 --> 00:01:55,929
be slow we in every particular

00:01:53,799 --> 00:01:58,600
application this long as can either come

00:01:55,929 --> 00:02:00,969
from the library which is inefficient or

00:01:58,600 --> 00:02:03,219
from the user code which means uses the

00:02:00,969 --> 00:02:05,770
library and uses the efficient library

00:02:03,219 --> 00:02:09,580
in inefficient ways I will cover both of

00:02:05,770 --> 00:02:11,050
these topics during my talk so ok i'll

00:02:09,580 --> 00:02:14,500
start with the library as a source of

00:02:11,050 --> 00:02:16,450
slow down so if we consider this two

00:02:14,500 --> 00:02:17,060
examples of code one written in java and

00:02:16,450 --> 00:02:20,420
the other

00:02:17,060 --> 00:02:21,950
color the skela one is a lot easier to

00:02:20,420 --> 00:02:24,880
follow it's clear what it done in degree

00:02:21,950 --> 00:02:27,319
what it does I like this code a lot more

00:02:24,880 --> 00:02:30,410
Java is quite verbose you need to write

00:02:27,319 --> 00:02:31,970
an explicit cycle and we could spend

00:02:30,410 --> 00:02:33,580
more time writing it and potentially

00:02:31,970 --> 00:02:35,989
introduce more bugs by writing it wrong

00:02:33,580 --> 00:02:40,190
but unfortunately the Java code runs

00:02:35,989 --> 00:02:41,989
faster and the reason here is actually

00:02:40,190 --> 00:02:44,599
in the Scala collections library in the

00:02:41,989 --> 00:02:47,599
source of slow down so why does it run

00:02:44,599 --> 00:02:49,850
slower let's compare what does java do

00:02:47,599 --> 00:02:52,280
here near and what does Scala code do

00:02:49,850 --> 00:02:54,440
here in case of Java you have the range

00:02:52,280 --> 00:02:55,760
check here so for every iteration of

00:02:54,440 --> 00:02:57,560
cycle you're checking if you need to do

00:02:55,760 --> 00:02:59,209
the next declaration of cycle you're

00:02:57,560 --> 00:03:02,750
actually going to do the addition that

00:02:59,209 --> 00:03:04,400
we're looking for and then you'll do the

00:03:02,750 --> 00:03:06,319
index increment so you're doing three

00:03:04,400 --> 00:03:08,120
operations forever iteration of a cycle

00:03:06,319 --> 00:03:10,760
and all of those operations are really

00:03:08,120 --> 00:03:14,890
fast compare this with Scala we're

00:03:10,760 --> 00:03:19,160
actually the reduce function itself is

00:03:14,890 --> 00:03:21,350
implemented in terms of for each and it

00:03:19,160 --> 00:03:24,920
creates a lamb that will be passed there

00:03:21,350 --> 00:03:27,230
so similarly to Java value we're doing

00:03:24,920 --> 00:03:28,220
arranged so we're doing a summation of a

00:03:27,230 --> 00:03:31,880
collection here we need to do a

00:03:28,220 --> 00:03:33,980
raincheck here then because we're being

00:03:31,880 --> 00:03:36,709
abstract we're working in a race world

00:03:33,980 --> 00:03:39,049
well we have functions which are already

00:03:36,709 --> 00:03:40,910
raised they work of our objects well

00:03:39,049 --> 00:03:43,040
when you'll be extracting this element

00:03:40,910 --> 00:03:45,440
here from an array you'll need to box it

00:03:43,040 --> 00:03:48,079
to be able to generically work over all

00:03:45,440 --> 00:03:51,079
kinds of elements of collections that

00:03:48,079 --> 00:03:53,389
there could be and so will reduce in

00:03:51,079 --> 00:03:55,489
boxing that wasn't there in Java we're

00:03:53,389 --> 00:03:57,680
also having the operation being passed

00:03:55,489 --> 00:03:58,850
as a lambda compiler doesn't know and

00:03:57,680 --> 00:04:00,290
the M doesn't know what kind of

00:03:58,850 --> 00:04:02,359
operation is it anymore so we'll have a

00:04:00,290 --> 00:04:05,030
dynamic dispatch here we'll have a

00:04:02,359 --> 00:04:06,560
predicate check because the reduce don't

00:04:05,030 --> 00:04:08,720
have the start an element the zero

00:04:06,560 --> 00:04:10,489
element we didn't initialize the

00:04:08,720 --> 00:04:13,519
accumulators with it in Java explicitly

00:04:10,489 --> 00:04:16,579
so we'll have one more branch / every

00:04:13,519 --> 00:04:19,370
iteration here and we'll have one more

00:04:16,579 --> 00:04:20,900
dispatch because the reduce itself also

00:04:19,370 --> 00:04:23,990
doesn't know what kind of reduction

00:04:20,900 --> 00:04:25,760
operation does it do and then finally

00:04:23,990 --> 00:04:28,700
you're going to do addition inside the

00:04:25,760 --> 00:04:30,650
soap apply but when you'll do addition

00:04:28,700 --> 00:04:32,600
you'll need to return it once again too

00:04:30,650 --> 00:04:34,250
our orbital location which doesn't know

00:04:32,600 --> 00:04:36,169
that it works on primitives sealed box

00:04:34,250 --> 00:04:38,389
at once again and then finally we'll do

00:04:36,169 --> 00:04:40,940
in index increment so you're doing a lot

00:04:38,389 --> 00:04:43,580
more stuff than Java was doing this is

00:04:40,940 --> 00:04:45,889
the cost of Hugh being generic and being

00:04:43,580 --> 00:04:48,320
apps a ballistic over all the things and

00:04:45,889 --> 00:04:50,840
just to give you a small baseline to

00:04:48,320 --> 00:04:53,780
know how much does it stuff cost single

00:04:50,840 --> 00:04:56,270
boxing or single allocation costs on

00:04:53,780 --> 00:04:58,430
average as much as five dynamic

00:04:56,270 --> 00:05:00,889
dispatches and by dynamic dispatches I

00:04:58,430 --> 00:05:02,270
mean that then dispatches which happen

00:05:00,889 --> 00:05:03,889
to be mega morphic where there are

00:05:02,270 --> 00:05:07,190
multiple targets where they can dispatch

00:05:03,889 --> 00:05:09,380
to every dynamic dispatch is more or

00:05:07,190 --> 00:05:10,610
less equivalent to three static

00:05:09,380 --> 00:05:12,380
dispatches where there is this either

00:05:10,610 --> 00:05:14,210
your call in a static method or a

00:05:12,380 --> 00:05:15,680
private method or there is the only a

00:05:14,210 --> 00:05:17,630
single method that reaches this call

00:05:15,680 --> 00:05:20,570
site in runtime and all of this cost

00:05:17,630 --> 00:05:22,729
more than additions so all the all the

00:05:20,570 --> 00:05:24,620
things that Skylar introduced actually

00:05:22,729 --> 00:05:26,240
cost a lot more than the operations

00:05:24,620 --> 00:05:27,770
we've been performing I'm kind of

00:05:26,240 --> 00:05:31,490
looking at the worst case example here

00:05:27,770 --> 00:05:33,580
to be honest but the same thing happened

00:05:31,490 --> 00:05:37,190
on a smaller scale in all the Scala code

00:05:33,580 --> 00:05:40,810
so the reason why these inefficiencies

00:05:37,190 --> 00:05:45,260
are they're actually good things because

00:05:40,810 --> 00:05:48,289
Scala is built to help you be productive

00:05:45,260 --> 00:05:49,729
it's helpful it allows library archers

00:05:48,289 --> 00:05:54,470
to build awesome libraries which

00:05:49,729 --> 00:05:57,110
developers can use in a way which allows

00:05:54,470 --> 00:05:59,479
them to write small amount of code which

00:05:57,110 --> 00:06:01,970
allows them to reach their goal fast

00:05:59,479 --> 00:06:06,139
they do it by having higher order types

00:06:01,970 --> 00:06:09,919
which includes it allow us to have

00:06:06,139 --> 00:06:12,139
Scala's EE shapeless and all the funny

00:06:09,919 --> 00:06:14,510
stuff in type level world we have

00:06:12,139 --> 00:06:16,099
generic methods like Java has we have

00:06:14,510 --> 00:06:18,229
generic classes we have multiple

00:06:16,099 --> 00:06:19,520
inheritance you may argue that Java has

00:06:18,229 --> 00:06:22,220
it but it doesn't have multiple

00:06:19,520 --> 00:06:23,990
inheritance of fields so we have better

00:06:22,220 --> 00:06:25,130
matching we have lazy evaluation we have

00:06:23,990 --> 00:06:28,479
garbage collection we have all the

00:06:25,130 --> 00:06:31,820
features which make you happy

00:06:28,479 --> 00:06:35,840
unfortunately if we consider all these

00:06:31,820 --> 00:06:38,599
features gvm has doesn't have any of

00:06:35,840 --> 00:06:40,669
them it does and all of these features

00:06:38,599 --> 00:06:43,390
make sure we are not happy those

00:06:40,669 --> 00:06:47,470
features don't exist in

00:06:43,390 --> 00:06:49,750
time it means that when compiler

00:06:47,470 --> 00:06:51,280
compiles the code it needs to express

00:06:49,750 --> 00:06:54,760
these features in the language which

00:06:51,280 --> 00:06:56,890
hotspot understands and in this case it

00:06:54,760 --> 00:07:00,580
means compiling them in a very

00:06:56,890 --> 00:07:02,830
conservative way because as we introduce

00:07:00,580 --> 00:07:06,580
them in order to allow you to express

00:07:02,830 --> 00:07:08,710
more stuff we can't assume that you're

00:07:06,580 --> 00:07:10,480
going to express only a subset of things

00:07:08,710 --> 00:07:13,030
that you could have that you could do

00:07:10,480 --> 00:07:15,160
all the crazy stuff all the scary stuff

00:07:13,030 --> 00:07:18,340
and because of this we need to do it in

00:07:15,160 --> 00:07:21,240
the most conservative way possible to

00:07:18,340 --> 00:07:23,740
make your application run correctly and

00:07:21,240 --> 00:07:30,310
because of this conservative lowering

00:07:23,740 --> 00:07:32,590
skylights lower so here they we went for

00:07:30,310 --> 00:07:35,050
the way to make you efficient to make

00:07:32,590 --> 00:07:36,370
the programmer be more efficient in

00:07:35,050 --> 00:07:37,930
writing their code because we have

00:07:36,370 --> 00:07:41,380
assumptions that servers are easier to

00:07:37,930 --> 00:07:43,780
buy than programmers but if you're are

00:07:41,380 --> 00:07:47,490
actually performance-oriented if you

00:07:43,780 --> 00:07:50,140
need high performance it may be a

00:07:47,490 --> 00:07:53,860
decisions that we took initially can

00:07:50,140 --> 00:07:55,710
slow you down to illustrate this on a

00:07:53,860 --> 00:07:59,680
small example let's consider a function

00:07:55,710 --> 00:08:02,860
which does just addition of two things

00:07:59,680 --> 00:08:06,010
to do and it doesn't know yet what kind

00:08:02,860 --> 00:08:07,180
of things does it add so in order

00:08:06,010 --> 00:08:08,440
because it doesn't know what kind of

00:08:07,180 --> 00:08:10,870
things does it add it miss anomeric

00:08:08,440 --> 00:08:14,590
which will actually define how are these

00:08:10,870 --> 00:08:16,330
things added one compiler compiles it

00:08:14,590 --> 00:08:19,000
because it doesn't know anything about

00:08:16,330 --> 00:08:20,980
the t's here the tea can be integer that

00:08:19,000 --> 00:08:23,950
he can be double like Dickon below the

00:08:20,980 --> 00:08:25,930
tea can be complex it needs to go to the

00:08:23,950 --> 00:08:28,960
most conservative tape type possible and

00:08:25,930 --> 00:08:30,940
the only common type here is object this

00:08:28,960 --> 00:08:32,710
is an example of boxing which is the

00:08:30,940 --> 00:08:35,320
slowest thing that I showed you in the

00:08:32,710 --> 00:08:38,500
compare in comparison of performance so

00:08:35,320 --> 00:08:40,780
when you +1 +1 here in order for this

00:08:38,500 --> 00:08:43,330
one's to actually reach the body of plus

00:08:40,780 --> 00:08:45,520
they need to be boxed and the return

00:08:43,330 --> 00:08:47,380
type similarly will be an object so if

00:08:45,520 --> 00:08:50,740
you're going to use it in a decent way

00:08:47,380 --> 00:08:52,090
you're going to unbox it so in this case

00:08:50,740 --> 00:08:54,700
you can actually spend a lot more time

00:08:52,090 --> 00:08:57,030
preparing to call the function than

00:08:54,700 --> 00:09:02,710
actually doing the work that you ask

00:08:57,030 --> 00:09:04,900
so Scala and Java here went through the

00:09:02,710 --> 00:09:07,150
approach war that all the generics are

00:09:04,900 --> 00:09:09,190
compared compiled in the same way you're

00:09:07,150 --> 00:09:11,920
doing one conservative compilation of

00:09:09,190 --> 00:09:14,320
all the code that you have but some

00:09:11,920 --> 00:09:17,560
languages like C++ went the other way

00:09:14,320 --> 00:09:19,360
they started doing clones of the methods

00:09:17,560 --> 00:09:21,930
they started doing clones of the classes

00:09:19,360 --> 00:09:24,940
which are compiled different way so

00:09:21,930 --> 00:09:27,370
let's consider a different option yes

00:09:24,940 --> 00:09:29,860
hipot adigal option what if compiler did

00:09:27,370 --> 00:09:32,260
it the other way and it did multiple

00:09:29,860 --> 00:09:34,150
classes so we have 1 plus frames we have

00:09:32,260 --> 00:09:36,580
1 plus for long so we can have 1 plus

00:09:34,150 --> 00:09:38,620
four doubles now we can call plus four

00:09:36,580 --> 00:09:40,480
insufficiently we don't need to box it

00:09:38,620 --> 00:09:45,010
anymore but we'll have a different

00:09:40,480 --> 00:09:48,820
problem Scala has nine privetik types we

00:09:45,010 --> 00:09:50,980
have five types for integer types we

00:09:48,820 --> 00:09:52,960
have floats bo that doubles booleans

00:09:50,980 --> 00:09:56,230
androids we also have an object type

00:09:52,960 --> 00:09:57,670
reference type and it means that if

00:09:56,230 --> 00:10:00,850
we'll do specialization if we won't do

00:09:57,670 --> 00:10:02,740
it for complex types it means you'll

00:10:00,850 --> 00:10:07,180
have to splash splash and generate

00:10:02,740 --> 00:10:09,280
different versions for 10 types in case

00:10:07,180 --> 00:10:11,740
you have a class with anti parameters

00:10:09,280 --> 00:10:13,870
you'll need to specialize every of those

00:10:11,740 --> 00:10:15,720
n type parameters for every type that

00:10:13,870 --> 00:10:17,440
yours is that you're considering

00:10:15,720 --> 00:10:20,080
unfortunately it means it will have

00:10:17,440 --> 00:10:23,260
exponential explosion of how much code

00:10:20,080 --> 00:10:25,060
you generate it becomes even worse if

00:10:23,260 --> 00:10:27,820
you have generic methods in generic

00:10:25,060 --> 00:10:29,860
classes because then you'll have number

00:10:27,820 --> 00:10:32,500
of argument the types that you need to

00:10:29,860 --> 00:10:34,680
specialized for will be both types of

00:10:32,500 --> 00:10:37,570
the class and types of the method itself

00:10:34,680 --> 00:10:40,240
so you'll be exponential over the sum of

00:10:37,570 --> 00:10:43,480
number of type arguments it means that

00:10:40,240 --> 00:10:48,670
for decent classes like functions like

00:10:43,480 --> 00:10:50,200
function 314 function for fix for

00:10:48,670 --> 00:10:53,530
arguments and returns one type it has

00:10:50,200 --> 00:10:56,050
five type parameters specializing each

00:10:53,530 --> 00:10:58,000
and generate you know the code will be

00:10:56,050 --> 00:11:03,370
bigger than the whole standard library

00:10:58,000 --> 00:11:06,970
and whole acha library together so in

00:11:03,370 --> 00:11:10,070
order to solve this problem six years

00:11:06,970 --> 00:11:14,820
ago you land rush

00:11:10,070 --> 00:11:17,430
decided to ask user that there did he

00:11:14,820 --> 00:11:19,080
that he tried that you maybe not need to

00:11:17,430 --> 00:11:21,480
all the specializations for example I

00:11:19,080 --> 00:11:23,610
don't think that a lot of you are using

00:11:21,480 --> 00:11:29,790
functions which take for voids and

00:11:23,610 --> 00:11:33,210
return the void neither are you likely

00:11:29,790 --> 00:11:36,900
to use functions which take seven

00:11:33,210 --> 00:11:41,130
characters and return of voids or a

00:11:36,900 --> 00:11:42,720
boolean so in order to do is to decide

00:11:41,130 --> 00:11:44,490
what functions make sense to specialized

00:11:42,720 --> 00:11:47,370
or not you die next user so we introduce

00:11:44,490 --> 00:11:49,440
a specialized annotation which allowed

00:11:47,370 --> 00:11:51,470
you to mark type arguments which you

00:11:49,440 --> 00:11:55,190
believe are crucial for performance and

00:11:51,470 --> 00:11:58,080
to say what type specialized them for

00:11:55,190 --> 00:12:00,420
because this was the early the first

00:11:58,080 --> 00:12:03,540
implementation of a prototype it has

00:12:00,420 --> 00:12:04,890
some limitations one limitation is it

00:12:03,540 --> 00:12:05,880
doesn't support inheritance if you

00:12:04,890 --> 00:12:08,040
inherit a class which has

00:12:05,880 --> 00:12:10,740
specializations the inherited versions

00:12:08,040 --> 00:12:13,410
are not specialized the other limitation

00:12:10,740 --> 00:12:15,450
is that if you have fields in your class

00:12:13,410 --> 00:12:17,310
fields will be duplicated you'll have

00:12:15,450 --> 00:12:19,920
both specialized and non specialized

00:12:17,310 --> 00:12:23,940
fields so you'll get a hit of in terms

00:12:19,920 --> 00:12:25,980
of memory layout well the years passed

00:12:23,940 --> 00:12:28,470
and we had one more student in Martin's

00:12:25,980 --> 00:12:30,360
lab blood oh heck I have been trying to

00:12:28,470 --> 00:12:34,710
improve over it by introducing the me

00:12:30,360 --> 00:12:37,290
bak stellar annotation he understood

00:12:34,710 --> 00:12:39,150
that all the primitive types can

00:12:37,290 --> 00:12:41,310
actually be encoded you don't need in

00:12:39,150 --> 00:12:44,370
total the primitive type separately ins

00:12:41,310 --> 00:12:46,920
can be represented by longs as well as

00:12:44,370 --> 00:12:50,190
shorts can floats can be represented by

00:12:46,920 --> 00:12:51,990
doubles so he changed the encoding to

00:12:50,190 --> 00:12:54,839
instead of having 10 to the power of n

00:12:51,990 --> 00:12:56,790
have 3 to the power of n and it and by

00:12:54,839 --> 00:12:59,750
doing that it became practical to

00:12:56,790 --> 00:13:02,640
specialized types like function for

00:12:59,750 --> 00:13:04,230
unfortunately because he needed to well

00:13:02,640 --> 00:13:06,750
dispatch in what kind of type do you

00:13:04,230 --> 00:13:08,880
actually have and see it in runtime it

00:13:06,750 --> 00:13:10,770
would introduced slow but sometimes

00:13:08,880 --> 00:13:12,990
visible performance degradation in

00:13:10,770 --> 00:13:16,410
particular for operations like least

00:13:12,990 --> 00:13:18,860
reversal it was a more complicated

00:13:16,410 --> 00:13:21,870
encoding so it did handle inheritance

00:13:18,860 --> 00:13:22,930
but because it tried to be generic over

00:13:21,870 --> 00:13:25,960
all the kinds of primitive

00:13:22,930 --> 00:13:28,649
it had problems with the race so because

00:13:25,960 --> 00:13:31,390
specialization you that lets say t isn't

00:13:28,649 --> 00:13:35,470
if you have an array of T well that's in

00:13:31,390 --> 00:13:37,810
a rare event in runtime it is unlikely

00:13:35,470 --> 00:13:42,310
this in mini boxing because it collapse

00:13:37,810 --> 00:13:44,260
as shorts flew in and lungs when it has

00:13:42,310 --> 00:13:45,490
an array of one of these types it

00:13:44,260 --> 00:13:47,440
doesn't actually statically know what

00:13:45,490 --> 00:13:50,620
kind of ray does it have and order all

00:13:47,440 --> 00:13:52,360
arrays on how in Java are different so

00:13:50,620 --> 00:13:54,570
it had substantial slowdowns and

00:13:52,360 --> 00:13:57,399
complications when you used to race and

00:13:54,570 --> 00:13:58,899
it had a very complicated implementation

00:13:57,399 --> 00:14:01,029
to actually handle all of this and

00:13:58,899 --> 00:14:04,660
that's one of the main reason why didn't

00:14:01,029 --> 00:14:06,940
remain plugin for a long time Vlad did a

00:14:04,660 --> 00:14:09,279
huge amount of work to make this plugin

00:14:06,940 --> 00:14:11,470
stable and now I would advise you to use

00:14:09,279 --> 00:14:13,480
it because it actually achieves what it

00:14:11,470 --> 00:14:19,690
was intending to but it was a really

00:14:13,480 --> 00:14:22,330
long way to get it done so but I want to

00:14:19,690 --> 00:14:24,790
try and show you one disadvantage of the

00:14:22,330 --> 00:14:26,260
bus approaches when I started it became

00:14:24,790 --> 00:14:28,839
apparent to me when I started working on

00:14:26,260 --> 00:14:30,970
it so I've been working on collections

00:14:28,839 --> 00:14:33,010
as I said and I've been working on

00:14:30,970 --> 00:14:34,779
collections which are supposed to be

00:14:33,010 --> 00:14:37,720
used by all the people in skala

00:14:34,779 --> 00:14:40,120
community when I was working for

00:14:37,720 --> 00:14:42,670
collection I needed to decide how would

00:14:40,120 --> 00:14:44,740
a special if I would use specialized or

00:14:42,670 --> 00:14:46,870
mini box I want to able to decide what

00:14:44,740 --> 00:14:48,250
type where I'm what type parameters just

00:14:46,870 --> 00:14:50,890
specialized and what specialized them

00:14:48,250 --> 00:14:54,100
for I need to make decisions for you I

00:14:50,890 --> 00:14:59,140
needed to find the one size that will

00:14:54,100 --> 00:15:00,970
feel all the scholar community and by

00:14:59,140 --> 00:15:05,529
doing this I believe I'll break

00:15:00,970 --> 00:15:07,300
modularity because my internal decisions

00:15:05,529 --> 00:15:10,870
would leak to the properties of your

00:15:07,300 --> 00:15:12,850
software depending on whether you will

00:15:10,870 --> 00:15:16,209
use the library in the way which I kind

00:15:12,850 --> 00:15:21,070
of blast performance of you will either

00:15:16,209 --> 00:15:25,089
be good all will suffer a lot so I try

00:15:21,070 --> 00:15:26,829
to see if there are other options so if

00:15:25,089 --> 00:15:30,459
you'll go back to the same question so

00:15:26,829 --> 00:15:33,040
we have function three specialization

00:15:30,459 --> 00:15:34,540
was trying was trying and specialization

00:15:33,040 --> 00:15:36,130
and mini box and we're trying to answer

00:15:34,540 --> 00:15:37,930
the simple question how

00:15:36,130 --> 00:15:41,080
specializations are needed in case of

00:15:37,930 --> 00:15:44,050
specialization it was 10,000 in case of

00:15:41,080 --> 00:15:47,170
mini box know what was 81 I believe that

00:15:44,050 --> 00:15:48,880
this is the wrong question to answer it

00:15:47,170 --> 00:15:51,000
doesn't matter how many specializations

00:15:48,880 --> 00:15:54,460
are needed for Hall scholar community

00:15:51,000 --> 00:15:57,040
because I mean how many specializations

00:15:54,460 --> 00:15:58,150
are needed is a question to ask about

00:15:57,040 --> 00:16:01,810
you asking when you're asking about

00:15:58,150 --> 00:16:04,600
specific code I'm building compiler it's

00:16:01,810 --> 00:16:06,160
likely that my compiler is not similar

00:16:04,600 --> 00:16:09,280
to the code that you're writing your in

00:16:06,160 --> 00:16:11,500
your day job I'm working on types which

00:16:09,280 --> 00:16:12,700
you don't normally work work on if

00:16:11,500 --> 00:16:14,260
somebody is building in numeric

00:16:12,700 --> 00:16:16,540
application he's likely to work on

00:16:14,260 --> 00:16:18,280
doubles all the time if you're building

00:16:16,540 --> 00:16:21,790
Bank complication you're likely to work

00:16:18,280 --> 00:16:25,420
on big integers or big decimals so I

00:16:21,790 --> 00:16:26,980
believe that the first question that we

00:16:25,420 --> 00:16:29,580
should ask is how many position is

00:16:26,980 --> 00:16:31,960
needed in there a particular code base

00:16:29,580 --> 00:16:35,740
actually this question is also impress

00:16:31,960 --> 00:16:37,630
eyes so the right question that i ended

00:16:35,740 --> 00:16:38,650
up answering is how many speculations

00:16:37,630 --> 00:16:40,660
are needed in every particular

00:16:38,650 --> 00:16:45,400
coal-based including all the libraries

00:16:40,660 --> 00:16:46,780
that depends on so i mean all of you are

00:16:45,400 --> 00:16:48,850
building some application but there's a

00:16:46,780 --> 00:16:50,680
lot of more code that you reuse your use

00:16:48,850 --> 00:16:53,410
at the very least standard library you

00:16:50,680 --> 00:16:56,380
may also be using shapeless kiz in all

00:16:53,410 --> 00:16:58,930
these libraries are complicated and I'm

00:16:56,380 --> 00:17:00,610
not asking you to know how are they how

00:16:58,930 --> 00:17:06,400
do they work and answer this in your

00:17:00,610 --> 00:17:08,110
code base so and this built a design for

00:17:06,400 --> 00:17:10,870
what a specialization in daughter linker

00:17:08,110 --> 00:17:13,839
it takes your program it takes all the

00:17:10,870 --> 00:17:15,970
library to depend on it analyzes how do

00:17:13,839 --> 00:17:18,370
you use them what will be the type sit

00:17:15,970 --> 00:17:21,189
here a particular instance your

00:17:18,370 --> 00:17:22,810
particular application will need and it

00:17:21,189 --> 00:17:25,089
will only generate the types that you

00:17:22,810 --> 00:17:28,690
need if you are actually an interesting

00:17:25,089 --> 00:17:31,260
guy who uses function 5 of unity unity

00:17:28,690 --> 00:17:34,360
unity unity engine unit you'll get it

00:17:31,260 --> 00:17:36,970
but everybody else won't suffer because

00:17:34,360 --> 00:17:40,330
he won't need to prepare for you getting

00:17:36,970 --> 00:17:43,150
it and the good thing that I like most

00:17:40,330 --> 00:17:45,790
is that library authors who built the

00:17:43,150 --> 00:17:48,490
libraries now don't need to think I

00:17:45,790 --> 00:17:49,510
don't need to do user studies I don't

00:17:48,490 --> 00:17:51,820
need to

00:17:49,510 --> 00:17:53,500
scar-h usage of some particular types by

00:17:51,820 --> 00:17:55,300
not specialize in them they do need to

00:17:53,500 --> 00:17:57,210
do hard decisions that now can

00:17:55,300 --> 00:18:00,970
concentrate on once again building if

00:17:57,210 --> 00:18:03,100
libraries which are convenient to use so

00:18:00,970 --> 00:18:06,490
actually there is a funny implementation

00:18:03,100 --> 00:18:10,780
artifact that was discovered quite late

00:18:06,490 --> 00:18:13,300
but it was awesome so type arguments and

00:18:10,780 --> 00:18:15,640
term arguments like normal argument

00:18:13,300 --> 00:18:17,740
citypass the methods in the

00:18:15,640 --> 00:18:20,920
implementation in the analysis are

00:18:17,740 --> 00:18:22,600
treated in the very very same way there

00:18:20,920 --> 00:18:25,450
is no distinction between types and

00:18:22,600 --> 00:18:27,370
germs well there is not much distinction

00:18:25,450 --> 00:18:29,430
between types and terms and dotting for

00:18:27,370 --> 00:18:32,430
this particular use case and if

00:18:29,430 --> 00:18:36,010
specialization for type arguments means

00:18:32,430 --> 00:18:38,950
removing of boxing when you specialize

00:18:36,010 --> 00:18:43,840
for term arguments you remove virtual

00:18:38,950 --> 00:18:45,640
dispatch and that's awesome I'll show a

00:18:43,840 --> 00:18:49,180
benchmark later which proves it's

00:18:45,640 --> 00:18:52,690
awesome okay and the benchmark has to do

00:18:49,180 --> 00:18:55,240
with this symbol this symbol is a symbol

00:18:52,690 --> 00:18:58,990
of scale a native will have won you back

00:18:55,240 --> 00:19:00,580
end we already have one you back end who

00:18:58,990 --> 00:19:02,110
Dennis your balance working on he'll

00:19:00,580 --> 00:19:05,350
give a presentation a bit later about it

00:19:02,110 --> 00:19:08,260
and the idea here is instead of

00:19:05,350 --> 00:19:10,300
compiling tune Java byte code to compile

00:19:08,260 --> 00:19:12,730
the native code there are multiple

00:19:10,300 --> 00:19:14,740
optimizations which are done by Java VM

00:19:12,730 --> 00:19:16,920
for us which are good like de

00:19:14,740 --> 00:19:20,110
virtualization like Thai profiling

00:19:16,920 --> 00:19:22,900
unfortunately because llvm is not built

00:19:20,110 --> 00:19:26,020
for languages which abuse those features

00:19:22,900 --> 00:19:27,880
it doesn't optimize them much it means

00:19:26,020 --> 00:19:31,030
to need some other optimizer to do it

00:19:27,880 --> 00:19:33,520
for us and ya hear the benchmarks that I

00:19:31,030 --> 00:19:35,850
promise to you so the same code which

00:19:33,520 --> 00:19:38,260
just takes an array of integers and

00:19:35,850 --> 00:19:40,150
computes the average value over it if

00:19:38,260 --> 00:19:41,860
you're right it in Java takes four to

00:19:40,150 --> 00:19:46,090
five milliseconds if you write its

00:19:41,860 --> 00:19:48,760
escala to 11 it takes nine hundred

00:19:46,090 --> 00:19:51,190
milliseconds Lucas has been doing a

00:19:48,760 --> 00:19:54,970
really good job in optimizing to 12 so

00:19:51,190 --> 00:19:56,590
he changed Nick improves its the running

00:19:54,970 --> 00:20:00,550
time by doing some local optimizations

00:19:56,590 --> 00:20:01,990
here and it did improve the previous

00:20:00,550 --> 00:20:02,940
projects that I used to work on scholar

00:20:01,990 --> 00:20:04,740
blades

00:20:02,940 --> 00:20:08,670
actually performs Java here by using

00:20:04,740 --> 00:20:10,590
some very low-level tricks and it

00:20:08,670 --> 00:20:13,560
actually is entirely memory bound so the

00:20:10,590 --> 00:20:15,060
42 milliseconds here is amount of time

00:20:13,560 --> 00:20:20,010
that it actually takes for you to read

00:20:15,060 --> 00:20:22,560
this array it can't get any faster if

00:20:20,010 --> 00:20:25,290
you use my current approach in lingere

00:20:22,560 --> 00:20:28,320
it takes six to eight milliseconds there

00:20:25,290 --> 00:20:30,780
are still some abstraction that are left

00:20:28,320 --> 00:20:32,790
there which are not eliminated but i

00:20:30,780 --> 00:20:36,270
believe is pretty good so if you take

00:20:32,790 --> 00:20:38,780
skellige yes I believe that Sebastian

00:20:36,270 --> 00:20:42,180
was able to get impressive result on

00:20:38,780 --> 00:20:43,860
such a slow runtime which boxes

00:20:42,180 --> 00:20:48,420
everything which assumes that you do can

00:20:43,860 --> 00:20:51,300
do all scary stuff and I'm quite

00:20:48,420 --> 00:20:54,690
impressed that it's as good as it looks

00:20:51,300 --> 00:20:56,400
now so and the last thing that the one

00:20:54,690 --> 00:20:59,640
that has to do with scale a native if

00:20:56,400 --> 00:21:02,310
you optimize it with native linker this

00:20:59,640 --> 00:21:07,830
particular code then then the phases

00:21:02,310 --> 00:21:11,150
which come from llvm itself are able to

00:21:07,830 --> 00:21:11,150
partially evaluate it away

00:21:21,350 --> 00:21:29,160
so we spent all this morning with Dennis

00:21:27,060 --> 00:21:33,990
trying to actually not make it partially

00:21:29,160 --> 00:21:35,520
evaluated a way to get numbers and so

00:21:33,990 --> 00:21:38,340
Skala native currently doesn't have to

00:21:35,520 --> 00:21:40,860
ready model we need to modify if they

00:21:38,340 --> 00:21:42,900
intermediate representation by hand to

00:21:40,860 --> 00:21:45,390
say that the fields which are used as

00:21:42,900 --> 00:21:47,690
accumulators of volatile and they can be

00:21:45,390 --> 00:21:50,250
potentially changed by other threats and

00:21:47,690 --> 00:21:54,750
then we got the numbers which are

00:21:50,250 --> 00:21:56,580
scalable it's like yeah so it was gets

00:21:54,750 --> 00:21:59,160
quite impressive by using that's all the

00:21:56,580 --> 00:22:02,010
virtualization estab that's it allowed

00:21:59,160 --> 00:22:02,940
us to open forum everything and so the

00:22:02,010 --> 00:22:04,560
other question that you may be

00:22:02,940 --> 00:22:06,900
interested well there's an optimizer as

00:22:04,560 --> 00:22:08,370
I said it optimized it analyzes all of

00:22:06,900 --> 00:22:12,420
your program it analyzes all of your

00:22:08,370 --> 00:22:14,910
libraries it and it rebuilds it for you

00:22:12,420 --> 00:22:16,950
it may take a long time so in this

00:22:14,910 --> 00:22:19,290
particular case well completion in Java

00:22:16,950 --> 00:22:21,390
is really fast Java is a simple language

00:22:19,290 --> 00:22:25,350
they don't do any complicated language

00:22:21,390 --> 00:22:28,650
feature Scala is slower the new Scala

00:22:25,350 --> 00:22:30,180
compiler is faster and if you take skala

00:22:28,650 --> 00:22:32,820
bliss which is actually based in Scala

00:22:30,180 --> 00:22:34,890
to 11 which is macro library so it

00:22:32,820 --> 00:22:37,830
spends quite a lot of time inside the

00:22:34,890 --> 00:22:41,430
recursive macro city defines the linker

00:22:37,830 --> 00:22:44,090
in this particular case is somewhere in

00:22:41,430 --> 00:22:46,440
between scalability and skeletor 11

00:22:44,090 --> 00:22:48,300
actually doggy in this case is faster

00:22:46,440 --> 00:22:51,330
than Scala to 11 it's somewhere around

00:22:48,300 --> 00:22:54,690
200 milliseconds so linker introduces

00:22:51,330 --> 00:22:57,600
like half of 1.5 x of speed up in this

00:22:54,690 --> 00:22:59,850
particular case so there are limitations

00:22:57,600 --> 00:23:01,350
of this approach hook obviously it slows

00:22:59,850 --> 00:23:03,500
down compilation as i said because

00:23:01,350 --> 00:23:05,640
you're not longer compiling your

00:23:03,500 --> 00:23:07,500
application you're kind of recompiling

00:23:05,640 --> 00:23:09,150
all the parts of libraries that you use

00:23:07,500 --> 00:23:11,070
i'm not going to recompile parts of

00:23:09,150 --> 00:23:13,770
libraries that you don't use but if you

00:23:11,070 --> 00:23:15,650
touch something if you use lists the

00:23:13,770 --> 00:23:18,420
list will be recompiled just for you

00:23:15,650 --> 00:23:20,040
with the optimizations which are

00:23:18,420 --> 00:23:22,770
appropriate for your particular use

00:23:20,040 --> 00:23:25,050
cases of this list in order to be able

00:23:22,770 --> 00:23:27,120
to do it I need to be able to read the

00:23:25,050 --> 00:23:29,460
sources of the West's and that's where

00:23:27,120 --> 00:23:32,460
tasty comes in taste is a project which

00:23:29,460 --> 00:23:36,140
initially was developed in skala meta

00:23:32,460 --> 00:23:38,610
where they tried to build the

00:23:36,140 --> 00:23:43,050
intermediate format for meta programming

00:23:38,610 --> 00:23:45,150
and now it it resulted in the dotty

00:23:43,050 --> 00:23:48,570
always imagined it as its own sir

00:23:45,150 --> 00:23:51,090
ization format so this approach the auto

00:23:48,570 --> 00:23:53,940
spell situation doesn't help if library

00:23:51,090 --> 00:23:56,460
does tricks and by tricks I mean funny

00:23:53,940 --> 00:23:58,710
casts which assume boxing for example

00:23:56,460 --> 00:24:01,320
which will be unsound if i remove boxing

00:23:58,710 --> 00:24:06,420
so let's say if you use the same array

00:24:01,320 --> 00:24:09,390
to store as absence of element we by

00:24:06,420 --> 00:24:11,340
using null if i'll specialized this

00:24:09,390 --> 00:24:13,560
array to be array of primitive you can't

00:24:11,340 --> 00:24:16,800
still not out there anymore and your

00:24:13,560 --> 00:24:18,720
algorithm will break so my analysis is

00:24:16,800 --> 00:24:21,060
smart enough to see that you're casting

00:24:18,720 --> 00:24:23,630
and now into integer this particular

00:24:21,060 --> 00:24:28,230
case and it won't perform optimizations

00:24:23,630 --> 00:24:31,020
so starting now if you want to take most

00:24:28,230 --> 00:24:33,000
advantage on dotty and scala native it's

00:24:31,020 --> 00:24:35,340
better to write libraries which don't do

00:24:33,000 --> 00:24:39,210
dirty tricks because you're trying to be

00:24:35,340 --> 00:24:41,700
smarter than the optimizer is and one

00:24:39,210 --> 00:24:43,710
more example is if you have a typed API

00:24:41,700 --> 00:24:46,230
but your internals are entirely on typed

00:24:43,710 --> 00:24:48,090
its I've seen several libraries do this

00:24:46,230 --> 00:24:49,530
if they're using shape let's just create

00:24:48,090 --> 00:24:51,480
their FB i-- they want to create

00:24:49,530 --> 00:24:54,330
complicated types which help the users

00:24:51,480 --> 00:24:55,770
but they don't want to mess with those

00:24:54,330 --> 00:24:58,080
types internally because it's too

00:24:55,770 --> 00:24:59,940
complicated you know and then they just

00:24:58,080 --> 00:25:02,160
cussed everything to any and cuz back

00:24:59,940 --> 00:25:04,350
when they returned because the internals

00:25:02,160 --> 00:25:06,030
of the library are an untyped none of

00:25:04,350 --> 00:25:08,600
this optimization supply anymore and

00:25:06,030 --> 00:25:12,930
they won't benefit any adult from them

00:25:08,600 --> 00:25:14,580
so okay now when we're done with the

00:25:12,930 --> 00:25:17,130
libraries the question is about the

00:25:14,580 --> 00:25:20,490
users code when i was optimized in this

00:25:17,130 --> 00:25:23,460
example the reason why scholar blitz was

00:25:20,490 --> 00:25:26,700
faster because scholar Blitzen you what

00:25:23,460 --> 00:25:30,000
is the reuse the actual reason is this

00:25:26,700 --> 00:25:33,240
if which only applies on the first

00:25:30,000 --> 00:25:35,520
iteration skala blitz knew that you've

00:25:33,240 --> 00:25:39,360
do in this particular kind of reduce it

00:25:35,520 --> 00:25:41,400
can do the first iteration aside so that

00:25:39,360 --> 00:25:42,930
only if will trigger only in the first

00:25:41,400 --> 00:25:44,559
iteration but do they all the following

00:25:42,930 --> 00:25:49,029
ones without faith

00:25:44,559 --> 00:25:50,499
and in order to do it I'll need to

00:25:49,029 --> 00:25:53,710
introduce one more kind of optimization

00:25:50,499 --> 00:25:56,559
that will actually help all of us so

00:25:53,710 --> 00:25:58,110
consider this code I like this code

00:25:56,559 --> 00:26:02,409
that's the code that i normally write

00:25:58,110 --> 00:26:05,169
but when I review this code I spot a

00:26:02,409 --> 00:26:08,080
problem the egg is that size here when

00:26:05,169 --> 00:26:09,820
called on the list takes linear time and

00:26:08,080 --> 00:26:11,259
what I'm actually trying to see if I'm

00:26:09,820 --> 00:26:13,090
trying to see if the list is empty I

00:26:11,259 --> 00:26:15,190
don't need to get the actual size of the

00:26:13,090 --> 00:26:17,529
list to do it I'd better read the code

00:26:15,190 --> 00:26:19,330
on the right but when I'm thinking when

00:26:17,529 --> 00:26:21,549
I'm building an algorithm when i'm

00:26:19,330 --> 00:26:25,080
building the complicated program I don't

00:26:21,549 --> 00:26:28,899
want to think about such small details

00:26:25,080 --> 00:26:31,119
compiler can do this for me and in this

00:26:28,899 --> 00:26:34,289
particular case it can be actually a lot

00:26:31,119 --> 00:26:36,490
more severe so if you compare those two

00:26:34,289 --> 00:26:40,779
examples written in spark that's

00:26:36,490 --> 00:26:43,419
actually an example from there their

00:26:40,779 --> 00:26:46,330
main page that's a word count example

00:26:43,419 --> 00:26:50,169
the example that they introduced his

00:26:46,330 --> 00:26:52,929
example on the right unfortunately

00:26:50,169 --> 00:26:55,749
compared to example on the left it's

00:26:52,929 --> 00:27:02,409
somewhere like 70 times slower the main

00:26:55,749 --> 00:27:04,149
reason here is this map which is global

00:27:02,409 --> 00:27:08,230
and it then you need to do global

00:27:04,149 --> 00:27:10,509
reduction here if you instead write it

00:27:08,230 --> 00:27:12,220
this way it will be harder to maintain

00:27:10,509 --> 00:27:14,399
it'll be harder to understand what a

00:27:12,220 --> 00:27:16,690
dust but it will be substantially faster

00:27:14,399 --> 00:27:18,369
when developing libraries have a new

00:27:16,690 --> 00:27:20,499
development application I see this

00:27:18,369 --> 00:27:22,179
program problem all the time when I

00:27:20,499 --> 00:27:23,889
write the code I need to decide whether

00:27:22,179 --> 00:27:28,119
they will i will write it fast or I'll

00:27:23,889 --> 00:27:31,960
ready to make it maintainable and if I

00:27:28,119 --> 00:27:36,070
decide to write it fast everybody in my

00:27:31,960 --> 00:27:37,570
project will have a problem of trying to

00:27:36,070 --> 00:27:40,330
understand what it does this code may be

00:27:37,570 --> 00:27:43,029
deleted in future and rewritten because

00:27:40,330 --> 00:27:46,230
nobody was capable of understanding how

00:27:43,029 --> 00:27:49,269
did it work even worse if it had a buck

00:27:46,230 --> 00:27:51,549
if you write the maintainable code it

00:27:49,269 --> 00:27:54,039
may stay there forever everybody will

00:27:51,549 --> 00:27:55,750
understand that but you'll be slow and

00:27:54,039 --> 00:27:57,460
nobody will know that somewhere deep in

00:27:55,750 --> 00:27:58,419
your program there is this part where

00:27:57,460 --> 00:27:59,950
somebody make

00:27:58,419 --> 00:28:02,230
made a decision for now i'll write

00:27:59,950 --> 00:28:03,999
maintainable but one day i will come

00:28:02,230 --> 00:28:06,879
back and rewriting it will have a

00:28:03,999 --> 00:28:08,440
problem with performance several years

00:28:06,879 --> 00:28:10,330
past now you have a problem with

00:28:08,440 --> 00:28:12,639
performance nobler nobody remembers

00:28:10,330 --> 00:28:14,460
somewhere deep inside the core there is

00:28:12,639 --> 00:28:19,149
this maintainable code which is slow so

00:28:14,460 --> 00:28:21,519
i believe that we need library specific

00:28:19,149 --> 00:28:25,269
optimizations here made optimizations

00:28:21,519 --> 00:28:28,389
which know what kind of operations are

00:28:25,269 --> 00:28:30,249
you doing what are the ways were to

00:28:28,389 --> 00:28:32,739
combine those operations and what are

00:28:30,249 --> 00:28:34,929
the ways to more efficiently do the same

00:28:32,739 --> 00:28:37,269
things which user do their everyday life

00:28:34,929 --> 00:28:39,940
so in this particular example with the

00:28:37,269 --> 00:28:42,639
list I want this code where they exist

00:28:39,940 --> 00:28:45,999
sequence any sequence list vector

00:28:42,639 --> 00:28:48,700
arbitrary sequence to be replaced by

00:28:45,999 --> 00:28:51,369
this code I don't want to compute length

00:28:48,700 --> 00:28:54,279
if I'm interested if the collection is

00:28:51,369 --> 00:28:58,960
empty and i'm introducing rewrite rules

00:28:54,279 --> 00:29:01,509
here so what this says is this is an

00:28:58,960 --> 00:29:03,879
object which contains rules which will

00:29:01,509 --> 00:29:06,039
restart rewriting your program and this

00:29:03,879 --> 00:29:07,929
particular rule says for arbitrary

00:29:06,039 --> 00:29:12,700
sequence if you have expression like

00:29:07,929 --> 00:29:14,440
this then rewrite it to this when i was

00:29:12,700 --> 00:29:17,320
trying to do similar stuff in skala

00:29:14,440 --> 00:29:20,169
blitz to make it combined able the

00:29:17,320 --> 00:29:23,169
average length of the macro was seven

00:29:20,169 --> 00:29:24,970
hundred lines of code to be capable of

00:29:23,169 --> 00:29:28,840
doing this in all the cases in all the

00:29:24,970 --> 00:29:31,779
complex situations once again if your

00:29:28,840 --> 00:29:34,149
bank you may be written a lot of big

00:29:31,779 --> 00:29:35,739
integers because you're a big back you

00:29:34,149 --> 00:29:37,919
have a lot of money it doesn't fit an

00:29:35,739 --> 00:29:42,220
integer anymore it doesn't fit in long

00:29:37,919 --> 00:29:46,330
so if you're the working on begin to

00:29:42,220 --> 00:29:49,269
jerz when you're dividing big integer on

00:29:46,330 --> 00:29:51,820
the other integer if the other integer

00:29:49,269 --> 00:29:55,600
is a power of 2 is preferred to make a

00:29:51,820 --> 00:29:56,919
shift instead it's a lot faster and it

00:29:55,600 --> 00:30:00,609
actually doesn't allocate as much

00:29:56,919 --> 00:30:03,100
memories the other yes so you can write

00:30:00,609 --> 00:30:06,399
such a rule which tests if you are

00:30:03,100 --> 00:30:09,429
dividing by a primitive or by constant

00:30:06,399 --> 00:30:11,950
which is an end here then this rule will

00:30:09,429 --> 00:30:13,539
apply and then you rewrite it too

00:30:11,950 --> 00:30:15,850
ode where you have this constant a

00:30:13,539 --> 00:30:18,370
you're checking how much does it

00:30:15,850 --> 00:30:19,870
have if it has a one bit it will execute

00:30:18,370 --> 00:30:24,039
this code otherwise it will do actual

00:30:19,870 --> 00:30:27,429
division so this rule will rewrite code

00:30:24,039 --> 00:30:31,679
similar to this to this one and then

00:30:27,429 --> 00:30:34,090
partial evaluation in either doggy or

00:30:31,679 --> 00:30:36,429
hotspot itself will see that only one of

00:30:34,090 --> 00:30:40,269
the branches is taken it will remove the

00:30:36,429 --> 00:30:41,860
other similarly going back to the

00:30:40,269 --> 00:30:45,429
example of collections you have multiple

00:30:41,860 --> 00:30:47,669
filters in a row then every of those

00:30:45,429 --> 00:30:50,380
will create intermediate collection and

00:30:47,669 --> 00:30:53,760
it may be slow because of this in the

00:30:50,380 --> 00:30:56,590
collections are huge or in local so I

00:30:53,760 --> 00:30:58,570
believe that this code is easier to

00:30:56,590 --> 00:31:01,360
follow an easier to maintain but it's

00:30:58,570 --> 00:31:03,429
slower and I'd prefer to be able to read

00:31:01,360 --> 00:31:06,340
this code and compile to write the code

00:31:03,429 --> 00:31:08,470
into this version this lesson also can

00:31:06,340 --> 00:31:11,200
be done with a simple rewrite rule which

00:31:08,470 --> 00:31:13,090
takes lambdas there is one more

00:31:11,200 --> 00:31:17,440
requirement for this rule to be correct

00:31:13,090 --> 00:31:20,110
it's needs to check if either of lambdas

00:31:17,440 --> 00:31:22,000
is pure one of the lambdas needs to be

00:31:20,110 --> 00:31:23,230
here it's fine if both are pure but even

00:31:22,000 --> 00:31:25,450
both a side-effect well this is

00:31:23,230 --> 00:31:27,669
rewriting is actually unsafe because

00:31:25,450 --> 00:31:29,710
they can be printing let's say the

00:31:27,669 --> 00:31:31,899
elements say that they're checking and

00:31:29,710 --> 00:31:34,600
if your fuse them they will print it in

00:31:31,899 --> 00:31:36,250
a different order so the East pier here

00:31:34,600 --> 00:31:38,889
is actually part of the analysis which

00:31:36,250 --> 00:31:42,580
linker does which which is not the

00:31:38,889 --> 00:31:45,070
purity analysis as if auto-rotate this

00:31:42,580 --> 00:31:47,500
pure it's more of analysis will somebody

00:31:45,070 --> 00:31:50,620
will be able to exceed that if it's not

00:31:47,500 --> 00:31:52,600
pure other any effects which escape

00:31:50,620 --> 00:31:56,039
either any effects that are is

00:31:52,600 --> 00:31:58,210
observable that they happen in

00:31:56,039 --> 00:31:59,950
particular when you create a list

00:31:58,210 --> 00:32:02,289
actually there are side effects and

00:31:59,950 --> 00:32:05,320
sides which are there for performance of

00:32:02,289 --> 00:32:10,840
creation of a list you don't want to

00:32:05,320 --> 00:32:12,820
create a list in quadratic time but this

00:32:10,840 --> 00:32:14,769
analysis though it has side effects

00:32:12,820 --> 00:32:16,450
inside is able to see that nobody will

00:32:14,769 --> 00:32:19,389
be able to observe them it will be able

00:32:16,450 --> 00:32:21,610
to optimize it also one more thing which

00:32:19,389 --> 00:32:23,290
can be done here is if somebody miss

00:32:21,610 --> 00:32:25,420
uses the library and there

00:32:23,290 --> 00:32:27,490
no getriebe right let's say for a pearl

00:32:25,420 --> 00:32:31,000
collection and somebody do does reduce

00:32:27,490 --> 00:32:33,960
left on it and he wants it 12 2 b'fast

00:32:31,000 --> 00:32:36,130
had to perform a parallel reduce left

00:32:33,960 --> 00:32:40,210
unfortunately there is no such thing as

00:32:36,130 --> 00:32:41,980
parallel to reduce left and if your

00:32:40,210 --> 00:32:47,620
author of the parallel collections

00:32:41,980 --> 00:32:51,070
library I would prefer this use case to

00:32:47,620 --> 00:32:52,960
be at least a warning because you're

00:32:51,070 --> 00:32:56,080
assuming that you will do something but

00:32:52,960 --> 00:32:59,740
it doesn't and yeah you can define

00:32:56,080 --> 00:33:02,890
warnings for this you can do also do

00:32:59,740 --> 00:33:05,860
easy logging so you know this example

00:33:02,890 --> 00:33:08,320
from Java which also applies to scala

00:33:05,860 --> 00:33:10,510
that if you're checking if some if your

00:33:08,320 --> 00:33:13,000
login is enabled in a performance

00:33:10,510 --> 00:33:14,890
sensitive code you don't want to pre

00:33:13,000 --> 00:33:17,590
create the closure which actually will

00:33:14,890 --> 00:33:19,660
create the lock message and you have

00:33:17,590 --> 00:33:21,730
this funny double checking if is log of

00:33:19,660 --> 00:33:25,150
all log and the log insight will check

00:33:21,730 --> 00:33:28,720
once again if it's laudable it's one

00:33:25,150 --> 00:33:31,030
more coat pattern which exists there for

00:33:28,720 --> 00:33:33,220
performance reasons but it's very

00:33:31,030 --> 00:33:35,110
unpleasant to spend time thinking about

00:33:33,220 --> 00:33:38,200
it and writing it and reviewing code

00:33:35,110 --> 00:33:41,260
which is bigger because somebody wanted

00:33:38,200 --> 00:33:43,030
to be fast here because there's rewrite

00:33:41,260 --> 00:33:45,130
rules apply anywhere even if they work

00:33:43,030 --> 00:33:50,980
in Java if they work in Java logging you

00:33:45,130 --> 00:33:54,610
can define them so and similarly you can

00:33:50,980 --> 00:33:58,840
define easy debug messages where you can

00:33:54,610 --> 00:34:00,600
promote this source in runtime you can

00:33:58,840 --> 00:34:02,800
ask the question how does it work

00:34:00,600 --> 00:34:06,550
actually it works to the real similar

00:34:02,800 --> 00:34:09,040
size mattress and because it kind of

00:34:06,550 --> 00:34:10,900
makes I mean squabbles previous that was

00:34:09,040 --> 00:34:12,669
implemented using macros now I'm

00:34:10,900 --> 00:34:14,260
re-implementing the staff which used to

00:34:12,669 --> 00:34:16,540
be in scalable is using rewrite rules

00:34:14,260 --> 00:34:19,120
and I want to give you some guidelines

00:34:16,540 --> 00:34:21,550
when to use one or another so in

00:34:19,120 --> 00:34:23,590
particular the rewrite rules can be

00:34:21,550 --> 00:34:27,179
defined everywhere in the library in

00:34:23,590 --> 00:34:32,880
their program or in the library so if

00:34:27,179 --> 00:34:35,620
you want to define some rules which

00:34:32,880 --> 00:34:37,210
should be separate you should we still

00:34:35,620 --> 00:34:38,919
have the default implementation

00:34:37,210 --> 00:34:42,159
which implements virtual calls and stuff

00:34:38,919 --> 00:34:44,770
and which are simple maybe rewrite rules

00:34:42,159 --> 00:34:47,740
are better macros are magnets are a very

00:34:44,770 --> 00:34:49,810
wonderful feature to define new language

00:34:47,740 --> 00:34:52,330
expressions to enhance your language

00:34:49,810 --> 00:34:55,230
waive rights rule happen after diaper

00:34:52,330 --> 00:34:58,630
then don't participate a typing at all

00:34:55,230 --> 00:35:00,640
the application in rewrite rules in this

00:34:58,630 --> 00:35:02,830
case is based on the analysis they will

00:35:00,640 --> 00:35:07,150
apply even if you have virtual calls

00:35:02,830 --> 00:35:08,730
which happen that they actually dispatch

00:35:07,150 --> 00:35:13,000
to places which are optimized about and

00:35:08,730 --> 00:35:18,310
like this macros can only work if you

00:35:13,000 --> 00:35:20,560
seem tactically call them because macros

00:35:18,310 --> 00:35:23,020
can only be decided divided defined

00:35:20,560 --> 00:35:24,790
inside java in skites color classes you

00:35:23,020 --> 00:35:29,290
can't make them work for java classes

00:35:24,790 --> 00:35:32,290
without magic unlike these rewrite rules

00:35:29,290 --> 00:35:34,000
perfectly work on Java methods and they

00:35:32,290 --> 00:35:36,760
work across libraries so let's say you

00:35:34,000 --> 00:35:40,540
want optimization which is optimization

00:35:36,760 --> 00:35:45,490
of usage of Scala standard collections

00:35:40,540 --> 00:35:46,930
inside spark who should be main issue

00:35:45,490 --> 00:35:48,880
should maintain and define this

00:35:46,930 --> 00:35:52,450
optimizations is a standard library is

00:35:48,880 --> 00:35:53,800
it spark here the rewrite rules can be

00:35:52,450 --> 00:35:56,440
anywhere they can be in the third

00:35:53,800 --> 00:35:58,060
library which is developed by other

00:35:56,440 --> 00:36:01,710
people you can have optimization as a

00:35:58,060 --> 00:36:03,730
library here unlike this mattress they

00:36:01,710 --> 00:36:05,500
introduce a lot more tight coupling

00:36:03,730 --> 00:36:08,080
between each other they are lot more

00:36:05,500 --> 00:36:11,980
powerful macros can do more because the

00:36:08,080 --> 00:36:14,020
influence diving and that's I believe

00:36:11,980 --> 00:36:16,060
the best distinction rope if you're

00:36:14,020 --> 00:36:18,220
interesting in simple declarative rules

00:36:16,060 --> 00:36:21,730
which are therefore performance for

00:36:18,220 --> 00:36:23,410
improving the user experience but not

00:36:21,730 --> 00:36:25,180
introducing your language features you

00:36:23,410 --> 00:36:28,270
may consider this if you're trying to do

00:36:25,180 --> 00:36:31,839
something complicated if you're trying

00:36:28,270 --> 00:36:33,250
to let's say drink play with a new

00:36:31,839 --> 00:36:36,670
language feature that you may then

00:36:33,250 --> 00:36:38,530
propose for upstream Scala you'd better

00:36:36,670 --> 00:36:40,180
go with mattress and it will also help

00:36:38,530 --> 00:36:45,970
you to understand the internals of

00:36:40,180 --> 00:36:47,920
compiler so yeah I was trying to help

00:36:45,970 --> 00:36:50,280
you with choosing between Matt and

00:36:47,920 --> 00:36:53,130
macros and Mattin rewrite rules

00:36:50,280 --> 00:36:55,610
actually you don't have to choose you

00:36:53,130 --> 00:36:58,470
can use meta inside the rewrite rules

00:36:55,610 --> 00:37:02,070
then you'll have a more complicated case

00:36:58,470 --> 00:37:03,870
when the matter will trigger let's say

00:37:02,070 --> 00:37:05,700
if you want to actually do complicated

00:37:03,870 --> 00:37:08,040
stuff actually this will be really slow

00:37:05,700 --> 00:37:11,400
but this allows you to bring back

00:37:08,040 --> 00:37:12,570
expressivity that you had with matter so

00:37:11,400 --> 00:37:16,620
you don't have to choose you can combine

00:37:12,570 --> 00:37:18,120
them and by the time I showed you all of

00:37:16,620 --> 00:37:21,930
this so let's rewrite and rules which

00:37:18,120 --> 00:37:24,420
are can Captain can come from any

00:37:21,930 --> 00:37:27,090
library in your class pass you should be

00:37:24,420 --> 00:37:28,740
scared they can break everything they

00:37:27,090 --> 00:37:33,690
can replace all the truths in your

00:37:28,740 --> 00:37:36,480
program by false so from the start I

00:37:33,690 --> 00:37:39,570
want this to be integrated with testing

00:37:36,480 --> 00:37:42,260
every time you define the rule every

00:37:39,570 --> 00:37:45,060
rule is a test to be checked by in

00:37:42,260 --> 00:37:46,620
scholar check in particular if you

00:37:45,060 --> 00:37:48,300
define a function that you take is an

00:37:46,620 --> 00:37:50,130
argument I'll be synthesized inside

00:37:48,300 --> 00:37:53,820
affecting functions to make your old

00:37:50,130 --> 00:37:57,260
break unless you ask me to ask for these

00:37:53,820 --> 00:37:59,880
functions to be side-effect free if and

00:37:57,260 --> 00:38:02,970
this is the only way how you will be

00:37:59,880 --> 00:38:05,010
able to define such rule this test

00:38:02,970 --> 00:38:06,860
should will make a stamp on your role

00:38:05,010 --> 00:38:09,540
which says if there's rule is applicable

00:38:06,860 --> 00:38:13,410
it will be checked of course somebody

00:38:09,540 --> 00:38:15,740
can forge the stamp if he wants but for

00:38:13,410 --> 00:38:17,880
me it makes me sure that during my

00:38:15,740 --> 00:38:21,660
day-to-day life when I be optimizing

00:38:17,880 --> 00:38:24,180
collections in particular I want not

00:38:21,660 --> 00:38:27,420
knowingly define the front roll just

00:38:24,180 --> 00:38:30,750
suddenly okay so the current status all

00:38:27,420 --> 00:38:34,640
this test is prototype unstable even

00:38:30,750 --> 00:38:37,530
more prototype than dotting but as

00:38:34,640 --> 00:38:40,590
similarly to Dottie if your experimenter

00:38:37,530 --> 00:38:42,630
and you want to participate in evolution

00:38:40,590 --> 00:38:44,520
of the language that's the best moment

00:38:42,630 --> 00:38:48,060
for you to join us in our effort to

00:38:44,520 --> 00:38:51,870
build better scala we're still flexible

00:38:48,060 --> 00:38:54,750
enough to consider ideas we're still

00:38:51,870 --> 00:38:57,390
didn't start stabilizing ourselves when

00:38:54,750 --> 00:38:59,840
we will start stabilizing ourselves will

00:38:57,390 --> 00:38:59,840
be less

00:39:00,289 --> 00:39:04,740
interested to consider complicated HDS

00:39:03,180 --> 00:39:12,000
which can stop us from stabilizing the

00:39:04,740 --> 00:39:15,440
code base speaking of the code base so I

00:39:12,000 --> 00:39:18,210
believe that while I specialized stuff

00:39:15,440 --> 00:39:20,549
I'm creating huge amount of default

00:39:18,210 --> 00:39:23,579
methods which nobody ever created in a

00:39:20,549 --> 00:39:27,000
single code base if you try to

00:39:23,579 --> 00:39:29,130
specialize list flat map you have twenty

00:39:27,000 --> 00:39:35,240
percent probability of hotspot to seg

00:39:29,130 --> 00:39:39,630
fault and it's segfaults inside situ

00:39:35,240 --> 00:39:41,520
yeah and serve a compiler so I'm still

00:39:39,630 --> 00:39:44,369
trying to understand who's wrong here

00:39:41,520 --> 00:39:47,069
but because it has huge probability of

00:39:44,369 --> 00:39:48,420
succeeding and it literally mean it

00:39:47,069 --> 00:39:51,089
segfaults doesn't throw an exception or

00:39:48,420 --> 00:39:52,770
something I assume that that's they

00:39:51,089 --> 00:39:55,230
actually have a bug but it's quite hard

00:39:52,770 --> 00:39:57,420
to debug so speaking of the

00:39:55,230 --> 00:39:59,579
implementation once again implementation

00:39:57,420 --> 00:40:01,940
is simple if you compare it with

00:39:59,579 --> 00:40:04,619
specialized or mini boxed in Scala see

00:40:01,940 --> 00:40:07,529
the most complicated part which is

00:40:04,619 --> 00:40:10,980
analysis is smaller the specialization

00:40:07,529 --> 00:40:12,569
part is a bit if if your editor now this

00:40:10,980 --> 00:40:15,930
is a round of the side same type of

00:40:12,569 --> 00:40:19,529
specialization but actually I'm a lot

00:40:15,930 --> 00:40:21,150
more confidently that's right and the

00:40:19,529 --> 00:40:22,710
main reason is because previous

00:40:21,150 --> 00:40:26,730
specialization used to work on trees

00:40:22,710 --> 00:40:28,950
this one works some types and if you're

00:40:26,730 --> 00:40:31,230
riggan types there is a lot of check and

00:40:28,950 --> 00:40:33,930
infrastructure in dotty which will make

00:40:31,230 --> 00:40:36,180
sure that you use types correctly we

00:40:33,930 --> 00:40:38,279
have a quite an impressive type system

00:40:36,180 --> 00:40:39,660
and Scala and in doggy we use its

00:40:38,279 --> 00:40:41,880
advantages to make sure that we're

00:40:39,660 --> 00:40:43,770
building the correct compiler we're

00:40:41,880 --> 00:40:45,329
retype checking the program after every

00:40:43,770 --> 00:40:50,220
face to make sure that we didn't break

00:40:45,329 --> 00:40:53,039
it and it because specialization creates

00:40:50,220 --> 00:40:56,250
very complicated types if they are

00:40:53,039 --> 00:40:58,309
correct it's a very strong indication

00:40:56,250 --> 00:41:01,740
that the transformation is correct here

00:40:58,309 --> 00:41:03,390
as I said about using tricks some

00:41:01,740 --> 00:41:06,569
collections don't benefit like lecture

00:41:03,390 --> 00:41:10,380
because vector stores nulls inside a

00:41:06,569 --> 00:41:12,390
race which presumably are used to store

00:41:10,380 --> 00:41:15,119
integers

00:41:12,390 --> 00:41:18,299
a most other collections like Lister a

00:41:15,119 --> 00:41:20,039
sleaze buffers they work perfectly you

00:41:18,299 --> 00:41:24,019
get the best performance possible here

00:41:20,039 --> 00:41:27,869
and it's open source in stone github

00:41:24,019 --> 00:41:30,390
yeah it's awesome so I want to thank

00:41:27,869 --> 00:41:34,829
everybody who helped me to be where i am

00:41:30,390 --> 00:41:39,150
now that you'll andhra gosh who started

00:41:34,829 --> 00:41:42,269
with specialization and he built a

00:41:39,150 --> 00:41:45,390
system which was complicated and we

00:41:42,269 --> 00:41:48,990
understood that our problems there to be

00:41:45,390 --> 00:41:51,029
addressed and blood oh heck I tried to

00:41:48,990 --> 00:41:52,950
address these problems by building even

00:41:51,029 --> 00:41:55,559
more complicated system and he succeeded

00:41:52,950 --> 00:41:58,289
in doing this now if you have

00:41:55,559 --> 00:41:59,970
performance sensitive code and you need

00:41:58,289 --> 00:42:01,529
have problems with primitives today in

00:41:59,970 --> 00:42:05,220
production now advisor to try mini

00:42:01,529 --> 00:42:09,180
boxing it has been stabilizing for three

00:42:05,220 --> 00:42:11,130
years it's pretty stable now so I want

00:42:09,180 --> 00:42:13,380
to thank you jean bro Marco because so

00:42:11,130 --> 00:42:15,390
while working on skala mat and scaling

00:42:13,380 --> 00:42:17,970
occurs before this he came up with idea

00:42:15,390 --> 00:42:20,460
of tasty and he convinced in particular

00:42:17,970 --> 00:42:23,460
martin to have it in da ting i want to

00:42:20,460 --> 00:42:24,809
thank andre low tech who helped me to

00:42:23,460 --> 00:42:26,579
build the static analysis which is

00:42:24,809 --> 00:42:27,779
needed here and of course nothing of

00:42:26,579 --> 00:42:29,849
this would have been possible without

00:42:27,779 --> 00:42:32,220
martin he was supervising all of us and

00:42:29,849 --> 00:42:37,309
he made this awesome language which a

00:42:32,220 --> 00:42:37,309
laugh okay thank you for listening to me

00:42:43,180 --> 00:42:57,860
and we have precisely five minutes for

00:42:46,010 --> 00:43:01,160
your questions yes please hello you've

00:42:57,860 --> 00:43:04,750
mentioned that the linker would work

00:43:01,160 --> 00:43:08,270
only with libraries which have tasty

00:43:04,750 --> 00:43:12,080
date in them yep but you also mentioned

00:43:08,270 --> 00:43:15,910
that rewrite rules also work on Java

00:43:12,080 --> 00:43:21,260
code how does that combined together so

00:43:15,910 --> 00:43:24,490
rewriting rules will work on the kallah

00:43:21,260 --> 00:43:27,440
code which uses Java code so if you use

00:43:24,490 --> 00:43:29,330
methods defined in Java and you optimize

00:43:27,440 --> 00:43:31,340
your usage of them you can use rewrite

00:43:29,330 --> 00:43:35,420
rules to do this we write rules wouldn't

00:43:31,340 --> 00:43:38,530
apply to know Java standard library so

00:43:35,420 --> 00:43:41,090
one more detail about the tasty here so

00:43:38,530 --> 00:43:43,280
what linker actually creates it creates

00:43:41,090 --> 00:43:46,580
a single jar it's like a pro smarter

00:43:43,280 --> 00:43:51,080
proguard which uses the advantages of

00:43:46,580 --> 00:43:53,180
scala type system but it attaches the

00:43:51,080 --> 00:43:54,850
correct tasty to it so if you're

00:43:53,180 --> 00:43:57,380
building something optimized and

00:43:54,850 --> 00:43:59,330
somebody needs to reopen mice with

00:43:57,380 --> 00:44:01,220
different assumptions he can perfectly

00:43:59,330 --> 00:44:06,560
depend on you he will just do it once

00:44:01,220 --> 00:44:12,280
again yeah thank you thank you yes

00:44:06,560 --> 00:44:12,280
please ok I'll repeat

00:44:39,679 --> 00:44:44,880
okay so the question was that all this

00:44:43,259 --> 00:44:46,949
presentation was optimized for usage of

00:44:44,880 --> 00:44:48,599
primitives and maybe we should consider

00:44:46,949 --> 00:44:52,979
some more complicated classes like

00:44:48,599 --> 00:44:53,939
begins so I've showed you the basis of

00:44:52,979 --> 00:44:56,339
optimizations there are other

00:44:53,939 --> 00:44:59,880
optimizations which rely on those so in

00:44:56,339 --> 00:45:02,279
particular for if you were to write

00:44:59,880 --> 00:45:05,459
begin then skala because internal it

00:45:02,279 --> 00:45:07,349
uses primitives then there are a lot

00:45:05,459 --> 00:45:10,589
more optimizations which will fire later

00:45:07,349 --> 00:45:13,919
either by hotspot or by my phases in

00:45:10,589 --> 00:45:16,289
particular I'm I'm inlining objects

00:45:13,919 --> 00:45:17,880
which I don't escape scopes so if you do

00:45:16,289 --> 00:45:22,099
pattern matching the tuples won't be

00:45:17,880 --> 00:45:24,809
allocated if you have fields which are

00:45:22,099 --> 00:45:27,299
case classes and they don't escape the

00:45:24,809 --> 00:45:31,889
class they will be split into fails just

00:45:27,299 --> 00:45:34,559
objects fusion and yeah and it seems

00:45:31,889 --> 00:45:36,869
let's llvm is doing quite impressive

00:45:34,559 --> 00:45:41,939
stuff here because you it was just able

00:45:36,869 --> 00:45:43,889
to eliminate everything and just get a

00:45:41,939 --> 00:45:47,459
single constant out of it and because it

00:45:43,889 --> 00:45:52,380
was correct by the way yeah thank you

00:45:47,459 --> 00:45:55,019
for some question yes please hi I'm so

00:45:52,380 --> 00:45:57,689
about the rewriting rules do you do

00:45:55,019 --> 00:46:00,299
several passes because clearly the rules

00:45:57,689 --> 00:46:02,579
are not side important so they can

00:46:00,299 --> 00:46:05,009
influence each other like a filter

00:46:02,579 --> 00:46:08,669
example you show you showed four to

00:46:05,009 --> 00:46:10,739
change filter cause if you change for

00:46:08,669 --> 00:46:12,929
filter calls when it could apply three

00:46:10,739 --> 00:46:14,969
times and then it would simplify the

00:46:12,929 --> 00:46:17,639
whole filter chain yeah so do you do

00:46:14,969 --> 00:46:21,680
passes until the code stops changing or

00:46:17,639 --> 00:46:26,990
and if so isn't that slow as hell

00:46:21,680 --> 00:46:28,970
so they wait the way it works is it

00:46:26,990 --> 00:46:31,190
doesn't actually try to find the coat

00:46:28,970 --> 00:46:34,250
pattern that you wrote it builds the

00:46:31,190 --> 00:46:36,260
call graph for it and it's easy there is

00:46:34,250 --> 00:46:39,230
a similar call graph which works as a

00:46:36,260 --> 00:46:41,120
really fast index Rico graph will be

00:46:39,230 --> 00:46:42,860
rebuilt when the transformation will be

00:46:41,120 --> 00:46:44,870
done and it will be rebuilt

00:46:42,860 --> 00:46:46,190
incrementally it will start losing

00:46:44,870 --> 00:46:48,110
precision by doing this but the

00:46:46,190 --> 00:46:50,090
assumption is that specialization has

00:46:48,110 --> 00:46:51,320
already happened and the precision of

00:46:50,090 --> 00:46:52,850
the call graph is not that important

00:46:51,320 --> 00:46:55,130
anymore and the drills that you're

00:46:52,850 --> 00:46:58,640
defining are very important you're

00:46:55,130 --> 00:46:59,810
having big savings here so also speaking

00:46:58,640 --> 00:47:02,210
about the rule some of the details

00:46:59,810 --> 00:47:04,250
currently their rules I ordered by this

00:47:02,210 --> 00:47:06,670
size of the tree that they match on with

00:47:04,250 --> 00:47:09,980
assumption that the big rules are

00:47:06,670 --> 00:47:12,470
matching on more complicated cases which

00:47:09,980 --> 00:47:14,180
are more rare and that's more and that's

00:47:12,470 --> 00:47:18,260
why they introduce more performance

00:47:14,180 --> 00:47:20,600
improvements currently there is no plan

00:47:18,260 --> 00:47:22,340
to introduce priorities between the

00:47:20,600 --> 00:47:25,790
rules because I want to keep the system

00:47:22,340 --> 00:47:28,130
comp simple I haven't yet seen an

00:47:25,790 --> 00:47:33,110
example where the priorities matter I'd

00:47:28,130 --> 00:47:35,290
be glad if you have fun thank you yes

00:47:33,110 --> 00:47:35,290
please

00:47:41,730 --> 00:47:47,470
euro specializing on previous types

00:47:44,190 --> 00:47:50,500
sooner or later the jvm is going to have

00:47:47,470 --> 00:47:52,720
value types for more complex types so

00:47:50,500 --> 00:47:56,049
when it starts specializing on those

00:47:52,720 --> 00:47:58,359
which I assume you would want to do you

00:47:56,049 --> 00:48:01,809
get something which is very very similar

00:47:58,359 --> 00:48:03,460
to know narrator generics so does this

00:48:01,809 --> 00:48:05,290
change the semantics of scale is

00:48:03,460 --> 00:48:09,099
something that it is worth considering

00:48:05,290 --> 00:48:11,380
for Scala together okay so the question

00:48:09,099 --> 00:48:13,329
was that because I he represented the

00:48:11,380 --> 00:48:15,549
system which specializes for primitive

00:48:13,329 --> 00:48:17,589
types it would make sense of specialized

00:48:15,549 --> 00:48:19,540
for non primitive size types in

00:48:17,589 --> 00:48:21,880
particular the value types which can

00:48:19,540 --> 00:48:25,540
come as as part of for example project

00:48:21,880 --> 00:48:27,400
Valhalla so I'm presented the simplified

00:48:25,540 --> 00:48:29,410
system in practice I actually have a

00:48:27,400 --> 00:48:33,299
bound on how much your program can

00:48:29,410 --> 00:48:36,730
become bigger currently this bound is

00:48:33,299 --> 00:48:40,619
0.7 so you can your program can become

00:48:36,730 --> 00:48:44,230
0.7 time Biggers which means smaller and

00:48:40,619 --> 00:48:46,390
I'll start duplicating classes for non

00:48:44,230 --> 00:48:48,700
primitives if I still have a budget to

00:48:46,390 --> 00:48:50,500
do it currently with assumption that if

00:48:48,700 --> 00:48:52,270
I'll duplicate list for tuples for

00:48:50,500 --> 00:48:55,140
example this table doesn't escape they

00:48:52,270 --> 00:48:58,869
and then it can inline the table and

00:48:55,140 --> 00:49:01,329
allow more optimizations to heaven this

00:48:58,869 --> 00:49:05,260
approach is quite flexible and I'm not

00:49:01,329 --> 00:49:07,720
in any way tired to a specialization for

00:49:05,260 --> 00:49:09,010
Bri motives if Valhalla was will be

00:49:07,720 --> 00:49:10,569
delivered and we'll have something great

00:49:09,010 --> 00:49:14,549
for us to offer will of course take use

00:49:10,569 --> 00:49:14,549
of it thank you for awesome question

00:49:23,249 --> 00:49:30,190
yes please so first of all I think the

00:49:27,880 --> 00:49:33,549
rewrite rules for libraries is a very

00:49:30,190 --> 00:49:39,269
good idea but how does it compare to the

00:49:33,549 --> 00:49:41,259
rear I system in lms and Scallon okay so

00:49:39,269 --> 00:49:43,390
the main difference between this

00:49:41,259 --> 00:49:47,019
rewriting rules is that they support

00:49:43,390 --> 00:49:48,910
virtual calls and you can rewrite you

00:49:47,019 --> 00:49:50,769
can define rewrite rules which work and

00:49:48,910 --> 00:49:53,950
standards galilea brace on java

00:49:50,769 --> 00:49:56,499
libraries and stuff with rewrite rules

00:49:53,950 --> 00:49:59,739
the design is heavily influenced by both

00:49:56,499 --> 00:50:02,859
LMS and Haskell rewrite rules but they

00:49:59,739 --> 00:50:05,440
try to take advantage of world and be

00:50:02,859 --> 00:50:06,880
like Scala they try to use the damages

00:50:05,440 --> 00:50:09,369
of our type system they try to use

00:50:06,880 --> 00:50:11,739
venturi certain places and I believe

00:50:09,369 --> 00:50:14,229
they fit better in the design of a

00:50:11,739 --> 00:50:16,450
language both in terms of when do they

00:50:14,229 --> 00:50:19,420
apply what are both in terms of how to

00:50:16,450 --> 00:50:23,529
ship them and how to write them thank

00:50:19,420 --> 00:50:25,749
you for awesome question I do have any

00:50:23,529 --> 00:50:28,630
idea of how this will affect debugging

00:50:25,749 --> 00:50:33,190
when you modify the call I get the call

00:50:28,630 --> 00:50:36,369
graph so the main reason why tests are

00:50:33,190 --> 00:50:39,789
there is to make sure that you don't

00:50:36,369 --> 00:50:43,029
have to do by debug the optimized code

00:50:39,789 --> 00:50:45,849
unless you really have to after all

00:50:43,029 --> 00:50:48,819
these optimizations the code has nothing

00:50:45,849 --> 00:50:50,109
to do with what you wrote the fields

00:50:48,819 --> 00:50:53,799
aren't there the glasses are not there

00:50:50,109 --> 00:50:57,309
the methods are not there I if if the

00:50:53,799 --> 00:50:59,950
stuff is pure can reorder it and compute

00:50:57,309 --> 00:51:05,460
it in a different order so debug ability

00:50:59,950 --> 00:51:09,190
here currently is not small as supported

00:51:05,460 --> 00:51:11,950
the assumption is that because we have a

00:51:09,190 --> 00:51:13,989
quite a complex checking system that if

00:51:11,950 --> 00:51:15,130
your program runs correctly before the

00:51:13,989 --> 00:51:18,849
optimization it should run correctly

00:51:15,130 --> 00:51:21,579
after the optimization and if it doesn't

00:51:18,849 --> 00:51:23,289
you can easily enable all the silo

00:51:21,579 --> 00:51:25,749
self-checking system inside its

00:51:23,289 --> 00:51:28,299
optimizations which will explode if they

00:51:25,749 --> 00:51:30,520
did something wrong and then you will

00:51:28,299 --> 00:51:39,310
report the issue dress

00:51:30,520 --> 00:51:41,400
thank you okay thank you and see you

00:51:39,310 --> 00:51:41,400

YouTube URL: https://www.youtube.com/watch?v=Xv2Z4ZdInXc


