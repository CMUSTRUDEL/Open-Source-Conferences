Title: Why Netflix â¤'s Scala for Machine Learning - Jeremy Smith & Aish
Publication date: 2019-07-11
Playlist: Scala Days Lausanne 2019
Description: 
	This video was recorded at Scala Days Lausanne 2019
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

More information and the abstract can be found here:
https://scaladays.org/schedule/why-netflix-s-scala-for-machine-learning
Captions: 
	00:00:00,030 --> 00:00:05,339
okay yes I assume you can hear me I can

00:00:03,000 --> 00:00:07,560
hear my own voice so that probably means

00:00:05,339 --> 00:00:09,840
yes okay good afternoon everyone my

00:00:07,560 --> 00:00:11,820
name's ash Winton I'm a director of

00:00:09,840 --> 00:00:13,830
machine learning research at Netflix and

00:00:11,820 --> 00:00:17,010
I'm Jeremy I work with Asia on our

00:00:13,830 --> 00:00:19,710
recommendation system so today we want

00:00:17,010 --> 00:00:22,070
to talk to you about why we love Scala

00:00:19,710 --> 00:00:24,539
for doing machine learning at Netflix

00:00:22,070 --> 00:00:27,779
but first I want to let you into a dirty

00:00:24,539 --> 00:00:29,160
secret of machine learning research now

00:00:27,779 --> 00:00:32,340
you might think of machine learning

00:00:29,160 --> 00:00:33,960
researchers as something like this we're

00:00:32,340 --> 00:00:36,230
working in a very high complex

00:00:33,960 --> 00:00:39,930
environment but we're trained scientists

00:00:36,230 --> 00:00:43,350
working with precision but the reality

00:00:39,930 --> 00:00:46,350
is more like this a lot of what we do is

00:00:43,350 --> 00:00:48,840
requires a lot of iterative work a lot

00:00:46,350 --> 00:00:49,950
of trial and error we're offering trying

00:00:48,840 --> 00:00:52,800
things really fast

00:00:49,950 --> 00:00:55,230
and unfortunately that results in a lot

00:00:52,800 --> 00:00:59,460
of spaghetti code and a lot of myths in

00:00:55,230 --> 00:01:03,449
their engineering setups so why is this

00:00:59,460 --> 00:01:06,240
the case so there's a number of things

00:01:03,449 --> 00:01:07,880
that make engineering quite challenging

00:01:06,240 --> 00:01:10,229
for machine learning they're not

00:01:07,880 --> 00:01:13,080
particular to just machine learning but

00:01:10,229 --> 00:01:14,909
I'd say that they're very prevalent so

00:01:13,080 --> 00:01:17,130
number one I'll call out is that numbers

00:01:14,909 --> 00:01:19,909
have meaning and machine learning we're

00:01:17,130 --> 00:01:22,729
working with mathematical objects so

00:01:19,909 --> 00:01:25,530
when I say numbers I mean things like

00:01:22,729 --> 00:01:30,470
that they operate in a certain domain

00:01:25,530 --> 00:01:34,409
but the types that we typically use and

00:01:30,470 --> 00:01:36,299
the languages that we use these don't

00:01:34,409 --> 00:01:38,369
have really any meaning there are things

00:01:36,299 --> 00:01:41,220
like primitives so they're floats and

00:01:38,369 --> 00:01:43,530
doubles and things like that so I guess

00:01:41,220 --> 00:01:46,829
the canonical example of this is if

00:01:43,530 --> 00:01:49,950
we're working in the particular domains

00:01:46,829 --> 00:01:52,829
such as logged space when you add two

00:01:49,950 --> 00:01:54,930
numbers together in log space that does

00:01:52,829 --> 00:01:57,630
not equal just the sum of the two logs

00:01:54,930 --> 00:02:01,770
that's different things so this is a

00:01:57,630 --> 00:02:04,560
number that's imbued with some semantics

00:02:01,770 --> 00:02:07,590
that tends to get lost with the simple

00:02:04,560 --> 00:02:08,849
types we use of just primitives the

00:02:07,590 --> 00:02:11,489
second one that call out is that

00:02:08,849 --> 00:02:13,530
mathematics is obviously a very rich

00:02:11,489 --> 00:02:15,450
domain with a lot of structure

00:02:13,530 --> 00:02:16,890
and arguably the whole point of

00:02:15,450 --> 00:02:19,290
mathematics is that we can make

00:02:16,890 --> 00:02:20,970
higher-level generalizations about

00:02:19,290 --> 00:02:23,910
patterns between things and the

00:02:20,970 --> 00:02:26,970
structure of things but when we express

00:02:23,910 --> 00:02:31,020
this in code especially fast code that

00:02:26,970 --> 00:02:33,030
gets completely lost so those of you

00:02:31,020 --> 00:02:35,100
that I think I'm talking to the right

00:02:33,030 --> 00:02:37,740
audience here when I say talk about

00:02:35,100 --> 00:02:39,930
abstract algebra and you know the beauty

00:02:37,740 --> 00:02:42,050
of it and some of the higher level

00:02:39,930 --> 00:02:47,760
abstractions and insights you can gain

00:02:42,050 --> 00:02:49,860
between things that is all present the

00:02:47,760 --> 00:02:53,310
mathematics but it does tend to get lost

00:02:49,860 --> 00:02:55,470
too once were operating in code so the

00:02:53,310 --> 00:02:58,140
third reason is that we have to write

00:02:55,470 --> 00:03:00,830
really fast code so we are always

00:02:58,140 --> 00:03:03,540
trading off performance for

00:03:00,830 --> 00:03:07,290
maintainability and it creates a huge

00:03:03,540 --> 00:03:10,290
mess so this was something I randomly

00:03:07,290 --> 00:03:12,690
copy and pasted from the numeric algebra

00:03:10,290 --> 00:03:14,580
library but this is what a lot of the

00:03:12,690 --> 00:03:20,760
code that we write will tend to look

00:03:14,580 --> 00:03:25,350
like it's very procedural it's very hard

00:03:20,760 --> 00:03:26,610
to read but it is fast and then the

00:03:25,350 --> 00:03:28,590
fourth and last one I've called out is

00:03:26,610 --> 00:03:30,150
that and I'd say that this is really

00:03:28,590 --> 00:03:32,190
Liberty seeker of the machine learning

00:03:30,150 --> 00:03:34,860
that we actually spend 80 percent of our

00:03:32,190 --> 00:03:37,590
time just gluing things together a lot

00:03:34,860 --> 00:03:39,630
of what we do is manipulating data find

00:03:37,590 --> 00:03:42,000
the new data sources new signals trying

00:03:39,630 --> 00:03:44,100
to plug them into the algorithms and we

00:03:42,000 --> 00:03:47,850
spend a lot of time doing this and it's

00:03:44,100 --> 00:03:50,610
we create a lot of our bugs so I think

00:03:47,850 --> 00:03:51,959
when you think I'd tell you that when we

00:03:50,610 --> 00:03:53,250
ourselves when we think of machine

00:03:51,959 --> 00:03:55,799
learning we tend to think of ourselves

00:03:53,250 --> 00:03:58,709
writing the numeric code the the deep

00:03:55,799 --> 00:04:00,000
learning model but really that is

00:03:58,709 --> 00:04:01,680
probably where we spent just a tiny

00:04:00,000 --> 00:04:04,019
little fraction of our time and a lot of

00:04:01,680 --> 00:04:05,940
it's on this giant ETL process around

00:04:04,019 --> 00:04:09,510
everything that we all plug into that

00:04:05,940 --> 00:04:11,790
system so that kind of sets the scene

00:04:09,510 --> 00:04:13,500
but now let's talk about why we think

00:04:11,790 --> 00:04:15,360
that scholar actually helps with a lot

00:04:13,500 --> 00:04:17,880
of this and why that's you know

00:04:15,360 --> 00:04:20,160
fundamentally an advantage of scholar

00:04:17,880 --> 00:04:22,280
for doing machine learning so Jeremy's

00:04:20,160 --> 00:04:25,560
going to take us through some examples

00:04:22,280 --> 00:04:26,889
ok I'm going to kind of stay close to my

00:04:25,560 --> 00:04:30,490
notes here because this is

00:04:26,889 --> 00:04:32,740
terrifying number of people so the

00:04:30,490 --> 00:04:35,680
strategy we're going to talk about is to

00:04:32,740 --> 00:04:36,789
make the type system work for you and in

00:04:35,680 --> 00:04:39,669
order to do that we're gonna try

00:04:36,789 --> 00:04:42,159
encoding some more meaning in the types

00:04:39,669 --> 00:04:47,069
that we use and we have two examples

00:04:42,159 --> 00:04:51,509
here the schema schema types is about

00:04:47,069 --> 00:04:55,659
assigning meaning to two things that are

00:04:51,509 --> 00:04:58,029
normally not typed and reducing some

00:04:55,659 --> 00:05:01,060
boilerplate in the process and then I'm

00:04:58,029 --> 00:05:02,860
going to talk about this idea of

00:05:01,060 --> 00:05:06,250
symbolic functions and one of these we

00:05:02,860 --> 00:05:09,129
actually use one of them is just a fun

00:05:06,250 --> 00:05:11,529
sort of side project and I'll let you

00:05:09,129 --> 00:05:13,210
guess which is which but both of these

00:05:11,529 --> 00:05:15,639
are made possible by implicit which is

00:05:13,210 --> 00:05:18,189
kind of as engineers it's our hook into

00:05:15,639 --> 00:05:21,310
the into the type system so if you hate

00:05:18,189 --> 00:05:24,939
implicit this is probably not the talk

00:05:21,310 --> 00:05:28,270
for you so the first thing that I'll

00:05:24,939 --> 00:05:30,759
talk about is is these schema types and

00:05:28,270 --> 00:05:32,830
the motivation here is when we're

00:05:30,759 --> 00:05:34,960
working with data transformation

00:05:32,830 --> 00:05:37,389
pipelines it would be really nice to

00:05:34,960 --> 00:05:39,699
have some type safety for example I have

00:05:37,389 --> 00:05:41,259
some some function to aggregate scores

00:05:39,699 --> 00:05:42,909
it takes a data frame it returns a data

00:05:41,259 --> 00:05:44,830
frame well that's great but it says

00:05:42,909 --> 00:05:46,029
nothing about what the input needs to

00:05:44,830 --> 00:05:48,279
have and it says nothing about what's

00:05:46,029 --> 00:05:50,680
outputs going to look like so that's

00:05:48,279 --> 00:05:51,849
just a recipe for exceptions when

00:05:50,680 --> 00:05:56,370
somebody who didn't write that function

00:05:51,849 --> 00:06:01,419
tries to use it now spark has these

00:05:56,370 --> 00:06:03,520
types data sets were it has a type

00:06:01,419 --> 00:06:07,330
parameter that's like a case class but

00:06:03,520 --> 00:06:09,310
we can't be expected to encode every

00:06:07,330 --> 00:06:10,569
intermediate shape of our data into a

00:06:09,310 --> 00:06:12,909
case class that would just be an

00:06:10,569 --> 00:06:16,810
explosion of case classes and and we

00:06:12,909 --> 00:06:19,719
also use Netflix we have some complex

00:06:16,810 --> 00:06:22,719
nested schemas arrays of structs and so

00:06:19,719 --> 00:06:25,029
forth where it would just be unworkable

00:06:22,719 --> 00:06:27,120
to use case classes everywhere so we

00:06:25,029 --> 00:06:29,319
have schema types as kind of a

00:06:27,120 --> 00:06:31,750
relatively straightforward middle ground

00:06:29,319 --> 00:06:35,259
and what we do is we just define some

00:06:31,750 --> 00:06:37,919
columns that we care about and these are

00:06:35,259 --> 00:06:40,340
just sort of abstract bits of meaning

00:06:37,919 --> 00:06:42,740
that that

00:06:40,340 --> 00:06:47,570
all it represents is an idea of what

00:06:42,740 --> 00:06:49,760
some column means and then we'll create

00:06:47,570 --> 00:06:51,430
a data set to wrap a data frame this is

00:06:49,760 --> 00:06:56,300
not Sparx data set

00:06:51,430 --> 00:06:57,470
it's naming things is hard but we're

00:06:56,300 --> 00:07:00,620
just going to give it a phantom type

00:06:57,470 --> 00:07:02,300
that describes what its schema is and

00:07:00,620 --> 00:07:05,090
it's just going to wrap a data frame and

00:07:02,300 --> 00:07:07,610
and it has this validate method which

00:07:05,090 --> 00:07:09,740
will check at run time that the column

00:07:07,610 --> 00:07:12,350
that you said is there is there and and

00:07:09,740 --> 00:07:14,510
do some other checks at run time and

00:07:12,350 --> 00:07:16,160
then at compile time it's going to

00:07:14,510 --> 00:07:17,810
actually track the type and we have a

00:07:16,160 --> 00:07:20,960
few overloads of that I didn't show them

00:07:17,810 --> 00:07:22,850
all but you could use your imagination

00:07:20,960 --> 00:07:28,580
there so here's an example of what that

00:07:22,850 --> 00:07:32,450
looks like so if I wrap a data frame in

00:07:28,580 --> 00:07:34,460
this data set then I can validate these

00:07:32,450 --> 00:07:36,260
columns and say what the physical column

00:07:34,460 --> 00:07:37,820
name is and that'll be checked at run

00:07:36,260 --> 00:07:40,729
time and that a compile time I have some

00:07:37,820 --> 00:07:44,889
nice type information that I can carry

00:07:40,729 --> 00:07:47,750
around with that with that data set and

00:07:44,889 --> 00:07:49,729
rather than encoding a bunch of case

00:07:47,750 --> 00:07:51,620
classes of every possible shape of data

00:07:49,729 --> 00:07:56,000
I could just sort of mix and match ad

00:07:51,620 --> 00:07:57,800
hoc here to represent what's actually in

00:07:56,000 --> 00:07:59,419
that in that data frame and we'll also

00:07:57,800 --> 00:08:02,930
have this wrapper store some information

00:07:59,419 --> 00:08:06,919
about what's been validated that we'll

00:08:02,930 --> 00:08:07,700
use later on so now the func this

00:08:06,919 --> 00:08:10,849
function could be a little more

00:08:07,700 --> 00:08:12,830
descriptive it could say i i need a data

00:08:10,849 --> 00:08:14,330
set with country and profile ID and

00:08:12,830 --> 00:08:16,760
score and then i'll give you back

00:08:14,330 --> 00:08:19,849
whatever you gave me but I'll add some

00:08:16,760 --> 00:08:22,580
aggregate score to it for example and

00:08:19,849 --> 00:08:24,889
that that intersection type does all the

00:08:22,580 --> 00:08:25,940
compiled work all the work at compile

00:08:24,889 --> 00:08:28,039
time right that you don't even need

00:08:25,940 --> 00:08:30,919
shapeless for this and I mean I love

00:08:28,039 --> 00:08:33,500
shapeless but it's it's not even

00:08:30,919 --> 00:08:36,380
necessary here because if you pass in

00:08:33,500 --> 00:08:37,990
something that has there that's missing

00:08:36,380 --> 00:08:40,669
one of the requirements then the

00:08:37,990 --> 00:08:43,430
compiler will just tell you that's not

00:08:40,669 --> 00:08:44,720
it's not going to work but you could

00:08:43,430 --> 00:08:47,860
also pass in something that has more

00:08:44,720 --> 00:08:50,839
than needed and that'll be just fine and

00:08:47,860 --> 00:08:52,970
you can add some additional information

00:08:50,839 --> 00:08:55,370
in those those

00:08:52,970 --> 00:08:57,230
sort of column ideas also we could have

00:08:55,370 --> 00:08:58,880
some logic for example to validate the

00:08:57,230 --> 00:09:01,850
data type and spark we could have

00:08:58,880 --> 00:09:05,780
another Scala type that says maybe what

00:09:01,850 --> 00:09:09,200
our domain level data type is and maybe

00:09:05,780 --> 00:09:10,670
some logic to move between those and

00:09:09,200 --> 00:09:14,360
then our api's will be able to use that

00:09:10,670 --> 00:09:18,470
information to take that one validate

00:09:14,360 --> 00:09:20,270
call and just do more useful work with

00:09:18,470 --> 00:09:23,810
it right so there's no magic here we

00:09:20,270 --> 00:09:25,730
still have to to explicitly validate

00:09:23,810 --> 00:09:29,210
what we think is there in the data set

00:09:25,730 --> 00:09:31,100
we're not hitting our data warehouse at

00:09:29,210 --> 00:09:34,370
compiled time or anything to to

00:09:31,100 --> 00:09:36,740
magically infer things but rather than

00:09:34,370 --> 00:09:38,870
trying to do magic with it we're just

00:09:36,740 --> 00:09:44,710
going to try to do more work from that

00:09:38,870 --> 00:09:47,180
one call and we also removed the

00:09:44,710 --> 00:09:49,790
hard-coded physical column names that

00:09:47,180 --> 00:09:51,410
were in that function before and it

00:09:49,790 --> 00:09:53,780
could just ask the data said what's the

00:09:51,410 --> 00:09:57,170
physical column that represents the

00:09:53,780 --> 00:09:58,610
profile ID because that was provided if

00:09:57,170 --> 00:10:01,130
you'll remember when we validated that

00:09:58,610 --> 00:10:05,000
that schema the user provided that

00:10:01,130 --> 00:10:06,080
physical column name and for functions

00:10:05,000 --> 00:10:08,780
like this we actually have a datatype

00:10:06,080 --> 00:10:11,270
for them so it's call it transform

00:10:08,780 --> 00:10:12,740
function it has two type parameters the

00:10:11,270 --> 00:10:14,810
input schema that's required in the

00:10:12,740 --> 00:10:20,660
output schema that will be the result

00:10:14,810 --> 00:10:23,330
and we have the compositional methods

00:10:20,660 --> 00:10:25,850
that you'd expect for example and then

00:10:23,330 --> 00:10:29,560
it takes another transform function that

00:10:25,850 --> 00:10:32,360
has its own input and output schema and

00:10:29,560 --> 00:10:34,700
gives you back another transform

00:10:32,360 --> 00:10:36,860
function that's the the composition of

00:10:34,700 --> 00:10:38,030
them and we have this this type class

00:10:36,860 --> 00:10:40,040
here that you'll notice schema

00:10:38,030 --> 00:10:42,710
composition so this is a dependent type

00:10:40,040 --> 00:10:45,470
class that computes what the what the

00:10:42,710 --> 00:10:47,480
resulting input and output schema are so

00:10:45,470 --> 00:10:51,890
it's not as straightforward as just mash

00:10:47,480 --> 00:10:54,530
them together and like here's an example

00:10:51,890 --> 00:10:56,480
of that so if I have one that takes an A

00:10:54,530 --> 00:10:59,720
and a B and outputs a C and I have

00:10:56,480 --> 00:11:03,110
another that requires a B and a C and a

00:10:59,720 --> 00:11:06,589
D and outputs an E and F then you can

00:11:03,110 --> 00:11:09,139
notice that the resulting composition

00:11:06,589 --> 00:11:10,519
doesn't require C even though the second

00:11:09,139 --> 00:11:13,720
one requires C and the reason is because

00:11:10,519 --> 00:11:16,579
the first one produces that so we have a

00:11:13,720 --> 00:11:22,129
type class that will compute that at

00:11:16,579 --> 00:11:26,870
compile time and we can also infer some

00:11:22,129 --> 00:11:28,459
some transforms so if you use the

00:11:26,870 --> 00:11:31,819
adapted method instead of the apply

00:11:28,459 --> 00:11:34,999
method then we can actually go out and

00:11:31,819 --> 00:11:36,709
search for more transforms that we need

00:11:34,999 --> 00:11:39,430
to get some of the columns that you

00:11:36,709 --> 00:11:43,370
might be missing and this helps us

00:11:39,430 --> 00:11:47,839
reduce a lot of boilerplate glue but but

00:11:43,370 --> 00:11:51,170
keep small modular pieces without making

00:11:47,839 --> 00:11:52,550
the user sort of copy and paste a whole

00:11:51,170 --> 00:11:54,259
bunch of things that they use every time

00:11:52,550 --> 00:11:56,149
because the compiler can kind of do that

00:11:54,259 --> 00:11:57,350
copy pasting for you and it works

00:11:56,149 --> 00:11:58,699
something like this this is all very

00:11:57,350 --> 00:12:01,269
simplified and I know it's a lot of

00:11:58,699 --> 00:12:03,470
walls of code but I'm just gonna try to

00:12:01,269 --> 00:12:08,990
get through everything and maybe we'll

00:12:03,470 --> 00:12:11,180
have time at the end for questions so if

00:12:08,990 --> 00:12:16,720
we just have some type class column

00:12:11,180 --> 00:12:20,689
provider it could say that this column B

00:12:16,720 --> 00:12:22,670
can be provided given columns a and C we

00:12:20,689 --> 00:12:27,050
can derive B and we'll also drive e at

00:12:22,670 --> 00:12:28,819
the same time and and then if I call

00:12:27,050 --> 00:12:32,600
adapted then I don't even have to think

00:12:28,819 --> 00:12:36,889
about where that that B came from and we

00:12:32,600 --> 00:12:39,040
actually do this recursively so if if

00:12:36,889 --> 00:12:43,269
there's a bunch of levels of

00:12:39,040 --> 00:12:47,120
requirements and and produced columns

00:12:43,269 --> 00:12:49,730
the implicit mechanism in Scala is

00:12:47,120 --> 00:12:52,610
perfect for resolving resolving those

00:12:49,730 --> 00:12:56,300
things recursively and that just reduces

00:12:52,610 --> 00:12:59,240
a lot of boilerplate when you're

00:12:56,300 --> 00:13:01,850
composing large pipe lines of data

00:12:59,240 --> 00:13:03,829
transforms and of course if they can't

00:13:01,850 --> 00:13:05,389
satisfy all the requirements then you

00:13:03,829 --> 00:13:10,550
get a nice compiler well it's not a nice

00:13:05,389 --> 00:13:13,100
compiler but it's a compiler and with

00:13:10,550 --> 00:13:15,350
some extra compositional flavors for

00:13:13,100 --> 00:13:17,540
example you could have a state transform

00:13:15,350 --> 00:13:20,570
function where it also emits a value in

00:13:17,540 --> 00:13:22,240
addition to the the transformed data set

00:13:20,570 --> 00:13:26,630
and that can lead to some really nice

00:13:22,240 --> 00:13:29,030
expressions of large transformation

00:13:26,630 --> 00:13:31,010
pipelines and this is just sort of a

00:13:29,030 --> 00:13:32,900
contrived example of that I could say

00:13:31,010 --> 00:13:35,840
first I'm going to stratify and that's

00:13:32,900 --> 00:13:37,060
going to transform the data set and also

00:13:35,840 --> 00:13:40,340
give me some Stata fication

00:13:37,060 --> 00:13:41,960
stratification statistics and then I'll

00:13:40,340 --> 00:13:44,390
generate features i'll go ahead and

00:13:41,960 --> 00:13:46,490
train a model and that's going to give

00:13:44,390 --> 00:13:49,910
me back the train model and also maybe

00:13:46,490 --> 00:13:52,400
score the data set so that's a

00:13:49,910 --> 00:13:54,980
transformation on the data set and then

00:13:52,400 --> 00:13:59,630
I'll do some ranking and then I'll run

00:13:54,980 --> 00:14:03,140
some test metrics which will just give

00:13:59,630 --> 00:14:06,920
me back an idea of how good that model

00:14:03,140 --> 00:14:10,070
is and then I can output all of those at

00:14:06,920 --> 00:14:11,960
the end and then I would have a one

00:14:10,070 --> 00:14:13,730
composed transform function that does

00:14:11,960 --> 00:14:18,290
all these things and outputs those those

00:14:13,730 --> 00:14:24,110
interesting pieces of data at the end so

00:14:18,290 --> 00:14:30,940
that it's a pretty simple idea but it's

00:14:24,110 --> 00:14:33,650
it's very helpful for you know tracking

00:14:30,940 --> 00:14:34,700
tracking the types and the schemas

00:14:33,650 --> 00:14:36,170
throughout the entire data

00:14:34,700 --> 00:14:38,420
transformation pipeline without

00:14:36,170 --> 00:14:40,220
introducing a lot of burden on the

00:14:38,420 --> 00:14:42,800
person who's using it so if we can take

00:14:40,220 --> 00:14:46,580
this and wrap it up in a nice API and

00:14:42,800 --> 00:14:49,490
make it kind of seamless then it works

00:14:46,580 --> 00:14:51,700
pretty well alright so this is the

00:14:49,490 --> 00:14:55,880
second thing I want to talk about is

00:14:51,700 --> 00:14:59,350
this idea of symbolic functions and and

00:14:55,880 --> 00:15:02,990
the motivating thing here is we like

00:14:59,350 --> 00:15:05,210
polymorph polymorphic functions for math

00:15:02,990 --> 00:15:07,070
right so here's an example aspire I

00:15:05,210 --> 00:15:11,000
could define the logistic function like

00:15:07,070 --> 00:15:15,490
this and I just need an implicit trig

00:15:11,000 --> 00:15:15,490
which is the thing that lets me do

00:15:17,350 --> 00:15:23,930
exponential and and it actually also has

00:15:22,460 --> 00:15:26,930
to be a field but you can only fit so

00:15:23,930 --> 00:15:28,760
much on the slide and this is great it

00:15:26,930 --> 00:15:31,460
works on anything with a trig algebra

00:15:28,760 --> 00:15:32,600
but it doesn't read that well and

00:15:31,460 --> 00:15:33,860
there's also performance implications

00:15:32,600 --> 00:15:35,269
here

00:15:33,860 --> 00:15:38,540
with regard to boxing so you have to be

00:15:35,269 --> 00:15:42,560
real careful about when you use type

00:15:38,540 --> 00:15:45,560
parameters you you kind of have an

00:15:42,560 --> 00:15:47,410
explosion of specialized things or you

00:15:45,560 --> 00:15:50,149
could choose to have boxing code instead

00:15:47,410 --> 00:15:51,410
and we really can't afford that in a

00:15:50,149 --> 00:15:55,579
tight loop where we're doing a lot of

00:15:51,410 --> 00:15:57,500
number crunching so this is a fun idea

00:15:55,579 --> 00:16:02,480
for dealing with this and we're just

00:15:57,500 --> 00:16:05,660
gonna sort of bear with me it I I

00:16:02,480 --> 00:16:07,610
mentioned this idea to Martin at Scala

00:16:05,660 --> 00:16:09,920
exchange and he looked a little bit

00:16:07,610 --> 00:16:11,720
horrified and I think that's probably a

00:16:09,920 --> 00:16:13,670
common reaction but bear with me and I

00:16:11,720 --> 00:16:16,160
think it's I think it's fun at the end

00:16:13,670 --> 00:16:17,690
of the day so we'll start with an

00:16:16,160 --> 00:16:22,220
expression DSL and this is pretty

00:16:17,690 --> 00:16:24,950
probably a pretty familiar idea but the

00:16:22,220 --> 00:16:28,610
difference to notice is that the these

00:16:24,950 --> 00:16:32,029
methods don't return expression DSL they

00:16:28,610 --> 00:16:34,370
return more specific things and so we're

00:16:32,029 --> 00:16:37,370
actually going to build up a recursive

00:16:34,370 --> 00:16:39,579
type instead of forgetting about

00:16:37,370 --> 00:16:42,079
anything that's happening and we have

00:16:39,579 --> 00:16:43,310
you know case classes for each of the

00:16:42,079 --> 00:16:45,589
operations that were going to support

00:16:43,310 --> 00:16:46,880
and we have like an argument case class

00:16:45,589 --> 00:16:50,750
as well that's going to represent some

00:16:46,880 --> 00:16:53,089
abstract argument and there there's two

00:16:50,750 --> 00:16:58,010
overloads of each of these methods and

00:16:53,089 --> 00:16:59,209
the reason is if we pass a constant to

00:16:58,010 --> 00:17:01,910
one of these operators we're going to

00:16:59,209 --> 00:17:03,500
remember the constant literal type of

00:17:01,910 --> 00:17:07,640
that constant as well

00:17:03,500 --> 00:17:11,140
and here's oh and then once we have that

00:17:07,640 --> 00:17:15,740
we'll create this symbolic function one

00:17:11,140 --> 00:17:19,760
and that has a type parameter that's a

00:17:15,740 --> 00:17:21,559
higher kind of type parameter and if you

00:17:19,760 --> 00:17:24,350
apply it with some type then you'll just

00:17:21,559 --> 00:17:25,910
get that thing filled in to the

00:17:24,350 --> 00:17:27,589
expression so it doesn't seem all that

00:17:25,910 --> 00:17:31,280
useful right now but bear bear with me

00:17:27,589 --> 00:17:34,070
and the constructor for that looks a

00:17:31,280 --> 00:17:36,110
little gnarly but really just pass it a

00:17:34,070 --> 00:17:37,160
function from an argument to something

00:17:36,110 --> 00:17:39,110
and then we're going to figure out what

00:17:37,160 --> 00:17:41,390
that something means with this an apply

00:17:39,110 --> 00:17:44,720
type class right here and all that does

00:17:41,390 --> 00:17:46,400
is recurse through and find the arg0 in

00:17:44,720 --> 00:17:47,600
that type and then make a hole there

00:17:46,400 --> 00:17:49,490
instead

00:17:47,600 --> 00:17:55,910
so it's kind of like edit expanding that

00:17:49,490 --> 00:17:58,330
type out and here's what that looks like

00:17:55,910 --> 00:18:01,720
so now I could define logistic as

00:17:58,330 --> 00:18:05,780
symbolic function one I'll say x2 1 over

00:18:01,720 --> 00:18:08,180
1 plus e to the minus X and and here's

00:18:05,780 --> 00:18:12,170
what that type looks like so it's kind

00:18:08,180 --> 00:18:16,270
of an interesting type but what it means

00:18:12,170 --> 00:18:20,960
is given some T this function computes

00:18:16,270 --> 00:18:25,250
the literal type 1 plus exponentiation

00:18:20,960 --> 00:18:28,730
of or exponential of literal minus 1

00:18:25,250 --> 00:18:32,210
times that T to the power of literal

00:18:28,730 --> 00:18:34,700
minus 1 and since that's such an early

00:18:32,210 --> 00:18:39,560
type I have a nice little pretty printer

00:18:34,700 --> 00:18:42,650
for that with fun Unicode superscripts

00:18:39,560 --> 00:18:45,160
and stuff so so the entire AST of that

00:18:42,650 --> 00:18:47,780
function is is encoded into the type

00:18:45,160 --> 00:18:50,960
which might seem completely insane but

00:18:47,780 --> 00:18:52,970
really what better type for a function

00:18:50,960 --> 00:18:55,250
than exactly everything it does right I

00:18:52,970 --> 00:18:57,740
mean this this is the purest function

00:18:55,250 --> 00:19:02,000
you can get you literally cannot perform

00:18:57,740 --> 00:19:03,530
side-effects here and it also means we

00:19:02,000 --> 00:19:06,980
can do some fun things with implicit so

00:19:03,530 --> 00:19:08,870
let's take a look at what that could be

00:19:06,980 --> 00:19:12,860
so maybe we could teach the compiler

00:19:08,870 --> 00:19:14,750
algebra so I'll just create a type class

00:19:12,860 --> 00:19:18,920
called simplify another dependent type

00:19:14,750 --> 00:19:20,120
class given an expression it will apply

00:19:18,920 --> 00:19:22,790
a bunch of rules that we're defining

00:19:20,120 --> 00:19:27,260
down here and here's some examples of

00:19:22,790 --> 00:19:32,390
them for example a plus 0 is a a times 1

00:19:27,260 --> 00:19:35,360
is a a times 0 is 0 a to the 1 is a a to

00:19:32,390 --> 00:19:39,940
the 0 is 1 etc etc and really you could

00:19:35,360 --> 00:19:42,070
have as many of these as you want and

00:19:39,940 --> 00:19:44,750
we'll go back and add this to our

00:19:42,070 --> 00:19:47,060
constructor for symbolic function 1 so

00:19:44,750 --> 00:19:49,250
we're gonna we're going to take that

00:19:47,060 --> 00:19:51,050
result type from the function you passed

00:19:49,250 --> 00:19:53,120
in first we're going to simplify it and

00:19:51,050 --> 00:19:55,340
then we'll uh apply that and make this

00:19:53,120 --> 00:19:57,890
the function out of out of the result of

00:19:55,340 --> 00:20:01,370
that and here's what that looks like so

00:19:57,890 --> 00:20:03,020
if I pass it X to X times 1 plus 0

00:20:01,370 --> 00:20:04,460
just gonna be back X tax which is good

00:20:03,020 --> 00:20:07,280
so it simplifies away all the trivial

00:20:04,460 --> 00:20:08,720
stuff and this is really only limited by

00:20:07,280 --> 00:20:11,690
how many rules you're willing to write

00:20:08,720 --> 00:20:12,830
right and how how long you're willing to

00:20:11,690 --> 00:20:17,540
wait for the compiler but this is

00:20:12,830 --> 00:20:18,050
actually relatively fast so what we do

00:20:17,540 --> 00:20:20,120
next

00:20:18,050 --> 00:20:22,580
maybe we'll teach the compiler or some

00:20:20,120 --> 00:20:24,830
calculus it will make another dependent

00:20:22,580 --> 00:20:26,240
type function derivative it'll take an

00:20:24,830 --> 00:20:29,090
expression and an X and it'll give us

00:20:26,240 --> 00:20:31,970
the derivative of the expression with

00:20:29,090 --> 00:20:33,440
with respect to X and it's just again

00:20:31,970 --> 00:20:37,610
it's just the rules that you learned in

00:20:33,440 --> 00:20:39,290
grade school you know derivative of X

00:20:37,610 --> 00:20:41,390
with respect to X is one derivative of

00:20:39,290 --> 00:20:44,809
any constant is zero you know the sum of

00:20:41,390 --> 00:20:47,510
the derivative of a plus B is derivative

00:20:44,809 --> 00:20:49,820
of a plus riveted B's and so forth you

00:20:47,510 --> 00:20:52,270
know we'll have other things here like

00:20:49,820 --> 00:20:55,130
our trig functions and log and

00:20:52,270 --> 00:20:57,140
exponential and the chain rule and so

00:20:55,130 --> 00:21:02,510
forth and it's all pretty

00:20:57,140 --> 00:21:05,480
straightforward but we actually need a

00:21:02,510 --> 00:21:07,730
couple of macros here I tried I really

00:21:05,480 --> 00:21:10,250
try to reduce the macros as much as

00:21:07,730 --> 00:21:12,200
possible but for some of this stuff we

00:21:10,250 --> 00:21:16,160
need them and this is just a simple

00:21:12,200 --> 00:21:20,870
tight class that's going to take too int

00:21:16,160 --> 00:21:24,320
or literal int types everybody is

00:21:20,870 --> 00:21:25,460
familiar with literal types now right

00:21:24,320 --> 00:21:28,370
Martin mentioned them in the keynote

00:21:25,460 --> 00:21:29,990
yesterday but for example the number one

00:21:28,370 --> 00:21:33,290
has the type inch but it also has the

00:21:29,990 --> 00:21:37,190
type one and so we're going to we're

00:21:33,290 --> 00:21:41,030
going to use those a lot and so this

00:21:37,190 --> 00:21:44,030
type class will just tell us if we have

00:21:41,030 --> 00:21:47,390
two literal in what's the difference

00:21:44,030 --> 00:21:49,100
between them and here's how we I didn't

00:21:47,390 --> 00:21:50,630
actually show that the macro

00:21:49,100 --> 00:21:54,470
implementation but I think this kind of

00:21:50,630 --> 00:21:55,610
thing will be easier in dotty and so

00:21:54,470 --> 00:21:56,929
using that we could we could implement

00:21:55,610 --> 00:21:59,840
the power rule here's what that would

00:21:56,929 --> 00:22:05,000
look like you know the derivative of X

00:21:59,840 --> 00:22:07,429
to the P if P is some integer is just P

00:22:05,000 --> 00:22:08,570
times X to the P minus 1 is what that

00:22:07,429 --> 00:22:14,060
means

00:22:08,570 --> 00:22:16,160
ok so put this together we can

00:22:14,060 --> 00:22:19,220
but a derivative method on the symbolic

00:22:16,160 --> 00:22:22,160
function and what it's going to do is

00:22:19,220 --> 00:22:24,590
it's going to first apply our higher

00:22:22,160 --> 00:22:26,660
kind of type parameter there with our

00:22:24,590 --> 00:22:30,350
zero and again that's the literal type

00:22:26,660 --> 00:22:32,720
zero which which would just mean like

00:22:30,350 --> 00:22:34,790
the first argument assuming we want to

00:22:32,720 --> 00:22:36,350
generalize this to functions of more

00:22:34,790 --> 00:22:37,970
than one argument so first we're going

00:22:36,350 --> 00:22:40,450
to apply it with that with that first

00:22:37,970 --> 00:22:43,070
argument then we're going to take the

00:22:40,450 --> 00:22:45,070
derivative of that resulting expression

00:22:43,070 --> 00:22:49,550
with respect to the two that argument

00:22:45,070 --> 00:22:51,590
and put it in this type parameter D and

00:22:49,550 --> 00:22:53,360
then we're going to simplify the result

00:22:51,590 --> 00:22:55,070
of that and put the simplified version

00:22:53,360 --> 00:22:56,450
in this type parameter D s and then

00:22:55,070 --> 00:23:00,320
finally we're going to edit expand that

00:22:56,450 --> 00:23:03,050
D s and get back another symbolic

00:23:00,320 --> 00:23:05,180
function that's the derivative of the

00:23:03,050 --> 00:23:09,530
one we created okay so here's what that

00:23:05,180 --> 00:23:11,030
looks like and hey works it defined my

00:23:09,530 --> 00:23:13,130
logistic function here and then I asked

00:23:11,030 --> 00:23:14,870
for the derivative and there it is I

00:23:13,130 --> 00:23:18,320
figured it out

00:23:14,870 --> 00:23:19,970
you'll notice that I have two negatives

00:23:18,320 --> 00:23:21,680
they're being multiplied and they didn't

00:23:19,970 --> 00:23:26,450
cancel out because I've forgot to write

00:23:21,680 --> 00:23:29,090
a simplification rule for that so I

00:23:26,450 --> 00:23:32,150
should go back and do that but it did

00:23:29,090 --> 00:23:33,470
find the derivative and it's correct but

00:23:32,150 --> 00:23:38,810
how am I going to use this thing right

00:23:33,470 --> 00:23:41,360
it's it's just an expression tree at the

00:23:38,810 --> 00:23:44,240
type level if I if I have the symbolic

00:23:41,360 --> 00:23:47,330
function value its supply doesn't do

00:23:44,240 --> 00:23:49,820
anything except oops it supply doesn't

00:23:47,330 --> 00:23:51,860
do anything except give me back another

00:23:49,820 --> 00:23:53,390
expression tree which is great because

00:23:51,860 --> 00:23:55,970
then I can call symbolic functions from

00:23:53,390 --> 00:23:58,750
within other symbolic functions and and

00:23:55,970 --> 00:24:03,050
have the whole thing sort of inlined

00:23:58,750 --> 00:24:04,490
in the result type but I also probably

00:24:03,050 --> 00:24:06,800
want to be able to actually use these

00:24:04,490 --> 00:24:11,570
things without evaluating a bunch of

00:24:06,800 --> 00:24:15,050
layers of objects so that's where reify

00:24:11,570 --> 00:24:18,260
comes in we're going to turn the the

00:24:15,050 --> 00:24:20,750
symbolic function back into sort of real

00:24:18,260 --> 00:24:22,460
code with some more help from literal

00:24:20,750 --> 00:24:26,020
types and we need a couple more macros

00:24:22,460 --> 00:24:27,810
here I'm not going to go into too their

00:24:26,020 --> 00:24:30,090
implementation but

00:24:27,810 --> 00:24:32,040
I'll just name those type classes and

00:24:30,090 --> 00:24:33,720
kind of use your imagination as to what

00:24:32,040 --> 00:24:37,050
they do and it's it's all pretty

00:24:33,720 --> 00:24:40,830
straightforward and I will post the POC

00:24:37,050 --> 00:24:42,960
code later today if you want to see how

00:24:40,830 --> 00:24:44,280
it all works but here's kind of what

00:24:42,960 --> 00:24:46,620
that looks like so we have a dependent

00:24:44,280 --> 00:24:48,240
type class again called reify and it

00:24:46,620 --> 00:24:54,510
takes an expression in some t that we

00:24:48,240 --> 00:24:56,040
want to pass pass into it and the the

00:24:54,510 --> 00:24:58,620
instances of that are pretty straight

00:24:56,040 --> 00:24:59,130
straightforward so the first one here

00:24:58,620 --> 00:25:03,270
arg

00:24:59,130 --> 00:25:06,840
that's just saying that the first

00:25:03,270 --> 00:25:09,750
argh-argh zero is going to expand to be

00:25:06,840 --> 00:25:14,310
x zero in code and a constant is just

00:25:09,750 --> 00:25:17,030
it's going to be itself in code and to

00:25:14,310 --> 00:25:19,710
multiply two things together if they're

00:25:17,030 --> 00:25:21,530
the reason for any value merrick there

00:25:19,710 --> 00:25:24,930
is to say that this is for primitive

00:25:21,530 --> 00:25:28,860
numerix because i know all those have a

00:25:24,930 --> 00:25:30,720
have a x operator so i could just push

00:25:28,860 --> 00:25:32,160
him together with the time x operator in

00:25:30,720 --> 00:25:35,880
between and I've got valid code for that

00:25:32,160 --> 00:25:39,690
expression so that's kind of like our

00:25:35,880 --> 00:25:43,170
algebra but all it does is witness that

00:25:39,690 --> 00:25:47,280
I can reify an expression over a given

00:25:43,170 --> 00:25:49,100
type so for every expression operator

00:25:47,280 --> 00:25:51,810
that we want to use we'd have to have

00:25:49,100 --> 00:25:54,210
reify instance for for any given type

00:25:51,810 --> 00:25:56,700
that we want to use but we can make that

00:25:54,210 --> 00:25:58,140
be different for different types which

00:25:56,700 --> 00:26:00,930
could be interesting and here's an

00:25:58,140 --> 00:26:04,530
example of what it looks like if i Rhian

00:26:00,930 --> 00:26:08,970
I get this code which looks like pretty

00:26:04,530 --> 00:26:10,470
much the you know pretty much the

00:26:08,970 --> 00:26:16,260
quickest way you could probably do that

00:26:10,470 --> 00:26:18,900
in in Scala okay and then we're gonna

00:26:16,260 --> 00:26:20,520
like we need one more macro to take that

00:26:18,900 --> 00:26:21,690
code and and you could guess what that

00:26:20,520 --> 00:26:23,310
macro is going to do it's going to take

00:26:21,690 --> 00:26:27,270
the code and it's going to actually emit

00:26:23,310 --> 00:26:30,030
a function in Scala that in lines that

00:26:27,270 --> 00:26:32,190
code in the function and the result is

00:26:30,030 --> 00:26:35,640
going to be a specialized function over

00:26:32,190 --> 00:26:38,310
doubles that does whatever was in in the

00:26:35,640 --> 00:26:41,040
symbolic function and again I'm not

00:26:38,310 --> 00:26:41,580
going to put up yet another wall of code

00:26:41,040 --> 00:26:42,960
for that

00:26:41,580 --> 00:26:45,870
macro implementation but it's pretty

00:26:42,960 --> 00:26:46,920
it's pretty straightforward and here's

00:26:45,870 --> 00:26:50,310
kind of what it looks like I'll put

00:26:46,920 --> 00:26:53,880
together so this is a repla send this is

00:26:50,310 --> 00:26:55,500
2.13 so I can have literals there so I

00:26:53,880 --> 00:26:57,360
created the logistic function I found

00:26:55,500 --> 00:27:00,180
its derivative and then I'm going to say

00:26:57,360 --> 00:27:02,610
to double operator which which will

00:27:00,180 --> 00:27:07,110
reify that into a specialized Java util

00:27:02,610 --> 00:27:09,150
function double operator and then I I

00:27:07,110 --> 00:27:10,830
spit out the disassembly of that so we

00:27:09,150 --> 00:27:12,660
can see that yes indeed is specialized

00:27:10,830 --> 00:27:14,960
it does pretty much what you would

00:27:12,660 --> 00:27:21,600
expect it to do and it should be

00:27:14,960 --> 00:27:23,490
relatively performant ok so just as a

00:27:21,600 --> 00:27:27,300
reminder this all happened at compile

00:27:23,490 --> 00:27:29,370
time in contrast with some state there's

00:27:27,300 --> 00:27:31,560
other staging mechanisms kind of like

00:27:29,370 --> 00:27:33,030
this that are partially a compile time

00:27:31,560 --> 00:27:36,150
and partially a run time so this was all

00:27:33,030 --> 00:27:37,470
at compile time that we took that

00:27:36,150 --> 00:27:39,900
symbolic function we found its

00:27:37,470 --> 00:27:41,790
derivative and then we turned the

00:27:39,900 --> 00:27:43,740
derivative into a specialized function

00:27:41,790 --> 00:27:46,500
over doubles all at compile time and

00:27:43,740 --> 00:27:49,550
again I if I implemented this as I have

00:27:46,500 --> 00:27:52,830
I could use that for other types as well

00:27:49,550 --> 00:27:54,990
and we can trivially trivially extend

00:27:52,830 --> 00:27:56,480
that to symbolic functions of more than

00:27:54,990 --> 00:28:00,960
one arguments so that's why we had that

00:27:56,480 --> 00:28:04,620
int type parameter in the art expression

00:28:00,960 --> 00:28:08,640
DSL was so that we could you know have R

00:28:04,620 --> 00:28:10,080
0 R 1 R 2 etc it's a little more work

00:28:08,640 --> 00:28:13,680
but we could also extend this to

00:28:10,080 --> 00:28:17,250
functions over vectors the calculus is a

00:28:13,680 --> 00:28:19,920
little more complicated but it might be

00:28:17,250 --> 00:28:22,440
worth it to get you know specialized

00:28:19,920 --> 00:28:24,660
gradient computations materialized at

00:28:22,440 --> 00:28:27,030
compile time I think that we pretty cool

00:28:24,660 --> 00:28:28,890
anyway and it also gives us an

00:28:27,030 --> 00:28:31,080
opportunity to optimize based on what

00:28:28,890 --> 00:28:32,760
the type is that we're working with so

00:28:31,080 --> 00:28:36,540
you could imagine if we had a matrix

00:28:32,760 --> 00:28:38,820
type for example our reify instances for

00:28:36,540 --> 00:28:41,340
that could look ahead into the

00:28:38,820 --> 00:28:44,010
expression tree to figure out hey what's

00:28:41,340 --> 00:28:48,240
the optimal series of blasts operations

00:28:44,010 --> 00:28:52,530
to do this computation so there's a lot

00:28:48,240 --> 00:28:55,690
of opportunities there and is this a

00:28:52,530 --> 00:28:58,360
zero cost abstraction I mean not exactly

00:28:55,690 --> 00:28:59,710
there was that object hanging around

00:28:58,360 --> 00:29:00,760
that represented the expression tree but

00:28:59,710 --> 00:29:03,340
it turns out you don't actually even

00:29:00,760 --> 00:29:05,380
need that value all you need is this

00:29:03,340 --> 00:29:07,780
type and as long as the compiler has the

00:29:05,380 --> 00:29:11,290
type you can materialize the function

00:29:07,780 --> 00:29:12,610
out of thin air basically yeah so so

00:29:11,290 --> 00:29:16,510
it's kind of fun and I will post the

00:29:12,610 --> 00:29:17,530
code of this to this URL later on I

00:29:16,510 --> 00:29:20,890
haven't done it yet because I was

00:29:17,530 --> 00:29:23,170
frantically scrambling to finish this

00:29:20,890 --> 00:29:25,660
presentation but I promise to do that

00:29:23,170 --> 00:29:28,860
it's a little bit rough but you know

00:29:25,660 --> 00:29:33,520
it's fun and the takeaway that I want

00:29:28,860 --> 00:29:36,040
out of this is that people think about

00:29:33,520 --> 00:29:38,130
what problems you could solve by moving

00:29:36,040 --> 00:29:41,020
more information into the type system

00:29:38,130 --> 00:29:42,790
because a scholar program has really two

00:29:41,020 --> 00:29:44,680
programs so there's a program that

00:29:42,790 --> 00:29:46,000
happens at compile time and the result

00:29:44,680 --> 00:29:48,060
of that program is a program that

00:29:46,000 --> 00:29:50,350
happens at run time and the more

00:29:48,060 --> 00:29:52,300
computation you can do once at compile

00:29:50,350 --> 00:30:00,340
time the less computation you have to do

00:29:52,300 --> 00:30:03,010
many times at run time so yeah and you

00:30:00,340 --> 00:30:07,480
know the other takeaway is whatever

00:30:03,010 --> 00:30:09,280
crazy use case you have that that Scala

00:30:07,480 --> 00:30:13,210
wasn't even thinking about when it was

00:30:09,280 --> 00:30:16,270
designed you can you can leverage the

00:30:13,210 --> 00:30:19,600
type system to to make some of those

00:30:16,270 --> 00:30:21,670
things a reality and then wrap it in a

00:30:19,600 --> 00:30:24,640
nice API and it'll blend seamlessly with

00:30:21,670 --> 00:30:26,560
all your other Scala components so

00:30:24,640 --> 00:30:30,090
that's that's what I love about Scala it

00:30:26,560 --> 00:30:34,480
gives you the power to do these things

00:30:30,090 --> 00:30:37,180
it's not always pretty but you know the

00:30:34,480 --> 00:30:43,660
power is there and I think that's pretty

00:30:37,180 --> 00:30:45,550
unique to Scala all right so just a

00:30:43,660 --> 00:30:51,010
little peek at some of the things that

00:30:45,550 --> 00:30:52,570
we're looking forward to in Scala 3 to

00:30:51,010 --> 00:30:56,350
solve some of the problems that h/h

00:30:52,570 --> 00:30:58,090
mentioned so opaque types those are

00:30:56,350 --> 00:31:02,500
going to be huge for us because we can

00:30:58,090 --> 00:31:06,280
give more meaning to our data without

00:31:02,500 --> 00:31:08,650
any performance penalty so that's that's

00:31:06,280 --> 00:31:10,410
going to be huge for us I mean

00:31:08,650 --> 00:31:14,530
I don't know I don't care what Martins

00:31:10,410 --> 00:31:18,630
poll said that's gonna be a game-changer

00:31:14,530 --> 00:31:22,240
I think and there's also some other

00:31:18,630 --> 00:31:23,850
interesting features that you know maybe

00:31:22,240 --> 00:31:27,130
other people have touched on but

00:31:23,850 --> 00:31:29,110
principled structured types you know

00:31:27,130 --> 00:31:31,630
maybe that will end up being a better

00:31:29,110 --> 00:31:34,510
way to do the kind of ad hoc schemas

00:31:31,630 --> 00:31:35,860
that we that we were trying to

00:31:34,510 --> 00:31:37,090
accomplish with those phantom types

00:31:35,860 --> 00:31:39,160
earlier on so that that could be

00:31:37,090 --> 00:31:43,660
interesting the the metaprogramming

00:31:39,160 --> 00:31:45,850
story looks a lot cleaner in Scala 3 so

00:31:43,660 --> 00:31:50,620
a lot of the ugly macros that I had to

00:31:45,850 --> 00:31:54,490
use for for my harebrained scheme

00:31:50,620 --> 00:32:01,050
earlier will look much nicer and much

00:31:54,490 --> 00:32:04,450
more comprehensible in Scala 3 and the

00:32:01,050 --> 00:32:08,740
cleaner dependent types meaning that you

00:32:04,450 --> 00:32:12,550
know an implicit can refer to the output

00:32:08,740 --> 00:32:13,840
of a previous implicit will let us throw

00:32:12,550 --> 00:32:15,730
away a bunch of those extra type

00:32:13,840 --> 00:32:18,550
parameters that we had hanging around so

00:32:15,730 --> 00:32:22,230
if you remember I had like a you know an

00:32:18,550 --> 00:32:25,450
R and a D and a D s and each implicit

00:32:22,230 --> 00:32:28,390
subsequently filling in one of those you

00:32:25,450 --> 00:32:30,430
won't really need those anymore because

00:32:28,390 --> 00:32:33,430
of that machinery so I'm looking forward

00:32:30,430 --> 00:32:35,140
to that and it's just more ways the type

00:32:33,430 --> 00:32:39,460
system can work for you which means more

00:32:35,140 --> 00:32:41,620
reasons to love Scala and I'll turn it

00:32:39,460 --> 00:32:44,620
back over to H now and he'll talk about

00:32:41,620 --> 00:32:47,500
some of the things that are on our wish

00:32:44,620 --> 00:32:49,570
list yeah this is very much a wish list

00:32:47,500 --> 00:32:51,610
and we did some brainstorming about

00:32:49,570 --> 00:32:53,590
trying to answer the question well scale

00:32:51,610 --> 00:32:55,030
was so great for machine learning why

00:32:53,590 --> 00:32:57,490
don't you see a lot of machine learning

00:32:55,030 --> 00:33:01,090
researchers data scientists using it

00:32:57,490 --> 00:33:04,210
especially compared to Python and really

00:33:01,090 --> 00:33:07,930
a lot of it came down to some key to

00:33:04,210 --> 00:33:09,520
lenders missing so we cheekily

00:33:07,930 --> 00:33:11,350
really put together a wish list of

00:33:09,520 --> 00:33:12,790
things that we wish were built and I

00:33:11,350 --> 00:33:15,910
think would really help the adoption and

00:33:12,790 --> 00:33:17,890
the machine learning community so one of

00:33:15,910 --> 00:33:20,830
the big ones is a great notebook

00:33:17,890 --> 00:33:22,670
environment in Scala so as researchers

00:33:20,830 --> 00:33:25,780
we spend a lot of time

00:33:22,670 --> 00:33:30,260
working in Jupiter and tools like that

00:33:25,780 --> 00:33:33,410
to do this kind of visual ripple type

00:33:30,260 --> 00:33:36,170
environment it's just a very natural way

00:33:33,410 --> 00:33:38,120
for us to do our work because a lot of

00:33:36,170 --> 00:33:40,700
what we're trying is is very iterative

00:33:38,120 --> 00:33:44,030
in nature often we need to visualize it

00:33:40,700 --> 00:33:46,040
too now there's some projects that are

00:33:44,030 --> 00:33:47,300
being worked on at the moment I think

00:33:46,040 --> 00:33:49,850
there's some really interesting things

00:33:47,300 --> 00:33:51,680
with metals being looked at with being

00:33:49,850 --> 00:33:53,150
combined with Jupiter so that's

00:33:51,680 --> 00:33:55,760
promising and there's some other

00:33:53,150 --> 00:33:58,670
projects there on the horizon as well on

00:33:55,760 --> 00:33:59,720
this space but I think at the moment we

00:33:58,670 --> 00:34:05,600
just really look forward to those

00:33:59,720 --> 00:34:08,300
maturing a simple one but absolutely

00:34:05,600 --> 00:34:10,070
required we need a good plotting library

00:34:08,300 --> 00:34:12,649
there needs to be a way to visualize

00:34:10,070 --> 00:34:16,399
what we do in the Python world they use

00:34:12,649 --> 00:34:20,120
map plot Lib I'd say it's a pretty ugly

00:34:16,399 --> 00:34:23,090
library the API is pretty awful but it's

00:34:20,120 --> 00:34:26,200
comprehensive and in Scala there just

00:34:23,090 --> 00:34:31,850
isn't anything that's got a great

00:34:26,200 --> 00:34:34,610
comprehensive set of visualizations done

00:34:31,850 --> 00:34:38,210
pi is an interesting one so when I

00:34:34,610 --> 00:34:41,240
reflect back about why why has - been

00:34:38,210 --> 00:34:43,580
such a successful machine learning one

00:34:41,240 --> 00:34:46,040
of the things that occurred to us was

00:34:43,580 --> 00:34:48,350
that numpy so if you're not familiar

00:34:46,040 --> 00:34:54,890
with numpy numpy is a multi-dimensional

00:34:48,350 --> 00:34:56,600
array library it came out early in

00:34:54,890 --> 00:34:58,700
python and it became the de facto

00:34:56,600 --> 00:35:01,400
standard so if you wanted to have an

00:34:58,700 --> 00:35:04,970
array with multiple multiple dimensions

00:35:01,400 --> 00:35:06,530
of data it was just the go-to tool and

00:35:04,970 --> 00:35:10,400
because of there became the lingua

00:35:06,530 --> 00:35:13,040
franca of data science and machine

00:35:10,400 --> 00:35:15,980
learning and it gave us a way that we

00:35:13,040 --> 00:35:17,630
could in paithan have mini libraries

00:35:15,980 --> 00:35:20,570
that were speaking the same language and

00:35:17,630 --> 00:35:24,860
had the same types essentially and in

00:35:20,570 --> 00:35:27,850
the java JVM Scala community we're still

00:35:24,860 --> 00:35:29,750
missing this the one true

00:35:27,850 --> 00:35:32,780
multi-dimensional array library that we

00:35:29,750 --> 00:35:35,760
can all know we're communicating the

00:35:32,780 --> 00:35:37,740
same way that you can rely on that type

00:35:35,760 --> 00:35:40,320
so I think that that's a missing bit

00:35:37,740 --> 00:35:41,850
there there's things like breeze but

00:35:40,320 --> 00:35:43,410
there has performance some performance

00:35:41,850 --> 00:35:46,260
simplifications and last time I checked

00:35:43,410 --> 00:35:50,010
it wasn't actively developed there's

00:35:46,260 --> 00:35:53,100
numerous Java libraries that wrap lower

00:35:50,010 --> 00:35:55,230
level primitives like Blas they're also

00:35:53,100 --> 00:35:58,200
very good but the community is just

00:35:55,230 --> 00:35:59,880
extremely fragmented in this space so it

00:35:58,200 --> 00:36:02,160
makes it hard to publish a library where

00:35:59,880 --> 00:36:05,910
you have a you have an API that requires

00:36:02,160 --> 00:36:08,040
the most really dimensional array and

00:36:05,910 --> 00:36:12,410
the last one is there needs to be a good

00:36:08,040 --> 00:36:14,930
story around wrapping C++ that's

00:36:12,410 --> 00:36:17,820
unfortunately we can't get away from C++

00:36:14,930 --> 00:36:19,830
maybe in the future we will be able to

00:36:17,820 --> 00:36:22,140
but at the moment is still just so much

00:36:19,830 --> 00:36:24,240
stuff written in C++ that we need to

00:36:22,140 --> 00:36:25,740
wrap it needs to be a good story for

00:36:24,240 --> 00:36:27,690
doing that easily

00:36:25,740 --> 00:36:30,330
there's some great stuff on the horizons

00:36:27,690 --> 00:36:32,610
with that we're looking forward to Grail

00:36:30,330 --> 00:36:34,440
vien still got some question marks or

00:36:32,610 --> 00:36:36,119
either it's really going to solve the

00:36:34,440 --> 00:36:38,280
whole problem there but looks really

00:36:36,119 --> 00:36:42,000
interesting there's also a number of

00:36:38,280 --> 00:36:44,190
JYP's and progress with java that try to

00:36:42,000 --> 00:36:46,050
address this kind of rebuild Jay and I

00:36:44,190 --> 00:36:48,960
from the ground up to make it more

00:36:46,050 --> 00:36:52,050
compatible and more easy to pass data

00:36:48,960 --> 00:36:55,200
back and forth out of the JVM into the

00:36:52,050 --> 00:36:58,440
native substrate but that's still on the

00:36:55,200 --> 00:37:01,020
horizon and it's the time frames sort of

00:36:58,440 --> 00:37:03,300
unknown and then there's Scala will have

00:37:01,020 --> 00:37:06,300
to support that too so that's still a

00:37:03,300 --> 00:37:08,640
missing piece of the puzzle but I'd say

00:37:06,300 --> 00:37:14,490
the largest bit that's missing is you

00:37:08,640 --> 00:37:16,920
guys we need the scour community to take

00:37:14,490 --> 00:37:18,450
an interest in machine learning and get

00:37:16,920 --> 00:37:20,010
excited about building some of these

00:37:18,450 --> 00:37:24,619
tools and tackling some of these

00:37:20,010 --> 00:37:26,670
problems I'm a firm believer that the

00:37:24,619 --> 00:37:28,050
some of the engineering talent working

00:37:26,670 --> 00:37:31,740
in the scale community is some of the

00:37:28,050 --> 00:37:35,250
best engineering talent available so I

00:37:31,740 --> 00:37:37,800
think if I can do anything I want to get

00:37:35,250 --> 00:37:41,040
you excited about machine learning and

00:37:37,800 --> 00:37:42,480
about data science and get you excited

00:37:41,040 --> 00:37:44,880
about building some of these tools and

00:37:42,480 --> 00:37:47,070
tackling some of these challenges and if

00:37:44,880 --> 00:37:48,729
I can do that that's really a success

00:37:47,070 --> 00:37:52,599
for me

00:37:48,729 --> 00:37:54,160
so yeah on that I think well we and uh I

00:37:52,599 --> 00:37:57,430
don't know if we have time for questions

00:37:54,160 --> 00:37:59,529
we do we actually I rushed so quickly

00:37:57,430 --> 00:38:33,309
through my students that we have several

00:37:59,529 --> 00:38:36,219
minutes for questions thanks in the list

00:38:33,309 --> 00:38:39,400
of things that you mentioned we need you

00:38:36,219 --> 00:38:42,369
didn't mention a sub dataset data frame

00:38:39,400 --> 00:38:44,049
API do you feel that's because you have

00:38:42,369 --> 00:38:45,789
a sufficient replacement what you've

00:38:44,049 --> 00:38:48,130
done already or do you think that sparks

00:38:45,789 --> 00:38:51,670
is good enough or do you think we need

00:38:48,130 --> 00:38:54,640
something there I do think spot does a

00:38:51,670 --> 00:38:56,920
good job so I guess in the Python world

00:38:54,640 --> 00:39:00,609
people use pandas

00:38:56,920 --> 00:39:02,499
I think spark so there is one thing

00:39:00,609 --> 00:39:04,450
missing and spark I think the data frame

00:39:02,499 --> 00:39:07,059
API and the tooling around there is

00:39:04,450 --> 00:39:09,249
actually really good in spark it's very

00:39:07,059 --> 00:39:12,910
intuitive and very easy to pick up

00:39:09,249 --> 00:39:14,380
but I wish they had an abstraction here

00:39:12,910 --> 00:39:16,960
that meant you could also use it locally

00:39:14,380 --> 00:39:20,049
on data it didn't have to be distributed

00:39:16,960 --> 00:39:21,640
but they decide that I that wouldn't be

00:39:20,049 --> 00:39:26,130
top of my list because I do think spark

00:39:21,640 --> 00:39:26,130
does a good job with it okay thanks

00:39:35,760 --> 00:39:45,760
hi you designed the solution to

00:39:42,270 --> 00:39:48,450
innocence check schemas at compile time

00:39:45,760 --> 00:39:52,420
for data frames have you ever tried

00:39:48,450 --> 00:39:55,059
frameless and what are you reasoned I

00:39:52,420 --> 00:39:58,809
have my own reasons not to use that

00:39:55,059 --> 00:40:03,609
assets but what are your reasons not to

00:39:58,809 --> 00:40:05,829
use data sets that's a good question

00:40:03,609 --> 00:40:14,500
yes I'm I'm intimately familiar with

00:40:05,829 --> 00:40:17,140
frameless I think there's there's a

00:40:14,500 --> 00:40:23,319
little bit more machinery that frameless

00:40:17,140 --> 00:40:29,319
requires and a lot of the consumers of

00:40:23,319 --> 00:40:31,920
our API are are not Scala experts and

00:40:29,319 --> 00:40:36,849
when they when they'll see something

00:40:31,920 --> 00:40:40,299
that requires all these dozens of

00:40:36,849 --> 00:40:44,950
implicit arguments to prove things about

00:40:40,299 --> 00:40:47,290
about the code they it can be a little

00:40:44,950 --> 00:40:50,140
intimidating and I think that's one of

00:40:47,290 --> 00:40:52,089
the reasons we don't really use

00:40:50,140 --> 00:40:56,099
frameless I think it's a really cool

00:40:52,089 --> 00:40:58,900
project but there's some other

00:40:56,099 --> 00:41:00,549
shortcomings that we just needed like a

00:40:58,900 --> 00:41:05,230
little bit more of a relaxed middle

00:41:00,549 --> 00:41:07,599
ground I think and the the the scheme

00:41:05,230 --> 00:41:10,270
that we've came up came up with solves

00:41:07,599 --> 00:41:14,680
our pretty well because it's flexible

00:41:10,270 --> 00:41:18,160
enough to give us the safety that we

00:41:14,680 --> 00:41:22,809
need and a little extra information from

00:41:18,160 --> 00:41:29,140
that but but still have a escape hatches

00:41:22,809 --> 00:41:30,940
sort of for when things when the user

00:41:29,140 --> 00:41:32,859
needs to say trust me you know we have

00:41:30,940 --> 00:41:35,040
escape hatches for that so that makes

00:41:32,859 --> 00:41:35,040
sense

00:41:45,070 --> 00:41:51,170
yeah so the question was what about

00:41:46,940 --> 00:41:55,340
datasets so the spark dataset API is why

00:41:51,170 --> 00:41:57,560
you're referring to yeah that that that

00:41:55,340 --> 00:42:00,440
I kind of covered the the motivation

00:41:57,560 --> 00:42:03,200
around not using that but it's it would

00:42:00,440 --> 00:42:07,340
just be an explosion of case classes to

00:42:03,200 --> 00:42:09,500
address every combination of columns

00:42:07,340 --> 00:42:12,530
that might appear at some point in our

00:42:09,500 --> 00:42:14,120
in our transformation pipeline yeah a

00:42:12,530 --> 00:42:17,300
lot of the workflow of machine learning

00:42:14,120 --> 00:42:20,060
as we iteratively build up the schema

00:42:17,300 --> 00:42:23,270
over time so it's not like it's

00:42:20,060 --> 00:42:25,460
transforming from A to B it's a much

00:42:23,270 --> 00:42:30,530
more kind of gradual process as a sort

00:42:25,460 --> 00:42:31,310
of morphs between the two just just a

00:42:30,530 --> 00:42:33,890
very quick question

00:42:31,310 --> 00:42:36,170
um I saw that you called your library

00:42:33,890 --> 00:42:41,270
both Beaudry ah I just wonder wouldn't

00:42:36,170 --> 00:42:43,580
what the background for that was naming

00:42:41,270 --> 00:42:47,870
things is hard but I guess the idea was

00:42:43,580 --> 00:42:51,980
that you know is it a program or is it a

00:42:47,870 --> 00:42:54,680
type maybe at some point at some level

00:42:51,980 --> 00:42:56,770
what's the difference and that the

00:42:54,680 --> 00:43:01,250
reason I named it after after

00:42:56,770 --> 00:43:03,500
Baudrillard was the you know a sort of

00:43:01,250 --> 00:43:05,720
parallel to the idea of are we a

00:43:03,500 --> 00:43:06,710
universe or are we a simulation or and

00:43:05,720 --> 00:43:12,760
maybe at some point what's the

00:43:06,710 --> 00:43:12,760
difference it's deep

00:43:16,170 --> 00:43:20,350
it's pretty cool that you built and I

00:43:19,180 --> 00:43:22,990
wanted to tell

00:43:20,350 --> 00:43:25,320
could you tell bit more about how your

00:43:22,990 --> 00:43:30,070
experience verifying that it's correct

00:43:25,320 --> 00:43:32,620
and debugging it when it comes to macros

00:43:30,070 --> 00:43:41,590
or implicit soar with a cement holder

00:43:32,620 --> 00:43:44,950
design well in implicit will are pretty

00:43:41,590 --> 00:43:47,500
trustworthy if it's not going to be

00:43:44,950 --> 00:43:49,320
correct it probably won't compile with

00:43:47,500 --> 00:43:51,490
implicit

00:43:49,320 --> 00:43:55,000
assuming that you've defined everything

00:43:51,490 --> 00:43:56,950
correctly in the rules that you made so

00:43:55,000 --> 00:43:58,570
so that's less of a worry if so if you

00:43:56,950 --> 00:44:01,150
get the wrong results then you can

00:43:58,570 --> 00:44:07,360
usually poke through your rules and

00:44:01,150 --> 00:44:11,980
figure out why macros are are kind of a

00:44:07,360 --> 00:44:15,610
difficult thing to to to become an

00:44:11,980 --> 00:44:19,600
expert in because the the api's are not

00:44:15,610 --> 00:44:22,390
very well documented and there's a lot

00:44:19,600 --> 00:44:27,790
of internal quirks that you just have to

00:44:22,390 --> 00:44:29,770
encounter before you kind of blunder

00:44:27,790 --> 00:44:32,680
your way around and to into getting

00:44:29,770 --> 00:44:34,980
around them one thing that helps a lot I

00:44:32,680 --> 00:44:40,630
think is in IntelliJ you can actually

00:44:34,980 --> 00:44:42,340
connect to and from an SPT session where

00:44:40,630 --> 00:44:44,380
your code is running and then actually

00:44:42,340 --> 00:44:46,420
put breakpoints inside the macro and see

00:44:44,380 --> 00:44:48,730
what's happening that really helped me

00:44:46,420 --> 00:44:51,490
at least learn the learn kind of the

00:44:48,730 --> 00:44:53,890
learn the ropes of the macro API but

00:44:51,490 --> 00:44:55,390
fortunately that's all going away and

00:44:53,890 --> 00:44:57,460
the macro system in Scala 3 is

00:44:55,390 --> 00:45:00,610
completely redesigned and and looks a

00:44:57,460 --> 00:45:05,080
lot cleaner and has more parity with

00:45:00,610 --> 00:45:06,580
actual code so it should be a better

00:45:05,080 --> 00:45:16,330
story around that does it does answer

00:45:06,580 --> 00:45:21,610
your question regarding schema types if

00:45:16,330 --> 00:45:24,190
I understood correctly you usually call

00:45:21,610 --> 00:45:26,200
default refers to columns using types

00:45:24,190 --> 00:45:28,190
that means having at most one column of

00:45:26,200 --> 00:45:30,380
each type in the data

00:45:28,190 --> 00:45:32,869
but in my experience its Mitchell to

00:45:30,380 --> 00:45:34,960
have several columns of one type at

00:45:32,869 --> 00:45:38,089
sometimes using joints for instance

00:45:34,960 --> 00:45:41,150
right and that that's why the the

00:45:38,089 --> 00:45:44,180
columns or the the columns that we were

00:45:41,150 --> 00:45:47,839
expressing in our schema type are more

00:45:44,180 --> 00:45:49,700
about the meaning of the column rather

00:45:47,839 --> 00:45:51,470
than like a data type so those weren't

00:45:49,700 --> 00:45:54,829
data types those were like I have a

00:45:51,470 --> 00:45:57,849
column that represents the profile ID or

00:45:54,829 --> 00:46:03,020
though or the video or the features or

00:45:57,849 --> 00:46:05,799
etc and it's it's not as common to have

00:46:03,020 --> 00:46:13,609
two columns that mean the same thing

00:46:05,799 --> 00:46:15,410
that are have different values so yeah I

00:46:13,609 --> 00:46:17,089
mean that being said you if you did have

00:46:15,410 --> 00:46:19,849
that situation you could just create a

00:46:17,089 --> 00:46:22,460
new idea that you know if I have two

00:46:19,849 --> 00:46:23,720
columns that are both profile IDs what

00:46:22,460 --> 00:46:26,089
do each of them mean and make a more

00:46:23,720 --> 00:46:27,799
refined concept about what about what

00:46:26,089 --> 00:46:30,380
that meaning is so that it was about

00:46:27,799 --> 00:46:33,559
encoding little bits of meaning into the

00:46:30,380 --> 00:46:37,309
type system does that answer your

00:46:33,559 --> 00:46:39,799
question er not really okay but we'll

00:46:37,309 --> 00:46:45,260
talk about it afterwards hello hello

00:46:39,799 --> 00:46:46,730
guys I'm here last summer I met with my

00:46:45,260 --> 00:46:49,039
colleague who is working at data

00:46:46,730 --> 00:46:51,380
engineering department LA and Netflix

00:46:49,039 --> 00:46:53,660
and we were talking about vertical

00:46:51,380 --> 00:46:56,059
content development and in the regard of

00:46:53,660 --> 00:46:59,450
that I have a question what is the very

00:46:56,059 --> 00:47:02,329
next big step combining machine learning

00:46:59,450 --> 00:47:03,980
and Scala at Netflix I'm talking about

00:47:02,329 --> 00:47:06,529
more perspective more less technology

00:47:03,980 --> 00:47:10,000
more kind of strategic if I may ask this

00:47:06,529 --> 00:47:12,260
question of course yeah sure

00:47:10,000 --> 00:47:14,180
well yeah I wouldn't say we have

00:47:12,260 --> 00:47:17,569
anything kind of as grandiose as a

00:47:14,180 --> 00:47:21,940
strategy I'd say that we're quite happy

00:47:17,569 --> 00:47:23,990
with what scour a use a mixture of

00:47:21,940 --> 00:47:26,319
Python for a lot of the modeling work

00:47:23,990 --> 00:47:28,730
because the ecosystem is so rich there

00:47:26,319 --> 00:47:30,020
but scowler for everything else around

00:47:28,730 --> 00:47:31,970
it

00:47:30,020 --> 00:47:35,000
and we're quite happy with their

00:47:31,970 --> 00:47:38,710
combination so it's yeah I wouldn't say

00:47:35,000 --> 00:47:38,710
we have kind of have a strategic

00:47:38,730 --> 00:47:46,349
initiative or anything to try and change

00:47:41,400 --> 00:47:48,450
this person I'm a big fan of Schuyler so

00:47:46,349 --> 00:47:53,790
I would love to see it get richer and

00:47:48,450 --> 00:47:55,200
more adopted in this area but I'd say

00:47:53,790 --> 00:47:56,700
yeah if it's uh sort of a little bit

00:47:55,200 --> 00:47:58,650
more tactical yes we come across

00:47:56,700 --> 00:48:09,990
problems we address them and solve them

00:47:58,650 --> 00:48:13,740
and put resources behind them look I was

00:48:09,990 --> 00:48:16,589
curious about your symbolic type so if I

00:48:13,740 --> 00:48:18,270
understood correctly that that was kind

00:48:16,589 --> 00:48:20,040
of an interesting thought experiment but

00:48:18,270 --> 00:48:22,200
it also felt like it was valuable

00:48:20,040 --> 00:48:24,990
because while it was difficult to

00:48:22,200 --> 00:48:27,240
express you could write it once and then

00:48:24,990 --> 00:48:29,730
you know you can use a I guess like a

00:48:27,240 --> 00:48:32,820
library to make like the machine

00:48:29,730 --> 00:48:34,950
learning aspect easier so like how far

00:48:32,820 --> 00:48:37,400
did you take it or like why did you not

00:48:34,950 --> 00:48:40,980
try to take it further

00:48:37,400 --> 00:48:43,380
okay so I'll spoil it and say that one

00:48:40,980 --> 00:48:45,630
was the research project and not the one

00:48:43,380 --> 00:48:51,869
that we actually use in case anybody

00:48:45,630 --> 00:48:57,420
didn't guess that but so why didn't I

00:48:51,869 --> 00:49:02,599
take it further I mean it's there there

00:48:57,420 --> 00:49:05,400
so in in versions of Scala prior to 2:13

00:49:02,599 --> 00:49:08,390
it was very difficult to express some of

00:49:05,400 --> 00:49:12,450
the things that that kind of relies on

00:49:08,390 --> 00:49:14,819
so it was I had implemented it before

00:49:12,450 --> 00:49:16,290
and it was just kind of ugly and it

00:49:14,819 --> 00:49:17,460
wasn't until two thirteen came around

00:49:16,290 --> 00:49:19,170
that I really kind of cleaned up a

00:49:17,460 --> 00:49:22,560
little bit and yes that was the cleaned

00:49:19,170 --> 00:49:26,130
up version that I was displaying if you

00:49:22,560 --> 00:49:27,990
can believe that but you know why not

00:49:26,130 --> 00:49:29,849
take it further I don't think there's

00:49:27,990 --> 00:49:34,890
any good reason I kind of think it's a

00:49:29,849 --> 00:49:36,810
cool and useful thing that you know

00:49:34,890 --> 00:49:42,240
maybe it's not maybe it's a little bit

00:49:36,810 --> 00:49:47,099
strange to to do like a version of spark

00:49:42,240 --> 00:49:49,319
koujun but in the type system and it's

00:49:47,099 --> 00:49:51,140
probably not the ideal way to do that at

00:49:49,319 --> 00:49:54,030
compile time but

00:49:51,140 --> 00:49:58,350
you know the reason I haven't done more

00:49:54,030 --> 00:50:00,450
with it I think is because I'm not sure

00:49:58,350 --> 00:50:03,060
anybody would use something like that in

00:50:00,450 --> 00:50:06,450
real life I guess is the honest answer I

00:50:03,060 --> 00:50:07,800
can I can kind of give you mind of that

00:50:06,450 --> 00:50:10,620
there's someone that would be more on

00:50:07,800 --> 00:50:17,130
the user end of it so I think the gap

00:50:10,620 --> 00:50:20,100
would be support for GPUs and that kind

00:50:17,130 --> 00:50:22,380
of extra level of effort and work that

00:50:20,100 --> 00:50:26,040
needs to go and still about really

00:50:22,380 --> 00:50:29,490
highly optimizing it for computation on

00:50:26,040 --> 00:50:34,620
GPUs or Victory's code or that type of

00:50:29,490 --> 00:50:36,750
thing so what we mostly use for this

00:50:34,620 --> 00:50:39,180
Auto gradient type work at the moment is

00:50:36,750 --> 00:50:42,660
things like tensor flow and PI torch I

00:50:39,180 --> 00:50:47,310
think as languages there actually have a

00:50:42,660 --> 00:50:49,980
severe deficit in the language to be

00:50:47,310 --> 00:50:52,200
able to express these things nicely but

00:50:49,980 --> 00:50:53,580
there's being big investments on earth

00:50:52,200 --> 00:50:56,790
and people have written highly optimized

00:50:53,580 --> 00:50:59,640
underlying GPU and C++ code to make it

00:50:56,790 --> 00:51:02,610
really fast and there if it's gone in I

00:50:59,640 --> 00:51:04,560
think starving from Scala would be a

00:51:02,610 --> 00:51:07,290
much better place to start from because

00:51:04,560 --> 00:51:09,300
we can do the things that Jeremy showed

00:51:07,290 --> 00:51:10,830
us but still there needs to be that work

00:51:09,300 --> 00:51:13,860
of someone to go in and really write

00:51:10,830 --> 00:51:16,140
that performance optimized code and I

00:51:13,860 --> 00:51:19,200
think another reason is that that

00:51:16,140 --> 00:51:21,120
obviously I mean both of those things

00:51:19,200 --> 00:51:22,680
that I showed rely a lot on type

00:51:21,120 --> 00:51:24,390
inference like you wouldn't want

00:51:22,680 --> 00:51:27,750
somebody having to type out one of those

00:51:24,390 --> 00:51:30,330
big schema types or type god forbid type

00:51:27,750 --> 00:51:33,870
out that the type of that function of

00:51:30,330 --> 00:51:35,130
that symbolic function and I kind of

00:51:33,870 --> 00:51:37,890
blame IntelliJ because they have a

00:51:35,130 --> 00:51:40,050
default setting that hates type

00:51:37,890 --> 00:51:43,190
inference anywhere you use it it says

00:51:40,050 --> 00:51:45,840
that your code is wrong or it says that

00:51:43,190 --> 00:51:49,980
you know your style is wrong or whatever

00:51:45,840 --> 00:51:54,810
so that's a perception that kind of

00:51:49,980 --> 00:51:58,200
blocks interesting things hi

00:51:54,810 --> 00:52:02,060
besides using Scala to implement detail

00:51:58,200 --> 00:52:05,330
pipelines do you also use

00:52:02,060 --> 00:52:08,330
scour to evaluate your model in life

00:52:05,330 --> 00:52:11,150
online systems and in general do you

00:52:08,330 --> 00:52:13,820
think it makes sense to strive to reuse

00:52:11,150 --> 00:52:17,680
some code between two worlds like

00:52:13,820 --> 00:52:20,930
offline training on online evaluation

00:52:17,680 --> 00:52:22,520
yeah take the first step with that yes

00:52:20,930 --> 00:52:25,940
absolutely in fact I'd say that that's

00:52:22,520 --> 00:52:28,580
one of the big advantages for us are

00:52:25,940 --> 00:52:32,270
being of using Scala so I'll set up at

00:52:28,580 --> 00:52:34,730
Netflix is there we mostly the teams

00:52:32,270 --> 00:52:38,470
that we partner with mostly run Java and

00:52:34,730 --> 00:52:40,670
production we have a very heterogeneous

00:52:38,470 --> 00:52:42,890
environment in the backend offline

00:52:40,670 --> 00:52:45,170
though in terms of modeling really with

00:52:42,890 --> 00:52:47,240
modeling it's sort of anything goes it

00:52:45,170 --> 00:52:48,619
depends on the scientist so we need a

00:52:47,240 --> 00:52:53,270
way to be able to share these offline

00:52:48,619 --> 00:52:54,890
components and with the online teams and

00:52:53,270 --> 00:52:57,980
that's why we that was one of the

00:52:54,890 --> 00:53:00,950
initial motivations for us about really

00:52:57,980 --> 00:53:03,470
getting into Scala was that we felt that

00:53:00,950 --> 00:53:06,500
if we could express a lot of the feature

00:53:03,470 --> 00:53:09,530
engineering the work that we do through

00:53:06,500 --> 00:53:12,260
scholars API there that would be a much

00:53:09,530 --> 00:53:15,020
more expressive but be it would be

00:53:12,260 --> 00:53:17,750
something that we could have run offline

00:53:15,020 --> 00:53:19,640
but then deploy it in the jar and the

00:53:17,750 --> 00:53:22,190
online Java systems could also run the

00:53:19,640 --> 00:53:24,050
same code that we are using offline to

00:53:22,190 --> 00:53:32,000
produce the models and to do the

00:53:24,050 --> 00:53:34,369
research work that's it well feel free

00:53:32,000 --> 00:53:36,170
to come and chat over lunch too

00:53:34,369 --> 00:53:37,160
thanks very much for listening to us

00:53:36,170 --> 00:53:43,580
yeah

00:53:37,160 --> 00:53:43,580

YouTube URL: https://www.youtube.com/watch?v=BfaBeT0pRe0


