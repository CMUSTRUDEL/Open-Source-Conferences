Title: How an Optimizing Compiler Works - Li Haoyi
Publication date: 2019-07-11
Playlist: Scala Days Lausanne 2019
Description: 
	This video was recorded at Scala Days Lausanne 2019
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

More information and the abstract can be found here:
https://scaladays.org/schedule/double-your-performance-scalas-missing-optimizing-compiler
Captions: 
	00:00:07,069 --> 00:00:12,509
okay let's get started hello everyone so

00:00:10,950 --> 00:00:14,670
my name is Howie and this talk is going

00:00:12,509 --> 00:00:18,180
to be about how an optimizing compiler

00:00:14,670 --> 00:00:20,250
works so the number of optimizes in the

00:00:18,180 --> 00:00:22,769
scala ecosystem you have the Scala Jas

00:00:20,250 --> 00:00:25,680
optimizer your Scala JVM optimizer you

00:00:22,769 --> 00:00:27,630
have the JavaScript JIT compiler you

00:00:25,680 --> 00:00:32,189
have the JVM JIT compiler your Scala ll

00:00:27,630 --> 00:00:33,840
DM optimizer and the question is if you

00:00:32,189 --> 00:00:35,250
want to write your own optimizer how

00:00:33,840 --> 00:00:37,020
would you do that let's say any one of

00:00:35,250 --> 00:00:38,730
you wanted to say I want my own Scala

00:00:37,020 --> 00:00:40,140
optimizer how do you write your own

00:00:38,730 --> 00:00:46,620
scale optimizer to do useful

00:00:40,140 --> 00:00:48,870
optimizations so for most of people the

00:00:46,620 --> 00:00:50,730
optimizes a blackbox so code goes in one

00:00:48,870 --> 00:00:52,770
end and faster code comes out the other

00:00:50,730 --> 00:00:54,570
the goal of this talk is to open up the

00:00:52,770 --> 00:00:56,579
black box so all of you can have the

00:00:54,570 --> 00:00:58,109
intuition for how an optimizer works you

00:00:56,579 --> 00:00:59,820
will not have a total understanding

00:00:58,109 --> 00:01:00,960
because that takes a lot of effort but

00:00:59,820 --> 00:01:02,609
at least you have a sense of these are

00:01:00,960 --> 00:01:04,229
the kinds of techniques algorithms and

00:01:02,609 --> 00:01:06,330
data structures that go into an

00:01:04,229 --> 00:01:08,700
optimizer that are enough to make it do

00:01:06,330 --> 00:01:12,600
useful optimizations into your programs

00:01:08,700 --> 00:01:14,670
so about myself a software engineer at

00:01:12,600 --> 00:01:16,140
data breaks so data breaks does a lot of

00:01:14,670 --> 00:01:17,549
interesting work you also Reynolds

00:01:16,140 --> 00:01:19,259
keynote this morning there's a lot of

00:01:17,549 --> 00:01:20,460
cool stuff a lot of cool technology and

00:01:19,259 --> 00:01:22,830
a lot of cool customer problems that

00:01:20,460 --> 00:01:24,750
you're solving so we're hiring in SF

00:01:22,830 --> 00:01:26,250
Amsterdam and in China so if you guys

00:01:24,750 --> 00:01:29,250
are looking for a job and come talk to

00:01:26,250 --> 00:01:32,250
us after the presentation I also

00:01:29,250 --> 00:01:34,530
maintain a large amount of open source

00:01:32,250 --> 00:01:38,689
scholar tools so who here uses one of

00:01:34,530 --> 00:01:43,259
these tools more than I thought okay

00:01:38,689 --> 00:01:45,270
so glad you like them but this talk is

00:01:43,259 --> 00:01:48,360
not going to be about either data bricks

00:01:45,270 --> 00:01:49,740
or my open source projects rather we're

00:01:48,360 --> 00:01:51,720
going to go into optimizing compilation

00:01:49,740 --> 00:01:53,250
in three steps first again their hand

00:01:51,720 --> 00:01:54,810
optimized some source code in order to

00:01:53,250 --> 00:01:57,240
see what kind of optimizations you can

00:01:54,810 --> 00:01:59,130
do second we'll talk about how to tool

00:01:57,240 --> 00:02:01,890
can model a program in order to achieve

00:01:59,130 --> 00:02:03,360
those optimizations and lastly we'll see

00:02:01,890 --> 00:02:05,399
how we can make an automated tool

00:02:03,360 --> 00:02:07,979
actually perform the same optimizations

00:02:05,399 --> 00:02:11,179
we did by hand but automatically and not

00:02:07,979 --> 00:02:11,179
too difficult a manner

00:02:11,860 --> 00:02:17,680
so first let's talk about hand

00:02:13,240 --> 00:02:19,690
optimizing some source code so this is a

00:02:17,680 --> 00:02:21,130
small city of Java source code I'll be

00:02:19,690 --> 00:02:23,440
using Java throughout this talk because

00:02:21,130 --> 00:02:24,070
it's it's a common language everyone

00:02:23,440 --> 00:02:25,690
knows about it

00:02:24,070 --> 00:02:28,660
it compiles relatively straightforwardly

00:02:25,690 --> 00:02:30,070
to its bytecode and Scala normally

00:02:28,660 --> 00:02:31,540
converts relatively straightforwardly

00:02:30,070 --> 00:02:32,890
into Java so all of you should be able

00:02:31,540 --> 00:02:35,650
to roughly read this and know what's

00:02:32,890 --> 00:02:37,000
going on so we have a main function it

00:02:35,650 --> 00:02:39,580
takes an argument perform some

00:02:37,000 --> 00:02:42,190
computation logging returns return value

00:02:39,580 --> 00:02:43,960
for now just ignore the fact that this

00:02:42,190 --> 00:02:46,210
function doesn't do anything actually

00:02:43,960 --> 00:02:47,500
useful because optimizers made to speed

00:02:46,210 --> 00:02:49,750
up your code and not question your

00:02:47,500 --> 00:02:53,709
business plan so we have this piece of

00:02:49,750 --> 00:02:56,020
code how do we optimize this so first we

00:02:53,709 --> 00:02:58,600
notice well this logger up here is not

00:02:56,020 --> 00:02:59,800
actually a logger is a print logger and

00:02:58,600 --> 00:03:02,830
we know that because the right-hand side

00:02:59,800 --> 00:03:04,959
of the assignments because we know it's

00:03:02,830 --> 00:03:07,030
a print logger this logger.log function

00:03:04,959 --> 00:03:08,740
call can only go to one concrete

00:03:07,030 --> 00:03:12,459
implementation which starts instant auto

00:03:08,740 --> 00:03:15,430
print line so we inline that next we can

00:03:12,459 --> 00:03:17,260
see that the multiplied all though it's

00:03:15,430 --> 00:03:19,840
assigned and updated throughout this

00:03:17,260 --> 00:03:22,030
loop it's a sign here and updated here

00:03:19,840 --> 00:03:23,739
it always remains zero because it starts

00:03:22,030 --> 00:03:26,260
off as zero and you're only updating it

00:03:23,739 --> 00:03:28,150
by multiplying it so we can constant

00:03:26,260 --> 00:03:30,130
fold it and say well everywhere multiply

00:03:28,150 --> 00:03:32,230
is used just put zero and don't even

00:03:30,130 --> 00:03:35,200
bother with this multiplied variable so

00:03:32,230 --> 00:03:36,910
we simplify it like that the last few

00:03:35,200 --> 00:03:39,519
optimizations have left a bunch of code

00:03:36,910 --> 00:03:42,310
unused or dead so this logger is not

00:03:39,519 --> 00:03:44,050
used this Eckerman call is not used this

00:03:42,310 --> 00:03:47,830
whole bunch of classes are not used we

00:03:44,050 --> 00:03:49,600
can remove them this if condition zero

00:03:47,830 --> 00:03:51,070
less than hundred always going to be

00:03:49,600 --> 00:03:55,209
true we just remove the check and just

00:03:51,070 --> 00:03:57,100
directly perform the print line and two

00:03:55,209 --> 00:03:59,260
of these aukerman calls calls to the

00:03:57,100 --> 00:04:01,900
Ackermann function have constant inputs

00:03:59,260 --> 00:04:03,910
the first one acraman two and two we

00:04:01,900 --> 00:04:05,380
know will always return seven that's

00:04:03,910 --> 00:04:06,670
just the definition Ackerman and you can

00:04:05,380 --> 00:04:08,560
evaluate to yourself using this

00:04:06,670 --> 00:04:11,320
definition if you want or look up the

00:04:08,560 --> 00:04:13,570
table on Wikipedia the second one

00:04:11,320 --> 00:04:16,000
Ackerman zero and n we can look at zero

00:04:13,570 --> 00:04:19,209
put zero in here and C Ackerman zero and

00:04:16,000 --> 00:04:20,859
always returns and class one over here

00:04:19,209 --> 00:04:25,600
so we can just put n plus one here and

00:04:20,859 --> 00:04:27,610
simplify the code further lastly we can

00:04:25,600 --> 00:04:29,260
the last call to acumen and encount

00:04:27,610 --> 00:04:31,210
which we cannot partially evaluate

00:04:29,260 --> 00:04:32,890
because both inputs are unknown but we

00:04:31,210 --> 00:04:34,570
can see that this function is pure it

00:04:32,890 --> 00:04:36,940
does not have any side effects that's

00:04:34,570 --> 00:04:39,190
not do any logging and it is only used

00:04:36,940 --> 00:04:41,110
within the body of the if conditional

00:04:39,190 --> 00:04:42,460
block so because it's only used if

00:04:41,110 --> 00:04:45,730
condition you can lay it schedule it

00:04:42,460 --> 00:04:47,680
into the body of in if condition now so

00:04:45,730 --> 00:04:51,430
it never gets computed unless actually

00:04:47,680 --> 00:04:54,330
it's necessary so this is what we end up

00:04:51,430 --> 00:04:56,770
with after don't other optimizations so

00:04:54,330 --> 00:04:58,480
contrast equals one multiply is gone if

00:04:56,770 --> 00:05:00,370
statements go on to call sacrament have

00:04:58,480 --> 00:05:02,290
been either completely evaluated a

00:05:00,370 --> 00:05:05,320
partial evaluated and last call has been

00:05:02,290 --> 00:05:07,720
a late schedule into the if block so

00:05:05,320 --> 00:05:09,250
this is the simplified code and you can

00:05:07,720 --> 00:05:11,080
do this automatically because many of

00:05:09,250 --> 00:05:13,000
these optimizations I just showed you

00:05:11,080 --> 00:05:14,560
extremely mechanical you look at this

00:05:13,000 --> 00:05:15,940
this is always zero remove it you look

00:05:14,560 --> 00:05:16,420
at this this is when you use later move

00:05:15,940 --> 00:05:18,580
it later

00:05:16,420 --> 00:05:20,560
this is always this acraman call always

00:05:18,580 --> 00:05:22,600
has the same inputs just evaluate and

00:05:20,560 --> 00:05:25,780
put the result so why can't me write a

00:05:22,600 --> 00:05:31,420
program to do that so over here is a

00:05:25,780 --> 00:05:33,310
small demo I have with here is the same

00:05:31,420 --> 00:05:34,900
code that we saw earlier so it's an

00:05:33,310 --> 00:05:38,200
IntelliJ IDE to wrap in a class because

00:05:34,900 --> 00:05:39,790
Java wants you to do that and over here

00:05:38,200 --> 00:05:41,950
I have the compiled version of the same

00:05:39,790 --> 00:05:45,370
code so this is d compiled using

00:05:41,950 --> 00:05:47,440
IntelliJ so all the local variable names

00:05:45,370 --> 00:05:49,710
are gone but it has more or less the

00:05:47,440 --> 00:05:53,050
same logic C virus 3 less than 100 var

00:05:49,710 --> 00:05:55,240
var for the log Ackerman to 2 Ackerman

00:05:53,050 --> 00:05:56,770
var 3 VAR 0 so this is a compiled

00:05:55,240 --> 00:05:59,080
version the Java compiler doesn't really

00:05:56,770 --> 00:06:02,020
do any heavy optimizations up front so

00:05:59,080 --> 00:06:06,040
all of the code here is almost as if we

00:06:02,020 --> 00:06:08,740
wrote it directly so over here I have a

00:06:06,040 --> 00:06:11,710
little optimized program C optimized and

00:06:08,740 --> 00:06:14,830
it's 11 megabytes of program and I can

00:06:11,710 --> 00:06:16,570
run optimize on the source folder give

00:06:14,830 --> 00:06:18,910
you the destination folder and what

00:06:16,570 --> 00:06:21,700
method I wanted to optimize here's demo

00:06:18,910 --> 00:06:24,970
main picture in 3 turns in integer so

00:06:21,700 --> 00:06:26,470
you run it it turns away a bit and now

00:06:24,970 --> 00:06:32,440
it spits out an optimized demo class

00:06:26,470 --> 00:06:37,120
file which I can look at more yeah how

00:06:32,440 --> 00:06:46,760
do I make this bigger f1

00:06:37,120 --> 00:06:52,040
that's not it just use your fingers a

00:06:46,760 --> 00:06:54,560
correct answer so here we have the

00:06:52,040 --> 00:06:56,090
optimized version converted using this

00:06:54,560 --> 00:06:58,220
optimized tool and we can see has done

00:06:56,090 --> 00:07:00,200
almost all the same optimizations the

00:06:58,220 --> 00:07:01,730
first called acraman is in full evaluate

00:07:00,200 --> 00:07:03,650
at the seven the second called

00:07:01,730 --> 00:07:05,600
Ackerman has been partially evaluated n

00:07:03,650 --> 00:07:06,860
plus one the variable names are gone to

00:07:05,600 --> 00:07:10,310
the court VAR a 0 but it's the same as

00:07:06,860 --> 00:07:12,740
enemy so earlier as arguments the if

00:07:10,310 --> 00:07:13,880
statement here was removed the log call

00:07:12,740 --> 00:07:16,100
has been in line because it knows

00:07:13,880 --> 00:07:18,470
exactly what the target what the

00:07:16,100 --> 00:07:20,900
destination method is and the last call

00:07:18,470 --> 00:07:24,410
to Ackerman has been late scheduled into

00:07:20,900 --> 00:07:26,480
the if conditional so this is not quite

00:07:24,410 --> 00:07:28,460
exactly if you wrote it before one its

00:07:26,480 --> 00:07:30,230
decompiled codes who looks a lot uglier

00:07:28,460 --> 00:07:31,760
to some things it's not quite clever

00:07:30,230 --> 00:07:33,320
enough to figure out yet for example

00:07:31,760 --> 00:07:34,130
this demo dot print line still hanging

00:07:33,320 --> 00:07:36,140
around being useless

00:07:34,130 --> 00:07:37,400
but overall we managed to do almost all

00:07:36,140 --> 00:07:40,640
the optimizations that we're done by

00:07:37,400 --> 00:07:42,470
hand earlier so how how does this eleven

00:07:40,640 --> 00:07:44,120
megabytes of optimize go and optimize

00:07:42,470 --> 00:07:45,860
our Java code to perform all these

00:07:44,120 --> 00:07:47,630
useful optimizations and spit out a

00:07:45,860 --> 00:07:49,810
program that can run and have the same

00:07:47,630 --> 00:07:49,810
output

00:07:50,200 --> 00:07:53,800
where are my slides

00:08:01,240 --> 00:08:06,350
ok so in order to answer that question

00:08:04,130 --> 00:08:08,090
first I'm going to go into how we model

00:08:06,350 --> 00:08:10,040
the program as a program inside the

00:08:08,090 --> 00:08:11,480
optimizer before I talk about how I use

00:08:10,040 --> 00:08:14,900
that model in order to make inferences

00:08:11,480 --> 00:08:16,370
and just optimizations so there are many

00:08:14,900 --> 00:08:18,050
ways of modeling a program perhaps the

00:08:16,370 --> 00:08:19,190
one that most people be familiar with is

00:08:18,050 --> 00:08:21,500
a source code

00:08:19,190 --> 00:08:24,410
so here's the Ackermann function we saw

00:08:21,500 --> 00:08:25,640
earlier as source code so source code

00:08:24,410 --> 00:08:26,690
should be familiar with most of you

00:08:25,640 --> 00:08:29,060
that's what you write that's what you

00:08:26,690 --> 00:08:31,610
read in the code review but source code

00:08:29,060 --> 00:08:32,870
has some unfortunate properties the

00:08:31,610 --> 00:08:35,240
biggest one is that it contains all

00:08:32,870 --> 00:08:37,490
sorts of miscellaneous information which

00:08:35,240 --> 00:08:39,320
isn't really relevant to the execution

00:08:37,490 --> 00:08:42,289
of your program so all of these three

00:08:39,320 --> 00:08:43,820
are the same program and if you want to

00:08:42,289 --> 00:08:46,730
you can write Java like Python it just

00:08:43,820 --> 00:08:48,410
looks like that but if you want to write

00:08:46,730 --> 00:08:49,640
for example something uses a reg X and

00:08:48,410 --> 00:08:50,930
also analyze the source code and figure

00:08:49,640 --> 00:08:53,149
out what needs to change or what

00:08:50,930 --> 00:08:56,360
Oh does it tends to be very error-prone

00:08:53,149 --> 00:08:57,980
you can do it but tools that use red Xs

00:08:56,360 --> 00:09:00,589
on source code tend to require a human

00:08:57,980 --> 00:09:03,020
oversight for example Facebook's codemod

00:09:00,589 --> 00:09:04,550
tool which you would run code mod see

00:09:03,020 --> 00:09:05,960
the refactoring as it did and then

00:09:04,550 --> 00:09:07,910
review it yourself to make sure it did

00:09:05,960 --> 00:09:09,649
something sensible so that's okay for a

00:09:07,910 --> 00:09:13,070
refactoring tool maybe not okay for

00:09:09,649 --> 00:09:16,160
automatic optimizer the next thing that

00:09:13,070 --> 00:09:18,440
we look at is abstract syntax trees so

00:09:16,160 --> 00:09:20,420
abstract syntax trees basically take the

00:09:18,440 --> 00:09:22,370
thing that you parse out of the source

00:09:20,420 --> 00:09:24,080
code as a hierarchical tree structure

00:09:22,370 --> 00:09:26,720
and give it to you to work with

00:09:24,080 --> 00:09:28,940
so here's abstract syntax tree of the of

00:09:26,720 --> 00:09:31,010
the Ackermann function we saw earlier

00:09:28,940 --> 00:09:32,540
here's it laid out as a diagram it's a

00:09:31,010 --> 00:09:34,220
tree and you can see more or less

00:09:32,540 --> 00:09:37,040
matches the hierarchical structure of

00:09:34,220 --> 00:09:38,180
your source code so these are much more

00:09:37,040 --> 00:09:39,830
convenient to work with in source code

00:09:38,180 --> 00:09:41,600
and many compilers use abstract syntax

00:09:39,830 --> 00:09:42,980
trees especially in the front-end since

00:09:41,600 --> 00:09:44,630
that's what the really front-end gives

00:09:42,980 --> 00:09:46,130
you the parser will give you abstract

00:09:44,630 --> 00:09:47,649
syntax tree before we can do anything

00:09:46,130 --> 00:09:51,550
else to convert it to either separate

00:09:47,649 --> 00:09:54,500
representations or compile it to output

00:09:51,550 --> 00:09:58,370
so the promised abstract syntax trees is

00:09:54,500 --> 00:09:59,839
that they are pretty fragile in that you

00:09:58,370 --> 00:10:01,910
can have many different abstract syntax

00:09:59,839 --> 00:10:03,740
trees they refer to exactly the same

00:10:01,910 --> 00:10:05,360
program and not even it's not even very

00:10:03,740 --> 00:10:07,880
difficult to do this so here we have a

00:10:05,360 --> 00:10:09,740
chrome and a Ackerman be both variants

00:10:07,880 --> 00:10:11,360
on a command function and they both

00:10:09,740 --> 00:10:12,830
refer to the same program as original

00:10:11,360 --> 00:10:15,200
but also we have different abstract

00:10:12,830 --> 00:10:17,750
syntax trees which may seem obvious but

00:10:15,200 --> 00:10:21,080
you can see here we have this assigned P

00:10:17,750 --> 00:10:23,420
Q all the idents have been replaced by P

00:10:21,080 --> 00:10:25,100
and Q and here we have assigned R and s

00:10:23,420 --> 00:10:27,680
all identified for every being replaced

00:10:25,100 --> 00:10:29,839
by RNs even though when your CPU is

00:10:27,680 --> 00:10:31,490
running when your Intel I line CPU is

00:10:29,839 --> 00:10:32,829
turning through your executable it

00:10:31,490 --> 00:10:35,060
doesn't care what you call your

00:10:32,829 --> 00:10:36,079
identifiers in your local variables or

00:10:35,060 --> 00:10:39,140
whether you're moving them back and

00:10:36,079 --> 00:10:40,250
forth so this makes abstract syntax

00:10:39,140 --> 00:10:42,620
trees slightly harder to work with

00:10:40,250 --> 00:10:45,770
because effectively what you have here

00:10:42,620 --> 00:10:48,410
is you have a tree this tree has Jesus I

00:10:45,770 --> 00:10:50,540
know it's these P and Q identifier nodes

00:10:48,410 --> 00:10:52,130
for any node it's going to know what

00:10:50,540 --> 00:10:54,620
that know it does look at its contents

00:10:52,130 --> 00:10:55,730
so if else you need to look at equals

00:10:54,620 --> 00:10:57,950
equals return if else

00:10:55,730 --> 00:11:00,230
equals equals means look at Q and zero

00:10:57,950 --> 00:11:01,790
but for Q you cannot just look at the

00:11:00,230 --> 00:11:03,890
contents of Q to know anything about Q

00:11:01,790 --> 00:11:04,830
because Q itself is meaningless it's

00:11:03,890 --> 00:11:07,010
simply a reference

00:11:04,830 --> 00:11:09,330
to this assign queue node up here

00:11:07,010 --> 00:11:11,310
effectively what we have is a directed

00:11:09,330 --> 00:11:13,800
graph that happens to be embedded within

00:11:11,310 --> 00:11:15,779
our tree structure using these reference

00:11:13,800 --> 00:11:18,300
references of assignments and identify

00:11:15,779 --> 00:11:21,600
us this is an idea we'll come back to

00:11:18,300 --> 00:11:23,040
later next representation we look at is

00:11:21,600 --> 00:11:24,810
byte code this is the thing your Java

00:11:23,040 --> 00:11:26,670
compiler spits out when you compile it

00:11:24,810 --> 00:11:28,769
into binary so on the right we have a

00:11:26,670 --> 00:11:30,300
command function same as earlier on the

00:11:28,769 --> 00:11:34,500
left if the byte code as a linear set of

00:11:30,300 --> 00:11:36,420
instructions bytecode works by executing

00:11:34,500 --> 00:11:38,450
top to bottom and each instruction

00:11:36,420 --> 00:11:41,790
either move something on to the stack

00:11:38,450 --> 00:11:43,589
does execute on the things on the stack

00:11:41,790 --> 00:11:46,380
for example maybe it adds two numbers on

00:11:43,589 --> 00:11:47,790
the stack leaving one number or maybe it

00:11:46,380 --> 00:11:49,440
returns the last number on the stack or

00:11:47,790 --> 00:11:50,730
it takes something on the stack and puts

00:11:49,440 --> 00:11:53,519
it back into a local variable array

00:11:50,730 --> 00:11:54,870
which is over here this function has no

00:11:53,519 --> 00:11:56,250
local variables so the only local

00:11:54,870 --> 00:11:58,230
variables are the two input parameters

00:11:56,250 --> 00:11:59,339
which kind of makes sense so here you

00:11:58,230 --> 00:12:00,540
can see the stack getting bigger and

00:11:59,339 --> 00:12:03,779
smaller as it puts things on and

00:12:00,540 --> 00:12:05,250
computes things or pop stuff off so the

00:12:03,779 --> 00:12:06,990
big problem is working with byte code is

00:12:05,250 --> 00:12:09,959
that working with byte code is pretty

00:12:06,990 --> 00:12:11,459
difficult to modify so here let's

00:12:09,959 --> 00:12:13,320
imagine we wanted to replace the

00:12:11,459 --> 00:12:15,300
Ackermann function at the end decrement

00:12:13,320 --> 00:12:17,250
call at the ends with a second decrement

00:12:15,300 --> 00:12:18,510
to function call and let's say it

00:12:17,250 --> 00:12:20,190
doesn't think the first parameter we

00:12:18,510 --> 00:12:22,170
only want a second parameter what I'm

00:12:20,190 --> 00:12:23,730
going to do this let's ignore for now

00:12:22,170 --> 00:12:25,649
let's just say we want to modify this

00:12:23,730 --> 00:12:29,130
function in a relatively straightforward

00:12:25,649 --> 00:12:30,450
way so in order to do that to bytecode

00:12:29,130 --> 00:12:32,160
you not only have to replace the

00:12:30,450 --> 00:12:35,040
instruction which is down here with

00:12:32,160 --> 00:12:37,860
acraman Sacramento you also need to

00:12:35,040 --> 00:12:40,320
trace up the stack to see where the

00:12:37,860 --> 00:12:43,050
variable that is the first parameter

00:12:40,320 --> 00:12:44,820
came from remove that instruction look

00:12:43,050 --> 00:12:46,380
at where that variables in inputs came

00:12:44,820 --> 00:12:48,480
from I remove those corresponding

00:12:46,380 --> 00:12:51,390
instructions so even the small change

00:12:48,480 --> 00:12:53,550
tends to require changes so even a small

00:12:51,390 --> 00:12:55,230
change to your logical program tends to

00:12:53,550 --> 00:12:56,940
require changes all over your bytecode

00:12:55,230 --> 00:12:58,140
program and that makes working in the

00:12:56,940 --> 00:12:58,620
back code very difficult even a tiny

00:12:58,140 --> 00:13:00,089
change

00:12:58,620 --> 00:13:02,070
reshuffle everything another time you

00:13:00,089 --> 00:13:03,810
change we shuffle everything and that's

00:13:02,070 --> 00:13:08,339
both expensive and easy to get wrong as

00:13:03,810 --> 00:13:10,350
a programmer so earlier we talked about

00:13:08,339 --> 00:13:14,300
the graph structure of es keys let us

00:13:10,350 --> 00:13:14,300
now talk about theater flow graphs

00:13:14,649 --> 00:13:19,459
so data flow graphs are basically

00:13:17,120 --> 00:13:21,980
basically a sts but with all the eyes

00:13:19,459 --> 00:13:24,290
assign identifier pairs verified as

00:13:21,980 --> 00:13:26,810
fully fledged edges within the syntax

00:13:24,290 --> 00:13:28,550
tree so here we see we have a chrome an

00:13:26,810 --> 00:13:30,170
acrobat a acraman be the three

00:13:28,550 --> 00:13:31,430
representation the three variants we had

00:13:30,170 --> 00:13:33,529
earlier that we know all do the same

00:13:31,430 --> 00:13:35,899
thing and they all compile to the same

00:13:33,529 --> 00:13:38,480
ast which is here represented with the N

00:13:35,899 --> 00:13:41,420
going directly to plus 2 equals equals

00:13:38,480 --> 00:13:43,430
and 2 minus in this case so the ast

00:13:41,420 --> 00:13:44,870
doesn't care what your how you're moving

00:13:43,430 --> 00:13:47,360
variables in and out of local variables

00:13:44,870 --> 00:13:50,570
or moving them into on the on the

00:13:47,360 --> 00:13:53,180
expression stack the data flow graph

00:13:50,570 --> 00:13:58,370
only cares wherever where the value

00:13:53,180 --> 00:14:00,740
comes from and where the value goes so

00:13:58,370 --> 00:14:02,180
in a data flow graph the inputs

00:14:00,740 --> 00:14:04,610
instructions are simply the incoming

00:14:02,180 --> 00:14:05,870
edges to the instruction so in if you

00:14:04,610 --> 00:14:08,000
want to do modifications I replace

00:14:05,870 --> 00:14:10,850
ackerman with a command to in this data

00:14:08,000 --> 00:14:12,620
flow graph you replace the node I come I

00:14:10,850 --> 00:14:15,320
recommend to look at the edge that was

00:14:12,620 --> 00:14:17,089
the first input remove it and simply

00:14:15,320 --> 00:14:18,620
removed upstream edges and they were

00:14:17,089 --> 00:14:20,630
corresponding the words from the data

00:14:18,620 --> 00:14:22,970
flow graph so working with data flow

00:14:20,630 --> 00:14:24,470
graphs basically every node in the graph

00:14:22,970 --> 00:14:28,130
which is instruction your programmers

00:14:24,470 --> 00:14:30,260
execute has direct edges from its inputs

00:14:28,130 --> 00:14:32,060
and direct edges to the places where its

00:14:30,260 --> 00:14:33,140
output is being used so the fact that

00:14:32,060 --> 00:14:34,430
you've directed just to basically

00:14:33,140 --> 00:14:36,079
everything that no one cares about makes

00:14:34,430 --> 00:14:38,060
it very easy to work with the node both

00:14:36,079 --> 00:14:40,540
to analyze it or to modify it if you

00:14:38,060 --> 00:14:42,740
want to change it during optimization

00:14:40,540 --> 00:14:44,540
this description is greatly simplified

00:14:42,740 --> 00:14:46,430
so there's a lot more detail around

00:14:44,540 --> 00:14:49,040
control flow around managing of state

00:14:46,430 --> 00:14:50,660
around exceptions and early returns

00:14:49,040 --> 00:14:57,740
which I won't go into for now but we can

00:14:50,660 --> 00:15:00,589
talk to about later so we've talked

00:14:57,740 --> 00:15:02,089
about hand optimizing some code we've

00:15:00,589 --> 00:15:04,250
seen the optimizations you can do the

00:15:02,089 --> 00:15:06,079
scheduling inlining constant folding

00:15:04,250 --> 00:15:07,790
we've seen that a program can do it

00:15:06,079 --> 00:15:09,860
automatically on a piece of byte code

00:15:07,790 --> 00:15:11,540
and we've looked at different ways in

00:15:09,860 --> 00:15:14,480
which you can model our program as a

00:15:11,540 --> 00:15:16,220
data structure it to work with so the

00:15:14,480 --> 00:15:18,620
last section of this talk will go into

00:15:16,220 --> 00:15:20,779
doing the inferences optimizations

00:15:18,620 --> 00:15:22,339
to actually perform those optimizations

00:15:20,779 --> 00:15:24,820
given the data structure that we are

00:15:22,339 --> 00:15:24,820
constructing

00:15:27,090 --> 00:15:33,190
so the first one will be type inference

00:15:29,590 --> 00:15:35,770
and cost constant folding so type

00:15:33,190 --> 00:15:37,690
inference involves inferring constraints

00:15:35,770 --> 00:15:39,970
about the values in your program let's

00:15:37,690 --> 00:15:42,100
see have a variable X what's X

00:15:39,970 --> 00:15:43,300
is it an integer string is an array is

00:15:42,100 --> 00:15:44,890
that our sequence it has multiple

00:15:43,300 --> 00:15:46,960
possibilities is it something else

00:15:44,890 --> 00:15:48,730
what do you know about this variable X

00:15:46,960 --> 00:15:50,440
can tell us what you can do to change

00:15:48,730 --> 00:15:52,270
the program for example if you know the

00:15:50,440 --> 00:15:54,250
variable X is of a certain type then you

00:15:52,270 --> 00:15:56,980
can check any you can convert any as

00:15:54,250 --> 00:15:59,680
instance of so is can remove any as

00:15:56,980 --> 00:16:01,720
distance of that are redundant or you

00:15:59,680 --> 00:16:03,640
can convert any is instance of to either

00:16:01,720 --> 00:16:06,310
true or false and propagate those to

00:16:03,640 --> 00:16:07,540
remove if statements to do more constant

00:16:06,310 --> 00:16:10,960
folding and do other sorts of

00:16:07,540 --> 00:16:13,000
optimizations in general the more things

00:16:10,960 --> 00:16:14,920
that you can infer about the program the

00:16:13,000 --> 00:16:16,930
more optimizations you can do so as

00:16:14,920 --> 00:16:19,120
optimizing compiler that goes optimize

00:16:16,930 --> 00:16:23,320
to infer as much as possible and then

00:16:19,120 --> 00:16:26,020
optimize based on those facts so talking

00:16:23,320 --> 00:16:27,460
about type inference types are usually

00:16:26,020 --> 00:16:29,380
model as a lattice so here's our

00:16:27,460 --> 00:16:31,180
simplified type lattice any integer

00:16:29,380 --> 00:16:35,710
sequence with a single string builder an

00:16:31,180 --> 00:16:36,880
array of floats so in Latin that is if

00:16:35,710 --> 00:16:38,710
you have two things of different types

00:16:36,880 --> 00:16:40,630
we for now we'll just say that we're

00:16:38,710 --> 00:16:43,090
going to take the common super type of

00:16:40,630 --> 00:16:45,460
those two things as a type of the value

00:16:43,090 --> 00:16:46,840
so if I have a variable X which is

00:16:45,460 --> 00:16:49,390
either string or string builder is at

00:16:46,840 --> 00:16:51,250
our sequence if of a variable X which is

00:16:49,390 --> 00:16:54,280
either integer or string we'll just call

00:16:51,250 --> 00:16:55,540
it any for now so you can do this with

00:16:54,280 --> 00:16:57,400
Union types in other ways I'm modeling

00:16:55,540 --> 00:17:00,280
it but for now this simplifies it for

00:16:57,400 --> 00:17:02,140
this discussion um

00:17:00,280 --> 00:17:04,330
modeling singleton types in the lattice

00:17:02,140 --> 00:17:07,180
which are basically constants it's also

00:17:04,330 --> 00:17:09,550
straightforward an integer can be 0 1 2

00:17:07,180 --> 00:17:12,400
or any other integer a string can be any

00:17:09,550 --> 00:17:14,410
constant knowing value of the string and

00:17:12,400 --> 00:17:16,209
he BC 3ds as any other types in your

00:17:14,410 --> 00:17:18,550
program so if AB something is either 0

00:17:16,209 --> 00:17:19,870
or 1 you can assume as integer if

00:17:18,550 --> 00:17:21,880
something's either Hello or world you

00:17:19,870 --> 00:17:24,400
treat your string hello or string build

00:17:21,880 --> 00:17:26,110
a tree test our sequence and so on so

00:17:24,400 --> 00:17:28,209
singleton types really adjust any other

00:17:26,110 --> 00:17:32,890
types with more specific information

00:17:28,209 --> 00:17:35,020
about the value being described so let's

00:17:32,890 --> 00:17:37,600
go to inferring values on the data flow

00:17:35,020 --> 00:17:38,950
graph so here is a data flow graph for

00:17:37,600 --> 00:17:41,710
the simplified version of

00:17:38,950 --> 00:17:43,810
this simplified version of the main

00:17:41,710 --> 00:17:45,160
method we looked at earlier so I removed

00:17:43,810 --> 00:17:47,980
a bunch of stuff that we don't care

00:17:45,160 --> 00:17:49,720
about for now we have this count equals

00:17:47,980 --> 00:17:51,460
zero x equals zero

00:17:49,720 --> 00:17:52,720
while counts less in the input end if

00:17:51,460 --> 00:17:54,700
multiplied less than hundred I log

00:17:52,720 --> 00:17:56,980
something increment count multiplied

00:17:54,700 --> 00:17:59,380
multiplied so there's a loop here which

00:17:56,980 --> 00:18:01,330
makes a program a bit cyclic and so you

00:17:59,380 --> 00:18:02,530
end up having a bit of a cycle in the

00:18:01,330 --> 00:18:04,360
data flow graph which is why it looks a

00:18:02,530 --> 00:18:05,800
bit messy but I'll walk you through this

00:18:04,360 --> 00:18:10,420
mess so we can understand what's going

00:18:05,800 --> 00:18:14,470
on first we start off at the top of the

00:18:10,420 --> 00:18:16,060
function in block zero we say we look at

00:18:14,470 --> 00:18:18,400
this and see well it's assigning zero to

00:18:16,060 --> 00:18:22,830
multiply zero to account so I can assign

00:18:18,400 --> 00:18:26,080
these two inferences zero and zero next

00:18:22,830 --> 00:18:28,270
next block that executes is this count

00:18:26,080 --> 00:18:29,830
less than anything and this is to check

00:18:28,270 --> 00:18:32,050
whether to go into if you go into the

00:18:29,830 --> 00:18:34,930
while loop I'll just exit and go return

00:18:32,050 --> 00:18:37,720
directly so that's highlighted here in

00:18:34,930 --> 00:18:39,820
the data flow graph and I know that n is

00:18:37,720 --> 00:18:41,980
an arbitrary integer because I it's an

00:18:39,820 --> 00:18:44,530
input parameter than what it is and I

00:18:41,980 --> 00:18:46,570
know count is zero from earlier so I

00:18:44,530 --> 00:18:49,030
know less than off between arbitrary

00:18:46,570 --> 00:18:51,910
integer and zero is arbitrary boolean if

00:18:49,030 --> 00:18:53,680
goes if statement I don't know what it's

00:18:51,910 --> 00:18:58,300
going to go do an if statement by new to

00:18:53,680 --> 00:18:59,560
analyze both cases for now let's ignore

00:18:58,300 --> 00:19:00,940
block three because it's just a return

00:18:59,560 --> 00:19:05,170
doesn't do anything interesting to our

00:19:00,940 --> 00:19:06,700
variables got one B and Ocwen C I will

00:19:05,170 --> 00:19:09,340
ignore as well since you also don't do

00:19:06,700 --> 00:19:11,860
anything to the variables just simplify

00:19:09,340 --> 00:19:14,110
it and let's go to block two which is

00:19:11,860 --> 00:19:16,450
here in the program and here on the data

00:19:14,110 --> 00:19:19,000
flow graph so count plus equals one

00:19:16,450 --> 00:19:20,290
corresponds to this these edges in the

00:19:19,000 --> 00:19:23,460
data flow graph where I take this count

00:19:20,290 --> 00:19:26,920
variable value I add it together with 1

00:19:23,460 --> 00:19:31,000
that gives me 0 plus 1 is 1 and I save

00:19:26,920 --> 00:19:33,190
it back into count so what happens I

00:19:31,000 --> 00:19:35,650
knew a new count is zero now I know

00:19:33,190 --> 00:19:38,950
count is 1 count is either 0 or 1 count

00:19:35,650 --> 00:19:41,800
is an integer I do the same thing for

00:19:38,950 --> 00:19:42,220
multiplied and I so multiply x equals

00:19:41,800 --> 00:19:44,650
count

00:19:42,220 --> 00:19:47,170
I take multiplied and count feed them in

00:19:44,650 --> 00:19:49,780
two times zero times arbitrary integer

00:19:47,170 --> 00:19:52,480
is 0 I put that back into multiplied and

00:19:49,780 --> 00:19:52,840
look in the common super type of 0 and 0

00:19:52,480 --> 00:19:55,299
is

00:19:52,840 --> 00:19:58,240
zero so this tells us at multiple ease

00:19:55,299 --> 00:20:02,529
and this part analysis count is an

00:19:58,240 --> 00:20:05,409
integer and multiply this zero so we

00:20:02,529 --> 00:20:07,000
just updated the infra inference

00:20:05,409 --> 00:20:08,860
previously we thought it was zero now we

00:20:07,000 --> 00:20:10,029
know now we think is integer and so when

00:20:08,860 --> 00:20:12,039
you propagate propagate that change

00:20:10,029 --> 00:20:14,590
forward through the data flow graph in

00:20:12,039 --> 00:20:16,990
order to update anyone else who may be

00:20:14,590 --> 00:20:18,789
assuming that count is still zero in

00:20:16,990 --> 00:20:22,750
this case there are two downstream nodes

00:20:18,789 --> 00:20:27,730
there's plus and there's greater than or

00:20:22,750 --> 00:20:30,399
less than so count and count as an

00:20:27,730 --> 00:20:33,279
integer and as an integer this becomes a

00:20:30,399 --> 00:20:34,960
boolean this less than block because it

00:20:33,279 --> 00:20:36,370
was already arbitrary boolean before we

00:20:34,960 --> 00:20:40,870
can stop the propagation there nothing

00:20:36,370 --> 00:20:42,460
changed count which is integer plus one

00:20:40,870 --> 00:20:44,710
integer plus one is still an integer

00:20:42,460 --> 00:20:47,470
don't what it is it's an integer in some

00:20:44,710 --> 00:20:49,720
integer and I put that back in to count

00:20:47,470 --> 00:20:51,880
which is now an integer since we already

00:20:49,720 --> 00:20:53,710
saw convert an integer earlier this does

00:20:51,880 --> 00:20:57,100
not need to we can stop the propagation

00:20:53,710 --> 00:20:59,730
and so we end up with this set of

00:20:57,100 --> 00:21:03,429
inferences for this program graph

00:20:59,730 --> 00:21:05,860
multiplied is zero this x is always zero

00:21:03,429 --> 00:21:07,929
so the x is the result of multiply times

00:21:05,860 --> 00:21:10,029
count which is always zero counties

00:21:07,929 --> 00:21:12,010
integer and your on use integer this

00:21:10,029 --> 00:21:14,620
less than is always a boolean this Plus

00:21:12,010 --> 00:21:16,029
is always an integer so now we've

00:21:14,620 --> 00:21:17,919
inferred all this we can then use this

00:21:16,029 --> 00:21:19,899
information to simplify the program

00:21:17,919 --> 00:21:21,190
quite straightforwardly for example we

00:21:19,899 --> 00:21:23,200
can take multiplied and just replace it

00:21:21,190 --> 00:21:24,159
with zero everywhere it's used and we

00:21:23,200 --> 00:21:26,350
can take all the code that computes

00:21:24,159 --> 00:21:27,490
multiplied which we know it's always

00:21:26,350 --> 00:21:30,460
going to be zero and just remove that

00:21:27,490 --> 00:21:31,690
code since we know the output so

00:21:30,460 --> 00:21:33,700
removing all that code and data flow

00:21:31,690 --> 00:21:36,909
graph in this simplified data flow graph

00:21:33,700 --> 00:21:38,740
where block zero just has one zero that

00:21:36,909 --> 00:21:40,570
is assigned to this current variable it

00:21:38,740 --> 00:21:42,250
goes in this if statement loops around a

00:21:40,570 --> 00:21:44,559
few times incrementing one to count and

00:21:42,250 --> 00:21:46,840
then returning something I didn't

00:21:44,559 --> 00:21:48,340
specify in this function and this data

00:21:46,840 --> 00:21:49,990
flow graph can be serialized in a

00:21:48,340 --> 00:21:54,669
relatively straightforward fashion to

00:21:49,990 --> 00:21:55,870
this this program in reality is easy to

00:21:54,669 --> 00:21:57,700
serialize to bytecode rather than

00:21:55,870 --> 00:21:58,899
serialize to a source code but when you

00:21:57,700 --> 00:22:01,710
decompile the bytecode you get this

00:21:58,899 --> 00:22:01,710
source program

00:22:02,670 --> 00:22:07,200
so next thing I look at is

00:22:03,930 --> 00:22:09,180
interprocedural inference so just now

00:22:07,200 --> 00:22:10,980
everything was inside one function and

00:22:09,180 --> 00:22:12,870
he had the loops had basic blocks you're

00:22:10,980 --> 00:22:15,000
jumping around but you're still within

00:22:12,870 --> 00:22:17,040
one function body now we will look at

00:22:15,000 --> 00:22:20,640
when there are multiple functions what

00:22:17,040 --> 00:22:22,500
do we do so here we have mean and called

00:22:20,640 --> 00:22:25,230
main calls called and then it returns

00:22:22,500 --> 00:22:28,440
the result of called after passing 0 and

00:22:25,230 --> 00:22:31,350
n how do we analyze this well we start

00:22:28,440 --> 00:22:33,210
off with 0 as 0 and there's a input

00:22:31,350 --> 00:22:35,820
integer goes into called

00:22:33,210 --> 00:22:37,470
inside called we have to analyze called

00:22:35,820 --> 00:22:39,330
before we can continue analyzing main

00:22:37,470 --> 00:22:40,680
because what the inferred value of this

00:22:39,330 --> 00:22:43,140
called node is depends on what the

00:22:40,680 --> 00:22:48,450
contents of the call function tells us

00:22:43,140 --> 00:22:51,390
it is so x is 0 Y is integer you

00:22:48,450 --> 00:22:54,540
propagate that down times the 0 return

00:22:51,390 --> 00:22:59,010
is 0 propagate that back out call the 0

00:22:54,540 --> 00:23:01,380
return is 0 and we are done and we see

00:22:59,010 --> 00:23:04,410
that this is our final inference where

00:23:01,380 --> 00:23:06,690
everything is 0 because 0 x 0 x things

00:23:04,410 --> 00:23:08,490
tend to be 0 this is a simplified case

00:23:06,690 --> 00:23:10,890
but the same can apply to other kinds of

00:23:08,490 --> 00:23:12,810
operations you do that constrain what

00:23:10,890 --> 00:23:16,140
kind of effect the types that are being

00:23:12,810 --> 00:23:19,260
propagated so now that we know this is 0

00:23:16,140 --> 00:23:20,880
we can simply make me in return 0 with

00:23:19,260 --> 00:23:22,620
also this rigmarole and this is our

00:23:20,880 --> 00:23:28,260
optimized program and optimized data

00:23:22,620 --> 00:23:29,430
flow graph so next bit of fun is you're

00:23:28,260 --> 00:23:31,830
going to look at recursive

00:23:29,430 --> 00:23:34,470
interprocedural type inference and

00:23:31,830 --> 00:23:36,810
constant folding so recursive functions

00:23:34,470 --> 00:23:38,040
are relatively common within scala like

00:23:36,810 --> 00:23:40,350
functional programming labs recursive

00:23:38,040 --> 00:23:42,120
functions and maybe for normal

00:23:40,350 --> 00:23:43,410
programming or normal compiler you're ok

00:23:42,120 --> 00:23:45,470
with telling people annotate recursive

00:23:43,410 --> 00:23:48,090
function but if you're if you're a

00:23:45,470 --> 00:23:49,920
optimizing compiler you want to say this

00:23:48,090 --> 00:23:51,570
recursive function is pure even though

00:23:49,920 --> 00:23:52,920
the person didn't annotate it so how do

00:23:51,570 --> 00:23:54,930
you analyze something to figure out that

00:23:52,920 --> 00:23:56,130
this is pure this is constant or this is

00:23:54,930 --> 00:23:57,570
something that's more specific than the

00:23:56,130 --> 00:23:59,400
person annotated even though it's

00:23:57,570 --> 00:24:01,770
recursive given how many recursive

00:23:59,400 --> 00:24:04,830
functions we tend to write in the

00:24:01,770 --> 00:24:07,410
functional programming style so let's

00:24:04,830 --> 00:24:10,170
look at this this is a pseudo Java

00:24:07,410 --> 00:24:12,090
version of a factorial function it takes

00:24:10,170 --> 00:24:13,860
an integer and I just said it returns

00:24:12,090 --> 00:24:15,750
any it's not reason real Java but it's

00:24:13,860 --> 00:24:16,620
pseudo Java let's just say we don't know

00:24:15,750 --> 00:24:18,570
what this returns yeah

00:24:16,620 --> 00:24:20,549
or the code does not know what this

00:24:18,570 --> 00:24:22,890
returns yeah we can see that this curly

00:24:20,549 --> 00:24:26,130
returns an integer but how do we analyze

00:24:22,890 --> 00:24:27,299
that in the programmatic fashion so on

00:24:26,130 --> 00:24:29,159
the right you see a data flow graph

00:24:27,299 --> 00:24:31,500
here's blocks you know it checks whether

00:24:29,159 --> 00:24:34,770
the equals if u is equal to 1 your turns

00:24:31,500 --> 00:24:37,799
1 it's not equal to 1 I subtract 1 from

00:24:34,770 --> 00:24:39,299
n pass that into factorial then

00:24:37,799 --> 00:24:40,470
multiplied by n again and then return

00:24:39,299 --> 00:24:42,600
that and this is a recursive call to

00:24:40,470 --> 00:24:44,130
factorial and comes back to itself so

00:24:42,600 --> 00:24:46,140
this more that's one of the simplest

00:24:44,130 --> 00:24:47,340
recursive functions to come up with but

00:24:46,140 --> 00:24:48,899
these techniques will generalize to

00:24:47,340 --> 00:24:50,789
other recursive functions new children

00:24:48,899 --> 00:24:56,370
Kuragin more than one because it calls

00:24:50,789 --> 00:24:57,779
etc so we start off a block 1 again in

00:24:56,370 --> 00:25:01,230
this case the first block we see n

00:24:57,779 --> 00:25:02,730
double equals 0 1 is 1 and it's integer

00:25:01,230 --> 00:25:03,840
double equals of one integer the boolean

00:25:02,730 --> 00:25:06,899
and we don't know whether it's true or

00:25:03,840 --> 00:25:10,049
false yet because it's a boolean you

00:25:06,899 --> 00:25:12,690
have to consider both cases so the two

00:25:10,049 --> 00:25:17,250
case is easy we return 1 so 1 is 1

00:25:12,690 --> 00:25:19,799
return is 1 the next case is more tricky

00:25:17,250 --> 00:25:22,770
so in the fourth case we need to pass in

00:25:19,799 --> 00:25:25,020
1 and n into minus so integer minus 1 is

00:25:22,770 --> 00:25:28,890
integer on which integer but when

00:25:25,020 --> 00:25:33,149
passing 2 factorial what do we do just a

00:25:28,890 --> 00:25:35,370
quiz who knows what we do here a few

00:25:33,149 --> 00:25:37,020
people know what we do so this is not a

00:25:35,370 --> 00:25:38,370
new technique but this is a technique

00:25:37,020 --> 00:25:39,630
that's more in the compiler back-end

00:25:38,370 --> 00:25:42,990
feel rather than a compiler front and

00:25:39,630 --> 00:25:44,730
field so what we do here is we say that

00:25:42,990 --> 00:25:48,450
there's a new type called bottom at the

00:25:44,730 --> 00:25:50,039
bottom of our type lattice bottom is

00:25:48,450 --> 00:25:51,480
below every other type but other than

00:25:50,039 --> 00:25:53,490
that it behaves just the same as any

00:25:51,480 --> 00:25:55,200
other type would behave and you guys use

00:25:53,490 --> 00:25:56,760
nothing in scala which is basically the

00:25:55,200 --> 00:26:00,179
same as bottom and you're familiar with

00:25:56,760 --> 00:26:02,340
it so first I come in annotate factorial

00:26:00,179 --> 00:26:06,600
as bottom so I don't know what it is

00:26:02,340 --> 00:26:08,760
it's bottom and bottom proper Cascades

00:26:06,600 --> 00:26:11,210
so bottom times integers bottom and

00:26:08,760 --> 00:26:14,309
returns bottom so bottom bottom bottom

00:26:11,210 --> 00:26:16,679
next what do we do well now we know that

00:26:14,309 --> 00:26:19,080
this factorial function either returns 1

00:26:16,679 --> 00:26:20,730
or bottom and you can look up 1 and

00:26:19,080 --> 00:26:24,000
bottom in our type lattice and see the

00:26:20,730 --> 00:26:26,610
least upper bound is 1 so least upper

00:26:24,000 --> 00:26:28,559
bounds 1 I can take this 1 and case it

00:26:26,610 --> 00:26:29,970
back into this factorial call and say

00:26:28,559 --> 00:26:30,490
that the recursive call is now read for

00:26:29,970 --> 00:26:35,380
- always

00:26:30,490 --> 00:26:37,570
turn 1 1 times the arbitrary integer is

00:26:35,380 --> 00:26:40,600
arbitrary integer it now returns an

00:26:37,570 --> 00:26:44,380
integer we can make one more round

00:26:40,600 --> 00:26:45,550
around this type lattice there what's

00:26:44,380 --> 00:26:48,160
the least upper bound of one an integer

00:26:45,550 --> 00:26:51,760
least upper bound is integer put that

00:26:48,160 --> 00:26:53,559
back into the factorial call and feed

00:26:51,760 --> 00:26:55,929
that back into times integer times

00:26:53,559 --> 00:26:57,250
integers integer and because it was

00:26:55,929 --> 00:26:59,400
already integer for the last iteration

00:26:57,250 --> 00:27:03,520
we can stop the propagation and get done

00:26:59,400 --> 00:27:05,559
so this is our final inference of a

00:27:03,520 --> 00:27:06,940
recursive factorial function telling us

00:27:05,559 --> 00:27:13,870
that returns an integer even though it

00:27:06,940 --> 00:27:15,340
was annotated to not return anything so

00:27:13,870 --> 00:27:17,050
you may notice that two if two of the

00:27:15,340 --> 00:27:19,179
cases we walk through so far we have a

00:27:17,050 --> 00:27:21,309
kind of iterative propagation approach

00:27:19,179 --> 00:27:23,110
where we make one pass around a function

00:27:21,309 --> 00:27:24,790
or one pass around a recursive set of

00:27:23,110 --> 00:27:27,870
recursive functions and then we have to

00:27:24,790 --> 00:27:29,710
keep propagating more passes until the

00:27:27,870 --> 00:27:32,770
inference stabilizes

00:27:29,710 --> 00:27:34,000
so in general if any any way that you

00:27:32,770 --> 00:27:35,650
have a loop you have a cycle in your

00:27:34,000 --> 00:27:37,360
program where there are cycles a loop or

00:27:35,650 --> 00:27:38,470
where there are cycles the recursion you

00:27:37,360 --> 00:27:39,850
are going to need to have you're going

00:27:38,470 --> 00:27:41,050
to need to do multiple passes of

00:27:39,850 --> 00:27:43,150
inference in order to get the most

00:27:41,050 --> 00:27:44,920
precise inference on the other hand if

00:27:43,150 --> 00:27:47,050
your program has no loops and no

00:27:44,920 --> 00:27:48,670
recursion then it is possible to do one

00:27:47,050 --> 00:27:49,690
pass from the top from top logically

00:27:48,670 --> 00:27:52,480
from the top of your program to the

00:27:49,690 --> 00:27:57,850
bottom and do get the most precise

00:27:52,480 --> 00:28:00,490
output so the number of iterations we do

00:27:57,850 --> 00:28:02,020
is bounded and number of iterations we

00:28:00,490 --> 00:28:04,780
do is bounded because every time you go

00:28:02,020 --> 00:28:07,480
around this cycle of propagation our

00:28:04,780 --> 00:28:09,460
types rise one at least one level in the

00:28:07,480 --> 00:28:12,250
lattice because if the type did not rise

00:28:09,460 --> 00:28:14,200
you stop the propagation so given a

00:28:12,250 --> 00:28:15,670
lattice of this height the number of

00:28:14,200 --> 00:28:18,429
iterations is completely bounded by the

00:28:15,670 --> 00:28:20,830
height of the lattice and if you want we

00:28:18,429 --> 00:28:23,590
can control how we can trade off number

00:28:20,830 --> 00:28:26,260
of iterations against precision of

00:28:23,590 --> 00:28:28,540
precision of inference by making a

00:28:26,260 --> 00:28:29,860
lattice more or less detailed for

00:28:28,540 --> 00:28:31,440
example we could easily have the lattice

00:28:29,860 --> 00:28:33,940
have a separate node four nonzero

00:28:31,440 --> 00:28:35,350
integers or the lattice curve a separate

00:28:33,940 --> 00:28:37,330
nodes four positive and negative

00:28:35,350 --> 00:28:39,040
integers or that lattice could have

00:28:37,330 --> 00:28:41,590
separate nodes for now or separate nodes

00:28:39,040 --> 00:28:44,030
for Strings of particular length and all

00:28:41,590 --> 00:28:45,740
of these allows it more precisely

00:28:44,030 --> 00:28:48,050
model the program during inference and

00:28:45,740 --> 00:28:49,550
generally more precise inferences but at

00:28:48,050 --> 00:28:51,410
the cost in that because our lattice is

00:28:49,550 --> 00:28:54,110
taller it may be require more iterations

00:28:51,410 --> 00:29:00,050
around this dataflow analysis in order

00:28:54,110 --> 00:29:02,750
to converge so the last thing I'm going

00:29:00,050 --> 00:29:06,260
to talk about is liveness and

00:29:02,750 --> 00:29:09,080
reachability analysis so Leibniz and

00:29:06,260 --> 00:29:12,110
reachability analysis are two pairs of

00:29:09,080 --> 00:29:15,290
related things which say this code never

00:29:12,110 --> 00:29:16,850
runs or this code always runs but it

00:29:15,290 --> 00:29:19,130
doesn't actually do anything it outputs

00:29:16,850 --> 00:29:21,770
not used in the end of the program and

00:29:19,130 --> 00:29:23,300
in either case the code is safe to

00:29:21,770 --> 00:29:25,130
remove and we can do so to make the

00:29:23,300 --> 00:29:29,270
program shorter smaller faster without

00:29:25,130 --> 00:29:31,640
affecting its output let's look at this

00:29:29,270 --> 00:29:34,280
last variant of the main method which I

00:29:31,640 --> 00:29:37,100
have mangled in a different way here we

00:29:34,280 --> 00:29:39,440
have this total func total variable

00:29:37,100 --> 00:29:41,570
which adds which gets aggregated and

00:29:39,440 --> 00:29:44,330
added to but never ends up being used in

00:29:41,570 --> 00:29:46,010
the return value of the program on the

00:29:44,330 --> 00:29:48,050
other hand we have this count function

00:29:46,010 --> 00:29:49,520
which does get used in the return count

00:29:48,050 --> 00:29:51,350
variable which does get used in the

00:29:49,520 --> 00:29:53,870
return value of the program but we have

00:29:51,350 --> 00:29:57,080
one update site which is never going to

00:29:53,870 --> 00:29:59,660
get run so total is fails aliveness

00:29:57,080 --> 00:30:01,520
analysis and can be removed this count

00:29:59,660 --> 00:30:04,340
class equals one fails the reachability

00:30:01,520 --> 00:30:06,830
analysis and can be removed so how do we

00:30:04,340 --> 00:30:08,690
do that optimization in a programmatic

00:30:06,830 --> 00:30:11,990
fashion rather than just squinting at it

00:30:08,690 --> 00:30:14,480
as humans first we can do the same

00:30:11,990 --> 00:30:16,250
constant folding we did earlier earlier

00:30:14,480 --> 00:30:19,780
so we know multiplied is always going to

00:30:16,250 --> 00:30:22,280
be 0 this is always going to be false

00:30:19,780 --> 00:30:24,380
next we end up with this simplified tree

00:30:22,280 --> 00:30:27,620
or program and simplify data flow graph

00:30:24,380 --> 00:30:30,380
where if 0 let great greater than 100 do

00:30:27,620 --> 00:30:32,420
this count as equals 1 so looking at the

00:30:30,380 --> 00:30:35,780
data flow graph we can see that we have

00:30:32,420 --> 00:30:37,550
zero hundred greater than this is always

00:30:35,780 --> 00:30:39,290
going to be false and so the if

00:30:37,550 --> 00:30:41,360
statement can only we can remove the

00:30:39,290 --> 00:30:43,640
false branch of the if statement and all

00:30:41,360 --> 00:30:47,150
of its downstream nodes in the data flow

00:30:43,640 --> 00:30:50,870
graph so one plus this arrow this arrow

00:30:47,150 --> 00:30:55,310
are all in this false are all in the

00:30:50,870 --> 00:30:57,799
true block and can be removed so that

00:30:55,310 --> 00:30:59,239
uses this simplified data flow graph so

00:30:57,799 --> 00:31:01,519
and we can now we do the live less

00:30:59,239 --> 00:31:03,440
analysis to say which code in this graph

00:31:01,519 --> 00:31:05,360
is not used in the return value of the

00:31:03,440 --> 00:31:07,429
program and that ends up being a

00:31:05,360 --> 00:31:09,769
relatively straightforward analysis you

00:31:07,429 --> 00:31:11,419
just start from the return value do a

00:31:09,769 --> 00:31:13,940
breadth-first search of the graph and

00:31:11,419 --> 00:31:15,619
you see here all the black nodes other

00:31:13,940 --> 00:31:17,450
ones appear in my breadth-first search

00:31:15,619 --> 00:31:19,519
all the red nodes are the ones that do

00:31:17,450 --> 00:31:21,259
not appear in my breadth-first search so

00:31:19,519 --> 00:31:23,450
even though we have total adding to

00:31:21,259 --> 00:31:26,090
itself and depending on itself and none

00:31:23,450 --> 00:31:28,100
of these nodes have zero inputs I have 0

00:31:26,090 --> 00:31:30,109
outputs we know that total is not ends

00:31:28,100 --> 00:31:32,059
up not being used and this greater than

00:31:30,109 --> 00:31:34,330
node ends up not being used so we can

00:31:32,059 --> 00:31:36,529
remove these from the data flow graph

00:31:34,330 --> 00:31:40,070
giving us this which is a simplified

00:31:36,529 --> 00:31:41,840
data flow graph of the earlier function

00:31:40,070 --> 00:31:43,580
with all the rubbish remove turtle is

00:31:41,840 --> 00:31:47,629
gone that if check is gone multiply this

00:31:43,580 --> 00:31:50,450
go on simple graph start from zero loops

00:31:47,629 --> 00:31:52,239
are loops around a few times this is

00:31:50,450 --> 00:31:55,100
around this conditional if statements

00:31:52,239 --> 00:32:05,659
increments counts and returns at the end

00:31:55,100 --> 00:32:07,100
when the if statement fails so so to

00:32:05,659 --> 00:32:08,720
wrap up we've seen some optimizations

00:32:07,100 --> 00:32:10,489
that we can perform manually we did type

00:32:08,720 --> 00:32:11,899
inference inlining constant folding dead

00:32:10,489 --> 00:32:13,970
code elimination advanced elimination

00:32:11,899 --> 00:32:16,220
late scheduling there are many more you

00:32:13,970 --> 00:32:17,749
can keep doing and you can list them out

00:32:16,220 --> 00:32:18,679
if you go into any compiler text there's

00:32:17,749 --> 00:32:20,059
gonna be a whole chapter full of

00:32:18,679 --> 00:32:23,330
different optimizations can do one by

00:32:20,059 --> 00:32:25,519
one after we did them all manually we

00:32:23,330 --> 00:32:26,840
saw that we can just they you can write

00:32:25,519 --> 00:32:28,809
the program they will run over your

00:32:26,840 --> 00:32:31,249
class file and do all the optimizations

00:32:28,809 --> 00:32:33,350
automatically so rather than spending

00:32:31,249 --> 00:32:35,059
your human brains how to do so here's

00:32:33,350 --> 00:32:39,109
relying a laptop to turn away and spit

00:32:35,059 --> 00:32:40,039
out and more optimized program next we

00:32:39,109 --> 00:32:41,239
look at the modeling approach of a

00:32:40,039 --> 00:32:43,070
program the different ways in which you

00:32:41,239 --> 00:32:44,749
can say this is a program data structure

00:32:43,070 --> 00:32:47,239
in memory and a different trade-offs are

00:32:44,749 --> 00:32:48,919
which of the different trade-offs of how

00:32:47,239 --> 00:32:52,789
easy it is to work with them analyze

00:32:48,919 --> 00:32:55,399
them or modify them for this demo I use

00:32:52,789 --> 00:32:56,960
data flow graphs both for implementation

00:32:55,399 --> 00:32:58,909
of the program you saw earlier and for

00:32:56,960 --> 00:33:01,190
the slides here but you can do the same

00:32:58,909 --> 00:33:02,600
work on a STS or bytecode just it's more

00:33:01,190 --> 00:33:05,539
or less effort depending on which

00:33:02,600 --> 00:33:07,340
representation you choose lastly we

00:33:05,539 --> 00:33:09,230
looked at how to do it in these

00:33:07,340 --> 00:33:11,890
inferences optimizations automatically

00:33:09,230 --> 00:33:14,750
we saw type inference constant folding

00:33:11,890 --> 00:33:18,770
how constant folding really is just type

00:33:14,750 --> 00:33:20,390
inferencing singleton types and we saw

00:33:18,770 --> 00:33:21,560
interprocedural inference when you have

00:33:20,390 --> 00:33:23,420
one function calling the other and

00:33:21,560 --> 00:33:25,310
analyzing both one after the other and

00:33:23,420 --> 00:33:26,990
we saw how to do recursive

00:33:25,310 --> 00:33:29,000
interprocedural inference with your

00:33:26,990 --> 00:33:30,520
recursive function how can analyze it

00:33:29,000 --> 00:33:33,170
use it taking advantage of this bottom

00:33:30,520 --> 00:33:34,700
like sentinel node in your type lattice

00:33:33,170 --> 00:33:36,440
in order to do multiple iterations

00:33:34,700 --> 00:33:38,180
around of the around dataflow

00:33:36,440 --> 00:33:42,280
propagation and end up with a correct

00:33:38,180 --> 00:33:44,120
answer lastly we looked at to two other

00:33:42,280 --> 00:33:45,890
optimizations which are not type

00:33:44,120 --> 00:33:47,900
inference and constant folding we looked

00:33:45,890 --> 00:33:48,950
at live left analysis which is removing

00:33:47,900 --> 00:33:50,480
things which are not used in the final

00:33:48,950 --> 00:33:52,550
output and we looked at reachability

00:33:50,480 --> 00:33:54,560
analysis which is removing things that

00:33:52,550 --> 00:33:56,330
will never get run even if they even

00:33:54,560 --> 00:33:58,460
though if they do get run it will affect

00:33:56,330 --> 00:33:59,900
the output and we saw that how we could

00:33:58,460 --> 00:34:01,670
do this using relatively simple data

00:33:59,900 --> 00:34:03,620
structures this is just a directed graph

00:34:01,670 --> 00:34:05,600
with maybe some cycles in in them and

00:34:03,620 --> 00:34:06,950
relatively simple algorithms with just

00:34:05,600 --> 00:34:10,370
reversals over the data flow graph

00:34:06,950 --> 00:34:12,290
possibly making more than one cycle and

00:34:10,370 --> 00:34:14,870
finally stabilizing and using the

00:34:12,290 --> 00:34:16,190
inferred values or inferred types of

00:34:14,870 --> 00:34:21,320
your program in order to make the

00:34:16,190 --> 00:34:22,520
optimizations so I didn't come up with

00:34:21,320 --> 00:34:24,740
any of this stuff myself

00:34:22,520 --> 00:34:26,300
all of this is well known in parts of

00:34:24,740 --> 00:34:27,889
industry so if you're interested in

00:34:26,300 --> 00:34:29,000
learning more about optimizing compilers

00:34:27,889 --> 00:34:30,200
and you want to go write your own

00:34:29,000 --> 00:34:33,169
scholar C optimizer

00:34:30,200 --> 00:34:35,629
Java program optimizer or even optimizes

00:34:33,169 --> 00:34:38,389
for other languages most of these

00:34:35,629 --> 00:34:40,669
techniques will go will transfer will

00:34:38,389 --> 00:34:44,360
transfer relatively easily from Scala to

00:34:40,669 --> 00:34:47,750
Java to c-sharp to C++ maybe even to

00:34:44,360 --> 00:34:49,010
JavaScript maybe not and these two books

00:34:47,750 --> 00:34:50,419
are I think a good reference where

00:34:49,010 --> 00:34:52,429
engineering compilers a very thorough

00:34:50,419 --> 00:34:54,440
reference of the general architecture of

00:34:52,429 --> 00:34:55,610
compiler with many sections many

00:34:54,440 --> 00:34:58,580
chapters based on optimization

00:34:55,610 --> 00:35:00,350
techniques and combining analyses

00:34:58,580 --> 00:35:03,790
combining optimizations by cliff click

00:35:00,350 --> 00:35:06,350
that is PCT system 1995 is a good

00:35:03,790 --> 00:35:08,570
introduction to this idea of data flow

00:35:06,350 --> 00:35:11,980
graph modeling and data flow graph graph

00:35:08,570 --> 00:35:14,450
analysis using this particular technique

00:35:11,980 --> 00:35:16,460
so that's it for how an optimizing

00:35:14,450 --> 00:35:20,800
compiler works I think I might have a

00:35:16,460 --> 00:35:20,800
bit of time for questions so have at me

00:35:22,100 --> 00:35:37,490
[Applause]

00:35:29,079 --> 00:35:39,170
Raynald yeah so the question is I did

00:35:37,490 --> 00:35:41,180
not go talk about how I go from class

00:35:39,170 --> 00:35:44,660
files to data flow when out of love

00:35:41,180 --> 00:35:46,069
programs so let's go back to the class

00:35:44,660 --> 00:35:47,780
file representation I can go into a bit

00:35:46,069 --> 00:35:51,020
of detail since I have some time

00:35:47,780 --> 00:35:52,609
so going from AST is the data flow

00:35:51,020 --> 00:35:55,280
programs is easier you just take these

00:35:52,609 --> 00:35:56,750
identify assign edges and you make them

00:35:55,280 --> 00:35:59,480
into really edges and that's our data

00:35:56,750 --> 00:36:01,819
flow graph so going from class files the

00:35:59,480 --> 00:36:05,420
data flow program is a bit trickier but

00:36:01,819 --> 00:36:08,030
if you look at how class files look you

00:36:05,420 --> 00:36:11,569
see as we move things on and off the

00:36:08,030 --> 00:36:14,839
stack for example here we look at this

00:36:11,569 --> 00:36:17,089
section where we load the first look

00:36:14,839 --> 00:36:19,180
load the first argument put the constant

00:36:17,089 --> 00:36:22,490
one subtract it to get another value

00:36:19,180 --> 00:36:24,530
load another constant one invoke set it

00:36:22,490 --> 00:36:29,780
to get another value and then return it

00:36:24,530 --> 00:36:31,280
so these abstract variables you call

00:36:29,780 --> 00:36:33,589
being moved on and off the stack

00:36:31,280 --> 00:36:37,430
basically form a set of edges between

00:36:33,589 --> 00:36:40,250
the node which constructs the abstract

00:36:37,430 --> 00:36:42,380
variable for example no.22 i sub

00:36:40,250 --> 00:36:44,480
constructs v4 and the node which

00:36:42,380 --> 00:36:47,900
consumes the abstract variable in this

00:36:44,480 --> 00:36:53,000
case I believe this one would be number

00:36:47,900 --> 00:36:56,109
27 no wrong number 30 invoke static so

00:36:53,000 --> 00:36:58,700
if you follow these nodes along the the

00:36:56,109 --> 00:37:00,680
virtual stack you basically end up with

00:36:58,700 --> 00:37:02,510
a graph of where the values come from

00:37:00,680 --> 00:37:04,549
and go to and that is your data flow

00:37:02,510 --> 00:37:06,799
graph so if you want to learn how to do

00:37:04,549 --> 00:37:09,049
that you should go look at it's called

00:37:06,799 --> 00:37:10,670
the ASM Java bytecode engineering

00:37:09,049 --> 00:37:13,040
library so you have a very good tutorial

00:37:10,670 --> 00:37:15,410
for dataflow analysis specifically

00:37:13,040 --> 00:37:17,329
converting data flow from bytecode to

00:37:15,410 --> 00:37:18,950
data flow graphs using their library and

00:37:17,329 --> 00:37:20,980
that's what i use for the demo earlier i

00:37:18,950 --> 00:37:25,910
didn't have to write it all myself um

00:37:20,980 --> 00:37:29,329
any other questions do you have

00:37:25,910 --> 00:37:31,250
benchmarks I do not have benchmarks so

00:37:29,329 --> 00:37:34,069
unfortunately this is not quite at that

00:37:31,250 --> 00:37:35,099
stage yet so I've demoed in working I

00:37:34,069 --> 00:37:37,349
have not demo at there if

00:37:35,099 --> 00:37:42,180
Cassie come on top of the JVM zero other

00:37:37,349 --> 00:37:43,650
jets and is it going to be open source I

00:37:42,180 --> 00:37:48,299
don't think isn't good enough state to

00:37:43,650 --> 00:37:50,130
open sauce it's a bit of a mess yeah but

00:37:48,299 --> 00:37:51,539
I don't think you'll get much on reading

00:37:50,130 --> 00:37:53,309
the code so if you want to know how it

00:37:51,539 --> 00:38:00,569
works this is basically everything about

00:37:53,309 --> 00:38:06,720
how it works on these slides yeah in

00:38:00,569 --> 00:38:11,059
France yeah and when you do the

00:38:06,720 --> 00:38:17,369
interprocedural analysis do you do like

00:38:11,059 --> 00:38:21,960
do you consider the context yes so if

00:38:17,369 --> 00:38:23,519
you look over here where am i you look

00:38:21,960 --> 00:38:25,140
over here when I'm propagating is zero

00:38:23,519 --> 00:38:27,539
from the main function to the caller

00:38:25,140 --> 00:38:29,549
function basically that means I've

00:38:27,539 --> 00:38:33,210
analyzed called separately for every

00:38:29,549 --> 00:38:34,829
different parameter it gets so obviously

00:38:33,210 --> 00:38:36,059
this does a scale if I call call there's

00:38:34,829 --> 00:38:37,920
a thousand different functions I don't a

00:38:36,059 --> 00:38:39,719
thousand different duplicates and you

00:38:37,920 --> 00:38:41,339
have to prune those with heuristics like

00:38:39,719 --> 00:38:43,759
the JVM says it's a three different

00:38:41,339 --> 00:38:45,930
monomorphic if they're three different

00:38:43,759 --> 00:38:47,999
dispatches in the polymorphic call side

00:38:45,930 --> 00:38:49,769
it just resets polymorphic doesn't try

00:38:47,999 --> 00:38:51,269
to in line similarly for this kind of

00:38:49,769 --> 00:38:52,700
thing you have to prune it eventually

00:38:51,269 --> 00:38:55,380
say there are too many different

00:38:52,700 --> 00:38:58,410
contexts analyze it within I'm just

00:38:55,380 --> 00:38:59,579
going to take the conservative view but

00:38:58,410 --> 00:39:02,700
that's also another thing you can trade

00:38:59,579 --> 00:39:04,529
off like if I have zero if there's only

00:39:02,700 --> 00:39:06,450
one call side and one call function it's

00:39:04,529 --> 00:39:07,710
very easy to propagate the context zero

00:39:06,450 --> 00:39:10,049
goes to zero and it gets optimized

00:39:07,710 --> 00:39:12,839
beautifully if I have to call sites it's

00:39:10,049 --> 00:39:14,369
also easy to propagate the context you

00:39:12,839 --> 00:39:16,920
especially if they both have constants

00:39:14,369 --> 00:39:18,239
if I have a million different call sites

00:39:16,920 --> 00:39:20,099
with different contexts

00:39:18,239 --> 00:39:21,900
then maybe you may decide you have to

00:39:20,099 --> 00:39:24,599
start collapsing them in order to make

00:39:21,900 --> 00:39:26,009
the analysis more tractable but that's

00:39:24,599 --> 00:39:27,690
the thing you can trade off and turn an

00:39:26,009 --> 00:39:31,650
optical higher or lower precision or

00:39:27,690 --> 00:39:34,920
higher and lower performance yeah you

00:39:31,650 --> 00:39:36,289
mentioned fusing your map and filter and

00:39:34,920 --> 00:39:38,910
things like that

00:39:36,289 --> 00:39:41,759
it's that in the talk description yeah

00:39:38,910 --> 00:39:43,109
so I don't have the demo here now but

00:39:41,759 --> 00:39:46,469
fusing map and filters basically

00:39:43,109 --> 00:39:48,630
inlining once you see inlining to a

00:39:46,469 --> 00:39:50,580
concrete function

00:39:48,630 --> 00:39:52,470
so it says if you have a map function

00:39:50,580 --> 00:39:54,990
and you copy the mat you copy the map

00:39:52,470 --> 00:39:56,790
function with only one lambda you can

00:39:54,990 --> 00:40:01,730
add in line through that lambda in map

00:39:56,790 --> 00:40:01,730
function to effectively fuse it um

00:40:02,750 --> 00:40:06,540
sometimes if you if you want to build a

00:40:04,830 --> 00:40:08,220
map but first you want to transform a

00:40:06,540 --> 00:40:09,990
list and you want to do something you

00:40:08,220 --> 00:40:13,590
can save a lot of performance by

00:40:09,990 --> 00:40:15,690
creating a view yeah so it doesn't do

00:40:13,590 --> 00:40:16,890
that kind of fusing but it does the

00:40:15,690 --> 00:40:18,810
inlining to primitives

00:40:16,890 --> 00:40:20,040
kind of fusing not sure that's the

00:40:18,810 --> 00:40:23,010
correct terminology might be the wrong

00:40:20,040 --> 00:40:24,960
terminology but basically comforts like

00:40:23,010 --> 00:40:28,110
chains of options flat maps into a

00:40:24,960 --> 00:40:30,750
straight line code it does not work on

00:40:28,110 --> 00:40:33,270
arrays yet it does work on array six due

00:40:30,750 --> 00:40:34,620
to implementation problems but in

00:40:33,270 --> 00:40:36,080
general a lot of this stuff is not

00:40:34,620 --> 00:40:44,160
production ready yet it's mostly

00:40:36,080 --> 00:40:45,930
demonstration of the principles what

00:40:44,160 --> 00:40:49,140
does the side-effects look like in the

00:40:45,930 --> 00:40:52,170
data flow graph that's a very

00:40:49,140 --> 00:40:55,320
interesting question so this data flow

00:40:52,170 --> 00:40:56,880
graph analysis of mod technique is

00:40:55,320 --> 00:40:59,820
basically copied from Cliff Lee clicks

00:40:56,880 --> 00:41:01,080
thesis and click-click-click thesis

00:40:59,820 --> 00:41:03,840
ended up in the JVM that you all are

00:41:01,080 --> 00:41:05,550
running as hot as the hot spot optimizer

00:41:03,840 --> 00:41:07,260
so if you go look at the hot spot

00:41:05,550 --> 00:41:11,940
documentation you'll talk about that in

00:41:07,260 --> 00:41:13,800
short it looks a lot like IO monad

00:41:11,940 --> 00:41:16,860
so we basically pass it you basically

00:41:13,800 --> 00:41:18,600
have nodes it's taken a world and pass

00:41:16,860 --> 00:41:20,730
out that changed world as a separate

00:41:18,600 --> 00:41:22,590
value and so these nodes have more than

00:41:20,730 --> 00:41:24,780
one output value and the ones which are

00:41:22,590 --> 00:41:26,430
pure will not need to take in or return

00:41:24,780 --> 00:41:28,320
the world and once it's a stateful

00:41:26,430 --> 00:41:29,790
well-taken return the world and when you

00:41:28,320 --> 00:41:31,380
do the graph traversal that we showed

00:41:29,790 --> 00:41:33,360
earlier all of it kind of flows

00:41:31,380 --> 00:41:39,110
beautifully I mean doesn't need that

00:41:33,360 --> 00:41:42,560
much special casing any other questions

00:41:39,110 --> 00:41:42,560
I'll further back

00:41:51,359 --> 00:41:57,670
III perceive the talk as a general

00:41:54,579 --> 00:41:59,890
introduction to optimization of

00:41:57,670 --> 00:42:02,799
compilers but would be interesting like

00:41:59,890 --> 00:42:05,559
what's your application in the end and

00:42:02,799 --> 00:42:08,200
the Scala ecosystems like where you plan

00:42:05,559 --> 00:42:11,579
into this kind of optimization is it a

00:42:08,200 --> 00:42:16,000
compiler plugin or like what's your goal

00:42:11,579 --> 00:42:18,579
it's unclear yeah we I have what I have

00:42:16,000 --> 00:42:21,640
now it kind of works what to do with it

00:42:18,579 --> 00:42:22,900
is and it's not that obvious in

00:42:21,640 --> 00:42:24,520
principle it should be able to do much

00:42:22,900 --> 00:42:26,920
more aggressive optimizations in the

00:42:24,520 --> 00:42:28,270
Scala C optimizer can do because Carles

00:42:26,920 --> 00:42:30,309
the optimizer doesn't do a closed what

00:42:28,270 --> 00:42:33,700
doesn't assume a closed world it still

00:42:30,309 --> 00:42:35,589
allows multiple separate compilation if

00:42:33,700 --> 00:42:37,480
you consider how much does the Scala ji

00:42:35,589 --> 00:42:44,020
optimize the speed up Scala GS code the

00:42:37,480 --> 00:42:47,530
genuine no Andrea no the questions how

00:42:44,020 --> 00:42:50,230
much the I think it's something like 2

00:42:47,530 --> 00:42:51,880
to 10x depending on the code so you can

00:42:50,230 --> 00:42:54,400
get very aggressive optimizations once

00:42:51,880 --> 00:42:55,869
you do a closed world analysis so in

00:42:54,400 --> 00:42:57,880
principle if you can get to the 10x

00:42:55,869 --> 00:43:00,190
speed up of Sky JVM code or even 1.5 to

00:42:57,880 --> 00:43:02,049
5x that would be pretty cool but there

00:43:00,190 --> 00:43:05,700
will be a lot a lot more work than this

00:43:02,049 --> 00:43:09,119
demo any other questions

00:43:05,700 --> 00:43:09,119
put the back there

00:43:22,150 --> 00:43:34,690
oh hi hi thank you very much for the

00:43:28,059 --> 00:43:39,420
talk nice into the socket of the

00:43:34,690 --> 00:43:39,420
demonstration and guess to clarify oh

00:43:43,140 --> 00:43:55,410
yeah sorry for the microphone so it was

00:43:49,990 --> 00:44:00,009
a nice presentation interaction to them

00:43:55,410 --> 00:44:03,190
stop keep them your optimizer is it

00:44:00,009 --> 00:44:07,480
working on the bytecode level by Cotto

00:44:03,190 --> 00:44:10,180
bike over on the sky assures this

00:44:07,480 --> 00:44:11,589
optimizer works on the bytecode so it

00:44:10,180 --> 00:44:13,150
does the same technique I described

00:44:11,589 --> 00:44:14,829
earlier where you walk the bike code in

00:44:13,150 --> 00:44:17,380
order to build a data flow and control

00:44:14,829 --> 00:44:19,210
flow graph it's arguable which one is

00:44:17,380 --> 00:44:21,279
better I was using byte code because

00:44:19,210 --> 00:44:26,319
that's more well defined and I'm more

00:44:21,279 --> 00:44:30,460
familiar with it is based on yes it's

00:44:26,319 --> 00:44:33,279
based on or object web ASM at least for

00:44:30,460 --> 00:44:35,170
the front-end parsing and graph

00:44:33,279 --> 00:44:37,529
construction after that ASM doesn't do

00:44:35,170 --> 00:44:37,529
anything

00:44:37,859 --> 00:44:44,440
one thing I was curious when you one of

00:44:41,559 --> 00:44:46,380
the techniques one of the things it

00:44:44,440 --> 00:44:49,630
sometimes is missing in Scala

00:44:46,380 --> 00:44:51,819
particularly if you do a bit of more

00:44:49,630 --> 00:44:53,950
functional style of pipelining is

00:44:51,819 --> 00:44:56,380
usually something called deforestation

00:44:53,950 --> 00:44:58,299
and the process by which you're not

00:44:56,380 --> 00:45:00,999
optimized in the cold you are like

00:44:58,299 --> 00:45:04,349
cutting away intermediate data

00:45:00,999 --> 00:45:07,119
structures yes I can talk about that so

00:45:04,349 --> 00:45:10,210
deforestation basically requires heap

00:45:07,119 --> 00:45:12,099
analysis which is a separate field of

00:45:10,210 --> 00:45:17,440
program optimization I did not touch on

00:45:12,099 --> 00:45:18,970
at all so yeah I have not implemented

00:45:17,440 --> 00:45:21,039
heap analysis and therefore this does

00:45:18,970 --> 00:45:23,559
not do either deforestation unboxing

00:45:21,039 --> 00:45:30,680
asleep analysis none of that and that

00:45:23,559 --> 00:45:34,910
would be its own project one last thing

00:45:30,680 --> 00:45:37,940
yeah another thing I'm thinking is that

00:45:34,910 --> 00:45:41,390
if you have a you prefer the functional

00:45:37,940 --> 00:45:43,760
style of Scylla and you like to pass

00:45:41,390 --> 00:45:45,530
around a lot of like a lot of the

00:45:43,760 --> 00:45:49,580
functions now those things are being

00:45:45,530 --> 00:45:51,200
implemented as polymorphic calls and you

00:45:49,580 --> 00:45:54,770
end up like having if you have like a

00:45:51,200 --> 00:46:00,140
lot of calls to list of map you may end

00:45:54,770 --> 00:46:03,860
up having like several references to an

00:46:00,140 --> 00:46:05,810
object that then can have many lambdas

00:46:03,860 --> 00:46:09,220
try the implementation of function one

00:46:05,810 --> 00:46:14,630
opiates in Scala how well does the

00:46:09,220 --> 00:46:16,220
optimizer achieves with us um you take

00:46:14,630 --> 00:46:17,600
more time to described and I think we

00:46:16,220 --> 00:46:21,140
have so I can come talk to you later

00:46:17,600 --> 00:46:24,080
after yeah I think we are done as far as

00:46:21,140 --> 00:46:29,590
times go so thank you for listening

00:46:24,080 --> 00:46:36,969
[Applause]

00:46:29,590 --> 00:46:36,969

YouTube URL: https://www.youtube.com/watch?v=EO0u-SQnJRQ


