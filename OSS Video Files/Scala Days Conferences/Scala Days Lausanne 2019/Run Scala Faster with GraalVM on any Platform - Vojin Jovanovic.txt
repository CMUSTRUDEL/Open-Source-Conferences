Title: Run Scala Faster with GraalVM on any Platform - Vojin Jovanovic
Publication date: 2019-07-11
Playlist: Scala Days Lausanne 2019
Description: 
	This video was recorded at Scala Days Lausanne 2019
Follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

More information and the abstract can be found here:
https://scaladays.org/schedule/run-scala-faster-with-graalvm-on-any-platform
Captions: 
	00:00:00,000 --> 00:00:06,620
30 hi my name is Wayne Ivanovich and I

00:00:03,840 --> 00:00:09,630
work in Oracle labs in the growl VM team

00:00:06,620 --> 00:00:11,580
today I'm going to first thank you all

00:00:09,630 --> 00:00:13,530
for coming and I'm especially glad that

00:00:11,580 --> 00:00:16,350
my little son is here first time to see

00:00:13,530 --> 00:00:23,430
me present because it is in his home

00:00:16,350 --> 00:00:25,529
town that's what David and today I'm

00:00:23,430 --> 00:00:27,590
going to talk to you about Gavin and how

00:00:25,529 --> 00:00:30,240
you can run scholar faster with Guardian

00:00:27,590 --> 00:00:32,279
it is kind of known already but I've

00:00:30,240 --> 00:00:34,890
just confirmed that with new results and

00:00:32,279 --> 00:00:36,719
then I will talk to you about a new

00:00:34,890 --> 00:00:39,930
thing that we did in the last six months

00:00:36,719 --> 00:00:43,020
and that is running scholar faster with

00:00:39,930 --> 00:00:45,030
Guardian on any platform so for those

00:00:43,020 --> 00:00:47,550
who don't know what Guardian is this is

00:00:45,030 --> 00:00:52,199
probably the slide that summarizes it

00:00:47,550 --> 00:00:55,020
best so gravity M is a virtual machine

00:00:52,199 --> 00:00:57,329
or a language runtime which is built on

00:00:55,020 --> 00:01:00,239
top of the ground compiler and it

00:00:57,329 --> 00:01:02,579
enables to run many languages so it's a

00:01:00,239 --> 00:01:04,290
polyglot runtime and you're here on the

00:01:02,579 --> 00:01:07,110
slide you can see you can run languages

00:01:04,290 --> 00:01:08,549
like Java Scala and Kotlin but then

00:01:07,110 --> 00:01:11,040
together with them in the same runtime

00:01:08,549 --> 00:01:13,560
you can run dynamic languages like

00:01:11,040 --> 00:01:15,180
JavaScript Ruby are fightin and they're

00:01:13,560 --> 00:01:16,740
knots really cool you can also run all

00:01:15,180 --> 00:01:18,530
of the native languages because we saw

00:01:16,740 --> 00:01:21,540
support the LLVM

00:01:18,530 --> 00:01:22,799
interpreter and then on the bottom of

00:01:21,540 --> 00:01:25,170
the ground vm so in the middle there is

00:01:22,799 --> 00:01:26,610
a growl growl compiler and then under

00:01:25,170 --> 00:01:29,220
them you can run that on the top of

00:01:26,610 --> 00:01:32,340
hotspot just like you do Scala or you

00:01:29,220 --> 00:01:34,170
can run it as a node.js application you

00:01:32,340 --> 00:01:36,600
can run it inside of databases and other

00:01:34,170 --> 00:01:38,850
native platforms such as Oracle database

00:01:36,600 --> 00:01:42,390
or MySQL or you can run it as a

00:01:38,850 --> 00:01:44,430
standalone shell script and we'll add a

00:01:42,390 --> 00:01:47,689
bit more today on this to this picture

00:01:44,430 --> 00:01:50,790
so what's really in the core of this

00:01:47,689 --> 00:01:52,439
trial VM so I won't have time to go into

00:01:50,790 --> 00:01:54,509
the details but the core is the growl

00:01:52,439 --> 00:01:56,700
compiler and it all revolves around it

00:01:54,509 --> 00:01:59,880
and what's the key difference of the

00:01:56,700 --> 00:02:01,920
growl compiler to the others is a few

00:01:59,880 --> 00:02:04,920
things it's written in Java right so the

00:02:01,920 --> 00:02:07,459
previous compiler c2 was written in C++

00:02:04,920 --> 00:02:09,869
and it was essentially very kind of

00:02:07,459 --> 00:02:11,879
entangled with the VM with the hotspot

00:02:09,869 --> 00:02:13,650
- been grouchy and it was written in

00:02:11,879 --> 00:02:16,319
Java and if you had a clear separation a

00:02:13,650 --> 00:02:18,629
clear interface to the VM so it kind of

00:02:16,319 --> 00:02:20,190
became very modular maintainable and

00:02:18,629 --> 00:02:22,620
expensive alright so you can plug in a

00:02:20,190 --> 00:02:25,200
new face you can refactor things so it

00:02:22,620 --> 00:02:27,239
makes development release and the ground

00:02:25,200 --> 00:02:29,280
compiler comes in two flavors which

00:02:27,239 --> 00:02:31,230
we'll see in all of the graphs that they

00:02:29,280 --> 00:02:32,730
show throughout throughout the

00:02:31,230 --> 00:02:34,860
presentation so there is a community

00:02:32,730 --> 00:02:37,319
edition or shorts EE which is

00:02:34,860 --> 00:02:39,299
essentially the open source part of the

00:02:37,319 --> 00:02:41,160
compiler and there is an Enterprise

00:02:39,299 --> 00:02:43,489
Edition which adds a few advanced

00:02:41,160 --> 00:02:46,890
optimizations which we will basically

00:02:43,489 --> 00:02:50,430
add to the performance right and our

00:02:46,890 --> 00:02:52,620
general goal is that you know the API of

00:02:50,430 --> 00:02:54,720
the growl VM doesn't really change it

00:02:52,620 --> 00:02:56,670
whether you're in like Community Edition

00:02:54,720 --> 00:02:59,849
or an Enterprise Edition it's just you

00:02:56,670 --> 00:03:03,959
know the performance and then because of

00:02:59,849 --> 00:03:05,819
this nice kind of nice interface and you

00:03:03,959 --> 00:03:07,349
know modularity and extensibility it was

00:03:05,819 --> 00:03:09,629
very easy to develop really cool

00:03:07,349 --> 00:03:11,970
optimizations right so what makes crawl

00:03:09,629 --> 00:03:14,340
faster I would take there is a lot of

00:03:11,970 --> 00:03:16,829
them right but I would take three out as

00:03:14,340 --> 00:03:19,470
which I like the most which is partially

00:03:16,829 --> 00:03:21,359
scape analysis part duplication and

00:03:19,470 --> 00:03:24,420
priority line all right so these through

00:03:21,359 --> 00:03:26,010
three I think make grow kind of unique

00:03:24,420 --> 00:03:27,840
compared to the other compilers and

00:03:26,010 --> 00:03:30,450
especially how they interact with each

00:03:27,840 --> 00:03:32,579
other so if you're not know more about

00:03:30,450 --> 00:03:36,480
these you can go and look at the papers

00:03:32,579 --> 00:03:37,799
to publish but in in short you know if

00:03:36,480 --> 00:03:41,630
you have something like this streams

00:03:37,799 --> 00:03:44,160
operation that you see on the top here

00:03:41,630 --> 00:03:45,930
essentially what what growl will do is

00:03:44,160 --> 00:03:47,579
that lets what everyone programs today

00:03:45,930 --> 00:03:49,590
especially in Southeast color you just

00:03:47,579 --> 00:03:52,260
do you know collection operations high

00:03:49,590 --> 00:03:53,849
level what growl will do it will be the

00:03:52,260 --> 00:03:55,950
combination of all these optimizations

00:03:53,849 --> 00:03:58,049
produce in the end something like this

00:03:55,950 --> 00:03:59,489
while loop right I actually measured

00:03:58,049 --> 00:04:01,230
performance I looked at the graphs and

00:03:59,489 --> 00:04:03,299
measure performance and it's actually

00:04:01,230 --> 00:04:05,040
not quite there yet if there's a few

00:04:03,299 --> 00:04:06,870
percent difference but what you would

00:04:05,040 --> 00:04:10,200
get is essentially just like writing a

00:04:06,870 --> 00:04:13,590
pileup okay so that's the core of the

00:04:10,200 --> 00:04:15,780
problem and why is this good for us why

00:04:13,590 --> 00:04:17,639
are we talking to the scholar community

00:04:15,780 --> 00:04:20,130
enough right well the scholar language

00:04:17,639 --> 00:04:22,440
has many abstractions it's kind of

00:04:20,130 --> 00:04:23,680
modern and you write you know in a very

00:04:22,440 --> 00:04:25,360
high level you

00:04:23,680 --> 00:04:28,750
you explicitly say what you want to do

00:04:25,360 --> 00:04:32,050
any captains and in these cases dravyam

00:04:28,750 --> 00:04:34,960
is especially good right so here on this

00:04:32,050 --> 00:04:37,600
graph we essentially and the problem

00:04:34,960 --> 00:04:40,389
with all the benchmarks before that kind

00:04:37,600 --> 00:04:43,030
of show the performance of virtual

00:04:40,389 --> 00:04:44,830
machines and languages was that they

00:04:43,030 --> 00:04:47,080
were kind of written for this old-school

00:04:44,830 --> 00:04:48,940
style of programming in Java where you

00:04:47,080 --> 00:04:51,220
have like big functions with vile ups

00:04:48,940 --> 00:04:53,830
around them and then if you inline those

00:04:51,220 --> 00:04:56,099
doesn't really matter much but that's

00:04:53,830 --> 00:04:58,870
not actually what's written today so

00:04:56,099 --> 00:05:01,289
what we've done is we developed this new

00:04:58,870 --> 00:05:04,060
benchmarking suite called Renaissance

00:05:01,289 --> 00:05:06,190
and essentially it kind of needs to

00:05:04,060 --> 00:05:09,400
represent more what people write today

00:05:06,190 --> 00:05:11,259
right and if you look on this graph on

00:05:09,400 --> 00:05:13,030
the essentially most of the graphs

00:05:11,259 --> 00:05:14,800
you'll do just speed up on the left and

00:05:13,030 --> 00:05:16,810
then you have benchmarks on the bottom

00:05:14,800 --> 00:05:19,180
and then you have a speed-up for they've

00:05:16,810 --> 00:05:21,009
individual and you have a do mean at the

00:05:19,180 --> 00:05:22,870
end okay so that's the do you mean is

00:05:21,009 --> 00:05:25,720
actually what you really care about in

00:05:22,870 --> 00:05:27,820
the end right and here we have growl EE

00:05:25,720 --> 00:05:30,490
and C E which we've seen on the first

00:05:27,820 --> 00:05:33,120
slide and on the y-axis is the speed-up

00:05:30,490 --> 00:05:35,169
right so and when you look at this

00:05:33,120 --> 00:05:36,520
Renaissance benchmark which kind of

00:05:35,169 --> 00:05:39,639
represents what people write today

00:05:36,520 --> 00:05:42,070
especially in Scala you will see that we

00:05:39,639 --> 00:05:44,199
get the Geo mean of of 32 percent

00:05:42,070 --> 00:05:47,740
improvement right so if you run your

00:05:44,199 --> 00:05:49,750
your program with rel EE you will get 32

00:05:47,740 --> 00:05:52,780
percent improvement and if you run it

00:05:49,750 --> 00:05:56,560
with C II which we'll see shortly how

00:05:52,780 --> 00:05:59,470
easy it is you will get 6 percent right

00:05:56,560 --> 00:06:01,150
and then there is a specific skull of

00:05:59,470 --> 00:06:02,919
the benchmark which is just for Scala

00:06:01,150 --> 00:06:05,979
and it feels a lot of like tools and

00:06:02,919 --> 00:06:09,340
stuff from the Scala ecosystem and here

00:06:05,979 --> 00:06:13,539
you will again see 38% for growl

00:06:09,340 --> 00:06:15,520
enterprise and 7% for C and because of

00:06:13,539 --> 00:06:17,560
this Twitter is already using it in

00:06:15,520 --> 00:06:19,870
production so when you're tweet you know

00:06:17,560 --> 00:06:21,699
the code that dispatches the tweets

00:06:19,870 --> 00:06:23,979
around is running on ground it was

00:06:21,699 --> 00:06:28,090
generated by God so you know this is a

00:06:23,979 --> 00:06:30,070
solid technology it won't failing and

00:06:28,090 --> 00:06:32,889
then before you know there were people

00:06:30,070 --> 00:06:34,750
are always kind of there was one problem

00:06:32,889 --> 00:06:36,909
that the ground was written in Java so

00:06:34,750 --> 00:06:37,520
people would always say well yeah but

00:06:36,909 --> 00:06:39,830
then it starts

00:06:37,520 --> 00:06:42,620
small and so on and in the last year

00:06:39,830 --> 00:06:44,840
what we developed is a library called

00:06:42,620 --> 00:06:47,300
Lib growl we just takes the whole growl

00:06:44,840 --> 00:06:50,449
lion growl compiler and compile is it as

00:06:47,300 --> 00:06:52,909
a native library right and then puts it

00:06:50,449 --> 00:06:55,460
as a JIT compiler in hotspot so here on

00:06:52,909 --> 00:06:57,949
the essentially and then we package it

00:06:55,460 --> 00:07:01,159
is a native image which will soon see

00:06:57,949 --> 00:07:02,569
what it is and every compilation is kind

00:07:01,159 --> 00:07:04,430
of a separate thing so just compile the

00:07:02,569 --> 00:07:07,030
function and throw away the whole the

00:07:04,430 --> 00:07:08,960
whole heap and it starts doors right and

00:07:07,030 --> 00:07:10,639
essentially when you what you see on the

00:07:08,960 --> 00:07:12,380
on the left you will see that you know

00:07:10,639 --> 00:07:14,599
on the on the right is what happened

00:07:12,380 --> 00:07:16,759
before this is a simple streams example

00:07:14,599 --> 00:07:18,199
that I composed you will see that this

00:07:16,759 --> 00:07:20,210
actually on the first run it would take

00:07:18,199 --> 00:07:22,729
a second to do a first iteration and

00:07:20,210 --> 00:07:25,310
then it would like slowly get to the to

00:07:22,729 --> 00:07:27,199
the to the performance on the on this

00:07:25,310 --> 00:07:30,650
side you will see how it kind of you

00:07:27,199 --> 00:07:32,990
know immediately goes to the essentially

00:07:30,650 --> 00:07:34,940
kind of right from the get-go it becomes

00:07:32,990 --> 00:07:36,500
fast and when you run this with c2 is

00:07:34,940 --> 00:07:39,490
basically pretty much the same numbers

00:07:36,500 --> 00:07:41,569
right so so now we have with the growl

00:07:39,490 --> 00:07:43,819
compiler you will whenever whenever you

00:07:41,569 --> 00:07:45,830
run your app it will run as fast the c2

00:07:43,819 --> 00:07:50,330
I mean it will warm up as fast the c2

00:07:45,830 --> 00:07:52,009
which brings us to the next point it is

00:07:50,330 --> 00:07:54,699
actually using gravity and for faster

00:07:52,009 --> 00:07:58,400
computation so Scott the Scala compiler

00:07:54,699 --> 00:08:00,110
is notorious for essentially being very

00:07:58,400 --> 00:08:02,180
slow to compile like every Scala Daisy

00:08:00,110 --> 00:08:05,659
visit that people would be like oh I

00:08:02,180 --> 00:08:07,699
slowed it from by slow so what we've

00:08:05,659 --> 00:08:09,710
done here is we use growl for

00:08:07,699 --> 00:08:11,509
compilation because for compilation

00:08:09,710 --> 00:08:14,240
there is another particularly important

00:08:11,509 --> 00:08:15,800
thing is that it's not only or the

00:08:14,240 --> 00:08:17,150
number of machines the front somewhere

00:08:15,800 --> 00:08:18,830
in the cloud which you don't see it's

00:08:17,150 --> 00:08:21,259
actually your time like computation

00:08:18,830 --> 00:08:23,330
whenever you do CI or test compilation

00:08:21,259 --> 00:08:25,159
is the first thing you do in a static

00:08:23,330 --> 00:08:27,560
language and because of that it's your

00:08:25,159 --> 00:08:29,569
time you wait for it so you want this

00:08:27,560 --> 00:08:31,550
time to get shorter that's why on this

00:08:29,569 --> 00:08:35,149
slide lower is better basically it's the

00:08:31,550 --> 00:08:36,620
time essentially to compile and then on

00:08:35,149 --> 00:08:39,709
the graph you'll also see I took

00:08:36,620 --> 00:08:42,079
numbers from the tree three big projects

00:08:39,709 --> 00:08:44,560
one is the akka liters which is written

00:08:42,079 --> 00:08:47,930
in Scala and the fronted for Guardian

00:08:44,560 --> 00:08:50,900
and then we'll have we compare like

00:08:47,930 --> 00:08:53,180
running with normal Java Java 8

00:08:50,900 --> 00:08:54,680
running Java with Grall VM and here I'm

00:08:53,180 --> 00:08:57,440
using Enterprise Edition only no

00:08:54,680 --> 00:08:59,300
Community Edition because in this case I

00:08:57,440 --> 00:09:01,310
think it's you know your time and your

00:08:59,300 --> 00:09:04,880
productivity so money doesn't really

00:09:01,310 --> 00:09:07,010
matter and essentially and it's not

00:09:04,880 --> 00:09:08,780
expensive for this case so essentially

00:09:07,010 --> 00:09:11,110
and then we use bloop which is a new

00:09:08,780 --> 00:09:13,340
framework for Cisco scholar compilation

00:09:11,110 --> 00:09:16,190
developed by George from Scarlet Center

00:09:13,340 --> 00:09:18,590
and essentially we use blue and blue

00:09:16,190 --> 00:09:20,750
plus gravia and there are other famous

00:09:18,590 --> 00:09:22,580
speed-up scholar compilation Hydra and

00:09:20,750 --> 00:09:25,430
the numbers for them are pretty much the

00:09:22,580 --> 00:09:27,100
same and so if you look at here you know

00:09:25,430 --> 00:09:30,260
compared to normal Java you will get

00:09:27,100 --> 00:09:31,940
anywhere from like thirty twenty five

00:09:30,260 --> 00:09:33,830
percent speed up right so you will go

00:09:31,940 --> 00:09:35,870
and you will get your results faster

00:09:33,830 --> 00:09:37,820
twenty to twenty five to thirty five

00:09:35,870 --> 00:09:39,800
percent and then also if you apply a

00:09:37,820 --> 00:09:41,480
blue which kind of paralyzes this color

00:09:39,800 --> 00:09:44,360
Belgium in this case actually pipelines

00:09:41,480 --> 00:09:46,730
if type pipelines and paralyzes you will

00:09:44,360 --> 00:09:48,020
you will get the similar improvements I

00:09:46,730 --> 00:09:49,790
mean it's here you don't see that much

00:09:48,020 --> 00:09:51,830
because there you know the first number

00:09:49,790 --> 00:09:53,900
is smaller but you will get pretty much

00:09:51,830 --> 00:09:56,060
the same spirit so any compilation

00:09:53,900 --> 00:09:59,600
framework you use is it Hydra which is

00:09:56,060 --> 00:10:02,540
commercial or blue or Scala you will get

00:09:59,600 --> 00:10:06,710
about 30% faster compilation and that's

00:10:02,540 --> 00:10:08,410
your time right and so this brings me to

00:10:06,710 --> 00:10:11,600
the conclusion of this first part about

00:10:08,410 --> 00:10:16,130
ground running Scala faster with gravy

00:10:11,600 --> 00:10:18,230
on is essentially using c2 like the

00:10:16,130 --> 00:10:20,540
older the compiler in Java

00:10:18,230 --> 00:10:23,180
instead of growl is just a waste of time

00:10:20,540 --> 00:10:26,000
and energy and money right so it will

00:10:23,180 --> 00:10:27,950
just say wasting save seven percent of

00:10:26,000 --> 00:10:30,980
your performance and all you need to do

00:10:27,950 --> 00:10:34,370
is basically for jdk eleven put this on

00:10:30,980 --> 00:10:38,240
your command line and that's it you know

00:10:34,370 --> 00:10:41,270
seven percent for free done right or you

00:10:38,240 --> 00:10:43,130
can download gravi vm c e or e and put

00:10:41,270 --> 00:10:43,520
it in your path and java home it's that

00:10:43,130 --> 00:10:46,400
easy

00:10:43,520 --> 00:10:47,990
so and you know it transit bitter people

00:10:46,400 --> 00:10:50,270
are already using it for compilation all

00:10:47,990 --> 00:10:52,220
around so there's absolutely no reason

00:10:50,270 --> 00:10:55,220
to not use it it's just throwing

00:10:52,220 --> 00:10:56,730
throwing money time and so on out of in

00:10:55,220 --> 00:10:58,590
them

00:10:56,730 --> 00:11:01,440
and then in production it will get to

00:10:58,590 --> 00:11:03,570
give you about 35% speed-up which is you

00:11:01,440 --> 00:11:06,630
know if you have a service running a

00:11:03,570 --> 00:11:10,250
thousand machines you know multiply the

00:11:06,630 --> 00:11:14,010
numbers it's a pretty cool thing to do

00:11:10,250 --> 00:11:15,540
and then of course for computation for

00:11:14,010 --> 00:11:16,950
me this is like a no-brainer you know

00:11:15,540 --> 00:11:18,390
you have a team of a hundred people

00:11:16,950 --> 00:11:19,980
waiting thirty percent more for

00:11:18,390 --> 00:11:22,860
something and you have like one or two

00:11:19,980 --> 00:11:24,270
or three machines or five doing CI it's

00:11:22,860 --> 00:11:28,970
just like a no-brainer

00:11:24,270 --> 00:11:31,770
get get your dumb stuff done faster cool

00:11:28,970 --> 00:11:33,810
so that was the part about growth you

00:11:31,770 --> 00:11:37,470
know running Scala faster on growth but

00:11:33,810 --> 00:11:40,340
then the JVM is also notorious for its

00:11:37,470 --> 00:11:42,630
slow startup right so we developed in

00:11:40,340 --> 00:11:44,520
underground VN we have this essentially

00:11:42,630 --> 00:11:46,170
project called native image or people

00:11:44,520 --> 00:11:48,990
call it gravia native image or just

00:11:46,170 --> 00:11:51,510
native image which allows us to run

00:11:48,990 --> 00:11:54,930
Scala with fast startup in long and

00:11:51,510 --> 00:11:57,420
appropriate so so how does this work on

00:11:54,930 --> 00:12:00,060
the on the left side we start with like

00:11:57,420 --> 00:12:02,130
just like a Java you say Java there CP

00:12:00,060 --> 00:12:05,100
and the main class you do the same will

00:12:02,130 --> 00:12:07,440
have your application libraries java

00:12:05,100 --> 00:12:08,970
class library and you will have

00:12:07,440 --> 00:12:11,460
something called substrate vm which is a

00:12:08,970 --> 00:12:14,130
vm developed in java that we will kind

00:12:11,460 --> 00:12:17,070
of ship together with all your libraries

00:12:14,130 --> 00:12:21,840
and then what we do inside of native

00:12:17,070 --> 00:12:23,700
image is we do an iterative in iterative

00:12:21,840 --> 00:12:26,070
analysis it's a variation of a point

00:12:23,700 --> 00:12:27,840
analysis which will kind of try to see

00:12:26,070 --> 00:12:30,990
which code from the you know all of

00:12:27,840 --> 00:12:32,340
these is reachable right so what what

00:12:30,990 --> 00:12:34,290
are you using and even if you're using

00:12:32,340 --> 00:12:35,760
not using some fields it will just kick

00:12:34,290 --> 00:12:38,820
the fields out you don't need that right

00:12:35,760 --> 00:12:40,320
and then it runs iteratively and another

00:12:38,820 --> 00:12:42,030
interesting thing it does it pre

00:12:40,320 --> 00:12:44,640
initializes your stuff so

00:12:42,030 --> 00:12:46,380
so essentially you can kind of run parts

00:12:44,640 --> 00:12:48,570
of your application ahead of time if you

00:12:46,380 --> 00:12:50,700
need some configuration or if you need

00:12:48,570 --> 00:12:52,860
some parsing some files you know which

00:12:50,700 --> 00:12:56,880
takes a lot of time you can essentially

00:12:52,860 --> 00:13:01,260
come and you can just do that at Build

00:12:56,880 --> 00:13:01,740
time and then it will produce it will be

00:13:01,260 --> 00:13:04,170
kind of

00:13:01,740 --> 00:13:06,180
serialized in the heap right and then we

00:13:04,170 --> 00:13:08,490
will able to compile the code and take

00:13:06,180 --> 00:13:09,970
the snapshot of this heap and we will

00:13:08,490 --> 00:13:12,879
use the ground compiler of course

00:13:09,970 --> 00:13:14,920
the same thing and produce machine code

00:13:12,879 --> 00:13:16,569
right so you will get machine code

00:13:14,920 --> 00:13:17,860
there's one object file image heap is

00:13:16,569 --> 00:13:19,750
another object file link them together

00:13:17,860 --> 00:13:22,389
you get an executable and this

00:13:19,750 --> 00:13:23,800
executable or a shared library so and

00:13:22,389 --> 00:13:26,230
this executable you can run just like

00:13:23,800 --> 00:13:27,160
any other native executable on pretty

00:13:26,230 --> 00:13:29,740
much any flat

00:13:27,160 --> 00:13:33,910
okay so Windows is it Windows Windows or

00:13:29,740 --> 00:13:38,319
Darwin or evil and also we support AR 64

00:13:33,910 --> 00:13:40,329
and AMD for now but more is to come and

00:13:38,319 --> 00:13:42,160
yeah so what you get to this so how does

00:13:40,329 --> 00:13:45,699
this work it's really easy Scala see

00:13:42,160 --> 00:13:47,529
hello world time hello world 70

00:13:45,699 --> 00:13:50,800
milliseconds to print like online that's

00:13:47,529 --> 00:13:53,170
bit ridiculous and then if they native

00:13:50,800 --> 00:13:54,670
image you pass the library we could make

00:13:53,170 --> 00:13:56,649
this a bit maybe we should do something

00:13:54,670 --> 00:13:59,589
like there's this tool scholar to make

00:13:56,649 --> 00:14:01,569
this nicer and in say hello world hello

00:13:59,589 --> 00:14:05,829
world this is now just like a C program

00:14:01,569 --> 00:14:07,660
and you get 5 min sex ok and now why is

00:14:05,829 --> 00:14:10,870
this interesting is because these days

00:14:07,660 --> 00:14:12,459
you know it's like microservices lambdas

00:14:10,870 --> 00:14:13,660
are becoming very popular and there's a

00:14:12,459 --> 00:14:16,209
whole ton of these frameworks

00:14:13,660 --> 00:14:18,459
essentially you know for micro services

00:14:16,209 --> 00:14:21,250
and what happens in the cloud is that

00:14:18,459 --> 00:14:22,809
basically people are you know the cloud

00:14:21,250 --> 00:14:26,230
providers are kind of removing your

00:14:22,809 --> 00:14:28,480
services are not started up right and so

00:14:26,230 --> 00:14:30,069
when the new request comes their service

00:14:28,480 --> 00:14:31,750
needs to boot and then your whole VM

00:14:30,069 --> 00:14:33,490
needs first the kernel needs to start

00:14:31,750 --> 00:14:35,379
and then your VM needs to start and that

00:14:33,490 --> 00:14:38,379
takes health tone-on-tone of time and

00:14:35,379 --> 00:14:39,790
here on this slide we have the startup

00:14:38,379 --> 00:14:41,559
time for some of the frameworks these

00:14:39,790 --> 00:14:44,019
are not scholar framers factor to talk

00:14:41,559 --> 00:14:46,600
about this later but they are very

00:14:44,019 --> 00:14:49,720
popular in the community so for Helena

00:14:46,600 --> 00:14:51,670
so we'll have again jdk jdk 12 and

00:14:49,720 --> 00:14:53,680
native inch right and we have like

00:14:51,670 --> 00:14:56,319
halide and it's an open source frame of

00:14:53,680 --> 00:14:58,180
developing oracle for micro services you

00:14:56,319 --> 00:15:00,309
will get like one second on top of the

00:14:58,180 --> 00:15:02,290
boot time of the kernel itself right so

00:15:00,309 --> 00:15:04,180
it's support ones that can be native

00:15:02,290 --> 00:15:06,639
image 35 milliseconds so you basically

00:15:04,180 --> 00:15:08,680
start and it just starts you know

00:15:06,639 --> 00:15:10,569
answering requests so this means if your

00:15:08,680 --> 00:15:13,089
lambda is cold and you get the request

00:15:10,569 --> 00:15:15,009
the request will be out before you break

00:15:13,089 --> 00:15:17,079
your service level agreement right your

00:15:15,009 --> 00:15:20,230
customer won't have to wait for like a

00:15:17,079 --> 00:15:22,600
second to get the page and similar

00:15:20,230 --> 00:15:23,300
things for micro not and corpus which is

00:15:22,600 --> 00:15:26,360
entirely

00:15:23,300 --> 00:15:30,649
albian you get 16 milliseconds alright

00:15:26,360 --> 00:15:33,100
so just you know service up and then

00:15:30,649 --> 00:15:36,410
another thing which kind of saves money

00:15:33,100 --> 00:15:37,580
is basically the memory footprint right

00:15:36,410 --> 00:15:39,290
because now you don't have a JIT

00:15:37,580 --> 00:15:40,339
compiler you don't gather an interpreter

00:15:39,290 --> 00:15:42,709
you don't have the class information

00:15:40,339 --> 00:15:46,430
it's all kind of burnt into this binary

00:15:42,709 --> 00:15:48,800
in a very minimal and compressed way you

00:15:46,430 --> 00:15:51,950
really essentially you know the memory

00:15:48,800 --> 00:15:54,200
footprint for essentially running the

00:15:51,950 --> 00:15:56,959
first request of these applications it

00:15:54,200 --> 00:15:59,390
will be about 120 Meg's hundred seventy

00:15:56,959 --> 00:16:01,760
hundred eighty and with with native

00:15:59,390 --> 00:16:05,390
image it will be about like 4x less I

00:16:01,760 --> 00:16:06,680
still get 30 40 and 70 right so and now

00:16:05,390 --> 00:16:09,019
you know you can you can

00:16:06,680 --> 00:16:13,630
you've spent like less memory which

00:16:09,019 --> 00:16:13,630
means it's cheaper right so that's it

00:16:14,829 --> 00:16:19,910
good so one thing that I tried before

00:16:17,720 --> 00:16:22,610
this conference is getting this so

00:16:19,910 --> 00:16:24,230
native image has one limitation in

00:16:22,610 --> 00:16:25,910
theory and there is a few you know it's

00:16:24,230 --> 00:16:29,329
still in active development it's getting

00:16:25,910 --> 00:16:32,000
quite close to being ready for wide

00:16:29,329 --> 00:16:33,680
adoption I would say but they tried a

00:16:32,000 --> 00:16:35,029
few scholar framers and I notice that

00:16:33,680 --> 00:16:36,440
the whole scholar community is not

00:16:35,029 --> 00:16:38,029
really trying to put these frameworks

00:16:36,440 --> 00:16:42,020
you know we get now these days we get a

00:16:38,029 --> 00:16:44,390
ton of issues on github and like 95% of

00:16:42,020 --> 00:16:45,560
these issues are java failures so so

00:16:44,390 --> 00:16:47,300
essentially I tried a few scholar

00:16:45,560 --> 00:16:49,100
framers and I found some things that are

00:16:47,300 --> 00:16:52,520
really not working which we can fix in

00:16:49,100 --> 00:16:56,329
another of days and and I kind of notice

00:16:52,520 --> 00:16:58,339
that essentially you know the scholar

00:16:56,329 --> 00:16:59,870
community doesn't really know about this

00:16:58,339 --> 00:17:02,480
or it doesn't want to try or doesn't

00:16:59,870 --> 00:17:03,350
report issues so you know this this is

00:17:02,480 --> 00:17:06,079
our priority

00:17:03,350 --> 00:17:07,579
just open initial github pinging if

00:17:06,079 --> 00:17:09,949
someone is not responding we're very

00:17:07,579 --> 00:17:12,410
kind of overloaded these days say hey

00:17:09,949 --> 00:17:13,760
you know can you fix my framework sure I

00:17:12,410 --> 00:17:15,890
will fix your framework I'll raise

00:17:13,760 --> 00:17:18,199
priority okay and and others in the team

00:17:15,890 --> 00:17:21,980
right so so it's kind of I think it's

00:17:18,199 --> 00:17:23,990
important to report issues test it in

00:17:21,980 --> 00:17:25,900
your CI if you are a framework culture

00:17:23,990 --> 00:17:28,580
of play just put native image in your CI

00:17:25,900 --> 00:17:31,040
because it will also attract users to

00:17:28,580 --> 00:17:33,290
your framework because others start up

00:17:31,040 --> 00:17:34,910
in 35 milliseconds and you don't so it's

00:17:33,290 --> 00:17:38,000
better that you also support that so you

00:17:34,910 --> 00:17:39,799
start in like 15 milliseconds

00:17:38,000 --> 00:17:41,630
so put it in your CI and that way it

00:17:39,799 --> 00:17:43,190
will keep it solid right then we we

00:17:41,630 --> 00:17:44,390
provided all the flags and all the

00:17:43,190 --> 00:17:47,419
infrastructure you can easily download

00:17:44,390 --> 00:17:51,830
native image and you can run it right so

00:17:47,419 --> 00:17:53,690
just put it in your test and here we are

00:17:51,830 --> 00:17:55,700
actively working with the community so

00:17:53,690 --> 00:17:58,820
just ping us on whatever means like

00:17:55,700 --> 00:18:00,220
email github whatever you want they will

00:17:58,820 --> 00:18:03,710
respond

00:18:00,220 --> 00:18:05,270
cool so they didn't which has another

00:18:03,710 --> 00:18:08,419
thing so whenever it's kind of

00:18:05,270 --> 00:18:10,190
notoriously bad to compile Java and

00:18:08,419 --> 00:18:12,200
dynamic languages in an ahead of time

00:18:10,190 --> 00:18:13,669
way right so what we provided in a

00:18:12,200 --> 00:18:16,520
native image is something called profile

00:18:13,669 --> 00:18:17,929
guided optimizations right so it's

00:18:16,520 --> 00:18:20,240
actually the whole girl compiler is

00:18:17,929 --> 00:18:21,860
built to know the profiles you can of

00:18:20,240 --> 00:18:25,909
run in an interpreter you get what your

00:18:21,860 --> 00:18:28,700
application is doing and then and then

00:18:25,909 --> 00:18:30,980
what happens is you basically get faster

00:18:28,700 --> 00:18:33,049
code right and we support this also with

00:18:30,980 --> 00:18:34,669
native image right it's called profile

00:18:33,049 --> 00:18:36,110
guided optimization so but it requires

00:18:34,669 --> 00:18:37,970
you to build to native image so you

00:18:36,110 --> 00:18:40,100
first do native image video instrument

00:18:37,970 --> 00:18:42,470
you will get an instrumented binary and

00:18:40,100 --> 00:18:44,179
then you take a few of your workloads if

00:18:42,470 --> 00:18:46,850
it's a web service just send a few

00:18:44,179 --> 00:18:48,500
requests you will get your profiles and

00:18:46,850 --> 00:18:50,659
then feed it to native image with this

00:18:48,500 --> 00:18:53,779
flag and it will get an optimized binary

00:18:50,659 --> 00:18:55,970
right and what this gives us is that

00:18:53,779 --> 00:18:57,740
when we look essentially the performance

00:18:55,970 --> 00:19:01,490
of native image at the moment which has

00:18:57,740 --> 00:19:02,899
still of a very low too many kangs

00:19:01,490 --> 00:19:06,470
low-hanging fruit so it will get very

00:19:02,899 --> 00:19:08,240
better so if you get like this Apache

00:19:06,470 --> 00:19:11,390
bunch and you get the cumulative number

00:19:08,240 --> 00:19:12,559
of requests sent by a patch event you

00:19:11,390 --> 00:19:14,120
will see you know in the beginning of

00:19:12,559 --> 00:19:17,090
course native image is the red line it

00:19:14,120 --> 00:19:18,740
will be very big right because it starts

00:19:17,090 --> 00:19:21,409
from the very beginning at full speed

00:19:18,740 --> 00:19:23,779
right and you will see that it needs

00:19:21,409 --> 00:19:25,970
about like a hundred thousand to five

00:19:23,779 --> 00:19:27,919
hundred to a million requests for the

00:19:25,970 --> 00:19:29,929
hot spot to warm up all its stuff and

00:19:27,919 --> 00:19:32,330
even when it's warmed up it's just a

00:19:29,929 --> 00:19:34,610
tiny bit faster than the native image

00:19:32,330 --> 00:19:36,049
right and that's mostly because our GC

00:19:34,610 --> 00:19:38,740
is currently not the best thing in the

00:19:36,049 --> 00:19:41,330
world and we are working on a new one

00:19:38,740 --> 00:19:44,390
but basically you know with native image

00:19:41,330 --> 00:19:46,970
and video we will get basically you know

00:19:44,390 --> 00:19:49,149
very soon you will get faster code then

00:19:46,970 --> 00:19:50,740
you would get by just you know running

00:19:49,149 --> 00:19:54,309
on the

00:19:50,740 --> 00:19:55,720
right and it's also very important the

00:19:54,309 --> 00:19:57,669
native image is called for command-line

00:19:55,720 --> 00:20:00,130
tools so here on the right to have it

00:19:57,669 --> 00:20:01,510
with pgo for Scala but in particular

00:20:00,130 --> 00:20:03,580
because of all the abstractions that we

00:20:01,510 --> 00:20:05,080
remove you will get actually faster code

00:20:03,580 --> 00:20:07,750
than a hot spot it's not only that it

00:20:05,080 --> 00:20:10,210
starts fast and it has low memory but it

00:20:07,750 --> 00:20:12,220
will run faster and Scala MT is the best

00:20:10,210 --> 00:20:14,230
I think it's like 37 percent faster than

00:20:12,220 --> 00:20:15,669
Hospice so it's not like so if you want

00:20:14,230 --> 00:20:17,559
to format your files you know in

00:20:15,669 --> 00:20:20,789
IntelliJ or whatever it will just go

00:20:17,559 --> 00:20:24,610
through them in like 5 milliseconds ok

00:20:20,789 --> 00:20:26,320
cool so you know now we're standing on

00:20:24,610 --> 00:20:28,059
the shoulders of giants right we have

00:20:26,320 --> 00:20:30,399
the growl compiler which makes stuff

00:20:28,059 --> 00:20:32,980
really fast we have the native image to

00:20:30,399 --> 00:20:34,480
compile it into native code and what's

00:20:32,980 --> 00:20:37,179
new what we've been working so late in

00:20:34,480 --> 00:20:40,240
the last six months is essentially to

00:20:37,179 --> 00:20:42,010
extend these pictures with three you

00:20:40,240 --> 00:20:44,140
know three new things

00:20:42,010 --> 00:20:45,880
it's like deploying to mobile devices

00:20:44,140 --> 00:20:49,799
right so what you're building is

00:20:45,880 --> 00:20:52,899
deploying to iOS Android and desktop and

00:20:49,799 --> 00:20:54,250
you know as a part of this effort we

00:20:52,899 --> 00:20:56,620
tried a few things we have a growl

00:20:54,250 --> 00:20:58,600
realmnet first of all iOS is kind of the

00:20:56,620 --> 00:21:00,460
biggest problem because first of all it

00:20:58,600 --> 00:21:02,919
runs it doesn't run on amd64

00:21:00,460 --> 00:21:05,080
so you need like you know an AR compiler

00:21:02,919 --> 00:21:07,840
so we have two efforts one these two

00:21:05,080 --> 00:21:09,640
called use LLVM and the other one is to

00:21:07,840 --> 00:21:11,950
use the growl native compilers to hear

00:21:09,640 --> 00:21:13,929
so what we added is just for fun is to

00:21:11,950 --> 00:21:17,409
see you know how well would this LLVM

00:21:13,929 --> 00:21:19,029
work as a back-end for native image and

00:21:17,409 --> 00:21:20,770
what we've done is we implement in an

00:21:19,029 --> 00:21:22,630
elegant that is program which is now

00:21:20,770 --> 00:21:23,940
immersed in its there it's kind of still

00:21:22,630 --> 00:21:26,710
not in the best shape

00:21:23,940 --> 00:21:30,190
you cannot you'll see in the demo it

00:21:26,710 --> 00:21:31,750
works and why do we need is one of the

00:21:30,190 --> 00:21:33,510
reasons is that a police constable each

00:21:31,750 --> 00:21:35,950
returning that it will require

00:21:33,510 --> 00:21:38,679
essentially LLVM bit code for the

00:21:35,950 --> 00:21:40,960
applications you ship to the IRS so you

00:21:38,679 --> 00:21:41,740
know then we can ship the 11 bit code

00:21:40,960 --> 00:21:43,750
and we're clear

00:21:41,740 --> 00:21:45,549
in case you know they pull the plug we

00:21:43,750 --> 00:21:49,809
can always say that we should be a bit

00:21:45,549 --> 00:21:51,429
code and then another interesting thing

00:21:49,809 --> 00:21:54,490
with the television gives is that you

00:21:51,429 --> 00:21:56,350
can you know relatively easily port to

00:21:54,490 --> 00:21:57,730
new niche architectures so if you're in

00:21:56,350 --> 00:22:01,090
the embedded market like is it

00:21:57,730 --> 00:22:02,990
automotive or Internet of Things you

00:22:01,090 --> 00:22:06,760
know you have some some

00:22:02,990 --> 00:22:09,590
little kind of not so well supported

00:22:06,760 --> 00:22:11,120
architecture you can just you know and

00:22:09,590 --> 00:22:13,250
you have an LVN back-end which is most

00:22:11,120 --> 00:22:15,350
likely you can just generate that and

00:22:13,250 --> 00:22:17,059
you should be able to with a few weeks

00:22:15,350 --> 00:22:19,370
or maybe a month or two you should be

00:22:17,059 --> 00:22:23,299
able to get native image so it means all

00:22:19,370 --> 00:22:26,270
Java and Scala programs running on your

00:22:23,299 --> 00:22:28,399
device right but it comes with the price

00:22:26,270 --> 00:22:30,770
this is like not done yet

00:22:28,399 --> 00:22:33,020
moving GC another VM is still

00:22:30,770 --> 00:22:34,940
experimental so I'll keep you posted

00:22:33,020 --> 00:22:36,350
right so you can build probably when

00:22:34,940 --> 00:22:38,990
it's done when we know exactly what's

00:22:36,350 --> 00:22:43,039
the story we'll write a blog post about

00:22:38,990 --> 00:22:45,200
it and you know talk about it so now

00:22:43,039 --> 00:22:48,080
let's see how this cross platform Scala

00:22:45,200 --> 00:22:50,120
and Java of course it's the same

00:22:48,080 --> 00:22:52,100
platform will look like all right so we

00:22:50,120 --> 00:22:53,659
talked about cloud via native image you

00:22:52,100 --> 00:22:57,710
know now we have all the you know

00:22:53,659 --> 00:22:59,990
bytecode compiling into the executable

00:22:57,710 --> 00:23:02,000
which runs on any platform

00:22:59,990 --> 00:23:03,320
what we did is now we need to do the

00:23:02,000 --> 00:23:05,390
front end right so how does the

00:23:03,320 --> 00:23:08,179
developer and which library the views

00:23:05,390 --> 00:23:11,210
right so for that we teamed up with this

00:23:08,179 --> 00:23:12,590
company called galloon and together we

00:23:11,210 --> 00:23:14,570
worked on this toolset which is

00:23:12,590 --> 00:23:16,340
essentially consists you start with your

00:23:14,570 --> 00:23:17,779
ID right and then you have a plugin

00:23:16,340 --> 00:23:20,240
which is in our case it's currently

00:23:17,779 --> 00:23:22,039
Gradle and maven but adding SBT you know

00:23:20,240 --> 00:23:23,539
took all the code is there so just you

00:23:22,039 --> 00:23:27,230
know someone can pick it up and make an

00:23:23,539 --> 00:23:32,090
SBT plugin and then we come with this

00:23:27,230 --> 00:23:34,100
JavaFX mobile which essentially contains

00:23:32,090 --> 00:23:35,720
all of the UI components that working on

00:23:34,100 --> 00:23:39,529
all the platforms right for they work on

00:23:35,720 --> 00:23:41,990
Android iOS and desktop right so so and

00:23:39,529 --> 00:23:43,970
and all of that is kind of good with

00:23:41,990 --> 00:23:45,380
gluon tools and the static libraries

00:23:43,970 --> 00:23:49,190
cross compile for all these platforms

00:23:45,380 --> 00:23:51,110
and compiled with the Guardian native

00:23:49,190 --> 00:23:55,130
image and set to the set to the your

00:23:51,110 --> 00:23:58,250
device right so so you kind of get you

00:23:55,130 --> 00:24:00,919
know a full full-blown stack for

00:23:58,250 --> 00:24:03,350
development on mobile and of course with

00:24:00,919 --> 00:24:05,059
this gluon stuff you will get also

00:24:03,350 --> 00:24:06,919
extensions for all the mobile stuff

00:24:05,059 --> 00:24:07,760
integration with the morning on mobile

00:24:06,919 --> 00:24:10,130
devices like

00:24:07,760 --> 00:24:12,500
abstractions for a camera as GPS and all

00:24:10,130 --> 00:24:15,220
the things like that right and all of

00:24:12,500 --> 00:24:18,440
this is open source

00:24:15,220 --> 00:24:19,970
this part and a part of blown mobile

00:24:18,440 --> 00:24:22,580
there is a closed source part that's the

00:24:19,970 --> 00:24:23,990
way how they earn money basically so it

00:24:22,580 --> 00:24:25,700
does they do some mobile specific

00:24:23,990 --> 00:24:27,049
connectivity and they do something no

00:24:25,700 --> 00:24:29,080
libraries for this kind of

00:24:27,049 --> 00:24:31,549
cross-platform stuff but essentially

00:24:29,080 --> 00:24:33,350
everything you need is open source so

00:24:31,549 --> 00:24:35,510
you can just start and you know today

00:24:33,350 --> 00:24:39,370
you can come out and start hacking your

00:24:35,510 --> 00:24:45,340
like cross but for mobile app on the JVM

00:24:39,370 --> 00:24:45,340
so tinker's said most to these things

00:24:46,630 --> 00:24:50,690
yes so that this was the only way

00:24:49,010 --> 00:24:53,870
basically before you know the JVM was

00:24:50,690 --> 00:24:56,390
locked because because running hotspot

00:24:53,870 --> 00:24:58,340
is not allowed on on iOS no-one has

00:24:56,390 --> 00:25:00,350
developed a proper IOT compiler there

00:24:58,340 --> 00:25:02,870
were few like you know open source and a

00:25:00,350 --> 00:25:06,289
few commercial ones but none was built

00:25:02,870 --> 00:25:08,029
on on solid ground right with the proper

00:25:06,289 --> 00:25:09,799
team supporting it so for the first time

00:25:08,029 --> 00:25:12,649
now we have a proper you know ahead of

00:25:09,799 --> 00:25:14,840
time compiler for Java so we can deploy

00:25:12,649 --> 00:25:17,990
to all these devices right and you can

00:25:14,840 --> 00:25:21,110
kind of spawn a new ecosystem based in

00:25:17,990 --> 00:25:23,270
Java and then for Java effects yeah it

00:25:21,110 --> 00:25:24,770
has native code but Java FX is not the

00:25:23,270 --> 00:25:28,070
only library in the world there is

00:25:24,770 --> 00:25:29,899
others which we'll talk about later and

00:25:28,070 --> 00:25:31,909
yeah this is all the things I said and

00:25:29,899 --> 00:25:34,159
of course this all works only for Java

00:25:31,909 --> 00:25:36,559
11 12 and 13 right

00:25:34,159 --> 00:25:38,270
so Java it is not supported so starting

00:25:36,559 --> 00:25:40,730
from Java 11 because Java effects

00:25:38,270 --> 00:25:43,909
starting 11 supports all of the native

00:25:40,730 --> 00:25:45,559
stuff and Android is coming so we are

00:25:43,909 --> 00:25:49,010
working on that it will be enough in a

00:25:45,559 --> 00:25:49,520
matter of months out so let's check this

00:25:49,010 --> 00:25:55,250
out

00:25:49,520 --> 00:25:57,890
how does this work right so so here we

00:25:55,250 --> 00:26:01,850
will have this chat app as a demo which

00:25:57,890 --> 00:26:04,490
we developed in our aid ID and then you

00:26:01,850 --> 00:26:06,620
know you will have just here it's just a

00:26:04,490 --> 00:26:09,230
normal Gradle project like anything else

00:26:06,620 --> 00:26:10,789
and then what we can do is you know

00:26:09,230 --> 00:26:13,399
while you develop you can develop on

00:26:10,789 --> 00:26:13,940
desktop freely so we can say just Gradle

00:26:13,399 --> 00:26:15,950
run

00:26:13,940 --> 00:26:17,870
I will not compile here and the reason

00:26:15,950 --> 00:26:19,309
for that is essentially that at the

00:26:17,870 --> 00:26:20,659
moment we do salary and stuff it

00:26:19,309 --> 00:26:23,630
compiles wait too long for this

00:26:20,659 --> 00:26:25,639
presentation to show but yeah you know

00:26:23,630 --> 00:26:28,330
this is an application now running on a

00:26:25,639 --> 00:26:32,350
desktop it's a chat app it's hello sky

00:26:28,330 --> 00:26:38,049
hello Scala days you know growl VM runs

00:26:32,350 --> 00:26:40,330
faster and then you send a message okay

00:26:38,049 --> 00:26:43,240
so you can just go back to your ID hack

00:26:40,330 --> 00:26:46,090
stuff browser on Gradle run and you get

00:26:43,240 --> 00:26:47,799
the app to run okay good

00:26:46,090 --> 00:26:52,899
now let's see what you're gonna do for

00:26:47,799 --> 00:26:58,000
the device right well same project use a

00:26:52,899 --> 00:26:59,919
Gradle native run right so of course

00:26:58,000 --> 00:27:02,769
again again I skip the compilation step

00:26:59,919 --> 00:27:04,809
because because now it would like take

00:27:02,769 --> 00:27:06,940
like you know a minute or two minutes to

00:27:04,809 --> 00:27:08,350
build so we don't have time for that so

00:27:06,940 --> 00:27:09,070
what this will do is it will fire up a

00:27:08,350 --> 00:27:11,500
simulator

00:27:09,070 --> 00:27:13,179
you know the simulator will go to the

00:27:11,500 --> 00:27:14,830
gluon tools and you can see that it sees

00:27:13,179 --> 00:27:16,210
this message it's actually downloaded

00:27:14,830 --> 00:27:18,549
from the internet right so all of this

00:27:16,210 --> 00:27:21,220
stuff here I am using is connected so

00:27:18,549 --> 00:27:22,929
it's all in the cloud alright so you

00:27:21,220 --> 00:27:24,639
will see the message I just posted and

00:27:22,929 --> 00:27:26,080
because this is a simulator you need to

00:27:24,639 --> 00:27:30,580
turn it off by clicking on this button

00:27:26,080 --> 00:27:33,850
on the side and then sliding off okay

00:27:30,580 --> 00:27:35,679
and then you know once you're done

00:27:33,850 --> 00:27:37,450
developing in this environment you

00:27:35,679 --> 00:27:39,519
basically want to finally test it on

00:27:37,450 --> 00:27:41,529
your device so you just change one

00:27:39,519 --> 00:27:44,139
variable in this case I copy the project

00:27:41,529 --> 00:27:46,120
and then you will say again native run

00:27:44,139 --> 00:27:49,210
and you will say instead of iOS you say

00:27:46,120 --> 00:27:52,360
iOS iOS there see me we'll just say iOS

00:27:49,210 --> 00:27:59,679
and then what this will do is you know

00:27:52,360 --> 00:28:01,750
when I do run you can see what you know

00:27:59,679 --> 00:28:03,700
same two messages right so it's all

00:28:01,750 --> 00:28:07,649
connected to the same thing and then you

00:28:03,700 --> 00:28:07,649
can basically start developing right

00:28:11,559 --> 00:28:14,559
that's

00:28:20,370 --> 00:28:29,740
cool so and good so you know many

00:28:28,090 --> 00:28:32,409
especially here in Scala days they've

00:28:29,740 --> 00:28:34,000
seen people are using a particular trick

00:28:32,409 --> 00:28:36,850
to get the way out about this blocker

00:28:34,000 --> 00:28:40,720
that you cannot do JVM on mobile and

00:28:36,850 --> 00:28:43,870
they're using Scala js2 to compile Scala

00:28:40,720 --> 00:28:46,149
into j/s and then hook into this react

00:28:43,870 --> 00:28:48,669
native so here I would just like to

00:28:46,149 --> 00:28:50,140
compare essentially you know what I'm

00:28:48,669 --> 00:28:52,840
trying to what they would like to see

00:28:50,140 --> 00:28:55,539
happening is that essentially we spawn a

00:28:52,840 --> 00:28:57,760
JVM community around mobile right

00:28:55,539 --> 00:28:59,380
because so that I don't like JavaScript

00:28:57,760 --> 00:29:01,630
I think it's just good to have you know

00:28:59,380 --> 00:29:03,549
it's good to have two things done you

00:29:01,630 --> 00:29:06,279
know things done into the or two or more

00:29:03,549 --> 00:29:08,380
solid base right so so and I would just

00:29:06,279 --> 00:29:09,909
like to compare react native and now at

00:29:08,380 --> 00:29:11,769
this point in time you know we just

00:29:09,909 --> 00:29:13,720
started right so we just this was the

00:29:11,769 --> 00:29:15,490
hardest part getting this like demo to

00:29:13,720 --> 00:29:17,049
run was the hard part of course it still

00:29:15,490 --> 00:29:20,559
buggy and stuff but you know in a few

00:29:17,049 --> 00:29:22,419
months it's it's it's fine but now and

00:29:20,559 --> 00:29:25,269
then we when we remove all of the all of

00:29:22,419 --> 00:29:27,250
this noise I want to just you know

00:29:25,269 --> 00:29:29,320
compare it to react native and say what

00:29:27,250 --> 00:29:31,149
they think needs to happen so if you now

00:29:29,320 --> 00:29:33,419
look at today of course react native has

00:29:31,149 --> 00:29:36,789
like 70,000 stars on github or whatever

00:29:33,419 --> 00:29:38,289
and you know because of that because of

00:29:36,789 --> 00:29:40,990
this bigger community has more

00:29:38,289 --> 00:29:42,490
components which are developed and if he

00:29:40,990 --> 00:29:44,350
has another feature that we still don't

00:29:42,490 --> 00:29:45,820
have any it's hot code updates alright

00:29:44,350 --> 00:29:47,200
if you make a bug in your application

00:29:45,820 --> 00:29:49,779
you can just you know send new code

00:29:47,200 --> 00:29:51,850
especially the code running on the on

00:29:49,779 --> 00:29:53,710
the devices when you call functions that

00:29:51,850 --> 00:29:55,419
you say what this function updated and

00:29:53,710 --> 00:29:59,019
it will download the new one from the

00:29:55,419 --> 00:30:01,059
internet right but then it's essentially

00:29:59,019 --> 00:30:02,529
interpreted code right so it's very slow

00:30:01,059 --> 00:30:05,590
it startup slow

00:30:02,529 --> 00:30:07,360
it has essentially four complicated apps

00:30:05,590 --> 00:30:11,380
you won't be able to run them and it

00:30:07,360 --> 00:30:13,360
burns better right so and for Java

00:30:11,380 --> 00:30:15,039
effects already in this state you know

00:30:13,360 --> 00:30:17,200
first of all you're running on the JVM

00:30:15,039 --> 00:30:19,779
so you get like a humongous ecosystem of

00:30:17,200 --> 00:30:21,399
Java libraries readily available right

00:30:19,779 --> 00:30:23,049
in one of the demos which you know

00:30:21,399 --> 00:30:24,309
because of the GC that doesn't work with

00:30:23,049 --> 00:30:26,950
it and make it you can run actually

00:30:24,309 --> 00:30:28,870
discolor compiler on on the thing and

00:30:26,950 --> 00:30:30,070
show trees and print trees and so on and

00:30:28,870 --> 00:30:31,600
so you can just like you know you cannot

00:30:30,070 --> 00:30:34,929
run Scala compiler jack

00:30:31,600 --> 00:30:36,940
sorry it's not going to work and then

00:30:34,929 --> 00:30:39,190
you will get to a better performance

00:30:36,940 --> 00:30:42,010
right because your based on growl it's

00:30:39,190 --> 00:30:43,809
all alt compiled you get like a full JVM

00:30:42,010 --> 00:30:45,309
performance on your iPad so is it given

00:30:43,809 --> 00:30:46,840
you when you click on this app actually

00:30:45,309 --> 00:30:49,570
download such stuff from the internet

00:30:46,840 --> 00:30:51,220
over my phone so so it's kind of waiting

00:30:49,570 --> 00:30:55,660
for the messages but then you click on

00:30:51,220 --> 00:30:57,130
an app you just gotta know or hit which

00:30:55,660 --> 00:30:58,660
we've seen also with the micro service

00:30:57,130 --> 00:31:00,760
alright so you get better performance

00:30:58,660 --> 00:31:03,789
and faster startup and what needs to

00:31:00,760 --> 00:31:05,500
happen now on the on the JVM is like you

00:31:03,789 --> 00:31:06,730
know there is to be able community right

00:31:05,500 --> 00:31:11,320
you need to people started hacking

00:31:06,730 --> 00:31:13,539
itself up and making new libraries right

00:31:11,320 --> 00:31:15,190
and then it will be very better than

00:31:13,539 --> 00:31:18,250
react native right you'll get you know

00:31:15,190 --> 00:31:23,020
purely native app running fast with a

00:31:18,250 --> 00:31:24,429
better community and and you know Scala

00:31:23,020 --> 00:31:26,230
is an awesome language to start this

00:31:24,429 --> 00:31:28,390
right we've seen this before right there

00:31:26,230 --> 00:31:29,890
was this like Hadoop and then and then

00:31:28,390 --> 00:31:31,780
there was parked right and then spark

00:31:29,890 --> 00:31:33,490
was written in Scala I'm not like oh and

00:31:31,780 --> 00:31:35,860
then make of a million people like just

00:31:33,490 --> 00:31:37,720
talking us about spark around the world

00:31:35,860 --> 00:31:40,450
right there was the same stuffy doctor

00:31:37,720 --> 00:31:41,890
right there was a caca actors there were

00:31:40,450 --> 00:31:43,090
actors before but you know then our

00:31:41,890 --> 00:31:45,309
characters come and then it was like

00:31:43,090 --> 00:31:47,080
crazy scarlet let's find big libraries

00:31:45,309 --> 00:31:49,240
and then like all of the acai ecosystem

00:31:47,080 --> 00:31:53,470
was born right and a similar would play

00:31:49,240 --> 00:31:55,090
right and what I suggest to people that

00:31:53,470 --> 00:31:57,039
you don't want to start these projects I

00:31:55,090 --> 00:31:59,409
mean this this libraries like react

00:31:57,039 --> 00:32:01,179
native and flutter they all already

00:31:59,409 --> 00:32:02,740
developed all of these native components

00:32:01,179 --> 00:32:04,960
and they're all open source I think so I

00:32:02,740 --> 00:32:07,360
think people should just like borrow

00:32:04,960 --> 00:32:09,610
that on the JVM and can make a really

00:32:07,360 --> 00:32:13,990
nice library on top of it so that we can

00:32:09,610 --> 00:32:17,080
start an ecosystem on the JVM right yeah

00:32:13,990 --> 00:32:18,940
so yeah if you have free time just spawn

00:32:17,080 --> 00:32:20,380
a pet project you have a Gradle build

00:32:18,940 --> 00:32:23,169
start from there

00:32:20,380 --> 00:32:25,120
at the Scala plugin and there you go SBT

00:32:23,169 --> 00:32:25,900
plug-in you know slowly it starts you

00:32:25,120 --> 00:32:29,169
know how it goes

00:32:25,900 --> 00:32:31,990
it goes pretty fast and what there are

00:32:29,169 --> 00:32:34,090
next steps on this project we still

00:32:31,990 --> 00:32:35,850
don't support DC for iOS so if you swipe

00:32:34,090 --> 00:32:39,100
through this app a bit it will just like

00:32:35,850 --> 00:32:41,110
collect your windows so that's not

00:32:39,100 --> 00:32:42,820
that's like a vehicle to work it's not

00:32:41,110 --> 00:32:45,730
the problem we need to do running on

00:32:42,820 --> 00:32:47,290
Android that will take a problem

00:32:45,730 --> 00:32:48,820
what we need to do is we need to use a

00:32:47,290 --> 00:32:50,500
Java bytecode interpreter for

00:32:48,820 --> 00:32:52,870
development because at the moment you

00:32:50,500 --> 00:32:55,330
know - when I was compiling Scala

00:32:52,870 --> 00:32:58,540
Videla VM and a Java effects took a

00:32:55,330 --> 00:32:59,770
thousand seconds last night very funny

00:32:58,540 --> 00:33:01,480
it's all we need to put the Java

00:32:59,770 --> 00:33:03,310
interpreter so that that's one of the

00:33:01,480 --> 00:33:05,110
advantages of react is where as you

00:33:03,310 --> 00:33:06,880
develop you see your stop of stuff

00:33:05,110 --> 00:33:08,620
appearing we need to make the same thing

00:33:06,880 --> 00:33:10,990
happen so in the Java interpreter an

00:33:08,620 --> 00:33:12,520
iPad or an Android and you just need to

00:33:10,990 --> 00:33:14,530
ship your bytecode and see it right away

00:33:12,520 --> 00:33:16,120
and of course you need to do the support

00:33:14,530 --> 00:33:18,220
for Android but these are all details

00:33:16,120 --> 00:33:20,470
you know will take care of this it's

00:33:18,220 --> 00:33:21,940
time to start hacking on this basically

00:33:20,470 --> 00:33:24,130
right it's like it this will kind of

00:33:21,940 --> 00:33:25,930
fill in the beginning every project is

00:33:24,130 --> 00:33:29,490
not perfect but you know we'll be there

00:33:25,930 --> 00:33:33,070
really soon like half a year or so and

00:33:29,490 --> 00:33:35,010
you know this is kind of it I would like

00:33:33,070 --> 00:33:37,810
to give special thanks to Johann was and

00:33:35,010 --> 00:33:41,410
like who worked on this project we

00:33:37,810 --> 00:33:43,450
cannot did it together like is he did he

00:33:41,410 --> 00:33:45,490
will he's in glue on and essentially he

00:33:43,450 --> 00:33:47,410
worked to Java effects and it's this is

00:33:45,490 --> 00:33:48,640
this is the type of contributors that

00:33:47,410 --> 00:33:50,110
are best in the world

00:33:48,640 --> 00:33:52,120
it just says I want to contribute to

00:33:50,110 --> 00:33:54,190
these projects and then in basically in

00:33:52,120 --> 00:33:57,310
a couple of months you get you know all

00:33:54,190 --> 00:33:59,080
this pull requests actually for for his

00:33:57,310 --> 00:34:01,360
full request I mean the metaphor it was

00:33:59,080 --> 00:34:03,040
saying we need an automated like bot

00:34:01,360 --> 00:34:06,700
that merges four requests because this

00:34:03,040 --> 00:34:08,260
is not possible for me right so so I

00:34:06,700 --> 00:34:11,679
would like to give special thanks a lot

00:34:08,260 --> 00:34:13,419
of this work was basically his stuff and

00:34:11,679 --> 00:34:14,860
like who didn't LOV and back and you

00:34:13,419 --> 00:34:16,659
know master student straight from

00:34:14,860 --> 00:34:20,190
university just puts an elegy and back

00:34:16,659 --> 00:34:22,750
and it works pretty impressive right sir

00:34:20,190 --> 00:34:25,690
yeah so so to conclude

00:34:22,750 --> 00:34:28,899
basically you know I would just say two

00:34:25,690 --> 00:34:31,330
things don't waste energy time and money

00:34:28,899 --> 00:34:35,290
just put this on your on your Java class

00:34:31,330 --> 00:34:37,090
Java you know in your Java flags and you

00:34:35,290 --> 00:34:38,530
know it's time to start a new Communion

00:34:37,090 --> 00:34:40,870
and you community for cross-platform

00:34:38,530 --> 00:34:43,060
development and I think Scott you know

00:34:40,870 --> 00:34:45,190
Scala is the best place to start that

00:34:43,060 --> 00:34:47,290
and you should just start here it's this

00:34:45,190 --> 00:34:49,330
this link you follow it you can you know

00:34:47,290 --> 00:34:52,780
the same stuff you did here you can do

00:34:49,330 --> 00:34:54,610
on your iOS device right so and it's now

00:34:52,780 --> 00:34:55,899
time to start we are we are kind of done

00:34:54,610 --> 00:34:57,950
with the hard part now it's just

00:34:55,899 --> 00:35:08,960
cleaning stuff

00:34:57,950 --> 00:35:08,960
cool thank you it's not over yet

00:35:14,000 --> 00:35:20,190
I'll just answer with my son accordingly

00:35:16,770 --> 00:35:28,680
we should not mind so so they have any

00:35:20,190 --> 00:35:30,180
questions hello

00:35:28,680 --> 00:35:31,589
I'm pretty sure I saw you at the CEO

00:35:30,180 --> 00:35:33,630
conference it's good to see you again

00:35:31,589 --> 00:35:35,309
I'm working at sweater were using native

00:35:33,630 --> 00:35:37,109
image if you'll tell the kweli I talked

00:35:35,309 --> 00:35:39,150
yesterday there was a couple slides on

00:35:37,109 --> 00:35:40,980
how it's allowed us to essentially do

00:35:39,150 --> 00:35:42,420
remote compilations because we don't

00:35:40,980 --> 00:35:44,460
have to wait for a JVM to start up each

00:35:42,420 --> 00:35:46,109
time we want to invoke a compile on a

00:35:44,460 --> 00:35:46,950
different machine and that's very very

00:35:46,109 --> 00:35:48,569
nice

00:35:46,950 --> 00:35:50,549
and that's very cool and I appreciate

00:35:48,569 --> 00:35:53,640
that a lot I was at a specific question

00:35:50,549 --> 00:35:56,160
which was if I for example where to you

00:35:53,640 --> 00:35:57,510
know 100% black box re-implement pgo

00:35:56,160 --> 00:35:59,910
nephrons compression in native image

00:35:57,510 --> 00:36:01,079
would that be a copyright concern or

00:35:59,910 --> 00:36:04,440
would that be something that would be

00:36:01,079 --> 00:36:06,869
accepted by the girl project tough

00:36:04,440 --> 00:36:09,630
question thanks for asking so it's not

00:36:06,869 --> 00:36:11,220
easy to answer I don't think I don't

00:36:09,630 --> 00:36:15,029
think I'm in a position to answer I

00:36:11,220 --> 00:36:18,049
think these two particular things yeah I

00:36:15,029 --> 00:36:30,059
cannot I cannot answer this publicly

00:36:18,049 --> 00:36:31,890
yeah I yeah things in particular I think

00:36:30,059 --> 00:36:33,680
they're not so hard to do there is

00:36:31,890 --> 00:36:36,990
things which are very hard to do and

00:36:33,680 --> 00:36:40,230
these things are moderately hard right

00:36:36,990 --> 00:36:41,910
so so it would probably spawn a ton of

00:36:40,230 --> 00:36:43,890
discussion but there is a chance of this

00:36:41,910 --> 00:36:45,480
going through I would say it's really

00:36:43,890 --> 00:36:46,950
good here thank you very much there is a

00:36:45,480 --> 00:36:48,839
chance but you know I cannot of course

00:36:46,950 --> 00:36:50,520
I'm not completely not in a position to

00:36:48,839 --> 00:36:53,099
say it's just like my gut feeling

00:36:50,520 --> 00:36:55,260
because because it's not really you know

00:36:53,099 --> 00:36:56,760
it's it's not really the core thing

00:36:55,260 --> 00:36:59,039
which is hard which is we're keeping

00:36:56,760 --> 00:37:00,000
close sources yeah thank you for

00:36:59,039 --> 00:37:01,470
answering that it may have been a bit of

00:37:00,000 --> 00:37:03,270
an unfair question but really efficient

00:37:01,470 --> 00:37:04,770
unfair question but it's I give you my

00:37:03,270 --> 00:37:08,099
you know this is a completely personal

00:37:04,770 --> 00:37:10,880
answer a gut feeling yeah it's like

00:37:08,099 --> 00:37:10,880
thank you so much

00:37:11,160 --> 00:37:32,910
I didn't understand how the native image

00:37:29,510 --> 00:37:35,490
reduces your memory footprint uh-huh

00:37:32,910 --> 00:37:38,070
so how I did what what happens when you

00:37:35,490 --> 00:37:39,930
start to Java when you start Java it

00:37:38,070 --> 00:37:43,950
essentially does a lot of things it

00:37:39,930 --> 00:37:45,540
starts loading classes from disk which

00:37:43,950 --> 00:37:48,030
are kind of not in an optimal format

00:37:45,540 --> 00:37:50,250
Daniel then you start interpreting those

00:37:48,030 --> 00:37:52,110
classes right so you need an interpreter

00:37:50,250 --> 00:37:54,900
and an interpreter generates a ton of

00:37:52,110 --> 00:37:56,880
garbage and stuff then you need to

00:37:54,900 --> 00:37:57,540
profile that as well right so you need a

00:37:56,880 --> 00:37:59,610
profiler

00:37:57,540 --> 00:38:01,650
and you store all of these in memory for

00:37:59,610 --> 00:38:03,780
every method that you run then you need

00:38:01,650 --> 00:38:05,700
the c1 compiler which compiles so you

00:38:03,780 --> 00:38:09,180
could get faster warm up so you compile

00:38:05,700 --> 00:38:11,220
once and then after 10000 times you need

00:38:09,180 --> 00:38:12,780
a c2 compiler which compiles to a final

00:38:11,220 --> 00:38:15,240
version of your code which is optimal so

00:38:12,780 --> 00:38:17,760
you need you know two compilers one

00:38:15,240 --> 00:38:20,220
interpreter one profiler byte class

00:38:17,760 --> 00:38:21,720
loading and it's an open world so you

00:38:20,220 --> 00:38:23,550
can only you know it's all you know you

00:38:21,720 --> 00:38:25,380
don't know what's bears you can no need

00:38:23,550 --> 00:38:27,810
to keep like massive data structures for

00:38:25,380 --> 00:38:32,700
that right so that's essentially White's

00:38:27,810 --> 00:38:34,920
right yes yes that you can basically

00:38:32,700 --> 00:38:37,440
done in advance all you need to do is

00:38:34,920 --> 00:38:39,240
throw of a dynamic class loading right

00:38:37,440 --> 00:38:41,190
so you cannot download the jar from the

00:38:39,240 --> 00:38:44,310
internet and run it a native image right

00:38:41,190 --> 00:38:45,810
so this is exclude some things like SBT

00:38:44,310 --> 00:38:47,220
for example if you want a native image

00:38:45,810 --> 00:38:49,650
of that that's not possible right it

00:38:47,220 --> 00:38:51,420
will you know it will download plugins

00:38:49,650 --> 00:38:53,340
with different versions it becomes a

00:38:51,420 --> 00:38:55,590
combinatorial explosion of like jars

00:38:53,340 --> 00:38:57,960
that you need right but if you have your

00:38:55,590 --> 00:39:01,290
microservice if you have your command

00:38:57,960 --> 00:39:03,210
line tool if you have a mobile app fine

00:39:01,290 --> 00:39:05,360
yeah you just put these jars on the

00:39:03,210 --> 00:39:12,530
classpath you do a bit of configuration

00:39:05,360 --> 00:39:12,530
and you're done Thanks good question

00:39:23,900 --> 00:39:27,900
really quickly I don't necessarily know

00:39:26,010 --> 00:39:29,130
about SPT specifically but we've in

00:39:27,900 --> 00:39:31,110
pants have been able to generate nated

00:39:29,130 --> 00:39:32,670
images dynamically from the jars we've

00:39:31,110 --> 00:39:33,960
downloaded it and then built into new

00:39:32,670 --> 00:39:35,310
images so definitely dynamic class

00:39:33,960 --> 00:39:36,750
letting you know definitely isn't there

00:39:35,310 --> 00:39:37,980
intentionally but we've been able to

00:39:36,750 --> 00:39:41,780
work around that at the build tool level

00:39:37,980 --> 00:39:41,780
so it actually is potentially possible

00:39:44,840 --> 00:39:50,430
you could make a scholar compiler for

00:39:47,340 --> 00:39:52,020
your macros and your project and do pgo

00:39:50,430 --> 00:39:53,790
on top of it you would get the Scala

00:39:52,020 --> 00:39:56,220
compiler that's faster than a hot spot

00:39:53,790 --> 00:39:58,290
and starts immediately doing that's what

00:39:56,220 --> 00:39:59,850
we need that's funny 18 holidays

00:39:58,290 --> 00:40:01,620
presentation about Ravi and we're using

00:39:59,850 --> 00:40:02,970
that directly so thank you whoever did

00:40:01,620 --> 00:40:04,470
that for the doing the hard work yes I

00:40:02,970 --> 00:40:06,000
was hoping last year when I gave a

00:40:04,470 --> 00:40:06,770
presentation this will happen and you'll

00:40:06,000 --> 00:40:12,330
see voila

00:40:06,770 --> 00:40:15,990
Oh amazing Thanks a short question I

00:40:12,330 --> 00:40:19,350
didn't stand wise to Corral irritation

00:40:15,990 --> 00:40:21,900
slower you're sorry then the C Edition

00:40:19,350 --> 00:40:24,540
is just some optimizations which are not

00:40:21,900 --> 00:40:26,460
active or yeah there's a lot of

00:40:24,540 --> 00:40:28,320
optimizations in enterprise right that

00:40:26,460 --> 00:40:31,950
are not active and and they're not easy

00:40:28,320 --> 00:40:35,480
to do it's like yeah it's a lot of

00:40:31,950 --> 00:40:35,480
optimizations right yes

00:40:48,500 --> 00:40:54,390
so no more questions here thank you very

00:40:52,410 --> 00:41:03,780
much once again

00:40:54,390 --> 00:41:03,780

YouTube URL: https://www.youtube.com/watch?v=cdYmr_rQ94I


