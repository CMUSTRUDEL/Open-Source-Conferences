Title: Distributed Real Time Stream Processing: Why and How by Petr Zapletal
Publication date: 2016-06-29
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.

In this talk, we are going to discuss various state of the art open-source distributed streaming frameworks, their similarities and differences, implementation trade-offs, their intended use-cases, and how to choose between them. Iâ€™m going to focus on the popular frameworks including Spark Streaming, Storm, Samza and Flink. In addition, I'll cover theoretical introduction, common pitfalls, popular architectures and many more.
The demand for stream processing is increasing. Immense amounts of data has to be processed fast from a rapidly growing set of disparate data sources. This pushes the limits of traditional data processing infrastructures. These stream-based applications include trading, social networks, Internet of things or system monitoring, are becoming more and more important. A number of powerful, easy-to-use open source platforms have emerged to address this. My goal is to provide comprehensive overview about modern streaming solutions and to help fellow developers with picking the best possible decision for their particular use-case. This talk should be interesting for anyone who is thinking about, implementing, or have already deployed streaming solution.
Captions: 
	00:00:10,040 --> 00:00:16,290
so hello everybody I hope you enjoy your

00:00:13,500 --> 00:00:18,840
lunches and my name is Peter and I work

00:00:16,290 --> 00:00:20,820
for cake solutions rock concert owns a

00:00:18,840 --> 00:00:23,550
company focusing on building reactive

00:00:20,820 --> 00:00:26,880
and data processing applications using

00:00:23,550 --> 00:00:30,030
technologies such as scar like a spark

00:00:26,880 --> 00:00:33,090
and many others in this presentation I

00:00:30,030 --> 00:00:35,129
won't talk about trains this prepare for

00:00:33,090 --> 00:00:39,300
next sessions but I'm going to talk

00:00:35,129 --> 00:00:40,860
about distributed stream processing this

00:00:39,300 --> 00:00:44,729
area attracts quite old owner of

00:00:40,860 --> 00:00:49,050
attention these days and I believe we

00:00:44,729 --> 00:00:51,330
will find x 45 minutes interesting so

00:00:49,050 --> 00:00:53,850
what am I going to talk about I'll

00:00:51,330 --> 00:00:55,470
starve a short introduction where are

00:00:53,850 --> 00:00:58,220
the reasons behind this increasing

00:00:55,470 --> 00:01:02,760
demand for real-time data processing and

00:00:58,220 --> 00:01:05,909
how to address it dan I'm going to talk

00:01:02,760 --> 00:01:09,720
about stream processing in general why

00:01:05,909 --> 00:01:12,530
do we care why should we care and we

00:01:09,720 --> 00:01:14,670
rather typical use cases we can expect

00:01:12,530 --> 00:01:16,860
after that I like to talk about

00:01:14,670 --> 00:01:18,960
available frameworks would rather

00:01:16,860 --> 00:01:22,320
similarities and differences and also

00:01:18,960 --> 00:01:24,240
their typical use cases finally we will

00:01:22,320 --> 00:01:27,480
conclude with general guidelines and

00:01:24,240 --> 00:01:29,520
recommendations I like to say this talk

00:01:27,480 --> 00:01:32,220
is based on my personal observation and

00:01:29,520 --> 00:01:34,520
opinions and I'm definitely biased in

00:01:32,220 --> 00:01:34,520
some way

00:01:37,870 --> 00:01:42,850
huge amounts of data has to be put as

00:01:40,540 --> 00:01:45,490
fast from a rapidly growing set of

00:01:42,850 --> 00:01:48,850
display data sources like trading

00:01:45,490 --> 00:01:52,450
trading social networks IOT system

00:01:48,850 --> 00:01:54,040
monitoring and so on and this pushes the

00:01:52,450 --> 00:01:55,810
limits of the traditional batch

00:01:54,040 --> 00:01:59,380
processing infrastructures which are

00:01:55,810 --> 00:02:02,830
often simply not good enough and stream

00:01:59,380 --> 00:02:04,600
processing might be a good way to go we

00:02:02,830 --> 00:02:07,150
want to process incoming data on the fly

00:02:04,600 --> 00:02:10,920
and we want to react to events as they

00:02:07,150 --> 00:02:13,540
occur as the latency or the matters here

00:02:10,920 --> 00:02:16,030
as you suspect distributed stream

00:02:13,540 --> 00:02:18,640
processing is continuous continuous

00:02:16,030 --> 00:02:21,010
processing aggregation and analysis of

00:02:18,640 --> 00:02:23,500
our MIDI data it is general

00:02:21,010 --> 00:02:26,760
computational model as MapReduce but we

00:02:23,500 --> 00:02:29,320
expect latencies in malice or in seconds

00:02:26,760 --> 00:02:32,730
these systems are usually model as

00:02:29,320 --> 00:02:35,440
directed acyclic graph the AGS or bags

00:02:32,730 --> 00:02:38,050
that is a graphical representation of

00:02:35,440 --> 00:02:41,980
chain of task and we use it for

00:02:38,050 --> 00:02:44,290
description of streaming job I will help

00:02:41,980 --> 00:02:45,940
myself with terminology from a customs

00:02:44,290 --> 00:02:50,470
little bit to make more descriptive but

00:02:45,940 --> 00:02:52,270
I'm sure it will be fine anyway so as

00:02:50,470 --> 00:02:54,250
you can see the picture data flows

00:02:52,270 --> 00:02:57,040
through chain of processors from sources

00:02:54,250 --> 00:02:59,470
to things and which would represent the

00:02:57,040 --> 00:03:01,360
streaming task and speaking about acha

00:02:59,470 --> 00:03:04,540
streams I think it's very important to

00:03:01,360 --> 00:03:06,730
emphasize the word distribute it because

00:03:04,540 --> 00:03:09,489
even local solution can create an exact

00:03:06,730 --> 00:03:13,290
but we are going to focus only two

00:03:09,489 --> 00:03:13,290
solutions running on multiple machines

00:03:13,709 --> 00:03:18,310
when choosing between different systems

00:03:16,060 --> 00:03:20,470
there is a couple of points which would

00:03:18,310 --> 00:03:22,690
take care of so let's start with runtime

00:03:20,470 --> 00:03:24,940
and programming model the programming

00:03:22,690 --> 00:03:26,800
model provided by platforms determines a

00:03:24,940 --> 00:03:28,780
lot of its features and it should be

00:03:26,800 --> 00:03:31,630
sufficient to handle all possibilities

00:03:28,780 --> 00:03:33,100
cases for an application this is really

00:03:31,630 --> 00:03:36,459
crucial topic and I will come back to it

00:03:33,100 --> 00:03:38,470
very soon the functional primitives

00:03:36,459 --> 00:03:40,810
exposed by a framework should be or

00:03:38,470 --> 00:03:42,640
should be able to provide each

00:03:40,810 --> 00:03:45,250
functionalities at interval message

00:03:42,640 --> 00:03:47,799
levels like map or filter which are

00:03:45,250 --> 00:03:49,720
pretty easy to implement even if you

00:03:47,799 --> 00:03:51,319
want to scale out but it should also

00:03:49,720 --> 00:03:54,170
provide across messages from Charlotte

00:03:51,319 --> 00:03:56,749
a like aggregations and across stream

00:03:54,170 --> 00:04:00,530
operations like just for example which

00:03:56,749 --> 00:04:02,810
are much harder to scale and state

00:04:00,530 --> 00:04:04,639
management also the application have

00:04:02,810 --> 00:04:07,159
stayed for processing logic the

00:04:04,639 --> 00:04:08,840
recruitment angle state the platform

00:04:07,159 --> 00:04:12,530
should add us to maintain access and

00:04:08,840 --> 00:04:14,450
update the state information for message

00:04:12,530 --> 00:04:16,970
over gravity's we have a couple of

00:04:14,450 --> 00:04:19,130
glasses like at most once at least once

00:04:16,970 --> 00:04:23,210
and exactly once an important thing to

00:04:19,130 --> 00:04:25,550
consider Phillips can and will happen at

00:04:23,210 --> 00:04:27,620
various levels like little partitions

00:04:25,550 --> 00:04:30,259
disk failures or nodes green down and so

00:04:27,620 --> 00:04:31,610
on and our platform should be able to

00:04:30,259 --> 00:04:33,979
recover from all such failures and

00:04:31,610 --> 00:04:37,849
resume from their last successful state

00:04:33,979 --> 00:04:39,710
before harming the result and then we

00:04:37,849 --> 00:04:42,949
have more performance rating

00:04:39,710 --> 00:04:44,750
requirements like latency throughput and

00:04:42,949 --> 00:04:48,470
scalability which are extremely

00:04:44,750 --> 00:04:50,120
important in streaming applications we

00:04:48,470 --> 00:04:52,610
should also take care of maturity and

00:04:50,120 --> 00:04:54,949
adoption level this information could

00:04:52,610 --> 00:04:57,830
give us a clue about potential support

00:04:54,949 --> 00:05:00,880
available libraries or even stackable

00:04:57,830 --> 00:05:04,250
stack overflow answers and so on and

00:05:00,880 --> 00:05:06,289
also last but at least the ease of

00:05:04,250 --> 00:05:08,270
development and ease of a probability

00:05:06,289 --> 00:05:10,580
it's great when we have like a super

00:05:08,270 --> 00:05:12,889
fancy fat platform which covers over

00:05:10,580 --> 00:05:14,690
whose cases but if we cannot buy the

00:05:12,889 --> 00:05:19,159
program for it or if we cannot deploy it

00:05:14,690 --> 00:05:21,080
we have done anyway so let's talk about

00:05:19,159 --> 00:05:23,509
runtime and programming model which is

00:05:21,080 --> 00:05:26,139
probably the most important trait of the

00:05:23,509 --> 00:05:28,460
system because it defines expressiveness

00:05:26,139 --> 00:05:30,440
possible operations and future

00:05:28,460 --> 00:05:34,639
limitations therefore it defines them

00:05:30,440 --> 00:05:36,860
capabilities and its use cases there are

00:05:34,639 --> 00:05:39,169
two distinct approaches how to implement

00:05:36,860 --> 00:05:41,240
streaming system first one native

00:05:39,169 --> 00:05:43,849
streaming it means only common records

00:05:41,240 --> 00:05:48,139
or events if you want our process us

00:05:43,849 --> 00:05:51,050
derive one by one second approach is

00:05:48,139 --> 00:05:53,870
called micro batching sure batches are

00:05:51,050 --> 00:05:55,669
created from incoming records and go

00:05:53,870 --> 00:05:57,770
through the system these batches are

00:05:55,669 --> 00:05:59,719
created according to predefine time

00:05:57,770 --> 00:06:04,130
constant typically every couple of

00:05:59,719 --> 00:06:05,160
seconds both approaches have inherent

00:06:04,130 --> 00:06:07,940
advantages and

00:06:05,160 --> 00:06:10,500
70 G's so let's start native streaming

00:06:07,940 --> 00:06:12,780
the great advantage of relative

00:06:10,500 --> 00:06:15,060
streaming this is expressiveness because

00:06:12,780 --> 00:06:16,830
it takes a stream as a test is not

00:06:15,060 --> 00:06:20,040
limited by any unnatural abstraction

00:06:16,830 --> 00:06:22,470
over it also other records are processed

00:06:20,040 --> 00:06:24,360
immediately arrival achieved latencies

00:06:22,470 --> 00:06:27,690
of these systems are always better than

00:06:24,360 --> 00:06:29,760
its micro batching companions apart from

00:06:27,690 --> 00:06:31,770
that estate pool operations are much

00:06:29,760 --> 00:06:34,170
easier in Poland as you will see next

00:06:31,770 --> 00:06:37,020
couple minutes native streaming system

00:06:34,170 --> 00:06:39,570
have usually lower throughput and photo

00:06:37,020 --> 00:06:43,530
runs is much more expensive as it has to

00:06:39,570 --> 00:06:45,740
take care of every single record also in

00:06:43,530 --> 00:06:48,120
Lansing this kind of issue for example

00:06:45,740 --> 00:06:49,890
let's say we have a data partition by

00:06:48,120 --> 00:06:52,200
the key and we want to process it if

00:06:49,890 --> 00:06:54,240
reprocessing of some QT partition is

00:06:52,200 --> 00:06:56,640
more resource intensive for any reason

00:06:54,240 --> 00:07:02,250
this partition quickly becomes jobs

00:06:56,640 --> 00:07:04,170
bottleneck spitting streams into micro

00:07:02,250 --> 00:07:06,480
batches inevitable reduces 6m

00:07:04,170 --> 00:07:08,130
expressiveness some operations

00:07:06,480 --> 00:07:10,200
especially state management or juniors

00:07:08,130 --> 00:07:12,290
plates are much higher to implement a

00:07:10,200 --> 00:07:15,450
system has to manipulate whole batch

00:07:12,290 --> 00:07:17,250
moreover the batch interval connects two

00:07:15,450 --> 00:07:19,590
things or two words which should never

00:07:17,250 --> 00:07:23,150
be connected and infrastructure property

00:07:19,590 --> 00:07:26,460
and business logic on the contrary

00:07:23,150 --> 00:07:28,650
torrance is much simpler as system just

00:07:26,460 --> 00:07:30,840
sends everywhere every batch to workload

00:07:28,650 --> 00:07:33,180
and if something goes wrong it can just

00:07:30,840 --> 00:07:35,640
use a different one lastly it's good to

00:07:33,180 --> 00:07:37,560
remark we can build budget microbe

00:07:35,640 --> 00:07:41,640
microbe etching system atop native

00:07:37,560 --> 00:07:43,410
streaming quite easily programming

00:07:41,640 --> 00:07:44,900
models can be classified as

00:07:43,410 --> 00:07:46,770
compositional and declarative

00:07:44,900 --> 00:07:48,840
composition approach provides basic

00:07:46,770 --> 00:07:51,419
building blocks like sources or pages

00:07:48,840 --> 00:07:53,580
and they must be tied together in order

00:07:51,419 --> 00:07:55,169
to create expected to poach a new

00:07:53,580 --> 00:07:58,080
components are usually defined by

00:07:55,169 --> 00:08:00,510
implementing some kind of interfaces on

00:07:58,080 --> 00:08:03,270
the contrary operators in the Celtic API

00:08:00,510 --> 00:08:05,640
and refined as higher order function it

00:08:03,270 --> 00:08:08,940
loves us to write function code with all

00:08:05,640 --> 00:08:11,510
its fancy stuff love and the system

00:08:08,940 --> 00:08:14,280
creates and optimizes to Porsche itself

00:08:11,510 --> 00:08:16,860
also recruited ap is usually provides

00:08:14,280 --> 00:08:19,330
more advanced operations like windowing

00:08:16,860 --> 00:08:21,860
or state measurement out of the

00:08:19,330 --> 00:08:25,610
I'm going to show you some code samples

00:08:21,860 --> 00:08:27,650
very very soon there's a number of

00:08:25,610 --> 00:08:30,590
diverse members available and is it

00:08:27,650 --> 00:08:32,960
highly impossible to cover them and just

00:08:30,590 --> 00:08:34,640
one session so I have been forced to

00:08:32,960 --> 00:08:36,950
endure it somehow and I decide to go for

00:08:34,640 --> 00:08:40,070
pop racemic solutions from apache

00:08:36,950 --> 00:08:42,500
landscape therefore we are going to

00:08:40,070 --> 00:08:44,930
focus on apache storm and its sibling

00:08:42,500 --> 00:08:48,440
trident and on streaming module or very

00:08:44,930 --> 00:08:50,780
proposed Park we are also going to talk

00:08:48,440 --> 00:08:53,000
about streaming system behind link in

00:08:50,780 --> 00:08:54,700
name thumbs up and we are going to

00:08:53,000 --> 00:08:59,210
discuss two premiership Apache project

00:08:54,700 --> 00:09:01,550
apex and fling I believe this is a great

00:08:59,210 --> 00:09:03,890
selection because even all of them are

00:09:01,550 --> 00:09:06,010
streaming systems they do approach by

00:09:03,890 --> 00:09:08,030
those challenges very differently

00:09:06,010 --> 00:09:10,880
unfortunately i won't talk about

00:09:08,030 --> 00:09:13,760
proprietary streaming system like google

00:09:10,880 --> 00:09:15,110
mobile or amazon kinesis and also

00:09:13,760 --> 00:09:16,670
they're going to miss interesting but

00:09:15,110 --> 00:09:19,820
still limited editing system like my

00:09:16,670 --> 00:09:26,360
beloved Intel GD bump so that's maybe

00:09:19,820 --> 00:09:28,700
for for next time i purchased storm was

00:09:26,360 --> 00:09:31,370
originally created but Nathan marks and

00:09:28,700 --> 00:09:33,230
his teammate back type and 2010 all I

00:09:31,370 --> 00:09:35,270
did was it was a quiet and pursues by

00:09:33,230 --> 00:09:39,200
Twitter and it became Apache total

00:09:35,270 --> 00:09:40,820
project in 2014 if of any depth stone

00:09:39,200 --> 00:09:43,100
was a pioneer in large kids in

00:09:40,820 --> 00:09:46,070
processing and became the factor

00:09:43,100 --> 00:09:48,350
industrial standard storm is a native

00:09:46,070 --> 00:09:52,010
streaming system and provides very loyal

00:09:48,350 --> 00:09:56,540
API also system uses for it for tubidy

00:09:52,010 --> 00:09:58,520
definition and and it also implements

00:09:56,540 --> 00:09:59,800
torment of each protocol and is

00:09:58,520 --> 00:10:02,270
basically allows us to implement

00:09:59,800 --> 00:10:04,540
absolution or application a large number

00:10:02,270 --> 00:10:09,740
of languages which is pretty unique and

00:10:04,540 --> 00:10:11,570
color is of course one of them Triton is

00:10:09,740 --> 00:10:14,390
a high-level micro budgeting system bill

00:10:11,570 --> 00:10:16,640
atop storm it simplifies to pooja

00:10:14,390 --> 00:10:18,890
billing process and also adds high level

00:10:16,640 --> 00:10:20,750
operations like when doing aggregation

00:10:18,890 --> 00:10:23,810
or state management which are not

00:10:20,750 --> 00:10:25,880
natively supported and storm in addition

00:10:23,810 --> 00:10:29,490
to storm kind of provides exactly month

00:10:25,880 --> 00:10:33,390
delivery traded has java cruz and scott

00:10:29,490 --> 00:10:34,830
eyes as we all know this part is a very

00:10:33,390 --> 00:10:36,930
popular batch processing frame of these

00:10:34,830 --> 00:10:39,630
days if a couple of building libraries

00:10:36,930 --> 00:10:42,750
like sparks equal Anna lip and of course

00:10:39,630 --> 00:10:44,940
spark streaming spark streaming is built

00:10:42,750 --> 00:10:47,070
for batch processing and therefore spark

00:10:44,940 --> 00:10:50,459
streaming as it was added a little bit

00:10:47,070 --> 00:10:52,649
lighter does Micro batch the stream of

00:10:50,459 --> 00:10:54,570
input data is ingested by receivers

00:10:52,649 --> 00:10:57,330
which creates micro batches and these

00:10:54,570 --> 00:11:00,810
micro batches are processed in a similar

00:10:57,330 --> 00:11:03,779
way as I disparage jobs spark streaming

00:11:00,810 --> 00:11:08,730
provides a level necrotic API and Colour

00:11:03,779 --> 00:11:10,050
java and buy me some that was originally

00:11:08,730 --> 00:11:12,510
developed in lincoln as a proprietary

00:11:10,050 --> 00:11:14,430
streaming solution and with Kafka which

00:11:12,510 --> 00:11:16,800
is add a great Lincoln's contribution to

00:11:14,430 --> 00:11:19,589
our community it became key part of

00:11:16,800 --> 00:11:21,270
their infrastructure as we are going to

00:11:19,589 --> 00:11:23,279
see a little bit later sums up builds

00:11:21,270 --> 00:11:26,089
heavily on cough castle basis of a and

00:11:23,279 --> 00:11:28,350
both together enjoy grace real well and

00:11:26,089 --> 00:11:34,110
also some that provides compositional

00:11:28,350 --> 00:11:37,079
API apex is a hydrophobic streaming

00:11:34,110 --> 00:11:38,940
system back by x0 engineers right now it

00:11:37,079 --> 00:11:42,720
provides compositional API force color

00:11:38,940 --> 00:11:44,310
and Java but you can also use a visual

00:11:42,720 --> 00:11:47,220
tool to assemble application which is

00:11:44,310 --> 00:11:50,940
kind of nice also high level AP ice is

00:11:47,220 --> 00:11:52,950
under preparation / construction apex

00:11:50,940 --> 00:11:56,040
also comes with a rich library of

00:11:52,950 --> 00:11:57,779
operators named mehar as i'm going to

00:11:56,040 --> 00:11:59,610
show you it a little bit lighter apex

00:11:57,779 --> 00:12:01,500
implements interesting compromise

00:11:59,610 --> 00:12:06,029
between native streaming and micro

00:12:01,500 --> 00:12:08,670
batching and last but not least blank

00:12:06,029 --> 00:12:11,310
blank is prettier projects it has its

00:12:08,670 --> 00:12:13,500
origin in 2008 but right now it's

00:12:11,310 --> 00:12:15,300
getting federal detention Frank is

00:12:13,500 --> 00:12:19,050
native streaming systems and provides

00:12:15,300 --> 00:12:22,500
high level API clean also provides API

00:12:19,050 --> 00:12:23,790
for batch processing like spark but

00:12:22,500 --> 00:12:26,399
there is a fundamental distinction

00:12:23,790 --> 00:12:28,290
between those two fring handles badge as

00:12:26,399 --> 00:12:30,149
a special case of streaming so basically

00:12:28,290 --> 00:12:31,500
everything is a stream and this is at

00:12:30,149 --> 00:12:33,300
least from my point of view definite is

00:12:31,500 --> 00:12:37,770
a better abstraction because this is how

00:12:33,300 --> 00:12:40,290
the world really looks like so it was a

00:12:37,770 --> 00:12:41,990
quick interaction of the systems and as

00:12:40,290 --> 00:12:44,180
you can see the table

00:12:41,990 --> 00:12:47,240
you have pretty different rates and now

00:12:44,180 --> 00:12:49,490
let's take a look at code samples and of

00:12:47,240 --> 00:12:52,279
course nothing is more important than

00:12:49,490 --> 00:12:55,100
counting words you know what count is

00:12:52,279 --> 00:12:59,390
something like hell worth of data

00:12:55,100 --> 00:13:00,920
processing torrential storm and please

00:12:59,390 --> 00:13:04,430
note the example was simplified

00:13:00,920 --> 00:13:06,980
significantly first let's take a look at

00:13:04,430 --> 00:13:09,020
it the body definition as you can see we

00:13:06,980 --> 00:13:11,660
have to define a spot or if you want a

00:13:09,020 --> 00:13:14,089
source and then there's a boat a

00:13:11,660 --> 00:13:16,279
processing component which splits text

00:13:14,089 --> 00:13:19,940
into the words then I have to find

00:13:16,279 --> 00:13:23,779
another boat for actual computation also

00:13:19,940 --> 00:13:26,959
take a look at the magic numbers 5 8 and

00:13:23,779 --> 00:13:29,330
12 these are the parents and they

00:13:26,959 --> 00:13:31,220
defined how many independent frets

00:13:29,330 --> 00:13:33,770
another cluster will be used for

00:13:31,220 --> 00:13:36,830
execution of every single compliant so

00:13:33,770 --> 00:13:40,640
as you can see always very manual and a

00:13:36,830 --> 00:13:44,750
level let's focus now how is the actual

00:13:40,640 --> 00:13:47,480
word count both implemented as long as

00:13:44,750 --> 00:13:50,329
storm doesn't have any support for many

00:13:47,480 --> 00:13:52,459
states so I have to find a local state

00:13:50,329 --> 00:13:55,940
which is far from buying ideal but good

00:13:52,459 --> 00:13:58,279
as a sample apart from that is not very

00:13:55,940 --> 00:14:01,579
interesting so wasn't phone and take a

00:13:58,279 --> 00:14:03,829
look at right hand as i mentioned before

00:14:01,579 --> 00:14:06,890
trial in a store micro batching

00:14:03,829 --> 00:14:09,740
extension and trident apart from many

00:14:06,890 --> 00:14:13,279
other goodies provides data management

00:14:09,740 --> 00:14:17,329
which is kind of useful i'm implementing

00:14:13,279 --> 00:14:19,130
core count as you can see i could use

00:14:17,329 --> 00:14:22,490
high load operations like each and group

00:14:19,130 --> 00:14:24,500
by so it is little bit better and also i

00:14:22,490 --> 00:14:28,630
was able to try to manage state for

00:14:24,500 --> 00:14:32,120
storing counts and now is the time for

00:14:28,630 --> 00:14:35,450
pretty lucrative api provided by apache

00:14:32,120 --> 00:14:37,279
spark also keep in mind the contrary to

00:14:35,450 --> 00:14:39,320
previous examples which readily

00:14:37,279 --> 00:14:41,570
simplified this is nearly all code you

00:14:39,320 --> 00:14:45,200
need to run this simple streaming word

00:14:41,570 --> 00:14:48,020
count every sparks Lemondrop require

00:14:45,200 --> 00:14:49,339
streaming context which is basically an

00:14:48,020 --> 00:14:51,920
entry point to the streaming

00:14:49,339 --> 00:14:53,810
functionality streaming come tanks takes

00:14:51,920 --> 00:14:55,059
a configuration which is as you can see

00:14:53,810 --> 00:14:57,609
in our case

00:14:55,059 --> 00:15:00,369
we're limited but more importantly it

00:14:57,609 --> 00:15:05,379
defines its batch interval which is set

00:15:00,369 --> 00:15:08,289
to one second and now you can see a

00:15:05,379 --> 00:15:10,299
whole world come computation apparently

00:15:08,289 --> 00:15:12,009
it's a quite a difference and that the

00:15:10,299 --> 00:15:14,949
reason why spark is sometime called

00:15:12,009 --> 00:15:16,949
distributed color as you can see it's

00:15:14,949 --> 00:15:20,829
quite standard functional code and

00:15:16,949 --> 00:15:25,479
politics care of topology definition and

00:15:20,829 --> 00:15:27,879
it's distributed execution and now the

00:15:25,479 --> 00:15:30,729
last part of every spark streaming job

00:15:27,879 --> 00:15:34,289
sat in the computation just keep in mind

00:15:30,729 --> 00:15:37,839
once that the job cannot be modified and

00:15:34,289 --> 00:15:40,329
now let's take a look at apache Sansa

00:15:37,839 --> 00:15:43,449
another representative of compositional

00:15:40,329 --> 00:15:45,849
API the topology is defined in some such

00:15:43,449 --> 00:15:49,569
properties file so you won't find you

00:15:45,849 --> 00:15:51,309
here but for us it's important the task

00:15:49,569 --> 00:15:53,469
has defined input and output channels

00:15:51,309 --> 00:15:56,079
and communication goes through Kafka's

00:15:53,469 --> 00:16:00,039
topics in our case the whole topology is

00:15:56,079 --> 00:16:02,499
work on task we just all the work in

00:16:00,039 --> 00:16:05,199
some time components are defined by

00:16:02,499 --> 00:16:07,239
implementing some or some particle

00:16:05,199 --> 00:16:09,699
interfaces in this case it's a stream

00:16:07,239 --> 00:16:12,849
task and I have just overdone method

00:16:09,699 --> 00:16:15,729
process its premiere these constraints

00:16:12,849 --> 00:16:19,569
always need for connecting with the rest

00:16:15,729 --> 00:16:25,059
of your system and the competition

00:16:19,569 --> 00:16:27,879
itself just a simple scar and now it's

00:16:25,059 --> 00:16:29,739
time to take a look at Apache I pegs as

00:16:27,879 --> 00:16:31,809
you can see it's a classic convolutional

00:16:29,739 --> 00:16:36,159
API and again the slip pad was

00:16:31,809 --> 00:16:39,039
simplified first we have to define just

00:16:36,159 --> 00:16:43,419
apology we have to add components to DAC

00:16:39,039 --> 00:16:44,949
and connect them with strings and then

00:16:43,419 --> 00:16:46,929
use the definition of one of the

00:16:44,949 --> 00:16:50,679
components this one splits incoming

00:16:46,929 --> 00:16:56,079
strings the code is excelled is pretty

00:16:50,679 --> 00:16:59,259
crater I guess and now let's take a look

00:16:56,079 --> 00:17:01,869
at flank as you can see API is pretty

00:16:59,259 --> 00:17:05,100
similar spark swimming but notice we are

00:17:01,869 --> 00:17:07,059
not setting any large interval

00:17:05,100 --> 00:17:08,350
computational itself is pretty

00:17:07,059 --> 00:17:09,730
straightforward

00:17:08,350 --> 00:17:16,750
there's just a couple of function calls

00:17:09,730 --> 00:17:18,850
and flings takes care of the rest and

00:17:16,750 --> 00:17:20,380
now it's a time to take a look at more

00:17:18,850 --> 00:17:23,890
interesting problems of stream

00:17:20,380 --> 00:17:25,929
processing starting with 420 runs for

00:17:23,890 --> 00:17:29,470
torrents and stream processing is

00:17:25,929 --> 00:17:31,750
enhance the harder than in badge when

00:17:29,470 --> 00:17:35,140
facing an error in batch processing

00:17:31,750 --> 00:17:38,500
system we can just rest are part of the

00:17:35,140 --> 00:17:40,240
computation and we are good but this is

00:17:38,500 --> 00:17:42,340
much harder in streaming scenarios

00:17:40,240 --> 00:17:47,020
because data are still in coming and

00:17:42,340 --> 00:17:49,000
love jobs can and 24 7 and our challenge

00:17:47,020 --> 00:17:51,070
we have to face a state consistency

00:17:49,000 --> 00:17:55,030
because in the end of the day we have to

00:17:51,070 --> 00:17:58,240
start applying events and of course not

00:17:55,030 --> 00:18:00,789
all state operations are ID important as

00:17:58,240 --> 00:18:02,830
you will see photons can be pretty hard

00:18:00,789 --> 00:18:09,490
so let's take a look how about systems

00:18:02,830 --> 00:18:11,530
deal with that storm uses a mechanism of

00:18:09,490 --> 00:18:13,870
upstream backup and recovery key

00:18:11,530 --> 00:18:15,750
knowledge meant to grantee the messages

00:18:13,870 --> 00:18:18,720
are reprocess after a failure

00:18:15,750 --> 00:18:20,470
acknowledgement work as follows

00:18:18,720 --> 00:18:23,169
operators and back through previous

00:18:20,470 --> 00:18:24,720
operator and acknowledgement that for

00:18:23,169 --> 00:18:27,070
every recorded has been processed and

00:18:24,720 --> 00:18:29,260
the source of the topology keeps a

00:18:27,070 --> 00:18:31,840
backup of all across a generous one

00:18:29,260 --> 00:18:34,570
receive acknowledgement from automated

00:18:31,840 --> 00:18:38,650
records under those things wake up can

00:18:34,570 --> 00:18:41,710
be discarded safely at failure if not

00:18:38,650 --> 00:18:49,240
all acknowledgments are collected or

00:18:41,710 --> 00:18:51,100
received just met then your records are

00:18:49,240 --> 00:18:53,320
applied by the source this grant is

00:18:51,100 --> 00:18:55,929
Nolita loss by just result in duplicate

00:18:53,320 --> 00:18:59,049
record passing for the system that's at

00:18:55,929 --> 00:19:01,270
least one delivery store implements this

00:18:59,049 --> 00:19:03,730
recover mechanism of upstream backup and

00:19:01,270 --> 00:19:05,530
recovery which requires only couple

00:19:03,730 --> 00:19:08,679
bites of storage per source to track the

00:19:05,530 --> 00:19:10,150
records of the acknowledgments pure

00:19:08,679 --> 00:19:12,640
record acknowledgement architectures

00:19:10,150 --> 00:19:15,190
regardless of that performance fell in

00:19:12,640 --> 00:19:17,020
offering exactly ones grantees tues

00:19:15,190 --> 00:19:18,670
burdening application developer with the

00:19:17,020 --> 00:19:21,740
duplication

00:19:18,670 --> 00:19:24,050
also strong mechanism is a fruit boot

00:19:21,740 --> 00:19:25,820
has problems with full control us

00:19:24,050 --> 00:19:29,390
acknowledgement mechanism often falsely

00:19:25,820 --> 00:19:33,650
classifies color failures and the back

00:19:29,390 --> 00:19:35,510
pressure sparks streaming and its micro

00:19:33,650 --> 00:19:38,480
batching semantics follow a different

00:19:35,510 --> 00:19:40,970
approach the idea is terribly simple

00:19:38,480 --> 00:19:44,300
spark process micro batches on various

00:19:40,970 --> 00:19:47,390
worker nodes and each micro batch major

00:19:44,300 --> 00:19:49,190
succeed or fail at a failure the micro

00:19:47,390 --> 00:19:52,700
batch can be simply computed as they are

00:19:49,190 --> 00:19:56,470
or peasant stamp and immutable so

00:19:52,700 --> 00:19:58,850
exactly once the very made easy

00:19:56,470 --> 00:20:01,040
sometimes approach is completely

00:19:58,850 --> 00:20:03,590
different it takes an advantage of

00:20:01,040 --> 00:20:05,750
offset based measuring systems it's

00:20:03,590 --> 00:20:08,420
usually or maybe of always cough cough

00:20:05,750 --> 00:20:11,240
course and some summary toes offset of

00:20:08,420 --> 00:20:14,060
this task and movie when message is

00:20:11,240 --> 00:20:16,310
processed office can be reported in a

00:20:14,060 --> 00:20:19,880
persistent storage and restored in case

00:20:16,310 --> 00:20:21,290
of failure the problem is when in

00:20:19,880 --> 00:20:23,120
restores offsets from the last

00:20:21,290 --> 00:20:25,040
checkpoint it doesn't have it doesn't

00:20:23,120 --> 00:20:28,070
know each upcoming messages were

00:20:25,040 --> 00:20:33,050
processed and it might do it advice so

00:20:28,070 --> 00:20:34,520
that at least once the very for us as we

00:20:33,050 --> 00:20:37,010
know there are two distinctive

00:20:34,520 --> 00:20:38,990
approaches how to implement stream

00:20:37,010 --> 00:20:42,440
processing to native streaming and the

00:20:38,990 --> 00:20:44,270
micro batch apex takes a little bit

00:20:42,440 --> 00:20:47,570
different I would say a hybrid approach

00:20:44,270 --> 00:20:49,640
which they call window dream real-time

00:20:47,570 --> 00:20:52,190
event processing so what does it mean

00:20:49,640 --> 00:20:55,070
basically apex pro represent some kind

00:20:52,190 --> 00:20:56,960
of markers name becomes for a stream and

00:20:55,070 --> 00:20:59,480
they are used to track the process

00:20:56,960 --> 00:21:03,260
events in case of Pharaoh it works quite

00:20:59,480 --> 00:21:06,380
well it it's efficient and and there is

00:21:03,260 --> 00:21:08,690
no artificial item say but as you may

00:21:06,380 --> 00:21:11,120
see in the picture your application

00:21:08,690 --> 00:21:13,310
windows must be multiplies of these

00:21:11,120 --> 00:21:17,810
system in those and it might be a

00:21:13,310 --> 00:21:20,060
limiting factor Frank approach is based

00:21:17,810 --> 00:21:22,790
on distributed snapshot which gives the

00:21:20,060 --> 00:21:25,880
state of streaming job and it's kind of

00:21:22,790 --> 00:21:29,180
similar to Apex Frank markers are called

00:21:25,880 --> 00:21:31,850
barriers and are sent through the stream

00:21:29,180 --> 00:21:33,350
when Barry reaches in operator

00:21:31,850 --> 00:21:36,440
operate a check points corresponding

00:21:33,350 --> 00:21:39,230
part of the stream so if we compare it

00:21:36,440 --> 00:21:41,240
to storm it's far more efficient because

00:21:39,230 --> 00:21:43,370
it doesn't have to acknowledge every

00:21:41,240 --> 00:21:46,610
single record but does it in small

00:21:43,370 --> 00:21:48,770
batches but don't be confuse a still

00:21:46,610 --> 00:21:51,320
native streaming conceptually it is very

00:21:48,770 --> 00:21:54,490
different from spark also flings been

00:21:51,320 --> 00:21:58,970
doing is not affected or limited and

00:21:54,490 --> 00:22:03,370
anyway lastly book apex and provide and

00:21:58,970 --> 00:22:05,900
flink provides all the river grantees

00:22:03,370 --> 00:22:08,690
most of gingival streaming applications

00:22:05,900 --> 00:22:11,630
have some kind of state on the contrary

00:22:08,690 --> 00:22:13,880
of status operations where we have just

00:22:11,630 --> 00:22:15,950
an input processing and an output we

00:22:13,880 --> 00:22:18,260
have an input an estate then we then we

00:22:15,950 --> 00:22:21,440
do the processing and we have an output

00:22:18,260 --> 00:22:23,390
in the modified state we have to manage

00:22:21,440 --> 00:22:25,760
our state purses that and in case of

00:22:23,390 --> 00:22:28,880
failure we expect our state to be

00:22:25,760 --> 00:22:31,250
recreated the location of the state

00:22:28,880 --> 00:22:33,260
might be a problem a little bit as we do

00:22:31,250 --> 00:22:35,270
not we do not have always exactly what

00:22:33,260 --> 00:22:37,669
grantee some of Records may be applied

00:22:35,270 --> 00:22:42,500
multiple times and that is not what we

00:22:37,669 --> 00:22:45,620
usually want as we know storm provides

00:22:42,500 --> 00:22:47,570
at least once divert grantees so how can

00:22:45,620 --> 00:22:50,630
we achieve exactly one semantics

00:22:47,570 --> 00:22:52,760
provided by try then conceptually it is

00:22:50,630 --> 00:22:54,500
quite simple we just start committing

00:22:52,760 --> 00:22:56,780
your records but obviously it is not

00:22:54,500 --> 00:22:58,820
very efficient so we start doing in

00:22:56,780 --> 00:23:02,630
small batches then do some optimizations

00:22:58,820 --> 00:23:03,980
and here we are tried and provides a

00:23:02,630 --> 00:23:07,010
couple of educated components for

00:23:03,980 --> 00:23:10,309
storing states which can be accessed by

00:23:07,010 --> 00:23:13,840
streams it's not very convenient but

00:23:10,309 --> 00:23:13,840
it's definitely usable

00:23:15,040 --> 00:23:19,750
when thinking about stateful operations

00:23:17,320 --> 00:23:22,600
in slippers a sink we usually have a

00:23:19,750 --> 00:23:24,900
long-running operator with a steak and a

00:23:22,600 --> 00:23:27,310
stream of Records coming through it and

00:23:24,900 --> 00:23:29,980
as we know spark streaming is micro

00:23:27,310 --> 00:23:32,860
batching system and is implemented very

00:23:29,980 --> 00:23:35,140
differently basically sparks Timmy

00:23:32,860 --> 00:23:38,320
manager state as neither bichromate

00:23:35,140 --> 00:23:40,210
microbe extreme so drink processing of

00:23:38,320 --> 00:23:41,560
each micro batch sparks takes the

00:23:40,210 --> 00:23:44,110
current state and a function

00:23:41,560 --> 00:23:46,210
representing the operation and result

00:23:44,110 --> 00:23:50,830
this process micro batch and an updated

00:23:46,210 --> 00:23:54,730
stream some the solution for everything

00:23:50,830 --> 00:23:57,040
is just push it out to Kafka and program

00:23:54,730 --> 00:24:00,370
soft and he also works in the context of

00:23:57,040 --> 00:24:02,680
state management some that has lost a

00:24:00,370 --> 00:24:05,050
proper address so any task in hollow

00:24:02,680 --> 00:24:08,380
state and the state change lock is

00:24:05,050 --> 00:24:11,710
pushed to Kafka if needed state can be

00:24:08,380 --> 00:24:15,130
easily recreated from Kafka's topics to

00:24:11,710 --> 00:24:18,250
make it a little bit faster Samael's us

00:24:15,130 --> 00:24:20,260
to plug in a key value store store as

00:24:18,250 --> 00:24:24,540
local storage so it does not have to go

00:24:20,260 --> 00:24:27,010
to Kafka all the time unfortunately

00:24:24,540 --> 00:24:29,380
since that provides at least once

00:24:27,010 --> 00:24:31,780
semantics only and it hurts a lot but

00:24:29,380 --> 00:24:37,180
the implementation of exactly ones

00:24:31,780 --> 00:24:40,000
delivery is planned apache apex meant

00:24:37,180 --> 00:24:43,300
maintains to type of test firstly apex

00:24:40,000 --> 00:24:45,700
give us a fancy ability or fancy feature

00:24:43,300 --> 00:24:49,300
to change it stupid you dynamically on

00:24:45,700 --> 00:24:51,370
runtime so it's races and palaces it's

00:24:49,300 --> 00:24:53,260
duck into a persistent storage which is

00:24:51,370 --> 00:24:57,130
usually HDFS but we can plug in

00:24:53,260 --> 00:24:59,380
something else and apart from that apex

00:24:57,130 --> 00:25:01,840
provides both stateless and tide pool

00:24:59,380 --> 00:25:04,350
operators as you can see the picture

00:25:01,840 --> 00:25:06,310
apex provide long-running operators and

00:25:04,350 --> 00:25:09,670
conceptually it is very similar to

00:25:06,310 --> 00:25:13,650
samsung and their status of course

00:25:09,670 --> 00:25:13,650
center saved into a persistent storage

00:25:15,919 --> 00:25:22,169
flink provides the operators like Sansa

00:25:19,259 --> 00:25:24,919
or apex my working fling we can use two

00:25:22,169 --> 00:25:27,840
different types of states first one is a

00:25:24,919 --> 00:25:30,419
traditional local or task state if you

00:25:27,840 --> 00:25:33,119
will it's a current state of particular

00:25:30,419 --> 00:25:35,580
operator instance only and these guys do

00:25:33,119 --> 00:25:38,639
not interact with each other apart from

00:25:35,580 --> 00:25:41,070
that Frank provides partition it or key

00:25:38,639 --> 00:25:46,859
state if you will which maintain state

00:25:41,070 --> 00:25:50,159
of all partition so let's take one more

00:25:46,859 --> 00:25:59,700
look how to convert focusing on state

00:25:50,159 --> 00:26:02,070
management so let's start with Trident

00:25:59,700 --> 00:26:06,779
you may have seen it but already as it

00:26:02,070 --> 00:26:08,549
is pretty similar as before we can

00:26:06,779 --> 00:26:10,889
create a state by calling persistent

00:26:08,549 --> 00:26:13,379
aggregate important argument is count

00:26:10,889 --> 00:26:16,200
which is building component for storing

00:26:13,379 --> 00:26:18,389
numbers as I said if you would like to

00:26:16,200 --> 00:26:21,839
process data from it or if you will have

00:26:18,389 --> 00:26:26,099
to we will have to create a stream for

00:26:21,839 --> 00:26:29,039
that spark the car did approach is a

00:26:26,099 --> 00:26:33,239
little bit better firstly we have to

00:26:29,039 --> 00:26:34,639
create a DD as an initial state then we

00:26:33,239 --> 00:26:37,469
have to define a transition function

00:26:34,639 --> 00:26:39,749
which take a word its count and current

00:26:37,469 --> 00:26:44,929
state the function of the computation up

00:26:39,749 --> 00:26:44,929
in the state and return the result

00:26:45,469 --> 00:26:51,029
finally we can put all bits together at

00:26:48,359 --> 00:26:56,389
get a stage stream which contains our

00:26:51,029 --> 00:26:58,769
count so let's take a look at sums up

00:26:56,389 --> 00:27:01,950
first we need to define our state in

00:26:58,769 --> 00:27:04,710
this case its key value store and I have

00:27:01,950 --> 00:27:08,820
just and also we have to define how it

00:27:04,710 --> 00:27:12,359
should be initialized and then we can

00:27:08,820 --> 00:27:16,379
use it during computation as you can see

00:27:12,359 --> 00:27:18,859
this is where i stay for work apex

00:27:16,379 --> 00:27:21,899
asleep at looks also similar before i

00:27:18,859 --> 00:27:24,479
have just added counter building

00:27:21,899 --> 00:27:26,800
component for counting words which are

00:27:24,479 --> 00:27:29,980
received on its input ports

00:27:26,800 --> 00:27:33,040
but I could also add a stateful to any

00:27:29,980 --> 00:27:37,390
other component if needed I think it's

00:27:33,040 --> 00:27:40,540
very simple and finally let's take a

00:27:37,390 --> 00:27:44,020
look at plink plink provides very neat

00:27:40,540 --> 00:27:46,510
API we just call a function malware

00:27:44,020 --> 00:27:49,270
state which takes us an argument

00:27:46,510 --> 00:27:52,210
function with two parameters first one

00:27:49,270 --> 00:27:54,850
is over to process and second one a

00:27:52,210 --> 00:28:02,140
state function and returns process

00:27:54,850 --> 00:28:03,820
output and a new state I really wanted

00:28:02,140 --> 00:28:06,640
to show you nice performance comparisons

00:28:03,820 --> 00:28:10,000
but i will not original comparison is

00:28:06,640 --> 00:28:12,820
the topic maybe for a whole talk so and

00:28:10,000 --> 00:28:14,680
I won't do it here but a couple of guys

00:28:12,820 --> 00:28:19,450
did already and I'm happy to reference

00:28:14,680 --> 00:28:21,970
them so for now just in general when we

00:28:19,450 --> 00:28:24,210
talk about performance in streaming we

00:28:21,970 --> 00:28:26,890
mostly talk about latency and throughput

00:28:24,210 --> 00:28:29,710
it depends on many variables but in

00:28:26,890 --> 00:28:33,460
general and for a simple task we can

00:28:29,710 --> 00:28:35,710
expect latencies and hundreds thousands

00:28:33,460 --> 00:28:37,810
hundreds of thousands or even millions

00:28:35,710 --> 00:28:41,920
of Records being processed patent or per

00:28:37,810 --> 00:28:44,080
seconds good thing is these systems have

00:28:41,920 --> 00:28:47,380
considerable origins of scanning

00:28:44,080 --> 00:28:49,590
capabilities so we can usually edges

00:28:47,380 --> 00:28:53,320
performance according to our needs or

00:28:49,590 --> 00:28:54,790
according to our budget for latency in

00:28:53,320 --> 00:28:57,220
case of micro batch we are usually

00:28:54,790 --> 00:29:00,070
thinking in seconds increase the native

00:28:57,220 --> 00:29:02,200
streaming we expect later Layton sees in

00:29:00,070 --> 00:29:05,620
over hundreds of malaise for modular

00:29:02,200 --> 00:29:08,080
systems but soon storm or apex can

00:29:05,620 --> 00:29:12,430
operate in pants or under good

00:29:08,080 --> 00:29:14,620
conditions even in milliseconds also

00:29:12,430 --> 00:29:17,860
it's important to keep in mind the cost

00:29:14,620 --> 00:29:20,950
of their very grantees for torrents and

00:29:17,860 --> 00:29:23,230
state management for example turning on

00:29:20,950 --> 00:29:25,540
for torrents may cause you like to ten

00:29:23,230 --> 00:29:27,640
to fifteen percent but in case of storm

00:29:25,540 --> 00:29:31,810
it could be like seventy percent of your

00:29:27,640 --> 00:29:34,840
fruit boot so there is no free lunch as

00:29:31,810 --> 00:29:36,880
always and during the talk I have shown

00:29:34,840 --> 00:29:37,389
you stateful and stateless word count

00:29:36,880 --> 00:29:41,200
example

00:29:37,389 --> 00:29:42,969
and of course Steelers will be faster in

00:29:41,200 --> 00:29:44,559
case you are wondering how much so in

00:29:42,969 --> 00:29:46,019
the context of budget flank the

00:29:44,559 --> 00:29:49,209
different was like twenty-five percent

00:29:46,019 --> 00:29:51,789
but in case of spark goes around fifty

00:29:49,209 --> 00:29:53,679
percent I'm really sure it can be tuned

00:29:51,789 --> 00:29:55,959
but it could give us an idea this is

00:29:53,679 --> 00:30:00,639
something what we should have in mind

00:29:55,959 --> 00:30:03,489
and speaking about tuning all systems

00:30:00,639 --> 00:30:05,259
have very rich tuning options which may

00:30:03,489 --> 00:30:08,979
lead to significant bad form and gains

00:30:05,259 --> 00:30:13,419
and you should always always find some

00:30:08,979 --> 00:30:15,429
time to take a look at it also it's

00:30:13,419 --> 00:30:17,649
important to have in mind or operations

00:30:15,429 --> 00:30:21,639
are distributed and selling data through

00:30:17,649 --> 00:30:23,649
network is it's pretty expensive so try

00:30:21,639 --> 00:30:25,929
to take an advantage later locality and

00:30:23,649 --> 00:30:28,929
also try to tune up your application

00:30:25,929 --> 00:30:31,419
cessation and just sort of to discuss

00:30:28,929 --> 00:30:34,929
about the performance hope I give you

00:30:31,419 --> 00:30:40,329
basic ideas who to expect but we have to

00:30:34,929 --> 00:30:41,979
move on when picking up the framework

00:30:40,329 --> 00:30:44,649
for application you should always

00:30:41,979 --> 00:30:46,749
consider it maturity so let's take a

00:30:44,649 --> 00:30:50,529
quick look how does it look are in our

00:30:46,749 --> 00:30:54,039
cases storm of the first main seems

00:30:50,529 --> 00:30:57,429
processing system and is used by many

00:30:54,039 --> 00:31:01,179
companies like Yahoo Spotify and many

00:30:57,429 --> 00:31:04,119
more spark is one of the most training

00:31:01,179 --> 00:31:06,719
sky repositories these days and one of

00:31:04,119 --> 00:31:09,820
the engines behind scars popularity

00:31:06,719 --> 00:31:11,589
sparks eruption grows every day is used

00:31:09,820 --> 00:31:16,659
by companies like Netflix escalator

00:31:11,589 --> 00:31:19,570
Starks Intel IBM and so on some that is

00:31:16,659 --> 00:31:21,820
used by linking and also by hands of

00:31:19,570 --> 00:31:27,789
other companies as an example we can

00:31:21,820 --> 00:31:30,129
have netflix or bear I do apex created

00:31:27,789 --> 00:31:33,339
very recently it has been adopted by a

00:31:30,129 --> 00:31:35,499
cup of corporate clients like GPS cloud

00:31:33,339 --> 00:31:40,889
capital one or silver spring networks

00:31:35,499 --> 00:31:44,409
and I'm really sure more are coming

00:31:40,889 --> 00:31:46,059
flank is also an emerging project but we

00:31:44,409 --> 00:31:48,460
can see its first production deployments

00:31:46,059 --> 00:31:51,700
and again I'm

00:31:48,460 --> 00:31:53,260
more real for very soon for example i

00:31:51,700 --> 00:31:58,020
heard amazon was highlighting it and

00:31:53,260 --> 00:31:58,020
also capital one was using it and so on

00:31:58,530 --> 00:32:04,750
so we just finished basic comparison of

00:32:02,020 --> 00:32:07,690
chosen systems which through the most of

00:32:04,750 --> 00:32:09,700
my time and we discuss how do they

00:32:07,690 --> 00:32:11,830
approved by those challenges which needs

00:32:09,700 --> 00:32:15,460
to be sorted out when implementing

00:32:11,830 --> 00:32:18,340
distributed stream processing system and

00:32:15,460 --> 00:32:21,010
you may take a quick look at a summary

00:32:18,340 --> 00:32:25,170
from from my opinion there and key trait

00:32:21,010 --> 00:32:27,550
and now's the time to move on and and

00:32:25,170 --> 00:32:30,640
have a look of the last part of this

00:32:27,550 --> 00:32:33,370
talk playing more recommendations i have

00:32:30,640 --> 00:32:36,190
to say this part is the most opinion

00:32:33,370 --> 00:32:49,000
based by far but i was retrying to be

00:32:36,190 --> 00:32:51,130
fair so what's wrong the answer for a

00:32:49,000 --> 00:32:55,110
typical question which one should i use

00:32:51,130 --> 00:32:58,660
or which one is the best as always

00:32:55,110 --> 00:33:01,150
depends so in general always try to

00:32:58,660 --> 00:33:04,300
evaluate requirements of your

00:33:01,150 --> 00:33:06,370
application carefully and be sure you

00:33:04,300 --> 00:33:09,850
fully understand the consequences of

00:33:06,370 --> 00:33:11,080
choosing particular framework and try to

00:33:09,850 --> 00:33:13,990
fully understand the interest as

00:33:11,080 --> 00:33:18,850
improper use can have like disastrous

00:33:13,990 --> 00:33:21,040
consequences for programming model and i

00:33:18,850 --> 00:33:23,560
think most of you guys would play for

00:33:21,040 --> 00:33:25,090
high / AP i-- and make sense you know

00:33:23,560 --> 00:33:28,000
it's more elegant and it's more

00:33:25,090 --> 00:33:31,390
proactive and so on but on the other

00:33:28,000 --> 00:33:33,610
hand held ap ice might hide all of its

00:33:31,390 --> 00:33:35,680
details you have to understand when

00:33:33,610 --> 00:33:39,460
you're given you want your once you are

00:33:35,680 --> 00:33:42,310
facing an issue and i have seen all of

00:33:39,460 --> 00:33:45,790
problems of that so I would recommend

00:33:42,310 --> 00:33:48,190
flowing if you want to do all of data

00:33:45,790 --> 00:33:51,880
science analysis or if you want to play

00:33:48,190 --> 00:33:55,330
with Red Bull I think the high level API

00:33:51,880 --> 00:33:57,550
is great way to go but if you expect

00:33:55,330 --> 00:34:00,130
more data entered operations like

00:33:57,550 --> 00:34:01,159
crunchy guitar by the blocks or if you

00:34:00,130 --> 00:34:03,190
want to

00:34:01,159 --> 00:34:05,629
manage your back rib precisely

00:34:03,190 --> 00:34:09,319
compositional FBI my different to make

00:34:05,629 --> 00:34:13,899
sense so bring it through what do you

00:34:09,319 --> 00:34:13,899
need and which approaches you best I

00:34:14,679 --> 00:34:20,539
would also recommend you for a framework

00:34:17,119 --> 00:34:23,089
with all their very semantics available

00:34:20,539 --> 00:34:27,200
as usually don't want to limit yourself

00:34:23,089 --> 00:34:30,379
and and especially if you are not sure

00:34:27,200 --> 00:34:32,780
what to expect but of course there are

00:34:30,379 --> 00:34:36,799
definitely use cases when at least once

00:34:32,780 --> 00:34:40,039
or a loss Adam at most once the other

00:34:36,799 --> 00:34:42,369
grantees are all you need also keep in

00:34:40,039 --> 00:34:44,929
mind which may be able to be surprising

00:34:42,369 --> 00:34:48,230
system supporting exactly one delivery

00:34:44,929 --> 00:34:52,659
doesn't have to support vehicle grantees

00:34:48,230 --> 00:34:52,659
yes I'm talking about spark streaming

00:34:53,500 --> 00:34:59,150
this point might be typed together with

00:34:56,929 --> 00:35:01,069
the previous valence of it most of the

00:34:59,150 --> 00:35:03,470
streaming application are stateful and

00:35:01,069 --> 00:35:05,869
as we have seen this area might be quite

00:35:03,470 --> 00:35:07,940
challenging so the state management of a

00:35:05,869 --> 00:35:12,589
particle framework should be really up

00:35:07,940 --> 00:35:14,779
on your evolution list lastly make sure

00:35:12,589 --> 00:35:17,690
your system is able to recover quickly

00:35:14,779 --> 00:35:20,359
you can use cows monkey or similar to

00:35:17,690 --> 00:35:22,819
for testing because I did as we have

00:35:20,359 --> 00:35:26,329
discussed fast recovery is crucial in

00:35:22,819 --> 00:35:32,210
stream processing remember data are

00:35:26,329 --> 00:35:35,839
still coming and now let's take a look

00:35:32,210 --> 00:35:39,770
at particle frameworks storm is a still

00:35:35,839 --> 00:35:42,470
a decent fit for small and fast task you

00:35:39,770 --> 00:35:44,839
can mainly a bow latency store might be

00:35:42,470 --> 00:35:47,960
a good way to go also keep in mind the

00:35:44,839 --> 00:35:51,950
photons or try instead management hurts

00:35:47,960 --> 00:35:53,779
the performance a lot interesting option

00:35:51,950 --> 00:35:56,240
might be a potential update to twitter's

00:35:53,779 --> 00:35:58,430
Iran which is designed as a strong

00:35:56,240 --> 00:36:01,190
replacement and should be better in

00:35:58,430 --> 00:36:03,980
every single point but it also keeps the

00:36:01,190 --> 00:36:06,819
API the problem is there is no guarantee

00:36:03,980 --> 00:36:11,470
it better is going to open source it so

00:36:06,819 --> 00:36:11,470
who knows if it is early gratia

00:36:12,660 --> 00:36:17,560
for spark streaming you should

00:36:14,650 --> 00:36:18,700
definitely a nice try it if spark is

00:36:17,560 --> 00:36:21,970
already part of your infrastructure

00:36:18,700 --> 00:36:24,670
because in this case swimming comes

00:36:21,970 --> 00:36:28,020
basically for free and you can also take

00:36:24,670 --> 00:36:30,160
an advantage of various parks libraries

00:36:28,020 --> 00:36:32,350
apart from that there's a bunch of

00:36:30,160 --> 00:36:35,020
helpful tools available like crapple or

00:36:32,350 --> 00:36:38,830
partner book for little data exploration

00:36:35,020 --> 00:36:41,950
for example you know spark ecosystem is

00:36:38,830 --> 00:36:44,140
really huge and impressive but you

00:36:41,950 --> 00:36:46,360
should always keep in mind its micro

00:36:44,140 --> 00:36:49,540
batching limitations which may really be

00:36:46,360 --> 00:36:55,240
in the camp shoe stupor and also be sure

00:36:49,540 --> 00:36:56,620
latency is not critical for you when

00:36:55,240 --> 00:37:00,250
thinking at all about I don't think

00:36:56,620 --> 00:37:03,010
Samsung kafka should be a curse tour of

00:37:00,250 --> 00:37:05,530
your architecture I know it's bugaboo

00:37:03,010 --> 00:37:08,250
but nearly everyone or maybe everyone is

00:37:05,530 --> 00:37:10,720
using Kafka so I would stick of that

00:37:08,250 --> 00:37:13,090
also as mentioned before Samsa is

00:37:10,720 --> 00:37:17,290
shipped with power if local storage and

00:37:13,090 --> 00:37:19,870
it's great for managing large states it

00:37:17,290 --> 00:37:23,230
can handle states of tens of gigabytes

00:37:19,870 --> 00:37:24,940
easily which is pretty nice but keep in

00:37:23,230 --> 00:37:29,770
mind sums us at least once dated a

00:37:24,940 --> 00:37:31,690
limitation also if you like some za you

00:37:29,770 --> 00:37:34,330
should also consider newly introduced

00:37:31,690 --> 00:37:37,960
kafka streams which offer a similar

00:37:34,330 --> 00:37:41,440
functionality with nice API and operated

00:37:37,960 --> 00:37:47,530
by Kafka itself so begin for operation

00:37:41,440 --> 00:37:49,330
ask Kafka is basically only if you

00:37:47,530 --> 00:37:51,730
prefer low level / completion my

00:37:49,330 --> 00:37:55,150
approach and you are also Hydra positive

00:37:51,730 --> 00:37:58,420
I believe apex is or might be a great

00:37:55,150 --> 00:38:01,420
choice for you it gives you a fine gain

00:37:58,420 --> 00:38:03,760
access to that so you can get really

00:38:01,420 --> 00:38:06,700
most of it therefore its performance

00:38:03,760 --> 00:38:11,350
especially especially HT Doble tenses

00:38:06,700 --> 00:38:15,040
are truly excellent moreover apex elves

00:38:11,350 --> 00:38:18,430
as dynamic duck changes which is very

00:38:15,040 --> 00:38:19,950
unique feature as you see apex or first

00:38:18,430 --> 00:38:22,770
interesting options

00:38:19,950 --> 00:38:27,080
which as I believe overweight is still

00:38:22,770 --> 00:38:27,080
emerging but already graduated status

00:38:27,320 --> 00:38:32,550
flank is conceptually great streaming

00:38:30,120 --> 00:38:35,340
system which fits very most use cases

00:38:32,550 --> 00:38:37,920
and it often provides progressive

00:38:35,340 --> 00:38:40,620
functionality like advanced been doing

00:38:37,920 --> 00:38:42,150
or time and link which may not be

00:38:40,620 --> 00:38:46,230
supported or measure may not be

00:38:42,150 --> 00:38:47,760
implemented by its competitors so you

00:38:46,230 --> 00:38:49,770
should always go to the flank when you

00:38:47,760 --> 00:38:53,430
need a functionality which might be hard

00:38:49,770 --> 00:38:56,730
to implement impart original in enema

00:38:53,430 --> 00:38:59,640
micromachining system apart from that

00:38:56,730 --> 00:39:01,170
flank also has an API for for common

00:38:59,640 --> 00:39:05,160
batch processing which may be pretty

00:39:01,170 --> 00:39:07,410
useful but you need to have enough

00:39:05,160 --> 00:39:10,080
courage to adopt emerging project and

00:39:07,410 --> 00:39:13,010
also as always do not forget check out

00:39:10,080 --> 00:39:13,010
aids or map

00:39:22,670 --> 00:39:28,640
and last thing I want to mention today

00:39:25,550 --> 00:39:32,720
is data flow and it's open source

00:39:28,640 --> 00:39:36,020
initiative data flow is a part of Google

00:39:32,720 --> 00:39:39,950
cloud platform and cloud platform has

00:39:36,020 --> 00:39:42,920
all sorts of things on it as as a huge

00:39:39,950 --> 00:39:46,550
data storage the query call pops up and

00:39:42,920 --> 00:39:49,610
samples for recognizes and so on and

00:39:46,550 --> 00:39:51,530
also a for mention call data flow it is

00:39:49,610 --> 00:39:55,570
glucose many terrorists for batch and

00:39:51,530 --> 00:39:58,190
stream processing with unified API and

00:39:55,570 --> 00:40:01,550
it's built upon well-known Google

00:39:58,190 --> 00:40:04,250
technologies such as mobile news for

00:40:01,550 --> 00:40:07,550
batch processing from from Java for

00:40:04,250 --> 00:40:10,640
programming model definition and milvia

00:40:07,550 --> 00:40:14,300
for simple to sync and all of them are

00:40:10,640 --> 00:40:16,190
really good you may be asking when I'm

00:40:14,300 --> 00:40:19,340
talking about that as i said i will be

00:40:16,190 --> 00:40:22,070
speaking about about open source

00:40:19,340 --> 00:40:25,310
framework and this is clearly google's

00:40:22,070 --> 00:40:30,400
proprietary solution but google decided

00:40:25,310 --> 00:40:34,270
to open source data for sdk recently and

00:40:30,400 --> 00:40:38,240
guys behind both park and flank

00:40:34,270 --> 00:40:41,300
implemented its runners so now we have

00:40:38,240 --> 00:40:46,130
an ability to run jobs defined by this

00:40:41,300 --> 00:40:48,770
data API in calpe form and Frank orange

00:40:46,130 --> 00:40:54,670
park and it is very probable more

00:40:48,770 --> 00:40:58,540
engines will follow very soon so and

00:40:54,670 --> 00:41:01,730
beta 4 provides API in java and python

00:40:58,540 --> 00:41:03,830
implementing by google itself and also i

00:41:01,730 --> 00:41:07,250
have found a couple of scary as all

00:41:03,830 --> 00:41:10,580
sports already apart from that google

00:41:07,250 --> 00:41:13,970
and a number of partners submitted this

00:41:10,580 --> 00:41:19,250
as a new apache also named apache beam

00:41:13,970 --> 00:41:22,790
and i think bin has a good chance to be

00:41:19,250 --> 00:41:27,170
unifying api that gives us a nice way to

00:41:22,790 --> 00:41:30,200
write once and run everywhere but it's

00:41:27,170 --> 00:41:33,080
important to say all the office is quite

00:41:30,200 --> 00:41:35,090
recent and the implementation of some of

00:41:33,080 --> 00:41:35,710
the promised feature from his features

00:41:35,090 --> 00:41:39,460
might be

00:41:35,710 --> 00:41:45,660
sing but it is definitely worth to check

00:41:39,460 --> 00:41:48,339
it out so now it's time for questions

00:41:45,660 --> 00:41:50,050
but you know if there are any let me

00:41:48,339 --> 00:41:52,359
know but also I will be summer and out

00:41:50,050 --> 00:41:54,430
anywhere and always happy to discuss

00:41:52,359 --> 00:42:01,300
where your stuff so just just find me

00:41:54,430 --> 00:42:03,640
and I'll have a chat thank you very much

00:42:01,300 --> 00:42:06,700
for attention I hope it was helpful for

00:42:03,640 --> 00:42:10,300
you also we are hiring so if you want to

00:42:06,700 --> 00:42:13,260
join us just hope the link so that's all

00:42:10,300 --> 00:42:13,260

YouTube URL: https://www.youtube.com/watch?v=AsP457crrtM


