Title: Transactional Event Sourcing using Slick audit log for free - by Adam Warski
Publication date: 2016-06-17
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.

Abstract:
Event sourcing is a great alternative to traditional "CRUD"-type architectures. The central concept is a persistent stream of events, which drives all changes to the read model and running any kind of business logic. There’s a lot of technical and business benefits to such an approach, such as being able to re-create the state of the system at any point in time, or keeping a detailed *audit log* of all actions. Typically, implementations of event sourcing are presented using a NoSQL data storage, which is great for many use cases (e.g. using Akka Persistence + Cassandra). However, nothing stops us from using a relational database and SQL! In many applications (especially “enterprise”), this brings many benefits, such as powerful and familiar query capabilities and higher guarantees around data consistency. In this mainly live-coding talk we’ll see one way of implementing transactional event sourcing using the 'slick-eventsourcing' micro-framework, introducing the core concepts: command handlers, read model updates and event listeners, and how to use them to build an event-sourced application. We’ll see how Slick’s 'DBAction' and Scala flexibility makes it possible to provide an elegant DSL to build the system from simple functions with minimum dependencies.
Captions: 
	00:00:03,860 --> 00:00:10,219
hello thank you for coming and my name

00:00:07,189 --> 00:00:12,709
is an inverse key and I would like to

00:00:10,219 --> 00:00:18,680
talk about how to do translational event

00:00:12,709 --> 00:00:22,160
sourcing using flick ok so the

00:00:18,680 --> 00:00:23,780
organizers asked you to vote on the

00:00:22,160 --> 00:00:26,240
sessions so after this session is

00:00:23,780 --> 00:00:27,740
complete all you have to do is you go

00:00:26,240 --> 00:00:31,340
you have to go to the mobile app and

00:00:27,740 --> 00:00:34,460
click the green face that you like the

00:00:31,340 --> 00:00:38,120
session and there will be our mind at

00:00:34,460 --> 00:00:41,780
the end as well so don't worry and ok so

00:00:38,120 --> 00:00:44,239
let's let's start with actually defining

00:00:41,780 --> 00:00:47,000
what what is the vent sourcing I guess

00:00:44,239 --> 00:00:49,070
most of you have some kind of idea what

00:00:47,000 --> 00:00:52,310
what can it mean there's a lot of

00:00:49,070 --> 00:00:54,050
articles on the web by people such as

00:00:52,310 --> 00:00:57,200
smart and flower or Greg young which

00:00:54,050 --> 00:00:59,420
probably explain this a lot better than

00:00:57,200 --> 00:01:01,940
me so for the purposes of the spread of

00:00:59,420 --> 00:01:04,579
this presentation and let's say that

00:01:01,940 --> 00:01:06,979
event sourcing is when all changes in

00:01:04,579 --> 00:01:09,680
the system I captured as a sequence of

00:01:06,979 --> 00:01:11,990
events and these events are our primary

00:01:09,680 --> 00:01:14,350
source of knowledge so the events come

00:01:11,990 --> 00:01:17,090
first in the system and everything else

00:01:14,350 --> 00:01:19,970
is derived is a consequence of these

00:01:17,090 --> 00:01:23,060
events so we focus on the event on what

00:01:19,970 --> 00:01:26,330
a on there on a description of what

00:01:23,060 --> 00:01:28,610
happens in in in the system it doesn't

00:01:26,330 --> 00:01:35,030
have to be strictly a sequence but here

00:01:28,610 --> 00:01:37,970
let's and let it to it usual it is so

00:01:35,030 --> 00:01:40,760
why should we be bothered with event

00:01:37,970 --> 00:01:43,460
sourcing so there's many reasons and one

00:01:40,760 --> 00:01:46,369
of them is that we work in I tnit is

00:01:43,460 --> 00:01:49,090
information technology so it's something

00:01:46,369 --> 00:01:51,920
to do with information right and and

00:01:49,090 --> 00:01:54,860
when using event sourcing we are not

00:01:51,920 --> 00:01:57,890
losing any information or we are losing

00:01:54,860 --> 00:02:00,290
much less information than in let's say

00:01:57,890 --> 00:02:02,810
more traditional crud system right in a

00:02:00,290 --> 00:02:06,409
crowd system every time we remove we

00:02:02,810 --> 00:02:08,989
update an existing a piece of data we

00:02:06,409 --> 00:02:10,909
lose the old information right we also

00:02:08,989 --> 00:02:14,780
lose the information on when the change

00:02:10,909 --> 00:02:17,150
was done and so on ok so just because we

00:02:14,780 --> 00:02:17,630
work in IT it is already a good reason

00:02:17,150 --> 00:02:19,190
to use a

00:02:17,630 --> 00:02:22,100
and sourcing because we don't lose this

00:02:19,190 --> 00:02:24,380
additional information another thing is

00:02:22,100 --> 00:02:27,170
that using event sourcing you get an

00:02:24,380 --> 00:02:31,670
audit log of what happens in the system

00:02:27,170 --> 00:02:33,950
kind of for free so you know using a new

00:02:31,670 --> 00:02:35,630
shiny web framework while attractive

00:02:33,950 --> 00:02:38,390
doesn't really bring any business value

00:02:35,630 --> 00:02:40,550
quite often here using event sourcing

00:02:38,390 --> 00:02:42,260
you can actually bring business value to

00:02:40,550 --> 00:02:44,750
the project even when a project is

00:02:42,260 --> 00:02:47,030
starting and there's no requirement yet

00:02:44,750 --> 00:02:49,280
to do an audit log it's quite often

00:02:47,030 --> 00:02:52,730
comes in later and then you can say it's

00:02:49,280 --> 00:02:54,830
all it's already done and also for

00:02:52,730 --> 00:02:57,020
testing and for the bugging you have the

00:02:54,830 --> 00:03:00,110
possibility to recreate the system state

00:02:57,020 --> 00:03:03,260
at any point in time by replaying the

00:03:00,110 --> 00:03:05,930
events up to a certain point and also

00:03:03,260 --> 00:03:08,120
some other benefits which which I won't

00:03:05,930 --> 00:03:10,940
mention here but I guess these are the

00:03:08,120 --> 00:03:14,510
main ones at least for at least for me

00:03:10,940 --> 00:03:17,450
and it's rather stock I will will quite

00:03:14,510 --> 00:03:20,540
often reference like what i say more

00:03:17,450 --> 00:03:23,750
traditional crud system so we will show

00:03:20,540 --> 00:03:26,000
things in contrast to crud systems where

00:03:23,750 --> 00:03:28,130
you like it typically have some entities

00:03:26,000 --> 00:03:31,310
and you create read update and delete

00:03:28,130 --> 00:03:33,860
them right and we will see how we can do

00:03:31,310 --> 00:03:37,370
things differently using event sourcing

00:03:33,860 --> 00:03:40,010
and so it's not my first approach to

00:03:37,370 --> 00:03:42,410
audit logs and I think I thought that I

00:03:40,010 --> 00:03:44,570
was going to shock you all by showing

00:03:42,410 --> 00:03:46,220
hibernate on a scholar conference but

00:03:44,570 --> 00:03:48,350
actually Marting already did that

00:03:46,220 --> 00:03:52,880
yesterday he didn't mention hibernate

00:03:48,350 --> 00:03:54,590
and so no surprise here but I did work

00:03:52,880 --> 00:03:57,440
on a project called hibernate and worse

00:03:54,590 --> 00:04:00,430
it was an extension into hibernate and

00:03:57,440 --> 00:04:03,620
but it kind of worked the other way so

00:04:00,430 --> 00:04:06,709
within averse every time you modified an

00:04:03,620 --> 00:04:10,610
entity and entry with the old data was

00:04:06,709 --> 00:04:12,530
written to an audit table so in inverse

00:04:10,610 --> 00:04:15,080
like the history was written after the

00:04:12,530 --> 00:04:16,910
changes and here like the history comes

00:04:15,080 --> 00:04:22,340
first and we derive the current state

00:04:16,910 --> 00:04:26,240
from it and continuing the subject of me

00:04:22,340 --> 00:04:28,970
just to introduce myself a bit and i'm a

00:04:26,240 --> 00:04:30,830
co-founder and the developer at software

00:04:28,970 --> 00:04:32,720
mode which is a

00:04:30,830 --> 00:04:35,450
tributed software house baton poland but

00:04:32,720 --> 00:04:37,880
we operate on the whole world we are a

00:04:35,450 --> 00:04:42,290
light Bend consulting partner we mainly

00:04:37,880 --> 00:04:44,750
do scala also Java and you know Big Data

00:04:42,290 --> 00:04:48,470
enormous data and so on and we do some

00:04:44,750 --> 00:04:50,960
open source projects like mcwire elastic

00:04:48,470 --> 00:04:53,690
mq boot zucca i have a blog and a

00:04:50,960 --> 00:04:56,300
twitter account you can invite it as a

00:04:53,690 --> 00:04:58,580
company we also do a scholar newsletters

00:04:56,300 --> 00:05:00,920
color times and maybe Fred of it if you

00:04:58,580 --> 00:05:04,310
haven't check it out it's a weekly

00:05:00,920 --> 00:05:05,750
weekly set of Scala news and there's

00:05:04,310 --> 00:05:09,080
color conference in Poland if you have a

00:05:05,750 --> 00:05:11,750
come to Poland please feel invited okay

00:05:09,080 --> 00:05:14,030
so what's a what's our goal and so our

00:05:11,750 --> 00:05:15,680
goal is to get the benefits of event

00:05:14,030 --> 00:05:18,980
sourcing as I mentioned on the previous

00:05:15,680 --> 00:05:21,650
slides but still be able to leverage the

00:05:18,980 --> 00:05:24,580
various features that a relational

00:05:21,650 --> 00:05:27,740
database gives us for example we want to

00:05:24,580 --> 00:05:29,330
be able to use transactions transactions

00:05:27,740 --> 00:05:31,160
give up some nice properties like it's

00:05:29,330 --> 00:05:34,150
easier to maintain consistency for

00:05:31,160 --> 00:05:36,580
example we want to be able to use the

00:05:34,150 --> 00:05:40,400
quite which schema language to describe

00:05:36,580 --> 00:05:42,230
how our data can look and but most of

00:05:40,400 --> 00:05:46,130
all we wants to be able to sequel data

00:05:42,230 --> 00:05:49,490
to query our current data okay sequel

00:05:46,130 --> 00:05:51,410
can be used by not only by programmers

00:05:49,490 --> 00:05:53,990
but quite often my analyst for example

00:05:51,410 --> 00:05:56,240
and we still want to maintain that and

00:05:53,990 --> 00:06:00,290
so we still want to be able to have our

00:05:56,240 --> 00:06:03,170
data core about using sequel and also I

00:06:00,290 --> 00:06:05,470
think that especially in the micro

00:06:03,170 --> 00:06:10,550
services era and you know where each

00:06:05,470 --> 00:06:13,910
microservice can have its own database I

00:06:10,550 --> 00:06:16,640
think it even more often than them then

00:06:13,910 --> 00:06:18,800
before it man it might be that the best

00:06:16,640 --> 00:06:22,040
fit for certain microservice would be a

00:06:18,800 --> 00:06:27,650
relational database not a no simple

00:06:22,040 --> 00:06:30,350
database okay so there are quite a lot

00:06:27,650 --> 00:06:33,470
of other approaches to Evan sourcing

00:06:30,350 --> 00:06:36,830
they might be more scalable a more

00:06:33,470 --> 00:06:40,940
formal fault tolerant they might be able

00:06:36,830 --> 00:06:43,250
to process a high number of events per

00:06:40,940 --> 00:06:44,760
second for example and so on but of

00:06:43,250 --> 00:06:47,010
course you you don't always need

00:06:44,760 --> 00:06:51,540
that so that's why you have the choice

00:06:47,010 --> 00:06:53,910
right so and the the trade-off here that

00:06:51,540 --> 00:06:56,700
we will have the convenience of

00:06:53,910 --> 00:07:00,270
transactions and the convenience of

00:06:56,700 --> 00:07:02,190
sequel and while they they can handle

00:07:00,270 --> 00:07:05,520
problem more data but on the other hand

00:07:02,190 --> 00:07:10,650
the this distortion listed here they are

00:07:05,520 --> 00:07:12,450
all eventually consistent right events

00:07:10,650 --> 00:07:16,140
though is an eventual constant database

00:07:12,450 --> 00:07:19,860
where events are the EFS class construct

00:07:16,140 --> 00:07:22,140
a couple substance uses where it can use

00:07:19,860 --> 00:07:25,710
many data stores but most of it

00:07:22,140 --> 00:07:32,640
Cassandra eventuate is a distributed

00:07:25,710 --> 00:07:36,390
event store as well okay so how will our

00:07:32,640 --> 00:07:39,000
events look like so first of all an

00:07:36,390 --> 00:07:41,610
event state something about what

00:07:39,000 --> 00:07:43,260
happened in the past okay so it's

00:07:41,610 --> 00:07:46,770
something that already happened for

00:07:43,260 --> 00:07:50,520
example a user created can be an event i

00:07:46,770 --> 00:07:52,950
probe product ordered so an event states

00:07:50,520 --> 00:07:55,860
what already happened it's an immutable

00:07:52,950 --> 00:08:00,120
fact right we cannot change the past at

00:07:55,860 --> 00:08:03,630
least yet and and it will also be our

00:08:00,120 --> 00:08:05,550
primary source of truth so more

00:08:03,630 --> 00:08:09,360
technically how we will represent events

00:08:05,550 --> 00:08:13,170
you will see a in a bit when we will do

00:08:09,360 --> 00:08:17,940
some coding so an event will have some

00:08:13,170 --> 00:08:21,060
data and some metadata the data will be

00:08:17,940 --> 00:08:24,210
an arbitrary a JSON represented by a

00:08:21,060 --> 00:08:25,740
case class so it will contain them yet

00:08:24,210 --> 00:08:27,360
the event data likely when the user is

00:08:25,740 --> 00:08:29,700
created for example that would be the

00:08:27,360 --> 00:08:31,380
username then we with the metadata

00:08:29,700 --> 00:08:34,740
example the type of the event that

00:08:31,380 --> 00:08:38,370
typically would be the name of the case

00:08:34,740 --> 00:08:39,870
class and the idea of the event the

00:08:38,370 --> 00:08:43,380
timestamp of the vents one day event

00:08:39,870 --> 00:08:46,110
actually happened and aggregate happened

00:08:43,380 --> 00:08:48,870
ID each event in our case will be

00:08:46,110 --> 00:08:51,360
associated to some kind of aggregate so

00:08:48,870 --> 00:08:53,640
for example the user created event is

00:08:51,360 --> 00:08:56,430
will be associated to the user aggregate

00:08:53,640 --> 00:08:58,529
right what it it defines what the event

00:08:56,430 --> 00:09:00,269
is about right and the

00:08:58,529 --> 00:09:02,129
aggregate also has an ID so that would

00:09:00,269 --> 00:09:06,749
be like a specific user ID for example

00:09:02,129 --> 00:09:08,370
and also as we are doing transactions we

00:09:06,749 --> 00:09:10,620
can have many events happening in a

00:09:08,370 --> 00:09:13,339
single transaction so we may want to

00:09:10,620 --> 00:09:15,899
capture that information as well and

00:09:13,339 --> 00:09:17,279
that a couple of events happened in a

00:09:15,899 --> 00:09:19,499
single transaction so we will solve

00:09:17,279 --> 00:09:21,540
transaction ID and also we can say user

00:09:19,499 --> 00:09:23,399
ID so that's the idea of the currently

00:09:21,540 --> 00:09:27,720
logged in user who actually did the

00:09:23,399 --> 00:09:30,050
change so how are we going to do that so

00:09:27,720 --> 00:09:34,069
events will be stored in a dedicated

00:09:30,050 --> 00:09:37,800
table in a dedicated sequel table and

00:09:34,069 --> 00:09:40,470
now basing on these events I read we

00:09:37,800 --> 00:09:42,930
will maintain a read model so the read

00:09:40,470 --> 00:09:46,529
model will be updated only in reaction

00:09:42,930 --> 00:09:49,730
to an incoming event and the rid model

00:09:46,529 --> 00:09:53,279
is the name suggests will be used to

00:09:49,730 --> 00:09:56,819
satisfy any read queries right so if if

00:09:53,279 --> 00:09:58,829
we want if we want to read anything from

00:09:56,819 --> 00:10:01,680
our application will use the read will

00:09:58,829 --> 00:10:05,459
query to read model using sequel right

00:10:01,680 --> 00:10:07,800
and and it's it's a kind of similar that

00:10:05,459 --> 00:10:09,360
the read model can be kind of similar to

00:10:07,800 --> 00:10:13,259
what a traditional quad model could be

00:10:09,360 --> 00:10:15,420
it could be but we have kind of more

00:10:13,259 --> 00:10:19,230
freedom to the normalize it more if we

00:10:15,420 --> 00:10:20,930
want to like we don't we can recreate it

00:10:19,230 --> 00:10:23,730
at any point in time right and we can

00:10:20,930 --> 00:10:26,970
also add new read models if you want to

00:10:23,730 --> 00:10:29,759
basing on past events so we are not so

00:10:26,970 --> 00:10:32,670
constrained to not to da pin not to

00:10:29,759 --> 00:10:36,149
duplicate data as in a normal crud

00:10:32,670 --> 00:10:41,459
application and and quite important day

00:10:36,149 --> 00:10:44,100
for consistency and both when when when

00:10:41,459 --> 00:10:46,230
doing a change about writing the event

00:10:44,100 --> 00:10:47,699
in the events table and updating the

00:10:46,230 --> 00:10:50,939
read model will be done in a single

00:10:47,699 --> 00:10:53,250
transaction so that way the read model

00:10:50,939 --> 00:11:00,449
will be consistent with what's in the

00:10:53,250 --> 00:11:03,809
events table and as you probably suspect

00:11:00,449 --> 00:11:08,160
it we will be using slick for actually

00:11:03,809 --> 00:11:10,110
talking to the database so i won't go

00:11:08,160 --> 00:11:12,150
into a very in-depth slick introduction

00:11:10,110 --> 00:11:14,740
but in slick

00:11:12,150 --> 00:11:20,140
special data type defined dbio action

00:11:14,740 --> 00:11:23,920
and using that type like that type

00:11:20,140 --> 00:11:26,550
describes an operation on a database so

00:11:23,920 --> 00:11:30,400
whenever you insert your query a

00:11:26,550 --> 00:11:33,340
database and you invoke some operations

00:11:30,400 --> 00:11:35,830
on on the slick object it don't really

00:11:33,340 --> 00:11:38,350
the operation isn't really executed you

00:11:35,830 --> 00:11:41,530
only get the description of what will be

00:11:38,350 --> 00:11:44,500
done okay and so for example it's a

00:11:41,530 --> 00:11:48,970
description of how to insert a new row

00:11:44,500 --> 00:11:51,220
into a table or how to query now you can

00:11:48,970 --> 00:11:53,190
then run such a description and this

00:11:51,220 --> 00:11:56,140
will actually go to the database and

00:11:53,190 --> 00:11:58,660
perform the operations right why is this

00:11:56,140 --> 00:12:01,990
nice well we can take a bunch of such

00:11:58,660 --> 00:12:04,330
this of such descriptions compose them

00:12:01,990 --> 00:12:06,670
together into one big description for

00:12:04,330 --> 00:12:08,130
example say dots transactional and they

00:12:06,670 --> 00:12:11,500
will all be run in a single transaction

00:12:08,130 --> 00:12:16,980
ok so these pieces can become it can be

00:12:11,500 --> 00:12:19,660
produced by unrelated methods and and

00:12:16,980 --> 00:12:21,730
they don't have to know anything about

00:12:19,660 --> 00:12:23,590
it each each other you don't have to

00:12:21,730 --> 00:12:25,600
know anything about the transaction

00:12:23,590 --> 00:12:27,700
context or anything like that it's just

00:12:25,600 --> 00:12:31,120
a method which produces a description of

00:12:27,700 --> 00:12:32,890
how to talk to the database and we can

00:12:31,120 --> 00:12:35,860
sequence these descriptions using a flat

00:12:32,890 --> 00:12:37,500
map so this forms a monitor almost a

00:12:35,860 --> 00:12:42,490
monad but that's not really that

00:12:37,500 --> 00:12:44,500
important ok so now we will do some live

00:12:42,490 --> 00:12:49,660
coding so i will be using a library

00:12:44,500 --> 00:12:52,570
called slick event sourcing and it's a

00:12:49,660 --> 00:12:57,160
very small libraries I'm not even sure I

00:12:52,570 --> 00:13:02,890
can call it a library its presentation

00:12:57,160 --> 00:13:04,570
and I would say so here it is I would

00:13:02,890 --> 00:13:07,540
say it's more like an application

00:13:04,570 --> 00:13:09,130
template so I would expect for any more

00:13:07,540 --> 00:13:11,980
serious you said she would end up

00:13:09,130 --> 00:13:13,890
probably forking it and changing it but

00:13:11,980 --> 00:13:18,220
there's quite a fur coat in their

00:13:13,890 --> 00:13:23,080
unfortunate is not a little enough to

00:13:18,220 --> 00:13:24,450
type it all in here and but well I I'll

00:13:23,080 --> 00:13:30,750
show you

00:13:24,450 --> 00:13:37,020
some parts of it okay so what will we be

00:13:30,750 --> 00:13:41,550
coding so our example application our

00:13:37,020 --> 00:13:43,410
example application will be and so we

00:13:41,550 --> 00:13:47,760
will be we create a very simple

00:13:43,410 --> 00:13:49,410
application to order a Tesla cars Tesla

00:13:47,760 --> 00:13:51,420
three models it's quite a fashionable

00:13:49,410 --> 00:13:53,460
thing to do everybody ordered one I

00:13:51,420 --> 00:13:55,980
guess already so we will order one as

00:13:53,460 --> 00:13:59,760
well so the events coming into our

00:13:55,980 --> 00:14:01,620
system will be Tesla orders and we want

00:13:59,760 --> 00:14:05,970
to maintain a list of current orders

00:14:01,620 --> 00:14:08,580
because the this applies quite limited

00:14:05,970 --> 00:14:10,980
we are imposing a limit of one per

00:14:08,580 --> 00:14:13,170
person so we will be storing a name of

00:14:10,980 --> 00:14:15,450
the person who ordered the car and we

00:14:13,170 --> 00:14:20,580
only want to allow one person to order

00:14:15,450 --> 00:14:22,890
one car ok so that's our that's the

00:14:20,580 --> 00:14:25,110
sequel to create our read model right

00:14:22,890 --> 00:14:28,170
our read model has an order stable it

00:14:25,110 --> 00:14:30,680
has each order has an ID at the name of

00:14:28,170 --> 00:14:34,260
the person ordering it ok so that's

00:14:30,680 --> 00:14:36,120
that's quite simple now analysts can go

00:14:34,260 --> 00:14:38,490
and query that and to find out how many

00:14:36,120 --> 00:14:41,730
tests louder's have there been and and

00:14:38,490 --> 00:14:44,010
so on and the second part of the sequel

00:14:41,730 --> 00:14:45,420
model will be the events table so let's

00:14:44,010 --> 00:14:50,330
small s what i have shown on the slide

00:14:45,420 --> 00:14:55,110
is the event ID over here there's the

00:14:50,330 --> 00:14:57,030
civilized case class to jason we have

00:14:55,110 --> 00:15:01,980
the type so that's the name of the case

00:14:57,030 --> 00:15:05,430
class now we have the timestamp and so

00:15:01,980 --> 00:15:10,620
on and also what I have already written

00:15:05,430 --> 00:15:14,360
here is a mapping of the of this table

00:15:10,620 --> 00:15:19,610
of the order table right too slick so

00:15:14,360 --> 00:15:22,620
here's the mapping and you can see that

00:15:19,610 --> 00:15:25,290
we can we have a class orders and it's

00:15:22,620 --> 00:15:27,210
mapped to the orders table and here are

00:15:25,290 --> 00:15:31,380
the field mappings right the ID and the

00:15:27,210 --> 00:15:35,790
name and we have four operations defined

00:15:31,380 --> 00:15:38,010
and we have a final operation it's a DB

00:15:35,790 --> 00:15:42,960
action which returns

00:15:38,010 --> 00:15:46,170
list of orders okay a single order let's

00:15:42,960 --> 00:15:48,090
the mapped that's the mapped class right

00:15:46,170 --> 00:15:52,170
so this corresponds to a role in a in

00:15:48,090 --> 00:15:55,050
our read model and so we have a method

00:15:52,170 --> 00:15:58,200
which returns a description how to find

00:15:55,050 --> 00:16:01,200
all of the orders here's a method which

00:15:58,200 --> 00:16:03,960
returns a description how to find a

00:16:01,200 --> 00:16:07,260
single order for the file for a given

00:16:03,960 --> 00:16:14,910
person okay we will get we will be using

00:16:07,260 --> 00:16:16,410
that in a in a second and okay so and we

00:16:14,910 --> 00:16:19,050
are building the event sourcing system

00:16:16,410 --> 00:16:21,510
at the event source system so we need

00:16:19,050 --> 00:16:25,220
some point of entry into our system so

00:16:21,510 --> 00:16:25,220
that point of entry will be a command

00:16:25,310 --> 00:16:30,510
class commands will have a single

00:16:27,810 --> 00:16:37,110
command for now and will be placed order

00:16:30,510 --> 00:16:39,510
and name string so of course we will be

00:16:37,110 --> 00:16:44,010
exposing this as a REST API but the rest

00:16:39,510 --> 00:16:46,170
api has to invoke our command has to

00:16:44,010 --> 00:16:48,990
invoke the business logic somehow and it

00:16:46,170 --> 00:16:51,900
will do so through a comment okay so we

00:16:48,990 --> 00:16:54,390
have f we have a place order command and

00:16:51,900 --> 00:16:56,430
where we kind of expect what what does

00:16:54,390 --> 00:16:59,940
have to do so what can be the result

00:16:56,430 --> 00:17:02,280
type of a command okay so well the

00:16:59,940 --> 00:17:03,870
comment i can either complete successful

00:17:02,280 --> 00:17:06,660
or fail because of validation errors

00:17:03,870 --> 00:17:11,240
right so we can expect that the result

00:17:06,660 --> 00:17:15,720
types would be either some failure type

00:17:11,240 --> 00:17:18,290
awesome success type right so but then

00:17:15,720 --> 00:17:21,690
during the validation we probably also

00:17:18,290 --> 00:17:26,790
read from the database so we rub that

00:17:21,690 --> 00:17:28,290
into a DB io action alright so let's our

00:17:26,790 --> 00:17:33,480
next candidate for the result type of

00:17:28,290 --> 00:17:35,580
the method but then during like if if if

00:17:33,480 --> 00:17:38,010
the by Dacian past it's quite possible

00:17:35,580 --> 00:17:41,400
that we also want to emit a couple of

00:17:38,010 --> 00:17:44,370
events right so the result should be

00:17:41,400 --> 00:17:46,920
probably something like dbio action and

00:17:44,370 --> 00:17:50,290
we want to return either the success or

00:17:46,920 --> 00:17:53,260
failure description and a list of events

00:17:50,290 --> 00:17:57,610
okay so that's the result that's the

00:17:53,260 --> 00:17:58,990
desired results type and if we already

00:17:57,610 --> 00:18:01,390
have the defined in the library I

00:17:58,990 --> 00:18:04,000
mentioned it's called common result it

00:18:01,390 --> 00:18:07,630
reads nicer than the long type that I

00:18:04,000 --> 00:18:09,790
wrote before is so as a failure type

00:18:07,630 --> 00:18:13,090
will return a string and as a success a

00:18:09,790 --> 00:18:15,420
unit and if we go to see the definition

00:18:13,090 --> 00:18:18,640
you can see that it's a type areas and

00:18:15,420 --> 00:18:20,380
it's more or less what I've written in

00:18:18,640 --> 00:18:24,100
the comments right it's a DB I've action

00:18:20,380 --> 00:18:26,740
so we can read from the database as part

00:18:24,100 --> 00:18:29,770
of validating the data and we return

00:18:26,740 --> 00:18:32,760
either success or failure value plus a

00:18:29,770 --> 00:18:35,320
list of events here's a partial event

00:18:32,760 --> 00:18:37,030
because the events that way I will be

00:18:35,320 --> 00:18:40,800
constructing by hand won't have all the

00:18:37,030 --> 00:18:47,320
meta-data food yet okay so we have the

00:18:40,800 --> 00:18:48,940
our command and so so so so so what do

00:18:47,320 --> 00:18:50,710
we need to do first me to validate the

00:18:48,940 --> 00:18:53,800
data so we will check if the person

00:18:50,710 --> 00:18:56,200
already ordered a Tesla or not so we'll

00:18:53,800 --> 00:19:01,480
add the perimeter here this low order

00:18:56,200 --> 00:19:07,690
model so we do it a slower model find by

00:19:01,480 --> 00:19:11,620
name and the given name and we flat map

00:19:07,690 --> 00:19:16,980
now if the if that person already

00:19:11,620 --> 00:19:20,740
ordered a Tesla then we return a failed

00:19:16,980 --> 00:19:25,290
result command result failed it's simply

00:19:20,740 --> 00:19:34,420
a left on the other side you've already

00:19:25,290 --> 00:19:36,970
ordered one okay and in case in case

00:19:34,420 --> 00:19:39,730
there's no order for the person yet we

00:19:36,970 --> 00:19:43,270
have to emit an event so we'll create an

00:19:39,730 --> 00:19:45,310
event now create an event we actually

00:19:43,270 --> 00:19:49,030
need a way to describe the event so

00:19:45,310 --> 00:19:53,260
let's add as a dead so we will create a

00:19:49,030 --> 00:19:56,320
new event case closed Tesla ordered for

00:19:53,260 --> 00:19:58,360
the person called name so that will be

00:19:56,320 --> 00:20:01,030
our event write it it's a simple case

00:19:58,360 --> 00:20:02,710
class it's in past tense right it says

00:20:01,030 --> 00:20:03,970
that a Tesla has been ordered for the

00:20:02,710 --> 00:20:06,970
given person

00:20:03,970 --> 00:20:08,620
so we created event we wrap it in an

00:20:06,970 --> 00:20:17,910
event as I would say what's within a

00:20:08,620 --> 00:20:24,400
second or third for the name yeah Oh

00:20:17,910 --> 00:20:28,540
Tesla monsters okay so now let's our

00:20:24,400 --> 00:20:30,730
payload and the event actually adds some

00:20:28,540 --> 00:20:33,100
method attitude right the ID the

00:20:30,730 --> 00:20:35,410
aggregate type which is the event type

00:20:33,100 --> 00:20:37,360
which is guests from the class pack and

00:20:35,410 --> 00:20:39,340
so on and we also say that it's a fun

00:20:37,360 --> 00:20:42,460
you aggregate so we auto generate an

00:20:39,340 --> 00:20:45,090
aggregate ID and now we return the

00:20:42,460 --> 00:20:50,710
result so we return the common result

00:20:45,090 --> 00:20:54,130
successful unit plus an event so now we

00:20:50,710 --> 00:20:59,500
have an a command which takes in some

00:20:54,130 --> 00:21:01,060
user data and returns both a success or

00:20:59,500 --> 00:21:04,900
failure value and the list of events

00:21:01,060 --> 00:21:08,680
limited to emit and also we can do some

00:21:04,900 --> 00:21:12,520
database operations as during the

00:21:08,680 --> 00:21:14,530
validation phase right and okay but like

00:21:12,520 --> 00:21:18,400
we didn't really do anything in the

00:21:14,530 --> 00:21:21,130
database yet right we just returned we

00:21:18,400 --> 00:21:24,700
just returned the event itself okay

00:21:21,130 --> 00:21:26,710
we'll wire all things in a second let's

00:21:24,700 --> 00:21:29,290
now think what should happen when the

00:21:26,710 --> 00:21:32,140
event actually is handled by the system

00:21:29,290 --> 00:21:36,460
so first of all we have event listeners

00:21:32,140 --> 00:21:39,460
and we will need an inclusive execution

00:21:36,460 --> 00:21:44,220
context here because you needed always

00:21:39,460 --> 00:21:46,690
everywhere so an event listener is a

00:21:44,220 --> 00:21:49,570
that's where the main business logic is

00:21:46,690 --> 00:21:54,310
and an event listener describes what

00:21:49,570 --> 00:21:56,890
should happen when an event is is it is

00:21:54,310 --> 00:21:59,830
triggered event listeners I meant to be

00:21:56,890 --> 00:22:02,080
run only once when the event happens and

00:21:59,830 --> 00:22:04,540
they can run some side effects for

00:22:02,080 --> 00:22:07,090
example we want to send an email to the

00:22:04,540 --> 00:22:12,060
customer confirming the order so we

00:22:07,090 --> 00:22:15,280
create an event listener send customer

00:22:12,060 --> 00:22:16,410
notification it would be an event

00:22:15,280 --> 00:22:23,920
listener

00:22:16,410 --> 00:22:25,780
for the Tesla ordered and the slower the

00:22:23,920 --> 00:22:27,940
event now what's this type event

00:22:25,780 --> 00:22:31,000
listener again it's a it's a very simple

00:22:27,940 --> 00:22:32,830
type this type areas it's a function

00:22:31,000 --> 00:22:37,510
it's a function which takes an event

00:22:32,830 --> 00:22:39,430
with payload of type T and returns a

00:22:37,510 --> 00:22:42,640
dbio action so we can touch the database

00:22:39,430 --> 00:22:45,220
we can read from the database and we can

00:22:42,640 --> 00:22:48,520
emit some some more events okay but we

00:22:45,220 --> 00:22:49,810
won't do that now and also what's very

00:22:48,520 --> 00:22:52,210
nice and slick and what we are using

00:22:49,810 --> 00:22:53,890
here is you probably know so that it has

00:22:52,210 --> 00:22:56,980
three type parameters right that's the

00:22:53,890 --> 00:22:59,290
type of the the results type of what's

00:22:56,980 --> 00:23:02,020
the result of the computation but here

00:22:59,290 --> 00:23:05,920
we also can control if we can retool it

00:23:02,020 --> 00:23:08,830
from the database or also right so an

00:23:05,920 --> 00:23:10,480
event listener can only read from the

00:23:08,830 --> 00:23:13,030
database it cannot write the data bit

00:23:10,480 --> 00:23:24,610
right it can only read data from the

00:23:13,030 --> 00:23:27,910
read model ok so our event listener is a

00:23:24,610 --> 00:23:29,890
function so we take in the event so

00:23:27,910 --> 00:23:32,170
that's the event of with the payload

00:23:29,890 --> 00:23:37,950
Tesla ordered and what we will do we

00:23:32,170 --> 00:23:43,860
will send email service send email your

00:23:37,950 --> 00:23:51,070
Tesla Model 3 will be ready in a couple

00:23:43,860 --> 00:23:53,440
of years right and so that's like a

00:23:51,070 --> 00:23:55,750
let's say this sends an email it has a

00:23:53,440 --> 00:23:57,520
it actually only right to the console

00:23:55,750 --> 00:23:59,830
but let's say it sends an email it

00:23:57,520 --> 00:24:02,050
really it returns the future now we need

00:23:59,830 --> 00:24:04,690
to convert this future into a dbl action

00:24:02,050 --> 00:24:08,530
and we actually have a method for that

00:24:04,690 --> 00:24:13,210
so we do a DB IO action dot from and

00:24:08,530 --> 00:24:15,940
this converts a future to a dbio action

00:24:13,210 --> 00:24:18,070
ok and we are not emitting an event so

00:24:15,940 --> 00:24:20,260
we are mapping the unit result to an

00:24:18,070 --> 00:24:21,580
empty list of events ok so that's an

00:24:20,260 --> 00:24:24,070
event listener that we want to be

00:24:21,580 --> 00:24:26,770
triggered whenever our event happens

00:24:24,070 --> 00:24:29,740
that's like kind of the side effects now

00:24:26,770 --> 00:24:30,250
we also need another kind of this node

00:24:29,740 --> 00:24:33,760
actually

00:24:30,250 --> 00:24:39,370
updates the read model so what we need

00:24:33,760 --> 00:24:45,280
is we need the model updates class tesla

00:24:39,370 --> 00:24:48,850
model okay we will have an order ordered

00:24:45,280 --> 00:24:52,180
update which is a model update another

00:24:48,850 --> 00:24:56,710
type RS which we are shown a second test

00:24:52,180 --> 00:24:59,200
order and now a model update it's again

00:24:56,710 --> 00:25:03,910
a type areas it's a function so it's a

00:24:59,200 --> 00:25:05,440
simple function right it's nothing very

00:25:03,910 --> 00:25:07,300
complicated you don't have to extend

00:25:05,440 --> 00:25:10,930
anything it's a simple scalar function

00:25:07,300 --> 00:25:14,560
it takes in an event with payload d and

00:25:10,930 --> 00:25:17,440
returns a description of how to update

00:25:14,560 --> 00:25:19,840
the read model notice that we can both

00:25:17,440 --> 00:25:23,770
read and write here to the database

00:25:19,840 --> 00:25:26,830
right and ok so it's would be quite a

00:25:23,770 --> 00:25:29,290
simple thing to do and when we take in

00:25:26,830 --> 00:25:33,730
the event we take the tesla order model

00:25:29,290 --> 00:25:39,120
and we insert a new row and the nero

00:25:33,730 --> 00:25:42,130
will be a tesla order and the ID of the

00:25:39,120 --> 00:25:48,520
of the row in the reed model will be the

00:25:42,130 --> 00:25:50,560
aggregate ID and the name will be itõs

00:25:48,520 --> 00:25:53,590
data that name that's the name from the

00:25:50,560 --> 00:25:56,170
event and there's no additional

00:25:53,590 --> 00:26:00,520
equipment ok so now we have a way to

00:25:56,170 --> 00:26:02,260
update update our read model now we need

00:26:00,520 --> 00:26:03,970
some kind is some kind of way to tie it

00:26:02,260 --> 00:26:06,820
all together ok we need some kind of

00:26:03,970 --> 00:26:08,650
registry which which says that when an

00:26:06,820 --> 00:26:10,570
event happens these events listeners

00:26:08,650 --> 00:26:12,580
should be run and this model updates to

00:26:10,570 --> 00:26:15,040
drop write all that we have done so far

00:26:12,580 --> 00:26:17,920
is write some blues functions and we

00:26:15,040 --> 00:26:21,520
need to get them together so that's

00:26:17,920 --> 00:26:28,570
where the registry comes in so you think

00:26:21,520 --> 00:26:29,800
the registry just change here ok and so

00:26:28,570 --> 00:26:34,480
what we need to do is we create

00:26:29,800 --> 00:26:37,810
instances of the commands new commands

00:26:34,480 --> 00:26:39,640
and the parameter here is the slower

00:26:37,810 --> 00:26:43,320
model

00:26:39,640 --> 00:26:49,690
and we need an instance of event

00:26:43,320 --> 00:26:56,740
listeners and we need an instance of

00:26:49,690 --> 00:26:59,050
model updates okay now we have a

00:26:56,740 --> 00:27:01,600
registry that also comes from from the

00:26:59,050 --> 00:27:03,820
library but it's a simple map from it's

00:27:01,600 --> 00:27:06,820
like multiple maps from event type to

00:27:03,820 --> 00:27:08,650
event listeners model updates has

00:27:06,820 --> 00:27:10,720
methods like we're just event listener

00:27:08,650 --> 00:27:14,040
and we pass in the function right be

00:27:10,720 --> 00:27:18,190
passing the function event listeners dot

00:27:14,040 --> 00:27:21,370
send customer notification and we also

00:27:18,190 --> 00:27:25,720
register a modern update model updates

00:27:21,370 --> 00:27:28,120
don't ordered update okay we line it up

00:27:25,720 --> 00:27:29,800
nicely okay so we now have the registry

00:27:28,120 --> 00:27:32,110
so now the last piece of the puzzle

00:27:29,800 --> 00:27:34,650
that's missing we need some kind of

00:27:32,110 --> 00:27:37,990
method which takes in the registry right

00:27:34,650 --> 00:27:41,410
takes in a command result failure

00:27:37,990 --> 00:27:43,870
success so we have the registry we have

00:27:41,410 --> 00:27:46,390
the common result which describes as how

00:27:43,870 --> 00:27:48,310
to produce the events right so we need

00:27:46,390 --> 00:27:51,550
now to actually write the vents to the

00:27:48,310 --> 00:27:53,410
events table to random event listeners

00:27:51,550 --> 00:27:57,400
from the model updates and return us a

00:27:53,410 --> 00:27:59,080
future either failure success okay in

00:27:57,400 --> 00:28:00,730
that future when that picture is

00:27:59,080 --> 00:28:02,980
complete we expect to have everything

00:28:00,730 --> 00:28:04,870
the transaction complete everything in

00:28:02,980 --> 00:28:08,890
the database the read model updated the

00:28:04,870 --> 00:28:12,700
events in the in the database and that's

00:28:08,890 --> 00:28:15,550
already written in the in the library

00:28:12,700 --> 00:28:18,400
mentioned there's an event machine which

00:28:15,550 --> 00:28:20,200
among other things which you don't have

00:28:18,400 --> 00:28:23,830
to worry about right now takes an error

00:28:20,200 --> 00:28:27,490
it takes in a registry it has a run

00:28:23,830 --> 00:28:31,510
method which takes a common result right

00:28:27,490 --> 00:28:34,660
and returns the future at the dimension

00:28:31,510 --> 00:28:37,990
okay and we will use that in our HTTP

00:28:34,660 --> 00:28:41,710
routes to actually run a run the result

00:28:37,990 --> 00:28:44,020
of the command result okay so so so and

00:28:41,710 --> 00:28:46,840
now let's why things up to actually see

00:28:44,020 --> 00:28:53,020
it working so here i have a very simple

00:28:46,840 --> 00:28:55,900
route HD archives TTP roads to

00:28:53,020 --> 00:28:59,560
place an order and list orders so we

00:28:55,900 --> 00:29:02,310
will need some passing some parameters

00:28:59,560 --> 00:29:05,860
to this route we need the events

00:29:02,310 --> 00:29:08,860
database will need the event machine

00:29:05,860 --> 00:29:15,040
which I mentioned we need the Tesla

00:29:08,860 --> 00:29:18,780
order model and the commands ok so now

00:29:15,040 --> 00:29:22,650
first when we want to list orders and

00:29:18,780 --> 00:29:25,600
what we need to do is we need to first

00:29:22,650 --> 00:29:27,670
get the Tesla order model so we will

00:29:25,600 --> 00:29:31,030
want to display all on the web page a

00:29:27,670 --> 00:29:36,330
list of all orders currently placed so

00:29:31,030 --> 00:29:41,320
we get the Tesla order model and dot

00:29:36,330 --> 00:29:44,170
find all and now we want to wait for

00:29:41,320 --> 00:29:45,940
that so we need to run it because now

00:29:44,170 --> 00:29:48,400
that only a description of how to read

00:29:45,940 --> 00:29:51,100
all the orders so we need to run that so

00:29:48,400 --> 00:29:54,910
we're an events database toad db2 run

00:29:51,100 --> 00:29:56,980
and now we have to wait when that's

00:29:54,910 --> 00:30:00,790
complete so there's a directive for

00:29:56,980 --> 00:30:05,040
waiting for future and we get a list of

00:30:00,790 --> 00:30:10,420
orders and we complete when the orders

00:30:05,040 --> 00:30:20,809
not map name and will be simple I'm

00:30:10,420 --> 00:30:23,470
constraint okay yeah and

00:30:20,809 --> 00:30:23,470
No

00:30:23,670 --> 00:30:30,470
you

00:30:25,350 --> 00:30:34,230
name is something one sucks on success

00:30:30,470 --> 00:30:37,830
yep and now over here we accept any

00:30:34,230 --> 00:30:40,380
order right we that at a post endpoint

00:30:37,830 --> 00:30:41,880
we get the data from the body the data

00:30:40,380 --> 00:30:46,820
from the body is the name of the person

00:30:41,880 --> 00:30:50,039
who ordered so now what we do is we

00:30:46,820 --> 00:30:51,960
create our command place order that's

00:30:50,039 --> 00:30:55,289
only a description of what events should

00:30:51,960 --> 00:30:59,429
be emitted right so we need to run the

00:30:55,289 --> 00:31:03,570
choosing the event machine run and again

00:30:59,429 --> 00:31:12,289
we use on success to unwrap the future

00:31:03,570 --> 00:31:19,860
and when we get an error we complete

00:31:12,289 --> 00:31:24,870
using status codes bed there's no better

00:31:19,860 --> 00:31:30,360
request and error and if there is no

00:31:24,870 --> 00:31:32,760
error and we complete okay so we create

00:31:30,360 --> 00:31:36,330
a description of how two of which event

00:31:32,760 --> 00:31:37,799
should be produced we run it through the

00:31:36,330 --> 00:31:39,390
event machine which actually persists

00:31:37,799 --> 00:31:41,520
the event and does the changes to the

00:31:39,390 --> 00:31:44,070
read model advanced event listeners and

00:31:41,520 --> 00:31:45,720
we then return the result of the user so

00:31:44,070 --> 00:31:49,860
now let's try to compile it there will

00:31:45,720 --> 00:31:53,600
be for sure some errors of course so we

00:31:49,860 --> 00:31:59,220
are missing parameters here events

00:31:53,600 --> 00:32:04,590
database and event machine and Tesla

00:31:59,220 --> 00:32:09,480
order model and commands so we need to

00:32:04,590 --> 00:32:13,909
instantiate that and ok so here we need

00:32:09,480 --> 00:32:16,909
a way to add some meta data to the event

00:32:13,909 --> 00:32:20,610
saying which order was dead so we need

00:32:16,909 --> 00:32:23,370
to specify the the aggregate for that

00:32:20,610 --> 00:32:25,770
event so the compiler has no way of

00:32:23,370 --> 00:32:29,190
knowing that so one way of doing that is

00:32:25,770 --> 00:32:32,580
in the companion object can create an

00:32:29,190 --> 00:32:35,909
implicit aggregate for event marker

00:32:32,580 --> 00:32:38,460
object that's the order is for the tests

00:32:35,909 --> 00:32:39,130
laughs order so here we specify that the

00:32:38,460 --> 00:32:43,840
test

00:32:39,130 --> 00:32:49,420
ordered event is a a gratuitous ordered

00:32:43,840 --> 00:32:55,570
event is the Tesla order class and an

00:32:49,420 --> 00:32:59,080
execution context of course I'm sure

00:32:55,570 --> 00:33:06,280
your spend your time on fixing bugs like

00:32:59,080 --> 00:33:13,120
that work ok so now let's just me

00:33:06,280 --> 00:33:23,350
quickly remove all the data ok and now

00:33:13,120 --> 00:33:25,750
we can run run this thing main ok so

00:33:23,350 --> 00:33:29,290
let's running and now we can go to

00:33:25,750 --> 00:33:37,200
localhost 8080 and we can place our

00:33:29,290 --> 00:33:45,570
orders so we can say for me for example

00:33:37,200 --> 00:33:45,570
nothing happened no

00:33:45,799 --> 00:33:51,739
it should happen of course for some

00:33:48,529 --> 00:33:56,629
reason it doesn't work but for that case

00:33:51,739 --> 00:34:01,879
I have another class right here I'm at

00:33:56,629 --> 00:34:03,200
film it's like something so that's

00:34:01,879 --> 00:34:08,059
almost the same code that's running now

00:34:03,200 --> 00:34:10,730
but it's working no it's not would you

00:34:08,059 --> 00:34:15,679
believe me it always worked it always

00:34:10,730 --> 00:34:20,000
worked before well anyway what you

00:34:15,679 --> 00:34:22,159
should see what you should see is some

00:34:20,000 --> 00:34:24,740
information getting out here about the

00:34:22,159 --> 00:34:27,500
event being persisted and we end the

00:34:24,740 --> 00:34:33,609
model being updated and the list of

00:34:27,500 --> 00:34:38,440
course being updated and so this work

00:34:33,609 --> 00:34:43,760
because I'm not doing a pause and then

00:34:38,440 --> 00:34:51,679
well anyway it always worked and so

00:34:43,760 --> 00:34:54,109
going back over here okay so what are

00:34:51,679 --> 00:34:57,309
the potential problems with such

00:34:54,109 --> 00:35:00,349
approach so first of all the ordering of

00:34:57,309 --> 00:35:02,809
concurrent events operating on the same

00:35:00,349 --> 00:35:05,240
aggregate route might be problematic if

00:35:02,809 --> 00:35:08,569
you have a couple of events coming in at

00:35:05,240 --> 00:35:10,970
the same time and they and they are for

00:35:08,569 --> 00:35:13,280
the same aggregate route instance so for

00:35:10,970 --> 00:35:15,710
the same ID so we can get a different

00:35:13,280 --> 00:35:17,329
order of them being applied in a real

00:35:15,710 --> 00:35:20,930
system and a different order when you

00:35:17,329 --> 00:35:22,849
when you replay so there are some ways

00:35:20,930 --> 00:35:25,450
of course to fix that either by using

00:35:22,849 --> 00:35:27,890
pessimistic optimistic locking and

00:35:25,450 --> 00:35:31,210
whether you want to do that or not three

00:35:27,890 --> 00:35:33,650
you know depends on on your use case and

00:35:31,210 --> 00:35:35,780
also some people don't like that the

00:35:33,650 --> 00:35:39,799
ebay auction kind of leaks quite high

00:35:35,780 --> 00:35:41,930
into your into your code base so but you

00:35:39,799 --> 00:35:44,540
can think of it as a non fit as a

00:35:41,930 --> 00:35:47,450
feature actuary and because then you

00:35:44,540 --> 00:35:49,730
know that the code that that you have

00:35:47,450 --> 00:35:52,040
it's that it actually touches the

00:35:49,730 --> 00:35:56,420
database right so maybe that's a good

00:35:52,040 --> 00:35:58,819
thing to know and another problem is the

00:35:56,420 --> 00:35:59,770
way you can rub futures from a DVI

00:35:58,819 --> 00:36:01,810
auction

00:35:59,770 --> 00:36:03,760
it's not really perfect because it's run

00:36:01,810 --> 00:36:07,030
its wrapping and already running future

00:36:03,760 --> 00:36:08,200
so it's not really Glenn Europe a future

00:36:07,030 --> 00:36:09,640
with the direction it's not really a

00:36:08,200 --> 00:36:11,710
description of a computation it's a

00:36:09,640 --> 00:36:15,520
running computation but that's our like

00:36:11,710 --> 00:36:17,440
probably more minor points and okay so

00:36:15,520 --> 00:36:22,630
summing up and the approach i have shown

00:36:17,440 --> 00:36:26,380
we have three main functions involved so

00:36:22,630 --> 00:36:30,000
and these are a quite simple functions

00:36:26,380 --> 00:36:32,890
you don't need much like scaffolding to

00:36:30,000 --> 00:36:36,370
to build that so we have the commands a

00:36:32,890 --> 00:36:39,670
command takes and user data validates it

00:36:36,370 --> 00:36:41,470
returns a success or failure result plus

00:36:39,670 --> 00:36:45,370
a list of events then you have another

00:36:41,470 --> 00:36:47,200
function which takes an event the event

00:36:45,370 --> 00:36:49,450
listeners which takes an event and

00:36:47,200 --> 00:36:53,560
returns but it does some side effects

00:36:49,450 --> 00:36:55,270
like sending an email and it returns a

00:36:53,560 --> 00:36:58,780
list of events which can be emitted and

00:36:55,270 --> 00:37:02,620
you have the model updates a function

00:36:58,780 --> 00:37:05,050
which which actually updates our read

00:37:02,620 --> 00:37:06,640
model and these are the main distinction

00:37:05,050 --> 00:37:08,650
between the event assess and the model

00:37:06,640 --> 00:37:10,420
updates is that you can run you can

00:37:08,650 --> 00:37:12,280
rerun the model updates multiple times

00:37:10,420 --> 00:37:14,080
to bring your model to a certain point

00:37:12,280 --> 00:37:16,990
in time while the event listeners should

00:37:14,080 --> 00:37:18,430
be probably only run once right when the

00:37:16,990 --> 00:37:22,930
event actually happens because that's

00:37:18,430 --> 00:37:26,350
what side effects happen and here are

00:37:22,930 --> 00:37:28,090
some links so the library is that I've

00:37:26,350 --> 00:37:30,940
used slick event sourcing is open source

00:37:28,090 --> 00:37:32,680
as I said it's the code is quite short

00:37:30,940 --> 00:37:34,540
probably they read me and the blog which

00:37:32,680 --> 00:37:38,050
described functionality are longer than

00:37:34,540 --> 00:37:42,640
the code it's only a skeleton and as I

00:37:38,050 --> 00:37:45,730
mentioned the slides the material that I

00:37:42,640 --> 00:37:50,200
use here in a working form hopefully is

00:37:45,730 --> 00:37:53,100
also on github and that's that

00:37:50,200 --> 00:37:55,360
everything is I had is so once again

00:37:53,100 --> 00:37:57,730
please remember to rate the sessions

00:37:55,360 --> 00:38:00,640
it's very valuable input both for the

00:37:57,730 --> 00:38:03,940
organizers and for the presenters so for

00:38:00,640 --> 00:38:06,640
me so please do that and if you have any

00:38:03,940 --> 00:38:08,380
questions I'm either here now or to the

00:38:06,640 --> 00:38:10,460
end of the conference and even a couple

00:38:08,380 --> 00:38:12,140
days later

00:38:10,460 --> 00:38:21,800
if you will be looking for me in New

00:38:12,140 --> 00:38:24,680
York so any questions yeah we usually

00:38:21,800 --> 00:38:28,070
use tries for our hand like instead of

00:38:24,680 --> 00:38:31,400
either's do you see a way we could still

00:38:28,070 --> 00:38:34,700
use your library if you want to use a

00:38:31,400 --> 00:38:37,849
try for failure handing me I guess it's

00:38:34,700 --> 00:38:41,660
a kind of different failures it writes

00:38:37,849 --> 00:38:44,660
because in a try that's when you want to

00:38:41,660 --> 00:38:48,470
capture some exception and i'm not sure

00:38:44,660 --> 00:38:52,970
if you use exceptions for data

00:38:48,470 --> 00:38:56,869
validation as well we normal view here

00:38:52,970 --> 00:38:58,849
and well one thing that you can do as I

00:38:56,869 --> 00:39:01,339
said well it is an it is a template so

00:38:58,849 --> 00:39:03,290
you can customize it and but the DVR

00:39:01,339 --> 00:39:05,660
action also has a failed state I think

00:39:03,290 --> 00:39:08,500
so maybe you can use that to propagate

00:39:05,660 --> 00:39:10,160
the errors and impact on that and

00:39:08,500 --> 00:39:12,619
although the exception would be

00:39:10,160 --> 00:39:18,050
restaurant then so the future would be

00:39:12,619 --> 00:39:21,140
Faith and and okay I would have to think

00:39:18,050 --> 00:39:28,810
about it so maybe we can talk after okay

00:39:21,140 --> 00:39:28,810
thank you any more questions

00:39:29,590 --> 00:39:34,440
okay then thank you very much and invite

00:39:31,960 --> 00:39:34,440
the conference

00:39:39,099 --> 00:39:41,160
you

00:39:50,060 --> 00:39:52,120

YouTube URL: https://www.youtube.com/watch?v=RGqr1cXjS5o


