Title: @inline and @specialized: What do they do? Should I be using them? - by Chris Birchall
Publication date: 2016-06-17
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.

Abstract:
You may have seen the @inline and @specialized annotations used in Scala code, and have some idea that they are added for performance reasons. But the exact details of what they do is not widely known, and it's hard to estimate whether they will provide a real performance benefit to your code.
 
This talk will: explain exactly what the annotations do; provide some examples of how to use them; and use benchmarks to explore how they affect performance.
 
There will also be honourable mentions for some of the more esoteric Scala annotations such as @elidable, @strictfp, @switch and @varargs.
Captions: 
	00:00:12,030 --> 00:00:17,100
so the talk is in two parts we're going

00:00:13,770 --> 00:00:19,020
to look at inlining first we'll talk

00:00:17,100 --> 00:00:20,310
about what inlining is in general and

00:00:19,020 --> 00:00:22,980
then we'll look more specifically at

00:00:20,310 --> 00:00:25,739
inlining on the JVM and how you do it in

00:00:22,980 --> 00:00:27,540
Scala and then finally we'll look at

00:00:25,739 --> 00:00:29,939
some benchmarks to see whether it's

00:00:27,540 --> 00:00:31,800
worth doing and what kind of effect it

00:00:29,939 --> 00:00:35,100
has on your you'll cut the performance

00:00:31,800 --> 00:00:38,040
of your code and then the second half of

00:00:35,100 --> 00:00:40,200
the talk is specialization which I spell

00:00:38,040 --> 00:00:45,269
quite inconsistent ly so apologies for

00:00:40,200 --> 00:00:47,089
that before we look at specialization

00:00:45,269 --> 00:00:49,410
itself we'll look at a bit of background

00:00:47,089 --> 00:00:52,379
like what the problem is that

00:00:49,410 --> 00:00:54,510
specialization solves then we'll look at

00:00:52,379 --> 00:00:58,079
how it works in Scala and again we'll

00:00:54,510 --> 00:00:59,519
look at a few benchmarks on the right

00:00:58,079 --> 00:01:02,219
hand side there is a warning there is

00:00:59,519 --> 00:01:04,350
bytecode in this presentation

00:01:02,219 --> 00:01:06,540
it's the final session of the day your

00:01:04,350 --> 00:01:08,880
brains are fried you just want to go and

00:01:06,540 --> 00:01:11,310
drink free beer at the party so that

00:01:08,880 --> 00:01:14,300
sauce that sit in a big dark room and

00:01:11,310 --> 00:01:14,300
stare at byte code

00:01:18,460 --> 00:01:24,130
just quick self-introduction I'm Chris

00:01:21,100 --> 00:01:27,340
virtual I work at the Guardian in London

00:01:24,130 --> 00:01:34,270
which is a newspaper and also a very

00:01:27,340 --> 00:01:35,680
popular online news resource we use

00:01:34,270 --> 00:01:37,630
Scala very heavily at the Guardian

00:01:35,680 --> 00:01:40,630
everything from the front end to the

00:01:37,630 --> 00:01:42,550
back end API is to the in-house CMS that

00:01:40,630 --> 00:01:44,040
we've built all of our monitoring tools

00:01:42,550 --> 00:01:46,360
pretty much everything is in together

00:01:44,040 --> 00:01:48,720
and we were very early adopter of

00:01:46,360 --> 00:01:53,320
scarlet we've been using it for years

00:01:48,720 --> 00:01:54,850
also my book is out recently so nothing

00:01:53,320 --> 00:02:01,570
to do with Scala but please buy it

00:01:54,850 --> 00:02:03,759
anyway so one question you should ask

00:02:01,570 --> 00:02:06,360
before you agree to listen to me for the

00:02:03,759 --> 00:02:08,619
next 45 minutes is why should you care

00:02:06,360 --> 00:02:10,739
why is it worth learning about these

00:02:08,619 --> 00:02:13,560
things in line and specialization and

00:02:10,739 --> 00:02:15,940
performance and optimization and so on

00:02:13,560 --> 00:02:21,489
and the answer is that performance

00:02:15,940 --> 00:02:23,920
matters sometimes so I come from a Java

00:02:21,489 --> 00:02:27,610
background and back in the bad old days

00:02:23,920 --> 00:02:29,650
when I was writing Java I was thinking

00:02:27,610 --> 00:02:31,420
about performance pretty much all the

00:02:29,650 --> 00:02:32,860
time it was quite a high priority like

00:02:31,420 --> 00:02:34,750
every time you wrote a bit of code in

00:02:32,860 --> 00:02:36,340
the back your mind you'd be thinking how

00:02:34,750 --> 00:02:39,370
is this performing am I using the right

00:02:36,340 --> 00:02:41,310
things a structure or am i looping in

00:02:39,370 --> 00:02:44,170
the correct way and and so on but then

00:02:41,310 --> 00:02:45,640
when I moved to skull or I went through

00:02:44,170 --> 00:02:48,040
a kind of honeymoon period where

00:02:45,640 --> 00:02:49,390
everything was suddenly immutable and

00:02:48,040 --> 00:02:51,660
functional and I had these nice

00:02:49,390 --> 00:02:54,220
primitives like map and filter and

00:02:51,660 --> 00:02:56,049
suddenly elegance became the top

00:02:54,220 --> 00:02:59,380
priority and performance was not that

00:02:56,049 --> 00:03:01,600
important and I think in a lot of cases

00:02:59,380 --> 00:03:05,340
this is valid this is totally fine

00:03:01,600 --> 00:03:08,560
unless you have real performance

00:03:05,340 --> 00:03:10,840
requirements or your your application is

00:03:08,560 --> 00:03:12,579
really struggling to perform to users

00:03:10,840 --> 00:03:13,299
expectations then fine don't worry about

00:03:12,579 --> 00:03:15,940
performance

00:03:13,299 --> 00:03:18,250
don't prematurely optimize but

00:03:15,940 --> 00:03:21,070
occasionally there are times when you

00:03:18,250 --> 00:03:24,190
need to worry about these things and in

00:03:21,070 --> 00:03:25,570
those cases you need to know how your

00:03:24,190 --> 00:03:27,519
code how your Scala code is actually

00:03:25,570 --> 00:03:28,950
compiled into byte code how it's running

00:03:27,519 --> 00:03:32,910
on the CPU

00:03:28,950 --> 00:03:39,930
and what kind of optimizations you can

00:03:32,910 --> 00:03:41,849
use to make it perform better so without

00:03:39,930 --> 00:03:46,140
further ado let's have a look at

00:03:41,849 --> 00:03:48,660
inlining so what is inlining basically

00:03:46,140 --> 00:03:51,560
it is removing a function call from your

00:03:48,660 --> 00:03:54,239
program by copying the functions body

00:03:51,560 --> 00:03:57,540
into all of the places where where the

00:03:54,239 --> 00:03:59,910
function is called so I have a quick

00:03:57,540 --> 00:04:01,970
example here we've got a target function

00:03:59,910 --> 00:04:04,739
this is the thing that we want to inline

00:04:01,970 --> 00:04:09,180
and then we have another function that

00:04:04,739 --> 00:04:10,860
is calling it and then after inlining

00:04:09,180 --> 00:04:11,519
you can see that the function call has

00:04:10,860 --> 00:04:14,940
disappeared

00:04:11,519 --> 00:04:16,950
and the the body of the inline function

00:04:14,940 --> 00:04:19,620
has been copied into the call site with

00:04:16,950 --> 00:04:24,570
obviously that a and B being turned into

00:04:19,620 --> 00:04:26,850
x and y I mean just for the sake of the

00:04:24,570 --> 00:04:29,520
song the example I've shown the inlining

00:04:26,850 --> 00:04:30,870
happening to your source code like karla

00:04:29,520 --> 00:04:32,639
source being transformed into other

00:04:30,870 --> 00:04:34,800
scalar source but of course this is not

00:04:32,639 --> 00:04:37,500
what actually happens your source code

00:04:34,800 --> 00:04:39,570
is what you write on the left hand side

00:04:37,500 --> 00:04:42,389
and the the inlining happens at the

00:04:39,570 --> 00:04:47,910
level of JVM bytecode or possibly at the

00:04:42,389 --> 00:04:50,400
level of assembly so this is inlining

00:04:47,910 --> 00:04:54,060
why would you want to do that why does

00:04:50,400 --> 00:04:55,800
why is this good for your code there's a

00:04:54,060 --> 00:04:58,979
couple of reasons which we'll look at in

00:04:55,800 --> 00:05:01,530
detail in a second one is that it's

00:04:58,979 --> 00:05:04,080
simply it removes the overhead of making

00:05:01,530 --> 00:05:06,539
the function call every time you call a

00:05:04,080 --> 00:05:08,789
function there is a certain overhead

00:05:06,539 --> 00:05:10,979
cost associated with that and if you can

00:05:08,789 --> 00:05:15,780
get rid of the function call then your

00:05:10,979 --> 00:05:18,830
program will run faster so functions are

00:05:15,780 --> 00:05:18,830
bad remember that

00:05:19,970 --> 00:05:24,710
and the second and probably more

00:05:21,890 --> 00:05:27,320
important reason is that it's an enabler

00:05:24,710 --> 00:05:31,850
for other more powerful optimizations to

00:05:27,320 --> 00:05:34,790
take place compilers or optimizers are

00:05:31,850 --> 00:05:37,370
quite good at optimizing within the

00:05:34,790 --> 00:05:39,250
within one function but then as soon as

00:05:37,370 --> 00:05:41,570
you start crossing the function boundary

00:05:39,250 --> 00:05:43,970
you try and compile across the whole

00:05:41,570 --> 00:05:45,710
program across multiple functions sorry

00:05:43,970 --> 00:05:48,080
optimize across multiple functions it

00:05:45,710 --> 00:05:50,300
becomes very difficult or even near

00:05:48,080 --> 00:05:52,520
impossible so if you can get rid of that

00:05:50,300 --> 00:05:55,130
function boundary so that all of your

00:05:52,520 --> 00:05:57,800
code is is now within the confines of

00:05:55,130 --> 00:06:02,480
one function then it becomes easier to

00:05:57,800 --> 00:06:05,120
optimize and it's worth pointing out

00:06:02,480 --> 00:06:06,980
that inlining is a kind of a classic

00:06:05,120 --> 00:06:09,230
optimization it's been around since the

00:06:06,980 --> 00:06:11,570
Stone Age it's not related to the JVM or

00:06:09,230 --> 00:06:17,840
Scala in particular it's it's been done

00:06:11,570 --> 00:06:21,740
since CEO yes so here's our first bit of

00:06:17,840 --> 00:06:23,150
bytecode we have the same sample that we

00:06:21,740 --> 00:06:25,550
had just now we've got our target

00:06:23,150 --> 00:06:27,100
function and our caller function and on

00:06:25,550 --> 00:06:32,600
the bottom left hand side you can see

00:06:27,100 --> 00:06:35,870
the bytecode for those functions I won't

00:06:32,600 --> 00:06:38,300
go into them in massive detail but you

00:06:35,870 --> 00:06:40,160
can see that after inlining there's a

00:06:38,300 --> 00:06:41,450
lot less bytecode for a start so that's

00:06:40,160 --> 00:06:44,210
a good thing there's less stuff to

00:06:41,450 --> 00:06:46,700
execute most importantly the things

00:06:44,210 --> 00:06:47,510
circled in red the invoke virtual has

00:06:46,700 --> 00:06:51,560
disappeared

00:06:47,510 --> 00:06:54,760
now this invoke virtual is the bytecode

00:06:51,560 --> 00:06:56,570
used to call a virtual function

00:06:54,760 --> 00:06:57,860
depending on what kind of function

00:06:56,570 --> 00:07:02,630
you're calling it'll be either invoke

00:06:57,860 --> 00:07:04,250
special or in both virtual and getting

00:07:02,630 --> 00:07:08,810
rid of this means that we've got rid of

00:07:04,250 --> 00:07:11,360
a lot of overhead so if we have a look

00:07:08,810 --> 00:07:14,240
at the JVM spec for in both invoke

00:07:11,360 --> 00:07:19,100
virtual we can see exactly why it's bad

00:07:14,240 --> 00:07:22,130
and we want to get rid of it so the

00:07:19,100 --> 00:07:24,740
three things circled in red are what the

00:07:22,130 --> 00:07:27,260
JVM needs to do when it invokes a

00:07:24,740 --> 00:07:29,270
virtual function so the first one is

00:07:27,260 --> 00:07:29,840
lookup it needs to find the function

00:07:29,270 --> 00:07:33,020
because

00:07:29,840 --> 00:07:34,310
it may not be defined on the concrete

00:07:33,020 --> 00:07:35,600
class that you're actually dealing with

00:07:34,310 --> 00:07:39,470
it might be higher up that type

00:07:35,600 --> 00:07:41,930
hierarchy so it needs to find it then it

00:07:39,470 --> 00:07:45,880
says a new frame is created on the Java

00:07:41,930 --> 00:07:49,130
Virtual Machine stack so this is like

00:07:45,880 --> 00:07:50,600
stack being allocated memory being

00:07:49,130 --> 00:07:53,870
allocated so that's obviously going to

00:07:50,600 --> 00:07:56,840
have a cost associated and then finally

00:07:53,870 --> 00:07:59,840
it says the Java Virtual Machine PC is

00:07:56,840 --> 00:08:01,790
set in pcs program counter and what this

00:07:59,840 --> 00:08:05,830
means is that your program is doing a

00:08:01,790 --> 00:08:09,440
jump and a jump is kryptonite for CPUs

00:08:05,830 --> 00:08:10,880
the one thing that your CPU wants to

00:08:09,440 --> 00:08:13,220
believe about your program is that

00:08:10,880 --> 00:08:14,260
whatever it's doing now it will continue

00:08:13,220 --> 00:08:17,570
to do in the future

00:08:14,260 --> 00:08:19,220
so if you're executing this instruction

00:08:17,570 --> 00:08:21,770
and then this instruction and then this

00:08:19,220 --> 00:08:25,010
instruction the CPU thinks our I spot a

00:08:21,770 --> 00:08:28,010
pattern here and it starts to pre catch

00:08:25,010 --> 00:08:29,449
the next few instructions it assumes

00:08:28,010 --> 00:08:32,089
that you'll keep doing this but then

00:08:29,449 --> 00:08:33,860
suddenly bang you jump over here and it

00:08:32,089 --> 00:08:36,620
hasn't cashed any of these things so it

00:08:33,860 --> 00:08:40,250
needs to suddenly fetch those from from

00:08:36,620 --> 00:08:43,839
main memory and start start executing

00:08:40,250 --> 00:08:43,839
over here so that's quite expensive

00:08:47,160 --> 00:08:52,620
and the other benefit of inlining that I

00:08:50,730 --> 00:08:56,030
mentioned is that it enables other

00:08:52,620 --> 00:09:00,180
optimizations to take place so just a

00:08:56,030 --> 00:09:03,960
here on the left-hand side we have a

00:09:00,180 --> 00:09:07,500
Class A with a field X and a method plus

00:09:03,960 --> 00:09:09,870
one and then we have some other method

00:09:07,500 --> 00:09:12,840
sum function which calls this it

00:09:09,870 --> 00:09:16,800
instantiates a new a with the exit to

00:09:12,840 --> 00:09:21,450
one and calls plus one so step one

00:09:16,800 --> 00:09:24,450
inlining you can get rid of the function

00:09:21,450 --> 00:09:27,780
call two plus one just replace it with X

00:09:24,450 --> 00:09:30,540
plus one and then as soon as you've done

00:09:27,780 --> 00:09:32,520
that hotspots escape analysis can kick

00:09:30,540 --> 00:09:35,910
in realize that you didn't even need to

00:09:32,520 --> 00:09:39,720
allocate a new a you can just reduce the

00:09:35,910 --> 00:09:42,780
whole thing down to one plus one which

00:09:39,720 --> 00:09:44,460
is obviously trivial and I guess hotspot

00:09:42,780 --> 00:09:46,860
would also realize that one plus one is

00:09:44,460 --> 00:09:50,120
equal to two so it would probably handle

00:09:46,860 --> 00:09:50,120
optimize even further

00:09:53,050 --> 00:09:57,070
so based on all of that it looks like

00:09:55,060 --> 00:09:57,970
inlining is a good thing and we should

00:09:57,070 --> 00:10:00,730
do lots of it

00:09:57,970 --> 00:10:02,740
so the obvious question is why not in

00:10:00,730 --> 00:10:04,780
line everything why don't we just in

00:10:02,740 --> 00:10:07,540
line our whole program into one huge

00:10:04,780 --> 00:10:11,220
function and then we could optimize it

00:10:07,540 --> 00:10:14,140
has like crazy and everyone's a winner

00:10:11,220 --> 00:10:17,770
so the answer why we don't want to do

00:10:14,140 --> 00:10:21,670
that is that code is data and the less

00:10:17,770 --> 00:10:25,000
cryptic answer is that every time you in

00:10:21,670 --> 00:10:27,640
line a function into multiple call sites

00:10:25,000 --> 00:10:29,320
that's duplication of code so the more

00:10:27,640 --> 00:10:33,280
inlining you do the bigger your code

00:10:29,320 --> 00:10:35,410
gets and if it gets too big then the

00:10:33,280 --> 00:10:37,690
working set of your codes the hot parts

00:10:35,410 --> 00:10:42,190
of your code didn't no longer fit into

00:10:37,690 --> 00:10:43,930
CPU caches and as soon as you over flow

00:10:42,190 --> 00:10:47,080
from the cache as soon as you bust the

00:10:43,930 --> 00:10:50,620
cache then your performance will

00:10:47,080 --> 00:10:52,390
radically decrease so it's a trade-off

00:10:50,620 --> 00:10:54,370
you want to inline as much as you can

00:10:52,390 --> 00:10:57,900
but you don't want to push things too

00:10:54,370 --> 00:10:57,900
far because then you run out of cash

00:11:00,140 --> 00:11:05,870
so we only want to inline hot functions

00:11:03,380 --> 00:11:09,200
meaning functions that are called very

00:11:05,870 --> 00:11:11,570
often in your code like really important

00:11:09,200 --> 00:11:14,209
stuff and ideally we want to inline the

00:11:11,570 --> 00:11:15,680
smaller hotter functions because then

00:11:14,209 --> 00:11:19,970
more of them will fit without

00:11:15,680 --> 00:11:23,209
overflowing the cache and it turns out

00:11:19,970 --> 00:11:25,519
that hotspot is pretty good at this I

00:11:23,209 --> 00:11:28,880
mean that's the whole point of hotspot

00:11:25,519 --> 00:11:30,920
that's what it was designed for hotspot

00:11:28,880 --> 00:11:36,470
is a JIT compiler a just-in-time

00:11:30,920 --> 00:11:38,269
compiler that measures how many times

00:11:36,470 --> 00:11:40,579
every function in your code is called

00:11:38,269 --> 00:11:42,829
when your program is running so it

00:11:40,579 --> 00:11:44,810
gathers metrics about your code it

00:11:42,829 --> 00:11:46,339
discovers these so-called hotspots

00:11:44,810 --> 00:11:48,920
these things that are called really

00:11:46,339 --> 00:11:52,940
heavily there but the most critical

00:11:48,920 --> 00:11:54,860
paths in your code and then it compiles

00:11:52,940 --> 00:11:57,079
them to assembly and then optimizes them

00:11:54,860 --> 00:12:00,170
aggressively that's the point of hotspot

00:11:57,079 --> 00:12:02,209
and the reason it's so good is that it

00:12:00,170 --> 00:12:05,360
has access to this runtime information

00:12:02,209 --> 00:12:07,699
there's metrics about how often things

00:12:05,360 --> 00:12:09,800
are being called obviously if you were

00:12:07,699 --> 00:12:11,089
to do inlining in the compiler then you

00:12:09,800 --> 00:12:13,820
don't have access to that information

00:12:11,089 --> 00:12:17,290
you don't know what's going to be the

00:12:13,820 --> 00:12:17,290
most important part of the code base

00:12:20,200 --> 00:12:26,320
so hotspot uses various heuristics to

00:12:22,780 --> 00:12:28,510
work out what it should be inlining it's

00:12:26,320 --> 00:12:30,490
got some quite complicated conditions

00:12:28,510 --> 00:12:33,010
but in general it tries to inline things

00:12:30,490 --> 00:12:36,430
that are small and things that are hot

00:12:33,010 --> 00:12:39,730
and it tries to avoid making the call

00:12:36,430 --> 00:12:42,370
site too big the if you inline a

00:12:39,730 --> 00:12:45,010
function into another function and that

00:12:42,370 --> 00:12:47,080
that caller ends up becoming huge then

00:12:45,010 --> 00:12:49,150
that's not good because you have this

00:12:47,080 --> 00:12:52,210
problem of the the caller function not

00:12:49,150 --> 00:12:53,830
fitting into the cache anymore and then

00:12:52,210 --> 00:12:58,240
it has a few other conditions like it

00:12:53,830 --> 00:13:00,340
can't inline native methods and so on as

00:12:58,240 --> 00:13:02,320
you can see you can tune all of these

00:13:00,340 --> 00:13:06,610
heuristics quite heavily if you want to

00:13:02,320 --> 00:13:08,530
you can set these JVM arguments to

00:13:06,610 --> 00:13:10,720
decide how you want to inline things but

00:13:08,530 --> 00:13:18,040
the defaults are pretty good for most

00:13:10,720 --> 00:13:19,840
use cases and if like me you're

00:13:18,040 --> 00:13:21,880
interested in this stuff and you like to

00:13:19,840 --> 00:13:25,060
spend your spare time looking at

00:13:21,880 --> 00:13:26,920
bytecode and x86 assembly then I really

00:13:25,060 --> 00:13:32,320
recommend this tool it's called JIT

00:13:26,920 --> 00:13:35,500
watch it's it pauses the logs that you

00:13:32,320 --> 00:13:38,730
can get hot spot to output with various

00:13:35,500 --> 00:13:41,380
JVM arguments and it shows you exactly

00:13:38,730 --> 00:13:43,600
what hot spot what the JIT compiler has

00:13:41,380 --> 00:13:48,820
done to your code so after every

00:13:43,600 --> 00:13:50,920
iteration of the compiler you can see

00:13:48,820 --> 00:13:52,480
how it's changed your code versus the

00:13:50,920 --> 00:13:54,640
previous iteration with where it's

00:13:52,480 --> 00:13:57,360
optimized and which functions it's in

00:13:54,640 --> 00:13:57,360
lined and so on

00:14:00,500 --> 00:14:04,340
so this is scarlet ace but so far I

00:14:02,810 --> 00:14:07,180
haven't really talked about Scala so

00:14:04,340 --> 00:14:09,620
this is how you do in lining in Scala

00:14:07,180 --> 00:14:12,290
until now I was just showing you how

00:14:09,620 --> 00:14:18,020
things might happen in hotspot at

00:14:12,290 --> 00:14:19,670
runtime but if you instead of doing that

00:14:18,020 --> 00:14:22,550
before as well as doing that you can

00:14:19,670 --> 00:14:26,210
also inline things at compile time using

00:14:22,550 --> 00:14:28,940
the Scarlet compiler so you can add

00:14:26,210 --> 00:14:31,130
these annotations at inline and at no

00:14:28,940 --> 00:14:31,670
inline and it's pretty obvious what

00:14:31,130 --> 00:14:34,670
those mean

00:14:31,670 --> 00:14:37,070
so the at inline invitation annotation

00:14:34,670 --> 00:14:38,870
says please inline me and the other one

00:14:37,070 --> 00:14:43,820
says please don't inline me under any

00:14:38,870 --> 00:14:47,030
circumstances but just doing that is not

00:14:43,820 --> 00:14:49,550
enough if you don't enable the -

00:14:47,030 --> 00:14:51,290
optimized flag then it will the compiler

00:14:49,550 --> 00:14:52,970
will not do any optimization so that

00:14:51,290 --> 00:14:55,670
includes inlining so it will ignore

00:14:52,970 --> 00:14:59,630
these annotations so don't forget to do

00:14:55,670 --> 00:15:02,240
- optimize and it's also worth adding

00:14:59,630 --> 00:15:04,190
this other option called - why inline

00:15:02,240 --> 00:15:06,110
warnings and if you add that then it

00:15:04,190 --> 00:15:08,540
will give you a compiler warning if it

00:15:06,110 --> 00:15:11,570
wasn't able to inline for whatever

00:15:08,540 --> 00:15:14,860
reason so if you annotated your method

00:15:11,570 --> 00:15:18,260
with at inline but it couldn't inline it

00:15:14,860 --> 00:15:22,160
because it wasn't final or whatever then

00:15:18,260 --> 00:15:25,280
it will tell you about that a word of

00:15:22,160 --> 00:15:28,580
warning about - optimize it is quite

00:15:25,280 --> 00:15:30,590
buggy apparently the akka docks for

00:15:28,580 --> 00:15:34,700
example have a big red warning box that

00:15:30,590 --> 00:15:37,000
says do not use - optimize so use at

00:15:34,700 --> 00:15:37,000
your own risk

00:15:41,970 --> 00:15:49,080
so you might think that you just add

00:15:47,100 --> 00:15:51,420
these app in line and apps no inline

00:15:49,080 --> 00:15:53,640
annotations and it will inline them or

00:15:51,420 --> 00:15:55,050
not inline them for you according to

00:15:53,640 --> 00:15:56,880
that but it's actually a little bit

00:15:55,050 --> 00:16:00,270
smarter than that

00:15:56,880 --> 00:16:03,060
so Scala C has certain heuristics that

00:16:00,270 --> 00:16:06,150
it uses to decide which methods to

00:16:03,060 --> 00:16:08,700
inline so first of all it will only

00:16:06,150 --> 00:16:11,130
inline so called effectively final with

00:16:08,700 --> 00:16:12,690
methods so this means basically a method

00:16:11,130 --> 00:16:15,450
that can't be overridden

00:16:12,690 --> 00:16:17,730
it's either marked as final or if it's

00:16:15,450 --> 00:16:20,340
inside a class that's marked as final or

00:16:17,730 --> 00:16:22,230
whatever it like the compiler knows that

00:16:20,340 --> 00:16:23,490
at runtime this is definitely the method

00:16:22,230 --> 00:16:28,770
that will be called it won't be

00:16:23,490 --> 00:16:30,210
overridden then it has it treats code

00:16:28,770 --> 00:16:32,070
differently depending on whether it's

00:16:30,210 --> 00:16:35,040
your own code that's being compiled as

00:16:32,070 --> 00:16:37,590
part of the current compilation run or

00:16:35,040 --> 00:16:39,990
it's somebody else's code for example an

00:16:37,590 --> 00:16:43,380
external library but that's already been

00:16:39,990 --> 00:16:46,410
compiled so for external libraries or

00:16:43,380 --> 00:16:48,780
already compiled code then in general

00:16:46,410 --> 00:16:52,170
they'll only inline things that have

00:16:48,780 --> 00:16:54,420
been annotated with inline but it has

00:16:52,170 --> 00:16:57,720
special rules for certain bits of the

00:16:54,420 --> 00:17:01,290
scala library and higher-order functions

00:16:57,720 --> 00:17:03,510
and the so-called monadic methods the

00:17:01,290 --> 00:17:07,200
monadic methods are map flatmap

00:17:03,510 --> 00:17:10,230
filter and one more I think and there's

00:17:07,200 --> 00:17:12,450
actually there's a if statement

00:17:10,230 --> 00:17:14,430
somewhere in the compiler that says if

00:17:12,450 --> 00:17:16,650
the method is called map or it's called

00:17:14,430 --> 00:17:22,770
flat map or it's called filter then do

00:17:16,650 --> 00:17:24,720
something special with it so when it

00:17:22,770 --> 00:17:28,830
decides whether to inline a method or

00:17:24,720 --> 00:17:30,930
not assuming that it can inline it if

00:17:28,830 --> 00:17:32,610
it's been annotated with at inline then

00:17:30,930 --> 00:17:34,650
it will inline it it'll respect your

00:17:32,610 --> 00:17:37,590
wishes but if it hasn't then it will

00:17:34,650 --> 00:17:40,890
calculate a score to decide whether it's

00:17:37,590 --> 00:17:44,760
worth inlining or not and it's based on

00:17:40,890 --> 00:17:47,700
these heuristics so if the cool site the

00:17:44,760 --> 00:17:49,290
caller method is is small then don't

00:17:47,700 --> 00:17:51,180
make it too big

00:17:49,290 --> 00:17:53,890
don't inline methods that are themselves

00:17:51,180 --> 00:17:56,980
already quite big

00:17:53,890 --> 00:18:02,350
do in line higher-order functions and so

00:17:56,980 --> 00:18:06,360
on so this is how Scala works right now

00:18:02,350 --> 00:18:10,860
this was all added in Scala to 10-0 and

00:18:06,360 --> 00:18:13,990
it's still works basically like this but

00:18:10,860 --> 00:18:17,380
in 212 there is a brand new back-end

00:18:13,990 --> 00:18:19,390
called Gen B code and that includes a

00:18:17,380 --> 00:18:23,400
new optimizer so all of the inlining

00:18:19,390 --> 00:18:25,990
code has been rewritten from scratch and

00:18:23,400 --> 00:18:29,470
the idea when they rewrote the inliner

00:18:25,990 --> 00:18:31,360
was to simplify it a lot and try and

00:18:29,470 --> 00:18:33,340
make it a bit more deterministic so you

00:18:31,360 --> 00:18:35,230
can tell more easily whether you're

00:18:33,340 --> 00:18:40,480
whether a certain function is going to

00:18:35,230 --> 00:18:42,820
be inlined or not so they try to distill

00:18:40,480 --> 00:18:45,760
it down to just one simple rule that

00:18:42,820 --> 00:18:48,520
says only in line in line marked methods

00:18:45,760 --> 00:18:52,120
and always in line them including under

00:18:48,520 --> 00:18:53,620
separate compilation so that was the

00:18:52,120 --> 00:18:58,330
idea but then later on they actually

00:18:53,620 --> 00:19:00,820
added a few more rules they decided to

00:18:58,330 --> 00:19:03,220
also inline higher-order functions and

00:19:00,820 --> 00:19:05,620
the reason for this is to fix the

00:19:03,220 --> 00:19:07,630
so-called inlining problem which is

00:19:05,620 --> 00:19:13,270
outlined quite nicely in a blog post by

00:19:07,630 --> 00:19:15,460
click click of Ã¶zil I won't go into the

00:19:13,270 --> 00:19:17,200
details of that but it turns out that in

00:19:15,460 --> 00:19:19,360
lining higher-order functions is quite

00:19:17,200 --> 00:19:22,330
important if you don't do that at

00:19:19,360 --> 00:19:26,860
compile time then hotspot will really

00:19:22,330 --> 00:19:31,240
struggle to do its inlining so it's all

00:19:26,860 --> 00:19:33,100
about helping hotspot out here so the

00:19:31,240 --> 00:19:35,740
point of the new optimizer I guess that

00:19:33,100 --> 00:19:38,590
the overall goal is to have better

00:19:35,740 --> 00:19:40,390
synergy with hotspots don't try and do

00:19:38,590 --> 00:19:41,470
the job that hotspot is already good at

00:19:40,390 --> 00:19:44,230
doing anyway

00:19:41,470 --> 00:19:46,740
but do kind of help it out where it

00:19:44,230 --> 00:19:46,740
needs some help

00:19:49,240 --> 00:19:55,610
okay so we're going to have a look at

00:19:52,910 --> 00:19:57,260
some benchmarks now to try and see what

00:19:55,610 --> 00:20:02,540
kind of effect adding these annotations

00:19:57,260 --> 00:20:06,100
has on our code just a word of warning

00:20:02,540 --> 00:20:06,100
that this is probably all wrong

00:20:07,070 --> 00:20:10,340
so when you write benchmarks there's a

00:20:09,050 --> 00:20:13,310
few different ways you can do it you can

00:20:10,340 --> 00:20:16,760
write a very specific micro benchmark

00:20:13,310 --> 00:20:20,030
that just looks at whether changing this

00:20:16,760 --> 00:20:21,260
one line of code will change the

00:20:20,030 --> 00:20:23,930
performance of this tiny little

00:20:21,260 --> 00:20:27,170
operation from one microsecond one point

00:20:23,930 --> 00:20:29,900
one microsecond but I prefer to do a

00:20:27,170 --> 00:20:31,580
kind of more real-world e benchmark or I

00:20:29,900 --> 00:20:34,010
try and simulate code that you would

00:20:31,580 --> 00:20:37,580
maybe write in a real-world program and

00:20:34,010 --> 00:20:40,220
somewhere inside that code you change

00:20:37,580 --> 00:20:42,650
one line and see what the effect is on

00:20:40,220 --> 00:20:48,700
the overall the runtime of the overall

00:20:42,650 --> 00:20:54,620
operation so to that end I came up with

00:20:48,700 --> 00:20:55,790
implementing fast Fourier transform this

00:20:54,620 --> 00:20:57,170
is not something that we use at the

00:20:55,790 --> 00:21:00,050
Guardian very much you don't really need

00:20:57,170 --> 00:21:02,510
to do it first courier of the news but I

00:21:00,050 --> 00:21:04,460
know it is used quite a lot in other

00:21:02,510 --> 00:21:07,730
domains I mean it's used in mp3 encoding

00:21:04,460 --> 00:21:09,920
and all kinds of things I implemented

00:21:07,730 --> 00:21:14,090
the coulee turkey algorithm because it

00:21:09,920 --> 00:21:15,590
has a really good name it's again I

00:21:14,090 --> 00:21:17,420
won't go into the details but it's a

00:21:15,590 --> 00:21:19,840
recursive algorithm it lends itself

00:21:17,420 --> 00:21:24,050
quite nicely to a kind of functional

00:21:19,840 --> 00:21:26,300
immutable implementation in Scala and

00:21:24,050 --> 00:21:27,860
the like the meat of the algorithm is

00:21:26,300 --> 00:21:30,770
just loads and loads of numerical

00:21:27,860 --> 00:21:33,800
operations on complex numbers so I'm not

00:21:30,770 --> 00:21:37,160
although complex number as a case class

00:21:33,800 --> 00:21:39,380
and it's got plus minus and multiply

00:21:37,160 --> 00:21:42,170
methods and the point of the benchmark

00:21:39,380 --> 00:21:47,660
is if you annotate these with inline or

00:21:42,170 --> 00:21:51,410
no inline what happens so the moment of

00:21:47,660 --> 00:21:52,850
truth let's look at some numbers there's

00:21:51,410 --> 00:21:55,370
quite a lot going on on this slide but

00:21:52,850 --> 00:21:58,490
I'd like to draw your attention to three

00:21:55,370 --> 00:21:59,130
things in particular so first of all if

00:21:58,490 --> 00:22:02,110
we

00:21:59,130 --> 00:22:03,130
can you see my mouse ear if you just

00:22:02,110 --> 00:22:05,080
have a look at the difference between

00:22:03,130 --> 00:22:07,600
this left-hand column and this

00:22:05,080 --> 00:22:09,970
right-hand column the left hand side is

00:22:07,600 --> 00:22:12,550
what happens if you just disable

00:22:09,970 --> 00:22:14,290
inlining completely in hotspot and then

00:22:12,550 --> 00:22:17,200
the right hand side is normal operation

00:22:14,290 --> 00:22:19,090
where you you don't pass any weird JVM

00:22:17,200 --> 00:22:23,410
arguments just running Java and normally

00:22:19,090 --> 00:22:25,000
and you can see that disabling inlining

00:22:23,410 --> 00:22:25,600
makes the code three or four times

00:22:25,000 --> 00:22:27,820
slower

00:22:25,600 --> 00:22:33,190
so obviously hotspot is doing quite a

00:22:27,820 --> 00:22:36,910
good job next thing to note if you look

00:22:33,190 --> 00:22:41,350
at the right-hand column the top number

00:22:36,910 --> 00:22:44,860
360 is annotating with the inline and

00:22:41,350 --> 00:22:48,880
station and the bottom number is an ax

00:22:44,860 --> 00:22:50,740
type annotating with no inline and like

00:22:48,880 --> 00:22:52,929
give or take the error they're basically

00:22:50,740 --> 00:22:55,929
the same and the reason for this is that

00:22:52,929 --> 00:22:58,110
no matter whether you annotate in

00:22:55,929 --> 00:23:00,850
scarlet or do the inlining in scarlet c

00:22:58,110 --> 00:23:01,690
hotspot will come along and just inline

00:23:00,850 --> 00:23:04,270
it for you anyway

00:23:01,690 --> 00:23:08,170
so don't there's no need to worry about

00:23:04,270 --> 00:23:11,200
it just leave it to hotpot and then the

00:23:08,170 --> 00:23:14,140
final thing to note if you compare these

00:23:11,200 --> 00:23:17,440
numbers here with the ones below you can

00:23:14,140 --> 00:23:19,480
see just by upgrading to scarlet 212 we

00:23:17,440 --> 00:23:23,650
can look forward to of that about the

00:23:19,480 --> 00:23:25,210
10% speed-up so that's quite nice and

00:23:23,650 --> 00:23:27,460
this is for a number of reasons it could

00:23:25,210 --> 00:23:29,710
be the new optimizer work that they've

00:23:27,460 --> 00:23:36,570
been doing in Scala 212 it could be the

00:23:29,710 --> 00:23:40,900
the use of Java 8 or they called Sam's

00:23:36,570 --> 00:23:44,410
the re-encoding of lambdas in to use

00:23:40,900 --> 00:23:47,140
Java 8 classes but anyway it looks like

00:23:44,410 --> 00:23:49,690
Scarlett e 12 for this use case in at

00:23:47,140 --> 00:23:51,870
least is faster than 211 so that's good

00:23:49,690 --> 00:23:51,870
news

00:23:54,380 --> 00:23:58,519
further reading I got a bit carried away

00:23:56,149 --> 00:24:00,190
here but there's there's just so much

00:23:58,519 --> 00:24:03,139
information available online about

00:24:00,190 --> 00:24:06,590
inlining in hot spot or the internals of

00:24:03,139 --> 00:24:10,360
the JVM so I'll put the slides online

00:24:06,590 --> 00:24:10,360
and you can read at your leisure

00:24:11,990 --> 00:24:16,669
that's all I have for inlining now I

00:24:14,090 --> 00:24:18,380
will look at specialization but first of

00:24:16,669 --> 00:24:21,620
all we'll have a look at some background

00:24:18,380 --> 00:24:27,379
on how types and generics work in the

00:24:21,620 --> 00:24:28,909
JVM and in Scala so this is just a bit

00:24:27,379 --> 00:24:31,580
of a recap that's probably familiar to

00:24:28,909 --> 00:24:33,529
most of you and Dimitri went through the

00:24:31,580 --> 00:24:36,590
stuff in his talk earlier today if you

00:24:33,529 --> 00:24:39,529
were in that but types in the JVM are

00:24:36,590 --> 00:24:42,409
split into two types of types there's

00:24:39,529 --> 00:24:45,679
primitives and reference types so

00:24:42,409 --> 00:24:50,529
primitives are boolean byte char in and

00:24:45,679 --> 00:24:53,240
so on they are not objects so they're

00:24:50,529 --> 00:24:56,769
small and memory efficient there's no

00:24:53,240 --> 00:25:00,860
object overhead they're just raw values

00:24:56,769 --> 00:25:03,830
and reference types are everything else

00:25:00,860 --> 00:25:07,370
so anything that extends from java.lang

00:25:03,830 --> 00:25:09,289
object they are stored on the heap

00:25:07,370 --> 00:25:12,769
whereas primitives can be stored on the

00:25:09,289 --> 00:25:14,990
stack and if you want to reference them

00:25:12,769 --> 00:25:18,769
then you need to pass a reference to the

00:25:14,990 --> 00:25:20,330
object not the object itself so there's

00:25:18,769 --> 00:25:21,620
a level of indirection there if you're

00:25:20,330 --> 00:25:24,799
working with a primitive then you have

00:25:21,620 --> 00:25:26,480
the value right there you can do what

00:25:24,799 --> 00:25:30,320
you like with it but the reference you

00:25:26,480 --> 00:25:33,490
have to do a jump from the pointer to

00:25:30,320 --> 00:25:33,490
the the object itself

00:25:35,550 --> 00:25:42,240
so how does this play with generics

00:25:38,300 --> 00:25:44,910
unfortunately not very nicely so we'll

00:25:42,240 --> 00:25:46,980
have a look at a generic piece of

00:25:44,910 --> 00:25:48,360
generic code in Java and in a second

00:25:46,980 --> 00:25:51,540
we'll see how that translates to a

00:25:48,360 --> 00:25:54,830
bytecode so we have a public class

00:25:51,540 --> 00:25:59,010
generic which has some function foo

00:25:54,830 --> 00:26:02,340
sorry method foo which is generic so it

00:25:59,010 --> 00:26:03,780
says I take an A but I don't care what

00:26:02,340 --> 00:26:06,210
its type is I'm just going to call it a

00:26:03,780 --> 00:26:07,980
it's there's no contact and that's sorry

00:26:06,210 --> 00:26:10,770
no bounds on this at all it could be

00:26:07,980 --> 00:26:14,490
anything it could be a primitive int or

00:26:10,770 --> 00:26:16,470
it could be a string or whatever and

00:26:14,490 --> 00:26:18,900
then underneath we have another function

00:26:16,470 --> 00:26:20,190
test which is calling this so first it

00:26:18,900 --> 00:26:22,710
calls it with a string which is a

00:26:20,190 --> 00:26:25,860
reference type and then it calls it with

00:26:22,710 --> 00:26:29,960
an integer which is a primitive so let's

00:26:25,860 --> 00:26:29,960
see how this translates into byte code

00:26:31,070 --> 00:26:37,230
so first of all underlined at the top

00:26:34,710 --> 00:26:40,140
you can see that even though we haven't

00:26:37,230 --> 00:26:42,660
said anything about objects or reference

00:26:40,140 --> 00:26:46,560
types or or given any kind of bounds on

00:26:42,660 --> 00:26:48,660
our function on its parameter it says

00:26:46,560 --> 00:26:50,970
that it will only take a Java line

00:26:48,660 --> 00:26:53,580
object or obviously a subclass of Java

00:26:50,970 --> 00:26:57,180
line object and this is basically

00:26:53,580 --> 00:27:01,620
because generics is broken in the JVM it

00:26:57,180 --> 00:27:03,510
was added retro actively after the hole

00:27:01,620 --> 00:27:07,890
type system and that the byte codes have

00:27:03,510 --> 00:27:11,160
been already formalized so this is the

00:27:07,890 --> 00:27:16,290
best they could do and then underneath

00:27:11,160 --> 00:27:19,620
that we can see our two indications of

00:27:16,290 --> 00:27:23,370
that method the first one we are passing

00:27:19,620 --> 00:27:25,470
in the string hello and we're passing

00:27:23,370 --> 00:27:27,030
that in as an object that's fair enough

00:27:25,470 --> 00:27:30,590
because it is an object it's a reference

00:27:27,030 --> 00:27:33,990
type but then the second function call

00:27:30,590 --> 00:27:35,850
we we have a primitive but that doesn't

00:27:33,990 --> 00:27:38,550
extend from java.lang objects so we need

00:27:35,850 --> 00:27:40,260
to convert it into a reference type need

00:27:38,550 --> 00:27:43,410
to convert it into an integer with a big

00:27:40,260 --> 00:27:45,900
eye before we can pass it into the

00:27:43,410 --> 00:27:47,740
method so can anyone tell me what we

00:27:45,900 --> 00:27:52,750
call this process of converting

00:27:47,740 --> 00:27:53,200
a primitive to a reference type that's

00:27:52,750 --> 00:27:58,750
right

00:27:53,200 --> 00:28:02,530
boxing so boxing is something we want to

00:27:58,750 --> 00:28:05,050
avoid for various reasons well firstly

00:28:02,530 --> 00:28:06,880
it's just a oh it's wasted effort really

00:28:05,050 --> 00:28:08,920
like we already have the value why do we

00:28:06,880 --> 00:28:11,070
need to convert it to an another

00:28:08,920 --> 00:28:16,120
representation of the number it's just

00:28:11,070 --> 00:28:18,190
it's wasted CPU but also it's it

00:28:16,120 --> 00:28:20,200
involves an allocation on the heap so

00:28:18,190 --> 00:28:22,660
every time you do this box and you

00:28:20,200 --> 00:28:24,429
convert an inter to an integer you're

00:28:22,660 --> 00:28:25,450
allocating a new object on the heap and

00:28:24,429 --> 00:28:28,330
that will have to be garbage collected

00:28:25,450 --> 00:28:31,450
so you're increasing your your CPU usage

00:28:28,330 --> 00:28:34,360
in that way as well and yeah you're

00:28:31,450 --> 00:28:38,500
increasing memory pressure so we'd like

00:28:34,360 --> 00:28:41,380
to avoid that so so much for Java let's

00:28:38,500 --> 00:28:44,710
see how it works in Scala

00:28:41,380 --> 00:28:48,370
so this is the the root of the Scala

00:28:44,710 --> 00:28:50,500
type hierarchy we haven't any at the top

00:28:48,370 --> 00:28:53,230
and that extending that we have any

00:28:50,500 --> 00:28:55,720
vowel and a ref so any vowel represents

00:28:53,230 --> 00:28:57,640
the primitives the value types so we

00:28:55,720 --> 00:29:01,000
have int and double and so on and they

00:28:57,640 --> 00:29:03,970
are encoded on the JVM as primitive

00:29:01,000 --> 00:29:05,770
types and then on the other side we have

00:29:03,970 --> 00:29:07,690
any ref which is pretty much equivalent

00:29:05,770 --> 00:29:09,370
to java.lang objects so this is the

00:29:07,690 --> 00:29:13,360
reference types so we have the same kind

00:29:09,370 --> 00:29:16,090
of thing that we had in Java so let's

00:29:13,360 --> 00:29:20,620
see generic code in Scala and see how

00:29:16,090 --> 00:29:24,490
that maps to bytecode so here I'm using

00:29:20,620 --> 00:29:27,790
the standard library mutable map I

00:29:24,490 --> 00:29:31,960
create a new map with an integer type

00:29:27,790 --> 00:29:34,600
for its value type and then I call put

00:29:31,960 --> 00:29:38,170
on it and I pass in an a primitive one

00:29:34,600 --> 00:29:41,440
two three so if we look at the bike Co

00:29:38,170 --> 00:29:43,540
for that you can see that we have the

00:29:41,440 --> 00:29:48,340
same problem before we can call the

00:29:43,540 --> 00:29:50,740
function we have to convert from an int

00:29:48,340 --> 00:29:53,350
a primitive int to a reference type an

00:29:50,740 --> 00:29:57,820
integer and cleani one remind me what

00:29:53,350 --> 00:29:59,400
this conversion is called BARC seen very

00:29:57,820 --> 00:30:02,440
good

00:29:59,400 --> 00:30:04,180
okay so the point of specialization is

00:30:02,440 --> 00:30:06,100
to avoid this problem to work around

00:30:04,180 --> 00:30:10,020
this problem and it does this by

00:30:06,100 --> 00:30:12,550
generating multiple versions of a class

00:30:10,020 --> 00:30:15,790
it generates a different version for

00:30:12,550 --> 00:30:17,410
each primitive type and then the

00:30:15,790 --> 00:30:19,840
compiler will choose the correct version

00:30:17,410 --> 00:30:21,100
and it will call it directly so you

00:30:19,840 --> 00:30:26,560
don't have to go through this boxing

00:30:21,100 --> 00:30:29,020
process so you use it like this it's

00:30:26,560 --> 00:30:31,540
pretty simple you just add the

00:30:29,020 --> 00:30:34,120
specialized annotation to your type

00:30:31,540 --> 00:30:37,350
parameter so I've got a my special map

00:30:34,120 --> 00:30:40,420
here with a specialized type parameter a

00:30:37,350 --> 00:30:43,200
and when I compile this the compiler

00:30:40,420 --> 00:30:46,150
will generate all of these ten different

00:30:43,200 --> 00:30:48,250
versions of my class so there's one for

00:30:46,150 --> 00:30:51,490
each of the primitive types there's one

00:30:48,250 --> 00:30:55,470
for null and there's one for any ref so

00:30:51,490 --> 00:30:59,110
just a normal non specialized version

00:30:55,470 --> 00:31:01,060
and then if I want to use this my

00:30:59,110 --> 00:31:04,740
special map from some other piece of

00:31:01,060 --> 00:31:04,740
code I can do it like this

00:31:05,010 --> 00:31:09,880
so my foo method here doesn't need to

00:31:08,260 --> 00:31:11,700
know anything about the specialization

00:31:09,880 --> 00:31:15,220
it doesn't know that my special map is

00:31:11,700 --> 00:31:20,470
specialized it just calls it with type

00:31:15,220 --> 00:31:23,410
parameter int and then it puts 1 2 3 as

00:31:20,470 --> 00:31:26,710
its value so we'll see how this looks in

00:31:23,410 --> 00:31:28,960
byte code you can see everything is now

00:31:26,710 --> 00:31:35,260
green circles instead of red circles so

00:31:28,960 --> 00:31:37,150
that's a good sign the top line the

00:31:35,260 --> 00:31:40,120
first line you can see that it's it's

00:31:37,150 --> 00:31:42,820
instantiating an instance of not my

00:31:40,120 --> 00:31:47,370
special map but the specialized integer

00:31:42,820 --> 00:31:50,920
version of my special map and then the

00:31:47,370 --> 00:31:52,840
the second green circle it has a capital

00:31:50,920 --> 00:31:54,730
I which means that it's passing in a

00:31:52,840 --> 00:31:58,260
primitive integer so there's no boxing

00:31:54,730 --> 00:31:58,260
going on here everybody's happy

00:32:01,220 --> 00:32:05,840
one thing that I didn't understand for

00:32:02,990 --> 00:32:07,870
quite a while is how does the call how

00:32:05,840 --> 00:32:10,310
does the client code know that you're

00:32:07,870 --> 00:32:14,060
you're my special map is actually

00:32:10,310 --> 00:32:16,970
specialized say if I want to release my

00:32:14,060 --> 00:32:18,800
special map as a library and I put it in

00:32:16,970 --> 00:32:20,870
a jar stick it on maven central and then

00:32:18,800 --> 00:32:23,390
somebody wants to use it how does the

00:32:20,870 --> 00:32:27,380
compiler know that it's actually

00:32:23,390 --> 00:32:29,090
specialized and the answer is that

00:32:27,380 --> 00:32:31,630
specialized is a so called static

00:32:29,090 --> 00:32:34,690
annotation which means that it gets

00:32:31,630 --> 00:32:38,630
persisted into the scholar signature

00:32:34,690 --> 00:32:42,680
which itself in turn is persisted as a

00:32:38,630 --> 00:32:45,880
an annotation inside the class file so

00:32:42,680 --> 00:32:49,420
somewhere inside that big blob of bytes

00:32:45,880 --> 00:32:54,230
if you decode that you can see the the

00:32:49,420 --> 00:32:56,600
specialized annotation in there so when

00:32:54,230 --> 00:32:58,090
the compiler sees that it knows that

00:32:56,600 --> 00:33:00,100
it's specialized and it will

00:32:58,090 --> 00:33:02,450
automatically choose the correct

00:33:00,100 --> 00:33:04,870
specialized version of that class when

00:33:02,450 --> 00:33:04,870
it needs to

00:33:10,070 --> 00:33:15,650
so once again just like in lining we

00:33:12,740 --> 00:33:17,210
have a trade-off here specialization

00:33:15,650 --> 00:33:19,610
similar to in lining it generates a lot

00:33:17,210 --> 00:33:23,660
of duplicated code from even more so I

00:33:19,610 --> 00:33:25,730
guess so if you have one type parameter

00:33:23,660 --> 00:33:28,550
like we had from my special map then it

00:33:25,730 --> 00:33:29,750
could generate ten types but if you have

00:33:28,550 --> 00:33:34,040
two type parameters it could be a

00:33:29,750 --> 00:33:36,230
hundred types sorry 100 classes and so

00:33:34,040 --> 00:33:38,330
on so it's 10 to the N where n is the

00:33:36,230 --> 00:33:40,490
number of type parameters that you want

00:33:38,330 --> 00:33:43,940
to specialize that could be a huge

00:33:40,490 --> 00:33:47,150
number of classes one thing that you can

00:33:43,940 --> 00:33:50,420
do is to specify the types that you want

00:33:47,150 --> 00:33:51,980
to specialize on so here I've said that

00:33:50,420 --> 00:33:55,580
I only want to generate specialized

00:33:51,980 --> 00:33:57,740
versions for int and long and double so

00:33:55,580 --> 00:34:02,420
then no only before classes I guess int

00:33:57,740 --> 00:34:04,570
along double and Ne ref but like Dimitri

00:34:02,420 --> 00:34:09,230
said in his presentation earlier today

00:34:04,570 --> 00:34:12,260
this is quite it's not that helpful

00:34:09,230 --> 00:34:14,630
because say if I'm a library author and

00:34:12,260 --> 00:34:16,790
I want to release my special map to the

00:34:14,630 --> 00:34:19,760
world how do I know what types people

00:34:16,790 --> 00:34:22,419
will want to use it for I can't I just

00:34:19,760 --> 00:34:22,419
have to make a guess

00:34:26,480 --> 00:34:31,730
and you can see this problem quite a lot

00:34:29,000 --> 00:34:33,679
in the scholar standard library so it's

00:34:31,730 --> 00:34:37,460
a it's a bit of a mess to be honest

00:34:33,679 --> 00:34:40,099
tuple one is specialized in int long and

00:34:37,460 --> 00:34:42,440
double triple two is specialized in both

00:34:40,099 --> 00:34:44,780
of its arguments in int long double char

00:34:42,440 --> 00:34:46,579
and boolean sheeple three doesn't have

00:34:44,780 --> 00:34:48,470
specialization tools so there's boxing

00:34:46,579 --> 00:34:49,940
there if you're in the front row you

00:34:48,470 --> 00:34:52,339
might be able to see a little tiny

00:34:49,940 --> 00:34:56,720
Muhammad Ali there he's representing the

00:34:52,339 --> 00:34:59,920
boxing option is boxing function zero

00:34:56,720 --> 00:35:03,829
one and two just random combinations of

00:34:59,920 --> 00:35:06,740
specialized different types of

00:35:03,829 --> 00:35:09,740
specialized function three or more

00:35:06,740 --> 00:35:12,050
doesn't have any specialization and most

00:35:09,740 --> 00:35:16,640
of the immutable immutable collections

00:35:12,050 --> 00:35:20,540
also no specialization so if you do want

00:35:16,640 --> 00:35:22,880
to use specialized collections there are

00:35:20,540 --> 00:35:24,500
some alternatives if you don't you can't

00:35:22,880 --> 00:35:28,369
really use the standard library but you

00:35:24,500 --> 00:35:30,829
can use for example d box this is

00:35:28,369 --> 00:35:33,829
written by Eric or Shyam who's the

00:35:30,829 --> 00:35:38,089
creator of cats and spire and various

00:35:33,829 --> 00:35:40,040
other things it's quite a nice mutable

00:35:38,089 --> 00:35:43,550
collections library that uses a

00:35:40,040 --> 00:35:47,000
specialization then there's metal which

00:35:43,550 --> 00:35:49,869
is a fork of that project I think and

00:35:47,000 --> 00:35:52,880
also worth mentioning is mini boxing so

00:35:49,869 --> 00:35:57,500
this is a kind of the second iteration

00:35:52,880 --> 00:36:02,000
of specialization I guess it's a version

00:35:57,500 --> 00:36:03,380
two it's it does basically the same

00:36:02,000 --> 00:36:04,700
thing the specialization but the

00:36:03,380 --> 00:36:08,180
implementation details are quite

00:36:04,700 --> 00:36:13,160
different it involves using a compiler

00:36:08,180 --> 00:36:16,420
plug-in you and you you annotate things

00:36:13,160 --> 00:36:18,640
with mini box rather than specialized

00:36:16,420 --> 00:36:20,940
it's

00:36:18,640 --> 00:36:24,190
okay gives you approximately the same

00:36:20,940 --> 00:36:26,859
speed ups or optimizations that you get

00:36:24,190 --> 00:36:30,430
from specialized but it doesn't generate

00:36:26,859 --> 00:36:33,960
as many types of as many classes so you

00:36:30,430 --> 00:36:33,960
have less code duplication

00:36:40,780 --> 00:36:46,060
so let's have a look at another

00:36:42,940 --> 00:36:49,840
benchmark and the same warnings apply

00:36:46,060 --> 00:36:51,670
this is all probably wrong again I

00:36:49,840 --> 00:36:53,260
wanted to do a kind of real-world II

00:36:51,670 --> 00:36:55,690
benchmark or something a bit more

00:36:53,260 --> 00:37:00,160
interesting than just a boring old map

00:36:55,690 --> 00:37:02,890
so I implemented a bloom filter a bloom

00:37:00,160 --> 00:37:05,830
filter is a probabilistic data structure

00:37:02,890 --> 00:37:08,590
that can tell you whether or whether a

00:37:05,830 --> 00:37:11,650
certain element is probably a member of

00:37:08,590 --> 00:37:14,470
a set so you add values to it you say

00:37:11,650 --> 00:37:16,000
this this element is in the set this

00:37:14,470 --> 00:37:18,370
element is in the set and then later on

00:37:16,000 --> 00:37:21,370
you can query saying is this element in

00:37:18,370 --> 00:37:24,400
the set and it will either say probably

00:37:21,370 --> 00:37:25,930
yes or definitely not so depending on

00:37:24,400 --> 00:37:31,030
your use cases this can be quite useful

00:37:25,930 --> 00:37:34,860
and it's a lot smaller than than just a

00:37:31,030 --> 00:37:38,440
normal set so it's more memory efficient

00:37:34,860 --> 00:37:41,260
so I implemented a bloom filter class

00:37:38,440 --> 00:37:44,950
which has a specialized type parameter

00:37:41,260 --> 00:37:47,320
which I specialized in int it also needs

00:37:44,950 --> 00:37:50,740
some hash functions so that what for

00:37:47,320 --> 00:37:53,470
various implementation reasons so that's

00:37:50,740 --> 00:38:00,700
also specialized in int that's a type

00:37:53,470 --> 00:38:02,380
class so let's look at some numbers so

00:38:00,700 --> 00:38:05,170
the operation here is to insert one

00:38:02,380 --> 00:38:08,500
number and then query for another number

00:38:05,170 --> 00:38:10,900
say and as you can see adding

00:38:08,500 --> 00:38:12,480
specialization doesn't really appear to

00:38:10,900 --> 00:38:15,520
make much difference to the performance

00:38:12,480 --> 00:38:17,350
but to be fair I think this is a problem

00:38:15,520 --> 00:38:23,550
of the benchmark rather than

00:38:17,350 --> 00:38:26,680
specialization in itself specialization

00:38:23,550 --> 00:38:29,850
like in the short term at the time you

00:38:26,680 --> 00:38:32,400
actually call the function the only

00:38:29,850 --> 00:38:38,430
overhead that you're going to save is

00:38:32,400 --> 00:38:41,020
one boxing one call to that boxing

00:38:38,430 --> 00:38:42,640
function so that's not much of a

00:38:41,020 --> 00:38:45,760
speed-up to be honest getting rid of one

00:38:42,640 --> 00:38:47,140
function call but over the long term if

00:38:45,760 --> 00:38:49,180
you're calling this over and over again

00:38:47,140 --> 00:38:51,740
and you're allocating more and more

00:38:49,180 --> 00:38:53,809
objects on to the heap due to all this

00:38:51,740 --> 00:38:56,390
boxing going on so you're you're

00:38:53,809 --> 00:38:59,180
exerting memory pressure and eventually

00:38:56,390 --> 00:39:01,220
GC will kick in and your program will

00:38:59,180 --> 00:39:03,500
slow down in that way so I don't think

00:39:01,220 --> 00:39:05,000
this benchmark really takes that into

00:39:03,500 --> 00:39:06,680
account or it doesn't show up in these

00:39:05,000 --> 00:39:10,549
numbers that that kind of long-term

00:39:06,680 --> 00:39:16,750
memory pressure issue that's quite hard

00:39:10,549 --> 00:39:19,130
to benchmark I think also another

00:39:16,750 --> 00:39:22,150
another thing that specialization can

00:39:19,130 --> 00:39:24,470
give you another benefit is that

00:39:22,150 --> 00:39:26,900
depending on your use case you might

00:39:24,470 --> 00:39:29,329
have an array a very large array of

00:39:26,900 --> 00:39:31,579
values inside your data structure and

00:39:29,329 --> 00:39:35,390
you might want to iterate over them in

00:39:31,579 --> 00:39:37,579
like iterate from start to finish and in

00:39:35,390 --> 00:39:39,650
that case it's much better if it can be

00:39:37,579 --> 00:39:44,960
a primitive array rather than array of

00:39:39,650 --> 00:39:47,030
references to boxed objects because if

00:39:44,960 --> 00:39:49,670
it's a primitive array then you get the

00:39:47,030 --> 00:39:52,369
benefit of spatial locality you get all

00:39:49,670 --> 00:39:57,829
of your values nicely in contiguous

00:39:52,369 --> 00:39:59,779
memory so that can be another big

00:39:57,829 --> 00:40:02,630
benefit of specialization but in this

00:39:59,779 --> 00:40:03,170
case in the bloom filter case we don't

00:40:02,630 --> 00:40:04,789
do that

00:40:03,170 --> 00:40:10,190
so obviously that wouldn't show up in

00:40:04,789 --> 00:40:12,980
this benchmark so yeah slightly

00:40:10,190 --> 00:40:14,450
disappointing result here but I think

00:40:12,980 --> 00:40:16,750
it's the fault of the benchmark more

00:40:14,450 --> 00:40:16,750
than anything

00:40:18,660 --> 00:40:22,710
so a bit more further reading here and

00:40:20,400 --> 00:40:26,910
also I haven't listed it here but

00:40:22,710 --> 00:40:28,640
Dimitri's talked from earlier today was

00:40:26,910 --> 00:40:31,410
really interesting he was talking about

00:40:28,640 --> 00:40:35,100
automatic specialization that he's

00:40:31,410 --> 00:40:36,900
adding to the doc te linker so one day

00:40:35,100 --> 00:40:38,250
in the bright future will not need to

00:40:36,900 --> 00:40:42,080
worry about any of this stuff and the

00:40:38,250 --> 00:40:42,080
dotty linker will just do it for us

00:40:44,070 --> 00:40:50,520
finally honourable mentions so this is

00:40:47,640 --> 00:40:52,380
just a few of the other annotations that

00:40:50,520 --> 00:40:53,640
I found in the scholar standard library

00:40:52,380 --> 00:40:59,730
while I was writing this talk and

00:40:53,640 --> 00:41:01,320
decided not to make a talk about so you

00:40:59,730 --> 00:41:02,220
may or may not already know about these

00:41:01,320 --> 00:41:07,320
but I thought they were quite

00:41:02,220 --> 00:41:10,560
interesting so strict FP annotation this

00:41:07,320 --> 00:41:14,850
adds a strict FP flag to the class file

00:41:10,560 --> 00:41:15,720
meaning strict floating-point so this is

00:41:14,850 --> 00:41:17,580
about whether you want your

00:41:15,720 --> 00:41:19,980
floating-point calculations to be as

00:41:17,580 --> 00:41:22,950
accurate as they possibly can be or to

00:41:19,980 --> 00:41:24,800
be consistent across platforms across

00:41:22,950 --> 00:41:29,190
any platform that your code might run on

00:41:24,800 --> 00:41:31,619
so that's quite interesting switch is

00:41:29,190 --> 00:41:35,880
something that you can add to a pattern

00:41:31,619 --> 00:41:37,350
match when you when a pattern match that

00:41:35,880 --> 00:41:40,109
you've written in your scarlet code gets

00:41:37,350 --> 00:41:41,400
compiled down to bytecode depending on

00:41:40,109 --> 00:41:43,260
what you're doing in your pattern match

00:41:41,400 --> 00:41:45,390
how complex the match is and what types

00:41:43,260 --> 00:41:47,310
you're matching on it can be it can

00:41:45,390 --> 00:41:48,600
generate a lot of different types of

00:41:47,310 --> 00:41:52,410
bytecode and some of those are more

00:41:48,600 --> 00:41:54,090
performant than others so this is an

00:41:52,410 --> 00:41:58,230
annotation to say please give me a

00:41:54,090 --> 00:41:59,540
warning if I've generated bytecode that

00:41:58,230 --> 00:42:02,910
doesn't perform very well

00:41:59,540 --> 00:42:05,820
and finally Elida belitz

00:42:02,910 --> 00:42:08,460
is an annotation for methods whose

00:42:05,820 --> 00:42:11,250
bodies may be excluded from compiler

00:42:08,460 --> 00:42:12,270
generated by code so if you annotate

00:42:11,250 --> 00:42:14,430
your method with this you're basically

00:42:12,270 --> 00:42:16,650
saying that the method is optional like

00:42:14,430 --> 00:42:20,670
you don't care if it gets compiled or

00:42:16,650 --> 00:42:22,530
not you you annotate it with a lie

00:42:20,670 --> 00:42:24,540
double and then if you pass certain

00:42:22,530 --> 00:42:26,940
flags to scarless see when you compile

00:42:24,540 --> 00:42:28,380
your code it will just rip that method

00:42:26,940 --> 00:42:29,900
out completely and just replace it with

00:42:28,380 --> 00:42:45,830
like zero or

00:42:29,900 --> 00:42:48,200
some default value so yeah okay it does

00:42:45,830 --> 00:42:50,090
make sense you know I can see why they

00:42:48,200 --> 00:42:57,320
added it but we're not gonna use it it

00:42:50,090 --> 00:43:01,310
ourselves in most cases so in summary in

00:42:57,320 --> 00:43:04,550
line should you use it I guess probably

00:43:01,310 --> 00:43:07,040
not just let hotspot do its thing

00:43:04,550 --> 00:43:08,570
the only exception I guess is if you're

00:43:07,040 --> 00:43:10,580
not targeting hotspots if you're

00:43:08,570 --> 00:43:15,620
targeting Android for example or scarlet

00:43:10,580 --> 00:43:18,280
j/s then I don't know what what their

00:43:15,620 --> 00:43:20,210
performance is like for inlining

00:43:18,280 --> 00:43:20,900
Sebastian might know I think he's out

00:43:20,210 --> 00:43:22,940
there somewhere

00:43:20,900 --> 00:43:27,620
how was how does inlining work in

00:43:22,940 --> 00:43:29,800
jeaious okay go to the Bastian store

00:43:27,620 --> 00:43:29,800
tomorrow

00:43:36,850 --> 00:43:41,210
okay

00:43:39,020 --> 00:43:42,380
okay just to repeat what Sebastian said

00:43:41,210 --> 00:43:45,170
into the mic

00:43:42,380 --> 00:43:52,610
Scala jazz has its own in liner and its

00:43:45,170 --> 00:43:54,020
own heuristics so yeah so specialized

00:43:52,610 --> 00:43:56,630
should you use it

00:43:54,020 --> 00:43:58,640
I guess so in certain circumstances I

00:43:56,630 --> 00:44:02,119
think it does make a difference but

00:43:58,640 --> 00:44:06,310
unfortunately not in my benchmark so

00:44:02,119 --> 00:44:06,310

YouTube URL: https://www.youtube.com/watch?v=WTeDaM3CC1I


