Title: Dotty Linker: Precise Types Bring Performance   by Dmitry Petrashko
Publication date: 2016-06-29
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.

Abstract:
Common arguments for using more elaborate type systems include safety and documentation. But we will show how more expressive type systems can be used to drive novel powerful optimizations and make the program faster. Based on this principle, we built the Dotty Linker, a whole-program optimizer that represents a breakthrough in optimization of Scala code. We will demonstrate how the linker is capable of reducing the performance overhead of commonly-used Scala features such as generic methods and classes, lazy vals, implicit conversions and closures.
Captions: 
	00:00:05,970 --> 00:00:11,549
so first I'll start by saying Who am Who

00:00:09,120 --> 00:00:13,889
I am I'm dark demons from github i'm

00:00:11,549 --> 00:00:16,139
doing a PhD at epfl under supervision of

00:00:13,889 --> 00:00:17,880
martin indoor ski so previously I've

00:00:16,139 --> 00:00:19,949
been working on scalability switch our

00:00:17,880 --> 00:00:23,400
macro collection micro operations for

00:00:19,949 --> 00:00:25,349
collections that we're replacing the

00:00:23,400 --> 00:00:28,019
standard abrasions on Scylla collections

00:00:25,349 --> 00:00:30,539
and they were substantially faster than

00:00:28,019 --> 00:00:32,340
the default ones and while doing this

00:00:30,539 --> 00:00:33,900
I've understood the optimization that I

00:00:32,340 --> 00:00:35,970
was doing there are specific to

00:00:33,900 --> 00:00:38,010
collections and they can be extended to

00:00:35,970 --> 00:00:40,290
apply to the whole language and all the

00:00:38,010 --> 00:00:43,680
libraries okay so in order to make it

00:00:40,290 --> 00:00:45,990
possible since March 2014 together with

00:00:43,680 --> 00:00:47,790
Martin I've been building dotty we're

00:00:45,990 --> 00:00:49,980
doing this on the scale of whole

00:00:47,790 --> 00:00:54,540
language and halle like a system will be

00:00:49,980 --> 00:00:56,280
possible and since March 2015 I've been

00:00:54,540 --> 00:00:58,200
actually working on this optimizations

00:00:56,280 --> 00:01:01,350
part and supervising other people

00:00:58,200 --> 00:01:03,090
working on dolly so when I say well I

00:01:01,350 --> 00:01:04,680
was working on Dante I actually mean

00:01:03,090 --> 00:01:08,189
this so if you'll have a look at the

00:01:04,680 --> 00:01:10,950
dota code base then at the moment if you

00:01:08,189 --> 00:01:14,159
see how many people are to blame for a

00:01:10,950 --> 00:01:17,990
buck in particular line I I'm more

00:01:14,159 --> 00:01:21,930
likely to have caused a bug than Martin

00:01:17,990 --> 00:01:25,140
okay I'm not committing as American mrs.

00:01:21,930 --> 00:01:29,340
Martin does but mark a micrometer bigger

00:01:25,140 --> 00:01:30,690
than average okay so when I was saying

00:01:29,340 --> 00:01:32,670
that I want to make your application

00:01:30,690 --> 00:01:35,460
faster and I won't make skala the

00:01:32,670 --> 00:01:38,810
language faster why need to think where

00:01:35,460 --> 00:01:42,870
does slow down or inefficiency come from

00:01:38,810 --> 00:01:44,580
I made the dama classification here

00:01:42,870 --> 00:01:46,890
which isn't readily really that

00:01:44,580 --> 00:01:49,440
classification of strict but we'll go

00:01:46,890 --> 00:01:53,250
with it for this presentation so if we

00:01:49,440 --> 00:01:55,650
oversimplify then the inefficiency can

00:01:53,250 --> 00:01:57,780
either come from the library which is

00:01:55,650 --> 00:02:00,479
written and efficiently or uses too many

00:01:57,780 --> 00:02:06,080
obstructions or users code which uses

00:02:00,479 --> 00:02:08,970
library in not the most efficient way so

00:02:06,080 --> 00:02:12,989
we'll address those points separately

00:02:08,970 --> 00:02:14,849
how can we make skala faster but not

00:02:12,989 --> 00:02:19,490
having slow libraries and not having

00:02:14,849 --> 00:02:22,580
slow user code so library can be a sir

00:02:19,490 --> 00:02:25,010
slow down and the main reason for this

00:02:22,580 --> 00:02:27,620
actually comes from simplicity of

00:02:25,010 --> 00:02:30,020
skeletal language so let's consider

00:02:27,620 --> 00:02:33,530
these two examples one is written in

00:02:30,020 --> 00:02:36,680
Java the other is written in Scala so

00:02:33,530 --> 00:02:39,080
the Java one uses for cycle it's quite

00:02:36,680 --> 00:02:40,550
verbose you need to read through it on

00:02:39,080 --> 00:02:43,070
the side of the desk while the skull one

00:02:40,550 --> 00:02:46,430
is obvious it just computer some and

00:02:43,070 --> 00:02:49,280
divides it unfortunately by using the

00:02:46,430 --> 00:02:52,610
convenience here of both the library and

00:02:49,280 --> 00:02:59,240
the language we're losing quite a bit on

00:02:52,610 --> 00:03:04,130
performance set yeah like 20 times so

00:02:59,240 --> 00:03:06,500
let's see why is it the case so if we

00:03:04,130 --> 00:03:08,060
take Java what happens in the Java body

00:03:06,500 --> 00:03:10,790
is quite obvious well it's written here

00:03:08,060 --> 00:03:12,860
so we have the range check for every

00:03:10,790 --> 00:03:14,900
iteration cycle we kept an addition and

00:03:12,860 --> 00:03:16,730
no cap index in current simple

00:03:14,900 --> 00:03:19,040
straightforward nothing hitting here in

00:03:16,730 --> 00:03:21,620
case of Scala actually there is a lot of

00:03:19,040 --> 00:03:23,270
stuff hidden inside so the reduce is

00:03:21,620 --> 00:03:27,530
actually implemented in terms of forage

00:03:23,270 --> 00:03:31,550
and forage does side effect in stuff on

00:03:27,530 --> 00:03:33,380
scope of reduce and because of all the

00:03:31,550 --> 00:03:35,240
stuff there is actually boxing happening

00:03:33,380 --> 00:03:37,580
here dynamic dispatch is happening here

00:03:35,240 --> 00:03:39,050
there's a if inside which checks if

00:03:37,580 --> 00:03:41,450
that's the first elements you're saying

00:03:39,050 --> 00:03:43,670
there's there are two dynamic dispatches

00:03:41,450 --> 00:03:45,860
and there is boxing / every iteration of

00:03:43,670 --> 00:03:47,660
a cycle and that's the reason why it's

00:03:45,860 --> 00:03:50,420
so slow because all this over has

00:03:47,660 --> 00:03:51,590
actually takes more time to execute than

00:03:50,420 --> 00:03:55,160
the actual something that you're

00:03:51,590 --> 00:03:57,080
performing so as those are the

00:03:55,160 --> 00:03:59,480
benchmarks which I've been doing one

00:03:57,080 --> 00:04:01,100
week ago I was present in the same slide

00:03:59,480 --> 00:04:05,560
three years ago and numbers were

00:04:01,100 --> 00:04:09,830
different so at the moment of 2016 mark

00:04:05,560 --> 00:04:11,690
may single boxing costs you somewhere

00:04:09,830 --> 00:04:14,030
like five dynamic dispatches in hot spot

00:04:11,690 --> 00:04:15,740
and by dynamic dispatch is I mean the

00:04:14,030 --> 00:04:17,209
ones which are actually magga morphix or

00:04:15,740 --> 00:04:20,270
they're real dynamic dispatch is not in

00:04:17,209 --> 00:04:22,430
line able the worst case every other

00:04:20,270 --> 00:04:25,280
dynamic dispatches goes to some were

00:04:22,430 --> 00:04:27,800
like three static dispatches if the this

00:04:25,280 --> 00:04:29,690
was either invoke static or normal then

00:04:27,800 --> 00:04:32,660
a dispatch which happens to have only a

00:04:29,690 --> 00:04:34,430
single implementation and

00:04:32,660 --> 00:04:36,980
addition is actually substantially

00:04:34,430 --> 00:04:38,120
faster even than aesthetic dispatches so

00:04:36,980 --> 00:04:39,830
what it means that in the previous

00:04:38,120 --> 00:04:42,050
benchmark where we're doing boxing

00:04:39,830 --> 00:04:45,080
dynamic dispatch all the time most of

00:04:42,050 --> 00:04:50,450
the time goes will spend there why is

00:04:45,080 --> 00:04:51,950
that okay so the reason is that we as I

00:04:50,450 --> 00:04:54,320
said can build convenience libraries in

00:04:51,950 --> 00:04:56,030
Scala so we have higher order types we

00:04:54,320 --> 00:04:58,070
have generic methods we can generate

00:04:56,030 --> 00:05:00,680
classes we have multiple inheritance

00:04:58,070 --> 00:05:02,360
through traits we have pattern matching

00:05:00,680 --> 00:05:05,330
we have lies evaluation we have garbage

00:05:02,360 --> 00:05:06,800
collection okay we're on a hot spot so

00:05:05,330 --> 00:05:08,930
we need to compile into code which runs

00:05:06,800 --> 00:05:11,570
a hot spot which of those features are

00:05:08,930 --> 00:05:15,650
natively supported on hot spot that's

00:05:11,570 --> 00:05:19,040
hot spot have higher order types no does

00:05:15,650 --> 00:05:21,890
it have generic methods no does it have

00:05:19,040 --> 00:05:25,040
generic classes no doesn't have multiple

00:05:21,890 --> 00:05:26,930
inheritance well you can say that kind

00:05:25,040 --> 00:05:28,280
of yes through default methods but

00:05:26,930 --> 00:05:30,290
actually that's not true because it

00:05:28,280 --> 00:05:31,850
doesn't have multiple inheritance of

00:05:30,290 --> 00:05:34,520
field so there were there are more

00:05:31,850 --> 00:05:37,490
restrictions which apply so I would say

00:05:34,520 --> 00:05:39,890
no here though that's arguable so

00:05:37,490 --> 00:05:44,090
doesn't have pattern matching no does it

00:05:39,890 --> 00:05:45,800
have lazy evaluation no well gladly does

00:05:44,090 --> 00:05:50,300
get garbage collection let's thank for

00:05:45,800 --> 00:05:52,760
it so all the features which were before

00:05:50,300 --> 00:05:55,190
which hotspot have they need to be

00:05:52,760 --> 00:05:56,870
lowered by compiler to something which

00:05:55,190 --> 00:05:58,700
will run independent thing on how you

00:05:56,870 --> 00:06:01,100
would use it if you compile it straight

00:05:58,700 --> 00:06:03,320
we need to compile it it conservatively

00:06:01,100 --> 00:06:05,060
assuming that you can do all the

00:06:03,320 --> 00:06:08,390
possible bad things with it and it

00:06:05,060 --> 00:06:10,400
should work correctly in most cases it's

00:06:08,390 --> 00:06:12,410
not it means it's not going to work fast

00:06:10,400 --> 00:06:16,370
because there is nothing that we can

00:06:12,410 --> 00:06:19,850
assume here so to illustrate this i will

00:06:16,370 --> 00:06:21,950
show how compiler compiles generics so

00:06:19,850 --> 00:06:24,470
if you have a generic method plus which

00:06:21,950 --> 00:06:27,200
takes an A and a B and passes them in a

00:06:24,470 --> 00:06:30,500
generic way by korn it in anomeric it's

00:06:27,200 --> 00:06:32,470
compiled by erasing the generics so all

00:06:30,500 --> 00:06:35,510
the t's here are replaced by objects

00:06:32,470 --> 00:06:37,370
what it means in practice that if you

00:06:35,510 --> 00:06:40,430
would use this method two plus two

00:06:37,370 --> 00:06:43,720
integers because integers now need to

00:06:40,430 --> 00:06:46,220
become objects they will be boxed and

00:06:43,720 --> 00:06:49,130
then they will be unboxed back

00:06:46,220 --> 00:06:50,930
as we saw in the previous slides slide

00:06:49,130 --> 00:06:53,630
is actually going to be like 20 times

00:06:50,930 --> 00:06:56,330
slower than if you just add it to

00:06:53,630 --> 00:06:58,130
numbers directly sometimes what's what

00:06:56,330 --> 00:07:02,420
is smart enough to remove this overhead

00:06:58,130 --> 00:07:04,520
but the more levels of generics and the

00:07:02,420 --> 00:07:07,040
more levels of obstructions you use the

00:07:04,520 --> 00:07:08,570
less likely is to be able to find out

00:07:07,040 --> 00:07:13,460
what your what you were doing in the

00:07:08,570 --> 00:07:15,500
first place so there's a different

00:07:13,460 --> 00:07:18,920
option what if compiler instead of

00:07:15,500 --> 00:07:22,330
erasing the generics created clothes

00:07:18,920 --> 00:07:24,650
which would apply to different types so

00:07:22,330 --> 00:07:26,630
let's say that we'll have a plus which

00:07:24,650 --> 00:07:28,370
works route vers for integers we will

00:07:26,630 --> 00:07:32,750
have a plus which works belongs we'll

00:07:28,370 --> 00:07:35,450
have a philosopher to Davos how many

00:07:32,750 --> 00:07:37,250
pluses would we need it depends on how

00:07:35,450 --> 00:07:39,110
many primitive styles do we have so

00:07:37,250 --> 00:07:41,300
Scala has nine primitive types which are

00:07:39,110 --> 00:07:44,090
integers floating point numbers

00:07:41,300 --> 00:07:46,630
bullion's and the void type and decide

00:07:44,090 --> 00:07:50,120
from this Scala has the reference type

00:07:46,630 --> 00:07:53,600
so if you unify all the reference types

00:07:50,120 --> 00:07:55,310
in one type then Scala has ten times

00:07:53,600 --> 00:07:58,550
from point of view of whether the

00:07:55,310 --> 00:08:01,310
reference reprimand if it means that if

00:07:58,550 --> 00:08:03,320
your class has anti parameters if we

00:08:01,310 --> 00:08:04,669
will start cloning and trying to create

00:08:03,320 --> 00:08:07,640
different instances for different

00:08:04,669 --> 00:08:09,680
combinations and associations then we'll

00:08:07,640 --> 00:08:13,880
have time to the power of n variants

00:08:09,680 --> 00:08:15,470
which is a lot it means that in practice

00:08:13,880 --> 00:08:16,669
something like function three isn't

00:08:15,470 --> 00:08:18,830
specialized it will basically because

00:08:16,669 --> 00:08:20,419
it's going to have the total size of all

00:08:18,830 --> 00:08:21,950
the specializations of function three is

00:08:20,419 --> 00:08:25,400
going to be bigger than the whole

00:08:21,950 --> 00:08:28,070
standard library at the moment even

00:08:25,400 --> 00:08:30,229
worse if you have methods inside which

00:08:28,070 --> 00:08:32,210
themselves tape type parameters then

00:08:30,229 --> 00:08:34,130
well you'll have 10 to the power of

00:08:32,210 --> 00:08:36,409
number of parameters in a class and now

00:08:34,130 --> 00:08:40,339
where the parameters of the method which

00:08:36,409 --> 00:08:42,469
makes it not practical even in this

00:08:40,339 --> 00:08:44,150
small cases like you have one class with

00:08:42,469 --> 00:08:49,520
one diaper amateur and the message miss

00:08:44,150 --> 00:08:52,339
to type parameters ok so in 2010 um drug

00:08:49,520 --> 00:08:53,810
rush was implementing something called

00:08:52,339 --> 00:08:56,120
specialization and he understood that

00:08:53,810 --> 00:08:58,280
you don't actually need to specialize

00:08:56,120 --> 00:08:59,880
all of your stuff into specialized some

00:08:58,280 --> 00:09:01,800
places which matter for performance

00:08:59,880 --> 00:09:04,320
so he will he created specialized

00:09:01,800 --> 00:09:06,210
notation where you can ask where user

00:09:04,320 --> 00:09:11,040
was provided input for what's going to

00:09:06,210 --> 00:09:13,320
be specialized there was a limitation

00:09:11,040 --> 00:09:14,670
there which was a limitation of

00:09:13,320 --> 00:09:16,500
implementation that it didn't support

00:09:14,670 --> 00:09:18,960
inheritance and there was actually one

00:09:16,500 --> 00:09:21,870
more limitation that if your class had

00:09:18,960 --> 00:09:23,790
fields then air tax is a the specialized

00:09:21,870 --> 00:09:26,700
versions will actually have both generic

00:09:23,790 --> 00:09:29,610
fields and specialized fields see so it

00:09:26,700 --> 00:09:33,180
may have like it may be like twice

00:09:29,610 --> 00:09:34,080
bigger in terms of memory footprint in

00:09:33,180 --> 00:09:36,690
order to solve some of these problems

00:09:34,080 --> 00:09:39,210
there was a mini boxing project by lata

00:09:36,690 --> 00:09:41,550
vaca who made it simpler to decide what

00:09:39,210 --> 00:09:43,470
to specialize by replacing 10 to the

00:09:41,550 --> 00:09:46,550
power of n by 3 to the power plant looks

00:09:43,470 --> 00:09:49,130
financial but at least it makes it

00:09:46,550 --> 00:09:51,410
practical to specialized function 3

00:09:49,130 --> 00:09:55,830
there was some performance degradation

00:09:51,410 --> 00:09:59,070
in some really complicated cases doesn't

00:09:55,830 --> 00:10:01,290
happen in normal code the great thing it

00:09:59,070 --> 00:10:03,030
does handle inheritance and that's the

00:10:01,290 --> 00:10:06,000
main source of performance degradation

00:10:03,030 --> 00:10:08,340
that can happen it has problems with the

00:10:06,000 --> 00:10:10,350
race because it tries to store different

00:10:08,340 --> 00:10:13,560
types of integers all of the same long

00:10:10,350 --> 00:10:15,900
and then you can't uniformly do the same

00:10:13,560 --> 00:10:17,880
within an array and it has a complicated

00:10:15,900 --> 00:10:19,860
implementation implementation of mini

00:10:17,880 --> 00:10:23,450
boxing is compared to something like

00:10:19,860 --> 00:10:26,940
one-third of the whole scale AC compiler

00:10:23,450 --> 00:10:29,430
yeah so both of this approaches have a

00:10:26,940 --> 00:10:31,440
problem so let's say your library order

00:10:29,430 --> 00:10:34,530
in particular let's say you're in

00:10:31,440 --> 00:10:38,160
standard library so let's take function

00:10:34,530 --> 00:10:40,800
3 function 3 has 4 type arguments as a

00:10:38,160 --> 00:10:42,180
library in either mini box of seeing of

00:10:40,800 --> 00:10:45,240
specialization into this site are you

00:10:42,180 --> 00:10:47,160
going to specialize it or not and if you

00:10:45,240 --> 00:10:49,350
do you need to decide which types are

00:10:47,160 --> 00:10:50,940
going to specialize it for the problem

00:10:49,350 --> 00:10:52,590
here is a different people are going to

00:10:50,940 --> 00:10:57,000
use function through in different ways

00:10:52,590 --> 00:11:00,300
and it's very unlikely that you would be

00:10:57,000 --> 00:11:01,470
able to fit all of them at once you will

00:11:00,300 --> 00:11:02,490
need to decide which functions they

00:11:01,470 --> 00:11:05,400
specialized for because you don't want

00:11:02,490 --> 00:11:07,440
to have 10 to the power of 4 and that's

00:11:05,400 --> 00:11:10,890
decision that scalar C does specializes

00:11:07,440 --> 00:11:13,430
functions for commonly used types so if

00:11:10,890 --> 00:11:16,460
you have functioned to on doubles it's

00:11:13,430 --> 00:11:18,560
on float it's specialized function 3 is

00:11:16,460 --> 00:11:21,710
specialized on the four doubles not for

00:11:18,560 --> 00:11:23,450
floats and it may need from you it made

00:11:21,710 --> 00:11:26,210
me that suddenly introduced in one more

00:11:23,450 --> 00:11:27,980
argument you're becoming slower what I'm

00:11:26,210 --> 00:11:29,779
trying to put my finger on here is that

00:11:27,980 --> 00:11:32,029
specialization and mini boxing bull a

00:11:29,779 --> 00:11:35,870
break modularity because they make

00:11:32,029 --> 00:11:39,110
library otter assume how would user use

00:11:35,870 --> 00:11:42,470
the code and that not in performance

00:11:39,110 --> 00:11:43,820
critical code what kind of patterns are

00:11:42,470 --> 00:11:45,740
going to be used in performance critical

00:11:43,820 --> 00:11:47,390
code and what kind of patterns are going

00:11:45,740 --> 00:11:49,580
to be used in non performance critical

00:11:47,390 --> 00:11:51,649
code it's a very complicated question

00:11:49,580 --> 00:11:53,300
even if you're asking it about your own

00:11:51,649 --> 00:11:56,440
code base because he normally is

00:11:53,300 --> 00:12:00,649
profiling to actually get the answer and

00:11:56,440 --> 00:12:02,420
here well library needs to speculate and

00:12:00,649 --> 00:12:05,959
guess and in most cases the gas is

00:12:02,420 --> 00:12:10,910
actually wrong so the question is other

00:12:05,959 --> 00:12:13,700
any other options so hmm let's think

00:12:10,910 --> 00:12:15,890
what question was asked by hulen and

00:12:13,700 --> 00:12:17,450
plaid here so they were asking the

00:12:15,890 --> 00:12:19,550
question how many specializations are

00:12:17,450 --> 00:12:21,709
needed so specialization was saying that

00:12:19,550 --> 00:12:26,300
for function for you needed 10,000

00:12:21,709 --> 00:12:30,380
classes meaning often set 81 I would

00:12:26,300 --> 00:12:32,150
claim that the question was wrong so

00:12:30,380 --> 00:12:33,709
what would be the right question let's

00:12:32,150 --> 00:12:35,540
start with this question how many

00:12:33,709 --> 00:12:38,060
specializations are needed in your code

00:12:35,540 --> 00:12:40,400
I mean I have my particular code base in

00:12:38,060 --> 00:12:45,529
my particular code base I'm using some

00:12:40,400 --> 00:12:47,360
specific functions in my code I don't

00:12:45,529 --> 00:12:50,900
actually use function for which takes

00:12:47,360 --> 00:12:54,080
for voids and returns a void but

00:12:50,900 --> 00:12:55,910
somebody may I don't use functions which

00:12:54,080 --> 00:13:01,160
take four characters in your current

00:12:55,910 --> 00:13:02,839
character but somebody might so maybe I

00:13:01,160 --> 00:13:04,339
should have an aversion which is

00:13:02,839 --> 00:13:06,320
different from the one that that the

00:13:04,339 --> 00:13:09,290
guiding roosts because my use case is

00:13:06,320 --> 00:13:13,160
different actually even this question is

00:13:09,290 --> 00:13:15,829
strong why because both of us use

00:13:13,160 --> 00:13:18,529
libraries and the question is not which

00:13:15,829 --> 00:13:21,430
versions does my code eat the question

00:13:18,529 --> 00:13:24,920
is what versions does all my

00:13:21,430 --> 00:13:26,810
dependencies and my application need so

00:13:24,920 --> 00:13:29,420
if i use only functions from

00:13:26,810 --> 00:13:32,029
characters though the library uses

00:13:29,420 --> 00:13:35,210
functions of integers and in both for my

00:13:32,029 --> 00:13:37,610
application to run tests and that's the

00:13:35,210 --> 00:13:39,890
specific question that auto

00:13:37,610 --> 00:13:43,070
specialization link yourselves it takes

00:13:39,890 --> 00:13:45,050
your program it takes your libraries it

00:13:43,070 --> 00:13:48,110
analyzes how to use the libraries

00:13:45,050 --> 00:13:50,240
analyzes all your code it analyzes all

00:13:48,110 --> 00:13:51,800
your dependencies it sees what

00:13:50,240 --> 00:13:54,920
combinations of type arguments are

00:13:51,800 --> 00:13:56,029
needed which locations do they reach so

00:13:54,920 --> 00:13:58,460
for example let's say you instantiate

00:13:56,029 --> 00:14:01,040
vectors of integers and list all doubles

00:13:58,460 --> 00:14:04,700
on vectors the only thing you do you to

00:14:01,040 --> 00:14:06,850
prepend and index and for loose the only

00:14:04,700 --> 00:14:09,350
thing to do is you check their size

00:14:06,850 --> 00:14:11,390
what's going to do is it's going to make

00:14:09,350 --> 00:14:13,010
factors which are capable of only

00:14:11,390 --> 00:14:15,200
storing the type that you need and doing

00:14:13,010 --> 00:14:16,760
all the operations that you need vectors

00:14:15,200 --> 00:14:18,620
aren't going to have zip on them because

00:14:16,760 --> 00:14:20,600
you don't need it the same will happen

00:14:18,620 --> 00:14:22,430
with doubles or there was list of

00:14:20,600 --> 00:14:24,410
doubles list of doubles won't be able to

00:14:22,430 --> 00:14:25,970
do random access index because you don't

00:14:24,410 --> 00:14:29,710
need it in your particular implication

00:14:25,970 --> 00:14:32,780
and this happens without library otter

00:14:29,710 --> 00:14:34,520
annotating their stuff library orders

00:14:32,780 --> 00:14:36,110
don't need to assume which functions

00:14:34,520 --> 00:14:38,480
they would be you would need in which

00:14:36,110 --> 00:14:41,080
combinations of use cases your

00:14:38,480 --> 00:14:46,040
particular applications going to require

00:14:41,080 --> 00:14:49,339
as an implementation artifact there is a

00:14:46,040 --> 00:14:51,830
fatty use case here so the

00:14:49,339 --> 00:14:55,850
implementation treats type arguments and

00:14:51,830 --> 00:14:59,330
term arguments in the very same way so

00:14:55,850 --> 00:15:02,450
for type arguments type specialization

00:14:59,330 --> 00:15:05,060
removes boxing it says that if something

00:15:02,450 --> 00:15:07,640
was a tea now I know it's an integer and

00:15:05,060 --> 00:15:11,270
it can eliminate boxing of integers by

00:15:07,640 --> 00:15:14,810
knowing more term specialization says I

00:15:11,270 --> 00:15:17,480
know what this term is I know specific

00:15:14,810 --> 00:15:19,310
type of this term it's not as spill just

00:15:17,480 --> 00:15:22,040
as serializable it's not just the

00:15:19,310 --> 00:15:24,050
product I know what kind of product and

00:15:22,040 --> 00:15:27,050
serial I suppose it it removes virtual

00:15:24,050 --> 00:15:30,650
dispatch in the same implementation

00:15:27,050 --> 00:15:35,180
without doing any changes that's great

00:15:30,650 --> 00:15:37,010
and it came for free yeah awesome so

00:15:35,180 --> 00:15:39,980
aside from this removing virtual

00:15:37,010 --> 00:15:40,700
dispatch is very helpful because hotspot

00:15:39,980 --> 00:15:43,340
that's all

00:15:40,700 --> 00:15:47,360
runtime type profiling to remove virtual

00:15:43,340 --> 00:15:49,640
dispatch we may have some new back end

00:15:47,360 --> 00:15:52,970
by Dennis which going to present it

00:15:49,640 --> 00:15:54,470
tomorrow in the evening where it tries

00:15:52,970 --> 00:15:56,360
to make sure that in runtime no

00:15:54,470 --> 00:15:58,220
compilation is performed in runtime

00:15:56,360 --> 00:16:00,740
there shouldn't be any warm up time it

00:15:58,220 --> 00:16:03,290
means that virtual cause which Scala has

00:16:00,740 --> 00:16:05,780
a lot should be optimized at compile

00:16:03,290 --> 00:16:07,940
time in a replication to run fast so

00:16:05,780 --> 00:16:10,010
this project that's going to be

00:16:07,940 --> 00:16:14,750
announced tomorrow may benefit from the

00:16:10,010 --> 00:16:16,160
virtualization a lot ok so this is a

00:16:14,750 --> 00:16:18,110
demo benchmark which is actually the

00:16:16,160 --> 00:16:21,110
worst case so I'm taking the operation

00:16:18,110 --> 00:16:25,610
which is one of the fastest to perform

00:16:21,110 --> 00:16:26,840
on hotspot some integers and just

00:16:25,610 --> 00:16:28,850
fasters to perform on the only

00:16:26,840 --> 00:16:31,640
contemporary CPUs and I'm trying to

00:16:28,850 --> 00:16:33,650
measure how many overheads does library

00:16:31,640 --> 00:16:36,020
create by using some specifics wasting

00:16:33,650 --> 00:16:38,750
for eliminating library overheads so in

00:16:36,020 --> 00:16:40,640
Java if we reinforce cycle that's a

00:16:38,750 --> 00:16:45,340
baseline in days for 25 milliseconds in

00:16:40,640 --> 00:16:47,720
squad 211 it's it takes 20 times more

00:16:45,340 --> 00:16:50,750
gladly Lucas has been working a lot and

00:16:47,720 --> 00:16:54,230
optimizing to 12 and into 12 it runs a

00:16:50,750 --> 00:16:56,810
bit faster but still slow if you compare

00:16:54,230 --> 00:16:59,060
it to Java so I was starting with my

00:16:56,810 --> 00:17:00,590
project which was scallop list which was

00:16:59,060 --> 00:17:02,900
trying to optimize collection

00:17:00,590 --> 00:17:05,030
specifically knowing what collections do

00:17:02,900 --> 00:17:07,610
now in the semantics of every operation

00:17:05,030 --> 00:17:10,970
and it knew what reuse means and it was

00:17:07,610 --> 00:17:13,130
able to optimize it a lot finally enough

00:17:10,970 --> 00:17:14,870
it was doing some low-level tricks that

00:17:13,130 --> 00:17:17,839
you don't normally use when you write

00:17:14,870 --> 00:17:19,640
for cycles it was doing block processing

00:17:17,839 --> 00:17:22,850
in particular and because of this it was

00:17:19,640 --> 00:17:25,579
able to outperform Java actually we

00:17:22,850 --> 00:17:28,040
wrote a paper about it it was on par

00:17:25,579 --> 00:17:30,350
with the best frameworks which exist for

00:17:28,040 --> 00:17:32,840
high-performance operation in in see it

00:17:30,350 --> 00:17:34,820
was on par 4 with Intel thread building

00:17:32,840 --> 00:17:36,560
blocks in case of parallelism and C

00:17:34,820 --> 00:17:39,650
standard collections in case of

00:17:36,560 --> 00:17:41,260
sequential operations so the stuff that

00:17:39,650 --> 00:17:44,090
I'm working on now is a bit slower

00:17:41,260 --> 00:17:46,010
mainly because it doesn't know about

00:17:44,090 --> 00:17:46,940
reduce in the first place it just did

00:17:46,010 --> 00:17:48,950
optimizations which are

00:17:46,940 --> 00:17:50,870
language-specific it doesn't know about

00:17:48,950 --> 00:17:55,240
that it also optimized in collections in

00:17:50,870 --> 00:17:55,240
knew nothing about your code up front

00:17:55,500 --> 00:18:01,540
there is one more data point here which

00:17:58,540 --> 00:18:04,210
is colleges which runs on JavaScript

00:18:01,540 --> 00:18:06,730
which is slow by default but if the good

00:18:04,210 --> 00:18:09,760
thing is that SAP by doing his

00:18:06,730 --> 00:18:11,620
optimizations in his linker which lanes

00:18:09,760 --> 00:18:14,080
JavaScript specifically which knows

00:18:11,620 --> 00:18:16,420
about JavaScript and colleges was able

00:18:14,080 --> 00:18:19,260
to make it not ridiculously slowed

00:18:16,420 --> 00:18:25,030
compared to scale which is already great

00:18:19,260 --> 00:18:27,370
yeah so there are limitations here first

00:18:25,030 --> 00:18:31,450
of all it needs to analyze your program

00:18:27,370 --> 00:18:34,740
on my examples which are small usages of

00:18:31,450 --> 00:18:37,240
collections in most cases it means it

00:18:34,740 --> 00:18:39,970
compiles like fifty percent slower than

00:18:37,240 --> 00:18:42,430
if you compare it with dotty the good

00:18:39,970 --> 00:18:44,880
thing about it is a dotty in my use

00:18:42,430 --> 00:18:48,490
cases it's twice faster than skele see

00:18:44,880 --> 00:18:50,770
so it kind of means that the optimized

00:18:48,490 --> 00:18:53,740
let's say a small operation collection

00:18:50,770 --> 00:18:56,020
is reduced compiling it in optimized way

00:18:53,740 --> 00:18:59,110
is faster than just normal compilation

00:18:56,020 --> 00:19:01,330
with skeleton unfortunately it requires

00:18:59,110 --> 00:19:03,550
your because linker needs to understand

00:19:01,330 --> 00:19:05,260
your dependencies it requires your

00:19:03,550 --> 00:19:07,240
dependencies to have taste in the first

00:19:05,260 --> 00:19:09,220
place so your dependency should be

00:19:07,240 --> 00:19:13,180
compiled either word Dottie or linker

00:19:09,220 --> 00:19:14,710
itself so yeah it will take some time

00:19:13,180 --> 00:19:17,770
for Dottie to get adoption and they may

00:19:14,710 --> 00:19:21,010
be a blocker for quite some time it does

00:19:17,770 --> 00:19:23,560
not help if the library does tricks by

00:19:21,010 --> 00:19:26,560
tricks I mean something like finding

00:19:23,560 --> 00:19:29,950
casts that vector does so if you if

00:19:26,560 --> 00:19:31,780
you're lying your user its signature and

00:19:29,950 --> 00:19:34,840
you're saying that you take a tea and

00:19:31,780 --> 00:19:37,060
tea can be whatever and then you cussed

00:19:34,840 --> 00:19:41,100
at T to an object so you're casting an

00:19:37,060 --> 00:19:43,870
integer to an object linker is going to

00:19:41,100 --> 00:19:45,760
understand this and not optimized in the

00:19:43,870 --> 00:19:50,130
first place because if i'll rewrite it

00:19:45,760 --> 00:19:52,660
to using primitives cast will fail and

00:19:50,130 --> 00:19:56,500
some of the collections in the standard

00:19:52,660 --> 00:19:58,660
library try to do districts vectors

00:19:56,500 --> 00:20:02,680
don't benefit from optimization from

00:19:58,660 --> 00:20:04,800
this lists arrays and ranges do the same

00:20:02,680 --> 00:20:07,000
happens if you use now as a special type

00:20:04,800 --> 00:20:09,610
so if you have an array

00:20:07,000 --> 00:20:11,620
t it may be an array of integers and

00:20:09,610 --> 00:20:15,150
doesn't mean that you can store in all

00:20:11,620 --> 00:20:17,380
there and be able to read now from there

00:20:15,150 --> 00:20:19,000
that's the same thing that's one more

00:20:17,380 --> 00:20:20,890
trick that vector does and some of the

00:20:19,000 --> 00:20:23,380
common libraries do so in order to

00:20:20,890 --> 00:20:26,500
benefit from it a lot you need to not be

00:20:23,380 --> 00:20:28,750
try to be smarter than hot spot that

00:20:26,500 --> 00:20:32,650
compiler and optimizer because in most

00:20:28,750 --> 00:20:34,300
cases even if you're smarter today they

00:20:32,650 --> 00:20:36,490
will get improved over the years and

00:20:34,300 --> 00:20:39,700
it's very likely that in five years from

00:20:36,490 --> 00:20:40,840
now the code that you assume to be smart

00:20:39,700 --> 00:20:43,060
is actually stupid this lots of

00:20:40,840 --> 00:20:45,700
musicians from happening like it's going

00:20:43,060 --> 00:20:47,440
to happen now and the same happens if

00:20:45,700 --> 00:20:49,480
you have a typed API button depth in

00:20:47,440 --> 00:20:51,760
journals I saw quite several libraries

00:20:49,480 --> 00:20:54,430
in the echo system which use shapeless

00:20:51,760 --> 00:20:57,790
to create a highly typed epi but then

00:20:54,430 --> 00:20:59,800
the library cannot survive with such

00:20:57,790 --> 00:21:01,810
complicated types inside because they

00:20:59,800 --> 00:21:04,240
both take long time to compile and it

00:21:01,810 --> 00:21:06,130
takes it's very unpleasant to figure out

00:21:04,240 --> 00:21:09,460
what the where the box so it's going to

00:21:06,130 --> 00:21:10,900
just cost everything to any implement it

00:21:09,460 --> 00:21:12,850
and cast it back when it needs to be

00:21:10,900 --> 00:21:14,380
writing to user this libraries obvious

00:21:12,850 --> 00:21:17,850
is not going to benefit from any kind of

00:21:14,380 --> 00:21:17,850
optimizations which are developed here

00:21:18,210 --> 00:21:25,600
okay so now we're coming back to

00:21:21,040 --> 00:21:28,360
question of users code so one more

00:21:25,600 --> 00:21:31,750
source of inefficiency is your less code

00:21:28,360 --> 00:21:34,990
and there is a good reason for it let's

00:21:31,750 --> 00:21:37,180
say you're a user and when i'm thinking

00:21:34,990 --> 00:21:40,150
i commonly write the code like this so i

00:21:37,180 --> 00:21:42,280
have some collection which may be a list

00:21:40,150 --> 00:21:44,890
in this case it is a list and i'm

00:21:42,280 --> 00:21:46,810
thinking that exercise if x is those

00:21:44,890 --> 00:21:49,270
size is equal to 0 then they should do

00:21:46,810 --> 00:21:51,100
stuff unfortunately this code is

00:21:49,270 --> 00:21:53,140
inefficient because it is of size equals

00:21:51,100 --> 00:21:55,660
to 0 computing extra size takes linear

00:21:53,140 --> 00:21:58,500
time but I actually intended to write

00:21:55,660 --> 00:22:04,600
was this how did you check if it's empty

00:21:58,500 --> 00:22:06,340
this is a lot faster and during the code

00:22:04,600 --> 00:22:09,010
review during my lifetime I need to

00:22:06,340 --> 00:22:13,270
spend a lot of time making sure that I

00:22:09,010 --> 00:22:14,860
do the right thing here though I mean we

00:22:13,270 --> 00:22:16,780
have a stupid we don't have a stupid

00:22:14,860 --> 00:22:19,060
compiler we have a smart compiler why

00:22:16,780 --> 00:22:20,240
shouldn't do it for us the other example

00:22:19,060 --> 00:22:21,679
is even

00:22:20,240 --> 00:22:25,490
more complicated so let's say you have a

00:22:21,679 --> 00:22:28,520
series of operations okay can everybody

00:22:25,490 --> 00:22:30,230
in stand what's happening here it takes

00:22:28,520 --> 00:22:32,690
me 20 seconds to understand what's

00:22:30,230 --> 00:22:35,600
happening here why because somebody was

00:22:32,690 --> 00:22:38,390
trying to be fast he took this coat on

00:22:35,600 --> 00:22:40,130
the right which was modular it was doing

00:22:38,390 --> 00:22:42,170
independent filtering it was doing

00:22:40,130 --> 00:22:44,360
independent flat maps it was trying to

00:22:42,170 --> 00:22:47,030
make operation in steps which made sense

00:22:44,360 --> 00:22:51,380
on their own and he fused them by hand

00:22:47,030 --> 00:22:52,820
in order to make it run faster I'm

00:22:51,380 --> 00:22:55,160
presented herein example which feeds on

00:22:52,820 --> 00:22:57,590
a slide in practice it's happens with

00:22:55,160 --> 00:22:59,030
examples which don't feed in a slide you

00:22:57,590 --> 00:23:01,520
have a serious operations let's say in

00:22:59,030 --> 00:23:03,740
spark and collections which ever of the

00:23:01,520 --> 00:23:06,170
step makes sense from the domain point

00:23:03,740 --> 00:23:08,390
of view in order to make it run fast the

00:23:06,170 --> 00:23:11,330
fuses they not only all in some huge

00:23:08,390 --> 00:23:12,530
giant which is impossible to maintain

00:23:11,330 --> 00:23:16,040
and you do it for the sake of

00:23:12,530 --> 00:23:19,220
performance so when I'm saying that user

00:23:16,040 --> 00:23:22,309
wrote an efficient code he may have had

00:23:19,220 --> 00:23:24,530
good reasons for doing so he may have

00:23:22,309 --> 00:23:26,480
done it for maintenance he may have done

00:23:24,530 --> 00:23:28,580
it to make code easier to understand

00:23:26,480 --> 00:23:30,830
because there are some people hard that

00:23:28,580 --> 00:23:33,290
experience in the code base and he wants

00:23:30,830 --> 00:23:35,360
to make sure that this the bugs are

00:23:33,290 --> 00:23:38,450
discovered early during code review for

00:23:35,360 --> 00:23:41,450
example so what I'm trying to pinpoint

00:23:38,450 --> 00:23:44,000
my finger on here is that we need

00:23:41,450 --> 00:23:45,980
library specific optimizations as I was

00:23:44,000 --> 00:23:48,140
saying previously linker provided a lot

00:23:45,980 --> 00:23:50,179
of performance improvement there by not

00:23:48,140 --> 00:23:51,590
knowing all the library did but there

00:23:50,179 --> 00:23:54,020
was partly there wasn't able to achieve

00:23:51,590 --> 00:23:56,540
that scalability did because skeletons

00:23:54,020 --> 00:23:59,000
knew something about the library it knew

00:23:56,540 --> 00:24:00,770
some tricks it was able to perform to

00:23:59,000 --> 00:24:02,870
get the most out of the proof of the

00:24:00,770 --> 00:24:06,080
code but it's required to know what

00:24:02,870 --> 00:24:08,540
reduce actually is so let's start with

00:24:06,080 --> 00:24:11,960
the examples that I propose just on the

00:24:08,540 --> 00:24:14,570
previous slide so we want to say that X

00:24:11,960 --> 00:24:17,270
dot length where X is a sequence when it

00:24:14,570 --> 00:24:18,950
is compared to zero well it should just

00:24:17,270 --> 00:24:23,120
be reviewed from taking so damn is that

00:24:18,950 --> 00:24:25,130
empty so what linker provides you it

00:24:23,120 --> 00:24:27,620
provides your rewrite rules which allow

00:24:25,130 --> 00:24:29,360
to define this in a convenient syntax so

00:24:27,620 --> 00:24:32,690
what you're saying is I'm defining a

00:24:29,360 --> 00:24:33,530
rewrite which says if you have the code

00:24:32,690 --> 00:24:35,510
which is it

00:24:33,530 --> 00:24:37,850
that length equals zero where excess

00:24:35,510 --> 00:24:41,480
arbitrary sequence just rewrite it twigs

00:24:37,850 --> 00:24:43,940
is empty that's all that's all you need

00:24:41,480 --> 00:24:47,630
to do I've been doing this stuff with

00:24:43,940 --> 00:24:49,430
macros and scalability implementing such

00:24:47,630 --> 00:24:51,320
operations and macros because they need

00:24:49,430 --> 00:24:55,280
to cover all the cases all the possible

00:24:51,320 --> 00:24:57,260
comparisons with length they need you

00:24:55,280 --> 00:24:59,090
need to fuse all rules in a single rule

00:24:57,260 --> 00:25:03,950
and then the average size of the rule is

00:24:59,090 --> 00:25:05,600
800 lines yeah it was possible but it

00:25:03,950 --> 00:25:09,440
took a lot time to implement an even

00:25:05,600 --> 00:25:11,240
more time to test let's take the second

00:25:09,440 --> 00:25:12,740
example let's take let's say that we

00:25:11,240 --> 00:25:14,540
kept operations on big integers we're

00:25:12,740 --> 00:25:17,420
Bank we're doing some stuff as being

00:25:14,540 --> 00:25:18,800
integers and we kept division normally

00:25:17,420 --> 00:25:20,240
operations on begin de jure starts slow

00:25:18,800 --> 00:25:23,030
but there are some kinds of operations

00:25:20,240 --> 00:25:25,190
on big integers which are fast in

00:25:23,030 --> 00:25:27,530
particular for example shifts so want to

00:25:25,190 --> 00:25:30,680
write an optimization which does

00:25:27,530 --> 00:25:32,330
conditionally check if something is e to

00:25:30,680 --> 00:25:35,150
the power of two you can actually use

00:25:32,330 --> 00:25:37,360
the system to do it you can ensure that

00:25:35,150 --> 00:25:40,130
the thing that you're dividing on is

00:25:37,360 --> 00:25:43,370
literal and you can generate a code

00:25:40,130 --> 00:25:45,890
which will take advantage from partial

00:25:43,370 --> 00:25:49,130
evaluation either in Lincoln hotspot or

00:25:45,890 --> 00:25:52,430
actually both that you generate such an

00:25:49,130 --> 00:25:54,950
if we're actually a here is a constant

00:25:52,430 --> 00:25:56,750
and what's going to happen is this if

00:25:54,950 --> 00:26:00,680
one of the branches is going to die

00:25:56,750 --> 00:26:03,020
because the if condition here is either

00:26:00,680 --> 00:26:05,870
always true or always false if the a is

00:26:03,020 --> 00:26:11,090
a constant and this allows you to do

00:26:05,870 --> 00:26:12,980
optimizations on begins for example what

00:26:11,090 --> 00:26:14,840
else you can do is you can check for for

00:26:12,980 --> 00:26:16,670
example purity so when I was talking

00:26:14,840 --> 00:26:19,700
about collections one of the complicated

00:26:16,670 --> 00:26:22,070
checks to perform was this so let's say

00:26:19,700 --> 00:26:24,260
you want fuse two filters if the

00:26:22,070 --> 00:26:27,290
operation which is being performed on

00:26:24,260 --> 00:26:30,290
element isn't pure joining two filters

00:26:27,290 --> 00:26:32,240
together is incorrect because the side

00:26:30,290 --> 00:26:33,860
effects will happen in different order

00:26:32,240 --> 00:26:36,530
for example let's say you were printing

00:26:33,860 --> 00:26:37,880
numbers let's say that the first lump

00:26:36,530 --> 00:26:39,170
that was praying to know the numbers saw

00:26:37,880 --> 00:26:43,040
and the second lamb that was printing

00:26:39,170 --> 00:26:45,110
all the numbers so if you will run them

00:26:43,040 --> 00:26:47,299
together the order in which printing

00:26:45,110 --> 00:26:49,489
will happen will be interleaved

00:26:47,299 --> 00:26:51,379
so you need to check if the function is

00:26:49,489 --> 00:26:53,090
pure and you can encourage in this

00:26:51,379 --> 00:26:54,499
simple rules once again you don't need

00:26:53,090 --> 00:26:56,330
to write the complicated macro which

00:26:54,499 --> 00:26:59,419
introduces so all notion of purity and

00:26:56,330 --> 00:27:00,769
checks for it you just say that well as

00:26:59,419 --> 00:27:02,840
previously I'm taking the list I'm

00:27:00,769 --> 00:27:04,580
taking into any kind of lambda any other

00:27:02,840 --> 00:27:08,480
kind of lambda and I'm checking that the

00:27:04,580 --> 00:27:11,090
first time days here that's all and this

00:27:08,480 --> 00:27:12,289
rule will be only apply it leave the

00:27:11,090 --> 00:27:14,929
lambda is pure and will be applied

00:27:12,289 --> 00:27:23,859
globally it will be applied through yes

00:27:14,929 --> 00:27:23,859
please no no that's an end

00:27:33,010 --> 00:27:40,450
so so the first filter gets only three

00:27:37,950 --> 00:27:43,630
okay I'll get to this into the next

00:27:40,450 --> 00:27:48,640
slides I'll show you why it's right okay

00:27:43,630 --> 00:27:51,790
I have the answer for this okay so here

00:27:48,640 --> 00:27:53,590
you can define that you have a very

00:27:51,790 --> 00:27:56,170
limited amount of conditions that you

00:27:53,590 --> 00:27:57,880
can here's here which is intended to

00:27:56,170 --> 00:28:01,470
have simple rules streamline for

00:27:57,880 --> 00:28:03,640
complicated stuff you have Scala nada

00:28:01,470 --> 00:28:07,030
another thing that you can have here is

00:28:03,640 --> 00:28:10,510
warnings one of the reasons why scallop

00:28:07,030 --> 00:28:12,910
boots was done was to remove parallel

00:28:10,510 --> 00:28:14,710
collections from the standard likely to

00:28:12,910 --> 00:28:16,780
not have parallel collections instance

00:28:14,710 --> 00:28:18,640
standard collections why because if they

00:28:16,780 --> 00:28:20,290
do you have this funny case that

00:28:18,640 --> 00:28:23,620
somebody can write least one two three

00:28:20,290 --> 00:28:25,810
dot par not reduce left and assume that

00:28:23,620 --> 00:28:28,090
it was going to run in peril the problem

00:28:25,810 --> 00:28:30,880
here is that the definition of reduced

00:28:28,090 --> 00:28:34,210
left makes it impossible to run and

00:28:30,880 --> 00:28:35,560
parallel in the first place but because

00:28:34,210 --> 00:28:37,960
of the wake of libraries decide you

00:28:35,560 --> 00:28:40,510
actually wanted to make sure that the

00:28:37,960 --> 00:28:43,690
permanent collection can run can act as

00:28:40,510 --> 00:28:47,050
if they were normal collection so you

00:28:43,690 --> 00:28:48,280
can pass them everywhere so what's

00:28:47,050 --> 00:28:50,140
happening here they want to have some

00:28:48,280 --> 00:28:52,030
kind of warning to say using this unit

00:28:50,140 --> 00:28:53,650
is made to do it something wrong that's

00:28:52,030 --> 00:28:55,510
what you can do easily here so you can

00:28:53,650 --> 00:28:57,490
define a rule which is looking for this

00:28:55,510 --> 00:29:01,030
code where X is some kind of part of the

00:28:57,490 --> 00:29:02,980
sequence and somebody does have reduced

00:29:01,030 --> 00:29:05,710
lack of parallel sequence and you will

00:29:02,980 --> 00:29:08,650
eat your warning to him and the great

00:29:05,710 --> 00:29:10,420
stuff is run through generics so if

00:29:08,650 --> 00:29:12,070
somebody is going to pass a perilous

00:29:10,420 --> 00:29:14,710
didn't signals in engineering place and

00:29:12,070 --> 00:29:17,710
then polo reduced lunch on it because of

00:29:14,710 --> 00:29:19,960
the analysis will be able to see in fact

00:29:17,710 --> 00:29:22,090
that the selected here says sequence

00:29:19,960 --> 00:29:26,040
actual there is a parallel sequestration

00:29:22,090 --> 00:29:26,040
displays and it shouldn't

00:29:26,890 --> 00:29:33,020
aside from this you can have any longer

00:29:29,000 --> 00:29:36,590
so let's say you have jabo to Lodi and

00:29:33,020 --> 00:29:39,560
you want to make sure that what do you

00:29:36,590 --> 00:29:42,200
make blogging if one is disabled you

00:29:39,560 --> 00:29:43,550
don't want to create the pests and pass

00:29:42,200 --> 00:29:45,290
a string that you're passing there or

00:29:43,550 --> 00:29:46,910
create the lab there's something there's

00:29:45,290 --> 00:29:49,070
a standard pattern that before doing

00:29:46,910 --> 00:29:50,870
logging in Java and Scala you're

00:29:49,070 --> 00:29:52,880
actually going to check if logging is

00:29:50,870 --> 00:29:54,620
enabled and if it is you're actually

00:29:52,880 --> 00:29:57,440
going to drool logging and the looking

00:29:54,620 --> 00:29:59,360
inside going to check it once again it's

00:29:57,440 --> 00:30:00,350
a very inconvenience index which once

00:29:59,360 --> 00:30:03,170
again you're doing for the sake of

00:30:00,350 --> 00:30:05,060
performance but well it can be done by

00:30:03,170 --> 00:30:08,420
comparing a compiler itself so it here

00:30:05,060 --> 00:30:11,690
is that for java library if you call x

00:30:08,420 --> 00:30:14,660
dot info in java standard logging it

00:30:11,690 --> 00:30:16,400
just replaces with if if info level is

00:30:14,660 --> 00:30:18,620
enabled then to logging you don't need

00:30:16,400 --> 00:30:20,000
to do it by hand anymore you're saving

00:30:18,620 --> 00:30:22,970
your time you're saving your reviewers

00:30:20,000 --> 00:30:25,070
time pull requests don't need any more

00:30:22,970 --> 00:30:27,260
to get stopped because somebody did the

00:30:25,070 --> 00:30:29,360
right thing but it did it in convenient

00:30:27,260 --> 00:30:33,130
way for him but not in the most

00:30:29,360 --> 00:30:35,870
performant way and the other thing that

00:30:33,130 --> 00:30:39,170
may help a lot is that now you can have

00:30:35,870 --> 00:30:43,340
easy debug messages that you can promote

00:30:39,170 --> 00:30:46,250
a source to the string but please don't

00:30:43,340 --> 00:30:48,350
try to look what it does because you're

00:30:46,250 --> 00:30:50,200
going to do it in runtime it's not going

00:30:48,350 --> 00:30:53,000
to be fast it's not replacing for macros

00:30:50,200 --> 00:30:56,740
if you want to see what they search look

00:30:53,000 --> 00:30:59,840
like use calamita you suppose a quote

00:30:56,740 --> 00:31:02,630
okay so what I'm trying to pinpoint I

00:30:59,840 --> 00:31:04,370
can hear is that this has a bit

00:31:02,630 --> 00:31:06,110
similarity whatever markers previously

00:31:04,370 --> 00:31:08,390
doing but I'm trying to build this for

00:31:06,110 --> 00:31:10,040
is I'm trying to create new foundations

00:31:08,390 --> 00:31:12,200
where people can build stuff like

00:31:10,040 --> 00:31:14,420
scallops for their own libraries that

00:31:12,200 --> 00:31:16,820
blinker will optimize language specific

00:31:14,420 --> 00:31:18,320
things which aren't library specific you

00:31:16,820 --> 00:31:19,490
can define your own rules which define

00:31:18,320 --> 00:31:22,010
library specific of the major

00:31:19,490 --> 00:31:24,710
installations and all to get all the

00:31:22,010 --> 00:31:26,450
performance that you need previously it

00:31:24,710 --> 00:31:28,460
was done by mattress now there is one

00:31:26,450 --> 00:31:31,310
more way to do it and the question is

00:31:28,460 --> 00:31:32,840
which way would you decide to use here

00:31:31,310 --> 00:31:36,470
are some pinpoints that may help you to

00:31:32,840 --> 00:31:37,970
do this to decide so rewrite rules can

00:31:36,470 --> 00:31:38,840
be defined and everywhere in your

00:31:37,970 --> 00:31:40,730
program I'm

00:31:38,840 --> 00:31:42,620
to analyze all your program analyze all

00:31:40,730 --> 00:31:44,360
your libraries if somebody defines an

00:31:42,620 --> 00:31:47,000
optimization rule I'm going to see if it

00:31:44,360 --> 00:31:48,890
applies for macros in order for macro to

00:31:47,000 --> 00:31:51,260
be applied you need to be explicitly

00:31:48,890 --> 00:31:53,390
calling this specific macro it means

00:31:51,260 --> 00:31:56,360
that well for example Java standard

00:31:53,390 --> 00:31:58,460
library doesn't have macros optimizing

00:31:56,360 --> 00:32:02,540
Java library optimizing begins with

00:31:58,460 --> 00:32:04,370
vectors is possible but you're going to

00:32:02,540 --> 00:32:05,600
have complications on the way it's very

00:32:04,370 --> 00:32:08,390
likely that you'll need to pay a price

00:32:05,600 --> 00:32:09,830
of some unpleasant to use syntax for

00:32:08,390 --> 00:32:14,180
your users and you don't want this to

00:32:09,830 --> 00:32:16,610
happen look as i said the application

00:32:14,180 --> 00:32:18,320
here is that the rewrite rules get

00:32:16,610 --> 00:32:20,300
applied globally i'm going to build a

00:32:18,320 --> 00:32:21,590
call graph and see where do you use a

00:32:20,300 --> 00:32:24,140
similar pattern from the point of view

00:32:21,590 --> 00:32:26,660
of call graph eat the specific types in

00:32:24,140 --> 00:32:28,340
this place are not saying that there's

00:32:26,660 --> 00:32:30,650
actually a pair sequence region displays

00:32:28,340 --> 00:32:32,540
but I see that the only thing that uses

00:32:30,650 --> 00:32:35,300
this latest Barre sequence that I'm

00:32:32,540 --> 00:32:37,040
going to apply this rule in order to

00:32:35,300 --> 00:32:40,100
form a close to align into syntactically

00:32:37,040 --> 00:32:41,900
call the Macra what it means is that for

00:32:40,100 --> 00:32:43,910
example if you want flat map to optimize

00:32:41,900 --> 00:32:45,770
consequent operations so if you say flat

00:32:43,910 --> 00:32:47,690
map that map la playa the filter flatten

00:32:45,770 --> 00:32:49,730
a blah blah you flatten up to be aware

00:32:47,690 --> 00:32:51,140
of all these possible cases and the

00:32:49,730 --> 00:32:56,200
macro which will be implementing the

00:32:51,140 --> 00:32:58,340
flat map is going to be huge macros are

00:32:56,200 --> 00:33:00,500
powerful they can influence type

00:32:58,340 --> 00:33:02,900
checking macros can introduce new types

00:33:00,500 --> 00:33:05,090
macros can introduce new classes my

00:33:02,900 --> 00:33:08,360
curves can affect implicit search this

00:33:05,090 --> 00:33:10,760
thing cannot it's limited and that's why

00:33:08,360 --> 00:33:12,410
it's powerful its power is in the places

00:33:10,760 --> 00:33:15,980
where it's applicable not in terms of

00:33:12,410 --> 00:33:17,630
what it can express and as I said it

00:33:15,980 --> 00:33:19,580
works with Java it works with anything

00:33:17,630 --> 00:33:22,190
that comes from everywhere it works with

00:33:19,580 --> 00:33:24,560
even across libraries so you can do

00:33:22,190 --> 00:33:26,090
cross library optimizations let's say

00:33:24,560 --> 00:33:27,620
that you have some optimizations which

00:33:26,090 --> 00:33:29,270
applies specifically to collections of

00:33:27,620 --> 00:33:31,430
matrixes if you dump some specific

00:33:29,270 --> 00:33:33,260
operations on them and you can perform

00:33:31,430 --> 00:33:36,440
them in different way well you can do it

00:33:33,260 --> 00:33:38,660
here and you don't need to ask standard

00:33:36,440 --> 00:33:40,040
library flat map to be aware of your

00:33:38,660 --> 00:33:41,930
optimizations which you apply to your

00:33:40,040 --> 00:33:45,710
specific use case if the collection

00:33:41,930 --> 00:33:47,890
contains is specifically your type yes

00:33:45,710 --> 00:33:47,890
please

00:33:50,130 --> 00:33:57,400
the question was well if it works with

00:33:53,799 --> 00:34:00,070
gel what's about jigsaw jigsaw is a way

00:33:57,400 --> 00:34:01,510
for you to motorize the library the

00:34:00,070 --> 00:34:03,520
library is still there is just broken

00:34:01,510 --> 00:34:10,270
apart and then runtime is also still

00:34:03,520 --> 00:34:13,000
there you say that you can might have

00:34:10,270 --> 00:34:14,679
multiple versions at the same time what

00:34:13,000 --> 00:34:16,179
I'm trying to say here this you should

00:34:14,679 --> 00:34:18,639
apply only optimizations which are

00:34:16,179 --> 00:34:20,290
correct by the point of view of design

00:34:18,639 --> 00:34:23,409
of the library it shouldn't change the

00:34:20,290 --> 00:34:25,450
behavior if the library has not

00:34:23,409 --> 00:34:27,700
well-defined API and they change the

00:34:25,450 --> 00:34:28,810
what it did in the first place maybe

00:34:27,700 --> 00:34:32,580
it's not the time to optimize this

00:34:28,810 --> 00:34:36,399
library yet libel should stabilize first

00:34:32,580 --> 00:34:39,010
thank you for the question okay and the

00:34:36,399 --> 00:34:41,379
question is what is best for so here you

00:34:39,010 --> 00:34:44,050
can only define simple declarative Rose

00:34:41,379 --> 00:34:47,109
if you do something complicated you're

00:34:44,050 --> 00:34:48,580
doing it wrong you the great idea here

00:34:47,109 --> 00:34:50,379
is you want to define a lot of small

00:34:48,580 --> 00:34:52,929
rules which going to be applied for

00:34:50,379 --> 00:34:54,669
cursive lee and make everything fly you

00:34:52,929 --> 00:34:57,330
don't want to apply create a rule which

00:34:54,669 --> 00:35:01,030
says that if I have n subsequent drops

00:34:57,330 --> 00:35:02,350
then I optimized him since define a

00:35:01,030 --> 00:35:04,330
single rule which works for two

00:35:02,350 --> 00:35:05,800
subsequent jobs and optimize it to one

00:35:04,330 --> 00:35:07,330
drop and then it will be applied to

00:35:05,800 --> 00:35:10,660
recursively if you can take have ten

00:35:07,330 --> 00:35:13,720
drops it will be applied nine times if

00:35:10,660 --> 00:35:15,250
you and then if you want full blown

00:35:13,720 --> 00:35:20,050
metaprogramming if you want generate

00:35:15,250 --> 00:35:25,920
code if you want to create new syntax

00:35:20,050 --> 00:35:28,630
for the language than this macros so

00:35:25,920 --> 00:35:31,270
going back to the question do you have

00:35:28,630 --> 00:35:33,400
to choose between macros and rewrite

00:35:31,270 --> 00:35:35,680
rules I'll actually it was a bit ly into

00:35:33,400 --> 00:35:40,840
you you don't you can use meta inside

00:35:35,680 --> 00:35:43,540
relatives so the thing is that it

00:35:40,840 --> 00:35:45,070
matters only what from is the from is

00:35:43,540 --> 00:35:46,930
the part which decides whether rule will

00:35:45,070 --> 00:35:49,930
trigger and the promise apart which

00:35:46,930 --> 00:35:51,790
decides well all the expressivity on one

00:35:49,930 --> 00:35:53,680
does it apply but the question what

00:35:51,790 --> 00:35:55,660
happens with it later can be more

00:35:53,680 --> 00:35:57,850
complicated you can do some analysis so

00:35:55,660 --> 00:35:59,350
then you can actually call into meta and

00:35:57,850 --> 00:36:00,910
you just going to talk about it more

00:35:59,350 --> 00:36:04,280
tomorrow

00:36:00,910 --> 00:36:05,690
so one thing which going back to this

00:36:04,280 --> 00:36:08,119
question of whether the optimization is

00:36:05,690 --> 00:36:09,770
right the way the rules written when

00:36:08,119 --> 00:36:12,290
they have the left side which is from

00:36:09,770 --> 00:36:15,230
and the right side which is too it can

00:36:12,290 --> 00:36:17,840
be perfectly checked with randomized

00:36:15,230 --> 00:36:20,270
testing so you can take color check and

00:36:17,840 --> 00:36:22,910
feed it with random inputs random

00:36:20,270 --> 00:36:25,850
functions random lists random vectors

00:36:22,910 --> 00:36:27,350
random whatever and make sure that the

00:36:25,850 --> 00:36:30,290
left-hand side and the right hand side

00:36:27,350 --> 00:36:32,240
are the same as I said we're trying to

00:36:30,290 --> 00:36:34,780
make a limited thing which is limited in

00:36:32,240 --> 00:36:38,300
terms of power but then you should be

00:36:34,780 --> 00:36:40,310
confident in using it so the idea is

00:36:38,300 --> 00:36:43,610
that as soon as you define your rule

00:36:40,310 --> 00:36:45,050
this rule is becoming a test a test that

00:36:43,610 --> 00:36:47,150
can be discovered by Skylar check and

00:36:45,050 --> 00:36:48,740
test it whether it's correct it

00:36:47,150 --> 00:36:49,610
shouldn't divide strong rules because

00:36:48,740 --> 00:36:51,800
then you're going to break your

00:36:49,610 --> 00:36:54,530
application because it will globally

00:36:51,800 --> 00:36:59,060
apply wrong rewritings you don't want

00:36:54,530 --> 00:37:01,420
this to happen okay so current status of

00:36:59,060 --> 00:37:03,560
all the thing that's a prototype

00:37:01,420 --> 00:37:05,300
specialization is more unstable than the

00:37:03,560 --> 00:37:06,619
rewrite rules I would say that it's a

00:37:05,300 --> 00:37:08,150
good moment for people to play with the

00:37:06,619 --> 00:37:10,340
rewrite rules because I want to make

00:37:08,150 --> 00:37:12,380
sure that rewrite rules capture the

00:37:10,340 --> 00:37:15,859
started light library orders need so

00:37:12,380 --> 00:37:17,330
please have a look and say to me if you

00:37:15,859 --> 00:37:19,280
think there is some use case that I

00:37:17,330 --> 00:37:22,520
didn't cover if this use case is very

00:37:19,280 --> 00:37:25,310
complicated i will say use macros if

00:37:22,520 --> 00:37:29,560
this use case makes sense and is common

00:37:25,310 --> 00:37:32,660
i'd like to include it so implementing

00:37:29,560 --> 00:37:35,240
for several weeks already had it has a

00:37:32,660 --> 00:37:38,330
problem i'm generating quite complicated

00:37:35,240 --> 00:37:42,290
bytecode specialized a lot of default

00:37:38,330 --> 00:37:45,440
methods hotspot randomly sack faults on

00:37:42,290 --> 00:37:49,310
some operations and what I mean way sac

00:37:45,440 --> 00:37:52,160
fault I mean it dies inside of c2

00:37:49,310 --> 00:37:53,540
compiler I don't know whose bucket this

00:37:52,160 --> 00:37:56,030
maybe i'm generating under specified

00:37:53,540 --> 00:37:58,040
bytecode maybe that's the back of

00:37:56,030 --> 00:37:59,840
hotspot itself those are the carters

00:37:58,040 --> 00:38:02,800
bucks to track I've been trying to track

00:37:59,840 --> 00:38:05,720
it for two weeks already no progress

00:38:02,800 --> 00:38:07,850
yeah Lucas has been also recently

00:38:05,720 --> 00:38:10,670
finding some funny bucks with default

00:38:07,850 --> 00:38:13,130
methods in hot spot maybe we're looking

00:38:10,670 --> 00:38:13,860
at the same back here to complicate it

00:38:13,130 --> 00:38:17,310
to say yet

00:38:13,860 --> 00:38:20,310
yeah so gladly I believe that thing

00:38:17,310 --> 00:38:22,560
actually kick will be practical why

00:38:20,310 --> 00:38:24,090
because it's small it's easy to

00:38:22,560 --> 00:38:26,100
understand what it does as soon as you

00:38:24,090 --> 00:38:27,480
understand the basics so if you're

00:38:26,100 --> 00:38:28,880
compared to the amount of code in

00:38:27,480 --> 00:38:30,630
specialization on mini boxing

00:38:28,880 --> 00:38:34,380
specialization which was trying to be

00:38:30,630 --> 00:38:37,290
simple and have all the basic

00:38:34,380 --> 00:38:38,820
transformation which was generating more

00:38:37,290 --> 00:38:41,010
fields not handling the handling

00:38:38,820 --> 00:38:42,960
inheritance had two thousand lines of

00:38:41,010 --> 00:38:44,400
code mini boxing which tried to be

00:38:42,960 --> 00:38:47,010
complete had more than five thousand

00:38:44,400 --> 00:38:50,670
lines of code so in my case I have

00:38:47,010 --> 00:38:52,800
analysis which is biggish the good part

00:38:50,670 --> 00:38:54,060
is analysis independent and now this

00:38:52,800 --> 00:38:56,040
will be used by a lot of stuff is going

00:38:54,060 --> 00:38:57,810
to be used by rewriting the rules you

00:38:56,040 --> 00:38:59,880
make pretty much have a chance to access

00:38:57,810 --> 00:39:01,380
and ask analysis from matter it's going

00:38:59,880 --> 00:39:03,690
to be used by specialization so analysis

00:39:01,380 --> 00:39:05,730
is normally tested a lot analysis

00:39:03,690 --> 00:39:07,950
actually can be also very available for

00:39:05,730 --> 00:39:09,060
IDEs because it's going to answer the

00:39:07,950 --> 00:39:13,350
question where this function is used

00:39:09,060 --> 00:39:15,540
better than all the Ides do so I believe

00:39:13,350 --> 00:39:16,860
that the analysis is going to be well

00:39:15,540 --> 00:39:18,320
tested in pretty stable and

00:39:16,860 --> 00:39:20,580
specialization is small here

00:39:18,320 --> 00:39:23,100
specialization this 900 lines of code

00:39:20,580 --> 00:39:24,420
I'll do this 900 lines of codes eight

00:39:23,100 --> 00:39:26,550
hundred lines of code r-type

00:39:24,420 --> 00:39:29,130
transformation and Datuk has a very

00:39:26,550 --> 00:39:32,940
strong self taking system which checks

00:39:29,130 --> 00:39:35,040
that types are correct and it means that

00:39:32,940 --> 00:39:37,710
if there is a bug is going to explode

00:39:35,040 --> 00:39:40,410
intestine very fast is I'm going to have

00:39:37,710 --> 00:39:42,540
butts in runtime and it's I believe that

00:39:40,410 --> 00:39:45,060
it will help me to fix bugs really fast

00:39:42,540 --> 00:39:48,210
here rewrite rules are very small and

00:39:45,060 --> 00:39:51,510
they actually implements they're really

00:39:48,210 --> 00:39:53,100
fast to apply and they're very has to

00:39:51,510 --> 00:39:54,780
evolve and I would as i said i would

00:39:53,100 --> 00:39:56,820
like to ask all the library orders to

00:39:54,780 --> 00:39:59,220
try them out and make sure that if you

00:39:56,820 --> 00:40:04,550
have some use case which is simple i

00:39:59,220 --> 00:40:08,340
covered so as I said if your library or

00:40:04,550 --> 00:40:10,530
instead the library does tricks you may

00:40:08,340 --> 00:40:12,540
be the only fit much from this if you're

00:40:10,530 --> 00:40:14,690
doing some unsound costs if you're

00:40:12,540 --> 00:40:17,160
trying to take advantage of of erasure

00:40:14,690 --> 00:40:19,350
I'm trying to eliminate a razor here

00:40:17,160 --> 00:40:20,960
kind of and trying to make it look like

00:40:19,350 --> 00:40:24,030
we don't have a razor in the first place

00:40:20,960 --> 00:40:25,800
if you need erasure well I'll do I will

00:40:24,030 --> 00:40:26,740
live erasure to you and you'll have a

00:40:25,800 --> 00:40:31,060
ratio

00:40:26,740 --> 00:40:33,220
so because of this it may be a good

00:40:31,060 --> 00:40:34,780
moment to rethink how libraries are

00:40:33,220 --> 00:40:36,250
built a list for Lahti to make sure

00:40:34,780 --> 00:40:38,440
they're they're even more type safe

00:40:36,250 --> 00:40:43,630
because precise types will bring

00:40:38,440 --> 00:40:45,250
performance as I said yeah and it vector

00:40:43,630 --> 00:40:47,140
is a really bad case here because it

00:40:45,250 --> 00:40:49,840
tries to get most out of the performance

00:40:47,140 --> 00:40:52,920
it has a really huge implementation

00:40:49,840 --> 00:40:55,540
which duplicates a lot of code by itself

00:40:52,920 --> 00:40:58,450
most other collections don't do this

00:40:55,540 --> 00:41:00,100
dirty magic and they work just fine and

00:40:58,450 --> 00:41:02,530
it's open source now so you can try out

00:41:00,100 --> 00:41:03,850
linker it's on github is for Condotti so

00:41:02,530 --> 00:41:05,980
you can either follow this link or just

00:41:03,850 --> 00:41:08,550
have a look so first of Dottie and see

00:41:05,980 --> 00:41:12,760
the one which is most frequently updated

00:41:08,550 --> 00:41:15,100
yeah so I want to thank people who I'm

00:41:12,760 --> 00:41:16,119
building on on top of your land records

00:41:15,100 --> 00:41:19,650
watched the first to implement

00:41:16,119 --> 00:41:23,110
specialization a lot of problems were

00:41:19,650 --> 00:41:25,750
discovered by him his implementation

00:41:23,110 --> 00:41:28,510
which tried to be simple opened a lot of

00:41:25,750 --> 00:41:33,250
kind of forms that have been we have

00:41:28,510 --> 00:41:35,290
been trying to close for a decade so

00:41:33,250 --> 00:41:37,420
blotto hecka has been it has done a lot

00:41:35,290 --> 00:41:40,240
here he has been maintaining one of the

00:41:37,420 --> 00:41:42,910
most complicated plugins for skala see

00:41:40,240 --> 00:41:45,880
how he isn't a huge amount of work to

00:41:42,910 --> 00:41:47,619
make it run spinny boxin now is a really

00:41:45,880 --> 00:41:50,859
stable plugin if you own something today

00:41:47,619 --> 00:41:53,980
consider using it Eugene Bohr model came

00:41:50,859 --> 00:41:56,530
was IDF tasty he have been trying to

00:41:53,980 --> 00:41:58,170
make martin acceptance idea for years

00:41:56,530 --> 00:42:00,660
convincing him that it makes sense

00:41:58,170 --> 00:42:04,840
making projects with student trying to

00:42:00,660 --> 00:42:06,930
prove that saving the tasty with class

00:42:04,840 --> 00:42:09,609
files isn't going to be either slow or

00:42:06,930 --> 00:42:11,950
your nightmare is going to take a lot of

00:42:09,609 --> 00:42:15,340
space and we and he succeeded in do this

00:42:11,950 --> 00:42:17,920
i also want to thank andre law tak from

00:42:15,340 --> 00:42:19,119
university of waterloo he helped me to

00:42:17,920 --> 00:42:21,070
build the call graph construction

00:42:19,119 --> 00:42:23,950
algorithm which all this stuff is based

00:42:21,070 --> 00:42:25,960
on originally as assumption was that

00:42:23,950 --> 00:42:27,100
there is no luck in optimizing standard

00:42:25,960 --> 00:42:29,200
collections and i've been trying to

00:42:27,100 --> 00:42:30,880
convert convince martin into building

00:42:29,200 --> 00:42:32,920
decorator based collection design which

00:42:30,880 --> 00:42:34,960
will be simpler to optimize now there is

00:42:32,920 --> 00:42:36,609
no much need to our analysis is smart

00:42:34,960 --> 00:42:38,350
enough to understand all the intricate

00:42:36,609 --> 00:42:40,570
substandard collections it's able to

00:42:38,350 --> 00:42:43,480
understand all the details of all

00:42:40,570 --> 00:42:46,990
42 superclasses of list is able to see

00:42:43,480 --> 00:42:49,060
all the 200 different kinds of named

00:42:46,990 --> 00:42:51,760
subtypes of interrater standard library

00:42:49,060 --> 00:42:53,740
and even more unnamed ones it's able to

00:42:51,760 --> 00:42:55,780
optimize all of them for particular use

00:42:53,740 --> 00:42:58,000
case if you don't use this specific

00:42:55,780 --> 00:43:01,150
specific class it won't be there in the

00:42:58,000 --> 00:43:04,560
first place so thank you for following

00:43:01,150 --> 00:43:04,560

YouTube URL: https://www.youtube.com/watch?v=h8KBLF0AgUc


