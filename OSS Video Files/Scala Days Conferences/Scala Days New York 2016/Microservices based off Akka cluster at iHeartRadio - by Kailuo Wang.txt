Title: Microservices based off Akka cluster at iHeartRadio - by Kailuo Wang
Publication date: 2016-06-17
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.

Abstract:
A talk with two main agenda items:
how we came to the decision of basing our microservices off Akka cluster, and
how we implemented this microservice platform - architecture, tips, lessons learned, and a couple of open source libraries we released to facilitate microservice development with Akka cluster, including a piece of reactive feature we contributed to the Akka core.
Captions: 
	00:00:07,450 --> 00:00:11,720
hello everyone

00:00:09,050 --> 00:00:15,710
thanks for coming it looks like you guys

00:00:11,720 --> 00:00:18,650
are really into microservices so okay

00:00:15,710 --> 00:00:22,640
you got everybody hurt here me great so

00:00:18,650 --> 00:00:25,100
this pug is about power n which is micro

00:00:22,640 --> 00:00:28,100
service platform that we implemented at

00:00:25,100 --> 00:00:30,140
iHeartRadio and it's going to be an

00:00:28,100 --> 00:00:31,760
overview of it and what's the

00:00:30,140 --> 00:00:33,800
architecture and some of the

00:00:31,760 --> 00:00:36,289
implementation details and also like

00:00:33,800 --> 00:00:38,510
some tools we implemented we developed

00:00:36,289 --> 00:00:44,710
to support this micro service platform

00:00:38,510 --> 00:00:47,780
so so first let's look at the offer I

00:00:44,710 --> 00:00:49,969
was asked to add this to the slides is

00:00:47,780 --> 00:00:53,449
basically you can rate the session so

00:00:49,969 --> 00:00:55,100
please remember to do that but let's

00:00:53,449 --> 00:00:58,100
start the presentation with this

00:00:55,100 --> 00:01:00,079
architectural overview of the micro

00:00:58,100 --> 00:01:03,109
services platform we call power and and

00:01:00,079 --> 00:01:08,899
iHeartRadio so the core thing is that

00:01:03,109 --> 00:01:10,579
our car coaster our apps are both part

00:01:08,899 --> 00:01:12,890
of our cluster there are concert

00:01:10,579 --> 00:01:15,710
together using under cluster technology

00:01:12,890 --> 00:01:17,930
and the on the top you see an API

00:01:15,710 --> 00:01:21,109
gateway that's a play out that's where

00:01:17,930 --> 00:01:23,420
all HTTP requests coming in and inside

00:01:21,109 --> 00:01:25,609
out that's also inside Karaka cluster

00:01:23,420 --> 00:01:28,460
all the micro services are actually

00:01:25,609 --> 00:01:31,340
implemented as archive apps as you can

00:01:28,460 --> 00:01:33,740
see here and here and here there are

00:01:31,340 --> 00:01:36,200
micro services that are also deployed

00:01:33,740 --> 00:01:39,259
into the Aqua cluster so the EPI gateway

00:01:36,200 --> 00:01:42,770
can talk to them through akka protocol

00:01:39,259 --> 00:01:44,600
and as well and the microscopes

00:01:42,770 --> 00:01:49,700
themselves can talk to each other super

00:01:44,600 --> 00:01:52,039
calm protocol so and then they can talk

00:01:49,700 --> 00:01:54,469
to the data stores external services or

00:01:52,039 --> 00:01:56,299
message queues which are you know the

00:01:54,469 --> 00:01:59,350
where the information comes from the

00:01:56,299 --> 00:02:00,950
data comes from so these are outside the

00:01:59,350 --> 00:02:06,020
Aqua coaster

00:02:00,950 --> 00:02:08,899
so and we also have a command center

00:02:06,020 --> 00:02:10,970
which you can control the ball micro

00:02:08,899 --> 00:02:12,700
services give them commands using this

00:02:10,970 --> 00:02:15,959
interface and we'll have

00:02:12,700 --> 00:02:18,790
trips marker that can give you matrix

00:02:15,959 --> 00:02:22,690
monitoring for all the micro service

00:02:18,790 --> 00:02:25,690
running so that's the basic idea what's

00:02:22,690 --> 00:02:28,540
interesting here is that we have this

00:02:25,690 --> 00:02:31,599
so-called epi gateway and backup sources

00:02:28,540 --> 00:02:37,150
discrete endpoints what actually means

00:02:31,599 --> 00:02:38,950
is that one thing that usually is

00:02:37,150 --> 00:02:41,319
interesting is that where you define

00:02:38,950 --> 00:02:44,200
these TP endpoints you can define them

00:02:41,319 --> 00:02:46,120
if the endpoints at the API gateway or

00:02:44,200 --> 00:02:48,970
you can define them at each archive

00:02:46,120 --> 00:02:52,780
service app so each micro service define

00:02:48,970 --> 00:02:55,750
their own HTTP services rest endpoints

00:02:52,780 --> 00:02:58,090
that's a common practice the other

00:02:55,750 --> 00:02:59,980
common practice is de fondos it's the

00:02:58,090 --> 00:03:03,730
endpoints of the DPR gateway the

00:02:59,980 --> 00:03:07,390
downside of defining each edge service

00:03:03,730 --> 00:03:10,060
that each archive services as long as to

00:03:07,390 --> 00:03:12,160
be an archive service is that then you

00:03:10,060 --> 00:03:16,900
have to make sure that you take out the

00:03:12,160 --> 00:03:19,380
service registry and the the discovery

00:03:16,900 --> 00:03:21,790
service discovery and also it encouraged

00:03:19,380 --> 00:03:25,600
in for micro service the communication

00:03:21,790 --> 00:03:27,150
to happen at the HTTP level so so that's

00:03:25,600 --> 00:03:32,709
one of problems the other approach is to

00:03:27,150 --> 00:03:34,299
actually define them in HTTP gateway and

00:03:32,709 --> 00:03:38,290
we take a different approach which I'm

00:03:34,299 --> 00:03:40,900
going to cover in after the next slide

00:03:38,290 --> 00:03:43,239
the first one we choose to use rocket

00:03:40,900 --> 00:03:45,639
cluster forecasting are micro services

00:03:43,239 --> 00:03:47,680
because well it's out of the box

00:03:45,639 --> 00:03:50,260
clustering infrastructure so when I use

00:03:47,680 --> 00:03:52,870
it and it also provided a loose coupling

00:03:50,260 --> 00:03:55,959
between micro circuits sort of typed

00:03:52,870 --> 00:03:57,730
binary protocol so you know it's it's a

00:03:55,959 --> 00:04:00,280
comm messages is typed and it's also

00:03:57,730 --> 00:04:00,880
binary protocol so you know it's a

00:04:00,280 --> 00:04:03,130
little bit

00:04:00,880 --> 00:04:04,930
performance gained from there and also

00:04:03,130 --> 00:04:05,500
it provides a transparent programming

00:04:04,930 --> 00:04:08,170
model

00:04:05,500 --> 00:04:11,889
whizzing all cost to micro services so

00:04:08,170 --> 00:04:15,940
you can write your programming in our

00:04:11,889 --> 00:04:17,980
actors and either it's within a micro

00:04:15,940 --> 00:04:20,470
service oh it's across the microphone

00:04:17,980 --> 00:04:22,330
it's the same programming model so if

00:04:20,470 --> 00:04:25,150
you want to refractor it's a lot easier

00:04:22,330 --> 00:04:27,160
when the last two is you know you get

00:04:25,150 --> 00:04:29,170
high resiliency performance and

00:04:27,160 --> 00:04:30,820
scalability Beauty English naka caster

00:04:29,170 --> 00:04:33,460
and you also get a strong community and

00:04:30,820 --> 00:04:36,790
commercial support from the outcome

00:04:33,460 --> 00:04:40,050
community so that's why we use a coaster

00:04:36,790 --> 00:04:44,050
so now let's look at our approach for

00:04:40,050 --> 00:04:45,760
defining HTTP browser endpoints so we

00:04:44,050 --> 00:04:49,690
call this the spirit and point meaning

00:04:45,760 --> 00:04:52,090
that you actually define your define us

00:04:49,690 --> 00:04:54,610
to be endpoints in the micro service to

00:04:52,090 --> 00:04:58,000
talk about it so however the accent

00:04:54,610 --> 00:05:00,340
endpoints are served by the API gateway

00:04:58,000 --> 00:05:05,290
which is the player and the weight and

00:05:00,340 --> 00:05:08,920
we developed this tool called asobu is

00:05:05,290 --> 00:05:11,770
Rotem sauce that allow you to remotely

00:05:08,920 --> 00:05:14,110
define at the endpoints in your micro

00:05:11,770 --> 00:05:15,880
service in your Hakka out and just send

00:05:14,110 --> 00:05:18,490
that different definition to the API

00:05:15,880 --> 00:05:21,940
gateway and then give API gateway it

00:05:18,490 --> 00:05:24,850
play up were basically quit outs HTP

00:05:21,940 --> 00:05:26,650
routes for those endpoints and then once

00:05:24,850 --> 00:05:29,350
they get the request for those endpoints

00:05:26,650 --> 00:05:33,640
you get it actually forward the request

00:05:29,350 --> 00:05:36,070
work through support work pipeline to

00:05:33,640 --> 00:05:37,690
the actual al-khattab and then I can do

00:05:36,070 --> 00:05:40,090
all the job through the world data

00:05:37,690 --> 00:05:43,540
processing and then send them back to

00:05:40,090 --> 00:05:46,120
the API gateway so and then API gateway

00:05:43,540 --> 00:05:51,640
finally some damage response back to the

00:05:46,120 --> 00:05:54,600
client so this way why we do this it

00:05:51,640 --> 00:05:58,750
allows you to implement cross-cutting

00:05:54,600 --> 00:06:01,030
API logic HTTP related in API gateway

00:05:58,750 --> 00:06:03,220
for example authentication our handling

00:06:01,030 --> 00:06:07,540
validation you can all implement them in

00:06:03,220 --> 00:06:09,760
the API gateway and that allows you to

00:06:07,540 --> 00:06:12,130
deploy a cross-cutting logic without

00:06:09,760 --> 00:06:14,590
redeploying micro services it's one

00:06:12,130 --> 00:06:17,470
common thing for example I have

00:06:14,590 --> 00:06:19,480
authentication and a lot of my micro

00:06:17,470 --> 00:06:21,670
service needs now I change the logic

00:06:19,480 --> 00:06:23,830
what does that mean to you if you

00:06:21,670 --> 00:06:26,320
implement this logic through a library

00:06:23,830 --> 00:06:28,600
and sort of binary dependency by those

00:06:26,320 --> 00:06:30,790
macro services now you have to read more

00:06:28,600 --> 00:06:31,680
micro services and this way allows you

00:06:30,790 --> 00:06:33,270
to get away from

00:06:31,680 --> 00:06:35,130
so you can evolve your cross-cutting

00:06:33,270 --> 00:06:37,560
logic all those validation error

00:06:35,130 --> 00:06:40,080
handling and authentication being

00:06:37,560 --> 00:06:42,720
separately independent from the micro

00:06:40,080 --> 00:06:46,020
services and this also allowed me and

00:06:42,720 --> 00:06:47,699
you can remain a footman to Microsoft's

00:06:46,020 --> 00:06:52,580
themself and remain independent right

00:06:47,699 --> 00:06:55,229
meaning they don't depend at all on the

00:06:52,580 --> 00:06:57,150
API if you have a new micro substance

00:06:55,229 --> 00:06:59,340
you simply write your knowledge to the

00:06:57,150 --> 00:07:01,590
endpoints in the micro service and you

00:06:59,340 --> 00:07:04,830
deploy it to cluster and this micro

00:07:01,590 --> 00:07:07,350
service will be added to the API gateway

00:07:04,830 --> 00:07:09,419
registry and we have all the endpoints

00:07:07,350 --> 00:07:13,229
defined by this new macro service

00:07:09,419 --> 00:07:15,180
experience to the public API so and if

00:07:13,229 --> 00:07:17,699
you take this micro service off the

00:07:15,180 --> 00:07:21,900
cluster those endpoints will be removed

00:07:17,699 --> 00:07:23,880
from the EPI gateway so that way your

00:07:21,900 --> 00:07:29,039
Microsoft independently deployable and

00:07:23,880 --> 00:07:31,889
independently developer develop it so so

00:07:29,039 --> 00:07:35,400
that's why this trillion points and this

00:07:31,889 --> 00:07:39,360
is how this is the code example on how

00:07:35,400 --> 00:07:41,430
you develop this and if you look at this

00:07:39,360 --> 00:07:44,840
this is actually diversified then

00:07:41,430 --> 00:07:47,669
actually is in the aqua micro service

00:07:44,840 --> 00:07:49,560
signed so you write this routes Phi

00:07:47,669 --> 00:07:51,780
which looks like a play routes for a lot

00:07:49,560 --> 00:07:54,360
especially if you look at this line and

00:07:51,780 --> 00:07:57,930
this line why is the guest the other is

00:07:54,360 --> 00:07:59,669
especially actually exactly using same

00:07:57,930 --> 00:08:02,310
syntax as they play route

00:07:59,669 --> 00:08:07,470
alright and they define those two

00:08:02,310 --> 00:08:12,210
endpoints and and you also write a

00:08:07,470 --> 00:08:14,520
controller in the actually this is the

00:08:12,210 --> 00:08:19,349
this is you quote by calling controller

00:08:14,520 --> 00:08:21,780
just so that it resembled what we

00:08:19,349 --> 00:08:23,550
usually do as a player which is you

00:08:21,780 --> 00:08:25,470
write a controller that handles the

00:08:23,550 --> 00:08:27,060
message but actually what thing what

00:08:25,470 --> 00:08:29,639
this controller does is to define the

00:08:27,060 --> 00:08:31,050
HTM point definition they don't actually

00:08:29,639 --> 00:08:34,560
handle anything they just create a

00:08:31,050 --> 00:08:37,349
definition of endpoints and send it over

00:08:34,560 --> 00:08:39,870
to the API gateway so in this first

00:08:37,349 --> 00:08:41,669
example you can see what it does is that

00:08:39,870 --> 00:08:44,219
they kind of get groups and I'm going to

00:08:41,669 --> 00:08:45,490
process the gallic cross get groups

00:08:44,219 --> 00:08:48,279
message

00:08:45,490 --> 00:08:50,860
gonna use a certain back-end and expect

00:08:48,279 --> 00:08:52,300
a groups result from the back end and

00:08:50,860 --> 00:08:56,980
response ISM so that's the whole

00:08:52,300 --> 00:09:00,940
definition and behind the saying this

00:08:56,980 --> 00:09:04,240
DSL we we call it a so the DSL is

00:09:00,940 --> 00:09:08,620
abusing us a place cats and kittens to

00:09:04,240 --> 00:09:10,209
have this type safe way to define where

00:09:08,620 --> 00:09:10,450
you want to get all the information come

00:09:10,209 --> 00:09:12,459
from

00:09:10,450 --> 00:09:14,440
so let's look at the next let's look at

00:09:12,459 --> 00:09:16,839
the next example which is create a test

00:09:14,440 --> 00:09:19,029
this service is about creating VB tap

00:09:16,839 --> 00:09:21,310
it's about DB test subject so you can

00:09:19,029 --> 00:09:24,339
create tests you can say ok giving user

00:09:21,310 --> 00:09:27,180
which any test groups this user is in

00:09:24,339 --> 00:09:29,740
and for the second for the create test

00:09:27,180 --> 00:09:34,510
endpoints we can look at this example so

00:09:29,740 --> 00:09:36,760
create test it says process create test

00:09:34,510 --> 00:09:39,430
and that is actually a case class as you

00:09:36,760 --> 00:09:41,470
can see here and it takes two annotated

00:09:39,430 --> 00:09:44,740
I mean take two fields why is the author

00:09:41,470 --> 00:09:46,899
the other is the evening test and as you

00:09:44,740 --> 00:09:48,520
can see the DSR is gonna say for the

00:09:46,899 --> 00:09:50,740
awesome I want to get it from the

00:09:48,520 --> 00:09:53,589
authenticated user name that has to be

00:09:50,740 --> 00:09:55,180
allocated get this this request has to

00:09:53,589 --> 00:09:57,250
be authenticated and I gotta use the

00:09:55,180 --> 00:09:59,290
authenticate username as the all store

00:09:57,250 --> 00:10:03,550
of this maybe test and the second field

00:09:59,290 --> 00:10:06,160
is the test and this is another nested

00:10:03,550 --> 00:10:08,829
case class so that we have another case

00:10:06,160 --> 00:10:11,700
cause of TB test that represents what to

00:10:08,829 --> 00:10:14,320
create the data to create a DB test and

00:10:11,700 --> 00:10:16,690
that part of information is from the

00:10:14,320 --> 00:10:18,940
body it from a disembodied so here you

00:10:16,690 --> 00:10:20,800
specify for also field I'm gonna from

00:10:18,940 --> 00:10:23,050
Muslim Caden username and for the test

00:10:20,800 --> 00:10:26,170
field I'm going to get it from the Jason

00:10:23,050 --> 00:10:29,649
body and from that to the system I mean

00:10:26,170 --> 00:10:32,079
the yes the the the the rest endpoints

00:10:29,649 --> 00:10:34,390
is sketch we construct the create test

00:10:32,079 --> 00:10:36,130
message and send it to the background

00:10:34,390 --> 00:10:38,410
the background here as you can see just

00:10:36,130 --> 00:10:41,649
the factory rough pass thing and then

00:10:38,410 --> 00:10:44,350
the back end is gonna do all the job and

00:10:41,649 --> 00:10:46,450
gonna the DSS that I'm gonna expect a

00:10:44,350 --> 00:10:48,700
test created message back from the back

00:10:46,450 --> 00:10:51,220
end and it simply responds its own ok

00:10:48,700 --> 00:10:54,640
and what it does is that you are a it

00:10:51,220 --> 00:10:56,890
automatically use a formatter of tests

00:10:54,640 --> 00:10:58,330
created and created Jason thought of

00:10:56,890 --> 00:11:02,440
that case class

00:10:58,330 --> 00:11:04,360
so but he doesn't if the back end didn't

00:11:02,440 --> 00:11:07,870
wood doesn't return the test grade it

00:11:04,360 --> 00:11:13,600
will return an error message like like

00:11:07,870 --> 00:11:16,690
five hundred our cross-cutting arrow

00:11:13,600 --> 00:11:19,990
handling method cross-cutting error

00:11:16,690 --> 00:11:21,610
message handling mechanism defined so

00:11:19,990 --> 00:11:24,760
that's what I'm saying so you only write

00:11:21,610 --> 00:11:26,650
the happy parts the bad part of the set

00:11:24,760 --> 00:11:28,390
policies usually taken care of by the

00:11:26,650 --> 00:11:30,340
cross-cutting object of what the parent

00:11:28,390 --> 00:11:33,880
panelling learn about addition and so on

00:11:30,340 --> 00:11:40,290
so so that's the that's the DSL that you

00:11:33,880 --> 00:11:43,300
can create those distribute endpoints so

00:11:40,290 --> 00:11:46,240
the other thing the other part of the

00:11:43,300 --> 00:11:50,620
the architecture is called reacting one

00:11:46,240 --> 00:11:52,750
part lines which is called it's powered

00:11:50,620 --> 00:11:53,560
by this open source project called

00:11:52,750 --> 00:11:56,730
kanaloa

00:11:53,560 --> 00:11:59,080
that we developed and it's to solve

00:11:56,730 --> 00:12:02,170
interesting problem which is if you

00:11:59,080 --> 00:12:04,000
write actually if you write you a car up

00:12:02,170 --> 00:12:05,740
right if you write everything right you

00:12:04,000 --> 00:12:09,580
do everything of synchronously which

00:12:05,740 --> 00:12:11,260
means that they don't block so whatever

00:12:09,580 --> 00:12:12,910
requests coming in we're just going to

00:12:11,260 --> 00:12:15,460
send that directly to database and

00:12:12,910 --> 00:12:17,230
without you know thinking twice just

00:12:15,460 --> 00:12:19,510
wait for the database to return the

00:12:17,230 --> 00:12:25,750
result and what that means is that if

00:12:19,510 --> 00:12:27,700
you have some expected increase of

00:12:25,750 --> 00:12:32,050
incoming traffic you're gonna kick the

00:12:27,700 --> 00:12:33,640
database and and then like a DDoS or

00:12:32,050 --> 00:12:35,740
whatever so and you burn down your

00:12:33,640 --> 00:12:39,130
database that's definitely not good so

00:12:35,740 --> 00:12:42,610
that's that's the main center of why

00:12:39,130 --> 00:12:44,770
they use this reactive or Python is to

00:12:42,610 --> 00:12:46,510
make sense more resilient so we have

00:12:44,770 --> 00:12:50,770
this course smart control pressure on

00:12:46,510 --> 00:12:53,650
back-end that this rock python provides

00:12:50,770 --> 00:12:55,960
so the first thing it does is a little

00:12:53,650 --> 00:12:58,040
law inspired back pressure so it's a

00:12:55,960 --> 00:13:03,290
very primitive back pressure

00:12:58,040 --> 00:13:06,440
so that if the request is not handled in

00:13:03,290 --> 00:13:08,899
time you can start to reject the request

00:13:06,440 --> 00:13:10,850
incoming requests and the other part is

00:13:08,899 --> 00:13:13,759
called optimal concurrency sighs

00:13:10,850 --> 00:13:15,769
exploring the what it means so basically

00:13:13,759 --> 00:13:18,980
what we call control pressure on a

00:13:15,769 --> 00:13:21,290
backhand is that you only make sure we

00:13:18,980 --> 00:13:24,860
make sure that at a certain time there's

00:13:21,290 --> 00:13:25,639
only a certain number of concurrent

00:13:24,860 --> 00:13:28,819
connection

00:13:25,639 --> 00:13:30,649
hit the database either it's five or six

00:13:28,819 --> 00:13:33,050
or eight in the matter that but it's

00:13:30,649 --> 00:13:35,120
it's confined so you have you have DDoS

00:13:33,050 --> 00:13:44,810
you won't increase the racket currency

00:13:35,120 --> 00:13:46,819
into the responsive so but now you have

00:13:44,810 --> 00:13:49,639
this control you have this limit of your

00:13:46,819 --> 00:13:51,980
concurrency to hit that delivers but

00:13:49,639 --> 00:13:52,990
then it becomes an arbitrary number so

00:13:51,980 --> 00:13:55,160
this

00:13:52,990 --> 00:13:56,990
so what's number two you said you don't

00:13:55,160 --> 00:14:00,259
know so this Optima concurrence of theis

00:13:56,990 --> 00:14:02,540
exploring is basically trying to figure

00:14:00,259 --> 00:14:05,029
out what's the optimum number of

00:14:02,540 --> 00:14:07,819
concurrent connection that you can allow

00:14:05,029 --> 00:14:12,230
to hit the backend data or the either a

00:14:07,819 --> 00:14:13,910
data service or external web service so

00:14:12,230 --> 00:14:17,839
what it does is that there are two

00:14:13,910 --> 00:14:20,319
phases one is explore a little bit up

00:14:17,839 --> 00:14:22,639
and down to see the neighborhood

00:14:20,319 --> 00:14:28,040
concurrency and connection numbers and

00:14:22,639 --> 00:14:31,550
then he recalled the the performance the

00:14:28,040 --> 00:14:36,190
matrix performance and then the that's

00:14:31,550 --> 00:14:41,360
the first top second the fact the second

00:14:36,190 --> 00:14:43,790
stage is to optimize so so basically he

00:14:41,360 --> 00:14:45,800
looks like neighborhood concurrency size

00:14:43,790 --> 00:14:48,079
and choose that one and has the best

00:14:45,800 --> 00:14:50,180
performance and move to there and then

00:14:48,079 --> 00:14:52,250
to explore a little bit again and then

00:14:50,180 --> 00:14:55,939
to optimize which is moving to the next

00:14:52,250 --> 00:14:58,970
optimal internet size so that way it

00:14:55,939 --> 00:15:01,370
automatically explore the best or the

00:14:58,970 --> 00:15:03,079
optimum concurrent connection and you

00:15:01,370 --> 00:15:05,540
are allowed to hit your back-end

00:15:03,079 --> 00:15:08,540
database and it's dynamic we need to

00:15:05,540 --> 00:15:11,350
keep cosmic optimizing so if you forget

00:15:08,540 --> 00:15:11,350
a bit scared or

00:15:12,220 --> 00:15:17,360
pthey or you know get more performant

00:15:15,110 --> 00:15:19,490
and then automatic increase the number

00:15:17,360 --> 00:15:25,160
of concurrent connections for that based

00:15:19,490 --> 00:15:28,640
on the performance so one if we saw this

00:15:25,160 --> 00:15:31,810
in real world working for database it

00:15:28,640 --> 00:15:35,870
stopped out of state number eight or ten

00:15:31,810 --> 00:15:38,570
connections for some really strong web

00:15:35,870 --> 00:15:39,590
services like a facebook web surface it

00:15:38,570 --> 00:15:43,720
go all the way to three hundred

00:15:39,590 --> 00:15:45,890
concurrent connections so so that's

00:15:43,720 --> 00:15:49,160
automatically figured that off for you a

00:15:45,890 --> 00:15:50,750
smart we call a smart controlled

00:15:49,160 --> 00:15:52,160
pressure on the backend and then we also

00:15:50,750 --> 00:15:55,790
have a circuit breaker which is pretty

00:15:52,160 --> 00:15:58,190
simple if you see you can if you see a

00:15:55,790 --> 00:16:00,290
lot of arrows from your back hand you

00:15:58,190 --> 00:16:03,010
probably want to give it a break so and

00:16:00,290 --> 00:16:06,470
then maybe you wait a little bit and

00:16:03,010 --> 00:16:12,590
close the circuit breaker to try it

00:16:06,470 --> 00:16:17,290
again and you're not saying the other

00:16:12,590 --> 00:16:20,840
thing that can aloha which is our record

00:16:17,290 --> 00:16:25,820
well the pipeline provides is the matrix

00:16:20,840 --> 00:16:27,410
monitor so that because now we know that

00:16:25,820 --> 00:16:31,340
your work is always going to come

00:16:27,410 --> 00:16:34,550
through this work pipeline we can have

00:16:31,340 --> 00:16:36,980
better understanding of this as the

00:16:34,550 --> 00:16:39,170
final work so that we can see this

00:16:36,980 --> 00:16:41,060
report we can see the failures we can

00:16:39,170 --> 00:16:43,430
see inbound requests queue lengths

00:16:41,060 --> 00:16:46,610
expected wait time we can also see the

00:16:43,430 --> 00:16:49,700
concurrency size like so that we know

00:16:46,610 --> 00:16:52,430
how many concurrent connections were

00:16:49,700 --> 00:16:54,680
making to the backend if it's optimum is

00:16:52,430 --> 00:16:57,860
it increasing or decreasing what's

00:16:54,680 --> 00:17:01,850
happening is we can see all those these

00:16:57,860 --> 00:17:08,540
are supported provided also by in

00:17:01,850 --> 00:17:13,040
equation two stats the coroner so the

00:17:08,540 --> 00:17:14,990
other part that we provide is actually

00:17:13,040 --> 00:17:15,620
also interesting called the distributed

00:17:14,990 --> 00:17:19,460
swagger

00:17:15,620 --> 00:17:22,819
definition of swagger swagger

00:17:19,460 --> 00:17:25,939
documentation so although

00:17:22,819 --> 00:17:28,339
your Antoinette define an account app or

00:17:25,939 --> 00:17:32,059
the micro service layer we provides a

00:17:28,339 --> 00:17:34,870
centralized swagger documentation UI at

00:17:32,059 --> 00:17:38,139
the player at API gateway how that

00:17:34,870 --> 00:17:42,399
achieved is that you write your swagger

00:17:38,139 --> 00:17:45,440
documentation or Yama file that Bingley

00:17:42,399 --> 00:17:47,059
in the routes file as comments just like

00:17:45,440 --> 00:17:50,630
this block you just say our summary

00:17:47,059 --> 00:17:52,909
perimeter and responses what's the

00:17:50,630 --> 00:17:55,639
response and Salam Salam and those are

00:17:52,909 --> 00:18:00,100
could have submitted to the API gateway

00:17:55,639 --> 00:18:04,429
which then generates the integrated

00:18:00,100 --> 00:18:06,230
swagger API you swagger documentation

00:18:04,429 --> 00:18:08,179
for you so that you have an API

00:18:06,230 --> 00:18:10,940
documentation and a centralized place

00:18:08,179 --> 00:18:14,330
where your clients can you know players

00:18:10,940 --> 00:18:17,389
you can try it with you know this viewer

00:18:14,330 --> 00:18:21,710
and noting that the plague or the place

00:18:17,389 --> 00:18:24,649
weather integration does is that it gets

00:18:21,710 --> 00:18:28,309
information from not only the comments

00:18:24,649 --> 00:18:30,799
here but also the routes definition

00:18:28,309 --> 00:18:33,289
itself and they also look at the case

00:18:30,799 --> 00:18:36,440
cloud definition so it generates a data

00:18:33,289 --> 00:18:39,559
schema for your based on reflection and

00:18:36,440 --> 00:18:42,289
look at your your actual message type

00:18:39,559 --> 00:18:44,870
and then generate the schema for that so

00:18:42,289 --> 00:18:47,450
that every basically extract as much

00:18:44,870 --> 00:18:50,450
information as possible from your code

00:18:47,450 --> 00:18:53,600
and to display them in a swagger in you

00:18:50,450 --> 00:18:55,750
I should have asked how many of you

00:18:53,600 --> 00:19:01,820
actually use the tracker before

00:18:55,750 --> 00:19:04,190
great so this is also only we achieve

00:19:01,820 --> 00:19:08,480
this through this open source library

00:19:04,190 --> 00:19:10,519
called place burger we developed and so

00:19:08,480 --> 00:19:14,720
that we can have distributed place

00:19:10,519 --> 00:19:20,059
whether any question so other things

00:19:14,720 --> 00:19:24,789
that are in our cluster the are note

00:19:20,059 --> 00:19:28,370
smarter which is infrastructure UI that

00:19:24,789 --> 00:19:31,279
that you can see all the nodes in

00:19:28,370 --> 00:19:36,230
right now and we can we adapted this

00:19:31,279 --> 00:19:37,789
from Luque 88 but I will also added a

00:19:36,230 --> 00:19:41,510
bunch of functionality like you can see

00:19:37,789 --> 00:19:43,909
the current come in get commit char in

00:19:41,510 --> 00:19:46,240
in need for each service state so you

00:19:43,909 --> 00:19:50,570
know exactly what working they are at

00:19:46,240 --> 00:19:55,940
and also we added some a sinkhole event

00:19:50,570 --> 00:19:58,070
monitor which is basically congregation

00:19:55,940 --> 00:19:59,870
of all the error and warning logs that

00:19:58,070 --> 00:20:02,149
you can find you can see them in a

00:19:59,870 --> 00:20:04,909
centralized place and you can search

00:20:02,149 --> 00:20:09,200
through them so we didn't use we didn't

00:20:04,909 --> 00:20:12,169
have to use any log congregation

00:20:09,200 --> 00:20:14,840
mechanic just a simple web page that are

00:20:12,169 --> 00:20:17,450
congregated all the logs from all the

00:20:14,840 --> 00:20:19,730
nodes in the cluster and you see them in

00:20:17,450 --> 00:20:24,200
a centralized place very useful when you

00:20:19,730 --> 00:20:27,289
are do development so the last part of

00:20:24,200 --> 00:20:30,559
the utility in command center is the job

00:20:27,289 --> 00:20:33,529
miner so we also write a lot of data

00:20:30,559 --> 00:20:38,809
processing jobs like queue processing

00:20:33,529 --> 00:20:40,669
jobs as well as in our micro sources and

00:20:38,809 --> 00:20:42,770
you need a centralized place to start

00:20:40,669 --> 00:20:49,309
stop them and monitor them and this is

00:20:42,770 --> 00:20:53,510
the tool that we created for that so to

00:20:49,309 --> 00:20:57,620
make this all developer friendly we also

00:20:53,510 --> 00:21:00,230
developed SPT utils including you know

00:20:57,620 --> 00:21:02,929
the SBT script to bootstrap clusters

00:21:00,230 --> 00:21:05,120
start stop services report services

00:21:02,929 --> 00:21:08,049
state standards in a cluster and report

00:21:05,120 --> 00:21:15,710
with milquetoast errors and also we do a

00:21:08,049 --> 00:21:18,500
blue-green tip deployment script allows

00:21:15,710 --> 00:21:26,510
us is to do blue green arc across the

00:21:18,500 --> 00:21:30,110
deployment in compatible services you

00:21:26,510 --> 00:21:34,279
want to bring to the new cluster you can

00:21:30,110 --> 00:21:36,350
use Bluegreen deployment so that's very

00:21:34,279 --> 00:21:39,230
handy for us where you can just start as

00:21:36,350 --> 00:21:41,490
week you can start catalog in your stuff

00:21:39,230 --> 00:21:44,470
cut off so it stopped a lot

00:21:41,490 --> 00:21:47,890
so you don't have to view each

00:21:44,470 --> 00:21:55,780
micro-services with different SVG window

00:21:47,890 --> 00:22:01,960
so so then the next part is what's

00:21:55,780 --> 00:22:04,030
coming so first thing we want to think

00:22:01,960 --> 00:22:08,380
about it is to improve the performance

00:22:04,030 --> 00:22:11,250
and the binary migration compatibility

00:22:08,380 --> 00:22:13,900
migration for our messages between

00:22:11,250 --> 00:22:17,020
micro-services so we want to generate

00:22:13,900 --> 00:22:19,540
case classes from message types of these

00:22:17,020 --> 00:22:24,490
are put above or beyond the new thing

00:22:19,540 --> 00:22:30,390
from Amazon right now we use case

00:22:24,490 --> 00:22:34,600
classes which is not very you know

00:22:30,390 --> 00:22:36,220
migration friendly so that's the first

00:22:34,600 --> 00:22:38,140
thing we're thinking and the second is

00:22:36,220 --> 00:22:41,050
multi service versioning so we are

00:22:38,140 --> 00:22:44,140
hoping to where we are planning to add

00:22:41,050 --> 00:22:47,530
this multi service visioning capability

00:22:44,140 --> 00:22:51,280
come closer so you can deploy different

00:22:47,530 --> 00:22:53,590
versions of the same microservice in the

00:22:51,280 --> 00:22:56,350
cluster and even interdependencies

00:22:53,590 --> 00:22:59,200
between microservices so it should be

00:22:56,350 --> 00:23:01,240
able to say okay I'm dependent on this

00:22:59,200 --> 00:23:03,370
version of that server so I'm only going

00:23:01,240 --> 00:23:05,080
to talk to this version if that's a new

00:23:03,370 --> 00:23:06,420
version of that service company we're

00:23:05,080 --> 00:23:09,190
going to ignore that

00:23:06,420 --> 00:23:12,100
now the other things including Auto

00:23:09,190 --> 00:23:16,510
scale services instance and then

00:23:12,100 --> 00:23:20,290
continue delivers can use the CD or

00:23:16,510 --> 00:23:22,600
continuously so those we are using a

00:23:20,290 --> 00:23:31,990
darker and we deploy from AWS

00:23:22,600 --> 00:23:37,720
so using PCs and other AWS related table

00:23:31,990 --> 00:23:40,840
tools so that's our next step so the

00:23:37,720 --> 00:23:45,040
open source projects that we developed

00:23:40,840 --> 00:23:47,380
for this project are high swagger

00:23:45,040 --> 00:23:49,950
I think kinda low just go over them

00:23:47,380 --> 00:23:54,630
again kind of lower house too

00:23:49,950 --> 00:23:58,500
provided the reactive work pipeline that

00:23:54,630 --> 00:24:01,850
give you the automatic concurrency

00:23:58,500 --> 00:24:05,480
detection that of American architecture

00:24:01,850 --> 00:24:08,580
sorry automatic concurrency size

00:24:05,480 --> 00:24:14,809
detection is also available through

00:24:08,580 --> 00:24:19,139
packing order that is in Rococo the we

00:24:14,809 --> 00:24:23,429
contribute that code in Tanaka so the

00:24:19,139 --> 00:24:26,490
others so that's the first thing second

00:24:23,429 --> 00:24:29,250
one is so cool it's the distributor or

00:24:26,490 --> 00:24:32,929
de suite the rest endpoints capability

00:24:29,250 --> 00:24:36,299
that allows you to write your REST API

00:24:32,929 --> 00:24:38,760
endpoints in your micro service and then

00:24:36,299 --> 00:24:41,760
deploy it to a centralized Play app

00:24:38,760 --> 00:24:42,830
called API gateway so that's the second

00:24:41,760 --> 00:24:45,210
thing

00:24:42,830 --> 00:24:47,909
laughing is the place worker which

00:24:45,210 --> 00:24:50,789
allows you to write swagger definition

00:24:47,909 --> 00:24:56,789
in the browser as Commons and generates

00:24:50,789 --> 00:25:00,960
swagger the real Swagger's back and be

00:24:56,789 --> 00:25:04,200
served by the swagger UI so that's our

00:25:00,960 --> 00:25:07,440
three open source projects so other than

00:25:04,200 --> 00:25:14,220
our card and play we use cats shapeless

00:25:07,440 --> 00:25:17,039
and kittens for a project I need to

00:25:14,220 --> 00:25:22,620
introduce them here except kittens which

00:25:17,039 --> 00:25:24,480
is a relatively new it is basically a

00:25:22,620 --> 00:25:29,279
library that a small library right now

00:25:24,480 --> 00:25:31,830
combining the the ability to combining

00:25:29,279 --> 00:25:33,779
basically generic generic programming

00:25:31,830 --> 00:25:42,620
and functional programming together so

00:25:33,779 --> 00:25:42,620
it's pretty awesome show an example that

00:25:42,889 --> 00:25:51,840
we just want to shout out

00:25:47,820 --> 00:25:57,529
thanks to a group of people that are

00:25:51,840 --> 00:25:57,529
very helpful for the for our Parliament

00:25:57,769 --> 00:26:10,039
and this is our team really awesome team

00:26:04,940 --> 00:26:14,519
so that's look at something more geeky

00:26:10,039 --> 00:26:17,970
it's our functional building blog so

00:26:14,519 --> 00:26:21,179
regularly in the full functional

00:26:17,970 --> 00:26:24,000
programming what we usually how we build

00:26:21,179 --> 00:26:29,159
application is is basically a function

00:26:24,000 --> 00:26:32,940
from A to B for example you have a get

00:26:29,159 --> 00:26:36,149
user which is from ID with user ID to a

00:26:32,940 --> 00:26:42,620
user the problem is that building blog

00:26:36,149 --> 00:26:45,840
is that first it's blocking it's

00:26:42,620 --> 00:26:54,690
synchronous a second it doesn't be so

00:26:45,840 --> 00:26:58,500
exceptions so so our building block we

00:26:54,690 --> 00:27:01,260
start to use is is basically a data

00:26:58,500 --> 00:27:04,049
structure that provided by cats and

00:27:01,260 --> 00:27:08,690
Scott idea as well called actually to

00:27:04,049 --> 00:27:13,220
dereference one is class Li the other is

00:27:08,690 --> 00:27:16,590
you can sync actual archaea just either

00:27:13,220 --> 00:27:18,450
it incorporates the future into it so

00:27:16,590 --> 00:27:24,090
it's basically you can think of it as a

00:27:18,450 --> 00:27:27,360
future of either so but what what we

00:27:24,090 --> 00:27:29,970
need either is either left or right so

00:27:27,360 --> 00:27:32,460
the right side is the successful case

00:27:29,970 --> 00:27:35,850
it's a success case it's easy to

00:27:32,460 --> 00:27:37,649
understand the left side is a reason why

00:27:35,850 --> 00:27:40,289
it didn't succeed it could be exception

00:27:37,649 --> 00:27:43,350
it could be the data is not found it

00:27:40,289 --> 00:27:46,559
could be some validation error but it's

00:27:43,350 --> 00:27:50,970
it's it's it's just a reason that we

00:27:46,559 --> 00:27:56,360
basically consolidate or our set paths

00:27:50,970 --> 00:27:59,760
into a DT of that we called reason and

00:27:56,360 --> 00:28:01,389
so so that's XOR T it's a future of

00:27:59,760 --> 00:28:03,459
either either

00:28:01,389 --> 00:28:06,989
this thing failed due to some reason or

00:28:03,459 --> 00:28:11,339
you get this thing out and class Lee is

00:28:06,989 --> 00:28:14,349
basically wrapping a function from a to

00:28:11,339 --> 00:28:17,469
this XOR T the future of the reason of

00:28:14,349 --> 00:28:21,820
this thing so so you can think of the

00:28:17,469 --> 00:28:25,989
Class D as just a function but instead

00:28:21,820 --> 00:28:29,169
of returning day to be its you give it a

00:28:25,989 --> 00:28:30,519
insta Burton and B it repents the XOR T

00:28:29,169 --> 00:28:34,149
future reason would be which is

00:28:30,519 --> 00:28:40,329
basically the future of either reason or

00:28:34,149 --> 00:28:42,929
B so so that's the actual type so what

00:28:40,329 --> 00:28:42,929
does that give us

00:28:43,769 --> 00:28:50,259
sorry white goes there just look at this

00:28:46,719 --> 00:28:52,359
again either example in our code which

00:28:50,259 --> 00:28:59,799
is a class the effect so our key future

00:28:52,359 --> 00:29:08,859
using ID from so the first thing it

00:28:59,799 --> 00:29:14,829
gives you is function composition which

00:29:08,859 --> 00:29:16,599
has an age it has the first message call

00:29:14,829 --> 00:29:19,599
validate user you're passing a common

00:29:16,599 --> 00:29:22,719
name a possible password the left side

00:29:19,599 --> 00:29:25,239
of the K is the Fromm type and the right

00:29:22,719 --> 00:29:30,070
side of the K which is this part is the

00:29:25,239 --> 00:29:35,459
ID is the result type so the first

00:29:30,070 --> 00:29:35,459
method of function is basically from

00:29:35,609 --> 00:29:42,190
from K from the account and password can

00:29:39,849 --> 00:29:46,149
ID and then you've got another one which

00:29:42,190 --> 00:29:49,299
is from ID to name then you can just

00:29:46,149 --> 00:29:51,549
compose them validate user and then get

00:29:49,299 --> 00:29:53,409
to user name it's just like ah mostly

00:29:51,549 --> 00:29:55,809
it's just like function conversation was

00:29:53,409 --> 00:29:57,369
all your your function is actually a lot

00:29:55,809 --> 00:29:59,549
more complicated they are non-blocking

00:29:57,369 --> 00:30:02,210
there are no synchronous and they also

00:29:59,549 --> 00:30:05,269
dumpster exceptions

00:30:02,210 --> 00:30:10,279
neither and you can just compose that

00:30:05,269 --> 00:30:16,820
this so the second type of composition

00:30:10,279 --> 00:30:19,850
you can do is this class Lee is monadic

00:30:16,820 --> 00:30:22,669
one addict so this class II is actually

00:30:19,850 --> 00:30:25,159
one apt so you can just use this thing

00:30:22,669 --> 00:30:28,340
you can say we've got user name name and

00:30:25,159 --> 00:30:32,990
get either age age and you'd a new user

00:30:28,340 --> 00:30:38,419
from name and age and that gives you a

00:30:32,990 --> 00:30:41,809
classic a of from ID to user so because

00:30:38,419 --> 00:30:45,980
because this get username takes ID and

00:30:41,809 --> 00:30:51,499
just get user page takes you to so when

00:30:45,980 --> 00:30:55,639
you do this one addict conversation they

00:30:51,499 --> 00:30:58,519
just just like one else so that's very

00:30:55,639 --> 00:31:02,929
convenient to use one thing I have to

00:30:58,519 --> 00:31:06,950
point out is that to use this you have

00:31:02,929 --> 00:31:12,110
to there's this scholar saying code si

00:31:06,950 --> 00:31:15,259
27 1 2 which is about prevent you to use

00:31:12,110 --> 00:31:18,679
this but very fortunately just a week

00:31:15,259 --> 00:31:23,210
ago I think maybe two weeks ago a guy

00:31:18,679 --> 00:31:26,149
called mine sobbing developed Scala

00:31:23,210 --> 00:31:28,610
compiler plugging that sticks there so

00:31:26,149 --> 00:31:36,980
if you use that companion you can use

00:31:28,610 --> 00:31:39,279
this so in the last type of

00:31:36,980 --> 00:31:45,230
conversations go and generic composition

00:31:39,279 --> 00:31:50,529
that is going to use the power so

00:31:45,230 --> 00:31:54,320
instead of full you can simply say I

00:31:50,529 --> 00:31:56,629
want the name field to be get user name

00:31:54,320 --> 00:32:02,740
and age view to be a get you to the page

00:31:56,629 --> 00:32:02,740
and that gives me a user out and that's

00:32:03,249 --> 00:32:08,070
very

00:32:05,370 --> 00:32:11,630
- Maeve our elegant and very new way to

00:32:08,070 --> 00:32:15,090
compose functionalities you can write

00:32:11,630 --> 00:32:17,360
you can sync up you have each gap

00:32:15,090 --> 00:32:19,410
username and get user age is

00:32:17,360 --> 00:32:21,150
micro-service and you can compose my

00:32:19,410 --> 00:32:23,100
craft server this way you can say but

00:32:21,150 --> 00:32:25,080
this is it fields they are from this

00:32:23,100 --> 00:32:26,640
micro service and what those little

00:32:25,080 --> 00:32:28,590
fields are from that my craft service

00:32:26,640 --> 00:32:30,930
and then we just put them together and

00:32:28,590 --> 00:32:34,800
we get a the congregating information

00:32:30,930 --> 00:32:39,900
out and you know that's very easy to

00:32:34,800 --> 00:32:43,700
read and easy to understand and there's

00:32:39,900 --> 00:32:46,680
no basically no bullet point so that

00:32:43,700 --> 00:32:49,050
basically concludes the presentation

00:32:46,680 --> 00:32:51,200
which is pretty short all right thank

00:32:49,050 --> 00:32:51,200

YouTube URL: https://www.youtube.com/watch?v=8mR40A7SRWM


