Title: Monitoring Reactive Applications - by Duncan DeVore & Henrik EngstroÌˆm
Publication date: 2016-06-17
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.


Abstract:
Reactive Applications are the next major evolution of the Internet. They allow for applications to be responsive, scalable and resilient by building on a fully event-driven foundation. Lightbendâ€™s Reactive Platform, consisting of the Play Framework, the Akka middleware and the Scala programming language embraces this new programming paradigm which allows developers to write interactive applications that are always available and which adapt to changing load by being distributed by design.
 
While the reactive approach enable us to build highly scalable and resilient applications it also introduces new challenges in how to monitor them. Almost every current monitoring tool relies on a stack frame based approach where using the stack trace can provide good answers to what caused the exceptional state. In message driven, or asynchronous, applications this approach no longer provides any good information. We therefore need to invent new approaches for how to monitor these types of applications. During this session we will cover the traditional monitoring approach, different possible ways of how to monitor asynchronous applications and finally show the way we have chosen to build a monitoring tool for reactive applications at Lightbend.
Captions: 
	00:00:01,089 --> 00:00:06,490
and today we're going to talk about

00:00:02,860 --> 00:00:09,010
monitoring reactive applications so the

00:00:06,490 --> 00:00:12,490
agenda for today is first a little bit

00:00:09,010 --> 00:00:13,330
about what we think monitoring us then

00:00:12,490 --> 00:00:16,119
we're going to talk about traditional

00:00:13,330 --> 00:00:19,360
monitoring and the architectural shift

00:00:16,119 --> 00:00:22,210
that's going on monitoring reactive

00:00:19,360 --> 00:00:24,280
applications trends in monitoring best

00:00:22,210 --> 00:00:25,870
practice and find it a little bit about

00:00:24,280 --> 00:00:29,710
our solution that we're working on like

00:00:25,870 --> 00:00:33,039
been monitoring all right so what is

00:00:29,710 --> 00:00:34,899
monitoring it's to be aware of the state

00:00:33,039 --> 00:00:37,030
of a system to observe a situation for

00:00:34,899 --> 00:00:38,829
any changes which may occur over time

00:00:37,030 --> 00:00:41,530
using and monitoring or measuring

00:00:38,829 --> 00:00:44,230
devices on Sorey now this can be a whole

00:00:41,530 --> 00:00:45,879
lot of things of course so we're gonna

00:00:44,230 --> 00:00:49,260
try to narrow it down what means

00:00:45,879 --> 00:00:53,019
tomorrow monitoring and computing means

00:00:49,260 --> 00:00:54,969
so we have a couple of categories the

00:00:53,019 --> 00:00:57,249
first one is business process monitoring

00:00:54,969 --> 00:01:00,579
and this is where you have monitoring of

00:00:57,249 --> 00:01:03,670
your whole process going on inside your

00:01:00,579 --> 00:01:06,040
system this could be you know a number

00:01:03,670 --> 00:01:09,759
of checkouts that's going on in your

00:01:06,040 --> 00:01:12,250
system or it's more on the flow through

00:01:09,759 --> 00:01:14,649
the system so that's one type of

00:01:12,250 --> 00:01:16,509
monitoring and then you have functional

00:01:14,649 --> 00:01:19,270
monitoring which is more on the use case

00:01:16,509 --> 00:01:21,700
level number of orders in the system

00:01:19,270 --> 00:01:23,350
right now and finally there's technical

00:01:21,700 --> 00:01:26,079
monitoring where you focus on more

00:01:23,350 --> 00:01:29,920
individual pieces like number of actors

00:01:26,079 --> 00:01:31,509
running or what-have-you and then there

00:01:29,920 --> 00:01:33,250
are different types of monitoring so you

00:01:31,509 --> 00:01:37,090
have system monitoring where you focus

00:01:33,250 --> 00:01:39,130
on CPU Network memory usage and things

00:01:37,090 --> 00:01:42,039
like that and then you have business

00:01:39,130 --> 00:01:44,770
activity monitoring where you look at

00:01:42,039 --> 00:01:47,950
business transactions that are going on

00:01:44,770 --> 00:01:51,000
like I said before you know number of

00:01:47,950 --> 00:01:54,969
checkouts of the carts or what have you

00:01:51,000 --> 00:01:57,070
you also have tracing span transaction

00:01:54,969 --> 00:01:59,499
monitoring which basically means you're

00:01:57,070 --> 00:02:01,659
you're trying to figure out the flow in

00:01:59,499 --> 00:02:03,219
your system what actors are

00:02:01,659 --> 00:02:06,100
communicating with other actors if

00:02:03,219 --> 00:02:08,619
you're looking at an actor system or on

00:02:06,100 --> 00:02:10,539
a synchronous system even and then you

00:02:08,619 --> 00:02:13,130
have performance monitoring which is of

00:02:10,539 --> 00:02:15,410
course related to performance

00:02:13,130 --> 00:02:17,780
integration monitoring were you trying

00:02:15,410 --> 00:02:20,930
to figure out how your micro-service are

00:02:17,780 --> 00:02:23,390
operating this is more of looking from

00:02:20,930 --> 00:02:26,690
the clients perspective on on a service

00:02:23,390 --> 00:02:29,540
for example Netflix has a dashboard

00:02:26,690 --> 00:02:31,400
where they gather information of what

00:02:29,540 --> 00:02:37,250
the clients think of a service and

00:02:31,400 --> 00:02:39,349
that's like the true-true status of that

00:02:37,250 --> 00:02:41,450
service how it's working and finally

00:02:39,349 --> 00:02:43,819
have application monitoring which is

00:02:41,450 --> 00:02:46,640
more under meta gritty details like how

00:02:43,819 --> 00:02:51,799
many messages have I got in my mailbox

00:02:46,640 --> 00:02:54,940
and so forth so the traditional

00:02:51,799 --> 00:02:57,170
monitoring you have a system that's

00:02:54,940 --> 00:02:59,450
consisting of a couple of layers here we

00:02:57,170 --> 00:03:02,080
have a web layer that's being called and

00:02:59,450 --> 00:03:04,310
I calls the application layer and

00:03:02,080 --> 00:03:08,030
something happens in the application

00:03:04,310 --> 00:03:11,000
layer and and in this type of system you

00:03:08,030 --> 00:03:12,860
have the stacktrace available so you

00:03:11,000 --> 00:03:15,049
have the call stack and you can figure

00:03:12,860 --> 00:03:16,459
out if you log this call stack you can

00:03:15,049 --> 00:03:19,160
actually reason about what has happened

00:03:16,459 --> 00:03:21,380
up until this point so it's it's quite

00:03:19,160 --> 00:03:25,489
easy to get a good understanding of what

00:03:21,380 --> 00:03:27,019
has led up to this exception and if

00:03:25,489 --> 00:03:29,109
there's no exception and you get a

00:03:27,019 --> 00:03:32,840
request back or a response back rather

00:03:29,109 --> 00:03:34,940
then in a synchronous system you can

00:03:32,840 --> 00:03:39,079
easily gather metrics based on the

00:03:34,940 --> 00:03:41,359
request response paradigm so this is not

00:03:39,079 --> 00:03:46,930
simple to monitor but it's much easier

00:03:41,359 --> 00:03:50,600
than what we're going to talk about sure

00:03:46,930 --> 00:03:53,359
so henrik mentioned in the previous

00:03:50,600 --> 00:03:54,829
slide you kind of have a bounded context

00:03:53,359 --> 00:03:57,290
if you will not using domain driven

00:03:54,829 --> 00:04:01,280
design terms there but you kind of have

00:03:57,290 --> 00:04:03,230
boundaries and a very vertical path

00:04:01,280 --> 00:04:07,639
where you're looking at the different

00:04:03,230 --> 00:04:09,230
stack inside your system and that's the

00:04:07,639 --> 00:04:13,730
way a lot of traditional monitoring

00:04:09,230 --> 00:04:15,049
solutions work this is kind of the next

00:04:13,730 --> 00:04:16,789
couple slides you're going to kind of go

00:04:15,049 --> 00:04:18,739
through the process of what has happened

00:04:16,789 --> 00:04:23,030
over the last 40 or 50 years to kind of

00:04:18,739 --> 00:04:24,830
change this scenario and the big piece

00:04:23,030 --> 00:04:26,669
of the puzzle here is has been the

00:04:24,830 --> 00:04:29,280
internet the

00:04:26,669 --> 00:04:31,470
and in in and of itself has had a

00:04:29,280 --> 00:04:33,389
significant impact on how we conduct our

00:04:31,470 --> 00:04:35,430
lives you know I look at my kids and the

00:04:33,389 --> 00:04:38,430
way they operate and without internet

00:04:35,430 --> 00:04:40,800
access they're like totally lost and so

00:04:38,430 --> 00:04:43,020
it's affected us societally but it's

00:04:40,800 --> 00:04:45,000
also had a drastic effect on our

00:04:43,020 --> 00:04:47,760
computing right our systems the way that

00:04:45,000 --> 00:04:49,530
we design stuff and so the original idea

00:04:47,760 --> 00:04:52,230
behind it was to build this distributed

00:04:49,530 --> 00:04:54,600
network that would allow people to

00:04:52,230 --> 00:04:58,169
essentially have access to data anywhere

00:04:54,600 --> 00:05:01,850
and this gentleman JCR Licklider which

00:04:58,169 --> 00:05:07,710
who was part of ARPA back then was the

00:05:01,850 --> 00:05:09,240
mastermind behind it as time went on and

00:05:07,710 --> 00:05:11,580
as they began to work through this

00:05:09,240 --> 00:05:13,350
scenario you know the whole idea behind

00:05:11,580 --> 00:05:16,229
distributed computing came into

00:05:13,350 --> 00:05:18,389
existence initially with mid-range

00:05:16,229 --> 00:05:21,300
computers mainframes and asked for

00:05:18,389 --> 00:05:24,389
hundreds of types of system 380s if you

00:05:21,300 --> 00:05:25,979
guys can remember then and by connecting

00:05:24,389 --> 00:05:27,900
them together through educational and

00:05:25,979 --> 00:05:30,900
military establishments they began to

00:05:27,900 --> 00:05:33,060
realize that the the computing model

00:05:30,900 --> 00:05:35,610
required to manage memory and do these

00:05:33,060 --> 00:05:37,350
types of things was different than your

00:05:35,610 --> 00:05:38,970
typical local system and they had to

00:05:37,350 --> 00:05:42,020
take that into consideration as they

00:05:38,970 --> 00:05:46,020
were passing information back and forth

00:05:42,020 --> 00:05:48,510
in 1990 ARPANET ended up being

00:05:46,020 --> 00:05:51,210
decommissioned and turned over to the

00:05:48,510 --> 00:05:52,830
public and so corporations got into it

00:05:51,210 --> 00:05:54,600
and that kind of blew the doors off

00:05:52,830 --> 00:05:57,600
everything because now people said hey

00:05:54,600 --> 00:06:00,300
we can use this to make money how can we

00:05:57,600 --> 00:06:02,850
do it we can we can change the way that

00:06:00,300 --> 00:06:06,450
people do things I mean think about it

00:06:02,850 --> 00:06:08,940
if you're 40 years old or older when you

00:06:06,450 --> 00:06:10,830
used to shop right you didn't shop on

00:06:08,940 --> 00:06:15,030
Amazon you went to the mall and you

00:06:10,830 --> 00:06:17,760
bought stuff or what have you the

00:06:15,030 --> 00:06:20,639
internet didn't exist but today it's so

00:06:17,760 --> 00:06:22,889
commonplace that it's almost like what

00:06:20,639 --> 00:06:25,620
would I do without it we buy all our

00:06:22,889 --> 00:06:27,240
toys off of Amazon way ahead of time

00:06:25,620 --> 00:06:30,210
rather than you know go fight the

00:06:27,240 --> 00:06:34,349
traffic at the mall so huge huge impact

00:06:30,210 --> 00:06:35,880
on our lives so we had distributed

00:06:34,349 --> 00:06:37,620
computing which was kind of the

00:06:35,880 --> 00:06:39,270
technical aspect of it

00:06:37,620 --> 00:06:41,160
and then the notion of cloud computing

00:06:39,270 --> 00:06:42,479
come in I love the word cloud because it

00:06:41,160 --> 00:06:46,050
means so many things to different people

00:06:42,479 --> 00:06:48,600
but I like taking a look at cloud

00:06:46,050 --> 00:06:51,449
computing as really being the economics

00:06:48,600 --> 00:06:55,050
part of it right you were able to now

00:06:51,449 --> 00:06:59,280
tap into computational abilities and

00:06:55,050 --> 00:07:01,590
powers on a scale of economics you could

00:06:59,280 --> 00:07:03,030
pay for the amount of bandwidth that you

00:07:01,590 --> 00:07:05,220
needed for the time that were you were

00:07:03,030 --> 00:07:08,220
using it or you're you are using it so

00:07:05,220 --> 00:07:10,710
it allowed smaller businesses to now get

00:07:08,220 --> 00:07:13,320
into the game bring their ideas to the

00:07:10,710 --> 00:07:15,300
forefront and really hit the ground

00:07:13,320 --> 00:07:16,740
running and that's that's had a pretty

00:07:15,300 --> 00:07:18,979
significant impact as we'll see here

00:07:16,740 --> 00:07:21,150
shortly

00:07:18,979 --> 00:07:24,300
when Henrik and I were talking about

00:07:21,150 --> 00:07:26,400
this he brought up this you know the

00:07:24,300 --> 00:07:29,400
network is the computer and in a sense

00:07:26,400 --> 00:07:32,010
I'm not a big fan of dumb terminals but

00:07:29,400 --> 00:07:34,530
in a sense it's true right when we're

00:07:32,010 --> 00:07:35,250
building our systems if we're using SBT

00:07:34,530 --> 00:07:37,530
or maven

00:07:35,250 --> 00:07:39,479
unless we have a local cache right we

00:07:37,530 --> 00:07:42,270
can't build because we're pulling from

00:07:39,479 --> 00:07:45,539
the Internet so the whole idea is is

00:07:42,270 --> 00:07:47,789
that you plug in to this network so to

00:07:45,539 --> 00:07:50,340
speak and you know you're off to the

00:07:47,789 --> 00:07:52,860
races and when cloud computing came

00:07:50,340 --> 00:07:55,800
around it began to do this economic

00:07:52,860 --> 00:07:57,270
shift and convincing businesses that

00:07:55,800 --> 00:07:59,849
security is a huge issue right

00:07:57,270 --> 00:08:02,639
convincing businesses the question ends

00:07:59,849 --> 00:08:04,470
up becoming D is your data center more

00:08:02,639 --> 00:08:07,289
secure than Amazon's Amazon spends

00:08:04,470 --> 00:08:09,240
billions of dollars on security and how

00:08:07,289 --> 00:08:12,090
much do you guys spend right and so the

00:08:09,240 --> 00:08:14,250
argument you beginning to see different

00:08:12,090 --> 00:08:17,400
businesses even financial institutions

00:08:14,250 --> 00:08:20,820
begin to move off-site to cloud

00:08:17,400 --> 00:08:26,760
computing models best company logo ever

00:08:20,820 --> 00:08:28,740
by the way that's right so the

00:08:26,760 --> 00:08:31,620
application of the shift here you can

00:08:28,740 --> 00:08:34,349
see is storage prices CPU prices

00:08:31,620 --> 00:08:37,469
bandwidth prices went down and the

00:08:34,349 --> 00:08:39,810
requirement for network traffic went up

00:08:37,469 --> 00:08:42,240
and that's a great mix when things get

00:08:39,810 --> 00:08:45,150
cheaper and people want more of it it

00:08:42,240 --> 00:08:47,209
begins to become very very popular so

00:08:45,150 --> 00:08:50,160
reducing all these different things

00:08:47,209 --> 00:08:51,329
totally reshaped how we do business

00:08:50,160 --> 00:08:54,299
working with differ

00:08:51,329 --> 00:08:57,149
clients I know several large clients who

00:08:54,299 --> 00:08:58,860
have had significant impact by little

00:08:57,149 --> 00:09:02,220
companies that have came out of nowhere

00:08:58,860 --> 00:09:04,259
and you know wrote a system on Ruby on

00:09:02,220 --> 00:09:06,899
Rails or whatever and all of a sudden

00:09:04,259 --> 00:09:08,610
they're doing really well and four or

00:09:06,899 --> 00:09:11,670
five guys that nobody knows are

00:09:08,610 --> 00:09:13,559
impacting a billion dollar company and

00:09:11,670 --> 00:09:15,540
that's the reality of the internet and

00:09:13,559 --> 00:09:18,809
it's kind of like the Wild West in many

00:09:15,540 --> 00:09:21,299
ways and I think I should add it a

00:09:18,809 --> 00:09:23,610
transition here this is that the

00:09:21,299 --> 00:09:25,829
interesting thing I was speaking to

00:09:23,610 --> 00:09:27,839
another company yesterday and the idea

00:09:25,829 --> 00:09:30,360
is what are we are we a financial

00:09:27,839 --> 00:09:34,350
institution or a software company this

00:09:30,360 --> 00:09:37,259
idea here with Amazon is originally they

00:09:34,350 --> 00:09:39,179
were a bookstore but their network

00:09:37,259 --> 00:09:41,730
services that they sell surpass the

00:09:39,179 --> 00:09:43,980
retail sales online so they had to step

00:09:41,730 --> 00:09:45,449
back and think what are we you know what

00:09:43,980 --> 00:09:47,459
what kind of business are we and the

00:09:45,449 --> 00:09:50,480
same thing here the the canonical

00:09:47,459 --> 00:09:53,040
example Netflix versus blockbuster

00:09:50,480 --> 00:09:55,649
blockbuster did not embrace the shift in

00:09:53,040 --> 00:09:58,019
time and when they did they finally did

00:09:55,649 --> 00:09:59,429
it with HBO but it was too late and they

00:09:58,019 --> 00:10:04,980
ended up going out of business I mean

00:09:59,429 --> 00:10:09,660
blockbuster was huge so the result

00:10:04,980 --> 00:10:12,569
became this quote in the new world it's

00:10:09,660 --> 00:10:15,449
not the big fish that that eats a small

00:10:12,569 --> 00:10:17,339
fish but it's the fastest fish that eats

00:10:15,449 --> 00:10:19,769
the slow fish and I realized by the

00:10:17,339 --> 00:10:21,929
other day that to the left that those

00:10:19,769 --> 00:10:24,959
were micro services right and to the

00:10:21,929 --> 00:10:29,309
right is a monolith that was not

00:10:24,959 --> 00:10:30,929
intended but uh so the advent of that is

00:10:29,309 --> 00:10:32,610
okay now we have this distributed

00:10:30,929 --> 00:10:34,709
computing model people like Google and

00:10:32,610 --> 00:10:36,329
Amazon and these companies that have all

00:10:34,709 --> 00:10:38,129
this money have hired the best and the

00:10:36,329 --> 00:10:40,799
brightest talent in the world to build

00:10:38,129 --> 00:10:42,959
distributed systems as you start to get

00:10:40,799 --> 00:10:46,049
into it it's complex right how do we

00:10:42,959 --> 00:10:48,709
manage this we don't have the threading

00:10:46,049 --> 00:10:51,299
concepts the same way that we do on a

00:10:48,709 --> 00:10:52,889
monolith we don't have transaction

00:10:51,299 --> 00:10:55,230
management the same way all these

00:10:52,889 --> 00:10:58,139
different problems so how do we do this

00:10:55,230 --> 00:11:02,339
so our mission at type or like been

00:10:58,139 --> 00:11:04,889
formerly known as type safe is to with

00:11:02,339 --> 00:11:08,939
the reactive manifesto is this idea of

00:11:04,889 --> 00:11:10,709
being a philosophy or giving an idea of

00:11:08,939 --> 00:11:13,350
how to build systems and then providing

00:11:10,709 --> 00:11:15,899
toolkits that satisfy those so we're all

00:11:13,350 --> 00:11:17,819
familiar with reactive you know the

00:11:15,899 --> 00:11:19,709
number one thing being responsive you've

00:11:17,819 --> 00:11:21,239
got to respond back to the client that's

00:11:19,709 --> 00:11:22,649
what's important that's why you're there

00:11:21,239 --> 00:11:25,559
you're presenting something to the

00:11:22,649 --> 00:11:29,129
client if you're not responsive then you

00:11:25,559 --> 00:11:31,379
fail how do you do that the base is you

00:11:29,129 --> 00:11:33,660
know being message driven and these are

00:11:31,379 --> 00:11:36,629
some definitions pulled out of the

00:11:33,660 --> 00:11:38,279
dictionary and as a result of this type

00:11:36,629 --> 00:11:40,319
of infrastructure you can be resilient

00:11:38,279 --> 00:11:45,480
elastic right we've we've all talked

00:11:40,319 --> 00:11:47,279
through that before so what happens is

00:11:45,480 --> 00:11:49,619
is okay now we have the toolkit we have

00:11:47,279 --> 00:11:51,749
the ideas web some of us may be still

00:11:49,619 --> 00:11:54,959
new to it there's still a ways to go but

00:11:51,749 --> 00:11:56,459
at least we have a way for the common

00:11:54,959 --> 00:11:59,100
person to begin to build these

00:11:56,459 --> 00:12:01,999
applications in a reasonable and

00:11:59,100 --> 00:12:04,769
responsible way so over here we have our

00:12:01,999 --> 00:12:06,779
micro service or whatever you want to

00:12:04,769 --> 00:12:08,819
call it that works together and that

00:12:06,779 --> 00:12:10,379
whole thing is an application and each

00:12:08,819 --> 00:12:12,660
one of those little fishes can be a node

00:12:10,379 --> 00:12:15,989
or a different service and we have this

00:12:12,660 --> 00:12:18,720
asynchronous parallel distributed system

00:12:15,989 --> 00:12:20,910
right a computing system that works but

00:12:18,720 --> 00:12:22,769
we have this little disclaimer down here

00:12:20,910 --> 00:12:25,290
and you probably can't read it so I'll

00:12:22,769 --> 00:12:27,059
read it to you the availability and

00:12:25,290 --> 00:12:29,040
accuracy of the information delivered by

00:12:27,059 --> 00:12:30,889
these services and information they

00:12:29,040 --> 00:12:32,910
portray are contingent upon a

00:12:30,889 --> 00:12:34,319
distributed computing environment

00:12:32,910 --> 00:12:36,269
comprised of several unique a

00:12:34,319 --> 00:12:39,179
synchronous parallel non deterministic

00:12:36,269 --> 00:12:40,679
applications within said companies multi

00:12:39,179 --> 00:12:42,269
clustered system as a result the

00:12:40,679 --> 00:12:44,939
availability accuracy and access to

00:12:42,269 --> 00:12:46,529
these services and data they provide may

00:12:44,939 --> 00:12:48,809
or may not be available at any given

00:12:46,529 --> 00:12:51,389
time you get the idea right just like a

00:12:48,809 --> 00:12:55,499
car ad that's the problem we got now

00:12:51,389 --> 00:12:59,069
right we have non determinism okay we

00:12:55,499 --> 00:13:00,859
have this problem so this is what we get

00:12:59,069 --> 00:13:03,899
now right we have this beautiful

00:13:00,859 --> 00:13:07,169
asynchronous distributed system and this

00:13:03,899 --> 00:13:10,169
is our stack trace you know what is that

00:13:07,169 --> 00:13:13,649
how does that help me find out what my

00:13:10,169 --> 00:13:15,419
problem is right I have no idea so how

00:13:13,649 --> 00:13:16,889
are we going to solve that right we

00:13:15,419 --> 00:13:18,400
can't just plug in a traditional

00:13:16,889 --> 00:13:20,710
monitoring system because

00:13:18,400 --> 00:13:22,570
we don't know where the problem is and

00:13:20,710 --> 00:13:25,690
we don't know when it's gonna happen in

00:13:22,570 --> 00:13:27,670
all kinds of problems so I had this

00:13:25,690 --> 00:13:29,800
comic that I really like that talks

00:13:27,670 --> 00:13:31,450
about it you know you said sometimes I'm

00:13:29,800 --> 00:13:33,010
shocked at how many options we have

00:13:31,450 --> 00:13:35,170
right and distributed computing is a lot

00:13:33,010 --> 00:13:37,029
of options features and circuit breakers

00:13:35,170 --> 00:13:39,430
and actors and all kinds of different

00:13:37,029 --> 00:13:41,320
asynchronous stuff like at any moment in

00:13:39,430 --> 00:13:42,910
this conversation I can punch the person

00:13:41,320 --> 00:13:44,529
I was talking to and all these

00:13:42,910 --> 00:13:48,940
potentially life-changing events would

00:13:44,529 --> 00:13:52,450
unfold it's only my mental rules that

00:13:48,940 --> 00:13:55,060
stop me from punching you and stripping

00:13:52,450 --> 00:13:56,830
naked or getting on a plane to Fiji sure

00:13:55,060 --> 00:13:58,690
rules have reasons but shouldn't you

00:13:56,830 --> 00:14:04,150
exercise that freedom at least once

00:13:58,690 --> 00:14:06,580
before you die Wham okay I should have

00:14:04,150 --> 00:14:10,120
seen that coming but you couldn't that's

00:14:06,580 --> 00:14:12,370
the beauty right that's the reality we

00:14:10,120 --> 00:14:14,320
live in now so how do we deal with that

00:14:12,370 --> 00:14:15,910
as Henrik was mentioning all the

00:14:14,320 --> 00:14:18,550
different types of monitoring at the end

00:14:15,910 --> 00:14:20,710
of the day it comes down to a military

00:14:18,550 --> 00:14:22,480
term situational awareness right you got

00:14:20,710 --> 00:14:25,000
to be aware of your situation your

00:14:22,480 --> 00:14:27,339
application your business because your

00:14:25,000 --> 00:14:30,100
business is becoming the software is

00:14:27,339 --> 00:14:31,810
becoming your business so on the

00:14:30,100 --> 00:14:33,370
monitoring team we're trying to address

00:14:31,810 --> 00:14:35,589
that right we're trying to look at the

00:14:33,370 --> 00:14:37,770
different ways we can handle it we have

00:14:35,589 --> 00:14:41,650
this asynchronous distributed system

00:14:37,770 --> 00:14:42,370
okay and the problem is you know what's

00:14:41,650 --> 00:14:45,250
going on

00:14:42,370 --> 00:14:46,690
yeah the path where you are is no longer

00:14:45,250 --> 00:14:48,310
available you go to the mall you are

00:14:46,690 --> 00:14:52,000
here well that you don't get that in

00:14:48,310 --> 00:14:53,890
akka right you don't know where your

00:14:52,000 --> 00:14:55,120
code will execute especially in a

00:14:53,890 --> 00:14:56,920
clustered system if you're using

00:14:55,120 --> 00:14:59,800
sharding right it could it could execute

00:14:56,920 --> 00:15:02,110
anywhere that's the beauty of it so you

00:14:59,800 --> 00:15:05,980
end up being in this environment as the

00:15:02,110 --> 00:15:07,720
epitome of non-determinism right and

00:15:05,980 --> 00:15:10,150
that was I forget his name when when

00:15:07,720 --> 00:15:12,339
multithreading first came out he was

00:15:10,150 --> 00:15:14,020
it's a great advancement in computing

00:15:12,339 --> 00:15:16,150
but now programmers chase

00:15:14,020 --> 00:15:19,060
non-deterministic problems all the time

00:15:16,150 --> 00:15:20,770
and it's no different in parallel

00:15:19,060 --> 00:15:24,360
computing or distributed computing it's

00:15:20,770 --> 00:15:28,000
just actually worse so what do we do

00:15:24,360 --> 00:15:31,030
well one of the things that I think is

00:15:28,000 --> 00:15:33,010
fairly obvious is the notion of tracing

00:15:31,030 --> 00:15:35,920
when you get into a distributed system

00:15:33,010 --> 00:15:39,010
you need to begin to think about paths

00:15:35,920 --> 00:15:41,590
through your application across your

00:15:39,010 --> 00:15:43,900
cluster rather than thinking about a

00:15:41,590 --> 00:15:45,790
specific service or a specific way

00:15:43,900 --> 00:15:48,640
something works you want to think about

00:15:45,790 --> 00:15:51,430
the behavior behavioral use of your

00:15:48,640 --> 00:15:54,400
system now as the developer you're going

00:15:51,430 --> 00:15:56,140
to know your actors or the different

00:15:54,400 --> 00:15:57,640
components of your system and you're

00:15:56,140 --> 00:15:59,740
going to begin to reason about okay

00:15:57,640 --> 00:16:02,950
what's you know happy the happy case

00:15:59,740 --> 00:16:04,450
right the happy path and so forth and

00:16:02,950 --> 00:16:05,410
you're going to identify different paths

00:16:04,450 --> 00:16:09,280
through your system

00:16:05,410 --> 00:16:11,290
so with tracing unit now can do this

00:16:09,280 --> 00:16:13,350
across the asynchronous flows you're

00:16:11,290 --> 00:16:15,640
gonna have a unique entry point and

00:16:13,350 --> 00:16:17,290
you're going to begin and then end

00:16:15,640 --> 00:16:21,910
somewhere and you're going to be able to

00:16:17,290 --> 00:16:23,830
trace through that path now the result

00:16:21,910 --> 00:16:25,960
of it is is a hot path and in our

00:16:23,830 --> 00:16:29,620
current implementation you can get

00:16:25,960 --> 00:16:31,510
things like the time to complete you

00:16:29,620 --> 00:16:34,200
know latency issues and stuff like that

00:16:31,510 --> 00:16:37,230
and we're working on ultimately

00:16:34,200 --> 00:16:40,600
establishing a flow visualization

00:16:37,230 --> 00:16:41,770
what are those graphs called the Sankey

00:16:40,600 --> 00:16:44,530
Sankey yeah

00:16:41,770 --> 00:16:47,230
the determined flow so the heavier the

00:16:44,530 --> 00:16:52,240
flow is through the actors the fatter

00:16:47,230 --> 00:16:54,370
the path is so for us for example we

00:16:52,240 --> 00:16:57,070
have a tracing implementation that you

00:16:54,370 --> 00:17:02,290
wire into your actor and here we begin

00:16:57,070 --> 00:17:04,420
by starting a trace start and then we're

00:17:02,290 --> 00:17:07,089
going to do some work right in this

00:17:04,420 --> 00:17:08,890
example it's pretty simple but you this

00:17:07,089 --> 00:17:11,380
could be through multiple actors you set

00:17:08,890 --> 00:17:13,390
up the starting point as we see here

00:17:11,380 --> 00:17:16,150
trace context system dot start we give

00:17:13,390 --> 00:17:17,800
it a name and then we're gonna simulate

00:17:16,150 --> 00:17:19,660
or whatever we're gonna do some work it

00:17:17,800 --> 00:17:23,790
could go through one or multiple actors

00:17:19,660 --> 00:17:26,770
and then we have an ending point and

00:17:23,790 --> 00:17:30,190
what we'll end up getting is in our

00:17:26,770 --> 00:17:32,440
metrics is this output that gives you

00:17:30,190 --> 00:17:34,270
some information about the process the

00:17:32,440 --> 00:17:36,370
number of counts the minimum the maximum

00:17:34,270 --> 00:17:38,200
and so forth so the thing you got to

00:17:36,370 --> 00:17:40,960
remember as we build a monitoring system

00:17:38,200 --> 00:17:44,000
we have to start down really let the low

00:17:40,960 --> 00:17:46,040
level and it's kind of like a fan-out

00:17:44,000 --> 00:17:47,960
scenario you have to capture your

00:17:46,040 --> 00:17:50,690
information and then you have to

00:17:47,960 --> 00:17:52,730
basically push or have that pulled up to

00:17:50,690 --> 00:17:54,740
another layer and then compose it

00:17:52,730 --> 00:17:57,110
together to get a picture right just

00:17:54,740 --> 00:17:58,280
like anything in life it's you start out

00:17:57,110 --> 00:18:01,430
with the little things and eventually

00:17:58,280 --> 00:18:03,260
you fan out the people in DevOps are

00:18:01,430 --> 00:18:06,170
going to be more interested in a little

00:18:03,260 --> 00:18:12,250
bit higher view until they zero in on a

00:18:06,170 --> 00:18:14,300
problem so oh and the last thing is is

00:18:12,250 --> 00:18:17,720
wouldn't it be nice if this would be

00:18:14,300 --> 00:18:19,760
your dump right your stack trace where

00:18:17,720 --> 00:18:22,460
you could see this is what happened and

00:18:19,760 --> 00:18:25,130
then maybe I don't show it here but see

00:18:22,460 --> 00:18:27,110
- you see boom or something and so you

00:18:25,130 --> 00:18:29,660
can say oh ok why did that happen right

00:18:27,110 --> 00:18:30,890
it gives you kind of an idea and so some

00:18:29,660 --> 00:18:38,060
of the things that we're working on

00:18:30,890 --> 00:18:40,790
hopefully providing ok so and 2010

00:18:38,060 --> 00:18:43,070
dapper wrote this paper called the

00:18:40,790 --> 00:18:45,350
dapper paper and that has been highly

00:18:43,070 --> 00:18:49,130
influential in how to monitor

00:18:45,350 --> 00:18:52,370
distributed distributed systems and back

00:18:49,130 --> 00:18:54,470
in 2011-12 we started implementing our

00:18:52,370 --> 00:18:56,180
own implementation of the DAF based on

00:18:54,470 --> 00:19:00,380
the dapper paper and we call it typesafe

00:18:56,180 --> 00:19:03,500
console and basically the way it's done

00:19:00,380 --> 00:19:05,420
is you have your monitored applications

00:19:03,500 --> 00:19:07,580
running on different nodes and you had

00:19:05,420 --> 00:19:10,910
instrumentation to them so they can push

00:19:07,580 --> 00:19:13,280
events into a database and they just

00:19:10,910 --> 00:19:15,580
push events that happens continuously to

00:19:13,280 --> 00:19:18,350
this database and then you have

00:19:15,580 --> 00:19:21,530
analyzers running continuously trying to

00:19:18,350 --> 00:19:23,690
make sense of this data and they write

00:19:21,530 --> 00:19:25,520
back to the database the results the

00:19:23,690 --> 00:19:28,790
metrics and the events that has happened

00:19:25,520 --> 00:19:31,490
and you have a query or a read side to

00:19:28,790 --> 00:19:34,700
the right of it so that's basically how

00:19:31,490 --> 00:19:38,600
the dapper paper said you should do

00:19:34,700 --> 00:19:42,410
things and here's a view of what's going

00:19:38,600 --> 00:19:44,120
on inside of your after system to give

00:19:42,410 --> 00:19:46,760
you a sense of all the events the events

00:19:44,120 --> 00:19:49,850
are the orange boxes here so a message

00:19:46,760 --> 00:19:51,980
one is sent to actor a and it will

00:19:49,850 --> 00:19:54,500
create an event called receive message 1

00:19:51,980 --> 00:19:57,330
and it's sending message to to actor B

00:19:54,500 --> 00:19:59,670
and then it creates event called - told

00:19:57,330 --> 00:20:02,190
message to in an it's completed message

00:19:59,670 --> 00:20:04,680
one so each of these actors create a lot

00:20:02,190 --> 00:20:07,140
of events and they write that somewhere

00:20:04,680 --> 00:20:09,630
and based on these events we can finally

00:20:07,140 --> 00:20:11,070
make sense of what's going on say each

00:20:09,630 --> 00:20:13,890
event if you look at it could look like

00:20:11,070 --> 00:20:17,340
this it's actually an example of duties

00:20:13,890 --> 00:20:20,100
instructor we had in types of consul so

00:20:17,340 --> 00:20:21,900
the idea is that you give each event

00:20:20,100 --> 00:20:23,880
that happens in the system a unique ID

00:20:21,900 --> 00:20:26,100
that's the ID and then you have a trace

00:20:23,880 --> 00:20:28,560
ID that's unique for the whole trace to

00:20:26,100 --> 00:20:31,500
flow through the system you also have

00:20:28,560 --> 00:20:33,090
this parent ID and that's basically the

00:20:31,500 --> 00:20:35,970
idea of the thing that happened before

00:20:33,090 --> 00:20:38,640
you and that's so you can make it costly

00:20:35,970 --> 00:20:42,630
consistent because in a distributed

00:20:38,640 --> 00:20:45,120
system normally you can't rely on on the

00:20:42,630 --> 00:20:47,490
clocks being super nice so time is not a

00:20:45,120 --> 00:20:49,860
good notion for for keeping track of how

00:20:47,490 --> 00:20:51,750
things have happened so by always having

00:20:49,860 --> 00:20:53,760
the parent ID you can point back to the

00:20:51,750 --> 00:20:56,160
parent ID and then the analyzers can

00:20:53,760 --> 00:21:00,060
extract this information and based on

00:20:56,160 --> 00:21:03,090
the ideas IDs creates metrics and and

00:21:00,060 --> 00:21:05,700
get an understanding on something we

00:21:03,090 --> 00:21:07,800
also add things like host and and time

00:21:05,700 --> 00:21:09,810
on that server the type that has

00:21:07,800 --> 00:21:12,000
happened this this is a received type it

00:21:09,810 --> 00:21:14,250
has received a message and also we add

00:21:12,000 --> 00:21:20,280
like we added information about what

00:21:14,250 --> 00:21:22,950
actor it was so on so and in like been

00:21:20,280 --> 00:21:26,880
monitoring we've decided not to rely as

00:21:22,950 --> 00:21:30,300
much on this type of dedapper

00:21:26,880 --> 00:21:32,370
infrastructure and the reason being as I

00:21:30,300 --> 00:21:35,100
will show you later it's there there are

00:21:32,370 --> 00:21:36,690
some costs associated with doing this so

00:21:35,100 --> 00:21:39,950
instead of like that monitoring we're

00:21:36,690 --> 00:21:42,990
we're actually in each application we're

00:21:39,950 --> 00:21:45,600
we're calculating the metrics and the

00:21:42,990 --> 00:21:48,390
events in that application and then we

00:21:45,600 --> 00:21:51,270
offload that to some other systems I

00:21:48,390 --> 00:21:53,850
like to keep eat where we also have like

00:21:51,270 --> 00:21:57,210
a stats D plug-in or you can log with

00:21:53,850 --> 00:22:02,640
console s lafurgey or JMX we have the

00:21:57,210 --> 00:22:04,440
lot of plugins they can use so the

00:22:02,640 --> 00:22:08,460
associated cost with logging all of

00:22:04,440 --> 00:22:10,710
these events each if we're talking about

00:22:08,460 --> 00:22:12,529
an application for example

00:22:10,710 --> 00:22:14,970
application has its own set of

00:22:12,529 --> 00:22:16,679
characteristics so what do you think

00:22:14,970 --> 00:22:18,750
which application is more costly to

00:22:16,679 --> 00:22:20,520
monitor an application with a few actors

00:22:18,750 --> 00:22:22,020
and lots of business logic or an

00:22:20,520 --> 00:22:24,779
application with several temporary

00:22:22,020 --> 00:22:27,390
short-lived actors it's the latter right

00:22:24,779 --> 00:22:30,450
because the the latter will generate a

00:22:27,390 --> 00:22:32,130
lot of more events and for each event

00:22:30,450 --> 00:22:34,830
you create there's going to be a cost

00:22:32,130 --> 00:22:37,350
associated and this is the reason why

00:22:34,830 --> 00:22:39,630
it's very hard to predict the

00:22:37,350 --> 00:22:42,360
performance overhead in monitoring of a

00:22:39,630 --> 00:22:44,100
distributed system because you know some

00:22:42,360 --> 00:22:45,690
some people generate millions and

00:22:44,100 --> 00:22:48,990
millions of actors whereas others only

00:22:45,690 --> 00:22:51,360
have ten actors and it doesn't and may

00:22:48,990 --> 00:22:53,730
be long-lived message or a lot of

00:22:51,360 --> 00:22:55,890
business logic so it's very hard to

00:22:53,730 --> 00:22:58,230
predict what they perform as overheads

00:22:55,890 --> 00:22:59,279
it's gonna be okay so there is an

00:22:58,230 --> 00:23:02,070
Associated cost

00:22:59,279 --> 00:23:04,799
how can you mitigate this cost well you

00:23:02,070 --> 00:23:06,870
can have flexible configuration which

00:23:04,799 --> 00:23:08,399
basically allows you to decide what

00:23:06,870 --> 00:23:10,380
parts of your system you want to monitor

00:23:08,399 --> 00:23:12,299
now if you created a lot of temporary

00:23:10,380 --> 00:23:14,429
actors in the actor system then maybe

00:23:12,299 --> 00:23:16,289
you don't want to monitor those and get

00:23:14,429 --> 00:23:17,760
insight into those because you know the

00:23:16,289 --> 00:23:20,220
overhead of doing that it's going to be

00:23:17,760 --> 00:23:21,899
too high so therefore you can buy

00:23:20,220 --> 00:23:23,460
configuration define okay I'm not

00:23:21,899 --> 00:23:25,909
interested in this part I'm only going

00:23:23,460 --> 00:23:28,830
to monitor this part of my actor system

00:23:25,909 --> 00:23:31,919
another way to do it is by sampling

00:23:28,830 --> 00:23:35,240
adding sampling so you for example only

00:23:31,919 --> 00:23:38,220
trace or monitor every thousand or enth

00:23:35,240 --> 00:23:40,200
message through the system so that's

00:23:38,220 --> 00:23:41,940
also a capability that you can add to

00:23:40,200 --> 00:23:43,470
your system and finally you can also use

00:23:41,940 --> 00:23:45,120
something called Delta approach with

00:23:43,470 --> 00:23:47,820
which basically means that you're only

00:23:45,120 --> 00:23:49,470
sending the differences so if there is

00:23:47,820 --> 00:23:53,610
no difference in your system you won't

00:23:49,470 --> 00:23:55,529
send any data to the backend now each of

00:23:53,610 --> 00:23:57,149
these custom aggregations has its own

00:23:55,529 --> 00:23:59,610
drawbacks of course you can decide

00:23:57,149 --> 00:24:01,649
between less insight or higher

00:23:59,610 --> 00:24:03,659
complexity so when it comes to

00:24:01,649 --> 00:24:06,570
monitoring there's no such thing as free

00:24:03,659 --> 00:24:10,399
a free lunch you you you you have to pay

00:24:06,570 --> 00:24:10,399
something for adding monitoring

00:24:12,050 --> 00:24:17,000
so in our current solution we have

00:24:17,570 --> 00:24:30,270
configuration exclude so you can

00:24:26,970 --> 00:24:32,070
configure how you want to monitor as you

00:24:30,270 --> 00:24:34,200
mentioned it's really important those of

00:24:32,070 --> 00:24:37,050
you know me I love event sourcing but

00:24:34,200 --> 00:24:38,430
the reality of it is is as Henrik had

00:24:37,050 --> 00:24:41,850
mentioned if you have five million

00:24:38,430 --> 00:24:44,580
actors you just it's too much data right

00:24:41,850 --> 00:24:45,870
it's it's like tenfold wasn't it and

00:24:44,580 --> 00:24:47,940
that's that was one of the problems we

00:24:45,870 --> 00:24:49,740
had with console in production is

00:24:47,940 --> 00:24:53,160
everybody wants to turn everything on

00:24:49,740 --> 00:24:54,720
and the whole system comes down you know

00:24:53,160 --> 00:24:55,920
you having a problem with your system

00:24:54,720 --> 00:24:59,460
you plug in monitoring and then it

00:24:55,920 --> 00:25:01,920
crashes that's not too helpful yeah and

00:24:59,460 --> 00:25:04,350
you need three times the hardware to run

00:25:01,920 --> 00:25:06,870
monitoring yeah exactly so it's really

00:25:04,350 --> 00:25:10,770
it's a tough it's a tough problem to

00:25:06,870 --> 00:25:12,450
solve because you know the customer

00:25:10,770 --> 00:25:14,160
monitoring is not something that they

00:25:12,450 --> 00:25:17,370
want to have to master it's it's like a

00:25:14,160 --> 00:25:19,620
tool they want to be able to use so but

00:25:17,370 --> 00:25:22,230
we have different ways of handling it we

00:25:19,620 --> 00:25:23,700
have a class path law court Karthik it's

00:25:22,230 --> 00:25:28,650
such a grouping you can group your

00:25:23,700 --> 00:25:30,810
actors together and so forth and we have

00:25:28,650 --> 00:25:32,670
the beginnings of dynamic configuration

00:25:30,810 --> 00:25:36,570
in the sense that you can have these

00:25:32,670 --> 00:25:39,180
group templates where every actor that

00:25:36,570 --> 00:25:42,810
resides under II question mark will have

00:25:39,180 --> 00:25:46,080
its own group which is pretty nice and

00:25:42,810 --> 00:25:51,750
so forth so that happens dynamically and

00:25:46,080 --> 00:25:54,780
then what wouldn't it be nice however

00:25:51,750 --> 00:25:58,380
though if the entire configuration could

00:25:54,780 --> 00:26:03,180
be dynamic right you know type safe

00:25:58,380 --> 00:26:06,210
config is immutable we just had this

00:26:03,180 --> 00:26:09,780
discussion yesterday but we're working

00:26:06,210 --> 00:26:11,250
on dynamic injection of configuration if

00:26:09,780 --> 00:26:13,080
you will it's something that we've been

00:26:11,250 --> 00:26:15,720
talking about and how we want to do it

00:26:13,080 --> 00:26:18,110
so the idea is is as your system is

00:26:15,720 --> 00:26:21,420
occurring and you begin to notice

00:26:18,110 --> 00:26:24,390
problems you can dynamically change how

00:26:21,420 --> 00:26:25,740
things are monitored and this is this

00:26:24,390 --> 00:26:28,230
will have a big impact

00:26:25,740 --> 00:26:30,750
example not code but you know kind of

00:26:28,230 --> 00:26:34,350
philosophically so the idea is having

00:26:30,750 --> 00:26:38,309
dynamically typed properties so you you

00:26:34,350 --> 00:26:41,570
catch things on on compile time pull or

00:26:38,309 --> 00:26:44,670
push based subscription property changes

00:26:41,570 --> 00:26:46,980
event based triggers you know that this

00:26:44,670 --> 00:26:48,690
stuff is not new so people can be aware

00:26:46,980 --> 00:26:51,240
that a property has been changed

00:26:48,690 --> 00:26:53,550
whenever you're changing properties you

00:26:51,240 --> 00:26:55,110
know there's a value of state there so

00:26:53,550 --> 00:26:58,590
you have to have conflict resolution

00:26:55,110 --> 00:27:01,260
because you have asynchronous potential

00:26:58,590 --> 00:27:03,660
changes to the property reloading for

00:27:01,260 --> 00:27:06,780
subscribers that may not support Delta

00:27:03,660 --> 00:27:09,000
changes so kind of giving them ability

00:27:06,780 --> 00:27:12,240
to restructure themselves based on the

00:27:09,000 --> 00:27:19,410
new configuration and then wrappers for

00:27:12,240 --> 00:27:22,080
more common things like URLs etc yeah so

00:27:19,410 --> 00:27:23,940
one of the interesting things that's

00:27:22,080 --> 00:27:25,800
happening in monitoring now is like it's

00:27:23,940 --> 00:27:27,990
the division is split between push

00:27:25,800 --> 00:27:29,610
monitoring and pulmonic drink so I'm

00:27:27,990 --> 00:27:32,400
gonna talk a little bit about that now

00:27:29,610 --> 00:27:34,800
what is what is pool monitoring well

00:27:32,400 --> 00:27:37,080
that's winter monitoring system actually

00:27:34,800 --> 00:27:40,080
calls out to the monitored application

00:27:37,080 --> 00:27:42,870
and and instructs what data it wants

00:27:40,080 --> 00:27:45,270
back and push being of course the

00:27:42,870 --> 00:27:47,400
reverse where the Montreat monitor

00:27:45,270 --> 00:27:51,059
applications push data to the monitoring

00:27:47,400 --> 00:27:53,309
system okay and then you have the

00:27:51,059 --> 00:27:56,179
discoverability of the system so one is

00:27:53,309 --> 00:27:58,830
where the monitored application

00:27:56,179 --> 00:28:01,770
registers with some service

00:27:58,830 --> 00:28:05,610
discoverability tool like console or

00:28:01,770 --> 00:28:08,670
zookeeper the other one being where you

00:28:05,610 --> 00:28:13,230
have a cluster scheduled as good dealer

00:28:08,670 --> 00:28:14,850
that actually instructs applications or

00:28:13,230 --> 00:28:17,100
you know actually smooths the

00:28:14,850 --> 00:28:18,330
applications and then that keeps track

00:28:17,100 --> 00:28:20,190
of where the applications are that

00:28:18,330 --> 00:28:22,200
should be monitored and then the

00:28:20,190 --> 00:28:25,130
monetary system would then call in to

00:28:22,200 --> 00:28:31,470
either of these two to find out what

00:28:25,130 --> 00:28:33,300
what status of your system there is so

00:28:31,470 --> 00:28:35,700
if we put this together and look at the

00:28:33,300 --> 00:28:38,160
pull scenario where you have an

00:28:35,700 --> 00:28:38,870
application that fails well that's not

00:28:38,160 --> 00:28:41,510
really respond

00:28:38,870 --> 00:28:44,240
for the pool case right so the monitor

00:28:41,510 --> 00:28:46,190
system knows that what what application

00:28:44,240 --> 00:28:48,230
it should monitor based on calling in

00:28:46,190 --> 00:28:51,260
tsuki Peru console or your cluster

00:28:48,230 --> 00:28:53,210
schedule and and then it's is trying to

00:28:51,260 --> 00:28:55,850
pull the information from that

00:28:53,210 --> 00:28:58,100
application it doesn't respond now of

00:28:55,850 --> 00:28:59,810
course it knows that it should send an

00:28:58,100 --> 00:29:03,710
alarm about this there's something wrong

00:28:59,810 --> 00:29:06,140
clearly right and the push scenario it's

00:29:03,710 --> 00:29:07,820
a little bit different you can you can

00:29:06,140 --> 00:29:10,010
do the same thing the monitoring system

00:29:07,820 --> 00:29:12,230
knows what what it should expect but it

00:29:10,010 --> 00:29:14,180
doesn't receive any data from one of the

00:29:12,230 --> 00:29:16,910
applications it only receives from from

00:29:14,180 --> 00:29:19,520
two of these three in this scenario you

00:29:16,910 --> 00:29:22,970
also have to instruct the monitoring

00:29:19,520 --> 00:29:25,700
system to have a scheduler to to check

00:29:22,970 --> 00:29:27,860
for have I received any data from all my

00:29:25,700 --> 00:29:29,420
all my notes that I'm expecting so it's

00:29:27,860 --> 00:29:31,730
a little bit you can do the same thing

00:29:29,420 --> 00:29:33,260
but it's a little bit more complex on

00:29:31,730 --> 00:29:40,670
the pull side you actually get this for

00:29:33,260 --> 00:29:43,970
free ok so finally pull push the

00:29:40,670 --> 00:29:47,660
difference it's really what data volumes

00:29:43,970 --> 00:29:49,790
in detail end up in the push scenario if

00:29:47,660 --> 00:29:51,380
you want to send old information you

00:29:49,790 --> 00:29:53,260
have to send all that information and

00:29:51,380 --> 00:29:56,150
you could just you know if you have

00:29:53,260 --> 00:29:59,030
thousands of nodes then that could

00:29:56,150 --> 00:30:03,140
easily cost a monitoring system to just

00:29:59,030 --> 00:30:05,570
fall over in the pool scenario you can

00:30:03,140 --> 00:30:09,050
decide the de monitoring system can

00:30:05,570 --> 00:30:11,090
decide what information to to gather and

00:30:09,050 --> 00:30:13,250
it could be that it's just querying for

00:30:11,090 --> 00:30:15,530
the over you know the the basic

00:30:13,250 --> 00:30:18,500
information like number of actors

00:30:15,530 --> 00:30:22,040
running or some other throughput latency

00:30:18,500 --> 00:30:24,500
you would have you and in the case of

00:30:22,040 --> 00:30:26,510
there's there's being a problem

00:30:24,500 --> 00:30:29,840
somewhere then the monitoring system can

00:30:26,510 --> 00:30:32,720
decide to pull more information by just

00:30:29,840 --> 00:30:35,750
having a simple query so this is really

00:30:32,720 --> 00:30:37,700
powerful it actually gives you a better

00:30:35,750 --> 00:30:40,400
sense of control you can do you can do

00:30:37,700 --> 00:30:43,400
this the same thing with both pull push

00:30:40,400 --> 00:30:45,740
and pull but pull gives you more for

00:30:43,400 --> 00:30:47,380
free I would say so one of the one of

00:30:45,740 --> 00:30:49,430
the trending

00:30:47,380 --> 00:30:52,450
implementations of apple-based systems

00:30:49,430 --> 00:30:56,060
right now is prometheus that was

00:30:52,450 --> 00:30:57,980
implemented by soundcloud and the other

00:30:56,060 --> 00:31:00,320
one of course being stats data's like

00:30:57,980 --> 00:31:05,720
the Wanda's being most used where you

00:31:00,320 --> 00:31:08,350
push data and and then you know your

00:31:05,720 --> 00:31:11,030
back-end will have to handle that

00:31:08,350 --> 00:31:13,400
another trend in monitoring is an

00:31:11,030 --> 00:31:15,650
anomaly detection and anomaly detection

00:31:13,400 --> 00:31:17,930
is a set of techniques and systems to

00:31:15,650 --> 00:31:21,490
find unusual behavior and or States and

00:31:17,930 --> 00:31:26,330
sisters and their observable signals and

00:31:21,490 --> 00:31:29,390
as I said before thresholds for metrics

00:31:26,330 --> 00:31:31,250
when it did they're too crude it base it

00:31:29,390 --> 00:31:33,320
basically means if you set thresholds

00:31:31,250 --> 00:31:35,450
for alarms and you know when you want

00:31:33,320 --> 00:31:38,030
something to be alerted you want to

00:31:35,450 --> 00:31:40,330
notify your dev ops team it's very hard

00:31:38,030 --> 00:31:42,830
to know what those thresholds should be

00:31:40,330 --> 00:31:45,080
should you let the dev ops team set that

00:31:42,830 --> 00:31:47,600
because they know about the you know how

00:31:45,080 --> 00:31:49,310
you deploy your system or should the

00:31:47,600 --> 00:31:51,410
development team set that because they

00:31:49,310 --> 00:31:53,870
know how they develop the system it's

00:31:51,410 --> 00:31:56,300
very hard to connect this threshold and

00:31:53,870 --> 00:31:58,760
and if you set it wrong you get either

00:31:56,300 --> 00:32:01,640
too much alerting where you get too

00:31:58,760 --> 00:32:03,700
little so it's very hard and by using

00:32:01,640 --> 00:32:06,290
anomaly detection you can actually get

00:32:03,700 --> 00:32:09,290
you you lessen the need to calibrate

00:32:06,290 --> 00:32:11,660
thresholds basically there's a

00:32:09,290 --> 00:32:14,360
misconception and basically that says

00:32:11,660 --> 00:32:18,200
that anomalies anomalies are not

00:32:14,360 --> 00:32:21,530
outliers which which are not equals to

00:32:18,200 --> 00:32:23,420
equal to outliers I should say you know

00:32:21,530 --> 00:32:25,400
if you look at your graph which is how

00:32:23,420 --> 00:32:26,780
you do it today is like you have dev ops

00:32:25,400 --> 00:32:29,120
team looking at graphs and there's a

00:32:26,780 --> 00:32:31,580
spike somewhere now this could this

00:32:29,120 --> 00:32:33,620
could be perfectly fine you have to

00:32:31,580 --> 00:32:35,270
correlate that with other things if

00:32:33,620 --> 00:32:38,360
there's a garbage collection going on

00:32:35,270 --> 00:32:39,680
then you know it could be that this bike

00:32:38,360 --> 00:32:41,600
it correlates with that garbage

00:32:39,680 --> 00:32:43,610
collection and of course that's going to

00:32:41,600 --> 00:32:45,560
happen so it doesn't really mean that

00:32:43,610 --> 00:32:48,970
because there's an outlier there's a

00:32:45,560 --> 00:32:51,530
problem but normally when you have

00:32:48,970 --> 00:32:56,210
anomalies they are outliers but not all

00:32:51,530 --> 00:32:59,670
outliers are anomalies so might by using

00:32:56,210 --> 00:33:02,580
anomaly detection you can read

00:32:59,670 --> 00:33:05,280
the surface area you get this automated

00:33:02,580 --> 00:33:06,810
this you know anomaly detection is

00:33:05,280 --> 00:33:08,190
automating a lot of things instead of

00:33:06,810 --> 00:33:09,720
you having a hundred graphs that you

00:33:08,190 --> 00:33:11,460
look at and trying to figure out what's

00:33:09,720 --> 00:33:14,130
going on in your sister you can automate

00:33:11,460 --> 00:33:17,040
that so it's it's a very very good

00:33:14,130 --> 00:33:19,080
effective way of doing things so example

00:33:17,040 --> 00:33:24,750
providers for this is vivid cortex or

00:33:19,080 --> 00:33:28,020
ROC Saito app dynamics yeah the the

00:33:24,750 --> 00:33:31,650
anomaly detection is really an

00:33:28,020 --> 00:33:33,210
interesting area because as anybody

00:33:31,650 --> 00:33:34,560
who's worked in industries where you're

00:33:33,210 --> 00:33:36,890
measuring stuff like that

00:33:34,560 --> 00:33:40,590
I'm from the energy industry originally

00:33:36,890 --> 00:33:42,960
outliers are really they can really

00:33:40,590 --> 00:33:45,120
throw you off so having some type of

00:33:42,960 --> 00:33:46,980
algorithms that understand how the

00:33:45,120 --> 00:33:49,500
system is supposed to work and smooth

00:33:46,980 --> 00:33:52,290
the results to determine whether or not

00:33:49,500 --> 00:33:54,540
it is truly a problem is very very

00:33:52,290 --> 00:33:57,810
important and monitoring is going in

00:33:54,540 --> 00:33:59,490
that direction more towards behavioral

00:33:57,810 --> 00:34:00,990
one of the things that we've been

00:33:59,490 --> 00:34:02,700
talking about here is the idea of self

00:34:00,990 --> 00:34:04,470
monitoring trying to look at the way the

00:34:02,700 --> 00:34:06,510
real world works and potentially takes

00:34:04,470 --> 00:34:10,679
some of those concepts and bring them

00:34:06,510 --> 00:34:12,720
into our world so in a real world I have

00:34:10,679 --> 00:34:14,159
this picture of a doctor here imagine if

00:34:12,720 --> 00:34:15,810
you had a doctor assigned to you that

00:34:14,159 --> 00:34:17,640
constantly walked around all the time

00:34:15,810 --> 00:34:19,679
checking your vitals making sure you're

00:34:17,640 --> 00:34:21,300
okay you went with you to the bathroom

00:34:19,679 --> 00:34:23,669
you went with you when you went to bed

00:34:21,300 --> 00:34:25,980
everywhere you go okay so what does that

00:34:23,669 --> 00:34:27,720
bring us well very quick detection of

00:34:25,980 --> 00:34:29,310
problems that's pretty obvious right you

00:34:27,720 --> 00:34:31,919
did know really well assuming he's

00:34:29,310 --> 00:34:34,290
competent or she was a quick resolution

00:34:31,919 --> 00:34:36,540
hopefully right this this earlier you

00:34:34,290 --> 00:34:39,270
find the problem there you're aware of

00:34:36,540 --> 00:34:41,790
it but there's another problem he's

00:34:39,270 --> 00:34:43,590
totally focused or she's totally focused

00:34:41,790 --> 00:34:45,720
on you so it's a vast waste of a

00:34:43,590 --> 00:34:48,590
resource resources it takes a long time

00:34:45,720 --> 00:34:51,060
to get an MD right seven years I think

00:34:48,590 --> 00:34:52,950
and it can be very expensive I don't

00:34:51,060 --> 00:34:54,659
know about you but I know one of my

00:34:52,950 --> 00:34:57,420
friends is a doctor and he makes quite a

00:34:54,659 --> 00:35:00,090
bit of money so it can be very very

00:34:57,420 --> 00:35:02,790
expensive so this kind of monitoring is

00:35:00,090 --> 00:35:05,010
what a lot of monitoring systems do

00:35:02,790 --> 00:35:08,910
today and we're starting to see a change

00:35:05,010 --> 00:35:11,829
there's a lot of effort focused on you

00:35:08,910 --> 00:35:16,790
know kind of like outside in view

00:35:11,829 --> 00:35:17,869
oops wrong way but what would happen if

00:35:16,790 --> 00:35:21,500
we could do something a little bit

00:35:17,869 --> 00:35:23,119
different right so here a it could be an

00:35:21,500 --> 00:35:26,060
actor it could be a group of actors

00:35:23,119 --> 00:35:28,400
right I don't know how old the feedback

00:35:26,060 --> 00:35:31,250
loop control is it's gonna be at least

00:35:28,400 --> 00:35:36,200
fifty or sixty years old but the idea

00:35:31,250 --> 00:35:40,040
here is is a feedback loop okay so you

00:35:36,200 --> 00:35:44,720
have this actor and a disturbance and

00:35:40,040 --> 00:35:46,910
the force is detected right the actor or

00:35:44,720 --> 00:35:48,460
the system group of actors has these

00:35:46,910 --> 00:35:51,849
rules that they're going to follow and

00:35:48,460 --> 00:35:54,680
they're going to project a measurement

00:35:51,849 --> 00:35:56,780
push this is where push and pull work

00:35:54,680 --> 00:36:00,950
together they would push a measurement

00:35:56,780 --> 00:36:02,630
to the rule engine or whatever it is it

00:36:00,950 --> 00:36:03,530
could be internal to the actor of the

00:36:02,630 --> 00:36:05,000
system itself

00:36:03,530 --> 00:36:06,829
they're just broke apart here on the

00:36:05,000 --> 00:36:09,440
diagram so you can see it and a

00:36:06,829 --> 00:36:11,839
thermostat it's all contained within but

00:36:09,440 --> 00:36:14,589
we also have distributed feedback loops

00:36:11,839 --> 00:36:16,670
to it's going to make an adjustment

00:36:14,589 --> 00:36:18,260
adjustment and then based on the rules

00:36:16,670 --> 00:36:20,630
and they send another measurement and

00:36:18,260 --> 00:36:23,990
it's going to continue to do this it's

00:36:20,630 --> 00:36:25,240
going to self repair itself until it's

00:36:23,990 --> 00:36:29,390
back to normal

00:36:25,240 --> 00:36:31,280
and the disturbance has been handled now

00:36:29,390 --> 00:36:34,069
the result of that may be spinning up

00:36:31,280 --> 00:36:37,940
other actors there who knows in in the

00:36:34,069 --> 00:36:40,280
sense of an akka scenario however the

00:36:37,940 --> 00:36:44,089
concept the philosophy is something

00:36:40,280 --> 00:36:45,920
that's very valid and very very useful

00:36:44,089 --> 00:36:48,260
it works very well in mechanical

00:36:45,920 --> 00:36:51,140
engineering especially with these types

00:36:48,260 --> 00:36:55,010
of devices so actors and and distributed

00:36:51,140 --> 00:36:56,930
systems we're exploring this idea to see

00:36:55,010 --> 00:37:03,230
how we can use it inside of our

00:36:56,930 --> 00:37:04,609
monitoring solution so we're getting

00:37:03,230 --> 00:37:07,910
close to finishing here some of the best

00:37:04,609 --> 00:37:11,240
practices number one is the most

00:37:07,910 --> 00:37:15,950
important practice of monitoring the

00:37:11,240 --> 00:37:17,990
number one know your own system okay if

00:37:15,950 --> 00:37:21,319
you don't know your own system if you

00:37:17,990 --> 00:37:23,119
don't know the field then there's no way

00:37:21,319 --> 00:37:24,440
you can be aware of what's going on it

00:37:23,119 --> 00:37:25,250
doesn't matter how much you know about

00:37:24,440 --> 00:37:27,530
monitor

00:37:25,250 --> 00:37:29,300
you have to understand your own system

00:37:27,530 --> 00:37:31,180
that's the number one most important

00:37:29,300 --> 00:37:34,550
thing and then the second one is

00:37:31,180 --> 00:37:39,380
understand your monitoring tool and read

00:37:34,550 --> 00:37:41,720
the manual read the manual you look

00:37:39,380 --> 00:37:43,670
really you do you have to understand the

00:37:41,720 --> 00:37:46,940
tool itself and what its capabilities

00:37:43,670 --> 00:37:50,540
are so those are the two most important

00:37:46,940 --> 00:37:53,270
things the next one would be your tool

00:37:50,540 --> 00:37:55,880
that you pick should be configurable and

00:37:53,270 --> 00:37:58,310
it should the vision that the the the

00:37:55,880 --> 00:37:59,930
tool maker has should be looking towards

00:37:58,310 --> 00:38:02,839
the future which is kind of like

00:37:59,930 --> 00:38:06,980
behavioral analysis of the system and

00:38:02,839 --> 00:38:09,349
and and composable fan up data or views

00:38:06,980 --> 00:38:12,079
of how your systems are behaving and

00:38:09,349 --> 00:38:15,770
acting and it should be elastic

00:38:12,079 --> 00:38:17,000
obviously deltas are important right the

00:38:15,770 --> 00:38:19,849
elk approach where you're logging

00:38:17,000 --> 00:38:23,660
everything it just it's too costly so

00:38:19,849 --> 00:38:24,440
capturing Delta information is a very

00:38:23,660 --> 00:38:27,500
good way to do it

00:38:24,440 --> 00:38:29,150
sampling reasoning through trends seeing

00:38:27,500 --> 00:38:32,060
how your system works those types of

00:38:29,150 --> 00:38:33,349
things are very important too the other

00:38:32,060 --> 00:38:36,050
thing is you need to capture enough

00:38:33,349 --> 00:38:37,730
information so it's relevant okay and

00:38:36,050 --> 00:38:39,530
that may take some tuning right

00:38:37,730 --> 00:38:42,290
everybody what are the perfect settings

00:38:39,530 --> 00:38:44,210
for AK on the JVM I don't know what are

00:38:42,290 --> 00:38:46,849
you doing you know do you have a high

00:38:44,210 --> 00:38:48,020
i/o you know that's the question I just

00:38:46,849 --> 00:38:49,849
want you to give it to me it's

00:38:48,020 --> 00:38:51,319
impossible I don't know your system you

00:38:49,849 --> 00:38:53,660
have to tune your system I have to work

00:38:51,319 --> 00:38:58,250
with it and see what information is

00:38:53,660 --> 00:38:59,480
relevant and important then you want to

00:38:58,250 --> 00:39:01,490
provide multiple channels of

00:38:59,480 --> 00:39:05,740
notification you know whatever they may

00:39:01,490 --> 00:39:09,650
be am at our SMS Email you know big red

00:39:05,740 --> 00:39:11,660
flag on the screen the other thing is

00:39:09,650 --> 00:39:14,869
what I thought was interesting was

00:39:11,660 --> 00:39:17,960
reports for your DevOps folks that's uh

00:39:14,869 --> 00:39:19,280
I think not just useful for them in the

00:39:17,960 --> 00:39:21,650
moment but it gives you like a

00:39:19,280 --> 00:39:23,210
historical analysis and kind of gives

00:39:21,650 --> 00:39:26,000
upper level management at the comfort

00:39:23,210 --> 00:39:27,619
level and then the other thing is

00:39:26,000 --> 00:39:30,800
running your monitoring system on a

00:39:27,619 --> 00:39:32,119
different machine ultimately is because

00:39:30,800 --> 00:39:35,000
you don't want it to eat up all the

00:39:32,119 --> 00:39:37,140
resources that you have your application

00:39:35,000 --> 00:39:40,780
running on

00:39:37,140 --> 00:39:42,820
okay so just real quick about the like

00:39:40,780 --> 00:39:45,130
been monitoring offering it's a project

00:39:42,820 --> 00:39:47,740
that we've been running for about a year

00:39:45,130 --> 00:39:50,170
right now we integrate with actors and

00:39:47,740 --> 00:39:51,910
logon circuit breakers we generate

00:39:50,170 --> 00:39:54,250
metrics events and traces based on that

00:39:51,910 --> 00:39:55,750
and we have support for various backends

00:39:54,250 --> 00:39:58,060
likes nets need to keep e and

00:39:55,750 --> 00:40:00,460
miscellaneous other coda Hill reporters

00:39:58,060 --> 00:40:02,710
so you can report to whatever back in

00:40:00,460 --> 00:40:05,470
yours the monitoring requires a

00:40:02,710 --> 00:40:10,870
subscription with us so it's not for

00:40:05,470 --> 00:40:12,490
free what will we be focus on next we're

00:40:10,870 --> 00:40:15,060
gonna focus on something we call flows

00:40:12,490 --> 00:40:17,770
which is basically future streams

00:40:15,060 --> 00:40:20,850
distributed tracing and also we're gonna

00:40:17,770 --> 00:40:22,840
support native Prometheus support so we

00:40:20,850 --> 00:40:24,550
automated we have this native support

00:40:22,840 --> 00:40:26,380
for pool based monitoring which we think

00:40:24,550 --> 00:40:30,850
is really important and of course

00:40:26,380 --> 00:40:33,940
increase log M support and a key HTTP so

00:40:30,850 --> 00:40:36,100
that's it I think we don't have time for

00:40:33,940 --> 00:40:37,750
any questions but feel free to come by

00:40:36,100 --> 00:40:42,330
booth Duncan and I will be at the booth

00:40:37,750 --> 00:40:42,330

YouTube URL: https://www.youtube.com/watch?v=eS5KkK5agvk


