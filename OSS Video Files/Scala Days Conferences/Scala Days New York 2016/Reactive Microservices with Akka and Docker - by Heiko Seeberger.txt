Title: Reactive Microservices with Akka and Docker - by Heiko Seeberger
Publication date: 2016-06-17
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.

Abstract:
Akka is a toolkit for building elastic and resilient distributed systems and Docker makes shipping and running those distributed systems easy as never before. In this talk we will briefly introduce you to the basics of Akka and Docker and then show how you can use these innovative technologies to build and run really Reactive micorservices. Donâ€™t expect too many slides, but be prepared for live demos.
Captions: 
	00:00:00,060 --> 00:00:06,029
it's pretty amazing to see so many of

00:00:02,070 --> 00:00:08,790
you my name is Michael I have been

00:00:06,029 --> 00:00:11,040
bending sunlight for a couple of years

00:00:08,790 --> 00:00:14,670
now I work for a return consultancy

00:00:11,040 --> 00:00:19,109
called concentric from scarlet lousiest

00:00:14,670 --> 00:00:21,289
and I cut fanboy and I'm the author a

00:00:19,109 --> 00:00:24,060
couple of mostly baka related

00:00:21,289 --> 00:00:27,410
open-source libraries I guess that's the

00:00:24,060 --> 00:00:31,830
reason why I'm here when I thought about

00:00:27,410 --> 00:00:34,860
the proposal post conference I happen to

00:00:31,830 --> 00:00:39,980
dear putting as many buzzwords into its

00:00:34,860 --> 00:00:42,870
short title as possible so here we are

00:00:39,980 --> 00:00:44,700
talking about reactive micro services

00:00:42,870 --> 00:00:51,059
with our kind docker at least for

00:00:44,700 --> 00:00:57,210
buzzwords so what is reactive who knows

00:00:51,059 --> 00:01:02,789
the reactive manifesto so I'm glad I

00:00:57,210 --> 00:01:05,159
have this I have this slide the reactive

00:01:02,789 --> 00:01:10,320
manifest who tries to be fine of a

00:01:05,159 --> 00:01:14,970
Cavallari or go to modern crucial

00:01:10,320 --> 00:01:18,420
whatsoever applications and the main

00:01:14,970 --> 00:01:20,700
trait the main goal of that of a

00:01:18,420 --> 00:01:23,009
reactive system which is described in

00:01:20,700 --> 00:01:25,560
the manifesto is responsive which means

00:01:23,009 --> 00:01:29,820
the system should respond in a timely

00:01:25,560 --> 00:01:33,210
manner under all circumstances if

00:01:29,820 --> 00:01:35,220
possible at all and there are two main

00:01:33,210 --> 00:01:38,400
traits which enable responsiveness

00:01:35,220 --> 00:01:40,680
that's elastic and resilient elastic

00:01:38,400 --> 00:01:44,420
means to stay responsive on the very

00:01:40,680 --> 00:01:48,659
workload and resilient means to remain

00:01:44,420 --> 00:01:51,210
responsive in the face of failure okay

00:01:48,659 --> 00:01:55,729
and the fourth trait which is

00:01:51,210 --> 00:01:59,610
subscribemessage driven is that meanings

00:01:55,729 --> 00:02:03,240
a possibility how to implement those

00:01:59,610 --> 00:02:08,600
other traits direct manifest has been

00:02:03,240 --> 00:02:10,880
written by different people

00:02:08,600 --> 00:02:14,630
it has been assigned by more than 10,000

00:02:10,880 --> 00:02:18,130
I think but some say it's a yucca

00:02:14,630 --> 00:02:21,020
manifesto because it's a perfect fit

00:02:18,130 --> 00:02:23,930
so I highly recommend reading it it's

00:02:21,020 --> 00:02:27,980
not long as five minutes read and after

00:02:23,930 --> 00:02:29,510
that you already have this vocabulary so

00:02:27,980 --> 00:02:31,550
what's the microservice I don't want to

00:02:29,510 --> 00:02:33,680
bore you that's a very quick definition

00:02:31,550 --> 00:02:36,260
for me and Microsoft is something that

00:02:33,680 --> 00:02:39,800
does one thing it does well it's jumex

00:02:36,260 --> 00:02:45,830
philosophy all right and it has to act

00:02:39,800 --> 00:02:47,120
autonomously so it has to be able even

00:02:45,830 --> 00:02:50,510
if it is collaborating with other

00:02:47,120 --> 00:02:53,060
services to work if those services are

00:02:50,510 --> 00:02:57,170
not available which means it has to own

00:02:53,060 --> 00:02:58,970
its own data questioners how does it get

00:02:57,170 --> 00:03:02,090
the data it needs from the other

00:02:58,970 --> 00:03:05,480
services talk about that later

00:03:02,090 --> 00:03:09,290
for me the size does not matter at least

00:03:05,480 --> 00:03:16,270
not size in terms of disk he CPU et

00:03:09,290 --> 00:03:19,550
cetera so reactive Microsoft says great

00:03:16,270 --> 00:03:24,050
of course I already made Micah's need to

00:03:19,550 --> 00:03:29,240
collaborate and I have taken the sewing

00:03:24,050 --> 00:03:33,170
quote from that book from your desk when

00:03:29,240 --> 00:03:37,880
air I highly recommend not only but also

00:03:33,170 --> 00:03:40,310
because it's short one micro service is

00:03:37,880 --> 00:03:43,010
know Microsoft they come insisting well

00:03:40,310 --> 00:03:48,860
actually this is a quote it has been

00:03:43,010 --> 00:03:51,080
stolen from who knows that call it

00:03:48,860 --> 00:03:54,680
Hewitt one actor is no actor

00:03:51,080 --> 00:03:57,640
they come in systems and that also has

00:03:54,680 --> 00:04:03,050
being spilled from somebody else anyway

00:03:57,640 --> 00:04:05,150
so microphones to collaborate and at

00:04:03,050 --> 00:04:08,510
least for reactive microservices it is

00:04:05,150 --> 00:04:09,970
pretty clear that this collaboration has

00:04:08,510 --> 00:04:14,570
to happen via

00:04:09,970 --> 00:04:18,100
communication a Sukkah knee allows for

00:04:14,570 --> 00:04:22,450
isolation and then enables autonomy okay

00:04:18,100 --> 00:04:27,140
so it would be pretty bad if service a

00:04:22,450 --> 00:04:29,570
call a service beef and wait for the

00:04:27,140 --> 00:04:33,380
response because if that doesn't come it

00:04:29,570 --> 00:04:35,840
comes to affiliates purpose okay so you

00:04:33,380 --> 00:04:38,210
get a decoupling in time to get

00:04:35,840 --> 00:04:42,470
containment of failure which you get

00:04:38,210 --> 00:04:44,600
from a synchrony the sender communicates

00:04:42,470 --> 00:04:48,230
in the fire forget matter it doesn't

00:04:44,600 --> 00:04:51,530
have to wait for response one thing I

00:04:48,230 --> 00:04:55,600
want to stress here is that a microphone

00:04:51,530 --> 00:04:59,630
should nap X another one synchronously

00:04:55,600 --> 00:05:03,050
from an init API and from within its

00:04:59,630 --> 00:05:06,950
request response cycle because that

00:05:03,050 --> 00:05:11,330
breaks economy if the other service is

00:05:06,950 --> 00:05:15,230
down the service is down to cannot

00:05:11,330 --> 00:05:17,750
respond to requests so I will later show

00:05:15,230 --> 00:05:20,270
you how those services could collaborate

00:05:17,750 --> 00:05:25,040
in a better way that does not break

00:05:20,270 --> 00:05:27,260
economy that deep self resiliency so the

00:05:25,040 --> 00:05:29,860
question is how does a can fit well the

00:05:27,260 --> 00:05:32,600
active model is a perfect fit for

00:05:29,860 --> 00:05:34,550
reactive as I already said reactive

00:05:32,600 --> 00:05:38,570
manifesto our company Festo that is

00:05:34,550 --> 00:05:41,570
obvious but apart from that there are

00:05:38,570 --> 00:05:45,560
many high level modules nothing akka

00:05:41,570 --> 00:05:47,810
actor core module but akka cluster tools

00:05:45,560 --> 00:05:50,150
are the Charming's to defend our

00:05:47,810 --> 00:05:55,790
persistence kind of the modules that

00:05:50,150 --> 00:05:58,910
enable you to use a couple of really

00:05:55,790 --> 00:06:03,890
powerful abstractions to implement your

00:05:58,910 --> 00:06:07,870
services and of course akka HTTP which

00:06:03,890 --> 00:06:09,500
has been added to akka just a couple of

00:06:07,870 --> 00:06:11,720
months ago

00:06:09,500 --> 00:06:16,670
it's the successor of the spray project

00:06:11,720 --> 00:06:19,130
and there's also akka SSC that's not

00:06:16,670 --> 00:06:20,740
official akka module that's a library

00:06:19,130 --> 00:06:23,840
which is

00:06:20,740 --> 00:06:25,450
used for server sent events and can be

00:06:23,840 --> 00:06:30,920
used for a sickness event based

00:06:25,450 --> 00:06:33,140
collaboration between services so how

00:06:30,920 --> 00:06:37,490
does the darkest it well I think

00:06:33,140 --> 00:06:39,770
containers provide a very good way to

00:06:37,490 --> 00:06:42,500
isolate your services so instead of

00:06:39,770 --> 00:06:45,170
putting everything into a war or you

00:06:42,500 --> 00:06:47,780
file and deploy more than three years

00:06:45,170 --> 00:06:50,780
into your application server you get

00:06:47,780 --> 00:06:53,540
much better isolation from containers

00:06:50,780 --> 00:06:56,750
and what I really like what containers

00:06:53,540 --> 00:07:00,290
is that they make this lifecycle easier

00:06:56,750 --> 00:07:02,750
with autonomy I not only mean services

00:07:00,290 --> 00:07:05,180
have to work autonomously they also have

00:07:02,750 --> 00:07:07,130
to have an enormous life cycle you want

00:07:05,180 --> 00:07:10,370
to deploy a new version of service a and

00:07:07,130 --> 00:07:13,460
that must just work without affecting

00:07:10,370 --> 00:07:17,150
service B and C right and the containers

00:07:13,460 --> 00:07:21,830
get a lot of infrastructure duties for

00:07:17,150 --> 00:07:24,560
that and docker in the meantime have the

00:07:21,830 --> 00:07:28,310
tools for for infrastructure and

00:07:24,560 --> 00:07:31,580
composition but a cloud for example them

00:07:28,310 --> 00:07:34,430
still in an early stage but I find it

00:07:31,580 --> 00:07:37,460
very nice to work with for example there

00:07:34,430 --> 00:07:39,620
are other tools to Benitez etc and of

00:07:37,460 --> 00:07:44,870
course also I've said conductor which is

00:07:39,620 --> 00:07:46,970
doctor so almost you're not slides I'm

00:07:44,870 --> 00:07:50,419
going to show you a demo it's not a

00:07:46,970 --> 00:07:55,340
shiny blinky demo there's enough shiny

00:07:50,419 --> 00:07:58,430
blinky at Times Square he could have a

00:07:55,340 --> 00:07:59,890
UI but it doesn't have a UI so we are

00:07:58,430 --> 00:08:03,260
going to focus on the server-side

00:07:59,890 --> 00:08:05,270
aspects here we're really going to look

00:08:03,260 --> 00:08:08,210
at two service auto chat tool what is a

00:08:05,270 --> 00:08:09,770
user service for identity management so

00:08:08,210 --> 00:08:16,120
you can add register users for example

00:08:09,770 --> 00:08:19,790
and then this chat service that is for

00:08:16,120 --> 00:08:23,039
conversations between two users so it's

00:08:19,790 --> 00:08:25,770
not like a pet room or

00:08:23,039 --> 00:08:29,369
it's really just for to uterus the user

00:08:25,770 --> 00:08:32,310
module has login information credentials

00:08:29,369 --> 00:08:35,849
and nicknames a lot of data let's say

00:08:32,310 --> 00:08:39,930
and chat modal only needs some of this

00:08:35,849 --> 00:08:42,779
data there's a name nickname let's say

00:08:39,930 --> 00:08:46,920
okay and we're going to take a look at

00:08:42,779 --> 00:08:49,610
how the check source can finally get

00:08:46,920 --> 00:08:53,010
that information from the user service

00:08:49,610 --> 00:08:54,510
step-by-step so first we're going to

00:08:53,010 --> 00:08:59,000
take a look at archives GP who has

00:08:54,510 --> 00:09:04,470
already worked with akka HTTP here okay

00:08:59,000 --> 00:09:08,279
let's say how it's actually pretty easy

00:09:04,470 --> 00:09:10,319
to run a server without HTTP you only

00:09:08,279 --> 00:09:14,279
need to do two things you need to bind

00:09:10,319 --> 00:09:16,380
to socket IP address and port and then

00:09:14,279 --> 00:09:19,139
you have to handle requests by sending

00:09:16,380 --> 00:09:25,880
responses those hammers you have to

00:09:19,139 --> 00:09:32,459
provide are our flows from the akka 3

00:09:25,880 --> 00:09:36,000
module and flow is is a stream in this

00:09:32,459 --> 00:09:38,040
case from request to response the ante

00:09:36,000 --> 00:09:40,980
here is just for the material has value

00:09:38,040 --> 00:09:44,699
which you can ignore in those cases in

00:09:40,980 --> 00:09:47,910
HTTP and those can be expressed with a

00:09:44,699 --> 00:09:51,839
pretty nice routing DSL let me show you

00:09:47,910 --> 00:09:54,410
that so here we have an actor it's

00:09:51,839 --> 00:09:58,800
called the user API of our

00:09:54,410 --> 00:10:01,800
user modules and it is parameterize with

00:09:58,800 --> 00:10:04,050
an address and a pour and then we call

00:10:01,800 --> 00:10:06,360
define and handle method with that

00:10:04,050 --> 00:10:09,360
address and pork as you can see here and

00:10:06,360 --> 00:10:12,000
the really interesting piece is this

00:10:09,360 --> 00:10:14,160
route here okay

00:10:12,000 --> 00:10:19,230
the route is defined up here at the

00:10:14,160 --> 00:10:21,720
companion object and proton beam this is

00:10:19,230 --> 00:10:24,870
just a hello world wrote as you can see

00:10:21,720 --> 00:10:28,450
here we are using the directors the

00:10:24,870 --> 00:10:30,970
routing DSL to first match

00:10:28,450 --> 00:10:33,820
the root path we have the path single

00:10:30,970 --> 00:10:36,340
slash directive here then we match on

00:10:33,820 --> 00:10:38,920
the HTTP verb they have to be method get

00:10:36,340 --> 00:10:41,800
post put delete whatever it's get here

00:10:38,920 --> 00:10:43,810
and so whenever somebody said to get to

00:10:41,800 --> 00:10:47,080
the root path we complete the request

00:10:43,810 --> 00:10:49,900
with hello world which is a string okay

00:10:47,080 --> 00:10:52,450
let's just see how this is working in

00:10:49,900 --> 00:10:55,510
action anyway before I can show you that

00:10:52,450 --> 00:11:00,430
I have to show you how to run that in

00:10:55,510 --> 00:11:03,220
docker okay so how do how can we create

00:11:00,430 --> 00:11:05,890
docker images with before Scala project

00:11:03,220 --> 00:11:08,770
well there's the SPT native packager

00:11:05,890 --> 00:11:10,300
plugin pretty awesome plugin it's not

00:11:08,770 --> 00:11:15,070
only used for docker it has many

00:11:10,300 --> 00:11:17,860
different deployment for months and if

00:11:15,070 --> 00:11:20,350
you want to use darker you have to use

00:11:17,860 --> 00:11:23,130
the so-called plugin for the SP native

00:11:20,350 --> 00:11:25,630
factor plugin so plug in for the plugin

00:11:23,130 --> 00:11:27,310
and then just configure a couple of

00:11:25,630 --> 00:11:30,220
docker related settings your project and

00:11:27,310 --> 00:11:33,460
then run the publish local task in the

00:11:30,220 --> 00:11:36,460
darker configuration so let me show you

00:11:33,460 --> 00:11:38,950
what you have to define in your project

00:11:36,460 --> 00:11:45,430
so the interesting line is line up to

00:11:38,950 --> 00:11:50,760
here oh you cannot see this so you have

00:11:45,430 --> 00:11:55,390
to add the SPF factor plug-in and then

00:11:50,760 --> 00:12:00,460
you have to specify some settings as you

00:11:55,390 --> 00:12:02,110
can see here even user maintain phase

00:12:00,460 --> 00:12:03,910
and I think this is really interesting

00:12:02,110 --> 00:12:06,370
which is your phase image in this case

00:12:03,910 --> 00:12:09,700
Java 8 make a little sense of think and

00:12:06,370 --> 00:12:15,070
so on and then you are essentially

00:12:09,700 --> 00:12:20,310
almost ready to go in your route sorry

00:12:15,070 --> 00:12:20,310
build SBT here okay

00:12:20,950 --> 00:12:28,730
here we are in your would be less t-wave

00:12:26,750 --> 00:12:31,340
you find the various self money on some

00:12:28,730 --> 00:12:36,650
projects you had to talk a plugin to

00:12:31,340 --> 00:12:38,960
your user project oh that's all you have

00:12:36,650 --> 00:12:43,130
to do to configure and then you can as I

00:12:38,960 --> 00:12:45,800
said run this sucker published local

00:12:43,130 --> 00:12:48,410
task which will first create the jar and

00:12:45,800 --> 00:12:53,360
then send everything to the dog demon

00:12:48,410 --> 00:12:56,210
and once this is done you can take a

00:12:53,360 --> 00:12:59,090
look at the dog fur images and here you

00:12:56,210 --> 00:13:02,090
can see the gavel user that has just

00:12:59,090 --> 00:13:04,130
been created in order to run that you

00:13:02,090 --> 00:13:06,800
doesn't have to know how to run doctor I

00:13:04,130 --> 00:13:09,170
have a small script here which

00:13:06,800 --> 00:13:12,350
essentially is prepare for the cluster

00:13:09,170 --> 00:13:15,680
mode for running multiple of those on my

00:13:12,350 --> 00:13:17,780
local machine but yeah what you have to

00:13:15,680 --> 00:13:21,550
do is you have to publish the HTTP port

00:13:17,780 --> 00:13:26,050
which is exposed and then just run this

00:13:21,550 --> 00:13:26,050
image let me do that

00:13:33,510 --> 00:13:39,290
as you can see here it seems to work

00:13:35,579 --> 00:13:39,290
it's listening so

00:13:45,840 --> 00:13:51,480
this one gear not foul that's not nice

00:13:49,260 --> 00:13:53,340
oh it's user event sorry so let me go

00:13:51,480 --> 00:13:54,030
for users that's the important I have

00:13:53,340 --> 00:13:58,800
Wow

00:13:54,030 --> 00:14:03,120
no also it's the route path right hello

00:13:58,800 --> 00:14:09,620
world yeah down there I hope you believe

00:14:03,120 --> 00:14:13,470
me yes hello world okay so of course

00:14:09,620 --> 00:14:17,280
this was just very simple route let's

00:14:13,470 --> 00:14:25,410
move on and see all we can complete the

00:14:17,280 --> 00:14:27,360
user API the user API and I don't want

00:14:25,410 --> 00:14:30,330
to really dive into details here just

00:14:27,360 --> 00:14:33,780
give you a very quick overview of the

00:14:30,330 --> 00:14:39,270
directives you would use the first we

00:14:33,780 --> 00:14:41,760
match on prefix users if that did we

00:14:39,270 --> 00:14:44,430
complete the request by asking the user

00:14:41,760 --> 00:14:47,720
repository that's an actor that is at

00:14:44,430 --> 00:14:51,810
the repository you can even posit Ori

00:14:47,720 --> 00:14:55,830
responsible for the users domain objects

00:14:51,810 --> 00:14:58,620
so we ask it to get the users and we map

00:14:55,830 --> 00:15:01,230
the response to the users message which

00:14:58,620 --> 00:15:05,160
is defined as a final case class users

00:15:01,230 --> 00:15:07,920
per set of user for a post which means

00:15:05,160 --> 00:15:11,220
we want to create a user we have to just

00:15:07,920 --> 00:15:17,210
unmarshal the entity from the request

00:15:11,220 --> 00:15:21,300
and a market as an add user command

00:15:17,210 --> 00:15:23,760
using a nickname email and then we can

00:15:21,300 --> 00:15:26,550
ask the user to post or to add the user

00:15:23,760 --> 00:15:28,860
now this time it's a little more complex

00:15:26,550 --> 00:15:32,430
because we can get back to different

00:15:28,860 --> 00:15:35,360
kind of successful responses so when is

00:15:32,430 --> 00:15:38,300
usually taken which is also happy path

00:15:35,360 --> 00:15:41,600
or user added as an event

00:15:38,300 --> 00:15:43,370
okay it has world and we complete the

00:15:41,600 --> 00:15:45,500
request of a conflict if the username

00:15:43,370 --> 00:15:50,180
has already been taken or with the

00:15:45,500 --> 00:15:52,790
created successful and so on I don't

00:15:50,180 --> 00:15:55,880
want to dive details here basically we

00:15:52,790 --> 00:15:59,050
have just communicating with an actor

00:15:55,880 --> 00:16:03,340
within the same active system here and

00:15:59,050 --> 00:16:03,340
let me just quickly run that

00:16:08,740 --> 00:16:16,780
all right smoke that quickly SBS compile

00:16:11,830 --> 00:16:19,350
that first we've done that before okay

00:16:16,780 --> 00:16:19,350
here we go

00:16:22,000 --> 00:16:24,300
and

00:16:30,320 --> 00:16:37,850
now if we ask what the users like before

00:16:34,480 --> 00:16:43,060
we get back an empty array because we

00:16:37,850 --> 00:16:43,060
have any users yet so

00:16:47,430 --> 00:16:52,860
let me find the right one for post to

00:16:50,760 --> 00:16:56,730
this one year 8,000 it looks good

00:16:52,860 --> 00:16:59,550
okay we get back I created 201 and we

00:16:56,730 --> 00:17:02,130
could do the same again we get back a

00:16:59,550 --> 00:17:05,250
conflict as I've shown you before and I

00:17:02,130 --> 00:17:08,640
thought we do that you get users again

00:17:05,250 --> 00:17:11,400
we get an array with exactly one so what

00:17:08,640 --> 00:17:14,760
you can see here is that the respondents

00:17:11,400 --> 00:17:21,089
we get back obviously is JSON encoded

00:17:14,760 --> 00:17:23,970
how's that working that's because of

00:17:21,089 --> 00:17:28,040
Jason Marshall II so HTTP has a really

00:17:23,970 --> 00:17:31,290
rich marshaling support you can simply

00:17:28,040 --> 00:17:33,750
complete your requests with the main

00:17:31,290 --> 00:17:36,750
objects like a set of users or a single

00:17:33,750 --> 00:17:38,750
user or whatever and then the

00:17:36,750 --> 00:17:42,570
marshalling infrastructure takes care of

00:17:38,750 --> 00:17:46,260
marshalling that to whatever format I

00:17:42,570 --> 00:17:49,160
can all the Box supports Spray JSON and

00:17:46,260 --> 00:17:51,750
XML and objective and there's another

00:17:49,160 --> 00:17:53,460
immunity project our case you PJs on

00:17:51,750 --> 00:17:57,120
that supports additional Jason libraries

00:17:53,460 --> 00:18:02,940
like Cersei which is my favorite because

00:17:57,120 --> 00:18:06,540
and to quickly show you that if all you

00:18:02,940 --> 00:18:08,370
need to do is to look at that import you

00:18:06,540 --> 00:18:10,950
need to imports you need to search the

00:18:08,370 --> 00:18:13,770
support and then the iOS or generic auto

00:18:10,950 --> 00:18:17,100
the first and fourth line here and then

00:18:13,770 --> 00:18:21,240
you can really complete your requests

00:18:17,100 --> 00:18:26,970
with type future of set of units okay

00:18:21,240 --> 00:18:29,670
that's Marshall to a array of JSON where

00:18:26,970 --> 00:18:32,820
each element reg is a user and each user

00:18:29,670 --> 00:18:38,690
which is case class is marking according

00:18:32,820 --> 00:18:38,690
according to the case class fields

00:18:38,960 --> 00:18:47,340
all right so we have a lot of things in

00:18:43,260 --> 00:18:49,680
place for writing HTTP api's for our

00:18:47,340 --> 00:18:50,460
micro services what it comes to

00:18:49,680 --> 00:18:56,700
persistence

00:18:50,460 --> 00:19:00,300
well packet persistence is a way to not

00:18:56,700 --> 00:19:02,940
store arbitrary data your databases but

00:19:00,300 --> 00:19:07,200
instead persist and recover actress

00:19:02,940 --> 00:19:10,890
state and our persistence based on the

00:19:07,200 --> 00:19:14,400
event sourcing so in a nutshell very

00:19:10,890 --> 00:19:16,650
quickly in the event sourcing do your

00:19:14,400 --> 00:19:20,430
act or receive a command to see message

00:19:16,650 --> 00:19:23,160
it then validates it for example if you

00:19:20,430 --> 00:19:25,320
try to add a user with send you the name

00:19:23,160 --> 00:19:29,430
like some other user that's not a

00:19:25,320 --> 00:19:32,130
command these it's validate the create

00:19:29,430 --> 00:19:35,280
event and let the journal is persistent

00:19:32,130 --> 00:19:36,330
a PR the event the journal is the

00:19:35,280 --> 00:19:39,450
database okay

00:19:36,330 --> 00:19:43,140
it's abstraction in our persistence for

00:19:39,450 --> 00:19:43,950
the database and after successful

00:19:43,140 --> 00:19:47,190
persistence

00:19:43,950 --> 00:19:51,170
the event is applied to the active state

00:19:47,190 --> 00:19:55,650
so you update the state of the actor and

00:19:51,170 --> 00:19:58,620
if the actor has to be recreated in the

00:19:55,650 --> 00:20:01,230
same zone or different node does invent

00:19:58,620 --> 00:20:02,700
a replace all the events are we played

00:20:01,230 --> 00:20:06,890
there's also snapshotting to avoid

00:20:02,700 --> 00:20:09,720
replaying buzz billions of events and

00:20:06,890 --> 00:20:14,760
therefore the actor final reaches the

00:20:09,720 --> 00:20:18,000
same state like before we need that

00:20:14,760 --> 00:20:22,340
because if we restart this app the user

00:20:18,000 --> 00:20:22,340
which we have added is launched

00:20:26,130 --> 00:20:30,919
so let me show you what we have to do

00:20:28,049 --> 00:20:34,380
for that if we go to the user repository

00:20:30,919 --> 00:20:37,049
which has been normal active before with

00:20:34,380 --> 00:20:42,240
that protocol get users at user remove

00:20:37,049 --> 00:20:44,100
user with trained actor persistent actor

00:20:42,240 --> 00:20:46,860
and therefore we have to implement

00:20:44,100 --> 00:20:51,299
receive command and receive recover and

00:20:46,860 --> 00:20:54,030
for example here add user is validated

00:20:51,299 --> 00:20:57,990
so if we have already a use of that

00:20:54,030 --> 00:21:00,030
username we don't persist anything we

00:20:57,990 --> 00:21:03,870
just respond to the senator username

00:21:00,030 --> 00:21:06,840
take it but in the other case we call

00:21:03,870 --> 00:21:08,700
the handle add user method and there we

00:21:06,840 --> 00:21:11,850
call this persist method which provided

00:21:08,700 --> 00:21:15,270
by this persistent active trait where we

00:21:11,850 --> 00:21:18,630
first create event and the persist

00:21:15,270 --> 00:21:20,250
method will invoke this handler once the

00:21:18,630 --> 00:21:22,860
journal gets back with the event and

00:21:20,250 --> 00:21:26,100
there we just call receive recover which

00:21:22,860 --> 00:21:29,010
does the application of the event to the

00:21:26,100 --> 00:21:31,860
state so in this case here in the case

00:21:29,010 --> 00:21:34,980
of a user edit we just add it to the

00:21:31,860 --> 00:21:38,400
internal map called users that's a map

00:21:34,980 --> 00:21:41,460
of string to user user name to user okay

00:21:38,400 --> 00:21:43,799
and it's important to not have any side

00:21:41,460 --> 00:21:48,299
effects in this receive recover those

00:21:43,799 --> 00:21:53,789
have to happen outside of the state

00:21:48,299 --> 00:21:58,020
handler okay with those changes we can

00:21:53,789 --> 00:22:01,010
let me just how much that again make the

00:21:58,020 --> 00:22:01,010
whole thing persistent

00:22:02,680 --> 00:22:11,050
so I have to run a database music

00:22:08,560 --> 00:22:14,650
Cassandra ear cluster just earlier just

00:22:11,050 --> 00:22:20,590
a single instance but I think it's a

00:22:14,650 --> 00:22:22,270
good idea to use a to use something like

00:22:20,590 --> 00:22:24,490
the center up because for descriptive

00:22:22,270 --> 00:22:26,680
systems of vadhaka usually if you want

00:22:24,490 --> 00:22:28,690
to build a reactive system you need to

00:22:26,680 --> 00:22:30,610
go to tip because one note if you only

00:22:28,690 --> 00:22:32,890
have one know that fails is doing really

00:22:30,610 --> 00:22:34,210
resilient so for I hate the student

00:22:32,890 --> 00:22:37,780
system you need a district database

00:22:34,210 --> 00:22:41,020
mister journal and I think this song a

00:22:37,780 --> 00:22:44,920
plugin for other persistence is totally

00:22:41,020 --> 00:22:47,260
already there it's maintained it has

00:22:44,920 --> 00:22:49,120
been created by market crosser and in

00:22:47,260 --> 00:22:51,610
the meanwhile it is maintained by the

00:22:49,120 --> 00:22:55,480
Aqua team and it also supports

00:22:51,610 --> 00:22:58,300
persistence we race which is additional

00:22:55,480 --> 00:23:02,080
to archive persistence which has been

00:22:58,300 --> 00:23:03,070
the latest version of our company the

00:23:02,080 --> 00:23:05,170
other thing you have to do is you have

00:23:03,070 --> 00:23:09,340
to configure a contact points for

00:23:05,170 --> 00:23:13,870
example via system properties so let me

00:23:09,340 --> 00:23:17,410
show you what that means so if you if

00:23:13,870 --> 00:23:20,590
you run your docker image you have to

00:23:17,410 --> 00:23:23,080
provide this system property because

00:23:20,590 --> 00:23:25,570
some internal contact points that's the

00:23:23,080 --> 00:23:30,780
people port on which some listening for

00:23:25,570 --> 00:23:30,780
clients and that's all so

00:23:32,940 --> 00:23:42,750
let me run Keppler again what instance

00:23:40,570 --> 00:23:42,750
only

00:23:44,790 --> 00:23:55,310
good is listening so adding a user that

00:23:53,040 --> 00:23:55,310
worked

00:23:59,040 --> 00:24:04,580
okay there now if we remove this

00:24:01,830 --> 00:24:04,580
container

00:24:09,300 --> 00:24:20,500
so the only containers we have is a

00:24:12,780 --> 00:24:24,370
container and we started again we should

00:24:20,500 --> 00:24:27,700
be able to see that user again great

00:24:24,370 --> 00:24:31,570
it's working so this user repository has

00:24:27,700 --> 00:24:35,050
been created and initialized with the

00:24:31,570 --> 00:24:37,630
events with this one at user event so we

00:24:35,050 --> 00:24:42,310
get in the same state we are the same

00:24:37,630 --> 00:24:44,980
state like the portal all right so now

00:24:42,310 --> 00:24:48,310
we we have a service it's not yet

00:24:44,980 --> 00:24:53,230
Brazilian it's not a distributed so we

00:24:48,310 --> 00:24:56,650
need to go remote and dump our

00:24:53,230 --> 00:24:59,190
networking can be a little tricky so in

00:24:56,650 --> 00:25:01,480
tougher networks isolate containers

00:24:59,190 --> 00:25:05,490
within the network the containers can't

00:25:01,480 --> 00:25:08,710
communicate but if you want to access

00:25:05,490 --> 00:25:10,810
container from external you need to be

00:25:08,710 --> 00:25:13,480
you need to publish ports and this is

00:25:10,810 --> 00:25:15,640
true for the traditional host networking

00:25:13,480 --> 00:25:17,710
here of rich bridge networking on a

00:25:15,640 --> 00:25:19,840
single machine on a single host and

00:25:17,710 --> 00:25:21,670
that's true for overlay networks which

00:25:19,840 --> 00:25:22,450
have recently added to thinking Oh

00:25:21,670 --> 00:25:25,000
attend docker

00:25:22,450 --> 00:25:27,700
open the networks are pretty cool for

00:25:25,000 --> 00:25:29,850
multi post deployment so they they have

00:25:27,700 --> 00:25:32,740
they essentially are a virtual network

00:25:29,850 --> 00:25:34,210
spending multiple hosts and all the

00:25:32,740 --> 00:25:37,930
containers can communicate with each

00:25:34,210 --> 00:25:40,930
other for five o'clock core OS and

00:25:37,930 --> 00:25:42,430
others and the good thing is if you

00:25:40,930 --> 00:25:44,410
don't need things between public and

00:25:42,430 --> 00:25:49,420
found address in aqua remote aqua remote

00:25:44,410 --> 00:25:51,820
has this notion of the bound address of

00:25:49,420 --> 00:25:54,070
public address and that's only important

00:25:51,820 --> 00:25:57,160
if you really want to talk to your

00:25:54,070 --> 00:25:59,020
container from the outside but if you

00:25:57,160 --> 00:26:00,550
have neither cluster you usually only

00:25:59,020 --> 00:26:02,350
want the containers within the cluster

00:26:00,550 --> 00:26:03,910
to talk to each other unless you are

00:26:02,350 --> 00:26:07,240
using a cluster client from the outside

00:26:03,910 --> 00:26:08,690
so in this case we don't have that need

00:26:07,240 --> 00:26:12,500
to access

00:26:08,690 --> 00:26:15,470
from the outside don't have to deal with

00:26:12,500 --> 00:26:20,780
these issues so using normal a network

00:26:15,470 --> 00:26:23,390
is this really helpful in those cases so

00:26:20,780 --> 00:26:27,100
to really go to stupid and reactive with

00:26:23,390 --> 00:26:29,270
akka cluster you only have to change one

00:26:27,100 --> 00:26:32,210
configuration setting it's a cluster

00:26:29,270 --> 00:26:38,570
actor wrap provider in the application

00:26:32,210 --> 00:26:41,750
of kana sorry so the application comp

00:26:38,570 --> 00:26:48,650
which is the configuration for oh I

00:26:41,750 --> 00:26:53,990
don't have it yet okay here we go

00:26:48,650 --> 00:26:56,710
so here no here akka that's essentially

00:26:53,990 --> 00:27:00,440
on in each here

00:26:56,710 --> 00:27:03,980
what more if you're running on docker

00:27:00,440 --> 00:27:06,350
you probably cannot work with seed notes

00:27:03,980 --> 00:27:11,870
seed notes are used to bootstrap the

00:27:06,350 --> 00:27:14,150
cluster and use to join the cluster that

00:27:11,870 --> 00:27:17,180
doesn't works if you don't see those up

00:27:14,150 --> 00:27:19,670
front in a fairly statics having that

00:27:17,180 --> 00:27:23,210
works perfectly with docker you don't

00:27:19,670 --> 00:27:27,740
know from the container a disease and

00:27:23,210 --> 00:27:29,870
therefore you need some for help and

00:27:27,740 --> 00:27:32,900
there's a lot recall constructor that

00:27:29,870 --> 00:27:34,610
helps reduce traffic essentially it's

00:27:32,900 --> 00:27:40,610
using a coordination service like Etsy

00:27:34,610 --> 00:27:42,830
or zoo keeper or console and all you to

00:27:40,610 --> 00:27:44,690
do is edit library configure the

00:27:42,830 --> 00:27:48,410
constructor extension in the application

00:27:44,690 --> 00:27:52,370
column that's done here and it will boot

00:27:48,410 --> 00:27:56,750
strap itself by simply applying this

00:27:52,370 --> 00:27:59,000
state diagram so I don't want to dive

00:27:56,750 --> 00:28:01,070
into details but what's going on here is

00:27:59,000 --> 00:28:03,020
this library tries to get the notes from

00:28:01,070 --> 00:28:06,560
the coordination service if there are

00:28:03,020 --> 00:28:09,050
already know it's the new node joining

00:28:06,560 --> 00:28:12,140
bells if there are none it's acquiring a

00:28:09,050 --> 00:28:14,090
lock and if that works it's joining

00:28:12,140 --> 00:28:15,990
itself so the first note always has to

00:28:14,090 --> 00:28:19,200
join itself and

00:28:15,990 --> 00:28:21,240
it cannot be acquired there was a race

00:28:19,200 --> 00:28:24,480
okay that can only be won

00:28:21,240 --> 00:28:27,660
so it's trying to get loads again then

00:28:24,480 --> 00:28:31,290
it's ending itself and refreshing to be

00:28:27,660 --> 00:28:32,910
sure that things are clean out let's do

00:28:31,290 --> 00:28:34,590
it here of a constructor it's kind of

00:28:32,910 --> 00:28:37,380
simple idea the implementation is a

00:28:34,590 --> 00:28:41,490
little involved but it seems to work and

00:28:37,380 --> 00:28:42,929
it's used in production okay so these

00:28:41,490 --> 00:28:52,580
are attended with the changes that are

00:28:42,929 --> 00:28:52,580
needed and now we can run it in parallel

00:29:00,100 --> 00:29:09,460
one more thing our user registry or

00:29:05,230 --> 00:29:13,150
repository this case needs to be a

00:29:09,460 --> 00:29:16,630
single team clusters singleton is an act

00:29:13,150 --> 00:29:20,560
inaccurate that only runs exactly once

00:29:16,630 --> 00:29:25,060
or at most once in the cluster at any

00:29:20,560 --> 00:29:26,590
time most once means it should run all

00:29:25,060 --> 00:29:29,170
the time but if it crashes if one

00:29:26,590 --> 00:29:32,910
machine crashes take some time until

00:29:29,170 --> 00:29:37,630
that's detected a second ten seconds and

00:29:32,910 --> 00:29:39,040
it is created on some of them so the

00:29:37,630 --> 00:29:40,840
actor you want to run as a single dozen

00:29:39,040 --> 00:29:43,000
is managed by the cluster of singleton

00:29:40,840 --> 00:29:45,160
manager that another actor that runs of

00:29:43,000 --> 00:29:49,180
every node in the cluster is

00:29:45,160 --> 00:29:50,920
participating here and access to the

00:29:49,180 --> 00:29:52,090
single factor is provided by the cluster

00:29:50,920 --> 00:29:54,850
to the proxy because you would actually

00:29:52,090 --> 00:29:56,560
have an indirection don't know where the

00:29:54,850 --> 00:30:01,390
singer is running so that's what you

00:29:56,560 --> 00:30:03,670
need these are the changes and once

00:30:01,390 --> 00:30:06,510
those are applied I'll let me just

00:30:03,670 --> 00:30:06,510
quickly bring up

00:30:09,640 --> 00:30:18,350
user hat that's the app that crazy

00:30:15,350 --> 00:30:19,880
active system and the various actors so

00:30:18,350 --> 00:30:24,230
the user repository as you can see here

00:30:19,880 --> 00:30:25,700
is now actually context actor of

00:30:24,230 --> 00:30:27,080
clustered single image so we are

00:30:25,700 --> 00:30:30,679
creating the consisting of the manager

00:30:27,080 --> 00:30:33,410
and configuring it to run the user

00:30:30,679 --> 00:30:35,510
repository as a singleton in order to

00:30:33,410 --> 00:30:37,820
access it we are also creating a

00:30:35,510 --> 00:30:41,090
singleton proxy okay that's what you

00:30:37,820 --> 00:30:45,530
need to run a specific actor only once

00:30:41,090 --> 00:30:47,860
as a singleton in your cluster alright

00:30:45,530 --> 00:30:47,860
so

00:30:50,050 --> 00:30:55,750
so we run one instance and other

00:30:52,420 --> 00:30:58,240
instance they are now working or

00:30:55,750 --> 00:31:01,200
listening on different ports for the

00:30:58,240 --> 00:31:01,200
HTTP requests

00:31:15,440 --> 00:31:22,760
oh yeah I told you that you need a

00:31:20,020 --> 00:31:25,930
coordination service like sed I haven't

00:31:22,760 --> 00:31:25,930
started that container

00:31:28,710 --> 00:31:36,680
okay now we have intensity up and

00:31:30,480 --> 00:31:36,680
running and I can do the same again

00:31:50,730 --> 00:31:54,980
finally yes

00:31:55,100 --> 00:32:00,899
yeah

00:31:57,960 --> 00:32:08,399
okay that looks good listening so now

00:32:00,899 --> 00:32:11,249
let's start second one and okay we are

00:32:08,399 --> 00:32:13,289
talking to the first node which is

00:32:11,249 --> 00:32:16,669
listing on eight thousand and we can

00:32:13,289 --> 00:32:19,799
also talk to the second node which is

00:32:16,669 --> 00:32:22,980
1001 it both gives you the same result

00:32:19,799 --> 00:32:25,169
and we can now even so if you remember

00:32:22,980 --> 00:32:26,909
we start first note first

00:32:25,169 --> 00:32:31,249
so the cluster Singleton's all the ways

00:32:26,909 --> 00:32:31,249
I'm the oldest node we can kill that one

00:32:31,730 --> 00:32:42,419
it is zero and we will still be able to

00:32:37,889 --> 00:32:44,580
see the user if we access the secondary

00:32:42,419 --> 00:32:49,379
because the singleton has been moved to

00:32:44,580 --> 00:32:52,830
the second member so with these tools we

00:32:49,379 --> 00:32:54,809
have a really really powerful tool is

00:32:52,830 --> 00:32:57,480
very powerful abstractions to build

00:32:54,809 --> 00:32:59,490
reactive services so I would say this is

00:32:57,480 --> 00:33:02,159
a reactive service a single reactive

00:32:59,490 --> 00:33:06,980
service because it is resilient can be

00:33:02,159 --> 00:33:14,029
scaled to 210 or whatever nodes and

00:33:06,980 --> 00:33:17,600
therefore it itself is is reactive but

00:33:14,029 --> 00:33:20,460
now let's talk about collaboration and

00:33:17,600 --> 00:33:23,690
collaboration between services probably

00:33:20,460 --> 00:33:27,570
should happen via HTTP of course you can

00:33:23,690 --> 00:33:30,330
employ any protocol you want you could

00:33:27,570 --> 00:33:32,249
do database integration but you don't

00:33:30,330 --> 00:33:36,629
want to do that in the micro sources

00:33:32,249 --> 00:33:38,940
roles so ideally you would use HTTP and

00:33:36,629 --> 00:33:42,899
suicide events are an official

00:33:38,940 --> 00:33:46,200
specification supported by every

00:33:42,899 --> 00:33:48,509
reasonable browser but we are not

00:33:46,200 --> 00:33:50,999
talking about brothers now we're talking

00:33:48,509 --> 00:33:53,070
about clients which are applications

00:33:50,999 --> 00:33:55,379
running akka so the communication

00:33:53,070 --> 00:33:58,590
between the client doesn't replace the

00:33:55,379 --> 00:34:00,749
broader client and the server works the

00:33:58,590 --> 00:34:03,419
following way you do a get from the

00:34:00,749 --> 00:34:05,970
client and the server send the response

00:34:03,419 --> 00:34:07,990
with that media type text event stream

00:34:05,970 --> 00:34:11,679
and keep the respondents and

00:34:07,990 --> 00:34:14,710
open okay and just pushes events down

00:34:11,679 --> 00:34:17,919
that connection and the events are

00:34:14,710 --> 00:34:20,470
really simple text-based things without

00:34:17,919 --> 00:34:26,080
any fires like event data and also ID

00:34:20,470 --> 00:34:28,810
which can be used to inform the client

00:34:26,080 --> 00:34:31,600
about the kind of event like user edit

00:34:28,810 --> 00:34:33,399
or get removed these are just labels of

00:34:31,600 --> 00:34:35,320
text and the data can span multiple

00:34:33,399 --> 00:34:38,590
lines that could also be based on

00:34:35,320 --> 00:34:40,540
encoded or whatever you need and for a

00:34:38,590 --> 00:34:43,480
really event based collaboration between

00:34:40,540 --> 00:34:45,909
a climate server what you have to do is

00:34:43,480 --> 00:34:48,940
you've got to make that resilient to

00:34:45,909 --> 00:34:52,149
because the connection here can bring at

00:34:48,940 --> 00:34:54,159
any time and what I've implemented it

00:34:52,149 --> 00:34:55,869
will show you in a moment is that if you

00:34:54,159 --> 00:34:57,730
have a second service that depends on

00:34:55,869 --> 00:35:02,050
the user service I've shown you so far

00:34:57,730 --> 00:35:06,100
you want to you want to subscribe to

00:35:02,050 --> 00:35:07,810
those events and if you get the events

00:35:06,100 --> 00:35:10,900
you can also get an idea if the server

00:35:07,810 --> 00:35:12,910
supports that and if you have consumed

00:35:10,900 --> 00:35:16,350
like ten events and then the connection

00:35:12,910 --> 00:35:19,600
is interrupted you want to reconnect and

00:35:16,350 --> 00:35:22,660
use the late late last event any header

00:35:19,600 --> 00:35:24,010
er to signal to the server that you

00:35:22,660 --> 00:35:27,490
already have consumed ten or in this

00:35:24,010 --> 00:35:34,619
case forty two events you want to start

00:35:27,490 --> 00:35:34,619
consuming from there okay so

00:35:36,980 --> 00:35:45,640
final thing published user events via

00:35:39,890 --> 00:35:45,640
SSE let's do that

00:35:47,510 --> 00:35:54,260
but we have to enhance our rod a little

00:35:52,250 --> 00:35:59,540
bit so that that is the route we have

00:35:54,260 --> 00:36:02,930
before users API endpoint and we have

00:35:59,540 --> 00:36:05,450
added a user events in point here where

00:36:02,930 --> 00:36:08,030
we first take a look at the optional

00:36:05,450 --> 00:36:10,430
header last event ID and then from that

00:36:08,030 --> 00:36:12,710
we calculate the next sequence number of

00:36:10,430 --> 00:36:15,140
events and then we just ask the usual

00:36:12,710 --> 00:36:18,170
posture to get the user events from that

00:36:15,140 --> 00:36:21,680
sequence number what the user Porter is

00:36:18,170 --> 00:36:26,210
giving us is a source okay let me go

00:36:21,680 --> 00:36:35,150
there show that to you what we get here

00:36:26,210 --> 00:36:40,450
is a source so the type here is a source

00:36:35,150 --> 00:36:42,890
of tuples sequence number and user event

00:36:40,450 --> 00:36:46,730
the cool thing is with that have a SSD

00:36:42,890 --> 00:36:49,100
library you can complete requests with a

00:36:46,730 --> 00:36:50,960
source of server sent events that's

00:36:49,100 --> 00:36:54,140
what's done here usually events are

00:36:50,960 --> 00:36:56,359
mapped in using this function here to

00:36:54,140 --> 00:36:59,240
service and events services events are

00:36:56,359 --> 00:37:01,490
simple case classes and for a user edit

00:36:59,240 --> 00:37:03,410
the current source an event which as

00:37:01,490 --> 00:37:06,380
usually added here and we do it self

00:37:03,410 --> 00:37:09,260
encoding this Jason and for user removed

00:37:06,380 --> 00:37:12,050
to do the same with a user removed event

00:37:09,260 --> 00:37:18,950
type and and that's it that's all you

00:37:12,050 --> 00:37:20,570
need to publish source and events now I

00:37:18,950 --> 00:37:22,670
want to show you the client side to and

00:37:20,570 --> 00:37:25,609
all the most running out of time so I

00:37:22,670 --> 00:37:27,950
have to hurry a little bit so in this

00:37:25,609 --> 00:37:30,890
last step here I have created a second

00:37:27,950 --> 00:37:32,740
product it's called GABA chat and the

00:37:30,890 --> 00:37:36,140
gallic chat

00:37:32,740 --> 00:37:41,000
Napoleon meets information from the gaba

00:37:36,140 --> 00:37:44,210
user service it subscribes to those user

00:37:41,000 --> 00:37:46,609
events okay it subscribe to these user

00:37:44,210 --> 00:37:50,720
events means it gets those events and

00:37:46,609 --> 00:37:52,630
stores it internally for itself so it

00:37:50,720 --> 00:37:57,010
has a youtube post or two

00:37:52,630 --> 00:38:00,570
this chat module now and what's done

00:37:57,010 --> 00:38:05,020
curious once the recovery is completed

00:38:00,570 --> 00:38:08,080
so that's persistent act or to it Chris

00:38:05,020 --> 00:38:11,200
Urmson even client that's also part of

00:38:08,080 --> 00:38:13,930
the akka SSE project that's the facility

00:38:11,200 --> 00:38:17,610
which gives you this reconnection logic

00:38:13,930 --> 00:38:24,090
with the last event ID and all that

00:38:17,610 --> 00:38:27,010
nitty-gritty details and that means

00:38:24,090 --> 00:38:31,500
every time they service an event is

00:38:27,010 --> 00:38:35,890
received here in in this in this actor

00:38:31,500 --> 00:38:40,720
it is just decoded is a nebula or remove

00:38:35,890 --> 00:38:43,480
user with the event ID and sent to sell

00:38:40,720 --> 00:38:46,210
this is an actor and when it's received

00:38:43,480 --> 00:38:51,100
it is essentially handled as an add user

00:38:46,210 --> 00:38:55,090
or remove user it's persisted and used

00:38:51,100 --> 00:38:58,770
to change the internal state important

00:38:55,090 --> 00:38:58,770
here we login okay

00:39:10,070 --> 00:39:14,860
publish local again now we have to

00:39:12,080 --> 00:39:14,860
publish both modules

00:39:22,700 --> 00:39:32,270
okay and now let's run the user module

00:39:29,810 --> 00:39:37,870
and what I wanted to show you is how to

00:39:32,270 --> 00:39:37,870
access those user events from Curl first

00:39:45,090 --> 00:39:48,090
huh

00:39:53,540 --> 00:39:56,540
okay

00:40:03,510 --> 00:40:09,720
that was binary incompatibility if

00:40:07,830 --> 00:40:12,810
you're doing that sourcing when you you

00:40:09,720 --> 00:40:16,680
change your events that's what it is you

00:40:12,810 --> 00:40:18,840
run into those issues so you better use

00:40:16,680 --> 00:40:28,369
some abstraction to avoid that in the

00:40:18,840 --> 00:40:28,369
production let's give it another try

00:40:35,950 --> 00:40:38,910
we're getting there

00:40:46,460 --> 00:40:49,420
I'm sorry

00:40:55,390 --> 00:40:59,109
okay someone is working

00:41:11,440 --> 00:41:14,799
yeah I was just okay there was a time

00:41:14,440 --> 00:41:17,740
out

00:41:14,799 --> 00:41:19,390
I was just tama des configure is only

00:41:17,740 --> 00:41:22,119
250 milliseconds and for the very first

00:41:19,390 --> 00:41:25,210
request using the persistence query it

00:41:22,119 --> 00:41:28,210
seems to take me 150 milliseconds so now

00:41:25,210 --> 00:41:31,569
we are as you can see here listening

00:41:28,210 --> 00:41:37,599
subscribing to those events there are no

00:41:31,569 --> 00:41:40,930
events yet so let's add one curl where's

00:41:37,599 --> 00:41:46,750
the addition ok we added one add a

00:41:40,930 --> 00:41:48,730
second one okay and again user events

00:41:46,750 --> 00:41:52,569
okay now you see those two events they

00:41:48,730 --> 00:41:59,309
have been send new events would be sent

00:41:52,569 --> 00:42:03,960
so last thing you to do we want to run

00:41:59,309 --> 00:42:03,960
the chat service

00:42:20,680 --> 00:42:27,930
chat service is listening on 8010 okay

00:42:24,220 --> 00:42:27,930
cool so cool

00:42:35,970 --> 00:42:41,090
I think this one 8010 users

00:42:46,740 --> 00:42:50,450
so you see me debugging a lot

00:42:54,880 --> 00:43:01,060
okay at least here in the log oh yeah

00:42:58,780 --> 00:43:05,280
sorry in this stage of the demo I

00:43:01,060 --> 00:43:08,200
haven't implemented HTTP API at all for

00:43:05,280 --> 00:43:09,940
for the chat service but as you can see

00:43:08,200 --> 00:43:13,120
here in the log

00:43:09,940 --> 00:43:17,340
you see edit user with username 1 & 3 so

00:43:13,120 --> 00:43:20,710
this guy here that check service is

00:43:17,340 --> 00:43:24,850
listening to the user service and

00:43:20,710 --> 00:43:29,950
asynchronously using or subscribe to

00:43:24,850 --> 00:43:32,170
those events and storing them or using

00:43:29,950 --> 00:43:36,100
using those events so let me add one

00:43:32,170 --> 00:43:38,380
more here or maybe follow the log in

00:43:36,100 --> 00:43:41,290
this case here so we see that something

00:43:38,380 --> 00:43:47,670
is going on so now right now we have two

00:43:41,290 --> 00:43:50,170
events and if we add one more user 99

00:43:47,670 --> 00:43:53,800
that has been added here and it's

00:43:50,170 --> 00:43:56,830
showing up here a second later mission

00:43:53,800 --> 00:43:58,090
completed we have two services which are

00:43:56,830 --> 00:44:00,970
completely independent only

00:43:58,090 --> 00:44:06,900
communicating is synchronously via HTTP

00:44:00,970 --> 00:44:06,900
server sent events that's it thank you

00:44:11,560 --> 00:44:16,280
I'm happy to take word questions and

00:44:14,300 --> 00:44:18,290
I'll be around so you can ask your

00:44:16,280 --> 00:44:24,980
questions outside if you want is there

00:44:18,290 --> 00:44:26,780
me are there any questions how do I

00:44:24,980 --> 00:44:31,190
approach schema migration in production

00:44:26,780 --> 00:44:33,590
so akka has support for schema migration

00:44:31,190 --> 00:44:38,750
or schema evolution after persistence

00:44:33,590 --> 00:44:40,730
introduced support for that no not

00:44:38,750 --> 00:44:42,590
purpose is Prairie schema evolution

00:44:40,730 --> 00:44:44,660
let's look it up in the talks archived

00:44:42,590 --> 00:44:49,310
on Io Doc's that has been added support

00:44:44,660 --> 00:44:53,050
for scheme evolution one more okay

00:44:49,310 --> 00:44:53,050

YouTube URL: https://www.youtube.com/watch?v=7_rxgnRvh1s


