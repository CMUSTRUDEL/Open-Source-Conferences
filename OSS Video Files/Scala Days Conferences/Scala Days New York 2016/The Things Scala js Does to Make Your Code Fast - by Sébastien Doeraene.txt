Title: The Things Scala js Does to Make Your Code Fast - by Sébastien Doeraene
Publication date: 2016-06-17
Playlist: Scala Days New York 2016
Description: 
	This talk was recorded at Scala Days New York, 2016. Follow along on Twitter @scaladays and on the website for more information http://scaladays.org/.

Abstract:
One of the strengths of Scala.js is its run-time performance. Compiled Scala.js programs typically run on par with equivalent, hand-written JavaScript code. To achieve this, Scala.js features an advanced optimizer. In this talk, we will explore some typical Scala.js code snippets, and see what the optimizer makes of them. In the process, we will give insights about the code patterns that it can optimize away, as well as things it cannot (yet) eliminate. Attendees will take away keys to write efficient Scala.js code. In particular, we will see that idiomatic Scala code is not to be feared (e.g., for loops, or maps/filters). Attendees are expected to be familiar with Scala (not necessarily Scala.js) and to be able to read JavaScript. No compiler knowledge is required; we will stay at the source code level, showing what the optimizer does without explaining how.
Captions: 
	00:00:01,230 --> 00:00:07,140
you will see a lot of codes a lot of

00:00:04,290 --> 00:00:10,549
benchmarks and code in two different

00:00:07,140 --> 00:00:14,369
languages and Scala and in JavaScript

00:00:10,549 --> 00:00:17,339
but I hope I'll be able to talk you

00:00:14,369 --> 00:00:20,820
through it will will actually look at

00:00:17,339 --> 00:00:23,519
generated codes at some point so try not

00:00:20,820 --> 00:00:26,910
to read everything that's on the screen

00:00:23,519 --> 00:00:28,919
at all times because there will be

00:00:26,910 --> 00:00:31,230
irrelevant parts that are just part of

00:00:28,919 --> 00:00:35,789
the generated thing so try to focus on

00:00:31,230 --> 00:00:40,500
what I'm showing and try not to read

00:00:35,789 --> 00:00:43,170
everything okay so that said I was asked

00:00:40,500 --> 00:00:45,870
to put the slides apparently no figures

00:00:43,170 --> 00:00:50,010
except me that but if you didn't already

00:00:45,870 --> 00:00:57,679
the previous recession please do so

00:00:50,010 --> 00:01:01,800
that's about all the slides I have so

00:00:57,679 --> 00:01:05,580
biggest will be switching between this

00:01:01,800 --> 00:01:09,020
Eclipse IDE yes I use Eclipse this SBT

00:01:05,580 --> 00:01:12,900
console and this notepad plus plus

00:01:09,020 --> 00:01:17,670
editor with generated codes for most of

00:01:12,900 --> 00:01:22,140
the session so this talk is about the

00:01:17,670 --> 00:01:25,310
things that Scala jeus does to make your

00:01:22,140 --> 00:01:29,790
code fast so it's obviously about

00:01:25,310 --> 00:01:31,680
optimizations right however no worries

00:01:29,790 --> 00:01:35,460
you don't have to be a compiler hacker

00:01:31,680 --> 00:01:37,440
will will will show what it does the

00:01:35,460 --> 00:01:40,140
kinds of things it can do things the

00:01:37,440 --> 00:01:45,420
kind of thing you cannot do and but will

00:01:40,140 --> 00:01:49,610
not explain how it does it so let's

00:01:45,420 --> 00:01:55,500
start with our first example which is a

00:01:49,610 --> 00:01:59,400
for loop like a for I from zero until n

00:01:55,500 --> 00:02:04,470
which is over here vs the good old while

00:01:59,400 --> 00:02:06,570
loop written Java style I mean it is it

00:02:04,470 --> 00:02:10,920
not even Java style because in Java you

00:02:06,570 --> 00:02:13,200
would use a for loop put so it's I don't

00:02:10,920 --> 00:02:14,450
know if you're familiar with performance

00:02:13,200 --> 00:02:17,540
in Scala JVM

00:02:14,450 --> 00:02:20,930
pretty notorious that if you need

00:02:17,540 --> 00:02:27,379
performance avoid avoid the for-loop on

00:02:20,930 --> 00:02:29,810
on a range at all costs this is slow so

00:02:27,379 --> 00:02:33,709
we'll see what what happens in Scala is

00:02:29,810 --> 00:02:39,380
is it is it also very slow or not too

00:02:33,709 --> 00:02:43,160
slow or maybe it's even worse so let's

00:02:39,380 --> 00:02:45,709
see so just just to give you an idea I I

00:02:43,160 --> 00:02:48,920
have written this myself this very

00:02:45,709 --> 00:02:50,870
little micro benchmarking framework so

00:02:48,920 --> 00:02:53,540
don't trust the benchmarks the

00:02:50,870 --> 00:02:55,610
benchmarks are wrong they're just there

00:02:53,540 --> 00:02:58,250
to highlight the fact that there is a

00:02:55,610 --> 00:03:00,200
difference when we change things not

00:02:58,250 --> 00:03:02,209
really how much of a difference there is

00:03:00,200 --> 00:03:06,049
because that's probably not going to be

00:03:02,209 --> 00:03:07,880
good however I can guarantee you that

00:03:06,049 --> 00:03:09,860
all these optimizations are going to

00:03:07,880 --> 00:03:13,030
talk about they have real impact in real

00:03:09,860 --> 00:03:16,640
codes because we have developed them

00:03:13,030 --> 00:03:18,590
against big benchmarks like macro

00:03:16,640 --> 00:03:21,109
benchmarks so full application

00:03:18,590 --> 00:03:22,880
benchmarks and we saw and difference but

00:03:21,109 --> 00:03:26,120
we're not going to look at micro

00:03:22,880 --> 00:03:28,970
benchmarks today okay so that's that's

00:03:26,120 --> 00:03:33,980
enough of an introduction so let's run

00:03:28,970 --> 00:03:36,410
this code so I have this small here a

00:03:33,980 --> 00:03:38,840
small script here which runs the

00:03:36,410 --> 00:03:44,239
benchmarks so this is using notes is

00:03:38,840 --> 00:03:47,180
four to one I think and we see that it

00:03:44,239 --> 00:03:52,609
runs at two times so this one here and

00:03:47,180 --> 00:03:55,069
this one here so scholar G's has an

00:03:52,609 --> 00:03:57,440
optimizer right and we're going to talk

00:03:55,069 --> 00:03:58,940
about utilizations does so obviously

00:03:57,440 --> 00:04:00,680
we're going to compare what happens

00:03:58,940 --> 00:04:03,290
without an optimizer and with the

00:04:00,680 --> 00:04:05,329
optimizer so here that's without the

00:04:03,290 --> 00:04:07,819
optimizer and that's pretty bad

00:04:05,329 --> 00:04:11,540
right so you can look this this is time

00:04:07,819 --> 00:04:14,019
spent executing the code so you can see

00:04:11,540 --> 00:04:17,440
that a while loop is reasonable it's

00:04:14,019 --> 00:04:20,479
0.30 in some unit of time it's

00:04:17,440 --> 00:04:21,859
microsecond seconds for some thing

00:04:20,479 --> 00:04:26,000
doesn't really matter because we're

00:04:21,859 --> 00:04:27,050
going and looking at differences and for

00:04:26,000 --> 00:04:30,570
loop

00:04:27,050 --> 00:04:35,810
1.64 which is that much bigger it's

00:04:30,570 --> 00:04:40,050
really slow so with with an optimizer

00:04:35,810 --> 00:04:42,660
that's much more reasonable the white

00:04:40,050 --> 00:04:45,960
Luke got a little bit better its 0.09

00:04:42,660 --> 00:04:50,040
and the full loop is 0.12 which is very

00:04:45,960 --> 00:04:53,130
close to the value right okay but I told

00:04:50,040 --> 00:04:54,150
you not to trust the benchmarks so what

00:04:53,130 --> 00:04:56,880
are we gonna trust

00:04:54,150 --> 00:05:00,810
well the generative codes is we like

00:04:56,880 --> 00:05:03,330
that so for this this little code here

00:05:00,810 --> 00:05:06,750
let's see if it the generated code so

00:05:03,330 --> 00:05:11,280
here first time looking at the non

00:05:06,750 --> 00:05:15,330
optimized version right and let me put

00:05:11,280 --> 00:05:17,640
that in top corner so this is the ugly

00:05:15,330 --> 00:05:20,100
stuff I was talking about right so let's

00:05:17,640 --> 00:05:23,250
let let me just find for you the nice

00:05:20,100 --> 00:05:27,240
things so here you can find nice things

00:05:23,250 --> 00:05:29,670
which is the direct compilation in

00:05:27,240 --> 00:05:31,800
JavaScript of the while loop and you can

00:05:29,670 --> 00:05:33,600
see that well yes you get voice you get

00:05:31,800 --> 00:05:35,520
a while loop it's pretty obvious

00:05:33,600 --> 00:05:38,970
something that might not be pretty

00:05:35,520 --> 00:05:41,820
obvious as these binary or zero and

00:05:38,970 --> 00:05:44,640
dollar I'm all but don't really worry

00:05:41,820 --> 00:05:47,220
about that that's the important thing is

00:05:44,640 --> 00:05:50,340
is this this while loop here so where is

00:05:47,220 --> 00:05:55,200
the the for example so the for example

00:05:50,340 --> 00:05:58,800
is somewhere really hidden inside this

00:05:55,200 --> 00:06:02,100
thing so that's one word is its over

00:05:58,800 --> 00:06:03,960
here and it has an apply method because

00:06:02,100 --> 00:06:06,540
that's that's a lambda I could not

00:06:03,960 --> 00:06:09,960
really optimize it away so because we

00:06:06,540 --> 00:06:13,860
cannot do that and look at all these

00:06:09,960 --> 00:06:15,930
ugliness here so first apparently we

00:06:13,860 --> 00:06:18,420
have a rich in thing we have an angel

00:06:15,930 --> 00:06:21,030
extension that creates somehow arrange

00:06:18,420 --> 00:06:24,990
its calling some method of pre-death

00:06:21,030 --> 00:06:26,250
here passing it to zero and well if you

00:06:24,990 --> 00:06:28,920
look at the curve that method just

00:06:26,250 --> 00:06:32,190
returns the same value so apparently

00:06:28,920 --> 00:06:35,520
nice call it and then we call it for

00:06:32,190 --> 00:06:37,080
which here with a nubbly name and we

00:06:35,520 --> 00:06:38,800
were passing in an otherwise function in

00:06:37,080 --> 00:06:42,280
there and that animist

00:06:38,800 --> 00:06:42,610
is actually doing the inside of the for

00:06:42,280 --> 00:06:45,699
loop

00:06:42,610 --> 00:06:49,030
right but it's even worse because we

00:06:45,699 --> 00:06:51,159
have two box that are value it's the

00:06:49,030 --> 00:06:53,440
second object right you can you can see

00:06:51,159 --> 00:06:56,560
it here it's a located it creates an

00:06:53,440 --> 00:06:58,539
object which is some intra it's

00:06:56,560 --> 00:07:03,370
basically a mutable box for an int

00:06:58,539 --> 00:07:05,409
inside and it's it's accessing the field

00:07:03,370 --> 00:07:08,379
of that thing every time you you try to

00:07:05,409 --> 00:07:10,120
update it and read it so this is pretty

00:07:08,379 --> 00:07:12,669
bad and we can understand pretty easily

00:07:10,120 --> 00:07:17,319
why this code is ten times slower than

00:07:12,669 --> 00:07:20,159
the the while loop right so now if we

00:07:17,319 --> 00:07:26,110
look at the version weight the optimizer

00:07:20,159 --> 00:07:29,409
it's actually much better give me one

00:07:26,110 --> 00:07:30,969
second to find it okay so this is same

00:07:29,409 --> 00:07:32,530
as before that's the while loop version

00:07:30,969 --> 00:07:34,419
right so it did not really change

00:07:32,530 --> 00:07:39,069
because there was not much to optimize

00:07:34,419 --> 00:07:40,569
from there but let's look at the other

00:07:39,069 --> 00:07:43,509
one which is still an anonymous function

00:07:40,569 --> 00:07:45,789
so that's you know in an anonymous class

00:07:43,509 --> 00:07:48,190
but now we have a completely different

00:07:45,789 --> 00:07:53,259
thing so we have a huge blob of code is

00:07:48,190 --> 00:07:55,659
completely illegible here don't worry

00:07:53,259 --> 00:07:58,330
we'll you wrote about it the important

00:07:55,659 --> 00:08:02,199
thing is here we have a good old while

00:07:58,330 --> 00:08:04,779
loop so it's still not completely

00:08:02,199 --> 00:08:06,909
optimal which explains the difference we

00:08:04,779 --> 00:08:08,909
have this VAR count here that is

00:08:06,909 --> 00:08:12,849
incremented here but is otherwise

00:08:08,909 --> 00:08:17,050
completely unused so it serves no

00:08:12,849 --> 00:08:19,120
purpose whatsoever so but the optimizer

00:08:17,050 --> 00:08:20,979
could not get rid of it turns out there

00:08:19,120 --> 00:08:23,560
is the closure compiler can actually

00:08:20,979 --> 00:08:28,060
remove that but we're not using closure

00:08:23,560 --> 00:08:31,779
here so and there is still this this

00:08:28,060 --> 00:08:34,539
complete this complicated header here

00:08:31,779 --> 00:08:37,510
which is checking to the bounds of the

00:08:34,539 --> 00:08:39,430
range or right in the city so blob but

00:08:37,510 --> 00:08:43,229
that's that's outside of the loop and

00:08:39,430 --> 00:08:47,589
it's only doing a simple simple stuff so

00:08:43,229 --> 00:08:52,410
what happened right we can see that we

00:08:47,589 --> 00:08:57,010
had codes with a very ugly

00:08:52,410 --> 00:08:58,870
box of an interest for our and calling

00:08:57,010 --> 00:09:00,640
things and calling it for which method

00:08:58,870 --> 00:09:06,670
and giving it an anonymous function and

00:09:00,640 --> 00:09:09,130
all of that became a while so two

00:09:06,670 --> 00:09:11,880
explanations either the optimizer knows

00:09:09,130 --> 00:09:16,959
that this is range for reach and

00:09:11,880 --> 00:09:19,089
magically just something about it or or

00:09:16,959 --> 00:09:22,990
it doesn't and it's just smart enough in

00:09:19,089 --> 00:09:24,430
some other ways to to get rid of it the

00:09:22,990 --> 00:09:26,770
correct answer of course is the second

00:09:24,430 --> 00:09:29,500
one it's it smart it smart enough to

00:09:26,770 --> 00:09:32,920
remove all of that all of that stuff so

00:09:29,500 --> 00:09:35,020
it's going to in line for each in line

00:09:32,920 --> 00:09:37,540
the closure inside get rid of the box

00:09:35,020 --> 00:09:40,149
because now it's completely visible in

00:09:37,540 --> 00:09:43,390
the same scope we move some dead codes

00:09:40,149 --> 00:09:51,310
and and eventually get get to this to

00:09:43,390 --> 00:09:53,770
this form okay so that's one thing so

00:09:51,310 --> 00:09:58,209
that was that was a good result right we

00:09:53,770 --> 00:09:59,860
had something that that we had a manual

00:09:58,209 --> 00:10:01,600
while loop that you don't want to write

00:09:59,860 --> 00:10:05,740
in Scala you want to do the idiomatic

00:10:01,600 --> 00:10:07,810
for range but you typically cannot use

00:10:05,740 --> 00:10:09,970
it because too slow if you want

00:10:07,810 --> 00:10:11,529
performance but but here you can because

00:10:09,970 --> 00:10:13,930
discussion something miser is just just

00:10:11,529 --> 00:10:16,510
going to remove it so let's look at the

00:10:13,930 --> 00:10:18,610
something bad now all right something

00:10:16,510 --> 00:10:22,089
that that even the star juice atomizer

00:10:18,610 --> 00:10:23,770
cannot get rid of and that's Long's so

00:10:22,089 --> 00:10:28,600
the previous example was using ends

00:10:23,770 --> 00:10:33,100
right but here we're going to just just

00:10:28,600 --> 00:10:34,839
use Long's instead so in in Scala JVM

00:10:33,100 --> 00:10:36,850
that's not a big deal right int or long

00:10:34,839 --> 00:10:39,329
I mean anyway it fits in a 64-bit

00:10:36,850 --> 00:10:39,329
registers

00:10:39,370 --> 00:10:46,329
however in JavaScript you may know that

00:10:42,730 --> 00:10:49,690
there is no such thing as a 64-bit

00:10:46,329 --> 00:10:52,320
integer so as a matter of fact there is

00:10:49,690 --> 00:10:55,770
no such thing as a 32-bit integer either

00:10:52,320 --> 00:10:59,079
there is our only doubles in JavaScript

00:10:55,770 --> 00:11:02,440
but it turns out that there is a pretty

00:10:59,079 --> 00:11:03,980
compact and encoding of signed 32-bit

00:11:02,440 --> 00:11:05,840
integers angels

00:11:03,980 --> 00:11:08,930
that virtual machines are very good at

00:11:05,840 --> 00:11:11,570
optimizing actually better than normal

00:11:08,930 --> 00:11:13,850
operations however for longs that just

00:11:11,570 --> 00:11:14,840
does not exist so how do what do you do

00:11:13,850 --> 00:11:18,380
about lungs

00:11:14,840 --> 00:11:22,430
well you implement them like we really

00:11:18,380 --> 00:11:27,680
have library code implementing addition

00:11:22,430 --> 00:11:32,810
on lungs and that's not so good so let's

00:11:27,680 --> 00:11:43,550
look at the benchmarks for this one it's

00:11:32,810 --> 00:11:46,040
colossi we compile let's run so here for

00:11:43,550 --> 00:11:47,570
some reason the for loop is faster than

00:11:46,040 --> 00:11:52,070
the while loop there's probably an

00:11:47,570 --> 00:11:54,950
artifact but the important thing to note

00:11:52,070 --> 00:11:59,600
is look at the absolute numbers here we

00:11:54,950 --> 00:12:03,850
had 0.12 and 0.09 the same code just

00:11:59,600 --> 00:12:07,010
replacing ends by lungs it's now 18 and

00:12:03,850 --> 00:12:13,760
even with the optimizer is still 10 and

00:12:07,010 --> 00:12:17,360
11 compared to 0.9 0.09 so that's that's

00:12:13,760 --> 00:12:22,420
how much slower that's a full hundred

00:12:17,360 --> 00:12:25,150
times slower so Long's are really bad

00:12:22,420 --> 00:12:27,530
don't use Long's

00:12:25,150 --> 00:12:30,530
except except of course when you need

00:12:27,530 --> 00:12:33,230
them but if if they're in performance

00:12:30,530 --> 00:12:36,230
critical codes really that that's a bad

00:12:33,230 --> 00:12:40,810
thing to do to use so the question now

00:12:36,230 --> 00:12:43,520
is can we do better in the future well

00:12:40,810 --> 00:12:46,370
sort of I mean we already did quite a

00:12:43,520 --> 00:12:49,130
lot even though it's pretty bad it was

00:12:46,370 --> 00:12:52,190
worse before we optimized the lungs

00:12:49,130 --> 00:12:54,020
quite heavily by hand with all full code

00:12:52,190 --> 00:12:58,100
that you don't want to read even in

00:12:54,020 --> 00:13:00,200
Scala so it's much better than before

00:12:58,100 --> 00:13:02,180
it's still it's still quite slow so wait

00:13:00,200 --> 00:13:02,810
we could but there are things we can do

00:13:02,180 --> 00:13:04,730
in the future

00:13:02,810 --> 00:13:07,400
eventually we'll get we'll get around to

00:13:04,730 --> 00:13:09,560
do to do them but it's not going to

00:13:07,400 --> 00:13:10,999
happen anytime soon

00:13:09,560 --> 00:13:16,670
don't have an infinite amount of time

00:13:10,999 --> 00:13:20,120
and fortunately okay let's look at a

00:13:16,670 --> 00:13:25,939
more fun example that was sort of

00:13:20,120 --> 00:13:28,009
introductory this in SCADA you don't

00:13:25,939 --> 00:13:31,129
really use wire loops you don't you

00:13:28,009 --> 00:13:33,920
don't really use for ranges either or

00:13:31,129 --> 00:13:38,629
most of the time the thing that you do

00:13:33,920 --> 00:13:41,600
all the time is called map right who

00:13:38,629 --> 00:13:44,499
programs in Scala and does not use map

00:13:41,600 --> 00:13:44,499
at least once a day

00:13:44,529 --> 00:13:51,829
right that's civil person okay but on

00:13:49,069 --> 00:13:54,379
maybe you're all sleep so who program in

00:13:51,829 --> 00:13:58,600
Scala and uses at least one is one that

00:13:54,379 --> 00:14:02,540
every day okay you're not asleep good

00:13:58,600 --> 00:14:06,170
so here I have three different versions

00:14:02,540 --> 00:14:10,220
of a map on an array so the actual I'm

00:14:06,170 --> 00:14:12,800
actually doing two maps in a row one

00:14:10,220 --> 00:14:15,829
with just some computation one win

00:14:12,800 --> 00:14:17,290
another computation over here and I'm

00:14:15,829 --> 00:14:21,230
doing that in three different ways

00:14:17,290 --> 00:14:22,579
the last way is the manual thing that

00:14:21,230 --> 00:14:26,180
uses the while loop that's for a

00:14:22,579 --> 00:14:30,649
baseline that's what that that's that's

00:14:26,180 --> 00:14:33,259
essentially what you get if you optimize

00:14:30,649 --> 00:14:34,759
it by a hand in a sense right so this

00:14:33,259 --> 00:14:37,819
this is our baseline this is what we

00:14:34,759 --> 00:14:39,529
want you to achieve in a sense but

00:14:37,819 --> 00:14:43,129
that's definitely not what we want to

00:14:39,529 --> 00:14:45,949
write as a code so of course you see

00:14:43,129 --> 00:14:48,319
that since I have two maps here I have

00:14:45,949 --> 00:14:50,209
also in the manual version done two

00:14:48,319 --> 00:14:53,059
different while loops one that performs

00:14:50,209 --> 00:14:56,540
the first map and one that performs a

00:14:53,059 --> 00:14:59,929
second second map right and then I have

00:14:56,540 --> 00:15:04,370
two versions of actually calling map but

00:14:59,929 --> 00:15:06,800
that are is slightly different so let's

00:15:04,370 --> 00:15:09,019
look at the second one first and this is

00:15:06,800 --> 00:15:11,649
this is the one that you would expect

00:15:09,019 --> 00:15:15,679
this this is the Scala collections map

00:15:11,649 --> 00:15:17,720
so even though I have an in here for the

00:15:15,679 --> 00:15:19,819
yeah that's probably too small for you

00:15:17,720 --> 00:15:22,579
to read so it says that in is a

00:15:19,819 --> 00:15:24,170
JavaScript array so because we

00:15:22,579 --> 00:15:26,149
katia so you can have childhood types

00:15:24,170 --> 00:15:30,199
and whatnot but whatever is busy an

00:15:26,149 --> 00:15:32,929
array but if you when we call math here

00:15:30,199 --> 00:15:35,779
it's not calling the JavaScript map we

00:15:32,929 --> 00:15:38,889
have set up the types so that when we

00:15:35,779 --> 00:15:42,319
call map we're actually calling this

00:15:38,889 --> 00:15:44,209
traversable like dot map function which

00:15:42,319 --> 00:15:46,819
takes a candle from which creates a

00:15:44,209 --> 00:15:50,119
builder with the Scythians then coils a

00:15:46,819 --> 00:15:55,369
for each loop on this thing called the

00:15:50,119 --> 00:15:57,829
plus equal version does this so this for

00:15:55,369 --> 00:15:59,749
which call is basically like a more fake

00:15:57,829 --> 00:16:02,149
word pieces it's definitely a

00:15:59,749 --> 00:16:04,489
polymorphic dispatch because there are

00:16:02,149 --> 00:16:08,779
many different reversible likes so this

00:16:04,489 --> 00:16:12,439
is really bad and that's what you get on

00:16:08,779 --> 00:16:15,980
the scholar JVM most of the time the

00:16:12,439 --> 00:16:18,079
other one is it looks the same except

00:16:15,980 --> 00:16:21,019
that I have two casts that are a bit

00:16:18,079 --> 00:16:23,480
weird I'm casting to a type called Jas

00:16:21,019 --> 00:16:27,199
dynamic and and then I'm casting back to

00:16:23,480 --> 00:16:30,139
a j/s array I'm not going to enter into

00:16:27,199 --> 00:16:32,689
details of why it does what it does you

00:16:30,139 --> 00:16:36,230
just have to believe me that this forces

00:16:32,689 --> 00:16:39,259
scaligeri has to call the map the

00:16:36,230 --> 00:16:43,279
JavaScript map function on a JavaScript

00:16:39,259 --> 00:16:47,809
array because JavaScript has a native

00:16:43,279 --> 00:16:49,970
map on on its native race so you would

00:16:47,809 --> 00:16:55,850
expect that to be reasonably fast right

00:16:49,970 --> 00:17:00,399
because it's it's native so let's see

00:16:55,850 --> 00:17:00,399
little bit see if it's if it's fast

00:17:00,939 --> 00:17:09,159
scalice you compiling good job let's

00:17:06,139 --> 00:17:12,860
first make it non optimized version so

00:17:09,159 --> 00:17:14,959
first thing first the manual version is

00:17:12,860 --> 00:17:17,089
fast okay let's get the Scala

00:17:14,959 --> 00:17:18,649
collections map is is bad all right

00:17:17,089 --> 00:17:20,750
because that's without optimizer you

00:17:18,649 --> 00:17:23,630
have all these reversible legs for each

00:17:20,750 --> 00:17:27,230
plus equal it's at least ten different

00:17:23,630 --> 00:17:30,289
in directions before you get to actually

00:17:27,230 --> 00:17:32,360
call the function that does the map and

00:17:30,289 --> 00:17:35,690
put elements in the array so that's

00:17:32,360 --> 00:17:41,330
really bad but but let's look at the J's

00:17:35,690 --> 00:17:43,280
mad native in quotes it's still four

00:17:41,330 --> 00:17:48,650
times slower than the manual version

00:17:43,280 --> 00:17:50,540
right so okay well it's still faster

00:17:48,650 --> 00:17:52,820
than the scholar collections map so it's

00:17:50,540 --> 00:17:56,390
not too bad right so obviously Josh

00:17:52,820 --> 00:17:59,960
which is doing something right here but

00:17:56,390 --> 00:18:04,280
then let's look at what what happens if

00:17:59,960 --> 00:18:08,810
we do have the optimizer oh that's a

00:18:04,280 --> 00:18:12,830
different kind of a picture right

00:18:08,810 --> 00:18:15,290
so here the my old time busily remain

00:18:12,830 --> 00:18:19,130
the same the stock collections map

00:18:15,290 --> 00:18:22,070
however grips it was completely

00:18:19,130 --> 00:18:26,030
optimized away it's as fast as the

00:18:22,070 --> 00:18:27,740
manual version so that that that's

00:18:26,030 --> 00:18:32,270
pretty good and the javascript native

00:18:27,740 --> 00:18:34,760
map well it's still lagging behind it's

00:18:32,270 --> 00:18:39,350
still four times slower than these two

00:18:34,760 --> 00:18:42,140
versions so what happens well remember

00:18:39,350 --> 00:18:45,400
we don't trust the benchmarks the only

00:18:42,140 --> 00:18:50,060
thing we really trust is generated code

00:18:45,400 --> 00:18:51,740
so let's look at generated code and try

00:18:50,060 --> 00:18:56,840
to figure out what the main function

00:18:51,740 --> 00:19:00,020
arrives here so that's that's the double

00:18:56,840 --> 00:19:01,610
while reasonable we can also look at

00:19:00,020 --> 00:19:03,140
this guy

00:19:01,610 --> 00:19:05,570
no that's the scallop election map I

00:19:03,140 --> 00:19:09,710
don't want to see that one yet I want to

00:19:05,570 --> 00:19:12,020
have a look at the JavaScript version so

00:19:09,710 --> 00:19:14,240
the JavaScript version is pretty much

00:19:12,020 --> 00:19:16,700
what you would write by hand in

00:19:14,240 --> 00:19:18,470
JavaScript right assuming you're a

00:19:16,700 --> 00:19:21,020
functional programmer and you use math

00:19:18,470 --> 00:19:23,390
and not you know a for loop every time

00:19:21,020 --> 00:19:25,640
so you're basically calling map which is

00:19:23,390 --> 00:19:28,310
a JavaScript function you give it an

00:19:25,640 --> 00:19:30,560
anonymous JavaScript function as a

00:19:28,310 --> 00:19:32,030
parameter and you do something and then

00:19:30,560 --> 00:19:35,720
you call map again and you do something

00:19:32,030 --> 00:19:37,640
else so that's I mean that's what you

00:19:35,720 --> 00:19:40,520
would write by hand in JavaScript so

00:19:37,640 --> 00:19:43,100
scholar GS did not make the javascript

00:19:40,520 --> 00:19:47,120
native map worse than it was

00:19:43,100 --> 00:19:53,850
right sorry we're not cheating here

00:19:47,120 --> 00:19:56,360
so what about this color collection is

00:19:53,850 --> 00:19:59,040
my provision well that one's really ugly

00:19:56,360 --> 00:20:01,590
we're not going to go through it

00:19:59,040 --> 00:20:03,450
completely but you can see that we we

00:20:01,590 --> 00:20:05,700
have some array herbs which is some

00:20:03,450 --> 00:20:10,380
implicit conversion on JavaScript arrays

00:20:05,700 --> 00:20:13,500
that taste in it you call we call map

00:20:10,380 --> 00:20:17,370
here and we give it a candle from which

00:20:13,500 --> 00:20:19,920
is this guy here which is I can build

00:20:17,370 --> 00:20:21,780
from for JavaScript arrays so you may

00:20:19,920 --> 00:20:24,360
not be familiar with can be from or

00:20:21,780 --> 00:20:26,400
maybe you are but it's a elaborate

00:20:24,360 --> 00:20:29,250
mechanism in the scale of collections

00:20:26,400 --> 00:20:32,370
library allows map to return the same

00:20:29,250 --> 00:20:33,840
type of element I mean the same the same

00:20:32,370 --> 00:20:35,790
type of collection so it's going to

00:20:33,840 --> 00:20:38,400
return a map even though there is only

00:20:35,790 --> 00:20:40,890
one J so even though there is only one

00:20:38,400 --> 00:20:42,630
single implementation of map and then in

00:20:40,890 --> 00:20:45,420
the middle of course you you give it the

00:20:42,630 --> 00:20:50,910
actual anonymous function which which

00:20:45,420 --> 00:20:54,360
does the inside of the work okay so that

00:20:50,910 --> 00:20:57,180
is is that me bad we can make it better

00:20:54,360 --> 00:21:00,570
we can we can actually go and look into

00:20:57,180 --> 00:21:04,560
this map function and but I don't want

00:21:00,570 --> 00:21:07,970
to scare you too much so we're not going

00:21:04,560 --> 00:21:11,730
to dive into those details so instead

00:21:07,970 --> 00:21:13,290
we're going to just look quickly at the

00:21:11,730 --> 00:21:21,390
generated code for the optimized version

00:21:13,290 --> 00:21:24,270
which is much much nicer but this time

00:21:21,390 --> 00:21:26,640
we're going to go directly to the Scala

00:21:24,270 --> 00:21:30,080
collections my version because the other

00:21:26,640 --> 00:21:33,870
two ones don't actually change much and

00:21:30,080 --> 00:21:36,930
here we go that looks that like that

00:21:33,870 --> 00:21:40,170
looks nice it's barely a while loop

00:21:36,930 --> 00:21:42,840
right so let's look at a few key

00:21:40,170 --> 00:21:45,780
ingredients we're creating first a Java

00:21:42,840 --> 00:21:48,090
scripts empty array for the results the

00:21:45,780 --> 00:21:50,010
result our way of the map we're

00:21:48,090 --> 00:21:52,530
initializing something to do two one

00:21:50,010 --> 00:21:54,000
we're fetching the length then we have

00:21:52,530 --> 00:21:57,300
this while loop here

00:21:54,000 --> 00:21:58,980
for every every iteration we get the

00:21:57,300 --> 00:22:01,230
elements which is here

00:21:58,980 --> 00:22:03,740
we're actually performing here this is

00:22:01,230 --> 00:22:06,060
this is the actual contents of the

00:22:03,740 --> 00:22:09,030
anonymous function that is given to map

00:22:06,060 --> 00:22:11,910
it this is right there and then we push

00:22:09,030 --> 00:22:14,490
directly to the destination array that's

00:22:11,910 --> 00:22:16,950
good and that we do basically the same

00:22:14,490 --> 00:22:19,170
thing right we create for the second map

00:22:16,950 --> 00:22:21,840
we have this this this thing so

00:22:19,170 --> 00:22:25,710
basically everything disappeared it's

00:22:21,840 --> 00:22:29,010
just the destination array and then we

00:22:25,710 --> 00:22:30,540
loop with the while loop and we call the

00:22:29,010 --> 00:22:32,640
anonymous function but it's actually

00:22:30,540 --> 00:22:34,530
being in lines also so it's not really a

00:22:32,640 --> 00:22:36,270
call it's just computation right there

00:22:34,530 --> 00:22:39,420
and then we push in the destination

00:22:36,270 --> 00:22:43,020
array and it's all gone so that'sthat's

00:22:39,420 --> 00:22:46,800
pretty cool we can see one thing it did

00:22:43,020 --> 00:22:52,320
not do well we still have to wire loops

00:22:46,800 --> 00:22:56,400
and that's I mean we're just calling two

00:22:52,320 --> 00:22:59,070
maps in a row ideally a very very smart

00:22:56,400 --> 00:23:02,310
atomizer it could just fuse the two maps

00:22:59,070 --> 00:23:05,460
into one map and to just in the inner

00:23:02,310 --> 00:23:07,230
computations it would do it inside one

00:23:05,460 --> 00:23:09,750
one single map one single right loop

00:23:07,230 --> 00:23:12,300
right here we still have to to create

00:23:09,750 --> 00:23:13,980
this intermediate array in the middle so

00:23:12,300 --> 00:23:19,460
that some mineralogist does not do for

00:23:13,980 --> 00:23:22,230
you it won't magically fuse successive

00:23:19,460 --> 00:23:25,740
operations on the collections and it's

00:23:22,230 --> 00:23:28,110
probably something it will never do for

00:23:25,740 --> 00:23:30,320
non obvious reasons unless we rewrite

00:23:28,110 --> 00:23:33,720
the collections library in a way that is

00:23:30,320 --> 00:23:42,930
more feasible for some definition of

00:23:33,720 --> 00:23:44,790
usable okay so that was for map which is

00:23:42,930 --> 00:23:47,880
good because as we saw it's something

00:23:44,790 --> 00:23:49,590
that we do like every day and it's it's

00:23:47,880 --> 00:23:53,450
visually as fast as the manual version

00:23:49,590 --> 00:23:53,450
so it couldn't hardly get better

00:23:56,440 --> 00:24:06,060
okay so now for something quite

00:24:00,430 --> 00:24:10,960
different we're going to look at trades

00:24:06,060 --> 00:24:15,520
so I have a trade foo which has a

00:24:10,960 --> 00:24:19,890
concrete methods bar and then I have a

00:24:15,520 --> 00:24:22,470
bunch of classes seven of them I think

00:24:19,890 --> 00:24:26,890
that all extends foo

00:24:22,470 --> 00:24:32,020
so on the JVM and on JavaScript you

00:24:26,890 --> 00:24:36,220
might know or not that this the Scala

00:24:32,020 --> 00:24:39,070
compiler is actually going to create a

00:24:36,220 --> 00:24:42,250
method which is called Bar in every

00:24:39,070 --> 00:24:44,560
single one of those classes so in the

00:24:42,250 --> 00:24:47,110
generated bytecode in Egypt generated

00:24:44,560 --> 00:24:49,810
JavaScript you will have a bar which

00:24:47,110 --> 00:24:51,640
really is a bridge to calling food at

00:24:49,810 --> 00:24:54,250
bar which is a static method at that

00:24:51,640 --> 00:24:57,610
point and then the same in all those

00:24:54,250 --> 00:25:00,340
classes with Scala 212 it's a bit

00:24:57,610 --> 00:25:06,820
different it uses default methods of

00:25:00,340 --> 00:25:09,340
Java 8 as much as possible on the JVM on

00:25:06,820 --> 00:25:12,940
Scala GS it basically does still the

00:25:09,340 --> 00:25:16,750
same thing in a different way but it's

00:25:12,940 --> 00:25:18,580
basically the same thing so that's good

00:25:16,750 --> 00:25:20,770
right because you get concrete methods

00:25:18,580 --> 00:25:24,940
in traits and I think we all love

00:25:20,770 --> 00:25:26,800
concrete methods and traits so but in

00:25:24,940 --> 00:25:27,720
terms of performance that's not really

00:25:26,800 --> 00:25:34,840
ideal

00:25:27,720 --> 00:25:37,480
so why well if I have this all thing

00:25:34,840 --> 00:25:40,540
which is an array of all these things

00:25:37,480 --> 00:25:45,390
and I'm busily creating a big random

00:25:40,540 --> 00:25:49,330
array of a mix a random mix of these

00:25:45,390 --> 00:25:52,300
ABCs and G's instances and the only

00:25:49,330 --> 00:25:54,670
thing I'm doing with those is basically

00:25:52,300 --> 00:25:56,590
calling the bar method everything else

00:25:54,670 --> 00:25:59,430
is just for the purpose of the benchmark

00:25:56,590 --> 00:26:04,180
but I'm basically calling the bar method

00:25:59,430 --> 00:26:08,040
and I mean there is only one bar method

00:26:04,180 --> 00:26:08,040
right it's it's this one

00:26:08,330 --> 00:26:13,740
but in fact there isn't there there's a

00:26:11,070 --> 00:26:15,750
bunch of them and and milk you're going

00:26:13,740 --> 00:26:18,390
to have a virtual dispatch basically on

00:26:15,750 --> 00:26:22,320
all these bridges so is it is it really

00:26:18,390 --> 00:26:23,970
bad I mean judge it's the JVM the Java

00:26:22,320 --> 00:26:25,740
subjects are pretty good right so they

00:26:23,970 --> 00:26:28,410
should they should be good at dealing

00:26:25,740 --> 00:26:31,860
with this stuff and and indeed in a

00:26:28,410 --> 00:26:34,320
sense they are if if we restrict or

00:26:31,860 --> 00:26:39,600
randomness to always return zero and

00:26:34,320 --> 00:26:42,420
hence always return an a what thing I

00:26:39,600 --> 00:26:51,990
forgot to do is of course change this

00:26:42,420 --> 00:26:56,670
guy here so here we're only going to

00:26:51,990 --> 00:27:00,650
look at at an optimized version first so

00:26:56,670 --> 00:27:00,650
this is a bit longer running benchmark

00:27:02,360 --> 00:27:12,570
yeah what's faster okay so so that

00:27:08,730 --> 00:27:15,510
that's good it's 390 it's pretty good

00:27:12,570 --> 00:27:17,040
and basically I'm jumping your head but

00:27:15,510 --> 00:27:19,650
the baseline is what the optimizer does

00:27:17,040 --> 00:27:24,540
which is 3/5 so that that's that's

00:27:19,650 --> 00:27:29,550
pretty reasonable so remember 390 we're

00:27:24,540 --> 00:27:32,100
just going to now so to change this 1

00:27:29,550 --> 00:27:34,980
into a 2 and now in this bigger way

00:27:32,100 --> 00:27:38,820
we've we have AIDS and we have these in

00:27:34,980 --> 00:27:43,500
a completely random pattern right so

00:27:38,820 --> 00:27:46,200
remember this 390 well it's going to not

00:27:43,500 --> 00:27:47,580
be 390 anymore now you can already see

00:27:46,200 --> 00:27:51,870
tens 8/9

00:27:47,580 --> 00:27:54,420
so that's 9.12 that's three times as

00:27:51,870 --> 00:27:59,640
slow because will basically change

00:27:54,420 --> 00:28:04,380
between always calling 8.4 to calling

00:27:59,640 --> 00:28:06,900
either a the bar or B that bar and the

00:28:04,380 --> 00:28:08,820
jets behind the JavaScript it behind

00:28:06,900 --> 00:28:12,540
scholar dress is not very good at this

00:28:08,820 --> 00:28:14,790
it it has now a choice between calling a

00:28:12,540 --> 00:28:17,040
dog bar and B that bar and has to check

00:28:14,790 --> 00:28:19,920
which one is the correct one before you

00:28:17,040 --> 00:28:20,669
can call it but this is fing a stupid

00:28:19,920 --> 00:28:22,950
because both

00:28:20,669 --> 00:28:25,019
these things then they then call the

00:28:22,950 --> 00:28:28,409
same method which is essentially food

00:28:25,019 --> 00:28:31,379
bar right so that that's that's bad but

00:28:28,409 --> 00:28:37,259
let's make it worse let's include all

00:28:31,379 --> 00:28:39,960
seven plus possible variations and now

00:28:37,259 --> 00:28:44,759
we can actually start waiting for the

00:28:39,960 --> 00:28:49,889
results of the benchmarks it's yeah

00:28:44,759 --> 00:28:52,200
that's turkey for you which is about

00:28:49,889 --> 00:28:54,299
three times as slow as before so we have

00:28:52,200 --> 00:28:56,730
some sub average around around thirty

00:28:54,299 --> 00:29:00,090
but it won't with the optimizer with the

00:28:56,730 --> 00:29:01,950
Scourge s atomizer is still still 3.43

00:29:00,090 --> 00:29:05,429
as it's been like since the beginning

00:29:01,950 --> 00:29:08,309
right so this is now we have a complete

00:29:05,429 --> 00:29:13,470
complete ten 10x difference between

00:29:08,309 --> 00:29:16,080
width and without the optimizer and the

00:29:13,470 --> 00:29:18,929
reason it's slower without the optimizer

00:29:16,080 --> 00:29:22,350
is as I explained that javascript en is

00:29:18,929 --> 00:29:24,330
not good at this game it suddenly has in

00:29:22,350 --> 00:29:25,559
front of it a multiple dispatch between

00:29:24,330 --> 00:29:28,739
seven different variations that's

00:29:25,559 --> 00:29:32,100
megamorph recall and it cannot in line

00:29:28,739 --> 00:29:33,779
anything is going to go into looking

00:29:32,100 --> 00:29:35,960
prototype chains and stuff and it's

00:29:33,779 --> 00:29:40,279
really slow and it's really bad

00:29:35,960 --> 00:29:42,419
however the version that is optimized is

00:29:40,279 --> 00:29:46,259
husband restage that stay the same

00:29:42,419 --> 00:29:50,759
across all variations of monomorphic buy

00:29:46,259 --> 00:29:53,700
more free mega morphic so how can there

00:29:50,759 --> 00:29:55,769
be what what is the optimizer doing here

00:29:53,700 --> 00:29:58,019
that that prevents this this huge

00:29:55,769 --> 00:30:01,499
degradation due to the metamorphic call

00:29:58,019 --> 00:30:08,759
on tracks well let's look at the codes

00:30:01,499 --> 00:30:10,529
so i love looking at the codes see we

00:30:08,759 --> 00:30:13,379
create an instance of each of those

00:30:10,529 --> 00:30:15,690
things right and then we have to code a

00:30:13,379 --> 00:30:17,789
benchmark and of course we're calling

00:30:15,690 --> 00:30:20,429
here the bar methods it has a funny name

00:30:17,789 --> 00:30:23,639
as always but it's basically calling the

00:30:20,429 --> 00:30:25,440
bar method in a while loop so it's

00:30:23,639 --> 00:30:28,590
reasonable

00:30:25,440 --> 00:30:32,039
the problem is what poor methods well

00:30:28,590 --> 00:30:34,410
might be able board or be the board or

00:30:32,039 --> 00:30:37,740
see that boy or did that boy

00:30:34,410 --> 00:30:39,870
but all of these if you if you're super

00:30:37,740 --> 00:30:43,800
attentive you can see the D here which

00:30:39,870 --> 00:30:45,510
changes but otherwise this this content

00:30:43,800 --> 00:30:48,270
here is exactly the same in all those

00:30:45,510 --> 00:30:53,340
variations and all of them they call

00:30:48,270 --> 00:30:56,190
this function here yeah here is its

00:30:53,340 --> 00:31:00,660
definition which is basically the

00:30:56,190 --> 00:31:06,300
contents of this of this matter right so

00:31:00,660 --> 00:31:14,880
with the optimizer what changes well try

00:31:06,300 --> 00:31:16,950
to figure it out we still have let's see

00:31:14,880 --> 00:31:24,780
no there is no main ve it septum eyes

00:31:16,950 --> 00:31:25,920
away name that's not ok there you are ok

00:31:24,780 --> 00:31:29,190
so what changed

00:31:25,920 --> 00:31:34,380
so here directly in the wire loop we

00:31:29,190 --> 00:31:39,690
have this giant name which is a direct

00:31:34,380 --> 00:31:41,610
call to to this method which is exactly

00:31:39,690 --> 00:31:43,920
the same as before it's this fool it's

00:31:41,610 --> 00:31:47,910
Rita bar it's its implementation and

00:31:43,920 --> 00:31:50,790
we've completely bypassed this this

00:31:47,910 --> 00:31:51,360
bridges right so remember we had a that

00:31:50,790 --> 00:31:54,030
boy

00:31:51,360 --> 00:31:56,490
Geeta bar and so Jesus bar and all of

00:31:54,030 --> 00:31:58,980
that is gone every if we if we look if

00:31:56,490 --> 00:32:01,230
we even look in the entire file we

00:31:58,980 --> 00:32:06,110
cannot find a bar anymore it's just just

00:32:01,230 --> 00:32:09,690
gone and the reason it can do this is

00:32:06,110 --> 00:32:13,140
what I call well you pretty guessed it

00:32:09,690 --> 00:32:16,680
from the name of this method here it's

00:32:13,140 --> 00:32:19,440
called what I call multi inlining that's

00:32:16,680 --> 00:32:21,270
very scholar specific optimization

00:32:19,440 --> 00:32:23,820
specifically designed for these concrete

00:32:21,270 --> 00:32:27,630
methods and trades that if you're in

00:32:23,820 --> 00:32:29,790
front of a polymorphic call like you're

00:32:27,630 --> 00:32:32,970
calling one of these bar methods but you

00:32:29,790 --> 00:32:34,290
don't know which one but you can

00:32:32,970 --> 00:32:35,040
actually see that they're all doing the

00:32:34,290 --> 00:32:37,620
same thing

00:32:35,040 --> 00:32:39,480
well doesn't really matter which one

00:32:37,620 --> 00:32:41,340
you're going to call in the end right so

00:32:39,480 --> 00:32:44,610
you can just pick one and then line it

00:32:41,340 --> 00:32:46,060
and completely disregards all of the

00:32:44,610 --> 00:32:47,410
other variations

00:32:46,060 --> 00:32:49,660
and that's really what this colleges

00:32:47,410 --> 00:32:53,140
optimizer is doing here and that's a

00:32:49,660 --> 00:32:55,570
very important optimization for for

00:32:53,140 --> 00:32:59,380
typical Scala codes because it's it come

00:32:55,570 --> 00:33:01,600
most concrete methods in trades are

00:32:59,380 --> 00:33:04,780
actually never overridden right so if

00:33:01,600 --> 00:33:06,370
you do override the methods in one or

00:33:04,780 --> 00:33:08,440
more of these classes then it doesn't

00:33:06,370 --> 00:33:09,820
work anymore because then of course is

00:33:08,440 --> 00:33:12,160
that bar is not going to do the same

00:33:09,820 --> 00:33:14,290
thing as be the bar and so well you

00:33:12,160 --> 00:33:21,700
cannot just pick one in alliance that I

00:33:14,290 --> 00:33:24,520
would be really wrong okay so let's

00:33:21,700 --> 00:33:32,410
let's just do a show of hands here who

00:33:24,520 --> 00:33:34,540
is still with me okay well I still have

00:33:32,410 --> 00:33:36,730
a couple examples we're probably going

00:33:34,540 --> 00:33:39,640
to go a little bit faster on these ones

00:33:36,730 --> 00:33:44,290
now that you've got there the rhythm of

00:33:39,640 --> 00:33:47,050
things we're doing so a very very very

00:33:44,290 --> 00:33:52,630
very important optimization is closure

00:33:47,050 --> 00:33:57,670
of elimination so it goes back to the

00:33:52,630 --> 00:34:00,100
map why is map slow if you don't advise

00:33:57,670 --> 00:34:03,220
it well because you're calling a map

00:34:00,100 --> 00:34:05,770
function you're giving it a closure a

00:34:03,220 --> 00:34:08,500
lambda write an anonymous function and

00:34:05,770 --> 00:34:11,950
map is going to call that lambda the

00:34:08,500 --> 00:34:14,170
problem is you you're calling Matt from

00:34:11,950 --> 00:34:17,170
many different places in your codes with

00:34:14,170 --> 00:34:20,520
many different lambdas and that means

00:34:17,170 --> 00:34:26,430
the call to the lambda inside the map is

00:34:20,520 --> 00:34:29,020
basically like a morphic and slow so we

00:34:26,430 --> 00:34:32,260
we're very with the optimizers tries

00:34:29,020 --> 00:34:34,690
very hard to inline map inside your code

00:34:32,260 --> 00:34:36,850
so that you can inline the lambda also

00:34:34,690 --> 00:34:39,160
inside the inline version of map to

00:34:36,850 --> 00:34:42,100
remove that thing to remove that closure

00:34:39,160 --> 00:34:44,410
completely so here we're going to look

00:34:42,100 --> 00:34:46,210
at just closure elimination the basic

00:34:44,410 --> 00:34:47,560
version without map and all the can deal

00:34:46,210 --> 00:34:50,640
from so we can actually have a closer

00:34:47,560 --> 00:34:54,850
look at what it what what it does really

00:34:50,640 --> 00:34:56,320
so I have this custom-made loop so that

00:34:54,850 --> 00:34:58,520
that's also to show that it's not

00:34:56,320 --> 00:35:00,470
because it's map right I mean

00:34:58,520 --> 00:35:01,910
the optimizer doesn't know about the

00:35:00,470 --> 00:35:04,010
collections map function it's not

00:35:01,910 --> 00:35:07,099
special in any way it's not even

00:35:04,010 --> 00:35:10,460
annotated with 89 it's just as you

00:35:07,099 --> 00:35:13,490
restrict to internet so it ways for you

00:35:10,460 --> 00:35:14,869
your functions to so here I have a loop

00:35:13,490 --> 00:35:17,450
method which takes function its

00:35:14,869 --> 00:35:19,310
implementation is stupid as just a wire

00:35:17,450 --> 00:35:21,830
loop that calls the function right I

00:35:19,310 --> 00:35:23,420
have another version which i've called

00:35:21,830 --> 00:35:26,180
looper boards for reasons that will

00:35:23,420 --> 00:35:28,400
become clear later which is even

00:35:26,180 --> 00:35:31,130
stupider because that one does the same

00:35:28,400 --> 00:35:33,800
thing but in two steps at first does one

00:35:31,130 --> 00:35:36,020
wire loop until the middle of it and

00:35:33,800 --> 00:35:39,890
then the second wire loop until the end

00:35:36,020 --> 00:35:41,930
so that's kind of stupid the key

00:35:39,890 --> 00:35:45,589
difference between those two things is

00:35:41,930 --> 00:35:47,990
that is calling F lexically twice right

00:35:45,589 --> 00:35:52,640
you see that we have we have two

00:35:47,990 --> 00:35:55,040
different texts your calls to toodle to

00:35:52,640 --> 00:35:58,730
the lambda F and that that will change

00:35:55,040 --> 00:36:01,580
things so here we're just going to look

00:35:58,730 --> 00:36:03,050
at the optimization I'm not really

00:36:01,580 --> 00:36:07,359
interested in an optimized version

00:36:03,050 --> 00:36:12,460
anyway that's the only all benchmarks I

00:36:07,359 --> 00:36:12,460
forgot to change that guy

00:36:15,160 --> 00:36:17,880
again

00:36:19,850 --> 00:36:29,390
compiling we love Scala okay that's bad

00:36:26,120 --> 00:36:33,800
so this is without the optimizer with

00:36:29,390 --> 00:36:39,350
don't look at it it's okay so with the

00:36:33,800 --> 00:36:42,890
optimizer we have so what we see here is

00:36:39,350 --> 00:36:46,610
the first version of the so we have to

00:36:42,890 --> 00:36:49,520
basically sorry that's not the code I

00:36:46,610 --> 00:36:50,870
want to show so these are the loop

00:36:49,520 --> 00:36:53,000
method but the actual code when

00:36:50,870 --> 00:36:58,360
benchmarking is basically calling loop

00:36:53,000 --> 00:37:02,150
twice twice well specifically to prevent

00:36:58,360 --> 00:37:03,620
well whatever degradation and here we're

00:37:02,150 --> 00:37:04,820
just doing exactly the same thing but

00:37:03,620 --> 00:37:07,580
we're calling loop abort

00:37:04,820 --> 00:37:10,970
which that's the same thing right but we

00:37:07,580 --> 00:37:14,330
optimizer the first one which is not a

00:37:10,970 --> 00:37:17,270
loop abort is significantly faster than

00:37:14,330 --> 00:37:20,600
than the one where it's aborted for some

00:37:17,270 --> 00:37:22,490
reason for some definition of aborted so

00:37:20,600 --> 00:37:23,690
let's look at the code to see what was

00:37:22,490 --> 00:37:28,430
the difference but we're going to

00:37:23,690 --> 00:37:29,720
directly to the optimized version okay

00:37:28,430 --> 00:37:38,300
test closure

00:37:29,720 --> 00:37:51,070
Alain where are you here so this is the

00:37:38,300 --> 00:37:58,010
one wait wait I lost myself okay this is

00:37:51,070 --> 00:37:58,730
one guy so this is the one with loop

00:37:58,010 --> 00:38:00,650
abort

00:37:58,730 --> 00:38:04,300
which is what you would in a sense

00:38:00,650 --> 00:38:07,010
expect it did not do anything special

00:38:04,300 --> 00:38:10,190
it's just calling loop aborts as

00:38:07,010 --> 00:38:13,220
expected it's giving it an anonymous

00:38:10,190 --> 00:38:14,960
function that does whatever it's

00:38:13,220 --> 00:38:17,270
supposed to do and then it's calling

00:38:14,960 --> 00:38:23,030
again loop abort with another anonymous

00:38:17,270 --> 00:38:25,420
function so we're interested in seeing

00:38:23,030 --> 00:38:25,420
what

00:38:25,569 --> 00:38:34,130
so going back here and looking at the

00:38:31,039 --> 00:38:36,890
version two which is the one with the

00:38:34,130 --> 00:38:39,199
loop which is not aborted for again some

00:38:36,890 --> 00:38:42,650
definition of aborted and here we have

00:38:39,199 --> 00:38:44,569
some languages and expectedly good which

00:38:42,650 --> 00:38:47,779
is we basically have two while loops so

00:38:44,569 --> 00:38:50,839
one for each call to loop right so here

00:38:47,779 --> 00:38:52,819
in this case this is the case where the

00:38:50,839 --> 00:38:55,489
optimizer did its good they did a good

00:38:52,819 --> 00:38:57,949
job it's it's completely annoying to

00:38:55,489 --> 00:39:01,699
call to loop it in line the lambda it's

00:38:57,949 --> 00:39:04,910
all gone but in the other case it did

00:39:01,699 --> 00:39:09,529
not and the only difference was really

00:39:04,910 --> 00:39:11,329
that loop abort had this funny thing of

00:39:09,529 --> 00:39:17,719
doing two different while loops and

00:39:11,329 --> 00:39:19,999
calling twice F so here I'm talking a

00:39:17,719 --> 00:39:22,459
little bit about the heuristics that the

00:39:19,999 --> 00:39:24,469
scholar J's optimizer uses to decide

00:39:22,459 --> 00:39:28,729
whether to inline and optimize things or

00:39:24,469 --> 00:39:32,989
whether not to and one key one key

00:39:28,729 --> 00:39:37,640
heuristics is if you call a method which

00:39:32,989 --> 00:39:40,249
is big don't inline it but an even more

00:39:37,640 --> 00:39:42,949
important heuristic is if you're calling

00:39:40,249 --> 00:39:44,079
a method but one of the parameters is a

00:39:42,949 --> 00:39:47,509
lambda

00:39:44,079 --> 00:39:48,949
please try very hard to inline it anyway

00:39:47,509 --> 00:39:53,959
even if it's big

00:39:48,949 --> 00:39:58,009
so here loop is big but we're calling it

00:39:53,959 --> 00:40:01,009
at this point here with an anonymous

00:39:58,009 --> 00:40:02,989
function and that that's a very strong

00:40:01,009 --> 00:40:05,259
incentive for the scholar jason similar

00:40:02,989 --> 00:40:07,669
to try very hard to inline loop

00:40:05,259 --> 00:40:10,339
precisely because it's trying to get rid

00:40:07,669 --> 00:40:11,719
of this this map problem right that the

00:40:10,339 --> 00:40:14,779
problem that you're calling and methods

00:40:11,719 --> 00:40:17,509
from various different places and from

00:40:14,779 --> 00:40:21,109
each of these pastes you'll be giving a

00:40:17,509 --> 00:40:23,719
different lambda so here it's going to

00:40:21,109 --> 00:40:26,539
inline loop and then try to inline the

00:40:23,719 --> 00:40:30,049
closure inside the loop and it works it

00:40:26,539 --> 00:40:31,999
works but then the question is as why

00:40:30,049 --> 00:40:33,769
doesn't it do the same thing for loop

00:40:31,999 --> 00:40:35,390
AdWords because the same thing right

00:40:33,769 --> 00:40:35,710
loop abort is a big function but we're

00:40:35,390 --> 00:40:38,890
giving

00:40:35,710 --> 00:40:40,630
it's a closure a lambda so it to try to

00:40:38,890 --> 00:40:45,369
inline it right and it doesn't

00:40:40,630 --> 00:40:49,060
apparently well it actually did try it

00:40:45,369 --> 00:40:52,630
did try but then it came it came in

00:40:49,060 --> 00:40:56,200
front of a problem here because it saw

00:40:52,630 --> 00:40:59,560
the call to F which is kids it's it's in

00:40:56,200 --> 00:41:04,180
lines the lambda inside that call but

00:40:59,560 --> 00:41:07,510
then later it does the same thing so it

00:41:04,180 --> 00:41:09,369
calls F again and that's a problem

00:41:07,510 --> 00:41:11,530
because now you have to in line the

00:41:09,369 --> 00:41:13,900
closure a second time if your codes and

00:41:11,530 --> 00:41:18,790
that means you're duplicating the body

00:41:13,900 --> 00:41:21,250
of your lambda and it might not be a

00:41:18,790 --> 00:41:23,920
problem all the time but you know it's

00:41:21,250 --> 00:41:27,089
heuristics and one of the heuristics is

00:41:23,920 --> 00:41:31,599
if you have two in line lambda twice

00:41:27,089 --> 00:41:34,300
just bail out it's not worth it so it's

00:41:31,599 --> 00:41:37,420
going to go back in time revert the

00:41:34,300 --> 00:41:39,250
decision it made to inline loop loop

00:41:37,420 --> 00:41:41,980
abort because it was giving in lambda

00:41:39,250 --> 00:41:43,660
it's just it just doesn't it's not worth

00:41:41,980 --> 00:41:46,030
it anymore because it's not going to be

00:41:43,660 --> 00:41:48,400
able to get rid of the lambda it has to

00:41:46,030 --> 00:41:51,970
duplicate it so that's not good and so

00:41:48,400 --> 00:41:54,820
it completely completely aborts all

00:41:51,970 --> 00:41:59,280
these optimization and that's finally

00:41:54,820 --> 00:42:04,089
the explanation for this loop abort name

00:41:59,280 --> 00:42:06,339
so I have a few minutes left so yeah the

00:42:04,089 --> 00:42:08,170
key thing to remember here is if you

00:42:06,339 --> 00:42:11,170
want your methods your higher order

00:42:08,170 --> 00:42:17,740
method to be in lines don't call the

00:42:11,170 --> 00:42:21,990
lander twice or or you know I mean if

00:42:17,740 --> 00:42:24,869
you have to you have to but try not to

00:42:21,990 --> 00:42:28,540
so I think I'll just skip over that one

00:42:24,869 --> 00:42:32,530
it's it's color replacement aka stack

00:42:28,540 --> 00:42:34,540
allocation bottom line is doubles if

00:42:32,530 --> 00:42:37,300
they're local to a method they disappear

00:42:34,540 --> 00:42:40,420
just become two different variables but

00:42:37,300 --> 00:42:42,609
I kind of expected I would not have the

00:42:40,420 --> 00:42:44,650
time to look at this one and indeed I

00:42:42,609 --> 00:42:48,240
don't so I look at one last example

00:42:44,650 --> 00:42:49,770
which is again a bad example it's

00:42:48,240 --> 00:42:53,480
one example where discourages atomizer

00:42:49,770 --> 00:42:57,600
does not do a good enough job quite yet

00:42:53,480 --> 00:43:00,990
special matching which is a bummer right

00:42:57,600 --> 00:43:05,490
we love pattern matching so this

00:43:00,990 --> 00:43:10,800
benchmark here is is comparing three

00:43:05,490 --> 00:43:15,870
different versions of doing a different

00:43:10,800 --> 00:43:19,560
thing depending on which class of an aeg

00:43:15,870 --> 00:43:21,840
and which case class you have so the

00:43:19,560 --> 00:43:24,870
obvious way is this pattern match here

00:43:21,840 --> 00:43:27,390
and pattern matching in against all my

00:43:24,870 --> 00:43:32,700
ABCDE and I'm doing different things

00:43:27,390 --> 00:43:35,060
based on on whatever the other version

00:43:32,700 --> 00:43:37,530
is the good old object-oriented met

00:43:35,060 --> 00:43:40,430
version which is I have an abstract

00:43:37,530 --> 00:43:44,070
method which is called methods in

00:43:40,430 --> 00:43:46,800
parents and I implemented I implemented

00:43:44,070 --> 00:43:50,400
differently in all the subclasses okay

00:43:46,800 --> 00:43:54,000
and then I have the third version which

00:43:50,400 --> 00:43:57,480
is what you find typically in JavaScript

00:43:54,000 --> 00:44:01,380
style pattern matching is that you have

00:43:57,480 --> 00:44:05,580
a special tag a type field on your

00:44:01,380 --> 00:44:09,180
object which is a number representing

00:44:05,580 --> 00:44:12,690
which class you have and so a is 1 these

00:44:09,180 --> 00:44:16,770
two etc and then you basically switch on

00:44:12,690 --> 00:44:19,080
these on this tag and and then it's like

00:44:16,770 --> 00:44:21,540
a pattern matching but but not quite

00:44:19,080 --> 00:44:24,570
right and then we of course we have to

00:44:21,540 --> 00:44:25,920
Caston it's ugly because in Java they

00:44:24,570 --> 00:44:27,230
don't have cast so they don't notice

00:44:25,920 --> 00:44:32,810
it's ugly

00:44:27,230 --> 00:44:40,620
so of course say I forgot again to

00:44:32,810 --> 00:44:42,680
update this nope not that one there's

00:44:40,620 --> 00:44:42,680
one

00:44:47,520 --> 00:44:50,390
okay

00:44:52,960 --> 00:45:00,069
compiling up nuts down reasonably fast

00:44:57,190 --> 00:45:04,180
okay so let's do it without the

00:45:00,069 --> 00:45:06,490
optimizer for a brief couple of seconds

00:45:04,180 --> 00:45:09,069
so the pattern matching is obviously the

00:45:06,490 --> 00:45:11,559
worst it's five something the

00:45:09,069 --> 00:45:16,030
object-oriented way is apparently the

00:45:11,559 --> 00:45:19,180
fastest and the manual switches is okay

00:45:16,030 --> 00:45:22,390
and but with the optimizer which is

00:45:19,180 --> 00:45:25,210
eventually what what matters what we see

00:45:22,390 --> 00:45:28,150
is the better match is still bad because

00:45:25,210 --> 00:45:31,020
well it's a bit faster but it's it's

00:45:28,150 --> 00:45:34,359
essentially bad the object-oriented

00:45:31,020 --> 00:45:36,970
Varon did not really change its it's

00:45:34,359 --> 00:45:39,010
about the same but the manual switch for

00:45:36,970 --> 00:45:41,050
some reason got better that's that's

00:45:39,010 --> 00:45:44,770
because we inline the accessories and

00:45:41,050 --> 00:45:48,280
stuff so bottom line is the manual

00:45:44,770 --> 00:45:50,890
switch is eventually what wins and the

00:45:48,280 --> 00:45:53,950
pattern matches is not that good I mean

00:45:50,890 --> 00:45:57,130
it's not quite as bad as you know Long's

00:45:53,950 --> 00:45:59,710
right that was a hundred times lower but

00:45:57,130 --> 00:46:02,470
here it it's only you know three times

00:45:59,710 --> 00:46:04,480
lower maybe the problem is also it

00:46:02,470 --> 00:46:07,119
doesn't scale them the more the more

00:46:04,480 --> 00:46:09,130
classes you have in your in your scope

00:46:07,119 --> 00:46:12,549
subclass of your abstract class that the

00:46:09,130 --> 00:46:15,040
the worse the pattern match gets whereas

00:46:12,549 --> 00:46:18,099
the switch basically remains the same so

00:46:15,040 --> 00:46:20,950
it does not scale so that's something

00:46:18,099 --> 00:46:23,530
that doesn't work quite well yet and we

00:46:20,950 --> 00:46:25,990
definitely plan to improve them Taiwan

00:46:23,530 --> 00:46:28,329
so we're trying to improve the optimizer

00:46:25,990 --> 00:46:30,460
so that it basically transforms a

00:46:28,329 --> 00:46:32,500
pattern matching that you wrote into a

00:46:30,460 --> 00:46:33,280
switch that you don't have to write but

00:46:32,500 --> 00:46:35,680
that is fast

00:46:33,280 --> 00:46:37,270
that's essentially what we do like all

00:46:35,680 --> 00:46:39,790
the time we take the code that you write

00:46:37,270 --> 00:46:42,599
and which is bad and we make it better

00:46:39,790 --> 00:46:47,440
that's the whole purpose of an optimizer

00:46:42,599 --> 00:46:50,020
so on that note that's the the end of my

00:46:47,440 --> 00:46:55,859
talk right I'm trying and I mean happy

00:46:50,020 --> 00:46:55,859
to take a few questions thank you

00:46:59,779 --> 00:47:12,839
yep how do you decide when to compile to

00:47:10,259 --> 00:47:16,710
an optimized version of map do you look

00:47:12,839 --> 00:47:18,660
at the that type parameters values or

00:47:16,710 --> 00:47:21,180
the can build from expression or

00:47:18,660 --> 00:47:23,700
something else so it is the same

00:47:21,180 --> 00:47:27,420
heuristic that powers the loop vs loop

00:47:23,700 --> 00:47:30,299
abort example so when you call map one

00:47:27,420 --> 00:47:33,029
of the argument is a lambda and that is

00:47:30,299 --> 00:47:36,029
a great incentive for Scala GS 29 map

00:47:33,029 --> 00:47:39,569
and then it in lines to the lambda

00:47:36,029 --> 00:47:42,750
within then the can build from in all

00:47:39,569 --> 00:47:44,819
these stuff is all sorts of stuff that

00:47:42,750 --> 00:47:47,250
basically get in mind and then that

00:47:44,819 --> 00:47:50,099
could eliminate away because they were

00:47:47,250 --> 00:47:52,259
small so I can build from is typically

00:47:50,099 --> 00:47:54,750
five that different in directions but

00:47:52,259 --> 00:47:56,670
that are all one-niners so they're small

00:47:54,750 --> 00:47:59,039
they're getting lines and eventually

00:47:56,670 --> 00:48:01,380
everything's happy and and it it

00:47:59,039 --> 00:48:04,049
basically knows everything at this point

00:48:01,380 --> 00:48:07,259
statically and so it it in lines and

00:48:04,049 --> 00:48:09,660
then removes so that is how it works but

00:48:07,259 --> 00:48:12,150
the core heuristic is the same as the

00:48:09,660 --> 00:48:15,059
loop yes super bored which is giving it

00:48:12,150 --> 00:48:17,240
a lambda it in lines it as much as

00:48:15,059 --> 00:48:17,240
possible

00:48:19,930 --> 00:48:28,150
other questions yep there so with your

00:48:26,589 --> 00:48:29,859
pattern matching how do you how do you

00:48:28,150 --> 00:48:31,779
do more complicated things you know like

00:48:29,859 --> 00:48:34,480
guards and stuff like that can you still

00:48:31,779 --> 00:48:36,519
get it down to a switch or do you do you

00:48:34,480 --> 00:48:41,140
have to sort of try and do something

00:48:36,519 --> 00:48:43,569
like enclosure script I am not familiar

00:48:41,140 --> 00:48:48,640
with what closure script does in this

00:48:43,569 --> 00:48:51,099
regard so right now basically we don't

00:48:48,640 --> 00:48:53,019
really do anything special about pattern

00:48:51,099 --> 00:48:56,499
matching so what happens is color sees

00:48:53,019 --> 00:48:59,769
compiles its pattern matching into bunch

00:48:56,499 --> 00:49:02,230
of is instance offs and then adds checks

00:48:59,769 --> 00:49:03,240
additional ifs for guards and that kind

00:49:02,230 --> 00:49:06,819
of stuff

00:49:03,240 --> 00:49:09,430
what we do plan to to optimize as the

00:49:06,819 --> 00:49:12,400
straightforward if else--if else--if

00:49:09,430 --> 00:49:14,650
else--if of business themselves so if

00:49:12,400 --> 00:49:18,059
you have a guard in the middle it will

00:49:14,650 --> 00:49:23,170
not be as as good I mean eventually

00:49:18,059 --> 00:49:25,420
eventually it will be good enough but

00:49:23,170 --> 00:49:35,049
but of course guards in the middle are

00:49:25,420 --> 00:49:36,910
always a problem it yeah so but but it's

00:49:35,049 --> 00:49:40,029
it doesn't really matter because the

00:49:36,910 --> 00:49:41,619
first the first branch chain is the big

00:49:40,029 --> 00:49:43,630
problem and that one

00:49:41,619 --> 00:49:45,549
skaara C gives us something that as a

00:49:43,630 --> 00:49:46,900
top level basically isn't if else if

00:49:45,549 --> 00:49:51,460
else if our business themselves in an

00:49:46,900 --> 00:49:53,410
inside you have ifs and so the for the

00:49:51,460 --> 00:49:56,559
guards and so it's up to the top of all

00:49:53,410 --> 00:49:58,779
if else it as if we can translate it to

00:49:56,559 --> 00:50:00,489
a switch eventually and then inside the

00:49:58,779 --> 00:50:06,450
cases of the switch well you have you

00:50:00,489 --> 00:50:09,130
have the ifs for the guards over here

00:50:06,450 --> 00:50:11,440
just out of curiosity can you explain

00:50:09,130 --> 00:50:16,930
why they generated JavaScript code has

00:50:11,440 --> 00:50:20,200
so many all zeros that's signed into

00:50:16,930 --> 00:50:22,660
integer 32-bit for you so this is the

00:50:20,200 --> 00:50:24,369
encoding to to encode properly the the

00:50:22,660 --> 00:50:26,920
cement the wrapping cement acceptor to

00:50:24,369 --> 00:50:29,470
do with sign integers it turns out that

00:50:26,920 --> 00:50:29,890
this code is faster than without the

00:50:29,470 --> 00:50:35,110
binary

00:50:29,890 --> 00:50:37,150
or zeros because insert faster than

00:50:35,110 --> 00:50:39,700
doubles and the VM is recognize these

00:50:37,150 --> 00:50:42,100
patterns as as what they are which is

00:50:39,700 --> 00:50:44,800
the encoding of signed 32-bit integer

00:50:42,100 --> 00:50:47,100
arithmetic so that's why all the order

00:50:44,800 --> 00:50:47,100
zeros

00:50:52,120 --> 00:50:58,090
with with all the generated code what

00:50:55,780 --> 00:51:03,720
happens you know when it all needs to

00:50:58,090 --> 00:51:06,730
transfer our network if it's a website

00:51:03,720 --> 00:51:12,460
so here we've looked at generated code

00:51:06,730 --> 00:51:14,860
but in its nice readable version which

00:51:12,460 --> 00:51:17,470
is which is pretty printed and yes the

00:51:14,860 --> 00:51:19,450
names are really long and kind of

00:51:17,470 --> 00:51:23,590
obscure the first time you read them for

00:51:19,450 --> 00:51:25,140
me it becomes a bit more obvious of

00:51:23,590 --> 00:51:28,450
course that's not what you shipped

00:51:25,140 --> 00:51:30,400
before you actually ship to to to the

00:51:28,450 --> 00:51:32,020
browsers of your clients in production

00:51:30,400 --> 00:51:34,030
you actually actually apply an

00:51:32,020 --> 00:51:36,420
additional pass which we which is

00:51:34,030 --> 00:51:40,240
powered by the closure compiler which

00:51:36,420 --> 00:51:44,760
very very actively minifiers the codes

00:51:40,240 --> 00:51:48,490
and performs some some JavaScript

00:51:44,760 --> 00:51:52,900
minimization and optimization so in the

00:51:48,490 --> 00:51:56,260
end a typical application weighs a

00:51:52,900 --> 00:51:57,010
couple of hundreds of kilobytes non

00:51:56,260 --> 00:51:59,590
gzipped

00:51:57,010 --> 00:52:01,210
then you can typically it's chips in

00:51:59,590 --> 00:52:04,770
addition if you have a very large very

00:52:01,210 --> 00:52:07,900
large code bases I know that people have

00:52:04,770 --> 00:52:10,990
non gzipped but minified javascript

00:52:07,900 --> 00:52:12,880
files of a couple of megabytes but those

00:52:10,990 --> 00:52:15,160
are I mean if you look at Gmail that's

00:52:12,880 --> 00:52:18,100
also it's also a couple megabytes so the

00:52:15,160 --> 00:52:20,770
big big code bases tend to be a couple

00:52:18,100 --> 00:52:24,970
megabytes typical applications tend to

00:52:20,770 --> 00:52:28,500
be a couple of hundred kilobytes I was

00:52:24,970 --> 00:52:28,500
one question and Mayall firsts

00:52:30,950 --> 00:52:36,710
which one would be faster a scholar

00:52:34,190 --> 00:52:39,980
native application or a scholar GS

00:52:36,710 --> 00:52:41,720
application and being a scholar native

00:52:39,980 --> 00:52:51,350
application is probably going to be much

00:52:41,720 --> 00:52:54,170
faster the front here how do you find

00:52:51,350 --> 00:52:56,440
targets for optimization so how do you

00:52:54,170 --> 00:52:58,970
decide what you can optimize next

00:52:56,440 --> 00:53:04,190
whatever is the bottleneck of our next

00:52:58,970 --> 00:53:08,420
benchmark but since we use the octane

00:53:04,190 --> 00:53:10,160
benchmarks which are the v8 JavaScript

00:53:08,420 --> 00:53:12,860
benchmarks that's that's what we

00:53:10,160 --> 00:53:17,750
progressively pour it and that's what

00:53:12,860 --> 00:53:19,580
drives the what we figure out is is a

00:53:17,750 --> 00:53:23,300
bottleneck in the in the current

00:53:19,580 --> 00:53:24,830
encoding and what we optimize for but it

00:53:23,300 --> 00:53:26,570
doesn't always work for example pattern

00:53:24,830 --> 00:53:28,760
matching is definitely not something

00:53:26,570 --> 00:53:30,890
you'll get from octane benchmarks so but

00:53:28,760 --> 00:53:32,900
those are things that we know from Scout

00:53:30,890 --> 00:53:38,030
are bad so we will also try to optimize

00:53:32,900 --> 00:53:40,310
for these kind of things okay I think

00:53:38,030 --> 00:53:43,130
that's all and it is good because we're

00:53:40,310 --> 00:53:45,880
a bit over time so thank you again and I

00:53:43,130 --> 00:53:45,880

YouTube URL: https://www.youtube.com/watch?v=gXhZjiMH37g


