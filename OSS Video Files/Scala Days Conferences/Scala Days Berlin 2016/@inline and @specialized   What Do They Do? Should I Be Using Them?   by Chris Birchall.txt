Title: @inline and @specialized   What Do They Do? Should I Be Using Them?   by Chris Birchall
Publication date: 2016-07-22
Playlist: Scala Days Berlin 2016
Description: 
	This video was recorded at Scala Days Berlin 2016
follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Abstract:
You may have seen the @inline and @specialized annotations used in Scala code, and have some idea that they are added for performance reasons. But the exact details of what they do is not widely known, and it's hard to estimate whether they will provide a real performance benefit to your code. This talk will: explain exactly what the annotations do; provide some examples of how to use them; and use benchmarks to explore how they affect performance. There will also be honourable mentions for some of the more esoteric Scala annotations such as @elidable, @strictfp, @switch and @varargs.
Captions: 
	00:00:03,110 --> 00:00:08,660
I'm Chris and I'm going to talk to you

00:00:05,240 --> 00:00:10,219
about inlining and specialization so the

00:00:08,660 --> 00:00:12,379
title of my talk is in line and

00:00:10,219 --> 00:00:15,230
specialized what do they do and should i

00:00:12,379 --> 00:00:17,119
be using them and for a long time I

00:00:15,230 --> 00:00:20,270
didn't have the answers to these

00:00:17,119 --> 00:00:22,280
questions I I kind of vaguely knew what

00:00:20,270 --> 00:00:24,050
they do but I didn't know enough detail

00:00:22,280 --> 00:00:25,640
about that in order to answer the second

00:00:24,050 --> 00:00:28,250
question should i actually use these

00:00:25,640 --> 00:00:31,460
things in my code will they improve the

00:00:28,250 --> 00:00:33,559
performance of my covert noticeably and

00:00:31,460 --> 00:00:35,930
usually when I have something in Scala

00:00:33,559 --> 00:00:38,720
that I I don't understand I write a talk

00:00:35,930 --> 00:00:40,220
about it so that's why I did here and

00:00:38,720 --> 00:00:42,170
now I know a lot more than I used to and

00:00:40,220 --> 00:00:47,960
hopefully by the end of the talk you

00:00:42,170 --> 00:00:50,360
will too so the talk is in two halves

00:00:47,960 --> 00:00:53,870
we'll talk about inlining first and then

00:00:50,360 --> 00:00:55,579
specialization after that so in lining

00:00:53,870 --> 00:00:57,620
we'll talk about what it is in general

00:00:55,579 --> 00:00:59,360
and then how it works on the JVM and

00:00:57,620 --> 00:01:02,420
then more specifically how you do it in

00:00:59,360 --> 00:01:04,549
Scala and finally we'll have a look at a

00:01:02,420 --> 00:01:07,640
quick benchmark to see how it affects

00:01:04,549 --> 00:01:10,490
the performance of your code and then

00:01:07,640 --> 00:01:13,840
specialization which I randomly spelled

00:01:10,490 --> 00:01:15,770
with an S or a Zed so sorry about that

00:01:13,840 --> 00:01:18,140
first we'll give a bit of background

00:01:15,770 --> 00:01:20,540
about why we need specialization what

00:01:18,140 --> 00:01:22,490
problem is it solving and then we'll

00:01:20,540 --> 00:01:25,330
talk about how it works in Scala and

00:01:22,490 --> 00:01:27,799
again we'll look at some benchmarks and

00:01:25,330 --> 00:01:29,600
there's a little one warning on the

00:01:27,799 --> 00:01:32,750
right hand side there will be bytecode

00:01:29,600 --> 00:01:34,610
in this presentation but don't worry

00:01:32,750 --> 00:01:41,000
I'll be gentle and I will explain the

00:01:34,610 --> 00:01:43,700
most important bits as we get on them so

00:01:41,000 --> 00:01:46,280
Who am I I'm Chris I work at The

00:01:43,700 --> 00:01:50,930
Guardian in London we are a newspaper

00:01:46,280 --> 00:01:52,759
and a news website I wrote this book if

00:01:50,930 --> 00:01:58,490
you're interested in re-engineering

00:01:52,759 --> 00:02:00,799
legacy software please have a look so

00:01:58,490 --> 00:02:03,200
the first question you should ask when

00:02:00,799 --> 00:02:07,220
you agree to listen to me for 45 minutes

00:02:03,200 --> 00:02:09,259
is why should I care about this why

00:02:07,220 --> 00:02:11,060
should I bother learning what in line

00:02:09,259 --> 00:02:11,630
and specialized do and bother putting

00:02:11,060 --> 00:02:15,590
them into Mike

00:02:11,630 --> 00:02:20,360
and the answer is that performance

00:02:15,590 --> 00:02:22,310
matters sometimes so I came from a Java

00:02:20,360 --> 00:02:24,910
background I was writing Java for a long

00:02:22,310 --> 00:02:27,440
time and when I was writing Java

00:02:24,910 --> 00:02:29,240
performance was a very high priority it

00:02:27,440 --> 00:02:31,640
was kind of its always at the back of

00:02:29,240 --> 00:02:33,080
your mind how is this code performing am

00:02:31,640 --> 00:02:37,130
I using the right thing to structure and

00:02:33,080 --> 00:02:38,390
so on and then I think that's just part

00:02:37,130 --> 00:02:41,510
of the nature of the language and the

00:02:38,390 --> 00:02:43,280
culture of Java but then when you move

00:02:41,510 --> 00:02:44,770
to scarlet for me at least there was a

00:02:43,280 --> 00:02:47,240
kind of honeymoon period in which

00:02:44,770 --> 00:02:49,340
suddenly performance is not the top

00:02:47,240 --> 00:02:52,880
priority there's things like readability

00:02:49,340 --> 00:02:54,770
and composability of your code and you

00:02:52,880 --> 00:02:56,840
have all of these nice functional

00:02:54,770 --> 00:02:59,210
primitives like map and filter on so on

00:02:56,840 --> 00:03:02,420
and so you're not really that concerned

00:02:59,210 --> 00:03:04,250
with performance so anymore but then one

00:03:02,420 --> 00:03:05,240
day there comes a time when you do

00:03:04,250 --> 00:03:08,000
actually need to write performance

00:03:05,240 --> 00:03:11,630
critical code and in those kind of cases

00:03:08,000 --> 00:03:13,280
you need to understand how your code is

00:03:11,630 --> 00:03:15,410
running on the JVM how does it get

00:03:13,280 --> 00:03:18,590
compiled down to bytecode what's

00:03:15,410 --> 00:03:20,690
actually doing and what kind of tools

00:03:18,590 --> 00:03:23,750
are available for you to improve the

00:03:20,690 --> 00:03:25,310
performance of your code so in lining

00:03:23,750 --> 00:03:31,910
and specialization are two of those

00:03:25,310 --> 00:03:35,360
tools so first of all in lining what is

00:03:31,910 --> 00:03:38,350
it so in lining is a compiler

00:03:35,360 --> 00:03:40,730
optimization and basically it is

00:03:38,350 --> 00:03:44,959
removing a function call from your code

00:03:40,730 --> 00:03:47,209
and it does that by basically copying

00:03:44,959 --> 00:03:49,370
the function body of the target function

00:03:47,209 --> 00:03:52,880
into the function that's calling that

00:03:49,370 --> 00:03:55,970
function so it's copying the code the

00:03:52,880 --> 00:03:59,810
body of the function into the caller and

00:03:55,970 --> 00:04:01,370
this happens at the compiler level JVM

00:03:59,810 --> 00:04:02,720
bytecode level for example it doesn't

00:04:01,370 --> 00:04:05,720
happen in the source code level but if

00:04:02,720 --> 00:04:08,540
we look at it in the source code it

00:04:05,720 --> 00:04:10,820
looks kind of like this so on the left

00:04:08,540 --> 00:04:13,190
hand side we have a target function that

00:04:10,820 --> 00:04:15,800
we want to in line it's just adding

00:04:13,190 --> 00:04:17,630
numbers and multiplying them and then we

00:04:15,800 --> 00:04:21,200
have a call site a calling function

00:04:17,630 --> 00:04:22,920
which is making a function call to that

00:04:21,200 --> 00:04:26,170
fashion

00:04:22,920 --> 00:04:28,690
so if we perform in lining on this then

00:04:26,170 --> 00:04:30,790
we get the result looks like the right

00:04:28,690 --> 00:04:32,830
hand side we've removed the function

00:04:30,790 --> 00:04:36,090
called completely when we just copy

00:04:32,830 --> 00:04:38,290
pasted the code into the call site and

00:04:36,090 --> 00:04:45,340
obviously updated the variables

00:04:38,290 --> 00:04:47,470
accordingly so in lining is a classic

00:04:45,340 --> 00:04:49,900
compiler optimization it's been around

00:04:47,470 --> 00:04:53,560
since the Stone Age so it's not specific

00:04:49,900 --> 00:04:56,560
to scala or even to the JVM and it has a

00:04:53,560 --> 00:04:58,540
couple of benefits firstly it removes a

00:04:56,560 --> 00:05:00,750
function called and function calls are

00:04:58,540 --> 00:05:03,520
quite expensive as we'll see in a second

00:05:00,750 --> 00:05:07,030
and secondly and more importantly it's

00:05:03,520 --> 00:05:09,610
an enabler for more optimizations to be

00:05:07,030 --> 00:05:12,580
done a lot of compiler optimization is

00:05:09,610 --> 00:05:13,990
only work within the body of one

00:05:12,580 --> 00:05:16,210
function it's quite hard to write

00:05:13,990 --> 00:05:18,910
optimizations that work across function

00:05:16,210 --> 00:05:21,340
boundaries so if you can remove that

00:05:18,910 --> 00:05:23,530
function boundary and put ever make

00:05:21,340 --> 00:05:26,320
everything one big function then you can

00:05:23,530 --> 00:05:29,590
do a lot more optimizations more easily

00:05:26,320 --> 00:05:35,020
and we'll have a look at that in a

00:05:29,590 --> 00:05:39,160
second as well so here's our first byte

00:05:35,020 --> 00:05:41,440
code so here is what it looks like to

00:05:39,160 --> 00:05:43,000
remove the function call overhead we've

00:05:41,440 --> 00:05:44,460
got the same sample code as before but

00:05:43,000 --> 00:05:48,310
now we're showing the bytecode as well

00:05:44,460 --> 00:05:51,420
so before we do our inlining we have the

00:05:48,310 --> 00:05:55,060
thing circled in red this invoke virtual

00:05:51,420 --> 00:05:56,970
bytecode instruction and this is the

00:05:55,060 --> 00:05:59,170
bike code for calling a virtual function

00:05:56,970 --> 00:06:01,360
and this is the thing that we want to

00:05:59,170 --> 00:06:03,040
get rid of and you can see on the right

00:06:01,360 --> 00:06:07,510
hand side but that call to in burg

00:06:03,040 --> 00:06:09,190
invoke virtual has disappeared the

00:06:07,510 --> 00:06:10,870
question obviously is what's so bad

00:06:09,190 --> 00:06:14,380
about invoke virtual so if we have a

00:06:10,870 --> 00:06:17,050
look at the JVM spec for it we can see

00:06:14,380 --> 00:06:22,480
what the JVM runtime actually has to do

00:06:17,050 --> 00:06:24,010
when you invoke a function so the first

00:06:22,480 --> 00:06:26,860
thing it needs to do if it's a virtual

00:06:24,010 --> 00:06:28,630
function is to look up which function

00:06:26,860 --> 00:06:30,850
you're actually trying to call because

00:06:28,630 --> 00:06:32,290
the function may not be on the concrete

00:06:30,850 --> 00:06:33,849
class that are dealing with it might be

00:06:32,290 --> 00:06:35,740
on an ancestor that class

00:06:33,849 --> 00:06:38,349
might have to walk up the class

00:06:35,740 --> 00:06:43,270
hierarchy to find the actual function

00:06:38,349 --> 00:06:45,159
that you're calling next it says a new

00:06:43,270 --> 00:06:48,309
frame is created on the Java Virtual

00:06:45,159 --> 00:06:50,919
Machine stack so this means there's

00:06:48,309 --> 00:06:52,509
memory allocation going on here and if

00:06:50,919 --> 00:06:53,740
you want to pass arguments into the

00:06:52,509 --> 00:06:55,529
function then you'll need to put those

00:06:53,740 --> 00:06:59,619
on to the stack as well so that's

00:06:55,529 --> 00:07:01,029
obviously extra overhead you have to put

00:06:59,619 --> 00:07:03,429
stuff on to the stack and then pop it

00:07:01,029 --> 00:07:07,990
off the stack once you're inside the

00:07:03,429 --> 00:07:11,229
function and then thirdly it says the

00:07:07,990 --> 00:07:13,539
Java Virtual Machine pc is set and here

00:07:11,229 --> 00:07:17,469
pc means program counter so this is the

00:07:13,539 --> 00:07:19,749
point are saying where where the CPU is

00:07:17,469 --> 00:07:22,240
currently executing which which line of

00:07:19,749 --> 00:07:23,949
code is currently excusing so this is

00:07:22,240 --> 00:07:27,069
basically saying that you are doing a

00:07:23,949 --> 00:07:31,389
jump and a jump is kryptonite for your

00:07:27,069 --> 00:07:33,519
CPU because the one thing that the CPU

00:07:31,389 --> 00:07:35,259
wants to believe about your code is that

00:07:33,519 --> 00:07:38,159
it's going to keep doing whatever it's

00:07:35,259 --> 00:07:40,509
doing now so if you're executing this

00:07:38,159 --> 00:07:42,399
instruction and then this one and then

00:07:40,509 --> 00:07:44,709
this one and then this one the CPU

00:07:42,399 --> 00:07:46,499
thinks are I spot a pattern here and it

00:07:44,709 --> 00:07:49,119
goes in pre caches a whole bunch of

00:07:46,499 --> 00:07:51,550
instructions so that it can keep doing

00:07:49,119 --> 00:07:54,459
this but then suddenly you jump over

00:07:51,550 --> 00:07:55,569
here and it's got a completely cold cash

00:07:54,459 --> 00:07:57,789
it doesn't have any of those

00:07:55,569 --> 00:07:59,919
instructions already cached and so it

00:07:57,789 --> 00:08:04,929
has to go and fetch them so any time

00:07:59,919 --> 00:08:06,939
that you do a jump or you somehow do

00:08:04,929 --> 00:08:08,679
something the CPU isn't expecting you to

00:08:06,939 --> 00:08:12,879
do then it will cause a dramatic

00:08:08,679 --> 00:08:17,619
slowdown so we want to avoid function

00:08:12,879 --> 00:08:19,599
calls and then the the other benefit of

00:08:17,619 --> 00:08:22,329
inlining as I explained before is that

00:08:19,599 --> 00:08:24,399
it enables more optimizations to be done

00:08:22,329 --> 00:08:28,449
later so we have a look at this example

00:08:24,399 --> 00:08:33,009
we have a class a that has an X int

00:08:28,449 --> 00:08:36,719
field and it has a method plus one that

00:08:33,009 --> 00:08:39,339
adds 1 to X then we have a function that

00:08:36,719 --> 00:08:43,029
creates a new a and calls the plus one

00:08:39,339 --> 00:08:44,870
method on it so step one we do any

00:08:43,029 --> 00:08:47,270
inlining we in line the

00:08:44,870 --> 00:08:52,040
one and replace it with the body which

00:08:47,270 --> 00:08:54,589
is a dot X plus 1 and then this enables

00:08:52,040 --> 00:08:57,620
a hotspot optimization called escape

00:08:54,589 --> 00:08:59,779
analysis which is clever enough to

00:08:57,620 --> 00:09:01,790
realize that we don't even need to

00:08:59,779 --> 00:09:03,620
allocate this new a it's completely

00:09:01,790 --> 00:09:05,810
pointless we can just delete all of that

00:09:03,620 --> 00:09:09,170
code and it simplifies down to one plus

00:09:05,810 --> 00:09:11,180
one and then I haven't checked but I

00:09:09,170 --> 00:09:12,350
think since hotspot is smart smart

00:09:11,180 --> 00:09:13,940
enough to get to this point it can

00:09:12,350 --> 00:09:16,670
probably tell that one plus one equals

00:09:13,940 --> 00:09:22,010
two so it probably reduces it even

00:09:16,670 --> 00:09:24,110
further so this is just one example but

00:09:22,010 --> 00:09:27,920
there's dozens of different

00:09:24,110 --> 00:09:30,260
optimizations both in hotspot and in

00:09:27,920 --> 00:09:36,320
other compilers that are made a lot

00:09:30,260 --> 00:09:38,779
easier to do by in line so it looks like

00:09:36,320 --> 00:09:40,910
in lining is quite a good thing so the

00:09:38,779 --> 00:09:42,860
big question obviously is why not in

00:09:40,910 --> 00:09:44,960
line everything why don't we just in

00:09:42,860 --> 00:09:48,550
line a whole program into one huge

00:09:44,960 --> 00:09:53,650
function and then optimize it like crazy

00:09:48,550 --> 00:09:57,339
and the answer is that code is data so

00:09:53,650 --> 00:10:00,200
every time you in line a function into

00:09:57,339 --> 00:10:02,630
multiple call sites it it's a

00:10:00,200 --> 00:10:04,910
duplication of coded your code size will

00:10:02,630 --> 00:10:08,180
get bigger and if your code gets too big

00:10:04,910 --> 00:10:11,959
then you're working set your hot spot

00:10:08,180 --> 00:10:15,680
hot code will no longer fit into the CPU

00:10:11,959 --> 00:10:19,160
caches and that will be dramatically bad

00:10:15,680 --> 00:10:20,390
for performance so we want to in line as

00:10:19,160 --> 00:10:22,100
much as we can on but we don't want to

00:10:20,390 --> 00:10:25,160
make the code too big so we have to be

00:10:22,100 --> 00:10:27,529
quite smart about it basically we want

00:10:25,160 --> 00:10:31,400
to in line hot functions things that are

00:10:27,529 --> 00:10:32,839
called very often and we don't want to

00:10:31,400 --> 00:10:34,279
in line anything that's not called very

00:10:32,839 --> 00:10:40,100
often because it doesn't really matter

00:10:34,279 --> 00:10:42,970
and hotspot is very good at this it's

00:10:40,100 --> 00:10:45,080
base its what hotspot was designed for

00:10:42,970 --> 00:10:47,529
hotspot by the way is the the

00:10:45,080 --> 00:10:50,209
just-in-time compiler for the JVM and

00:10:47,529 --> 00:10:52,640
the way it works is that it's

00:10:50,209 --> 00:10:55,250
continually continuously measuring how

00:10:52,640 --> 00:10:57,500
many times each function in your program

00:10:55,250 --> 00:10:58,940
is being cooled and it so it's finding

00:10:57,500 --> 00:11:00,140
the hot spots for functions that are

00:10:58,940 --> 00:11:06,230
called a lot and then aggressively

00:11:00,140 --> 00:11:09,830
optimizing them so hot spot has some

00:11:06,230 --> 00:11:12,200
heuristics for inlining code it likes to

00:11:09,830 --> 00:11:16,370
inline things that are small things that

00:11:12,200 --> 00:11:17,930
are hot I called lots of times and it

00:11:16,370 --> 00:11:20,270
has a few other heuristics and

00:11:17,930 --> 00:11:24,140
restrictions as well but basically small

00:11:20,270 --> 00:11:27,170
things but a hot and as you can see here

00:11:24,140 --> 00:11:28,730
you have a few compiler sorry jvm

00:11:27,170 --> 00:11:31,640
arguments that you can use to tweak

00:11:28,730 --> 00:11:38,960
these heuristics but the defaults are

00:11:31,640 --> 00:11:40,580
pretty sensible um as an aside if you're

00:11:38,960 --> 00:11:43,670
interested in this kind of stuff and

00:11:40,580 --> 00:11:46,250
like me you enjoy looking at assembly in

00:11:43,670 --> 00:11:49,460
your free time then I really recommend

00:11:46,250 --> 00:11:52,190
this program it's called get watch it's

00:11:49,460 --> 00:11:56,030
a really nice open source tool and you

00:11:52,190 --> 00:11:58,670
can show you exactly how hot spot is

00:11:56,030 --> 00:12:02,630
optimizing your code it passes hot spot

00:11:58,670 --> 00:12:04,840
logs and it can show you exactly what

00:12:02,630 --> 00:12:13,130
hot spot did at each iteration of

00:12:04,840 --> 00:12:14,390
optimization so this is Scarlett ages

00:12:13,130 --> 00:12:18,050
but I haven't really talked about Scott

00:12:14,390 --> 00:12:21,530
yet so let's remedy that this is how you

00:12:18,050 --> 00:12:23,360
do in lining in Scala we have to

00:12:21,530 --> 00:12:25,490
annotations avail all we have one called

00:12:23,360 --> 00:12:28,880
in line and one called no in line and

00:12:25,490 --> 00:12:31,430
these are hints to the compiler they're

00:12:28,880 --> 00:12:34,010
saying please in line this code if you

00:12:31,430 --> 00:12:39,980
can or obviously please do not enlighten

00:12:34,010 --> 00:12:41,900
this code and they are just hints so

00:12:39,980 --> 00:12:47,060
they're not guarantees that this method

00:12:41,900 --> 00:12:48,530
will actually be inlined and one thing

00:12:47,060 --> 00:12:52,010
that a lot of people don't realize is

00:12:48,530 --> 00:12:55,370
that you have to enable optimization you

00:12:52,010 --> 00:12:57,470
have to pass this minus optimize flag to

00:12:55,370 --> 00:13:00,020
the compiler otherwise these annotations

00:12:57,470 --> 00:13:02,810
will not do anything at all the in liner

00:13:00,020 --> 00:13:05,290
is part of the optimizer so unless you

00:13:02,810 --> 00:13:08,639
turn on optimization specifically

00:13:05,290 --> 00:13:08,639
you won't get any in lining at all

00:13:08,820 --> 00:13:14,850
another nice flag that's worth passing

00:13:11,410 --> 00:13:18,519
is this minus y in line warnings so this

00:13:14,850 --> 00:13:20,199
is saying if you have to ignore my hint

00:13:18,519 --> 00:13:22,170
if you don't in line something that I

00:13:20,199 --> 00:13:24,459
want to in line please tell me about it

00:13:22,170 --> 00:13:31,930
so it'll give you a compiler warning

00:13:24,459 --> 00:13:34,779
saying sorry I couldn't in line this so

00:13:31,930 --> 00:13:38,949
the way inlining works right now in

00:13:34,779 --> 00:13:43,360
scarlet to 11 is quite quite complicated

00:13:38,949 --> 00:13:44,680
i guess but in 212 which I'll describe

00:13:43,360 --> 00:13:47,319
in a second everything's going to change

00:13:44,680 --> 00:13:49,810
they've written the optimizer has been

00:13:47,319 --> 00:13:52,540
completely rewritten so it's a bit

00:13:49,810 --> 00:13:55,990
simpler in 212 but for now this is how

00:13:52,540 --> 00:13:58,600
it works first of all it will only in

00:13:55,990 --> 00:14:02,259
line so called effectively final methods

00:13:58,600 --> 00:14:04,180
so this is when the you know at compile

00:14:02,259 --> 00:14:07,899
time exactly which method is going to be

00:14:04,180 --> 00:14:10,449
called if it's a like a virtual function

00:14:07,899 --> 00:14:12,399
that could be one of many different

00:14:10,449 --> 00:14:14,620
concrete implementations then it's just

00:14:12,399 --> 00:14:17,940
impossible for the compiler to enlight

00:14:14,620 --> 00:14:22,690
it it doesn't know which one to in line

00:14:17,940 --> 00:14:24,339
and then it treats your own code the

00:14:22,690 --> 00:14:28,240
code that you're compiling right now as

00:14:24,339 --> 00:14:30,010
the current compilation what's called

00:14:28,240 --> 00:14:32,680
like batch of files that want to compile

00:14:30,010 --> 00:14:35,680
it treats those differently from code

00:14:32,680 --> 00:14:37,930
that's already making being compiled so

00:14:35,680 --> 00:14:40,420
for example your own source code versus

00:14:37,930 --> 00:14:44,050
some library that you're depending on

00:14:40,420 --> 00:14:47,680
the tinge in a jar so for for stuff

00:14:44,050 --> 00:14:49,269
that's already been compiled it will

00:14:47,680 --> 00:14:52,600
only in line things that have been

00:14:49,269 --> 00:14:56,170
annotated with inline annotation except

00:14:52,600 --> 00:14:59,709
for a few special rules like scarlett

00:14:56,170 --> 00:15:01,240
runtime dot star everything in that

00:14:59,709 --> 00:15:05,860
package gets special treatment and

00:15:01,240 --> 00:15:07,839
things like that and then it's got these

00:15:05,860 --> 00:15:10,720
score based heuristics which are kind of

00:15:07,839 --> 00:15:12,850
similar to what hotspot does so it looks

00:15:10,720 --> 00:15:15,110
at the size of the method the size of

00:15:12,850 --> 00:15:19,220
the method that's calling that method

00:15:15,110 --> 00:15:21,140
and things like that it also has special

00:15:19,220 --> 00:15:23,510
treatment for higher-order functions and

00:15:21,140 --> 00:15:28,670
closures which I will talk about a

00:15:23,510 --> 00:15:34,940
little bit later so in 212 all of this

00:15:28,670 --> 00:15:37,430
changes its now the aim is to make it a

00:15:34,940 --> 00:15:39,890
lot simpler a lot more deterministic and

00:15:37,430 --> 00:15:41,510
so you can easily tell or predict

00:15:39,890 --> 00:15:43,420
whether the compiler is going to inline

00:15:41,510 --> 00:15:47,120
a certain piece of code for you or not

00:15:43,420 --> 00:15:49,610
so the basic premise is only in line in

00:15:47,120 --> 00:15:51,680
line marked methods and always inline

00:15:49,610 --> 00:15:54,200
them including under separate

00:15:51,680 --> 00:15:55,970
compilation so now there's no longer

00:15:54,200 --> 00:15:57,769
this split between your code that you're

00:15:55,970 --> 00:16:04,610
compiling now and you're your

00:15:57,769 --> 00:16:07,130
dependencies and yeah I mean there's

00:16:04,610 --> 00:16:09,380
basically one rule if you want to inline

00:16:07,130 --> 00:16:13,700
it you annotate it with inline otherwise

00:16:09,380 --> 00:16:15,800
you don't so no longer looks of the size

00:16:13,700 --> 00:16:17,750
of the methods or anything like that but

00:16:15,800 --> 00:16:20,630
there is one other heuristic that it

00:16:17,750 --> 00:16:25,130
does which is to inline higher-order

00:16:20,630 --> 00:16:27,199
functions and closures so the whole

00:16:25,130 --> 00:16:29,300
point of this is the aim is better

00:16:27,199 --> 00:16:30,860
synergy with hot spot because hot spots

00:16:29,300 --> 00:16:34,010
very good at enlightening so there's no

00:16:30,860 --> 00:16:36,560
point trying to do hot spots job but the

00:16:34,010 --> 00:16:38,750
idea is to use knowledge that we have a

00:16:36,560 --> 00:16:44,240
compilation time to make life easier for

00:16:38,750 --> 00:16:46,880
hot spot so why do we want to inline

00:16:44,240 --> 00:16:49,940
higher-order functions at a compile-time

00:16:46,880 --> 00:16:52,339
rather than leaving it up to hotspot we

00:16:49,940 --> 00:16:54,560
can look at a quick example here this is

00:16:52,339 --> 00:16:56,300
a kind of canonical example of

00:16:54,560 --> 00:17:00,050
higher-order functions or closures I

00:16:56,300 --> 00:17:04,069
guess so we've got four I in one until

00:17:00,050 --> 00:17:08,870
10 print than I so print with a nicer

00:17:04,069 --> 00:17:13,150
and another anonymous function and then

00:17:08,870 --> 00:17:15,290
this get D sugared to the version below

00:17:13,150 --> 00:17:18,230
so what we're actually saying here is

00:17:15,290 --> 00:17:20,089
create a new instance of range create a

00:17:18,230 --> 00:17:23,740
new instance of this anonymous function

00:17:20,089 --> 00:17:26,220
that does a print line and then pass the

00:17:23,740 --> 00:17:30,750
function into the rain

00:17:26,220 --> 00:17:32,220
stop for each method and if I'm hot

00:17:30,750 --> 00:17:33,960
spots and I'm looking at this code I

00:17:32,220 --> 00:17:35,760
have no idea that this is a higher-order

00:17:33,960 --> 00:17:37,730
function that needs to be treated in any

00:17:35,760 --> 00:17:41,070
special way it just looks like i'm

00:17:37,730 --> 00:17:43,350
creating two new instances of objects

00:17:41,070 --> 00:17:46,350
and i'm passing one into a method of the

00:17:43,350 --> 00:17:48,480
other so i might in line it or i might

00:17:46,350 --> 00:17:50,659
not i mean it all depends on whether it

00:17:48,480 --> 00:17:55,049
matches those heuristics that i'm using

00:17:50,659 --> 00:17:58,320
but in scarlet compiler we have more

00:17:55,049 --> 00:18:00,450
information that we know that it's a

00:17:58,320 --> 00:18:02,400
higher-order function so we can treat it

00:18:00,450 --> 00:18:05,789
especially and we can do the inlining at

00:18:02,400 --> 00:18:08,970
compile time so if we look at how it

00:18:05,789 --> 00:18:11,700
looks after we in line range dot for

00:18:08,970 --> 00:18:15,059
each f and just replace that line with

00:18:11,700 --> 00:18:20,909
the body of that function it now looks

00:18:15,059 --> 00:18:23,400
like this and then that enables us to do

00:18:20,909 --> 00:18:26,370
another step of inlining another

00:18:23,400 --> 00:18:31,350
iteration of it in mining we can inline

00:18:26,370 --> 00:18:35,030
the F dot apply I so we replace that

00:18:31,350 --> 00:18:37,740
with its body which is just print them

00:18:35,030 --> 00:18:40,590
and then if you look carefully you find

00:18:37,740 --> 00:18:43,080
that the second line of the function the

00:18:40,590 --> 00:18:45,409
vowel F line is no longer needed it's

00:18:43,080 --> 00:18:49,320
dead code so we can just delete that and

00:18:45,409 --> 00:18:52,440
so we've completely eliminated this

00:18:49,320 --> 00:18:54,419
allocation of a new object that we

00:18:52,440 --> 00:18:57,000
needed in order to pass in our our

00:18:54,419 --> 00:19:01,110
anonymous function so this is a big win

00:18:57,000 --> 00:19:05,820
and all this code now looks very very

00:19:01,110 --> 00:19:08,190
high highly performant so that's the

00:19:05,820 --> 00:19:09,929
main reason why we want to do

00:19:08,190 --> 00:19:16,799
higher-order function inlining at

00:19:09,929 --> 00:19:19,770
compile time ok so let's do some

00:19:16,799 --> 00:19:21,270
benchmarking and like most benchmarks in

00:19:19,770 --> 00:19:23,429
the world this one is probably wrong in

00:19:21,270 --> 00:19:28,470
some way benchmarking is very difficult

00:19:23,429 --> 00:19:31,159
so apologies for that so when I write

00:19:28,470 --> 00:19:33,630
benchmarks I try to make them kind of

00:19:31,159 --> 00:19:35,760
real-world e in some way a bit more

00:19:33,630 --> 00:19:38,130
interesting than just like a very

00:19:35,760 --> 00:19:41,010
specific micro benchmark

00:19:38,130 --> 00:19:44,610
so in this case are chosen to do a fast

00:19:41,010 --> 00:19:46,110
fourier transform in my day job at the

00:19:44,610 --> 00:19:49,890
Guardian we don't really do a lot of

00:19:46,110 --> 00:19:52,200
fast fourier transforms but in other

00:19:49,890 --> 00:19:54,750
domains obviously it's very useful I

00:19:52,200 --> 00:19:59,490
mean it's used in mp3 encoding and all

00:19:54,750 --> 00:20:01,620
kinds of things I decided to implement

00:19:59,490 --> 00:20:04,860
the Coulee turkey algorithm because it

00:20:01,620 --> 00:20:07,170
has a really cool name I won't go into

00:20:04,860 --> 00:20:10,650
the details but it's a recursive

00:20:07,170 --> 00:20:13,650
algorithm it so it's quite amenable to a

00:20:10,650 --> 00:20:16,920
nice functional implementation in Scala

00:20:13,650 --> 00:20:19,530
and the meat of the algorithm is lots

00:20:16,920 --> 00:20:22,560
and lots of numerical operations on

00:20:19,530 --> 00:20:24,540
complex numbers so I modeled a complex

00:20:22,560 --> 00:20:27,150
number with this case class complex and

00:20:24,540 --> 00:20:29,640
the point of the benchmark is what

00:20:27,150 --> 00:20:34,500
happens if i add this in line annotation

00:20:29,640 --> 00:20:38,220
to my my complex my numerical operations

00:20:34,500 --> 00:20:42,030
on complex numbers so the moment of

00:20:38,220 --> 00:20:44,760
truth here are some numbers there's

00:20:42,030 --> 00:20:47,640
quite a lot going on here so I'll go

00:20:44,760 --> 00:20:49,500
through it in stages but first of all if

00:20:47,640 --> 00:20:51,210
you compare the left oh sorry the middle

00:20:49,500 --> 00:20:53,430
column the left-hand column with the

00:20:51,210 --> 00:20:56,250
right hand column this is the difference

00:20:53,430 --> 00:21:00,240
between telling just completely turning

00:20:56,250 --> 00:21:03,950
off in lining in hotspot versus leaving

00:21:00,240 --> 00:21:06,600
it running like normal and you can see

00:21:03,950 --> 00:21:08,550
if you enable hotspot in lining then the

00:21:06,600 --> 00:21:11,100
code gets like three or four times

00:21:08,550 --> 00:21:15,810
faster so obviously in lining is a good

00:21:11,100 --> 00:21:19,440
thing we've confirmed that second if you

00:21:15,810 --> 00:21:24,930
compare if i can find my mouse you

00:21:19,440 --> 00:21:28,080
compare this row so this is with the

00:21:24,930 --> 00:21:29,940
inline annotation with this one below it

00:21:28,080 --> 00:21:31,590
this is where we have a no in line so

00:21:29,940 --> 00:21:34,470
we're saying to scala see please don't

00:21:31,590 --> 00:21:37,020
in line this then you can see they're

00:21:34,470 --> 00:21:39,570
basically the same and the reason for

00:21:37,020 --> 00:21:41,640
this is that hot spot has in lined it

00:21:39,570 --> 00:21:47,610
for us anyway so the whole thing was

00:21:41,640 --> 00:21:49,260
pointless and finally if you look at the

00:21:47,610 --> 00:21:50,419
difference between the numbers in top

00:21:49,260 --> 00:21:53,090
table and the numbers in

00:21:50,419 --> 00:21:56,570
bottom table you can see that just by

00:21:53,090 --> 00:21:58,759
upgrading to scala 212 we've got what's

00:21:56,570 --> 00:22:01,399
that maybe ten percent performance speed

00:21:58,759 --> 00:22:03,200
up so that's good news we can look

00:22:01,399 --> 00:22:09,440
forward to ten percent faster code as

00:22:03,200 --> 00:22:11,059
soon as scarlet to 12 comes out and the

00:22:09,440 --> 00:22:15,259
reason for that it could be because of a

00:22:11,059 --> 00:22:18,590
new optimizer it could be because the

00:22:15,259 --> 00:22:22,190
higher-order functions are now what are

00:22:18,590 --> 00:22:27,109
they called Sam's not sure exactly but

00:22:22,190 --> 00:22:30,559
it's definitely faster so further

00:22:27,109 --> 00:22:32,119
reading about inlining that I got a bit

00:22:30,559 --> 00:22:35,840
carried away here but there's there's so

00:22:32,119 --> 00:22:38,059
much information online them about not

00:22:35,840 --> 00:22:43,820
just in lining but the internals of the

00:22:38,059 --> 00:22:47,539
JVM and how the JVM works okay how am i

00:22:43,820 --> 00:22:49,970
doing for time okay I'll speed up a

00:22:47,539 --> 00:22:54,799
little bit second half the talk is

00:22:49,970 --> 00:22:58,509
specialization so just a quick refresher

00:22:54,799 --> 00:23:00,889
on how the type system works in the JVM

00:22:58,509 --> 00:23:03,460
we have primitive types which are

00:23:00,889 --> 00:23:05,989
billions and imps and things like that

00:23:03,460 --> 00:23:07,730
which are memory efficient they're not

00:23:05,989 --> 00:23:10,999
objects so they don't have the the

00:23:07,730 --> 00:23:13,840
object header overhead and they can be

00:23:10,999 --> 00:23:16,639
stored on the stack rather than the heap

00:23:13,840 --> 00:23:19,549
and they are passed around passed into

00:23:16,639 --> 00:23:22,009
functions by value and then on the other

00:23:19,549 --> 00:23:24,559
hand everything else is a reference type

00:23:22,009 --> 00:23:28,549
so it's an object it lives on the heap

00:23:24,559 --> 00:23:31,149
and you pass references to that objects

00:23:28,549 --> 00:23:37,190
rather than passing the object itself I

00:23:31,149 --> 00:23:39,739
think you probably know all this so

00:23:37,190 --> 00:23:42,799
generics let's have a quick look at Java

00:23:39,739 --> 00:23:46,220
first of all this is I in a class in

00:23:42,799 --> 00:23:49,879
Java that has a generic method foo it's

00:23:46,220 --> 00:23:51,830
got the a in in brackets saying it's

00:23:49,879 --> 00:23:53,359
generic in some type a it doesn't give

00:23:51,830 --> 00:23:55,340
any kind of bound on it it could be

00:23:53,359 --> 00:23:58,940
anything could be a need or a string or

00:23:55,340 --> 00:24:01,520
whatever and then we call it first with

00:23:58,940 --> 00:24:04,490
a string which is a reference type and

00:24:01,520 --> 00:24:07,000
with an int which is a primitive and if

00:24:04,490 --> 00:24:11,480
we have a look at the bike code for this

00:24:07,000 --> 00:24:14,330
at the top the underlying bit that says

00:24:11,480 --> 00:24:18,200
that even though we didn't put any bound

00:24:14,330 --> 00:24:21,680
on a it says a has to be an object which

00:24:18,200 --> 00:24:23,870
is the the ancestor of all reference

00:24:21,680 --> 00:24:26,980
types so it's restricted a to being a

00:24:23,870 --> 00:24:30,980
reference type which is a bit strange

00:24:26,980 --> 00:24:35,000
but this is basically because generics

00:24:30,980 --> 00:24:37,820
had to be retrofitted onto the JVM later

00:24:35,000 --> 00:24:44,600
after after the fact so this is the best

00:24:37,820 --> 00:24:47,450
they could do and then the the bytecode

00:24:44,600 --> 00:24:49,730
for the test method down below we can

00:24:47,450 --> 00:24:54,950
see that in circled in red we're having

00:24:49,730 --> 00:24:57,560
to convert our entire primitive into a

00:24:54,950 --> 00:25:00,620
reference type an integer with a with a

00:24:57,560 --> 00:25:02,860
big I we're having to call this integer

00:25:00,620 --> 00:25:05,900
or value of to convert a primitive to

00:25:02,860 --> 00:25:08,030
reference type can anyone tell me the

00:25:05,900 --> 00:25:11,810
name of this process of converting a

00:25:08,030 --> 00:25:17,810
primitive to a reference type yes it's

00:25:11,810 --> 00:25:20,390
boxing rest in peace and this boxing is

00:25:17,810 --> 00:25:24,020
obviously bad it's just overhead that we

00:25:20,390 --> 00:25:26,120
don't want to deal with but because of

00:25:24,020 --> 00:25:27,530
the way the JVM is arced architected and

00:25:26,120 --> 00:25:31,670
the way generics is implemented in the

00:25:27,530 --> 00:25:34,850
JVM is kind of unavoidable so how does

00:25:31,670 --> 00:25:37,310
this work in Scala again we have this

00:25:34,850 --> 00:25:39,200
split between a reference auric

00:25:37,310 --> 00:25:41,330
primitives on one side and reference

00:25:39,200 --> 00:25:44,260
types on the other so all the primitives

00:25:41,330 --> 00:25:48,380
extend any vowel and they are encoded as

00:25:44,260 --> 00:25:50,600
JVM primitives and then on the other

00:25:48,380 --> 00:25:55,280
side any ref is kind of equivalent to

00:25:50,600 --> 00:25:58,910
you java.lang.object so if we look at

00:25:55,280 --> 00:26:02,020
some generic code in Scala here we're

00:25:58,910 --> 00:26:05,180
using the standard libraries mutable map

00:26:02,020 --> 00:26:07,490
so we created in an empty map with int

00:26:05,180 --> 00:26:09,100
as its value type so it's got a

00:26:07,490 --> 00:26:12,050
primitive that it's about you tight and

00:26:09,100 --> 00:26:13,310
then we call it with 123 which is

00:26:12,050 --> 00:26:17,160
obviously a primitive

00:26:13,310 --> 00:26:20,130
we look at the bytecode for this we have

00:26:17,160 --> 00:26:23,790
the same problem calling boxes runtime

00:26:20,130 --> 00:26:25,410
dot box to integer so whether you're

00:26:23,790 --> 00:26:30,510
using Java or scholar you have the same

00:26:25,410 --> 00:26:33,590
problem boxing so how can we get around

00:26:30,510 --> 00:26:36,630
this well one way of doing it is

00:26:33,590 --> 00:26:39,710
specialization so the idea is that you

00:26:36,630 --> 00:26:42,690
generate multiple versions of a class

00:26:39,710 --> 00:26:44,370
specialized to each primitive type so

00:26:42,690 --> 00:26:46,170
you'd have an intern of your class you'd

00:26:44,370 --> 00:26:50,430
have a white version of your class and

00:26:46,170 --> 00:26:52,410
so on and then depending on what type

00:26:50,430 --> 00:26:55,830
you pass into it when you call the

00:26:52,410 --> 00:27:00,210
function the appropriate specialized

00:26:55,830 --> 00:27:02,730
version of the class would get used this

00:27:00,210 --> 00:27:05,280
is how you do it you just have to add

00:27:02,730 --> 00:27:07,650
this at specialized annotation to the

00:27:05,280 --> 00:27:10,470
type parameter of your class and just by

00:27:07,650 --> 00:27:12,570
doing that when you compile it the

00:27:10,470 --> 00:27:17,910
compiler will generate all of these ten

00:27:12,570 --> 00:27:21,440
also version to solve the class so here

00:27:17,910 --> 00:27:24,390
we do we've got my special map which is

00:27:21,440 --> 00:27:27,690
unlike an immutable map we've put and

00:27:24,390 --> 00:27:33,690
get but it's specialized so you can

00:27:27,690 --> 00:27:37,320
avoid that boxing overhead so if we have

00:27:33,690 --> 00:27:40,320
a look at it using this actually calling

00:27:37,320 --> 00:27:41,700
some methods on this it's similar to the

00:27:40,320 --> 00:27:43,950
sample code before but now we're using

00:27:41,700 --> 00:27:48,300
my special map rather than the standard

00:27:43,950 --> 00:27:51,300
library immutable map and we instantiate

00:27:48,300 --> 00:27:55,380
it with int as its parameter type type

00:27:51,300 --> 00:27:57,630
parameter so it these into specialized a

00:27:55,380 --> 00:28:00,630
version of the map we call its put

00:27:57,630 --> 00:28:02,580
method passing in one two three and then

00:28:00,630 --> 00:28:05,220
if we look at the bytecode now

00:28:02,580 --> 00:28:09,570
everything's nice and green we can see

00:28:05,220 --> 00:28:12,480
that here on line 11 we are pushing a

00:28:09,570 --> 00:28:15,390
nice primitive integer 1 2 3 on to the

00:28:12,480 --> 00:28:17,310
stack and then on line 13 we're in vote

00:28:15,390 --> 00:28:19,650
invoking the function and we're passing

00:28:17,310 --> 00:28:25,470
in this thing as an integer so there's

00:28:19,650 --> 00:28:26,410
no boxing going on here so one thing I

00:28:25,470 --> 00:28:29,020
didn't understand for

00:28:26,410 --> 00:28:31,180
I'll is how does the calling the caller

00:28:29,020 --> 00:28:35,140
code know that your function or your

00:28:31,180 --> 00:28:37,540
class is specialized say if I want to

00:28:35,140 --> 00:28:39,070
put my special map in a jar and publish

00:28:37,540 --> 00:28:41,350
it to maven central and then you start

00:28:39,070 --> 00:28:42,750
using it how does your when you compile

00:28:41,350 --> 00:28:45,370
your code how does it know that it's

00:28:42,750 --> 00:28:50,200
specialized and it can call the

00:28:45,370 --> 00:28:52,000
appropriate term specialized clubs and

00:28:50,200 --> 00:28:54,250
the answer is that specialized it is a

00:28:52,000 --> 00:28:57,160
so called static annotation which means

00:28:54,250 --> 00:29:01,050
that that specialized annotation gets

00:28:57,160 --> 00:29:04,750
stored into the class file for the class

00:29:01,050 --> 00:29:09,840
inside the scholar signature so in that

00:29:04,750 --> 00:29:14,920
big blob of binary if you decode that

00:29:09,840 --> 00:29:17,280
using the Scarlet signature format level

00:29:14,920 --> 00:29:19,840
protocol then you can see that the

00:29:17,280 --> 00:29:21,490
specialized annotation is actually in so

00:29:19,840 --> 00:29:23,440
the compiler can read that and though

00:29:21,490 --> 00:29:28,110
okay this class is specialized i will

00:29:23,440 --> 00:29:28,110
i'll use the appropriate version of it

00:29:30,870 --> 00:29:37,710
so as you may have noticed there is a

00:29:34,510 --> 00:29:40,690
space trade-off here every time you add

00:29:37,710 --> 00:29:42,940
specialized to a type parameter you're

00:29:40,690 --> 00:29:44,680
generating ten different classes and if

00:29:42,940 --> 00:29:47,860
you do that on to type parameters you're

00:29:44,680 --> 00:29:50,590
doing 100 classes three typewriters of

00:29:47,860 --> 00:29:52,720
that was in classes so it's kind of an

00:29:50,590 --> 00:29:56,530
exponential explosion in the number of

00:29:52,720 --> 00:29:58,600
classes you're generating and one way to

00:29:56,530 --> 00:30:00,490
avoid that is that you can specify

00:29:58,600 --> 00:30:03,730
exactly which types you want to

00:30:00,490 --> 00:30:06,700
specialize on so if you know that you my

00:30:03,730 --> 00:30:09,850
special map will only be used with int

00:30:06,700 --> 00:30:11,650
songs and doubles then you can you can

00:30:09,850 --> 00:30:15,280
specify that and that reduces the number

00:30:11,650 --> 00:30:17,770
of classes that are generated the

00:30:15,280 --> 00:30:19,360
problem is of course that if you if you

00:30:17,770 --> 00:30:21,430
want to publish this as a library for

00:30:19,360 --> 00:30:23,440
other people to use is pretty hard to

00:30:21,430 --> 00:30:28,120
predict what types people will want to

00:30:23,440 --> 00:30:30,330
use and if any of you went to the dot e

00:30:28,120 --> 00:30:34,840
linker talked this morning then he

00:30:30,330 --> 00:30:37,480
Dimitri talked about a way that the dot

00:30:34,840 --> 00:30:38,659
e linker in the bright new future will

00:30:37,480 --> 00:30:40,970
be able to solve this problem

00:30:38,659 --> 00:30:43,700
for us and do automatic specialization

00:30:40,970 --> 00:30:49,460
so that will be really exciting when it

00:30:43,700 --> 00:30:50,570
happens so how how do things look in the

00:30:49,460 --> 00:30:54,889
scholar standard library at the moment

00:30:50,570 --> 00:30:58,039
to be honest it's a bit of a mess so to

00:30:54,889 --> 00:31:00,739
pull one is specialized in int along a

00:30:58,039 --> 00:31:02,749
double to Paul to is specialized in int

00:31:00,739 --> 00:31:05,929
long double charm boolean for some

00:31:02,749 --> 00:31:08,259
reason tuple three has no specialization

00:31:05,929 --> 00:31:12,619
so if you use tuple three you get boxing

00:31:08,259 --> 00:31:14,950
option is boxing function 01 and to have

00:31:12,619 --> 00:31:17,809
a kind of random combination of

00:31:14,950 --> 00:31:20,509
specializations on on their various

00:31:17,809 --> 00:31:21,830
parameters and then all of the

00:31:20,509 --> 00:31:26,720
collections classes have no

00:31:21,830 --> 00:31:28,759
specialization so boxing so if you want

00:31:26,720 --> 00:31:32,450
to avoid boxing what what do you do

00:31:28,759 --> 00:31:35,419
there are a few alternatives there's

00:31:32,450 --> 00:31:38,919
library called D box and another one

00:31:35,419 --> 00:31:43,340
called metal and these both provides

00:31:38,919 --> 00:31:48,229
mutable collection classes like math and

00:31:43,340 --> 00:31:51,409
set and and list and so on but with

00:31:48,229 --> 00:31:53,720
specialization so no boxing and then

00:31:51,409 --> 00:31:56,749
there is also an alternative approach

00:31:53,720 --> 00:31:58,190
approach that's not specialized so it

00:31:56,749 --> 00:32:02,659
doesn't use the specialized annotation

00:31:58,190 --> 00:32:06,200
it's called mini boxing it involves a

00:32:02,659 --> 00:32:07,609
compiler plugin and it's quite

00:32:06,200 --> 00:32:09,379
complicated I won't go into the details

00:32:07,609 --> 00:32:12,080
here but it's definitely worth having a

00:32:09,379 --> 00:32:16,789
look at if you're interested in using

00:32:12,080 --> 00:32:18,859
the specialization the idea of mini

00:32:16,789 --> 00:32:20,809
boxing is that it should give the same

00:32:18,859 --> 00:32:26,320
speed ups a specialization but it

00:32:20,809 --> 00:32:26,320
results in fewer classes being generated

00:32:27,070 --> 00:32:32,059
ok so just like before we'll run some

00:32:30,229 --> 00:32:35,509
benchmarks we've got two different

00:32:32,059 --> 00:32:38,450
benchmarks this time the first one is a

00:32:35,509 --> 00:32:41,629
bloom filter so a bloom filter is a

00:32:38,450 --> 00:32:44,299
probabilistic data structure it's it's

00:32:41,629 --> 00:32:47,299
like a set but it has this query method

00:32:44,299 --> 00:32:50,539
that will tell you if a certain element

00:32:47,299 --> 00:32:51,570
is probably in the set so it returns a

00:32:50,539 --> 00:32:53,970
boolean and if it's

00:32:51,570 --> 00:32:55,920
rue it means it's probably intercept if

00:32:53,970 --> 00:32:58,170
it's false it means is definitely not in

00:32:55,920 --> 00:33:02,190
the set so in some use cases this is

00:32:58,170 --> 00:33:04,830
this is good enough and this uses a lot

00:33:02,190 --> 00:33:06,690
less space than if you were to put all

00:33:04,830 --> 00:33:08,040
of the elements into a normal set so

00:33:06,690 --> 00:33:12,630
it's useful when you have millions and

00:33:08,040 --> 00:33:15,270
millions of elements so I've added a

00:33:12,630 --> 00:33:19,110
specialized annotation on the the a type

00:33:15,270 --> 00:33:22,920
parameter of my Bluebird filter and the

00:33:19,110 --> 00:33:24,810
point of the benchmark is does this this

00:33:22,920 --> 00:33:29,180
specialized annotation speed things up

00:33:24,810 --> 00:33:32,550
and the results are a bit disappointing

00:33:29,180 --> 00:33:35,750
so with specialization and without

00:33:32,550 --> 00:33:39,360
specialization is basically no change I

00:33:35,750 --> 00:33:41,580
think the reason is that the bloom

00:33:39,360 --> 00:33:43,170
filter is doing quite a lot of other

00:33:41,580 --> 00:33:45,510
stuff it's computing hash functions

00:33:43,170 --> 00:33:47,820
things and so the benefits that you get

00:33:45,510 --> 00:33:50,040
from specialization are just dilute its

00:33:47,820 --> 00:33:52,860
they're not really that important in the

00:33:50,040 --> 00:33:54,630
grand scheme of things so that's a bit

00:33:52,860 --> 00:33:57,980
disappointing but let's have another

00:33:54,630 --> 00:34:00,900
look have a look at another benchmark

00:33:57,980 --> 00:34:05,220
this is another different data structure

00:34:00,900 --> 00:34:06,660
we've got a pen only mutable buffer so

00:34:05,220 --> 00:34:08,760
you can append stuff onto the end of it

00:34:06,660 --> 00:34:11,540
and then it's got a for each so you can

00:34:08,760 --> 00:34:14,720
iterate all over all of its content and

00:34:11,540 --> 00:34:17,250
the benchmark is to create one of these

00:34:14,720 --> 00:34:20,610
buffers with a million integers in it

00:34:17,250 --> 00:34:23,100
and then do a for each and just loop

00:34:20,610 --> 00:34:25,460
through all of them and this time the

00:34:23,100 --> 00:34:28,470
results are much more satisfying we've

00:34:25,460 --> 00:34:32,610
just by adding specialization we have

00:34:28,470 --> 00:34:35,060
doubled the speed of the code so that's

00:34:32,610 --> 00:34:35,060
much better

00:34:37,179 --> 00:34:44,730
again we've got a bit of further reading

00:34:39,629 --> 00:34:44,730
Dimitri's Skala days talk is in there

00:34:45,210 --> 00:34:52,359
finally honorable mentions so this is

00:34:48,970 --> 00:34:53,980
just a few other annotations that are in

00:34:52,359 --> 00:34:55,210
the standard library that I discovered

00:34:53,980 --> 00:34:57,640
while I was writing this talk and

00:34:55,210 --> 00:35:01,690
they're quite interesting but not enough

00:34:57,640 --> 00:35:04,990
to make a whole talk about so first of

00:35:01,690 --> 00:35:10,450
all we've got strict FP so apparently in

00:35:04,990 --> 00:35:13,809
the jvm spec you can add a claw flag to

00:35:10,450 --> 00:35:17,020
a class file the strict FP flag which

00:35:13,809 --> 00:35:20,230
means make sure that my floating point

00:35:17,020 --> 00:35:22,420
operations give exactly the same answer

00:35:20,230 --> 00:35:24,930
on all platforms no matter where the

00:35:22,420 --> 00:35:28,780
code runs I want to get the same answer

00:35:24,930 --> 00:35:32,520
so if you don't have that then you will

00:35:28,780 --> 00:35:34,569
get more accurate floating-point

00:35:32,520 --> 00:35:37,210
calculations but they might be different

00:35:34,569 --> 00:35:39,990
depending on where your code ones so

00:35:37,210 --> 00:35:43,990
that might be useful in certain cases

00:35:39,990 --> 00:35:46,030
second is switch so when you do a

00:35:43,990 --> 00:35:49,690
pattern matching Scala that actually

00:35:46,030 --> 00:35:51,579
gets compiled down to some bytecode and

00:35:49,690 --> 00:35:53,140
there's no there's no bytecode

00:35:51,579 --> 00:35:56,290
instructions for pattern match so it

00:35:53,140 --> 00:36:01,299
needs to be lowered to one of a few

00:35:56,290 --> 00:36:03,549
different statements so if it happens to

00:36:01,299 --> 00:36:07,950
be a switch sorry I pattern match on

00:36:03,549 --> 00:36:10,900
integers then it can potentially be

00:36:07,950 --> 00:36:14,230
encoded in byte code as one of these

00:36:10,900 --> 00:36:16,480
very performant byte codes or table

00:36:14,230 --> 00:36:17,859
switch or look up switch and if you want

00:36:16,480 --> 00:36:19,569
to ensure that's going to happen when

00:36:17,859 --> 00:36:22,960
your code is going to run quickly then

00:36:19,569 --> 00:36:25,770
you can add this switch annotation and

00:36:22,960 --> 00:36:28,900
finally Alai dab'll is the weirdest one

00:36:25,770 --> 00:36:31,660
so it's an annotation for methods whose

00:36:28,900 --> 00:36:34,329
bodies may be excluded from compiler

00:36:31,660 --> 00:36:36,339
generated by code so you can anise you

00:36:34,329 --> 00:36:38,980
can write your code you've got your

00:36:36,339 --> 00:36:41,380
function but then you add a light able

00:36:38,980 --> 00:36:46,619
to it and then when the compiler runs it

00:36:41,380 --> 00:36:46,619
just deletes it just strips it out so

00:36:49,130 --> 00:36:53,999
although i should say because somebody

00:36:51,929 --> 00:36:56,459
heckled me about this in New York there

00:36:53,999 --> 00:36:58,979
is one good use case for it and that is

00:36:56,459 --> 00:37:01,679
to remove the assert statements from the

00:36:58,979 --> 00:37:04,019
compiler so it's used in the compiler to

00:37:01,679 --> 00:37:06,749
all of the assert statements have this

00:37:04,019 --> 00:37:09,089
Alai dab'll annotation on them so they

00:37:06,749 --> 00:37:15,569
they get removed completely when you the

00:37:09,089 --> 00:37:18,869
compiler is compiled fair enough so just

00:37:15,569 --> 00:37:22,439
to sum up in line is for inlining

00:37:18,869 --> 00:37:25,219
obviously should you use it in general

00:37:22,439 --> 00:37:29,630
probably not just leave it up to hotspot

00:37:25,219 --> 00:37:33,299
it does a pretty good job in most cases

00:37:29,630 --> 00:37:36,299
specialized should you use it it depends

00:37:33,299 --> 00:37:38,669
it seems to be useful in some cases but

00:37:36,299 --> 00:37:40,019
just make sure that you benchmark it and

00:37:38,669 --> 00:37:45,809
make sure it's actually doing something

00:37:40,019 --> 00:37:47,819
useful for your code so that's it that's

00:37:45,809 --> 00:37:49,589
my cat Eric the slides are online and

00:37:47,819 --> 00:37:53,059
the code for the benchmarks is also

00:37:49,589 --> 00:37:53,059
online thank you very much

00:37:59,100 --> 00:38:03,160
if you have any questions then please go

00:38:01,630 --> 00:38:12,570
to the mics there's one there and one

00:38:03,160 --> 00:38:15,910
over there you had in your specialized

00:38:12,570 --> 00:38:19,450
example yeah you put specialized both on

00:38:15,910 --> 00:38:22,900
the crate in the class what was the

00:38:19,450 --> 00:38:25,210
reason for that sorry where was that it

00:38:22,900 --> 00:38:31,120
just missed it on the bloom filter yeah

00:38:25,210 --> 00:38:32,680
oh yeah so this is you have to be very

00:38:31,120 --> 00:38:35,350
careful when you do specialization that

00:38:32,680 --> 00:38:39,730
you you have to specialize all the way

00:38:35,350 --> 00:38:41,590
down if you have you have your function

00:38:39,730 --> 00:38:43,540
that somebody's calling and passing in a

00:38:41,590 --> 00:38:45,420
primitive then you want that to be

00:38:43,540 --> 00:38:48,220
specialized obviously but then if that

00:38:45,420 --> 00:38:49,720
internally calls another function on say

00:38:48,220 --> 00:38:52,210
on the same class or on another class

00:38:49,720 --> 00:38:53,590
and you don't have that function

00:38:52,210 --> 00:38:56,770
specialized then you will still get

00:38:53,590 --> 00:39:02,050
boxing at that point so I haven't shown

00:38:56,770 --> 00:39:04,870
my implementation here but when you you

00:39:02,050 --> 00:39:06,100
do an ad or a query on bloom filter when

00:39:04,870 --> 00:39:08,530
you call one of those two methods then

00:39:06,100 --> 00:39:11,140
internally will call the hash functions

00:39:08,530 --> 00:39:13,240
trait and it will call the method on

00:39:11,140 --> 00:39:15,550
there and so I wanted to make sure that

00:39:13,240 --> 00:39:16,650
was specialized as well so you have to

00:39:15,550 --> 00:39:19,540
be really careful when you use

00:39:16,650 --> 00:39:22,510
specialized because it's very easy to

00:39:19,540 --> 00:39:24,520
accidentally do boxing somewhere in your

00:39:22,510 --> 00:39:27,130
code so you end up doing quite a lot of

00:39:24,520 --> 00:39:36,580
Java p work and checking the bytecode to

00:39:27,130 --> 00:39:40,330
make sure you got really not boxing you

00:39:36,580 --> 00:39:42,490
mentioned optimized flag for scale AC

00:39:40,330 --> 00:39:47,200
compiler yeah do I understand correctly

00:39:42,490 --> 00:39:49,480
that this flag is only for skull

00:39:47,200 --> 00:39:52,060
annotations so it's not for first hot

00:39:49,480 --> 00:39:54,640
spot hot spot will in line anything what

00:39:52,060 --> 00:39:57,520
I need it will be inlined in runtime

00:39:54,640 --> 00:40:00,040
right yes that is correct if you want to

00:39:57,520 --> 00:40:03,370
do in lining in Scala see at compile

00:40:00,040 --> 00:40:07,840
time you need- optimized but hot spot

00:40:03,370 --> 00:40:10,690
will always run oh and by the way it's

00:40:07,840 --> 00:40:12,310
worth mentioning that optimize the minus

00:40:10,690 --> 00:40:15,290
optimize flag is a bit

00:40:12,310 --> 00:40:17,720
suspicious like for example in the Acker

00:40:15,290 --> 00:40:20,390
official documentation there's a big red

00:40:17,720 --> 00:40:22,970
box that says do not use optimize it

00:40:20,390 --> 00:40:32,270
will break your code so use at your own

00:40:22,970 --> 00:40:34,990
risk okay looks like no more questions

00:40:32,270 --> 00:40:34,990

YouTube URL: https://www.youtube.com/watch?v=LDIvBxTo15A


