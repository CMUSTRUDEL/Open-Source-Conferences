Title: Monitoring Reactive Applications by Duncan DeVore & Henrik EngstroÌˆm
Publication date: 2016-07-04
Playlist: Scala Days Berlin 2016
Description: 
	This video was recorded at Scala Days Berlin 2016
follow us on Twitter @ScalaDays or visit our website for more information http://scaladays.org 

Abstract: 
Reactive Applications are the next major evolution of the Internet. They allow for applications to be responsive, scalable and resilient by building on a fully event-driven foundation. Lightbendâ€™s Reactive Platform, consisting of the Play Framework, the Akka middleware and the Scala programming language embraces this new programming paradigm which allows developers to write interactive applications that are always available and which adapt to changing load by being distributed by design.While the reactive approach enable us to build highly scalable and resilient applications it also introduces new challenges in how to monitor them. Almost every current monitoring tool relies on a stack frame based approach where using the stack trace can provide good answers to what caused the exceptional state. In message driven, or asynchronous, applications this approach no longer provides any good information. We therefore need to invent new approaches for how to monitor these types of applications. During this session we will cover the traditional monitoring approach, different possible ways of how to monitor asynchronous applications and finally show the way we have chosen to build a monitoring tool for reactive applications at Lightbend.
Captions: 
	00:00:01,950 --> 00:00:06,269
hi everyone we're super excited to be

00:00:04,230 --> 00:00:08,580
here my name is henrik and this is

00:00:06,269 --> 00:00:11,400
duncan and we're both engineers at like

00:00:08,580 --> 00:00:12,900
bend and we're working in the monitoring

00:00:11,400 --> 00:00:14,280
team it like been so today we're going

00:00:12,900 --> 00:00:20,490
to talk about monitoring reactive

00:00:14,280 --> 00:00:22,200
applications there's this rating rating

00:00:20,490 --> 00:00:23,660
thing in the application if you

00:00:22,200 --> 00:00:27,740
downloaded that so you can read us

00:00:23,660 --> 00:00:29,790
before or after so the agenda today

00:00:27,740 --> 00:00:33,420
we're going to talk a little bit what

00:00:29,790 --> 00:00:35,730
monitoring is the traditional way of

00:00:33,420 --> 00:00:37,620
monitoring applications the

00:00:35,730 --> 00:00:41,160
architectural shift what's going on

00:00:37,620 --> 00:00:43,110
right now being reactive applications of

00:00:41,160 --> 00:00:45,870
course and then how to monitor reactive

00:00:43,110 --> 00:00:48,510
applications some trends in monitoring

00:00:45,870 --> 00:00:50,550
and best practice and then a little bit

00:00:48,510 --> 00:00:54,420
finally about what we're doing it like

00:00:50,550 --> 00:00:56,550
Bend so what is monitoring well

00:00:54,420 --> 00:00:58,649
monitoring according to Wikipedia is to

00:00:56,550 --> 00:01:00,149
be aware of a state of a system to

00:00:58,649 --> 00:01:02,730
observe a situation for any changes

00:01:00,149 --> 00:01:04,670
which may occur over time using a

00:01:02,730 --> 00:01:07,139
monitoring or measuring device some sort

00:01:04,670 --> 00:01:09,030
now this of course can mean a lot of

00:01:07,139 --> 00:01:12,770
things let's try to narrow it down a

00:01:09,030 --> 00:01:15,659
little for monitoring computer systems

00:01:12,770 --> 00:01:17,819
we have different categories of

00:01:15,659 --> 00:01:21,049
monitoring so first of all you have this

00:01:17,819 --> 00:01:24,170
thing called business process monitoring

00:01:21,049 --> 00:01:27,209
basically you can think of this as if

00:01:24,170 --> 00:01:29,280
you have a credit card system if you're

00:01:27,209 --> 00:01:31,979
a bank then maybe you want to detect

00:01:29,280 --> 00:01:33,899
fraud so you're looking at different

00:01:31,979 --> 00:01:36,389
transactions and if there's a purchase

00:01:33,899 --> 00:01:38,459
being made in Athens and five minute

00:01:36,389 --> 00:01:40,770
later five minutes later it's done in

00:01:38,459 --> 00:01:42,749
Rome then you could suspect things right

00:01:40,770 --> 00:01:45,299
you want to keep track of that that's

00:01:42,749 --> 00:01:47,639
business process monitoring you can also

00:01:45,299 --> 00:01:49,439
think of this as a key performance

00:01:47,639 --> 00:01:53,729
indicator where you have a dashboard and

00:01:49,439 --> 00:01:56,219
you basically just look at one circle if

00:01:53,729 --> 00:01:58,560
it's green yellow red and then you can

00:01:56,219 --> 00:02:00,779
drill down from there to get into the

00:01:58,560 --> 00:02:02,880
the next level which would be functional

00:02:00,779 --> 00:02:05,490
monitoring and functional monitoring

00:02:02,880 --> 00:02:08,490
could be a credit card transaction just

00:02:05,490 --> 00:02:09,869
one where you do a purchase and you just

00:02:08,490 --> 00:02:13,110
want to make sure that this is working

00:02:09,869 --> 00:02:15,840
as it should and the final thing is the

00:02:13,110 --> 00:02:18,450
technical monitoring where you focus on

00:02:15,840 --> 00:02:20,430
individual pieces of this and that could

00:02:18,450 --> 00:02:24,360
be like the transaction time to

00:02:20,430 --> 00:02:26,430
MasterCard or Visa there are different

00:02:24,360 --> 00:02:28,140
types of monitoring so one is system

00:02:26,430 --> 00:02:31,260
monitoring where you're looking at the

00:02:28,140 --> 00:02:36,299
network traffic or you know CPU or

00:02:31,260 --> 00:02:37,590
memory utilization so that's one thing

00:02:36,299 --> 00:02:40,470
that we're doing it would like by

00:02:37,590 --> 00:02:42,410
monitoring another another thing is were

00:02:40,470 --> 00:02:44,430
you looking at transaction monitoring

00:02:42,410 --> 00:02:47,610
basically tracing you want to make sure

00:02:44,430 --> 00:02:49,819
that you can have IDs following what's

00:02:47,610 --> 00:02:51,870
going on inside of your application

00:02:49,819 --> 00:02:53,459
there's also this thing called

00:02:51,870 --> 00:02:55,170
performance monitoring where you might

00:02:53,459 --> 00:02:57,599
want to make sure that you can cram out

00:02:55,170 --> 00:02:59,730
the most out of your system so you want

00:02:57,599 --> 00:03:03,060
to see how it performs under stress load

00:02:59,730 --> 00:03:05,549
things like that integration monitoring

00:03:03,060 --> 00:03:07,500
which is very popular now with when

00:03:05,549 --> 00:03:10,950
everyone is talking about micro services

00:03:07,500 --> 00:03:14,310
where you basically you can think of

00:03:10,950 --> 00:03:16,560
this as a dashboard again this is

00:03:14,310 --> 00:03:19,010
netflix has this thing called historic

00:03:16,560 --> 00:03:21,690
stash board where they're looking at how

00:03:19,010 --> 00:03:23,190
individual microservice are operating

00:03:21,690 --> 00:03:26,190
and they're actually doing it from the

00:03:23,190 --> 00:03:28,500
clients perspective so the client is

00:03:26,190 --> 00:03:32,430
basically sending information about how

00:03:28,500 --> 00:03:34,530
the server is doing and finally there's

00:03:32,430 --> 00:03:36,660
this thing called application monitoring

00:03:34,530 --> 00:03:39,170
and for us that means looking into

00:03:36,660 --> 00:03:42,000
things like you know actor mailbox

00:03:39,170 --> 00:03:44,160
number of messages in the mailbox or

00:03:42,000 --> 00:03:48,540
processing time per message inside of

00:03:44,160 --> 00:03:50,250
vodka so traditional monitoring you

00:03:48,540 --> 00:03:51,870
normally have these layers and then you

00:03:50,250 --> 00:03:54,269
have a request coming in to the web

00:03:51,870 --> 00:03:55,919
layer that goes on to the next layer

00:03:54,269 --> 00:03:58,859
application layer and all of a sudden

00:03:55,919 --> 00:04:01,590
you have an exception now this being a

00:03:58,859 --> 00:04:03,959
synchronous call just looking at the

00:04:01,590 --> 00:04:06,000
exception here which of course there's a

00:04:03,959 --> 00:04:08,220
lot of layers in this exception it's a

00:04:06,000 --> 00:04:10,290
traditional spring application so there

00:04:08,220 --> 00:04:12,359
are a lot of layers but but the

00:04:10,290 --> 00:04:14,220
exception in itself actually tells you

00:04:12,359 --> 00:04:16,829
what's been going on up until this point

00:04:14,220 --> 00:04:18,989
so just logging this except exceptional

00:04:16,829 --> 00:04:20,700
looking at it you can kind of make sense

00:04:18,989 --> 00:04:23,940
of what's been happening up until this

00:04:20,700 --> 00:04:26,640
point and also if this if there's no

00:04:23,940 --> 00:04:29,430
exception the request comes back then

00:04:26,640 --> 00:04:30,900
it's fairly simple to gather metrics

00:04:29,430 --> 00:04:32,370
based on this because it's being a

00:04:30,900 --> 00:04:33,930
synchronous call so you know there's

00:04:32,370 --> 00:04:36,240
going to be a request and a response

00:04:33,930 --> 00:04:38,580
back so you can measure time times and

00:04:36,240 --> 00:04:46,440
things like that so that's the

00:04:38,580 --> 00:04:49,170
traditional monitoring so how good

00:04:46,440 --> 00:04:53,190
everybody can hear me so the issue

00:04:49,170 --> 00:04:55,050
behind monitoring is it's kind of it's a

00:04:53,190 --> 00:04:56,820
lot of data right there's a lot of stuff

00:04:55,050 --> 00:04:59,730
going on and you're trying to distill

00:04:56,820 --> 00:05:01,620
what's going on and one of the things I

00:04:59,730 --> 00:05:04,620
like to do is a reminder is how we got

00:05:01,620 --> 00:05:07,020
here and this architectural shift from

00:05:04,620 --> 00:05:10,290
the 50s into the 60s and so forth as the

00:05:07,020 --> 00:05:14,490
internet came into being it started out

00:05:10,290 --> 00:05:18,420
with DARPA and the notion of a galactic

00:05:14,490 --> 00:05:21,360
were interconnected global computing

00:05:18,420 --> 00:05:22,740
network but this gentleman Lickliter has

00:05:21,360 --> 00:05:25,740
some pretty amazing papers on the

00:05:22,740 --> 00:05:28,320
subject and that brought us into this

00:05:25,740 --> 00:05:31,230
idea of distributed computing which is

00:05:28,320 --> 00:05:33,740
what the whole reactive movement is or

00:05:31,230 --> 00:05:36,990
the reactive manifesto is kind of

00:05:33,740 --> 00:05:39,420
distilling for the business programmer

00:05:36,990 --> 00:05:41,850
for the most part whereas distributed

00:05:39,420 --> 00:05:43,230
computing was generally for companies

00:05:41,850 --> 00:05:44,940
like Google and Netflix and all these

00:05:43,230 --> 00:05:47,520
types of companies well now we see all

00:05:44,940 --> 00:05:49,500
kinds of smaller businesses or even

00:05:47,520 --> 00:05:51,720
larger businesses that aren't used to

00:05:49,500 --> 00:05:54,150
the distributed computing model getting

00:05:51,720 --> 00:05:57,060
into it and it started back in the 70s

00:05:54,150 --> 00:05:59,880
with the mainframe and and many

00:05:57,060 --> 00:06:02,130
computers being the core hub like the

00:05:59,880 --> 00:06:04,290
as400 and then branched out from there

00:06:02,130 --> 00:06:06,680
and so we had to deal with a new way to

00:06:04,290 --> 00:06:08,880
write programs a new paradigm because

00:06:06,680 --> 00:06:10,500
memory models are different and

00:06:08,880 --> 00:06:15,270
distributed systems and they are in a

00:06:10,500 --> 00:06:17,790
local system but what really happened in

00:06:15,270 --> 00:06:19,530
the 90s was the whole cloud computing

00:06:17,790 --> 00:06:22,230
thing where distributed computing is the

00:06:19,530 --> 00:06:24,780
technical aspect cloud computing ended

00:06:22,230 --> 00:06:27,720
up being the monetary aspect of it or

00:06:24,780 --> 00:06:30,090
the economics and once business got

00:06:27,720 --> 00:06:33,090
involved in the 90s to the Internet it

00:06:30,090 --> 00:06:34,890
kind of opened the doors to the Internet

00:06:33,090 --> 00:06:37,650
as we see it today and all kinds of

00:06:34,890 --> 00:06:39,990
stuff started happening multi-billion

00:06:37,650 --> 00:06:42,060
dollar companies that used to take 20 30

00:06:39,990 --> 00:06:42,610
40 years that come into existence came

00:06:42,060 --> 00:06:45,669
into

00:06:42,610 --> 00:06:47,919
within a matter of years and it really

00:06:45,669 --> 00:06:50,050
changed the dynamics of our economy it

00:06:47,919 --> 00:06:53,219
changed the dynamics of everything but

00:06:50,050 --> 00:06:56,349
in so doing we now have these systems

00:06:53,219 --> 00:06:58,750
that provide us you know the network is

00:06:56,349 --> 00:07:00,789
the computer kind of the Sun moniker

00:06:58,750 --> 00:07:03,129
there but we now have these systems

00:07:00,789 --> 00:07:05,319
because of things that used to be

00:07:03,129 --> 00:07:07,710
extremely expensive like storage and

00:07:05,319 --> 00:07:13,569
network and when I was younger I had a

00:07:07,710 --> 00:07:16,779
TI 99 and the i think i paid $1,500 for

00:07:13,569 --> 00:07:18,520
the whole system and i think i had 4k a

00:07:16,779 --> 00:07:21,039
memory or something like that and i used

00:07:18,520 --> 00:07:25,689
to store things on a cassette tape so

00:07:21,039 --> 00:07:29,590
but today storage cpu costs bandwidth

00:07:25,689 --> 00:07:33,189
cost for a while i ran an ISP and i had

00:07:29,590 --> 00:07:34,870
two t1s coming into my office and that

00:07:33,189 --> 00:07:38,889
was fifteen hundred dollars a month and

00:07:34,870 --> 00:07:41,199
now i have fios it's 75 up and down and

00:07:38,889 --> 00:07:44,199
it's a hundred dollars a month so the

00:07:41,199 --> 00:07:46,300
economics drastically changed and so

00:07:44,199 --> 00:07:48,279
they allowed a lot of people to get

00:07:46,300 --> 00:07:51,039
involved in these types of scenarios

00:07:48,279 --> 00:07:54,009
whereas before it was much smaller

00:07:51,039 --> 00:07:58,210
playing field and the use of the network

00:07:54,009 --> 00:08:00,430
increased dramatically from a company

00:07:58,210 --> 00:08:03,940
perspective I like to use this example

00:08:00,430 --> 00:08:07,060
these two examples amazon not only did

00:08:03,940 --> 00:08:09,159
the economics affect us and allowing us

00:08:07,060 --> 00:08:11,620
to be able to get involved in this arena

00:08:09,159 --> 00:08:16,150
but it also shaped how we view ourselves

00:08:11,620 --> 00:08:19,680
as a company so amazon up until two

00:08:16,150 --> 00:08:24,250
thousand seven ish their retail sales

00:08:19,680 --> 00:08:26,500
outpaced their infrastructure or network

00:08:24,250 --> 00:08:28,270
sales or cloud services they had to

00:08:26,500 --> 00:08:31,260
build a whole new infrastructure to

00:08:28,270 --> 00:08:34,659
support what they were doing and then

00:08:31,260 --> 00:08:36,669
2007 around their cloud services started

00:08:34,659 --> 00:08:38,560
to outpace the retail sales so they had

00:08:36,669 --> 00:08:41,110
to step back and say what are we are we

00:08:38,560 --> 00:08:43,240
an online retailer or are we a provider

00:08:41,110 --> 00:08:45,190
of services for other people that want

00:08:43,240 --> 00:08:47,320
to get on the internet that's a pretty

00:08:45,190 --> 00:08:51,279
dramatic shift in what you view yourself

00:08:47,320 --> 00:08:54,029
as and of course Netflix and blockbuster

00:08:51,279 --> 00:08:56,470
right blockbuster was king of the hill I

00:08:54,029 --> 00:08:59,080
remember when blockbuster was around

00:08:56,470 --> 00:09:00,340
Netflix first came out and my friend

00:08:59,080 --> 00:09:02,590
said you have to check it out I'm like

00:09:00,340 --> 00:09:04,930
seriously I'm not going to order DVDs to

00:09:02,590 --> 00:09:06,670
the mail you know maybe if they stream

00:09:04,930 --> 00:09:09,250
someday but blockbuster will be here

00:09:06,670 --> 00:09:11,110
forever blockbuster was a multi-million

00:09:09,250 --> 00:09:13,240
dollar or a multi-billion dollar company

00:09:11,110 --> 00:09:15,160
and they actually had an opportunity to

00:09:13,240 --> 00:09:16,720
buy netflix I think for two million

00:09:15,160 --> 00:09:18,850
dollars at something at one point but

00:09:16,720 --> 00:09:22,360
they turn them down if you look at it

00:09:18,850 --> 00:09:23,740
today where's blockbuster you know many

00:09:22,360 --> 00:09:27,310
younger kids have never even heard of

00:09:23,740 --> 00:09:33,250
blockbuster so it has a dramatic impact

00:09:27,310 --> 00:09:35,290
on our our business model and it used to

00:09:33,250 --> 00:09:37,810
be if you have lots of money and you had

00:09:35,290 --> 00:09:40,090
lots of resources you were kind of king

00:09:37,810 --> 00:09:43,900
of the hill many of the clients that we

00:09:40,090 --> 00:09:45,970
work for or rather large and some of the

00:09:43,900 --> 00:09:48,250
competition is rather small they're very

00:09:45,970 --> 00:09:50,710
agile they're very quick who would have

00:09:48,250 --> 00:09:52,540
thought a company with four guys in

00:09:50,710 --> 00:09:54,940
their 20s could compete against a

00:09:52,540 --> 00:09:57,070
billion-dollar company I mean that

00:09:54,940 --> 00:10:00,730
sounds absurd but it's it's a fact in

00:09:57,070 --> 00:10:03,240
today's world so here we have the micro

00:10:00,730 --> 00:10:06,760
services chasing after the monolith

00:10:03,240 --> 00:10:09,100
right it's the fast fish that eats the

00:10:06,760 --> 00:10:13,530
slow fish now not the big fish anymore

00:10:09,100 --> 00:10:15,610
and we have this whole notion of

00:10:13,530 --> 00:10:18,730
reactive rate we're all familiar with it

00:10:15,610 --> 00:10:22,360
responsiveness monitoring very much in

00:10:18,730 --> 00:10:24,190
many ways is akin to being responsive

00:10:22,360 --> 00:10:25,870
rate it doesn't matter how good your

00:10:24,190 --> 00:10:27,580
application is it doesn't matter how

00:10:25,870 --> 00:10:29,530
well it scales it doesn't matter any of

00:10:27,580 --> 00:10:31,180
that stuff if at the top you're not

00:10:29,530 --> 00:10:32,980
responding to your customer if you're

00:10:31,180 --> 00:10:36,010
not responding to your client in some

00:10:32,980 --> 00:10:39,010
way regardless of how good you are if

00:10:36,010 --> 00:10:40,770
your communication is is tainted then

00:10:39,010 --> 00:10:43,030
you're going to have a problem I

00:10:40,770 --> 00:10:44,440
remember a long time ago through going

00:10:43,030 --> 00:10:46,620
through consulting training and they

00:10:44,440 --> 00:10:48,370
said perception is reality and

00:10:46,620 --> 00:10:50,140
unfortunately there's some truth to that

00:10:48,370 --> 00:10:53,020
but the reality of it is it's the same

00:10:50,140 --> 00:10:55,000
thing with us and monitoring we want to

00:10:53,020 --> 00:10:59,580
be able to be responsive but there is so

00:10:55,000 --> 00:11:03,010
much stuff going on in any given system

00:10:59,580 --> 00:11:05,320
so again we're familiar with these

00:11:03,010 --> 00:11:06,370
things but at the top if you if we go

00:11:05,320 --> 00:11:09,130
back to previous side you have

00:11:06,370 --> 00:11:10,160
responsiveness message driven at the

00:11:09,130 --> 00:11:12,350
bottom and then

00:11:10,160 --> 00:11:17,000
that it all works together in this

00:11:12,350 --> 00:11:18,949
pillar structure and so today what we

00:11:17,000 --> 00:11:22,430
have is we have the ability with these

00:11:18,949 --> 00:11:24,470
toolkits like akka and play and legume

00:11:22,430 --> 00:11:28,670
and and different tool kits we can begin

00:11:24,470 --> 00:11:30,980
to build these systems that are isolated

00:11:28,670 --> 00:11:33,350
and bulk headed against failure and can

00:11:30,980 --> 00:11:34,970
scale independently and so forth have

00:11:33,350 --> 00:11:37,790
asynchronous boundaries and they can

00:11:34,970 --> 00:11:40,069
kind of work together in cohesion to

00:11:37,790 --> 00:11:42,019
provide a solution so there's a lot of

00:11:40,069 --> 00:11:44,089
advantages to being able to design

00:11:42,019 --> 00:11:47,240
systems like that obviously there's

00:11:44,089 --> 00:11:50,149
issues too but one of the problems now

00:11:47,240 --> 00:11:52,069
becomes as monitoring how do I monitor

00:11:50,149 --> 00:11:55,910
these systems I have systems that have

00:11:52,069 --> 00:11:58,720
asynchronous boundaries that have a very

00:11:55,910 --> 00:12:02,240
light white protocol between each other

00:11:58,720 --> 00:12:05,680
there's no hard context and so today you

00:12:02,240 --> 00:12:08,000
know when we're we get some type of

00:12:05,680 --> 00:12:10,879
problem say for example in an Akha

00:12:08,000 --> 00:12:12,589
system we get a dump like this and it's

00:12:10,879 --> 00:12:14,209
like okay what does that mean it doesn't

00:12:12,589 --> 00:12:17,569
mean anything to me how do I find my

00:12:14,209 --> 00:12:19,519
problem where is the error and so forth

00:12:17,569 --> 00:12:22,009
and and when you're dealing with a

00:12:19,519 --> 00:12:24,139
customs you can have systems that have

00:12:22,009 --> 00:12:26,569
millions of actors in them and this

00:12:24,139 --> 00:12:29,180
becomes a very difficult challenge it's

00:12:26,569 --> 00:12:31,279
kind of like distilling the noise out of

00:12:29,180 --> 00:12:34,639
the picture to find what's really

00:12:31,279 --> 00:12:37,370
important and I like this little cartoon

00:12:34,639 --> 00:12:40,699
here basically it kind of gives you an

00:12:37,370 --> 00:12:42,350
example in an asynchronous environment

00:12:40,699 --> 00:12:44,899
what can happen he says sometimes I'm

00:12:42,350 --> 00:12:48,079
shocked to realize how many options I

00:12:44,899 --> 00:12:50,029
have and the guy says oh like at any

00:12:48,079 --> 00:12:52,189
moment in any conversation I could just

00:12:50,029 --> 00:12:53,839
punch the person I was talking to and

00:12:52,189 --> 00:12:58,160
all these potentially life-changing

00:12:53,839 --> 00:13:00,259
events would unfold it's only a mental

00:12:58,160 --> 00:13:02,329
rules that stop me from punching you or

00:13:00,259 --> 00:13:05,209
stripping naked or getting on a plane to

00:13:02,329 --> 00:13:06,980
Fiji sure rules have reasons but

00:13:05,209 --> 00:13:08,420
shouldn't the shouldn't you exercise

00:13:06,980 --> 00:13:12,379
that freedom at least once before you

00:13:08,420 --> 00:13:13,939
die Wham I should have saw that comin

00:13:12,379 --> 00:13:15,559
that that's the great thing about it but

00:13:13,939 --> 00:13:17,709
you couldn't that's the beauty right you

00:13:15,559 --> 00:13:19,939
don't see it coming and all of a sudden

00:13:17,709 --> 00:13:24,060
we were talking about yesterday when it

00:13:19,939 --> 00:13:26,850
fails it feels hard so what to do how do

00:13:24,060 --> 00:13:29,040
you deal with this situation again just

00:13:26,850 --> 00:13:30,660
like thinking about building systems and

00:13:29,040 --> 00:13:33,450
going asynchronous you got the start to

00:13:30,660 --> 00:13:35,100
think differently there's there's so

00:13:33,450 --> 00:13:38,580
many challenges that you have to

00:13:35,100 --> 00:13:41,250
overcome that one of the key ones here

00:13:38,580 --> 00:13:42,780
is is in an asynchronous distributed

00:13:41,250 --> 00:13:44,960
system you have this whole notion of

00:13:42,780 --> 00:13:47,460
non-determinism you can't reason about

00:13:44,960 --> 00:13:50,100
when something happened what was the

00:13:47,460 --> 00:13:52,290
sequence of events that occurred to get

00:13:50,100 --> 00:13:54,090
me there you have to be able to take a

00:13:52,290 --> 00:13:55,860
look at them independently and kind of

00:13:54,090 --> 00:14:01,350
piece a puzzle together that makes sense

00:13:55,860 --> 00:14:03,810
and that becomes very difficult so one

00:14:01,350 --> 00:14:05,640
of the ways that you can do this is

00:14:03,810 --> 00:14:09,570
through the notion of tracing you can

00:14:05,640 --> 00:14:13,110
set up essentially i'm going to begin to

00:14:09,570 --> 00:14:14,910
observe at this point in time and i'm

00:14:13,110 --> 00:14:17,460
going to tag it or I'm going to mark it

00:14:14,910 --> 00:14:20,520
and I'm going to follow kind of like a

00:14:17,460 --> 00:14:22,620
tracker I'm going to follow where this

00:14:20,520 --> 00:14:26,370
message goes or where this particular

00:14:22,620 --> 00:14:29,820
thing is that I'm observing and how it

00:14:26,370 --> 00:14:32,460
behaves over time in the system and you

00:14:29,820 --> 00:14:34,610
may get back information out of order

00:14:32,460 --> 00:14:38,340
you make it back information potentially

00:14:34,610 --> 00:14:39,570
and not necessarily asynchronous fashion

00:14:38,340 --> 00:14:41,370
so therefore you want to be able to

00:14:39,570 --> 00:14:42,870
piece that together so tracing

00:14:41,370 --> 00:14:45,030
especially across these synchronous

00:14:42,870 --> 00:14:47,250
boundaries is one of the ways that you

00:14:45,030 --> 00:14:50,670
can do it so you have multiple actors

00:14:47,250 --> 00:14:53,250
for example when akka you set up a hot

00:14:50,670 --> 00:14:54,660
path where you set up a flow that you

00:14:53,250 --> 00:14:57,150
think is going to make sense so that

00:14:54,660 --> 00:14:59,760
begs another question is who determines

00:14:57,150 --> 00:15:01,440
what the hot taz are in my system right

00:14:59,760 --> 00:15:05,190
so monitoring kind of crosses this

00:15:01,440 --> 00:15:07,860
boundary of business rules you know

00:15:05,190 --> 00:15:10,800
there's so many things going on I can't

00:15:07,860 --> 00:15:12,510
watch everything but I do have to watch

00:15:10,800 --> 00:15:14,220
what's important right you have to make

00:15:12,510 --> 00:15:15,990
a decision in life what are the

00:15:14,220 --> 00:15:18,390
important things I have to focus on its

00:15:15,990 --> 00:15:20,550
it's what we do every day and so

00:15:18,390 --> 00:15:22,590
monitoring is no different one of the

00:15:20,550 --> 00:15:24,150
ways that we achieve that is by giving

00:15:22,590 --> 00:15:27,090
you the ability to set up these things

00:15:24,150 --> 00:15:28,050
called trace pans that can go across and

00:15:27,090 --> 00:15:29,610
then you can kind of get a visual

00:15:28,050 --> 00:15:33,390
picture of what's going on in your

00:15:29,610 --> 00:15:36,690
system in our case here in our current

00:15:33,390 --> 00:15:37,920
solution its programmatic and what you

00:15:36,690 --> 00:15:40,920
can see here is you're going to

00:15:37,920 --> 00:15:44,370
start a trace within an actor based on

00:15:40,920 --> 00:15:45,990
some message and then it's inside or the

00:15:44,370 --> 00:15:48,029
internals we're going to set up a

00:15:45,990 --> 00:15:52,950
context for you and we're going to start

00:15:48,029 --> 00:15:55,050
to track and then somewhere at the end

00:15:52,950 --> 00:15:57,149
somewhere later in your application

00:15:55,050 --> 00:15:58,800
you're going to have a closure to it

00:15:57,149 --> 00:16:01,170
it's going to be the end of the trace

00:15:58,800 --> 00:16:03,060
and we're going to capture histogram

00:16:01,170 --> 00:16:05,370
information for you that would then

00:16:03,060 --> 00:16:08,010
allow you to reason about that trace

00:16:05,370 --> 00:16:12,360
right metric data so that's one way that

00:16:08,010 --> 00:16:14,550
you can you can solve the problem but

00:16:12,360 --> 00:16:18,930
wouldn't it be nice if you could tag all

00:16:14,550 --> 00:16:21,529
along the way and for you know an

00:16:18,930 --> 00:16:23,930
exception this was the kind of

00:16:21,529 --> 00:16:26,190
information that you would get in akka

00:16:23,930 --> 00:16:28,139
right so one of the things that we're

00:16:26,190 --> 00:16:30,089
taking a look at is is this kind of

00:16:28,139 --> 00:16:38,639
notion to kind of give you a pretty

00:16:30,089 --> 00:16:41,399
output of your trace okay so six years

00:16:38,639 --> 00:16:44,220
ago Google released this paper called a

00:16:41,399 --> 00:16:46,380
dapper paper it's basically a lessons

00:16:44,220 --> 00:16:48,060
learned from monitoring distributed

00:16:46,380 --> 00:16:51,000
systems Google have a couple of service

00:16:48,060 --> 00:16:53,490
out there so this was the best practice

00:16:51,000 --> 00:16:57,720
from from how to monitor distributed

00:16:53,490 --> 00:17:01,140
systems basically and typesafe when we

00:16:57,720 --> 00:17:03,240
started 2011 we had an implementation

00:17:01,140 --> 00:17:05,730
called types of console which basically

00:17:03,240 --> 00:17:08,610
is an implementation of the dapper paper

00:17:05,730 --> 00:17:10,500
so the dapper paper basically prescribes

00:17:08,610 --> 00:17:12,809
that you have your monitored

00:17:10,500 --> 00:17:16,049
applications and you instrument them and

00:17:12,809 --> 00:17:17,819
based based on this instrumentation you

00:17:16,049 --> 00:17:20,400
create events and those events are

00:17:17,819 --> 00:17:23,429
stored offline into some database so you

00:17:20,400 --> 00:17:25,439
can have X number of systems that that's

00:17:23,429 --> 00:17:26,910
instrumented and they all generate

00:17:25,439 --> 00:17:29,870
events and you store them into the

00:17:26,910 --> 00:17:32,309
database and then offline you have

00:17:29,870 --> 00:17:34,620
analyzers looking at these individual

00:17:32,309 --> 00:17:36,540
events and trying to make sense so based

00:17:34,620 --> 00:17:38,610
on the individual events you can create

00:17:36,540 --> 00:17:42,600
metrics and you you can get an

00:17:38,610 --> 00:17:44,400
understanding of how systems are calling

00:17:42,600 --> 00:17:47,460
each other even if it's a synchronous

00:17:44,400 --> 00:17:49,409
and you generate you store that

00:17:47,460 --> 00:17:51,779
information back into the database and

00:17:49,409 --> 00:17:53,460
finally have a query or

00:17:51,779 --> 00:17:56,820
side where he can retrieve this

00:17:53,460 --> 00:17:59,099
information and present it to the users

00:17:56,820 --> 00:18:01,739
so we had this implementation and types

00:17:59,099 --> 00:18:05,099
of console we decided not to continue

00:18:01,739 --> 00:18:07,499
with that with that product because we

00:18:05,099 --> 00:18:10,229
ended up generating a lot of events and

00:18:07,499 --> 00:18:13,739
some some customers came back and said

00:18:10,229 --> 00:18:16,529
you know it takes me a minute to to get

00:18:13,739 --> 00:18:18,690
the notification and that's because you

00:18:16,529 --> 00:18:21,149
know if you generate X number of events

00:18:18,690 --> 00:18:23,549
the analyzers are going to lag behind

00:18:21,149 --> 00:18:25,859
and before they've done their

00:18:23,549 --> 00:18:30,239
calculation and stored it back into the

00:18:25,859 --> 00:18:32,159
database it might be too late so here if

00:18:30,239 --> 00:18:33,989
looking at the dapper paper again and

00:18:32,159 --> 00:18:36,299
looking at a knack application where you

00:18:33,989 --> 00:18:39,119
have three actors you can see that actor

00:18:36,299 --> 00:18:41,519
a receives a message one and each of

00:18:39,119 --> 00:18:44,129
these orange boxes are individual events

00:18:41,519 --> 00:18:45,779
created so what we did in types of

00:18:44,129 --> 00:18:47,999
console is we said okay I have now

00:18:45,779 --> 00:18:51,210
received message one and we created an

00:18:47,999 --> 00:18:55,019
event the store that offline and then we

00:18:51,210 --> 00:18:57,059
also said I have sent a message to to

00:18:55,019 --> 00:18:59,629
actor be that's the told message to

00:18:57,059 --> 00:19:03,119
message there and finally when it's done

00:18:59,629 --> 00:19:05,279
it says I now completed message one so

00:19:03,119 --> 00:19:07,289
those three events are generated same

00:19:05,279 --> 00:19:09,839
thing for actor be same thing for

00:19:07,289 --> 00:19:12,989
accuracy and then actor see replies back

00:19:09,839 --> 00:19:15,450
to actor a and it says you know received

00:19:12,989 --> 00:19:17,700
and complete the message for all these

00:19:15,450 --> 00:19:19,919
things can of course happen they will

00:19:17,700 --> 00:19:21,719
happen a synchronous e innaka but it

00:19:19,919 --> 00:19:23,099
could also be remote over remote

00:19:21,719 --> 00:19:26,070
boundaries so it could be different

00:19:23,099 --> 00:19:27,599
servers generating these events but

00:19:26,070 --> 00:19:29,609
they're all going to be stored into the

00:19:27,599 --> 00:19:32,429
database so the analyzers when they look

00:19:29,609 --> 00:19:37,979
at this they can make sense of the data

00:19:32,429 --> 00:19:40,499
right so looking at a piece of this or a

00:19:37,979 --> 00:19:42,960
one of these trace events what it can

00:19:40,499 --> 00:19:48,389
look like this is Jason so it's not a

00:19:42,960 --> 00:19:51,029
bit you know large data format but each

00:19:48,389 --> 00:19:53,669
of these each of these events will have

00:19:51,029 --> 00:19:56,039
a unique ID so that's the ID there they

00:19:53,669 --> 00:19:58,080
will also have a trace ID so the trace

00:19:56,039 --> 00:20:00,450
ID and the example before it would be

00:19:58,080 --> 00:20:03,269
the whole trace from actor a b c and

00:20:00,450 --> 00:20:06,230
back to a that's a trace event so they

00:20:03,269 --> 00:20:08,880
all belong to the same trace contact

00:20:06,230 --> 00:20:11,580
they're also pointing back to the

00:20:08,880 --> 00:20:13,290
parents and this is very important in a

00:20:11,580 --> 00:20:15,360
distributed system that you're always

00:20:13,290 --> 00:20:18,780
pointing back to what happened before

00:20:15,360 --> 00:20:20,940
because the notion of time no longer is

00:20:18,780 --> 00:20:22,950
working unless your google and you're

00:20:20,940 --> 00:20:25,860
using a synchronous clocked atomic is

00:20:22,950 --> 00:20:27,900
atomic clocks where the clock will be

00:20:25,860 --> 00:20:30,630
the same in the whole distributed system

00:20:27,900 --> 00:20:32,250
then you can use time but for most of us

00:20:30,630 --> 00:20:34,320
out there we can afford that kind of

00:20:32,250 --> 00:20:36,960
infrastructure so instead we're going to

00:20:34,320 --> 00:20:39,540
use call kaushal colossal consistency

00:20:36,960 --> 00:20:41,630
which basically means that this is the

00:20:39,540 --> 00:20:45,120
event that happened before me so even if

00:20:41,630 --> 00:20:47,130
you know if actor B's events are stored

00:20:45,120 --> 00:20:48,870
in the database before after a because

00:20:47,130 --> 00:20:50,550
that can absolutely happen if there's a

00:20:48,870 --> 00:20:54,000
garbage collection on the system where

00:20:50,550 --> 00:20:55,980
actor a exists eventually we can make

00:20:54,000 --> 00:20:57,750
sense of this because we can piece these

00:20:55,980 --> 00:21:00,030
together right I know what's going to

00:20:57,750 --> 00:21:01,350
happen before me I couldn't find that

00:21:00,030 --> 00:21:03,390
event right now so I'm going to wait a

00:21:01,350 --> 00:21:05,940
little and then when that event arrives

00:21:03,390 --> 00:21:08,970
I can now complete the whole trace and

00:21:05,940 --> 00:21:11,160
create metrics from that we also added a

00:21:08,970 --> 00:21:14,070
lot of other things like nano time and

00:21:11,160 --> 00:21:15,360
that's on this specific server if you if

00:21:14,070 --> 00:21:17,130
you're into it I mean if you want to

00:21:15,360 --> 00:21:20,400
make sense of timing you can do that so

00:21:17,130 --> 00:21:22,590
within the boundary of one server and we

00:21:20,400 --> 00:21:25,800
had type annotations that said this is a

00:21:22,590 --> 00:21:28,080
receive receive a message and what actor

00:21:25,800 --> 00:21:31,800
in and what message and the message

00:21:28,080 --> 00:21:34,080
content and stuff like that so it would

00:21:31,800 --> 00:21:36,150
like been monitoring we're having a

00:21:34,080 --> 00:21:37,620
slightly different approach and this is

00:21:36,150 --> 00:21:39,810
instead of generating all of these

00:21:37,620 --> 00:21:42,420
events and sending them offline we're

00:21:39,810 --> 00:21:45,090
trying to capture metrics inside of the

00:21:42,420 --> 00:21:46,860
application so internally we still have

00:21:45,090 --> 00:21:49,080
these events but it's going to be inside

00:21:46,860 --> 00:21:50,910
of the jb m and then we have our

00:21:49,080 --> 00:21:53,100
monitoring application listening to all

00:21:50,910 --> 00:21:55,500
of these events and generating the

00:21:53,100 --> 00:21:57,780
metrics locally and then we're sending

00:21:55,500 --> 00:22:02,340
these events or this metric information

00:21:57,780 --> 00:22:04,920
rather to some other system so we we are

00:22:02,340 --> 00:22:07,860
internal years in kota hail for example

00:22:04,920 --> 00:22:09,480
in two key metrics and we can offload

00:22:07,860 --> 00:22:11,100
the information to to keep it what we

00:22:09,480 --> 00:22:12,810
call a Hail we can also we have a lot of

00:22:11,100 --> 00:22:16,260
reporters so you can offload that to

00:22:12,810 --> 00:22:18,530
elasticsearch or or jmx or slf4j and

00:22:16,260 --> 00:22:18,530
what have you

00:22:19,260 --> 00:22:25,350
now monitoring applications a lot of a

00:22:23,670 --> 00:22:27,210
lot of times we get a question you know

00:22:25,350 --> 00:22:29,220
how much does this cost monitoring to

00:22:27,210 --> 00:22:30,930
this application you know what's the

00:22:29,220 --> 00:22:34,620
overhead and that's a very different

00:22:30,930 --> 00:22:36,210
question to answer because each of these

00:22:34,620 --> 00:22:39,030
different systems that you're creating

00:22:36,210 --> 00:22:42,150
acabe systems they have their own

00:22:39,030 --> 00:22:44,610
individual characteristic you know which

00:22:42,150 --> 00:22:46,830
application is more costly to monitor an

00:22:44,610 --> 00:22:49,500
application which few actors with lots

00:22:46,830 --> 00:22:52,020
of business logic or an application with

00:22:49,500 --> 00:22:53,970
several temporary short-lived actors now

00:22:52,020 --> 00:22:55,830
the answer of course is the the last one

00:22:53,970 --> 00:22:58,530
right because if you think again about

00:22:55,830 --> 00:22:59,850
these events being generated if you have

00:22:58,530 --> 00:23:01,650
if you're creating millions and millions

00:22:59,850 --> 00:23:03,600
of actors we are going to track those

00:23:01,650 --> 00:23:05,490
actors for you and everything that's

00:23:03,600 --> 00:23:09,540
going on it's going to generate an event

00:23:05,490 --> 00:23:12,540
so there will be much more things going

00:23:09,540 --> 00:23:14,040
on from a monitoring perspective in that

00:23:12,540 --> 00:23:15,960
type of application then if you're

00:23:14,040 --> 00:23:18,540
having just a couple of actors and the

00:23:15,960 --> 00:23:21,990
business logic is taking a long time to

00:23:18,540 --> 00:23:24,420
run so there's a cost associated with

00:23:21,990 --> 00:23:26,880
each event in the application and it's

00:23:24,420 --> 00:23:29,970
very hard to to predict the performance

00:23:26,880 --> 00:23:32,280
overhead there are a couple of ways that

00:23:29,970 --> 00:23:34,560
you can mitigate this cost that its

00:23:32,280 --> 00:23:36,690
associated with monitoring so one of the

00:23:34,560 --> 00:23:38,610
things is flexible configuration where

00:23:36,690 --> 00:23:40,260
you can decide what parts of your system

00:23:38,610 --> 00:23:42,660
you want to monitor so let's say you

00:23:40,260 --> 00:23:44,450
have an actor system again where some of

00:23:42,660 --> 00:23:47,220
the parts are generating a lot of trans

00:23:44,450 --> 00:23:49,140
short-lived temporary actors then you

00:23:47,220 --> 00:23:51,390
can decide not by configuration you can

00:23:49,140 --> 00:23:53,220
decide not to monitor that part you just

00:23:51,390 --> 00:23:55,800
want to monitor the other side parts of

00:23:53,220 --> 00:23:57,870
your system so that's one way of trying

00:23:55,800 --> 00:24:01,110
to mitigate the cost that's associated

00:23:57,870 --> 00:24:02,580
you can also use sampling so sampling is

00:24:01,110 --> 00:24:05,400
that you only want to trace every

00:24:02,580 --> 00:24:07,980
hundred or a thousand message to a

00:24:05,400 --> 00:24:10,350
certain actor of course that's going to

00:24:07,980 --> 00:24:12,840
generate a lot of less events and

00:24:10,350 --> 00:24:15,390
therefore it's it's cheaper to monitor

00:24:12,840 --> 00:24:17,340
that system and there's also a delta

00:24:15,390 --> 00:24:19,740
approach where you can basically say

00:24:17,340 --> 00:24:21,180
that you know if nothing happens inside

00:24:19,740 --> 00:24:25,050
of my actor I'm not going to create any

00:24:21,180 --> 00:24:27,090
in events for that you and and on the

00:24:25,050 --> 00:24:29,430
receiving end it will understand that

00:24:27,090 --> 00:24:31,170
whatever happened before is now it's

00:24:29,430 --> 00:24:33,090
still valid because I didn't receive any

00:24:31,170 --> 00:24:35,760
event so i can create

00:24:33,090 --> 00:24:39,650
I can draw my own conclusions based on

00:24:35,760 --> 00:24:43,170
that now eat either of these approaches

00:24:39,650 --> 00:24:45,420
will also mean that you get less insight

00:24:43,170 --> 00:24:47,430
into your application or you increase

00:24:45,420 --> 00:24:49,830
the complexity of your monitoring system

00:24:47,430 --> 00:24:51,150
so there's no such thing as free lunch

00:24:49,830 --> 00:24:54,930
when it's come when it comes to

00:24:51,150 --> 00:24:58,460
monitoring ok so let's switch and talk a

00:24:54,930 --> 00:25:03,840
little bit about trends and monitoring

00:24:58,460 --> 00:25:06,450
and specifically pull and push so there

00:25:03,840 --> 00:25:09,060
are different trends going on and one is

00:25:06,450 --> 00:25:11,820
pull based systems where you actually

00:25:09,060 --> 00:25:14,250
have your monitoring system pulling data

00:25:11,820 --> 00:25:16,590
from the monitored applications you know

00:25:14,250 --> 00:25:19,200
by querying some side is some sort of

00:25:16,590 --> 00:25:20,940
API and can can get this type of

00:25:19,200 --> 00:25:23,010
information back the other one of course

00:25:20,940 --> 00:25:24,990
being pushed where the monitored

00:25:23,010 --> 00:25:27,390
application pushed data to some endpoint

00:25:24,990 --> 00:25:30,900
and it doesn't really care what's going

00:25:27,390 --> 00:25:33,750
on there now there are different ways of

00:25:30,900 --> 00:25:36,150
discover what to monitor depending on

00:25:33,750 --> 00:25:38,370
your infrastructure one is where the

00:25:36,150 --> 00:25:40,830
monitor applications register somewhere

00:25:38,370 --> 00:25:44,520
in some sort of you know this case it

00:25:40,830 --> 00:25:46,620
could be Sookie proconsul and or you

00:25:44,520 --> 00:25:48,720
have a cluster scheduler that actually

00:25:46,620 --> 00:25:50,700
spawns these monitored applications and

00:25:48,720 --> 00:25:53,550
you know where the montreux applications

00:25:50,700 --> 00:25:55,290
exist so either of those the monetary

00:25:53,550 --> 00:25:58,140
system can then query zookeeper and say

00:25:55,290 --> 00:26:00,060
you know what system should I monitor or

00:25:58,140 --> 00:26:03,780
the cluster scheduler to still receive

00:26:00,060 --> 00:26:06,480
the same information ok let's put these

00:26:03,780 --> 00:26:09,750
two together now pull and push so if you

00:26:06,480 --> 00:26:12,600
have a pool based system the monitoring

00:26:09,750 --> 00:26:14,490
system can then ask zookeeper council or

00:26:12,600 --> 00:26:16,410
the cluster scheduler you know give me

00:26:14,490 --> 00:26:18,900
the systems that I that you want me to

00:26:16,410 --> 00:26:20,550
monitor and then it will call these

00:26:18,900 --> 00:26:23,820
systems and try to retrieve information

00:26:20,550 --> 00:26:27,450
and the middle system here is actually

00:26:23,820 --> 00:26:29,370
down and in the pool based system you

00:26:27,450 --> 00:26:30,990
now know that something is wrong and can

00:26:29,370 --> 00:26:32,790
alert and how can you know if

00:26:30,990 --> 00:26:35,880
something's wrong well you already have

00:26:32,790 --> 00:26:37,950
the information about what systems to

00:26:35,880 --> 00:26:40,550
monitor so even if DevOps you know a

00:26:37,950 --> 00:26:43,950
DevOps guy decides to restart the system

00:26:40,550 --> 00:26:46,320
by yep by subscribing to the information

00:26:43,950 --> 00:26:46,870
from your cluster scalar or service

00:26:46,320 --> 00:26:50,380
discover

00:26:46,870 --> 00:26:52,809
to you know that you know okay I don't

00:26:50,380 --> 00:26:54,190
this is fine because the DevOps guy we

00:26:52,809 --> 00:26:57,100
started this so that's perfectly fine

00:26:54,190 --> 00:26:58,240
it's part of the normal operations but

00:26:57,100 --> 00:27:00,010
if you don't receive that information

00:26:58,240 --> 00:27:02,890
you also know that there's something

00:27:00,010 --> 00:27:04,780
fishy going on right so full bae systems

00:27:02,890 --> 00:27:06,610
are quite effective in that sense now

00:27:04,780 --> 00:27:09,760
for the push base you can still achieve

00:27:06,610 --> 00:27:12,070
the same thing but you need to add some

00:27:09,760 --> 00:27:14,260
sort of scheduler to the monitoring

00:27:12,070 --> 00:27:18,220
system because the push pace you really

00:27:14,260 --> 00:27:20,410
don't know when to receive data so the

00:27:18,220 --> 00:27:21,880
you know the the mantra application

00:27:20,410 --> 00:27:23,710
would just push push push and you

00:27:21,880 --> 00:27:25,690
receive data and all of a sudden you

00:27:23,710 --> 00:27:27,280
don't receive something anything from

00:27:25,690 --> 00:27:29,830
this one you need to have a scheduler

00:27:27,280 --> 00:27:31,570
internally that's that queries yourself

00:27:29,830 --> 00:27:33,460
and say have I received anything from

00:27:31,570 --> 00:27:35,530
these systems that I'm expecting data

00:27:33,460 --> 00:27:37,840
from and based on that information you

00:27:35,530 --> 00:27:41,860
can now start to generate alerts if you

00:27:37,840 --> 00:27:44,110
want to so what are the difference is

00:27:41,860 --> 00:27:46,390
well data volumes in detail in the pool

00:27:44,110 --> 00:27:48,760
based systems you can basically say you

00:27:46,390 --> 00:27:50,350
know I just want to know the top five

00:27:48,760 --> 00:27:54,250
things that's going on inside of the

00:27:50,350 --> 00:27:56,440
application by clearing some API and you

00:27:54,250 --> 00:27:58,000
get that type of information and then

00:27:56,440 --> 00:28:00,250
all of a sudden there's something wrong

00:27:58,000 --> 00:28:02,020
and then you can dive into detail and

00:28:00,250 --> 00:28:03,550
say okay give me more information I want

00:28:02,020 --> 00:28:06,100
to know exactly what's happening right

00:28:03,550 --> 00:28:08,080
now you can basically decide how much

00:28:06,100 --> 00:28:10,450
data you want to retrieve in a push

00:28:08,080 --> 00:28:12,820
based system you can because to push you

00:28:10,450 --> 00:28:14,890
basically well you can but normally you

00:28:12,820 --> 00:28:17,440
define what data it should push and it

00:28:14,890 --> 00:28:19,540
just pushes that information right you

00:28:17,440 --> 00:28:22,150
can still if you have dynamic

00:28:19,540 --> 00:28:25,059
configuration you can instruct the push

00:28:22,150 --> 00:28:27,190
bae systems what to you know to update

00:28:25,059 --> 00:28:28,900
what they should push but it's a little

00:28:27,190 --> 00:28:32,590
bit more tricky in the pool base is more

00:28:28,900 --> 00:28:35,559
natural examples of pool based systems

00:28:32,590 --> 00:28:37,630
is prometheus that's developed by

00:28:35,559 --> 00:28:40,150
soundcloud and say here in berlin and

00:28:37,630 --> 00:28:44,860
the push based system is that state as

00:28:40,150 --> 00:28:46,950
use in a lot of places another trend is

00:28:44,860 --> 00:28:49,630
going on is anomaly detection and

00:28:46,950 --> 00:28:51,220
anomaly detection basically it's its

00:28:49,630 --> 00:28:53,920
associated with machine learning of

00:28:51,220 --> 00:28:56,410
course you're looking at data you're

00:28:53,920 --> 00:28:59,230
having machines or algorithm statistics

00:28:56,410 --> 00:29:00,380
you're using that to determine if

00:28:59,230 --> 00:29:01,850
something is

00:29:00,380 --> 00:29:04,760
it's happening a system that it

00:29:01,850 --> 00:29:08,030
shouldn't happen normally when you you

00:29:04,760 --> 00:29:10,940
know when you want to fire alerts you

00:29:08,030 --> 00:29:13,160
have static thresholds so you say ok if

00:29:10,940 --> 00:29:15,020
this call takes longer than one second

00:29:13,160 --> 00:29:17,330
you add that's a configuration file and

00:29:15,020 --> 00:29:19,130
if it takes longer than one second there

00:29:17,330 --> 00:29:22,240
will be an event fired saying you know I

00:29:19,130 --> 00:29:24,950
this took longer than one second and

00:29:22,240 --> 00:29:27,350
that's very very crude way of doing

00:29:24,950 --> 00:29:28,520
things especially because you normally

00:29:27,350 --> 00:29:30,980
don't know what hardware you're

00:29:28,520 --> 00:29:33,350
deploying on right so if you're

00:29:30,980 --> 00:29:35,180
deploying on a small server in Amazon

00:29:33,350 --> 00:29:38,240
and all of a sudden you move it to one

00:29:35,180 --> 00:29:41,000
of the large servers then the this the

00:29:38,240 --> 00:29:44,690
threshold is no longer valid because the

00:29:41,000 --> 00:29:46,280
you know the large server is capable it

00:29:44,690 --> 00:29:49,820
shouldn't take that long for a larger

00:29:46,280 --> 00:29:52,120
and for small I could so by having

00:29:49,820 --> 00:29:55,670
anomaly detection you can basically

00:29:52,120 --> 00:29:57,590
calibrate the threshold automatically it

00:29:55,670 --> 00:30:00,440
also gives you things like better

00:29:57,590 --> 00:30:02,540
overview of what's going on if you think

00:30:00,440 --> 00:30:04,760
of it you know you can only have so many

00:30:02,540 --> 00:30:06,800
dashboards and look at them and trying

00:30:04,760 --> 00:30:08,690
to figure out what's going on you don't

00:30:06,800 --> 00:30:10,280
want to have human sitting a lot of in

00:30:08,690 --> 00:30:12,350
front of a lot of graphs trying to

00:30:10,280 --> 00:30:13,610
figure out and it's actually very hard

00:30:12,350 --> 00:30:18,230
to figure out what's going on because

00:30:13,610 --> 00:30:21,950
outliers aren't equal to anomalies so

00:30:18,230 --> 00:30:24,710
there's this example and an anomaly

00:30:21,950 --> 00:30:26,540
detection literature where where the

00:30:24,710 --> 00:30:28,280
looking at number of patients going into

00:30:26,540 --> 00:30:30,800
a hospital I believe it's in the UK

00:30:28,280 --> 00:30:32,750
somewhere and I'm just looking at this

00:30:30,800 --> 00:30:35,450
is a couple of weeks and you look monday

00:30:32,750 --> 00:30:36,710
tuesday and so on and then all of a

00:30:35,450 --> 00:30:39,500
sudden there's a huge spike on a

00:30:36,710 --> 00:30:40,910
thursday and then it continues and

00:30:39,500 --> 00:30:42,440
normally you know as human beings we

00:30:40,910 --> 00:30:44,660
just look at the spike and saying that's

00:30:42,440 --> 00:30:48,080
the anomaly and that's not the case

00:30:44,660 --> 00:30:49,640
because it's normal for people to to

00:30:48,080 --> 00:30:51,800
come to hospital on a thursday on a

00:30:49,640 --> 00:30:53,690
friday however right at a week after

00:30:51,800 --> 00:30:55,100
it's like a little peek going on but

00:30:53,690 --> 00:30:57,140
it's nothing to the Thursday the week

00:30:55,100 --> 00:30:59,180
before but the anomaly is actually the

00:30:57,140 --> 00:31:01,190
Friday and just looking at the graphs is

00:30:59,180 --> 00:31:03,260
very hard to tell what we're doing on

00:31:01,190 --> 00:31:05,360
anomalies are an anomaly detection can

00:31:03,260 --> 00:31:07,190
give you that for free so a couple of

00:31:05,360 --> 00:31:13,100
providers appdynamics wraps it in the

00:31:07,190 --> 00:31:15,200
big vortex okay Duncan yep so the

00:31:13,100 --> 00:31:17,270
just kind of a checkpoint we kind of

00:31:15,200 --> 00:31:20,330
went through where we got or why we're

00:31:17,270 --> 00:31:21,950
here because of distributed systems some

00:31:20,330 --> 00:31:24,200
of the challenges and some of the trends

00:31:21,950 --> 00:31:25,580
and the anomaly detection that Henrik

00:31:24,200 --> 00:31:27,679
was just talking about is really really

00:31:25,580 --> 00:31:30,470
important you're gonna have two types of

00:31:27,679 --> 00:31:32,990
anomalies one is the one that Henrik

00:31:30,470 --> 00:31:36,080
described which was a legitimate outlier

00:31:32,990 --> 00:31:38,270
but it was not an along an anomaly which

00:31:36,080 --> 00:31:41,660
was the Thursday intake of the hospital

00:31:38,270 --> 00:31:45,380
another one is erroneous data if you're

00:31:41,660 --> 00:31:47,330
doing deltas and some of the data that

00:31:45,380 --> 00:31:49,250
you get back is erroneous you could have

00:31:47,330 --> 00:31:50,870
an outlier that shows a false negative

00:31:49,250 --> 00:31:53,000
or a false positive and you might assume

00:31:50,870 --> 00:31:54,679
that's in an autumn anomaly but it isn't

00:31:53,000 --> 00:31:57,200
so you got to deal with those things

00:31:54,679 --> 00:31:59,960
through smoothing algorithms or

00:31:57,200 --> 00:32:02,090
something like that so the bottom line

00:31:59,960 --> 00:32:03,980
for anomalies is kind of getting to the

00:32:02,090 --> 00:32:08,150
truth let's figure out what the real

00:32:03,980 --> 00:32:11,690
problem was it may not be what we we see

00:32:08,150 --> 00:32:13,789
visually and that requires some real

00:32:11,690 --> 00:32:16,159
thought put into how the system works a

00:32:13,789 --> 00:32:18,230
lot of time it requires training with

00:32:16,159 --> 00:32:23,360
historical data and so forth to

00:32:18,230 --> 00:32:26,179
establish a baseline so on to a

00:32:23,360 --> 00:32:27,679
different topic configuration for us one

00:32:26,179 --> 00:32:30,260
of the things that we do to get around

00:32:27,679 --> 00:32:31,640
the the issue of there's so much going

00:32:30,260 --> 00:32:34,130
on as we give you the ability to

00:32:31,640 --> 00:32:36,080
configure how you want to monitor and we

00:32:34,130 --> 00:32:38,659
have a number of ways you can do a bike

00:32:36,080 --> 00:32:41,270
class and paths and wild card and so

00:32:38,659 --> 00:32:44,690
forth you can do grouping you can do

00:32:41,270 --> 00:32:47,120
includes and excludes and etc so it's a

00:32:44,690 --> 00:32:48,830
pretty robust configuration for a

00:32:47,120 --> 00:32:53,210
monitoring support and this is an

00:32:48,830 --> 00:32:56,270
example we also have kind of like static

00:32:53,210 --> 00:32:59,120
dynamic configuration where based on a

00:32:56,270 --> 00:33:02,870
path you can group actors together on

00:32:59,120 --> 00:33:06,890
the fly to to get out and output so for

00:33:02,870 --> 00:33:08,510
example here we have ? star and you're

00:33:06,890 --> 00:33:11,000
going to get a group name back for that

00:33:08,510 --> 00:33:14,059
scenario but one of the things that

00:33:11,000 --> 00:33:17,780
we're taking a look into is really

00:33:14,059 --> 00:33:20,000
runtime dynamic configuration right the

00:33:17,780 --> 00:33:22,730
types of config is immutable and there's

00:33:20,000 --> 00:33:24,440
a lot of reasons for that but wouldn't

00:33:22,730 --> 00:33:27,049
it be nice if especially from a

00:33:24,440 --> 00:33:29,480
monitoring perspective if while you

00:33:27,049 --> 00:33:31,249
are observing your system and you begin

00:33:29,480 --> 00:33:34,789
to think that there might be a problem

00:33:31,249 --> 00:33:37,039
in this location you want to turn up the

00:33:34,789 --> 00:33:39,619
monitoring a little bit during the

00:33:37,039 --> 00:33:42,860
runtime environment those types of

00:33:39,619 --> 00:33:44,950
scenarios so as you begin to focus in on

00:33:42,860 --> 00:33:47,029
where you think a problem might be

00:33:44,950 --> 00:33:50,119
initially you weren't paying the cost

00:33:47,029 --> 00:33:51,919
for more detailed observation but now

00:33:50,119 --> 00:33:53,570
you recognize a hotspot or whatever

00:33:51,919 --> 00:33:56,739
let's zoom in a little bit and see

00:33:53,570 --> 00:34:00,100
what's going on dynamic configuration

00:33:56,739 --> 00:34:02,480
could provide you the semantics and

00:34:00,100 --> 00:34:04,460
there's already examples of it out there

00:34:02,480 --> 00:34:06,619
there's there's toolkits out there that

00:34:04,460 --> 00:34:08,540
provided but things like typed

00:34:06,619 --> 00:34:10,280
properties etc are some of the things

00:34:08,540 --> 00:34:11,270
that you're going to want in that and

00:34:10,280 --> 00:34:15,889
that's one of the things that we're

00:34:11,270 --> 00:34:20,020
looking at as well the other thing is

00:34:15,889 --> 00:34:23,589
self monitoring so self monitoring is

00:34:20,020 --> 00:34:25,940
the best way to think about it is you

00:34:23,589 --> 00:34:27,440
monitor yourself every day right if you

00:34:25,940 --> 00:34:29,869
start to feel sick you start to get a

00:34:27,440 --> 00:34:32,079
cold you might go take some you know

00:34:29,869 --> 00:34:34,970
natural remedy or you might go to the

00:34:32,079 --> 00:34:37,309
pharmacy and get some cold medicine or

00:34:34,970 --> 00:34:40,040
whatever when that cold starts to get

00:34:37,309 --> 00:34:41,659
worse and you start to feel really sick

00:34:40,040 --> 00:34:43,700
you might think hey do I have the flu

00:34:41,659 --> 00:34:46,190
and at that point most likely you're

00:34:43,700 --> 00:34:47,960
going to give your doctor a call so up

00:34:46,190 --> 00:34:50,450
until the point that you call your

00:34:47,960 --> 00:34:51,889
doctor you have been self-monitoring you

00:34:50,450 --> 00:34:53,960
have been taking your temperature you

00:34:51,889 --> 00:34:56,839
have been kind of just saying how do I

00:34:53,960 --> 00:35:00,099
feel it there is a point at what you say

00:34:56,839 --> 00:35:02,839
okay this is beyond my ability to self

00:35:00,099 --> 00:35:05,030
care and I'm going to go to professional

00:35:02,839 --> 00:35:06,740
so one of the things that we're also

00:35:05,030 --> 00:35:10,849
taking a look at internally is

00:35:06,740 --> 00:35:13,220
self-monitoring where an actor outside

00:35:10,849 --> 00:35:15,079
of the monitoring system or it would be

00:35:13,220 --> 00:35:17,780
our monitoring solution that provides it

00:35:15,079 --> 00:35:19,490
but the actor kind of takes a look at

00:35:17,780 --> 00:35:22,339
itself every now and again and it really

00:35:19,490 --> 00:35:25,400
doesn't complain until it feels the need

00:35:22,339 --> 00:35:27,859
to and then says okay I think I might

00:35:25,400 --> 00:35:30,200
have a problem in the big picture it may

00:35:27,859 --> 00:35:32,089
not be a problem but that actor is kind

00:35:30,200 --> 00:35:38,030
of looking at itself and saying okay I

00:35:32,089 --> 00:35:39,850
want to notify someone else so another

00:35:38,030 --> 00:35:43,540
way to think about this is is

00:35:39,850 --> 00:35:45,970
um your feedback control loops so the

00:35:43,540 --> 00:35:49,000
example here is we have an actor that

00:35:45,970 --> 00:35:53,560
has some type of intelligence baked into

00:35:49,000 --> 00:35:57,160
it and it detects a disturbance okay as

00:35:53,560 --> 00:35:59,740
a result of that disturbance it's going

00:35:57,160 --> 00:36:02,320
to execute a measurement and provide

00:35:59,740 --> 00:36:04,900
that measurement either to itself or to

00:36:02,320 --> 00:36:07,180
an external source who then is going to

00:36:04,900 --> 00:36:10,270
make an adjustment and that's a loop

00:36:07,180 --> 00:36:12,460
that that happens it could be scheduled

00:36:10,270 --> 00:36:16,320
it could be time-based whatever until

00:36:12,460 --> 00:36:19,570
such a time that the disturbance is gone

00:36:16,320 --> 00:36:21,910
right and so it's kind of like

00:36:19,570 --> 00:36:23,770
programming large systems right do it in

00:36:21,910 --> 00:36:26,560
small chunks if you can capture the

00:36:23,770 --> 00:36:29,980
problem when it first starts and begin

00:36:26,560 --> 00:36:32,560
to adjust or compensate for it then you

00:36:29,980 --> 00:36:34,750
might be able to stop or at least

00:36:32,560 --> 00:36:37,540
mitigate the larger way that could

00:36:34,750 --> 00:36:39,850
result from not handling it quickly and

00:36:37,540 --> 00:36:41,650
that's the whole idea behind resilience

00:36:39,850 --> 00:36:44,440
and self-healing and reactive in the

00:36:41,650 --> 00:36:47,320
reactive manifesto and the same idea and

00:36:44,440 --> 00:36:49,270
monitoring this loop the clothes back

00:36:47,320 --> 00:36:51,790
control loop is I don't know 50 years

00:36:49,270 --> 00:36:55,150
old at least you see it in thermometer I

00:36:51,790 --> 00:36:57,550
mean your thermometer thermostat on your

00:36:55,150 --> 00:36:59,530
wall and so forth it's in Hardware it's

00:36:57,550 --> 00:37:02,440
pretty common but bringing that into

00:36:59,530 --> 00:37:05,320
software is one of the things that we're

00:37:02,440 --> 00:37:08,980
taking a deep look at the challenge

00:37:05,320 --> 00:37:11,620
becomes is for a a generalized

00:37:08,980 --> 00:37:14,050
monitoring solution it's very difficult

00:37:11,620 --> 00:37:16,960
to abstract some of these concepts in

00:37:14,050 --> 00:37:18,400
such a way that they apply to all these

00:37:16,960 --> 00:37:21,390
different types of use cases because

00:37:18,400 --> 00:37:24,130
every customer has a different use case

00:37:21,390 --> 00:37:29,740
so some of the challenges some of the

00:37:24,130 --> 00:37:32,020
best practices for monitoring is the

00:37:29,740 --> 00:37:35,500
first and foremost most important thing

00:37:32,020 --> 00:37:38,140
is understand your system okay you would

00:37:35,500 --> 00:37:41,740
be amazed at how many people really

00:37:38,140 --> 00:37:43,180
don't have a good understanding of the

00:37:41,740 --> 00:37:46,300
software that they're actually working

00:37:43,180 --> 00:37:48,430
on and that's crucial because that's

00:37:46,300 --> 00:37:50,230
going to let you know what's important

00:37:48,430 --> 00:37:53,470
and what's not important in your system

00:37:50,230 --> 00:37:55,590
what are the hot pads what are the info

00:37:53,470 --> 00:37:58,780
routes that I want to pay attention to

00:37:55,590 --> 00:38:01,000
so that's that's crucial understand

00:37:58,780 --> 00:38:03,160
whatever tool you're using read the

00:38:01,000 --> 00:38:06,670
manual right understand how it works all

00:38:03,160 --> 00:38:12,160
the details of it all the features of it

00:38:06,670 --> 00:38:13,599
and so forth being configurable right

00:38:12,160 --> 00:38:15,670
your tools you want them to be

00:38:13,599 --> 00:38:17,550
configurable you want them to be elastic

00:38:15,670 --> 00:38:22,900
and that's one of the things that we're

00:38:17,550 --> 00:38:25,480
pushing pretty hard Delta's in the

00:38:22,900 --> 00:38:28,869
energy industry capturing Delta readings

00:38:25,480 --> 00:38:31,480
is commonplace right you don't if you're

00:38:28,869 --> 00:38:33,670
for example reading a meter every two

00:38:31,480 --> 00:38:36,609
seconds or every five seconds and the

00:38:33,670 --> 00:38:39,340
reading has not changed then you do not

00:38:36,609 --> 00:38:41,380
persist that value the only time you

00:38:39,340 --> 00:38:43,960
persist the value and time stamp it is

00:38:41,380 --> 00:38:45,990
when the reading is actually changed so

00:38:43,960 --> 00:38:49,000
that's a huge decrease in the amount of

00:38:45,990 --> 00:38:52,450
data that you have to store so capturing

00:38:49,000 --> 00:38:54,340
Delta's is one way you know that the

00:38:52,450 --> 00:38:55,750
traditional elastic approach where

00:38:54,340 --> 00:38:57,220
you're capturing everything you can

00:38:55,750 --> 00:38:59,650
deplete your resources pretty quickly

00:38:57,220 --> 00:39:01,630
and the only person that can answer the

00:38:59,650 --> 00:39:03,400
questions is do I need all that data or

00:39:01,630 --> 00:39:06,099
the data scientists right we're the

00:39:03,400 --> 00:39:08,020
business so to speak so you have to be

00:39:06,099 --> 00:39:10,450
able to take a look at your your system

00:39:08,020 --> 00:39:13,599
from that point of view sampling is as

00:39:10,450 --> 00:39:16,390
we had mentioned earlier you know

00:39:13,599 --> 00:39:17,980
obviously capturing enough data if you

00:39:16,390 --> 00:39:19,480
scale back too far then you don't have

00:39:17,980 --> 00:39:24,609
enough data to reason about what the

00:39:19,480 --> 00:39:27,790
problem is okay multiple channels for

00:39:24,609 --> 00:39:29,349
notification right what's the purpose of

00:39:27,790 --> 00:39:31,359
this at the end of the day you want to

00:39:29,349 --> 00:39:33,400
let people know that what is the health

00:39:31,359 --> 00:39:35,770
of the system or is there a potential

00:39:33,400 --> 00:39:38,200
problem brewing so being able to notify

00:39:35,770 --> 00:39:41,320
the right people is very very important

00:39:38,200 --> 00:39:43,300
and reports graphs all kinds of pretty

00:39:41,320 --> 00:39:45,910
things for DevOps and the different

00:39:43,300 --> 00:39:48,670
people that are responsible for keeping

00:39:45,910 --> 00:39:52,570
the system up and running more important

00:39:48,670 --> 00:39:56,109
to so and you don't want your monitoring

00:39:52,570 --> 00:39:57,700
system finally impeding your application

00:39:56,109 --> 00:40:00,940
so running your monitoring tool on a

00:39:57,700 --> 00:40:05,380
different machine and so forth is a

00:40:00,940 --> 00:40:07,060
pretty important thing as well okay

00:40:05,380 --> 00:40:07,430
let's talk a little bit about life and

00:40:07,060 --> 00:40:08,930
month

00:40:07,430 --> 00:40:10,760
and what we've been doing the project

00:40:08,930 --> 00:40:13,970
started a little more than a year ago

00:40:10,760 --> 00:40:17,329
and currently we integrate with actors

00:40:13,970 --> 00:40:19,700
and log on our new Micra service

00:40:17,329 --> 00:40:20,690
framework it's circuit breakers so weird

00:40:19,700 --> 00:40:23,750
you based on that we're generating

00:40:20,690 --> 00:40:26,300
metrics events and traces we have

00:40:23,750 --> 00:40:28,579
support for various backends as I said

00:40:26,300 --> 00:40:31,400
before the via Dakota hail reported we

00:40:28,579 --> 00:40:33,980
can generate a lot of different outputs

00:40:31,400 --> 00:40:36,050
output channels and we also have to keep

00:40:33,980 --> 00:40:37,640
the integration which is a really cool

00:40:36,050 --> 00:40:40,430
tool if you haven't seen that take a

00:40:37,640 --> 00:40:44,660
look monitoring requires a subscription

00:40:40,430 --> 00:40:46,700
with light Bend okay so that's what we

00:40:44,660 --> 00:40:48,200
had what's what's on the road map then

00:40:46,700 --> 00:40:51,500
well we're going to add information

00:40:48,200 --> 00:40:56,270
about dispatches and thread pulls you

00:40:51,500 --> 00:40:58,940
know being working in for life band and

00:40:56,270 --> 00:41:01,849
being a template life and I I do quite a

00:40:58,940 --> 00:41:04,220
lot of consulting as well and going out

00:41:01,849 --> 00:41:06,290
to customers one of the biggest mistakes

00:41:04,220 --> 00:41:08,089
that newbies do with a way to hack

00:41:06,290 --> 00:41:10,130
applications is that they run all the

00:41:08,089 --> 00:41:12,559
actors in the same dispatcher at the

00:41:10,130 --> 00:41:15,500
thread pool basically what happens is

00:41:12,559 --> 00:41:17,540
you know use the default configuration

00:41:15,500 --> 00:41:19,880
and then all of a sudden they call us

00:41:17,540 --> 00:41:21,260
say my act myakka application is no

00:41:19,880 --> 00:41:23,210
longer working it's not it's not

00:41:21,260 --> 00:41:24,920
responsive didn't you tell us you know

00:41:23,210 --> 00:41:26,480
didn't you promise us that this is a

00:41:24,920 --> 00:41:27,710
synchronous and everything's good it's

00:41:26,480 --> 00:41:30,770
going to solve all the problems out

00:41:27,710 --> 00:41:32,480
there we kind of did that but not if you

00:41:30,770 --> 00:41:33,799
run everything in the same thread pool

00:41:32,480 --> 00:41:36,530
because what happens if you call a

00:41:33,799 --> 00:41:38,809
database you know eventually if the

00:41:36,530 --> 00:41:40,730
database will it's a synchronous call so

00:41:38,809 --> 00:41:42,349
what happens is that you're waiting for

00:41:40,730 --> 00:41:45,319
that call to come back you're basically

00:41:42,349 --> 00:41:47,150
locking one thread right so whenever

00:41:45,319 --> 00:41:48,559
you're communicating with an external

00:41:47,150 --> 00:41:50,690
system you want to make sure that that

00:41:48,559 --> 00:41:52,970
runs running its own thread pull in its

00:41:50,690 --> 00:41:55,520
own dispatcher so that's one of the

00:41:52,970 --> 00:41:57,710
patterns actor patterns or akka patterns

00:41:55,520 --> 00:41:59,839
that's that should be applied for the

00:41:57,710 --> 00:42:01,700
first thing you do and by providing

00:41:59,839 --> 00:42:04,220
information about the dispatchers and

00:42:01,700 --> 00:42:05,690
thread pulls in monitoring you can we

00:42:04,220 --> 00:42:08,420
can easily you know you run your

00:42:05,690 --> 00:42:10,369
monitoring tool and you just look at it

00:42:08,420 --> 00:42:11,420
and it will tell you that you probably

00:42:10,369 --> 00:42:14,410
need to do something with your

00:42:11,420 --> 00:42:16,819
dispatchers make it it makes it obvious

00:42:14,410 --> 00:42:19,369
another thing that we're going to do is

00:42:16,819 --> 00:42:20,800
this what we've Rand flows which

00:42:19,369 --> 00:42:23,710
basically is

00:42:20,800 --> 00:42:25,690
you know futures and streams and you can

00:42:23,710 --> 00:42:28,840
also think of actors as a kind of a

00:42:25,690 --> 00:42:31,630
flow-through system and where you you

00:42:28,840 --> 00:42:34,870
have you know trip your transactions are

00:42:31,630 --> 00:42:37,600
flowing through your system as right now

00:42:34,870 --> 00:42:38,740
we only have actors monitor buoy we're

00:42:37,600 --> 00:42:40,930
going to add this for futures and

00:42:38,740 --> 00:42:43,390
streams as well so you get the same type

00:42:40,930 --> 00:42:45,000
of information for what regardless of

00:42:43,390 --> 00:42:47,170
what you're running under the hood and

00:42:45,000 --> 00:42:51,430
we're also going to add distributed

00:42:47,170 --> 00:42:53,860
tracing the using sip container we're

00:42:51,430 --> 00:43:00,580
going to add increased logon support and

00:42:53,860 --> 00:43:03,060
akka HTTP support okay I think it's time

00:43:00,580 --> 00:43:06,250
to wrap up thank you for listening and

00:43:03,060 --> 00:43:08,200
we like bend has its own booth down

00:43:06,250 --> 00:43:10,000
there and the whole monitoring team

00:43:08,200 --> 00:43:12,340
duncan in myself and BR in a peter we're

00:43:10,000 --> 00:43:14,980
going to be there the next hour so we'd

00:43:12,340 --> 00:43:16,690
be happy to answer any questions you

00:43:14,980 --> 00:43:18,850
might have that that are related to

00:43:16,690 --> 00:43:23,250
monitoring or life and monitoring or

00:43:18,850 --> 00:43:23,250

YouTube URL: https://www.youtube.com/watch?v=oNAqAkRvDdo


