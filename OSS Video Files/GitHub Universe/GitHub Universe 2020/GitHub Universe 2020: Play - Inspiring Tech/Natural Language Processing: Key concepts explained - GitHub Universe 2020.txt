Title: Natural Language Processing: Key concepts explained - GitHub Universe 2020
Publication date: 2020-12-12
Playlist: GitHub Universe 2020: Play - Inspiring Tech
Description: 
	Presented by 
Benedetta Dal Canton, Co-founder & Developer, Ponicode
Hamza Sayah, Data Scientist, Ponicode

In this talk, Ponicode's Cofounder, Benedetta Dal Canton, will share a roundup of the latest concepts in natural language processing that researchers and tech startups love. She will then chat with Ponicode's Innovation Lead, Hamza Sayah, about his work in NLP and beyond. This session is fully dedicated to developers who want to wrap their head around what the fuss is all about.

For more from GitHub Universe 2020, visit https://githubuniverse.com

As always, feel free to leave us a comment below and don't forget to subscribe: http://bit.ly/subgithub

Thanks!

Connect with us.
Facebook: http://fb.com/github
Twitter: http://twitter.com/github
LinkedIn: http://linkedin.com/company/github

About GitHub
GitHub is the best place to share code with friends, co-workers, classmates, and complete strangers. Millions of people use GitHub to build amazing things together. For more info, go to http://github.com
Captions: 
	00:00:02,540 --> 00:00:06,000
[Music]

00:00:09,470 --> 00:00:13,920
[Music]

00:00:12,799 --> 00:00:15,519
hello everyone

00:00:13,920 --> 00:00:17,279
my name is benedetta and i'm a

00:00:15,519 --> 00:00:19,840
co-founder and software developer at

00:00:17,279 --> 00:00:22,160
pony code which is a startup that

00:00:19,840 --> 00:00:24,160
helps developers code better using

00:00:22,160 --> 00:00:26,480
artificial intelligence

00:00:24,160 --> 00:00:27,199
as you can imagine machine learning and

00:00:26,480 --> 00:00:29,519
nlp

00:00:27,199 --> 00:00:30,800
in particular are very important topics

00:00:29,519 --> 00:00:32,160
for us at pony code

00:00:30,800 --> 00:00:34,000
so today i'm here because i'd like to

00:00:32,160 --> 00:00:36,559
explain some of the key concepts

00:00:34,000 --> 00:00:38,559
uh from these topics this is meant to be

00:00:36,559 --> 00:00:40,719
a very much of an introduction

00:00:38,559 --> 00:00:42,399
so it's suitable for people who have

00:00:40,719 --> 00:00:45,840
absolutely no pre-existing knowledge

00:00:42,399 --> 00:00:47,440
of both ml and nlp but if you do know

00:00:45,840 --> 00:00:49,360
lots about these topics um

00:00:47,440 --> 00:00:51,520
it might still be worth staying with us

00:00:49,360 --> 00:00:54,079
um because i can guarantee

00:00:51,520 --> 00:00:54,719
that it will be um a little bit

00:00:54,079 --> 00:00:56,559
different

00:00:54,719 --> 00:00:58,399
from other introductions to ml that you

00:00:56,559 --> 00:01:00,800
might have seen because

00:00:58,399 --> 00:01:02,079
to make it a little bit less dull i've

00:01:00,800 --> 00:01:05,360
decided to present it

00:01:02,079 --> 00:01:07,360
to you in the form of a story so

00:01:05,360 --> 00:01:10,000
let's imagine that we have a big tech

00:01:07,360 --> 00:01:13,040
company where lots of developers work

00:01:10,000 --> 00:01:14,159
and over the course of two months lots

00:01:13,040 --> 00:01:16,880
of developers start

00:01:14,159 --> 00:01:17,520
calling in sick for reasons of stress

00:01:16,880 --> 00:01:20,240
and

00:01:17,520 --> 00:01:22,080
a few of them actually end up leaving

00:01:20,240 --> 00:01:23,680
they receive a lot of resignations

00:01:22,080 --> 00:01:25,840
and the reason that they all give is

00:01:23,680 --> 00:01:29,040
that they're unhappy at their job

00:01:25,840 --> 00:01:30,000
they were all really talented so this is

00:01:29,040 --> 00:01:32,720
terrible news for

00:01:30,000 --> 00:01:33,520
for the company obviously and the hr

00:01:32,720 --> 00:01:36,240
department

00:01:33,520 --> 00:01:37,600
realizes that they absolutely need to do

00:01:36,240 --> 00:01:40,640
something about it they need

00:01:37,600 --> 00:01:42,799
a way to predict if the developers

00:01:40,640 --> 00:01:44,159
are happy or unhappy so that they can

00:01:42,799 --> 00:01:46,399
act before

00:01:44,159 --> 00:01:48,320
they receive a letter of resignation so

00:01:46,399 --> 00:01:49,360
what they do is that they go to the city

00:01:48,320 --> 00:01:52,399
of the company

00:01:49,360 --> 00:01:54,240
and they ask him to help them

00:01:52,399 --> 00:01:55,600
and the city of being a massive machine

00:01:54,240 --> 00:01:57,280
learning fan uh

00:01:55,600 --> 00:01:58,960
he decides that he's going to take this

00:01:57,280 --> 00:02:01,280
opportunity to practice his skills

00:01:58,960 --> 00:02:02,640
a little bit and he decides he's going

00:02:01,280 --> 00:02:05,119
to provide the hr department

00:02:02,640 --> 00:02:06,399
with a model that can predict which

00:02:05,119 --> 00:02:08,319
developers are happy and which

00:02:06,399 --> 00:02:10,239
developers are unhappy

00:02:08,319 --> 00:02:11,680
so he starts thinking um he knows that

00:02:10,239 --> 00:02:13,360
the first step um

00:02:11,680 --> 00:02:15,520
in any machine learning application is

00:02:13,360 --> 00:02:17,520
deciding how to represent

00:02:15,520 --> 00:02:19,360
uh your data points so in this case the

00:02:17,520 --> 00:02:21,520
data points are the developers

00:02:19,360 --> 00:02:22,480
and so he says okay i'm going to keep it

00:02:21,520 --> 00:02:25,360
simple and use

00:02:22,480 --> 00:02:25,920
just two parameters so he starts

00:02:25,360 --> 00:02:29,520
thinking

00:02:25,920 --> 00:02:30,720
uh what could i use uh but maybe beauty

00:02:29,520 --> 00:02:32,640
and charisma

00:02:30,720 --> 00:02:34,640
maybe you know they're not happy because

00:02:32,640 --> 00:02:35,599
they're not very beautiful and not very

00:02:34,640 --> 00:02:37,200
charismatic

00:02:35,599 --> 00:02:38,800
but then he looks like he's developers

00:02:37,200 --> 00:02:40,800
and he realizes that

00:02:38,800 --> 00:02:42,800
surely this is not a good metric in his

00:02:40,800 --> 00:02:44,720
case because all his developers are

00:02:42,800 --> 00:02:45,040
really beautiful and really charismatic

00:02:44,720 --> 00:02:46,720
like

00:02:45,040 --> 00:02:48,400
most developers are really we all know

00:02:46,720 --> 00:02:49,760
that and

00:02:48,400 --> 00:02:51,519
so he starts thinking again maybe i can

00:02:49,760 --> 00:02:53,920
find something better maybe

00:02:51,519 --> 00:02:54,879
um i could look at their code quality so

00:02:53,920 --> 00:02:56,879
if i take

00:02:54,879 --> 00:02:58,239
the coverage the test coverage and the

00:02:56,879 --> 00:02:59,040
documentation coverage for each

00:02:58,239 --> 00:03:01,519
developer

00:02:59,040 --> 00:03:02,720
maybe i could find a pattern there so he

00:03:01,519 --> 00:03:04,959
looks um

00:03:02,720 --> 00:03:06,640
he looks at the developers and realizes

00:03:04,959 --> 00:03:09,280
that actually there is a pattern

00:03:06,640 --> 00:03:10,560
and you can see that clearly um these

00:03:09,280 --> 00:03:13,680
representation dimensions

00:03:10,560 --> 00:03:14,319
are quite helpful and uh and it turns

00:03:13,680 --> 00:03:15,920
out yeah that

00:03:14,319 --> 00:03:18,000
status developers actually were the ones

00:03:15,920 --> 00:03:19,599
that had the lowest quality

00:03:18,000 --> 00:03:21,040
code and happy developers were the ones

00:03:19,599 --> 00:03:23,920
that had um

00:03:21,040 --> 00:03:24,560
really high quality code so um this is

00:03:23,920 --> 00:03:26,640
what he does

00:03:24,560 --> 00:03:27,599
he he decides to represent each

00:03:26,640 --> 00:03:30,560
developer

00:03:27,599 --> 00:03:32,799
using a vector and that is made up of

00:03:30,560 --> 00:03:35,840
two dimensions so documentation coverage

00:03:32,799 --> 00:03:39,680
and test coverage and

00:03:35,840 --> 00:03:41,920
for each of them he also assigns a label

00:03:39,680 --> 00:03:44,239
and that is a strict label so either

00:03:41,920 --> 00:03:46,400
happy or unhappy

00:03:44,239 --> 00:03:48,000
and all this data constitutes his

00:03:46,400 --> 00:03:49,920
training data

00:03:48,000 --> 00:03:52,319
um at this point he can feed all this

00:03:49,920 --> 00:03:53,519
data to a machine learning model finally

00:03:52,319 --> 00:03:55,840
and in this case he uses a

00:03:53,519 --> 00:03:58,959
classification model and decides to

00:03:55,840 --> 00:04:00,080
to train it now um the job of the

00:03:58,959 --> 00:04:03,200
classification model

00:04:00,080 --> 00:04:05,519
is to divide the representation space

00:04:03,200 --> 00:04:06,400
in a way that maximizes the number of

00:04:05,519 --> 00:04:09,040
developers

00:04:06,400 --> 00:04:09,760
that are classified correctly for our

00:04:09,040 --> 00:04:11,840
training set

00:04:09,760 --> 00:04:13,120
so in our case which is very very simple

00:04:11,840 --> 00:04:16,639
we see that this is simply

00:04:13,120 --> 00:04:18,479
a straight line but of course it becomes

00:04:16,639 --> 00:04:20,880
it can be much more complex in reality

00:04:18,479 --> 00:04:24,639
in other examples

00:04:20,880 --> 00:04:28,000
so using using this system the hr

00:04:24,639 --> 00:04:29,600
department can predict which developers

00:04:28,000 --> 00:04:30,479
are happy and which developers are

00:04:29,600 --> 00:04:34,240
unhappy

00:04:30,479 --> 00:04:37,120
and overall it does a pretty good job

00:04:34,240 --> 00:04:37,680
now i know um i know what you're going

00:04:37,120 --> 00:04:39,120
to say

00:04:37,680 --> 00:04:40,320
that of course they're going to be

00:04:39,120 --> 00:04:41,919
mistakes of course there's going to be

00:04:40,320 --> 00:04:45,680
some developers that are sad

00:04:41,919 --> 00:04:47,120
even if um their code coverage the

00:04:45,680 --> 00:04:49,520
test coverage and documentation coverage

00:04:47,120 --> 00:04:51,120
is is good and at the same time there's

00:04:49,520 --> 00:04:53,440
going to be some developers that are

00:04:51,120 --> 00:04:54,960
happy even though their code quality is

00:04:53,440 --> 00:04:57,360
very low

00:04:54,960 --> 00:04:58,639
but this is the thing about machine

00:04:57,360 --> 00:04:59,840
learning models they

00:04:58,639 --> 00:05:01,680
are at the end of the day just

00:04:59,840 --> 00:05:03,360
statistical models so

00:05:01,680 --> 00:05:04,880
we can't expect them to be right all the

00:05:03,360 --> 00:05:07,520
time as long as they're right

00:05:04,880 --> 00:05:08,160
most of the time so i'd say that overall

00:05:07,520 --> 00:05:10,800
um

00:05:08,160 --> 00:05:12,080
this is quite a good thing um for the hr

00:05:10,800 --> 00:05:14,960
department

00:05:12,080 --> 00:05:15,520
but then a month comes a month goes and

00:05:14,960 --> 00:05:17,919
uh

00:05:15,520 --> 00:05:20,000
the cto receives another call and it's a

00:05:17,919 --> 00:05:22,479
hr again and they say actually you know

00:05:20,000 --> 00:05:23,199
we're not happy with this it's uh it's

00:05:22,479 --> 00:05:25,600
not enough

00:05:23,199 --> 00:05:26,240
um it's too black or white this system

00:05:25,600 --> 00:05:28,240
and

00:05:26,240 --> 00:05:29,919
we just end up having developers put in

00:05:28,240 --> 00:05:31,280
boxes where we know that they're either

00:05:29,919 --> 00:05:34,240
really happy or

00:05:31,280 --> 00:05:36,000
or really unhappy but in reality some

00:05:34,240 --> 00:05:38,639
developers just lie in between

00:05:36,000 --> 00:05:39,600
and okay they might not love their job

00:05:38,639 --> 00:05:42,960
with a passion

00:05:39,600 --> 00:05:44,400
but uh they're not completely unhappy

00:05:42,960 --> 00:05:46,720
and they're definitely not close to

00:05:44,400 --> 00:05:49,039
resignation so they suggest

00:05:46,720 --> 00:05:50,160
um why don't you give us a happiness

00:05:49,039 --> 00:05:52,479
score instead

00:05:50,160 --> 00:05:53,600
um so each developer would be assigned a

00:05:52,479 --> 00:05:56,639
score from

00:05:53,600 --> 00:05:59,759
a 0 to 100 of happiness

00:05:56,639 --> 00:06:00,720
and hopefully this means that hr has a

00:05:59,759 --> 00:06:03,840
bit of a more

00:06:00,720 --> 00:06:05,919
nuanced vision into how

00:06:03,840 --> 00:06:07,199
close a developer is to leaving the

00:06:05,919 --> 00:06:08,960
company

00:06:07,199 --> 00:06:10,800
and and they cannot adjust on the cases

00:06:08,960 --> 00:06:13,440
that are very urgent

00:06:10,800 --> 00:06:15,039
and so the the cto starts looking at his

00:06:13,440 --> 00:06:15,520
developers and said okay i think i can

00:06:15,039 --> 00:06:18,080
do this

00:06:15,520 --> 00:06:19,039
i think i just need a different model so

00:06:18,080 --> 00:06:21,520
i'm going to use

00:06:19,039 --> 00:06:23,280
a regression model so once again he

00:06:21,520 --> 00:06:26,080
starts preparing his training data

00:06:23,280 --> 00:06:28,240
which uses the same metrics as before so

00:06:26,080 --> 00:06:31,280
test coverage and documentation coverage

00:06:28,240 --> 00:06:34,319
but instead of a categorical label so

00:06:31,280 --> 00:06:35,360
happy or unhappy he labels each

00:06:34,319 --> 00:06:38,639
developer

00:06:35,360 --> 00:06:41,120
with a percentage so for example 35

00:06:38,639 --> 00:06:43,199
happy and he also chooses like i said a

00:06:41,120 --> 00:06:46,000
different type of model which is called

00:06:43,199 --> 00:06:47,680
a regression model now what the

00:06:46,000 --> 00:06:48,000
regression model does is that instead of

00:06:47,680 --> 00:06:51,520
giving

00:06:48,000 --> 00:06:52,560
us a discrete value so categorical happy

00:06:51,520 --> 00:06:54,800
or unhappy

00:06:52,560 --> 00:06:56,319
it gives us a continuous value so a

00:06:54,800 --> 00:06:59,199
degrees of happiness

00:06:56,319 --> 00:07:00,080
um and on the representation space the

00:06:59,199 --> 00:07:02,400
effect is

00:07:00,080 --> 00:07:04,000
that instead of having a clear division

00:07:02,400 --> 00:07:06,319
between two opposite areas

00:07:04,000 --> 00:07:08,240
uh we have this kind of gradient that i

00:07:06,319 --> 00:07:11,440
represented here with colors

00:07:08,240 --> 00:07:14,000
now in the same way of classification

00:07:11,440 --> 00:07:15,280
this model learns uh the mapping by

00:07:14,000 --> 00:07:19,120
looking at the training data

00:07:15,280 --> 00:07:21,440
so the mapping maximizes the prediction

00:07:19,120 --> 00:07:23,919
of the correct happiness value for all

00:07:21,440 --> 00:07:26,880
developers in our data set

00:07:23,919 --> 00:07:27,680
so now we have a model that takes the

00:07:26,880 --> 00:07:29,440
test coverage

00:07:27,680 --> 00:07:31,199
and the documentation coverage for each

00:07:29,440 --> 00:07:33,919
developer and identifies

00:07:31,199 --> 00:07:35,120
how happy they're likely to be from zero

00:07:33,919 --> 00:07:38,160
percent to 100

00:07:35,120 --> 00:07:39,680
so for example uh grace here who has

00:07:38,160 --> 00:07:41,759
impeccable tests and documentation

00:07:39,680 --> 00:07:42,880
coverage will be classified as very

00:07:41,759 --> 00:07:46,160
happy

00:07:42,880 --> 00:07:47,520
while poor old allen instead is

00:07:46,160 --> 00:07:49,280
down at the bottom because he doesn't

00:07:47,520 --> 00:07:50,319
like to document and to test so he's

00:07:49,280 --> 00:07:52,720
considered

00:07:50,319 --> 00:07:54,080
to be very unhappy and the big

00:07:52,720 --> 00:07:56,319
improvement here

00:07:54,080 --> 00:07:57,759
is for all of those developers are lying

00:07:56,319 --> 00:07:58,639
in the middle so previously they were

00:07:57,759 --> 00:08:01,840
classified

00:07:58,639 --> 00:08:03,840
either as a zero or a one and now we can

00:08:01,840 --> 00:08:07,280
say they're kind of like 50 percent

00:08:03,840 --> 00:08:08,400
happy so cto is happy he gives this new

00:08:07,280 --> 00:08:10,560
model to hr

00:08:08,400 --> 00:08:12,160
and for a while everything goes well and

00:08:10,560 --> 00:08:15,199
they have a nice way to categorize

00:08:12,160 --> 00:08:16,960
developers but one day

00:08:15,199 --> 00:08:18,400
one of the developers finds out that

00:08:16,960 --> 00:08:20,879
this has been happening

00:08:18,400 --> 00:08:21,919
and he tells all the others and they all

00:08:20,879 --> 00:08:23,919
go furious

00:08:21,919 --> 00:08:25,680
they about the fact that they've been

00:08:23,919 --> 00:08:27,360
categorizing them this way they say you

00:08:25,680 --> 00:08:29,360
know we're not just figures on an excel

00:08:27,360 --> 00:08:31,360
file this is unacceptable

00:08:29,360 --> 00:08:32,880
and because they're french they work in

00:08:31,360 --> 00:08:35,279
a french company they decide to go

00:08:32,880 --> 00:08:37,760
on strike say we're not coming back

00:08:35,279 --> 00:08:40,959
until you find a more human way

00:08:37,760 --> 00:08:42,880
um to find out about our well-being

00:08:40,959 --> 00:08:44,560
and their representative proposes that

00:08:42,880 --> 00:08:45,120
maybe they should be able to send emails

00:08:44,560 --> 00:08:46,880
to the

00:08:45,120 --> 00:08:49,279
hr department to tell them how they're

00:08:46,880 --> 00:08:51,680
feeling and the hr

00:08:49,279 --> 00:08:52,480
should use these emails to make their

00:08:51,680 --> 00:08:56,240
judgments

00:08:52,480 --> 00:08:58,959
and act when it's necessary immediately

00:08:56,240 --> 00:08:59,760
hr is inundated by emails and they

00:08:58,959 --> 00:09:01,279
realize

00:08:59,760 --> 00:09:03,120
there is no way they will be able to do

00:09:01,279 --> 00:09:05,519
this job manually

00:09:03,120 --> 00:09:06,959
so once again they go to the cto and ask

00:09:05,519 --> 00:09:09,920
him for a way to

00:09:06,959 --> 00:09:11,200
to to help them in the process the cto

00:09:09,920 --> 00:09:13,200
says uh no problem

00:09:11,200 --> 00:09:14,880
okay uh but at this point he's become so

00:09:13,200 --> 00:09:17,760
obsessed with the fact that

00:09:14,880 --> 00:09:18,080
uh code quality equals happiness at work

00:09:17,760 --> 00:09:20,720
that

00:09:18,080 --> 00:09:21,680
he uses this criteria to label all the

00:09:20,720 --> 00:09:24,240
emails that

00:09:21,680 --> 00:09:25,920
the hr department starts receiving uh so

00:09:24,240 --> 00:09:27,600
his training set

00:09:25,920 --> 00:09:29,200
he labels all the ones that talk about

00:09:27,600 --> 00:09:31,120
testing code um

00:09:29,200 --> 00:09:32,480
with various degrees of happiness so

00:09:31,120 --> 00:09:36,399
kind of like let's say 50

00:09:32,480 --> 00:09:38,320
to 100 and instead all the ones that uh

00:09:36,399 --> 00:09:40,399
you know where the developers confess

00:09:38,320 --> 00:09:42,080
that they are not big fans of testing

00:09:40,399 --> 00:09:44,880
uh he says okay this must be zero

00:09:42,080 --> 00:09:48,160
percent to fifty percent

00:09:44,880 --> 00:09:49,360
and uh he has the problem now what is

00:09:48,160 --> 00:09:51,760
his data set

00:09:49,360 --> 00:09:52,800
so his data set is very different from

00:09:51,760 --> 00:09:54,880
what it was before

00:09:52,800 --> 00:09:56,560
before each developer had a vector with

00:09:54,880 --> 00:09:59,360
a score of documentation coverage

00:09:56,560 --> 00:10:01,200
and test coverage but now all he has for

00:09:59,360 --> 00:10:03,440
each developers is an email which is

00:10:01,200 --> 00:10:06,160
essentially natural language

00:10:03,440 --> 00:10:08,480
so he realizes that he needs to use nlp

00:10:06,160 --> 00:10:09,760
and he's very very happy because he's

00:10:08,480 --> 00:10:12,800
never used it before

00:10:09,760 --> 00:10:15,680
so it's his first time he decides to

00:10:12,800 --> 00:10:16,800
apply techniques of sentiment analysis

00:10:15,680 --> 00:10:19,360
to detect

00:10:16,800 --> 00:10:20,640
if each developer is happy or unlikely

00:10:19,360 --> 00:10:23,920
or unhappy sorry

00:10:20,640 --> 00:10:25,279
based on um on his email now

00:10:23,920 --> 00:10:28,640
before you comment that sentiment

00:10:25,279 --> 00:10:30,959
analysis does not cover the whole of nlp

00:10:28,640 --> 00:10:33,040
this is absolutely true it's only one of

00:10:30,959 --> 00:10:34,880
many tasks that nlp can do

00:10:33,040 --> 00:10:36,399
but i decided to use this as an example

00:10:34,880 --> 00:10:38,160
because um it's

00:10:36,399 --> 00:10:39,519
for the sake of simplification but also

00:10:38,160 --> 00:10:41,279
because um

00:10:39,519 --> 00:10:42,720
most like many techniques used in

00:10:41,279 --> 00:10:46,000
sentiment analysis are

00:10:42,720 --> 00:10:49,680
actually the root of nlp as a whole

00:10:46,000 --> 00:10:51,760
so let's get back to our story um

00:10:49,680 --> 00:10:53,760
and actually my screen froze for a

00:10:51,760 --> 00:10:57,519
second

00:10:53,760 --> 00:11:00,240
let me get back to it okay yeah i'm good

00:10:57,519 --> 00:11:01,120
so the first thing the cto needs to do

00:11:00,240 --> 00:11:04,320
is to

00:11:01,120 --> 00:11:05,519
break up these emails um all the emails

00:11:04,320 --> 00:11:08,240
that are in this data set

00:11:05,519 --> 00:11:09,680
into smaller units um so that processing

00:11:08,240 --> 00:11:11,440
will be a little bit easier

00:11:09,680 --> 00:11:14,480
and this process in nlp is called

00:11:11,440 --> 00:11:17,200
tokenization so in our case we consider

00:11:14,480 --> 00:11:18,880
our words to be our tokens which means

00:11:17,200 --> 00:11:19,279
that in a sentence like i always test my

00:11:18,880 --> 00:11:23,760
code

00:11:19,279 --> 00:11:23,760
we'll end up with i always test my code

00:11:23,839 --> 00:11:27,680
and the advantage of tokenization is

00:11:26,240 --> 00:11:30,399
that

00:11:27,680 --> 00:11:30,720
whole emails are unlikely to be repeated

00:11:30,399 --> 00:11:32,560
so

00:11:30,720 --> 00:11:34,079
we're not gonna receive the same email

00:11:32,560 --> 00:11:36,480
twice exactly

00:11:34,079 --> 00:11:38,320
but often the same words uh do appear in

00:11:36,480 --> 00:11:41,040
different emails in different contexts

00:11:38,320 --> 00:11:42,399
and this allows us to find some points

00:11:41,040 --> 00:11:45,839
in common before

00:11:42,399 --> 00:11:48,399
emails between emails sorry

00:11:45,839 --> 00:11:49,279
now uh the cto notices immediately that

00:11:48,399 --> 00:11:51,360
sometimes there

00:11:49,279 --> 00:11:52,560
are small mistakes or differences in how

00:11:51,360 --> 00:11:54,240
a word is spelled

00:11:52,560 --> 00:11:55,760
and differences between uppercase and

00:11:54,240 --> 00:11:57,519
lowercase and

00:11:55,760 --> 00:11:59,920
he realizes it's in his interest to

00:11:57,519 --> 00:12:01,760
remove these discrepancies because

00:11:59,920 --> 00:12:03,279
it doesn't look like they add much value

00:12:01,760 --> 00:12:04,880
to the meaning of the sentence

00:12:03,279 --> 00:12:06,320
so he decides to do a little bit of

00:12:04,880 --> 00:12:08,639
preprocessing

00:12:06,320 --> 00:12:09,519
and he transforms everything into

00:12:08,639 --> 00:12:11,120
lowercase

00:12:09,519 --> 00:12:13,200
which means that we end up with a

00:12:11,120 --> 00:12:16,880
slightly more limited number

00:12:13,200 --> 00:12:17,600
of unique tokens and we can identify the

00:12:16,880 --> 00:12:19,600
same word

00:12:17,600 --> 00:12:21,680
even when it's capitalized in a

00:12:19,600 --> 00:12:24,079
different way

00:12:21,680 --> 00:12:24,720
then he notices that um there are some

00:12:24,079 --> 00:12:27,600
words that

00:12:24,720 --> 00:12:28,720
are uh used in different maybe some

00:12:27,600 --> 00:12:29,360
verbs that are used in different

00:12:28,720 --> 00:12:31,680
sentences

00:12:29,360 --> 00:12:33,440
in different sentence different tenses

00:12:31,680 --> 00:12:36,240
in different sentences sorry

00:12:33,440 --> 00:12:38,320
um or some adjectives that i used

00:12:36,240 --> 00:12:41,120
sometimes are singular sometimes in a

00:12:38,320 --> 00:12:41,519
plural and it would make sense to reduce

00:12:41,120 --> 00:12:43,839
those

00:12:41,519 --> 00:12:44,560
just to the essence of what it is so

00:12:43,839 --> 00:12:46,560
what he does

00:12:44,560 --> 00:12:48,639
is uh he breaks down all these words

00:12:46,560 --> 00:12:50,720
where he notices this behavior

00:12:48,639 --> 00:12:52,720
and he breaks them into some words

00:12:50,720 --> 00:12:56,000
basically in most cases he just

00:12:52,720 --> 00:12:59,440
separates the root of the word from a

00:12:56,000 --> 00:13:02,079
suffix or a prefix so like testing

00:12:59,440 --> 00:13:04,839
becomes just test plus ing tested is

00:13:02,079 --> 00:13:06,880
test plus ed

00:13:04,839 --> 00:13:08,800
etc uh

00:13:06,880 --> 00:13:10,959
you know he's pretty happy at this point

00:13:08,800 --> 00:13:13,279
he can match words not only when they're

00:13:10,959 --> 00:13:15,760
capitalized differently but also when

00:13:13,279 --> 00:13:16,800
they appear in different uh tenses or

00:13:15,760 --> 00:13:20,000
different suffixes

00:13:16,800 --> 00:13:22,560
etc now the question is

00:13:20,000 --> 00:13:23,279
what do we do with these words so when

00:13:22,560 --> 00:13:25,839
we had

00:13:23,279 --> 00:13:27,519
uh code coverage and uh and

00:13:25,839 --> 00:13:29,200
documentation coverage it was quite easy

00:13:27,519 --> 00:13:32,079
to picture how to represent each other

00:13:29,200 --> 00:13:35,279
space but how do we do this for words

00:13:32,079 --> 00:13:38,079
so basically we need to go from words um

00:13:35,279 --> 00:13:39,120
to numbers uh if we eventually want to

00:13:38,079 --> 00:13:41,760
represent a whole

00:13:39,120 --> 00:13:42,959
email uh with numbers with a series of

00:13:41,760 --> 00:13:45,440
numbers

00:13:42,959 --> 00:13:46,079
so what we do is that we look at the

00:13:45,440 --> 00:13:48,880
context

00:13:46,079 --> 00:13:50,240
in which each word appears and we make

00:13:48,880 --> 00:13:52,320
the assumption that

00:13:50,240 --> 00:13:55,040
words that appear most often close

00:13:52,320 --> 00:13:58,000
together are also closed semantically

00:13:55,040 --> 00:13:59,519
now with this assumption we can then map

00:13:58,000 --> 00:14:03,040
the words that are in the same

00:13:59,519 --> 00:14:05,279
context as close together let me explain

00:14:03,040 --> 00:14:07,680
a bit more so

00:14:05,279 --> 00:14:08,800
if we take an example um if i notice

00:14:07,680 --> 00:14:12,079
that the word bug

00:14:08,800 --> 00:14:14,959
appears very often near the word sad

00:14:12,079 --> 00:14:16,639
and almost never near the word happy

00:14:14,959 --> 00:14:18,399
then i can deduce

00:14:16,639 --> 00:14:20,160
that basically they belong to the same

00:14:18,399 --> 00:14:22,320
family of meaning

00:14:20,160 --> 00:14:24,079
and we have some very powerful

00:14:22,320 --> 00:14:26,160
algorithms in nlp

00:14:24,079 --> 00:14:27,440
that can exploit this information and

00:14:26,160 --> 00:14:30,480
they create a

00:14:27,440 --> 00:14:33,600
numerical representation for words

00:14:30,480 --> 00:14:35,440
um and they're called embeddings now

00:14:33,600 --> 00:14:37,360
embeddings help us obtain a space that

00:14:35,440 --> 00:14:39,120
looks a little bit like this

00:14:37,360 --> 00:14:40,800
where we can find in our example

00:14:39,120 --> 00:14:43,040
positive words all

00:14:40,800 --> 00:14:44,000
cornered on the top right and negative

00:14:43,040 --> 00:14:46,880
words are all

00:14:44,000 --> 00:14:47,199
on the bottom left and all neutral words

00:14:46,880 --> 00:14:49,760
are

00:14:47,199 --> 00:14:51,199
in the middle so this is good so we have

00:14:49,760 --> 00:14:53,040
a representation

00:14:51,199 --> 00:14:55,440
space for all of the words that can

00:14:53,040 --> 00:14:57,600
appear in any email

00:14:55,440 --> 00:14:58,560
but what does the cto do at this point

00:14:57,600 --> 00:15:01,600
so he needs to

00:14:58,560 --> 00:15:04,800
exploit this mechanism

00:15:01,600 --> 00:15:07,839
um one moment

00:15:04,800 --> 00:15:08,639
okay um so he uses these things

00:15:07,839 --> 00:15:11,040
embeddings

00:15:08,639 --> 00:15:12,079
to extract semantic information about

00:15:11,040 --> 00:15:14,399
about

00:15:12,079 --> 00:15:16,000
those emails and it allows him to make

00:15:14,399 --> 00:15:17,760
some simple predictions

00:15:16,000 --> 00:15:20,160
of whether a developer is happy or

00:15:17,760 --> 00:15:22,399
unhappy just like before

00:15:20,160 --> 00:15:23,440
so for example he can take each of the

00:15:22,399 --> 00:15:26,399
words that make up an

00:15:23,440 --> 00:15:27,279
animal and take the vector that

00:15:26,399 --> 00:15:29,360
represents them

00:15:27,279 --> 00:15:30,560
and make the mathematical mean between

00:15:29,360 --> 00:15:34,079
them so

00:15:30,560 --> 00:15:37,199
if we look at it in our embedding space

00:15:34,079 --> 00:15:40,560
um so we have lots of individual vectors

00:15:37,199 --> 00:15:42,000
and we end up having only one vector

00:15:40,560 --> 00:15:43,279
that represents the whole sentence

00:15:42,000 --> 00:15:44,880
that's kind of like in the center

00:15:43,279 --> 00:15:47,920
between all of them

00:15:44,880 --> 00:15:50,720
and now we can repeat this for all of my

00:15:47,920 --> 00:15:52,160
emails and we end up having something

00:15:50,720 --> 00:15:52,720
that looks like this which is very

00:15:52,160 --> 00:15:54,639
similar

00:15:52,720 --> 00:15:56,000
if you remember to the slide where we

00:15:54,639 --> 00:15:56,800
had all the little faces of the

00:15:56,000 --> 00:15:59,040
developers

00:15:56,800 --> 00:16:00,880
so each of these emails represent a

00:15:59,040 --> 00:16:03,279
developer and it's somewhere in an

00:16:00,880 --> 00:16:07,199
embedding space

00:16:03,279 --> 00:16:09,759
um so now we know how to represent

00:16:07,199 --> 00:16:10,880
each email which is good we have we have

00:16:09,759 --> 00:16:13,759
some numbers and we know

00:16:10,880 --> 00:16:14,240
artificial intelligence loves numbers

00:16:13,759 --> 00:16:17,680
and

00:16:14,240 --> 00:16:20,079
um we can label them first of course

00:16:17,680 --> 00:16:22,639
and then we feed them to our nlp model

00:16:20,079 --> 00:16:25,440
as training data so

00:16:22,639 --> 00:16:26,240
the output of this model is that the hr

00:16:25,440 --> 00:16:28,880
department

00:16:26,240 --> 00:16:30,480
can predict the happiness score for each

00:16:28,880 --> 00:16:32,160
new email that comes in

00:16:30,480 --> 00:16:33,600
uh pretty much in the same way that they

00:16:32,160 --> 00:16:34,959
did before um

00:16:33,600 --> 00:16:37,600
with with the regression model that we

00:16:34,959 --> 00:16:41,040
looked at before

00:16:37,600 --> 00:16:44,240
and this looks fantastic at first sight

00:16:41,040 --> 00:16:47,600
but if we're honest um

00:16:44,240 --> 00:16:49,600
this is completely based on how good the

00:16:47,600 --> 00:16:51,759
mapping for the words is

00:16:49,600 --> 00:16:52,800
and it means that it's also only based

00:16:51,759 --> 00:16:55,759
on semantics

00:16:52,800 --> 00:16:56,320
so it's done in a way that is too simple

00:16:55,759 --> 00:16:58,560
because

00:16:56,320 --> 00:17:00,079
if we try to look at a sentence that is

00:16:58,560 --> 00:17:02,320
a little bit more complex

00:17:00,079 --> 00:17:05,199
uh not even much more complex like i

00:17:02,320 --> 00:17:07,679
really never test my code

00:17:05,199 --> 00:17:08,720
and we try to do the mean once again

00:17:07,679 --> 00:17:12,000
between

00:17:08,720 --> 00:17:15,120
the position of each word um so

00:17:12,000 --> 00:17:18,160
we reconduce those two here

00:17:15,120 --> 00:17:20,400
we see that it seems to have

00:17:18,160 --> 00:17:21,760
quite positive meaning and we know that

00:17:20,400 --> 00:17:23,280
this is absolutely impossible a

00:17:21,760 --> 00:17:26,720
developer that never tests

00:17:23,280 --> 00:17:28,960
their code cannot be happy really

00:17:26,720 --> 00:17:31,200
so it looks like there is a problem and

00:17:28,960 --> 00:17:34,240
the cto needs to fix it

00:17:31,200 --> 00:17:35,760
so what does he do he looks up his

00:17:34,240 --> 00:17:37,280
machine learning notes and decides to

00:17:35,760 --> 00:17:40,000
add another ml piece

00:17:37,280 --> 00:17:42,559
to his uh to help his embeddings and

00:17:40,000 --> 00:17:45,600
this new piece is called recurrence

00:17:42,559 --> 00:17:47,280
now our embeddings so the red piece um

00:17:45,600 --> 00:17:49,200
didn't really look at the relationship

00:17:47,280 --> 00:17:49,919
between words um didn't look at the

00:17:49,200 --> 00:17:53,120
order

00:17:49,919 --> 00:17:55,200
it only looked at semantics so

00:17:53,120 --> 00:17:56,240
it understood things really in quite a

00:17:55,200 --> 00:17:58,960
dumb way

00:17:56,240 --> 00:18:00,240
now recurrence on the other hand um it

00:17:58,960 --> 00:18:03,280
gives meaning to

00:18:00,240 --> 00:18:04,880
the order in which things appear so

00:18:03,280 --> 00:18:07,520
basically when we move from one word to

00:18:04,880 --> 00:18:10,400
another it keeps some sort of um

00:18:07,520 --> 00:18:11,520
shorter memory and it can alter the

00:18:10,400 --> 00:18:15,039
meaning of a word

00:18:11,520 --> 00:18:17,600
based on what came before and

00:18:15,039 --> 00:18:18,799
especially it's able to look at words

00:18:17,600 --> 00:18:20,559
that are

00:18:18,799 --> 00:18:21,840
present in many different semantic

00:18:20,559 --> 00:18:25,200
contexts um

00:18:21,840 --> 00:18:26,000
and don't seem to have a specific value

00:18:25,200 --> 00:18:29,039
of their own

00:18:26,000 --> 00:18:32,559
and these are words like very some not

00:18:29,039 --> 00:18:34,400
etc and um recognize that

00:18:32,559 --> 00:18:36,720
actually they're not useless they do

00:18:34,400 --> 00:18:39,360
have some utility because they react

00:18:36,720 --> 00:18:42,400
to the semantic value of other words in

00:18:39,360 --> 00:18:45,760
the same sentence

00:18:42,400 --> 00:18:49,679
um so oh sorry

00:18:45,760 --> 00:18:51,840
froze again let me see

00:18:49,679 --> 00:18:53,120
okay yes so he puts together the two

00:18:51,840 --> 00:18:55,840
pieces

00:18:53,120 --> 00:18:56,320
and uh looks at what happens so the new

00:18:55,840 --> 00:18:59,360
model

00:18:56,320 --> 00:18:59,760
starts looking at the tokens in order uh

00:18:59,360 --> 00:19:01,919
so

00:18:59,760 --> 00:19:03,840
takes them one by one so first we see

00:19:01,919 --> 00:19:05,360
the word i for the sentence i really

00:19:03,840 --> 00:19:08,840
never test

00:19:05,360 --> 00:19:10,000
and i is quite neutral so nobody says

00:19:08,840 --> 00:19:12,960
anything

00:19:10,000 --> 00:19:13,440
but then we get to the word really and

00:19:12,960 --> 00:19:17,280
really

00:19:13,440 --> 00:19:20,720
has has an amplifying meaning

00:19:17,280 --> 00:19:23,120
so the recurrence recognizes this and

00:19:20,720 --> 00:19:25,520
starts kind of repeating to himself

00:19:23,120 --> 00:19:26,799
amplify amplify amplify amplify remember

00:19:25,520 --> 00:19:30,000
to amplify

00:19:26,799 --> 00:19:30,799
and then we move on to the next word the

00:19:30,000 --> 00:19:34,160
next word is

00:19:30,799 --> 00:19:36,720
never which has a negating effect so

00:19:34,160 --> 00:19:38,400
once again recurrence identify this and

00:19:36,720 --> 00:19:40,320
says okay amplifying the gate amplifying

00:19:38,400 --> 00:19:42,799
the gate amplify negate

00:19:40,320 --> 00:19:43,600
and finally we arrive to the word test

00:19:42,799 --> 00:19:46,640
and here our

00:19:43,600 --> 00:19:48,080
embedding piece um sees this and says oh

00:19:46,640 --> 00:19:50,799
i know i know this

00:19:48,080 --> 00:19:52,480
and looks it up sees that it does have a

00:19:50,799 --> 00:19:54,880
polarized value

00:19:52,480 --> 00:19:56,160
and and says okay it means that this

00:19:54,880 --> 00:19:58,720
sentence so far

00:19:56,160 --> 00:19:59,360
must be sent by a happy developer at the

00:19:58,720 --> 00:20:01,200
same time

00:19:59,360 --> 00:20:02,799
yellow peace keeps saying amplify negate

00:20:01,200 --> 00:20:04,880
amplifying the gate

00:20:02,799 --> 00:20:06,960
and because we're at the end of our

00:20:04,880 --> 00:20:08,960
sentence once we put the two together

00:20:06,960 --> 00:20:10,240
we have the embedding that tells us that

00:20:08,960 --> 00:20:12,320
it's a happy email

00:20:10,240 --> 00:20:14,080
and the recurrence that tells us to

00:20:12,320 --> 00:20:15,440
amplify and negate whatever the

00:20:14,080 --> 00:20:18,159
embedding said

00:20:15,440 --> 00:20:20,480
so in the end we found out that the

00:20:18,159 --> 00:20:21,600
developer who sent the email is very not

00:20:20,480 --> 00:20:24,400
happy

00:20:21,600 --> 00:20:26,240
which is good it's what we wanted so cto

00:20:24,400 --> 00:20:26,799
is super happy he sends a new model to

00:20:26,240 --> 00:20:28,640
hr

00:20:26,799 --> 00:20:30,640
and says use this for all your future

00:20:28,640 --> 00:20:34,240
predictions

00:20:30,640 --> 00:20:36,559
but we have another problem we know that

00:20:34,240 --> 00:20:37,280
chatty developers do exist they're quite

00:20:36,559 --> 00:20:39,679
rare but

00:20:37,280 --> 00:20:41,200
they exist we all know some of them and

00:20:39,679 --> 00:20:43,520
one day hr receives

00:20:41,200 --> 00:20:44,799
a very very long email in which this

00:20:43,520 --> 00:20:47,919
developer decides to

00:20:44,799 --> 00:20:49,520
be oversharing he talks a lot about his

00:20:47,919 --> 00:20:51,360
life not just a professional side he

00:20:49,520 --> 00:20:53,760
talks about you know his wonderful wife

00:20:51,360 --> 00:20:55,840
his children where he's going on holiday

00:20:53,760 --> 00:20:58,159
his friends etc and somewhere in there

00:20:55,840 --> 00:21:00,480
he also says but i never test my coat

00:20:58,159 --> 00:21:03,440
but overall he's conveying like

00:21:00,480 --> 00:21:06,960
enthusiasm about the rest of his life

00:21:03,440 --> 00:21:06,960
so um

00:21:07,039 --> 00:21:10,080
having some problems with slides again

00:21:08,559 --> 00:21:12,240
okay um

00:21:10,080 --> 00:21:13,679
so this means that when the nlp

00:21:12,240 --> 00:21:16,240
algorithm that we've prepared

00:21:13,679 --> 00:21:18,000
processes this um it will make a

00:21:16,240 --> 00:21:20,159
prediction the developer the developer

00:21:18,000 --> 00:21:22,480
is uh really really happy

00:21:20,159 --> 00:21:23,679
but the cto looks at this and says oh my

00:21:22,480 --> 00:21:26,320
god not

00:21:23,679 --> 00:21:27,760
again this is not possible it failed

00:21:26,320 --> 00:21:29,600
because if this developer doesn't test

00:21:27,760 --> 00:21:30,720
this code there's absolutely no chance

00:21:29,600 --> 00:21:32,880
that he's really happy

00:21:30,720 --> 00:21:35,200
there must be a mistake so all this

00:21:32,880 --> 00:21:37,840
chatting about wives and children's and

00:21:35,200 --> 00:21:38,880
holidays has confused my algorithms i

00:21:37,840 --> 00:21:42,000
need to do something about

00:21:38,880 --> 00:21:43,520
it so once again he decides to add a new

00:21:42,000 --> 00:21:45,679
piece to the puzzle

00:21:43,520 --> 00:21:46,799
the new piece is called attention

00:21:45,679 --> 00:21:49,760
attention is

00:21:46,799 --> 00:21:50,640
a mechanism that gives way to important

00:21:49,760 --> 00:21:52,240
things

00:21:50,640 --> 00:21:53,919
and ignores the things are less

00:21:52,240 --> 00:21:56,720
important so the concept is that

00:21:53,919 --> 00:21:58,880
um what is the concept of what is

00:21:56,720 --> 00:22:01,280
important is completely dependent on

00:21:58,880 --> 00:22:02,880
on our objective so in our case the

00:22:01,280 --> 00:22:03,520
attention mechanism will prioritize

00:22:02,880 --> 00:22:06,480
information

00:22:03,520 --> 00:22:06,960
related to developers happiness at work

00:22:06,480 --> 00:22:09,120
and

00:22:06,960 --> 00:22:11,679
it will give less weight to things that

00:22:09,120 --> 00:22:13,760
belong to different semantic areas

00:22:11,679 --> 00:22:14,960
so we introduce this piece and we try

00:22:13,760 --> 00:22:17,919
them all together

00:22:14,960 --> 00:22:19,760
and what happens is that when the the

00:22:17,919 --> 00:22:22,240
developer talks about personal stuff

00:22:19,760 --> 00:22:23,919
uh the attention piece is kind of

00:22:22,240 --> 00:22:25,600
distracting the other two and says don't

00:22:23,919 --> 00:22:26,880
pay attention at all it prevents them

00:22:25,600 --> 00:22:28,559
from doing their job

00:22:26,880 --> 00:22:30,559
but when we get to something that talks

00:22:28,559 --> 00:22:32,640
about code quality which we know is

00:22:30,559 --> 00:22:33,120
important it shuts up and forces them to

00:22:32,640 --> 00:22:34,720
do

00:22:33,120 --> 00:22:36,240
what they have to do so they do the

00:22:34,720 --> 00:22:37,760
usual so

00:22:36,240 --> 00:22:40,240
recurrence identifies that he has to

00:22:37,760 --> 00:22:41,840
negate and then

00:22:40,240 --> 00:22:43,760
the embedding piece recognizes when

00:22:41,840 --> 00:22:46,400
there is a polarizing word like test

00:22:43,760 --> 00:22:48,000
and that is happening and finally about

00:22:46,400 --> 00:22:49,840
the rest of the sentence pretty initial

00:22:48,000 --> 00:22:51,200
and finally when we get back to talking

00:22:49,840 --> 00:22:54,799
about holism friends

00:22:51,200 --> 00:22:57,840
um attention once again says no no no

00:22:54,799 --> 00:22:58,720
don't listen don't pay attention when we

00:22:57,840 --> 00:23:00,880
get to the end

00:22:58,720 --> 00:23:02,880
uh we put together everything that we

00:23:00,880 --> 00:23:04,240
have so embedding and recurrence what

00:23:02,880 --> 00:23:05,520
they were able to guess

00:23:04,240 --> 00:23:07,039
in the moments that they were paying

00:23:05,520 --> 00:23:08,320
attention and we realized that the

00:23:07,039 --> 00:23:11,360
developer was definitely

00:23:08,320 --> 00:23:13,039
not happy which is the correct

00:23:11,360 --> 00:23:15,600
conclusion for the cto

00:23:13,039 --> 00:23:17,600
cto is very very proud of himself and he

00:23:15,600 --> 00:23:20,480
presents a new model to hr

00:23:17,600 --> 00:23:20,960
and everybody is happy and this brings

00:23:20,480 --> 00:23:25,120
us to

00:23:20,960 --> 00:23:28,960
the end of this presentation um

00:23:25,120 --> 00:23:32,000
now i guess the meaning wait one second

00:23:28,960 --> 00:23:35,039
once again it froze um

00:23:32,000 --> 00:23:36,960
okay yes the the message i want you guys

00:23:35,039 --> 00:23:37,679
to keep from this apart from the story

00:23:36,960 --> 00:23:41,440
is that

00:23:37,679 --> 00:23:43,520
all impressive neural networks of nlp

00:23:41,440 --> 00:23:46,080
really are just very smart combinations

00:23:43,520 --> 00:23:47,919
of these mechanisms so we have semantic

00:23:46,080 --> 00:23:48,799
mechanisms that find meaning in words

00:23:47,919 --> 00:23:50,400
and sub words

00:23:48,799 --> 00:23:52,400
we have recurrent mechanisms that

00:23:50,400 --> 00:23:56,000
capture the order dimension

00:23:52,400 --> 00:23:56,799
of sentences and um attention mechanisms

00:23:56,000 --> 00:23:59,679
that select

00:23:56,799 --> 00:24:01,520
interesting parts from text depending on

00:23:59,679 --> 00:24:03,679
what our objective is

00:24:01,520 --> 00:24:05,679
and these are you know some of the the

00:24:03,679 --> 00:24:07,039
most relevant mechanisms from nlp uh

00:24:05,679 --> 00:24:07,520
they're not the only ones but i'll let

00:24:07,039 --> 00:24:09,760
you guys

00:24:07,520 --> 00:24:12,240
look at what the what the rest is and

00:24:09,760 --> 00:24:15,520
now just to conclude

00:24:12,240 --> 00:24:18,880
um we actually asked uh one

00:24:15,520 --> 00:24:21,360
a famous nlp model um

00:24:18,880 --> 00:24:21,919
when when our developers happy gpg3

00:24:21,360 --> 00:24:24,960
probably

00:24:21,919 --> 00:24:26,799
many of you have heard of it and so

00:24:24,960 --> 00:24:28,640
i kid you not we really really asked

00:24:26,799 --> 00:24:30,640
this and we got this answer

00:24:28,640 --> 00:24:32,640
when are developers happy but when their

00:24:30,640 --> 00:24:33,840
code is works and when someone else has

00:24:32,640 --> 00:24:36,159
to maintain it

00:24:33,840 --> 00:24:37,279
and when a developer said when a

00:24:36,159 --> 00:24:39,440
developer said

00:24:37,279 --> 00:24:40,720
when their users are sad and one of the

00:24:39,440 --> 00:24:43,520
users said

00:24:40,720 --> 00:24:46,000
when you've broken their trust and on

00:24:43,520 --> 00:24:48,159
this poetic note

00:24:46,000 --> 00:24:49,520
i wanna thank you for paying attention

00:24:48,159 --> 00:24:51,039
to my silly story

00:24:49,520 --> 00:24:54,080
i really hope you enjoyed it and that

00:24:51,039 --> 00:24:56,640
you learned something from it

00:24:54,080 --> 00:24:57,200
now um at the start of this i also told

00:24:56,640 --> 00:24:58,960
you that

00:24:57,200 --> 00:25:00,320
i am a developer i'm not a data

00:24:58,960 --> 00:25:02,400
scientist so

00:25:00,320 --> 00:25:04,000
why is it me presenting all of this to

00:25:02,400 --> 00:25:04,640
you considering i work in a company

00:25:04,000 --> 00:25:07,200
where

00:25:04,640 --> 00:25:07,919
there are many great data scientists but

00:25:07,200 --> 00:25:10,400
the reason

00:25:07,919 --> 00:25:11,520
um let me introduce the reason for you

00:25:10,400 --> 00:25:13,279
his name is hamsa

00:25:11,520 --> 00:25:14,799
saya and he's joining me now on this

00:25:13,279 --> 00:25:17,520
virtual stage um

00:25:14,799 --> 00:25:17,520
hello hamza

00:25:18,799 --> 00:25:24,880
hello benny hi um around eight months

00:25:22,559 --> 00:25:26,080
ago hamza introduced to pony code a new

00:25:24,880 --> 00:25:29,360
format that he called

00:25:26,080 --> 00:25:30,960
ml inspiration so every week hamza holds

00:25:29,360 --> 00:25:32,320
a 30 minutes presentation about a

00:25:30,960 --> 00:25:34,559
machine learning topic

00:25:32,320 --> 00:25:35,679
of his choice for the benefit of the

00:25:34,559 --> 00:25:37,760
whole team so

00:25:35,679 --> 00:25:38,960
developers data scientists marketing

00:25:37,760 --> 00:25:41,120
team sales

00:25:38,960 --> 00:25:42,000
anything and that's 20 minutes of

00:25:41,120 --> 00:25:45,200
presentation plus

00:25:42,000 --> 00:25:47,200
10 minutes of q a and i am

00:25:45,200 --> 00:25:48,640
always there um so we actually thought

00:25:47,200 --> 00:25:49,120
it would be cool for me to try and give

00:25:48,640 --> 00:25:52,400
back

00:25:49,120 --> 00:25:53,279
um and make a talk inspired by hamza's

00:25:52,400 --> 00:25:55,039
presentation

00:25:53,279 --> 00:25:56,480
and explain kind of the concepts that i

00:25:55,039 --> 00:25:59,600
learned from him

00:25:56,480 --> 00:26:01,039
um but machine learning's inspiration is

00:25:59,600 --> 00:26:02,559
so loved at pony code that we thought

00:26:01,039 --> 00:26:03,679
we'd actually share a little bit more

00:26:02,559 --> 00:26:05,679
about the format

00:26:03,679 --> 00:26:07,440
uh that might inspire some of you to do

00:26:05,679 --> 00:26:08,320
the same and there is no better person

00:26:07,440 --> 00:26:11,440
to do so than

00:26:08,320 --> 00:26:13,760
hamza himself so hamza can you tell us

00:26:11,440 --> 00:26:14,720
how the idea came about and why you

00:26:13,760 --> 00:26:18,960
decided to start

00:26:14,720 --> 00:26:21,120
ml inspiration i think we could say it

00:26:18,960 --> 00:26:21,760
started with a bit of frustration in a

00:26:21,120 --> 00:26:24,080
sense

00:26:21,760 --> 00:26:25,600
the tech team match pony code is made up

00:26:24,080 --> 00:26:27,840
of an equal number of

00:26:25,600 --> 00:26:30,400
developers and data scientists who have

00:26:27,840 --> 00:26:32,720
very different backgrounds and expertise

00:26:30,400 --> 00:26:35,279
i noticed the communication between the

00:26:32,720 --> 00:26:37,760
two was not always easy

00:26:35,279 --> 00:26:38,559
lots of things were being lost shall we

00:26:37,760 --> 00:26:41,120
say in

00:26:38,559 --> 00:26:42,080
translation and often i think we

00:26:41,120 --> 00:26:44,159
suffered from

00:26:42,080 --> 00:26:45,440
not having the same vocabulary and

00:26:44,159 --> 00:26:48,880
knowledge on certain

00:26:45,440 --> 00:26:50,799
specific topics you know they say

00:26:48,880 --> 00:26:52,559
that in a conversation there is always a

00:26:50,799 --> 00:26:55,360
distance between

00:26:52,559 --> 00:26:56,320
what i want to say what i say what i

00:26:55,360 --> 00:26:59,200
what you hear

00:26:56,320 --> 00:27:00,799
and what you understand and the

00:26:59,200 --> 00:27:01,919
difference between them can be

00:27:00,799 --> 00:27:04,159
significant

00:27:01,919 --> 00:27:06,400
i figured that we need to reduce this

00:27:04,159 --> 00:27:09,279
gap in order to work together well

00:27:06,400 --> 00:27:11,120
and know and i know that my machine

00:27:09,279 --> 00:27:11,919
learning knowledge comes from years of

00:27:11,120 --> 00:27:13,919
study

00:27:11,919 --> 00:27:15,360
so i shouldn't really expect others to

00:27:13,919 --> 00:27:18,240
understand immediately

00:27:15,360 --> 00:27:20,399
when i speak about something technical i

00:27:18,240 --> 00:27:22,799
watch a lot of videos on youtube

00:27:20,399 --> 00:27:23,919
and i'm a big fan of scientific

00:27:22,799 --> 00:27:26,720
vulgarization

00:27:23,919 --> 00:27:29,120
so i figured i try to apply it myself to

00:27:26,720 --> 00:27:33,039
bridge this gap between data scientists

00:27:29,120 --> 00:27:35,279
and developers at punycode

00:27:33,039 --> 00:27:38,559
um that's really really interesting and

00:27:35,279 --> 00:27:41,360
how do you prepare for it then

00:27:38,559 --> 00:27:42,399
i'm really passionate about what i do

00:27:41,360 --> 00:27:45,360
and because of this

00:27:42,399 --> 00:27:46,240
i end up speaking to lots of people

00:27:45,360 --> 00:27:48,880
about it

00:27:46,240 --> 00:27:51,200
and it frustrates me when i want to

00:27:48,880 --> 00:27:55,120
communicate an idea

00:27:51,200 --> 00:27:55,120
uh that i find fascinating

00:27:55,279 --> 00:27:58,960
so uh

00:27:59,120 --> 00:28:06,000
so i do this often and i know the points

00:28:03,039 --> 00:28:07,760
where people block directly and i

00:28:06,000 --> 00:28:10,480
reflect on it a lot

00:28:07,760 --> 00:28:12,559
and try to find analogies and tangible

00:28:10,480 --> 00:28:13,279
examples that can make the concept more

00:28:12,559 --> 00:28:15,679
clear

00:28:13,279 --> 00:28:16,799
so in reality the larger part of my

00:28:15,679 --> 00:28:20,559
preparation

00:28:16,799 --> 00:28:23,600
is done in this informal context with my

00:28:20,559 --> 00:28:26,960
friends and people i

00:28:23,600 --> 00:28:28,799
and people i know but okay

00:28:26,960 --> 00:28:30,480
that's uh that's really really

00:28:28,799 --> 00:28:32,720
interesting so

00:28:30,480 --> 00:28:34,399
i know that i personally enjoyed all of

00:28:32,720 --> 00:28:37,120
the machine learning inspiration

00:28:34,399 --> 00:28:39,120
because i learned a lot of things but

00:28:37,120 --> 00:28:40,880
what improvement do you see in the team

00:28:39,120 --> 00:28:42,799
so far

00:28:40,880 --> 00:28:44,320
i'd say there were three effects i

00:28:42,799 --> 00:28:46,159
noticed first

00:28:44,320 --> 00:28:47,919
inspiration which i guess was the main

00:28:46,159 --> 00:28:50,880
goal of the the

00:28:47,919 --> 00:28:52,799
given the name i have had people come in

00:28:50,880 --> 00:28:56,000
to me with new ideas

00:28:52,799 --> 00:28:58,080
inspired by my presentations second

00:28:56,000 --> 00:28:59,840
communication between devs and data

00:28:58,080 --> 00:29:02,799
scientists has been more fluid

00:28:59,840 --> 00:29:04,559
many cases we know can use words from

00:29:02,799 --> 00:29:05,120
the machine learning dictionary without

00:29:04,559 --> 00:29:07,679
fear

00:29:05,120 --> 00:29:09,600
of being misinterpreted and it happened

00:29:07,679 --> 00:29:12,559
a lot less to waste time

00:29:09,600 --> 00:29:14,159
debating semantics like before and

00:29:12,559 --> 00:29:17,200
finally i actually think

00:29:14,159 --> 00:29:20,320
that it has bounced back and inspired us

00:29:17,200 --> 00:29:21,120
data scientists because during the q a

00:29:20,320 --> 00:29:23,600
part

00:29:21,120 --> 00:29:25,279
developers often make comments and ask

00:29:23,600 --> 00:29:28,559
questions on our domain

00:29:25,279 --> 00:29:29,440
which is code which in many cases had

00:29:28,559 --> 00:29:32,720
maybe

00:29:29,440 --> 00:29:37,600
have made us realize new things

00:29:32,720 --> 00:29:39,840
and think about other approaches

00:29:37,600 --> 00:29:41,440
and what do you think that um other

00:29:39,840 --> 00:29:41,760
teams that might be watching us right

00:29:41,440 --> 00:29:44,960
now

00:29:41,760 --> 00:29:44,960
or can take from this

00:29:45,360 --> 00:29:49,039
i'd say that whenever there are

00:29:47,120 --> 00:29:50,880
different expertise that work closely

00:29:49,039 --> 00:29:53,039
together especially when topics

00:29:50,880 --> 00:29:54,159
are technical miscommunication and

00:29:53,039 --> 00:29:57,360
misinterpretation

00:29:54,159 --> 00:29:59,360
are always big risks so this format of

00:29:57,360 --> 00:30:00,159
scientific vulgarization can definitely

00:29:59,360 --> 00:30:03,760
be adapted

00:30:00,159 --> 00:30:06,080
and would be very beneficial

00:30:03,760 --> 00:30:08,000
thank you very much um guys i hope this

00:30:06,080 --> 00:30:10,080
was of itself inspiring for at least

00:30:08,000 --> 00:30:13,279
some of you

00:30:10,080 --> 00:30:21,840
if you have any questions contact us

00:30:13,279 --> 00:30:21,840

YouTube URL: https://www.youtube.com/watch?v=bPTCKd-gJjg


