Title: Applying the GitHub security development lifecycle to your project - GitHub Universe 2019
Publication date: 2019-12-13
Playlist: GitHub Universe 2019 - GitHub Product Updates
Description: 
	Presented by Justin Hutchings, Senior Product Manager, GitHub

Software security is hard! In this talk, we will review the causes of major software security incidents, and how they could have been mitigated. Then, you will learn about the how adopting a security development lifecycle is the best way to protect your projects and learn specific security practices.

About GitHub Universe:
GitHub Universe is a two-day conference dedicated to the creativity and curiosity of the largest software community in the world. Sessions cover topics from team culture to open source software across industries and technologies.

For more information on GitHub Universe, check the website:
https://githubuniverse.com
Captions: 
	00:00:00,680 --> 00:00:18,929
[Music]

00:00:19,100 --> 00:00:24,619
so I hope nobody's burned out on

00:00:21,590 --> 00:00:28,099
security I know we just hit that hard we

00:00:24,619 --> 00:00:30,410
talked a lot about security so today

00:00:28,099 --> 00:00:33,110
what I want to do is tell the security

00:00:30,410 --> 00:00:35,120
story in a slightly different way I want

00:00:33,110 --> 00:00:38,059
to talk about a security development

00:00:35,120 --> 00:00:41,090
lifecycle and today I hope to convince

00:00:38,059 --> 00:00:43,690
you that there's no set of tools you can

00:00:41,090 --> 00:00:46,790
buy that's gonna make you secure

00:00:43,690 --> 00:00:47,930
security is a human problem and we're

00:00:46,790 --> 00:00:50,120
gonna talk about some of the ways that

00:00:47,930 --> 00:00:51,770
you can integrate that into your

00:00:50,120 --> 00:00:55,250
development process to be more

00:00:51,770 --> 00:00:56,989
successful going forward so my name is

00:00:55,250 --> 00:00:59,390
Justin Hutchings I'm a product manager

00:00:56,989 --> 00:01:01,340
at github I've worked on a lot of the

00:00:59,390 --> 00:01:04,699
features that you saw Jamie and crew

00:01:01,340 --> 00:01:07,910
demo earlier and you know my background

00:01:04,699 --> 00:01:10,039
has been a software product manager for

00:01:07,910 --> 00:01:12,590
a long time I've worked in organizations

00:01:10,039 --> 00:01:14,450
of varying levels of security

00:01:12,590 --> 00:01:18,380
consciousness and one of the things I've

00:01:14,450 --> 00:01:22,490
seen is that that security is often an

00:01:18,380 --> 00:01:25,850
afterthought even great organizations

00:01:22,490 --> 00:01:30,229
often have to be reminded that security

00:01:25,850 --> 00:01:32,750
is the existential threat for every one

00:01:30,229 --> 00:01:34,790
of our products doesn't matter how good

00:01:32,750 --> 00:01:38,829
your features are it doesn't matter how

00:01:34,790 --> 00:01:43,369
clean your UI is if no one trusts you

00:01:38,829 --> 00:01:47,180
and so I thought sort of long and hard

00:01:43,369 --> 00:01:49,369
about what message I wanted you to take

00:01:47,180 --> 00:01:53,030
away here and so I threw the the word

00:01:49,369 --> 00:01:54,770
soup here on the screen to try and

00:01:53,030 --> 00:01:57,829
figure out like which one of these

00:01:54,770 --> 00:01:59,210
catchphrases we should go for you've

00:01:57,829 --> 00:02:00,740
probably seen these in the marketing

00:01:59,210 --> 00:02:02,450
material from like half a dozen

00:02:00,740 --> 00:02:08,660
companies out on the show floor right

00:02:02,450 --> 00:02:11,500
shift left or defense-in-depth I I sort

00:02:08,660 --> 00:02:15,680
of created one that that was new here

00:02:11,500 --> 00:02:18,950
there it is you can't wave a magic wand

00:02:15,680 --> 00:02:22,850
and be secure that's just not something

00:02:18,950 --> 00:02:24,560
you can do you need security to become a

00:02:22,850 --> 00:02:27,220
comprehensive part of your software

00:02:24,560 --> 00:02:27,220
development lifecycle

00:02:29,420 --> 00:02:34,140
and so today I'm gonna tell you about

00:02:31,830 --> 00:02:35,849
three different things I'm gonna tell

00:02:34,140 --> 00:02:38,099
you about some past security incidents

00:02:35,849 --> 00:02:40,530
I'm gonna try and demonstrate to you

00:02:38,099 --> 00:02:42,660
that it didn't matter how sophisticated

00:02:40,530 --> 00:02:45,239
their tooling was I want to demonstrate

00:02:42,660 --> 00:02:47,390
to you that security incidents can

00:02:45,239 --> 00:02:49,590
happen to any one of you in the room

00:02:47,390 --> 00:02:52,170
we'll talk about what the security

00:02:49,590 --> 00:02:53,880
development lifecycle is and then

00:02:52,170 --> 00:02:56,190
recommend some specific practices that

00:02:53,880 --> 00:02:58,830
everyone can take back and implement in

00:02:56,190 --> 00:03:00,870
your organization to protect you from

00:02:58,830 --> 00:03:06,660
the common kinds of security issues that

00:03:00,870 --> 00:03:09,590
you might encounter so I'm going to talk

00:03:06,660 --> 00:03:13,739
about three security incidents today

00:03:09,590 --> 00:03:15,599
I've redacted the names and I've done so

00:03:13,739 --> 00:03:17,660
because any of these incidents could

00:03:15,599 --> 00:03:21,989
have happened to anyone in the room

00:03:17,660 --> 00:03:25,440
there's nothing special about these

00:03:21,989 --> 00:03:27,540
incidents or about these companies that

00:03:25,440 --> 00:03:30,269
any one of us would have been vulnerable

00:03:27,540 --> 00:03:37,019
or immune to and so let's go through

00:03:30,269 --> 00:03:39,840
those first I want to talk briefly maybe

00:03:37,019 --> 00:03:41,700
there it goes first I'll talk about an

00:03:39,840 --> 00:03:45,180
issue that happened with a financial

00:03:41,700 --> 00:03:47,370
company and you know this is a really

00:03:45,180 --> 00:03:49,290
interesting one because there was a

00:03:47,370 --> 00:03:51,569
hostile actor and they went fishing for

00:03:49,290 --> 00:03:53,370
credentials so they're sending emails

00:03:51,569 --> 00:03:55,620
into the organization and seeing if they

00:03:53,370 --> 00:03:57,780
can get anyone to bite they got one

00:03:55,620 --> 00:04:00,510
person to bite they provided their

00:03:57,780 --> 00:04:04,590
password and their username and they

00:04:00,510 --> 00:04:06,690
installed some malware now this problem

00:04:04,590 --> 00:04:10,500
was compounded because once they had

00:04:06,690 --> 00:04:12,540
access to that users credentials that

00:04:10,500 --> 00:04:17,880
user had a VPN that got onto the

00:04:12,540 --> 00:04:19,799
production network and so with those

00:04:17,880 --> 00:04:21,000
credentials they had and the

00:04:19,799 --> 00:04:23,789
vulnerability you can see they went

00:04:21,000 --> 00:04:25,680
searching through the network to see if

00:04:23,789 --> 00:04:26,310
they could find anyone that they could

00:04:25,680 --> 00:04:29,340
get into

00:04:26,310 --> 00:04:31,760
they found one server that didn't

00:04:29,340 --> 00:04:34,020
require two-factor authentication and

00:04:31,760 --> 00:04:37,289
with that they were able to get access

00:04:34,020 --> 00:04:38,430
to the production database and these are

00:04:37,289 --> 00:04:40,830
the sorts of things that can happen to

00:04:38,430 --> 00:04:42,120
anyone it was a configuration issue one

00:04:40,830 --> 00:04:44,760
user made a mistake

00:04:42,120 --> 00:04:49,620
and then one developer made a

00:04:44,760 --> 00:04:51,900
configuration issue and so the origin

00:04:49,620 --> 00:04:56,130
here was a phishing attack some malware

00:04:51,900 --> 00:04:59,460
on a PC pedestrian stuff the escalation

00:04:56,130 --> 00:05:00,840
we had a VPN with production access it

00:04:59,460 --> 00:05:03,150
didn't do health checks I didn't find

00:05:00,840 --> 00:05:08,010
the malware two-factor authentication

00:05:03,150 --> 00:05:09,540
was missed on one minor server and then

00:05:08,010 --> 00:05:12,690
you know they they didn't have the data

00:05:09,540 --> 00:05:17,669
security to isolate that database from

00:05:12,690 --> 00:05:19,560
those lower security services ultimately

00:05:17,669 --> 00:05:21,780
what ended up happening is more than 70

00:05:19,560 --> 00:05:25,260
million accounts were breached and it

00:05:21,780 --> 00:05:28,500
costs the company 10 billion dollars for

00:05:25,260 --> 00:05:31,320
a phishing attack let's do another one

00:05:28,500 --> 00:05:34,080
it's not special sorry we'll talk about

00:05:31,320 --> 00:05:34,800
mitigation so in this one there are a

00:05:34,080 --> 00:05:38,280
number of things we could have done

00:05:34,800 --> 00:05:40,889
obviously more user training helps

00:05:38,280 --> 00:05:43,470
prevent phishing not everyone is an

00:05:40,889 --> 00:05:46,470
engineer not everyone as sort of the

00:05:43,470 --> 00:05:48,270
security spidey sense and so having that

00:05:46,470 --> 00:05:51,360
phishing training is really important

00:05:48,270 --> 00:05:53,100
and then if you get fished do you have a

00:05:51,360 --> 00:05:55,770
reporting process in your organization

00:05:53,100 --> 00:05:58,349
so that people can let your Incident

00:05:55,770 --> 00:06:00,180
Response Team know that someone tried to

00:05:58,349 --> 00:06:02,639
fish you so that someone that might not

00:06:00,180 --> 00:06:03,900
be as security conscious maybe could be

00:06:02,639 --> 00:06:07,110
protected because they found out about

00:06:03,900 --> 00:06:09,240
an attempted phishing attack obviously

00:06:07,110 --> 00:06:11,220
anti-malware scanning especially on

00:06:09,240 --> 00:06:14,520
machines that have access to prod that

00:06:11,220 --> 00:06:16,080
that could have helped if they threat

00:06:14,520 --> 00:06:17,280
modeled all their servers they might

00:06:16,080 --> 00:06:20,310
have found that they had the one that

00:06:17,280 --> 00:06:22,770
was missing to a PHA and of course

00:06:20,310 --> 00:06:24,210
monitoring once the user was in the

00:06:22,770 --> 00:06:26,280
system you know there were all these

00:06:24,210 --> 00:06:28,349
errant network calls trying to find a

00:06:26,280 --> 00:06:30,780
server that would work without to a PHA

00:06:28,349 --> 00:06:33,210
at all these login attempts that failed

00:06:30,780 --> 00:06:34,620
because I'm gonna assume the user didn't

00:06:33,210 --> 00:06:37,500
click the approve button on the to FA

00:06:34,620 --> 00:06:41,210
prompt those should have triggered on so

00:06:37,500 --> 00:06:41,210
many of things and they didn't

00:06:42,180 --> 00:06:48,060
so look at another company call this one

00:06:43,710 --> 00:06:49,710
credit company this is gonna maybe seem

00:06:48,060 --> 00:06:51,590
a little familiar for you you've got a

00:06:49,710 --> 00:06:56,420
huge server farm you've got tons of

00:06:51,590 --> 00:06:56,420
microservices tons of instances and

00:06:56,570 --> 00:07:02,070
we're all using open source in our

00:06:58,650 --> 00:07:03,780
supply chain you may remember back there

00:07:02,070 --> 00:07:06,410
was a particular open source

00:07:03,780 --> 00:07:08,790
vulnerability that allowed pretty easy

00:07:06,410 --> 00:07:11,610
remote code execution from a network

00:07:08,790 --> 00:07:13,320
endpoint this company knew they had a

00:07:11,610 --> 00:07:15,180
great monitoring system in place there

00:07:13,320 --> 00:07:17,550
their security team let everyone know

00:07:15,180 --> 00:07:20,010
there's this problem they told everybody

00:07:17,550 --> 00:07:23,790
go patch this is a big vulnerability

00:07:20,010 --> 00:07:25,560
they sent the emails to everyone the

00:07:23,790 --> 00:07:28,260
owner of one of the servers didn't see

00:07:25,560 --> 00:07:32,220
the email he didn't patch the server and

00:07:28,260 --> 00:07:34,980
no one followed up and so an outside

00:07:32,220 --> 00:07:37,320
user went poking around to see if they

00:07:34,980 --> 00:07:38,850
could find any networks or any endpoints

00:07:37,320 --> 00:07:41,220
in the network that had that

00:07:38,850 --> 00:07:43,920
vulnerability it had a very identifiable

00:07:41,220 --> 00:07:45,030
network pattern and so they found it now

00:07:43,920 --> 00:07:49,470
they're in they've got a foot in the

00:07:45,030 --> 00:07:51,540
door and from there what they what they

00:07:49,470 --> 00:07:53,580
found was that the monitoring systems

00:07:51,540 --> 00:07:56,670
were offline so they had a remote code

00:07:53,580 --> 00:07:59,580
execution system and this company had a

00:07:56,670 --> 00:08:01,770
great security system they purchased but

00:07:59,580 --> 00:08:04,080
all the SSL certs for that security

00:08:01,770 --> 00:08:05,250
system were expired so all the traffic

00:08:04,080 --> 00:08:07,290
that happened in the datacenter was

00:08:05,250 --> 00:08:10,170
encrypted they couldn't tell what it was

00:08:07,290 --> 00:08:12,840
doing and so they were effectively blind

00:08:10,170 --> 00:08:14,460
in the organization this one gets better

00:08:12,840 --> 00:08:18,810
though because there's another common

00:08:14,460 --> 00:08:21,060
mistake one of the servers had plaintext

00:08:18,810 --> 00:08:23,640
credentials on it and eventually that

00:08:21,060 --> 00:08:28,260
user from scanning the network found

00:08:23,640 --> 00:08:30,710
those credentials brought them back and

00:08:28,260 --> 00:08:32,730
then used those to access the database

00:08:30,710 --> 00:08:35,460
once they got into the database they

00:08:32,730 --> 00:08:37,650
managed to get you know to scan 48

00:08:35,460 --> 00:08:39,510
different databases they found a whole

00:08:37,650 --> 00:08:41,580
bunch of valuable data ultimately they

00:08:39,510 --> 00:08:45,720
were in the network for 78 days without

00:08:41,580 --> 00:08:51,960
being detected so what was the origin

00:08:45,720 --> 00:08:53,850
here one unpatched server and then no

00:08:51,960 --> 00:08:55,620
one was caught because the network

00:08:53,850 --> 00:08:57,570
monitoring wasn't working

00:08:55,620 --> 00:09:00,180
and then they had that plane touch text

00:08:57,570 --> 00:09:04,040
credential cash that was leveraged for

00:09:00,180 --> 00:09:06,360
an EOP this cost them a hundred million

00:09:04,040 --> 00:09:10,440
accounts and more than five billion in

00:09:06,360 --> 00:09:12,150
financial damage and I think all of you

00:09:10,440 --> 00:09:14,430
are probably thinking there are so many

00:09:12,150 --> 00:09:17,550
servers I have do I know if they're all

00:09:14,430 --> 00:09:24,480
patched do I know that no one checked in

00:09:17,550 --> 00:09:25,500
a honey pot full of credentials so what

00:09:24,480 --> 00:09:28,350
are the mitigations here

00:09:25,500 --> 00:09:29,790
well obviously better monitoring you

00:09:28,350 --> 00:09:32,550
know jamie talked earlier today about

00:09:29,790 --> 00:09:34,710
how you know we're offering some tools

00:09:32,550 --> 00:09:37,250
for for open source Vil dependency

00:09:34,710 --> 00:09:40,230
management you should be using something

00:09:37,250 --> 00:09:42,930
for this you've also got to make sure

00:09:40,230 --> 00:09:45,920
that you have a process in place to deal

00:09:42,930 --> 00:09:48,600
with everyday things like expiring

00:09:45,920 --> 00:09:51,360
certificates you know maintaining your

00:09:48,600 --> 00:09:54,720
servers doing service health obviously

00:09:51,360 --> 00:09:56,339
threat modeling if if they had gone and

00:09:54,720 --> 00:09:58,470
found that they didn't have a credential

00:09:56,339 --> 00:10:00,230
store there was a plain text place that

00:09:58,470 --> 00:10:02,430
everyone was pulling their creds from

00:10:00,230 --> 00:10:04,529
that would have been identified during a

00:10:02,430 --> 00:10:07,760
threat model and then pen testers would

00:10:04,529 --> 00:10:07,760
have had a heyday with all of this

00:10:08,300 --> 00:10:12,839
finally I want to talk about one and

00:10:10,260 --> 00:10:15,510
this one's a favorite of mine because it

00:10:12,839 --> 00:10:18,240
actually used part of a platform I

00:10:15,510 --> 00:10:21,110
worked on story time here is I used to

00:10:18,240 --> 00:10:22,920
work on print drivers of all things

00:10:21,110 --> 00:10:27,060
sexiest technology in the world

00:10:22,920 --> 00:10:27,870
everybody used print drivers yeah so one

00:10:27,060 --> 00:10:32,580
of the things that's really interesting

00:10:27,870 --> 00:10:36,740
about Windows is print servers are a

00:10:32,580 --> 00:10:38,970
software distribution endpoint IT

00:10:36,740 --> 00:10:40,260
administrators hate this because why

00:10:38,970 --> 00:10:42,120
would you distribute software from a

00:10:40,260 --> 00:10:46,230
print server but it's something that

00:10:42,120 --> 00:10:47,880
happens and so the the Stuxnet worm was

00:10:46,230 --> 00:10:50,370
a really interesting one this happened

00:10:47,880 --> 00:10:53,580
ages ago and I'm not gonna redact this

00:10:50,370 --> 00:10:57,390
one because it's super fun but uh this

00:10:53,580 --> 00:11:00,180
was a case where we had a couple of as

00:10:57,390 --> 00:11:02,339
yet unknown state-sponsored actors and

00:11:00,180 --> 00:11:05,459
they had a target system that they

00:11:02,339 --> 00:11:07,200
wanted to breach in this case you can

00:11:05,459 --> 00:11:09,620
see our our fun little nuclear icon

00:11:07,200 --> 00:11:13,010
there they wanted to get to

00:11:09,620 --> 00:11:15,860
a collection of industrial machines made

00:11:13,010 --> 00:11:17,780
by Simmons and those machines were

00:11:15,860 --> 00:11:22,310
centrifuges that are being used for

00:11:17,780 --> 00:11:23,900
nuclear enrichment in Iran and so they

00:11:22,310 --> 00:11:28,970
knew their their adversary was

00:11:23,900 --> 00:11:32,840
air-gapped and so they had engineered a

00:11:28,970 --> 00:11:37,100
system to automatically replicate on a

00:11:32,840 --> 00:11:39,410
network and propagate by any USB key so

00:11:37,100 --> 00:11:41,450
let's see what that looks like so you

00:11:39,410 --> 00:11:44,140
can see the net the vulnerability once

00:11:41,450 --> 00:11:46,220
introduced propagates on the network and

00:11:44,140 --> 00:11:49,820
then if there are any attached USB

00:11:46,220 --> 00:11:51,620
devices it'll jump onto that and infect

00:11:49,820 --> 00:11:54,710
those machines as well and in fact those

00:11:51,620 --> 00:11:58,070
networks once it's on a network that has

00:11:54,710 --> 00:12:00,070
one of those Simmons centrifuges it

00:11:58,070 --> 00:12:05,360
tells it to spin out of control and

00:12:00,070 --> 00:12:07,700
eventually they explode now I'm giving

00:12:05,360 --> 00:12:10,790
you this example just as way of contrast

00:12:07,700 --> 00:12:12,710
the first two vulnerability are you know

00:12:10,790 --> 00:12:17,240
incidents we talked about super

00:12:12,710 --> 00:12:22,400
pedestrian this one wasn't you know we

00:12:17,240 --> 00:12:25,610
ended up with we ended up with there it

00:12:22,400 --> 00:12:29,060
is we ended up with four unique zero

00:12:25,610 --> 00:12:30,770
days on Windows as well as a compromised

00:12:29,060 --> 00:12:34,060
trusted cert that allowed the software

00:12:30,770 --> 00:12:39,470
to propagate without any install prompts

00:12:34,060 --> 00:12:42,320
it expanded itself by infecting devices

00:12:39,470 --> 00:12:45,830
via the network as well as using USB

00:12:42,320 --> 00:12:49,070
devices to jump an air gap it infected

00:12:45,830 --> 00:12:52,480
about 200,000 computers and destroyed 20

00:12:49,070 --> 00:12:54,980
percent of the Iranian nuclear program

00:12:52,480 --> 00:12:57,290
and so that was a very specific attack

00:12:54,980 --> 00:13:00,740
from a very motivated attacker with

00:12:57,290 --> 00:13:03,830
extreme capabilities and you think about

00:13:00,740 --> 00:13:05,420
the mitigation here I guess they could

00:13:03,830 --> 00:13:08,420
have stuffed their workstations ports

00:13:05,420 --> 00:13:11,630
with epoxy this isn't what you're

00:13:08,420 --> 00:13:13,100
defending against the majority of

00:13:11,630 --> 00:13:16,370
attackers that want to do financial

00:13:13,100 --> 00:13:18,590
damage that want to get information that

00:13:16,370 --> 00:13:21,320
they can sell on the black market on the

00:13:18,590 --> 00:13:23,540
dark web as it were they're not gonna

00:13:21,320 --> 00:13:26,839
jump think design things to jump

00:13:23,540 --> 00:13:28,730
and the amount of effort that you're

00:13:26,839 --> 00:13:32,480
gonna spend to build an aircraft Network

00:13:28,730 --> 00:13:35,540
and you know build out this culture

00:13:32,480 --> 00:13:38,839
where there's such a stuffy sense of

00:13:35,540 --> 00:13:41,720
security you're going to kill all of

00:13:38,839 --> 00:13:43,850
your innovation that's not your risk

00:13:41,720 --> 00:13:47,779
factor the other things are the

00:13:43,850 --> 00:13:50,449
low-hanging fruit and so what did we see

00:13:47,779 --> 00:13:52,639
across all of these obviously there's

00:13:50,449 --> 00:13:54,680
human error here human error is the

00:13:52,639 --> 00:13:57,500
number one source of security

00:13:54,680 --> 00:13:59,000
vulnerabilities we also see the limited

00:13:57,500 --> 00:14:01,699
threat modeling and this is really a

00:13:59,000 --> 00:14:04,730
social process for how we engineer

00:14:01,699 --> 00:14:06,910
software with security in mind of course

00:14:04,730 --> 00:14:10,459
insecure development practices and

00:14:06,910 --> 00:14:12,860
ineffective validation made it worse if

00:14:10,459 --> 00:14:15,139
we had the right pen testers for using

00:14:12,860 --> 00:14:16,490
great static analysis tooling any one of

00:14:15,139 --> 00:14:20,089
these vulnerabilities might have been

00:14:16,490 --> 00:14:22,760
detected and then finally you think

00:14:20,089 --> 00:14:25,760
about this whole assume breach if you

00:14:22,760 --> 00:14:26,930
don't have monitoring you can assume

00:14:25,760 --> 00:14:31,160
they're in your network all day long

00:14:26,930 --> 00:14:33,949
you're never gonna know and so I hope at

00:14:31,160 --> 00:14:37,639
this point I've convinced you your

00:14:33,949 --> 00:14:39,500
security threats aren't state-sponsored

00:14:37,639 --> 00:14:41,269
actors that are gonna jump air gaps and

00:14:39,500 --> 00:14:43,730
go attack you to blow up all your

00:14:41,269 --> 00:14:45,319
equipment they're financially motivated

00:14:43,730 --> 00:14:47,149
hackers that are gonna find the

00:14:45,319 --> 00:14:51,709
low-hanging fruit because there's a lot

00:14:47,149 --> 00:14:53,680
of it and so what I want to do is shift

00:14:51,709 --> 00:14:56,089
to the positive part of the talk and

00:14:53,680 --> 00:14:57,769
talk about why you should add a security

00:14:56,089 --> 00:15:01,670
development lifecycle to your software

00:14:57,769 --> 00:15:03,350
development lifecycle and I'm gonna

00:15:01,670 --> 00:15:04,370
mirror sort of the the pattern that I

00:15:03,350 --> 00:15:06,880
showed in terms of the common problems

00:15:04,370 --> 00:15:10,670
with the solutions to those problems so

00:15:06,880 --> 00:15:13,940
you start with training humans are a

00:15:10,670 --> 00:15:16,550
weak link they operate unpredictably and

00:15:13,940 --> 00:15:17,440
if they're not educated they will do bad

00:15:16,550 --> 00:15:21,380
things

00:15:17,440 --> 00:15:22,610
not intentionally obviously you also

00:15:21,380 --> 00:15:25,569
have to make sure that you integrate

00:15:22,610 --> 00:15:29,260
security design into your software as

00:15:25,569 --> 00:15:31,190
well as secure development practices

00:15:29,260 --> 00:15:33,529
we'll also talk about verification

00:15:31,190 --> 00:15:36,260
techniques that you can use and then

00:15:33,529 --> 00:15:37,520
finally monitoring in response because

00:15:36,260 --> 00:15:40,970
security incidents will

00:15:37,520 --> 00:15:42,650
every one of us in this room will be

00:15:40,970 --> 00:15:43,580
part of an incident response at some

00:15:42,650 --> 00:15:46,610
point in our lives

00:15:43,580 --> 00:15:48,530
and so having the process to respond to

00:15:46,610 --> 00:15:50,710
it makes your life a lot easier going

00:15:48,530 --> 00:15:53,000
forward

00:15:50,710 --> 00:15:55,910
alright so training this is the boring

00:15:53,000 --> 00:15:57,560
one right everyone goes ugh like

00:15:55,910 --> 00:16:00,520
training sure sure

00:15:57,560 --> 00:16:03,170
and and you know I want to start like

00:16:00,520 --> 00:16:04,430
yes you need to do things like account

00:16:03,170 --> 00:16:06,740
security training you've got to tell

00:16:04,430 --> 00:16:09,140
people you're being phished you need to

00:16:06,740 --> 00:16:10,400
use to FA you you want to make sure that

00:16:09,140 --> 00:16:14,420
you're communicating securely on

00:16:10,400 --> 00:16:17,420
security issues but you know let's let's

00:16:14,420 --> 00:16:19,240
go to even a more basic thing does your

00:16:17,420 --> 00:16:23,330
team know what your security policy is

00:16:19,240 --> 00:16:26,240
do they know how to disclose a

00:16:23,330 --> 00:16:33,020
vulnerability to your customers do they

00:16:26,240 --> 00:16:34,970
know you know whether or not whether or

00:16:33,020 --> 00:16:37,070
not a service is maintained or supported

00:16:34,970 --> 00:16:39,050
do they know what kind of data they can

00:16:37,070 --> 00:16:42,310
put on servers do you have encryption

00:16:39,050 --> 00:16:44,510
policies that they should be respecting

00:16:42,310 --> 00:16:46,550
do you have threat modeling that you've

00:16:44,510 --> 00:16:48,230
trained people on we'll talk more about

00:16:46,550 --> 00:16:49,580
that in a bit

00:16:48,230 --> 00:16:51,400
does everyone know how to use the

00:16:49,580 --> 00:16:53,480
verification tools you've purchased

00:16:51,400 --> 00:16:55,040
everyone in this room has probably spent

00:16:53,480 --> 00:16:57,140
an inordinate amounts of money on

00:16:55,040 --> 00:16:59,210
software that will protect your systems

00:16:57,140 --> 00:17:01,190
but if your developers don't use it and

00:16:59,210 --> 00:17:03,590
don't know how it's not gonna get you a

00:17:01,190 --> 00:17:04,940
lot I mean then finally when there is an

00:17:03,590 --> 00:17:06,950
incident do people know how to respond

00:17:04,940 --> 00:17:08,780
do they know who to go to I'm at github

00:17:06,950 --> 00:17:12,230
we have a great thing we have the oh

00:17:08,780 --> 00:17:13,940
 alias when you screw up and having

00:17:12,230 --> 00:17:15,680
something like that we all laughed like

00:17:13,940 --> 00:17:17,209
when we're at the the orientation and

00:17:15,680 --> 00:17:18,890
they say yeah email oh we're not

00:17:17,209 --> 00:17:22,839
kidding but that's what it's called

00:17:18,890 --> 00:17:25,880
you'll never forget it because of that

00:17:22,839 --> 00:17:27,890
and you make it something where no one

00:17:25,880 --> 00:17:31,010
every github er knows this that's what

00:17:27,890 --> 00:17:34,130
you do and so when there's a phishing

00:17:31,010 --> 00:17:35,600
attack and you respond to it you did the

00:17:34,130 --> 00:17:39,170
wrong thing because it was really well

00:17:35,600 --> 00:17:44,090
done that's what you do and we protect

00:17:39,170 --> 00:17:46,430
each other if I haven't convinced you on

00:17:44,090 --> 00:17:48,440
why humans are your biggest risk I want

00:17:46,430 --> 00:17:51,830
to point to this this great tweet here

00:17:48,440 --> 00:17:53,780
from from Joe so there's an app on the

00:17:51,830 --> 00:17:55,990
Google Play Store I don't know why they

00:17:53,780 --> 00:17:58,610
published it this makes no sense to me

00:17:55,990 --> 00:18:02,950
it's an app that automatically accepts

00:17:58,610 --> 00:18:05,240
duo to FA pushes because some people go

00:18:02,950 --> 00:18:05,990
look security team you made this too

00:18:05,240 --> 00:18:07,640
hard for me

00:18:05,990 --> 00:18:10,490
I just can't be bothered to get my phone

00:18:07,640 --> 00:18:11,870
out of my pocket so this accepts it more

00:18:10,490 --> 00:18:14,390
than a thousand people have installed

00:18:11,870 --> 00:18:16,430
this thing the negative reviews are all

00:18:14,390 --> 00:18:19,580
from security people that go oh my don't

00:18:16,430 --> 00:18:22,450
please this is a terrible idea I know

00:18:19,580 --> 00:18:28,850
it's painful but please don't do this

00:18:22,450 --> 00:18:31,130
but your users are your biggest risk so

00:18:28,850 --> 00:18:33,020
let's talk about you know a design phase

00:18:31,130 --> 00:18:35,300
architecture review how many of you have

00:18:33,020 --> 00:18:38,330
an architecture review board anyone in

00:18:35,300 --> 00:18:39,710
the room phew okay how many of you do

00:18:38,330 --> 00:18:41,180
threat modeling and do the little data

00:18:39,710 --> 00:18:44,210
flow diagrams and what have you

00:18:41,180 --> 00:18:47,630
very few okay so you know I had a I had

00:18:44,210 --> 00:18:50,210
a developer I worked with ages ago and I

00:18:47,630 --> 00:18:52,730
was some like young out of college guy

00:18:50,210 --> 00:18:53,720
going through our our security practices

00:18:52,730 --> 00:18:55,280
and I'm like we got to do threat

00:18:53,720 --> 00:18:57,680
modeling he's like we're not gonna do

00:18:55,280 --> 00:19:00,350
that no no we have to do threat modeling

00:18:57,680 --> 00:19:02,660
it's it's really good I'll show you so I

00:19:00,350 --> 00:19:04,220
built this big data flow diagram to

00:19:02,660 --> 00:19:08,720
describe these legacy systems that had

00:19:04,220 --> 00:19:10,700
been in place for fifteen years and we

00:19:08,720 --> 00:19:12,860
found real vulnerabilities at the end of

00:19:10,700 --> 00:19:15,290
it he said I'm glad you made me do that

00:19:12,860 --> 00:19:16,970
they said I'm glad you did it because

00:19:15,290 --> 00:19:18,980
this is what we have to do we have to

00:19:16,970 --> 00:19:20,810
have the conversation about how these

00:19:18,980 --> 00:19:22,310
things work you know the types of

00:19:20,810 --> 00:19:25,600
vulnerabilities we were dealing with at

00:19:22,310 --> 00:19:28,340
the time were things like do we have

00:19:25,600 --> 00:19:31,190
insecure data stores how do we Akal down

00:19:28,340 --> 00:19:34,430
the data that we execute

00:19:31,190 --> 00:19:37,360
do we have data that we're running or

00:19:34,430 --> 00:19:41,510
parsing right do you do process images

00:19:37,360 --> 00:19:43,880
well there's a there's an AOP risk right

00:19:41,510 --> 00:19:47,090
there because if someone can break out

00:19:43,880 --> 00:19:49,460
of that image parsing code and overrun a

00:19:47,090 --> 00:19:51,290
buffer well all of a sudden you're

00:19:49,460 --> 00:19:52,760
you're now vulnerable and so you go

00:19:51,290 --> 00:19:55,280
through and you have to figure out what

00:19:52,760 --> 00:19:57,440
are your trust boundaries where are you

00:19:55,280 --> 00:19:58,100
accepting input where are you storing

00:19:57,440 --> 00:19:59,930
things

00:19:58,100 --> 00:20:01,970
how are you interacting between your

00:19:59,930 --> 00:20:03,560
micro services micro service based

00:20:01,970 --> 00:20:04,490
architecture by the way is one of the

00:20:03,560 --> 00:20:06,230
biggest

00:20:04,490 --> 00:20:08,210
boons and risks that I've ever seen

00:20:06,230 --> 00:20:09,740
because people will say I want to

00:20:08,210 --> 00:20:11,690
isolate all my things but then I give

00:20:09,740 --> 00:20:13,670
them full token access to everything and

00:20:11,690 --> 00:20:15,950
so now you have 50 different end points

00:20:13,670 --> 00:20:18,460
that you can talk to and if you find one

00:20:15,950 --> 00:20:22,640
that's over permissioned well you lost

00:20:18,460 --> 00:20:24,800
and so threat modeling and architecture

00:20:22,640 --> 00:20:26,690
review are amazing processes and I hope

00:20:24,800 --> 00:20:30,950
everyone adopts them as part of your

00:20:26,690 --> 00:20:32,000
flow once you get into development

00:20:30,950 --> 00:20:33,410
obviously you're gonna be writing your

00:20:32,000 --> 00:20:37,010
code you're gonna be doing the normal

00:20:33,410 --> 00:20:39,800
things you do but as you know as we've

00:20:37,010 --> 00:20:42,040
heard all week this week open source is

00:20:39,800 --> 00:20:45,050
an increasingly large part of

00:20:42,040 --> 00:20:46,400
development right do you know what open

00:20:45,050 --> 00:20:48,710
source you're using do you have an

00:20:46,400 --> 00:20:50,060
inventory and did the developers that

00:20:48,710 --> 00:20:53,060
brought it in tell you why they needed

00:20:50,060 --> 00:20:55,820
it because one of the biggest challenges

00:20:53,060 --> 00:20:57,200
you have is you bring in an open source

00:20:55,820 --> 00:20:58,610
dependency maybe you used it for a

00:20:57,200 --> 00:21:02,180
prototype you never got rid of it you

00:20:58,610 --> 00:21:04,610
you aren't using that that code path

00:21:02,180 --> 00:21:06,500
anymore for for production but you still

00:21:04,610 --> 00:21:09,920
have the vulnerabilities there because

00:21:06,500 --> 00:21:11,060
you've inherited all those things one of

00:21:09,920 --> 00:21:13,910
the things we do at github that I'm

00:21:11,060 --> 00:21:16,490
really excited about um we we do a

00:21:13,910 --> 00:21:18,980
security review and so for every feature

00:21:16,490 --> 00:21:20,870
that goes live we open an issue there's

00:21:18,980 --> 00:21:22,160
an issue template we fill it out and

00:21:20,870 --> 00:21:24,950
they ask us all these questions they're

00:21:22,160 --> 00:21:26,270
like do you accept user data do you use

00:21:24,950 --> 00:21:28,610
these particular architectural

00:21:26,270 --> 00:21:31,430
constructs where do you store things how

00:21:28,610 --> 00:21:33,230
do you audit and we go through this sort

00:21:31,430 --> 00:21:36,370
of social process with our security

00:21:33,230 --> 00:21:38,540
people and it's really important because

00:21:36,370 --> 00:21:41,540
you know they're not on the ground every

00:21:38,540 --> 00:21:42,890
day discussing what you did but they

00:21:41,540 --> 00:21:44,740
come through and they say who that that

00:21:42,890 --> 00:21:47,120
looks risky can I see your PRS and

00:21:44,740 --> 00:21:49,820
they'll go through and review the PRS

00:21:47,120 --> 00:21:53,000
and say ooh this right here we should

00:21:49,820 --> 00:21:55,130
probably change and when they tell you

00:21:53,000 --> 00:21:58,220
to change it that this may seem obvious

00:21:55,130 --> 00:22:01,130
or rudimentary do it like mitigate those

00:21:58,220 --> 00:22:03,380
things I even when you're doing

00:22:01,130 --> 00:22:05,570
conference different development you

00:22:03,380 --> 00:22:07,430
know you've got a deadline it's better

00:22:05,570 --> 00:22:10,370
to miss your conference than it is to

00:22:07,430 --> 00:22:12,710
ship and have someone up on you the next

00:22:10,370 --> 00:22:14,000
week right like all of your great press

00:22:12,710 --> 00:22:17,170
goes out the window the minute you get

00:22:14,000 --> 00:22:19,180
exploited and so take your time

00:22:17,170 --> 00:22:21,520
and make sure that security has the

00:22:19,180 --> 00:22:27,100
right to say no you can't ship until you

00:22:21,520 --> 00:22:29,830
fix these things verifying obviously

00:22:27,100 --> 00:22:31,090
this this ones later you know you think

00:22:29,830 --> 00:22:32,860
about the shift left paradigm right

00:22:31,090 --> 00:22:36,460
we're we're already after development

00:22:32,860 --> 00:22:38,800
we've maybe shipped some things you know

00:22:36,460 --> 00:22:42,130
how many of you use pen testing or

00:22:38,800 --> 00:22:44,850
employ a red team okay fair number good

00:22:42,130 --> 00:22:48,130
how many of you using static analysis

00:22:44,850 --> 00:22:50,950
more good good I like that

00:22:48,130 --> 00:22:53,320
and then fuzzing maybe maybe okay couple

00:22:50,950 --> 00:22:55,900
so you know the the key lessons that I

00:22:53,320 --> 00:22:57,520
think are here regardless of how good

00:22:55,900 --> 00:23:00,160
your practices are it's always good to

00:22:57,520 --> 00:23:01,480
have something double-check you cuz

00:23:00,160 --> 00:23:03,580
things slip through the cracks it's a

00:23:01,480 --> 00:23:05,590
big complicated world we all know how

00:23:03,580 --> 00:23:08,410
hard software is to write and these

00:23:05,590 --> 00:23:11,490
things help I'm not gonna you know

00:23:08,410 --> 00:23:15,040
belabor the point on static analysis

00:23:11,490 --> 00:23:17,850
fuzzing let's go into that briefly

00:23:15,040 --> 00:23:19,930
so fuzzing is an amazing thing in there

00:23:17,850 --> 00:23:21,730
it's a lot easier than it used to be

00:23:19,930 --> 00:23:25,810
there are a lot of open source tools out

00:23:21,730 --> 00:23:28,690
there that helped we used to have to

00:23:25,810 --> 00:23:32,740
take a well-known set of files and bit

00:23:28,690 --> 00:23:33,760
flip and do all these random things you

00:23:32,740 --> 00:23:35,500
don't have to do that anywhere there are

00:23:33,760 --> 00:23:38,350
tools that will help you with your

00:23:35,500 --> 00:23:40,810
fuzzing and help you figure out how to

00:23:38,350 --> 00:23:42,970
protect yourself and you should use them

00:23:40,810 --> 00:23:44,440
because they're an amazing way to

00:23:42,970 --> 00:23:48,990
protect yourself when you're parsing

00:23:44,440 --> 00:23:48,990
data or accepting input from any users

00:23:49,440 --> 00:23:56,440
alright let's jump ahead

00:23:51,220 --> 00:23:58,210
finally monitoring and responding so we

00:23:56,440 --> 00:23:59,500
talked all of those incidents we talked

00:23:58,210 --> 00:24:01,210
about could have been prevented with

00:23:59,500 --> 00:24:03,910
some monitoring some really good network

00:24:01,210 --> 00:24:07,540
monitoring some great open source

00:24:03,910 --> 00:24:10,540
dependency monitoring obviously you know

00:24:07,540 --> 00:24:12,490
as Jaime told you just last hour we've

00:24:10,540 --> 00:24:15,070
got the dependency graph dependency

00:24:12,490 --> 00:24:18,700
insights I hope everyone will use those

00:24:15,070 --> 00:24:21,700
they're free but you you also have to

00:24:18,700 --> 00:24:25,840
recognize what your inventory looks like

00:24:21,700 --> 00:24:27,640
if you're a C++ house we can't do much

00:24:25,840 --> 00:24:29,530
for you there are commercial products

00:24:27,640 --> 00:24:31,090
out there that can help and you may have

00:24:29,530 --> 00:24:34,539
to buy one

00:24:31,090 --> 00:24:37,659
or you know if you're primarily running

00:24:34,539 --> 00:24:38,919
you know you're primarily running

00:24:37,659 --> 00:24:41,500
systems where your vendor in your

00:24:38,919 --> 00:24:43,960
software do you have a process where you

00:24:41,500 --> 00:24:45,760
can monitor what you're actually using

00:24:43,960 --> 00:24:47,590
do you know what's vendor din do you

00:24:45,760 --> 00:24:51,580
know what the versions are do you know

00:24:47,590 --> 00:24:55,240
where they came from I remember when I

00:24:51,580 --> 00:24:56,860
worked on a previous team we had 15

00:24:55,240 --> 00:24:59,860
copies of one open source library

00:24:56,860 --> 00:25:01,720
checked into our mono repo there were

00:24:59,860 --> 00:25:03,730
different versions they had been forked

00:25:01,720 --> 00:25:05,139
because people had said ooh that one's

00:25:03,730 --> 00:25:08,230
really good but if I change this one

00:25:05,139 --> 00:25:09,580
method signature it's better and then

00:25:08,230 --> 00:25:11,590
when the vulnerabilities come out you go

00:25:09,580 --> 00:25:12,639
now I have to handwrite everything I

00:25:11,590 --> 00:25:14,590
have to go back and look at all these

00:25:12,639 --> 00:25:16,659
things and I've moved on to the next

00:25:14,590 --> 00:25:19,090
thing and so you've got to have a

00:25:16,659 --> 00:25:21,070
process to keep these things going to

00:25:19,090 --> 00:25:24,490
monitor the risks that are gonna be

00:25:21,070 --> 00:25:27,190
facing you going forward and then

00:25:24,490 --> 00:25:29,289
response of course does everyone have an

00:25:27,190 --> 00:25:32,590
incident response plan when you find a

00:25:29,289 --> 00:25:35,110
vulnerability how you respond to it from

00:25:32,590 --> 00:25:36,970
an engineering perspective from a an

00:25:35,110 --> 00:25:38,950
investigation perspective in terms of

00:25:36,970 --> 00:25:43,419
what the damage actually was how you

00:25:38,950 --> 00:25:44,980
disclose those things if you don't now's

00:25:43,419 --> 00:25:48,510
a great time there's no better time than

00:25:44,980 --> 00:25:51,669
now one of the things that github added

00:25:48,510 --> 00:25:53,139
earlier this year is a capability is the

00:25:51,669 --> 00:25:55,480
ability to describe a security policy

00:25:53,139 --> 00:25:56,590
Jamie showed that earlier and it's one

00:25:55,480 --> 00:25:58,990
of those things you know you think about

00:25:56,590 --> 00:26:02,080
the verification and you know hacker

00:25:58,990 --> 00:26:04,659
powered security telling people how to

00:26:02,080 --> 00:26:08,559
contact you when they find something

00:26:04,659 --> 00:26:11,289
he's so important I've gone to so many

00:26:08,559 --> 00:26:12,820
open-source projects and there's

00:26:11,289 --> 00:26:14,769
literally no way to contact them for

00:26:12,820 --> 00:26:17,289
security things I have had to post

00:26:14,769 --> 00:26:19,059
issues and say I am aware of a security

00:26:17,289 --> 00:26:20,620
thing will you please contact me at this

00:26:19,059 --> 00:26:23,350
email address so we don't disclose

00:26:20,620 --> 00:26:26,110
everything to people so give them a

00:26:23,350 --> 00:26:30,730
chance go to hacker 1 put up a secure

00:26:26,110 --> 00:26:32,980
email a box do something and then when

00:26:30,730 --> 00:26:35,730
you actually get to fixing things make

00:26:32,980 --> 00:26:38,440
sure you do it in a quiet place you know

00:26:35,730 --> 00:26:39,970
it wouldn't be appropriate for everyone

00:26:38,440 --> 00:26:42,820
in your organization to know you have a

00:26:39,970 --> 00:26:44,550
an unpatched security vulnerability and

00:26:42,820 --> 00:26:49,470
we talked about the human risk

00:26:44,550 --> 00:26:50,880
people talk have a policy in place for

00:26:49,470 --> 00:26:52,860
who gets to hear about these things

00:26:50,880 --> 00:26:55,530
who's involved in incident response

00:26:52,860 --> 00:26:59,630
who's in the tent as it were on these

00:26:55,530 --> 00:27:02,429
things and then finally publish the CVE

00:26:59,630 --> 00:27:04,950
this is one of the best ways that we can

00:27:02,429 --> 00:27:07,650
improve transparency and security across

00:27:04,950 --> 00:27:08,820
our ecosystem is to tell people when

00:27:07,650 --> 00:27:11,429
we've patched a security vulnerability

00:27:08,820 --> 00:27:13,890
and what has to happen it's not enough

00:27:11,429 --> 00:27:16,230
to send a thing to your your user forum

00:27:13,890 --> 00:27:16,950
it's not enough to tweet it put it in

00:27:16,230 --> 00:27:19,440
the CVEs

00:27:16,950 --> 00:27:21,750
so people can actually discover it and

00:27:19,440 --> 00:27:23,790
then it flows into all the Incident

00:27:21,750 --> 00:27:27,380
Response organizations in every other

00:27:23,790 --> 00:27:27,380
company that consumes your software so

00:27:28,730 --> 00:27:34,830
recap security incidents can happen to

00:27:32,309 --> 00:27:37,010
any one of us every one of us in the

00:27:34,830 --> 00:27:40,950
room will deal with a security incident

00:27:37,010 --> 00:27:43,650
in your career and you should bake

00:27:40,950 --> 00:27:46,650
security into every phase of your

00:27:43,650 --> 00:27:49,200
software development process so that

00:27:46,650 --> 00:27:51,440
it's cheaper than cleaning up at the end

00:27:49,200 --> 00:27:54,120
you don't have that reputational impact

00:27:51,440 --> 00:27:55,920
we talked about how you want to train

00:27:54,120 --> 00:27:58,380
your users because your users are often

00:27:55,920 --> 00:28:01,700
your greatest risk you want to implement

00:27:58,380 --> 00:28:04,110
design reviews so that you can protect

00:28:01,700 --> 00:28:06,000
from issues before they've even been

00:28:04,110 --> 00:28:07,830
authored you won't have secure

00:28:06,000 --> 00:28:10,410
development practices you make sure that

00:28:07,830 --> 00:28:12,230
you know you have protected branches and

00:28:10,410 --> 00:28:14,550
you have code review when you have

00:28:12,230 --> 00:28:18,000
security review you want to have people

00:28:14,550 --> 00:28:20,540
be empowered to say no when there's a

00:28:18,000 --> 00:28:20,540
security risk

00:28:20,870 --> 00:28:27,179
verification use the ecosystem use the

00:28:24,750 --> 00:28:29,460
community use pen testers use bug

00:28:27,179 --> 00:28:32,220
bounties and use great static analysis

00:28:29,460 --> 00:28:34,860
tools and great fuzzing tools that can

00:28:32,220 --> 00:28:37,590
make you more productive we're in sort

00:28:34,860 --> 00:28:40,080
of the golden era of software security

00:28:37,590 --> 00:28:43,800
but it's also the scariest time because

00:28:40,080 --> 00:28:45,990
there are more risks than ever and so

00:28:43,800 --> 00:28:49,860
it's it's okay for all of you to go back

00:28:45,990 --> 00:28:53,809
and be that advocate for how we do

00:28:49,860 --> 00:28:53,809
better how we prevent the next one

00:28:55,300 --> 00:29:01,250
what I want to do sort of as a parting

00:28:58,490 --> 00:29:04,550
note here and and we'll be around later

00:29:01,250 --> 00:29:07,820
there's a capture the flag exercise over

00:29:04,550 --> 00:29:09,860
in the the connect space but I want to

00:29:07,820 --> 00:29:13,000
give you a couple of resources that I I

00:29:09,860 --> 00:29:15,260
really personally like a couple of books

00:29:13,000 --> 00:29:17,750
from Microsoft press that I'm a big fan

00:29:15,260 --> 00:29:20,600
of to people like secure writing secure

00:29:17,750 --> 00:29:24,220
code - or SATA is that a fun book for

00:29:20,600 --> 00:29:26,240
people it's good good bedtime reading

00:29:24,220 --> 00:29:28,370
I'm also a big fan of the threat

00:29:26,240 --> 00:29:30,560
modeling book if you haven't done threat

00:29:28,370 --> 00:29:32,090
modeling before it is such a good

00:29:30,560 --> 00:29:35,240
practice to bring to your organization

00:29:32,090 --> 00:29:37,610
and that book walks through categorizing

00:29:35,240 --> 00:29:41,150
issues how to diagnose them what a

00:29:37,610 --> 00:29:45,050
repudiation attack even is that's always

00:29:41,150 --> 00:29:47,390
a fun one and then there's one you know

00:29:45,050 --> 00:29:50,150
the the 24 deadly sins of software

00:29:47,390 --> 00:29:52,910
security I'm a big fan of that one a

00:29:50,150 --> 00:29:55,730
security person from Microsoft David

00:29:52,910 --> 00:29:57,830
LeBlanc wrote that and it's great it

00:29:55,730 --> 00:29:59,720
talks about all of these sort of classic

00:29:57,830 --> 00:30:01,010
things that you're gonna see your

00:29:59,720 --> 00:30:03,050
cross-site scripting your buffer

00:30:01,010 --> 00:30:05,240
overruns your you know unvalidated

00:30:03,050 --> 00:30:06,770
inputs all those sorts of things and it

00:30:05,240 --> 00:30:09,920
does it in a very conversational way a

00:30:06,770 --> 00:30:11,480
very practical way I'm also gonna plug

00:30:09,920 --> 00:30:13,370
all the secure the github security tools

00:30:11,480 --> 00:30:15,980
because by and large you have them for

00:30:13,370 --> 00:30:19,970
free and if you're not using them or

00:30:15,980 --> 00:30:23,420
something else think about it and then

00:30:19,970 --> 00:30:24,770
finally you know I stole a lot of this

00:30:23,420 --> 00:30:27,050
from Microsoft

00:30:24,770 --> 00:30:29,420
they bought github but I I'm gonna steal

00:30:27,050 --> 00:30:30,500
from them prodigiously the security

00:30:29,420 --> 00:30:33,320
development lifecycle that they

00:30:30,500 --> 00:30:34,940
developed is really where world class so

00:30:33,320 --> 00:30:38,390
if you want to know more about some of

00:30:34,940 --> 00:30:40,010
the practices that are in here there's a

00:30:38,390 --> 00:30:42,410
lot of long-form documentation you can

00:30:40,010 --> 00:30:45,860
read there to try and figure out how you

00:30:42,410 --> 00:30:48,070
can apply all of these concepts to your

00:30:45,860 --> 00:30:50,410
organization

00:30:48,070 --> 00:30:53,660
the last thing I'll leave you with is

00:30:50,410 --> 00:30:56,360
your greatest asset as much as your

00:30:53,660 --> 00:30:57,560
greatest risk are your people and it's

00:30:56,360 --> 00:30:59,690
not just the people you work with it's

00:30:57,560 --> 00:31:01,250
also the people in this room so it

00:30:59,690 --> 00:31:04,550
encourage you while you're here

00:31:01,250 --> 00:31:07,050
at github universe to make connections

00:31:04,550 --> 00:31:09,510
with other people that are like-minded

00:31:07,050 --> 00:31:11,280
because what you might find is the other

00:31:09,510 --> 00:31:14,400
people in the room have figured

00:31:11,280 --> 00:31:17,660
something out you haven't and so I want

00:31:14,400 --> 00:31:20,480
to challenge you all to go and talk to

00:31:17,660 --> 00:31:22,560
two people you've never met today and

00:31:20,480 --> 00:31:24,360
just ask them hey what are you what are

00:31:22,560 --> 00:31:26,670
you doing for software security what's

00:31:24,360 --> 00:31:28,440
working for you and bring that back to

00:31:26,670 --> 00:31:31,890
your organization because I bet you're

00:31:28,440 --> 00:31:34,040
gonna learn some things and you know

00:31:31,890 --> 00:31:38,160
we've all got things to teach each other

00:31:34,040 --> 00:31:39,420
so with that I'll thank you all and have

00:31:38,160 --> 00:31:40,490
you enjoy the rest of your universe

00:31:39,420 --> 00:31:41,200
thank you everybody

00:31:40,490 --> 00:32:12,609
[Applause]

00:31:41,200 --> 00:32:12,609

YouTube URL: https://www.youtube.com/watch?v=R9JvD7hzJBg


