Title: The JanusGraph FoundationDB Storage Adapter - Ted Wilmes, Expero Inc.
Publication date: 2018-12-14
Playlist: FoundationDB Summit 2018
Description: 
	JanusGraph is a popular open source property graph database that serves a variety of transactional and analytical use cases. It was originally designed to run on top of a number of different distributed storage engines including Apache Cassandra and Apache HBase. This talk will discuss the new JanusGraph FoundationDB storage adapter which adds distributed ACID support to JanusGraph. Topics will include an intro to JanusGraph and FoundationDB layer development followed by a deep dive into how the property graph model and read/write access patterns have been mapped on to FoundationDB. We will also discuss how FoundationDB's unique features  address a number of JanusGraph pain points and discuss further improvements that it will enable going forward.
Captions: 
	00:00:00,030 --> 00:00:06,000
okay hi my name is Ted Wilmes I work for

00:00:04,170 --> 00:00:08,400
a company called expiry we're a

00:00:06,000 --> 00:00:10,769
consulting company I specifically do a

00:00:08,400 --> 00:00:12,509
lot of graph database work so that's why

00:00:10,769 --> 00:00:14,940
I'm talking about Janis graph today I'm

00:00:12,509 --> 00:00:17,690
active member of a Patchi tinkerer pop

00:00:14,940 --> 00:00:20,100
and the Janice graph communities and

00:00:17,690 --> 00:00:21,480
over the last few months have gotten to

00:00:20,100 --> 00:00:23,119
know a little bit more about and use a

00:00:21,480 --> 00:00:25,439
foundation dB

00:00:23,119 --> 00:00:28,980
so today I'm going to talk about graph

00:00:25,439 --> 00:00:31,050
databases in general just briefly to

00:00:28,980 --> 00:00:33,030
give people an introduction to what the

00:00:31,050 --> 00:00:35,070
state of the graph database world is

00:00:33,030 --> 00:00:36,960
then we'll talk about Janus graph how it

00:00:35,070 --> 00:00:38,460
currently runs on a number of different

00:00:36,960 --> 00:00:41,309
storage backends and then what it looks

00:00:38,460 --> 00:00:42,629
like on top of foundation DB then I'll

00:00:41,309 --> 00:00:45,239
talk a little bit about what it took to

00:00:42,629 --> 00:00:48,930
put together an adapter to actually run

00:00:45,239 --> 00:00:50,160
Janus graph on foundation DB and then if

00:00:48,930 --> 00:00:53,309
there's time at the end we'll talk a

00:00:50,160 --> 00:00:55,559
little bit about performance so first of

00:00:53,309 --> 00:00:57,449
all today I'm going to talk about graph

00:00:55,559 --> 00:00:59,160
databases specifically the property

00:00:57,449 --> 00:01:01,230
graph data model so you may have heard

00:00:59,160 --> 00:01:02,940
of triple stores and RDF and things like

00:01:01,230 --> 00:01:06,390
that but I'm gonna be talking about

00:01:02,940 --> 00:01:09,030
property graphs property graphs have a

00:01:06,390 --> 00:01:11,640
basic idea where you have vertices and

00:01:09,030 --> 00:01:13,409
edges both vertices and edges can have

00:01:11,640 --> 00:01:16,920
labels and then they can have properties

00:01:13,409 --> 00:01:20,159
just properties being key value pairs so

00:01:16,920 --> 00:01:21,930
pretty simple model here so what do

00:01:20,159 --> 00:01:23,610
people actually use graph databases for

00:01:21,930 --> 00:01:24,869
so there's of course as you would

00:01:23,610 --> 00:01:26,850
probably imagine there's kind of the

00:01:24,869 --> 00:01:28,829
canonical graph database examples of

00:01:26,850 --> 00:01:31,409
social network analysis and things like

00:01:28,829 --> 00:01:33,360
that but we're finding lots of customers

00:01:31,409 --> 00:01:35,130
are also just wanting to use graph

00:01:33,360 --> 00:01:37,350
databases for you know other sorts of

00:01:35,130 --> 00:01:39,420
industry use cases here's just an

00:01:37,350 --> 00:01:42,150
example simple data model from a supply

00:01:39,420 --> 00:01:45,119
chain use case usually it's pretty easy

00:01:42,150 --> 00:01:46,880
to see graphs and your existing in your

00:01:45,119 --> 00:01:49,619
existing data sets that you're using

00:01:46,880 --> 00:01:51,420
whether or not it's a good idea to use a

00:01:49,619 --> 00:01:53,670
graph database or not it's usually more

00:01:51,420 --> 00:01:55,380
of an operational question but here we

00:01:53,670 --> 00:01:57,090
have a bill of materials graph and that

00:01:55,380 --> 00:01:58,560
has some connection into your supply

00:01:57,090 --> 00:02:00,869
chain where you have a network of

00:01:58,560 --> 00:02:02,310
suppliers you can use that to look at

00:02:00,869 --> 00:02:04,680
things like hey what happens if a

00:02:02,310 --> 00:02:07,649
distribute disruption happens here at a

00:02:04,680 --> 00:02:09,780
particular distributor another area

00:02:07,649 --> 00:02:12,209
where I've spent a lot of time is got

00:02:09,780 --> 00:02:14,940
started in graphs is actually in the IOT

00:02:12,209 --> 00:02:16,860
space here's just a simple little graph

00:02:14,940 --> 00:02:19,200
of maybe some infrastructure that you

00:02:16,860 --> 00:02:20,940
might be monitoring specifically I

00:02:19,200 --> 00:02:22,800
worked in oil and gas so we would look

00:02:20,940 --> 00:02:24,660
at equipment out in the field and how

00:02:22,800 --> 00:02:27,270
that equipment was connected and then

00:02:24,660 --> 00:02:28,440
coupled that up with time series data so

00:02:27,270 --> 00:02:30,989
it gives you kind of a high-level

00:02:28,440 --> 00:02:33,300
contextual view of the system that's

00:02:30,989 --> 00:02:35,690
laid out in addition to those time

00:02:33,300 --> 00:02:38,489
series data that you're actually getting

00:02:35,690 --> 00:02:40,980
so the graph world right now is kind of

00:02:38,489 --> 00:02:43,319
exploding so there's lots of different

00:02:40,980 --> 00:02:45,840
different vendors that are coming into

00:02:43,319 --> 00:02:47,459
the space and the one that I'm going to

00:02:45,840 --> 00:02:49,379
talk about today is specifically the

00:02:47,459 --> 00:02:52,080
Janus craft project you all may have

00:02:49,379 --> 00:02:54,000
heard of Titan before I think I don't

00:02:52,080 --> 00:02:55,080
know if the person here is did it but

00:02:54,000 --> 00:02:59,610
there actually was somebody wrote a

00:02:55,080 --> 00:03:05,069
Titan adapter anyway for okay for

00:02:59,610 --> 00:03:08,760
Foundation DB I thought so maybe and so

00:03:05,069 --> 00:03:10,400
Janus graph is a fork of Titan Janus

00:03:08,760 --> 00:03:13,379
graph is hosted at the Linux Foundation

00:03:10,400 --> 00:03:16,110
Apache tinkerer pop is a graph

00:03:13,379 --> 00:03:18,720
processing framework that Janus graph

00:03:16,110 --> 00:03:21,209
actually makes use of in the graph space

00:03:18,720 --> 00:03:23,129
right now there's a few different

00:03:21,209 --> 00:03:25,470
languages that are common the two most

00:03:23,129 --> 00:03:28,140
common are ciphers that's neo4j slang

00:03:25,470 --> 00:03:30,569
guack and then also gremlin which is

00:03:28,140 --> 00:03:33,720
part of the Apache tinkerer pop stack so

00:03:30,569 --> 00:03:35,700
the Apache tinker pop stack gives some

00:03:33,720 --> 00:03:39,269
basic graph query and language

00:03:35,700 --> 00:03:42,090
capabilities a web server to contact it

00:03:39,269 --> 00:03:44,280
and drivers and also some analytical

00:03:42,090 --> 00:03:48,049
processing tools for running graph

00:03:44,280 --> 00:03:50,580
algorithms over OLAP systems like spark

00:03:48,049 --> 00:03:51,959
so the gremlin query language won't go

00:03:50,580 --> 00:03:53,250
into a ton of detail this is just

00:03:51,959 --> 00:03:55,019
supposed to be kind of a pointer if you

00:03:53,250 --> 00:03:58,080
get interested in this later but a

00:03:55,019 --> 00:03:59,790
gremlin query language is is a graphic

00:03:58,080 --> 00:04:02,099
learning language that allows you to do

00:03:59,790 --> 00:04:04,530
anything from analytical type queries to

00:04:02,099 --> 00:04:09,530
just regular old OLTP type queries

00:04:04,530 --> 00:04:11,640
mutations and reads so the Janus graph

00:04:09,530 --> 00:04:13,500
architecture from the very beginning

00:04:11,640 --> 00:04:16,500
when Janus graph was originally titin

00:04:13,500 --> 00:04:18,870
years and years ago it was built from

00:04:16,500 --> 00:04:21,209
the beginning to actually abstract out

00:04:18,870 --> 00:04:24,180
the storage layer so Janus graph doesn't

00:04:21,209 --> 00:04:25,240
actually store any data itself it's a

00:04:24,180 --> 00:04:26,830
layer that actually

00:04:25,240 --> 00:04:30,490
on top of another storage back-end

00:04:26,830 --> 00:04:33,490
that's why it made it particularly easy

00:04:30,490 --> 00:04:35,530
to put foundation DB in underneath of it

00:04:33,490 --> 00:04:38,259
so traditionally folks have run Janus

00:04:35,530 --> 00:04:40,270
graph probably mostly on Cassandra and

00:04:38,259 --> 00:04:43,180
then I'd say a little bit further second

00:04:40,270 --> 00:04:44,919
from that HBase but there's also a

00:04:43,180 --> 00:04:46,919
number of different other adapters that

00:04:44,919 --> 00:04:49,090
folks have developed over the years

00:04:46,919 --> 00:04:52,060
Janus graph also can integrate with

00:04:49,090 --> 00:04:53,620
third-party indexing tools so there's a

00:04:52,060 --> 00:04:56,050
lot of benefits to running and this

00:04:53,620 --> 00:04:57,310
layered approach but there can be some

00:04:56,050 --> 00:04:58,419
challenges especially when you're

00:04:57,310 --> 00:05:01,960
running on top of these eventually

00:04:58,419 --> 00:05:05,050
consistent backends so what is the Janus

00:05:01,960 --> 00:05:09,069
graph on foundation DB value proposition

00:05:05,050 --> 00:05:10,930
so when foundation DB got open source I

00:05:09,069 --> 00:05:12,580
was I was really excited because the

00:05:10,930 --> 00:05:14,979
thing that Janus graph really was

00:05:12,580 --> 00:05:17,860
missing was a distributed highly

00:05:14,979 --> 00:05:19,270
available acid storage option so there

00:05:17,860 --> 00:05:21,099
just wasn't anything out there you could

00:05:19,270 --> 00:05:23,830
run it on a single instance with

00:05:21,099 --> 00:05:25,330
Berkeley DB you can probably play Oracle

00:05:23,830 --> 00:05:27,849
to give you you know highly available

00:05:25,330 --> 00:05:30,940
Berkeley DB but I'm not sure of anybody

00:05:27,849 --> 00:05:33,820
doing that so this was this was really

00:05:30,940 --> 00:05:35,229
good news so one on the face of it you

00:05:33,820 --> 00:05:38,050
know we get high availability and fault

00:05:35,229 --> 00:05:40,810
tolerance acid transactions are a huge

00:05:38,050 --> 00:05:42,940
win overall I think that pays off with

00:05:40,810 --> 00:05:45,070
simplified operations and developer

00:05:42,940 --> 00:05:46,930
experience and then also there's just a

00:05:45,070 --> 00:05:49,750
lot of things internal to Janus graph

00:05:46,930 --> 00:05:51,520
right now that have had to to be done to

00:05:49,750 --> 00:05:52,990
get over the fact that a lot of times

00:05:51,520 --> 00:05:54,819
it's running on these distributed

00:05:52,990 --> 00:05:57,729
eventually consistent stores there's

00:05:54,819 --> 00:05:59,500
sorts of bespoke locking recipes and

00:05:57,729 --> 00:06:01,270
things like that things that maybe the

00:05:59,500 --> 00:06:05,169
end users don't directly see but really

00:06:01,270 --> 00:06:07,900
affect their usage of the system so

00:06:05,169 --> 00:06:09,460
right now apache tinker pop and Janus

00:06:07,900 --> 00:06:11,620
graph take kind of a generic a

00:06:09,460 --> 00:06:12,699
high-level approach to transactions and

00:06:11,620 --> 00:06:15,190
they say okay we have this thing called

00:06:12,699 --> 00:06:17,860
the transaction but in and of itself it

00:06:15,190 --> 00:06:19,690
doesn't actually give you any specific

00:06:17,860 --> 00:06:21,699
sort of guarantees those guarantees are

00:06:19,690 --> 00:06:23,199
gonna be inherited from the back-end

00:06:21,699 --> 00:06:26,169
storage layer that you're actually

00:06:23,199 --> 00:06:27,940
putting underneath of it so syntax

00:06:26,169 --> 00:06:30,880
doesn't really matter here but you can

00:06:27,940 --> 00:06:32,979
start explicit transactions do multiple

00:06:30,880 --> 00:06:34,990
queries and then at the end you know

00:06:32,979 --> 00:06:37,599
commit your transaction or rollback and

00:06:34,990 --> 00:06:38,700
then whether or not you have any sort of

00:06:37,599 --> 00:06:41,280
acid or something

00:06:38,700 --> 00:06:43,170
or any consistency that depends on the

00:06:41,280 --> 00:06:45,750
engine underneath it so why might acid

00:06:43,170 --> 00:06:47,880
matter in a graph database so I'm gonna

00:06:45,750 --> 00:06:50,790
tell a little story the parable the edge

00:06:47,880 --> 00:06:52,980
to know where so here we go we're going

00:06:50,790 --> 00:06:56,540
to just start with two vertices and B

00:06:52,980 --> 00:06:59,100
vertex and so let's say user one here

00:06:56,540 --> 00:07:02,910
looks up the vertex a and they look up

00:06:59,100 --> 00:07:04,920
vertex B then another user comes in and

00:07:02,910 --> 00:07:06,990
in the meantime while this first

00:07:04,920 --> 00:07:08,580
transaction still open pretty

00:07:06,990 --> 00:07:11,730
straightforward but they drop one of

00:07:08,580 --> 00:07:13,590
those vertices then I go and I say okay

00:07:11,730 --> 00:07:15,660
let's go add an edge between these two

00:07:13,590 --> 00:07:18,240
things let's say you know Ted knows Tom

00:07:15,660 --> 00:07:20,670
and then commits that well if you're

00:07:18,240 --> 00:07:23,310
running this on Cassandra what's going

00:07:20,670 --> 00:07:25,320
to happen is you're going to get what we

00:07:23,310 --> 00:07:28,500
call kind of like this phantom edge this

00:07:25,320 --> 00:07:30,150
edge to nowhere and so you go back I run

00:07:28,500 --> 00:07:32,220
a little query on my graph again I say

00:07:30,150 --> 00:07:34,140
hey how many people does you know vertex

00:07:32,220 --> 00:07:36,690
a now and it says oh yeah he knows one

00:07:34,140 --> 00:07:38,190
person he doesn't really know one person

00:07:36,690 --> 00:07:40,440
though in reality but the database

00:07:38,190 --> 00:07:41,640
thinks he does so this is the equivalent

00:07:40,440 --> 00:07:43,080
of if you couldn't trust you know a

00:07:41,640 --> 00:07:45,770
foreign key constraint in your

00:07:43,080 --> 00:07:48,450
relational database so that's no good

00:07:45,770 --> 00:07:51,810
there's things that are built into Janis

00:07:48,450 --> 00:07:54,870
graph to try to lessen the chance of

00:07:51,810 --> 00:07:57,420
this happen happening on a eventually

00:07:54,870 --> 00:07:59,700
consistent back in but they're not

00:07:57,420 --> 00:08:01,470
foolproof so this is something ideally

00:07:59,700 --> 00:08:03,810
that we want to push down into a system

00:08:01,470 --> 00:08:06,210
that is actually just purpose-built and

00:08:03,810 --> 00:08:08,210
can handle that without any issues some

00:08:06,210 --> 00:08:12,210
other operation the rely on consistency

00:08:08,210 --> 00:08:13,980
Janis graph vertices have IDs ID block

00:08:12,210 --> 00:08:15,690
allocation of course when you're running

00:08:13,980 --> 00:08:17,940
that in a distributed system you want to

00:08:15,690 --> 00:08:19,950
make sure two different you know

00:08:17,940 --> 00:08:21,870
vertices that you don't want them to end

00:08:19,950 --> 00:08:24,240
up with the same ID this is also

00:08:21,870 --> 00:08:27,240
problematic from just ID allocation from

00:08:24,240 --> 00:08:29,340
a performance standpoint schema changes

00:08:27,240 --> 00:08:31,710
having agreement this goes back to kind

00:08:29,340 --> 00:08:33,060
of metadata like we discussed earlier if

00:08:31,710 --> 00:08:35,430
you're making changes to your graph

00:08:33,060 --> 00:08:37,560
schema and a cluster you need to rely on

00:08:35,430 --> 00:08:41,070
consistency their unique index

00:08:37,560 --> 00:08:43,320
constraints and then lastly Janus allows

00:08:41,070 --> 00:08:44,940
you to plug in third-party search index

00:08:43,320 --> 00:08:48,540
things so now you're storing data and

00:08:44,940 --> 00:08:50,430
say Cassandra and elasticsearch ideally

00:08:48,540 --> 00:08:52,110
those things would stay in sync but

00:08:50,430 --> 00:08:54,910
sometimes they don't

00:08:52,110 --> 00:08:56,800
so Janice Graff like I said has a few

00:08:54,910 --> 00:08:58,690
tools internal to it there's even a nice

00:08:56,800 --> 00:09:01,300
warning in there that if anybody reads

00:08:58,690 --> 00:09:04,930
the documentation it basically says this

00:09:01,300 --> 00:09:08,200
works most of the time probably but

00:09:04,930 --> 00:09:10,510
cross your fingers so obviously there's

00:09:08,200 --> 00:09:12,700
a lot of room for improvement here so

00:09:10,510 --> 00:09:14,710
right now the options for the developer

00:09:12,700 --> 00:09:16,240
it's really just largely you know it's

00:09:14,710 --> 00:09:18,430
left up to the developer you need to do

00:09:16,240 --> 00:09:21,850
things at the application level to just

00:09:18,430 --> 00:09:23,350
kind of plan ahead and and assume from

00:09:21,850 --> 00:09:25,270
the beginning that you're not going to

00:09:23,350 --> 00:09:27,250
get these sorts of guarantees and it's

00:09:25,270 --> 00:09:28,960
just it's extra complication and and

00:09:27,250 --> 00:09:32,170
frankly it's something that people just

00:09:28,960 --> 00:09:35,050
they miss so and I can't blame them I've

00:09:32,170 --> 00:09:37,540
done it before so the foundation DB

00:09:35,050 --> 00:09:40,390
storage adapter so building a new

00:09:37,540 --> 00:09:41,740
adapter for Janice Graf is fairly

00:09:40,390 --> 00:09:43,870
straightforward partially because

00:09:41,740 --> 00:09:46,300
there's a lot of examples already in

00:09:43,870 --> 00:09:47,740
place already so I won't go into detail

00:09:46,300 --> 00:09:49,510
and all these bullets but there's a

00:09:47,740 --> 00:09:51,660
little recipe if you you want to build

00:09:49,510 --> 00:09:54,280
your own Janice craft storage adapter

00:09:51,660 --> 00:09:58,660
the data model for Janice graph itself

00:09:54,280 --> 00:10:01,840
was initially built upon basically kind

00:09:58,660 --> 00:10:04,270
of this generic BigTable model and so we

00:10:01,840 --> 00:10:06,700
have here is vertex and edge data is

00:10:04,270 --> 00:10:10,960
stored in adjacency list format so we

00:10:06,700 --> 00:10:13,450
have a vertex ID then its properties for

00:10:10,960 --> 00:10:16,720
that vertex are stored and then that

00:10:13,450 --> 00:10:20,050
vertices inbound and outbound edges are

00:10:16,720 --> 00:10:22,000
stored so one of the nice things about

00:10:20,050 --> 00:10:24,190
foundation DB and also just about

00:10:22,000 --> 00:10:27,310
Cassandra in general is in a graph

00:10:24,190 --> 00:10:30,340
database there's not many opportunities

00:10:27,310 --> 00:10:33,280
for sequential reads so the ability to

00:10:30,340 --> 00:10:35,890
sweat slice queries on the edges is nice

00:10:33,280 --> 00:10:37,240
from a performance standpoint so if we

00:10:35,890 --> 00:10:39,520
were to map this to Cassander if you

00:10:37,240 --> 00:10:41,650
used Cassandra before your partition key

00:10:39,520 --> 00:10:42,940
would be the vertex ID and then your

00:10:41,650 --> 00:10:45,490
rows are going to be sorted on the

00:10:42,940 --> 00:10:47,590
clustering keys right now this data is

00:10:45,490 --> 00:10:49,360
just stored is you know serialized byte

00:10:47,590 --> 00:10:51,400
arrays so if you were to look at it and

00:10:49,360 --> 00:10:53,560
you know cql you want to be able to read

00:10:51,400 --> 00:10:56,110
it so how do we map this then to

00:10:53,560 --> 00:10:57,790
foundation DB this is not really that

00:10:56,110 --> 00:11:00,760
much different than the than the

00:10:57,790 --> 00:11:03,130
documental air example we're basically

00:11:00,760 --> 00:11:04,690
going to use a combination of the

00:11:03,130 --> 00:11:07,360
directory layer and then

00:11:04,690 --> 00:11:09,459
the tuple support and so our keys are

00:11:07,360 --> 00:11:10,990
going to look like this if in Cassandra

00:11:09,459 --> 00:11:13,810
we had a you know a key space that

00:11:10,990 --> 00:11:16,029
stored graph for a customer a and in a

00:11:13,810 --> 00:11:17,200
key space for customer B here we're

00:11:16,029 --> 00:11:20,079
going to have our key is going to be

00:11:17,200 --> 00:11:22,389
prefixed with the graph and then within

00:11:20,079 --> 00:11:24,130
that graph there's different sorts of if

00:11:22,389 --> 00:11:26,410
you want to think about it table terms

00:11:24,130 --> 00:11:29,470
so there's table that stores vertex and

00:11:26,410 --> 00:11:31,839
edge data one that stores index data one

00:11:29,470 --> 00:11:33,250
that stores schema data and so then

00:11:31,839 --> 00:11:35,740
we'll break it out a little further and

00:11:33,250 --> 00:11:37,630
then finally we get down to the actual

00:11:35,740 --> 00:11:39,850
key for that vertex and then whether it

00:11:37,630 --> 00:11:41,500
be a property in or an edge and then the

00:11:39,850 --> 00:11:42,850
value is just simply that byte array

00:11:41,500 --> 00:11:46,050
that we want to pull back which is

00:11:42,850 --> 00:11:48,730
storing maybe property value information

00:11:46,050 --> 00:11:50,920
so if we stretch that out a little bit

00:11:48,730 --> 00:11:53,860
here you can see from the first example

00:11:50,920 --> 00:11:57,279
basically how that's mapped so obviously

00:11:53,860 --> 00:11:59,680
here's something like prefix compression

00:11:57,279 --> 00:12:04,680
will be something that'll really help us

00:11:59,680 --> 00:12:08,399
out so I use the Berkeley DB adapter as

00:12:04,680 --> 00:12:11,320
inspiration for this particular adapter

00:12:08,399 --> 00:12:13,209
there's a host of different methods that

00:12:11,320 --> 00:12:16,959
you basically go in and implement and

00:12:13,209 --> 00:12:19,120
then there's a number of tests that you

00:12:16,959 --> 00:12:19,930
can use as inspiration however I like

00:12:19,120 --> 00:12:22,390
that

00:12:19,930 --> 00:12:25,329
autonomous testing idea I think we could

00:12:22,390 --> 00:12:27,519
probably use that so we took those

00:12:25,329 --> 00:12:30,430
Berkeley DB tests and adapted them then

00:12:27,519 --> 00:12:32,110
for the foundation you'd be adapter so

00:12:30,430 --> 00:12:34,660
now if we go back to our example over

00:12:32,110 --> 00:12:36,040
visiting this edge to nowhere case you

00:12:34,660 --> 00:12:37,870
don't really need to read this but this

00:12:36,040 --> 00:12:40,120
is the one time I'm excited to see an

00:12:37,870 --> 00:12:41,860
exception basically we did that first

00:12:40,120 --> 00:12:44,230
operation again but now we're running

00:12:41,860 --> 00:12:46,180
his foundation DB and look we don't

00:12:44,230 --> 00:12:48,519
corrupt our graph we're actually going

00:12:46,180 --> 00:12:50,019
to get this exception because there was

00:12:48,519 --> 00:12:54,190
a conflict when we went to commit

00:12:50,019 --> 00:12:58,930
because that vertex was deleted so

00:12:54,190 --> 00:13:01,240
future work I think future work there's

00:12:58,930 --> 00:13:03,040
a lot of potential here so one thing is

00:13:01,240 --> 00:13:05,410
and maybe this will be overcome by

00:13:03,040 --> 00:13:11,170
events because of the improved support

00:13:05,410 --> 00:13:13,070
for transactions but initially the the

00:13:11,170 --> 00:13:14,600
current adapter

00:13:13,070 --> 00:13:16,400
could use some improvements in the area

00:13:14,600 --> 00:13:18,410
where it's extending transactions past

00:13:16,400 --> 00:13:21,830
five seconds so right now you can do

00:13:18,410 --> 00:13:24,050
reads past five seconds in the current

00:13:21,830 --> 00:13:27,260
adapter it doesn't of course maintain

00:13:24,050 --> 00:13:28,460
the same consistency guarantees as it is

00:13:27,260 --> 00:13:30,710
it what if it was in a single

00:13:28,460 --> 00:13:32,930
transaction but I think it sounds like

00:13:30,710 --> 00:13:34,400
with the Redwoods storage engine we may

00:13:32,930 --> 00:13:36,170
be able to just kind of pull that out

00:13:34,400 --> 00:13:38,720
and hopefully just make use of that

00:13:36,170 --> 00:13:42,890
storage engine for longer reader or size

00:13:38,720 --> 00:13:44,630
limits for our for our queries the other

00:13:42,890 --> 00:13:48,250
thing like I mentioned I think the one

00:13:44,630 --> 00:13:50,840
of the biggest wins here is the custom

00:13:48,250 --> 00:13:52,910
foundation DB implementations of Janus

00:13:50,840 --> 00:13:55,670
graph internal pieces so the ID

00:13:52,910 --> 00:13:57,350
allocation other sorts of invariants

00:13:55,670 --> 00:13:59,660
that we're trying to maintain within

00:13:57,350 --> 00:14:02,780
Janus graph I think that Janus graph

00:13:59,660 --> 00:14:04,790
code can be greatly reduced and

00:14:02,780 --> 00:14:07,190
simplified if we can make use of

00:14:04,790 --> 00:14:10,880
foundation DB for that I think another

00:14:07,190 --> 00:14:12,680
thing is and now there's certain use

00:14:10,880 --> 00:14:14,780
cases for us where it would be helpful

00:14:12,680 --> 00:14:16,610
to have some sort of hybrid storage

00:14:14,780 --> 00:14:20,150
model right now we store data and kind

00:14:16,610 --> 00:14:23,270
of a graph equivalent of this of a row

00:14:20,150 --> 00:14:25,340
row oriented format I think in certain

00:14:23,270 --> 00:14:27,140
cases it would be nice to store say more

00:14:25,340 --> 00:14:30,410
of the historical adjacency list data

00:14:27,140 --> 00:14:32,510
and a column oriented format so to do

00:14:30,410 --> 00:14:34,220
that online it would be nice if the data

00:14:32,510 --> 00:14:37,520
based on the backend could be moving

00:14:34,220 --> 00:14:39,260
data from row 2 column oriented format

00:14:37,520 --> 00:14:41,390
but to do that we need to have that

00:14:39,260 --> 00:14:43,160
consistency we don't want to say start

00:14:41,390 --> 00:14:44,720
moving some data and then I'll miss out

00:14:43,160 --> 00:14:47,210
a write happened here or something like

00:14:44,720 --> 00:14:49,130
that so I think that'll greatly simplify

00:14:47,210 --> 00:14:51,820
that sort of thing the other thing that

00:14:49,130 --> 00:14:54,500
I started looking at but isn't in the

00:14:51,820 --> 00:14:57,110
listen in the actual adaptor yet is

00:14:54,500 --> 00:15:00,170
foundation DB like I think was discussed

00:14:57,110 --> 00:15:03,650
earlier publishes information about the

00:15:00,170 --> 00:15:06,080
locations of keys and so if we co-locate

00:15:03,650 --> 00:15:08,630
our Janus graph layer with the

00:15:06,080 --> 00:15:10,370
foundation DB nodes I think we can do

00:15:08,630 --> 00:15:12,380
some intelligent query routing and

00:15:10,370 --> 00:15:14,450
predicate push down that really isn't

00:15:12,380 --> 00:15:17,090
happening in any of the layers right now

00:15:14,450 --> 00:15:19,610
so that you know gives performance

00:15:17,090 --> 00:15:22,730
improvements from from a client

00:15:19,610 --> 00:15:25,170
perspective and then lastly it'd be

00:15:22,730 --> 00:15:27,000
great to pull full text search in

00:15:25,170 --> 00:15:28,980
so it's no longer another third-party

00:15:27,000 --> 00:15:31,380
component that we need to keep in sync

00:15:28,980 --> 00:15:32,760
so that'll be a larger thing to do but I

00:15:31,380 --> 00:15:35,370
think getting full-text and geospatial

00:15:32,760 --> 00:15:37,500
search pulled in maybe we could make use

00:15:35,370 --> 00:15:40,200
of some of that sort of indexing work in

00:15:37,500 --> 00:15:44,610
the document layer but that would be

00:15:40,200 --> 00:15:47,760
great to use as inspiration for that so

00:15:44,610 --> 00:15:50,730
if you are interested in graph databases

00:15:47,760 --> 00:15:54,300
or want to try this out we have it up on

00:15:50,730 --> 00:15:56,700
our github repo if you're unfamiliar

00:15:54,300 --> 00:15:58,560
with how to use Janice graph Janice

00:15:56,700 --> 00:16:01,410
graph site has pretty good documentation

00:15:58,560 --> 00:16:04,170
tinker pop does too so you can get

00:16:01,410 --> 00:16:06,720
started download Janice craft basically

00:16:04,170 --> 00:16:08,250
and then install this foundation DB

00:16:06,720 --> 00:16:10,560
adapter it's easy to get up and running

00:16:08,250 --> 00:16:12,480
on one instance or if you want to stand

00:16:10,560 --> 00:16:14,460
up more Foundation DB nodes you can do

00:16:12,480 --> 00:16:17,700
that I should have said that the Janice

00:16:14,460 --> 00:16:19,830
graph deployment model you can also

00:16:17,700 --> 00:16:21,300
horizontally scale Janice graph itself

00:16:19,830 --> 00:16:23,220
out too so you don't just have one

00:16:21,300 --> 00:16:24,990
Janice graph instance but you can have

00:16:23,220 --> 00:16:29,490
however many whether that be one-to-one

00:16:24,990 --> 00:16:31,310
with the storage layer or not so okay so

00:16:29,490 --> 00:16:34,610
I'm excited about the future of

00:16:31,310 --> 00:16:36,870
foundation to be excited to have

00:16:34,610 --> 00:16:39,120
something that kind of fit this need and

00:16:36,870 --> 00:16:40,950
this this hole that we had in the Janice

00:16:39,120 --> 00:16:43,350
graph stack and appreciate the

00:16:40,950 --> 00:16:50,559
opportunity to speak to you

00:16:43,350 --> 00:16:50,559

YouTube URL: https://www.youtube.com/watch?v=rQM_ZPZy8Ck


