Title: Cross-Region Replication Options with FoundationDB - Evan Tschannen, Apple
Publication date: 2018-12-14
Playlist: FoundationDB Summit 2018
Description: 
	FoundationDB has a number of different configurations for replicating data between regions. This presentation will go through these different options and discuss the tradeoffs between them.
Captions: 
	00:00:00,000 --> 00:00:05,640
this I'm now gonna talk about something

00:00:02,970 --> 00:00:07,799
that's really special to me which is the

00:00:05,640 --> 00:00:10,740
new multi region support that was

00:00:07,799 --> 00:00:12,719
recently added in six oh and it's

00:00:10,740 --> 00:00:13,950
special not only because I spent the

00:00:12,719 --> 00:00:18,300
last year-and-a-half painfully

00:00:13,950 --> 00:00:21,119
implementing it but also because it

00:00:18,300 --> 00:00:23,609
removes a really big caveat that

00:00:21,119 --> 00:00:26,580
foundation DB has had up until this

00:00:23,609 --> 00:00:29,160
point which is that generally if you're

00:00:26,580 --> 00:00:30,359
as a user choosing foundation to be one

00:00:29,160 --> 00:00:32,399
of the reasons you're using it is

00:00:30,359 --> 00:00:33,780
obviously like data safety and

00:00:32,399 --> 00:00:35,880
availability right you want your

00:00:33,780 --> 00:00:39,390
database to be like always alive and

00:00:35,880 --> 00:00:41,370
never lose your data and so the fact

00:00:39,390 --> 00:00:43,860
that foundation DB has basically been

00:00:41,370 --> 00:00:47,670
generally designed to work within one

00:00:43,860 --> 00:00:49,559
data center has kind of been that caveat

00:00:47,670 --> 00:00:51,239
I was talking about it's it's like well

00:00:49,559 --> 00:00:54,059
it's great if they're all co-located

00:00:51,239 --> 00:00:58,230
together but I want to be safe against

00:00:54,059 --> 00:01:00,149
failing a region and so like this the

00:00:58,230 --> 00:01:01,859
six oh release like is gonna remove that

00:01:00,149 --> 00:01:03,870
caveat and so I'm really happy to be

00:01:01,859 --> 00:01:04,680
here and share this share the this new

00:01:03,870 --> 00:01:08,100
feature with you

00:01:04,680 --> 00:01:10,710
so already talked about myself and I've

00:01:08,100 --> 00:01:12,420
already done a lot of motivation but you

00:01:10,710 --> 00:01:14,070
know the the obvious reason why do you

00:01:12,420 --> 00:01:15,659
want the multi region support you want

00:01:14,070 --> 00:01:19,380
to survive you want to remain available

00:01:15,659 --> 00:01:20,549
right when the region is out and the

00:01:19,380 --> 00:01:23,040
other the other one that's a little

00:01:20,549 --> 00:01:24,960
that's also important for some people in

00:01:23,040 --> 00:01:27,060
some applications is potentially you

00:01:24,960 --> 00:01:29,549
want to be able to serve reads locally

00:01:27,060 --> 00:01:31,020
from a lot of different regions so that

00:01:29,549 --> 00:01:36,450
can make a big difference for some

00:01:31,020 --> 00:01:39,329
applications ah so coming to this

00:01:36,450 --> 00:01:41,310
problem we had foundation DB and we're

00:01:39,329 --> 00:01:44,549
looking at what we can we do with in in

00:01:41,310 --> 00:01:46,049
multiple regions and the first thought

00:01:44,549 --> 00:01:47,820
was sort of to take the same approach

00:01:46,049 --> 00:01:51,210
that a lot of databases like sequel

00:01:47,820 --> 00:01:53,340
databases use which is basically to set

00:01:51,210 --> 00:01:55,829
up some asynchronous replication between

00:01:53,340 --> 00:01:57,600
your primary region and a completely

00:01:55,829 --> 00:01:58,649
different foundation DB database that

00:01:57,600 --> 00:02:01,290
you're going to run in the secondary

00:01:58,649 --> 00:02:03,750
region so these are just completely

00:02:01,290 --> 00:02:05,640
independent data databases and we're

00:02:03,750 --> 00:02:08,039
basically shipping the changelog from

00:02:05,640 --> 00:02:10,080
the first one and there's some external

00:02:08,039 --> 00:02:11,849
agent to the system like these dr agents

00:02:10,080 --> 00:02:12,890
we're taking the data and applying it to

00:02:11,849 --> 00:02:17,030
the other region in

00:02:12,890 --> 00:02:20,720
in order this approach it has a huge

00:02:17,030 --> 00:02:22,459
flaw which is that basically if you lose

00:02:20,720 --> 00:02:24,500
your primary region right just like it's

00:02:22,459 --> 00:02:27,740
a synchronous replication you're going

00:02:24,500 --> 00:02:29,660
to lose some amount of data if that

00:02:27,740 --> 00:02:30,890
hasn't been synced yet from the primary

00:02:29,660 --> 00:02:33,080
to the secondary if you just

00:02:30,890 --> 00:02:35,180
instantaneously lose your primary so

00:02:33,080 --> 00:02:36,950
this has leaves you like with a really

00:02:35,180 --> 00:02:39,410
really hard choice as an operator right

00:02:36,950 --> 00:02:41,209
because your database is down and most

00:02:39,410 --> 00:02:42,950
databases failures like a region failure

00:02:41,209 --> 00:02:44,090
generally is not permanent unless you

00:02:42,950 --> 00:02:44,450
know there's something really bad going

00:02:44,090 --> 00:02:47,030
down

00:02:44,450 --> 00:02:49,400
so you're stuck with like okay do I wait

00:02:47,030 --> 00:02:51,650
till it's back or do I choose to lose

00:02:49,400 --> 00:02:56,420
some data and no one wants to make that

00:02:51,650 --> 00:02:58,010
choice it's if you are losing data

00:02:56,420 --> 00:02:59,540
though here's the sales pitch it's the

00:02:58,010 --> 00:03:01,190
best kind of data loss you could have

00:02:59,540 --> 00:03:03,110
because you're gonna lose just the tail

00:03:01,190 --> 00:03:04,880
of a mutation log so you're basically

00:03:03,110 --> 00:03:06,830
going to roll back to a consistent point

00:03:04,880 --> 00:03:08,600
in time but still no one wants to make

00:03:06,830 --> 00:03:11,360
the choice um

00:03:08,600 --> 00:03:14,450
the other kind of bad thing about this

00:03:11,360 --> 00:03:16,519
design is because these two databases

00:03:14,450 --> 00:03:18,070
are completely separate they actually

00:03:16,519 --> 00:03:20,780
don't have the opportunity to cooperate

00:03:18,070 --> 00:03:23,420
so let's say we were running double

00:03:20,780 --> 00:03:25,340
replication in both sides and in the

00:03:23,420 --> 00:03:27,530
primary there's not a region failure but

00:03:25,340 --> 00:03:29,870
we just lose both replicas we lose two

00:03:27,530 --> 00:03:31,549
machines simultaneously we'd really like

00:03:29,870 --> 00:03:33,560
it if we could heal from that by

00:03:31,549 --> 00:03:34,940
grabbing the data from the secondary but

00:03:33,560 --> 00:03:36,829
because they're different clusters like

00:03:34,940 --> 00:03:39,860
there's no ability to do this healing

00:03:36,829 --> 00:03:41,450
across across the regions this generally

00:03:39,860 --> 00:03:43,430
is going to mean that we need to run

00:03:41,450 --> 00:03:46,700
with more replicas in both sides which

00:03:43,430 --> 00:03:49,910
is obviously going to cost you something

00:03:46,700 --> 00:03:54,890
so our first attempt at doing something

00:03:49,910 --> 00:03:57,410
better here was what was called three

00:03:54,890 --> 00:04:00,410
data center mode in the 500 releases or

00:03:57,410 --> 00:04:02,000
it's still there in 600 and the basic

00:04:00,410 --> 00:04:04,040
concept was well let's just take

00:04:02,000 --> 00:04:07,400
Foundation DB and spread the processes

00:04:04,040 --> 00:04:09,320
across regions um and this approach

00:04:07,400 --> 00:04:12,590
works but it comes with some pretty big

00:04:09,320 --> 00:04:15,440
caveats so the first one is you're

00:04:12,590 --> 00:04:18,560
basically the the way the setup works

00:04:15,440 --> 00:04:21,080
first off um is that you're gonna have

00:04:18,560 --> 00:04:23,240
three different regions and you're gonna

00:04:21,080 --> 00:04:26,150
put your transaction logs in two of the

00:04:23,240 --> 00:04:28,340
three regions and you have storage nodes

00:04:26,150 --> 00:04:30,199
across all of them like two and each two

00:04:28,340 --> 00:04:33,080
swords replicas in each of the regions

00:04:30,199 --> 00:04:34,850
for six total because we're

00:04:33,080 --> 00:04:37,490
synchronously replicating to multiple

00:04:34,850 --> 00:04:39,350
regions on the transaction logs we now

00:04:37,490 --> 00:04:41,660
can survive a region failure with no

00:04:39,350 --> 00:04:43,540
data loss so that's you know checks that

00:04:41,660 --> 00:04:50,169
checkbox

00:04:43,540 --> 00:04:55,820
however the they're the costs here are

00:04:50,169 --> 00:04:57,380
that basically the system wasn't really

00:04:55,820 --> 00:04:58,790
designed to handle this configuration we

00:04:57,380 --> 00:05:00,620
sort of jammed it in there by spreading

00:04:58,790 --> 00:05:02,330
our processes everywhere so you're gonna

00:05:00,620 --> 00:05:04,340
have more because you're replicating

00:05:02,330 --> 00:05:06,650
across regions you're gonna have a cross

00:05:04,340 --> 00:05:08,000
region network latency as part of your

00:05:06,650 --> 00:05:10,250
commit pass so that's gonna obviously

00:05:08,000 --> 00:05:12,770
increase your latency Xand for some

00:05:10,250 --> 00:05:14,150
applications having 40 milliseconds is

00:05:12,770 --> 00:05:17,419
on your commits is going to be a big

00:05:14,150 --> 00:05:18,770
deal the the other thing is that

00:05:17,419 --> 00:05:22,130
basically the data distribution

00:05:18,770 --> 00:05:24,650
algorithm that we have is really

00:05:22,130 --> 00:05:26,330
targeted for machine failures not region

00:05:24,650 --> 00:05:27,919
failures and what you want to do in

00:05:26,330 --> 00:05:30,800
these two cases is dramatically

00:05:27,919 --> 00:05:33,440
different so if a regular machine fails

00:05:30,800 --> 00:05:35,450
you really just want to replicate it and

00:05:33,440 --> 00:05:37,669
like heal from that loss and put the

00:05:35,450 --> 00:05:39,350
data somewhere else if an entire region

00:05:37,669 --> 00:05:41,570
fails you know you're losing one third

00:05:39,350 --> 00:05:43,639
of your total capacity it would be a

00:05:41,570 --> 00:05:45,470
disaster to try and copy all of the data

00:05:43,639 --> 00:05:48,500
from all of those machines to other

00:05:45,470 --> 00:05:50,510
locations so basically what we had to do

00:05:48,500 --> 00:05:52,190
with this design is effectively when a

00:05:50,510 --> 00:05:54,860
region fails disabled a distribution

00:05:52,190 --> 00:05:56,300
altogether so this means that while

00:05:54,860 --> 00:05:58,729
you're in a region failure scenario

00:05:56,300 --> 00:06:00,979
you're in inherently degraded State

00:05:58,729 --> 00:06:02,960
you're pretty fragile and it means that

00:06:00,979 --> 00:06:05,090
basically an operator of the system is

00:06:02,960 --> 00:06:06,860
going to need it to drop the region

00:06:05,090 --> 00:06:08,720
that's failed immediately discarding the

00:06:06,860 --> 00:06:10,760
replicas that are there so the system

00:06:08,720 --> 00:06:13,099
could get back to a healthy state so

00:06:10,760 --> 00:06:14,389
that's pretty painful the the final

00:06:13,099 --> 00:06:17,090
thing I'll talk about that's that's not

00:06:14,389 --> 00:06:19,910
great about this this mode is that it

00:06:17,090 --> 00:06:23,419
has no awareness of the locality of the

00:06:19,910 --> 00:06:25,130
machines so I talked previous

00:06:23,419 --> 00:06:26,660
presentation about how the transaction

00:06:25,130 --> 00:06:28,610
logs and the storage process ease oh I

00:06:26,660 --> 00:06:30,139
have like a buddy system where for a

00:06:28,610 --> 00:06:31,700
given storage node there's one

00:06:30,139 --> 00:06:34,490
transaction log shipping it's all it's

00:06:31,700 --> 00:06:36,080
data well in this node model the

00:06:34,490 --> 00:06:37,550
transaction logs are spread across two

00:06:36,080 --> 00:06:40,070
of the regions and the storage servers

00:06:37,550 --> 00:06:43,640
across three and basically there's

00:06:40,070 --> 00:06:45,800
no attempt to match up the transaction

00:06:43,640 --> 00:06:47,180
log that's serving data to have a store

00:06:45,800 --> 00:06:49,610
to a storage server in the same region

00:06:47,180 --> 00:06:51,560
so this is gonna explode the amount of

00:06:49,610 --> 00:06:53,030
wind traffic you have across region

00:06:51,560 --> 00:06:54,950
traffic you're gonna have because

00:06:53,030 --> 00:06:56,180
basically for all six of these storage

00:06:54,950 --> 00:06:58,010
replicas they could potentially be

00:06:56,180 --> 00:07:00,080
grabbing it from some transaction log

00:06:58,010 --> 00:07:01,160
across the network and even originally

00:07:00,080 --> 00:07:02,660
when you're writing the data to the

00:07:01,160 --> 00:07:04,730
transaction logs those were

00:07:02,660 --> 00:07:06,200
traveling across regions so you saw a

00:07:04,730 --> 00:07:11,180
given mutation might go across the

00:07:06,200 --> 00:07:13,070
network maybe eight times here um so

00:07:11,180 --> 00:07:15,650
basically that's that's where we were at

00:07:13,070 --> 00:07:17,630
five - we had this asynchronous

00:07:15,650 --> 00:07:19,700
replication option that had this manual

00:07:17,630 --> 00:07:22,220
failover with with the potential of data

00:07:19,700 --> 00:07:25,400
loss and the two sides didn't will it

00:07:22,220 --> 00:07:27,170
cooperate then we also had this three

00:07:25,400 --> 00:07:29,630
data center mode this policy based

00:07:27,170 --> 00:07:32,270
replication it had high cross region

00:07:29,630 --> 00:07:33,950
Layton sees the high overhead you know a

00:07:32,270 --> 00:07:37,730
lots more storage replicas in this

00:07:33,950 --> 00:07:40,310
inefficient way in communication so the

00:07:37,730 --> 00:07:41,990
goal with the six oh release was really

00:07:40,310 --> 00:07:44,330
to try and combine these approaches into

00:07:41,990 --> 00:07:47,380
something kind of unique and I think is

00:07:44,330 --> 00:07:49,430
really special so we're gonna do a

00:07:47,380 --> 00:07:53,990
synchronous replication within a

00:07:49,430 --> 00:07:55,430
database and then some policy based we

00:07:53,990 --> 00:07:57,500
use some of the policy based designs

00:07:55,430 --> 00:08:00,740
from the other from the three datacenter

00:07:57,500 --> 00:08:04,610
mode on the transaction logs and what

00:08:00,740 --> 00:08:06,890
we're gonna do is take advantage of sort

00:08:04,610 --> 00:08:08,360
of the geographic features that are kind

00:08:06,890 --> 00:08:10,970
of provided to you by cloud providers

00:08:08,360 --> 00:08:14,420
today and that is that basically you

00:08:10,970 --> 00:08:16,340
know like AWS or whatever already has

00:08:14,420 --> 00:08:18,440
these two different notions of locality

00:08:16,340 --> 00:08:19,700
right you have regions which are

00:08:18,440 --> 00:08:21,080
generally going to be distinct

00:08:19,700 --> 00:08:23,900
geographic locations that are far apart

00:08:21,080 --> 00:08:25,520
from each other and then within a region

00:08:23,900 --> 00:08:28,160
you're gonna have availability zones

00:08:25,520 --> 00:08:32,090
that are just still distinct geographic

00:08:28,160 --> 00:08:34,700
locations usually however they're pretty

00:08:32,090 --> 00:08:36,680
close together and so there's like a

00:08:34,700 --> 00:08:39,080
difference here the the being farther

00:08:36,680 --> 00:08:41,300
away a part is going to isolate you

00:08:39,080 --> 00:08:43,430
better from failures for correlated

00:08:41,300 --> 00:08:45,800
failures but being close together is

00:08:43,430 --> 00:08:47,840
going to give you a lot lower latency so

00:08:45,800 --> 00:08:49,430
the mode that we've come up with is

00:08:47,840 --> 00:08:53,930
basically taking advantage of this

00:08:49,430 --> 00:08:55,279
difference and so we're going to make

00:08:53,930 --> 00:08:57,020
do synchronous replication of the

00:08:55,279 --> 00:08:58,970
transaction logs to multiple

00:08:57,020 --> 00:09:02,360
availability zones in one region and

00:08:58,970 --> 00:09:04,880
then do asynchronous replication of the

00:09:02,360 --> 00:09:08,180
actual physical storage data across the

00:09:04,880 --> 00:09:10,430
regions what this basically means is

00:09:08,180 --> 00:09:12,709
that in the event that we lose one of

00:09:10,430 --> 00:09:16,370
the availability zones wherever we're

00:09:12,709 --> 00:09:17,570
printing writes at the moment um we can

00:09:16,370 --> 00:09:19,880
copy the data from the other

00:09:17,570 --> 00:09:21,709
availability loan zone and it's just the

00:09:19,880 --> 00:09:24,800
most recent history the last little bit

00:09:21,709 --> 00:09:26,630
of the the transaction logs history we

00:09:24,800 --> 00:09:28,970
can get that shipped to the other region

00:09:26,630 --> 00:09:31,209
and then we can just seamlessly and

00:09:28,970 --> 00:09:35,270
automatically failover with no data loss

00:09:31,209 --> 00:09:36,950
and and basically as long as the

00:09:35,270 --> 00:09:39,529
availability zones the to availability

00:09:36,950 --> 00:09:42,410
zones don't die within you know ten to

00:09:39,529 --> 00:09:44,870
thirty seconds of each other it only

00:09:42,410 --> 00:09:46,490
basically like you only have the they

00:09:44,870 --> 00:09:47,839
don't have to survive both availability

00:09:46,490 --> 00:09:50,420
zones it zones don't have to survive a

00:09:47,839 --> 00:09:52,790
very long time just enough to like copy

00:09:50,420 --> 00:09:55,910
this last little bit of data so we're

00:09:52,790 --> 00:09:58,220
getting the failure resilience for the

00:09:55,910 --> 00:10:00,529
most part of being in multiple regions

00:09:58,220 --> 00:10:01,760
but we're only paying the latency cost

00:10:00,529 --> 00:10:04,430
of talking to multiple availability

00:10:01,760 --> 00:10:07,480
zones and this is really powerful it's

00:10:04,430 --> 00:10:13,400
kind of a best of both worlds scenario

00:10:07,480 --> 00:10:14,630
um so I think I said this a lot of it at

00:10:13,400 --> 00:10:16,490
least but I'll go through it so the

00:10:14,630 --> 00:10:19,700
commit latencies are only talking to all

00:10:16,490 --> 00:10:22,720
of the availability zones in a region so

00:10:19,700 --> 00:10:25,820
very quick commits Layton sees again and

00:10:22,720 --> 00:10:27,260
storage replicas you only need to in

00:10:25,820 --> 00:10:28,700
each region so this is much better

00:10:27,260 --> 00:10:30,800
compared to the each of the other

00:10:28,700 --> 00:10:32,360
scenarios are described basically you

00:10:30,800 --> 00:10:34,730
only have four total storage replicas

00:10:32,360 --> 00:10:36,829
because we have that because we're all

00:10:34,730 --> 00:10:38,570
one cluster we can use them to heal we

00:10:36,829 --> 00:10:41,779
can use copies in one region to heal

00:10:38,570 --> 00:10:43,790
another region so you can lose all both

00:10:41,779 --> 00:10:45,290
replicas in one region plus another copy

00:10:43,790 --> 00:10:49,329
and the other region in your database is

00:10:45,290 --> 00:10:52,160
still running just fine and then also we

00:10:49,329 --> 00:10:53,870
like optimize the design to only send

00:10:52,160 --> 00:10:56,510
every mutation across the network

00:10:53,870 --> 00:10:58,100
exactly one time and I'll get into how

00:10:56,510 --> 00:11:00,500
we do that but it's so it's going to be

00:10:58,100 --> 00:11:03,770
significantly more efficient than the

00:11:00,500 --> 00:11:06,910
previous implementation so it's time to

00:11:03,770 --> 00:11:06,910
bring back the boxes

00:11:07,570 --> 00:11:12,350
so if you look inside of region one

00:11:10,580 --> 00:11:14,950
you're gonna see a diagram that's very

00:11:12,350 --> 00:11:17,480
similar to what I described this morning

00:11:14,950 --> 00:11:19,040
it's got all the components there and

00:11:17,480 --> 00:11:21,560
generally we're basically going to be

00:11:19,040 --> 00:11:24,380
accepting commits in that in that like

00:11:21,560 --> 00:11:25,940
that primary region and the only thing

00:11:24,380 --> 00:11:27,410
that's really different about a 600

00:11:25,940 --> 00:11:30,080
configuration will all go through the

00:11:27,410 --> 00:11:31,700
differences is that when the proxies are

00:11:30,080 --> 00:11:34,040
writing stuff to the transaction logs

00:11:31,700 --> 00:11:35,810
they're gonna make sure the stuff is

00:11:34,040 --> 00:11:37,910
durable in both availability zones

00:11:35,810 --> 00:11:41,000
inside of that region so the second

00:11:37,910 --> 00:11:43,850
region you know just has those just has

00:11:41,000 --> 00:11:45,230
those extra transaction logs and so

00:11:43,850 --> 00:11:46,580
you're paying a little bit of cost but

00:11:45,230 --> 00:11:52,280
not too much to replicate your data

00:11:46,580 --> 00:11:54,290
there once the after everything has been

00:11:52,280 --> 00:11:56,600
committed we're gonna we have this new

00:11:54,290 --> 00:11:57,980
role called a log router which is going

00:11:56,600 --> 00:12:00,830
to be responsible for pulling the

00:11:57,980 --> 00:12:02,630
mutations across the network across the

00:12:00,830 --> 00:12:05,180
regions and it's going to pull every

00:12:02,630 --> 00:12:07,070
mutation across it exactly one time so

00:12:05,180 --> 00:12:09,620
basically the way we accomplish this is

00:12:07,070 --> 00:12:11,600
every mutation is basically when it's

00:12:09,620 --> 00:12:13,910
created or when it's like committed

00:12:11,600 --> 00:12:16,310
assign a random one of these log routers

00:12:13,910 --> 00:12:17,900
and that one log router is responsible

00:12:16,310 --> 00:12:21,410
for pulling it across the network just

00:12:17,900 --> 00:12:24,050
purely random then that means that the

00:12:21,410 --> 00:12:25,940
log routers now have combined in total

00:12:24,050 --> 00:12:27,680
have exactly one copy of everything and

00:12:25,940 --> 00:12:29,960
so the transaction logs on the other

00:12:27,680 --> 00:12:31,250
side will reindex the data for the

00:12:29,960 --> 00:12:34,220
storage server that for the local

00:12:31,250 --> 00:12:35,510
storage servers and so basically they're

00:12:34,220 --> 00:12:37,580
pulling they're combining results from

00:12:35,510 --> 00:12:42,230
all the log routers and redistributing

00:12:37,580 --> 00:12:43,820
it so a lot of changes went on under the

00:12:42,230 --> 00:12:45,770
covers that you know are not in my

00:12:43,820 --> 00:12:48,350
diagram here related to these

00:12:45,770 --> 00:12:50,000
transaction logs because we had to be a

00:12:48,350 --> 00:12:51,680
lot smarter about the pairing between

00:12:50,000 --> 00:12:54,320
transaction logs and storage servers as

00:12:51,680 --> 00:12:56,000
a little bit mentioned basically we only

00:12:54,320 --> 00:12:57,500
want storage servers to be able to grab

00:12:56,000 --> 00:13:02,210
their data from the local transaction

00:12:57,500 --> 00:13:05,120
logs to prevent the crosswind traffic so

00:13:02,210 --> 00:13:08,900
what happens when our region one goes

00:13:05,120 --> 00:13:10,280
down well the first thing that's going

00:13:08,900 --> 00:13:12,350
to happen here you can notice that the

00:13:10,280 --> 00:13:16,430
other AZ has survived and maybe that's

00:13:12,350 --> 00:13:17,720
temporary so the the first thing that's

00:13:16,430 --> 00:13:19,550
going to happen is the cluster

00:13:17,720 --> 00:13:20,190
controller that the coordinators are

00:13:19,550 --> 00:13:21,210
going to detect

00:13:20,190 --> 00:13:23,310
that the previous cluster controller

00:13:21,210 --> 00:13:26,760
died and they're gonna pick a new one

00:13:23,310 --> 00:13:27,990
over in the other region this cluster

00:13:26,760 --> 00:13:30,630
controller is then gonna spin up the

00:13:27,990 --> 00:13:32,790
entire system and the the new

00:13:30,630 --> 00:13:34,980
transaction logs are going to use the

00:13:32,790 --> 00:13:36,870
log routers so stream the last little

00:13:34,980 --> 00:13:38,820
bit of data from those lat from those

00:13:36,870 --> 00:13:41,010
last remaining transaction logs across

00:13:38,820 --> 00:13:42,720
the network and this is the part that

00:13:41,010 --> 00:13:43,620
you know hopefully is generally quite

00:13:42,720 --> 00:13:46,140
quick

00:13:43,620 --> 00:13:47,250
I put 30 seconds as an upper bound but

00:13:46,140 --> 00:13:49,260
generally is gonna be a lot quicker than

00:13:47,250 --> 00:13:51,750
that

00:13:49,260 --> 00:13:53,790
once we've strained all the data now

00:13:51,750 --> 00:13:56,280
we're completely safe even if we lose

00:13:53,790 --> 00:13:58,830
those other transaction logs just a pure

00:13:56,280 --> 00:14:00,120
short-term storage and the database will

00:13:58,830 --> 00:14:03,300
just continue seamless you know

00:14:00,120 --> 00:14:05,070
seamlessly running in region two you

00:14:03,300 --> 00:14:09,360
have the option of having a different a

00:14:05,070 --> 00:14:11,520
Z on the second side which might give

00:14:09,360 --> 00:14:13,410
you some better failure probably

00:14:11,520 --> 00:14:15,810
properties when failing back to the

00:14:13,410 --> 00:14:19,650
first side although it's optional to

00:14:15,810 --> 00:14:22,650
configure them the coordinators in this

00:14:19,650 --> 00:14:23,910
scenario you'll notice that there's a

00:14:22,650 --> 00:14:26,460
third region here that has some

00:14:23,910 --> 00:14:28,950
coordinators in it the coordinators as

00:14:26,460 --> 00:14:32,670
you'll recall are relying on quorum

00:14:28,950 --> 00:14:35,790
based logic to do to provide like

00:14:32,670 --> 00:14:38,460
failure properties so we need a majority

00:14:35,790 --> 00:14:40,590
of them alive and so if we want the

00:14:38,460 --> 00:14:42,510
failure property of surviving one one

00:14:40,590 --> 00:14:45,210
region failure plus one additional

00:14:42,510 --> 00:14:46,620
machine failure like three coordinators

00:14:45,210 --> 00:14:48,540
in three different regions is a nice way

00:14:46,620 --> 00:14:50,370
to accomplish that you can you know if

00:14:48,540 --> 00:14:52,050
you lose losing a region takes down

00:14:50,370 --> 00:14:53,880
three of your copies an additional

00:14:52,050 --> 00:14:57,440
machine will take you four and there's

00:14:53,880 --> 00:14:57,440
nine total so you still have a majority

00:14:57,860 --> 00:15:09,720
um so what's next here so foundation TB

00:15:06,180 --> 00:15:13,200
is like the six oh release has all of

00:15:09,720 --> 00:15:14,640
this in it in working today it can be it

00:15:13,200 --> 00:15:16,589
can you know fill over to one region

00:15:14,640 --> 00:15:18,660
fail back to another region however

00:15:16,589 --> 00:15:19,680
there's still you know some work to go

00:15:18,660 --> 00:15:21,330
and there's still some things we'd

00:15:19,680 --> 00:15:23,640
really like to add the current

00:15:21,330 --> 00:15:26,190
implementation only supports two regions

00:15:23,640 --> 00:15:28,560
I mentioned all the way back at the very

00:15:26,190 --> 00:15:29,670
start that one of the reasons you're

00:15:28,560 --> 00:15:31,470
going to want this feature is

00:15:29,670 --> 00:15:33,779
potentially to do local region to

00:15:31,470 --> 00:15:35,430
replicate data like look to

00:15:33,779 --> 00:15:37,230
do local reads in different places and

00:15:35,430 --> 00:15:39,569
so because we only have two regions

00:15:37,230 --> 00:15:40,949
support if you're using this for reading

00:15:39,569 --> 00:15:42,389
from lots of different places it's not

00:15:40,949 --> 00:15:47,490
quite there yet we're hoping to get

00:15:42,389 --> 00:15:49,470
there if also even though we think is a

00:15:47,490 --> 00:15:52,680
good trade-off between the availability

00:15:49,470 --> 00:15:55,050
zones and regions in terms of your log

00:15:52,680 --> 00:15:57,449
replication you you might be super

00:15:55,050 --> 00:15:59,490
paranoid and you might not care about a

00:15:57,449 --> 00:16:00,899
40 millisecond commit latency so you

00:15:59,490 --> 00:16:02,519
might want to synchronously replicate

00:16:00,899 --> 00:16:05,399
those logs across the network instead of

00:16:02,519 --> 00:16:09,139
doing the async plan I showed so that'll

00:16:05,399 --> 00:16:11,639
come to probably in the next release ah

00:16:09,139 --> 00:16:15,499
the other caveat the other big caveat

00:16:11,639 --> 00:16:17,879
here is there's always the potential

00:16:15,499 --> 00:16:20,160
that you lose an entire region or that

00:16:17,879 --> 00:16:23,009
in which case in the previous in this

00:16:20,160 --> 00:16:25,379
design here if you lose both like all of

00:16:23,009 --> 00:16:27,449
your key logs simultaneously you may

00:16:25,379 --> 00:16:29,399
want to switch to the other side even if

00:16:27,449 --> 00:16:31,559
that means data loss so this is

00:16:29,399 --> 00:16:33,420
equivalent to the FD BDR trade-off

00:16:31,559 --> 00:16:35,160
before so decision no one wants to make

00:16:33,420 --> 00:16:36,870
but we want to let you make the decision

00:16:35,160 --> 00:16:39,709
in the worst case scenario that like a

00:16:36,870 --> 00:16:42,480
meteor takes out something you know like

00:16:39,709 --> 00:16:43,829
and there's probably easier ways that

00:16:42,480 --> 00:16:49,259
you lose both availability zones at the

00:16:43,829 --> 00:16:51,449
same time so that feature exists you

00:16:49,259 --> 00:16:53,490
from the CLI already in sick so however

00:16:51,449 --> 00:16:55,290
it's not tested to the same standard as

00:16:53,490 --> 00:16:57,389
the rest of the codebase there are some

00:16:55,290 --> 00:16:59,910
really rare correctness problems related

00:16:57,389 --> 00:17:01,829
to the fact that if a machine comes back

00:16:59,910 --> 00:17:03,360
alive in the region you thought was dead

00:17:01,829 --> 00:17:05,370
at the same time you're doing the

00:17:03,360 --> 00:17:06,959
command it could possibly like have a

00:17:05,370 --> 00:17:08,699
corrupt view of the world

00:17:06,959 --> 00:17:10,199
so in any case I want to throw it out

00:17:08,699 --> 00:17:13,740
there because we're super paranoid about

00:17:10,199 --> 00:17:17,730
these things and but probably it's safe

00:17:13,740 --> 00:17:20,819
but be careful the last thing to talk

00:17:17,730 --> 00:17:23,010
about is um right throughput is

00:17:20,819 --> 00:17:25,559
currently going to be reduced when a

00:17:23,010 --> 00:17:29,100
region is filled so while a region is

00:17:25,559 --> 00:17:31,080
down we enter a performance mode where

00:17:29,100 --> 00:17:32,580
the transaction logs are having to queue

00:17:31,080 --> 00:17:34,230
up all of the data that's bound for the

00:17:32,580 --> 00:17:36,030
other region and currently the

00:17:34,230 --> 00:17:38,909
transaction logs just aren't haven't

00:17:36,030 --> 00:17:40,980
been optimized for this use case so what

00:17:38,909 --> 00:17:42,149
this means is that generally when a

00:17:40,980 --> 00:17:44,490
region goes down in this configuration

00:17:42,149 --> 00:17:46,169
you're gonna have to just like with the

00:17:44,490 --> 00:17:47,940
three data center mode you know what

00:17:46,169 --> 00:17:49,590
then if you have a high rate bandwidth

00:17:47,940 --> 00:17:51,749
workload you're gonna have to configure

00:17:49,590 --> 00:17:54,539
it to drop that remote that remote

00:17:51,749 --> 00:17:56,100
region pretty quickly so that you can

00:17:54,539 --> 00:18:02,700
flush out the log data that's being

00:17:56,100 --> 00:18:06,539
queued up for that region the last thing

00:18:02,700 --> 00:18:08,940
I'll mention here is replicating to

00:18:06,539 --> 00:18:12,359
multiple regions adds a new thing to

00:18:08,940 --> 00:18:14,609
monitor which is that you really need to

00:18:12,359 --> 00:18:17,609
pay attention to how far behind one

00:18:14,609 --> 00:18:19,289
region is from the other region because

00:18:17,609 --> 00:18:20,759
the amount of data that's queued up in

00:18:19,289 --> 00:18:22,619
the log system down for the other side

00:18:20,759 --> 00:18:25,409
is going to determine what you have to

00:18:22,619 --> 00:18:26,909
copy on a region failure so if this

00:18:25,409 --> 00:18:28,830
thing gets out of hand and is an hour

00:18:26,909 --> 00:18:30,359
behind the other side well you're no

00:18:28,830 --> 00:18:32,249
longer safe against a region failure

00:18:30,359 --> 00:18:34,649
because you're gonna spend a long time

00:18:32,249 --> 00:18:38,039
copying that out at that hour of data

00:18:34,649 --> 00:18:40,200
before you can recover so it's really

00:18:38,039 --> 00:18:42,330
important operationally to monitor this

00:18:40,200 --> 00:18:44,279
lag and if it gets you no more than a

00:18:42,330 --> 00:18:53,260
few seconds to figure out what's going

00:18:44,279 --> 00:18:58,579
on so that's all I have thank you guys

00:18:53,260 --> 00:18:58,579

YouTube URL: https://www.youtube.com/watch?v=fN25ERr5nck


