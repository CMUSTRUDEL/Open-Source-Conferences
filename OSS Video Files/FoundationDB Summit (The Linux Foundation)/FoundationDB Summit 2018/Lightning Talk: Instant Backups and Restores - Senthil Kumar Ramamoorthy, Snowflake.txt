Title: Lightning Talk: Instant Backups and Restores - Senthil Kumar Ramamoorthy, Snowflake
Publication date: 2018-12-14
Playlist: FoundationDB Summit 2018
Description: 
	Current backups and restore mechanism available for FDB can be quite resource and time intensive operation. Senthil, will present a mechanism to do instant backup and restores across FDB clusters that are equivalent. The mechanism relies on a snapshottable file-system made available to TLogs and Storage processes.
Captions: 
	00:00:00,030 --> 00:00:04,230
hi everyone my name is senthil

00:00:02,340 --> 00:00:08,189
ramamoorthy i am part of the foundation

00:00:04,230 --> 00:00:09,840
TV team at snowflake today I'm going to

00:00:08,189 --> 00:00:12,620
present about instant backup and restore

00:00:09,840 --> 00:00:15,210
feature that we have been developing

00:00:12,620 --> 00:00:16,049
first I'll start off with explaining the

00:00:15,210 --> 00:00:19,350
current backup and restore

00:00:16,049 --> 00:00:22,380
implementation and explain some of the

00:00:19,350 --> 00:00:24,840
challenges that we run into and the new

00:00:22,380 --> 00:00:27,300
approach that we take and how it solves

00:00:24,840 --> 00:00:29,880
some of our challenges and what are the

00:00:27,300 --> 00:00:32,520
caveats with that and we'll conclude

00:00:29,880 --> 00:00:38,300
with a quick live demo of the backup

00:00:32,520 --> 00:00:41,090
feature so the current backup

00:00:38,300 --> 00:00:44,579
implementation works as a logical level

00:00:41,090 --> 00:00:46,559
backup here is defined as a consistent

00:00:44,579 --> 00:00:49,860
copy of all the key values in the

00:00:46,559 --> 00:00:51,690
database and the consistent copy of the

00:00:49,860 --> 00:00:54,570
key values in the database are obtained

00:00:51,690 --> 00:00:58,199
by reading the entire database through

00:00:54,570 --> 00:00:59,850
the f DB stack there are much more

00:00:58,199 --> 00:01:01,800
details about the current backup

00:00:59,850 --> 00:01:05,369
implementation which I'm not going

00:01:01,800 --> 00:01:08,780
because of the time constraints the

00:01:05,369 --> 00:01:12,750
restore works by playing back the backup

00:01:08,780 --> 00:01:18,299
key values into their f DB cluster again

00:01:12,750 --> 00:01:20,610
through the f DB stack as you can see if

00:01:18,299 --> 00:01:22,530
you want to read the entire key value in

00:01:20,610 --> 00:01:25,650
the database through the f DB stack it

00:01:22,530 --> 00:01:29,670
consumes resources like CPU network disk

00:01:25,650 --> 00:01:33,840
across the f DB cluster and that impacts

00:01:29,670 --> 00:01:35,220
the foreground workload and the current

00:01:33,840 --> 00:01:39,659
restore mechanism also consumes

00:01:35,220 --> 00:01:42,180
resources on top of it it is slow the f

00:01:39,659 --> 00:01:44,939
DB 3 version that we use is extremely

00:01:42,180 --> 00:01:48,000
slow the future version that is supposed

00:01:44,939 --> 00:01:54,750
to get better but it still may not meet

00:01:48,000 --> 00:01:56,520
our performance requirements the impact

00:01:54,750 --> 00:01:58,290
of the current backup this is a slide

00:01:56,520 --> 00:02:01,229
that Marcus one of my teammates shared

00:01:58,290 --> 00:02:04,259
already the pink bar here represents the

00:02:01,229 --> 00:02:09,450
eye ops purely driven by the backup

00:02:04,259 --> 00:02:12,500
process this is from one of our

00:02:09,450 --> 00:02:12,500
production deployments

00:02:13,530 --> 00:02:18,700
so let's switch over to the new instant

00:02:17,020 --> 00:02:24,280
backup and restore and look at that

00:02:18,700 --> 00:02:26,950
approach in the instant backup and

00:02:24,280 --> 00:02:28,990
restore we don't look at backup from a

00:02:26,950 --> 00:02:32,440
logical standpoint we look at it from a

00:02:28,990 --> 00:02:35,260
physical standpoint so backup here is

00:02:32,440 --> 00:02:40,380
defined as a consistent copy of all the

00:02:35,260 --> 00:02:43,150
disk images specifically FDB takes a

00:02:40,380 --> 00:02:46,870
application level consistent snapshot of

00:02:43,150 --> 00:02:50,260
all the persistent data of all the FDB

00:02:46,870 --> 00:02:52,239
processes across the cluster and this

00:02:50,260 --> 00:02:54,910
collection of disk images form the

00:02:52,239 --> 00:02:56,950
backup and you can copy this disk images

00:02:54,910 --> 00:02:59,260
over attach it to another set of

00:02:56,950 --> 00:03:02,020
machines and then you can restore the

00:02:59,260 --> 00:03:04,540
cluster instantaneously so in this

00:03:02,020 --> 00:03:06,790
picture there's a cluster one with a set

00:03:04,540 --> 00:03:09,550
of FDB processes the gray boxes

00:03:06,790 --> 00:03:11,410
represents the FDB processes some of

00:03:09,550 --> 00:03:15,430
them a persistent data some of them

00:03:11,410 --> 00:03:17,170
don't have persistent data and when you

00:03:15,430 --> 00:03:19,900
issue a snapshot command which we

00:03:17,170 --> 00:03:22,180
introduced as part of this feature it

00:03:19,900 --> 00:03:24,130
creates a copy of the disk images the

00:03:22,180 --> 00:03:26,350
blue storage boxes that popped out or

00:03:24,130 --> 00:03:28,090
the snapshot disk images that we that

00:03:26,350 --> 00:03:31,540
came out of after as part of the

00:03:28,090 --> 00:03:33,430
snapshot operation these blue disk

00:03:31,540 --> 00:03:37,570
images if you care and get a copy of

00:03:33,430 --> 00:03:39,519
them those are the backup and the

00:03:37,570 --> 00:03:42,400
cluster - it's like a vanilla cluster

00:03:39,519 --> 00:03:45,280
which with no disk images attached to it

00:03:42,400 --> 00:03:46,360
you can copy this disks over there and

00:03:45,280 --> 00:03:48,549
attach to it

00:03:46,360 --> 00:03:50,560
and you can bring up the cluster of

00:03:48,549 --> 00:03:52,030
course you need to modify the FDB dot

00:03:50,560 --> 00:03:53,620
cluster and phone division in DB dot

00:03:52,030 --> 00:03:55,660
convict cetera a little bit of tooling

00:03:53,620 --> 00:03:58,540
is necessary but the restores are pretty

00:03:55,660 --> 00:04:00,430
much instantaneous for this feature to

00:03:58,540 --> 00:04:01,870
work you need either a snapshot double

00:04:00,430 --> 00:04:07,900
file system or a snapshot double block

00:04:01,870 --> 00:04:09,070
storage so this is pretty much the text

00:04:07,900 --> 00:04:14,650
of what I explained in the previous

00:04:09,070 --> 00:04:18,579
slide so I'll just skip this so how does

00:04:14,650 --> 00:04:21,609
f DB create a consistent snapshot across

00:04:18,579 --> 00:04:23,140
the f DB cluster for that let us go

00:04:21,609 --> 00:04:25,560
through the flow of the snapshot create

00:04:23,140 --> 00:04:27,180
operation

00:04:25,560 --> 00:04:31,410
so this is a standard of difficult

00:04:27,180 --> 00:04:33,510
architecture and there are really three

00:04:31,410 --> 00:04:35,300
persistence data three sets of

00:04:33,510 --> 00:04:37,560
persistent data in the cluster the

00:04:35,300 --> 00:04:39,360
coordinator which stores the information

00:04:37,560 --> 00:04:42,570
about where the master is or the tea

00:04:39,360 --> 00:04:44,850
logs etcetera and the transaction logs

00:04:42,570 --> 00:04:47,130
which keeps the mutations and the

00:04:44,850 --> 00:04:49,110
storage servers that keep the in storage

00:04:47,130 --> 00:04:50,960
of all the key values its previous

00:04:49,110 --> 00:04:55,440
because I've already gone through this

00:04:50,960 --> 00:04:57,330
so the client initially sends a request

00:04:55,440 --> 00:04:59,669
to snap the coordinators to the proxy

00:04:57,330 --> 00:05:01,890
which gets forwarded to the coordinators

00:04:59,669 --> 00:05:04,560
the coordinators when they see this

00:05:01,890 --> 00:05:06,720
request they go on snapshot their own

00:05:04,560 --> 00:05:08,910
file system or block storage based on

00:05:06,720 --> 00:05:10,560
the configuration so basically the blue

00:05:08,910 --> 00:05:13,760
boxes that emerged out of the snapshot

00:05:10,560 --> 00:05:17,160
dead disk images of this coordinator

00:05:13,760 --> 00:05:20,430
once that is complete the client sends a

00:05:17,160 --> 00:05:23,070
snap create command to snap the tea logs

00:05:20,430 --> 00:05:25,820
in the storage this snap create is

00:05:23,070 --> 00:05:28,370
nothing but a specialized a transaction

00:05:25,820 --> 00:05:31,830
except that it is different in two ways

00:05:28,370 --> 00:05:33,870
that this snap create command goes to

00:05:31,830 --> 00:05:34,470
every T log and every storage server in

00:05:33,870 --> 00:05:36,510
the system

00:05:34,470 --> 00:05:39,240
the second way it is different is that

00:05:36,510 --> 00:05:41,910
venti logs and storage see this special

00:05:39,240 --> 00:05:44,640
command they respond by creating a

00:05:41,910 --> 00:05:48,750
snapshot of their disks or the file

00:05:44,640 --> 00:05:51,030
system so in this picture you see the

00:05:48,750 --> 00:05:53,940
request goes to the T log and it creates

00:05:51,030 --> 00:05:55,320
a snap of their disk images and then it

00:05:53,940 --> 00:05:57,810
sends the success to the client and

00:05:55,320 --> 00:06:00,630
shortly after the storage is pulled the

00:05:57,810 --> 00:06:03,030
snap create and they snapshot themselves

00:06:00,630 --> 00:06:05,820
so now this all this blue disk image is

00:06:03,030 --> 00:06:08,180
put together make the snapshot and you

00:06:05,820 --> 00:06:10,800
can bring it back as further restore

00:06:08,180 --> 00:06:14,550
since the snap create is a transaction

00:06:10,800 --> 00:06:17,700
that is a version attached to it and the

00:06:14,550 --> 00:06:20,010
storage T log all of them will execute

00:06:17,700 --> 00:06:22,710
the snap create at the exactly the same

00:06:20,010 --> 00:06:24,900
version of the database that gives a

00:06:22,710 --> 00:06:30,600
point in time consistent image of all

00:06:24,900 --> 00:06:32,940
the disk images in the system now the

00:06:30,600 --> 00:06:36,599
three parts to this the snap create is

00:06:32,940 --> 00:06:40,650
very cheap we saw that it is as cheap as

00:06:36,599 --> 00:06:42,510
transacting a key value to the database

00:06:40,650 --> 00:06:45,449
the second is copying of the disk images

00:06:42,510 --> 00:06:47,699
this does take some resources but it is

00:06:45,449 --> 00:06:49,350
significantly cheaper to copy the disk

00:06:47,699 --> 00:06:51,060
images at the lowest level at the file

00:06:49,350 --> 00:06:54,090
system or disk level rather go through

00:06:51,060 --> 00:06:56,160
the entire FDB stack and this can be

00:06:54,090 --> 00:06:57,600
highly paralyzed and which will reduce

00:06:56,160 --> 00:07:01,800
the impact on the foreground and the

00:06:57,600 --> 00:07:04,680
user workload on top of this many cloud

00:07:01,800 --> 00:07:08,310
providers give you an option to snapshot

00:07:04,680 --> 00:07:10,710
the disk images block storage and have

00:07:08,310 --> 00:07:12,510
it have a copy of it available without

00:07:10,710 --> 00:07:14,850
you spending any additional resources

00:07:12,510 --> 00:07:16,440
from the production cluster and the

00:07:14,850 --> 00:07:18,120
restores are instantaneous because you

00:07:16,440 --> 00:07:20,700
have the disk images you just attach to

00:07:18,120 --> 00:07:25,050
your line any machine set of missions

00:07:20,700 --> 00:07:28,440
and it is as much as the cost is like

00:07:25,050 --> 00:07:30,690
recovering a cluster the disadvantages

00:07:28,440 --> 00:07:33,300
are dependency on snapshot double file

00:07:30,690 --> 00:07:34,950
system and second it's somewhat the

00:07:33,300 --> 00:07:38,940
production and the backup cluster has to

00:07:34,950 --> 00:07:41,960
be somewhat homogeneous now I'll switch

00:07:38,940 --> 00:07:41,960
over to the demo

00:07:48,330 --> 00:07:53,410
then was it this is instant back up

00:07:50,770 --> 00:07:56,920
really so what I'm going to I have a

00:07:53,410 --> 00:08:02,770
cluster one which is you know I'm going

00:07:56,920 --> 00:08:05,920
to start a workload on this and I'm

00:08:02,770 --> 00:08:07,770
going to watch the the workload to make

00:08:05,920 --> 00:08:11,260
sure that the transactions are starting

00:08:07,770 --> 00:08:14,260
there is a thing that says three Dre

00:08:11,260 --> 00:08:17,410
transaction rates etcetera so now I see

00:08:14,260 --> 00:08:21,730
the transactions are progressing how I

00:08:17,410 --> 00:08:25,600
switch over I'll start a CLI and I will

00:08:21,730 --> 00:08:30,010
create a snapshot this response with the

00:08:25,600 --> 00:08:32,140
UID which basically is all the disk

00:08:30,010 --> 00:08:35,710
images are tagged with this particular

00:08:32,140 --> 00:08:41,230
UID and then I invoke a cluster copy on

00:08:35,710 --> 00:08:49,830
this one with that UID which copies this

00:08:41,230 --> 00:08:52,990
disk images okay to the cluster two as

00:08:49,830 --> 00:08:56,110
it is copying this workload is self

00:08:52,990 --> 00:08:58,960
describing we can validate this data on

00:08:56,110 --> 00:09:03,400
the second cluster where any script now

00:08:58,960 --> 00:09:05,050
I'm going to there is nothing to do here

00:09:03,400 --> 00:09:09,180
because the disk images have been copied

00:09:05,050 --> 00:09:09,180
I'm just going to start the cluster here

00:09:10,950 --> 00:09:17,890
okay and I'm going to watch for the

00:09:14,140 --> 00:09:23,500
cluster to come up okay

00:09:17,890 --> 00:09:25,240
this takes few tens of seconds and so

00:09:23,500 --> 00:09:26,980
the workload is self-describing so we

00:09:25,240 --> 00:09:28,990
can make sure it is it's a cyclic

00:09:26,980 --> 00:09:31,470
workload for the FDB developers that

00:09:28,990 --> 00:09:34,900
this the set of key values make a cycle

00:09:31,470 --> 00:09:37,780
and you can verify that the database is

00:09:34,900 --> 00:09:42,450
the integrity is still there so once it

00:09:37,780 --> 00:09:42,450
turns healthy I'm going to run a quick

00:09:48,470 --> 00:09:55,520
okay it's taking it's on time okay

00:09:52,170 --> 00:10:00,900
it turned now I do a quick get range and

00:09:55,520 --> 00:10:04,440
then I close to verify which will take a

00:10:00,900 --> 00:10:06,530
while so I'll leave it there and the

00:10:04,440 --> 00:10:09,360
integrity of the database gets verified

00:10:06,530 --> 00:10:11,940
so that's the conclusion of my talk and

00:10:09,360 --> 00:10:14,700
we are excited that to have an

00:10:11,940 --> 00:10:19,500
alternative backup implementation for

00:10:14,700 --> 00:10:21,350
the f DB operators to leverage okay

00:10:19,500 --> 00:10:25,350
thank you Center

00:10:21,350 --> 00:10:25,350

YouTube URL: https://www.youtube.com/watch?v=hxjAS_1_qbE


