Title: Solving Everyday Data Problems with FoundationDB - Ryan Worl, Ryan Worl
Publication date: 2018-12-14
Playlist: FoundationDB Summit 2018
Description: 
	Ryan will demonstrate how FoundationDB can be applied to solve real business problems today and how to map common infrastructure components like logs, tables, and indexes into a cohesive system within FoundationDB. His example applies these techniques to a problem ClickFunnels was facing in mid-2018, which required scanning millions of end-user data points for each of their tens of thousands of customers multiple times per hour. Through custom bitmap indexes built on top of FoundationDB, queries which simply wouldn't finish now take milliseconds, which enables new use cases never thought possible.
Captions: 
	00:00:05,930 --> 00:00:10,860
all right I think everyone's about

00:00:08,130 --> 00:00:12,809
settled now so my name is Ryan Worrell

00:00:10,860 --> 00:00:14,610
and I'm here to talk to you about

00:00:12,809 --> 00:00:17,310
solving everyday data problems with

00:00:14,610 --> 00:00:20,090
foundation DB so everyone so far this

00:00:17,310 --> 00:00:23,189
morning is led off with a story and

00:00:20,090 --> 00:00:24,930
there's have started from like before

00:00:23,189 --> 00:00:27,119
the acquisition I'm the first person

00:00:24,930 --> 00:00:28,560
speaking today who didn't really know

00:00:27,119 --> 00:00:31,140
anything about foundation DB until after

00:00:28,560 --> 00:00:32,309
the acquisition and I've been starting

00:00:31,140 --> 00:00:37,050
to work with it in the open source

00:00:32,309 --> 00:00:39,750
during the last eight months so a little

00:00:37,050 --> 00:00:42,989
bit about me I am an independent

00:00:39,750 --> 00:00:45,539
software engineer my primary client

00:00:42,989 --> 00:00:46,140
right now is a company called

00:00:45,539 --> 00:00:49,170
clickfunnels

00:00:46,140 --> 00:00:51,420
they make web page builder and marketing

00:00:49,170 --> 00:00:54,120
automation software that's integrated

00:00:51,420 --> 00:00:55,530
together so entrepreneurs can sell their

00:00:54,120 --> 00:00:58,170
products online without having to know a

00:00:55,530 --> 00:01:02,940
ton about websites and technology and

00:00:58,170 --> 00:01:03,899
thing like that things like that they

00:01:02,940 --> 00:01:07,740
have over seventy thousand customers

00:01:03,899 --> 00:01:09,600
they've processed almost two billion

00:01:07,740 --> 00:01:12,450
dollars of payments directly through

00:01:09,600 --> 00:01:16,920
their you know direct integrations in

00:01:12,450 --> 00:01:20,490
the software and there are billions of

00:01:16,920 --> 00:01:23,369
rows of ltp data in there in their

00:01:20,490 --> 00:01:25,680
database which is Amazon or my sequel

00:01:23,369 --> 00:01:27,270
and I'm very happy that they let me come

00:01:25,680 --> 00:01:27,930
to this conference and and talk about

00:01:27,270 --> 00:01:30,740
all this

00:01:27,930 --> 00:01:35,040
entering stuff is very gracious to them

00:01:30,740 --> 00:01:38,970
so for this talk I want to cover kind of

00:01:35,040 --> 00:01:41,790
the the status quo today in companies

00:01:38,970 --> 00:01:43,229
that are running at scale and the

00:01:41,790 --> 00:01:46,320
proliferation of different data systems

00:01:43,229 --> 00:01:47,460
that you know that comes about after you

00:01:46,320 --> 00:01:48,540
know you add one thing then you add

00:01:47,460 --> 00:01:52,320
another because you have to solve these

00:01:48,540 --> 00:01:54,750
different problems over time I want to

00:01:52,320 --> 00:01:58,009
describe what I mean by everyday data

00:01:54,750 --> 00:02:01,520
problems from the title this talk and

00:01:58,009 --> 00:02:03,630
why foundation DB can be a solution to

00:02:01,520 --> 00:02:06,270
some of these data problems at your

00:02:03,630 --> 00:02:08,520
company and to motivate that I'm going

00:02:06,270 --> 00:02:10,520
to show you the recent data problem that

00:02:08,520 --> 00:02:13,709
I came up with clickfunnels

00:02:10,520 --> 00:02:16,409
that was you know enabling

00:02:13,709 --> 00:02:19,079
if solving it would enable lots of great

00:02:16,409 --> 00:02:20,579
new features for them and at the end I'm

00:02:19,079 --> 00:02:22,379
gonna go cover a little bit about how

00:02:20,579 --> 00:02:23,700
foundation TV you can be a solution to

00:02:22,379 --> 00:02:25,680
your data problems at your company and

00:02:23,700 --> 00:02:28,920
just like general things you should know

00:02:25,680 --> 00:02:30,780
about using it if you're coming in cold

00:02:28,920 --> 00:02:34,500
you know don't not knowing anything

00:02:30,780 --> 00:02:36,810
about it so the the status quo today is

00:02:34,500 --> 00:02:39,659
that most apps start out uncomplicated

00:02:36,810 --> 00:02:41,549
you don't start out by building an

00:02:39,659 --> 00:02:44,489
architecture that has you know ten

00:02:41,549 --> 00:02:47,159
different data systems in it usually

00:02:44,489 --> 00:02:49,799
just like a database and a hue and that

00:02:47,159 --> 00:02:52,470
gets you pretty far but five years later

00:02:49,799 --> 00:02:55,650
you end up with a dozen systems in

00:02:52,470 --> 00:02:59,730
production and you got a run of all it's

00:02:55,650 --> 00:03:01,799
not a good time so when I when I say

00:02:59,730 --> 00:03:03,870
everyday data problems this is what I

00:03:01,799 --> 00:03:05,159
really mean like there are specific

00:03:03,870 --> 00:03:08,069
things that come up in your company and

00:03:05,159 --> 00:03:10,170
you just rip tools off the shelf and you

00:03:08,069 --> 00:03:11,519
know like how did you end up in this

00:03:10,170 --> 00:03:14,639
with this architecture nobody thought

00:03:11,519 --> 00:03:16,439
about it it just emerged over time this

00:03:14,639 --> 00:03:18,239
is a pretty old picture right now some

00:03:16,439 --> 00:03:19,739
of the technologies are a bit dated

00:03:18,239 --> 00:03:21,629
maybe you wouldn't pick them anymore for

00:03:19,739 --> 00:03:23,699
a specific thing but it's still

00:03:21,629 --> 00:03:29,489
representative of how things were today

00:03:23,699 --> 00:03:31,260
in in big companies so over the last you

00:03:29,489 --> 00:03:33,150
know five years or so a lot of companies

00:03:31,260 --> 00:03:36,090
are moving into microservices

00:03:33,150 --> 00:03:37,590
architectures and this might have good

00:03:36,090 --> 00:03:39,510
benefits for your team in terms of being

00:03:37,590 --> 00:03:43,109
able to scale like the number of

00:03:39,510 --> 00:03:44,989
programmers working on a product but you

00:03:43,109 --> 00:03:48,419
can make the situation worse very easily

00:03:44,989 --> 00:03:50,129
by by breaking gear your model if that

00:03:48,419 --> 00:03:51,930
had you maybe had transactions with your

00:03:50,129 --> 00:03:56,419
sequel database and now you just don't

00:03:51,930 --> 00:04:01,919
and what you can do so you can end up

00:03:56,419 --> 00:04:03,780
reimplemented that thing like this where

00:04:01,919 --> 00:04:05,909
all you just have the same data systems

00:04:03,780 --> 00:04:10,859
under the hood it's now just worse

00:04:05,909 --> 00:04:12,269
because there's more of them so you know

00:04:10,859 --> 00:04:14,760
that I know that's a funny picture but

00:04:12,269 --> 00:04:16,829
like why is this actually a problem the

00:04:14,760 --> 00:04:18,900
the biggest most direct one I think

00:04:16,829 --> 00:04:20,880
that's applicable to big companies is

00:04:18,900 --> 00:04:24,840
you have to run this thing you got to

00:04:20,880 --> 00:04:27,270
pay people to run it and whether you use

00:04:24,840 --> 00:04:29,569
a managed service or you run it yourself

00:04:27,270 --> 00:04:33,330
you're still paying for it at some level

00:04:29,569 --> 00:04:35,430
the the more direct financial costs for

00:04:33,330 --> 00:04:37,530
people that you know maybe they they

00:04:35,430 --> 00:04:38,669
have a bunch of people they hired to run

00:04:37,530 --> 00:04:39,569
these things anyway so they don't care

00:04:38,669 --> 00:04:41,909
about the salaries that's not how

00:04:39,569 --> 00:04:44,300
they're thinking about it you still pay

00:04:41,909 --> 00:04:46,620
for duplicated data if you have like

00:04:44,300 --> 00:04:49,319
triple replicated systems for high

00:04:46,620 --> 00:04:51,180
availability and then you have you know

00:04:49,319 --> 00:04:53,280
ten of them that all have triple

00:04:51,180 --> 00:04:58,500
replicated all of the data you're paying

00:04:53,280 --> 00:05:01,139
for a lot of storage the the insidious

00:04:58,500 --> 00:05:03,720
one is the development cost that comes

00:05:01,139 --> 00:05:05,849
in the future of when you introduce

00:05:03,720 --> 00:05:07,259
these tools in your architecture and it

00:05:05,849 --> 00:05:08,699
just makes it more complicated to

00:05:07,259 --> 00:05:12,810
develop features over time and you end

00:05:08,699 --> 00:05:16,169
up going slower where this where this

00:05:12,810 --> 00:05:18,569
you know people trade off things in

00:05:16,169 --> 00:05:20,310
their you know consistency or or a de

00:05:18,569 --> 00:05:23,340
Missa T by introducing all these new

00:05:20,310 --> 00:05:25,289
systems and from my experience I worked

00:05:23,340 --> 00:05:26,610
with a few different companies that end

00:05:25,289 --> 00:05:28,819
up with this this problem is that a

00:05:26,610 --> 00:05:32,099
diversity is just like ignored and

00:05:28,819 --> 00:05:34,349
people just gloss over it and they they

00:05:32,099 --> 00:05:35,719
forget that like oh if I push a job into

00:05:34,349 --> 00:05:38,340
the job queue and then in the same

00:05:35,719 --> 00:05:40,380
request handler I have to write into the

00:05:38,340 --> 00:05:44,099
sequel database they just like don't do

00:05:40,380 --> 00:05:45,870
anything about it and this can end up

00:05:44,099 --> 00:05:47,669
with corrupt data and I've I've seen

00:05:45,870 --> 00:05:51,360
this like in the real world in multiple

00:05:47,669 --> 00:05:52,560
places and that's you know it's not it's

00:05:51,360 --> 00:05:54,360
not good for your company to have a

00:05:52,560 --> 00:05:55,740
reputation of like losing or corrupting

00:05:54,360 --> 00:05:59,430
data for your customers so you should

00:05:55,740 --> 00:06:01,259
try to avoid that the the cost of a lot

00:05:59,430 --> 00:06:02,729
of people also ignore but is still there

00:06:01,259 --> 00:06:04,469
and it's becoming more prevalent the

00:06:02,729 --> 00:06:06,599
cost of securing these different systems

00:06:04,469 --> 00:06:09,060
because if you or if you're running

00:06:06,599 --> 00:06:11,580
multiple different data systems so you

00:06:09,060 --> 00:06:13,560
do a really good job of securing your

00:06:11,580 --> 00:06:15,659
front end sequel database but if all

00:06:13,560 --> 00:06:17,449
that same data is in another system that

00:06:15,659 --> 00:06:20,789
nobody thought about they gets hacked

00:06:17,449 --> 00:06:22,110
you know you still lose so the more

00:06:20,789 --> 00:06:27,779
systems you're running the more risk you

00:06:22,110 --> 00:06:30,389
have the a way that this manifests not

00:06:27,779 --> 00:06:31,889
the not security necessarily but a way

00:06:30,389 --> 00:06:33,360
that these problems manifest himself in

00:06:31,889 --> 00:06:36,029
the world is that error handling code is

00:06:33,360 --> 00:06:38,370
not exercised very often so when when

00:06:36,029 --> 00:06:39,930
areas do come up they can do really bad

00:06:38,370 --> 00:06:40,800
things like you know an error in a

00:06:39,930 --> 00:06:43,110
system that you don't really

00:06:40,800 --> 00:06:45,930
think about that much just say you know

00:06:43,110 --> 00:06:47,970
the safe like your Redis Goes Down and

00:06:45,930 --> 00:06:50,729
it's maybe not core to your architecture

00:06:47,970 --> 00:06:53,550
it's just a cache you may end up causing

00:06:50,729 --> 00:06:55,440
some kind of cascading failure and you

00:06:53,550 --> 00:06:57,110
know how often do you exercise all that

00:06:55,440 --> 00:07:03,300
error handling code do you know it works

00:06:57,110 --> 00:07:05,520
probably not so a lot of people will use

00:07:03,300 --> 00:07:07,620
manage cloud services nowadays to try to

00:07:05,520 --> 00:07:08,699
avoid some of the operational headaches

00:07:07,620 --> 00:07:12,210
that come with running a bunch of

00:07:08,699 --> 00:07:14,130
different data systems but they will not

00:07:12,210 --> 00:07:17,880
pick up the pieces for you if something

00:07:14,130 --> 00:07:20,430
breaks like they will reboot the VM and

00:07:17,880 --> 00:07:22,590
maybe you know update the software to

00:07:20,430 --> 00:07:24,780
the next inversion but if you lost data

00:07:22,590 --> 00:07:27,120
they can't fix that so if you're running

00:07:24,780 --> 00:07:29,430
a weak system that like doesn't have

00:07:27,120 --> 00:07:31,500
durability it does async replication and

00:07:29,430 --> 00:07:33,719
somebody's managing it for you it

00:07:31,500 --> 00:07:38,069
doesn't matter you'll see you can still

00:07:33,719 --> 00:07:40,860
lose data so why is foundation to be a

00:07:38,069 --> 00:07:42,360
solution to this problem where I could

00:07:40,860 --> 00:07:45,530
it be a solution to some of these

00:07:42,360 --> 00:07:48,000
problems at your company you get the

00:07:45,530 --> 00:07:50,039
ability to build anything that you want

00:07:48,000 --> 00:07:52,770
or anything that you'd need at your

00:07:50,039 --> 00:07:56,180
company and you can run multiple of

00:07:52,770 --> 00:07:57,900
these systems together in one cluster

00:07:56,180 --> 00:07:59,069
and one thing that people don't talk

00:07:57,900 --> 00:08:02,759
about a lot with foundation TV is that

00:07:59,069 --> 00:08:04,349
if you have solutions that are by their

00:08:02,759 --> 00:08:05,880
nature eventually consistent those are

00:08:04,349 --> 00:08:08,550
easier to build in foundation db2

00:08:05,880 --> 00:08:11,550
because you can you know if you get

00:08:08,550 --> 00:08:14,130
transactions inside the system you can

00:08:11,550 --> 00:08:16,020
build the the fancier things on top that

00:08:14,130 --> 00:08:17,340
are eventually consistent say like in

00:08:16,020 --> 00:08:20,069
the example I'm going to talk about

00:08:17,340 --> 00:08:22,199
we're replicating data from Aurora into

00:08:20,069 --> 00:08:24,719
Foundation DB so that you know it's

00:08:22,199 --> 00:08:28,830
eventually consistent but inside it's

00:08:24,719 --> 00:08:30,029
still really easy a program so as an

00:08:28,830 --> 00:08:32,370
example it's something that you you

00:08:30,029 --> 00:08:34,260
could do if you do transactions on the

00:08:32,370 --> 00:08:35,669
front end you take the changelog of the

00:08:34,260 --> 00:08:39,060
data and write it into some downstream

00:08:35,669 --> 00:08:43,140
the left database like snowflake for

00:08:39,060 --> 00:08:45,779
example you can do some of this with

00:08:43,140 --> 00:08:47,459
foundation BB if you take if you as you

00:08:45,779 --> 00:08:49,470
mutate data you write it to a change log

00:08:47,459 --> 00:08:52,500
and foundation DB and then you make like

00:08:49,470 --> 00:08:53,970
say a compressed column structure in the

00:08:52,500 --> 00:08:56,910
OLAP side you do a big tables

00:08:53,970 --> 00:08:58,050
and it's all in the same cluster depends

00:08:56,910 --> 00:08:59,759
on the size of the data if this is a

00:08:58,050 --> 00:09:05,040
good idea or not but is something that

00:08:59,759 --> 00:09:07,410
you can do so the the reason why I was

00:09:05,040 --> 00:09:08,720
interested in foundation DB is a product

00:09:07,410 --> 00:09:14,100
their problem I was working with

00:09:08,720 --> 00:09:15,300
clickfunnels to to solve the one of the

00:09:14,100 --> 00:09:17,910
most important features of the the

00:09:15,300 --> 00:09:20,189
clickfunnels platform is I called Smart

00:09:17,910 --> 00:09:22,259
lists and these are basically dynamic

00:09:20,189 --> 00:09:24,480
email lists that are based on user

00:09:22,259 --> 00:09:27,600
defined rules so the customer can come

00:09:24,480 --> 00:09:30,120
in and say I want a smart list based on

00:09:27,600 --> 00:09:33,689
people who bought this product who are

00:09:30,120 --> 00:09:36,990
on this static email list and who live

00:09:33,689 --> 00:09:39,180
in this state for example the the way

00:09:36,990 --> 00:09:41,370
that that works on the back end is we

00:09:39,180 --> 00:09:43,170
just we have these crazy sequel queries

00:09:41,370 --> 00:09:45,180
that get generated and they run against

00:09:43,170 --> 00:09:48,569
the the billions of rows in that OLTP

00:09:45,180 --> 00:09:51,360
database and their user facing portions

00:09:48,569 --> 00:09:53,550
and automated portions of this that do

00:09:51,360 --> 00:09:55,259
hundreds of queries a second to

00:09:53,550 --> 00:10:00,839
calculate these smart lists as things

00:09:55,259 --> 00:10:02,339
change this is a it's not exactly a

00:10:00,839 --> 00:10:04,800
query but it's like a representative

00:10:02,339 --> 00:10:07,110
query of what it would look like this is

00:10:04,800 --> 00:10:13,350
like for one rule and the where clause

00:10:07,110 --> 00:10:16,769
can get weird looking so to break the

00:10:13,350 --> 00:10:19,680
problem down the data volume is in the

00:10:16,769 --> 00:10:22,290
hundreds of gigabytes for the system

00:10:19,680 --> 00:10:24,660
that we're talking about and you were

00:10:22,290 --> 00:10:27,449
doing complex joins on a row oriented

00:10:24,660 --> 00:10:30,990
storage database so you can already tell

00:10:27,449 --> 00:10:33,240
us is not going well we have a lot of

00:10:30,990 --> 00:10:34,319
indexes but they can't satisfy every

00:10:33,240 --> 00:10:36,629
query because the queries are

00:10:34,319 --> 00:10:39,240
essentially user generated they can kind

00:10:36,629 --> 00:10:44,480
of do whatever they want with these

00:10:39,240 --> 00:10:47,670
rules and Aurora just recently released

00:10:44,480 --> 00:10:50,069
Amazon recently released for a parallel

00:10:47,670 --> 00:10:51,779
querying but you can't directly upgrade

00:10:50,069 --> 00:10:54,300
your cluster to that you have to do some

00:10:51,779 --> 00:10:56,129
downtime which is you know not something

00:10:54,300 --> 00:10:57,569
we want to do but so right now we're

00:10:56,129 --> 00:11:01,290
just stuck with single threaded queries

00:10:57,569 --> 00:11:03,120
in Aurora the when you get down to the

00:11:01,290 --> 00:11:07,240
core level in the product of of what

00:11:03,120 --> 00:11:10,029
we're doing we're doing set operations

00:11:07,240 --> 00:11:12,660
on you know sets of integers like anding

00:11:10,029 --> 00:11:16,029
and o-ring sets of of integers together

00:11:12,660 --> 00:11:19,269
to say like you are you match this rule

00:11:16,029 --> 00:11:20,519
or this rule and then and this rule that

00:11:19,269 --> 00:11:24,730
type of thing

00:11:20,519 --> 00:11:26,019
so if you if you study databases you

00:11:24,730 --> 00:11:31,689
might think you know the solution to

00:11:26,019 --> 00:11:33,819
this in app indexes so what we do what

00:11:31,689 --> 00:11:36,879
we're doing here is not directly like a

00:11:33,819 --> 00:11:41,170
bitmap index you'd see in relational

00:11:36,879 --> 00:11:43,420
database we're doing bitmaps for the for

00:11:41,170 --> 00:11:46,050
the individual rules I'm not here to

00:11:43,420 --> 00:11:48,339
cover what bitmap indexes are that's a

00:11:46,050 --> 00:11:51,660
longer talk but we use the roaring

00:11:48,339 --> 00:11:56,499
bitmap library which implements a

00:11:51,660 --> 00:11:58,929
compressed bitmap format for our use

00:11:56,499 --> 00:12:02,079
cases it ends up being two to three bits

00:11:58,929 --> 00:12:03,550
per set bit in the in the bitmap but in

00:12:02,079 --> 00:12:07,119
general its proportional to the number

00:12:03,550 --> 00:12:09,999
of bits that you set and the library

00:12:07,119 --> 00:12:11,980
implements vectorized operations for for

00:12:09,999 --> 00:12:13,929
doing the hands indoors on the sets and

00:12:11,980 --> 00:12:15,730
it's really fast if you get a big enough

00:12:13,929 --> 00:12:16,980
machine you're doing billions of

00:12:15,730 --> 00:12:19,569
operations a second

00:12:16,980 --> 00:12:21,339
you can parallel as this to multiple

00:12:19,569 --> 00:12:23,980
cores and distribute across multiple

00:12:21,339 --> 00:12:25,629
machines relatively easily when you're

00:12:23,980 --> 00:12:26,920
using foundation to be I should say if

00:12:25,629 --> 00:12:31,980
you're just doing it all yourself then

00:12:26,920 --> 00:12:35,529
it's obviously not is not as easy so the

00:12:31,980 --> 00:12:37,569
you know it's like I described what what

00:12:35,529 --> 00:12:39,639
we're gonna do with the bitmap indexes

00:12:37,569 --> 00:12:42,069
but what did we get out of it like

00:12:39,639 --> 00:12:43,509
what's the result here so are the

00:12:42,069 --> 00:12:45,999
biggest customers it takes multiple

00:12:43,509 --> 00:12:48,519
minutes to evaluate there the rules

00:12:45,999 --> 00:12:50,980
against the the list of customers that

00:12:48,519 --> 00:12:54,040
they have and it's under 100

00:12:50,980 --> 00:12:57,549
milliseconds with with it Maps so it's a

00:12:54,040 --> 00:12:59,470
it's a huge win the the new

00:12:57,549 --> 00:13:01,869
possibilities that this enables on the

00:12:59,470 --> 00:13:03,939
product side are things like evaluating

00:13:01,869 --> 00:13:05,769
rules on every customer website page

00:13:03,939 --> 00:13:08,110
view its now it's fast enough that we

00:13:05,769 --> 00:13:09,639
can do that and you can you can imagine

00:13:08,110 --> 00:13:11,470
a scenario where you want to dynamically

00:13:09,639 --> 00:13:14,350
change things on the page based on the

00:13:11,470 --> 00:13:16,749
valuation of those rules you can also

00:13:14,350 --> 00:13:18,610
show people in the UI as they're setting

00:13:16,749 --> 00:13:19,220
up rules how many people is just going

00:13:18,610 --> 00:13:21,170
to match

00:13:19,220 --> 00:13:22,910
like in real time as they're clicking

00:13:21,170 --> 00:13:26,629
around it can change the rules however

00:13:22,910 --> 00:13:29,750
they want and we can recalculate you can

00:13:26,629 --> 00:13:31,730
also adapt your stats and analytics in

00:13:29,750 --> 00:13:34,579
this format for example you can make

00:13:31,730 --> 00:13:37,459
bitmaps for every hour if you want to do

00:13:34,579 --> 00:13:38,509
stats hourly and you can still run all

00:13:37,459 --> 00:13:40,550
the same rules against them that you

00:13:38,509 --> 00:13:42,050
that I'm talking about before so for

00:13:40,550 --> 00:13:45,199
example if you wanted to do you new

00:13:42,050 --> 00:13:47,569
unique email opens per hour with a bunch

00:13:45,199 --> 00:13:49,189
of rules applied to them to say filter

00:13:47,569 --> 00:13:51,019
out people outside the United States

00:13:49,189 --> 00:13:53,209
just as as an example something you can

00:13:51,019 --> 00:13:55,970
do make a bitmap for every hour of the

00:13:53,209 --> 00:13:58,129
unique email opens with the set bits

00:13:55,970 --> 00:14:03,699
being the contacts that open the email

00:13:58,129 --> 00:14:06,259
and you can create a graph out of it the

00:14:03,699 --> 00:14:08,930
basically the to reduce it all down we

00:14:06,259 --> 00:14:11,120
can do whatever we want with us now and

00:14:08,930 --> 00:14:15,050
the pages will load instantly for even

00:14:11,120 --> 00:14:16,939
our largest customers so how do we use

00:14:15,050 --> 00:14:18,860
foundation to be to get there I should

00:14:16,939 --> 00:14:20,810
say this is not in production today I'm

00:14:18,860 --> 00:14:23,649
talking about a prototype system was

00:14:20,810 --> 00:14:26,449
still working to get it into production

00:14:23,649 --> 00:14:27,949
so the the first step is to replicate

00:14:26,449 --> 00:14:30,259
the binary log from Aurora into

00:14:27,949 --> 00:14:32,149
Foundation DB this is pretty

00:14:30,259 --> 00:14:34,430
straightforward to do the the right

00:14:32,149 --> 00:14:36,290
volume is not high enough for us to need

00:14:34,430 --> 00:14:37,310
to worry about charting and by sharding

00:14:36,290 --> 00:14:39,470
I mean writing data at different

00:14:37,310 --> 00:14:43,639
portions of the key space to not hit one

00:14:39,470 --> 00:14:45,319
storage server so what I'm gonna show is

00:14:43,639 --> 00:14:47,389
an example of how you could do a log

00:14:45,319 --> 00:14:48,560
structure if you needed to you know do

00:14:47,389 --> 00:14:50,269
exactly what we're saying like replicate

00:14:48,560 --> 00:14:54,709
data out of another database in a

00:14:50,269 --> 00:14:56,779
foundation DB you you pick a prefix that

00:14:54,709 --> 00:14:58,670
you want to represent your log if you

00:14:56,779 --> 00:15:00,500
don't have more than one log different

00:14:58,670 --> 00:15:02,149
prefix and you can use version stamp

00:15:00,500 --> 00:15:04,670
operations which allow you to write data

00:15:02,149 --> 00:15:08,240
in order into foundation DB without

00:15:04,670 --> 00:15:10,370
needing to like coordinate incrementing

00:15:08,240 --> 00:15:13,189
some kind of counter key because it uses

00:15:10,370 --> 00:15:14,870
the commit version of the transaction to

00:15:13,189 --> 00:15:17,660
and it sticks that into the key

00:15:14,870 --> 00:15:21,519
dynamically for you and we just write

00:15:17,660 --> 00:15:21,519
the data from the bin log as the value

00:15:21,740 --> 00:15:28,730
so because these bitmaps can be big if

00:15:26,930 --> 00:15:30,650
you have lots of bits set on them you

00:15:28,730 --> 00:15:33,920
need to chunk it up into smaller

00:15:30,650 --> 00:15:34,550
segments so say 2 to the 18th that's a

00:15:33,920 --> 00:15:35,450
good size

00:15:34,550 --> 00:15:38,030
you just want to know that it will

00:15:35,450 --> 00:15:41,690
always fit within a single value under

00:15:38,030 --> 00:15:42,860
100 kilobyte value limit so this gets a

00:15:41,690 --> 00:15:43,940
little more complicated and I'm not

00:15:42,860 --> 00:15:46,010
gonna go into it but basically we just

00:15:43,940 --> 00:15:48,310
have to evaluate every write against the

00:15:46,010 --> 00:15:51,350
rules because the rules it can be

00:15:48,310 --> 00:15:54,460
complicated just like the code is not

00:15:51,350 --> 00:15:56,750
that interesting but you can imagine

00:15:54,460 --> 00:15:59,660
importantly we only use one writer at a

00:15:56,750 --> 00:16:01,310
time so there's no contention among the

00:15:59,660 --> 00:16:02,720
different writes going on we could scale

00:16:01,310 --> 00:16:05,630
this a different way by saying you get

00:16:02,720 --> 00:16:06,740
one writer per per user but as I saying

00:16:05,630 --> 00:16:07,700
the the right volume isn't high enough

00:16:06,740 --> 00:16:11,080
so you don't worry about that right now

00:16:07,700 --> 00:16:13,220
because setting the bits is really fast

00:16:11,080 --> 00:16:16,000
this is an example of how you'd store a

00:16:13,220 --> 00:16:20,030
large object among many different keys

00:16:16,000 --> 00:16:22,550
so the the bitmap is identified by a

00:16:20,030 --> 00:16:26,030
rule which is just the idea of a rule in

00:16:22,550 --> 00:16:29,180
the in the database and each chunk gets

00:16:26,030 --> 00:16:32,720
an offset from 0 that is like the 2 to

00:16:29,180 --> 00:16:34,880
the 18th chunk of what what the bitmap

00:16:32,720 --> 00:16:38,890
is and the value you store in the key is

00:16:34,880 --> 00:16:41,180
the compressed chunk of the bitmap so

00:16:38,890 --> 00:16:42,620
this is the the fun part is how do you

00:16:41,180 --> 00:16:45,950
read it how do you do the calculations

00:16:42,620 --> 00:16:47,780
so you do a range read for for every

00:16:45,950 --> 00:16:50,750
chunk for each rule that you want to

00:16:47,780 --> 00:16:54,110
evaluate and you paralyze by reading

00:16:50,750 --> 00:16:57,050
different ranges and this is just like a

00:16:54,110 --> 00:16:59,030
classic fork/join pattern that you've

00:16:57,050 --> 00:17:02,630
learned if you did she done parallel

00:16:59,030 --> 00:17:05,140
programming before so the in this

00:17:02,630 --> 00:17:08,600
example core one is gonna read chunks

00:17:05,140 --> 00:17:10,880
one chunk one for rule one and two and

00:17:08,600 --> 00:17:13,160
then a different core can go read chunk

00:17:10,880 --> 00:17:15,440
and four one and two and then you know

00:17:13,160 --> 00:17:17,990
they individually do the operations

00:17:15,440 --> 00:17:20,390
required for that for the rules and then

00:17:17,990 --> 00:17:25,160
they combine the data at the end into a

00:17:20,390 --> 00:17:27,620
resulting bitmap so yeah the the results

00:17:25,160 --> 00:17:29,360
of this this prototype real world

00:17:27,620 --> 00:17:30,680
queries for like representative data for

00:17:29,360 --> 00:17:32,690
our customers are under a hundred

00:17:30,680 --> 00:17:34,659
milliseconds for the smaller customers

00:17:32,690 --> 00:17:37,570
it's a lot less than that

00:17:34,659 --> 00:17:41,349
that can run on a single large box today

00:17:37,570 --> 00:17:43,269
and you know it's a it's got a lot of

00:17:41,349 --> 00:17:45,129
cores and it's doing the calculations in

00:17:43,269 --> 00:17:46,929
parallel but you could also distribute

00:17:45,129 --> 00:17:48,669
this among multiple machines later with

00:17:46,929 --> 00:17:51,849
very little extra work if you had a

00:17:48,669 --> 00:17:54,369
really big bitmap thankfully we don't we

00:17:51,849 --> 00:17:55,809
don't need to do that right now it's

00:17:54,369 --> 00:17:57,609
really easy to get high availability out

00:17:55,809 --> 00:17:59,080
of this because you just put a little

00:17:57,609 --> 00:18:04,929
balancer in front use an auto scaling

00:17:59,080 --> 00:18:06,879
group I heard all the the point that's

00:18:04,929 --> 00:18:10,029
really important I think for people that

00:18:06,879 --> 00:18:12,519
are coming new to foundation DB this is

00:18:10,029 --> 00:18:15,460
under 3,000 lines of JavaScript using

00:18:12,519 --> 00:18:19,559
the the node bindings and and the wrong

00:18:15,460 --> 00:18:21,369
a bitmap library it's very easy to get a

00:18:19,559 --> 00:18:25,450
solution that provides a lot of value

00:18:21,369 --> 00:18:27,399
with little code so if you were going to

00:18:25,450 --> 00:18:30,519
decide to use foundation you be at your

00:18:27,399 --> 00:18:31,570
company one thing one thing I've heard a

00:18:30,519 --> 00:18:33,129
lot about and that's been talked about

00:18:31,570 --> 00:18:36,009
it today is the performance to

00:18:33,129 --> 00:18:40,419
Foundation DB it's it's very easy to

00:18:36,009 --> 00:18:41,679
create you know a simplistic transaction

00:18:40,419 --> 00:18:43,690
in foundation to be that performs poorly

00:18:41,679 --> 00:18:46,450
because you're saying doing all the the

00:18:43,690 --> 00:18:48,700
reads sequentially you you need to

00:18:46,450 --> 00:18:51,009
understand the concurrency potential of

00:18:48,700 --> 00:18:53,799
your problem and do as many reads

00:18:51,009 --> 00:18:55,830
concurrently as you as you can you also

00:18:53,799 --> 00:18:57,879
need to make sure you don't

00:18:55,830 --> 00:19:01,690
unintentionally coordinate and cause

00:18:57,879 --> 00:19:04,419
conflicts some examples of that in a

00:19:01,690 --> 00:19:05,529
second the the way that this works is

00:19:04,419 --> 00:19:09,099
you need to break down the critical path

00:19:05,529 --> 00:19:09,879
of your transaction and you know make

00:19:09,099 --> 00:19:13,809
sure you can do as many things

00:19:09,879 --> 00:19:15,940
concurrently as possible this is like

00:19:13,809 --> 00:19:18,220
just because of Dell's law if you're

00:19:15,940 --> 00:19:19,840
going to do things in parallel the more

00:19:18,220 --> 00:19:24,869
you can do in parallel the greater speed

00:19:19,840 --> 00:19:27,820
up you get so this is an example that

00:19:24,869 --> 00:19:29,799
made the rounds a little while ago from

00:19:27,820 --> 00:19:32,710
a company called active sphere they

00:19:29,799 --> 00:19:36,129
created a high contention allocator

00:19:32,710 --> 00:19:39,820
class it just allocates short numeric

00:19:36,129 --> 00:19:44,379
prefixes to like that are unique just to

00:19:39,820 --> 00:19:46,960
save space in the keys and the naive

00:19:44,379 --> 00:19:48,370
implementation tops out at about 275

00:19:46,960 --> 00:19:50,350
allocations the second

00:19:48,370 --> 00:19:52,659
and the latency grows as you add more

00:19:50,350 --> 00:19:55,120
and more concurrent clients because this

00:19:52,659 --> 00:19:56,919
the naive implementation coordinates and

00:19:55,120 --> 00:20:00,370
only essentially allows one operation to

00:19:56,919 --> 00:20:02,490
happen at any given time but if you

00:20:00,370 --> 00:20:05,500
relax the constraints a little bit and

00:20:02,490 --> 00:20:08,020
you you model a concurrency a bit better

00:20:05,500 --> 00:20:09,730
you can get you know more or less linear

00:20:08,020 --> 00:20:11,830
scalability out of it and the latency is

00:20:09,730 --> 00:20:15,279
consistent even at higher concurrency

00:20:11,830 --> 00:20:20,190
and the the link that is down there in

00:20:15,279 --> 00:20:22,809
the corner has the full explanation so

00:20:20,190 --> 00:20:25,270
the the documentation covers how to do

00:20:22,809 --> 00:20:28,750
stuff like tables logs queues and

00:20:25,270 --> 00:20:31,110
secondary indexes very well and it's

00:20:28,750 --> 00:20:33,640
also just not a lot of code to do so I I

00:20:31,110 --> 00:20:35,409
think that you should like if you

00:20:33,640 --> 00:20:37,720
haven't read the documentation yet in in

00:20:35,409 --> 00:20:40,090
detail please do that because it's it's

00:20:37,720 --> 00:20:43,090
pretty good at the at the basics that

00:20:40,090 --> 00:20:44,140
you need to get started but the the more

00:20:43,090 --> 00:20:46,480
important thing is you get the freedom

00:20:44,140 --> 00:20:48,610
to build your exact solution regardless

00:20:46,480 --> 00:20:49,750
of you know the simplified things that

00:20:48,610 --> 00:20:52,000
are in the documentation if you are

00:20:49,750 --> 00:20:55,809
creative you can do whatever you want

00:20:52,000 --> 00:20:57,760
and you don't get the explosion of data

00:20:55,809 --> 00:20:59,740
systems that I was talking about before

00:20:57,760 --> 00:21:03,580
because you can run it all in one

00:20:59,740 --> 00:21:07,720
cluster there's one cluster I manage one

00:21:03,580 --> 00:21:12,700
cluster to secure and one API for all of

00:21:07,720 --> 00:21:15,130
your developers to learn so that's my

00:21:12,700 --> 00:21:18,039
talk if anybody has any questions feel

00:21:15,130 --> 00:21:20,020
free to email me or tweet me if you have

00:21:18,039 --> 00:21:21,880
any questions want to know anything

00:21:20,020 --> 00:21:25,270
about foundation TV I'm by no means an

00:21:21,880 --> 00:21:28,130
expert but I've done a little bit of

00:21:25,270 --> 00:21:33,389
work with it thank you

00:21:28,130 --> 00:21:33,389

YouTube URL: https://www.youtube.com/watch?v=SKcF3HPnYqg


