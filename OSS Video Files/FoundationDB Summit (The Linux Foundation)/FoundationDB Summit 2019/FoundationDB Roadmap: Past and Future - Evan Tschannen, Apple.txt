Title: FoundationDB Roadmap: Past and Future - Evan Tschannen, Apple
Publication date: 2020-05-07
Playlist: FoundationDB Summit 2019
Description: 
	FoundationDB Roadmap: Past and Future - Evan Tschannen, Apple

During the last Summit, a number of ongoing projects were presented. Â This will be an update on their status and other notable features that have occurred in the past year, as well as an overview of what work is currently ongoing that will be released over the next year.
Captions: 
	00:00:00,140 --> 00:00:04,070
hello oh there we go

00:00:08,389 --> 00:00:14,099
so I'm Evan Chanin I lead the

00:00:12,090 --> 00:00:16,410
development of foundation DB at Apple

00:00:14,099 --> 00:00:19,560
and I'm super excited to see all the new

00:00:16,410 --> 00:00:21,090
faces here today I'm going to spend the

00:00:19,560 --> 00:00:23,609
next little bit of time talking you

00:00:21,090 --> 00:00:24,840
through a lot of the improvements that

00:00:23,609 --> 00:00:27,449
have happened over the past year since

00:00:24,840 --> 00:00:29,279
the previous summit and give you a taste

00:00:27,449 --> 00:00:31,080
of some of the exciting projects that

00:00:29,279 --> 00:00:34,980
are being worked on right now that are

00:00:31,080 --> 00:00:37,590
coming at you pretty soon so what

00:00:34,980 --> 00:00:39,660
happened in 2019 well we had this 6-1

00:00:37,590 --> 00:00:41,579
release in the 62 releases and in

00:00:39,660 --> 00:00:44,700
between there was nine different patch

00:00:41,579 --> 00:00:47,670
releases all these releases combined

00:00:44,700 --> 00:00:50,010
added up to over 200 release notes which

00:00:47,670 --> 00:00:54,180
means over 200 meaningful ways that

00:00:50,010 --> 00:00:57,600
foundation B was improved and in total

00:00:54,180 --> 00:01:00,059
over 3,000 commits looking through those

00:00:57,600 --> 00:01:01,770
release notes was for to prepare for

00:01:00,059 --> 00:01:04,260
this summit was a challenge to condense

00:01:01,770 --> 00:01:07,010
it to this timeslot but there was a few

00:01:04,260 --> 00:01:09,810
themes I talked at the last summit about

00:01:07,010 --> 00:01:11,520
multi region replication and gave a

00:01:09,810 --> 00:01:13,650
presentation on that topic

00:01:11,520 --> 00:01:15,150
and this year as we've pushed that

00:01:13,650 --> 00:01:16,979
feature to production in our production

00:01:15,150 --> 00:01:19,350
use of it a lot of the improvements have

00:01:16,979 --> 00:01:23,009
been hardening and making that as

00:01:19,350 --> 00:01:24,720
performed as possible the we've also

00:01:23,009 --> 00:01:27,540
done a whole lot of work on foundation

00:01:24,720 --> 00:01:29,430
B's data distribution algorithm so the

00:01:27,540 --> 00:01:31,290
data stream algorithm foundation DB is

00:01:29,430 --> 00:01:33,420
basically what's dividing your data

00:01:31,290 --> 00:01:35,850
across all of the storage nodes in the

00:01:33,420 --> 00:01:39,210
system so it's basically breaking up key

00:01:35,850 --> 00:01:42,000
space into moveable chunks of key ranges

00:01:39,210 --> 00:01:43,320
and it's dividing that data across you

00:01:42,000 --> 00:01:46,259
know this server holds these of this

00:01:43,320 --> 00:01:48,329
this set of keys and so forth so we've

00:01:46,259 --> 00:01:53,880
improved it into two ways one of the

00:01:48,329 --> 00:01:55,829
major one of the major goals of the

00:01:53,880 --> 00:01:58,530
distribution algorithm is keeping load

00:01:55,829 --> 00:02:01,110
even across all of the servers and

00:01:58,530 --> 00:02:03,390
looking at the 600 release there was a

00:02:01,110 --> 00:02:05,340
number of ways at which you could get a

00:02:03,390 --> 00:02:07,320
lot of right hot bandwidth into a

00:02:05,340 --> 00:02:08,879
certain small number of servers so we've

00:02:07,320 --> 00:02:10,950
done a lot of work to really balance

00:02:08,879 --> 00:02:13,140
better the the right load across the

00:02:10,950 --> 00:02:13,950
servers we've also done a lot of work

00:02:13,140 --> 00:02:16,290
complete creasing

00:02:13,950 --> 00:02:18,840
reliability so when a server failure

00:02:16,290 --> 00:02:20,970
fails this algorithm is gonna

00:02:18,840 --> 00:02:22,730
redistribute those keys to elsewhere and

00:02:20,970 --> 00:02:26,430
so we've done a whole lot of work

00:02:22,730 --> 00:02:28,830
basically spreading your data in a way

00:02:26,430 --> 00:02:30,989
that's safer so that if you lose if

00:02:28,830 --> 00:02:32,790
you're if your triple replicated and you

00:02:30,989 --> 00:02:34,220
lose three machines we want to minimize

00:02:32,790 --> 00:02:39,660
the chance that you actually lose data

00:02:34,220 --> 00:02:42,660
and we have so those two topics maybe

00:02:39,660 --> 00:02:47,430
cover 10 of the release notes so I got

00:02:42,660 --> 00:02:49,260
190 left for you guys the rest goes into

00:02:47,430 --> 00:02:51,360
this final category well basically we've

00:02:49,260 --> 00:02:55,319
made the database better in every way a

00:02:51,360 --> 00:02:58,799
database can get better I'll just hit on

00:02:55,319 --> 00:03:00,480
one that I'm particularly proud of so if

00:02:58,799 --> 00:03:04,140
we're looking at the scalability limits

00:03:00,480 --> 00:03:07,019
in 6 oh we could go to around 200 disk

00:03:04,140 --> 00:03:10,260
clusters it's a little fuzzy and it

00:03:07,019 --> 00:03:13,440
depends on your exact deployment through

00:03:10,260 --> 00:03:16,680
the few releases the 61 and 62 we've

00:03:13,440 --> 00:03:20,040
more than doubled that limit and the

00:03:16,680 --> 00:03:21,750
improvements come in two forms so one of

00:03:20,040 --> 00:03:24,690
the reasons that there's a scalability

00:03:21,750 --> 00:03:26,940
limit was related to recovery times

00:03:24,690 --> 00:03:29,310
which as you guys are all familiar with

00:03:26,940 --> 00:03:31,889
and one of the pain points of foundation

00:03:29,310 --> 00:03:33,299
EB when a machine cover dies you're

00:03:31,889 --> 00:03:36,030
gonna have to do a recovery to recover

00:03:33,299 --> 00:03:39,000
from that and that recovery is gonna

00:03:36,030 --> 00:03:41,760
scale or did scale with the amount of

00:03:39,000 --> 00:03:43,739
data in the database because the amount

00:03:41,760 --> 00:03:46,230
of data in the database governed how

00:03:43,739 --> 00:03:47,730
much metadata like that shard map I was

00:03:46,230 --> 00:03:49,530
just talking to you about day

00:03:47,730 --> 00:03:51,660
distribution like how big that thing is

00:03:49,530 --> 00:03:53,280
and so basically we've done a lot of

00:03:51,660 --> 00:03:54,840
optimizations to speed up how we can

00:03:53,280 --> 00:03:56,790
recover that metadata to make recovery

00:03:54,840 --> 00:03:59,160
as as fast as possible let's a scale

00:03:56,790 --> 00:04:00,660
more the other scaling limit is related

00:03:59,160 --> 00:04:02,819
to the cluster controller which is

00:04:00,660 --> 00:04:04,530
basically owning the membership of all

00:04:02,819 --> 00:04:06,359
the processes in the cluster so

00:04:04,530 --> 00:04:08,340
basically when you start up a new 50 B

00:04:06,359 --> 00:04:09,510
server instance it's going to join the

00:04:08,340 --> 00:04:10,620
cluster controller and the cluster

00:04:09,510 --> 00:04:11,880
controller is going to tell it you do

00:04:10,620 --> 00:04:16,470
that job you're a storage server your

00:04:11,880 --> 00:04:17,970
transaction server and so that guy that

00:04:16,470 --> 00:04:20,940
cluster controller could get overloaded

00:04:17,970 --> 00:04:22,320
with CPU and so we've done a number of

00:04:20,940 --> 00:04:24,090
different improvements to reduce the

00:04:22,320 --> 00:04:25,110
amount of CPU load on that cluster

00:04:24,090 --> 00:04:27,890
controller which has allowed our

00:04:25,110 --> 00:04:35,810
scalability limit to go a lot higher

00:04:27,890 --> 00:04:40,650
um so maybe we're at a 191 now 192 or

00:04:35,810 --> 00:04:42,600
left I guess so the starting is I

00:04:40,650 --> 00:04:44,220
obviously don't have time to keep going

00:04:42,600 --> 00:04:45,540
through all the different provements so

00:04:44,220 --> 00:04:47,760
I thought it would be fun instead of

00:04:45,540 --> 00:04:50,550
hitting all of the big highlights to

00:04:47,760 --> 00:04:53,880
take a deep dive into maybe just one or

00:04:50,550 --> 00:04:55,290
two of the release notes so if we go to

00:04:53,880 --> 00:04:57,330
everyone's favorite section of our

00:04:55,290 --> 00:04:58,890
release notes the six point two other

00:04:57,330 --> 00:05:01,610
changes to actually I'm sure I'm sure

00:04:58,890 --> 00:05:04,350
you've all combed over in great detail

00:05:01,610 --> 00:05:06,960
some were buried in there you'll see

00:05:04,350 --> 00:05:09,360
this guy causal read risky has been

00:05:06,960 --> 00:05:11,880
enhanced to further reduce the chance of

00:05:09,360 --> 00:05:13,740
causally inconsistent reads and I'm sure

00:05:11,880 --> 00:05:16,020
all of you guys are wondering well what

00:05:13,740 --> 00:05:18,870
the heck is causal read risky so to

00:05:16,020 --> 00:05:21,240
explain that we've got to go back to my

00:05:18,870 --> 00:05:22,710
presentation from last year you guys

00:05:21,240 --> 00:05:27,450
couldn't exceed the boxes like I

00:05:22,710 --> 00:05:29,370
couldn't do it so the what I was

00:05:27,450 --> 00:05:31,500
explaining how read versions worked in

00:05:29,370 --> 00:05:34,200
foundation to be last year I didn't

00:05:31,500 --> 00:05:35,640
really tell the full story so basically

00:05:34,200 --> 00:05:37,290
the way I explained it last year was a

00:05:35,640 --> 00:05:39,930
client sends her regrets to one of the

00:05:37,290 --> 00:05:41,310
proxies that proxy sends like ask the

00:05:39,930 --> 00:05:43,830
other proxies that they've sent seen a

00:05:41,310 --> 00:05:45,360
bigger version all of that is aggregated

00:05:43,830 --> 00:05:47,750
together and you send the bigger biggest

00:05:45,360 --> 00:05:51,480
number back to the back to the client

00:05:47,750 --> 00:05:53,520
seems simple enough however when there's

00:05:51,480 --> 00:05:54,650
a failure like a transaction log dies

00:05:53,520 --> 00:05:57,300
and there's a recovery

00:05:54,650 --> 00:05:58,890
you're gonna recruit an entirely new set

00:05:57,300 --> 00:06:01,440
of all of these different roles and that

00:05:58,890 --> 00:06:03,480
includes the proxies and because proxies

00:06:01,440 --> 00:06:05,880
are stateless there's nothing that's

00:06:03,480 --> 00:06:07,710
going to prevent a client from talking

00:06:05,880 --> 00:06:09,180
to the old set of proxies and getting a

00:06:07,710 --> 00:06:12,180
reversion so you could be happily

00:06:09,180 --> 00:06:13,920
accepting commits on on a new generation

00:06:12,180 --> 00:06:15,810
of logs but still getting giving out

00:06:13,920 --> 00:06:19,470
versions to this old version from the

00:06:15,810 --> 00:06:22,260
previous generation so to handle this

00:06:19,470 --> 00:06:24,690
edge case basically every time that you

00:06:22,260 --> 00:06:26,370
talk to one of the proxies and ask for

00:06:24,690 --> 00:06:27,870
read version instead of just ask talking

00:06:26,370 --> 00:06:29,520
to the other proxies you're also talking

00:06:27,870 --> 00:06:31,110
to the transaction logs to ask are you

00:06:29,520 --> 00:06:32,460
still alive are you still accepting

00:06:31,110 --> 00:06:36,870
commits are you part of the latest

00:06:32,460 --> 00:06:39,060
generation and with multi-region

00:06:36,870 --> 00:06:40,350
replication with multi a zebra filiation

00:06:39,060 --> 00:06:42,690
like if you're using three date

00:06:40,350 --> 00:06:45,330
all these transaction logs might not be

00:06:42,690 --> 00:06:47,430
in the same locations as the proxies so

00:06:45,330 --> 00:06:48,780
talking to them in general thorough

00:06:47,430 --> 00:06:50,160
collocated is cheap but if they're

00:06:48,780 --> 00:06:52,290
farther away you're gonna start to see

00:06:50,160 --> 00:06:58,560
bigger and bigger grv latency is get

00:06:52,290 --> 00:07:00,750
reversion Layton sees so basically that

00:06:58,560 --> 00:07:02,520
takes it so that so causal read risky is

00:07:00,750 --> 00:07:04,050
basically saying I don't care about

00:07:02,520 --> 00:07:07,200
talking those transaction logs I'm just

00:07:04,050 --> 00:07:09,210
gonna assume that they're like I that I

00:07:07,200 --> 00:07:11,100
don't either don't care about seeing a

00:07:09,210 --> 00:07:13,200
potentially stale read version in this

00:07:11,100 --> 00:07:14,730
very rare and weird scenario where your

00:07:13,200 --> 00:07:20,070
proxies are partitioned from the rest of

00:07:14,730 --> 00:07:21,810
the system so so that's useful by itself

00:07:20,070 --> 00:07:23,250
but then if we go back to this line now

00:07:21,810 --> 00:07:25,050
that it might make more sense so calls

00:07:23,250 --> 00:07:26,580
or read risky has been enhanced the

00:07:25,050 --> 00:07:29,430
Fertile reduce the chance of causing

00:07:26,580 --> 00:07:31,980
inconsistent reads so basically what we

00:07:29,430 --> 00:07:34,110
did to improve calls or read risky is we

00:07:31,980 --> 00:07:36,840
put a minimum time on master recoveries

00:07:34,110 --> 00:07:38,370
so basically every recovery recovery is

00:07:36,840 --> 00:07:40,440
now guaranteed to take at least 80

00:07:38,370 --> 00:07:42,930
milliseconds and this gives the proxies

00:07:40,440 --> 00:07:44,670
the freedom to say well I know as long

00:07:42,930 --> 00:07:46,950
as I talk to the transaction logs within

00:07:44,670 --> 00:07:50,490
the last 80 milliseconds that I know Ana

00:07:46,950 --> 00:07:52,230
hasn't completed in time so then I can

00:07:50,490 --> 00:07:53,850
just trust the results and don't have to

00:07:52,230 --> 00:07:57,000
do this extra hop to those transaction

00:07:53,850 --> 00:07:59,160
logs so as every good distributed

00:07:57,000 --> 00:08:00,960
database engineer we don't trust clocks

00:07:59,160 --> 00:08:03,540
because there is still the chance that

00:08:00,960 --> 00:08:05,340
the master measures time differently

00:08:03,540 --> 00:08:07,110
than the proxies so it's still an option

00:08:05,340 --> 00:08:08,790
it's not enabled by default and you

00:08:07,110 --> 00:08:10,380
still have to turn this on but it's

00:08:08,790 --> 00:08:13,160
really really safe at this point and

00:08:10,380 --> 00:08:16,020
it's safe enough that we're using it so

00:08:13,160 --> 00:08:18,240
that takes you into just one line and

00:08:16,020 --> 00:08:20,130
the release notes by the way if we look

00:08:18,240 --> 00:08:21,150
a few lines up from the calls will read

00:08:20,130 --> 00:08:23,010
risky there's another kind of

00:08:21,150 --> 00:08:25,260
interesting thing here you can set the

00:08:23,010 --> 00:08:29,040
amount of memory for the page caches of

00:08:25,260 --> 00:08:32,010
the storage engine the snowflake team

00:08:29,040 --> 00:08:33,690
has successfully halved the amount of I

00:08:32,010 --> 00:08:35,400
ops well to disk they're doing by

00:08:33,690 --> 00:08:37,650
increasing the page cache size so maybe

00:08:35,400 --> 00:08:39,120
you got maybe if you're having trouble

00:08:37,650 --> 00:08:40,710
or want to reduce costs and the amount

00:08:39,120 --> 00:08:42,090
of disk work you do you might want to

00:08:40,710 --> 00:08:45,420
increase the memory you give to your

00:08:42,090 --> 00:08:47,880
processes okay

00:08:45,420 --> 00:08:48,990
bonus features I threw this in here

00:08:47,880 --> 00:08:50,490
because when I was going through calls

00:08:48,990 --> 00:08:52,380
read risky it sort of got my brain

00:08:50,490 --> 00:08:53,850
churning what other things that are do

00:08:52,380 --> 00:08:54,180
we do at Apple that might be interesting

00:08:53,850 --> 00:08:56,520
to the

00:08:54,180 --> 00:08:58,529
and I actually found a few things that

00:08:56,520 --> 00:09:00,480
we do that might be interesting to you

00:08:58,529 --> 00:09:04,020
guys so it's a little off theme but I

00:09:00,480 --> 00:09:05,940
figured I'd throw it in here so one of

00:09:04,020 --> 00:09:07,770
them is a problem that probably

00:09:05,940 --> 00:09:10,110
everybody has here which is when you're

00:09:07,770 --> 00:09:11,760
developing layers it and something goes

00:09:10,110 --> 00:09:14,640
wrong like you have a hot key you're

00:09:11,760 --> 00:09:15,870
like well what is hot it's kind of

00:09:14,640 --> 00:09:19,050
useful to know that when you're trying

00:09:15,870 --> 00:09:21,000
to debug problems so we basically added

00:09:19,050 --> 00:09:24,120
have a tool from the CLI that you can

00:09:21,000 --> 00:09:26,190
turn on client sampling basically every

00:09:24,120 --> 00:09:27,959
transaction a client do will does has a

00:09:26,190 --> 00:09:30,029
chance to be putting being stored back

00:09:27,959 --> 00:09:32,670
in the database itself so you can enable

00:09:30,029 --> 00:09:35,070
it with FTB CLI profile client and turn

00:09:32,670 --> 00:09:36,839
on a rate to sample with and then I've

00:09:35,070 --> 00:09:38,279
linked to basically an analyzer that

00:09:36,839 --> 00:09:40,890
we've committed to the repo that can

00:09:38,279 --> 00:09:42,690
look through this sample of transactions

00:09:40,890 --> 00:09:45,450
that happened recently and find hot keys

00:09:42,690 --> 00:09:47,370
and heavily conflicting keys so this guy

00:09:45,450 --> 00:09:50,130
hopefully can help you guys solve

00:09:47,370 --> 00:09:52,740
problems more quickly I have one other

00:09:50,130 --> 00:09:56,130
one of these and that's a basically

00:09:52,740 --> 00:09:58,170
hidden depth in the depths of our like -

00:09:56,130 --> 00:10:00,779
- dev help on fuv server you'll see that

00:09:58,170 --> 00:10:02,550
there's this consistency check option so

00:10:00,779 --> 00:10:06,480
what this is going to do is have a

00:10:02,550 --> 00:10:08,610
process that's slowly scanning the key

00:10:06,480 --> 00:10:11,520
space and comparing all the replicas of

00:10:08,610 --> 00:10:13,410
the data and basically it's saying you

00:10:11,520 --> 00:10:16,110
know let me read for this shard and

00:10:13,410 --> 00:10:16,470
check it all three replicas are they all

00:10:16,110 --> 00:10:19,050
the same

00:10:16,470 --> 00:10:20,400
and so Foundation DB itself that's our

00:10:19,050 --> 00:10:22,350
whole job is making sure it's consistent

00:10:20,400 --> 00:10:27,120
but foundation DB is built on top of

00:10:22,350 --> 00:10:28,350
disks and disks can have problems so and

00:10:27,120 --> 00:10:30,240
then something a lot of those problems

00:10:28,350 --> 00:10:32,040
are found by checksums but there's some

00:10:30,240 --> 00:10:34,410
that aren't for instance if a disk

00:10:32,040 --> 00:10:35,970
doesn't by violates an F sync and just

00:10:34,410 --> 00:10:37,589
doesn't actually sync it and you lose

00:10:35,970 --> 00:10:39,740
some data it's possible that you'll end

00:10:37,589 --> 00:10:42,300
up with a valid checksum but an invalid

00:10:39,740 --> 00:10:43,829
set of data so it's possible so it's so

00:10:42,300 --> 00:10:44,940
something we do is for all of our

00:10:43,829 --> 00:10:47,010
clusters we leave one of these

00:10:44,940 --> 00:10:48,329
consistency check processes on slowly

00:10:47,010 --> 00:10:51,120
scanning through our data kind of on a

00:10:48,329 --> 00:10:52,770
monthly basis it also has a side benefit

00:10:51,120 --> 00:10:54,510
that it reads cold data so if you have

00:10:52,770 --> 00:10:58,560
really cold data in your foundation TB

00:10:54,510 --> 00:11:00,329
database it's off often could be subject

00:10:58,560 --> 00:11:01,980
to corruption because some types of disk

00:11:00,329 --> 00:11:03,180
corruption basically when you haven't

00:11:01,980 --> 00:11:05,430
read something a long time it can get

00:11:03,180 --> 00:11:06,600
corrupted so by reading it every month

00:11:05,430 --> 00:11:07,950
you're basically are going to protect

00:11:06,600 --> 00:11:13,300
yourself also from that

00:11:07,950 --> 00:11:15,310
okay so back to the presentation that

00:11:13,300 --> 00:11:17,170
was sort of my best attempt at covering

00:11:15,310 --> 00:11:18,970
the last year so let's look at what's

00:11:17,170 --> 00:11:21,850
some exciting projects that are

00:11:18,970 --> 00:11:23,890
happening right now I already mentioned

00:11:21,850 --> 00:11:27,040
a little bit about our scaling increases

00:11:23,890 --> 00:11:28,810
improvements from six oh two six - and

00:11:27,040 --> 00:11:32,110
we're still working on it and we're

00:11:28,810 --> 00:11:34,810
aiming to go about three times larger we

00:11:32,110 --> 00:11:38,260
really want a really big clusters

00:11:34,810 --> 00:11:39,640
because basically the size of an

00:11:38,260 --> 00:11:41,560
individual foundation to be cluster is

00:11:39,640 --> 00:11:43,810
going to determine how big of a key

00:11:41,560 --> 00:11:45,760
space you can use asset transactions

00:11:43,810 --> 00:11:46,900
over as soon as you get to the scaling

00:11:45,760 --> 00:11:49,180
limits and you're forced to shard your

00:11:46,900 --> 00:11:50,470
database it's a problem and it's a whole

00:11:49,180 --> 00:11:52,960
lot of engineering effort for you guys

00:11:50,470 --> 00:11:55,980
so we're doing our very best to keep

00:11:52,960 --> 00:11:58,450
pushing this limit higher and higher

00:11:55,980 --> 00:11:59,890
another key improvement that we've

00:11:58,450 --> 00:12:04,660
started work on is a stable wire

00:11:59,890 --> 00:12:06,490
protocol one a really annoying aspect of

00:12:04,660 --> 00:12:08,860
using Foundation TV that I think all you

00:12:06,490 --> 00:12:10,810
guys can relate to is the fact that the

00:12:08,860 --> 00:12:13,810
client has to be upgraded before the

00:12:10,810 --> 00:12:16,090
server so this hair-wise process of kind

00:12:13,810 --> 00:12:17,320
of putting the new binaries on that for

00:12:16,090 --> 00:12:19,660
the clients and then upgrading the

00:12:17,320 --> 00:12:21,640
servers this it is very hard to get

00:12:19,660 --> 00:12:23,650
right and it's a very delicate dance so

00:12:21,640 --> 00:12:26,920
what we're using a we're starting work

00:12:23,650 --> 00:12:28,450
on a G RPC protocol for we're talking

00:12:26,920 --> 00:12:30,760
between clients and servers and we'll

00:12:28,450 --> 00:12:35,710
reemployment our bindings to take

00:12:30,760 --> 00:12:37,560
advantage of that another key area for

00:12:35,710 --> 00:12:40,270
improvement is on our backup and restore

00:12:37,560 --> 00:12:43,170
and anyone who's using backup and

00:12:40,270 --> 00:12:45,220
restore which I hope is most of you

00:12:43,170 --> 00:12:48,520
probably don't realize how much it's

00:12:45,220 --> 00:12:50,950
costing you so backup for foundation DB

00:12:48,520 --> 00:12:52,660
the way it's implemented right now is

00:12:50,950 --> 00:12:54,490
every time you write to the database

00:12:52,660 --> 00:12:56,740
we're actually saving a separate

00:12:54,490 --> 00:12:58,360
separate copy of what you wrote and into

00:12:56,740 --> 00:13:00,820
the storage servers themselves at the

00:12:58,360 --> 00:13:02,140
very bottom of the database so it's

00:13:00,820 --> 00:13:04,270
effectively doubling the amount of

00:13:02,140 --> 00:13:06,430
writes that are going to your disks just

00:13:04,270 --> 00:13:08,500
because you have backup enabled well we

00:13:06,430 --> 00:13:10,510
have these T logs and they happen to

00:13:08,500 --> 00:13:13,410
have a change feed of all of the data

00:13:10,510 --> 00:13:16,870
already in a nice append-only log format

00:13:13,410 --> 00:13:19,300
so we're currently doing work to

00:13:16,870 --> 00:13:20,680
basically have the mutations shipped

00:13:19,300 --> 00:13:21,880
straight from those transaction logs out

00:13:20,680 --> 00:13:23,410
to the storage server which

00:13:21,880 --> 00:13:25,030
just be a straightforward doubling of

00:13:23,410 --> 00:13:28,480
your right bandwidth I mean it's it's

00:13:25,030 --> 00:13:29,950
gonna be really really helpful also I

00:13:28,480 --> 00:13:31,690
talked a little bit about scaling

00:13:29,950 --> 00:13:33,190
earlier and one of the things that

00:13:31,690 --> 00:13:35,170
doesn't scale right now is our restore

00:13:33,190 --> 00:13:37,300
so as you add more and more data into

00:13:35,170 --> 00:13:39,730
the cluster your store times are getting

00:13:37,300 --> 00:13:41,710
larger and larger and basically there's

00:13:39,730 --> 00:13:43,870
a hundred megabyte limit right now on

00:13:41,710 --> 00:13:46,030
how fast clusters can restore no matter

00:13:43,870 --> 00:13:47,560
how big it is and so we're breaking

00:13:46,030 --> 00:13:49,510
through that bottleneck and basically

00:13:47,560 --> 00:13:51,600
allowing the store to scale as speeds as

00:13:49,510 --> 00:13:54,100
fast as you know as big as your cluster

00:13:51,600 --> 00:13:57,100
the snowflake team has also done a lot

00:13:54,100 --> 00:13:59,080
of work on snapshot backups for disks

00:13:57,100 --> 00:14:01,120
like our places like EBS that support it

00:13:59,080 --> 00:14:02,620
and so if you're in an environment that

00:14:01,120 --> 00:14:05,020
supports snapshotting you might want to

00:14:02,620 --> 00:14:08,410
check out that work I think it's been in

00:14:05,020 --> 00:14:09,730
it's in six to however the documentation

00:14:08,410 --> 00:14:16,030
isn't there yet so that's coming from

00:14:09,730 --> 00:14:18,580
the so plate guys okay the next cool

00:14:16,030 --> 00:14:22,480
feature to many cool features is query

00:14:18,580 --> 00:14:25,870
push down so this one is basically

00:14:22,480 --> 00:14:28,960
allowing a more sophisticated logic that

00:14:25,870 --> 00:14:30,370
happen on the storage servers a very

00:14:28,960 --> 00:14:31,930
simple example that's very easy to

00:14:30,370 --> 00:14:33,550
understand is right now if you wanted to

00:14:31,930 --> 00:14:35,470
count all of the keys in a given key

00:14:33,550 --> 00:14:37,570
space and Foundation to you be your only

00:14:35,470 --> 00:14:38,950
option and only way to do it is to scan

00:14:37,570 --> 00:14:40,570
all of the data sending every single

00:14:38,950 --> 00:14:41,830
result back up to the client only to

00:14:40,570 --> 00:14:44,140
throw it away and just count the number

00:14:41,830 --> 00:14:45,550
of them so having the ability to say

00:14:44,140 --> 00:14:47,380
with your get range I don't care about

00:14:45,550 --> 00:14:49,120
the actual keys just give me the count

00:14:47,380 --> 00:14:50,500
of them is gonna be very powerful and

00:14:49,120 --> 00:14:52,420
there's a whole like we're starting

00:14:50,500 --> 00:14:54,130
we're just starting work on what other

00:14:52,420 --> 00:14:56,560
operations we want to support with this

00:14:54,130 --> 00:15:00,910
so if you have some opinions like jump

00:14:56,560 --> 00:15:02,140
in the discussion on the forums so the

00:15:00,910 --> 00:15:06,340
last two things are going to talk about

00:15:02,140 --> 00:15:07,960
are basically related to features that

00:15:06,340 --> 00:15:09,670
are being talked about today so I'm not

00:15:07,960 --> 00:15:11,260
going to go into as much detail and

00:15:09,670 --> 00:15:12,430
leave it to those presenters but I just

00:15:11,260 --> 00:15:16,060
wanted to highlight them because they're

00:15:12,430 --> 00:15:18,760
so critical for for our future and the

00:15:16,060 --> 00:15:20,050
first is new storage engines so one of

00:15:18,760 --> 00:15:22,150
the breakout sessions right after this

00:15:20,050 --> 00:15:24,880
is FTB internals and they'll each of

00:15:22,150 --> 00:15:28,510
these two redwood and these two storage

00:15:24,880 --> 00:15:31,000
engines will be talked about but the

00:15:28,510 --> 00:15:33,580
foundation DB is effectively scaling up

00:15:31,000 --> 00:15:35,620
an individual single key value store to

00:15:33,580 --> 00:15:37,930
like participate and have a

00:15:35,620 --> 00:15:40,330
of them participating we act as one big

00:15:37,930 --> 00:15:42,160
key value store and but also ultimately

00:15:40,330 --> 00:15:43,570
the performance of our whole system is

00:15:42,160 --> 00:15:44,950
going to be dependent on how fast that

00:15:43,570 --> 00:15:46,750
one key value store is so that's why

00:15:44,950 --> 00:15:48,550
this work on the storage engine is so

00:15:46,750 --> 00:15:51,130
critical for getting great performance

00:15:48,550 --> 00:15:53,200
out of our system redwood is in

00:15:51,130 --> 00:15:54,730
pre-release right now it's and we've

00:15:53,200 --> 00:15:57,070
already seen some really good numbers

00:15:54,730 --> 00:16:00,160
for performance and you'll hear more

00:15:57,070 --> 00:16:02,020
from Steve later wave front has been

00:16:00,160 --> 00:16:03,339
developing a radix tree based memory

00:16:02,020 --> 00:16:06,100
storage engine so anyone using the

00:16:03,339 --> 00:16:11,190
memory storage engine tune in from mung

00:16:06,100 --> 00:16:15,370
runs talk later today also and finally

00:16:11,190 --> 00:16:17,410
another problem that is very hard to

00:16:15,370 --> 00:16:20,980
work with in foundation DB is reed

00:16:17,410 --> 00:16:22,060
hotspots they are very easy to trick

00:16:20,980 --> 00:16:23,560
yourself into thinking you've

00:16:22,060 --> 00:16:24,880
distributed data when in fact there's

00:16:23,560 --> 00:16:27,670
some key that you're reading a whole

00:16:24,880 --> 00:16:29,740
bunch of a lot so we want to make our

00:16:27,670 --> 00:16:31,960
system be able to scale up reads and

00:16:29,740 --> 00:16:34,630
small key ranges a lot more fluently and

00:16:31,960 --> 00:16:35,830
so we're gonna do this with some a new

00:16:34,630 --> 00:16:38,230
role that's going to provide native

00:16:35,830 --> 00:16:41,020
consistent caching basically we can

00:16:38,230 --> 00:16:42,880
detect hotkey ranges and give some

00:16:41,020 --> 00:16:44,589
stateless processes that those key

00:16:42,880 --> 00:16:46,420
ranges insert they can serve reads

00:16:44,589 --> 00:16:47,650
basically taking load away from the

00:16:46,420 --> 00:16:49,180
storage servers that are responsible for

00:16:47,650 --> 00:16:53,770
that hot range you can hear more about

00:16:49,180 --> 00:16:57,010
that during the lightning talks so that

00:16:53,770 --> 00:17:00,520
is all I have for you guys I hope this

00:16:57,010 --> 00:17:02,260
was informative we are now at a break

00:17:00,520 --> 00:17:03,820
and then following the break we'll split

00:17:02,260 --> 00:17:06,079
up for the case studies and have to be

00:17:03,820 --> 00:17:10,889
internals thank you guys

00:17:06,079 --> 00:17:10,889

YouTube URL: https://www.youtube.com/watch?v=PmSkp9zEVLg


