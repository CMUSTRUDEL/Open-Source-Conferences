Title: A ZooKeeper Layer for FoundationDB - Paul Hemberger, HubSpot
Publication date: 2019-11-25
Playlist: FoundationDB Summit 2019
Description: 
	A ZooKeeper Layer for FoundationDB - Paul Hemberger, HubSpot

ZooKeeper plays a central role in coordinating many distributed systems. It is also itself a distributed system and can be pushed to its scaling limits, particularly with high write volume.

Can we simplify operations by replacing yet another system with FoundationDB?

What happens to system design when clients have access to a ZooKeeper ensemble that is easily scaled? And offers not just sequential consistency across replicas, but strict serializability?

This talk will examine the building blocks of a proof-of-concept ZooKeeper layer for FDB. First, we'll compare the data models, consistency guarantees, and watch semantics of ZK vs FDB. Then, we'll dig into the specifics of how to emulate ZK by leveraging the Directory Layer for the data model, changefeeds for ZK watches, and evaluate different approaches to essential components like ephemeral nodes and session management.
Captions: 
	00:00:00,030 --> 00:00:07,950
well oh wow such power alright my name

00:00:04,589 --> 00:00:11,099
is Paul I'm a software nerd working in

00:00:07,950 --> 00:00:12,150
the Boston area really excited honored

00:00:11,099 --> 00:00:13,860
to be able to share with you hack

00:00:12,150 --> 00:00:17,940
project that I've had which is a

00:00:13,860 --> 00:00:18,869
zookeeper layer for foundation DB yeah I

00:00:17,940 --> 00:00:20,820
think there's there's a couple

00:00:18,869 --> 00:00:22,470
interesting techniques in here that will

00:00:20,820 --> 00:00:24,689
be pretty fun we're gonna blast through

00:00:22,470 --> 00:00:26,099
the zookeeper API talk about all sorts

00:00:24,689 --> 00:00:28,529
of stuff about like what it's used for

00:00:26,099 --> 00:00:31,349
what makes it special and then we're

00:00:28,529 --> 00:00:35,460
into how to map those ideas onto a

00:00:31,349 --> 00:00:37,440
stateless layer zookeeper itself is a

00:00:35,460 --> 00:00:39,870
distributed system it's open source it's

00:00:37,440 --> 00:00:41,760
run by Apache these days their tagline

00:00:39,870 --> 00:00:43,710
is that distributed systems are a zoo

00:00:41,760 --> 00:00:46,200
and therefore you want a zookeeper and

00:00:43,710 --> 00:00:48,180
so the idea is that it helps offload

00:00:46,200 --> 00:00:50,460
certain responsibilities of a larger

00:00:48,180 --> 00:00:52,440
system and in my mind it kind of maps on

00:00:50,460 --> 00:00:55,199
to like two different types of access

00:00:52,440 --> 00:00:57,000
patterns and two usages the first thing

00:00:55,199 --> 00:00:59,250
I see is ooh keeper use a lot for is

00:00:57,000 --> 00:01:02,309
storing sort of like system level

00:00:59,250 --> 00:01:03,690
configuration service discovery data

00:01:02,309 --> 00:01:05,700
where it's like the total data set is

00:01:03,690 --> 00:01:07,229
pretty small you're not evolving it very

00:01:05,700 --> 00:01:09,000
often like you're not updating your

00:01:07,229 --> 00:01:10,979
configuration data like thousands of

00:01:09,000 --> 00:01:15,299
times per second it's like ones of times

00:01:10,979 --> 00:01:16,500
per minute and despite all that you can

00:01:15,299 --> 00:01:18,689
actually have a huge amount of read

00:01:16,500 --> 00:01:21,119
throughput on to like a like single

00:01:18,689 --> 00:01:23,009
piece of data the other thing that

00:01:21,119 --> 00:01:25,080
zookeepers used a lot for is for

00:01:23,009 --> 00:01:26,340
distributed synchronization so out of

00:01:25,080 --> 00:01:27,509
the box it doesn't actually give you a

00:01:26,340 --> 00:01:29,490
lot of these things but it gives you all

00:01:27,509 --> 00:01:32,670
the tools to write your own things like

00:01:29,490 --> 00:01:33,540
a leader election protocols and mutexes

00:01:32,670 --> 00:01:36,990
semaphores

00:01:33,540 --> 00:01:38,729
and a lot of pretty neat stuff and so I

00:01:36,990 --> 00:01:40,799
see zookeeper use for these things and

00:01:38,729 --> 00:01:42,630
when you start to look at how to zoo

00:01:40,799 --> 00:01:46,740
keeper itself actually fair against the

00:01:42,630 --> 00:01:48,329
use cases that people use it for it in

00:01:46,740 --> 00:01:50,579
my mind it works really really well for

00:01:48,329 --> 00:01:52,049
the configuration case like it can scale

00:01:50,579 --> 00:01:53,610
out reads incredibly well it can handle

00:01:52,049 --> 00:01:57,329
like that narrow distribution lots of

00:01:53,610 --> 00:01:58,680
reads and I've seen applications that

00:01:57,329 --> 00:02:00,509
have really struggled with the

00:01:58,680 --> 00:02:01,619
distributed synchronization side of

00:02:00,509 --> 00:02:03,479
things where it's like you're writing an

00:02:01,619 --> 00:02:05,759
application and then you start to hit

00:02:03,479 --> 00:02:07,590
some some problem you're like you know

00:02:05,759 --> 00:02:08,610
what I'm going to use like a mutex for

00:02:07,590 --> 00:02:09,899
this and since we're already connected

00:02:08,610 --> 00:02:12,330
to zookeeper I'm going to take out a

00:02:09,899 --> 00:02:13,849
zookeeper lock and zookeeper does not

00:02:12,330 --> 00:02:15,739
scale writes particularly

00:02:13,849 --> 00:02:17,329
so as the application has grows you

00:02:15,739 --> 00:02:19,579
don't really have a way to scale your

00:02:17,329 --> 00:02:21,079
zookeeper right throughput and in fact

00:02:19,579 --> 00:02:22,519
adding an extra instance into your

00:02:21,079 --> 00:02:26,060
zookeeper ensemble is going to bring

00:02:22,519 --> 00:02:28,639
your total throughput down so that got

00:02:26,060 --> 00:02:29,870
me thinking about what would this what

00:02:28,639 --> 00:02:33,170
would these set of trade-offs look like

00:02:29,870 --> 00:02:34,159
on top of foundation DB and this is

00:02:33,170 --> 00:02:35,659
something where it's like the whole

00:02:34,159 --> 00:02:36,799
horizontal scalability the way it's

00:02:35,659 --> 00:02:37,879
going to be architect is going to be

00:02:36,799 --> 00:02:39,620
really phenomenal for the

00:02:37,879 --> 00:02:42,439
synchronization case and actually

00:02:39,620 --> 00:02:44,269
somewhat weaker for the case of hot like

00:02:42,439 --> 00:02:44,989
hot keys which hopefully some of the

00:02:44,269 --> 00:02:46,579
stuff that was talked about earlier

00:02:44,989 --> 00:02:48,849
today like consistent caching would

00:02:46,579 --> 00:02:53,750
really like pickup that that particular

00:02:48,849 --> 00:02:55,669
use case so why build a zookeeper layer

00:02:53,750 --> 00:02:57,500
I think it'd be cool if you could offer

00:02:55,669 --> 00:02:58,879
something to applications that have kind

00:02:57,500 --> 00:03:00,680
of gotten themselves into a pickle with

00:02:58,879 --> 00:03:02,659
their like zookeeper usage or just be

00:03:00,680 --> 00:03:03,889
able to take existing libraries off the

00:03:02,659 --> 00:03:05,480
shelf that are already built on top of

00:03:03,889 --> 00:03:06,799
zookeeper and be like great this is

00:03:05,480 --> 00:03:09,260
going to scale way better than before

00:03:06,799 --> 00:03:11,209
I haven't really seen a layer that does

00:03:09,260 --> 00:03:16,519
similar stuff so I was kind of curious

00:03:11,209 --> 00:03:18,470
to see like what's possible here so why

00:03:16,519 --> 00:03:20,840
do people use zookeeper for storing

00:03:18,470 --> 00:03:22,040
configuration information like data and

00:03:20,840 --> 00:03:24,650
all that stuff and I think there's like

00:03:22,040 --> 00:03:26,810
a couple key features that it offers an

00:03:24,650 --> 00:03:28,639
application that make this to make it

00:03:26,810 --> 00:03:30,079
good for this it's got a really simple

00:03:28,639 --> 00:03:31,970
data model it looks like a file system

00:03:30,079 --> 00:03:33,409
it gives you watches we're going to talk

00:03:31,970 --> 00:03:35,359
a lot more about those but it helps you

00:03:33,409 --> 00:03:38,239
avoid polling and then it has really

00:03:35,359 --> 00:03:41,290
really precise semantics about how the

00:03:38,239 --> 00:03:43,669
operations are ordered and this is

00:03:41,290 --> 00:03:45,019
convenient for us because foundation EB

00:03:43,669 --> 00:03:46,909
actually has stronger semantics somewhat

00:03:45,019 --> 00:03:48,319
zookeeper offers so we'd like by virtue

00:03:46,909 --> 00:03:49,909
of building on this and not actively

00:03:48,319 --> 00:03:52,639
undermining this guarantee we kind of

00:03:49,909 --> 00:03:54,620
get this we get this for free why do

00:03:52,639 --> 00:03:59,379
people use zookeeper for synchronization

00:03:54,620 --> 00:04:02,299
or what does it offer for for helping

00:03:59,379 --> 00:04:03,829
build synchronization primitives again I

00:04:02,299 --> 00:04:06,799
have some data model data models come

00:04:03,829 --> 00:04:08,389
doesn't really matter and allows you

00:04:06,799 --> 00:04:09,979
have really really precisely ordered

00:04:08,389 --> 00:04:12,409
watches we'll talk a lot more about that

00:04:09,979 --> 00:04:14,299
it attracts client states oh- knows

00:04:12,409 --> 00:04:17,049
exactly who is currently active on the

00:04:14,299 --> 00:04:19,969
talking to zookeeper and then it ties

00:04:17,049 --> 00:04:21,829
like pieces of data which are like

00:04:19,969 --> 00:04:23,570
ephemeral so there's like if the client

00:04:21,829 --> 00:04:26,020
disconnects their data is removed and

00:04:23,570 --> 00:04:29,139
that's really really important for

00:04:26,020 --> 00:04:30,699
some of synchronization primitives as

00:04:29,139 --> 00:04:32,500
well and again the sequential

00:04:30,699 --> 00:04:33,490
consistency is a huge factor here and we

00:04:32,500 --> 00:04:35,020
don't have to worry about it

00:04:33,490 --> 00:04:36,580
so we're left with three pieces here

00:04:35,020 --> 00:04:39,669
that we are going to have to implement

00:04:36,580 --> 00:04:41,710
at the lair level so digging into the

00:04:39,669 --> 00:04:43,990
first one the zookeeper data model is

00:04:41,710 --> 00:04:45,849
really quite simple it looks like a

00:04:43,990 --> 00:04:48,669
distributed file system you create

00:04:45,849 --> 00:04:52,509
things at a particular path a path can

00:04:48,669 --> 00:04:54,460
have child paths you can store a very

00:04:52,509 --> 00:04:57,310
small data blob there it's tracking some

00:04:54,460 --> 00:05:00,250
metadata so it you know that's that's

00:04:57,310 --> 00:05:01,270
that's pretty much it there so I was

00:05:00,250 --> 00:05:03,639
thinking it's like alright so how do you

00:05:01,270 --> 00:05:05,050
build a file system with something with

00:05:03,639 --> 00:05:07,900
like directories or something like that

00:05:05,050 --> 00:05:09,970
on top of foundation DP and I decided to

00:05:07,900 --> 00:05:11,409
be lazy and I just recycled the

00:05:09,970 --> 00:05:12,880
directory layer because it already does

00:05:11,409 --> 00:05:16,690
pretty much all of those things so just

00:05:12,880 --> 00:05:18,789
like pass in the like zookeepers node

00:05:16,690 --> 00:05:20,520
path of just call to Z node get a

00:05:18,789 --> 00:05:22,690
subspace back from the directory layer

00:05:20,520 --> 00:05:24,789
serialized zookeepers native objects

00:05:22,690 --> 00:05:26,759
into that path and then like pretty much

00:05:24,789 --> 00:05:30,340
all of the work is done

00:05:26,759 --> 00:05:32,110
if you keeper just offered a file system

00:05:30,340 --> 00:05:33,490
interface like this for very small

00:05:32,110 --> 00:05:34,840
amounts of data that doesn't have a lot

00:05:33,490 --> 00:05:37,180
of right volume that'd be pretty boring

00:05:34,840 --> 00:05:39,729
so one of the things that really like

00:05:37,180 --> 00:05:42,240
Backson like buoys this as a useful idea

00:05:39,729 --> 00:05:45,280
is that su keeper offers offers a

00:05:42,240 --> 00:05:47,320
sequential consistency here so it has a

00:05:45,280 --> 00:05:48,610
total ordering of all right operations

00:05:47,320 --> 00:05:50,620
so you can imagine that every write

00:05:48,610 --> 00:05:52,479
request that zookeeper has ever accepted

00:05:50,620 --> 00:05:53,860
could be put into a single line and

00:05:52,479 --> 00:05:57,400
saying like this is the state of the

00:05:53,860 --> 00:05:59,830
system and so when there are multiple

00:05:57,400 --> 00:06:02,349
instances in a zookeeper ensemble they

00:05:59,830 --> 00:06:04,840
are all replicating they're all keeping

00:06:02,349 --> 00:06:07,990
like moving along that line and they

00:06:04,840 --> 00:06:09,219
agree on exactly the same ordering an

00:06:07,990 --> 00:06:10,509
interesting thing to note is that you

00:06:09,219 --> 00:06:13,210
can get stale reads like if you're

00:06:10,509 --> 00:06:14,860
connected to the zookeeper instance that

00:06:13,210 --> 00:06:17,409
is not the leader you can be seeing a

00:06:14,860 --> 00:06:19,210
stale view of the world and so when we

00:06:17,409 --> 00:06:23,409
look at how that compares to foundation

00:06:19,210 --> 00:06:25,150
bebés consistency level sanitation DB

00:06:23,409 --> 00:06:26,590
has strict serialize ability you don't

00:06:25,150 --> 00:06:29,289
have stale reads you still have a total

00:06:26,590 --> 00:06:31,210
ordering so between this guarantee and

00:06:29,289 --> 00:06:32,830
between the directory layer this whole

00:06:31,210 --> 00:06:36,699
first thing is like pretty much taken

00:06:32,830 --> 00:06:38,710
care of so let's move on to something

00:06:36,699 --> 00:06:39,879
much more challenging let's move on to

00:06:38,710 --> 00:06:43,899
how watches were

00:06:39,879 --> 00:06:45,610
and zoo keeper in zookeeper there are

00:06:43,899 --> 00:06:47,770
four different ways to set a watch and a

00:06:45,610 --> 00:06:51,009
watch request is when you go to the

00:06:47,770 --> 00:06:53,050
server and say hey for a given Xena like

00:06:51,009 --> 00:06:55,449
a particular path and a particular

00:06:53,050 --> 00:06:57,490
action give me back a future that is

00:06:55,449 --> 00:07:00,490
going to complete when that action has

00:06:57,490 --> 00:07:01,300
been observed and zookeeper allows you

00:07:00,490 --> 00:07:02,709
to do this

00:07:01,300 --> 00:07:05,349
for a bunch of different things like if

00:07:02,709 --> 00:07:06,879
the node does not exist already notify

00:07:05,349 --> 00:07:09,249
me when it's created or if it does exist

00:07:06,879 --> 00:07:10,809
notify me when it's deleted and then it

00:07:09,249 --> 00:07:12,639
backs it will jump into each of these

00:07:10,809 --> 00:07:14,439
with some ultra-precise guarantees

00:07:12,639 --> 00:07:16,749
around exactly how the ordering of those

00:07:14,439 --> 00:07:19,300
things must work and all of the ordering

00:07:16,749 --> 00:07:20,979
here adds up to zookeeper being a useful

00:07:19,300 --> 00:07:25,059
system to like to build these primitives

00:07:20,979 --> 00:07:27,339
on top of in contrast foundation DB also

00:07:25,059 --> 00:07:30,490
has a feature called a watch and the way

00:07:27,339 --> 00:07:31,839
it works is you say for a given key give

00:07:30,490 --> 00:07:33,610
me back a future that can please if the

00:07:31,839 --> 00:07:34,689
value has changed we don't know if it

00:07:33,610 --> 00:07:35,110
was created we don't know if it's

00:07:34,689 --> 00:07:37,539
deleted

00:07:35,110 --> 00:07:40,269
updated there's no ordering guarantees

00:07:37,539 --> 00:07:41,830
there's no guarantees of exactly when it

00:07:40,269 --> 00:07:43,360
fires relative to other things it's

00:07:41,830 --> 00:07:46,240
possible that it doesn't fire if you

00:07:43,360 --> 00:07:50,579
were watching value a it goes to B and

00:07:46,240 --> 00:07:54,069
then immediately flows back to a and so

00:07:50,579 --> 00:07:58,169
the like we're gonna have to do a lot of

00:07:54,069 --> 00:08:00,339
like work at the layer level in order to

00:07:58,169 --> 00:08:02,589
recreate the exact semantics of what

00:08:00,339 --> 00:08:06,240
zookeepers giving us and so for that

00:08:02,589 --> 00:08:08,679
we'll dig into each of these constraints

00:08:06,240 --> 00:08:10,360
the first one here is that it dispatches

00:08:08,679 --> 00:08:11,559
all of the events and callbacks in order

00:08:10,360 --> 00:08:13,689
this is actually something that's done

00:08:11,559 --> 00:08:15,550
at the client level so we don't have to

00:08:13,689 --> 00:08:17,679
worry about that one so we can check

00:08:15,550 --> 00:08:19,719
that one off next one is super

00:08:17,679 --> 00:08:21,399
interesting this one is saying that the

00:08:19,719 --> 00:08:23,649
order of watch events corresponds to the

00:08:21,399 --> 00:08:27,819
order of updates that the zookeeper

00:08:23,649 --> 00:08:29,199
service observed this one if we're going

00:08:27,819 --> 00:08:30,699
back to that picture of that sequential

00:08:29,199 --> 00:08:33,060
consistency where we're putting all of

00:08:30,699 --> 00:08:35,860
the updates in a line if two updates

00:08:33,060 --> 00:08:38,229
triggered watches then the watches must

00:08:35,860 --> 00:08:40,029
have been dispatched in that order it

00:08:38,229 --> 00:08:42,430
like in the exact same order and so for

00:08:40,029 --> 00:08:46,689
that we are going to need a log of watch

00:08:42,430 --> 00:08:48,520
events and so how do we build up this

00:08:46,689 --> 00:08:50,050
log of watch events that

00:08:48,520 --> 00:08:51,490
contains a list of all the watch events

00:08:50,050 --> 00:08:53,850
that have occurred in the same orders

00:08:51,490 --> 00:08:56,260
the updates that triggered them for this

00:08:53,850 --> 00:08:57,850
we can imagine that a zookeeper client

00:08:56,260 --> 00:09:00,280
has come in and says I want to perform a

00:08:57,850 --> 00:09:03,160
right I'm gonna create a like a Z note

00:09:00,280 --> 00:09:04,540
at the path like slash AB and now it

00:09:03,160 --> 00:09:07,720
gets passed off to our lair and our

00:09:04,540 --> 00:09:10,390
player our lair goes in and checks to

00:09:07,720 --> 00:09:12,460
see are there any clients who are

00:09:10,390 --> 00:09:16,300
actively watching for this note in this

00:09:12,460 --> 00:09:19,390
particular action and if so we append it

00:09:16,300 --> 00:09:21,910
into an event log that is keyed per

00:09:19,390 --> 00:09:24,940
client so we have an individual event

00:09:21,910 --> 00:09:26,410
log per for each of them and then this

00:09:24,940 --> 00:09:29,560
is yet another place where we use

00:09:26,410 --> 00:09:32,260
version stamps so version stamps like

00:09:29,560 --> 00:09:35,500
substitute in that that ordering number

00:09:32,260 --> 00:09:36,940
from from the like FTP server and so

00:09:35,500 --> 00:09:38,500
these are going to be in the exact same

00:09:36,940 --> 00:09:40,210
order as the updates because all of this

00:09:38,500 --> 00:09:43,390
was running in a single transaction so

00:09:40,210 --> 00:09:44,680
this part is super super nice and so now

00:09:43,390 --> 00:09:46,120
we can go back to our question of like

00:09:44,680 --> 00:09:48,400
alright are we keeping an order of watch

00:09:46,120 --> 00:09:49,720
events relative to the the same orders

00:09:48,400 --> 00:09:51,820
updates and the answer is yes all right

00:09:49,720 --> 00:09:53,590
we got this part so we built up we've

00:09:51,820 --> 00:09:56,620
persisted this list we haven't actually

00:09:53,590 --> 00:10:01,030
delivered it to the client yet how do we

00:09:56,620 --> 00:10:02,890
do that so we have our event log and we

00:10:01,030 --> 00:10:05,260
need to deliver it and the way we're

00:10:02,890 --> 00:10:07,600
gonna do that is by actually

00:10:05,260 --> 00:10:09,910
piggybacking off of a foundation TV

00:10:07,600 --> 00:10:12,750
watch now and so when somebody comes in

00:10:09,910 --> 00:10:14,860
and watches a zookeeper action

00:10:12,750 --> 00:10:17,560
what like looks is looking for a

00:10:14,860 --> 00:10:19,990
zookeeper action we will the layer will

00:10:17,560 --> 00:10:23,770
create a watch notifications key for

00:10:19,990 --> 00:10:26,860
that particular client and when that one

00:10:23,770 --> 00:10:28,540
fires that's not telling the layer that

00:10:26,860 --> 00:10:32,650
any particular watch event has happened

00:10:28,540 --> 00:10:34,750
what is telling the the client to do is

00:10:32,650 --> 00:10:36,910
go read the event log that we have

00:10:34,750 --> 00:10:38,410
persisted for it and so that at that

00:10:36,910 --> 00:10:39,940
point then it can go find all of the

00:10:38,410 --> 00:10:44,020
pending watch events play them back in

00:10:39,940 --> 00:10:45,190
the exact order that it needs to we can

00:10:44,020 --> 00:10:47,560
now look at the last constraint that

00:10:45,190 --> 00:10:49,570
zookeeper has for our watches which is

00:10:47,560 --> 00:10:51,820
that a client will see a watch event

00:10:49,570 --> 00:10:54,910
before it can read the corresponding

00:10:51,820 --> 00:10:56,230
data out of the underlying store this is

00:10:54,910 --> 00:10:57,760
an interesting one to kind of like

00:10:56,230 --> 00:10:59,650
noodle on for a little bit for exactly

00:10:57,760 --> 00:11:01,210
why this is in here

00:10:59,650 --> 00:11:06,970
but ultimately it means that there's a

00:11:01,210 --> 00:11:08,800
race where if we trigger if we perform a

00:11:06,970 --> 00:11:10,600
right the foundation DB watch is not

00:11:08,800 --> 00:11:12,310
fired yet somebody goes in and tries to

00:11:10,600 --> 00:11:14,950
read the same data that triggered that

00:11:12,310 --> 00:11:16,810
watch they could see it before the watch

00:11:14,950 --> 00:11:18,610
is fired so that means on read request

00:11:16,810 --> 00:11:20,680
we actually have to go and check out our

00:11:18,610 --> 00:11:24,730
watch event log to make sure that that

00:11:20,680 --> 00:11:25,779
has been satisfied first and so with

00:11:24,730 --> 00:11:29,380
this that's how we're going to notify

00:11:25,779 --> 00:11:31,510
the client if we go back to how we're

00:11:29,380 --> 00:11:33,490
building up this event this watch event

00:11:31,510 --> 00:11:37,630
log we can see that we now need to

00:11:33,490 --> 00:11:39,460
trigger a notification for the for The

00:11:37,630 --> 00:11:41,170
Watcher and so we'll just to perform an

00:11:39,460 --> 00:11:43,029
atomic update to this key as well and

00:11:41,170 --> 00:11:45,070
all of this is happening in a single

00:11:43,029 --> 00:11:48,150
transaction and I can't say enough good

00:11:45,070 --> 00:11:48,150
things about foundation

00:11:57,460 --> 00:12:01,300
so with that we have now built out

00:11:59,170 --> 00:12:03,550
ordered watches in the exact same way

00:12:01,300 --> 00:12:07,330
that zookeeper handles them the last bit

00:12:03,550 --> 00:12:10,180
is tacking ku is currently connected to

00:12:07,330 --> 00:12:12,100
the cluster and so this is useful for

00:12:10,180 --> 00:12:13,630
things like the femoral nodes where as

00:12:12,100 --> 00:12:16,750
mentioned before like zookeeper allows

00:12:13,630 --> 00:12:18,700
you to create and like a Z node and its

00:12:16,750 --> 00:12:21,130
existence is tied to whether or not the

00:12:18,700 --> 00:12:22,450
client is still connected and so you can

00:12:21,130 --> 00:12:24,160
imagine for a like a leader election

00:12:22,450 --> 00:12:26,350
protocol you say like everybody writes

00:12:24,160 --> 00:12:27,400
to this directory the node only exists

00:12:26,350 --> 00:12:28,630
as long as the client is there

00:12:27,400 --> 00:12:30,310
somebody's selected the leader

00:12:28,630 --> 00:12:32,770
everybody's watching that directory to

00:12:30,310 --> 00:12:36,910
see if any anybody has like been added

00:12:32,770 --> 00:12:38,530
or removed so it's like all starts to

00:12:36,910 --> 00:12:42,100
add on each other and so this is a super

00:12:38,530 --> 00:12:44,350
important feature for free zookeeper the

00:12:42,100 --> 00:12:44,980
way it works is nothing particularly

00:12:44,350 --> 00:12:47,350
special

00:12:44,980 --> 00:12:49,660
when a client connects to a do keeper

00:12:47,350 --> 00:12:51,430
server the server responds with a

00:12:49,660 --> 00:12:53,820
particular session ID he says all right

00:12:51,430 --> 00:12:57,040
that's like that's what you are now and

00:12:53,820 --> 00:12:58,870
every few seconds the client comes in

00:12:57,040 --> 00:13:00,640
and sends a heartbeat request and the

00:12:58,870 --> 00:13:02,500
zookeeper server in memory is keeping

00:13:00,640 --> 00:13:04,000
track of all of the clients who that is

00:13:02,500 --> 00:13:06,490
talking to and when they are going to

00:13:04,000 --> 00:13:08,500
expire and then about once every second

00:13:06,490 --> 00:13:10,180
there's a background thread that's just

00:13:08,500 --> 00:13:11,590
checking all right are there any

00:13:10,180 --> 00:13:14,560
sessions that haven't checked in and

00:13:11,590 --> 00:13:16,180
enough time so that they're expired and

00:13:14,560 --> 00:13:17,980
so that's how we're gonna just like

00:13:16,180 --> 00:13:20,350
detect if somebody has disconnected and

00:13:17,980 --> 00:13:21,730
if they have the zookeeper goes in the

00:13:20,350 --> 00:13:23,200
leaves their ephemeral nodes triggers

00:13:21,730 --> 00:13:25,420
the watches for anybody who is looking

00:13:23,200 --> 00:13:28,360
for that and cleans up any other state

00:13:25,420 --> 00:13:32,070
associated with the client so how do we

00:13:28,360 --> 00:13:35,110
recreate this on top of Foundation dB

00:13:32,070 --> 00:13:36,640
it's pretty simple I think the secret to

00:13:35,110 --> 00:13:38,290
any like stateless layers you just take

00:13:36,640 --> 00:13:39,460
any state that you previously had and

00:13:38,290 --> 00:13:42,100
just say you push it down into

00:13:39,460 --> 00:13:43,900
foundation DB instead so we're just

00:13:42,100 --> 00:13:45,730
going to persist the like the heartbeats

00:13:43,900 --> 00:13:47,830
and all of the sessions so we're going

00:13:45,730 --> 00:13:49,150
to have a subspace which is just all of

00:13:47,830 --> 00:13:51,790
the sessions we actually use version

00:13:49,150 --> 00:13:54,760
stamps to generate the session IDs and

00:13:51,790 --> 00:13:57,670
then we have at second subspace which is

00:13:54,760 --> 00:13:58,960
an index of all of the session IDs which

00:13:57,670 --> 00:14:01,540
is ordered by when they're going to

00:13:58,960 --> 00:14:04,840
expire so now how do we find all of the

00:14:01,540 --> 00:14:08,670
sessions who might be expiring it's a

00:14:04,840 --> 00:14:12,610
simple range read across the sub space

00:14:08,670 --> 00:14:15,040
so for each of those we found it like an

00:14:12,610 --> 00:14:16,960
expiring session go in and delete all of

00:14:15,040 --> 00:14:19,260
their ephemeral nodes and all of that

00:14:16,960 --> 00:14:22,060
other data that they haven't have

00:14:19,260 --> 00:14:23,890
staring at this one for a little bit we

00:14:22,060 --> 00:14:26,080
don't have an interesting question but

00:14:23,890 --> 00:14:29,620
just like who actually runs this code

00:14:26,080 --> 00:14:31,210
because when you had a lot of clients

00:14:29,620 --> 00:14:32,800
connecting to like an actual zookeeper

00:14:31,210 --> 00:14:33,880
server zookeepers keeping track of all

00:14:32,800 --> 00:14:36,430
of this in memory and it just has a

00:14:33,880 --> 00:14:38,080
background thread so it's like lots of

00:14:36,430 --> 00:14:41,650
clients connected to one server and as a

00:14:38,080 --> 00:14:44,470
background thread that's that's cleaning

00:14:41,650 --> 00:14:46,960
these up now we have lots and lots of

00:14:44,470 --> 00:14:48,970
like layer instances all kept like

00:14:46,960 --> 00:14:51,160
pushing their state down into foundation

00:14:48,970 --> 00:14:52,900
DB which has no idea that something

00:14:51,160 --> 00:14:57,250
needs to be cleaned up at any regular

00:14:52,900 --> 00:14:58,930
interval and so like how do we keep like

00:14:57,250 --> 00:15:00,490
the layer stateless how or like or do we

00:14:58,930 --> 00:15:01,930
have to introduce a second process that

00:15:00,490 --> 00:15:04,990
is only responsible for dealing with

00:15:01,930 --> 00:15:06,490
this so I asked about this on the forums

00:15:04,990 --> 00:15:07,930
and there was one idea there that I

00:15:06,490 --> 00:15:10,510
thought was like such a fun idea I had

00:15:07,930 --> 00:15:12,640
to go and implement it which is running

00:15:10,510 --> 00:15:14,890
a little mini election every second so

00:15:12,640 --> 00:15:16,510
on a zookeeper servers got a thread

00:15:14,890 --> 00:15:19,750
which runs every second well we're gonna

00:15:16,510 --> 00:15:21,520
do is elect one of the layer instances

00:15:19,750 --> 00:15:24,730
every second to be responsible for

00:15:21,520 --> 00:15:27,790
cleaning up all of the expired sessions

00:15:24,730 --> 00:15:30,010
and the way we're gonna do that is by

00:15:27,790 --> 00:15:32,700
using transaction conflicts so we're

00:15:30,010 --> 00:15:34,960
gonna create a new sub space which is

00:15:32,700 --> 00:15:37,570
saying like here's where the election is

00:15:34,960 --> 00:15:40,270
and then the value is when the next

00:15:37,570 --> 00:15:42,850
election occurs and so that our layer

00:15:40,270 --> 00:15:44,980
every second starts up a new transaction

00:15:42,850 --> 00:15:48,010
and it reads when the next election is

00:15:44,980 --> 00:15:50,050
it waits and while holding this

00:15:48,010 --> 00:15:51,550
transaction open and then it comes in

00:15:50,050 --> 00:15:53,260
and commits and writes when the

00:15:51,550 --> 00:15:55,180
subsequent election will occur and

00:15:53,260 --> 00:15:58,150
because in theory everybody's doing this

00:15:55,180 --> 00:16:00,310
at once when you go to commit one of the

00:15:58,150 --> 00:16:01,840
clients is going to exist succeed in

00:16:00,310 --> 00:16:03,640
this right and everybody else fails if

00:16:01,840 --> 00:16:05,800
you succeeded then you are the person

00:16:03,640 --> 00:16:08,170
who is responsible for going in reading

00:16:05,800 --> 00:16:10,090
all of the expired sessions and cleaning

00:16:08,170 --> 00:16:11,800
up that data so I thought that's pretty

00:16:10,090 --> 00:16:14,260
neat it allows you to just deploy like

00:16:11,800 --> 00:16:16,750
one thing like this works equally if you

00:16:14,260 --> 00:16:21,010
have like a single instance of the layer

00:16:16,750 --> 00:16:22,100
versus like lots of them and so now the

00:16:21,010 --> 00:16:23,870
way we're

00:16:22,100 --> 00:16:26,390
like fleshing out this whole session

00:16:23,870 --> 00:16:29,080
story is that we are generating session

00:16:26,390 --> 00:16:31,460
IDs and version stamps we're pushing the

00:16:29,080 --> 00:16:33,560
like all the session information down

00:16:31,460 --> 00:16:35,270
into Foundation dB I didn't give us its

00:16:33,560 --> 00:16:37,490
own slide but it's pretty simple we're

00:16:35,270 --> 00:16:39,500
keeping track of ephemeral nodes by

00:16:37,490 --> 00:16:43,520
session ID and then every second we go

00:16:39,500 --> 00:16:45,560
in and nominate one of the layer

00:16:43,520 --> 00:16:47,540
instances to go and perform cleanup duty

00:16:45,560 --> 00:16:49,640
and so with these three features

00:16:47,540 --> 00:16:51,230
complete we have now really like fleshed

00:16:49,640 --> 00:16:52,820
out like the the special stuff that

00:16:51,230 --> 00:16:54,410
zookeeper is doing that allows you to

00:16:52,820 --> 00:16:57,800
build all of this interesting primitives

00:16:54,410 --> 00:17:00,920
that it offers what's the state of

00:16:57,800 --> 00:17:04,130
things today this is very much a proof

00:17:00,920 --> 00:17:05,510
of concept I think it'd be like software

00:17:04,130 --> 00:17:08,209
engineering malpractice to go and use

00:17:05,510 --> 00:17:10,250
this in production right now but it's

00:17:08,209 --> 00:17:12,350
coming along nicely it runs everything

00:17:10,250 --> 00:17:14,750
that's in Apache curator which is a

00:17:12,350 --> 00:17:17,660
whole bunch of like well-honed like

00:17:14,750 --> 00:17:21,740
recipes for four different

00:17:17,660 --> 00:17:23,930
synchronization primitives and so yeah

00:17:21,740 --> 00:17:25,760
it's it's coming along nicely so there's

00:17:23,930 --> 00:17:27,410
a github link if you're interested if

00:17:25,760 --> 00:17:30,170
you want to talk to me more about it you

00:17:27,410 --> 00:17:34,870
can reach me there we have time for

00:17:30,170 --> 00:17:34,870
questions if anybody has any thoughts

00:17:38,860 --> 00:17:41,860
sure

00:17:55,960 --> 00:18:01,820
yes so the question here is is there a

00:17:58,309 --> 00:18:03,940
guarantee that only one of the instances

00:18:01,820 --> 00:18:07,639
here becomes the leader for the second

00:18:03,940 --> 00:18:10,249
the answer is I don't think so but it

00:18:07,639 --> 00:18:11,690
doesn't matter so much I think it's more

00:18:10,249 --> 00:18:13,519
just that we don't want it to be

00:18:11,690 --> 00:18:15,169
designed such that every single instance

00:18:13,519 --> 00:18:17,450
is running this clean up every second

00:18:15,169 --> 00:18:21,049
which would be very redundant it's more

00:18:17,450 --> 00:18:22,639
like one or maybe slightly more than one

00:18:21,049 --> 00:18:24,200
are running it but that should be fine

00:18:22,639 --> 00:18:25,729
it's like an idempotent operation here

00:18:24,200 --> 00:18:29,599
at this point the session is like it is

00:18:25,729 --> 00:18:31,960
gone so it's just cleaning it up other

00:18:29,599 --> 00:18:31,960
questions

00:18:38,690 --> 00:18:41,679
I did not know that

00:19:17,020 --> 00:19:21,610
I think I'm missing part of this

00:19:19,660 --> 00:19:24,480
question sorry it's like it's like a

00:19:21,610 --> 00:19:24,480
little far from here

00:19:24,780 --> 00:19:33,610
multi-region that's a big question I

00:19:31,110 --> 00:19:38,380
think I need to know more details about

00:19:33,610 --> 00:19:40,210
how its set up all right cool thank you

00:19:38,380 --> 00:19:42,160
everybody I think we have a break now so

00:19:40,210 --> 00:19:43,240
if you have more questions just pull me

00:19:42,160 --> 00:19:45,789
aside thank you

00:19:43,240 --> 00:19:45,789

YouTube URL: https://www.youtube.com/watch?v=3FYpf1QMPgQ


