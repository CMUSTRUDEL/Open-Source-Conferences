Title: PromCon 2017: Why We Love Prometheus Even Though I Hate It - Yaroslav Molochko
Publication date: 2017-09-01
Playlist: PromCon 2017
Description: 
	* Abstract:

At Anchorfree we had about 10 monitoring systems of different types. It was difficult to manage, we had 0 observability, as it was impossible to see whole picture. We decided to go with Prometheus full speed, migrated all the major and minor systems to it. This was not easy move, as we faced with a bunch of problems, fundamental misunderstandings, and resistance.

In this talk I would like to highlight the problems we faced, how we solved it. Answer why we still hate Prometheus and why we love it with all our hearts at the same time.

* Speaker biography:

Yaroslav Molochko is a system architect passionate about large scale and high load. He recently joined a DevOps team at AnchorFree to lead the company's technology stack transformation.

* Slides:

* PromCon website:

https://promcon.io/
Captions: 
	00:00:00,380 --> 00:00:19,880
[Music]

00:00:13,400 --> 00:00:22,830
next up if you love Moscow very good

00:00:19,880 --> 00:00:28,949
tell us why they love to missus but he

00:00:22,830 --> 00:00:31,830
doesn't yeah sense for having me and let

00:00:28,949 --> 00:00:36,210
me speak even though I have hate and

00:00:31,830 --> 00:00:39,600
permissions in the same sentence so Who

00:00:36,210 --> 00:00:42,600
am I I'm a System Architect and part

00:00:39,600 --> 00:00:46,620
time DevOps team lead a tanker free and

00:00:42,600 --> 00:00:50,430
what anchor phrase is our mission is to

00:00:46,620 --> 00:00:53,149
provide secure and anonymous access to

00:00:50,430 --> 00:00:55,770
Internet to or people in the pool

00:00:53,149 --> 00:00:59,789
basically we a VPN provider one was the

00:00:55,770 --> 00:01:03,629
biggest in why and we on a short list to

00:00:59,789 --> 00:01:09,330
be blocked on when our country decided

00:01:03,629 --> 00:01:12,450
to to block anything so we were using a

00:01:09,330 --> 00:01:14,640
lot of monitoring solution project our

00:01:12,450 --> 00:01:19,710
hospital shield project is like ten

00:01:14,640 --> 00:01:23,040
years old and we approached monitoring

00:01:19,710 --> 00:01:28,430
from different angles and I would say it

00:01:23,040 --> 00:01:32,400
is my click said it looks like a mess so

00:01:28,430 --> 00:01:36,530
we said a couple of requirements to our

00:01:32,400 --> 00:01:38,130
new age winter and solution it had to be

00:01:36,530 --> 00:01:40,799
highly available

00:01:38,130 --> 00:01:44,820
it had scaling up and down and out

00:01:40,799 --> 00:01:48,770
without data loss is maintenance lawn

00:01:44,820 --> 00:01:54,479
retention friendly community everything

00:01:48,770 --> 00:01:58,800
must be premises right and 2016 we

00:01:54,479 --> 00:02:03,580
discovered that it had zero

00:01:58,800 --> 00:02:05,440
don't don't kick me right now let me

00:02:03,580 --> 00:02:08,530
speak

00:02:05,440 --> 00:02:11,110
so about high-level beauty we discovered

00:02:08,530 --> 00:02:13,600
that even though you have you can have

00:02:11,110 --> 00:02:18,010
several premises servers you still have

00:02:13,600 --> 00:02:21,640
gaps in graphs and if you if you have

00:02:18,010 --> 00:02:25,390
stables stable platform it is may be

00:02:21,640 --> 00:02:29,050
acceptable to have one gap for one hour

00:02:25,390 --> 00:02:34,209
per month but when you are tuning and

00:02:29,050 --> 00:02:39,370
prior to 1.6 it was dark magic we were

00:02:34,209 --> 00:02:42,220
not able to like have continuous graph

00:02:39,370 --> 00:02:44,500
every day it was like some gaps and our

00:02:42,220 --> 00:02:46,270
management was driving crazy because our

00:02:44,500 --> 00:02:49,330
CEO is so questioned about this

00:02:46,270 --> 00:02:54,489
deliverances free internet to everyone

00:02:49,330 --> 00:02:58,870
that we have this white screens around

00:02:54,489 --> 00:03:02,350
the office and if it sees some gap he we

00:02:58,870 --> 00:03:07,110
should call an ambulance so we couldn't

00:03:02,350 --> 00:03:10,000
afford so horizontal scaling actually

00:03:07,110 --> 00:03:13,810
there is no such thing as scaling

00:03:10,000 --> 00:03:16,019
promises but there is a sharding and we

00:03:13,810 --> 00:03:20,350
discovered that host-based sharding

00:03:16,019 --> 00:03:23,950
doesn't work well and Federation server

00:03:20,350 --> 00:03:27,280
is actually it is not a single point of

00:03:23,950 --> 00:03:30,370
entrance to the data but it is basically

00:03:27,280 --> 00:03:36,060
yet another promise use with some

00:03:30,370 --> 00:03:40,209
limited amount of metrics and actually

00:03:36,060 --> 00:03:43,840
when we tried to shared our data by node

00:03:40,209 --> 00:03:46,810
we discovered that our herbs guys had a

00:03:43,840 --> 00:03:52,299
hard time figuring out figuring out

00:03:46,810 --> 00:03:54,760
where data is and actually this was we

00:03:52,299 --> 00:03:57,640
were not alone I am happy that we are

00:03:54,760 --> 00:04:02,230
not like the one who wants something

00:03:57,640 --> 00:04:06,130
strange so ease of maintenance back to

00:04:02,230 --> 00:04:07,900
1.6 when we were actually we start with

00:04:06,130 --> 00:04:11,390
1.4

00:04:07,900 --> 00:04:15,709
it was a dark magic of tuning we had a

00:04:11,390 --> 00:04:20,090
lot of from we we were incrementing this

00:04:15,709 --> 00:04:26,479
ancient storage engine like it was like

00:04:20,090 --> 00:04:29,419
one Zen to and was like not really easy

00:04:26,479 --> 00:04:32,350
if if you start to have more than like

00:04:29,419 --> 00:04:34,970
ten promises server it was like

00:04:32,350 --> 00:04:40,280
especially if if this has different

00:04:34,970 --> 00:04:45,740
hardware s is these other discount them

00:04:40,280 --> 00:04:46,930
so but for one note it worked very fine

00:04:45,740 --> 00:04:52,130
fine

00:04:46,930 --> 00:04:53,199
long potential period and right now does

00:04:52,130 --> 00:04:57,550
support

00:04:53,199 --> 00:05:01,669
reads and writes but back in that time

00:04:57,550 --> 00:05:04,100
we had no chance of doing this and we

00:05:01,669 --> 00:05:07,340
figure out that x4 doesn't work Wells

00:05:04,100 --> 00:05:10,850
and we've found XFS and it was like all

00:05:07,340 --> 00:05:15,770
of the problem I believe if we hit all

00:05:10,850 --> 00:05:19,389
the problems premises user could hit so

00:05:15,770 --> 00:05:24,410
the community what could be wrong right

00:05:19,389 --> 00:05:28,550
so we had a cheap proxy and there is a

00:05:24,410 --> 00:05:31,370
poor request from 2015 and this poor

00:05:28,550 --> 00:05:35,770
request was not married because brand

00:05:31,370 --> 00:05:35,770
Brasilia and not pointing fingers sorry

00:05:36,860 --> 00:05:44,370
but brand brazil was going to write a

00:05:40,620 --> 00:05:46,680
different statistics for HZ proxy that

00:05:44,370 --> 00:05:49,259
was the reason why he didn't measure it

00:05:46,680 --> 00:05:52,470
but for me as a newcomer to the

00:05:49,259 --> 00:05:54,870
community it looked like come on this

00:05:52,470 --> 00:05:58,169
pull request is for a year already and

00:05:54,870 --> 00:06:03,300
it provides what I need but nobody is

00:05:58,169 --> 00:06:16,169
merging it it was like we hurt so we

00:06:03,300 --> 00:06:18,690
went in flux DB three months later time

00:06:16,169 --> 00:06:20,819
series database and we decided that we

00:06:18,690 --> 00:06:22,710
do not need longer tension we do not

00:06:20,819 --> 00:06:27,389
need anything we just wanted to be

00:06:22,710 --> 00:06:30,599
stable fast some human readable query

00:06:27,389 --> 00:06:33,720
language and handle just our load we do

00:06:30,599 --> 00:06:37,500
not want to handle like possible load in

00:06:33,720 --> 00:06:40,469
ten years just our because there should

00:06:37,500 --> 00:06:46,740
be another talk about flux EB why we

00:06:40,469 --> 00:06:51,210
hated I'm not keeping it if you want you

00:06:46,740 --> 00:06:55,139
can read it later so because we were

00:06:51,210 --> 00:06:57,810
using in flux DB for three months all of

00:06:55,139 --> 00:07:02,610
our server team guys created all of

00:06:57,810 --> 00:07:05,610
these exporters or support for in flux

00:07:02,610 --> 00:07:08,699
eb and we spent like a lot of resources

00:07:05,610 --> 00:07:12,900
and we decided okay let's use telegraph

00:07:08,699 --> 00:07:15,719
let's use one exporter and Prometheus

00:07:12,900 --> 00:07:17,789
what could be wrong right and he

00:07:15,719 --> 00:07:21,180
discovers that don't use it whisper

00:07:17,789 --> 00:07:25,259
service charting because if Telegraph is

00:07:21,180 --> 00:07:28,289
down you lose everything if Telegraph is

00:07:25,259 --> 00:07:30,389
up you have like bunch of matrix and if

00:07:28,289 --> 00:07:33,090
you shared it by service not by not

00:07:30,389 --> 00:07:37,020
because not doesn't work with with

00:07:33,090 --> 00:07:41,219
Federation to figure out where your

00:07:37,020 --> 00:07:43,360
details sorry so if you share my service

00:07:41,219 --> 00:07:47,110
you you

00:07:43,360 --> 00:07:51,069
cannot actually distinguish were what

00:07:47,110 --> 00:07:54,280
data you can get from the Telegraph and

00:07:51,069 --> 00:08:01,300
you eat your bandwidth eat you CPU and

00:07:54,280 --> 00:08:05,830
it just done so while allow it first of

00:08:01,300 --> 00:08:10,419
all is output format I do not know who

00:08:05,830 --> 00:08:19,719
created that but this is second most

00:08:10,419 --> 00:08:23,199
loud format I see and basically we could

00:08:19,719 --> 00:08:25,900
we as soon as we introduce promiscuous

00:08:23,199 --> 00:08:28,180
and we said like okey this is finals it

00:08:25,900 --> 00:08:31,539
is going to be promises no more

00:08:28,180 --> 00:08:35,620
other monitoring solutions our developer

00:08:31,539 --> 00:08:39,339
started using this output and we changed

00:08:35,620 --> 00:08:41,890
all our infrastructure to use this

00:08:39,339 --> 00:08:45,640
output format even for non Prometheus

00:08:41,890 --> 00:08:51,370
tasks it it become like a standard

00:08:45,640 --> 00:08:53,579
output for for for read-only API why I

00:08:51,370 --> 00:08:59,740
will tell you later

00:08:53,579 --> 00:09:03,010
branchial this is a number one thing I

00:08:59,740 --> 00:09:06,579
love about permissions because of this

00:09:03,010 --> 00:09:10,949
how good is offset a data from yesterday

00:09:06,579 --> 00:09:15,959
right with influx actually it is

00:09:10,949 --> 00:09:20,050
capacitor you needed to write this fancy

00:09:15,959 --> 00:09:24,339
query with promises it is just and it's

00:09:20,050 --> 00:09:27,940
done so with promises we were able to

00:09:24,339 --> 00:09:32,350
unify dashboards alerts and deep dive

00:09:27,940 --> 00:09:37,480
analysis the operation guys s3 guys were

00:09:32,350 --> 00:09:40,779
able to dig deeply see graphs and all

00:09:37,480 --> 00:09:44,920
with one tool and this is just amazing

00:09:40,779 --> 00:09:50,010
like probably I cannot overestimate how

00:09:44,920 --> 00:09:53,089
how changed our operation speed but

00:09:50,010 --> 00:09:55,950
actually this is amazing

00:09:53,089 --> 00:10:01,680
so promises become first point of

00:09:55,950 --> 00:10:05,690
analysis previously I didn't state that

00:10:01,680 --> 00:10:08,190
we have several thousand of nodes and

00:10:05,690 --> 00:10:11,070
previously whenever you need to figure

00:10:08,190 --> 00:10:13,950
out what went wrong with that knot or

00:10:11,070 --> 00:10:17,160
what is software installed on that

00:10:13,950 --> 00:10:20,370
particular node you had to go or you if

00:10:17,160 --> 00:10:22,980
you have it this task for some bunch of

00:10:20,370 --> 00:10:25,709
nodes you use ansible or side stack or

00:10:22,980 --> 00:10:29,940
whatever you have right now we export

00:10:25,709 --> 00:10:32,370
everything premises and first when

00:10:29,940 --> 00:10:34,140
somebody asks you like okay what what is

00:10:32,370 --> 00:10:38,700
installed there you just go to premises

00:10:34,140 --> 00:10:44,660
and you're like doesn't work I need

00:10:38,700 --> 00:10:48,930
to do this unzip oh so auntie blocking

00:10:44,660 --> 00:10:51,149
you know we were using we on the short

00:10:48,930 --> 00:10:54,140
list of blockage by most of the

00:10:51,149 --> 00:10:56,250
countries and we spent most of our our

00:10:54,140 --> 00:11:00,500
development and research and development

00:10:56,250 --> 00:11:07,740
resources in ninety blocking field and

00:11:00,500 --> 00:11:12,690
prior to Prometheus we had Hadoop with

00:11:07,740 --> 00:11:16,680
all of this batch processing and we had

00:11:12,690 --> 00:11:19,980
like a lot of reaction fuge reaction

00:11:16,680 --> 00:11:23,100
time from the time when we got blocked

00:11:19,980 --> 00:11:27,660
to the time when we figured like oh this

00:11:23,100 --> 00:11:33,170
this got blocked right now we change in

00:11:27,660 --> 00:11:36,480
this pipeline and had this Hadoop in

00:11:33,170 --> 00:11:42,209
computations as matrix in real time

00:11:36,480 --> 00:11:45,800
but we had the six months of introducing

00:11:42,209 --> 00:11:50,730
Prometheus for this so we had basically

00:11:45,800 --> 00:11:54,029
four matrix main matrix it is it's it is

00:11:50,730 --> 00:11:57,540
like one metric but different dimensions

00:11:54,029 --> 00:12:00,300
so it could be a country server IP user

00:11:57,540 --> 00:12:02,910
connected user platform Android Windows

00:12:00,300 --> 00:12:04,220
whatever and domain it connected if it

00:12:02,910 --> 00:12:12,540
has domain

00:12:04,220 --> 00:12:16,920
so I took naive approach and tail file

00:12:12,540 --> 00:12:20,940
then calculated set the labels country

00:12:16,920 --> 00:12:25,050
platform what our use counter type as it

00:12:20,940 --> 00:12:27,380
should be because it is a counter and it

00:12:25,050 --> 00:12:31,940
was a complete fail because we got like

00:12:27,380 --> 00:12:39,480
almost three billion three billion

00:12:31,940 --> 00:12:43,830
metrics so our promise your server I

00:12:39,480 --> 00:12:46,880
dedicated for this particular time died

00:12:43,830 --> 00:12:49,680
in a couple of minutes

00:12:46,880 --> 00:12:54,450
so I was thinking fact what can I do

00:12:49,680 --> 00:12:57,780
better so I introduced TTL of the

00:12:54,450 --> 00:13:01,650
message so on the exporter side we were

00:12:57,780 --> 00:13:05,400
calculating the country and and the

00:13:01,650 --> 00:13:07,800
platform and all this matrix and then if

00:13:05,400 --> 00:13:09,990
we do not increment it within five

00:13:07,800 --> 00:13:14,460
minutes then we remove this from cache

00:13:09,990 --> 00:13:18,690
and it actually helped because whenever

00:13:14,460 --> 00:13:22,590
user previously whenever user connected

00:13:18,690 --> 00:13:27,210
to the server it remains there forever

00:13:22,590 --> 00:13:31,280
and because we have different host names

00:13:27,210 --> 00:13:34,200
as well so this metric could be like

00:13:31,280 --> 00:13:35,520
increased a lot this cardinality but

00:13:34,200 --> 00:13:38,850
with five minute cache

00:13:35,520 --> 00:13:41,930
we might get we might not get this user

00:13:38,850 --> 00:13:47,970
to that fraction of set of servers and

00:13:41,930 --> 00:13:52,620
it is more or less safe it worked

00:13:47,970 --> 00:13:58,110
somehow but we we were blind whether it

00:13:52,620 --> 00:14:01,930
is really working or it is like or not

00:13:58,110 --> 00:14:06,120
because Hadoop had completely different

00:14:01,930 --> 00:14:08,740
data Hadoop has absolute values so

00:14:06,120 --> 00:14:13,960
probably brand Brazil will kick me in

00:14:08,740 --> 00:14:19,420
that right now but I decided to actually

00:14:13,960 --> 00:14:25,270
do gosh and even though it is counter

00:14:19,420 --> 00:14:28,300
but in order to fill our need in some

00:14:25,270 --> 00:14:33,450
reference data with Hadoop so that we

00:14:28,300 --> 00:14:37,480
can have it we calculate this with

00:14:33,450 --> 00:14:41,760
five-minute batches we calculate this

00:14:37,480 --> 00:14:41,760
data and then we create yet another

00:14:41,940 --> 00:14:46,510
intermediate format and then our

00:14:44,530 --> 00:14:53,460
exporter is actually shown this five

00:14:46,510 --> 00:14:59,170
minutes samples and it was a success

00:14:53,460 --> 00:15:03,000
right now this particular task is is

00:14:59,170 --> 00:15:07,680
done by two nodes

00:15:03,000 --> 00:15:13,390
93 gigabyte from each and we got like 80

00:15:07,680 --> 00:15:19,920
k ingested samples per second and it is

00:15:13,390 --> 00:15:23,650
only four million time serious so result

00:15:19,920 --> 00:15:25,090
we have a complete visibility of per

00:15:23,650 --> 00:15:29,410
country

00:15:25,090 --> 00:15:33,070
anti blocking we decrease the amount of

00:15:29,410 --> 00:15:36,910
time we spent on analyzing when we got

00:15:33,070 --> 00:15:39,460
blocked from 24 hours to 30 minutes in

00:15:36,910 --> 00:15:43,000
and it's not because of premises but

00:15:39,460 --> 00:15:48,790
because of our ops guys we got alerts

00:15:43,000 --> 00:15:50,680
and we we can theoretically handle it

00:15:48,790 --> 00:15:54,520
with one server but we will not have

00:15:50,680 --> 00:15:58,630
high availability instead of petabytes

00:15:54,520 --> 00:16:03,130
of Hadoop right now we moving towards

00:15:58,630 --> 00:16:07,090
Hadoop anyway but still we can do it so

00:16:03,130 --> 00:16:10,730
this is look like this our draft for

00:16:07,090 --> 00:16:17,270
this is for Ukraine I believe

00:16:10,730 --> 00:16:20,390
we got IPS we got IP ranges domains we

00:16:17,270 --> 00:16:26,950
got platforms and everything is done by

00:16:20,390 --> 00:16:26,950
Prometheus that is it that was fast

00:16:27,500 --> 00:16:40,320
[Music]

00:16:40,130 --> 00:16:43,459
you

00:16:40,320 --> 00:16:43,459

YouTube URL: https://www.youtube.com/watch?v=Z-4XmQPBFn8


