Title: PromCon 2017: Integrating Prometheus and InfluxDB - Paul Dix
Publication date: 2017-09-04
Playlist: PromCon 2017
Description: 
	* Abstract:

This talk will look at the different integrations between InfluxDB and Prometheus. We'll dive into using InfluxDB for remote long term storage. Other examples will show how to use Kapacitor to scrape Prometheus metrics targets to pull data into InfluxDB and transform it on the fly to different schemas. Finally, we'll take a look at the upcoming enhancements to the Influx Query Language and possible implementation of PromQL within Influx itself for better long term integration of the two projects.

* Speaker biography:

Paul is the creator of InfluxDB. He has helped build software for startups, large companies and organizations like Microsoft, Google, McAfee, Thomson Reuters, and Air Force Space Command. He is the series editor for Addison Wesley’s Data & Analytics book and video series. In 2010 Paul wrote the book Service Oriented Design with Ruby and Rails for Addison Wesley’s. In 2009 he started the NYC Machine Learning Meetup, which now has over 10,000 members. Paul holds a degree in computer science from Columbia University.

* Slides:

* PromCon website:

https://promcon.io/
Captions: 
	00:00:00,380 --> 00:00:17,220
[Music]

00:00:13,490 --> 00:00:19,050
in folks TV is a system which is often

00:00:17,220 --> 00:00:20,640
compared to Regis there are similarities

00:00:19,050 --> 00:00:23,340
I think we're both of the Turkish

00:00:20,640 --> 00:00:26,189
virtual restorer gingival yeah yeah

00:00:23,340 --> 00:00:29,609
about to launch it or something and you

00:00:26,189 --> 00:00:31,230
know it turns out that in folks started

00:00:29,609 --> 00:00:32,969
like a few insan for previous we know

00:00:31,230 --> 00:00:42,719
Infosys the better system because it has

00:00:32,969 --> 00:00:44,129
172 more stars ok so right now we're

00:00:42,719 --> 00:00:48,090
talking about integrating influx I'm

00:00:44,129 --> 00:00:50,520
Prometheus thanks all right hey

00:00:48,090 --> 00:00:53,250
everybody uh so yeah this is my talk

00:00:50,520 --> 00:00:54,840
about influx to be in Prometheus I'll

00:00:53,250 --> 00:00:56,910
cover a little bit about what exists now

00:00:54,840 --> 00:01:00,140
this is mostly thanks to the efforts of

00:00:56,910 --> 00:01:03,359
the Prometheus team Julius in particular

00:01:00,140 --> 00:01:06,540
but I'm also going to close with where

00:01:03,359 --> 00:01:09,689
we see the future of things like moving

00:01:06,540 --> 00:01:12,689
so just as an intro in case you don't

00:01:09,689 --> 00:01:15,630
know influx DB is an open source time

00:01:12,689 --> 00:01:18,090
series database we say time series

00:01:15,630 --> 00:01:20,490
instead of just metrics in my mind

00:01:18,090 --> 00:01:23,040
metrics are a subset of time-series

00:01:20,490 --> 00:01:25,409
metrics our samples have fixed intervals

00:01:23,040 --> 00:01:27,930
whereas in my mind a time series could

00:01:25,409 --> 00:01:31,350
be irregular time series data of like

00:01:27,930 --> 00:01:33,540
trades in a stock market or individual

00:01:31,350 --> 00:01:35,060
requests to an API not just

00:01:33,540 --> 00:01:38,100
summarizations

00:01:35,060 --> 00:01:40,290
so a little bit about influx QB it's

00:01:38,100 --> 00:01:42,270
open source it's MIT licensed it's

00:01:40,290 --> 00:01:46,829
written and go it has a query language

00:01:42,270 --> 00:01:48,630
that looks kind of like SQL we as Brian

00:01:46,829 --> 00:01:50,939
mentioned we're on our third version of

00:01:48,630 --> 00:01:53,520
our storage engine we rewrote the

00:01:50,939 --> 00:01:56,490
storage engine from scratch starting in

00:01:53,520 --> 00:01:58,920
the fall of 2015 we call it a time

00:01:56,490 --> 00:02:01,409
series merge tree it's heavily inspired

00:01:58,920 --> 00:02:05,880
by LS m trees and leveldb

00:02:01,409 --> 00:02:08,190
but it's specific to our use case and

00:02:05,880 --> 00:02:10,500
also actually we have an inverted index

00:02:08,190 --> 00:02:11,680
as well those bits are available for

00:02:10,500 --> 00:02:13,989
preview right now

00:02:11,680 --> 00:02:16,420
they're going in by default in the next

00:02:13,989 --> 00:02:18,310
release so it's basically an on disk

00:02:16,420 --> 00:02:20,950
inverted index for looking up time

00:02:18,310 --> 00:02:22,659
series and stuff and then obviously we

00:02:20,950 --> 00:02:24,250
have wear company so we have a

00:02:22,659 --> 00:02:27,700
commercial offering which offers high

00:02:24,250 --> 00:02:29,620
availability and scale out closer so the

00:02:27,700 --> 00:02:31,569
data model looks like this you have a

00:02:29,620 --> 00:02:33,730
measurement name which is a string you

00:02:31,569 --> 00:02:35,950
have tags so the measurement name is

00:02:33,730 --> 00:02:37,359
kind of like a metric in Prometheus you

00:02:35,950 --> 00:02:39,150
have tags which are key value pairs

00:02:37,359 --> 00:02:42,159
which are like Prometheus labels

00:02:39,150 --> 00:02:45,069
unlike Prometheus you then have fields

00:02:42,159 --> 00:02:47,230
which is just key value pairs you have

00:02:45,069 --> 00:02:50,049
the field identifier and then the value

00:02:47,230 --> 00:02:52,540
and then you have a nanosecond scale

00:02:50,049 --> 00:02:53,799
epoch which is again different than

00:02:52,540 --> 00:02:57,549
Prometheus which stores at the

00:02:53,799 --> 00:03:00,099
millisecond precision we support more

00:02:57,549 --> 00:03:02,950
than just float 64's we have float 64 in

00:03:00,099 --> 00:03:07,510
64 boolean's and string types and we're

00:03:02,950 --> 00:03:09,879
adding U n 64 in the next release so a

00:03:07,510 --> 00:03:12,069
query looks like this basically we're

00:03:09,879 --> 00:03:13,900
getting the 90th percentile from the CPU

00:03:12,069 --> 00:03:16,209
measurement for the last 12 hours from

00:03:13,900 --> 00:03:20,349
the western region in 10-minute

00:03:16,209 --> 00:03:22,000
intervals for every single host I just

00:03:20,349 --> 00:03:24,220
want to give a quick intro of the things

00:03:22,000 --> 00:03:26,409
and then we'll dig into how the to

00:03:24,220 --> 00:03:28,599
integrate together so we also have some

00:03:26,409 --> 00:03:31,859
other projects which you may or may not

00:03:28,599 --> 00:03:34,239
know about capacitor which is our

00:03:31,859 --> 00:03:37,060
project for processing time series data

00:03:34,239 --> 00:03:38,829
so this could be doing basic ETL tasks

00:03:37,060 --> 00:03:43,209
and it could also be doing monitoring

00:03:38,829 --> 00:03:44,769
learning it's open source written go we

00:03:43,209 --> 00:03:46,599
have a scripting language for it called

00:03:44,769 --> 00:03:48,750
tick script it looks kind of like a

00:03:46,599 --> 00:03:51,459
lightweight kind of scripting language

00:03:48,750 --> 00:03:54,699
and it operates in both streaming and

00:03:51,459 --> 00:03:55,900
batch modes and it could store data back

00:03:54,699 --> 00:03:58,419
into influx dB

00:03:55,900 --> 00:04:00,609
it has user-defined functions so you can

00:03:58,419 --> 00:04:01,209
actually pipe out to custom code that

00:04:00,609 --> 00:04:03,069
you wrote

00:04:01,209 --> 00:04:04,959
right now we have support for go and

00:04:03,069 --> 00:04:07,299
Python but basically any programming

00:04:04,959 --> 00:04:10,319
language that can communicate over a

00:04:07,299 --> 00:04:14,049
socket and decode protobufs will work

00:04:10,319 --> 00:04:16,989
and recently we actually added support

00:04:14,049 --> 00:04:19,329
for we pulled in prometheus bits to add

00:04:16,989 --> 00:04:22,419
support for service discovery and pull

00:04:19,329 --> 00:04:25,330
style so basically it can now scrape

00:04:22,419 --> 00:04:28,120
prometheus targets using the premiere

00:04:25,330 --> 00:04:32,860
service discovery in scraping code and

00:04:28,120 --> 00:04:34,810
work with with that so Telegraph we have

00:04:32,860 --> 00:04:36,490
a data collector again open source

00:04:34,810 --> 00:04:38,199
written Ingo it's an agent deployed

00:04:36,490 --> 00:04:40,720
across infrastructure it has a bunch of

00:04:38,199 --> 00:04:42,520
different plugins not the focus of this

00:04:40,720 --> 00:04:44,740
talk so this is a question I got a

00:04:42,520 --> 00:04:46,270
couple of times where a sponsor here I

00:04:44,740 --> 00:04:48,639
had a couple of people come up and say

00:04:46,270 --> 00:04:51,159
like you you seem to be a competitor

00:04:48,639 --> 00:04:54,690
with prometheus why are you actually at

00:04:51,159 --> 00:04:57,759
prom con which is a legitimate question

00:04:54,690 --> 00:05:00,039
and I asked this myself multiple times

00:04:57,759 --> 00:05:03,250
particularly when I was going over you

00:05:00,039 --> 00:05:06,129
know this talk in the hotel a couple of

00:05:03,250 --> 00:05:07,810
days ago I was just like wow it feels

00:05:06,129 --> 00:05:10,199
kind of odd to be here and then I

00:05:07,810 --> 00:05:12,789
thought well what is prometheus right

00:05:10,199 --> 00:05:15,099
well there's the Prometheus server and

00:05:12,789 --> 00:05:16,960
on in some sense we're definitely can

00:05:15,099 --> 00:05:18,940
like a competing project with the

00:05:16,960 --> 00:05:20,770
Prometheus server but by that same

00:05:18,940 --> 00:05:23,830
rationale so is cortex which we heard

00:05:20,770 --> 00:05:25,150
about earlier today right so then I

00:05:23,830 --> 00:05:26,860
thought well Prometheus is actually a

00:05:25,150 --> 00:05:28,990
lot more than just the server the

00:05:26,860 --> 00:05:31,090
implementation there's also the alert

00:05:28,990 --> 00:05:33,009
manager which is a separate thing which

00:05:31,090 --> 00:05:36,009
you could use with or without prometheus

00:05:33,009 --> 00:05:38,529
right there's the exposition format

00:05:36,009 --> 00:05:41,130
which I think is is one of the what I

00:05:38,529 --> 00:05:43,389
want to think of the core strengths of

00:05:41,130 --> 00:05:46,389
Prometheus is an overall project an

00:05:43,389 --> 00:05:47,860
ecosystem is this exposition format it

00:05:46,389 --> 00:05:49,750
gives you a standard so that you can

00:05:47,860 --> 00:05:51,400
instrument your apps and expose

00:05:49,750 --> 00:05:53,310
something that people can use and look

00:05:51,400 --> 00:05:55,870
at and I think it's actually a really

00:05:53,310 --> 00:05:58,270
good thing it makes it really easy for

00:05:55,870 --> 00:05:59,949
people to understand things the client

00:05:58,270 --> 00:06:02,830
libraries is another spot where I think

00:05:59,949 --> 00:06:04,779
Prometheus did really good work the the

00:06:02,830 --> 00:06:08,080
supportive ones Go Java Python and Ruby

00:06:04,779 --> 00:06:09,729
and even better there is a document that

00:06:08,080 --> 00:06:11,560
describes if you're going to implement a

00:06:09,729 --> 00:06:12,819
client library this is what it should

00:06:11,560 --> 00:06:14,560
look like these are the things that

00:06:12,819 --> 00:06:16,270
should do these are the things it must

00:06:14,560 --> 00:06:18,690
do these are the things they should not

00:06:16,270 --> 00:06:21,219
do which of course of course leads to

00:06:18,690 --> 00:06:22,539
people in the community creating client

00:06:21,219 --> 00:06:25,659
libraries that kind of have a similar

00:06:22,539 --> 00:06:28,930
set of functionality and a look and feel

00:06:25,659 --> 00:06:31,000
so I think the client libraries are

00:06:28,930 --> 00:06:33,339
again like a strong piece of the

00:06:31,000 --> 00:06:34,979
Prometheus ecosystem then of course

00:06:33,339 --> 00:06:37,779
there's the query language prom QL

00:06:34,979 --> 00:06:39,639
there's the API there's more to the API

00:06:37,779 --> 00:06:41,319
than just this but for me

00:06:39,639 --> 00:06:43,990
what I care about is the stuff that lets

00:06:41,319 --> 00:06:46,289
you discover the metadata around the

00:06:43,990 --> 00:06:49,419
data that you have inside Prometheus and

00:06:46,289 --> 00:06:53,460
then most importantly for us for influx

00:06:49,419 --> 00:06:57,039
is the remote read and write API which

00:06:53,460 --> 00:06:59,319
my understanding is it's like it's there

00:06:57,039 --> 00:07:01,210
but again this is I think it's entirely

00:06:59,319 --> 00:07:03,699
experimental functionality at this point

00:07:01,210 --> 00:07:06,610
which isn't guaranteed to be stable so

00:07:03,699 --> 00:07:08,259
there may be changes to it over time but

00:07:06,610 --> 00:07:10,270
the point of all this is that Prometheus

00:07:08,259 --> 00:07:12,669
is more than just the actual server that

00:07:10,270 --> 00:07:16,719
stores data and scrapes targets right

00:07:12,669 --> 00:07:18,759
it's all these other things and we can

00:07:16,719 --> 00:07:21,430
certainly build an ecosystem of tooling

00:07:18,759 --> 00:07:23,500
around it replacing some parts keeping

00:07:21,430 --> 00:07:27,759
other parts just like we've works does

00:07:23,500 --> 00:07:30,539
just like cortex does right so let's

00:07:27,759 --> 00:07:33,939
look at what the inflow in flux plus

00:07:30,539 --> 00:07:36,669
prometheus picture looks like today and

00:07:33,939 --> 00:07:39,310
like I said most of this is due to not

00:07:36,669 --> 00:07:41,499
our efforts we haven't got Jove into

00:07:39,310 --> 00:07:43,270
that yet but due to the Prometheus

00:07:41,499 --> 00:07:45,759
people being nice enough to actually

00:07:43,270 --> 00:07:48,819
write integration and tools to work with

00:07:45,759 --> 00:07:50,830
other projects so a key thing that I

00:07:48,819 --> 00:07:54,159
think is important to note is that we're

00:07:50,830 --> 00:07:56,289
embracing pull and push previously we

00:07:54,159 --> 00:07:58,509
were strictly focused on push that was

00:07:56,289 --> 00:08:02,289
the thing that we're doing and when we

00:07:58,509 --> 00:08:03,879
saw Prometheus come out I particularly

00:08:02,289 --> 00:08:05,770
in the beginning I was like Paul does

00:08:03,879 --> 00:08:07,389
not seem like the right thing and then

00:08:05,770 --> 00:08:08,949
over the course of the last couple of

00:08:07,389 --> 00:08:11,469
years I kind of came around to the idea

00:08:08,949 --> 00:08:13,449
of pull I think there there are some

00:08:11,469 --> 00:08:15,610
cases where Paul makes a lot of sense

00:08:13,449 --> 00:08:16,960
and it works really really well and

00:08:15,610 --> 00:08:19,120
there are other cases of where you want

00:08:16,960 --> 00:08:21,039
push I think push is more important

00:08:19,120 --> 00:08:23,889
primarily for application developers

00:08:21,039 --> 00:08:25,529
people who are tracking say sensor data

00:08:23,889 --> 00:08:27,939
where they're building apps on top of it

00:08:25,529 --> 00:08:31,060
Paul I think is very very strong for

00:08:27,939 --> 00:08:32,560
decoupling your how you expose your

00:08:31,060 --> 00:08:35,199
metrics from your actual monitoring

00:08:32,560 --> 00:08:37,479
infrastructure which seems to be in line

00:08:35,199 --> 00:08:39,070
with kind of one of the core ideals of

00:08:37,479 --> 00:08:41,469
Prometheus as a project is this

00:08:39,070 --> 00:08:43,029
decoupling separating things out so you

00:08:41,469 --> 00:08:46,449
don't have like these big points of

00:08:43,029 --> 00:08:48,220
failure so as I mentioned we added

00:08:46,449 --> 00:08:50,480
support for Prometheus scrape targets

00:08:48,220 --> 00:08:52,649
into capacitor

00:08:50,480 --> 00:08:55,199
what that looks like it's kind of like

00:08:52,649 --> 00:08:57,240
this we have the service discovery stuff

00:08:55,199 --> 00:08:59,339
we discover things we scrape the targets

00:08:57,240 --> 00:09:02,339
we have a tick script which is

00:08:59,339 --> 00:09:04,170
user-defined which can then modify that

00:09:02,339 --> 00:09:06,389
data and either store it into in flux DB

00:09:04,170 --> 00:09:08,879
or modify that data and pipe it out to

00:09:06,389 --> 00:09:11,910
other things capacitor has the ability

00:09:08,879 --> 00:09:15,389
to pipe data to kafka to in flux and a

00:09:11,910 --> 00:09:18,120
few other places as a result of this

00:09:15,389 --> 00:09:20,399
work so the two issues I have linked at

00:09:18,120 --> 00:09:23,459
the bottom there the first is just a

00:09:20,399 --> 00:09:26,639
repo that we have of tick scripts that

00:09:23,459 --> 00:09:29,040
will normalize metric data from some of

00:09:26,639 --> 00:09:30,899
the different exporters that exist and

00:09:29,040 --> 00:09:33,870
the other one is actually a discussion

00:09:30,899 --> 00:09:36,120
that one of the Prometheus developers

00:09:33,870 --> 00:09:37,769
opened up about potentially separating

00:09:36,120 --> 00:09:40,259
the service discovery bits from the

00:09:37,769 --> 00:09:42,060
actual core Prometheus project because

00:09:40,259 --> 00:09:43,529
they see that there are other projects

00:09:42,060 --> 00:09:45,480
that could get value out of actually

00:09:43,529 --> 00:09:47,160
using those bits I know there was one

00:09:45,480 --> 00:09:49,649
other project I can't remember the name

00:09:47,160 --> 00:09:54,959
of that was using the Prometheus service

00:09:49,649 --> 00:09:58,379
discovery pieces so now there's the

00:09:54,959 --> 00:09:59,819
remote read/write API so it looks like

00:09:58,379 --> 00:10:01,350
this basically at the top you have the

00:09:59,819 --> 00:10:03,809
Prometheus server which is collecting

00:10:01,350 --> 00:10:08,550
data and storing it and it can make

00:10:03,809 --> 00:10:10,379
requests to a remote gateway so there's

00:10:08,550 --> 00:10:12,449
basically in your Prometheus config you

00:10:10,379 --> 00:10:15,329
can set this up like this you basically

00:10:12,449 --> 00:10:17,759
just say the URL it could be a service

00:10:15,329 --> 00:10:19,800
that you write yourself and there's

00:10:17,759 --> 00:10:21,209
something for it right and for read the

00:10:19,800 --> 00:10:22,860
truth is it doesn't have to be their

00:10:21,209 --> 00:10:24,209
remote gateway you can write the service

00:10:22,860 --> 00:10:26,309
yourself and if you look at the remote

00:10:24,209 --> 00:10:28,470
gateway code there's actually not that

00:10:26,309 --> 00:10:30,389
much there so it it would be pretty easy

00:10:28,470 --> 00:10:32,399
to write one I think I talked to

00:10:30,389 --> 00:10:34,379
somebody earlier today and it sounds

00:10:32,399 --> 00:10:36,660
like they wrote a remote gateway just on

00:10:34,379 --> 00:10:38,670
the right side of things to pipe all of

00:10:36,660 --> 00:10:41,309
their Prometheus data into Kafka so I

00:10:38,670 --> 00:10:42,509
think that's interesting but for us I'm

00:10:41,309 --> 00:10:45,120
gonna be talking about the remote

00:10:42,509 --> 00:10:47,970
gateway which is the code that exists in

00:10:45,120 --> 00:10:51,839
the Prometheus repo under documentation

00:10:47,970 --> 00:10:54,779
examples remote gateway so it makes a

00:10:51,839 --> 00:11:00,059
call to the remote gateway which then

00:10:54,779 --> 00:11:01,920
makes a call to influx DB so the mapping

00:11:00,059 --> 00:11:03,390
that it does looks like this a

00:11:01,920 --> 00:11:06,450
Prometheus metric name

00:11:03,390 --> 00:11:08,970
maps to an influx measurement the labels

00:11:06,450 --> 00:11:11,550
map to tags and there's only one field

00:11:08,970 --> 00:11:18,480
it's always one field it's called value

00:11:11,550 --> 00:11:20,550
and it's a float64 so the read process

00:11:18,480 --> 00:11:22,800
looks like this so we know query comes

00:11:20,550 --> 00:11:25,620
into Prometheus it will read the data

00:11:22,800 --> 00:11:27,960
and in storage flash remote it has

00:11:25,620 --> 00:11:31,080
adapters to pull in from the remote

00:11:27,960 --> 00:11:33,420
gateway it's protobuf over HTTP so

00:11:31,080 --> 00:11:36,270
there's like a request which then makes

00:11:33,420 --> 00:11:38,310
a request to influx DB so basically to

00:11:36,270 --> 00:11:39,750
have this set up up and running you have

00:11:38,310 --> 00:11:41,250
this other piece of infrastructure that

00:11:39,750 --> 00:11:45,300
you have to run in addition to

00:11:41,250 --> 00:11:49,110
Prometheus and in flux so the reads look

00:11:45,300 --> 00:11:52,500
like this this is the proto fault proto

00:11:49,110 --> 00:11:54,510
file for Prometheus that describes what

00:11:52,500 --> 00:11:56,820
a Kree looks like and what information

00:11:54,510 --> 00:11:59,490
you pass on so you can see from this

00:11:56,820 --> 00:12:01,710
that the the query that gets passed that

00:11:59,490 --> 00:12:03,810
will get passed on to the remote reader

00:12:01,710 --> 00:12:05,370
in our case in flux but it could be

00:12:03,810 --> 00:12:08,070
anything else if you want to implement

00:12:05,370 --> 00:12:10,170
it is the start timestamp an end

00:12:08,070 --> 00:12:12,600
timestamp and then there's the matress

00:12:10,170 --> 00:12:14,550
the set of matches right you have a

00:12:12,600 --> 00:12:16,230
match type and you have just the

00:12:14,550 --> 00:12:18,390
collection of matches that you're you're

00:12:16,230 --> 00:12:20,880
matching against right you don't have

00:12:18,390 --> 00:12:23,670
metric in here because again under the

00:12:20,880 --> 00:12:25,440
covers the the metric one is always

00:12:23,670 --> 00:12:28,470
going to be underscore underscore name

00:12:25,440 --> 00:12:33,620
underscore underscore but there is

00:12:28,470 --> 00:12:35,910
actually also like I'm a metric match so

00:12:33,620 --> 00:12:37,890
once we get to the remote gateway we

00:12:35,910 --> 00:12:40,650
decode that it gets converted into an

00:12:37,890 --> 00:12:42,120
influx DV query the way it does that

00:12:40,650 --> 00:12:44,340
right now is this like string

00:12:42,120 --> 00:12:47,400
concatenation kind of thing it's not

00:12:44,340 --> 00:12:50,610
it's not ideal but it's it works as a

00:12:47,400 --> 00:12:52,980
good hack for now and that makes an HTTP

00:12:50,610 --> 00:12:55,410
request in flux DB which then can Costa

00:12:52,980 --> 00:12:57,900
the data is Jason comes back to the

00:12:55,410 --> 00:13:00,150
remote gateway which then converts it to

00:12:57,900 --> 00:13:04,850
the format that Prometheus is expecting

00:13:00,150 --> 00:13:07,440
of the time series data so that's today

00:13:04,850 --> 00:13:09,300
there's a lot of unnecessary overhead in

00:13:07,440 --> 00:13:12,510
that right the remote gateway is doing

00:13:09,300 --> 00:13:14,250
these layers of translation that are

00:13:12,510 --> 00:13:16,710
unfortunate it's making a request to

00:13:14,250 --> 00:13:18,600
influx which is then Marsh

00:13:16,710 --> 00:13:20,790
the data is JSON which is inefficient

00:13:18,600 --> 00:13:23,250
which then gets parsed and then

00:13:20,790 --> 00:13:24,330
converted so what we'd like to do is see

00:13:23,250 --> 00:13:27,839
if we can eliminate some of that

00:13:24,330 --> 00:13:30,630
unnecessary overhead and for looking

00:13:27,839 --> 00:13:33,270
much further out the question I have is

00:13:30,630 --> 00:13:35,700
is it possible for us to push down some

00:13:33,270 --> 00:13:38,310
of the query processing so right now the

00:13:35,700 --> 00:13:40,890
way the remote read stuff works is it

00:13:38,310 --> 00:13:44,190
can request label matters and a time

00:13:40,890 --> 00:13:47,279
range but if you're doing any functions

00:13:44,190 --> 00:13:51,209
like sums or whatever histograms any of

00:13:47,279 --> 00:13:52,440
the other stuff or counts any any of

00:13:51,209 --> 00:13:54,920
those things you're actually streaming

00:13:52,440 --> 00:13:57,240
all of the raw data over the network to

00:13:54,920 --> 00:14:00,660
Prometheus which then process it

00:13:57,240 --> 00:14:02,640
processes it locally what I'd like to

00:14:00,660 --> 00:14:04,230
see is if we can actually get to a stage

00:14:02,640 --> 00:14:06,300
where we can push down some of these

00:14:04,230 --> 00:14:08,130
primitives and have them executed

00:14:06,300 --> 00:14:10,380
locally so that the summary data gets

00:14:08,130 --> 00:14:12,720
sent up and the Prometheus server would

00:14:10,380 --> 00:14:14,880
act to basically just combine those

00:14:12,720 --> 00:14:16,649
summaries so basically like think of it

00:14:14,880 --> 00:14:20,940
like a MapReduce that you run on the fly

00:14:16,649 --> 00:14:22,830
so this is this is the future stuff that

00:14:20,940 --> 00:14:25,459
that we're thinking about and so there's

00:14:22,830 --> 00:14:29,310
work that we've just recently started

00:14:25,459 --> 00:14:32,339
and I wanted to you know make it known

00:14:29,310 --> 00:14:33,600
to everybody here and talk about how we

00:14:32,339 --> 00:14:37,020
could potentially work with the

00:14:33,600 --> 00:14:38,580
Prometheus project to have what we want

00:14:37,020 --> 00:14:40,920
to accomplish together influence some of

00:14:38,580 --> 00:14:43,110
the work that we're doing so the first

00:14:40,920 --> 00:14:45,360
thing to note is we're going to be

00:14:43,110 --> 00:14:47,790
changing our data model we can represent

00:14:45,360 --> 00:14:49,230
our old data model using the new one the

00:14:47,790 --> 00:14:52,320
new data model is basically just going

00:14:49,230 --> 00:14:55,080
to be tags a value at a time this is

00:14:52,320 --> 00:14:57,570
very much like Prometheus right here in

00:14:55,080 --> 00:14:59,820
the remote definition is the proto for

00:14:57,570 --> 00:15:02,250
basically series data you have a sample

00:14:59,820 --> 00:15:04,079
which is a value in a timestamp you have

00:15:02,250 --> 00:15:06,029
the label pair and a time series is

00:15:04,079 --> 00:15:09,029
basically just a collection of label

00:15:06,029 --> 00:15:12,680
pairs and then a series of samples right

00:15:09,029 --> 00:15:15,899
so we're moving to the same model and

00:15:12,680 --> 00:15:17,670
the way obviously for Prometheus metric

00:15:15,899 --> 00:15:20,459
is basically just a label underscore

00:15:17,670 --> 00:15:22,620
underscore name for us will have

00:15:20,459 --> 00:15:25,110
underscore metric for Prometheus

00:15:22,620 --> 00:15:26,820
compatibility and for influx 1x

00:15:25,110 --> 00:15:28,650
compatibility will have underscore

00:15:26,820 --> 00:15:29,999
measurement so we'll basically be able

00:15:28,650 --> 00:15:33,209
to represent

00:15:29,999 --> 00:15:36,689
the Prometheus model plus the influx 1x

00:15:33,209 --> 00:15:39,109
model using this but we will for us will

00:15:36,689 --> 00:15:41,479
continue to support these data types

00:15:39,109 --> 00:15:43,619
we're not just going to be float64

00:15:41,479 --> 00:15:45,599
because we have other use cases where

00:15:43,619 --> 00:15:49,649
people people find that important for

00:15:45,599 --> 00:15:52,470
them so we are working on a new query

00:15:49,649 --> 00:15:54,419
language it's still very early days but

00:15:52,470 --> 00:15:57,029
we're basically defining a new language

00:15:54,419 --> 00:15:59,279
that looks very functional nature we

00:15:57,029 --> 00:16:01,529
found that the SQL style language is

00:15:59,279 --> 00:16:03,689
kind of painful to work with it doesn't

00:16:01,529 --> 00:16:06,449
I don't feel like it really Maps cleanly

00:16:03,689 --> 00:16:07,799
to working with time series data when I

00:16:06,449 --> 00:16:09,569
think of working with time series data

00:16:07,799 --> 00:16:14,039
actually think of working with like data

00:16:09,569 --> 00:16:15,569
frames or matrices of data so this is

00:16:14,039 --> 00:16:18,379
basically what it looks like at least

00:16:15,569 --> 00:16:20,789
one example of what it might look like

00:16:18,379 --> 00:16:23,220
we have a select statement still we

00:16:20,789 --> 00:16:24,869
specify a database we specify a where

00:16:23,220 --> 00:16:28,559
clause which is basically like label

00:16:24,869 --> 00:16:32,339
Gaucher's for us we have + or equals not

00:16:28,559 --> 00:16:35,629
equals reg X matches you get a range of

00:16:32,339 --> 00:16:38,909
time we can partition that into Windows

00:16:35,629 --> 00:16:41,429
and then we can compute aggregates

00:16:38,909 --> 00:16:43,019
across each window and then do things

00:16:41,429 --> 00:16:44,579
like interpolate the data to fill in

00:16:43,019 --> 00:16:44,929
missing values or any of that kind of

00:16:44,579 --> 00:16:48,569
stuff

00:16:44,929 --> 00:16:50,489
so one of the things as part of this

00:16:48,569 --> 00:16:52,529
effort is that we want a decouple the

00:16:50,489 --> 00:16:55,169
query language from the processing

00:16:52,529 --> 00:16:56,699
engine from the storage engine and this

00:16:55,169 --> 00:16:58,379
is where I think it gets interesting in

00:16:56,699 --> 00:17:01,079
terms of having Prometheus and it fluffs

00:16:58,379 --> 00:17:03,239
work together what that looks like is

00:17:01,079 --> 00:17:04,470
what I'm imagining this looks like is

00:17:03,239 --> 00:17:06,689
something like this and we actually have

00:17:04,470 --> 00:17:09,360
some prototype code already that we're

00:17:06,689 --> 00:17:11,730
going to be putting out in September

00:17:09,360 --> 00:17:13,799
that shows a couple of basic Prometheus

00:17:11,730 --> 00:17:15,269
queries that work along with I fql

00:17:13,799 --> 00:17:17,730
queries which is what we're tentatively

00:17:15,269 --> 00:17:19,620
calling the new language so the idea is

00:17:17,730 --> 00:17:23,309
you have the query language at the top

00:17:19,620 --> 00:17:25,559
in flex QL ifq L or prom QL or tick

00:17:23,309 --> 00:17:28,230
script that gets parsed and it gets

00:17:25,559 --> 00:17:31,620
parsed into a directed acyclic graph

00:17:28,230 --> 00:17:33,960
that describes what the query is that

00:17:31,620 --> 00:17:35,730
gets passed over to the execution engine

00:17:33,960 --> 00:17:39,029
which will then develop a plan to

00:17:35,730 --> 00:17:42,330
execute that graph and then go across n

00:17:39,029 --> 00:17:43,710
number of storage nodes to do it the dag

00:17:42,330 --> 00:17:46,020
can be represented as

00:17:43,710 --> 00:17:49,289
JSON here's an example basically we have

00:17:46,020 --> 00:17:51,570
operations we have select the range the

00:17:49,289 --> 00:17:54,120
sum and then you have edges that connect

00:17:51,570 --> 00:17:57,149
them it's always it's not always

00:17:54,120 --> 00:17:59,399
necessarily strictly a list it could be

00:17:57,149 --> 00:18:05,460
like a tree an inverted tree and that

00:17:59,399 --> 00:18:07,529
kind of stuff so I think so basically

00:18:05,460 --> 00:18:09,179
the debt the dag thing we hand it to the

00:18:07,529 --> 00:18:12,330
engine and then the engine figures out

00:18:09,179 --> 00:18:14,190
how to execute it it asks the storage

00:18:12,330 --> 00:18:16,409
tier each of the members of the storage

00:18:14,190 --> 00:18:19,320
tier what kind of capabilities it

00:18:16,409 --> 00:18:21,929
exposes so does it expose passing

00:18:19,320 --> 00:18:25,580
through the label matchers or the where

00:18:21,929 --> 00:18:28,890
predicate does it expose pushing down

00:18:25,580 --> 00:18:30,539
computation like count or sum or you

00:18:28,890 --> 00:18:33,840
know like tea digest or something like

00:18:30,539 --> 00:18:37,169
that so basically what we're looking at

00:18:33,840 --> 00:18:40,260
is can we can we do more in the remote

00:18:37,169 --> 00:18:42,600
read side of things add more potential

00:18:40,260 --> 00:18:45,029
complexity to be able to get processing

00:18:42,600 --> 00:18:47,190
locally that just sends summary text

00:18:45,029 --> 00:18:51,210
right do we have opportunities to

00:18:47,190 --> 00:18:53,730
improve stored / remote then the other

00:18:51,210 --> 00:18:55,559
thing we're looking at is bulk right the

00:18:53,730 --> 00:18:58,620
way the right gateway works right now is

00:18:55,559 --> 00:19:00,929
very very inefficient in terms of it

00:18:58,620 --> 00:19:02,460
just pulls you know sends all the stuff

00:19:00,929 --> 00:19:08,360
and then it writes it it can batch it

00:19:02,460 --> 00:19:10,470
that's fine but for influx the

00:19:08,360 --> 00:19:12,419
processing that data like parsing all

00:19:10,470 --> 00:19:13,799
the line protocol data and then indexing

00:19:12,419 --> 00:19:16,049
it and all this other stuff is fairly

00:19:13,799 --> 00:19:18,750
inefficient if we had some place where

00:19:16,049 --> 00:19:22,080
we were actually like able to pull bulk

00:19:18,750 --> 00:19:24,990
data out of Prometheus in the say the

00:19:22,080 --> 00:19:26,309
the TS DB 2.0 format we could probably

00:19:24,990 --> 00:19:29,100
come up with something that's far more

00:19:26,309 --> 00:19:33,510
efficient to translate that into the

00:19:29,100 --> 00:19:37,649
influx storage format so but overall

00:19:33,510 --> 00:19:39,240
like our the way we view like working

00:19:37,649 --> 00:19:40,770
with Prometheus is one we want to

00:19:39,240 --> 00:19:43,529
support the scrape targets we want to

00:19:40,770 --> 00:19:46,200
support the exposition format but we

00:19:43,529 --> 00:19:48,000
want to also support being a an option

00:19:46,200 --> 00:19:52,649
for long term storage

00:19:48,000 --> 00:19:55,549
and query of Prometheus data so that's

00:19:52,649 --> 00:19:55,549
all I have thanks

00:20:00,830 --> 00:20:13,580
questions hi I've got a question about

00:20:11,030 --> 00:20:15,710
the query language because as I

00:20:13,580 --> 00:20:18,440
understood it prometheus is planning to

00:20:15,710 --> 00:20:20,390
at some point include the type of the

00:20:18,440 --> 00:20:23,030
metric into its data model so that you

00:20:20,390 --> 00:20:25,520
can distinguish between click counters

00:20:23,030 --> 00:20:27,860
and gauges are you planning to do this

00:20:25,520 --> 00:20:33,020
right away also if you design the new

00:20:27,860 --> 00:20:35,480
data model and query language so I mean

00:20:33,020 --> 00:20:38,000
so we have talked about having type as

00:20:35,480 --> 00:20:39,820
part of it in the spec for like the new

00:20:38,000 --> 00:20:42,830
data model of Korean language I have

00:20:39,820 --> 00:20:44,870
underscore like type as a reserved like

00:20:42,830 --> 00:20:49,040
tag name so that we could later work

00:20:44,870 --> 00:20:49,760
with that in the query engine yeah okay

00:20:49,040 --> 00:20:53,179
hello god

00:20:49,760 --> 00:20:55,760
so my question is anybody test remote

00:20:53,179 --> 00:20:59,000
storage adapter performance on rats

00:20:55,760 --> 00:21:01,250
let's say sky testing or stress testing

00:20:59,000 --> 00:21:02,929
because in my case I'm trying to push

00:21:01,250 --> 00:21:06,500
something like 4 million metrics

00:21:02,929 --> 00:21:09,169
something like 70,000 metrics per

00:21:06,500 --> 00:21:10,940
seconds and impulsive is working

00:21:09,169 --> 00:21:14,390
prometheus is working but remote storage

00:21:10,940 --> 00:21:17,150
adapter is somehow dying i I don't know

00:21:14,390 --> 00:21:21,410
root cause but might be somebody anybody

00:21:17,150 --> 00:21:23,690
please yeah so so we haven't we haven't

00:21:21,410 --> 00:21:25,700
tested that yet actually that's one of

00:21:23,690 --> 00:21:28,880
the things I should have mentioned is we

00:21:25,700 --> 00:21:30,530
we'd like to pull in the to make it so

00:21:28,880 --> 00:21:32,360
that you don't need the if it wasn't

00:21:30,530 --> 00:21:34,070
obvious from the talk make it so you

00:21:32,360 --> 00:21:36,350
don't need the remote storage adapter

00:21:34,070 --> 00:21:37,730
you'd be able to edit your Prometheus

00:21:36,350 --> 00:21:39,980
config and actually just point it

00:21:37,730 --> 00:21:42,020
directly it influx and influx would

00:21:39,980 --> 00:21:45,830
implement all that stuff inside so that

00:21:42,020 --> 00:21:48,110
it would have a specific end point for

00:21:45,830 --> 00:21:52,190
handling premies Prometheus write

00:21:48,110 --> 00:21:54,590
requests and read requests so that's

00:21:52,190 --> 00:21:56,809
work that we'll get to later this year

00:21:54,590 --> 00:22:01,790
I would guess in not in the next release

00:21:56,809 --> 00:22:04,880
but the one after so 1.5 from from you

00:22:01,790 --> 00:22:06,149
ok so that you are going to support from

00:22:04,880 --> 00:22:14,519
QL right

00:22:06,149 --> 00:22:18,449
and so some model of gag stuff so why do

00:22:14,519 --> 00:22:22,949
you create new language no and don't use

00:22:18,449 --> 00:22:26,489
bronchial right away so that's because

00:22:22,949 --> 00:22:28,919
the are we have a bunch of different use

00:22:26,489 --> 00:22:30,869
cases that are usually not prometheus

00:22:28,919 --> 00:22:33,629
usually isn't concerned with and we have

00:22:30,869 --> 00:22:37,949
to keep those users in mind with the new

00:22:33,629 --> 00:22:41,759
the new query language so it's not it's

00:22:37,949 --> 00:22:44,909
not strictly a one-to-one mapping if

00:22:41,759 --> 00:22:47,729
nori could get ready please so right now

00:22:44,909 --> 00:22:49,829
folks EP has both labels and fields I'm

00:22:47,729 --> 00:22:52,349
index and heels and taxa index and that

00:22:49,829 --> 00:22:54,269
feels a lot and you're going to me right

00:22:52,349 --> 00:22:56,369
to tax doesn't mean that feels ago in

00:22:54,269 --> 00:22:59,999
the way and every type of index by

00:22:56,369 --> 00:23:02,129
default so you still have in the new

00:22:59,999 --> 00:23:04,799
model basically underscore field is

00:23:02,129 --> 00:23:09,149
reserved and you can have you can have

00:23:04,799 --> 00:23:11,089
that so basically you'll be able to get

00:23:09,149 --> 00:23:13,829
the same functionality is having fields

00:23:11,089 --> 00:23:18,299
it's just that the way it's represented

00:23:13,829 --> 00:23:20,639
is as you know underscore field then you

00:23:18,299 --> 00:23:22,949
have the field name and then the values

00:23:20,639 --> 00:23:27,359
are all there they're not indexed there

00:23:22,949 --> 00:23:32,239
just by range fun time range any other

00:23:27,359 --> 00:23:32,239
questions take very much full

00:23:32,350 --> 00:23:45,040
[Music]

00:23:44,850 --> 00:23:48,180
you

00:23:45,040 --> 00:23:48,180

YouTube URL: https://www.youtube.com/watch?v=BZkHlhautGk


