Title: PromCon 2017: A Worked Example of Monitoring a Queue Based Application - Laurie Clark-Michalek
Publication date: 2017-09-01
Playlist: PromCon 2017
Description: 
	* Abstract:

There has been a lot of work around educating people about how to instrument their applications, and how to set up your Prometheus installation to do tons of interesting things. This talk aims to address questions around which metrics provide the most value, and why. We will go through an example of instrumenting a service in production at Qubit, and explain the rationale behind the metrics we use for alerting and dashboarding. The aim is to give viewers a concrete example of how to monitor something, and highlight the logic behind the decisions made, be they specific to this service, or generalisable to almost anything.

Viewers should come away with the ability to implement meaningful instrumentation on their services, and a basic understanding around the answer to the questions ‘what makes a good metric’, ‘what makes a good dashboard’ and ‘what makes a good alert’. My aim is that the services that viewers write will wake people up needlessly less often, and when they wake people up, the service’s dashboards will be a boon to the responder, and not a false friend.

* Speaker biography:

Laurie is an engineer building systems with an eye to security, reliability and keeping people happy.

* Slides:

https://talks.generictestdomain.net/2017-08-18/talk.slide

* PromCon website:

https://promcon.io/
Captions: 
	00:00:00,380 --> 00:00:17,070
[Music]

00:00:12,980 --> 00:00:18,720
so now and Laurie Keller is going to

00:00:17,070 --> 00:00:22,650
talk about monitoring queue based

00:00:18,720 --> 00:00:25,380
applications hey so I don't have to full

00:00:22,650 --> 00:00:28,529
screen this so be able to see my Firefox

00:00:25,380 --> 00:00:45,450
head up I'm so I'm gonna give Bree f11

00:00:28,529 --> 00:00:57,750
okay so today it's okay to have a clicky

00:00:45,450 --> 00:00:59,480
thing as well this is going well okay so

00:00:57,750 --> 00:01:09,330
I'll hit space and that should be fine

00:00:59,480 --> 00:01:14,430
okay okay cool

00:01:09,330 --> 00:01:17,070
so yeah this is placed off work I did at

00:01:14,430 --> 00:01:19,560
my previous job at qubit since left

00:01:17,070 --> 00:01:21,950
there and work at another company not

00:01:19,560 --> 00:01:24,659
philia to Eve a company giving this talk

00:01:21,950 --> 00:01:28,979
so the basic idea of what I wanna tackle

00:01:24,659 --> 00:01:30,900
is we often with the people in the room

00:01:28,979 --> 00:01:33,689
are probably the monitoring enthusiasts

00:01:30,900 --> 00:01:36,420
are various employment places there are

00:01:33,689 --> 00:01:37,770
so a lot of people there who just they

00:01:36,420 --> 00:01:39,840
want monitoring because they are decent

00:01:37,770 --> 00:01:41,280
engineers and they see it as part of the

00:01:39,840 --> 00:01:42,780
engineering process but they're not

00:01:41,280 --> 00:01:45,780
actually you know enthused about

00:01:42,780 --> 00:01:47,640
monitoring or so and so forth so part of

00:01:45,780 --> 00:01:51,689
where the way I see that a lot is that

00:01:47,640 --> 00:01:53,549
people deploy previous or you say hey

00:01:51,689 --> 00:01:56,159
I've got problems q+ evesham on to your

00:01:53,549 --> 00:01:58,469
application and then the person wearing

00:01:56,159 --> 00:02:00,149
the application then says well cool I've

00:01:58,469 --> 00:02:01,649
read the tutorial I can understand the

00:02:00,149 --> 00:02:04,590
client library what do I actually

00:02:01,649 --> 00:02:06,299
monitor and part of the way I've been

00:02:04,590 --> 00:02:08,670
thinking about this is we can kind of

00:02:06,299 --> 00:02:10,619
find application archetypes we see on

00:02:08,670 --> 00:02:12,780
the prom documentation even it talks

00:02:10,619 --> 00:02:13,560
about here's how you Montes like request

00:02:12,780 --> 00:02:14,790
space here's how

00:02:13,560 --> 00:02:17,910
you monitor something that's kind of

00:02:14,790 --> 00:02:19,560
batch and one thing we saw a lot a cubit

00:02:17,910 --> 00:02:23,640
was Cubase applications thing that

00:02:19,560 --> 00:02:26,970
things that read and write to cues so my

00:02:23,640 --> 00:02:28,319
aim is to be kind of maybe a contrast

00:02:26,970 --> 00:02:30,630
the rest of the talks I don't want to be

00:02:28,319 --> 00:02:32,819
interesting here I want to explain how

00:02:30,630 --> 00:02:34,590
you can implement monitoring without

00:02:32,819 --> 00:02:36,450
thinking can take of a methodical

00:02:34,590 --> 00:02:38,760
approach that allows you to at the end

00:02:36,450 --> 00:02:40,860
of the day have something maybe not

00:02:38,760 --> 00:02:43,530
perfect but so you can build on and

00:02:40,860 --> 00:02:45,330
without really needing to think too much

00:02:43,530 --> 00:02:47,340
about what your application is actually

00:02:45,330 --> 00:02:49,890
doing beyond that that it seems to be

00:02:47,340 --> 00:02:51,959
doing something with keys so I'm gonna

00:02:49,890 --> 00:02:53,489
use that use an example I cube it we

00:02:51,959 --> 00:02:56,670
have this thing called stash the third

00:02:53,489 --> 00:02:59,420
and it tackled the complicated use case

00:02:56,670 --> 00:03:03,239
of I want to do something but in a bit

00:02:59,420 --> 00:03:04,799
so you would say hey can you send me I

00:03:03,239 --> 00:03:06,150
want to send you this message but here's

00:03:04,799 --> 00:03:07,950
a time standpoint I want to send it to

00:03:06,150 --> 00:03:10,680
you so kind of a big priority queue and

00:03:07,950 --> 00:03:13,049
so in from this in standard way we spun

00:03:10,680 --> 00:03:15,030
the big wheel of technologies and the

00:03:13,049 --> 00:03:16,530
mark I landed on BigTable so we had an

00:03:15,030 --> 00:03:18,570
API that wrote stuff into BigTable and

00:03:16,530 --> 00:03:20,040
then we spun the wheel again and then it

00:03:18,570 --> 00:03:22,769
landed on Kinesis so we wrote out

00:03:20,040 --> 00:03:24,209
records to Kinesis and so such as this

00:03:22,769 --> 00:03:26,070
little thing in the middle which sat

00:03:24,209 --> 00:03:28,489
there and it had a scanner which would

00:03:26,070 --> 00:03:31,350
continually read BigTable queries

00:03:28,489 --> 00:03:33,269
BigTable rose try and find any that

00:03:31,350 --> 00:03:35,640
would you had expired and would you to

00:03:33,269 --> 00:03:38,160
be sent off it then get pushed down over

00:03:35,640 --> 00:03:40,200
I go channel to a publisher would you

00:03:38,160 --> 00:03:41,519
then send them off Kinesis and then

00:03:40,200 --> 00:03:43,380
those keys would get sent down to

00:03:41,519 --> 00:03:45,269
Adelita which would then get delete them

00:03:43,380 --> 00:03:46,920
from Victor and there's a whole other

00:03:45,269 --> 00:03:48,989
faff around making sure we didn't scan

00:03:46,920 --> 00:03:51,150
same row twice while it was still being

00:03:48,989 --> 00:03:53,790
processed and all of them and it didn't

00:03:51,150 --> 00:03:55,440
scale and this whole thing kind of I

00:03:53,790 --> 00:03:57,209
think it still achieved kind of

00:03:55,440 --> 00:03:58,799
perfection and computing terms in the it

00:03:57,209 --> 00:04:01,079
ran on one box and did what was meant to

00:03:58,799 --> 00:04:03,030
despite the constraints anyway I

00:04:01,079 --> 00:04:05,220
unfortunately don't work you anymore so

00:04:03,030 --> 00:04:07,230
I had to re-implement it so I scan I

00:04:05,220 --> 00:04:09,090
spun the big wheel of technologies again

00:04:07,230 --> 00:04:10,920
ended up in MySQL in so picked it all

00:04:09,090 --> 00:04:12,150
this time and because it's like a cloud

00:04:10,920 --> 00:04:14,250
native thing I had to use a Google

00:04:12,150 --> 00:04:17,750
product still so we've got pub/sub in

00:04:14,250 --> 00:04:21,539
cytokinesis so how can we monitor this

00:04:17,750 --> 00:04:24,479
this is red stuff or whatever

00:04:21,539 --> 00:04:26,670
it goes for any operation in the entire

00:04:24,479 --> 00:04:27,630
world these are kind of things we can

00:04:26,670 --> 00:04:28,770
mantra about it there are some

00:04:27,630 --> 00:04:32,340
operations where you can't really define

00:04:28,770 --> 00:04:34,140
failure potentially but for basically

00:04:32,340 --> 00:04:36,450
living the world we can define success

00:04:34,140 --> 00:04:39,270
failure and duration and these these

00:04:36,450 --> 00:04:41,820
things aren't actually super useful in

00:04:39,270 --> 00:04:43,500
terms of maybe alerting you probably

00:04:41,820 --> 00:04:45,630
don't want to learn on this for every

00:04:43,500 --> 00:04:47,610
single random application every single

00:04:45,630 --> 00:04:49,530
random operation but it gives visibility

00:04:47,610 --> 00:04:51,630
so when it comes to actually

00:04:49,530 --> 00:04:55,650
implementing Prometheus alerting is a

00:04:51,630 --> 00:04:57,330
much harder goal so chief visibility is

00:04:55,650 --> 00:05:00,180
something you can implement in an hour

00:04:57,330 --> 00:05:01,740
you can get basic like idea of what is

00:05:00,180 --> 00:05:03,690
going on your application and people

00:05:01,740 --> 00:05:05,190
really enjoy knowing what's going on in

00:05:03,690 --> 00:05:07,950
their application so in terms of pushing

00:05:05,190 --> 00:05:09,630
Prometheus adoption getting the basic

00:05:07,950 --> 00:05:13,170
visibility and skipping alerting at the

00:05:09,630 --> 00:05:14,780
beginning is a good way of driving

00:05:13,170 --> 00:05:16,980
adoption and making people happy so

00:05:14,780 --> 00:05:20,460
super quickly what does this look like

00:05:16,980 --> 00:05:22,320
in prom metrics so we got at the top

00:05:20,460 --> 00:05:26,100
we've got delayed my SQL message read

00:05:22,320 --> 00:05:27,810
total so standard prom Meldrick format

00:05:26,100 --> 00:05:30,180
regard the namespace Adelaide and

00:05:27,810 --> 00:05:32,630
operation MySQL message read and any

00:05:30,180 --> 00:05:34,950
unit which is total there was a bit of

00:05:32,630 --> 00:05:36,630
debate where we should use total or

00:05:34,950 --> 00:05:39,090
count inside the company we eventually

00:05:36,630 --> 00:05:40,290
settled on total because counts is used

00:05:39,090 --> 00:05:43,590
in histograms and that could potentially

00:05:40,290 --> 00:05:45,090
be confusing if count is your convention

00:05:43,590 --> 00:05:46,410
stick to your conventions conventions

00:05:45,090 --> 00:05:49,470
are more important than being correct

00:05:46,410 --> 00:05:51,720
again here we've got two labels so we

00:05:49,470 --> 00:05:53,370
got failure and sesor one labeled two

00:05:51,720 --> 00:05:56,400
values failure and success to count

00:05:53,370 --> 00:05:58,980
count each case individually again

00:05:56,400 --> 00:06:01,200
there's in the community is suggested

00:05:58,980 --> 00:06:03,480
that you have a total without a label

00:06:01,200 --> 00:06:05,100
and then a separate error metric we had

00:06:03,480 --> 00:06:07,770
a very strong convention a cubit of

00:06:05,100 --> 00:06:09,960
having a result labeled with a failure

00:06:07,770 --> 00:06:12,030
and success value the convention was a

00:06:09,960 --> 00:06:15,810
lot more important than being correct on

00:06:12,030 --> 00:06:17,010
that one and then histograms so latency

00:06:15,810 --> 00:06:18,240
is a potentially a little bit

00:06:17,010 --> 00:06:20,850
interesting when it comes to monitoring

00:06:18,240 --> 00:06:22,350
any object application operation in that

00:06:20,850 --> 00:06:24,210
we don't actually always know how long

00:06:22,350 --> 00:06:26,100
cycle take if you really want to

00:06:24,210 --> 00:06:27,690
implement monitoring without thinking at

00:06:26,100 --> 00:06:29,220
all you don't actually want to think

00:06:27,690 --> 00:06:31,140
about how long it might take to say

00:06:29,220 --> 00:06:34,080
right to Kinesis especially if you've

00:06:31,140 --> 00:06:36,180
never used Kinesis before so what I've

00:06:34,080 --> 00:06:38,960
done here is we've monitored everything

00:06:36,180 --> 00:06:40,490
we've got buckets in the range of

00:06:38,960 --> 00:06:42,860
ten seconds all the way up to ten

00:06:40,490 --> 00:06:47,090
seconds and by using exponential buckets

00:06:42,860 --> 00:06:49,940
with a exponent of root ten we can cover

00:06:47,090 --> 00:06:52,130
a vast array of durations without a ton

00:06:49,940 --> 00:06:54,289
of buckets and because buckets means

00:06:52,130 --> 00:06:56,419
more metrics previous scales with number

00:06:54,289 --> 00:06:57,620
of metrics fewer buckets is better and

00:06:56,419 --> 00:06:59,180
one of the biggest problems we saw all

00:06:57,620 --> 00:07:01,400
the time was people creating way away

00:06:59,180 --> 00:07:02,949
too many buckets and this is an easy way

00:07:01,400 --> 00:07:06,110
to solve that problem

00:07:02,949 --> 00:07:07,639
so don't pull on the graph not an

00:07:06,110 --> 00:07:09,349
interesting query we've seen this group

00:07:07,639 --> 00:07:12,080
before I think in different places but

00:07:09,349 --> 00:07:14,570
super clearly through it rate the counts

00:07:12,080 --> 00:07:16,810
to get a rate and a greater than by

00:07:14,570 --> 00:07:19,310
result in this case we only ran one

00:07:16,810 --> 00:07:21,860
instance of this application so the sum

00:07:19,310 --> 00:07:23,330
there didn't really do much but if

00:07:21,860 --> 00:07:25,520
you're doing this without thinking you

00:07:23,330 --> 00:07:27,229
you want to know that rates you sum them

00:07:25,520 --> 00:07:29,840
because that's just what you do for

00:07:27,229 --> 00:07:32,539
rates and roughly the same for quanties

00:07:29,840 --> 00:07:34,340
we're gonna sum the rates and then we're

00:07:32,539 --> 00:07:37,880
gonna take the converse we're doing by

00:07:34,340 --> 00:07:39,889
le each bucket in a histogram is a le

00:07:37,880 --> 00:07:42,440
label so we just sum over the buckets

00:07:39,889 --> 00:07:44,780
and then take the contest again with

00:07:42,440 --> 00:07:47,570
conventions it's kind of ruined by the

00:07:44,780 --> 00:07:51,110
lines on the graph on the screen but we

00:07:47,570 --> 00:07:52,669
use 0.5 0.9 0.99 it's not meaningful to

00:07:51,110 --> 00:07:53,229
compare different contours from

00:07:52,669 --> 00:07:58,009
different

00:07:53,229 --> 00:08:00,320
quantiles with different values but so

00:07:58,009 --> 00:08:02,539
we settled a cubit and basically every

00:08:00,320 --> 00:08:05,449
single dashboard would use 0.5 0.9 to

00:08:02,539 --> 00:08:10,159
0.99 I didn't want Caesar per 8 but that

00:08:05,449 --> 00:08:12,469
was a odd day other things so dashboards

00:08:10,159 --> 00:08:14,030
have to be read by people units all of

00:08:12,469 --> 00:08:16,820
the you know the metric systems if I

00:08:14,030 --> 00:08:19,070
have units in the name or the diagrams

00:08:16,820 --> 00:08:21,080
have units on the side they also have

00:08:19,070 --> 00:08:21,830
titles these are things people make

00:08:21,080 --> 00:08:24,349
available to you

00:08:21,830 --> 00:08:26,389
Angra fana and they're like by far more

00:08:24,349 --> 00:08:28,430
valuable than I know coloring of graphs

00:08:26,389 --> 00:08:30,199
all of these graphs use the completed

00:08:28,430 --> 00:08:32,300
default color scheme because it doesn't

00:08:30,199 --> 00:08:35,120
add any value compared to say writing a

00:08:32,300 --> 00:08:36,770
meaningful title for your graph anyway

00:08:35,120 --> 00:08:38,390
so that's the really basic stuff let's

00:08:36,770 --> 00:08:41,570
go on to something a little bit Hugh

00:08:38,390 --> 00:08:43,310
specific so in a qubit system usually

00:08:41,570 --> 00:08:45,740
what we have is a long stream of things

00:08:43,310 --> 00:08:48,709
writing into each other and very basic

00:08:45,740 --> 00:08:50,779
we have a component a which is writing

00:08:48,709 --> 00:08:52,630
into component B and it's doing that

00:08:50,779 --> 00:08:57,130
over some kind of communication

00:08:52,630 --> 00:08:59,050
so this back pressure is what happens

00:08:57,130 --> 00:09:02,290
when thing we're writing into starts

00:08:59,050 --> 00:09:04,000
slowing down so the way we weigh

00:09:02,290 --> 00:09:06,550
component a right since come on bu can

00:09:04,000 --> 00:09:09,430
happen in three kind of ways it can

00:09:06,550 --> 00:09:11,110
happen it's unbuffered between them so

00:09:09,430 --> 00:09:14,590
it's something like pops up you can have

00:09:11,110 --> 00:09:16,780
an arbitrary number of messages that are

00:09:14,590 --> 00:09:18,970
currently pending between us to have

00:09:16,780 --> 00:09:21,820
been sent by QA it's like component a

00:09:18,970 --> 00:09:24,670
and not being read by component B yeah

00:09:21,820 --> 00:09:26,170
well that's the thing you can do I have

00:09:24,670 --> 00:09:28,540
opinions about that but they're not too

00:09:26,170 --> 00:09:30,120
relevant here you can have a limited

00:09:28,540 --> 00:09:32,860
buffer so this is where you can say I

00:09:30,120 --> 00:09:35,410
between component a and component B we

00:09:32,860 --> 00:09:37,810
could have a maximum say ten messages

00:09:35,410 --> 00:09:39,040
though do to be read by component B what

00:09:37,810 --> 00:09:40,390
happens here is that the buffer fills up

00:09:39,040 --> 00:09:42,220
and then you end up with something

00:09:40,390 --> 00:09:44,890
that's roughly equivalent to Campu

00:09:42,220 --> 00:09:46,390
type C where you have no buffer tool so

00:09:44,890 --> 00:09:48,880
in this case which is long and talked

00:09:46,390 --> 00:09:51,210
about here when component a writes a

00:09:48,880 --> 00:09:54,250
component B component need B needs to

00:09:51,210 --> 00:09:55,780
receive that message and then component

00:09:54,250 --> 00:09:57,850
a can continue to for doing what it

00:09:55,780 --> 00:10:00,340
wants to do this is important the cause

00:09:57,850 --> 00:10:02,320
if component B slows down it's going to

00:10:00,340 --> 00:10:04,330
take longer for component B to come

00:10:02,320 --> 00:10:06,700
around and say okay I'd like to have a

00:10:04,330 --> 00:10:08,890
new message now that means component a

00:10:06,700 --> 00:10:11,860
is going to spend more time waiting to

00:10:08,890 --> 00:10:14,440
send a message to component B so that

00:10:11,860 --> 00:10:17,650
time that spent waiting is back pressure

00:10:14,440 --> 00:10:19,990
so super simply here at the top I've got

00:10:17,650 --> 00:10:22,810
a simple go function but it should be

00:10:19,990 --> 00:10:24,400
moderately readable from by anyone we

00:10:22,810 --> 00:10:25,990
are in an infinite loop reading a

00:10:24,400 --> 00:10:28,870
message from my squirrel and then we're

00:10:25,990 --> 00:10:30,490
taking the time writing to component B

00:10:28,870 --> 00:10:32,350
which is the writer Chan

00:10:30,490 --> 00:10:35,620
I either think that publish it off to

00:10:32,350 --> 00:10:39,010
Kinesis and then we are observing the

00:10:35,620 --> 00:10:40,960
time since we started writing and that's

00:10:39,010 --> 00:10:41,860
being caught in a metric called delayed

00:10:40,960 --> 00:10:46,090
backpressure

00:10:41,860 --> 00:10:49,570
seconds so in go this might be specific

00:10:46,090 --> 00:10:51,070
to go slightly but if component B is

00:10:49,570 --> 00:10:53,110
waiting if component B is generally

00:10:51,070 --> 00:10:54,820
faster than component a will find that

00:10:53,110 --> 00:10:56,470
this actually takes like no time at all

00:10:54,820 --> 00:10:58,930
because component B has already gone

00:10:56,470 --> 00:11:01,000
through its cycle and is now waiting for

00:10:58,930 --> 00:11:03,910
something to be render in that case I

00:11:01,000 --> 00:11:06,040
think is like two locks time which is

00:11:03,910 --> 00:11:09,190
like 200 nanoseconds maybe I don't know

00:11:06,040 --> 00:11:11,050
and do the level stuff so this histogram

00:11:09,190 --> 00:11:12,880
here goes from one millisecond all the

00:11:11,050 --> 00:11:13,959
way up to one second which is less than

00:11:12,880 --> 00:11:17,170
what we talked about previously

00:11:13,959 --> 00:11:18,220
so back pressure to me I would expect

00:11:17,170 --> 00:11:20,860
the back pressure on this to be

00:11:18,220 --> 00:11:21,459
basically always zero and if it hits one

00:11:20,860 --> 00:11:22,990
second

00:11:21,459 --> 00:11:25,569
I would roughly consider that to be as

00:11:22,990 --> 00:11:29,110
bad as if it would hit a hundred seconds

00:11:25,569 --> 00:11:30,699
or so anyway dumping that on a graph

00:11:29,110 --> 00:11:33,220
it's exactly the same as what we saw

00:11:30,699 --> 00:11:34,930
before but not again we're not thinking

00:11:33,220 --> 00:11:36,279
about this at all we're just dumped it

00:11:34,930 --> 00:11:37,810
would take we know it's histogram so

00:11:36,279 --> 00:11:39,810
going to dump the quantiles at the

00:11:37,810 --> 00:11:41,829
quanto of numbers we've got conventions

00:11:39,810 --> 00:11:45,370
maybe the one interesting thing here is

00:11:41,829 --> 00:11:47,319
I've used a log axis on the y axis so

00:11:45,370 --> 00:11:48,579
see the distance between one millisecond

00:11:47,319 --> 00:11:50,050
and Timnath signs is the same as the

00:11:48,579 --> 00:11:52,660
distance you seen 10 milliseconds and

00:11:50,050 --> 00:11:55,899
100 milliseconds potentially this makes

00:11:52,660 --> 00:11:57,610
a slight difference in that as you go

00:11:55,899 --> 00:11:59,199
into the larger buckets the book the

00:11:57,610 --> 00:12:02,980
distance between buckets is larger

00:11:59,199 --> 00:12:04,959
obviously so what we find there is that

00:12:02,980 --> 00:12:07,569
each integer point has a lower accuracy

00:12:04,959 --> 00:12:09,100
I this is just like I was think to

00:12:07,569 --> 00:12:10,329
myself yesterday in a hotel room but by

00:12:09,100 --> 00:12:14,279
putting it on a log scale

00:12:10,329 --> 00:12:16,690
I think the accuracy per pixel of Y

00:12:14,279 --> 00:12:18,550
should be roughly equal and you don't

00:12:16,690 --> 00:12:20,680
suffer from weird distortions where

00:12:18,550 --> 00:12:24,699
values the high here are completely

00:12:20,680 --> 00:12:26,829
random now on psych actually useful

00:12:24,699 --> 00:12:27,970
right pressure is a little bit like if

00:12:26,829 --> 00:12:29,800
something goes wrong I might look at it

00:12:27,970 --> 00:12:31,120
but it's not you think I'd alert on

00:12:29,800 --> 00:12:34,990
immediately or at least not without

00:12:31,120 --> 00:12:36,699
thinking lag whatever is a it's my

00:12:34,990 --> 00:12:40,750
favorite metric by far when it comes to

00:12:36,699 --> 00:12:42,810
best systems so we can lag is very like

00:12:40,750 --> 00:12:45,490
everyone knows what like if I this

00:12:42,810 --> 00:12:47,199
system is Mentos you say I want to

00:12:45,490 --> 00:12:50,319
receive a message now if you receive a

00:12:47,199 --> 00:12:52,480
message now plus five seconds even the

00:12:50,319 --> 00:12:54,250
least technical user before I say okay

00:12:52,480 --> 00:12:56,260
it's a bit laggy and slightly more

00:12:54,250 --> 00:13:00,160
technical user conserve I like to be

00:12:56,260 --> 00:13:04,180
five seconds so way we did lag

00:13:00,160 --> 00:13:06,600
monitoring here was using a tracer so we

00:13:04,180 --> 00:13:10,209
would continually least every 10 seconds

00:13:06,600 --> 00:13:12,910
send a message and see how what the lag

00:13:10,209 --> 00:13:14,980
on it was so you know my top loop here

00:13:12,910 --> 00:13:17,829
I've got four ranging basically once

00:13:14,980 --> 00:13:19,080
every 10 seconds send a message which is

00:13:17,829 --> 00:13:21,540
jus now

00:13:19,080 --> 00:13:24,089
so because it's do now the if there is

00:13:21,540 --> 00:13:27,330
zero lag it should arrive now at my

00:13:24,089 --> 00:13:29,250
receiver and then in the data I also saw

00:13:27,330 --> 00:13:30,660
the time it's June and that means when I

00:13:29,250 --> 00:13:33,330
received the message I can look at

00:13:30,660 --> 00:13:35,399
message data to get this to see the time

00:13:33,330 --> 00:13:36,180
it should have arrived so then in my

00:13:35,399 --> 00:13:38,430
receiver

00:13:36,180 --> 00:13:40,890
I read that message N and I do the time

00:13:38,430 --> 00:13:43,290
since it should have arrived which is in

00:13:40,890 --> 00:13:44,579
message data and store that and dump

00:13:43,290 --> 00:13:47,190
that as a metric at the bottom as

00:13:44,579 --> 00:13:48,630
delayed lag seconds and I can alert on

00:13:47,190 --> 00:13:50,459
this and I can graph it and life is

00:13:48,630 --> 00:13:52,740
wonderful there is a slight issue though

00:13:50,459 --> 00:13:56,120
of what happens if the lag of monitor

00:13:52,740 --> 00:13:59,399
here goes down at the same time as my

00:13:56,120 --> 00:14:01,440
deferred whole big pipeline thing well

00:13:59,399 --> 00:14:03,870
what happened is the late like seconds

00:14:01,440 --> 00:14:05,370
will stay at 10 despite the fact that

00:14:03,870 --> 00:14:07,170
there are no new traces coming through

00:14:05,370 --> 00:14:09,959
and the whole thing is kind of gum tats

00:14:07,170 --> 00:14:14,010
up and we everything is terrible there

00:14:09,959 --> 00:14:17,070
is a better way of doing this so if what

00:14:14,010 --> 00:14:20,060
if instead of exporting delayed like

00:14:17,070 --> 00:14:23,130
seconds directly we exported the

00:14:20,060 --> 00:14:26,730
timestamp when the last message we last

00:14:23,130 --> 00:14:29,490
received was sent so by doing this we

00:14:26,730 --> 00:14:31,230
can then calculate the lag seconds by

00:14:29,490 --> 00:14:32,839
using the time function of Prometheus

00:14:31,230 --> 00:14:35,700
which returns the current unix timestamp

00:14:32,839 --> 00:14:37,380
minus the time when the last miss you

00:14:35,700 --> 00:14:40,020
receive was sent it's a bit of a

00:14:37,380 --> 00:14:42,270
mouthful but it ends up it being the

00:14:40,020 --> 00:14:44,640
same thing for any given instant of

00:14:42,270 --> 00:14:45,990
which previous was scraped sorry the

00:14:44,640 --> 00:14:49,410
application of script so we end up

00:14:45,990 --> 00:14:52,110
something like this one fun thing is if

00:14:49,410 --> 00:14:54,690
we go back to the Lions bottom here time

00:14:52,110 --> 00:14:56,610
- delay dag delay trace her last receive

00:14:54,690 --> 00:14:58,790
epoch seconds what's the gradient of

00:14:56,610 --> 00:15:02,339
this so the gradient of time is

00:14:58,790 --> 00:15:04,440
unsurprisingly one second per second and

00:15:02,339 --> 00:15:06,660
then delay trace the last receive epoch

00:15:04,440 --> 00:15:08,910
seconds would only ever reset so if we

00:15:06,660 --> 00:15:11,430
jump here what we see is lots of little

00:15:08,910 --> 00:15:13,140
jumping up and down and that's because

00:15:11,430 --> 00:15:15,060
this Prometheus I've got here is being

00:15:13,140 --> 00:15:18,300
scraped is scraping applications once

00:15:15,060 --> 00:15:19,649
every ten seconds so that we scrape and

00:15:18,300 --> 00:15:21,180
then over the next ten seconds

00:15:19,649 --> 00:15:22,769
it increases because time is increasing

00:15:21,180 --> 00:15:24,750
but the last time we received a message

00:15:22,769 --> 00:15:26,880
is not and then we scrape again and it

00:15:24,750 --> 00:15:28,620
resets there was have some big spikes an

00:15:26,880 --> 00:15:31,740
asterisk from me being a bad programmer

00:15:28,620 --> 00:15:34,950
and making the application panic

00:15:31,740 --> 00:15:37,580
cool so the sre book was mentioned

00:15:34,950 --> 00:15:39,750
earlier today one of the things that

00:15:37,580 --> 00:15:42,900
Google essary book talks a little bit

00:15:39,750 --> 00:15:44,640
about is SLI Xena salute so an SLI is a

00:15:42,900 --> 00:15:47,940
service level indicator

00:15:44,640 --> 00:15:50,310
and the way I've always answer this has

00:15:47,940 --> 00:15:52,020
been that it is a metric that correlates

00:15:50,310 --> 00:15:54,540
with what you might consider the

00:15:52,020 --> 00:15:57,600
operational health of the service so for

00:15:54,540 --> 00:16:01,440
this service I could say the average lag

00:15:57,600 --> 00:16:04,020
in any given time period is my SLI

00:16:01,440 --> 00:16:05,700
because I want to keep lag low but to be

00:16:04,020 --> 00:16:08,100
honest actually I consider a lag of more

00:16:05,700 --> 00:16:12,300
than 60 seconds as broken as a lag of a

00:16:08,100 --> 00:16:14,370
day so I define my lag at my sorry my s

00:16:12,300 --> 00:16:17,130
Elias what proportion of time was lag

00:16:14,370 --> 00:16:18,660
greater than 60 seconds and Prometheus

00:16:17,130 --> 00:16:22,320
makes it moderately easy to track this

00:16:18,660 --> 00:16:25,020
so I can just do delay like seconds is

00:16:22,320 --> 00:16:26,940
smaller than 60 but what happens if I do

00:16:25,020 --> 00:16:30,420
small of that is I get a filter that

00:16:26,940 --> 00:16:32,550
will return me any metrics where the

00:16:30,420 --> 00:16:35,010
current value of delayed like seconds is

00:16:32,550 --> 00:16:37,710
smaller than 60 what I actually want is

00:16:35,010 --> 00:16:39,960
what I've got here by adding bula after

00:16:37,710 --> 00:16:42,330
my smaller than sign this returns a

00:16:39,960 --> 00:16:45,150
metric where when delayed like seconds

00:16:42,330 --> 00:16:47,040
is smaller than 60 the rezoning metric

00:16:45,150 --> 00:16:50,010
is zero and when it's greater than it's

00:16:47,040 --> 00:16:52,350
1 and then if I want to say see the

00:16:50,010 --> 00:16:55,380
proportion of time which lag was greater

00:16:52,350 --> 00:16:58,080
than 60 seconds I can then take the

00:16:55,380 --> 00:17:00,180
average in any window here and it will

00:16:58,080 --> 00:17:03,600
return me the proportion of time which

00:17:00,180 --> 00:17:05,610
lag was greater than 60 seconds so I can

00:17:03,600 --> 00:17:08,310
dump this on side here and I can use

00:17:05,610 --> 00:17:11,130
Prometheus's average over time function

00:17:08,310 --> 00:17:13,590
so this allows me to take that so I

00:17:11,130 --> 00:17:16,410
should be clear here I've defined SLI

00:17:13,590 --> 00:17:18,600
colon delayed lag : threshold as an

00:17:16,410 --> 00:17:20,640
aggregate there and then I can take the

00:17:18,600 --> 00:17:23,340
window after 30 over the last 30 days

00:17:20,640 --> 00:17:24,960
and take the average over time so this

00:17:23,340 --> 00:17:27,510
is the kind of thing where we might

00:17:24,960 --> 00:17:30,630
calculate the lag on per cluster level

00:17:27,510 --> 00:17:32,160
and then we would Fed rate the SLI

00:17:30,630 --> 00:17:35,130
curran delays like a low threshold

00:17:32,160 --> 00:17:37,170
metric up to a kind of a longer term

00:17:35,130 --> 00:17:38,940
Prometheus incidence it's just like we

00:17:37,170 --> 00:17:41,280
did a qubit because our actual cluster

00:17:38,940 --> 00:17:43,650
level things have like 14 days or 15

00:17:41,280 --> 00:17:44,640
days worth of retention and they usually

00:17:43,650 --> 00:17:47,430
crash more often

00:17:44,640 --> 00:17:48,750
that whereas our long-term one it wasn't

00:17:47,430 --> 00:17:51,540
that great either but it had longer than

00:17:48,750 --> 00:17:53,730
that so I can dump this as a single stat

00:17:51,540 --> 00:17:55,020
on my graph

00:17:53,730 --> 00:17:57,750
I don't feel super useful to have this

00:17:55,020 --> 00:18:00,090
as a whole time series but as a kind of

00:17:57,750 --> 00:18:01,830
a top-level dime my per like this is the

00:18:00,090 --> 00:18:03,870
first thing I want you to see when you

00:18:01,830 --> 00:18:06,150
come to my dashboard and if any like

00:18:03,870 --> 00:18:08,370
wandering PM comes along they can look

00:18:06,150 --> 00:18:10,350
at this and say well I guess we should

00:18:08,370 --> 00:18:13,860
prioritize stability of a future

00:18:10,350 --> 00:18:16,260
development hopefully maybe one day so

00:18:13,860 --> 00:18:17,970
I've also got the like there because in

00:18:16,260 --> 00:18:20,040
the event of an actual incident you

00:18:17,970 --> 00:18:21,600
might you find that the lag often burns

00:18:20,040 --> 00:18:24,090
down so if you've got a large backlog

00:18:21,600 --> 00:18:25,530
you might increase capacity but your lag

00:18:24,090 --> 00:18:27,630
doesn't drop to zero immediately it just

00:18:25,530 --> 00:18:28,950
gradually decreases and so it's a nice

00:18:27,630 --> 00:18:31,260
thing to be able to track even though

00:18:28,950 --> 00:18:33,780
when systems fine it's completely

00:18:31,260 --> 00:18:35,640
useless working on it there are two

00:18:33,780 --> 00:18:38,760
things that I care about for a loading

00:18:35,640 --> 00:18:41,610
when it comes to Q's message messages

00:18:38,760 --> 00:18:44,400
being dropped and lack I never found a

00:18:41,610 --> 00:18:46,800
really really nice like well elegant way

00:18:44,400 --> 00:18:48,180
of measuring messages being dropped so I

00:18:46,800 --> 00:18:50,550
just like some of the errors which is a

00:18:48,180 --> 00:18:52,860
terrible terrible thing to do and it's

00:18:50,550 --> 00:18:54,600
not equivalent at all but lag is super

00:18:52,860 --> 00:18:56,010
easy you just say hey my lag it's great

00:18:54,600 --> 00:18:58,080
- in six seconds for five minutes which

00:18:56,010 --> 00:18:59,700
means if the thing goes down then within

00:18:58,080 --> 00:19:03,030
six minutes or so because you add that

00:18:59,700 --> 00:19:04,560
to them we should fire in a lot maybe

00:19:03,030 --> 00:19:06,000
one interesting thing here as well is

00:19:04,560 --> 00:19:09,840
the dashboard unscored Eurorail

00:19:06,000 --> 00:19:11,910
annotation so when Cubitt we wanted to

00:19:09,840 --> 00:19:14,550
ignore alerts we send them to slack and

00:19:11,910 --> 00:19:17,100
one thing we did was we if you added a

00:19:14,550 --> 00:19:19,980
dashboard URL annotation we'd add a nice

00:19:17,100 --> 00:19:22,230
little emoji of a think as a clipboard

00:19:19,980 --> 00:19:24,420
if you click that it take you through to

00:19:22,230 --> 00:19:27,000
your relevant dashboard and when in some

00:19:24,420 --> 00:19:28,440
cases we had her client alerts we can

00:19:27,000 --> 00:19:31,200
actually use templating from other

00:19:28,440 --> 00:19:33,390
variables - because graph ana allows you

00:19:31,200 --> 00:19:35,730
to parameterize a dashboard based on

00:19:33,390 --> 00:19:37,290
your route we could have the emoji take

00:19:35,730 --> 00:19:39,570
you directly through to the relevant

00:19:37,290 --> 00:19:40,980
dashboard for the client we also had

00:19:39,570 --> 00:19:45,090
other things for Brun books but I'm not

00:19:40,980 --> 00:19:47,130
sure anyone ever wrote a run book cool

00:19:45,090 --> 00:19:49,980
diagrams so this is actually my favorite

00:19:47,130 --> 00:19:51,830
thing in profanity I grant I think it

00:19:49,980 --> 00:19:54,630
was mentioned earlier at some point

00:19:51,830 --> 00:19:57,240
diagrams contextualize all the data in

00:19:54,630 --> 00:19:58,029
your dashboard dashboards are usually

00:19:57,240 --> 00:19:59,409
open by people

00:19:58,029 --> 00:20:01,349
stun them when something has gone wrong

00:19:59,409 --> 00:20:05,080
and that's when they need the most help

00:20:01,349 --> 00:20:07,840
dashboard should be documentation most -

00:20:05,080 --> 00:20:11,590
those aren't the diagram plugin sucks it

00:20:07,840 --> 00:20:14,049
is perfect - right it does not look very

00:20:11,590 --> 00:20:15,909
good it does weird weird things and it's

00:20:14,049 --> 00:20:18,129
not very good at showing a load of

00:20:15,909 --> 00:20:20,109
information but the fact that I love it

00:20:18,129 --> 00:20:21,969
so much regardless of all those flaws

00:20:20,109 --> 00:20:24,070
kind of speaks to its actual value just

00:20:21,969 --> 00:20:25,989
the feature that it provides so when

00:20:24,070 --> 00:20:28,899
someone comes to my dashboard they can

00:20:25,989 --> 00:20:30,429
immediately see ok the MySQL reader I

00:20:28,899 --> 00:20:32,259
can see the latency is and the rates up

00:20:30,429 --> 00:20:36,099
here and this is that you where it sits

00:20:32,259 --> 00:20:39,219
in a broader context so super query

00:20:36,099 --> 00:20:43,239
going through that it looks a bit like

00:20:39,219 --> 00:20:45,279
dot it's not that I wish it was dot you

00:20:43,239 --> 00:20:48,580
have nodes you have edges you have

00:20:45,279 --> 00:20:51,159
graphed you have sub graphs ya be

00:20:48,580 --> 00:20:54,369
consistent the only thing I might really

00:20:51,159 --> 00:20:58,089
mention here is that squares diamonds

00:20:54,369 --> 00:21:01,139
and circles do not use them from of

00:20:58,089 --> 00:21:04,210
those is that they the area of those is

00:21:01,139 --> 00:21:06,039
relevant is proportional to the square

00:21:04,210 --> 00:21:07,989
of the amount of information of the

00:21:06,039 --> 00:21:10,359
amount of text inside them so that means

00:21:07,989 --> 00:21:13,479
if I have a long label like MySQL reader

00:21:10,359 --> 00:21:15,009
I get a very very big box and that kind

00:21:13,479 --> 00:21:16,330
of leads the human brain to believe that

00:21:15,009 --> 00:21:18,070
that thing is happening a lot Early's

00:21:16,330 --> 00:21:19,839
that's what happens for me I think that

00:21:18,070 --> 00:21:22,599
a big box means this thing is happening

00:21:19,839 --> 00:21:24,429
a lot if I use a rectangle then it's

00:21:22,599 --> 00:21:26,759
linear and my brain doesn't get as

00:21:24,429 --> 00:21:29,830
confused about half and that's happening

00:21:26,759 --> 00:21:35,109
cool so I ended up with something that

00:21:29,830 --> 00:21:37,869
looks like doo-doo-doo this I just fell

00:21:35,109 --> 00:21:42,039
thinking so this is the the aim here is

00:21:37,869 --> 00:21:44,190
that as a developer I can come along on

00:21:42,039 --> 00:21:46,269
day zero of having Prometheus and

00:21:44,190 --> 00:21:48,399
implement a dashboard that looks a bit

00:21:46,269 --> 00:21:51,729
like this and this is a decent starting

00:21:48,399 --> 00:21:52,929
point and someone who sees this probably

00:21:51,729 --> 00:21:54,639
understands some of the value of

00:21:52,929 --> 00:21:55,960
Prometheus and decent monitoring at this

00:21:54,639 --> 00:21:59,080
point actually like nothing I've really

00:21:55,960 --> 00:22:00,700
said here is very specific but like

00:21:59,080 --> 00:22:02,440
someone who sees this from day one can

00:22:00,700 --> 00:22:04,629
kind of get the value of decent

00:22:02,440 --> 00:22:06,970
monitoring and then they can come along

00:22:04,629 --> 00:22:08,450
long later because they've got the kind

00:22:06,970 --> 00:22:12,650
of the vocabulary now

00:22:08,450 --> 00:22:14,930
add in alerts they can customize this so

00:22:12,650 --> 00:22:17,090
I think there are some useless things

00:22:14,930 --> 00:22:19,040
there I think my school reader back

00:22:17,090 --> 00:22:21,260
pressure is actually useless I think my

00:22:19,040 --> 00:22:23,840
school latency and massacre read rate ah

00:22:21,260 --> 00:22:25,670
you only need one of them actually my

00:22:23,840 --> 00:22:27,380
school reader rate it's always one

00:22:25,670 --> 00:22:30,440
because I set it up to Paul at one per

00:22:27,380 --> 00:22:32,420
second so there's some really terrible

00:22:30,440 --> 00:22:34,670
things there but this is about as much

00:22:32,420 --> 00:22:36,320
information as I want on a graph we can

00:22:34,670 --> 00:22:38,090
see that the diagram is right down the

00:22:36,320 --> 00:22:39,800
bottom just below the fold I think

00:22:38,090 --> 00:22:42,230
that's fine it's ugly but it will draw

00:22:39,800 --> 00:22:44,330
your eye and you'll probably nothing

00:22:42,230 --> 00:22:46,370
below that and I tried very hard not to

00:22:44,330 --> 00:22:48,320
include information but below the fold

00:22:46,370 --> 00:22:50,270
because when you're scrolling down on

00:22:48,320 --> 00:22:53,750
dashboard and it's just line after the

00:22:50,270 --> 00:22:56,480
line after the line of graphs you don't

00:22:53,750 --> 00:22:59,330
actually gain anything from it it's it

00:22:56,480 --> 00:23:02,960
just I can't scroll down on dashboards

00:22:59,330 --> 00:23:04,490
it breaks me one potential thing you

00:23:02,960 --> 00:23:08,120
might add here I think I had back in

00:23:04,490 --> 00:23:12,050
Cuba on my dash was some system stats

00:23:08,120 --> 00:23:14,090
CPU memory and network they were pure

00:23:12,050 --> 00:23:16,940
vanity for me I was very proud of this

00:23:14,090 --> 00:23:20,750
that it ran on 50 Meg of RAM and it was

00:23:16,940 --> 00:23:23,150
all on one box but and when you but if

00:23:20,750 --> 00:23:26,210
there ever was an issue with my system

00:23:23,150 --> 00:23:28,610
stats I would actually go and click on a

00:23:26,210 --> 00:23:31,340
dashboard for system stats when we had

00:23:28,610 --> 00:23:35,660
many of them one thing I'd love to you

00:23:31,340 --> 00:23:37,340
fana is a bit more kind of cooperation

00:23:35,660 --> 00:23:39,470
between graphs so I would love to be

00:23:37,340 --> 00:23:41,900
able to hover over my chant and have

00:23:39,470 --> 00:23:43,850
that highlight some of the other charts

00:23:41,900 --> 00:23:47,000
so that when I hovered over - go reader

00:23:43,850 --> 00:23:48,770
instantly it would light up the read

00:23:47,000 --> 00:23:50,000
rate and the real agency because that

00:23:48,770 --> 00:23:51,440
kind of stuff would actually be really

00:23:50,000 --> 00:23:54,650
cool and useful when it comes to

00:23:51,440 --> 00:23:56,770
navigating this stuff but broadly I was

00:23:54,650 --> 00:24:02,260
fairly happy with where we ended up and

00:23:56,770 --> 00:24:02,260
yeah that's it

00:24:06,110 --> 00:24:09,710
[Applause]

00:24:10,280 --> 00:24:24,590
I am you mentioned from solver lining

00:24:22,340 --> 00:24:30,140
the graphs there is a there is a shed

00:24:24,590 --> 00:24:30,950
yeah there is a shared crosshair here a

00:24:30,140 --> 00:24:32,570
teacher in Befana

00:24:30,950 --> 00:24:34,040
so when you scroll over you can actually

00:24:32,570 --> 00:24:35,870
see the values on the other graphs as

00:24:34,040 --> 00:24:37,700
you go along yeah I just looked up four

00:24:35,870 --> 00:24:39,440
diagrams so I could actually correlate

00:24:37,700 --> 00:24:42,020
the diagram with the appropriate like

00:24:39,440 --> 00:24:43,280
columns and so on in the dash book cool

00:24:42,020 --> 00:24:44,720
okay the other thing I was going to

00:24:43,280 --> 00:24:46,340
stress is I don't know if you've seen

00:24:44,720 --> 00:24:49,070
the claps cool that's a claps four rows

00:24:46,340 --> 00:24:50,270
ingre fauna so sometimes if you have if

00:24:49,070 --> 00:24:51,640
you do need to put a lot on a graph

00:24:50,270 --> 00:24:54,230
sometimes that's really useful for

00:24:51,640 --> 00:24:56,780
hiding some information and they only

00:24:54,230 --> 00:24:59,930
load as you actually open their rows so

00:24:56,780 --> 00:25:02,720
I find that super useful for more larger

00:24:59,930 --> 00:25:05,570
dashboards if you if you do have to I've

00:25:02,720 --> 00:25:06,950
always preferred kind of drill down

00:25:05,570 --> 00:25:09,140
dashboards so one thing you can do in

00:25:06,950 --> 00:25:12,680
qivana is you can have the title be a

00:25:09,140 --> 00:25:15,470
link to another dashboard so kind of I

00:25:12,680 --> 00:25:16,640
find that for say system stats it's

00:25:15,470 --> 00:25:18,050
counting where you end up the

00:25:16,640 --> 00:25:20,690
organization bills like a very

00:25:18,050 --> 00:25:22,550
comprehensive per machine stats

00:25:20,690 --> 00:25:25,220
dashboard and then like have a drill

00:25:22,550 --> 00:25:26,900
down to that class for rows on the graph

00:25:25,220 --> 00:25:29,030
a know you want user experience a little

00:25:26,900 --> 00:25:32,240
bit terrible sorry anyone for Cortana

00:25:29,030 --> 00:25:35,450
here and I find like finding via the

00:25:32,240 --> 00:25:37,500
expanding very complicated but maybe

00:25:35,450 --> 00:25:50,260
that's just me

00:25:37,500 --> 00:25:50,440
[Music]

00:25:50,260 --> 00:25:53,579
you

00:25:50,440 --> 00:25:53,579

YouTube URL: https://www.youtube.com/watch?v=EtxM48cWr4Y


