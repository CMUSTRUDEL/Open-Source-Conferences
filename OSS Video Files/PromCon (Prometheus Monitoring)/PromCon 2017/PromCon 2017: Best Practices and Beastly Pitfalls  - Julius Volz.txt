Title: PromCon 2017: Best Practices and Beastly Pitfalls  - Julius Volz
Publication date: 2017-09-01
Playlist: PromCon 2017
Description: 
	* Abstract:

Julius gives an overview over the most important best practices and most treacherous pitfalls when starting to use Prometheus.

* Speaker biography:

Julius co-founded Prometheus and lead the project to success at SoundCloud and beyond. He now freelances around Prometheus, focuses on growing the Prometheus community, and is the lead organizer of PromCon. In a previous life, Julius was a Site Reliability Engineer at Google.

* Slides:

https://promcon.io/2017-munich/slides/best-practices-and-beastly-pitfalls.pdf

* PromCon website:

https://promcon.io/
Captions: 
	00:00:00,380 --> 00:00:15,570
[Music]

00:00:13,190 --> 00:00:20,160
next up we've gotta be secured

00:00:15,570 --> 00:00:22,289
who's most of you won't know him he's

00:00:20,160 --> 00:00:27,869
pretty new to Prometheus his coach

00:00:22,289 --> 00:00:29,160
Julius and he's be telling about he'll

00:00:27,869 --> 00:00:30,119
be talking about best practices and

00:00:29,160 --> 00:00:33,059
beastie controls

00:00:30,119 --> 00:00:35,280
yeah I'm probably actually the person

00:00:33,059 --> 00:00:42,239
with the longest years of Prometheus

00:00:35,280 --> 00:00:44,820
experience as well all right

00:00:42,239 --> 00:00:47,129
welcome to Prometheus best practices in

00:00:44,820 --> 00:00:48,570
beastly pitfalls I had to put the

00:00:47,129 --> 00:00:50,850
beastly in there for Brian because

00:00:48,570 --> 00:00:54,440
that's like it alliteration type kind of

00:00:50,850 --> 00:00:57,539
thing that makes it sound more exciting

00:00:54,440 --> 00:01:00,629
so as you might know Prometheus the

00:00:57,539 --> 00:01:03,270
monitoring system was named after this

00:01:00,629 --> 00:01:06,689
person here Prometheus the ancient Greek

00:01:03,270 --> 00:01:08,640
Titan and was he most famous for for

00:01:06,689 --> 00:01:11,520
stealing the fire from the gods and

00:01:08,640 --> 00:01:16,590
bringing it to the humans and so that's

00:01:11,520 --> 00:01:18,689
amazing but you know oh let me just get

00:01:16,590 --> 00:01:25,770
rid of this mirror display kind of thing

00:01:18,689 --> 00:01:29,369
here yeah as a punishment for that he

00:01:25,770 --> 00:01:32,130
got tied to rock for all of eternity by

00:01:29,369 --> 00:01:34,590
the gods and basically got his liver

00:01:32,130 --> 00:01:37,740
picked out every day again and again and

00:01:34,590 --> 00:01:39,540
the tree grew again and again and as

00:01:37,740 --> 00:01:41,490
Richard here likes to say sometimes

00:01:39,540 --> 00:01:43,500
Prometheus feels more like in the first

00:01:41,490 --> 00:01:45,810
picture but on some days the fields

00:01:43,500 --> 00:01:48,350
you're like using from it just feels

00:01:45,810 --> 00:01:51,540
more like in the second picture and so

00:01:48,350 --> 00:01:54,329
the goal of this talk is to make it you

00:01:51,540 --> 00:01:56,250
feel at least somewhat more like in the

00:01:54,329 --> 00:01:59,460
you know make you feel more often like

00:01:56,250 --> 00:02:04,409
you're in the in the first picture like

00:01:59,460 --> 00:02:06,990
illuminating your systems it's kind of

00:02:04,409 --> 00:02:09,239
in I would say in entry level some

00:02:06,990 --> 00:02:10,679
intermediate kind of level talk stuff

00:02:09,239 --> 00:02:12,700
and you've already heard some of it

00:02:10,679 --> 00:02:15,160
today from other speakers

00:02:12,700 --> 00:02:18,459
I'm going to cover instrumentation

00:02:15,160 --> 00:02:20,739
alerting and querying I had architecture

00:02:18,459 --> 00:02:23,739
and topology in there earlier but then I

00:02:20,739 --> 00:02:26,230
noticed I only have a 20 minute slot so

00:02:23,739 --> 00:02:27,250
that's what we have for now so I'll

00:02:26,230 --> 00:02:30,250
start pretty general with

00:02:27,250 --> 00:02:32,500
instrumentation not really premiere

00:02:30,250 --> 00:02:36,250
specific but Prometheus is a very

00:02:32,500 --> 00:02:38,440
efficient metric storing system and it's

00:02:36,250 --> 00:02:41,830
all about having good white box

00:02:38,440 --> 00:02:44,760
instrumentation in your software so

00:02:41,830 --> 00:02:47,560
really one big recommendation is to add

00:02:44,760 --> 00:02:49,390
metrics through all throughout all of

00:02:47,560 --> 00:02:51,549
your major components of your software

00:02:49,390 --> 00:02:53,650
including libraries that that they use

00:02:51,549 --> 00:02:57,390
so that you don't have to wrap any

00:02:53,650 --> 00:02:59,290
libraries that you use with metrics

00:02:57,390 --> 00:03:01,120
spread the metric very liberally

00:02:59,290 --> 00:03:04,299
everywhere where you would traditionally

00:03:01,120 --> 00:03:06,160
have had or still have a lot line just

00:03:04,299 --> 00:03:07,660
add a dimensionless counter like you

00:03:06,160 --> 00:03:11,590
know Prometheus is very good at handling

00:03:07,660 --> 00:03:13,390
big dimension dimensional metrics but

00:03:11,590 --> 00:03:15,160
the ones that don't even have any

00:03:13,390 --> 00:03:17,350
dimensions they are so cheap just add

00:03:15,160 --> 00:03:19,540
them everywhere and it just makes it

00:03:17,350 --> 00:03:21,519
very easy to figure out like how many

00:03:19,540 --> 00:03:25,420
times a certain arrows happened or

00:03:21,519 --> 00:03:27,910
things like that there's two methods

00:03:25,420 --> 00:03:29,709
that Alexander mentioned in his talk

00:03:27,910 --> 00:03:32,200
already the use method and the read

00:03:29,709 --> 00:03:35,350
method the use method got coined by

00:03:32,200 --> 00:03:36,910
Brendan Gregg that's so these are two

00:03:35,350 --> 00:03:39,670
methods that just give you a guideline

00:03:36,910 --> 00:03:42,700
around what metrics in general to add to

00:03:39,670 --> 00:03:44,079
your software the use method is for when

00:03:42,700 --> 00:03:46,900
you have something that looks a bit like

00:03:44,079 --> 00:03:49,630
a resource you know like a queue CPU or

00:03:46,900 --> 00:03:52,450
disk where you want to track utilization

00:03:49,630 --> 00:03:54,880
saturation and errors and you can find

00:03:52,450 --> 00:03:57,910
more about that on the link given there

00:03:54,880 --> 00:03:59,859
the read method was coined by Tom Wilkie

00:03:57,910 --> 00:04:01,480
who's in the audience here somewhere

00:03:59,859 --> 00:04:04,030
if he has made it here today arc back

00:04:01,480 --> 00:04:07,000
there so it's just a kind of a

00:04:04,030 --> 00:04:09,099
complementary method that works better

00:04:07,000 --> 00:04:11,470
if you have something that looks like a

00:04:09,099 --> 00:04:13,989
service endpoint that receives requests

00:04:11,470 --> 00:04:16,359
and so you want to track the request

00:04:13,989 --> 00:04:19,539
rate and you want to track the total

00:04:16,359 --> 00:04:23,519
error rate and also the latency

00:04:19,539 --> 00:04:23,519
distribution so T duration

00:04:23,729 --> 00:04:30,699
getting more Prometheus specific

00:04:26,729 --> 00:04:33,180
Prometheus doesn't really have any

00:04:30,699 --> 00:04:36,550
server-side typing of metrics or

00:04:33,180 --> 00:04:37,690
knowledge of units there's some typing

00:04:36,550 --> 00:04:39,550
in the client libraries

00:04:37,690 --> 00:04:41,830
you know gauges counters histograms that

00:04:39,550 --> 00:04:43,210
even get put into the wire format but

00:04:41,830 --> 00:04:43,960
then just gets thrown away by the

00:04:43,210 --> 00:04:46,509
Prometheus server

00:04:43,960 --> 00:04:51,550
upon ingestion plans to change that but

00:04:46,509 --> 00:04:54,250
not yet so to make metrics more useful

00:04:51,550 --> 00:04:55,690
to work with for humans we have a set of

00:04:54,250 --> 00:04:57,490
conventions that we recommend for

00:04:55,690 --> 00:04:59,139
everyone to follow if you're adding

00:04:57,490 --> 00:05:02,020
metrics your own metrics to your own

00:04:59,139 --> 00:05:03,940
software first would be really add unit

00:05:02,020 --> 00:05:06,400
suffixes and if you're adding these

00:05:03,940 --> 00:05:10,270
units like buy it seconds and so on keep

00:05:06,400 --> 00:05:13,000
them as base units so seconds versus

00:05:10,270 --> 00:05:15,610
milliseconds by it's kind of then

00:05:13,000 --> 00:05:17,440
kilobytes or megabytes or so and this

00:05:15,610 --> 00:05:20,169
just makes it easier just by looking at

00:05:17,440 --> 00:05:22,360
a metric name to know what unit is it is

00:05:20,169 --> 00:05:24,280
in and also do not have to convert when

00:05:22,360 --> 00:05:27,039
you're doing arithmetic between

00:05:24,280 --> 00:05:30,400
different metrics or comparisons or so

00:05:27,039 --> 00:05:32,830
on now you want to distinguish gauges

00:05:30,400 --> 00:05:35,469
from counters so current tallies of

00:05:32,830 --> 00:05:38,560
things from cumulative counts over time

00:05:35,469 --> 00:05:41,380
by having an underscore total suffix on

00:05:38,560 --> 00:05:44,979
counters and having none so no such

00:05:41,380 --> 00:05:48,130
topics on Khan gauges now there's a

00:05:44,979 --> 00:05:50,529
really nice rule of thumb that I like it

00:05:48,130 --> 00:05:53,710
is that all the series that belong to

00:05:50,529 --> 00:05:55,690
the same metric name should it should

00:05:53,710 --> 00:05:58,180
either make sense to sum over all of

00:05:55,690 --> 00:06:00,580
them or to average over all of them in

00:05:58,180 --> 00:06:03,279
the usual case so that means basically

00:06:00,580 --> 00:06:06,490
that all the label dimensions on a given

00:06:03,279 --> 00:06:08,879
metric name should partition that metric

00:06:06,490 --> 00:06:11,400
space completely and without overlap

00:06:08,879 --> 00:06:14,919
meaning let's say for example you are

00:06:11,400 --> 00:06:17,349
exposing CPU usage metrics and seconds

00:06:14,919 --> 00:06:19,629
and you want to have a mode label on

00:06:17,349 --> 00:06:22,389
there you might want to have modes like

00:06:19,629 --> 00:06:25,629
mode equals idle mode equals user mode

00:06:22,389 --> 00:06:28,029
equal system but don't add something

00:06:25,629 --> 00:06:30,069
like mode equals total because that

00:06:28,029 --> 00:06:31,960
actually overlaps with the others and if

00:06:30,069 --> 00:06:34,370
you know sum over the whole thing you'll

00:06:31,960 --> 00:06:36,919
get a double counted instead leave that

00:06:34,370 --> 00:06:40,669
out do any such summing and calculations

00:06:36,919 --> 00:06:42,260
in Prometheus instead and in other

00:06:40,669 --> 00:06:44,060
situations you might want to split

00:06:42,260 --> 00:06:48,440
certain parts out of the metric name

00:06:44,060 --> 00:06:50,570
there's some situations where this rule

00:06:48,440 --> 00:06:53,500
doesn't apply like if you're bridging

00:06:50,570 --> 00:06:57,530
some existing table kind of paste matrix

00:06:53,500 --> 00:06:59,360
into Prometheus more details on the

00:06:57,530 --> 00:07:01,940
website of parameters IO about the

00:06:59,360 --> 00:07:03,440
naming follow this if you are adding

00:07:01,940 --> 00:07:05,710
metrics to your own software

00:07:03,440 --> 00:07:10,280
it'll make everyone's lives easier

00:07:05,710 --> 00:07:11,900
labour carbon ality this is also it was

00:07:10,280 --> 00:07:13,669
a pretty obvious one but something that

00:07:11,900 --> 00:07:16,580
still happens to everyone who starts

00:07:13,669 --> 00:07:18,380
using Prometheus the first time they end

00:07:16,580 --> 00:07:20,810
up putting something in the label value

00:07:18,380 --> 00:07:24,320
that they shouldn't keep in mind that

00:07:20,810 --> 00:07:26,960
every unique set of labels creates one

00:07:24,320 --> 00:07:28,550
new time series and Prometheus you know

00:07:26,960 --> 00:07:30,199
has a limited number of time series that

00:07:28,550 --> 00:07:34,070
it contract at any given time it's not a

00:07:30,199 --> 00:07:36,350
log based system a track series so you

00:07:34,070 --> 00:07:40,310
know don't put public IP addresses user

00:07:36,350 --> 00:07:43,580
IDs or soundcloud track IDs into a label

00:07:40,310 --> 00:07:45,800
value because otherwise your Prometheus

00:07:43,580 --> 00:07:47,539
will immediately blow up it will create

00:07:45,800 --> 00:07:51,289
potentially you know millions billions

00:07:47,539 --> 00:07:55,280
of series so keep your label values

00:07:51,289 --> 00:07:57,680
generally well bounded keep in mind that

00:07:55,280 --> 00:07:59,389
the cardinality is our multiplicative so

00:07:57,680 --> 00:08:00,979
to get to the total number of series

00:07:59,389 --> 00:08:03,260
that you will have to deal with in a

00:08:00,979 --> 00:08:06,020
given Prometheus server you have to

00:08:03,260 --> 00:08:08,720
multiply you know all the metrics with

00:08:06,020 --> 00:08:11,930
the individual cardinalities of their

00:08:08,720 --> 00:08:13,220
labels times the number of targets you

00:08:11,930 --> 00:08:15,919
have that you're scraping for those

00:08:13,220 --> 00:08:17,750
metrics and then you'll end up at the

00:08:15,919 --> 00:08:20,660
total number of metrics that you have

00:08:17,750 --> 00:08:23,270
and the limits that actually ultimately

00:08:20,660 --> 00:08:25,400
matter are what parameters can do under

00:08:23,270 --> 00:08:26,750
the ingestion side and what it can do on

00:08:25,400 --> 00:08:29,210
the query side and for the ingestion

00:08:26,750 --> 00:08:31,669
side a single parameter server typically

00:08:29,210 --> 00:08:35,479
is fine with a couple of million active

00:08:31,669 --> 00:08:37,849
series at the same time and queries you

00:08:35,479 --> 00:08:39,800
typically want to still be able to at

00:08:37,849 --> 00:08:42,050
least in the tabular view in the instant

00:08:39,800 --> 00:08:45,020
we review be able to query one metric

00:08:42,050 --> 00:08:46,610
name with all of its series without any

00:08:45,020 --> 00:08:48,180
further filters so that you can start

00:08:46,610 --> 00:08:50,970
exploring from there

00:08:48,180 --> 00:08:52,920
so also try to keep a single metric -

00:08:50,970 --> 00:08:55,170
maybe a couple of tens of thousands of

00:08:52,920 --> 00:08:57,779
series but that should be really the

00:08:55,170 --> 00:08:59,790
upper limit so choose your metrics the

00:08:57,779 --> 00:09:02,010
labels on them and the number of targets

00:08:59,790 --> 00:09:06,660
accordingly just to kind of stay within

00:09:02,010 --> 00:09:09,690
those limits so if you have something

00:09:06,660 --> 00:09:12,810
that handles requests that can fail and

00:09:09,690 --> 00:09:15,180
succeed one of the first things that

00:09:12,810 --> 00:09:17,610
people typically do intuitively is they

00:09:15,180 --> 00:09:21,420
add two counters one for successes and

00:09:17,610 --> 00:09:22,920
one for failures or sometimes that might

00:09:21,420 --> 00:09:25,950
even have you know single metric with a

00:09:22,920 --> 00:09:28,019
label but this is actually nicer so the

00:09:25,950 --> 00:09:31,610
problem here is yes it gives you all the

00:09:28,019 --> 00:09:33,540
information but one of the typical

00:09:31,610 --> 00:09:35,160
calculations that you will want to do

00:09:33,540 --> 00:09:38,310
with this information is to get a ratio

00:09:35,160 --> 00:09:40,769
of the failed requests to all requests

00:09:38,310 --> 00:09:44,040
and to do that now you have to do an

00:09:40,769 --> 00:09:46,200
extra addition on the left on the

00:09:44,040 --> 00:09:49,560
right-hand side of the division here

00:09:46,200 --> 00:09:52,199
basically adding up all the successes

00:09:49,560 --> 00:09:54,829
with all the failures so the ratio

00:09:52,199 --> 00:09:57,810
expression gets quite complicated so

00:09:54,829 --> 00:09:59,820
instead of tracking failures and

00:09:57,810 --> 00:10:02,790
successes track the failures and the

00:09:59,820 --> 00:10:07,410
total number of requests and then your

00:10:02,790 --> 00:10:11,269
ratios just get a bit simpler missing

00:10:07,410 --> 00:10:14,670
series this is a bit of a tricky one so

00:10:11,269 --> 00:10:17,790
imagine you have a metric opps total

00:10:14,670 --> 00:10:20,250
that is a counter counts how many opps

00:10:17,790 --> 00:10:23,399
of a given type have happened so far up

00:10:20,250 --> 00:10:25,949
types might be create update delete this

00:10:23,399 --> 00:10:29,370
kind of thing the parameters client

00:10:25,949 --> 00:10:32,070
libraries have no idea what label values

00:10:29,370 --> 00:10:36,779
can exist for a given label when you're

00:10:32,070 --> 00:10:38,880
creating a metric so as long as no event

00:10:36,779 --> 00:10:40,500
for certain type has happened yet the

00:10:38,880 --> 00:10:43,709
series for that type will simply be

00:10:40,500 --> 00:10:45,630
absent in the metrics output or if no

00:10:43,709 --> 00:10:47,519
type has happened at all so far then

00:10:45,630 --> 00:10:49,920
there will be no series at all for this

00:10:47,519 --> 00:10:52,949
metric yet and this can get a bit

00:10:49,920 --> 00:10:55,440
confusing if you want to have let's say

00:10:52,949 --> 00:10:57,080
a graph over the total rate of

00:10:55,440 --> 00:10:59,240
operations as ever

00:10:57,080 --> 00:11:01,310
over the last five minutes if no

00:10:59,240 --> 00:11:03,200
operation at all has happened yet you

00:11:01,310 --> 00:11:06,110
will get an empty grass instead of a

00:11:03,200 --> 00:11:09,200
flat zero line similar if you are

00:11:06,110 --> 00:11:11,120
selecting for a particular op type in

00:11:09,200 --> 00:11:13,070
this rate and that particular operation

00:11:11,120 --> 00:11:14,720
type hasn't happened yet again you'll

00:11:13,070 --> 00:11:16,970
get an empty graph instead of a zero

00:11:14,720 --> 00:11:18,830
line and this is kind of dangerous

00:11:16,970 --> 00:11:21,170
because it cannot only mess up your

00:11:18,830 --> 00:11:26,120
graphs it can also you know make alerts

00:11:21,170 --> 00:11:29,540
silent and not alert so be aware of this

00:11:26,120 --> 00:11:32,600
if feasible initialize known label

00:11:29,540 --> 00:11:34,940
values to zero this is when you can

00:11:32,600 --> 00:11:36,980
conveniently enumerate all the label

00:11:34,940 --> 00:11:38,750
values in gold would looked something

00:11:36,980 --> 00:11:40,580
like this where you just you know could

00:11:38,750 --> 00:11:45,280
iterate through the ones like create

00:11:40,580 --> 00:11:48,410
delete and so on and then just mention

00:11:45,280 --> 00:11:51,950
the particular label value on that

00:11:48,410 --> 00:11:53,450
dimension for metric and don't include

00:11:51,950 --> 00:11:55,970
the dot Inc at the end to actually

00:11:53,450 --> 00:11:58,160
increment it and in this way

00:11:55,970 --> 00:12:00,980
this dimension gets referenced and

00:11:58,160 --> 00:12:02,930
created but initialized to zero and the

00:12:00,980 --> 00:12:05,060
series will appear but it's still a zero

00:12:02,930 --> 00:12:08,750
counter you don't need to do anything

00:12:05,060 --> 00:12:10,340
for metrics that already don't have any

00:12:08,750 --> 00:12:11,770
labels at all because the Prometheus

00:12:10,340 --> 00:12:16,670
client library can automatically

00:12:11,770 --> 00:12:19,910
initialize them to 0 so sometimes this

00:12:16,670 --> 00:12:22,070
is not feasible because you might have

00:12:19,910 --> 00:12:23,690
something like HTTP status codes and

00:12:22,070 --> 00:12:26,360
while you could go through hundreds of

00:12:23,690 --> 00:12:27,980
status codes you might not want to

00:12:26,360 --> 00:12:31,820
create that many series that will never

00:12:27,980 --> 00:12:33,890
be used and so on so again in this case

00:12:31,820 --> 00:12:36,380
either you have to be aware of the

00:12:33,890 --> 00:12:39,110
problem when looking at a graph that you

00:12:36,380 --> 00:12:42,020
know it might be empty and it should be

00:12:39,110 --> 00:12:44,420
a zero read graph or so or you can use

00:12:42,020 --> 00:12:46,280
the or set operator in different ways

00:12:44,420 --> 00:12:50,360
different combinations depending on your

00:12:46,280 --> 00:12:53,330
exact expression to make you know to

00:12:50,360 --> 00:12:55,190
join in series for a metric name which

00:12:53,330 --> 00:12:57,470
you know will always exist like the

00:12:55,190 --> 00:13:00,800
uptime series for the same job for which

00:12:57,470 --> 00:13:02,810
you are selecting data from there is a

00:13:00,800 --> 00:13:04,490
nice blog post from robust perception

00:13:02,810 --> 00:13:08,990
where you can learn more about

00:13:04,490 --> 00:13:12,710
that's linked on their metric

00:13:08,990 --> 00:13:15,050
normalization try to not put anything

00:13:12,710 --> 00:13:17,570
into label values or into labels and

00:13:15,050 --> 00:13:24,080
generally that's not strictly needed for

00:13:17,570 --> 00:13:26,090
the identification of a given series so

00:13:24,080 --> 00:13:28,190
let's say you are building something

00:13:26,090 --> 00:13:31,400
like a note exporter and you're exposing

00:13:28,190 --> 00:13:34,040
CPU and disk usage and so on don't put

00:13:31,400 --> 00:13:37,120
something like a machine roll label into

00:13:34,040 --> 00:13:40,430
every metric that exporter exposes

00:13:37,120 --> 00:13:43,790
because this break series continuity

00:13:40,430 --> 00:13:45,380
every time the machine rule changes you

00:13:43,790 --> 00:13:47,330
know the label changes and then you have

00:13:45,380 --> 00:13:49,790
a completely new set of time series it's

00:13:47,330 --> 00:13:51,470
kind of unnecessary you might also have

00:13:49,790 --> 00:13:54,200
a lot of this kind of metadata that you

00:13:51,470 --> 00:13:56,810
don't all want to stuff into labels so

00:13:54,200 --> 00:13:58,580
what often a better thing to do is to

00:13:56,810 --> 00:14:01,190
have a completely separate metric in

00:13:58,580 --> 00:14:04,370
that exporter that only contains that

00:14:01,190 --> 00:14:06,260
label and has a sample value of one

00:14:04,370 --> 00:14:12,260
until you can then join that in doing

00:14:06,260 --> 00:14:15,130
the query when you really need it let's

00:14:12,260 --> 00:14:20,540
talk a bit about some lurking conscience

00:14:15,130 --> 00:14:23,060
so starting general again there's the

00:14:20,540 --> 00:14:24,740
famous my philosophy on alerting

00:14:23,060 --> 00:14:27,140
document from what ever shock who has

00:14:24,740 --> 00:14:31,460
heard about that before yeah like half

00:14:27,140 --> 00:14:33,890
the people ok well third maybe google it

00:14:31,460 --> 00:14:36,640
it's some google doc link so I couldn't

00:14:33,890 --> 00:14:38,930
really put it in the slide in useful way

00:14:36,640 --> 00:14:40,430
but it's really great like it really

00:14:38,930 --> 00:14:43,310
outlines a good philosophy on how

00:14:40,430 --> 00:14:45,440
alerting should work the gist of it some

00:14:43,310 --> 00:14:48,350
some points of it are that you should

00:14:45,440 --> 00:14:50,600
really alert on user visible symptoms of

00:14:48,350 --> 00:14:52,910
your service do not try to alert on

00:14:50,600 --> 00:14:55,730
underlying causes there can be too many

00:14:52,910 --> 00:14:58,100
underlying causes and it can be just too

00:14:55,730 --> 00:15:00,170
noisy no some cause might actually

00:14:58,100 --> 00:15:04,190
create an alert but not create a user

00:15:00,170 --> 00:15:06,980
visible problem so you know alert on the

00:15:04,190 --> 00:15:10,340
actual user visible stuff with the

00:15:06,980 --> 00:15:12,230
exception of causes that could cause you

00:15:10,340 --> 00:15:15,170
know a really bad problem very soon now

00:15:12,230 --> 00:15:16,360
like a disk running for in the next four

00:15:15,170 --> 00:15:18,910
hours or so

00:15:16,360 --> 00:15:21,850
generally err on the side of fewer pages

00:15:18,910 --> 00:15:24,220
that generally you know on-call fatigue

00:15:21,850 --> 00:15:26,439
is a real thing so you don't yeah you

00:15:24,220 --> 00:15:28,029
actually react better to pages if you

00:15:26,439 --> 00:15:31,149
get fewer of them and they have

00:15:28,029 --> 00:15:34,239
contained less noise still add a lot of

00:15:31,149 --> 00:15:36,100
causal metrics to your software and

00:15:34,239 --> 00:15:39,040
collected and so on that will then help

00:15:36,100 --> 00:15:40,629
you debug why something is broken once

00:15:39,040 --> 00:15:45,459
you know that it is broken once you have

00:15:40,629 --> 00:15:48,399
received a page right so let's say you

00:15:45,459 --> 00:15:50,559
have service in Prometheus that you're

00:15:48,399 --> 00:15:54,009
monitoring and Attis handling requests

00:15:50,559 --> 00:15:57,670
and you want to alert in case the you

00:15:54,009 --> 00:15:59,559
know the the error rate goes over ten

00:15:57,670 --> 00:16:01,649
per second and you're adding this alert

00:15:59,559 --> 00:16:05,049
and that's amazing and congratulations

00:16:01,649 --> 00:16:07,600
that works most of the time but what

00:16:05,049 --> 00:16:11,470
happens if Prometheus either cannot

00:16:07,600 --> 00:16:13,179
scrape your targets at all for whatever

00:16:11,470 --> 00:16:15,970
reason they might be down there might be

00:16:13,179 --> 00:16:17,559
Network problem or whatever or your

00:16:15,970 --> 00:16:20,230
service discovery or your prometheus

00:16:17,559 --> 00:16:24,579
configuration doesn't even contain those

00:16:20,230 --> 00:16:26,980
targets so basically in both cases this

00:16:24,579 --> 00:16:28,899
metric that the expression here is

00:16:26,980 --> 00:16:30,759
referring to errors total will just

00:16:28,899 --> 00:16:33,730
simply not be present in Prometheus and

00:16:30,759 --> 00:16:38,049
this writing will recreate an empty

00:16:33,730 --> 00:16:40,869
output and you will not get an alert so

00:16:38,049 --> 00:16:43,209
for all jobs in Prometheus it's a good

00:16:40,869 --> 00:16:45,999
practice to have at least two types of

00:16:43,209 --> 00:16:49,110
kind of basic health alerts the first

00:16:45,999 --> 00:16:51,549
one tells you whether the app you series

00:16:49,110 --> 00:16:53,350
whether the weather prometheus knows

00:16:51,549 --> 00:16:56,439
that it should be scraping targets for

00:16:53,350 --> 00:16:58,419
the job you're referencing but cannot so

00:16:56,439 --> 00:17:00,939
every time it does a scrape it records a

00:16:58,419 --> 00:17:04,209
synthetic up metric with a value of 0 or

00:17:00,939 --> 00:17:06,939
1 and you won't want to alert in some

00:17:04,209 --> 00:17:08,949
way or another whether either any

00:17:06,939 --> 00:17:12,339
individual instances down or some

00:17:08,949 --> 00:17:14,470
minimal amount of them are present or

00:17:12,339 --> 00:17:20,169
not or some some variation of this kind

00:17:14,470 --> 00:17:22,539
of alert and the second alert is for the

00:17:20,169 --> 00:17:24,449
case where Prometheus doesn't even know

00:17:22,539 --> 00:17:26,770
that it was supposed to be scraping

00:17:24,449 --> 00:17:28,899
targets for this job like the service

00:17:26,770 --> 00:17:29,539
discovery might not have returned any

00:17:28,899 --> 00:17:32,090
for them

00:17:29,539 --> 00:17:34,940
but you really expect as human this job

00:17:32,090 --> 00:17:37,879
to be there so in that case Prometheus

00:17:34,940 --> 00:17:41,059
will not even create the up metric for

00:17:37,879 --> 00:17:42,889
this job and their instances so you can

00:17:41,059 --> 00:17:46,359
use the absent function to detect that

00:17:42,889 --> 00:17:46,359
and alert on that as well

00:17:48,200 --> 00:17:53,509
Prometheus alerting rules allow you to

00:17:50,179 --> 00:17:56,269
set a four modifier with a time duration

00:17:53,509 --> 00:17:58,249
where you can basically say after what

00:17:56,269 --> 00:18:00,830
time an alert should really start

00:17:58,249 --> 00:18:03,049
notifying you after it starts going bad

00:18:00,830 --> 00:18:06,649
you know like if in instances down in

00:18:03,049 --> 00:18:09,080
this case here if you're just saying you

00:18:06,649 --> 00:18:12,109
know alert me if up equals equals zero

00:18:09,080 --> 00:18:14,210
then after a single failed scrape you

00:18:12,109 --> 00:18:16,970
might already get a notification about a

00:18:14,210 --> 00:18:18,830
down instance and you that's very you

00:18:16,970 --> 00:18:22,159
know typically don't want that you want

00:18:18,830 --> 00:18:25,330
to have some tolerance in there so add

00:18:22,159 --> 00:18:29,059
something like four or five M to this

00:18:25,330 --> 00:18:33,649
similar for the absent kind of alert and

00:18:29,059 --> 00:18:38,330
many other types of alerts in this case

00:18:33,649 --> 00:18:40,129
with a absent alert on the up metric if

00:18:38,330 --> 00:18:42,499
you have a completely fresh Prometheus

00:18:40,129 --> 00:18:44,299
server that doesn't have any data yet or

00:18:42,499 --> 00:18:46,249
it has been down for a long time and you

00:18:44,299 --> 00:18:49,429
restart it it might not have the up

00:18:46,249 --> 00:18:51,769
metric yet but alerting rule might

00:18:49,429 --> 00:18:55,220
already run before the first scrapes and

00:18:51,769 --> 00:18:57,619
also alert you so again you know at four

00:18:55,220 --> 00:19:00,169
five M there and in general the

00:18:57,619 --> 00:19:01,999
recommendation would be even for alerts

00:19:00,169 --> 00:19:04,609
that already includes some time windows

00:19:01,999 --> 00:19:06,440
like rate windows and so on always you

00:19:04,609 --> 00:19:10,460
know make this at least five minutes or

00:19:06,440 --> 00:19:13,539
a couple of many minutes just to be safe

00:19:10,460 --> 00:19:16,519
and to be more failure tolerant there

00:19:13,539 --> 00:19:21,769
but also do not make the for duration

00:19:16,519 --> 00:19:23,779
too long so yeah if you wanted to for

00:19:21,769 --> 00:19:25,909
example you know alert when an instance

00:19:23,779 --> 00:19:27,950
has been down for a whole day the

00:19:25,909 --> 00:19:32,299
problem here is that Prometheus does not

00:19:27,950 --> 00:19:34,489
currently persist the four-state for the

00:19:32,299 --> 00:19:36,619
given time series that result from an

00:19:34,489 --> 00:19:39,080
alert expression so if the Prometheus

00:19:36,619 --> 00:19:40,760
server restarts it will just begin them

00:19:39,080 --> 00:19:44,180
in as begin them as pending

00:19:40,760 --> 00:19:46,700
Alerts new and let's say if your

00:19:44,180 --> 00:19:49,130
Prometheus server restarts at least once

00:19:46,700 --> 00:19:51,920
a day for a crash reason or some

00:19:49,130 --> 00:19:54,950
intended reason then you will never ever

00:19:51,920 --> 00:19:56,480
receive this alert now this might

00:19:54,950 --> 00:19:59,630
actually get fixed in the future there's

00:19:56,480 --> 00:20:02,060
an issue for it but you know try to make

00:19:59,630 --> 00:20:04,600
this at most one hour unless you know

00:20:02,060 --> 00:20:04,600
what you're doing

00:20:05,140 --> 00:20:10,640
so alerts and Prometheus are useful

00:20:08,180 --> 00:20:12,380
because they have labels and because the

00:20:10,640 --> 00:20:14,030
parts on the chain that come after

00:20:12,380 --> 00:20:16,340
Prometheus can do useful stuff with the

00:20:14,030 --> 00:20:19,970
labels a lot manager can route on the

00:20:16,340 --> 00:20:21,980
labels you can silence alerts in there

00:20:19,970 --> 00:20:25,880
for example you might want to silence

00:20:21,980 --> 00:20:27,650
everything by a particular job label and

00:20:25,880 --> 00:20:30,860
also you can use those labels for

00:20:27,650 --> 00:20:33,500
notifications and so on and so on so try

00:20:30,860 --> 00:20:35,600
to preserve as many useful labels as you

00:20:33,500 --> 00:20:38,150
can in both your recording routes but

00:20:35,600 --> 00:20:40,370
also your alerting rules so let's say

00:20:38,150 --> 00:20:45,620
you wanted to alert on some rate being

00:20:40,370 --> 00:20:47,990
high in a sound over the entire job then

00:20:45,620 --> 00:20:50,690
at least try to keep you know that this

00:20:47,990 --> 00:20:55,220
first expression here will drop all the

00:20:50,690 --> 00:20:56,660
all the labels basically and that's okay

00:20:55,220 --> 00:20:58,400
like most of them you actually want to

00:20:56,660 --> 00:21:00,830
just aggregate over but there's many

00:20:58,400 --> 00:21:03,050
labels or several labels potentially in

00:21:00,830 --> 00:21:04,730
there that are common among all the

00:21:03,050 --> 00:21:07,280
series that are being summed over and

00:21:04,730 --> 00:21:09,050
you'll probably want to at least keep

00:21:07,280 --> 00:21:12,110
those and the one you typically at least

00:21:09,050 --> 00:21:13,760
one to keep is the job label because

00:21:12,110 --> 00:21:16,490
that's very useful for silencing

00:21:13,760 --> 00:21:18,380
individual jobs and so on so you know

00:21:16,490 --> 00:21:24,040
just think of it about what labels you

00:21:18,380 --> 00:21:27,350
preserve at that stage on the query side

00:21:24,040 --> 00:21:30,020
keep in mind that the single metric name

00:21:27,350 --> 00:21:33,710
only has you know a single unique

00:21:30,020 --> 00:21:36,890
meaning within one binary and a job kind

00:21:33,710 --> 00:21:39,050
of groups instances of the same binary

00:21:36,890 --> 00:21:43,280
and configuration together kind of like

00:21:39,050 --> 00:21:44,930
a service so just to be sure if you like

00:21:43,280 --> 00:21:47,510
at least you should be a bit extra

00:21:44,930 --> 00:21:51,050
paranoid always try to add a job

00:21:47,510 --> 00:21:52,500
selector to your individual time series

00:21:51,050 --> 00:21:55,470
selectors

00:21:52,500 --> 00:21:57,030
that really namespaces that metric to

00:21:55,470 --> 00:22:01,140
the binary comes from to the job it

00:21:57,030 --> 00:22:02,669
comes from yeah otherwise you might get

00:22:01,140 --> 00:22:09,360
surprises and sales select something

00:22:02,669 --> 00:22:12,210
that you don't actually intend to yeah

00:22:09,360 --> 00:22:15,630
sometimes people get the order of rate

00:22:12,210 --> 00:22:17,370
and some the wrong way around that's

00:22:15,630 --> 00:22:20,340
actually not that easy in Prometheus so

00:22:17,370 --> 00:22:22,380
the question is let's say you know you

00:22:20,340 --> 00:22:25,140
have a bunch of counters being exported

00:22:22,380 --> 00:22:26,700
by later let's say one culture by a

00:22:25,140 --> 00:22:28,679
hundred instances and now you want to

00:22:26,700 --> 00:22:30,780
have the total rate over all those

00:22:28,679 --> 00:22:32,940
hundred hundred instances you might

00:22:30,780 --> 00:22:35,400
think well I might just sum up over all

00:22:32,940 --> 00:22:37,950
the counters and then take the the rate

00:22:35,400 --> 00:22:39,960
of increase of the Sun why is this a

00:22:37,950 --> 00:22:42,360
problem the problem is that counters can

00:22:39,960 --> 00:22:45,419
reset in Prometheus and the rate

00:22:42,360 --> 00:22:47,789
function expects to see those resets and

00:22:45,419 --> 00:22:50,070
so that it can correct for them so if

00:22:47,789 --> 00:22:53,820
you have a row counter that kind of goes

00:22:50,070 --> 00:22:55,830
up and then resets and goes up again you

00:22:53,820 --> 00:22:57,299
see the dark blue line is what the rate

00:22:55,830 --> 00:22:59,370
will actually be working with it

00:22:57,299 --> 00:23:02,700
pretends as if that like it will just

00:22:59,370 --> 00:23:05,960
treat any decrease in value as a reset

00:23:02,700 --> 00:23:11,039
and pretends as if it had never happened

00:23:05,960 --> 00:23:13,140
so generally yeah if you have one very

00:23:11,039 --> 00:23:17,549
slow moving counter that resets and one

00:23:13,140 --> 00:23:21,750
that increases very rapidly then let's

00:23:17,549 --> 00:23:23,880
see what happens if you some first you

00:23:21,750 --> 00:23:25,620
actually get a counter that where you

00:23:23,880 --> 00:23:28,080
can't even see that reset happen there's

00:23:25,620 --> 00:23:29,850
just a plateau here so this is an

00:23:28,080 --> 00:23:32,460
extreme example but this also works in

00:23:29,850 --> 00:23:35,039
other examples that summing before

00:23:32,460 --> 00:23:37,169
taking the rate actually can mask the

00:23:35,039 --> 00:23:39,929
resets that can help them in individual

00:23:37,169 --> 00:23:44,789
counters at different times so then rate

00:23:39,929 --> 00:23:47,610
will under report the rate so always

00:23:44,789 --> 00:23:49,799
take the sum of the rates and not the

00:23:47,610 --> 00:23:51,570
rate of the sums from Q I'll actually

00:23:49,799 --> 00:23:54,860
makes it somewhat hard to do the wrong

00:23:51,570 --> 00:23:57,570
thing because you cannot take the rate

00:23:54,860 --> 00:24:00,480
of an arbitrary expression you can only

00:23:57,570 --> 00:24:02,429
take the rate of something that has

00:24:00,480 --> 00:24:04,770
already been really recorded on disk as

00:24:02,429 --> 00:24:07,660
a time series

00:24:04,770 --> 00:24:10,390
but still if you first pre-record the

00:24:07,660 --> 00:24:11,920
sum in a recording rule and then do the

00:24:10,390 --> 00:24:13,930
rate on the recording recording role

00:24:11,920 --> 00:24:15,970
result you might still stumble into this

00:24:13,930 --> 00:24:19,030
problem and people do so that's what I'm

00:24:15,970 --> 00:24:21,870
talking about it yeah thanks that's

00:24:19,030 --> 00:24:21,870
already been it

00:24:32,090 --> 00:24:43,770
questions its hi you mentioned that

00:24:40,520 --> 00:24:45,660
sometimes developers can you know

00:24:43,770 --> 00:24:47,250
accidentally create like tens of

00:24:45,660 --> 00:24:49,320
thousands hundred thousands time series

00:24:47,250 --> 00:24:51,030
if these like IDs and stuff like that

00:24:49,320 --> 00:24:53,070
and I've actually personally seen that

00:24:51,030 --> 00:24:54,330
you know of other developers of other

00:24:53,070 --> 00:24:56,220
teams you know they learn to use a

00:24:54,330 --> 00:24:58,200
client they don't know how many times

00:24:56,220 --> 00:24:59,790
you're just gonna generate so and then

00:24:58,200 --> 00:25:02,160
things just sort of sort of go out of

00:24:59,790 --> 00:25:03,690
control yeah it's kind of hard to scale

00:25:02,160 --> 00:25:05,250
that you know on a human level because I

00:25:03,690 --> 00:25:07,710
can't be part of every code review or

00:25:05,250 --> 00:25:09,420
like you know I can't necessarily tell

00:25:07,710 --> 00:25:11,370
this is gonna happen is there any sort

00:25:09,420 --> 00:25:13,140
of future work plan on sort of combating

00:25:11,370 --> 00:25:15,360
this problem where like a developer

00:25:13,140 --> 00:25:16,830
accidentally just so crazy too many time

00:25:15,360 --> 00:25:21,120
series because it doesn't understand

00:25:16,830 --> 00:25:22,860
that you know yeah Natalie issue so I

00:25:21,120 --> 00:25:24,630
think the three answers may be that I

00:25:22,860 --> 00:25:28,050
can give and maybe Brian can fill in the

00:25:24,630 --> 00:25:29,250
rest first of all you'll want to have I

00:25:28,050 --> 00:25:31,050
mean generally it's nice to have

00:25:29,250 --> 00:25:32,550
permeated servers per team so the teams

00:25:31,050 --> 00:25:34,320
are actually responsible for what they

00:25:32,550 --> 00:25:36,780
break and then they actually tend to

00:25:34,320 --> 00:25:39,210
learn faster than if you run a central

00:25:36,780 --> 00:25:40,500
premier server for them that's at least

00:25:39,210 --> 00:25:42,510
the experience I had really like

00:25:40,500 --> 00:25:45,000
everyone broke it once but then they

00:25:42,510 --> 00:25:46,670
learned really quickly the other thing

00:25:45,000 --> 00:25:49,140
is there are two major change mitigation

00:25:46,670 --> 00:25:52,530
strategies you can do on the prometheus

00:25:49,140 --> 00:25:54,990
server level which one is a limit per

00:25:52,530 --> 00:25:58,020
scrape where you can just have a safety

00:25:54,990 --> 00:26:00,770
limit that allows you to say any scrape

00:25:58,020 --> 00:26:03,750
may only produce at most as many metrics

00:26:00,770 --> 00:26:07,140
and then there's another metric we label

00:26:03,750 --> 00:26:09,660
conflicts that allows you to well you

00:26:07,140 --> 00:26:11,040
know it's like relabeling but on during

00:26:09,660 --> 00:26:14,400
scrape that allows you to throw away

00:26:11,040 --> 00:26:15,900
certain metrics yeah that helps to a

00:26:14,400 --> 00:26:17,850
limited degree I don't know Ryan if you

00:26:15,900 --> 00:26:20,100
want to add some yeah those are the

00:26:17,850 --> 00:26:22,620
answers which is yes they learn when

00:26:20,100 --> 00:26:24,510
they have their own using scrape finish

00:26:22,620 --> 00:26:26,640
like set up way beyond what you need

00:26:24,510 --> 00:26:28,980
it's just meant to be an emergency stop

00:26:26,640 --> 00:26:30,450
valve basically that it's better to stop

00:26:28,980 --> 00:26:33,180
Chris tripping that job and take out the

00:26:30,450 --> 00:26:35,340
radius and then as a mitigation while

00:26:33,180 --> 00:26:38,040
the developers are learning not to do

00:26:35,340 --> 00:26:40,880
this you can drop it on the fly using

00:26:38,040 --> 00:26:40,880
metric label things

00:26:41,450 --> 00:26:45,090
actually think what we have not thought

00:26:43,559 --> 00:26:47,430
of for some reason is because just

00:26:45,090 --> 00:26:49,950
instrument how many values therefore

00:26:47,430 --> 00:26:51,660
suddenly understand about on it at least

00:26:49,950 --> 00:26:54,930
like if you a reasonable hint why yeah

00:26:51,660 --> 00:26:57,150
reasons degrading you you can if you're

00:26:54,930 --> 00:26:58,950
Prometheus isn't so overloaded yet that

00:26:57,150 --> 00:27:00,540
you can still query which metric is

00:26:58,950 --> 00:27:02,850
large then you can actually query that

00:27:00,540 --> 00:27:06,150
already read with underscore knows your

00:27:02,850 --> 00:27:08,880
name and then metric all metric metric

00:27:06,150 --> 00:27:12,390
promise export itself right out like how

00:27:08,880 --> 00:27:14,460
many pal yeah okay okay that sounds like

00:27:12,390 --> 00:27:17,690
a metric wish not unbounded cardinality

00:27:14,460 --> 00:27:20,940
missing about any unreal able makes huh

00:27:17,690 --> 00:27:22,740
yep but one thing I would like and it

00:27:20,940 --> 00:27:25,110
should be easier now with new storage is

00:27:22,740 --> 00:27:26,520
a page of the radius telling you which

00:27:25,110 --> 00:27:28,110
the big symmetric sandwich our biggest

00:27:26,520 --> 00:27:30,000
table names just trick debugging that's

00:27:28,110 --> 00:27:32,460
what I'm saying because you'll normally

00:27:30,000 --> 00:27:34,740
find any given previous that at least

00:27:32,460 --> 00:27:37,890
half the resources are taken up by like

00:27:34,740 --> 00:27:40,290
10 metrics and that's pretty normal like

00:27:37,890 --> 00:27:43,590
I've seen and previous similar

00:27:40,290 --> 00:27:45,150
monitoring systems where 80% of all

00:27:43,590 --> 00:27:47,280
monitoring resources are we taking up by

00:27:45,150 --> 00:27:51,600
a single histogram and this is not

00:27:47,280 --> 00:27:53,280
unusual yeah histograms are very

00:27:51,600 --> 00:27:56,850
resource intensive if you have a lot of

00:27:53,280 --> 00:28:06,990
buckets more questions

00:27:56,850 --> 00:28:09,690
oh come on this one okay this is

00:28:06,990 --> 00:28:11,970
something I've tried to do it's what you

00:28:09,690 --> 00:28:14,280
were saying about maintaining labels in

00:28:11,970 --> 00:28:17,220
your alerts so when you're alerting on

00:28:14,280 --> 00:28:20,460
absent absolute kinds of like to throw

00:28:17,220 --> 00:28:22,620
away labels it doesn't have them to

00:28:20,460 --> 00:28:25,620
begin with right yeah but you can add

00:28:22,620 --> 00:28:27,390
them you can do absent on a metric and

00:28:25,620 --> 00:28:30,090
then put some labels in there yeah yeah

00:28:27,390 --> 00:28:33,300
but if you use a rag axe in there then

00:28:30,090 --> 00:28:37,230
that is yeah yeah if there's some

00:28:33,300 --> 00:28:39,420
solution for that no there isn't sadly

00:28:37,230 --> 00:28:41,280
because it's it since it doesn't have

00:28:39,420 --> 00:28:43,320
underlying time series to work with

00:28:41,280 --> 00:28:46,530
since they're absent it can only work

00:28:43,320 --> 00:28:48,660
with whatever you select by and it

00:28:46,530 --> 00:28:50,600
cannot produce a label an actual label

00:28:48,660 --> 00:28:53,299
value from a regular expression

00:28:50,600 --> 00:28:55,070
episode actually only adds labour values

00:28:53,299 --> 00:29:00,830
for the ones that have equal selectors

00:28:55,070 --> 00:29:03,410
in the absent it doesn't yeah I cannot

00:29:00,830 --> 00:29:05,330
see it has been there previously and

00:29:03,410 --> 00:29:07,669
yeah exactly it has no way of knowing

00:29:05,330 --> 00:29:08,270
what otherwise should be there that

00:29:07,669 --> 00:29:13,820
isn't there

00:29:08,270 --> 00:29:17,240
yeah sadly is there any difference

00:29:13,820 --> 00:29:19,970
between one my trick with a lot of

00:29:17,240 --> 00:29:25,220
labels and a lot of matrix with one

00:29:19,970 --> 00:29:26,630
label each yeah so one thing the

00:29:25,220 --> 00:29:27,440
queering bit that I mentioned earlier

00:29:26,630 --> 00:29:29,360
right

00:29:27,440 --> 00:29:31,909
you still typically want to at least be

00:29:29,360 --> 00:29:34,580
able to query a single metric name

00:29:31,909 --> 00:29:37,370
without any further filters at least in

00:29:34,580 --> 00:29:40,429
the tabular view to be able to even

00:29:37,370 --> 00:29:41,299
start formulating a query and narrowing

00:29:40,429 --> 00:29:44,030
down and so on

00:29:41,299 --> 00:29:46,250
so I would recommend keeping a single

00:29:44,030 --> 00:29:49,270
metric name across all instances you

00:29:46,250 --> 00:29:52,100
know multiply together to a couple of

00:29:49,270 --> 00:29:53,630
maybe ten thousands of metrics but

00:29:52,100 --> 00:30:01,270
that's already on the high level keep it

00:29:53,630 --> 00:30:03,679
lower normally yeah alright so I have a

00:30:01,270 --> 00:30:07,940
question about so I'm working on

00:30:03,679 --> 00:30:11,720
something that I'm dizzy that creates a

00:30:07,940 --> 00:30:13,190
lot of Easter ones for matrix that I

00:30:11,720 --> 00:30:14,690
don't know and I don't know what the

00:30:13,190 --> 00:30:16,880
values would be I don't know if you've

00:30:14,690 --> 00:30:18,950
answered that already but I'm kind of

00:30:16,880 --> 00:30:21,860
stuck with how to choose the buckets

00:30:18,950 --> 00:30:25,460
appropriately and other guys the one

00:30:21,860 --> 00:30:27,950
default the default one but it's not

00:30:25,460 --> 00:30:31,940
great and is there any best practices or

00:30:27,950 --> 00:30:35,510
methods to kind of dynamically change or

00:30:31,940 --> 00:30:37,970
choose the caps of a lot of instruments

00:30:35,510 --> 00:30:39,980
yeah so dynamic choosing isn't possible

00:30:37,970 --> 00:30:41,929
at least yet and we don't know yet if

00:30:39,980 --> 00:30:42,169
mathematically somehow it can be worked

00:30:41,929 --> 00:30:45,350
out

00:30:42,169 --> 00:30:50,690
John was reading another paper but yes

00:30:45,350 --> 00:30:52,220
it's it's a tricky a bit because don't

00:30:50,690 --> 00:30:54,140
use the default buckets because they are

00:30:52,220 --> 00:30:56,000
very generic and you typically want to

00:30:54,140 --> 00:30:57,860
use something that really fits the

00:30:56,000 --> 00:30:59,090
latency profile of your service but then

00:30:57,860 --> 00:31:01,490
you have to kind of know it in advance

00:30:59,090 --> 00:31:03,300
or manually change it once in a while

00:31:01,490 --> 00:31:05,820
iterate towards something

00:31:03,300 --> 00:31:07,590
useful that's really the best that sadly

00:31:05,820 --> 00:31:09,630
there is at the moment

00:31:07,590 --> 00:31:11,610
sometimes you already know that you only

00:31:09,630 --> 00:31:13,620
care about certain latency boundaries

00:31:11,610 --> 00:31:15,060
like if you have an SLA of this many

00:31:13,620 --> 00:31:18,360
requests have to be under 300

00:31:15,060 --> 00:31:19,890
milliseconds then you can have boundary

00:31:18,360 --> 00:31:22,680
exactly there and then you need like one

00:31:19,890 --> 00:31:24,210
or two buckets but if you really

00:31:22,680 --> 00:31:26,340
generally want to know what is my

00:31:24,210 --> 00:31:28,350
latency distribution from the beginning

00:31:26,340 --> 00:31:31,980
on then you kind of have to iterate

00:31:28,350 --> 00:31:35,100
towards that I don't know if that's

00:31:31,980 --> 00:31:36,750
basically in fact yeah fundamentally if

00:31:35,100 --> 00:31:38,610
you want to see your actual histogram

00:31:36,750 --> 00:31:40,830
you need event logging so you can get

00:31:38,610 --> 00:31:42,300
your actual histogram and so once you

00:31:40,830 --> 00:31:43,710
know that you can figure out the buckets

00:31:42,300 --> 00:31:45,840
and the Depot buckets are meant to do

00:31:43,710 --> 00:31:48,000
something reasonable ish for Tings

00:31:45,840 --> 00:31:50,700
between like a millisecond and 10

00:31:48,000 --> 00:31:56,580
seconds which covers most web services

00:31:50,700 --> 00:31:59,570
but it's just a default sorry and nobody

00:31:56,580 --> 00:32:02,880
has done any integration on third-party

00:31:59,570 --> 00:32:09,630
library to dynamically update historical

00:32:02,880 --> 00:32:11,610
events also the top choosing the right

00:32:09,630 --> 00:32:13,620
bucket size civility depends on how your

00:32:11,610 --> 00:32:17,330
data is distributed so if you have a

00:32:13,620 --> 00:32:20,250
normal distribution rules how you could

00:32:17,330 --> 00:32:22,290
dimension the bins of yester gram so you

00:32:20,250 --> 00:32:24,030
have to look into the data if it follows

00:32:22,290 --> 00:32:25,980
certain statistical properties there are

00:32:24,030 --> 00:32:27,780
rules how to dimension it but it's

00:32:25,980 --> 00:32:30,300
nothing that can be done automatically I

00:32:27,780 --> 00:32:32,280
guess there's always some kind of

00:32:30,300 --> 00:32:36,840
interpretation how the data is

00:32:32,280 --> 00:32:38,850
distributed so the fundamental reason

00:32:36,840 --> 00:32:41,580
why the buckets are static now to be

00:32:38,850 --> 00:32:43,740
pre-configured is that our computational

00:32:41,580 --> 00:32:45,330
model is that we want to be able to

00:32:43,740 --> 00:32:47,220
aggregation which requires the focus to

00:32:45,330 --> 00:32:49,170
be the same and we want to be able to

00:32:47,220 --> 00:32:51,540
aggregate over any arbitrary time period

00:32:49,170 --> 00:32:53,760
and nothing like at each I just or

00:32:51,540 --> 00:32:55,020
whatnot works under dose constraints so

00:32:53,760 --> 00:32:56,490
there are other systems out there which

00:32:55,020 --> 00:32:58,350
have taken different approaches and can

00:32:56,490 --> 00:32:59,760
do dynamically reasonably well because

00:32:58,350 --> 00:33:02,130
they're decided right you were going to

00:32:59,760 --> 00:33:04,380
have minute egg regressions but we want

00:33:02,130 --> 00:33:06,990
any aggregation with any start time over

00:33:04,380 --> 00:33:08,610
any duration so we end up that it seems

00:33:06,990 --> 00:33:10,290
unlikely there is a mathematical

00:33:08,610 --> 00:33:12,160
solution that will work under our

00:33:10,290 --> 00:33:14,530
constraints but there are others

00:33:12,160 --> 00:33:16,870
which might work for you so there is the

00:33:14,530 --> 00:33:22,570
quantity quantile always into summaries

00:33:16,870 --> 00:33:25,810
which have different trade-offs again is

00:33:22,570 --> 00:33:28,060
there a way to monitor an alert when you

00:33:25,810 --> 00:33:32,230
are having a cardan err cardinality

00:33:28,060 --> 00:33:33,970
explosion yeah so if you have any

00:33:32,230 --> 00:33:37,650
cardinality explosion your Prometheus

00:33:33,970 --> 00:33:40,390
server is probably already dead so you

00:33:37,650 --> 00:33:43,390
like a serious run right where you put

00:33:40,390 --> 00:33:45,070
yeah so what you want to do is have meta

00:33:43,390 --> 00:33:46,630
monitoring basically another Prometheus

00:33:45,070 --> 00:33:48,340
server or a set of other primitive

00:33:46,630 --> 00:33:51,520
servers that does nothing else than

00:33:48,340 --> 00:33:54,610
monitor primitive servers and that will

00:33:51,520 --> 00:33:56,590
send you an alert if they are basically

00:33:54,610 --> 00:33:58,630
you know they might become unreachable

00:33:56,590 --> 00:34:00,870
but there's also metrics that the

00:33:58,630 --> 00:34:03,820
primitive server itself will output

00:34:00,870 --> 00:34:06,760
about number of ingested samples active

00:34:03,820 --> 00:34:08,679
series and so on and you'll have want to

00:34:06,760 --> 00:34:14,380
have some meta monitoring rules on that

00:34:08,679 --> 00:34:17,020
yeah hello is it possible to use

00:34:14,380 --> 00:34:19,720
different expressions for start and stop

00:34:17,020 --> 00:34:27,130
firing alerts and what is the best

00:34:19,720 --> 00:34:29,260
practice to use them not really yeah no

00:34:27,130 --> 00:34:32,410
so you're asking something about like a

00:34:29,260 --> 00:34:34,750
hysteresis maybe no not really

00:34:32,410 --> 00:34:38,100
basically you're formulating an alerting

00:34:34,750 --> 00:34:40,360
rule that is either active or does not

00:34:38,100 --> 00:34:42,460
theoretically you could maybe build a

00:34:40,360 --> 00:34:46,570
contraption with recording rules and

00:34:42,460 --> 00:34:49,960
depend on some prior state but then the

00:34:46,570 --> 00:34:51,790
question really want it maybe again Ryan

00:34:49,960 --> 00:34:54,070
is are kind of our best practices master

00:34:51,790 --> 00:34:57,010
here maybe he has an opinion on this

00:34:54,070 --> 00:34:59,800
there's Mike behind you but I think then

00:34:57,010 --> 00:35:01,270
it gets a bit easier so the thing was

00:34:59,800 --> 00:35:03,880
alerts is you want to keep them simple

00:35:01,270 --> 00:35:06,430
it's like yes I could write an alert to

00:35:03,880 --> 00:35:09,130
do that but it will be on maintained by

00:35:06,430 --> 00:35:10,570
anyone else and you want generally what

00:35:09,130 --> 00:35:13,000
you're in urging to keep it simple tresh

00:35:10,570 --> 00:35:14,560
holds we also often get a question of

00:35:13,000 --> 00:35:17,770
hey can Prometheus automatically detect

00:35:14,560 --> 00:35:19,660
problems and the answer is well if you

00:35:17,770 --> 00:35:22,090
want to go create strong AI and destroy

00:35:19,660 --> 00:35:23,840
a soul off you go because that's it

00:35:22,090 --> 00:35:25,910
requires intelligence to understand how

00:35:23,840 --> 00:35:27,440
systems work just simple thresholds you

00:35:25,910 --> 00:35:29,000
can create them yes you'll need to tweak

00:35:27,440 --> 00:35:31,220
them every three months when the system

00:35:29,000 --> 00:35:32,930
changes but it over always far less

00:35:31,220 --> 00:35:34,580
effort that actually tried to get

00:35:32,930 --> 00:35:36,230
machine learning or anything working but

00:35:34,580 --> 00:35:38,720
it's working just choose the threshold

00:35:36,230 --> 00:35:40,820
that is bad at that session so but if

00:35:38,720 --> 00:35:42,500
you if you do need and of hysteresis for

00:35:40,820 --> 00:35:44,380
a very special use case you could do

00:35:42,500 --> 00:35:47,690
that over recording rules and then

00:35:44,380 --> 00:35:49,550
referencing the recorded result of you

00:35:47,690 --> 00:35:52,490
know previously at some our previous

00:35:49,550 --> 00:35:54,200
states in your loading rule but yeah

00:35:52,490 --> 00:36:00,140
it's kind of I've never tried it

00:35:54,200 --> 00:36:02,030
actually yeah yeah alerts actually when

00:36:00,140 --> 00:36:06,200
they are pending or firing they will

00:36:02,030 --> 00:36:09,500
actually create time series themselves

00:36:06,200 --> 00:36:12,140
upper case alerts metric name with a lot

00:36:09,500 --> 00:36:14,090
name and the alert state and so on so

00:36:12,140 --> 00:36:18,110
you could even reference previous states

00:36:14,090 --> 00:36:19,850
of that alert mmm just a real simple

00:36:18,110 --> 00:36:21,440
question you mentioned at the start that

00:36:19,850 --> 00:36:23,510
you had to skip some slides about

00:36:21,440 --> 00:36:25,430
architecture and topology yep is zero

00:36:23,510 --> 00:36:28,210
I'm really interested can i I mean is

00:36:25,430 --> 00:36:30,920
there a way for me to find them oh no I

00:36:28,210 --> 00:36:32,660
well I didn't read it

00:36:30,920 --> 00:36:35,750
yeah sorry they weren't even fully done

00:36:32,660 --> 00:36:38,780
because I already noticed then like okay

00:36:35,750 --> 00:36:41,690
I will had not have time for this so but

00:36:38,780 --> 00:36:43,880
I would have talked about basically

00:36:41,690 --> 00:36:45,740
abuse of the push gateway there's a doc

00:36:43,880 --> 00:36:48,200
on that on the best practices on their

00:36:45,740 --> 00:36:51,350
Prometheus website when to use when to

00:36:48,200 --> 00:36:53,870
push some other things what were there

00:36:51,350 --> 00:36:55,790
other things Federation don't federate

00:36:53,870 --> 00:37:00,170
all metrics from one Prometheus server

00:36:55,790 --> 00:37:02,450
to another only a small subset yeah I

00:37:00,170 --> 00:37:06,350
generally tend to avoid super exporters

00:37:02,450 --> 00:37:08,420
these kind of big things where the the

00:37:06,350 --> 00:37:10,100
pool model with the up metric and

00:37:08,420 --> 00:37:12,200
metadata association then breaks down

00:37:10,100 --> 00:37:13,520
because you have metrics from all kinds

00:37:12,200 --> 00:37:16,730
of things in there and it also becomes a

00:37:13,520 --> 00:37:18,050
single point of failure and yeah I might

00:37:16,730 --> 00:37:20,240
have had one or two other points there

00:37:18,050 --> 00:37:22,690
but that's kind of what I would have

00:37:20,240 --> 00:37:22,690
mentioned

00:37:23,990 --> 00:37:34,460
I know I have a question about these

00:37:29,390 --> 00:37:38,030
exploding metrics things if I have to

00:37:34,460 --> 00:37:41,119
tomato service and they are both getting

00:37:38,030 --> 00:37:43,880
these increasing numbers of metrics and

00:37:41,119 --> 00:37:48,230
and they probably explode at the same

00:37:43,880 --> 00:37:50,810
time maybe yes it could be a good idea

00:37:48,230 --> 00:37:54,440
to have a grace period to be

00:37:50,810 --> 00:38:00,920
configurable that new metrics only get

00:37:54,440 --> 00:38:03,589
into or create new time series after a

00:38:00,920 --> 00:38:08,119
given period of time so I can configure

00:38:03,589 --> 00:38:11,119
one of these two redundant servers to

00:38:08,119 --> 00:38:14,630
just wait an hour before it creates

00:38:11,119 --> 00:38:16,369
networks that appear afresh also you

00:38:14,630 --> 00:38:19,280
want us to like buffer up all the

00:38:16,369 --> 00:38:25,220
samples for an hour no just just all

00:38:19,280 --> 00:38:27,140
them away for an hour oh yeah that does

00:38:25,220 --> 00:38:29,960
tend to break everything that all the

00:38:27,140 --> 00:38:32,390
assumptions in Prometheus if you just

00:38:29,960 --> 00:38:34,599
throw away something that looks new

00:38:32,390 --> 00:38:37,330
because Prometheus really depends on

00:38:34,599 --> 00:38:40,040
things that can just you know things

00:38:37,330 --> 00:38:42,530
dynamically appearing at any times new

00:38:40,040 --> 00:38:44,540
labels new time series new metrics and

00:38:42,530 --> 00:38:46,750
so on I think that would break too many

00:38:44,540 --> 00:38:49,400
assumptions of the entire model yeah

00:38:46,750 --> 00:38:51,560
yeah that's all it was a bad idea I

00:38:49,400 --> 00:38:58,430
guess you have meta monitoring for this

00:38:51,560 --> 00:39:01,910
yeah in if you look at Prometheus's own

00:38:58,430 --> 00:39:03,619
metrics sometimes it will have the name

00:39:01,910 --> 00:39:05,510
space Prometheus at the start of the

00:39:03,619 --> 00:39:07,670
metric name yeah when should you include

00:39:05,510 --> 00:39:09,589
the name of the application in the

00:39:07,670 --> 00:39:11,660
metric name itself when she once you do

00:39:09,589 --> 00:39:14,900
not do that I don't believe there's

00:39:11,660 --> 00:39:17,800
consensus on this I like I like the idea

00:39:14,900 --> 00:39:22,070
of including it in there simply for

00:39:17,800 --> 00:39:25,550
autocomplete in your metrics input box

00:39:22,070 --> 00:39:27,650
and also just to very quickly see what

00:39:25,550 --> 00:39:30,140
something is coming from but if a metric

00:39:27,650 --> 00:39:32,330
is really a generic metric like the

00:39:30,140 --> 00:39:33,200
number of HTTP requests received or so

00:39:32,330 --> 00:39:34,700
right you

00:39:33,200 --> 00:39:37,760
might want to keep that completely

00:39:34,700 --> 00:39:39,829
without an application-level prefix if

00:39:37,760 --> 00:39:42,430
you want to use it across jobs and it

00:39:39,829 --> 00:39:44,690
really has the same meaning across jobs

00:39:42,430 --> 00:39:46,099
so the important thing is that is not an

00:39:44,690 --> 00:39:48,859
application name prefix there's a

00:39:46,099 --> 00:39:51,339
library name prefix library just happens

00:39:48,859 --> 00:39:56,740
to be called Prometheus in this case

00:39:51,339 --> 00:39:59,630
yeah if you were to you reuse components

00:39:56,740 --> 00:40:02,089
go packages of Prometheus and you pass

00:39:59,630 --> 00:40:04,700
in a matrix register you would then also

00:40:02,089 --> 00:40:05,990
get that Prometheus prefix in there okay

00:40:04,700 --> 00:40:07,849
so but I mean if you have the alert

00:40:05,990 --> 00:40:10,880
monitor metrics and it has the alert

00:40:07,849 --> 00:40:16,700
manager it has a web manager it is the

00:40:10,880 --> 00:40:19,070
name like the metric name is meant to

00:40:16,700 --> 00:40:20,990
tell you what the values values of the

00:40:19,070 --> 00:40:22,730
series semantically mean and for some

00:40:20,990 --> 00:40:23,780
things just doesn't just make sense to

00:40:22,730 --> 00:40:25,640
have a prefix in there to actually

00:40:23,780 --> 00:40:28,339
assign some meaning right biometric on

00:40:25,640 --> 00:40:30,140
samples appended total like what samples

00:40:28,339 --> 00:40:32,270
promised you sent us right it's part of

00:40:30,140 --> 00:40:34,490
the semantics idea of what that is okay

00:40:32,270 --> 00:40:35,990
I mean some you might be arguing well

00:40:34,490 --> 00:40:39,349
you know you know that from the job

00:40:35,990 --> 00:40:42,290
label yeah okay we are out of time but I

00:40:39,349 --> 00:40:44,060
agree so you're more than welcome to

00:40:42,290 --> 00:40:46,099
continue this discussion over there else

00:40:44,060 --> 00:40:48,589
there's toilets there's toilets we have

00:40:46,099 --> 00:40:53,079
a 15-minute break there's drink up down

00:40:48,589 --> 00:40:53,079
here and upstairs and see you soon

00:40:56,350 --> 00:41:09,160
[Music]

00:41:08,980 --> 00:41:11,699
you

00:41:09,160 --> 00:41:11,699

YouTube URL: https://www.youtube.com/watch?v=_MNYuTNfTb4


