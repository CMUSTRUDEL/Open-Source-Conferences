Title: PromCon 2018: RPC Metrics at Google
Publication date: 2018-11-10
Playlist: PromCon 2018
Description: 
	Speaker: Jaana B. Dogan

Collecting and alerting on RPC metrics is a fundamental part of Google's reliability story. In this talk, we will go through what we have learned in the last two decades and why we are trying to flex our instrumentation stack to cooperate with Prometheus.
Captions: 
	00:00:10,530 --> 00:00:14,550
yeah it's super bad news for me because

00:00:12,450 --> 00:00:17,670
I missed a party last night and I'm so

00:00:14,550 --> 00:00:19,529
jealous but you know don't be judgmental

00:00:17,670 --> 00:00:22,430
if I mess up things I really prepared

00:00:19,529 --> 00:00:25,560
this talk last night I'm JB D as a

00:00:22,430 --> 00:00:27,150
Julius mentioned I work at Google main

00:00:25,560 --> 00:00:29,100
on the instrumentation side of the thing

00:00:27,150 --> 00:00:32,160
so I don't understand everything end to

00:00:29,100 --> 00:00:35,010
end but I understand my stuff

00:00:32,160 --> 00:00:37,440
if you have questions I may need to you

00:00:35,010 --> 00:00:39,210
know reroute you to the right people if

00:00:37,440 --> 00:00:42,600
I don't know anything about it so

00:00:39,210 --> 00:00:45,149
today's talk is about RPC metrics and to

00:00:42,600 --> 00:00:47,520
be honest RPC is just basic G RPC at

00:00:45,149 --> 00:00:50,250
Google now pretty much so it's going to

00:00:47,520 --> 00:00:52,020
be more about G RPC metrics well if you

00:00:50,250 --> 00:00:54,780
don't like JR pieces that's fine because

00:00:52,020 --> 00:00:58,140
you know these concepts work regardless

00:00:54,780 --> 00:01:00,960
of the protocol so you can see it as a

00:00:58,140 --> 00:01:03,239
talk on request metrics so why do we

00:01:00,960 --> 00:01:04,589
care about metrics is the first question

00:01:03,239 --> 00:01:07,080
I think because we care about

00:01:04,589 --> 00:01:09,539
availability and you know we as an

00:01:07,080 --> 00:01:11,220
industry like to trivialize and you know

00:01:09,539 --> 00:01:14,640
use simple descriptions of what

00:01:11,220 --> 00:01:18,630
availability is this is our VP of asari

00:01:14,640 --> 00:01:21,060
on reliability a hundred percent is the

00:01:18,630 --> 00:01:23,310
wrong reliable to target basically for

00:01:21,060 --> 00:01:25,830
anything just because you know a hundred

00:01:23,310 --> 00:01:28,380
percent just doesn't exist it's so

00:01:25,830 --> 00:01:31,200
complex and expensive to hu hundred

00:01:28,380 --> 00:01:33,840
percent that it's not practical to set

00:01:31,200 --> 00:01:38,070
it as a goal and it's not achievable at

00:01:33,840 --> 00:01:39,689
all so maybe we should you know try to

00:01:38,070 --> 00:01:41,790
understand what is good availability

00:01:39,689 --> 00:01:44,400
what is good reliability or you know

00:01:41,790 --> 00:01:46,680
let's ask first what is availability to

00:01:44,400 --> 00:01:49,619
begin with so we see available there's a

00:01:46,680 --> 00:01:55,229
as is about you know whether a service

00:01:49,619 --> 00:01:57,090
is performing is user expects or not in

00:01:55,229 --> 00:01:59,759
simpler terms we say that like a

00:01:57,090 --> 00:02:03,750
services available if users cannot tell

00:01:59,759 --> 00:02:06,630
it's there was a knowledge so failure

00:02:03,750 --> 00:02:08,220
can happen and might happen but it

00:02:06,630 --> 00:02:10,380
should be rare enough and rare enough

00:02:08,220 --> 00:02:12,299
here it just really depends on the

00:02:10,380 --> 00:02:14,370
business you know how much your users

00:02:12,299 --> 00:02:17,060
can tolerate failure and so on

00:02:14,370 --> 00:02:22,500
so you need to set your you know failure

00:02:17,060 --> 00:02:23,459
in when we you know it depends on the

00:02:22,500 --> 00:02:26,519
system

00:02:23,459 --> 00:02:27,629
so I just want to reiterate the key here

00:02:26,519 --> 00:02:29,430
is not like a hundred percent

00:02:27,629 --> 00:02:33,450
reliability because it's you know just

00:02:29,430 --> 00:02:35,609
not possible we are more of a principled

00:02:33,450 --> 00:02:38,280
way of saying things like you know what

00:02:35,609 --> 00:02:40,500
type of what kind what what is the level

00:02:38,280 --> 00:02:42,359
of downtown which is acceptable for our

00:02:40,500 --> 00:02:45,810
service lots of people have mentioned

00:02:42,359 --> 00:02:49,799
you know Isolators Eliza solos so we

00:02:45,810 --> 00:02:52,439
define and use this we have this common

00:02:49,799 --> 00:02:55,319
language all across the organization we

00:02:52,439 --> 00:02:57,030
write several objectives to tell

00:02:55,319 --> 00:02:59,790
everybody hey this is you know what is

00:02:57,030 --> 00:03:02,030
acceptable downtown and there are two

00:02:59,790 --> 00:03:04,519
major categories we care about our PC

00:03:02,030 --> 00:03:07,620
especially but you can add more

00:03:04,519 --> 00:03:09,329
indicators to your SLO so the first one

00:03:07,620 --> 00:03:11,219
is about you know the error rate how

00:03:09,329 --> 00:03:13,560
much you know error I can tolerate what

00:03:11,219 --> 00:03:14,939
I mean by error here is more like hey

00:03:13,560 --> 00:03:17,849
this you know it's some sort of like

00:03:14,939 --> 00:03:20,689
HTTP 500 like a this crashed and you

00:03:17,849 --> 00:03:24,480
know I'm not getting anything

00:03:20,689 --> 00:03:25,650
the second one is the latency we just

00:03:24,480 --> 00:03:28,440
want to you know have something you know

00:03:25,650 --> 00:03:33,900
acceptance latency boundaries you can

00:03:28,440 --> 00:03:37,019
say hey I want 99.99% of the time I just

00:03:33,900 --> 00:03:40,069
what I'm going to tell you this method

00:03:37,019 --> 00:03:42,000
is going to return in less than hundred

00:03:40,069 --> 00:03:44,430
milliseconds it's kind of like you know

00:03:42,000 --> 00:03:46,109
setting those boundaries and if we are

00:03:44,430 --> 00:03:49,260
going outside of those boundaries

00:03:46,109 --> 00:03:51,269
there's an ISO low violation so

00:03:49,260 --> 00:03:52,859
measuring it no larger than our PC

00:03:51,269 --> 00:03:54,689
metrics in an effective way in a

00:03:52,859 --> 00:03:56,970
distributed system is very hard that's

00:03:54,689 --> 00:03:59,729
why you know it's just like you have all

00:03:56,970 --> 00:04:03,299
these different layers of infrastructure

00:03:59,729 --> 00:04:05,220
in a large company and this is an

00:04:03,299 --> 00:04:08,040
everyday architectural diagram we

00:04:05,220 --> 00:04:09,509
usually end up like having this big you

00:04:08,040 --> 00:04:11,099
know business savvy logic front-end

00:04:09,509 --> 00:04:13,709
server that depends on different layers

00:04:11,099 --> 00:04:15,659
and at the Sun at some point everybody's

00:04:13,709 --> 00:04:18,750
depending on common infrastructure

00:04:15,659 --> 00:04:21,720
layers like the storage systems like

00:04:18,750 --> 00:04:23,430
spanner and blob storage so things are

00:04:21,720 --> 00:04:25,470
getting a little bit nastier here

00:04:23,430 --> 00:04:27,000
because you know since the entire

00:04:25,470 --> 00:04:29,130
company is dependent on the storage

00:04:27,000 --> 00:04:31,650
systems it's just harder for this team

00:04:29,130 --> 00:04:33,450
to analyze their metrics it's hard for

00:04:31,650 --> 00:04:36,300
them to understand the root cause of you

00:04:33,450 --> 00:04:36,990
know outages break down their data if

00:04:36,300 --> 00:04:40,380
there's

00:04:36,990 --> 00:04:43,020
not enough you know cardinality they

00:04:40,380 --> 00:04:45,510
cannot like ezel tail like hey who is

00:04:43,020 --> 00:04:49,290
you know breaking this API because they

00:04:45,510 --> 00:04:52,110
were misusing the API easily if they

00:04:49,290 --> 00:04:54,780
don't have enough dimensions so our

00:04:52,110 --> 00:04:56,790
infantry by our infrastructure team so

00:04:54,780 --> 00:04:57,150
if we want to ask like questions like

00:04:56,790 --> 00:04:59,520
this

00:04:57,150 --> 00:05:01,770
hey are we you know meeting the solo for

00:04:59,520 --> 00:05:04,500
this particular other team or you know

00:05:01,770 --> 00:05:07,200
particular other customer and what is

00:05:04,500 --> 00:05:09,630
the impact of infra what is the impact

00:05:07,200 --> 00:05:11,850
of a product on our interest so we can

00:05:09,630 --> 00:05:15,930
actually say that like hey this product

00:05:11,850 --> 00:05:17,790
is feasible or profitable or not and the

00:05:15,930 --> 00:05:19,680
other one like how much do we need to

00:05:17,790 --> 00:05:22,740
scale up if you know this product grows

00:05:19,680 --> 00:05:25,260
10% overnight so we can do some planning

00:05:22,740 --> 00:05:30,710
maybe and we can see now if it's

00:05:25,260 --> 00:05:33,570
feasible if it we actually have means of

00:05:30,710 --> 00:05:36,780
computing power to you know support that

00:05:33,570 --> 00:05:39,660
growth so we basically this is why we

00:05:36,780 --> 00:05:41,040
basically wanna you know have more high

00:05:39,660 --> 00:05:43,350
cardinality and you know

00:05:41,040 --> 00:05:45,540
multi-dimensional data then you know we

00:05:43,350 --> 00:05:47,250
can filter group by things and like

00:05:45,540 --> 00:05:49,290
cross compare to understand what is

00:05:47,250 --> 00:05:50,610
going on but you know the in in the end

00:05:49,290 --> 00:05:52,560
of the day I just want to query stuff

00:05:50,610 --> 00:05:55,620
like this I just want you know latency

00:05:52,560 --> 00:05:57,990
distribution of our pcs you know

00:05:55,620 --> 00:06:00,860
originated at Google Analytics maybe and

00:05:57,990 --> 00:06:04,710
you know I just want to see the the

00:06:00,860 --> 00:06:08,370
requests that took this much for this

00:06:04,710 --> 00:06:10,920
customer you know compare the request

00:06:08,370 --> 00:06:13,170
latency initiator that web versus

00:06:10,920 --> 00:06:17,630
front-end so I can see you know the

00:06:13,170 --> 00:06:21,120
users experience in different front ends

00:06:17,630 --> 00:06:24,900
so the complicated part of it is just

00:06:21,120 --> 00:06:28,080
like the entire promise of our micro

00:06:24,900 --> 00:06:30,270
services architecture is we just don't

00:06:28,080 --> 00:06:31,860
want any tight coupling between things

00:06:30,270 --> 00:06:34,050
and if we you know if you want to have

00:06:31,860 --> 00:06:36,480
high dimensions what does this mean for

00:06:34,050 --> 00:06:38,220
the you know lower ends of the stack how

00:06:36,480 --> 00:06:41,010
can you know a low level service such as

00:06:38,220 --> 00:06:43,230
blob storage in this case knows about

00:06:41,010 --> 00:06:46,820
these dimensions and you know record

00:06:43,230 --> 00:06:50,040
data with those dimensions this is why

00:06:46,820 --> 00:06:50,850
rather than you know this is why we

00:06:50,040 --> 00:06:54,450
label things

00:06:50,850 --> 00:06:57,750
by propagating labels all across so we

00:06:54,450 --> 00:06:59,700
produce some labels at the higher level

00:06:57,750 --> 00:07:02,310
services like the analytics front-end

00:06:59,700 --> 00:07:04,410
server for example and then we pass it

00:07:02,310 --> 00:07:06,270
as a part of the RPC all across the

00:07:04,410 --> 00:07:08,730
stack so the you know the lower ends of

00:07:06,270 --> 00:07:10,650
the stack can use these labels when

00:07:08,730 --> 00:07:12,750
they're recording metrics in this case

00:07:10,650 --> 00:07:15,810
there's an example label it cites an

00:07:12,750 --> 00:07:18,650
originator originator is a it's just say

00:07:15,810 --> 00:07:22,550
now it's been generated at the first

00:07:18,650 --> 00:07:25,290
place that RPC is starting and then

00:07:22,550 --> 00:07:30,420
nothing is you know mutating it all

00:07:25,290 --> 00:07:32,670
across we just pass it if it exists so

00:07:30,420 --> 00:07:34,230
when you are recording metrics at the

00:07:32,670 --> 00:07:38,940
low end you actually know that like

00:07:34,230 --> 00:07:40,260
originator was the analytics so this is

00:07:38,940 --> 00:07:43,170
why the way this Amin is set up a

00:07:40,260 --> 00:07:45,570
conceptual dashboard another real one it

00:07:43,170 --> 00:07:48,030
looks like a toy because it's a toy you

00:07:45,570 --> 00:07:51,930
know this is a breakdown of the

00:07:48,030 --> 00:07:53,970
blobstore treat RPC errors by originator

00:07:51,930 --> 00:07:56,630
service so you can see you know spinner

00:07:53,970 --> 00:07:59,460
itself is directly creating off errors

00:07:56,630 --> 00:08:01,800
some of the other services are also you

00:07:59,460 --> 00:08:03,000
know seeing some errors and most they're

00:08:01,800 --> 00:08:04,860
most likely going through you know

00:08:03,000 --> 00:08:06,210
spanner or other DBS but you can

00:08:04,860 --> 00:08:08,640
actually see you know the spanner is

00:08:06,210 --> 00:08:11,790
just directly having this number of

00:08:08,640 --> 00:08:13,620
error account so now I will actually

00:08:11,790 --> 00:08:16,050
focus a little bit more on the concepts

00:08:13,620 --> 00:08:18,900
that I haven't seen elsewhere in my 10

00:08:16,050 --> 00:08:21,270
year career before coming to Google and

00:08:18,900 --> 00:08:24,180
these are like my favorite ones like

00:08:21,270 --> 00:08:27,600
they're even more I think I will try to

00:08:24,180 --> 00:08:29,820
do my best to capture a few of those so

00:08:27,600 --> 00:08:32,000
we have an interesting story when it

00:08:29,820 --> 00:08:36,620
comes to metric collection we split

00:08:32,000 --> 00:08:40,560
aggregation from recording things so

00:08:36,620 --> 00:08:42,840
this means that we had two different API

00:08:40,560 --> 00:08:46,020
is the first API is the recording API

00:08:42,840 --> 00:08:49,050
the other API is setting up aggregations

00:08:46,020 --> 00:08:51,090
on what is being recorded this means

00:08:49,050 --> 00:08:54,030
that you can set up aggregations in the

00:08:51,090 --> 00:08:56,040
runtime and as well as in production for

00:08:54,030 --> 00:08:58,800
example we have this high-level concept

00:08:56,040 --> 00:09:00,780
of a measure handle you can just you

00:08:58,800 --> 00:09:04,889
know record values on different measures

00:09:00,780 --> 00:09:06,569
and what you do is at any time you can

00:09:04,889 --> 00:09:10,429
set an egg regression on that measure

00:09:06,569 --> 00:09:15,600
broken die broken down with a set of

00:09:10,429 --> 00:09:17,579
labels label keys and you know export

00:09:15,600 --> 00:09:20,579
data start aggregation and exporting

00:09:17,579 --> 00:09:23,009
data so this is this is very interesting

00:09:20,579 --> 00:09:24,929
because if you have a production nation

00:09:23,009 --> 00:09:27,649
if you want to understand maybe more

00:09:24,929 --> 00:09:30,779
you can push dynamically new

00:09:27,649 --> 00:09:33,299
aggregations or expand an existing egg

00:09:30,779 --> 00:09:36,419
regression and you know get gather more

00:09:33,299 --> 00:09:38,639
data and then disable it once you are

00:09:36,419 --> 00:09:41,970
done because you know it might be an

00:09:38,639 --> 00:09:44,040
expensive thing to Agra great but at

00:09:41,970 --> 00:09:46,859
least in order to respond to an incident

00:09:44,040 --> 00:09:50,269
you just you know you can just

00:09:46,859 --> 00:09:52,859
dynamically change the egg regression

00:09:50,269 --> 00:09:55,529
you know design and what the monitoring

00:09:52,859 --> 00:09:57,929
monitor is very hard and this is I think

00:09:55,529 --> 00:09:59,639
this is why we have this we encourage a

00:09:57,929 --> 00:10:02,459
model where we have this you know

00:09:59,639 --> 00:10:05,309
flexibility to dynamically expand what

00:10:02,459 --> 00:10:08,160
we aggregate and collect and you know

00:10:05,309 --> 00:10:10,459
disable non-essential things when things

00:10:08,160 --> 00:10:12,839
are not needed anymore

00:10:10,459 --> 00:10:15,389
example is an entirely piece of

00:10:12,839 --> 00:10:18,209
technology at Google and most recently

00:10:15,389 --> 00:10:21,509
we started to we started to do a better

00:10:18,209 --> 00:10:25,860
job internally like associating metrics

00:10:21,509 --> 00:10:27,809
with other signals such as you know

00:10:25,860 --> 00:10:30,600
distributed traces for example here

00:10:27,809 --> 00:10:33,959
there's a dashboard each you know latest

00:10:30,600 --> 00:10:35,669
is a heat map latency heat map for each

00:10:33,959 --> 00:10:38,489
late in the bucket we collect some

00:10:35,669 --> 00:10:41,579
example traces if the tray you know

00:10:38,489 --> 00:10:43,529
traces sampled in the in the critical

00:10:41,579 --> 00:10:46,709
path if there's a sample trace in the

00:10:43,529 --> 00:10:49,919
critical path and our dashboards now can

00:10:46,709 --> 00:10:51,660
display this stuff and you know if

00:10:49,919 --> 00:10:55,049
there's a problem hey there's this like

00:10:51,660 --> 00:10:57,119
super high latency issue people can just

00:10:55,049 --> 00:10:59,160
click on and like see an example trace

00:10:57,119 --> 00:11:02,220
and like further dig and like see what

00:10:59,160 --> 00:11:04,889
actually happens this was a lot of you

00:11:02,220 --> 00:11:06,389
know it's a lot of hot it's it's a big

00:11:04,889 --> 00:11:10,589
issue if you want to do this manually

00:11:06,389 --> 00:11:13,470
like a you need to go and like query ir

00:11:10,589 --> 00:11:16,230
tracing back-end to have a sample this

00:11:13,470 --> 00:11:18,790
is more like smooth a I just need an

00:11:16,230 --> 00:11:23,590
example and you can see the distribu

00:11:18,790 --> 00:11:24,930
the trace one of the other useful tools

00:11:23,590 --> 00:11:27,760
is like we have these pages

00:11:24,930 --> 00:11:30,360
introspection pages these are I don't

00:11:27,760 --> 00:11:33,940
know if you are in any familiar but

00:11:30,360 --> 00:11:38,050
these are little pages that is sort from

00:11:33,940 --> 00:11:40,780
all servers at Google and they're just

00:11:38,050 --> 00:11:44,110
small you know dashboards they are only

00:11:40,780 --> 00:11:46,720
responsible for anything collected in

00:11:44,110 --> 00:11:49,870
the in the in the current process and

00:11:46,720 --> 00:11:51,520
you know visualizes them and allows you

00:11:49,870 --> 00:11:53,500
to see what is going on it's it's a good

00:11:51,520 --> 00:11:54,670
tool some people who have never used

00:11:53,500 --> 00:11:57,130
this tools actually just don't

00:11:54,670 --> 00:11:58,690
understand how useful they are it's a

00:11:57,130 --> 00:12:01,600
very big tool during development time

00:11:58,690 --> 00:12:05,590
but I think more importantly if you have

00:12:01,600 --> 00:12:07,600
an issue exporting data to to your

00:12:05,590 --> 00:12:10,060
actual back end to your monitoring back

00:12:07,600 --> 00:12:13,930
end you can see what is going on by

00:12:10,060 --> 00:12:16,540
looking at these pages we provide

00:12:13,930 --> 00:12:18,700
several pages for RPC stats and so on

00:12:16,540 --> 00:12:22,390
but we also have like a tracing for

00:12:18,700 --> 00:12:25,210
example dashboard you can see hey this

00:12:22,390 --> 00:12:27,640
you know request has failed we want to

00:12:25,210 --> 00:12:30,670
export to for example mark but it's

00:12:27,640 --> 00:12:32,770
consistently failing because you know

00:12:30,670 --> 00:12:35,440
there's the error message there and you

00:12:32,770 --> 00:12:37,750
can easily debug things without having

00:12:35,440 --> 00:12:40,570
to depend on an actual back-end and it's

00:12:37,750 --> 00:12:44,200
it's useful and it's kind of like a true

00:12:40,570 --> 00:12:46,210
last resort so it's it's important this

00:12:44,200 --> 00:12:48,700
is this is what it looks like so CSS is

00:12:46,210 --> 00:12:53,560
not a skill that we are you know highly

00:12:48,700 --> 00:12:56,860
invested in so our pages are just okay

00:12:53,560 --> 00:12:59,470
but you know this is our pcs page there

00:12:56,860 --> 00:13:03,910
so it in this process I'm making a bunch

00:12:59,470 --> 00:13:05,620
of pops up our pcs they're all out going

00:13:03,910 --> 00:13:09,340
this is not a service it was just like a

00:13:05,620 --> 00:13:12,520
command-line tool but I also in exposed

00:13:09,340 --> 00:13:15,730
in our PCs page by starting a server

00:13:12,520 --> 00:13:19,510
because why not you can see the you know

00:13:15,730 --> 00:13:21,850
the count RPC call latency rate input

00:13:19,510 --> 00:13:25,020
output like payload sizes and that type

00:13:21,850 --> 00:13:27,370
of stuff in like area counts of course

00:13:25,020 --> 00:13:29,740
so what about exporting the backends and

00:13:27,370 --> 00:13:32,440
what about primitives we use monarch

00:13:29,740 --> 00:13:34,510
it's our new you know global distribute

00:13:32,440 --> 00:13:36,790
monitoring service it's quite different

00:13:34,510 --> 00:13:41,230
than Borgman to be honest in various

00:13:36,790 --> 00:13:43,510
ways as well as exposition format but

00:13:41,230 --> 00:13:45,430
you know to be honest a huge portion of

00:13:43,510 --> 00:13:47,830
our infrastructure is actually like

00:13:45,430 --> 00:13:50,890
living in the open and you know we're

00:13:47,830 --> 00:13:52,690
building more things in open lots of

00:13:50,890 --> 00:13:54,400
other companies are also depending our

00:13:52,690 --> 00:13:56,950
you know infrastructure open source

00:13:54,400 --> 00:13:58,690
infrastructure and these people don't

00:13:56,950 --> 00:14:00,930
have any access to banach so we cannot

00:13:58,690 --> 00:14:05,110
instrument things with just with monarch

00:14:00,930 --> 00:14:06,940
and you know generally speaking Google

00:14:05,110 --> 00:14:09,610
cloud customers love primitives use

00:14:06,940 --> 00:14:13,540
primitives it's a huge ecosystem that we

00:14:09,610 --> 00:14:15,370
cannot just like you know ignore so we'd

00:14:13,540 --> 00:14:17,230
like to instrument things the way we

00:14:15,370 --> 00:14:19,930
like and we have already know specific

00:14:17,230 --> 00:14:21,880
backends but in the end of the day we

00:14:19,930 --> 00:14:24,670
just want to give people the opportunity

00:14:21,880 --> 00:14:26,260
to export all this platform metrics so

00:14:24,670 --> 00:14:28,570
you know the framework metrics are the

00:14:26,260 --> 00:14:30,550
client library metrics - primitives as

00:14:28,570 --> 00:14:32,590
well that's why we started to you know

00:14:30,550 --> 00:14:34,000
write this instrumentation layers that

00:14:32,590 --> 00:14:37,180
is a little bit you know back-end

00:14:34,000 --> 00:14:40,300
agnostic so you can you know send stuff

00:14:37,180 --> 00:14:43,450
sorry as you know see the data in

00:14:40,300 --> 00:14:45,820
primitives as well for example this is

00:14:43,450 --> 00:14:48,490
an example of our client libraries this

00:14:45,820 --> 00:14:51,030
is a property API our pub/sub API is a

00:14:48,490 --> 00:14:54,400
Google cloud platform API there's a

00:14:51,030 --> 00:14:56,860
library for that which is this like the

00:14:54,400 --> 00:15:01,120
go libraries cloud Google comm go pops

00:14:56,860 --> 00:15:04,540
up and it's it's exposing some some

00:15:01,120 --> 00:15:07,530
counters if you go get this and like set

00:15:04,540 --> 00:15:10,570
up things you can actually like you know

00:15:07,530 --> 00:15:12,640
export the pool count you know stream

00:15:10,570 --> 00:15:13,750
related things the number of

00:15:12,640 --> 00:15:15,640
acknowledged stuff

00:15:13,750 --> 00:15:17,920
number of non acknowledged stuff and

00:15:15,640 --> 00:15:20,400
more and we also provide to the RPC

00:15:17,920 --> 00:15:24,250
metrics so you can you know you can

00:15:20,400 --> 00:15:27,820
export a lot of those custom counters as

00:15:24,250 --> 00:15:32,170
well as RPC metrics from the client

00:15:27,820 --> 00:15:35,560
library and see things in parameters so

00:15:32,170 --> 00:15:37,960
last but not least few hours later I

00:15:35,560 --> 00:15:40,450
think we will announce that we are happy

00:15:37,960 --> 00:15:42,460
to be collaborating on open metrics so

00:15:40,450 --> 00:15:46,110
I'm spoiling of spoiling it right now

00:15:42,460 --> 00:15:46,110
we've been already collaborating it but

00:15:46,459 --> 00:15:50,750
we were trying to you know make it as a

00:15:48,110 --> 00:15:52,940
first-class export format for our core

00:15:50,750 --> 00:15:55,880
instrumentation libraries in the long

00:15:52,940 --> 00:15:58,399
term sorry for spoiling it I actually

00:15:55,880 --> 00:16:00,320
need to ask my company if it's okay for

00:15:58,399 --> 00:16:02,420
me to talk about this and not get fired

00:16:00,320 --> 00:16:04,370
and they said oh yeah

00:16:02,420 --> 00:16:06,380
so research is the next speaker he is

00:16:04,370 --> 00:16:09,470
you know he should be the one talking

00:16:06,380 --> 00:16:11,360
about this so I really like that you

00:16:09,470 --> 00:16:13,160
know it's a collaboration effort between

00:16:11,360 --> 00:16:16,550
a lot of parties and we are a part of it

00:16:13,160 --> 00:16:18,800
I think I have a I have done a good job

00:16:16,550 --> 00:16:20,839
you know connecting my talk to the next

00:16:18,800 --> 00:16:23,240
one so I just want to say thank you so

00:16:20,839 --> 00:16:30,920
much I can have questions if you have

00:16:23,240 --> 00:16:33,670
any thank you so much we have like 10

00:16:30,920 --> 00:16:33,670
minutes for questions

00:16:36,279 --> 00:16:45,230
dashboard looks interesting what this is

00:16:38,779 --> 00:16:47,390
it's something this board with where you

00:16:45,230 --> 00:16:49,760
can put this distributing trace oh this

00:16:47,390 --> 00:16:51,680
is this is actual sector ever I mean we

00:16:49,760 --> 00:16:54,140
have something similar internal which is

00:16:51,680 --> 00:17:04,579
different it's just a heap map from sec

00:16:54,140 --> 00:17:07,250
driver yeah yes it's hello

00:17:04,579 --> 00:17:08,510
so I've read the sre book and I'm glad

00:17:07,250 --> 00:17:09,890
you're up there and I've always had this

00:17:08,510 --> 00:17:13,069
question and I think they had a chapter

00:17:09,890 --> 00:17:14,660
on a capacity try planning how do you go

00:17:13,069 --> 00:17:17,720
about that with teams that have no idea

00:17:14,660 --> 00:17:19,669
about doing that or bothering there's

00:17:17,720 --> 00:17:22,189
actually a team that is like entirely

00:17:19,669 --> 00:17:25,339
like focused on this they are not just

00:17:22,189 --> 00:17:28,669
doing like some consultancy but they

00:17:25,339 --> 00:17:30,740
actually provide they know what to look

00:17:28,669 --> 00:17:36,380
and how to look and like measure things

00:17:30,740 --> 00:17:38,419
sorry there's always that you know team

00:17:36,380 --> 00:17:40,400
available for you to just go and learn

00:17:38,419 --> 00:17:41,929
and it's just like basically I think

00:17:40,400 --> 00:17:43,940
from my knowledge it leaves like it

00:17:41,929 --> 00:17:46,550
works that way it's more of like a

00:17:43,940 --> 00:17:48,980
learning and like there's some certain

00:17:46,550 --> 00:17:51,320
things that you can inherit you you're

00:17:48,980 --> 00:17:53,150
not starting from scratch but it's just

00:17:51,320 --> 00:17:56,540
more of like I know the consultants role

00:17:53,150 --> 00:17:58,150
and they're so tooling and so on and you

00:17:56,540 --> 00:18:00,760
know they utilize some

00:17:58,150 --> 00:18:05,680
they exist and signals at least to give

00:18:00,760 --> 00:18:07,900
you a bunch of things already I do so I

00:18:05,680 --> 00:18:10,780
recently had the experience of playing

00:18:07,900 --> 00:18:12,790
around with er PC well being an

00:18:10,780 --> 00:18:14,590
ex-googler it was quite easy to use it

00:18:12,790 --> 00:18:16,930
you know produce EE whatever it all

00:18:14,590 --> 00:18:18,760
works but after I got it running the

00:18:16,930 --> 00:18:20,320
first thing I missed was having an RPC Z

00:18:18,760 --> 00:18:21,490
page in there and it was quite funny

00:18:20,320 --> 00:18:24,490
that like in this talk you gave your

00:18:21,490 --> 00:18:26,620
screenshot of it is there an RPC Z

00:18:24,490 --> 00:18:28,500
equivalent in like the open-source

00:18:26,620 --> 00:18:32,950
version of G RPC yours

00:18:28,500 --> 00:18:35,770
yeah there's we have this client library

00:18:32,950 --> 00:18:38,500
instrumentation project at Google called

00:18:35,770 --> 00:18:41,650
senses it's we are also maintaining that

00:18:38,500 --> 00:18:43,990
our pcs page and we're sort of like open

00:18:41,650 --> 00:18:46,270
source in it so there is actually a open

00:18:43,990 --> 00:18:48,700
source version of it it's not entirely

00:18:46,270 --> 00:18:51,370
super complete in all these different

00:18:48,700 --> 00:18:53,260
languages so I didn't want to like go

00:18:51,370 --> 00:18:55,660
and like talk about that project a lot I

00:18:53,260 --> 00:18:59,140
think it requires a little bit more you

00:18:55,660 --> 00:19:01,060
know work but we are open sourcing that

00:18:59,140 --> 00:19:02,740
stack and we want to you know reuse the

00:19:01,060 --> 00:19:05,590
open source version internally as well

00:19:02,740 --> 00:19:08,110
so our bzees is going to be served by

00:19:05,590 --> 00:19:10,180
the new open-source version of the

00:19:08,110 --> 00:19:11,710
implementation and I think that like any

00:19:10,180 --> 00:19:13,390
in six months or something that we will

00:19:11,710 --> 00:19:15,250
have you know better support all across

00:19:13,390 --> 00:19:20,530
different languages to support our pcs

00:19:15,250 --> 00:19:22,060
and stats and traces Z yeah thank you

00:19:20,530 --> 00:19:24,490
for the talk I was just curious how you

00:19:22,060 --> 00:19:26,530
gather RPC metrics are they emitted from

00:19:24,490 --> 00:19:27,820
the clients or do you have a proxy you

00:19:26,530 --> 00:19:30,640
know in the open source world this might

00:19:27,820 --> 00:19:33,550
be Envoy that's responsible for emitting

00:19:30,640 --> 00:19:36,010
kind of these standardized metrics so we

00:19:33,550 --> 00:19:37,930
usually like to scenarios if there's a

00:19:36,010 --> 00:19:42,940
sidecar we're trying to utilize in a

00:19:37,930 --> 00:19:45,100
sidecar you know try to generate request

00:19:42,940 --> 00:19:48,130
matrix from the sidecar if there's no

00:19:45,100 --> 00:19:50,770
sidecar we by default are trying to

00:19:48,130 --> 00:19:53,440
utilize framework integrations in that

00:19:50,770 --> 00:19:55,630
case I was just depending on the client

00:19:53,440 --> 00:19:57,880
fibers were just dependent on G RPC

00:19:55,630 --> 00:20:00,280
integration so as soon as you just pull

00:19:57,880 --> 00:20:04,180
it in and the client libraries are

00:20:00,280 --> 00:20:08,560
pulling it in you you know we just

00:20:04,180 --> 00:20:11,350
generate you know our RPC stats we don't

00:20:08,560 --> 00:20:11,980
encourage people to think about RPC

00:20:11,350 --> 00:20:14,530
stats then

00:20:11,980 --> 00:20:16,360
sells it needs to be enough coming to

00:20:14,530 --> 00:20:18,220
you from framework integrations or

00:20:16,360 --> 00:20:20,679
sidecars and if you want to add like

00:20:18,220 --> 00:20:23,290
custom stuff yeah just use the you know

00:20:20,679 --> 00:20:33,059
the the low-level api is where otherwise

00:20:23,290 --> 00:20:37,550
you shouldn't be doing it anyone okay

00:20:33,059 --> 00:20:41,970
alright thank you so much yeah thanks

00:20:37,550 --> 00:20:41,970

YouTube URL: https://www.youtube.com/watch?v=Dm3r0Siu7PU


