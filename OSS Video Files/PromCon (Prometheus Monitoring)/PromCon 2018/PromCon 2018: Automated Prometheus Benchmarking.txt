Title: PromCon 2018: Automated Prometheus Benchmarking
Publication date: 2018-11-10
Playlist: PromCon 2018
Description: 
	Speakers: Krasi Georgiev, Harsh Agarwal

Automated Prometheus Benchmarking - Pushing It to Its Limits until It Breaks!

We will show you how we are trying to make Prometheus more stable by running automated benchmarking for risky PRs and before every release. In other words, let's try to break it in our tests so it doesn't break in your production.

We will cover why we decided to use Prow and how it is integrated with GitHub.

We will also cover the current progress, the project roadmap and of course do a short demo.
Captions: 
	00:00:13,139 --> 00:00:22,599
okay my name is Chrissy I have seen many

00:00:18,970 --> 00:00:24,279
people read it is crazy and I don't mind

00:00:22,599 --> 00:00:25,300
it fits very well with the things I like

00:00:24,279 --> 00:00:28,449
to do in my weekends

00:00:25,300 --> 00:00:31,330
so that's fine prometheus maintainer

00:00:28,449 --> 00:00:33,100
from March this year and since then I

00:00:31,330 --> 00:00:38,290
managed to fix and break quite a few

00:00:33,100 --> 00:00:39,940
things already work is part of the

00:00:38,290 --> 00:00:42,550
Prometheus teaming red hot which means

00:00:39,940 --> 00:00:47,140
mainly fixing bugs and adding features

00:00:42,550 --> 00:00:49,120
upstream in red hot prometheus is used

00:00:47,140 --> 00:00:51,640
in OpenShift of course

00:00:49,120 --> 00:00:54,280
Jiali which is the new open-source

00:00:51,640 --> 00:00:56,829
project for monitoring in tracing of

00:00:54,280 --> 00:01:01,149
containers and as far as I know in the

00:00:56,829 --> 00:01:03,640
operations monitoring harsh who is here

00:01:01,149 --> 00:01:05,680
with me today he is an undergraduate

00:01:03,640 --> 00:01:09,340
student from the Indian Institute of

00:01:05,680 --> 00:01:10,899
Technology of Hyderabad who decided to

00:01:09,340 --> 00:01:14,259
help us through the google Summer of

00:01:10,899 --> 00:01:23,290
Code so it's great - it's great to

00:01:14,259 --> 00:01:26,740
having him here so now back to the main

00:01:23,290 --> 00:01:29,470
part everybody wants stable soft right

00:01:26,740 --> 00:01:32,110
but how do we know it's stable well in

00:01:29,470 --> 00:01:35,049
prometheus case that means earning it

00:01:32,110 --> 00:01:37,299
long enough and high load comparing

00:01:35,049 --> 00:01:39,399
comparing it with another version and

00:01:37,299 --> 00:01:41,229
then the results should give us the

00:01:39,399 --> 00:01:45,159
answer if it's ready for another release

00:01:41,229 --> 00:01:47,439
or it needs more work to be done well

00:01:45,159 --> 00:01:49,659
the project is not 100% there yet but

00:01:47,439 --> 00:01:52,600
we're very very close and the funny

00:01:49,659 --> 00:01:54,790
story is that when I submitted the talk

00:01:52,600 --> 00:01:57,700
this was just an idea and maybe some

00:01:54,790 --> 00:01:59,380
discussions but when I received the

00:01:57,700 --> 00:02:01,570
email one day saying your talk is

00:01:59,380 --> 00:02:04,810
accepted that I thought oh no now I

00:02:01,570 --> 00:02:08,229
really have to do it so lucky for me

00:02:04,810 --> 00:02:10,840
harsh also liked the idea and decided to

00:02:08,229 --> 00:02:12,400
help us so I thought well - is a team so

00:02:10,840 --> 00:02:17,859
there's there is no excuse we can do it

00:02:12,400 --> 00:02:20,190
no problem so let me see some hands how

00:02:17,859 --> 00:02:22,840
many of you are some sort of like

00:02:20,190 --> 00:02:27,459
maintainer Zoar open-source

00:02:22,840 --> 00:02:29,410
project maintainer okay so you will like

00:02:27,459 --> 00:02:32,560
the the I promise you will like the next

00:02:29,410 --> 00:02:35,800
few slides this is what a normal day

00:02:32,560 --> 00:02:37,840
looks like for me that's just before I

00:02:35,800 --> 00:02:40,569
look at the github homepage hoping to

00:02:37,840 --> 00:02:41,950
see a PAPR that is only a single line

00:02:40,569 --> 00:02:46,360
and the fix is at least two or three

00:02:41,950 --> 00:02:49,239
bucks but this is what I get next now

00:02:46,360 --> 00:02:51,370
this might sound and look familiar to

00:02:49,239 --> 00:02:53,739
many of you usually it starts my

00:02:51,370 --> 00:02:56,680
prometheus is broken please help so here

00:02:53,739 --> 00:02:58,930
I keep it calm trying to ask for more

00:02:56,680 --> 00:03:00,959
details Amen I'm not a psychic give me

00:02:58,930 --> 00:03:03,700
some detail and this is what I get next

00:03:00,959 --> 00:03:07,209
it's like a huge config which is

00:03:03,700 --> 00:03:09,280
supposed to work on like amazing three

00:03:07,209 --> 00:03:11,560
hundred and thirty five hundred targets

00:03:09,280 --> 00:03:13,870
now don't get me wrong this is amazing I

00:03:11,560 --> 00:03:17,799
mean Prometheus can handle that but how

00:03:13,870 --> 00:03:23,200
do i replicate this locally right well

00:03:17,799 --> 00:03:25,000
benchmarking and ok let me see some

00:03:23,200 --> 00:03:28,299
hands how many of you use to point one

00:03:25,000 --> 00:03:30,790
or two points to version ok I feel your

00:03:28,299 --> 00:03:34,060
pain there were quite a few there were

00:03:30,790 --> 00:03:38,500
few memory leaks and Hugh crosses based

00:03:34,060 --> 00:03:40,120
on compactions so but go lonk is garbage

00:03:38,500 --> 00:03:42,910
collected right so how can there be

00:03:40,120 --> 00:03:46,810
memory leaks well what happens is that

00:03:42,910 --> 00:03:48,489
when the application generates more more

00:03:46,810 --> 00:03:51,010
garbage than what the garbage collector

00:03:48,489 --> 00:03:53,590
can collect then then the garbage

00:03:51,010 --> 00:03:55,450
collector can clear then over time the

00:03:53,590 --> 00:03:57,400
memory usage grows so much until the

00:03:55,450 --> 00:04:01,720
system just kills the application and

00:03:57,400 --> 00:04:04,540
the next one was with compaction now in

00:04:01,720 --> 00:04:07,150
Prometheus the data base is separated

00:04:04,540 --> 00:04:08,889
into folders by a time range two hours

00:04:07,150 --> 00:04:11,349
four hours ten hours and so on and

00:04:08,889 --> 00:04:13,959
compaction is when two or more smaller

00:04:11,349 --> 00:04:16,090
blocks are joined to into a bigger one

00:04:13,959 --> 00:04:17,950
and if the system runs out of memory

00:04:16,090 --> 00:04:20,530
during this compaction then next time

00:04:17,950 --> 00:04:22,900
Prometheus starts it was game over it

00:04:20,530 --> 00:04:26,820
would go into a crush loop with some

00:04:22,900 --> 00:04:31,120
overlapping ranges arrows both of these

00:04:26,820 --> 00:04:34,030
are fixed in 2.3 but anyway my point is

00:04:31,120 --> 00:04:36,249
why don't we just do unit testing and

00:04:34,030 --> 00:04:37,959
end-to-end tests well none

00:04:36,249 --> 00:04:39,489
these will appear in unit testing and

00:04:37,959 --> 00:04:42,189
end-to-end test only because they run

00:04:39,489 --> 00:04:45,549
for a very short period of time and with

00:04:42,189 --> 00:04:47,109
hardly any load so now that you see why

00:04:45,549 --> 00:04:51,159
we need benchmarking let's see how we

00:04:47,109 --> 00:04:54,459
did it after a long discussion we

00:04:51,159 --> 00:04:56,469
decided to use pro CI which is developed

00:04:54,459 --> 00:04:59,469
and maintained by the kubernetes testing

00:04:56,469 --> 00:05:00,969
team it turns on kubernetes which is

00:04:59,469 --> 00:05:03,999
great because most of the maintainer

00:05:00,969 --> 00:05:05,979
czar familiar with kubernetes it's

00:05:03,999 --> 00:05:07,959
integrating rates nicely with github so

00:05:05,979 --> 00:05:10,719
we can trigger just by a single single

00:05:07,959 --> 00:05:13,449
comment which is easy it's written in go

00:05:10,719 --> 00:05:15,610
lonk so that's a big win for me and it's

00:05:13,449 --> 00:05:18,009
very easy to extend using plugins which

00:05:15,610 --> 00:05:21,489
is what we did we implemented one for

00:05:18,009 --> 00:05:23,619
our use case it's it's not as popular as

00:05:21,489 --> 00:05:25,539
drone which is another continuous

00:05:23,619 --> 00:05:28,899
integration tool but it's still used by

00:05:25,539 --> 00:05:31,239
quite a few projects out there now

00:05:28,899 --> 00:05:34,469
before we even decided what to use they

00:05:31,239 --> 00:05:37,179
were like two months of discussions and

00:05:34,469 --> 00:05:39,129
with prom cone approaching in the talk

00:05:37,179 --> 00:05:41,069
being accepted that's really helped to

00:05:39,129 --> 00:05:44,379
get us nervous and speed up the process

00:05:41,069 --> 00:05:47,769
so I think we headed down in another one

00:05:44,379 --> 00:05:51,069
or two months now another tool that we

00:05:47,769 --> 00:05:54,129
were considered was drone CI and it's

00:05:51,069 --> 00:05:56,259
grant great but it was missing two other

00:05:54,129 --> 00:05:59,529
main features that we needed namely

00:05:56,259 --> 00:06:02,829
comments and it runs from kubernetes but

00:05:59,529 --> 00:06:04,989
it's it's kind of hacking packet which

00:06:02,829 --> 00:06:08,529
is a cloud on bare metal provider is

00:06:04,989 --> 00:06:11,919
what we used to the beginning their team

00:06:08,529 --> 00:06:15,129
is great the API the API is amazing so

00:06:11,919 --> 00:06:17,469
big things they're a team but one day on

00:06:15,129 --> 00:06:20,769
IRC I think Julius or Fabian mentioned

00:06:17,469 --> 00:06:23,049
why don't we just use the manage google

00:06:20,769 --> 00:06:26,110
kubernetes engine this will save us a

00:06:23,049 --> 00:06:27,519
lot of hassle and maintenance and I

00:06:26,110 --> 00:06:31,899
think they were right I was thinking

00:06:27,519 --> 00:06:34,029
should I rather spend my weekend fixing

00:06:31,899 --> 00:06:35,860
a kubernetes cluster or should I do

00:06:34,029 --> 00:06:37,890
something else crazy that might kill me

00:06:35,860 --> 00:06:42,340
or something I don't know

00:06:37,890 --> 00:06:44,140
so at the end terraform why don't we why

00:06:42,340 --> 00:06:46,720
don't we use terraform or any other more

00:06:44,140 --> 00:06:49,390
generic tool well I thought I would

00:06:46,720 --> 00:06:51,820
rather write few lines of Golan calls

00:06:49,390 --> 00:06:54,520
that will do exactly what I need rather

00:06:51,820 --> 00:06:56,410
than learn another two or three tools

00:06:54,520 --> 00:06:59,740
that will do exactly the same thing and

00:06:56,410 --> 00:07:01,630
life is too short right I mean if I was

00:06:59,740 --> 00:07:05,950
teenager that's fine to experiment but

00:07:01,630 --> 00:07:08,050
these days that's too much so at the end

00:07:05,950 --> 00:07:10,990
I think it was the right decision but

00:07:08,050 --> 00:07:13,510
time will tell the prom bench the prom

00:07:10,990 --> 00:07:15,550
bench tool ended up being really easy to

00:07:13,510 --> 00:07:17,620
use it doesn't use it doesn't need any

00:07:15,550 --> 00:07:20,770
dependence he doesn't need cube control

00:07:17,620 --> 00:07:22,990
or anything else just it's written in go

00:07:20,770 --> 00:07:24,670
long he just downloaded create on

00:07:22,990 --> 00:07:28,210
account with the google kubernetes

00:07:24,670 --> 00:07:30,160
engine download the authentication file

00:07:28,210 --> 00:07:31,720
run it with a config for the machines

00:07:30,160 --> 00:07:34,950
that you need to run and the two

00:07:31,720 --> 00:07:38,500
versions of Prometheus you want to test

00:07:34,950 --> 00:07:42,130
so now let me see some hands how many of

00:07:38,500 --> 00:07:42,460
you want to see a recorded demo shame on

00:07:42,130 --> 00:07:45,430
you

00:07:42,460 --> 00:08:02,410
we're doing it life we feel we feel

00:07:45,430 --> 00:08:09,520
adventurous so now let's see what's on

00:08:02,410 --> 00:08:11,680
the PR skew it one looks interesting and

00:08:09,520 --> 00:08:16,620
it's one of the top contributors so it

00:08:11,680 --> 00:08:20,530
must be good let's see what we have here

00:08:16,620 --> 00:08:22,900
well it's just removing some buffer so

00:08:20,530 --> 00:08:24,060
it must be okay these are not these are

00:08:22,900 --> 00:08:27,970
not important

00:08:24,060 --> 00:08:29,800
and I'm thinking since we I mean since

00:08:27,970 --> 00:08:33,940
we have so many maintained errs here

00:08:29,800 --> 00:08:34,720
should I just click on merch or should

00:08:33,940 --> 00:08:37,740
we run a test

00:08:34,720 --> 00:08:37,740
auditing Brian

00:08:37,760 --> 00:08:46,310
I don't know we feel adventurous okay

00:08:43,279 --> 00:08:57,680
let's run a test anyway I'm sure it will

00:08:46,310 --> 00:09:03,860
be fine but let's see you later I be

00:08:57,680 --> 00:09:09,019
right my screen shows completely

00:09:03,860 --> 00:09:10,670
different thing okay so now if

00:09:09,019 --> 00:09:12,680
everything goes well in a second we

00:09:10,670 --> 00:09:15,199
should receive a response from the pro

00:09:12,680 --> 00:09:17,860
system that test has been started

00:09:15,199 --> 00:09:30,410
can you just scroll back a little bit

00:09:17,860 --> 00:09:32,420
scroll up up the other up let me do okay

00:09:30,410 --> 00:09:36,470
so now you can see that the job the job

00:09:32,420 --> 00:09:39,320
has been started and I think this is

00:09:36,470 --> 00:09:40,550
where I hand and over to harsh to

00:09:39,320 --> 00:09:42,639
explain what's happening in the

00:09:40,550 --> 00:09:42,639
background

00:10:00,270 --> 00:10:07,000
check and so I'm going to take you

00:10:04,840 --> 00:10:11,320
through the life of a bench test and I

00:10:07,000 --> 00:10:14,010
will explain the full procedure so when

00:10:11,320 --> 00:10:17,260
the maintainer wants to benchmark of PR

00:10:14,010 --> 00:10:19,780
he will mention the release version he

00:10:17,260 --> 00:10:21,580
wants to benchmark it away the default

00:10:19,780 --> 00:10:23,880
version is the master branch but he can

00:10:21,580 --> 00:10:28,420
also pinch mark it with any previous

00:10:23,880 --> 00:10:31,570
release so github er will send this per

00:10:28,420 --> 00:10:34,180
book even to prowl and on receiving this

00:10:31,570 --> 00:10:37,090
event prowl will create a kubernetes job

00:10:34,180 --> 00:10:43,660
this job uses the prom bench tool as the

00:10:37,090 --> 00:10:45,640
container image so as crashy showed the

00:10:43,660 --> 00:10:49,090
prom bought it printed the

00:10:45,640 --> 00:10:52,210
acknowledgment and now the two versions

00:10:49,090 --> 00:11:01,600
of prom bench of Prometheus are being

00:10:52,210 --> 00:11:08,320
benchmarked if we look at the comment at

00:11:01,600 --> 00:11:20,250
the so a job by the name of start

00:11:08,320 --> 00:11:23,100
benchmark was started by a problem now

00:11:20,250 --> 00:11:25,500
see what does this job actually do so

00:11:23,100 --> 00:11:30,180
first thing this prom bench tool it will

00:11:25,500 --> 00:11:32,540
create a new node pool no 2 and node 3

00:11:30,180 --> 00:11:35,280
they will be used to run the two

00:11:32,540 --> 00:11:37,860
Prometheus's version that are being

00:11:35,280 --> 00:11:41,010
benchmarked we did we did this because

00:11:37,860 --> 00:11:43,500
we want we want to dedicate one node

00:11:41,010 --> 00:11:46,290
completely to Prometheus because we

00:11:43,500 --> 00:11:49,170
don't want any other part interfering

00:11:46,290 --> 00:11:51,600
with the benchmarking results and in

00:11:49,170 --> 00:11:53,700
Norvin these are a bunch of nodes they

00:11:51,600 --> 00:11:55,950
will contain many fake web servers and

00:11:53,700 --> 00:11:58,200
we also have a load gen scalar and loads

00:11:55,950 --> 00:12:04,280
in query er which we use to generate

00:11:58,200 --> 00:12:06,870
load on the Prometheus servers so the

00:12:04,280 --> 00:12:09,930
Prometheus servers being benchmark they

00:12:06,870 --> 00:12:13,680
will service discover the fake web

00:12:09,930 --> 00:12:17,180
servers and then we have load gen

00:12:13,680 --> 00:12:19,980
queriers so this load gen querier will

00:12:17,180 --> 00:12:22,110
constantly query thee to Prometheus

00:12:19,980 --> 00:12:25,020
servers will with complex prom ql

00:12:22,110 --> 00:12:26,670
expressions it will also expose metrics

00:12:25,020 --> 00:12:29,640
which tell us the time taken by

00:12:26,670 --> 00:12:31,800
Prometheus to give the results we need

00:12:29,640 --> 00:12:34,860
this because we also want to see in how

00:12:31,800 --> 00:12:39,200
how fast does Prometheus give us the

00:12:34,860 --> 00:12:41,760
query results when it is under high load

00:12:39,200 --> 00:12:44,040
then we have got a load gen scalar this

00:12:41,760 --> 00:12:46,860
will constantly scale the fake web

00:12:44,040 --> 00:12:51,120
server pots up and down from 300 to 700

00:12:46,860 --> 00:12:53,400
and back to 300 and so on so with this

00:12:51,120 --> 00:12:56,790
fear and all this will be done in a new

00:12:53,400 --> 00:13:00,750
namespace in the cluster and we will use

00:12:56,790 --> 00:13:04,230
the PR number as the name so with this

00:13:00,750 --> 00:13:16,730
we can run many different benchmarking

00:13:04,230 --> 00:13:24,050
instances on the same cluster itself so

00:13:16,730 --> 00:13:29,030
we let's okay so let's see

00:13:24,050 --> 00:13:31,310
okay so ever as you can see we use the

00:13:29,030 --> 00:13:34,670
tool to create a node pool and right now

00:13:31,310 --> 00:13:36,200
the objects are being deployed so we

00:13:34,670 --> 00:13:42,530
give it some time

00:13:36,200 --> 00:13:45,110
for it to be deployed and I will explain

00:13:42,530 --> 00:13:47,030
the parts by the way now to get the

00:13:45,110 --> 00:13:48,920
benchmarking results we have one main

00:13:47,030 --> 00:13:51,710
Prometheus servers which will service

00:13:48,920 --> 00:13:53,240
discover these two Prometheus servers

00:13:51,710 --> 00:13:55,640
being benchmarked and it will also

00:13:53,240 --> 00:14:00,950
scrape metrics from the load gen querier

00:13:55,640 --> 00:14:03,410
and we also have an refiner sub server

00:14:00,950 --> 00:14:05,590
which uses the main Prometheus server as

00:14:03,410 --> 00:14:08,120
the data source and we have go to

00:14:05,590 --> 00:14:11,900
dashboards which tell us about the

00:14:08,120 --> 00:14:15,470
benchmarking results and of course we

00:14:11,900 --> 00:14:17,480
have an alert manager so if we find that

00:14:15,470 --> 00:14:21,100
there is a lot of difference between the

00:14:17,480 --> 00:14:23,600
benchmarking results between the PR and

00:14:21,100 --> 00:14:26,870
release version we are benchmarking it

00:14:23,600 --> 00:14:29,000
with then we want to trigger alerts and

00:14:26,870 --> 00:14:31,400
tell the maintainer that something is

00:14:29,000 --> 00:14:34,880
wrong with this PR and to implement this

00:14:31,400 --> 00:14:38,690
we use a custom web hook event a custom

00:14:34,880 --> 00:14:41,500
web hook and on receiving an alert this

00:14:38,690 --> 00:14:44,240
will print a comment in the PR

00:14:41,500 --> 00:14:46,370
conversation itself so with this the

00:14:44,240 --> 00:14:48,230
maintainer can know okay something is

00:14:46,370 --> 00:14:52,160
going wrong and we need to check

00:14:48,230 --> 00:14:52,520
something so let's just look at the

00:14:52,160 --> 00:15:06,320
locks

00:14:52,520 --> 00:15:08,810
if appear to a few things are being

00:15:06,320 --> 00:15:10,990
deployed so I will just continue and

00:15:08,810 --> 00:15:10,990
then

00:15:39,170 --> 00:15:44,670
so here you also have a Steen shorter

00:15:42,300 --> 00:15:46,890
the sample results but I will show you

00:15:44,670 --> 00:15:51,750
this in the demo

00:15:46,890 --> 00:15:54,030
and while the objects are being deployed

00:15:51,750 --> 00:15:57,180
I'll let Grassi tell the future roadmap

00:15:54,030 --> 00:15:59,460
of this project let me just double check

00:15:57,180 --> 00:16:04,400
I think maybe by now the test should be

00:15:59,460 --> 00:16:04,400
ready let's just check the logs again

00:16:07,430 --> 00:16:18,470
it's done so if we go to the graph on a

00:16:11,790 --> 00:16:21,450
dashboard let's refresh this and then

00:16:18,470 --> 00:16:23,850
from the drop down menu here we can

00:16:21,450 --> 00:16:27,750
select the P R which is 4 4 7 8 if I'm

00:16:23,850 --> 00:16:35,130
not 4 4 8 7 is it the last one I have

00:16:27,750 --> 00:16:37,700
another screen here ok that's easy my

00:16:35,130 --> 00:16:37,700
neck hurts

00:16:45,770 --> 00:16:54,360
so let's see how grass is PR actually

00:16:49,970 --> 00:16:58,980
performed I think there is something

00:16:54,360 --> 00:17:00,690
wrong here so as you can see the yellow

00:16:58,980 --> 00:17:02,850
one actually that's the master branch

00:17:00,690 --> 00:17:05,520
and the green one that's the PR that if

00:17:02,850 --> 00:17:07,190
you are benchmarking it with so as we

00:17:05,520 --> 00:17:10,110
can see that there are so many more

00:17:07,190 --> 00:17:13,709
allocation so that so now with this tool

00:17:10,110 --> 00:17:15,810
the maintain us can easily see ok that

00:17:13,709 --> 00:17:17,280
we can easily test that if there is

00:17:15,810 --> 00:17:19,770
something fundamentally wrong with the

00:17:17,280 --> 00:17:21,690
PR and if this had been accidentally

00:17:19,770 --> 00:17:23,910
merged then we would have got a flurry

00:17:21,690 --> 00:17:25,589
of github issues saying something is

00:17:23,910 --> 00:17:27,360
wrong wrong with my server please help

00:17:25,589 --> 00:17:29,160
please help so now with this the

00:17:27,360 --> 00:17:31,230
maintainer can also find new ways of

00:17:29,160 --> 00:17:34,740
optimizing prometheus

00:17:31,230 --> 00:17:38,670
or finding bugs under high load so that

00:17:34,740 --> 00:17:42,290
means this PR is not quite correct and

00:17:38,670 --> 00:17:42,290
some work that needs to be done on this

00:17:43,780 --> 00:17:49,890
[Applause]

00:17:47,210 --> 00:17:53,370
so just to summarize just with one

00:17:49,890 --> 00:17:56,910
command we scaled up a kubernetes

00:17:53,370 --> 00:18:00,390
cluster we deployed so many pieces we

00:17:56,910 --> 00:18:02,010
built primitives from the PR and we run

00:18:00,390 --> 00:18:04,200
it along with another version and we

00:18:02,010 --> 00:18:09,110
compared the results so a lot of things

00:18:04,200 --> 00:18:11,460
done only in a single command okay

00:18:09,110 --> 00:18:12,900
so now I will share with you quickly

00:18:11,460 --> 00:18:16,590
because I think we only have a few

00:18:12,900 --> 00:18:18,960
minutes who thinks that we want to see

00:18:16,590 --> 00:18:22,260
happening next the first thing is you

00:18:18,960 --> 00:18:23,880
can run this prom bench without pro so

00:18:22,260 --> 00:18:27,330
it's just you need you can run it on

00:18:23,880 --> 00:18:29,130
your own google kubernetes cluster you

00:18:27,330 --> 00:18:31,950
don't need to run it from github so

00:18:29,130 --> 00:18:34,230
we'll add we will add it into the readme

00:18:31,950 --> 00:18:37,350
the next thing we want to add is another

00:18:34,230 --> 00:18:39,570
job that will just detect for races with

00:18:37,350 --> 00:18:41,460
children primitive set high load and it

00:18:39,570 --> 00:18:44,310
will just monitor foreign race

00:18:41,460 --> 00:18:47,150
exceptions then we want to be able to

00:18:44,310 --> 00:18:49,620
test the server's the service discovery

00:18:47,150 --> 00:18:51,720
providers which is something that we're

00:18:49,620 --> 00:18:53,700
not testing right now ideally because we

00:18:51,720 --> 00:18:55,110
need to actually deploy the actual

00:18:53,700 --> 00:18:57,060
service provider service discovery

00:18:55,110 --> 00:19:02,310
providers which is kind of difficult

00:18:57,060 --> 00:19:04,020
with kubernetes in amazon scalability

00:19:02,310 --> 00:19:08,250
tests we've been discussing that it will

00:19:04,020 --> 00:19:10,050
be great to know how much matrix and how

00:19:08,250 --> 00:19:11,880
much load can a single Prometheus take

00:19:10,050 --> 00:19:14,640
on a given machine so this is what we

00:19:11,880 --> 00:19:16,140
want to implement next just sort of push

00:19:14,640 --> 00:19:17,880
it to its limit and post the results

00:19:16,140 --> 00:19:19,950
with every new release so it gives some

00:19:17,880 --> 00:19:22,140
idea of what people can expect and

00:19:19,950 --> 00:19:24,600
quickly I want to mention a couple of

00:19:22,140 --> 00:19:27,180
new the prom tool has a new debug

00:19:24,600 --> 00:19:30,810
command so if you're submitting an issue

00:19:27,180 --> 00:19:32,910
please use it it will create profile a

00:19:30,810 --> 00:19:35,460
go long profile with some metrics

00:19:32,910 --> 00:19:38,370
because it will really help speed up the

00:19:35,460 --> 00:19:41,100
debugging the T is DB scan the teens Dib

00:19:38,370 --> 00:19:45,150
it will also have a scan which will try

00:19:41,100 --> 00:19:47,520
to repair or delete corrupted blocks so

00:19:45,150 --> 00:19:49,050
can select at least primitive skin

00:19:47,520 --> 00:19:53,460
starts without deleting the entire

00:19:49,050 --> 00:19:55,800
folder now that I see the project almost

00:19:53,460 --> 00:19:59,400
ready it makes me believe in

00:19:55,800 --> 00:20:01,500
open source even more it was really nice

00:19:59,400 --> 00:20:03,809
to see how many people helped and how

00:20:01,500 --> 00:20:09,660
easy was to get what we need it's just

00:20:03,809 --> 00:20:13,590
common sense and so many people have

00:20:09,660 --> 00:20:16,290
like pocket I don't know if I have time

00:20:13,590 --> 00:20:20,100
how much time do you have over okay I

00:20:16,290 --> 00:20:22,590
will let you read this later and at the

00:20:20,100 --> 00:20:24,870
end I want to say I like refactoring but

00:20:22,590 --> 00:20:26,880
I like breaking I hate breaking code and

00:20:24,870 --> 00:20:30,410
now with this I hope I can do what I

00:20:26,880 --> 00:20:30,410
like without hating hating what I do

00:20:31,040 --> 00:20:34,559
that's another project from my

00:20:33,030 --> 00:20:36,120
colleagues because I want to be a team

00:20:34,559 --> 00:20:37,950
player so I decided to quickly mention

00:20:36,120 --> 00:20:40,200
it is really cool it's using Prometheus

00:20:37,950 --> 00:20:42,000
East you and Egger so really cool go and

00:20:40,200 --> 00:20:46,910
check it out I recommend it Jiali

00:20:42,000 --> 00:20:46,910
on github and questions if we have time

00:20:48,790 --> 00:20:56,220
[Applause]

00:20:56,450 --> 00:21:00,500
outside are very good or very bad

00:21:09,080 --> 00:21:14,399
thank you very much great presentation

00:21:12,269 --> 00:21:17,549
since you are benchmarking in the cloud

00:21:14,399 --> 00:21:19,619
have you ever experienced inconsistent

00:21:17,549 --> 00:21:24,960
or strange results due to noisy

00:21:19,619 --> 00:21:26,940
neighbors or cloudy effects it's still

00:21:24,960 --> 00:21:30,149
early stages we haven't really run any

00:21:26,940 --> 00:21:33,269
real tests but what we are doing is we

00:21:30,149 --> 00:21:36,119
are deploying kubernetes itself on a

00:21:33,269 --> 00:21:38,100
single machine so every instance of

00:21:36,119 --> 00:21:40,139
permit permit prometheus runs on its own

00:21:38,100 --> 00:21:42,389
machine so it doesn't really have any

00:21:40,139 --> 00:21:44,129
noisy neighbors if this is what I mean I

00:21:42,389 --> 00:21:46,739
mean it doesn't run with anything else

00:21:44,129 --> 00:21:49,019
next to it so it's on its own on a

00:21:46,739 --> 00:21:51,269
single machine so this is how we are

00:21:49,019 --> 00:21:55,159
trying to get the best results by

00:21:51,269 --> 00:21:57,960
comparing the two do you only run the

00:21:55,159 --> 00:22:00,989
benchmarks with Pro or everything else

00:21:57,960 --> 00:22:02,460
like the whole CI pipelines sorry can

00:22:00,989 --> 00:22:05,999
you repeat it you also run everything

00:22:02,460 --> 00:22:09,989
with pro like the whole CI pipeline No

00:22:05,999 --> 00:22:12,960
pro pro only runs the prom bench tool by

00:22:09,989 --> 00:22:15,179
passing arguments which is the PR and

00:22:12,960 --> 00:22:17,879
which are the two versions you want to

00:22:15,179 --> 00:22:20,039
compare and that's it just runs the prom

00:22:17,879 --> 00:22:22,080
bench tool nothing else we're using pro

00:22:20,039 --> 00:22:25,379
mainly so we can trigger jobs from the

00:22:22,080 --> 00:22:26,700
comments bypassing the PR in the the

00:22:25,379 --> 00:22:32,940
other version that we want to test a

00:22:26,700 --> 00:22:39,649
release or a master one more at least no

00:22:32,940 --> 00:22:39,649
we got time for one more thank you

00:22:45,650 --> 00:22:50,880
and I am interested to know how you

00:22:48,300 --> 00:22:54,870
built the queries that you know test

00:22:50,880 --> 00:22:56,220
with well the queries this is the second

00:22:54,870 --> 00:22:58,800
version of the prompt bench the first

00:22:56,220 --> 00:23:02,460
one was built by Fabian and Max if I am

00:22:58,800 --> 00:23:04,170
NOT wrong kind of so the query start

00:23:02,460 --> 00:23:08,760
from the first version so I don't really

00:23:04,170 --> 00:23:10,680
know we just reused it but all the all

00:23:08,760 --> 00:23:13,650
the code is in prompt bench in

00:23:10,680 --> 00:23:15,660
components you will see the queries

00:23:13,650 --> 00:23:17,220
there it's like it's a simple text file

00:23:15,660 --> 00:23:18,900
and you can see it there so if you go to

00:23:17,220 --> 00:23:22,680
prom bench just browse around and you

00:23:18,900 --> 00:23:26,370
will find it yeah is there potential

00:23:22,680 --> 00:23:27,840
ability to shoot here here right is

00:23:26,370 --> 00:23:30,210
there potential ability to shoot this

00:23:27,840 --> 00:23:34,740
benchmark against my own deployment of

00:23:30,210 --> 00:23:37,170
parameters so to predict how much it can

00:23:34,740 --> 00:23:39,510
handle this is on the roadmap this is

00:23:37,170 --> 00:23:42,150
like the scalability test at the moment

00:23:39,510 --> 00:23:44,730
the only thing I can say that Google

00:23:42,150 --> 00:23:49,230
it's so easy to run you can run it in

00:23:44,730 --> 00:23:50,580
your google kubernetes account but at

00:23:49,230 --> 00:23:54,000
the moment you can only choose between

00:23:50,580 --> 00:23:56,790
two given versions a PR a master or a

00:23:54,000 --> 00:23:58,260
release and master I think what you're

00:23:56,790 --> 00:23:59,850
referring to is the scalability test

00:23:58,260 --> 00:24:02,970
which is how much it can a single

00:23:59,850 --> 00:24:06,020
Prometheus it's it's coming we know it's

00:24:02,970 --> 00:24:08,820
important so we'll try to do this next

00:24:06,020 --> 00:24:14,289
all right thanks

00:24:08,820 --> 00:24:14,289
[Applause]

00:24:15,620 --> 00:24:17,680

YouTube URL: https://www.youtube.com/watch?v=9LuVvVddJjg


