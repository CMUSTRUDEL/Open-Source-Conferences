Title: PromCon 2018: Life of an Alert
Publication date: 2018-11-10
Playlist: PromCon 2018
Description: 
	Speaker: Stuart Nelson

Alerting is a key concept to remediating issues that arise in the systems we monitor. In order to alert effectively, it's helpful to understand the concepts available in Alertmanager and how they are actually executed within the code. In this talk, I'll give a brief, high-level description of the wondrous journey an alert takes, from its triggering in Prometheus to the email in your mailbox. Then, I'll break down in-depth how alerts are ingested, grouped, and processed, including high availability mode. At the end of this exciting trip you'll understand how your configuration affects Alertmanager, what an alerting pipeline is, and why you sometimes get two emails for the same alert.
Captions: 
	00:00:09,840 --> 00:00:16,030
hey everybody yeah as mentioned I'm

00:00:12,940 --> 00:00:18,340
Stewart Nelson I work at SoundCloud on

00:00:16,030 --> 00:00:20,740
the production engineering team where

00:00:18,340 --> 00:00:23,080
most of the time we focus on uptime

00:00:20,740 --> 00:00:26,430
availability and we also operate a lot

00:00:23,080 --> 00:00:30,029
of the infrastructure there so very

00:00:26,430 --> 00:00:33,010
briefly why does the alert manager exist

00:00:30,029 --> 00:00:35,230
so we have prometheus Prometheus is

00:00:33,010 --> 00:00:37,780
sending the alerts why can't

00:00:35,230 --> 00:00:41,170
Prometheus just integrate against all

00:00:37,780 --> 00:00:42,850
these notifiers or all these people at

00:00:41,170 --> 00:00:45,760
like pager duty that want to accept our

00:00:42,850 --> 00:00:48,699
alerts the reason is actually pretty

00:00:45,760 --> 00:00:51,399
simple if you run a Prometheus in H a

00:00:48,699 --> 00:00:53,199
mode which you should be doing how do

00:00:51,399 --> 00:00:55,109
you handle deduplication they would have

00:00:53,199 --> 00:00:57,489
to somehow coordinate with each other

00:00:55,109 --> 00:00:58,320
and then that would all get very very

00:00:57,489 --> 00:01:00,010
messy

00:00:58,320 --> 00:01:01,870
additionally there are a lot of core

00:01:00,010 --> 00:01:05,080
features which we'll talk about an alert

00:01:01,870 --> 00:01:07,090
manager like silencing or inhibition so

00:01:05,080 --> 00:01:09,460
between different unrelated Prometheus

00:01:07,090 --> 00:01:11,740
servers how would they handle inhibition

00:01:09,460 --> 00:01:14,080
so it's really convenient to have this

00:01:11,740 --> 00:01:19,350
alert manager thing be separate that

00:01:14,080 --> 00:01:19,350
manages all that for you all right so

00:01:19,650 --> 00:01:30,490
moving into it this is an overview of

00:01:23,070 --> 00:01:32,530
what happens to an alert so at a high

00:01:30,490 --> 00:01:34,480
level we start with the alert generator

00:01:32,530 --> 00:01:37,960
in this case it's going to be Prometheus

00:01:34,480 --> 00:01:40,660
the alert gets ingested into the alert

00:01:37,960 --> 00:01:43,330
manager from there it hops along through

00:01:40,660 --> 00:01:46,180
the alert provider it gets grouped and

00:01:43,330 --> 00:01:48,700
this grouping then moves to the

00:01:46,180 --> 00:01:51,070
notification pipeline at the end of the

00:01:48,700 --> 00:01:53,650
notification pipeline you receive your

00:01:51,070 --> 00:01:58,840
your page your slack message however

00:01:53,650 --> 00:02:01,390
it's configured but let's take a deeper

00:01:58,840 --> 00:02:03,940
dive into the alert manager and let's

00:02:01,390 --> 00:02:09,170
see what actually happens in the life of

00:02:03,940 --> 00:02:17,580
an alert so

00:02:09,170 --> 00:02:21,090
stage one so we have this alert

00:02:17,580 --> 00:02:24,210
generator prometheus multiple Prometheus

00:02:21,090 --> 00:02:27,030
servers all sending their alerts all the

00:02:24,210 --> 00:02:30,000
time to the alert manager why is it

00:02:27,030 --> 00:02:34,200
doing this basically the alert manager

00:02:30,000 --> 00:02:36,060
exists for deduplication if you have as

00:02:34,200 --> 00:02:38,670
mentioned all of these h.a servers

00:02:36,060 --> 00:02:40,440
sending all of their alerts each a

00:02:38,670 --> 00:02:43,770
Prometheus servers sending all of their

00:02:40,440 --> 00:02:45,530
alerts all the time you if you send them

00:02:43,770 --> 00:02:48,240
directly to some sort of integration

00:02:45,530 --> 00:02:49,830
such as page or duty that's gonna be a

00:02:48,240 --> 00:02:53,790
lot of alerts that's going to be a pager

00:02:49,830 --> 00:02:56,400
storm so the detector to do you what's

00:02:53,790 --> 00:02:57,990
happening here is they go into the alert

00:02:56,400 --> 00:03:00,060
manager the alert manager takes all of

00:02:57,990 --> 00:03:02,010
these potentially duplicate alerts and

00:03:00,060 --> 00:03:06,060
it merges them together so that you have

00:03:02,010 --> 00:03:11,100
just one example of by its labels and

00:03:06,060 --> 00:03:13,710
alert from there it moves into our alert

00:03:11,100 --> 00:03:15,420
moves into the alert provider which is

00:03:13,710 --> 00:03:17,550
what kind of keeps track of all this for

00:03:15,420 --> 00:03:25,440
you and moves your alert throughout the

00:03:17,550 --> 00:03:27,870
rest of the system moving on to grouping

00:03:25,440 --> 00:03:31,020
you can think of grouping as kind of the

00:03:27,870 --> 00:03:33,150
sorting hat for the alerts when the

00:03:31,020 --> 00:03:35,520
alerts come in it's important to know

00:03:33,150 --> 00:03:38,250
okay where is this alert going to go

00:03:35,520 --> 00:03:41,000
because why would you want to be paged

00:03:38,250 --> 00:03:46,590
if it's not really your responsibility

00:03:41,000 --> 00:03:48,810
further did you further the way that

00:03:46,590 --> 00:03:50,040
it's set up with the configuration we

00:03:48,810 --> 00:03:56,280
want to make sure that no alert

00:03:50,040 --> 00:03:59,130
disappears into a black hole so looking

00:03:56,280 --> 00:04:01,410
at this concept of matching routes on

00:03:59,130 --> 00:04:04,200
the lab I guess it'd be your right hand

00:04:01,410 --> 00:04:07,350
side you can see what an example of a

00:04:04,200 --> 00:04:09,570
config file so as mentioned we match

00:04:07,350 --> 00:04:12,660
these routes so that each alert has some

00:04:09,570 --> 00:04:15,030
place to end up in the actual

00:04:12,660 --> 00:04:18,120
description you can see match and match

00:04:15,030 --> 00:04:19,770
re match is a direct label match you can

00:04:18,120 --> 00:04:21,970
put as many labels as you want in there

00:04:19,770 --> 00:04:23,800
for the match and then match re

00:04:21,970 --> 00:04:27,700
ends up becoming an anchored regex for

00:04:23,800 --> 00:04:29,350
the match against a label as alerts move

00:04:27,700 --> 00:04:32,470
through this process which we'll take a

00:04:29,350 --> 00:04:35,770
look at in a moment they are sent to

00:04:32,470 --> 00:04:37,120
their most specific match and I cannot

00:04:35,770 --> 00:04:42,190
recommend this enough the route

00:04:37,120 --> 00:04:44,500
visualizer it is available here and it

00:04:42,190 --> 00:04:46,480
helps you to look at your ever-growing

00:04:44,500 --> 00:04:49,530
alert manager config to see what

00:04:46,480 --> 00:04:53,140
actually happens when the labels come in

00:04:49,530 --> 00:04:55,330
so the picture at the bottom here is an

00:04:53,140 --> 00:04:57,340
example of what you will see if you use

00:04:55,330 --> 00:05:00,190
that route visualizer on the previous

00:04:57,340 --> 00:05:03,220
website so let's say our alert comes in

00:05:00,190 --> 00:05:06,040
and it has as a label system my sequel

00:05:03,220 --> 00:05:08,440
well if you look on the right side that

00:05:06,040 --> 00:05:11,740
gets matched there and it goes to the

00:05:08,440 --> 00:05:13,360
initial red dot my sequel in general but

00:05:11,740 --> 00:05:16,150
then the process continues trying to

00:05:13,360 --> 00:05:19,390
find the most specific match in this

00:05:16,150 --> 00:05:22,330
case match REE looks for some cluster

00:05:19,390 --> 00:05:24,280
label that's either user or API this one

00:05:22,330 --> 00:05:26,650
the alert happens to have a cluster of

00:05:24,280 --> 00:05:30,640
user and so it ends up at the more

00:05:26,650 --> 00:05:34,150
specific point my sequel off if for some

00:05:30,640 --> 00:05:36,130
reason someone had and miss typed the

00:05:34,150 --> 00:05:37,780
label for the cluster it wouldn't make

00:05:36,130 --> 00:05:39,580
it to my sequel off but it would still

00:05:37,780 --> 00:05:44,560
end up at my sequel general someone

00:05:39,580 --> 00:05:47,830
would be notified of this alert all

00:05:44,560 --> 00:05:50,410
right after that is add to group add to

00:05:47,830 --> 00:05:53,260
group is sort of the second part of the

00:05:50,410 --> 00:05:56,040
sorting that happens this is where all

00:05:53,260 --> 00:05:59,110
of the alerts that are somehow similar

00:05:56,040 --> 00:06:01,330
based on what you define it to be get

00:05:59,110 --> 00:06:03,640
grouped together this is important

00:06:01,330 --> 00:06:05,530
because when you get an email when you

00:06:03,640 --> 00:06:07,060
get a page you want as many things

00:06:05,530 --> 00:06:09,010
grouped together as possible that are

00:06:07,060 --> 00:06:11,530
similar this helps to issue helps for

00:06:09,010 --> 00:06:14,110
issue remediation and trying to figure

00:06:11,530 --> 00:06:16,690
out what actually is going on versus

00:06:14,110 --> 00:06:19,770
getting 30 emails and you're not sure

00:06:16,690 --> 00:06:22,600
which ones are related to the other ones

00:06:19,770 --> 00:06:25,350
if we look at the snippet of the config

00:06:22,600 --> 00:06:28,270
there are three interesting values

00:06:25,350 --> 00:06:32,490
underneath group I there's group wait

00:06:28,270 --> 00:06:35,190
group interval and repeat interval so

00:06:32,490 --> 00:06:37,080
Oh group wait is the initial wait that

00:06:35,190 --> 00:06:38,310
happens when the alerts are first

00:06:37,080 --> 00:06:40,830
entering the system

00:06:38,310 --> 00:06:44,729
this means no alert is firing at all

00:06:40,830 --> 00:06:46,710
these are brand new alerts we do the

00:06:44,729 --> 00:06:48,690
initial group wait because we want to

00:06:46,710 --> 00:06:50,099
get as many of these first alerts as

00:06:48,690 --> 00:06:53,340
possible before sending out the

00:06:50,099 --> 00:06:55,830
notification it is less helpful to get

00:06:53,340 --> 00:06:58,050
one alert and then notice that oh

00:06:55,830 --> 00:07:00,240
there's also five other instances that

00:06:58,050 --> 00:07:02,880
are down so we give it that initial wait

00:07:00,240 --> 00:07:06,599
time first and that's configurable by

00:07:02,880 --> 00:07:08,789
you the group interval is the interval

00:07:06,599 --> 00:07:12,060
on which the alerts will continue to be

00:07:08,789 --> 00:07:14,009
evaluated so if new alerts come in if

00:07:12,060 --> 00:07:17,069
other alerts get resolved this will

00:07:14,009 --> 00:07:20,639
update you to a change in its status and

00:07:17,069 --> 00:07:23,520
finally the repeat interval so the group

00:07:20,639 --> 00:07:25,590
interval it evaluates every in this case

00:07:23,520 --> 00:07:28,349
30 minutes but it actually won't send

00:07:25,590 --> 00:07:30,419
any notifications if nothing changes the

00:07:28,349 --> 00:07:33,090
repeat interval is what says okay

00:07:30,419 --> 00:07:37,500
nothing has changed but just to remind

00:07:33,090 --> 00:07:39,270
you these alerts are still firing in

00:07:37,500 --> 00:07:41,909
general group weight is going to be

00:07:39,270 --> 00:07:45,150
fairly small group interval is going to

00:07:41,909 --> 00:07:47,940
be I use 30 minutes here but anything

00:07:45,150 --> 00:07:50,190
really on the kind of minute order and

00:07:47,940 --> 00:07:55,590
then repeat interval depends on what

00:07:50,190 --> 00:07:58,590
you're alerting on so from the grouping

00:07:55,590 --> 00:08:05,150
we move to the next and to me most

00:07:58,590 --> 00:08:10,199
exciting stage the notify pipeline so

00:08:05,150 --> 00:08:11,819
whoops the notify pipeline the notified

00:08:10,199 --> 00:08:14,460
pipeline is important because this is

00:08:11,819 --> 00:08:16,889
what actually processes filters and ends

00:08:14,460 --> 00:08:18,870
up taking these alerts sending them or

00:08:16,889 --> 00:08:21,030
changing them into notifications and

00:08:18,870 --> 00:08:24,509
then sending them to you so that you can

00:08:21,030 --> 00:08:26,250
do something about it this first flush

00:08:24,509 --> 00:08:30,990
portion that actually looks like a bunch

00:08:26,250 --> 00:08:32,430
of flames is the the execution of the

00:08:30,990 --> 00:08:37,110
group that gets created in the previous

00:08:32,430 --> 00:08:40,409
step moving through the filtering stages

00:08:37,110 --> 00:08:42,300
we start off with the inhibited check so

00:08:40,409 --> 00:08:44,339
inhibition is probably something that

00:08:42,300 --> 00:08:45,690
you've all heard of it was mentioned in

00:08:44,339 --> 00:08:49,650
the previous talk

00:08:45,690 --> 00:08:53,070
but why do you inhibit inhibiting the

00:08:49,650 --> 00:08:55,020
whole idea is to reduce noise so you can

00:08:53,070 --> 00:08:58,290
focus on more important alerts if you

00:08:55,020 --> 00:09:00,240
get such an alert that is super super

00:08:58,290 --> 00:09:03,870
important you don't necessarily want to

00:09:00,240 --> 00:09:05,430
hear about some sort of error rate

00:09:03,870 --> 00:09:10,140
warning that doesn't really matter when

00:09:05,430 --> 00:09:12,030
the networking is down so let's take a

00:09:10,140 --> 00:09:14,840
quick detour to see how inhibition

00:09:12,030 --> 00:09:14,840
actually works

00:09:16,070 --> 00:09:21,300
so besides why do we inhibit there's a

00:09:19,650 --> 00:09:23,760
question of what should we inhibit and

00:09:21,300 --> 00:09:26,490
that's a difficult question that depends

00:09:23,760 --> 00:09:28,320
a lot on your system how you want it to

00:09:26,490 --> 00:09:31,800
function and if anyone wants to chat

00:09:28,320 --> 00:09:33,840
about it afterwards I would love to if

00:09:31,800 --> 00:09:35,820
you look at an example of inhibit rules

00:09:33,840 --> 00:09:38,370
on the right this is something that I

00:09:35,820 --> 00:09:40,830
think is a relatively reasonable inhibit

00:09:38,370 --> 00:09:43,700
rule if an alert comes in and it says

00:09:40,830 --> 00:09:46,980
hey the top of rack router is down then

00:09:43,700 --> 00:09:49,800
every other alert that for the sake of

00:09:46,980 --> 00:09:52,110
this example unreachable means there's

00:09:49,800 --> 00:09:54,000
some sort of networking error we're not

00:09:52,110 --> 00:09:56,940
really interested in it because if the

00:09:54,000 --> 00:09:59,640
top of rack router is down obviously

00:09:56,940 --> 00:10:01,620
thinks I'm going to be reachable so

00:09:59,640 --> 00:10:04,670
let's take a look at what source match

00:10:01,620 --> 00:10:06,630
target match and equal actually means

00:10:04,670 --> 00:10:09,480
and just as an aside

00:10:06,630 --> 00:10:11,160
match match re they function the same as

00:10:09,480 --> 00:10:15,210
the match in the match re in the

00:10:11,160 --> 00:10:17,610
previous example so looking at the color

00:10:15,210 --> 00:10:19,860
coding we can see our example of an

00:10:17,610 --> 00:10:23,190
inhibiting alert the alert that comes in

00:10:19,860 --> 00:10:26,220
is it matches the source match if you

00:10:23,190 --> 00:10:28,260
look at the red color tor router down ok

00:10:26,220 --> 00:10:30,630
boom this one is going to be an

00:10:28,260 --> 00:10:32,910
inhibiting alert and then if we look at

00:10:30,630 --> 00:10:36,060
the inhibited alert the yellow one below

00:10:32,910 --> 00:10:39,330
you can see oh okay it's yellow it

00:10:36,060 --> 00:10:42,900
matches that unreachable check so okay

00:10:39,330 --> 00:10:45,660
this alert could be inhibited what

00:10:42,900 --> 00:10:48,630
happens is as these this alert is being

00:10:45,660 --> 00:10:50,970
processed it checks to see the alert in

00:10:48,630 --> 00:10:53,730
question being our yellow alert it gets

00:10:50,970 --> 00:10:56,339
checked to see if the data center so DC

00:10:53,730 --> 00:10:59,370
stands for and the rack match if they're

00:10:56,339 --> 00:11:03,210
equal between the two different alerts

00:10:59,370 --> 00:11:07,650
so in this case data center is mu C and

00:11:03,210 --> 00:11:10,590
RAC is a zero one so that's a match the

00:11:07,650 --> 00:11:13,050
target match is correct and then finally

00:11:10,590 --> 00:11:15,300
since it's the source match is there it

00:11:13,050 --> 00:11:18,740
already exists or the inhibiting Alert

00:11:15,300 --> 00:11:22,620
exists the actual check that happens is

00:11:18,740 --> 00:11:25,140
do do these labels match okay does it

00:11:22,620 --> 00:11:28,710
match the is the target match correct

00:11:25,140 --> 00:11:31,080
okay and then does it not match the

00:11:28,710 --> 00:11:34,980
source match this is an attempt to not

00:11:31,080 --> 00:11:37,680
inhibit yourself the thing is you could

00:11:34,980 --> 00:11:40,530
very easily inhibit in some sort of

00:11:37,680 --> 00:11:43,820
circular way your alerts so make sure

00:11:40,530 --> 00:11:43,820
you check what you're actually writing

00:11:43,940 --> 00:11:50,490
okay so that's the inhibition stage each

00:11:48,150 --> 00:11:52,710
time that this pipeline gets flushed or

00:11:50,490 --> 00:11:54,660
executed the first thing that happens is

00:11:52,710 --> 00:11:56,970
all of the alerts in this group could

00:11:54,660 --> 00:11:59,010
check to see okay are they inhibited if

00:11:56,970 --> 00:12:01,050
they're inhibited filter them out and

00:11:59,010 --> 00:12:04,770
then move on to the next stage the next

00:12:01,050 --> 00:12:06,840
stage being the silent stage silences

00:12:04,770 --> 00:12:07,620
are relatively simple in comparison to

00:12:06,840 --> 00:12:11,010
inhibition

00:12:07,620 --> 00:12:14,880
these are user-defined Lubell label

00:12:11,010 --> 00:12:17,100
pairs that during the comparison just as

00:12:14,880 --> 00:12:18,690
a direct match saying oh does this one

00:12:17,100 --> 00:12:21,080
cover this one yes

00:12:18,690 --> 00:12:23,490
okay filter it out does this silence

00:12:21,080 --> 00:12:27,990
affect this alert or this notification

00:12:23,490 --> 00:12:31,170
to be a bit more precise Oh

00:12:27,990 --> 00:12:32,790
silences are important because maybe

00:12:31,170 --> 00:12:35,220
something is happening at the moment

00:12:32,790 --> 00:12:36,690
there's some sort of maintenance going

00:12:35,220 --> 00:12:38,490
on you don't want to write an inhibition

00:12:36,690 --> 00:12:41,040
because an inhibition is actually

00:12:38,490 --> 00:12:43,650
defined in your config file a silence is

00:12:41,040 --> 00:12:46,260
defined at runtime silences are not

00:12:43,650 --> 00:12:48,060
meant to be a permanent solution for a

00:12:46,260 --> 00:12:51,270
firing Alert they're meant to be a

00:12:48,060 --> 00:12:52,770
short-term we know this is happening but

00:12:51,270 --> 00:12:55,230
we just don't need to hear about it

00:12:52,770 --> 00:12:58,170
right now because we're doing network

00:12:55,230 --> 00:13:02,460
maintenance something like that and

00:12:58,170 --> 00:13:05,850
another thing to note and in it so if

00:13:02,460 --> 00:13:08,310
you have an inhibited alert wait and

00:13:05,850 --> 00:13:11,820
inhibiting alert and you silence it it

00:13:08,310 --> 00:13:12,720
will continue to inhibit other alerts so

00:13:11,820 --> 00:13:14,879
that's

00:13:12,720 --> 00:13:16,290
kind of a tongue twister I'll get back

00:13:14,879 --> 00:13:21,149
to that later

00:13:16,290 --> 00:13:23,310
oh one more thing about silences these

00:13:21,149 --> 00:13:26,190
are shared between all of the notes

00:13:23,310 --> 00:13:27,720
there gossiped when you're in a chase as

00:13:26,190 --> 00:13:31,079
one of the advantages of using alert

00:13:27,720 --> 00:13:42,509
manager versus if all of this were to be

00:13:31,079 --> 00:13:48,360
put into Prometheus okay and then

00:13:42,509 --> 00:13:51,629
finally we get to the last part of the

00:13:48,360 --> 00:13:54,870
notify pipeline all of these now are

00:13:51,629 --> 00:13:56,639
going to be executed in parallel if your

00:13:54,870 --> 00:13:59,850
meta Don if you remember back to the

00:13:56,639 --> 00:14:02,250
routes each route leads to a single

00:13:59,850 --> 00:14:04,829
receiver and a receiver can have

00:14:02,250 --> 00:14:07,560
multiple integrations defined on it so

00:14:04,829 --> 00:14:09,509
if I am let's say the receiver my sequel

00:14:07,560 --> 00:14:11,129
general it might want okay let's send a

00:14:09,509 --> 00:14:14,279
slack message let's send a pager duty

00:14:11,129 --> 00:14:17,610
and let's let's send it to to slack

00:14:14,279 --> 00:14:19,529
channels why not these are all

00:14:17,610 --> 00:14:21,389
independent there's no reason to do them

00:14:19,529 --> 00:14:24,209
in serial so actually they get executed

00:14:21,389 --> 00:14:26,790
independently and then this moves into

00:14:24,209 --> 00:14:29,370
the after this split happens it moves

00:14:26,790 --> 00:14:33,240
into what's called the wait stage the

00:14:29,370 --> 00:14:35,850
wait stage is again for har not

00:14:33,240 --> 00:14:40,079
executing an hae mode this is just

00:14:35,850 --> 00:14:43,139
entirely skipped so the reason for this

00:14:40,079 --> 00:14:47,250
H a wait is to attempt to have an at

00:14:43,139 --> 00:14:49,680
least once alerting system alert manager

00:14:47,250 --> 00:14:52,550
wants to reduce as much noise as

00:14:49,680 --> 00:14:55,199
possible for you that's coming from

00:14:52,550 --> 00:14:56,550
notifications but it also wants to make

00:14:55,199 --> 00:14:59,519
sure you're getting at least one

00:14:56,550 --> 00:15:02,880
notification that should be sent so this

00:14:59,519 --> 00:15:05,519
wait stage is based on your alert

00:15:02,880 --> 00:15:08,279
managers position amongst its peers in

00:15:05,519 --> 00:15:10,139
the cluster it waits it's position times

00:15:08,279 --> 00:15:13,350
a certain amount of seconds by Z by

00:15:10,139 --> 00:15:16,949
default it's 15 seconds so the zeroeth

00:15:13,350 --> 00:15:20,550
alert manager is going to wait 0 times

00:15:16,949 --> 00:15:22,680
15 seconds so 0 and immediately start

00:15:20,550 --> 00:15:25,950
sending the first one will wait 1 times

00:15:22,680 --> 00:15:29,399
15 15 seconds and so on and so forth

00:15:25,950 --> 00:15:32,160
the idea is allow one of the alert

00:15:29,399 --> 00:15:35,279
managers to send a message a

00:15:32,160 --> 00:15:38,399
notification and then the later alert

00:15:35,279 --> 00:15:41,220
managers will not have to send it but

00:15:38,399 --> 00:15:42,180
how do they know not to send it that's

00:15:41,220 --> 00:15:44,070
actually the stage that comes

00:15:42,180 --> 00:15:47,790
immediately after this called the

00:15:44,070 --> 00:15:49,889
deduplication stage as mentioned it's

00:15:47,790 --> 00:15:52,529
trying to this deduplication stage is

00:15:49,889 --> 00:15:54,899
trying to prevent extra notifications or

00:15:52,529 --> 00:15:57,529
unnecessary notifications from going to

00:15:54,899 --> 00:16:00,329
your mailbox or to your slack channel

00:15:57,529 --> 00:16:02,399
what it does is at the start it checks

00:16:00,329 --> 00:16:04,350
its notification log the notification

00:16:02,399 --> 00:16:08,820
log is actually what gets gossiped

00:16:04,350 --> 00:16:11,010
between each of the alert managers so

00:16:08,820 --> 00:16:12,990
this stage starts your alert manager

00:16:11,010 --> 00:16:15,570
zero since it's the first one to go

00:16:12,990 --> 00:16:18,120
check see a notification log and says Oh

00:16:15,570 --> 00:16:20,370
none of these alerts have been have been

00:16:18,120 --> 00:16:22,050
notified upon so I'm just going to

00:16:20,370 --> 00:16:23,550
continue on through and send all these

00:16:22,050 --> 00:16:26,910
the next one

00:16:23,550 --> 00:16:28,470
15 seconds later will say oh okay I got

00:16:26,910 --> 00:16:31,050
a message from the first one saying

00:16:28,470 --> 00:16:32,880
these have been notified upon so I can

00:16:31,050 --> 00:16:35,910
just filter all these out and I'm done

00:16:32,880 --> 00:16:44,190
and the same for the the next one and

00:16:35,910 --> 00:16:47,040
the next one of the next one yeah so the

00:16:44,190 --> 00:16:50,279
one caveat to this deduplication stage

00:16:47,040 --> 00:16:52,560
is that if all of the alerts have

00:16:50,279 --> 00:16:54,779
already been alerted upon but that

00:16:52,560 --> 00:16:58,949
repeat interval has been surpassed this

00:16:54,779 --> 00:17:01,019
is a user-defined indication that okay I

00:16:58,949 --> 00:17:03,269
know this hasn't changed but I want to

00:17:01,019 --> 00:17:06,179
be reminded that it's still happening so

00:17:03,269 --> 00:17:09,059
in our example it was 90 minutes let's

00:17:06,179 --> 00:17:13,350
say after 90 minutes of this pipeline

00:17:09,059 --> 00:17:16,199
being executed every 30 minutes after

00:17:13,350 --> 00:17:18,120
the up at the 90th minute mark if

00:17:16,199 --> 00:17:20,130
nothing has changed it's going to say oh

00:17:18,120 --> 00:17:25,199
well let's remind them that this is

00:17:20,130 --> 00:17:27,600
still happening yeah and after this

00:17:25,199 --> 00:17:30,270
stage the deduplication stage we end up

00:17:27,600 --> 00:17:32,460
at send send is pretty straightforward

00:17:30,270 --> 00:17:35,460
you have a list of your notifications

00:17:32,460 --> 00:17:36,690
and they get sent out to whatever

00:17:35,460 --> 00:17:39,029
receiver they have

00:17:36,690 --> 00:17:41,610
to be or whatever integration they

00:17:39,029 --> 00:17:44,669
should be sent to this will happen on a

00:17:41,610 --> 00:17:48,059
repeat because things can fail on the

00:17:44,669 --> 00:17:50,309
internet and after X amount of times if

00:17:48,059 --> 00:17:52,049
it hasn't succeeded it will fail but

00:17:50,309 --> 00:17:55,769
generally it's pretty good about sending

00:17:52,049 --> 00:17:57,990
your notifications and then the final

00:17:55,769 --> 00:18:00,059
step after it has sent this notification

00:17:57,990 --> 00:18:02,399
after you've gotten your page the alert

00:18:00,059 --> 00:18:04,710
manager keeps working unbeknownst to you

00:18:02,399 --> 00:18:07,529
and it makes a record of what it's sent

00:18:04,710 --> 00:18:09,899
in the notification log or abbreviated

00:18:07,529 --> 00:18:14,009
an F log because it doesn't fit to say

00:18:09,899 --> 00:18:16,590
notification log on the picture so yeah

00:18:14,009 --> 00:18:19,200
this log is updated and then that is

00:18:16,590 --> 00:18:26,580
used in the prior step the deduplication

00:18:19,200 --> 00:18:29,460
stage as mentioned alright so this is

00:18:26,580 --> 00:18:32,009
the life of an alert comes in from a

00:18:29,460 --> 00:18:33,629
Prometheus it gets ingested it gets

00:18:32,009 --> 00:18:36,899
merged with all of its other similar

00:18:33,629 --> 00:18:39,210
labels then it gets sorted into a a

00:18:36,899 --> 00:18:42,870
route and then further on the route it

00:18:39,210 --> 00:18:46,019
gets grouped based on similar similar

00:18:42,870 --> 00:18:48,419
labels that you've defined then on timed

00:18:46,019 --> 00:18:51,240
intervals it gets evaluated and sent out

00:18:48,419 --> 00:18:53,850
and finally it ends up in your mailbox

00:18:51,240 --> 00:18:57,600
it ends up on your phone or in your

00:18:53,850 --> 00:18:58,910
slack channel thank you for joining me

00:18:57,600 --> 00:19:06,380
on the life of an alert

00:18:58,910 --> 00:19:06,380
[Applause]

00:19:08,959 --> 00:19:14,959
so Thank You Stuart are there any

00:19:11,039 --> 00:19:14,959
questions with your hand there we go

00:19:21,109 --> 00:19:26,519
hi can you talk about your

00:19:23,749 --> 00:19:29,729
infrastructure fornalik manager what you

00:19:26,519 --> 00:19:32,549
are using splitted data centers how many

00:19:29,729 --> 00:19:36,059
a lot managers you are using SoundCloud

00:19:32,549 --> 00:19:38,429
thank you at SoundCloud we have three

00:19:36,059 --> 00:19:40,950
alert managers they are co-located with

00:19:38,429 --> 00:19:43,409
prometheus servers just because an alert

00:19:40,950 --> 00:19:46,109
manager generally doesn't need an entire

00:19:43,409 --> 00:19:50,159
machine to itself and they're only in

00:19:46,109 --> 00:19:52,169
one data center we do have a Prometheus

00:19:50,159 --> 00:19:55,079
servers running in different data

00:19:52,169 --> 00:19:57,539
centers or in like AWS but they send

00:19:55,079 --> 00:20:01,339
their alerts also to to the alert

00:19:57,539 --> 00:20:01,339
managers running in our main data center

00:20:02,179 --> 00:20:12,919
next questions over there make me walk

00:20:04,859 --> 00:20:12,919
why don't you it's gonna be a long day

00:20:15,889 --> 00:20:23,849
hey so you mentioned a visualizer right

00:20:20,129 --> 00:20:26,609
and the elder said that at some point it

00:20:23,849 --> 00:20:28,320
was part of the alert manager package so

00:20:26,609 --> 00:20:31,289
you could use it on your own machine

00:20:28,320 --> 00:20:33,359
right do you plan to bring it back I

00:20:31,289 --> 00:20:36,479
think it's no longer in the package that

00:20:33,359 --> 00:20:40,619
was removed unfortunately in the UI

00:20:36,479 --> 00:20:43,049
rewrite which is awesome but even though

00:20:40,619 --> 00:20:46,109
there have been plans to add it back it

00:20:43,049 --> 00:20:54,359
hasn't happened yet but we would welcome

00:20:46,109 --> 00:20:57,690
pull requests the thing is that when you

00:20:54,359 --> 00:21:01,049
just put the whole list of emailing the

00:20:57,690 --> 00:21:03,149
holy mailing list on website on the

00:21:01,049 --> 00:21:07,289
Internet management doesn't take that

00:21:03,149 --> 00:21:10,889
lightly I mean you could still generate

00:21:07,289 --> 00:21:13,289
that but only put it in on prom on

00:21:10,889 --> 00:21:16,440
parameters that I owe and nobody likes

00:21:13,289 --> 00:21:16,950
that yeah I understand but it does just

00:21:16,440 --> 00:21:18,720
run in

00:21:16,950 --> 00:21:25,830
browser I guess you can't have to trust

00:21:18,720 --> 00:21:27,650
us on that thank you so you mentioned

00:21:25,830 --> 00:21:29,970
that you're running free alert managers

00:21:27,650 --> 00:21:33,150
that's sufficient in this case because

00:21:29,970 --> 00:21:35,310
it it doesn't use vac sauce or anything

00:21:33,150 --> 00:21:40,530
that it requires a majority to be

00:21:35,310 --> 00:21:42,600
available as in oh yeah so there is an

00:21:40,530 --> 00:21:46,310
excellent talk about a che alert manager

00:21:42,600 --> 00:21:49,800
that happened right here last year but

00:21:46,310 --> 00:21:53,310
in brief it's not a consensus protocol

00:21:49,800 --> 00:21:56,130
it's just a gossip just what members are

00:21:53,310 --> 00:21:59,040
present and then try to send a send a

00:21:56,130 --> 00:22:00,330
message there are cases where we had

00:21:59,040 --> 00:22:02,070
this happen earlier this year where our

00:22:00,330 --> 00:22:03,090
network disintegrated and all of the

00:22:02,070 --> 00:22:04,890
alert managers were sending

00:22:03,090 --> 00:22:06,360
independently which is exactly what you

00:22:04,890 --> 00:22:09,210
want to have happen you don't want to

00:22:06,360 --> 00:22:18,750
have some sort of waiting for consensus

00:22:09,210 --> 00:22:21,180
and it never never occurs do you meet a

00:22:18,750 --> 00:22:24,930
history of alert or and how you work is

00:22:21,180 --> 00:22:28,470
that we don't have a history of the

00:22:24,930 --> 00:22:30,540
alerts I've thought about maybe like

00:22:28,470 --> 00:22:33,330
sending them to a Kafka or something if

00:22:30,540 --> 00:22:34,560
people want to do analysis on that but

00:22:33,330 --> 00:22:36,390
the alert manager itself does not

00:22:34,560 --> 00:22:47,580
support any sort of long-term history of

00:22:36,390 --> 00:22:49,020
alerts or notifications hi I was

00:22:47,580 --> 00:22:50,760
wondering if you had beyond the

00:22:49,020 --> 00:22:52,920
visualization if you had any other ways

00:22:50,760 --> 00:22:54,030
of testing the routing and the

00:22:52,920 --> 00:23:00,240
inhibitions

00:22:54,030 --> 00:23:02,040
if the alerts unfortunately no I don't

00:23:00,240 --> 00:23:05,250
think I I don't have any other way

00:23:02,040 --> 00:23:07,470
unless someone else does okay and

00:23:05,250 --> 00:23:10,490
there's a quick question is how are you

00:23:07,470 --> 00:23:12,630
Oh what are you instrumenting on the

00:23:10,490 --> 00:23:16,140
manager is why are you seeing how many

00:23:12,630 --> 00:23:18,990
inhibitions are being triggered yeah so

00:23:16,140 --> 00:23:21,030
within the alert manager there is a I

00:23:18,990 --> 00:23:22,230
guess it would be a gauge of all the

00:23:21,030 --> 00:23:25,590
different states the alerts are in

00:23:22,230 --> 00:23:29,250
there's your normal saturation like

00:23:25,590 --> 00:23:32,179
memory usage CPU stuff like that

00:23:29,250 --> 00:23:34,169
there's also stuff about the gossip the

00:23:32,179 --> 00:23:36,779
member list just to see how many

00:23:34,169 --> 00:23:39,080
messages are being sent are their

00:23:36,779 --> 00:23:42,139
messages being queued that can't be sent

00:23:39,080 --> 00:23:47,190
there's a lot in there so give it a look

00:23:42,139 --> 00:23:55,529
yeah sorry I'm quite say no that's it

00:23:47,190 --> 00:23:58,889
thanks okay

00:23:55,529 --> 00:24:02,399
so there is - a message in the gift

00:23:58,889 --> 00:24:09,769
eater page that a lot manager AJ is in

00:24:02,399 --> 00:24:14,129
progress is there just checked oh yeah

00:24:09,769 --> 00:24:14,909
okay can we use it oh yeah you can

00:24:14,129 --> 00:24:23,100
totally use it

00:24:14,909 --> 00:24:26,639
it's a we've been using it for when did

00:24:23,100 --> 00:24:29,580
we upgrade the fifteen it's been a

00:24:26,639 --> 00:24:33,360
couple months it's been working fine so

00:24:29,580 --> 00:24:38,070
yeah I I would say use it I'm a bit

00:24:33,360 --> 00:24:40,620
biased though yeah hi you talked about

00:24:38,070 --> 00:24:43,769
what happens when an alert is triggered

00:24:40,620 --> 00:24:46,110
in India as manager it can also send

00:24:43,769 --> 00:24:48,690
notifications when the alert is resolved

00:24:46,110 --> 00:24:51,450
can you maybe say word about how that

00:24:48,690 --> 00:24:53,220
works like does it get notified by

00:24:51,450 --> 00:24:54,000
parameters that it's resolved does it

00:24:53,220 --> 00:24:57,330
wait some time

00:24:54,000 --> 00:24:59,460
yeah definitely so Prometheus sends when

00:24:57,330 --> 00:25:02,039
an alert is firing it continually sends

00:24:59,460 --> 00:25:03,929
the messages on the it's an interval

00:25:02,039 --> 00:25:05,429
evaluation interval it Center

00:25:03,929 --> 00:25:07,740
continually on the evaluation interval

00:25:05,429 --> 00:25:09,450
which is something on the order of I

00:25:07,740 --> 00:25:12,750
don't know half a minute depends on your

00:25:09,450 --> 00:25:15,629
Prometheus after that situation is

00:25:12,750 --> 00:25:17,159
resolved so whatever alert threshold

00:25:15,629 --> 00:25:19,620
you've defined in your Prometheus after

00:25:17,159 --> 00:25:21,629
that is no longer true it will continue

00:25:19,620 --> 00:25:25,320
to send the same alert but will it'll

00:25:21,629 --> 00:25:26,970
provide a it's been resolved flag in the

00:25:25,320 --> 00:25:30,090
in the alert that moves through the

00:25:26,970 --> 00:25:31,889
alert manager that gets merged with the

00:25:30,090 --> 00:25:34,139
other alert the other instances of the

00:25:31,889 --> 00:25:37,169
alert based on its on their labels and

00:25:34,139 --> 00:25:38,639
then if you've configured your alert

00:25:37,169 --> 00:25:41,279
manager to send out resolved messages

00:25:38,639 --> 00:25:42,809
that will be sent on the next evaluation

00:25:41,279 --> 00:25:45,600
in the

00:25:42,809 --> 00:25:46,830
was that the deduplication stage it

00:25:45,600 --> 00:25:49,679
checks to see if your alerts have

00:25:46,830 --> 00:25:51,480
changed at all and if an alert that was

00:25:49,679 --> 00:25:53,129
previously firing is now resolved and

00:25:51,480 --> 00:25:54,330
you want to be notified about that it'll

00:25:53,129 --> 00:26:00,419
continue through and send you that

00:25:54,330 --> 00:26:02,669
notification thank you hey thanks for

00:26:00,419 --> 00:26:05,960
the talk so I wanted to ask about like

00:26:02,669 --> 00:26:08,850
grouped alerts so imagine if I have like

00:26:05,960 --> 00:26:10,769
grouped alert which is like happening

00:26:08,850 --> 00:26:14,480
which is firing right now and like

00:26:10,769 --> 00:26:17,009
another alert comes in does like

00:26:14,480 --> 00:26:20,159
notification integration gets an update

00:26:17,009 --> 00:26:23,039
for like like another a large I into the

00:26:20,159 --> 00:26:25,470
group something like that and another

00:26:23,039 --> 00:26:28,080
part of the question is how what kind of

00:26:25,470 --> 00:26:30,480
templates do you write for grouped

00:26:28,080 --> 00:26:33,360
alerts do you include how many of alerts

00:26:30,480 --> 00:26:37,799
are firing what what like information do

00:26:33,360 --> 00:26:39,809
you put there so the first question when

00:26:37,799 --> 00:26:43,139
a new alert comes in that should be

00:26:39,809 --> 00:26:47,159
joining an already existing group that

00:26:43,139 --> 00:26:50,369
will join the group but okay so it

00:26:47,159 --> 00:26:51,779
depends when this is happening if the if

00:26:50,369 --> 00:26:54,749
that group has already been notified

00:26:51,779 --> 00:26:56,460
upon this new incoming alert will join

00:26:54,749 --> 00:26:59,909
the group and it will be notified about

00:26:56,460 --> 00:27:02,850
after the next group interval if it

00:26:59,909 --> 00:27:04,679
joins before the first execution or

00:27:02,850 --> 00:27:06,899
which would be before the group wait

00:27:04,679 --> 00:27:08,220
time it will join that group and then

00:27:06,899 --> 00:27:10,440
you'll receive a message about it

00:27:08,220 --> 00:27:13,230
so either way you'll receive a message

00:27:10,440 --> 00:27:14,820
but it depends if it's within a short

00:27:13,230 --> 00:27:17,639
amount of time or a slightly longer

00:27:14,820 --> 00:27:19,730
amount of time what was the second

00:27:17,639 --> 00:27:19,730
question

00:27:23,179 --> 00:27:27,720
I actually want to bother one of my

00:27:26,190 --> 00:27:32,039
fellow engineers to do a lightning talk

00:27:27,720 --> 00:27:35,340
about that we generally don't do the

00:27:32,039 --> 00:27:38,039
counts I believe we do just the like the

00:27:35,340 --> 00:27:40,169
labels and the alert name and then we

00:27:38,039 --> 00:27:43,110
include actually a link to the runbook

00:27:40,169 --> 00:27:44,669
we find that's more important because

00:27:43,110 --> 00:27:47,940
you can look at the actual source of the

00:27:44,669 --> 00:27:49,940
alert and see oh this many instances are

00:27:47,940 --> 00:27:53,899
firing with this alert or whatever it is

00:27:49,940 --> 00:27:56,100
but knowing how to remediate that I

00:27:53,899 --> 00:27:56,640
think generally we consider it more

00:27:56,100 --> 00:27:58,440
important

00:27:56,640 --> 00:28:04,350
knowing there's ten of these versus

00:27:58,440 --> 00:28:06,560
there's 15 of these that's not that was

00:28:04,350 --> 00:28:06,560
a lie

00:28:10,430 --> 00:28:20,100
Dewey I'm sorry oh okay so actually at

00:28:18,150 --> 00:28:22,230
SoundCloud with our current slack

00:28:20,100 --> 00:28:23,640
template we do list this is the number

00:28:22,230 --> 00:28:26,450
firing and this is the number resolved

00:28:23,640 --> 00:28:29,130
so I apologize for the misinformation

00:28:26,450 --> 00:28:31,290
okay thank you for your talk quick

00:28:29,130 --> 00:28:32,910
question regarding silences how are you

00:28:31,290 --> 00:28:34,920
operationally handling silence is to

00:28:32,910 --> 00:28:36,600
imply any sanity checks of any kind

00:28:34,920 --> 00:28:38,040
that's I don't know someone from the

00:28:36,600 --> 00:28:40,170
application team doesn't silence the

00:28:38,040 --> 00:28:41,460
network alerts or any kind of that and

00:28:40,170 --> 00:28:43,530
if so how do you do it

00:28:41,460 --> 00:28:46,680
we actually don't we're a very trusting

00:28:43,530 --> 00:28:49,140
company we hope that everyone has

00:28:46,680 --> 00:28:51,660
everyone else's best interests in mind

00:28:49,140 --> 00:28:54,140
we don't do any sort of check I believe

00:28:51,660 --> 00:28:56,790
there is an issue open for verifying

00:28:54,140 --> 00:28:59,460
some sort of header before applying a

00:28:56,790 --> 00:29:02,910
silence but as it is there is no sort of

00:28:59,460 --> 00:29:07,110
limitation no sort of yeah no sort of

00:29:02,910 --> 00:29:09,180
group separation authorization is

00:29:07,110 --> 00:29:12,840
handled outside of previous because

00:29:09,180 --> 00:29:25,170
that's that's a rabbit hole try for one

00:29:12,840 --> 00:29:28,470
more question I think hi do you intend

00:29:25,170 --> 00:29:30,120
to connect the acknowledgement system

00:29:28,470 --> 00:29:33,330
from the JIT to the alert manager at

00:29:30,120 --> 00:29:35,640
some point for instance you know

00:29:33,330 --> 00:29:39,180
silencing an alert we need to be never

00:29:35,640 --> 00:29:41,820
acknowledged in the mind yes when you

00:29:39,180 --> 00:29:45,570
snooze another in in pager duty for

00:29:41,820 --> 00:29:47,910
instance do you plan to allow a lot

00:29:45,570 --> 00:29:50,400
manager to be aware of that and declare

00:29:47,910 --> 00:29:53,940
some reason in our silence other for

00:29:50,400 --> 00:29:56,670
this particular a lot group I'm sorry I

00:29:53,940 --> 00:30:00,030
didn't understand the question when you

00:29:56,670 --> 00:30:01,590
use a pager duty you have alerts and you

00:30:00,030 --> 00:30:04,430
can snooze those mm-hmm

00:30:01,590 --> 00:30:08,190
when you snooze one alert you could

00:30:04,430 --> 00:30:09,340
imagine that you make a lot manager

00:30:08,190 --> 00:30:11,680
aware of the fact that

00:30:09,340 --> 00:30:13,690
been acknowledged and silenced it's for

00:30:11,680 --> 00:30:15,400
the same duration that would be

00:30:13,690 --> 00:30:17,140
something possible what you sound like a

00:30:15,400 --> 00:30:19,350
reverse integration from your duty bag

00:30:17,140 --> 00:30:23,530
exactly

00:30:19,350 --> 00:30:26,290
well that isn't possible right now and I

00:30:23,530 --> 00:30:29,260
don't I don't I guess I don't have any

00:30:26,290 --> 00:30:33,000
super strong opinion on it at first

00:30:29,260 --> 00:30:40,420
blush but the reverse integration I

00:30:33,000 --> 00:30:42,940
don't know you can write something to do

00:30:40,420 --> 00:30:44,290
- I didn't run externally yeah yeah you

00:30:42,940 --> 00:30:50,530
could integrate with some sort of web

00:30:44,290 --> 00:30:52,550
hook that allocated time so thank you

00:30:50,530 --> 00:30:56,010
very much Stuart

00:30:52,550 --> 00:30:56,010

YouTube URL: https://www.youtube.com/watch?v=PUdjca23Qa4


