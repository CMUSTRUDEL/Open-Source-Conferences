Title: PromCon Online 2020 - Lightning Talks Day 2
Publication date: 2020-07-23
Playlist: PromCon Online 2020
Description: 
	
Captions: 
	00:00:01,770 --> 00:00:04,940
[Music]

00:00:14,160 --> 00:00:17,199
so we're going to start off

00:00:15,360 --> 00:00:18,960
by the talk doing it the hard way

00:00:17,199 --> 00:00:19,279
improving observability from the bottom

00:00:18,960 --> 00:00:22,400
up

00:00:19,279 --> 00:00:23,840
by eric dielinski

00:00:22,400 --> 00:00:25,439
hey my name is eric i'm a software

00:00:23,840 --> 00:00:26,960
engineer at sauce labs and today i'm

00:00:25,439 --> 00:00:30,240
going to talk a little bit about how we

00:00:26,960 --> 00:00:32,719
improved our observability the hard way

00:00:30,240 --> 00:00:33,840
this is what our monitoring looked like

00:00:32,719 --> 00:00:35,840
a year and a half ago

00:00:33,840 --> 00:00:38,399
and no this is not during an outage it

00:00:35,840 --> 00:00:41,440
was just this unreliable

00:00:38,399 --> 00:00:43,280
we ended up having to once a day go in

00:00:41,440 --> 00:00:44,800
and restart all the services just to

00:00:43,280 --> 00:00:46,640
keep it alive and in the process we'd

00:00:44,800 --> 00:00:48,960
lose about six hours of data

00:00:46,640 --> 00:00:50,480
at the same time my team realized that

00:00:48,960 --> 00:00:51,440
we needed to double down on improving

00:00:50,480 --> 00:00:54,079
our observability

00:00:51,440 --> 00:00:55,760
we knew that some other teams had

00:00:54,079 --> 00:00:57,440
started using prometheus but we needed

00:00:55,760 --> 00:00:59,680
to use it at a scale

00:00:57,440 --> 00:01:00,960
that they just weren't at yet so we came

00:00:59,680 --> 00:01:02,480
up with a master plan

00:01:00,960 --> 00:01:04,159
we were going to build our own

00:01:02,480 --> 00:01:06,720
monitoring platform from scratch

00:01:04,159 --> 00:01:08,320
with no previous experience we were

00:01:06,720 --> 00:01:10,240
going to use this platform to improve

00:01:08,320 --> 00:01:13,439
our observability at scale

00:01:10,240 --> 00:01:15,200
and just by having this platform all of

00:01:13,439 --> 00:01:17,600
the other teams in the company

00:01:15,200 --> 00:01:19,360
are going to immediately start using it

00:01:17,600 --> 00:01:20,720
and love it

00:01:19,360 --> 00:01:23,040
obviously this is a little bit

00:01:20,720 --> 00:01:26,159
short-sighted but

00:01:23,040 --> 00:01:28,799
it put us on a road of learning

00:01:26,159 --> 00:01:30,079
some new things and i learned four main

00:01:28,799 --> 00:01:31,119
lessons out of this that i'm going to

00:01:30,079 --> 00:01:33,439
talk about today

00:01:31,119 --> 00:01:34,799
the first of which is make it worth it

00:01:33,439 --> 00:01:37,439
so part of the premise

00:01:34,799 --> 00:01:38,320
is that we need to make this new

00:01:37,439 --> 00:01:40,240
platform

00:01:38,320 --> 00:01:42,000
better than anything anybody else is

00:01:40,240 --> 00:01:44,560
using within the company

00:01:42,000 --> 00:01:45,680
um so that really boils down to a bunch

00:01:44,560 --> 00:01:47,840
of different features

00:01:45,680 --> 00:01:49,360
things like having aha prometheus

00:01:47,840 --> 00:01:50,640
deployments decentralized scraper and

00:01:49,360 --> 00:01:52,399
rule configuration

00:01:50,640 --> 00:01:53,759
having prometheus be horizontally

00:01:52,399 --> 00:01:55,920
scalable but with a single query

00:01:53,759 --> 00:01:58,240
endpoint and having long-term storage

00:01:55,920 --> 00:01:59,439
this basically boils down to using

00:01:58,240 --> 00:02:02,880
prometheus operator

00:01:59,439 --> 00:02:04,560
and thanos or cortex we use thanos

00:02:02,880 --> 00:02:06,159
but there were also some features that

00:02:04,560 --> 00:02:07,439
we just weren't using before in our

00:02:06,159 --> 00:02:09,679
existing stacks so

00:02:07,439 --> 00:02:10,800
having a single sign-on for grifana

00:02:09,679 --> 00:02:14,000
upgrading our

00:02:10,800 --> 00:02:15,520
slack notification templates and uh

00:02:14,000 --> 00:02:17,599
being able to have alert driven tickets

00:02:15,520 --> 00:02:18,959
and chat annotations

00:02:17,599 --> 00:02:22,319
have been really useful especially

00:02:18,959 --> 00:02:24,959
recently uh to improve our workflow

00:02:22,319 --> 00:02:26,480
on top of features you also have to

00:02:24,959 --> 00:02:28,480
lower the barriers to entry

00:02:26,480 --> 00:02:29,680
and this really came up when we were

00:02:28,480 --> 00:02:32,959
talking about how to scale

00:02:29,680 --> 00:02:34,640
our platform we wanted each team to have

00:02:32,959 --> 00:02:36,239
control of their own prometheus instance

00:02:34,640 --> 00:02:37,280
so we were going to shard a prometheus

00:02:36,239 --> 00:02:39,519
instances by

00:02:37,280 --> 00:02:41,040
owner and that introduces a new problem

00:02:39,519 --> 00:02:43,040
in that you have to

00:02:41,040 --> 00:02:44,319
teach a team how to run their own

00:02:43,040 --> 00:02:45,519
prometheus instance

00:02:44,319 --> 00:02:48,239
and how to deploy it and how to

00:02:45,519 --> 00:02:49,120
configure it luckily we came over that

00:02:48,239 --> 00:02:52,800
problem

00:02:49,120 --> 00:02:55,760
using gitlab pipelines and automation

00:02:52,800 --> 00:02:57,680
so in our deployment we have a two stage

00:02:55,760 --> 00:03:00,239
two repo pipeline

00:02:57,680 --> 00:03:01,120
in the upstream repo you define all your

00:03:00,239 --> 00:03:03,840
configuration

00:03:01,120 --> 00:03:05,920
for a particular prometheus instance and

00:03:03,840 --> 00:03:07,360
in the downstream pipeline we have

00:03:05,920 --> 00:03:09,360
a common configuration for each

00:03:07,360 --> 00:03:11,760
environment uh the result

00:03:09,360 --> 00:03:13,280
is that it's really really simple for a

00:03:11,760 --> 00:03:14,080
team to spin up their own prometheus

00:03:13,280 --> 00:03:17,360
instance

00:03:14,080 --> 00:03:20,080
all the configuration that they need

00:03:17,360 --> 00:03:21,840
is shown on the right side of the screen

00:03:20,080 --> 00:03:24,480
and through the magic of helm

00:03:21,840 --> 00:03:25,760
we overlay the upstream configuration on

00:03:24,480 --> 00:03:27,040
the downstream configuration before

00:03:25,760 --> 00:03:30,080
deploying it

00:03:27,040 --> 00:03:32,400
the next lesson is implementation

00:03:30,080 --> 00:03:33,280
over standardization we can leverage

00:03:32,400 --> 00:03:35,120
that pipeline

00:03:33,280 --> 00:03:37,040
to introduce common configuration and

00:03:35,120 --> 00:03:37,599
make sure that teams are following the

00:03:37,040 --> 00:03:40,959
standard

00:03:37,599 --> 00:03:44,080
that we've set out but we don't

00:03:40,959 --> 00:03:46,080
have to police teams into following the

00:03:44,080 --> 00:03:47,040
standard the standard is built into the

00:03:46,080 --> 00:03:48,799
implementation

00:03:47,040 --> 00:03:51,040
of the permeate hips deployment so

00:03:48,799 --> 00:03:52,799
things like alerting endpoints and

00:03:51,040 --> 00:03:54,480
and the prometheus version and thanos

00:03:52,799 --> 00:03:56,000
sidecar config

00:03:54,480 --> 00:03:57,680
as well as external labels and

00:03:56,000 --> 00:03:59,200
environment specific configuration

00:03:57,680 --> 00:04:01,200
are all configured in the downstream

00:03:59,200 --> 00:04:03,360
pipeline and

00:04:01,200 --> 00:04:04,319
by having the helm values overlay on top

00:04:03,360 --> 00:04:05,920
of those

00:04:04,319 --> 00:04:07,360
we make sure the teams are following the

00:04:05,920 --> 00:04:09,040
standard

00:04:07,360 --> 00:04:10,720
while still allowing them the freedom

00:04:09,040 --> 00:04:12,720
that they need in configuring their own

00:04:10,720 --> 00:04:15,040
prometheus instances

00:04:12,720 --> 00:04:15,840
and the last lesson is that sharing is

00:04:15,040 --> 00:04:18,000
caring

00:04:15,840 --> 00:04:19,199
one of the core shortfalls of our

00:04:18,000 --> 00:04:20,880
initial plan

00:04:19,199 --> 00:04:22,000
was that we were just going to build

00:04:20,880 --> 00:04:23,759
this thing and everybody was going to

00:04:22,000 --> 00:04:25,680
come

00:04:23,759 --> 00:04:27,199
we tried that for a while and it didn't

00:04:25,680 --> 00:04:29,120
really work out well

00:04:27,199 --> 00:04:31,120
we didn't end up improving our own

00:04:29,120 --> 00:04:34,080
observability or the observability of

00:04:31,120 --> 00:04:37,040
other teams in the process

00:04:34,080 --> 00:04:38,160
so really simple things like having a q

00:04:37,040 --> 00:04:40,320
and a slack channel

00:04:38,160 --> 00:04:42,240
where people can ask questions about how

00:04:40,320 --> 00:04:44,160
to improve their own observability

00:04:42,240 --> 00:04:45,440
or good documentation so that when you

00:04:44,160 --> 00:04:47,600
do

00:04:45,440 --> 00:04:48,960
get asked questions that you can

00:04:47,600 --> 00:04:51,040
reference documentation and don't have

00:04:48,960 --> 00:04:53,360
to repeat yourself every time

00:04:51,040 --> 00:04:54,400
i also like to tail team slack channels

00:04:53,360 --> 00:04:56,479
and

00:04:54,400 --> 00:04:57,919
inject myself into conversations where i

00:04:56,479 --> 00:05:00,000
think there's an opportunity

00:04:57,919 --> 00:05:01,199
that the team can improve their

00:05:00,000 --> 00:05:03,440
observability

00:05:01,199 --> 00:05:04,479
uh and the running joke is there's an

00:05:03,440 --> 00:05:06,639
exporter for that

00:05:04,479 --> 00:05:08,080
but there's also a lot of really good

00:05:06,639 --> 00:05:11,919
content out there on the web

00:05:08,080 --> 00:05:14,000
uh from prom con from grafanacon kubecon

00:05:11,919 --> 00:05:15,360
as well as a bunch of blog posts that

00:05:14,000 --> 00:05:17,759
are really useful uh

00:05:15,360 --> 00:05:18,960
when teams are learning to improve their

00:05:17,759 --> 00:05:22,080
observability

00:05:18,960 --> 00:05:24,160
and of course demos uh demos allow us to

00:05:22,080 --> 00:05:25,919
share the cool things that we're doing

00:05:24,160 --> 00:05:28,560
and that can help inspire teams to

00:05:25,919 --> 00:05:31,039
improve their own observability

00:05:28,560 --> 00:05:32,880
so in summary make it worth it lower

00:05:31,039 --> 00:05:34,080
barriers to entry

00:05:32,880 --> 00:05:36,639
favor implementation over

00:05:34,080 --> 00:05:38,639
standardization and of course

00:05:36,639 --> 00:05:40,320
sharing is caring thanks so much have a

00:05:38,639 --> 00:05:44,720
great con

00:05:40,320 --> 00:05:47,680
okay thank you so the next talk is from

00:05:44,720 --> 00:05:48,160
kim and it's on conceptual architecture

00:05:47,680 --> 00:05:50,840
for

00:05:48,160 --> 00:05:53,199
tracking and rollback releases based on

00:05:50,840 --> 00:05:56,720
metrics

00:05:53,199 --> 00:05:57,759
hi my name is gino the topic of this

00:05:56,720 --> 00:06:01,360
writing talk

00:05:57,759 --> 00:06:04,800
is to introduce metric ops concept

00:06:01,360 --> 00:06:06,000
architecture with the deployment and

00:06:04,800 --> 00:06:10,400
load back based on

00:06:06,000 --> 00:06:11,280
metrics i joined domnex cloud in this

00:06:10,400 --> 00:06:13,919
year

00:06:11,280 --> 00:06:15,680
i'm currently in charge of product owner

00:06:13,919 --> 00:06:18,960
called xclipper

00:06:15,680 --> 00:06:21,440
and xclip open source i like to learn

00:06:18,960 --> 00:06:26,160
all kinds of things related to

00:06:21,440 --> 00:06:29,039
cloud native platform and ecosystem

00:06:26,160 --> 00:06:30,000
first i'm going to talk about today is

00:06:29,039 --> 00:06:34,319
the githubs

00:06:30,000 --> 00:06:35,520
and the slo next i'm going to explain

00:06:34,319 --> 00:06:38,479
metric of

00:06:35,520 --> 00:06:39,440
cicd architecture that you are not

00:06:38,479 --> 00:06:43,440
familiar

00:06:39,440 --> 00:06:47,199
with metricobs but you can think of

00:06:43,440 --> 00:06:50,479
as a concept architecture

00:06:47,199 --> 00:06:50,479
simply today

00:06:51,680 --> 00:06:56,160
kidops is though is a way to do

00:06:54,160 --> 00:06:59,759
kubernetes cluster management

00:06:56,160 --> 00:07:03,680
and application delivery deployment

00:06:59,759 --> 00:07:07,280
in a single way from a single source

00:07:03,680 --> 00:07:10,400
as also known as ssot

00:07:07,280 --> 00:07:13,599
a key part of github is the idea of

00:07:10,400 --> 00:07:14,840
environment as code describing your

00:07:13,599 --> 00:07:18,319
deployment

00:07:14,840 --> 00:07:21,680
declaratively using yaml file store

00:07:18,319 --> 00:07:25,440
in a get repository automated

00:07:21,680 --> 00:07:27,840
delivery pipeline for dji to system

00:07:25,440 --> 00:07:27,840
state

00:07:28,479 --> 00:07:36,000
as you know slows can

00:07:31,759 --> 00:07:39,280
give you a concise and low noise signal

00:07:36,000 --> 00:07:41,280
as to the overall heart of your service

00:07:39,280 --> 00:07:44,720
or system

00:07:41,280 --> 00:07:47,919
slo must be a accreditedly

00:07:44,720 --> 00:07:53,039
measured and displayed using a

00:07:47,919 --> 00:07:56,879
monitoring system such as parameters

00:07:53,039 --> 00:07:59,520
typically applications are deployed

00:07:56,879 --> 00:08:00,639
declaratively in the following kit of

00:07:59,520 --> 00:08:04,960
style

00:08:00,639 --> 00:08:08,319
first we deploy your flask application

00:08:04,960 --> 00:08:10,960
and monitor it with an existing defined

00:08:08,319 --> 00:08:10,960
allotted loop

00:08:11,199 --> 00:08:17,840
id for a new version of the flask

00:08:14,240 --> 00:08:22,000
application but internet server error is

00:08:17,840 --> 00:08:25,440
detected and firing

00:08:22,000 --> 00:08:28,639
yeah and send the notification

00:08:25,440 --> 00:08:31,840
so office manager in charge of

00:08:28,639 --> 00:08:34,959
try to roll back on his home or

00:08:31,840 --> 00:08:35,599
go back of peace so obvious major role

00:08:34,959 --> 00:08:38,959
back

00:08:35,599 --> 00:08:43,279
to previous version yeah

00:08:38,959 --> 00:08:46,480
this scenario is a common scenario

00:08:43,279 --> 00:08:50,080
next scenario i call

00:08:46,480 --> 00:08:52,880
metric ops we are going to deploy

00:08:50,080 --> 00:08:54,560
uh same application to the kubernetes

00:08:52,880 --> 00:08:58,320
cluster but

00:08:54,560 --> 00:09:01,839
we are going to have a web proof

00:08:58,320 --> 00:09:05,279
of side cast for injection

00:09:01,839 --> 00:09:08,320
when the application is deployed a set

00:09:05,279 --> 00:09:11,360
of apps called of pipeline

00:09:08,320 --> 00:09:14,800
is prepared in advanced and

00:09:11,360 --> 00:09:19,519
to monitor we create rules through

00:09:14,800 --> 00:09:22,800
from jan or from cat that io

00:09:19,519 --> 00:09:26,720
yeah we are building a solution is

00:09:22,800 --> 00:09:30,000
expert herb exporter catalog is to

00:09:26,720 --> 00:09:32,399
add a lot load at the parameters

00:09:30,000 --> 00:09:32,399
instance

00:09:34,080 --> 00:09:38,040
when the application is deployed the

00:09:37,040 --> 00:09:41,200
side car is

00:09:38,040 --> 00:09:45,040
injected and the site call

00:09:41,200 --> 00:09:48,560
api to store

00:09:45,040 --> 00:09:51,600
image tag time stamp label

00:09:48,560 --> 00:09:52,880
a lot low information on the metric of

00:09:51,600 --> 00:09:56,480
spike flying

00:09:52,880 --> 00:10:00,080
then when application version

00:09:56,480 --> 00:10:03,440
is updated the relate metric of

00:10:00,080 --> 00:10:07,279
pipeline information will be update

00:10:03,440 --> 00:10:11,040
yeah image version is uh 1.1

00:10:07,279 --> 00:10:14,240
yeah however if 500 internals of

00:10:11,040 --> 00:10:18,480
error occur in the same way

00:10:14,240 --> 00:10:22,560
the controller check uh

00:10:18,480 --> 00:10:26,560
the firing state and the uh notification

00:10:22,560 --> 00:10:30,320
uh there request uh

00:10:26,560 --> 00:10:33,360
roll back uh command uh control

00:10:30,320 --> 00:10:36,360
uh load back to cube api

00:10:33,360 --> 00:10:39,839
the application go back with the

00:10:36,360 --> 00:10:39,839
existing version

00:10:42,160 --> 00:10:48,560
battery box can be not a nice idea but

00:10:46,240 --> 00:10:51,600
through simple idea

00:10:48,560 --> 00:10:55,120
i hope the people who say

00:10:51,600 --> 00:10:58,240
this today and our customer

00:10:55,120 --> 00:11:00,160
we may get the value thank you for

00:10:58,240 --> 00:11:03,279
listening to my presentation

00:11:00,160 --> 00:11:04,560
so far if you have any question feel

00:11:03,279 --> 00:11:07,680
free

00:11:04,560 --> 00:11:11,440
to contact me and question below channel

00:11:07,680 --> 00:11:12,000
thank you so our third lighting talk

00:11:11,440 --> 00:11:15,120
today

00:11:12,000 --> 00:11:16,959
is from john whitten about aws private

00:11:15,120 --> 00:11:20,320
link for easier multi-account

00:11:16,959 --> 00:11:22,240
monitoring my name is john winton and

00:11:20,320 --> 00:11:24,160
i'm a devops engineer at button

00:11:22,240 --> 00:11:25,600
a mobile e-commerce company based in new

00:11:24,160 --> 00:11:27,920
york today

00:11:25,600 --> 00:11:29,279
i'm talking about an aws networking tool

00:11:27,920 --> 00:11:31,200
called private link

00:11:29,279 --> 00:11:32,959
this is going to be quick and we'll use

00:11:31,200 --> 00:11:34,240
a lot of aws terminology

00:11:32,959 --> 00:11:35,760
so if you're not familiar with any of

00:11:34,240 --> 00:11:37,040
these tools check out the docs on the

00:11:35,760 --> 00:11:39,760
aws website

00:11:37,040 --> 00:11:39,760
let's get started

00:11:40,480 --> 00:11:44,079
let's say you have a single account

00:11:42,160 --> 00:11:45,600
running some set of applications

00:11:44,079 --> 00:11:47,120
and prometheus is monitoring those

00:11:45,600 --> 00:11:49,680
applications

00:11:47,120 --> 00:11:51,680
a vpc stands for a virtual private cloud

00:11:49,680 --> 00:11:53,040
and it's just your corner of the aws

00:11:51,680 --> 00:11:56,000
cloud where you can launch

00:11:53,040 --> 00:11:57,360
your compute resources it's simple now

00:11:56,000 --> 00:12:00,639
but as time goes on

00:11:57,360 --> 00:12:01,360
complexity increases say your data team

00:12:00,639 --> 00:12:02,560
comes to you

00:12:01,360 --> 00:12:04,880
and says they want to start running

00:12:02,560 --> 00:12:06,399
their own services in their own vpc for

00:12:04,880 --> 00:12:09,360
some network isolation

00:12:06,399 --> 00:12:10,240
great they also need to monitor their

00:12:09,360 --> 00:12:12,240
services

00:12:10,240 --> 00:12:13,519
so you follow best practices and drop a

00:12:12,240 --> 00:12:16,959
prometheus instance

00:12:13,519 --> 00:12:18,560
in their new data vpc but you realize

00:12:16,959 --> 00:12:20,160
you should probably take advantage of

00:12:18,560 --> 00:12:21,680
the alert manager you already have

00:12:20,160 --> 00:12:23,360
running in your core vpc

00:12:21,680 --> 00:12:26,240
since it has all your alerting and

00:12:23,360 --> 00:12:26,240
inhibition rules

00:12:26,399 --> 00:12:32,000
so you cure your vpcs peering just

00:12:29,920 --> 00:12:35,839
allows network connectivity across a

00:12:32,000 --> 00:12:38,959
certain ip range that you control

00:12:35,839 --> 00:12:40,079
but we get even more complex your

00:12:38,959 --> 00:12:41,600
environment matures

00:12:40,079 --> 00:12:43,519
and you start to realize it would be

00:12:41,600 --> 00:12:45,920
much easier to control access

00:12:43,519 --> 00:12:47,760
if you could use multiple accounts so

00:12:45,920 --> 00:12:51,040
you spin up another account

00:12:47,760 --> 00:12:52,639
and now you have an aws organization

00:12:51,040 --> 00:12:55,680
you still need to get alerts from your

00:12:52,639 --> 00:12:57,600
new account to your old alert manager

00:12:55,680 --> 00:12:59,040
so what do you do i made this slide a

00:12:57,600 --> 00:13:00,480
little more obtuse than it needs to be

00:12:59,040 --> 00:13:02,639
to illustrate a point

00:13:00,480 --> 00:13:04,000
we can definitely peer the tools vpc

00:13:02,639 --> 00:13:05,680
with the core vpc

00:13:04,000 --> 00:13:07,120
and route alerts to our original alert

00:13:05,680 --> 00:13:08,880
manager and

00:13:07,120 --> 00:13:11,279
this is a common network topology

00:13:08,880 --> 00:13:11,839
pattern but i want to take this time to

00:13:11,279 --> 00:13:16,320
discuss

00:13:11,839 --> 00:13:18,160
another option private link

00:13:16,320 --> 00:13:20,240
if you've heard of vpc endpoints you're

00:13:18,160 --> 00:13:22,720
kind of familiar with private link

00:13:20,240 --> 00:13:24,000
vpc endpoints enable users to connect to

00:13:22,720 --> 00:13:27,120
aws services

00:13:24,000 --> 00:13:29,360
like s3 that are outside of a vpc

00:13:27,120 --> 00:13:30,959
through a private connection or a

00:13:29,360 --> 00:13:33,120
private link

00:13:30,959 --> 00:13:35,680
now normally if your servers and your

00:13:33,120 --> 00:13:37,440
vpc try and connect to s3

00:13:35,680 --> 00:13:38,880
they'll make a request that goes out to

00:13:37,440 --> 00:13:42,480
the public internet and then

00:13:38,880 --> 00:13:44,880
back into aws in order to find s3

00:13:42,480 --> 00:13:47,519
a vpc endpoint provides direct

00:13:44,880 --> 00:13:50,320
connectivity to the s3 service

00:13:47,519 --> 00:13:51,760
and it stays entirely within the aws

00:13:50,320 --> 00:13:55,440
network

00:13:51,760 --> 00:13:56,880
now here's the thing private link lets

00:13:55,440 --> 00:13:59,920
you do the same thing

00:13:56,880 --> 00:14:02,320
but with your services

00:13:59,920 --> 00:14:04,639
so why is this better private link is a

00:14:02,320 --> 00:14:05,839
direct line to a load balancer in front

00:14:04,639 --> 00:14:07,920
of your service

00:14:05,839 --> 00:14:10,079
and you can authorize any account to

00:14:07,920 --> 00:14:12,079
connect the load balancer

00:14:10,079 --> 00:14:13,920
these connections happen entirely within

00:14:12,079 --> 00:14:15,680
the aws network

00:14:13,920 --> 00:14:17,920
and since it's a direct connection to a

00:14:15,680 --> 00:14:20,399
load balancer you don't need to peer

00:14:17,920 --> 00:14:21,760
vpcs or maintain blocks of ips for

00:14:20,399 --> 00:14:23,279
authorized traffic

00:14:21,760 --> 00:14:25,279
all you have to do is provision a

00:14:23,279 --> 00:14:26,800
network load balancer and you're good to

00:14:25,279 --> 00:14:28,639
go

00:14:26,800 --> 00:14:30,639
looking at the diagram on the right i

00:14:28,639 --> 00:14:32,160
added some more complexity to the mix

00:14:30,639 --> 00:14:34,240
since we can cross account boundaries

00:14:32,160 --> 00:14:36,320
with private link i moved alert manager

00:14:34,240 --> 00:14:37,279
into its own account and connected the

00:14:36,320 --> 00:14:40,320
new account

00:14:37,279 --> 00:14:42,320
to the private link interface endpoint

00:14:40,320 --> 00:14:44,959
by adding private link to those other

00:14:42,320 --> 00:14:46,560
vpcs and leaning into account separation

00:14:44,959 --> 00:14:48,399
we're able to create one centralized

00:14:46,560 --> 00:14:50,240
plane for alerting in our organization

00:14:48,399 --> 00:14:51,519
while keeping prometheus local to each

00:14:50,240 --> 00:14:53,360
vpc

00:14:51,519 --> 00:14:55,920
we can even take this pattern further to

00:14:53,360 --> 00:14:58,000
other types of observability

00:14:55,920 --> 00:15:00,240
at button we've centralized our alerting

00:14:58,000 --> 00:15:01,920
plane along with our log aggregation

00:15:00,240 --> 00:15:03,920
in this way all of our application

00:15:01,920 --> 00:15:04,560
monitoring can be aggregated in a single

00:15:03,920 --> 00:15:07,519
place

00:15:04,560 --> 00:15:09,199
which makes maintenance much easier one

00:15:07,519 --> 00:15:11,199
thing to note here is that you shouldn't

00:15:09,199 --> 00:15:12,000
run alert manager behind a load balancer

00:15:11,199 --> 00:15:13,760
since prometheus

00:15:12,000 --> 00:15:15,680
needs to send an alert to all alert

00:15:13,760 --> 00:15:17,839
managers in the cluster

00:15:15,680 --> 00:15:18,959
if we go the docs when you create a

00:15:17,839 --> 00:15:20,320
private link endpoint

00:15:18,959 --> 00:15:22,399
a service must specify which

00:15:20,320 --> 00:15:24,880
availability zones it will run in

00:15:22,399 --> 00:15:26,320
when you connect your account say the

00:15:24,880 --> 00:15:27,120
tools account to the private link

00:15:26,320 --> 00:15:29,120
service

00:15:27,120 --> 00:15:30,399
you get a dns entry for each

00:15:29,120 --> 00:15:33,519
availability zone

00:15:30,399 --> 00:15:35,519
the services is running in and yes

00:15:33,519 --> 00:15:37,199
you can assign your own private dns

00:15:35,519 --> 00:15:38,079
entry to make it a lot easier to reason

00:15:37,199 --> 00:15:41,199
about

00:15:38,079 --> 00:15:42,240
but this gives you direct connection to

00:15:41,199 --> 00:15:45,680
a single instance

00:15:42,240 --> 00:15:47,759
running in each availability zone

00:15:45,680 --> 00:15:48,720
and finally the only bit of code that

00:15:47,759 --> 00:15:50,639
i'll show

00:15:48,720 --> 00:15:52,399
button is a terraforms shop so i've

00:15:50,639 --> 00:15:54,320
included the resource declaration for a

00:15:52,399 --> 00:15:55,680
private link and point service

00:15:54,320 --> 00:15:57,759
as long as you have a network load

00:15:55,680 --> 00:15:59,360
balancer provisioned you can quickly

00:15:57,759 --> 00:16:00,320
turn it into a private link endpoint

00:15:59,360 --> 00:16:02,079
service

00:16:00,320 --> 00:16:03,519
and pick which accounts you want to

00:16:02,079 --> 00:16:04,880
connect well

00:16:03,519 --> 00:16:06,480
thanks for hanging out as we ran through

00:16:04,880 --> 00:16:09,839
private link hope you'll have a great

00:16:06,480 --> 00:16:09,839
rest of the day

00:16:10,160 --> 00:16:23,519
okay our final talk then today is by

00:16:13,519 --> 00:16:25,519
ravi hari about prometheus for remedy

00:16:23,519 --> 00:16:26,639
hi i am ravi hari staff software

00:16:25,519 --> 00:16:27,920
engineer at interior

00:16:26,639 --> 00:16:31,120
today we are going to talk about

00:16:27,920 --> 00:16:31,120
prometheus for remedy

00:16:31,199 --> 00:16:34,800
so we look at high level agenda where

00:16:34,160 --> 00:16:38,079
rumi

00:16:34,800 --> 00:16:40,320
remedy fits in the prometheus and

00:16:38,079 --> 00:16:41,120
what are the use cases for it and how

00:16:40,320 --> 00:16:43,519
can

00:16:41,120 --> 00:16:44,320
we implement a remedy solution what are

00:16:43,519 --> 00:16:46,000
the challenges

00:16:44,320 --> 00:16:48,079
and stuff like that and how we can also

00:16:46,000 --> 00:16:50,320
overcome them

00:16:48,079 --> 00:16:52,320
so this is a high level uh prometheus

00:16:50,320 --> 00:16:53,440
architecture uh nowadays prometheus has

00:16:52,320 --> 00:16:54,959
become a defective standard in

00:16:53,440 --> 00:16:57,120
kubernetes monitoring

00:16:54,959 --> 00:16:58,800
uh and it kind of pulls up data from

00:16:57,120 --> 00:17:02,000
various different uh

00:16:58,800 --> 00:17:03,759
sources and elect manager kind of gets

00:17:02,000 --> 00:17:05,360
those metrics and validates against the

00:17:03,759 --> 00:17:07,919
alerts that we have defined

00:17:05,360 --> 00:17:08,880
uh and if a particular criteria is met

00:17:07,919 --> 00:17:10,559
it will kind of

00:17:08,880 --> 00:17:12,319
send the alerts through notification

00:17:10,559 --> 00:17:14,000
channels the challenge here is that a

00:17:12,319 --> 00:17:16,959
human intervention is needed

00:17:14,000 --> 00:17:19,520
uh for example to pick up that alert and

00:17:16,959 --> 00:17:21,439
then kind of act upon the alerts because

00:17:19,520 --> 00:17:24,160
of which the mean time to recover

00:17:21,439 --> 00:17:26,480
uh can be high uh instead if we know a

00:17:24,160 --> 00:17:29,600
particular pattern of uh scenario we can

00:17:26,480 --> 00:17:32,240
implement a remedy solution uh for it

00:17:29,600 --> 00:17:34,000
uh with which the recovery time for a

00:17:32,240 --> 00:17:36,080
given issue can be less

00:17:34,000 --> 00:17:37,200
uh if you look into it there can be any

00:17:36,080 --> 00:17:38,930
number of use cases

00:17:37,200 --> 00:17:40,320
for such

00:17:38,930 --> 00:17:42,160
[Music]

00:17:40,320 --> 00:17:44,640
you know scenarios right uh example a

00:17:42,160 --> 00:17:47,039
dns pod can be in a bad state and we can

00:17:44,640 --> 00:17:50,160
go ahead and delete it and ensure that

00:17:47,039 --> 00:17:51,919
it comes up fine uh or the cpu or memory

00:17:50,160 --> 00:17:53,919
given pod is high we can go and delete

00:17:51,919 --> 00:17:56,880
those parts and

00:17:53,919 --> 00:17:58,640
the new parts comes up clean and in the

00:17:56,880 --> 00:18:01,840
back end we can anyway troubleshoot

00:17:58,640 --> 00:18:04,480
why they went high or if

00:18:01,840 --> 00:18:05,919
a storage volume is high say example in

00:18:04,480 --> 00:18:09,120
a prometheus storage

00:18:05,919 --> 00:18:12,240
uh we can kind of delete the old set of

00:18:09,120 --> 00:18:12,960
metrics that we don't need or we know

00:18:12,240 --> 00:18:14,880
the metrics

00:18:12,960 --> 00:18:16,799
which have high cardinality those can be

00:18:14,880 --> 00:18:19,440
deleted so there can be a

00:18:16,799 --> 00:18:20,000
bunch of such use cases uh uh we can

00:18:19,440 --> 00:18:22,640
solve

00:18:20,000 --> 00:18:24,400
uh using a remedy solution now how we

00:18:22,640 --> 00:18:26,559
can implement an md solution there can

00:18:24,400 --> 00:18:28,559
be multiple ways one such way is using

00:18:26,559 --> 00:18:30,880
a controller and kubernetes where we can

00:18:28,559 --> 00:18:34,880
define a remedy

00:18:30,880 --> 00:18:38,720
cr like this now i'll quickly show

00:18:34,880 --> 00:18:40,799
uh an already run cr for this

00:18:38,720 --> 00:18:42,799
so here we define the resource that we

00:18:40,799 --> 00:18:43,200
want to monitor it's a pod and we given

00:18:42,799 --> 00:18:45,600
uh

00:18:43,200 --> 00:18:46,880
the definition for the analysis of what

00:18:45,600 --> 00:18:48,799
we want to monitor

00:18:46,880 --> 00:18:50,480
uh here we are looking for uh memory

00:18:48,799 --> 00:18:52,320
utilization and then we give the

00:18:50,480 --> 00:18:54,160
threshold as 95 percentage if we

00:18:52,320 --> 00:18:56,640
process this 95 percentage we define the

00:18:54,160 --> 00:18:58,799
remedy action to delete that

00:18:56,640 --> 00:19:00,320
here we see that the pod is running now

00:18:58,799 --> 00:19:02,960
and then once we launch this

00:19:00,320 --> 00:19:03,760
here after certain time the pod is not

00:19:02,960 --> 00:19:06,480
available

00:19:03,760 --> 00:19:07,120
and if we look into why the port is

00:19:06,480 --> 00:19:11,360
deleted

00:19:07,120 --> 00:19:11,760
see that uh remedy uh analysis is that

00:19:11,360 --> 00:19:14,880
uh

00:19:11,760 --> 00:19:15,200
the memory realization is 99.48 whereas

00:19:14,880 --> 00:19:17,679
the

00:19:15,200 --> 00:19:18,960
threshold is 95 so it exceeded it and

00:19:17,679 --> 00:19:21,039
the analysis uh

00:19:18,960 --> 00:19:22,640
check failed so it went ahead and

00:19:21,039 --> 00:19:23,760
deleted based on the memory action that

00:19:22,640 --> 00:19:26,320
we defined

00:19:23,760 --> 00:19:27,760
so this is a very good use case and now

00:19:26,320 --> 00:19:29,760
there can be any number of such use

00:19:27,760 --> 00:19:32,240
cases that we can

00:19:29,760 --> 00:19:33,039
custom define in the controller but an

00:19:32,240 --> 00:19:34,720
end user

00:19:33,039 --> 00:19:36,400
might have a different scenario which we

00:19:34,720 --> 00:19:39,760
have been thought of and

00:19:36,400 --> 00:19:41,520
he might kind of struggle uh in bringing

00:19:39,760 --> 00:19:42,160
in his use case when we implement it

00:19:41,520 --> 00:19:44,960
with a

00:19:42,160 --> 00:19:46,720
controller uh so and there can be delay

00:19:44,960 --> 00:19:47,600
in order to implement uh his particular

00:19:46,720 --> 00:19:49,919
use case

00:19:47,600 --> 00:19:52,320
instead uh we can solve this using

00:19:49,919 --> 00:19:52,960
active monitor and open source keycode

00:19:52,320 --> 00:19:55,600
project

00:19:52,960 --> 00:19:56,400
here we defined a workflow uh that kind

00:19:55,600 --> 00:19:59,120
of does a

00:19:56,400 --> 00:20:00,720
monitoring for us and here in case uh it

00:19:59,120 --> 00:20:03,039
is kind of looking at

00:20:00,720 --> 00:20:05,120
whether google.com is reachable inside a

00:20:03,039 --> 00:20:07,280
for a given namespace or not

00:20:05,120 --> 00:20:08,480
so we can define a workflow like this

00:20:07,280 --> 00:20:11,120
for monitoring

00:20:08,480 --> 00:20:13,919
uh and in order to have a remedy we can

00:20:11,120 --> 00:20:16,159
also define a remedy workflow

00:20:13,919 --> 00:20:17,520
and then if with this remedy workflow

00:20:16,159 --> 00:20:18,480
what we can do is we can go and

00:20:17,520 --> 00:20:20,720
remediate

00:20:18,480 --> 00:20:21,600
if in case actual monitoring fails for a

00:20:20,720 --> 00:20:23,440
given issue

00:20:21,600 --> 00:20:24,640
and here the user can define what that

00:20:23,440 --> 00:20:26,880
remedy action

00:20:24,640 --> 00:20:28,640
could be uh he can define to delete the

00:20:26,880 --> 00:20:30,640
power or he can define to do any other

00:20:28,640 --> 00:20:32,480
action say

00:20:30,640 --> 00:20:34,320
you know reduce the storage on the

00:20:32,480 --> 00:20:36,880
metrics and stuff like that so

00:20:34,320 --> 00:20:38,640
it can uh it can give that ability for

00:20:36,880 --> 00:20:41,919
the user to define his custom

00:20:38,640 --> 00:20:42,640
remediation action another way it works

00:20:41,919 --> 00:20:44,480
uh

00:20:42,640 --> 00:20:46,480
in the active monitor for the remedy is

00:20:44,480 --> 00:20:49,679
that we define this uh

00:20:46,480 --> 00:20:51,919
workflow for the active monitor

00:20:49,679 --> 00:20:53,840
both for the monitoring workflow as well

00:20:51,919 --> 00:20:54,960
as the remedy workflow and the cr starts

00:20:53,840 --> 00:20:57,679
uh

00:20:54,960 --> 00:20:58,960
executing uh it will pull the data from

00:20:57,679 --> 00:21:01,520
the prometheus to see

00:20:58,960 --> 00:21:02,400
if a particular criteria is met or not

00:21:01,520 --> 00:21:04,480
if

00:21:02,400 --> 00:21:06,240
a particular check analysis stick has

00:21:04,480 --> 00:21:07,120
failed as we have seen in the example

00:21:06,240 --> 00:21:08,640
for memory

00:21:07,120 --> 00:21:10,159
uh it will go ahead and execute the

00:21:08,640 --> 00:21:13,679
remedy workflow and then

00:21:10,159 --> 00:21:16,159
uh it will re rerun the cr

00:21:13,679 --> 00:21:17,840
if in case uh if everything is working

00:21:16,159 --> 00:21:31,840
fine it would go ahead and continue

00:21:17,840 --> 00:21:31,840
monitoring it that's it thank you

00:21:32,320 --> 00:21:34,400

YouTube URL: https://www.youtube.com/watch?v=xOya8uWrVk0


